Epoch: 1| Step: 0
Training loss: 5.0482258796691895
Validation loss: 5.239861026886971

Epoch: 5| Step: 1
Training loss: 6.116814613342285
Validation loss: 5.220991606353431

Epoch: 5| Step: 2
Training loss: 5.166365146636963
Validation loss: 5.203792730967204

Epoch: 5| Step: 3
Training loss: 3.4989001750946045
Validation loss: 5.185741188705609

Epoch: 5| Step: 4
Training loss: 4.791467189788818
Validation loss: 5.16600210948657

Epoch: 5| Step: 5
Training loss: 4.531543731689453
Validation loss: 5.14310388154881

Epoch: 5| Step: 6
Training loss: 5.521796226501465
Validation loss: 5.115996350524246

Epoch: 5| Step: 7
Training loss: 4.0881218910217285
Validation loss: 5.084942612596738

Epoch: 5| Step: 8
Training loss: 5.057890892028809
Validation loss: 5.049164736142722

Epoch: 5| Step: 9
Training loss: 4.522848606109619
Validation loss: 5.009802756770965

Epoch: 5| Step: 10
Training loss: 5.955783843994141
Validation loss: 4.964772924300163

Epoch: 2| Step: 0
Training loss: 4.552709102630615
Validation loss: 4.915294847180767

Epoch: 5| Step: 1
Training loss: 3.7682807445526123
Validation loss: 4.862501270027571

Epoch: 5| Step: 2
Training loss: 4.618537902832031
Validation loss: 4.805557830359346

Epoch: 5| Step: 3
Training loss: 4.474017143249512
Validation loss: 4.746251952263616

Epoch: 5| Step: 4
Training loss: 4.9212164878845215
Validation loss: 4.685455968303065

Epoch: 5| Step: 5
Training loss: 4.543684005737305
Validation loss: 4.625874996185303

Epoch: 5| Step: 6
Training loss: 4.884520530700684
Validation loss: 4.564379174222228

Epoch: 5| Step: 7
Training loss: 3.6856846809387207
Validation loss: 4.5052209900271505

Epoch: 5| Step: 8
Training loss: 4.200293064117432
Validation loss: 4.447844610419325

Epoch: 5| Step: 9
Training loss: 3.7224044799804688
Validation loss: 4.39213038516301

Epoch: 5| Step: 10
Training loss: 5.358696460723877
Validation loss: 4.336874228651806

Epoch: 3| Step: 0
Training loss: 4.990263938903809
Validation loss: 4.281605858956614

Epoch: 5| Step: 1
Training loss: 4.271904945373535
Validation loss: 4.229320520995765

Epoch: 5| Step: 2
Training loss: 5.02235746383667
Validation loss: 4.1788891771788235

Epoch: 5| Step: 3
Training loss: 3.3652381896972656
Validation loss: 4.128998869208879

Epoch: 5| Step: 4
Training loss: 4.215689659118652
Validation loss: 4.079297681008616

Epoch: 5| Step: 5
Training loss: 4.096648216247559
Validation loss: 4.025827689837384

Epoch: 5| Step: 6
Training loss: 4.198976039886475
Validation loss: 3.977332345900997

Epoch: 5| Step: 7
Training loss: 3.5468246936798096
Validation loss: 3.9321758362554733

Epoch: 5| Step: 8
Training loss: 3.2323555946350098
Validation loss: 3.8973468349825953

Epoch: 5| Step: 9
Training loss: 2.950270175933838
Validation loss: 3.872904505780948

Epoch: 5| Step: 10
Training loss: 2.9533276557922363
Validation loss: 3.855079471424062

Epoch: 4| Step: 0
Training loss: 3.351079225540161
Validation loss: 3.8410042588428785

Epoch: 5| Step: 1
Training loss: 3.3336119651794434
Validation loss: 3.8238331169210453

Epoch: 5| Step: 2
Training loss: 3.7729008197784424
Validation loss: 3.805109859794699

Epoch: 5| Step: 3
Training loss: 3.7480788230895996
Validation loss: 3.7802253974381315

Epoch: 5| Step: 4
Training loss: 4.190838813781738
Validation loss: 3.7589567963794996

Epoch: 5| Step: 5
Training loss: 3.548452854156494
Validation loss: 3.7469372518600954

Epoch: 5| Step: 6
Training loss: 4.179914951324463
Validation loss: 3.7289192138179654

Epoch: 5| Step: 7
Training loss: 3.0528616905212402
Validation loss: 3.7149724627053864

Epoch: 5| Step: 8
Training loss: 3.7263247966766357
Validation loss: 3.7029149609227336

Epoch: 5| Step: 9
Training loss: 3.102673053741455
Validation loss: 3.6898871955051216

Epoch: 5| Step: 10
Training loss: 4.1123833656311035
Validation loss: 3.674355076205346

Epoch: 5| Step: 0
Training loss: 3.0187888145446777
Validation loss: 3.6600470337816464

Epoch: 5| Step: 1
Training loss: 4.379822731018066
Validation loss: 3.648413560723746

Epoch: 5| Step: 2
Training loss: 2.624654769897461
Validation loss: 3.634810504092965

Epoch: 5| Step: 3
Training loss: 4.893941879272461
Validation loss: 3.6226759777274182

Epoch: 5| Step: 4
Training loss: 4.273279666900635
Validation loss: 3.6082438909879295

Epoch: 5| Step: 5
Training loss: 2.730659008026123
Validation loss: 3.594067068510158

Epoch: 5| Step: 6
Training loss: 3.571953535079956
Validation loss: 3.581977977547594

Epoch: 5| Step: 7
Training loss: 3.579834461212158
Validation loss: 3.5702434714122484

Epoch: 5| Step: 8
Training loss: 2.6326851844787598
Validation loss: 3.5626145537181566

Epoch: 5| Step: 9
Training loss: 3.7877564430236816
Validation loss: 3.5536604004521526

Epoch: 5| Step: 10
Training loss: 3.1572985649108887
Validation loss: 3.5403865973154702

Epoch: 6| Step: 0
Training loss: 3.7710213661193848
Validation loss: 3.5323343738432853

Epoch: 5| Step: 1
Training loss: 1.5399826765060425
Validation loss: 3.5211186255178144

Epoch: 5| Step: 2
Training loss: 3.1750593185424805
Validation loss: 3.517412390760196

Epoch: 5| Step: 3
Training loss: 3.297985792160034
Validation loss: 3.4986679835986068

Epoch: 5| Step: 4
Training loss: 3.8071117401123047
Validation loss: 3.4964862843995452

Epoch: 5| Step: 5
Training loss: 4.173935890197754
Validation loss: 3.494276310807915

Epoch: 5| Step: 6
Training loss: 3.407033920288086
Validation loss: 3.4844083427101054

Epoch: 5| Step: 7
Training loss: 3.2173476219177246
Validation loss: 3.47100079700511

Epoch: 5| Step: 8
Training loss: 3.1926305294036865
Validation loss: 3.4549758690659718

Epoch: 5| Step: 9
Training loss: 4.123439788818359
Validation loss: 3.438824043479017

Epoch: 5| Step: 10
Training loss: 3.993216037750244
Validation loss: 3.4347250128305085

Epoch: 7| Step: 0
Training loss: 3.1045873165130615
Validation loss: 3.425273556863108

Epoch: 5| Step: 1
Training loss: 3.7193596363067627
Validation loss: 3.4152925078586867

Epoch: 5| Step: 2
Training loss: 3.0454001426696777
Validation loss: 3.4098847758385444

Epoch: 5| Step: 3
Training loss: 2.428274631500244
Validation loss: 3.396607437441426

Epoch: 5| Step: 4
Training loss: 3.60688853263855
Validation loss: 3.38752660956434

Epoch: 5| Step: 5
Training loss: 3.598066806793213
Validation loss: 3.37393932701439

Epoch: 5| Step: 6
Training loss: 3.5023746490478516
Validation loss: 3.3627257911107873

Epoch: 5| Step: 7
Training loss: 3.1912193298339844
Validation loss: 3.3574612294473956

Epoch: 5| Step: 8
Training loss: 3.5080406665802
Validation loss: 3.351080015141477

Epoch: 5| Step: 9
Training loss: 3.5410823822021484
Validation loss: 3.3438625053692888

Epoch: 5| Step: 10
Training loss: 3.421085834503174
Validation loss: 3.3379026971837527

Epoch: 8| Step: 0
Training loss: 2.9819178581237793
Validation loss: 3.3374963319429787

Epoch: 5| Step: 1
Training loss: 2.3917651176452637
Validation loss: 3.3329965504266883

Epoch: 5| Step: 2
Training loss: 3.203467607498169
Validation loss: 3.3234823775547806

Epoch: 5| Step: 3
Training loss: 3.1037685871124268
Validation loss: 3.314308456195298

Epoch: 5| Step: 4
Training loss: 4.019078731536865
Validation loss: 3.309540069231423

Epoch: 5| Step: 5
Training loss: 3.7494819164276123
Validation loss: 3.292764720096383

Epoch: 5| Step: 6
Training loss: 3.7397613525390625
Validation loss: 3.284183374015234

Epoch: 5| Step: 7
Training loss: 2.9219253063201904
Validation loss: 3.282268190896639

Epoch: 5| Step: 8
Training loss: 3.7437102794647217
Validation loss: 3.2769000709697766

Epoch: 5| Step: 9
Training loss: 3.766833782196045
Validation loss: 3.2613035889082056

Epoch: 5| Step: 10
Training loss: 2.1395630836486816
Validation loss: 3.2582260126708658

Epoch: 9| Step: 0
Training loss: 2.62186336517334
Validation loss: 3.2466906424491637

Epoch: 5| Step: 1
Training loss: 3.8574116230010986
Validation loss: 3.2423406544552056

Epoch: 5| Step: 2
Training loss: 3.2667174339294434
Validation loss: 3.2405073847821964

Epoch: 5| Step: 3
Training loss: 2.994962215423584
Validation loss: 3.2395156147659465

Epoch: 5| Step: 4
Training loss: 2.5537970066070557
Validation loss: 3.2269071071378645

Epoch: 5| Step: 5
Training loss: 2.9148306846618652
Validation loss: 3.216492417038128

Epoch: 5| Step: 6
Training loss: 4.369946002960205
Validation loss: 3.2099634857587915

Epoch: 5| Step: 7
Training loss: 3.5059707164764404
Validation loss: 3.2018717796571794

Epoch: 5| Step: 8
Training loss: 2.7657716274261475
Validation loss: 3.198460860918927

Epoch: 5| Step: 9
Training loss: 3.0207245349884033
Validation loss: 3.1928997091067735

Epoch: 5| Step: 10
Training loss: 3.4688925743103027
Validation loss: 3.186729984898721

Epoch: 10| Step: 0
Training loss: 3.2354462146759033
Validation loss: 3.1874323762873167

Epoch: 5| Step: 1
Training loss: 3.4728806018829346
Validation loss: 3.178908132737683

Epoch: 5| Step: 2
Training loss: 3.048072099685669
Validation loss: 3.1776440630676928

Epoch: 5| Step: 3
Training loss: 2.254777193069458
Validation loss: 3.1838369292597615

Epoch: 5| Step: 4
Training loss: 3.6545538902282715
Validation loss: 3.1757473458525953

Epoch: 5| Step: 5
Training loss: 2.926767587661743
Validation loss: 3.162285445838846

Epoch: 5| Step: 6
Training loss: 3.7145392894744873
Validation loss: 3.176089520095497

Epoch: 5| Step: 7
Training loss: 3.8446617126464844
Validation loss: 3.1775919801445416

Epoch: 5| Step: 8
Training loss: 2.6854593753814697
Validation loss: 3.1568102631517636

Epoch: 5| Step: 9
Training loss: 2.975701332092285
Validation loss: 3.1468424591966855

Epoch: 5| Step: 10
Training loss: 3.151244878768921
Validation loss: 3.141071024761405

Epoch: 11| Step: 0
Training loss: 3.8236336708068848
Validation loss: 3.1417226765745427

Epoch: 5| Step: 1
Training loss: 2.8636491298675537
Validation loss: 3.13689673331476

Epoch: 5| Step: 2
Training loss: 2.688455104827881
Validation loss: 3.1282601279597126

Epoch: 5| Step: 3
Training loss: 2.4628117084503174
Validation loss: 3.1216139434486307

Epoch: 5| Step: 4
Training loss: 3.574227809906006
Validation loss: 3.1191566169902845

Epoch: 5| Step: 5
Training loss: 2.8670055866241455
Validation loss: 3.1147358391874578

Epoch: 5| Step: 6
Training loss: 2.9284911155700684
Validation loss: 3.1078859452278382

Epoch: 5| Step: 7
Training loss: 2.818777561187744
Validation loss: 3.107136300815049

Epoch: 5| Step: 8
Training loss: 3.339848041534424
Validation loss: 3.0960099004930064

Epoch: 5| Step: 9
Training loss: 3.244314670562744
Validation loss: 3.0924995432617846

Epoch: 5| Step: 10
Training loss: 4.041563510894775
Validation loss: 3.088272512599986

Epoch: 12| Step: 0
Training loss: 3.5229296684265137
Validation loss: 3.086017744515532

Epoch: 5| Step: 1
Training loss: 2.7301573753356934
Validation loss: 3.0798938915293705

Epoch: 5| Step: 2
Training loss: 4.353404521942139
Validation loss: 3.0735835747052263

Epoch: 5| Step: 3
Training loss: 2.8728466033935547
Validation loss: 3.068238325016473

Epoch: 5| Step: 4
Training loss: 2.7263262271881104
Validation loss: 3.0693844851627143

Epoch: 5| Step: 5
Training loss: 3.0025887489318848
Validation loss: 3.064225527548021

Epoch: 5| Step: 6
Training loss: 3.067409038543701
Validation loss: 3.064519877074867

Epoch: 5| Step: 7
Training loss: 3.058145046234131
Validation loss: 3.0558877837273384

Epoch: 5| Step: 8
Training loss: 2.8694801330566406
Validation loss: 3.052915293683288

Epoch: 5| Step: 9
Training loss: 3.289684772491455
Validation loss: 3.0464905128684094

Epoch: 5| Step: 10
Training loss: 2.5778071880340576
Validation loss: 3.0491397175737607

Epoch: 13| Step: 0
Training loss: 3.0046441555023193
Validation loss: 3.043833573659261

Epoch: 5| Step: 1
Training loss: 2.599674940109253
Validation loss: 3.0399952703906643

Epoch: 5| Step: 2
Training loss: 3.7206873893737793
Validation loss: 3.0366646218043503

Epoch: 5| Step: 3
Training loss: 3.5835506916046143
Validation loss: 3.039849970930366

Epoch: 5| Step: 4
Training loss: 2.991872787475586
Validation loss: 3.0332009971782727

Epoch: 5| Step: 5
Training loss: 3.0972936153411865
Validation loss: 3.0259455660338044

Epoch: 5| Step: 6
Training loss: 2.445183277130127
Validation loss: 3.026138472300704

Epoch: 5| Step: 7
Training loss: 3.1058318614959717
Validation loss: 3.034592197787377

Epoch: 5| Step: 8
Training loss: 2.6508100032806396
Validation loss: 3.030335398130519

Epoch: 5| Step: 9
Training loss: 3.788527727127075
Validation loss: 3.0536315569313626

Epoch: 5| Step: 10
Training loss: 2.9682981967926025
Validation loss: 3.0225780599860737

Epoch: 14| Step: 0
Training loss: 3.471266984939575
Validation loss: 3.013953080741308

Epoch: 5| Step: 1
Training loss: 3.555232524871826
Validation loss: 3.0176923069902646

Epoch: 5| Step: 2
Training loss: 2.904284715652466
Validation loss: 3.0104890946419007

Epoch: 5| Step: 3
Training loss: 2.953983783721924
Validation loss: 3.0063121036816667

Epoch: 5| Step: 4
Training loss: 2.8686094284057617
Validation loss: 3.0039251337769213

Epoch: 5| Step: 5
Training loss: 3.6478431224823
Validation loss: 3.003262145544893

Epoch: 5| Step: 6
Training loss: 2.837923049926758
Validation loss: 3.006881385721186

Epoch: 5| Step: 7
Training loss: 2.7596333026885986
Validation loss: 3.0090764132879113

Epoch: 5| Step: 8
Training loss: 2.551962375640869
Validation loss: 3.002830587407594

Epoch: 5| Step: 9
Training loss: 3.0958938598632812
Validation loss: 2.9926720562801568

Epoch: 5| Step: 10
Training loss: 3.1018447875976562
Validation loss: 2.988992921767696

Epoch: 15| Step: 0
Training loss: 2.942824363708496
Validation loss: 2.987220097613591

Epoch: 5| Step: 1
Training loss: 2.7148990631103516
Validation loss: 2.9827933285825994

Epoch: 5| Step: 2
Training loss: 2.9309685230255127
Validation loss: 2.9780015278888006

Epoch: 5| Step: 3
Training loss: 2.346320629119873
Validation loss: 2.971005726886052

Epoch: 5| Step: 4
Training loss: 2.4516215324401855
Validation loss: 2.968386306557604

Epoch: 5| Step: 5
Training loss: 2.162451982498169
Validation loss: 2.966384123730403

Epoch: 5| Step: 6
Training loss: 3.544158458709717
Validation loss: 2.9662552930975474

Epoch: 5| Step: 7
Training loss: 3.4671478271484375
Validation loss: 2.965945969345749

Epoch: 5| Step: 8
Training loss: 2.747267961502075
Validation loss: 2.962547048445671

Epoch: 5| Step: 9
Training loss: 4.019096851348877
Validation loss: 2.9671367983664236

Epoch: 5| Step: 10
Training loss: 4.363795757293701
Validation loss: 2.9591479019452165

Epoch: 16| Step: 0
Training loss: 2.3069937229156494
Validation loss: 2.9637222828403598

Epoch: 5| Step: 1
Training loss: 3.3353240489959717
Validation loss: 2.9677733862271873

Epoch: 5| Step: 2
Training loss: 2.3704018592834473
Validation loss: 2.967497161639634

Epoch: 5| Step: 3
Training loss: 3.561676025390625
Validation loss: 2.9681260867785384

Epoch: 5| Step: 4
Training loss: 3.133523941040039
Validation loss: 2.9552846647077993

Epoch: 5| Step: 5
Training loss: 3.3594093322753906
Validation loss: 2.947863737742106

Epoch: 5| Step: 6
Training loss: 3.7530517578125
Validation loss: 2.9492219904417634

Epoch: 5| Step: 7
Training loss: 3.20379900932312
Validation loss: 2.9536071644034436

Epoch: 5| Step: 8
Training loss: 2.7499797344207764
Validation loss: 2.9538610340446554

Epoch: 5| Step: 9
Training loss: 2.294037342071533
Validation loss: 2.944548240271948

Epoch: 5| Step: 10
Training loss: 3.344846487045288
Validation loss: 2.947041073153096

Epoch: 17| Step: 0
Training loss: 3.1286513805389404
Validation loss: 2.943522378962527

Epoch: 5| Step: 1
Training loss: 2.787191867828369
Validation loss: 2.9418656697837253

Epoch: 5| Step: 2
Training loss: 2.7912845611572266
Validation loss: 2.9499132505027195

Epoch: 5| Step: 3
Training loss: 3.032581090927124
Validation loss: 2.950484839818811

Epoch: 5| Step: 4
Training loss: 3.994398593902588
Validation loss: 2.9424727937226653

Epoch: 5| Step: 5
Training loss: 2.5137670040130615
Validation loss: 2.9361893925615536

Epoch: 5| Step: 6
Training loss: 2.7258763313293457
Validation loss: 2.9322086252192014

Epoch: 5| Step: 7
Training loss: 2.640890121459961
Validation loss: 2.9305063498917447

Epoch: 5| Step: 8
Training loss: 2.810652732849121
Validation loss: 2.9452708613487983

Epoch: 5| Step: 9
Training loss: 3.4183526039123535
Validation loss: 2.9367294824251564

Epoch: 5| Step: 10
Training loss: 3.468177556991577
Validation loss: 2.926396131515503

Epoch: 18| Step: 0
Training loss: 2.289506673812866
Validation loss: 2.923547375586725

Epoch: 5| Step: 1
Training loss: 2.5475211143493652
Validation loss: 2.9327522580341627

Epoch: 5| Step: 2
Training loss: 2.566596508026123
Validation loss: 2.9624247268963884

Epoch: 5| Step: 3
Training loss: 2.658172130584717
Validation loss: 2.9442081682143675

Epoch: 5| Step: 4
Training loss: 3.2306466102600098
Validation loss: 2.941726717897641

Epoch: 5| Step: 5
Training loss: 2.824470043182373
Validation loss: 2.9377770757162445

Epoch: 5| Step: 6
Training loss: 2.9549736976623535
Validation loss: 2.9181127830218245

Epoch: 5| Step: 7
Training loss: 3.7105331420898438
Validation loss: 2.9132479467699604

Epoch: 5| Step: 8
Training loss: 3.814995527267456
Validation loss: 2.916569520068425

Epoch: 5| Step: 9
Training loss: 3.474780559539795
Validation loss: 2.912835036554644

Epoch: 5| Step: 10
Training loss: 3.064413070678711
Validation loss: 2.9144222505630983

Epoch: 19| Step: 0
Training loss: 2.378640651702881
Validation loss: 2.913292308007517

Epoch: 5| Step: 1
Training loss: 2.900660991668701
Validation loss: 2.90992574537954

Epoch: 5| Step: 2
Training loss: 2.803915500640869
Validation loss: 2.907502507650724

Epoch: 5| Step: 3
Training loss: 3.2519004344940186
Validation loss: 2.909421382411834

Epoch: 5| Step: 4
Training loss: 2.832253932952881
Validation loss: 2.9146075581991546

Epoch: 5| Step: 5
Training loss: 2.746481418609619
Validation loss: 2.9154404876052693

Epoch: 5| Step: 6
Training loss: 3.1766631603240967
Validation loss: 2.9032047153801046

Epoch: 5| Step: 7
Training loss: 2.972320079803467
Validation loss: 2.902742708882978

Epoch: 5| Step: 8
Training loss: 2.9705986976623535
Validation loss: 2.899563632985597

Epoch: 5| Step: 9
Training loss: 3.4923882484436035
Validation loss: 2.897436293222571

Epoch: 5| Step: 10
Training loss: 3.540586471557617
Validation loss: 2.8920097479256253

Epoch: 20| Step: 0
Training loss: 2.9599900245666504
Validation loss: 2.890243596928094

Epoch: 5| Step: 1
Training loss: 3.767195463180542
Validation loss: 2.8943448092347834

Epoch: 5| Step: 2
Training loss: 3.3366801738739014
Validation loss: 2.89008242084134

Epoch: 5| Step: 3
Training loss: 3.007035970687866
Validation loss: 2.892214767394527

Epoch: 5| Step: 4
Training loss: 3.371499538421631
Validation loss: 2.891669278503746

Epoch: 5| Step: 5
Training loss: 2.1679561138153076
Validation loss: 2.8856851413685787

Epoch: 5| Step: 6
Training loss: 2.985154390335083
Validation loss: 2.8878681634062078

Epoch: 5| Step: 7
Training loss: 3.3389878273010254
Validation loss: 2.895393774073611

Epoch: 5| Step: 8
Training loss: 2.88714337348938
Validation loss: 2.9026663226466023

Epoch: 5| Step: 9
Training loss: 2.1554787158966064
Validation loss: 2.916891533841369

Epoch: 5| Step: 10
Training loss: 2.9757988452911377
Validation loss: 2.9549247654535438

Epoch: 21| Step: 0
Training loss: 3.192502498626709
Validation loss: 2.9172011780482467

Epoch: 5| Step: 1
Training loss: 3.2485556602478027
Validation loss: 2.9097745495457805

Epoch: 5| Step: 2
Training loss: 3.450352907180786
Validation loss: 2.896868654476699

Epoch: 5| Step: 3
Training loss: 3.034864664077759
Validation loss: 2.8886015466464463

Epoch: 5| Step: 4
Training loss: 2.176819324493408
Validation loss: 2.8814314565350934

Epoch: 5| Step: 5
Training loss: 3.442579984664917
Validation loss: 2.8849257551213747

Epoch: 5| Step: 6
Training loss: 2.2938897609710693
Validation loss: 2.8837091179304224

Epoch: 5| Step: 7
Training loss: 2.9149458408355713
Validation loss: 2.8802155551090034

Epoch: 5| Step: 8
Training loss: 3.018057346343994
Validation loss: 2.881317694981893

Epoch: 5| Step: 9
Training loss: 3.6159560680389404
Validation loss: 2.8836916133921635

Epoch: 5| Step: 10
Training loss: 2.3099818229675293
Validation loss: 2.8948488440564883

Epoch: 22| Step: 0
Training loss: 2.5549111366271973
Validation loss: 2.9256563699373634

Epoch: 5| Step: 1
Training loss: 2.975796937942505
Validation loss: 2.93813927455615

Epoch: 5| Step: 2
Training loss: 3.3393940925598145
Validation loss: 2.9182804758830736

Epoch: 5| Step: 3
Training loss: 2.9094130992889404
Validation loss: 2.8757340267140377

Epoch: 5| Step: 4
Training loss: 3.091700315475464
Validation loss: 2.8739452285151326

Epoch: 5| Step: 5
Training loss: 2.9148459434509277
Validation loss: 2.956669433142549

Epoch: 5| Step: 6
Training loss: 3.2967371940612793
Validation loss: 2.968070671122561

Epoch: 5| Step: 7
Training loss: 3.0592198371887207
Validation loss: 2.896466898661788

Epoch: 5| Step: 8
Training loss: 2.722843647003174
Validation loss: 2.8786046786974837

Epoch: 5| Step: 9
Training loss: 2.90126371383667
Validation loss: 2.8964720003066526

Epoch: 5| Step: 10
Training loss: 3.394423246383667
Validation loss: 2.9242327213287354

Epoch: 23| Step: 0
Training loss: 3.1433796882629395
Validation loss: 2.937961611696469

Epoch: 5| Step: 1
Training loss: 2.979940891265869
Validation loss: 2.9200507761329733

Epoch: 5| Step: 2
Training loss: 2.7085723876953125
Validation loss: 2.892090161641439

Epoch: 5| Step: 3
Training loss: 3.2967476844787598
Validation loss: 2.8813403114195792

Epoch: 5| Step: 4
Training loss: 3.0809245109558105
Validation loss: 2.876148046985749

Epoch: 5| Step: 5
Training loss: 1.8563381433486938
Validation loss: 2.886333965486096

Epoch: 5| Step: 6
Training loss: 3.359691619873047
Validation loss: 2.9085824284502255

Epoch: 5| Step: 7
Training loss: 3.154557466506958
Validation loss: 2.8798046419697423

Epoch: 5| Step: 8
Training loss: 3.367968797683716
Validation loss: 2.8655569630284465

Epoch: 5| Step: 9
Training loss: 2.823397159576416
Validation loss: 2.866932197283673

Epoch: 5| Step: 10
Training loss: 3.0796852111816406
Validation loss: 2.865919531032603

Epoch: 24| Step: 0
Training loss: 3.0098955631256104
Validation loss: 2.861949764272218

Epoch: 5| Step: 1
Training loss: 2.988223075866699
Validation loss: 2.870370252158052

Epoch: 5| Step: 2
Training loss: 2.5991291999816895
Validation loss: 2.870305145940473

Epoch: 5| Step: 3
Training loss: 3.437474489212036
Validation loss: 2.882307490994853

Epoch: 5| Step: 4
Training loss: 2.3107032775878906
Validation loss: 2.886574650323519

Epoch: 5| Step: 5
Training loss: 2.9229745864868164
Validation loss: 2.880910540139803

Epoch: 5| Step: 6
Training loss: 3.0455825328826904
Validation loss: 2.8652735115379415

Epoch: 5| Step: 7
Training loss: 3.3780574798583984
Validation loss: 2.8502243436792845

Epoch: 5| Step: 8
Training loss: 2.6201395988464355
Validation loss: 2.8492126772480626

Epoch: 5| Step: 9
Training loss: 2.9281795024871826
Validation loss: 2.851832600050075

Epoch: 5| Step: 10
Training loss: 3.445155143737793
Validation loss: 2.852652544616371

Epoch: 25| Step: 0
Training loss: 3.2020668983459473
Validation loss: 2.8589448672468945

Epoch: 5| Step: 1
Training loss: 3.1010804176330566
Validation loss: 2.8812378683397846

Epoch: 5| Step: 2
Training loss: 3.107504367828369
Validation loss: 2.877456247165639

Epoch: 5| Step: 3
Training loss: 3.469313144683838
Validation loss: 2.8478830245233353

Epoch: 5| Step: 4
Training loss: 2.411125659942627
Validation loss: 2.8417611839950725

Epoch: 5| Step: 5
Training loss: 2.2699074745178223
Validation loss: 2.8431168448540474

Epoch: 5| Step: 6
Training loss: 3.4741759300231934
Validation loss: 2.8441435880558465

Epoch: 5| Step: 7
Training loss: 3.127315044403076
Validation loss: 2.859153252775951

Epoch: 5| Step: 8
Training loss: 3.1719508171081543
Validation loss: 2.854422110383229

Epoch: 5| Step: 9
Training loss: 2.461961269378662
Validation loss: 2.848835427273986

Epoch: 5| Step: 10
Training loss: 2.750638723373413
Validation loss: 2.8385562819819294

Epoch: 26| Step: 0
Training loss: 2.9375622272491455
Validation loss: 2.8365455750496156

Epoch: 5| Step: 1
Training loss: 3.054832935333252
Validation loss: 2.834287166595459

Epoch: 5| Step: 2
Training loss: 2.8768467903137207
Validation loss: 2.834851477735786

Epoch: 5| Step: 3
Training loss: 2.8512251377105713
Validation loss: 2.832448951659664

Epoch: 5| Step: 4
Training loss: 3.1401209831237793
Validation loss: 2.8313199166328675

Epoch: 5| Step: 5
Training loss: 2.5620338916778564
Validation loss: 2.8312747837394796

Epoch: 5| Step: 6
Training loss: 3.118875503540039
Validation loss: 2.833468588449622

Epoch: 5| Step: 7
Training loss: 2.6597225666046143
Validation loss: 2.833234917732977

Epoch: 5| Step: 8
Training loss: 2.6411101818084717
Validation loss: 2.832397894192767

Epoch: 5| Step: 9
Training loss: 3.3252811431884766
Validation loss: 2.8345760376222673

Epoch: 5| Step: 10
Training loss: 3.253972053527832
Validation loss: 2.830726695317094

Epoch: 27| Step: 0
Training loss: 3.6185219287872314
Validation loss: 2.827736821225894

Epoch: 5| Step: 1
Training loss: 3.0586326122283936
Validation loss: 2.824842465821133

Epoch: 5| Step: 2
Training loss: 2.677004814147949
Validation loss: 2.8247449218585925

Epoch: 5| Step: 3
Training loss: 2.3400235176086426
Validation loss: 2.822232405344645

Epoch: 5| Step: 4
Training loss: 2.6025614738464355
Validation loss: 2.824207180289812

Epoch: 5| Step: 5
Training loss: 2.923236608505249
Validation loss: 2.829691025518602

Epoch: 5| Step: 6
Training loss: 3.029554843902588
Validation loss: 2.8267340173003492

Epoch: 5| Step: 7
Training loss: 2.958259105682373
Validation loss: 2.830411280355146

Epoch: 5| Step: 8
Training loss: 2.4960670471191406
Validation loss: 2.8295918433896956

Epoch: 5| Step: 9
Training loss: 3.4733893871307373
Validation loss: 2.8277340960758988

Epoch: 5| Step: 10
Training loss: 3.1451144218444824
Validation loss: 2.8231806549974667

Epoch: 28| Step: 0
Training loss: 3.3287456035614014
Validation loss: 2.816852587525563

Epoch: 5| Step: 1
Training loss: 3.0481128692626953
Validation loss: 2.817466333348264

Epoch: 5| Step: 2
Training loss: 3.5380866527557373
Validation loss: 2.8156527319262104

Epoch: 5| Step: 3
Training loss: 2.843228578567505
Validation loss: 2.809766182335474

Epoch: 5| Step: 4
Training loss: 2.591005802154541
Validation loss: 2.8128702307260163

Epoch: 5| Step: 5
Training loss: 2.5337107181549072
Validation loss: 2.8109271141790573

Epoch: 5| Step: 6
Training loss: 2.9851906299591064
Validation loss: 2.811767275615405

Epoch: 5| Step: 7
Training loss: 3.486138105392456
Validation loss: 2.813891569773356

Epoch: 5| Step: 8
Training loss: 2.5278563499450684
Validation loss: 2.8131013454929477

Epoch: 5| Step: 9
Training loss: 2.392976999282837
Validation loss: 2.8201489910002677

Epoch: 5| Step: 10
Training loss: 2.9919233322143555
Validation loss: 2.8276619577920563

Epoch: 29| Step: 0
Training loss: 3.2908248901367188
Validation loss: 2.815648650610319

Epoch: 5| Step: 1
Training loss: 2.594547748565674
Validation loss: 2.809461260354647

Epoch: 5| Step: 2
Training loss: 3.010291576385498
Validation loss: 2.8052517009037796

Epoch: 5| Step: 3
Training loss: 3.360307216644287
Validation loss: 2.8066461855365383

Epoch: 5| Step: 4
Training loss: 3.14039945602417
Validation loss: 2.8062369926001436

Epoch: 5| Step: 5
Training loss: 2.9475302696228027
Validation loss: 2.8053567704334053

Epoch: 5| Step: 6
Training loss: 2.0445806980133057
Validation loss: 2.8045557980896323

Epoch: 5| Step: 7
Training loss: 2.9160406589508057
Validation loss: 2.8016637858524116

Epoch: 5| Step: 8
Training loss: 3.0478928089141846
Validation loss: 2.798914752980714

Epoch: 5| Step: 9
Training loss: 3.248870372772217
Validation loss: 2.801404353111021

Epoch: 5| Step: 10
Training loss: 2.4783899784088135
Validation loss: 2.800243362303703

Epoch: 30| Step: 0
Training loss: 2.3040382862091064
Validation loss: 2.801219058293168

Epoch: 5| Step: 1
Training loss: 4.011298179626465
Validation loss: 2.7989724092586066

Epoch: 5| Step: 2
Training loss: 3.7522683143615723
Validation loss: 2.7983084288976525

Epoch: 5| Step: 3
Training loss: 2.8391947746276855
Validation loss: 2.7964722392379597

Epoch: 5| Step: 4
Training loss: 2.4198341369628906
Validation loss: 2.7954941359899377

Epoch: 5| Step: 5
Training loss: 2.9128644466400146
Validation loss: 2.797452267780099

Epoch: 5| Step: 6
Training loss: 2.1307196617126465
Validation loss: 2.794259625096475

Epoch: 5| Step: 7
Training loss: 3.0348377227783203
Validation loss: 2.793534678797568

Epoch: 5| Step: 8
Training loss: 2.8837990760803223
Validation loss: 2.796024722437705

Epoch: 5| Step: 9
Training loss: 2.0443177223205566
Validation loss: 2.7984138714369906

Epoch: 5| Step: 10
Training loss: 3.8622751235961914
Validation loss: 2.8027032062571537

Epoch: 31| Step: 0
Training loss: 3.6742897033691406
Validation loss: 2.8073260091966197

Epoch: 5| Step: 1
Training loss: 3.416255235671997
Validation loss: 2.822003746545443

Epoch: 5| Step: 2
Training loss: 2.2375340461730957
Validation loss: 2.8290061232864216

Epoch: 5| Step: 3
Training loss: 2.381155490875244
Validation loss: 2.794985878852106

Epoch: 5| Step: 4
Training loss: 3.351248264312744
Validation loss: 2.786625603193878

Epoch: 5| Step: 5
Training loss: 3.3748269081115723
Validation loss: 2.7832800111462994

Epoch: 5| Step: 6
Training loss: 2.682581663131714
Validation loss: 2.7940084754779773

Epoch: 5| Step: 7
Training loss: 2.7737855911254883
Validation loss: 2.8185315106504705

Epoch: 5| Step: 8
Training loss: 2.954108476638794
Validation loss: 2.8145757618770806

Epoch: 5| Step: 9
Training loss: 2.416086435317993
Validation loss: 2.8007032794337117

Epoch: 5| Step: 10
Training loss: 2.8079493045806885
Validation loss: 2.8064506669198312

Epoch: 32| Step: 0
Training loss: 2.816179037094116
Validation loss: 2.786985748557634

Epoch: 5| Step: 1
Training loss: 3.511263608932495
Validation loss: 2.7832923832760064

Epoch: 5| Step: 2
Training loss: 3.294264316558838
Validation loss: 2.7830719793996503

Epoch: 5| Step: 3
Training loss: 2.073759078979492
Validation loss: 2.7820352097993255

Epoch: 5| Step: 4
Training loss: 3.2071776390075684
Validation loss: 2.7802795364010717

Epoch: 5| Step: 5
Training loss: 2.8943867683410645
Validation loss: 2.783311464453256

Epoch: 5| Step: 6
Training loss: 3.0486583709716797
Validation loss: 2.782035384126889

Epoch: 5| Step: 7
Training loss: 2.873678207397461
Validation loss: 2.788851866158106

Epoch: 5| Step: 8
Training loss: 2.8667426109313965
Validation loss: 2.794459040446948

Epoch: 5| Step: 9
Training loss: 2.18572998046875
Validation loss: 2.8123271490937922

Epoch: 5| Step: 10
Training loss: 3.23160719871521
Validation loss: 2.8060513773272113

Epoch: 33| Step: 0
Training loss: 2.523425340652466
Validation loss: 2.7981333578786542

Epoch: 5| Step: 1
Training loss: 2.3280298709869385
Validation loss: 2.7769510412728913

Epoch: 5| Step: 2
Training loss: 3.197613477706909
Validation loss: 2.774834391891315

Epoch: 5| Step: 3
Training loss: 2.8391835689544678
Validation loss: 2.770658452023742

Epoch: 5| Step: 4
Training loss: 3.0419814586639404
Validation loss: 2.7877583221722673

Epoch: 5| Step: 5
Training loss: 2.891516923904419
Validation loss: 2.787160514503397

Epoch: 5| Step: 6
Training loss: 3.782156467437744
Validation loss: 2.776952756348477

Epoch: 5| Step: 7
Training loss: 2.8229165077209473
Validation loss: 2.7629326415318314

Epoch: 5| Step: 8
Training loss: 3.193162441253662
Validation loss: 2.75691056764254

Epoch: 5| Step: 9
Training loss: 3.2790329456329346
Validation loss: 2.759648564041302

Epoch: 5| Step: 10
Training loss: 1.6965581178665161
Validation loss: 2.752141519259381

Epoch: 34| Step: 0
Training loss: 3.450143337249756
Validation loss: 2.758449205788233

Epoch: 5| Step: 1
Training loss: 3.280654191970825
Validation loss: 2.7588271505089215

Epoch: 5| Step: 2
Training loss: 2.642246723175049
Validation loss: 2.7621162963169876

Epoch: 5| Step: 3
Training loss: 3.8613038063049316
Validation loss: 2.7500499269013763

Epoch: 5| Step: 4
Training loss: 2.4896512031555176
Validation loss: 2.7572512447193103

Epoch: 5| Step: 5
Training loss: 2.9189534187316895
Validation loss: 2.7532135722457722

Epoch: 5| Step: 6
Training loss: 1.9438457489013672
Validation loss: 2.7492705980936685

Epoch: 5| Step: 7
Training loss: 2.3651390075683594
Validation loss: 2.7486834192788727

Epoch: 5| Step: 8
Training loss: 3.3639583587646484
Validation loss: 2.7548305988311768

Epoch: 5| Step: 9
Training loss: 2.3770668506622314
Validation loss: 2.7434036398446686

Epoch: 5| Step: 10
Training loss: 2.8501217365264893
Validation loss: 2.7384014257820706

Epoch: 35| Step: 0
Training loss: 2.274933338165283
Validation loss: 2.7328852453539447

Epoch: 5| Step: 1
Training loss: 3.2455315589904785
Validation loss: 2.7302657583708405

Epoch: 5| Step: 2
Training loss: 3.31554913520813
Validation loss: 2.7315659599919475

Epoch: 5| Step: 3
Training loss: 2.3614251613616943
Validation loss: 2.7302082405295423

Epoch: 5| Step: 4
Training loss: 2.875631332397461
Validation loss: 2.7306543268183225

Epoch: 5| Step: 5
Training loss: 2.5547585487365723
Validation loss: 2.743531060475175

Epoch: 5| Step: 6
Training loss: 3.5075936317443848
Validation loss: 2.7477277914683023

Epoch: 5| Step: 7
Training loss: 2.2817769050598145
Validation loss: 2.7364766597747803

Epoch: 5| Step: 8
Training loss: 2.978015899658203
Validation loss: 2.730858323394611

Epoch: 5| Step: 9
Training loss: 3.0887744426727295
Validation loss: 2.7312884869114047

Epoch: 5| Step: 10
Training loss: 3.0147905349731445
Validation loss: 2.735129822966873

Epoch: 36| Step: 0
Training loss: 3.4254660606384277
Validation loss: 2.723844130833944

Epoch: 5| Step: 1
Training loss: 2.7138442993164062
Validation loss: 2.719727446956019

Epoch: 5| Step: 2
Training loss: 3.041842460632324
Validation loss: 2.7191713087020384

Epoch: 5| Step: 3
Training loss: 2.69867205619812
Validation loss: 2.7209456505314

Epoch: 5| Step: 4
Training loss: 3.605574131011963
Validation loss: 2.722419026077435

Epoch: 5| Step: 5
Training loss: 2.329720973968506
Validation loss: 2.729885116700203

Epoch: 5| Step: 6
Training loss: 2.416682004928589
Validation loss: 2.7318253004422752

Epoch: 5| Step: 7
Training loss: 3.3930022716522217
Validation loss: 2.7292754957752843

Epoch: 5| Step: 8
Training loss: 2.784532070159912
Validation loss: 2.7179077979057067

Epoch: 5| Step: 9
Training loss: 2.237077236175537
Validation loss: 2.7188086125158493

Epoch: 5| Step: 10
Training loss: 2.558892250061035
Validation loss: 2.7173218291292907

Epoch: 37| Step: 0
Training loss: 2.4624128341674805
Validation loss: 2.725696691902735

Epoch: 5| Step: 1
Training loss: 2.533579111099243
Validation loss: 2.7208522955576577

Epoch: 5| Step: 2
Training loss: 2.781660795211792
Validation loss: 2.717370048646004

Epoch: 5| Step: 3
Training loss: 2.954946517944336
Validation loss: 2.7263957300493793

Epoch: 5| Step: 4
Training loss: 2.85780668258667
Validation loss: 2.719884664781632

Epoch: 5| Step: 5
Training loss: 2.8014140129089355
Validation loss: 2.7207598327308573

Epoch: 5| Step: 6
Training loss: 2.9072399139404297
Validation loss: 2.713624249222458

Epoch: 5| Step: 7
Training loss: 2.4143497943878174
Validation loss: 2.7074314137940765

Epoch: 5| Step: 8
Training loss: 2.2571325302124023
Validation loss: 2.706165470102782

Epoch: 5| Step: 9
Training loss: 4.138303279876709
Validation loss: 2.7065872069328063

Epoch: 5| Step: 10
Training loss: 3.1783902645111084
Validation loss: 2.708054055449783

Epoch: 38| Step: 0
Training loss: 2.63946270942688
Validation loss: 2.7037929693857827

Epoch: 5| Step: 1
Training loss: 3.230618715286255
Validation loss: 2.69979916849444

Epoch: 5| Step: 2
Training loss: 2.8601155281066895
Validation loss: 2.7010582544470347

Epoch: 5| Step: 3
Training loss: 2.561913013458252
Validation loss: 2.709641246385472

Epoch: 5| Step: 4
Training loss: 2.298041582107544
Validation loss: 2.70822141503775

Epoch: 5| Step: 5
Training loss: 3.2658772468566895
Validation loss: 2.7177986688511346

Epoch: 5| Step: 6
Training loss: 2.489152431488037
Validation loss: 2.756296327037196

Epoch: 5| Step: 7
Training loss: 3.2184531688690186
Validation loss: 2.7189898695997012

Epoch: 5| Step: 8
Training loss: 3.210402727127075
Validation loss: 2.7074647795769478

Epoch: 5| Step: 9
Training loss: 1.921250581741333
Validation loss: 2.70558488240806

Epoch: 5| Step: 10
Training loss: 3.6424503326416016
Validation loss: 2.7435109615325928

Epoch: 39| Step: 0
Training loss: 3.1172680854797363
Validation loss: 2.7698418145538657

Epoch: 5| Step: 1
Training loss: 2.1663355827331543
Validation loss: 2.78308948650155

Epoch: 5| Step: 2
Training loss: 2.8297641277313232
Validation loss: 2.7471088183823453

Epoch: 5| Step: 3
Training loss: 2.404667854309082
Validation loss: 2.71651872768197

Epoch: 5| Step: 4
Training loss: 3.178422451019287
Validation loss: 2.707101798826648

Epoch: 5| Step: 5
Training loss: 2.270650625228882
Validation loss: 2.7095291332532

Epoch: 5| Step: 6
Training loss: 2.8737220764160156
Validation loss: 2.7048161388725362

Epoch: 5| Step: 7
Training loss: 3.158276081085205
Validation loss: 2.7241721512168966

Epoch: 5| Step: 8
Training loss: 3.4170327186584473
Validation loss: 2.7777660969764955

Epoch: 5| Step: 9
Training loss: 2.368258476257324
Validation loss: 2.780342343033001

Epoch: 5| Step: 10
Training loss: 3.6763246059417725
Validation loss: 2.7296758928606586

Epoch: 40| Step: 0
Training loss: 2.1646666526794434
Validation loss: 2.6979345198600524

Epoch: 5| Step: 1
Training loss: 3.037712812423706
Validation loss: 2.6905475739509828

Epoch: 5| Step: 2
Training loss: 3.104004144668579
Validation loss: 2.688310835951118

Epoch: 5| Step: 3
Training loss: 2.5324490070343018
Validation loss: 2.684346286199426

Epoch: 5| Step: 4
Training loss: 3.352856397628784
Validation loss: 2.690280117014403

Epoch: 5| Step: 5
Training loss: 2.737966537475586
Validation loss: 2.692274211555399

Epoch: 5| Step: 6
Training loss: 2.969130039215088
Validation loss: 2.6923566377291115

Epoch: 5| Step: 7
Training loss: 3.045330762863159
Validation loss: 2.6934180926251154

Epoch: 5| Step: 8
Training loss: 2.2790780067443848
Validation loss: 2.6923510105379167

Epoch: 5| Step: 9
Training loss: 2.9274380207061768
Validation loss: 2.6924553020026094

Epoch: 5| Step: 10
Training loss: 2.8580238819122314
Validation loss: 2.687284272204163

Epoch: 41| Step: 0
Training loss: 2.938218355178833
Validation loss: 2.685151564177646

Epoch: 5| Step: 1
Training loss: 2.5617780685424805
Validation loss: 2.6907222142783542

Epoch: 5| Step: 2
Training loss: 3.058349132537842
Validation loss: 2.694094650207027

Epoch: 5| Step: 3
Training loss: 3.0338289737701416
Validation loss: 2.6943054071036716

Epoch: 5| Step: 4
Training loss: 2.4265313148498535
Validation loss: 2.6750091583498063

Epoch: 5| Step: 5
Training loss: 2.466578245162964
Validation loss: 2.6769181323307816

Epoch: 5| Step: 6
Training loss: 3.1041109561920166
Validation loss: 2.6793731130579466

Epoch: 5| Step: 7
Training loss: 3.3101706504821777
Validation loss: 2.6822339873160086

Epoch: 5| Step: 8
Training loss: 2.9654948711395264
Validation loss: 2.6830435183740433

Epoch: 5| Step: 9
Training loss: 2.3736958503723145
Validation loss: 2.682095548158051

Epoch: 5| Step: 10
Training loss: 2.6661853790283203
Validation loss: 2.6734796185647287

Epoch: 42| Step: 0
Training loss: 3.112351894378662
Validation loss: 2.6687052403726885

Epoch: 5| Step: 1
Training loss: 2.7801976203918457
Validation loss: 2.666781143475604

Epoch: 5| Step: 2
Training loss: 3.570528745651245
Validation loss: 2.670735841156334

Epoch: 5| Step: 3
Training loss: 3.2781856060028076
Validation loss: 2.6703920620743946

Epoch: 5| Step: 4
Training loss: 2.564558506011963
Validation loss: 2.6845377235002417

Epoch: 5| Step: 5
Training loss: 2.050158977508545
Validation loss: 2.6855625849898144

Epoch: 5| Step: 6
Training loss: 3.418616771697998
Validation loss: 2.7337053770660074

Epoch: 5| Step: 7
Training loss: 2.96494722366333
Validation loss: 2.732987901215912

Epoch: 5| Step: 8
Training loss: 2.5594286918640137
Validation loss: 2.696387273009105

Epoch: 5| Step: 9
Training loss: 2.444617509841919
Validation loss: 2.663486978059174

Epoch: 5| Step: 10
Training loss: 2.2135260105133057
Validation loss: 2.673766956534437

Epoch: 43| Step: 0
Training loss: 2.89526104927063
Validation loss: 2.6990405436485045

Epoch: 5| Step: 1
Training loss: 2.724716901779175
Validation loss: 2.710830621821906

Epoch: 5| Step: 2
Training loss: 3.689502000808716
Validation loss: 2.6750170543629634

Epoch: 5| Step: 3
Training loss: 3.1250483989715576
Validation loss: 2.667252012478408

Epoch: 5| Step: 4
Training loss: 1.8859186172485352
Validation loss: 2.658768953815583

Epoch: 5| Step: 5
Training loss: 3.2605488300323486
Validation loss: 2.660650348150602

Epoch: 5| Step: 6
Training loss: 2.8651719093322754
Validation loss: 2.6694560371419436

Epoch: 5| Step: 7
Training loss: 3.035153388977051
Validation loss: 2.6820634308681695

Epoch: 5| Step: 8
Training loss: 2.4205873012542725
Validation loss: 2.6797605073580177

Epoch: 5| Step: 9
Training loss: 2.4244766235351562
Validation loss: 2.678449499991632

Epoch: 5| Step: 10
Training loss: 2.5405139923095703
Validation loss: 2.6589094208132837

Epoch: 44| Step: 0
Training loss: 2.2923364639282227
Validation loss: 2.6482515924720356

Epoch: 5| Step: 1
Training loss: 2.5505595207214355
Validation loss: 2.6537021539544545

Epoch: 5| Step: 2
Training loss: 2.4517035484313965
Validation loss: 2.6621847203982774

Epoch: 5| Step: 3
Training loss: 2.782104969024658
Validation loss: 2.688538538512363

Epoch: 5| Step: 4
Training loss: 3.275852918624878
Validation loss: 2.70046724811677

Epoch: 5| Step: 5
Training loss: 3.3045477867126465
Validation loss: 2.695972240099343

Epoch: 5| Step: 6
Training loss: 2.8350613117218018
Validation loss: 2.692274667883432

Epoch: 5| Step: 7
Training loss: 2.3755452632904053
Validation loss: 2.676146235517276

Epoch: 5| Step: 8
Training loss: 2.538949489593506
Validation loss: 2.6548132947696153

Epoch: 5| Step: 9
Training loss: 3.2701163291931152
Validation loss: 2.6441792570134646

Epoch: 5| Step: 10
Training loss: 3.207150459289551
Validation loss: 2.649850255699568

Epoch: 45| Step: 0
Training loss: 3.2714171409606934
Validation loss: 2.6504579385121665

Epoch: 5| Step: 1
Training loss: 3.9129233360290527
Validation loss: 2.657099390542635

Epoch: 5| Step: 2
Training loss: 1.7150328159332275
Validation loss: 2.644276229284143

Epoch: 5| Step: 3
Training loss: 2.725616931915283
Validation loss: 2.6443592566315846

Epoch: 5| Step: 4
Training loss: 2.2007522583007812
Validation loss: 2.6419307801031295

Epoch: 5| Step: 5
Training loss: 2.6106364727020264
Validation loss: 2.6400076304712603

Epoch: 5| Step: 6
Training loss: 2.369563102722168
Validation loss: 2.638116923711633

Epoch: 5| Step: 7
Training loss: 2.6440682411193848
Validation loss: 2.6442256332725607

Epoch: 5| Step: 8
Training loss: 3.2362632751464844
Validation loss: 2.656202326538742

Epoch: 5| Step: 9
Training loss: 3.4211363792419434
Validation loss: 2.657335578754384

Epoch: 5| Step: 10
Training loss: 2.525050401687622
Validation loss: 2.6643231748252787

Epoch: 46| Step: 0
Training loss: 3.4230797290802
Validation loss: 2.661109444915607

Epoch: 5| Step: 1
Training loss: 2.5952372550964355
Validation loss: 2.6594189495168705

Epoch: 5| Step: 2
Training loss: 2.402158737182617
Validation loss: 2.652530398420108

Epoch: 5| Step: 3
Training loss: 2.7954673767089844
Validation loss: 2.653871500363914

Epoch: 5| Step: 4
Training loss: 2.82106614112854
Validation loss: 2.648803077718263

Epoch: 5| Step: 5
Training loss: 2.9039368629455566
Validation loss: 2.651911207424697

Epoch: 5| Step: 6
Training loss: 2.453489303588867
Validation loss: 2.6466667959767003

Epoch: 5| Step: 7
Training loss: 2.586430311203003
Validation loss: 2.6377315085421325

Epoch: 5| Step: 8
Training loss: 3.0733463764190674
Validation loss: 2.6331641135677213

Epoch: 5| Step: 9
Training loss: 2.7052834033966064
Validation loss: 2.631571028822212

Epoch: 5| Step: 10
Training loss: 2.768364429473877
Validation loss: 2.7163137235949115

Epoch: 47| Step: 0
Training loss: 3.988367795944214
Validation loss: 2.700470124521563

Epoch: 5| Step: 1
Training loss: 2.803295612335205
Validation loss: 2.6407785620740665

Epoch: 5| Step: 2
Training loss: 3.1274542808532715
Validation loss: 2.6188113227967293

Epoch: 5| Step: 3
Training loss: 3.0136947631835938
Validation loss: 2.646383734159572

Epoch: 5| Step: 4
Training loss: 2.5768094062805176
Validation loss: 2.683150778534592

Epoch: 5| Step: 5
Training loss: 2.272733449935913
Validation loss: 2.6922389435511764

Epoch: 5| Step: 6
Training loss: 2.6975390911102295
Validation loss: 2.6760632273971394

Epoch: 5| Step: 7
Training loss: 3.0734469890594482
Validation loss: 2.663865820054085

Epoch: 5| Step: 8
Training loss: 2.697187900543213
Validation loss: 2.6361278974881737

Epoch: 5| Step: 9
Training loss: 2.2349658012390137
Validation loss: 2.6208150386810303

Epoch: 5| Step: 10
Training loss: 2.247133255004883
Validation loss: 2.6180542822807067

Epoch: 48| Step: 0
Training loss: 3.3910088539123535
Validation loss: 2.6274932917728218

Epoch: 5| Step: 1
Training loss: 2.59152889251709
Validation loss: 2.647764080314226

Epoch: 5| Step: 2
Training loss: 2.4645440578460693
Validation loss: 2.655245932199622

Epoch: 5| Step: 3
Training loss: 3.938452959060669
Validation loss: 2.6304662663449525

Epoch: 5| Step: 4
Training loss: 2.9277265071868896
Validation loss: 2.62339029260861

Epoch: 5| Step: 5
Training loss: 2.852788209915161
Validation loss: 2.6172355272436656

Epoch: 5| Step: 6
Training loss: 2.1317362785339355
Validation loss: 2.613330493691147

Epoch: 5| Step: 7
Training loss: 2.402039051055908
Validation loss: 2.619209425423735

Epoch: 5| Step: 8
Training loss: 2.475330352783203
Validation loss: 2.6319218681704615

Epoch: 5| Step: 9
Training loss: 3.091136932373047
Validation loss: 2.634424650540916

Epoch: 5| Step: 10
Training loss: 2.2295711040496826
Validation loss: 2.626059760329544

Epoch: 49| Step: 0
Training loss: 3.281780958175659
Validation loss: 2.623842047106835

Epoch: 5| Step: 1
Training loss: 2.9345717430114746
Validation loss: 2.6103705206224994

Epoch: 5| Step: 2
Training loss: 2.233065366744995
Validation loss: 2.615301001456476

Epoch: 5| Step: 3
Training loss: 2.3916172981262207
Validation loss: 2.6131423109321186

Epoch: 5| Step: 4
Training loss: 2.5352065563201904
Validation loss: 2.616606266267838

Epoch: 5| Step: 5
Training loss: 2.9550235271453857
Validation loss: 2.610708152094195

Epoch: 5| Step: 6
Training loss: 3.185354709625244
Validation loss: 2.607350036662112

Epoch: 5| Step: 7
Training loss: 3.0129923820495605
Validation loss: 2.602030446452479

Epoch: 5| Step: 8
Training loss: 2.8905696868896484
Validation loss: 2.6065883328837733

Epoch: 5| Step: 9
Training loss: 3.050636053085327
Validation loss: 2.606579065322876

Epoch: 5| Step: 10
Training loss: 1.7162398099899292
Validation loss: 2.6059619918946297

Epoch: 50| Step: 0
Training loss: 2.9748153686523438
Validation loss: 2.6045037828465945

Epoch: 5| Step: 1
Training loss: 2.620039463043213
Validation loss: 2.6010666893374537

Epoch: 5| Step: 2
Training loss: 3.2783474922180176
Validation loss: 2.601281335276942

Epoch: 5| Step: 3
Training loss: 2.214690685272217
Validation loss: 2.597806433195709

Epoch: 5| Step: 4
Training loss: 2.66999888420105
Validation loss: 2.5988238703820015

Epoch: 5| Step: 5
Training loss: 2.8071460723876953
Validation loss: 2.594486105826593

Epoch: 5| Step: 6
Training loss: 2.783384323120117
Validation loss: 2.5940636178498626

Epoch: 5| Step: 7
Training loss: 2.7967324256896973
Validation loss: 2.6030758221944175

Epoch: 5| Step: 8
Training loss: 2.5455985069274902
Validation loss: 2.619118498217675

Epoch: 5| Step: 9
Training loss: 2.551459312438965
Validation loss: 2.6263671946781937

Epoch: 5| Step: 10
Training loss: 3.1384811401367188
Validation loss: 2.6232465262054117

Epoch: 51| Step: 0
Training loss: 3.17865252494812
Validation loss: 2.625522336652202

Epoch: 5| Step: 1
Training loss: 2.948413372039795
Validation loss: 2.607478944204187

Epoch: 5| Step: 2
Training loss: 2.8188297748565674
Validation loss: 2.593011038277739

Epoch: 5| Step: 3
Training loss: 2.3816988468170166
Validation loss: 2.5935960072343067

Epoch: 5| Step: 4
Training loss: 3.3829073905944824
Validation loss: 2.59109478868464

Epoch: 5| Step: 5
Training loss: 2.058082342147827
Validation loss: 2.5918915348668254

Epoch: 5| Step: 6
Training loss: 3.3813514709472656
Validation loss: 2.600381297449912

Epoch: 5| Step: 7
Training loss: 2.91013765335083
Validation loss: 2.609506969810814

Epoch: 5| Step: 8
Training loss: 2.8477883338928223
Validation loss: 2.5994072114267657

Epoch: 5| Step: 9
Training loss: 2.0184874534606934
Validation loss: 2.5928291505382908

Epoch: 5| Step: 10
Training loss: 2.3427751064300537
Validation loss: 2.5898265582258984

Epoch: 52| Step: 0
Training loss: 2.785705089569092
Validation loss: 2.5839029563370572

Epoch: 5| Step: 1
Training loss: 2.6889538764953613
Validation loss: 2.5856654131284325

Epoch: 5| Step: 2
Training loss: 2.570119857788086
Validation loss: 2.5875351659713255

Epoch: 5| Step: 3
Training loss: 2.782379627227783
Validation loss: 2.582772929181335

Epoch: 5| Step: 4
Training loss: 3.5358757972717285
Validation loss: 2.584506037414715

Epoch: 5| Step: 5
Training loss: 2.619621753692627
Validation loss: 2.586877535748225

Epoch: 5| Step: 6
Training loss: 2.616429090499878
Validation loss: 2.5855738129667056

Epoch: 5| Step: 7
Training loss: 2.2875492572784424
Validation loss: 2.592535070193711

Epoch: 5| Step: 8
Training loss: 2.875265598297119
Validation loss: 2.588365526609523

Epoch: 5| Step: 9
Training loss: 2.487319231033325
Validation loss: 2.5993069038596204

Epoch: 5| Step: 10
Training loss: 3.043610095977783
Validation loss: 2.6046014216638382

Epoch: 53| Step: 0
Training loss: 2.8323662281036377
Validation loss: 2.6031358895763272

Epoch: 5| Step: 1
Training loss: 2.377971649169922
Validation loss: 2.5982347444821428

Epoch: 5| Step: 2
Training loss: 3.2557532787323
Validation loss: 2.5931030652856313

Epoch: 5| Step: 3
Training loss: 2.737164258956909
Validation loss: 2.5908656402300765

Epoch: 5| Step: 4
Training loss: 2.9049980640411377
Validation loss: 2.5787610136052614

Epoch: 5| Step: 5
Training loss: 2.3906829357147217
Validation loss: 2.5740147149691017

Epoch: 5| Step: 6
Training loss: 2.2288947105407715
Validation loss: 2.574478615996658

Epoch: 5| Step: 7
Training loss: 2.8373477458953857
Validation loss: 2.5722893361122376

Epoch: 5| Step: 8
Training loss: 2.7648863792419434
Validation loss: 2.5813737864135415

Epoch: 5| Step: 9
Training loss: 2.9091193675994873
Validation loss: 2.575662330914569

Epoch: 5| Step: 10
Training loss: 2.942026138305664
Validation loss: 2.5694973340598484

Epoch: 54| Step: 0
Training loss: 2.835780382156372
Validation loss: 2.5716740367233113

Epoch: 5| Step: 1
Training loss: 2.606480836868286
Validation loss: 2.5722948863942134

Epoch: 5| Step: 2
Training loss: 2.554530143737793
Validation loss: 2.571377641411238

Epoch: 5| Step: 3
Training loss: 3.4018521308898926
Validation loss: 2.5751819866959766

Epoch: 5| Step: 4
Training loss: 2.4426863193511963
Validation loss: 2.575295981540475

Epoch: 5| Step: 5
Training loss: 3.156344413757324
Validation loss: 2.5809069961629887

Epoch: 5| Step: 6
Training loss: 2.1025047302246094
Validation loss: 2.5796256706278813

Epoch: 5| Step: 7
Training loss: 3.1422207355499268
Validation loss: 2.5794974296323714

Epoch: 5| Step: 8
Training loss: 3.1798293590545654
Validation loss: 2.5733044737128803

Epoch: 5| Step: 9
Training loss: 2.483555316925049
Validation loss: 2.5718646985228344

Epoch: 5| Step: 10
Training loss: 2.1892569065093994
Validation loss: 2.5684606900779148

Epoch: 55| Step: 0
Training loss: 2.3563876152038574
Validation loss: 2.560924450556437

Epoch: 5| Step: 1
Training loss: 2.8320000171661377
Validation loss: 2.558711862051359

Epoch: 5| Step: 2
Training loss: 2.885667324066162
Validation loss: 2.562812715448359

Epoch: 5| Step: 3
Training loss: 2.6387321949005127
Validation loss: 2.5687578262821322

Epoch: 5| Step: 4
Training loss: 2.7110064029693604
Validation loss: 2.5751664843610538

Epoch: 5| Step: 5
Training loss: 2.6955599784851074
Validation loss: 2.569226182917113

Epoch: 5| Step: 6
Training loss: 2.536557674407959
Validation loss: 2.5705902191900436

Epoch: 5| Step: 7
Training loss: 2.6833508014678955
Validation loss: 2.5648516378095074

Epoch: 5| Step: 8
Training loss: 3.246473789215088
Validation loss: 2.5550460046337498

Epoch: 5| Step: 9
Training loss: 3.093498706817627
Validation loss: 2.555373434097536

Epoch: 5| Step: 10
Training loss: 2.3305840492248535
Validation loss: 2.5534459749857583

Epoch: 56| Step: 0
Training loss: 2.5673038959503174
Validation loss: 2.5529709657033286

Epoch: 5| Step: 1
Training loss: 2.8898684978485107
Validation loss: 2.551285946240989

Epoch: 5| Step: 2
Training loss: 2.595729351043701
Validation loss: 2.549380205010855

Epoch: 5| Step: 3
Training loss: 2.5041048526763916
Validation loss: 2.550302500365883

Epoch: 5| Step: 4
Training loss: 2.5887999534606934
Validation loss: 2.5528388869377876

Epoch: 5| Step: 5
Training loss: 3.0871121883392334
Validation loss: 2.5517584918647684

Epoch: 5| Step: 6
Training loss: 2.396012306213379
Validation loss: 2.5523903805722474

Epoch: 5| Step: 7
Training loss: 2.533632278442383
Validation loss: 2.557101067676339

Epoch: 5| Step: 8
Training loss: 2.925746440887451
Validation loss: 2.570460616901357

Epoch: 5| Step: 9
Training loss: 3.601527690887451
Validation loss: 2.554114644245435

Epoch: 5| Step: 10
Training loss: 2.185120105743408
Validation loss: 2.547886715140394

Epoch: 57| Step: 0
Training loss: 2.6479296684265137
Validation loss: 2.5425543938913653

Epoch: 5| Step: 1
Training loss: 2.2872676849365234
Validation loss: 2.544313923005135

Epoch: 5| Step: 2
Training loss: 3.187810182571411
Validation loss: 2.549191241623253

Epoch: 5| Step: 3
Training loss: 1.9504810571670532
Validation loss: 2.5555278178184264

Epoch: 5| Step: 4
Training loss: 3.543217897415161
Validation loss: 2.560278856626121

Epoch: 5| Step: 5
Training loss: 2.277726411819458
Validation loss: 2.5643481567341793

Epoch: 5| Step: 6
Training loss: 2.6168758869171143
Validation loss: 2.5549297614764144

Epoch: 5| Step: 7
Training loss: 2.401528835296631
Validation loss: 2.548621760901584

Epoch: 5| Step: 8
Training loss: 2.737431049346924
Validation loss: 2.5406006638721754

Epoch: 5| Step: 9
Training loss: 2.472033977508545
Validation loss: 2.5373463374312206

Epoch: 5| Step: 10
Training loss: 3.9684035778045654
Validation loss: 2.5393564111442974

Epoch: 58| Step: 0
Training loss: 3.463707447052002
Validation loss: 2.5442855486305813

Epoch: 5| Step: 1
Training loss: 2.5315475463867188
Validation loss: 2.542004527584199

Epoch: 5| Step: 2
Training loss: 2.9248642921447754
Validation loss: 2.5465789020702405

Epoch: 5| Step: 3
Training loss: 2.0507724285125732
Validation loss: 2.546449722782258

Epoch: 5| Step: 4
Training loss: 2.5115437507629395
Validation loss: 2.5456420631818872

Epoch: 5| Step: 5
Training loss: 2.1549878120422363
Validation loss: 2.5406531031413744

Epoch: 5| Step: 6
Training loss: 2.7744531631469727
Validation loss: 2.54530059137652

Epoch: 5| Step: 7
Training loss: 3.1124320030212402
Validation loss: 2.545016001629573

Epoch: 5| Step: 8
Training loss: 3.3416805267333984
Validation loss: 2.5387112940511396

Epoch: 5| Step: 9
Training loss: 2.131286144256592
Validation loss: 2.5316763770195747

Epoch: 5| Step: 10
Training loss: 2.932555675506592
Validation loss: 2.533456628040601

Epoch: 59| Step: 0
Training loss: 3.204348087310791
Validation loss: 2.5301550819027807

Epoch: 5| Step: 1
Training loss: 2.6205546855926514
Validation loss: 2.5303139084128925

Epoch: 5| Step: 2
Training loss: 2.628234386444092
Validation loss: 2.5307324573557866

Epoch: 5| Step: 3
Training loss: 2.1532225608825684
Validation loss: 2.5321209328148955

Epoch: 5| Step: 4
Training loss: 3.091946840286255
Validation loss: 2.5312892493381294

Epoch: 5| Step: 5
Training loss: 2.3480615615844727
Validation loss: 2.528337040255147

Epoch: 5| Step: 6
Training loss: 2.511960983276367
Validation loss: 2.5292529905996015

Epoch: 5| Step: 7
Training loss: 2.7811453342437744
Validation loss: 2.5295872803657287

Epoch: 5| Step: 8
Training loss: 2.930004835128784
Validation loss: 2.53520784583143

Epoch: 5| Step: 9
Training loss: 2.792698860168457
Validation loss: 2.5367438203545025

Epoch: 5| Step: 10
Training loss: 2.7870826721191406
Validation loss: 2.533280526438067

Epoch: 60| Step: 0
Training loss: 2.1506764888763428
Validation loss: 2.5274081281436387

Epoch: 5| Step: 1
Training loss: 2.4143128395080566
Validation loss: 2.525590455660256

Epoch: 5| Step: 2
Training loss: 2.990652322769165
Validation loss: 2.5236844837024646

Epoch: 5| Step: 3
Training loss: 3.165846347808838
Validation loss: 2.5257896659194783

Epoch: 5| Step: 4
Training loss: 3.228452205657959
Validation loss: 2.524739162896269

Epoch: 5| Step: 5
Training loss: 2.6194510459899902
Validation loss: 2.5273918259528374

Epoch: 5| Step: 6
Training loss: 2.1561214923858643
Validation loss: 2.5287172076522664

Epoch: 5| Step: 7
Training loss: 2.415231704711914
Validation loss: 2.5280998855508785

Epoch: 5| Step: 8
Training loss: 3.338963270187378
Validation loss: 2.531315247217814

Epoch: 5| Step: 9
Training loss: 2.3865435123443604
Validation loss: 2.533231063555646

Epoch: 5| Step: 10
Training loss: 2.925755262374878
Validation loss: 2.5317256809562765

Epoch: 61| Step: 0
Training loss: 2.799152135848999
Validation loss: 2.527175244464669

Epoch: 5| Step: 1
Training loss: 2.150702476501465
Validation loss: 2.5267199111241165

Epoch: 5| Step: 2
Training loss: 2.5749690532684326
Validation loss: 2.521725995566255

Epoch: 5| Step: 3
Training loss: 2.9546377658843994
Validation loss: 2.5151537925966325

Epoch: 5| Step: 4
Training loss: 2.4101791381835938
Validation loss: 2.5144946575164795

Epoch: 5| Step: 5
Training loss: 2.9627506732940674
Validation loss: 2.5127786333842943

Epoch: 5| Step: 6
Training loss: 2.748793601989746
Validation loss: 2.5162337518507436

Epoch: 5| Step: 7
Training loss: 3.1162095069885254
Validation loss: 2.521173605354883

Epoch: 5| Step: 8
Training loss: 2.590883493423462
Validation loss: 2.5298044168820946

Epoch: 5| Step: 9
Training loss: 2.3722026348114014
Validation loss: 2.5267546484547276

Epoch: 5| Step: 10
Training loss: 3.105088472366333
Validation loss: 2.5185515060219714

Epoch: 62| Step: 0
Training loss: 2.804783344268799
Validation loss: 2.509352171292869

Epoch: 5| Step: 1
Training loss: 2.2961578369140625
Validation loss: 2.511997451064407

Epoch: 5| Step: 2
Training loss: 1.8060718774795532
Validation loss: 2.5166233431908394

Epoch: 5| Step: 3
Training loss: 2.5982680320739746
Validation loss: 2.518717817080918

Epoch: 5| Step: 4
Training loss: 3.0031089782714844
Validation loss: 2.518865836563931

Epoch: 5| Step: 5
Training loss: 1.785283088684082
Validation loss: 2.526330389002318

Epoch: 5| Step: 6
Training loss: 2.8531105518341064
Validation loss: 2.515402509320167

Epoch: 5| Step: 7
Training loss: 2.652402400970459
Validation loss: 2.512802218878141

Epoch: 5| Step: 8
Training loss: 2.8933849334716797
Validation loss: 2.5116572918430453

Epoch: 5| Step: 9
Training loss: 3.4409873485565186
Validation loss: 2.5090357154928227

Epoch: 5| Step: 10
Training loss: 3.700139284133911
Validation loss: 2.510568049646193

Epoch: 63| Step: 0
Training loss: 2.4984614849090576
Validation loss: 2.5116226365489345

Epoch: 5| Step: 1
Training loss: 2.9328625202178955
Validation loss: 2.5133072919743036

Epoch: 5| Step: 2
Training loss: 2.2420687675476074
Validation loss: 2.512644406287901

Epoch: 5| Step: 3
Training loss: 2.7860512733459473
Validation loss: 2.521843635907737

Epoch: 5| Step: 4
Training loss: 2.300828456878662
Validation loss: 2.5240860446806876

Epoch: 5| Step: 5
Training loss: 2.9317805767059326
Validation loss: 2.519279290271062

Epoch: 5| Step: 6
Training loss: 2.491854190826416
Validation loss: 2.5194739654499996

Epoch: 5| Step: 7
Training loss: 3.308525562286377
Validation loss: 2.5120479701667704

Epoch: 5| Step: 8
Training loss: 2.4458229541778564
Validation loss: 2.5018091073600193

Epoch: 5| Step: 9
Training loss: 2.935403347015381
Validation loss: 2.507538878789512

Epoch: 5| Step: 10
Training loss: 2.8364756107330322
Validation loss: 2.531138809778357

Epoch: 64| Step: 0
Training loss: 2.952690601348877
Validation loss: 2.5420669406972904

Epoch: 5| Step: 1
Training loss: 2.490990400314331
Validation loss: 2.5497133065295476

Epoch: 5| Step: 2
Training loss: 3.0300021171569824
Validation loss: 2.527544718916698

Epoch: 5| Step: 3
Training loss: 2.388401985168457
Validation loss: 2.5189509571239515

Epoch: 5| Step: 4
Training loss: 3.5198662281036377
Validation loss: 2.506390551085113

Epoch: 5| Step: 5
Training loss: 2.421090841293335
Validation loss: 2.4961325122464086

Epoch: 5| Step: 6
Training loss: 1.8478857278823853
Validation loss: 2.4947850422192643

Epoch: 5| Step: 7
Training loss: 2.334665536880493
Validation loss: 2.5027928454901582

Epoch: 5| Step: 8
Training loss: 2.2804317474365234
Validation loss: 2.5060076252106698

Epoch: 5| Step: 9
Training loss: 3.4950802326202393
Validation loss: 2.512868686388898

Epoch: 5| Step: 10
Training loss: 2.971534252166748
Validation loss: 2.521802088265778

Epoch: 65| Step: 0
Training loss: 2.876072406768799
Validation loss: 2.5118698714881815

Epoch: 5| Step: 1
Training loss: 2.5318264961242676
Validation loss: 2.5058433009732153

Epoch: 5| Step: 2
Training loss: 2.44527006149292
Validation loss: 2.495037253184985

Epoch: 5| Step: 3
Training loss: 2.590738296508789
Validation loss: 2.4902714631890737

Epoch: 5| Step: 4
Training loss: 2.0487587451934814
Validation loss: 2.4938808718035297

Epoch: 5| Step: 5
Training loss: 3.1605160236358643
Validation loss: 2.4935999877991213

Epoch: 5| Step: 6
Training loss: 3.072108030319214
Validation loss: 2.4980034623094785

Epoch: 5| Step: 7
Training loss: 2.352609157562256
Validation loss: 2.4993227451078353

Epoch: 5| Step: 8
Training loss: 2.576063632965088
Validation loss: 2.494096497053741

Epoch: 5| Step: 9
Training loss: 2.959268093109131
Validation loss: 2.4848006053637435

Epoch: 5| Step: 10
Training loss: 3.0921459197998047
Validation loss: 2.4822570431616997

Epoch: 66| Step: 0
Training loss: 2.3073360919952393
Validation loss: 2.4872489667707876

Epoch: 5| Step: 1
Training loss: 2.0366740226745605
Validation loss: 2.4920809422769854

Epoch: 5| Step: 2
Training loss: 2.490431308746338
Validation loss: 2.5203785563027985

Epoch: 5| Step: 3
Training loss: 2.670823335647583
Validation loss: 2.528173262073148

Epoch: 5| Step: 4
Training loss: 2.9107303619384766
Validation loss: 2.5277157393834924

Epoch: 5| Step: 5
Training loss: 2.8573665618896484
Validation loss: 2.5144842747719056

Epoch: 5| Step: 6
Training loss: 2.7587833404541016
Validation loss: 2.495972059106314

Epoch: 5| Step: 7
Training loss: 2.616309404373169
Validation loss: 2.479466498539012

Epoch: 5| Step: 8
Training loss: 3.1448721885681152
Validation loss: 2.482091344812865

Epoch: 5| Step: 9
Training loss: 3.1215457916259766
Validation loss: 2.4862401408533894

Epoch: 5| Step: 10
Training loss: 2.6226184368133545
Validation loss: 2.4998332505585044

Epoch: 67| Step: 0
Training loss: 2.98506760597229
Validation loss: 2.569927583458603

Epoch: 5| Step: 1
Training loss: 2.8793282508850098
Validation loss: 2.6100714386150403

Epoch: 5| Step: 2
Training loss: 2.6897857189178467
Validation loss: 2.6205209788455757

Epoch: 5| Step: 3
Training loss: 2.0683445930480957
Validation loss: 2.5879478531499065

Epoch: 5| Step: 4
Training loss: 3.1264805793762207
Validation loss: 2.586487406043596

Epoch: 5| Step: 5
Training loss: 2.376267910003662
Validation loss: 2.5432231246784167

Epoch: 5| Step: 6
Training loss: 3.0560996532440186
Validation loss: 2.5126706169497584

Epoch: 5| Step: 7
Training loss: 2.251373767852783
Validation loss: 2.506825331718691

Epoch: 5| Step: 8
Training loss: 2.756962299346924
Validation loss: 2.4923848234197146

Epoch: 5| Step: 9
Training loss: 2.744734048843384
Validation loss: 2.4764032235709568

Epoch: 5| Step: 10
Training loss: 2.75451922416687
Validation loss: 2.487838319552842

Epoch: 68| Step: 0
Training loss: 3.2213706970214844
Validation loss: 2.5153636035098823

Epoch: 5| Step: 1
Training loss: 3.0047550201416016
Validation loss: 2.5314033262191282

Epoch: 5| Step: 2
Training loss: 2.333275318145752
Validation loss: 2.5273402557578137

Epoch: 5| Step: 3
Training loss: 1.8758167028427124
Validation loss: 2.5026815347774054

Epoch: 5| Step: 4
Training loss: 3.158435344696045
Validation loss: 2.484353917901234

Epoch: 5| Step: 5
Training loss: 2.7486534118652344
Validation loss: 2.4744998203810824

Epoch: 5| Step: 6
Training loss: 2.569117546081543
Validation loss: 2.4703808958812425

Epoch: 5| Step: 7
Training loss: 2.6540610790252686
Validation loss: 2.479153404953659

Epoch: 5| Step: 8
Training loss: 2.567596912384033
Validation loss: 2.5121939233554307

Epoch: 5| Step: 9
Training loss: 2.4183287620544434
Validation loss: 2.5210179769864647

Epoch: 5| Step: 10
Training loss: 3.09478497505188
Validation loss: 2.5086773672411518

Epoch: 69| Step: 0
Training loss: 2.258460521697998
Validation loss: 2.505124922721617

Epoch: 5| Step: 1
Training loss: 2.4376673698425293
Validation loss: 2.517507158299928

Epoch: 5| Step: 2
Training loss: 2.755948543548584
Validation loss: 2.5703683335294008

Epoch: 5| Step: 3
Training loss: 2.9380996227264404
Validation loss: 2.5238425962386595

Epoch: 5| Step: 4
Training loss: 2.846712112426758
Validation loss: 2.4823267664960635

Epoch: 5| Step: 5
Training loss: 2.9446425437927246
Validation loss: 2.4724940151296635

Epoch: 5| Step: 6
Training loss: 2.502495050430298
Validation loss: 2.469413293305264

Epoch: 5| Step: 7
Training loss: 2.444685220718384
Validation loss: 2.471753487022974

Epoch: 5| Step: 8
Training loss: 2.8183977603912354
Validation loss: 2.4897410254324637

Epoch: 5| Step: 9
Training loss: 3.1078765392303467
Validation loss: 2.4962167765504573

Epoch: 5| Step: 10
Training loss: 2.474613666534424
Validation loss: 2.4948347460839058

Epoch: 70| Step: 0
Training loss: 1.573058843612671
Validation loss: 2.5011163116783224

Epoch: 5| Step: 1
Training loss: 2.6791164875030518
Validation loss: 2.4884428311419744

Epoch: 5| Step: 2
Training loss: 3.1651692390441895
Validation loss: 2.4701885433607202

Epoch: 5| Step: 3
Training loss: 2.5548717975616455
Validation loss: 2.467850113427767

Epoch: 5| Step: 4
Training loss: 2.8214645385742188
Validation loss: 2.4741240419367307

Epoch: 5| Step: 5
Training loss: 2.7921111583709717
Validation loss: 2.4837103556561213

Epoch: 5| Step: 6
Training loss: 2.7111475467681885
Validation loss: 2.4822992586320445

Epoch: 5| Step: 7
Training loss: 3.3921561241149902
Validation loss: 2.4870592368546354

Epoch: 5| Step: 8
Training loss: 2.084693431854248
Validation loss: 2.4846677369968866

Epoch: 5| Step: 9
Training loss: 2.5969326496124268
Validation loss: 2.474584197485319

Epoch: 5| Step: 10
Training loss: 3.334350109100342
Validation loss: 2.465720727879514

Epoch: 71| Step: 0
Training loss: 2.7050986289978027
Validation loss: 2.458387287714148

Epoch: 5| Step: 1
Training loss: 3.0061349868774414
Validation loss: 2.4583046641401065

Epoch: 5| Step: 2
Training loss: 2.261881113052368
Validation loss: 2.4680148273385982

Epoch: 5| Step: 3
Training loss: 2.827305793762207
Validation loss: 2.4854673903475524

Epoch: 5| Step: 4
Training loss: 2.4234418869018555
Validation loss: 2.5106392522012033

Epoch: 5| Step: 5
Training loss: 2.452650547027588
Validation loss: 2.5332097391928396

Epoch: 5| Step: 6
Training loss: 2.5087368488311768
Validation loss: 2.486359585997879

Epoch: 5| Step: 7
Training loss: 3.4160447120666504
Validation loss: 2.460929973151094

Epoch: 5| Step: 8
Training loss: 2.083440065383911
Validation loss: 2.4556176457353818

Epoch: 5| Step: 9
Training loss: 3.0993380546569824
Validation loss: 2.4517363091950775

Epoch: 5| Step: 10
Training loss: 2.5996289253234863
Validation loss: 2.4630807163894817

Epoch: 72| Step: 0
Training loss: 2.1977553367614746
Validation loss: 2.4816300048623035

Epoch: 5| Step: 1
Training loss: 3.0524065494537354
Validation loss: 2.515608690118277

Epoch: 5| Step: 2
Training loss: 2.1920714378356934
Validation loss: 2.5765574311697357

Epoch: 5| Step: 3
Training loss: 3.2780144214630127
Validation loss: 2.57253844763643

Epoch: 5| Step: 4
Training loss: 3.3527374267578125
Validation loss: 2.508193431362029

Epoch: 5| Step: 5
Training loss: 3.052441120147705
Validation loss: 2.470579316539149

Epoch: 5| Step: 6
Training loss: 2.144547939300537
Validation loss: 2.4556969699039253

Epoch: 5| Step: 7
Training loss: 2.922179698944092
Validation loss: 2.448309334375525

Epoch: 5| Step: 8
Training loss: 2.5599052906036377
Validation loss: 2.452711192510461

Epoch: 5| Step: 9
Training loss: 2.705005168914795
Validation loss: 2.467286161197129

Epoch: 5| Step: 10
Training loss: 1.9792050123214722
Validation loss: 2.479436013006395

Epoch: 73| Step: 0
Training loss: 2.657424211502075
Validation loss: 2.5059546603951404

Epoch: 5| Step: 1
Training loss: 2.577080011367798
Validation loss: 2.504626602254888

Epoch: 5| Step: 2
Training loss: 2.6386466026306152
Validation loss: 2.495605904568908

Epoch: 5| Step: 3
Training loss: 2.4038403034210205
Validation loss: 2.4700248856698312

Epoch: 5| Step: 4
Training loss: 2.545851707458496
Validation loss: 2.4483841721729567

Epoch: 5| Step: 5
Training loss: 2.5949904918670654
Validation loss: 2.442058527341453

Epoch: 5| Step: 6
Training loss: 3.0429739952087402
Validation loss: 2.446117144758983

Epoch: 5| Step: 7
Training loss: 2.109837055206299
Validation loss: 2.4375330273823073

Epoch: 5| Step: 8
Training loss: 2.6992056369781494
Validation loss: 2.440989996797295

Epoch: 5| Step: 9
Training loss: 3.073996067047119
Validation loss: 2.4366411150142713

Epoch: 5| Step: 10
Training loss: 3.0888404846191406
Validation loss: 2.4396633666048766

Epoch: 74| Step: 0
Training loss: 2.5686323642730713
Validation loss: 2.439030016622236

Epoch: 5| Step: 1
Training loss: 2.2319514751434326
Validation loss: 2.44028655944332

Epoch: 5| Step: 2
Training loss: 2.64389705657959
Validation loss: 2.4377407027829077

Epoch: 5| Step: 3
Training loss: 2.1170997619628906
Validation loss: 2.4391418528813187

Epoch: 5| Step: 4
Training loss: 3.507399797439575
Validation loss: 2.4376816749572754

Epoch: 5| Step: 5
Training loss: 2.867311954498291
Validation loss: 2.450148702949606

Epoch: 5| Step: 6
Training loss: 2.3596036434173584
Validation loss: 2.4460285530295423

Epoch: 5| Step: 7
Training loss: 3.4097740650177
Validation loss: 2.4435568612108947

Epoch: 5| Step: 8
Training loss: 1.6781705617904663
Validation loss: 2.4460920979899745

Epoch: 5| Step: 9
Training loss: 3.097257137298584
Validation loss: 2.4454982588368077

Epoch: 5| Step: 10
Training loss: 2.811866521835327
Validation loss: 2.449447392135538

Epoch: 75| Step: 0
Training loss: 2.7735705375671387
Validation loss: 2.4464694171823482

Epoch: 5| Step: 1
Training loss: 1.8995097875595093
Validation loss: 2.4494370722001597

Epoch: 5| Step: 2
Training loss: 2.387253522872925
Validation loss: 2.4448439357101277

Epoch: 5| Step: 3
Training loss: 2.3199386596679688
Validation loss: 2.4403635917171353

Epoch: 5| Step: 4
Training loss: 2.8233020305633545
Validation loss: 2.450017657331241

Epoch: 5| Step: 5
Training loss: 3.5813369750976562
Validation loss: 2.4557031662233415

Epoch: 5| Step: 6
Training loss: 2.6655373573303223
Validation loss: 2.483909555660781

Epoch: 5| Step: 7
Training loss: 3.1278131008148193
Validation loss: 2.483909119841873

Epoch: 5| Step: 8
Training loss: 2.0948944091796875
Validation loss: 2.469333497426843

Epoch: 5| Step: 9
Training loss: 2.6553497314453125
Validation loss: 2.4333613662309546

Epoch: 5| Step: 10
Training loss: 2.845945358276367
Validation loss: 2.4340686080276326

Epoch: 76| Step: 0
Training loss: 2.5556230545043945
Validation loss: 2.4622382528038433

Epoch: 5| Step: 1
Training loss: 3.056212902069092
Validation loss: 2.525928856224142

Epoch: 5| Step: 2
Training loss: 2.528291702270508
Validation loss: 2.6551909318534275

Epoch: 5| Step: 3
Training loss: 2.164646625518799
Validation loss: 2.6732685745403333

Epoch: 5| Step: 4
Training loss: 2.6644625663757324
Validation loss: 2.536115713016961

Epoch: 5| Step: 5
Training loss: 2.8309192657470703
Validation loss: 2.435123687149376

Epoch: 5| Step: 6
Training loss: 2.709498643875122
Validation loss: 2.4261971058384066

Epoch: 5| Step: 7
Training loss: 2.8744301795959473
Validation loss: 2.459750231876168

Epoch: 5| Step: 8
Training loss: 2.256791353225708
Validation loss: 2.5176799425514798

Epoch: 5| Step: 9
Training loss: 3.425936222076416
Validation loss: 2.5432152645562285

Epoch: 5| Step: 10
Training loss: 2.5117545127868652
Validation loss: 2.4832658408790507

Epoch: 77| Step: 0
Training loss: 2.713066577911377
Validation loss: 2.449274714275073

Epoch: 5| Step: 1
Training loss: 2.7295303344726562
Validation loss: 2.425124675996842

Epoch: 5| Step: 2
Training loss: 2.6258697509765625
Validation loss: 2.4262390187991563

Epoch: 5| Step: 3
Training loss: 2.936069965362549
Validation loss: 2.434767461592151

Epoch: 5| Step: 4
Training loss: 2.796300172805786
Validation loss: 2.435793161392212

Epoch: 5| Step: 5
Training loss: 1.8758480548858643
Validation loss: 2.4427400865862445

Epoch: 5| Step: 6
Training loss: 2.654317855834961
Validation loss: 2.447992217156195

Epoch: 5| Step: 7
Training loss: 2.782430410385132
Validation loss: 2.4338350860021447

Epoch: 5| Step: 8
Training loss: 3.502864122390747
Validation loss: 2.433413661936278

Epoch: 5| Step: 9
Training loss: 1.9075343608856201
Validation loss: 2.4360419268249185

Epoch: 5| Step: 10
Training loss: 2.877066135406494
Validation loss: 2.4376108466937976

Epoch: 78| Step: 0
Training loss: 2.849790334701538
Validation loss: 2.444005189403411

Epoch: 5| Step: 1
Training loss: 3.029599666595459
Validation loss: 2.4414984231354087

Epoch: 5| Step: 2
Training loss: 3.0716965198516846
Validation loss: 2.4595907016467025

Epoch: 5| Step: 3
Training loss: 2.5315053462982178
Validation loss: 2.4697401959408998

Epoch: 5| Step: 4
Training loss: 3.027315378189087
Validation loss: 2.474692949684717

Epoch: 5| Step: 5
Training loss: 2.6025564670562744
Validation loss: 2.464493123433923

Epoch: 5| Step: 6
Training loss: 1.8813426494598389
Validation loss: 2.427067090106267

Epoch: 5| Step: 7
Training loss: 2.5051429271698
Validation loss: 2.420355540449901

Epoch: 5| Step: 8
Training loss: 1.8819580078125
Validation loss: 2.4176960504183205

Epoch: 5| Step: 9
Training loss: 2.7142155170440674
Validation loss: 2.426127836268435

Epoch: 5| Step: 10
Training loss: 3.1663739681243896
Validation loss: 2.4328781071529595

Epoch: 79| Step: 0
Training loss: 2.97406005859375
Validation loss: 2.4461737268714496

Epoch: 5| Step: 1
Training loss: 2.1635241508483887
Validation loss: 2.4453613450450282

Epoch: 5| Step: 2
Training loss: 2.4925038814544678
Validation loss: 2.447834501984299

Epoch: 5| Step: 3
Training loss: 2.821540355682373
Validation loss: 2.4347483650330575

Epoch: 5| Step: 4
Training loss: 3.170732259750366
Validation loss: 2.4352097075472594

Epoch: 5| Step: 5
Training loss: 2.260345935821533
Validation loss: 2.4251959913520404

Epoch: 5| Step: 6
Training loss: 3.2553699016571045
Validation loss: 2.419776847285609

Epoch: 5| Step: 7
Training loss: 3.0358872413635254
Validation loss: 2.417472836791828

Epoch: 5| Step: 8
Training loss: 2.3597500324249268
Validation loss: 2.4118762323933263

Epoch: 5| Step: 9
Training loss: 2.3808789253234863
Validation loss: 2.4106910177456435

Epoch: 5| Step: 10
Training loss: 2.259337902069092
Validation loss: 2.410767391163816

Epoch: 80| Step: 0
Training loss: 3.019257068634033
Validation loss: 2.4074924812521985

Epoch: 5| Step: 1
Training loss: 2.6076788902282715
Validation loss: 2.4036279980854323

Epoch: 5| Step: 2
Training loss: 2.6575210094451904
Validation loss: 2.4094937770597395

Epoch: 5| Step: 3
Training loss: 2.68629789352417
Validation loss: 2.407228021211522

Epoch: 5| Step: 4
Training loss: 2.511514186859131
Validation loss: 2.411936398475401

Epoch: 5| Step: 5
Training loss: 2.6524760723114014
Validation loss: 2.4304319889314714

Epoch: 5| Step: 6
Training loss: 2.2917990684509277
Validation loss: 2.4438489739612868

Epoch: 5| Step: 7
Training loss: 2.6704888343811035
Validation loss: 2.4521526444342827

Epoch: 5| Step: 8
Training loss: 2.713135242462158
Validation loss: 2.4713575506723053

Epoch: 5| Step: 9
Training loss: 2.662405490875244
Validation loss: 2.481344184567851

Epoch: 5| Step: 10
Training loss: 2.7606000900268555
Validation loss: 2.474645450551023

Epoch: 81| Step: 0
Training loss: 2.4328465461730957
Validation loss: 2.4346967538197837

Epoch: 5| Step: 1
Training loss: 2.9807159900665283
Validation loss: 2.4198121281080347

Epoch: 5| Step: 2
Training loss: 2.192595958709717
Validation loss: 2.4227055042020735

Epoch: 5| Step: 3
Training loss: 3.4024481773376465
Validation loss: 2.4362509507004932

Epoch: 5| Step: 4
Training loss: 2.602782964706421
Validation loss: 2.475051180008919

Epoch: 5| Step: 5
Training loss: 2.859717607498169
Validation loss: 2.4556256391668834

Epoch: 5| Step: 6
Training loss: 3.070906162261963
Validation loss: 2.4550513195735153

Epoch: 5| Step: 7
Training loss: 2.6068522930145264
Validation loss: 2.4490664518007668

Epoch: 5| Step: 8
Training loss: 3.102509021759033
Validation loss: 2.4292667424806984

Epoch: 5| Step: 9
Training loss: 1.9126040935516357
Validation loss: 2.406339140348537

Epoch: 5| Step: 10
Training loss: 2.0734477043151855
Validation loss: 2.39614603852713

Epoch: 82| Step: 0
Training loss: 2.6423161029815674
Validation loss: 2.3982823228323333

Epoch: 5| Step: 1
Training loss: 2.5539567470550537
Validation loss: 2.3889683702940583

Epoch: 5| Step: 2
Training loss: 2.9118080139160156
Validation loss: 2.4031128396270094

Epoch: 5| Step: 3
Training loss: 3.008025646209717
Validation loss: 2.413939091467088

Epoch: 5| Step: 4
Training loss: 2.1191372871398926
Validation loss: 2.4308151365608297

Epoch: 5| Step: 5
Training loss: 2.5908043384552
Validation loss: 2.4374111801065426

Epoch: 5| Step: 6
Training loss: 3.1220293045043945
Validation loss: 2.4625131160982194

Epoch: 5| Step: 7
Training loss: 2.4437592029571533
Validation loss: 2.4764509816323557

Epoch: 5| Step: 8
Training loss: 3.1020617485046387
Validation loss: 2.4906522971327587

Epoch: 5| Step: 9
Training loss: 2.650815486907959
Validation loss: 2.4602903883944274

Epoch: 5| Step: 10
Training loss: 2.0319294929504395
Validation loss: 2.427720280103786

Epoch: 83| Step: 0
Training loss: 2.5855331420898438
Validation loss: 2.4020820202366

Epoch: 5| Step: 1
Training loss: 2.9270713329315186
Validation loss: 2.433156357016615

Epoch: 5| Step: 2
Training loss: 2.389756441116333
Validation loss: 2.523482497020434

Epoch: 5| Step: 3
Training loss: 2.5574841499328613
Validation loss: 2.577221626876503

Epoch: 5| Step: 4
Training loss: 2.3935036659240723
Validation loss: 2.538566489373484

Epoch: 5| Step: 5
Training loss: 2.214900493621826
Validation loss: 2.438207346905944

Epoch: 5| Step: 6
Training loss: 3.2692806720733643
Validation loss: 2.4080207040232997

Epoch: 5| Step: 7
Training loss: 3.142782688140869
Validation loss: 2.3925787761647213

Epoch: 5| Step: 8
Training loss: 2.8360755443573
Validation loss: 2.3880452007375736

Epoch: 5| Step: 9
Training loss: 2.572164535522461
Validation loss: 2.4066650764916533

Epoch: 5| Step: 10
Training loss: 2.4620330333709717
Validation loss: 2.472180422916207

Epoch: 84| Step: 0
Training loss: 2.721719741821289
Validation loss: 2.521141463710416

Epoch: 5| Step: 1
Training loss: 2.838094711303711
Validation loss: 2.486812109588295

Epoch: 5| Step: 2
Training loss: 2.4516348838806152
Validation loss: 2.4324467143704815

Epoch: 5| Step: 3
Training loss: 2.9044368267059326
Validation loss: 2.396675764873464

Epoch: 5| Step: 4
Training loss: 2.6428868770599365
Validation loss: 2.3850897255764214

Epoch: 5| Step: 5
Training loss: 2.8187811374664307
Validation loss: 2.3881633538071827

Epoch: 5| Step: 6
Training loss: 2.77305006980896
Validation loss: 2.380948382039224

Epoch: 5| Step: 7
Training loss: 2.0360941886901855
Validation loss: 2.381436214652113

Epoch: 5| Step: 8
Training loss: 2.895092487335205
Validation loss: 2.3873772569881972

Epoch: 5| Step: 9
Training loss: 2.5047192573547363
Validation loss: 2.3887843008964293

Epoch: 5| Step: 10
Training loss: 2.4469218254089355
Validation loss: 2.393445558445428

Epoch: 85| Step: 0
Training loss: 2.8133723735809326
Validation loss: 2.389057174805672

Epoch: 5| Step: 1
Training loss: 2.5242605209350586
Validation loss: 2.391802462198401

Epoch: 5| Step: 2
Training loss: 1.886541724205017
Validation loss: 2.3912617519337642

Epoch: 5| Step: 3
Training loss: 3.112708568572998
Validation loss: 2.3922968205585273

Epoch: 5| Step: 4
Training loss: 2.663147211074829
Validation loss: 2.403427846970097

Epoch: 5| Step: 5
Training loss: 2.828054428100586
Validation loss: 2.386816955381824

Epoch: 5| Step: 6
Training loss: 2.5844879150390625
Validation loss: 2.3824614273604525

Epoch: 5| Step: 7
Training loss: 2.7874083518981934
Validation loss: 2.381248939421869

Epoch: 5| Step: 8
Training loss: 2.048201560974121
Validation loss: 2.375117476268481

Epoch: 5| Step: 9
Training loss: 3.0881597995758057
Validation loss: 2.37550340929339

Epoch: 5| Step: 10
Training loss: 2.626927375793457
Validation loss: 2.376848328498102

Epoch: 86| Step: 0
Training loss: 2.146423816680908
Validation loss: 2.3807254914314515

Epoch: 5| Step: 1
Training loss: 2.923387050628662
Validation loss: 2.3815641300652617

Epoch: 5| Step: 2
Training loss: 2.228227376937866
Validation loss: 2.376840832412884

Epoch: 5| Step: 3
Training loss: 2.313406467437744
Validation loss: 2.376241712160008

Epoch: 5| Step: 4
Training loss: 3.3631386756896973
Validation loss: 2.374256677525018

Epoch: 5| Step: 5
Training loss: 2.599238872528076
Validation loss: 2.3802602829471713

Epoch: 5| Step: 6
Training loss: 2.3005852699279785
Validation loss: 2.3813872580887168

Epoch: 5| Step: 7
Training loss: 2.8779959678649902
Validation loss: 2.3932274772274877

Epoch: 5| Step: 8
Training loss: 2.676847457885742
Validation loss: 2.389685658998387

Epoch: 5| Step: 9
Training loss: 2.5744171142578125
Validation loss: 2.392124888717487

Epoch: 5| Step: 10
Training loss: 2.9242751598358154
Validation loss: 2.390443842898133

Epoch: 87| Step: 0
Training loss: 2.7533085346221924
Validation loss: 2.3942484701833417

Epoch: 5| Step: 1
Training loss: 2.643338680267334
Validation loss: 2.4034969704125517

Epoch: 5| Step: 2
Training loss: 2.5746428966522217
Validation loss: 2.3819557159177718

Epoch: 5| Step: 3
Training loss: 2.541520595550537
Validation loss: 2.372649254337434

Epoch: 5| Step: 4
Training loss: 2.7890706062316895
Validation loss: 2.3658184633460095

Epoch: 5| Step: 5
Training loss: 2.432037830352783
Validation loss: 2.365444960132722

Epoch: 5| Step: 6
Training loss: 2.571235179901123
Validation loss: 2.363036660737889

Epoch: 5| Step: 7
Training loss: 1.7906920909881592
Validation loss: 2.3571100722077074

Epoch: 5| Step: 8
Training loss: 2.853726863861084
Validation loss: 2.3615014296706005

Epoch: 5| Step: 9
Training loss: 2.9925897121429443
Validation loss: 2.3724981700220416

Epoch: 5| Step: 10
Training loss: 3.1207151412963867
Validation loss: 2.3806334823690434

Epoch: 88| Step: 0
Training loss: 3.188339948654175
Validation loss: 2.3831308246940694

Epoch: 5| Step: 1
Training loss: 2.7079482078552246
Validation loss: 2.3845807967647428

Epoch: 5| Step: 2
Training loss: 2.1859869956970215
Validation loss: 2.3979886372884116

Epoch: 5| Step: 3
Training loss: 2.8493945598602295
Validation loss: 2.3832562790122083

Epoch: 5| Step: 4
Training loss: 2.51603627204895
Validation loss: 2.361215264566483

Epoch: 5| Step: 5
Training loss: 2.5445926189422607
Validation loss: 2.364794713194652

Epoch: 5| Step: 6
Training loss: 3.3167757987976074
Validation loss: 2.3802307908253004

Epoch: 5| Step: 7
Training loss: 2.0533900260925293
Validation loss: 2.4161735721813735

Epoch: 5| Step: 8
Training loss: 2.24289608001709
Validation loss: 2.4430726676858883

Epoch: 5| Step: 9
Training loss: 2.6452059745788574
Validation loss: 2.458143344489477

Epoch: 5| Step: 10
Training loss: 2.9116930961608887
Validation loss: 2.459584718109459

Epoch: 89| Step: 0
Training loss: 2.606813430786133
Validation loss: 2.4042783732055337

Epoch: 5| Step: 1
Training loss: 3.2242989540100098
Validation loss: 2.3913448831086517

Epoch: 5| Step: 2
Training loss: 3.21665620803833
Validation loss: 2.3807356049937587

Epoch: 5| Step: 3
Training loss: 2.0681493282318115
Validation loss: 2.362144236923546

Epoch: 5| Step: 4
Training loss: 2.377323865890503
Validation loss: 2.3566563155061457

Epoch: 5| Step: 5
Training loss: 3.0966849327087402
Validation loss: 2.3595378475804485

Epoch: 5| Step: 6
Training loss: 2.095960855484009
Validation loss: 2.351940231938516

Epoch: 5| Step: 7
Training loss: 2.7610106468200684
Validation loss: 2.3628425649417344

Epoch: 5| Step: 8
Training loss: 2.8002471923828125
Validation loss: 2.3738826423562984

Epoch: 5| Step: 9
Training loss: 2.2422187328338623
Validation loss: 2.375427605003439

Epoch: 5| Step: 10
Training loss: 2.168165922164917
Validation loss: 2.378914345977127

Epoch: 90| Step: 0
Training loss: 2.484221935272217
Validation loss: 2.375317060819236

Epoch: 5| Step: 1
Training loss: 2.9399523735046387
Validation loss: 2.3886594772338867

Epoch: 5| Step: 2
Training loss: 2.4270310401916504
Validation loss: 2.3966626813334804

Epoch: 5| Step: 3
Training loss: 2.1531877517700195
Validation loss: 2.4011608554470922

Epoch: 5| Step: 4
Training loss: 2.7948646545410156
Validation loss: 2.398915308778004

Epoch: 5| Step: 5
Training loss: 2.449620485305786
Validation loss: 2.4049352702274116

Epoch: 5| Step: 6
Training loss: 2.609563112258911
Validation loss: 2.370533361229845

Epoch: 5| Step: 7
Training loss: 2.8222708702087402
Validation loss: 2.3504513925121677

Epoch: 5| Step: 8
Training loss: 3.0471043586730957
Validation loss: 2.3481472281999487

Epoch: 5| Step: 9
Training loss: 2.3248772621154785
Validation loss: 2.3461711457980576

Epoch: 5| Step: 10
Training loss: 2.6076977252960205
Validation loss: 2.350437856489612

Epoch: 91| Step: 0
Training loss: 2.8514485359191895
Validation loss: 2.372814409194454

Epoch: 5| Step: 1
Training loss: 2.576439380645752
Validation loss: 2.39118177916414

Epoch: 5| Step: 2
Training loss: 2.8619141578674316
Validation loss: 2.437853023570071

Epoch: 5| Step: 3
Training loss: 2.2892134189605713
Validation loss: 2.4216214097956175

Epoch: 5| Step: 4
Training loss: 3.052462100982666
Validation loss: 2.422728253949073

Epoch: 5| Step: 5
Training loss: 2.7175395488739014
Validation loss: 2.3716465093756236

Epoch: 5| Step: 6
Training loss: 3.174787998199463
Validation loss: 2.345058851344611

Epoch: 5| Step: 7
Training loss: 1.9705156087875366
Validation loss: 2.343356551662568

Epoch: 5| Step: 8
Training loss: 2.2127087116241455
Validation loss: 2.360474991542037

Epoch: 5| Step: 9
Training loss: 3.1431331634521484
Validation loss: 2.3983787259747906

Epoch: 5| Step: 10
Training loss: 2.032356023788452
Validation loss: 2.414876389247115

Epoch: 92| Step: 0
Training loss: 2.583817958831787
Validation loss: 2.4290426469618276

Epoch: 5| Step: 1
Training loss: 2.309417963027954
Validation loss: 2.395563171755883

Epoch: 5| Step: 2
Training loss: 2.6900391578674316
Validation loss: 2.362429183016541

Epoch: 5| Step: 3
Training loss: 2.643698215484619
Validation loss: 2.3355057854806223

Epoch: 5| Step: 4
Training loss: 2.422433376312256
Validation loss: 2.3314971898191716

Epoch: 5| Step: 5
Training loss: 3.0028140544891357
Validation loss: 2.332413060690767

Epoch: 5| Step: 6
Training loss: 2.920891523361206
Validation loss: 2.344140624487272

Epoch: 5| Step: 7
Training loss: 2.615614652633667
Validation loss: 2.3587714369579027

Epoch: 5| Step: 8
Training loss: 2.8987698554992676
Validation loss: 2.38214881702136

Epoch: 5| Step: 9
Training loss: 2.5441818237304688
Validation loss: 2.3983374411059963

Epoch: 5| Step: 10
Training loss: 2.3532540798187256
Validation loss: 2.4148351402692896

Epoch: 93| Step: 0
Training loss: 2.8561413288116455
Validation loss: 2.4207537020406416

Epoch: 5| Step: 1
Training loss: 2.3580384254455566
Validation loss: 2.3995425060231197

Epoch: 5| Step: 2
Training loss: 2.3305916786193848
Validation loss: 2.3925631046295166

Epoch: 5| Step: 3
Training loss: 2.830211877822876
Validation loss: 2.4326224737269904

Epoch: 5| Step: 4
Training loss: 3.1246755123138428
Validation loss: 2.4515872386194046

Epoch: 5| Step: 5
Training loss: 3.9978034496307373
Validation loss: 2.451052957965482

Epoch: 5| Step: 6
Training loss: 2.195866346359253
Validation loss: 2.374488663929765

Epoch: 5| Step: 7
Training loss: 2.738769769668579
Validation loss: 2.3379657447979016

Epoch: 5| Step: 8
Training loss: 1.5594546794891357
Validation loss: 2.3290187210165043

Epoch: 5| Step: 9
Training loss: 3.0115807056427
Validation loss: 2.3409913547577395

Epoch: 5| Step: 10
Training loss: 1.9423495531082153
Validation loss: 2.38054899502826

Epoch: 94| Step: 0
Training loss: 3.0861716270446777
Validation loss: 2.4376271078663487

Epoch: 5| Step: 1
Training loss: 2.9919724464416504
Validation loss: 2.4389046674133628

Epoch: 5| Step: 2
Training loss: 2.1867663860321045
Validation loss: 2.445203963146415

Epoch: 5| Step: 3
Training loss: 2.683892011642456
Validation loss: 2.4496894703116467

Epoch: 5| Step: 4
Training loss: 2.8134896755218506
Validation loss: 2.3858460021275345

Epoch: 5| Step: 5
Training loss: 2.40580153465271
Validation loss: 2.356694341987692

Epoch: 5| Step: 6
Training loss: 2.855632781982422
Validation loss: 2.351097824752972

Epoch: 5| Step: 7
Training loss: 2.3816683292388916
Validation loss: 2.346013565217295

Epoch: 5| Step: 8
Training loss: 2.8267691135406494
Validation loss: 2.341864012902783

Epoch: 5| Step: 9
Training loss: 2.5275044441223145
Validation loss: 2.33745159897753

Epoch: 5| Step: 10
Training loss: 2.2059924602508545
Validation loss: 2.3283280121382846

Epoch: 95| Step: 0
Training loss: 3.1201412677764893
Validation loss: 2.3255250018130065

Epoch: 5| Step: 1
Training loss: 2.5385360717773438
Validation loss: 2.32382543112642

Epoch: 5| Step: 2
Training loss: 2.977055311203003
Validation loss: 2.324430937408119

Epoch: 5| Step: 3
Training loss: 1.8130464553833008
Validation loss: 2.321004572735038

Epoch: 5| Step: 4
Training loss: 2.7879557609558105
Validation loss: 2.3219538465622933

Epoch: 5| Step: 5
Training loss: 2.172058582305908
Validation loss: 2.3179654126526206

Epoch: 5| Step: 6
Training loss: 2.391857624053955
Validation loss: 2.319543666737054

Epoch: 5| Step: 7
Training loss: 2.1738438606262207
Validation loss: 2.3189236707584833

Epoch: 5| Step: 8
Training loss: 3.0525436401367188
Validation loss: 2.314992423980467

Epoch: 5| Step: 9
Training loss: 2.8080806732177734
Validation loss: 2.319741495193974

Epoch: 5| Step: 10
Training loss: 2.8800313472747803
Validation loss: 2.318226588669644

Epoch: 96| Step: 0
Training loss: 2.579801559448242
Validation loss: 2.3252567040022982

Epoch: 5| Step: 1
Training loss: 2.8453516960144043
Validation loss: 2.339162293300834

Epoch: 5| Step: 2
Training loss: 3.1325695514678955
Validation loss: 2.336581422436622

Epoch: 5| Step: 3
Training loss: 2.2809548377990723
Validation loss: 2.3157667677889586

Epoch: 5| Step: 4
Training loss: 2.4874775409698486
Validation loss: 2.3120666614142795

Epoch: 5| Step: 5
Training loss: 1.9885135889053345
Validation loss: 2.3159528534899474

Epoch: 5| Step: 6
Training loss: 2.4732916355133057
Validation loss: 2.3139434988780687

Epoch: 5| Step: 7
Training loss: 2.6841723918914795
Validation loss: 2.3176364360317105

Epoch: 5| Step: 8
Training loss: 2.6152334213256836
Validation loss: 2.313481233453238

Epoch: 5| Step: 9
Training loss: 2.64329195022583
Validation loss: 2.3167134766937583

Epoch: 5| Step: 10
Training loss: 2.9479708671569824
Validation loss: 2.31434456763729

Epoch: 97| Step: 0
Training loss: 2.2457993030548096
Validation loss: 2.3205372800109205

Epoch: 5| Step: 1
Training loss: 2.475809335708618
Validation loss: 2.3166865251397573

Epoch: 5| Step: 2
Training loss: 3.1076345443725586
Validation loss: 2.323448665680424

Epoch: 5| Step: 3
Training loss: 2.4835166931152344
Validation loss: 2.322156031926473

Epoch: 5| Step: 4
Training loss: 2.4487144947052
Validation loss: 2.3302714875949326

Epoch: 5| Step: 5
Training loss: 3.3050994873046875
Validation loss: 2.349275327497913

Epoch: 5| Step: 6
Training loss: 1.9482533931732178
Validation loss: 2.327855305005145

Epoch: 5| Step: 7
Training loss: 2.6741156578063965
Validation loss: 2.340768816650555

Epoch: 5| Step: 8
Training loss: 3.237036943435669
Validation loss: 2.3132528771636305

Epoch: 5| Step: 9
Training loss: 1.9315602779388428
Validation loss: 2.3105559015786774

Epoch: 5| Step: 10
Training loss: 2.7707161903381348
Validation loss: 2.317764659081736

Epoch: 98| Step: 0
Training loss: 2.4358811378479004
Validation loss: 2.315928074621385

Epoch: 5| Step: 1
Training loss: 2.617762327194214
Validation loss: 2.3189771995749524

Epoch: 5| Step: 2
Training loss: 2.7715096473693848
Validation loss: 2.321050759284727

Epoch: 5| Step: 3
Training loss: 2.11186146736145
Validation loss: 2.317881609803887

Epoch: 5| Step: 4
Training loss: 2.6808903217315674
Validation loss: 2.3184020647438626

Epoch: 5| Step: 5
Training loss: 2.3148441314697266
Validation loss: 2.321760477558259

Epoch: 5| Step: 6
Training loss: 2.779006004333496
Validation loss: 2.32551489081434

Epoch: 5| Step: 7
Training loss: 2.423877477645874
Validation loss: 2.3265610689757974

Epoch: 5| Step: 8
Training loss: 2.75545334815979
Validation loss: 2.330982490252423

Epoch: 5| Step: 9
Training loss: 2.7711801528930664
Validation loss: 2.33153360889804

Epoch: 5| Step: 10
Training loss: 2.8639285564422607
Validation loss: 2.335725406164764

Epoch: 99| Step: 0
Training loss: 2.9024417400360107
Validation loss: 2.3251237843626287

Epoch: 5| Step: 1
Training loss: 2.8005247116088867
Validation loss: 2.3310658060094362

Epoch: 5| Step: 2
Training loss: 1.817482352256775
Validation loss: 2.339605103256882

Epoch: 5| Step: 3
Training loss: 2.4559969902038574
Validation loss: 2.3307965519607707

Epoch: 5| Step: 4
Training loss: 2.2835280895233154
Validation loss: 2.3346274565624934

Epoch: 5| Step: 5
Training loss: 2.7091190814971924
Validation loss: 2.345124900981944

Epoch: 5| Step: 6
Training loss: 2.6964645385742188
Validation loss: 2.3417020228601273

Epoch: 5| Step: 7
Training loss: 2.845247268676758
Validation loss: 2.3296121756235757

Epoch: 5| Step: 8
Training loss: 2.9061331748962402
Validation loss: 2.3228008054917857

Epoch: 5| Step: 9
Training loss: 2.2512478828430176
Validation loss: 2.321288888172437

Epoch: 5| Step: 10
Training loss: 2.889498472213745
Validation loss: 2.328559414032967

Epoch: 100| Step: 0
Training loss: 2.042236804962158
Validation loss: 2.324397663916311

Epoch: 5| Step: 1
Training loss: 2.7516777515411377
Validation loss: 2.3248391074519

Epoch: 5| Step: 2
Training loss: 2.607680320739746
Validation loss: 2.3266736486906647

Epoch: 5| Step: 3
Training loss: 2.1556687355041504
Validation loss: 2.3118118060532438

Epoch: 5| Step: 4
Training loss: 3.325040340423584
Validation loss: 2.3193155757842527

Epoch: 5| Step: 5
Training loss: 2.9750499725341797
Validation loss: 2.30433064891446

Epoch: 5| Step: 6
Training loss: 2.4935946464538574
Validation loss: 2.3039359379840154

Epoch: 5| Step: 7
Training loss: 2.7644176483154297
Validation loss: 2.3125638423427457

Epoch: 5| Step: 8
Training loss: 2.1878790855407715
Validation loss: 2.3010447102208293

Epoch: 5| Step: 9
Training loss: 2.4242146015167236
Validation loss: 2.3063070312623055

Epoch: 5| Step: 10
Training loss: 2.810429811477661
Validation loss: 2.3147382377296366

Epoch: 101| Step: 0
Training loss: 2.1894242763519287
Validation loss: 2.318315247053741

Epoch: 5| Step: 1
Training loss: 2.3757576942443848
Validation loss: 2.3198993718752297

Epoch: 5| Step: 2
Training loss: 2.0493507385253906
Validation loss: 2.3199025405350553

Epoch: 5| Step: 3
Training loss: 2.616241931915283
Validation loss: 2.3105201234099684

Epoch: 5| Step: 4
Training loss: 2.875153064727783
Validation loss: 2.307717046430034

Epoch: 5| Step: 5
Training loss: 2.5688815116882324
Validation loss: 2.3056906295079056

Epoch: 5| Step: 6
Training loss: 2.8582570552825928
Validation loss: 2.3115275547068608

Epoch: 5| Step: 7
Training loss: 2.2267041206359863
Validation loss: 2.314164134763902

Epoch: 5| Step: 8
Training loss: 2.6345343589782715
Validation loss: 2.3201653393366004

Epoch: 5| Step: 9
Training loss: 3.097578763961792
Validation loss: 2.3270347092741277

Epoch: 5| Step: 10
Training loss: 2.949167490005493
Validation loss: 2.313712723793522

Epoch: 102| Step: 0
Training loss: 2.8575315475463867
Validation loss: 2.3071043568272747

Epoch: 5| Step: 1
Training loss: 2.2213191986083984
Validation loss: 2.302850502793507

Epoch: 5| Step: 2
Training loss: 2.707162380218506
Validation loss: 2.3032616748604724

Epoch: 5| Step: 3
Training loss: 2.1027750968933105
Validation loss: 2.3010694698620866

Epoch: 5| Step: 4
Training loss: 2.780069351196289
Validation loss: 2.2990648925945325

Epoch: 5| Step: 5
Training loss: 2.6082191467285156
Validation loss: 2.3007387627837477

Epoch: 5| Step: 6
Training loss: 2.143958568572998
Validation loss: 2.2947462668982883

Epoch: 5| Step: 7
Training loss: 3.6531219482421875
Validation loss: 2.3004747770165883

Epoch: 5| Step: 8
Training loss: 2.5508615970611572
Validation loss: 2.2998263092451197

Epoch: 5| Step: 9
Training loss: 2.0708630084991455
Validation loss: 2.294450834233274

Epoch: 5| Step: 10
Training loss: 2.659358501434326
Validation loss: 2.289090100155082

Epoch: 103| Step: 0
Training loss: 2.4118611812591553
Validation loss: 2.2897970368785243

Epoch: 5| Step: 1
Training loss: 3.040428876876831
Validation loss: 2.288115906459029

Epoch: 5| Step: 2
Training loss: 3.558401584625244
Validation loss: 2.2974973955462055

Epoch: 5| Step: 3
Training loss: 2.2423081398010254
Validation loss: 2.297590909465667

Epoch: 5| Step: 4
Training loss: 2.5036749839782715
Validation loss: 2.3066187263816915

Epoch: 5| Step: 5
Training loss: 1.822957992553711
Validation loss: 2.3054624654913463

Epoch: 5| Step: 6
Training loss: 2.7662134170532227
Validation loss: 2.3217244635346117

Epoch: 5| Step: 7
Training loss: 2.1206936836242676
Validation loss: 2.327869276846609

Epoch: 5| Step: 8
Training loss: 2.5845603942871094
Validation loss: 2.334976488544095

Epoch: 5| Step: 9
Training loss: 2.7880122661590576
Validation loss: 2.298015163790795

Epoch: 5| Step: 10
Training loss: 2.4154796600341797
Validation loss: 2.2909221700442735

Epoch: 104| Step: 0
Training loss: 2.3073408603668213
Validation loss: 2.284323879467544

Epoch: 5| Step: 1
Training loss: 2.9176104068756104
Validation loss: 2.289620307184035

Epoch: 5| Step: 2
Training loss: 2.539736270904541
Validation loss: 2.2825251804885043

Epoch: 5| Step: 3
Training loss: 2.3198959827423096
Validation loss: 2.2827200094858804

Epoch: 5| Step: 4
Training loss: 2.8017449378967285
Validation loss: 2.2851212691235285

Epoch: 5| Step: 5
Training loss: 2.1544692516326904
Validation loss: 2.283428825357909

Epoch: 5| Step: 6
Training loss: 2.651772975921631
Validation loss: 2.2971415724805606

Epoch: 5| Step: 7
Training loss: 2.748936176300049
Validation loss: 2.310618855619943

Epoch: 5| Step: 8
Training loss: 2.6216683387756348
Validation loss: 2.347402334213257

Epoch: 5| Step: 9
Training loss: 2.2586140632629395
Validation loss: 2.348803884239607

Epoch: 5| Step: 10
Training loss: 2.9733526706695557
Validation loss: 2.315685555499087

Epoch: 105| Step: 0
Training loss: 2.8187811374664307
Validation loss: 2.2909693115500995

Epoch: 5| Step: 1
Training loss: 2.6990532875061035
Validation loss: 2.2766649953780638

Epoch: 5| Step: 2
Training loss: 2.627126693725586
Validation loss: 2.271483322625519

Epoch: 5| Step: 3
Training loss: 2.413374185562134
Validation loss: 2.274452599146033

Epoch: 5| Step: 4
Training loss: 2.634462356567383
Validation loss: 2.2740829324209564

Epoch: 5| Step: 5
Training loss: 2.460056781768799
Validation loss: 2.280164146936068

Epoch: 5| Step: 6
Training loss: 2.52864146232605
Validation loss: 2.279169095459805

Epoch: 5| Step: 7
Training loss: 2.543973445892334
Validation loss: 2.284372098984257

Epoch: 5| Step: 8
Training loss: 2.4681954383850098
Validation loss: 2.274021920337472

Epoch: 5| Step: 9
Training loss: 2.322366237640381
Validation loss: 2.277465831848883

Epoch: 5| Step: 10
Training loss: 2.9026262760162354
Validation loss: 2.274576974171464

Epoch: 106| Step: 0
Training loss: 2.78895902633667
Validation loss: 2.2725481961363103

Epoch: 5| Step: 1
Training loss: 3.2133564949035645
Validation loss: 2.272531952909244

Epoch: 5| Step: 2
Training loss: 2.1079931259155273
Validation loss: 2.2792927475385767

Epoch: 5| Step: 3
Training loss: 2.596045732498169
Validation loss: 2.277385562978765

Epoch: 5| Step: 4
Training loss: 2.9992592334747314
Validation loss: 2.2802138559279905

Epoch: 5| Step: 5
Training loss: 2.1450366973876953
Validation loss: 2.2821756024514475

Epoch: 5| Step: 6
Training loss: 2.6270511150360107
Validation loss: 2.2825851978794223

Epoch: 5| Step: 7
Training loss: 2.39876127243042
Validation loss: 2.294709833719397

Epoch: 5| Step: 8
Training loss: 2.4757471084594727
Validation loss: 2.3019704844361994

Epoch: 5| Step: 9
Training loss: 2.6971065998077393
Validation loss: 2.3049537007526686

Epoch: 5| Step: 10
Training loss: 2.010221242904663
Validation loss: 2.307446833579771

Epoch: 107| Step: 0
Training loss: 2.7747693061828613
Validation loss: 2.3041404190883843

Epoch: 5| Step: 1
Training loss: 3.1511497497558594
Validation loss: 2.2974115187121975

Epoch: 5| Step: 2
Training loss: 2.298532009124756
Validation loss: 2.2827626171932427

Epoch: 5| Step: 3
Training loss: 2.2213220596313477
Validation loss: 2.278367525787764

Epoch: 5| Step: 4
Training loss: 2.1919772624969482
Validation loss: 2.282228615976149

Epoch: 5| Step: 5
Training loss: 3.174332857131958
Validation loss: 2.2779117348373576

Epoch: 5| Step: 6
Training loss: 2.1799676418304443
Validation loss: 2.282503210088258

Epoch: 5| Step: 7
Training loss: 2.8726656436920166
Validation loss: 2.2939769093708327

Epoch: 5| Step: 8
Training loss: 2.0660629272460938
Validation loss: 2.3029627594896542

Epoch: 5| Step: 9
Training loss: 2.419302463531494
Validation loss: 2.3203565536006803

Epoch: 5| Step: 10
Training loss: 2.8508756160736084
Validation loss: 2.325465706086928

Epoch: 108| Step: 0
Training loss: 2.8197824954986572
Validation loss: 2.325251817703247

Epoch: 5| Step: 1
Training loss: 2.9603946208953857
Validation loss: 2.3421860125757035

Epoch: 5| Step: 2
Training loss: 2.5071640014648438
Validation loss: 2.3258731801022767

Epoch: 5| Step: 3
Training loss: 1.8920199871063232
Validation loss: 2.3026470599635953

Epoch: 5| Step: 4
Training loss: 1.8752996921539307
Validation loss: 2.285532036135274

Epoch: 5| Step: 5
Training loss: 2.032085418701172
Validation loss: 2.2790791834554365

Epoch: 5| Step: 6
Training loss: 2.9042418003082275
Validation loss: 2.268737539168327

Epoch: 5| Step: 7
Training loss: 2.930896759033203
Validation loss: 2.2661904340149253

Epoch: 5| Step: 8
Training loss: 2.7674953937530518
Validation loss: 2.263106924231334

Epoch: 5| Step: 9
Training loss: 2.6590213775634766
Validation loss: 2.267029627676933

Epoch: 5| Step: 10
Training loss: 2.77703595161438
Validation loss: 2.2621365670234925

Epoch: 109| Step: 0
Training loss: 2.530423641204834
Validation loss: 2.2669434996061426

Epoch: 5| Step: 1
Training loss: 2.618201732635498
Validation loss: 2.2663224256166847

Epoch: 5| Step: 2
Training loss: 2.736328601837158
Validation loss: 2.2682219192545903

Epoch: 5| Step: 3
Training loss: 2.564640760421753
Validation loss: 2.268807185593472

Epoch: 5| Step: 4
Training loss: 2.637782573699951
Validation loss: 2.2672989112074657

Epoch: 5| Step: 5
Training loss: 2.0970113277435303
Validation loss: 2.2651881017992572

Epoch: 5| Step: 6
Training loss: 2.6540729999542236
Validation loss: 2.262913421917987

Epoch: 5| Step: 7
Training loss: 3.1274924278259277
Validation loss: 2.261294391847426

Epoch: 5| Step: 8
Training loss: 2.3630480766296387
Validation loss: 2.2654769882079093

Epoch: 5| Step: 9
Training loss: 2.0710225105285645
Validation loss: 2.2797891478384695

Epoch: 5| Step: 10
Training loss: 2.793314218521118
Validation loss: 2.296956467372115

Epoch: 110| Step: 0
Training loss: 2.7856285572052
Validation loss: 2.3047120007135535

Epoch: 5| Step: 1
Training loss: 2.958245038986206
Validation loss: 2.311595129710372

Epoch: 5| Step: 2
Training loss: 2.0968620777130127
Validation loss: 2.3109030749208186

Epoch: 5| Step: 3
Training loss: 2.8142762184143066
Validation loss: 2.313889439387988

Epoch: 5| Step: 4
Training loss: 2.5485968589782715
Validation loss: 2.3039332769250356

Epoch: 5| Step: 5
Training loss: 2.138817310333252
Validation loss: 2.2849849372781734

Epoch: 5| Step: 6
Training loss: 2.1801466941833496
Validation loss: 2.2841813154118036

Epoch: 5| Step: 7
Training loss: 2.2258331775665283
Validation loss: 2.284157294099049

Epoch: 5| Step: 8
Training loss: 3.3692517280578613
Validation loss: 2.276441640751336

Epoch: 5| Step: 9
Training loss: 2.552682638168335
Validation loss: 2.26841155944332

Epoch: 5| Step: 10
Training loss: 2.320206880569458
Validation loss: 2.261365541847803

Epoch: 111| Step: 0
Training loss: 2.4475741386413574
Validation loss: 2.2562133573716685

Epoch: 5| Step: 1
Training loss: 2.0054683685302734
Validation loss: 2.255423620182981

Epoch: 5| Step: 2
Training loss: 2.8490421772003174
Validation loss: 2.260154721557453

Epoch: 5| Step: 3
Training loss: 2.8082456588745117
Validation loss: 2.2493565262004895

Epoch: 5| Step: 4
Training loss: 2.180295944213867
Validation loss: 2.2532225526789182

Epoch: 5| Step: 5
Training loss: 2.597670316696167
Validation loss: 2.2541387183691866

Epoch: 5| Step: 6
Training loss: 2.860564947128296
Validation loss: 2.2477629082177275

Epoch: 5| Step: 7
Training loss: 2.97182035446167
Validation loss: 2.2535295922269105

Epoch: 5| Step: 8
Training loss: 1.7779788970947266
Validation loss: 2.255535694860643

Epoch: 5| Step: 9
Training loss: 2.7248570919036865
Validation loss: 2.2551872294436217

Epoch: 5| Step: 10
Training loss: 2.767674207687378
Validation loss: 2.2541583840565016

Epoch: 112| Step: 0
Training loss: 1.739708662033081
Validation loss: 2.2778464030194026

Epoch: 5| Step: 1
Training loss: 2.170668363571167
Validation loss: 2.2875258743122058

Epoch: 5| Step: 2
Training loss: 2.8788251876831055
Validation loss: 2.3026122739238124

Epoch: 5| Step: 3
Training loss: 2.4588167667388916
Validation loss: 2.325261277537192

Epoch: 5| Step: 4
Training loss: 2.491107225418091
Validation loss: 2.320521919958053

Epoch: 5| Step: 5
Training loss: 2.8871665000915527
Validation loss: 2.3238270385290987

Epoch: 5| Step: 6
Training loss: 3.2987499237060547
Validation loss: 2.2991368501417098

Epoch: 5| Step: 7
Training loss: 3.073509693145752
Validation loss: 2.2793600584871028

Epoch: 5| Step: 8
Training loss: 2.545987367630005
Validation loss: 2.2551714143445416

Epoch: 5| Step: 9
Training loss: 2.6136362552642822
Validation loss: 2.2507368851733465

Epoch: 5| Step: 10
Training loss: 1.7050617933273315
Validation loss: 2.259155806674752

Epoch: 113| Step: 0
Training loss: 2.8841259479522705
Validation loss: 2.268711643834268

Epoch: 5| Step: 1
Training loss: 2.5102009773254395
Validation loss: 2.255414173167239

Epoch: 5| Step: 2
Training loss: 2.038548469543457
Validation loss: 2.255096435546875

Epoch: 5| Step: 3
Training loss: 2.863679885864258
Validation loss: 2.234053675846387

Epoch: 5| Step: 4
Training loss: 2.1525657176971436
Validation loss: 2.2339020980301725

Epoch: 5| Step: 5
Training loss: 2.789640188217163
Validation loss: 2.2546162374557985

Epoch: 5| Step: 6
Training loss: 2.755305528640747
Validation loss: 2.2588547737367692

Epoch: 5| Step: 7
Training loss: 2.720879316329956
Validation loss: 2.283935099519709

Epoch: 5| Step: 8
Training loss: 2.3788273334503174
Validation loss: 2.2972190085277764

Epoch: 5| Step: 9
Training loss: 2.4933419227600098
Validation loss: 2.3126772911317888

Epoch: 5| Step: 10
Training loss: 2.6108322143554688
Validation loss: 2.2916996094488327

Epoch: 114| Step: 0
Training loss: 3.1385226249694824
Validation loss: 2.2747559778151976

Epoch: 5| Step: 1
Training loss: 2.5359914302825928
Validation loss: 2.2715564209927797

Epoch: 5| Step: 2
Training loss: 2.3164429664611816
Validation loss: 2.2636290878377934

Epoch: 5| Step: 3
Training loss: 2.3453946113586426
Validation loss: 2.2551806101235012

Epoch: 5| Step: 4
Training loss: 2.7006468772888184
Validation loss: 2.2439398970655215

Epoch: 5| Step: 5
Training loss: 2.4031119346618652
Validation loss: 2.245135509839622

Epoch: 5| Step: 6
Training loss: 2.5617241859436035
Validation loss: 2.2507771253585815

Epoch: 5| Step: 7
Training loss: 1.813161849975586
Validation loss: 2.2473752421717488

Epoch: 5| Step: 8
Training loss: 2.8363614082336426
Validation loss: 2.252308537883143

Epoch: 5| Step: 9
Training loss: 2.677919626235962
Validation loss: 2.2487065535719677

Epoch: 5| Step: 10
Training loss: 2.544431209564209
Validation loss: 2.238544584602438

Epoch: 115| Step: 0
Training loss: 2.435678005218506
Validation loss: 2.2426188786824546

Epoch: 5| Step: 1
Training loss: 2.532113552093506
Validation loss: 2.2476003503286712

Epoch: 5| Step: 2
Training loss: 2.4706783294677734
Validation loss: 2.2618111718085503

Epoch: 5| Step: 3
Training loss: 1.9154636859893799
Validation loss: 2.2608819930784163

Epoch: 5| Step: 4
Training loss: 2.7488298416137695
Validation loss: 2.2695859657820834

Epoch: 5| Step: 5
Training loss: 2.344417095184326
Validation loss: 2.2775811046682377

Epoch: 5| Step: 6
Training loss: 2.413907527923584
Validation loss: 2.2723328426320064

Epoch: 5| Step: 7
Training loss: 2.5233328342437744
Validation loss: 2.2820163349951468

Epoch: 5| Step: 8
Training loss: 2.8544249534606934
Validation loss: 2.2784157799136255

Epoch: 5| Step: 9
Training loss: 2.5323915481567383
Validation loss: 2.277450710214594

Epoch: 5| Step: 10
Training loss: 3.1088685989379883
Validation loss: 2.2776589739707207

Epoch: 116| Step: 0
Training loss: 2.379531145095825
Validation loss: 2.2541616296255462

Epoch: 5| Step: 1
Training loss: 2.474012851715088
Validation loss: 2.236981984107725

Epoch: 5| Step: 2
Training loss: 2.088583469390869
Validation loss: 2.219510729594897

Epoch: 5| Step: 3
Training loss: 2.2204151153564453
Validation loss: 2.223614210723549

Epoch: 5| Step: 4
Training loss: 2.8500049114227295
Validation loss: 2.2200092910438456

Epoch: 5| Step: 5
Training loss: 2.4010725021362305
Validation loss: 2.221503993516327

Epoch: 5| Step: 6
Training loss: 2.3792552947998047
Validation loss: 2.22567093500527

Epoch: 5| Step: 7
Training loss: 3.244887590408325
Validation loss: 2.2214749167042394

Epoch: 5| Step: 8
Training loss: 2.4649224281311035
Validation loss: 2.2233326050543014

Epoch: 5| Step: 9
Training loss: 2.693341016769409
Validation loss: 2.222181954691487

Epoch: 5| Step: 10
Training loss: 2.5308263301849365
Validation loss: 2.2247826309614283

Epoch: 117| Step: 0
Training loss: 2.054964780807495
Validation loss: 2.233992309980495

Epoch: 5| Step: 1
Training loss: 2.934255361557007
Validation loss: 2.24022872729968

Epoch: 5| Step: 2
Training loss: 3.0742249488830566
Validation loss: 2.2542088544496925

Epoch: 5| Step: 3
Training loss: 2.75433611869812
Validation loss: 2.2461396596765004

Epoch: 5| Step: 4
Training loss: 1.7857658863067627
Validation loss: 2.2468411742999987

Epoch: 5| Step: 5
Training loss: 2.5943000316619873
Validation loss: 2.261759647759058

Epoch: 5| Step: 6
Training loss: 2.36655855178833
Validation loss: 2.2715342737013295

Epoch: 5| Step: 7
Training loss: 2.800062656402588
Validation loss: 2.2612124591745357

Epoch: 5| Step: 8
Training loss: 2.4456608295440674
Validation loss: 2.251711937689012

Epoch: 5| Step: 9
Training loss: 2.6353163719177246
Validation loss: 2.2312292232308337

Epoch: 5| Step: 10
Training loss: 2.1563305854797363
Validation loss: 2.228606444533153

Epoch: 118| Step: 0
Training loss: 2.786937713623047
Validation loss: 2.2262844193366265

Epoch: 5| Step: 1
Training loss: 2.3698158264160156
Validation loss: 2.2390341989455687

Epoch: 5| Step: 2
Training loss: 2.2469382286071777
Validation loss: 2.2383241115077848

Epoch: 5| Step: 3
Training loss: 2.3214943408966064
Validation loss: 2.2685897837403

Epoch: 5| Step: 4
Training loss: 2.714287281036377
Validation loss: 2.288785393520068

Epoch: 5| Step: 5
Training loss: 2.5764946937561035
Validation loss: 2.264241700531334

Epoch: 5| Step: 6
Training loss: 2.7284324169158936
Validation loss: 2.2585802949884886

Epoch: 5| Step: 7
Training loss: 2.669116735458374
Validation loss: 2.2467409039056427

Epoch: 5| Step: 8
Training loss: 1.8728866577148438
Validation loss: 2.240616863773715

Epoch: 5| Step: 9
Training loss: 2.5167784690856934
Validation loss: 2.2612984308632473

Epoch: 5| Step: 10
Training loss: 2.859410047531128
Validation loss: 2.276890367589971

Epoch: 119| Step: 0
Training loss: 2.2923526763916016
Validation loss: 2.2993961816192954

Epoch: 5| Step: 1
Training loss: 2.6508350372314453
Validation loss: 2.3026766700129353

Epoch: 5| Step: 2
Training loss: 2.5190494060516357
Validation loss: 2.2984863353031937

Epoch: 5| Step: 3
Training loss: 2.2825071811676025
Validation loss: 2.272116618771707

Epoch: 5| Step: 4
Training loss: 2.4857535362243652
Validation loss: 2.26930126836223

Epoch: 5| Step: 5
Training loss: 2.491520643234253
Validation loss: 2.2794527648597636

Epoch: 5| Step: 6
Training loss: 2.573090076446533
Validation loss: 2.2694497800642446

Epoch: 5| Step: 7
Training loss: 2.397754192352295
Validation loss: 2.273285542764971

Epoch: 5| Step: 8
Training loss: 3.147285223007202
Validation loss: 2.2596395912990777

Epoch: 5| Step: 9
Training loss: 2.494333267211914
Validation loss: 2.2587512846915954

Epoch: 5| Step: 10
Training loss: 2.3737032413482666
Validation loss: 2.260927577172556

Epoch: 120| Step: 0
Training loss: 1.7049427032470703
Validation loss: 2.2653107463672595

Epoch: 5| Step: 1
Training loss: 3.62739634513855
Validation loss: 2.251856916694231

Epoch: 5| Step: 2
Training loss: 2.490912914276123
Validation loss: 2.2525577698984454

Epoch: 5| Step: 3
Training loss: 2.556962251663208
Validation loss: 2.2416185332882788

Epoch: 5| Step: 4
Training loss: 2.9035611152648926
Validation loss: 2.236171066120107

Epoch: 5| Step: 5
Training loss: 2.5326733589172363
Validation loss: 2.217853985806947

Epoch: 5| Step: 6
Training loss: 2.084587812423706
Validation loss: 2.2207404900622625

Epoch: 5| Step: 7
Training loss: 2.2790417671203613
Validation loss: 2.2233508940665954

Epoch: 5| Step: 8
Training loss: 2.826469898223877
Validation loss: 2.2406245098319104

Epoch: 5| Step: 9
Training loss: 2.1037650108337402
Validation loss: 2.2349156205372145

Epoch: 5| Step: 10
Training loss: 2.602329969406128
Validation loss: 2.224886478916291

Epoch: 121| Step: 0
Training loss: 2.441514253616333
Validation loss: 2.213590242529428

Epoch: 5| Step: 1
Training loss: 2.0650527477264404
Validation loss: 2.1966603353459346

Epoch: 5| Step: 2
Training loss: 3.158816337585449
Validation loss: 2.1909975954281387

Epoch: 5| Step: 3
Training loss: 2.448627233505249
Validation loss: 2.1960928414457586

Epoch: 5| Step: 4
Training loss: 2.6117029190063477
Validation loss: 2.186248187095888

Epoch: 5| Step: 5
Training loss: 2.7074472904205322
Validation loss: 2.198388356034474

Epoch: 5| Step: 6
Training loss: 2.8209755420684814
Validation loss: 2.203484214762206

Epoch: 5| Step: 7
Training loss: 1.5585583448410034
Validation loss: 2.208838580757059

Epoch: 5| Step: 8
Training loss: 2.188603162765503
Validation loss: 2.2141535666681107

Epoch: 5| Step: 9
Training loss: 2.521019697189331
Validation loss: 2.2282712844110306

Epoch: 5| Step: 10
Training loss: 3.0629703998565674
Validation loss: 2.2375390247632096

Epoch: 122| Step: 0
Training loss: 2.4336440563201904
Validation loss: 2.2320233698814147

Epoch: 5| Step: 1
Training loss: 2.1967408657073975
Validation loss: 2.210022884030496

Epoch: 5| Step: 2
Training loss: 1.657527208328247
Validation loss: 2.2008712150717296

Epoch: 5| Step: 3
Training loss: 2.35211443901062
Validation loss: 2.2040274399583057

Epoch: 5| Step: 4
Training loss: 2.327449321746826
Validation loss: 2.218450618046586

Epoch: 5| Step: 5
Training loss: 2.5344114303588867
Validation loss: 2.2260448522465204

Epoch: 5| Step: 6
Training loss: 2.3772616386413574
Validation loss: 2.2157542423535417

Epoch: 5| Step: 7
Training loss: 2.7387325763702393
Validation loss: 2.2086438953235583

Epoch: 5| Step: 8
Training loss: 3.1394991874694824
Validation loss: 2.208326223076031

Epoch: 5| Step: 9
Training loss: 3.1183829307556152
Validation loss: 2.2013722042883597

Epoch: 5| Step: 10
Training loss: 2.546168088912964
Validation loss: 2.206011461955245

Epoch: 123| Step: 0
Training loss: 1.8460441827774048
Validation loss: 2.1945225756655455

Epoch: 5| Step: 1
Training loss: 2.1323728561401367
Validation loss: 2.1991365981358353

Epoch: 5| Step: 2
Training loss: 2.7521560192108154
Validation loss: 2.206807123717441

Epoch: 5| Step: 3
Training loss: 2.933654308319092
Validation loss: 2.2071335597704818

Epoch: 5| Step: 4
Training loss: 2.35356068611145
Validation loss: 2.2022768271866666

Epoch: 5| Step: 5
Training loss: 2.446376085281372
Validation loss: 2.200105885023712

Epoch: 5| Step: 6
Training loss: 3.147366762161255
Validation loss: 2.196667407148628

Epoch: 5| Step: 7
Training loss: 2.4529013633728027
Validation loss: 2.198875927156018

Epoch: 5| Step: 8
Training loss: 2.216825008392334
Validation loss: 2.1919083954185568

Epoch: 5| Step: 9
Training loss: 2.029139995574951
Validation loss: 2.1993432557711037

Epoch: 5| Step: 10
Training loss: 3.119274616241455
Validation loss: 2.2155924151020665

Epoch: 124| Step: 0
Training loss: 2.8132171630859375
Validation loss: 2.263954149779453

Epoch: 5| Step: 1
Training loss: 3.2035529613494873
Validation loss: 2.2854170619800525

Epoch: 5| Step: 2
Training loss: 2.0852956771850586
Validation loss: 2.280419265070269

Epoch: 5| Step: 3
Training loss: 2.0298657417297363
Validation loss: 2.2317598532604914

Epoch: 5| Step: 4
Training loss: 2.2449328899383545
Validation loss: 2.188008616047521

Epoch: 5| Step: 5
Training loss: 3.248347759246826
Validation loss: 2.1959752395588863

Epoch: 5| Step: 6
Training loss: 1.7190825939178467
Validation loss: 2.215260171121167

Epoch: 5| Step: 7
Training loss: 2.1683053970336914
Validation loss: 2.208004133675688

Epoch: 5| Step: 8
Training loss: 3.0959908962249756
Validation loss: 2.211076218594787

Epoch: 5| Step: 9
Training loss: 2.2879879474639893
Validation loss: 2.2038926565518944

Epoch: 5| Step: 10
Training loss: 2.470961093902588
Validation loss: 2.196833300334151

Epoch: 125| Step: 0
Training loss: 2.076373815536499
Validation loss: 2.185503113654352

Epoch: 5| Step: 1
Training loss: 2.1821436882019043
Validation loss: 2.1744499244997577

Epoch: 5| Step: 2
Training loss: 2.06276535987854
Validation loss: 2.186419815145513

Epoch: 5| Step: 3
Training loss: 2.961400270462036
Validation loss: 2.200896647668654

Epoch: 5| Step: 4
Training loss: 2.677417278289795
Validation loss: 2.216047877906471

Epoch: 5| Step: 5
Training loss: 2.389523983001709
Validation loss: 2.265099130651002

Epoch: 5| Step: 6
Training loss: 2.665532112121582
Validation loss: 2.2966227044341383

Epoch: 5| Step: 7
Training loss: 2.4382007122039795
Validation loss: 2.2527943862381803

Epoch: 5| Step: 8
Training loss: 2.831451177597046
Validation loss: 2.2072860579336844

Epoch: 5| Step: 9
Training loss: 2.5478034019470215
Validation loss: 2.1737216493134857

Epoch: 5| Step: 10
Training loss: 2.518590211868286
Validation loss: 2.181156366102157

Epoch: 126| Step: 0
Training loss: 1.8272680044174194
Validation loss: 2.2083607822336178

Epoch: 5| Step: 1
Training loss: 2.6072306632995605
Validation loss: 2.2204264158843667

Epoch: 5| Step: 2
Training loss: 2.3493614196777344
Validation loss: 2.211475687642251

Epoch: 5| Step: 3
Training loss: 2.447526454925537
Validation loss: 2.1754894436046643

Epoch: 5| Step: 4
Training loss: 2.723715305328369
Validation loss: 2.1763971992718276

Epoch: 5| Step: 5
Training loss: 2.4118735790252686
Validation loss: 2.184883627840268

Epoch: 5| Step: 6
Training loss: 2.912020206451416
Validation loss: 2.1913593751128

Epoch: 5| Step: 7
Training loss: 2.1917150020599365
Validation loss: 2.2037362962640743

Epoch: 5| Step: 8
Training loss: 2.4112563133239746
Validation loss: 2.1989969181758102

Epoch: 5| Step: 9
Training loss: 3.0146915912628174
Validation loss: 2.1982198735719085

Epoch: 5| Step: 10
Training loss: 2.3719217777252197
Validation loss: 2.1863561599485335

Epoch: 127| Step: 0
Training loss: 2.575477361679077
Validation loss: 2.2018764147194485

Epoch: 5| Step: 1
Training loss: 3.047545909881592
Validation loss: 2.192453440799508

Epoch: 5| Step: 2
Training loss: 3.054039478302002
Validation loss: 2.1878424280433246

Epoch: 5| Step: 3
Training loss: 2.5115678310394287
Validation loss: 2.1750526376949844

Epoch: 5| Step: 4
Training loss: 2.413346767425537
Validation loss: 2.1744377177248717

Epoch: 5| Step: 5
Training loss: 2.2715466022491455
Validation loss: 2.182656062546597

Epoch: 5| Step: 6
Training loss: 1.8189191818237305
Validation loss: 2.1759302116209462

Epoch: 5| Step: 7
Training loss: 2.6415820121765137
Validation loss: 2.1718094195089033

Epoch: 5| Step: 8
Training loss: 1.9060084819793701
Validation loss: 2.180012656796363

Epoch: 5| Step: 9
Training loss: 2.057135581970215
Validation loss: 2.224332001901442

Epoch: 5| Step: 10
Training loss: 2.9481873512268066
Validation loss: 2.238280601398919

Epoch: 128| Step: 0
Training loss: 2.5555851459503174
Validation loss: 2.233649848609842

Epoch: 5| Step: 1
Training loss: 2.4427058696746826
Validation loss: 2.2072839249846754

Epoch: 5| Step: 2
Training loss: 2.7727885246276855
Validation loss: 2.202101363930651

Epoch: 5| Step: 3
Training loss: 1.728426218032837
Validation loss: 2.205887625294347

Epoch: 5| Step: 4
Training loss: 1.8824599981307983
Validation loss: 2.1979148464818157

Epoch: 5| Step: 5
Training loss: 2.5042710304260254
Validation loss: 2.215908896538519

Epoch: 5| Step: 6
Training loss: 2.771393060684204
Validation loss: 2.226167103295685

Epoch: 5| Step: 7
Training loss: 2.7689104080200195
Validation loss: 2.1910341580708823

Epoch: 5| Step: 8
Training loss: 2.5205368995666504
Validation loss: 2.171156708912183

Epoch: 5| Step: 9
Training loss: 2.730929374694824
Validation loss: 2.1766760003182197

Epoch: 5| Step: 10
Training loss: 2.6613047122955322
Validation loss: 2.199372512038036

Epoch: 129| Step: 0
Training loss: 2.716850757598877
Validation loss: 2.2647605019231

Epoch: 5| Step: 1
Training loss: 2.7636704444885254
Validation loss: 2.314404482482582

Epoch: 5| Step: 2
Training loss: 2.52599835395813
Validation loss: 2.359085412435634

Epoch: 5| Step: 3
Training loss: 2.895472764968872
Validation loss: 2.3838494823824976

Epoch: 5| Step: 4
Training loss: 2.187955617904663
Validation loss: 2.354407941141436

Epoch: 5| Step: 5
Training loss: 2.5627307891845703
Validation loss: 2.2720022355356524

Epoch: 5| Step: 6
Training loss: 2.2779386043548584
Validation loss: 2.2012571762966853

Epoch: 5| Step: 7
Training loss: 2.509506940841675
Validation loss: 2.1648718618577525

Epoch: 5| Step: 8
Training loss: 2.5693249702453613
Validation loss: 2.164292973856772

Epoch: 5| Step: 9
Training loss: 1.6719605922698975
Validation loss: 2.1789870672328497

Epoch: 5| Step: 10
Training loss: 3.160019874572754
Validation loss: 2.2565839649528585

Epoch: 130| Step: 0
Training loss: 2.818903684616089
Validation loss: 2.297820145084012

Epoch: 5| Step: 1
Training loss: 2.6196563243865967
Validation loss: 2.2934546419369277

Epoch: 5| Step: 2
Training loss: 3.062903642654419
Validation loss: 2.2197362633161646

Epoch: 5| Step: 3
Training loss: 2.5227737426757812
Validation loss: 2.1733769524481987

Epoch: 5| Step: 4
Training loss: 2.5862362384796143
Validation loss: 2.1545937984220442

Epoch: 5| Step: 5
Training loss: 1.9503542184829712
Validation loss: 2.1425603999886462

Epoch: 5| Step: 6
Training loss: 2.1107892990112305
Validation loss: 2.161648060685845

Epoch: 5| Step: 7
Training loss: 2.3375351428985596
Validation loss: 2.1748427985816874

Epoch: 5| Step: 8
Training loss: 2.1588070392608643
Validation loss: 2.203335532578089

Epoch: 5| Step: 9
Training loss: 2.26717209815979
Validation loss: 2.244935107487504

Epoch: 5| Step: 10
Training loss: 3.083726644515991
Validation loss: 2.2987332228691346

Epoch: 131| Step: 0
Training loss: 2.819113254547119
Validation loss: 2.3064784901116484

Epoch: 5| Step: 1
Training loss: 2.284158706665039
Validation loss: 2.29167035061826

Epoch: 5| Step: 2
Training loss: 2.1953461170196533
Validation loss: 2.2600844572949153

Epoch: 5| Step: 3
Training loss: 3.6581034660339355
Validation loss: 2.1897536400825746

Epoch: 5| Step: 4
Training loss: 2.199439287185669
Validation loss: 2.164453516724289

Epoch: 5| Step: 5
Training loss: 2.945103406906128
Validation loss: 2.1672023470683763

Epoch: 5| Step: 6
Training loss: 1.7880569696426392
Validation loss: 2.175061689910068

Epoch: 5| Step: 7
Training loss: 2.7735767364501953
Validation loss: 2.194253577980944

Epoch: 5| Step: 8
Training loss: 2.4770233631134033
Validation loss: 2.2295000809495167

Epoch: 5| Step: 9
Training loss: 2.1071937084198
Validation loss: 2.253178491387316

Epoch: 5| Step: 10
Training loss: 1.9093340635299683
Validation loss: 2.2608600201145297

Epoch: 132| Step: 0
Training loss: 2.667509078979492
Validation loss: 2.2604856593634493

Epoch: 5| Step: 1
Training loss: 2.6271634101867676
Validation loss: 2.247737338466029

Epoch: 5| Step: 2
Training loss: 1.828589677810669
Validation loss: 2.2265685924919705

Epoch: 5| Step: 3
Training loss: 2.334245443344116
Validation loss: 2.2321052423087497

Epoch: 5| Step: 4
Training loss: 2.763545274734497
Validation loss: 2.2248733453853156

Epoch: 5| Step: 5
Training loss: 1.9046344757080078
Validation loss: 2.246697977025022

Epoch: 5| Step: 6
Training loss: 2.7556889057159424
Validation loss: 2.229787447119272

Epoch: 5| Step: 7
Training loss: 2.628880739212036
Validation loss: 2.214003437308855

Epoch: 5| Step: 8
Training loss: 2.4209208488464355
Validation loss: 2.198023091080368

Epoch: 5| Step: 9
Training loss: 2.0891549587249756
Validation loss: 2.1768701858417963

Epoch: 5| Step: 10
Training loss: 2.7909913063049316
Validation loss: 2.1630746754266883

Epoch: 133| Step: 0
Training loss: 2.9858415126800537
Validation loss: 2.163224122857535

Epoch: 5| Step: 1
Training loss: 2.4993321895599365
Validation loss: 2.153865803954422

Epoch: 5| Step: 2
Training loss: 2.1219563484191895
Validation loss: 2.1525632540384927

Epoch: 5| Step: 3
Training loss: 1.543448567390442
Validation loss: 2.196805804006515

Epoch: 5| Step: 4
Training loss: 2.785701274871826
Validation loss: 2.176512934828317

Epoch: 5| Step: 5
Training loss: 2.829080104827881
Validation loss: 2.182110450601065

Epoch: 5| Step: 6
Training loss: 2.6228089332580566
Validation loss: 2.163897968107654

Epoch: 5| Step: 7
Training loss: 2.677506685256958
Validation loss: 2.151490285832395

Epoch: 5| Step: 8
Training loss: 2.0073230266571045
Validation loss: 2.159037470817566

Epoch: 5| Step: 9
Training loss: 2.4550328254699707
Validation loss: 2.1823060358724287

Epoch: 5| Step: 10
Training loss: 2.2614777088165283
Validation loss: 2.214228512138449

Epoch: 134| Step: 0
Training loss: 2.6229965686798096
Validation loss: 2.201149320089689

Epoch: 5| Step: 1
Training loss: 2.87489914894104
Validation loss: 2.222273559980495

Epoch: 5| Step: 2
Training loss: 2.2463390827178955
Validation loss: 2.2222717667138703

Epoch: 5| Step: 3
Training loss: 2.7218575477600098
Validation loss: 2.205585329763351

Epoch: 5| Step: 4
Training loss: 2.801697254180908
Validation loss: 2.196966245610227

Epoch: 5| Step: 5
Training loss: 2.3485138416290283
Validation loss: 2.1981839544029644

Epoch: 5| Step: 6
Training loss: 1.9943797588348389
Validation loss: 2.164798972427204

Epoch: 5| Step: 7
Training loss: 2.7733023166656494
Validation loss: 2.162324320885443

Epoch: 5| Step: 8
Training loss: 2.206000328063965
Validation loss: 2.1557414890617452

Epoch: 5| Step: 9
Training loss: 1.9305171966552734
Validation loss: 2.1627743090352705

Epoch: 5| Step: 10
Training loss: 2.219475269317627
Validation loss: 2.149619024286988

Epoch: 135| Step: 0
Training loss: 2.635284185409546
Validation loss: 2.146786146266486

Epoch: 5| Step: 1
Training loss: 2.577761173248291
Validation loss: 2.148200281204716

Epoch: 5| Step: 2
Training loss: 2.088893413543701
Validation loss: 2.154076909506193

Epoch: 5| Step: 3
Training loss: 2.3927290439605713
Validation loss: 2.154026254530876

Epoch: 5| Step: 4
Training loss: 2.1204276084899902
Validation loss: 2.168975442968389

Epoch: 5| Step: 5
Training loss: 2.76353120803833
Validation loss: 2.1733723673769223

Epoch: 5| Step: 6
Training loss: 1.9104820489883423
Validation loss: 2.1765229855814288

Epoch: 5| Step: 7
Training loss: 2.8772284984588623
Validation loss: 2.1607510095001548

Epoch: 5| Step: 8
Training loss: 2.7110774517059326
Validation loss: 2.1592970073864026

Epoch: 5| Step: 9
Training loss: 2.6897308826446533
Validation loss: 2.1575620353862806

Epoch: 5| Step: 10
Training loss: 1.892091155052185
Validation loss: 2.1521281196225073

Epoch: 136| Step: 0
Training loss: 2.3163866996765137
Validation loss: 2.149196811901626

Epoch: 5| Step: 1
Training loss: 1.7254575490951538
Validation loss: 2.1594873500126663

Epoch: 5| Step: 2
Training loss: 2.2499635219573975
Validation loss: 2.1678326668277865

Epoch: 5| Step: 3
Training loss: 2.126585006713867
Validation loss: 2.1703296681886077

Epoch: 5| Step: 4
Training loss: 2.0598535537719727
Validation loss: 2.200950441821929

Epoch: 5| Step: 5
Training loss: 2.240546703338623
Validation loss: 2.2256654026687785

Epoch: 5| Step: 6
Training loss: 3.061302661895752
Validation loss: 2.2402761020968036

Epoch: 5| Step: 7
Training loss: 2.483020544052124
Validation loss: 2.2406004064826557

Epoch: 5| Step: 8
Training loss: 2.8876404762268066
Validation loss: 2.2369014217007543

Epoch: 5| Step: 9
Training loss: 2.6850180625915527
Validation loss: 2.202486176644602

Epoch: 5| Step: 10
Training loss: 2.9613401889801025
Validation loss: 2.1877286511082805

Epoch: 137| Step: 0
Training loss: 2.3358702659606934
Validation loss: 2.211629686817046

Epoch: 5| Step: 1
Training loss: 2.5398736000061035
Validation loss: 2.2418013054837465

Epoch: 5| Step: 2
Training loss: 2.126995801925659
Validation loss: 2.2923920154571533

Epoch: 5| Step: 3
Training loss: 2.716987133026123
Validation loss: 2.333410406625399

Epoch: 5| Step: 4
Training loss: 2.089478015899658
Validation loss: 2.3125029430594495

Epoch: 5| Step: 5
Training loss: 2.2702481746673584
Validation loss: 2.2316933396042034

Epoch: 5| Step: 6
Training loss: 2.7774481773376465
Validation loss: 2.1881791955681256

Epoch: 5| Step: 7
Training loss: 1.9424545764923096
Validation loss: 2.178080645940637

Epoch: 5| Step: 8
Training loss: 2.8696789741516113
Validation loss: 2.2022764400769304

Epoch: 5| Step: 9
Training loss: 2.699263334274292
Validation loss: 2.2177203957752516

Epoch: 5| Step: 10
Training loss: 2.636477470397949
Validation loss: 2.246100899993732

Epoch: 138| Step: 0
Training loss: 1.8970367908477783
Validation loss: 2.294240810537851

Epoch: 5| Step: 1
Training loss: 2.1861159801483154
Validation loss: 2.307220951203377

Epoch: 5| Step: 2
Training loss: 2.2253408432006836
Validation loss: 2.253537239566926

Epoch: 5| Step: 3
Training loss: 3.2327194213867188
Validation loss: 2.1852522832091137

Epoch: 5| Step: 4
Training loss: 2.304135799407959
Validation loss: 2.1595987837801696

Epoch: 5| Step: 5
Training loss: 2.690080404281616
Validation loss: 2.1419213228328253

Epoch: 5| Step: 6
Training loss: 1.6867376565933228
Validation loss: 2.1593657206463557

Epoch: 5| Step: 7
Training loss: 2.2271156311035156
Validation loss: 2.1865959885299846

Epoch: 5| Step: 8
Training loss: 3.160576343536377
Validation loss: 2.229553027819562

Epoch: 5| Step: 9
Training loss: 3.0257740020751953
Validation loss: 2.2083795980740617

Epoch: 5| Step: 10
Training loss: 2.4320526123046875
Validation loss: 2.2099240287657707

Epoch: 139| Step: 0
Training loss: 2.8999853134155273
Validation loss: 2.1800590497191235

Epoch: 5| Step: 1
Training loss: 2.2855947017669678
Validation loss: 2.181132706262732

Epoch: 5| Step: 2
Training loss: 2.422316789627075
Validation loss: 2.162777587931643

Epoch: 5| Step: 3
Training loss: 1.9573615789413452
Validation loss: 2.1406642685654345

Epoch: 5| Step: 4
Training loss: 2.533618450164795
Validation loss: 2.1402455952859696

Epoch: 5| Step: 5
Training loss: 2.545041084289551
Validation loss: 2.1361138641193347

Epoch: 5| Step: 6
Training loss: 2.484065532684326
Validation loss: 2.1383593633610714

Epoch: 5| Step: 7
Training loss: 2.0632359981536865
Validation loss: 2.1686112983252412

Epoch: 5| Step: 8
Training loss: 2.878218650817871
Validation loss: 2.207874431405016

Epoch: 5| Step: 9
Training loss: 2.422435998916626
Validation loss: 2.2214355212385937

Epoch: 5| Step: 10
Training loss: 2.092895030975342
Validation loss: 2.227419678882886

Epoch: 140| Step: 0
Training loss: 3.1395695209503174
Validation loss: 2.2027714008926065

Epoch: 5| Step: 1
Training loss: 2.0586628913879395
Validation loss: 2.1847850686760357

Epoch: 5| Step: 2
Training loss: 3.0397167205810547
Validation loss: 2.195166754466231

Epoch: 5| Step: 3
Training loss: 2.736051321029663
Validation loss: 2.20986408059315

Epoch: 5| Step: 4
Training loss: 1.905571699142456
Validation loss: 2.2097513214234383

Epoch: 5| Step: 5
Training loss: 2.2288246154785156
Validation loss: 2.262690178809627

Epoch: 5| Step: 6
Training loss: 2.7298483848571777
Validation loss: 2.2275081219211703

Epoch: 5| Step: 7
Training loss: 2.4527668952941895
Validation loss: 2.202343071660688

Epoch: 5| Step: 8
Training loss: 1.793144941329956
Validation loss: 2.171160808173559

Epoch: 5| Step: 9
Training loss: 2.2800705432891846
Validation loss: 2.157633739133035

Epoch: 5| Step: 10
Training loss: 1.90800142288208
Validation loss: 2.14908201976489

Epoch: 141| Step: 0
Training loss: 1.9523725509643555
Validation loss: 2.1432261928435294

Epoch: 5| Step: 1
Training loss: 2.032243490219116
Validation loss: 2.1503337224324546

Epoch: 5| Step: 2
Training loss: 2.3803486824035645
Validation loss: 2.162170816493291

Epoch: 5| Step: 3
Training loss: 2.3835372924804688
Validation loss: 2.1577107790977723

Epoch: 5| Step: 4
Training loss: 2.3790500164031982
Validation loss: 2.1769555922477477

Epoch: 5| Step: 5
Training loss: 2.0462305545806885
Validation loss: 2.169541028238112

Epoch: 5| Step: 6
Training loss: 3.3176803588867188
Validation loss: 2.1672248917241252

Epoch: 5| Step: 7
Training loss: 2.1733996868133545
Validation loss: 2.166184804772818

Epoch: 5| Step: 8
Training loss: 2.722318410873413
Validation loss: 2.1623644380159277

Epoch: 5| Step: 9
Training loss: 2.6067397594451904
Validation loss: 2.139050796467771

Epoch: 5| Step: 10
Training loss: 2.496248960494995
Validation loss: 2.137246395951958

Epoch: 142| Step: 0
Training loss: 2.691986083984375
Validation loss: 2.148548250557274

Epoch: 5| Step: 1
Training loss: 2.691812515258789
Validation loss: 2.1719213275499243

Epoch: 5| Step: 2
Training loss: 2.1816487312316895
Validation loss: 2.2240158511746313

Epoch: 5| Step: 3
Training loss: 1.9785236120224
Validation loss: 2.317310212760843

Epoch: 5| Step: 4
Training loss: 2.1314568519592285
Validation loss: 2.352314464507564

Epoch: 5| Step: 5
Training loss: 2.3644070625305176
Validation loss: 2.3484863619650564

Epoch: 5| Step: 6
Training loss: 2.207127094268799
Validation loss: 2.265130768540085

Epoch: 5| Step: 7
Training loss: 2.9065968990325928
Validation loss: 2.1826459592388523

Epoch: 5| Step: 8
Training loss: 2.519357204437256
Validation loss: 2.149619545987857

Epoch: 5| Step: 9
Training loss: 2.4625391960144043
Validation loss: 2.16369064136218

Epoch: 5| Step: 10
Training loss: 2.357046604156494
Validation loss: 2.2063344896480603

Epoch: 143| Step: 0
Training loss: 2.3405463695526123
Validation loss: 2.2640537446545017

Epoch: 5| Step: 1
Training loss: 2.840315341949463
Validation loss: 2.3018442123166976

Epoch: 5| Step: 2
Training loss: 2.526982307434082
Validation loss: 2.243890344455678

Epoch: 5| Step: 3
Training loss: 2.164822816848755
Validation loss: 2.192595410090621

Epoch: 5| Step: 4
Training loss: 2.914701461791992
Validation loss: 2.1514743553694857

Epoch: 5| Step: 5
Training loss: 2.8331973552703857
Validation loss: 2.122202529702135

Epoch: 5| Step: 6
Training loss: 2.3813204765319824
Validation loss: 2.1125775960183915

Epoch: 5| Step: 7
Training loss: 1.8311774730682373
Validation loss: 2.1061948012280207

Epoch: 5| Step: 8
Training loss: 2.407837390899658
Validation loss: 2.1025794859855407

Epoch: 5| Step: 9
Training loss: 1.8126251697540283
Validation loss: 2.0852821462897846

Epoch: 5| Step: 10
Training loss: 2.689476251602173
Validation loss: 2.0879243240561536

Epoch: 144| Step: 0
Training loss: 2.6357359886169434
Validation loss: 2.097962981911116

Epoch: 5| Step: 1
Training loss: 2.528510808944702
Validation loss: 2.1048731803894043

Epoch: 5| Step: 2
Training loss: 1.860669493675232
Validation loss: 2.1078848479896464

Epoch: 5| Step: 3
Training loss: 2.7496695518493652
Validation loss: 2.1157407670892696

Epoch: 5| Step: 4
Training loss: 2.067852020263672
Validation loss: 2.1291807005482335

Epoch: 5| Step: 5
Training loss: 2.585144519805908
Validation loss: 2.146761004642774

Epoch: 5| Step: 6
Training loss: 2.5349583625793457
Validation loss: 2.1966787538220807

Epoch: 5| Step: 7
Training loss: 1.916233777999878
Validation loss: 2.262882609521189

Epoch: 5| Step: 8
Training loss: 2.257185459136963
Validation loss: 2.288880294369113

Epoch: 5| Step: 9
Training loss: 2.8460357189178467
Validation loss: 2.2074157986589658

Epoch: 5| Step: 10
Training loss: 2.430513620376587
Validation loss: 2.1471384750899447

Epoch: 145| Step: 0
Training loss: 2.6050660610198975
Validation loss: 2.134564409973801

Epoch: 5| Step: 1
Training loss: 2.5474002361297607
Validation loss: 2.1709226280130367

Epoch: 5| Step: 2
Training loss: 2.345247745513916
Validation loss: 2.1746334337419078

Epoch: 5| Step: 3
Training loss: 2.4391233921051025
Validation loss: 2.1622525927841023

Epoch: 5| Step: 4
Training loss: 2.470463275909424
Validation loss: 2.143862093648603

Epoch: 5| Step: 5
Training loss: 2.513761043548584
Validation loss: 2.141109760089587

Epoch: 5| Step: 6
Training loss: 2.0843756198883057
Validation loss: 2.141756352557931

Epoch: 5| Step: 7
Training loss: 2.11851167678833
Validation loss: 2.136827802145353

Epoch: 5| Step: 8
Training loss: 2.1233341693878174
Validation loss: 2.1524581652815624

Epoch: 5| Step: 9
Training loss: 2.0068624019622803
Validation loss: 2.1382513353901524

Epoch: 5| Step: 10
Training loss: 3.129112958908081
Validation loss: 2.1348193678804623

Epoch: 146| Step: 0
Training loss: 1.9537525177001953
Validation loss: 2.1308548347924345

Epoch: 5| Step: 1
Training loss: 2.521843433380127
Validation loss: 2.120586823391658

Epoch: 5| Step: 2
Training loss: 2.471235513687134
Validation loss: 2.1222752486505816

Epoch: 5| Step: 3
Training loss: 2.528886079788208
Validation loss: 2.127462289666617

Epoch: 5| Step: 4
Training loss: 2.2461416721343994
Validation loss: 2.144051162145471

Epoch: 5| Step: 5
Training loss: 2.8294596672058105
Validation loss: 2.1337904289204586

Epoch: 5| Step: 6
Training loss: 1.5748345851898193
Validation loss: 2.117997747595592

Epoch: 5| Step: 7
Training loss: 2.4043514728546143
Validation loss: 2.145156357877998

Epoch: 5| Step: 8
Training loss: 2.243408679962158
Validation loss: 2.1519777954265638

Epoch: 5| Step: 9
Training loss: 2.5092341899871826
Validation loss: 2.1522383228425057

Epoch: 5| Step: 10
Training loss: 2.777402877807617
Validation loss: 2.169853277103875

Epoch: 147| Step: 0
Training loss: 2.383840560913086
Validation loss: 2.1683028410839778

Epoch: 5| Step: 1
Training loss: 2.258190155029297
Validation loss: 2.1774157734327417

Epoch: 5| Step: 2
Training loss: 2.077528953552246
Validation loss: 2.2054180124754548

Epoch: 5| Step: 3
Training loss: 2.971327543258667
Validation loss: 2.2112234715492494

Epoch: 5| Step: 4
Training loss: 1.8978122472763062
Validation loss: 2.2025449609243744

Epoch: 5| Step: 5
Training loss: 3.059619188308716
Validation loss: 2.155255158742269

Epoch: 5| Step: 6
Training loss: 1.8797607421875
Validation loss: 2.1658810928303707

Epoch: 5| Step: 7
Training loss: 2.02131724357605
Validation loss: 2.143441205383629

Epoch: 5| Step: 8
Training loss: 3.0637831687927246
Validation loss: 2.14004990618716

Epoch: 5| Step: 9
Training loss: 2.065986156463623
Validation loss: 2.107823371887207

Epoch: 5| Step: 10
Training loss: 2.259047031402588
Validation loss: 2.0989509628665064

Epoch: 148| Step: 0
Training loss: 2.3807241916656494
Validation loss: 2.108682870864868

Epoch: 5| Step: 1
Training loss: 2.649484634399414
Validation loss: 2.1440837460179485

Epoch: 5| Step: 2
Training loss: 2.088573694229126
Validation loss: 2.1482058827595045

Epoch: 5| Step: 3
Training loss: 2.733552932739258
Validation loss: 2.246572102269819

Epoch: 5| Step: 4
Training loss: 2.255086660385132
Validation loss: 2.3284135582626506

Epoch: 5| Step: 5
Training loss: 2.221940517425537
Validation loss: 2.392525907485716

Epoch: 5| Step: 6
Training loss: 2.564098596572876
Validation loss: 2.3803473877650436

Epoch: 5| Step: 7
Training loss: 2.548902988433838
Validation loss: 2.277584304091751

Epoch: 5| Step: 8
Training loss: 2.012392997741699
Validation loss: 2.200961523158576

Epoch: 5| Step: 9
Training loss: 2.487234354019165
Validation loss: 2.1370358082555954

Epoch: 5| Step: 10
Training loss: 2.9190967082977295
Validation loss: 2.107936441257436

Epoch: 149| Step: 0
Training loss: 2.2153732776641846
Validation loss: 2.122017901430848

Epoch: 5| Step: 1
Training loss: 2.36775541305542
Validation loss: 2.223855944089992

Epoch: 5| Step: 2
Training loss: 2.8169312477111816
Validation loss: 2.3214766030670493

Epoch: 5| Step: 3
Training loss: 2.4276883602142334
Validation loss: 2.2711286544799805

Epoch: 5| Step: 4
Training loss: 3.0043888092041016
Validation loss: 2.2213854661551853

Epoch: 5| Step: 5
Training loss: 2.043708324432373
Validation loss: 2.142589061490951

Epoch: 5| Step: 6
Training loss: 2.194180965423584
Validation loss: 2.1154668818237963

Epoch: 5| Step: 7
Training loss: 2.1218481063842773
Validation loss: 2.112443108712473

Epoch: 5| Step: 8
Training loss: 2.6160311698913574
Validation loss: 2.1394595125670075

Epoch: 5| Step: 9
Training loss: 2.326920509338379
Validation loss: 2.1775554149381575

Epoch: 5| Step: 10
Training loss: 2.191185235977173
Validation loss: 2.3211114047676005

Epoch: 150| Step: 0
Training loss: 3.036714792251587
Validation loss: 2.4240397458435385

Epoch: 5| Step: 1
Training loss: 2.7641453742980957
Validation loss: 2.309779833721858

Epoch: 5| Step: 2
Training loss: 2.1924545764923096
Validation loss: 2.188382614043451

Epoch: 5| Step: 3
Training loss: 2.437130928039551
Validation loss: 2.131332130842311

Epoch: 5| Step: 4
Training loss: 2.2615270614624023
Validation loss: 2.0987209299559235

Epoch: 5| Step: 5
Training loss: 2.9605579376220703
Validation loss: 2.1005277197848082

Epoch: 5| Step: 6
Training loss: 2.912299633026123
Validation loss: 2.1043648373696113

Epoch: 5| Step: 7
Training loss: 1.3897945880889893
Validation loss: 2.1159073075940533

Epoch: 5| Step: 8
Training loss: 1.5829970836639404
Validation loss: 2.105589039864079

Epoch: 5| Step: 9
Training loss: 2.311310291290283
Validation loss: 2.104203272891301

Epoch: 5| Step: 10
Training loss: 2.210207939147949
Validation loss: 2.1292479243329776

Epoch: 151| Step: 0
Training loss: 2.524956464767456
Validation loss: 2.1079023281733194

Epoch: 5| Step: 1
Training loss: 2.2528138160705566
Validation loss: 2.0945126600162958

Epoch: 5| Step: 2
Training loss: 2.5277011394500732
Validation loss: 2.08927277083038

Epoch: 5| Step: 3
Training loss: 2.040473461151123
Validation loss: 2.102585739986871

Epoch: 5| Step: 4
Training loss: 2.5110979080200195
Validation loss: 2.0943244990482124

Epoch: 5| Step: 5
Training loss: 2.7233641147613525
Validation loss: 2.1076096821856756

Epoch: 5| Step: 6
Training loss: 2.449857234954834
Validation loss: 2.098726741729244

Epoch: 5| Step: 7
Training loss: 2.0973873138427734
Validation loss: 2.088086087216613

Epoch: 5| Step: 8
Training loss: 2.4527862071990967
Validation loss: 2.093712370882752

Epoch: 5| Step: 9
Training loss: 1.9220049381256104
Validation loss: 2.0946869068248297

Epoch: 5| Step: 10
Training loss: 2.2238998413085938
Validation loss: 2.1025148360959944

Epoch: 152| Step: 0
Training loss: 2.359893321990967
Validation loss: 2.1199635818440425

Epoch: 5| Step: 1
Training loss: 2.3549892902374268
Validation loss: 2.1115254663651988

Epoch: 5| Step: 2
Training loss: 1.799919843673706
Validation loss: 2.134209749519184

Epoch: 5| Step: 3
Training loss: 2.154834270477295
Validation loss: 2.1485428323027906

Epoch: 5| Step: 4
Training loss: 1.9463748931884766
Validation loss: 2.194437414087275

Epoch: 5| Step: 5
Training loss: 2.0589070320129395
Validation loss: 2.2440150014815794

Epoch: 5| Step: 6
Training loss: 2.179617404937744
Validation loss: 2.2696575977469005

Epoch: 5| Step: 7
Training loss: 2.808654546737671
Validation loss: 2.233229421800183

Epoch: 5| Step: 8
Training loss: 2.5827131271362305
Validation loss: 2.1911199836320776

Epoch: 5| Step: 9
Training loss: 2.992534875869751
Validation loss: 2.179654223944551

Epoch: 5| Step: 10
Training loss: 2.753594398498535
Validation loss: 2.2179409457791235

Epoch: 153| Step: 0
Training loss: 2.435805082321167
Validation loss: 2.2212865378267024

Epoch: 5| Step: 1
Training loss: 2.2157866954803467
Validation loss: 2.244061893032443

Epoch: 5| Step: 2
Training loss: 2.106887102127075
Validation loss: 2.2226333695073284

Epoch: 5| Step: 3
Training loss: 2.4151859283447266
Validation loss: 2.2018870051189134

Epoch: 5| Step: 4
Training loss: 2.548893451690674
Validation loss: 2.1557456113958873

Epoch: 5| Step: 5
Training loss: 1.8746082782745361
Validation loss: 2.111577255751497

Epoch: 5| Step: 6
Training loss: 2.4933485984802246
Validation loss: 2.07965947222966

Epoch: 5| Step: 7
Training loss: 2.3382935523986816
Validation loss: 2.0859585115986485

Epoch: 5| Step: 8
Training loss: 2.836667537689209
Validation loss: 2.097889598979745

Epoch: 5| Step: 9
Training loss: 2.3074917793273926
Validation loss: 2.105681852627826

Epoch: 5| Step: 10
Training loss: 2.3214542865753174
Validation loss: 2.146655713358233

Epoch: 154| Step: 0
Training loss: 2.1952147483825684
Validation loss: 2.219443000772948

Epoch: 5| Step: 1
Training loss: 2.1128640174865723
Validation loss: 2.2689599734480663

Epoch: 5| Step: 2
Training loss: 2.864514112472534
Validation loss: 2.267811788025723

Epoch: 5| Step: 3
Training loss: 2.9484546184539795
Validation loss: 2.2167430795649046

Epoch: 5| Step: 4
Training loss: 2.5255796909332275
Validation loss: 2.167479589421262

Epoch: 5| Step: 5
Training loss: 2.3246216773986816
Validation loss: 2.110583607868482

Epoch: 5| Step: 6
Training loss: 2.0054733753204346
Validation loss: 2.1073342933449695

Epoch: 5| Step: 7
Training loss: 2.4295742511749268
Validation loss: 2.107691998122841

Epoch: 5| Step: 8
Training loss: 1.474875569343567
Validation loss: 2.106855138655632

Epoch: 5| Step: 9
Training loss: 2.1589462757110596
Validation loss: 2.1216207242781118

Epoch: 5| Step: 10
Training loss: 2.792848825454712
Validation loss: 2.1206742307191253

Epoch: 155| Step: 0
Training loss: 2.5396389961242676
Validation loss: 2.1016341435011996

Epoch: 5| Step: 1
Training loss: 2.6360301971435547
Validation loss: 2.0901733290764595

Epoch: 5| Step: 2
Training loss: 2.1015632152557373
Validation loss: 2.078482647095957

Epoch: 5| Step: 3
Training loss: 1.641226053237915
Validation loss: 2.0750935910850443

Epoch: 5| Step: 4
Training loss: 2.4747657775878906
Validation loss: 2.0831514866121355

Epoch: 5| Step: 5
Training loss: 2.981163263320923
Validation loss: 2.09168061389718

Epoch: 5| Step: 6
Training loss: 2.4582622051239014
Validation loss: 2.0850071907043457

Epoch: 5| Step: 7
Training loss: 2.288618803024292
Validation loss: 2.0880968673254854

Epoch: 5| Step: 8
Training loss: 1.9702072143554688
Validation loss: 2.094693189026207

Epoch: 5| Step: 9
Training loss: 2.0620028972625732
Validation loss: 2.1139469736365863

Epoch: 5| Step: 10
Training loss: 2.163105010986328
Validation loss: 2.1246511961824153

Epoch: 156| Step: 0
Training loss: 1.952450156211853
Validation loss: 2.1451482221644413

Epoch: 5| Step: 1
Training loss: 1.6890337467193604
Validation loss: 2.1397206296202955

Epoch: 5| Step: 2
Training loss: 2.279268264770508
Validation loss: 2.152686224188856

Epoch: 5| Step: 3
Training loss: 2.198042869567871
Validation loss: 2.1758492941497476

Epoch: 5| Step: 4
Training loss: 2.7165403366088867
Validation loss: 2.213724254280008

Epoch: 5| Step: 5
Training loss: 1.6761213541030884
Validation loss: 2.233267714900355

Epoch: 5| Step: 6
Training loss: 2.5707199573516846
Validation loss: 2.2267723442405782

Epoch: 5| Step: 7
Training loss: 2.6414272785186768
Validation loss: 2.209594211270732

Epoch: 5| Step: 8
Training loss: 3.156489849090576
Validation loss: 2.1826171977545625

Epoch: 5| Step: 9
Training loss: 1.980412483215332
Validation loss: 2.1557984864839943

Epoch: 5| Step: 10
Training loss: 2.297161817550659
Validation loss: 2.124096075693766

Epoch: 157| Step: 0
Training loss: 2.7434029579162598
Validation loss: 2.1258528437665714

Epoch: 5| Step: 1
Training loss: 2.1362202167510986
Validation loss: 2.1123564794499385

Epoch: 5| Step: 2
Training loss: 2.413794994354248
Validation loss: 2.125657009822066

Epoch: 5| Step: 3
Training loss: 2.7746479511260986
Validation loss: 2.1455710036780244

Epoch: 5| Step: 4
Training loss: 1.6787697076797485
Validation loss: 2.1342818198665494

Epoch: 5| Step: 5
Training loss: 1.9798673391342163
Validation loss: 2.1352651837051555

Epoch: 5| Step: 6
Training loss: 2.960289239883423
Validation loss: 2.116744669534827

Epoch: 5| Step: 7
Training loss: 2.0267629623413086
Validation loss: 2.111139997359245

Epoch: 5| Step: 8
Training loss: 2.1179556846618652
Validation loss: 2.109453216675789

Epoch: 5| Step: 9
Training loss: 2.4666905403137207
Validation loss: 2.1141060936835503

Epoch: 5| Step: 10
Training loss: 1.644139051437378
Validation loss: 2.1330124203876784

Epoch: 158| Step: 0
Training loss: 1.9548429250717163
Validation loss: 2.1567639689291678

Epoch: 5| Step: 1
Training loss: 2.895606517791748
Validation loss: 2.1849931029863257

Epoch: 5| Step: 2
Training loss: 2.4331326484680176
Validation loss: 2.2163454435204946

Epoch: 5| Step: 3
Training loss: 2.683986186981201
Validation loss: 2.2417262087586107

Epoch: 5| Step: 4
Training loss: 1.9780473709106445
Validation loss: 2.2884133092818724

Epoch: 5| Step: 5
Training loss: 2.3531172275543213
Validation loss: 2.2188438946200955

Epoch: 5| Step: 6
Training loss: 2.5485527515411377
Validation loss: 2.1605357803324217

Epoch: 5| Step: 7
Training loss: 2.191702365875244
Validation loss: 2.1242486328207035

Epoch: 5| Step: 8
Training loss: 2.187662124633789
Validation loss: 2.1355862694401897

Epoch: 5| Step: 9
Training loss: 2.193138599395752
Validation loss: 2.1734688115376297

Epoch: 5| Step: 10
Training loss: 2.176997661590576
Validation loss: 2.163254822454145

Epoch: 159| Step: 0
Training loss: 2.6141858100891113
Validation loss: 2.1660612398578274

Epoch: 5| Step: 1
Training loss: 2.5628225803375244
Validation loss: 2.153874612623645

Epoch: 5| Step: 2
Training loss: 2.008098602294922
Validation loss: 2.1094265163585706

Epoch: 5| Step: 3
Training loss: 2.711235523223877
Validation loss: 2.0748713324146886

Epoch: 5| Step: 4
Training loss: 1.902100920677185
Validation loss: 2.0757070305526897

Epoch: 5| Step: 5
Training loss: 1.8236593008041382
Validation loss: 2.076066963134273

Epoch: 5| Step: 6
Training loss: 1.8659942150115967
Validation loss: 2.0977656584914013

Epoch: 5| Step: 7
Training loss: 2.084193706512451
Validation loss: 2.0983094861430507

Epoch: 5| Step: 8
Training loss: 2.8827853202819824
Validation loss: 2.080772215320218

Epoch: 5| Step: 9
Training loss: 1.9618244171142578
Validation loss: 2.0972851476361676

Epoch: 5| Step: 10
Training loss: 2.74933123588562
Validation loss: 2.0835642071180445

Epoch: 160| Step: 0
Training loss: 2.3838698863983154
Validation loss: 2.1117720911579747

Epoch: 5| Step: 1
Training loss: 2.0263991355895996
Validation loss: 2.1326736557868218

Epoch: 5| Step: 2
Training loss: 2.291006088256836
Validation loss: 2.1453586957787953

Epoch: 5| Step: 3
Training loss: 2.4385344982147217
Validation loss: 2.162484081842566

Epoch: 5| Step: 4
Training loss: 2.00887393951416
Validation loss: 2.187584556559081

Epoch: 5| Step: 5
Training loss: 2.0124924182891846
Validation loss: 2.213128089904785

Epoch: 5| Step: 6
Training loss: 2.247283458709717
Validation loss: 2.1807732864092757

Epoch: 5| Step: 7
Training loss: 2.296928882598877
Validation loss: 2.1958555547139977

Epoch: 5| Step: 8
Training loss: 2.6544971466064453
Validation loss: 2.195807328788183

Epoch: 5| Step: 9
Training loss: 2.8122470378875732
Validation loss: 2.1801188351005636

Epoch: 5| Step: 10
Training loss: 1.8889801502227783
Validation loss: 2.155637735961586

Epoch: 161| Step: 0
Training loss: 2.5136635303497314
Validation loss: 2.1344013457657187

Epoch: 5| Step: 1
Training loss: 2.1364498138427734
Validation loss: 2.141416108736428

Epoch: 5| Step: 2
Training loss: 2.091127872467041
Validation loss: 2.251468268773889

Epoch: 5| Step: 3
Training loss: 2.4308083057403564
Validation loss: 2.2950160811024327

Epoch: 5| Step: 4
Training loss: 2.693434715270996
Validation loss: 2.3184754284479285

Epoch: 5| Step: 5
Training loss: 2.4390034675598145
Validation loss: 2.2720147461019535

Epoch: 5| Step: 6
Training loss: 2.186373233795166
Validation loss: 2.2116932445956814

Epoch: 5| Step: 7
Training loss: 2.3671669960021973
Validation loss: 2.1322188505562405

Epoch: 5| Step: 8
Training loss: 2.485309600830078
Validation loss: 2.086647419519322

Epoch: 5| Step: 9
Training loss: 2.268939256668091
Validation loss: 2.05588900145664

Epoch: 5| Step: 10
Training loss: 2.245424509048462
Validation loss: 2.0722201434514855

Epoch: 162| Step: 0
Training loss: 2.5546138286590576
Validation loss: 2.1098616610291185

Epoch: 5| Step: 1
Training loss: 2.3050265312194824
Validation loss: 2.120521089082123

Epoch: 5| Step: 2
Training loss: 2.2635035514831543
Validation loss: 2.1288630757280576

Epoch: 5| Step: 3
Training loss: 2.31674861907959
Validation loss: 2.1336397676057715

Epoch: 5| Step: 4
Training loss: 2.3924312591552734
Validation loss: 2.1623897514035626

Epoch: 5| Step: 5
Training loss: 2.285579204559326
Validation loss: 2.136468441255631

Epoch: 5| Step: 6
Training loss: 2.8283610343933105
Validation loss: 2.0960999688794537

Epoch: 5| Step: 7
Training loss: 2.72294545173645
Validation loss: 2.0529526792546755

Epoch: 5| Step: 8
Training loss: 1.739450454711914
Validation loss: 2.041535569775489

Epoch: 5| Step: 9
Training loss: 2.6200432777404785
Validation loss: 2.0738942341137956

Epoch: 5| Step: 10
Training loss: 1.4717155694961548
Validation loss: 2.1083865114437637

Epoch: 163| Step: 0
Training loss: 2.452136516571045
Validation loss: 2.1300142708645073

Epoch: 5| Step: 1
Training loss: 2.5311808586120605
Validation loss: 2.146518197110904

Epoch: 5| Step: 2
Training loss: 1.8195968866348267
Validation loss: 2.167074857219573

Epoch: 5| Step: 3
Training loss: 1.6562302112579346
Validation loss: 2.1665746986225085

Epoch: 5| Step: 4
Training loss: 2.1332602500915527
Validation loss: 2.1324058014859437

Epoch: 5| Step: 5
Training loss: 2.12367844581604
Validation loss: 2.1403867403666177

Epoch: 5| Step: 6
Training loss: 2.358504056930542
Validation loss: 2.155459171982222

Epoch: 5| Step: 7
Training loss: 2.9384407997131348
Validation loss: 2.1541583050963697

Epoch: 5| Step: 8
Training loss: 2.0084240436553955
Validation loss: 2.15397991929003

Epoch: 5| Step: 9
Training loss: 2.2197787761688232
Validation loss: 2.1807436327780447

Epoch: 5| Step: 10
Training loss: 2.520214080810547
Validation loss: 2.169809881077018

Epoch: 164| Step: 0
Training loss: 2.3460183143615723
Validation loss: 2.153719345728556

Epoch: 5| Step: 1
Training loss: 2.9048752784729004
Validation loss: 2.161351196227535

Epoch: 5| Step: 2
Training loss: 2.2586469650268555
Validation loss: 2.1599242059133386

Epoch: 5| Step: 3
Training loss: 1.7976576089859009
Validation loss: 2.15907076738214

Epoch: 5| Step: 4
Training loss: 1.8952735662460327
Validation loss: 2.14710799853007

Epoch: 5| Step: 5
Training loss: 2.0235815048217773
Validation loss: 2.1423064303654495

Epoch: 5| Step: 6
Training loss: 1.7944040298461914
Validation loss: 2.1202154877365276

Epoch: 5| Step: 7
Training loss: 2.2689850330352783
Validation loss: 2.11786344615362

Epoch: 5| Step: 8
Training loss: 2.5362181663513184
Validation loss: 2.1090861392277542

Epoch: 5| Step: 9
Training loss: 2.0683305263519287
Validation loss: 2.1399285870213665

Epoch: 5| Step: 10
Training loss: 2.3495116233825684
Validation loss: 2.134341865457514

Epoch: 165| Step: 0
Training loss: 2.2776150703430176
Validation loss: 2.139730872646455

Epoch: 5| Step: 1
Training loss: 1.9760421514511108
Validation loss: 2.135622219372821

Epoch: 5| Step: 2
Training loss: 2.476004123687744
Validation loss: 2.138995370557231

Epoch: 5| Step: 3
Training loss: 2.6767826080322266
Validation loss: 2.155381651334865

Epoch: 5| Step: 4
Training loss: 1.9412742853164673
Validation loss: 2.1280023795302196

Epoch: 5| Step: 5
Training loss: 2.1678948402404785
Validation loss: 2.1226549840742543

Epoch: 5| Step: 6
Training loss: 1.5725085735321045
Validation loss: 2.1108548487386396

Epoch: 5| Step: 7
Training loss: 2.4253172874450684
Validation loss: 2.099884076785016

Epoch: 5| Step: 8
Training loss: 2.448206663131714
Validation loss: 2.092989488314557

Epoch: 5| Step: 9
Training loss: 1.6305698156356812
Validation loss: 2.072940295742404

Epoch: 5| Step: 10
Training loss: 2.3834753036499023
Validation loss: 2.0773764758981685

Epoch: 166| Step: 0
Training loss: 2.574326992034912
Validation loss: 2.0805019717062674

Epoch: 5| Step: 1
Training loss: 2.451324939727783
Validation loss: 2.067883619698145

Epoch: 5| Step: 2
Training loss: 1.907051682472229
Validation loss: 2.0811171967496156

Epoch: 5| Step: 3
Training loss: 2.441382884979248
Validation loss: 2.098281068186606

Epoch: 5| Step: 4
Training loss: 2.2826104164123535
Validation loss: 2.1192237356657624

Epoch: 5| Step: 5
Training loss: 2.3985021114349365
Validation loss: 2.160738650188651

Epoch: 5| Step: 6
Training loss: 1.9440438747406006
Validation loss: 2.1407936926810973

Epoch: 5| Step: 7
Training loss: 1.8793962001800537
Validation loss: 2.1249199221211095

Epoch: 5| Step: 8
Training loss: 1.836221694946289
Validation loss: 2.1054625588078655

Epoch: 5| Step: 9
Training loss: 2.3014767169952393
Validation loss: 2.1045780976613364

Epoch: 5| Step: 10
Training loss: 1.9581141471862793
Validation loss: 2.108031213924449

Epoch: 167| Step: 0
Training loss: 2.143998622894287
Validation loss: 2.1243472406941075

Epoch: 5| Step: 1
Training loss: 2.2270350456237793
Validation loss: 2.1252760887145996

Epoch: 5| Step: 2
Training loss: 2.071246385574341
Validation loss: 2.124436370788082

Epoch: 5| Step: 3
Training loss: 1.8448960781097412
Validation loss: 2.1163782688879196

Epoch: 5| Step: 4
Training loss: 1.9005746841430664
Validation loss: 2.125618468048752

Epoch: 5| Step: 5
Training loss: 1.730230689048767
Validation loss: 2.134053478958786

Epoch: 5| Step: 6
Training loss: 2.163161516189575
Validation loss: 2.130814613834504

Epoch: 5| Step: 7
Training loss: 2.278759479522705
Validation loss: 2.150504696753717

Epoch: 5| Step: 8
Training loss: 2.6619293689727783
Validation loss: 2.159414770782635

Epoch: 5| Step: 9
Training loss: 2.5162792205810547
Validation loss: 2.1485315599749164

Epoch: 5| Step: 10
Training loss: 2.2559750080108643
Validation loss: 2.130836327870687

Epoch: 168| Step: 0
Training loss: 2.0271568298339844
Validation loss: 2.111489601032708

Epoch: 5| Step: 1
Training loss: 2.3080506324768066
Validation loss: 2.1058486046329623

Epoch: 5| Step: 2
Training loss: 2.363259792327881
Validation loss: 2.0956850718426447

Epoch: 5| Step: 3
Training loss: 2.1908915042877197
Validation loss: 2.110800871285059

Epoch: 5| Step: 4
Training loss: 1.6351906061172485
Validation loss: 2.1127772536329044

Epoch: 5| Step: 5
Training loss: 1.7802683115005493
Validation loss: 2.1182532848850375

Epoch: 5| Step: 6
Training loss: 2.195561647415161
Validation loss: 2.116145872300671

Epoch: 5| Step: 7
Training loss: 2.281137466430664
Validation loss: 2.0913106574807117

Epoch: 5| Step: 8
Training loss: 2.1620888710021973
Validation loss: 2.100085868630358

Epoch: 5| Step: 9
Training loss: 2.226154327392578
Validation loss: 2.091619239058546

Epoch: 5| Step: 10
Training loss: 2.344766139984131
Validation loss: 2.0792443624106784

Epoch: 169| Step: 0
Training loss: 1.5165045261383057
Validation loss: 2.074166795258881

Epoch: 5| Step: 1
Training loss: 2.547306537628174
Validation loss: 2.0852783341561594

Epoch: 5| Step: 2
Training loss: 2.265580654144287
Validation loss: 2.091855533661381

Epoch: 5| Step: 3
Training loss: 1.9360730648040771
Validation loss: 2.0927550895239717

Epoch: 5| Step: 4
Training loss: 2.3218026161193848
Validation loss: 2.073063532511393

Epoch: 5| Step: 5
Training loss: 2.020596981048584
Validation loss: 2.0841096344814507

Epoch: 5| Step: 6
Training loss: 2.417290687561035
Validation loss: 2.0869804659197406

Epoch: 5| Step: 7
Training loss: 1.5983800888061523
Validation loss: 2.080270594166171

Epoch: 5| Step: 8
Training loss: 2.4930968284606934
Validation loss: 2.093082679215298

Epoch: 5| Step: 9
Training loss: 1.9781923294067383
Validation loss: 2.1017036284169843

Epoch: 5| Step: 10
Training loss: 2.2564022541046143
Validation loss: 2.1160929831125403

Epoch: 170| Step: 0
Training loss: 1.9845569133758545
Validation loss: 2.1363803789179814

Epoch: 5| Step: 1
Training loss: 2.4678101539611816
Validation loss: 2.1642385567388227

Epoch: 5| Step: 2
Training loss: 1.8346227407455444
Validation loss: 2.1384266755914174

Epoch: 5| Step: 3
Training loss: 2.037499189376831
Validation loss: 2.1248295589159896

Epoch: 5| Step: 4
Training loss: 1.2770977020263672
Validation loss: 2.1198381813623572

Epoch: 5| Step: 5
Training loss: 2.3892006874084473
Validation loss: 2.0980048410354124

Epoch: 5| Step: 6
Training loss: 2.362637996673584
Validation loss: 2.113750147563155

Epoch: 5| Step: 7
Training loss: 2.3160159587860107
Validation loss: 2.12775945150724

Epoch: 5| Step: 8
Training loss: 2.4488253593444824
Validation loss: 2.1184438095297864

Epoch: 5| Step: 9
Training loss: 2.193732976913452
Validation loss: 2.1003886345894105

Epoch: 5| Step: 10
Training loss: 2.1405673027038574
Validation loss: 2.074452789880896

Epoch: 171| Step: 0
Training loss: 1.6368305683135986
Validation loss: 2.0614985560858123

Epoch: 5| Step: 1
Training loss: 2.3853068351745605
Validation loss: 2.0431291057217504

Epoch: 5| Step: 2
Training loss: 2.573326826095581
Validation loss: 2.0523195881997385

Epoch: 5| Step: 3
Training loss: 2.4752190113067627
Validation loss: 2.0617308873002247

Epoch: 5| Step: 4
Training loss: 1.8078439235687256
Validation loss: 2.066850826304446

Epoch: 5| Step: 5
Training loss: 1.8697025775909424
Validation loss: 2.0857395023427983

Epoch: 5| Step: 6
Training loss: 2.035749912261963
Validation loss: 2.0920675287964525

Epoch: 5| Step: 7
Training loss: 2.156996250152588
Validation loss: 2.0993038992727957

Epoch: 5| Step: 8
Training loss: 2.211787700653076
Validation loss: 2.1128943991917435

Epoch: 5| Step: 9
Training loss: 2.068995714187622
Validation loss: 2.1156945408031507

Epoch: 5| Step: 10
Training loss: 2.0862832069396973
Validation loss: 2.124627701697811

Epoch: 172| Step: 0
Training loss: 2.4390852451324463
Validation loss: 2.1076550304248767

Epoch: 5| Step: 1
Training loss: 2.137665271759033
Validation loss: 2.075857359875915

Epoch: 5| Step: 2
Training loss: 1.6923000812530518
Validation loss: 2.0788282655900523

Epoch: 5| Step: 3
Training loss: 1.9882930517196655
Validation loss: 2.0666656853050314

Epoch: 5| Step: 4
Training loss: 1.8587837219238281
Validation loss: 2.07446398017227

Epoch: 5| Step: 5
Training loss: 2.780792713165283
Validation loss: 2.0675199672739994

Epoch: 5| Step: 6
Training loss: 1.754307746887207
Validation loss: 2.0791719985264603

Epoch: 5| Step: 7
Training loss: 1.6552460193634033
Validation loss: 2.0915173586978706

Epoch: 5| Step: 8
Training loss: 2.502216100692749
Validation loss: 2.1080636414148475

Epoch: 5| Step: 9
Training loss: 2.384564161300659
Validation loss: 2.155204911385813

Epoch: 5| Step: 10
Training loss: 1.6654562950134277
Validation loss: 2.215600889216187

Epoch: 173| Step: 0
Training loss: 3.074531078338623
Validation loss: 2.2330653308540263

Epoch: 5| Step: 1
Training loss: 1.991929292678833
Validation loss: 2.1715454004144155

Epoch: 5| Step: 2
Training loss: 2.6818888187408447
Validation loss: 2.1030806879843436

Epoch: 5| Step: 3
Training loss: 1.7294814586639404
Validation loss: 2.0499845679088304

Epoch: 5| Step: 4
Training loss: 2.065915584564209
Validation loss: 2.0617225708500033

Epoch: 5| Step: 5
Training loss: 2.5262529850006104
Validation loss: 2.045830662532519

Epoch: 5| Step: 6
Training loss: 2.2473371028900146
Validation loss: 2.0364272978998

Epoch: 5| Step: 7
Training loss: 1.6468017101287842
Validation loss: 2.0268148401732087

Epoch: 5| Step: 8
Training loss: 2.2004008293151855
Validation loss: 2.0506476894501717

Epoch: 5| Step: 9
Training loss: 1.6033073663711548
Validation loss: 2.071673861113928

Epoch: 5| Step: 10
Training loss: 1.964030146598816
Validation loss: 2.0817337471951722

Epoch: 174| Step: 0
Training loss: 2.2305266857147217
Validation loss: 2.0947311514167377

Epoch: 5| Step: 1
Training loss: 2.171081066131592
Validation loss: 2.1053265371630268

Epoch: 5| Step: 2
Training loss: 2.1882152557373047
Validation loss: 2.1459161209803757

Epoch: 5| Step: 3
Training loss: 2.438023090362549
Validation loss: 2.1419054410790883

Epoch: 5| Step: 4
Training loss: 2.259176731109619
Validation loss: 2.127156014083534

Epoch: 5| Step: 5
Training loss: 1.946771264076233
Validation loss: 2.141410081617294

Epoch: 5| Step: 6
Training loss: 2.3332412242889404
Validation loss: 2.1087771641310824

Epoch: 5| Step: 7
Training loss: 2.1806228160858154
Validation loss: 2.098086449407762

Epoch: 5| Step: 8
Training loss: 1.9134910106658936
Validation loss: 2.1020515939240814

Epoch: 5| Step: 9
Training loss: 1.5729877948760986
Validation loss: 2.0806127594363306

Epoch: 5| Step: 10
Training loss: 1.6143056154251099
Validation loss: 2.0803657936793503

Epoch: 175| Step: 0
Training loss: 2.3187549114227295
Validation loss: 2.076487038725166

Epoch: 5| Step: 1
Training loss: 2.0472187995910645
Validation loss: 2.075906370275764

Epoch: 5| Step: 2
Training loss: 1.663582444190979
Validation loss: 2.0660084101461593

Epoch: 5| Step: 3
Training loss: 1.6313400268554688
Validation loss: 2.0670872554984143

Epoch: 5| Step: 4
Training loss: 2.234588384628296
Validation loss: 2.0667278305176766

Epoch: 5| Step: 5
Training loss: 2.4385266304016113
Validation loss: 2.076886905136929

Epoch: 5| Step: 6
Training loss: 1.689143419265747
Validation loss: 2.080858879191901

Epoch: 5| Step: 7
Training loss: 2.412611484527588
Validation loss: 2.0833678168635212

Epoch: 5| Step: 8
Training loss: 1.823468565940857
Validation loss: 2.064221961523897

Epoch: 5| Step: 9
Training loss: 2.5459988117218018
Validation loss: 2.0646877622091644

Epoch: 5| Step: 10
Training loss: 2.08746600151062
Validation loss: 2.0524982636974705

Epoch: 176| Step: 0
Training loss: 1.8603813648223877
Validation loss: 2.065502069329703

Epoch: 5| Step: 1
Training loss: 1.6888974905014038
Validation loss: 2.0540794403322282

Epoch: 5| Step: 2
Training loss: 2.106255054473877
Validation loss: 2.067428893940423

Epoch: 5| Step: 3
Training loss: 1.6429275274276733
Validation loss: 2.0672683677365704

Epoch: 5| Step: 4
Training loss: 2.1835479736328125
Validation loss: 2.107115376380182

Epoch: 5| Step: 5
Training loss: 1.564636468887329
Validation loss: 2.1054753706019413

Epoch: 5| Step: 6
Training loss: 1.8443673849105835
Validation loss: 2.0946609050996843

Epoch: 5| Step: 7
Training loss: 2.768507957458496
Validation loss: 2.0634914341793267

Epoch: 5| Step: 8
Training loss: 2.0013389587402344
Validation loss: 2.046941393165178

Epoch: 5| Step: 9
Training loss: 3.004410743713379
Validation loss: 2.0638086026714695

Epoch: 5| Step: 10
Training loss: 2.2779905796051025
Validation loss: 2.0580820729655604

Epoch: 177| Step: 0
Training loss: 2.075984477996826
Validation loss: 2.068298496225829

Epoch: 5| Step: 1
Training loss: 2.5402016639709473
Validation loss: 2.0518430894420994

Epoch: 5| Step: 2
Training loss: 1.5042808055877686
Validation loss: 2.044311641364969

Epoch: 5| Step: 3
Training loss: 2.219958543777466
Validation loss: 2.039400041744273

Epoch: 5| Step: 4
Training loss: 1.97967529296875
Validation loss: 2.031629193213678

Epoch: 5| Step: 5
Training loss: 2.1245930194854736
Validation loss: 2.04103607772499

Epoch: 5| Step: 6
Training loss: 1.6379616260528564
Validation loss: 2.068156965317265

Epoch: 5| Step: 7
Training loss: 2.702509880065918
Validation loss: 2.1066008844683246

Epoch: 5| Step: 8
Training loss: 1.898461937904358
Validation loss: 2.104555847824261

Epoch: 5| Step: 9
Training loss: 2.138990640640259
Validation loss: 2.1017498841849704

Epoch: 5| Step: 10
Training loss: 1.9324628114700317
Validation loss: 2.0982886745083715

Epoch: 178| Step: 0
Training loss: 1.9751272201538086
Validation loss: 2.079046928754417

Epoch: 5| Step: 1
Training loss: 2.186530590057373
Validation loss: 2.0617712313129055

Epoch: 5| Step: 2
Training loss: 1.9727890491485596
Validation loss: 2.068110783894857

Epoch: 5| Step: 3
Training loss: 2.093698263168335
Validation loss: 2.0700019123733684

Epoch: 5| Step: 4
Training loss: 1.8028484582901
Validation loss: 2.055825646205615

Epoch: 5| Step: 5
Training loss: 2.052063465118408
Validation loss: 2.0711894060975764

Epoch: 5| Step: 6
Training loss: 2.466076374053955
Validation loss: 2.073367570036201

Epoch: 5| Step: 7
Training loss: 2.073517084121704
Validation loss: 2.0984958102626186

Epoch: 5| Step: 8
Training loss: 1.7046175003051758
Validation loss: 2.1356589640340498

Epoch: 5| Step: 9
Training loss: 1.9038736820220947
Validation loss: 2.1487265209997854

Epoch: 5| Step: 10
Training loss: 2.4907143115997314
Validation loss: 2.172791624581942

Epoch: 179| Step: 0
Training loss: 2.416088104248047
Validation loss: 2.1547223009088987

Epoch: 5| Step: 1
Training loss: 2.0484650135040283
Validation loss: 2.124353144758491

Epoch: 5| Step: 2
Training loss: 1.8034957647323608
Validation loss: 2.091686451306907

Epoch: 5| Step: 3
Training loss: 2.313093662261963
Validation loss: 2.068334343612835

Epoch: 5| Step: 4
Training loss: 1.8442341089248657
Validation loss: 2.0566818739778254

Epoch: 5| Step: 5
Training loss: 1.7943122386932373
Validation loss: 2.0691903560392317

Epoch: 5| Step: 6
Training loss: 2.1376519203186035
Validation loss: 2.0555656712542296

Epoch: 5| Step: 7
Training loss: 2.3224093914031982
Validation loss: 2.0629302493987547

Epoch: 5| Step: 8
Training loss: 2.1045823097229004
Validation loss: 2.067195580851647

Epoch: 5| Step: 9
Training loss: 1.763282060623169
Validation loss: 2.0990790449162966

Epoch: 5| Step: 10
Training loss: 2.0784337520599365
Validation loss: 2.1047231869031022

Epoch: 180| Step: 0
Training loss: 1.914564847946167
Validation loss: 2.097332941588535

Epoch: 5| Step: 1
Training loss: 1.7596575021743774
Validation loss: 2.0886959439964703

Epoch: 5| Step: 2
Training loss: 1.5978156328201294
Validation loss: 2.110516021328588

Epoch: 5| Step: 3
Training loss: 2.087928295135498
Validation loss: 2.0843197068860455

Epoch: 5| Step: 4
Training loss: 2.6849026679992676
Validation loss: 2.08234501910466

Epoch: 5| Step: 5
Training loss: 1.7410730123519897
Validation loss: 2.080181242317282

Epoch: 5| Step: 6
Training loss: 2.0234086513519287
Validation loss: 2.080102059148973

Epoch: 5| Step: 7
Training loss: 1.9626452922821045
Validation loss: 2.090698219114734

Epoch: 5| Step: 8
Training loss: 1.6963207721710205
Validation loss: 2.0754271322681057

Epoch: 5| Step: 9
Training loss: 2.4619030952453613
Validation loss: 2.086166566418063

Epoch: 5| Step: 10
Training loss: 2.1096458435058594
Validation loss: 2.0777710304465344

Epoch: 181| Step: 0
Training loss: 2.3131394386291504
Validation loss: 2.0839521346553678

Epoch: 5| Step: 1
Training loss: 1.6006180047988892
Validation loss: 2.080191432788808

Epoch: 5| Step: 2
Training loss: 1.7411737442016602
Validation loss: 2.0890725363967237

Epoch: 5| Step: 3
Training loss: 2.087725877761841
Validation loss: 2.0998063266918225

Epoch: 5| Step: 4
Training loss: 2.2347524166107178
Validation loss: 2.0989577052413777

Epoch: 5| Step: 5
Training loss: 1.8240928649902344
Validation loss: 2.1056000724915536

Epoch: 5| Step: 6
Training loss: 1.7579587697982788
Validation loss: 2.0887815875391804

Epoch: 5| Step: 7
Training loss: 2.2538061141967773
Validation loss: 2.0774260182534494

Epoch: 5| Step: 8
Training loss: 2.0424370765686035
Validation loss: 2.0587112749776533

Epoch: 5| Step: 9
Training loss: 2.053154706954956
Validation loss: 2.054852206219909

Epoch: 5| Step: 10
Training loss: 2.1692118644714355
Validation loss: 2.071926510462197

Epoch: 182| Step: 0
Training loss: 1.4645521640777588
Validation loss: 2.103870686664376

Epoch: 5| Step: 1
Training loss: 1.882185697555542
Validation loss: 2.1040810513240036

Epoch: 5| Step: 2
Training loss: 2.512256622314453
Validation loss: 2.120299618731263

Epoch: 5| Step: 3
Training loss: 2.7059149742126465
Validation loss: 2.1011073999507452

Epoch: 5| Step: 4
Training loss: 2.358635663986206
Validation loss: 2.0585060632357033

Epoch: 5| Step: 5
Training loss: 1.2221511602401733
Validation loss: 2.0316752464540544

Epoch: 5| Step: 6
Training loss: 2.21944260597229
Validation loss: 2.0285133777126187

Epoch: 5| Step: 7
Training loss: 2.2855327129364014
Validation loss: 2.031210596843432

Epoch: 5| Step: 8
Training loss: 1.7167730331420898
Validation loss: 2.0481392004156627

Epoch: 5| Step: 9
Training loss: 1.8368504047393799
Validation loss: 2.0693207992020475

Epoch: 5| Step: 10
Training loss: 2.148592948913574
Validation loss: 2.0455093435061875

Epoch: 183| Step: 0
Training loss: 1.371812105178833
Validation loss: 2.080670464423395

Epoch: 5| Step: 1
Training loss: 2.4489026069641113
Validation loss: 2.0941171466663318

Epoch: 5| Step: 2
Training loss: 2.395007371902466
Validation loss: 2.1075201214000745

Epoch: 5| Step: 3
Training loss: 2.4740073680877686
Validation loss: 2.113006055995982

Epoch: 5| Step: 4
Training loss: 2.370102643966675
Validation loss: 2.0872790813446045

Epoch: 5| Step: 5
Training loss: 2.0370311737060547
Validation loss: 2.0529504091508928

Epoch: 5| Step: 6
Training loss: 1.7368396520614624
Validation loss: 2.0565736319429133

Epoch: 5| Step: 7
Training loss: 1.4453389644622803
Validation loss: 2.032339721597651

Epoch: 5| Step: 8
Training loss: 1.8282276391983032
Validation loss: 2.041940786505258

Epoch: 5| Step: 9
Training loss: 2.213442802429199
Validation loss: 2.060104173998679

Epoch: 5| Step: 10
Training loss: 1.6008520126342773
Validation loss: 2.067954747907577

Epoch: 184| Step: 0
Training loss: 1.56934654712677
Validation loss: 2.0893170910496868

Epoch: 5| Step: 1
Training loss: 1.9909427165985107
Validation loss: 2.1110167503356934

Epoch: 5| Step: 2
Training loss: 3.180600643157959
Validation loss: 2.1280175921737507

Epoch: 5| Step: 3
Training loss: 1.396504521369934
Validation loss: 2.141513201498216

Epoch: 5| Step: 4
Training loss: 1.7367846965789795
Validation loss: 2.1375888239952827

Epoch: 5| Step: 5
Training loss: 2.2784218788146973
Validation loss: 2.1399991127752487

Epoch: 5| Step: 6
Training loss: 2.316706657409668
Validation loss: 2.1316370784595446

Epoch: 5| Step: 7
Training loss: 1.4668865203857422
Validation loss: 2.1040515104929605

Epoch: 5| Step: 8
Training loss: 1.9447124004364014
Validation loss: 2.0796943313332013

Epoch: 5| Step: 9
Training loss: 2.1219563484191895
Validation loss: 2.0575490177318616

Epoch: 5| Step: 10
Training loss: 1.9835635423660278
Validation loss: 2.0653522642709876

Epoch: 185| Step: 0
Training loss: 1.811187744140625
Validation loss: 2.0495088690070697

Epoch: 5| Step: 1
Training loss: 2.557025909423828
Validation loss: 2.05451657695155

Epoch: 5| Step: 2
Training loss: 1.2806529998779297
Validation loss: 2.0501587313990437

Epoch: 5| Step: 3
Training loss: 2.3683135509490967
Validation loss: 2.055192821769304

Epoch: 5| Step: 4
Training loss: 2.0017828941345215
Validation loss: 2.09227164073657

Epoch: 5| Step: 5
Training loss: 2.0157887935638428
Validation loss: 2.093454509653071

Epoch: 5| Step: 6
Training loss: 1.9267383813858032
Validation loss: 2.0982487496509346

Epoch: 5| Step: 7
Training loss: 1.6006358861923218
Validation loss: 2.091314446541571

Epoch: 5| Step: 8
Training loss: 1.948550820350647
Validation loss: 2.0740651263985583

Epoch: 5| Step: 9
Training loss: 1.9660263061523438
Validation loss: 2.080278609388618

Epoch: 5| Step: 10
Training loss: 2.276263475418091
Validation loss: 2.0707256678612

Epoch: 186| Step: 0
Training loss: 1.791491150856018
Validation loss: 2.038683875914543

Epoch: 5| Step: 1
Training loss: 2.1422696113586426
Validation loss: 2.039990496891801

Epoch: 5| Step: 2
Training loss: 1.5254857540130615
Validation loss: 2.0376673603570588

Epoch: 5| Step: 3
Training loss: 2.2999892234802246
Validation loss: 2.0335329194222727

Epoch: 5| Step: 4
Training loss: 1.6277074813842773
Validation loss: 2.0319705022278653

Epoch: 5| Step: 5
Training loss: 2.3279519081115723
Validation loss: 2.035837527244322

Epoch: 5| Step: 6
Training loss: 2.074535608291626
Validation loss: 2.0271018102604854

Epoch: 5| Step: 7
Training loss: 2.0665791034698486
Validation loss: 2.035298475655176

Epoch: 5| Step: 8
Training loss: 1.9457228183746338
Validation loss: 2.0225691897894746

Epoch: 5| Step: 9
Training loss: 2.132375955581665
Validation loss: 2.044097214616755

Epoch: 5| Step: 10
Training loss: 1.6442052125930786
Validation loss: 2.049295102396319

Epoch: 187| Step: 0
Training loss: 1.8527265787124634
Validation loss: 2.0374311157452163

Epoch: 5| Step: 1
Training loss: 0.921617865562439
Validation loss: 2.0348174597627375

Epoch: 5| Step: 2
Training loss: 1.7529720067977905
Validation loss: 2.062330466444774

Epoch: 5| Step: 3
Training loss: 1.9436225891113281
Validation loss: 2.0808762042753157

Epoch: 5| Step: 4
Training loss: 2.6317522525787354
Validation loss: 2.0879417478397326

Epoch: 5| Step: 5
Training loss: 1.3464616537094116
Validation loss: 2.086112339009521

Epoch: 5| Step: 6
Training loss: 2.4499783515930176
Validation loss: 2.086551002276841

Epoch: 5| Step: 7
Training loss: 1.8633493185043335
Validation loss: 2.083222581494239

Epoch: 5| Step: 8
Training loss: 2.6261179447174072
Validation loss: 2.076031739993762

Epoch: 5| Step: 9
Training loss: 1.4596697092056274
Validation loss: 2.0917310291720974

Epoch: 5| Step: 10
Training loss: 2.5896806716918945
Validation loss: 2.0954635950826828

Epoch: 188| Step: 0
Training loss: 1.7213337421417236
Validation loss: 2.0985300105105162

Epoch: 5| Step: 1
Training loss: 2.250744342803955
Validation loss: 2.069764337232036

Epoch: 5| Step: 2
Training loss: 1.3634259700775146
Validation loss: 2.0684818708768455

Epoch: 5| Step: 3
Training loss: 2.302298069000244
Validation loss: 2.063193759610576

Epoch: 5| Step: 4
Training loss: 2.0689244270324707
Validation loss: 2.0513398108943814

Epoch: 5| Step: 5
Training loss: 1.891097068786621
Validation loss: 2.058940024786098

Epoch: 5| Step: 6
Training loss: 1.9269158840179443
Validation loss: 2.0374131125788533

Epoch: 5| Step: 7
Training loss: 2.6077558994293213
Validation loss: 2.024538618262096

Epoch: 5| Step: 8
Training loss: 1.6389961242675781
Validation loss: 2.0499855318377094

Epoch: 5| Step: 9
Training loss: 1.6328293085098267
Validation loss: 2.044546647738385

Epoch: 5| Step: 10
Training loss: 1.9141340255737305
Validation loss: 2.0440354988139164

Epoch: 189| Step: 0
Training loss: 2.045170783996582
Validation loss: 2.025689514734412

Epoch: 5| Step: 1
Training loss: 2.046792507171631
Validation loss: 2.0085747126610047

Epoch: 5| Step: 2
Training loss: 1.3901526927947998
Validation loss: 2.020384698785761

Epoch: 5| Step: 3
Training loss: 2.436833143234253
Validation loss: 2.037324966922883

Epoch: 5| Step: 4
Training loss: 1.7747825384140015
Validation loss: 2.049088394770058

Epoch: 5| Step: 5
Training loss: 2.2191362380981445
Validation loss: 2.0379130763392292

Epoch: 5| Step: 6
Training loss: 2.116647720336914
Validation loss: 2.0223732225356565

Epoch: 5| Step: 7
Training loss: 1.5700182914733887
Validation loss: 2.02417512606549

Epoch: 5| Step: 8
Training loss: 1.4270906448364258
Validation loss: 2.0224926394800984

Epoch: 5| Step: 9
Training loss: 2.519793748855591
Validation loss: 2.0172114154343963

Epoch: 5| Step: 10
Training loss: 1.325725793838501
Validation loss: 2.040560004531696

Epoch: 190| Step: 0
Training loss: 1.9394553899765015
Validation loss: 2.055787670996881

Epoch: 5| Step: 1
Training loss: 2.21203875541687
Validation loss: 2.0817502198680753

Epoch: 5| Step: 2
Training loss: 1.7953779697418213
Validation loss: 2.0889431481720298

Epoch: 5| Step: 3
Training loss: 2.526137113571167
Validation loss: 2.112557731648927

Epoch: 5| Step: 4
Training loss: 1.5378705263137817
Validation loss: 2.107654220314436

Epoch: 5| Step: 5
Training loss: 2.7745842933654785
Validation loss: 2.104085465913178

Epoch: 5| Step: 6
Training loss: 1.8858247995376587
Validation loss: 2.1011666867040817

Epoch: 5| Step: 7
Training loss: 1.3644609451293945
Validation loss: 2.1018475012112687

Epoch: 5| Step: 8
Training loss: 1.6352462768554688
Validation loss: 2.113501371875886

Epoch: 5| Step: 9
Training loss: 1.7070043087005615
Validation loss: 2.0951012360152377

Epoch: 5| Step: 10
Training loss: 1.5183671712875366
Validation loss: 2.068117627533533

Epoch: 191| Step: 0
Training loss: 1.5498775243759155
Validation loss: 2.0673915519509265

Epoch: 5| Step: 1
Training loss: 1.9031620025634766
Validation loss: 2.022186510024532

Epoch: 5| Step: 2
Training loss: 1.851676344871521
Validation loss: 2.0361820779820925

Epoch: 5| Step: 3
Training loss: 1.7660942077636719
Validation loss: 2.0461049067076815

Epoch: 5| Step: 4
Training loss: 1.8422530889511108
Validation loss: 2.0373513237122567

Epoch: 5| Step: 5
Training loss: 2.450432538986206
Validation loss: 2.036852272607947

Epoch: 5| Step: 6
Training loss: 2.3140954971313477
Validation loss: 2.038266183227621

Epoch: 5| Step: 7
Training loss: 1.7463762760162354
Validation loss: 2.0634965460787535

Epoch: 5| Step: 8
Training loss: 2.1494414806365967
Validation loss: 2.0529973891473587

Epoch: 5| Step: 9
Training loss: 2.1678314208984375
Validation loss: 2.013748394545688

Epoch: 5| Step: 10
Training loss: 1.5770649909973145
Validation loss: 2.0106129800119708

Epoch: 192| Step: 0
Training loss: 1.2743251323699951
Validation loss: 2.027532386523421

Epoch: 5| Step: 1
Training loss: 2.1448569297790527
Validation loss: 2.048448661322235

Epoch: 5| Step: 2
Training loss: 1.8377710580825806
Validation loss: 2.0803376333687895

Epoch: 5| Step: 3
Training loss: 1.9398670196533203
Validation loss: 2.085656504477224

Epoch: 5| Step: 4
Training loss: 1.835720419883728
Validation loss: 2.0983495712280273

Epoch: 5| Step: 5
Training loss: 1.5407932996749878
Validation loss: 2.0826138052889096

Epoch: 5| Step: 6
Training loss: 1.5768630504608154
Validation loss: 2.0908802286271126

Epoch: 5| Step: 7
Training loss: 2.8906664848327637
Validation loss: 2.089908625489922

Epoch: 5| Step: 8
Training loss: 1.7958892583847046
Validation loss: 2.0729481533009517

Epoch: 5| Step: 9
Training loss: 1.456402063369751
Validation loss: 2.103194426464778

Epoch: 5| Step: 10
Training loss: 3.0699031352996826
Validation loss: 2.0980540090991604

Epoch: 193| Step: 0
Training loss: 1.886331558227539
Validation loss: 2.0619428080897175

Epoch: 5| Step: 1
Training loss: 1.6339504718780518
Validation loss: 2.0235030907456593

Epoch: 5| Step: 2
Training loss: 1.5295841693878174
Validation loss: 2.026013584547145

Epoch: 5| Step: 3
Training loss: 1.7501485347747803
Validation loss: 2.022180376514312

Epoch: 5| Step: 4
Training loss: 1.6737428903579712
Validation loss: 2.0316520993427565

Epoch: 5| Step: 5
Training loss: 2.1985297203063965
Validation loss: 2.0690552598686627

Epoch: 5| Step: 6
Training loss: 2.2446892261505127
Validation loss: 2.071519943975633

Epoch: 5| Step: 7
Training loss: 2.278289318084717
Validation loss: 2.0971008411017795

Epoch: 5| Step: 8
Training loss: 1.876185417175293
Validation loss: 2.1116948025200957

Epoch: 5| Step: 9
Training loss: 2.215681552886963
Validation loss: 2.0904623898126746

Epoch: 5| Step: 10
Training loss: 1.608858346939087
Validation loss: 2.051284010692309

Epoch: 194| Step: 0
Training loss: 1.8909631967544556
Validation loss: 2.028746515192011

Epoch: 5| Step: 1
Training loss: 2.056826591491699
Validation loss: 2.0270606856192313

Epoch: 5| Step: 2
Training loss: 1.9680687189102173
Validation loss: 2.0316097813267864

Epoch: 5| Step: 3
Training loss: 1.9370386600494385
Validation loss: 2.044219801502843

Epoch: 5| Step: 4
Training loss: 2.1498780250549316
Validation loss: 2.0478862165122904

Epoch: 5| Step: 5
Training loss: 1.56619131565094
Validation loss: 2.06632032445682

Epoch: 5| Step: 6
Training loss: 1.8766807317733765
Validation loss: 2.135803202147125

Epoch: 5| Step: 7
Training loss: 2.3820252418518066
Validation loss: 2.160562579349805

Epoch: 5| Step: 8
Training loss: 2.1691935062408447
Validation loss: 2.0985277673249603

Epoch: 5| Step: 9
Training loss: 1.3836898803710938
Validation loss: 2.030566928207233

Epoch: 5| Step: 10
Training loss: 1.748188853263855
Validation loss: 2.0186885569685247

Epoch: 195| Step: 0
Training loss: 2.2440524101257324
Validation loss: 2.0030033511500203

Epoch: 5| Step: 1
Training loss: 2.095881700515747
Validation loss: 2.014644749702946

Epoch: 5| Step: 2
Training loss: 1.8457729816436768
Validation loss: 1.990672339675247

Epoch: 5| Step: 3
Training loss: 1.6256096363067627
Validation loss: 1.9906183417125414

Epoch: 5| Step: 4
Training loss: 1.8579304218292236
Validation loss: 1.9830127685300765

Epoch: 5| Step: 5
Training loss: 1.7721201181411743
Validation loss: 2.001722446051977

Epoch: 5| Step: 6
Training loss: 2.4058327674865723
Validation loss: 2.0495826275117937

Epoch: 5| Step: 7
Training loss: 1.2249493598937988
Validation loss: 2.1231667457088346

Epoch: 5| Step: 8
Training loss: 1.9017858505249023
Validation loss: 2.1736511338141655

Epoch: 5| Step: 9
Training loss: 1.831830620765686
Validation loss: 2.205918674827904

Epoch: 5| Step: 10
Training loss: 2.017838478088379
Validation loss: 2.1662573993846936

Epoch: 196| Step: 0
Training loss: 1.420396089553833
Validation loss: 2.0962432456272904

Epoch: 5| Step: 1
Training loss: 1.638352394104004
Validation loss: 2.0745559712891937

Epoch: 5| Step: 2
Training loss: 2.606046438217163
Validation loss: 2.0776505290821032

Epoch: 5| Step: 3
Training loss: 1.9868860244750977
Validation loss: 2.1343831631445114

Epoch: 5| Step: 4
Training loss: 1.921419382095337
Validation loss: 2.1362159175257527

Epoch: 5| Step: 5
Training loss: 1.8651634454727173
Validation loss: 2.1188845890824513

Epoch: 5| Step: 6
Training loss: 2.108032464981079
Validation loss: 2.0758338961549985

Epoch: 5| Step: 7
Training loss: 1.7416627407073975
Validation loss: 2.0217234037255727

Epoch: 5| Step: 8
Training loss: 1.8906923532485962
Validation loss: 2.019989400781611

Epoch: 5| Step: 9
Training loss: 2.177398204803467
Validation loss: 2.124301107980872

Epoch: 5| Step: 10
Training loss: 2.180838108062744
Validation loss: 2.2341915176760767

Epoch: 197| Step: 0
Training loss: 2.0211169719696045
Validation loss: 2.2565766508861254

Epoch: 5| Step: 1
Training loss: 2.001960277557373
Validation loss: 2.2380782711890435

Epoch: 5| Step: 2
Training loss: 1.7896945476531982
Validation loss: 2.127111939973729

Epoch: 5| Step: 3
Training loss: 2.0869393348693848
Validation loss: 2.03549591700236

Epoch: 5| Step: 4
Training loss: 1.7057688236236572
Validation loss: 1.996383265782428

Epoch: 5| Step: 5
Training loss: 2.1952526569366455
Validation loss: 1.983580340621292

Epoch: 5| Step: 6
Training loss: 1.6624372005462646
Validation loss: 2.0210139700161514

Epoch: 5| Step: 7
Training loss: 2.012268543243408
Validation loss: 2.0582838237926526

Epoch: 5| Step: 8
Training loss: 2.5591282844543457
Validation loss: 2.0339059739984493

Epoch: 5| Step: 9
Training loss: 2.0378425121307373
Validation loss: 2.001000718403888

Epoch: 5| Step: 10
Training loss: 1.78922700881958
Validation loss: 2.0083571351984495

Epoch: 198| Step: 0
Training loss: 1.9826949834823608
Validation loss: 2.0380168166211856

Epoch: 5| Step: 1
Training loss: 2.325317859649658
Validation loss: 2.080588104904339

Epoch: 5| Step: 2
Training loss: 1.8724701404571533
Validation loss: 2.1163249451627015

Epoch: 5| Step: 3
Training loss: 2.0850257873535156
Validation loss: 2.128040941812659

Epoch: 5| Step: 4
Training loss: 1.942786455154419
Validation loss: 2.1142809250021495

Epoch: 5| Step: 5
Training loss: 1.6679531335830688
Validation loss: 2.083392773905108

Epoch: 5| Step: 6
Training loss: 2.0885462760925293
Validation loss: 2.0566010282885645

Epoch: 5| Step: 7
Training loss: 2.458143711090088
Validation loss: 2.013639937164963

Epoch: 5| Step: 8
Training loss: 1.3043880462646484
Validation loss: 2.0079888951393867

Epoch: 5| Step: 9
Training loss: 1.669076681137085
Validation loss: 2.016008464238977

Epoch: 5| Step: 10
Training loss: 1.0893810987472534
Validation loss: 2.030502588518204

Epoch: 199| Step: 0
Training loss: 1.962039589881897
Validation loss: 2.0234867013910764

Epoch: 5| Step: 1
Training loss: 2.1166789531707764
Validation loss: 2.037495018333517

Epoch: 5| Step: 2
Training loss: 1.2631256580352783
Validation loss: 2.0445760309055285

Epoch: 5| Step: 3
Training loss: 2.049715995788574
Validation loss: 2.040253000874673

Epoch: 5| Step: 4
Training loss: 1.6791365146636963
Validation loss: 2.031940487123305

Epoch: 5| Step: 5
Training loss: 1.9381297826766968
Validation loss: 2.0500297008022184

Epoch: 5| Step: 6
Training loss: 1.5058900117874146
Validation loss: 2.056123169519568

Epoch: 5| Step: 7
Training loss: 2.2033069133758545
Validation loss: 2.0610806377985145

Epoch: 5| Step: 8
Training loss: 1.9036080837249756
Validation loss: 2.061694460530435

Epoch: 5| Step: 9
Training loss: 1.6316540241241455
Validation loss: 2.066719913995394

Epoch: 5| Step: 10
Training loss: 1.6837780475616455
Validation loss: 2.0965209084172405

Epoch: 200| Step: 0
Training loss: 2.069859027862549
Validation loss: 2.0862682019510577

Epoch: 5| Step: 1
Training loss: 1.3943332433700562
Validation loss: 2.107335347001271

Epoch: 5| Step: 2
Training loss: 2.1781718730926514
Validation loss: 2.1193950060875184

Epoch: 5| Step: 3
Training loss: 1.6023695468902588
Validation loss: 2.12757513600011

Epoch: 5| Step: 4
Training loss: 1.6829540729522705
Validation loss: 2.1009121966618363

Epoch: 5| Step: 5
Training loss: 1.882694959640503
Validation loss: 2.083481106706845

Epoch: 5| Step: 6
Training loss: 1.9191783666610718
Validation loss: 2.046534933069701

Epoch: 5| Step: 7
Training loss: 1.995032548904419
Validation loss: 2.034318070257864

Epoch: 5| Step: 8
Training loss: 1.4887937307357788
Validation loss: 2.013616887472009

Epoch: 5| Step: 9
Training loss: 2.0817999839782715
Validation loss: 2.0097822784095682

Epoch: 5| Step: 10
Training loss: 1.9218177795410156
Validation loss: 2.008206840484373

Epoch: 201| Step: 0
Training loss: 2.2259063720703125
Validation loss: 2.004929100313494

Epoch: 5| Step: 1
Training loss: 1.7370964288711548
Validation loss: 2.0113692975813344

Epoch: 5| Step: 2
Training loss: 1.5082085132598877
Validation loss: 2.026448793308709

Epoch: 5| Step: 3
Training loss: 1.3436996936798096
Validation loss: 2.036090403474787

Epoch: 5| Step: 4
Training loss: 1.5874741077423096
Validation loss: 2.0524728567369523

Epoch: 5| Step: 5
Training loss: 1.4023075103759766
Validation loss: 2.039077374242967

Epoch: 5| Step: 6
Training loss: 1.639674186706543
Validation loss: 2.028292671326668

Epoch: 5| Step: 7
Training loss: 2.0626513957977295
Validation loss: 2.041315286390243

Epoch: 5| Step: 8
Training loss: 1.9639289379119873
Validation loss: 2.0355733453586535

Epoch: 5| Step: 9
Training loss: 2.236361265182495
Validation loss: 2.0523132842074157

Epoch: 5| Step: 10
Training loss: 2.130744695663452
Validation loss: 2.064982210436175

Epoch: 202| Step: 0
Training loss: 1.8407245874404907
Validation loss: 2.062861220811003

Epoch: 5| Step: 1
Training loss: 1.5128432512283325
Validation loss: 2.0789512331767748

Epoch: 5| Step: 2
Training loss: 1.8423373699188232
Validation loss: 2.0553586867547806

Epoch: 5| Step: 3
Training loss: 2.560145139694214
Validation loss: 2.0437051403907036

Epoch: 5| Step: 4
Training loss: 1.7149183750152588
Validation loss: 2.0317639881564724

Epoch: 5| Step: 5
Training loss: 1.7017936706542969
Validation loss: 2.0476884354827223

Epoch: 5| Step: 6
Training loss: 1.738096833229065
Validation loss: 2.0491901546396236

Epoch: 5| Step: 7
Training loss: 1.9563690423965454
Validation loss: 2.0557925419140886

Epoch: 5| Step: 8
Training loss: 1.3765703439712524
Validation loss: 2.0563850043922343

Epoch: 5| Step: 9
Training loss: 1.743721604347229
Validation loss: 2.0613176873935166

Epoch: 5| Step: 10
Training loss: 1.7567464113235474
Validation loss: 2.0577664990578928

Epoch: 203| Step: 0
Training loss: 1.3220221996307373
Validation loss: 2.0492586499901226

Epoch: 5| Step: 1
Training loss: 1.8123899698257446
Validation loss: 2.06903495839847

Epoch: 5| Step: 2
Training loss: 1.5821181535720825
Validation loss: 2.0915721847165014

Epoch: 5| Step: 3
Training loss: 2.161282777786255
Validation loss: 2.0633466679562806

Epoch: 5| Step: 4
Training loss: 2.029933452606201
Validation loss: 2.06697202497913

Epoch: 5| Step: 5
Training loss: 2.0560970306396484
Validation loss: 2.0132284625884025

Epoch: 5| Step: 6
Training loss: 1.909629464149475
Validation loss: 2.0317244709178968

Epoch: 5| Step: 7
Training loss: 1.5010085105895996
Validation loss: 2.0165431909663702

Epoch: 5| Step: 8
Training loss: 1.1918516159057617
Validation loss: 2.0093643152585594

Epoch: 5| Step: 9
Training loss: 2.210801839828491
Validation loss: 2.0120212544677076

Epoch: 5| Step: 10
Training loss: 1.773184061050415
Validation loss: 2.013451745433192

Epoch: 204| Step: 0
Training loss: 2.2177116870880127
Validation loss: 2.0064718505387664

Epoch: 5| Step: 1
Training loss: 1.376689076423645
Validation loss: 2.02956885163502

Epoch: 5| Step: 2
Training loss: 1.081762433052063
Validation loss: 2.01973980985662

Epoch: 5| Step: 3
Training loss: 2.1432507038116455
Validation loss: 2.0460153138765724

Epoch: 5| Step: 4
Training loss: 1.9382365942001343
Validation loss: 2.0342090783580655

Epoch: 5| Step: 5
Training loss: 1.6714550256729126
Validation loss: 2.053586147164786

Epoch: 5| Step: 6
Training loss: 1.81649649143219
Validation loss: 2.077760870738696

Epoch: 5| Step: 7
Training loss: 1.6956226825714111
Validation loss: 2.0951579129824074

Epoch: 5| Step: 8
Training loss: 1.729036569595337
Validation loss: 2.0952131440562587

Epoch: 5| Step: 9
Training loss: 1.8351352214813232
Validation loss: 2.0910277725547872

Epoch: 5| Step: 10
Training loss: 1.8412151336669922
Validation loss: 2.0753350821874474

Epoch: 205| Step: 0
Training loss: 2.0598206520080566
Validation loss: 2.074213280472704

Epoch: 5| Step: 1
Training loss: 1.8334665298461914
Validation loss: 2.0569544351229103

Epoch: 5| Step: 2
Training loss: 1.5030072927474976
Validation loss: 2.0635795721443753

Epoch: 5| Step: 3
Training loss: 2.0889317989349365
Validation loss: 2.0692922184544225

Epoch: 5| Step: 4
Training loss: 2.0489907264709473
Validation loss: 2.037191257681898

Epoch: 5| Step: 5
Training loss: 1.7923614978790283
Validation loss: 2.04367858107372

Epoch: 5| Step: 6
Training loss: 2.1031413078308105
Validation loss: 2.0415965741680515

Epoch: 5| Step: 7
Training loss: 1.2838798761367798
Validation loss: 2.0469005236061673

Epoch: 5| Step: 8
Training loss: 1.3295568227767944
Validation loss: 2.072838209008658

Epoch: 5| Step: 9
Training loss: 2.049928903579712
Validation loss: 2.075504174796484

Epoch: 5| Step: 10
Training loss: 1.482092022895813
Validation loss: 2.077268062099334

Epoch: 206| Step: 0
Training loss: 2.188981294631958
Validation loss: 2.035770244495843

Epoch: 5| Step: 1
Training loss: 1.2505897283554077
Validation loss: 1.995110200297448

Epoch: 5| Step: 2
Training loss: 1.8570677042007446
Validation loss: 1.9764700615277855

Epoch: 5| Step: 3
Training loss: 1.5131123065948486
Validation loss: 1.9635340116357292

Epoch: 5| Step: 4
Training loss: 2.042760133743286
Validation loss: 1.9729078879920385

Epoch: 5| Step: 5
Training loss: 1.683941125869751
Validation loss: 1.9728860265465193

Epoch: 5| Step: 6
Training loss: 1.6095720529556274
Validation loss: 1.9907124683421145

Epoch: 5| Step: 7
Training loss: 1.3295762538909912
Validation loss: 2.002039691453339

Epoch: 5| Step: 8
Training loss: 1.7836120128631592
Validation loss: 2.0174994109779276

Epoch: 5| Step: 9
Training loss: 1.7788223028182983
Validation loss: 2.055534803739158

Epoch: 5| Step: 10
Training loss: 2.1306140422821045
Validation loss: 2.092800026298851

Epoch: 207| Step: 0
Training loss: 1.9607648849487305
Validation loss: 2.1161684246473413

Epoch: 5| Step: 1
Training loss: 2.3540351390838623
Validation loss: 2.1336845556894937

Epoch: 5| Step: 2
Training loss: 1.791317343711853
Validation loss: 2.162131837619248

Epoch: 5| Step: 3
Training loss: 2.0548412799835205
Validation loss: 2.1685820728219967

Epoch: 5| Step: 4
Training loss: 1.4801411628723145
Validation loss: 2.1536644094733783

Epoch: 5| Step: 5
Training loss: 2.2680916786193848
Validation loss: 2.123936471118722

Epoch: 5| Step: 6
Training loss: 2.3260574340820312
Validation loss: 2.079761697400001

Epoch: 5| Step: 7
Training loss: 1.3087915182113647
Validation loss: 2.0970491004246536

Epoch: 5| Step: 8
Training loss: 1.796592354774475
Validation loss: 2.0724417214752524

Epoch: 5| Step: 9
Training loss: 1.36246657371521
Validation loss: 1.993465514593227

Epoch: 5| Step: 10
Training loss: 1.2267966270446777
Validation loss: 1.9962809008936728

Epoch: 208| Step: 0
Training loss: 2.0884597301483154
Validation loss: 2.0500550500808226

Epoch: 5| Step: 1
Training loss: 1.7638466358184814
Validation loss: 2.0863401095072427

Epoch: 5| Step: 2
Training loss: 1.8508278131484985
Validation loss: 2.1071585865430933

Epoch: 5| Step: 3
Training loss: 2.034579038619995
Validation loss: 2.0880648653994323

Epoch: 5| Step: 4
Training loss: 1.5366052389144897
Validation loss: 2.032628074769051

Epoch: 5| Step: 5
Training loss: 2.1234655380249023
Validation loss: 1.9678885513736355

Epoch: 5| Step: 6
Training loss: 2.0297226905822754
Validation loss: 1.9377434163965204

Epoch: 5| Step: 7
Training loss: 1.3533083200454712
Validation loss: 1.9210470145748508

Epoch: 5| Step: 8
Training loss: 2.0231738090515137
Validation loss: 1.9446643142290012

Epoch: 5| Step: 9
Training loss: 1.7993495464324951
Validation loss: 1.9967689270614295

Epoch: 5| Step: 10
Training loss: 1.1122595071792603
Validation loss: 2.0147674442619405

Epoch: 209| Step: 0
Training loss: 2.400590419769287
Validation loss: 2.0428974987358175

Epoch: 5| Step: 1
Training loss: 1.6397335529327393
Validation loss: 2.0470689727414038

Epoch: 5| Step: 2
Training loss: 1.6846415996551514
Validation loss: 2.0859270685462543

Epoch: 5| Step: 3
Training loss: 1.9803386926651
Validation loss: 2.0830429292494252

Epoch: 5| Step: 4
Training loss: 1.7587560415267944
Validation loss: 2.0961076623650006

Epoch: 5| Step: 5
Training loss: 1.4387054443359375
Validation loss: 2.0639512744001163

Epoch: 5| Step: 6
Training loss: 1.7797229290008545
Validation loss: 2.073312126180177

Epoch: 5| Step: 7
Training loss: 1.7352771759033203
Validation loss: 2.067981130333357

Epoch: 5| Step: 8
Training loss: 1.6353399753570557
Validation loss: 2.035544228810136

Epoch: 5| Step: 9
Training loss: 1.7131677865982056
Validation loss: 2.0334814774092806

Epoch: 5| Step: 10
Training loss: 1.576872706413269
Validation loss: 2.0322119702575026

Epoch: 210| Step: 0
Training loss: 1.794249176979065
Validation loss: 2.038720033502066

Epoch: 5| Step: 1
Training loss: 2.501927614212036
Validation loss: 2.059579715933851

Epoch: 5| Step: 2
Training loss: 1.8791720867156982
Validation loss: 2.046106812774494

Epoch: 5| Step: 3
Training loss: 1.450659155845642
Validation loss: 2.06413669355454

Epoch: 5| Step: 4
Training loss: 1.9658416509628296
Validation loss: 2.070082859326434

Epoch: 5| Step: 5
Training loss: 1.4629576206207275
Validation loss: 2.065192012376683

Epoch: 5| Step: 6
Training loss: 1.4532026052474976
Validation loss: 2.0652019605841687

Epoch: 5| Step: 7
Training loss: 0.9545110464096069
Validation loss: 2.0612422458587156

Epoch: 5| Step: 8
Training loss: 1.7185580730438232
Validation loss: 2.0582778543554325

Epoch: 5| Step: 9
Training loss: 1.3853389024734497
Validation loss: 2.0675033805190877

Epoch: 5| Step: 10
Training loss: 2.3240697383880615
Validation loss: 2.0592950403049426

Epoch: 211| Step: 0
Training loss: 1.565154790878296
Validation loss: 2.0492417068891626

Epoch: 5| Step: 1
Training loss: 2.2275280952453613
Validation loss: 2.0446296468857796

Epoch: 5| Step: 2
Training loss: 1.9884727001190186
Validation loss: 2.0272228999804427

Epoch: 5| Step: 3
Training loss: 1.5678396224975586
Validation loss: 1.9985684348690895

Epoch: 5| Step: 4
Training loss: 1.9008973836898804
Validation loss: 2.0157125073094524

Epoch: 5| Step: 5
Training loss: 1.928156852722168
Validation loss: 2.007008200050682

Epoch: 5| Step: 6
Training loss: 2.0340394973754883
Validation loss: 1.993019985896285

Epoch: 5| Step: 7
Training loss: 1.4672924280166626
Validation loss: 1.9939071798837313

Epoch: 5| Step: 8
Training loss: 1.4547054767608643
Validation loss: 2.029709845460871

Epoch: 5| Step: 9
Training loss: 1.52457594871521
Validation loss: 2.0401993669489378

Epoch: 5| Step: 10
Training loss: 0.9415097236633301
Validation loss: 2.030075237315188

Epoch: 212| Step: 0
Training loss: 1.5926975011825562
Validation loss: 2.016149563174094

Epoch: 5| Step: 1
Training loss: 1.1914050579071045
Validation loss: 2.0364486812263407

Epoch: 5| Step: 2
Training loss: 1.9609229564666748
Validation loss: 2.0312359397129347

Epoch: 5| Step: 3
Training loss: 2.152128219604492
Validation loss: 2.0309549044537287

Epoch: 5| Step: 4
Training loss: 1.7171016931533813
Validation loss: 2.035923937315582

Epoch: 5| Step: 5
Training loss: 1.986189603805542
Validation loss: 2.0297669159468783

Epoch: 5| Step: 6
Training loss: 1.2876393795013428
Validation loss: 2.01789810580592

Epoch: 5| Step: 7
Training loss: 1.484379529953003
Validation loss: 2.028568419077063

Epoch: 5| Step: 8
Training loss: 1.9553741216659546
Validation loss: 2.004899199290942

Epoch: 5| Step: 9
Training loss: 1.3922407627105713
Validation loss: 1.997957347541727

Epoch: 5| Step: 10
Training loss: 1.7030845880508423
Validation loss: 1.9827065275561424

Epoch: 213| Step: 0
Training loss: 1.4748446941375732
Validation loss: 2.010303992097096

Epoch: 5| Step: 1
Training loss: 1.52712082862854
Validation loss: 2.0112876174270466

Epoch: 5| Step: 2
Training loss: 2.020491600036621
Validation loss: 2.0173953399863294

Epoch: 5| Step: 3
Training loss: 1.6697399616241455
Validation loss: 2.0144918605845463

Epoch: 5| Step: 4
Training loss: 1.620927095413208
Validation loss: 2.0171629164808538

Epoch: 5| Step: 5
Training loss: 1.214577078819275
Validation loss: 2.0310089844529347

Epoch: 5| Step: 6
Training loss: 1.488828420639038
Validation loss: 2.0449747347062632

Epoch: 5| Step: 7
Training loss: 1.72125244140625
Validation loss: 2.035701587635984

Epoch: 5| Step: 8
Training loss: 1.8759368658065796
Validation loss: 2.030751394969161

Epoch: 5| Step: 9
Training loss: 1.69394052028656
Validation loss: 2.0288451769018687

Epoch: 5| Step: 10
Training loss: 1.8121604919433594
Validation loss: 2.022250271612598

Epoch: 214| Step: 0
Training loss: 1.6083557605743408
Validation loss: 2.0377620420148297

Epoch: 5| Step: 1
Training loss: 1.9864698648452759
Validation loss: 2.0519039528344267

Epoch: 5| Step: 2
Training loss: 1.6337922811508179
Validation loss: 2.059206747239636

Epoch: 5| Step: 3
Training loss: 1.8824710845947266
Validation loss: 2.0660871472409976

Epoch: 5| Step: 4
Training loss: 1.8170578479766846
Validation loss: 2.0559291506326325

Epoch: 5| Step: 5
Training loss: 1.6557449102401733
Validation loss: 2.0457350143822293

Epoch: 5| Step: 6
Training loss: 1.131593108177185
Validation loss: 2.0614361224635953

Epoch: 5| Step: 7
Training loss: 1.33233642578125
Validation loss: 2.0405971901391142

Epoch: 5| Step: 8
Training loss: 2.0353782176971436
Validation loss: 2.060846273617078

Epoch: 5| Step: 9
Training loss: 1.6354210376739502
Validation loss: 2.01531578904839

Epoch: 5| Step: 10
Training loss: 1.321241021156311
Validation loss: 2.0308460727814706

Epoch: 215| Step: 0
Training loss: 1.4174991846084595
Validation loss: 2.0246084736239527

Epoch: 5| Step: 1
Training loss: 1.6051536798477173
Validation loss: 2.030159277300681

Epoch: 5| Step: 2
Training loss: 1.8151838779449463
Validation loss: 2.0063041461411344

Epoch: 5| Step: 3
Training loss: 1.2109038829803467
Validation loss: 2.038060006274972

Epoch: 5| Step: 4
Training loss: 1.3642053604125977
Validation loss: 2.036814684508949

Epoch: 5| Step: 5
Training loss: 1.476883053779602
Validation loss: 2.038042494045791

Epoch: 5| Step: 6
Training loss: 1.8931258916854858
Validation loss: 2.049146847058368

Epoch: 5| Step: 7
Training loss: 2.0956406593322754
Validation loss: 2.044294482918196

Epoch: 5| Step: 8
Training loss: 2.091887950897217
Validation loss: 2.0489654951198126

Epoch: 5| Step: 9
Training loss: 1.924176573753357
Validation loss: 2.021909047198552

Epoch: 5| Step: 10
Training loss: 1.1587529182434082
Validation loss: 1.9972476010681481

Epoch: 216| Step: 0
Training loss: 1.8098366260528564
Validation loss: 1.9834923039200485

Epoch: 5| Step: 1
Training loss: 1.8403260707855225
Validation loss: 1.993338748972903

Epoch: 5| Step: 2
Training loss: 1.2238774299621582
Validation loss: 1.9835142115110993

Epoch: 5| Step: 3
Training loss: 1.772925615310669
Validation loss: 1.9772970702058525

Epoch: 5| Step: 4
Training loss: 1.7318973541259766
Validation loss: 1.9795144924553492

Epoch: 5| Step: 5
Training loss: 1.7877724170684814
Validation loss: 1.9708255234585013

Epoch: 5| Step: 6
Training loss: 1.2914823293685913
Validation loss: 1.9742673263754895

Epoch: 5| Step: 7
Training loss: 1.4280885457992554
Validation loss: 2.0006050896900955

Epoch: 5| Step: 8
Training loss: 1.7989046573638916
Validation loss: 2.0037062091212117

Epoch: 5| Step: 9
Training loss: 1.8825031518936157
Validation loss: 2.023519016081287

Epoch: 5| Step: 10
Training loss: 1.2575799226760864
Validation loss: 2.030635851685719

Epoch: 217| Step: 0
Training loss: 1.4585902690887451
Validation loss: 2.03864013507802

Epoch: 5| Step: 1
Training loss: 1.1660444736480713
Validation loss: 2.0530759493509927

Epoch: 5| Step: 2
Training loss: 1.6736583709716797
Validation loss: 2.0382048186435493

Epoch: 5| Step: 3
Training loss: 0.8432673215866089
Validation loss: 2.024378411231502

Epoch: 5| Step: 4
Training loss: 1.7936649322509766
Validation loss: 2.0313242968692573

Epoch: 5| Step: 5
Training loss: 1.725940465927124
Validation loss: 2.050337650442636

Epoch: 5| Step: 6
Training loss: 1.8237006664276123
Validation loss: 2.061410157911239

Epoch: 5| Step: 7
Training loss: 1.791124701499939
Validation loss: 2.0430723697908464

Epoch: 5| Step: 8
Training loss: 2.067579746246338
Validation loss: 2.0386047030007965

Epoch: 5| Step: 9
Training loss: 1.7665904760360718
Validation loss: 2.037814450520341

Epoch: 5| Step: 10
Training loss: 1.424089789390564
Validation loss: 2.079476491097481

Epoch: 218| Step: 0
Training loss: 1.5644452571868896
Validation loss: 2.112124422545074

Epoch: 5| Step: 1
Training loss: 1.6726058721542358
Validation loss: 2.0467333293730214

Epoch: 5| Step: 2
Training loss: 2.2783021926879883
Validation loss: 2.0275042467219855

Epoch: 5| Step: 3
Training loss: 1.5086206197738647
Validation loss: 2.022241585998125

Epoch: 5| Step: 4
Training loss: 1.4831898212432861
Validation loss: 2.0476097035151657

Epoch: 5| Step: 5
Training loss: 1.6470896005630493
Validation loss: 2.0292852181260304

Epoch: 5| Step: 6
Training loss: 2.0598654747009277
Validation loss: 2.0030069094832226

Epoch: 5| Step: 7
Training loss: 1.3052537441253662
Validation loss: 2.0410070214220273

Epoch: 5| Step: 8
Training loss: 1.1724069118499756
Validation loss: 2.0620182278335735

Epoch: 5| Step: 9
Training loss: 2.165499448776245
Validation loss: 2.0604691428522908

Epoch: 5| Step: 10
Training loss: 1.3136959075927734
Validation loss: 2.0369576228562223

Epoch: 219| Step: 0
Training loss: 1.7557544708251953
Validation loss: 2.035231349288776

Epoch: 5| Step: 1
Training loss: 1.8353779315948486
Validation loss: 2.011449936897524

Epoch: 5| Step: 2
Training loss: 2.0322647094726562
Validation loss: 2.0031401329143073

Epoch: 5| Step: 3
Training loss: 1.4642961025238037
Validation loss: 1.996038745808345

Epoch: 5| Step: 4
Training loss: 1.2164745330810547
Validation loss: 1.9979551902381323

Epoch: 5| Step: 5
Training loss: 1.957291603088379
Validation loss: 1.9836894132757699

Epoch: 5| Step: 6
Training loss: 1.4923161268234253
Validation loss: 1.998250904903617

Epoch: 5| Step: 7
Training loss: 1.9034286737442017
Validation loss: 2.0188209600346063

Epoch: 5| Step: 8
Training loss: 0.8939208984375
Validation loss: 2.011613517679194

Epoch: 5| Step: 9
Training loss: 1.4693909883499146
Validation loss: 2.011259058470367

Epoch: 5| Step: 10
Training loss: 1.2716162204742432
Validation loss: 2.0189077418337584

Epoch: 220| Step: 0
Training loss: 1.511427640914917
Validation loss: 2.0386093419085265

Epoch: 5| Step: 1
Training loss: 1.6740859746932983
Validation loss: 2.049410846925551

Epoch: 5| Step: 2
Training loss: 1.711276650428772
Validation loss: 2.0559012466861355

Epoch: 5| Step: 3
Training loss: 1.4072377681732178
Validation loss: 2.0465534041004796

Epoch: 5| Step: 4
Training loss: 1.5391165018081665
Validation loss: 2.043401869394446

Epoch: 5| Step: 5
Training loss: 1.5297755002975464
Validation loss: 2.026146573405112

Epoch: 5| Step: 6
Training loss: 0.9893864393234253
Validation loss: 2.0147917603933685

Epoch: 5| Step: 7
Training loss: 1.6398303508758545
Validation loss: 1.9920667448351461

Epoch: 5| Step: 8
Training loss: 1.4935258626937866
Validation loss: 1.996516994250718

Epoch: 5| Step: 9
Training loss: 2.1829466819763184
Validation loss: 1.9822630933535996

Epoch: 5| Step: 10
Training loss: 1.5763567686080933
Validation loss: 2.0031249215525966

Epoch: 221| Step: 0
Training loss: 1.9981168508529663
Validation loss: 2.003234076243575

Epoch: 5| Step: 1
Training loss: 2.109929323196411
Validation loss: 2.0042949440658733

Epoch: 5| Step: 2
Training loss: 1.4769700765609741
Validation loss: 2.0207496919939594

Epoch: 5| Step: 3
Training loss: 1.0799003839492798
Validation loss: 2.017701279732489

Epoch: 5| Step: 4
Training loss: 1.9002602100372314
Validation loss: 2.035531477261615

Epoch: 5| Step: 5
Training loss: 1.3631317615509033
Validation loss: 2.0260962055575464

Epoch: 5| Step: 6
Training loss: 1.467872142791748
Validation loss: 2.017909680643389

Epoch: 5| Step: 7
Training loss: 1.6426589488983154
Validation loss: 2.028640998307095

Epoch: 5| Step: 8
Training loss: 1.6659793853759766
Validation loss: 2.029958409647788

Epoch: 5| Step: 9
Training loss: 1.0739398002624512
Validation loss: 2.0258639063886417

Epoch: 5| Step: 10
Training loss: 1.2529083490371704
Validation loss: 2.0695466123601443

Epoch: 222| Step: 0
Training loss: 1.619086503982544
Validation loss: 2.0696448254328903

Epoch: 5| Step: 1
Training loss: 1.5075032711029053
Validation loss: 2.081471348321566

Epoch: 5| Step: 2
Training loss: 1.5581142902374268
Validation loss: 2.0424141678758847

Epoch: 5| Step: 3
Training loss: 2.113550901412964
Validation loss: 2.00126181046168

Epoch: 5| Step: 4
Training loss: 1.671727180480957
Validation loss: 2.001398253184493

Epoch: 5| Step: 5
Training loss: 1.7304718494415283
Validation loss: 2.0142942910553305

Epoch: 5| Step: 6
Training loss: 1.9769474267959595
Validation loss: 2.012014150619507

Epoch: 5| Step: 7
Training loss: 1.0581481456756592
Validation loss: 1.9876501893484464

Epoch: 5| Step: 8
Training loss: 1.6328535079956055
Validation loss: 1.9968637061375443

Epoch: 5| Step: 9
Training loss: 1.0328953266143799
Validation loss: 1.9965207666479132

Epoch: 5| Step: 10
Training loss: 1.1652075052261353
Validation loss: 2.0009018695482643

Epoch: 223| Step: 0
Training loss: 1.7591806650161743
Validation loss: 2.001038516721418

Epoch: 5| Step: 1
Training loss: 0.7635028958320618
Validation loss: 2.006558979711225

Epoch: 5| Step: 2
Training loss: 1.8758291006088257
Validation loss: 2.003693126863049

Epoch: 5| Step: 3
Training loss: 1.3658192157745361
Validation loss: 1.9904265865202873

Epoch: 5| Step: 4
Training loss: 1.4493072032928467
Validation loss: 1.9910951622070805

Epoch: 5| Step: 5
Training loss: 1.7529569864273071
Validation loss: 2.016751335513207

Epoch: 5| Step: 6
Training loss: 1.8369814157485962
Validation loss: 2.0135083006274317

Epoch: 5| Step: 7
Training loss: 1.546233892440796
Validation loss: 2.024785631446428

Epoch: 5| Step: 8
Training loss: 1.7074114084243774
Validation loss: 2.005497391505908

Epoch: 5| Step: 9
Training loss: 1.59225332736969
Validation loss: 2.0176260471343994

Epoch: 5| Step: 10
Training loss: 1.1148054599761963
Validation loss: 2.0301591991096415

Epoch: 224| Step: 0
Training loss: 1.0803849697113037
Validation loss: 2.031214573050058

Epoch: 5| Step: 1
Training loss: 1.2349059581756592
Validation loss: 2.0427946634190057

Epoch: 5| Step: 2
Training loss: 1.6032692193984985
Validation loss: 2.03566482246563

Epoch: 5| Step: 3
Training loss: 1.8449060916900635
Validation loss: 2.051107346370656

Epoch: 5| Step: 4
Training loss: 1.4079935550689697
Validation loss: 2.0402125440618044

Epoch: 5| Step: 5
Training loss: 1.4841339588165283
Validation loss: 2.004645375795262

Epoch: 5| Step: 6
Training loss: 1.8040246963500977
Validation loss: 2.0204563627960863

Epoch: 5| Step: 7
Training loss: 1.4673768281936646
Validation loss: 2.0063135329113213

Epoch: 5| Step: 8
Training loss: 1.476393699645996
Validation loss: 2.0037099340910554

Epoch: 5| Step: 9
Training loss: 1.5991079807281494
Validation loss: 2.0094737032408356

Epoch: 5| Step: 10
Training loss: 1.898036241531372
Validation loss: 2.002147638669578

Epoch: 225| Step: 0
Training loss: 1.3629038333892822
Validation loss: 1.9987911537129393

Epoch: 5| Step: 1
Training loss: 1.771360993385315
Validation loss: 1.9881732976564797

Epoch: 5| Step: 2
Training loss: 1.86043381690979
Validation loss: 2.0142354067935737

Epoch: 5| Step: 3
Training loss: 1.3518317937850952
Validation loss: 2.0080105527754752

Epoch: 5| Step: 4
Training loss: 1.6991373300552368
Validation loss: 1.9953067533431514

Epoch: 5| Step: 5
Training loss: 1.2410900592803955
Validation loss: 1.9929421563302316

Epoch: 5| Step: 6
Training loss: 1.4667766094207764
Validation loss: 1.9835822018243934

Epoch: 5| Step: 7
Training loss: 1.4862703084945679
Validation loss: 2.0258637294974378

Epoch: 5| Step: 8
Training loss: 1.64702570438385
Validation loss: 2.025419258302258

Epoch: 5| Step: 9
Training loss: 1.2832854986190796
Validation loss: 2.0313374611639206

Epoch: 5| Step: 10
Training loss: 1.5262315273284912
Validation loss: 2.0299115424515097

Epoch: 226| Step: 0
Training loss: 1.4512407779693604
Validation loss: 2.038020646700295

Epoch: 5| Step: 1
Training loss: 1.0609643459320068
Validation loss: 2.0509262956598753

Epoch: 5| Step: 2
Training loss: 1.6870266199111938
Validation loss: 2.0591905937399915

Epoch: 5| Step: 3
Training loss: 1.5856754779815674
Validation loss: 2.0588234483554797

Epoch: 5| Step: 4
Training loss: 1.429972529411316
Validation loss: 2.0707375413628033

Epoch: 5| Step: 5
Training loss: 1.2649770975112915
Validation loss: 2.025750132017238

Epoch: 5| Step: 6
Training loss: 1.4018805027008057
Validation loss: 1.9942464085035427

Epoch: 5| Step: 7
Training loss: 1.9203708171844482
Validation loss: 1.988005066430697

Epoch: 5| Step: 8
Training loss: 1.3335130214691162
Validation loss: 1.9688862818543629

Epoch: 5| Step: 9
Training loss: 1.7299503087997437
Validation loss: 1.9702853028492262

Epoch: 5| Step: 10
Training loss: 1.542219877243042
Validation loss: 1.9561170506220993

Epoch: 227| Step: 0
Training loss: 1.220562219619751
Validation loss: 1.95101075531334

Epoch: 5| Step: 1
Training loss: 1.9907872676849365
Validation loss: 1.9519071309797225

Epoch: 5| Step: 2
Training loss: 1.926134467124939
Validation loss: 1.9623279571533203

Epoch: 5| Step: 3
Training loss: 1.161478042602539
Validation loss: 1.9703759249820505

Epoch: 5| Step: 4
Training loss: 1.6974084377288818
Validation loss: 1.9855755682914489

Epoch: 5| Step: 5
Training loss: 1.3330305814743042
Validation loss: 2.012840081286687

Epoch: 5| Step: 6
Training loss: 1.7647838592529297
Validation loss: 2.000465081584069

Epoch: 5| Step: 7
Training loss: 1.3356653451919556
Validation loss: 2.008312422742126

Epoch: 5| Step: 8
Training loss: 1.1610236167907715
Validation loss: 2.028207496930194

Epoch: 5| Step: 9
Training loss: 1.0069688558578491
Validation loss: 2.027235552828799

Epoch: 5| Step: 10
Training loss: 1.7704218626022339
Validation loss: 2.016200275831325

Epoch: 228| Step: 0
Training loss: 1.7481094598770142
Validation loss: 2.000371836846875

Epoch: 5| Step: 1
Training loss: 1.5341445207595825
Validation loss: 2.023172361876375

Epoch: 5| Step: 2
Training loss: 1.245912790298462
Validation loss: 2.0670860172599874

Epoch: 5| Step: 3
Training loss: 1.1707395315170288
Validation loss: 2.039419435685681

Epoch: 5| Step: 4
Training loss: 1.3773025274276733
Validation loss: 1.9952681474788214

Epoch: 5| Step: 5
Training loss: 0.8817922472953796
Validation loss: 1.9711737581478652

Epoch: 5| Step: 6
Training loss: 1.1670629978179932
Validation loss: 1.9471110810515702

Epoch: 5| Step: 7
Training loss: 1.8300268650054932
Validation loss: 1.9474697548856017

Epoch: 5| Step: 8
Training loss: 2.002384662628174
Validation loss: 1.9696721928094023

Epoch: 5| Step: 9
Training loss: 1.496890664100647
Validation loss: 1.9543942097694642

Epoch: 5| Step: 10
Training loss: 2.0153708457946777
Validation loss: 1.9421657182837044

Epoch: 229| Step: 0
Training loss: 1.348541498184204
Validation loss: 1.9570363798449117

Epoch: 5| Step: 1
Training loss: 1.9868395328521729
Validation loss: 1.9553949012551257

Epoch: 5| Step: 2
Training loss: 1.362184762954712
Validation loss: 1.9636003971099854

Epoch: 5| Step: 3
Training loss: 1.257735252380371
Validation loss: 1.9618265833905948

Epoch: 5| Step: 4
Training loss: 1.9528090953826904
Validation loss: 1.9770232913314656

Epoch: 5| Step: 5
Training loss: 1.1712398529052734
Validation loss: 2.004462601036154

Epoch: 5| Step: 6
Training loss: 1.0504796504974365
Validation loss: 2.0216894918872463

Epoch: 5| Step: 7
Training loss: 1.8015590906143188
Validation loss: 2.025294905067772

Epoch: 5| Step: 8
Training loss: 1.225396752357483
Validation loss: 2.017607024920884

Epoch: 5| Step: 9
Training loss: 1.7251722812652588
Validation loss: 1.9878568739019415

Epoch: 5| Step: 10
Training loss: 1.3712059259414673
Validation loss: 1.9909730412626778

Epoch: 230| Step: 0
Training loss: 1.5512441396713257
Validation loss: 1.980448092183759

Epoch: 5| Step: 1
Training loss: 1.2365518808364868
Validation loss: 1.966182025530005

Epoch: 5| Step: 2
Training loss: 1.3907204866409302
Validation loss: 1.9796624491291661

Epoch: 5| Step: 3
Training loss: 1.6026427745819092
Validation loss: 1.9811954498291016

Epoch: 5| Step: 4
Training loss: 2.3236913681030273
Validation loss: 1.964278777440389

Epoch: 5| Step: 5
Training loss: 1.0533415079116821
Validation loss: 1.9973835252946424

Epoch: 5| Step: 6
Training loss: 1.2161321640014648
Validation loss: 1.9724002986825921

Epoch: 5| Step: 7
Training loss: 1.4026896953582764
Validation loss: 1.9555353221072946

Epoch: 5| Step: 8
Training loss: 1.1346421241760254
Validation loss: 1.9482672804145402

Epoch: 5| Step: 9
Training loss: 1.5816140174865723
Validation loss: 1.9580527300475745

Epoch: 5| Step: 10
Training loss: 1.7079622745513916
Validation loss: 1.941270682119554

Epoch: 231| Step: 0
Training loss: 1.3429148197174072
Validation loss: 1.9456001814975534

Epoch: 5| Step: 1
Training loss: 1.578667163848877
Validation loss: 1.9517744036131008

Epoch: 5| Step: 2
Training loss: 1.196829915046692
Validation loss: 1.9600174965397004

Epoch: 5| Step: 3
Training loss: 0.888237476348877
Validation loss: 1.9764261297000352

Epoch: 5| Step: 4
Training loss: 1.606757402420044
Validation loss: 2.0002810737138152

Epoch: 5| Step: 5
Training loss: 1.8546931743621826
Validation loss: 2.020127027265487

Epoch: 5| Step: 6
Training loss: 1.1678564548492432
Validation loss: 2.0100544601358394

Epoch: 5| Step: 7
Training loss: 1.5965945720672607
Validation loss: 2.007913548459289

Epoch: 5| Step: 8
Training loss: 1.5810920000076294
Validation loss: 1.9924927988360006

Epoch: 5| Step: 9
Training loss: 1.7171119451522827
Validation loss: 2.029469913051974

Epoch: 5| Step: 10
Training loss: 1.381742000579834
Validation loss: 2.0026418957658993

Epoch: 232| Step: 0
Training loss: 1.188208818435669
Validation loss: 2.0110090740265383

Epoch: 5| Step: 1
Training loss: 1.8636887073516846
Validation loss: 1.98749743482118

Epoch: 5| Step: 2
Training loss: 1.3862109184265137
Validation loss: 2.008853902098953

Epoch: 5| Step: 3
Training loss: 2.2142207622528076
Validation loss: 2.0184959878203688

Epoch: 5| Step: 4
Training loss: 1.7752304077148438
Validation loss: 1.9881792312027307

Epoch: 5| Step: 5
Training loss: 1.195319414138794
Validation loss: 1.9832039610032113

Epoch: 5| Step: 6
Training loss: 1.4215389490127563
Validation loss: 1.9798519175539735

Epoch: 5| Step: 7
Training loss: 1.5544788837432861
Validation loss: 1.9669674211932766

Epoch: 5| Step: 8
Training loss: 0.9520424008369446
Validation loss: 1.9554095857886857

Epoch: 5| Step: 9
Training loss: 1.2080470323562622
Validation loss: 1.9472860110703336

Epoch: 5| Step: 10
Training loss: 1.0791330337524414
Validation loss: 1.967232891308364

Epoch: 233| Step: 0
Training loss: 1.2485971450805664
Validation loss: 1.9791152913083312

Epoch: 5| Step: 1
Training loss: 1.3503626585006714
Validation loss: 1.9831994348956692

Epoch: 5| Step: 2
Training loss: 2.049668788909912
Validation loss: 2.0126740535100303

Epoch: 5| Step: 3
Training loss: 1.360325813293457
Validation loss: 1.995782813718242

Epoch: 5| Step: 4
Training loss: 1.4286785125732422
Validation loss: 2.0005423074127524

Epoch: 5| Step: 5
Training loss: 1.635759711265564
Validation loss: 1.9778768362537507

Epoch: 5| Step: 6
Training loss: 1.1905924081802368
Validation loss: 1.9631184595887379

Epoch: 5| Step: 7
Training loss: 1.0998839139938354
Validation loss: 1.965331615940217

Epoch: 5| Step: 8
Training loss: 1.1877121925354004
Validation loss: 1.9620792263297624

Epoch: 5| Step: 9
Training loss: 1.331251621246338
Validation loss: 1.9482925015111123

Epoch: 5| Step: 10
Training loss: 1.7893116474151611
Validation loss: 1.9456742630209973

Epoch: 234| Step: 0
Training loss: 1.4131271839141846
Validation loss: 1.9567025989614508

Epoch: 5| Step: 1
Training loss: 0.8880882263183594
Validation loss: 1.9523963492403749

Epoch: 5| Step: 2
Training loss: 1.4918725490570068
Validation loss: 1.96976819346028

Epoch: 5| Step: 3
Training loss: 1.2926490306854248
Validation loss: 1.9829175318441083

Epoch: 5| Step: 4
Training loss: 1.3495124578475952
Validation loss: 1.9860528720322477

Epoch: 5| Step: 5
Training loss: 1.5641940832138062
Validation loss: 1.998800564837712

Epoch: 5| Step: 6
Training loss: 1.4692444801330566
Validation loss: 1.9997431411538074

Epoch: 5| Step: 7
Training loss: 1.4973078966140747
Validation loss: 2.0069702453510736

Epoch: 5| Step: 8
Training loss: 1.5149587392807007
Validation loss: 2.0089139399989957

Epoch: 5| Step: 9
Training loss: 1.7364003658294678
Validation loss: 2.0230926364980717

Epoch: 5| Step: 10
Training loss: 1.1312792301177979
Validation loss: 1.9780093393018168

Epoch: 235| Step: 0
Training loss: 0.6917434930801392
Validation loss: 1.9939652283986409

Epoch: 5| Step: 1
Training loss: 1.6022145748138428
Validation loss: 1.9938926927505

Epoch: 5| Step: 2
Training loss: 1.4741544723510742
Validation loss: 1.9892399528975129

Epoch: 5| Step: 3
Training loss: 0.9448738098144531
Validation loss: 1.9885895649592082

Epoch: 5| Step: 4
Training loss: 1.7410800457000732
Validation loss: 1.9813411517809796

Epoch: 5| Step: 5
Training loss: 1.6988611221313477
Validation loss: 1.9606374643182243

Epoch: 5| Step: 6
Training loss: 1.7507810592651367
Validation loss: 1.9626694046041018

Epoch: 5| Step: 7
Training loss: 1.7507671117782593
Validation loss: 1.9613045748843942

Epoch: 5| Step: 8
Training loss: 1.4254192113876343
Validation loss: 1.9696490508253857

Epoch: 5| Step: 9
Training loss: 0.8037331700325012
Validation loss: 1.9607229912152855

Epoch: 5| Step: 10
Training loss: 1.5109034776687622
Validation loss: 1.9684768902358187

Epoch: 236| Step: 0
Training loss: 2.050529956817627
Validation loss: 1.975682927716163

Epoch: 5| Step: 1
Training loss: 0.8886266946792603
Validation loss: 1.9622317526930122

Epoch: 5| Step: 2
Training loss: 0.7716468572616577
Validation loss: 1.970575991497245

Epoch: 5| Step: 3
Training loss: 1.2923338413238525
Validation loss: 1.9668158715771091

Epoch: 5| Step: 4
Training loss: 1.7291572093963623
Validation loss: 1.952695728630148

Epoch: 5| Step: 5
Training loss: 1.1050066947937012
Validation loss: 1.9562613938444404

Epoch: 5| Step: 6
Training loss: 1.971001386642456
Validation loss: 1.9462929669246878

Epoch: 5| Step: 7
Training loss: 1.3999967575073242
Validation loss: 1.9562291496543474

Epoch: 5| Step: 8
Training loss: 1.0455248355865479
Validation loss: 1.9440606883777085

Epoch: 5| Step: 9
Training loss: 1.6423752307891846
Validation loss: 1.9737729410971365

Epoch: 5| Step: 10
Training loss: 1.2216618061065674
Validation loss: 1.966965301062471

Epoch: 237| Step: 0
Training loss: 0.8595464825630188
Validation loss: 1.991646476971206

Epoch: 5| Step: 1
Training loss: 1.4102966785430908
Validation loss: 2.010433966113675

Epoch: 5| Step: 2
Training loss: 0.9834259152412415
Validation loss: 2.012620891294172

Epoch: 5| Step: 3
Training loss: 1.7808599472045898
Validation loss: 2.0142317664238716

Epoch: 5| Step: 4
Training loss: 1.3389612436294556
Validation loss: 2.0205075689541396

Epoch: 5| Step: 5
Training loss: 1.5144517421722412
Validation loss: 1.9904564657518942

Epoch: 5| Step: 6
Training loss: 1.2623364925384521
Validation loss: 1.9942732498209963

Epoch: 5| Step: 7
Training loss: 1.3659894466400146
Validation loss: 1.9967397028400051

Epoch: 5| Step: 8
Training loss: 1.6492271423339844
Validation loss: 1.9768983394868913

Epoch: 5| Step: 9
Training loss: 1.7727956771850586
Validation loss: 2.009446194094996

Epoch: 5| Step: 10
Training loss: 1.3803685903549194
Validation loss: 1.9763396478468371

Epoch: 238| Step: 0
Training loss: 1.2751230001449585
Validation loss: 1.9671164789507467

Epoch: 5| Step: 1
Training loss: 1.5110399723052979
Validation loss: 1.9453475834220968

Epoch: 5| Step: 2
Training loss: 1.5653618574142456
Validation loss: 1.932703423243697

Epoch: 5| Step: 3
Training loss: 0.8632979393005371
Validation loss: 1.9615980809734714

Epoch: 5| Step: 4
Training loss: 1.697745680809021
Validation loss: 1.9683298936454199

Epoch: 5| Step: 5
Training loss: 1.6409547328948975
Validation loss: 1.9776892521048104

Epoch: 5| Step: 6
Training loss: 1.1438637971878052
Validation loss: 1.9693177182187316

Epoch: 5| Step: 7
Training loss: 1.7454185485839844
Validation loss: 1.965286208737281

Epoch: 5| Step: 8
Training loss: 1.0337573289871216
Validation loss: 1.9954973113152288

Epoch: 5| Step: 9
Training loss: 1.2144927978515625
Validation loss: 1.9960617096193376

Epoch: 5| Step: 10
Training loss: 1.3826406002044678
Validation loss: 2.004159924804523

Epoch: 239| Step: 0
Training loss: 1.3228309154510498
Validation loss: 1.974675464373763

Epoch: 5| Step: 1
Training loss: 0.853527843952179
Validation loss: 1.9790185702744352

Epoch: 5| Step: 2
Training loss: 1.424925446510315
Validation loss: 1.9838201294663131

Epoch: 5| Step: 3
Training loss: 1.925423264503479
Validation loss: 1.9624358415603638

Epoch: 5| Step: 4
Training loss: 0.8222096562385559
Validation loss: 1.9439349225772324

Epoch: 5| Step: 5
Training loss: 1.31167471408844
Validation loss: 1.9556747546759985

Epoch: 5| Step: 6
Training loss: 1.392573595046997
Validation loss: 1.9304110978239326

Epoch: 5| Step: 7
Training loss: 1.768032431602478
Validation loss: 1.9356006870987594

Epoch: 5| Step: 8
Training loss: 1.0511212348937988
Validation loss: 1.9396900105220016

Epoch: 5| Step: 9
Training loss: 1.7791576385498047
Validation loss: 1.966468911017141

Epoch: 5| Step: 10
Training loss: 1.4356733560562134
Validation loss: 1.9763760605166036

Epoch: 240| Step: 0
Training loss: 1.2109472751617432
Validation loss: 1.96107877198086

Epoch: 5| Step: 1
Training loss: 1.0564682483673096
Validation loss: 1.9565068021897347

Epoch: 5| Step: 2
Training loss: 1.4550567865371704
Validation loss: 1.9618992908026582

Epoch: 5| Step: 3
Training loss: 1.090368390083313
Validation loss: 1.9629434641971384

Epoch: 5| Step: 4
Training loss: 1.0334092378616333
Validation loss: 1.9772295669842792

Epoch: 5| Step: 5
Training loss: 2.253744602203369
Validation loss: 1.9900034473788353

Epoch: 5| Step: 6
Training loss: 1.8071982860565186
Validation loss: 1.964106975063201

Epoch: 5| Step: 7
Training loss: 1.3718334436416626
Validation loss: 1.9642168655190417

Epoch: 5| Step: 8
Training loss: 1.1287901401519775
Validation loss: 1.9564735889434814

Epoch: 5| Step: 9
Training loss: 1.2001971006393433
Validation loss: 1.9656631587654032

Epoch: 5| Step: 10
Training loss: 1.1839336156845093
Validation loss: 1.9477874079058248

Epoch: 241| Step: 0
Training loss: 1.5726333856582642
Validation loss: 1.9744262887585549

Epoch: 5| Step: 1
Training loss: 1.5999723672866821
Validation loss: 1.9656301083103302

Epoch: 5| Step: 2
Training loss: 1.449620246887207
Validation loss: 1.9589030101735105

Epoch: 5| Step: 3
Training loss: 1.2837045192718506
Validation loss: 1.9820274640155096

Epoch: 5| Step: 4
Training loss: 1.854962944984436
Validation loss: 1.973372515811715

Epoch: 5| Step: 5
Training loss: 0.9104127883911133
Validation loss: 1.9742671174387778

Epoch: 5| Step: 6
Training loss: 1.006280779838562
Validation loss: 1.9586503223706317

Epoch: 5| Step: 7
Training loss: 1.3882179260253906
Validation loss: 1.9354343593761485

Epoch: 5| Step: 8
Training loss: 1.0722535848617554
Validation loss: 1.9484916528065999

Epoch: 5| Step: 9
Training loss: 1.0877565145492554
Validation loss: 1.9552314358372842

Epoch: 5| Step: 10
Training loss: 1.2864527702331543
Validation loss: 1.9430073127951673

Epoch: 242| Step: 0
Training loss: 1.0268704891204834
Validation loss: 1.9415416461165234

Epoch: 5| Step: 1
Training loss: 1.4178121089935303
Validation loss: 1.935357524502662

Epoch: 5| Step: 2
Training loss: 1.6275867223739624
Validation loss: 1.943408094426637

Epoch: 5| Step: 3
Training loss: 0.9365730285644531
Validation loss: 1.9524374277360979

Epoch: 5| Step: 4
Training loss: 1.1274398565292358
Validation loss: 1.948462813131271

Epoch: 5| Step: 5
Training loss: 1.2991082668304443
Validation loss: 1.9552387755404237

Epoch: 5| Step: 6
Training loss: 1.2071067094802856
Validation loss: 1.947909765346076

Epoch: 5| Step: 7
Training loss: 1.1881107091903687
Validation loss: 1.9775687545858405

Epoch: 5| Step: 8
Training loss: 1.9903453588485718
Validation loss: 1.9926277027335217

Epoch: 5| Step: 9
Training loss: 1.440216302871704
Validation loss: 1.9975413981304373

Epoch: 5| Step: 10
Training loss: 1.6242601871490479
Validation loss: 1.9994222669191257

Epoch: 243| Step: 0
Training loss: 1.2210232019424438
Validation loss: 1.9932911293480986

Epoch: 5| Step: 1
Training loss: 1.1100742816925049
Validation loss: 1.973431948692568

Epoch: 5| Step: 2
Training loss: 1.2929524183273315
Validation loss: 1.9595973542941514

Epoch: 5| Step: 3
Training loss: 0.9764358401298523
Validation loss: 1.959289522581203

Epoch: 5| Step: 4
Training loss: 1.0771325826644897
Validation loss: 1.9805411664388513

Epoch: 5| Step: 5
Training loss: 1.9146007299423218
Validation loss: 1.9537414402090094

Epoch: 5| Step: 6
Training loss: 0.951402485370636
Validation loss: 1.934826973945864

Epoch: 5| Step: 7
Training loss: 1.8194847106933594
Validation loss: 1.9270920727842598

Epoch: 5| Step: 8
Training loss: 1.6280748844146729
Validation loss: 1.9359191874022126

Epoch: 5| Step: 9
Training loss: 1.5675065517425537
Validation loss: 1.9318870395742438

Epoch: 5| Step: 10
Training loss: 1.1292943954467773
Validation loss: 1.9164721004424556

Epoch: 244| Step: 0
Training loss: 1.733298897743225
Validation loss: 1.900294183402933

Epoch: 5| Step: 1
Training loss: 1.4137609004974365
Validation loss: 1.9158892772530998

Epoch: 5| Step: 2
Training loss: 1.3138445615768433
Validation loss: 1.939434951351535

Epoch: 5| Step: 3
Training loss: 1.1672651767730713
Validation loss: 1.9248687592885827

Epoch: 5| Step: 4
Training loss: 1.2622750997543335
Validation loss: 1.9244523766220256

Epoch: 5| Step: 5
Training loss: 1.4168002605438232
Validation loss: 1.9157084136880853

Epoch: 5| Step: 6
Training loss: 1.965161919593811
Validation loss: 1.9232375801250499

Epoch: 5| Step: 7
Training loss: 0.9016230702400208
Validation loss: 1.9505692746049614

Epoch: 5| Step: 8
Training loss: 0.9959942102432251
Validation loss: 1.9534157732481598

Epoch: 5| Step: 9
Training loss: 1.4884474277496338
Validation loss: 1.931223197649884

Epoch: 5| Step: 10
Training loss: 1.2309423685073853
Validation loss: 1.9339295689777662

Epoch: 245| Step: 0
Training loss: 1.7722822427749634
Validation loss: 1.9666178662289855

Epoch: 5| Step: 1
Training loss: 1.1496150493621826
Validation loss: 1.9955976573369836

Epoch: 5| Step: 2
Training loss: 1.2524901628494263
Validation loss: 1.9528471321187995

Epoch: 5| Step: 3
Training loss: 1.3236640691757202
Validation loss: 1.9551907059966878

Epoch: 5| Step: 4
Training loss: 1.0080125331878662
Validation loss: 1.9202946180938392

Epoch: 5| Step: 5
Training loss: 1.3190982341766357
Validation loss: 1.9341905424671788

Epoch: 5| Step: 6
Training loss: 1.2111599445343018
Validation loss: 1.9307510416994813

Epoch: 5| Step: 7
Training loss: 1.7649730443954468
Validation loss: 1.9314255291415798

Epoch: 5| Step: 8
Training loss: 0.8414679765701294
Validation loss: 1.941591324344758

Epoch: 5| Step: 9
Training loss: 1.7459663152694702
Validation loss: 1.924888075038951

Epoch: 5| Step: 10
Training loss: 1.2521326541900635
Validation loss: 1.9361701819204515

Epoch: 246| Step: 0
Training loss: 1.402443528175354
Validation loss: 1.9185646990294098

Epoch: 5| Step: 1
Training loss: 1.5563228130340576
Validation loss: 1.9179047358933317

Epoch: 5| Step: 2
Training loss: 1.3149858713150024
Validation loss: 1.9157728584863807

Epoch: 5| Step: 3
Training loss: 1.2690825462341309
Validation loss: 1.9179244425988966

Epoch: 5| Step: 4
Training loss: 1.1830976009368896
Validation loss: 1.9234120538157802

Epoch: 5| Step: 5
Training loss: 1.037557601928711
Validation loss: 1.9113907147479314

Epoch: 5| Step: 6
Training loss: 1.0474145412445068
Validation loss: 1.9175713780105754

Epoch: 5| Step: 7
Training loss: 1.2136695384979248
Validation loss: 1.9282848501718173

Epoch: 5| Step: 8
Training loss: 1.18436861038208
Validation loss: 1.9250482256694506

Epoch: 5| Step: 9
Training loss: 1.3527244329452515
Validation loss: 1.9169206055261756

Epoch: 5| Step: 10
Training loss: 1.740527868270874
Validation loss: 1.9028865586044967

Epoch: 247| Step: 0
Training loss: 1.3768155574798584
Validation loss: 1.9122255412481164

Epoch: 5| Step: 1
Training loss: 1.3782612085342407
Validation loss: 1.9114315304704892

Epoch: 5| Step: 2
Training loss: 1.2622443437576294
Validation loss: 1.9136134116880354

Epoch: 5| Step: 3
Training loss: 1.5034348964691162
Validation loss: 1.933614864144274

Epoch: 5| Step: 4
Training loss: 1.4555420875549316
Validation loss: 1.9565252924478183

Epoch: 5| Step: 5
Training loss: 1.076007604598999
Validation loss: 1.976660684872699

Epoch: 5| Step: 6
Training loss: 1.1708167791366577
Validation loss: 1.9873777435671898

Epoch: 5| Step: 7
Training loss: 0.9332097172737122
Validation loss: 1.9809305308967509

Epoch: 5| Step: 8
Training loss: 1.9352937936782837
Validation loss: 1.9732973267955165

Epoch: 5| Step: 9
Training loss: 1.1009294986724854
Validation loss: 1.9836838117209814

Epoch: 5| Step: 10
Training loss: 1.1442245244979858
Validation loss: 1.9845593308889737

Epoch: 248| Step: 0
Training loss: 1.0916024446487427
Validation loss: 1.9507183400533532

Epoch: 5| Step: 1
Training loss: 1.4340169429779053
Validation loss: 1.968072651534952

Epoch: 5| Step: 2
Training loss: 1.3972580432891846
Validation loss: 1.9557838824487501

Epoch: 5| Step: 3
Training loss: 1.5061129331588745
Validation loss: 1.918008703057484

Epoch: 5| Step: 4
Training loss: 1.1114137172698975
Validation loss: 1.9211386096092962

Epoch: 5| Step: 5
Training loss: 2.09626841545105
Validation loss: 1.9001668486543881

Epoch: 5| Step: 6
Training loss: 1.127076506614685
Validation loss: 1.9006672777155393

Epoch: 5| Step: 7
Training loss: 1.3063894510269165
Validation loss: 1.9048400053413965

Epoch: 5| Step: 8
Training loss: 1.1914379596710205
Validation loss: 1.9145747307808167

Epoch: 5| Step: 9
Training loss: 0.763914167881012
Validation loss: 1.9297695006093671

Epoch: 5| Step: 10
Training loss: 1.0468777418136597
Validation loss: 1.9237360979921074

Epoch: 249| Step: 0
Training loss: 1.3897348642349243
Validation loss: 1.930736898094095

Epoch: 5| Step: 1
Training loss: 1.0191270112991333
Validation loss: 1.9335861667510001

Epoch: 5| Step: 2
Training loss: 1.51302170753479
Validation loss: 1.9273689485365344

Epoch: 5| Step: 3
Training loss: 1.2418752908706665
Validation loss: 1.9280250034024637

Epoch: 5| Step: 4
Training loss: 1.4095814228057861
Validation loss: 1.9450285614177745

Epoch: 5| Step: 5
Training loss: 1.4485986232757568
Validation loss: 1.937720920449944

Epoch: 5| Step: 6
Training loss: 0.8452412486076355
Validation loss: 1.9408708131441506

Epoch: 5| Step: 7
Training loss: 1.241154432296753
Validation loss: 1.925047302758822

Epoch: 5| Step: 8
Training loss: 1.6934852600097656
Validation loss: 1.9230975925281484

Epoch: 5| Step: 9
Training loss: 0.9256418347358704
Validation loss: 1.9662143645748016

Epoch: 5| Step: 10
Training loss: 1.403972864151001
Validation loss: 1.9610691019283828

Epoch: 250| Step: 0
Training loss: 1.7179466485977173
Validation loss: 1.9362898924017464

Epoch: 5| Step: 1
Training loss: 1.6146085262298584
Validation loss: 1.941202361096618

Epoch: 5| Step: 2
Training loss: 1.4282819032669067
Validation loss: 1.935553236674237

Epoch: 5| Step: 3
Training loss: 1.0907325744628906
Validation loss: 1.9483925450232722

Epoch: 5| Step: 4
Training loss: 0.9406331181526184
Validation loss: 1.9419490086135043

Epoch: 5| Step: 5
Training loss: 1.3096840381622314
Validation loss: 1.9623926147337882

Epoch: 5| Step: 6
Training loss: 1.5894315242767334
Validation loss: 1.9373687505722046

Epoch: 5| Step: 7
Training loss: 0.6885868906974792
Validation loss: 1.9378751400978333

Epoch: 5| Step: 8
Training loss: 1.3963536024093628
Validation loss: 1.9269984229918449

Epoch: 5| Step: 9
Training loss: 1.1920992136001587
Validation loss: 1.9239186215144333

Epoch: 5| Step: 10
Training loss: 0.7778063416481018
Validation loss: 1.9088442094864384

Epoch: 251| Step: 0
Training loss: 1.4034864902496338
Validation loss: 1.9125796466745355

Epoch: 5| Step: 1
Training loss: 1.458945631980896
Validation loss: 1.9499535932335803

Epoch: 5| Step: 2
Training loss: 1.7029651403427124
Validation loss: 1.9243538328396377

Epoch: 5| Step: 3
Training loss: 0.892468273639679
Validation loss: 1.919627006335925

Epoch: 5| Step: 4
Training loss: 0.9237651824951172
Validation loss: 1.9043154883128341

Epoch: 5| Step: 5
Training loss: 1.1291674375534058
Validation loss: 1.9327904921706005

Epoch: 5| Step: 6
Training loss: 1.5665714740753174
Validation loss: 1.9195996279357581

Epoch: 5| Step: 7
Training loss: 1.434658169746399
Validation loss: 1.9104798327210128

Epoch: 5| Step: 8
Training loss: 0.9435615539550781
Validation loss: 1.903746296000737

Epoch: 5| Step: 9
Training loss: 1.0826175212860107
Validation loss: 1.9021097075554632

Epoch: 5| Step: 10
Training loss: 1.3013147115707397
Validation loss: 1.9281523330237276

Epoch: 252| Step: 0
Training loss: 1.5565450191497803
Validation loss: 1.910183459199885

Epoch: 5| Step: 1
Training loss: 1.505674123764038
Validation loss: 1.9156680209662325

Epoch: 5| Step: 2
Training loss: 1.3303639888763428
Validation loss: 1.9256393383908015

Epoch: 5| Step: 3
Training loss: 0.7553130984306335
Validation loss: 1.913827706408757

Epoch: 5| Step: 4
Training loss: 1.416598916053772
Validation loss: 1.9124778483503608

Epoch: 5| Step: 5
Training loss: 1.4233070611953735
Validation loss: 1.8938821361910911

Epoch: 5| Step: 6
Training loss: 0.9241878390312195
Validation loss: 1.9198148891489992

Epoch: 5| Step: 7
Training loss: 0.710138201713562
Validation loss: 1.9185782940157

Epoch: 5| Step: 8
Training loss: 0.8505150675773621
Validation loss: 1.9190565898854246

Epoch: 5| Step: 9
Training loss: 1.9561259746551514
Validation loss: 1.913384956698264

Epoch: 5| Step: 10
Training loss: 1.4175795316696167
Validation loss: 1.913542132223806

Epoch: 253| Step: 0
Training loss: 1.3939080238342285
Validation loss: 1.9084000408008535

Epoch: 5| Step: 1
Training loss: 1.5460398197174072
Validation loss: 1.9126082107584963

Epoch: 5| Step: 2
Training loss: 1.2500025033950806
Validation loss: 1.9180938812994188

Epoch: 5| Step: 3
Training loss: 1.0031810998916626
Validation loss: 1.9155714486234932

Epoch: 5| Step: 4
Training loss: 1.272444486618042
Validation loss: 1.9190077012585056

Epoch: 5| Step: 5
Training loss: 1.393449068069458
Validation loss: 1.9247783845470798

Epoch: 5| Step: 6
Training loss: 1.6530736684799194
Validation loss: 1.907964312902061

Epoch: 5| Step: 7
Training loss: 0.9951649904251099
Validation loss: 1.9096333557559597

Epoch: 5| Step: 8
Training loss: 1.1785469055175781
Validation loss: 1.9223770556911346

Epoch: 5| Step: 9
Training loss: 0.8343143463134766
Validation loss: 1.919880619613073

Epoch: 5| Step: 10
Training loss: 1.1150609254837036
Validation loss: 1.9227749045177172

Epoch: 254| Step: 0
Training loss: 1.3201181888580322
Validation loss: 1.9240598960589337

Epoch: 5| Step: 1
Training loss: 1.13643479347229
Validation loss: 1.9181277623740576

Epoch: 5| Step: 2
Training loss: 1.4517329931259155
Validation loss: 1.9200982765484882

Epoch: 5| Step: 3
Training loss: 1.1199572086334229
Validation loss: 1.8932420617790633

Epoch: 5| Step: 4
Training loss: 1.382704496383667
Validation loss: 1.9048842473696637

Epoch: 5| Step: 5
Training loss: 1.0806987285614014
Validation loss: 1.9258783440436087

Epoch: 5| Step: 6
Training loss: 1.013714075088501
Validation loss: 1.9345805850080264

Epoch: 5| Step: 7
Training loss: 1.3257213830947876
Validation loss: 1.962710480536184

Epoch: 5| Step: 8
Training loss: 1.087183952331543
Validation loss: 1.939940716630669

Epoch: 5| Step: 9
Training loss: 1.0193674564361572
Validation loss: 1.9224775324585617

Epoch: 5| Step: 10
Training loss: 1.6044901609420776
Validation loss: 1.9391593599832186

Epoch: 255| Step: 0
Training loss: 0.7547780275344849
Validation loss: 1.9541144409487325

Epoch: 5| Step: 1
Training loss: 1.1564785242080688
Validation loss: 1.9604754255663963

Epoch: 5| Step: 2
Training loss: 1.4237797260284424
Validation loss: 2.002121474153252

Epoch: 5| Step: 3
Training loss: 0.9920662641525269
Validation loss: 1.9666789577853294

Epoch: 5| Step: 4
Training loss: 1.4677075147628784
Validation loss: 1.951564085099005

Epoch: 5| Step: 5
Training loss: 1.2682604789733887
Validation loss: 1.953612212211855

Epoch: 5| Step: 6
Training loss: 1.4324119091033936
Validation loss: 1.9421208955908333

Epoch: 5| Step: 7
Training loss: 0.9963563084602356
Validation loss: 1.9121639690091532

Epoch: 5| Step: 8
Training loss: 0.7182154059410095
Validation loss: 1.9056325061346895

Epoch: 5| Step: 9
Training loss: 1.6812465190887451
Validation loss: 1.8970110941958684

Epoch: 5| Step: 10
Training loss: 1.9533953666687012
Validation loss: 1.8700425189028504

Epoch: 256| Step: 0
Training loss: 1.137485146522522
Validation loss: 1.8921164556216168

Epoch: 5| Step: 1
Training loss: 1.3574721813201904
Validation loss: 1.897939892225368

Epoch: 5| Step: 2
Training loss: 0.8937762379646301
Validation loss: 1.9021274812759892

Epoch: 5| Step: 3
Training loss: 1.4234678745269775
Validation loss: 1.9287009675015685

Epoch: 5| Step: 4
Training loss: 1.2421973943710327
Validation loss: 1.9405705877529678

Epoch: 5| Step: 5
Training loss: 1.155676007270813
Validation loss: 1.9817844975379206

Epoch: 5| Step: 6
Training loss: 1.7726176977157593
Validation loss: 1.9551842263949815

Epoch: 5| Step: 7
Training loss: 1.379995584487915
Validation loss: 1.912671826219046

Epoch: 5| Step: 8
Training loss: 1.1793434619903564
Validation loss: 1.9266195476696055

Epoch: 5| Step: 9
Training loss: 0.8252254724502563
Validation loss: 1.9484359269501061

Epoch: 5| Step: 10
Training loss: 1.1221592426300049
Validation loss: 1.9170468033000987

Epoch: 257| Step: 0
Training loss: 1.0978121757507324
Validation loss: 1.9121041887549943

Epoch: 5| Step: 1
Training loss: 1.331774353981018
Validation loss: 1.9082145062826013

Epoch: 5| Step: 2
Training loss: 1.243685007095337
Validation loss: 1.8897476965381252

Epoch: 5| Step: 3
Training loss: 1.070344090461731
Validation loss: 1.8716113695534327

Epoch: 5| Step: 4
Training loss: 1.4941760301589966
Validation loss: 1.8876390508426133

Epoch: 5| Step: 5
Training loss: 0.716265082359314
Validation loss: 1.8858160639321933

Epoch: 5| Step: 6
Training loss: 1.7214237451553345
Validation loss: 1.8857156897103915

Epoch: 5| Step: 7
Training loss: 1.2636789083480835
Validation loss: 1.9085286945425055

Epoch: 5| Step: 8
Training loss: 1.2606101036071777
Validation loss: 1.909810378987302

Epoch: 5| Step: 9
Training loss: 0.9940403699874878
Validation loss: 1.9091674204795592

Epoch: 5| Step: 10
Training loss: 0.9500396847724915
Validation loss: 1.9481525498051797

Epoch: 258| Step: 0
Training loss: 1.2982714176177979
Validation loss: 1.9257826266750213

Epoch: 5| Step: 1
Training loss: 0.904231071472168
Validation loss: 1.960610068613483

Epoch: 5| Step: 2
Training loss: 1.4608182907104492
Validation loss: 1.9255686306184339

Epoch: 5| Step: 3
Training loss: 0.9426746368408203
Validation loss: 1.907615473193507

Epoch: 5| Step: 4
Training loss: 1.0172111988067627
Validation loss: 1.9031024004823418

Epoch: 5| Step: 5
Training loss: 1.2437303066253662
Validation loss: 1.9077089832675072

Epoch: 5| Step: 6
Training loss: 1.1113606691360474
Validation loss: 1.898700524401921

Epoch: 5| Step: 7
Training loss: 1.4998605251312256
Validation loss: 1.8649092720400902

Epoch: 5| Step: 8
Training loss: 1.3020139932632446
Validation loss: 1.8805359845520349

Epoch: 5| Step: 9
Training loss: 1.0916087627410889
Validation loss: 1.89544758489055

Epoch: 5| Step: 10
Training loss: 1.1253633499145508
Validation loss: 1.932217631288754

Epoch: 259| Step: 0
Training loss: 0.9602365493774414
Validation loss: 1.9208771951736943

Epoch: 5| Step: 1
Training loss: 0.9897695779800415
Validation loss: 1.8902397937672113

Epoch: 5| Step: 2
Training loss: 1.7348463535308838
Validation loss: 1.8869362877261253

Epoch: 5| Step: 3
Training loss: 0.8954662084579468
Validation loss: 1.9019913173490954

Epoch: 5| Step: 4
Training loss: 1.6169769763946533
Validation loss: 1.9181479536077028

Epoch: 5| Step: 5
Training loss: 1.3911569118499756
Validation loss: 1.9237228465336624

Epoch: 5| Step: 6
Training loss: 0.9751260876655579
Validation loss: 1.919391611570953

Epoch: 5| Step: 7
Training loss: 1.176658272743225
Validation loss: 1.907187443907543

Epoch: 5| Step: 8
Training loss: 1.2556036710739136
Validation loss: 1.909308023350213

Epoch: 5| Step: 9
Training loss: 0.9468389749526978
Validation loss: 1.919703798909341

Epoch: 5| Step: 10
Training loss: 1.1543700695037842
Validation loss: 1.9605893665744412

Epoch: 260| Step: 0
Training loss: 1.915936827659607
Validation loss: 1.9466929974094513

Epoch: 5| Step: 1
Training loss: 0.7314602732658386
Validation loss: 1.921374305602043

Epoch: 5| Step: 2
Training loss: 1.2778724431991577
Validation loss: 1.9183887794453611

Epoch: 5| Step: 3
Training loss: 0.8972920179367065
Validation loss: 1.897567641350531

Epoch: 5| Step: 4
Training loss: 1.0174797773361206
Validation loss: 1.928660237660972

Epoch: 5| Step: 5
Training loss: 1.4303405284881592
Validation loss: 1.9327206534724082

Epoch: 5| Step: 6
Training loss: 1.310821533203125
Validation loss: 1.9189769401345202

Epoch: 5| Step: 7
Training loss: 0.7034069895744324
Validation loss: 1.9255416649644093

Epoch: 5| Step: 8
Training loss: 1.2507611513137817
Validation loss: 1.942293850324487

Epoch: 5| Step: 9
Training loss: 1.5524661540985107
Validation loss: 1.9418803056081135

Epoch: 5| Step: 10
Training loss: 1.2921618223190308
Validation loss: 1.9050483729249688

Epoch: 261| Step: 0
Training loss: 1.1663693189620972
Validation loss: 1.9186429515961678

Epoch: 5| Step: 1
Training loss: 1.2392030954360962
Validation loss: 1.931151601576036

Epoch: 5| Step: 2
Training loss: 0.512811005115509
Validation loss: 1.9210709166783158

Epoch: 5| Step: 3
Training loss: 1.1155474185943604
Validation loss: 1.9079919989391039

Epoch: 5| Step: 4
Training loss: 0.9462800025939941
Validation loss: 1.9060949561416463

Epoch: 5| Step: 5
Training loss: 1.1230785846710205
Validation loss: 1.9097661228590115

Epoch: 5| Step: 6
Training loss: 1.3876755237579346
Validation loss: 1.896970683528531

Epoch: 5| Step: 7
Training loss: 1.635699987411499
Validation loss: 1.9070941927612468

Epoch: 5| Step: 8
Training loss: 1.3820509910583496
Validation loss: 1.8982924645946873

Epoch: 5| Step: 9
Training loss: 0.7947968244552612
Validation loss: 1.8920407320863457

Epoch: 5| Step: 10
Training loss: 1.5917662382125854
Validation loss: 1.9158122231883388

Epoch: 262| Step: 0
Training loss: 1.046687126159668
Validation loss: 1.9061499628969418

Epoch: 5| Step: 1
Training loss: 1.287899374961853
Validation loss: 1.9213571843280588

Epoch: 5| Step: 2
Training loss: 0.9344444274902344
Validation loss: 1.9070741412460164

Epoch: 5| Step: 3
Training loss: 0.9793194532394409
Validation loss: 1.8976882503878685

Epoch: 5| Step: 4
Training loss: 1.2010409832000732
Validation loss: 1.9025924667235343

Epoch: 5| Step: 5
Training loss: 1.2042800188064575
Validation loss: 1.932976266389252

Epoch: 5| Step: 6
Training loss: 1.4992427825927734
Validation loss: 1.9159102491153184

Epoch: 5| Step: 7
Training loss: 1.5839226245880127
Validation loss: 1.8944662835008355

Epoch: 5| Step: 8
Training loss: 1.3057312965393066
Validation loss: 1.895805469123266

Epoch: 5| Step: 9
Training loss: 1.127057433128357
Validation loss: 1.891501795861029

Epoch: 5| Step: 10
Training loss: 0.5670413374900818
Validation loss: 1.8951624106335383

Epoch: 263| Step: 0
Training loss: 1.391361117362976
Validation loss: 1.9261234960248392

Epoch: 5| Step: 1
Training loss: 0.8391298055648804
Validation loss: 1.898761208339404

Epoch: 5| Step: 2
Training loss: 0.9905998110771179
Validation loss: 1.886943268519576

Epoch: 5| Step: 3
Training loss: 0.7862011194229126
Validation loss: 1.9169714220108525

Epoch: 5| Step: 4
Training loss: 0.5913093686103821
Validation loss: 1.9210107698235461

Epoch: 5| Step: 5
Training loss: 1.2017059326171875
Validation loss: 1.9305028479586366

Epoch: 5| Step: 6
Training loss: 1.7261664867401123
Validation loss: 1.9364804644738474

Epoch: 5| Step: 7
Training loss: 1.2064205408096313
Validation loss: 1.9449805111013434

Epoch: 5| Step: 8
Training loss: 0.7841852903366089
Validation loss: 1.9438028322753085

Epoch: 5| Step: 9
Training loss: 1.7456012964248657
Validation loss: 1.9391688390444684

Epoch: 5| Step: 10
Training loss: 1.3897509574890137
Validation loss: 1.9352851606184436

Epoch: 264| Step: 0
Training loss: 0.9878963232040405
Validation loss: 1.913119113573464

Epoch: 5| Step: 1
Training loss: 1.0918205976486206
Validation loss: 1.9222291105537004

Epoch: 5| Step: 2
Training loss: 1.2574282884597778
Validation loss: 1.9086082263659405

Epoch: 5| Step: 3
Training loss: 0.880415141582489
Validation loss: 1.916478254461801

Epoch: 5| Step: 4
Training loss: 1.3596748113632202
Validation loss: 1.873498539770803

Epoch: 5| Step: 5
Training loss: 1.11989426612854
Validation loss: 1.8432539983462262

Epoch: 5| Step: 6
Training loss: 0.9100378155708313
Validation loss: 1.8614492416381836

Epoch: 5| Step: 7
Training loss: 0.8636852502822876
Validation loss: 1.8494086611655451

Epoch: 5| Step: 8
Training loss: 1.2092963457107544
Validation loss: 1.8632783389860583

Epoch: 5| Step: 9
Training loss: 1.5285389423370361
Validation loss: 1.855450681460801

Epoch: 5| Step: 10
Training loss: 1.25856351852417
Validation loss: 1.87304473692371

Epoch: 265| Step: 0
Training loss: 0.9422757029533386
Validation loss: 1.874796308496947

Epoch: 5| Step: 1
Training loss: 1.233563780784607
Validation loss: 1.8994699447385726

Epoch: 5| Step: 2
Training loss: 0.5805391669273376
Validation loss: 1.90807326891089

Epoch: 5| Step: 3
Training loss: 1.2017593383789062
Validation loss: 1.9247118849908151

Epoch: 5| Step: 4
Training loss: 0.9088686108589172
Validation loss: 1.908739823167042

Epoch: 5| Step: 5
Training loss: 1.4166345596313477
Validation loss: 1.9144972960154216

Epoch: 5| Step: 6
Training loss: 1.0172319412231445
Validation loss: 1.9283717678439232

Epoch: 5| Step: 7
Training loss: 1.1754133701324463
Validation loss: 1.9252596491126603

Epoch: 5| Step: 8
Training loss: 1.5609766244888306
Validation loss: 1.8847504674747426

Epoch: 5| Step: 9
Training loss: 1.3929030895233154
Validation loss: 1.911587049884181

Epoch: 5| Step: 10
Training loss: 1.1443301439285278
Validation loss: 1.8900363195327021

Epoch: 266| Step: 0
Training loss: 1.3152903318405151
Validation loss: 1.90538986011218

Epoch: 5| Step: 1
Training loss: 1.172191858291626
Validation loss: 1.901739042292359

Epoch: 5| Step: 2
Training loss: 1.3863182067871094
Validation loss: 1.8820690595975487

Epoch: 5| Step: 3
Training loss: 1.1787217855453491
Validation loss: 1.854878858853412

Epoch: 5| Step: 4
Training loss: 1.5501174926757812
Validation loss: 1.8647342035847325

Epoch: 5| Step: 5
Training loss: 1.2263727188110352
Validation loss: 1.8576461512555358

Epoch: 5| Step: 6
Training loss: 1.1332402229309082
Validation loss: 1.8623425973358976

Epoch: 5| Step: 7
Training loss: 0.654950737953186
Validation loss: 1.8629090234797487

Epoch: 5| Step: 8
Training loss: 1.1433674097061157
Validation loss: 1.8898665533270886

Epoch: 5| Step: 9
Training loss: 0.8797529339790344
Validation loss: 1.9084342807851813

Epoch: 5| Step: 10
Training loss: 1.022222876548767
Validation loss: 1.9199848213503439

Epoch: 267| Step: 0
Training loss: 1.7258918285369873
Validation loss: 1.9266442637289725

Epoch: 5| Step: 1
Training loss: 1.1371454000473022
Validation loss: 1.9183242244105185

Epoch: 5| Step: 2
Training loss: 0.7063565254211426
Validation loss: 1.9263589997445383

Epoch: 5| Step: 3
Training loss: 0.9801076054573059
Validation loss: 1.9135208437519688

Epoch: 5| Step: 4
Training loss: 1.2994368076324463
Validation loss: 1.8816865951784196

Epoch: 5| Step: 5
Training loss: 1.3081793785095215
Validation loss: 1.8919265911143313

Epoch: 5| Step: 6
Training loss: 0.9717631340026855
Validation loss: 1.8852551316702237

Epoch: 5| Step: 7
Training loss: 1.4607629776000977
Validation loss: 1.8766622517698555

Epoch: 5| Step: 8
Training loss: 0.9561986923217773
Validation loss: 1.8595036678416754

Epoch: 5| Step: 9
Training loss: 0.9952162504196167
Validation loss: 1.8585235739267

Epoch: 5| Step: 10
Training loss: 0.9983338713645935
Validation loss: 1.8711835286950553

Epoch: 268| Step: 0
Training loss: 1.0381791591644287
Validation loss: 1.9019164295606716

Epoch: 5| Step: 1
Training loss: 0.8085758090019226
Validation loss: 1.8858060080518004

Epoch: 5| Step: 2
Training loss: 1.3411041498184204
Validation loss: 1.877862968752461

Epoch: 5| Step: 3
Training loss: 1.242361068725586
Validation loss: 1.8616240319385324

Epoch: 5| Step: 4
Training loss: 1.1434149742126465
Validation loss: 1.867187992219002

Epoch: 5| Step: 5
Training loss: 1.1760435104370117
Validation loss: 1.8709288694525277

Epoch: 5| Step: 6
Training loss: 1.1645725965499878
Validation loss: 1.8754531337368874

Epoch: 5| Step: 7
Training loss: 0.9980414509773254
Validation loss: 1.8776232145165885

Epoch: 5| Step: 8
Training loss: 1.458655595779419
Validation loss: 1.883878546376382

Epoch: 5| Step: 9
Training loss: 1.2384283542633057
Validation loss: 1.9110213953961608

Epoch: 5| Step: 10
Training loss: 1.127711296081543
Validation loss: 1.9154381329013455

Epoch: 269| Step: 0
Training loss: 1.1432052850723267
Validation loss: 1.8885587428205757

Epoch: 5| Step: 1
Training loss: 1.782627820968628
Validation loss: 1.863529871868831

Epoch: 5| Step: 2
Training loss: 1.0610864162445068
Validation loss: 1.8855692648118543

Epoch: 5| Step: 3
Training loss: 1.0419909954071045
Validation loss: 1.883046688572053

Epoch: 5| Step: 4
Training loss: 1.126908540725708
Validation loss: 1.8918872751215452

Epoch: 5| Step: 5
Training loss: 1.5778061151504517
Validation loss: 1.888296414447087

Epoch: 5| Step: 6
Training loss: 0.6574223637580872
Validation loss: 1.8847764179270754

Epoch: 5| Step: 7
Training loss: 1.2480064630508423
Validation loss: 1.9039652732110792

Epoch: 5| Step: 8
Training loss: 1.1152446269989014
Validation loss: 1.9143121242523193

Epoch: 5| Step: 9
Training loss: 0.6665157079696655
Validation loss: 1.89550498864984

Epoch: 5| Step: 10
Training loss: 1.1394891738891602
Validation loss: 1.8573996123447214

Epoch: 270| Step: 0
Training loss: 1.1718173027038574
Validation loss: 1.8551689950368737

Epoch: 5| Step: 1
Training loss: 0.9627491235733032
Validation loss: 1.8624614592521422

Epoch: 5| Step: 2
Training loss: 1.2162001132965088
Validation loss: 1.852495237063336

Epoch: 5| Step: 3
Training loss: 0.8571569323539734
Validation loss: 1.8372753820111674

Epoch: 5| Step: 4
Training loss: 0.8696958422660828
Validation loss: 1.84035337099465

Epoch: 5| Step: 5
Training loss: 1.422826886177063
Validation loss: 1.850522082339051

Epoch: 5| Step: 6
Training loss: 0.6152746677398682
Validation loss: 1.8616097332328878

Epoch: 5| Step: 7
Training loss: 1.0624290704727173
Validation loss: 1.8600865743493522

Epoch: 5| Step: 8
Training loss: 1.7406963109970093
Validation loss: 1.853195349375407

Epoch: 5| Step: 9
Training loss: 1.1247689723968506
Validation loss: 1.8826406527591009

Epoch: 5| Step: 10
Training loss: 0.8848057389259338
Validation loss: 1.8770819569146762

Epoch: 271| Step: 0
Training loss: 1.1395987272262573
Validation loss: 1.8776905664833643

Epoch: 5| Step: 1
Training loss: 1.0048691034317017
Validation loss: 1.8949141938199279

Epoch: 5| Step: 2
Training loss: 1.5833053588867188
Validation loss: 1.9033268651654642

Epoch: 5| Step: 3
Training loss: 1.5645946264266968
Validation loss: 1.9021476032913371

Epoch: 5| Step: 4
Training loss: 0.9859838485717773
Validation loss: 1.8899494973562097

Epoch: 5| Step: 5
Training loss: 0.963363766670227
Validation loss: 1.895605973018113

Epoch: 5| Step: 6
Training loss: 1.0602622032165527
Validation loss: 1.9021452088509836

Epoch: 5| Step: 7
Training loss: 0.7371127009391785
Validation loss: 1.883953385455634

Epoch: 5| Step: 8
Training loss: 1.2987228631973267
Validation loss: 1.8796471062526907

Epoch: 5| Step: 9
Training loss: 0.907110333442688
Validation loss: 1.8970022893721057

Epoch: 5| Step: 10
Training loss: 0.5526087880134583
Validation loss: 1.9014322937175792

Epoch: 272| Step: 0
Training loss: 1.2917969226837158
Validation loss: 1.9063984963201708

Epoch: 5| Step: 1
Training loss: 0.8885242342948914
Validation loss: 1.9045116875761299

Epoch: 5| Step: 2
Training loss: 0.8965368270874023
Validation loss: 1.8807612798547233

Epoch: 5| Step: 3
Training loss: 0.8723152875900269
Validation loss: 1.8472790154077674

Epoch: 5| Step: 4
Training loss: 1.2374082803726196
Validation loss: 1.8421008381792294

Epoch: 5| Step: 5
Training loss: 1.2448017597198486
Validation loss: 1.8397846298833047

Epoch: 5| Step: 6
Training loss: 0.8768211603164673
Validation loss: 1.8397876293428483

Epoch: 5| Step: 7
Training loss: 0.8948677182197571
Validation loss: 1.83598917658611

Epoch: 5| Step: 8
Training loss: 1.1723664999008179
Validation loss: 1.855146364499164

Epoch: 5| Step: 9
Training loss: 1.1978236436843872
Validation loss: 1.8377850850423176

Epoch: 5| Step: 10
Training loss: 1.5610486268997192
Validation loss: 1.8707125110010947

Epoch: 273| Step: 0
Training loss: 1.1351783275604248
Validation loss: 1.9077039418681976

Epoch: 5| Step: 1
Training loss: 1.3205368518829346
Validation loss: 1.9243833121433054

Epoch: 5| Step: 2
Training loss: 0.9058691263198853
Validation loss: 1.9018852915815128

Epoch: 5| Step: 3
Training loss: 0.788105845451355
Validation loss: 1.8906352302079559

Epoch: 5| Step: 4
Training loss: 0.9598474502563477
Validation loss: 1.9042632118348153

Epoch: 5| Step: 5
Training loss: 0.7290838360786438
Validation loss: 1.864373045582925

Epoch: 5| Step: 6
Training loss: 0.8120015263557434
Validation loss: 1.8757219673484884

Epoch: 5| Step: 7
Training loss: 1.3126550912857056
Validation loss: 1.8684379875019033

Epoch: 5| Step: 8
Training loss: 1.3071502447128296
Validation loss: 1.8530817288224415

Epoch: 5| Step: 9
Training loss: 1.1745359897613525
Validation loss: 1.8414800308083976

Epoch: 5| Step: 10
Training loss: 1.3620728254318237
Validation loss: 1.8443345305740193

Epoch: 274| Step: 0
Training loss: 1.1465760469436646
Validation loss: 1.8526949895325528

Epoch: 5| Step: 1
Training loss: 1.09214186668396
Validation loss: 1.823244515285697

Epoch: 5| Step: 2
Training loss: 0.7221566438674927
Validation loss: 1.8476525724575084

Epoch: 5| Step: 3
Training loss: 1.1414655447006226
Validation loss: 1.8708372295543712

Epoch: 5| Step: 4
Training loss: 1.1449649333953857
Validation loss: 1.8751287550054572

Epoch: 5| Step: 5
Training loss: 1.121399164199829
Validation loss: 1.8829695076070807

Epoch: 5| Step: 6
Training loss: 0.8985950350761414
Validation loss: 1.8791966745930333

Epoch: 5| Step: 7
Training loss: 1.3346643447875977
Validation loss: 1.886558755751579

Epoch: 5| Step: 8
Training loss: 0.93670654296875
Validation loss: 1.9117845181495912

Epoch: 5| Step: 9
Training loss: 1.031313419342041
Validation loss: 1.915502973782119

Epoch: 5| Step: 10
Training loss: 1.2408849000930786
Validation loss: 1.9238645133151804

Epoch: 275| Step: 0
Training loss: 1.198876142501831
Validation loss: 1.9244978043340868

Epoch: 5| Step: 1
Training loss: 1.2086408138275146
Validation loss: 1.900650607642307

Epoch: 5| Step: 2
Training loss: 0.7815166711807251
Validation loss: 1.8625669505006524

Epoch: 5| Step: 3
Training loss: 0.6864263415336609
Validation loss: 1.848432949794236

Epoch: 5| Step: 4
Training loss: 1.0116335153579712
Validation loss: 1.8364219383526874

Epoch: 5| Step: 5
Training loss: 1.2244809865951538
Validation loss: 1.8042975061683244

Epoch: 5| Step: 6
Training loss: 0.785108208656311
Validation loss: 1.8157385472328431

Epoch: 5| Step: 7
Training loss: 1.129196047782898
Validation loss: 1.8084340454429708

Epoch: 5| Step: 8
Training loss: 1.0502668619155884
Validation loss: 1.7696681561008576

Epoch: 5| Step: 9
Training loss: 1.3739819526672363
Validation loss: 1.7950968537279355

Epoch: 5| Step: 10
Training loss: 1.3257509469985962
Validation loss: 1.8097255050495107

Epoch: 276| Step: 0
Training loss: 1.1894261837005615
Validation loss: 1.8174077721052273

Epoch: 5| Step: 1
Training loss: 1.1099908351898193
Validation loss: 1.8454007346143004

Epoch: 5| Step: 2
Training loss: 1.0146420001983643
Validation loss: 1.8633602857589722

Epoch: 5| Step: 3
Training loss: 1.0296502113342285
Validation loss: 1.8609186474994948

Epoch: 5| Step: 4
Training loss: 0.6831411123275757
Validation loss: 1.8628457310379192

Epoch: 5| Step: 5
Training loss: 0.9414752721786499
Validation loss: 1.8824874188310357

Epoch: 5| Step: 6
Training loss: 1.334441065788269
Validation loss: 1.889092855556037

Epoch: 5| Step: 7
Training loss: 0.9026883840560913
Validation loss: 1.8983121251547208

Epoch: 5| Step: 8
Training loss: 1.227109670639038
Validation loss: 1.9095241151830202

Epoch: 5| Step: 9
Training loss: 0.9145714640617371
Validation loss: 1.908727950947259

Epoch: 5| Step: 10
Training loss: 1.1790761947631836
Validation loss: 1.891241063353836

Epoch: 277| Step: 0
Training loss: 1.2208601236343384
Validation loss: 1.8580546917453888

Epoch: 5| Step: 1
Training loss: 0.9337301254272461
Validation loss: 1.8395996401386876

Epoch: 5| Step: 2
Training loss: 1.184201955795288
Validation loss: 1.8512637333203388

Epoch: 5| Step: 3
Training loss: 1.0172761678695679
Validation loss: 1.8371934762565039

Epoch: 5| Step: 4
Training loss: 0.5542075037956238
Validation loss: 1.8400462160828293

Epoch: 5| Step: 5
Training loss: 0.9538407325744629
Validation loss: 1.8433283580246793

Epoch: 5| Step: 6
Training loss: 1.256793737411499
Validation loss: 1.8516480307425223

Epoch: 5| Step: 7
Training loss: 0.8016380071640015
Validation loss: 1.856495734184019

Epoch: 5| Step: 8
Training loss: 0.7341222763061523
Validation loss: 1.872197126829496

Epoch: 5| Step: 9
Training loss: 1.4871947765350342
Validation loss: 1.9081140295151742

Epoch: 5| Step: 10
Training loss: 1.260594129562378
Validation loss: 1.9016252281845256

Epoch: 278| Step: 0
Training loss: 0.9662979245185852
Validation loss: 1.897588071002755

Epoch: 5| Step: 1
Training loss: 1.3988416194915771
Validation loss: 1.869553683906473

Epoch: 5| Step: 2
Training loss: 1.5952401161193848
Validation loss: 1.8782604907148628

Epoch: 5| Step: 3
Training loss: 0.8722914457321167
Validation loss: 1.8506594357951995

Epoch: 5| Step: 4
Training loss: 0.9968055486679077
Validation loss: 1.8558852339303622

Epoch: 5| Step: 5
Training loss: 0.6891432404518127
Validation loss: 1.8626741036292045

Epoch: 5| Step: 6
Training loss: 0.8778042793273926
Validation loss: 1.8811128011313818

Epoch: 5| Step: 7
Training loss: 0.9110628366470337
Validation loss: 1.8641292818130986

Epoch: 5| Step: 8
Training loss: 0.944410502910614
Validation loss: 1.8539592860847391

Epoch: 5| Step: 9
Training loss: 0.9582141637802124
Validation loss: 1.8441860868084816

Epoch: 5| Step: 10
Training loss: 0.8820093870162964
Validation loss: 1.8280713814561085

Epoch: 279| Step: 0
Training loss: 1.0218183994293213
Validation loss: 1.840545182586998

Epoch: 5| Step: 1
Training loss: 1.2316575050354004
Validation loss: 1.8524863707121981

Epoch: 5| Step: 2
Training loss: 0.993698239326477
Validation loss: 1.8322363027962305

Epoch: 5| Step: 3
Training loss: 1.0304090976715088
Validation loss: 1.8416136977493123

Epoch: 5| Step: 4
Training loss: 0.7884216904640198
Validation loss: 1.8430293144718293

Epoch: 5| Step: 5
Training loss: 0.9904683232307434
Validation loss: 1.8649950335102696

Epoch: 5| Step: 6
Training loss: 1.1681487560272217
Validation loss: 1.86574847467484

Epoch: 5| Step: 7
Training loss: 0.928369402885437
Validation loss: 1.8660172390681442

Epoch: 5| Step: 8
Training loss: 1.3637957572937012
Validation loss: 1.8806631231820712

Epoch: 5| Step: 9
Training loss: 0.7675183415412903
Validation loss: 1.9073860542748564

Epoch: 5| Step: 10
Training loss: 1.0582716464996338
Validation loss: 1.893302773916593

Epoch: 280| Step: 0
Training loss: 0.9778364300727844
Validation loss: 1.850718839194185

Epoch: 5| Step: 1
Training loss: 1.342827558517456
Validation loss: 1.8681789290520452

Epoch: 5| Step: 2
Training loss: 1.366874098777771
Validation loss: 1.854325698268029

Epoch: 5| Step: 3
Training loss: 1.0025259256362915
Validation loss: 1.8607417447592622

Epoch: 5| Step: 4
Training loss: 0.8399263620376587
Validation loss: 1.8299788146890619

Epoch: 5| Step: 5
Training loss: 0.7713726758956909
Validation loss: 1.8427670668530207

Epoch: 5| Step: 6
Training loss: 0.6264102458953857
Validation loss: 1.8471642066073675

Epoch: 5| Step: 7
Training loss: 1.1836397647857666
Validation loss: 1.8508545032111547

Epoch: 5| Step: 8
Training loss: 0.687932014465332
Validation loss: 1.8613477932509555

Epoch: 5| Step: 9
Training loss: 1.0760068893432617
Validation loss: 1.8789441790632022

Epoch: 5| Step: 10
Training loss: 1.2552720308303833
Validation loss: 1.8767521150650517

Epoch: 281| Step: 0
Training loss: 1.3889275789260864
Validation loss: 1.8381374087384952

Epoch: 5| Step: 1
Training loss: 0.7449485659599304
Validation loss: 1.8338628558702366

Epoch: 5| Step: 2
Training loss: 0.8354486227035522
Validation loss: 1.8551836949522778

Epoch: 5| Step: 3
Training loss: 1.0089384317398071
Validation loss: 1.8340498298727057

Epoch: 5| Step: 4
Training loss: 1.5859787464141846
Validation loss: 1.8450871923918366

Epoch: 5| Step: 5
Training loss: 0.728731632232666
Validation loss: 1.8311711972759617

Epoch: 5| Step: 6
Training loss: 0.7599108815193176
Validation loss: 1.8524803115475563

Epoch: 5| Step: 7
Training loss: 0.9109399914741516
Validation loss: 1.8377134799957275

Epoch: 5| Step: 8
Training loss: 0.5596548318862915
Validation loss: 1.8457294125710764

Epoch: 5| Step: 9
Training loss: 1.190985083580017
Validation loss: 1.8286269839091966

Epoch: 5| Step: 10
Training loss: 1.2916884422302246
Validation loss: 1.8256728367138935

Epoch: 282| Step: 0
Training loss: 0.998925507068634
Validation loss: 1.828660072818879

Epoch: 5| Step: 1
Training loss: 1.0464200973510742
Validation loss: 1.835304461499696

Epoch: 5| Step: 2
Training loss: 0.5933828949928284
Validation loss: 1.8188156594512284

Epoch: 5| Step: 3
Training loss: 0.8481438755989075
Validation loss: 1.8410550394365865

Epoch: 5| Step: 4
Training loss: 0.8127368688583374
Validation loss: 1.8720916932629001

Epoch: 5| Step: 5
Training loss: 0.869009792804718
Validation loss: 1.8630723222609489

Epoch: 5| Step: 6
Training loss: 0.8665680885314941
Validation loss: 1.855294232727379

Epoch: 5| Step: 7
Training loss: 0.9531564712524414
Validation loss: 1.8529681069876558

Epoch: 5| Step: 8
Training loss: 1.309106707572937
Validation loss: 1.8740587106315039

Epoch: 5| Step: 9
Training loss: 1.333965539932251
Validation loss: 1.8731983515524095

Epoch: 5| Step: 10
Training loss: 1.1321007013320923
Validation loss: 1.8692527227504279

Epoch: 283| Step: 0
Training loss: 1.0564045906066895
Validation loss: 1.8597134851640271

Epoch: 5| Step: 1
Training loss: 1.1780647039413452
Validation loss: 1.8592803657695811

Epoch: 5| Step: 2
Training loss: 1.183681607246399
Validation loss: 1.8161028700490152

Epoch: 5| Step: 3
Training loss: 1.124993920326233
Validation loss: 1.8147907474989533

Epoch: 5| Step: 4
Training loss: 0.8599697351455688
Validation loss: 1.8426408075517224

Epoch: 5| Step: 5
Training loss: 0.9217960238456726
Validation loss: 1.852020748199955

Epoch: 5| Step: 6
Training loss: 1.051900863647461
Validation loss: 1.9068523478764359

Epoch: 5| Step: 7
Training loss: 0.8274347186088562
Validation loss: 1.9049104541860602

Epoch: 5| Step: 8
Training loss: 0.6836735606193542
Validation loss: 1.8402338168954337

Epoch: 5| Step: 9
Training loss: 0.920663058757782
Validation loss: 1.8415476378574167

Epoch: 5| Step: 10
Training loss: 0.9972051978111267
Validation loss: 1.8709835365254393

Epoch: 284| Step: 0
Training loss: 1.4001597166061401
Validation loss: 1.8785798882925382

Epoch: 5| Step: 1
Training loss: 1.4271644353866577
Validation loss: 1.8851531782457907

Epoch: 5| Step: 2
Training loss: 1.0116808414459229
Validation loss: 1.8101114226925759

Epoch: 5| Step: 3
Training loss: 1.1292344331741333
Validation loss: 1.8355712762442968

Epoch: 5| Step: 4
Training loss: 1.0291812419891357
Validation loss: 1.9294040510731358

Epoch: 5| Step: 5
Training loss: 1.188403844833374
Validation loss: 1.977665945406883

Epoch: 5| Step: 6
Training loss: 1.2901887893676758
Validation loss: 1.970968182368945

Epoch: 5| Step: 7
Training loss: 0.8004819750785828
Validation loss: 1.892257907057321

Epoch: 5| Step: 8
Training loss: 1.017683982849121
Validation loss: 1.8569614297600203

Epoch: 5| Step: 9
Training loss: 0.9589334726333618
Validation loss: 1.8231302576680337

Epoch: 5| Step: 10
Training loss: 1.2121686935424805
Validation loss: 1.8564400506275955

Epoch: 285| Step: 0
Training loss: 0.5950647592544556
Validation loss: 1.8843660226432226

Epoch: 5| Step: 1
Training loss: 0.7741308212280273
Validation loss: 1.8991501126238095

Epoch: 5| Step: 2
Training loss: 0.9810343980789185
Validation loss: 1.8655876357068297

Epoch: 5| Step: 3
Training loss: 0.6837605237960815
Validation loss: 1.8558975701691003

Epoch: 5| Step: 4
Training loss: 1.1646873950958252
Validation loss: 1.8859203169422765

Epoch: 5| Step: 5
Training loss: 1.3656044006347656
Validation loss: 1.9053786352116575

Epoch: 5| Step: 6
Training loss: 1.3391507863998413
Validation loss: 1.8799793861245597

Epoch: 5| Step: 7
Training loss: 0.9352127313613892
Validation loss: 1.847400060264013

Epoch: 5| Step: 8
Training loss: 1.2074569463729858
Validation loss: 1.8321013424986152

Epoch: 5| Step: 9
Training loss: 1.1951720714569092
Validation loss: 1.8478103094203497

Epoch: 5| Step: 10
Training loss: 0.941295862197876
Validation loss: 1.8220590827285603

Epoch: 286| Step: 0
Training loss: 1.1020970344543457
Validation loss: 1.8267252188856884

Epoch: 5| Step: 1
Training loss: 0.8734205365180969
Validation loss: 1.8209488802058722

Epoch: 5| Step: 2
Training loss: 1.1053416728973389
Validation loss: 1.8403646446043445

Epoch: 5| Step: 3
Training loss: 1.3644293546676636
Validation loss: 1.8403116900433776

Epoch: 5| Step: 4
Training loss: 0.953574538230896
Validation loss: 1.8394224079706336

Epoch: 5| Step: 5
Training loss: 0.9161518812179565
Validation loss: 1.8503438913693993

Epoch: 5| Step: 6
Training loss: 0.429709255695343
Validation loss: 1.8672832109594857

Epoch: 5| Step: 7
Training loss: 1.0360792875289917
Validation loss: 1.8832226671198362

Epoch: 5| Step: 8
Training loss: 1.4457614421844482
Validation loss: 1.9327820565110894

Epoch: 5| Step: 9
Training loss: 1.185183048248291
Validation loss: 1.9731628997351534

Epoch: 5| Step: 10
Training loss: 0.44907867908477783
Validation loss: 1.9098784744098622

Epoch: 287| Step: 0
Training loss: 0.5860460996627808
Validation loss: 1.8842030955899147

Epoch: 5| Step: 1
Training loss: 1.1547129154205322
Validation loss: 1.8526878690206876

Epoch: 5| Step: 2
Training loss: 1.2308475971221924
Validation loss: 1.8389229172019548

Epoch: 5| Step: 3
Training loss: 0.8892871737480164
Validation loss: 1.8452587717322892

Epoch: 5| Step: 4
Training loss: 0.7526952028274536
Validation loss: 1.8464379079880253

Epoch: 5| Step: 5
Training loss: 1.1920779943466187
Validation loss: 1.8228484789530437

Epoch: 5| Step: 6
Training loss: 1.1574642658233643
Validation loss: 1.7913811937455209

Epoch: 5| Step: 7
Training loss: 0.9459058046340942
Validation loss: 1.8585146998846402

Epoch: 5| Step: 8
Training loss: 1.0120363235473633
Validation loss: 1.8894549544139574

Epoch: 5| Step: 9
Training loss: 1.3164414167404175
Validation loss: 1.9684631927039034

Epoch: 5| Step: 10
Training loss: 1.1740161180496216
Validation loss: 1.99740913221913

Epoch: 288| Step: 0
Training loss: 0.9731661081314087
Validation loss: 1.898657892339973

Epoch: 5| Step: 1
Training loss: 1.084648847579956
Validation loss: 1.8441815113508573

Epoch: 5| Step: 2
Training loss: 1.153582215309143
Validation loss: 1.8100682766206804

Epoch: 5| Step: 3
Training loss: 1.085078477859497
Validation loss: 1.8248192456460768

Epoch: 5| Step: 4
Training loss: 1.0559232234954834
Validation loss: 1.830739007201246

Epoch: 5| Step: 5
Training loss: 1.058811068534851
Validation loss: 1.8221921049138552

Epoch: 5| Step: 6
Training loss: 0.8541103601455688
Validation loss: 1.84443703902665

Epoch: 5| Step: 7
Training loss: 1.1423507928848267
Validation loss: 1.824514958166307

Epoch: 5| Step: 8
Training loss: 0.697102963924408
Validation loss: 1.8509912234480663

Epoch: 5| Step: 9
Training loss: 0.5728882551193237
Validation loss: 1.851663048549365

Epoch: 5| Step: 10
Training loss: 0.9708220362663269
Validation loss: 1.867198105781309

Epoch: 289| Step: 0
Training loss: 1.0014852285385132
Validation loss: 1.866533887001776

Epoch: 5| Step: 1
Training loss: 0.8885126113891602
Validation loss: 1.8422153419063938

Epoch: 5| Step: 2
Training loss: 0.6526233553886414
Validation loss: 1.8075295776449225

Epoch: 5| Step: 3
Training loss: 1.0102999210357666
Validation loss: 1.8106345079278434

Epoch: 5| Step: 4
Training loss: 1.1589319705963135
Validation loss: 1.819863168142175

Epoch: 5| Step: 5
Training loss: 1.491136908531189
Validation loss: 1.812000500258579

Epoch: 5| Step: 6
Training loss: 0.9281477928161621
Validation loss: 1.8043404522762503

Epoch: 5| Step: 7
Training loss: 0.7046321034431458
Validation loss: 1.8403823811520812

Epoch: 5| Step: 8
Training loss: 0.7335246205329895
Validation loss: 1.8403021212547057

Epoch: 5| Step: 9
Training loss: 0.8970174789428711
Validation loss: 1.8481607514043008

Epoch: 5| Step: 10
Training loss: 0.8119158744812012
Validation loss: 1.8466519181446364

Epoch: 290| Step: 0
Training loss: 0.9503018260002136
Validation loss: 1.8677400619752946

Epoch: 5| Step: 1
Training loss: 0.9627631902694702
Validation loss: 1.8306338799897062

Epoch: 5| Step: 2
Training loss: 1.135854959487915
Validation loss: 1.8579222617610809

Epoch: 5| Step: 3
Training loss: 1.1071584224700928
Validation loss: 1.83583410709135

Epoch: 5| Step: 4
Training loss: 0.4762190878391266
Validation loss: 1.8116877437919698

Epoch: 5| Step: 5
Training loss: 0.6445655822753906
Validation loss: 1.8284513809347664

Epoch: 5| Step: 6
Training loss: 0.7700491547584534
Validation loss: 1.814120061935917

Epoch: 5| Step: 7
Training loss: 1.0869770050048828
Validation loss: 1.8128835642209618

Epoch: 5| Step: 8
Training loss: 0.5428014993667603
Validation loss: 1.8155147234598796

Epoch: 5| Step: 9
Training loss: 0.9741403460502625
Validation loss: 1.80385559861378

Epoch: 5| Step: 10
Training loss: 1.4097305536270142
Validation loss: 1.8042569609098538

Epoch: 291| Step: 0
Training loss: 0.5556873083114624
Validation loss: 1.810440888968847

Epoch: 5| Step: 1
Training loss: 1.2751914262771606
Validation loss: 1.7756360179634505

Epoch: 5| Step: 2
Training loss: 1.3001136779785156
Validation loss: 1.7901993900217035

Epoch: 5| Step: 3
Training loss: 1.1314654350280762
Validation loss: 1.8051138436922463

Epoch: 5| Step: 4
Training loss: 0.36932915449142456
Validation loss: 1.7902379394859396

Epoch: 5| Step: 5
Training loss: 0.6737133264541626
Validation loss: 1.795833178745803

Epoch: 5| Step: 6
Training loss: 0.926672637462616
Validation loss: 1.7922643217989194

Epoch: 5| Step: 7
Training loss: 0.7371959686279297
Validation loss: 1.7787853543476393

Epoch: 5| Step: 8
Training loss: 0.8325842022895813
Validation loss: 1.807809422093053

Epoch: 5| Step: 9
Training loss: 1.1579667329788208
Validation loss: 1.8347287934313539

Epoch: 5| Step: 10
Training loss: 0.9309790730476379
Validation loss: 1.8231940333561232

Epoch: 292| Step: 0
Training loss: 0.9704042673110962
Validation loss: 1.8203517454926685

Epoch: 5| Step: 1
Training loss: 1.1027597188949585
Validation loss: 1.8006208994055306

Epoch: 5| Step: 2
Training loss: 1.0316219329833984
Validation loss: 1.8297154288138113

Epoch: 5| Step: 3
Training loss: 0.6541159152984619
Validation loss: 1.8051248083832443

Epoch: 5| Step: 4
Training loss: 0.7115722894668579
Validation loss: 1.8233936486705657

Epoch: 5| Step: 5
Training loss: 0.85670006275177
Validation loss: 1.8418112416421213

Epoch: 5| Step: 6
Training loss: 1.0332070589065552
Validation loss: 1.846452602776148

Epoch: 5| Step: 7
Training loss: 0.6833099126815796
Validation loss: 1.8461869185970676

Epoch: 5| Step: 8
Training loss: 1.1507627964019775
Validation loss: 1.8147062960491385

Epoch: 5| Step: 9
Training loss: 0.8044260740280151
Validation loss: 1.787021799754071

Epoch: 5| Step: 10
Training loss: 1.0056754350662231
Validation loss: 1.8021756179871098

Epoch: 293| Step: 0
Training loss: 0.8429194688796997
Validation loss: 1.8060117844612367

Epoch: 5| Step: 1
Training loss: 1.0552219152450562
Validation loss: 1.8096069033427904

Epoch: 5| Step: 2
Training loss: 0.9943963289260864
Validation loss: 1.8100252330944102

Epoch: 5| Step: 3
Training loss: 1.002558946609497
Validation loss: 1.8128697602979598

Epoch: 5| Step: 4
Training loss: 0.7818581461906433
Validation loss: 1.8037847857321463

Epoch: 5| Step: 5
Training loss: 0.818141758441925
Validation loss: 1.8446194843579364

Epoch: 5| Step: 6
Training loss: 0.9323312044143677
Validation loss: 1.8525678919207664

Epoch: 5| Step: 7
Training loss: 0.6907623410224915
Validation loss: 1.848433445858699

Epoch: 5| Step: 8
Training loss: 0.9147777557373047
Validation loss: 1.8544210695451306

Epoch: 5| Step: 9
Training loss: 0.8997604250907898
Validation loss: 1.8383798958152853

Epoch: 5| Step: 10
Training loss: 1.1072442531585693
Validation loss: 1.81826574443489

Epoch: 294| Step: 0
Training loss: 0.9132431745529175
Validation loss: 1.8322734627672421

Epoch: 5| Step: 1
Training loss: 1.1128298044204712
Validation loss: 1.8267553108994679

Epoch: 5| Step: 2
Training loss: 0.9282585978507996
Validation loss: 1.7989808077453284

Epoch: 5| Step: 3
Training loss: 0.7319964170455933
Validation loss: 1.7876369132790515

Epoch: 5| Step: 4
Training loss: 0.7556068301200867
Validation loss: 1.7865021485154347

Epoch: 5| Step: 5
Training loss: 1.1173146963119507
Validation loss: 1.7760510239549863

Epoch: 5| Step: 6
Training loss: 0.9970465898513794
Validation loss: 1.8063878500333397

Epoch: 5| Step: 7
Training loss: 1.4657059907913208
Validation loss: 1.82790409621372

Epoch: 5| Step: 8
Training loss: 0.43827128410339355
Validation loss: 1.847073342210503

Epoch: 5| Step: 9
Training loss: 0.7467347383499146
Validation loss: 1.8185192308118265

Epoch: 5| Step: 10
Training loss: 0.925804078578949
Validation loss: 1.786407539921422

Epoch: 295| Step: 0
Training loss: 0.7817140817642212
Validation loss: 1.778244637673901

Epoch: 5| Step: 1
Training loss: 0.4302748739719391
Validation loss: 1.7786889512051818

Epoch: 5| Step: 2
Training loss: 0.8416019678115845
Validation loss: 1.7929949580982167

Epoch: 5| Step: 3
Training loss: 0.9516000747680664
Validation loss: 1.7900887676464614

Epoch: 5| Step: 4
Training loss: 0.6216140985488892
Validation loss: 1.817746663606295

Epoch: 5| Step: 5
Training loss: 1.2767388820648193
Validation loss: 1.8581731960337649

Epoch: 5| Step: 6
Training loss: 0.9512945413589478
Validation loss: 1.8710821264533586

Epoch: 5| Step: 7
Training loss: 0.9537514448165894
Validation loss: 1.9174151548775293

Epoch: 5| Step: 8
Training loss: 0.8443297147750854
Validation loss: 1.8962659194905271

Epoch: 5| Step: 9
Training loss: 1.2007005214691162
Validation loss: 1.8771289112747356

Epoch: 5| Step: 10
Training loss: 1.0355656147003174
Validation loss: 1.8466610575235018

Epoch: 296| Step: 0
Training loss: 0.45104607939720154
Validation loss: 1.8106003166526876

Epoch: 5| Step: 1
Training loss: 1.076237440109253
Validation loss: 1.7885145525778494

Epoch: 5| Step: 2
Training loss: 0.750519871711731
Validation loss: 1.756717510120843

Epoch: 5| Step: 3
Training loss: 0.5055816173553467
Validation loss: 1.745748305833468

Epoch: 5| Step: 4
Training loss: 0.7925753593444824
Validation loss: 1.754666422003059

Epoch: 5| Step: 5
Training loss: 0.570792019367218
Validation loss: 1.7516555145222654

Epoch: 5| Step: 6
Training loss: 0.9994214177131653
Validation loss: 1.7436843892579437

Epoch: 5| Step: 7
Training loss: 0.9223560094833374
Validation loss: 1.7584214761692991

Epoch: 5| Step: 8
Training loss: 1.3437811136245728
Validation loss: 1.7925611144752913

Epoch: 5| Step: 9
Training loss: 1.3464314937591553
Validation loss: 1.7882721321557158

Epoch: 5| Step: 10
Training loss: 0.932854175567627
Validation loss: 1.7868154407829366

Epoch: 297| Step: 0
Training loss: 1.0814257860183716
Validation loss: 1.7912880835994598

Epoch: 5| Step: 1
Training loss: 0.764741063117981
Validation loss: 1.8006743102945306

Epoch: 5| Step: 2
Training loss: 0.7086670398712158
Validation loss: 1.818672969777097

Epoch: 5| Step: 3
Training loss: 0.9483402967453003
Validation loss: 1.7944150406827208

Epoch: 5| Step: 4
Training loss: 0.8906303644180298
Validation loss: 1.8029636234365485

Epoch: 5| Step: 5
Training loss: 1.0253149271011353
Validation loss: 1.793275603684046

Epoch: 5| Step: 6
Training loss: 0.8220890760421753
Validation loss: 1.7572094842951784

Epoch: 5| Step: 7
Training loss: 0.782514214515686
Validation loss: 1.7559007265234505

Epoch: 5| Step: 8
Training loss: 0.69536292552948
Validation loss: 1.773727782310978

Epoch: 5| Step: 9
Training loss: 0.9245556592941284
Validation loss: 1.762937036893701

Epoch: 5| Step: 10
Training loss: 0.8354311585426331
Validation loss: 1.7515825686916229

Epoch: 298| Step: 0
Training loss: 0.600400984287262
Validation loss: 1.7361601783383278

Epoch: 5| Step: 1
Training loss: 1.0102561712265015
Validation loss: 1.8007570364141976

Epoch: 5| Step: 2
Training loss: 1.0381911993026733
Validation loss: 1.7983650917647986

Epoch: 5| Step: 3
Training loss: 0.7922071218490601
Validation loss: 1.7743130755680863

Epoch: 5| Step: 4
Training loss: 0.8792959451675415
Validation loss: 1.7626952253362185

Epoch: 5| Step: 5
Training loss: 0.6963698267936707
Validation loss: 1.7720278257964759

Epoch: 5| Step: 6
Training loss: 0.9213425517082214
Validation loss: 1.773968231293463

Epoch: 5| Step: 7
Training loss: 0.8144460916519165
Validation loss: 1.7710518785702285

Epoch: 5| Step: 8
Training loss: 0.8469853401184082
Validation loss: 1.768257156495125

Epoch: 5| Step: 9
Training loss: 0.9835523366928101
Validation loss: 1.7789568580606931

Epoch: 5| Step: 10
Training loss: 1.2636778354644775
Validation loss: 1.7803333151725032

Epoch: 299| Step: 0
Training loss: 0.8144213557243347
Validation loss: 1.8303358913749777

Epoch: 5| Step: 1
Training loss: 0.8575372695922852
Validation loss: 1.8160322314949446

Epoch: 5| Step: 2
Training loss: 0.760564386844635
Validation loss: 1.8059441530576317

Epoch: 5| Step: 3
Training loss: 0.5929149985313416
Validation loss: 1.804231136075912

Epoch: 5| Step: 4
Training loss: 1.1513527631759644
Validation loss: 1.7848910708581247

Epoch: 5| Step: 5
Training loss: 0.7395827770233154
Validation loss: 1.7778118015617452

Epoch: 5| Step: 6
Training loss: 1.2335772514343262
Validation loss: 1.766531446928619

Epoch: 5| Step: 7
Training loss: 1.1049648523330688
Validation loss: 1.7545780853558612

Epoch: 5| Step: 8
Training loss: 0.7469335794448853
Validation loss: 1.7675763753152662

Epoch: 5| Step: 9
Training loss: 1.0049397945404053
Validation loss: 1.7702289960717643

Epoch: 5| Step: 10
Training loss: 0.6938513517379761
Validation loss: 1.7936134543470157

Epoch: 300| Step: 0
Training loss: 1.0657533407211304
Validation loss: 1.8140747624058877

Epoch: 5| Step: 1
Training loss: 1.1857006549835205
Validation loss: 1.8103026126020698

Epoch: 5| Step: 2
Training loss: 0.6940239071846008
Validation loss: 1.7957461546826106

Epoch: 5| Step: 3
Training loss: 0.9166265726089478
Validation loss: 1.784411576486403

Epoch: 5| Step: 4
Training loss: 0.7628418803215027
Validation loss: 1.7457932349174254

Epoch: 5| Step: 5
Training loss: 0.5388914346694946
Validation loss: 1.744937817255656

Epoch: 5| Step: 6
Training loss: 0.9908100962638855
Validation loss: 1.7594614849295667

Epoch: 5| Step: 7
Training loss: 0.45504388213157654
Validation loss: 1.7615543321896625

Epoch: 5| Step: 8
Training loss: 0.8587004542350769
Validation loss: 1.755204200744629

Epoch: 5| Step: 9
Training loss: 1.118615984916687
Validation loss: 1.7353547183416222

Epoch: 5| Step: 10
Training loss: 0.7750486135482788
Validation loss: 1.7395829910873084

Epoch: 301| Step: 0
Training loss: 0.5218769907951355
Validation loss: 1.7667635922790856

Epoch: 5| Step: 1
Training loss: 0.7954121828079224
Validation loss: 1.7467415102066532

Epoch: 5| Step: 2
Training loss: 0.9854717254638672
Validation loss: 1.757543840715962

Epoch: 5| Step: 3
Training loss: 0.9685875177383423
Validation loss: 1.773388019172094

Epoch: 5| Step: 4
Training loss: 0.571602463722229
Validation loss: 1.755095096044643

Epoch: 5| Step: 5
Training loss: 0.95454341173172
Validation loss: 1.7703240789392942

Epoch: 5| Step: 6
Training loss: 0.7614232897758484
Validation loss: 1.7691713738185104

Epoch: 5| Step: 7
Training loss: 0.8322078585624695
Validation loss: 1.7928518287597164

Epoch: 5| Step: 8
Training loss: 1.1449609994888306
Validation loss: 1.7726267819763513

Epoch: 5| Step: 9
Training loss: 0.7045387625694275
Validation loss: 1.7949010659289617

Epoch: 5| Step: 10
Training loss: 0.9771237969398499
Validation loss: 1.803278212906212

Epoch: 302| Step: 0
Training loss: 0.46908140182495117
Validation loss: 1.7843008182382072

Epoch: 5| Step: 1
Training loss: 1.2936897277832031
Validation loss: 1.7897334329543575

Epoch: 5| Step: 2
Training loss: 0.5613076090812683
Validation loss: 1.7710482766551356

Epoch: 5| Step: 3
Training loss: 0.615293025970459
Validation loss: 1.747852765103822

Epoch: 5| Step: 4
Training loss: 0.929661750793457
Validation loss: 1.7769954371195968

Epoch: 5| Step: 5
Training loss: 0.5775500535964966
Validation loss: 1.7522929829935874

Epoch: 5| Step: 6
Training loss: 0.9671961665153503
Validation loss: 1.7417038615031908

Epoch: 5| Step: 7
Training loss: 0.5581965446472168
Validation loss: 1.7669870699605634

Epoch: 5| Step: 8
Training loss: 1.02248215675354
Validation loss: 1.7558158930911814

Epoch: 5| Step: 9
Training loss: 1.0262823104858398
Validation loss: 1.7416401960516488

Epoch: 5| Step: 10
Training loss: 1.0176533460617065
Validation loss: 1.7744962976824852

Epoch: 303| Step: 0
Training loss: 0.7379298210144043
Validation loss: 1.735772544337857

Epoch: 5| Step: 1
Training loss: 0.647948145866394
Validation loss: 1.7299655175978137

Epoch: 5| Step: 2
Training loss: 0.567638099193573
Validation loss: 1.7323653172421198

Epoch: 5| Step: 3
Training loss: 0.769641101360321
Validation loss: 1.7308347878917572

Epoch: 5| Step: 4
Training loss: 0.9043736457824707
Validation loss: 1.7645653588797456

Epoch: 5| Step: 5
Training loss: 0.7900904417037964
Validation loss: 1.733151578134106

Epoch: 5| Step: 6
Training loss: 0.7985789775848389
Validation loss: 1.7583574171989196

Epoch: 5| Step: 7
Training loss: 1.1160269975662231
Validation loss: 1.807012528501531

Epoch: 5| Step: 8
Training loss: 0.7635814547538757
Validation loss: 1.8611194625977547

Epoch: 5| Step: 9
Training loss: 0.998900294303894
Validation loss: 1.8586754209251815

Epoch: 5| Step: 10
Training loss: 1.0804998874664307
Validation loss: 1.8414171241944837

Epoch: 304| Step: 0
Training loss: 1.150790810585022
Validation loss: 1.847103976434277

Epoch: 5| Step: 1
Training loss: 0.841820240020752
Validation loss: 1.8221591441862044

Epoch: 5| Step: 2
Training loss: 0.6584857702255249
Validation loss: 1.8164764732442877

Epoch: 5| Step: 3
Training loss: 0.9420185089111328
Validation loss: 1.8018649560148998

Epoch: 5| Step: 4
Training loss: 0.7373207211494446
Validation loss: 1.7842262355230187

Epoch: 5| Step: 5
Training loss: 0.7466493844985962
Validation loss: 1.7822028808696295

Epoch: 5| Step: 6
Training loss: 0.754100501537323
Validation loss: 1.7990698429845995

Epoch: 5| Step: 7
Training loss: 0.8040881156921387
Validation loss: 1.750767743715676

Epoch: 5| Step: 8
Training loss: 0.5647676587104797
Validation loss: 1.7538424390618519

Epoch: 5| Step: 9
Training loss: 0.9488566517829895
Validation loss: 1.762150065873259

Epoch: 5| Step: 10
Training loss: 1.1067131757736206
Validation loss: 1.7827713630532707

Epoch: 305| Step: 0
Training loss: 0.9160356521606445
Validation loss: 1.7862734884344122

Epoch: 5| Step: 1
Training loss: 0.9899195432662964
Validation loss: 1.7813335964756627

Epoch: 5| Step: 2
Training loss: 0.7715667486190796
Validation loss: 1.779223725359927

Epoch: 5| Step: 3
Training loss: 0.9715960621833801
Validation loss: 1.7894808643607683

Epoch: 5| Step: 4
Training loss: 0.6940110921859741
Validation loss: 1.7970521603861163

Epoch: 5| Step: 5
Training loss: 0.7126900553703308
Validation loss: 1.8004167349107805

Epoch: 5| Step: 6
Training loss: 0.675563633441925
Validation loss: 1.8202915653105705

Epoch: 5| Step: 7
Training loss: 0.6543515920639038
Validation loss: 1.812852458287311

Epoch: 5| Step: 8
Training loss: 0.8301044702529907
Validation loss: 1.7893515466361918

Epoch: 5| Step: 9
Training loss: 0.5885181427001953
Validation loss: 1.7832071088975476

Epoch: 5| Step: 10
Training loss: 1.1333249807357788
Validation loss: 1.7607421580181326

Epoch: 306| Step: 0
Training loss: 0.907649040222168
Validation loss: 1.764095414069391

Epoch: 5| Step: 1
Training loss: 0.6019831895828247
Validation loss: 1.7500173404652586

Epoch: 5| Step: 2
Training loss: 0.45983296632766724
Validation loss: 1.7779098710706156

Epoch: 5| Step: 3
Training loss: 0.799446702003479
Validation loss: 1.7345196149682487

Epoch: 5| Step: 4
Training loss: 0.5789984464645386
Validation loss: 1.7291228848118936

Epoch: 5| Step: 5
Training loss: 0.9157333374023438
Validation loss: 1.7523486370681434

Epoch: 5| Step: 6
Training loss: 0.8251821398735046
Validation loss: 1.7490578902665006

Epoch: 5| Step: 7
Training loss: 0.9108117818832397
Validation loss: 1.7412765372184016

Epoch: 5| Step: 8
Training loss: 1.0735578536987305
Validation loss: 1.733279497392716

Epoch: 5| Step: 9
Training loss: 0.7757170796394348
Validation loss: 1.7348293373661656

Epoch: 5| Step: 10
Training loss: 0.8717700242996216
Validation loss: 1.7392610811418103

Epoch: 307| Step: 0
Training loss: 0.7590068578720093
Validation loss: 1.7571930705860097

Epoch: 5| Step: 1
Training loss: 0.9336905479431152
Validation loss: 1.758738584415887

Epoch: 5| Step: 2
Training loss: 0.6161845922470093
Validation loss: 1.754164113793322

Epoch: 5| Step: 3
Training loss: 0.48165711760520935
Validation loss: 1.7648746762224423

Epoch: 5| Step: 4
Training loss: 0.7420822381973267
Validation loss: 1.7812883225820397

Epoch: 5| Step: 5
Training loss: 0.6632259488105774
Validation loss: 1.746303767286321

Epoch: 5| Step: 6
Training loss: 1.1726053953170776
Validation loss: 1.7606441064547467

Epoch: 5| Step: 7
Training loss: 1.041326642036438
Validation loss: 1.7724862124330254

Epoch: 5| Step: 8
Training loss: 0.9450913667678833
Validation loss: 1.8133259332308205

Epoch: 5| Step: 9
Training loss: 0.7836499214172363
Validation loss: 1.795100845316405

Epoch: 5| Step: 10
Training loss: 1.1400965452194214
Validation loss: 1.7419153823647449

Epoch: 308| Step: 0
Training loss: 0.7134866714477539
Validation loss: 1.7439966368418869

Epoch: 5| Step: 1
Training loss: 0.6593374609947205
Validation loss: 1.7326266163138933

Epoch: 5| Step: 2
Training loss: 0.8125977516174316
Validation loss: 1.7414567611550773

Epoch: 5| Step: 3
Training loss: 1.0220553874969482
Validation loss: 1.7608365986936836

Epoch: 5| Step: 4
Training loss: 0.5857333540916443
Validation loss: 1.752129066374994

Epoch: 5| Step: 5
Training loss: 0.796333372592926
Validation loss: 1.737795578536167

Epoch: 5| Step: 6
Training loss: 0.7575085163116455
Validation loss: 1.7262497954471137

Epoch: 5| Step: 7
Training loss: 1.0585333108901978
Validation loss: 1.7448533914422477

Epoch: 5| Step: 8
Training loss: 0.6787444949150085
Validation loss: 1.7524370128108608

Epoch: 5| Step: 9
Training loss: 0.8293557167053223
Validation loss: 1.745552356525134

Epoch: 5| Step: 10
Training loss: 0.8983224034309387
Validation loss: 1.7529203866117744

Epoch: 309| Step: 0
Training loss: 0.6844888925552368
Validation loss: 1.7626517177909933

Epoch: 5| Step: 1
Training loss: 0.8631304502487183
Validation loss: 1.7510300772164458

Epoch: 5| Step: 2
Training loss: 0.9090641140937805
Validation loss: 1.7743176503848004

Epoch: 5| Step: 3
Training loss: 0.7803595662117004
Validation loss: 1.7640121572761125

Epoch: 5| Step: 4
Training loss: 0.5927395820617676
Validation loss: 1.778069817891685

Epoch: 5| Step: 5
Training loss: 0.9265966415405273
Validation loss: 1.7558563447767688

Epoch: 5| Step: 6
Training loss: 0.6345321536064148
Validation loss: 1.7707957042160856

Epoch: 5| Step: 7
Training loss: 0.8602336645126343
Validation loss: 1.7767779955299952

Epoch: 5| Step: 8
Training loss: 0.8063887357711792
Validation loss: 1.786577877177987

Epoch: 5| Step: 9
Training loss: 0.7281560897827148
Validation loss: 1.7704342334501204

Epoch: 5| Step: 10
Training loss: 0.7949125170707703
Validation loss: 1.7492387794679212

Epoch: 310| Step: 0
Training loss: 0.8124338388442993
Validation loss: 1.7703130552845616

Epoch: 5| Step: 1
Training loss: 0.8867508172988892
Validation loss: 1.7238649168322164

Epoch: 5| Step: 2
Training loss: 0.5828741788864136
Validation loss: 1.7202839928288614

Epoch: 5| Step: 3
Training loss: 0.786151111125946
Validation loss: 1.7335758016955467

Epoch: 5| Step: 4
Training loss: 1.042220950126648
Validation loss: 1.7234342534054992

Epoch: 5| Step: 5
Training loss: 0.9451980590820312
Validation loss: 1.7029591170690392

Epoch: 5| Step: 6
Training loss: 0.6779487729072571
Validation loss: 1.7109376724048326

Epoch: 5| Step: 7
Training loss: 0.46983832120895386
Validation loss: 1.711493860008896

Epoch: 5| Step: 8
Training loss: 1.1227225065231323
Validation loss: 1.7448405411935621

Epoch: 5| Step: 9
Training loss: 0.6931015849113464
Validation loss: 1.7518229446103495

Epoch: 5| Step: 10
Training loss: 0.3852628469467163
Validation loss: 1.7125214581848474

Epoch: 311| Step: 0
Training loss: 1.0946487188339233
Validation loss: 1.7400322434722737

Epoch: 5| Step: 1
Training loss: 0.8974410891532898
Validation loss: 1.7091387625663512

Epoch: 5| Step: 2
Training loss: 0.9906600713729858
Validation loss: 1.7631484846914969

Epoch: 5| Step: 3
Training loss: 0.5376585125923157
Validation loss: 1.7396912113312752

Epoch: 5| Step: 4
Training loss: 0.8438495397567749
Validation loss: 1.7352884046493038

Epoch: 5| Step: 5
Training loss: 1.1078708171844482
Validation loss: 1.7196603821169945

Epoch: 5| Step: 6
Training loss: 0.40779227018356323
Validation loss: 1.7228612515234178

Epoch: 5| Step: 7
Training loss: 0.6510469913482666
Validation loss: 1.7325825063131188

Epoch: 5| Step: 8
Training loss: 0.5159143209457397
Validation loss: 1.715720239505973

Epoch: 5| Step: 9
Training loss: 0.790336549282074
Validation loss: 1.7198454077525804

Epoch: 5| Step: 10
Training loss: 0.5556767582893372
Validation loss: 1.7177752230757026

Epoch: 312| Step: 0
Training loss: 0.722078800201416
Validation loss: 1.7595190899346465

Epoch: 5| Step: 1
Training loss: 0.5418645143508911
Validation loss: 1.7773141527688632

Epoch: 5| Step: 2
Training loss: 0.7861348390579224
Validation loss: 1.7629585202022264

Epoch: 5| Step: 3
Training loss: 0.9885234832763672
Validation loss: 1.747986944772864

Epoch: 5| Step: 4
Training loss: 0.4532140791416168
Validation loss: 1.7815813582430604

Epoch: 5| Step: 5
Training loss: 0.8541923761367798
Validation loss: 1.7869811827136624

Epoch: 5| Step: 6
Training loss: 0.7642624378204346
Validation loss: 1.8045047662591422

Epoch: 5| Step: 7
Training loss: 0.8931988477706909
Validation loss: 1.8288157063145791

Epoch: 5| Step: 8
Training loss: 0.8495403528213501
Validation loss: 1.8342736972275602

Epoch: 5| Step: 9
Training loss: 0.6590336561203003
Validation loss: 1.8650760317361483

Epoch: 5| Step: 10
Training loss: 0.9995214939117432
Validation loss: 1.8589128076389272

Epoch: 313| Step: 0
Training loss: 0.9377830624580383
Validation loss: 1.7924720112995436

Epoch: 5| Step: 1
Training loss: 0.5510573387145996
Validation loss: 1.7707561574956423

Epoch: 5| Step: 2
Training loss: 0.7429424524307251
Validation loss: 1.7547431389490764

Epoch: 5| Step: 3
Training loss: 0.7936978340148926
Validation loss: 1.769612717372115

Epoch: 5| Step: 4
Training loss: 0.4037493169307709
Validation loss: 1.7400384205643848

Epoch: 5| Step: 5
Training loss: 0.6362107396125793
Validation loss: 1.7398196522907545

Epoch: 5| Step: 6
Training loss: 0.9466743469238281
Validation loss: 1.7479877292468984

Epoch: 5| Step: 7
Training loss: 1.271456003189087
Validation loss: 1.7488946940309258

Epoch: 5| Step: 8
Training loss: 0.6718298196792603
Validation loss: 1.7468460041989562

Epoch: 5| Step: 9
Training loss: 0.2720564007759094
Validation loss: 1.7530369745787753

Epoch: 5| Step: 10
Training loss: 0.9267356395721436
Validation loss: 1.7669681464472125

Epoch: 314| Step: 0
Training loss: 0.6675165891647339
Validation loss: 1.7367412851702781

Epoch: 5| Step: 1
Training loss: 0.727249026298523
Validation loss: 1.8012804241590603

Epoch: 5| Step: 2
Training loss: 0.973652720451355
Validation loss: 1.7835760251168282

Epoch: 5| Step: 3
Training loss: 0.5154858827590942
Validation loss: 1.8216845835408857

Epoch: 5| Step: 4
Training loss: 0.3639240264892578
Validation loss: 1.8264523590764692

Epoch: 5| Step: 5
Training loss: 0.5275722742080688
Validation loss: 1.8020055165854834

Epoch: 5| Step: 6
Training loss: 1.0672415494918823
Validation loss: 1.7835494856680594

Epoch: 5| Step: 7
Training loss: 1.0321040153503418
Validation loss: 1.7613418538083312

Epoch: 5| Step: 8
Training loss: 0.6019179821014404
Validation loss: 1.7634631702976842

Epoch: 5| Step: 9
Training loss: 0.8248418569564819
Validation loss: 1.7319319927564232

Epoch: 5| Step: 10
Training loss: 0.8680857419967651
Validation loss: 1.7270385757569344

Epoch: 315| Step: 0
Training loss: 0.7615618705749512
Validation loss: 1.7302749541498

Epoch: 5| Step: 1
Training loss: 0.5929836630821228
Validation loss: 1.7132679852106238

Epoch: 5| Step: 2
Training loss: 0.6760842800140381
Validation loss: 1.7256131684908302

Epoch: 5| Step: 3
Training loss: 0.5496394038200378
Validation loss: 1.7327780903026622

Epoch: 5| Step: 4
Training loss: 0.5191648602485657
Validation loss: 1.7505498214434552

Epoch: 5| Step: 5
Training loss: 0.6166008114814758
Validation loss: 1.7160181845388105

Epoch: 5| Step: 6
Training loss: 0.4929795265197754
Validation loss: 1.7517097944854407

Epoch: 5| Step: 7
Training loss: 0.8511011004447937
Validation loss: 1.725535008215135

Epoch: 5| Step: 8
Training loss: 0.8952415585517883
Validation loss: 1.732492958345721

Epoch: 5| Step: 9
Training loss: 1.0566275119781494
Validation loss: 1.7443576615343812

Epoch: 5| Step: 10
Training loss: 0.8282016515731812
Validation loss: 1.7282538067909978

Epoch: 316| Step: 0
Training loss: 0.6139981150627136
Validation loss: 1.7287641520141273

Epoch: 5| Step: 1
Training loss: 1.03713059425354
Validation loss: 1.7579947748491842

Epoch: 5| Step: 2
Training loss: 0.28524598479270935
Validation loss: 1.7548851325947752

Epoch: 5| Step: 3
Training loss: 0.6475080251693726
Validation loss: 1.712637819269652

Epoch: 5| Step: 4
Training loss: 0.6833758354187012
Validation loss: 1.7047230146264518

Epoch: 5| Step: 5
Training loss: 0.7057080864906311
Validation loss: 1.7156439064651408

Epoch: 5| Step: 6
Training loss: 0.6918573379516602
Validation loss: 1.7220261622500677

Epoch: 5| Step: 7
Training loss: 0.9061660766601562
Validation loss: 1.7216250367702977

Epoch: 5| Step: 8
Training loss: 0.9236272573471069
Validation loss: 1.717685482835257

Epoch: 5| Step: 9
Training loss: 0.7440112829208374
Validation loss: 1.7059739815291537

Epoch: 5| Step: 10
Training loss: 0.5761438012123108
Validation loss: 1.6946249623452463

Epoch: 317| Step: 0
Training loss: 0.6208378076553345
Validation loss: 1.7145807550799461

Epoch: 5| Step: 1
Training loss: 0.500399112701416
Validation loss: 1.7496829109807168

Epoch: 5| Step: 2
Training loss: 1.026288628578186
Validation loss: 1.7249010788497103

Epoch: 5| Step: 3
Training loss: 0.6784220933914185
Validation loss: 1.7426098444128548

Epoch: 5| Step: 4
Training loss: 0.5941634774208069
Validation loss: 1.7449042309996903

Epoch: 5| Step: 5
Training loss: 0.6862632036209106
Validation loss: 1.717289697739386

Epoch: 5| Step: 6
Training loss: 0.6226410269737244
Validation loss: 1.732764777316842

Epoch: 5| Step: 7
Training loss: 0.7158726453781128
Validation loss: 1.726051402348344

Epoch: 5| Step: 8
Training loss: 0.720573902130127
Validation loss: 1.7321921625444967

Epoch: 5| Step: 9
Training loss: 0.65191650390625
Validation loss: 1.7167259595727409

Epoch: 5| Step: 10
Training loss: 1.0699843168258667
Validation loss: 1.7343195984440465

Epoch: 318| Step: 0
Training loss: 0.8573756217956543
Validation loss: 1.7158472409812353

Epoch: 5| Step: 1
Training loss: 0.6293967962265015
Validation loss: 1.7163552917459959

Epoch: 5| Step: 2
Training loss: 0.48675018548965454
Validation loss: 1.711929880162721

Epoch: 5| Step: 3
Training loss: 0.6751583814620972
Validation loss: 1.735212920814432

Epoch: 5| Step: 4
Training loss: 0.9793969988822937
Validation loss: 1.7190322478612263

Epoch: 5| Step: 5
Training loss: 0.8797553181648254
Validation loss: 1.7273987044570267

Epoch: 5| Step: 6
Training loss: 0.5267902612686157
Validation loss: 1.7445141205223658

Epoch: 5| Step: 7
Training loss: 0.8044294118881226
Validation loss: 1.7469406025384062

Epoch: 5| Step: 8
Training loss: 0.654464066028595
Validation loss: 1.7477292360798005

Epoch: 5| Step: 9
Training loss: 0.5857511758804321
Validation loss: 1.775984428262198

Epoch: 5| Step: 10
Training loss: 0.6816427707672119
Validation loss: 1.7881097844851914

Epoch: 319| Step: 0
Training loss: 0.6169617772102356
Validation loss: 1.7762036823457288

Epoch: 5| Step: 1
Training loss: 0.6408123970031738
Validation loss: 1.7637878284659436

Epoch: 5| Step: 2
Training loss: 0.7682285308837891
Validation loss: 1.7486944660063712

Epoch: 5| Step: 3
Training loss: 0.4794754087924957
Validation loss: 1.7038180148729714

Epoch: 5| Step: 4
Training loss: 0.697239100933075
Validation loss: 1.722755761556728

Epoch: 5| Step: 5
Training loss: 0.994337260723114
Validation loss: 1.7344122035529024

Epoch: 5| Step: 6
Training loss: 0.9035526514053345
Validation loss: 1.7116382237403625

Epoch: 5| Step: 7
Training loss: 0.570472240447998
Validation loss: 1.7137681720077351

Epoch: 5| Step: 8
Training loss: 0.6526675224304199
Validation loss: 1.7559914127472909

Epoch: 5| Step: 9
Training loss: 0.8084081411361694
Validation loss: 1.7366952383390037

Epoch: 5| Step: 10
Training loss: 0.8147326111793518
Validation loss: 1.7523873711145053

Epoch: 320| Step: 0
Training loss: 0.6900913119316101
Validation loss: 1.7524809093885525

Epoch: 5| Step: 1
Training loss: 0.8526558876037598
Validation loss: 1.7443359398072766

Epoch: 5| Step: 2
Training loss: 0.4830082952976227
Validation loss: 1.7024503651485647

Epoch: 5| Step: 3
Training loss: 0.6166125535964966
Validation loss: 1.7061408283889934

Epoch: 5| Step: 4
Training loss: 0.46301165223121643
Validation loss: 1.7028578955640075

Epoch: 5| Step: 5
Training loss: 0.8795258402824402
Validation loss: 1.7058824646857478

Epoch: 5| Step: 6
Training loss: 0.5273965001106262
Validation loss: 1.7306957808873986

Epoch: 5| Step: 7
Training loss: 0.7321513891220093
Validation loss: 1.7365371552846764

Epoch: 5| Step: 8
Training loss: 0.7367874979972839
Validation loss: 1.7396141290664673

Epoch: 5| Step: 9
Training loss: 0.9348726272583008
Validation loss: 1.705110219217116

Epoch: 5| Step: 10
Training loss: 0.7649232745170593
Validation loss: 1.687158405139882

Epoch: 321| Step: 0
Training loss: 0.8041172027587891
Validation loss: 1.7177464116004206

Epoch: 5| Step: 1
Training loss: 0.7595558762550354
Validation loss: 1.7091135158333728

Epoch: 5| Step: 2
Training loss: 0.5577182769775391
Validation loss: 1.6876640255733202

Epoch: 5| Step: 3
Training loss: 0.8113774061203003
Validation loss: 1.7005328260442263

Epoch: 5| Step: 4
Training loss: 0.7427874207496643
Validation loss: 1.7293874102254068

Epoch: 5| Step: 5
Training loss: 0.5330251455307007
Validation loss: 1.7377657198136853

Epoch: 5| Step: 6
Training loss: 0.851436972618103
Validation loss: 1.7606447576194681

Epoch: 5| Step: 7
Training loss: 0.5610753297805786
Validation loss: 1.7522608323763775

Epoch: 5| Step: 8
Training loss: 0.7037625312805176
Validation loss: 1.7550684354638542

Epoch: 5| Step: 9
Training loss: 0.7455341219902039
Validation loss: 1.745484435430137

Epoch: 5| Step: 10
Training loss: 0.3573096990585327
Validation loss: 1.7250705963821822

Epoch: 322| Step: 0
Training loss: 0.7777653932571411
Validation loss: 1.723184495843867

Epoch: 5| Step: 1
Training loss: 0.4443167746067047
Validation loss: 1.7382060686747234

Epoch: 5| Step: 2
Training loss: 0.7122586965560913
Validation loss: 1.7253674396904566

Epoch: 5| Step: 3
Training loss: 0.7877664566040039
Validation loss: 1.7253560173896052

Epoch: 5| Step: 4
Training loss: 0.5376484394073486
Validation loss: 1.715794753002864

Epoch: 5| Step: 5
Training loss: 0.6128586530685425
Validation loss: 1.7294549185742614

Epoch: 5| Step: 6
Training loss: 1.1432288885116577
Validation loss: 1.7294160076366958

Epoch: 5| Step: 7
Training loss: 0.7766920328140259
Validation loss: 1.7150895698096162

Epoch: 5| Step: 8
Training loss: 0.5981067419052124
Validation loss: 1.7211732018378474

Epoch: 5| Step: 9
Training loss: 0.4239196181297302
Validation loss: 1.7467224572294502

Epoch: 5| Step: 10
Training loss: 0.44540268182754517
Validation loss: 1.7119953068353797

Epoch: 323| Step: 0
Training loss: 0.6256037354469299
Validation loss: 1.7222871959850352

Epoch: 5| Step: 1
Training loss: 0.7427898049354553
Validation loss: 1.707407191235532

Epoch: 5| Step: 2
Training loss: 0.6758384704589844
Validation loss: 1.691024798218922

Epoch: 5| Step: 3
Training loss: 0.6580865383148193
Validation loss: 1.7095789268452635

Epoch: 5| Step: 4
Training loss: 0.4444633424282074
Validation loss: 1.7045198179060412

Epoch: 5| Step: 5
Training loss: 0.6635531187057495
Validation loss: 1.7221191057594873

Epoch: 5| Step: 6
Training loss: 0.9255563616752625
Validation loss: 1.7066516748038671

Epoch: 5| Step: 7
Training loss: 0.4070819020271301
Validation loss: 1.730230292966289

Epoch: 5| Step: 8
Training loss: 0.7788479328155518
Validation loss: 1.7136410705504879

Epoch: 5| Step: 9
Training loss: 0.7834073305130005
Validation loss: 1.723876545506139

Epoch: 5| Step: 10
Training loss: 0.667745053768158
Validation loss: 1.7399954718928183

Epoch: 324| Step: 0
Training loss: 0.7318421602249146
Validation loss: 1.7267968487995926

Epoch: 5| Step: 1
Training loss: 0.7892731428146362
Validation loss: 1.7535976389402985

Epoch: 5| Step: 2
Training loss: 0.9520664215087891
Validation loss: 1.7115372970540037

Epoch: 5| Step: 3
Training loss: 0.8465676307678223
Validation loss: 1.744289787866736

Epoch: 5| Step: 4
Training loss: 0.6372406482696533
Validation loss: 1.7379749359623078

Epoch: 5| Step: 5
Training loss: 0.7425378561019897
Validation loss: 1.7647943547976914

Epoch: 5| Step: 6
Training loss: 0.506477952003479
Validation loss: 1.7241218987331595

Epoch: 5| Step: 7
Training loss: 0.6866061091423035
Validation loss: 1.6665186894837247

Epoch: 5| Step: 8
Training loss: 0.5927972197532654
Validation loss: 1.6731630768827213

Epoch: 5| Step: 9
Training loss: 0.47399869561195374
Validation loss: 1.6800211411650463

Epoch: 5| Step: 10
Training loss: 0.628777265548706
Validation loss: 1.6779794180265037

Epoch: 325| Step: 0
Training loss: 0.5056012272834778
Validation loss: 1.6617968351610246

Epoch: 5| Step: 1
Training loss: 0.7547875642776489
Validation loss: 1.6743601509319839

Epoch: 5| Step: 2
Training loss: 0.6858026385307312
Validation loss: 1.6805306224412815

Epoch: 5| Step: 3
Training loss: 0.7324591279029846
Validation loss: 1.6893608685462707

Epoch: 5| Step: 4
Training loss: 0.7168000936508179
Validation loss: 1.6737133943906395

Epoch: 5| Step: 5
Training loss: 0.8371920585632324
Validation loss: 1.6721847018887919

Epoch: 5| Step: 6
Training loss: 0.5591384172439575
Validation loss: 1.6725048185676656

Epoch: 5| Step: 7
Training loss: 0.8237050175666809
Validation loss: 1.6769553999747

Epoch: 5| Step: 8
Training loss: 0.2399185448884964
Validation loss: 1.681553356109127

Epoch: 5| Step: 9
Training loss: 0.9176526069641113
Validation loss: 1.6778063069107712

Epoch: 5| Step: 10
Training loss: 0.4192030727863312
Validation loss: 1.6886280236705657

Epoch: 326| Step: 0
Training loss: 0.7828204035758972
Validation loss: 1.6777726809183757

Epoch: 5| Step: 1
Training loss: 0.8659936785697937
Validation loss: 1.69012063933957

Epoch: 5| Step: 2
Training loss: 0.615312933921814
Validation loss: 1.6680695574770692

Epoch: 5| Step: 3
Training loss: 0.5911540985107422
Validation loss: 1.687902932525963

Epoch: 5| Step: 4
Training loss: 0.5061641335487366
Validation loss: 1.6791305516355781

Epoch: 5| Step: 5
Training loss: 0.6950620412826538
Validation loss: 1.7023405503201228

Epoch: 5| Step: 6
Training loss: 0.354666143655777
Validation loss: 1.6672926308006368

Epoch: 5| Step: 7
Training loss: 0.5145131349563599
Validation loss: 1.6602616271665018

Epoch: 5| Step: 8
Training loss: 0.6525218486785889
Validation loss: 1.6633160896198724

Epoch: 5| Step: 9
Training loss: 0.6490207314491272
Validation loss: 1.6649183906534666

Epoch: 5| Step: 10
Training loss: 0.6940146088600159
Validation loss: 1.6688307075090305

Epoch: 327| Step: 0
Training loss: 0.6751278638839722
Validation loss: 1.6849277468137844

Epoch: 5| Step: 1
Training loss: 0.552545428276062
Validation loss: 1.7149058708580591

Epoch: 5| Step: 2
Training loss: 0.46238166093826294
Validation loss: 1.698380054325186

Epoch: 5| Step: 3
Training loss: 0.3822100758552551
Validation loss: 1.711988405514789

Epoch: 5| Step: 4
Training loss: 0.49211445450782776
Validation loss: 1.7236452999935354

Epoch: 5| Step: 5
Training loss: 0.37983718514442444
Validation loss: 1.7198696085201797

Epoch: 5| Step: 6
Training loss: 0.7372041344642639
Validation loss: 1.699568876656153

Epoch: 5| Step: 7
Training loss: 0.814967930316925
Validation loss: 1.7273644503726755

Epoch: 5| Step: 8
Training loss: 0.6373255848884583
Validation loss: 1.7227111619005921

Epoch: 5| Step: 9
Training loss: 1.1247965097427368
Validation loss: 1.7219045303201164

Epoch: 5| Step: 10
Training loss: 0.6112707853317261
Validation loss: 1.71782640487917

Epoch: 328| Step: 0
Training loss: 0.6915320158004761
Validation loss: 1.680775857740833

Epoch: 5| Step: 1
Training loss: 0.4113221764564514
Validation loss: 1.7065609680709017

Epoch: 5| Step: 2
Training loss: 0.6560055017471313
Validation loss: 1.6949068064330726

Epoch: 5| Step: 3
Training loss: 0.4685680866241455
Validation loss: 1.6792150441036429

Epoch: 5| Step: 4
Training loss: 0.27664127945899963
Validation loss: 1.6813892061992357

Epoch: 5| Step: 5
Training loss: 0.7615052461624146
Validation loss: 1.7129976621238134

Epoch: 5| Step: 6
Training loss: 0.729200005531311
Validation loss: 1.6822159508223176

Epoch: 5| Step: 7
Training loss: 0.9883779287338257
Validation loss: 1.679543020904705

Epoch: 5| Step: 8
Training loss: 0.48531660437583923
Validation loss: 1.706691723997875

Epoch: 5| Step: 9
Training loss: 0.5390739440917969
Validation loss: 1.7296483183419833

Epoch: 5| Step: 10
Training loss: 0.9678882360458374
Validation loss: 1.69893261437775

Epoch: 329| Step: 0
Training loss: 0.9249553680419922
Validation loss: 1.7239398635843748

Epoch: 5| Step: 1
Training loss: 0.5756267309188843
Validation loss: 1.7279800368893532

Epoch: 5| Step: 2
Training loss: 0.797833263874054
Validation loss: 1.7303362802792621

Epoch: 5| Step: 3
Training loss: 0.6718330979347229
Validation loss: 1.7413279177040182

Epoch: 5| Step: 4
Training loss: 0.4247087836265564
Validation loss: 1.7437501299765803

Epoch: 5| Step: 5
Training loss: 0.7310992479324341
Validation loss: 1.7390691426492506

Epoch: 5| Step: 6
Training loss: 0.6454625129699707
Validation loss: 1.724627423030074

Epoch: 5| Step: 7
Training loss: 0.6069437265396118
Validation loss: 1.7304285521148353

Epoch: 5| Step: 8
Training loss: 0.4776870310306549
Validation loss: 1.718791381005318

Epoch: 5| Step: 9
Training loss: 0.35171544551849365
Validation loss: 1.693135074389878

Epoch: 5| Step: 10
Training loss: 0.6657786965370178
Validation loss: 1.7001550800056868

Epoch: 330| Step: 0
Training loss: 0.6990891695022583
Validation loss: 1.7158038846908077

Epoch: 5| Step: 1
Training loss: 0.4976122975349426
Validation loss: 1.7259578717652189

Epoch: 5| Step: 2
Training loss: 1.018096923828125
Validation loss: 1.705304209904004

Epoch: 5| Step: 3
Training loss: 0.5423396825790405
Validation loss: 1.707223371792865

Epoch: 5| Step: 4
Training loss: 0.5747449994087219
Validation loss: 1.7065028529013357

Epoch: 5| Step: 5
Training loss: 0.5528072118759155
Validation loss: 1.7138712277976416

Epoch: 5| Step: 6
Training loss: 0.4574664533138275
Validation loss: 1.7142316218345397

Epoch: 5| Step: 7
Training loss: 0.7397162914276123
Validation loss: 1.7250968205031527

Epoch: 5| Step: 8
Training loss: 0.5801643133163452
Validation loss: 1.7573661804199219

Epoch: 5| Step: 9
Training loss: 0.6327002644538879
Validation loss: 1.7287052715978315

Epoch: 5| Step: 10
Training loss: 0.477588027715683
Validation loss: 1.7214526335398357

Epoch: 331| Step: 0
Training loss: 0.5089157223701477
Validation loss: 1.7192243145358177

Epoch: 5| Step: 1
Training loss: 0.4325215220451355
Validation loss: 1.7074598061141146

Epoch: 5| Step: 2
Training loss: 0.462271511554718
Validation loss: 1.7067177526412471

Epoch: 5| Step: 3
Training loss: 0.581215500831604
Validation loss: 1.720238665098785

Epoch: 5| Step: 4
Training loss: 0.7660487294197083
Validation loss: 1.7258390162580757

Epoch: 5| Step: 5
Training loss: 0.7749208807945251
Validation loss: 1.7480258390467653

Epoch: 5| Step: 6
Training loss: 0.6796528697013855
Validation loss: 1.7454695124779978

Epoch: 5| Step: 7
Training loss: 0.5954989194869995
Validation loss: 1.7621916596607496

Epoch: 5| Step: 8
Training loss: 0.9946921467781067
Validation loss: 1.7414182104090208

Epoch: 5| Step: 9
Training loss: 0.49055829644203186
Validation loss: 1.7547714710235596

Epoch: 5| Step: 10
Training loss: 0.46552252769470215
Validation loss: 1.7574991731233494

Epoch: 332| Step: 0
Training loss: 0.4071617126464844
Validation loss: 1.732040289909609

Epoch: 5| Step: 1
Training loss: 0.7561637759208679
Validation loss: 1.6993323628620436

Epoch: 5| Step: 2
Training loss: 0.6140335202217102
Validation loss: 1.7010576417369228

Epoch: 5| Step: 3
Training loss: 0.5557212829589844
Validation loss: 1.7164083334707445

Epoch: 5| Step: 4
Training loss: 0.5319042205810547
Validation loss: 1.680762461436692

Epoch: 5| Step: 5
Training loss: 0.6568912267684937
Validation loss: 1.709422396075341

Epoch: 5| Step: 6
Training loss: 0.8494011759757996
Validation loss: 1.7076241649607176

Epoch: 5| Step: 7
Training loss: 0.6337207555770874
Validation loss: 1.7040332517316263

Epoch: 5| Step: 8
Training loss: 0.34417739510536194
Validation loss: 1.6776376437115412

Epoch: 5| Step: 9
Training loss: 0.6516674757003784
Validation loss: 1.6897119065766693

Epoch: 5| Step: 10
Training loss: 0.6631374359130859
Validation loss: 1.69994233756937

Epoch: 333| Step: 0
Training loss: 0.5899481773376465
Validation loss: 1.691178915321186

Epoch: 5| Step: 1
Training loss: 0.7928177118301392
Validation loss: 1.7225487565481534

Epoch: 5| Step: 2
Training loss: 0.6951118111610413
Validation loss: 1.6964088063086233

Epoch: 5| Step: 3
Training loss: 0.7415828704833984
Validation loss: 1.7145454742575204

Epoch: 5| Step: 4
Training loss: 0.768778920173645
Validation loss: 1.7188252287526284

Epoch: 5| Step: 5
Training loss: 0.5536715388298035
Validation loss: 1.76259978612264

Epoch: 5| Step: 6
Training loss: 0.7047420740127563
Validation loss: 1.7313357617265435

Epoch: 5| Step: 7
Training loss: 0.5408419966697693
Validation loss: 1.7064855572997883

Epoch: 5| Step: 8
Training loss: 0.37386298179626465
Validation loss: 1.717286309888286

Epoch: 5| Step: 9
Training loss: 0.5103013515472412
Validation loss: 1.7206504665395266

Epoch: 5| Step: 10
Training loss: 0.43052011728286743
Validation loss: 1.7174508071714831

Epoch: 334| Step: 0
Training loss: 0.5494063496589661
Validation loss: 1.7105007927904847

Epoch: 5| Step: 1
Training loss: 0.680772602558136
Validation loss: 1.7196890179828932

Epoch: 5| Step: 2
Training loss: 0.5314739942550659
Validation loss: 1.7195460514355732

Epoch: 5| Step: 3
Training loss: 0.6258519291877747
Validation loss: 1.718850476767427

Epoch: 5| Step: 4
Training loss: 0.45580682158470154
Validation loss: 1.6758718529055197

Epoch: 5| Step: 5
Training loss: 0.5261763334274292
Validation loss: 1.700270765571184

Epoch: 5| Step: 6
Training loss: 0.790126383304596
Validation loss: 1.6980687046563754

Epoch: 5| Step: 7
Training loss: 0.463967502117157
Validation loss: 1.6758364862011326

Epoch: 5| Step: 8
Training loss: 0.6495082974433899
Validation loss: 1.673040086223233

Epoch: 5| Step: 9
Training loss: 0.6196600198745728
Validation loss: 1.671846225697507

Epoch: 5| Step: 10
Training loss: 0.512570858001709
Validation loss: 1.679850056607236

Epoch: 335| Step: 0
Training loss: 0.414785772562027
Validation loss: 1.6930029815243137

Epoch: 5| Step: 1
Training loss: 0.41646862030029297
Validation loss: 1.6774643005863312

Epoch: 5| Step: 2
Training loss: 0.4112755358219147
Validation loss: 1.666606303184263

Epoch: 5| Step: 3
Training loss: 0.6921324729919434
Validation loss: 1.6933980449553458

Epoch: 5| Step: 4
Training loss: 0.814217209815979
Validation loss: 1.675626080523255

Epoch: 5| Step: 5
Training loss: 0.6051255464553833
Validation loss: 1.6713309454661545

Epoch: 5| Step: 6
Training loss: 0.7823778986930847
Validation loss: 1.668457781114886

Epoch: 5| Step: 7
Training loss: 0.7137160301208496
Validation loss: 1.689779523880251

Epoch: 5| Step: 8
Training loss: 0.7878624796867371
Validation loss: 1.6610115228160736

Epoch: 5| Step: 9
Training loss: 0.4991929531097412
Validation loss: 1.6678016929216282

Epoch: 5| Step: 10
Training loss: 0.3403948247432709
Validation loss: 1.7199312589501823

Epoch: 336| Step: 0
Training loss: 0.731220006942749
Validation loss: 1.7107330829866472

Epoch: 5| Step: 1
Training loss: 0.29485559463500977
Validation loss: 1.7170290113777242

Epoch: 5| Step: 2
Training loss: 0.6359313130378723
Validation loss: 1.7060556693743634

Epoch: 5| Step: 3
Training loss: 0.622188150882721
Validation loss: 1.7025106760763353

Epoch: 5| Step: 4
Training loss: 0.5179056525230408
Validation loss: 1.699082733482443

Epoch: 5| Step: 5
Training loss: 0.5230039358139038
Validation loss: 1.7071387280700028

Epoch: 5| Step: 6
Training loss: 0.5936911702156067
Validation loss: 1.6888478327822942

Epoch: 5| Step: 7
Training loss: 0.5165814161300659
Validation loss: 1.6960113638190812

Epoch: 5| Step: 8
Training loss: 0.618800163269043
Validation loss: 1.685244934533232

Epoch: 5| Step: 9
Training loss: 0.9642392992973328
Validation loss: 1.7004272809592627

Epoch: 5| Step: 10
Training loss: 0.41989561915397644
Validation loss: 1.7095097111117454

Epoch: 337| Step: 0
Training loss: 0.5527669191360474
Validation loss: 1.7313629375991

Epoch: 5| Step: 1
Training loss: 0.3811403214931488
Validation loss: 1.7077055374781291

Epoch: 5| Step: 2
Training loss: 0.7568371891975403
Validation loss: 1.6920945541833037

Epoch: 5| Step: 3
Training loss: 0.6122512221336365
Validation loss: 1.6919938607882428

Epoch: 5| Step: 4
Training loss: 0.6913174986839294
Validation loss: 1.7038187211559666

Epoch: 5| Step: 5
Training loss: 0.609014630317688
Validation loss: 1.7032783794146713

Epoch: 5| Step: 6
Training loss: 0.6037171483039856
Validation loss: 1.7128829084416872

Epoch: 5| Step: 7
Training loss: 0.3132767081260681
Validation loss: 1.704758935077216

Epoch: 5| Step: 8
Training loss: 0.5368437767028809
Validation loss: 1.7756324801393735

Epoch: 5| Step: 9
Training loss: 0.8233469128608704
Validation loss: 1.775961100414235

Epoch: 5| Step: 10
Training loss: 0.4634840190410614
Validation loss: 1.740171096658194

Epoch: 338| Step: 0
Training loss: 0.6383291482925415
Validation loss: 1.7678994645354569

Epoch: 5| Step: 1
Training loss: 0.5958806276321411
Validation loss: 1.7351380304623676

Epoch: 5| Step: 2
Training loss: 0.34550729393959045
Validation loss: 1.7165141131288262

Epoch: 5| Step: 3
Training loss: 0.7830142974853516
Validation loss: 1.7180888409255652

Epoch: 5| Step: 4
Training loss: 0.871171772480011
Validation loss: 1.7257798922959195

Epoch: 5| Step: 5
Training loss: 0.5492478609085083
Validation loss: 1.6877893773458337

Epoch: 5| Step: 6
Training loss: 0.49179187417030334
Validation loss: 1.6929826441631521

Epoch: 5| Step: 7
Training loss: 0.803869366645813
Validation loss: 1.6840343782978673

Epoch: 5| Step: 8
Training loss: 0.6772345304489136
Validation loss: 1.7068879655612412

Epoch: 5| Step: 9
Training loss: 0.2628733515739441
Validation loss: 1.7198416802190966

Epoch: 5| Step: 10
Training loss: 0.5009503364562988
Validation loss: 1.6992604642786004

Epoch: 339| Step: 0
Training loss: 0.6751745343208313
Validation loss: 1.7065579199021863

Epoch: 5| Step: 1
Training loss: 0.4587617814540863
Validation loss: 1.7205906260398127

Epoch: 5| Step: 2
Training loss: 0.47715550661087036
Validation loss: 1.7201252778371174

Epoch: 5| Step: 3
Training loss: 0.5445650815963745
Validation loss: 1.6956136547109133

Epoch: 5| Step: 4
Training loss: 0.5212932825088501
Validation loss: 1.7067139058984735

Epoch: 5| Step: 5
Training loss: 0.5285338163375854
Validation loss: 1.7016351222991943

Epoch: 5| Step: 6
Training loss: 0.4403713345527649
Validation loss: 1.716980904661199

Epoch: 5| Step: 7
Training loss: 0.4818111062049866
Validation loss: 1.7043557346508067

Epoch: 5| Step: 8
Training loss: 0.8262626528739929
Validation loss: 1.699311012862831

Epoch: 5| Step: 9
Training loss: 0.7651089429855347
Validation loss: 1.6995389717881397

Epoch: 5| Step: 10
Training loss: 0.5191723704338074
Validation loss: 1.6880168055975309

Epoch: 340| Step: 0
Training loss: 0.5108721256256104
Validation loss: 1.7040700386929255

Epoch: 5| Step: 1
Training loss: 0.862298846244812
Validation loss: 1.6897697012911561

Epoch: 5| Step: 2
Training loss: 0.7518498301506042
Validation loss: 1.6929082626937537

Epoch: 5| Step: 3
Training loss: 0.5341722965240479
Validation loss: 1.6903898818518526

Epoch: 5| Step: 4
Training loss: 0.6996599435806274
Validation loss: 1.7185777816721188

Epoch: 5| Step: 5
Training loss: 0.48188096284866333
Validation loss: 1.7092592921308292

Epoch: 5| Step: 6
Training loss: 0.5127130150794983
Validation loss: 1.715287805885397

Epoch: 5| Step: 7
Training loss: 0.29763466119766235
Validation loss: 1.7629510330897507

Epoch: 5| Step: 8
Training loss: 0.6348309516906738
Validation loss: 1.7801451811226465

Epoch: 5| Step: 9
Training loss: 0.36676326394081116
Validation loss: 1.7615159352620442

Epoch: 5| Step: 10
Training loss: 0.5294654965400696
Validation loss: 1.7291537818088327

Epoch: 341| Step: 0
Training loss: 0.5274052023887634
Validation loss: 1.706253682413409

Epoch: 5| Step: 1
Training loss: 0.2993166744709015
Validation loss: 1.677363613600372

Epoch: 5| Step: 2
Training loss: 0.48684245347976685
Validation loss: 1.6670900980631511

Epoch: 5| Step: 3
Training loss: 0.5971823930740356
Validation loss: 1.691471815109253

Epoch: 5| Step: 4
Training loss: 0.4884161949157715
Validation loss: 1.6566908590255245

Epoch: 5| Step: 5
Training loss: 0.5983821749687195
Validation loss: 1.673736797866001

Epoch: 5| Step: 6
Training loss: 0.7071660757064819
Validation loss: 1.6688699517198788

Epoch: 5| Step: 7
Training loss: 0.6880612373352051
Validation loss: 1.6757300515328684

Epoch: 5| Step: 8
Training loss: 0.46516045928001404
Validation loss: 1.6891969634640602

Epoch: 5| Step: 9
Training loss: 0.7312933206558228
Validation loss: 1.704325943864802

Epoch: 5| Step: 10
Training loss: 0.7049683332443237
Validation loss: 1.7003015677134197

Epoch: 342| Step: 0
Training loss: 0.597856879234314
Validation loss: 1.7075633887321717

Epoch: 5| Step: 1
Training loss: 0.6277599334716797
Validation loss: 1.6920242232661094

Epoch: 5| Step: 2
Training loss: 0.2993493974208832
Validation loss: 1.6849172384508195

Epoch: 5| Step: 3
Training loss: 0.7462002038955688
Validation loss: 1.713529130463959

Epoch: 5| Step: 4
Training loss: 0.611079752445221
Validation loss: 1.7173882081944456

Epoch: 5| Step: 5
Training loss: 0.4165027141571045
Validation loss: 1.7303777894666117

Epoch: 5| Step: 6
Training loss: 0.3866923451423645
Validation loss: 1.734749202446271

Epoch: 5| Step: 7
Training loss: 0.5279632806777954
Validation loss: 1.7352143436349847

Epoch: 5| Step: 8
Training loss: 1.1084016561508179
Validation loss: 1.722466132974112

Epoch: 5| Step: 9
Training loss: 0.38285204768180847
Validation loss: 1.676961180984333

Epoch: 5| Step: 10
Training loss: 0.43296682834625244
Validation loss: 1.694254873901285

Epoch: 343| Step: 0
Training loss: 0.8133500218391418
Validation loss: 1.6893822070091002

Epoch: 5| Step: 1
Training loss: 0.6475473642349243
Validation loss: 1.6546486141861125

Epoch: 5| Step: 2
Training loss: 0.5058911442756653
Validation loss: 1.652624701940885

Epoch: 5| Step: 3
Training loss: 0.5867880582809448
Validation loss: 1.6775782076261376

Epoch: 5| Step: 4
Training loss: 0.8060749173164368
Validation loss: 1.661774181550549

Epoch: 5| Step: 5
Training loss: 0.46186012029647827
Validation loss: 1.6676066972876107

Epoch: 5| Step: 6
Training loss: 0.3834172487258911
Validation loss: 1.6412385522678334

Epoch: 5| Step: 7
Training loss: 0.444040447473526
Validation loss: 1.6966293652852376

Epoch: 5| Step: 8
Training loss: 0.5037597417831421
Validation loss: 1.6834760635129866

Epoch: 5| Step: 9
Training loss: 0.47605210542678833
Validation loss: 1.705657850029648

Epoch: 5| Step: 10
Training loss: 0.3916299045085907
Validation loss: 1.6594237025066088

Epoch: 344| Step: 0
Training loss: 0.20760683715343475
Validation loss: 1.665241700346752

Epoch: 5| Step: 1
Training loss: 0.8322148323059082
Validation loss: 1.6833419293485663

Epoch: 5| Step: 2
Training loss: 0.5948042869567871
Validation loss: 1.6882665785410071

Epoch: 5| Step: 3
Training loss: 0.467569500207901
Validation loss: 1.6852575796906666

Epoch: 5| Step: 4
Training loss: 0.4791502058506012
Validation loss: 1.6723495798726236

Epoch: 5| Step: 5
Training loss: 0.49901866912841797
Validation loss: 1.6905295887301046

Epoch: 5| Step: 6
Training loss: 0.8333619832992554
Validation loss: 1.7280961313555319

Epoch: 5| Step: 7
Training loss: 0.4192756712436676
Validation loss: 1.730219989694575

Epoch: 5| Step: 8
Training loss: 0.4839891493320465
Validation loss: 1.6901878579970329

Epoch: 5| Step: 9
Training loss: 0.5000317692756653
Validation loss: 1.6734593029945128

Epoch: 5| Step: 10
Training loss: 0.7295429706573486
Validation loss: 1.6929887366551224

Epoch: 345| Step: 0
Training loss: 0.5919522643089294
Validation loss: 1.6974338536621423

Epoch: 5| Step: 1
Training loss: 0.7518179416656494
Validation loss: 1.7009957298155753

Epoch: 5| Step: 2
Training loss: 0.6842737197875977
Validation loss: 1.7377605297232186

Epoch: 5| Step: 3
Training loss: 0.4685903489589691
Validation loss: 1.7333048120621712

Epoch: 5| Step: 4
Training loss: 0.765633761882782
Validation loss: 1.712039533481803

Epoch: 5| Step: 5
Training loss: 0.6306824088096619
Validation loss: 1.7026198089763682

Epoch: 5| Step: 6
Training loss: 0.36565619707107544
Validation loss: 1.7036500374476116

Epoch: 5| Step: 7
Training loss: 0.3646697402000427
Validation loss: 1.7006020622868692

Epoch: 5| Step: 8
Training loss: 0.5430002212524414
Validation loss: 1.7157279496551843

Epoch: 5| Step: 9
Training loss: 0.5130919814109802
Validation loss: 1.6867920788385535

Epoch: 5| Step: 10
Training loss: 0.5450617671012878
Validation loss: 1.661059239859222

Epoch: 346| Step: 0
Training loss: 0.5200244188308716
Validation loss: 1.655001530083277

Epoch: 5| Step: 1
Training loss: 0.4222007691860199
Validation loss: 1.6469093356081235

Epoch: 5| Step: 2
Training loss: 0.5466058254241943
Validation loss: 1.6202544320014216

Epoch: 5| Step: 3
Training loss: 0.5676318407058716
Validation loss: 1.6703453512601956

Epoch: 5| Step: 4
Training loss: 0.4522838592529297
Validation loss: 1.6576012424243394

Epoch: 5| Step: 5
Training loss: 0.6267697215080261
Validation loss: 1.6586235569369407

Epoch: 5| Step: 6
Training loss: 0.6819141507148743
Validation loss: 1.6831315589207474

Epoch: 5| Step: 7
Training loss: 0.4976000189781189
Validation loss: 1.6779312767008299

Epoch: 5| Step: 8
Training loss: 0.48150435090065
Validation loss: 1.6804106786686888

Epoch: 5| Step: 9
Training loss: 0.35418540239334106
Validation loss: 1.6984906658049552

Epoch: 5| Step: 10
Training loss: 0.720668613910675
Validation loss: 1.6984597867535007

Epoch: 347| Step: 0
Training loss: 0.33551841974258423
Validation loss: 1.676050773230932

Epoch: 5| Step: 1
Training loss: 0.8804782629013062
Validation loss: 1.6774408625018211

Epoch: 5| Step: 2
Training loss: 0.5678561925888062
Validation loss: 1.6890621646758048

Epoch: 5| Step: 3
Training loss: 0.5143964886665344
Validation loss: 1.673071143447712

Epoch: 5| Step: 4
Training loss: 0.5130671858787537
Validation loss: 1.7129324610515306

Epoch: 5| Step: 5
Training loss: 0.5122469663619995
Validation loss: 1.658645373518749

Epoch: 5| Step: 6
Training loss: 0.45479851961135864
Validation loss: 1.6838035634768906

Epoch: 5| Step: 7
Training loss: 0.5693258047103882
Validation loss: 1.6786038465397333

Epoch: 5| Step: 8
Training loss: 0.6003544926643372
Validation loss: 1.6593745491837943

Epoch: 5| Step: 9
Training loss: 0.47619980573654175
Validation loss: 1.6654486528006933

Epoch: 5| Step: 10
Training loss: 0.40046820044517517
Validation loss: 1.6446331399743275

Epoch: 348| Step: 0
Training loss: 0.7074364423751831
Validation loss: 1.6442068546049056

Epoch: 5| Step: 1
Training loss: 0.33531397581100464
Validation loss: 1.645207187180878

Epoch: 5| Step: 2
Training loss: 0.6702197790145874
Validation loss: 1.6415302086901922

Epoch: 5| Step: 3
Training loss: 0.4662711024284363
Validation loss: 1.6708859128336753

Epoch: 5| Step: 4
Training loss: 0.563310980796814
Validation loss: 1.6510989050711355

Epoch: 5| Step: 5
Training loss: 0.3252640664577484
Validation loss: 1.6520953024587324

Epoch: 5| Step: 6
Training loss: 0.407331645488739
Validation loss: 1.6534336151615265

Epoch: 5| Step: 7
Training loss: 0.5575952529907227
Validation loss: 1.6377004673404079

Epoch: 5| Step: 8
Training loss: 0.3066937029361725
Validation loss: 1.6420725020029212

Epoch: 5| Step: 9
Training loss: 0.510574221611023
Validation loss: 1.6014231430586947

Epoch: 5| Step: 10
Training loss: 0.6288437843322754
Validation loss: 1.6619907348386702

Epoch: 349| Step: 0
Training loss: 0.5818000435829163
Validation loss: 1.6065735560591503

Epoch: 5| Step: 1
Training loss: 0.4890885353088379
Validation loss: 1.6171487223717473

Epoch: 5| Step: 2
Training loss: 0.8304446935653687
Validation loss: 1.663193126519521

Epoch: 5| Step: 3
Training loss: 0.5301724672317505
Validation loss: 1.6359749340241956

Epoch: 5| Step: 4
Training loss: 0.4609529376029968
Validation loss: 1.6738230143823931

Epoch: 5| Step: 5
Training loss: 0.5231771469116211
Validation loss: 1.6708918886799966

Epoch: 5| Step: 6
Training loss: 0.3984277546405792
Validation loss: 1.6790994777474353

Epoch: 5| Step: 7
Training loss: 0.3978097438812256
Validation loss: 1.7157387944959825

Epoch: 5| Step: 8
Training loss: 0.5906242728233337
Validation loss: 1.6978853184689757

Epoch: 5| Step: 9
Training loss: 0.5148802995681763
Validation loss: 1.6721104909014959

Epoch: 5| Step: 10
Training loss: 0.25228631496429443
Validation loss: 1.6768057820617512

Epoch: 350| Step: 0
Training loss: 0.5624182820320129
Validation loss: 1.7108189585388347

Epoch: 5| Step: 1
Training loss: 0.41472911834716797
Validation loss: 1.6874276156066566

Epoch: 5| Step: 2
Training loss: 0.5535236597061157
Validation loss: 1.6686649848056097

Epoch: 5| Step: 3
Training loss: 0.42748814821243286
Validation loss: 1.6801069500625774

Epoch: 5| Step: 4
Training loss: 0.32061031460762024
Validation loss: 1.695952268056972

Epoch: 5| Step: 5
Training loss: 0.6112911105155945
Validation loss: 1.6806153302551599

Epoch: 5| Step: 6
Training loss: 0.6686898469924927
Validation loss: 1.7092637477382537

Epoch: 5| Step: 7
Training loss: 0.4233410954475403
Validation loss: 1.7057032662053262

Epoch: 5| Step: 8
Training loss: 0.4185374677181244
Validation loss: 1.6830320153185117

Epoch: 5| Step: 9
Training loss: 0.375922292470932
Validation loss: 1.664360829578933

Epoch: 5| Step: 10
Training loss: 0.7280155420303345
Validation loss: 1.6807849343105028

Epoch: 351| Step: 0
Training loss: 0.4920808672904968
Validation loss: 1.6661256000559816

Epoch: 5| Step: 1
Training loss: 0.42471280694007874
Validation loss: 1.7066432660625828

Epoch: 5| Step: 2
Training loss: 0.5373145341873169
Validation loss: 1.666706282605407

Epoch: 5| Step: 3
Training loss: 0.40250474214553833
Validation loss: 1.6748007497479838

Epoch: 5| Step: 4
Training loss: 0.5630403161048889
Validation loss: 1.674917153132859

Epoch: 5| Step: 5
Training loss: 0.4497244358062744
Validation loss: 1.6964423861554874

Epoch: 5| Step: 6
Training loss: 0.47177910804748535
Validation loss: 1.6534963013023458

Epoch: 5| Step: 7
Training loss: 0.49599727988243103
Validation loss: 1.6474804519325175

Epoch: 5| Step: 8
Training loss: 0.691961407661438
Validation loss: 1.6320853117973573

Epoch: 5| Step: 9
Training loss: 0.5817989110946655
Validation loss: 1.6333461217982794

Epoch: 5| Step: 10
Training loss: 0.38752198219299316
Validation loss: 1.641136606534322

Epoch: 352| Step: 0
Training loss: 0.700241208076477
Validation loss: 1.651508444099016

Epoch: 5| Step: 1
Training loss: 0.3995736241340637
Validation loss: 1.6459753936336887

Epoch: 5| Step: 2
Training loss: 0.3020727336406708
Validation loss: 1.6977674307361725

Epoch: 5| Step: 3
Training loss: 0.509952962398529
Validation loss: 1.7061741903264036

Epoch: 5| Step: 4
Training loss: 0.4719749391078949
Validation loss: 1.6921463743332894

Epoch: 5| Step: 5
Training loss: 0.7518776655197144
Validation loss: 1.6906814626468125

Epoch: 5| Step: 6
Training loss: 0.4243105351924896
Validation loss: 1.6442100489011375

Epoch: 5| Step: 7
Training loss: 0.2695402204990387
Validation loss: 1.6733943352135279

Epoch: 5| Step: 8
Training loss: 0.8776376843452454
Validation loss: 1.6826006814997683

Epoch: 5| Step: 9
Training loss: 0.3321560025215149
Validation loss: 1.6556458870569866

Epoch: 5| Step: 10
Training loss: 0.5182399153709412
Validation loss: 1.6487838183679888

Epoch: 353| Step: 0
Training loss: 0.420236200094223
Validation loss: 1.6758461882991176

Epoch: 5| Step: 1
Training loss: 0.47426992654800415
Validation loss: 1.7174193859100342

Epoch: 5| Step: 2
Training loss: 0.5110677480697632
Validation loss: 1.7227648483809603

Epoch: 5| Step: 3
Training loss: 0.5169034600257874
Validation loss: 1.7536284218552292

Epoch: 5| Step: 4
Training loss: 0.33873382210731506
Validation loss: 1.6875354602772703

Epoch: 5| Step: 5
Training loss: 0.5914068818092346
Validation loss: 1.6941326869431363

Epoch: 5| Step: 6
Training loss: 0.46293607354164124
Validation loss: 1.66391783888622

Epoch: 5| Step: 7
Training loss: 0.5351687669754028
Validation loss: 1.6687240344221874

Epoch: 5| Step: 8
Training loss: 0.6890612840652466
Validation loss: 1.6619174480438232

Epoch: 5| Step: 9
Training loss: 0.4942834973335266
Validation loss: 1.6460413573890604

Epoch: 5| Step: 10
Training loss: 0.5165016055107117
Validation loss: 1.6244879448285667

Epoch: 354| Step: 0
Training loss: 0.48052993416786194
Validation loss: 1.6284152756455124

Epoch: 5| Step: 1
Training loss: 0.39265984296798706
Validation loss: 1.6282719847976521

Epoch: 5| Step: 2
Training loss: 0.5641598105430603
Validation loss: 1.6231251044939923

Epoch: 5| Step: 3
Training loss: 0.3249199688434601
Validation loss: 1.6478260499174877

Epoch: 5| Step: 4
Training loss: 0.5886478424072266
Validation loss: 1.6355503669349096

Epoch: 5| Step: 5
Training loss: 0.42289218306541443
Validation loss: 1.6522859796400993

Epoch: 5| Step: 6
Training loss: 0.45790067315101624
Validation loss: 1.6783518957835373

Epoch: 5| Step: 7
Training loss: 0.4598453640937805
Validation loss: 1.6250350321492841

Epoch: 5| Step: 8
Training loss: 0.6772478222846985
Validation loss: 1.6663268663549935

Epoch: 5| Step: 9
Training loss: 0.4751063287258148
Validation loss: 1.6541577077681018

Epoch: 5| Step: 10
Training loss: 0.39835718274116516
Validation loss: 1.672086937453157

Epoch: 355| Step: 0
Training loss: 0.3968314528465271
Validation loss: 1.6641270229893346

Epoch: 5| Step: 1
Training loss: 0.31548571586608887
Validation loss: 1.6721091026900916

Epoch: 5| Step: 2
Training loss: 0.5422865152359009
Validation loss: 1.6495036296947028

Epoch: 5| Step: 3
Training loss: 0.6265074610710144
Validation loss: 1.6592652477243894

Epoch: 5| Step: 4
Training loss: 0.5744619965553284
Validation loss: 1.669250456235742

Epoch: 5| Step: 5
Training loss: 0.4882650375366211
Validation loss: 1.6644210136064919

Epoch: 5| Step: 6
Training loss: 0.5759297609329224
Validation loss: 1.678078261754846

Epoch: 5| Step: 7
Training loss: 0.3234521746635437
Validation loss: 1.658573499289892

Epoch: 5| Step: 8
Training loss: 0.5395902991294861
Validation loss: 1.6820550208450646

Epoch: 5| Step: 9
Training loss: 0.5078295469284058
Validation loss: 1.71100264979947

Epoch: 5| Step: 10
Training loss: 0.3781234920024872
Validation loss: 1.6697726864968576

Epoch: 356| Step: 0
Training loss: 0.5968473553657532
Validation loss: 1.6723343838927567

Epoch: 5| Step: 1
Training loss: 0.6085049510002136
Validation loss: 1.6531995637442476

Epoch: 5| Step: 2
Training loss: 0.5492141246795654
Validation loss: 1.6517273610638035

Epoch: 5| Step: 3
Training loss: 0.35939210653305054
Validation loss: 1.6654784307684949

Epoch: 5| Step: 4
Training loss: 0.4266044497489929
Validation loss: 1.6654161278919508

Epoch: 5| Step: 5
Training loss: 0.40078848600387573
Validation loss: 1.6744743906041628

Epoch: 5| Step: 6
Training loss: 0.30124038457870483
Validation loss: 1.6687892226762668

Epoch: 5| Step: 7
Training loss: 0.5532152652740479
Validation loss: 1.6751841563050465

Epoch: 5| Step: 8
Training loss: 0.33122777938842773
Validation loss: 1.6624986420395553

Epoch: 5| Step: 9
Training loss: 0.5748473405838013
Validation loss: 1.662408431371053

Epoch: 5| Step: 10
Training loss: 0.601538360118866
Validation loss: 1.6475338756397206

Epoch: 357| Step: 0
Training loss: 0.6301570534706116
Validation loss: 1.6643722313706593

Epoch: 5| Step: 1
Training loss: 0.22737443447113037
Validation loss: 1.6378599636016353

Epoch: 5| Step: 2
Training loss: 0.27661338448524475
Validation loss: 1.64427468469066

Epoch: 5| Step: 3
Training loss: 0.5850905776023865
Validation loss: 1.6727874714841124

Epoch: 5| Step: 4
Training loss: 0.5472882390022278
Validation loss: 1.6662840638109433

Epoch: 5| Step: 5
Training loss: 0.35975170135498047
Validation loss: 1.6771672733368412

Epoch: 5| Step: 6
Training loss: 0.4210112690925598
Validation loss: 1.6901612973982287

Epoch: 5| Step: 7
Training loss: 0.4388173520565033
Validation loss: 1.6851985018740419

Epoch: 5| Step: 8
Training loss: 0.5421980619430542
Validation loss: 1.6889275940515662

Epoch: 5| Step: 9
Training loss: 0.344343364238739
Validation loss: 1.685814724173597

Epoch: 5| Step: 10
Training loss: 0.6661043763160706
Validation loss: 1.6698038603669854

Epoch: 358| Step: 0
Training loss: 0.40265780687332153
Validation loss: 1.6471415950405983

Epoch: 5| Step: 1
Training loss: 0.4245576858520508
Validation loss: 1.6570874388499925

Epoch: 5| Step: 2
Training loss: 0.32862144708633423
Validation loss: 1.644633423897528

Epoch: 5| Step: 3
Training loss: 0.3816113770008087
Validation loss: 1.6304201836227088

Epoch: 5| Step: 4
Training loss: 0.5324957370758057
Validation loss: 1.6435735135950067

Epoch: 5| Step: 5
Training loss: 0.7287638783454895
Validation loss: 1.6255009866529895

Epoch: 5| Step: 6
Training loss: 0.4099867343902588
Validation loss: 1.6592601512068061

Epoch: 5| Step: 7
Training loss: 0.5173514485359192
Validation loss: 1.6562537890608593

Epoch: 5| Step: 8
Training loss: 0.4113449156284332
Validation loss: 1.6393381934012137

Epoch: 5| Step: 9
Training loss: 0.6348155736923218
Validation loss: 1.6383552589724142

Epoch: 5| Step: 10
Training loss: 0.628923237323761
Validation loss: 1.6239057740857523

Epoch: 359| Step: 0
Training loss: 0.4213307797908783
Validation loss: 1.6297477663204234

Epoch: 5| Step: 1
Training loss: 0.6110869646072388
Validation loss: 1.6396786846140379

Epoch: 5| Step: 2
Training loss: 0.2378157377243042
Validation loss: 1.6598306086755568

Epoch: 5| Step: 3
Training loss: 0.33417099714279175
Validation loss: 1.7014512105654644

Epoch: 5| Step: 4
Training loss: 0.4773501455783844
Validation loss: 1.7145475995156072

Epoch: 5| Step: 5
Training loss: 0.6228562593460083
Validation loss: 1.7254860760063253

Epoch: 5| Step: 6
Training loss: 0.6411994695663452
Validation loss: 1.673914086434149

Epoch: 5| Step: 7
Training loss: 0.46642714738845825
Validation loss: 1.651322708334974

Epoch: 5| Step: 8
Training loss: 0.4028862416744232
Validation loss: 1.6203332460054787

Epoch: 5| Step: 9
Training loss: 0.5289098024368286
Validation loss: 1.6281269417014173

Epoch: 5| Step: 10
Training loss: 0.5587766170501709
Validation loss: 1.6297460845721665

Epoch: 360| Step: 0
Training loss: 0.5298841595649719
Validation loss: 1.623532546463833

Epoch: 5| Step: 1
Training loss: 0.303837388753891
Validation loss: 1.6373540739859305

Epoch: 5| Step: 2
Training loss: 0.6314821243286133
Validation loss: 1.6311845728146133

Epoch: 5| Step: 3
Training loss: 0.5402944684028625
Validation loss: 1.6428340519628217

Epoch: 5| Step: 4
Training loss: 0.4919079840183258
Validation loss: 1.6359365268420147

Epoch: 5| Step: 5
Training loss: 0.5266861915588379
Validation loss: 1.6827226761848695

Epoch: 5| Step: 6
Training loss: 0.7111402750015259
Validation loss: 1.7071608022976947

Epoch: 5| Step: 7
Training loss: 0.3452608585357666
Validation loss: 1.7195993713153306

Epoch: 5| Step: 8
Training loss: 0.3455600142478943
Validation loss: 1.705593373826755

Epoch: 5| Step: 9
Training loss: 0.5296327471733093
Validation loss: 1.67089763123502

Epoch: 5| Step: 10
Training loss: 0.3254818618297577
Validation loss: 1.6710586727306407

Epoch: 361| Step: 0
Training loss: 0.7909634709358215
Validation loss: 1.6927980376828102

Epoch: 5| Step: 1
Training loss: 0.38812142610549927
Validation loss: 1.6579016946977185

Epoch: 5| Step: 2
Training loss: 0.5797184705734253
Validation loss: 1.6665165039800829

Epoch: 5| Step: 3
Training loss: 0.4495328962802887
Validation loss: 1.6398158598971624

Epoch: 5| Step: 4
Training loss: 0.40820083022117615
Validation loss: 1.6615358193715413

Epoch: 5| Step: 5
Training loss: 0.4447675347328186
Validation loss: 1.6676757720208937

Epoch: 5| Step: 6
Training loss: 0.37170010805130005
Validation loss: 1.6641832859285417

Epoch: 5| Step: 7
Training loss: 0.2648501396179199
Validation loss: 1.6563883673760198

Epoch: 5| Step: 8
Training loss: 0.6288913488388062
Validation loss: 1.6297970048842891

Epoch: 5| Step: 9
Training loss: 0.44553035497665405
Validation loss: 1.6522573501833024

Epoch: 5| Step: 10
Training loss: 0.27741387486457825
Validation loss: 1.624089523028302

Epoch: 362| Step: 0
Training loss: 0.28074949979782104
Validation loss: 1.6614290027208225

Epoch: 5| Step: 1
Training loss: 0.4119585156440735
Validation loss: 1.668361880445993

Epoch: 5| Step: 2
Training loss: 0.18720003962516785
Validation loss: 1.6502334917745283

Epoch: 5| Step: 3
Training loss: 0.421759694814682
Validation loss: 1.6779847350171817

Epoch: 5| Step: 4
Training loss: 0.36730271577835083
Validation loss: 1.659793435886342

Epoch: 5| Step: 5
Training loss: 0.386589914560318
Validation loss: 1.6573850659913913

Epoch: 5| Step: 6
Training loss: 0.42731791734695435
Validation loss: 1.6634446722204967

Epoch: 5| Step: 7
Training loss: 0.8927985429763794
Validation loss: 1.6427183715246056

Epoch: 5| Step: 8
Training loss: 0.5339627265930176
Validation loss: 1.6503479544834425

Epoch: 5| Step: 9
Training loss: 0.4274836480617523
Validation loss: 1.644368270392059

Epoch: 5| Step: 10
Training loss: 0.6775100827217102
Validation loss: 1.632794442997184

Epoch: 363| Step: 0
Training loss: 0.6413879990577698
Validation loss: 1.6531652609507244

Epoch: 5| Step: 1
Training loss: 0.648945689201355
Validation loss: 1.6440666862713393

Epoch: 5| Step: 2
Training loss: 0.5376514196395874
Validation loss: 1.6551657620296683

Epoch: 5| Step: 3
Training loss: 0.3499424457550049
Validation loss: 1.6629990172642533

Epoch: 5| Step: 4
Training loss: 0.28757673501968384
Validation loss: 1.6599810815626574

Epoch: 5| Step: 5
Training loss: 0.5296307802200317
Validation loss: 1.6861696089467695

Epoch: 5| Step: 6
Training loss: 0.6423196196556091
Validation loss: 1.7161757535831903

Epoch: 5| Step: 7
Training loss: 0.4645290970802307
Validation loss: 1.7067294351516231

Epoch: 5| Step: 8
Training loss: 0.33631443977355957
Validation loss: 1.6559319842246272

Epoch: 5| Step: 9
Training loss: 0.20475058257579803
Validation loss: 1.6664244410812215

Epoch: 5| Step: 10
Training loss: 0.4671962559223175
Validation loss: 1.6428783247547765

Epoch: 364| Step: 0
Training loss: 0.5457658171653748
Validation loss: 1.6651484504822762

Epoch: 5| Step: 1
Training loss: 0.514648973941803
Validation loss: 1.6448426567098147

Epoch: 5| Step: 2
Training loss: 0.531082272529602
Validation loss: 1.642920563297887

Epoch: 5| Step: 3
Training loss: 0.3397567868232727
Validation loss: 1.656546054347869

Epoch: 5| Step: 4
Training loss: 0.3913312554359436
Validation loss: 1.6956425943682272

Epoch: 5| Step: 5
Training loss: 0.791124165058136
Validation loss: 1.7183116584695795

Epoch: 5| Step: 6
Training loss: 0.5607696771621704
Validation loss: 1.705976463133289

Epoch: 5| Step: 7
Training loss: 0.3720320463180542
Validation loss: 1.663603610248976

Epoch: 5| Step: 8
Training loss: 0.6396594643592834
Validation loss: 1.6577407185749342

Epoch: 5| Step: 9
Training loss: 0.4775867462158203
Validation loss: 1.6295813052884993

Epoch: 5| Step: 10
Training loss: 0.3412086069583893
Validation loss: 1.6659296968931794

Epoch: 365| Step: 0
Training loss: 0.33755362033843994
Validation loss: 1.6492263809327157

Epoch: 5| Step: 1
Training loss: 0.7099478840827942
Validation loss: 1.6704371321585871

Epoch: 5| Step: 2
Training loss: 0.3138046860694885
Validation loss: 1.678872795515163

Epoch: 5| Step: 3
Training loss: 0.4952888488769531
Validation loss: 1.7063514083944342

Epoch: 5| Step: 4
Training loss: 0.47321492433547974
Validation loss: 1.7294323687912316

Epoch: 5| Step: 5
Training loss: 0.339146226644516
Validation loss: 1.7008295123295119

Epoch: 5| Step: 6
Training loss: 0.6287586092948914
Validation loss: 1.6956243899560743

Epoch: 5| Step: 7
Training loss: 0.346660315990448
Validation loss: 1.730047707916588

Epoch: 5| Step: 8
Training loss: 0.41490182280540466
Validation loss: 1.6956659696435417

Epoch: 5| Step: 9
Training loss: 0.5200026631355286
Validation loss: 1.6735438121262418

Epoch: 5| Step: 10
Training loss: 0.47934767603874207
Validation loss: 1.7102407217025757

Epoch: 366| Step: 0
Training loss: 0.35740289092063904
Validation loss: 1.674421097642632

Epoch: 5| Step: 1
Training loss: 0.6043190360069275
Validation loss: 1.6730003549206642

Epoch: 5| Step: 2
Training loss: 0.3598140478134155
Validation loss: 1.6834841851265199

Epoch: 5| Step: 3
Training loss: 0.36534667015075684
Validation loss: 1.6780161293604041

Epoch: 5| Step: 4
Training loss: 0.4772737920284271
Validation loss: 1.6725673906264766

Epoch: 5| Step: 5
Training loss: 0.5863432884216309
Validation loss: 1.7128014949060255

Epoch: 5| Step: 6
Training loss: 0.5329511761665344
Validation loss: 1.718739172463776

Epoch: 5| Step: 7
Training loss: 0.35108405351638794
Validation loss: 1.6820771322455457

Epoch: 5| Step: 8
Training loss: 0.3361411392688751
Validation loss: 1.69899873323338

Epoch: 5| Step: 9
Training loss: 0.5269001722335815
Validation loss: 1.6632188379123647

Epoch: 5| Step: 10
Training loss: 0.36762404441833496
Validation loss: 1.6495685449210546

Epoch: 367| Step: 0
Training loss: 0.4452241063117981
Validation loss: 1.6482482443573654

Epoch: 5| Step: 1
Training loss: 0.5161380767822266
Validation loss: 1.6489091022040254

Epoch: 5| Step: 2
Training loss: 0.4272190034389496
Validation loss: 1.640300537950249

Epoch: 5| Step: 3
Training loss: 0.36676299571990967
Validation loss: 1.6398259209048363

Epoch: 5| Step: 4
Training loss: 0.3798747956752777
Validation loss: 1.6385446838153306

Epoch: 5| Step: 5
Training loss: 0.2134477198123932
Validation loss: 1.6577915581323768

Epoch: 5| Step: 6
Training loss: 0.5246489644050598
Validation loss: 1.667023866407333

Epoch: 5| Step: 7
Training loss: 0.4230126738548279
Validation loss: 1.6922726720891974

Epoch: 5| Step: 8
Training loss: 0.3510214388370514
Validation loss: 1.690544230963594

Epoch: 5| Step: 9
Training loss: 0.5436705350875854
Validation loss: 1.6907345671807565

Epoch: 5| Step: 10
Training loss: 0.46153929829597473
Validation loss: 1.684890515060835

Epoch: 368| Step: 0
Training loss: 0.4229959547519684
Validation loss: 1.7163041304516535

Epoch: 5| Step: 1
Training loss: 0.44365543127059937
Validation loss: 1.6899650250711749

Epoch: 5| Step: 2
Training loss: 0.34597721695899963
Validation loss: 1.6951087828605407

Epoch: 5| Step: 3
Training loss: 0.2946057915687561
Validation loss: 1.6478085684519943

Epoch: 5| Step: 4
Training loss: 0.5369971990585327
Validation loss: 1.6466505565950948

Epoch: 5| Step: 5
Training loss: 0.32108423113822937
Validation loss: 1.6259101680530015

Epoch: 5| Step: 6
Training loss: 0.33783483505249023
Validation loss: 1.6539523614350187

Epoch: 5| Step: 7
Training loss: 0.5120574235916138
Validation loss: 1.6514386861555037

Epoch: 5| Step: 8
Training loss: 0.2663295865058899
Validation loss: 1.6442002622030114

Epoch: 5| Step: 9
Training loss: 0.5760226845741272
Validation loss: 1.6559563990562194

Epoch: 5| Step: 10
Training loss: 0.3354339003562927
Validation loss: 1.663614123098312

Epoch: 369| Step: 0
Training loss: 0.32573169469833374
Validation loss: 1.6648460767602409

Epoch: 5| Step: 1
Training loss: 0.35235416889190674
Validation loss: 1.6592780287547777

Epoch: 5| Step: 2
Training loss: 0.5107957124710083
Validation loss: 1.664195022275371

Epoch: 5| Step: 3
Training loss: 0.4202798306941986
Validation loss: 1.67649406643324

Epoch: 5| Step: 4
Training loss: 0.3452993333339691
Validation loss: 1.6767557090328586

Epoch: 5| Step: 5
Training loss: 0.49359840154647827
Validation loss: 1.6693200949699647

Epoch: 5| Step: 6
Training loss: 0.4080938398838043
Validation loss: 1.681345074407516

Epoch: 5| Step: 7
Training loss: 0.3863227069377899
Validation loss: 1.6753888642916115

Epoch: 5| Step: 8
Training loss: 0.358964741230011
Validation loss: 1.671427313999463

Epoch: 5| Step: 9
Training loss: 0.26908862590789795
Validation loss: 1.6634608237974104

Epoch: 5| Step: 10
Training loss: 0.5059409141540527
Validation loss: 1.6508605480194092

Epoch: 370| Step: 0
Training loss: 0.4412704408168793
Validation loss: 1.6666201776073826

Epoch: 5| Step: 1
Training loss: 0.3318902552127838
Validation loss: 1.7159295248728927

Epoch: 5| Step: 2
Training loss: 0.43726029992103577
Validation loss: 1.6887809256071686

Epoch: 5| Step: 3
Training loss: 0.3201727867126465
Validation loss: 1.6725424566576559

Epoch: 5| Step: 4
Training loss: 0.4092453122138977
Validation loss: 1.6888877281578638

Epoch: 5| Step: 5
Training loss: 0.6468414068222046
Validation loss: 1.7306855929795133

Epoch: 5| Step: 6
Training loss: 0.2810820937156677
Validation loss: 1.7014875617078555

Epoch: 5| Step: 7
Training loss: 0.21830317378044128
Validation loss: 1.6699773855106805

Epoch: 5| Step: 8
Training loss: 0.4710024297237396
Validation loss: 1.6756712082893617

Epoch: 5| Step: 9
Training loss: 0.43839091062545776
Validation loss: 1.6496160543093117

Epoch: 5| Step: 10
Training loss: 0.38829290866851807
Validation loss: 1.6457093748995053

Epoch: 371| Step: 0
Training loss: 0.4958224296569824
Validation loss: 1.6536463088886713

Epoch: 5| Step: 1
Training loss: 0.3847953975200653
Validation loss: 1.6478952297600367

Epoch: 5| Step: 2
Training loss: 0.39128807187080383
Validation loss: 1.6720667295558478

Epoch: 5| Step: 3
Training loss: 0.41798168420791626
Validation loss: 1.6611845903499152

Epoch: 5| Step: 4
Training loss: 0.49267929792404175
Validation loss: 1.6460747987993303

Epoch: 5| Step: 5
Training loss: 0.325806587934494
Validation loss: 1.6631824457517235

Epoch: 5| Step: 6
Training loss: 0.35613715648651123
Validation loss: 1.6713041925943026

Epoch: 5| Step: 7
Training loss: 0.5179226398468018
Validation loss: 1.6491239468256633

Epoch: 5| Step: 8
Training loss: 0.4302993714809418
Validation loss: 1.6759291131009337

Epoch: 5| Step: 9
Training loss: 0.2463894635438919
Validation loss: 1.637166505218834

Epoch: 5| Step: 10
Training loss: 0.32439136505126953
Validation loss: 1.6496107462913758

Epoch: 372| Step: 0
Training loss: 0.3564212918281555
Validation loss: 1.639465759518326

Epoch: 5| Step: 1
Training loss: 0.5595887303352356
Validation loss: 1.654424036702802

Epoch: 5| Step: 2
Training loss: 0.3430507779121399
Validation loss: 1.6307131346835886

Epoch: 5| Step: 3
Training loss: 0.46318450570106506
Validation loss: 1.63896099469995

Epoch: 5| Step: 4
Training loss: 0.3557645380496979
Validation loss: 1.6293260948632353

Epoch: 5| Step: 5
Training loss: 0.2596374452114105
Validation loss: 1.6428902867019817

Epoch: 5| Step: 6
Training loss: 0.48884671926498413
Validation loss: 1.6138938127025482

Epoch: 5| Step: 7
Training loss: 0.5281405448913574
Validation loss: 1.6458945171807402

Epoch: 5| Step: 8
Training loss: 0.42892903089523315
Validation loss: 1.642402639953039

Epoch: 5| Step: 9
Training loss: 0.3133966028690338
Validation loss: 1.6378422629448675

Epoch: 5| Step: 10
Training loss: 0.3496030867099762
Validation loss: 1.6609546112757858

Epoch: 373| Step: 0
Training loss: 0.48260730504989624
Validation loss: 1.6574227168995848

Epoch: 5| Step: 1
Training loss: 0.3939202129840851
Validation loss: 1.6645310489080285

Epoch: 5| Step: 2
Training loss: 0.40890949964523315
Validation loss: 1.6482884140424832

Epoch: 5| Step: 3
Training loss: 0.26538366079330444
Validation loss: 1.652077821634149

Epoch: 5| Step: 4
Training loss: 0.3809555172920227
Validation loss: 1.6713130358726747

Epoch: 5| Step: 5
Training loss: 0.24230022728443146
Validation loss: 1.6670697965929586

Epoch: 5| Step: 6
Training loss: 0.533390998840332
Validation loss: 1.6572924301188479

Epoch: 5| Step: 7
Training loss: 0.3040841519832611
Validation loss: 1.6534109179691603

Epoch: 5| Step: 8
Training loss: 0.4137820303440094
Validation loss: 1.6396242380142212

Epoch: 5| Step: 9
Training loss: 0.5823072791099548
Validation loss: 1.6700572582983202

Epoch: 5| Step: 10
Training loss: 0.3883174657821655
Validation loss: 1.6684434183182255

Epoch: 374| Step: 0
Training loss: 0.4812011122703552
Validation loss: 1.6424621676885953

Epoch: 5| Step: 1
Training loss: 0.2867528796195984
Validation loss: 1.6606311080276326

Epoch: 5| Step: 2
Training loss: 0.461228609085083
Validation loss: 1.6589709789522233

Epoch: 5| Step: 3
Training loss: 0.2533704340457916
Validation loss: 1.6544683415402648

Epoch: 5| Step: 4
Training loss: 0.31491079926490784
Validation loss: 1.661676182541796

Epoch: 5| Step: 5
Training loss: 0.33477652072906494
Validation loss: 1.6430225346678047

Epoch: 5| Step: 6
Training loss: 0.3682127892971039
Validation loss: 1.612101931725779

Epoch: 5| Step: 7
Training loss: 0.25918012857437134
Validation loss: 1.647153792842742

Epoch: 5| Step: 8
Training loss: 0.41899481415748596
Validation loss: 1.6312791724358835

Epoch: 5| Step: 9
Training loss: 0.4822838306427002
Validation loss: 1.639242801614987

Epoch: 5| Step: 10
Training loss: 0.49891871213912964
Validation loss: 1.6185287660168064

Epoch: 375| Step: 0
Training loss: 0.34908992052078247
Validation loss: 1.6229324353638517

Epoch: 5| Step: 1
Training loss: 0.40985211730003357
Validation loss: 1.6423311553975588

Epoch: 5| Step: 2
Training loss: 0.3063914477825165
Validation loss: 1.6429852311329176

Epoch: 5| Step: 3
Training loss: 0.31458336114883423
Validation loss: 1.6286383828809183

Epoch: 5| Step: 4
Training loss: 0.3648197054862976
Validation loss: 1.6264941717988701

Epoch: 5| Step: 5
Training loss: 0.3918886184692383
Validation loss: 1.6484245331056657

Epoch: 5| Step: 6
Training loss: 0.5529161691665649
Validation loss: 1.6338541110356648

Epoch: 5| Step: 7
Training loss: 0.5005740523338318
Validation loss: 1.6357340338409587

Epoch: 5| Step: 8
Training loss: 0.30795860290527344
Validation loss: 1.610871813630545

Epoch: 5| Step: 9
Training loss: 0.250720739364624
Validation loss: 1.6218903064727783

Epoch: 5| Step: 10
Training loss: 0.24483352899551392
Validation loss: 1.6480508389011506

Epoch: 376| Step: 0
Training loss: 0.3966689705848694
Validation loss: 1.6395373946876937

Epoch: 5| Step: 1
Training loss: 0.5095045566558838
Validation loss: 1.6713689546431265

Epoch: 5| Step: 2
Training loss: 0.43618184328079224
Validation loss: 1.6611604870006602

Epoch: 5| Step: 3
Training loss: 0.3549676537513733
Validation loss: 1.6643387886785692

Epoch: 5| Step: 4
Training loss: 0.3864419758319855
Validation loss: 1.6665312705501434

Epoch: 5| Step: 5
Training loss: 0.35425493121147156
Validation loss: 1.6714867558530582

Epoch: 5| Step: 6
Training loss: 0.2663428783416748
Validation loss: 1.6190291771324732

Epoch: 5| Step: 7
Training loss: 0.3980522155761719
Validation loss: 1.6654084972155991

Epoch: 5| Step: 8
Training loss: 0.21173962950706482
Validation loss: 1.6481253165070728

Epoch: 5| Step: 9
Training loss: 0.4524257183074951
Validation loss: 1.6473589097299883

Epoch: 5| Step: 10
Training loss: 0.41852879524230957
Validation loss: 1.6652916323754094

Epoch: 377| Step: 0
Training loss: 0.4560111463069916
Validation loss: 1.6619182607179046

Epoch: 5| Step: 1
Training loss: 0.289218544960022
Validation loss: 1.6656382776075793

Epoch: 5| Step: 2
Training loss: 0.6275837421417236
Validation loss: 1.6820066718644993

Epoch: 5| Step: 3
Training loss: 0.42025071382522583
Validation loss: 1.7010806863025953

Epoch: 5| Step: 4
Training loss: 0.2966849207878113
Validation loss: 1.6921171911301152

Epoch: 5| Step: 5
Training loss: 0.3788377344608307
Validation loss: 1.6993530129873624

Epoch: 5| Step: 6
Training loss: 0.26001253724098206
Validation loss: 1.6923852761586506

Epoch: 5| Step: 7
Training loss: 0.38163304328918457
Validation loss: 1.6793895921399515

Epoch: 5| Step: 8
Training loss: 0.4138995110988617
Validation loss: 1.6694902245716383

Epoch: 5| Step: 9
Training loss: 0.16728070378303528
Validation loss: 1.6544446778553787

Epoch: 5| Step: 10
Training loss: 0.5777726173400879
Validation loss: 1.6501711594161166

Epoch: 378| Step: 0
Training loss: 0.4608830511569977
Validation loss: 1.696909305869892

Epoch: 5| Step: 1
Training loss: 0.2791297733783722
Validation loss: 1.6856969864137712

Epoch: 5| Step: 2
Training loss: 0.3640934228897095
Validation loss: 1.6913677633449595

Epoch: 5| Step: 3
Training loss: 0.42622414231300354
Validation loss: 1.6818477684451687

Epoch: 5| Step: 4
Training loss: 0.46643489599227905
Validation loss: 1.6839054694739721

Epoch: 5| Step: 5
Training loss: 0.27516141533851624
Validation loss: 1.701483549610261

Epoch: 5| Step: 6
Training loss: 0.4524480402469635
Validation loss: 1.7227964119244648

Epoch: 5| Step: 7
Training loss: 0.4013752341270447
Validation loss: 1.732900277260811

Epoch: 5| Step: 8
Training loss: 0.427683025598526
Validation loss: 1.7343413470893778

Epoch: 5| Step: 9
Training loss: 0.32641515135765076
Validation loss: 1.714661322614198

Epoch: 5| Step: 10
Training loss: 0.5592483282089233
Validation loss: 1.6808762242717128

Epoch: 379| Step: 0
Training loss: 0.43754148483276367
Validation loss: 1.6505701054808914

Epoch: 5| Step: 1
Training loss: 0.4308393597602844
Validation loss: 1.6170697571128927

Epoch: 5| Step: 2
Training loss: 0.4845448136329651
Validation loss: 1.5922266296161118

Epoch: 5| Step: 3
Training loss: 0.41559067368507385
Validation loss: 1.6424435389939176

Epoch: 5| Step: 4
Training loss: 0.29302269220352173
Validation loss: 1.6021564019623624

Epoch: 5| Step: 5
Training loss: 0.5035877227783203
Validation loss: 1.612294609828662

Epoch: 5| Step: 6
Training loss: 0.19979937374591827
Validation loss: 1.5766175459789973

Epoch: 5| Step: 7
Training loss: 0.31616249680519104
Validation loss: 1.6256306568781536

Epoch: 5| Step: 8
Training loss: 0.37042373418807983
Validation loss: 1.6164218841060516

Epoch: 5| Step: 9
Training loss: 0.3503805696964264
Validation loss: 1.6226648105088102

Epoch: 5| Step: 10
Training loss: 0.37022387981414795
Validation loss: 1.6351580145538493

Epoch: 380| Step: 0
Training loss: 0.5694501996040344
Validation loss: 1.6222927570343018

Epoch: 5| Step: 1
Training loss: 0.4355643689632416
Validation loss: 1.6378398941409202

Epoch: 5| Step: 2
Training loss: 0.2812426686286926
Validation loss: 1.6047725510853592

Epoch: 5| Step: 3
Training loss: 0.2812633812427521
Validation loss: 1.6348342382779686

Epoch: 5| Step: 4
Training loss: 0.45846328139305115
Validation loss: 1.6230149448558848

Epoch: 5| Step: 5
Training loss: 0.4102305769920349
Validation loss: 1.6107075419477237

Epoch: 5| Step: 6
Training loss: 0.37739720940589905
Validation loss: 1.6261986673519175

Epoch: 5| Step: 7
Training loss: 0.2804742455482483
Validation loss: 1.6166858750004922

Epoch: 5| Step: 8
Training loss: 0.33549994230270386
Validation loss: 1.6297952564813758

Epoch: 5| Step: 9
Training loss: 0.35427892208099365
Validation loss: 1.6027065374517953

Epoch: 5| Step: 10
Training loss: 0.26400113105773926
Validation loss: 1.6049753927415418

Epoch: 381| Step: 0
Training loss: 0.38224005699157715
Validation loss: 1.6259641890884728

Epoch: 5| Step: 1
Training loss: 0.43861955404281616
Validation loss: 1.5960401591434275

Epoch: 5| Step: 2
Training loss: 0.4803099036216736
Validation loss: 1.616708695247609

Epoch: 5| Step: 3
Training loss: 0.5126374959945679
Validation loss: 1.6027780386709398

Epoch: 5| Step: 4
Training loss: 0.3100757598876953
Validation loss: 1.6203970140026462

Epoch: 5| Step: 5
Training loss: 0.20448443293571472
Validation loss: 1.6162975859898392

Epoch: 5| Step: 6
Training loss: 0.3012145161628723
Validation loss: 1.6240388142165316

Epoch: 5| Step: 7
Training loss: 0.5067917704582214
Validation loss: 1.6334107146468213

Epoch: 5| Step: 8
Training loss: 0.2585292458534241
Validation loss: 1.6512681438076882

Epoch: 5| Step: 9
Training loss: 0.3191182315349579
Validation loss: 1.6584812210452171

Epoch: 5| Step: 10
Training loss: 0.21782977879047394
Validation loss: 1.6333041460283342

Epoch: 382| Step: 0
Training loss: 0.5647088289260864
Validation loss: 1.6237264205050725

Epoch: 5| Step: 1
Training loss: 0.2900480628013611
Validation loss: 1.6593279812925605

Epoch: 5| Step: 2
Training loss: 0.38477790355682373
Validation loss: 1.6288406554088797

Epoch: 5| Step: 3
Training loss: 0.1462346762418747
Validation loss: 1.6370538973039197

Epoch: 5| Step: 4
Training loss: 0.17835256457328796
Validation loss: 1.633766665253588

Epoch: 5| Step: 5
Training loss: 0.5269373655319214
Validation loss: 1.6302830198759675

Epoch: 5| Step: 6
Training loss: 0.2305515706539154
Validation loss: 1.6107144996684084

Epoch: 5| Step: 7
Training loss: 0.49702683091163635
Validation loss: 1.6197964260655064

Epoch: 5| Step: 8
Training loss: 0.3620389699935913
Validation loss: 1.6215408335449875

Epoch: 5| Step: 9
Training loss: 0.3937026560306549
Validation loss: 1.6030380264405282

Epoch: 5| Step: 10
Training loss: 0.37429279088974
Validation loss: 1.605954280463598

Epoch: 383| Step: 0
Training loss: 0.2717895805835724
Validation loss: 1.6100005013968355

Epoch: 5| Step: 1
Training loss: 0.3089624345302582
Validation loss: 1.6265135593311761

Epoch: 5| Step: 2
Training loss: 0.45319676399230957
Validation loss: 1.5848708588589904

Epoch: 5| Step: 3
Training loss: 0.3900274336338043
Validation loss: 1.6153250176419494

Epoch: 5| Step: 4
Training loss: 0.26420730352401733
Validation loss: 1.6508126092213455

Epoch: 5| Step: 5
Training loss: 0.3632376790046692
Validation loss: 1.6276708828505648

Epoch: 5| Step: 6
Training loss: 0.14794541895389557
Validation loss: 1.6274364545781126

Epoch: 5| Step: 7
Training loss: 0.3179091811180115
Validation loss: 1.6535435613765512

Epoch: 5| Step: 8
Training loss: 0.541425347328186
Validation loss: 1.6405436223553074

Epoch: 5| Step: 9
Training loss: 0.6018932461738586
Validation loss: 1.6349660658067273

Epoch: 5| Step: 10
Training loss: 0.36373552680015564
Validation loss: 1.6098000176491276

Epoch: 384| Step: 0
Training loss: 0.4583578109741211
Validation loss: 1.6175374241285427

Epoch: 5| Step: 1
Training loss: 0.3683639466762543
Validation loss: 1.6265429014800696

Epoch: 5| Step: 2
Training loss: 0.21192970871925354
Validation loss: 1.6390963369800198

Epoch: 5| Step: 3
Training loss: 0.39617258310317993
Validation loss: 1.6430662908861715

Epoch: 5| Step: 4
Training loss: 0.3561320900917053
Validation loss: 1.6389849544853292

Epoch: 5| Step: 5
Training loss: 0.33980363607406616
Validation loss: 1.6717080454672537

Epoch: 5| Step: 6
Training loss: 0.385877400636673
Validation loss: 1.6696354842955066

Epoch: 5| Step: 7
Training loss: 0.38414040207862854
Validation loss: 1.684661897279883

Epoch: 5| Step: 8
Training loss: 0.2696132957935333
Validation loss: 1.664568462679463

Epoch: 5| Step: 9
Training loss: 0.3871479034423828
Validation loss: 1.6328577226208103

Epoch: 5| Step: 10
Training loss: 0.38458573818206787
Validation loss: 1.6157313918554654

Epoch: 385| Step: 0
Training loss: 0.5566998720169067
Validation loss: 1.6062068913572578

Epoch: 5| Step: 1
Training loss: 0.3206575810909271
Validation loss: 1.607980320530553

Epoch: 5| Step: 2
Training loss: 0.38274699449539185
Validation loss: 1.5849793598216066

Epoch: 5| Step: 3
Training loss: 0.2742207944393158
Validation loss: 1.5938041338356592

Epoch: 5| Step: 4
Training loss: 0.4079047739505768
Validation loss: 1.594415719150215

Epoch: 5| Step: 5
Training loss: 0.36612528562545776
Validation loss: 1.6043708773069485

Epoch: 5| Step: 6
Training loss: 0.30886751413345337
Validation loss: 1.5984857697640695

Epoch: 5| Step: 7
Training loss: 0.22706246376037598
Validation loss: 1.6046000738297739

Epoch: 5| Step: 8
Training loss: 0.35541558265686035
Validation loss: 1.6069194937265048

Epoch: 5| Step: 9
Training loss: 0.38321566581726074
Validation loss: 1.59207756416772

Epoch: 5| Step: 10
Training loss: 0.3573566675186157
Validation loss: 1.6118017108209672

Epoch: 386| Step: 0
Training loss: 0.4330406188964844
Validation loss: 1.6140751313137751

Epoch: 5| Step: 1
Training loss: 0.5061254501342773
Validation loss: 1.6051230071693339

Epoch: 5| Step: 2
Training loss: 0.37286821007728577
Validation loss: 1.5816954669132028

Epoch: 5| Step: 3
Training loss: 0.41038355231285095
Validation loss: 1.5780574096146451

Epoch: 5| Step: 4
Training loss: 0.13087508082389832
Validation loss: 1.5715386252249441

Epoch: 5| Step: 5
Training loss: 0.29236704111099243
Validation loss: 1.6138036186977098

Epoch: 5| Step: 6
Training loss: 0.2662303149700165
Validation loss: 1.5595481869994954

Epoch: 5| Step: 7
Training loss: 0.2699818015098572
Validation loss: 1.5738406142880839

Epoch: 5| Step: 8
Training loss: 0.4081413745880127
Validation loss: 1.5915490132506176

Epoch: 5| Step: 9
Training loss: 0.3107075095176697
Validation loss: 1.5506482124328613

Epoch: 5| Step: 10
Training loss: 0.43714699149131775
Validation loss: 1.5796229211232995

Epoch: 387| Step: 0
Training loss: 0.3621022403240204
Validation loss: 1.5934853669135802

Epoch: 5| Step: 1
Training loss: 0.3575866222381592
Validation loss: 1.616872138874505

Epoch: 5| Step: 2
Training loss: 0.44745177030563354
Validation loss: 1.6361532954759495

Epoch: 5| Step: 3
Training loss: 0.25331398844718933
Validation loss: 1.64329618536016

Epoch: 5| Step: 4
Training loss: 0.48353761434555054
Validation loss: 1.6115939219792683

Epoch: 5| Step: 5
Training loss: 0.2751275599002838
Validation loss: 1.6419144125394924

Epoch: 5| Step: 6
Training loss: 0.16307078301906586
Validation loss: 1.6212026842178837

Epoch: 5| Step: 7
Training loss: 0.3780302405357361
Validation loss: 1.6356473142100918

Epoch: 5| Step: 8
Training loss: 0.23168492317199707
Validation loss: 1.608044626892254

Epoch: 5| Step: 9
Training loss: 0.2883814871311188
Validation loss: 1.632284451556462

Epoch: 5| Step: 10
Training loss: 0.547065258026123
Validation loss: 1.633764108022054

Epoch: 388| Step: 0
Training loss: 0.42269009351730347
Validation loss: 1.6059524013150124

Epoch: 5| Step: 1
Training loss: 0.4247918128967285
Validation loss: 1.609987239683828

Epoch: 5| Step: 2
Training loss: 0.17204789817333221
Validation loss: 1.6350481471707743

Epoch: 5| Step: 3
Training loss: 0.36218997836112976
Validation loss: 1.6105145132669838

Epoch: 5| Step: 4
Training loss: 0.41410374641418457
Validation loss: 1.6305139731335383

Epoch: 5| Step: 5
Training loss: 0.2766109108924866
Validation loss: 1.6157475889370005

Epoch: 5| Step: 6
Training loss: 0.16315613687038422
Validation loss: 1.6203250615827498

Epoch: 5| Step: 7
Training loss: 0.4080274701118469
Validation loss: 1.629992667064872

Epoch: 5| Step: 8
Training loss: 0.3734320402145386
Validation loss: 1.615076704691815

Epoch: 5| Step: 9
Training loss: 0.29822659492492676
Validation loss: 1.6626985996000228

Epoch: 5| Step: 10
Training loss: 0.28467968106269836
Validation loss: 1.6695984243064799

Epoch: 389| Step: 0
Training loss: 0.28220638632774353
Validation loss: 1.63890375245002

Epoch: 5| Step: 1
Training loss: 0.33549973368644714
Validation loss: 1.6103938523159231

Epoch: 5| Step: 2
Training loss: 0.3132174015045166
Validation loss: 1.5980389066921767

Epoch: 5| Step: 3
Training loss: 0.40261101722717285
Validation loss: 1.6144038400342386

Epoch: 5| Step: 4
Training loss: 0.5221040844917297
Validation loss: 1.6030281551422612

Epoch: 5| Step: 5
Training loss: 0.2673361003398895
Validation loss: 1.61284512858237

Epoch: 5| Step: 6
Training loss: 0.4094890058040619
Validation loss: 1.571123884570214

Epoch: 5| Step: 7
Training loss: 0.3951854407787323
Validation loss: 1.592090408007304

Epoch: 5| Step: 8
Training loss: 0.16804277896881104
Validation loss: 1.5861123954096148

Epoch: 5| Step: 9
Training loss: 0.3134462833404541
Validation loss: 1.5677736279784993

Epoch: 5| Step: 10
Training loss: 0.3310436010360718
Validation loss: 1.5747254471625052

Epoch: 390| Step: 0
Training loss: 0.31982719898223877
Validation loss: 1.5970429066688783

Epoch: 5| Step: 1
Training loss: 0.354971319437027
Validation loss: 1.6118791180272256

Epoch: 5| Step: 2
Training loss: 0.4748314917087555
Validation loss: 1.596767005100045

Epoch: 5| Step: 3
Training loss: 0.19685807824134827
Validation loss: 1.5574769948118476

Epoch: 5| Step: 4
Training loss: 0.27817410230636597
Validation loss: 1.5880783821946831

Epoch: 5| Step: 5
Training loss: 0.26897507905960083
Validation loss: 1.586759219887436

Epoch: 5| Step: 6
Training loss: 0.145950585603714
Validation loss: 1.5735526764264671

Epoch: 5| Step: 7
Training loss: 0.33297353982925415
Validation loss: 1.5817406844067317

Epoch: 5| Step: 8
Training loss: 0.4580845236778259
Validation loss: 1.5727383859695927

Epoch: 5| Step: 9
Training loss: 0.4728431701660156
Validation loss: 1.5776904090758292

Epoch: 5| Step: 10
Training loss: 0.3826146721839905
Validation loss: 1.5579538473518946

Epoch: 391| Step: 0
Training loss: 0.3315102159976959
Validation loss: 1.592744582442827

Epoch: 5| Step: 1
Training loss: 0.31200113892555237
Validation loss: 1.617331409967074

Epoch: 5| Step: 2
Training loss: 0.4795524477958679
Validation loss: 1.6360607185671407

Epoch: 5| Step: 3
Training loss: 0.24398569762706757
Validation loss: 1.6682802079826273

Epoch: 5| Step: 4
Training loss: 0.2686418890953064
Validation loss: 1.658380578922969

Epoch: 5| Step: 5
Training loss: 0.37729546427726746
Validation loss: 1.6831691675288702

Epoch: 5| Step: 6
Training loss: 0.3226093649864197
Validation loss: 1.6755975625848258

Epoch: 5| Step: 7
Training loss: 0.23807719349861145
Validation loss: 1.6347088083144157

Epoch: 5| Step: 8
Training loss: 0.39329129457473755
Validation loss: 1.6575611445211595

Epoch: 5| Step: 9
Training loss: 0.3203398287296295
Validation loss: 1.6274281201824066

Epoch: 5| Step: 10
Training loss: 0.24485290050506592
Validation loss: 1.6247827288925007

Epoch: 392| Step: 0
Training loss: 0.274655282497406
Validation loss: 1.6497084286905104

Epoch: 5| Step: 1
Training loss: 0.32752251625061035
Validation loss: 1.6437096506036737

Epoch: 5| Step: 2
Training loss: 0.4593993127346039
Validation loss: 1.6184080480247416

Epoch: 5| Step: 3
Training loss: 0.38944095373153687
Validation loss: 1.6572279981387559

Epoch: 5| Step: 4
Training loss: 0.44623446464538574
Validation loss: 1.649434543425037

Epoch: 5| Step: 5
Training loss: 0.29301023483276367
Validation loss: 1.6095548265723771

Epoch: 5| Step: 6
Training loss: 0.3468875288963318
Validation loss: 1.6239712635676067

Epoch: 5| Step: 7
Training loss: 0.22506089508533478
Validation loss: 1.6200700370214318

Epoch: 5| Step: 8
Training loss: 0.21871459484100342
Validation loss: 1.5775153406204716

Epoch: 5| Step: 9
Training loss: 0.3096340596675873
Validation loss: 1.5995756195437523

Epoch: 5| Step: 10
Training loss: 0.29152747988700867
Validation loss: 1.6007606111547

Epoch: 393| Step: 0
Training loss: 0.303225576877594
Validation loss: 1.58263748691928

Epoch: 5| Step: 1
Training loss: 0.43669286370277405
Validation loss: 1.5992620888576712

Epoch: 5| Step: 2
Training loss: 0.3745315968990326
Validation loss: 1.6256102977260467

Epoch: 5| Step: 3
Training loss: 0.3754514455795288
Validation loss: 1.6229335941294187

Epoch: 5| Step: 4
Training loss: 0.1119127869606018
Validation loss: 1.6216031992307274

Epoch: 5| Step: 5
Training loss: 0.3078609108924866
Validation loss: 1.5911476612091064

Epoch: 5| Step: 6
Training loss: 0.24223867058753967
Validation loss: 1.6039674576892649

Epoch: 5| Step: 7
Training loss: 0.1876867115497589
Validation loss: 1.6164818450968752

Epoch: 5| Step: 8
Training loss: 0.3709631860256195
Validation loss: 1.5767450576187463

Epoch: 5| Step: 9
Training loss: 0.20104536414146423
Validation loss: 1.5868005906381915

Epoch: 5| Step: 10
Training loss: 0.382323682308197
Validation loss: 1.620009619702575

Epoch: 394| Step: 0
Training loss: 0.25246304273605347
Validation loss: 1.604023656537456

Epoch: 5| Step: 1
Training loss: 0.20360100269317627
Validation loss: 1.6403689140914588

Epoch: 5| Step: 2
Training loss: 0.3054942786693573
Validation loss: 1.6137859116318405

Epoch: 5| Step: 3
Training loss: 0.26914817094802856
Validation loss: 1.6175557387772428

Epoch: 5| Step: 4
Training loss: 0.35413751006126404
Validation loss: 1.615825318521069

Epoch: 5| Step: 5
Training loss: 0.39636003971099854
Validation loss: 1.6440439660062072

Epoch: 5| Step: 6
Training loss: 0.25892263650894165
Validation loss: 1.6191907851926741

Epoch: 5| Step: 7
Training loss: 0.3905642628669739
Validation loss: 1.6349756974045948

Epoch: 5| Step: 8
Training loss: 0.16298191249370575
Validation loss: 1.607411535837317

Epoch: 5| Step: 9
Training loss: 0.29318052530288696
Validation loss: 1.652194244887239

Epoch: 5| Step: 10
Training loss: 0.46503308415412903
Validation loss: 1.6203552164057249

Epoch: 395| Step: 0
Training loss: 0.2534187138080597
Validation loss: 1.6221237003162343

Epoch: 5| Step: 1
Training loss: 0.33976614475250244
Validation loss: 1.6453569281485774

Epoch: 5| Step: 2
Training loss: 0.4077891409397125
Validation loss: 1.6212226395965905

Epoch: 5| Step: 3
Training loss: 0.31986674666404724
Validation loss: 1.6107336039184241

Epoch: 5| Step: 4
Training loss: 0.2702866494655609
Validation loss: 1.6209420850200038

Epoch: 5| Step: 5
Training loss: 0.3402842879295349
Validation loss: 1.591768136588476

Epoch: 5| Step: 6
Training loss: 0.3386310636997223
Validation loss: 1.5996375058286934

Epoch: 5| Step: 7
Training loss: 0.21456566452980042
Validation loss: 1.5980075892581735

Epoch: 5| Step: 8
Training loss: 0.2685251235961914
Validation loss: 1.5901504998566003

Epoch: 5| Step: 9
Training loss: 0.2698606848716736
Validation loss: 1.6145848022994174

Epoch: 5| Step: 10
Training loss: 0.2815145254135132
Validation loss: 1.5868995625485656

Epoch: 396| Step: 0
Training loss: 0.3396129012107849
Validation loss: 1.6177740097045898

Epoch: 5| Step: 1
Training loss: 0.33589616417884827
Validation loss: 1.6152280761349587

Epoch: 5| Step: 2
Training loss: 0.3157235085964203
Validation loss: 1.6242985289583924

Epoch: 5| Step: 3
Training loss: 0.24809062480926514
Validation loss: 1.6254658699035645

Epoch: 5| Step: 4
Training loss: 0.2673751711845398
Validation loss: 1.6139356064540085

Epoch: 5| Step: 5
Training loss: 0.31402477622032166
Validation loss: 1.6082633515839935

Epoch: 5| Step: 6
Training loss: 0.2762386202812195
Validation loss: 1.622417414060203

Epoch: 5| Step: 7
Training loss: 0.35196566581726074
Validation loss: 1.5895344288118425

Epoch: 5| Step: 8
Training loss: 0.3618530035018921
Validation loss: 1.6328473552580802

Epoch: 5| Step: 9
Training loss: 0.2982967793941498
Validation loss: 1.6357356053526684

Epoch: 5| Step: 10
Training loss: 0.18897803127765656
Validation loss: 1.6293776990264974

Epoch: 397| Step: 0
Training loss: 0.4659584164619446
Validation loss: 1.6079400995726227

Epoch: 5| Step: 1
Training loss: 0.360935240983963
Validation loss: 1.6100627235186997

Epoch: 5| Step: 2
Training loss: 0.20657214522361755
Validation loss: 1.611538940860379

Epoch: 5| Step: 3
Training loss: 0.2177838534116745
Validation loss: 1.584499389894547

Epoch: 5| Step: 4
Training loss: 0.30180174112319946
Validation loss: 1.6276137675008466

Epoch: 5| Step: 5
Training loss: 0.14294543862342834
Validation loss: 1.6165966282608688

Epoch: 5| Step: 6
Training loss: 0.3387776017189026
Validation loss: 1.618546594855606

Epoch: 5| Step: 7
Training loss: 0.3384181559085846
Validation loss: 1.615036206860696

Epoch: 5| Step: 8
Training loss: 0.3754538297653198
Validation loss: 1.6417106941182127

Epoch: 5| Step: 9
Training loss: 0.25699344277381897
Validation loss: 1.6560726947681879

Epoch: 5| Step: 10
Training loss: 0.41896191239356995
Validation loss: 1.638807403144016

Epoch: 398| Step: 0
Training loss: 0.22240690886974335
Validation loss: 1.6371877090905302

Epoch: 5| Step: 1
Training loss: 0.45688900351524353
Validation loss: 1.5957894222710722

Epoch: 5| Step: 2
Training loss: 0.38217997550964355
Validation loss: 1.6120810303636777

Epoch: 5| Step: 3
Training loss: 0.3197861313819885
Validation loss: 1.589453742068301

Epoch: 5| Step: 4
Training loss: 0.2600852847099304
Validation loss: 1.5931134646938694

Epoch: 5| Step: 5
Training loss: 0.3089998960494995
Validation loss: 1.5707786365221905

Epoch: 5| Step: 6
Training loss: 0.24627819657325745
Validation loss: 1.5872294492619012

Epoch: 5| Step: 7
Training loss: 0.37534376978874207
Validation loss: 1.5940806481146044

Epoch: 5| Step: 8
Training loss: 0.34786832332611084
Validation loss: 1.6130850648367276

Epoch: 5| Step: 9
Training loss: 0.26662197709083557
Validation loss: 1.6387499891301638

Epoch: 5| Step: 10
Training loss: 0.338490754365921
Validation loss: 1.6654942509948567

Epoch: 399| Step: 0
Training loss: 0.38254305720329285
Validation loss: 1.6285770247059483

Epoch: 5| Step: 1
Training loss: 0.19501611590385437
Validation loss: 1.63020412383541

Epoch: 5| Step: 2
Training loss: 0.3487068712711334
Validation loss: 1.6552768804693734

Epoch: 5| Step: 3
Training loss: 0.32838037610054016
Validation loss: 1.6446305654382194

Epoch: 5| Step: 4
Training loss: 0.456550270318985
Validation loss: 1.6400477117107761

Epoch: 5| Step: 5
Training loss: 0.333674818277359
Validation loss: 1.6526012330926874

Epoch: 5| Step: 6
Training loss: 0.1791195124387741
Validation loss: 1.6321154050929572

Epoch: 5| Step: 7
Training loss: 0.2339107096195221
Validation loss: 1.6265795442365831

Epoch: 5| Step: 8
Training loss: 0.20852503180503845
Validation loss: 1.60290095754849

Epoch: 5| Step: 9
Training loss: 0.2584560215473175
Validation loss: 1.6279976214132001

Epoch: 5| Step: 10
Training loss: 0.3113756477832794
Validation loss: 1.6208817471740067

Epoch: 400| Step: 0
Training loss: 0.1967650204896927
Validation loss: 1.5996029658984112

Epoch: 5| Step: 1
Training loss: 0.4235711693763733
Validation loss: 1.622381882000995

Epoch: 5| Step: 2
Training loss: 0.22885684669017792
Validation loss: 1.6004064659918509

Epoch: 5| Step: 3
Training loss: 0.24561724066734314
Validation loss: 1.5791289344910653

Epoch: 5| Step: 4
Training loss: 0.5027211308479309
Validation loss: 1.5965262215624574

Epoch: 5| Step: 5
Training loss: 0.2345902919769287
Validation loss: 1.588309504652536

Epoch: 5| Step: 6
Training loss: 0.3640058934688568
Validation loss: 1.5883077190768333

Epoch: 5| Step: 7
Training loss: 0.30639663338661194
Validation loss: 1.5710500542835524

Epoch: 5| Step: 8
Training loss: 0.24637088179588318
Validation loss: 1.6194149101934125

Epoch: 5| Step: 9
Training loss: 0.2984357476234436
Validation loss: 1.600547618763421

Epoch: 5| Step: 10
Training loss: 0.13424928486347198
Validation loss: 1.6048364985373713

Epoch: 401| Step: 0
Training loss: 0.2531031668186188
Validation loss: 1.6110630958311019

Epoch: 5| Step: 1
Training loss: 0.3322482109069824
Validation loss: 1.6357804921365553

Epoch: 5| Step: 2
Training loss: 0.3143937885761261
Validation loss: 1.624365472024487

Epoch: 5| Step: 3
Training loss: 0.45491284132003784
Validation loss: 1.6448105048107844

Epoch: 5| Step: 4
Training loss: 0.23898176848888397
Validation loss: 1.6345360522629113

Epoch: 5| Step: 5
Training loss: 0.2727503180503845
Validation loss: 1.625755149831054

Epoch: 5| Step: 6
Training loss: 0.21765556931495667
Validation loss: 1.6409392741418654

Epoch: 5| Step: 7
Training loss: 0.35068899393081665
Validation loss: 1.6134692802224109

Epoch: 5| Step: 8
Training loss: 0.21050333976745605
Validation loss: 1.6211204426262968

Epoch: 5| Step: 9
Training loss: 0.2102929800748825
Validation loss: 1.6272034683535177

Epoch: 5| Step: 10
Training loss: 0.22206401824951172
Validation loss: 1.6154985222765195

Epoch: 402| Step: 0
Training loss: 0.3436835706233978
Validation loss: 1.6417061987743582

Epoch: 5| Step: 1
Training loss: 0.40988993644714355
Validation loss: 1.6453833682562715

Epoch: 5| Step: 2
Training loss: 0.23243403434753418
Validation loss: 1.623332226789126

Epoch: 5| Step: 3
Training loss: 0.40611696243286133
Validation loss: 1.5880908658427577

Epoch: 5| Step: 4
Training loss: 0.334697961807251
Validation loss: 1.5708977855661863

Epoch: 5| Step: 5
Training loss: 0.2558409571647644
Validation loss: 1.5861847400665283

Epoch: 5| Step: 6
Training loss: 0.2254742681980133
Validation loss: 1.6036591581119004

Epoch: 5| Step: 7
Training loss: 0.2596849501132965
Validation loss: 1.5885510521550332

Epoch: 5| Step: 8
Training loss: 0.3108237087726593
Validation loss: 1.6042557147241407

Epoch: 5| Step: 9
Training loss: 0.28987255692481995
Validation loss: 1.592109671203039

Epoch: 5| Step: 10
Training loss: 0.14013110101222992
Validation loss: 1.5753842579421176

Epoch: 403| Step: 0
Training loss: 0.42090290784835815
Validation loss: 1.5789021420222458

Epoch: 5| Step: 1
Training loss: 0.27333152294158936
Validation loss: 1.5953047198633994

Epoch: 5| Step: 2
Training loss: 0.25785011053085327
Validation loss: 1.5798219378276537

Epoch: 5| Step: 3
Training loss: 0.23403628170490265
Validation loss: 1.584073483303029

Epoch: 5| Step: 4
Training loss: 0.2297285497188568
Validation loss: 1.5922889068562498

Epoch: 5| Step: 5
Training loss: 0.26581811904907227
Validation loss: 1.6095996672107327

Epoch: 5| Step: 6
Training loss: 0.30504941940307617
Validation loss: 1.5960165890314246

Epoch: 5| Step: 7
Training loss: 0.14182782173156738
Validation loss: 1.586325950520013

Epoch: 5| Step: 8
Training loss: 0.32183316349983215
Validation loss: 1.5882176417176441

Epoch: 5| Step: 9
Training loss: 0.299469918012619
Validation loss: 1.5928869465345978

Epoch: 5| Step: 10
Training loss: 0.3388000428676605
Validation loss: 1.5840897624210646

Epoch: 404| Step: 0
Training loss: 0.3520907759666443
Validation loss: 1.6003825619656553

Epoch: 5| Step: 1
Training loss: 0.1806371659040451
Validation loss: 1.6046536378963019

Epoch: 5| Step: 2
Training loss: 0.3293136954307556
Validation loss: 1.6051362765732633

Epoch: 5| Step: 3
Training loss: 0.23570504784584045
Validation loss: 1.6097441386151057

Epoch: 5| Step: 4
Training loss: 0.16910472512245178
Validation loss: 1.5624316007860246

Epoch: 5| Step: 5
Training loss: 0.2784166932106018
Validation loss: 1.6071057858005646

Epoch: 5| Step: 6
Training loss: 0.2490556687116623
Validation loss: 1.5959219637737478

Epoch: 5| Step: 7
Training loss: 0.38921087980270386
Validation loss: 1.5906176451713807

Epoch: 5| Step: 8
Training loss: 0.12050671875476837
Validation loss: 1.5953212886728265

Epoch: 5| Step: 9
Training loss: 0.2460024356842041
Validation loss: 1.5918651819229126

Epoch: 5| Step: 10
Training loss: 0.31489935517311096
Validation loss: 1.583230536471131

Epoch: 405| Step: 0
Training loss: 0.23984909057617188
Validation loss: 1.586372539561282

Epoch: 5| Step: 1
Training loss: 0.2102772742509842
Validation loss: 1.5752949278841737

Epoch: 5| Step: 2
Training loss: 0.14106984436511993
Validation loss: 1.6428637735305294

Epoch: 5| Step: 3
Training loss: 0.39555394649505615
Validation loss: 1.5872673411523142

Epoch: 5| Step: 4
Training loss: 0.28115367889404297
Validation loss: 1.5869575918361705

Epoch: 5| Step: 5
Training loss: 0.3072117269039154
Validation loss: 1.5509524935035295

Epoch: 5| Step: 6
Training loss: 0.23679180443286896
Validation loss: 1.5552328325087024

Epoch: 5| Step: 7
Training loss: 0.20144414901733398
Validation loss: 1.5567270017439319

Epoch: 5| Step: 8
Training loss: 0.35901880264282227
Validation loss: 1.5595802818575213

Epoch: 5| Step: 9
Training loss: 0.35723695158958435
Validation loss: 1.5453225233221566

Epoch: 5| Step: 10
Training loss: 0.3921618163585663
Validation loss: 1.5611281510322326

Epoch: 406| Step: 0
Training loss: 0.28393420577049255
Validation loss: 1.582093338812551

Epoch: 5| Step: 1
Training loss: 0.2874118685722351
Validation loss: 1.5717771899315618

Epoch: 5| Step: 2
Training loss: 0.22343778610229492
Validation loss: 1.5673392344546575

Epoch: 5| Step: 3
Training loss: 0.29764503240585327
Validation loss: 1.5827100725584133

Epoch: 5| Step: 4
Training loss: 0.19105705618858337
Validation loss: 1.5982588106586086

Epoch: 5| Step: 5
Training loss: 0.29689693450927734
Validation loss: 1.6031902682396673

Epoch: 5| Step: 6
Training loss: 0.3321685791015625
Validation loss: 1.6272733301244757

Epoch: 5| Step: 7
Training loss: 0.2807333171367645
Validation loss: 1.6107457504477551

Epoch: 5| Step: 8
Training loss: 0.3328813910484314
Validation loss: 1.6377099560153099

Epoch: 5| Step: 9
Training loss: 0.1928926408290863
Validation loss: 1.622578404283011

Epoch: 5| Step: 10
Training loss: 0.3206176161766052
Validation loss: 1.6029863319089335

Epoch: 407| Step: 0
Training loss: 0.16630545258522034
Validation loss: 1.5905127832966466

Epoch: 5| Step: 1
Training loss: 0.3984028398990631
Validation loss: 1.5925069227013537

Epoch: 5| Step: 2
Training loss: 0.21549899876117706
Validation loss: 1.5667069419737785

Epoch: 5| Step: 3
Training loss: 0.4236156940460205
Validation loss: 1.5609879250167518

Epoch: 5| Step: 4
Training loss: 0.29311174154281616
Validation loss: 1.5705735939805225

Epoch: 5| Step: 5
Training loss: 0.25036507844924927
Validation loss: 1.5635468293261785

Epoch: 5| Step: 6
Training loss: 0.23955702781677246
Validation loss: 1.5761605014083206

Epoch: 5| Step: 7
Training loss: 0.3311126232147217
Validation loss: 1.57899558800523

Epoch: 5| Step: 8
Training loss: 0.12185732275247574
Validation loss: 1.5909202432119718

Epoch: 5| Step: 9
Training loss: 0.3290424346923828
Validation loss: 1.61787449929022

Epoch: 5| Step: 10
Training loss: 0.11632079631090164
Validation loss: 1.6366581814263457

Epoch: 408| Step: 0
Training loss: 0.19975925981998444
Validation loss: 1.616440132100095

Epoch: 5| Step: 1
Training loss: 0.34996089339256287
Validation loss: 1.6290857561172978

Epoch: 5| Step: 2
Training loss: 0.5964391827583313
Validation loss: 1.6445079311247794

Epoch: 5| Step: 3
Training loss: 0.2358279973268509
Validation loss: 1.6241688805241739

Epoch: 5| Step: 4
Training loss: 0.26534169912338257
Validation loss: 1.62048218839912

Epoch: 5| Step: 5
Training loss: 0.08115377277135849
Validation loss: 1.5974851590330883

Epoch: 5| Step: 6
Training loss: 0.26579490303993225
Validation loss: 1.5841131030872304

Epoch: 5| Step: 7
Training loss: 0.2891490161418915
Validation loss: 1.5769144617101198

Epoch: 5| Step: 8
Training loss: 0.2339719980955124
Validation loss: 1.5785007425533828

Epoch: 5| Step: 9
Training loss: 0.32332494854927063
Validation loss: 1.564622941837516

Epoch: 5| Step: 10
Training loss: 0.30616122484207153
Validation loss: 1.591181617911144

Epoch: 409| Step: 0
Training loss: 0.3655700087547302
Validation loss: 1.5923873737294187

Epoch: 5| Step: 1
Training loss: 0.4031168818473816
Validation loss: 1.6028063348544541

Epoch: 5| Step: 2
Training loss: 0.16272872686386108
Validation loss: 1.6087359036168745

Epoch: 5| Step: 3
Training loss: 0.36937257647514343
Validation loss: 1.6189713913907287

Epoch: 5| Step: 4
Training loss: 0.2523490786552429
Validation loss: 1.6227848234997

Epoch: 5| Step: 5
Training loss: 0.18605487048625946
Validation loss: 1.6290990716667586

Epoch: 5| Step: 6
Training loss: 0.2649758756160736
Validation loss: 1.6116754060150476

Epoch: 5| Step: 7
Training loss: 0.20406243205070496
Validation loss: 1.6066029789627239

Epoch: 5| Step: 8
Training loss: 0.12677590548992157
Validation loss: 1.6294945324620893

Epoch: 5| Step: 9
Training loss: 0.3060417175292969
Validation loss: 1.618933541800386

Epoch: 5| Step: 10
Training loss: 0.29075172543525696
Validation loss: 1.592480782539614

Epoch: 410| Step: 0
Training loss: 0.27886292338371277
Validation loss: 1.598371919124357

Epoch: 5| Step: 1
Training loss: 0.2628123462200165
Validation loss: 1.6081255315452494

Epoch: 5| Step: 2
Training loss: 0.1739894449710846
Validation loss: 1.6001794222862489

Epoch: 5| Step: 3
Training loss: 0.21238327026367188
Validation loss: 1.5965498044926634

Epoch: 5| Step: 4
Training loss: 0.28429776430130005
Validation loss: 1.617943759887449

Epoch: 5| Step: 5
Training loss: 0.24568302929401398
Validation loss: 1.6158565193094232

Epoch: 5| Step: 6
Training loss: 0.26947489380836487
Validation loss: 1.6132894844137213

Epoch: 5| Step: 7
Training loss: 0.27375006675720215
Validation loss: 1.6174179764204129

Epoch: 5| Step: 8
Training loss: 0.30150893330574036
Validation loss: 1.6273274883147208

Epoch: 5| Step: 9
Training loss: 0.2653277814388275
Validation loss: 1.619960500988909

Epoch: 5| Step: 10
Training loss: 0.31339138746261597
Validation loss: 1.6202404499053955

Epoch: 411| Step: 0
Training loss: 0.1890869289636612
Validation loss: 1.607177968948118

Epoch: 5| Step: 1
Training loss: 0.30635055899620056
Validation loss: 1.5897318791317683

Epoch: 5| Step: 2
Training loss: 0.18521547317504883
Validation loss: 1.6190379934926187

Epoch: 5| Step: 3
Training loss: 0.1403357833623886
Validation loss: 1.6257794210987706

Epoch: 5| Step: 4
Training loss: 0.28999629616737366
Validation loss: 1.6244468958147111

Epoch: 5| Step: 5
Training loss: 0.30190151929855347
Validation loss: 1.6084030059076124

Epoch: 5| Step: 6
Training loss: 0.36196205019950867
Validation loss: 1.6071654160817463

Epoch: 5| Step: 7
Training loss: 0.2997927665710449
Validation loss: 1.6263414185534242

Epoch: 5| Step: 8
Training loss: 0.3365147113800049
Validation loss: 1.6074521772323116

Epoch: 5| Step: 9
Training loss: 0.22516946494579315
Validation loss: 1.59257363119433

Epoch: 5| Step: 10
Training loss: 0.2116716057062149
Validation loss: 1.6130727798708024

Epoch: 412| Step: 0
Training loss: 0.32852703332901
Validation loss: 1.5855040486140917

Epoch: 5| Step: 1
Training loss: 0.2839619219303131
Validation loss: 1.5771583677620016

Epoch: 5| Step: 2
Training loss: 0.3110296130180359
Validation loss: 1.585943438673532

Epoch: 5| Step: 3
Training loss: 0.24832744896411896
Validation loss: 1.585129322544221

Epoch: 5| Step: 4
Training loss: 0.18482467532157898
Validation loss: 1.5736953225187076

Epoch: 5| Step: 5
Training loss: 0.3291526436805725
Validation loss: 1.5844101623822284

Epoch: 5| Step: 6
Training loss: 0.1767697036266327
Validation loss: 1.5791331606526529

Epoch: 5| Step: 7
Training loss: 0.21862883865833282
Validation loss: 1.5891341586266794

Epoch: 5| Step: 8
Training loss: 0.1812591254711151
Validation loss: 1.5879636733762679

Epoch: 5| Step: 9
Training loss: 0.29580309987068176
Validation loss: 1.6394004898686563

Epoch: 5| Step: 10
Training loss: 0.2622891962528229
Validation loss: 1.5970763416700466

Epoch: 413| Step: 0
Training loss: 0.3235326409339905
Validation loss: 1.638303892586821

Epoch: 5| Step: 1
Training loss: 0.1536891758441925
Validation loss: 1.6206164244682557

Epoch: 5| Step: 2
Training loss: 0.34515926241874695
Validation loss: 1.5828564525932394

Epoch: 5| Step: 3
Training loss: 0.23188666999340057
Validation loss: 1.5699883378962034

Epoch: 5| Step: 4
Training loss: 0.4480891227722168
Validation loss: 1.5820586322456278

Epoch: 5| Step: 5
Training loss: 0.323255717754364
Validation loss: 1.5869396848063315

Epoch: 5| Step: 6
Training loss: 0.2570984959602356
Validation loss: 1.585790890519337

Epoch: 5| Step: 7
Training loss: 0.2074541598558426
Validation loss: 1.5939627385908557

Epoch: 5| Step: 8
Training loss: 0.21150043606758118
Validation loss: 1.6026489491103797

Epoch: 5| Step: 9
Training loss: 0.3359031081199646
Validation loss: 1.5946085529942666

Epoch: 5| Step: 10
Training loss: 0.2722719609737396
Validation loss: 1.6074210007985432

Epoch: 414| Step: 0
Training loss: 0.3699660897254944
Validation loss: 1.5851847241001744

Epoch: 5| Step: 1
Training loss: 0.3270328938961029
Validation loss: 1.6124678427173245

Epoch: 5| Step: 2
Training loss: 0.24480906128883362
Validation loss: 1.602115188875506

Epoch: 5| Step: 3
Training loss: 0.20998573303222656
Validation loss: 1.6258772611618042

Epoch: 5| Step: 4
Training loss: 0.17685379087924957
Validation loss: 1.6370950398906585

Epoch: 5| Step: 5
Training loss: 0.23083452880382538
Validation loss: 1.616613330379609

Epoch: 5| Step: 6
Training loss: 0.23153415322303772
Validation loss: 1.6261615701901015

Epoch: 5| Step: 7
Training loss: 0.1827610433101654
Validation loss: 1.6307225752902288

Epoch: 5| Step: 8
Training loss: 0.28161874413490295
Validation loss: 1.6336921850840251

Epoch: 5| Step: 9
Training loss: 0.18678537011146545
Validation loss: 1.606279888460713

Epoch: 5| Step: 10
Training loss: 0.45592209696769714
Validation loss: 1.5940065640275196

Epoch: 415| Step: 0
Training loss: 0.25807538628578186
Validation loss: 1.612838222134498

Epoch: 5| Step: 1
Training loss: 0.19031356275081635
Validation loss: 1.5763463474089099

Epoch: 5| Step: 2
Training loss: 0.31520915031433105
Validation loss: 1.56777367156039

Epoch: 5| Step: 3
Training loss: 0.23695091903209686
Validation loss: 1.589478119727104

Epoch: 5| Step: 4
Training loss: 0.3137659728527069
Validation loss: 1.5765299912421935

Epoch: 5| Step: 5
Training loss: 0.3408627510070801
Validation loss: 1.6100972865217476

Epoch: 5| Step: 6
Training loss: 0.31337103247642517
Validation loss: 1.6126185706866685

Epoch: 5| Step: 7
Training loss: 0.29172325134277344
Validation loss: 1.6013217331260763

Epoch: 5| Step: 8
Training loss: 0.17499220371246338
Validation loss: 1.5842647347398984

Epoch: 5| Step: 9
Training loss: 0.20962171256542206
Validation loss: 1.5956189952870852

Epoch: 5| Step: 10
Training loss: 0.23372109234333038
Validation loss: 1.5778692460829211

Epoch: 416| Step: 0
Training loss: 0.21915045380592346
Validation loss: 1.6018672912351546

Epoch: 5| Step: 1
Training loss: 0.24458906054496765
Validation loss: 1.5807767247640958

Epoch: 5| Step: 2
Training loss: 0.2949635982513428
Validation loss: 1.582942598609514

Epoch: 5| Step: 3
Training loss: 0.3271825909614563
Validation loss: 1.601389786248566

Epoch: 5| Step: 4
Training loss: 0.19214577972888947
Validation loss: 1.6276282418158747

Epoch: 5| Step: 5
Training loss: 0.19664183259010315
Validation loss: 1.6433229497683945

Epoch: 5| Step: 6
Training loss: 0.28332895040512085
Validation loss: 1.6531538899226854

Epoch: 5| Step: 7
Training loss: 0.16174140572547913
Validation loss: 1.6104070601924774

Epoch: 5| Step: 8
Training loss: 0.22262373566627502
Validation loss: 1.625432764330218

Epoch: 5| Step: 9
Training loss: 0.22757244110107422
Validation loss: 1.5805221232034827

Epoch: 5| Step: 10
Training loss: 0.42790845036506653
Validation loss: 1.5912294387817383

Epoch: 417| Step: 0
Training loss: 0.22072911262512207
Validation loss: 1.5420506026155205

Epoch: 5| Step: 1
Training loss: 0.45520657300949097
Validation loss: 1.5867533504322011

Epoch: 5| Step: 2
Training loss: 0.22300784289836884
Validation loss: 1.5931586270691247

Epoch: 5| Step: 3
Training loss: 0.2313164919614792
Validation loss: 1.597817664505333

Epoch: 5| Step: 4
Training loss: 0.3216274678707123
Validation loss: 1.5868367187438472

Epoch: 5| Step: 5
Training loss: 0.2415371835231781
Validation loss: 1.5914382908933906

Epoch: 5| Step: 6
Training loss: 0.2056102305650711
Validation loss: 1.5984014746963338

Epoch: 5| Step: 7
Training loss: 0.12077101320028305
Validation loss: 1.6055693395676152

Epoch: 5| Step: 8
Training loss: 0.160331130027771
Validation loss: 1.6004662641914942

Epoch: 5| Step: 9
Training loss: 0.22576551139354706
Validation loss: 1.6069273307759275

Epoch: 5| Step: 10
Training loss: 0.26326820254325867
Validation loss: 1.5948274648317726

Epoch: 418| Step: 0
Training loss: 0.14360912144184113
Validation loss: 1.5997846895648586

Epoch: 5| Step: 1
Training loss: 0.2474633753299713
Validation loss: 1.5841412890341975

Epoch: 5| Step: 2
Training loss: 0.34623000025749207
Validation loss: 1.584403790453429

Epoch: 5| Step: 3
Training loss: 0.2249746024608612
Validation loss: 1.5870848176299885

Epoch: 5| Step: 4
Training loss: 0.22564418613910675
Validation loss: 1.587332885752442

Epoch: 5| Step: 5
Training loss: 0.32046788930892944
Validation loss: 1.5832416601078485

Epoch: 5| Step: 6
Training loss: 0.28753983974456787
Validation loss: 1.566657502164123

Epoch: 5| Step: 7
Training loss: 0.268575519323349
Validation loss: 1.5915694570028653

Epoch: 5| Step: 8
Training loss: 0.19556273519992828
Validation loss: 1.5722453914662844

Epoch: 5| Step: 9
Training loss: 0.3349534571170807
Validation loss: 1.5790866062205324

Epoch: 5| Step: 10
Training loss: 0.15511077642440796
Validation loss: 1.603369560292972

Epoch: 419| Step: 0
Training loss: 0.35080379247665405
Validation loss: 1.5879861500955397

Epoch: 5| Step: 1
Training loss: 0.2509567141532898
Validation loss: 1.587792875946209

Epoch: 5| Step: 2
Training loss: 0.28852084279060364
Validation loss: 1.5623514806070635

Epoch: 5| Step: 3
Training loss: 0.2744368016719818
Validation loss: 1.566092352713308

Epoch: 5| Step: 4
Training loss: 0.3380478620529175
Validation loss: 1.5420076129257039

Epoch: 5| Step: 5
Training loss: 0.09499593824148178
Validation loss: 1.566172040918822

Epoch: 5| Step: 6
Training loss: 0.2394748032093048
Validation loss: 1.561471995487008

Epoch: 5| Step: 7
Training loss: 0.1715484857559204
Validation loss: 1.5850606041569864

Epoch: 5| Step: 8
Training loss: 0.2721834182739258
Validation loss: 1.5966902919994888

Epoch: 5| Step: 9
Training loss: 0.22044667601585388
Validation loss: 1.6241690913836162

Epoch: 5| Step: 10
Training loss: 0.2800368070602417
Validation loss: 1.6235123629211097

Epoch: 420| Step: 0
Training loss: 0.2129785269498825
Validation loss: 1.6116412224308136

Epoch: 5| Step: 1
Training loss: 0.4328223168849945
Validation loss: 1.5995056494589774

Epoch: 5| Step: 2
Training loss: 0.3049881160259247
Validation loss: 1.5658365244506507

Epoch: 5| Step: 3
Training loss: 0.2496744692325592
Validation loss: 1.6099539085101056

Epoch: 5| Step: 4
Training loss: 0.14518669247627258
Validation loss: 1.6018142783513634

Epoch: 5| Step: 5
Training loss: 0.31531888246536255
Validation loss: 1.5843746867231143

Epoch: 5| Step: 6
Training loss: 0.20270344614982605
Validation loss: 1.5932967124446746

Epoch: 5| Step: 7
Training loss: 0.2416149079799652
Validation loss: 1.596785553040043

Epoch: 5| Step: 8
Training loss: 0.1585061103105545
Validation loss: 1.6272602555572346

Epoch: 5| Step: 9
Training loss: 0.23887737095355988
Validation loss: 1.6296993109487719

Epoch: 5| Step: 10
Training loss: 0.18511024117469788
Validation loss: 1.6561176071884811

Epoch: 421| Step: 0
Training loss: 0.24925628304481506
Validation loss: 1.632669823144072

Epoch: 5| Step: 1
Training loss: 0.37450844049453735
Validation loss: 1.64267058526316

Epoch: 5| Step: 2
Training loss: 0.2899022698402405
Validation loss: 1.627087193150674

Epoch: 5| Step: 3
Training loss: 0.2732018530368805
Validation loss: 1.623017362369004

Epoch: 5| Step: 4
Training loss: 0.1695828139781952
Validation loss: 1.6209031099914222

Epoch: 5| Step: 5
Training loss: 0.2233787477016449
Validation loss: 1.629582748618177

Epoch: 5| Step: 6
Training loss: 0.17377902567386627
Validation loss: 1.6127125396523425

Epoch: 5| Step: 7
Training loss: 0.2592722475528717
Validation loss: 1.6282560799711494

Epoch: 5| Step: 8
Training loss: 0.23469586670398712
Validation loss: 1.635618636685033

Epoch: 5| Step: 9
Training loss: 0.21320900321006775
Validation loss: 1.6209306640009726

Epoch: 5| Step: 10
Training loss: 0.25047698616981506
Validation loss: 1.5905631255078059

Epoch: 422| Step: 0
Training loss: 0.18422695994377136
Validation loss: 1.6036814335853822

Epoch: 5| Step: 1
Training loss: 0.31241753697395325
Validation loss: 1.6087004459032448

Epoch: 5| Step: 2
Training loss: 0.18301436305046082
Validation loss: 1.6274689089867376

Epoch: 5| Step: 3
Training loss: 0.2149469405412674
Validation loss: 1.5976425511862642

Epoch: 5| Step: 4
Training loss: 0.23747138679027557
Validation loss: 1.5958782101190219

Epoch: 5| Step: 5
Training loss: 0.2410106211900711
Validation loss: 1.644579178543501

Epoch: 5| Step: 6
Training loss: 0.2942330241203308
Validation loss: 1.6036355200634207

Epoch: 5| Step: 7
Training loss: 0.17129041254520416
Validation loss: 1.6022322767524309

Epoch: 5| Step: 8
Training loss: 0.3201376497745514
Validation loss: 1.6448868115743

Epoch: 5| Step: 9
Training loss: 0.23704314231872559
Validation loss: 1.6361624579275809

Epoch: 5| Step: 10
Training loss: 0.22041568160057068
Validation loss: 1.629420075365292

Epoch: 423| Step: 0
Training loss: 0.17639365792274475
Validation loss: 1.6360763311386108

Epoch: 5| Step: 1
Training loss: 0.22179456055164337
Validation loss: 1.6055469794939923

Epoch: 5| Step: 2
Training loss: 0.18941864371299744
Validation loss: 1.595654196636651

Epoch: 5| Step: 3
Training loss: 0.2009676694869995
Validation loss: 1.589002937398931

Epoch: 5| Step: 4
Training loss: 0.21872811019420624
Validation loss: 1.598777223658818

Epoch: 5| Step: 5
Training loss: 0.22357602417469025
Validation loss: 1.596418317928109

Epoch: 5| Step: 6
Training loss: 0.2817049026489258
Validation loss: 1.5830808942035963

Epoch: 5| Step: 7
Training loss: 0.2894822955131531
Validation loss: 1.5755452532922067

Epoch: 5| Step: 8
Training loss: 0.18488165736198425
Validation loss: 1.5674407071964715

Epoch: 5| Step: 9
Training loss: 0.2797365188598633
Validation loss: 1.5924857431842434

Epoch: 5| Step: 10
Training loss: 0.20993149280548096
Validation loss: 1.572958989809918

Epoch: 424| Step: 0
Training loss: 0.21179088950157166
Validation loss: 1.5593996752974808

Epoch: 5| Step: 1
Training loss: 0.1341256946325302
Validation loss: 1.5612103926238192

Epoch: 5| Step: 2
Training loss: 0.3554820120334625
Validation loss: 1.5733320020860242

Epoch: 5| Step: 3
Training loss: 0.263827383518219
Validation loss: 1.5804806845162505

Epoch: 5| Step: 4
Training loss: 0.26817241311073303
Validation loss: 1.570189740068169

Epoch: 5| Step: 5
Training loss: 0.17972178757190704
Validation loss: 1.5741815913108088

Epoch: 5| Step: 6
Training loss: 0.3083597421646118
Validation loss: 1.5565319503507307

Epoch: 5| Step: 7
Training loss: 0.2105046808719635
Validation loss: 1.5546496170823292

Epoch: 5| Step: 8
Training loss: 0.14066630601882935
Validation loss: 1.5723077629202156

Epoch: 5| Step: 9
Training loss: 0.2487465888261795
Validation loss: 1.5518181195823095

Epoch: 5| Step: 10
Training loss: 0.1475319266319275
Validation loss: 1.5624008659393556

Epoch: 425| Step: 0
Training loss: 0.2564226984977722
Validation loss: 1.5683078509505077

Epoch: 5| Step: 1
Training loss: 0.2890373170375824
Validation loss: 1.6014226098214426

Epoch: 5| Step: 2
Training loss: 0.22015324234962463
Validation loss: 1.5468052574383315

Epoch: 5| Step: 3
Training loss: 0.13835826516151428
Validation loss: 1.551951301995144

Epoch: 5| Step: 4
Training loss: 0.1959797590970993
Validation loss: 1.550962386592742

Epoch: 5| Step: 5
Training loss: 0.14225856959819794
Validation loss: 1.5584777888431345

Epoch: 5| Step: 6
Training loss: 0.32243427634239197
Validation loss: 1.5673857081320979

Epoch: 5| Step: 7
Training loss: 0.4115033745765686
Validation loss: 1.5945691485558786

Epoch: 5| Step: 8
Training loss: 0.2860275208950043
Validation loss: 1.5665358087067962

Epoch: 5| Step: 9
Training loss: 0.19690103828907013
Validation loss: 1.5772137821361583

Epoch: 5| Step: 10
Training loss: 0.13497519493103027
Validation loss: 1.5858013783731768

Epoch: 426| Step: 0
Training loss: 0.3205875754356384
Validation loss: 1.602830139539575

Epoch: 5| Step: 1
Training loss: 0.20526853203773499
Validation loss: 1.600681298522539

Epoch: 5| Step: 2
Training loss: 0.31014806032180786
Validation loss: 1.6208929015744118

Epoch: 5| Step: 3
Training loss: 0.26506346464157104
Validation loss: 1.6206607177693357

Epoch: 5| Step: 4
Training loss: 0.24571053683757782
Validation loss: 1.625452544099541

Epoch: 5| Step: 5
Training loss: 0.27075284719467163
Validation loss: 1.6336968227099347

Epoch: 5| Step: 6
Training loss: 0.2683175206184387
Validation loss: 1.6425726541908838

Epoch: 5| Step: 7
Training loss: 0.13902539014816284
Validation loss: 1.597124070249578

Epoch: 5| Step: 8
Training loss: 0.19174151122570038
Validation loss: 1.6192815149984052

Epoch: 5| Step: 9
Training loss: 0.22019901871681213
Validation loss: 1.5893493647216468

Epoch: 5| Step: 10
Training loss: 0.09924763441085815
Validation loss: 1.5679798831221878

Epoch: 427| Step: 0
Training loss: 0.19323644042015076
Validation loss: 1.569355296832259

Epoch: 5| Step: 1
Training loss: 0.3150237202644348
Validation loss: 1.5779923854335662

Epoch: 5| Step: 2
Training loss: 0.26487818360328674
Validation loss: 1.589631192145809

Epoch: 5| Step: 3
Training loss: 0.22152671217918396
Validation loss: 1.561042494671319

Epoch: 5| Step: 4
Training loss: 0.4064600467681885
Validation loss: 1.5861619339194348

Epoch: 5| Step: 5
Training loss: 0.2367388755083084
Validation loss: 1.5501879492113668

Epoch: 5| Step: 6
Training loss: 0.242970272898674
Validation loss: 1.5791035300941878

Epoch: 5| Step: 7
Training loss: 0.1728803962469101
Validation loss: 1.5241508547977736

Epoch: 5| Step: 8
Training loss: 0.2402847707271576
Validation loss: 1.5644160637291529

Epoch: 5| Step: 9
Training loss: 0.3164845407009125
Validation loss: 1.5519869276272353

Epoch: 5| Step: 10
Training loss: 0.16644348204135895
Validation loss: 1.5565088211849172

Epoch: 428| Step: 0
Training loss: 0.14040687680244446
Validation loss: 1.569350633569943

Epoch: 5| Step: 1
Training loss: 0.2839065194129944
Validation loss: 1.5856184779956777

Epoch: 5| Step: 2
Training loss: 0.21006961166858673
Validation loss: 1.5972528239732147

Epoch: 5| Step: 3
Training loss: 0.17363224923610687
Validation loss: 1.5968441335103845

Epoch: 5| Step: 4
Training loss: 0.1330561637878418
Validation loss: 1.5956368446350098

Epoch: 5| Step: 5
Training loss: 0.20376889407634735
Validation loss: 1.5887577815722393

Epoch: 5| Step: 6
Training loss: 0.26103124022483826
Validation loss: 1.6048597571670369

Epoch: 5| Step: 7
Training loss: 0.2600606083869934
Validation loss: 1.6023396791950348

Epoch: 5| Step: 8
Training loss: 0.3147664964199066
Validation loss: 1.6050626244596256

Epoch: 5| Step: 9
Training loss: 0.2412552833557129
Validation loss: 1.5758426291968233

Epoch: 5| Step: 10
Training loss: 0.21920877695083618
Validation loss: 1.5816502032741424

Epoch: 429| Step: 0
Training loss: 0.22639897465705872
Validation loss: 1.5877879768289545

Epoch: 5| Step: 1
Training loss: 0.27434608340263367
Validation loss: 1.5974473004700036

Epoch: 5| Step: 2
Training loss: 0.22863900661468506
Validation loss: 1.6099422606088782

Epoch: 5| Step: 3
Training loss: 0.20751336216926575
Validation loss: 1.6324458750345374

Epoch: 5| Step: 4
Training loss: 0.2007574588060379
Validation loss: 1.61842010354483

Epoch: 5| Step: 5
Training loss: 0.12200965732336044
Validation loss: 1.595701056142007

Epoch: 5| Step: 6
Training loss: 0.18606609106063843
Validation loss: 1.5807554439831806

Epoch: 5| Step: 7
Training loss: 0.18885628879070282
Validation loss: 1.614995530856553

Epoch: 5| Step: 8
Training loss: 0.274458646774292
Validation loss: 1.5891278341252317

Epoch: 5| Step: 9
Training loss: 0.33502668142318726
Validation loss: 1.5865538043360556

Epoch: 5| Step: 10
Training loss: 0.18429754674434662
Validation loss: 1.6080799102783203

Epoch: 430| Step: 0
Training loss: 0.1816273182630539
Validation loss: 1.6018931455509637

Epoch: 5| Step: 1
Training loss: 0.3008964955806732
Validation loss: 1.5977422652706024

Epoch: 5| Step: 2
Training loss: 0.1514950692653656
Validation loss: 1.6240782583913496

Epoch: 5| Step: 3
Training loss: 0.2089071273803711
Validation loss: 1.5811675838244859

Epoch: 5| Step: 4
Training loss: 0.28655925393104553
Validation loss: 1.589100815916574

Epoch: 5| Step: 5
Training loss: 0.33945876359939575
Validation loss: 1.5639868449139338

Epoch: 5| Step: 6
Training loss: 0.18020595610141754
Validation loss: 1.5631813240307633

Epoch: 5| Step: 7
Training loss: 0.19431571662425995
Validation loss: 1.5599474368556854

Epoch: 5| Step: 8
Training loss: 0.24647419154644012
Validation loss: 1.5559810028281262

Epoch: 5| Step: 9
Training loss: 0.1639527678489685
Validation loss: 1.5444053770393453

Epoch: 5| Step: 10
Training loss: 0.1467781960964203
Validation loss: 1.5457107379872312

Epoch: 431| Step: 0
Training loss: 0.1344211995601654
Validation loss: 1.565722874415818

Epoch: 5| Step: 1
Training loss: 0.2154848575592041
Validation loss: 1.566216713638716

Epoch: 5| Step: 2
Training loss: 0.18668422102928162
Validation loss: 1.5636194829017884

Epoch: 5| Step: 3
Training loss: 0.26852041482925415
Validation loss: 1.5513485580362298

Epoch: 5| Step: 4
Training loss: 0.28337112069129944
Validation loss: 1.5609238070826377

Epoch: 5| Step: 5
Training loss: 0.2668762803077698
Validation loss: 1.5736318172947052

Epoch: 5| Step: 6
Training loss: 0.3135921061038971
Validation loss: 1.5709414789753575

Epoch: 5| Step: 7
Training loss: 0.20574669539928436
Validation loss: 1.5584835711345877

Epoch: 5| Step: 8
Training loss: 0.31578320264816284
Validation loss: 1.5763072890620078

Epoch: 5| Step: 9
Training loss: 0.10447174310684204
Validation loss: 1.5466508339810114

Epoch: 5| Step: 10
Training loss: 0.26142382621765137
Validation loss: 1.5452406598675636

Epoch: 432| Step: 0
Training loss: 0.20146635174751282
Validation loss: 1.5371934034491097

Epoch: 5| Step: 1
Training loss: 0.17025884985923767
Validation loss: 1.5270703966899584

Epoch: 5| Step: 2
Training loss: 0.11724807322025299
Validation loss: 1.5541564418423561

Epoch: 5| Step: 3
Training loss: 0.15659227967262268
Validation loss: 1.5655360241090097

Epoch: 5| Step: 4
Training loss: 0.27739217877388
Validation loss: 1.5772651139126028

Epoch: 5| Step: 5
Training loss: 0.27737218141555786
Validation loss: 1.5974775604022446

Epoch: 5| Step: 6
Training loss: 0.20783543586730957
Validation loss: 1.624897405665408

Epoch: 5| Step: 7
Training loss: 0.24196486175060272
Validation loss: 1.5952881843813005

Epoch: 5| Step: 8
Training loss: 0.3331174850463867
Validation loss: 1.5641411888983943

Epoch: 5| Step: 9
Training loss: 0.20249760150909424
Validation loss: 1.5689178064305296

Epoch: 5| Step: 10
Training loss: 0.2392771691083908
Validation loss: 1.5609169339620939

Epoch: 433| Step: 0
Training loss: 0.16882917284965515
Validation loss: 1.5484390380561992

Epoch: 5| Step: 1
Training loss: 0.14221706986427307
Validation loss: 1.5656419056718067

Epoch: 5| Step: 2
Training loss: 0.3547918200492859
Validation loss: 1.571979429132195

Epoch: 5| Step: 3
Training loss: 0.22835317254066467
Validation loss: 1.5796169132314704

Epoch: 5| Step: 4
Training loss: 0.16745588183403015
Validation loss: 1.585150453352159

Epoch: 5| Step: 5
Training loss: 0.39683955907821655
Validation loss: 1.549478837238845

Epoch: 5| Step: 6
Training loss: 0.143504336476326
Validation loss: 1.5646085617362813

Epoch: 5| Step: 7
Training loss: 0.13543784618377686
Validation loss: 1.5576618858563003

Epoch: 5| Step: 8
Training loss: 0.20682387053966522
Validation loss: 1.5616544613274195

Epoch: 5| Step: 9
Training loss: 0.24329300224781036
Validation loss: 1.5612459657012776

Epoch: 5| Step: 10
Training loss: 0.1861427128314972
Validation loss: 1.5537632011598157

Epoch: 434| Step: 0
Training loss: 0.23935005068778992
Validation loss: 1.5847349487325197

Epoch: 5| Step: 1
Training loss: 0.2760913670063019
Validation loss: 1.5734303305225987

Epoch: 5| Step: 2
Training loss: 0.25003841519355774
Validation loss: 1.6061359272208264

Epoch: 5| Step: 3
Training loss: 0.10591699182987213
Validation loss: 1.5649468052771784

Epoch: 5| Step: 4
Training loss: 0.151686891913414
Validation loss: 1.592538942572891

Epoch: 5| Step: 5
Training loss: 0.23066914081573486
Validation loss: 1.623413557647377

Epoch: 5| Step: 6
Training loss: 0.26683589816093445
Validation loss: 1.6040942733005812

Epoch: 5| Step: 7
Training loss: 0.12407036870718002
Validation loss: 1.5984704725203975

Epoch: 5| Step: 8
Training loss: 0.16107383370399475
Validation loss: 1.5611528068460443

Epoch: 5| Step: 9
Training loss: 0.2984314560890198
Validation loss: 1.5654850441922423

Epoch: 5| Step: 10
Training loss: 0.27870047092437744
Validation loss: 1.563445355302544

Epoch: 435| Step: 0
Training loss: 0.14260631799697876
Validation loss: 1.5484064227791243

Epoch: 5| Step: 1
Training loss: 0.1636383831501007
Validation loss: 1.572300886595121

Epoch: 5| Step: 2
Training loss: 0.21617284417152405
Validation loss: 1.544154219729926

Epoch: 5| Step: 3
Training loss: 0.19810336828231812
Validation loss: 1.5560483022402691

Epoch: 5| Step: 4
Training loss: 0.22479304671287537
Validation loss: 1.543989642973869

Epoch: 5| Step: 5
Training loss: 0.14875894784927368
Validation loss: 1.5528809838397528

Epoch: 5| Step: 6
Training loss: 0.2203264683485031
Validation loss: 1.5826952521518995

Epoch: 5| Step: 7
Training loss: 0.13682584464550018
Validation loss: 1.5554393792665133

Epoch: 5| Step: 8
Training loss: 0.245155930519104
Validation loss: 1.5480728226323281

Epoch: 5| Step: 9
Training loss: 0.23072735965251923
Validation loss: 1.5441832388600996

Epoch: 5| Step: 10
Training loss: 0.2060670703649521
Validation loss: 1.568142323083775

Epoch: 436| Step: 0
Training loss: 0.16832733154296875
Validation loss: 1.547035183957828

Epoch: 5| Step: 1
Training loss: 0.06946312636137009
Validation loss: 1.5752716987363753

Epoch: 5| Step: 2
Training loss: 0.1417851448059082
Validation loss: 1.5771416169340893

Epoch: 5| Step: 3
Training loss: 0.16026470065116882
Validation loss: 1.5625318340075913

Epoch: 5| Step: 4
Training loss: 0.24234485626220703
Validation loss: 1.5501573137057725

Epoch: 5| Step: 5
Training loss: 0.26424333453178406
Validation loss: 1.5567798768320391

Epoch: 5| Step: 6
Training loss: 0.24229054152965546
Validation loss: 1.5527819292519682

Epoch: 5| Step: 7
Training loss: 0.17724403738975525
Validation loss: 1.5474713604937318

Epoch: 5| Step: 8
Training loss: 0.33215123414993286
Validation loss: 1.545671950104416

Epoch: 5| Step: 9
Training loss: 0.22817400097846985
Validation loss: 1.5804339570383872

Epoch: 5| Step: 10
Training loss: 0.24751758575439453
Validation loss: 1.5809476183306785

Epoch: 437| Step: 0
Training loss: 0.21885792911052704
Validation loss: 1.5866952890990882

Epoch: 5| Step: 1
Training loss: 0.2505868077278137
Validation loss: 1.6181070355958835

Epoch: 5| Step: 2
Training loss: 0.1930428445339203
Validation loss: 1.619079948753439

Epoch: 5| Step: 3
Training loss: 0.2816307544708252
Validation loss: 1.6279256472023584

Epoch: 5| Step: 4
Training loss: 0.18869149684906006
Validation loss: 1.6162073330212665

Epoch: 5| Step: 5
Training loss: 0.1993914693593979
Validation loss: 1.5936823173235821

Epoch: 5| Step: 6
Training loss: 0.08882325887680054
Validation loss: 1.567040608775231

Epoch: 5| Step: 7
Training loss: 0.41235774755477905
Validation loss: 1.5819308552690732

Epoch: 5| Step: 8
Training loss: 0.25951921939849854
Validation loss: 1.5533714614888674

Epoch: 5| Step: 9
Training loss: 0.23804588615894318
Validation loss: 1.5867907847127607

Epoch: 5| Step: 10
Training loss: 0.2988203167915344
Validation loss: 1.5561147479600803

Epoch: 438| Step: 0
Training loss: 0.28155940771102905
Validation loss: 1.5567806177241827

Epoch: 5| Step: 1
Training loss: 0.17723563313484192
Validation loss: 1.5621244599742274

Epoch: 5| Step: 2
Training loss: 0.14140930771827698
Validation loss: 1.5426425600564608

Epoch: 5| Step: 3
Training loss: 0.27440816164016724
Validation loss: 1.5659698132545716

Epoch: 5| Step: 4
Training loss: 0.24131658673286438
Validation loss: 1.572412698499618

Epoch: 5| Step: 5
Training loss: 0.27779877185821533
Validation loss: 1.5463799199750345

Epoch: 5| Step: 6
Training loss: 0.09307881444692612
Validation loss: 1.5134239606959845

Epoch: 5| Step: 7
Training loss: 0.20802459120750427
Validation loss: 1.5366791884104412

Epoch: 5| Step: 8
Training loss: 0.3258470594882965
Validation loss: 1.54002215913547

Epoch: 5| Step: 9
Training loss: 0.13228075206279755
Validation loss: 1.5436700313322005

Epoch: 5| Step: 10
Training loss: 0.31023263931274414
Validation loss: 1.5766261354569466

Epoch: 439| Step: 0
Training loss: 0.29804855585098267
Validation loss: 1.5700036588535513

Epoch: 5| Step: 1
Training loss: 0.3433676064014435
Validation loss: 1.6031701718607256

Epoch: 5| Step: 2
Training loss: 0.35907483100891113
Validation loss: 1.6027724025070027

Epoch: 5| Step: 3
Training loss: 0.31259652972221375
Validation loss: 1.5903734737826931

Epoch: 5| Step: 4
Training loss: 0.21343925595283508
Validation loss: 1.5770045236874652

Epoch: 5| Step: 5
Training loss: 0.23359966278076172
Validation loss: 1.5443861176890712

Epoch: 5| Step: 6
Training loss: 0.2144063264131546
Validation loss: 1.550809129591911

Epoch: 5| Step: 7
Training loss: 0.18279537558555603
Validation loss: 1.5363443820707259

Epoch: 5| Step: 8
Training loss: 0.2771625518798828
Validation loss: 1.529636235647304

Epoch: 5| Step: 9
Training loss: 0.2634701728820801
Validation loss: 1.557732302655456

Epoch: 5| Step: 10
Training loss: 0.12200136482715607
Validation loss: 1.5793264758202337

Epoch: 440| Step: 0
Training loss: 0.19848890602588654
Validation loss: 1.582862025947981

Epoch: 5| Step: 1
Training loss: 0.18263748288154602
Validation loss: 1.5658905890680128

Epoch: 5| Step: 2
Training loss: 0.14060989022254944
Validation loss: 1.5460213076683782

Epoch: 5| Step: 3
Training loss: 0.22107422351837158
Validation loss: 1.5675597934312717

Epoch: 5| Step: 4
Training loss: 0.1484074890613556
Validation loss: 1.5711892907337477

Epoch: 5| Step: 5
Training loss: 0.17773786187171936
Validation loss: 1.565005079392464

Epoch: 5| Step: 6
Training loss: 0.34763574600219727
Validation loss: 1.5631029349501415

Epoch: 5| Step: 7
Training loss: 0.31692105531692505
Validation loss: 1.5608107966761435

Epoch: 5| Step: 8
Training loss: 0.2915671765804291
Validation loss: 1.5569641340163447

Epoch: 5| Step: 9
Training loss: 0.2144581824541092
Validation loss: 1.5920789485336633

Epoch: 5| Step: 10
Training loss: 0.3246603012084961
Validation loss: 1.5607637743796072

Epoch: 441| Step: 0
Training loss: 0.11805605888366699
Validation loss: 1.529793741241578

Epoch: 5| Step: 1
Training loss: 0.22749671339988708
Validation loss: 1.5675294732534757

Epoch: 5| Step: 2
Training loss: 0.11091835796833038
Validation loss: 1.517069395511381

Epoch: 5| Step: 3
Training loss: 0.22444304823875427
Validation loss: 1.5469670552079395

Epoch: 5| Step: 4
Training loss: 0.25255388021469116
Validation loss: 1.5342408969838133

Epoch: 5| Step: 5
Training loss: 0.23112520575523376
Validation loss: 1.5296647253856863

Epoch: 5| Step: 6
Training loss: 0.16774912178516388
Validation loss: 1.547167061477579

Epoch: 5| Step: 7
Training loss: 0.2854230999946594
Validation loss: 1.586098531241058

Epoch: 5| Step: 8
Training loss: 0.19766947627067566
Validation loss: 1.5342517245200373

Epoch: 5| Step: 9
Training loss: 0.15323591232299805
Validation loss: 1.577417569775735

Epoch: 5| Step: 10
Training loss: 0.23493745923042297
Validation loss: 1.5516334682382562

Epoch: 442| Step: 0
Training loss: 0.095044806599617
Validation loss: 1.5632062419768302

Epoch: 5| Step: 1
Training loss: 0.2649417221546173
Validation loss: 1.5654221093782814

Epoch: 5| Step: 2
Training loss: 0.18308976292610168
Validation loss: 1.5575668132433327

Epoch: 5| Step: 3
Training loss: 0.2797657549381256
Validation loss: 1.5637133185581495

Epoch: 5| Step: 4
Training loss: 0.16677920520305634
Validation loss: 1.5568310611991472

Epoch: 5| Step: 5
Training loss: 0.21893644332885742
Validation loss: 1.5594045910783993

Epoch: 5| Step: 6
Training loss: 0.18775856494903564
Validation loss: 1.5320967000017884

Epoch: 5| Step: 7
Training loss: 0.16562989354133606
Validation loss: 1.5193624060641053

Epoch: 5| Step: 8
Training loss: 0.1446693390607834
Validation loss: 1.5260572010470974

Epoch: 5| Step: 9
Training loss: 0.15696048736572266
Validation loss: 1.5606616133002824

Epoch: 5| Step: 10
Training loss: 0.30719342827796936
Validation loss: 1.597332182750907

Epoch: 443| Step: 0
Training loss: 0.17998984456062317
Validation loss: 1.5736609248704807

Epoch: 5| Step: 1
Training loss: 0.24861808121204376
Validation loss: 1.6027076705809562

Epoch: 5| Step: 2
Training loss: 0.19567544758319855
Validation loss: 1.5579476318051737

Epoch: 5| Step: 3
Training loss: 0.21775014698505402
Validation loss: 1.5741243259881132

Epoch: 5| Step: 4
Training loss: 0.15175274014472961
Validation loss: 1.5519839461131761

Epoch: 5| Step: 5
Training loss: 0.21443906426429749
Validation loss: 1.561323783730948

Epoch: 5| Step: 6
Training loss: 0.17021194100379944
Validation loss: 1.5623895122158913

Epoch: 5| Step: 7
Training loss: 0.1886787712574005
Validation loss: 1.5337943614170115

Epoch: 5| Step: 8
Training loss: 0.24221546947956085
Validation loss: 1.5651693254388788

Epoch: 5| Step: 9
Training loss: 0.25046348571777344
Validation loss: 1.612877921391559

Epoch: 5| Step: 10
Training loss: 0.10120358318090439
Validation loss: 1.5973850078480218

Epoch: 444| Step: 0
Training loss: 0.14454121887683868
Validation loss: 1.6215707819948915

Epoch: 5| Step: 1
Training loss: 0.19891266524791718
Validation loss: 1.6088892221450806

Epoch: 5| Step: 2
Training loss: 0.18934646248817444
Validation loss: 1.6196084394249866

Epoch: 5| Step: 3
Training loss: 0.32258522510528564
Validation loss: 1.6112911393565517

Epoch: 5| Step: 4
Training loss: 0.28386279940605164
Validation loss: 1.5875841936757487

Epoch: 5| Step: 5
Training loss: 0.236121267080307
Validation loss: 1.609338188684115

Epoch: 5| Step: 6
Training loss: 0.3012358248233795
Validation loss: 1.598213485492173

Epoch: 5| Step: 7
Training loss: 0.30036264657974243
Validation loss: 1.5963880400503836

Epoch: 5| Step: 8
Training loss: 0.18041586875915527
Validation loss: 1.5829462197519117

Epoch: 5| Step: 9
Training loss: 0.19365856051445007
Validation loss: 1.5691867528423187

Epoch: 5| Step: 10
Training loss: 0.23056204617023468
Validation loss: 1.5674742069295657

Epoch: 445| Step: 0
Training loss: 0.27407875657081604
Validation loss: 1.5654615086893882

Epoch: 5| Step: 1
Training loss: 0.2929803729057312
Validation loss: 1.5808359640900806

Epoch: 5| Step: 2
Training loss: 0.19057898223400116
Validation loss: 1.5440612505840998

Epoch: 5| Step: 3
Training loss: 0.17461268603801727
Validation loss: 1.5309406698391002

Epoch: 5| Step: 4
Training loss: 0.18673738837242126
Validation loss: 1.5560380688277624

Epoch: 5| Step: 5
Training loss: 0.30243390798568726
Validation loss: 1.5505497314596688

Epoch: 5| Step: 6
Training loss: 0.12991811335086823
Validation loss: 1.5668503968946395

Epoch: 5| Step: 7
Training loss: 0.2294425666332245
Validation loss: 1.5663135974637923

Epoch: 5| Step: 8
Training loss: 0.1776757687330246
Validation loss: 1.5411916227750881

Epoch: 5| Step: 9
Training loss: 0.1737113893032074
Validation loss: 1.521531649815139

Epoch: 5| Step: 10
Training loss: 0.12611041963100433
Validation loss: 1.549138335771458

Epoch: 446| Step: 0
Training loss: 0.21193721890449524
Validation loss: 1.5585663241724814

Epoch: 5| Step: 1
Training loss: 0.06860977411270142
Validation loss: 1.554233689461985

Epoch: 5| Step: 2
Training loss: 0.34086376428604126
Validation loss: 1.5373764717450706

Epoch: 5| Step: 3
Training loss: 0.1923864334821701
Validation loss: 1.5438501193959226

Epoch: 5| Step: 4
Training loss: 0.154774010181427
Validation loss: 1.5435270122302476

Epoch: 5| Step: 5
Training loss: 0.23767821490764618
Validation loss: 1.5710671883757397

Epoch: 5| Step: 6
Training loss: 0.1174209713935852
Validation loss: 1.5806684513245859

Epoch: 5| Step: 7
Training loss: 0.15710173547267914
Validation loss: 1.5538440237763107

Epoch: 5| Step: 8
Training loss: 0.23350825905799866
Validation loss: 1.5503671682009132

Epoch: 5| Step: 9
Training loss: 0.33530017733573914
Validation loss: 1.5733020882452688

Epoch: 5| Step: 10
Training loss: 0.30435416102409363
Validation loss: 1.6027570847542054

Epoch: 447| Step: 0
Training loss: 0.2664906978607178
Validation loss: 1.5706290878275389

Epoch: 5| Step: 1
Training loss: 0.1718052178621292
Validation loss: 1.5553163187478178

Epoch: 5| Step: 2
Training loss: 0.2210143506526947
Validation loss: 1.6000685794379121

Epoch: 5| Step: 3
Training loss: 0.11854638904333115
Validation loss: 1.5808842220614034

Epoch: 5| Step: 4
Training loss: 0.1857849657535553
Validation loss: 1.5707664669200938

Epoch: 5| Step: 5
Training loss: 0.17102555930614471
Validation loss: 1.5669845855364235

Epoch: 5| Step: 6
Training loss: 0.2271377146244049
Validation loss: 1.5486525707347418

Epoch: 5| Step: 7
Training loss: 0.18525777757167816
Validation loss: 1.5407893042410574

Epoch: 5| Step: 8
Training loss: 0.1664613038301468
Validation loss: 1.5563712863511936

Epoch: 5| Step: 9
Training loss: 0.2698279023170471
Validation loss: 1.5665968182266399

Epoch: 5| Step: 10
Training loss: 0.19425083696842194
Validation loss: 1.5432137763628395

Epoch: 448| Step: 0
Training loss: 0.1984802782535553
Validation loss: 1.5955259723048056

Epoch: 5| Step: 1
Training loss: 0.21578840911388397
Validation loss: 1.6088769974247101

Epoch: 5| Step: 2
Training loss: 0.16172388195991516
Validation loss: 1.5791626925109534

Epoch: 5| Step: 3
Training loss: 0.1722063571214676
Validation loss: 1.57107074029984

Epoch: 5| Step: 4
Training loss: 0.25640004873275757
Validation loss: 1.5614355379535305

Epoch: 5| Step: 5
Training loss: 0.15511536598205566
Validation loss: 1.547211500265265

Epoch: 5| Step: 6
Training loss: 0.11180479824542999
Validation loss: 1.5419642374079714

Epoch: 5| Step: 7
Training loss: 0.13836587965488434
Validation loss: 1.560192032526898

Epoch: 5| Step: 8
Training loss: 0.21397221088409424
Validation loss: 1.5242587571503015

Epoch: 5| Step: 9
Training loss: 0.2914336323738098
Validation loss: 1.5372387696337957

Epoch: 5| Step: 10
Training loss: 0.2151172161102295
Validation loss: 1.5300576174131004

Epoch: 449| Step: 0
Training loss: 0.176841601729393
Validation loss: 1.5530733011102165

Epoch: 5| Step: 1
Training loss: 0.2557457685470581
Validation loss: 1.5697861627865863

Epoch: 5| Step: 2
Training loss: 0.21036481857299805
Validation loss: 1.5628074343486498

Epoch: 5| Step: 3
Training loss: 0.32974594831466675
Validation loss: 1.5602151475926882

Epoch: 5| Step: 4
Training loss: 0.15829797089099884
Validation loss: 1.5629260911736438

Epoch: 5| Step: 5
Training loss: 0.16410169005393982
Validation loss: 1.5594365622407647

Epoch: 5| Step: 6
Training loss: 0.3085100054740906
Validation loss: 1.558471243868592

Epoch: 5| Step: 7
Training loss: 0.14373202621936798
Validation loss: 1.5146247802242156

Epoch: 5| Step: 8
Training loss: 0.1724773794412613
Validation loss: 1.5195830932227514

Epoch: 5| Step: 9
Training loss: 0.11676595360040665
Validation loss: 1.5300857828509422

Epoch: 5| Step: 10
Training loss: 0.19967521727085114
Validation loss: 1.5464163595630276

Epoch: 450| Step: 0
Training loss: 0.1462232768535614
Validation loss: 1.5384913567573792

Epoch: 5| Step: 1
Training loss: 0.15168090164661407
Validation loss: 1.5401108316195908

Epoch: 5| Step: 2
Training loss: 0.147527813911438
Validation loss: 1.5186569626613329

Epoch: 5| Step: 3
Training loss: 0.2299170047044754
Validation loss: 1.5348700233685073

Epoch: 5| Step: 4
Training loss: 0.3106841444969177
Validation loss: 1.539965950032716

Epoch: 5| Step: 5
Training loss: 0.1541750133037567
Validation loss: 1.5385068244831537

Epoch: 5| Step: 6
Training loss: 0.22272849082946777
Validation loss: 1.5672364183651504

Epoch: 5| Step: 7
Training loss: 0.24568350613117218
Validation loss: 1.5583481237452517

Epoch: 5| Step: 8
Training loss: 0.1739417016506195
Validation loss: 1.5780688062790902

Epoch: 5| Step: 9
Training loss: 0.16255277395248413
Validation loss: 1.5761923020885837

Epoch: 5| Step: 10
Training loss: 0.39400190114974976
Validation loss: 1.5945085479367165

Epoch: 451| Step: 0
Training loss: 0.21390005946159363
Validation loss: 1.6116055391168083

Epoch: 5| Step: 1
Training loss: 0.10154043138027191
Validation loss: 1.58481567136703

Epoch: 5| Step: 2
Training loss: 0.1873009353876114
Validation loss: 1.5696574218811528

Epoch: 5| Step: 3
Training loss: 0.28403741121292114
Validation loss: 1.5403068322007374

Epoch: 5| Step: 4
Training loss: 0.2309393584728241
Validation loss: 1.5498245121330343

Epoch: 5| Step: 5
Training loss: 0.1288709193468094
Validation loss: 1.5150517097083471

Epoch: 5| Step: 6
Training loss: 0.19170399010181427
Validation loss: 1.52459450562795

Epoch: 5| Step: 7
Training loss: 0.200687974691391
Validation loss: 1.534775500656456

Epoch: 5| Step: 8
Training loss: 0.18421150743961334
Validation loss: 1.512833991358357

Epoch: 5| Step: 9
Training loss: 0.2230943739414215
Validation loss: 1.5231871322918964

Epoch: 5| Step: 10
Training loss: 0.18425537645816803
Validation loss: 1.500321904818217

Epoch: 452| Step: 0
Training loss: 0.176224023103714
Validation loss: 1.4967660801385039

Epoch: 5| Step: 1
Training loss: 0.28584691882133484
Validation loss: 1.5106674855755222

Epoch: 5| Step: 2
Training loss: 0.2288094013929367
Validation loss: 1.507835154892296

Epoch: 5| Step: 3
Training loss: 0.19674183428287506
Validation loss: 1.5043573276970976

Epoch: 5| Step: 4
Training loss: 0.1894662231206894
Validation loss: 1.5069125313912668

Epoch: 5| Step: 5
Training loss: 0.16675357520580292
Validation loss: 1.5051143118130264

Epoch: 5| Step: 6
Training loss: 0.2631891965866089
Validation loss: 1.4982079197001714

Epoch: 5| Step: 7
Training loss: 0.08779583871364594
Validation loss: 1.517086394371525

Epoch: 5| Step: 8
Training loss: 0.10172116756439209
Validation loss: 1.517455949578234

Epoch: 5| Step: 9
Training loss: 0.20913131535053253
Validation loss: 1.5452858735156316

Epoch: 5| Step: 10
Training loss: 0.15402457118034363
Validation loss: 1.5410652545190626

Epoch: 453| Step: 0
Training loss: 0.20607414841651917
Validation loss: 1.5547197659810383

Epoch: 5| Step: 1
Training loss: 0.19346272945404053
Validation loss: 1.5518938161993538

Epoch: 5| Step: 2
Training loss: 0.19155645370483398
Validation loss: 1.5608834310244488

Epoch: 5| Step: 3
Training loss: 0.3119972050189972
Validation loss: 1.5427614514545729

Epoch: 5| Step: 4
Training loss: 0.1901974380016327
Validation loss: 1.5224912679323586

Epoch: 5| Step: 5
Training loss: 0.12155812978744507
Validation loss: 1.5416727424949728

Epoch: 5| Step: 6
Training loss: 0.18127642571926117
Validation loss: 1.5450642185826455

Epoch: 5| Step: 7
Training loss: 0.13513198494911194
Validation loss: 1.5308954459364696

Epoch: 5| Step: 8
Training loss: 0.2022169828414917
Validation loss: 1.554836512893759

Epoch: 5| Step: 9
Training loss: 0.1833796501159668
Validation loss: 1.5912850076152432

Epoch: 5| Step: 10
Training loss: 0.1622592657804489
Validation loss: 1.5697944010457685

Epoch: 454| Step: 0
Training loss: 0.2437901496887207
Validation loss: 1.5559356494616436

Epoch: 5| Step: 1
Training loss: 0.16661302745342255
Validation loss: 1.5598638672982492

Epoch: 5| Step: 2
Training loss: 0.20459195971488953
Validation loss: 1.5804305345781389

Epoch: 5| Step: 3
Training loss: 0.2768014073371887
Validation loss: 1.5834584133599394

Epoch: 5| Step: 4
Training loss: 0.22707800567150116
Validation loss: 1.5783228271750993

Epoch: 5| Step: 5
Training loss: 0.109782874584198
Validation loss: 1.5553100685919485

Epoch: 5| Step: 6
Training loss: 0.17461763322353363
Validation loss: 1.555128175725219

Epoch: 5| Step: 7
Training loss: 0.15327182412147522
Validation loss: 1.563753354933954

Epoch: 5| Step: 8
Training loss: 0.1764368861913681
Validation loss: 1.555759169722116

Epoch: 5| Step: 9
Training loss: 0.1696857064962387
Validation loss: 1.5572452365711171

Epoch: 5| Step: 10
Training loss: 0.27187418937683105
Validation loss: 1.571229693710163

Epoch: 455| Step: 0
Training loss: 0.18715472519397736
Validation loss: 1.563141902287801

Epoch: 5| Step: 1
Training loss: 0.1286565661430359
Validation loss: 1.5391690372138895

Epoch: 5| Step: 2
Training loss: 0.2689328193664551
Validation loss: 1.5443547336004113

Epoch: 5| Step: 3
Training loss: 0.2306857407093048
Validation loss: 1.5560803016026814

Epoch: 5| Step: 4
Training loss: 0.25409212708473206
Validation loss: 1.528709279593601

Epoch: 5| Step: 5
Training loss: 0.22227425873279572
Validation loss: 1.5409844331843878

Epoch: 5| Step: 6
Training loss: 0.22547385096549988
Validation loss: 1.530398444462848

Epoch: 5| Step: 7
Training loss: 0.26793020963668823
Validation loss: 1.550143095754808

Epoch: 5| Step: 8
Training loss: 0.1731746643781662
Validation loss: 1.5939730213534447

Epoch: 5| Step: 9
Training loss: 0.28530994057655334
Validation loss: 1.6379097315572924

Epoch: 5| Step: 10
Training loss: 0.15499718487262726
Validation loss: 1.680871320027177

Epoch: 456| Step: 0
Training loss: 0.24483290314674377
Validation loss: 1.6675907309337328

Epoch: 5| Step: 1
Training loss: 0.31323572993278503
Validation loss: 1.6595458651101718

Epoch: 5| Step: 2
Training loss: 0.26596522331237793
Validation loss: 1.6260229368363657

Epoch: 5| Step: 3
Training loss: 0.2684074938297272
Validation loss: 1.6165382003271451

Epoch: 5| Step: 4
Training loss: 0.13891272246837616
Validation loss: 1.593085519729122

Epoch: 5| Step: 5
Training loss: 0.1781131476163864
Validation loss: 1.5548007616432764

Epoch: 5| Step: 6
Training loss: 0.20071950554847717
Validation loss: 1.5531131971266963

Epoch: 5| Step: 7
Training loss: 0.14888334274291992
Validation loss: 1.568127429613503

Epoch: 5| Step: 8
Training loss: 0.22808465361595154
Validation loss: 1.570211515631727

Epoch: 5| Step: 9
Training loss: 0.19617310166358948
Validation loss: 1.5508796335548483

Epoch: 5| Step: 10
Training loss: 0.16140596568584442
Validation loss: 1.5626531749643304

Epoch: 457| Step: 0
Training loss: 0.16660597920417786
Validation loss: 1.6071627652773293

Epoch: 5| Step: 1
Training loss: 0.21088984608650208
Validation loss: 1.5801512284945416

Epoch: 5| Step: 2
Training loss: 0.17907190322875977
Validation loss: 1.5855842110931233

Epoch: 5| Step: 3
Training loss: 0.16889533400535583
Validation loss: 1.5907741746594828

Epoch: 5| Step: 4
Training loss: 0.22873811423778534
Validation loss: 1.592873687385231

Epoch: 5| Step: 5
Training loss: 0.11865150928497314
Validation loss: 1.577116076664258

Epoch: 5| Step: 6
Training loss: 0.2096324861049652
Validation loss: 1.6024506515072239

Epoch: 5| Step: 7
Training loss: 0.2588423192501068
Validation loss: 1.5979881824985627

Epoch: 5| Step: 8
Training loss: 0.14938147366046906
Validation loss: 1.6048138385177941

Epoch: 5| Step: 9
Training loss: 0.27044886350631714
Validation loss: 1.5976474990126908

Epoch: 5| Step: 10
Training loss: 0.27322515845298767
Validation loss: 1.5578277880145657

Epoch: 458| Step: 0
Training loss: 0.203190416097641
Validation loss: 1.5659270542924122

Epoch: 5| Step: 1
Training loss: 0.115284763276577
Validation loss: 1.5566178303892895

Epoch: 5| Step: 2
Training loss: 0.09843187034130096
Validation loss: 1.5690959589455717

Epoch: 5| Step: 3
Training loss: 0.11149201542139053
Validation loss: 1.5801889140118834

Epoch: 5| Step: 4
Training loss: 0.21271243691444397
Validation loss: 1.5759637535259288

Epoch: 5| Step: 5
Training loss: 0.3080173134803772
Validation loss: 1.5678318226209251

Epoch: 5| Step: 6
Training loss: 0.2601226270198822
Validation loss: 1.5493542410994088

Epoch: 5| Step: 7
Training loss: 0.26224687695503235
Validation loss: 1.5589487168096727

Epoch: 5| Step: 8
Training loss: 0.1916496753692627
Validation loss: 1.5440330274643437

Epoch: 5| Step: 9
Training loss: 0.18113210797309875
Validation loss: 1.5518120770813317

Epoch: 5| Step: 10
Training loss: 0.1547149121761322
Validation loss: 1.547757133360832

Epoch: 459| Step: 0
Training loss: 0.17824260890483856
Validation loss: 1.5748712439690866

Epoch: 5| Step: 1
Training loss: 0.2227383553981781
Validation loss: 1.5883479208074591

Epoch: 5| Step: 2
Training loss: 0.14646221697330475
Validation loss: 1.5804278068645026

Epoch: 5| Step: 3
Training loss: 0.191603422164917
Validation loss: 1.5713086692235803

Epoch: 5| Step: 4
Training loss: 0.14212600886821747
Validation loss: 1.5636560775900399

Epoch: 5| Step: 5
Training loss: 0.21705543994903564
Validation loss: 1.5597069635186145

Epoch: 5| Step: 6
Training loss: 0.134857177734375
Validation loss: 1.5334531145711099

Epoch: 5| Step: 7
Training loss: 0.1280752569437027
Validation loss: 1.5619805807708411

Epoch: 5| Step: 8
Training loss: 0.18205639719963074
Validation loss: 1.5518481539141746

Epoch: 5| Step: 9
Training loss: 0.17423292994499207
Validation loss: 1.555504282315572

Epoch: 5| Step: 10
Training loss: 0.16096000373363495
Validation loss: 1.5783926299823228

Epoch: 460| Step: 0
Training loss: 0.13765251636505127
Validation loss: 1.5848927318408925

Epoch: 5| Step: 1
Training loss: 0.17955735325813293
Validation loss: 1.5669303312096545

Epoch: 5| Step: 2
Training loss: 0.1449463963508606
Validation loss: 1.5483522197251678

Epoch: 5| Step: 3
Training loss: 0.1405426263809204
Validation loss: 1.565124709119079

Epoch: 5| Step: 4
Training loss: 0.2699717581272125
Validation loss: 1.5575313645024453

Epoch: 5| Step: 5
Training loss: 0.12777963280677795
Validation loss: 1.564502505845921

Epoch: 5| Step: 6
Training loss: 0.2767699360847473
Validation loss: 1.5213382615838

Epoch: 5| Step: 7
Training loss: 0.18032173812389374
Validation loss: 1.5771609942118328

Epoch: 5| Step: 8
Training loss: 0.0684426948428154
Validation loss: 1.5478392980431999

Epoch: 5| Step: 9
Training loss: 0.3094068467617035
Validation loss: 1.5693607202140234

Epoch: 5| Step: 10
Training loss: 0.1461031138896942
Validation loss: 1.55699509702703

Epoch: 461| Step: 0
Training loss: 0.2764785885810852
Validation loss: 1.5830514995000695

Epoch: 5| Step: 1
Training loss: 0.1807907074689865
Validation loss: 1.5833542910955285

Epoch: 5| Step: 2
Training loss: 0.2790624499320984
Validation loss: 1.5705530502462899

Epoch: 5| Step: 3
Training loss: 0.20556640625
Validation loss: 1.5788130811465684

Epoch: 5| Step: 4
Training loss: 0.13881464302539825
Validation loss: 1.585400435232347

Epoch: 5| Step: 5
Training loss: 0.20044024288654327
Validation loss: 1.5612734325470463

Epoch: 5| Step: 6
Training loss: 0.23382540047168732
Validation loss: 1.5717898030434885

Epoch: 5| Step: 7
Training loss: 0.15926192700862885
Validation loss: 1.5789330210737003

Epoch: 5| Step: 8
Training loss: 0.12005747854709625
Validation loss: 1.5903695744852866

Epoch: 5| Step: 9
Training loss: 0.14284400641918182
Validation loss: 1.568135658899943

Epoch: 5| Step: 10
Training loss: 0.14020642638206482
Validation loss: 1.5729570414430352

Epoch: 462| Step: 0
Training loss: 0.11659570038318634
Validation loss: 1.5421233254094278

Epoch: 5| Step: 1
Training loss: 0.21954187750816345
Validation loss: 1.5632977319020096

Epoch: 5| Step: 2
Training loss: 0.2012082040309906
Validation loss: 1.5392134035787275

Epoch: 5| Step: 3
Training loss: 0.09732826054096222
Validation loss: 1.57240943883055

Epoch: 5| Step: 4
Training loss: 0.11809271574020386
Validation loss: 1.6002483624283985

Epoch: 5| Step: 5
Training loss: 0.16885095834732056
Validation loss: 1.5639396534171155

Epoch: 5| Step: 6
Training loss: 0.24846115708351135
Validation loss: 1.5795447980203936

Epoch: 5| Step: 7
Training loss: 0.1696157455444336
Validation loss: 1.5835130740237493

Epoch: 5| Step: 8
Training loss: 0.13063564896583557
Validation loss: 1.5873572416202997

Epoch: 5| Step: 9
Training loss: 0.1605469137430191
Validation loss: 1.5736381648689188

Epoch: 5| Step: 10
Training loss: 0.21990154683589935
Validation loss: 1.5980993650292838

Epoch: 463| Step: 0
Training loss: 0.2067832052707672
Validation loss: 1.5855439593715053

Epoch: 5| Step: 1
Training loss: 0.19710712134838104
Validation loss: 1.6080993401106967

Epoch: 5| Step: 2
Training loss: 0.2145765721797943
Validation loss: 1.5722663889649093

Epoch: 5| Step: 3
Training loss: 0.18997466564178467
Validation loss: 1.6089318772797943

Epoch: 5| Step: 4
Training loss: 0.1376206874847412
Validation loss: 1.5841419517353017

Epoch: 5| Step: 5
Training loss: 0.2424236238002777
Validation loss: 1.5575396783890263

Epoch: 5| Step: 6
Training loss: 0.12385322153568268
Validation loss: 1.5619251484512

Epoch: 5| Step: 7
Training loss: 0.22034721076488495
Validation loss: 1.5642269529322141

Epoch: 5| Step: 8
Training loss: 0.19943180680274963
Validation loss: 1.5637620174756615

Epoch: 5| Step: 9
Training loss: 0.23687438666820526
Validation loss: 1.5336481813461549

Epoch: 5| Step: 10
Training loss: 0.09885139763355255
Validation loss: 1.5624378265873078

Epoch: 464| Step: 0
Training loss: 0.10348889976739883
Validation loss: 1.5416437810467136

Epoch: 5| Step: 1
Training loss: 0.1651144027709961
Validation loss: 1.574098720345446

Epoch: 5| Step: 2
Training loss: 0.16548849642276764
Validation loss: 1.538271132335868

Epoch: 5| Step: 3
Training loss: 0.2522140145301819
Validation loss: 1.5597396717276624

Epoch: 5| Step: 4
Training loss: 0.18875038623809814
Validation loss: 1.605951484813485

Epoch: 5| Step: 5
Training loss: 0.28151702880859375
Validation loss: 1.5867178452912198

Epoch: 5| Step: 6
Training loss: 0.2568589150905609
Validation loss: 1.60541650941295

Epoch: 5| Step: 7
Training loss: 0.16977804899215698
Validation loss: 1.5651603232147873

Epoch: 5| Step: 8
Training loss: 0.16221173107624054
Validation loss: 1.6136937872056039

Epoch: 5| Step: 9
Training loss: 0.1817801296710968
Validation loss: 1.5772120644969325

Epoch: 5| Step: 10
Training loss: 0.19331640005111694
Validation loss: 1.5808138975533106

Epoch: 465| Step: 0
Training loss: 0.1497720181941986
Validation loss: 1.5579655529350362

Epoch: 5| Step: 1
Training loss: 0.22701235115528107
Validation loss: 1.5626380469209404

Epoch: 5| Step: 2
Training loss: 0.12427613884210587
Validation loss: 1.5824954663553545

Epoch: 5| Step: 3
Training loss: 0.15142564475536346
Validation loss: 1.5246168349378852

Epoch: 5| Step: 4
Training loss: 0.22426585853099823
Validation loss: 1.5674368771173621

Epoch: 5| Step: 5
Training loss: 0.19408613443374634
Validation loss: 1.5456975160106536

Epoch: 5| Step: 6
Training loss: 0.21321836113929749
Validation loss: 1.529648273221908

Epoch: 5| Step: 7
Training loss: 0.25148123502731323
Validation loss: 1.5581200533015753

Epoch: 5| Step: 8
Training loss: 0.09735442698001862
Validation loss: 1.5562468369801838

Epoch: 5| Step: 9
Training loss: 0.16869549453258514
Validation loss: 1.555459382713482

Epoch: 5| Step: 10
Training loss: 0.2314448356628418
Validation loss: 1.5533276437431254

Epoch: 466| Step: 0
Training loss: 0.09955618530511856
Validation loss: 1.556668839147014

Epoch: 5| Step: 1
Training loss: 0.17003774642944336
Validation loss: 1.5437218091821159

Epoch: 5| Step: 2
Training loss: 0.13867461681365967
Validation loss: 1.5399750727479176

Epoch: 5| Step: 3
Training loss: 0.1684311032295227
Validation loss: 1.5323950949535574

Epoch: 5| Step: 4
Training loss: 0.152553528547287
Validation loss: 1.5159793438449982

Epoch: 5| Step: 5
Training loss: 0.16724324226379395
Validation loss: 1.5374031118167344

Epoch: 5| Step: 6
Training loss: 0.18435566127300262
Validation loss: 1.5133363982682586

Epoch: 5| Step: 7
Training loss: 0.16368432343006134
Validation loss: 1.5447945223059705

Epoch: 5| Step: 8
Training loss: 0.20946311950683594
Validation loss: 1.5469041159076076

Epoch: 5| Step: 9
Training loss: 0.21450713276863098
Validation loss: 1.5301216904835035

Epoch: 5| Step: 10
Training loss: 0.23630759119987488
Validation loss: 1.5207504110951577

Epoch: 467| Step: 0
Training loss: 0.192501038312912
Validation loss: 1.5288714875457108

Epoch: 5| Step: 1
Training loss: 0.16695956885814667
Validation loss: 1.5280640830275833

Epoch: 5| Step: 2
Training loss: 0.1448444128036499
Validation loss: 1.5287529986391786

Epoch: 5| Step: 3
Training loss: 0.17873093485832214
Validation loss: 1.5066845955387238

Epoch: 5| Step: 4
Training loss: 0.18018805980682373
Validation loss: 1.5451213390596452

Epoch: 5| Step: 5
Training loss: 0.19806358218193054
Validation loss: 1.5537992715835571

Epoch: 5| Step: 6
Training loss: 0.1838988959789276
Validation loss: 1.613205753346925

Epoch: 5| Step: 7
Training loss: 0.3610643744468689
Validation loss: 1.5888039565855456

Epoch: 5| Step: 8
Training loss: 0.2398536652326584
Validation loss: 1.5672864529394335

Epoch: 5| Step: 9
Training loss: 0.08640895783901215
Validation loss: 1.5640170420369794

Epoch: 5| Step: 10
Training loss: 0.17617130279541016
Validation loss: 1.5707481714986986

Epoch: 468| Step: 0
Training loss: 0.15268580615520477
Validation loss: 1.5664216536347584

Epoch: 5| Step: 1
Training loss: 0.22202973067760468
Validation loss: 1.5231763592330358

Epoch: 5| Step: 2
Training loss: 0.14808389544487
Validation loss: 1.534519615993705

Epoch: 5| Step: 3
Training loss: 0.20448045432567596
Validation loss: 1.5299941006527151

Epoch: 5| Step: 4
Training loss: 0.1654028296470642
Validation loss: 1.54683131171811

Epoch: 5| Step: 5
Training loss: 0.12498565018177032
Validation loss: 1.5249550406650831

Epoch: 5| Step: 6
Training loss: 0.1888452172279358
Validation loss: 1.5618875539431007

Epoch: 5| Step: 7
Training loss: 0.21064290404319763
Validation loss: 1.5392921534917687

Epoch: 5| Step: 8
Training loss: 0.19492438435554504
Validation loss: 1.560795505841573

Epoch: 5| Step: 9
Training loss: 0.19404380023479462
Validation loss: 1.5486361416437293

Epoch: 5| Step: 10
Training loss: 0.22503677010536194
Validation loss: 1.5350730047431043

Epoch: 469| Step: 0
Training loss: 0.20149114727973938
Validation loss: 1.5390447173067319

Epoch: 5| Step: 1
Training loss: 0.20139102637767792
Validation loss: 1.5403161433435255

Epoch: 5| Step: 2
Training loss: 0.2005254328250885
Validation loss: 1.5434209377534929

Epoch: 5| Step: 3
Training loss: 0.13728441298007965
Validation loss: 1.546979486301381

Epoch: 5| Step: 4
Training loss: 0.1641143560409546
Validation loss: 1.55727179204264

Epoch: 5| Step: 5
Training loss: 0.17594552040100098
Validation loss: 1.558044207993374

Epoch: 5| Step: 6
Training loss: 0.09548312425613403
Validation loss: 1.5405261388389013

Epoch: 5| Step: 7
Training loss: 0.22574873268604279
Validation loss: 1.5549475685242684

Epoch: 5| Step: 8
Training loss: 0.20809784531593323
Validation loss: 1.5436791399473786

Epoch: 5| Step: 9
Training loss: 0.16899654269218445
Validation loss: 1.559009264874202

Epoch: 5| Step: 10
Training loss: 0.15099672973155975
Validation loss: 1.5504190383418914

Epoch: 470| Step: 0
Training loss: 0.1987842619419098
Validation loss: 1.54014051857815

Epoch: 5| Step: 1
Training loss: 0.11637143045663834
Validation loss: 1.517721006947179

Epoch: 5| Step: 2
Training loss: 0.2043311893939972
Validation loss: 1.5494405428568523

Epoch: 5| Step: 3
Training loss: 0.15179720520973206
Validation loss: 1.4976644951810119

Epoch: 5| Step: 4
Training loss: 0.22251179814338684
Validation loss: 1.542347946474629

Epoch: 5| Step: 5
Training loss: 0.35451894998550415
Validation loss: 1.525210247244886

Epoch: 5| Step: 6
Training loss: 0.13744047284126282
Validation loss: 1.5479268232981365

Epoch: 5| Step: 7
Training loss: 0.09157729148864746
Validation loss: 1.564993716055347

Epoch: 5| Step: 8
Training loss: 0.22429852187633514
Validation loss: 1.542568822060862

Epoch: 5| Step: 9
Training loss: 0.11916421353816986
Validation loss: 1.5546497036052007

Epoch: 5| Step: 10
Training loss: 0.10234789550304413
Validation loss: 1.5662037928899128

Epoch: 471| Step: 0
Training loss: 0.19370043277740479
Validation loss: 1.5487895319538731

Epoch: 5| Step: 1
Training loss: 0.1696413904428482
Validation loss: 1.5535816889937206

Epoch: 5| Step: 2
Training loss: 0.20291709899902344
Validation loss: 1.5350635103000108

Epoch: 5| Step: 3
Training loss: 0.17048873007297516
Validation loss: 1.5744211122553835

Epoch: 5| Step: 4
Training loss: 0.1457662284374237
Validation loss: 1.551433091522545

Epoch: 5| Step: 5
Training loss: 0.11591561138629913
Validation loss: 1.5716862319618143

Epoch: 5| Step: 6
Training loss: 0.18311378359794617
Validation loss: 1.5454574631106468

Epoch: 5| Step: 7
Training loss: 0.10466428101062775
Validation loss: 1.5319599054192985

Epoch: 5| Step: 8
Training loss: 0.15142852067947388
Validation loss: 1.5348296396193966

Epoch: 5| Step: 9
Training loss: 0.0961303636431694
Validation loss: 1.5250237231613488

Epoch: 5| Step: 10
Training loss: 0.2749602496623993
Validation loss: 1.5664859125691075

Epoch: 472| Step: 0
Training loss: 0.1511772871017456
Validation loss: 1.572117999035825

Epoch: 5| Step: 1
Training loss: 0.17727074027061462
Validation loss: 1.5537552846375333

Epoch: 5| Step: 2
Training loss: 0.2139851152896881
Validation loss: 1.5378927723053963

Epoch: 5| Step: 3
Training loss: 0.11602945625782013
Validation loss: 1.5388771462184128

Epoch: 5| Step: 4
Training loss: 0.15858399868011475
Validation loss: 1.5409943711373113

Epoch: 5| Step: 5
Training loss: 0.18465837836265564
Validation loss: 1.536638746979416

Epoch: 5| Step: 6
Training loss: 0.15643243491649628
Validation loss: 1.5265024118526007

Epoch: 5| Step: 7
Training loss: 0.21496275067329407
Validation loss: 1.5255593535720662

Epoch: 5| Step: 8
Training loss: 0.18724775314331055
Validation loss: 1.5255142540060065

Epoch: 5| Step: 9
Training loss: 0.1046234741806984
Validation loss: 1.5125210554369035

Epoch: 5| Step: 10
Training loss: 0.17298036813735962
Validation loss: 1.5263263602410593

Epoch: 473| Step: 0
Training loss: 0.22657206654548645
Validation loss: 1.518895838850288

Epoch: 5| Step: 1
Training loss: 0.09218950569629669
Validation loss: 1.544830487620446

Epoch: 5| Step: 2
Training loss: 0.21953444182872772
Validation loss: 1.5240885160302604

Epoch: 5| Step: 3
Training loss: 0.2169301062822342
Validation loss: 1.5182844067132601

Epoch: 5| Step: 4
Training loss: 0.09831291437149048
Validation loss: 1.546061103061963

Epoch: 5| Step: 5
Training loss: 0.11286543309688568
Validation loss: 1.5275038967850387

Epoch: 5| Step: 6
Training loss: 0.2663625478744507
Validation loss: 1.541036795544368

Epoch: 5| Step: 7
Training loss: 0.15585866570472717
Validation loss: 1.518702208995819

Epoch: 5| Step: 8
Training loss: 0.14411500096321106
Validation loss: 1.5123692347157387

Epoch: 5| Step: 9
Training loss: 0.11460764706134796
Validation loss: 1.5562677011694959

Epoch: 5| Step: 10
Training loss: 0.1888454258441925
Validation loss: 1.5240907258884882

Epoch: 474| Step: 0
Training loss: 0.09612961858510971
Validation loss: 1.5722542219264533

Epoch: 5| Step: 1
Training loss: 0.14166803658008575
Validation loss: 1.582326308373482

Epoch: 5| Step: 2
Training loss: 0.20744922757148743
Validation loss: 1.5664400323744743

Epoch: 5| Step: 3
Training loss: 0.13224400579929352
Validation loss: 1.5424453173914263

Epoch: 5| Step: 4
Training loss: 0.1522049903869629
Validation loss: 1.5627410937381048

Epoch: 5| Step: 5
Training loss: 0.11918847262859344
Validation loss: 1.568773490126415

Epoch: 5| Step: 6
Training loss: 0.15920671820640564
Validation loss: 1.560507143697431

Epoch: 5| Step: 7
Training loss: 0.20693166553974152
Validation loss: 1.5298373417187763

Epoch: 5| Step: 8
Training loss: 0.209278866648674
Validation loss: 1.5504973267996183

Epoch: 5| Step: 9
Training loss: 0.2564401626586914
Validation loss: 1.5430857763495496

Epoch: 5| Step: 10
Training loss: 0.0901980996131897
Validation loss: 1.5501240338048627

Epoch: 475| Step: 0
Training loss: 0.19729584455490112
Validation loss: 1.5110685325437976

Epoch: 5| Step: 1
Training loss: 0.1475621908903122
Validation loss: 1.5211204444208453

Epoch: 5| Step: 2
Training loss: 0.16619518399238586
Validation loss: 1.527148901775319

Epoch: 5| Step: 3
Training loss: 0.14205875992774963
Validation loss: 1.5522792505961593

Epoch: 5| Step: 4
Training loss: 0.24707546830177307
Validation loss: 1.5319828359029626

Epoch: 5| Step: 5
Training loss: 0.06678652763366699
Validation loss: 1.5336747989859632

Epoch: 5| Step: 6
Training loss: 0.08443741500377655
Validation loss: 1.5392122935223322

Epoch: 5| Step: 7
Training loss: 0.14493480324745178
Validation loss: 1.5133333218994962

Epoch: 5| Step: 8
Training loss: 0.1565539687871933
Validation loss: 1.530240430626818

Epoch: 5| Step: 9
Training loss: 0.1915939599275589
Validation loss: 1.5542500121619112

Epoch: 5| Step: 10
Training loss: 0.11589646339416504
Validation loss: 1.5674213670915174

Epoch: 476| Step: 0
Training loss: 0.1304672360420227
Validation loss: 1.5634988302825599

Epoch: 5| Step: 1
Training loss: 0.17194901406764984
Validation loss: 1.5689113063196982

Epoch: 5| Step: 2
Training loss: 0.1339164525270462
Validation loss: 1.5235684135908723

Epoch: 5| Step: 3
Training loss: 0.24521522223949432
Validation loss: 1.5525574953325334

Epoch: 5| Step: 4
Training loss: 0.12357152998447418
Validation loss: 1.555448942286994

Epoch: 5| Step: 5
Training loss: 0.16748246550559998
Validation loss: 1.5546735358494583

Epoch: 5| Step: 6
Training loss: 0.20569416880607605
Validation loss: 1.531484624390961

Epoch: 5| Step: 7
Training loss: 0.11060478538274765
Validation loss: 1.5581101217577535

Epoch: 5| Step: 8
Training loss: 0.2130005806684494
Validation loss: 1.57174882324793

Epoch: 5| Step: 9
Training loss: 0.17164862155914307
Validation loss: 1.5415503530092136

Epoch: 5| Step: 10
Training loss: 0.15878702700138092
Validation loss: 1.5250643568654214

Epoch: 477| Step: 0
Training loss: 0.14191511273384094
Validation loss: 1.5362708004572059

Epoch: 5| Step: 1
Training loss: 0.19990503787994385
Validation loss: 1.538734923126877

Epoch: 5| Step: 2
Training loss: 0.21688289940357208
Validation loss: 1.5499754131481212

Epoch: 5| Step: 3
Training loss: 0.20022711157798767
Validation loss: 1.5397830599097795

Epoch: 5| Step: 4
Training loss: 0.2313046157360077
Validation loss: 1.5348865114232546

Epoch: 5| Step: 5
Training loss: 0.2169434130191803
Validation loss: 1.5230049804974628

Epoch: 5| Step: 6
Training loss: 0.1620291769504547
Validation loss: 1.5110992949496034

Epoch: 5| Step: 7
Training loss: 0.2102547138929367
Validation loss: 1.5239769207533969

Epoch: 5| Step: 8
Training loss: 0.12555330991744995
Validation loss: 1.5132234801528275

Epoch: 5| Step: 9
Training loss: 0.1863577663898468
Validation loss: 1.5541295159247615

Epoch: 5| Step: 10
Training loss: 0.13810229301452637
Validation loss: 1.543713733714114

Epoch: 478| Step: 0
Training loss: 0.12089023739099503
Validation loss: 1.516522765159607

Epoch: 5| Step: 1
Training loss: 0.18269488215446472
Validation loss: 1.510624885559082

Epoch: 5| Step: 2
Training loss: 0.1592077612876892
Validation loss: 1.528987637130163

Epoch: 5| Step: 3
Training loss: 0.09744983911514282
Validation loss: 1.497361235721137

Epoch: 5| Step: 4
Training loss: 0.14815063774585724
Validation loss: 1.5040709382744246

Epoch: 5| Step: 5
Training loss: 0.19909772276878357
Validation loss: 1.5134381171195739

Epoch: 5| Step: 6
Training loss: 0.2147250920534134
Validation loss: 1.4691355465560831

Epoch: 5| Step: 7
Training loss: 0.2012077271938324
Validation loss: 1.488235850487986

Epoch: 5| Step: 8
Training loss: 0.12813158333301544
Validation loss: 1.5159809832931848

Epoch: 5| Step: 9
Training loss: 0.15524891018867493
Validation loss: 1.5025917407005065

Epoch: 5| Step: 10
Training loss: 0.16115280985832214
Validation loss: 1.5182073552121398

Epoch: 479| Step: 0
Training loss: 0.15668341517448425
Validation loss: 1.5198766967301727

Epoch: 5| Step: 1
Training loss: 0.22183772921562195
Validation loss: 1.5417547969407932

Epoch: 5| Step: 2
Training loss: 0.14973923563957214
Validation loss: 1.5694973622598956

Epoch: 5| Step: 3
Training loss: 0.16331008076667786
Validation loss: 1.5623684378080471

Epoch: 5| Step: 4
Training loss: 0.09325070679187775
Validation loss: 1.5349226920835433

Epoch: 5| Step: 5
Training loss: 0.1564141809940338
Validation loss: 1.527221110559279

Epoch: 5| Step: 6
Training loss: 0.1762818992137909
Validation loss: 1.5571660200754802

Epoch: 5| Step: 7
Training loss: 0.14204099774360657
Validation loss: 1.4957340276369484

Epoch: 5| Step: 8
Training loss: 0.1622919738292694
Validation loss: 1.5433893742099885

Epoch: 5| Step: 9
Training loss: 0.13720442354679108
Validation loss: 1.521629269405078

Epoch: 5| Step: 10
Training loss: 0.18957269191741943
Validation loss: 1.5142226026904198

Epoch: 480| Step: 0
Training loss: 0.10334987938404083
Validation loss: 1.5031146977537422

Epoch: 5| Step: 1
Training loss: 0.18386392295360565
Validation loss: 1.5031827701035367

Epoch: 5| Step: 2
Training loss: 0.09890874475240707
Validation loss: 1.5118969948061052

Epoch: 5| Step: 3
Training loss: 0.13172554969787598
Validation loss: 1.537353975798494

Epoch: 5| Step: 4
Training loss: 0.18200060725212097
Validation loss: 1.5048720926366828

Epoch: 5| Step: 5
Training loss: 0.20276181399822235
Validation loss: 1.5203049349528488

Epoch: 5| Step: 6
Training loss: 0.20531690120697021
Validation loss: 1.5517250235362718

Epoch: 5| Step: 7
Training loss: 0.135491281747818
Validation loss: 1.5151498138263662

Epoch: 5| Step: 8
Training loss: 0.13609081506729126
Validation loss: 1.5070612533118135

Epoch: 5| Step: 9
Training loss: 0.09889570623636246
Validation loss: 1.5415298990024033

Epoch: 5| Step: 10
Training loss: 0.12869228422641754
Validation loss: 1.5114801340205695

Epoch: 481| Step: 0
Training loss: 0.18893173336982727
Validation loss: 1.4945834798197593

Epoch: 5| Step: 1
Training loss: 0.1435992419719696
Validation loss: 1.4778093484140211

Epoch: 5| Step: 2
Training loss: 0.1720046103000641
Validation loss: 1.501264650334594

Epoch: 5| Step: 3
Training loss: 0.20304858684539795
Validation loss: 1.4815043621165778

Epoch: 5| Step: 4
Training loss: 0.10083656013011932
Validation loss: 1.5051678880568473

Epoch: 5| Step: 5
Training loss: 0.13480082154273987
Validation loss: 1.4970334909295524

Epoch: 5| Step: 6
Training loss: 0.07417158037424088
Validation loss: 1.4775643182057205

Epoch: 5| Step: 7
Training loss: 0.1690266728401184
Validation loss: 1.5062370274656562

Epoch: 5| Step: 8
Training loss: 0.12944045662879944
Validation loss: 1.4741966775668565

Epoch: 5| Step: 9
Training loss: 0.10939142853021622
Validation loss: 1.5240176172666653

Epoch: 5| Step: 10
Training loss: 0.15566766262054443
Validation loss: 1.5058936790753437

Epoch: 482| Step: 0
Training loss: 0.07562735676765442
Validation loss: 1.4973260330897507

Epoch: 5| Step: 1
Training loss: 0.08289063721895218
Validation loss: 1.5049045098725187

Epoch: 5| Step: 2
Training loss: 0.14816734194755554
Validation loss: 1.5181136438923497

Epoch: 5| Step: 3
Training loss: 0.14321540296077728
Validation loss: 1.5149923255366664

Epoch: 5| Step: 4
Training loss: 0.11808246374130249
Validation loss: 1.5250205852652108

Epoch: 5| Step: 5
Training loss: 0.18171723186969757
Validation loss: 1.5518728584371588

Epoch: 5| Step: 6
Training loss: 0.1274975687265396
Validation loss: 1.5557569393547632

Epoch: 5| Step: 7
Training loss: 0.1384863555431366
Validation loss: 1.5589507241402902

Epoch: 5| Step: 8
Training loss: 0.20940537750720978
Validation loss: 1.5328900109055221

Epoch: 5| Step: 9
Training loss: 0.15199963748455048
Validation loss: 1.5283471768902195

Epoch: 5| Step: 10
Training loss: 0.17537224292755127
Validation loss: 1.5091014613387406

Epoch: 483| Step: 0
Training loss: 0.1261415034532547
Validation loss: 1.54029429599803

Epoch: 5| Step: 1
Training loss: 0.08539237827062607
Validation loss: 1.527627315572513

Epoch: 5| Step: 2
Training loss: 0.15342453122138977
Validation loss: 1.5112908860688568

Epoch: 5| Step: 3
Training loss: 0.15970785915851593
Validation loss: 1.530378694175392

Epoch: 5| Step: 4
Training loss: 0.11618240922689438
Validation loss: 1.505870262781779

Epoch: 5| Step: 5
Training loss: 0.2021125853061676
Validation loss: 1.520857023936446

Epoch: 5| Step: 6
Training loss: 0.13847574591636658
Validation loss: 1.5006591184164888

Epoch: 5| Step: 7
Training loss: 0.11742456257343292
Validation loss: 1.4916438774396015

Epoch: 5| Step: 8
Training loss: 0.15880019962787628
Validation loss: 1.5271798128722816

Epoch: 5| Step: 9
Training loss: 0.15232166647911072
Validation loss: 1.522048181103122

Epoch: 5| Step: 10
Training loss: 0.15040279924869537
Validation loss: 1.5404506268039826

Epoch: 484| Step: 0
Training loss: 0.1332811415195465
Validation loss: 1.5149426011629001

Epoch: 5| Step: 1
Training loss: 0.20872917771339417
Validation loss: 1.5261933213921004

Epoch: 5| Step: 2
Training loss: 0.1396133005619049
Validation loss: 1.5224477078325005

Epoch: 5| Step: 3
Training loss: 0.07762609422206879
Validation loss: 1.5386756479099233

Epoch: 5| Step: 4
Training loss: 0.2065598964691162
Validation loss: 1.5263092921626182

Epoch: 5| Step: 5
Training loss: 0.1276843100786209
Validation loss: 1.5311363986743394

Epoch: 5| Step: 6
Training loss: 0.19851233065128326
Validation loss: 1.5023508071899414

Epoch: 5| Step: 7
Training loss: 0.12403180450201035
Validation loss: 1.4957079131116149

Epoch: 5| Step: 8
Training loss: 0.11156018078327179
Validation loss: 1.4793363014856975

Epoch: 5| Step: 9
Training loss: 0.11552280187606812
Validation loss: 1.5316588776085966

Epoch: 5| Step: 10
Training loss: 0.1706409752368927
Validation loss: 1.4837698064824587

Epoch: 485| Step: 0
Training loss: 0.15507586300373077
Validation loss: 1.508997712084042

Epoch: 5| Step: 1
Training loss: 0.11921465396881104
Validation loss: 1.5050083091182094

Epoch: 5| Step: 2
Training loss: 0.17058065533638
Validation loss: 1.517666116196622

Epoch: 5| Step: 3
Training loss: 0.13697674870491028
Validation loss: 1.5099110398241269

Epoch: 5| Step: 4
Training loss: 0.1446259319782257
Validation loss: 1.5326596254943519

Epoch: 5| Step: 5
Training loss: 0.12256404012441635
Validation loss: 1.5044214533221336

Epoch: 5| Step: 6
Training loss: 0.08743777871131897
Validation loss: 1.5195507721234394

Epoch: 5| Step: 7
Training loss: 0.19142882525920868
Validation loss: 1.5169718489852002

Epoch: 5| Step: 8
Training loss: 0.13870754837989807
Validation loss: 1.5002278051068705

Epoch: 5| Step: 9
Training loss: 0.11579453945159912
Validation loss: 1.5160972866960751

Epoch: 5| Step: 10
Training loss: 0.14451079070568085
Validation loss: 1.4729632933934529

Epoch: 486| Step: 0
Training loss: 0.11234106868505478
Validation loss: 1.5115448069828812

Epoch: 5| Step: 1
Training loss: 0.1347309947013855
Validation loss: 1.4946353948244484

Epoch: 5| Step: 2
Training loss: 0.08801142126321793
Validation loss: 1.5041517544818181

Epoch: 5| Step: 3
Training loss: 0.12466494739055634
Validation loss: 1.5048994928277948

Epoch: 5| Step: 4
Training loss: 0.16983720660209656
Validation loss: 1.5026249898377286

Epoch: 5| Step: 5
Training loss: 0.21650218963623047
Validation loss: 1.485179361476693

Epoch: 5| Step: 6
Training loss: 0.1956479847431183
Validation loss: 1.5095279883312922

Epoch: 5| Step: 7
Training loss: 0.2133512794971466
Validation loss: 1.508633844314083

Epoch: 5| Step: 8
Training loss: 0.12171826511621475
Validation loss: 1.4970657748560752

Epoch: 5| Step: 9
Training loss: 0.21688933670520782
Validation loss: 1.4970155800542524

Epoch: 5| Step: 10
Training loss: 0.1562224179506302
Validation loss: 1.4780135667452248

Epoch: 487| Step: 0
Training loss: 0.15545013546943665
Validation loss: 1.462392476297194

Epoch: 5| Step: 1
Training loss: 0.16583049297332764
Validation loss: 1.4862169296510759

Epoch: 5| Step: 2
Training loss: 0.13283047080039978
Validation loss: 1.5017933345610095

Epoch: 5| Step: 3
Training loss: 0.1447170525789261
Validation loss: 1.5075085291298487

Epoch: 5| Step: 4
Training loss: 0.16124682128429413
Validation loss: 1.5258240161403533

Epoch: 5| Step: 5
Training loss: 0.09548090398311615
Validation loss: 1.5182783719032042

Epoch: 5| Step: 6
Training loss: 0.13221076130867004
Validation loss: 1.519571263303039

Epoch: 5| Step: 7
Training loss: 0.14313772320747375
Validation loss: 1.5373848445953862

Epoch: 5| Step: 8
Training loss: 0.21386203169822693
Validation loss: 1.5412842060929985

Epoch: 5| Step: 9
Training loss: 0.15509286522865295
Validation loss: 1.5325821984198786

Epoch: 5| Step: 10
Training loss: 0.17574508488178253
Validation loss: 1.5504117729843303

Epoch: 488| Step: 0
Training loss: 0.14016078412532806
Validation loss: 1.537456089450467

Epoch: 5| Step: 1
Training loss: 0.09966305643320084
Validation loss: 1.5065639852195658

Epoch: 5| Step: 2
Training loss: 0.16305406391620636
Validation loss: 1.5126022010721185

Epoch: 5| Step: 3
Training loss: 0.2040172517299652
Validation loss: 1.490428965578797

Epoch: 5| Step: 4
Training loss: 0.08184360712766647
Validation loss: 1.5056615362885177

Epoch: 5| Step: 5
Training loss: 0.09165839850902557
Validation loss: 1.5043335903075434

Epoch: 5| Step: 6
Training loss: 0.1347436010837555
Validation loss: 1.4737417588951767

Epoch: 5| Step: 7
Training loss: 0.13538920879364014
Validation loss: 1.506897731493878

Epoch: 5| Step: 8
Training loss: 0.17624971270561218
Validation loss: 1.5154123024273944

Epoch: 5| Step: 9
Training loss: 0.15477517247200012
Validation loss: 1.4695853533283356

Epoch: 5| Step: 10
Training loss: 0.12291739881038666
Validation loss: 1.4767457887690554

Epoch: 489| Step: 0
Training loss: 0.15356647968292236
Validation loss: 1.4891186362953597

Epoch: 5| Step: 1
Training loss: 0.07684781402349472
Validation loss: 1.508869383924751

Epoch: 5| Step: 2
Training loss: 0.1523100584745407
Validation loss: 1.5020894414635115

Epoch: 5| Step: 3
Training loss: 0.1785154640674591
Validation loss: 1.514474855956211

Epoch: 5| Step: 4
Training loss: 0.18454958498477936
Validation loss: 1.5165618074837552

Epoch: 5| Step: 5
Training loss: 0.10080172121524811
Validation loss: 1.5161910108340684

Epoch: 5| Step: 6
Training loss: 0.1424318253993988
Validation loss: 1.5346340210207048

Epoch: 5| Step: 7
Training loss: 0.1606403887271881
Validation loss: 1.5063872926978654

Epoch: 5| Step: 8
Training loss: 0.08562414348125458
Validation loss: 1.5199702702542788

Epoch: 5| Step: 9
Training loss: 0.14075034856796265
Validation loss: 1.5058547296831686

Epoch: 5| Step: 10
Training loss: 0.19128914177417755
Validation loss: 1.4905631772933468

Epoch: 490| Step: 0
Training loss: 0.0899115726351738
Validation loss: 1.5062903345272105

Epoch: 5| Step: 1
Training loss: 0.11401695013046265
Validation loss: 1.540162795333452

Epoch: 5| Step: 2
Training loss: 0.13018304109573364
Validation loss: 1.529237307528014

Epoch: 5| Step: 3
Training loss: 0.16050787270069122
Validation loss: 1.5489065826580088

Epoch: 5| Step: 4
Training loss: 0.12799252569675446
Validation loss: 1.5245155852328065

Epoch: 5| Step: 5
Training loss: 0.17869725823402405
Validation loss: 1.5103403829759168

Epoch: 5| Step: 6
Training loss: 0.10276772826910019
Validation loss: 1.5265763498121692

Epoch: 5| Step: 7
Training loss: 0.10582494735717773
Validation loss: 1.5120402254084104

Epoch: 5| Step: 8
Training loss: 0.1066991314291954
Validation loss: 1.5183376458383375

Epoch: 5| Step: 9
Training loss: 0.15657338500022888
Validation loss: 1.5225073137590963

Epoch: 5| Step: 10
Training loss: 0.1580514758825302
Validation loss: 1.5010688227991904

Epoch: 491| Step: 0
Training loss: 0.08721782267093658
Validation loss: 1.5107524933353547

Epoch: 5| Step: 1
Training loss: 0.16548223793506622
Validation loss: 1.5074155997204524

Epoch: 5| Step: 2
Training loss: 0.07397085428237915
Validation loss: 1.4875337949363134

Epoch: 5| Step: 3
Training loss: 0.17228837311267853
Validation loss: 1.4744348397818945

Epoch: 5| Step: 4
Training loss: 0.09957688301801682
Validation loss: 1.4866325432254421

Epoch: 5| Step: 5
Training loss: 0.06228993088006973
Validation loss: 1.4821817195543678

Epoch: 5| Step: 6
Training loss: 0.09273330122232437
Validation loss: 1.4986927727217316

Epoch: 5| Step: 7
Training loss: 0.16087178885936737
Validation loss: 1.4462438635928656

Epoch: 5| Step: 8
Training loss: 0.1637507528066635
Validation loss: 1.4894443122289514

Epoch: 5| Step: 9
Training loss: 0.16915924847126007
Validation loss: 1.4679321871008923

Epoch: 5| Step: 10
Training loss: 0.17992612719535828
Validation loss: 1.4632828568899503

Epoch: 492| Step: 0
Training loss: 0.14378541707992554
Validation loss: 1.4916174591228526

Epoch: 5| Step: 1
Training loss: 0.15930916368961334
Validation loss: 1.5135163235408005

Epoch: 5| Step: 2
Training loss: 0.12800106406211853
Validation loss: 1.5179723796024118

Epoch: 5| Step: 3
Training loss: 0.11819746345281601
Validation loss: 1.4975001408207802

Epoch: 5| Step: 4
Training loss: 0.1323699653148651
Validation loss: 1.466094281083794

Epoch: 5| Step: 5
Training loss: 0.13565602898597717
Validation loss: 1.478091206601871

Epoch: 5| Step: 6
Training loss: 0.09884312748908997
Validation loss: 1.4696371613010284

Epoch: 5| Step: 7
Training loss: 0.08640927076339722
Validation loss: 1.465931979558801

Epoch: 5| Step: 8
Training loss: 0.17595727741718292
Validation loss: 1.4788488764916696

Epoch: 5| Step: 9
Training loss: 0.19536642730236053
Validation loss: 1.4560385243867033

Epoch: 5| Step: 10
Training loss: 0.10980720818042755
Validation loss: 1.4809239859222083

Epoch: 493| Step: 0
Training loss: 0.16102972626686096
Validation loss: 1.4629881112806258

Epoch: 5| Step: 1
Training loss: 0.14006322622299194
Validation loss: 1.4463595715902184

Epoch: 5| Step: 2
Training loss: 0.1478883922100067
Validation loss: 1.453806620772167

Epoch: 5| Step: 3
Training loss: 0.10313626378774643
Validation loss: 1.4526715047897831

Epoch: 5| Step: 4
Training loss: 0.10249669849872589
Validation loss: 1.4792223066411994

Epoch: 5| Step: 5
Training loss: 0.10086612403392792
Validation loss: 1.4737963990498615

Epoch: 5| Step: 6
Training loss: 0.14255283772945404
Validation loss: 1.4524744338886713

Epoch: 5| Step: 7
Training loss: 0.1668718010187149
Validation loss: 1.482937975596356

Epoch: 5| Step: 8
Training loss: 0.12169788777828217
Validation loss: 1.4501101124671198

Epoch: 5| Step: 9
Training loss: 0.08920358121395111
Validation loss: 1.4720320227325603

Epoch: 5| Step: 10
Training loss: 0.22235095500946045
Validation loss: 1.4892901169356478

Epoch: 494| Step: 0
Training loss: 0.15092554688453674
Validation loss: 1.4856512149175007

Epoch: 5| Step: 1
Training loss: 0.12772135436534882
Validation loss: 1.498889664167999

Epoch: 5| Step: 2
Training loss: 0.22241370379924774
Validation loss: 1.4840735338067497

Epoch: 5| Step: 3
Training loss: 0.18645986914634705
Validation loss: 1.4818134692407423

Epoch: 5| Step: 4
Training loss: 0.07679513841867447
Validation loss: 1.4692462317405208

Epoch: 5| Step: 5
Training loss: 0.1143091693520546
Validation loss: 1.484861045755366

Epoch: 5| Step: 6
Training loss: 0.13380101323127747
Validation loss: 1.4624331625558997

Epoch: 5| Step: 7
Training loss: 0.0528927817940712
Validation loss: 1.5137243322146836

Epoch: 5| Step: 8
Training loss: 0.1427292674779892
Validation loss: 1.5053692658742268

Epoch: 5| Step: 9
Training loss: 0.1384129822254181
Validation loss: 1.489035608947918

Epoch: 5| Step: 10
Training loss: 0.1030617207288742
Validation loss: 1.4723627580109464

Epoch: 495| Step: 0
Training loss: 0.07491786777973175
Validation loss: 1.4918655701862868

Epoch: 5| Step: 1
Training loss: 0.10840380191802979
Validation loss: 1.4998248706581772

Epoch: 5| Step: 2
Training loss: 0.10361919552087784
Validation loss: 1.4786272407859884

Epoch: 5| Step: 3
Training loss: 0.12522056698799133
Validation loss: 1.4931897194154802

Epoch: 5| Step: 4
Training loss: 0.12277434766292572
Validation loss: 1.4795083076723161

Epoch: 5| Step: 5
Training loss: 0.14762017130851746
Validation loss: 1.4834398825963337

Epoch: 5| Step: 6
Training loss: 0.16313618421554565
Validation loss: 1.5016417330311191

Epoch: 5| Step: 7
Training loss: 0.1726371943950653
Validation loss: 1.515171298416712

Epoch: 5| Step: 8
Training loss: 0.12619924545288086
Validation loss: 1.5050207620025964

Epoch: 5| Step: 9
Training loss: 0.15962204337120056
Validation loss: 1.496785431779841

Epoch: 5| Step: 10
Training loss: 0.15256594121456146
Validation loss: 1.5039641664874168

Epoch: 496| Step: 0
Training loss: 0.2054661214351654
Validation loss: 1.4825909919636224

Epoch: 5| Step: 1
Training loss: 0.14706872403621674
Validation loss: 1.4753459448455482

Epoch: 5| Step: 2
Training loss: 0.13674631714820862
Validation loss: 1.4807129585614769

Epoch: 5| Step: 3
Training loss: 0.11080269515514374
Validation loss: 1.4817880122892317

Epoch: 5| Step: 4
Training loss: 0.17981141805648804
Validation loss: 1.4803309312430761

Epoch: 5| Step: 5
Training loss: 0.17614340782165527
Validation loss: 1.4892707153033184

Epoch: 5| Step: 6
Training loss: 0.08741623163223267
Validation loss: 1.4618620205950994

Epoch: 5| Step: 7
Training loss: 0.11055950820446014
Validation loss: 1.4792073894572515

Epoch: 5| Step: 8
Training loss: 0.11978564411401749
Validation loss: 1.4813809241017988

Epoch: 5| Step: 9
Training loss: 0.1028372272849083
Validation loss: 1.4902098050681494

Epoch: 5| Step: 10
Training loss: 0.11865604668855667
Validation loss: 1.485022569215426

Epoch: 497| Step: 0
Training loss: 0.09062109142541885
Validation loss: 1.5034582743080713

Epoch: 5| Step: 1
Training loss: 0.17285005748271942
Validation loss: 1.544628385574587

Epoch: 5| Step: 2
Training loss: 0.1871514618396759
Validation loss: 1.5498784049864738

Epoch: 5| Step: 3
Training loss: 0.17607367038726807
Validation loss: 1.5264561176300049

Epoch: 5| Step: 4
Training loss: 0.14606408774852753
Validation loss: 1.507592515278888

Epoch: 5| Step: 5
Training loss: 0.08687879890203476
Validation loss: 1.445308582757109

Epoch: 5| Step: 6
Training loss: 0.1568969041109085
Validation loss: 1.5095353908436273

Epoch: 5| Step: 7
Training loss: 0.11595692485570908
Validation loss: 1.4891594148451281

Epoch: 5| Step: 8
Training loss: 0.18483830988407135
Validation loss: 1.4654183900484474

Epoch: 5| Step: 9
Training loss: 0.1566370129585266
Validation loss: 1.474446867101936

Epoch: 5| Step: 10
Training loss: 0.14235155284404755
Validation loss: 1.5060058896259596

Epoch: 498| Step: 0
Training loss: 0.11079631745815277
Validation loss: 1.4846160963017454

Epoch: 5| Step: 1
Training loss: 0.1812519133090973
Validation loss: 1.4944468595648324

Epoch: 5| Step: 2
Training loss: 0.15725061297416687
Validation loss: 1.4833691555966613

Epoch: 5| Step: 3
Training loss: 0.1286911964416504
Validation loss: 1.4846411840890044

Epoch: 5| Step: 4
Training loss: 0.10221345722675323
Validation loss: 1.477222845118533

Epoch: 5| Step: 5
Training loss: 0.15270695090293884
Validation loss: 1.4612496373473958

Epoch: 5| Step: 6
Training loss: 0.12884503602981567
Validation loss: 1.4490861700427147

Epoch: 5| Step: 7
Training loss: 0.1639142483472824
Validation loss: 1.4567162054841236

Epoch: 5| Step: 8
Training loss: 0.14799240231513977
Validation loss: 1.4721899776048557

Epoch: 5| Step: 9
Training loss: 0.15106722712516785
Validation loss: 1.462528553060306

Epoch: 5| Step: 10
Training loss: 0.0904221385717392
Validation loss: 1.475076998433759

Epoch: 499| Step: 0
Training loss: 0.10470469295978546
Validation loss: 1.4972506274459183

Epoch: 5| Step: 1
Training loss: 0.18231630325317383
Validation loss: 1.5029699904944307

Epoch: 5| Step: 2
Training loss: 0.10858267545700073
Validation loss: 1.5173244822409846

Epoch: 5| Step: 3
Training loss: 0.07669152319431305
Validation loss: 1.5168827182503157

Epoch: 5| Step: 4
Training loss: 0.1701897382736206
Validation loss: 1.4985135691140288

Epoch: 5| Step: 5
Training loss: 0.10919170081615448
Validation loss: 1.5135807161049177

Epoch: 5| Step: 6
Training loss: 0.17777135968208313
Validation loss: 1.5147756940575057

Epoch: 5| Step: 7
Training loss: 0.1720397174358368
Validation loss: 1.4960128690606804

Epoch: 5| Step: 8
Training loss: 0.2401973307132721
Validation loss: 1.5363902686744608

Epoch: 5| Step: 9
Training loss: 0.15561246871948242
Validation loss: 1.5033656268991449

Epoch: 5| Step: 10
Training loss: 0.2790522277355194
Validation loss: 1.525880099624716

Epoch: 500| Step: 0
Training loss: 0.1324690282344818
Validation loss: 1.4880678551171416

Epoch: 5| Step: 1
Training loss: 0.1251058727502823
Validation loss: 1.5148432793155793

Epoch: 5| Step: 2
Training loss: 0.15598151087760925
Validation loss: 1.5086556621777114

Epoch: 5| Step: 3
Training loss: 0.13329964876174927
Validation loss: 1.4955585515627297

Epoch: 5| Step: 4
Training loss: 0.1852053850889206
Validation loss: 1.5207480974094842

Epoch: 5| Step: 5
Training loss: 0.11258131265640259
Validation loss: 1.4877832012791787

Epoch: 5| Step: 6
Training loss: 0.18125346302986145
Validation loss: 1.486650775837642

Epoch: 5| Step: 7
Training loss: 0.16607607901096344
Validation loss: 1.5144433334309568

Epoch: 5| Step: 8
Training loss: 0.08878844976425171
Validation loss: 1.4928190887615245

Epoch: 5| Step: 9
Training loss: 0.12429438531398773
Validation loss: 1.5026328038143855

Epoch: 5| Step: 10
Training loss: 0.1172146201133728
Validation loss: 1.5240791702783236

Testing loss: 1.9776811599731445
