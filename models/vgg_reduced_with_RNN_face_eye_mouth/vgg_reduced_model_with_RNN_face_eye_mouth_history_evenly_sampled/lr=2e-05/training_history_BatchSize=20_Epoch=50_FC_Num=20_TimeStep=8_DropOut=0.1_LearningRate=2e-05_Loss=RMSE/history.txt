Epoch: 1| Step: 0
Training loss: 6.609865860263264
Validation loss: 5.813981087050833

Epoch: 5| Step: 1
Training loss: 5.760834810372741
Validation loss: 5.795898089836627

Epoch: 5| Step: 2
Training loss: 4.713117458862051
Validation loss: 5.78090906576313

Epoch: 5| Step: 3
Training loss: 6.548907344622251
Validation loss: 5.765770406862848

Epoch: 5| Step: 4
Training loss: 5.67692135454366
Validation loss: 5.748338968586895

Epoch: 5| Step: 5
Training loss: 5.689181907048181
Validation loss: 5.727965908312749

Epoch: 5| Step: 6
Training loss: 5.409721891408357
Validation loss: 5.70426413003831

Epoch: 5| Step: 7
Training loss: 4.778979990516372
Validation loss: 5.678061985071173

Epoch: 5| Step: 8
Training loss: 5.566220700032449
Validation loss: 5.6472263797912525

Epoch: 5| Step: 9
Training loss: 6.233587765048355
Validation loss: 5.613611267944514

Epoch: 5| Step: 10
Training loss: 5.976472821528984
Validation loss: 5.576861857033648

Epoch: 2| Step: 0
Training loss: 5.269758192736371
Validation loss: 5.534115060831992

Epoch: 5| Step: 1
Training loss: 5.144498067530135
Validation loss: 5.4893772313594775

Epoch: 5| Step: 2
Training loss: 5.8037923582175726
Validation loss: 5.44036253537267

Epoch: 5| Step: 3
Training loss: 5.037154245934788
Validation loss: 5.3879206554071

Epoch: 5| Step: 4
Training loss: 4.173491318447452
Validation loss: 5.334242017819369

Epoch: 5| Step: 5
Training loss: 6.059362799251996
Validation loss: 5.278906136865631

Epoch: 5| Step: 6
Training loss: 6.434713112246269
Validation loss: 5.220359394436095

Epoch: 5| Step: 7
Training loss: 5.093425342534305
Validation loss: 5.164460003050773

Epoch: 5| Step: 8
Training loss: 5.137198468569104
Validation loss: 5.107811987172721

Epoch: 5| Step: 9
Training loss: 4.732882122687598
Validation loss: 5.051717773581286

Epoch: 5| Step: 10
Training loss: 5.357152005142394
Validation loss: 4.992304844452603

Epoch: 3| Step: 0
Training loss: 3.985460200905347
Validation loss: 4.930193675883136

Epoch: 5| Step: 1
Training loss: 4.965847103080387
Validation loss: 4.876047687051994

Epoch: 5| Step: 2
Training loss: 3.994504252625495
Validation loss: 4.833156893645847

Epoch: 5| Step: 3
Training loss: 5.658078061592489
Validation loss: 4.793352426375694

Epoch: 5| Step: 4
Training loss: 5.160327385859161
Validation loss: 4.7526570451677

Epoch: 5| Step: 5
Training loss: 5.152658587388502
Validation loss: 4.706301226754713

Epoch: 5| Step: 6
Training loss: 5.044044858498574
Validation loss: 4.653006354953565

Epoch: 5| Step: 7
Training loss: 5.266506404289365
Validation loss: 4.60708720233184

Epoch: 5| Step: 8
Training loss: 4.8867359237308134
Validation loss: 4.573355284147005

Epoch: 5| Step: 9
Training loss: 3.9812468572152038
Validation loss: 4.544084311694336

Epoch: 5| Step: 10
Training loss: 4.285111071505802
Validation loss: 4.511471541042809

Epoch: 4| Step: 0
Training loss: 4.1467235638148425
Validation loss: 4.472226790871657

Epoch: 5| Step: 1
Training loss: 4.289652799414699
Validation loss: 4.434666071999081

Epoch: 5| Step: 2
Training loss: 4.571578934444577
Validation loss: 4.403789640048568

Epoch: 5| Step: 3
Training loss: 3.6323538541963014
Validation loss: 4.368916112797942

Epoch: 5| Step: 4
Training loss: 5.118609281848402
Validation loss: 4.350688174660169

Epoch: 5| Step: 5
Training loss: 3.476979982833578
Validation loss: 4.3137027370522265

Epoch: 5| Step: 6
Training loss: 5.297834731396075
Validation loss: 4.3019509692771845

Epoch: 5| Step: 7
Training loss: 5.3202370345579375
Validation loss: 4.28842674382209

Epoch: 5| Step: 8
Training loss: 4.731585697575494
Validation loss: 4.273140171382278

Epoch: 5| Step: 9
Training loss: 4.788022897714981
Validation loss: 4.25521750012418

Epoch: 5| Step: 10
Training loss: 2.6279210686232224
Validation loss: 4.236189641190427

Epoch: 5| Step: 0
Training loss: 4.719380923906401
Validation loss: 4.22015802425902

Epoch: 5| Step: 1
Training loss: 3.9627926787581678
Validation loss: 4.20652736550249

Epoch: 5| Step: 2
Training loss: 4.200746224732517
Validation loss: 4.191464152536966

Epoch: 5| Step: 3
Training loss: 4.320358193347311
Validation loss: 4.175588487248448

Epoch: 5| Step: 4
Training loss: 4.760913157987697
Validation loss: 4.1621285432403505

Epoch: 5| Step: 5
Training loss: 3.5962894920962514
Validation loss: 4.148542945380231

Epoch: 5| Step: 6
Training loss: 4.976582429807032
Validation loss: 4.1338185786351875

Epoch: 5| Step: 7
Training loss: 3.838916748161701
Validation loss: 4.114693948617388

Epoch: 5| Step: 8
Training loss: 4.529071994740746
Validation loss: 4.101367500384911

Epoch: 5| Step: 9
Training loss: 4.142389806687303
Validation loss: 4.096223148160292

Epoch: 5| Step: 10
Training loss: 3.8414109719359706
Validation loss: 4.0809245627760244

Epoch: 6| Step: 0
Training loss: 3.7770147643867515
Validation loss: 4.068502101986356

Epoch: 5| Step: 1
Training loss: 4.746276399841911
Validation loss: 4.071958784810147

Epoch: 5| Step: 2
Training loss: 4.560846316454267
Validation loss: 4.057651324017686

Epoch: 5| Step: 3
Training loss: 3.668534207861899
Validation loss: 4.041732616708969

Epoch: 5| Step: 4
Training loss: 4.2874901952158755
Validation loss: 4.0280106045920565

Epoch: 5| Step: 5
Training loss: 3.5989023177576285
Validation loss: 4.015870297604315

Epoch: 5| Step: 6
Training loss: 4.0075167124798945
Validation loss: 4.006406061253272

Epoch: 5| Step: 7
Training loss: 3.9160236615410056
Validation loss: 4.001314152424684

Epoch: 5| Step: 8
Training loss: 4.195057212975957
Validation loss: 3.989687395383959

Epoch: 5| Step: 9
Training loss: 3.8124937463927964
Validation loss: 3.975637790517305

Epoch: 5| Step: 10
Training loss: 5.174031617600693
Validation loss: 3.9638976429537394

Epoch: 7| Step: 0
Training loss: 3.7729616990641426
Validation loss: 3.953294368995194

Epoch: 5| Step: 1
Training loss: 3.858052880549173
Validation loss: 3.9431746753473176

Epoch: 5| Step: 2
Training loss: 4.056295498679481
Validation loss: 3.934099285248655

Epoch: 5| Step: 3
Training loss: 3.965015967626758
Validation loss: 3.926846705519283

Epoch: 5| Step: 4
Training loss: 4.308338091987229
Validation loss: 3.9184532402111474

Epoch: 5| Step: 5
Training loss: 5.005825654331899
Validation loss: 3.9074621538923022

Epoch: 5| Step: 6
Training loss: 3.363588183992889
Validation loss: 3.898524020421456

Epoch: 5| Step: 7
Training loss: 4.297057657694368
Validation loss: 3.89041616043474

Epoch: 5| Step: 8
Training loss: 3.058128194832629
Validation loss: 3.881121633238279

Epoch: 5| Step: 9
Training loss: 4.460263817686601
Validation loss: 3.8736849222838208

Epoch: 5| Step: 10
Training loss: 4.298742713755661
Validation loss: 3.86452279345986

Epoch: 8| Step: 0
Training loss: 4.713886305993703
Validation loss: 3.8582716579411884

Epoch: 5| Step: 1
Training loss: 3.7852247800813874
Validation loss: 3.8500605817742004

Epoch: 5| Step: 2
Training loss: 4.377838086155512
Validation loss: 3.8415629570008716

Epoch: 5| Step: 3
Training loss: 4.01772339613391
Validation loss: 3.8342528629153847

Epoch: 5| Step: 4
Training loss: 4.26526592825356
Validation loss: 3.8258404274873548

Epoch: 5| Step: 5
Training loss: 3.537813281957255
Validation loss: 3.8169597817501293

Epoch: 5| Step: 6
Training loss: 4.5689947853317445
Validation loss: 3.808329753955279

Epoch: 5| Step: 7
Training loss: 3.7516380547124872
Validation loss: 3.80259447267939

Epoch: 5| Step: 8
Training loss: 3.516503389614798
Validation loss: 3.7940326441111853

Epoch: 5| Step: 9
Training loss: 3.388865352680905
Validation loss: 3.78723617025236

Epoch: 5| Step: 10
Training loss: 3.7428169119366896
Validation loss: 3.780772518776804

Epoch: 9| Step: 0
Training loss: 3.4621318194473027
Validation loss: 3.7715162996812457

Epoch: 5| Step: 1
Training loss: 3.7998429617305867
Validation loss: 3.762830090286196

Epoch: 5| Step: 2
Training loss: 4.089708502718382
Validation loss: 3.7559814904247095

Epoch: 5| Step: 3
Training loss: 4.512544947688303
Validation loss: 3.748911469232578

Epoch: 5| Step: 4
Training loss: 3.612997639840857
Validation loss: 3.749272426998807

Epoch: 5| Step: 5
Training loss: 3.6643702656342674
Validation loss: 3.7364708995750435

Epoch: 5| Step: 6
Training loss: 4.208208944666681
Validation loss: 3.729055117814774

Epoch: 5| Step: 7
Training loss: 3.517079505974065
Validation loss: 3.717375658099964

Epoch: 5| Step: 8
Training loss: 3.513266760058442
Validation loss: 3.7059819153297298

Epoch: 5| Step: 9
Training loss: 4.020474011008324
Validation loss: 3.703423088568236

Epoch: 5| Step: 10
Training loss: 4.598104061334661
Validation loss: 3.689140777932531

Epoch: 10| Step: 0
Training loss: 3.4097716998420795
Validation loss: 3.680689561854726

Epoch: 5| Step: 1
Training loss: 4.261908061073693
Validation loss: 3.6741899337699637

Epoch: 5| Step: 2
Training loss: 3.5663095818378276
Validation loss: 3.6663445031007322

Epoch: 5| Step: 3
Training loss: 3.1454790096865084
Validation loss: 3.6543010147936017

Epoch: 5| Step: 4
Training loss: 3.825437139327452
Validation loss: 3.6425976469075487

Epoch: 5| Step: 5
Training loss: 4.7440497624069415
Validation loss: 3.63414688470172

Epoch: 5| Step: 6
Training loss: 3.933254556890738
Validation loss: 3.6259545161122366

Epoch: 5| Step: 7
Training loss: 3.4589357119582966
Validation loss: 3.6151203833305314

Epoch: 5| Step: 8
Training loss: 3.7991035106642213
Validation loss: 3.607298094854433

Epoch: 5| Step: 9
Training loss: 4.242611465203682
Validation loss: 3.5973340225620736

Epoch: 5| Step: 10
Training loss: 3.343928394728246
Validation loss: 3.590824710385516

Epoch: 11| Step: 0
Training loss: 4.370101366067729
Validation loss: 3.584993743726266

Epoch: 5| Step: 1
Training loss: 3.15803643460845
Validation loss: 3.5789224420523826

Epoch: 5| Step: 2
Training loss: 4.196445759561233
Validation loss: 3.5807542631849016

Epoch: 5| Step: 3
Training loss: 2.6018759965310534
Validation loss: 3.5599040021669937

Epoch: 5| Step: 4
Training loss: 3.559153675033901
Validation loss: 3.565389046417564

Epoch: 5| Step: 5
Training loss: 3.259912632666653
Validation loss: 3.562029761651375

Epoch: 5| Step: 6
Training loss: 4.123705805425764
Validation loss: 3.556449285326044

Epoch: 5| Step: 7
Training loss: 2.7802337332792395
Validation loss: 3.550185971412906

Epoch: 5| Step: 8
Training loss: 4.8031900693100775
Validation loss: 3.544201820254189

Epoch: 5| Step: 9
Training loss: 4.035954768446289
Validation loss: 3.532445624054287

Epoch: 5| Step: 10
Training loss: 3.8657291629606885
Validation loss: 3.521342281092633

Epoch: 12| Step: 0
Training loss: 3.6368229868503508
Validation loss: 3.51131664993936

Epoch: 5| Step: 1
Training loss: 3.375504773857166
Validation loss: 3.5056470239203583

Epoch: 5| Step: 2
Training loss: 3.1937048862204778
Validation loss: 3.501858570823257

Epoch: 5| Step: 3
Training loss: 3.124504355225051
Validation loss: 3.493643228112779

Epoch: 5| Step: 4
Training loss: 3.8653286252089063
Validation loss: 3.5118653927946495

Epoch: 5| Step: 5
Training loss: 4.494871395931901
Validation loss: 3.4841722381308107

Epoch: 5| Step: 6
Training loss: 3.3087548731244514
Validation loss: 3.5148177731692587

Epoch: 5| Step: 7
Training loss: 4.014213581144983
Validation loss: 3.4800225371169784

Epoch: 5| Step: 8
Training loss: 4.186771614152397
Validation loss: 3.4754243284294835

Epoch: 5| Step: 9
Training loss: 3.931702963443325
Validation loss: 3.486795173608851

Epoch: 5| Step: 10
Training loss: 3.318661124266056
Validation loss: 3.4786696412735543

Epoch: 13| Step: 0
Training loss: 3.763638174067461
Validation loss: 3.471597219322771

Epoch: 5| Step: 1
Training loss: 3.651681115733999
Validation loss: 3.465009718351008

Epoch: 5| Step: 2
Training loss: 3.8108270445359627
Validation loss: 3.463547559473004

Epoch: 5| Step: 3
Training loss: 4.119972864820878
Validation loss: 3.459030498197753

Epoch: 5| Step: 4
Training loss: 3.663206866797205
Validation loss: 3.453592270563168

Epoch: 5| Step: 5
Training loss: 2.757807831584664
Validation loss: 3.4388193799761475

Epoch: 5| Step: 6
Training loss: 3.245090591271165
Validation loss: 3.4317726906720676

Epoch: 5| Step: 7
Training loss: 4.086465425831188
Validation loss: 3.425825781779546

Epoch: 5| Step: 8
Training loss: 2.74470452321726
Validation loss: 3.4218519517863393

Epoch: 5| Step: 9
Training loss: 3.8514505799535086
Validation loss: 3.4208299081628417

Epoch: 5| Step: 10
Training loss: 4.309048141908167
Validation loss: 3.413761253185638

Epoch: 14| Step: 0
Training loss: 3.725642380593082
Validation loss: 3.4060081312519555

Epoch: 5| Step: 1
Training loss: 3.2461163718563433
Validation loss: 3.4023499663077796

Epoch: 5| Step: 2
Training loss: 3.7117363963252648
Validation loss: 3.397927625457923

Epoch: 5| Step: 3
Training loss: 3.643004200742626
Validation loss: 3.396599848728253

Epoch: 5| Step: 4
Training loss: 3.49301076312172
Validation loss: 3.3932243263208153

Epoch: 5| Step: 5
Training loss: 3.6987430705746545
Validation loss: 3.3965386743321173

Epoch: 5| Step: 6
Training loss: 3.230483805795478
Validation loss: 3.3898062872720893

Epoch: 5| Step: 7
Training loss: 3.7418370729878303
Validation loss: 3.3842235578683497

Epoch: 5| Step: 8
Training loss: 3.484823155342496
Validation loss: 3.381381485303609

Epoch: 5| Step: 9
Training loss: 3.4939951474571487
Validation loss: 3.3847132136374936

Epoch: 5| Step: 10
Training loss: 4.2895460846321045
Validation loss: 3.3819356620915824

Epoch: 15| Step: 0
Training loss: 3.48377677674503
Validation loss: 3.374144904230846

Epoch: 5| Step: 1
Training loss: 3.501228934200478
Validation loss: 3.369477707103127

Epoch: 5| Step: 2
Training loss: 2.7806080280865504
Validation loss: 3.3627224132365923

Epoch: 5| Step: 3
Training loss: 3.3651154907269047
Validation loss: 3.3613984417006204

Epoch: 5| Step: 4
Training loss: 3.8112082872769877
Validation loss: 3.3602451793345676

Epoch: 5| Step: 5
Training loss: 3.0186151889055695
Validation loss: 3.356756807799146

Epoch: 5| Step: 6
Training loss: 3.9747100292460775
Validation loss: 3.354809989729358

Epoch: 5| Step: 7
Training loss: 3.915181196168081
Validation loss: 3.3621911285760744

Epoch: 5| Step: 8
Training loss: 3.5172545322858357
Validation loss: 3.3470802502251895

Epoch: 5| Step: 9
Training loss: 4.200487408285268
Validation loss: 3.3491377299789717

Epoch: 5| Step: 10
Training loss: 3.680812007838534
Validation loss: 3.3544182188500944

Epoch: 16| Step: 0
Training loss: 4.039146083062888
Validation loss: 3.3517413462725663

Epoch: 5| Step: 1
Training loss: 3.3872348695721572
Validation loss: 3.3446626166283484

Epoch: 5| Step: 2
Training loss: 3.332702497552823
Validation loss: 3.3426482753060784

Epoch: 5| Step: 3
Training loss: 2.941796589720807
Validation loss: 3.331835861602651

Epoch: 5| Step: 4
Training loss: 3.948658104407178
Validation loss: 3.3369742618150484

Epoch: 5| Step: 5
Training loss: 3.665271421324754
Validation loss: 3.3269667465642203

Epoch: 5| Step: 6
Training loss: 3.410961287691188
Validation loss: 3.3230844823633534

Epoch: 5| Step: 7
Training loss: 3.7730020149361057
Validation loss: 3.317720722495966

Epoch: 5| Step: 8
Training loss: 3.64405523628052
Validation loss: 3.3143022788256347

Epoch: 5| Step: 9
Training loss: 3.555927839922286
Validation loss: 3.313344046506334

Epoch: 5| Step: 10
Training loss: 3.3546631881906075
Validation loss: 3.310188974784889

Epoch: 17| Step: 0
Training loss: 4.2297358137738685
Validation loss: 3.3098473781294118

Epoch: 5| Step: 1
Training loss: 4.107839319164068
Validation loss: 3.3042750482650156

Epoch: 5| Step: 2
Training loss: 2.995423004388483
Validation loss: 3.301367331190788

Epoch: 5| Step: 3
Training loss: 3.7163768216231587
Validation loss: 3.3006943356009524

Epoch: 5| Step: 4
Training loss: 3.095227129710689
Validation loss: 3.3027251286826975

Epoch: 5| Step: 5
Training loss: 3.311792694007808
Validation loss: 3.3052205228230602

Epoch: 5| Step: 6
Training loss: 3.983406338095867
Validation loss: 3.296195656899267

Epoch: 5| Step: 7
Training loss: 3.683178195591872
Validation loss: 3.290691250421448

Epoch: 5| Step: 8
Training loss: 3.5599996258167543
Validation loss: 3.2898828001242655

Epoch: 5| Step: 9
Training loss: 2.7049986238881556
Validation loss: 3.288364678452557

Epoch: 5| Step: 10
Training loss: 3.2046204588306946
Validation loss: 3.2949960760088572

Epoch: 18| Step: 0
Training loss: 3.194094250783114
Validation loss: 3.2955774956680193

Epoch: 5| Step: 1
Training loss: 3.7346906329085887
Validation loss: 3.269191607128105

Epoch: 5| Step: 2
Training loss: 4.0683068662598005
Validation loss: 3.2677238695712445

Epoch: 5| Step: 3
Training loss: 3.5930542645580905
Validation loss: 3.2645057031390485

Epoch: 5| Step: 4
Training loss: 3.4940803057782657
Validation loss: 3.2725787584971178

Epoch: 5| Step: 5
Training loss: 3.1907128989789943
Validation loss: 3.2668683738371898

Epoch: 5| Step: 6
Training loss: 3.608293643818298
Validation loss: 3.2711633004129776

Epoch: 5| Step: 7
Training loss: 3.515504555228457
Validation loss: 3.248081949138966

Epoch: 5| Step: 8
Training loss: 3.54006532856635
Validation loss: 3.3029546675300776

Epoch: 5| Step: 9
Training loss: 3.4542140710489866
Validation loss: 3.2542020264960803

Epoch: 5| Step: 10
Training loss: 3.084404750630249
Validation loss: 3.2352959128969223

Epoch: 19| Step: 0
Training loss: 3.6032176155567672
Validation loss: 3.2516962740943645

Epoch: 5| Step: 1
Training loss: 3.877243131077203
Validation loss: 3.276182332898949

Epoch: 5| Step: 2
Training loss: 3.65879772138215
Validation loss: 3.259729316003082

Epoch: 5| Step: 3
Training loss: 3.767303472606357
Validation loss: 3.244643453480242

Epoch: 5| Step: 4
Training loss: 3.285354082135946
Validation loss: 3.2447139672945755

Epoch: 5| Step: 5
Training loss: 3.574035973383324
Validation loss: 3.2506589860368194

Epoch: 5| Step: 6
Training loss: 4.139435910481333
Validation loss: 3.2504577117207902

Epoch: 5| Step: 7
Training loss: 2.679437653485525
Validation loss: 3.246426489576689

Epoch: 5| Step: 8
Training loss: 2.989712401117212
Validation loss: 3.239878479039488

Epoch: 5| Step: 9
Training loss: 3.5633195971612865
Validation loss: 3.235574626738596

Epoch: 5| Step: 10
Training loss: 3.0098716128016685
Validation loss: 3.2247506619133843

Epoch: 20| Step: 0
Training loss: 2.2814047773973165
Validation loss: 3.2234267449372154

Epoch: 5| Step: 1
Training loss: 3.658437482065351
Validation loss: 3.225241277365185

Epoch: 5| Step: 2
Training loss: 3.9583758435559977
Validation loss: 3.223853576719287

Epoch: 5| Step: 3
Training loss: 3.113129003001812
Validation loss: 3.221509065363346

Epoch: 5| Step: 4
Training loss: 4.000622224096102
Validation loss: 3.2179908291231945

Epoch: 5| Step: 5
Training loss: 3.7183640223635472
Validation loss: 3.215753596028867

Epoch: 5| Step: 6
Training loss: 3.3271422748603774
Validation loss: 3.2146748464636827

Epoch: 5| Step: 7
Training loss: 3.093219287704739
Validation loss: 3.2120578520810223

Epoch: 5| Step: 8
Training loss: 3.469664032252129
Validation loss: 3.210676115881377

Epoch: 5| Step: 9
Training loss: 3.8472100788266035
Validation loss: 3.207776586400894

Epoch: 5| Step: 10
Training loss: 3.3629236684729533
Validation loss: 3.2070202409025885

Epoch: 21| Step: 0
Training loss: 3.9953541001237896
Validation loss: 3.2043110634208394

Epoch: 5| Step: 1
Training loss: 3.3077937828835413
Validation loss: 3.2031798655415353

Epoch: 5| Step: 2
Training loss: 3.134747979895822
Validation loss: 3.2011613582937937

Epoch: 5| Step: 3
Training loss: 3.0168799126495958
Validation loss: 3.199456471126255

Epoch: 5| Step: 4
Training loss: 3.8900092070404377
Validation loss: 3.1984029655808985

Epoch: 5| Step: 5
Training loss: 3.5782409382656546
Validation loss: 3.196407116683888

Epoch: 5| Step: 6
Training loss: 3.461485533024357
Validation loss: 3.195002281866909

Epoch: 5| Step: 7
Training loss: 3.377739959708651
Validation loss: 3.194353813632271

Epoch: 5| Step: 8
Training loss: 4.026403781781012
Validation loss: 3.193194773526344

Epoch: 5| Step: 9
Training loss: 3.0268455046138825
Validation loss: 3.1928804843624237

Epoch: 5| Step: 10
Training loss: 2.9126406721598235
Validation loss: 3.191477318322609

Epoch: 22| Step: 0
Training loss: 4.279172072860636
Validation loss: 3.1890623706066106

Epoch: 5| Step: 1
Training loss: 3.039223634816826
Validation loss: 3.1873613520819037

Epoch: 5| Step: 2
Training loss: 3.4010235648187073
Validation loss: 3.1881031621452633

Epoch: 5| Step: 3
Training loss: 2.9920102856301156
Validation loss: 3.1871641731334583

Epoch: 5| Step: 4
Training loss: 4.065780254334718
Validation loss: 3.187367556557151

Epoch: 5| Step: 5
Training loss: 3.4518300385787213
Validation loss: 3.1924996443919875

Epoch: 5| Step: 6
Training loss: 3.1736660114847646
Validation loss: 3.1849945889914757

Epoch: 5| Step: 7
Training loss: 4.021786960447384
Validation loss: 3.180914368103154

Epoch: 5| Step: 8
Training loss: 2.9136064187852186
Validation loss: 3.1810120212948165

Epoch: 5| Step: 9
Training loss: 2.8760883095862293
Validation loss: 3.178325165209622

Epoch: 5| Step: 10
Training loss: 3.2843171816018675
Validation loss: 3.175952648180359

Epoch: 23| Step: 0
Training loss: 3.2027035319609674
Validation loss: 3.1755359116305164

Epoch: 5| Step: 1
Training loss: 4.050842225839888
Validation loss: 3.1747626070133776

Epoch: 5| Step: 2
Training loss: 3.3463404238328374
Validation loss: 3.174497570785442

Epoch: 5| Step: 3
Training loss: 3.7261366370922646
Validation loss: 3.172977452524087

Epoch: 5| Step: 4
Training loss: 2.8124636329842794
Validation loss: 3.1719538478163067

Epoch: 5| Step: 5
Training loss: 3.5537314669903717
Validation loss: 3.1694562301317633

Epoch: 5| Step: 6
Training loss: 3.5469842969548426
Validation loss: 3.1688652507407156

Epoch: 5| Step: 7
Training loss: 3.388175536642405
Validation loss: 3.168799051266498

Epoch: 5| Step: 8
Training loss: 3.263608903351571
Validation loss: 3.166932916269521

Epoch: 5| Step: 9
Training loss: 3.3373400131912634
Validation loss: 3.1663639904071834

Epoch: 5| Step: 10
Training loss: 3.399287395972138
Validation loss: 3.1651202286410043

Epoch: 24| Step: 0
Training loss: 2.9890663860832194
Validation loss: 3.1645634218077063

Epoch: 5| Step: 1
Training loss: 3.690713419811971
Validation loss: 3.1638106083437436

Epoch: 5| Step: 2
Training loss: 3.1657062546449635
Validation loss: 3.1627168119903852

Epoch: 5| Step: 3
Training loss: 3.415103011804738
Validation loss: 3.162012288505212

Epoch: 5| Step: 4
Training loss: 3.6553171386063155
Validation loss: 3.161667180012296

Epoch: 5| Step: 5
Training loss: 3.7207587450731183
Validation loss: 3.170614219400379

Epoch: 5| Step: 6
Training loss: 2.251369165701124
Validation loss: 3.163935878483144

Epoch: 5| Step: 7
Training loss: 3.3005245312058067
Validation loss: 3.1589759248822302

Epoch: 5| Step: 8
Training loss: 4.3316151562737595
Validation loss: 3.1588283385220546

Epoch: 5| Step: 9
Training loss: 3.0634698694439955
Validation loss: 3.1580090416804136

Epoch: 5| Step: 10
Training loss: 3.6978935276794034
Validation loss: 3.1571727221429637

Epoch: 25| Step: 0
Training loss: 3.547479653599185
Validation loss: 3.157536788039041

Epoch: 5| Step: 1
Training loss: 2.667105896857354
Validation loss: 3.1560916119722

Epoch: 5| Step: 2
Training loss: 3.417340623087506
Validation loss: 3.1560839943698458

Epoch: 5| Step: 3
Training loss: 2.9269311578003405
Validation loss: 3.154372275751136

Epoch: 5| Step: 4
Training loss: 3.151541947093059
Validation loss: 3.1540416138153273

Epoch: 5| Step: 5
Training loss: 3.5462545112632267
Validation loss: 3.1526408419110097

Epoch: 5| Step: 6
Training loss: 4.099306252565102
Validation loss: 3.1533894148802126

Epoch: 5| Step: 7
Training loss: 3.471326953335794
Validation loss: 3.153189430239954

Epoch: 5| Step: 8
Training loss: 3.6595177027293304
Validation loss: 3.150179185278027

Epoch: 5| Step: 9
Training loss: 3.5245796602305695
Validation loss: 3.1470746190564194

Epoch: 5| Step: 10
Training loss: 3.347594715741345
Validation loss: 3.1466656905051598

Epoch: 26| Step: 0
Training loss: 3.729529521202899
Validation loss: 3.1458333466438915

Epoch: 5| Step: 1
Training loss: 3.5899199933245978
Validation loss: 3.1424755296710445

Epoch: 5| Step: 2
Training loss: 3.2964592983441565
Validation loss: 3.1422827707458616

Epoch: 5| Step: 3
Training loss: 3.865824757921647
Validation loss: 3.1405172764729046

Epoch: 5| Step: 4
Training loss: 3.3871053543216534
Validation loss: 3.141493286530194

Epoch: 5| Step: 5
Training loss: 3.156038182770988
Validation loss: 3.1392145550254935

Epoch: 5| Step: 6
Training loss: 3.5016648556321655
Validation loss: 3.138978042543984

Epoch: 5| Step: 7
Training loss: 3.6627127107166237
Validation loss: 3.1408506396147824

Epoch: 5| Step: 8
Training loss: 2.823958051159229
Validation loss: 3.1404558320988247

Epoch: 5| Step: 9
Training loss: 3.208521767239108
Validation loss: 3.1358804967119123

Epoch: 5| Step: 10
Training loss: 3.041848286122859
Validation loss: 3.13818709710358

Epoch: 27| Step: 0
Training loss: 3.886597413895944
Validation loss: 3.1353151921422615

Epoch: 5| Step: 1
Training loss: 3.3913768866339264
Validation loss: 3.136610428074483

Epoch: 5| Step: 2
Training loss: 3.8697835204225677
Validation loss: 3.136173156349587

Epoch: 5| Step: 3
Training loss: 3.544440017612394
Validation loss: 3.1336564809392757

Epoch: 5| Step: 4
Training loss: 3.465328419191527
Validation loss: 3.1339643360334772

Epoch: 5| Step: 5
Training loss: 3.1556760058301254
Validation loss: 3.1325995579225765

Epoch: 5| Step: 6
Training loss: 2.708315590042289
Validation loss: 3.1341046500504754

Epoch: 5| Step: 7
Training loss: 3.434431891625293
Validation loss: 3.1361232233058978

Epoch: 5| Step: 8
Training loss: 2.942096603861375
Validation loss: 3.1568448271642615

Epoch: 5| Step: 9
Training loss: 3.557239597250387
Validation loss: 3.195179451276194

Epoch: 5| Step: 10
Training loss: 3.3239099020653886
Validation loss: 3.1571852481101734

Epoch: 28| Step: 0
Training loss: 3.6671266411768766
Validation loss: 3.128276336357159

Epoch: 5| Step: 1
Training loss: 3.1662355095990717
Validation loss: 3.1472265924162737

Epoch: 5| Step: 2
Training loss: 3.209061494575066
Validation loss: 3.209918485688881

Epoch: 5| Step: 3
Training loss: 3.434403012745458
Validation loss: 3.235599840143897

Epoch: 5| Step: 4
Training loss: 3.210406851253238
Validation loss: 3.190305603913525

Epoch: 5| Step: 5
Training loss: 3.6157958152731164
Validation loss: 3.149650024111543

Epoch: 5| Step: 6
Training loss: 3.7774470097216297
Validation loss: 3.1258267947584706

Epoch: 5| Step: 7
Training loss: 3.2264197366456524
Validation loss: 3.1352757771225934

Epoch: 5| Step: 8
Training loss: 3.8783601528191767
Validation loss: 3.153672831152287

Epoch: 5| Step: 9
Training loss: 3.138961427313672
Validation loss: 3.1514543602574

Epoch: 5| Step: 10
Training loss: 3.199634715927531
Validation loss: 3.1390611271766473

Epoch: 29| Step: 0
Training loss: 3.3322669389734796
Validation loss: 3.1322689203151706

Epoch: 5| Step: 1
Training loss: 3.8284172102281757
Validation loss: 3.121085181229574

Epoch: 5| Step: 2
Training loss: 2.9647353482941448
Validation loss: 3.115178186022594

Epoch: 5| Step: 3
Training loss: 3.496157853375298
Validation loss: 3.1128726505357283

Epoch: 5| Step: 4
Training loss: 3.829496924126527
Validation loss: 3.1161670341145578

Epoch: 5| Step: 5
Training loss: 2.8887209007946733
Validation loss: 3.1191484232351128

Epoch: 5| Step: 6
Training loss: 3.3233439171819272
Validation loss: 3.124062168950987

Epoch: 5| Step: 7
Training loss: 3.613169075539175
Validation loss: 3.1199390341579263

Epoch: 5| Step: 8
Training loss: 2.8308480152119597
Validation loss: 3.1175726258585916

Epoch: 5| Step: 9
Training loss: 2.986101699538271
Validation loss: 3.111934909753855

Epoch: 5| Step: 10
Training loss: 4.074954616551346
Validation loss: 3.108919692944796

Epoch: 30| Step: 0
Training loss: 3.083990868917324
Validation loss: 3.107665524269569

Epoch: 5| Step: 1
Training loss: 3.4438991285875002
Validation loss: 3.108312654436076

Epoch: 5| Step: 2
Training loss: 3.5004214986676905
Validation loss: 3.1067582850929196

Epoch: 5| Step: 3
Training loss: 3.149031892994757
Validation loss: 3.115981708546431

Epoch: 5| Step: 4
Training loss: 3.0939697804075585
Validation loss: 3.1367908628305505

Epoch: 5| Step: 5
Training loss: 3.423705843598601
Validation loss: 3.105379904953482

Epoch: 5| Step: 6
Training loss: 3.846947681226919
Validation loss: 3.1053142046600546

Epoch: 5| Step: 7
Training loss: 3.1918841859749936
Validation loss: 3.105136597301033

Epoch: 5| Step: 8
Training loss: 3.5971709844670574
Validation loss: 3.1055936295381783

Epoch: 5| Step: 9
Training loss: 3.799520191217791
Validation loss: 3.102233776880514

Epoch: 5| Step: 10
Training loss: 2.8056589638397806
Validation loss: 3.102689745302537

Epoch: 31| Step: 0
Training loss: 3.3968768866427603
Validation loss: 3.101528456938582

Epoch: 5| Step: 1
Training loss: 3.5706644030880277
Validation loss: 3.1010963240656473

Epoch: 5| Step: 2
Training loss: 3.3886952336190603
Validation loss: 3.102765521042621

Epoch: 5| Step: 3
Training loss: 3.934844559697927
Validation loss: 3.103386899885137

Epoch: 5| Step: 4
Training loss: 3.22185744124474
Validation loss: 3.098563348600998

Epoch: 5| Step: 5
Training loss: 2.849784401217547
Validation loss: 3.099161381772427

Epoch: 5| Step: 6
Training loss: 3.05742364671119
Validation loss: 3.0948345942720015

Epoch: 5| Step: 7
Training loss: 4.14885081730448
Validation loss: 3.0980281308928386

Epoch: 5| Step: 8
Training loss: 3.660667554709927
Validation loss: 3.09725924320966

Epoch: 5| Step: 9
Training loss: 2.4858802697710938
Validation loss: 3.095618344162382

Epoch: 5| Step: 10
Training loss: 2.91948892196746
Validation loss: 3.09587685573158

Epoch: 32| Step: 0
Training loss: 3.553160890852563
Validation loss: 3.094226151268117

Epoch: 5| Step: 1
Training loss: 4.043522805106339
Validation loss: 3.0927671791992313

Epoch: 5| Step: 2
Training loss: 3.0267972982115023
Validation loss: 3.092736023448836

Epoch: 5| Step: 3
Training loss: 3.3937154300959285
Validation loss: 3.091629622564495

Epoch: 5| Step: 4
Training loss: 3.0248748753418893
Validation loss: 3.091228079947199

Epoch: 5| Step: 5
Training loss: 3.4237870400504873
Validation loss: 3.091772968134329

Epoch: 5| Step: 6
Training loss: 3.4625951099760255
Validation loss: 3.095450445993399

Epoch: 5| Step: 7
Training loss: 2.8132153766846995
Validation loss: 3.090036942718831

Epoch: 5| Step: 8
Training loss: 2.8084112328234494
Validation loss: 3.090142440520845

Epoch: 5| Step: 9
Training loss: 3.647830365327662
Validation loss: 3.0865978269179126

Epoch: 5| Step: 10
Training loss: 3.5575852875662877
Validation loss: 3.0885180627523776

Epoch: 33| Step: 0
Training loss: 2.980467790076025
Validation loss: 3.084321575107508

Epoch: 5| Step: 1
Training loss: 3.5037479768897595
Validation loss: 3.085441030823908

Epoch: 5| Step: 2
Training loss: 2.7808474131467693
Validation loss: 3.0825940043666686

Epoch: 5| Step: 3
Training loss: 3.22804946441757
Validation loss: 3.0833222844381236

Epoch: 5| Step: 4
Training loss: 3.5913240952354943
Validation loss: 3.0845859353434135

Epoch: 5| Step: 5
Training loss: 3.7892342754635986
Validation loss: 3.0833327989874335

Epoch: 5| Step: 6
Training loss: 3.8899421552265143
Validation loss: 3.0776748773692213

Epoch: 5| Step: 7
Training loss: 3.399332844970253
Validation loss: 3.079032408153921

Epoch: 5| Step: 8
Training loss: 2.7359535238601733
Validation loss: 3.0776422060667867

Epoch: 5| Step: 9
Training loss: 2.843105704291764
Validation loss: 3.076202940164656

Epoch: 5| Step: 10
Training loss: 3.9187215460272053
Validation loss: 3.0790484775317624

Epoch: 34| Step: 0
Training loss: 3.2498612007432994
Validation loss: 3.0773442999589866

Epoch: 5| Step: 1
Training loss: 3.5444552195859242
Validation loss: 3.0734919770584717

Epoch: 5| Step: 2
Training loss: 3.017007619512468
Validation loss: 3.071800758189812

Epoch: 5| Step: 3
Training loss: 2.8929595592743222
Validation loss: 3.072267189586385

Epoch: 5| Step: 4
Training loss: 4.079927360411623
Validation loss: 3.0685600492476715

Epoch: 5| Step: 5
Training loss: 3.207089533955763
Validation loss: 3.0707383972908335

Epoch: 5| Step: 6
Training loss: 3.3834029248476565
Validation loss: 3.070788223913263

Epoch: 5| Step: 7
Training loss: 2.5668863111701414
Validation loss: 3.0671139148923476

Epoch: 5| Step: 8
Training loss: 4.248972824731598
Validation loss: 3.071553668036998

Epoch: 5| Step: 9
Training loss: 2.72106528079714
Validation loss: 3.0674504209052094

Epoch: 5| Step: 10
Training loss: 3.4883370218805774
Validation loss: 3.069647791282938

Epoch: 35| Step: 0
Training loss: 2.4048333890308915
Validation loss: 3.0694151316915863

Epoch: 5| Step: 1
Training loss: 3.4626065399635206
Validation loss: 3.07039483264828

Epoch: 5| Step: 2
Training loss: 3.1482572669605204
Validation loss: 3.0723410196344743

Epoch: 5| Step: 3
Training loss: 2.9474290280456645
Validation loss: 3.0779358021913774

Epoch: 5| Step: 4
Training loss: 3.187863497483678
Validation loss: 3.0782412780883393

Epoch: 5| Step: 5
Training loss: 3.5037607696509223
Validation loss: 3.0681800211537977

Epoch: 5| Step: 6
Training loss: 3.27181420328954
Validation loss: 3.0667309961843587

Epoch: 5| Step: 7
Training loss: 3.598280464220978
Validation loss: 3.0637173948341463

Epoch: 5| Step: 8
Training loss: 3.798869045007759
Validation loss: 3.0623031077441736

Epoch: 5| Step: 9
Training loss: 3.4403483294293933
Validation loss: 3.062885853625363

Epoch: 5| Step: 10
Training loss: 3.748311234733151
Validation loss: 3.0628311467063436

Epoch: 36| Step: 0
Training loss: 3.018967747387445
Validation loss: 3.063546426152378

Epoch: 5| Step: 1
Training loss: 3.9764566163840973
Validation loss: 3.063594707008618

Epoch: 5| Step: 2
Training loss: 3.5308419050866355
Validation loss: 3.0625313344343983

Epoch: 5| Step: 3
Training loss: 3.6876644809052883
Validation loss: 3.0578533915139436

Epoch: 5| Step: 4
Training loss: 2.595622478348857
Validation loss: 3.057572031929138

Epoch: 5| Step: 5
Training loss: 3.3544333373658723
Validation loss: 3.0564476900299833

Epoch: 5| Step: 6
Training loss: 2.82338903962913
Validation loss: 3.0567182048592505

Epoch: 5| Step: 7
Training loss: 3.171098585893393
Validation loss: 3.0612958759625877

Epoch: 5| Step: 8
Training loss: 3.023429614310614
Validation loss: 3.0640739730738384

Epoch: 5| Step: 9
Training loss: 4.036633822000088
Validation loss: 3.069599512094779

Epoch: 5| Step: 10
Training loss: 3.0726138897887343
Validation loss: 3.066558380564757

Epoch: 37| Step: 0
Training loss: 3.376371599455887
Validation loss: 3.06052463805413

Epoch: 5| Step: 1
Training loss: 3.8644577101916724
Validation loss: 3.0570628402753823

Epoch: 5| Step: 2
Training loss: 2.855203222200388
Validation loss: 3.0474846881199573

Epoch: 5| Step: 3
Training loss: 3.652319466413256
Validation loss: 3.0492428851059388

Epoch: 5| Step: 4
Training loss: 3.117403945483159
Validation loss: 3.0483894633526876

Epoch: 5| Step: 5
Training loss: 3.147154440116705
Validation loss: 3.048062083442129

Epoch: 5| Step: 6
Training loss: 2.7705540241398454
Validation loss: 3.047994504214535

Epoch: 5| Step: 7
Training loss: 3.4580367700354895
Validation loss: 3.0494977921880317

Epoch: 5| Step: 8
Training loss: 3.0591670993384463
Validation loss: 3.0480075259570225

Epoch: 5| Step: 9
Training loss: 4.160228459980702
Validation loss: 3.0468181662653038

Epoch: 5| Step: 10
Training loss: 2.6310622739537366
Validation loss: 3.043432088892898

Epoch: 38| Step: 0
Training loss: 3.3765484118928972
Validation loss: 3.0429908313234653

Epoch: 5| Step: 1
Training loss: 3.393443540221193
Validation loss: 3.043291365709662

Epoch: 5| Step: 2
Training loss: 3.393590377510166
Validation loss: 3.040299687588101

Epoch: 5| Step: 3
Training loss: 2.859873577071381
Validation loss: 3.039540048194738

Epoch: 5| Step: 4
Training loss: 3.023666333747716
Validation loss: 3.038752234349486

Epoch: 5| Step: 5
Training loss: 2.9707003962738123
Validation loss: 3.039947073129773

Epoch: 5| Step: 6
Training loss: 3.5624912998026304
Validation loss: 3.038861487476919

Epoch: 5| Step: 7
Training loss: 3.1271321461675914
Validation loss: 3.039875752930239

Epoch: 5| Step: 8
Training loss: 3.1924150756437912
Validation loss: 3.0362909990276226

Epoch: 5| Step: 9
Training loss: 3.8272894745478636
Validation loss: 3.0351117730100445

Epoch: 5| Step: 10
Training loss: 3.594732531703479
Validation loss: 3.035228057800369

Epoch: 39| Step: 0
Training loss: 3.2374220790838577
Validation loss: 3.036379169752145

Epoch: 5| Step: 1
Training loss: 2.998494724286215
Validation loss: 3.0388555492384905

Epoch: 5| Step: 2
Training loss: 2.916271364580978
Validation loss: 3.03803243456905

Epoch: 5| Step: 3
Training loss: 3.3551018084614963
Validation loss: 3.0372342477078647

Epoch: 5| Step: 4
Training loss: 3.842539775098987
Validation loss: 3.034931147854763

Epoch: 5| Step: 5
Training loss: 3.686962411778387
Validation loss: 3.0325814323216975

Epoch: 5| Step: 6
Training loss: 2.361273803590956
Validation loss: 3.0290124464426245

Epoch: 5| Step: 7
Training loss: 3.7161113449595677
Validation loss: 3.0286168141401846

Epoch: 5| Step: 8
Training loss: 3.7129541960546066
Validation loss: 3.0284380779053137

Epoch: 5| Step: 9
Training loss: 2.8467775095756744
Validation loss: 3.0264827790893407

Epoch: 5| Step: 10
Training loss: 3.357780752480137
Validation loss: 3.0269436919967667

Epoch: 40| Step: 0
Training loss: 3.0694272849714244
Validation loss: 3.024197361824065

Epoch: 5| Step: 1
Training loss: 2.8338119065262295
Validation loss: 3.026219198611981

Epoch: 5| Step: 2
Training loss: 3.0472942357308805
Validation loss: 3.0252114185043766

Epoch: 5| Step: 3
Training loss: 3.3128857657890904
Validation loss: 3.024692080189189

Epoch: 5| Step: 4
Training loss: 3.301098328659126
Validation loss: 3.0247203795976847

Epoch: 5| Step: 5
Training loss: 3.546361541553631
Validation loss: 3.024302925237535

Epoch: 5| Step: 6
Training loss: 3.288356968104682
Validation loss: 3.022684766558735

Epoch: 5| Step: 7
Training loss: 3.264059321144934
Validation loss: 3.0211862671209464

Epoch: 5| Step: 8
Training loss: 3.682624568036558
Validation loss: 3.0207489194239048

Epoch: 5| Step: 9
Training loss: 3.791255355715467
Validation loss: 3.019808392875156

Epoch: 5| Step: 10
Training loss: 2.9527077354847373
Validation loss: 3.0189259548087417

Epoch: 41| Step: 0
Training loss: 3.0200051235635508
Validation loss: 3.014086332117278

Epoch: 5| Step: 1
Training loss: 3.542578291906146
Validation loss: 3.0154936877333838

Epoch: 5| Step: 2
Training loss: 3.307928853968519
Validation loss: 3.0222064831217508

Epoch: 5| Step: 3
Training loss: 3.6699262926563354
Validation loss: 3.0327797520356836

Epoch: 5| Step: 4
Training loss: 2.2433126464313156
Validation loss: 3.015468347871408

Epoch: 5| Step: 5
Training loss: 2.7075062784983364
Validation loss: 3.0150613863277855

Epoch: 5| Step: 6
Training loss: 3.4878178167973375
Validation loss: 3.010648500837938

Epoch: 5| Step: 7
Training loss: 3.743880301167848
Validation loss: 3.0106467296666812

Epoch: 5| Step: 8
Training loss: 3.2510936070849774
Validation loss: 3.011366567035274

Epoch: 5| Step: 9
Training loss: 3.6579099620168574
Validation loss: 3.0108917238467905

Epoch: 5| Step: 10
Training loss: 3.2969123151213218
Validation loss: 3.008536691558337

Epoch: 42| Step: 0
Training loss: 3.2505347472198016
Validation loss: 3.0071354185317514

Epoch: 5| Step: 1
Training loss: 2.89088727431356
Validation loss: 3.008002714682244

Epoch: 5| Step: 2
Training loss: 3.9316637897898676
Validation loss: 3.007943295299979

Epoch: 5| Step: 3
Training loss: 3.044488216543363
Validation loss: 3.0071689905498467

Epoch: 5| Step: 4
Training loss: 3.147653183849183
Validation loss: 3.009138618121533

Epoch: 5| Step: 5
Training loss: 3.5459004546348574
Validation loss: 3.006157457514604

Epoch: 5| Step: 6
Training loss: 2.911565697907643
Validation loss: 3.0105857751947114

Epoch: 5| Step: 7
Training loss: 2.7778947286358004
Validation loss: 3.016189009830306

Epoch: 5| Step: 8
Training loss: 3.9617553107444574
Validation loss: 3.004263881395978

Epoch: 5| Step: 9
Training loss: 3.215315977619851
Validation loss: 3.0021507917646417

Epoch: 5| Step: 10
Training loss: 3.207762101748821
Validation loss: 3.0014524635397493

Epoch: 43| Step: 0
Training loss: 3.2255995377967897
Validation loss: 3.001996806316469

Epoch: 5| Step: 1
Training loss: 2.873867143431175
Validation loss: 3.000409294052703

Epoch: 5| Step: 2
Training loss: 3.0265318341688237
Validation loss: 3.001966802487013

Epoch: 5| Step: 3
Training loss: 3.105193273453833
Validation loss: 2.9992213264108534

Epoch: 5| Step: 4
Training loss: 2.966180592981598
Validation loss: 2.997250447159095

Epoch: 5| Step: 5
Training loss: 3.128865712030623
Validation loss: 2.998653730192536

Epoch: 5| Step: 6
Training loss: 4.354467548883255
Validation loss: 2.9973731709317217

Epoch: 5| Step: 7
Training loss: 3.3094661422728873
Validation loss: 2.999787087217194

Epoch: 5| Step: 8
Training loss: 2.8879268116117616
Validation loss: 3.0003657408605395

Epoch: 5| Step: 9
Training loss: 3.237633579399931
Validation loss: 2.9969587480538262

Epoch: 5| Step: 10
Training loss: 3.753456176071067
Validation loss: 3.0019762620861514

Epoch: 44| Step: 0
Training loss: 3.0710897068646275
Validation loss: 3.004859522895168

Epoch: 5| Step: 1
Training loss: 3.4176194017895383
Validation loss: 2.9943842847900703

Epoch: 5| Step: 2
Training loss: 3.8316330386878206
Validation loss: 2.992235765346603

Epoch: 5| Step: 3
Training loss: 3.2982441016475317
Validation loss: 2.9909430795204677

Epoch: 5| Step: 4
Training loss: 3.4032069621098753
Validation loss: 2.9907152376231503

Epoch: 5| Step: 5
Training loss: 2.98050106726008
Validation loss: 2.990554593200704

Epoch: 5| Step: 6
Training loss: 2.9790115493903957
Validation loss: 2.9877621886145063

Epoch: 5| Step: 7
Training loss: 3.3308419612886984
Validation loss: 2.987547387682501

Epoch: 5| Step: 8
Training loss: 3.0960298095076317
Validation loss: 2.9875666624596757

Epoch: 5| Step: 9
Training loss: 3.0207977994385478
Validation loss: 2.988024236715065

Epoch: 5| Step: 10
Training loss: 3.4776369641863556
Validation loss: 2.9894451154997914

Epoch: 45| Step: 0
Training loss: 3.467638679707055
Validation loss: 2.986622379990202

Epoch: 5| Step: 1
Training loss: 3.2471850014989845
Validation loss: 2.9871201219317127

Epoch: 5| Step: 2
Training loss: 3.6454550991953014
Validation loss: 2.9870982463884603

Epoch: 5| Step: 3
Training loss: 3.191562382626996
Validation loss: 2.986472246508251

Epoch: 5| Step: 4
Training loss: 2.821301738516435
Validation loss: 2.986353592798328

Epoch: 5| Step: 5
Training loss: 3.391476853766481
Validation loss: 2.986077164532288

Epoch: 5| Step: 6
Training loss: 2.565595478440937
Validation loss: 2.9843393461226637

Epoch: 5| Step: 7
Training loss: 3.158105739019149
Validation loss: 2.983936020037537

Epoch: 5| Step: 8
Training loss: 3.500698837267091
Validation loss: 2.9849466906862494

Epoch: 5| Step: 9
Training loss: 3.654396956932217
Validation loss: 2.982896497524143

Epoch: 5| Step: 10
Training loss: 3.0208116903297064
Validation loss: 2.9830552313924716

Epoch: 46| Step: 0
Training loss: 2.924247227498759
Validation loss: 2.9848463986192346

Epoch: 5| Step: 1
Training loss: 4.081715373543947
Validation loss: 2.981037632923311

Epoch: 5| Step: 2
Training loss: 2.7215809607418997
Validation loss: 2.9783586960686605

Epoch: 5| Step: 3
Training loss: 3.3535518833126505
Validation loss: 2.976156986411454

Epoch: 5| Step: 4
Training loss: 3.1078998382708733
Validation loss: 2.9772893158067517

Epoch: 5| Step: 5
Training loss: 3.6357833691933075
Validation loss: 2.977406647424351

Epoch: 5| Step: 6
Training loss: 3.3669586457901346
Validation loss: 2.9779402754809055

Epoch: 5| Step: 7
Training loss: 2.973446313681597
Validation loss: 2.976004149843578

Epoch: 5| Step: 8
Training loss: 3.95819755455174
Validation loss: 2.977727689785028

Epoch: 5| Step: 9
Training loss: 2.618069354986986
Validation loss: 2.9730393273650773

Epoch: 5| Step: 10
Training loss: 2.632347813017404
Validation loss: 2.971027692638616

Epoch: 47| Step: 0
Training loss: 3.0116346770548965
Validation loss: 2.9747189871034245

Epoch: 5| Step: 1
Training loss: 3.6293185588060393
Validation loss: 2.983213517684152

Epoch: 5| Step: 2
Training loss: 3.7752170828744602
Validation loss: 2.9960699745085506

Epoch: 5| Step: 3
Training loss: 3.1184917580020253
Validation loss: 2.9697240089813173

Epoch: 5| Step: 4
Training loss: 3.1218514411961436
Validation loss: 2.967569496661122

Epoch: 5| Step: 5
Training loss: 3.1669580091337193
Validation loss: 2.9676883234778777

Epoch: 5| Step: 6
Training loss: 3.340512713979808
Validation loss: 2.9675908622035383

Epoch: 5| Step: 7
Training loss: 3.6474281238065487
Validation loss: 2.967777405915195

Epoch: 5| Step: 8
Training loss: 3.2836894821671874
Validation loss: 2.9671355801091646

Epoch: 5| Step: 9
Training loss: 2.3541843334874177
Validation loss: 2.966343368919931

Epoch: 5| Step: 10
Training loss: 3.1220671051457565
Validation loss: 2.9649799425943946

Epoch: 48| Step: 0
Training loss: 2.907650681819911
Validation loss: 2.9642248738183388

Epoch: 5| Step: 1
Training loss: 2.98912780339423
Validation loss: 2.9626016416879692

Epoch: 5| Step: 2
Training loss: 3.3123471206798323
Validation loss: 2.96388533872966

Epoch: 5| Step: 3
Training loss: 3.147928883099451
Validation loss: 2.9611780593430512

Epoch: 5| Step: 4
Training loss: 2.5850702312380895
Validation loss: 2.9641653985034138

Epoch: 5| Step: 5
Training loss: 3.8228333314271765
Validation loss: 2.966655053778172

Epoch: 5| Step: 6
Training loss: 2.946482782567016
Validation loss: 2.964095228413018

Epoch: 5| Step: 7
Training loss: 3.188310856624435
Validation loss: 2.954932069743225

Epoch: 5| Step: 8
Training loss: 3.6596688482424726
Validation loss: 2.9541662068803944

Epoch: 5| Step: 9
Training loss: 3.6315020422863435
Validation loss: 2.952544020255087

Epoch: 5| Step: 10
Training loss: 3.198560039071858
Validation loss: 2.9548380589895307

Epoch: 49| Step: 0
Training loss: 3.667993319980608
Validation loss: 2.9501713122318085

Epoch: 5| Step: 1
Training loss: 2.6539305489600915
Validation loss: 2.945410556574821

Epoch: 5| Step: 2
Training loss: 3.157131411920674
Validation loss: 2.9473965360377035

Epoch: 5| Step: 3
Training loss: 2.770199457004079
Validation loss: 2.948310938448616

Epoch: 5| Step: 4
Training loss: 3.274591429173285
Validation loss: 2.9479997455701836

Epoch: 5| Step: 5
Training loss: 3.13429175862523
Validation loss: 2.945538943371043

Epoch: 5| Step: 6
Training loss: 3.131673781904739
Validation loss: 2.943780539748964

Epoch: 5| Step: 7
Training loss: 2.976645320831461
Validation loss: 2.944146361179824

Epoch: 5| Step: 8
Training loss: 4.121481117013687
Validation loss: 2.9415389626712

Epoch: 5| Step: 9
Training loss: 3.4001396038341607
Validation loss: 2.9536984098515897

Epoch: 5| Step: 10
Training loss: 3.026142339733402
Validation loss: 2.957057437408789

Epoch: 50| Step: 0
Training loss: 3.1018836482133274
Validation loss: 2.9583915786751884

Epoch: 5| Step: 1
Training loss: 2.9159361514831508
Validation loss: 2.9459187400056757

Epoch: 5| Step: 2
Training loss: 3.4689967437139444
Validation loss: 2.944146041611417

Epoch: 5| Step: 3
Training loss: 3.459588677096927
Validation loss: 2.9444470979886654

Epoch: 5| Step: 4
Training loss: 3.2516643957315554
Validation loss: 2.94681966759225

Epoch: 5| Step: 5
Training loss: 2.965548103710328
Validation loss: 2.9465906272728097

Epoch: 5| Step: 6
Training loss: 3.567079378177919
Validation loss: 2.944042564059429

Epoch: 5| Step: 7
Training loss: 2.6505577580063844
Validation loss: 2.9446621812266245

Epoch: 5| Step: 8
Training loss: 3.471020479564427
Validation loss: 2.941838061928062

Epoch: 5| Step: 9
Training loss: 3.497299242236228
Validation loss: 2.9433469041190428

Epoch: 5| Step: 10
Training loss: 3.0335964284409047
Validation loss: 2.940771286499037

Testing loss: 3.129413446684124
