Epoch: 1| Step: 0
Training loss: 6.106398582458496
Validation loss: 5.143552857060587

Epoch: 5| Step: 1
Training loss: 4.6071271896362305
Validation loss: 5.1270624078730105

Epoch: 5| Step: 2
Training loss: 4.573296546936035
Validation loss: 5.113833576120356

Epoch: 5| Step: 3
Training loss: 6.035764694213867
Validation loss: 5.100049700788272

Epoch: 5| Step: 4
Training loss: 4.981107711791992
Validation loss: 5.084129461678126

Epoch: 5| Step: 5
Training loss: 4.382468223571777
Validation loss: 5.066185720505253

Epoch: 5| Step: 6
Training loss: 4.888474941253662
Validation loss: 5.04546094709827

Epoch: 5| Step: 7
Training loss: 5.617053985595703
Validation loss: 5.021577691519132

Epoch: 5| Step: 8
Training loss: 4.697865962982178
Validation loss: 4.994873523712158

Epoch: 5| Step: 9
Training loss: 3.257586717605591
Validation loss: 4.964946844244516

Epoch: 5| Step: 10
Training loss: 4.120659828186035
Validation loss: 4.931692923268964

Epoch: 2| Step: 0
Training loss: 4.347508430480957
Validation loss: 4.895269352902648

Epoch: 5| Step: 1
Training loss: 3.9789910316467285
Validation loss: 4.854329673192835

Epoch: 5| Step: 2
Training loss: 5.644214630126953
Validation loss: 4.810928954873034

Epoch: 5| Step: 3
Training loss: 4.553837299346924
Validation loss: 4.762018301153696

Epoch: 5| Step: 4
Training loss: 4.735651969909668
Validation loss: 4.711147400640672

Epoch: 5| Step: 5
Training loss: 4.907956123352051
Validation loss: 4.65841019025413

Epoch: 5| Step: 6
Training loss: 4.160663604736328
Validation loss: 4.602282319017636

Epoch: 5| Step: 7
Training loss: 3.4437015056610107
Validation loss: 4.5467572263492055

Epoch: 5| Step: 8
Training loss: 4.302536964416504
Validation loss: 4.49117689235236

Epoch: 5| Step: 9
Training loss: 4.4409990310668945
Validation loss: 4.436953611271356

Epoch: 5| Step: 10
Training loss: 4.36695671081543
Validation loss: 4.387119913613924

Epoch: 3| Step: 0
Training loss: 3.648050308227539
Validation loss: 4.3381144308274795

Epoch: 5| Step: 1
Training loss: 3.4376018047332764
Validation loss: 4.295204172852219

Epoch: 5| Step: 2
Training loss: 4.2975358963012695
Validation loss: 4.247472263151599

Epoch: 5| Step: 3
Training loss: 4.119046211242676
Validation loss: 4.196722748459027

Epoch: 5| Step: 4
Training loss: 3.885483503341675
Validation loss: 4.138796539716823

Epoch: 5| Step: 5
Training loss: 3.2771897315979004
Validation loss: 4.087531607638123

Epoch: 5| Step: 6
Training loss: 4.558248043060303
Validation loss: 4.049076664832331

Epoch: 5| Step: 7
Training loss: 4.418386459350586
Validation loss: 4.013508176290861

Epoch: 5| Step: 8
Training loss: 3.9468116760253906
Validation loss: 3.976319497631442

Epoch: 5| Step: 9
Training loss: 4.791266441345215
Validation loss: 3.9400044820641957

Epoch: 5| Step: 10
Training loss: 2.9958713054656982
Validation loss: 3.900652700854886

Epoch: 4| Step: 0
Training loss: 3.220210552215576
Validation loss: 3.8638088933883177

Epoch: 5| Step: 1
Training loss: 4.865236282348633
Validation loss: 3.8290348078614924

Epoch: 5| Step: 2
Training loss: 2.847165107727051
Validation loss: 3.797976824545091

Epoch: 5| Step: 3
Training loss: 3.5729644298553467
Validation loss: 3.7677184920157156

Epoch: 5| Step: 4
Training loss: 4.120478630065918
Validation loss: 3.74133030573527

Epoch: 5| Step: 5
Training loss: 3.4580230712890625
Validation loss: 3.7206948828953568

Epoch: 5| Step: 6
Training loss: 3.7482306957244873
Validation loss: 3.7009500534303728

Epoch: 5| Step: 7
Training loss: 3.9681344032287598
Validation loss: 3.6842794725971837

Epoch: 5| Step: 8
Training loss: 2.9289908409118652
Validation loss: 3.6655525904829784

Epoch: 5| Step: 9
Training loss: 3.249018907546997
Validation loss: 3.647349883151311

Epoch: 5| Step: 10
Training loss: 4.023545742034912
Validation loss: 3.630634548843548

Epoch: 5| Step: 0
Training loss: 3.641420841217041
Validation loss: 3.61312956963816

Epoch: 5| Step: 1
Training loss: 4.40814208984375
Validation loss: 3.595335114386774

Epoch: 5| Step: 2
Training loss: 3.4378390312194824
Validation loss: 3.5860330776501725

Epoch: 5| Step: 3
Training loss: 3.7426459789276123
Validation loss: 3.5578208508030063

Epoch: 5| Step: 4
Training loss: 3.1030285358428955
Validation loss: 3.534781922576248

Epoch: 5| Step: 5
Training loss: 4.62313175201416
Validation loss: 3.5147027815541914

Epoch: 5| Step: 6
Training loss: 2.920381546020508
Validation loss: 3.502813369997086

Epoch: 5| Step: 7
Training loss: 2.8582165241241455
Validation loss: 3.5027058355269896

Epoch: 5| Step: 8
Training loss: 3.293203830718994
Validation loss: 3.5071046993296635

Epoch: 5| Step: 9
Training loss: 3.1124300956726074
Validation loss: 3.482566190022294

Epoch: 5| Step: 10
Training loss: 2.894094467163086
Validation loss: 3.4673701768280356

Epoch: 6| Step: 0
Training loss: 3.770491361618042
Validation loss: 3.4505131654841925

Epoch: 5| Step: 1
Training loss: 2.9165024757385254
Validation loss: 3.434501322366858

Epoch: 5| Step: 2
Training loss: 4.432412624359131
Validation loss: 3.4305856381693194

Epoch: 5| Step: 3
Training loss: 2.7322959899902344
Validation loss: 3.432268427264306

Epoch: 5| Step: 4
Training loss: 3.905792236328125
Validation loss: 3.4225737843462216

Epoch: 5| Step: 5
Training loss: 2.6371796131134033
Validation loss: 3.4027630103531705

Epoch: 5| Step: 6
Training loss: 3.4836432933807373
Validation loss: 3.3982853992010957

Epoch: 5| Step: 7
Training loss: 3.3848960399627686
Validation loss: 3.393353126382315

Epoch: 5| Step: 8
Training loss: 3.247403621673584
Validation loss: 3.379490713919363

Epoch: 5| Step: 9
Training loss: 2.7471249103546143
Validation loss: 3.3653870910726567

Epoch: 5| Step: 10
Training loss: 3.685884952545166
Validation loss: 3.3574837484667377

Epoch: 7| Step: 0
Training loss: 3.195411443710327
Validation loss: 3.348469465009628

Epoch: 5| Step: 1
Training loss: 3.3877296447753906
Validation loss: 3.3311563948149323

Epoch: 5| Step: 2
Training loss: 3.493750810623169
Validation loss: 3.32378323360156

Epoch: 5| Step: 3
Training loss: 3.551278591156006
Validation loss: 3.315371667185137

Epoch: 5| Step: 4
Training loss: 3.3230843544006348
Validation loss: 3.300313718857304

Epoch: 5| Step: 5
Training loss: 3.4076790809631348
Validation loss: 3.287834641753986

Epoch: 5| Step: 6
Training loss: 2.0005860328674316
Validation loss: 3.278958910255022

Epoch: 5| Step: 7
Training loss: 2.8433525562286377
Validation loss: 3.2615868506893033

Epoch: 5| Step: 8
Training loss: 3.0762195587158203
Validation loss: 3.2624546225352953

Epoch: 5| Step: 9
Training loss: 3.9654617309570312
Validation loss: 3.258569645625289

Epoch: 5| Step: 10
Training loss: 3.7410926818847656
Validation loss: 3.2500413438325286

Epoch: 8| Step: 0
Training loss: 2.9216322898864746
Validation loss: 3.224161781290526

Epoch: 5| Step: 1
Training loss: 3.6464333534240723
Validation loss: 3.2362905471555647

Epoch: 5| Step: 2
Training loss: 2.4760940074920654
Validation loss: 3.22146846402076

Epoch: 5| Step: 3
Training loss: 3.5456016063690186
Validation loss: 3.2577782728338756

Epoch: 5| Step: 4
Training loss: 2.8360772132873535
Validation loss: 3.2160774200193343

Epoch: 5| Step: 5
Training loss: 3.478497266769409
Validation loss: 3.219667973056916

Epoch: 5| Step: 6
Training loss: 3.6528518199920654
Validation loss: 3.2157182129480506

Epoch: 5| Step: 7
Training loss: 2.7065372467041016
Validation loss: 3.218640363344582

Epoch: 5| Step: 8
Training loss: 3.105867862701416
Validation loss: 3.2348659448726202

Epoch: 5| Step: 9
Training loss: 3.5307915210723877
Validation loss: 3.2009989907664638

Epoch: 5| Step: 10
Training loss: 3.493542194366455
Validation loss: 3.189301198528659

Epoch: 9| Step: 0
Training loss: 2.325408458709717
Validation loss: 3.1782269400935017

Epoch: 5| Step: 1
Training loss: 3.59175181388855
Validation loss: 3.1682291389793478

Epoch: 5| Step: 2
Training loss: 3.629601240158081
Validation loss: 3.1662412920305805

Epoch: 5| Step: 3
Training loss: 3.298248767852783
Validation loss: 3.1704794232563307

Epoch: 5| Step: 4
Training loss: 3.1356732845306396
Validation loss: 3.2034204185649915

Epoch: 5| Step: 5
Training loss: 2.56040620803833
Validation loss: 3.1628722683075936

Epoch: 5| Step: 6
Training loss: 3.764216661453247
Validation loss: 3.1515040397644043

Epoch: 5| Step: 7
Training loss: 3.2621352672576904
Validation loss: 3.1319183559827906

Epoch: 5| Step: 8
Training loss: 2.6541831493377686
Validation loss: 3.1288443252604496

Epoch: 5| Step: 9
Training loss: 3.7481913566589355
Validation loss: 3.1246446512078725

Epoch: 5| Step: 10
Training loss: 2.806065797805786
Validation loss: 3.139974163424584

Epoch: 10| Step: 0
Training loss: 2.0919322967529297
Validation loss: 3.115708653644849

Epoch: 5| Step: 1
Training loss: 2.9853270053863525
Validation loss: 3.1144630139873875

Epoch: 5| Step: 2
Training loss: 2.7743237018585205
Validation loss: 3.1241708468365412

Epoch: 5| Step: 3
Training loss: 3.3815085887908936
Validation loss: 3.1148849559086624

Epoch: 5| Step: 4
Training loss: 3.124659299850464
Validation loss: 3.107156922740321

Epoch: 5| Step: 5
Training loss: 2.8946285247802734
Validation loss: 3.100010612959503

Epoch: 5| Step: 6
Training loss: 3.7337889671325684
Validation loss: 3.0951509347525974

Epoch: 5| Step: 7
Training loss: 3.9721665382385254
Validation loss: 3.091059387371104

Epoch: 5| Step: 8
Training loss: 3.0685508251190186
Validation loss: 3.0873717005534838

Epoch: 5| Step: 9
Training loss: 2.961622714996338
Validation loss: 3.0794737364656184

Epoch: 5| Step: 10
Training loss: 3.5093483924865723
Validation loss: 3.0774122335577525

Epoch: 11| Step: 0
Training loss: 2.967156171798706
Validation loss: 3.082710373786188

Epoch: 5| Step: 1
Training loss: 2.1265571117401123
Validation loss: 3.0752036981685187

Epoch: 5| Step: 2
Training loss: 3.830725908279419
Validation loss: 3.0722258834428686

Epoch: 5| Step: 3
Training loss: 3.5156960487365723
Validation loss: 3.066702127456665

Epoch: 5| Step: 4
Training loss: 2.3996644020080566
Validation loss: 3.063316983561362

Epoch: 5| Step: 5
Training loss: 2.9770395755767822
Validation loss: 3.059352764519312

Epoch: 5| Step: 6
Training loss: 3.3929569721221924
Validation loss: 3.054910364971366

Epoch: 5| Step: 7
Training loss: 3.068113327026367
Validation loss: 3.054096475724251

Epoch: 5| Step: 8
Training loss: 3.9554526805877686
Validation loss: 3.0478348244902906

Epoch: 5| Step: 9
Training loss: 3.2049102783203125
Validation loss: 3.046015206203666

Epoch: 5| Step: 10
Training loss: 2.6305739879608154
Validation loss: 3.043884772126393

Epoch: 12| Step: 0
Training loss: 3.1548311710357666
Validation loss: 3.0401595689917125

Epoch: 5| Step: 1
Training loss: 2.86952543258667
Validation loss: 3.0385698759427635

Epoch: 5| Step: 2
Training loss: 2.8713300228118896
Validation loss: 3.03568148356612

Epoch: 5| Step: 3
Training loss: 2.396005153656006
Validation loss: 3.032508368133217

Epoch: 5| Step: 4
Training loss: 2.655853509902954
Validation loss: 3.030767338250273

Epoch: 5| Step: 5
Training loss: 3.7856407165527344
Validation loss: 3.029051714046027

Epoch: 5| Step: 6
Training loss: 2.744577169418335
Validation loss: 3.0280621179970364

Epoch: 5| Step: 7
Training loss: 2.6705212593078613
Validation loss: 3.0300975871342484

Epoch: 5| Step: 8
Training loss: 3.9765820503234863
Validation loss: 3.0353010418594524

Epoch: 5| Step: 9
Training loss: 3.2207913398742676
Validation loss: 3.020582247805852

Epoch: 5| Step: 10
Training loss: 3.7018184661865234
Validation loss: 3.0240136807964695

Epoch: 13| Step: 0
Training loss: 3.219146251678467
Validation loss: 3.0152718174842095

Epoch: 5| Step: 1
Training loss: 3.3342785835266113
Validation loss: 3.01834306152918

Epoch: 5| Step: 2
Training loss: 2.8712782859802246
Validation loss: 3.028453319303451

Epoch: 5| Step: 3
Training loss: 2.6547739505767822
Validation loss: 3.0152998816582466

Epoch: 5| Step: 4
Training loss: 3.3548362255096436
Validation loss: 3.007038588164955

Epoch: 5| Step: 5
Training loss: 3.872013568878174
Validation loss: 3.0071231319058325

Epoch: 5| Step: 6
Training loss: 3.5774312019348145
Validation loss: 3.0054529713046167

Epoch: 5| Step: 7
Training loss: 2.9237775802612305
Validation loss: 3.0033849208585677

Epoch: 5| Step: 8
Training loss: 1.9630426168441772
Validation loss: 3.0020683324465187

Epoch: 5| Step: 9
Training loss: 3.3234291076660156
Validation loss: 3.0009144557419645

Epoch: 5| Step: 10
Training loss: 2.644390344619751
Validation loss: 3.003189512478408

Epoch: 14| Step: 0
Training loss: 2.6581149101257324
Validation loss: 2.993249511206022

Epoch: 5| Step: 1
Training loss: 2.6081833839416504
Validation loss: 2.991558254406016

Epoch: 5| Step: 2
Training loss: 2.745898962020874
Validation loss: 2.9894626114958074

Epoch: 5| Step: 3
Training loss: 3.530834913253784
Validation loss: 2.986688067836146

Epoch: 5| Step: 4
Training loss: 3.7314274311065674
Validation loss: 2.986150997941212

Epoch: 5| Step: 5
Training loss: 3.130845546722412
Validation loss: 2.983641534723261

Epoch: 5| Step: 6
Training loss: 2.9060771465301514
Validation loss: 2.980701805442892

Epoch: 5| Step: 7
Training loss: 2.771432399749756
Validation loss: 2.9818648394717964

Epoch: 5| Step: 8
Training loss: 3.6827285289764404
Validation loss: 2.974661709159933

Epoch: 5| Step: 9
Training loss: 3.1197123527526855
Validation loss: 2.9733496327554025

Epoch: 5| Step: 10
Training loss: 2.6723318099975586
Validation loss: 2.9707673326615365

Epoch: 15| Step: 0
Training loss: 3.8403537273406982
Validation loss: 2.969150432976343

Epoch: 5| Step: 1
Training loss: 2.3964526653289795
Validation loss: 2.965510840057045

Epoch: 5| Step: 2
Training loss: 3.461181640625
Validation loss: 2.9646236358150357

Epoch: 5| Step: 3
Training loss: 3.0762600898742676
Validation loss: 2.9590897380664782

Epoch: 5| Step: 4
Training loss: 2.440786361694336
Validation loss: 2.9591110855020504

Epoch: 5| Step: 5
Training loss: 2.726332187652588
Validation loss: 2.9566033245414816

Epoch: 5| Step: 6
Training loss: 3.4779210090637207
Validation loss: 2.953606105619861

Epoch: 5| Step: 7
Training loss: 2.32775616645813
Validation loss: 2.9527301685784453

Epoch: 5| Step: 8
Training loss: 3.7117507457733154
Validation loss: 2.9494476882360314

Epoch: 5| Step: 9
Training loss: 2.4013373851776123
Validation loss: 2.9468098404586955

Epoch: 5| Step: 10
Training loss: 3.657402515411377
Validation loss: 2.9444273953796714

Epoch: 16| Step: 0
Training loss: 2.7220170497894287
Validation loss: 2.9420741014583136

Epoch: 5| Step: 1
Training loss: 3.022226095199585
Validation loss: 2.941724031202255

Epoch: 5| Step: 2
Training loss: 3.0336873531341553
Validation loss: 2.938379277465164

Epoch: 5| Step: 3
Training loss: 2.9011988639831543
Validation loss: 2.936187372412733

Epoch: 5| Step: 4
Training loss: 2.484229564666748
Validation loss: 2.9330200328621814

Epoch: 5| Step: 5
Training loss: 3.133197784423828
Validation loss: 2.9306309325720674

Epoch: 5| Step: 6
Training loss: 2.7548980712890625
Validation loss: 2.9297560876415623

Epoch: 5| Step: 7
Training loss: 2.271995782852173
Validation loss: 2.9298891918633574

Epoch: 5| Step: 8
Training loss: 3.947441577911377
Validation loss: 2.9600740530157603

Epoch: 5| Step: 9
Training loss: 3.595996379852295
Validation loss: 2.9680628750913884

Epoch: 5| Step: 10
Training loss: 3.5132083892822266
Validation loss: 2.9298007180613856

Epoch: 17| Step: 0
Training loss: 3.354733943939209
Validation loss: 2.9141408448578208

Epoch: 5| Step: 1
Training loss: 2.574956178665161
Validation loss: 2.911837580383465

Epoch: 5| Step: 2
Training loss: 2.9125654697418213
Validation loss: 2.934645756598442

Epoch: 5| Step: 3
Training loss: 2.4482645988464355
Validation loss: 2.931169604742399

Epoch: 5| Step: 4
Training loss: 3.174778461456299
Validation loss: 2.9313061468062864

Epoch: 5| Step: 5
Training loss: 2.926517963409424
Validation loss: 2.9096347003854732

Epoch: 5| Step: 6
Training loss: 3.348344326019287
Validation loss: 2.9052428327580935

Epoch: 5| Step: 7
Training loss: 3.1281979084014893
Validation loss: 2.91139801086918

Epoch: 5| Step: 8
Training loss: 3.4764130115509033
Validation loss: 2.919340105466945

Epoch: 5| Step: 9
Training loss: 2.7652945518493652
Validation loss: 2.91516310937943

Epoch: 5| Step: 10
Training loss: 2.9515132904052734
Validation loss: 2.900964544665429

Epoch: 18| Step: 0
Training loss: 2.122382402420044
Validation loss: 2.897330489209903

Epoch: 5| Step: 1
Training loss: 2.87066912651062
Validation loss: 2.8946270865778767

Epoch: 5| Step: 2
Training loss: 3.087355136871338
Validation loss: 2.888706704621674

Epoch: 5| Step: 3
Training loss: 3.515439987182617
Validation loss: 2.894858824309482

Epoch: 5| Step: 4
Training loss: 2.4454309940338135
Validation loss: 2.888985485158941

Epoch: 5| Step: 5
Training loss: 2.768548011779785
Validation loss: 2.876910714692967

Epoch: 5| Step: 6
Training loss: 2.972990036010742
Validation loss: 2.868642145587552

Epoch: 5| Step: 7
Training loss: 3.4523234367370605
Validation loss: 2.862997031980945

Epoch: 5| Step: 8
Training loss: 2.253944158554077
Validation loss: 2.8611871657832975

Epoch: 5| Step: 9
Training loss: 3.8122692108154297
Validation loss: 2.8654559350782827

Epoch: 5| Step: 10
Training loss: 3.606027364730835
Validation loss: 2.856756915328323

Epoch: 19| Step: 0
Training loss: 2.8619935512542725
Validation loss: 2.851311409345237

Epoch: 5| Step: 1
Training loss: 3.4565341472625732
Validation loss: 2.8488502861351095

Epoch: 5| Step: 2
Training loss: 2.898522138595581
Validation loss: 2.845683384967107

Epoch: 5| Step: 3
Training loss: 2.9435551166534424
Validation loss: 2.840702795213269

Epoch: 5| Step: 4
Training loss: 3.3361496925354004
Validation loss: 2.8373545267248668

Epoch: 5| Step: 5
Training loss: 2.755805253982544
Validation loss: 2.8329686195619646

Epoch: 5| Step: 6
Training loss: 2.2383015155792236
Validation loss: 2.83087319712485

Epoch: 5| Step: 7
Training loss: 2.882154941558838
Validation loss: 2.8297388066527662

Epoch: 5| Step: 8
Training loss: 3.0053515434265137
Validation loss: 2.827513874218028

Epoch: 5| Step: 9
Training loss: 2.7139344215393066
Validation loss: 2.8271118979300223

Epoch: 5| Step: 10
Training loss: 3.4980521202087402
Validation loss: 2.8374267188451623

Epoch: 20| Step: 0
Training loss: 3.3640809059143066
Validation loss: 2.838472984170401

Epoch: 5| Step: 1
Training loss: 3.730239152908325
Validation loss: 2.812394662569928

Epoch: 5| Step: 2
Training loss: 2.266597032546997
Validation loss: 2.8164554155001076

Epoch: 5| Step: 3
Training loss: 2.4043307304382324
Validation loss: 2.8191487199516705

Epoch: 5| Step: 4
Training loss: 3.5301029682159424
Validation loss: 2.831389227221089

Epoch: 5| Step: 5
Training loss: 2.394655227661133
Validation loss: 2.8253675353142524

Epoch: 5| Step: 6
Training loss: 3.1586341857910156
Validation loss: 2.817428952904158

Epoch: 5| Step: 7
Training loss: 3.1376099586486816
Validation loss: 2.8086088190796556

Epoch: 5| Step: 8
Training loss: 3.174673080444336
Validation loss: 2.798629355686967

Epoch: 5| Step: 9
Training loss: 2.3529279232025146
Validation loss: 2.78823794088056

Epoch: 5| Step: 10
Training loss: 2.837430953979492
Validation loss: 2.7954622904459634

Epoch: 21| Step: 0
Training loss: 2.9675745964050293
Validation loss: 2.7907223163112516

Epoch: 5| Step: 1
Training loss: 2.9501068592071533
Validation loss: 2.7761665518565843

Epoch: 5| Step: 2
Training loss: 2.631950616836548
Validation loss: 2.769898529975645

Epoch: 5| Step: 3
Training loss: 2.350615978240967
Validation loss: 2.772400253562517

Epoch: 5| Step: 4
Training loss: 3.408510208129883
Validation loss: 2.773036536350045

Epoch: 5| Step: 5
Training loss: 3.5103397369384766
Validation loss: 2.7808200261926137

Epoch: 5| Step: 6
Training loss: 3.3560593128204346
Validation loss: 2.7674793120353454

Epoch: 5| Step: 7
Training loss: 2.581847667694092
Validation loss: 2.7578831616268364

Epoch: 5| Step: 8
Training loss: 2.282011032104492
Validation loss: 2.754579077484787

Epoch: 5| Step: 9
Training loss: 2.6606485843658447
Validation loss: 2.7519505613593647

Epoch: 5| Step: 10
Training loss: 3.440919876098633
Validation loss: 2.7497267030900523

Epoch: 22| Step: 0
Training loss: 2.881620168685913
Validation loss: 2.7453939017429145

Epoch: 5| Step: 1
Training loss: 2.5447189807891846
Validation loss: 2.743862985282816

Epoch: 5| Step: 2
Training loss: 2.9111974239349365
Validation loss: 2.7415749488338346

Epoch: 5| Step: 3
Training loss: 3.0705103874206543
Validation loss: 2.741667534715386

Epoch: 5| Step: 4
Training loss: 2.667025089263916
Validation loss: 2.7424580871417956

Epoch: 5| Step: 5
Training loss: 3.8114845752716064
Validation loss: 2.7455200687531502

Epoch: 5| Step: 6
Training loss: 3.087409734725952
Validation loss: 2.7387312432771087

Epoch: 5| Step: 7
Training loss: 2.87939715385437
Validation loss: 2.7352985899935485

Epoch: 5| Step: 8
Training loss: 2.816312313079834
Validation loss: 2.7330216182175504

Epoch: 5| Step: 9
Training loss: 2.8677897453308105
Validation loss: 2.7310455845248316

Epoch: 5| Step: 10
Training loss: 2.193697214126587
Validation loss: 2.733070250480406

Epoch: 23| Step: 0
Training loss: 3.645939588546753
Validation loss: 2.728217355666622

Epoch: 5| Step: 1
Training loss: 2.3727054595947266
Validation loss: 2.7275452818921817

Epoch: 5| Step: 2
Training loss: 2.844332218170166
Validation loss: 2.724827338290471

Epoch: 5| Step: 3
Training loss: 2.8820621967315674
Validation loss: 2.728154420852661

Epoch: 5| Step: 4
Training loss: 3.2496681213378906
Validation loss: 2.727518161137899

Epoch: 5| Step: 5
Training loss: 2.9248876571655273
Validation loss: 2.721064411183839

Epoch: 5| Step: 6
Training loss: 2.7033514976501465
Validation loss: 2.7325981688755814

Epoch: 5| Step: 7
Training loss: 2.929082155227661
Validation loss: 2.821277859390423

Epoch: 5| Step: 8
Training loss: 2.642887592315674
Validation loss: 2.9983651843122257

Epoch: 5| Step: 9
Training loss: 2.905366897583008
Validation loss: 2.8706958217005574

Epoch: 5| Step: 10
Training loss: 2.9572463035583496
Validation loss: 2.7489462155167774

Epoch: 24| Step: 0
Training loss: 3.2445061206817627
Validation loss: 2.754767264089277

Epoch: 5| Step: 1
Training loss: 2.7294974327087402
Validation loss: 2.799778135873938

Epoch: 5| Step: 2
Training loss: 3.024303674697876
Validation loss: 2.8300601513155046

Epoch: 5| Step: 3
Training loss: 2.5949583053588867
Validation loss: 2.8235307457626506

Epoch: 5| Step: 4
Training loss: 3.6024436950683594
Validation loss: 2.755373365135603

Epoch: 5| Step: 5
Training loss: 2.432467222213745
Validation loss: 2.734079896762807

Epoch: 5| Step: 6
Training loss: 2.6477692127227783
Validation loss: 2.7535642577755834

Epoch: 5| Step: 7
Training loss: 2.2745914459228516
Validation loss: 2.7549540996551514

Epoch: 5| Step: 8
Training loss: 3.4444527626037598
Validation loss: 2.771566390991211

Epoch: 5| Step: 9
Training loss: 3.059345006942749
Validation loss: 2.7691517517130864

Epoch: 5| Step: 10
Training loss: 3.0955188274383545
Validation loss: 2.7429129564633934

Epoch: 25| Step: 0
Training loss: 3.0042426586151123
Validation loss: 2.7495843671983287

Epoch: 5| Step: 1
Training loss: 3.012965440750122
Validation loss: 2.720544820190758

Epoch: 5| Step: 2
Training loss: 2.875181198120117
Validation loss: 2.7286139534365748

Epoch: 5| Step: 3
Training loss: 3.0433578491210938
Validation loss: 2.7295251764276975

Epoch: 5| Step: 4
Training loss: 2.690396547317505
Validation loss: 2.712462986669233

Epoch: 5| Step: 5
Training loss: 1.6822353601455688
Validation loss: 2.720196639337847

Epoch: 5| Step: 6
Training loss: 3.0324769020080566
Validation loss: 2.750217189070999

Epoch: 5| Step: 7
Training loss: 3.497126340866089
Validation loss: 2.772035388536351

Epoch: 5| Step: 8
Training loss: 3.1150972843170166
Validation loss: 2.7723472708015033

Epoch: 5| Step: 9
Training loss: 3.420731782913208
Validation loss: 2.7677454204969507

Epoch: 5| Step: 10
Training loss: 2.537548065185547
Validation loss: 2.747793048940679

Epoch: 26| Step: 0
Training loss: 3.72404146194458
Validation loss: 2.7074031060741794

Epoch: 5| Step: 1
Training loss: 2.5108754634857178
Validation loss: 2.715500065075454

Epoch: 5| Step: 2
Training loss: 2.9760918617248535
Validation loss: 2.77780899693889

Epoch: 5| Step: 3
Training loss: 3.039374828338623
Validation loss: 2.8417534238548687

Epoch: 5| Step: 4
Training loss: 2.5537593364715576
Validation loss: 2.8175467778277654

Epoch: 5| Step: 5
Training loss: 3.3020501136779785
Validation loss: 2.7793158049224527

Epoch: 5| Step: 6
Training loss: 2.3567957878112793
Validation loss: 2.736620718433011

Epoch: 5| Step: 7
Training loss: 2.380654811859131
Validation loss: 2.7081488255531556

Epoch: 5| Step: 8
Training loss: 3.033966541290283
Validation loss: 2.6984380291354273

Epoch: 5| Step: 9
Training loss: 2.706101655960083
Validation loss: 2.6961884319141345

Epoch: 5| Step: 10
Training loss: 3.3934130668640137
Validation loss: 2.696734925752045

Epoch: 27| Step: 0
Training loss: 1.9022178649902344
Validation loss: 2.694689025161087

Epoch: 5| Step: 1
Training loss: 2.8881313800811768
Validation loss: 2.6953074239915416

Epoch: 5| Step: 2
Training loss: 2.787865400314331
Validation loss: 2.7196030975669943

Epoch: 5| Step: 3
Training loss: 2.7688000202178955
Validation loss: 2.710967540740967

Epoch: 5| Step: 4
Training loss: 2.915966749191284
Validation loss: 2.690365009410407

Epoch: 5| Step: 5
Training loss: 3.090904951095581
Validation loss: 2.6854687377970707

Epoch: 5| Step: 6
Training loss: 3.171464443206787
Validation loss: 2.6833313741991596

Epoch: 5| Step: 7
Training loss: 3.3805630207061768
Validation loss: 2.7149123581506873

Epoch: 5| Step: 8
Training loss: 2.630026340484619
Validation loss: 2.7004040915478944

Epoch: 5| Step: 9
Training loss: 2.766801357269287
Validation loss: 2.688090214165308

Epoch: 5| Step: 10
Training loss: 3.125131607055664
Validation loss: 2.686915636062622

Epoch: 28| Step: 0
Training loss: 2.7177200317382812
Validation loss: 2.6696731121309343

Epoch: 5| Step: 1
Training loss: 3.0012807846069336
Validation loss: 2.6666965946074455

Epoch: 5| Step: 2
Training loss: 3.5259265899658203
Validation loss: 2.6671892135374007

Epoch: 5| Step: 3
Training loss: 2.905388832092285
Validation loss: 2.664872520713396

Epoch: 5| Step: 4
Training loss: 2.8729496002197266
Validation loss: 2.6641027132670083

Epoch: 5| Step: 5
Training loss: 2.8054001331329346
Validation loss: 2.6575670780674105

Epoch: 5| Step: 6
Training loss: 2.2760539054870605
Validation loss: 2.6571413445216354

Epoch: 5| Step: 7
Training loss: 2.8373048305511475
Validation loss: 2.6531693525211786

Epoch: 5| Step: 8
Training loss: 3.0033950805664062
Validation loss: 2.6489642896959857

Epoch: 5| Step: 9
Training loss: 2.150719165802002
Validation loss: 2.6414896724044636

Epoch: 5| Step: 10
Training loss: 3.1036040782928467
Validation loss: 2.6340885726354455

Epoch: 29| Step: 0
Training loss: 3.130840301513672
Validation loss: 2.6430463021801365

Epoch: 5| Step: 1
Training loss: 3.06528639793396
Validation loss: 2.6671678737927507

Epoch: 5| Step: 2
Training loss: 3.07279896736145
Validation loss: 2.657488420445432

Epoch: 5| Step: 3
Training loss: 3.094257354736328
Validation loss: 2.638689958921043

Epoch: 5| Step: 4
Training loss: 2.8986425399780273
Validation loss: 2.625301089338077

Epoch: 5| Step: 5
Training loss: 2.874107837677002
Validation loss: 2.6298469625493532

Epoch: 5| Step: 6
Training loss: 2.4177136421203613
Validation loss: 2.6331426097500708

Epoch: 5| Step: 7
Training loss: 2.5433156490325928
Validation loss: 2.634256128341921

Epoch: 5| Step: 8
Training loss: 2.783900737762451
Validation loss: 2.6342751595281784

Epoch: 5| Step: 9
Training loss: 2.38219952583313
Validation loss: 2.6304626003388436

Epoch: 5| Step: 10
Training loss: 2.72477388381958
Validation loss: 2.6319999438460155

Epoch: 30| Step: 0
Training loss: 3.8316664695739746
Validation loss: 2.6473352421996412

Epoch: 5| Step: 1
Training loss: 2.2445900440216064
Validation loss: 2.6727646858461442

Epoch: 5| Step: 2
Training loss: 2.947317600250244
Validation loss: 2.6652601611229683

Epoch: 5| Step: 3
Training loss: 2.38604474067688
Validation loss: 2.642469229236726

Epoch: 5| Step: 4
Training loss: 2.4831414222717285
Validation loss: 2.622840819820281

Epoch: 5| Step: 5
Training loss: 3.3963210582733154
Validation loss: 2.630275603263609

Epoch: 5| Step: 6
Training loss: 2.8283469676971436
Validation loss: 2.625246483792541

Epoch: 5| Step: 7
Training loss: 2.319946765899658
Validation loss: 2.6234856010765157

Epoch: 5| Step: 8
Training loss: 2.5151920318603516
Validation loss: 2.621176532519761

Epoch: 5| Step: 9
Training loss: 2.6368825435638428
Validation loss: 2.615986954781317

Epoch: 5| Step: 10
Training loss: 3.4181935787200928
Validation loss: 2.6170393164439867

Epoch: 31| Step: 0
Training loss: 2.338871479034424
Validation loss: 2.6215796291187243

Epoch: 5| Step: 1
Training loss: 2.7871336936950684
Validation loss: 2.6175840644426245

Epoch: 5| Step: 2
Training loss: 2.955641746520996
Validation loss: 2.630805141182356

Epoch: 5| Step: 3
Training loss: 2.948728322982788
Validation loss: 2.6260612395501908

Epoch: 5| Step: 4
Training loss: 2.712576389312744
Validation loss: 2.61430053300755

Epoch: 5| Step: 5
Training loss: 2.8422741889953613
Validation loss: 2.6088469489928214

Epoch: 5| Step: 6
Training loss: 2.740792751312256
Validation loss: 2.605901213102443

Epoch: 5| Step: 7
Training loss: 3.0835766792297363
Validation loss: 2.6051936380324827

Epoch: 5| Step: 8
Training loss: 2.8509483337402344
Validation loss: 2.608856903609409

Epoch: 5| Step: 9
Training loss: 2.5810611248016357
Validation loss: 2.6028608609271306

Epoch: 5| Step: 10
Training loss: 2.862981081008911
Validation loss: 2.6039708404130835

Epoch: 32| Step: 0
Training loss: 2.2282826900482178
Validation loss: 2.599376634884906

Epoch: 5| Step: 1
Training loss: 3.0687096118927
Validation loss: 2.601259159785445

Epoch: 5| Step: 2
Training loss: 2.6563644409179688
Validation loss: 2.6064245393199306

Epoch: 5| Step: 3
Training loss: 1.9849436283111572
Validation loss: 2.6032074651410504

Epoch: 5| Step: 4
Training loss: 2.920654773712158
Validation loss: 2.6041126251220703

Epoch: 5| Step: 5
Training loss: 3.2310385704040527
Validation loss: 2.600185614760204

Epoch: 5| Step: 6
Training loss: 2.8187479972839355
Validation loss: 2.605905097018006

Epoch: 5| Step: 7
Training loss: 2.9075989723205566
Validation loss: 2.6117364616804224

Epoch: 5| Step: 8
Training loss: 3.2723655700683594
Validation loss: 2.6031955570302983

Epoch: 5| Step: 9
Training loss: 3.002150058746338
Validation loss: 2.6047318238084034

Epoch: 5| Step: 10
Training loss: 2.548809289932251
Validation loss: 2.5960678874805407

Epoch: 33| Step: 0
Training loss: 2.3973255157470703
Validation loss: 2.5934448934370473

Epoch: 5| Step: 1
Training loss: 3.359394073486328
Validation loss: 2.595645837886359

Epoch: 5| Step: 2
Training loss: 2.6773738861083984
Validation loss: 2.597022292434528

Epoch: 5| Step: 3
Training loss: 3.0203020572662354
Validation loss: 2.6122850730854976

Epoch: 5| Step: 4
Training loss: 2.9908533096313477
Validation loss: 2.6076257818488666

Epoch: 5| Step: 5
Training loss: 2.997633695602417
Validation loss: 2.5985600794515302

Epoch: 5| Step: 6
Training loss: 2.102252244949341
Validation loss: 2.5926364185989543

Epoch: 5| Step: 7
Training loss: 3.170527696609497
Validation loss: 2.5896439219033844

Epoch: 5| Step: 8
Training loss: 2.887572765350342
Validation loss: 2.585654012618526

Epoch: 5| Step: 9
Training loss: 2.4486887454986572
Validation loss: 2.5903716484705606

Epoch: 5| Step: 10
Training loss: 2.4374284744262695
Validation loss: 2.5932857451900357

Epoch: 34| Step: 0
Training loss: 2.789574146270752
Validation loss: 2.593975768294386

Epoch: 5| Step: 1
Training loss: 3.4558608531951904
Validation loss: 2.6109901935823503

Epoch: 5| Step: 2
Training loss: 2.4302456378936768
Validation loss: 2.6803636397084882

Epoch: 5| Step: 3
Training loss: 2.7428665161132812
Validation loss: 2.658861619169994

Epoch: 5| Step: 4
Training loss: 2.8845813274383545
Validation loss: 2.585375339754166

Epoch: 5| Step: 5
Training loss: 2.153642177581787
Validation loss: 2.583175536124937

Epoch: 5| Step: 6
Training loss: 3.2871909141540527
Validation loss: 2.601410993965723

Epoch: 5| Step: 7
Training loss: 2.4426839351654053
Validation loss: 2.6204625252754457

Epoch: 5| Step: 8
Training loss: 3.026669979095459
Validation loss: 2.6559047237519295

Epoch: 5| Step: 9
Training loss: 2.893569231033325
Validation loss: 2.6425625355012956

Epoch: 5| Step: 10
Training loss: 2.641688108444214
Validation loss: 2.607044061024984

Epoch: 35| Step: 0
Training loss: 2.7031376361846924
Validation loss: 2.5906724224808397

Epoch: 5| Step: 1
Training loss: 3.069812059402466
Validation loss: 2.576856820814071

Epoch: 5| Step: 2
Training loss: 2.6703975200653076
Validation loss: 2.5714863577196674

Epoch: 5| Step: 3
Training loss: 2.0472912788391113
Validation loss: 2.5913810653071248

Epoch: 5| Step: 4
Training loss: 3.2374184131622314
Validation loss: 2.618071663764215

Epoch: 5| Step: 5
Training loss: 2.232379674911499
Validation loss: 2.606825145342017

Epoch: 5| Step: 6
Training loss: 3.423248767852783
Validation loss: 2.583363781693161

Epoch: 5| Step: 7
Training loss: 3.393723964691162
Validation loss: 2.5728499786828154

Epoch: 5| Step: 8
Training loss: 2.7701492309570312
Validation loss: 2.5661819596444406

Epoch: 5| Step: 9
Training loss: 2.421128749847412
Validation loss: 2.567881243203276

Epoch: 5| Step: 10
Training loss: 2.500471830368042
Validation loss: 2.5659078731331775

Epoch: 36| Step: 0
Training loss: 3.044227361679077
Validation loss: 2.5657867026585404

Epoch: 5| Step: 1
Training loss: 3.271695375442505
Validation loss: 2.567903403312929

Epoch: 5| Step: 2
Training loss: 2.5258750915527344
Validation loss: 2.566123467619701

Epoch: 5| Step: 3
Training loss: 2.5794177055358887
Validation loss: 2.5646703320164836

Epoch: 5| Step: 4
Training loss: 3.017998695373535
Validation loss: 2.5690895280530377

Epoch: 5| Step: 5
Training loss: 3.0595905780792236
Validation loss: 2.5751674431626514

Epoch: 5| Step: 6
Training loss: 2.4843873977661133
Validation loss: 2.60174879207406

Epoch: 5| Step: 7
Training loss: 2.32957124710083
Validation loss: 2.613233409902101

Epoch: 5| Step: 8
Training loss: 2.1054906845092773
Validation loss: 2.5828016855383433

Epoch: 5| Step: 9
Training loss: 3.021456003189087
Validation loss: 2.563758183551091

Epoch: 5| Step: 10
Training loss: 2.8802101612091064
Validation loss: 2.5605462597262476

Epoch: 37| Step: 0
Training loss: 3.0138628482818604
Validation loss: 2.566518304168537

Epoch: 5| Step: 1
Training loss: 3.0160670280456543
Validation loss: 2.5697236599460727

Epoch: 5| Step: 2
Training loss: 3.0619945526123047
Validation loss: 2.5775150099108295

Epoch: 5| Step: 3
Training loss: 2.9811320304870605
Validation loss: 2.5680683120604484

Epoch: 5| Step: 4
Training loss: 2.6287262439727783
Validation loss: 2.5617184459522204

Epoch: 5| Step: 5
Training loss: 2.5710761547088623
Validation loss: 2.5612389708078034

Epoch: 5| Step: 6
Training loss: 3.2193055152893066
Validation loss: 2.554043480145034

Epoch: 5| Step: 7
Training loss: 2.45076060295105
Validation loss: 2.5534782153303905

Epoch: 5| Step: 8
Training loss: 2.448817729949951
Validation loss: 2.556422887309905

Epoch: 5| Step: 9
Training loss: 2.192911148071289
Validation loss: 2.56175091702451

Epoch: 5| Step: 10
Training loss: 2.635841131210327
Validation loss: 2.5701226444654566

Epoch: 38| Step: 0
Training loss: 3.1586625576019287
Validation loss: 2.5835167900208504

Epoch: 5| Step: 1
Training loss: 2.5677592754364014
Validation loss: 2.5900829709986204

Epoch: 5| Step: 2
Training loss: 2.2711997032165527
Validation loss: 2.576030538928124

Epoch: 5| Step: 3
Training loss: 2.3907077312469482
Validation loss: 2.560782737629388

Epoch: 5| Step: 4
Training loss: 2.939155340194702
Validation loss: 2.5482284971462783

Epoch: 5| Step: 5
Training loss: 2.93965220451355
Validation loss: 2.5435380448577223

Epoch: 5| Step: 6
Training loss: 3.450695037841797
Validation loss: 2.5456673663149596

Epoch: 5| Step: 7
Training loss: 2.5454859733581543
Validation loss: 2.5473631299952024

Epoch: 5| Step: 8
Training loss: 2.8871328830718994
Validation loss: 2.5498962620253205

Epoch: 5| Step: 9
Training loss: 2.664628505706787
Validation loss: 2.546091766767604

Epoch: 5| Step: 10
Training loss: 2.3019917011260986
Validation loss: 2.5454975815229517

Epoch: 39| Step: 0
Training loss: 2.5981712341308594
Validation loss: 2.5425878570925806

Epoch: 5| Step: 1
Training loss: 3.694685459136963
Validation loss: 2.5374633291716218

Epoch: 5| Step: 2
Training loss: 2.7850639820098877
Validation loss: 2.5367832440201954

Epoch: 5| Step: 3
Training loss: 2.6728005409240723
Validation loss: 2.5421501782632645

Epoch: 5| Step: 4
Training loss: 2.7134664058685303
Validation loss: 2.561367255385204

Epoch: 5| Step: 5
Training loss: 3.08262038230896
Validation loss: 2.5892019476941837

Epoch: 5| Step: 6
Training loss: 3.048475742340088
Validation loss: 2.5689792889420704

Epoch: 5| Step: 7
Training loss: 2.2417092323303223
Validation loss: 2.5709775160717707

Epoch: 5| Step: 8
Training loss: 2.0216822624206543
Validation loss: 2.566552787698725

Epoch: 5| Step: 9
Training loss: 2.634260654449463
Validation loss: 2.5670686998674945

Epoch: 5| Step: 10
Training loss: 2.4439046382904053
Validation loss: 2.564357752441078

Epoch: 40| Step: 0
Training loss: 3.31846284866333
Validation loss: 2.5561039678512083

Epoch: 5| Step: 1
Training loss: 3.00299334526062
Validation loss: 2.541522076053004

Epoch: 5| Step: 2
Training loss: 2.0219154357910156
Validation loss: 2.5383987196030153

Epoch: 5| Step: 3
Training loss: 2.5481085777282715
Validation loss: 2.5412226543631604

Epoch: 5| Step: 4
Training loss: 2.571911096572876
Validation loss: 2.539086118821175

Epoch: 5| Step: 5
Training loss: 2.38264536857605
Validation loss: 2.5404089650800152

Epoch: 5| Step: 6
Training loss: 3.2338497638702393
Validation loss: 2.5414246769361597

Epoch: 5| Step: 7
Training loss: 2.609586238861084
Validation loss: 2.5379295784940004

Epoch: 5| Step: 8
Training loss: 2.736501693725586
Validation loss: 2.531919453733711

Epoch: 5| Step: 9
Training loss: 2.9931633472442627
Validation loss: 2.5356669015781854

Epoch: 5| Step: 10
Training loss: 2.477018356323242
Validation loss: 2.5595674181497223

Epoch: 41| Step: 0
Training loss: 2.839045763015747
Validation loss: 2.600256384059947

Epoch: 5| Step: 1
Training loss: 3.075204372406006
Validation loss: 2.658232304357713

Epoch: 5| Step: 2
Training loss: 2.6081366539001465
Validation loss: 2.6093590259552

Epoch: 5| Step: 3
Training loss: 3.124101400375366
Validation loss: 2.567138853893485

Epoch: 5| Step: 4
Training loss: 2.6481804847717285
Validation loss: 2.5361228912107405

Epoch: 5| Step: 5
Training loss: 3.2157084941864014
Validation loss: 2.525574932816208

Epoch: 5| Step: 6
Training loss: 2.269558906555176
Validation loss: 2.5283386245850594

Epoch: 5| Step: 7
Training loss: 2.476893663406372
Validation loss: 2.5339064803174747

Epoch: 5| Step: 8
Training loss: 2.6841845512390137
Validation loss: 2.5521407537562872

Epoch: 5| Step: 9
Training loss: 2.7922420501708984
Validation loss: 2.563016296714865

Epoch: 5| Step: 10
Training loss: 2.4084677696228027
Validation loss: 2.55020647920588

Epoch: 42| Step: 0
Training loss: 2.631967306137085
Validation loss: 2.5463868853866414

Epoch: 5| Step: 1
Training loss: 2.9060094356536865
Validation loss: 2.537263249838224

Epoch: 5| Step: 2
Training loss: 3.1833159923553467
Validation loss: 2.525515542235426

Epoch: 5| Step: 3
Training loss: 2.5824480056762695
Validation loss: 2.5232135788086922

Epoch: 5| Step: 4
Training loss: 2.5083041191101074
Validation loss: 2.5232994530790593

Epoch: 5| Step: 5
Training loss: 2.457134962081909
Validation loss: 2.522440387356666

Epoch: 5| Step: 6
Training loss: 1.9688917398452759
Validation loss: 2.520802726027786

Epoch: 5| Step: 7
Training loss: 2.7820162773132324
Validation loss: 2.516277651632986

Epoch: 5| Step: 8
Training loss: 2.664592742919922
Validation loss: 2.517716428285004

Epoch: 5| Step: 9
Training loss: 3.6511752605438232
Validation loss: 2.513266207069479

Epoch: 5| Step: 10
Training loss: 2.489561080932617
Validation loss: 2.513093968873383

Epoch: 43| Step: 0
Training loss: 2.9536893367767334
Validation loss: 2.513430210851854

Epoch: 5| Step: 1
Training loss: 2.935347557067871
Validation loss: 2.5106416415142756

Epoch: 5| Step: 2
Training loss: 2.5071520805358887
Validation loss: 2.5114565792904107

Epoch: 5| Step: 3
Training loss: 2.792785167694092
Validation loss: 2.5100184050939416

Epoch: 5| Step: 4
Training loss: 2.681593418121338
Validation loss: 2.5130082561123754

Epoch: 5| Step: 5
Training loss: 2.3047871589660645
Validation loss: 2.5144661523962535

Epoch: 5| Step: 6
Training loss: 3.206904649734497
Validation loss: 2.5195491954844487

Epoch: 5| Step: 7
Training loss: 2.070621967315674
Validation loss: 2.5159452730609524

Epoch: 5| Step: 8
Training loss: 3.0090415477752686
Validation loss: 2.5075694258495043

Epoch: 5| Step: 9
Training loss: 2.812486410140991
Validation loss: 2.5071836466430337

Epoch: 5| Step: 10
Training loss: 2.456415891647339
Validation loss: 2.5034209682095434

Epoch: 44| Step: 0
Training loss: 2.707663059234619
Validation loss: 2.5061464155873945

Epoch: 5| Step: 1
Training loss: 3.291133403778076
Validation loss: 2.510995134230583

Epoch: 5| Step: 2
Training loss: 2.4985828399658203
Validation loss: 2.5155952412595033

Epoch: 5| Step: 3
Training loss: 2.699556350708008
Validation loss: 2.5387970785940848

Epoch: 5| Step: 4
Training loss: 2.629849433898926
Validation loss: 2.5056807712842057

Epoch: 5| Step: 5
Training loss: 2.444155216217041
Validation loss: 2.494227542672106

Epoch: 5| Step: 6
Training loss: 2.3813774585723877
Validation loss: 2.50063035949584

Epoch: 5| Step: 7
Training loss: 2.5037739276885986
Validation loss: 2.5064541319365143

Epoch: 5| Step: 8
Training loss: 2.62441349029541
Validation loss: 2.5119054702020462

Epoch: 5| Step: 9
Training loss: 2.361423969268799
Validation loss: 2.54087156890541

Epoch: 5| Step: 10
Training loss: 3.91363263130188
Validation loss: 2.554162517670662

Epoch: 45| Step: 0
Training loss: 2.6795859336853027
Validation loss: 2.5469152465943368

Epoch: 5| Step: 1
Training loss: 2.4567437171936035
Validation loss: 2.5096462388192453

Epoch: 5| Step: 2
Training loss: 2.4489424228668213
Validation loss: 2.5002799034118652

Epoch: 5| Step: 3
Training loss: 2.806800365447998
Validation loss: 2.496745942741312

Epoch: 5| Step: 4
Training loss: 2.554460048675537
Validation loss: 2.4961418259528374

Epoch: 5| Step: 5
Training loss: 2.890289783477783
Validation loss: 2.489377978027508

Epoch: 5| Step: 6
Training loss: 2.717128276824951
Validation loss: 2.4958900123514156

Epoch: 5| Step: 7
Training loss: 2.616868257522583
Validation loss: 2.493819728974373

Epoch: 5| Step: 8
Training loss: 3.2853119373321533
Validation loss: 2.4945785922388874

Epoch: 5| Step: 9
Training loss: 2.1959457397460938
Validation loss: 2.488112126627276

Epoch: 5| Step: 10
Training loss: 3.255770683288574
Validation loss: 2.488594860158941

Epoch: 46| Step: 0
Training loss: 3.0588696002960205
Validation loss: 2.494896255513673

Epoch: 5| Step: 1
Training loss: 1.7872636318206787
Validation loss: 2.5041979230860227

Epoch: 5| Step: 2
Training loss: 2.5913288593292236
Validation loss: 2.5060849035939863

Epoch: 5| Step: 3
Training loss: 3.516711473464966
Validation loss: 2.507994359539401

Epoch: 5| Step: 4
Training loss: 2.893308639526367
Validation loss: 2.5140026512966362

Epoch: 5| Step: 5
Training loss: 3.182034730911255
Validation loss: 2.52352132848514

Epoch: 5| Step: 6
Training loss: 2.3878166675567627
Validation loss: 2.537823664244785

Epoch: 5| Step: 7
Training loss: 2.597928762435913
Validation loss: 2.568266437899682

Epoch: 5| Step: 8
Training loss: 2.6036200523376465
Validation loss: 2.5781693484193537

Epoch: 5| Step: 9
Training loss: 2.550227642059326
Validation loss: 2.5459666098317792

Epoch: 5| Step: 10
Training loss: 2.60795259475708
Validation loss: 2.5006128254757134

Epoch: 47| Step: 0
Training loss: 2.2335495948791504
Validation loss: 2.498516498073455

Epoch: 5| Step: 1
Training loss: 2.7076833248138428
Validation loss: 2.5446133972496114

Epoch: 5| Step: 2
Training loss: 2.941925048828125
Validation loss: 2.5915831647893435

Epoch: 5| Step: 3
Training loss: 2.8626205921173096
Validation loss: 2.624555418568273

Epoch: 5| Step: 4
Training loss: 3.1288859844207764
Validation loss: 2.6312281367599324

Epoch: 5| Step: 5
Training loss: 2.796140193939209
Validation loss: 2.6137342606821368

Epoch: 5| Step: 6
Training loss: 2.6538240909576416
Validation loss: 2.6177829260467202

Epoch: 5| Step: 7
Training loss: 3.3821754455566406
Validation loss: 2.6055200458854757

Epoch: 5| Step: 8
Training loss: 2.4582202434539795
Validation loss: 2.5679371485146145

Epoch: 5| Step: 9
Training loss: 2.941340684890747
Validation loss: 2.5326383677862023

Epoch: 5| Step: 10
Training loss: 2.2407941818237305
Validation loss: 2.5233493979259203

Epoch: 48| Step: 0
Training loss: 2.613551139831543
Validation loss: 2.5347109212670276

Epoch: 5| Step: 1
Training loss: 3.0852155685424805
Validation loss: 2.5570757004522506

Epoch: 5| Step: 2
Training loss: 3.3403420448303223
Validation loss: 2.5641283578770135

Epoch: 5| Step: 3
Training loss: 2.6646978855133057
Validation loss: 2.6339514383705716

Epoch: 5| Step: 4
Training loss: 2.9443397521972656
Validation loss: 2.6137283284177064

Epoch: 5| Step: 5
Training loss: 3.0698800086975098
Validation loss: 2.552265828655612

Epoch: 5| Step: 6
Training loss: 2.6642048358917236
Validation loss: 2.507063329860728

Epoch: 5| Step: 7
Training loss: 2.0635337829589844
Validation loss: 2.4758801075720016

Epoch: 5| Step: 8
Training loss: 2.075871467590332
Validation loss: 2.469439750076622

Epoch: 5| Step: 9
Training loss: 2.5367157459259033
Validation loss: 2.5138649991763535

Epoch: 5| Step: 10
Training loss: 2.8614308834075928
Validation loss: 2.5800055585881716

Epoch: 49| Step: 0
Training loss: 2.521174907684326
Validation loss: 2.641832979776526

Epoch: 5| Step: 1
Training loss: 2.9089550971984863
Validation loss: 2.7024876994471394

Epoch: 5| Step: 2
Training loss: 3.2095541954040527
Validation loss: 2.606309654892132

Epoch: 5| Step: 3
Training loss: 2.557138204574585
Validation loss: 2.5081898268832954

Epoch: 5| Step: 4
Training loss: 2.5853495597839355
Validation loss: 2.4663658347181094

Epoch: 5| Step: 5
Training loss: 2.9817309379577637
Validation loss: 2.4690121937823553

Epoch: 5| Step: 6
Training loss: 2.539768695831299
Validation loss: 2.5109980234535794

Epoch: 5| Step: 7
Training loss: 2.252378463745117
Validation loss: 2.61278780557776

Epoch: 5| Step: 8
Training loss: 3.0679948329925537
Validation loss: 2.746268677455123

Epoch: 5| Step: 9
Training loss: 2.581062078475952
Validation loss: 2.772241279643069

Epoch: 5| Step: 10
Training loss: 3.4704995155334473
Validation loss: 2.6750933226718696

Epoch: 50| Step: 0
Training loss: 3.1605591773986816
Validation loss: 2.572041070589455

Epoch: 5| Step: 1
Training loss: 2.6045327186584473
Validation loss: 2.525978716470862

Epoch: 5| Step: 2
Training loss: 2.749223470687866
Validation loss: 2.5069637580584456

Epoch: 5| Step: 3
Training loss: 3.2635016441345215
Validation loss: 2.5002483539683844

Epoch: 5| Step: 4
Training loss: 2.462190628051758
Validation loss: 2.5109773758919007

Epoch: 5| Step: 5
Training loss: 2.405968427658081
Validation loss: 2.538970478119389

Epoch: 5| Step: 6
Training loss: 3.2640762329101562
Validation loss: 2.566349744796753

Epoch: 5| Step: 7
Training loss: 2.7181379795074463
Validation loss: 2.5479691336231847

Epoch: 5| Step: 8
Training loss: 3.1037795543670654
Validation loss: 2.5211600795868905

Epoch: 5| Step: 9
Training loss: 2.3929829597473145
Validation loss: 2.4937727066778366

Epoch: 5| Step: 10
Training loss: 1.9347902536392212
Validation loss: 2.4965744326191563

Epoch: 51| Step: 0
Training loss: 3.37890887260437
Validation loss: 2.522557568806474

Epoch: 5| Step: 1
Training loss: 2.8326241970062256
Validation loss: 2.531483519461847

Epoch: 5| Step: 2
Training loss: 2.354483127593994
Validation loss: 2.53512135628731

Epoch: 5| Step: 3
Training loss: 2.3486363887786865
Validation loss: 2.54977148835377

Epoch: 5| Step: 4
Training loss: 2.36388897895813
Validation loss: 2.555127272041895

Epoch: 5| Step: 5
Training loss: 2.7261962890625
Validation loss: 2.5626972054922454

Epoch: 5| Step: 6
Training loss: 2.4675135612487793
Validation loss: 2.546665827433268

Epoch: 5| Step: 7
Training loss: 2.3402278423309326
Validation loss: 2.5439886123903337

Epoch: 5| Step: 8
Training loss: 2.6160502433776855
Validation loss: 2.536789337793986

Epoch: 5| Step: 9
Training loss: 3.310272693634033
Validation loss: 2.541634923668318

Epoch: 5| Step: 10
Training loss: 3.3526651859283447
Validation loss: 2.560579220453898

Epoch: 52| Step: 0
Training loss: 3.4991016387939453
Validation loss: 2.540276094149518

Epoch: 5| Step: 1
Training loss: 2.99862003326416
Validation loss: 2.522457504785189

Epoch: 5| Step: 2
Training loss: 2.491295337677002
Validation loss: 2.5120613395526843

Epoch: 5| Step: 3
Training loss: 2.2375855445861816
Validation loss: 2.507731048009729

Epoch: 5| Step: 4
Training loss: 2.273925304412842
Validation loss: 2.503567869945239

Epoch: 5| Step: 5
Training loss: 3.0008702278137207
Validation loss: 2.4976767211832027

Epoch: 5| Step: 6
Training loss: 3.235840320587158
Validation loss: 2.49070047050394

Epoch: 5| Step: 7
Training loss: 2.5289206504821777
Validation loss: 2.492830837926557

Epoch: 5| Step: 8
Training loss: 2.742182970046997
Validation loss: 2.4940351158060055

Epoch: 5| Step: 9
Training loss: 2.643192768096924
Validation loss: 2.4970253026613625

Epoch: 5| Step: 10
Training loss: 2.0398075580596924
Validation loss: 2.5106461099399033

Epoch: 53| Step: 0
Training loss: 2.7310686111450195
Validation loss: 2.5560441606788227

Epoch: 5| Step: 1
Training loss: 2.8783137798309326
Validation loss: 2.5968730039494012

Epoch: 5| Step: 2
Training loss: 2.6670174598693848
Validation loss: 2.5735956161252913

Epoch: 5| Step: 3
Training loss: 2.9910476207733154
Validation loss: 2.5333638242495957

Epoch: 5| Step: 4
Training loss: 2.1538376808166504
Validation loss: 2.4942890597927954

Epoch: 5| Step: 5
Training loss: 2.4864401817321777
Validation loss: 2.4649620709880704

Epoch: 5| Step: 6
Training loss: 2.364199638366699
Validation loss: 2.464505457109021

Epoch: 5| Step: 7
Training loss: 2.63749361038208
Validation loss: 2.45489187266237

Epoch: 5| Step: 8
Training loss: 2.689545154571533
Validation loss: 2.4444927118157826

Epoch: 5| Step: 9
Training loss: 3.469022035598755
Validation loss: 2.444947850319647

Epoch: 5| Step: 10
Training loss: 2.6191952228546143
Validation loss: 2.440430760383606

Epoch: 54| Step: 0
Training loss: 2.1742329597473145
Validation loss: 2.4280014422632035

Epoch: 5| Step: 1
Training loss: 2.913844347000122
Validation loss: 2.431107072420018

Epoch: 5| Step: 2
Training loss: 2.9188733100891113
Validation loss: 2.4196185860582577

Epoch: 5| Step: 3
Training loss: 2.4667420387268066
Validation loss: 2.4214764512995237

Epoch: 5| Step: 4
Training loss: 2.4175617694854736
Validation loss: 2.418146305186774

Epoch: 5| Step: 5
Training loss: 3.179513454437256
Validation loss: 2.4145890589683288

Epoch: 5| Step: 6
Training loss: 2.30006742477417
Validation loss: 2.4133770978578957

Epoch: 5| Step: 7
Training loss: 2.989497423171997
Validation loss: 2.419289137727471

Epoch: 5| Step: 8
Training loss: 2.9361069202423096
Validation loss: 2.422046438340218

Epoch: 5| Step: 9
Training loss: 2.3257217407226562
Validation loss: 2.4253858955957557

Epoch: 5| Step: 10
Training loss: 2.6369102001190186
Validation loss: 2.4460106459997033

Epoch: 55| Step: 0
Training loss: 2.23376727104187
Validation loss: 2.4517199608587448

Epoch: 5| Step: 1
Training loss: 3.3872389793395996
Validation loss: 2.463659160880632

Epoch: 5| Step: 2
Training loss: 2.3317501544952393
Validation loss: 2.456707767260972

Epoch: 5| Step: 3
Training loss: 3.278841495513916
Validation loss: 2.4387568017487884

Epoch: 5| Step: 4
Training loss: 1.9692741632461548
Validation loss: 2.4201264394226896

Epoch: 5| Step: 5
Training loss: 2.0409443378448486
Validation loss: 2.4155409566817747

Epoch: 5| Step: 6
Training loss: 3.2926433086395264
Validation loss: 2.4075515347142376

Epoch: 5| Step: 7
Training loss: 1.918335199356079
Validation loss: 2.409920564261816

Epoch: 5| Step: 8
Training loss: 2.719999074935913
Validation loss: 2.4082961928459907

Epoch: 5| Step: 9
Training loss: 2.661571502685547
Validation loss: 2.405791687709029

Epoch: 5| Step: 10
Training loss: 3.5011041164398193
Validation loss: 2.4022240459278064

Epoch: 56| Step: 0
Training loss: 2.650320529937744
Validation loss: 2.400707314091344

Epoch: 5| Step: 1
Training loss: 1.9185899496078491
Validation loss: 2.4003314959105624

Epoch: 5| Step: 2
Training loss: 2.950700283050537
Validation loss: 2.3996008621749056

Epoch: 5| Step: 3
Training loss: 1.8910377025604248
Validation loss: 2.400328920733544

Epoch: 5| Step: 4
Training loss: 3.1501145362854004
Validation loss: 2.399992671064151

Epoch: 5| Step: 5
Training loss: 2.4244601726531982
Validation loss: 2.399358105915849

Epoch: 5| Step: 6
Training loss: 2.384334087371826
Validation loss: 2.393539064673967

Epoch: 5| Step: 7
Training loss: 3.9482688903808594
Validation loss: 2.3908205083621445

Epoch: 5| Step: 8
Training loss: 2.616593837738037
Validation loss: 2.3905474396162134

Epoch: 5| Step: 9
Training loss: 2.7645745277404785
Validation loss: 2.3904320014420377

Epoch: 5| Step: 10
Training loss: 2.4348485469818115
Validation loss: 2.3924614703783424

Epoch: 57| Step: 0
Training loss: 2.632986545562744
Validation loss: 2.3922569405648018

Epoch: 5| Step: 1
Training loss: 2.737938165664673
Validation loss: 2.3954316198184924

Epoch: 5| Step: 2
Training loss: 2.10372257232666
Validation loss: 2.395309543096891

Epoch: 5| Step: 3
Training loss: 2.6142566204071045
Validation loss: 2.399069993726669

Epoch: 5| Step: 4
Training loss: 2.5797958374023438
Validation loss: 2.3997368248560096

Epoch: 5| Step: 5
Training loss: 2.656400442123413
Validation loss: 2.410998813567623

Epoch: 5| Step: 6
Training loss: 2.1648030281066895
Validation loss: 2.4040134209458546

Epoch: 5| Step: 7
Training loss: 3.26179575920105
Validation loss: 2.411867992852324

Epoch: 5| Step: 8
Training loss: 2.92834210395813
Validation loss: 2.4057407033058906

Epoch: 5| Step: 9
Training loss: 2.984663724899292
Validation loss: 2.399315828918129

Epoch: 5| Step: 10
Training loss: 2.3377859592437744
Validation loss: 2.3937111695607505

Epoch: 58| Step: 0
Training loss: 2.810298204421997
Validation loss: 2.3932126029845207

Epoch: 5| Step: 1
Training loss: 3.1454079151153564
Validation loss: 2.389572997247019

Epoch: 5| Step: 2
Training loss: 2.1365180015563965
Validation loss: 2.38926419391427

Epoch: 5| Step: 3
Training loss: 3.359919786453247
Validation loss: 2.3861772424431256

Epoch: 5| Step: 4
Training loss: 2.9667980670928955
Validation loss: 2.387006705807101

Epoch: 5| Step: 5
Training loss: 2.0655884742736816
Validation loss: 2.38504256227965

Epoch: 5| Step: 6
Training loss: 2.675034761428833
Validation loss: 2.384473390476678

Epoch: 5| Step: 7
Training loss: 2.535651683807373
Validation loss: 2.384498793591735

Epoch: 5| Step: 8
Training loss: 3.1980278491973877
Validation loss: 2.391209325482768

Epoch: 5| Step: 9
Training loss: 2.0171499252319336
Validation loss: 2.390454420479395

Epoch: 5| Step: 10
Training loss: 2.034403085708618
Validation loss: 2.390035311381022

Epoch: 59| Step: 0
Training loss: 2.521265745162964
Validation loss: 2.385111149921212

Epoch: 5| Step: 1
Training loss: 2.967176914215088
Validation loss: 2.382103971255723

Epoch: 5| Step: 2
Training loss: 3.1211037635803223
Validation loss: 2.376783165880429

Epoch: 5| Step: 3
Training loss: 2.6222903728485107
Validation loss: 2.3816060148259646

Epoch: 5| Step: 4
Training loss: 2.414053440093994
Validation loss: 2.371508716255106

Epoch: 5| Step: 5
Training loss: 2.6541340351104736
Validation loss: 2.3678645292917886

Epoch: 5| Step: 6
Training loss: 2.8464274406433105
Validation loss: 2.3698867520978375

Epoch: 5| Step: 7
Training loss: 2.295572280883789
Validation loss: 2.370112208909886

Epoch: 5| Step: 8
Training loss: 2.3831658363342285
Validation loss: 2.370581452564527

Epoch: 5| Step: 9
Training loss: 2.9308974742889404
Validation loss: 2.373310330093548

Epoch: 5| Step: 10
Training loss: 2.058349609375
Validation loss: 2.3668449745383313

Epoch: 60| Step: 0
Training loss: 1.9478471279144287
Validation loss: 2.3697759412950083

Epoch: 5| Step: 1
Training loss: 2.524109125137329
Validation loss: 2.368126905092629

Epoch: 5| Step: 2
Training loss: 3.048781633377075
Validation loss: 2.3670428440135014

Epoch: 5| Step: 3
Training loss: 2.838407039642334
Validation loss: 2.3671880588736585

Epoch: 5| Step: 4
Training loss: 2.851627826690674
Validation loss: 2.3737741055027133

Epoch: 5| Step: 5
Training loss: 2.8037467002868652
Validation loss: 2.368914178622666

Epoch: 5| Step: 6
Training loss: 2.5086052417755127
Validation loss: 2.368941806977795

Epoch: 5| Step: 7
Training loss: 2.582134962081909
Validation loss: 2.372502496165614

Epoch: 5| Step: 8
Training loss: 2.706143617630005
Validation loss: 2.3762610291921966

Epoch: 5| Step: 9
Training loss: 2.193516254425049
Validation loss: 2.389463363155242

Epoch: 5| Step: 10
Training loss: 2.8266215324401855
Validation loss: 2.3777285288738947

Epoch: 61| Step: 0
Training loss: 2.8627352714538574
Validation loss: 2.4006826954503215

Epoch: 5| Step: 1
Training loss: 2.6907601356506348
Validation loss: 2.4085715201593216

Epoch: 5| Step: 2
Training loss: 2.6921448707580566
Validation loss: 2.388279681564659

Epoch: 5| Step: 3
Training loss: 2.4562013149261475
Validation loss: 2.3898032224306496

Epoch: 5| Step: 4
Training loss: 3.4363532066345215
Validation loss: 2.384562143715479

Epoch: 5| Step: 5
Training loss: 2.300110101699829
Validation loss: 2.391805092493693

Epoch: 5| Step: 6
Training loss: 2.7118172645568848
Validation loss: 2.3923845650047384

Epoch: 5| Step: 7
Training loss: 2.3703646659851074
Validation loss: 2.393891737025271

Epoch: 5| Step: 8
Training loss: 2.2595882415771484
Validation loss: 2.396989894169633

Epoch: 5| Step: 9
Training loss: 2.521026134490967
Validation loss: 2.38881593109459

Epoch: 5| Step: 10
Training loss: 2.5370304584503174
Validation loss: 2.377585849454326

Epoch: 62| Step: 0
Training loss: 2.8465349674224854
Validation loss: 2.374818822389008

Epoch: 5| Step: 1
Training loss: 2.613194227218628
Validation loss: 2.3715895811716714

Epoch: 5| Step: 2
Training loss: 2.5821971893310547
Validation loss: 2.3707689059677945

Epoch: 5| Step: 3
Training loss: 2.2369866371154785
Validation loss: 2.366636532609181

Epoch: 5| Step: 4
Training loss: 3.1821835041046143
Validation loss: 2.369071170847903

Epoch: 5| Step: 5
Training loss: 2.4389736652374268
Validation loss: 2.3615235743984098

Epoch: 5| Step: 6
Training loss: 2.2537338733673096
Validation loss: 2.3570971924771547

Epoch: 5| Step: 7
Training loss: 2.9122061729431152
Validation loss: 2.3600774708614556

Epoch: 5| Step: 8
Training loss: 2.3816702365875244
Validation loss: 2.3634180997007634

Epoch: 5| Step: 9
Training loss: 2.2155869007110596
Validation loss: 2.3582203490759737

Epoch: 5| Step: 10
Training loss: 3.364683151245117
Validation loss: 2.3565491655821442

Epoch: 63| Step: 0
Training loss: 2.922534942626953
Validation loss: 2.355841149565994

Epoch: 5| Step: 1
Training loss: 2.355483293533325
Validation loss: 2.351518525872179

Epoch: 5| Step: 2
Training loss: 2.5379817485809326
Validation loss: 2.3526573322152577

Epoch: 5| Step: 3
Training loss: 3.085672616958618
Validation loss: 2.3465935235382407

Epoch: 5| Step: 4
Training loss: 2.941903591156006
Validation loss: 2.3591620332451275

Epoch: 5| Step: 5
Training loss: 2.6431708335876465
Validation loss: 2.375754779384982

Epoch: 5| Step: 6
Training loss: 1.8470942974090576
Validation loss: 2.3914737457870157

Epoch: 5| Step: 7
Training loss: 2.7745234966278076
Validation loss: 2.401729058193904

Epoch: 5| Step: 8
Training loss: 2.5724573135375977
Validation loss: 2.424614329491892

Epoch: 5| Step: 9
Training loss: 2.232691526412964
Validation loss: 2.4153090830772155

Epoch: 5| Step: 10
Training loss: 2.8761751651763916
Validation loss: 2.38346185991841

Epoch: 64| Step: 0
Training loss: 3.0518276691436768
Validation loss: 2.3472442857680784

Epoch: 5| Step: 1
Training loss: 2.635439395904541
Validation loss: 2.3354021067260415

Epoch: 5| Step: 2
Training loss: 1.7642364501953125
Validation loss: 2.3405574111528296

Epoch: 5| Step: 3
Training loss: 2.7949137687683105
Validation loss: 2.3524970649391093

Epoch: 5| Step: 4
Training loss: 3.0277342796325684
Validation loss: 2.3532774474031184

Epoch: 5| Step: 5
Training loss: 2.9465346336364746
Validation loss: 2.3710716052721907

Epoch: 5| Step: 6
Training loss: 2.7249252796173096
Validation loss: 2.383170263741606

Epoch: 5| Step: 7
Training loss: 2.307905673980713
Validation loss: 2.3838953202770603

Epoch: 5| Step: 8
Training loss: 2.5438289642333984
Validation loss: 2.3801856528046312

Epoch: 5| Step: 9
Training loss: 2.517791509628296
Validation loss: 2.3686115062364967

Epoch: 5| Step: 10
Training loss: 2.797804832458496
Validation loss: 2.355691804680773

Epoch: 65| Step: 0
Training loss: 2.7591404914855957
Validation loss: 2.342527594617618

Epoch: 5| Step: 1
Training loss: 2.4835073947906494
Validation loss: 2.3461438558434926

Epoch: 5| Step: 2
Training loss: 2.609879970550537
Validation loss: 2.347011422598234

Epoch: 5| Step: 3
Training loss: 2.4535446166992188
Validation loss: 2.344922932245398

Epoch: 5| Step: 4
Training loss: 2.8685431480407715
Validation loss: 2.3437313930962675

Epoch: 5| Step: 5
Training loss: 2.717130661010742
Validation loss: 2.357468315350112

Epoch: 5| Step: 6
Training loss: 2.3544464111328125
Validation loss: 2.362019346606347

Epoch: 5| Step: 7
Training loss: 2.5386404991149902
Validation loss: 2.3730115070137927

Epoch: 5| Step: 8
Training loss: 2.791874408721924
Validation loss: 2.370860956048453

Epoch: 5| Step: 9
Training loss: 2.6550345420837402
Validation loss: 2.3472368947921263

Epoch: 5| Step: 10
Training loss: 2.57637357711792
Validation loss: 2.331968145985757

Epoch: 66| Step: 0
Training loss: 2.829096555709839
Validation loss: 2.3236721023436515

Epoch: 5| Step: 1
Training loss: 3.1827540397644043
Validation loss: 2.3195961688154485

Epoch: 5| Step: 2
Training loss: 2.72910213470459
Validation loss: 2.322488530989616

Epoch: 5| Step: 3
Training loss: 2.6521449089050293
Validation loss: 2.324887316714051

Epoch: 5| Step: 4
Training loss: 2.5564932823181152
Validation loss: 2.322495291309972

Epoch: 5| Step: 5
Training loss: 2.4574897289276123
Validation loss: 2.3292860177255448

Epoch: 5| Step: 6
Training loss: 1.9665858745574951
Validation loss: 2.329043326839324

Epoch: 5| Step: 7
Training loss: 2.413825511932373
Validation loss: 2.3241702587373796

Epoch: 5| Step: 8
Training loss: 2.824951648712158
Validation loss: 2.331026704080643

Epoch: 5| Step: 9
Training loss: 2.4853453636169434
Validation loss: 2.3278879939868884

Epoch: 5| Step: 10
Training loss: 2.7579710483551025
Validation loss: 2.3249728577111357

Epoch: 67| Step: 0
Training loss: 2.9493727684020996
Validation loss: 2.326475694615354

Epoch: 5| Step: 1
Training loss: 2.985713481903076
Validation loss: 2.3182575138666297

Epoch: 5| Step: 2
Training loss: 2.786259174346924
Validation loss: 2.316966679788405

Epoch: 5| Step: 3
Training loss: 2.3455283641815186
Validation loss: 2.315964288609002

Epoch: 5| Step: 4
Training loss: 2.8265392780303955
Validation loss: 2.311409854119824

Epoch: 5| Step: 5
Training loss: 2.208695411682129
Validation loss: 2.3186262538356166

Epoch: 5| Step: 6
Training loss: 2.226511240005493
Validation loss: 2.325228332191385

Epoch: 5| Step: 7
Training loss: 2.480621337890625
Validation loss: 2.3461692089675577

Epoch: 5| Step: 8
Training loss: 3.1731295585632324
Validation loss: 2.364670871406473

Epoch: 5| Step: 9
Training loss: 2.4875762462615967
Validation loss: 2.409646285477505

Epoch: 5| Step: 10
Training loss: 2.2702224254608154
Validation loss: 2.4380110848334526

Epoch: 68| Step: 0
Training loss: 2.2945804595947266
Validation loss: 2.3843210102409444

Epoch: 5| Step: 1
Training loss: 2.910526990890503
Validation loss: 2.350917770016578

Epoch: 5| Step: 2
Training loss: 2.6332201957702637
Validation loss: 2.3316956079134377

Epoch: 5| Step: 3
Training loss: 2.6053624153137207
Validation loss: 2.3311240621792373

Epoch: 5| Step: 4
Training loss: 2.898557662963867
Validation loss: 2.316957364800156

Epoch: 5| Step: 5
Training loss: 2.5210843086242676
Validation loss: 2.3081237962169032

Epoch: 5| Step: 6
Training loss: 2.5025429725646973
Validation loss: 2.3063289555170203

Epoch: 5| Step: 7
Training loss: 2.384747266769409
Validation loss: 2.3090391159057617

Epoch: 5| Step: 8
Training loss: 2.5993990898132324
Validation loss: 2.3118481918047835

Epoch: 5| Step: 9
Training loss: 2.9032273292541504
Validation loss: 2.3151723133620394

Epoch: 5| Step: 10
Training loss: 2.3800699710845947
Validation loss: 2.3217036352362683

Epoch: 69| Step: 0
Training loss: 2.8139655590057373
Validation loss: 2.3185754642691663

Epoch: 5| Step: 1
Training loss: 1.902382493019104
Validation loss: 2.3219721445473294

Epoch: 5| Step: 2
Training loss: 2.680115222930908
Validation loss: 2.3207101642444568

Epoch: 5| Step: 3
Training loss: 2.718648910522461
Validation loss: 2.325048731219384

Epoch: 5| Step: 4
Training loss: 2.2318522930145264
Validation loss: 2.33949803280574

Epoch: 5| Step: 5
Training loss: 2.501077175140381
Validation loss: 2.381325375649237

Epoch: 5| Step: 6
Training loss: 2.7576797008514404
Validation loss: 2.416421608258319

Epoch: 5| Step: 7
Training loss: 2.597564220428467
Validation loss: 2.4448624746773833

Epoch: 5| Step: 8
Training loss: 3.1519908905029297
Validation loss: 2.4553523371296544

Epoch: 5| Step: 9
Training loss: 2.9841039180755615
Validation loss: 2.431926709349437

Epoch: 5| Step: 10
Training loss: 2.9405603408813477
Validation loss: 2.3855864476132136

Epoch: 70| Step: 0
Training loss: 2.69079327583313
Validation loss: 2.345409449710641

Epoch: 5| Step: 1
Training loss: 2.6140058040618896
Validation loss: 2.3355944669374855

Epoch: 5| Step: 2
Training loss: 2.448880910873413
Validation loss: 2.3281809950387604

Epoch: 5| Step: 3
Training loss: 2.3963241577148438
Validation loss: 2.333663396937873

Epoch: 5| Step: 4
Training loss: 2.2558517456054688
Validation loss: 2.340383611699586

Epoch: 5| Step: 5
Training loss: 2.464951753616333
Validation loss: 2.3343402313929733

Epoch: 5| Step: 6
Training loss: 2.214962959289551
Validation loss: 2.3284218875310754

Epoch: 5| Step: 7
Training loss: 3.0591495037078857
Validation loss: 2.3153638352629957

Epoch: 5| Step: 8
Training loss: 2.6345298290252686
Validation loss: 2.309195190347651

Epoch: 5| Step: 9
Training loss: 3.343855619430542
Validation loss: 2.3115119549535934

Epoch: 5| Step: 10
Training loss: 2.694826602935791
Validation loss: 2.3164955134032876

Epoch: 71| Step: 0
Training loss: 3.335181713104248
Validation loss: 2.3175694455382643

Epoch: 5| Step: 1
Training loss: 2.04718279838562
Validation loss: 2.3265201096893637

Epoch: 5| Step: 2
Training loss: 2.3012399673461914
Validation loss: 2.3269726691707486

Epoch: 5| Step: 3
Training loss: 2.962719440460205
Validation loss: 2.314394393274861

Epoch: 5| Step: 4
Training loss: 2.4775023460388184
Validation loss: 2.307674192613171

Epoch: 5| Step: 5
Training loss: 2.7316815853118896
Validation loss: 2.307650032863822

Epoch: 5| Step: 6
Training loss: 2.4481658935546875
Validation loss: 2.300490989479967

Epoch: 5| Step: 7
Training loss: 2.3633739948272705
Validation loss: 2.3056607759127052

Epoch: 5| Step: 8
Training loss: 1.9196903705596924
Validation loss: 2.324678877348541

Epoch: 5| Step: 9
Training loss: 3.152930974960327
Validation loss: 2.3326051722290697

Epoch: 5| Step: 10
Training loss: 2.8259897232055664
Validation loss: 2.3234318251250894

Epoch: 72| Step: 0
Training loss: 2.09946870803833
Validation loss: 2.310592212984639

Epoch: 5| Step: 1
Training loss: 2.247366189956665
Validation loss: 2.3044489070933354

Epoch: 5| Step: 2
Training loss: 2.29235577583313
Validation loss: 2.295852038168138

Epoch: 5| Step: 3
Training loss: 2.2771992683410645
Validation loss: 2.292349535931823

Epoch: 5| Step: 4
Training loss: 2.6211891174316406
Validation loss: 2.288088044812602

Epoch: 5| Step: 5
Training loss: 3.0336828231811523
Validation loss: 2.289184155002717

Epoch: 5| Step: 6
Training loss: 2.9232289791107178
Validation loss: 2.2892190179517193

Epoch: 5| Step: 7
Training loss: 2.6278979778289795
Validation loss: 2.2897484507612003

Epoch: 5| Step: 8
Training loss: 2.857394218444824
Validation loss: 2.2883233024228002

Epoch: 5| Step: 9
Training loss: 2.6610159873962402
Validation loss: 2.286655823389689

Epoch: 5| Step: 10
Training loss: 2.9422554969787598
Validation loss: 2.2855957810596754

Epoch: 73| Step: 0
Training loss: 2.4846253395080566
Validation loss: 2.2838514338257494

Epoch: 5| Step: 1
Training loss: 2.154306411743164
Validation loss: 2.2880645951917096

Epoch: 5| Step: 2
Training loss: 2.346195936203003
Validation loss: 2.2874727351691133

Epoch: 5| Step: 3
Training loss: 2.433870792388916
Validation loss: 2.2927043719958236

Epoch: 5| Step: 4
Training loss: 2.1354517936706543
Validation loss: 2.2932103628753335

Epoch: 5| Step: 5
Training loss: 2.8135805130004883
Validation loss: 2.298843822171611

Epoch: 5| Step: 6
Training loss: 2.600876569747925
Validation loss: 2.3098277763653825

Epoch: 5| Step: 7
Training loss: 2.7413763999938965
Validation loss: 2.3089430127092587

Epoch: 5| Step: 8
Training loss: 2.5344438552856445
Validation loss: 2.306580405081472

Epoch: 5| Step: 9
Training loss: 3.0121989250183105
Validation loss: 2.3200726252730175

Epoch: 5| Step: 10
Training loss: 3.246899366378784
Validation loss: 2.3006703187060613

Epoch: 74| Step: 0
Training loss: 2.7843165397644043
Validation loss: 2.2862210658288773

Epoch: 5| Step: 1
Training loss: 3.113839864730835
Validation loss: 2.2735247663272324

Epoch: 5| Step: 2
Training loss: 2.5920071601867676
Validation loss: 2.2785027975677163

Epoch: 5| Step: 3
Training loss: 2.1571264266967773
Validation loss: 2.2813599058376846

Epoch: 5| Step: 4
Training loss: 2.256286859512329
Validation loss: 2.2851010753262426

Epoch: 5| Step: 5
Training loss: 2.558746337890625
Validation loss: 2.2795229573403635

Epoch: 5| Step: 6
Training loss: 2.8060379028320312
Validation loss: 2.2748959064483643

Epoch: 5| Step: 7
Training loss: 2.53511118888855
Validation loss: 2.2785599564993255

Epoch: 5| Step: 8
Training loss: 2.588299512863159
Validation loss: 2.2746497379836215

Epoch: 5| Step: 9
Training loss: 2.5629239082336426
Validation loss: 2.2750880179866666

Epoch: 5| Step: 10
Training loss: 2.414003372192383
Validation loss: 2.2772097100493727

Epoch: 75| Step: 0
Training loss: 2.0782434940338135
Validation loss: 2.2838735503535115

Epoch: 5| Step: 1
Training loss: 2.5381383895874023
Validation loss: 2.3408747014179023

Epoch: 5| Step: 2
Training loss: 2.464238405227661
Validation loss: 2.3726169191380984

Epoch: 5| Step: 3
Training loss: 2.6802170276641846
Validation loss: 2.3801630966125

Epoch: 5| Step: 4
Training loss: 2.6397287845611572
Validation loss: 2.3501979843262704

Epoch: 5| Step: 5
Training loss: 2.475461006164551
Validation loss: 2.2881648284132763

Epoch: 5| Step: 6
Training loss: 2.2711715698242188
Validation loss: 2.2681791628560712

Epoch: 5| Step: 7
Training loss: 2.8326172828674316
Validation loss: 2.2740944021491596

Epoch: 5| Step: 8
Training loss: 3.738295078277588
Validation loss: 2.2827357169120543

Epoch: 5| Step: 9
Training loss: 2.614413261413574
Validation loss: 2.2999138780819472

Epoch: 5| Step: 10
Training loss: 2.1074585914611816
Validation loss: 2.2974015948592976

Epoch: 76| Step: 0
Training loss: 2.7036280632019043
Validation loss: 2.3037172902014946

Epoch: 5| Step: 1
Training loss: 2.937690019607544
Validation loss: 2.296915228648852

Epoch: 5| Step: 2
Training loss: 2.611724376678467
Validation loss: 2.292799242081181

Epoch: 5| Step: 3
Training loss: 3.2594974040985107
Validation loss: 2.2812094726870136

Epoch: 5| Step: 4
Training loss: 2.5764870643615723
Validation loss: 2.276691194503538

Epoch: 5| Step: 5
Training loss: 2.39774489402771
Validation loss: 2.2715796014314056

Epoch: 5| Step: 6
Training loss: 2.8884894847869873
Validation loss: 2.2712523578315653

Epoch: 5| Step: 7
Training loss: 2.492649555206299
Validation loss: 2.263962827703004

Epoch: 5| Step: 8
Training loss: 1.9057697057724
Validation loss: 2.2656832305333947

Epoch: 5| Step: 9
Training loss: 1.9874505996704102
Validation loss: 2.27383622559168

Epoch: 5| Step: 10
Training loss: 2.5071048736572266
Validation loss: 2.304255723953247

Epoch: 77| Step: 0
Training loss: 3.050687551498413
Validation loss: 2.3293242608347247

Epoch: 5| Step: 1
Training loss: 2.5104188919067383
Validation loss: 2.373416590434249

Epoch: 5| Step: 2
Training loss: 2.194624423980713
Validation loss: 2.3597803192753948

Epoch: 5| Step: 3
Training loss: 2.3320295810699463
Validation loss: 2.3739924225755917

Epoch: 5| Step: 4
Training loss: 2.4918365478515625
Validation loss: 2.326457437648568

Epoch: 5| Step: 5
Training loss: 2.867704153060913
Validation loss: 2.2747749577286425

Epoch: 5| Step: 6
Training loss: 2.7869210243225098
Validation loss: 2.2561970103171562

Epoch: 5| Step: 7
Training loss: 2.7008683681488037
Validation loss: 2.262131816597395

Epoch: 5| Step: 8
Training loss: 2.2113499641418457
Validation loss: 2.2624589243242816

Epoch: 5| Step: 9
Training loss: 2.071180582046509
Validation loss: 2.2817795789369972

Epoch: 5| Step: 10
Training loss: 3.455929756164551
Validation loss: 2.2971211274464927

Epoch: 78| Step: 0
Training loss: 2.9943013191223145
Validation loss: 2.3271461199688654

Epoch: 5| Step: 1
Training loss: 2.47052264213562
Validation loss: 2.315142339275729

Epoch: 5| Step: 2
Training loss: 2.4606261253356934
Validation loss: 2.2952466908321587

Epoch: 5| Step: 3
Training loss: 2.8621151447296143
Validation loss: 2.297167190941431

Epoch: 5| Step: 4
Training loss: 2.518016815185547
Validation loss: 2.283329807302003

Epoch: 5| Step: 5
Training loss: 2.6225757598876953
Validation loss: 2.277737489310644

Epoch: 5| Step: 6
Training loss: 2.401909589767456
Validation loss: 2.263568893555672

Epoch: 5| Step: 7
Training loss: 1.908227562904358
Validation loss: 2.255517710921585

Epoch: 5| Step: 8
Training loss: 2.866964101791382
Validation loss: 2.2565864414297123

Epoch: 5| Step: 9
Training loss: 2.5064454078674316
Validation loss: 2.2699916849854174

Epoch: 5| Step: 10
Training loss: 3.2398083209991455
Validation loss: 2.2959038698545067

Epoch: 79| Step: 0
Training loss: 3.0250084400177
Validation loss: 2.3083812549550045

Epoch: 5| Step: 1
Training loss: 3.022623062133789
Validation loss: 2.327946480884347

Epoch: 5| Step: 2
Training loss: 2.7783801555633545
Validation loss: 2.388968183148292

Epoch: 5| Step: 3
Training loss: 2.6753461360931396
Validation loss: 2.402539424998786

Epoch: 5| Step: 4
Training loss: 2.3595364093780518
Validation loss: 2.352486880876685

Epoch: 5| Step: 5
Training loss: 2.363807201385498
Validation loss: 2.3036432804599887

Epoch: 5| Step: 6
Training loss: 2.5715553760528564
Validation loss: 2.267034730603618

Epoch: 5| Step: 7
Training loss: 2.6798012256622314
Validation loss: 2.2423980415508313

Epoch: 5| Step: 8
Training loss: 2.071549415588379
Validation loss: 2.235609018674461

Epoch: 5| Step: 9
Training loss: 2.2933554649353027
Validation loss: 2.2437723554590696

Epoch: 5| Step: 10
Training loss: 2.5643486976623535
Validation loss: 2.243313533003612

Epoch: 80| Step: 0
Training loss: 2.590282917022705
Validation loss: 2.2571416593367055

Epoch: 5| Step: 1
Training loss: 1.889219880104065
Validation loss: 2.258260432110038

Epoch: 5| Step: 2
Training loss: 3.248696804046631
Validation loss: 2.2680552544132357

Epoch: 5| Step: 3
Training loss: 2.350257396697998
Validation loss: 2.276665441451534

Epoch: 5| Step: 4
Training loss: 2.410587787628174
Validation loss: 2.268190868439213

Epoch: 5| Step: 5
Training loss: 2.4577224254608154
Validation loss: 2.2590569168008785

Epoch: 5| Step: 6
Training loss: 3.0423381328582764
Validation loss: 2.2511703814229658

Epoch: 5| Step: 7
Training loss: 2.9513561725616455
Validation loss: 2.2465635781647055

Epoch: 5| Step: 8
Training loss: 2.3441786766052246
Validation loss: 2.243914710578098

Epoch: 5| Step: 9
Training loss: 2.115570068359375
Validation loss: 2.239637459478071

Epoch: 5| Step: 10
Training loss: 3.0415706634521484
Validation loss: 2.2353283461704048

Epoch: 81| Step: 0
Training loss: 2.189171075820923
Validation loss: 2.2373639998897428

Epoch: 5| Step: 1
Training loss: 2.7339060306549072
Validation loss: 2.2416765971850325

Epoch: 5| Step: 2
Training loss: 2.1346380710601807
Validation loss: 2.258447188203053

Epoch: 5| Step: 3
Training loss: 3.0019826889038086
Validation loss: 2.2683443228403726

Epoch: 5| Step: 4
Training loss: 2.448493003845215
Validation loss: 2.2681944806088685

Epoch: 5| Step: 5
Training loss: 2.3842551708221436
Validation loss: 2.2639592924425678

Epoch: 5| Step: 6
Training loss: 2.93343448638916
Validation loss: 2.244762803918572

Epoch: 5| Step: 7
Training loss: 2.669476270675659
Validation loss: 2.237348187354303

Epoch: 5| Step: 8
Training loss: 2.5316030979156494
Validation loss: 2.229592090011925

Epoch: 5| Step: 9
Training loss: 2.2267589569091797
Validation loss: 2.2287387386445077

Epoch: 5| Step: 10
Training loss: 2.9206881523132324
Validation loss: 2.2283630832549064

Epoch: 82| Step: 0
Training loss: 1.9932349920272827
Validation loss: 2.2257152834246234

Epoch: 5| Step: 1
Training loss: 2.399568557739258
Validation loss: 2.2198138493363575

Epoch: 5| Step: 2
Training loss: 2.9214649200439453
Validation loss: 2.2240057017213557

Epoch: 5| Step: 3
Training loss: 2.8716492652893066
Validation loss: 2.2233745231423327

Epoch: 5| Step: 4
Training loss: 2.563798189163208
Validation loss: 2.22607587229821

Epoch: 5| Step: 5
Training loss: 2.4000179767608643
Validation loss: 2.2233033898056194

Epoch: 5| Step: 6
Training loss: 2.6305253505706787
Validation loss: 2.222375305750037

Epoch: 5| Step: 7
Training loss: 2.52089786529541
Validation loss: 2.2221339569296887

Epoch: 5| Step: 8
Training loss: 2.850921630859375
Validation loss: 2.2212819284008396

Epoch: 5| Step: 9
Training loss: 2.8601155281066895
Validation loss: 2.2221276003827333

Epoch: 5| Step: 10
Training loss: 1.8795024156570435
Validation loss: 2.2187225946816067

Epoch: 83| Step: 0
Training loss: 2.887807846069336
Validation loss: 2.2186062259058796

Epoch: 5| Step: 1
Training loss: 2.5660080909729004
Validation loss: 2.221770558305966

Epoch: 5| Step: 2
Training loss: 2.4525556564331055
Validation loss: 2.2194420829896004

Epoch: 5| Step: 3
Training loss: 2.572154998779297
Validation loss: 2.217383743614279

Epoch: 5| Step: 4
Training loss: 2.6939196586608887
Validation loss: 2.218322935924735

Epoch: 5| Step: 5
Training loss: 2.3376967906951904
Validation loss: 2.217793513369817

Epoch: 5| Step: 6
Training loss: 2.4072585105895996
Validation loss: 2.2172644112699773

Epoch: 5| Step: 7
Training loss: 2.089768409729004
Validation loss: 2.23141049826017

Epoch: 5| Step: 8
Training loss: 2.6003401279449463
Validation loss: 2.23696966068719

Epoch: 5| Step: 9
Training loss: 2.3860905170440674
Validation loss: 2.2720003717689106

Epoch: 5| Step: 10
Training loss: 2.949544906616211
Validation loss: 2.284795456035163

Epoch: 84| Step: 0
Training loss: 2.7667770385742188
Validation loss: 2.2704056001478627

Epoch: 5| Step: 1
Training loss: 2.5699143409729004
Validation loss: 2.2545260831873906

Epoch: 5| Step: 2
Training loss: 3.3047804832458496
Validation loss: 2.2306036872248494

Epoch: 5| Step: 3
Training loss: 2.2001891136169434
Validation loss: 2.217858858005975

Epoch: 5| Step: 4
Training loss: 2.473227024078369
Validation loss: 2.217157394655289

Epoch: 5| Step: 5
Training loss: 2.505458116531372
Validation loss: 2.21303924052946

Epoch: 5| Step: 6
Training loss: 2.630422592163086
Validation loss: 2.2171127796173096

Epoch: 5| Step: 7
Training loss: 2.0110294818878174
Validation loss: 2.2178215416528846

Epoch: 5| Step: 8
Training loss: 2.5302231311798096
Validation loss: 2.2183063927517144

Epoch: 5| Step: 9
Training loss: 2.194272041320801
Validation loss: 2.2193798506131737

Epoch: 5| Step: 10
Training loss: 2.8480031490325928
Validation loss: 2.217566095372682

Epoch: 85| Step: 0
Training loss: 1.6151173114776611
Validation loss: 2.227398657029675

Epoch: 5| Step: 1
Training loss: 2.8200767040252686
Validation loss: 2.2412510584759455

Epoch: 5| Step: 2
Training loss: 2.370227575302124
Validation loss: 2.244079456534437

Epoch: 5| Step: 3
Training loss: 2.8626327514648438
Validation loss: 2.2472622702198644

Epoch: 5| Step: 4
Training loss: 2.7924232482910156
Validation loss: 2.2397687794059835

Epoch: 5| Step: 5
Training loss: 2.989638566970825
Validation loss: 2.252045068689572

Epoch: 5| Step: 6
Training loss: 2.3347816467285156
Validation loss: 2.247530052738805

Epoch: 5| Step: 7
Training loss: 2.3137896060943604
Validation loss: 2.242399913008495

Epoch: 5| Step: 8
Training loss: 2.7522897720336914
Validation loss: 2.2637856211713565

Epoch: 5| Step: 9
Training loss: 2.8109734058380127
Validation loss: 2.2567673088401876

Epoch: 5| Step: 10
Training loss: 2.095245838165283
Validation loss: 2.251691013254145

Epoch: 86| Step: 0
Training loss: 2.3996074199676514
Validation loss: 2.23506498336792

Epoch: 5| Step: 1
Training loss: 2.5066943168640137
Validation loss: 2.2246047758286998

Epoch: 5| Step: 2
Training loss: 2.6166279315948486
Validation loss: 2.2354964543414373

Epoch: 5| Step: 3
Training loss: 2.4196982383728027
Validation loss: 2.2281783844835017

Epoch: 5| Step: 4
Training loss: 2.5390725135803223
Validation loss: 2.227087620765932

Epoch: 5| Step: 5
Training loss: 2.4647116661071777
Validation loss: 2.2144033524297897

Epoch: 5| Step: 6
Training loss: 2.616947650909424
Validation loss: 2.2147350465097735

Epoch: 5| Step: 7
Training loss: 2.673708438873291
Validation loss: 2.2173806210999847

Epoch: 5| Step: 8
Training loss: 2.790086507797241
Validation loss: 2.2048771791560675

Epoch: 5| Step: 9
Training loss: 2.859194278717041
Validation loss: 2.2008448646914576

Epoch: 5| Step: 10
Training loss: 1.7653965950012207
Validation loss: 2.193870617497352

Epoch: 87| Step: 0
Training loss: 2.2470943927764893
Validation loss: 2.1949997896789224

Epoch: 5| Step: 1
Training loss: 2.1968894004821777
Validation loss: 2.198543587038594

Epoch: 5| Step: 2
Training loss: 2.9704811573028564
Validation loss: 2.2014582669863136

Epoch: 5| Step: 3
Training loss: 2.3816120624542236
Validation loss: 2.1963678790676977

Epoch: 5| Step: 4
Training loss: 2.654404640197754
Validation loss: 2.1967961916359524

Epoch: 5| Step: 5
Training loss: 2.3018455505371094
Validation loss: 2.193699900821973

Epoch: 5| Step: 6
Training loss: 2.6932151317596436
Validation loss: 2.1940197919004705

Epoch: 5| Step: 7
Training loss: 2.667877674102783
Validation loss: 2.1920092259683917

Epoch: 5| Step: 8
Training loss: 2.192737102508545
Validation loss: 2.1967477144733554

Epoch: 5| Step: 9
Training loss: 3.0682225227355957
Validation loss: 2.200208689576836

Epoch: 5| Step: 10
Training loss: 2.4883670806884766
Validation loss: 2.220526094077736

Epoch: 88| Step: 0
Training loss: 2.301359176635742
Validation loss: 2.2602810808407363

Epoch: 5| Step: 1
Training loss: 2.2099051475524902
Validation loss: 2.2819078814598823

Epoch: 5| Step: 2
Training loss: 2.3806939125061035
Validation loss: 2.311400441713231

Epoch: 5| Step: 3
Training loss: 2.7716195583343506
Validation loss: 2.2937316394621328

Epoch: 5| Step: 4
Training loss: 2.5382018089294434
Validation loss: 2.3285491415249404

Epoch: 5| Step: 5
Training loss: 2.5035500526428223
Validation loss: 2.316998140786284

Epoch: 5| Step: 6
Training loss: 2.809316396713257
Validation loss: 2.2584806078223774

Epoch: 5| Step: 7
Training loss: 2.536149501800537
Validation loss: 2.2227180773212063

Epoch: 5| Step: 8
Training loss: 2.3514389991760254
Validation loss: 2.2070413071622133

Epoch: 5| Step: 9
Training loss: 2.6921608448028564
Validation loss: 2.1930710269558813

Epoch: 5| Step: 10
Training loss: 2.7063817977905273
Validation loss: 2.1868733847013084

Epoch: 89| Step: 0
Training loss: 2.2831904888153076
Validation loss: 2.1834938141607467

Epoch: 5| Step: 1
Training loss: 2.044745445251465
Validation loss: 2.188298567648857

Epoch: 5| Step: 2
Training loss: 2.4992456436157227
Validation loss: 2.1813386255694973

Epoch: 5| Step: 3
Training loss: 2.4679532051086426
Validation loss: 2.19402882617007

Epoch: 5| Step: 4
Training loss: 2.7454731464385986
Validation loss: 2.2026411051391275

Epoch: 5| Step: 5
Training loss: 2.802896499633789
Validation loss: 2.2079251120167394

Epoch: 5| Step: 6
Training loss: 1.9101448059082031
Validation loss: 2.2104615396068943

Epoch: 5| Step: 7
Training loss: 2.7504026889801025
Validation loss: 2.2250811566588697

Epoch: 5| Step: 8
Training loss: 2.367602586746216
Validation loss: 2.2245623603943856

Epoch: 5| Step: 9
Training loss: 3.010258913040161
Validation loss: 2.233556742309242

Epoch: 5| Step: 10
Training loss: 2.782073736190796
Validation loss: 2.224381846766318

Epoch: 90| Step: 0
Training loss: 2.419527530670166
Validation loss: 2.217911062702056

Epoch: 5| Step: 1
Training loss: 2.892010450363159
Validation loss: 2.207255191700433

Epoch: 5| Step: 2
Training loss: 2.0148677825927734
Validation loss: 2.2072095819698867

Epoch: 5| Step: 3
Training loss: 2.8623063564300537
Validation loss: 2.2048304132235947

Epoch: 5| Step: 4
Training loss: 3.0959362983703613
Validation loss: 2.1936833371398268

Epoch: 5| Step: 5
Training loss: 2.433342456817627
Validation loss: 2.185062434083672

Epoch: 5| Step: 6
Training loss: 2.578782081604004
Validation loss: 2.179963582305498

Epoch: 5| Step: 7
Training loss: 2.7629711627960205
Validation loss: 2.1833981006376204

Epoch: 5| Step: 8
Training loss: 2.660977840423584
Validation loss: 2.178195150949622

Epoch: 5| Step: 9
Training loss: 1.5590057373046875
Validation loss: 2.1842877582837175

Epoch: 5| Step: 10
Training loss: 2.30846905708313
Validation loss: 2.182529108498686

Epoch: 91| Step: 0
Training loss: 2.492842435836792
Validation loss: 2.2101437545591787

Epoch: 5| Step: 1
Training loss: 2.301309108734131
Validation loss: 2.2419123752142793

Epoch: 5| Step: 2
Training loss: 2.3709070682525635
Validation loss: 2.2858329434548654

Epoch: 5| Step: 3
Training loss: 2.046488046646118
Validation loss: 2.313387467015174

Epoch: 5| Step: 4
Training loss: 3.1593990325927734
Validation loss: 2.282951219107515

Epoch: 5| Step: 5
Training loss: 2.9213452339172363
Validation loss: 2.2406425655529065

Epoch: 5| Step: 6
Training loss: 2.1869258880615234
Validation loss: 2.202803191318307

Epoch: 5| Step: 7
Training loss: 2.7401909828186035
Validation loss: 2.18701030618401

Epoch: 5| Step: 8
Training loss: 2.6840879917144775
Validation loss: 2.1859915692319154

Epoch: 5| Step: 9
Training loss: 2.1593990325927734
Validation loss: 2.1877517777104534

Epoch: 5| Step: 10
Training loss: 2.7865140438079834
Validation loss: 2.1922418968651884

Epoch: 92| Step: 0
Training loss: 2.809037685394287
Validation loss: 2.201935609181722

Epoch: 5| Step: 1
Training loss: 2.5285446643829346
Validation loss: 2.2040936485413583

Epoch: 5| Step: 2
Training loss: 3.345432758331299
Validation loss: 2.201591250716999

Epoch: 5| Step: 3
Training loss: 2.2636361122131348
Validation loss: 2.188183537093542

Epoch: 5| Step: 4
Training loss: 2.2425498962402344
Validation loss: 2.1740942847344185

Epoch: 5| Step: 5
Training loss: 2.664078712463379
Validation loss: 2.1731830809706

Epoch: 5| Step: 6
Training loss: 2.9379525184631348
Validation loss: 2.1696116988376906

Epoch: 5| Step: 7
Training loss: 1.9326362609863281
Validation loss: 2.1766485962816464

Epoch: 5| Step: 8
Training loss: 2.0907015800476074
Validation loss: 2.1892497770247923

Epoch: 5| Step: 9
Training loss: 2.5871403217315674
Validation loss: 2.2216349160799416

Epoch: 5| Step: 10
Training loss: 2.0198094844818115
Validation loss: 2.248268283823485

Epoch: 93| Step: 0
Training loss: 2.3741307258605957
Validation loss: 2.2867828312740532

Epoch: 5| Step: 1
Training loss: 2.6786599159240723
Validation loss: 2.2459518063452935

Epoch: 5| Step: 2
Training loss: 1.8907592296600342
Validation loss: 2.228175602933412

Epoch: 5| Step: 3
Training loss: 2.6534745693206787
Validation loss: 2.2197364863529

Epoch: 5| Step: 4
Training loss: 2.9126696586608887
Validation loss: 2.1996443348546184

Epoch: 5| Step: 5
Training loss: 2.5767831802368164
Validation loss: 2.199831303729806

Epoch: 5| Step: 6
Training loss: 2.9414713382720947
Validation loss: 2.205612859418315

Epoch: 5| Step: 7
Training loss: 2.280683994293213
Validation loss: 2.197397644801806

Epoch: 5| Step: 8
Training loss: 2.7238895893096924
Validation loss: 2.201723119264008

Epoch: 5| Step: 9
Training loss: 2.7721190452575684
Validation loss: 2.1967641384370866

Epoch: 5| Step: 10
Training loss: 1.8029755353927612
Validation loss: 2.1815236870960524

Epoch: 94| Step: 0
Training loss: 2.448673963546753
Validation loss: 2.1658904783187376

Epoch: 5| Step: 1
Training loss: 2.61586332321167
Validation loss: 2.1775599000274495

Epoch: 5| Step: 2
Training loss: 2.579965353012085
Validation loss: 2.1737732605267595

Epoch: 5| Step: 3
Training loss: 2.037083625793457
Validation loss: 2.178164653880622

Epoch: 5| Step: 4
Training loss: 2.1047050952911377
Validation loss: 2.1828726978712183

Epoch: 5| Step: 5
Training loss: 1.9173853397369385
Validation loss: 2.207480107584307

Epoch: 5| Step: 6
Training loss: 2.842979907989502
Validation loss: 2.243061659156635

Epoch: 5| Step: 7
Training loss: 3.3039844036102295
Validation loss: 2.2892586531177646

Epoch: 5| Step: 8
Training loss: 2.3853585720062256
Validation loss: 2.293431310243504

Epoch: 5| Step: 9
Training loss: 2.9889369010925293
Validation loss: 2.2692326653388237

Epoch: 5| Step: 10
Training loss: 2.398404836654663
Validation loss: 2.2207035146733767

Epoch: 95| Step: 0
Training loss: 3.083918809890747
Validation loss: 2.192490122651541

Epoch: 5| Step: 1
Training loss: 2.623530626296997
Validation loss: 2.175342893087736

Epoch: 5| Step: 2
Training loss: 2.580395221710205
Validation loss: 2.171836901736516

Epoch: 5| Step: 3
Training loss: 2.9986929893493652
Validation loss: 2.1703521564442623

Epoch: 5| Step: 4
Training loss: 1.8867933750152588
Validation loss: 2.1626240245757566

Epoch: 5| Step: 5
Training loss: 2.334960460662842
Validation loss: 2.1629980533353743

Epoch: 5| Step: 6
Training loss: 1.988250732421875
Validation loss: 2.186407691688948

Epoch: 5| Step: 7
Training loss: 1.4949716329574585
Validation loss: 2.2189764207409275

Epoch: 5| Step: 8
Training loss: 2.6311850547790527
Validation loss: 2.2481879470168904

Epoch: 5| Step: 9
Training loss: 3.217268705368042
Validation loss: 2.2815691732591197

Epoch: 5| Step: 10
Training loss: 2.714698314666748
Validation loss: 2.2581925930515414

Epoch: 96| Step: 0
Training loss: 2.3377063274383545
Validation loss: 2.237379289442493

Epoch: 5| Step: 1
Training loss: 2.7921810150146484
Validation loss: 2.2222901262262815

Epoch: 5| Step: 2
Training loss: 1.9632031917572021
Validation loss: 2.1973886541140977

Epoch: 5| Step: 3
Training loss: 2.3713314533233643
Validation loss: 2.1933332207382366

Epoch: 5| Step: 4
Training loss: 3.427654266357422
Validation loss: 2.196513231082629

Epoch: 5| Step: 5
Training loss: 2.2472317218780518
Validation loss: 2.1861093121190227

Epoch: 5| Step: 6
Training loss: 2.6083362102508545
Validation loss: 2.174935083235464

Epoch: 5| Step: 7
Training loss: 2.740795135498047
Validation loss: 2.175714421015914

Epoch: 5| Step: 8
Training loss: 2.7124245166778564
Validation loss: 2.167706602363176

Epoch: 5| Step: 9
Training loss: 1.9117380380630493
Validation loss: 2.1714248913590626

Epoch: 5| Step: 10
Training loss: 2.2787160873413086
Validation loss: 2.1651126620590047

Epoch: 97| Step: 0
Training loss: 2.4035842418670654
Validation loss: 2.1663588349537184

Epoch: 5| Step: 1
Training loss: 2.0663466453552246
Validation loss: 2.1702921813534153

Epoch: 5| Step: 2
Training loss: 1.8440135717391968
Validation loss: 2.17096858896235

Epoch: 5| Step: 3
Training loss: 2.686811923980713
Validation loss: 2.1944568926288235

Epoch: 5| Step: 4
Training loss: 2.770444393157959
Validation loss: 2.224424854401619

Epoch: 5| Step: 5
Training loss: 2.967939853668213
Validation loss: 2.2567830444664083

Epoch: 5| Step: 6
Training loss: 2.1780025959014893
Validation loss: 2.2800770703182427

Epoch: 5| Step: 7
Training loss: 2.3896303176879883
Validation loss: 2.2815979962707846

Epoch: 5| Step: 8
Training loss: 2.927880048751831
Validation loss: 2.2781698575583835

Epoch: 5| Step: 9
Training loss: 2.8247809410095215
Validation loss: 2.267581024477559

Epoch: 5| Step: 10
Training loss: 2.4803619384765625
Validation loss: 2.254411043659333

Epoch: 98| Step: 0
Training loss: 2.522395610809326
Validation loss: 2.259620722904

Epoch: 5| Step: 1
Training loss: 3.1432197093963623
Validation loss: 2.239910720497049

Epoch: 5| Step: 2
Training loss: 2.716041326522827
Validation loss: 2.215556372878372

Epoch: 5| Step: 3
Training loss: 1.710214614868164
Validation loss: 2.201776558353055

Epoch: 5| Step: 4
Training loss: 2.1051368713378906
Validation loss: 2.1761723359425864

Epoch: 5| Step: 5
Training loss: 2.0503458976745605
Validation loss: 2.1701106025326635

Epoch: 5| Step: 6
Training loss: 2.5371627807617188
Validation loss: 2.15835125471956

Epoch: 5| Step: 7
Training loss: 2.1627116203308105
Validation loss: 2.1523479030978296

Epoch: 5| Step: 8
Training loss: 2.643183946609497
Validation loss: 2.1463381013562604

Epoch: 5| Step: 9
Training loss: 2.8918604850769043
Validation loss: 2.1493836884857505

Epoch: 5| Step: 10
Training loss: 2.990391969680786
Validation loss: 2.149157606145387

Epoch: 99| Step: 0
Training loss: 2.4972329139709473
Validation loss: 2.1674496512259207

Epoch: 5| Step: 1
Training loss: 1.6217927932739258
Validation loss: 2.1840123566248084

Epoch: 5| Step: 2
Training loss: 3.0716378688812256
Validation loss: 2.203454312457833

Epoch: 5| Step: 3
Training loss: 2.6675171852111816
Validation loss: 2.212708027132096

Epoch: 5| Step: 4
Training loss: 2.247551679611206
Validation loss: 2.2003461276331255

Epoch: 5| Step: 5
Training loss: 2.291900396347046
Validation loss: 2.1836680750693045

Epoch: 5| Step: 6
Training loss: 2.705443859100342
Validation loss: 2.1829309335318943

Epoch: 5| Step: 7
Training loss: 2.603026866912842
Validation loss: 2.1638946687021563

Epoch: 5| Step: 8
Training loss: 2.6469528675079346
Validation loss: 2.1615373447377193

Epoch: 5| Step: 9
Training loss: 2.3729801177978516
Validation loss: 2.150262581404819

Epoch: 5| Step: 10
Training loss: 2.4669997692108154
Validation loss: 2.149041365551692

Epoch: 100| Step: 0
Training loss: 2.8140745162963867
Validation loss: 2.14238719273639

Epoch: 5| Step: 1
Training loss: 2.7463743686676025
Validation loss: 2.142394960567515

Epoch: 5| Step: 2
Training loss: 2.835996150970459
Validation loss: 2.138790458761236

Epoch: 5| Step: 3
Training loss: 2.0986487865448
Validation loss: 2.1445183600148847

Epoch: 5| Step: 4
Training loss: 2.3418190479278564
Validation loss: 2.1446808512492845

Epoch: 5| Step: 5
Training loss: 2.924191951751709
Validation loss: 2.140416863144085

Epoch: 5| Step: 6
Training loss: 2.3954379558563232
Validation loss: 2.153451914428383

Epoch: 5| Step: 7
Training loss: 2.067190408706665
Validation loss: 2.1536310565087105

Epoch: 5| Step: 8
Training loss: 1.9724689722061157
Validation loss: 2.1514125844483734

Epoch: 5| Step: 9
Training loss: 2.023348569869995
Validation loss: 2.1564507074253534

Epoch: 5| Step: 10
Training loss: 2.891047954559326
Validation loss: 2.167420256522394

Epoch: 101| Step: 0
Training loss: 2.334622859954834
Validation loss: 2.184945960198679

Epoch: 5| Step: 1
Training loss: 3.0487446784973145
Validation loss: 2.2013903971641295

Epoch: 5| Step: 2
Training loss: 2.4181015491485596
Validation loss: 2.2235711338699504

Epoch: 5| Step: 3
Training loss: 2.5203490257263184
Validation loss: 2.2293934693900486

Epoch: 5| Step: 4
Training loss: 2.3499419689178467
Validation loss: 2.196039084465273

Epoch: 5| Step: 5
Training loss: 2.7367053031921387
Validation loss: 2.1950740378390075

Epoch: 5| Step: 6
Training loss: 2.009760618209839
Validation loss: 2.1790967833611274

Epoch: 5| Step: 7
Training loss: 2.6566615104675293
Validation loss: 2.1544898376669934

Epoch: 5| Step: 8
Training loss: 2.712181806564331
Validation loss: 2.1726130644480386

Epoch: 5| Step: 9
Training loss: 2.212618350982666
Validation loss: 2.169107142315116

Epoch: 5| Step: 10
Training loss: 1.9566706418991089
Validation loss: 2.1614149514064995

Epoch: 102| Step: 0
Training loss: 2.599762201309204
Validation loss: 2.1426263983531664

Epoch: 5| Step: 1
Training loss: 2.5776805877685547
Validation loss: 2.1395502551909416

Epoch: 5| Step: 2
Training loss: 2.166858196258545
Validation loss: 2.156308771461569

Epoch: 5| Step: 3
Training loss: 2.217329502105713
Validation loss: 2.182605694699031

Epoch: 5| Step: 4
Training loss: 2.540977954864502
Validation loss: 2.193988997449157

Epoch: 5| Step: 5
Training loss: 1.6697921752929688
Validation loss: 2.200731031356319

Epoch: 5| Step: 6
Training loss: 2.453894853591919
Validation loss: 2.189187090883973

Epoch: 5| Step: 7
Training loss: 3.3091049194335938
Validation loss: 2.1847278277079263

Epoch: 5| Step: 8
Training loss: 2.5473642349243164
Validation loss: 2.180116379132835

Epoch: 5| Step: 9
Training loss: 3.0396270751953125
Validation loss: 2.1815323163104314

Epoch: 5| Step: 10
Training loss: 2.0193395614624023
Validation loss: 2.169497618111231

Epoch: 103| Step: 0
Training loss: 2.600437879562378
Validation loss: 2.174131760033228

Epoch: 5| Step: 1
Training loss: 2.619687557220459
Validation loss: 2.1739115099753104

Epoch: 5| Step: 2
Training loss: 2.39509654045105
Validation loss: 2.1703728193877847

Epoch: 5| Step: 3
Training loss: 2.553101062774658
Validation loss: 2.177627077666662

Epoch: 5| Step: 4
Training loss: 2.38307523727417
Validation loss: 2.176515345932335

Epoch: 5| Step: 5
Training loss: 2.903010129928589
Validation loss: 2.1747297779206307

Epoch: 5| Step: 6
Training loss: 2.578235626220703
Validation loss: 2.1862711675705446

Epoch: 5| Step: 7
Training loss: 1.5132311582565308
Validation loss: 2.1824300981337026

Epoch: 5| Step: 8
Training loss: 2.5599448680877686
Validation loss: 2.1931970683477258

Epoch: 5| Step: 9
Training loss: 2.6511101722717285
Validation loss: 2.20892475112792

Epoch: 5| Step: 10
Training loss: 2.538949966430664
Validation loss: 2.1988411898254068

Epoch: 104| Step: 0
Training loss: 2.509472370147705
Validation loss: 2.177369971429148

Epoch: 5| Step: 1
Training loss: 2.5899548530578613
Validation loss: 2.1637588700940533

Epoch: 5| Step: 2
Training loss: 2.0304863452911377
Validation loss: 2.160362764071393

Epoch: 5| Step: 3
Training loss: 2.781083822250366
Validation loss: 2.128672294719245

Epoch: 5| Step: 4
Training loss: 2.622300624847412
Validation loss: 2.117454678781571

Epoch: 5| Step: 5
Training loss: 2.197319269180298
Validation loss: 2.118882438187958

Epoch: 5| Step: 6
Training loss: 2.800208330154419
Validation loss: 2.129110441412977

Epoch: 5| Step: 7
Training loss: 3.0422558784484863
Validation loss: 2.128681413588985

Epoch: 5| Step: 8
Training loss: 2.4338200092315674
Validation loss: 2.1269813506833968

Epoch: 5| Step: 9
Training loss: 1.9540666341781616
Validation loss: 2.122937043507894

Epoch: 5| Step: 10
Training loss: 2.4917380809783936
Validation loss: 2.127758305559876

Epoch: 105| Step: 0
Training loss: 2.5733487606048584
Validation loss: 2.1292487946889733

Epoch: 5| Step: 1
Training loss: 2.966341495513916
Validation loss: 2.1452551939154185

Epoch: 5| Step: 2
Training loss: 1.8797645568847656
Validation loss: 2.1721317563005673

Epoch: 5| Step: 3
Training loss: 1.9564870595932007
Validation loss: 2.1813016822261195

Epoch: 5| Step: 4
Training loss: 1.9183012247085571
Validation loss: 2.2337397042141167

Epoch: 5| Step: 5
Training loss: 2.7991490364074707
Validation loss: 2.2480434730488765

Epoch: 5| Step: 6
Training loss: 2.0832839012145996
Validation loss: 2.2499943061541487

Epoch: 5| Step: 7
Training loss: 2.7733447551727295
Validation loss: 2.2537905029071275

Epoch: 5| Step: 8
Training loss: 2.978086233139038
Validation loss: 2.212085385476389

Epoch: 5| Step: 9
Training loss: 2.287010669708252
Validation loss: 2.175385049594346

Epoch: 5| Step: 10
Training loss: 2.856921911239624
Validation loss: 2.171774866760418

Epoch: 106| Step: 0
Training loss: 2.287384510040283
Validation loss: 2.145721427855953

Epoch: 5| Step: 1
Training loss: 1.9138208627700806
Validation loss: 2.163049313329881

Epoch: 5| Step: 2
Training loss: 2.173426389694214
Validation loss: 2.1953202703947663

Epoch: 5| Step: 3
Training loss: 2.4972825050354004
Validation loss: 2.237385155052267

Epoch: 5| Step: 4
Training loss: 2.8348910808563232
Validation loss: 2.2496984210065616

Epoch: 5| Step: 5
Training loss: 2.157320976257324
Validation loss: 2.250074396851242

Epoch: 5| Step: 6
Training loss: 2.868546962738037
Validation loss: 2.1931509381981305

Epoch: 5| Step: 7
Training loss: 2.5017592906951904
Validation loss: 2.149345023657686

Epoch: 5| Step: 8
Training loss: 3.0380587577819824
Validation loss: 2.1599720408839564

Epoch: 5| Step: 9
Training loss: 2.5492637157440186
Validation loss: 2.1242693983098513

Epoch: 5| Step: 10
Training loss: 2.170274496078491
Validation loss: 2.146391704518308

Epoch: 107| Step: 0
Training loss: 2.347689628601074
Validation loss: 2.152515652359173

Epoch: 5| Step: 1
Training loss: 2.374850034713745
Validation loss: 2.15489355210335

Epoch: 5| Step: 2
Training loss: 2.7146573066711426
Validation loss: 2.157104601142227

Epoch: 5| Step: 3
Training loss: 2.400869607925415
Validation loss: 2.135008099258587

Epoch: 5| Step: 4
Training loss: 1.760923147201538
Validation loss: 2.132226692732944

Epoch: 5| Step: 5
Training loss: 3.034012794494629
Validation loss: 2.125546081091768

Epoch: 5| Step: 6
Training loss: 2.9393160343170166
Validation loss: 2.127969273956873

Epoch: 5| Step: 7
Training loss: 2.5073771476745605
Validation loss: 2.132797154047156

Epoch: 5| Step: 8
Training loss: 2.946800947189331
Validation loss: 2.135648150597849

Epoch: 5| Step: 9
Training loss: 2.6312415599823
Validation loss: 2.1350133803582962

Epoch: 5| Step: 10
Training loss: 1.5979902744293213
Validation loss: 2.153001085404427

Epoch: 108| Step: 0
Training loss: 2.371936321258545
Validation loss: 2.179181562956943

Epoch: 5| Step: 1
Training loss: 2.0899617671966553
Validation loss: 2.1726640706421225

Epoch: 5| Step: 2
Training loss: 2.5551486015319824
Validation loss: 2.176353452026203

Epoch: 5| Step: 3
Training loss: 2.513310670852661
Validation loss: 2.151723559184741

Epoch: 5| Step: 4
Training loss: 2.23331618309021
Validation loss: 2.123304687520509

Epoch: 5| Step: 5
Training loss: 2.4727659225463867
Validation loss: 2.0988809293316257

Epoch: 5| Step: 6
Training loss: 2.2557520866394043
Validation loss: 2.0983468204416256

Epoch: 5| Step: 7
Training loss: 1.985913872718811
Validation loss: 2.0972957252174296

Epoch: 5| Step: 8
Training loss: 2.66873836517334
Validation loss: 2.098581898596979

Epoch: 5| Step: 9
Training loss: 2.867941379547119
Validation loss: 2.09973112101196

Epoch: 5| Step: 10
Training loss: 3.1825804710388184
Validation loss: 2.1196916090544833

Epoch: 109| Step: 0
Training loss: 2.71543550491333
Validation loss: 2.142587720706899

Epoch: 5| Step: 1
Training loss: 2.896209239959717
Validation loss: 2.16610150952493

Epoch: 5| Step: 2
Training loss: 2.327549695968628
Validation loss: 2.1607091990850305

Epoch: 5| Step: 3
Training loss: 2.2455976009368896
Validation loss: 2.169907336593956

Epoch: 5| Step: 4
Training loss: 2.7215559482574463
Validation loss: 2.1817069438196

Epoch: 5| Step: 5
Training loss: 2.547208547592163
Validation loss: 2.1948398697760796

Epoch: 5| Step: 6
Training loss: 2.2369587421417236
Validation loss: 2.1995712992965535

Epoch: 5| Step: 7
Training loss: 2.783691644668579
Validation loss: 2.1767148305011053

Epoch: 5| Step: 8
Training loss: 1.6238734722137451
Validation loss: 2.1699421995429584

Epoch: 5| Step: 9
Training loss: 2.480721950531006
Validation loss: 2.139572364027782

Epoch: 5| Step: 10
Training loss: 2.2989792823791504
Validation loss: 2.099462224591163

Epoch: 110| Step: 0
Training loss: 2.2818336486816406
Validation loss: 2.09841856392481

Epoch: 5| Step: 1
Training loss: 2.06583833694458
Validation loss: 2.0924934648698374

Epoch: 5| Step: 2
Training loss: 3.0464558601379395
Validation loss: 2.0875806065015894

Epoch: 5| Step: 3
Training loss: 2.711291790008545
Validation loss: 2.0910545959267566

Epoch: 5| Step: 4
Training loss: 2.3824851512908936
Validation loss: 2.0979125704816592

Epoch: 5| Step: 5
Training loss: 2.572620391845703
Validation loss: 2.1019472127319663

Epoch: 5| Step: 6
Training loss: 2.1213669776916504
Validation loss: 2.1353555494739163

Epoch: 5| Step: 7
Training loss: 2.584810256958008
Validation loss: 2.1943276210497786

Epoch: 5| Step: 8
Training loss: 2.0239675045013428
Validation loss: 2.2394377159815964

Epoch: 5| Step: 9
Training loss: 2.403101682662964
Validation loss: 2.2967483407707623

Epoch: 5| Step: 10
Training loss: 2.785956382751465
Validation loss: 2.340087700915593

Epoch: 111| Step: 0
Training loss: 2.7107701301574707
Validation loss: 2.286662934928812

Epoch: 5| Step: 1
Training loss: 3.4781289100646973
Validation loss: 2.258264413443945

Epoch: 5| Step: 2
Training loss: 2.62176775932312
Validation loss: 2.1685132403527536

Epoch: 5| Step: 3
Training loss: 3.0940592288970947
Validation loss: 2.1111722351402364

Epoch: 5| Step: 4
Training loss: 2.3619120121002197
Validation loss: 2.0924254232837307

Epoch: 5| Step: 5
Training loss: 2.247910976409912
Validation loss: 2.0866817556401736

Epoch: 5| Step: 6
Training loss: 2.0100531578063965
Validation loss: 2.085463993010982

Epoch: 5| Step: 7
Training loss: 2.380176305770874
Validation loss: 2.0990038815365044

Epoch: 5| Step: 8
Training loss: 1.4592050313949585
Validation loss: 2.0990477146640902

Epoch: 5| Step: 9
Training loss: 2.67924165725708
Validation loss: 2.095568956867341

Epoch: 5| Step: 10
Training loss: 2.031309127807617
Validation loss: 2.1011513356239564

Epoch: 112| Step: 0
Training loss: 2.6382813453674316
Validation loss: 2.1007701940433954

Epoch: 5| Step: 1
Training loss: 2.499171733856201
Validation loss: 2.104534690098096

Epoch: 5| Step: 2
Training loss: 2.287160634994507
Validation loss: 2.116545231111588

Epoch: 5| Step: 3
Training loss: 2.419639825820923
Validation loss: 2.1158704091143865

Epoch: 5| Step: 4
Training loss: 2.8028788566589355
Validation loss: 2.112169301638039

Epoch: 5| Step: 5
Training loss: 2.6528966426849365
Validation loss: 2.102667381686549

Epoch: 5| Step: 6
Training loss: 2.2485556602478027
Validation loss: 2.116073654543969

Epoch: 5| Step: 7
Training loss: 2.7296295166015625
Validation loss: 2.114396587494881

Epoch: 5| Step: 8
Training loss: 2.102405548095703
Validation loss: 2.1123546631105485

Epoch: 5| Step: 9
Training loss: 1.9251744747161865
Validation loss: 2.110217807113483

Epoch: 5| Step: 10
Training loss: 2.4938955307006836
Validation loss: 2.1058087041301112

Epoch: 113| Step: 0
Training loss: 2.3206143379211426
Validation loss: 2.1139704206938386

Epoch: 5| Step: 1
Training loss: 2.2604782581329346
Validation loss: 2.1100947600539013

Epoch: 5| Step: 2
Training loss: 1.8282390832901
Validation loss: 2.115563251638925

Epoch: 5| Step: 3
Training loss: 2.229396104812622
Validation loss: 2.1287669315133044

Epoch: 5| Step: 4
Training loss: 2.5336968898773193
Validation loss: 2.1467596471950574

Epoch: 5| Step: 5
Training loss: 2.5605101585388184
Validation loss: 2.152072165601997

Epoch: 5| Step: 6
Training loss: 1.7546470165252686
Validation loss: 2.1534186845184653

Epoch: 5| Step: 7
Training loss: 2.6481220722198486
Validation loss: 2.1548649034192486

Epoch: 5| Step: 8
Training loss: 2.6780714988708496
Validation loss: 2.142823508990708

Epoch: 5| Step: 9
Training loss: 2.5802407264709473
Validation loss: 2.13537464475119

Epoch: 5| Step: 10
Training loss: 3.2848644256591797
Validation loss: 2.126458232120801

Epoch: 114| Step: 0
Training loss: 2.503649950027466
Validation loss: 2.1093897370881933

Epoch: 5| Step: 1
Training loss: 2.6812009811401367
Validation loss: 2.1019589413878736

Epoch: 5| Step: 2
Training loss: 2.054826021194458
Validation loss: 2.1101539314434095

Epoch: 5| Step: 3
Training loss: 2.43190860748291
Validation loss: 2.1144953799504105

Epoch: 5| Step: 4
Training loss: 2.711252450942993
Validation loss: 2.1311363686797438

Epoch: 5| Step: 5
Training loss: 2.565068006515503
Validation loss: 2.1367611744070567

Epoch: 5| Step: 6
Training loss: 2.046726703643799
Validation loss: 2.1256231902748026

Epoch: 5| Step: 7
Training loss: 2.5925731658935547
Validation loss: 2.123569708998485

Epoch: 5| Step: 8
Training loss: 2.9286372661590576
Validation loss: 2.1133209146479124

Epoch: 5| Step: 9
Training loss: 1.9538389444351196
Validation loss: 2.1036245745997273

Epoch: 5| Step: 10
Training loss: 2.2098171710968018
Validation loss: 2.107657819665888

Epoch: 115| Step: 0
Training loss: 2.4249277114868164
Validation loss: 2.0932216362286638

Epoch: 5| Step: 1
Training loss: 2.4332518577575684
Validation loss: 2.078125943419754

Epoch: 5| Step: 2
Training loss: 2.1644091606140137
Validation loss: 2.0995160379717426

Epoch: 5| Step: 3
Training loss: 2.7164292335510254
Validation loss: 2.093734279755623

Epoch: 5| Step: 4
Training loss: 2.333995819091797
Validation loss: 2.099666803113876

Epoch: 5| Step: 5
Training loss: 2.5811126232147217
Validation loss: 2.0962538347449353

Epoch: 5| Step: 6
Training loss: 2.4183154106140137
Validation loss: 2.0922740761951735

Epoch: 5| Step: 7
Training loss: 2.312319755554199
Validation loss: 2.0909194625833982

Epoch: 5| Step: 8
Training loss: 2.2860662937164307
Validation loss: 2.0949531011683966

Epoch: 5| Step: 9
Training loss: 2.6721839904785156
Validation loss: 2.1102427462095856

Epoch: 5| Step: 10
Training loss: 2.022901773452759
Validation loss: 2.1020213968010357

Epoch: 116| Step: 0
Training loss: 1.9804017543792725
Validation loss: 2.168093700562754

Epoch: 5| Step: 1
Training loss: 2.4428391456604004
Validation loss: 2.2374508867981615

Epoch: 5| Step: 2
Training loss: 1.9016027450561523
Validation loss: 2.3020329552312053

Epoch: 5| Step: 3
Training loss: 3.0546581745147705
Validation loss: 2.3753172043831117

Epoch: 5| Step: 4
Training loss: 2.584521532058716
Validation loss: 2.450418100562147

Epoch: 5| Step: 5
Training loss: 2.681966543197632
Validation loss: 2.5147681287539903

Epoch: 5| Step: 6
Training loss: 2.6299827098846436
Validation loss: 2.4223205556151686

Epoch: 5| Step: 7
Training loss: 2.5663094520568848
Validation loss: 2.214941801563386

Epoch: 5| Step: 8
Training loss: 2.1924221515655518
Validation loss: 2.101406822922409

Epoch: 5| Step: 9
Training loss: 2.7034900188446045
Validation loss: 2.082464525776525

Epoch: 5| Step: 10
Training loss: 2.4386587142944336
Validation loss: 2.1084475978728263

Epoch: 117| Step: 0
Training loss: 2.956334114074707
Validation loss: 2.157165524780109

Epoch: 5| Step: 1
Training loss: 2.1469573974609375
Validation loss: 2.142789243369974

Epoch: 5| Step: 2
Training loss: 2.4217498302459717
Validation loss: 2.1585910653555267

Epoch: 5| Step: 3
Training loss: 3.0009891986846924
Validation loss: 2.0972340414600987

Epoch: 5| Step: 4
Training loss: 2.5710816383361816
Validation loss: 2.087018238600864

Epoch: 5| Step: 5
Training loss: 2.7431368827819824
Validation loss: 2.0884927934215916

Epoch: 5| Step: 6
Training loss: 2.3736178874969482
Validation loss: 2.088989475721954

Epoch: 5| Step: 7
Training loss: 2.507115125656128
Validation loss: 2.0971992836203626

Epoch: 5| Step: 8
Training loss: 1.7245466709136963
Validation loss: 2.1101317328791462

Epoch: 5| Step: 9
Training loss: 2.146824836730957
Validation loss: 2.1302601240014516

Epoch: 5| Step: 10
Training loss: 2.3409502506256104
Validation loss: 2.1612323919932046

Epoch: 118| Step: 0
Training loss: 1.9513893127441406
Validation loss: 2.1742879600935083

Epoch: 5| Step: 1
Training loss: 2.178575038909912
Validation loss: 2.118123686441811

Epoch: 5| Step: 2
Training loss: 2.643968105316162
Validation loss: 2.1089792533587386

Epoch: 5| Step: 3
Training loss: 2.5936362743377686
Validation loss: 2.0708005761587494

Epoch: 5| Step: 4
Training loss: 2.7635467052459717
Validation loss: 2.0590556411332983

Epoch: 5| Step: 5
Training loss: 2.349428653717041
Validation loss: 2.0597024374110724

Epoch: 5| Step: 6
Training loss: 2.228217601776123
Validation loss: 2.0535490141120007

Epoch: 5| Step: 7
Training loss: 2.144486427307129
Validation loss: 2.0561693406874135

Epoch: 5| Step: 8
Training loss: 2.439267635345459
Validation loss: 2.0593469924824213

Epoch: 5| Step: 9
Training loss: 3.2859771251678467
Validation loss: 2.0711327163122033

Epoch: 5| Step: 10
Training loss: 1.8137797117233276
Validation loss: 2.11347641739794

Epoch: 119| Step: 0
Training loss: 2.25105881690979
Validation loss: 2.1115222566871235

Epoch: 5| Step: 1
Training loss: 1.9511566162109375
Validation loss: 2.157250009557252

Epoch: 5| Step: 2
Training loss: 2.291992664337158
Validation loss: 2.1953058986253637

Epoch: 5| Step: 3
Training loss: 2.5356571674346924
Validation loss: 2.2195002096955494

Epoch: 5| Step: 4
Training loss: 2.4475560188293457
Validation loss: 2.176261330163607

Epoch: 5| Step: 5
Training loss: 2.275341272354126
Validation loss: 2.1384625947603615

Epoch: 5| Step: 6
Training loss: 2.237870693206787
Validation loss: 2.1189102049796813

Epoch: 5| Step: 7
Training loss: 2.498060703277588
Validation loss: 2.120826713500484

Epoch: 5| Step: 8
Training loss: 2.759453058242798
Validation loss: 2.1187719401492866

Epoch: 5| Step: 9
Training loss: 2.5596089363098145
Validation loss: 2.108547205566078

Epoch: 5| Step: 10
Training loss: 2.5786097049713135
Validation loss: 2.1152362003121326

Epoch: 120| Step: 0
Training loss: 2.196890354156494
Validation loss: 2.1051848690996886

Epoch: 5| Step: 1
Training loss: 2.805135488510132
Validation loss: 2.097181502208915

Epoch: 5| Step: 2
Training loss: 2.21368145942688
Validation loss: 2.0958191630660847

Epoch: 5| Step: 3
Training loss: 2.1694045066833496
Validation loss: 2.06815517076882

Epoch: 5| Step: 4
Training loss: 2.7678182125091553
Validation loss: 2.0595467346970753

Epoch: 5| Step: 5
Training loss: 1.4954675436019897
Validation loss: 2.049754588834701

Epoch: 5| Step: 6
Training loss: 1.9443445205688477
Validation loss: 2.04939672511111

Epoch: 5| Step: 7
Training loss: 2.809457302093506
Validation loss: 2.055698847257963

Epoch: 5| Step: 8
Training loss: 2.591496467590332
Validation loss: 2.057454421956052

Epoch: 5| Step: 9
Training loss: 2.285490036010742
Validation loss: 2.056263674971878

Epoch: 5| Step: 10
Training loss: 3.0987966060638428
Validation loss: 2.0750938000217563

Epoch: 121| Step: 0
Training loss: 2.496117115020752
Validation loss: 2.0751990015788744

Epoch: 5| Step: 1
Training loss: 2.1776599884033203
Validation loss: 2.085335332860229

Epoch: 5| Step: 2
Training loss: 2.809901714324951
Validation loss: 2.1061965227127075

Epoch: 5| Step: 3
Training loss: 2.3458383083343506
Validation loss: 2.1186742398046676

Epoch: 5| Step: 4
Training loss: 2.4760384559631348
Validation loss: 2.1402509366312334

Epoch: 5| Step: 5
Training loss: 2.1046435832977295
Validation loss: 2.1525178981083695

Epoch: 5| Step: 6
Training loss: 2.517829418182373
Validation loss: 2.198039985472156

Epoch: 5| Step: 7
Training loss: 2.9438586235046387
Validation loss: 2.2142453373119397

Epoch: 5| Step: 8
Training loss: 2.0590853691101074
Validation loss: 2.229145183358141

Epoch: 5| Step: 9
Training loss: 2.0310399532318115
Validation loss: 2.196346808505315

Epoch: 5| Step: 10
Training loss: 2.628011703491211
Validation loss: 2.1614079526675645

Epoch: 122| Step: 0
Training loss: 2.7167599201202393
Validation loss: 2.1049475208405526

Epoch: 5| Step: 1
Training loss: 2.052394390106201
Validation loss: 2.0883960159876014

Epoch: 5| Step: 2
Training loss: 1.6098337173461914
Validation loss: 2.0795194961691417

Epoch: 5| Step: 3
Training loss: 2.650930166244507
Validation loss: 2.065734155716435

Epoch: 5| Step: 4
Training loss: 2.1017651557922363
Validation loss: 2.043430430914766

Epoch: 5| Step: 5
Training loss: 2.4827425479888916
Validation loss: 2.052900977032159

Epoch: 5| Step: 6
Training loss: 2.3567354679107666
Validation loss: 2.051956635649486

Epoch: 5| Step: 7
Training loss: 2.4827494621276855
Validation loss: 2.091224278173139

Epoch: 5| Step: 8
Training loss: 2.597423553466797
Validation loss: 2.134268142843759

Epoch: 5| Step: 9
Training loss: 2.9928207397460938
Validation loss: 2.175905150751914

Epoch: 5| Step: 10
Training loss: 2.0083887577056885
Validation loss: 2.152503487884357

Epoch: 123| Step: 0
Training loss: 1.5888035297393799
Validation loss: 2.163973723688433

Epoch: 5| Step: 1
Training loss: 1.9927070140838623
Validation loss: 2.1303511076076056

Epoch: 5| Step: 2
Training loss: 2.1627230644226074
Validation loss: 2.1095879001002156

Epoch: 5| Step: 3
Training loss: 2.349923610687256
Validation loss: 2.0813899604223107

Epoch: 5| Step: 4
Training loss: 2.5503768920898438
Validation loss: 2.063497627935102

Epoch: 5| Step: 5
Training loss: 2.6127567291259766
Validation loss: 2.065865937099662

Epoch: 5| Step: 6
Training loss: 2.5722572803497314
Validation loss: 2.074316914363574

Epoch: 5| Step: 7
Training loss: 2.8624496459960938
Validation loss: 2.080783792721328

Epoch: 5| Step: 8
Training loss: 2.428037643432617
Validation loss: 2.0681375636849353

Epoch: 5| Step: 9
Training loss: 2.933302879333496
Validation loss: 2.068359823637111

Epoch: 5| Step: 10
Training loss: 2.135730266571045
Validation loss: 2.0834690909231863

Epoch: 124| Step: 0
Training loss: 1.9845794439315796
Validation loss: 2.0918709180688344

Epoch: 5| Step: 1
Training loss: 2.492208957672119
Validation loss: 2.1193158703465618

Epoch: 5| Step: 2
Training loss: 2.5140395164489746
Validation loss: 2.1388822640142133

Epoch: 5| Step: 3
Training loss: 2.5735669136047363
Validation loss: 2.142277822699598

Epoch: 5| Step: 4
Training loss: 2.1576552391052246
Validation loss: 2.150197652078444

Epoch: 5| Step: 5
Training loss: 2.6651697158813477
Validation loss: 2.1587604886742047

Epoch: 5| Step: 6
Training loss: 2.1821420192718506
Validation loss: 2.1393875460470877

Epoch: 5| Step: 7
Training loss: 2.430569887161255
Validation loss: 2.1186885321012108

Epoch: 5| Step: 8
Training loss: 2.550346851348877
Validation loss: 2.113082542214342

Epoch: 5| Step: 9
Training loss: 2.694270133972168
Validation loss: 2.096534170130248

Epoch: 5| Step: 10
Training loss: 1.682308316230774
Validation loss: 2.093399493925033

Epoch: 125| Step: 0
Training loss: 1.5605216026306152
Validation loss: 2.100711784055156

Epoch: 5| Step: 1
Training loss: 2.1627678871154785
Validation loss: 2.105869731595439

Epoch: 5| Step: 2
Training loss: 3.107496976852417
Validation loss: 2.1379682710093837

Epoch: 5| Step: 3
Training loss: 2.068784713745117
Validation loss: 2.1516489726240917

Epoch: 5| Step: 4
Training loss: 2.5467886924743652
Validation loss: 2.1593176421298774

Epoch: 5| Step: 5
Training loss: 2.654928207397461
Validation loss: 2.159937466344526

Epoch: 5| Step: 6
Training loss: 2.8371543884277344
Validation loss: 2.121151570350893

Epoch: 5| Step: 7
Training loss: 2.5768473148345947
Validation loss: 2.0946625137841828

Epoch: 5| Step: 8
Training loss: 1.980822205543518
Validation loss: 2.0690753267657374

Epoch: 5| Step: 9
Training loss: 2.434056043624878
Validation loss: 2.083014940702787

Epoch: 5| Step: 10
Training loss: 1.8610155582427979
Validation loss: 2.0643836682842625

Epoch: 126| Step: 0
Training loss: 2.9579203128814697
Validation loss: 2.0641537353556645

Epoch: 5| Step: 1
Training loss: 2.249497890472412
Validation loss: 2.068314613834504

Epoch: 5| Step: 2
Training loss: 2.533299207687378
Validation loss: 2.074372796602147

Epoch: 5| Step: 3
Training loss: 2.2928004264831543
Validation loss: 2.077020632323398

Epoch: 5| Step: 4
Training loss: 1.6705539226531982
Validation loss: 2.1011011010857037

Epoch: 5| Step: 5
Training loss: 2.937389612197876
Validation loss: 2.095053615108613

Epoch: 5| Step: 6
Training loss: 1.958197832107544
Validation loss: 2.10346160909181

Epoch: 5| Step: 7
Training loss: 2.388890027999878
Validation loss: 2.098867375363586

Epoch: 5| Step: 8
Training loss: 2.060596466064453
Validation loss: 2.126722917761854

Epoch: 5| Step: 9
Training loss: 1.9752051830291748
Validation loss: 2.119409117647397

Epoch: 5| Step: 10
Training loss: 2.747701406478882
Validation loss: 2.0697200734128236

Epoch: 127| Step: 0
Training loss: 2.0862343311309814
Validation loss: 2.0443376571901384

Epoch: 5| Step: 1
Training loss: 2.657073497772217
Validation loss: 2.0353151162465415

Epoch: 5| Step: 2
Training loss: 2.3483829498291016
Validation loss: 2.0345023485922042

Epoch: 5| Step: 3
Training loss: 2.983607769012451
Validation loss: 2.0452731988763295

Epoch: 5| Step: 4
Training loss: 2.544935941696167
Validation loss: 2.0574692641535113

Epoch: 5| Step: 5
Training loss: 1.458473801612854
Validation loss: 2.0588764413710563

Epoch: 5| Step: 6
Training loss: 2.003791332244873
Validation loss: 2.078303098678589

Epoch: 5| Step: 7
Training loss: 2.501218795776367
Validation loss: 2.1116401841563563

Epoch: 5| Step: 8
Training loss: 2.819398880004883
Validation loss: 2.10792439727373

Epoch: 5| Step: 9
Training loss: 2.0294013023376465
Validation loss: 2.112808571066908

Epoch: 5| Step: 10
Training loss: 2.1846582889556885
Validation loss: 2.1209068759795158

Epoch: 128| Step: 0
Training loss: 2.5173659324645996
Validation loss: 2.116348644738556

Epoch: 5| Step: 1
Training loss: 2.197340726852417
Validation loss: 2.1268636693236647

Epoch: 5| Step: 2
Training loss: 1.725359559059143
Validation loss: 2.112340340050318

Epoch: 5| Step: 3
Training loss: 2.303501605987549
Validation loss: 2.089713775983421

Epoch: 5| Step: 4
Training loss: 2.127681255340576
Validation loss: 2.072912786596565

Epoch: 5| Step: 5
Training loss: 3.0789577960968018
Validation loss: 2.0578926840136127

Epoch: 5| Step: 6
Training loss: 2.5797038078308105
Validation loss: 2.0671858402990524

Epoch: 5| Step: 7
Training loss: 2.3127715587615967
Validation loss: 2.046371013887467

Epoch: 5| Step: 8
Training loss: 1.7682462930679321
Validation loss: 2.050762709750924

Epoch: 5| Step: 9
Training loss: 2.464526414871216
Validation loss: 2.0465585672727196

Epoch: 5| Step: 10
Training loss: 2.406179428100586
Validation loss: 2.051425386500615

Epoch: 129| Step: 0
Training loss: 2.6546902656555176
Validation loss: 2.0461077767033733

Epoch: 5| Step: 1
Training loss: 2.914989948272705
Validation loss: 2.0290486889500774

Epoch: 5| Step: 2
Training loss: 2.546715021133423
Validation loss: 2.0398127263592136

Epoch: 5| Step: 3
Training loss: 2.4685940742492676
Validation loss: 2.058173697481873

Epoch: 5| Step: 4
Training loss: 2.124690532684326
Validation loss: 2.0545007900525163

Epoch: 5| Step: 5
Training loss: 1.8269622325897217
Validation loss: 2.059436405858686

Epoch: 5| Step: 6
Training loss: 2.252819538116455
Validation loss: 2.0489404355326006

Epoch: 5| Step: 7
Training loss: 2.3013997077941895
Validation loss: 2.03314955260164

Epoch: 5| Step: 8
Training loss: 2.588456392288208
Validation loss: 2.0284900280737106

Epoch: 5| Step: 9
Training loss: 1.5357141494750977
Validation loss: 2.0252747766433226

Epoch: 5| Step: 10
Training loss: 2.1806375980377197
Validation loss: 2.033203806928409

Epoch: 130| Step: 0
Training loss: 1.749410629272461
Validation loss: 2.068781787349332

Epoch: 5| Step: 1
Training loss: 2.5133657455444336
Validation loss: 2.1079131467368013

Epoch: 5| Step: 2
Training loss: 2.5960958003997803
Validation loss: 2.106919921854491

Epoch: 5| Step: 3
Training loss: 2.540893316268921
Validation loss: 2.0863273656496437

Epoch: 5| Step: 4
Training loss: 2.405146837234497
Validation loss: 2.063766679456157

Epoch: 5| Step: 5
Training loss: 2.1045851707458496
Validation loss: 2.04848418312688

Epoch: 5| Step: 6
Training loss: 2.0959722995758057
Validation loss: 2.0349127656670025

Epoch: 5| Step: 7
Training loss: 2.976973295211792
Validation loss: 2.0482625628030426

Epoch: 5| Step: 8
Training loss: 2.3735361099243164
Validation loss: 2.061205329433564

Epoch: 5| Step: 9
Training loss: 2.0526394844055176
Validation loss: 2.067984325911409

Epoch: 5| Step: 10
Training loss: 1.7810307741165161
Validation loss: 2.0758779471920383

Epoch: 131| Step: 0
Training loss: 2.9097495079040527
Validation loss: 2.0481718227427494

Epoch: 5| Step: 1
Training loss: 1.7759826183319092
Validation loss: 2.033208413790631

Epoch: 5| Step: 2
Training loss: 2.3309428691864014
Validation loss: 2.0135560804797756

Epoch: 5| Step: 3
Training loss: 2.3847317695617676
Validation loss: 2.0299204959664294

Epoch: 5| Step: 4
Training loss: 2.146660804748535
Validation loss: 2.0289991747948433

Epoch: 5| Step: 5
Training loss: 2.572705030441284
Validation loss: 2.020644471209536

Epoch: 5| Step: 6
Training loss: 2.1852688789367676
Validation loss: 2.0232295015806794

Epoch: 5| Step: 7
Training loss: 2.9250121116638184
Validation loss: 2.021819555631248

Epoch: 5| Step: 8
Training loss: 1.5088456869125366
Validation loss: 2.0381268608954644

Epoch: 5| Step: 9
Training loss: 2.245579242706299
Validation loss: 2.069268975206601

Epoch: 5| Step: 10
Training loss: 2.4872334003448486
Validation loss: 2.1272741902259087

Epoch: 132| Step: 0
Training loss: 2.134719133377075
Validation loss: 2.1717775355103197

Epoch: 5| Step: 1
Training loss: 2.4128220081329346
Validation loss: 2.2251322064348447

Epoch: 5| Step: 2
Training loss: 2.88232684135437
Validation loss: 2.285349340849025

Epoch: 5| Step: 3
Training loss: 3.2597999572753906
Validation loss: 2.2506456221303632

Epoch: 5| Step: 4
Training loss: 2.47065806388855
Validation loss: 2.2235479226676365

Epoch: 5| Step: 5
Training loss: 1.8099720478057861
Validation loss: 2.1406936542962187

Epoch: 5| Step: 6
Training loss: 2.3319644927978516
Validation loss: 2.0487322935494046

Epoch: 5| Step: 7
Training loss: 2.190800905227661
Validation loss: 2.006672820737285

Epoch: 5| Step: 8
Training loss: 1.8838790655136108
Validation loss: 2.0167081843140306

Epoch: 5| Step: 9
Training loss: 2.0899271965026855
Validation loss: 2.0238984451499036

Epoch: 5| Step: 10
Training loss: 2.2209999561309814
Validation loss: 2.0339194984846216

Epoch: 133| Step: 0
Training loss: 2.208214044570923
Validation loss: 2.019375467813143

Epoch: 5| Step: 1
Training loss: 2.6642565727233887
Validation loss: 2.0160271326700845

Epoch: 5| Step: 2
Training loss: 2.128718852996826
Validation loss: 2.0356076263612315

Epoch: 5| Step: 3
Training loss: 2.4087746143341064
Validation loss: 2.0788686454937024

Epoch: 5| Step: 4
Training loss: 2.2128822803497314
Validation loss: 2.128200659187891

Epoch: 5| Step: 5
Training loss: 2.4001986980438232
Validation loss: 2.139873896875689

Epoch: 5| Step: 6
Training loss: 2.3559179306030273
Validation loss: 2.1309587891383837

Epoch: 5| Step: 7
Training loss: 2.6081345081329346
Validation loss: 2.1156339619749334

Epoch: 5| Step: 8
Training loss: 2.403083324432373
Validation loss: 2.071501487044878

Epoch: 5| Step: 9
Training loss: 2.068236827850342
Validation loss: 2.051025817471166

Epoch: 5| Step: 10
Training loss: 1.9813685417175293
Validation loss: 2.0315822221899547

Epoch: 134| Step: 0
Training loss: 2.28625750541687
Validation loss: 2.012648441458261

Epoch: 5| Step: 1
Training loss: 2.804724931716919
Validation loss: 2.020839662962062

Epoch: 5| Step: 2
Training loss: 2.047748327255249
Validation loss: 2.0395292825596307

Epoch: 5| Step: 3
Training loss: 2.305673599243164
Validation loss: 2.0459938228771253

Epoch: 5| Step: 4
Training loss: 2.464534044265747
Validation loss: 2.0383902390797934

Epoch: 5| Step: 5
Training loss: 2.187107801437378
Validation loss: 2.0424693502405638

Epoch: 5| Step: 6
Training loss: 2.353869676589966
Validation loss: 2.036884052779085

Epoch: 5| Step: 7
Training loss: 1.8625530004501343
Validation loss: 2.0270178138568835

Epoch: 5| Step: 8
Training loss: 2.5552849769592285
Validation loss: 2.0290387189516457

Epoch: 5| Step: 9
Training loss: 1.946078896522522
Validation loss: 2.023147024134154

Epoch: 5| Step: 10
Training loss: 2.1647937297821045
Validation loss: 2.053445736567179

Epoch: 135| Step: 0
Training loss: 2.483537197113037
Validation loss: 2.060736892043903

Epoch: 5| Step: 1
Training loss: 2.2852158546447754
Validation loss: 2.086043401431012

Epoch: 5| Step: 2
Training loss: 2.9488608837127686
Validation loss: 2.104837667557501

Epoch: 5| Step: 3
Training loss: 2.254067897796631
Validation loss: 2.1321006539047405

Epoch: 5| Step: 4
Training loss: 2.3544487953186035
Validation loss: 2.149009140588904

Epoch: 5| Step: 5
Training loss: 2.3599305152893066
Validation loss: 2.14198717763347

Epoch: 5| Step: 6
Training loss: 2.110863447189331
Validation loss: 2.146024400188077

Epoch: 5| Step: 7
Training loss: 1.9241321086883545
Validation loss: 2.1175649550653275

Epoch: 5| Step: 8
Training loss: 2.1811106204986572
Validation loss: 2.0589653650919595

Epoch: 5| Step: 9
Training loss: 1.763558030128479
Validation loss: 1.9746497625945716

Epoch: 5| Step: 10
Training loss: 2.5869433879852295
Validation loss: 1.9949861546998382

Epoch: 136| Step: 0
Training loss: 2.750563621520996
Validation loss: 2.0158214235818512

Epoch: 5| Step: 1
Training loss: 2.947580337524414
Validation loss: 2.0457185429911457

Epoch: 5| Step: 2
Training loss: 1.5979541540145874
Validation loss: 2.0459152216552408

Epoch: 5| Step: 3
Training loss: 2.6090610027313232
Validation loss: 2.040650575391708

Epoch: 5| Step: 4
Training loss: 2.1269681453704834
Validation loss: 2.02565602589679

Epoch: 5| Step: 5
Training loss: 2.2639145851135254
Validation loss: 2.025156767137589

Epoch: 5| Step: 6
Training loss: 2.5424370765686035
Validation loss: 2.023176150937234

Epoch: 5| Step: 7
Training loss: 2.4671339988708496
Validation loss: 2.0326205812474734

Epoch: 5| Step: 8
Training loss: 2.049643039703369
Validation loss: 2.0524098860320223

Epoch: 5| Step: 9
Training loss: 2.101166248321533
Validation loss: 2.1199404142236196

Epoch: 5| Step: 10
Training loss: 2.348191022872925
Validation loss: 2.1552906472195863

Epoch: 137| Step: 0
Training loss: 2.338740587234497
Validation loss: 2.2284096364052064

Epoch: 5| Step: 1
Training loss: 2.318204164505005
Validation loss: 2.197573600276824

Epoch: 5| Step: 2
Training loss: 2.3629980087280273
Validation loss: 2.1811776955922446

Epoch: 5| Step: 3
Training loss: 1.5726988315582275
Validation loss: 2.1354071132598387

Epoch: 5| Step: 4
Training loss: 2.768157482147217
Validation loss: 2.092755450997301

Epoch: 5| Step: 5
Training loss: 1.6433712244033813
Validation loss: 2.0703697768590783

Epoch: 5| Step: 6
Training loss: 2.7067155838012695
Validation loss: 2.0493571988997923

Epoch: 5| Step: 7
Training loss: 2.2292988300323486
Validation loss: 2.0435770839773197

Epoch: 5| Step: 8
Training loss: 1.9515571594238281
Validation loss: 2.0505988418415027

Epoch: 5| Step: 9
Training loss: 2.5227959156036377
Validation loss: 2.058279273330524

Epoch: 5| Step: 10
Training loss: 2.8636531829833984
Validation loss: 2.0738630704982306

Epoch: 138| Step: 0
Training loss: 2.4044952392578125
Validation loss: 2.0740949107754614

Epoch: 5| Step: 1
Training loss: 2.4263272285461426
Validation loss: 2.088988939921061

Epoch: 5| Step: 2
Training loss: 1.9731273651123047
Validation loss: 2.1233005805682112

Epoch: 5| Step: 3
Training loss: 2.824608564376831
Validation loss: 2.155711717503045

Epoch: 5| Step: 4
Training loss: 3.034961700439453
Validation loss: 2.167265722828527

Epoch: 5| Step: 5
Training loss: 2.0623791217803955
Validation loss: 2.1605776010021085

Epoch: 5| Step: 6
Training loss: 2.1778147220611572
Validation loss: 2.14791246896149

Epoch: 5| Step: 7
Training loss: 2.210402727127075
Validation loss: 2.144156999485467

Epoch: 5| Step: 8
Training loss: 2.1134438514709473
Validation loss: 2.125459829966227

Epoch: 5| Step: 9
Training loss: 2.0236129760742188
Validation loss: 2.130400078271025

Epoch: 5| Step: 10
Training loss: 1.9380239248275757
Validation loss: 2.0951007322598527

Epoch: 139| Step: 0
Training loss: 1.9134563207626343
Validation loss: 2.0809684979018344

Epoch: 5| Step: 1
Training loss: 2.966456174850464
Validation loss: 2.0591807262871855

Epoch: 5| Step: 2
Training loss: 2.4180209636688232
Validation loss: 2.0803036587212675

Epoch: 5| Step: 3
Training loss: 2.070319890975952
Validation loss: 2.096731339731524

Epoch: 5| Step: 4
Training loss: 2.507502794265747
Validation loss: 2.0918936985795216

Epoch: 5| Step: 5
Training loss: 2.1911511421203613
Validation loss: 2.118390369158919

Epoch: 5| Step: 6
Training loss: 2.026890277862549
Validation loss: 2.1294334203966203

Epoch: 5| Step: 7
Training loss: 2.0904345512390137
Validation loss: 2.1192284399463284

Epoch: 5| Step: 8
Training loss: 2.084542751312256
Validation loss: 2.0903509624542727

Epoch: 5| Step: 9
Training loss: 2.3886945247650146
Validation loss: 2.075394476613691

Epoch: 5| Step: 10
Training loss: 2.2753517627716064
Validation loss: 2.0397247793853923

Epoch: 140| Step: 0
Training loss: 2.032360792160034
Validation loss: 2.0398379064375356

Epoch: 5| Step: 1
Training loss: 2.592559814453125
Validation loss: 2.0454214157596713

Epoch: 5| Step: 2
Training loss: 2.1990342140197754
Validation loss: 2.047142644082346

Epoch: 5| Step: 3
Training loss: 1.9267511367797852
Validation loss: 2.0529009424230105

Epoch: 5| Step: 4
Training loss: 2.6114814281463623
Validation loss: 2.058633347993256

Epoch: 5| Step: 5
Training loss: 1.5927033424377441
Validation loss: 2.0940284703367498

Epoch: 5| Step: 6
Training loss: 2.426790952682495
Validation loss: 2.125210564623597

Epoch: 5| Step: 7
Training loss: 2.2388317584991455
Validation loss: 2.185201778206774

Epoch: 5| Step: 8
Training loss: 2.8693606853485107
Validation loss: 2.238776127497355

Epoch: 5| Step: 9
Training loss: 1.8612773418426514
Validation loss: 2.225496630514822

Epoch: 5| Step: 10
Training loss: 2.8428280353546143
Validation loss: 2.1908001438263924

Epoch: 141| Step: 0
Training loss: 2.0131378173828125
Validation loss: 2.152135287561724

Epoch: 5| Step: 1
Training loss: 2.0307395458221436
Validation loss: 2.1083078666399886

Epoch: 5| Step: 2
Training loss: 2.1048760414123535
Validation loss: 2.108975318170363

Epoch: 5| Step: 3
Training loss: 2.267439365386963
Validation loss: 2.0807154293983214

Epoch: 5| Step: 4
Training loss: 2.1998562812805176
Validation loss: 2.074285218792577

Epoch: 5| Step: 5
Training loss: 2.524387836456299
Validation loss: 2.0949059327443442

Epoch: 5| Step: 6
Training loss: 2.1575846672058105
Validation loss: 2.0819398844113914

Epoch: 5| Step: 7
Training loss: 2.579907178878784
Validation loss: 2.063815632174092

Epoch: 5| Step: 8
Training loss: 2.065703868865967
Validation loss: 2.0690072749250676

Epoch: 5| Step: 9
Training loss: 2.352085828781128
Validation loss: 2.075082309784428

Epoch: 5| Step: 10
Training loss: 2.1207234859466553
Validation loss: 2.078261616409466

Epoch: 142| Step: 0
Training loss: 2.613328456878662
Validation loss: 2.099523969875869

Epoch: 5| Step: 1
Training loss: 1.8670399188995361
Validation loss: 2.097572911170221

Epoch: 5| Step: 2
Training loss: 2.397047519683838
Validation loss: 2.098212634363482

Epoch: 5| Step: 3
Training loss: 2.035216808319092
Validation loss: 2.082961551604732

Epoch: 5| Step: 4
Training loss: 3.0567049980163574
Validation loss: 2.081534401062996

Epoch: 5| Step: 5
Training loss: 2.449516773223877
Validation loss: 2.0869776625787058

Epoch: 5| Step: 6
Training loss: 2.129662275314331
Validation loss: 2.0821741191289758

Epoch: 5| Step: 7
Training loss: 1.41078782081604
Validation loss: 2.0849706793344147

Epoch: 5| Step: 8
Training loss: 2.298905849456787
Validation loss: 2.098953890544112

Epoch: 5| Step: 9
Training loss: 2.3913416862487793
Validation loss: 2.1134931118257585

Epoch: 5| Step: 10
Training loss: 1.6135594844818115
Validation loss: 2.105823122045045

Epoch: 143| Step: 0
Training loss: 2.665390729904175
Validation loss: 2.1075674410789245

Epoch: 5| Step: 1
Training loss: 1.6525554656982422
Validation loss: 2.0878367821375527

Epoch: 5| Step: 2
Training loss: 2.7160263061523438
Validation loss: 2.103828243030015

Epoch: 5| Step: 3
Training loss: 1.9003040790557861
Validation loss: 2.103849172592163

Epoch: 5| Step: 4
Training loss: 2.4228804111480713
Validation loss: 2.1264829174164803

Epoch: 5| Step: 5
Training loss: 2.8126158714294434
Validation loss: 2.1463894049326577

Epoch: 5| Step: 6
Training loss: 1.9639873504638672
Validation loss: 2.161254712330398

Epoch: 5| Step: 7
Training loss: 2.034621000289917
Validation loss: 2.174133654563658

Epoch: 5| Step: 8
Training loss: 2.070514678955078
Validation loss: 2.193824029737903

Epoch: 5| Step: 9
Training loss: 1.909759521484375
Validation loss: 2.1458069893621627

Epoch: 5| Step: 10
Training loss: 1.986348271369934
Validation loss: 2.125950836366223

Epoch: 144| Step: 0
Training loss: 2.3315443992614746
Validation loss: 2.104940850247619

Epoch: 5| Step: 1
Training loss: 2.931406021118164
Validation loss: 2.086565461210025

Epoch: 5| Step: 2
Training loss: 1.9797910451889038
Validation loss: 2.0731213067167547

Epoch: 5| Step: 3
Training loss: 2.696683406829834
Validation loss: 2.0764172525816065

Epoch: 5| Step: 4
Training loss: 2.535637855529785
Validation loss: 2.0891497340253604

Epoch: 5| Step: 5
Training loss: 2.2284367084503174
Validation loss: 2.0979473488305205

Epoch: 5| Step: 6
Training loss: 1.5548969507217407
Validation loss: 2.1330795595722813

Epoch: 5| Step: 7
Training loss: 2.028857707977295
Validation loss: 2.1618236008510796

Epoch: 5| Step: 8
Training loss: 1.9913349151611328
Validation loss: 2.228960778123589

Epoch: 5| Step: 9
Training loss: 2.088280200958252
Validation loss: 2.2683740354353383

Epoch: 5| Step: 10
Training loss: 2.0649797916412354
Validation loss: 2.214385058290215

Epoch: 145| Step: 0
Training loss: 2.4970178604125977
Validation loss: 2.147117622437016

Epoch: 5| Step: 1
Training loss: 2.04687237739563
Validation loss: 2.1169431568473898

Epoch: 5| Step: 2
Training loss: 2.896854877471924
Validation loss: 2.1211538314819336

Epoch: 5| Step: 3
Training loss: 1.5335004329681396
Validation loss: 2.079898641955468

Epoch: 5| Step: 4
Training loss: 2.0468039512634277
Validation loss: 2.0813842845219437

Epoch: 5| Step: 5
Training loss: 2.2921745777130127
Validation loss: 2.077711623202088

Epoch: 5| Step: 6
Training loss: 2.1985878944396973
Validation loss: 2.062248832436018

Epoch: 5| Step: 7
Training loss: 2.7521543502807617
Validation loss: 2.082568117367324

Epoch: 5| Step: 8
Training loss: 2.597283124923706
Validation loss: 2.1053869044908913

Epoch: 5| Step: 9
Training loss: 1.464350700378418
Validation loss: 2.1304766170440184

Epoch: 5| Step: 10
Training loss: 1.9296231269836426
Validation loss: 2.184129922620712

Epoch: 146| Step: 0
Training loss: 2.271045207977295
Validation loss: 2.250937887417373

Epoch: 5| Step: 1
Training loss: 1.9083213806152344
Validation loss: 2.2844093845736597

Epoch: 5| Step: 2
Training loss: 2.1458535194396973
Validation loss: 2.3438999473407702

Epoch: 5| Step: 3
Training loss: 1.968173623085022
Validation loss: 2.3671828341740433

Epoch: 5| Step: 4
Training loss: 2.2697787284851074
Validation loss: 2.3215540045051166

Epoch: 5| Step: 5
Training loss: 2.28047776222229
Validation loss: 2.2502824670525006

Epoch: 5| Step: 6
Training loss: 2.5245418548583984
Validation loss: 2.1742322291097333

Epoch: 5| Step: 7
Training loss: 2.334643602371216
Validation loss: 2.1363713254210768

Epoch: 5| Step: 8
Training loss: 2.277109146118164
Validation loss: 2.1049719830994964

Epoch: 5| Step: 9
Training loss: 2.2435882091522217
Validation loss: 2.0800298644650366

Epoch: 5| Step: 10
Training loss: 2.073914051055908
Validation loss: 2.0731361860870035

Epoch: 147| Step: 0
Training loss: 1.5810562372207642
Validation loss: 2.0654253293109197

Epoch: 5| Step: 1
Training loss: 1.8811590671539307
Validation loss: 2.0614328384399414

Epoch: 5| Step: 2
Training loss: 2.014461040496826
Validation loss: 2.0593474077922043

Epoch: 5| Step: 3
Training loss: 2.320042610168457
Validation loss: 2.061425937119351

Epoch: 5| Step: 4
Training loss: 2.485447406768799
Validation loss: 2.1058316461501585

Epoch: 5| Step: 5
Training loss: 2.212925434112549
Validation loss: 2.1432160190356675

Epoch: 5| Step: 6
Training loss: 1.9040768146514893
Validation loss: 2.1537530858029603

Epoch: 5| Step: 7
Training loss: 2.560824155807495
Validation loss: 2.1513190346379436

Epoch: 5| Step: 8
Training loss: 2.9885847568511963
Validation loss: 2.1604580597210954

Epoch: 5| Step: 9
Training loss: 1.8325903415679932
Validation loss: 2.121668792540027

Epoch: 5| Step: 10
Training loss: 1.8901087045669556
Validation loss: 2.1135738331784486

Epoch: 148| Step: 0
Training loss: 2.5477585792541504
Validation loss: 2.1092188127579226

Epoch: 5| Step: 1
Training loss: 2.0898966789245605
Validation loss: 2.116021994621523

Epoch: 5| Step: 2
Training loss: 1.732730507850647
Validation loss: 2.1246470405209448

Epoch: 5| Step: 3
Training loss: 2.3732950687408447
Validation loss: 2.12214921879512

Epoch: 5| Step: 4
Training loss: 2.5603346824645996
Validation loss: 2.1239674937340522

Epoch: 5| Step: 5
Training loss: 2.326777458190918
Validation loss: 2.1263959638534056

Epoch: 5| Step: 6
Training loss: 2.201249599456787
Validation loss: 2.104965748325471

Epoch: 5| Step: 7
Training loss: 1.9422576427459717
Validation loss: 2.0942048770125195

Epoch: 5| Step: 8
Training loss: 1.8979698419570923
Validation loss: 2.1082418862209527

Epoch: 5| Step: 9
Training loss: 2.080324172973633
Validation loss: 2.105363153642224

Epoch: 5| Step: 10
Training loss: 1.5953282117843628
Validation loss: 2.1039789492084133

Epoch: 149| Step: 0
Training loss: 1.9919217824935913
Validation loss: 2.128091835206555

Epoch: 5| Step: 1
Training loss: 1.865349531173706
Validation loss: 2.1361212730407715

Epoch: 5| Step: 2
Training loss: 1.5396074056625366
Validation loss: 2.1339419939184703

Epoch: 5| Step: 3
Training loss: 1.8743960857391357
Validation loss: 2.141146477832589

Epoch: 5| Step: 4
Training loss: 1.5353195667266846
Validation loss: 2.104757865269979

Epoch: 5| Step: 5
Training loss: 2.022376775741577
Validation loss: 2.120377645697645

Epoch: 5| Step: 6
Training loss: 2.8585364818573
Validation loss: 2.0959306570791427

Epoch: 5| Step: 7
Training loss: 2.258084774017334
Validation loss: 2.090321056304439

Epoch: 5| Step: 8
Training loss: 2.5898818969726562
Validation loss: 2.0867058102802565

Epoch: 5| Step: 9
Training loss: 2.065401792526245
Validation loss: 2.0848683182911207

Epoch: 5| Step: 10
Training loss: 2.780299186706543
Validation loss: 2.0827453828627065

Epoch: 150| Step: 0
Training loss: 2.0744740962982178
Validation loss: 2.0967377975422847

Epoch: 5| Step: 1
Training loss: 2.764106273651123
Validation loss: 2.1065506012209

Epoch: 5| Step: 2
Training loss: 1.852357268333435
Validation loss: 2.1034760769977363

Epoch: 5| Step: 3
Training loss: 2.6041259765625
Validation loss: 2.106272846139887

Epoch: 5| Step: 4
Training loss: 2.077272653579712
Validation loss: 2.125004663262316

Epoch: 5| Step: 5
Training loss: 1.6572307348251343
Validation loss: 2.144346990892964

Epoch: 5| Step: 6
Training loss: 2.071122407913208
Validation loss: 2.1899599849536853

Epoch: 5| Step: 7
Training loss: 1.7328879833221436
Validation loss: 2.1917496432540235

Epoch: 5| Step: 8
Training loss: 2.3586511611938477
Validation loss: 2.176889750265306

Epoch: 5| Step: 9
Training loss: 1.9804903268814087
Validation loss: 2.106710046850225

Epoch: 5| Step: 10
Training loss: 2.025702476501465
Validation loss: 2.09714267587149

Epoch: 151| Step: 0
Training loss: 2.8059606552124023
Validation loss: 2.0904597556719215

Epoch: 5| Step: 1
Training loss: 2.3086557388305664
Validation loss: 2.0797356995203162

Epoch: 5| Step: 2
Training loss: 1.8734464645385742
Validation loss: 2.055239490283433

Epoch: 5| Step: 3
Training loss: 2.541545867919922
Validation loss: 2.0585572027391

Epoch: 5| Step: 4
Training loss: 1.9930522441864014
Validation loss: 2.06365869891259

Epoch: 5| Step: 5
Training loss: 1.7517684698104858
Validation loss: 2.1001657196270522

Epoch: 5| Step: 6
Training loss: 2.3543219566345215
Validation loss: 2.157214403152466

Epoch: 5| Step: 7
Training loss: 1.9329274892807007
Validation loss: 2.212105263945877

Epoch: 5| Step: 8
Training loss: 1.4500010013580322
Validation loss: 2.192869145383117

Epoch: 5| Step: 9
Training loss: 2.5802879333496094
Validation loss: 2.159365677064465

Epoch: 5| Step: 10
Training loss: 1.6080702543258667
Validation loss: 2.1256248592048563

Epoch: 152| Step: 0
Training loss: 2.595191478729248
Validation loss: 2.1046920155966156

Epoch: 5| Step: 1
Training loss: 1.561025857925415
Validation loss: 2.100543106755903

Epoch: 5| Step: 2
Training loss: 1.4103496074676514
Validation loss: 2.1057207353653444

Epoch: 5| Step: 3
Training loss: 2.3396999835968018
Validation loss: 2.1359485323711107

Epoch: 5| Step: 4
Training loss: 1.2907544374465942
Validation loss: 2.19612282065935

Epoch: 5| Step: 5
Training loss: 2.5477991104125977
Validation loss: 2.200242926997523

Epoch: 5| Step: 6
Training loss: 2.0339505672454834
Validation loss: 2.176865675116098

Epoch: 5| Step: 7
Training loss: 1.9641708135604858
Validation loss: 2.1395946010466544

Epoch: 5| Step: 8
Training loss: 2.547600269317627
Validation loss: 2.094081453097764

Epoch: 5| Step: 9
Training loss: 1.9790256023406982
Validation loss: 2.07634303903067

Epoch: 5| Step: 10
Training loss: 2.770271062850952
Validation loss: 2.069576585164634

Epoch: 153| Step: 0
Training loss: 1.9412851333618164
Validation loss: 2.0620576976447977

Epoch: 5| Step: 1
Training loss: 1.947544813156128
Validation loss: 2.0740549179815475

Epoch: 5| Step: 2
Training loss: 2.3436737060546875
Validation loss: 2.092815168442265

Epoch: 5| Step: 3
Training loss: 2.1127207279205322
Validation loss: 2.1334837380275933

Epoch: 5| Step: 4
Training loss: 2.1467909812927246
Validation loss: 2.179103643663468

Epoch: 5| Step: 5
Training loss: 1.5035855770111084
Validation loss: 2.164093509797127

Epoch: 5| Step: 6
Training loss: 1.455466628074646
Validation loss: 2.137303288264941

Epoch: 5| Step: 7
Training loss: 2.5160534381866455
Validation loss: 2.116174236420662

Epoch: 5| Step: 8
Training loss: 2.139946222305298
Validation loss: 2.10140505144673

Epoch: 5| Step: 9
Training loss: 2.664522171020508
Validation loss: 2.10121141710589

Epoch: 5| Step: 10
Training loss: 2.024918794631958
Validation loss: 2.0980229864838305

Epoch: 154| Step: 0
Training loss: 2.407597541809082
Validation loss: 2.1012177569891817

Epoch: 5| Step: 1
Training loss: 1.8262897729873657
Validation loss: 2.09464959175356

Epoch: 5| Step: 2
Training loss: 2.119015693664551
Validation loss: 2.0896263814741567

Epoch: 5| Step: 3
Training loss: 2.399379253387451
Validation loss: 2.1300909237195085

Epoch: 5| Step: 4
Training loss: 2.175832509994507
Validation loss: 2.1617940625836773

Epoch: 5| Step: 5
Training loss: 1.73371160030365
Validation loss: 2.181271599185082

Epoch: 5| Step: 6
Training loss: 2.8785178661346436
Validation loss: 2.1516286314174695

Epoch: 5| Step: 7
Training loss: 1.4802972078323364
Validation loss: 2.098071503382857

Epoch: 5| Step: 8
Training loss: 1.589726209640503
Validation loss: 2.0971672957943333

Epoch: 5| Step: 9
Training loss: 1.9287755489349365
Validation loss: 2.074759401300902

Epoch: 5| Step: 10
Training loss: 2.31384539604187
Validation loss: 2.076514724762209

Epoch: 155| Step: 0
Training loss: 1.951603889465332
Validation loss: 2.0590503292699016

Epoch: 5| Step: 1
Training loss: 1.6648986339569092
Validation loss: 2.0433698418319866

Epoch: 5| Step: 2
Training loss: 2.4525434970855713
Validation loss: 2.0462358356803976

Epoch: 5| Step: 3
Training loss: 1.896114706993103
Validation loss: 2.052762628883444

Epoch: 5| Step: 4
Training loss: 2.2353451251983643
Validation loss: 2.0736207654399257

Epoch: 5| Step: 5
Training loss: 2.0177619457244873
Validation loss: 2.110335211600027

Epoch: 5| Step: 6
Training loss: 1.929566740989685
Validation loss: 2.1610526910392185

Epoch: 5| Step: 7
Training loss: 2.1203548908233643
Validation loss: 2.218158821905813

Epoch: 5| Step: 8
Training loss: 2.084742784500122
Validation loss: 2.2283369238658617

Epoch: 5| Step: 9
Training loss: 2.085178852081299
Validation loss: 2.2011451311008905

Epoch: 5| Step: 10
Training loss: 2.740274429321289
Validation loss: 2.1496059022923952

Epoch: 156| Step: 0
Training loss: 2.409895181655884
Validation loss: 2.097845627415565

Epoch: 5| Step: 1
Training loss: 2.1824231147766113
Validation loss: 2.0827761593685357

Epoch: 5| Step: 2
Training loss: 2.1588032245635986
Validation loss: 2.069878996700369

Epoch: 5| Step: 3
Training loss: 2.148703098297119
Validation loss: 2.057600618690573

Epoch: 5| Step: 4
Training loss: 1.9805999994277954
Validation loss: 2.065528755546898

Epoch: 5| Step: 5
Training loss: 1.4634721279144287
Validation loss: 2.0804878204099593

Epoch: 5| Step: 6
Training loss: 2.496424913406372
Validation loss: 2.107055546135031

Epoch: 5| Step: 7
Training loss: 1.6757198572158813
Validation loss: 2.119786265075848

Epoch: 5| Step: 8
Training loss: 1.817684531211853
Validation loss: 2.1585764141492945

Epoch: 5| Step: 9
Training loss: 1.9131746292114258
Validation loss: 2.1817016652835313

Epoch: 5| Step: 10
Training loss: 2.3363428115844727
Validation loss: 2.1979489057294783

Epoch: 157| Step: 0
Training loss: 2.028449058532715
Validation loss: 2.168547737982965

Epoch: 5| Step: 1
Training loss: 1.9419100284576416
Validation loss: 2.130214173306701

Epoch: 5| Step: 2
Training loss: 2.188894748687744
Validation loss: 2.0962222135195168

Epoch: 5| Step: 3
Training loss: 2.368016481399536
Validation loss: 2.0775491729859383

Epoch: 5| Step: 4
Training loss: 2.070854425430298
Validation loss: 2.0654480149669032

Epoch: 5| Step: 5
Training loss: 2.3309292793273926
Validation loss: 2.0794372891867035

Epoch: 5| Step: 6
Training loss: 1.331813097000122
Validation loss: 2.1060034946728776

Epoch: 5| Step: 7
Training loss: 1.550292730331421
Validation loss: 2.1356495016364643

Epoch: 5| Step: 8
Training loss: 2.0389647483825684
Validation loss: 2.14243850784917

Epoch: 5| Step: 9
Training loss: 2.764615297317505
Validation loss: 2.116083739906229

Epoch: 5| Step: 10
Training loss: 1.632306694984436
Validation loss: 2.0954939216695805

Epoch: 158| Step: 0
Training loss: 2.1341004371643066
Validation loss: 2.1098731230663996

Epoch: 5| Step: 1
Training loss: 2.100355863571167
Validation loss: 2.0938722215672976

Epoch: 5| Step: 2
Training loss: 2.162783622741699
Validation loss: 2.0888531310583955

Epoch: 5| Step: 3
Training loss: 2.185325860977173
Validation loss: 2.107213451016334

Epoch: 5| Step: 4
Training loss: 2.0051262378692627
Validation loss: 2.1075546485121532

Epoch: 5| Step: 5
Training loss: 1.971017837524414
Validation loss: 2.117698359233077

Epoch: 5| Step: 6
Training loss: 2.6324682235717773
Validation loss: 2.1098124904017292

Epoch: 5| Step: 7
Training loss: 1.8682466745376587
Validation loss: 2.092759547695037

Epoch: 5| Step: 8
Training loss: 1.0993210077285767
Validation loss: 2.0840423312238467

Epoch: 5| Step: 9
Training loss: 1.5140798091888428
Validation loss: 2.079369188636862

Epoch: 5| Step: 10
Training loss: 2.4708428382873535
Validation loss: 2.089220154669977

Epoch: 159| Step: 0
Training loss: 1.6243683099746704
Validation loss: 2.0825304344136226

Epoch: 5| Step: 1
Training loss: 1.737000823020935
Validation loss: 2.1084605288761917

Epoch: 5| Step: 2
Training loss: 1.76263427734375
Validation loss: 2.1242586694737917

Epoch: 5| Step: 3
Training loss: 2.1888227462768555
Validation loss: 2.1336444065135014

Epoch: 5| Step: 4
Training loss: 2.063565731048584
Validation loss: 2.112609996590563

Epoch: 5| Step: 5
Training loss: 1.8030624389648438
Validation loss: 2.113019061344926

Epoch: 5| Step: 6
Training loss: 1.9034579992294312
Validation loss: 2.1010487617984897

Epoch: 5| Step: 7
Training loss: 2.654818058013916
Validation loss: 2.092922527302978

Epoch: 5| Step: 8
Training loss: 1.7481130361557007
Validation loss: 2.085310543737104

Epoch: 5| Step: 9
Training loss: 2.6054375171661377
Validation loss: 2.0902183773697063

Epoch: 5| Step: 10
Training loss: 2.0884904861450195
Validation loss: 2.100478623502998

Epoch: 160| Step: 0
Training loss: 2.5544357299804688
Validation loss: 2.1410509719643542

Epoch: 5| Step: 1
Training loss: 2.2849009037017822
Validation loss: 2.2226221920341573

Epoch: 5| Step: 2
Training loss: 1.7963829040527344
Validation loss: 2.2719736073606756

Epoch: 5| Step: 3
Training loss: 1.7566955089569092
Validation loss: 2.2839250154392694

Epoch: 5| Step: 4
Training loss: 1.8919670581817627
Validation loss: 2.2555964505800636

Epoch: 5| Step: 5
Training loss: 2.5809903144836426
Validation loss: 2.1862821220069804

Epoch: 5| Step: 6
Training loss: 2.0288100242614746
Validation loss: 2.1528641831490303

Epoch: 5| Step: 7
Training loss: 1.9627717733383179
Validation loss: 2.0953062939387497

Epoch: 5| Step: 8
Training loss: 1.3374903202056885
Validation loss: 2.072654406229655

Epoch: 5| Step: 9
Training loss: 1.6791942119598389
Validation loss: 2.063873871680229

Epoch: 5| Step: 10
Training loss: 2.2433300018310547
Validation loss: 2.0908095836639404

Epoch: 161| Step: 0
Training loss: 2.2543771266937256
Validation loss: 2.118022730273585

Epoch: 5| Step: 1
Training loss: 1.987732172012329
Validation loss: 2.1629423672153103

Epoch: 5| Step: 2
Training loss: 2.029585361480713
Validation loss: 2.196911229882189

Epoch: 5| Step: 3
Training loss: 1.4192148447036743
Validation loss: 2.2162148029573503

Epoch: 5| Step: 4
Training loss: 2.1066806316375732
Validation loss: 2.1930644832631594

Epoch: 5| Step: 5
Training loss: 1.6714404821395874
Validation loss: 2.146044751649262

Epoch: 5| Step: 6
Training loss: 2.4016478061676025
Validation loss: 2.1189711683539936

Epoch: 5| Step: 7
Training loss: 2.093074083328247
Validation loss: 2.0778863430023193

Epoch: 5| Step: 8
Training loss: 2.3071353435516357
Validation loss: 2.0645701475040887

Epoch: 5| Step: 9
Training loss: 1.798277497291565
Validation loss: 2.042908291662893

Epoch: 5| Step: 10
Training loss: 1.6655510663986206
Validation loss: 2.054760048466344

Epoch: 162| Step: 0
Training loss: 1.6955769062042236
Validation loss: 2.0704521158690095

Epoch: 5| Step: 1
Training loss: 2.275402545928955
Validation loss: 2.0936354283363587

Epoch: 5| Step: 2
Training loss: 2.992650270462036
Validation loss: 2.136233560500606

Epoch: 5| Step: 3
Training loss: 1.7410545349121094
Validation loss: 2.1960464549321

Epoch: 5| Step: 4
Training loss: 1.9291194677352905
Validation loss: 2.2530613817194456

Epoch: 5| Step: 5
Training loss: 1.9822603464126587
Validation loss: 2.3261761678162443

Epoch: 5| Step: 6
Training loss: 1.828243613243103
Validation loss: 2.2871159609927925

Epoch: 5| Step: 7
Training loss: 2.1100783348083496
Validation loss: 2.235864687991399

Epoch: 5| Step: 8
Training loss: 1.7001903057098389
Validation loss: 2.1444878296185563

Epoch: 5| Step: 9
Training loss: 1.378051996231079
Validation loss: 2.0902227470951695

Epoch: 5| Step: 10
Training loss: 2.5865583419799805
Validation loss: 2.059873532223445

Epoch: 163| Step: 0
Training loss: 1.8024415969848633
Validation loss: 2.0522623805589575

Epoch: 5| Step: 1
Training loss: 2.01318359375
Validation loss: 2.0577365275352233

Epoch: 5| Step: 2
Training loss: 2.638587474822998
Validation loss: 2.0511862103657057

Epoch: 5| Step: 3
Training loss: 2.2768361568450928
Validation loss: 2.053758757088774

Epoch: 5| Step: 4
Training loss: 1.9119176864624023
Validation loss: 2.044080147179224

Epoch: 5| Step: 5
Training loss: 1.849495530128479
Validation loss: 2.0645460595366774

Epoch: 5| Step: 6
Training loss: 2.5073750019073486
Validation loss: 2.0620940475053686

Epoch: 5| Step: 7
Training loss: 1.9520622491836548
Validation loss: 2.1192282451096403

Epoch: 5| Step: 8
Training loss: 1.8205502033233643
Validation loss: 2.173277629319058

Epoch: 5| Step: 9
Training loss: 1.362500548362732
Validation loss: 2.228848465027348

Epoch: 5| Step: 10
Training loss: 2.201211929321289
Validation loss: 2.2975741432559107

Epoch: 164| Step: 0
Training loss: 2.143012523651123
Validation loss: 2.257222557580599

Epoch: 5| Step: 1
Training loss: 2.018162965774536
Validation loss: 2.1898475359844904

Epoch: 5| Step: 2
Training loss: 1.9779106378555298
Validation loss: 2.1401062344992035

Epoch: 5| Step: 3
Training loss: 2.3210513591766357
Validation loss: 2.1138338606844664

Epoch: 5| Step: 4
Training loss: 2.10451078414917
Validation loss: 2.096192208669519

Epoch: 5| Step: 5
Training loss: 1.1965701580047607
Validation loss: 2.0797322180963334

Epoch: 5| Step: 6
Training loss: 2.0498528480529785
Validation loss: 2.0651380195412585

Epoch: 5| Step: 7
Training loss: 2.137230396270752
Validation loss: 2.0705024298801216

Epoch: 5| Step: 8
Training loss: 1.5418981313705444
Validation loss: 2.0712810562502955

Epoch: 5| Step: 9
Training loss: 2.0122082233428955
Validation loss: 2.0695600830098635

Epoch: 5| Step: 10
Training loss: 2.2084081172943115
Validation loss: 2.0978566651703208

Epoch: 165| Step: 0
Training loss: 2.109158754348755
Validation loss: 2.1344170852374007

Epoch: 5| Step: 1
Training loss: 1.302225947380066
Validation loss: 2.1913520008005123

Epoch: 5| Step: 2
Training loss: 2.251647710800171
Validation loss: 2.2048740258780857

Epoch: 5| Step: 3
Training loss: 1.7706438302993774
Validation loss: 2.219802515481108

Epoch: 5| Step: 4
Training loss: 1.8933992385864258
Validation loss: 2.2277147282836256

Epoch: 5| Step: 5
Training loss: 1.9575779438018799
Validation loss: 2.216145505187332

Epoch: 5| Step: 6
Training loss: 2.4582207202911377
Validation loss: 2.1625532591214744

Epoch: 5| Step: 7
Training loss: 2.314152717590332
Validation loss: 2.089887253699764

Epoch: 5| Step: 8
Training loss: 1.598466157913208
Validation loss: 2.0636212748865925

Epoch: 5| Step: 9
Training loss: 2.102210521697998
Validation loss: 2.0579774738639913

Epoch: 5| Step: 10
Training loss: 2.005479097366333
Validation loss: 2.036316904970395

Epoch: 166| Step: 0
Training loss: 1.9085445404052734
Validation loss: 2.042229654968426

Epoch: 5| Step: 1
Training loss: 1.7195374965667725
Validation loss: 2.0515890467551445

Epoch: 5| Step: 2
Training loss: 1.6701171398162842
Validation loss: 2.0625108852181384

Epoch: 5| Step: 3
Training loss: 2.335707902908325
Validation loss: 2.0638514603337934

Epoch: 5| Step: 4
Training loss: 1.8627471923828125
Validation loss: 2.1027753801756006

Epoch: 5| Step: 5
Training loss: 2.26213002204895
Validation loss: 2.1447486518531718

Epoch: 5| Step: 6
Training loss: 1.6981706619262695
Validation loss: 2.1506776707146757

Epoch: 5| Step: 7
Training loss: 1.4906162023544312
Validation loss: 2.1213533186143443

Epoch: 5| Step: 8
Training loss: 2.0612058639526367
Validation loss: 2.07096234572831

Epoch: 5| Step: 9
Training loss: 2.537902355194092
Validation loss: 2.0673727784105527

Epoch: 5| Step: 10
Training loss: 1.6867657899856567
Validation loss: 2.064939647592524

Epoch: 167| Step: 0
Training loss: 2.1099209785461426
Validation loss: 2.056596444499108

Epoch: 5| Step: 1
Training loss: 2.0319056510925293
Validation loss: 2.0637855170875468

Epoch: 5| Step: 2
Training loss: 1.6275043487548828
Validation loss: 2.0822167499091035

Epoch: 5| Step: 3
Training loss: 1.5220258235931396
Validation loss: 2.0812194424290813

Epoch: 5| Step: 4
Training loss: 2.0910074710845947
Validation loss: 2.1232568897226805

Epoch: 5| Step: 5
Training loss: 2.171877145767212
Validation loss: 2.147053587821222

Epoch: 5| Step: 6
Training loss: 1.4180703163146973
Validation loss: 2.179770287647042

Epoch: 5| Step: 7
Training loss: 2.3453423976898193
Validation loss: 2.23161901966218

Epoch: 5| Step: 8
Training loss: 1.8866485357284546
Validation loss: 2.2374457082440777

Epoch: 5| Step: 9
Training loss: 2.0536491870880127
Validation loss: 2.1579075692802347

Epoch: 5| Step: 10
Training loss: 1.955670714378357
Validation loss: 2.1070718637076755

Epoch: 168| Step: 0
Training loss: 2.6897544860839844
Validation loss: 2.082629124323527

Epoch: 5| Step: 1
Training loss: 2.3800439834594727
Validation loss: 2.074246714192052

Epoch: 5| Step: 2
Training loss: 1.7608356475830078
Validation loss: 2.048914163343368

Epoch: 5| Step: 3
Training loss: 1.733496904373169
Validation loss: 2.0667921727703464

Epoch: 5| Step: 4
Training loss: 1.8819000720977783
Validation loss: 2.0887981794213735

Epoch: 5| Step: 5
Training loss: 1.745126724243164
Validation loss: 2.1194182672808246

Epoch: 5| Step: 6
Training loss: 1.4995529651641846
Validation loss: 2.1575382589012064

Epoch: 5| Step: 7
Training loss: 1.8996198177337646
Validation loss: 2.204883994594697

Epoch: 5| Step: 8
Training loss: 1.680032730102539
Validation loss: 2.229593046249882

Epoch: 5| Step: 9
Training loss: 1.9453203678131104
Validation loss: 2.224874017059162

Epoch: 5| Step: 10
Training loss: 2.2346982955932617
Validation loss: 2.210553851178897

Epoch: 169| Step: 0
Training loss: 1.4939277172088623
Validation loss: 2.1183992329464165

Epoch: 5| Step: 1
Training loss: 1.4176695346832275
Validation loss: 2.096743852861466

Epoch: 5| Step: 2
Training loss: 2.2937474250793457
Validation loss: 2.0778093773831605

Epoch: 5| Step: 3
Training loss: 2.462631940841675
Validation loss: 2.0789003782374884

Epoch: 5| Step: 4
Training loss: 2.4865946769714355
Validation loss: 2.087154738364681

Epoch: 5| Step: 5
Training loss: 1.4897011518478394
Validation loss: 2.0732050352199103

Epoch: 5| Step: 6
Training loss: 1.9677852392196655
Validation loss: 2.07916166961834

Epoch: 5| Step: 7
Training loss: 2.5136523246765137
Validation loss: 2.0678141988733763

Epoch: 5| Step: 8
Training loss: 1.6668552160263062
Validation loss: 2.0746418276140766

Epoch: 5| Step: 9
Training loss: 1.6008485555648804
Validation loss: 2.098429476061175

Epoch: 5| Step: 10
Training loss: 1.3390352725982666
Validation loss: 2.126523971557617

Epoch: 170| Step: 0
Training loss: 1.6895039081573486
Validation loss: 2.1470745314833937

Epoch: 5| Step: 1
Training loss: 2.071868419647217
Validation loss: 2.1361435562051754

Epoch: 5| Step: 2
Training loss: 1.8576686382293701
Validation loss: 2.123281578863821

Epoch: 5| Step: 3
Training loss: 1.3737685680389404
Validation loss: 2.116212543620858

Epoch: 5| Step: 4
Training loss: 1.7360725402832031
Validation loss: 2.1011209154641755

Epoch: 5| Step: 5
Training loss: 2.2588467597961426
Validation loss: 2.0837563891564646

Epoch: 5| Step: 6
Training loss: 2.699279308319092
Validation loss: 2.0891263779773506

Epoch: 5| Step: 7
Training loss: 1.4942023754119873
Validation loss: 2.1091006020063996

Epoch: 5| Step: 8
Training loss: 1.9665391445159912
Validation loss: 2.1270518495190527

Epoch: 5| Step: 9
Training loss: 2.098917245864868
Validation loss: 2.1062037790975263

Epoch: 5| Step: 10
Training loss: 1.5623310804367065
Validation loss: 2.0819119138102375

Epoch: 171| Step: 0
Training loss: 1.8154613971710205
Validation loss: 2.0652657785723285

Epoch: 5| Step: 1
Training loss: 1.9148480892181396
Validation loss: 2.0697372062231905

Epoch: 5| Step: 2
Training loss: 2.214977502822876
Validation loss: 2.0687132919988325

Epoch: 5| Step: 3
Training loss: 2.296462297439575
Validation loss: 2.068011341556426

Epoch: 5| Step: 4
Training loss: 1.8463518619537354
Validation loss: 2.0808483554470922

Epoch: 5| Step: 5
Training loss: 1.9461791515350342
Validation loss: 2.0815433020232827

Epoch: 5| Step: 6
Training loss: 1.5784287452697754
Validation loss: 2.1136613789425103

Epoch: 5| Step: 7
Training loss: 1.7201392650604248
Validation loss: 2.1169807398191063

Epoch: 5| Step: 8
Training loss: 1.8154878616333008
Validation loss: 2.143313874480545

Epoch: 5| Step: 9
Training loss: 1.6403744220733643
Validation loss: 2.1313371927507463

Epoch: 5| Step: 10
Training loss: 1.6081708669662476
Validation loss: 2.121312023490988

Epoch: 172| Step: 0
Training loss: 2.393531322479248
Validation loss: 2.0998533643702024

Epoch: 5| Step: 1
Training loss: 1.8868329524993896
Validation loss: 2.089134475236298

Epoch: 5| Step: 2
Training loss: 1.6108283996582031
Validation loss: 2.0750422400812947

Epoch: 5| Step: 3
Training loss: 1.573180913925171
Validation loss: 2.066338021268127

Epoch: 5| Step: 4
Training loss: 1.8251488208770752
Validation loss: 2.0540595592991

Epoch: 5| Step: 5
Training loss: 1.952289342880249
Validation loss: 2.0770101957423712

Epoch: 5| Step: 6
Training loss: 1.9378551244735718
Validation loss: 2.080826546556206

Epoch: 5| Step: 7
Training loss: 1.6060545444488525
Validation loss: 2.1037812104789158

Epoch: 5| Step: 8
Training loss: 2.68205189704895
Validation loss: 2.1347583211878294

Epoch: 5| Step: 9
Training loss: 1.3810316324234009
Validation loss: 2.143809562088341

Epoch: 5| Step: 10
Training loss: 1.658435583114624
Validation loss: 2.1465573797943773

Epoch: 173| Step: 0
Training loss: 2.488638401031494
Validation loss: 2.132269308131228

Epoch: 5| Step: 1
Training loss: 1.0425196886062622
Validation loss: 2.081131814628519

Epoch: 5| Step: 2
Training loss: 2.1226906776428223
Validation loss: 2.059989566444069

Epoch: 5| Step: 3
Training loss: 2.435831069946289
Validation loss: 2.0518765449523926

Epoch: 5| Step: 4
Training loss: 2.145906925201416
Validation loss: 2.066661778316703

Epoch: 5| Step: 5
Training loss: 1.7635434865951538
Validation loss: 2.051422416522939

Epoch: 5| Step: 6
Training loss: 1.6683269739151
Validation loss: 2.058281478061471

Epoch: 5| Step: 7
Training loss: 1.5364729166030884
Validation loss: 2.0842212682129233

Epoch: 5| Step: 8
Training loss: 2.0552268028259277
Validation loss: 2.102873320220619

Epoch: 5| Step: 9
Training loss: 1.8846015930175781
Validation loss: 2.1238534450531006

Epoch: 5| Step: 10
Training loss: 1.1107666492462158
Validation loss: 2.1702801771061395

Epoch: 174| Step: 0
Training loss: 1.8628737926483154
Validation loss: 2.153601731023481

Epoch: 5| Step: 1
Training loss: 1.8110969066619873
Validation loss: 2.1625306119201

Epoch: 5| Step: 2
Training loss: 1.3499479293823242
Validation loss: 2.140123159654679

Epoch: 5| Step: 3
Training loss: 1.598448395729065
Validation loss: 2.1232899376141128

Epoch: 5| Step: 4
Training loss: 2.108492612838745
Validation loss: 2.1263726398509037

Epoch: 5| Step: 5
Training loss: 1.3571205139160156
Validation loss: 2.099085569381714

Epoch: 5| Step: 6
Training loss: 1.9372165203094482
Validation loss: 2.0751517472728604

Epoch: 5| Step: 7
Training loss: 2.6274983882904053
Validation loss: 2.0727187228459183

Epoch: 5| Step: 8
Training loss: 1.5384876728057861
Validation loss: 2.0721434444509526

Epoch: 5| Step: 9
Training loss: 2.296933174133301
Validation loss: 2.0718144703936834

Epoch: 5| Step: 10
Training loss: 1.648219347000122
Validation loss: 2.071300168191233

Epoch: 175| Step: 0
Training loss: 1.6707589626312256
Validation loss: 2.08223908434632

Epoch: 5| Step: 1
Training loss: 1.961370825767517
Validation loss: 2.093543447473998

Epoch: 5| Step: 2
Training loss: 1.7496225833892822
Validation loss: 2.1000052139323246

Epoch: 5| Step: 3
Training loss: 1.8023523092269897
Validation loss: 2.117422931937761

Epoch: 5| Step: 4
Training loss: 1.4101226329803467
Validation loss: 2.1476536348301876

Epoch: 5| Step: 5
Training loss: 1.7485904693603516
Validation loss: 2.176717840215211

Epoch: 5| Step: 6
Training loss: 2.6329572200775146
Validation loss: 2.1998031447010655

Epoch: 5| Step: 7
Training loss: 1.9898790121078491
Validation loss: 2.1715625127156577

Epoch: 5| Step: 8
Training loss: 1.613223671913147
Validation loss: 2.1267135092007217

Epoch: 5| Step: 9
Training loss: 1.6689422130584717
Validation loss: 2.0847856113987584

Epoch: 5| Step: 10
Training loss: 1.8659050464630127
Validation loss: 2.0704379107362483

Epoch: 176| Step: 0
Training loss: 1.144310712814331
Validation loss: 2.0627891658454813

Epoch: 5| Step: 1
Training loss: 1.524850606918335
Validation loss: 2.0754252915741294

Epoch: 5| Step: 2
Training loss: 1.7701534032821655
Validation loss: 2.0728126520751626

Epoch: 5| Step: 3
Training loss: 1.9363609552383423
Validation loss: 2.0973272426154024

Epoch: 5| Step: 4
Training loss: 2.9608840942382812
Validation loss: 2.144028657226152

Epoch: 5| Step: 5
Training loss: 1.5140178203582764
Validation loss: 2.1618192170255925

Epoch: 5| Step: 6
Training loss: 1.8448337316513062
Validation loss: 2.1399790215235885

Epoch: 5| Step: 7
Training loss: 1.5472456216812134
Validation loss: 2.122223828428535

Epoch: 5| Step: 8
Training loss: 2.04534912109375
Validation loss: 2.082177903062554

Epoch: 5| Step: 9
Training loss: 2.0596930980682373
Validation loss: 2.0794082687747095

Epoch: 5| Step: 10
Training loss: 1.842801570892334
Validation loss: 2.053856116469188

Epoch: 177| Step: 0
Training loss: 1.6980221271514893
Validation loss: 2.07282615605221

Epoch: 5| Step: 1
Training loss: 1.9131383895874023
Validation loss: 2.070311423270933

Epoch: 5| Step: 2
Training loss: 1.3338522911071777
Validation loss: 2.0896981300846225

Epoch: 5| Step: 3
Training loss: 2.227660655975342
Validation loss: 2.1069184913430163

Epoch: 5| Step: 4
Training loss: 2.470987558364868
Validation loss: 2.1268100161706247

Epoch: 5| Step: 5
Training loss: 1.4656298160552979
Validation loss: 2.1326843974410847

Epoch: 5| Step: 6
Training loss: 1.3594688177108765
Validation loss: 2.144448047043175

Epoch: 5| Step: 7
Training loss: 2.290086269378662
Validation loss: 2.1324945316519788

Epoch: 5| Step: 8
Training loss: 1.4660437107086182
Validation loss: 2.118197241137105

Epoch: 5| Step: 9
Training loss: 1.3217610120773315
Validation loss: 2.1144000637915825

Epoch: 5| Step: 10
Training loss: 2.154691457748413
Validation loss: 2.096354091039268

Epoch: 178| Step: 0
Training loss: 1.8530981540679932
Validation loss: 2.0820552943855204

Epoch: 5| Step: 1
Training loss: 2.4608826637268066
Validation loss: 2.09608063133814

Epoch: 5| Step: 2
Training loss: 1.310840368270874
Validation loss: 2.1038376887639365

Epoch: 5| Step: 3
Training loss: 1.9404308795928955
Validation loss: 2.0831447211644982

Epoch: 5| Step: 4
Training loss: 1.7437251806259155
Validation loss: 2.097780766025666

Epoch: 5| Step: 5
Training loss: 1.4647243022918701
Validation loss: 2.11435769706644

Epoch: 5| Step: 6
Training loss: 2.268646001815796
Validation loss: 2.09030597184294

Epoch: 5| Step: 7
Training loss: 1.812578797340393
Validation loss: 2.0930005388875164

Epoch: 5| Step: 8
Training loss: 1.5709621906280518
Validation loss: 2.0901644742617043

Epoch: 5| Step: 9
Training loss: 1.484370470046997
Validation loss: 2.12796615528804

Epoch: 5| Step: 10
Training loss: 1.6380482912063599
Validation loss: 2.106117792026971

Epoch: 179| Step: 0
Training loss: 2.1865851879119873
Validation loss: 2.111412981505035

Epoch: 5| Step: 1
Training loss: 1.73735773563385
Validation loss: 2.1143427177142073

Epoch: 5| Step: 2
Training loss: 1.6034228801727295
Validation loss: 2.093494742147384

Epoch: 5| Step: 3
Training loss: 1.2992199659347534
Validation loss: 2.090065525424096

Epoch: 5| Step: 4
Training loss: 1.9637782573699951
Validation loss: 2.0464036746691634

Epoch: 5| Step: 5
Training loss: 1.5739548206329346
Validation loss: 2.0493177342158493

Epoch: 5| Step: 6
Training loss: 1.4718575477600098
Validation loss: 2.060300047679614

Epoch: 5| Step: 7
Training loss: 1.905006766319275
Validation loss: 2.0712318215318906

Epoch: 5| Step: 8
Training loss: 2.0559282302856445
Validation loss: 2.0760471410648798

Epoch: 5| Step: 9
Training loss: 2.1865947246551514
Validation loss: 2.1363791470886557

Epoch: 5| Step: 10
Training loss: 1.523335576057434
Validation loss: 2.185728621739213

Epoch: 180| Step: 0
Training loss: 1.6280372142791748
Validation loss: 2.1795239269092517

Epoch: 5| Step: 1
Training loss: 1.7491405010223389
Validation loss: 2.1624427585191626

Epoch: 5| Step: 2
Training loss: 1.8467652797698975
Validation loss: 2.1675879852746123

Epoch: 5| Step: 3
Training loss: 2.0663375854492188
Validation loss: 2.134939650053619

Epoch: 5| Step: 4
Training loss: 1.3309465646743774
Validation loss: 2.1258737079558836

Epoch: 5| Step: 5
Training loss: 1.661486268043518
Validation loss: 2.101594216080122

Epoch: 5| Step: 6
Training loss: 1.5252125263214111
Validation loss: 2.107162191021827

Epoch: 5| Step: 7
Training loss: 2.2345118522644043
Validation loss: 2.1080217643450667

Epoch: 5| Step: 8
Training loss: 1.7236045598983765
Validation loss: 2.12011916406693

Epoch: 5| Step: 9
Training loss: 1.6366208791732788
Validation loss: 2.1238854623609975

Epoch: 5| Step: 10
Training loss: 2.031820297241211
Validation loss: 2.1281968688452118

Epoch: 181| Step: 0
Training loss: 1.3416377305984497
Validation loss: 2.1232216717094503

Epoch: 5| Step: 1
Training loss: 2.331970453262329
Validation loss: 2.11944418568765

Epoch: 5| Step: 2
Training loss: 1.743361473083496
Validation loss: 2.13375517629808

Epoch: 5| Step: 3
Training loss: 1.846614122390747
Validation loss: 2.154231527800201

Epoch: 5| Step: 4
Training loss: 2.1166200637817383
Validation loss: 2.1502214195907756

Epoch: 5| Step: 5
Training loss: 1.648407220840454
Validation loss: 2.1200240145447435

Epoch: 5| Step: 6
Training loss: 1.2690433263778687
Validation loss: 2.070150536875571

Epoch: 5| Step: 7
Training loss: 1.7806304693222046
Validation loss: 2.0838696725906862

Epoch: 5| Step: 8
Training loss: 1.975690484046936
Validation loss: 2.094311084798587

Epoch: 5| Step: 9
Training loss: 1.6062376499176025
Validation loss: 2.1041083835786387

Epoch: 5| Step: 10
Training loss: 1.3750168085098267
Validation loss: 2.103678772526403

Epoch: 182| Step: 0
Training loss: 1.895509958267212
Validation loss: 2.092861685701596

Epoch: 5| Step: 1
Training loss: 1.430189847946167
Validation loss: 2.0809982566423315

Epoch: 5| Step: 2
Training loss: 1.96905517578125
Validation loss: 2.0810002139819566

Epoch: 5| Step: 3
Training loss: 1.901519536972046
Validation loss: 2.0870541628970893

Epoch: 5| Step: 4
Training loss: 1.7526664733886719
Validation loss: 2.1104155458429807

Epoch: 5| Step: 5
Training loss: 1.933753252029419
Validation loss: 2.086116715144086

Epoch: 5| Step: 6
Training loss: 1.4820337295532227
Validation loss: 2.076080640157064

Epoch: 5| Step: 7
Training loss: 1.653428077697754
Validation loss: 2.0578343022254204

Epoch: 5| Step: 8
Training loss: 1.738506555557251
Validation loss: 2.0782737091023433

Epoch: 5| Step: 9
Training loss: 1.4775537252426147
Validation loss: 2.101147928545552

Epoch: 5| Step: 10
Training loss: 1.768043041229248
Validation loss: 2.107353392467704

Epoch: 183| Step: 0
Training loss: 1.5691912174224854
Validation loss: 2.1193021676873647

Epoch: 5| Step: 1
Training loss: 1.2667137384414673
Validation loss: 2.1451395609045543

Epoch: 5| Step: 2
Training loss: 1.9841060638427734
Validation loss: 2.1273244324550835

Epoch: 5| Step: 3
Training loss: 0.7924439311027527
Validation loss: 2.126189657436904

Epoch: 5| Step: 4
Training loss: 1.95314621925354
Validation loss: 2.107796243442002

Epoch: 5| Step: 5
Training loss: 1.693437933921814
Validation loss: 2.1210719103454263

Epoch: 5| Step: 6
Training loss: 1.9215558767318726
Validation loss: 2.0990454125147995

Epoch: 5| Step: 7
Training loss: 2.1009130477905273
Validation loss: 2.1087351691338325

Epoch: 5| Step: 8
Training loss: 1.7865279912948608
Validation loss: 2.1212883918516097

Epoch: 5| Step: 9
Training loss: 1.5393375158309937
Validation loss: 2.109303225753128

Epoch: 5| Step: 10
Training loss: 2.253861665725708
Validation loss: 2.1178528621632564

Epoch: 184| Step: 0
Training loss: 2.0084035396575928
Validation loss: 2.135653482970371

Epoch: 5| Step: 1
Training loss: 1.2968066930770874
Validation loss: 2.1466238857597433

Epoch: 5| Step: 2
Training loss: 1.5963035821914673
Validation loss: 2.1722845595370055

Epoch: 5| Step: 3
Training loss: 1.7917884588241577
Validation loss: 2.1985259004818496

Epoch: 5| Step: 4
Training loss: 1.9697341918945312
Validation loss: 2.2049111038125973

Epoch: 5| Step: 5
Training loss: 2.071110963821411
Validation loss: 2.225020562448809

Epoch: 5| Step: 6
Training loss: 1.638898491859436
Validation loss: 2.207826519525179

Epoch: 5| Step: 7
Training loss: 1.1715128421783447
Validation loss: 2.1815857041266655

Epoch: 5| Step: 8
Training loss: 1.7330505847930908
Validation loss: 2.146769306992972

Epoch: 5| Step: 9
Training loss: 1.7069311141967773
Validation loss: 2.1533531886275097

Epoch: 5| Step: 10
Training loss: 1.6782370805740356
Validation loss: 2.111402750015259

Epoch: 185| Step: 0
Training loss: 2.09846830368042
Validation loss: 2.0845006178784113

Epoch: 5| Step: 1
Training loss: 1.9450256824493408
Validation loss: 2.072747015183972

Epoch: 5| Step: 2
Training loss: 2.3780665397644043
Validation loss: 2.092953863964286

Epoch: 5| Step: 3
Training loss: 1.62705397605896
Validation loss: 2.1220190653236966

Epoch: 5| Step: 4
Training loss: 1.8184036016464233
Validation loss: 2.149388979840022

Epoch: 5| Step: 5
Training loss: 1.318047285079956
Validation loss: 2.1638902156583724

Epoch: 5| Step: 6
Training loss: 1.4970576763153076
Validation loss: 2.179091715043591

Epoch: 5| Step: 7
Training loss: 1.5493855476379395
Validation loss: 2.164635673646004

Epoch: 5| Step: 8
Training loss: 1.3789446353912354
Validation loss: 2.1404906319033716

Epoch: 5| Step: 9
Training loss: 1.318193793296814
Validation loss: 2.172812082434213

Epoch: 5| Step: 10
Training loss: 1.840072512626648
Validation loss: 2.1929829556454896

Epoch: 186| Step: 0
Training loss: 1.4092730283737183
Validation loss: 2.158273764835891

Epoch: 5| Step: 1
Training loss: 1.7993013858795166
Validation loss: 2.1687502527749665

Epoch: 5| Step: 2
Training loss: 1.6170594692230225
Validation loss: 2.1496188127866356

Epoch: 5| Step: 3
Training loss: 1.8400115966796875
Validation loss: 2.104203362618723

Epoch: 5| Step: 4
Training loss: 1.8131237030029297
Validation loss: 2.0861388906355827

Epoch: 5| Step: 5
Training loss: 1.75765860080719
Validation loss: 2.070194349494032

Epoch: 5| Step: 6
Training loss: 2.569019317626953
Validation loss: 2.1150717927563574

Epoch: 5| Step: 7
Training loss: 1.507830262184143
Validation loss: 2.1309066767333658

Epoch: 5| Step: 8
Training loss: 1.2408007383346558
Validation loss: 2.1357012923045824

Epoch: 5| Step: 9
Training loss: 1.9069201946258545
Validation loss: 2.1446989633703746

Epoch: 5| Step: 10
Training loss: 1.2233874797821045
Validation loss: 2.1423016966030164

Epoch: 187| Step: 0
Training loss: 1.70491623878479
Validation loss: 2.126727286205497

Epoch: 5| Step: 1
Training loss: 1.6326097249984741
Validation loss: 2.115168474053824

Epoch: 5| Step: 2
Training loss: 1.6015727519989014
Validation loss: 2.0890297415435954

Epoch: 5| Step: 3
Training loss: 2.148493528366089
Validation loss: 2.0811860458825224

Epoch: 5| Step: 4
Training loss: 1.5755066871643066
Validation loss: 2.0993292562423216

Epoch: 5| Step: 5
Training loss: 1.3908785581588745
Validation loss: 2.117967995264197

Epoch: 5| Step: 6
Training loss: 1.562178134918213
Validation loss: 2.1608884488382647

Epoch: 5| Step: 7
Training loss: 1.2558730840682983
Validation loss: 2.253284664564235

Epoch: 5| Step: 8
Training loss: 1.470386266708374
Validation loss: 2.2391475528799076

Epoch: 5| Step: 9
Training loss: 2.0546882152557373
Validation loss: 2.1640886786163493

Epoch: 5| Step: 10
Training loss: 2.1478967666625977
Validation loss: 2.1465807499424105

Epoch: 188| Step: 0
Training loss: 1.536419153213501
Validation loss: 2.1329522414874007

Epoch: 5| Step: 1
Training loss: 1.5823055505752563
Validation loss: 2.1243889331817627

Epoch: 5| Step: 2
Training loss: 1.5779459476470947
Validation loss: 2.1267647409951813

Epoch: 5| Step: 3
Training loss: 1.3963936567306519
Validation loss: 2.1840861638387046

Epoch: 5| Step: 4
Training loss: 1.7835884094238281
Validation loss: 2.2437007017033075

Epoch: 5| Step: 5
Training loss: 1.959855318069458
Validation loss: 2.2646356833878385

Epoch: 5| Step: 6
Training loss: 1.7731281518936157
Validation loss: 2.2346795041074037

Epoch: 5| Step: 7
Training loss: 2.0328383445739746
Validation loss: 2.210486832485404

Epoch: 5| Step: 8
Training loss: 1.866231918334961
Validation loss: 2.1448359284349667

Epoch: 5| Step: 9
Training loss: 1.4215081930160522
Validation loss: 2.1038103103637695

Epoch: 5| Step: 10
Training loss: 1.5727185010910034
Validation loss: 2.0512261672686507

Epoch: 189| Step: 0
Training loss: 1.5402636528015137
Validation loss: 2.02280137103091

Epoch: 5| Step: 1
Training loss: 1.94095778465271
Validation loss: 2.014377373521046

Epoch: 5| Step: 2
Training loss: 1.6643781661987305
Validation loss: 1.9967518147601877

Epoch: 5| Step: 3
Training loss: 1.1556451320648193
Validation loss: 1.9924251879415205

Epoch: 5| Step: 4
Training loss: 1.8458162546157837
Validation loss: 2.0416785696501374

Epoch: 5| Step: 5
Training loss: 1.152883529663086
Validation loss: 2.1223353083415697

Epoch: 5| Step: 6
Training loss: 1.933150053024292
Validation loss: 2.224540179775607

Epoch: 5| Step: 7
Training loss: 1.5875822305679321
Validation loss: 2.3187116012778333

Epoch: 5| Step: 8
Training loss: 2.109889268875122
Validation loss: 2.4368890306001068

Epoch: 5| Step: 9
Training loss: 2.2223453521728516
Validation loss: 2.50648989728702

Epoch: 5| Step: 10
Training loss: 2.6177453994750977
Validation loss: 2.515629688898722

Epoch: 190| Step: 0
Training loss: 1.393011450767517
Validation loss: 2.3835670512209655

Epoch: 5| Step: 1
Training loss: 1.799206018447876
Validation loss: 2.2626726601713445

Epoch: 5| Step: 2
Training loss: 1.6363804340362549
Validation loss: 2.099056445142274

Epoch: 5| Step: 3
Training loss: 1.764365792274475
Validation loss: 2.0426583085008847

Epoch: 5| Step: 4
Training loss: 1.962577223777771
Validation loss: 2.027550208953119

Epoch: 5| Step: 5
Training loss: 1.7712364196777344
Validation loss: 2.016604395322902

Epoch: 5| Step: 6
Training loss: 2.040294647216797
Validation loss: 2.0290950293182046

Epoch: 5| Step: 7
Training loss: 1.6271746158599854
Validation loss: 2.039964263157178

Epoch: 5| Step: 8
Training loss: 1.6861217021942139
Validation loss: 2.087452744924894

Epoch: 5| Step: 9
Training loss: 1.6272073984146118
Validation loss: 2.131520732756584

Epoch: 5| Step: 10
Training loss: 2.1203150749206543
Validation loss: 2.160983459923857

Epoch: 191| Step: 0
Training loss: 2.0243873596191406
Validation loss: 2.2397996328210317

Epoch: 5| Step: 1
Training loss: 2.1402270793914795
Validation loss: 2.279089955873387

Epoch: 5| Step: 2
Training loss: 1.6710106134414673
Validation loss: 2.299693702369608

Epoch: 5| Step: 3
Training loss: 1.3995485305786133
Validation loss: 2.282983636343351

Epoch: 5| Step: 4
Training loss: 1.1154335737228394
Validation loss: 2.2425140667987127

Epoch: 5| Step: 5
Training loss: 1.5955708026885986
Validation loss: 2.206547906321864

Epoch: 5| Step: 6
Training loss: 1.9502443075180054
Validation loss: 2.1497828242599324

Epoch: 5| Step: 7
Training loss: 2.003389835357666
Validation loss: 2.104166643593901

Epoch: 5| Step: 8
Training loss: 1.377954363822937
Validation loss: 2.088395080258769

Epoch: 5| Step: 9
Training loss: 1.985778570175171
Validation loss: 2.0728583182058027

Epoch: 5| Step: 10
Training loss: 1.2354035377502441
Validation loss: 2.0618243294377483

Epoch: 192| Step: 0
Training loss: 1.7684600353240967
Validation loss: 2.0748594140493744

Epoch: 5| Step: 1
Training loss: 1.0866868495941162
Validation loss: 2.091934524556642

Epoch: 5| Step: 2
Training loss: 1.8224475383758545
Validation loss: 2.1008906236258884

Epoch: 5| Step: 3
Training loss: 1.544926643371582
Validation loss: 2.115721994830716

Epoch: 5| Step: 4
Training loss: 1.6001160144805908
Validation loss: 2.1457735018063615

Epoch: 5| Step: 5
Training loss: 1.8735793828964233
Validation loss: 2.1746869010310017

Epoch: 5| Step: 6
Training loss: 1.5726710557937622
Validation loss: 2.203834900292017

Epoch: 5| Step: 7
Training loss: 1.7892544269561768
Validation loss: 2.206476714021416

Epoch: 5| Step: 8
Training loss: 1.7787853479385376
Validation loss: 2.146491212229575

Epoch: 5| Step: 9
Training loss: 1.6584789752960205
Validation loss: 2.102923595777122

Epoch: 5| Step: 10
Training loss: 1.858342170715332
Validation loss: 2.079397372020188

Epoch: 193| Step: 0
Training loss: 1.7790582180023193
Validation loss: 2.0753393019399335

Epoch: 5| Step: 1
Training loss: 2.0494678020477295
Validation loss: 2.1005173857494066

Epoch: 5| Step: 2
Training loss: 1.295227289199829
Validation loss: 2.1035553909117177

Epoch: 5| Step: 3
Training loss: 1.9198799133300781
Validation loss: 2.14944335081244

Epoch: 5| Step: 4
Training loss: 1.4127839803695679
Validation loss: 2.1462973215246715

Epoch: 5| Step: 5
Training loss: 1.4652292728424072
Validation loss: 2.170158452885125

Epoch: 5| Step: 6
Training loss: 1.129157304763794
Validation loss: 2.206619301149922

Epoch: 5| Step: 7
Training loss: 1.2337837219238281
Validation loss: 2.1818702426008

Epoch: 5| Step: 8
Training loss: 1.969862937927246
Validation loss: 2.155588852461948

Epoch: 5| Step: 9
Training loss: 1.96259343624115
Validation loss: 2.134466867293081

Epoch: 5| Step: 10
Training loss: 1.6642353534698486
Validation loss: 2.114425968098384

Epoch: 194| Step: 0
Training loss: 1.2404053211212158
Validation loss: 2.103372153415475

Epoch: 5| Step: 1
Training loss: 1.2762848138809204
Validation loss: 2.0854277559505996

Epoch: 5| Step: 2
Training loss: 1.3717124462127686
Validation loss: 2.067786560263685

Epoch: 5| Step: 3
Training loss: 2.106206178665161
Validation loss: 2.0755309481774606

Epoch: 5| Step: 4
Training loss: 1.7703940868377686
Validation loss: 2.0851366853201263

Epoch: 5| Step: 5
Training loss: 1.723031997680664
Validation loss: 2.112811697426663

Epoch: 5| Step: 6
Training loss: 1.635221242904663
Validation loss: 2.172776949021124

Epoch: 5| Step: 7
Training loss: 1.5048965215682983
Validation loss: 2.206055510428644

Epoch: 5| Step: 8
Training loss: 1.7677762508392334
Validation loss: 2.2263401169930734

Epoch: 5| Step: 9
Training loss: 1.4955205917358398
Validation loss: 2.1742957509973997

Epoch: 5| Step: 10
Training loss: 1.669749140739441
Validation loss: 2.1657500395210842

Epoch: 195| Step: 0
Training loss: 1.095282793045044
Validation loss: 2.1009316662306428

Epoch: 5| Step: 1
Training loss: 1.8306509256362915
Validation loss: 2.063117819447671

Epoch: 5| Step: 2
Training loss: 1.3537830114364624
Validation loss: 2.0524880424622567

Epoch: 5| Step: 3
Training loss: 1.565800428390503
Validation loss: 2.047895928864838

Epoch: 5| Step: 4
Training loss: 1.6036574840545654
Validation loss: 2.050521182757552

Epoch: 5| Step: 5
Training loss: 1.5161242485046387
Validation loss: 2.0844339196399977

Epoch: 5| Step: 6
Training loss: 1.0676732063293457
Validation loss: 2.1760864591085785

Epoch: 5| Step: 7
Training loss: 1.7254390716552734
Validation loss: 2.2376370506901897

Epoch: 5| Step: 8
Training loss: 1.9433282613754272
Validation loss: 2.259098219615157

Epoch: 5| Step: 9
Training loss: 1.5005861520767212
Validation loss: 2.2829422258561656

Epoch: 5| Step: 10
Training loss: 2.261014699935913
Validation loss: 2.2385398418672624

Epoch: 196| Step: 0
Training loss: 2.0132436752319336
Validation loss: 2.2459981262042956

Epoch: 5| Step: 1
Training loss: 1.9051806926727295
Validation loss: 2.228444912100351

Epoch: 5| Step: 2
Training loss: 0.9386512041091919
Validation loss: 2.2261738213159705

Epoch: 5| Step: 3
Training loss: 2.4399020671844482
Validation loss: 2.2221602291189213

Epoch: 5| Step: 4
Training loss: 1.353737473487854
Validation loss: 2.166316588719686

Epoch: 5| Step: 5
Training loss: 1.8664277791976929
Validation loss: 2.1131773148813555

Epoch: 5| Step: 6
Training loss: 1.625488519668579
Validation loss: 2.0929921493735364

Epoch: 5| Step: 7
Training loss: 1.2196850776672363
Validation loss: 2.1037962154675554

Epoch: 5| Step: 8
Training loss: 1.179648518562317
Validation loss: 2.0755880724999214

Epoch: 5| Step: 9
Training loss: 1.6327154636383057
Validation loss: 2.0967998709729923

Epoch: 5| Step: 10
Training loss: 1.1545164585113525
Validation loss: 2.14264480785657

Epoch: 197| Step: 0
Training loss: 1.5857082605361938
Validation loss: 2.20444498010861

Epoch: 5| Step: 1
Training loss: 1.1486260890960693
Validation loss: 2.260421573474843

Epoch: 5| Step: 2
Training loss: 1.9673246145248413
Validation loss: 2.2739251736671693

Epoch: 5| Step: 3
Training loss: 1.4654293060302734
Validation loss: 2.266276482612856

Epoch: 5| Step: 4
Training loss: 1.6706327199935913
Validation loss: 2.2145678586857294

Epoch: 5| Step: 5
Training loss: 1.7166423797607422
Validation loss: 2.1474993869822514

Epoch: 5| Step: 6
Training loss: 1.547558069229126
Validation loss: 2.0971349721313803

Epoch: 5| Step: 7
Training loss: 1.5774481296539307
Validation loss: 2.068930761788481

Epoch: 5| Step: 8
Training loss: 1.222839593887329
Validation loss: 2.0699941829968522

Epoch: 5| Step: 9
Training loss: 1.9116567373275757
Validation loss: 2.0816933929279284

Epoch: 5| Step: 10
Training loss: 1.8712704181671143
Validation loss: 2.0854315193750526

Epoch: 198| Step: 0
Training loss: 1.9917709827423096
Validation loss: 2.122825058557654

Epoch: 5| Step: 1
Training loss: 0.8992345929145813
Validation loss: 2.1622958234561387

Epoch: 5| Step: 2
Training loss: 1.4056544303894043
Validation loss: 2.2364973227183023

Epoch: 5| Step: 3
Training loss: 0.9800456762313843
Validation loss: 2.3030047878142326

Epoch: 5| Step: 4
Training loss: 1.4520633220672607
Validation loss: 2.30830608260247

Epoch: 5| Step: 5
Training loss: 2.4924674034118652
Validation loss: 2.343605774705128

Epoch: 5| Step: 6
Training loss: 1.1829023361206055
Validation loss: 2.2364828240486885

Epoch: 5| Step: 7
Training loss: 1.381239652633667
Validation loss: 2.0958431279787453

Epoch: 5| Step: 8
Training loss: 1.639570951461792
Validation loss: 2.0117720865434214

Epoch: 5| Step: 9
Training loss: 2.3689446449279785
Validation loss: 2.008617607496118

Epoch: 5| Step: 10
Training loss: 1.8886983394622803
Validation loss: 2.008651625725531

Epoch: 199| Step: 0
Training loss: 2.4529037475585938
Validation loss: 2.0264418881426574

Epoch: 5| Step: 1
Training loss: 1.269643783569336
Validation loss: 2.0385134963579077

Epoch: 5| Step: 2
Training loss: 1.5499554872512817
Validation loss: 2.073471733318862

Epoch: 5| Step: 3
Training loss: 1.4517486095428467
Validation loss: 2.1182064625524704

Epoch: 5| Step: 4
Training loss: 1.0790923833847046
Validation loss: 2.1332096822800173

Epoch: 5| Step: 5
Training loss: 1.2933305501937866
Validation loss: 2.135632263716831

Epoch: 5| Step: 6
Training loss: 1.8540265560150146
Validation loss: 2.168626953196782

Epoch: 5| Step: 7
Training loss: 1.5155798196792603
Validation loss: 2.176584352729141

Epoch: 5| Step: 8
Training loss: 1.8092763423919678
Validation loss: 2.194198231543264

Epoch: 5| Step: 9
Training loss: 1.2995026111602783
Validation loss: 2.2129275388615106

Epoch: 5| Step: 10
Training loss: 1.5259689092636108
Validation loss: 2.20661166919175

Epoch: 200| Step: 0
Training loss: 1.3870203495025635
Validation loss: 2.1912636961988223

Epoch: 5| Step: 1
Training loss: 1.666937232017517
Validation loss: 2.164544423421224

Epoch: 5| Step: 2
Training loss: 2.168994903564453
Validation loss: 2.143504750344061

Epoch: 5| Step: 3
Training loss: 2.0549731254577637
Validation loss: 2.1334598166968233

Epoch: 5| Step: 4
Training loss: 1.4974615573883057
Validation loss: 2.124463262096528

Epoch: 5| Step: 5
Training loss: 1.3847013711929321
Validation loss: 2.118585043056037

Epoch: 5| Step: 6
Training loss: 1.4209802150726318
Validation loss: 2.1392060120900473

Epoch: 5| Step: 7
Training loss: 1.0949914455413818
Validation loss: 2.143085989900815

Epoch: 5| Step: 8
Training loss: 1.6820586919784546
Validation loss: 2.1692260798587593

Epoch: 5| Step: 9
Training loss: 1.174513816833496
Validation loss: 2.1654106596464753

Epoch: 5| Step: 10
Training loss: 1.2486908435821533
Validation loss: 2.1837688056371545

Epoch: 201| Step: 0
Training loss: 1.975945234298706
Validation loss: 2.178373215019062

Epoch: 5| Step: 1
Training loss: 1.3862130641937256
Validation loss: 2.1706986094033844

Epoch: 5| Step: 2
Training loss: 1.6594833135604858
Validation loss: 2.1587628523508706

Epoch: 5| Step: 3
Training loss: 1.352276086807251
Validation loss: 2.1407804591681368

Epoch: 5| Step: 4
Training loss: 1.9126945734024048
Validation loss: 2.1252390441074165

Epoch: 5| Step: 5
Training loss: 1.7717145681381226
Validation loss: 2.0719861804798083

Epoch: 5| Step: 6
Training loss: 0.8954191207885742
Validation loss: 2.0631277817551807

Epoch: 5| Step: 7
Training loss: 1.5731465816497803
Validation loss: 2.0858677305201048

Epoch: 5| Step: 8
Training loss: 0.9245815277099609
Validation loss: 2.105853696023264

Epoch: 5| Step: 9
Training loss: 1.540469765663147
Validation loss: 2.101763925244731

Epoch: 5| Step: 10
Training loss: 1.47597074508667
Validation loss: 2.1277265958888556

Epoch: 202| Step: 0
Training loss: 1.7709147930145264
Validation loss: 2.144194846512169

Epoch: 5| Step: 1
Training loss: 1.5267326831817627
Validation loss: 2.17086870695955

Epoch: 5| Step: 2
Training loss: 1.7369556427001953
Validation loss: 2.1566806134357246

Epoch: 5| Step: 3
Training loss: 1.5787419080734253
Validation loss: 2.1318782965342202

Epoch: 5| Step: 4
Training loss: 1.4572776556015015
Validation loss: 2.1351201047179518

Epoch: 5| Step: 5
Training loss: 1.327371597290039
Validation loss: 2.087218117970292

Epoch: 5| Step: 6
Training loss: 1.6302562952041626
Validation loss: 2.084595778936981

Epoch: 5| Step: 7
Training loss: 1.5652563571929932
Validation loss: 2.085093367484308

Epoch: 5| Step: 8
Training loss: 1.0790696144104004
Validation loss: 2.0502838293711343

Epoch: 5| Step: 9
Training loss: 1.4747382402420044
Validation loss: 2.1001502467739965

Epoch: 5| Step: 10
Training loss: 1.2335022687911987
Validation loss: 2.109948412064583

Epoch: 203| Step: 0
Training loss: 1.801095724105835
Validation loss: 2.154182030308631

Epoch: 5| Step: 1
Training loss: 1.5113022327423096
Validation loss: 2.2087342764741633

Epoch: 5| Step: 2
Training loss: 1.029100775718689
Validation loss: 2.197648168891989

Epoch: 5| Step: 3
Training loss: 1.1410562992095947
Validation loss: 2.2088095705996276

Epoch: 5| Step: 4
Training loss: 1.731915831565857
Validation loss: 2.1975333703461515

Epoch: 5| Step: 5
Training loss: 1.6720117330551147
Validation loss: 2.1254320324108167

Epoch: 5| Step: 6
Training loss: 1.5537728071212769
Validation loss: 2.08560239115069

Epoch: 5| Step: 7
Training loss: 1.264531135559082
Validation loss: 2.079381215956903

Epoch: 5| Step: 8
Training loss: 1.555457353591919
Validation loss: 2.0738444482126543

Epoch: 5| Step: 9
Training loss: 1.4085489511489868
Validation loss: 2.0740892912751887

Epoch: 5| Step: 10
Training loss: 1.6069120168685913
Validation loss: 2.1121154190391622

Epoch: 204| Step: 0
Training loss: 0.9797895550727844
Validation loss: 2.1383227532909763

Epoch: 5| Step: 1
Training loss: 1.617746114730835
Validation loss: 2.166968168750886

Epoch: 5| Step: 2
Training loss: 1.0197536945343018
Validation loss: 2.1825829372611096

Epoch: 5| Step: 3
Training loss: 1.4437477588653564
Validation loss: 2.168544682123328

Epoch: 5| Step: 4
Training loss: 1.4799343347549438
Validation loss: 2.1514663901380313

Epoch: 5| Step: 5
Training loss: 1.4749737977981567
Validation loss: 2.1751176952033915

Epoch: 5| Step: 6
Training loss: 1.9477694034576416
Validation loss: 2.146348230300411

Epoch: 5| Step: 7
Training loss: 1.7741279602050781
Validation loss: 2.1095089399686424

Epoch: 5| Step: 8
Training loss: 1.7920595407485962
Validation loss: 2.0637848659228255

Epoch: 5| Step: 9
Training loss: 1.3361784219741821
Validation loss: 2.0360241859189925

Epoch: 5| Step: 10
Training loss: 1.3320814371109009
Validation loss: 2.0228661234660814

Epoch: 205| Step: 0
Training loss: 1.3317954540252686
Validation loss: 2.0701957851327877

Epoch: 5| Step: 1
Training loss: 1.5441884994506836
Validation loss: 2.107825756072998

Epoch: 5| Step: 2
Training loss: 1.2987315654754639
Validation loss: 2.1384144444619455

Epoch: 5| Step: 3
Training loss: 1.2843444347381592
Validation loss: 2.1477411408578195

Epoch: 5| Step: 4
Training loss: 1.1308656930923462
Validation loss: 2.170465797506353

Epoch: 5| Step: 5
Training loss: 1.3867676258087158
Validation loss: 2.1427149003551853

Epoch: 5| Step: 6
Training loss: 1.414637565612793
Validation loss: 2.124192455763458

Epoch: 5| Step: 7
Training loss: 2.143015146255493
Validation loss: 2.125134801351896

Epoch: 5| Step: 8
Training loss: 1.8084602355957031
Validation loss: 2.118328930229269

Epoch: 5| Step: 9
Training loss: 1.230006217956543
Validation loss: 2.1397726279433056

Epoch: 5| Step: 10
Training loss: 1.410419225692749
Validation loss: 2.1240587221678866

Epoch: 206| Step: 0
Training loss: 1.2236077785491943
Validation loss: 2.138955707191139

Epoch: 5| Step: 1
Training loss: 1.9054384231567383
Validation loss: 2.145703569535286

Epoch: 5| Step: 2
Training loss: 1.1861512660980225
Validation loss: 2.2111712091712543

Epoch: 5| Step: 3
Training loss: 1.045241117477417
Validation loss: 2.2171828182794715

Epoch: 5| Step: 4
Training loss: 1.5142979621887207
Validation loss: 2.2320354395015265

Epoch: 5| Step: 5
Training loss: 1.7883446216583252
Validation loss: 2.177006424114268

Epoch: 5| Step: 6
Training loss: 1.7253841161727905
Validation loss: 2.119582974782554

Epoch: 5| Step: 7
Training loss: 1.734290361404419
Validation loss: 2.0839496120329826

Epoch: 5| Step: 8
Training loss: 0.9448516964912415
Validation loss: 2.0453593577108076

Epoch: 5| Step: 9
Training loss: 1.3071670532226562
Validation loss: 2.0451237245272567

Epoch: 5| Step: 10
Training loss: 1.420936107635498
Validation loss: 2.0678363384739047

Epoch: 207| Step: 0
Training loss: 1.8977314233779907
Validation loss: 2.088292944815851

Epoch: 5| Step: 1
Training loss: 1.6195132732391357
Validation loss: 2.13870140429466

Epoch: 5| Step: 2
Training loss: 1.4940460920333862
Validation loss: 2.1771423483407624

Epoch: 5| Step: 3
Training loss: 1.601441740989685
Validation loss: 2.237224189184045

Epoch: 5| Step: 4
Training loss: 0.8950091600418091
Validation loss: 2.220100420777516

Epoch: 5| Step: 5
Training loss: 1.4833252429962158
Validation loss: 2.2112010704573763

Epoch: 5| Step: 6
Training loss: 1.1861718893051147
Validation loss: 2.168084725256889

Epoch: 5| Step: 7
Training loss: 1.7186800241470337
Validation loss: 2.1165263088800574

Epoch: 5| Step: 8
Training loss: 0.9968271255493164
Validation loss: 2.0820966356544086

Epoch: 5| Step: 9
Training loss: 1.0817979574203491
Validation loss: 2.07427550900367

Epoch: 5| Step: 10
Training loss: 1.7413197755813599
Validation loss: 2.075521687025665

Epoch: 208| Step: 0
Training loss: 1.5239074230194092
Validation loss: 2.0627447520532916

Epoch: 5| Step: 1
Training loss: 1.8478114604949951
Validation loss: 2.1009703887406217

Epoch: 5| Step: 2
Training loss: 1.4734429121017456
Validation loss: 2.12177199445745

Epoch: 5| Step: 3
Training loss: 1.5289528369903564
Validation loss: 2.1660561535948064

Epoch: 5| Step: 4
Training loss: 1.26327645778656
Validation loss: 2.1668961548036143

Epoch: 5| Step: 5
Training loss: 1.5140374898910522
Validation loss: 2.13092198294978

Epoch: 5| Step: 6
Training loss: 1.533771276473999
Validation loss: 2.108677194964501

Epoch: 5| Step: 7
Training loss: 1.4318616390228271
Validation loss: 2.105136166336716

Epoch: 5| Step: 8
Training loss: 1.227204442024231
Validation loss: 2.1364611605162263

Epoch: 5| Step: 9
Training loss: 1.039107322692871
Validation loss: 2.1874890212089784

Epoch: 5| Step: 10
Training loss: 1.0354011058807373
Validation loss: 2.2022702117120065

Epoch: 209| Step: 0
Training loss: 1.4753153324127197
Validation loss: 2.203049108546267

Epoch: 5| Step: 1
Training loss: 1.7448747158050537
Validation loss: 2.163718085135183

Epoch: 5| Step: 2
Training loss: 1.5530747175216675
Validation loss: 2.120686090120705

Epoch: 5| Step: 3
Training loss: 1.038527250289917
Validation loss: 2.111718996878593

Epoch: 5| Step: 4
Training loss: 1.1043672561645508
Validation loss: 2.083916543632425

Epoch: 5| Step: 5
Training loss: 0.9015089273452759
Validation loss: 2.0820690303720455

Epoch: 5| Step: 6
Training loss: 1.39845871925354
Validation loss: 2.07123807168776

Epoch: 5| Step: 7
Training loss: 1.2452585697174072
Validation loss: 2.070120960153559

Epoch: 5| Step: 8
Training loss: 1.5849180221557617
Validation loss: 2.0956908964341685

Epoch: 5| Step: 9
Training loss: 1.5425904989242554
Validation loss: 2.1133824586868286

Epoch: 5| Step: 10
Training loss: 1.5112088918685913
Validation loss: 2.1864036795913533

Epoch: 210| Step: 0
Training loss: 1.6731007099151611
Validation loss: 2.1871913492038684

Epoch: 5| Step: 1
Training loss: 1.134615421295166
Validation loss: 2.2027697922081075

Epoch: 5| Step: 2
Training loss: 1.6526905298233032
Validation loss: 2.1167313975672566

Epoch: 5| Step: 3
Training loss: 1.0139166116714478
Validation loss: 2.0730639696121216

Epoch: 5| Step: 4
Training loss: 1.0482157468795776
Validation loss: 2.037033300245962

Epoch: 5| Step: 5
Training loss: 1.329466462135315
Validation loss: 2.027964094633697

Epoch: 5| Step: 6
Training loss: 1.7768148183822632
Validation loss: 2.043739349611344

Epoch: 5| Step: 7
Training loss: 1.5562859773635864
Validation loss: 2.067846562272759

Epoch: 5| Step: 8
Training loss: 1.5740361213684082
Validation loss: 2.0770124722552556

Epoch: 5| Step: 9
Training loss: 1.4416149854660034
Validation loss: 2.0728697033338648

Epoch: 5| Step: 10
Training loss: 1.2431586980819702
Validation loss: 2.098573729556094

Epoch: 211| Step: 0
Training loss: 1.574181079864502
Validation loss: 2.0921712408783617

Epoch: 5| Step: 1
Training loss: 1.1472723484039307
Validation loss: 2.096654854794984

Epoch: 5| Step: 2
Training loss: 1.5567270517349243
Validation loss: 2.13299512222249

Epoch: 5| Step: 3
Training loss: 1.3857648372650146
Validation loss: 2.1181231608954807

Epoch: 5| Step: 4
Training loss: 1.8977947235107422
Validation loss: 2.1135849337424

Epoch: 5| Step: 5
Training loss: 1.2671806812286377
Validation loss: 2.1126816785463722

Epoch: 5| Step: 6
Training loss: 1.1817222833633423
Validation loss: 2.093996993957027

Epoch: 5| Step: 7
Training loss: 1.0296542644500732
Validation loss: 2.102704035338535

Epoch: 5| Step: 8
Training loss: 1.037527322769165
Validation loss: 2.1012076921360467

Epoch: 5| Step: 9
Training loss: 1.3693300485610962
Validation loss: 2.091787548475368

Epoch: 5| Step: 10
Training loss: 1.5383087396621704
Validation loss: 2.1233702859570904

Epoch: 212| Step: 0
Training loss: 1.350130319595337
Validation loss: 2.1638528813597975

Epoch: 5| Step: 1
Training loss: 1.8465656042099
Validation loss: 2.1586240632559663

Epoch: 5| Step: 2
Training loss: 1.109565019607544
Validation loss: 2.136812920211464

Epoch: 5| Step: 3
Training loss: 1.6159546375274658
Validation loss: 2.1195069666831725

Epoch: 5| Step: 4
Training loss: 1.126787543296814
Validation loss: 2.114392847143194

Epoch: 5| Step: 5
Training loss: 1.2521194219589233
Validation loss: 2.0971332826922016

Epoch: 5| Step: 6
Training loss: 1.5927015542984009
Validation loss: 2.0809177865264235

Epoch: 5| Step: 7
Training loss: 1.1020796298980713
Validation loss: 2.0692029204419864

Epoch: 5| Step: 8
Training loss: 1.2407399415969849
Validation loss: 2.065282437109178

Epoch: 5| Step: 9
Training loss: 1.365543246269226
Validation loss: 2.0686274241375666

Epoch: 5| Step: 10
Training loss: 1.166664481163025
Validation loss: 2.089942656537538

Epoch: 213| Step: 0
Training loss: 1.1049822568893433
Validation loss: 2.145895811819261

Epoch: 5| Step: 1
Training loss: 1.1138204336166382
Validation loss: 2.126351166796941

Epoch: 5| Step: 2
Training loss: 1.253028392791748
Validation loss: 2.1246611943808933

Epoch: 5| Step: 3
Training loss: 1.0906273126602173
Validation loss: 2.102608839670817

Epoch: 5| Step: 4
Training loss: 2.006875514984131
Validation loss: 2.086065617940759

Epoch: 5| Step: 5
Training loss: 1.0336521863937378
Validation loss: 2.084495231669436

Epoch: 5| Step: 6
Training loss: 1.9323936700820923
Validation loss: 2.0711421607643046

Epoch: 5| Step: 7
Training loss: 1.6173814535140991
Validation loss: 2.011590298785958

Epoch: 5| Step: 8
Training loss: 1.2107703685760498
Validation loss: 1.9959507039798203

Epoch: 5| Step: 9
Training loss: 1.089792013168335
Validation loss: 2.0152921753544963

Epoch: 5| Step: 10
Training loss: 1.148692011833191
Validation loss: 2.0303890999927314

Epoch: 214| Step: 0
Training loss: 1.4694321155548096
Validation loss: 2.0625316455800045

Epoch: 5| Step: 1
Training loss: 1.313223123550415
Validation loss: 2.1454829554403982

Epoch: 5| Step: 2
Training loss: 1.633880615234375
Validation loss: 2.187174004893149

Epoch: 5| Step: 3
Training loss: 1.082252860069275
Validation loss: 2.172959699425646

Epoch: 5| Step: 4
Training loss: 1.4353176355361938
Validation loss: 2.1477388361448884

Epoch: 5| Step: 5
Training loss: 1.7161531448364258
Validation loss: 2.128920784560583

Epoch: 5| Step: 6
Training loss: 1.3182296752929688
Validation loss: 2.063527435384771

Epoch: 5| Step: 7
Training loss: 1.0524563789367676
Validation loss: 2.048728294270013

Epoch: 5| Step: 8
Training loss: 1.6610561609268188
Validation loss: 2.0721893233637654

Epoch: 5| Step: 9
Training loss: 1.3278127908706665
Validation loss: 2.0691964831403507

Epoch: 5| Step: 10
Training loss: 0.9283080697059631
Validation loss: 2.1281031370162964

Epoch: 215| Step: 0
Training loss: 1.4359729290008545
Validation loss: 2.156751763436102

Epoch: 5| Step: 1
Training loss: 1.4676134586334229
Validation loss: 2.187280108851771

Epoch: 5| Step: 2
Training loss: 1.1428319215774536
Validation loss: 2.2265342204801497

Epoch: 5| Step: 3
Training loss: 1.637624979019165
Validation loss: 2.239460740038144

Epoch: 5| Step: 4
Training loss: 1.1303737163543701
Validation loss: 2.140514555797782

Epoch: 5| Step: 5
Training loss: 1.3780596256256104
Validation loss: 2.104306883709405

Epoch: 5| Step: 6
Training loss: 1.1252738237380981
Validation loss: 2.0668493637474636

Epoch: 5| Step: 7
Training loss: 1.2046356201171875
Validation loss: 2.0468866607194305

Epoch: 5| Step: 8
Training loss: 1.6584446430206299
Validation loss: 2.073173697276782

Epoch: 5| Step: 9
Training loss: 1.0049903392791748
Validation loss: 2.0987430695564515

Epoch: 5| Step: 10
Training loss: 1.6223963499069214
Validation loss: 2.1213061245538856

Epoch: 216| Step: 0
Training loss: 1.1464351415634155
Validation loss: 2.1413341055634203

Epoch: 5| Step: 1
Training loss: 1.2281389236450195
Validation loss: 2.174266046093356

Epoch: 5| Step: 2
Training loss: 1.2393001317977905
Validation loss: 2.16867817858214

Epoch: 5| Step: 3
Training loss: 0.9912775754928589
Validation loss: 2.1636871778836815

Epoch: 5| Step: 4
Training loss: 1.2524583339691162
Validation loss: 2.116351213506473

Epoch: 5| Step: 5
Training loss: 1.378793478012085
Validation loss: 2.0859229718485186

Epoch: 5| Step: 6
Training loss: 1.3544927835464478
Validation loss: 2.0196153784310944

Epoch: 5| Step: 7
Training loss: 1.1399002075195312
Validation loss: 2.018769774385678

Epoch: 5| Step: 8
Training loss: 1.9897645711898804
Validation loss: 2.01488567936805

Epoch: 5| Step: 9
Training loss: 1.4875048398971558
Validation loss: 2.061203610512518

Epoch: 5| Step: 10
Training loss: 1.5739303827285767
Validation loss: 2.047737447164392

Epoch: 217| Step: 0
Training loss: 1.3079692125320435
Validation loss: 2.0730948909636466

Epoch: 5| Step: 1
Training loss: 1.3111588954925537
Validation loss: 2.1136345581341813

Epoch: 5| Step: 2
Training loss: 1.1884095668792725
Validation loss: 2.153626872647193

Epoch: 5| Step: 3
Training loss: 1.261426568031311
Validation loss: 2.2051649913992932

Epoch: 5| Step: 4
Training loss: 1.4617273807525635
Validation loss: 2.231082603495608

Epoch: 5| Step: 5
Training loss: 1.1225125789642334
Validation loss: 2.2087796811134583

Epoch: 5| Step: 6
Training loss: 1.9004898071289062
Validation loss: 2.204203677433793

Epoch: 5| Step: 7
Training loss: 1.2451156377792358
Validation loss: 2.1366134766609437

Epoch: 5| Step: 8
Training loss: 0.8877833485603333
Validation loss: 2.0743377400982763

Epoch: 5| Step: 9
Training loss: 1.6280128955841064
Validation loss: 2.0444923998207174

Epoch: 5| Step: 10
Training loss: 1.3422948122024536
Validation loss: 2.04585212661374

Epoch: 218| Step: 0
Training loss: 1.8130061626434326
Validation loss: 2.024491693383904

Epoch: 5| Step: 1
Training loss: 1.5599024295806885
Validation loss: 2.0418331674350205

Epoch: 5| Step: 2
Training loss: 1.3660427331924438
Validation loss: 2.070499752157478

Epoch: 5| Step: 3
Training loss: 1.4163367748260498
Validation loss: 2.103283595013362

Epoch: 5| Step: 4
Training loss: 1.1080628633499146
Validation loss: 2.1145346908159155

Epoch: 5| Step: 5
Training loss: 1.3839141130447388
Validation loss: 2.1252458326278196

Epoch: 5| Step: 6
Training loss: 1.1550251245498657
Validation loss: 2.1391601075408277

Epoch: 5| Step: 7
Training loss: 1.1092662811279297
Validation loss: 2.1671504589819137

Epoch: 5| Step: 8
Training loss: 1.3687586784362793
Validation loss: 2.155433016438638

Epoch: 5| Step: 9
Training loss: 0.9588813781738281
Validation loss: 2.15936614108342

Epoch: 5| Step: 10
Training loss: 1.171555519104004
Validation loss: 2.170867766103437

Epoch: 219| Step: 0
Training loss: 1.4254028797149658
Validation loss: 2.168822903786936

Epoch: 5| Step: 1
Training loss: 0.98516446352005
Validation loss: 2.1710484361135833

Epoch: 5| Step: 2
Training loss: 1.2851868867874146
Validation loss: 2.1830437414107786

Epoch: 5| Step: 3
Training loss: 1.2035844326019287
Validation loss: 2.1102898223425752

Epoch: 5| Step: 4
Training loss: 0.7968896627426147
Validation loss: 2.0913458793394026

Epoch: 5| Step: 5
Training loss: 1.6827638149261475
Validation loss: 2.081289001690444

Epoch: 5| Step: 6
Training loss: 1.7195966243743896
Validation loss: 2.0588134129842124

Epoch: 5| Step: 7
Training loss: 1.4787142276763916
Validation loss: 2.0553902259436985

Epoch: 5| Step: 8
Training loss: 1.3953020572662354
Validation loss: 2.042189141755463

Epoch: 5| Step: 9
Training loss: 0.9867997169494629
Validation loss: 2.0404992206122285

Epoch: 5| Step: 10
Training loss: 1.1967740058898926
Validation loss: 2.0285281083917104

Epoch: 220| Step: 0
Training loss: 1.0502073764801025
Validation loss: 2.060649069406653

Epoch: 5| Step: 1
Training loss: 1.206990122795105
Validation loss: 2.0788212104510237

Epoch: 5| Step: 2
Training loss: 1.10972261428833
Validation loss: 2.0808384239032702

Epoch: 5| Step: 3
Training loss: 0.9619245529174805
Validation loss: 2.119502131656934

Epoch: 5| Step: 4
Training loss: 1.2816143035888672
Validation loss: 2.1499642351622223

Epoch: 5| Step: 5
Training loss: 1.088961124420166
Validation loss: 2.138816036203856

Epoch: 5| Step: 6
Training loss: 1.441861867904663
Validation loss: 2.129946098532728

Epoch: 5| Step: 7
Training loss: 1.2327158451080322
Validation loss: 2.1193349105055614

Epoch: 5| Step: 8
Training loss: 1.2972966432571411
Validation loss: 2.062770034677239

Epoch: 5| Step: 9
Training loss: 1.8042681217193604
Validation loss: 2.086351925326932

Epoch: 5| Step: 10
Training loss: 1.5317740440368652
Validation loss: 2.086915969848633

Epoch: 221| Step: 0
Training loss: 1.1093670129776
Validation loss: 2.090975753722652

Epoch: 5| Step: 1
Training loss: 1.8579599857330322
Validation loss: 2.1052294392739572

Epoch: 5| Step: 2
Training loss: 1.1430891752243042
Validation loss: 2.1533670297233005

Epoch: 5| Step: 3
Training loss: 1.3764665126800537
Validation loss: 2.161469923552646

Epoch: 5| Step: 4
Training loss: 1.470231294631958
Validation loss: 2.1405638981890935

Epoch: 5| Step: 5
Training loss: 0.9622637033462524
Validation loss: 2.092322357239262

Epoch: 5| Step: 6
Training loss: 1.567577600479126
Validation loss: 2.0938815198918825

Epoch: 5| Step: 7
Training loss: 1.3089240789413452
Validation loss: 2.0870888028093564

Epoch: 5| Step: 8
Training loss: 1.536102056503296
Validation loss: 2.132919849887971

Epoch: 5| Step: 9
Training loss: 0.7906757593154907
Validation loss: 2.1345528146272064

Epoch: 5| Step: 10
Training loss: 0.949090838432312
Validation loss: 2.1276943145259732

Epoch: 222| Step: 0
Training loss: 0.7136480212211609
Validation loss: 2.0546263494799213

Epoch: 5| Step: 1
Training loss: 1.261101484298706
Validation loss: 2.042621453603109

Epoch: 5| Step: 2
Training loss: 1.3396764993667603
Validation loss: 2.0054405863567064

Epoch: 5| Step: 3
Training loss: 1.4107311964035034
Validation loss: 2.0118874836993474

Epoch: 5| Step: 4
Training loss: 1.4678683280944824
Validation loss: 2.041567325592041

Epoch: 5| Step: 5
Training loss: 1.5156859159469604
Validation loss: 2.0932172652213805

Epoch: 5| Step: 6
Training loss: 0.8769842982292175
Validation loss: 2.133281812872938

Epoch: 5| Step: 7
Training loss: 1.0382716655731201
Validation loss: 2.1617526431237497

Epoch: 5| Step: 8
Training loss: 1.1987826824188232
Validation loss: 2.1689235753910516

Epoch: 5| Step: 9
Training loss: 1.8291997909545898
Validation loss: 2.1244264033532914

Epoch: 5| Step: 10
Training loss: 1.0692460536956787
Validation loss: 2.074450494140707

Epoch: 223| Step: 0
Training loss: 1.0873123407363892
Validation loss: 2.044474104399322

Epoch: 5| Step: 1
Training loss: 0.984621524810791
Validation loss: 2.0233481596874934

Epoch: 5| Step: 2
Training loss: 1.215266466140747
Validation loss: 2.0173196100419566

Epoch: 5| Step: 3
Training loss: 0.9380102157592773
Validation loss: 2.009951477409691

Epoch: 5| Step: 4
Training loss: 1.3291410207748413
Validation loss: 2.009462107894241

Epoch: 5| Step: 5
Training loss: 1.4536501169204712
Validation loss: 2.053902946492677

Epoch: 5| Step: 6
Training loss: 1.2917520999908447
Validation loss: 2.109258440233046

Epoch: 5| Step: 7
Training loss: 1.2150534391403198
Validation loss: 2.1526248608866045

Epoch: 5| Step: 8
Training loss: 1.541820764541626
Validation loss: 2.1470188966361423

Epoch: 5| Step: 9
Training loss: 1.4487650394439697
Validation loss: 2.12270603897751

Epoch: 5| Step: 10
Training loss: 1.0830188989639282
Validation loss: 2.071170222374701

Epoch: 224| Step: 0
Training loss: 1.435309648513794
Validation loss: 2.0484843202816543

Epoch: 5| Step: 1
Training loss: 1.1313159465789795
Validation loss: 2.051126277574929

Epoch: 5| Step: 2
Training loss: 1.2223104238510132
Validation loss: 2.0376692753966137

Epoch: 5| Step: 3
Training loss: 0.8251811265945435
Validation loss: 2.038278075956529

Epoch: 5| Step: 4
Training loss: 0.808039665222168
Validation loss: 2.038990297625142

Epoch: 5| Step: 5
Training loss: 1.5771241188049316
Validation loss: 2.065356736542076

Epoch: 5| Step: 6
Training loss: 1.4022741317749023
Validation loss: 2.061532929379453

Epoch: 5| Step: 7
Training loss: 1.316870927810669
Validation loss: 2.068929613277476

Epoch: 5| Step: 8
Training loss: 1.1844228506088257
Validation loss: 2.0790082754627353

Epoch: 5| Step: 9
Training loss: 1.1768572330474854
Validation loss: 2.0947536178814468

Epoch: 5| Step: 10
Training loss: 1.4369089603424072
Validation loss: 2.1047121094119166

Epoch: 225| Step: 0
Training loss: 1.4355762004852295
Validation loss: 2.0609424062954482

Epoch: 5| Step: 1
Training loss: 0.8951862454414368
Validation loss: 2.0522434890911145

Epoch: 5| Step: 2
Training loss: 1.0075219869613647
Validation loss: 2.031305423346899

Epoch: 5| Step: 3
Training loss: 1.646908164024353
Validation loss: 2.0374309837177234

Epoch: 5| Step: 4
Training loss: 1.421865701675415
Validation loss: 2.053403159623505

Epoch: 5| Step: 5
Training loss: 1.078003168106079
Validation loss: 2.089068361507949

Epoch: 5| Step: 6
Training loss: 1.6631046533584595
Validation loss: 2.0884309302094164

Epoch: 5| Step: 7
Training loss: 1.1362158060073853
Validation loss: 2.0751756301490207

Epoch: 5| Step: 8
Training loss: 1.1453808546066284
Validation loss: 2.0706955579019364

Epoch: 5| Step: 9
Training loss: 0.7137792110443115
Validation loss: 2.0502536143026044

Epoch: 5| Step: 10
Training loss: 0.9276277422904968
Validation loss: 2.0499545592133717

Epoch: 226| Step: 0
Training loss: 0.899173378944397
Validation loss: 2.0395316167544295

Epoch: 5| Step: 1
Training loss: 1.8043134212493896
Validation loss: 2.0645737942828926

Epoch: 5| Step: 2
Training loss: 1.1593456268310547
Validation loss: 2.0948590027388705

Epoch: 5| Step: 3
Training loss: 1.1777576208114624
Validation loss: 2.082724336654909

Epoch: 5| Step: 4
Training loss: 1.4327977895736694
Validation loss: 2.0890358981265815

Epoch: 5| Step: 5
Training loss: 0.7282666563987732
Validation loss: 2.046760400136312

Epoch: 5| Step: 6
Training loss: 0.8343375325202942
Validation loss: 2.0392707150469542

Epoch: 5| Step: 7
Training loss: 1.0138351917266846
Validation loss: 2.0059104478487404

Epoch: 5| Step: 8
Training loss: 1.6822866201400757
Validation loss: 2.037558055693103

Epoch: 5| Step: 9
Training loss: 1.0267794132232666
Validation loss: 2.0654762791049097

Epoch: 5| Step: 10
Training loss: 1.077815294265747
Validation loss: 2.0847384006746355

Epoch: 227| Step: 0
Training loss: 0.7519417405128479
Validation loss: 2.0194378386261644

Epoch: 5| Step: 1
Training loss: 0.7812840938568115
Validation loss: 2.0075389249350435

Epoch: 5| Step: 2
Training loss: 0.9844661951065063
Validation loss: 2.038145016598445

Epoch: 5| Step: 3
Training loss: 1.2074836492538452
Validation loss: 2.0517692706918202

Epoch: 5| Step: 4
Training loss: 1.7482134103775024
Validation loss: 2.0943615269917313

Epoch: 5| Step: 5
Training loss: 1.4368095397949219
Validation loss: 2.06551335319396

Epoch: 5| Step: 6
Training loss: 1.5489985942840576
Validation loss: 2.0885877916889806

Epoch: 5| Step: 7
Training loss: 1.0283620357513428
Validation loss: 2.0727628520739976

Epoch: 5| Step: 8
Training loss: 1.3605234622955322
Validation loss: 2.088200387134347

Epoch: 5| Step: 9
Training loss: 0.8477270007133484
Validation loss: 2.055664511137111

Epoch: 5| Step: 10
Training loss: 1.006173849105835
Validation loss: 2.0276995858838482

Epoch: 228| Step: 0
Training loss: 1.2234232425689697
Validation loss: 2.03098790876327

Epoch: 5| Step: 1
Training loss: 1.3166223764419556
Validation loss: 2.006378087946164

Epoch: 5| Step: 2
Training loss: 1.0070741176605225
Validation loss: 2.0099937236437233

Epoch: 5| Step: 3
Training loss: 1.295942783355713
Validation loss: 2.0172011621536745

Epoch: 5| Step: 4
Training loss: 1.390368103981018
Validation loss: 2.0120602474417737

Epoch: 5| Step: 5
Training loss: 1.27180016040802
Validation loss: 2.0151602965529247

Epoch: 5| Step: 6
Training loss: 1.3213872909545898
Validation loss: 2.0402867153126705

Epoch: 5| Step: 7
Training loss: 0.7991452217102051
Validation loss: 2.0773682773754163

Epoch: 5| Step: 8
Training loss: 1.0712037086486816
Validation loss: 2.10571389813577

Epoch: 5| Step: 9
Training loss: 1.0259428024291992
Validation loss: 2.0585690313769924

Epoch: 5| Step: 10
Training loss: 0.709169864654541
Validation loss: 2.0408211805487193

Epoch: 229| Step: 0
Training loss: 1.1150903701782227
Validation loss: 2.036508890890306

Epoch: 5| Step: 1
Training loss: 0.8843281865119934
Validation loss: 2.014938877474877

Epoch: 5| Step: 2
Training loss: 1.4678713083267212
Validation loss: 2.0428382914553405

Epoch: 5| Step: 3
Training loss: 1.0547552108764648
Validation loss: 2.0535604761492823

Epoch: 5| Step: 4
Training loss: 1.396267056465149
Validation loss: 2.092328234385419

Epoch: 5| Step: 5
Training loss: 0.8380140066146851
Validation loss: 2.0652035615777455

Epoch: 5| Step: 6
Training loss: 1.5804321765899658
Validation loss: 2.0559813027740805

Epoch: 5| Step: 7
Training loss: 1.149606704711914
Validation loss: 2.0192492879847044

Epoch: 5| Step: 8
Training loss: 1.2350355386734009
Validation loss: 2.023647867223268

Epoch: 5| Step: 9
Training loss: 0.8549515008926392
Validation loss: 1.9938076542269798

Epoch: 5| Step: 10
Training loss: 0.9576148986816406
Validation loss: 2.0024019877115884

Epoch: 230| Step: 0
Training loss: 0.9709075093269348
Validation loss: 1.9628534804108322

Epoch: 5| Step: 1
Training loss: 1.4546716213226318
Validation loss: 1.965681229868243

Epoch: 5| Step: 2
Training loss: 1.3229451179504395
Validation loss: 1.9824996481659591

Epoch: 5| Step: 3
Training loss: 0.8697412610054016
Validation loss: 2.0301699535821074

Epoch: 5| Step: 4
Training loss: 0.8566758036613464
Validation loss: 2.0822510232207594

Epoch: 5| Step: 5
Training loss: 1.1736700534820557
Validation loss: 2.1231026572565876

Epoch: 5| Step: 6
Training loss: 1.3025386333465576
Validation loss: 2.1606003238308813

Epoch: 5| Step: 7
Training loss: 1.2592298984527588
Validation loss: 2.152537392031762

Epoch: 5| Step: 8
Training loss: 0.7875427007675171
Validation loss: 2.1001193369588544

Epoch: 5| Step: 9
Training loss: 1.360091209411621
Validation loss: 2.0603525074579383

Epoch: 5| Step: 10
Training loss: 1.4918864965438843
Validation loss: 2.0129101558398177

Epoch: 231| Step: 0
Training loss: 1.1431201696395874
Validation loss: 1.9829834507357689

Epoch: 5| Step: 1
Training loss: 1.0855311155319214
Validation loss: 1.9889407632171467

Epoch: 5| Step: 2
Training loss: 1.2287981510162354
Validation loss: 2.01698552408526

Epoch: 5| Step: 3
Training loss: 1.1133925914764404
Validation loss: 2.0202611415616927

Epoch: 5| Step: 4
Training loss: 1.0130937099456787
Validation loss: 2.038263267086398

Epoch: 5| Step: 5
Training loss: 1.30624520778656
Validation loss: 2.0780965025706957

Epoch: 5| Step: 6
Training loss: 1.764447569847107
Validation loss: 2.0774934189293974

Epoch: 5| Step: 7
Training loss: 0.7918611168861389
Validation loss: 2.0468218326568604

Epoch: 5| Step: 8
Training loss: 0.9131040573120117
Validation loss: 1.9839821169453282

Epoch: 5| Step: 9
Training loss: 1.3766685724258423
Validation loss: 1.9535913569952852

Epoch: 5| Step: 10
Training loss: 0.7834932804107666
Validation loss: 1.9731384631126159

Epoch: 232| Step: 0
Training loss: 1.1903228759765625
Validation loss: 1.9756551609244397

Epoch: 5| Step: 1
Training loss: 1.5505564212799072
Validation loss: 1.9890729624737975

Epoch: 5| Step: 2
Training loss: 1.2276912927627563
Validation loss: 1.9946244352607316

Epoch: 5| Step: 3
Training loss: 1.1037825345993042
Validation loss: 2.030370663571101

Epoch: 5| Step: 4
Training loss: 0.9475769996643066
Validation loss: 2.0030565595114105

Epoch: 5| Step: 5
Training loss: 0.5889413952827454
Validation loss: 1.9898875656948294

Epoch: 5| Step: 6
Training loss: 1.2380672693252563
Validation loss: 1.9648600547544417

Epoch: 5| Step: 7
Training loss: 0.9310318827629089
Validation loss: 1.9813746175458353

Epoch: 5| Step: 8
Training loss: 0.8358229398727417
Validation loss: 1.9733079402677474

Epoch: 5| Step: 9
Training loss: 0.9788581728935242
Validation loss: 2.016184074904329

Epoch: 5| Step: 10
Training loss: 1.6321539878845215
Validation loss: 2.050798693010884

Epoch: 233| Step: 0
Training loss: 0.9289410710334778
Validation loss: 2.0759155981002317

Epoch: 5| Step: 1
Training loss: 1.0506412982940674
Validation loss: 2.0854794568912958

Epoch: 5| Step: 2
Training loss: 1.1962721347808838
Validation loss: 2.100658657730267

Epoch: 5| Step: 3
Training loss: 1.4852063655853271
Validation loss: 2.12745750334955

Epoch: 5| Step: 4
Training loss: 1.3287352323532104
Validation loss: 2.0788344901095153

Epoch: 5| Step: 5
Training loss: 0.9058372378349304
Validation loss: 2.0359125393693165

Epoch: 5| Step: 6
Training loss: 1.1360266208648682
Validation loss: 2.029351508745583

Epoch: 5| Step: 7
Training loss: 1.2925927639007568
Validation loss: 2.03755118257256

Epoch: 5| Step: 8
Training loss: 0.6463971734046936
Validation loss: 2.0347979927575714

Epoch: 5| Step: 9
Training loss: 0.9837163090705872
Validation loss: 2.0549503603289203

Epoch: 5| Step: 10
Training loss: 0.9495399594306946
Validation loss: 2.062481105968516

Epoch: 234| Step: 0
Training loss: 1.2801111936569214
Validation loss: 2.0757668607978412

Epoch: 5| Step: 1
Training loss: 0.9486162066459656
Validation loss: 2.0354654378788446

Epoch: 5| Step: 2
Training loss: 1.2552707195281982
Validation loss: 2.0069149668498705

Epoch: 5| Step: 3
Training loss: 1.2553879022598267
Validation loss: 1.9552755407107774

Epoch: 5| Step: 4
Training loss: 1.1728578805923462
Validation loss: 1.9294991775225567

Epoch: 5| Step: 5
Training loss: 0.8934317827224731
Validation loss: 1.9373892866155153

Epoch: 5| Step: 6
Training loss: 0.42794090509414673
Validation loss: 2.0178561697724047

Epoch: 5| Step: 7
Training loss: 1.5263079404830933
Validation loss: 2.1094270777958695

Epoch: 5| Step: 8
Training loss: 1.247809648513794
Validation loss: 2.1326228290475826

Epoch: 5| Step: 9
Training loss: 1.1781209707260132
Validation loss: 2.127250302222467

Epoch: 5| Step: 10
Training loss: 1.2732340097427368
Validation loss: 2.104629135900928

Epoch: 235| Step: 0
Training loss: 0.9489568471908569
Validation loss: 2.106757729284225

Epoch: 5| Step: 1
Training loss: 1.3154311180114746
Validation loss: 2.099568243949644

Epoch: 5| Step: 2
Training loss: 1.3681092262268066
Validation loss: 2.049300871869569

Epoch: 5| Step: 3
Training loss: 1.1815141439437866
Validation loss: 2.0165543376758532

Epoch: 5| Step: 4
Training loss: 1.2926584482192993
Validation loss: 1.9856293560356222

Epoch: 5| Step: 5
Training loss: 1.0722140073776245
Validation loss: 1.9790512759198424

Epoch: 5| Step: 6
Training loss: 1.098137617111206
Validation loss: 1.9810906943454538

Epoch: 5| Step: 7
Training loss: 1.0906877517700195
Validation loss: 1.9459594859871814

Epoch: 5| Step: 8
Training loss: 1.0174882411956787
Validation loss: 1.9703269979005218

Epoch: 5| Step: 9
Training loss: 1.095215916633606
Validation loss: 2.046707772439526

Epoch: 5| Step: 10
Training loss: 1.0757356882095337
Validation loss: 2.092843960690242

Epoch: 236| Step: 0
Training loss: 0.8538433909416199
Validation loss: 2.1415112864586616

Epoch: 5| Step: 1
Training loss: 0.7839244604110718
Validation loss: 2.1600147062732327

Epoch: 5| Step: 2
Training loss: 1.0344078540802002
Validation loss: 2.1013073857112596

Epoch: 5| Step: 3
Training loss: 1.1483229398727417
Validation loss: 2.041760616405036

Epoch: 5| Step: 4
Training loss: 1.4097038507461548
Validation loss: 1.9825149838642409

Epoch: 5| Step: 5
Training loss: 1.1315581798553467
Validation loss: 1.9519655832680323

Epoch: 5| Step: 6
Training loss: 0.6505299806594849
Validation loss: 1.9307167414695985

Epoch: 5| Step: 7
Training loss: 0.9248639941215515
Validation loss: 1.9314116662548435

Epoch: 5| Step: 8
Training loss: 1.4273103475570679
Validation loss: 1.9696347739106865

Epoch: 5| Step: 9
Training loss: 1.4845784902572632
Validation loss: 2.023575928903395

Epoch: 5| Step: 10
Training loss: 0.9845287203788757
Validation loss: 2.0460693579848095

Epoch: 237| Step: 0
Training loss: 0.6864100694656372
Validation loss: 2.01878684823231

Epoch: 5| Step: 1
Training loss: 0.9127628207206726
Validation loss: 1.9805143904942337

Epoch: 5| Step: 2
Training loss: 1.0905096530914307
Validation loss: 1.959881531294956

Epoch: 5| Step: 3
Training loss: 1.2267911434173584
Validation loss: 1.958519237015837

Epoch: 5| Step: 4
Training loss: 1.4691025018692017
Validation loss: 1.9804542359485422

Epoch: 5| Step: 5
Training loss: 1.211098074913025
Validation loss: 1.9765878108239943

Epoch: 5| Step: 6
Training loss: 0.6157678961753845
Validation loss: 1.993558568339194

Epoch: 5| Step: 7
Training loss: 1.3240039348602295
Validation loss: 2.02588717655469

Epoch: 5| Step: 8
Training loss: 0.8152557611465454
Validation loss: 2.071154309857276

Epoch: 5| Step: 9
Training loss: 1.1920303106307983
Validation loss: 2.0638770813583047

Epoch: 5| Step: 10
Training loss: 1.0240429639816284
Validation loss: 2.0495889353495773

Epoch: 238| Step: 0
Training loss: 0.8091362118721008
Validation loss: 2.0105940603440806

Epoch: 5| Step: 1
Training loss: 1.1128740310668945
Validation loss: 1.9772307052407214

Epoch: 5| Step: 2
Training loss: 0.6313632726669312
Validation loss: 1.9584612269555368

Epoch: 5| Step: 3
Training loss: 1.0655908584594727
Validation loss: 1.9421153401815763

Epoch: 5| Step: 4
Training loss: 1.036765694618225
Validation loss: 1.9463911261609805

Epoch: 5| Step: 5
Training loss: 1.1771645545959473
Validation loss: 1.9641451348540604

Epoch: 5| Step: 6
Training loss: 1.431748867034912
Validation loss: 1.9499734050484114

Epoch: 5| Step: 7
Training loss: 0.6207190752029419
Validation loss: 1.973205840715798

Epoch: 5| Step: 8
Training loss: 1.0591880083084106
Validation loss: 2.0000122824022846

Epoch: 5| Step: 9
Training loss: 1.004241704940796
Validation loss: 2.0257193144931587

Epoch: 5| Step: 10
Training loss: 1.228473424911499
Validation loss: 2.104208201490423

Epoch: 239| Step: 0
Training loss: 1.2402856349945068
Validation loss: 2.0828293395298783

Epoch: 5| Step: 1
Training loss: 1.1531704664230347
Validation loss: 2.111640371302123

Epoch: 5| Step: 2
Training loss: 0.9052839279174805
Validation loss: 2.0339837599826116

Epoch: 5| Step: 3
Training loss: 0.6544075608253479
Validation loss: 2.0155150326349403

Epoch: 5| Step: 4
Training loss: 1.2366855144500732
Validation loss: 1.9504407349453177

Epoch: 5| Step: 5
Training loss: 0.9056090116500854
Validation loss: 1.9291322462020382

Epoch: 5| Step: 6
Training loss: 1.124834656715393
Validation loss: 1.9277637799580891

Epoch: 5| Step: 7
Training loss: 0.737539529800415
Validation loss: 1.9517197250038065

Epoch: 5| Step: 8
Training loss: 1.0652594566345215
Validation loss: 2.004158204601657

Epoch: 5| Step: 9
Training loss: 1.0495460033416748
Validation loss: 2.066990024300032

Epoch: 5| Step: 10
Training loss: 1.4246253967285156
Validation loss: 2.098537416868312

Epoch: 240| Step: 0
Training loss: 0.9755881428718567
Validation loss: 2.0675413493187196

Epoch: 5| Step: 1
Training loss: 1.1474323272705078
Validation loss: 2.039165048189061

Epoch: 5| Step: 2
Training loss: 1.0405563116073608
Validation loss: 1.98701556780005

Epoch: 5| Step: 3
Training loss: 1.2622239589691162
Validation loss: 1.9636959811692596

Epoch: 5| Step: 4
Training loss: 1.1996228694915771
Validation loss: 1.9519213912307576

Epoch: 5| Step: 5
Training loss: 1.0232923030853271
Validation loss: 1.948143207898704

Epoch: 5| Step: 6
Training loss: 0.8875938653945923
Validation loss: 1.961511000510185

Epoch: 5| Step: 7
Training loss: 1.1959874629974365
Validation loss: 2.002798436790384

Epoch: 5| Step: 8
Training loss: 0.7355807423591614
Validation loss: 2.0361677318490963

Epoch: 5| Step: 9
Training loss: 0.9413551092147827
Validation loss: 2.126107341499739

Epoch: 5| Step: 10
Training loss: 0.8089925050735474
Validation loss: 2.1735448683461835

Epoch: 241| Step: 0
Training loss: 1.3227641582489014
Validation loss: 2.152087575645857

Epoch: 5| Step: 1
Training loss: 1.0138332843780518
Validation loss: 2.139571302680559

Epoch: 5| Step: 2
Training loss: 1.1709294319152832
Validation loss: 2.1321363577278714

Epoch: 5| Step: 3
Training loss: 0.8492591977119446
Validation loss: 2.051661249130003

Epoch: 5| Step: 4
Training loss: 0.7104675769805908
Validation loss: 1.9928648792287356

Epoch: 5| Step: 5
Training loss: 0.9426220655441284
Validation loss: 1.9688924294646069

Epoch: 5| Step: 6
Training loss: 0.916488766670227
Validation loss: 1.9234305799648326

Epoch: 5| Step: 7
Training loss: 0.8836463093757629
Validation loss: 1.9344365853135304

Epoch: 5| Step: 8
Training loss: 1.1218922138214111
Validation loss: 1.9184052521182644

Epoch: 5| Step: 9
Training loss: 1.1522563695907593
Validation loss: 1.9605458192927863

Epoch: 5| Step: 10
Training loss: 1.081804871559143
Validation loss: 2.0128483208276893

Epoch: 242| Step: 0
Training loss: 0.7254045605659485
Validation loss: 2.0546429029075046

Epoch: 5| Step: 1
Training loss: 1.35068678855896
Validation loss: 2.0484259923299155

Epoch: 5| Step: 2
Training loss: 1.119809865951538
Validation loss: 2.0418451088731007

Epoch: 5| Step: 3
Training loss: 0.747290849685669
Validation loss: 2.008880297342936

Epoch: 5| Step: 4
Training loss: 1.3423335552215576
Validation loss: 1.995489788311784

Epoch: 5| Step: 5
Training loss: 0.6779160499572754
Validation loss: 1.9895130357434672

Epoch: 5| Step: 6
Training loss: 0.9645730257034302
Validation loss: 1.9717781184822

Epoch: 5| Step: 7
Training loss: 0.9828481674194336
Validation loss: 1.958398957406321

Epoch: 5| Step: 8
Training loss: 1.1902291774749756
Validation loss: 1.981950101032052

Epoch: 5| Step: 9
Training loss: 0.9382116198539734
Validation loss: 1.9776714540296985

Epoch: 5| Step: 10
Training loss: 0.6925981044769287
Validation loss: 2.000999237901421

Epoch: 243| Step: 0
Training loss: 0.9406896829605103
Validation loss: 1.9994204531433761

Epoch: 5| Step: 1
Training loss: 0.7637685537338257
Validation loss: 2.0232536510754655

Epoch: 5| Step: 2
Training loss: 0.8774336576461792
Validation loss: 2.0413451194763184

Epoch: 5| Step: 3
Training loss: 1.2132799625396729
Validation loss: 2.0241637050464587

Epoch: 5| Step: 4
Training loss: 1.3225123882293701
Validation loss: 2.0386042312909196

Epoch: 5| Step: 5
Training loss: 0.8166790008544922
Validation loss: 2.017890630229827

Epoch: 5| Step: 6
Training loss: 1.157981038093567
Validation loss: 1.990495712526383

Epoch: 5| Step: 7
Training loss: 1.351863145828247
Validation loss: 1.9848334148365965

Epoch: 5| Step: 8
Training loss: 0.7967309951782227
Validation loss: 1.9790931888805923

Epoch: 5| Step: 9
Training loss: 0.8324815630912781
Validation loss: 1.9782123360582577

Epoch: 5| Step: 10
Training loss: 0.5058546662330627
Validation loss: 1.9720485646237609

Epoch: 244| Step: 0
Training loss: 1.2553026676177979
Validation loss: 1.9899025809380315

Epoch: 5| Step: 1
Training loss: 1.039454698562622
Validation loss: 2.0063294441469255

Epoch: 5| Step: 2
Training loss: 0.7745267152786255
Validation loss: 2.0207678374423774

Epoch: 5| Step: 3
Training loss: 1.180317997932434
Validation loss: 2.029449911527736

Epoch: 5| Step: 4
Training loss: 0.7854655981063843
Validation loss: 2.033417591484644

Epoch: 5| Step: 5
Training loss: 0.9655464291572571
Validation loss: 2.012957875446607

Epoch: 5| Step: 6
Training loss: 0.8479159474372864
Validation loss: 2.0047360107462895

Epoch: 5| Step: 7
Training loss: 0.9249763488769531
Validation loss: 2.0155758319362516

Epoch: 5| Step: 8
Training loss: 0.8947756886482239
Validation loss: 1.9785897680508193

Epoch: 5| Step: 9
Training loss: 0.9885047078132629
Validation loss: 1.9236887501132103

Epoch: 5| Step: 10
Training loss: 0.9312387108802795
Validation loss: 1.911917148097869

Epoch: 245| Step: 0
Training loss: 0.8090196847915649
Validation loss: 1.9345050358003186

Epoch: 5| Step: 1
Training loss: 1.126946210861206
Validation loss: 1.9294357709987189

Epoch: 5| Step: 2
Training loss: 1.4851243495941162
Validation loss: 1.8991395068425003

Epoch: 5| Step: 3
Training loss: 0.6961544752120972
Validation loss: 1.897899450794343

Epoch: 5| Step: 4
Training loss: 0.8141120076179504
Validation loss: 1.9648343606661725

Epoch: 5| Step: 5
Training loss: 0.8890829086303711
Validation loss: 1.9985696295256257

Epoch: 5| Step: 6
Training loss: 0.9510167837142944
Validation loss: 2.0445582712850263

Epoch: 5| Step: 7
Training loss: 0.7248096466064453
Validation loss: 2.06859984320979

Epoch: 5| Step: 8
Training loss: 0.8879725337028503
Validation loss: 2.06164336973621

Epoch: 5| Step: 9
Training loss: 1.159855604171753
Validation loss: 2.0403218346257366

Epoch: 5| Step: 10
Training loss: 1.1336584091186523
Validation loss: 2.000115543283442

Epoch: 246| Step: 0
Training loss: 1.0948832035064697
Validation loss: 1.9661911636270502

Epoch: 5| Step: 1
Training loss: 1.318119764328003
Validation loss: 1.9569108178538661

Epoch: 5| Step: 2
Training loss: 0.8650683164596558
Validation loss: 1.927640708543921

Epoch: 5| Step: 3
Training loss: 0.9647117853164673
Validation loss: 1.9293375374168478

Epoch: 5| Step: 4
Training loss: 0.4955120086669922
Validation loss: 1.9434037746921662

Epoch: 5| Step: 5
Training loss: 0.9949966669082642
Validation loss: 1.967313528060913

Epoch: 5| Step: 6
Training loss: 1.2351408004760742
Validation loss: 2.0215074593021023

Epoch: 5| Step: 7
Training loss: 0.9949922561645508
Validation loss: 2.0945037206014

Epoch: 5| Step: 8
Training loss: 0.750789225101471
Validation loss: 2.1054027798355266

Epoch: 5| Step: 9
Training loss: 0.8149898648262024
Validation loss: 2.075264000123547

Epoch: 5| Step: 10
Training loss: 1.046136736869812
Validation loss: 2.0279661660553305

Epoch: 247| Step: 0
Training loss: 0.9367690086364746
Validation loss: 1.9834802496817805

Epoch: 5| Step: 1
Training loss: 1.137921929359436
Validation loss: 1.9601177656522362

Epoch: 5| Step: 2
Training loss: 0.931263267993927
Validation loss: 1.9600748503079979

Epoch: 5| Step: 3
Training loss: 0.8987972140312195
Validation loss: 1.9854644331880795

Epoch: 5| Step: 4
Training loss: 0.8027325868606567
Validation loss: 1.9666566220662927

Epoch: 5| Step: 5
Training loss: 1.2278013229370117
Validation loss: 1.9664067504226521

Epoch: 5| Step: 6
Training loss: 0.7070093750953674
Validation loss: 1.9901670563605525

Epoch: 5| Step: 7
Training loss: 1.0958280563354492
Validation loss: 2.0520698870382

Epoch: 5| Step: 8
Training loss: 0.8484097719192505
Validation loss: 2.0844489579559653

Epoch: 5| Step: 9
Training loss: 1.1997406482696533
Validation loss: 2.0505953937448482

Epoch: 5| Step: 10
Training loss: 0.8065276741981506
Validation loss: 2.052112530636531

Epoch: 248| Step: 0
Training loss: 0.9715553522109985
Validation loss: 2.0312288140737884

Epoch: 5| Step: 1
Training loss: 0.8192081451416016
Validation loss: 2.029177619564918

Epoch: 5| Step: 2
Training loss: 0.9086602926254272
Validation loss: 1.9739428925257858

Epoch: 5| Step: 3
Training loss: 1.004413366317749
Validation loss: 1.947244257055303

Epoch: 5| Step: 4
Training loss: 1.0086137056350708
Validation loss: 1.9468831939081992

Epoch: 5| Step: 5
Training loss: 0.7727190256118774
Validation loss: 1.9420781622650802

Epoch: 5| Step: 6
Training loss: 1.1113561391830444
Validation loss: 1.9563612668744979

Epoch: 5| Step: 7
Training loss: 1.1918350458145142
Validation loss: 1.946481171474662

Epoch: 5| Step: 8
Training loss: 1.0571258068084717
Validation loss: 1.971882079237251

Epoch: 5| Step: 9
Training loss: 0.8836051821708679
Validation loss: 1.9839145650145829

Epoch: 5| Step: 10
Training loss: 0.8548292517662048
Validation loss: 2.0095681067435973

Epoch: 249| Step: 0
Training loss: 0.8444598913192749
Validation loss: 2.001588454810522

Epoch: 5| Step: 1
Training loss: 0.9448648691177368
Validation loss: 1.9650296242006364

Epoch: 5| Step: 2
Training loss: 1.4395012855529785
Validation loss: 1.96241259062162

Epoch: 5| Step: 3
Training loss: 0.6881872415542603
Validation loss: 1.9503776860493485

Epoch: 5| Step: 4
Training loss: 0.6161783933639526
Validation loss: 1.961916741504464

Epoch: 5| Step: 5
Training loss: 0.8691452741622925
Validation loss: 1.9990351097558134

Epoch: 5| Step: 6
Training loss: 0.45840883255004883
Validation loss: 1.9831111059393933

Epoch: 5| Step: 7
Training loss: 1.1372040510177612
Validation loss: 1.9913297878798617

Epoch: 5| Step: 8
Training loss: 0.9125898480415344
Validation loss: 1.9886409262175202

Epoch: 5| Step: 9
Training loss: 1.163248062133789
Validation loss: 2.008413965984057

Epoch: 5| Step: 10
Training loss: 1.229919195175171
Validation loss: 1.9933530938240789

Epoch: 250| Step: 0
Training loss: 1.3894586563110352
Validation loss: 1.9633511420219176

Epoch: 5| Step: 1
Training loss: 0.4744440019130707
Validation loss: 1.9289370762404574

Epoch: 5| Step: 2
Training loss: 0.9902641177177429
Validation loss: 1.9387759790625623

Epoch: 5| Step: 3
Training loss: 1.0408364534378052
Validation loss: 1.9190588151254961

Epoch: 5| Step: 4
Training loss: 0.9703935384750366
Validation loss: 1.9305344461112894

Epoch: 5| Step: 5
Training loss: 0.7909005880355835
Validation loss: 1.963808418602072

Epoch: 5| Step: 6
Training loss: 0.8181177973747253
Validation loss: 1.984771728515625

Epoch: 5| Step: 7
Training loss: 0.7305467128753662
Validation loss: 1.9865221336323728

Epoch: 5| Step: 8
Training loss: 1.2446973323822021
Validation loss: 1.9413703423674389

Epoch: 5| Step: 9
Training loss: 1.1242787837982178
Validation loss: 1.9437087940913376

Epoch: 5| Step: 10
Training loss: 0.8251635432243347
Validation loss: 1.936636012087586

Epoch: 251| Step: 0
Training loss: 0.8493725061416626
Validation loss: 1.9354406197865803

Epoch: 5| Step: 1
Training loss: 0.7805424928665161
Validation loss: 1.9590531792691959

Epoch: 5| Step: 2
Training loss: 1.1186933517456055
Validation loss: 1.9925646217920447

Epoch: 5| Step: 3
Training loss: 0.9358624219894409
Validation loss: 1.973258541476342

Epoch: 5| Step: 4
Training loss: 1.0892603397369385
Validation loss: 2.0049710863380024

Epoch: 5| Step: 5
Training loss: 0.9385784864425659
Validation loss: 1.9575594907165856

Epoch: 5| Step: 6
Training loss: 1.148482322692871
Validation loss: 1.9616685105908302

Epoch: 5| Step: 7
Training loss: 0.5377963185310364
Validation loss: 1.9512636981984621

Epoch: 5| Step: 8
Training loss: 0.6317562460899353
Validation loss: 1.9500424272270613

Epoch: 5| Step: 9
Training loss: 1.036450982093811
Validation loss: 1.9592293770082536

Epoch: 5| Step: 10
Training loss: 1.027943730354309
Validation loss: 1.9503842220511487

Epoch: 252| Step: 0
Training loss: 0.6866997480392456
Validation loss: 1.9458924006390315

Epoch: 5| Step: 1
Training loss: 1.5281124114990234
Validation loss: 1.956877193143291

Epoch: 5| Step: 2
Training loss: 0.572756290435791
Validation loss: 1.93726638824709

Epoch: 5| Step: 3
Training loss: 0.9779307246208191
Validation loss: 1.9472455952757148

Epoch: 5| Step: 4
Training loss: 1.0418965816497803
Validation loss: 1.9524202808257072

Epoch: 5| Step: 5
Training loss: 0.5210322141647339
Validation loss: 1.9408100407610658

Epoch: 5| Step: 6
Training loss: 1.2632431983947754
Validation loss: 1.9445542571365193

Epoch: 5| Step: 7
Training loss: 0.5839685201644897
Validation loss: 1.9484953649582402

Epoch: 5| Step: 8
Training loss: 0.7350336313247681
Validation loss: 1.9447338927176692

Epoch: 5| Step: 9
Training loss: 0.6853247880935669
Validation loss: 1.943599800909719

Epoch: 5| Step: 10
Training loss: 1.0528628826141357
Validation loss: 1.9342318786087858

Epoch: 253| Step: 0
Training loss: 1.2235625982284546
Validation loss: 1.9334195147278488

Epoch: 5| Step: 1
Training loss: 0.6656104326248169
Validation loss: 1.9307125345353158

Epoch: 5| Step: 2
Training loss: 1.0735572576522827
Validation loss: 1.9393756492163545

Epoch: 5| Step: 3
Training loss: 0.7182442545890808
Validation loss: 1.9514377911885579

Epoch: 5| Step: 4
Training loss: 0.7454546689987183
Validation loss: 1.9855275461750646

Epoch: 5| Step: 5
Training loss: 0.8540658950805664
Validation loss: 1.9909259657705984

Epoch: 5| Step: 6
Training loss: 0.8731096982955933
Validation loss: 2.0006867185715707

Epoch: 5| Step: 7
Training loss: 0.7606652975082397
Validation loss: 1.9756099383036296

Epoch: 5| Step: 8
Training loss: 0.9271257519721985
Validation loss: 1.9966326387979652

Epoch: 5| Step: 9
Training loss: 0.8942488431930542
Validation loss: 1.9513803246200725

Epoch: 5| Step: 10
Training loss: 0.7948998212814331
Validation loss: 1.9405589898427327

Epoch: 254| Step: 0
Training loss: 1.0119050741195679
Validation loss: 1.9405830752465032

Epoch: 5| Step: 1
Training loss: 1.145744800567627
Validation loss: 1.9548275804006925

Epoch: 5| Step: 2
Training loss: 0.719591498374939
Validation loss: 1.9713680744171143

Epoch: 5| Step: 3
Training loss: 1.089827537536621
Validation loss: 1.9613687992095947

Epoch: 5| Step: 4
Training loss: 0.5995354056358337
Validation loss: 1.9409430539736183

Epoch: 5| Step: 5
Training loss: 0.9648083448410034
Validation loss: 1.9777338632973291

Epoch: 5| Step: 6
Training loss: 0.9192060232162476
Validation loss: 1.996542598611565

Epoch: 5| Step: 7
Training loss: 0.6425701379776001
Validation loss: 1.965700376418329

Epoch: 5| Step: 8
Training loss: 0.8600285649299622
Validation loss: 1.9880201226921492

Epoch: 5| Step: 9
Training loss: 0.828486442565918
Validation loss: 1.9863395024371404

Epoch: 5| Step: 10
Training loss: 0.9555743932723999
Validation loss: 1.9710690911098192

Epoch: 255| Step: 0
Training loss: 0.7197807431221008
Validation loss: 1.9733135764316847

Epoch: 5| Step: 1
Training loss: 1.0413482189178467
Validation loss: 1.94387448218561

Epoch: 5| Step: 2
Training loss: 0.8749217987060547
Validation loss: 1.9233650469010877

Epoch: 5| Step: 3
Training loss: 1.1489461660385132
Validation loss: 1.9188333249861194

Epoch: 5| Step: 4
Training loss: 0.5996342301368713
Validation loss: 1.8630673782799834

Epoch: 5| Step: 5
Training loss: 0.9790353775024414
Validation loss: 1.895864845604025

Epoch: 5| Step: 6
Training loss: 0.8278888463973999
Validation loss: 1.9201486469596944

Epoch: 5| Step: 7
Training loss: 0.7289970517158508
Validation loss: 1.9385320114833053

Epoch: 5| Step: 8
Training loss: 0.7797746062278748
Validation loss: 1.979483550594699

Epoch: 5| Step: 9
Training loss: 0.7483453750610352
Validation loss: 1.9743260773279334

Epoch: 5| Step: 10
Training loss: 1.0470229387283325
Validation loss: 1.9874321337669127

Epoch: 256| Step: 0
Training loss: 0.4713595509529114
Validation loss: 1.9810539676297096

Epoch: 5| Step: 1
Training loss: 1.0126712322235107
Validation loss: 1.9808758753602222

Epoch: 5| Step: 2
Training loss: 0.723003625869751
Validation loss: 1.985141888741524

Epoch: 5| Step: 3
Training loss: 0.7184110879898071
Validation loss: 1.9737212722019484

Epoch: 5| Step: 4
Training loss: 0.9332815408706665
Validation loss: 1.9434083533543411

Epoch: 5| Step: 5
Training loss: 1.0916030406951904
Validation loss: 1.9441421416498

Epoch: 5| Step: 6
Training loss: 0.8433621525764465
Validation loss: 1.9450053015062887

Epoch: 5| Step: 7
Training loss: 0.7914092540740967
Validation loss: 1.9290266677897463

Epoch: 5| Step: 8
Training loss: 0.4583008885383606
Validation loss: 1.941465857208416

Epoch: 5| Step: 9
Training loss: 0.9115716814994812
Validation loss: 1.9411413233767274

Epoch: 5| Step: 10
Training loss: 1.4221562147140503
Validation loss: 1.9804149776376703

Epoch: 257| Step: 0
Training loss: 0.6297651529312134
Validation loss: 2.0068860182198147

Epoch: 5| Step: 1
Training loss: 1.222731351852417
Validation loss: 2.0072152819684757

Epoch: 5| Step: 2
Training loss: 0.7482644319534302
Validation loss: 1.9635949865464242

Epoch: 5| Step: 3
Training loss: 1.0636475086212158
Validation loss: 1.9268665313720703

Epoch: 5| Step: 4
Training loss: 0.7974383234977722
Validation loss: 1.9280738176838044

Epoch: 5| Step: 5
Training loss: 0.5807659029960632
Validation loss: 1.9233626986062655

Epoch: 5| Step: 6
Training loss: 0.751594066619873
Validation loss: 1.9370720412141533

Epoch: 5| Step: 7
Training loss: 0.6148773431777954
Validation loss: 1.9278385831463722

Epoch: 5| Step: 8
Training loss: 1.0431082248687744
Validation loss: 1.912986275970295

Epoch: 5| Step: 9
Training loss: 0.9838136434555054
Validation loss: 1.9441257856225456

Epoch: 5| Step: 10
Training loss: 1.033530354499817
Validation loss: 1.9606967856807094

Epoch: 258| Step: 0
Training loss: 0.576257050037384
Validation loss: 1.9786378696400633

Epoch: 5| Step: 1
Training loss: 1.1356420516967773
Validation loss: 1.9584938659462878

Epoch: 5| Step: 2
Training loss: 0.48947954177856445
Validation loss: 1.95525106435181

Epoch: 5| Step: 3
Training loss: 0.6594682335853577
Validation loss: 1.9512953348057245

Epoch: 5| Step: 4
Training loss: 0.9141813516616821
Validation loss: 1.9309804234453427

Epoch: 5| Step: 5
Training loss: 0.8290260434150696
Validation loss: 1.9346329435225456

Epoch: 5| Step: 6
Training loss: 0.6523811221122742
Validation loss: 1.8943033551657071

Epoch: 5| Step: 7
Training loss: 0.7747427821159363
Validation loss: 1.8956063511551067

Epoch: 5| Step: 8
Training loss: 0.7715212106704712
Validation loss: 1.9009436920124998

Epoch: 5| Step: 9
Training loss: 1.0223854780197144
Validation loss: 1.914601969462569

Epoch: 5| Step: 10
Training loss: 1.2021560668945312
Validation loss: 1.9505630231672717

Epoch: 259| Step: 0
Training loss: 1.1381875276565552
Validation loss: 1.9658697805097025

Epoch: 5| Step: 1
Training loss: 1.015904188156128
Validation loss: 1.9761938587311776

Epoch: 5| Step: 2
Training loss: 0.9763023257255554
Validation loss: 1.9848260623152538

Epoch: 5| Step: 3
Training loss: 0.7534129023551941
Validation loss: 2.0132803327293805

Epoch: 5| Step: 4
Training loss: 0.8676850199699402
Validation loss: 2.013771294265665

Epoch: 5| Step: 5
Training loss: 0.6985152959823608
Validation loss: 1.9671597467955722

Epoch: 5| Step: 6
Training loss: 0.5679148435592651
Validation loss: 1.9253430417788926

Epoch: 5| Step: 7
Training loss: 0.8104352951049805
Validation loss: 1.8967887073434808

Epoch: 5| Step: 8
Training loss: 0.6983762383460999
Validation loss: 1.8929254342150945

Epoch: 5| Step: 9
Training loss: 0.5630248188972473
Validation loss: 1.8955174992161412

Epoch: 5| Step: 10
Training loss: 0.9490910768508911
Validation loss: 1.9066585943263064

Epoch: 260| Step: 0
Training loss: 0.5605860948562622
Validation loss: 1.8970963698561474

Epoch: 5| Step: 1
Training loss: 0.811186671257019
Validation loss: 1.858514332002209

Epoch: 5| Step: 2
Training loss: 0.6928511261940002
Validation loss: 1.8354512286442581

Epoch: 5| Step: 3
Training loss: 0.8101504445075989
Validation loss: 1.8420720702858382

Epoch: 5| Step: 4
Training loss: 0.713180422782898
Validation loss: 1.841669221078196

Epoch: 5| Step: 5
Training loss: 0.5222750902175903
Validation loss: 1.8551083867267897

Epoch: 5| Step: 6
Training loss: 0.854591965675354
Validation loss: 1.9000810141204505

Epoch: 5| Step: 7
Training loss: 1.293553113937378
Validation loss: 1.88366751645201

Epoch: 5| Step: 8
Training loss: 0.868435263633728
Validation loss: 1.883438753825362

Epoch: 5| Step: 9
Training loss: 0.6433335542678833
Validation loss: 1.8487618072058565

Epoch: 5| Step: 10
Training loss: 1.2035375833511353
Validation loss: 1.8471310702703332

Epoch: 261| Step: 0
Training loss: 1.0998435020446777
Validation loss: 1.8450075452045729

Epoch: 5| Step: 1
Training loss: 0.7598049640655518
Validation loss: 1.8694579203923543

Epoch: 5| Step: 2
Training loss: 0.9138692021369934
Validation loss: 1.8482903049838157

Epoch: 5| Step: 3
Training loss: 1.1215908527374268
Validation loss: 1.8687151144909602

Epoch: 5| Step: 4
Training loss: 0.5209667086601257
Validation loss: 1.8835713299371863

Epoch: 5| Step: 5
Training loss: 0.7094149589538574
Validation loss: 1.883241125332412

Epoch: 5| Step: 6
Training loss: 0.6732254028320312
Validation loss: 1.8866769882940477

Epoch: 5| Step: 7
Training loss: 1.0790479183197021
Validation loss: 1.8883919408244472

Epoch: 5| Step: 8
Training loss: 0.33250564336776733
Validation loss: 1.8876073706534602

Epoch: 5| Step: 9
Training loss: 0.6643903851509094
Validation loss: 1.8842739815353065

Epoch: 5| Step: 10
Training loss: 0.6736641526222229
Validation loss: 1.8609744823107155

Epoch: 262| Step: 0
Training loss: 0.9357614517211914
Validation loss: 1.8548010510783042

Epoch: 5| Step: 1
Training loss: 0.7292309999465942
Validation loss: 1.8380026919867403

Epoch: 5| Step: 2
Training loss: 0.8638830184936523
Validation loss: 1.8469579245454522

Epoch: 5| Step: 3
Training loss: 0.9146186709403992
Validation loss: 1.8776455515174455

Epoch: 5| Step: 4
Training loss: 0.7869055271148682
Validation loss: 1.9441937631176365

Epoch: 5| Step: 5
Training loss: 0.8331864476203918
Validation loss: 1.9695744604192755

Epoch: 5| Step: 6
Training loss: 0.678519070148468
Validation loss: 1.9644044906862321

Epoch: 5| Step: 7
Training loss: 1.05286705493927
Validation loss: 1.9664514667244368

Epoch: 5| Step: 8
Training loss: 0.667815089225769
Validation loss: 1.9539482260263095

Epoch: 5| Step: 9
Training loss: 1.0120441913604736
Validation loss: 1.8987391751299623

Epoch: 5| Step: 10
Training loss: 0.4704306125640869
Validation loss: 1.8655497092072681

Epoch: 263| Step: 0
Training loss: 0.7370344400405884
Validation loss: 1.8660000460122221

Epoch: 5| Step: 1
Training loss: 0.9039653539657593
Validation loss: 1.8423487704287294

Epoch: 5| Step: 2
Training loss: 0.7620833516120911
Validation loss: 1.8336497558060514

Epoch: 5| Step: 3
Training loss: 0.7880748510360718
Validation loss: 1.8233417349476968

Epoch: 5| Step: 4
Training loss: 0.4534565508365631
Validation loss: 1.840861492259528

Epoch: 5| Step: 5
Training loss: 1.0300008058547974
Validation loss: 1.841845912318076

Epoch: 5| Step: 6
Training loss: 0.8218309283256531
Validation loss: 1.8400260248491842

Epoch: 5| Step: 7
Training loss: 0.8059951066970825
Validation loss: 1.8430797489740516

Epoch: 5| Step: 8
Training loss: 0.6650022268295288
Validation loss: 1.8637358565484323

Epoch: 5| Step: 9
Training loss: 0.7333720922470093
Validation loss: 1.8874231897374636

Epoch: 5| Step: 10
Training loss: 1.328250765800476
Validation loss: 1.907932714749408

Epoch: 264| Step: 0
Training loss: 0.8101248741149902
Validation loss: 1.9164376976669475

Epoch: 5| Step: 1
Training loss: 0.8000890612602234
Validation loss: 1.8980637904136413

Epoch: 5| Step: 2
Training loss: 0.938772976398468
Validation loss: 1.8911323278181014

Epoch: 5| Step: 3
Training loss: 0.5679377317428589
Validation loss: 1.8657755198017243

Epoch: 5| Step: 4
Training loss: 0.9310632944107056
Validation loss: 1.8691510295355191

Epoch: 5| Step: 5
Training loss: 0.9668735265731812
Validation loss: 1.8771780165292884

Epoch: 5| Step: 6
Training loss: 0.6589624881744385
Validation loss: 1.8690511962418914

Epoch: 5| Step: 7
Training loss: 0.7315751314163208
Validation loss: 1.8645448812874414

Epoch: 5| Step: 8
Training loss: 0.8146413564682007
Validation loss: 1.858529777937038

Epoch: 5| Step: 9
Training loss: 0.3377186357975006
Validation loss: 1.8959105373710714

Epoch: 5| Step: 10
Training loss: 0.9719716310501099
Validation loss: 1.9140892387718282

Epoch: 265| Step: 0
Training loss: 0.8486949801445007
Validation loss: 1.9045121695405693

Epoch: 5| Step: 1
Training loss: 0.6093992590904236
Validation loss: 1.9021206478918753

Epoch: 5| Step: 2
Training loss: 0.851273238658905
Validation loss: 1.8919500330443024

Epoch: 5| Step: 3
Training loss: 0.8612499237060547
Validation loss: 1.8811677886593727

Epoch: 5| Step: 4
Training loss: 0.7772587537765503
Validation loss: 1.8892550583808654

Epoch: 5| Step: 5
Training loss: 0.7998492121696472
Validation loss: 1.8891176639064666

Epoch: 5| Step: 6
Training loss: 0.7928091287612915
Validation loss: 1.8887797388979184

Epoch: 5| Step: 7
Training loss: 0.8780779838562012
Validation loss: 1.9055702199218094

Epoch: 5| Step: 8
Training loss: 1.1973644495010376
Validation loss: 1.9216720570800125

Epoch: 5| Step: 9
Training loss: 0.5630141496658325
Validation loss: 1.9294217607026458

Epoch: 5| Step: 10
Training loss: 0.5826840400695801
Validation loss: 1.901126673785589

Epoch: 266| Step: 0
Training loss: 0.9483684301376343
Validation loss: 1.8726890343491749

Epoch: 5| Step: 1
Training loss: 0.8964059948921204
Validation loss: 1.8638540878090808

Epoch: 5| Step: 2
Training loss: 0.810367226600647
Validation loss: 1.8350554909757388

Epoch: 5| Step: 3
Training loss: 0.83668053150177
Validation loss: 1.8304566068034018

Epoch: 5| Step: 4
Training loss: 0.9212018847465515
Validation loss: 1.881528615951538

Epoch: 5| Step: 5
Training loss: 0.759606659412384
Validation loss: 1.8926476252976285

Epoch: 5| Step: 6
Training loss: 0.4858492910861969
Validation loss: 1.8675954495706866

Epoch: 5| Step: 7
Training loss: 0.7141650319099426
Validation loss: 1.8595069992926814

Epoch: 5| Step: 8
Training loss: 0.6072289347648621
Validation loss: 1.8839955509349864

Epoch: 5| Step: 9
Training loss: 1.037864089012146
Validation loss: 1.8586283268467072

Epoch: 5| Step: 10
Training loss: 0.5633542537689209
Validation loss: 1.8369050448940647

Epoch: 267| Step: 0
Training loss: 0.8595305681228638
Validation loss: 1.7835278600774787

Epoch: 5| Step: 1
Training loss: 1.0938093662261963
Validation loss: 1.789171935409628

Epoch: 5| Step: 2
Training loss: 1.0032844543457031
Validation loss: 1.82420430773048

Epoch: 5| Step: 3
Training loss: 0.7671071887016296
Validation loss: 1.8567237969367736

Epoch: 5| Step: 4
Training loss: 0.843396782875061
Validation loss: 1.8812138201088033

Epoch: 5| Step: 5
Training loss: 0.759061872959137
Validation loss: 1.8830217930578417

Epoch: 5| Step: 6
Training loss: 0.4925927221775055
Validation loss: 1.8952363357749036

Epoch: 5| Step: 7
Training loss: 0.49424856901168823
Validation loss: 1.8729759095817484

Epoch: 5| Step: 8
Training loss: 0.5930359363555908
Validation loss: 1.9017388666829755

Epoch: 5| Step: 9
Training loss: 0.9770323634147644
Validation loss: 1.8700279779331659

Epoch: 5| Step: 10
Training loss: 0.6527636051177979
Validation loss: 1.8615372027120283

Epoch: 268| Step: 0
Training loss: 0.9582430720329285
Validation loss: 1.8587443392763856

Epoch: 5| Step: 1
Training loss: 0.5911755561828613
Validation loss: 1.8791988741966985

Epoch: 5| Step: 2
Training loss: 0.9728256464004517
Validation loss: 1.8601005820817844

Epoch: 5| Step: 3
Training loss: 0.5854584574699402
Validation loss: 1.9198867044141215

Epoch: 5| Step: 4
Training loss: 0.9695135951042175
Validation loss: 1.9085369084471016

Epoch: 5| Step: 5
Training loss: 0.38278481364250183
Validation loss: 1.9135845322762766

Epoch: 5| Step: 6
Training loss: 0.8284052610397339
Validation loss: 1.9261965136374197

Epoch: 5| Step: 7
Training loss: 0.5926310420036316
Validation loss: 1.8878293139960176

Epoch: 5| Step: 8
Training loss: 0.9793996810913086
Validation loss: 1.8834589988954606

Epoch: 5| Step: 9
Training loss: 0.5951821804046631
Validation loss: 1.8699217406652306

Epoch: 5| Step: 10
Training loss: 0.817501962184906
Validation loss: 1.8346101314790788

Epoch: 269| Step: 0
Training loss: 1.027919054031372
Validation loss: 1.8606212715948782

Epoch: 5| Step: 1
Training loss: 0.4761541485786438
Validation loss: 1.8481953938802083

Epoch: 5| Step: 2
Training loss: 1.1867587566375732
Validation loss: 1.876814765314902

Epoch: 5| Step: 3
Training loss: 0.472464382648468
Validation loss: 1.9030152546462191

Epoch: 5| Step: 4
Training loss: 0.7923892140388489
Validation loss: 1.9048107029289327

Epoch: 5| Step: 5
Training loss: 1.1602332592010498
Validation loss: 1.8878418143077562

Epoch: 5| Step: 6
Training loss: 0.9053777456283569
Validation loss: 1.893188145852858

Epoch: 5| Step: 7
Training loss: 0.5678145885467529
Validation loss: 1.8588812017953524

Epoch: 5| Step: 8
Training loss: 0.6015434861183167
Validation loss: 1.8657586728372881

Epoch: 5| Step: 9
Training loss: 0.3432101607322693
Validation loss: 1.8275372802570302

Epoch: 5| Step: 10
Training loss: 0.534014880657196
Validation loss: 1.8241541898378761

Epoch: 270| Step: 0
Training loss: 0.4416019916534424
Validation loss: 1.8451024140081098

Epoch: 5| Step: 1
Training loss: 0.8421546220779419
Validation loss: 1.846994633315712

Epoch: 5| Step: 2
Training loss: 0.5879889726638794
Validation loss: 1.899475202765516

Epoch: 5| Step: 3
Training loss: 0.8266938924789429
Validation loss: 1.9160530913260676

Epoch: 5| Step: 4
Training loss: 0.8046171069145203
Validation loss: 1.8925142724026915

Epoch: 5| Step: 5
Training loss: 0.9219438433647156
Validation loss: 1.881365031324407

Epoch: 5| Step: 6
Training loss: 0.5470852851867676
Validation loss: 1.834653890261086

Epoch: 5| Step: 7
Training loss: 0.8921974897384644
Validation loss: 1.8261920047062699

Epoch: 5| Step: 8
Training loss: 0.7707163691520691
Validation loss: 1.8325334466913694

Epoch: 5| Step: 9
Training loss: 0.6131395697593689
Validation loss: 1.8336588541666667

Epoch: 5| Step: 10
Training loss: 0.8746914863586426
Validation loss: 1.8337893050204042

Epoch: 271| Step: 0
Training loss: 0.6116524338722229
Validation loss: 1.8579154809315999

Epoch: 5| Step: 1
Training loss: 0.7218246459960938
Validation loss: 1.8937321298865861

Epoch: 5| Step: 2
Training loss: 0.8070257306098938
Validation loss: 1.8795923007431852

Epoch: 5| Step: 3
Training loss: 0.6947286128997803
Validation loss: 1.9048263565186532

Epoch: 5| Step: 4
Training loss: 0.5093547105789185
Validation loss: 1.9136639410449612

Epoch: 5| Step: 5
Training loss: 0.7199825644493103
Validation loss: 1.8796661118025422

Epoch: 5| Step: 6
Training loss: 0.66396564245224
Validation loss: 1.8542293271710795

Epoch: 5| Step: 7
Training loss: 0.94122314453125
Validation loss: 1.8320873232298

Epoch: 5| Step: 8
Training loss: 0.3866400718688965
Validation loss: 1.8105265966025732

Epoch: 5| Step: 9
Training loss: 0.8331865072250366
Validation loss: 1.834143574519824

Epoch: 5| Step: 10
Training loss: 0.988274097442627
Validation loss: 1.8466282044687579

Epoch: 272| Step: 0
Training loss: 0.6916335225105286
Validation loss: 1.8844543874904673

Epoch: 5| Step: 1
Training loss: 0.7438548803329468
Validation loss: 1.9228274976053545

Epoch: 5| Step: 2
Training loss: 0.7323784232139587
Validation loss: 1.8952513458908244

Epoch: 5| Step: 3
Training loss: 0.6909085512161255
Validation loss: 1.9027810840196506

Epoch: 5| Step: 4
Training loss: 0.8578511476516724
Validation loss: 1.8525012334187825

Epoch: 5| Step: 5
Training loss: 1.1508382558822632
Validation loss: 1.8287511461524553

Epoch: 5| Step: 6
Training loss: 0.4903540015220642
Validation loss: 1.8017839231798727

Epoch: 5| Step: 7
Training loss: 0.5306118726730347
Validation loss: 1.8101362297611852

Epoch: 5| Step: 8
Training loss: 0.5953665971755981
Validation loss: 1.8392917045982935

Epoch: 5| Step: 9
Training loss: 0.6878954768180847
Validation loss: 1.905159108100399

Epoch: 5| Step: 10
Training loss: 0.6924824714660645
Validation loss: 2.018394813742689

Epoch: 273| Step: 0
Training loss: 0.7361387014389038
Validation loss: 1.9812778939482987

Epoch: 5| Step: 1
Training loss: 0.690569281578064
Validation loss: 1.930938914257993

Epoch: 5| Step: 2
Training loss: 0.5578058958053589
Validation loss: 1.8834199136303318

Epoch: 5| Step: 3
Training loss: 0.6649041175842285
Validation loss: 1.8052854678964103

Epoch: 5| Step: 4
Training loss: 0.8054876327514648
Validation loss: 1.7966458387272333

Epoch: 5| Step: 5
Training loss: 0.6414841413497925
Validation loss: 1.7837421842800674

Epoch: 5| Step: 6
Training loss: 1.041885495185852
Validation loss: 1.7664364499430503

Epoch: 5| Step: 7
Training loss: 0.5516794323921204
Validation loss: 1.7815406117387997

Epoch: 5| Step: 8
Training loss: 0.69498211145401
Validation loss: 1.8049834300112981

Epoch: 5| Step: 9
Training loss: 1.2309691905975342
Validation loss: 1.8296631818176599

Epoch: 5| Step: 10
Training loss: 0.27530911564826965
Validation loss: 1.8973614297887331

Epoch: 274| Step: 0
Training loss: 0.6965462565422058
Validation loss: 1.9337589420298094

Epoch: 5| Step: 1
Training loss: 0.8935712575912476
Validation loss: 1.9311891909568542

Epoch: 5| Step: 2
Training loss: 0.7862997651100159
Validation loss: 1.9014976075900498

Epoch: 5| Step: 3
Training loss: 0.9015324711799622
Validation loss: 1.882606953702947

Epoch: 5| Step: 4
Training loss: 0.5991499423980713
Validation loss: 1.8291206129135624

Epoch: 5| Step: 5
Training loss: 0.7230738401412964
Validation loss: 1.7970745666052705

Epoch: 5| Step: 6
Training loss: 0.6446868181228638
Validation loss: 1.818500639289938

Epoch: 5| Step: 7
Training loss: 0.6255005598068237
Validation loss: 1.7957476108304915

Epoch: 5| Step: 8
Training loss: 0.6907579302787781
Validation loss: 1.7916730962773806

Epoch: 5| Step: 9
Training loss: 1.1655141115188599
Validation loss: 1.83801225180267

Epoch: 5| Step: 10
Training loss: 0.5209220051765442
Validation loss: 1.8825201155037008

Epoch: 275| Step: 0
Training loss: 0.7508026957511902
Validation loss: 1.9431613593973138

Epoch: 5| Step: 1
Training loss: 0.6817616820335388
Validation loss: 1.9638839024369434

Epoch: 5| Step: 2
Training loss: 0.5385990738868713
Validation loss: 1.9633312340705626

Epoch: 5| Step: 3
Training loss: 0.9309293627738953
Validation loss: 1.971246853951485

Epoch: 5| Step: 4
Training loss: 0.8686786890029907
Validation loss: 1.926869156540081

Epoch: 5| Step: 5
Training loss: 0.5896637439727783
Validation loss: 1.8898114260806833

Epoch: 5| Step: 6
Training loss: 0.7378463745117188
Validation loss: 1.8688590834217687

Epoch: 5| Step: 7
Training loss: 0.6508750915527344
Validation loss: 1.8182178697278422

Epoch: 5| Step: 8
Training loss: 0.6470297574996948
Validation loss: 1.840632450196051

Epoch: 5| Step: 9
Training loss: 0.7303163409233093
Validation loss: 1.8342882894700574

Epoch: 5| Step: 10
Training loss: 0.805442214012146
Validation loss: 1.8362313855078913

Epoch: 276| Step: 0
Training loss: 0.6873776316642761
Validation loss: 1.8605309288988832

Epoch: 5| Step: 1
Training loss: 0.716943621635437
Validation loss: 1.8504478700699345

Epoch: 5| Step: 2
Training loss: 0.8162225484848022
Validation loss: 1.8589488421716998

Epoch: 5| Step: 3
Training loss: 0.4492715001106262
Validation loss: 1.8478788816800682

Epoch: 5| Step: 4
Training loss: 0.6055985689163208
Validation loss: 1.8526761096010926

Epoch: 5| Step: 5
Training loss: 0.7002613544464111
Validation loss: 1.869485088573989

Epoch: 5| Step: 6
Training loss: 0.8321791887283325
Validation loss: 1.893540491339981

Epoch: 5| Step: 7
Training loss: 0.45154744386672974
Validation loss: 1.913563007949501

Epoch: 5| Step: 8
Training loss: 0.5268330574035645
Validation loss: 1.883295084840508

Epoch: 5| Step: 9
Training loss: 0.9293907284736633
Validation loss: 1.8623627795968005

Epoch: 5| Step: 10
Training loss: 0.9934678673744202
Validation loss: 1.840209081608762

Epoch: 277| Step: 0
Training loss: 0.6704936623573303
Validation loss: 1.8461414050030451

Epoch: 5| Step: 1
Training loss: 0.46870461106300354
Validation loss: 1.8375160860758957

Epoch: 5| Step: 2
Training loss: 0.89244145154953
Validation loss: 1.8319011734377952

Epoch: 5| Step: 3
Training loss: 0.5938233137130737
Validation loss: 1.8265710376924085

Epoch: 5| Step: 4
Training loss: 0.6344987154006958
Validation loss: 1.8030408608016146

Epoch: 5| Step: 5
Training loss: 0.9758513569831848
Validation loss: 1.8079443952088714

Epoch: 5| Step: 6
Training loss: 0.5768386721611023
Validation loss: 1.8527126683983752

Epoch: 5| Step: 7
Training loss: 0.668491005897522
Validation loss: 1.903166627371183

Epoch: 5| Step: 8
Training loss: 0.508529007434845
Validation loss: 1.9007329222976521

Epoch: 5| Step: 9
Training loss: 0.8131494522094727
Validation loss: 1.886911194811585

Epoch: 5| Step: 10
Training loss: 0.6129648089408875
Validation loss: 1.8800838634531984

Epoch: 278| Step: 0
Training loss: 0.70948725938797
Validation loss: 1.8398231511474938

Epoch: 5| Step: 1
Training loss: 0.7019144892692566
Validation loss: 1.8479194564204062

Epoch: 5| Step: 2
Training loss: 0.6551581621170044
Validation loss: 1.8337280096546296

Epoch: 5| Step: 3
Training loss: 0.542219340801239
Validation loss: 1.8260851496009416

Epoch: 5| Step: 4
Training loss: 0.9921743273735046
Validation loss: 1.8247401432324482

Epoch: 5| Step: 5
Training loss: 0.7656723856925964
Validation loss: 1.8363241559715682

Epoch: 5| Step: 6
Training loss: 0.6114076375961304
Validation loss: 1.827226492666429

Epoch: 5| Step: 7
Training loss: 0.7935570478439331
Validation loss: 1.8263454462892266

Epoch: 5| Step: 8
Training loss: 0.4751729965209961
Validation loss: 1.844046478630394

Epoch: 5| Step: 9
Training loss: 0.38138189911842346
Validation loss: 1.8759931877095213

Epoch: 5| Step: 10
Training loss: 0.708503007888794
Validation loss: 1.9108794389232513

Epoch: 279| Step: 0
Training loss: 0.5101771354675293
Validation loss: 1.935380474213631

Epoch: 5| Step: 1
Training loss: 0.7136853933334351
Validation loss: 1.9517124955372145

Epoch: 5| Step: 2
Training loss: 0.5564448237419128
Validation loss: 1.8949711707330519

Epoch: 5| Step: 3
Training loss: 0.8691490292549133
Validation loss: 1.8458769654714933

Epoch: 5| Step: 4
Training loss: 0.7797986268997192
Validation loss: 1.820309700504426

Epoch: 5| Step: 5
Training loss: 0.49423813819885254
Validation loss: 1.8087843759085542

Epoch: 5| Step: 6
Training loss: 0.9768165349960327
Validation loss: 1.8184151226474392

Epoch: 5| Step: 7
Training loss: 0.6420292854309082
Validation loss: 1.8211438117488739

Epoch: 5| Step: 8
Training loss: 0.6794279217720032
Validation loss: 1.8649898946926158

Epoch: 5| Step: 9
Training loss: 0.7636621594429016
Validation loss: 1.9007287499725178

Epoch: 5| Step: 10
Training loss: 0.5793782472610474
Validation loss: 1.9173719062600085

Epoch: 280| Step: 0
Training loss: 0.980280876159668
Validation loss: 1.9144662695546304

Epoch: 5| Step: 1
Training loss: 1.0015102624893188
Validation loss: 1.8981994005941576

Epoch: 5| Step: 2
Training loss: 0.5954669117927551
Validation loss: 1.8859722088742

Epoch: 5| Step: 3
Training loss: 0.602474570274353
Validation loss: 1.8362908414615098

Epoch: 5| Step: 4
Training loss: 0.5771065950393677
Validation loss: 1.8190672230976883

Epoch: 5| Step: 5
Training loss: 0.3998650908470154
Validation loss: 1.8171563545862834

Epoch: 5| Step: 6
Training loss: 0.4998892843723297
Validation loss: 1.8418551157879572

Epoch: 5| Step: 7
Training loss: 0.5101372003555298
Validation loss: 1.8323941705047444

Epoch: 5| Step: 8
Training loss: 0.6885221600532532
Validation loss: 1.8177061362933087

Epoch: 5| Step: 9
Training loss: 0.6538494229316711
Validation loss: 1.8298261934711086

Epoch: 5| Step: 10
Training loss: 0.744754433631897
Validation loss: 1.806203842163086

Epoch: 281| Step: 0
Training loss: 0.914178192615509
Validation loss: 1.80984938785594

Epoch: 5| Step: 1
Training loss: 0.38939744234085083
Validation loss: 1.8159968852996826

Epoch: 5| Step: 2
Training loss: 0.3754420578479767
Validation loss: 1.817154953556676

Epoch: 5| Step: 3
Training loss: 1.0996732711791992
Validation loss: 1.8264333727539226

Epoch: 5| Step: 4
Training loss: 0.9105056524276733
Validation loss: 1.8349986550628499

Epoch: 5| Step: 5
Training loss: 0.7184200882911682
Validation loss: 1.8095461758234168

Epoch: 5| Step: 6
Training loss: 0.7720907330513
Validation loss: 1.8086274208561066

Epoch: 5| Step: 7
Training loss: 0.6402686834335327
Validation loss: 1.8026940361146004

Epoch: 5| Step: 8
Training loss: 0.2786405682563782
Validation loss: 1.8096656837771017

Epoch: 5| Step: 9
Training loss: 0.5702983140945435
Validation loss: 1.8374102871905091

Epoch: 5| Step: 10
Training loss: 0.3494676947593689
Validation loss: 1.8349138972579793

Epoch: 282| Step: 0
Training loss: 0.6021416783332825
Validation loss: 1.8588076663273636

Epoch: 5| Step: 1
Training loss: 0.8790172338485718
Validation loss: 1.8436595329674341

Epoch: 5| Step: 2
Training loss: 0.4891207814216614
Validation loss: 1.8343047723975232

Epoch: 5| Step: 3
Training loss: 1.014717936515808
Validation loss: 1.818921724955241

Epoch: 5| Step: 4
Training loss: 0.3170740604400635
Validation loss: 1.8180601250740789

Epoch: 5| Step: 5
Training loss: 0.5869807004928589
Validation loss: 1.7909915549780733

Epoch: 5| Step: 6
Training loss: 0.5812702178955078
Validation loss: 1.8134131944307716

Epoch: 5| Step: 7
Training loss: 0.43118906021118164
Validation loss: 1.792853755335654

Epoch: 5| Step: 8
Training loss: 0.7054834961891174
Validation loss: 1.8178107251403153

Epoch: 5| Step: 9
Training loss: 0.7724781036376953
Validation loss: 1.84794585422803

Epoch: 5| Step: 10
Training loss: 0.3576682209968567
Validation loss: 1.8342257007475822

Epoch: 283| Step: 0
Training loss: 0.532825767993927
Validation loss: 1.8400743981843353

Epoch: 5| Step: 1
Training loss: 0.47920697927474976
Validation loss: 1.8225319180437314

Epoch: 5| Step: 2
Training loss: 0.633493959903717
Validation loss: 1.8460999611885316

Epoch: 5| Step: 3
Training loss: 0.4266938269138336
Validation loss: 1.8544070554035965

Epoch: 5| Step: 4
Training loss: 0.7087379693984985
Validation loss: 1.863082392241365

Epoch: 5| Step: 5
Training loss: 0.704229474067688
Validation loss: 1.8910146259492444

Epoch: 5| Step: 6
Training loss: 0.5490527153015137
Validation loss: 1.9141116488364436

Epoch: 5| Step: 7
Training loss: 0.853186309337616
Validation loss: 1.8971578895404775

Epoch: 5| Step: 8
Training loss: 0.8476503491401672
Validation loss: 1.8941448016833233

Epoch: 5| Step: 9
Training loss: 0.6003638505935669
Validation loss: 1.8259083558154363

Epoch: 5| Step: 10
Training loss: 0.7007419466972351
Validation loss: 1.816242838418612

Epoch: 284| Step: 0
Training loss: 0.8995715975761414
Validation loss: 1.7970933760366132

Epoch: 5| Step: 1
Training loss: 0.29009777307510376
Validation loss: 1.7945296226009246

Epoch: 5| Step: 2
Training loss: 0.5132738947868347
Validation loss: 1.8175490966407202

Epoch: 5| Step: 3
Training loss: 0.5833446979522705
Validation loss: 1.856529123039656

Epoch: 5| Step: 4
Training loss: 0.5270130038261414
Validation loss: 1.914006006333136

Epoch: 5| Step: 5
Training loss: 0.8230284452438354
Validation loss: 1.9299208297524402

Epoch: 5| Step: 6
Training loss: 0.7047945857048035
Validation loss: 1.9231889837531633

Epoch: 5| Step: 7
Training loss: 0.8699496984481812
Validation loss: 1.8976028606455813

Epoch: 5| Step: 8
Training loss: 0.6088141202926636
Validation loss: 1.8548686068545106

Epoch: 5| Step: 9
Training loss: 0.5622665286064148
Validation loss: 1.8254243199543287

Epoch: 5| Step: 10
Training loss: 0.8973480463027954
Validation loss: 1.8137880166371663

Epoch: 285| Step: 0
Training loss: 0.6360143423080444
Validation loss: 1.8375623200529365

Epoch: 5| Step: 1
Training loss: 0.30500146746635437
Validation loss: 1.817475466318028

Epoch: 5| Step: 2
Training loss: 0.7559820413589478
Validation loss: 1.8267613380186019

Epoch: 5| Step: 3
Training loss: 0.7186548113822937
Validation loss: 1.855420579192459

Epoch: 5| Step: 4
Training loss: 0.4939126968383789
Validation loss: 1.8955272513051187

Epoch: 5| Step: 5
Training loss: 0.5810917019844055
Validation loss: 1.9105040950159873

Epoch: 5| Step: 6
Training loss: 0.5780032277107239
Validation loss: 1.9219961845746605

Epoch: 5| Step: 7
Training loss: 0.8726462125778198
Validation loss: 1.9278384229188323

Epoch: 5| Step: 8
Training loss: 0.61811363697052
Validation loss: 1.8699749926085114

Epoch: 5| Step: 9
Training loss: 0.6409820318222046
Validation loss: 1.8243141302498438

Epoch: 5| Step: 10
Training loss: 0.8995664119720459
Validation loss: 1.8235006781034573

Epoch: 286| Step: 0
Training loss: 0.48067131638526917
Validation loss: 1.8175324547675349

Epoch: 5| Step: 1
Training loss: 0.5693165063858032
Validation loss: 1.844749484010922

Epoch: 5| Step: 2
Training loss: 0.6956709027290344
Validation loss: 1.8446610755817865

Epoch: 5| Step: 3
Training loss: 0.5179381966590881
Validation loss: 1.8584069846778788

Epoch: 5| Step: 4
Training loss: 0.5850906372070312
Validation loss: 1.8973591712213331

Epoch: 5| Step: 5
Training loss: 0.33054104447364807
Validation loss: 1.9044102391889017

Epoch: 5| Step: 6
Training loss: 0.5918237566947937
Validation loss: 1.8867733119636454

Epoch: 5| Step: 7
Training loss: 0.44799375534057617
Validation loss: 1.879639430712628

Epoch: 5| Step: 8
Training loss: 0.9090499877929688
Validation loss: 1.8607188283756215

Epoch: 5| Step: 9
Training loss: 0.704703152179718
Validation loss: 1.8218179364358225

Epoch: 5| Step: 10
Training loss: 1.0013447999954224
Validation loss: 1.822910721584033

Epoch: 287| Step: 0
Training loss: 0.6069505214691162
Validation loss: 1.8023184409705542

Epoch: 5| Step: 1
Training loss: 0.5646703243255615
Validation loss: 1.7970952269851521

Epoch: 5| Step: 2
Training loss: 0.899040699005127
Validation loss: 1.8085721321003412

Epoch: 5| Step: 3
Training loss: 0.5697913765907288
Validation loss: 1.8141252020353913

Epoch: 5| Step: 4
Training loss: 0.5624080896377563
Validation loss: 1.7989652490103116

Epoch: 5| Step: 5
Training loss: 0.45374053716659546
Validation loss: 1.8884867263096634

Epoch: 5| Step: 6
Training loss: 0.4548220634460449
Validation loss: 1.9304110080965105

Epoch: 5| Step: 7
Training loss: 0.7698320150375366
Validation loss: 1.957393838513282

Epoch: 5| Step: 8
Training loss: 0.7886025309562683
Validation loss: 1.988623934407388

Epoch: 5| Step: 9
Training loss: 0.8695297241210938
Validation loss: 1.985319866929003

Epoch: 5| Step: 10
Training loss: 0.5541759729385376
Validation loss: 1.9250085776852024

Epoch: 288| Step: 0
Training loss: 0.6459985971450806
Validation loss: 1.8556002750191638

Epoch: 5| Step: 1
Training loss: 0.41705092787742615
Validation loss: 1.8233020536361202

Epoch: 5| Step: 2
Training loss: 0.7125077843666077
Validation loss: 1.8027346262367823

Epoch: 5| Step: 3
Training loss: 0.9182153940200806
Validation loss: 1.7946189847043765

Epoch: 5| Step: 4
Training loss: 0.842261791229248
Validation loss: 1.7845445345806819

Epoch: 5| Step: 5
Training loss: 0.8342008590698242
Validation loss: 1.7890842563362532

Epoch: 5| Step: 6
Training loss: 0.6796820759773254
Validation loss: 1.8099801335283505

Epoch: 5| Step: 7
Training loss: 0.6501920819282532
Validation loss: 1.8510457136297738

Epoch: 5| Step: 8
Training loss: 0.392340749502182
Validation loss: 1.8902511353133826

Epoch: 5| Step: 9
Training loss: 0.4190099835395813
Validation loss: 1.9227143936259772

Epoch: 5| Step: 10
Training loss: 0.6472730040550232
Validation loss: 1.9254613332850958

Epoch: 289| Step: 0
Training loss: 0.3807346224784851
Validation loss: 1.9280785655462613

Epoch: 5| Step: 1
Training loss: 0.531027615070343
Validation loss: 1.9158897246083906

Epoch: 5| Step: 2
Training loss: 0.6940904259681702
Validation loss: 1.919633726919851

Epoch: 5| Step: 3
Training loss: 0.5668826699256897
Validation loss: 1.9179872812763337

Epoch: 5| Step: 4
Training loss: 1.1191526651382446
Validation loss: 1.8713832093823342

Epoch: 5| Step: 5
Training loss: 0.6268781423568726
Validation loss: 1.8026935490228797

Epoch: 5| Step: 6
Training loss: 0.5782690048217773
Validation loss: 1.8000313466595066

Epoch: 5| Step: 7
Training loss: 0.5883340239524841
Validation loss: 1.805882953828381

Epoch: 5| Step: 8
Training loss: 0.6128262281417847
Validation loss: 1.804930902296497

Epoch: 5| Step: 9
Training loss: 0.5048978924751282
Validation loss: 1.8112817707882132

Epoch: 5| Step: 10
Training loss: 0.40214109420776367
Validation loss: 1.8176796679855676

Epoch: 290| Step: 0
Training loss: 0.3925479054450989
Validation loss: 1.8118470907211304

Epoch: 5| Step: 1
Training loss: 0.8604885935783386
Validation loss: 1.8526281310665993

Epoch: 5| Step: 2
Training loss: 0.5076794624328613
Validation loss: 1.8908659924742997

Epoch: 5| Step: 3
Training loss: 0.39058712124824524
Validation loss: 1.8960871709290372

Epoch: 5| Step: 4
Training loss: 0.6645363569259644
Validation loss: 1.8522484866521691

Epoch: 5| Step: 5
Training loss: 0.7325167059898376
Validation loss: 1.8206605244708318

Epoch: 5| Step: 6
Training loss: 0.5348179936408997
Validation loss: 1.8135100500558012

Epoch: 5| Step: 7
Training loss: 0.6423318982124329
Validation loss: 1.8180679749417048

Epoch: 5| Step: 8
Training loss: 0.46111616492271423
Validation loss: 1.8116380168545632

Epoch: 5| Step: 9
Training loss: 0.6703972816467285
Validation loss: 1.8355687433673489

Epoch: 5| Step: 10
Training loss: 0.633684515953064
Validation loss: 1.7897781351561188

Epoch: 291| Step: 0
Training loss: 0.4895104467868805
Validation loss: 1.7771035009814846

Epoch: 5| Step: 1
Training loss: 0.9887136220932007
Validation loss: 1.7840422866164998

Epoch: 5| Step: 2
Training loss: 0.5040255188941956
Validation loss: 1.7939732664374894

Epoch: 5| Step: 3
Training loss: 0.5684572458267212
Validation loss: 1.7967759742531726

Epoch: 5| Step: 4
Training loss: 0.39287838339805603
Validation loss: 1.814161023785991

Epoch: 5| Step: 5
Training loss: 0.3783338963985443
Validation loss: 1.84661147158633

Epoch: 5| Step: 6
Training loss: 0.4748111665248871
Validation loss: 1.88570120129534

Epoch: 5| Step: 7
Training loss: 0.8760741353034973
Validation loss: 1.9478168308093984

Epoch: 5| Step: 8
Training loss: 0.6301745176315308
Validation loss: 1.9539104341178812

Epoch: 5| Step: 9
Training loss: 0.9190143346786499
Validation loss: 1.8739725979425574

Epoch: 5| Step: 10
Training loss: 0.528513491153717
Validation loss: 1.8262361082979428

Epoch: 292| Step: 0
Training loss: 0.8314809799194336
Validation loss: 1.7937285028478152

Epoch: 5| Step: 1
Training loss: 0.5309877395629883
Validation loss: 1.8085477006050847

Epoch: 5| Step: 2
Training loss: 0.6524049639701843
Validation loss: 1.8051939766894105

Epoch: 5| Step: 3
Training loss: 0.828377366065979
Validation loss: 1.7984043539211314

Epoch: 5| Step: 4
Training loss: 0.5943467020988464
Validation loss: 1.7980653675653602

Epoch: 5| Step: 5
Training loss: 0.3288031816482544
Validation loss: 1.815643015728202

Epoch: 5| Step: 6
Training loss: 0.4584949016571045
Validation loss: 1.845317086865825

Epoch: 5| Step: 7
Training loss: 0.6558891534805298
Validation loss: 1.8452816253067346

Epoch: 5| Step: 8
Training loss: 0.7670344710350037
Validation loss: 1.8698520352763515

Epoch: 5| Step: 9
Training loss: 0.4084247648715973
Validation loss: 1.8830004597222934

Epoch: 5| Step: 10
Training loss: 0.6480720043182373
Validation loss: 1.8622024520750968

Epoch: 293| Step: 0
Training loss: 0.7874974012374878
Validation loss: 1.846098938295918

Epoch: 5| Step: 1
Training loss: 0.43095502257347107
Validation loss: 1.8303808294316775

Epoch: 5| Step: 2
Training loss: 1.065040946006775
Validation loss: 1.8117059276949974

Epoch: 5| Step: 3
Training loss: 0.4684349596500397
Validation loss: 1.8155778761832946

Epoch: 5| Step: 4
Training loss: 0.5792819857597351
Validation loss: 1.797013658349232

Epoch: 5| Step: 5
Training loss: 0.3207527995109558
Validation loss: 1.7730602500259236

Epoch: 5| Step: 6
Training loss: 0.5243858695030212
Validation loss: 1.773065754162368

Epoch: 5| Step: 7
Training loss: 0.5133422017097473
Validation loss: 1.7894974690611645

Epoch: 5| Step: 8
Training loss: 0.4117303490638733
Validation loss: 1.786264810510861

Epoch: 5| Step: 9
Training loss: 0.4278814196586609
Validation loss: 1.7866897301007343

Epoch: 5| Step: 10
Training loss: 0.5565454959869385
Validation loss: 1.8021824500894035

Epoch: 294| Step: 0
Training loss: 0.543084442615509
Validation loss: 1.807568920555935

Epoch: 5| Step: 1
Training loss: 0.5130274891853333
Validation loss: 1.782412910974154

Epoch: 5| Step: 2
Training loss: 0.7410855293273926
Validation loss: 1.783310003178094

Epoch: 5| Step: 3
Training loss: 0.2509308457374573
Validation loss: 1.7777159252474386

Epoch: 5| Step: 4
Training loss: 0.6594265699386597
Validation loss: 1.7630989410543954

Epoch: 5| Step: 5
Training loss: 0.6920408010482788
Validation loss: 1.7886557040675994

Epoch: 5| Step: 6
Training loss: 0.4751465916633606
Validation loss: 1.7974028125885995

Epoch: 5| Step: 7
Training loss: 0.4874429702758789
Validation loss: 1.790929873784383

Epoch: 5| Step: 8
Training loss: 0.7560313940048218
Validation loss: 1.815955312021317

Epoch: 5| Step: 9
Training loss: 0.4741344451904297
Validation loss: 1.8431365630959953

Epoch: 5| Step: 10
Training loss: 0.6125249862670898
Validation loss: 1.8345744186832058

Epoch: 295| Step: 0
Training loss: 0.67404705286026
Validation loss: 1.8307397083569599

Epoch: 5| Step: 1
Training loss: 0.7910051941871643
Validation loss: 1.8732063026838406

Epoch: 5| Step: 2
Training loss: 0.31893402338027954
Validation loss: 1.8558528141308857

Epoch: 5| Step: 3
Training loss: 0.4046770930290222
Validation loss: 1.863022824769379

Epoch: 5| Step: 4
Training loss: 0.8028078079223633
Validation loss: 1.8703806490026496

Epoch: 5| Step: 5
Training loss: 0.4810259938240051
Validation loss: 1.8893881574753792

Epoch: 5| Step: 6
Training loss: 0.6018885374069214
Validation loss: 1.8942648755606784

Epoch: 5| Step: 7
Training loss: 0.7345044016838074
Validation loss: 1.9120489499902213

Epoch: 5| Step: 8
Training loss: 0.575985312461853
Validation loss: 1.85892564763305

Epoch: 5| Step: 9
Training loss: 0.5543026924133301
Validation loss: 1.8439731085172264

Epoch: 5| Step: 10
Training loss: 0.2955157160758972
Validation loss: 1.8495005382004606

Epoch: 296| Step: 0
Training loss: 0.4335624575614929
Validation loss: 1.836048569730533

Epoch: 5| Step: 1
Training loss: 0.5889831185340881
Validation loss: 1.8442072073618572

Epoch: 5| Step: 2
Training loss: 0.796382486820221
Validation loss: 1.861300806845388

Epoch: 5| Step: 3
Training loss: 0.6541444063186646
Validation loss: 1.846243675037097

Epoch: 5| Step: 4
Training loss: 0.45366305112838745
Validation loss: 1.8606479962666829

Epoch: 5| Step: 5
Training loss: 0.4494163393974304
Validation loss: 1.821103572845459

Epoch: 5| Step: 6
Training loss: 0.37063342332839966
Validation loss: 1.8233757454861876

Epoch: 5| Step: 7
Training loss: 0.6563481688499451
Validation loss: 1.8458174864451091

Epoch: 5| Step: 8
Training loss: 0.48353081941604614
Validation loss: 1.8457395338243054

Epoch: 5| Step: 9
Training loss: 0.8501936793327332
Validation loss: 1.8307042557706115

Epoch: 5| Step: 10
Training loss: 0.36878445744514465
Validation loss: 1.817197903510063

Epoch: 297| Step: 0
Training loss: 0.49717527627944946
Validation loss: 1.830612369762954

Epoch: 5| Step: 1
Training loss: 0.5729809999465942
Validation loss: 1.8359894239774315

Epoch: 5| Step: 2
Training loss: 0.5759783983230591
Validation loss: 1.836696203036975

Epoch: 5| Step: 3
Training loss: 0.6311988830566406
Validation loss: 1.8082798193859797

Epoch: 5| Step: 4
Training loss: 0.7412427067756653
Validation loss: 1.821647617124742

Epoch: 5| Step: 5
Training loss: 0.4664185643196106
Validation loss: 1.8321121277347687

Epoch: 5| Step: 6
Training loss: 0.38024765253067017
Validation loss: 1.8224243412735641

Epoch: 5| Step: 7
Training loss: 0.38016945123672485
Validation loss: 1.8484747294456727

Epoch: 5| Step: 8
Training loss: 0.47942981123924255
Validation loss: 1.8612696381025418

Epoch: 5| Step: 9
Training loss: 0.7896075248718262
Validation loss: 1.8835849082598122

Epoch: 5| Step: 10
Training loss: 0.44755491614341736
Validation loss: 1.8490155473832162

Epoch: 298| Step: 0
Training loss: 0.7738792300224304
Validation loss: 1.8127478886676092

Epoch: 5| Step: 1
Training loss: 0.294522225856781
Validation loss: 1.792838619601342

Epoch: 5| Step: 2
Training loss: 0.5918682813644409
Validation loss: 1.7787446770616757

Epoch: 5| Step: 3
Training loss: 0.3593948781490326
Validation loss: 1.7486250323633994

Epoch: 5| Step: 4
Training loss: 0.4554177224636078
Validation loss: 1.7722135231059084

Epoch: 5| Step: 5
Training loss: 0.7716497182846069
Validation loss: 1.7691810720710344

Epoch: 5| Step: 6
Training loss: 0.4913333058357239
Validation loss: 1.7812920693428285

Epoch: 5| Step: 7
Training loss: 0.3451647162437439
Validation loss: 1.8070362460228704

Epoch: 5| Step: 8
Training loss: 0.8291172981262207
Validation loss: 1.8372232132060553

Epoch: 5| Step: 9
Training loss: 0.5337570905685425
Validation loss: 1.8285342519001295

Epoch: 5| Step: 10
Training loss: 0.6287795305252075
Validation loss: 1.8096532257654334

Epoch: 299| Step: 0
Training loss: 0.5800849199295044
Validation loss: 1.8040263140073387

Epoch: 5| Step: 1
Training loss: 0.46138086915016174
Validation loss: 1.8101767314377653

Epoch: 5| Step: 2
Training loss: 0.8051934242248535
Validation loss: 1.8286710413553382

Epoch: 5| Step: 3
Training loss: 0.5153797268867493
Validation loss: 1.8357386178867792

Epoch: 5| Step: 4
Training loss: 0.3031042516231537
Validation loss: 1.863374574210054

Epoch: 5| Step: 5
Training loss: 0.47964492440223694
Validation loss: 1.8762222105456936

Epoch: 5| Step: 6
Training loss: 0.7238550186157227
Validation loss: 1.8780694764147523

Epoch: 5| Step: 7
Training loss: 0.6576820611953735
Validation loss: 1.853765663280282

Epoch: 5| Step: 8
Training loss: 0.5386170148849487
Validation loss: 1.8723466960332726

Epoch: 5| Step: 9
Training loss: 0.5128945112228394
Validation loss: 1.822535249494737

Epoch: 5| Step: 10
Training loss: 0.3046374022960663
Validation loss: 1.8461890553915372

Epoch: 300| Step: 0
Training loss: 0.5024721622467041
Validation loss: 1.832504036605999

Epoch: 5| Step: 1
Training loss: 0.505548357963562
Validation loss: 1.811419343435636

Epoch: 5| Step: 2
Training loss: 0.4023945927619934
Validation loss: 1.8067986939543037

Epoch: 5| Step: 3
Training loss: 0.3910474181175232
Validation loss: 1.8111346011520715

Epoch: 5| Step: 4
Training loss: 0.8405618667602539
Validation loss: 1.7931685422056465

Epoch: 5| Step: 5
Training loss: 0.6254773736000061
Validation loss: 1.8195323662091327

Epoch: 5| Step: 6
Training loss: 0.563453733921051
Validation loss: 1.8034147139518493

Epoch: 5| Step: 7
Training loss: 0.5991204977035522
Validation loss: 1.8459984371739049

Epoch: 5| Step: 8
Training loss: 0.22349898517131805
Validation loss: 1.8382933011618994

Epoch: 5| Step: 9
Training loss: 0.5225111842155457
Validation loss: 1.8489306485781105

Epoch: 5| Step: 10
Training loss: 0.7067884802818298
Validation loss: 1.8611759716464626

Epoch: 301| Step: 0
Training loss: 0.4557840824127197
Validation loss: 1.847132622554738

Epoch: 5| Step: 1
Training loss: 0.17104290425777435
Validation loss: 1.8306946190454627

Epoch: 5| Step: 2
Training loss: 0.5705960392951965
Validation loss: 1.825199577116197

Epoch: 5| Step: 3
Training loss: 0.7203157544136047
Validation loss: 1.845117429251312

Epoch: 5| Step: 4
Training loss: 0.5032576322555542
Validation loss: 1.8656972172439739

Epoch: 5| Step: 5
Training loss: 0.6467811465263367
Validation loss: 1.866134544854523

Epoch: 5| Step: 6
Training loss: 0.7207149267196655
Validation loss: 1.873663676682339

Epoch: 5| Step: 7
Training loss: 0.7723401784896851
Validation loss: 1.8884458670052149

Epoch: 5| Step: 8
Training loss: 0.446380615234375
Validation loss: 1.8549068358636671

Epoch: 5| Step: 9
Training loss: 0.5528374314308167
Validation loss: 1.860050437270954

Epoch: 5| Step: 10
Training loss: 0.32492950558662415
Validation loss: 1.857245824670279

Epoch: 302| Step: 0
Training loss: 0.6479746103286743
Validation loss: 1.8532561332948747

Epoch: 5| Step: 1
Training loss: 0.30576086044311523
Validation loss: 1.781430890483241

Epoch: 5| Step: 2
Training loss: 0.6073848605155945
Validation loss: 1.7845095178132415

Epoch: 5| Step: 3
Training loss: 0.4474422335624695
Validation loss: 1.7669552090347453

Epoch: 5| Step: 4
Training loss: 0.46111002564430237
Validation loss: 1.7376217367828533

Epoch: 5| Step: 5
Training loss: 0.5279535055160522
Validation loss: 1.7396827256807716

Epoch: 5| Step: 6
Training loss: 0.7025707960128784
Validation loss: 1.7878041664759319

Epoch: 5| Step: 7
Training loss: 0.839796245098114
Validation loss: 1.832646518625239

Epoch: 5| Step: 8
Training loss: 0.9320365786552429
Validation loss: 1.8521098795757498

Epoch: 5| Step: 9
Training loss: 0.4456019401550293
Validation loss: 1.8705647401912238

Epoch: 5| Step: 10
Training loss: 0.32792237401008606
Validation loss: 1.85169630922297

Epoch: 303| Step: 0
Training loss: 0.5066924095153809
Validation loss: 1.8358973508240075

Epoch: 5| Step: 1
Training loss: 0.4750279486179352
Validation loss: 1.8554421368465628

Epoch: 5| Step: 2
Training loss: 0.4718555510044098
Validation loss: 1.8322209850434334

Epoch: 5| Step: 3
Training loss: 0.6418975591659546
Validation loss: 1.8276724059094664

Epoch: 5| Step: 4
Training loss: 0.3089134693145752
Validation loss: 1.8164031172311434

Epoch: 5| Step: 5
Training loss: 0.6339668035507202
Validation loss: 1.8518476076023553

Epoch: 5| Step: 6
Training loss: 0.7513730525970459
Validation loss: 1.8643136037293302

Epoch: 5| Step: 7
Training loss: 0.43986135721206665
Validation loss: 1.8501136866948937

Epoch: 5| Step: 8
Training loss: 0.8705031275749207
Validation loss: 1.8894997412158596

Epoch: 5| Step: 9
Training loss: 0.45033055543899536
Validation loss: 1.908262163080195

Epoch: 5| Step: 10
Training loss: 0.37288960814476013
Validation loss: 1.8801420939865934

Epoch: 304| Step: 0
Training loss: 0.6588565707206726
Validation loss: 1.8623817736102688

Epoch: 5| Step: 1
Training loss: 0.2022431641817093
Validation loss: 1.841603599568849

Epoch: 5| Step: 2
Training loss: 0.3902275860309601
Validation loss: 1.8206487368511897

Epoch: 5| Step: 3
Training loss: 0.5229865908622742
Validation loss: 1.7965005418305755

Epoch: 5| Step: 4
Training loss: 0.40787473320961
Validation loss: 1.7984700984852289

Epoch: 5| Step: 5
Training loss: 0.42880478501319885
Validation loss: 1.7901001591836252

Epoch: 5| Step: 6
Training loss: 0.47026053071022034
Validation loss: 1.7968284865861297

Epoch: 5| Step: 7
Training loss: 0.6858575344085693
Validation loss: 1.7954628672651065

Epoch: 5| Step: 8
Training loss: 0.915327250957489
Validation loss: 1.7976410606855988

Epoch: 5| Step: 9
Training loss: 0.46873459219932556
Validation loss: 1.8122822225734752

Epoch: 5| Step: 10
Training loss: 0.457973450422287
Validation loss: 1.8081423774842293

Epoch: 305| Step: 0
Training loss: 0.7875663042068481
Validation loss: 1.825562588630184

Epoch: 5| Step: 1
Training loss: 0.5400799512863159
Validation loss: 1.8245041075573172

Epoch: 5| Step: 2
Training loss: 0.37221086025238037
Validation loss: 1.8185334635037247

Epoch: 5| Step: 3
Training loss: 0.4306160807609558
Validation loss: 1.8066870422773464

Epoch: 5| Step: 4
Training loss: 0.2699070870876312
Validation loss: 1.8482226492256246

Epoch: 5| Step: 5
Training loss: 0.4089067578315735
Validation loss: 1.8283299784506521

Epoch: 5| Step: 6
Training loss: 0.4353969693183899
Validation loss: 1.8188471204491072

Epoch: 5| Step: 7
Training loss: 0.6574941873550415
Validation loss: 1.8410068083834905

Epoch: 5| Step: 8
Training loss: 0.45463091135025024
Validation loss: 1.8426287046042822

Epoch: 5| Step: 9
Training loss: 0.40877336263656616
Validation loss: 1.829470185823338

Epoch: 5| Step: 10
Training loss: 0.6934186220169067
Validation loss: 1.8306771106617425

Epoch: 306| Step: 0
Training loss: 0.363384872674942
Validation loss: 1.8376842442379202

Epoch: 5| Step: 1
Training loss: 0.6959909200668335
Validation loss: 1.8419079665214784

Epoch: 5| Step: 2
Training loss: 0.34710001945495605
Validation loss: 1.810796086506177

Epoch: 5| Step: 3
Training loss: 0.6508567929267883
Validation loss: 1.83526946139592

Epoch: 5| Step: 4
Training loss: 0.6401697993278503
Validation loss: 1.8704680306937105

Epoch: 5| Step: 5
Training loss: 0.43444615602493286
Validation loss: 1.8465424840168287

Epoch: 5| Step: 6
Training loss: 0.48824891448020935
Validation loss: 1.8033969171585575

Epoch: 5| Step: 7
Training loss: 0.5468916893005371
Validation loss: 1.8138879678582633

Epoch: 5| Step: 8
Training loss: 0.15947815775871277
Validation loss: 1.8135187241338915

Epoch: 5| Step: 9
Training loss: 0.5225614905357361
Validation loss: 1.7923954045900734

Epoch: 5| Step: 10
Training loss: 0.4759036898612976
Validation loss: 1.814906043391074

Epoch: 307| Step: 0
Training loss: 0.45170801877975464
Validation loss: 1.808208643749196

Epoch: 5| Step: 1
Training loss: 0.4522605836391449
Validation loss: 1.8152618920931252

Epoch: 5| Step: 2
Training loss: 0.5758519172668457
Validation loss: 1.8044269213112452

Epoch: 5| Step: 3
Training loss: 0.3292355239391327
Validation loss: 1.7836710099251039

Epoch: 5| Step: 4
Training loss: 0.24671943485736847
Validation loss: 1.8008554174054054

Epoch: 5| Step: 5
Training loss: 0.5374549627304077
Validation loss: 1.7607824212761336

Epoch: 5| Step: 6
Training loss: 0.8495817184448242
Validation loss: 1.8103544378793368

Epoch: 5| Step: 7
Training loss: 0.3736956715583801
Validation loss: 1.8388423765859296

Epoch: 5| Step: 8
Training loss: 0.682499349117279
Validation loss: 1.8618520921276462

Epoch: 5| Step: 9
Training loss: 0.5504619479179382
Validation loss: 1.814299621889668

Epoch: 5| Step: 10
Training loss: 0.48648738861083984
Validation loss: 1.7739325364430745

Epoch: 308| Step: 0
Training loss: 0.25996464490890503
Validation loss: 1.7762262872470322

Epoch: 5| Step: 1
Training loss: 0.3196027874946594
Validation loss: 1.761884827767649

Epoch: 5| Step: 2
Training loss: 0.746334433555603
Validation loss: 1.7483354999173073

Epoch: 5| Step: 3
Training loss: 0.7049616575241089
Validation loss: 1.7576868572542745

Epoch: 5| Step: 4
Training loss: 0.3928958773612976
Validation loss: 1.7964007200733307

Epoch: 5| Step: 5
Training loss: 0.6936158537864685
Validation loss: 1.8061287915834816

Epoch: 5| Step: 6
Training loss: 0.3219278156757355
Validation loss: 1.8633498440506637

Epoch: 5| Step: 7
Training loss: 0.39099186658859253
Validation loss: 1.8959221429722284

Epoch: 5| Step: 8
Training loss: 0.965154767036438
Validation loss: 1.8870402946267077

Epoch: 5| Step: 9
Training loss: 0.28191184997558594
Validation loss: 1.93735457235767

Epoch: 5| Step: 10
Training loss: 0.4489721655845642
Validation loss: 1.909807235963883

Epoch: 309| Step: 0
Training loss: 0.3664982318878174
Validation loss: 1.890999404332971

Epoch: 5| Step: 1
Training loss: 0.50956791639328
Validation loss: 1.8554261781836068

Epoch: 5| Step: 2
Training loss: 0.5807802081108093
Validation loss: 1.8523974662185998

Epoch: 5| Step: 3
Training loss: 0.6241012811660767
Validation loss: 1.8399556272773332

Epoch: 5| Step: 4
Training loss: 0.4944034218788147
Validation loss: 1.8110479988077635

Epoch: 5| Step: 5
Training loss: 0.6257603168487549
Validation loss: 1.8098627034054007

Epoch: 5| Step: 6
Training loss: 0.8461402058601379
Validation loss: 1.801927758801368

Epoch: 5| Step: 7
Training loss: 0.32141125202178955
Validation loss: 1.7860638428759832

Epoch: 5| Step: 8
Training loss: 0.42704978585243225
Validation loss: 1.7769549854340092

Epoch: 5| Step: 9
Training loss: 0.3160395920276642
Validation loss: 1.8380431539268904

Epoch: 5| Step: 10
Training loss: 0.5804132223129272
Validation loss: 1.894814464353746

Epoch: 310| Step: 0
Training loss: 0.4716664254665375
Validation loss: 1.9263948676406697

Epoch: 5| Step: 1
Training loss: 0.413554847240448
Validation loss: 1.900261144484243

Epoch: 5| Step: 2
Training loss: 0.8920978307723999
Validation loss: 1.825708734091892

Epoch: 5| Step: 3
Training loss: 0.9641499519348145
Validation loss: 1.780552557719651

Epoch: 5| Step: 4
Training loss: 0.3027118146419525
Validation loss: 1.7523579123199626

Epoch: 5| Step: 5
Training loss: 0.25759586691856384
Validation loss: 1.7737923681095082

Epoch: 5| Step: 6
Training loss: 0.35055840015411377
Validation loss: 1.769778569539388

Epoch: 5| Step: 7
Training loss: 0.664655327796936
Validation loss: 1.7934141966604418

Epoch: 5| Step: 8
Training loss: 0.3641325533390045
Validation loss: 1.818915646563294

Epoch: 5| Step: 9
Training loss: 0.6484667658805847
Validation loss: 1.8095545256009666

Epoch: 5| Step: 10
Training loss: 0.3857647180557251
Validation loss: 1.8227452129446051

Epoch: 311| Step: 0
Training loss: 0.2560182511806488
Validation loss: 1.7989266841642317

Epoch: 5| Step: 1
Training loss: 0.6300365924835205
Validation loss: 1.7811805202114968

Epoch: 5| Step: 2
Training loss: 0.4321216642856598
Validation loss: 1.8040046717530938

Epoch: 5| Step: 3
Training loss: 0.3136809766292572
Validation loss: 1.802592921000655

Epoch: 5| Step: 4
Training loss: 0.16210819780826569
Validation loss: 1.8216276514914729

Epoch: 5| Step: 5
Training loss: 0.548854410648346
Validation loss: 1.8385712920978505

Epoch: 5| Step: 6
Training loss: 0.6036100387573242
Validation loss: 1.8482590811226958

Epoch: 5| Step: 7
Training loss: 0.44119223952293396
Validation loss: 1.8559619329308952

Epoch: 5| Step: 8
Training loss: 0.7195836305618286
Validation loss: 1.8358460152021019

Epoch: 5| Step: 9
Training loss: 0.5466374754905701
Validation loss: 1.8602324916470436

Epoch: 5| Step: 10
Training loss: 0.8206608891487122
Validation loss: 1.8450199762980144

Epoch: 312| Step: 0
Training loss: 0.7228512763977051
Validation loss: 1.82537131796601

Epoch: 5| Step: 1
Training loss: 0.46799033880233765
Validation loss: 1.811293525080527

Epoch: 5| Step: 2
Training loss: 0.3189460337162018
Validation loss: 1.795700427024595

Epoch: 5| Step: 3
Training loss: 0.5329617261886597
Validation loss: 1.802620808283488

Epoch: 5| Step: 4
Training loss: 0.7317360639572144
Validation loss: 1.7722186580781014

Epoch: 5| Step: 5
Training loss: 0.3431256413459778
Validation loss: 1.7774125683692195

Epoch: 5| Step: 6
Training loss: 0.46871957182884216
Validation loss: 1.8006755510965984

Epoch: 5| Step: 7
Training loss: 0.34079164266586304
Validation loss: 1.787224095354798

Epoch: 5| Step: 8
Training loss: 0.18809741735458374
Validation loss: 1.8104415426972091

Epoch: 5| Step: 9
Training loss: 0.44612646102905273
Validation loss: 1.8108905028271418

Epoch: 5| Step: 10
Training loss: 0.39345335960388184
Validation loss: 1.7815287677190637

Epoch: 313| Step: 0
Training loss: 0.3936223089694977
Validation loss: 1.7765255666548205

Epoch: 5| Step: 1
Training loss: 0.47486773133277893
Validation loss: 1.7634681322241341

Epoch: 5| Step: 2
Training loss: 0.42026978731155396
Validation loss: 1.7528729131144862

Epoch: 5| Step: 3
Training loss: 0.3864665627479553
Validation loss: 1.7632398554073867

Epoch: 5| Step: 4
Training loss: 0.6638296842575073
Validation loss: 1.756864059355951

Epoch: 5| Step: 5
Training loss: 0.3345966935157776
Validation loss: 1.7712636019593926

Epoch: 5| Step: 6
Training loss: 0.7663934826850891
Validation loss: 1.7861514834947483

Epoch: 5| Step: 7
Training loss: 0.2602296769618988
Validation loss: 1.7860651810963948

Epoch: 5| Step: 8
Training loss: 0.4979327321052551
Validation loss: 1.8109847371296217

Epoch: 5| Step: 9
Training loss: 0.4701090455055237
Validation loss: 1.7798338064583399

Epoch: 5| Step: 10
Training loss: 0.48536086082458496
Validation loss: 1.7779155995256157

Epoch: 314| Step: 0
Training loss: 0.7757101655006409
Validation loss: 1.7814974643850838

Epoch: 5| Step: 1
Training loss: 0.35369381308555603
Validation loss: 1.7935675779978435

Epoch: 5| Step: 2
Training loss: 0.35708189010620117
Validation loss: 1.815806883637623

Epoch: 5| Step: 3
Training loss: 0.31789854168891907
Validation loss: 1.812764790750319

Epoch: 5| Step: 4
Training loss: 0.6578071117401123
Validation loss: 1.7826334532871042

Epoch: 5| Step: 5
Training loss: 0.4394504427909851
Validation loss: 1.7935898714168097

Epoch: 5| Step: 6
Training loss: 0.6118210554122925
Validation loss: 1.7718306049223869

Epoch: 5| Step: 7
Training loss: 0.29608869552612305
Validation loss: 1.7576421973525838

Epoch: 5| Step: 8
Training loss: 0.2900391221046448
Validation loss: 1.7436616920655774

Epoch: 5| Step: 9
Training loss: 0.36505332589149475
Validation loss: 1.7732138223545526

Epoch: 5| Step: 10
Training loss: 0.4102862477302551
Validation loss: 1.7850475721461798

Epoch: 315| Step: 0
Training loss: 0.27601417899131775
Validation loss: 1.8231947780937277

Epoch: 5| Step: 1
Training loss: 0.7696816325187683
Validation loss: 1.8402049374836746

Epoch: 5| Step: 2
Training loss: 0.460711807012558
Validation loss: 1.7914063417783348

Epoch: 5| Step: 3
Training loss: 0.7470037341117859
Validation loss: 1.751548892708235

Epoch: 5| Step: 4
Training loss: 0.5047276616096497
Validation loss: 1.741524334876768

Epoch: 5| Step: 5
Training loss: 0.3346218764781952
Validation loss: 1.749905933615982

Epoch: 5| Step: 6
Training loss: 0.27064400911331177
Validation loss: 1.7425315175005185

Epoch: 5| Step: 7
Training loss: 0.3746192455291748
Validation loss: 1.7552172317299792

Epoch: 5| Step: 8
Training loss: 0.3839123845100403
Validation loss: 1.787205675596832

Epoch: 5| Step: 9
Training loss: 0.24409528076648712
Validation loss: 1.7875742232927712

Epoch: 5| Step: 10
Training loss: 0.8443872928619385
Validation loss: 1.7993125082344137

Epoch: 316| Step: 0
Training loss: 0.38027024269104004
Validation loss: 1.8564797703937819

Epoch: 5| Step: 1
Training loss: 0.4832684397697449
Validation loss: 1.835448488753329

Epoch: 5| Step: 2
Training loss: 0.4362598955631256
Validation loss: 1.8031962398559815

Epoch: 5| Step: 3
Training loss: 0.3329404592514038
Validation loss: 1.7937680713592037

Epoch: 5| Step: 4
Training loss: 0.49210673570632935
Validation loss: 1.7511482290042344

Epoch: 5| Step: 5
Training loss: 0.9127806425094604
Validation loss: 1.7185551530571395

Epoch: 5| Step: 6
Training loss: 0.38561439514160156
Validation loss: 1.7326421686398086

Epoch: 5| Step: 7
Training loss: 0.4752821922302246
Validation loss: 1.752242398518388

Epoch: 5| Step: 8
Training loss: 0.4177180230617523
Validation loss: 1.753759830228744

Epoch: 5| Step: 9
Training loss: 0.3481985926628113
Validation loss: 1.7755880560926212

Epoch: 5| Step: 10
Training loss: 0.6647281646728516
Validation loss: 1.779431022623534

Epoch: 317| Step: 0
Training loss: 0.3345886766910553
Validation loss: 1.8228220721726776

Epoch: 5| Step: 1
Training loss: 0.45825037360191345
Validation loss: 1.811504828032627

Epoch: 5| Step: 2
Training loss: 0.4629989564418793
Validation loss: 1.7935231501056301

Epoch: 5| Step: 3
Training loss: 0.5680583715438843
Validation loss: 1.8067426079063005

Epoch: 5| Step: 4
Training loss: 0.531591534614563
Validation loss: 1.7711478382028558

Epoch: 5| Step: 5
Training loss: 0.4056012034416199
Validation loss: 1.760667489420983

Epoch: 5| Step: 6
Training loss: 0.6517162919044495
Validation loss: 1.7632888029980403

Epoch: 5| Step: 7
Training loss: 0.3643576204776764
Validation loss: 1.750345940230995

Epoch: 5| Step: 8
Training loss: 0.30991941690444946
Validation loss: 1.7516499193765784

Epoch: 5| Step: 9
Training loss: 0.20330455899238586
Validation loss: 1.7718150525964715

Epoch: 5| Step: 10
Training loss: 0.4991607069969177
Validation loss: 1.7575629193295714

Epoch: 318| Step: 0
Training loss: 0.34391188621520996
Validation loss: 1.7681610789350284

Epoch: 5| Step: 1
Training loss: 0.4566655158996582
Validation loss: 1.7836815246971705

Epoch: 5| Step: 2
Training loss: 0.4880064129829407
Validation loss: 1.787290193701303

Epoch: 5| Step: 3
Training loss: 0.6784901022911072
Validation loss: 1.7573734355229202

Epoch: 5| Step: 4
Training loss: 0.40184539556503296
Validation loss: 1.7888273385263258

Epoch: 5| Step: 5
Training loss: 0.5906393527984619
Validation loss: 1.7811362410104403

Epoch: 5| Step: 6
Training loss: 0.4853195250034332
Validation loss: 1.7868014740687546

Epoch: 5| Step: 7
Training loss: 0.383990615606308
Validation loss: 1.80088222155007

Epoch: 5| Step: 8
Training loss: 0.4840509295463562
Validation loss: 1.8224556920348958

Epoch: 5| Step: 9
Training loss: 0.3855001926422119
Validation loss: 1.8374811539085962

Epoch: 5| Step: 10
Training loss: 0.29586708545684814
Validation loss: 1.827221767876738

Epoch: 319| Step: 0
Training loss: 0.4362349510192871
Validation loss: 1.7968559406136955

Epoch: 5| Step: 1
Training loss: 0.4002896845340729
Validation loss: 1.7813350282689577

Epoch: 5| Step: 2
Training loss: 0.3361404538154602
Validation loss: 1.7768336771636881

Epoch: 5| Step: 3
Training loss: 0.5366295576095581
Validation loss: 1.7845578142391738

Epoch: 5| Step: 4
Training loss: 0.4305710196495056
Validation loss: 1.756021402856355

Epoch: 5| Step: 5
Training loss: 0.28344422578811646
Validation loss: 1.7719447356398388

Epoch: 5| Step: 6
Training loss: 0.4548550248146057
Validation loss: 1.7779245658587384

Epoch: 5| Step: 7
Training loss: 0.48275431990623474
Validation loss: 1.793126788190616

Epoch: 5| Step: 8
Training loss: 0.33593687415122986
Validation loss: 1.8352584044138591

Epoch: 5| Step: 9
Training loss: 0.2957932949066162
Validation loss: 1.8330757848678096

Epoch: 5| Step: 10
Training loss: 0.8293192982673645
Validation loss: 1.816065651114269

Epoch: 320| Step: 0
Training loss: 0.4503074288368225
Validation loss: 1.7977257249175862

Epoch: 5| Step: 1
Training loss: 0.15476906299591064
Validation loss: 1.8206789519197197

Epoch: 5| Step: 2
Training loss: 0.33806830644607544
Validation loss: 1.7853718752502112

Epoch: 5| Step: 3
Training loss: 0.30113551020622253
Validation loss: 1.7957745123935003

Epoch: 5| Step: 4
Training loss: 0.5722254514694214
Validation loss: 1.8087757813033236

Epoch: 5| Step: 5
Training loss: 0.48555493354797363
Validation loss: 1.7820180782707788

Epoch: 5| Step: 6
Training loss: 0.6533972024917603
Validation loss: 1.773626942788401

Epoch: 5| Step: 7
Training loss: 0.42606696486473083
Validation loss: 1.7791565964298863

Epoch: 5| Step: 8
Training loss: 0.43184715509414673
Validation loss: 1.7412385838006132

Epoch: 5| Step: 9
Training loss: 0.4598314166069031
Validation loss: 1.7604493812848163

Epoch: 5| Step: 10
Training loss: 0.4398435354232788
Validation loss: 1.773431392126186

Epoch: 321| Step: 0
Training loss: 0.44600600004196167
Validation loss: 1.7480389328413113

Epoch: 5| Step: 1
Training loss: 0.474977970123291
Validation loss: 1.7805146555746756

Epoch: 5| Step: 2
Training loss: 0.6111686825752258
Validation loss: 1.7941596482389717

Epoch: 5| Step: 3
Training loss: 0.2190881073474884
Validation loss: 1.7846619480399675

Epoch: 5| Step: 4
Training loss: 0.5774328708648682
Validation loss: 1.783198070782487

Epoch: 5| Step: 5
Training loss: 0.33052530884742737
Validation loss: 1.7750071825519684

Epoch: 5| Step: 6
Training loss: 0.4009569585323334
Validation loss: 1.8054960594382337

Epoch: 5| Step: 7
Training loss: 0.17905659973621368
Validation loss: 1.7855686615872126

Epoch: 5| Step: 8
Training loss: 0.6834894418716431
Validation loss: 1.782481481952052

Epoch: 5| Step: 9
Training loss: 0.3862174153327942
Validation loss: 1.7805629340551232

Epoch: 5| Step: 10
Training loss: 0.2704756259918213
Validation loss: 1.8056967078998525

Epoch: 322| Step: 0
Training loss: 0.6067317128181458
Validation loss: 1.8023453745790707

Epoch: 5| Step: 1
Training loss: 0.43581151962280273
Validation loss: 1.8396025678162933

Epoch: 5| Step: 2
Training loss: 0.6077638268470764
Validation loss: 1.8576842482371996

Epoch: 5| Step: 3
Training loss: 0.45894670486450195
Validation loss: 1.8618010218425463

Epoch: 5| Step: 4
Training loss: 0.26477187871932983
Validation loss: 1.8472156575931016

Epoch: 5| Step: 5
Training loss: 0.39748093485832214
Validation loss: 1.8126839219882924

Epoch: 5| Step: 6
Training loss: 0.30531907081604004
Validation loss: 1.7755830544297413

Epoch: 5| Step: 7
Training loss: 0.5357061624526978
Validation loss: 1.753661096736949

Epoch: 5| Step: 8
Training loss: 0.3952552080154419
Validation loss: 1.762084645609702

Epoch: 5| Step: 9
Training loss: 0.46330851316452026
Validation loss: 1.7622117201487224

Epoch: 5| Step: 10
Training loss: 0.39187926054000854
Validation loss: 1.7562781277523245

Epoch: 323| Step: 0
Training loss: 0.4924464821815491
Validation loss: 1.7584161079058083

Epoch: 5| Step: 1
Training loss: 0.7015216946601868
Validation loss: 1.7659553058685795

Epoch: 5| Step: 2
Training loss: 0.23318438231945038
Validation loss: 1.8022994226024998

Epoch: 5| Step: 3
Training loss: 0.3594247102737427
Validation loss: 1.792965172439493

Epoch: 5| Step: 4
Training loss: 0.18457284569740295
Validation loss: 1.7819736664013197

Epoch: 5| Step: 5
Training loss: 0.4508836269378662
Validation loss: 1.8236337348979006

Epoch: 5| Step: 6
Training loss: 0.6572741270065308
Validation loss: 1.8130038220395324

Epoch: 5| Step: 7
Training loss: 0.2170144021511078
Validation loss: 1.8025418122609456

Epoch: 5| Step: 8
Training loss: 0.3772786855697632
Validation loss: 1.802193251989221

Epoch: 5| Step: 9
Training loss: 0.4889877736568451
Validation loss: 1.7738642846384356

Epoch: 5| Step: 10
Training loss: 0.3996048867702484
Validation loss: 1.792119529939467

Epoch: 324| Step: 0
Training loss: 0.47704726457595825
Validation loss: 1.7690687230838242

Epoch: 5| Step: 1
Training loss: 0.4140063226222992
Validation loss: 1.7513791373980943

Epoch: 5| Step: 2
Training loss: 0.8607420921325684
Validation loss: 1.7571965238099456

Epoch: 5| Step: 3
Training loss: 0.37198251485824585
Validation loss: 1.7559731096349738

Epoch: 5| Step: 4
Training loss: 0.3746832311153412
Validation loss: 1.7456082259455035

Epoch: 5| Step: 5
Training loss: 0.22858038544654846
Validation loss: 1.7649686772336242

Epoch: 5| Step: 6
Training loss: 0.3528619110584259
Validation loss: 1.7833890427825272

Epoch: 5| Step: 7
Training loss: 0.3597390055656433
Validation loss: 1.7936284439538115

Epoch: 5| Step: 8
Training loss: 0.23142032325267792
Validation loss: 1.7568665576237503

Epoch: 5| Step: 9
Training loss: 0.34766775369644165
Validation loss: 1.7615035990233063

Epoch: 5| Step: 10
Training loss: 0.44990038871765137
Validation loss: 1.7623781004259664

Epoch: 325| Step: 0
Training loss: 0.2156641036272049
Validation loss: 1.7797824477636686

Epoch: 5| Step: 1
Training loss: 0.2532499432563782
Validation loss: 1.7376027440512052

Epoch: 5| Step: 2
Training loss: 0.5910874605178833
Validation loss: 1.7756607660683252

Epoch: 5| Step: 3
Training loss: 0.30025798082351685
Validation loss: 1.7961686734230287

Epoch: 5| Step: 4
Training loss: 0.3811829090118408
Validation loss: 1.821131621637652

Epoch: 5| Step: 5
Training loss: 0.7557259798049927
Validation loss: 1.8099674614526893

Epoch: 5| Step: 6
Training loss: 0.3295203745365143
Validation loss: 1.8159290872594362

Epoch: 5| Step: 7
Training loss: 0.4024811387062073
Validation loss: 1.7952773801742061

Epoch: 5| Step: 8
Training loss: 0.3436145484447479
Validation loss: 1.7829165638134044

Epoch: 5| Step: 9
Training loss: 0.5205024480819702
Validation loss: 1.7727609629272132

Epoch: 5| Step: 10
Training loss: 0.42724502086639404
Validation loss: 1.7856629202442784

Epoch: 326| Step: 0
Training loss: 0.46091586351394653
Validation loss: 1.7755097035438783

Epoch: 5| Step: 1
Training loss: 0.5153454542160034
Validation loss: 1.7704682568068146

Epoch: 5| Step: 2
Training loss: 0.4321952760219574
Validation loss: 1.7979614157830515

Epoch: 5| Step: 3
Training loss: 0.2215850055217743
Validation loss: 1.7840329947010163

Epoch: 5| Step: 4
Training loss: 0.49442967772483826
Validation loss: 1.7988503671461535

Epoch: 5| Step: 5
Training loss: 0.38178470730781555
Validation loss: 1.785125514512421

Epoch: 5| Step: 6
Training loss: 0.37990841269493103
Validation loss: 1.793557777199694

Epoch: 5| Step: 7
Training loss: 0.2840688228607178
Validation loss: 1.7955130415578042

Epoch: 5| Step: 8
Training loss: 0.3430136442184448
Validation loss: 1.7968563366961736

Epoch: 5| Step: 9
Training loss: 0.4347290098667145
Validation loss: 1.7958042185793641

Epoch: 5| Step: 10
Training loss: 0.4735007584095001
Validation loss: 1.7844107586850402

Epoch: 327| Step: 0
Training loss: 0.4621421694755554
Validation loss: 1.7877794286256194

Epoch: 5| Step: 1
Training loss: 0.426386296749115
Validation loss: 1.7885681467671548

Epoch: 5| Step: 2
Training loss: 0.5209867358207703
Validation loss: 1.7685317723981795

Epoch: 5| Step: 3
Training loss: 0.19448992609977722
Validation loss: 1.7601854314086258

Epoch: 5| Step: 4
Training loss: 0.3512009084224701
Validation loss: 1.7741677812350694

Epoch: 5| Step: 5
Training loss: 0.20904092490673065
Validation loss: 1.7550251958190755

Epoch: 5| Step: 6
Training loss: 0.588512122631073
Validation loss: 1.7812536031969133

Epoch: 5| Step: 7
Training loss: 0.4645484983921051
Validation loss: 1.790961742401123

Epoch: 5| Step: 8
Training loss: 0.2511686682701111
Validation loss: 1.8454837709344842

Epoch: 5| Step: 9
Training loss: 0.3850276470184326
Validation loss: 1.8487419159181657

Epoch: 5| Step: 10
Training loss: 0.5677852630615234
Validation loss: 1.8665321616716282

Epoch: 328| Step: 0
Training loss: 0.501395583152771
Validation loss: 1.8232036809767447

Epoch: 5| Step: 1
Training loss: 0.4859834611415863
Validation loss: 1.7936734179014802

Epoch: 5| Step: 2
Training loss: 0.43668031692504883
Validation loss: 1.7931239322949482

Epoch: 5| Step: 3
Training loss: 0.5449600219726562
Validation loss: 1.7857108782696467

Epoch: 5| Step: 4
Training loss: 0.4184519648551941
Validation loss: 1.7776046344029006

Epoch: 5| Step: 5
Training loss: 0.4426340162754059
Validation loss: 1.7775449150352067

Epoch: 5| Step: 6
Training loss: 0.30487093329429626
Validation loss: 1.7728044115087038

Epoch: 5| Step: 7
Training loss: 0.22986188530921936
Validation loss: 1.776079713657338

Epoch: 5| Step: 8
Training loss: 0.5827118754386902
Validation loss: 1.8018848024388796

Epoch: 5| Step: 9
Training loss: 0.3798690438270569
Validation loss: 1.8008844826811103

Epoch: 5| Step: 10
Training loss: 0.3501916229724884
Validation loss: 1.78106261837867

Epoch: 329| Step: 0
Training loss: 0.28693637251853943
Validation loss: 1.7756434717485983

Epoch: 5| Step: 1
Training loss: 0.3750332295894623
Validation loss: 1.7885457636207662

Epoch: 5| Step: 2
Training loss: 0.5467850565910339
Validation loss: 1.7769807320769115

Epoch: 5| Step: 3
Training loss: 0.2783818244934082
Validation loss: 1.7654989624536166

Epoch: 5| Step: 4
Training loss: 0.4567832946777344
Validation loss: 1.7661255303249563

Epoch: 5| Step: 5
Training loss: 0.3076104521751404
Validation loss: 1.812710419777901

Epoch: 5| Step: 6
Training loss: 0.7655848860740662
Validation loss: 1.778046013206564

Epoch: 5| Step: 7
Training loss: 0.35764995217323303
Validation loss: 1.7795822774210284

Epoch: 5| Step: 8
Training loss: 0.31273403763771057
Validation loss: 1.7478627697114022

Epoch: 5| Step: 9
Training loss: 0.324563205242157
Validation loss: 1.750059723854065

Epoch: 5| Step: 10
Training loss: 0.3719452917575836
Validation loss: 1.728928493556156

Epoch: 330| Step: 0
Training loss: 0.20614445209503174
Validation loss: 1.7523845472643453

Epoch: 5| Step: 1
Training loss: 0.3484988212585449
Validation loss: 1.7520031313742361

Epoch: 5| Step: 2
Training loss: 0.4237993657588959
Validation loss: 1.7455450796311902

Epoch: 5| Step: 3
Training loss: 0.158163383603096
Validation loss: 1.7623498414152412

Epoch: 5| Step: 4
Training loss: 0.40888509154319763
Validation loss: 1.7954905481748684

Epoch: 5| Step: 5
Training loss: 0.5427767038345337
Validation loss: 1.8105470531730241

Epoch: 5| Step: 6
Training loss: 0.543887734413147
Validation loss: 1.8187729306118463

Epoch: 5| Step: 7
Training loss: 0.21716587245464325
Validation loss: 1.8038439276397868

Epoch: 5| Step: 8
Training loss: 0.32803091406822205
Validation loss: 1.7710968794361237

Epoch: 5| Step: 9
Training loss: 0.694912850856781
Validation loss: 1.7556573678088445

Epoch: 5| Step: 10
Training loss: 0.647158145904541
Validation loss: 1.7368590831756592

Epoch: 331| Step: 0
Training loss: 0.33899539709091187
Validation loss: 1.7420247908561461

Epoch: 5| Step: 1
Training loss: 0.3864910900592804
Validation loss: 1.7513775338408768

Epoch: 5| Step: 2
Training loss: 0.3900284469127655
Validation loss: 1.7663516985472811

Epoch: 5| Step: 3
Training loss: 0.26494377851486206
Validation loss: 1.7982566497659171

Epoch: 5| Step: 4
Training loss: 0.2972145676612854
Validation loss: 1.8056731044605214

Epoch: 5| Step: 5
Training loss: 0.4253086447715759
Validation loss: 1.857202273543163

Epoch: 5| Step: 6
Training loss: 0.6153371930122375
Validation loss: 1.8840534840860674

Epoch: 5| Step: 7
Training loss: 0.44518962502479553
Validation loss: 1.8957782855597876

Epoch: 5| Step: 8
Training loss: 0.5473751425743103
Validation loss: 1.8516561895288446

Epoch: 5| Step: 9
Training loss: 0.39401865005493164
Validation loss: 1.8233028458010765

Epoch: 5| Step: 10
Training loss: 0.5005112886428833
Validation loss: 1.78794660106782

Epoch: 332| Step: 0
Training loss: 0.41680651903152466
Validation loss: 1.7791041533152263

Epoch: 5| Step: 1
Training loss: 0.2746461033821106
Validation loss: 1.7701189697429698

Epoch: 5| Step: 2
Training loss: 0.4116474688053131
Validation loss: 1.7563813386424896

Epoch: 5| Step: 3
Training loss: 0.5726576447486877
Validation loss: 1.7320396989904425

Epoch: 5| Step: 4
Training loss: 0.3774028420448303
Validation loss: 1.7521636101507372

Epoch: 5| Step: 5
Training loss: 0.24122563004493713
Validation loss: 1.7875324961959675

Epoch: 5| Step: 6
Training loss: 0.5294522047042847
Validation loss: 1.8368464259691135

Epoch: 5| Step: 7
Training loss: 0.35012298822402954
Validation loss: 1.8429569531512517

Epoch: 5| Step: 8
Training loss: 0.32995104789733887
Validation loss: 1.8530315750388688

Epoch: 5| Step: 9
Training loss: 0.33947569131851196
Validation loss: 1.8387040322826755

Epoch: 5| Step: 10
Training loss: 0.6568169593811035
Validation loss: 1.819570629827438

Epoch: 333| Step: 0
Training loss: 0.3163115978240967
Validation loss: 1.8154024949637793

Epoch: 5| Step: 1
Training loss: 0.46517905592918396
Validation loss: 1.780947583977894

Epoch: 5| Step: 2
Training loss: 0.20472614467144012
Validation loss: 1.7659827201597151

Epoch: 5| Step: 3
Training loss: 0.3093339502811432
Validation loss: 1.7724418627318514

Epoch: 5| Step: 4
Training loss: 0.4569515287876129
Validation loss: 1.7785938965376986

Epoch: 5| Step: 5
Training loss: 0.268312931060791
Validation loss: 1.7838829896783317

Epoch: 5| Step: 6
Training loss: 0.5161374807357788
Validation loss: 1.7628329159111105

Epoch: 5| Step: 7
Training loss: 0.5481833815574646
Validation loss: 1.8033904901114843

Epoch: 5| Step: 8
Training loss: 0.39118582010269165
Validation loss: 1.7794471915050218

Epoch: 5| Step: 9
Training loss: 0.30542293190956116
Validation loss: 1.7854136946380779

Epoch: 5| Step: 10
Training loss: 0.31736817955970764
Validation loss: 1.7901840158688125

Epoch: 334| Step: 0
Training loss: 0.3439626097679138
Validation loss: 1.7800793570856894

Epoch: 5| Step: 1
Training loss: 0.4610942006111145
Validation loss: 1.7874981857115222

Epoch: 5| Step: 2
Training loss: 0.27576327323913574
Validation loss: 1.7742200384857834

Epoch: 5| Step: 3
Training loss: 0.25921401381492615
Validation loss: 1.7663315829410349

Epoch: 5| Step: 4
Training loss: 0.736021876335144
Validation loss: 1.7473636058069044

Epoch: 5| Step: 5
Training loss: 0.4061950147151947
Validation loss: 1.7363457590021112

Epoch: 5| Step: 6
Training loss: 0.45993098616600037
Validation loss: 1.7403251727422078

Epoch: 5| Step: 7
Training loss: 0.30365291237831116
Validation loss: 1.758749968262129

Epoch: 5| Step: 8
Training loss: 0.36373481154441833
Validation loss: 1.7474041036380235

Epoch: 5| Step: 9
Training loss: 0.33041858673095703
Validation loss: 1.7471304375638244

Epoch: 5| Step: 10
Training loss: 0.23905818164348602
Validation loss: 1.7503789445405364

Epoch: 335| Step: 0
Training loss: 0.31265169382095337
Validation loss: 1.7578868942876016

Epoch: 5| Step: 1
Training loss: 0.4460884630680084
Validation loss: 1.775887567509887

Epoch: 5| Step: 2
Training loss: 0.43116384744644165
Validation loss: 1.760809095956946

Epoch: 5| Step: 3
Training loss: 0.3010699152946472
Validation loss: 1.783853833393384

Epoch: 5| Step: 4
Training loss: 0.22521190345287323
Validation loss: 1.7779489999176354

Epoch: 5| Step: 5
Training loss: 0.4604119658470154
Validation loss: 1.7617932955423992

Epoch: 5| Step: 6
Training loss: 0.2849852442741394
Validation loss: 1.762805700302124

Epoch: 5| Step: 7
Training loss: 0.2368202954530716
Validation loss: 1.7762156635202386

Epoch: 5| Step: 8
Training loss: 0.4117167592048645
Validation loss: 1.8161783474747852

Epoch: 5| Step: 9
Training loss: 0.3621301054954529
Validation loss: 1.8497081264372794

Epoch: 5| Step: 10
Training loss: 0.9414811134338379
Validation loss: 1.8887983727198776

Epoch: 336| Step: 0
Training loss: 0.37939217686653137
Validation loss: 1.8563953573985765

Epoch: 5| Step: 1
Training loss: 0.5651140213012695
Validation loss: 1.8133495110337452

Epoch: 5| Step: 2
Training loss: 0.38518229126930237
Validation loss: 1.774934123921138

Epoch: 5| Step: 3
Training loss: 0.4315316081047058
Validation loss: 1.7318910655154978

Epoch: 5| Step: 4
Training loss: 0.29637521505355835
Validation loss: 1.7070148414181125

Epoch: 5| Step: 5
Training loss: 0.35033878684043884
Validation loss: 1.713656670303755

Epoch: 5| Step: 6
Training loss: 0.18403589725494385
Validation loss: 1.709828838225334

Epoch: 5| Step: 7
Training loss: 0.32738184928894043
Validation loss: 1.709733352866224

Epoch: 5| Step: 8
Training loss: 0.2618303894996643
Validation loss: 1.718817618585402

Epoch: 5| Step: 9
Training loss: 0.5245109796524048
Validation loss: 1.7556604621230916

Epoch: 5| Step: 10
Training loss: 0.5379972457885742
Validation loss: 1.795256632630543

Epoch: 337| Step: 0
Training loss: 0.4817296862602234
Validation loss: 1.8395224002099806

Epoch: 5| Step: 1
Training loss: 0.5342756509780884
Validation loss: 1.8379169574347876

Epoch: 5| Step: 2
Training loss: 0.4443741738796234
Validation loss: 1.821327570945986

Epoch: 5| Step: 3
Training loss: 0.5342316627502441
Validation loss: 1.7932089387729604

Epoch: 5| Step: 4
Training loss: 0.349819540977478
Validation loss: 1.7917907263642998

Epoch: 5| Step: 5
Training loss: 0.45234090089797974
Validation loss: 1.7538110607413835

Epoch: 5| Step: 6
Training loss: 0.48927682638168335
Validation loss: 1.7575961607758717

Epoch: 5| Step: 7
Training loss: 0.21025176346302032
Validation loss: 1.7505131729187504

Epoch: 5| Step: 8
Training loss: 0.29878926277160645
Validation loss: 1.7490769304255003

Epoch: 5| Step: 9
Training loss: 0.2535381615161896
Validation loss: 1.71740420146655

Epoch: 5| Step: 10
Training loss: 0.35939905047416687
Validation loss: 1.7436207225245814

Epoch: 338| Step: 0
Training loss: 0.49579644203186035
Validation loss: 1.731134412109211

Epoch: 5| Step: 1
Training loss: 0.42777305841445923
Validation loss: 1.7446203693266837

Epoch: 5| Step: 2
Training loss: 0.46835121512413025
Validation loss: 1.7376182335679249

Epoch: 5| Step: 3
Training loss: 0.22553518414497375
Validation loss: 1.7454257447232482

Epoch: 5| Step: 4
Training loss: 0.33121299743652344
Validation loss: 1.739360027415778

Epoch: 5| Step: 5
Training loss: 0.2588368058204651
Validation loss: 1.765758292649382

Epoch: 5| Step: 6
Training loss: 0.5187875032424927
Validation loss: 1.8249052288711711

Epoch: 5| Step: 7
Training loss: 0.2593613266944885
Validation loss: 1.8501142981231853

Epoch: 5| Step: 8
Training loss: 0.3855653405189514
Validation loss: 1.8584448214500182

Epoch: 5| Step: 9
Training loss: 0.28265610337257385
Validation loss: 1.8448463486086937

Epoch: 5| Step: 10
Training loss: 0.45778870582580566
Validation loss: 1.8368834116125619

Epoch: 339| Step: 0
Training loss: 0.5086677074432373
Validation loss: 1.8095305376155402

Epoch: 5| Step: 1
Training loss: 0.41172438859939575
Validation loss: 1.7850309559094009

Epoch: 5| Step: 2
Training loss: 0.2183256596326828
Validation loss: 1.7612754465431295

Epoch: 5| Step: 3
Training loss: 0.5150419473648071
Validation loss: 1.7292224309777702

Epoch: 5| Step: 4
Training loss: 0.4724086821079254
Validation loss: 1.7321074752397434

Epoch: 5| Step: 5
Training loss: 0.317436158657074
Validation loss: 1.7422777042594007

Epoch: 5| Step: 6
Training loss: 0.6037843823432922
Validation loss: 1.7771718604590303

Epoch: 5| Step: 7
Training loss: 0.1135636568069458
Validation loss: 1.7628881674940868

Epoch: 5| Step: 8
Training loss: 0.29356226325035095
Validation loss: 1.7968872618931595

Epoch: 5| Step: 9
Training loss: 0.41106241941452026
Validation loss: 1.7738922642123314

Epoch: 5| Step: 10
Training loss: 0.27301299571990967
Validation loss: 1.7860271687148719

Epoch: 340| Step: 0
Training loss: 0.4796168804168701
Validation loss: 1.7865100188921856

Epoch: 5| Step: 1
Training loss: 0.4262372851371765
Validation loss: 1.7637369171265633

Epoch: 5| Step: 2
Training loss: 0.287362277507782
Validation loss: 1.7490432595693937

Epoch: 5| Step: 3
Training loss: 0.15536144375801086
Validation loss: 1.747354656137446

Epoch: 5| Step: 4
Training loss: 0.5371831059455872
Validation loss: 1.7489251898181053

Epoch: 5| Step: 5
Training loss: 0.4844346046447754
Validation loss: 1.747765706431481

Epoch: 5| Step: 6
Training loss: 0.26996108889579773
Validation loss: 1.7638793863275999

Epoch: 5| Step: 7
Training loss: 0.3226206302642822
Validation loss: 1.7830865229329755

Epoch: 5| Step: 8
Training loss: 0.30709272623062134
Validation loss: 1.800082968127343

Epoch: 5| Step: 9
Training loss: 0.42953816056251526
Validation loss: 1.7915976714062434

Epoch: 5| Step: 10
Training loss: 0.18810655176639557
Validation loss: 1.7487883337082402

Epoch: 341| Step: 0
Training loss: 0.6527647972106934
Validation loss: 1.7342285417741345

Epoch: 5| Step: 1
Training loss: 0.5487189888954163
Validation loss: 1.6937492150132374

Epoch: 5| Step: 2
Training loss: 0.4173347055912018
Validation loss: 1.7078860985335482

Epoch: 5| Step: 3
Training loss: 0.14599129557609558
Validation loss: 1.6871931142704462

Epoch: 5| Step: 4
Training loss: 0.3911678194999695
Validation loss: 1.7050904227841286

Epoch: 5| Step: 5
Training loss: 0.21475207805633545
Validation loss: 1.6867061148407638

Epoch: 5| Step: 6
Training loss: 0.24251441657543182
Validation loss: 1.7120607014625304

Epoch: 5| Step: 7
Training loss: 0.4240504801273346
Validation loss: 1.7275751726601714

Epoch: 5| Step: 8
Training loss: 0.3274926245212555
Validation loss: 1.7582227453108756

Epoch: 5| Step: 9
Training loss: 0.30082935094833374
Validation loss: 1.77717056838415

Epoch: 5| Step: 10
Training loss: 0.33320650458335876
Validation loss: 1.7794783012841338

Epoch: 342| Step: 0
Training loss: 0.2674242854118347
Validation loss: 1.794942194415677

Epoch: 5| Step: 1
Training loss: 0.24359555542469025
Validation loss: 1.7846849656874133

Epoch: 5| Step: 2
Training loss: 0.6944760084152222
Validation loss: 1.7785965242693502

Epoch: 5| Step: 3
Training loss: 0.20074883103370667
Validation loss: 1.7585594192627938

Epoch: 5| Step: 4
Training loss: 0.19318978488445282
Validation loss: 1.7444157164583924

Epoch: 5| Step: 5
Training loss: 0.40234827995300293
Validation loss: 1.740045221902991

Epoch: 5| Step: 6
Training loss: 0.4477230906486511
Validation loss: 1.7355681978246218

Epoch: 5| Step: 7
Training loss: 0.38610705733299255
Validation loss: 1.747854471206665

Epoch: 5| Step: 8
Training loss: 0.44378432631492615
Validation loss: 1.7506941697930778

Epoch: 5| Step: 9
Training loss: 0.39404815435409546
Validation loss: 1.766305814507187

Epoch: 5| Step: 10
Training loss: 0.24575522541999817
Validation loss: 1.767658152887898

Epoch: 343| Step: 0
Training loss: 0.2034609019756317
Validation loss: 1.7954854785755117

Epoch: 5| Step: 1
Training loss: 0.6982771754264832
Validation loss: 1.7844666473327144

Epoch: 5| Step: 2
Training loss: 0.20271968841552734
Validation loss: 1.762867800651058

Epoch: 5| Step: 3
Training loss: 0.3470982015132904
Validation loss: 1.7454982085894513

Epoch: 5| Step: 4
Training loss: 0.2775871157646179
Validation loss: 1.7128629005083473

Epoch: 5| Step: 5
Training loss: 0.4693990647792816
Validation loss: 1.718794124100798

Epoch: 5| Step: 6
Training loss: 0.2543444037437439
Validation loss: 1.7297593470542663

Epoch: 5| Step: 7
Training loss: 0.3497334122657776
Validation loss: 1.7520012368438065

Epoch: 5| Step: 8
Training loss: 0.32274436950683594
Validation loss: 1.7570756994267946

Epoch: 5| Step: 9
Training loss: 0.3167611360549927
Validation loss: 1.7797097647061912

Epoch: 5| Step: 10
Training loss: 0.45644402503967285
Validation loss: 1.78655251508118

Epoch: 344| Step: 0
Training loss: 0.42700010538101196
Validation loss: 1.7875281944069812

Epoch: 5| Step: 1
Training loss: 0.5037664175033569
Validation loss: 1.7807749573902418

Epoch: 5| Step: 2
Training loss: 0.24340367317199707
Validation loss: 1.7803211250612814

Epoch: 5| Step: 3
Training loss: 0.38287267088890076
Validation loss: 1.748904440992622

Epoch: 5| Step: 4
Training loss: 0.24583125114440918
Validation loss: 1.7554510870287496

Epoch: 5| Step: 5
Training loss: 0.15947015583515167
Validation loss: 1.7530524256408855

Epoch: 5| Step: 6
Training loss: 0.30928534269332886
Validation loss: 1.7544026342771386

Epoch: 5| Step: 7
Training loss: 0.321807324886322
Validation loss: 1.7411163353150891

Epoch: 5| Step: 8
Training loss: 0.6024454832077026
Validation loss: 1.7558821324379212

Epoch: 5| Step: 9
Training loss: 0.29650822281837463
Validation loss: 1.7525856366721533

Epoch: 5| Step: 10
Training loss: 0.29273873567581177
Validation loss: 1.767999646484211

Epoch: 345| Step: 0
Training loss: 0.30574294924736023
Validation loss: 1.7862348120699647

Epoch: 5| Step: 1
Training loss: 0.2302512675523758
Validation loss: 1.803916338951357

Epoch: 5| Step: 2
Training loss: 0.46620869636535645
Validation loss: 1.7619855115490575

Epoch: 5| Step: 3
Training loss: 0.22276577353477478
Validation loss: 1.7606156974710443

Epoch: 5| Step: 4
Training loss: 0.21789996325969696
Validation loss: 1.7405360475663216

Epoch: 5| Step: 5
Training loss: 0.7027596831321716
Validation loss: 1.7352687376801685

Epoch: 5| Step: 6
Training loss: 0.2928210198879242
Validation loss: 1.7349303524981263

Epoch: 5| Step: 7
Training loss: 0.22974476218223572
Validation loss: 1.712247371673584

Epoch: 5| Step: 8
Training loss: 0.36418217420578003
Validation loss: 1.7447706243043304

Epoch: 5| Step: 9
Training loss: 0.2179216891527176
Validation loss: 1.7338154046766219

Epoch: 5| Step: 10
Training loss: 0.5782089233398438
Validation loss: 1.7286573071633615

Epoch: 346| Step: 0
Training loss: 0.16081461310386658
Validation loss: 1.7160756613618584

Epoch: 5| Step: 1
Training loss: 0.1811453253030777
Validation loss: 1.7241471531570598

Epoch: 5| Step: 2
Training loss: 0.550872266292572
Validation loss: 1.7190789689299881

Epoch: 5| Step: 3
Training loss: 0.2825648784637451
Validation loss: 1.7546699585453156

Epoch: 5| Step: 4
Training loss: 0.36208462715148926
Validation loss: 1.7657391384083738

Epoch: 5| Step: 5
Training loss: 0.43455806374549866
Validation loss: 1.7599514633096673

Epoch: 5| Step: 6
Training loss: 0.36066940426826477
Validation loss: 1.776300763571134

Epoch: 5| Step: 7
Training loss: 0.40453773736953735
Validation loss: 1.7953403739519016

Epoch: 5| Step: 8
Training loss: 0.33245378732681274
Validation loss: 1.8206106065421976

Epoch: 5| Step: 9
Training loss: 0.30740851163864136
Validation loss: 1.826471140307765

Epoch: 5| Step: 10
Training loss: 0.5050210356712341
Validation loss: 1.808783572207215

Epoch: 347| Step: 0
Training loss: 0.5102817416191101
Validation loss: 1.758789772628456

Epoch: 5| Step: 1
Training loss: 0.19253647327423096
Validation loss: 1.7519032570623583

Epoch: 5| Step: 2
Training loss: 0.23517146706581116
Validation loss: 1.7309900394050024

Epoch: 5| Step: 3
Training loss: 0.3120531439781189
Validation loss: 1.7423014461353261

Epoch: 5| Step: 4
Training loss: 0.6273704767227173
Validation loss: 1.710565814407923

Epoch: 5| Step: 5
Training loss: 0.46663475036621094
Validation loss: 1.7087404792026808

Epoch: 5| Step: 6
Training loss: 0.379814088344574
Validation loss: 1.7324763818453717

Epoch: 5| Step: 7
Training loss: 0.3610552251338959
Validation loss: 1.7350876946603098

Epoch: 5| Step: 8
Training loss: 0.27322524785995483
Validation loss: 1.7554866780516922

Epoch: 5| Step: 9
Training loss: 0.20114143192768097
Validation loss: 1.7784398512173725

Epoch: 5| Step: 10
Training loss: 0.21138231456279755
Validation loss: 1.8093627729723532

Epoch: 348| Step: 0
Training loss: 0.3712088167667389
Validation loss: 1.8390006198677966

Epoch: 5| Step: 1
Training loss: 0.4156860411167145
Validation loss: 1.8532251888705837

Epoch: 5| Step: 2
Training loss: 0.45269283652305603
Validation loss: 1.8216659894553564

Epoch: 5| Step: 3
Training loss: 0.34303370118141174
Validation loss: 1.787134100032109

Epoch: 5| Step: 4
Training loss: 0.614587664604187
Validation loss: 1.7532092473840202

Epoch: 5| Step: 5
Training loss: 0.49035215377807617
Validation loss: 1.7127898470047982

Epoch: 5| Step: 6
Training loss: 0.16610249876976013
Validation loss: 1.6969536812074724

Epoch: 5| Step: 7
Training loss: 0.22840110957622528
Validation loss: 1.6909860052088255

Epoch: 5| Step: 8
Training loss: 0.390666663646698
Validation loss: 1.6872085127779233

Epoch: 5| Step: 9
Training loss: 0.339541494846344
Validation loss: 1.7177098156303487

Epoch: 5| Step: 10
Training loss: 0.15089888870716095
Validation loss: 1.716028328864805

Epoch: 349| Step: 0
Training loss: 0.34662938117980957
Validation loss: 1.7433885425649664

Epoch: 5| Step: 1
Training loss: 0.42716583609580994
Validation loss: 1.7684460070825392

Epoch: 5| Step: 2
Training loss: 0.2762798070907593
Validation loss: 1.7711958539101385

Epoch: 5| Step: 3
Training loss: 0.31433001160621643
Validation loss: 1.7612472272688342

Epoch: 5| Step: 4
Training loss: 0.27802979946136475
Validation loss: 1.7444380611501715

Epoch: 5| Step: 5
Training loss: 0.5032724142074585
Validation loss: 1.7390752889776742

Epoch: 5| Step: 6
Training loss: 0.26919302344322205
Validation loss: 1.754789290889617

Epoch: 5| Step: 7
Training loss: 0.16411912441253662
Validation loss: 1.7286048896851078

Epoch: 5| Step: 8
Training loss: 0.5838950872421265
Validation loss: 1.7300604645923903

Epoch: 5| Step: 9
Training loss: 0.2641315460205078
Validation loss: 1.740091113634007

Epoch: 5| Step: 10
Training loss: 0.21177776157855988
Validation loss: 1.7539533466421149

Epoch: 350| Step: 0
Training loss: 0.37828364968299866
Validation loss: 1.7524245182673137

Epoch: 5| Step: 1
Training loss: 0.3553406298160553
Validation loss: 1.7412110503001879

Epoch: 5| Step: 2
Training loss: 0.4373153746128082
Validation loss: 1.7533441487179007

Epoch: 5| Step: 3
Training loss: 0.278808057308197
Validation loss: 1.7425780168143652

Epoch: 5| Step: 4
Training loss: 0.28826704621315
Validation loss: 1.7623901828642814

Epoch: 5| Step: 5
Training loss: 0.40634626150131226
Validation loss: 1.7739181031462967

Epoch: 5| Step: 6
Training loss: 0.2701667547225952
Validation loss: 1.7421986031275924

Epoch: 5| Step: 7
Training loss: 0.34110715985298157
Validation loss: 1.753568826183196

Epoch: 5| Step: 8
Training loss: 0.24987438321113586
Validation loss: 1.7509863709890714

Epoch: 5| Step: 9
Training loss: 0.3425931930541992
Validation loss: 1.7433185231301092

Epoch: 5| Step: 10
Training loss: 0.33598092198371887
Validation loss: 1.755849806211328

Epoch: 351| Step: 0
Training loss: 0.33807724714279175
Validation loss: 1.7447203077295774

Epoch: 5| Step: 1
Training loss: 0.3214278817176819
Validation loss: 1.7537974106368197

Epoch: 5| Step: 2
Training loss: 0.22041411697864532
Validation loss: 1.7587278645525697

Epoch: 5| Step: 3
Training loss: 0.4852654039859772
Validation loss: 1.7748433043879848

Epoch: 5| Step: 4
Training loss: 0.24073991179466248
Validation loss: 1.787120605027804

Epoch: 5| Step: 5
Training loss: 0.25345945358276367
Validation loss: 1.7786898048975135

Epoch: 5| Step: 6
Training loss: 0.21839094161987305
Validation loss: 1.790195934234127

Epoch: 5| Step: 7
Training loss: 0.3449573814868927
Validation loss: 1.772507582941363

Epoch: 5| Step: 8
Training loss: 0.3317868709564209
Validation loss: 1.7530693841236893

Epoch: 5| Step: 9
Training loss: 0.608049213886261
Validation loss: 1.7627664496821742

Epoch: 5| Step: 10
Training loss: 0.1016598492860794
Validation loss: 1.754698250883369

Epoch: 352| Step: 0
Training loss: 0.21302612125873566
Validation loss: 1.737277796191554

Epoch: 5| Step: 1
Training loss: 0.284166157245636
Validation loss: 1.716949285999421

Epoch: 5| Step: 2
Training loss: 0.318922221660614
Validation loss: 1.7271887230616745

Epoch: 5| Step: 3
Training loss: 0.3710181713104248
Validation loss: 1.722942077985374

Epoch: 5| Step: 4
Training loss: 0.42168721556663513
Validation loss: 1.7265548039508123

Epoch: 5| Step: 5
Training loss: 0.332849383354187
Validation loss: 1.7480904363816785

Epoch: 5| Step: 6
Training loss: 0.358446329832077
Validation loss: 1.770400785630749

Epoch: 5| Step: 7
Training loss: 0.23512299358844757
Validation loss: 1.728896631989428

Epoch: 5| Step: 8
Training loss: 0.6342185139656067
Validation loss: 1.744094956305719

Epoch: 5| Step: 9
Training loss: 0.19001908600330353
Validation loss: 1.7527856954964258

Epoch: 5| Step: 10
Training loss: 0.18374210596084595
Validation loss: 1.7035573720932007

Epoch: 353| Step: 0
Training loss: 0.17282681167125702
Validation loss: 1.7209223239652571

Epoch: 5| Step: 1
Training loss: 0.28302377462387085
Validation loss: 1.700237392097391

Epoch: 5| Step: 2
Training loss: 0.28582963347435
Validation loss: 1.706441883117922

Epoch: 5| Step: 3
Training loss: 0.3029661178588867
Validation loss: 1.7165785451089182

Epoch: 5| Step: 4
Training loss: 0.2788606286048889
Validation loss: 1.6951322094086678

Epoch: 5| Step: 5
Training loss: 0.2212512046098709
Validation loss: 1.713795788826481

Epoch: 5| Step: 6
Training loss: 0.5030781030654907
Validation loss: 1.726233600288309

Epoch: 5| Step: 7
Training loss: 0.40415316820144653
Validation loss: 1.7418784826032576

Epoch: 5| Step: 8
Training loss: 0.1942715346813202
Validation loss: 1.7382079914052

Epoch: 5| Step: 9
Training loss: 0.46679410338401794
Validation loss: 1.7500802880974227

Epoch: 5| Step: 10
Training loss: 0.5862230658531189
Validation loss: 1.740891880886529

Epoch: 354| Step: 0
Training loss: 0.2218029946088791
Validation loss: 1.7532883523612894

Epoch: 5| Step: 1
Training loss: 0.2687701880931854
Validation loss: 1.7510535306827997

Epoch: 5| Step: 2
Training loss: 0.21299496293067932
Validation loss: 1.7591622978128412

Epoch: 5| Step: 3
Training loss: 0.5454797744750977
Validation loss: 1.7537444509485716

Epoch: 5| Step: 4
Training loss: 0.13646253943443298
Validation loss: 1.7475749215772074

Epoch: 5| Step: 5
Training loss: 0.4278998374938965
Validation loss: 1.7613104774105934

Epoch: 5| Step: 6
Training loss: 0.2913677990436554
Validation loss: 1.7576286023662937

Epoch: 5| Step: 7
Training loss: 0.27073773741722107
Validation loss: 1.7671593261021439

Epoch: 5| Step: 8
Training loss: 0.3615202307701111
Validation loss: 1.7634948915050876

Epoch: 5| Step: 9
Training loss: 0.25553181767463684
Validation loss: 1.717345650478076

Epoch: 5| Step: 10
Training loss: 0.2936522960662842
Validation loss: 1.688874670254287

Epoch: 355| Step: 0
Training loss: 0.22545213997364044
Validation loss: 1.6955080160530664

Epoch: 5| Step: 1
Training loss: 0.2670658230781555
Validation loss: 1.6783983079336022

Epoch: 5| Step: 2
Training loss: 0.3523983061313629
Validation loss: 1.6802859690881544

Epoch: 5| Step: 3
Training loss: 0.4337334632873535
Validation loss: 1.6945145873613254

Epoch: 5| Step: 4
Training loss: 0.3024270534515381
Validation loss: 1.6905673037293136

Epoch: 5| Step: 5
Training loss: 0.4962698817253113
Validation loss: 1.7119268486576695

Epoch: 5| Step: 6
Training loss: 0.21323755383491516
Validation loss: 1.7307577306224453

Epoch: 5| Step: 7
Training loss: 0.185370072722435
Validation loss: 1.7665780090516614

Epoch: 5| Step: 8
Training loss: 0.27331608533859253
Validation loss: 1.7660938898722331

Epoch: 5| Step: 9
Training loss: 0.2487652748823166
Validation loss: 1.7888579830046623

Epoch: 5| Step: 10
Training loss: 0.30696240067481995
Validation loss: 1.786157105558662

Epoch: 356| Step: 0
Training loss: 0.16209404170513153
Validation loss: 1.7735782951437018

Epoch: 5| Step: 1
Training loss: 0.4387292265892029
Validation loss: 1.7792334184851697

Epoch: 5| Step: 2
Training loss: 0.19211754202842712
Validation loss: 1.7542487985344344

Epoch: 5| Step: 3
Training loss: 0.3594314455986023
Validation loss: 1.7385767813651793

Epoch: 5| Step: 4
Training loss: 0.3173343539237976
Validation loss: 1.7328180113146383

Epoch: 5| Step: 5
Training loss: 0.4369925558567047
Validation loss: 1.7580071751789381

Epoch: 5| Step: 6
Training loss: 0.5774596929550171
Validation loss: 1.7602765406331708

Epoch: 5| Step: 7
Training loss: 0.350710391998291
Validation loss: 1.7445977503253567

Epoch: 5| Step: 8
Training loss: 0.3423929810523987
Validation loss: 1.7409942585934874

Epoch: 5| Step: 9
Training loss: 0.17323018610477448
Validation loss: 1.7294149744895198

Epoch: 5| Step: 10
Training loss: 0.22519327700138092
Validation loss: 1.729223620507025

Epoch: 357| Step: 0
Training loss: 0.2524028420448303
Validation loss: 1.7258936987128308

Epoch: 5| Step: 1
Training loss: 0.22875015437602997
Validation loss: 1.7118579828610985

Epoch: 5| Step: 2
Training loss: 0.3543853163719177
Validation loss: 1.7118785137771277

Epoch: 5| Step: 3
Training loss: 0.19558468461036682
Validation loss: 1.7049166528127526

Epoch: 5| Step: 4
Training loss: 0.4006161689758301
Validation loss: 1.6768959158210344

Epoch: 5| Step: 5
Training loss: 0.3566824495792389
Validation loss: 1.7079835053413146

Epoch: 5| Step: 6
Training loss: 0.38730424642562866
Validation loss: 1.7058693196183892

Epoch: 5| Step: 7
Training loss: 0.42092379927635193
Validation loss: 1.7109429451727098

Epoch: 5| Step: 8
Training loss: 0.24904879927635193
Validation loss: 1.7091257110718758

Epoch: 5| Step: 9
Training loss: 0.3633852005004883
Validation loss: 1.719875407475297

Epoch: 5| Step: 10
Training loss: 0.25088822841644287
Validation loss: 1.7042613003843574

Epoch: 358| Step: 0
Training loss: 0.20664536952972412
Validation loss: 1.7051109549819783

Epoch: 5| Step: 1
Training loss: 0.2265959084033966
Validation loss: 1.7390234162730556

Epoch: 5| Step: 2
Training loss: 0.33007118105888367
Validation loss: 1.7029173925358763

Epoch: 5| Step: 3
Training loss: 0.2899256944656372
Validation loss: 1.6907075553812005

Epoch: 5| Step: 4
Training loss: 0.4461914896965027
Validation loss: 1.6891806305095713

Epoch: 5| Step: 5
Training loss: 0.2876778542995453
Validation loss: 1.679308601604995

Epoch: 5| Step: 6
Training loss: 0.19465577602386475
Validation loss: 1.6821312224993141

Epoch: 5| Step: 7
Training loss: 0.20113137364387512
Validation loss: 1.692512664743649

Epoch: 5| Step: 8
Training loss: 0.10727180540561676
Validation loss: 1.712662443037956

Epoch: 5| Step: 9
Training loss: 0.7194291949272156
Validation loss: 1.6997932490482126

Epoch: 5| Step: 10
Training loss: 0.3161841630935669
Validation loss: 1.691952068318603

Epoch: 359| Step: 0
Training loss: 0.30497461557388306
Validation loss: 1.7099641189780286

Epoch: 5| Step: 1
Training loss: 0.2798409163951874
Validation loss: 1.6875322147082257

Epoch: 5| Step: 2
Training loss: 0.24577602744102478
Validation loss: 1.6712048310105518

Epoch: 5| Step: 3
Training loss: 0.27467718720436096
Validation loss: 1.6594350440527803

Epoch: 5| Step: 4
Training loss: 0.4262315630912781
Validation loss: 1.6773743334636892

Epoch: 5| Step: 5
Training loss: 0.27471452951431274
Validation loss: 1.6798270299870481

Epoch: 5| Step: 6
Training loss: 0.3392016291618347
Validation loss: 1.6816837556900517

Epoch: 5| Step: 7
Training loss: 0.4516147971153259
Validation loss: 1.6872361744603803

Epoch: 5| Step: 8
Training loss: 0.26595795154571533
Validation loss: 1.7302251080031037

Epoch: 5| Step: 9
Training loss: 0.17699618637561798
Validation loss: 1.75106377883624

Epoch: 5| Step: 10
Training loss: 0.26005813479423523
Validation loss: 1.750783081977598

Epoch: 360| Step: 0
Training loss: 0.5214436650276184
Validation loss: 1.7398271817033009

Epoch: 5| Step: 1
Training loss: 0.22650671005249023
Validation loss: 1.7438294272268973

Epoch: 5| Step: 2
Training loss: 0.2597338557243347
Validation loss: 1.7497525574058614

Epoch: 5| Step: 3
Training loss: 0.292341411113739
Validation loss: 1.724297756789833

Epoch: 5| Step: 4
Training loss: 0.24322214722633362
Validation loss: 1.7196989854176838

Epoch: 5| Step: 5
Training loss: 0.39918917417526245
Validation loss: 1.7075869780714794

Epoch: 5| Step: 6
Training loss: 0.36032944917678833
Validation loss: 1.7000810869278447

Epoch: 5| Step: 7
Training loss: 0.2597467005252838
Validation loss: 1.7012029847791117

Epoch: 5| Step: 8
Training loss: 0.26118308305740356
Validation loss: 1.6619022943640267

Epoch: 5| Step: 9
Training loss: 0.17734196782112122
Validation loss: 1.6878009470560218

Epoch: 5| Step: 10
Training loss: 0.23141402006149292
Validation loss: 1.6917285855098436

Epoch: 361| Step: 0
Training loss: 0.26461121439933777
Validation loss: 1.674011024095679

Epoch: 5| Step: 1
Training loss: 0.26935356855392456
Validation loss: 1.6893111364815825

Epoch: 5| Step: 2
Training loss: 0.2816883623600006
Validation loss: 1.6609067724597069

Epoch: 5| Step: 3
Training loss: 0.25885775685310364
Validation loss: 1.6824723136040471

Epoch: 5| Step: 4
Training loss: 0.6525336503982544
Validation loss: 1.6726182301839192

Epoch: 5| Step: 5
Training loss: 0.2619583010673523
Validation loss: 1.6782146641003188

Epoch: 5| Step: 6
Training loss: 0.11530885845422745
Validation loss: 1.6820769566361622

Epoch: 5| Step: 7
Training loss: 0.2168644368648529
Validation loss: 1.6995257254569762

Epoch: 5| Step: 8
Training loss: 0.26405513286590576
Validation loss: 1.7264215254014539

Epoch: 5| Step: 9
Training loss: 0.2604324221611023
Validation loss: 1.7425333146126039

Epoch: 5| Step: 10
Training loss: 0.45282983779907227
Validation loss: 1.734832477825944

Epoch: 362| Step: 0
Training loss: 0.4478701651096344
Validation loss: 1.744522221626774

Epoch: 5| Step: 1
Training loss: 0.361051082611084
Validation loss: 1.7118402078587522

Epoch: 5| Step: 2
Training loss: 0.24913358688354492
Validation loss: 1.7267254680715582

Epoch: 5| Step: 3
Training loss: 0.28696542978286743
Validation loss: 1.7113959917458155

Epoch: 5| Step: 4
Training loss: 0.2920912206172943
Validation loss: 1.6798814509504585

Epoch: 5| Step: 5
Training loss: 0.27907198667526245
Validation loss: 1.6844007661265712

Epoch: 5| Step: 6
Training loss: 0.3068522810935974
Validation loss: 1.652499056631519

Epoch: 5| Step: 7
Training loss: 0.3054211735725403
Validation loss: 1.6675697500987718

Epoch: 5| Step: 8
Training loss: 0.21824677288532257
Validation loss: 1.6893518970858665

Epoch: 5| Step: 9
Training loss: 0.29442498087882996
Validation loss: 1.7168032059105494

Epoch: 5| Step: 10
Training loss: 0.21056950092315674
Validation loss: 1.7132084946478567

Epoch: 363| Step: 0
Training loss: 0.2319919317960739
Validation loss: 1.7045214945270168

Epoch: 5| Step: 1
Training loss: 0.22115068137645721
Validation loss: 1.7248179604930263

Epoch: 5| Step: 2
Training loss: 0.4719776511192322
Validation loss: 1.72539516802757

Epoch: 5| Step: 3
Training loss: 0.3267967402935028
Validation loss: 1.742929490663672

Epoch: 5| Step: 4
Training loss: 0.26465851068496704
Validation loss: 1.7286952285356418

Epoch: 5| Step: 5
Training loss: 0.19020482897758484
Validation loss: 1.7233602616094774

Epoch: 5| Step: 6
Training loss: 0.34978193044662476
Validation loss: 1.7124049368725027

Epoch: 5| Step: 7
Training loss: 0.4018685221672058
Validation loss: 1.7086222235874464

Epoch: 5| Step: 8
Training loss: 0.25479888916015625
Validation loss: 1.6920327473712224

Epoch: 5| Step: 9
Training loss: 0.2782588601112366
Validation loss: 1.7129518242292507

Epoch: 5| Step: 10
Training loss: 0.1484871506690979
Validation loss: 1.7022352064809492

Epoch: 364| Step: 0
Training loss: 0.3118184506893158
Validation loss: 1.7577694116100189

Epoch: 5| Step: 1
Training loss: 0.38881099224090576
Validation loss: 1.741426238449671

Epoch: 5| Step: 2
Training loss: 0.23615708947181702
Validation loss: 1.7653064420146327

Epoch: 5| Step: 3
Training loss: 0.298525869846344
Validation loss: 1.7348937629371561

Epoch: 5| Step: 4
Training loss: 0.2471269816160202
Validation loss: 1.7060689874874648

Epoch: 5| Step: 5
Training loss: 0.20151333510875702
Validation loss: 1.6917898603664931

Epoch: 5| Step: 6
Training loss: 0.6706479787826538
Validation loss: 1.7065223263156029

Epoch: 5| Step: 7
Training loss: 0.18193571269512177
Validation loss: 1.6817261493334206

Epoch: 5| Step: 8
Training loss: 0.3872494101524353
Validation loss: 1.6963634708876252

Epoch: 5| Step: 9
Training loss: 0.20866522192955017
Validation loss: 1.718410208661069

Epoch: 5| Step: 10
Training loss: 0.22264398634433746
Validation loss: 1.7222477595011394

Epoch: 365| Step: 0
Training loss: 0.4269603192806244
Validation loss: 1.7337220920029508

Epoch: 5| Step: 1
Training loss: 0.33492475748062134
Validation loss: 1.7573391263202955

Epoch: 5| Step: 2
Training loss: 0.21521468460559845
Validation loss: 1.7634603682384695

Epoch: 5| Step: 3
Training loss: 0.2860953211784363
Validation loss: 1.7871497587491108

Epoch: 5| Step: 4
Training loss: 0.29907259345054626
Validation loss: 1.761611597512358

Epoch: 5| Step: 5
Training loss: 0.25942403078079224
Validation loss: 1.7397346676036876

Epoch: 5| Step: 6
Training loss: 0.37385207414627075
Validation loss: 1.6795907007750643

Epoch: 5| Step: 7
Training loss: 0.3390699326992035
Validation loss: 1.6932641665140789

Epoch: 5| Step: 8
Training loss: 0.17913022637367249
Validation loss: 1.6562048158337992

Epoch: 5| Step: 9
Training loss: 0.25968143343925476
Validation loss: 1.6470100110577

Epoch: 5| Step: 10
Training loss: 0.2740396559238434
Validation loss: 1.6436169403855518

Epoch: 366| Step: 0
Training loss: 0.1667645126581192
Validation loss: 1.6693658687735116

Epoch: 5| Step: 1
Training loss: 0.3319798409938812
Validation loss: 1.6774953847290368

Epoch: 5| Step: 2
Training loss: 0.26340144872665405
Validation loss: 1.6920523746039278

Epoch: 5| Step: 3
Training loss: 0.25929391384124756
Validation loss: 1.7057379407267417

Epoch: 5| Step: 4
Training loss: 0.24841174483299255
Validation loss: 1.7106385961655648

Epoch: 5| Step: 5
Training loss: 0.14457687735557556
Validation loss: 1.698885908690832

Epoch: 5| Step: 6
Training loss: 0.14932790398597717
Validation loss: 1.6990039079420027

Epoch: 5| Step: 7
Training loss: 0.593718945980072
Validation loss: 1.7216593450115574

Epoch: 5| Step: 8
Training loss: 0.2525707185268402
Validation loss: 1.7412593774898077

Epoch: 5| Step: 9
Training loss: 0.5285450220108032
Validation loss: 1.7398776572237733

Epoch: 5| Step: 10
Training loss: 0.2461954802274704
Validation loss: 1.7626455471079836

Epoch: 367| Step: 0
Training loss: 0.2565930485725403
Validation loss: 1.7716993388309275

Epoch: 5| Step: 1
Training loss: 0.3172304034233093
Validation loss: 1.7628503858402211

Epoch: 5| Step: 2
Training loss: 0.21620340645313263
Validation loss: 1.7550211709032777

Epoch: 5| Step: 3
Training loss: 0.3747172951698303
Validation loss: 1.7420710748241794

Epoch: 5| Step: 4
Training loss: 0.30204349756240845
Validation loss: 1.7266223789543234

Epoch: 5| Step: 5
Training loss: 0.3524753153324127
Validation loss: 1.7185074821595223

Epoch: 5| Step: 6
Training loss: 0.3429590165615082
Validation loss: 1.7035161590063443

Epoch: 5| Step: 7
Training loss: 0.29554691910743713
Validation loss: 1.7170763810475667

Epoch: 5| Step: 8
Training loss: 0.28874754905700684
Validation loss: 1.709381761089448

Epoch: 5| Step: 9
Training loss: 0.1951242834329605
Validation loss: 1.7163757303709626

Epoch: 5| Step: 10
Training loss: 0.45278021693229675
Validation loss: 1.7397250129330544

Epoch: 368| Step: 0
Training loss: 0.2606542706489563
Validation loss: 1.7268694370023665

Epoch: 5| Step: 1
Training loss: 0.19003349542617798
Validation loss: 1.7282251824614823

Epoch: 5| Step: 2
Training loss: 0.31134968996047974
Validation loss: 1.7379883809756207

Epoch: 5| Step: 3
Training loss: 0.23633918166160583
Validation loss: 1.729009025840349

Epoch: 5| Step: 4
Training loss: 0.25808387994766235
Validation loss: 1.6821052284650906

Epoch: 5| Step: 5
Training loss: 0.36875802278518677
Validation loss: 1.6813780261624245

Epoch: 5| Step: 6
Training loss: 0.32092899084091187
Validation loss: 1.6591603345768426

Epoch: 5| Step: 7
Training loss: 0.2949449121952057
Validation loss: 1.6482496607688166

Epoch: 5| Step: 8
Training loss: 0.32663851976394653
Validation loss: 1.6822620630264282

Epoch: 5| Step: 9
Training loss: 0.4384990334510803
Validation loss: 1.7037191801173712

Epoch: 5| Step: 10
Training loss: 0.34108152985572815
Validation loss: 1.7294521383059922

Epoch: 369| Step: 0
Training loss: 0.5875602960586548
Validation loss: 1.738469144349457

Epoch: 5| Step: 1
Training loss: 0.29997119307518005
Validation loss: 1.7498000155213058

Epoch: 5| Step: 2
Training loss: 0.1779605746269226
Validation loss: 1.7396654698156542

Epoch: 5| Step: 3
Training loss: 0.3291342854499817
Validation loss: 1.765682440932079

Epoch: 5| Step: 4
Training loss: 0.17016065120697021
Validation loss: 1.7575012778723111

Epoch: 5| Step: 5
Training loss: 0.3475259244441986
Validation loss: 1.7456864035257729

Epoch: 5| Step: 6
Training loss: 0.18250954151153564
Validation loss: 1.7466004330624816

Epoch: 5| Step: 7
Training loss: 0.2848272919654846
Validation loss: 1.740845678954996

Epoch: 5| Step: 8
Training loss: 0.24906568229198456
Validation loss: 1.7069451219292098

Epoch: 5| Step: 9
Training loss: 0.2097322642803192
Validation loss: 1.7308520758023827

Epoch: 5| Step: 10
Training loss: 0.2822132706642151
Validation loss: 1.7450124653436805

Epoch: 370| Step: 0
Training loss: 0.29488006234169006
Validation loss: 1.7500405619221349

Epoch: 5| Step: 1
Training loss: 0.37412482500076294
Validation loss: 1.734839572701403

Epoch: 5| Step: 2
Training loss: 0.2977968752384186
Validation loss: 1.7508260767946962

Epoch: 5| Step: 3
Training loss: 0.23231229186058044
Validation loss: 1.724098615748908

Epoch: 5| Step: 4
Training loss: 0.1836792677640915
Validation loss: 1.7210293405799455

Epoch: 5| Step: 5
Training loss: 0.5271022319793701
Validation loss: 1.6859264322506484

Epoch: 5| Step: 6
Training loss: 0.26103419065475464
Validation loss: 1.7133735879775016

Epoch: 5| Step: 7
Training loss: 0.20133176445960999
Validation loss: 1.6931306880007508

Epoch: 5| Step: 8
Training loss: 0.23424215614795685
Validation loss: 1.7039541621362009

Epoch: 5| Step: 9
Training loss: 0.23585526645183563
Validation loss: 1.6984921988620554

Epoch: 5| Step: 10
Training loss: 0.3615095019340515
Validation loss: 1.6983917708038

Epoch: 371| Step: 0
Training loss: 0.25280827283859253
Validation loss: 1.6835260711690432

Epoch: 5| Step: 1
Training loss: 0.18353798985481262
Validation loss: 1.6823886568828295

Epoch: 5| Step: 2
Training loss: 0.2060556411743164
Validation loss: 1.6846314553291566

Epoch: 5| Step: 3
Training loss: 0.3341553807258606
Validation loss: 1.7071992915163758

Epoch: 5| Step: 4
Training loss: 0.3666295111179352
Validation loss: 1.6931944303615118

Epoch: 5| Step: 5
Training loss: 0.2982007563114166
Validation loss: 1.7030110692465177

Epoch: 5| Step: 6
Training loss: 0.15431663393974304
Validation loss: 1.7055558235414567

Epoch: 5| Step: 7
Training loss: 0.4272634983062744
Validation loss: 1.7180437734050136

Epoch: 5| Step: 8
Training loss: 0.2679431140422821
Validation loss: 1.7033385371649137

Epoch: 5| Step: 9
Training loss: 0.2795495092868805
Validation loss: 1.7078215883624168

Epoch: 5| Step: 10
Training loss: 0.2704782485961914
Validation loss: 1.7111969045413438

Epoch: 372| Step: 0
Training loss: 0.4235077500343323
Validation loss: 1.7195631765550183

Epoch: 5| Step: 1
Training loss: 0.12442102283239365
Validation loss: 1.6981560619928504

Epoch: 5| Step: 2
Training loss: 0.16662108898162842
Validation loss: 1.6944161435609222

Epoch: 5| Step: 3
Training loss: 0.2582252025604248
Validation loss: 1.7099833360282324

Epoch: 5| Step: 4
Training loss: 0.26216191053390503
Validation loss: 1.688721078698353

Epoch: 5| Step: 5
Training loss: 0.28295010328292847
Validation loss: 1.683898134898114

Epoch: 5| Step: 6
Training loss: 0.3833828866481781
Validation loss: 1.7071079515641736

Epoch: 5| Step: 7
Training loss: 0.3803170323371887
Validation loss: 1.6848088041428597

Epoch: 5| Step: 8
Training loss: 0.322990357875824
Validation loss: 1.6923429581426805

Epoch: 5| Step: 9
Training loss: 0.12461133301258087
Validation loss: 1.6815077630422448

Epoch: 5| Step: 10
Training loss: 0.42723578214645386
Validation loss: 1.6889615827991116

Epoch: 373| Step: 0
Training loss: 0.4884273111820221
Validation loss: 1.6585628755630986

Epoch: 5| Step: 1
Training loss: 0.2854313254356384
Validation loss: 1.6584648124633297

Epoch: 5| Step: 2
Training loss: 0.18344174325466156
Validation loss: 1.6762223474441036

Epoch: 5| Step: 3
Training loss: 0.3812209367752075
Validation loss: 1.632722226522302

Epoch: 5| Step: 4
Training loss: 0.45776620507240295
Validation loss: 1.6517104833356795

Epoch: 5| Step: 5
Training loss: 0.2742574214935303
Validation loss: 1.6765442073986094

Epoch: 5| Step: 6
Training loss: 0.08985491096973419
Validation loss: 1.6504804113859772

Epoch: 5| Step: 7
Training loss: 0.15658776462078094
Validation loss: 1.6890299756039855

Epoch: 5| Step: 8
Training loss: 0.23382475972175598
Validation loss: 1.6855628246902137

Epoch: 5| Step: 9
Training loss: 0.12977316975593567
Validation loss: 1.6743803370383479

Epoch: 5| Step: 10
Training loss: 0.2323402315378189
Validation loss: 1.6808806209154026

Epoch: 374| Step: 0
Training loss: 0.12646958231925964
Validation loss: 1.6909545993292203

Epoch: 5| Step: 1
Training loss: 0.15425315499305725
Validation loss: 1.689156134923299

Epoch: 5| Step: 2
Training loss: 0.3543108403682709
Validation loss: 1.6886065493347824

Epoch: 5| Step: 3
Training loss: 0.13662919402122498
Validation loss: 1.699498165038324

Epoch: 5| Step: 4
Training loss: 0.4640105366706848
Validation loss: 1.6819020509719849

Epoch: 5| Step: 5
Training loss: 0.41529956459999084
Validation loss: 1.6666830996031403

Epoch: 5| Step: 6
Training loss: 0.2879897654056549
Validation loss: 1.680305979585135

Epoch: 5| Step: 7
Training loss: 0.19131715595722198
Validation loss: 1.6767631666634673

Epoch: 5| Step: 8
Training loss: 0.21967358887195587
Validation loss: 1.6847479856142433

Epoch: 5| Step: 9
Training loss: 0.21289582550525665
Validation loss: 1.6991489036108858

Epoch: 5| Step: 10
Training loss: 0.20394933223724365
Validation loss: 1.7177136764731458

Epoch: 375| Step: 0
Training loss: 0.20967721939086914
Validation loss: 1.7309380859457038

Epoch: 5| Step: 1
Training loss: 0.5550721883773804
Validation loss: 1.7252552073488954

Epoch: 5| Step: 2
Training loss: 0.21181759238243103
Validation loss: 1.7426946675905617

Epoch: 5| Step: 3
Training loss: 0.4008244574069977
Validation loss: 1.718393660360767

Epoch: 5| Step: 4
Training loss: 0.18562383949756622
Validation loss: 1.6896351716851676

Epoch: 5| Step: 5
Training loss: 0.24881310760974884
Validation loss: 1.6765810340963385

Epoch: 5| Step: 6
Training loss: 0.15346889197826385
Validation loss: 1.6604281478030707

Epoch: 5| Step: 7
Training loss: 0.2303040325641632
Validation loss: 1.6473294893900554

Epoch: 5| Step: 8
Training loss: 0.32119208574295044
Validation loss: 1.6754356391968266

Epoch: 5| Step: 9
Training loss: 0.13060082495212555
Validation loss: 1.6855691030461302

Epoch: 5| Step: 10
Training loss: 0.1568528413772583
Validation loss: 1.6991810068007438

Epoch: 376| Step: 0
Training loss: 0.3547869324684143
Validation loss: 1.7238065324803835

Epoch: 5| Step: 1
Training loss: 0.21240448951721191
Validation loss: 1.7013431031216857

Epoch: 5| Step: 2
Training loss: 0.2599203586578369
Validation loss: 1.6886059840520222

Epoch: 5| Step: 3
Training loss: 0.23353609442710876
Validation loss: 1.68734755310961

Epoch: 5| Step: 4
Training loss: 0.17846179008483887
Validation loss: 1.6609225542314592

Epoch: 5| Step: 5
Training loss: 0.1608017086982727
Validation loss: 1.6630263033733572

Epoch: 5| Step: 6
Training loss: 0.19120950996875763
Validation loss: 1.6459985740723149

Epoch: 5| Step: 7
Training loss: 0.3653210699558258
Validation loss: 1.6437678490915606

Epoch: 5| Step: 8
Training loss: 0.34941449761390686
Validation loss: 1.6538255906874133

Epoch: 5| Step: 9
Training loss: 0.3028910756111145
Validation loss: 1.6509669403876028

Epoch: 5| Step: 10
Training loss: 0.16766059398651123
Validation loss: 1.6704208979042627

Epoch: 377| Step: 0
Training loss: 0.24003033339977264
Validation loss: 1.6791882457271698

Epoch: 5| Step: 1
Training loss: 0.22608605027198792
Validation loss: 1.6860437495734102

Epoch: 5| Step: 2
Training loss: 0.17295077443122864
Validation loss: 1.692505600631878

Epoch: 5| Step: 3
Training loss: 0.22278395295143127
Validation loss: 1.6998310947930941

Epoch: 5| Step: 4
Training loss: 0.20060408115386963
Validation loss: 1.7064142342536681

Epoch: 5| Step: 5
Training loss: 0.32655617594718933
Validation loss: 1.7263334399910384

Epoch: 5| Step: 6
Training loss: 0.26421988010406494
Validation loss: 1.6912628219973656

Epoch: 5| Step: 7
Training loss: 0.16020065546035767
Validation loss: 1.7003335632303709

Epoch: 5| Step: 8
Training loss: 0.13807636499404907
Validation loss: 1.6925143247009606

Epoch: 5| Step: 9
Training loss: 0.4767675995826721
Validation loss: 1.713295785329675

Epoch: 5| Step: 10
Training loss: 0.29308366775512695
Validation loss: 1.7203018921677784

Epoch: 378| Step: 0
Training loss: 0.29154515266418457
Validation loss: 1.746172188430704

Epoch: 5| Step: 1
Training loss: 0.23145003616809845
Validation loss: 1.7331488491386495

Epoch: 5| Step: 2
Training loss: 0.2762824594974518
Validation loss: 1.7381291376647128

Epoch: 5| Step: 3
Training loss: 0.18841418623924255
Validation loss: 1.716067192375019

Epoch: 5| Step: 4
Training loss: 0.2041664570569992
Validation loss: 1.6969551924736268

Epoch: 5| Step: 5
Training loss: 0.32801342010498047
Validation loss: 1.6985624195427023

Epoch: 5| Step: 6
Training loss: 0.12114252150058746
Validation loss: 1.6620764091450682

Epoch: 5| Step: 7
Training loss: 0.2073584496974945
Validation loss: 1.651523010705107

Epoch: 5| Step: 8
Training loss: 0.40092843770980835
Validation loss: 1.6783839169368948

Epoch: 5| Step: 9
Training loss: 0.3429057002067566
Validation loss: 1.6777849158933085

Epoch: 5| Step: 10
Training loss: 0.18091857433319092
Validation loss: 1.664036948193786

Epoch: 379| Step: 0
Training loss: 0.2035122811794281
Validation loss: 1.699369348505492

Epoch: 5| Step: 1
Training loss: 0.2663342356681824
Validation loss: 1.7256745317930817

Epoch: 5| Step: 2
Training loss: 0.333690345287323
Validation loss: 1.7317892069457679

Epoch: 5| Step: 3
Training loss: 0.28312018513679504
Validation loss: 1.7460827929999239

Epoch: 5| Step: 4
Training loss: 0.3513766825199127
Validation loss: 1.746104557027099

Epoch: 5| Step: 5
Training loss: 0.19041070342063904
Validation loss: 1.7290529384407947

Epoch: 5| Step: 6
Training loss: 0.23274078965187073
Validation loss: 1.7525561522412043

Epoch: 5| Step: 7
Training loss: 0.1733652949333191
Validation loss: 1.7368958470641926

Epoch: 5| Step: 8
Training loss: 0.23458552360534668
Validation loss: 1.7279114428386892

Epoch: 5| Step: 9
Training loss: 0.18254469335079193
Validation loss: 1.7203928757739324

Epoch: 5| Step: 10
Training loss: 0.39905497431755066
Validation loss: 1.7320350536736109

Epoch: 380| Step: 0
Training loss: 0.40588682889938354
Validation loss: 1.7041227356080086

Epoch: 5| Step: 1
Training loss: 0.3609979748725891
Validation loss: 1.7122327576401413

Epoch: 5| Step: 2
Training loss: 0.2975619435310364
Validation loss: 1.683211447090231

Epoch: 5| Step: 3
Training loss: 0.12574513256549835
Validation loss: 1.6689989515530166

Epoch: 5| Step: 4
Training loss: 0.1582457721233368
Validation loss: 1.6502085398602229

Epoch: 5| Step: 5
Training loss: 0.1536809355020523
Validation loss: 1.6360520534617926

Epoch: 5| Step: 6
Training loss: 0.25163885951042175
Validation loss: 1.6287360716891546

Epoch: 5| Step: 7
Training loss: 0.34017470479011536
Validation loss: 1.627728921110912

Epoch: 5| Step: 8
Training loss: 0.34375622868537903
Validation loss: 1.647774011858048

Epoch: 5| Step: 9
Training loss: 0.16613483428955078
Validation loss: 1.643460198115277

Epoch: 5| Step: 10
Training loss: 0.2250956892967224
Validation loss: 1.6328660493255944

Epoch: 381| Step: 0
Training loss: 0.2914206385612488
Validation loss: 1.6543481901127806

Epoch: 5| Step: 1
Training loss: 0.19864434003829956
Validation loss: 1.6589593906556406

Epoch: 5| Step: 2
Training loss: 0.23865313827991486
Validation loss: 1.669390477159972

Epoch: 5| Step: 3
Training loss: 0.22837774455547333
Validation loss: 1.6855818276764245

Epoch: 5| Step: 4
Training loss: 0.25102370977401733
Validation loss: 1.7095632783828243

Epoch: 5| Step: 5
Training loss: 0.2082149088382721
Validation loss: 1.7107360773189093

Epoch: 5| Step: 6
Training loss: 0.46191462874412537
Validation loss: 1.7322857572186379

Epoch: 5| Step: 7
Training loss: 0.30526986718177795
Validation loss: 1.721073647981049

Epoch: 5| Step: 8
Training loss: 0.27590325474739075
Validation loss: 1.7082853112169492

Epoch: 5| Step: 9
Training loss: 0.21985292434692383
Validation loss: 1.6671056914073166

Epoch: 5| Step: 10
Training loss: 0.168330579996109
Validation loss: 1.6743446947425924

Epoch: 382| Step: 0
Training loss: 0.19859519600868225
Validation loss: 1.6054844651170956

Epoch: 5| Step: 1
Training loss: 0.22408850491046906
Validation loss: 1.6223219107556086

Epoch: 5| Step: 2
Training loss: 0.4390704035758972
Validation loss: 1.5982175142534318

Epoch: 5| Step: 3
Training loss: 0.33077511191368103
Validation loss: 1.6082283604529597

Epoch: 5| Step: 4
Training loss: 0.2900879383087158
Validation loss: 1.6038882232481433

Epoch: 5| Step: 5
Training loss: 0.21916186809539795
Validation loss: 1.6240274931794854

Epoch: 5| Step: 6
Training loss: 0.16064372658729553
Validation loss: 1.6099612507768857

Epoch: 5| Step: 7
Training loss: 0.15421323478221893
Validation loss: 1.6319008681081957

Epoch: 5| Step: 8
Training loss: 0.2602371573448181
Validation loss: 1.6384669016766291

Epoch: 5| Step: 9
Training loss: 0.23081350326538086
Validation loss: 1.638948235460507

Epoch: 5| Step: 10
Training loss: 0.20155587792396545
Validation loss: 1.6551280854850687

Epoch: 383| Step: 0
Training loss: 0.22738173604011536
Validation loss: 1.6392365271045315

Epoch: 5| Step: 1
Training loss: 0.2887997627258301
Validation loss: 1.6316546599070232

Epoch: 5| Step: 2
Training loss: 0.3818594515323639
Validation loss: 1.6496755974267119

Epoch: 5| Step: 3
Training loss: 0.08429288864135742
Validation loss: 1.638536141764733

Epoch: 5| Step: 4
Training loss: 0.34470218420028687
Validation loss: 1.648869461910699

Epoch: 5| Step: 5
Training loss: 0.35972583293914795
Validation loss: 1.654097375049386

Epoch: 5| Step: 6
Training loss: 0.08287203311920166
Validation loss: 1.685802746844548

Epoch: 5| Step: 7
Training loss: 0.2861135005950928
Validation loss: 1.6778148284522436

Epoch: 5| Step: 8
Training loss: 0.14820745587348938
Validation loss: 1.7259823929878972

Epoch: 5| Step: 9
Training loss: 0.22833895683288574
Validation loss: 1.7451931840629988

Epoch: 5| Step: 10
Training loss: 0.4547436535358429
Validation loss: 1.7363825177633634

Epoch: 384| Step: 0
Training loss: 0.19257542490959167
Validation loss: 1.7577840179525397

Epoch: 5| Step: 1
Training loss: 0.1819102019071579
Validation loss: 1.7614262001488799

Epoch: 5| Step: 2
Training loss: 0.3182705342769623
Validation loss: 1.7584327164516653

Epoch: 5| Step: 3
Training loss: 0.38402122259140015
Validation loss: 1.7333617543661466

Epoch: 5| Step: 4
Training loss: 0.22026415169239044
Validation loss: 1.7051397485117759

Epoch: 5| Step: 5
Training loss: 0.2327510416507721
Validation loss: 1.685754196618193

Epoch: 5| Step: 6
Training loss: 0.35514384508132935
Validation loss: 1.7122539858664236

Epoch: 5| Step: 7
Training loss: 0.27090686559677124
Validation loss: 1.6844825424173826

Epoch: 5| Step: 8
Training loss: 0.30522775650024414
Validation loss: 1.7081252413411294

Epoch: 5| Step: 9
Training loss: 0.171428382396698
Validation loss: 1.6664591117571759

Epoch: 5| Step: 10
Training loss: 0.3995800018310547
Validation loss: 1.6691574486353065

Epoch: 385| Step: 0
Training loss: 0.2790650427341461
Validation loss: 1.6588183974706998

Epoch: 5| Step: 1
Training loss: 0.25117069482803345
Validation loss: 1.66671758954243

Epoch: 5| Step: 2
Training loss: 0.231743723154068
Validation loss: 1.6982117724675003

Epoch: 5| Step: 3
Training loss: 0.15028004348278046
Validation loss: 1.723770538965861

Epoch: 5| Step: 4
Training loss: 0.5414170026779175
Validation loss: 1.723745387087586

Epoch: 5| Step: 5
Training loss: 0.21736972033977509
Validation loss: 1.749217015440746

Epoch: 5| Step: 6
Training loss: 0.2371179163455963
Validation loss: 1.724806627919597

Epoch: 5| Step: 7
Training loss: 0.44923868775367737
Validation loss: 1.7054995849568357

Epoch: 5| Step: 8
Training loss: 0.26518750190734863
Validation loss: 1.6911958033038723

Epoch: 5| Step: 9
Training loss: 0.1438596546649933
Validation loss: 1.6788795250718311

Epoch: 5| Step: 10
Training loss: 0.18188613653182983
Validation loss: 1.643011881459144

Epoch: 386| Step: 0
Training loss: 0.18246307969093323
Validation loss: 1.6588686691817416

Epoch: 5| Step: 1
Training loss: 0.2240048348903656
Validation loss: 1.6978128392209288

Epoch: 5| Step: 2
Training loss: 0.29392868280410767
Validation loss: 1.6823591557882165

Epoch: 5| Step: 3
Training loss: 0.31371498107910156
Validation loss: 1.7299535338596632

Epoch: 5| Step: 4
Training loss: 0.20501437783241272
Validation loss: 1.7398727286246516

Epoch: 5| Step: 5
Training loss: 0.1327798068523407
Validation loss: 1.7721225830816454

Epoch: 5| Step: 6
Training loss: 0.2872445583343506
Validation loss: 1.7814720792155112

Epoch: 5| Step: 7
Training loss: 0.4925078749656677
Validation loss: 1.7677776685325048

Epoch: 5| Step: 8
Training loss: 0.20283620059490204
Validation loss: 1.7374461594448294

Epoch: 5| Step: 9
Training loss: 0.5502172112464905
Validation loss: 1.743293805788922

Epoch: 5| Step: 10
Training loss: 0.18004734814167023
Validation loss: 1.7080598108230098

Epoch: 387| Step: 0
Training loss: 0.23292335867881775
Validation loss: 1.7101316041843866

Epoch: 5| Step: 1
Training loss: 0.26351088285446167
Validation loss: 1.683156474944084

Epoch: 5| Step: 2
Training loss: 0.24229860305786133
Validation loss: 1.6835111251441381

Epoch: 5| Step: 3
Training loss: 0.22353017330169678
Validation loss: 1.671550113667724

Epoch: 5| Step: 4
Training loss: 0.25041472911834717
Validation loss: 1.6430050147477018

Epoch: 5| Step: 5
Training loss: 0.28322067856788635
Validation loss: 1.608453090472888

Epoch: 5| Step: 6
Training loss: 0.43335238099098206
Validation loss: 1.5959212036542996

Epoch: 5| Step: 7
Training loss: 0.3007945120334625
Validation loss: 1.6087381762842978

Epoch: 5| Step: 8
Training loss: 0.2560671865940094
Validation loss: 1.6381459005417363

Epoch: 5| Step: 9
Training loss: 0.32029110193252563
Validation loss: 1.6657256234076716

Epoch: 5| Step: 10
Training loss: 0.3348153531551361
Validation loss: 1.692550128506076

Epoch: 388| Step: 0
Training loss: 0.19641020894050598
Validation loss: 1.7243561744689941

Epoch: 5| Step: 1
Training loss: 0.3525469899177551
Validation loss: 1.7168758120588077

Epoch: 5| Step: 2
Training loss: 0.27240660786628723
Validation loss: 1.7149454778240574

Epoch: 5| Step: 3
Training loss: 0.2064301073551178
Validation loss: 1.7016220169682656

Epoch: 5| Step: 4
Training loss: 0.3274613916873932
Validation loss: 1.6663225902024137

Epoch: 5| Step: 5
Training loss: 0.3199600577354431
Validation loss: 1.674719338775963

Epoch: 5| Step: 6
Training loss: 0.2837142050266266
Validation loss: 1.6894915078275947

Epoch: 5| Step: 7
Training loss: 0.1722453534603119
Validation loss: 1.6693700705805132

Epoch: 5| Step: 8
Training loss: 0.17161628603935242
Validation loss: 1.6708128862483527

Epoch: 5| Step: 9
Training loss: 0.3164155185222626
Validation loss: 1.6768610285174461

Epoch: 5| Step: 10
Training loss: 0.17412498593330383
Validation loss: 1.7000643899363856

Epoch: 389| Step: 0
Training loss: 0.1121491938829422
Validation loss: 1.7227788945680023

Epoch: 5| Step: 1
Training loss: 0.30412185192108154
Validation loss: 1.7037720910964473

Epoch: 5| Step: 2
Training loss: 0.29843825101852417
Validation loss: 1.7124293055585635

Epoch: 5| Step: 3
Training loss: 0.10401134192943573
Validation loss: 1.711600071640425

Epoch: 5| Step: 4
Training loss: 0.41044721007347107
Validation loss: 1.6910946574262393

Epoch: 5| Step: 5
Training loss: 0.17348124086856842
Validation loss: 1.6735020478566487

Epoch: 5| Step: 6
Training loss: 0.1833394169807434
Validation loss: 1.6478714212294547

Epoch: 5| Step: 7
Training loss: 0.23115329444408417
Validation loss: 1.6335536504304538

Epoch: 5| Step: 8
Training loss: 0.3228343427181244
Validation loss: 1.6090088992990472

Epoch: 5| Step: 9
Training loss: 0.19104279577732086
Validation loss: 1.640133958990856

Epoch: 5| Step: 10
Training loss: 0.18667632341384888
Validation loss: 1.6190664486218524

Epoch: 390| Step: 0
Training loss: 0.20965218544006348
Validation loss: 1.633608764217746

Epoch: 5| Step: 1
Training loss: 0.3711053729057312
Validation loss: 1.643528453765377

Epoch: 5| Step: 2
Training loss: 0.16783542931079865
Validation loss: 1.6616242060097315

Epoch: 5| Step: 3
Training loss: 0.22713151574134827
Validation loss: 1.673005893666257

Epoch: 5| Step: 4
Training loss: 0.14352157711982727
Validation loss: 1.6623354445221603

Epoch: 5| Step: 5
Training loss: 0.19124451279640198
Validation loss: 1.6444334701825214

Epoch: 5| Step: 6
Training loss: 0.3470330238342285
Validation loss: 1.6526942304385606

Epoch: 5| Step: 7
Training loss: 0.19908416271209717
Validation loss: 1.654151073066137

Epoch: 5| Step: 8
Training loss: 0.15615642070770264
Validation loss: 1.6745737470606321

Epoch: 5| Step: 9
Training loss: 0.2845725417137146
Validation loss: 1.6730332502754786

Epoch: 5| Step: 10
Training loss: 0.2742534577846527
Validation loss: 1.6551134137697117

Epoch: 391| Step: 0
Training loss: 0.3684362471103668
Validation loss: 1.6763892891586467

Epoch: 5| Step: 1
Training loss: 0.20157337188720703
Validation loss: 1.6687514461496824

Epoch: 5| Step: 2
Training loss: 0.28866878151893616
Validation loss: 1.6957703533992972

Epoch: 5| Step: 3
Training loss: 0.18684625625610352
Validation loss: 1.6957785916584793

Epoch: 5| Step: 4
Training loss: 0.23171266913414001
Validation loss: 1.706453142627593

Epoch: 5| Step: 5
Training loss: 0.24681882560253143
Validation loss: 1.689495539152494

Epoch: 5| Step: 6
Training loss: 0.20010307431221008
Validation loss: 1.704421995788492

Epoch: 5| Step: 7
Training loss: 0.297124445438385
Validation loss: 1.702299920461511

Epoch: 5| Step: 8
Training loss: 0.09436450898647308
Validation loss: 1.6882329640849945

Epoch: 5| Step: 9
Training loss: 0.15423192083835602
Validation loss: 1.7051474099518151

Epoch: 5| Step: 10
Training loss: 0.24387648701667786
Validation loss: 1.6537182420812628

Epoch: 392| Step: 0
Training loss: 0.19193241000175476
Validation loss: 1.6302893533501575

Epoch: 5| Step: 1
Training loss: 0.13081638514995575
Validation loss: 1.6172375935380177

Epoch: 5| Step: 2
Training loss: 0.4220331609249115
Validation loss: 1.617591001654184

Epoch: 5| Step: 3
Training loss: 0.23560598492622375
Validation loss: 1.5890156440837409

Epoch: 5| Step: 4
Training loss: 0.1916799545288086
Validation loss: 1.6212681313996673

Epoch: 5| Step: 5
Training loss: 0.2153068333864212
Validation loss: 1.6057586311012186

Epoch: 5| Step: 6
Training loss: 0.276809960603714
Validation loss: 1.6365530349875008

Epoch: 5| Step: 7
Training loss: 0.22875924408435822
Validation loss: 1.6408074248221614

Epoch: 5| Step: 8
Training loss: 0.18501755595207214
Validation loss: 1.6519913327309392

Epoch: 5| Step: 9
Training loss: 0.23826555907726288
Validation loss: 1.6539338532314505

Epoch: 5| Step: 10
Training loss: 0.1831122636795044
Validation loss: 1.6804079419823104

Epoch: 393| Step: 0
Training loss: 0.3071820139884949
Validation loss: 1.6803823837669947

Epoch: 5| Step: 1
Training loss: 0.20603959262371063
Validation loss: 1.6644565225929342

Epoch: 5| Step: 2
Training loss: 0.14611151814460754
Validation loss: 1.6497753615020423

Epoch: 5| Step: 3
Training loss: 0.27149733901023865
Validation loss: 1.6583515597927956

Epoch: 5| Step: 4
Training loss: 0.1641729772090912
Validation loss: 1.6265143220142653

Epoch: 5| Step: 5
Training loss: 0.19466634094715118
Validation loss: 1.631188992531069

Epoch: 5| Step: 6
Training loss: 0.2446744441986084
Validation loss: 1.620031468329891

Epoch: 5| Step: 7
Training loss: 0.2254309207201004
Validation loss: 1.6123616906904406

Epoch: 5| Step: 8
Training loss: 0.2269497811794281
Validation loss: 1.6267369357488488

Epoch: 5| Step: 9
Training loss: 0.14099517464637756
Validation loss: 1.6245512872613885

Epoch: 5| Step: 10
Training loss: 0.2363300919532776
Validation loss: 1.6347934161463091

Epoch: 394| Step: 0
Training loss: 0.1661703884601593
Validation loss: 1.6349737951832433

Epoch: 5| Step: 1
Training loss: 0.22515888512134552
Validation loss: 1.6755356788635254

Epoch: 5| Step: 2
Training loss: 0.23352596163749695
Validation loss: 1.6859407655654415

Epoch: 5| Step: 3
Training loss: 0.22767619788646698
Validation loss: 1.66630555224675

Epoch: 5| Step: 4
Training loss: 0.2115917205810547
Validation loss: 1.654516944321253

Epoch: 5| Step: 5
Training loss: 0.3886326253414154
Validation loss: 1.6337462522650277

Epoch: 5| Step: 6
Training loss: 0.28051453828811646
Validation loss: 1.614264352347261

Epoch: 5| Step: 7
Training loss: 0.1620895117521286
Validation loss: 1.6172476237820042

Epoch: 5| Step: 8
Training loss: 0.23912551999092102
Validation loss: 1.6334395459903184

Epoch: 5| Step: 9
Training loss: 0.18848510086536407
Validation loss: 1.6420359387192676

Epoch: 5| Step: 10
Training loss: 0.18589435517787933
Validation loss: 1.6218637433103336

Epoch: 395| Step: 0
Training loss: 0.31065577268600464
Validation loss: 1.637712158182616

Epoch: 5| Step: 1
Training loss: 0.2764569818973541
Validation loss: 1.6608099681074902

Epoch: 5| Step: 2
Training loss: 0.24927659332752228
Validation loss: 1.6501263546687301

Epoch: 5| Step: 3
Training loss: 0.31676220893859863
Validation loss: 1.6270527301296112

Epoch: 5| Step: 4
Training loss: 0.07864777743816376
Validation loss: 1.636434906272478

Epoch: 5| Step: 5
Training loss: 0.17338719964027405
Validation loss: 1.6068164481911609

Epoch: 5| Step: 6
Training loss: 0.2009243667125702
Validation loss: 1.5905518967618224

Epoch: 5| Step: 7
Training loss: 0.352529913187027
Validation loss: 1.6217234057764853

Epoch: 5| Step: 8
Training loss: 0.11806149780750275
Validation loss: 1.6015287650528776

Epoch: 5| Step: 9
Training loss: 0.16940483450889587
Validation loss: 1.618632612689849

Epoch: 5| Step: 10
Training loss: 0.15106427669525146
Validation loss: 1.6130490482494395

Epoch: 396| Step: 0
Training loss: 0.38445836305618286
Validation loss: 1.668228216068719

Epoch: 5| Step: 1
Training loss: 0.15174585580825806
Validation loss: 1.6946936409960511

Epoch: 5| Step: 2
Training loss: 0.15540680289268494
Validation loss: 1.715933644643394

Epoch: 5| Step: 3
Training loss: 0.2421930581331253
Validation loss: 1.7314403339098858

Epoch: 5| Step: 4
Training loss: 0.33988070487976074
Validation loss: 1.6978253100508003

Epoch: 5| Step: 5
Training loss: 0.3737643361091614
Validation loss: 1.6831979597768476

Epoch: 5| Step: 6
Training loss: 0.18536674976348877
Validation loss: 1.6480931620444021

Epoch: 5| Step: 7
Training loss: 0.1783929169178009
Validation loss: 1.5990053120479788

Epoch: 5| Step: 8
Training loss: 0.2503129541873932
Validation loss: 1.5852918291604647

Epoch: 5| Step: 9
Training loss: 0.1889750212430954
Validation loss: 1.6105103338918378

Epoch: 5| Step: 10
Training loss: 0.15129166841506958
Validation loss: 1.6118447364017527

Epoch: 397| Step: 0
Training loss: 0.3186171054840088
Validation loss: 1.5788448651631672

Epoch: 5| Step: 1
Training loss: 0.18146789073944092
Validation loss: 1.6352775891621907

Epoch: 5| Step: 2
Training loss: 0.1322106420993805
Validation loss: 1.6468594061431063

Epoch: 5| Step: 3
Training loss: 0.2521008551120758
Validation loss: 1.669558531494551

Epoch: 5| Step: 4
Training loss: 0.1456882208585739
Validation loss: 1.7205252288490214

Epoch: 5| Step: 5
Training loss: 0.2941369414329529
Validation loss: 1.7149073205968386

Epoch: 5| Step: 6
Training loss: 0.33500951528549194
Validation loss: 1.6990504296877051

Epoch: 5| Step: 7
Training loss: 0.12031791359186172
Validation loss: 1.6817388816546368

Epoch: 5| Step: 8
Training loss: 0.22683486342430115
Validation loss: 1.6514603963462255

Epoch: 5| Step: 9
Training loss: 0.3824755549430847
Validation loss: 1.657304807375836

Epoch: 5| Step: 10
Training loss: 0.3549744486808777
Validation loss: 1.6443232925989295

Epoch: 398| Step: 0
Training loss: 0.41865357756614685
Validation loss: 1.6322379612153577

Epoch: 5| Step: 1
Training loss: 0.16128243505954742
Validation loss: 1.6403557741513817

Epoch: 5| Step: 2
Training loss: 0.2538122534751892
Validation loss: 1.6595097434136175

Epoch: 5| Step: 3
Training loss: 0.4503951966762543
Validation loss: 1.677628715833028

Epoch: 5| Step: 4
Training loss: 0.302449494600296
Validation loss: 1.668976519697456

Epoch: 5| Step: 5
Training loss: 0.22157295048236847
Validation loss: 1.6488774316285246

Epoch: 5| Step: 6
Training loss: 0.22046026587486267
Validation loss: 1.6888780542599258

Epoch: 5| Step: 7
Training loss: 0.13781966269016266
Validation loss: 1.6708374279801563

Epoch: 5| Step: 8
Training loss: 0.2561718821525574
Validation loss: 1.7165684917921662

Epoch: 5| Step: 9
Training loss: 0.25119051337242126
Validation loss: 1.7171130411086544

Epoch: 5| Step: 10
Training loss: 0.2979128360748291
Validation loss: 1.702004999242803

Epoch: 399| Step: 0
Training loss: 0.1523549109697342
Validation loss: 1.693186665094027

Epoch: 5| Step: 1
Training loss: 0.2789638340473175
Validation loss: 1.6511523851784327

Epoch: 5| Step: 2
Training loss: 0.13364441692829132
Validation loss: 1.6317190765052714

Epoch: 5| Step: 3
Training loss: 0.3155687749385834
Validation loss: 1.591327803109282

Epoch: 5| Step: 4
Training loss: 0.2969786524772644
Validation loss: 1.5790671199880622

Epoch: 5| Step: 5
Training loss: 0.23513217270374298
Validation loss: 1.593707779402374

Epoch: 5| Step: 6
Training loss: 0.3078753352165222
Validation loss: 1.5862591785769309

Epoch: 5| Step: 7
Training loss: 0.2620200514793396
Validation loss: 1.6249311611216555

Epoch: 5| Step: 8
Training loss: 0.32757917046546936
Validation loss: 1.6388380104495632

Epoch: 5| Step: 9
Training loss: 0.15727844834327698
Validation loss: 1.6705854990149056

Epoch: 5| Step: 10
Training loss: 0.16454435884952545
Validation loss: 1.6956576865206483

Epoch: 400| Step: 0
Training loss: 0.24903130531311035
Validation loss: 1.7194843612691408

Epoch: 5| Step: 1
Training loss: 0.18781475722789764
Validation loss: 1.7284075380653463

Epoch: 5| Step: 2
Training loss: 0.36096006631851196
Validation loss: 1.7238580347389303

Epoch: 5| Step: 3
Training loss: 0.17694680392742157
Validation loss: 1.6858073703704342

Epoch: 5| Step: 4
Training loss: 0.25368157029151917
Validation loss: 1.6947016716003418

Epoch: 5| Step: 5
Training loss: 0.1292678862810135
Validation loss: 1.6611584912064254

Epoch: 5| Step: 6
Training loss: 0.20437303185462952
Validation loss: 1.6582356729815084

Epoch: 5| Step: 7
Training loss: 0.11766333878040314
Validation loss: 1.6627456308693014

Epoch: 5| Step: 8
Training loss: 0.44053521752357483
Validation loss: 1.6545855870810888

Epoch: 5| Step: 9
Training loss: 0.258159339427948
Validation loss: 1.6696721623020787

Epoch: 5| Step: 10
Training loss: 0.26277872920036316
Validation loss: 1.6815762058381112

Epoch: 401| Step: 0
Training loss: 0.17234420776367188
Validation loss: 1.6577283233724616

Epoch: 5| Step: 1
Training loss: 0.1800580620765686
Validation loss: 1.6836916720995339

Epoch: 5| Step: 2
Training loss: 0.21217584609985352
Validation loss: 1.6804912577393234

Epoch: 5| Step: 3
Training loss: 0.17004849016666412
Validation loss: 1.664771237680989

Epoch: 5| Step: 4
Training loss: 0.14599797129631042
Validation loss: 1.6754309310707995

Epoch: 5| Step: 5
Training loss: 0.30080467462539673
Validation loss: 1.6599583177156345

Epoch: 5| Step: 6
Training loss: 0.10983039438724518
Validation loss: 1.6549266525494155

Epoch: 5| Step: 7
Training loss: 0.16489312052726746
Validation loss: 1.6247296679404475

Epoch: 5| Step: 8
Training loss: 0.42673200368881226
Validation loss: 1.6161269302009253

Epoch: 5| Step: 9
Training loss: 0.19296471774578094
Validation loss: 1.6480216441615936

Epoch: 5| Step: 10
Training loss: 0.3081822395324707
Validation loss: 1.6633846580341298

Epoch: 402| Step: 0
Training loss: 0.316945344209671
Validation loss: 1.6716227531433105

Epoch: 5| Step: 1
Training loss: 0.2921045422554016
Validation loss: 1.6574797220127557

Epoch: 5| Step: 2
Training loss: 0.16130013763904572
Validation loss: 1.6745524919161232

Epoch: 5| Step: 3
Training loss: 0.17828360199928284
Validation loss: 1.6690323814269035

Epoch: 5| Step: 4
Training loss: 0.19527578353881836
Validation loss: 1.662673960449875

Epoch: 5| Step: 5
Training loss: 0.3126903176307678
Validation loss: 1.633788429280763

Epoch: 5| Step: 6
Training loss: 0.15672577917575836
Validation loss: 1.6377913746782529

Epoch: 5| Step: 7
Training loss: 0.3649718761444092
Validation loss: 1.635752695862965

Epoch: 5| Step: 8
Training loss: 0.24616019427776337
Validation loss: 1.6214774718848608

Epoch: 5| Step: 9
Training loss: 0.24754612147808075
Validation loss: 1.6412210361931914

Epoch: 5| Step: 10
Training loss: 0.17785179615020752
Validation loss: 1.6343357639928018

Epoch: 403| Step: 0
Training loss: 0.19144420325756073
Validation loss: 1.6871606278163132

Epoch: 5| Step: 1
Training loss: 0.363686740398407
Validation loss: 1.681063316201651

Epoch: 5| Step: 2
Training loss: 0.28142663836479187
Validation loss: 1.6821546939111525

Epoch: 5| Step: 3
Training loss: 0.1728387176990509
Validation loss: 1.7448496767269668

Epoch: 5| Step: 4
Training loss: 0.2845478653907776
Validation loss: 1.7369036918045373

Epoch: 5| Step: 5
Training loss: 0.2354932576417923
Validation loss: 1.7511087027929162

Epoch: 5| Step: 6
Training loss: 0.14976027607917786
Validation loss: 1.7194624248371329

Epoch: 5| Step: 7
Training loss: 0.27694064378738403
Validation loss: 1.7260188646213983

Epoch: 5| Step: 8
Training loss: 0.22370783984661102
Validation loss: 1.7256106997048983

Epoch: 5| Step: 9
Training loss: 0.28016743063926697
Validation loss: 1.6666314377579639

Epoch: 5| Step: 10
Training loss: 0.13455092906951904
Validation loss: 1.6433451893509075

Epoch: 404| Step: 0
Training loss: 0.14304152131080627
Validation loss: 1.6407234194458171

Epoch: 5| Step: 1
Training loss: 0.20201165974140167
Validation loss: 1.6046221128074072

Epoch: 5| Step: 2
Training loss: 0.40268293023109436
Validation loss: 1.5888563817547214

Epoch: 5| Step: 3
Training loss: 0.2272600680589676
Validation loss: 1.5735080652339484

Epoch: 5| Step: 4
Training loss: 0.282320499420166
Validation loss: 1.5899716743858912

Epoch: 5| Step: 5
Training loss: 0.22120115160942078
Validation loss: 1.6066787883799563

Epoch: 5| Step: 6
Training loss: 0.1770573854446411
Validation loss: 1.6300927746680476

Epoch: 5| Step: 7
Training loss: 0.1479020118713379
Validation loss: 1.6641983678264003

Epoch: 5| Step: 8
Training loss: 0.3702126443386078
Validation loss: 1.6968845923741658

Epoch: 5| Step: 9
Training loss: 0.191313698887825
Validation loss: 1.7042502581432302

Epoch: 5| Step: 10
Training loss: 0.21921461820602417
Validation loss: 1.7033228694751699

Epoch: 405| Step: 0
Training loss: 0.1738409847021103
Validation loss: 1.6939707212550665

Epoch: 5| Step: 1
Training loss: 0.1260160654783249
Validation loss: 1.639095446114899

Epoch: 5| Step: 2
Training loss: 0.16814133524894714
Validation loss: 1.6580725703188168

Epoch: 5| Step: 3
Training loss: 0.16126221418380737
Validation loss: 1.6601785036825365

Epoch: 5| Step: 4
Training loss: 0.22989001870155334
Validation loss: 1.6459224326636201

Epoch: 5| Step: 5
Training loss: 0.28987812995910645
Validation loss: 1.6425155708866734

Epoch: 5| Step: 6
Training loss: 0.1585489958524704
Validation loss: 1.6597669470694758

Epoch: 5| Step: 7
Training loss: 0.2407546043395996
Validation loss: 1.6384351138145692

Epoch: 5| Step: 8
Training loss: 0.29402291774749756
Validation loss: 1.6325435561518515

Epoch: 5| Step: 9
Training loss: 0.1811009645462036
Validation loss: 1.6604878819116982

Epoch: 5| Step: 10
Training loss: 0.30751582980155945
Validation loss: 1.6464115214604202

Epoch: 406| Step: 0
Training loss: 0.11509597301483154
Validation loss: 1.6606241579978698

Epoch: 5| Step: 1
Training loss: 0.1908445954322815
Validation loss: 1.6394849977185648

Epoch: 5| Step: 2
Training loss: 0.20977143943309784
Validation loss: 1.63530610710062

Epoch: 5| Step: 3
Training loss: 0.3993520140647888
Validation loss: 1.626487067950669

Epoch: 5| Step: 4
Training loss: 0.1034746915102005
Validation loss: 1.6119558683005712

Epoch: 5| Step: 5
Training loss: 0.20124492049217224
Validation loss: 1.6240170976167083

Epoch: 5| Step: 6
Training loss: 0.23912420868873596
Validation loss: 1.6303028906545332

Epoch: 5| Step: 7
Training loss: 0.13814404606819153
Validation loss: 1.6327169902863041

Epoch: 5| Step: 8
Training loss: 0.26944535970687866
Validation loss: 1.642568629275086

Epoch: 5| Step: 9
Training loss: 0.13100314140319824
Validation loss: 1.6431928526970647

Epoch: 5| Step: 10
Training loss: 0.2189270406961441
Validation loss: 1.6629056648541523

Epoch: 407| Step: 0
Training loss: 0.1389494240283966
Validation loss: 1.6727505794135473

Epoch: 5| Step: 1
Training loss: 0.12038011848926544
Validation loss: 1.6628637647116056

Epoch: 5| Step: 2
Training loss: 0.20583704113960266
Validation loss: 1.6409868912030292

Epoch: 5| Step: 3
Training loss: 0.23918981850147247
Validation loss: 1.6569632022611556

Epoch: 5| Step: 4
Training loss: 0.23514986038208008
Validation loss: 1.6540957099647933

Epoch: 5| Step: 5
Training loss: 0.25303027033805847
Validation loss: 1.6361030635013376

Epoch: 5| Step: 6
Training loss: 0.1842961311340332
Validation loss: 1.629759806458668

Epoch: 5| Step: 7
Training loss: 0.17254802584648132
Validation loss: 1.6438183079483688

Epoch: 5| Step: 8
Training loss: 0.24209952354431152
Validation loss: 1.6367096311302596

Epoch: 5| Step: 9
Training loss: 0.26235446333885193
Validation loss: 1.6601496960527153

Epoch: 5| Step: 10
Training loss: 0.14640524983406067
Validation loss: 1.6539144323718162

Epoch: 408| Step: 0
Training loss: 0.22133879363536835
Validation loss: 1.6532256500695341

Epoch: 5| Step: 1
Training loss: 0.1615004986524582
Validation loss: 1.628442152853935

Epoch: 5| Step: 2
Training loss: 0.15792039036750793
Validation loss: 1.6245730089884933

Epoch: 5| Step: 3
Training loss: 0.4640270173549652
Validation loss: 1.6180959427228538

Epoch: 5| Step: 4
Training loss: 0.2629997134208679
Validation loss: 1.627465291689801

Epoch: 5| Step: 5
Training loss: 0.10804009437561035
Validation loss: 1.6284244227153

Epoch: 5| Step: 6
Training loss: 0.18121172487735748
Validation loss: 1.6207033818767917

Epoch: 5| Step: 7
Training loss: 0.19300955533981323
Validation loss: 1.6162353049042404

Epoch: 5| Step: 8
Training loss: 0.13094167411327362
Validation loss: 1.6248724614420245

Epoch: 5| Step: 9
Training loss: 0.11753107607364655
Validation loss: 1.6292187706116708

Epoch: 5| Step: 10
Training loss: 0.1791086494922638
Validation loss: 1.6331288711999052

Epoch: 409| Step: 0
Training loss: 0.3152613043785095
Validation loss: 1.6311394604303504

Epoch: 5| Step: 1
Training loss: 0.15924318134784698
Validation loss: 1.627769454833

Epoch: 5| Step: 2
Training loss: 0.19456805288791656
Validation loss: 1.6192719692824988

Epoch: 5| Step: 3
Training loss: 0.27069878578186035
Validation loss: 1.6279238167629446

Epoch: 5| Step: 4
Training loss: 0.30456167459487915
Validation loss: 1.6248961340996526

Epoch: 5| Step: 5
Training loss: 0.09310109168291092
Validation loss: 1.6413654486338298

Epoch: 5| Step: 6
Training loss: 0.14071024954319
Validation loss: 1.628066147527387

Epoch: 5| Step: 7
Training loss: 0.1462395191192627
Validation loss: 1.6425165386610134

Epoch: 5| Step: 8
Training loss: 0.18278485536575317
Validation loss: 1.639417887374919

Epoch: 5| Step: 9
Training loss: 0.11356103420257568
Validation loss: 1.6259723453111545

Epoch: 5| Step: 10
Training loss: 0.2098877876996994
Validation loss: 1.6257060638038061

Epoch: 410| Step: 0
Training loss: 0.15374824404716492
Validation loss: 1.6223402612952775

Epoch: 5| Step: 1
Training loss: 0.17109255492687225
Validation loss: 1.615876131160285

Epoch: 5| Step: 2
Training loss: 0.13799342513084412
Validation loss: 1.5840693737870903

Epoch: 5| Step: 3
Training loss: 0.22624003887176514
Validation loss: 1.5970550531982093

Epoch: 5| Step: 4
Training loss: 0.24601802229881287
Validation loss: 1.5858901828847907

Epoch: 5| Step: 5
Training loss: 0.22537016868591309
Validation loss: 1.5908887411958428

Epoch: 5| Step: 6
Training loss: 0.12266351282596588
Validation loss: 1.608859960750867

Epoch: 5| Step: 7
Training loss: 0.2096177637577057
Validation loss: 1.6065583203428535

Epoch: 5| Step: 8
Training loss: 0.34569859504699707
Validation loss: 1.608034582548244

Epoch: 5| Step: 9
Training loss: 0.1891104280948639
Validation loss: 1.6316255343857633

Epoch: 5| Step: 10
Training loss: 0.1607840657234192
Validation loss: 1.6416276167797785

Epoch: 411| Step: 0
Training loss: 0.17571356892585754
Validation loss: 1.6490332426563385

Epoch: 5| Step: 1
Training loss: 0.11250852048397064
Validation loss: 1.666856995192907

Epoch: 5| Step: 2
Training loss: 0.24624140560626984
Validation loss: 1.6760870564368464

Epoch: 5| Step: 3
Training loss: 0.1837650090456009
Validation loss: 1.6571172539905836

Epoch: 5| Step: 4
Training loss: 0.16178083419799805
Validation loss: 1.6565732532931912

Epoch: 5| Step: 5
Training loss: 0.16967281699180603
Validation loss: 1.652279644884089

Epoch: 5| Step: 6
Training loss: 0.19668616354465485
Validation loss: 1.6620708050266388

Epoch: 5| Step: 7
Training loss: 0.15932556986808777
Validation loss: 1.643129171863679

Epoch: 5| Step: 8
Training loss: 0.3474520742893219
Validation loss: 1.6426776750113374

Epoch: 5| Step: 9
Training loss: 0.20979467034339905
Validation loss: 1.66336380281756

Epoch: 5| Step: 10
Training loss: 0.21820341050624847
Validation loss: 1.648353172245846

Epoch: 412| Step: 0
Training loss: 0.2612692713737488
Validation loss: 1.6764321891210412

Epoch: 5| Step: 1
Training loss: 0.15375916659832
Validation loss: 1.6633117506580968

Epoch: 5| Step: 2
Training loss: 0.3997716009616852
Validation loss: 1.6635543864260438

Epoch: 5| Step: 3
Training loss: 0.12362813949584961
Validation loss: 1.6803936189220798

Epoch: 5| Step: 4
Training loss: 0.14778050780296326
Validation loss: 1.687243705154747

Epoch: 5| Step: 5
Training loss: 0.16661468148231506
Validation loss: 1.7010782687894759

Epoch: 5| Step: 6
Training loss: 0.3083662986755371
Validation loss: 1.735739605401152

Epoch: 5| Step: 7
Training loss: 0.1566959023475647
Validation loss: 1.7545160273069977

Epoch: 5| Step: 8
Training loss: 0.2396681010723114
Validation loss: 1.7193564926424334

Epoch: 5| Step: 9
Training loss: 0.1661030799150467
Validation loss: 1.696418640434101

Epoch: 5| Step: 10
Training loss: 0.15008516609668732
Validation loss: 1.679350604293167

Epoch: 413| Step: 0
Training loss: 0.26070696115493774
Validation loss: 1.6656851986403107

Epoch: 5| Step: 1
Training loss: 0.2638179361820221
Validation loss: 1.639655855394179

Epoch: 5| Step: 2
Training loss: 0.168723925948143
Validation loss: 1.6224380129127092

Epoch: 5| Step: 3
Training loss: 0.11722671985626221
Validation loss: 1.6278843213153142

Epoch: 5| Step: 4
Training loss: 0.16181595623493195
Validation loss: 1.6127198139826457

Epoch: 5| Step: 5
Training loss: 0.14065292477607727
Validation loss: 1.601150453731578

Epoch: 5| Step: 6
Training loss: 0.29381951689720154
Validation loss: 1.623898567691926

Epoch: 5| Step: 7
Training loss: 0.1518450677394867
Validation loss: 1.6229053620369203

Epoch: 5| Step: 8
Training loss: 0.1806507557630539
Validation loss: 1.609717233206636

Epoch: 5| Step: 9
Training loss: 0.17929178476333618
Validation loss: 1.604924545493177

Epoch: 5| Step: 10
Training loss: 0.1629740446805954
Validation loss: 1.5993698091917141

Epoch: 414| Step: 0
Training loss: 0.2859691381454468
Validation loss: 1.6142127001157371

Epoch: 5| Step: 1
Training loss: 0.30239954590797424
Validation loss: 1.597123146057129

Epoch: 5| Step: 2
Training loss: 0.09463272988796234
Validation loss: 1.6245008155863772

Epoch: 5| Step: 3
Training loss: 0.14215901494026184
Validation loss: 1.6044002694468344

Epoch: 5| Step: 4
Training loss: 0.21710272133350372
Validation loss: 1.6250710795002599

Epoch: 5| Step: 5
Training loss: 0.12077458947896957
Validation loss: 1.612414013954901

Epoch: 5| Step: 6
Training loss: 0.15250954031944275
Validation loss: 1.6292177182371899

Epoch: 5| Step: 7
Training loss: 0.2764633893966675
Validation loss: 1.6335494774644093

Epoch: 5| Step: 8
Training loss: 0.10581549257040024
Validation loss: 1.6162203229883665

Epoch: 5| Step: 9
Training loss: 0.18630777299404144
Validation loss: 1.6252309929940008

Epoch: 5| Step: 10
Training loss: 0.11114335060119629
Validation loss: 1.6288713050144974

Epoch: 415| Step: 0
Training loss: 0.13363178074359894
Validation loss: 1.6056615319303287

Epoch: 5| Step: 1
Training loss: 0.23399968445301056
Validation loss: 1.6090337050858365

Epoch: 5| Step: 2
Training loss: 0.223307803273201
Validation loss: 1.61267057541878

Epoch: 5| Step: 3
Training loss: 0.17314715683460236
Validation loss: 1.6063446229504001

Epoch: 5| Step: 4
Training loss: 0.14155785739421844
Validation loss: 1.626357065734043

Epoch: 5| Step: 5
Training loss: 0.12200579792261124
Validation loss: 1.615992388417644

Epoch: 5| Step: 6
Training loss: 0.22618210315704346
Validation loss: 1.6016927342261038

Epoch: 5| Step: 7
Training loss: 0.18797215819358826
Validation loss: 1.6070669274176321

Epoch: 5| Step: 8
Training loss: 0.20400314033031464
Validation loss: 1.6001656311814503

Epoch: 5| Step: 9
Training loss: 0.14372576773166656
Validation loss: 1.6104010023096555

Epoch: 5| Step: 10
Training loss: 0.11312059313058853
Validation loss: 1.6079685559836767

Epoch: 416| Step: 0
Training loss: 0.2336619347333908
Validation loss: 1.575139714825538

Epoch: 5| Step: 1
Training loss: 0.15135353803634644
Validation loss: 1.6218981460858417

Epoch: 5| Step: 2
Training loss: 0.08847087621688843
Validation loss: 1.5853717634754796

Epoch: 5| Step: 3
Training loss: 0.24851751327514648
Validation loss: 1.5860015576885593

Epoch: 5| Step: 4
Training loss: 0.14961528778076172
Validation loss: 1.6367688358470958

Epoch: 5| Step: 5
Training loss: 0.15255123376846313
Validation loss: 1.6516622894553727

Epoch: 5| Step: 6
Training loss: 0.18811945617198944
Validation loss: 1.6218011956061087

Epoch: 5| Step: 7
Training loss: 0.1911328285932541
Validation loss: 1.6375007283303045

Epoch: 5| Step: 8
Training loss: 0.22467398643493652
Validation loss: 1.6390902996063232

Epoch: 5| Step: 9
Training loss: 0.2639104723930359
Validation loss: 1.6351348661607312

Epoch: 5| Step: 10
Training loss: 0.1173730120062828
Validation loss: 1.627217568377013

Epoch: 417| Step: 0
Training loss: 0.22385044395923615
Validation loss: 1.6257869005203247

Epoch: 5| Step: 1
Training loss: 0.1993575394153595
Validation loss: 1.6035841408596243

Epoch: 5| Step: 2
Training loss: 0.16881825029850006
Validation loss: 1.6043306396853538

Epoch: 5| Step: 3
Training loss: 0.20466089248657227
Validation loss: 1.603648926622124

Epoch: 5| Step: 4
Training loss: 0.2875376045703888
Validation loss: 1.6321622344755358

Epoch: 5| Step: 5
Training loss: 0.26751846075057983
Validation loss: 1.6238901063960085

Epoch: 5| Step: 6
Training loss: 0.1659417748451233
Validation loss: 1.6412652769396383

Epoch: 5| Step: 7
Training loss: 0.21049630641937256
Validation loss: 1.657152695040549

Epoch: 5| Step: 8
Training loss: 0.23117022216320038
Validation loss: 1.665785087052212

Epoch: 5| Step: 9
Training loss: 0.17141957581043243
Validation loss: 1.6547932676089707

Epoch: 5| Step: 10
Training loss: 0.1291886419057846
Validation loss: 1.6315474010282947

Epoch: 418| Step: 0
Training loss: 0.1706123650074005
Validation loss: 1.632120209355508

Epoch: 5| Step: 1
Training loss: 0.18783359229564667
Validation loss: 1.6175411298710813

Epoch: 5| Step: 2
Training loss: 0.17200520634651184
Validation loss: 1.614393267580258

Epoch: 5| Step: 3
Training loss: 0.09244952350854874
Validation loss: 1.6221021144620833

Epoch: 5| Step: 4
Training loss: 0.24519118666648865
Validation loss: 1.6041822741108556

Epoch: 5| Step: 5
Training loss: 0.25825533270835876
Validation loss: 1.6271185785211542

Epoch: 5| Step: 6
Training loss: 0.1723824441432953
Validation loss: 1.6251379033570648

Epoch: 5| Step: 7
Training loss: 0.23712973296642303
Validation loss: 1.6481532665991014

Epoch: 5| Step: 8
Training loss: 0.2689903974533081
Validation loss: 1.6676968297650736

Epoch: 5| Step: 9
Training loss: 0.17191563546657562
Validation loss: 1.6895034185019873

Epoch: 5| Step: 10
Training loss: 0.13755425810813904
Validation loss: 1.6699651697630524

Epoch: 419| Step: 0
Training loss: 0.2683711647987366
Validation loss: 1.6767956864449285

Epoch: 5| Step: 1
Training loss: 0.17076489329338074
Validation loss: 1.6724163357929518

Epoch: 5| Step: 2
Training loss: 0.11915276944637299
Validation loss: 1.643899179274036

Epoch: 5| Step: 3
Training loss: 0.22460821270942688
Validation loss: 1.6503029600266488

Epoch: 5| Step: 4
Training loss: 0.11265547573566437
Validation loss: 1.6450982568084553

Epoch: 5| Step: 5
Training loss: 0.20261064171791077
Validation loss: 1.6112211071034914

Epoch: 5| Step: 6
Training loss: 0.18101105093955994
Validation loss: 1.6565745287044074

Epoch: 5| Step: 7
Training loss: 0.1898917406797409
Validation loss: 1.6271797636503815

Epoch: 5| Step: 8
Training loss: 0.14682377874851227
Validation loss: 1.6491876340681506

Epoch: 5| Step: 9
Training loss: 0.13355202972888947
Validation loss: 1.6353830650288572

Epoch: 5| Step: 10
Training loss: 0.260457307100296
Validation loss: 1.6555263534668954

Epoch: 420| Step: 0
Training loss: 0.19822284579277039
Validation loss: 1.6417430780267204

Epoch: 5| Step: 1
Training loss: 0.1230795830488205
Validation loss: 1.6234093199494064

Epoch: 5| Step: 2
Training loss: 0.21981129050254822
Validation loss: 1.6072117949044833

Epoch: 5| Step: 3
Training loss: 0.1488054394721985
Validation loss: 1.6096684830163115

Epoch: 5| Step: 4
Training loss: 0.1374342143535614
Validation loss: 1.5811421320002566

Epoch: 5| Step: 5
Training loss: 0.1837107390165329
Validation loss: 1.6011935587852233

Epoch: 5| Step: 6
Training loss: 0.3016647696495056
Validation loss: 1.5770343093461887

Epoch: 5| Step: 7
Training loss: 0.1718887835741043
Validation loss: 1.580973776437903

Epoch: 5| Step: 8
Training loss: 0.17795108258724213
Validation loss: 1.6033095134201871

Epoch: 5| Step: 9
Training loss: 0.14422295987606049
Validation loss: 1.6060906180771448

Epoch: 5| Step: 10
Training loss: 0.15762034058570862
Validation loss: 1.6238391796747844

Epoch: 421| Step: 0
Training loss: 0.17542055249214172
Validation loss: 1.6083151396884714

Epoch: 5| Step: 1
Training loss: 0.11567951738834381
Validation loss: 1.638958058049602

Epoch: 5| Step: 2
Training loss: 0.1788330376148224
Validation loss: 1.666669882753844

Epoch: 5| Step: 3
Training loss: 0.21355760097503662
Validation loss: 1.6789993739897204

Epoch: 5| Step: 4
Training loss: 0.1692332923412323
Validation loss: 1.675331929678558

Epoch: 5| Step: 5
Training loss: 0.16497927904129028
Validation loss: 1.6804303674287693

Epoch: 5| Step: 6
Training loss: 0.37007418274879456
Validation loss: 1.6700951591614754

Epoch: 5| Step: 7
Training loss: 0.18183711171150208
Validation loss: 1.663305332583766

Epoch: 5| Step: 8
Training loss: 0.10528787225484848
Validation loss: 1.6687111495643534

Epoch: 5| Step: 9
Training loss: 0.12454773485660553
Validation loss: 1.6714387350184943

Epoch: 5| Step: 10
Training loss: 0.19948391616344452
Validation loss: 1.640559797645897

Epoch: 422| Step: 0
Training loss: 0.29582080245018005
Validation loss: 1.6150908861109006

Epoch: 5| Step: 1
Training loss: 0.08851814270019531
Validation loss: 1.5869978704760153

Epoch: 5| Step: 2
Training loss: 0.15390044450759888
Validation loss: 1.5912422428848922

Epoch: 5| Step: 3
Training loss: 0.23334893584251404
Validation loss: 1.593207263177441

Epoch: 5| Step: 4
Training loss: 0.13166967034339905
Validation loss: 1.5908572045705651

Epoch: 5| Step: 5
Training loss: 0.18258331716060638
Validation loss: 1.5770127593830068

Epoch: 5| Step: 6
Training loss: 0.21368253231048584
Validation loss: 1.601470826774515

Epoch: 5| Step: 7
Training loss: 0.14612552523612976
Validation loss: 1.6258082005285448

Epoch: 5| Step: 8
Training loss: 0.15039199590682983
Validation loss: 1.6526879802826913

Epoch: 5| Step: 9
Training loss: 0.11104588210582733
Validation loss: 1.65595035142796

Epoch: 5| Step: 10
Training loss: 0.18870481848716736
Validation loss: 1.6464729911537581

Epoch: 423| Step: 0
Training loss: 0.26040706038475037
Validation loss: 1.6613855387574883

Epoch: 5| Step: 1
Training loss: 0.22539369761943817
Validation loss: 1.6339605937721908

Epoch: 5| Step: 2
Training loss: 0.16239787638187408
Validation loss: 1.6156596195313238

Epoch: 5| Step: 3
Training loss: 0.09648257493972778
Validation loss: 1.622805009606064

Epoch: 5| Step: 4
Training loss: 0.1423141062259674
Validation loss: 1.61443397947537

Epoch: 5| Step: 5
Training loss: 0.11046459525823593
Validation loss: 1.6314798349975257

Epoch: 5| Step: 6
Training loss: 0.1554078608751297
Validation loss: 1.6093108372021747

Epoch: 5| Step: 7
Training loss: 0.13910017907619476
Validation loss: 1.6314418315887451

Epoch: 5| Step: 8
Training loss: 0.15030887722969055
Validation loss: 1.6272763911113943

Epoch: 5| Step: 9
Training loss: 0.2902924120426178
Validation loss: 1.6187475573632024

Epoch: 5| Step: 10
Training loss: 0.10043845325708389
Validation loss: 1.6325640306677869

Epoch: 424| Step: 0
Training loss: 0.09770704805850983
Validation loss: 1.6292661389996927

Epoch: 5| Step: 1
Training loss: 0.1828213334083557
Validation loss: 1.633478795328448

Epoch: 5| Step: 2
Training loss: 0.165288046002388
Validation loss: 1.6188127917628135

Epoch: 5| Step: 3
Training loss: 0.15481629967689514
Validation loss: 1.6031693886685114

Epoch: 5| Step: 4
Training loss: 0.17496927082538605
Validation loss: 1.5884982450034029

Epoch: 5| Step: 5
Training loss: 0.34171923995018005
Validation loss: 1.5827240187634704

Epoch: 5| Step: 6
Training loss: 0.15814052522182465
Validation loss: 1.5834574648129043

Epoch: 5| Step: 7
Training loss: 0.2669345736503601
Validation loss: 1.6011238719827385

Epoch: 5| Step: 8
Training loss: 0.08781884610652924
Validation loss: 1.5895196084053285

Epoch: 5| Step: 9
Training loss: 0.11624817550182343
Validation loss: 1.58868375901253

Epoch: 5| Step: 10
Training loss: 0.128391295671463
Validation loss: 1.6008860654728387

Epoch: 425| Step: 0
Training loss: 0.08416919410228729
Validation loss: 1.583924191613351

Epoch: 5| Step: 1
Training loss: 0.18400391936302185
Validation loss: 1.6026549736658733

Epoch: 5| Step: 2
Training loss: 0.3660085201263428
Validation loss: 1.5781178923063381

Epoch: 5| Step: 3
Training loss: 0.16935673356056213
Validation loss: 1.5684876070227673

Epoch: 5| Step: 4
Training loss: 0.1423504799604416
Validation loss: 1.5674249574702273

Epoch: 5| Step: 5
Training loss: 0.08025967329740524
Validation loss: 1.5557207484399118

Epoch: 5| Step: 6
Training loss: 0.12322399765253067
Validation loss: 1.5736163482871106

Epoch: 5| Step: 7
Training loss: 0.13266171514987946
Validation loss: 1.5860354656814246

Epoch: 5| Step: 8
Training loss: 0.08686285465955734
Validation loss: 1.5873549907438216

Epoch: 5| Step: 9
Training loss: 0.22611065208911896
Validation loss: 1.5845924372314124

Epoch: 5| Step: 10
Training loss: 0.08289100229740143
Validation loss: 1.6088808864675543

Epoch: 426| Step: 0
Training loss: 0.1227974072098732
Validation loss: 1.615459660048126

Epoch: 5| Step: 1
Training loss: 0.11373431980609894
Validation loss: 1.5998324694172028

Epoch: 5| Step: 2
Training loss: 0.09239368140697479
Validation loss: 1.6090009571403585

Epoch: 5| Step: 3
Training loss: 0.22692465782165527
Validation loss: 1.595399623276085

Epoch: 5| Step: 4
Training loss: 0.19788944721221924
Validation loss: 1.594657797967234

Epoch: 5| Step: 5
Training loss: 0.11654406785964966
Validation loss: 1.5949521769759476

Epoch: 5| Step: 6
Training loss: 0.2618161141872406
Validation loss: 1.5798922661812074

Epoch: 5| Step: 7
Training loss: 0.216007262468338
Validation loss: 1.5519011738479778

Epoch: 5| Step: 8
Training loss: 0.16908404231071472
Validation loss: 1.5560390269884499

Epoch: 5| Step: 9
Training loss: 0.1728101670742035
Validation loss: 1.5878931694133307

Epoch: 5| Step: 10
Training loss: 0.10314036905765533
Validation loss: 1.5857852940918298

Epoch: 427| Step: 0
Training loss: 0.1355341225862503
Validation loss: 1.6070079271511366

Epoch: 5| Step: 1
Training loss: 0.13661262392997742
Validation loss: 1.6045879023049467

Epoch: 5| Step: 2
Training loss: 0.13260917365550995
Validation loss: 1.6395642193414832

Epoch: 5| Step: 3
Training loss: 0.2371114045381546
Validation loss: 1.5684224905506257

Epoch: 5| Step: 4
Training loss: 0.19660580158233643
Validation loss: 1.5817016632326188

Epoch: 5| Step: 5
Training loss: 0.17898361384868622
Validation loss: 1.6014524826439478

Epoch: 5| Step: 6
Training loss: 0.15839315950870514
Validation loss: 1.5508172473599833

Epoch: 5| Step: 7
Training loss: 0.19212719798088074
Validation loss: 1.5771540544366325

Epoch: 5| Step: 8
Training loss: 0.14987263083457947
Validation loss: 1.6018889488712433

Epoch: 5| Step: 9
Training loss: 0.16525982320308685
Validation loss: 1.5992760427536503

Epoch: 5| Step: 10
Training loss: 0.10343139618635178
Validation loss: 1.5951630492364206

Epoch: 428| Step: 0
Training loss: 0.14709633588790894
Validation loss: 1.5929325806197299

Epoch: 5| Step: 1
Training loss: 0.12100343406200409
Validation loss: 1.6132438195649015

Epoch: 5| Step: 2
Training loss: 0.06474677473306656
Validation loss: 1.597129932013891

Epoch: 5| Step: 3
Training loss: 0.19376610219478607
Validation loss: 1.6277956578039354

Epoch: 5| Step: 4
Training loss: 0.23878145217895508
Validation loss: 1.6384421369080902

Epoch: 5| Step: 5
Training loss: 0.1343369483947754
Validation loss: 1.6441897051308745

Epoch: 5| Step: 6
Training loss: 0.12033876031637192
Validation loss: 1.62762741632359

Epoch: 5| Step: 7
Training loss: 0.15449945628643036
Validation loss: 1.6057158606026762

Epoch: 5| Step: 8
Training loss: 0.13504162430763245
Validation loss: 1.583307578358599

Epoch: 5| Step: 9
Training loss: 0.11803726851940155
Validation loss: 1.5940786856476978

Epoch: 5| Step: 10
Training loss: 0.15833184123039246
Validation loss: 1.5928306656499063

Epoch: 429| Step: 0
Training loss: 0.08519478142261505
Validation loss: 1.5863008037690194

Epoch: 5| Step: 1
Training loss: 0.1475127637386322
Validation loss: 1.5667606451178109

Epoch: 5| Step: 2
Training loss: 0.1119852066040039
Validation loss: 1.5595408729327622

Epoch: 5| Step: 3
Training loss: 0.15297046303749084
Validation loss: 1.5485673258381505

Epoch: 5| Step: 4
Training loss: 0.22995910048484802
Validation loss: 1.5580294965415873

Epoch: 5| Step: 5
Training loss: 0.13948360085487366
Validation loss: 1.5603369038592103

Epoch: 5| Step: 6
Training loss: 0.09708185493946075
Validation loss: 1.5615638097127278

Epoch: 5| Step: 7
Training loss: 0.13267984986305237
Validation loss: 1.556608582055697

Epoch: 5| Step: 8
Training loss: 0.13729405403137207
Validation loss: 1.554603176732217

Epoch: 5| Step: 9
Training loss: 0.1647481918334961
Validation loss: 1.5490359811372654

Epoch: 5| Step: 10
Training loss: 0.2955176830291748
Validation loss: 1.5286657810211182

Epoch: 430| Step: 0
Training loss: 0.1441662758588791
Validation loss: 1.5542127381088913

Epoch: 5| Step: 1
Training loss: 0.09011147916316986
Validation loss: 1.55204487487834

Epoch: 5| Step: 2
Training loss: 0.12471328675746918
Validation loss: 1.5567842670666274

Epoch: 5| Step: 3
Training loss: 0.14355552196502686
Validation loss: 1.5788231306178595

Epoch: 5| Step: 4
Training loss: 0.26782676577568054
Validation loss: 1.5836965319930867

Epoch: 5| Step: 5
Training loss: 0.2542673945426941
Validation loss: 1.5984994596050632

Epoch: 5| Step: 6
Training loss: 0.14017093181610107
Validation loss: 1.6087228944224696

Epoch: 5| Step: 7
Training loss: 0.20179185271263123
Validation loss: 1.6129464385330037

Epoch: 5| Step: 8
Training loss: 0.16448846459388733
Validation loss: 1.5999053934569

Epoch: 5| Step: 9
Training loss: 0.08714145421981812
Validation loss: 1.5973663599260393

Epoch: 5| Step: 10
Training loss: 0.13176532089710236
Validation loss: 1.5835592041733444

Epoch: 431| Step: 0
Training loss: 0.24970951676368713
Validation loss: 1.5693720156146633

Epoch: 5| Step: 1
Training loss: 0.13854685425758362
Validation loss: 1.5704745733609764

Epoch: 5| Step: 2
Training loss: 0.11363144218921661
Validation loss: 1.5817002532302693

Epoch: 5| Step: 3
Training loss: 0.11849043518304825
Validation loss: 1.576299669922039

Epoch: 5| Step: 4
Training loss: 0.09767746180295944
Validation loss: 1.5904652098173737

Epoch: 5| Step: 5
Training loss: 0.14030542969703674
Validation loss: 1.5751030560462707

Epoch: 5| Step: 6
Training loss: 0.18591859936714172
Validation loss: 1.6057773982324908

Epoch: 5| Step: 7
Training loss: 0.16481545567512512
Validation loss: 1.6104441791452386

Epoch: 5| Step: 8
Training loss: 0.22886696457862854
Validation loss: 1.6254628448076145

Epoch: 5| Step: 9
Training loss: 0.19447045028209686
Validation loss: 1.6095356338767595

Epoch: 5| Step: 10
Training loss: 0.12249559164047241
Validation loss: 1.6196519559429539

Epoch: 432| Step: 0
Training loss: 0.09917787462472916
Validation loss: 1.639799548733619

Epoch: 5| Step: 1
Training loss: 0.1574651598930359
Validation loss: 1.6300925413767497

Epoch: 5| Step: 2
Training loss: 0.14646172523498535
Validation loss: 1.636021364119745

Epoch: 5| Step: 3
Training loss: 0.12497830390930176
Validation loss: 1.634354309369159

Epoch: 5| Step: 4
Training loss: 0.14139994978904724
Validation loss: 1.6391306602826683

Epoch: 5| Step: 5
Training loss: 0.2343786060810089
Validation loss: 1.6390221939292005

Epoch: 5| Step: 6
Training loss: 0.1578376591205597
Validation loss: 1.6474423434144707

Epoch: 5| Step: 7
Training loss: 0.2330109179019928
Validation loss: 1.6423437505640008

Epoch: 5| Step: 8
Training loss: 0.1603703647851944
Validation loss: 1.6505842401135353

Epoch: 5| Step: 9
Training loss: 0.37196940183639526
Validation loss: 1.6726853334775535

Epoch: 5| Step: 10
Training loss: 0.17258213460445404
Validation loss: 1.6671153781234578

Epoch: 433| Step: 0
Training loss: 0.1418517529964447
Validation loss: 1.640516956647237

Epoch: 5| Step: 1
Training loss: 0.08839012682437897
Validation loss: 1.646188615470804

Epoch: 5| Step: 2
Training loss: 0.16291026771068573
Validation loss: 1.6151931555040422

Epoch: 5| Step: 3
Training loss: 0.08647225052118301
Validation loss: 1.6034762782435263

Epoch: 5| Step: 4
Training loss: 0.12337297201156616
Validation loss: 1.6038222261654433

Epoch: 5| Step: 5
Training loss: 0.13780267536640167
Validation loss: 1.607928893899405

Epoch: 5| Step: 6
Training loss: 0.3036569654941559
Validation loss: 1.5925087005861345

Epoch: 5| Step: 7
Training loss: 0.18260161578655243
Validation loss: 1.6102848411888204

Epoch: 5| Step: 8
Training loss: 0.3063037693500519
Validation loss: 1.6096896022878668

Epoch: 5| Step: 9
Training loss: 0.17336362600326538
Validation loss: 1.614800921050451

Epoch: 5| Step: 10
Training loss: 0.29998978972435
Validation loss: 1.6015544335047405

Epoch: 434| Step: 0
Training loss: 0.19295451045036316
Validation loss: 1.6059725117939774

Epoch: 5| Step: 1
Training loss: 0.14590367674827576
Validation loss: 1.627071197314929

Epoch: 5| Step: 2
Training loss: 0.10644242912530899
Validation loss: 1.622586973251835

Epoch: 5| Step: 3
Training loss: 0.09529781341552734
Validation loss: 1.6390975175365325

Epoch: 5| Step: 4
Training loss: 0.12008414417505264
Validation loss: 1.6009493386873634

Epoch: 5| Step: 5
Training loss: 0.15369842946529388
Validation loss: 1.6274077418029949

Epoch: 5| Step: 6
Training loss: 0.17335264384746552
Validation loss: 1.6006189623186666

Epoch: 5| Step: 7
Training loss: 0.13508598506450653
Validation loss: 1.636950841514013

Epoch: 5| Step: 8
Training loss: 0.31919020414352417
Validation loss: 1.6303556503788117

Epoch: 5| Step: 9
Training loss: 0.25318804383277893
Validation loss: 1.6357051967292704

Epoch: 5| Step: 10
Training loss: 0.15042373538017273
Validation loss: 1.669495662053426

Epoch: 435| Step: 0
Training loss: 0.08723359555006027
Validation loss: 1.653443682578302

Epoch: 5| Step: 1
Training loss: 0.2443176805973053
Validation loss: 1.633510676763391

Epoch: 5| Step: 2
Training loss: 0.12304119020700455
Validation loss: 1.614910315441829

Epoch: 5| Step: 3
Training loss: 0.1376524269580841
Validation loss: 1.607575633192575

Epoch: 5| Step: 4
Training loss: 0.16483961045742035
Validation loss: 1.6224017655977638

Epoch: 5| Step: 5
Training loss: 0.11492283642292023
Validation loss: 1.6372139838434034

Epoch: 5| Step: 6
Training loss: 0.15097495913505554
Validation loss: 1.6443840592138228

Epoch: 5| Step: 7
Training loss: 0.2034197300672531
Validation loss: 1.6571269522431076

Epoch: 5| Step: 8
Training loss: 0.2573075294494629
Validation loss: 1.6481769546385734

Epoch: 5| Step: 9
Training loss: 0.11451613903045654
Validation loss: 1.6359800728418494

Epoch: 5| Step: 10
Training loss: 0.16748113930225372
Validation loss: 1.6137048191921686

Epoch: 436| Step: 0
Training loss: 0.09580248594284058
Validation loss: 1.6142198693367742

Epoch: 5| Step: 1
Training loss: 0.18962831795215607
Validation loss: 1.6131863055690643

Epoch: 5| Step: 2
Training loss: 0.10584390163421631
Validation loss: 1.6291501791246477

Epoch: 5| Step: 3
Training loss: 0.1667851358652115
Validation loss: 1.6330984356582805

Epoch: 5| Step: 4
Training loss: 0.08628986775875092
Validation loss: 1.6536188702429495

Epoch: 5| Step: 5
Training loss: 0.14769050478935242
Validation loss: 1.635573819119443

Epoch: 5| Step: 6
Training loss: 0.13915929198265076
Validation loss: 1.6364113733332644

Epoch: 5| Step: 7
Training loss: 0.09981384128332138
Validation loss: 1.6263966624454786

Epoch: 5| Step: 8
Training loss: 0.16737647354602814
Validation loss: 1.6144033273061116

Epoch: 5| Step: 9
Training loss: 0.28290456533432007
Validation loss: 1.6244940988479122

Epoch: 5| Step: 10
Training loss: 0.18060442805290222
Validation loss: 1.6038284404303438

Epoch: 437| Step: 0
Training loss: 0.11604628711938858
Validation loss: 1.6183105540531937

Epoch: 5| Step: 1
Training loss: 0.12070576846599579
Validation loss: 1.6253672710029028

Epoch: 5| Step: 2
Training loss: 0.18668954074382782
Validation loss: 1.6288408553728493

Epoch: 5| Step: 3
Training loss: 0.1999007612466812
Validation loss: 1.6700126240330357

Epoch: 5| Step: 4
Training loss: 0.288382351398468
Validation loss: 1.673487131313611

Epoch: 5| Step: 5
Training loss: 0.1932811439037323
Validation loss: 1.6621623936519827

Epoch: 5| Step: 6
Training loss: 0.13360585272312164
Validation loss: 1.6377255711504208

Epoch: 5| Step: 7
Training loss: 0.08799736946821213
Validation loss: 1.643212572220833

Epoch: 5| Step: 8
Training loss: 0.09545986354351044
Validation loss: 1.6216552238310538

Epoch: 5| Step: 9
Training loss: 0.09851713478565216
Validation loss: 1.6182705663865613

Epoch: 5| Step: 10
Training loss: 0.1046886146068573
Validation loss: 1.5820159117380779

Epoch: 438| Step: 0
Training loss: 0.12942872941493988
Validation loss: 1.557573349245133

Epoch: 5| Step: 1
Training loss: 0.14716583490371704
Validation loss: 1.566529901437862

Epoch: 5| Step: 2
Training loss: 0.17079980671405792
Validation loss: 1.5553945020962787

Epoch: 5| Step: 3
Training loss: 0.09653487056493759
Validation loss: 1.5750560978407502

Epoch: 5| Step: 4
Training loss: 0.15806511044502258
Validation loss: 1.5764824228902017

Epoch: 5| Step: 5
Training loss: 0.13769757747650146
Validation loss: 1.6181099645553096

Epoch: 5| Step: 6
Training loss: 0.12893390655517578
Validation loss: 1.6134098883598083

Epoch: 5| Step: 7
Training loss: 0.1616433709859848
Validation loss: 1.6377371306060462

Epoch: 5| Step: 8
Training loss: 0.2605324387550354
Validation loss: 1.6614026754133162

Epoch: 5| Step: 9
Training loss: 0.1969347447156906
Validation loss: 1.6508880020469747

Epoch: 5| Step: 10
Training loss: 0.1461092233657837
Validation loss: 1.6616722742716472

Epoch: 439| Step: 0
Training loss: 0.09027650207281113
Validation loss: 1.6517096693797777

Epoch: 5| Step: 1
Training loss: 0.08544144034385681
Validation loss: 1.6026859655175159

Epoch: 5| Step: 2
Training loss: 0.10256528854370117
Validation loss: 1.6122442983811902

Epoch: 5| Step: 3
Training loss: 0.21089963614940643
Validation loss: 1.6194049209676764

Epoch: 5| Step: 4
Training loss: 0.14899441599845886
Validation loss: 1.6349786622549898

Epoch: 5| Step: 5
Training loss: 0.1375807672739029
Validation loss: 1.5737931369453348

Epoch: 5| Step: 6
Training loss: 0.1920575201511383
Validation loss: 1.602401505234421

Epoch: 5| Step: 7
Training loss: 0.1459915041923523
Validation loss: 1.5986564543939406

Epoch: 5| Step: 8
Training loss: 0.15905845165252686
Validation loss: 1.6025523857403827

Epoch: 5| Step: 9
Training loss: 0.23171143233776093
Validation loss: 1.6150222709102016

Epoch: 5| Step: 10
Training loss: 0.11837420612573624
Validation loss: 1.6389082247211086

Epoch: 440| Step: 0
Training loss: 0.16724398732185364
Validation loss: 1.6688338575824615

Epoch: 5| Step: 1
Training loss: 0.09204297512769699
Validation loss: 1.6725793269372755

Epoch: 5| Step: 2
Training loss: 0.10657427459955215
Validation loss: 1.669351900777509

Epoch: 5| Step: 3
Training loss: 0.17360170185565948
Validation loss: 1.6572267496457664

Epoch: 5| Step: 4
Training loss: 0.21431024372577667
Validation loss: 1.6558966482839277

Epoch: 5| Step: 5
Training loss: 0.11297353357076645
Validation loss: 1.655062993367513

Epoch: 5| Step: 6
Training loss: 0.16545523703098297
Validation loss: 1.6417829810932119

Epoch: 5| Step: 7
Training loss: 0.22665293514728546
Validation loss: 1.6310197384126726

Epoch: 5| Step: 8
Training loss: 0.20440611243247986
Validation loss: 1.6122750543778943

Epoch: 5| Step: 9
Training loss: 0.0941242203116417
Validation loss: 1.6204550445720713

Epoch: 5| Step: 10
Training loss: 0.2053939551115036
Validation loss: 1.5993534390644362

Epoch: 441| Step: 0
Training loss: 0.10952761024236679
Validation loss: 1.5863636552646596

Epoch: 5| Step: 1
Training loss: 0.13022959232330322
Validation loss: 1.598946173985799

Epoch: 5| Step: 2
Training loss: 0.13660910725593567
Validation loss: 1.6104273642263105

Epoch: 5| Step: 3
Training loss: 0.2660796344280243
Validation loss: 1.6144244196594402

Epoch: 5| Step: 4
Training loss: 0.16762198507785797
Validation loss: 1.6200482281305457

Epoch: 5| Step: 5
Training loss: 0.1421469897031784
Validation loss: 1.6083009037920224

Epoch: 5| Step: 6
Training loss: 0.18949562311172485
Validation loss: 1.596496033412154

Epoch: 5| Step: 7
Training loss: 0.16524896025657654
Validation loss: 1.5792679325226815

Epoch: 5| Step: 8
Training loss: 0.15277788043022156
Validation loss: 1.575449776905839

Epoch: 5| Step: 9
Training loss: 0.08838628232479095
Validation loss: 1.587138819438155

Epoch: 5| Step: 10
Training loss: 0.16071917116641998
Validation loss: 1.5857422108291297

Epoch: 442| Step: 0
Training loss: 0.2116537094116211
Validation loss: 1.5661516215211602

Epoch: 5| Step: 1
Training loss: 0.14004430174827576
Validation loss: 1.562946513134946

Epoch: 5| Step: 2
Training loss: 0.2407589703798294
Validation loss: 1.5962823283287786

Epoch: 5| Step: 3
Training loss: 0.14121763408184052
Validation loss: 1.624236338882036

Epoch: 5| Step: 4
Training loss: 0.15338172018527985
Validation loss: 1.6304545889618576

Epoch: 5| Step: 5
Training loss: 0.19696292281150818
Validation loss: 1.6319062940536007

Epoch: 5| Step: 6
Training loss: 0.13075172901153564
Validation loss: 1.641233145549733

Epoch: 5| Step: 7
Training loss: 0.18255683779716492
Validation loss: 1.6744333563312408

Epoch: 5| Step: 8
Training loss: 0.11112220585346222
Validation loss: 1.6411398418488041

Epoch: 5| Step: 9
Training loss: 0.3116273880004883
Validation loss: 1.5999054908752441

Epoch: 5| Step: 10
Training loss: 0.15051022171974182
Validation loss: 1.5686135997054398

Epoch: 443| Step: 0
Training loss: 0.14076592028141022
Validation loss: 1.5530350656919583

Epoch: 5| Step: 1
Training loss: 0.15215758979320526
Validation loss: 1.540033152026515

Epoch: 5| Step: 2
Training loss: 0.14960192143917084
Validation loss: 1.5170472655245053

Epoch: 5| Step: 3
Training loss: 0.15482795238494873
Validation loss: 1.516591022091527

Epoch: 5| Step: 4
Training loss: 0.1303790956735611
Validation loss: 1.550099265190863

Epoch: 5| Step: 5
Training loss: 0.10348169505596161
Validation loss: 1.5586415747160554

Epoch: 5| Step: 6
Training loss: 0.1334179937839508
Validation loss: 1.5674657475563787

Epoch: 5| Step: 7
Training loss: 0.1149946004152298
Validation loss: 1.5813645842254802

Epoch: 5| Step: 8
Training loss: 0.11094945669174194
Validation loss: 1.5959626051687426

Epoch: 5| Step: 9
Training loss: 0.1561412811279297
Validation loss: 1.6625084851377754

Epoch: 5| Step: 10
Training loss: 0.4531320035457611
Validation loss: 1.6898916357307023

Epoch: 444| Step: 0
Training loss: 0.17994031310081482
Validation loss: 1.6711019623664118

Epoch: 5| Step: 1
Training loss: 0.19369447231292725
Validation loss: 1.6600252992363387

Epoch: 5| Step: 2
Training loss: 0.12838692963123322
Validation loss: 1.6550411050037672

Epoch: 5| Step: 3
Training loss: 0.1242840439081192
Validation loss: 1.6232784909586753

Epoch: 5| Step: 4
Training loss: 0.35644426941871643
Validation loss: 1.6003671480763344

Epoch: 5| Step: 5
Training loss: 0.23172537982463837
Validation loss: 1.6189062903004308

Epoch: 5| Step: 6
Training loss: 0.22742366790771484
Validation loss: 1.6171054288905153

Epoch: 5| Step: 7
Training loss: 0.2743004262447357
Validation loss: 1.592606262494159

Epoch: 5| Step: 8
Training loss: 0.18318995833396912
Validation loss: 1.636841195885853

Epoch: 5| Step: 9
Training loss: 0.12489445507526398
Validation loss: 1.6288890646349998

Epoch: 5| Step: 10
Training loss: 0.1742614358663559
Validation loss: 1.6597857039461854

Epoch: 445| Step: 0
Training loss: 0.15050008893013
Validation loss: 1.6519051700510003

Epoch: 5| Step: 1
Training loss: 0.14000804722309113
Validation loss: 1.6505906633151475

Epoch: 5| Step: 2
Training loss: 0.1976325809955597
Validation loss: 1.6531139766016314

Epoch: 5| Step: 3
Training loss: 0.2187112271785736
Validation loss: 1.647343611204496

Epoch: 5| Step: 4
Training loss: 0.14563655853271484
Validation loss: 1.6385880336966565

Epoch: 5| Step: 5
Training loss: 0.17048947513103485
Validation loss: 1.648012025381929

Epoch: 5| Step: 6
Training loss: 0.2058233767747879
Validation loss: 1.662378332948172

Epoch: 5| Step: 7
Training loss: 0.23726144433021545
Validation loss: 1.6518475791459442

Epoch: 5| Step: 8
Training loss: 0.16672512888908386
Validation loss: 1.664202993915927

Epoch: 5| Step: 9
Training loss: 0.20471236109733582
Validation loss: 1.6921658644112207

Epoch: 5| Step: 10
Training loss: 0.20299918949604034
Validation loss: 1.6857260055439447

Epoch: 446| Step: 0
Training loss: 0.13203737139701843
Validation loss: 1.6594034471819479

Epoch: 5| Step: 1
Training loss: 0.12374679744243622
Validation loss: 1.6222436376797256

Epoch: 5| Step: 2
Training loss: 0.1059485673904419
Validation loss: 1.6392797795675134

Epoch: 5| Step: 3
Training loss: 0.176278755068779
Validation loss: 1.6472682081243044

Epoch: 5| Step: 4
Training loss: 0.16424541175365448
Validation loss: 1.625867760309609

Epoch: 5| Step: 5
Training loss: 0.2610456347465515
Validation loss: 1.6281106010560067

Epoch: 5| Step: 6
Training loss: 0.2323167771100998
Validation loss: 1.6342203373550086

Epoch: 5| Step: 7
Training loss: 0.12510299682617188
Validation loss: 1.6303791352497634

Epoch: 5| Step: 8
Training loss: 0.32708168029785156
Validation loss: 1.6259417341601463

Epoch: 5| Step: 9
Training loss: 0.12349468469619751
Validation loss: 1.6282102907857587

Epoch: 5| Step: 10
Training loss: 0.08846069872379303
Validation loss: 1.6259935799465384

Epoch: 447| Step: 0
Training loss: 0.1594623625278473
Validation loss: 1.6494574110995057

Epoch: 5| Step: 1
Training loss: 0.1555633842945099
Validation loss: 1.6301857848321237

Epoch: 5| Step: 2
Training loss: 0.3319026827812195
Validation loss: 1.619320846373035

Epoch: 5| Step: 3
Training loss: 0.16621336340904236
Validation loss: 1.6240279174620105

Epoch: 5| Step: 4
Training loss: 0.14392253756523132
Validation loss: 1.6019057022627963

Epoch: 5| Step: 5
Training loss: 0.16228087246418
Validation loss: 1.6189040227602887

Epoch: 5| Step: 6
Training loss: 0.11355073750019073
Validation loss: 1.586876997383692

Epoch: 5| Step: 7
Training loss: 0.16405464708805084
Validation loss: 1.6151286414874497

Epoch: 5| Step: 8
Training loss: 0.148295059800148
Validation loss: 1.6158396326085573

Epoch: 5| Step: 9
Training loss: 0.13632220029830933
Validation loss: 1.625996760783657

Epoch: 5| Step: 10
Training loss: 0.15401378273963928
Validation loss: 1.6281581899171234

Epoch: 448| Step: 0
Training loss: 0.11645817756652832
Validation loss: 1.611506571051895

Epoch: 5| Step: 1
Training loss: 0.1644880622625351
Validation loss: 1.6109733696906798

Epoch: 5| Step: 2
Training loss: 0.09464456886053085
Validation loss: 1.5924895886451966

Epoch: 5| Step: 3
Training loss: 0.1176275834441185
Validation loss: 1.5828392492827548

Epoch: 5| Step: 4
Training loss: 0.14575867354869843
Validation loss: 1.5500082585119432

Epoch: 5| Step: 5
Training loss: 0.28098613023757935
Validation loss: 1.5592221085743239

Epoch: 5| Step: 6
Training loss: 0.16269952058792114
Validation loss: 1.5652688318683254

Epoch: 5| Step: 7
Training loss: 0.1724986881017685
Validation loss: 1.54834787179065

Epoch: 5| Step: 8
Training loss: 0.1788381040096283
Validation loss: 1.5483622108736346

Epoch: 5| Step: 9
Training loss: 0.16872449219226837
Validation loss: 1.5714019703608688

Epoch: 5| Step: 10
Training loss: 0.16142809391021729
Validation loss: 1.551921671436679

Epoch: 449| Step: 0
Training loss: 0.12260095775127411
Validation loss: 1.5744132341877106

Epoch: 5| Step: 1
Training loss: 0.08985905349254608
Validation loss: 1.5803440437521985

Epoch: 5| Step: 2
Training loss: 0.14776429533958435
Validation loss: 1.5556158199105212

Epoch: 5| Step: 3
Training loss: 0.08762858808040619
Validation loss: 1.5556206421185566

Epoch: 5| Step: 4
Training loss: 0.13463036715984344
Validation loss: 1.537137705792663

Epoch: 5| Step: 5
Training loss: 0.14837273955345154
Validation loss: 1.5684144355917489

Epoch: 5| Step: 6
Training loss: 0.10568436235189438
Validation loss: 1.571443344957085

Epoch: 5| Step: 7
Training loss: 0.20824578404426575
Validation loss: 1.5777038066617903

Epoch: 5| Step: 8
Training loss: 0.1337549388408661
Validation loss: 1.5823536931827504

Epoch: 5| Step: 9
Training loss: 0.1237713098526001
Validation loss: 1.5652254166141633

Epoch: 5| Step: 10
Training loss: 0.24493223428726196
Validation loss: 1.5881956700355775

Epoch: 450| Step: 0
Training loss: 0.2017611265182495
Validation loss: 1.573352288174373

Epoch: 5| Step: 1
Training loss: 0.24660339951515198
Validation loss: 1.5506558649001583

Epoch: 5| Step: 2
Training loss: 0.12801668047904968
Validation loss: 1.570148370599234

Epoch: 5| Step: 3
Training loss: 0.13284946978092194
Validation loss: 1.543058410767586

Epoch: 5| Step: 4
Training loss: 0.1729232221841812
Validation loss: 1.5772386366321194

Epoch: 5| Step: 5
Training loss: 0.11328721046447754
Validation loss: 1.5926329064112839

Epoch: 5| Step: 6
Training loss: 0.15723231434822083
Validation loss: 1.572714433875135

Epoch: 5| Step: 7
Training loss: 0.21379098296165466
Validation loss: 1.5472359836742442

Epoch: 5| Step: 8
Training loss: 0.16995635628700256
Validation loss: 1.5540582967060868

Epoch: 5| Step: 9
Training loss: 0.11865260452032089
Validation loss: 1.5643542863989388

Epoch: 5| Step: 10
Training loss: 0.15766438841819763
Validation loss: 1.5724618434906006

Testing loss: 1.9881030983395047
