Epoch: 1| Step: 0
Training loss: 5.424201400269765
Validation loss: 5.809085142306054

Epoch: 5| Step: 1
Training loss: 6.041953279558942
Validation loss: 5.793352086193687

Epoch: 5| Step: 2
Training loss: 5.620641757800549
Validation loss: 5.780008243765397

Epoch: 5| Step: 3
Training loss: 5.443854641702454
Validation loss: 5.766712051451056

Epoch: 5| Step: 4
Training loss: 4.811745126153048
Validation loss: 5.751542970884873

Epoch: 5| Step: 5
Training loss: 6.410726927484085
Validation loss: 5.733867665627619

Epoch: 5| Step: 6
Training loss: 7.1837400470251165
Validation loss: 5.714122639217442

Epoch: 5| Step: 7
Training loss: 4.881325945586972
Validation loss: 5.690951928254523

Epoch: 5| Step: 8
Training loss: 5.666769961743322
Validation loss: 5.664968968587102

Epoch: 5| Step: 9
Training loss: 5.591038222418177
Validation loss: 5.6359937676881655

Epoch: 5| Step: 10
Training loss: 5.889241589874391
Validation loss: 5.602655158974885

Epoch: 2| Step: 0
Training loss: 6.333193559944667
Validation loss: 5.567235888642981

Epoch: 5| Step: 1
Training loss: 5.879355581354299
Validation loss: 5.526334769664871

Epoch: 5| Step: 2
Training loss: 5.988517582379854
Validation loss: 5.482541671881929

Epoch: 5| Step: 3
Training loss: 5.196321271894395
Validation loss: 5.435953080753513

Epoch: 5| Step: 4
Training loss: 5.917864324573731
Validation loss: 5.385392370478813

Epoch: 5| Step: 5
Training loss: 5.248685581423372
Validation loss: 5.332375926304228

Epoch: 5| Step: 6
Training loss: 5.0434683530844575
Validation loss: 5.276796104930968

Epoch: 5| Step: 7
Training loss: 5.045155707717286
Validation loss: 5.2199613528356625

Epoch: 5| Step: 8
Training loss: 4.754791252616358
Validation loss: 5.164518488628978

Epoch: 5| Step: 9
Training loss: 4.179603304861688
Validation loss: 5.108828124955038

Epoch: 5| Step: 10
Training loss: 5.346887214151742
Validation loss: 5.059866921949821

Epoch: 3| Step: 0
Training loss: 5.157092216372888
Validation loss: 5.011596779486085

Epoch: 5| Step: 1
Training loss: 5.141806237764969
Validation loss: 4.967362551524895

Epoch: 5| Step: 2
Training loss: 4.922109640674345
Validation loss: 4.925340812054981

Epoch: 5| Step: 3
Training loss: 4.945753321955197
Validation loss: 4.877728489843633

Epoch: 5| Step: 4
Training loss: 3.917386103899375
Validation loss: 4.832280082780621

Epoch: 5| Step: 5
Training loss: 4.496413391046103
Validation loss: 4.793712320904451

Epoch: 5| Step: 6
Training loss: 5.122998288644464
Validation loss: 4.753628386072881

Epoch: 5| Step: 7
Training loss: 5.408938230162178
Validation loss: 4.71233164973825

Epoch: 5| Step: 8
Training loss: 4.714888047055269
Validation loss: 4.667936404303172

Epoch: 5| Step: 9
Training loss: 4.9690129432440555
Validation loss: 4.6242285774938345

Epoch: 5| Step: 10
Training loss: 4.7082712400049775
Validation loss: 4.578498909899213

Epoch: 4| Step: 0
Training loss: 4.41408561768006
Validation loss: 4.532588923016233

Epoch: 5| Step: 1
Training loss: 3.831634407610092
Validation loss: 4.48566140621407

Epoch: 5| Step: 2
Training loss: 4.157721008188692
Validation loss: 4.447482407635671

Epoch: 5| Step: 3
Training loss: 4.613033174955735
Validation loss: 4.412241026547991

Epoch: 5| Step: 4
Training loss: 5.301110838592877
Validation loss: 4.375143497065034

Epoch: 5| Step: 5
Training loss: 4.808269672644521
Validation loss: 4.348187935481659

Epoch: 5| Step: 6
Training loss: 3.8425701780742134
Validation loss: 4.322306270428737

Epoch: 5| Step: 7
Training loss: 4.380587470315255
Validation loss: 4.3015476163300885

Epoch: 5| Step: 8
Training loss: 4.327890768495471
Validation loss: 4.28469419192924

Epoch: 5| Step: 9
Training loss: 4.4298707093258125
Validation loss: 4.26579084272679

Epoch: 5| Step: 10
Training loss: 5.024003965436986
Validation loss: 4.2445928582791135

Epoch: 5| Step: 0
Training loss: 4.346280246088495
Validation loss: 4.2210859569898895

Epoch: 5| Step: 1
Training loss: 4.764526240522856
Validation loss: 4.201266605761896

Epoch: 5| Step: 2
Training loss: 4.4267268976074154
Validation loss: 4.1784545147058605

Epoch: 5| Step: 3
Training loss: 4.330367956583401
Validation loss: 4.165725864311525

Epoch: 5| Step: 4
Training loss: 3.9765625
Validation loss: 4.1492600069472045

Epoch: 5| Step: 5
Training loss: 3.974153699693078
Validation loss: 4.137638254820281

Epoch: 5| Step: 6
Training loss: 3.6998947798743025
Validation loss: 4.129375899871895

Epoch: 5| Step: 7
Training loss: 3.883082666342856
Validation loss: 4.128176160252869

Epoch: 5| Step: 8
Training loss: 4.081338485996999
Validation loss: 4.115741971698193

Epoch: 5| Step: 9
Training loss: 4.877641988982039
Validation loss: 4.116267203527878

Epoch: 5| Step: 10
Training loss: 4.730257062640688
Validation loss: 4.102650870262674

Epoch: 6| Step: 0
Training loss: 4.408884113327981
Validation loss: 4.075840217378429

Epoch: 5| Step: 1
Training loss: 3.288288813768326
Validation loss: 4.046945453220099

Epoch: 5| Step: 2
Training loss: 4.504201199484163
Validation loss: 4.07849032203309

Epoch: 5| Step: 3
Training loss: 4.296463492369017
Validation loss: 4.024952505070068

Epoch: 5| Step: 4
Training loss: 3.0239821936471647
Validation loss: 4.012895572875183

Epoch: 5| Step: 5
Training loss: 4.776028643153193
Validation loss: 4.017146560954858

Epoch: 5| Step: 6
Training loss: 4.39891036152982
Validation loss: 4.017545271341071

Epoch: 5| Step: 7
Training loss: 4.4791612255447815
Validation loss: 3.9995143221235576

Epoch: 5| Step: 8
Training loss: 3.7691861483868645
Validation loss: 3.9888742701900637

Epoch: 5| Step: 9
Training loss: 4.233694324470845
Validation loss: 3.973931061425551

Epoch: 5| Step: 10
Training loss: 4.349775567239253
Validation loss: 3.960132198333409

Epoch: 7| Step: 0
Training loss: 4.407116311044803
Validation loss: 3.964201794016904

Epoch: 5| Step: 1
Training loss: 4.919081315899509
Validation loss: 3.958382057101635

Epoch: 5| Step: 2
Training loss: 3.846783441217861
Validation loss: 3.932378469235894

Epoch: 5| Step: 3
Training loss: 4.041812513938165
Validation loss: 3.923850495705938

Epoch: 5| Step: 4
Training loss: 3.4889347365647727
Validation loss: 3.921166791755915

Epoch: 5| Step: 5
Training loss: 3.704476669149497
Validation loss: 3.9213186707059244

Epoch: 5| Step: 6
Training loss: 4.929915965449269
Validation loss: 3.921140425408184

Epoch: 5| Step: 7
Training loss: 4.051217477792098
Validation loss: 3.9133906062944424

Epoch: 5| Step: 8
Training loss: 3.8880964894821526
Validation loss: 3.8845697896574123

Epoch: 5| Step: 9
Training loss: 3.604610849399745
Validation loss: 3.8751127667910783

Epoch: 5| Step: 10
Training loss: 3.624788080795382
Validation loss: 3.8788386533174837

Epoch: 8| Step: 0
Training loss: 3.6005452802745888
Validation loss: 3.8806162638800408

Epoch: 5| Step: 1
Training loss: 3.936054630512936
Validation loss: 3.8688262732078127

Epoch: 5| Step: 2
Training loss: 3.812716493557015
Validation loss: 3.860904737344575

Epoch: 5| Step: 3
Training loss: 4.397820383689774
Validation loss: 3.846633923065045

Epoch: 5| Step: 4
Training loss: 3.568456254885267
Validation loss: 3.831703733583498

Epoch: 5| Step: 5
Training loss: 2.042742102105729
Validation loss: 3.8333841795757038

Epoch: 5| Step: 6
Training loss: 4.234560578843859
Validation loss: 3.8366071066780614

Epoch: 5| Step: 7
Training loss: 3.324970738561842
Validation loss: 3.8293108511622487

Epoch: 5| Step: 8
Training loss: 4.924871979419554
Validation loss: 3.826938905978951

Epoch: 5| Step: 9
Training loss: 5.172493981145396
Validation loss: 3.8095214790822003

Epoch: 5| Step: 10
Training loss: 4.185740086826091
Validation loss: 3.791039547630225

Epoch: 9| Step: 0
Training loss: 4.217571630858898
Validation loss: 3.7931210080404245

Epoch: 5| Step: 1
Training loss: 3.539776795241733
Validation loss: 3.7951441930615664

Epoch: 5| Step: 2
Training loss: 3.8632780408701284
Validation loss: 3.799656941170495

Epoch: 5| Step: 3
Training loss: 4.672834112918046
Validation loss: 3.7661028414872617

Epoch: 5| Step: 4
Training loss: 3.6163766829674078
Validation loss: 3.7618657020176296

Epoch: 5| Step: 5
Training loss: 4.2269668244683745
Validation loss: 3.7670530847534107

Epoch: 5| Step: 6
Training loss: 3.930616022610159
Validation loss: 3.7633788256359444

Epoch: 5| Step: 7
Training loss: 4.139525530251092
Validation loss: 3.746122763605836

Epoch: 5| Step: 8
Training loss: 3.747237777646254
Validation loss: 3.7373629318895687

Epoch: 5| Step: 9
Training loss: 3.6798655472947637
Validation loss: 3.724961535584245

Epoch: 5| Step: 10
Training loss: 3.4873477588088546
Validation loss: 3.7210680316422278

Epoch: 10| Step: 0
Training loss: 4.006921977849365
Validation loss: 3.7156175135994833

Epoch: 5| Step: 1
Training loss: 3.4273302323627175
Validation loss: 3.7151666454343792

Epoch: 5| Step: 2
Training loss: 4.352676112135867
Validation loss: 3.708769810038245

Epoch: 5| Step: 3
Training loss: 3.6455840688598857
Validation loss: 3.6964155525131064

Epoch: 5| Step: 4
Training loss: 3.7495829032363304
Validation loss: 3.6936991228885834

Epoch: 5| Step: 5
Training loss: 4.713729511824425
Validation loss: 3.68897481590022

Epoch: 5| Step: 6
Training loss: 3.5229194074124157
Validation loss: 3.6805902366580456

Epoch: 5| Step: 7
Training loss: 4.131102238723597
Validation loss: 3.672351432895808

Epoch: 5| Step: 8
Training loss: 4.25041398668736
Validation loss: 3.6646564912709954

Epoch: 5| Step: 9
Training loss: 2.68854333896479
Validation loss: 3.6655805639503938

Epoch: 5| Step: 10
Training loss: 3.741204182363061
Validation loss: 3.67197388930589

Epoch: 11| Step: 0
Training loss: 3.7614344155667347
Validation loss: 3.6610679606825833

Epoch: 5| Step: 1
Training loss: 3.890362221296447
Validation loss: 3.6488683548526817

Epoch: 5| Step: 2
Training loss: 3.7173744029600013
Validation loss: 3.6373161494140223

Epoch: 5| Step: 3
Training loss: 3.8589052231007206
Validation loss: 3.6338469822327983

Epoch: 5| Step: 4
Training loss: 3.9738518070260374
Validation loss: 3.627398584556311

Epoch: 5| Step: 5
Training loss: 4.1252538429530405
Validation loss: 3.622740740587805

Epoch: 5| Step: 6
Training loss: 3.8570277686332273
Validation loss: 3.61604864417108

Epoch: 5| Step: 7
Training loss: 3.9661712679065166
Validation loss: 3.6108045995881017

Epoch: 5| Step: 8
Training loss: 3.2150198052776653
Validation loss: 3.607348501731765

Epoch: 5| Step: 9
Training loss: 4.125458200611204
Validation loss: 3.601389881101188

Epoch: 5| Step: 10
Training loss: 3.3323487894103563
Validation loss: 3.595936617629068

Epoch: 12| Step: 0
Training loss: 3.7028386130029096
Validation loss: 3.592602975210573

Epoch: 5| Step: 1
Training loss: 3.7331027493339852
Validation loss: 3.5878567577434315

Epoch: 5| Step: 2
Training loss: 3.5012038748990895
Validation loss: 3.583406781480997

Epoch: 5| Step: 3
Training loss: 3.8301696299545367
Validation loss: 3.5755767754554504

Epoch: 5| Step: 4
Training loss: 4.087473710001822
Validation loss: 3.5703765518016093

Epoch: 5| Step: 5
Training loss: 3.4602295299977652
Validation loss: 3.56947403231254

Epoch: 5| Step: 6
Training loss: 3.596659005421801
Validation loss: 3.5640356743878248

Epoch: 5| Step: 7
Training loss: 3.4405650952188767
Validation loss: 3.561344331322807

Epoch: 5| Step: 8
Training loss: 3.8716205504078434
Validation loss: 3.5560664539775337

Epoch: 5| Step: 9
Training loss: 3.802405454324237
Validation loss: 3.5516401890226303

Epoch: 5| Step: 10
Training loss: 4.47626764681229
Validation loss: 3.5552595357783

Epoch: 13| Step: 0
Training loss: 3.2624749135189273
Validation loss: 3.543062369142904

Epoch: 5| Step: 1
Training loss: 4.055652187595485
Validation loss: 3.5413716684981638

Epoch: 5| Step: 2
Training loss: 3.1774363504033025
Validation loss: 3.5361222813629363

Epoch: 5| Step: 3
Training loss: 4.031986612842679
Validation loss: 3.5327572159209244

Epoch: 5| Step: 4
Training loss: 3.9223134073158867
Validation loss: 3.529320806514126

Epoch: 5| Step: 5
Training loss: 3.071168270677132
Validation loss: 3.5266154508812546

Epoch: 5| Step: 6
Training loss: 4.119930967474796
Validation loss: 3.5218550647391544

Epoch: 5| Step: 7
Training loss: 3.700618491158208
Validation loss: 3.5186740020225176

Epoch: 5| Step: 8
Training loss: 4.335596569507522
Validation loss: 3.514027655536851

Epoch: 5| Step: 9
Training loss: 3.58209408171448
Validation loss: 3.5124324968578273

Epoch: 5| Step: 10
Training loss: 3.5438774987484054
Validation loss: 3.5077987309959937

Epoch: 14| Step: 0
Training loss: 3.7417004612767903
Validation loss: 3.505671400618654

Epoch: 5| Step: 1
Training loss: 4.024765832379962
Validation loss: 3.50356389175762

Epoch: 5| Step: 2
Training loss: 3.734262376946474
Validation loss: 3.498839879003699

Epoch: 5| Step: 3
Training loss: 2.1637768057623292
Validation loss: 3.498685919716218

Epoch: 5| Step: 4
Training loss: 4.158958986315388
Validation loss: 3.4942839424406924

Epoch: 5| Step: 5
Training loss: 4.043294729461001
Validation loss: 3.48836747379765

Epoch: 5| Step: 6
Training loss: 3.2207510940560558
Validation loss: 3.4869976667980547

Epoch: 5| Step: 7
Training loss: 4.212085574448198
Validation loss: 3.484034152939523

Epoch: 5| Step: 8
Training loss: 3.3798203130507902
Validation loss: 3.480399468150858

Epoch: 5| Step: 9
Training loss: 3.819301104697655
Validation loss: 3.480236638811398

Epoch: 5| Step: 10
Training loss: 3.797672392075728
Validation loss: 3.4753895805978323

Epoch: 15| Step: 0
Training loss: 4.035714922300884
Validation loss: 3.473065890837099

Epoch: 5| Step: 1
Training loss: 3.4842117339744907
Validation loss: 3.4706300420349923

Epoch: 5| Step: 2
Training loss: 3.246940933747655
Validation loss: 3.4708013716671573

Epoch: 5| Step: 3
Training loss: 3.9072410852095136
Validation loss: 3.467971712967143

Epoch: 5| Step: 4
Training loss: 3.5427893411283704
Validation loss: 3.4656615960454658

Epoch: 5| Step: 5
Training loss: 3.7771155082284684
Validation loss: 3.46396583527606

Epoch: 5| Step: 6
Training loss: 3.496975000228294
Validation loss: 3.4734169043563146

Epoch: 5| Step: 7
Training loss: 3.783985252061295
Validation loss: 3.457646189115858

Epoch: 5| Step: 8
Training loss: 3.6239594906443897
Validation loss: 3.4586219004983483

Epoch: 5| Step: 9
Training loss: 3.332267225167321
Validation loss: 3.45606557684888

Epoch: 5| Step: 10
Training loss: 4.23407769655089
Validation loss: 3.4543464522319822

Epoch: 16| Step: 0
Training loss: 3.7652967634433376
Validation loss: 3.451958120569016

Epoch: 5| Step: 1
Training loss: 4.359566414298412
Validation loss: 3.446219755582292

Epoch: 5| Step: 2
Training loss: 3.8419713813156693
Validation loss: 3.447129931633842

Epoch: 5| Step: 3
Training loss: 3.537972322346025
Validation loss: 3.445860481078388

Epoch: 5| Step: 4
Training loss: 3.225564945625002
Validation loss: 3.4362767986280582

Epoch: 5| Step: 5
Training loss: 3.3147068949330056
Validation loss: 3.436372545587544

Epoch: 5| Step: 6
Training loss: 3.8232330828834757
Validation loss: 3.4365011022383745

Epoch: 5| Step: 7
Training loss: 2.936696368733715
Validation loss: 3.4357471296352653

Epoch: 5| Step: 8
Training loss: 3.6380230032773966
Validation loss: 3.4311582654096315

Epoch: 5| Step: 9
Training loss: 3.7399495546743395
Validation loss: 3.4272150893993905

Epoch: 5| Step: 10
Training loss: 3.9273115069870124
Validation loss: 3.4243710349878294

Epoch: 17| Step: 0
Training loss: 3.852543146979774
Validation loss: 3.423390403041646

Epoch: 5| Step: 1
Training loss: 3.394280638404269
Validation loss: 3.4221589828472077

Epoch: 5| Step: 2
Training loss: 3.964166713092048
Validation loss: 3.4241646331383446

Epoch: 5| Step: 3
Training loss: 3.003235026397251
Validation loss: 3.416549654101693

Epoch: 5| Step: 4
Training loss: 3.3713431150075612
Validation loss: 3.4128389374331616

Epoch: 5| Step: 5
Training loss: 3.8656460242597857
Validation loss: 3.4105863820614144

Epoch: 5| Step: 6
Training loss: 3.128058653288894
Validation loss: 3.410291168337145

Epoch: 5| Step: 7
Training loss: 3.7582532977077854
Validation loss: 3.4071176249387967

Epoch: 5| Step: 8
Training loss: 3.9232532769405055
Validation loss: 3.404796770895083

Epoch: 5| Step: 9
Training loss: 4.02761511346321
Validation loss: 3.403475666171126

Epoch: 5| Step: 10
Training loss: 3.5281519169959017
Validation loss: 3.399314283535271

Epoch: 18| Step: 0
Training loss: 4.029986042916714
Validation loss: 3.398339154351948

Epoch: 5| Step: 1
Training loss: 3.730696522414869
Validation loss: 3.3967974545016077

Epoch: 5| Step: 2
Training loss: 3.4209335634615408
Validation loss: 3.3947916089516346

Epoch: 5| Step: 3
Training loss: 3.137675404299977
Validation loss: 3.3929558153258608

Epoch: 5| Step: 4
Training loss: 3.478123278073333
Validation loss: 3.394082534118051

Epoch: 5| Step: 5
Training loss: 3.7447972127407354
Validation loss: 3.3926562307836683

Epoch: 5| Step: 6
Training loss: 4.398286806713092
Validation loss: 3.393453470088248

Epoch: 5| Step: 7
Training loss: 3.3048287580163684
Validation loss: 3.386796108306246

Epoch: 5| Step: 8
Training loss: 2.9260221211554795
Validation loss: 3.384657750537549

Epoch: 5| Step: 9
Training loss: 3.2846519636544245
Validation loss: 3.3842059725914564

Epoch: 5| Step: 10
Training loss: 4.164391366879795
Validation loss: 3.3816383762761495

Epoch: 19| Step: 0
Training loss: 3.914089545424899
Validation loss: 3.3809152643801577

Epoch: 5| Step: 1
Training loss: 3.409114088499856
Validation loss: 3.378586433255596

Epoch: 5| Step: 2
Training loss: 3.749104710835975
Validation loss: 3.377515284736548

Epoch: 5| Step: 3
Training loss: 3.153561192748784
Validation loss: 3.377565344013849

Epoch: 5| Step: 4
Training loss: 3.457122146359754
Validation loss: 3.375745937751472

Epoch: 5| Step: 5
Training loss: 3.750378017446065
Validation loss: 3.3748082509445365

Epoch: 5| Step: 6
Training loss: 3.2413746745607472
Validation loss: 3.3721531567062533

Epoch: 5| Step: 7
Training loss: 4.004384260719133
Validation loss: 3.3699212823516094

Epoch: 5| Step: 8
Training loss: 4.058702307709623
Validation loss: 3.3693792679088683

Epoch: 5| Step: 9
Training loss: 3.538421235923512
Validation loss: 3.3677864662127144

Epoch: 5| Step: 10
Training loss: 3.1559485867546653
Validation loss: 3.3640465107013457

Epoch: 20| Step: 0
Training loss: 3.2886468257690904
Validation loss: 3.363570124223199

Epoch: 5| Step: 1
Training loss: 2.985338944148586
Validation loss: 3.365302122850136

Epoch: 5| Step: 2
Training loss: 4.148504626634401
Validation loss: 3.3637256423767576

Epoch: 5| Step: 3
Training loss: 3.661487968111462
Validation loss: 3.3657302118353343

Epoch: 5| Step: 4
Training loss: 3.736661458438598
Validation loss: 3.368460056406012

Epoch: 5| Step: 5
Training loss: 3.8787394292787574
Validation loss: 3.3697945601320978

Epoch: 5| Step: 6
Training loss: 4.059639495854738
Validation loss: 3.3558495779234643

Epoch: 5| Step: 7
Training loss: 3.087084747683465
Validation loss: 3.356612567509851

Epoch: 5| Step: 8
Training loss: 3.1385573227968044
Validation loss: 3.3633925525378863

Epoch: 5| Step: 9
Training loss: 3.184678268591425
Validation loss: 3.3666203702677455

Epoch: 5| Step: 10
Training loss: 4.194812368350229
Validation loss: 3.366636423917125

Epoch: 21| Step: 0
Training loss: 3.2872056952614
Validation loss: 3.3532549862954677

Epoch: 5| Step: 1
Training loss: 4.347155656125507
Validation loss: 3.354943242812899

Epoch: 5| Step: 2
Training loss: 3.1028405926420337
Validation loss: 3.3763132628048975

Epoch: 5| Step: 3
Training loss: 3.076214502432824
Validation loss: 3.384008048217465

Epoch: 5| Step: 4
Training loss: 3.629811480962765
Validation loss: 3.4017145647337026

Epoch: 5| Step: 5
Training loss: 3.464020813040284
Validation loss: 3.345200287083157

Epoch: 5| Step: 6
Training loss: 3.799588085737302
Validation loss: 3.3512137544453697

Epoch: 5| Step: 7
Training loss: 3.282279007642219
Validation loss: 3.3768525161008776

Epoch: 5| Step: 8
Training loss: 4.420132674560547
Validation loss: 3.393839264932721

Epoch: 5| Step: 9
Training loss: 3.162518612049203
Validation loss: 3.3782693211747024

Epoch: 5| Step: 10
Training loss: 3.761143340312809
Validation loss: 3.378132720195031

Epoch: 22| Step: 0
Training loss: 4.357192720400368
Validation loss: 3.387569293010565

Epoch: 5| Step: 1
Training loss: 2.884515688224842
Validation loss: 3.3437145125083707

Epoch: 5| Step: 2
Training loss: 3.7210208146441666
Validation loss: 3.3440306550234733

Epoch: 5| Step: 3
Training loss: 3.7810240118418976
Validation loss: 3.3547979464097484

Epoch: 5| Step: 4
Training loss: 2.909924716827736
Validation loss: 3.362164673082608

Epoch: 5| Step: 5
Training loss: 3.1555809596058464
Validation loss: 3.368506600203747

Epoch: 5| Step: 6
Training loss: 3.204784726249419
Validation loss: 3.3699892676563437

Epoch: 5| Step: 7
Training loss: 4.211553921284253
Validation loss: 3.371088715635803

Epoch: 5| Step: 8
Training loss: 3.7200135720938574
Validation loss: 3.366379766525909

Epoch: 5| Step: 9
Training loss: 3.8321188509355126
Validation loss: 3.356142788161503

Epoch: 5| Step: 10
Training loss: 3.370821308606504
Validation loss: 3.347775196791858

Epoch: 23| Step: 0
Training loss: 2.2220223164712456
Validation loss: 3.340672942247228

Epoch: 5| Step: 1
Training loss: 3.002475035450083
Validation loss: 3.3440837124309857

Epoch: 5| Step: 2
Training loss: 3.7109775902439734
Validation loss: 3.330450368415713

Epoch: 5| Step: 3
Training loss: 4.28417623714102
Validation loss: 3.3305905445458253

Epoch: 5| Step: 4
Training loss: 3.7172430495304214
Validation loss: 3.3327043514153316

Epoch: 5| Step: 5
Training loss: 3.1692018566707287
Validation loss: 3.325114693808108

Epoch: 5| Step: 6
Training loss: 3.524659209315006
Validation loss: 3.3205003841355634

Epoch: 5| Step: 7
Training loss: 3.4801314305008035
Validation loss: 3.3199803965494237

Epoch: 5| Step: 8
Training loss: 3.730931693706089
Validation loss: 3.3184167295582316

Epoch: 5| Step: 9
Training loss: 3.9064254111006234
Validation loss: 3.3168290621676206

Epoch: 5| Step: 10
Training loss: 4.062196925669045
Validation loss: 3.315387741766643

Epoch: 24| Step: 0
Training loss: 3.1672970662975013
Validation loss: 3.3133044729682

Epoch: 5| Step: 1
Training loss: 3.428798412575045
Validation loss: 3.312392493291399

Epoch: 5| Step: 2
Training loss: 3.362379425042513
Validation loss: 3.3100723546515125

Epoch: 5| Step: 3
Training loss: 3.433284185730595
Validation loss: 3.3103255295409038

Epoch: 5| Step: 4
Training loss: 3.81643061400712
Validation loss: 3.310295149762414

Epoch: 5| Step: 5
Training loss: 3.308770437375639
Validation loss: 3.308506758784895

Epoch: 5| Step: 6
Training loss: 3.5906580353255513
Validation loss: 3.308810089934426

Epoch: 5| Step: 7
Training loss: 3.725972190822775
Validation loss: 3.308735719883319

Epoch: 5| Step: 8
Training loss: 3.656326945220665
Validation loss: 3.3066702940722816

Epoch: 5| Step: 9
Training loss: 3.054686719499181
Validation loss: 3.306181357719291

Epoch: 5| Step: 10
Training loss: 4.423964151813204
Validation loss: 3.3048025570009174

Epoch: 25| Step: 0
Training loss: 3.353055892473938
Validation loss: 3.3027366058487035

Epoch: 5| Step: 1
Training loss: 3.029888988009806
Validation loss: 3.301729621910867

Epoch: 5| Step: 2
Training loss: 4.291149861350493
Validation loss: 3.303114164210095

Epoch: 5| Step: 3
Training loss: 2.5878943101388856
Validation loss: 3.304216959438047

Epoch: 5| Step: 4
Training loss: 3.369059668411411
Validation loss: 3.305236792476854

Epoch: 5| Step: 5
Training loss: 3.48292312822877
Validation loss: 3.3058236238833905

Epoch: 5| Step: 6
Training loss: 3.724466114059548
Validation loss: 3.3049605822144392

Epoch: 5| Step: 7
Training loss: 3.6827851234166227
Validation loss: 3.2990160973722533

Epoch: 5| Step: 8
Training loss: 3.4561325025677436
Validation loss: 3.2959882543578862

Epoch: 5| Step: 9
Training loss: 3.849686542978144
Validation loss: 3.297888983175376

Epoch: 5| Step: 10
Training loss: 3.8360553420353836
Validation loss: 3.309191876264481

Epoch: 26| Step: 0
Training loss: 3.15884821242075
Validation loss: 3.316242441963973

Epoch: 5| Step: 1
Training loss: 3.8777463471439293
Validation loss: 3.320149644480672

Epoch: 5| Step: 2
Training loss: 3.756692001564235
Validation loss: 3.306318640917661

Epoch: 5| Step: 3
Training loss: 3.577411963701165
Validation loss: 3.292611119169601

Epoch: 5| Step: 4
Training loss: 3.24767528433839
Validation loss: 3.2873218694768545

Epoch: 5| Step: 5
Training loss: 3.0739694806918787
Validation loss: 3.28704002802999

Epoch: 5| Step: 6
Training loss: 3.6821564573565633
Validation loss: 3.285705930114131

Epoch: 5| Step: 7
Training loss: 3.5243324784042382
Validation loss: 3.2832802565587174

Epoch: 5| Step: 8
Training loss: 3.9229836891568417
Validation loss: 3.284193115405978

Epoch: 5| Step: 9
Training loss: 3.4918761658619633
Validation loss: 3.282892695529162

Epoch: 5| Step: 10
Training loss: 3.455100758652547
Validation loss: 3.2888699903594643

Epoch: 27| Step: 0
Training loss: 3.6535668594551254
Validation loss: 3.290122649156469

Epoch: 5| Step: 1
Training loss: 3.6087659181535128
Validation loss: 3.2908052901291267

Epoch: 5| Step: 2
Training loss: 2.907331368040759
Validation loss: 3.289837455263758

Epoch: 5| Step: 3
Training loss: 3.4340000715039114
Validation loss: 3.2806188661009106

Epoch: 5| Step: 4
Training loss: 3.624676130888525
Validation loss: 3.278468480609622

Epoch: 5| Step: 5
Training loss: 3.676607239820217
Validation loss: 3.278208290905657

Epoch: 5| Step: 6
Training loss: 3.3494497900669
Validation loss: 3.2715383197987817

Epoch: 5| Step: 7
Training loss: 4.4381779972119775
Validation loss: 3.274785193091815

Epoch: 5| Step: 8
Training loss: 3.1964574874946097
Validation loss: 3.2727917358202094

Epoch: 5| Step: 9
Training loss: 3.0779164819720366
Validation loss: 3.272864318939939

Epoch: 5| Step: 10
Training loss: 3.4788785956050527
Validation loss: 3.2689645644909984

Epoch: 28| Step: 0
Training loss: 2.111227620685466
Validation loss: 3.2710163046205585

Epoch: 5| Step: 1
Training loss: 3.736696423546227
Validation loss: 3.269700470160909

Epoch: 5| Step: 2
Training loss: 3.4167019136673176
Validation loss: 3.266832671134066

Epoch: 5| Step: 3
Training loss: 3.803508599400092
Validation loss: 3.2643613133188683

Epoch: 5| Step: 4
Training loss: 3.0370098330753375
Validation loss: 3.263181762063352

Epoch: 5| Step: 5
Training loss: 3.3333308378846045
Validation loss: 3.2625142518148977

Epoch: 5| Step: 6
Training loss: 3.872142476471296
Validation loss: 3.2603439529479177

Epoch: 5| Step: 7
Training loss: 3.781644438040377
Validation loss: 3.2601632216914305

Epoch: 5| Step: 8
Training loss: 3.167370684482238
Validation loss: 3.2568097801736697

Epoch: 5| Step: 9
Training loss: 4.2207532859409405
Validation loss: 3.2575058791672493

Epoch: 5| Step: 10
Training loss: 3.633147455996208
Validation loss: 3.2565104645568264

Epoch: 29| Step: 0
Training loss: 3.4436029530889516
Validation loss: 3.2501899247250816

Epoch: 5| Step: 1
Training loss: 2.5698102558908387
Validation loss: 3.245264819229986

Epoch: 5| Step: 2
Training loss: 3.410558093538272
Validation loss: 3.2431613416833533

Epoch: 5| Step: 3
Training loss: 4.1608205345522835
Validation loss: 3.2398136277187457

Epoch: 5| Step: 4
Training loss: 3.6477076190428748
Validation loss: 3.237705774071383

Epoch: 5| Step: 5
Training loss: 2.8938611859903953
Validation loss: 3.2355739595972417

Epoch: 5| Step: 6
Training loss: 3.8063280770949
Validation loss: 3.234753141590332

Epoch: 5| Step: 7
Training loss: 3.6053318646567174
Validation loss: 3.2342887455941667

Epoch: 5| Step: 8
Training loss: 3.4220709200298387
Validation loss: 3.2327505547037796

Epoch: 5| Step: 9
Training loss: 3.541768300711221
Validation loss: 3.2313312438029436

Epoch: 5| Step: 10
Training loss: 3.581795754382268
Validation loss: 3.230141198450554

Epoch: 30| Step: 0
Training loss: 4.242821408956637
Validation loss: 3.228793579100674

Epoch: 5| Step: 1
Training loss: 3.6454947323466116
Validation loss: 3.2276505313249744

Epoch: 5| Step: 2
Training loss: 2.831628978703719
Validation loss: 3.226691623265119

Epoch: 5| Step: 3
Training loss: 3.561826809638952
Validation loss: 3.2247449204992122

Epoch: 5| Step: 4
Training loss: 2.7052528077059774
Validation loss: 3.2235083687044983

Epoch: 5| Step: 5
Training loss: 3.7346450516487106
Validation loss: 3.2237114377486336

Epoch: 5| Step: 6
Training loss: 3.9001632265021136
Validation loss: 3.2206699432785255

Epoch: 5| Step: 7
Training loss: 3.5733544143605296
Validation loss: 3.2185533134722095

Epoch: 5| Step: 8
Training loss: 3.2021392049653423
Validation loss: 3.21513348149034

Epoch: 5| Step: 9
Training loss: 2.958306343779329
Validation loss: 3.2117908440566807

Epoch: 5| Step: 10
Training loss: 3.4518634683919562
Validation loss: 3.209779601712931

Epoch: 31| Step: 0
Training loss: 3.5835583342654
Validation loss: 3.20832704901163

Epoch: 5| Step: 1
Training loss: 3.155719825859661
Validation loss: 3.2078724117076867

Epoch: 5| Step: 2
Training loss: 3.5658823654275786
Validation loss: 3.2052422521887114

Epoch: 5| Step: 3
Training loss: 3.1924943878196195
Validation loss: 3.2070146052405093

Epoch: 5| Step: 4
Training loss: 2.9169578588539107
Validation loss: 3.2063048803179055

Epoch: 5| Step: 5
Training loss: 4.059561737910418
Validation loss: 3.2011920337922826

Epoch: 5| Step: 6
Training loss: 3.21619573186346
Validation loss: 3.2038747466767563

Epoch: 5| Step: 7
Training loss: 3.1778145037339107
Validation loss: 3.2032114324906154

Epoch: 5| Step: 8
Training loss: 3.7370705552396073
Validation loss: 3.194523632702238

Epoch: 5| Step: 9
Training loss: 3.0756099127074035
Validation loss: 3.1934383787349883

Epoch: 5| Step: 10
Training loss: 4.116684363529196
Validation loss: 3.1936716214621512

Epoch: 32| Step: 0
Training loss: 3.6906108342350255
Validation loss: 3.1938105380609922

Epoch: 5| Step: 1
Training loss: 3.2315334055592118
Validation loss: 3.1913985319324523

Epoch: 5| Step: 2
Training loss: 3.459528168937545
Validation loss: 3.190395355228214

Epoch: 5| Step: 3
Training loss: 2.9289768018184814
Validation loss: 3.187939843737785

Epoch: 5| Step: 4
Training loss: 3.201603374527464
Validation loss: 3.1873996919101635

Epoch: 5| Step: 5
Training loss: 2.540153292588345
Validation loss: 3.184732413505305

Epoch: 5| Step: 6
Training loss: 3.8463790710235273
Validation loss: 3.1839599286047457

Epoch: 5| Step: 7
Training loss: 3.432517029344251
Validation loss: 3.1816754223866646

Epoch: 5| Step: 8
Training loss: 3.8822854987319713
Validation loss: 3.180111616949934

Epoch: 5| Step: 9
Training loss: 3.4625252898356518
Validation loss: 3.179373030279633

Epoch: 5| Step: 10
Training loss: 3.945892351804135
Validation loss: 3.1792540758614805

Epoch: 33| Step: 0
Training loss: 2.9497511225314397
Validation loss: 3.178210080504772

Epoch: 5| Step: 1
Training loss: 2.993960022378486
Validation loss: 3.17679522233613

Epoch: 5| Step: 2
Training loss: 3.636623950874052
Validation loss: 3.1756685207662585

Epoch: 5| Step: 3
Training loss: 3.5198566654672985
Validation loss: 3.173074391767029

Epoch: 5| Step: 4
Training loss: 3.6275670400428
Validation loss: 3.1723125985765392

Epoch: 5| Step: 5
Training loss: 4.07175740608689
Validation loss: 3.1746669144660205

Epoch: 5| Step: 6
Training loss: 2.784974936298887
Validation loss: 3.1694921739682793

Epoch: 5| Step: 7
Training loss: 3.642601688094029
Validation loss: 3.169250126363206

Epoch: 5| Step: 8
Training loss: 3.817697453017124
Validation loss: 3.168266006389353

Epoch: 5| Step: 9
Training loss: 3.353595534957214
Validation loss: 3.167359652466666

Epoch: 5| Step: 10
Training loss: 2.9759524063078318
Validation loss: 3.167244187936668

Epoch: 34| Step: 0
Training loss: 4.296369599183488
Validation loss: 3.1665250496104624

Epoch: 5| Step: 1
Training loss: 3.371847446389174
Validation loss: 3.162612382204497

Epoch: 5| Step: 2
Training loss: 3.1156629309454478
Validation loss: 3.1638702913516705

Epoch: 5| Step: 3
Training loss: 3.1394433982425998
Validation loss: 3.1620285969486006

Epoch: 5| Step: 4
Training loss: 3.5397563195276227
Validation loss: 3.1611304233285815

Epoch: 5| Step: 5
Training loss: 3.420674988910923
Validation loss: 3.162293236000586

Epoch: 5| Step: 6
Training loss: 3.8854927007822355
Validation loss: 3.1591177621416406

Epoch: 5| Step: 7
Training loss: 3.160142820728187
Validation loss: 3.159322694652376

Epoch: 5| Step: 8
Training loss: 3.3040984510296725
Validation loss: 3.1596350446470387

Epoch: 5| Step: 9
Training loss: 3.2361463036394955
Validation loss: 3.161203576894931

Epoch: 5| Step: 10
Training loss: 2.812575445222901
Validation loss: 3.159763410887933

Epoch: 35| Step: 0
Training loss: 2.5788197823872334
Validation loss: 3.1564443035620537

Epoch: 5| Step: 1
Training loss: 2.7745805131178285
Validation loss: 3.154203970317589

Epoch: 5| Step: 2
Training loss: 3.0899334109640444
Validation loss: 3.1536653654116327

Epoch: 5| Step: 3
Training loss: 4.207434278077995
Validation loss: 3.153611397596075

Epoch: 5| Step: 4
Training loss: 3.924635079300529
Validation loss: 3.1530780446569033

Epoch: 5| Step: 5
Training loss: 3.7423277890343347
Validation loss: 3.1516884690718734

Epoch: 5| Step: 6
Training loss: 3.1706115010111597
Validation loss: 3.1507213576513693

Epoch: 5| Step: 7
Training loss: 3.395113176304942
Validation loss: 3.148868571281178

Epoch: 5| Step: 8
Training loss: 3.232930178595395
Validation loss: 3.1483594955535703

Epoch: 5| Step: 9
Training loss: 3.8685615949713035
Validation loss: 3.1486660783699274

Epoch: 5| Step: 10
Training loss: 3.0746637238022196
Validation loss: 3.1475410240609465

Epoch: 36| Step: 0
Training loss: 3.7608045693183736
Validation loss: 3.145948113885533

Epoch: 5| Step: 1
Training loss: 3.082133360356977
Validation loss: 3.1463901494489326

Epoch: 5| Step: 2
Training loss: 3.175028919478745
Validation loss: 3.1507851274091703

Epoch: 5| Step: 3
Training loss: 2.7041305700243083
Validation loss: 3.147420205184967

Epoch: 5| Step: 4
Training loss: 3.5393789794080384
Validation loss: 3.1439160249018108

Epoch: 5| Step: 5
Training loss: 3.5358992496567465
Validation loss: 3.1403194469251274

Epoch: 5| Step: 6
Training loss: 4.0360989055783
Validation loss: 3.1408529715685796

Epoch: 5| Step: 7
Training loss: 3.4232166743126253
Validation loss: 3.140510817809003

Epoch: 5| Step: 8
Training loss: 3.449565589202708
Validation loss: 3.139874378356621

Epoch: 5| Step: 9
Training loss: 2.947067425979433
Validation loss: 3.1381644447104797

Epoch: 5| Step: 10
Training loss: 3.5761673415283934
Validation loss: 3.136402237825769

Epoch: 37| Step: 0
Training loss: 3.8109043722054006
Validation loss: 3.1374004423554402

Epoch: 5| Step: 1
Training loss: 3.2527364801148315
Validation loss: 3.1378358003724514

Epoch: 5| Step: 2
Training loss: 3.7150597735148994
Validation loss: 3.135172074430966

Epoch: 5| Step: 3
Training loss: 3.9370860533123384
Validation loss: 3.1345385978106086

Epoch: 5| Step: 4
Training loss: 3.5039383664567696
Validation loss: 3.1337741319747585

Epoch: 5| Step: 5
Training loss: 3.0296954071744415
Validation loss: 3.132483146850053

Epoch: 5| Step: 6
Training loss: 3.016300738429993
Validation loss: 3.131261800658157

Epoch: 5| Step: 7
Training loss: 2.60413075740216
Validation loss: 3.1311159038348606

Epoch: 5| Step: 8
Training loss: 3.435617520992306
Validation loss: 3.131637142041588

Epoch: 5| Step: 9
Training loss: 3.0261694421016103
Validation loss: 3.1344047638460797

Epoch: 5| Step: 10
Training loss: 3.764271346426988
Validation loss: 3.1370159847043655

Epoch: 38| Step: 0
Training loss: 3.4756354649726973
Validation loss: 3.1451750008531656

Epoch: 5| Step: 1
Training loss: 2.668821765372489
Validation loss: 3.1375202490269145

Epoch: 5| Step: 2
Training loss: 3.2309289532958037
Validation loss: 3.129379676835293

Epoch: 5| Step: 3
Training loss: 3.4901220712381327
Validation loss: 3.126465725639051

Epoch: 5| Step: 4
Training loss: 3.469186978695708
Validation loss: 3.1266424461016276

Epoch: 5| Step: 5
Training loss: 3.3084118645585465
Validation loss: 3.1265804010756852

Epoch: 5| Step: 6
Training loss: 3.545361569881674
Validation loss: 3.1237536859427593

Epoch: 5| Step: 7
Training loss: 3.7813587015464085
Validation loss: 3.1231976896412794

Epoch: 5| Step: 8
Training loss: 3.5279636450903378
Validation loss: 3.1226654963968197

Epoch: 5| Step: 9
Training loss: 3.340706697041322
Validation loss: 3.1212105932525134

Epoch: 5| Step: 10
Training loss: 3.2454178125873527
Validation loss: 3.1205682384617273

Epoch: 39| Step: 0
Training loss: 3.313761057221892
Validation loss: 3.1211604939366033

Epoch: 5| Step: 1
Training loss: 3.0022282272694194
Validation loss: 3.118426704719068

Epoch: 5| Step: 2
Training loss: 3.029399818427356
Validation loss: 3.117623354333304

Epoch: 5| Step: 3
Training loss: 3.3846379876215678
Validation loss: 3.1168581292834316

Epoch: 5| Step: 4
Training loss: 3.5936476983146317
Validation loss: 3.1166600301699425

Epoch: 5| Step: 5
Training loss: 2.6480799971018674
Validation loss: 3.1173408645954632

Epoch: 5| Step: 6
Training loss: 3.031505770559983
Validation loss: 3.1203966539037236

Epoch: 5| Step: 7
Training loss: 4.153480697107562
Validation loss: 3.118922292803527

Epoch: 5| Step: 8
Training loss: 3.2702245125414184
Validation loss: 3.1148987962645878

Epoch: 5| Step: 9
Training loss: 3.393837527556696
Validation loss: 3.111742590494224

Epoch: 5| Step: 10
Training loss: 4.148800706498939
Validation loss: 3.1094093562018434

Epoch: 40| Step: 0
Training loss: 3.526716309566396
Validation loss: 3.1094940668985096

Epoch: 5| Step: 1
Training loss: 3.1875721044425815
Validation loss: 3.107137165703888

Epoch: 5| Step: 2
Training loss: 3.8394447344421367
Validation loss: 3.1105525433203733

Epoch: 5| Step: 3
Training loss: 3.5743289451080065
Validation loss: 3.1072014388689713

Epoch: 5| Step: 4
Training loss: 3.390407854149773
Validation loss: 3.106830593289038

Epoch: 5| Step: 5
Training loss: 3.630883670785106
Validation loss: 3.1056422043704948

Epoch: 5| Step: 6
Training loss: 3.1596532923593816
Validation loss: 3.104083052177538

Epoch: 5| Step: 7
Training loss: 2.910765882297202
Validation loss: 3.1061730390375337

Epoch: 5| Step: 8
Training loss: 3.4890409285292354
Validation loss: 3.110071936980438

Epoch: 5| Step: 9
Training loss: 3.09126413060594
Validation loss: 3.1067081944987667

Epoch: 5| Step: 10
Training loss: 3.141606419505882
Validation loss: 3.1056222112186864

Epoch: 41| Step: 0
Training loss: 3.188244003530753
Validation loss: 3.1022870609257636

Epoch: 5| Step: 1
Training loss: 2.789832428305927
Validation loss: 3.1026084778752527

Epoch: 5| Step: 2
Training loss: 3.138993935716792
Validation loss: 3.1035845262219808

Epoch: 5| Step: 3
Training loss: 3.1897643778967475
Validation loss: 3.10030387331176

Epoch: 5| Step: 4
Training loss: 3.113378506509043
Validation loss: 3.0965376933690285

Epoch: 5| Step: 5
Training loss: 3.719483759960889
Validation loss: 3.0976304368438177

Epoch: 5| Step: 6
Training loss: 4.233564573765722
Validation loss: 3.095541420364746

Epoch: 5| Step: 7
Training loss: 2.7063728181311224
Validation loss: 3.0943895335449785

Epoch: 5| Step: 8
Training loss: 2.812527635226643
Validation loss: 3.094059572033475

Epoch: 5| Step: 9
Training loss: 3.970259972427149
Validation loss: 3.095184176053237

Epoch: 5| Step: 10
Training loss: 3.7884134582245035
Validation loss: 3.101150610570208

Epoch: 42| Step: 0
Training loss: 3.2090001259694083
Validation loss: 3.114562109677587

Epoch: 5| Step: 1
Training loss: 2.981228432887218
Validation loss: 3.08888046851429

Epoch: 5| Step: 2
Training loss: 3.2916199081254613
Validation loss: 3.0884879399004257

Epoch: 5| Step: 3
Training loss: 3.793580937899897
Validation loss: 3.0887005167881796

Epoch: 5| Step: 4
Training loss: 3.3377730525756975
Validation loss: 3.0907511433182138

Epoch: 5| Step: 5
Training loss: 3.617871477289386
Validation loss: 3.0915306411532404

Epoch: 5| Step: 6
Training loss: 3.1282158136285516
Validation loss: 3.088142334480043

Epoch: 5| Step: 7
Training loss: 3.166172557897285
Validation loss: 3.0846715920232604

Epoch: 5| Step: 8
Training loss: 3.9643978976917977
Validation loss: 3.084361034513424

Epoch: 5| Step: 9
Training loss: 3.2081582322992173
Validation loss: 3.0847300254287218

Epoch: 5| Step: 10
Training loss: 3.011241197141684
Validation loss: 3.083813744334281

Epoch: 43| Step: 0
Training loss: 2.5532981524355343
Validation loss: 3.08286605682079

Epoch: 5| Step: 1
Training loss: 3.6962159163419726
Validation loss: 3.0825476844161983

Epoch: 5| Step: 2
Training loss: 3.5514605620389847
Validation loss: 3.0884855011733507

Epoch: 5| Step: 3
Training loss: 3.646353344843873
Validation loss: 3.0994837828961153

Epoch: 5| Step: 4
Training loss: 3.0324129056570626
Validation loss: 3.102475765310417

Epoch: 5| Step: 5
Training loss: 4.007627843577443
Validation loss: 3.091919689959884

Epoch: 5| Step: 6
Training loss: 2.591658058847277
Validation loss: 3.0758285405345442

Epoch: 5| Step: 7
Training loss: 3.3972852134600413
Validation loss: 3.0762619461126497

Epoch: 5| Step: 8
Training loss: 3.2278662903804145
Validation loss: 3.0752573113574377

Epoch: 5| Step: 9
Training loss: 3.6631149661023215
Validation loss: 3.0761446014669307

Epoch: 5| Step: 10
Training loss: 3.1193697755036487
Validation loss: 3.0790490187269657

Epoch: 44| Step: 0
Training loss: 3.7193687629423056
Validation loss: 3.08264167586412

Epoch: 5| Step: 1
Training loss: 3.531220427532768
Validation loss: 3.071932142138885

Epoch: 5| Step: 2
Training loss: 3.2339375517978426
Validation loss: 3.070389083144745

Epoch: 5| Step: 3
Training loss: 3.458628967395382
Validation loss: 3.070621928591966

Epoch: 5| Step: 4
Training loss: 2.343271639008617
Validation loss: 3.0697727801415207

Epoch: 5| Step: 5
Training loss: 3.7914616176509184
Validation loss: 3.068483396225168

Epoch: 5| Step: 6
Training loss: 2.7425820265181087
Validation loss: 3.0673338106439427

Epoch: 5| Step: 7
Training loss: 2.623470314824876
Validation loss: 3.067022610944945

Epoch: 5| Step: 8
Training loss: 4.0646861136519075
Validation loss: 3.0655337574625197

Epoch: 5| Step: 9
Training loss: 3.476807866385242
Validation loss: 3.063488349372904

Epoch: 5| Step: 10
Training loss: 3.32356142746509
Validation loss: 3.064774683681284

Epoch: 45| Step: 0
Training loss: 2.2774892665639426
Validation loss: 3.0640647076972285

Epoch: 5| Step: 1
Training loss: 3.302991066403482
Validation loss: 3.062170570574488

Epoch: 5| Step: 2
Training loss: 2.8329879512833616
Validation loss: 3.0618513222674677

Epoch: 5| Step: 3
Training loss: 3.2174386621658857
Validation loss: 3.0606110116889904

Epoch: 5| Step: 4
Training loss: 3.9808705195451646
Validation loss: 3.060648542868621

Epoch: 5| Step: 5
Training loss: 2.981423081466004
Validation loss: 3.0613320831491935

Epoch: 5| Step: 6
Training loss: 3.2928258247174673
Validation loss: 3.0609520538352095

Epoch: 5| Step: 7
Training loss: 2.9739583155180513
Validation loss: 3.0618748565695832

Epoch: 5| Step: 8
Training loss: 3.5357598058239166
Validation loss: 3.0607457447002604

Epoch: 5| Step: 9
Training loss: 3.611276101149752
Validation loss: 3.061137336770132

Epoch: 5| Step: 10
Training loss: 4.343175836392673
Validation loss: 3.058037061463334

Epoch: 46| Step: 0
Training loss: 3.2833169875407746
Validation loss: 3.0567237989200193

Epoch: 5| Step: 1
Training loss: 3.0087638638489596
Validation loss: 3.055831785074424

Epoch: 5| Step: 2
Training loss: 2.9105529105195944
Validation loss: 3.053411504232297

Epoch: 5| Step: 3
Training loss: 3.6374812489449044
Validation loss: 3.0523056043973824

Epoch: 5| Step: 4
Training loss: 3.488494490612699
Validation loss: 3.052158601034294

Epoch: 5| Step: 5
Training loss: 3.7104831136286602
Validation loss: 3.0518118829215335

Epoch: 5| Step: 6
Training loss: 3.8365331369910605
Validation loss: 3.0506270737852135

Epoch: 5| Step: 7
Training loss: 2.741324699278172
Validation loss: 3.0500431372437884

Epoch: 5| Step: 8
Training loss: 2.9381274912616075
Validation loss: 3.0520743081850004

Epoch: 5| Step: 9
Training loss: 3.638241491086173
Validation loss: 3.0739146674543263

Epoch: 5| Step: 10
Training loss: 3.1000702388558623
Validation loss: 3.091765779123241

Epoch: 47| Step: 0
Training loss: 3.325694024642741
Validation loss: 3.071812959616468

Epoch: 5| Step: 1
Training loss: 2.609093382480477
Validation loss: 3.050284654515987

Epoch: 5| Step: 2
Training loss: 3.5612437392314
Validation loss: 3.0482293799096407

Epoch: 5| Step: 3
Training loss: 3.6503903637473156
Validation loss: 3.0485229024083256

Epoch: 5| Step: 4
Training loss: 3.747384367132859
Validation loss: 3.046210132267486

Epoch: 5| Step: 5
Training loss: 3.582291754814754
Validation loss: 3.0501593646491076

Epoch: 5| Step: 6
Training loss: 3.2225770882796247
Validation loss: 3.053290552591968

Epoch: 5| Step: 7
Training loss: 2.8346946662220973
Validation loss: 3.050352768793525

Epoch: 5| Step: 8
Training loss: 3.322142619480308
Validation loss: 3.065619509955266

Epoch: 5| Step: 9
Training loss: 3.3370285215499274
Validation loss: 3.0825456285447523

Epoch: 5| Step: 10
Training loss: 3.23832836968131
Validation loss: 3.0494562271852796

Epoch: 48| Step: 0
Training loss: 2.993753765318858
Validation loss: 3.040866189076824

Epoch: 5| Step: 1
Training loss: 3.3404915878448063
Validation loss: 3.0455619664752422

Epoch: 5| Step: 2
Training loss: 3.89482153879106
Validation loss: 3.0486488851660853

Epoch: 5| Step: 3
Training loss: 2.7590633505792805
Validation loss: 3.052727705419988

Epoch: 5| Step: 4
Training loss: 3.220109670915668
Validation loss: 3.045357458397855

Epoch: 5| Step: 5
Training loss: 3.5770307308558733
Validation loss: 3.0457192239004436

Epoch: 5| Step: 6
Training loss: 2.590231381689145
Validation loss: 3.0394914333181613

Epoch: 5| Step: 7
Training loss: 3.764453753275085
Validation loss: 3.043903014744512

Epoch: 5| Step: 8
Training loss: 3.0903664013064422
Validation loss: 3.0413601887081874

Epoch: 5| Step: 9
Training loss: 3.3209937260725564
Validation loss: 3.0387996107835624

Epoch: 5| Step: 10
Training loss: 3.735197862442395
Validation loss: 3.0390001313742583

Epoch: 49| Step: 0
Training loss: 3.809006763463264
Validation loss: 3.0403619949840293

Epoch: 5| Step: 1
Training loss: 2.229110384316746
Validation loss: 3.039940958228265

Epoch: 5| Step: 2
Training loss: 2.9688664463696233
Validation loss: 3.0419570142590624

Epoch: 5| Step: 3
Training loss: 3.283786628788948
Validation loss: 3.0343384422199606

Epoch: 5| Step: 4
Training loss: 3.847621549653171
Validation loss: 3.0325304664799417

Epoch: 5| Step: 5
Training loss: 3.750828587861623
Validation loss: 3.029512349454372

Epoch: 5| Step: 6
Training loss: 3.632811843707938
Validation loss: 3.029610338709117

Epoch: 5| Step: 7
Training loss: 2.73991069119107
Validation loss: 3.026935878115361

Epoch: 5| Step: 8
Training loss: 3.1091763993677253
Validation loss: 3.028742478830139

Epoch: 5| Step: 9
Training loss: 3.3792521217036433
Validation loss: 3.0267143132364906

Epoch: 5| Step: 10
Training loss: 3.2181598900144404
Validation loss: 3.02487974688042

Epoch: 50| Step: 0
Training loss: 4.254236465962511
Validation loss: 3.0380282035072117

Epoch: 5| Step: 1
Training loss: 2.843349218946521
Validation loss: 3.023695160792928

Epoch: 5| Step: 2
Training loss: 3.478986602204773
Validation loss: 3.0238558478815256

Epoch: 5| Step: 3
Training loss: 3.4764492059313765
Validation loss: 3.022565480993541

Epoch: 5| Step: 4
Training loss: 3.2494463815862846
Validation loss: 3.0211895968462334

Epoch: 5| Step: 5
Training loss: 2.8926003794615722
Validation loss: 3.019096592096291

Epoch: 5| Step: 6
Training loss: 3.582232919921026
Validation loss: 3.017790202237466

Epoch: 5| Step: 7
Training loss: 3.034607119575485
Validation loss: 3.016967810268453

Epoch: 5| Step: 8
Training loss: 2.776150604076384
Validation loss: 3.0167114759167655

Epoch: 5| Step: 9
Training loss: 2.72222651807831
Validation loss: 3.016339248454608

Epoch: 5| Step: 10
Training loss: 3.6835374392981843
Validation loss: 3.016086108492483

Epoch: 51| Step: 0
Training loss: 3.0032289929599565
Validation loss: 3.015098373197816

Epoch: 5| Step: 1
Training loss: 2.717701150561299
Validation loss: 3.0139396948876778

Epoch: 5| Step: 2
Training loss: 3.51292838202841
Validation loss: 3.016171062017173

Epoch: 5| Step: 3
Training loss: 2.993290869561019
Validation loss: 3.013370538114429

Epoch: 5| Step: 4
Training loss: 3.382296269520098
Validation loss: 3.0147162922695805

Epoch: 5| Step: 5
Training loss: 3.1199143799013203
Validation loss: 3.012187022628724

Epoch: 5| Step: 6
Training loss: 3.5574799353327924
Validation loss: 3.0094071404513727

Epoch: 5| Step: 7
Training loss: 3.5368224880205084
Validation loss: 3.0085346089711775

Epoch: 5| Step: 8
Training loss: 3.5802051877513064
Validation loss: 3.0098402241613953

Epoch: 5| Step: 9
Training loss: 3.4106352689230888
Validation loss: 3.0075742224718147

Epoch: 5| Step: 10
Training loss: 3.1930396616999555
Validation loss: 3.006874449380372

Epoch: 52| Step: 0
Training loss: 3.7908521063717076
Validation loss: 3.006832704423531

Epoch: 5| Step: 1
Training loss: 3.372849803793551
Validation loss: 3.0068345187664502

Epoch: 5| Step: 2
Training loss: 3.128345987019651
Validation loss: 3.008676105730907

Epoch: 5| Step: 3
Training loss: 2.9015966098076698
Validation loss: 3.013704338949188

Epoch: 5| Step: 4
Training loss: 3.2287430680245226
Validation loss: 3.0101846568001496

Epoch: 5| Step: 5
Training loss: 2.5822895053630326
Validation loss: 3.0107561196763246

Epoch: 5| Step: 6
Training loss: 3.319682270151145
Validation loss: 3.013846655421308

Epoch: 5| Step: 7
Training loss: 3.5559195259351353
Validation loss: 3.0053938415657546

Epoch: 5| Step: 8
Training loss: 3.3347118547172405
Validation loss: 3.008320618012506

Epoch: 5| Step: 9
Training loss: 3.3708664341178807
Validation loss: 3.008269051958192

Epoch: 5| Step: 10
Training loss: 3.3031878303896787
Validation loss: 3.0064770106780982

Epoch: 53| Step: 0
Training loss: 2.831652217361859
Validation loss: 3.0003283416700217

Epoch: 5| Step: 1
Training loss: 2.9908085526567927
Validation loss: 3.0046070300828958

Epoch: 5| Step: 2
Training loss: 3.3894807493274004
Validation loss: 3.001872545607648

Epoch: 5| Step: 3
Training loss: 3.5474156711225127
Validation loss: 2.9974328426139922

Epoch: 5| Step: 4
Training loss: 2.756456165864031
Validation loss: 2.99565962288777

Epoch: 5| Step: 5
Training loss: 3.605240472611563
Validation loss: 2.995353552854679

Epoch: 5| Step: 6
Training loss: 3.4574681927258473
Validation loss: 2.9940930916148267

Epoch: 5| Step: 7
Training loss: 3.646427098924172
Validation loss: 2.99334512937867

Epoch: 5| Step: 8
Training loss: 2.9986906373165736
Validation loss: 2.9915215876765355

Epoch: 5| Step: 9
Training loss: 2.9729031073072347
Validation loss: 2.991201239018326

Epoch: 5| Step: 10
Training loss: 3.645349931913071
Validation loss: 2.989416606504852

Epoch: 54| Step: 0
Training loss: 3.0876778246369687
Validation loss: 2.9892705944079982

Epoch: 5| Step: 1
Training loss: 3.4096438797503104
Validation loss: 2.9906199154813975

Epoch: 5| Step: 2
Training loss: 3.8310174718989622
Validation loss: 2.9921919809459583

Epoch: 5| Step: 3
Training loss: 3.609688617242788
Validation loss: 2.988707876263839

Epoch: 5| Step: 4
Training loss: 2.9772307679543917
Validation loss: 2.987114055086954

Epoch: 5| Step: 5
Training loss: 2.986375547622567
Validation loss: 2.9923072563287594

Epoch: 5| Step: 6
Training loss: 2.283259617063367
Validation loss: 2.9934876772597807

Epoch: 5| Step: 7
Training loss: 3.0206172120404142
Validation loss: 2.9932388321752574

Epoch: 5| Step: 8
Training loss: 3.606333057630506
Validation loss: 2.9905823532655353

Epoch: 5| Step: 9
Training loss: 3.5321670286747526
Validation loss: 2.9874736082950455

Epoch: 5| Step: 10
Training loss: 3.4085884116929033
Validation loss: 2.9878481997323276

Epoch: 55| Step: 0
Training loss: 2.9687040626585715
Validation loss: 2.9888918977717123

Epoch: 5| Step: 1
Training loss: 3.5234863548528854
Validation loss: 2.9977482938737943

Epoch: 5| Step: 2
Training loss: 2.25300778574811
Validation loss: 2.9914923357608383

Epoch: 5| Step: 3
Training loss: 3.1743328925530387
Validation loss: 2.994430251104404

Epoch: 5| Step: 4
Training loss: 3.1502438042159495
Validation loss: 2.991769536178684

Epoch: 5| Step: 5
Training loss: 3.7427692638052057
Validation loss: 2.9972812645695415

Epoch: 5| Step: 6
Training loss: 3.067789142539542
Validation loss: 2.9832032457914126

Epoch: 5| Step: 7
Training loss: 3.174410703743301
Validation loss: 2.9882502968783093

Epoch: 5| Step: 8
Training loss: 3.905801732091653
Validation loss: 2.9865620768526626

Epoch: 5| Step: 9
Training loss: 3.022856111837938
Validation loss: 2.9815419133344236

Epoch: 5| Step: 10
Training loss: 3.651139298392973
Validation loss: 2.978856257651681

Epoch: 56| Step: 0
Training loss: 2.648323259168429
Validation loss: 2.978849047432261

Epoch: 5| Step: 1
Training loss: 3.5799510577388713
Validation loss: 2.978822526618268

Epoch: 5| Step: 2
Training loss: 3.0983795052860867
Validation loss: 2.9781815605223096

Epoch: 5| Step: 3
Training loss: 3.972759354265226
Validation loss: 2.978905040205569

Epoch: 5| Step: 4
Training loss: 2.5026912508661283
Validation loss: 2.9778222770212266

Epoch: 5| Step: 5
Training loss: 3.2973124860152594
Validation loss: 2.9772397869164537

Epoch: 5| Step: 6
Training loss: 3.1132055869295328
Validation loss: 2.9755741479134477

Epoch: 5| Step: 7
Training loss: 3.2008617313723904
Validation loss: 2.9741018503571732

Epoch: 5| Step: 8
Training loss: 3.218667779261226
Validation loss: 2.9738611773988146

Epoch: 5| Step: 9
Training loss: 4.120671862661651
Validation loss: 2.972701253525135

Epoch: 5| Step: 10
Training loss: 2.585481724521226
Validation loss: 2.9709448774308886

Epoch: 57| Step: 0
Training loss: 3.402296659404313
Validation loss: 2.9707438640143664

Epoch: 5| Step: 1
Training loss: 3.104891050334656
Validation loss: 2.9690871897268223

Epoch: 5| Step: 2
Training loss: 3.6388491773177565
Validation loss: 2.9677119669865744

Epoch: 5| Step: 3
Training loss: 3.8201534807618853
Validation loss: 2.969647134782664

Epoch: 5| Step: 4
Training loss: 3.6376697513783154
Validation loss: 2.965851024299966

Epoch: 5| Step: 5
Training loss: 3.942204888812348
Validation loss: 2.9661923352041777

Epoch: 5| Step: 6
Training loss: 2.8842921814440805
Validation loss: 2.965867883240092

Epoch: 5| Step: 7
Training loss: 2.828669205884343
Validation loss: 2.9651122356350172

Epoch: 5| Step: 8
Training loss: 3.145550864634745
Validation loss: 2.966053368473355

Epoch: 5| Step: 9
Training loss: 2.56202953951123
Validation loss: 2.9618864344902023

Epoch: 5| Step: 10
Training loss: 2.2070683028900184
Validation loss: 2.9628812707692274

Epoch: 58| Step: 0
Training loss: 3.114794125435525
Validation loss: 2.9704623229559473

Epoch: 5| Step: 1
Training loss: 3.8972114668577102
Validation loss: 2.9770146232915264

Epoch: 5| Step: 2
Training loss: 3.14149334039002
Validation loss: 2.9593018508129623

Epoch: 5| Step: 3
Training loss: 2.7661983089728417
Validation loss: 2.9595317524754927

Epoch: 5| Step: 4
Training loss: 3.2789230088120833
Validation loss: 2.959208713527246

Epoch: 5| Step: 5
Training loss: 3.424670466699089
Validation loss: 2.957274706104722

Epoch: 5| Step: 6
Training loss: 3.1973791178028024
Validation loss: 2.9567812762767063

Epoch: 5| Step: 7
Training loss: 2.7929801033696253
Validation loss: 2.9597411670085783

Epoch: 5| Step: 8
Training loss: 3.480020719006126
Validation loss: 2.9591836921823407

Epoch: 5| Step: 9
Training loss: 3.443241249347553
Validation loss: 2.95276328976957

Epoch: 5| Step: 10
Training loss: 2.9250611258094557
Validation loss: 2.9526786147797353

Epoch: 59| Step: 0
Training loss: 3.028179383158619
Validation loss: 2.952211178609268

Epoch: 5| Step: 1
Training loss: 2.7462183352951173
Validation loss: 2.952962365321687

Epoch: 5| Step: 2
Training loss: 3.0959879169573323
Validation loss: 2.958353518865325

Epoch: 5| Step: 3
Training loss: 3.3587105027301627
Validation loss: 2.957364077951291

Epoch: 5| Step: 4
Training loss: 2.9331878503210453
Validation loss: 2.9540512213285965

Epoch: 5| Step: 5
Training loss: 3.131315182675547
Validation loss: 2.9541162252202087

Epoch: 5| Step: 6
Training loss: 2.9473293694440232
Validation loss: 2.9532208274949476

Epoch: 5| Step: 7
Training loss: 3.027045096155681
Validation loss: 2.9514049636882413

Epoch: 5| Step: 8
Training loss: 3.6543336720655373
Validation loss: 2.9520705689357567

Epoch: 5| Step: 9
Training loss: 4.021026185044129
Validation loss: 2.946999637724565

Epoch: 5| Step: 10
Training loss: 3.4828810974731454
Validation loss: 2.9459455970657733

Epoch: 60| Step: 0
Training loss: 3.2131420280630114
Validation loss: 2.9470520870725023

Epoch: 5| Step: 1
Training loss: 2.984632710619074
Validation loss: 2.943399968144205

Epoch: 5| Step: 2
Training loss: 3.002672118018822
Validation loss: 2.943011760976385

Epoch: 5| Step: 3
Training loss: 2.847522622572044
Validation loss: 2.940940517736614

Epoch: 5| Step: 4
Training loss: 3.4808800108628297
Validation loss: 2.9402473830675935

Epoch: 5| Step: 5
Training loss: 3.2484700930209387
Validation loss: 2.941944825553473

Epoch: 5| Step: 6
Training loss: 3.7243581846177336
Validation loss: 2.9385633671223967

Epoch: 5| Step: 7
Training loss: 2.8129021251153614
Validation loss: 2.943998625447241

Epoch: 5| Step: 8
Training loss: 4.054513916533674
Validation loss: 2.950350931066546

Epoch: 5| Step: 9
Training loss: 3.2480568578845386
Validation loss: 2.951674201842549

Epoch: 5| Step: 10
Training loss: 2.520273025496816
Validation loss: 2.950242641614191

Epoch: 61| Step: 0
Training loss: 2.968838178429351
Validation loss: 2.9455071424649986

Epoch: 5| Step: 1
Training loss: 3.142144438203347
Validation loss: 2.9415713834234998

Epoch: 5| Step: 2
Training loss: 3.3537431216515956
Validation loss: 2.940029161241796

Epoch: 5| Step: 3
Training loss: 2.1846091651104707
Validation loss: 2.9387336885944504

Epoch: 5| Step: 4
Training loss: 3.6283318564943934
Validation loss: 2.9379554592677133

Epoch: 5| Step: 5
Training loss: 3.0084506856443736
Validation loss: 2.934075580817601

Epoch: 5| Step: 6
Training loss: 2.975373919413684
Validation loss: 2.9333074161870583

Epoch: 5| Step: 7
Training loss: 3.1613065797351356
Validation loss: 2.933316677697385

Epoch: 5| Step: 8
Training loss: 3.8443755594475464
Validation loss: 2.9287700999086073

Epoch: 5| Step: 9
Training loss: 3.6523395721901237
Validation loss: 2.929945523401908

Epoch: 5| Step: 10
Training loss: 3.2047174728531918
Validation loss: 2.9288843370125344

Epoch: 62| Step: 0
Training loss: 3.0820142312782655
Validation loss: 2.9278217016890626

Epoch: 5| Step: 1
Training loss: 2.6751571929949587
Validation loss: 2.926744158441139

Epoch: 5| Step: 2
Training loss: 2.9829567939782855
Validation loss: 2.927738474742502

Epoch: 5| Step: 3
Training loss: 3.1566376400841287
Validation loss: 2.926505082961785

Epoch: 5| Step: 4
Training loss: 3.3377121932907428
Validation loss: 2.925396359806927

Epoch: 5| Step: 5
Training loss: 2.4655409611254786
Validation loss: 2.925340253379563

Epoch: 5| Step: 6
Training loss: 4.047732700493999
Validation loss: 2.9258714839396847

Epoch: 5| Step: 7
Training loss: 3.0640581799155227
Validation loss: 2.9249813336215955

Epoch: 5| Step: 8
Training loss: 3.2459716773921685
Validation loss: 2.9262879879670542

Epoch: 5| Step: 9
Training loss: 3.711864604585334
Validation loss: 2.9248523030145877

Epoch: 5| Step: 10
Training loss: 3.3273045061264317
Validation loss: 2.9219013322818594

Epoch: 63| Step: 0
Training loss: 3.1209947477258
Validation loss: 2.9231545313575853

Epoch: 5| Step: 1
Training loss: 2.6983888622819734
Validation loss: 2.923166661280818

Epoch: 5| Step: 2
Training loss: 2.978298852255214
Validation loss: 2.920682428477048

Epoch: 5| Step: 3
Training loss: 3.2198562943040234
Validation loss: 2.920741583229945

Epoch: 5| Step: 4
Training loss: 3.0350912079782826
Validation loss: 2.920204859666704

Epoch: 5| Step: 5
Training loss: 3.4470606237734964
Validation loss: 2.924105155658676

Epoch: 5| Step: 6
Training loss: 3.506328039269818
Validation loss: 2.9252666823351516

Epoch: 5| Step: 7
Training loss: 3.0481508371471673
Validation loss: 2.9358187568067984

Epoch: 5| Step: 8
Training loss: 3.5582264481392682
Validation loss: 2.948470781294325

Epoch: 5| Step: 9
Training loss: 3.573566181249484
Validation loss: 2.949938222531312

Epoch: 5| Step: 10
Training loss: 3.002649250116649
Validation loss: 2.929817742190662

Epoch: 64| Step: 0
Training loss: 2.7495553784298896
Validation loss: 2.9229410431351432

Epoch: 5| Step: 1
Training loss: 2.771537108185117
Validation loss: 2.917333096663232

Epoch: 5| Step: 2
Training loss: 3.6267293553918165
Validation loss: 2.91464403193595

Epoch: 5| Step: 3
Training loss: 3.46556109686808
Validation loss: 2.914862380260382

Epoch: 5| Step: 4
Training loss: 3.191301808696867
Validation loss: 2.9144017321946367

Epoch: 5| Step: 5
Training loss: 3.1554203264903733
Validation loss: 2.9203043351753077

Epoch: 5| Step: 6
Training loss: 3.3959771030314627
Validation loss: 2.9161399336385245

Epoch: 5| Step: 7
Training loss: 3.5030150369881707
Validation loss: 2.9196413232498473

Epoch: 5| Step: 8
Training loss: 3.233589998525548
Validation loss: 2.919084812825459

Epoch: 5| Step: 9
Training loss: 3.1494602406982786
Validation loss: 2.911513279365869

Epoch: 5| Step: 10
Training loss: 2.780452399595655
Validation loss: 2.907086156270845

Epoch: 65| Step: 0
Training loss: 3.0552618945256764
Validation loss: 2.909339588354627

Epoch: 5| Step: 1
Training loss: 3.001033128229503
Validation loss: 2.9096870488437956

Epoch: 5| Step: 2
Training loss: 3.2121659873363013
Validation loss: 2.910951208790938

Epoch: 5| Step: 3
Training loss: 3.092019878545623
Validation loss: 2.915316653104852

Epoch: 5| Step: 4
Training loss: 3.10561615216213
Validation loss: 2.915930130833766

Epoch: 5| Step: 5
Training loss: 3.360344325542556
Validation loss: 2.913311219774782

Epoch: 5| Step: 6
Training loss: 2.823554376358575
Validation loss: 2.90787745194042

Epoch: 5| Step: 7
Training loss: 3.0759725257827184
Validation loss: 2.9046764058902954

Epoch: 5| Step: 8
Training loss: 3.4132478558248547
Validation loss: 2.906881571850361

Epoch: 5| Step: 9
Training loss: 3.8747940008720896
Validation loss: 2.903153182588927

Epoch: 5| Step: 10
Training loss: 3.071579222929061
Validation loss: 2.9046819467899727

Epoch: 66| Step: 0
Training loss: 2.9982876659207176
Validation loss: 2.9019640774672073

Epoch: 5| Step: 1
Training loss: 3.103041750126373
Validation loss: 2.9339946951670384

Epoch: 5| Step: 2
Training loss: 2.609847705534088
Validation loss: 2.9783959235405195

Epoch: 5| Step: 3
Training loss: 3.1875875124418305
Validation loss: 3.0561047183265986

Epoch: 5| Step: 4
Training loss: 3.6483546376263436
Validation loss: 3.0005450966957485

Epoch: 5| Step: 5
Training loss: 2.8862155584144764
Validation loss: 2.943080407629592

Epoch: 5| Step: 6
Training loss: 3.559817726526704
Validation loss: 2.920342114842108

Epoch: 5| Step: 7
Training loss: 3.534343208689428
Validation loss: 2.907922436212899

Epoch: 5| Step: 8
Training loss: 3.3765070340933305
Validation loss: 2.9371107275948996

Epoch: 5| Step: 9
Training loss: 3.1807724509951614
Validation loss: 2.915899972890371

Epoch: 5| Step: 10
Training loss: 3.3011381960753177
Validation loss: 2.9051403335795523

Epoch: 67| Step: 0
Training loss: 2.8608057997019647
Validation loss: 2.900968283868071

Epoch: 5| Step: 1
Training loss: 2.782099390521085
Validation loss: 2.9002557032522844

Epoch: 5| Step: 2
Training loss: 3.5164568785756263
Validation loss: 2.8990966960059565

Epoch: 5| Step: 3
Training loss: 3.4335868062891963
Validation loss: 2.898531762165187

Epoch: 5| Step: 4
Training loss: 3.4384251129972903
Validation loss: 2.898090612997911

Epoch: 5| Step: 5
Training loss: 3.420990015144128
Validation loss: 2.897338232407759

Epoch: 5| Step: 6
Training loss: 2.7139520511762885
Validation loss: 2.904193600078201

Epoch: 5| Step: 7
Training loss: 3.361608995564847
Validation loss: 2.9301591399735667

Epoch: 5| Step: 8
Training loss: 3.373871649986629
Validation loss: 2.96650648678981

Epoch: 5| Step: 9
Training loss: 3.175965626374459
Validation loss: 2.909820369440568

Epoch: 5| Step: 10
Training loss: 2.9356644759793897
Validation loss: 2.8956128934568355

Epoch: 68| Step: 0
Training loss: 3.670644480898602
Validation loss: 2.89400992652345

Epoch: 5| Step: 1
Training loss: 3.1911949732123333
Validation loss: 2.896857588598721

Epoch: 5| Step: 2
Training loss: 2.5849410151055103
Validation loss: 2.897237585224288

Epoch: 5| Step: 3
Training loss: 3.8442650426657266
Validation loss: 2.9037704157782014

Epoch: 5| Step: 4
Training loss: 2.0807517523528447
Validation loss: 2.8957708893089396

Epoch: 5| Step: 5
Training loss: 3.301569484517355
Validation loss: 2.89670727292652

Epoch: 5| Step: 6
Training loss: 3.726123328092126
Validation loss: 2.899941896925131

Epoch: 5| Step: 7
Training loss: 3.159292586371397
Validation loss: 2.9000659875713697

Epoch: 5| Step: 8
Training loss: 2.8412399113245637
Validation loss: 2.8973559996623885

Epoch: 5| Step: 9
Training loss: 3.116601568619963
Validation loss: 2.892749916849033

Epoch: 5| Step: 10
Training loss: 3.218330133700908
Validation loss: 2.8893388036807703

Epoch: 69| Step: 0
Training loss: 2.400792062712085
Validation loss: 2.8900160618420263

Epoch: 5| Step: 1
Training loss: 3.6619539029497767
Validation loss: 2.8877066938282296

Epoch: 5| Step: 2
Training loss: 3.390783209559549
Validation loss: 2.888674219723147

Epoch: 5| Step: 3
Training loss: 3.370861483072469
Validation loss: 2.887113700645675

Epoch: 5| Step: 4
Training loss: 3.0785819551959954
Validation loss: 2.882969385091115

Epoch: 5| Step: 5
Training loss: 3.2150045287484508
Validation loss: 2.8829832633665147

Epoch: 5| Step: 6
Training loss: 3.1968606868360085
Validation loss: 2.884535451501482

Epoch: 5| Step: 7
Training loss: 2.9811511777097706
Validation loss: 2.8828338089577876

Epoch: 5| Step: 8
Training loss: 3.420618671430201
Validation loss: 2.8820347228482532

Epoch: 5| Step: 9
Training loss: 3.4476642497039243
Validation loss: 2.885232277076933

Epoch: 5| Step: 10
Training loss: 2.497952194745994
Validation loss: 2.8819628572639737

Epoch: 70| Step: 0
Training loss: 2.542636925865288
Validation loss: 2.8814573804893375

Epoch: 5| Step: 1
Training loss: 3.4596540081810554
Validation loss: 2.8805305623957445

Epoch: 5| Step: 2
Training loss: 2.8089134235993916
Validation loss: 2.8795022029712976

Epoch: 5| Step: 3
Training loss: 2.7571699134069494
Validation loss: 2.877504904501308

Epoch: 5| Step: 4
Training loss: 2.810557478725002
Validation loss: 2.8746234946877784

Epoch: 5| Step: 5
Training loss: 3.0495806296278776
Validation loss: 2.875428758548927

Epoch: 5| Step: 6
Training loss: 2.9907385602255703
Validation loss: 2.8706600743151536

Epoch: 5| Step: 7
Training loss: 3.726334474892775
Validation loss: 2.8717776194698468

Epoch: 5| Step: 8
Training loss: 3.6563658084624096
Validation loss: 2.8701316182954266

Epoch: 5| Step: 9
Training loss: 3.2807100850905053
Validation loss: 2.8680162394753745

Epoch: 5| Step: 10
Training loss: 3.611212060609553
Validation loss: 2.8685270456542624

Epoch: 71| Step: 0
Training loss: 3.227199685494933
Validation loss: 2.8688735513151196

Epoch: 5| Step: 1
Training loss: 2.32560357903834
Validation loss: 2.8690020274352275

Epoch: 5| Step: 2
Training loss: 3.1231061155654047
Validation loss: 2.870896537748561

Epoch: 5| Step: 3
Training loss: 2.9535312272270082
Validation loss: 2.8728959890157157

Epoch: 5| Step: 4
Training loss: 3.8881948457253523
Validation loss: 2.8844186767197897

Epoch: 5| Step: 5
Training loss: 3.2595410781053147
Validation loss: 2.880333669620818

Epoch: 5| Step: 6
Training loss: 3.15932835696359
Validation loss: 2.8820707892849238

Epoch: 5| Step: 7
Training loss: 3.5440766306787914
Validation loss: 2.8786666943427193

Epoch: 5| Step: 8
Training loss: 3.1004858190036564
Validation loss: 2.8698457480127195

Epoch: 5| Step: 9
Training loss: 3.165412972552586
Validation loss: 2.8738539838412027

Epoch: 5| Step: 10
Training loss: 2.756561600767464
Validation loss: 2.86936512794751

Epoch: 72| Step: 0
Training loss: 3.086979093895432
Validation loss: 2.86487478494468

Epoch: 5| Step: 1
Training loss: 3.1529859529201083
Validation loss: 2.8667445902906636

Epoch: 5| Step: 2
Training loss: 3.0938860930747576
Validation loss: 2.8731491351633744

Epoch: 5| Step: 3
Training loss: 2.379593472742775
Validation loss: 2.874809207087284

Epoch: 5| Step: 4
Training loss: 3.9273247412727517
Validation loss: 2.887882508344078

Epoch: 5| Step: 5
Training loss: 2.8193763595236137
Validation loss: 2.861232138108716

Epoch: 5| Step: 6
Training loss: 2.970974379976962
Validation loss: 2.8592693977976853

Epoch: 5| Step: 7
Training loss: 2.669429083374299
Validation loss: 2.858095724441972

Epoch: 5| Step: 8
Training loss: 3.363668988746802
Validation loss: 2.8593766532815614

Epoch: 5| Step: 9
Training loss: 3.7334476101506042
Validation loss: 2.858508880767607

Epoch: 5| Step: 10
Training loss: 3.3012992497576157
Validation loss: 2.856442550014173

Epoch: 73| Step: 0
Training loss: 3.3701984016583544
Validation loss: 2.858414519411576

Epoch: 5| Step: 1
Training loss: 2.7659300727472993
Validation loss: 2.8580653536014395

Epoch: 5| Step: 2
Training loss: 3.102979514100794
Validation loss: 2.8603883899015563

Epoch: 5| Step: 3
Training loss: 3.656561552940398
Validation loss: 2.8652622021826293

Epoch: 5| Step: 4
Training loss: 3.3595568230682327
Validation loss: 2.878432811710028

Epoch: 5| Step: 5
Training loss: 3.222651959040704
Validation loss: 2.8600355371937427

Epoch: 5| Step: 6
Training loss: 3.0286301765244934
Validation loss: 2.8547736324099913

Epoch: 5| Step: 7
Training loss: 3.533297325046764
Validation loss: 2.855440395530865

Epoch: 5| Step: 8
Training loss: 3.1344692957681497
Validation loss: 2.857732225497644

Epoch: 5| Step: 9
Training loss: 2.820734726850697
Validation loss: 2.8588731561717737

Epoch: 5| Step: 10
Training loss: 2.5612705351647214
Validation loss: 2.857365863091174

Epoch: 74| Step: 0
Training loss: 3.4234112639751615
Validation loss: 2.8570879176951136

Epoch: 5| Step: 1
Training loss: 2.6940841750748836
Validation loss: 2.8540285575715285

Epoch: 5| Step: 2
Training loss: 3.4962849655285058
Validation loss: 2.8523231614469804

Epoch: 5| Step: 3
Training loss: 3.4308696265003964
Validation loss: 2.8492373091647734

Epoch: 5| Step: 4
Training loss: 3.1788316929348173
Validation loss: 2.846116553524611

Epoch: 5| Step: 5
Training loss: 3.28519979441266
Validation loss: 2.8456471391829625

Epoch: 5| Step: 6
Training loss: 2.9296910807269785
Validation loss: 2.8454137859656923

Epoch: 5| Step: 7
Training loss: 3.154572900558255
Validation loss: 2.849919574166218

Epoch: 5| Step: 8
Training loss: 2.7274776114463637
Validation loss: 2.851296203828461

Epoch: 5| Step: 9
Training loss: 2.971025097094179
Validation loss: 2.8490623861102637

Epoch: 5| Step: 10
Training loss: 3.3419309998288695
Validation loss: 2.8465951459283887

Epoch: 75| Step: 0
Training loss: 2.85844998432126
Validation loss: 2.846344907110001

Epoch: 5| Step: 1
Training loss: 3.3551529723539444
Validation loss: 2.846192593857926

Epoch: 5| Step: 2
Training loss: 3.8811728010623985
Validation loss: 2.8453713164904055

Epoch: 5| Step: 3
Training loss: 2.5363140548205334
Validation loss: 2.843965131232484

Epoch: 5| Step: 4
Training loss: 3.0396709078295423
Validation loss: 2.8424927705491068

Epoch: 5| Step: 5
Training loss: 3.188984244852272
Validation loss: 2.840870712751917

Epoch: 5| Step: 6
Training loss: 2.98369506759801
Validation loss: 2.8408448512625464

Epoch: 5| Step: 7
Training loss: 2.9376308330862515
Validation loss: 2.839817081128775

Epoch: 5| Step: 8
Training loss: 3.1845117661265805
Validation loss: 2.8394371195558024

Epoch: 5| Step: 9
Training loss: 3.4222170863450168
Validation loss: 2.838140041135149

Epoch: 5| Step: 10
Training loss: 2.9926614012569552
Validation loss: 2.838965155056928

Epoch: 76| Step: 0
Training loss: 3.4069920002916456
Validation loss: 2.841681181220097

Epoch: 5| Step: 1
Training loss: 3.251596792132813
Validation loss: 2.843734010950985

Epoch: 5| Step: 2
Training loss: 3.2469701582298316
Validation loss: 2.845748060602794

Epoch: 5| Step: 3
Training loss: 2.6342372944273738
Validation loss: 2.855941709724822

Epoch: 5| Step: 4
Training loss: 2.720681129470717
Validation loss: 2.870392207789888

Epoch: 5| Step: 5
Training loss: 2.649027710812514
Validation loss: 2.8667483390635935

Epoch: 5| Step: 6
Training loss: 3.2307620301707867
Validation loss: 2.8725836123891133

Epoch: 5| Step: 7
Training loss: 3.3055749157108005
Validation loss: 2.851344291641767

Epoch: 5| Step: 8
Training loss: 3.0256166318302156
Validation loss: 2.838605545437564

Epoch: 5| Step: 9
Training loss: 3.8247623544308076
Validation loss: 2.831880496167156

Epoch: 5| Step: 10
Training loss: 3.0890800602924626
Validation loss: 2.8327451007244724

Epoch: 77| Step: 0
Training loss: 3.2282097331740798
Validation loss: 2.833661721494044

Epoch: 5| Step: 1
Training loss: 2.8933809906100736
Validation loss: 2.834789848790774

Epoch: 5| Step: 2
Training loss: 2.4794521861926926
Validation loss: 2.8345328174076365

Epoch: 5| Step: 3
Training loss: 3.487965876044892
Validation loss: 2.837615428826612

Epoch: 5| Step: 4
Training loss: 3.2092359354855504
Validation loss: 2.836396234511547

Epoch: 5| Step: 5
Training loss: 3.2043006786271313
Validation loss: 2.8357894905392524

Epoch: 5| Step: 6
Training loss: 3.6915633233777547
Validation loss: 2.8346453083596477

Epoch: 5| Step: 7
Training loss: 3.1151930468457665
Validation loss: 2.8344458965945365

Epoch: 5| Step: 8
Training loss: 3.468825055934179
Validation loss: 2.832225411633062

Epoch: 5| Step: 9
Training loss: 2.6373367150551483
Validation loss: 2.8310973391409324

Epoch: 5| Step: 10
Training loss: 2.9343413557209956
Validation loss: 2.8307110621267166

Epoch: 78| Step: 0
Training loss: 2.887711990303124
Validation loss: 2.8295585893553756

Epoch: 5| Step: 1
Training loss: 3.7792345460784067
Validation loss: 2.83060348486372

Epoch: 5| Step: 2
Training loss: 2.49860906053673
Validation loss: 2.827572246590429

Epoch: 5| Step: 3
Training loss: 2.6507139971471143
Validation loss: 2.826647618086015

Epoch: 5| Step: 4
Training loss: 2.2320979326359507
Validation loss: 2.8226637649602986

Epoch: 5| Step: 5
Training loss: 3.6213335371405986
Validation loss: 2.8216492209224606

Epoch: 5| Step: 6
Training loss: 3.34946559230399
Validation loss: 2.819341831618898

Epoch: 5| Step: 7
Training loss: 2.738254780988334
Validation loss: 2.8188070224671025

Epoch: 5| Step: 8
Training loss: 3.3133408540861664
Validation loss: 2.8241655962017274

Epoch: 5| Step: 9
Training loss: 3.905931017249438
Validation loss: 2.829139791647313

Epoch: 5| Step: 10
Training loss: 3.0287868284347135
Validation loss: 2.8504688196850214

Epoch: 79| Step: 0
Training loss: 3.7853741814358917
Validation loss: 2.8677226776402827

Epoch: 5| Step: 1
Training loss: 3.1022273583386353
Validation loss: 2.860257303164658

Epoch: 5| Step: 2
Training loss: 3.031826947550367
Validation loss: 2.85464454017447

Epoch: 5| Step: 3
Training loss: 3.496970500443096
Validation loss: 2.8889401577298783

Epoch: 5| Step: 4
Training loss: 2.6259967183240036
Validation loss: 2.856303494262301

Epoch: 5| Step: 5
Training loss: 3.2310434773482464
Validation loss: 2.831498533392469

Epoch: 5| Step: 6
Training loss: 3.3309781019028697
Validation loss: 2.8197215516740584

Epoch: 5| Step: 7
Training loss: 3.2938520846390413
Validation loss: 2.8176858161195026

Epoch: 5| Step: 8
Training loss: 2.6240382476263764
Validation loss: 2.8173600139382553

Epoch: 5| Step: 9
Training loss: 2.991992754861148
Validation loss: 2.8158899511897926

Epoch: 5| Step: 10
Training loss: 2.7268897791970623
Validation loss: 2.8144716577871245

Epoch: 80| Step: 0
Training loss: 2.3146664549297173
Validation loss: 2.815065434851095

Epoch: 5| Step: 1
Training loss: 3.258910362357015
Validation loss: 2.8114817025810503

Epoch: 5| Step: 2
Training loss: 2.9499030727691564
Validation loss: 2.8126090954913665

Epoch: 5| Step: 3
Training loss: 2.629039199890901
Validation loss: 2.8138331417785505

Epoch: 5| Step: 4
Training loss: 3.663528110600912
Validation loss: 2.815911687367343

Epoch: 5| Step: 5
Training loss: 3.6255762365698745
Validation loss: 2.8183575757678505

Epoch: 5| Step: 6
Training loss: 2.806157653920393
Validation loss: 2.814651528605855

Epoch: 5| Step: 7
Training loss: 2.9529638498730773
Validation loss: 2.812086355219922

Epoch: 5| Step: 8
Training loss: 3.5040811178232794
Validation loss: 2.8125459783480644

Epoch: 5| Step: 9
Training loss: 2.9385176174329577
Validation loss: 2.8106708334660953

Epoch: 5| Step: 10
Training loss: 3.389653220430218
Validation loss: 2.8098510244723043

Epoch: 81| Step: 0
Training loss: 3.2221813984912013
Validation loss: 2.8078825415525612

Epoch: 5| Step: 1
Training loss: 3.036681352978341
Validation loss: 2.809558889300439

Epoch: 5| Step: 2
Training loss: 2.688437630966983
Validation loss: 2.811840488673982

Epoch: 5| Step: 3
Training loss: 2.9571676688933692
Validation loss: 2.816217045856431

Epoch: 5| Step: 4
Training loss: 3.040234337357863
Validation loss: 2.8348016618308276

Epoch: 5| Step: 5
Training loss: 3.45328435055472
Validation loss: 2.8386820434528532

Epoch: 5| Step: 6
Training loss: 3.4664280998843005
Validation loss: 2.811945258228473

Epoch: 5| Step: 7
Training loss: 3.2190204988166444
Validation loss: 2.802685482420056

Epoch: 5| Step: 8
Training loss: 3.1405077860200783
Validation loss: 2.8048067853902596

Epoch: 5| Step: 9
Training loss: 2.755035385347677
Validation loss: 2.80924290750721

Epoch: 5| Step: 10
Training loss: 3.3304475372447837
Validation loss: 2.8174065781322093

Epoch: 82| Step: 0
Training loss: 2.916195331818133
Validation loss: 2.824914085206303

Epoch: 5| Step: 1
Training loss: 3.3756052110357166
Validation loss: 2.818911908698864

Epoch: 5| Step: 2
Training loss: 3.351783727355967
Validation loss: 2.8123898082371643

Epoch: 5| Step: 3
Training loss: 2.687506121251432
Validation loss: 2.808094021789057

Epoch: 5| Step: 4
Training loss: 2.9785943893274243
Validation loss: 2.8049994480390685

Epoch: 5| Step: 5
Training loss: 3.5102881041094816
Validation loss: 2.8044084523304824

Epoch: 5| Step: 6
Training loss: 2.674563744881275
Validation loss: 2.8019287076470905

Epoch: 5| Step: 7
Training loss: 3.471496457014181
Validation loss: 2.799053885839509

Epoch: 5| Step: 8
Training loss: 3.033008497961398
Validation loss: 2.8003279837406727

Epoch: 5| Step: 9
Training loss: 2.907951759148132
Validation loss: 2.801211123970351

Epoch: 5| Step: 10
Training loss: 3.336548653216854
Validation loss: 2.8058229971645408

Epoch: 83| Step: 0
Training loss: 3.5952410714465874
Validation loss: 2.8157462223537197

Epoch: 5| Step: 1
Training loss: 3.025008865217349
Validation loss: 2.807476627464158

Epoch: 5| Step: 2
Training loss: 3.5025105327962445
Validation loss: 2.7944527340628498

Epoch: 5| Step: 3
Training loss: 3.0616774719523843
Validation loss: 2.794263854029212

Epoch: 5| Step: 4
Training loss: 2.3707319357518783
Validation loss: 2.795094932605081

Epoch: 5| Step: 5
Training loss: 2.815250916351042
Validation loss: 2.7945766138120187

Epoch: 5| Step: 6
Training loss: 3.205463132916112
Validation loss: 2.796854708037624

Epoch: 5| Step: 7
Training loss: 2.947080531795606
Validation loss: 2.799115658640396

Epoch: 5| Step: 8
Training loss: 3.0595891704154714
Validation loss: 2.802347672965776

Epoch: 5| Step: 9
Training loss: 2.9632523880992947
Validation loss: 2.817438978706397

Epoch: 5| Step: 10
Training loss: 3.5372125030262094
Validation loss: 2.848231690624946

Epoch: 84| Step: 0
Training loss: 3.874551685610263
Validation loss: 2.8047260034186063

Epoch: 5| Step: 1
Training loss: 3.4146789413265295
Validation loss: 2.788675868495826

Epoch: 5| Step: 2
Training loss: 2.576374546318427
Validation loss: 2.7883713333659865

Epoch: 5| Step: 3
Training loss: 2.4114376476436004
Validation loss: 2.7892667592699953

Epoch: 5| Step: 4
Training loss: 2.652943965994484
Validation loss: 2.790672250639862

Epoch: 5| Step: 5
Training loss: 2.792406828580189
Validation loss: 2.789089273643838

Epoch: 5| Step: 6
Training loss: 3.332140009581985
Validation loss: 2.792798777131831

Epoch: 5| Step: 7
Training loss: 2.890774449789479
Validation loss: 2.7963756216977087

Epoch: 5| Step: 8
Training loss: 3.177311790048569
Validation loss: 2.797616861719486

Epoch: 5| Step: 9
Training loss: 3.350159251285253
Validation loss: 2.7965484179153304

Epoch: 5| Step: 10
Training loss: 3.479231523529834
Validation loss: 2.793608922067323

Epoch: 85| Step: 0
Training loss: 3.15504145381917
Validation loss: 2.7902500382747424

Epoch: 5| Step: 1
Training loss: 3.021569120751179
Validation loss: 2.7874845390566105

Epoch: 5| Step: 2
Training loss: 3.348616436739997
Validation loss: 2.783439234570307

Epoch: 5| Step: 3
Training loss: 2.7453033916081293
Validation loss: 2.7824960055802284

Epoch: 5| Step: 4
Training loss: 2.9929545641916167
Validation loss: 2.7808356331874413

Epoch: 5| Step: 5
Training loss: 3.508925909043428
Validation loss: 2.7818497723940716

Epoch: 5| Step: 6
Training loss: 2.882525670118412
Validation loss: 2.7869492443494748

Epoch: 5| Step: 7
Training loss: 2.761870686237862
Validation loss: 2.8031831952295563

Epoch: 5| Step: 8
Training loss: 2.811773163867015
Validation loss: 2.815660583548765

Epoch: 5| Step: 9
Training loss: 3.3900347077159907
Validation loss: 2.8064585361977588

Epoch: 5| Step: 10
Training loss: 3.428557815978865
Validation loss: 2.810888800121388

Epoch: 86| Step: 0
Training loss: 3.1294789070019498
Validation loss: 2.8048783282319834

Epoch: 5| Step: 1
Training loss: 2.857591750439978
Validation loss: 2.789290092596711

Epoch: 5| Step: 2
Training loss: 3.0652568631096515
Validation loss: 2.782177591490187

Epoch: 5| Step: 3
Training loss: 2.943687901580951
Validation loss: 2.7787914925106514

Epoch: 5| Step: 4
Training loss: 2.8683698747233097
Validation loss: 2.779370511555304

Epoch: 5| Step: 5
Training loss: 3.1341300343775935
Validation loss: 2.7771730959136067

Epoch: 5| Step: 6
Training loss: 3.158830852794651
Validation loss: 2.777137033402607

Epoch: 5| Step: 7
Training loss: 3.0801459324931506
Validation loss: 2.7750436636207416

Epoch: 5| Step: 8
Training loss: 3.4766775733676707
Validation loss: 2.7775691268519545

Epoch: 5| Step: 9
Training loss: 3.2251316250695004
Validation loss: 2.776426195441954

Epoch: 5| Step: 10
Training loss: 3.038710389908889
Validation loss: 2.77540658471938

Epoch: 87| Step: 0
Training loss: 3.5578028179936605
Validation loss: 2.7751629520764345

Epoch: 5| Step: 1
Training loss: 2.52113714567935
Validation loss: 2.7794694186352267

Epoch: 5| Step: 2
Training loss: 3.2145420456659908
Validation loss: 2.778635883141453

Epoch: 5| Step: 3
Training loss: 3.0365579282328325
Validation loss: 2.7797749373047655

Epoch: 5| Step: 4
Training loss: 3.1854423912777663
Validation loss: 2.7875756372157263

Epoch: 5| Step: 5
Training loss: 2.6675285099011132
Validation loss: 2.819527696455704

Epoch: 5| Step: 6
Training loss: 3.1194958851770775
Validation loss: 2.8113855868127358

Epoch: 5| Step: 7
Training loss: 3.009333713838516
Validation loss: 2.774394053491521

Epoch: 5| Step: 8
Training loss: 2.881941997317663
Validation loss: 2.770511301000941

Epoch: 5| Step: 9
Training loss: 3.01983822622962
Validation loss: 2.7752395619600043

Epoch: 5| Step: 10
Training loss: 3.5977010485979806
Validation loss: 2.781083815816427

Epoch: 88| Step: 0
Training loss: 2.775152315650627
Validation loss: 2.7813997088968203

Epoch: 5| Step: 1
Training loss: 3.599741974166845
Validation loss: 2.7798176167494106

Epoch: 5| Step: 2
Training loss: 3.1584686941431483
Validation loss: 2.77742475980494

Epoch: 5| Step: 3
Training loss: 2.7945030852986896
Validation loss: 2.7734871559024983

Epoch: 5| Step: 4
Training loss: 3.1229148011374845
Validation loss: 2.775140807128705

Epoch: 5| Step: 5
Training loss: 3.435404329449347
Validation loss: 2.772071615040254

Epoch: 5| Step: 6
Training loss: 3.2029925063108404
Validation loss: 2.7730330957365923

Epoch: 5| Step: 7
Training loss: 2.7535562062827856
Validation loss: 2.7742102510517515

Epoch: 5| Step: 8
Training loss: 3.2928712950344146
Validation loss: 2.772884248894252

Epoch: 5| Step: 9
Training loss: 2.5355063550805887
Validation loss: 2.7717542361632788

Epoch: 5| Step: 10
Training loss: 3.2860839114582165
Validation loss: 2.7714762201320537

Epoch: 89| Step: 0
Training loss: 3.742714480444495
Validation loss: 2.771360618412865

Epoch: 5| Step: 1
Training loss: 3.0281389139680495
Validation loss: 2.770241738899276

Epoch: 5| Step: 2
Training loss: 3.386503324950008
Validation loss: 2.7700721428563053

Epoch: 5| Step: 3
Training loss: 3.0551779272831885
Validation loss: 2.769731107307977

Epoch: 5| Step: 4
Training loss: 3.045417789304708
Validation loss: 2.7689492383427434

Epoch: 5| Step: 5
Training loss: 2.9242909281141944
Validation loss: 2.767826079259539

Epoch: 5| Step: 6
Training loss: 2.445281884729974
Validation loss: 2.7662556543724253

Epoch: 5| Step: 7
Training loss: 3.081413100686521
Validation loss: 2.765760018587103

Epoch: 5| Step: 8
Training loss: 3.3991173776649073
Validation loss: 2.766094225662074

Epoch: 5| Step: 9
Training loss: 2.8688037277210228
Validation loss: 2.7648692719822057

Epoch: 5| Step: 10
Training loss: 2.7864589132623276
Validation loss: 2.7645831765923017

Epoch: 90| Step: 0
Training loss: 3.4529928466917217
Validation loss: 2.763457721637058

Epoch: 5| Step: 1
Training loss: 2.8718023347015316
Validation loss: 2.7697526864731126

Epoch: 5| Step: 2
Training loss: 2.9426723961900394
Validation loss: 2.7658249857066552

Epoch: 5| Step: 3
Training loss: 2.9134064209395465
Validation loss: 2.7601287530671534

Epoch: 5| Step: 4
Training loss: 2.7709505347989327
Validation loss: 2.7625364309817204

Epoch: 5| Step: 5
Training loss: 2.933751413144266
Validation loss: 2.7601043632857696

Epoch: 5| Step: 6
Training loss: 3.482187722165113
Validation loss: 2.7572375840553507

Epoch: 5| Step: 7
Training loss: 2.8521222962940382
Validation loss: 2.763430420422225

Epoch: 5| Step: 8
Training loss: 3.4474942658330354
Validation loss: 2.764302290534603

Epoch: 5| Step: 9
Training loss: 2.937665244791193
Validation loss: 2.7623004447218453

Epoch: 5| Step: 10
Training loss: 3.1658240418591923
Validation loss: 2.760053649237954

Epoch: 91| Step: 0
Training loss: 2.8260704713040785
Validation loss: 2.760383649099606

Epoch: 5| Step: 1
Training loss: 3.1397524708172346
Validation loss: 2.7786914264934777

Epoch: 5| Step: 2
Training loss: 2.803169711127445
Validation loss: 2.773105425945763

Epoch: 5| Step: 3
Training loss: 3.044033192457373
Validation loss: 2.7609662713646403

Epoch: 5| Step: 4
Training loss: 3.1299041414054853
Validation loss: 2.7645539502374272

Epoch: 5| Step: 5
Training loss: 2.789031469348781
Validation loss: 2.755297818349264

Epoch: 5| Step: 6
Training loss: 3.184900308243526
Validation loss: 2.751148881630201

Epoch: 5| Step: 7
Training loss: 2.9249770073924366
Validation loss: 2.7481890296750815

Epoch: 5| Step: 8
Training loss: 3.574446207115311
Validation loss: 2.746598853275098

Epoch: 5| Step: 9
Training loss: 3.1530344985056997
Validation loss: 2.743132945344484

Epoch: 5| Step: 10
Training loss: 3.086410911076443
Validation loss: 2.7465566293068173

Epoch: 92| Step: 0
Training loss: 3.2362641792679248
Validation loss: 2.745423652921506

Epoch: 5| Step: 1
Training loss: 3.137973102296268
Validation loss: 2.7495694909534567

Epoch: 5| Step: 2
Training loss: 2.676641662816577
Validation loss: 2.7494558260192923

Epoch: 5| Step: 3
Training loss: 3.1453483325567735
Validation loss: 2.7479348235667977

Epoch: 5| Step: 4
Training loss: 3.046871400488659
Validation loss: 2.750209938306616

Epoch: 5| Step: 5
Training loss: 3.1161283065470475
Validation loss: 2.757965842174626

Epoch: 5| Step: 6
Training loss: 3.1235734353724665
Validation loss: 2.7715596269446667

Epoch: 5| Step: 7
Training loss: 3.121193665777885
Validation loss: 2.767407065099829

Epoch: 5| Step: 8
Training loss: 3.049670536194606
Validation loss: 2.760802364200989

Epoch: 5| Step: 9
Training loss: 2.7764423264926803
Validation loss: 2.7449329694225035

Epoch: 5| Step: 10
Training loss: 3.2338260792975584
Validation loss: 2.7423236968409648

Epoch: 93| Step: 0
Training loss: 3.6075334350982198
Validation loss: 2.7576992640649975

Epoch: 5| Step: 1
Training loss: 3.2969146292234646
Validation loss: 2.7400302853791936

Epoch: 5| Step: 2
Training loss: 2.8090476145526573
Validation loss: 2.735106049068551

Epoch: 5| Step: 3
Training loss: 3.4264515272157836
Validation loss: 2.7382382283637408

Epoch: 5| Step: 4
Training loss: 3.4782296630247287
Validation loss: 2.741922074067382

Epoch: 5| Step: 5
Training loss: 2.525893678295655
Validation loss: 2.747449540511085

Epoch: 5| Step: 6
Training loss: 3.061557235409535
Validation loss: 2.7515834824809393

Epoch: 5| Step: 7
Training loss: 2.5588176600199994
Validation loss: 2.7519781636603273

Epoch: 5| Step: 8
Training loss: 3.1598387607047838
Validation loss: 2.751587073236817

Epoch: 5| Step: 9
Training loss: 3.0224584132663126
Validation loss: 2.747788640183829

Epoch: 5| Step: 10
Training loss: 2.602799221870115
Validation loss: 2.7457878364718638

Epoch: 94| Step: 0
Training loss: 3.03153943125307
Validation loss: 2.7462838113748242

Epoch: 5| Step: 1
Training loss: 3.0380088725258685
Validation loss: 2.7428469530335406

Epoch: 5| Step: 2
Training loss: 2.904601747458734
Validation loss: 2.7419310199356177

Epoch: 5| Step: 3
Training loss: 2.630311043625499
Validation loss: 2.739196775025911

Epoch: 5| Step: 4
Training loss: 3.2186385940975204
Validation loss: 2.7379929700318186

Epoch: 5| Step: 5
Training loss: 3.506238826523111
Validation loss: 2.7346298591220926

Epoch: 5| Step: 6
Training loss: 2.948407315421639
Validation loss: 2.732210599915577

Epoch: 5| Step: 7
Training loss: 3.0995489161459515
Validation loss: 2.735161945881314

Epoch: 5| Step: 8
Training loss: 2.735774788192812
Validation loss: 2.7424411647591365

Epoch: 5| Step: 9
Training loss: 3.5476894703888764
Validation loss: 2.7475370786714217

Epoch: 5| Step: 10
Training loss: 2.886019280002457
Validation loss: 2.7555321733143385

Epoch: 95| Step: 0
Training loss: 3.5474940360558818
Validation loss: 2.7815228289573284

Epoch: 5| Step: 1
Training loss: 2.8576134430401448
Validation loss: 2.79202565612556

Epoch: 5| Step: 2
Training loss: 2.843504507346662
Validation loss: 2.8054521514470725

Epoch: 5| Step: 3
Training loss: 2.7576312905232014
Validation loss: 2.782552388599695

Epoch: 5| Step: 4
Training loss: 2.1798836131043573
Validation loss: 2.774781131141231

Epoch: 5| Step: 5
Training loss: 3.0423600612734254
Validation loss: 2.7501016227015893

Epoch: 5| Step: 6
Training loss: 3.7801330429964906
Validation loss: 2.727521624298139

Epoch: 5| Step: 7
Training loss: 2.9468590194899913
Validation loss: 2.7245393056361293

Epoch: 5| Step: 8
Training loss: 3.1261335224476414
Validation loss: 2.721560345706519

Epoch: 5| Step: 9
Training loss: 2.945869696652131
Validation loss: 2.7246762039951546

Epoch: 5| Step: 10
Training loss: 3.529099070964932
Validation loss: 2.72391212772571

Epoch: 96| Step: 0
Training loss: 2.4890741974195967
Validation loss: 2.722671780630443

Epoch: 5| Step: 1
Training loss: 3.548671855435641
Validation loss: 2.722235878056366

Epoch: 5| Step: 2
Training loss: 2.763332472809894
Validation loss: 2.7251937293085575

Epoch: 5| Step: 3
Training loss: 2.7007388128423067
Validation loss: 2.722684974158141

Epoch: 5| Step: 4
Training loss: 3.2292281770487823
Validation loss: 2.7290383864326957

Epoch: 5| Step: 5
Training loss: 3.4677125221258462
Validation loss: 2.7378868977757564

Epoch: 5| Step: 6
Training loss: 3.5387075890438924
Validation loss: 2.740753740438862

Epoch: 5| Step: 7
Training loss: 2.875955671613429
Validation loss: 2.7420788282315796

Epoch: 5| Step: 8
Training loss: 2.6294575944880605
Validation loss: 2.7209447786039944

Epoch: 5| Step: 9
Training loss: 2.9294596265545767
Validation loss: 2.7210868030941193

Epoch: 5| Step: 10
Training loss: 3.2068436041517923
Validation loss: 2.735296964833623

Epoch: 97| Step: 0
Training loss: 2.812864830938185
Validation loss: 2.7419257634935836

Epoch: 5| Step: 1
Training loss: 2.892312871605252
Validation loss: 2.7399710634238192

Epoch: 5| Step: 2
Training loss: 3.253377773054353
Validation loss: 2.7305517757789097

Epoch: 5| Step: 3
Training loss: 3.429916895535272
Validation loss: 2.7283327497054617

Epoch: 5| Step: 4
Training loss: 2.910300764553577
Validation loss: 2.734913511440547

Epoch: 5| Step: 5
Training loss: 3.130711333641261
Validation loss: 2.757301839880564

Epoch: 5| Step: 6
Training loss: 2.751723962884689
Validation loss: 2.7683798633844505

Epoch: 5| Step: 7
Training loss: 3.258389428737996
Validation loss: 2.7745485609842118

Epoch: 5| Step: 8
Training loss: 3.268949285963932
Validation loss: 2.777489701445029

Epoch: 5| Step: 9
Training loss: 3.119383686032944
Validation loss: 2.7668404823180617

Epoch: 5| Step: 10
Training loss: 2.976150604344271
Validation loss: 2.761738967804098

Epoch: 98| Step: 0
Training loss: 2.846714863633438
Validation loss: 2.7486421378092047

Epoch: 5| Step: 1
Training loss: 3.4292143406263658
Validation loss: 2.7399330160852933

Epoch: 5| Step: 2
Training loss: 2.824204145422776
Validation loss: 2.7253954514369103

Epoch: 5| Step: 3
Training loss: 3.344401643661535
Validation loss: 2.732462565739417

Epoch: 5| Step: 4
Training loss: 2.9415027050399467
Validation loss: 2.7747220115289823

Epoch: 5| Step: 5
Training loss: 2.9421852569652565
Validation loss: 2.797394581014029

Epoch: 5| Step: 6
Training loss: 2.8989954820053616
Validation loss: 2.778481566954667

Epoch: 5| Step: 7
Training loss: 2.6756704934023388
Validation loss: 2.713284035261768

Epoch: 5| Step: 8
Training loss: 3.2333643711868216
Validation loss: 2.7083671365778694

Epoch: 5| Step: 9
Training loss: 3.1154958011388914
Validation loss: 2.7112530758125435

Epoch: 5| Step: 10
Training loss: 3.3242177458962203
Validation loss: 2.713087449706719

Epoch: 99| Step: 0
Training loss: 2.76977968379529
Validation loss: 2.7131019820084936

Epoch: 5| Step: 1
Training loss: 3.332521927940988
Validation loss: 2.716512302074895

Epoch: 5| Step: 2
Training loss: 3.085813572966535
Validation loss: 2.723300100843148

Epoch: 5| Step: 3
Training loss: 2.91484979625311
Validation loss: 2.7342792875118755

Epoch: 5| Step: 4
Training loss: 2.791685692641678
Validation loss: 2.7327321638750037

Epoch: 5| Step: 5
Training loss: 3.122226399757906
Validation loss: 2.746095273567925

Epoch: 5| Step: 6
Training loss: 3.460131824826653
Validation loss: 2.746728644253703

Epoch: 5| Step: 7
Training loss: 3.2539968123089182
Validation loss: 2.7084094845373348

Epoch: 5| Step: 8
Training loss: 2.925884250106202
Validation loss: 2.706241603238554

Epoch: 5| Step: 9
Training loss: 2.9862840548170713
Validation loss: 2.709923093192114

Epoch: 5| Step: 10
Training loss: 2.938090488253057
Validation loss: 2.7083930817506245

Epoch: 100| Step: 0
Training loss: 2.828180133429705
Validation loss: 2.71881110424776

Epoch: 5| Step: 1
Training loss: 2.8335699281829685
Validation loss: 2.7322987285771694

Epoch: 5| Step: 2
Training loss: 2.46118763454734
Validation loss: 2.7405098410087083

Epoch: 5| Step: 3
Training loss: 3.3464270597403
Validation loss: 2.7566595025233642

Epoch: 5| Step: 4
Training loss: 2.744207784570746
Validation loss: 2.7381798589663604

Epoch: 5| Step: 5
Training loss: 2.784837958725761
Validation loss: 2.723017032275996

Epoch: 5| Step: 6
Training loss: 3.584200170189348
Validation loss: 2.7129821263433276

Epoch: 5| Step: 7
Training loss: 3.384256032893965
Validation loss: 2.711048694767724

Epoch: 5| Step: 8
Training loss: 3.1408521275925017
Validation loss: 2.7068796167307223

Epoch: 5| Step: 9
Training loss: 3.4220950260579563
Validation loss: 2.7059866482771864

Epoch: 5| Step: 10
Training loss: 2.6540317922325096
Validation loss: 2.7083516356147173

Epoch: 101| Step: 0
Training loss: 2.332985840762224
Validation loss: 2.7088312932858827

Epoch: 5| Step: 1
Training loss: 2.480370418972481
Validation loss: 2.704706428744861

Epoch: 5| Step: 2
Training loss: 3.0998613511120405
Validation loss: 2.705383228133833

Epoch: 5| Step: 3
Training loss: 2.705680477131369
Validation loss: 2.706649005368947

Epoch: 5| Step: 4
Training loss: 3.4188550748142292
Validation loss: 2.7066469045582675

Epoch: 5| Step: 5
Training loss: 3.1251907290428704
Validation loss: 2.7104829759020235

Epoch: 5| Step: 6
Training loss: 2.861497935180879
Validation loss: 2.719264043034406

Epoch: 5| Step: 7
Training loss: 3.4636582127898903
Validation loss: 2.7197262118491694

Epoch: 5| Step: 8
Training loss: 3.3826136012994152
Validation loss: 2.715679199209568

Epoch: 5| Step: 9
Training loss: 3.180708137935329
Validation loss: 2.7102034902774395

Epoch: 5| Step: 10
Training loss: 3.0205569085991306
Validation loss: 2.711909863362322

Epoch: 102| Step: 0
Training loss: 3.0405726272447913
Validation loss: 2.7084064224515636

Epoch: 5| Step: 1
Training loss: 3.4578893598658187
Validation loss: 2.7036665820183075

Epoch: 5| Step: 2
Training loss: 2.9805209054045756
Validation loss: 2.7034880615815693

Epoch: 5| Step: 3
Training loss: 3.2757533946764634
Validation loss: 2.70410418482257

Epoch: 5| Step: 4
Training loss: 2.8498630423849427
Validation loss: 2.704259651962172

Epoch: 5| Step: 5
Training loss: 3.206304098345841
Validation loss: 2.7071409328280955

Epoch: 5| Step: 6
Training loss: 3.0191918659834465
Validation loss: 2.713214351836701

Epoch: 5| Step: 7
Training loss: 2.7650508823507254
Validation loss: 2.7084253609469373

Epoch: 5| Step: 8
Training loss: 2.7421024667972436
Validation loss: 2.704286304876668

Epoch: 5| Step: 9
Training loss: 2.7089714374522087
Validation loss: 2.703022484676207

Epoch: 5| Step: 10
Training loss: 3.1050570616953688
Validation loss: 2.6986229715124357

Epoch: 103| Step: 0
Training loss: 2.969818083717994
Validation loss: 2.6969229304117834

Epoch: 5| Step: 1
Training loss: 3.151692943681996
Validation loss: 2.6997601394575725

Epoch: 5| Step: 2
Training loss: 3.211472960884337
Validation loss: 2.6989937749331454

Epoch: 5| Step: 3
Training loss: 2.326571464649399
Validation loss: 2.695148098595209

Epoch: 5| Step: 4
Training loss: 2.6429503545929993
Validation loss: 2.699344509144118

Epoch: 5| Step: 5
Training loss: 3.233960111241113
Validation loss: 2.7017577686997556

Epoch: 5| Step: 6
Training loss: 3.4052382900304714
Validation loss: 2.704739347177898

Epoch: 5| Step: 7
Training loss: 3.0382755309894907
Validation loss: 2.703668734451586

Epoch: 5| Step: 8
Training loss: 2.9033075018637655
Validation loss: 2.703471525572864

Epoch: 5| Step: 9
Training loss: 3.1611076214917646
Validation loss: 2.7025000315457284

Epoch: 5| Step: 10
Training loss: 3.1705119394108543
Validation loss: 2.7011730442719775

Epoch: 104| Step: 0
Training loss: 2.8906947771878024
Validation loss: 2.6989138514274895

Epoch: 5| Step: 1
Training loss: 3.067710647625312
Validation loss: 2.698870068315913

Epoch: 5| Step: 2
Training loss: 3.7725441074510413
Validation loss: 2.701379441318416

Epoch: 5| Step: 3
Training loss: 2.8649417907233996
Validation loss: 2.7061636520418557

Epoch: 5| Step: 4
Training loss: 2.855843786823994
Validation loss: 2.7219512540346336

Epoch: 5| Step: 5
Training loss: 3.346317767033105
Validation loss: 2.739512583268487

Epoch: 5| Step: 6
Training loss: 2.3327432181411325
Validation loss: 2.7775358864528528

Epoch: 5| Step: 7
Training loss: 3.0772049976454574
Validation loss: 2.767571648219404

Epoch: 5| Step: 8
Training loss: 2.8873701586574363
Validation loss: 2.7426947920367346

Epoch: 5| Step: 9
Training loss: 3.0852473392597197
Validation loss: 2.713827731287495

Epoch: 5| Step: 10
Training loss: 2.922615814133203
Validation loss: 2.701609027855484

Epoch: 105| Step: 0
Training loss: 3.513241515169245
Validation loss: 2.6901213407506805

Epoch: 5| Step: 1
Training loss: 2.74908614146405
Validation loss: 2.6919308914622873

Epoch: 5| Step: 2
Training loss: 2.4793360248922722
Validation loss: 2.691034592562745

Epoch: 5| Step: 3
Training loss: 2.79286750663309
Validation loss: 2.69463549067289

Epoch: 5| Step: 4
Training loss: 2.854377590284348
Validation loss: 2.697065472274412

Epoch: 5| Step: 5
Training loss: 3.435156144503708
Validation loss: 2.6971379392043073

Epoch: 5| Step: 6
Training loss: 3.248813118991135
Validation loss: 2.6966146967821656

Epoch: 5| Step: 7
Training loss: 3.177520388365973
Validation loss: 2.700426323099655

Epoch: 5| Step: 8
Training loss: 3.1099662793652705
Validation loss: 2.697740302381254

Epoch: 5| Step: 9
Training loss: 2.8900253086235876
Validation loss: 2.695440567110473

Epoch: 5| Step: 10
Training loss: 3.002894118183652
Validation loss: 2.69456581210558

Epoch: 106| Step: 0
Training loss: 3.083101538803381
Validation loss: 2.6933473856273165

Epoch: 5| Step: 1
Training loss: 2.95488916411919
Validation loss: 2.691358904164119

Epoch: 5| Step: 2
Training loss: 3.0171781503225312
Validation loss: 2.688784894784262

Epoch: 5| Step: 3
Training loss: 2.921359093146688
Validation loss: 2.6891504148446628

Epoch: 5| Step: 4
Training loss: 3.2606676064022406
Validation loss: 2.6867606559499837

Epoch: 5| Step: 5
Training loss: 2.190589575814408
Validation loss: 2.686577186585505

Epoch: 5| Step: 6
Training loss: 3.0439855715476116
Validation loss: 2.6852547103645135

Epoch: 5| Step: 7
Training loss: 3.0881299692780613
Validation loss: 2.6869147365290242

Epoch: 5| Step: 8
Training loss: 3.4543946292568646
Validation loss: 2.683372923015597

Epoch: 5| Step: 9
Training loss: 2.8927294519624502
Validation loss: 2.68095959996032

Epoch: 5| Step: 10
Training loss: 3.36116015886262
Validation loss: 2.6830207812610967

Epoch: 107| Step: 0
Training loss: 3.316710764785077
Validation loss: 2.682145881135766

Epoch: 5| Step: 1
Training loss: 3.1548283462862523
Validation loss: 2.6796673500377097

Epoch: 5| Step: 2
Training loss: 2.8263534139603754
Validation loss: 2.676797512484467

Epoch: 5| Step: 3
Training loss: 2.290577462029631
Validation loss: 2.675800626352417

Epoch: 5| Step: 4
Training loss: 3.1052852552412085
Validation loss: 2.6754671100874123

Epoch: 5| Step: 5
Training loss: 3.101721002867032
Validation loss: 2.6852164452984915

Epoch: 5| Step: 6
Training loss: 3.033219159950372
Validation loss: 2.7019760058022233

Epoch: 5| Step: 7
Training loss: 3.1034464843423284
Validation loss: 2.7342407306103724

Epoch: 5| Step: 8
Training loss: 2.778717859985798
Validation loss: 2.700002530938789

Epoch: 5| Step: 9
Training loss: 3.137542882375493
Validation loss: 2.682777457485845

Epoch: 5| Step: 10
Training loss: 3.2778573071445587
Validation loss: 2.6775231143605596

Epoch: 108| Step: 0
Training loss: 3.19559229439544
Validation loss: 2.6746220993473315

Epoch: 5| Step: 1
Training loss: 3.110900044850412
Validation loss: 2.67122903367466

Epoch: 5| Step: 2
Training loss: 2.625692548675198
Validation loss: 2.6728846133239665

Epoch: 5| Step: 3
Training loss: 2.7120362619321954
Validation loss: 2.673920561339778

Epoch: 5| Step: 4
Training loss: 3.335429454415989
Validation loss: 2.6710047350124375

Epoch: 5| Step: 5
Training loss: 3.2973386610239777
Validation loss: 2.673258748083364

Epoch: 5| Step: 6
Training loss: 2.4206860977369318
Validation loss: 2.6749577460384213

Epoch: 5| Step: 7
Training loss: 2.7449645845112367
Validation loss: 2.676329240822997

Epoch: 5| Step: 8
Training loss: 3.430275834005668
Validation loss: 2.6731556071861617

Epoch: 5| Step: 9
Training loss: 2.9338430814275718
Validation loss: 2.6702710532830913

Epoch: 5| Step: 10
Training loss: 3.156660751960259
Validation loss: 2.6703913748804697

Epoch: 109| Step: 0
Training loss: 3.2759541235519003
Validation loss: 2.6711356154582235

Epoch: 5| Step: 1
Training loss: 2.3821022851348097
Validation loss: 2.68762938657079

Epoch: 5| Step: 2
Training loss: 3.4582866221264554
Validation loss: 2.7137903622263297

Epoch: 5| Step: 3
Training loss: 3.445275961753531
Validation loss: 2.756222336855628

Epoch: 5| Step: 4
Training loss: 3.295285533290043
Validation loss: 2.7210792047365184

Epoch: 5| Step: 5
Training loss: 2.9980319243316145
Validation loss: 2.6765629989811

Epoch: 5| Step: 6
Training loss: 2.5327906688241173
Validation loss: 2.665644318650641

Epoch: 5| Step: 7
Training loss: 3.1200294637511505
Validation loss: 2.671759460365164

Epoch: 5| Step: 8
Training loss: 3.285328682491594
Validation loss: 2.6746886796821228

Epoch: 5| Step: 9
Training loss: 2.6354681821670867
Validation loss: 2.6799332653014574

Epoch: 5| Step: 10
Training loss: 2.7135262125835773
Validation loss: 2.68166788225052

Epoch: 110| Step: 0
Training loss: 2.6877498067040206
Validation loss: 2.6908365377690986

Epoch: 5| Step: 1
Training loss: 2.900615521583778
Validation loss: 2.690879385505986

Epoch: 5| Step: 2
Training loss: 3.1118457887975164
Validation loss: 2.67659171399136

Epoch: 5| Step: 3
Training loss: 2.960398280180375
Validation loss: 2.6752253445447947

Epoch: 5| Step: 4
Training loss: 2.9860065254605144
Validation loss: 2.67400604947796

Epoch: 5| Step: 5
Training loss: 3.6573178288845845
Validation loss: 2.67058199338403

Epoch: 5| Step: 6
Training loss: 2.934811599637396
Validation loss: 2.669904892970339

Epoch: 5| Step: 7
Training loss: 2.7561211519118882
Validation loss: 2.672379303216782

Epoch: 5| Step: 8
Training loss: 3.1797633806401935
Validation loss: 2.666878392546082

Epoch: 5| Step: 9
Training loss: 2.9894863914872896
Validation loss: 2.666848680862799

Epoch: 5| Step: 10
Training loss: 2.9819679339480225
Validation loss: 2.6699282996444866

Epoch: 111| Step: 0
Training loss: 3.266170182418923
Validation loss: 2.6660920105252304

Epoch: 5| Step: 1
Training loss: 3.158788585480008
Validation loss: 2.664109092475537

Epoch: 5| Step: 2
Training loss: 3.010385656142092
Validation loss: 2.686234414907061

Epoch: 5| Step: 3
Training loss: 3.416833237720221
Validation loss: 2.721020495520826

Epoch: 5| Step: 4
Training loss: 2.8198032077815705
Validation loss: 2.735930194796844

Epoch: 5| Step: 5
Training loss: 2.7648897217321062
Validation loss: 2.737933381907524

Epoch: 5| Step: 6
Training loss: 3.114952873498052
Validation loss: 2.7070871052712593

Epoch: 5| Step: 7
Training loss: 3.1732231995627354
Validation loss: 2.6722132702484362

Epoch: 5| Step: 8
Training loss: 2.8508381798940983
Validation loss: 2.661237150526811

Epoch: 5| Step: 9
Training loss: 2.3485535289047816
Validation loss: 2.660950142705114

Epoch: 5| Step: 10
Training loss: 2.9890891983746224
Validation loss: 2.660816501898856

Epoch: 112| Step: 0
Training loss: 3.0172984169515744
Validation loss: 2.6621761454939636

Epoch: 5| Step: 1
Training loss: 3.0017691799735147
Validation loss: 2.663443864298427

Epoch: 5| Step: 2
Training loss: 3.408180179901273
Validation loss: 2.6652188953515723

Epoch: 5| Step: 3
Training loss: 3.4485528979332405
Validation loss: 2.665532404130428

Epoch: 5| Step: 4
Training loss: 2.544870629310649
Validation loss: 2.6646571535130423

Epoch: 5| Step: 5
Training loss: 2.655717414869357
Validation loss: 2.663331330788752

Epoch: 5| Step: 6
Training loss: 3.058942947818382
Validation loss: 2.6631288120110717

Epoch: 5| Step: 7
Training loss: 3.289231103485468
Validation loss: 2.65881210772282

Epoch: 5| Step: 8
Training loss: 3.218910287365951
Validation loss: 2.6629911602208822

Epoch: 5| Step: 9
Training loss: 2.8195727109833455
Validation loss: 2.660439088143471

Epoch: 5| Step: 10
Training loss: 2.088111116419665
Validation loss: 2.6555600673976283

Epoch: 113| Step: 0
Training loss: 3.131836851028866
Validation loss: 2.657162511873624

Epoch: 5| Step: 1
Training loss: 3.1951680418904367
Validation loss: 2.654755529878332

Epoch: 5| Step: 2
Training loss: 3.0551724646502896
Validation loss: 2.6518943945193785

Epoch: 5| Step: 3
Training loss: 3.08198638225817
Validation loss: 2.65151331105759

Epoch: 5| Step: 4
Training loss: 2.4353046801566474
Validation loss: 2.653729023642253

Epoch: 5| Step: 5
Training loss: 2.800702762967127
Validation loss: 2.6544070496047123

Epoch: 5| Step: 6
Training loss: 2.610536054320216
Validation loss: 2.651103925675993

Epoch: 5| Step: 7
Training loss: 3.561353800242673
Validation loss: 2.659442536448078

Epoch: 5| Step: 8
Training loss: 3.1139602973577727
Validation loss: 2.67763096321207

Epoch: 5| Step: 9
Training loss: 3.065295286656242
Validation loss: 2.675782941029224

Epoch: 5| Step: 10
Training loss: 2.611441975681691
Validation loss: 2.655396380183214

Epoch: 114| Step: 0
Training loss: 2.354558715133576
Validation loss: 2.6528445724012357

Epoch: 5| Step: 1
Training loss: 2.8188982770198185
Validation loss: 2.651808627624456

Epoch: 5| Step: 2
Training loss: 2.866202120141889
Validation loss: 2.648593826464541

Epoch: 5| Step: 3
Training loss: 2.7419401312649336
Validation loss: 2.646762781219256

Epoch: 5| Step: 4
Training loss: 3.253767177728424
Validation loss: 2.6466027819588986

Epoch: 5| Step: 5
Training loss: 3.0562440462581004
Validation loss: 2.644749451787738

Epoch: 5| Step: 6
Training loss: 2.847905068326232
Validation loss: 2.6429115197089548

Epoch: 5| Step: 7
Training loss: 3.3888432616061483
Validation loss: 2.645306909262319

Epoch: 5| Step: 8
Training loss: 3.1716353603093546
Validation loss: 2.648619651550156

Epoch: 5| Step: 9
Training loss: 3.0095992689059807
Validation loss: 2.6546172256476215

Epoch: 5| Step: 10
Training loss: 3.2093860005725996
Validation loss: 2.6547014407025724

Epoch: 115| Step: 0
Training loss: 2.8144312691617555
Validation loss: 2.657447178404368

Epoch: 5| Step: 1
Training loss: 2.895469112041118
Validation loss: 2.6657257743480534

Epoch: 5| Step: 2
Training loss: 3.193991241003554
Validation loss: 2.6755319815610688

Epoch: 5| Step: 3
Training loss: 3.2988148266087784
Validation loss: 2.6769627248310894

Epoch: 5| Step: 4
Training loss: 2.254244932648098
Validation loss: 2.6747694741711996

Epoch: 5| Step: 5
Training loss: 2.8510566158179182
Validation loss: 2.6622154321788294

Epoch: 5| Step: 6
Training loss: 3.3841972776404834
Validation loss: 2.650490082566728

Epoch: 5| Step: 7
Training loss: 2.8432566455846247
Validation loss: 2.6407134173627163

Epoch: 5| Step: 8
Training loss: 2.6137236946201576
Validation loss: 2.644554683495262

Epoch: 5| Step: 9
Training loss: 3.2240469596320396
Validation loss: 2.6457955865845717

Epoch: 5| Step: 10
Training loss: 3.413738593267871
Validation loss: 2.652183452358709

Epoch: 116| Step: 0
Training loss: 3.3726520141546685
Validation loss: 2.6544865757266303

Epoch: 5| Step: 1
Training loss: 2.742605932757873
Validation loss: 2.654091199895158

Epoch: 5| Step: 2
Training loss: 3.5425474679764295
Validation loss: 2.653363107127849

Epoch: 5| Step: 3
Training loss: 3.047551945532311
Validation loss: 2.6466422058563777

Epoch: 5| Step: 4
Training loss: 2.6017598945031457
Validation loss: 2.649049950964209

Epoch: 5| Step: 5
Training loss: 3.0881980631958914
Validation loss: 2.648168985520512

Epoch: 5| Step: 6
Training loss: 2.7522379698662394
Validation loss: 2.6444708491189104

Epoch: 5| Step: 7
Training loss: 2.717601138762246
Validation loss: 2.6419140273274917

Epoch: 5| Step: 8
Training loss: 3.1245376244848275
Validation loss: 2.6436641218657284

Epoch: 5| Step: 9
Training loss: 2.86561711933213
Validation loss: 2.6405781620825697

Epoch: 5| Step: 10
Training loss: 2.952236950273315
Validation loss: 2.6361734919234387

Epoch: 117| Step: 0
Training loss: 2.587802917145794
Validation loss: 2.640800436752229

Epoch: 5| Step: 1
Training loss: 2.602598516704805
Validation loss: 2.644352175100258

Epoch: 5| Step: 2
Training loss: 3.209125239414332
Validation loss: 2.6615574537346456

Epoch: 5| Step: 3
Training loss: 2.4767047829174302
Validation loss: 2.6835941426288112

Epoch: 5| Step: 4
Training loss: 3.2096875953172908
Validation loss: 2.716978515078813

Epoch: 5| Step: 5
Training loss: 3.213762140774134
Validation loss: 2.698368509945966

Epoch: 5| Step: 6
Training loss: 3.291976978467166
Validation loss: 2.6690918606660583

Epoch: 5| Step: 7
Training loss: 2.70439056582431
Validation loss: 2.6697860080562252

Epoch: 5| Step: 8
Training loss: 3.6639773881539335
Validation loss: 2.643549920105254

Epoch: 5| Step: 9
Training loss: 2.6080264872803176
Validation loss: 2.6485877672460325

Epoch: 5| Step: 10
Training loss: 2.920344150590088
Validation loss: 2.644469203019028

Epoch: 118| Step: 0
Training loss: 2.9716628391015147
Validation loss: 2.638325546753565

Epoch: 5| Step: 1
Training loss: 2.6447988174740455
Validation loss: 2.6366472725122345

Epoch: 5| Step: 2
Training loss: 2.5032035329550575
Validation loss: 2.634227951687524

Epoch: 5| Step: 3
Training loss: 3.4180065567105498
Validation loss: 2.634093630568198

Epoch: 5| Step: 4
Training loss: 3.0139993822164226
Validation loss: 2.634132513701862

Epoch: 5| Step: 5
Training loss: 2.7533629402280657
Validation loss: 2.633657750211027

Epoch: 5| Step: 6
Training loss: 3.198837909690509
Validation loss: 2.635763737327594

Epoch: 5| Step: 7
Training loss: 2.8321735214802652
Validation loss: 2.6341566654915023

Epoch: 5| Step: 8
Training loss: 3.474886303695187
Validation loss: 2.634204937263681

Epoch: 5| Step: 9
Training loss: 2.8993954784790916
Validation loss: 2.6436465367218673

Epoch: 5| Step: 10
Training loss: 2.74933312739949
Validation loss: 2.6453435885594345

Epoch: 119| Step: 0
Training loss: 3.1117746879191017
Validation loss: 2.6433311566790776

Epoch: 5| Step: 1
Training loss: 3.561154027618414
Validation loss: 2.6369437289677293

Epoch: 5| Step: 2
Training loss: 2.586837934480546
Validation loss: 2.6302107723342143

Epoch: 5| Step: 3
Training loss: 2.6359806186154535
Validation loss: 2.629629086009376

Epoch: 5| Step: 4
Training loss: 2.5714904497663893
Validation loss: 2.630710176644153

Epoch: 5| Step: 5
Training loss: 2.58422647439176
Validation loss: 2.62887348005362

Epoch: 5| Step: 6
Training loss: 2.9008775501411788
Validation loss: 2.6287084265906473

Epoch: 5| Step: 7
Training loss: 2.8003705733171085
Validation loss: 2.630579057605611

Epoch: 5| Step: 8
Training loss: 2.8502742836122437
Validation loss: 2.6316936631854526

Epoch: 5| Step: 9
Training loss: 3.3327933509873877
Validation loss: 2.6302356823734234

Epoch: 5| Step: 10
Training loss: 3.498784807964944
Validation loss: 2.6393017021933463

Epoch: 120| Step: 0
Training loss: 2.9990603246876715
Validation loss: 2.6513836675090316

Epoch: 5| Step: 1
Training loss: 3.0487854274616697
Validation loss: 2.6628622757302196

Epoch: 5| Step: 2
Training loss: 2.7580368339784345
Validation loss: 2.6542621304131973

Epoch: 5| Step: 3
Training loss: 3.2049309826351315
Validation loss: 2.6631004774447717

Epoch: 5| Step: 4
Training loss: 2.9155912505687533
Validation loss: 2.669298719515076

Epoch: 5| Step: 5
Training loss: 2.6599592452404854
Validation loss: 2.653986240917238

Epoch: 5| Step: 6
Training loss: 2.8559279379208222
Validation loss: 2.6361538077698747

Epoch: 5| Step: 7
Training loss: 2.7402334179268197
Validation loss: 2.627172552556215

Epoch: 5| Step: 8
Training loss: 3.354944332473942
Validation loss: 2.628718457964609

Epoch: 5| Step: 9
Training loss: 3.0451999852948006
Validation loss: 2.6287706563803885

Epoch: 5| Step: 10
Training loss: 3.011707667071858
Validation loss: 2.626955104122201

Epoch: 121| Step: 0
Training loss: 2.4069254534041202
Validation loss: 2.62922359727536

Epoch: 5| Step: 1
Training loss: 3.1373912047714647
Validation loss: 2.6231912748130006

Epoch: 5| Step: 2
Training loss: 2.862365992711783
Validation loss: 2.624588503913166

Epoch: 5| Step: 3
Training loss: 3.2868299722497802
Validation loss: 2.6197582056726962

Epoch: 5| Step: 4
Training loss: 2.8584247948904364
Validation loss: 2.625018763829139

Epoch: 5| Step: 5
Training loss: 3.184175590283661
Validation loss: 2.622073552649502

Epoch: 5| Step: 6
Training loss: 2.758568765402336
Validation loss: 2.6224695931301665

Epoch: 5| Step: 7
Training loss: 1.998813575272706
Validation loss: 2.6278187725425477

Epoch: 5| Step: 8
Training loss: 3.7762199552692546
Validation loss: 2.6385075452470335

Epoch: 5| Step: 9
Training loss: 3.154221439935833
Validation loss: 2.6439488047449102

Epoch: 5| Step: 10
Training loss: 2.80291675147048
Validation loss: 2.6702381419640497

Epoch: 122| Step: 0
Training loss: 2.5805053819209616
Validation loss: 2.6936414449074886

Epoch: 5| Step: 1
Training loss: 2.752110278459467
Validation loss: 2.657098652668693

Epoch: 5| Step: 2
Training loss: 2.755064029676477
Validation loss: 2.632495231861328

Epoch: 5| Step: 3
Training loss: 2.367351966910623
Validation loss: 2.6233235771567034

Epoch: 5| Step: 4
Training loss: 3.0362510719470177
Validation loss: 2.620118995665788

Epoch: 5| Step: 5
Training loss: 3.049207840904134
Validation loss: 2.625485483250021

Epoch: 5| Step: 6
Training loss: 3.146553630765212
Validation loss: 2.628680044792277

Epoch: 5| Step: 7
Training loss: 3.3371158278736774
Validation loss: 2.639147788061279

Epoch: 5| Step: 8
Training loss: 2.8587232169967915
Validation loss: 2.6418632812118985

Epoch: 5| Step: 9
Training loss: 3.1572085898324667
Validation loss: 2.642943411381319

Epoch: 5| Step: 10
Training loss: 3.6793001461044885
Validation loss: 2.6323873958666284

Epoch: 123| Step: 0
Training loss: 2.8213684134252444
Validation loss: 2.6273739886702843

Epoch: 5| Step: 1
Training loss: 2.7598094248282523
Validation loss: 2.6205572668568

Epoch: 5| Step: 2
Training loss: 2.8957283129047524
Validation loss: 2.622031103831592

Epoch: 5| Step: 3
Training loss: 3.157700611304809
Validation loss: 2.615349212306039

Epoch: 5| Step: 4
Training loss: 3.365745288679255
Validation loss: 2.61760455992838

Epoch: 5| Step: 5
Training loss: 3.015785331614609
Validation loss: 2.6188407024480354

Epoch: 5| Step: 6
Training loss: 2.418539593044232
Validation loss: 2.6279191926602183

Epoch: 5| Step: 7
Training loss: 2.5438051035018487
Validation loss: 2.66664215590636

Epoch: 5| Step: 8
Training loss: 2.857705885043987
Validation loss: 2.7153581841420293

Epoch: 5| Step: 9
Training loss: 3.4064074838612535
Validation loss: 2.73498896443221

Epoch: 5| Step: 10
Training loss: 3.2351814775696988
Validation loss: 2.7296983234996675

Epoch: 124| Step: 0
Training loss: 3.6715282519953725
Validation loss: 2.6882182366083587

Epoch: 5| Step: 1
Training loss: 3.1583325153708763
Validation loss: 2.618636394447412

Epoch: 5| Step: 2
Training loss: 2.506762228202726
Validation loss: 2.6139001414972802

Epoch: 5| Step: 3
Training loss: 2.6187242238089468
Validation loss: 2.614364937165026

Epoch: 5| Step: 4
Training loss: 2.711888127379812
Validation loss: 2.62521041323702

Epoch: 5| Step: 5
Training loss: 3.4923974983175787
Validation loss: 2.6415510588312276

Epoch: 5| Step: 6
Training loss: 3.368718836822465
Validation loss: 2.6591341212113777

Epoch: 5| Step: 7
Training loss: 2.261653181057865
Validation loss: 2.7131297920219635

Epoch: 5| Step: 8
Training loss: 3.7007634483587313
Validation loss: 2.734061258484883

Epoch: 5| Step: 9
Training loss: 2.1607426818278834
Validation loss: 2.639404888757926

Epoch: 5| Step: 10
Training loss: 2.765197720899709
Validation loss: 2.6207992353770493

Epoch: 125| Step: 0
Training loss: 2.8673444907633505
Validation loss: 2.6284275218472897

Epoch: 5| Step: 1
Training loss: 3.441216142060384
Validation loss: 2.6326848617437157

Epoch: 5| Step: 2
Training loss: 3.0136098503014592
Validation loss: 2.6305497769758013

Epoch: 5| Step: 3
Training loss: 2.527132146310955
Validation loss: 2.6217955618070716

Epoch: 5| Step: 4
Training loss: 2.7014926104884918
Validation loss: 2.637456182969206

Epoch: 5| Step: 5
Training loss: 2.9128294271389192
Validation loss: 2.658983821350582

Epoch: 5| Step: 6
Training loss: 3.0923258268114373
Validation loss: 2.6972547517260765

Epoch: 5| Step: 7
Training loss: 3.3521818998049437
Validation loss: 2.6654663890466637

Epoch: 5| Step: 8
Training loss: 2.7712443532098994
Validation loss: 2.6593496219309114

Epoch: 5| Step: 9
Training loss: 2.2795304388753035
Validation loss: 2.641053421014062

Epoch: 5| Step: 10
Training loss: 3.3905151630665045
Validation loss: 2.6340725069912643

Epoch: 126| Step: 0
Training loss: 2.71074330626508
Validation loss: 2.6185239188306912

Epoch: 5| Step: 1
Training loss: 3.0725830069395506
Validation loss: 2.617239069350243

Epoch: 5| Step: 2
Training loss: 3.133098028018566
Validation loss: 2.611211814900614

Epoch: 5| Step: 3
Training loss: 2.9124062257004146
Validation loss: 2.6136562964195567

Epoch: 5| Step: 4
Training loss: 2.8522650702351964
Validation loss: 2.6141284013603694

Epoch: 5| Step: 5
Training loss: 3.022794275590707
Validation loss: 2.6081792193879014

Epoch: 5| Step: 6
Training loss: 2.9531842584063597
Validation loss: 2.6104843437153873

Epoch: 5| Step: 7
Training loss: 2.9533121362561245
Validation loss: 2.6101792228298124

Epoch: 5| Step: 8
Training loss: 2.564548603962058
Validation loss: 2.612117942565454

Epoch: 5| Step: 9
Training loss: 2.8087979853919185
Validation loss: 2.6134640047458757

Epoch: 5| Step: 10
Training loss: 3.3702654655333166
Validation loss: 2.6220863171765747

Epoch: 127| Step: 0
Training loss: 2.9778031294330276
Validation loss: 2.6103607982038164

Epoch: 5| Step: 1
Training loss: 3.1648332575405402
Validation loss: 2.612095144564175

Epoch: 5| Step: 2
Training loss: 2.98931507852081
Validation loss: 2.611666105780907

Epoch: 5| Step: 3
Training loss: 3.0351556215813376
Validation loss: 2.606747553221103

Epoch: 5| Step: 4
Training loss: 2.4815308226977604
Validation loss: 2.61238088201298

Epoch: 5| Step: 5
Training loss: 2.854310099392435
Validation loss: 2.606483018649465

Epoch: 5| Step: 6
Training loss: 2.926208872288137
Validation loss: 2.606158031093021

Epoch: 5| Step: 7
Training loss: 3.061067985958601
Validation loss: 2.6012882757118816

Epoch: 5| Step: 8
Training loss: 2.6884323986678615
Validation loss: 2.604712656846238

Epoch: 5| Step: 9
Training loss: 3.1653804341898395
Validation loss: 2.6058998489838006

Epoch: 5| Step: 10
Training loss: 2.8408156126422104
Validation loss: 2.6038954234632636

Epoch: 128| Step: 0
Training loss: 2.891852535756623
Validation loss: 2.6069517308984476

Epoch: 5| Step: 1
Training loss: 2.928053255128425
Validation loss: 2.6048137738589854

Epoch: 5| Step: 2
Training loss: 2.793504356832881
Validation loss: 2.6047280255781096

Epoch: 5| Step: 3
Training loss: 2.691718051604948
Validation loss: 2.599780339608438

Epoch: 5| Step: 4
Training loss: 3.0567395276531157
Validation loss: 2.6019932894846924

Epoch: 5| Step: 5
Training loss: 2.7843726983365906
Validation loss: 2.603563471349101

Epoch: 5| Step: 6
Training loss: 3.060199730033207
Validation loss: 2.6010127806167227

Epoch: 5| Step: 7
Training loss: 2.133118324571118
Validation loss: 2.6079375780770895

Epoch: 5| Step: 8
Training loss: 2.964336769071414
Validation loss: 2.6110022107678152

Epoch: 5| Step: 9
Training loss: 3.7044193886764694
Validation loss: 2.6166514249720496

Epoch: 5| Step: 10
Training loss: 3.0465209755262297
Validation loss: 2.6097420354542744

Epoch: 129| Step: 0
Training loss: 2.9643776267110633
Validation loss: 2.60231341435575

Epoch: 5| Step: 1
Training loss: 2.556482273731966
Validation loss: 2.6005877996631983

Epoch: 5| Step: 2
Training loss: 2.606003644904093
Validation loss: 2.597518949097566

Epoch: 5| Step: 3
Training loss: 3.074185711732811
Validation loss: 2.6023325368201182

Epoch: 5| Step: 4
Training loss: 3.0820327971518613
Validation loss: 2.599200932054895

Epoch: 5| Step: 5
Training loss: 2.654437894352238
Validation loss: 2.600684971383709

Epoch: 5| Step: 6
Training loss: 2.8351198809538696
Validation loss: 2.5992224425916834

Epoch: 5| Step: 7
Training loss: 3.3384022953898556
Validation loss: 2.60125001430376

Epoch: 5| Step: 8
Training loss: 3.0779807739549683
Validation loss: 2.6017652607064345

Epoch: 5| Step: 9
Training loss: 3.2042599039852555
Validation loss: 2.6056332064691308

Epoch: 5| Step: 10
Training loss: 2.666130091407139
Validation loss: 2.6138388385918017

Epoch: 130| Step: 0
Training loss: 3.1856881770469867
Validation loss: 2.611470125646231

Epoch: 5| Step: 1
Training loss: 2.7884704645352967
Validation loss: 2.6318509530285517

Epoch: 5| Step: 2
Training loss: 2.898586217967008
Validation loss: 2.646135640591239

Epoch: 5| Step: 3
Training loss: 2.4446012297354995
Validation loss: 2.6686821545291615

Epoch: 5| Step: 4
Training loss: 3.48931056232867
Validation loss: 2.6718762487775467

Epoch: 5| Step: 5
Training loss: 2.9239960993624656
Validation loss: 2.6548929172821896

Epoch: 5| Step: 6
Training loss: 2.791097630443266
Validation loss: 2.621250370238485

Epoch: 5| Step: 7
Training loss: 2.7928378841445554
Validation loss: 2.61823758967205

Epoch: 5| Step: 8
Training loss: 3.2047339887515887
Validation loss: 2.6129991135751505

Epoch: 5| Step: 9
Training loss: 2.5365021458366126
Validation loss: 2.5947135759382074

Epoch: 5| Step: 10
Training loss: 2.99007490593718
Validation loss: 2.5908008205789343

Epoch: 131| Step: 0
Training loss: 3.072740676926571
Validation loss: 2.5934275745367654

Epoch: 5| Step: 1
Training loss: 3.3364180279092737
Validation loss: 2.596148328351935

Epoch: 5| Step: 2
Training loss: 2.9252112613907206
Validation loss: 2.5955595575244454

Epoch: 5| Step: 3
Training loss: 2.76397112516897
Validation loss: 2.5937526854585062

Epoch: 5| Step: 4
Training loss: 3.306845823659252
Validation loss: 2.5919736543528926

Epoch: 5| Step: 5
Training loss: 2.322045189844069
Validation loss: 2.592135813067586

Epoch: 5| Step: 6
Training loss: 2.8052676990080903
Validation loss: 2.5888110156230684

Epoch: 5| Step: 7
Training loss: 2.5638476293937686
Validation loss: 2.5954192535568876

Epoch: 5| Step: 8
Training loss: 2.599750976374498
Validation loss: 2.599965139814787

Epoch: 5| Step: 9
Training loss: 2.9949141944477295
Validation loss: 2.608150787187895

Epoch: 5| Step: 10
Training loss: 3.4394540954623136
Validation loss: 2.625143976946015

Epoch: 132| Step: 0
Training loss: 3.1847637624277794
Validation loss: 2.641688624446974

Epoch: 5| Step: 1
Training loss: 2.92469757342466
Validation loss: 2.6702186033166786

Epoch: 5| Step: 2
Training loss: 3.273776744661914
Validation loss: 2.691755814712459

Epoch: 5| Step: 3
Training loss: 3.3308900620782813
Validation loss: 2.6845534441429875

Epoch: 5| Step: 4
Training loss: 2.8272046862657847
Validation loss: 2.6195807059603586

Epoch: 5| Step: 5
Training loss: 3.10038262128668
Validation loss: 2.60285282848995

Epoch: 5| Step: 6
Training loss: 2.6461300320611474
Validation loss: 2.58570744256613

Epoch: 5| Step: 7
Training loss: 2.317788957772255
Validation loss: 2.582904089979744

Epoch: 5| Step: 8
Training loss: 3.1266818289263747
Validation loss: 2.586196305020249

Epoch: 5| Step: 9
Training loss: 2.7033125090198764
Validation loss: 2.5849254126929373

Epoch: 5| Step: 10
Training loss: 2.537270720698429
Validation loss: 2.5831210768357113

Epoch: 133| Step: 0
Training loss: 2.88836796253516
Validation loss: 2.581175408634703

Epoch: 5| Step: 1
Training loss: 3.108665500377502
Validation loss: 2.583303722948899

Epoch: 5| Step: 2
Training loss: 2.844949322669838
Validation loss: 2.57874490066336

Epoch: 5| Step: 3
Training loss: 2.333570525057312
Validation loss: 2.585347874371324

Epoch: 5| Step: 4
Training loss: 2.7772519811392598
Validation loss: 2.5841309417317517

Epoch: 5| Step: 5
Training loss: 3.208936675838053
Validation loss: 2.587205751870442

Epoch: 5| Step: 6
Training loss: 3.0876209930311145
Validation loss: 2.5851353738799596

Epoch: 5| Step: 7
Training loss: 2.97911719078827
Validation loss: 2.5875708706791287

Epoch: 5| Step: 8
Training loss: 3.125153499648026
Validation loss: 2.5879354941807917

Epoch: 5| Step: 9
Training loss: 2.8063827959003107
Validation loss: 2.5907881413758855

Epoch: 5| Step: 10
Training loss: 2.855629724643512
Validation loss: 2.592599839363804

Epoch: 134| Step: 0
Training loss: 3.3257003333454978
Validation loss: 2.601789629199858

Epoch: 5| Step: 1
Training loss: 2.4275001419020197
Validation loss: 2.602552830558624

Epoch: 5| Step: 2
Training loss: 2.68023462521086
Validation loss: 2.6096486829919225

Epoch: 5| Step: 3
Training loss: 2.7870181843328985
Validation loss: 2.6015335185355712

Epoch: 5| Step: 4
Training loss: 3.3025042308748507
Validation loss: 2.601058587446389

Epoch: 5| Step: 5
Training loss: 2.626311655678024
Validation loss: 2.5892680159616126

Epoch: 5| Step: 6
Training loss: 2.6074060561025294
Validation loss: 2.5886407476962296

Epoch: 5| Step: 7
Training loss: 3.397883788853543
Validation loss: 2.5880563916210906

Epoch: 5| Step: 8
Training loss: 2.5577628846853027
Validation loss: 2.586841998701906

Epoch: 5| Step: 9
Training loss: 3.3742034819907376
Validation loss: 2.587703771673497

Epoch: 5| Step: 10
Training loss: 2.724429370033928
Validation loss: 2.5888173157592234

Epoch: 135| Step: 0
Training loss: 3.2281255376765494
Validation loss: 2.590241865922516

Epoch: 5| Step: 1
Training loss: 3.185419787614756
Validation loss: 2.591546643063019

Epoch: 5| Step: 2
Training loss: 2.2612689004069173
Validation loss: 2.5875688584613323

Epoch: 5| Step: 3
Training loss: 2.6097497728035055
Validation loss: 2.59922551987892

Epoch: 5| Step: 4
Training loss: 2.8763790969358594
Validation loss: 2.5960538565407134

Epoch: 5| Step: 5
Training loss: 2.8631182073826085
Validation loss: 2.5914312248274607

Epoch: 5| Step: 6
Training loss: 3.3742539322951637
Validation loss: 2.5874963819103876

Epoch: 5| Step: 7
Training loss: 2.610378963099736
Validation loss: 2.5823877746326067

Epoch: 5| Step: 8
Training loss: 2.9220861674821346
Validation loss: 2.5775003361968554

Epoch: 5| Step: 9
Training loss: 2.667489272635
Validation loss: 2.5728785725530563

Epoch: 5| Step: 10
Training loss: 3.3245766219582
Validation loss: 2.5751655385224694

Epoch: 136| Step: 0
Training loss: 2.898167024315555
Validation loss: 2.576017606433028

Epoch: 5| Step: 1
Training loss: 3.0983159443936925
Validation loss: 2.5755560930268215

Epoch: 5| Step: 2
Training loss: 2.475414503432941
Validation loss: 2.5753324656632364

Epoch: 5| Step: 3
Training loss: 3.056151212566195
Validation loss: 2.5783672543363214

Epoch: 5| Step: 4
Training loss: 2.799641524937051
Validation loss: 2.587150347551103

Epoch: 5| Step: 5
Training loss: 3.2268707645380337
Validation loss: 2.5986044889433195

Epoch: 5| Step: 6
Training loss: 3.308641885995029
Validation loss: 2.6019285117560256

Epoch: 5| Step: 7
Training loss: 2.037327872652621
Validation loss: 2.6088028353485524

Epoch: 5| Step: 8
Training loss: 3.342512810967146
Validation loss: 2.6141748903942084

Epoch: 5| Step: 9
Training loss: 2.8369416279856985
Validation loss: 2.633579122454692

Epoch: 5| Step: 10
Training loss: 2.6914438098340714
Validation loss: 2.6514892090762996

Epoch: 137| Step: 0
Training loss: 3.152049678430365
Validation loss: 2.632951924278422

Epoch: 5| Step: 1
Training loss: 2.524012449919983
Validation loss: 2.612037192246414

Epoch: 5| Step: 2
Training loss: 2.3568629350457115
Validation loss: 2.607498012609571

Epoch: 5| Step: 3
Training loss: 2.639793942386045
Validation loss: 2.5920844445205913

Epoch: 5| Step: 4
Training loss: 3.0109316023574344
Validation loss: 2.5866524798728685

Epoch: 5| Step: 5
Training loss: 2.9431335322073515
Validation loss: 2.583669248316088

Epoch: 5| Step: 6
Training loss: 3.0581699823173776
Validation loss: 2.576155063122409

Epoch: 5| Step: 7
Training loss: 2.8385906996852075
Validation loss: 2.579156271474735

Epoch: 5| Step: 8
Training loss: 2.9675261534749136
Validation loss: 2.572320418071271

Epoch: 5| Step: 9
Training loss: 3.0698757491922235
Validation loss: 2.567953328229708

Epoch: 5| Step: 10
Training loss: 3.3053764184305985
Validation loss: 2.5692020873629593

Epoch: 138| Step: 0
Training loss: 2.715245849690498
Validation loss: 2.5744207724533537

Epoch: 5| Step: 1
Training loss: 2.8649344674116852
Validation loss: 2.570275511994307

Epoch: 5| Step: 2
Training loss: 3.059087915559484
Validation loss: 2.57910812292667

Epoch: 5| Step: 3
Training loss: 3.09296152875712
Validation loss: 2.597532631252432

Epoch: 5| Step: 4
Training loss: 3.0996276816468686
Validation loss: 2.6302588026788194

Epoch: 5| Step: 5
Training loss: 2.549477774308279
Validation loss: 2.632411973668811

Epoch: 5| Step: 6
Training loss: 3.214071187928827
Validation loss: 2.6321060431998857

Epoch: 5| Step: 7
Training loss: 2.3178964488521308
Validation loss: 2.615503854511941

Epoch: 5| Step: 8
Training loss: 3.1057756764108153
Validation loss: 2.5957352411344146

Epoch: 5| Step: 9
Training loss: 2.737742241718947
Validation loss: 2.581309468189834

Epoch: 5| Step: 10
Training loss: 3.116729167236752
Validation loss: 2.5727621524231097

Epoch: 139| Step: 0
Training loss: 2.489892937683363
Validation loss: 2.5690260971079186

Epoch: 5| Step: 1
Training loss: 2.8557025276224994
Validation loss: 2.573427196912192

Epoch: 5| Step: 2
Training loss: 2.998125921443681
Validation loss: 2.578249451836326

Epoch: 5| Step: 3
Training loss: 3.3204064210061968
Validation loss: 2.5777961290005904

Epoch: 5| Step: 4
Training loss: 3.33650206315777
Validation loss: 2.5789403874556887

Epoch: 5| Step: 5
Training loss: 2.452705298802911
Validation loss: 2.5747435030537518

Epoch: 5| Step: 6
Training loss: 3.103881583894724
Validation loss: 2.5731545821098782

Epoch: 5| Step: 7
Training loss: 2.766904459542925
Validation loss: 2.584248842678538

Epoch: 5| Step: 8
Training loss: 2.8643298967553106
Validation loss: 2.577779638004846

Epoch: 5| Step: 9
Training loss: 2.6142202381031527
Validation loss: 2.5740948313193233

Epoch: 5| Step: 10
Training loss: 2.82280319004557
Validation loss: 2.5829113692720727

Epoch: 140| Step: 0
Training loss: 2.655866976779136
Validation loss: 2.5773334301009223

Epoch: 5| Step: 1
Training loss: 2.7339927188131714
Validation loss: 2.581127798337223

Epoch: 5| Step: 2
Training loss: 2.9775289733655734
Validation loss: 2.5824673633883557

Epoch: 5| Step: 3
Training loss: 2.7968663902789532
Validation loss: 2.576372718397279

Epoch: 5| Step: 4
Training loss: 3.097155305589062
Validation loss: 2.5762170796382886

Epoch: 5| Step: 5
Training loss: 2.951610358412123
Validation loss: 2.5780360271455787

Epoch: 5| Step: 6
Training loss: 2.756688134626065
Validation loss: 2.5875598871807726

Epoch: 5| Step: 7
Training loss: 2.3570484538804943
Validation loss: 2.5891682622071928

Epoch: 5| Step: 8
Training loss: 2.9826172450539414
Validation loss: 2.5890465106653937

Epoch: 5| Step: 9
Training loss: 3.1112383142836553
Validation loss: 2.5888903088784114

Epoch: 5| Step: 10
Training loss: 3.2431256878657853
Validation loss: 2.587666745941274

Epoch: 141| Step: 0
Training loss: 2.548313413367081
Validation loss: 2.6008584468127833

Epoch: 5| Step: 1
Training loss: 2.6378009750969484
Validation loss: 2.5994775018330767

Epoch: 5| Step: 2
Training loss: 3.1713905904157467
Validation loss: 2.5899207478444217

Epoch: 5| Step: 3
Training loss: 2.847854167826375
Validation loss: 2.5881377534512757

Epoch: 5| Step: 4
Training loss: 3.263150824748024
Validation loss: 2.603420051769122

Epoch: 5| Step: 5
Training loss: 2.4264122576850755
Validation loss: 2.595340630948806

Epoch: 5| Step: 6
Training loss: 3.03937456347874
Validation loss: 2.605270855194612

Epoch: 5| Step: 7
Training loss: 2.4145355254984433
Validation loss: 2.5997290659023675

Epoch: 5| Step: 8
Training loss: 2.7996888737164736
Validation loss: 2.599043653838844

Epoch: 5| Step: 9
Training loss: 3.0549021301575783
Validation loss: 2.5955419408030656

Epoch: 5| Step: 10
Training loss: 3.400059104854489
Validation loss: 2.603757323220705

Epoch: 142| Step: 0
Training loss: 1.8927792972690096
Validation loss: 2.6138789998858827

Epoch: 5| Step: 1
Training loss: 3.2990669087276356
Validation loss: 2.6055074896351313

Epoch: 5| Step: 2
Training loss: 2.4416220607740855
Validation loss: 2.601243763004576

Epoch: 5| Step: 3
Training loss: 2.7010629539567925
Validation loss: 2.5887837531470166

Epoch: 5| Step: 4
Training loss: 2.5920666667053096
Validation loss: 2.5797287314242596

Epoch: 5| Step: 5
Training loss: 3.070803226925505
Validation loss: 2.581390973154945

Epoch: 5| Step: 6
Training loss: 3.010065042800512
Validation loss: 2.5770430705124947

Epoch: 5| Step: 7
Training loss: 3.050018723227143
Validation loss: 2.5775455851699394

Epoch: 5| Step: 8
Training loss: 3.275760090689324
Validation loss: 2.57233123143738

Epoch: 5| Step: 9
Training loss: 2.7260851073214165
Validation loss: 2.5756686553809596

Epoch: 5| Step: 10
Training loss: 3.2804124035576
Validation loss: 2.573560171838825

Epoch: 143| Step: 0
Training loss: 2.789786194159824
Validation loss: 2.5829110913610975

Epoch: 5| Step: 1
Training loss: 2.925739690386156
Validation loss: 2.5820904645328686

Epoch: 5| Step: 2
Training loss: 2.6320911177600146
Validation loss: 2.5966713489499367

Epoch: 5| Step: 3
Training loss: 2.951861075732529
Validation loss: 2.5925709248229984

Epoch: 5| Step: 4
Training loss: 2.872417119011586
Validation loss: 2.5831896443916498

Epoch: 5| Step: 5
Training loss: 2.8417106274497996
Validation loss: 2.5704356694930626

Epoch: 5| Step: 6
Training loss: 3.0613813887500614
Validation loss: 2.569706948427583

Epoch: 5| Step: 7
Training loss: 2.9555663659161775
Validation loss: 2.5648505442424643

Epoch: 5| Step: 8
Training loss: 3.0181189783810005
Validation loss: 2.567446386911394

Epoch: 5| Step: 9
Training loss: 2.834348122869915
Validation loss: 2.567432246863448

Epoch: 5| Step: 10
Training loss: 2.797738309635202
Validation loss: 2.5607342112296334

Epoch: 144| Step: 0
Training loss: 2.711729170444857
Validation loss: 2.5701891006763695

Epoch: 5| Step: 1
Training loss: 3.0890958051955524
Validation loss: 2.5736397377384823

Epoch: 5| Step: 2
Training loss: 3.012854375612512
Validation loss: 2.5755187154801606

Epoch: 5| Step: 3
Training loss: 2.5997267652871505
Validation loss: 2.59074448133923

Epoch: 5| Step: 4
Training loss: 2.3209561569431667
Validation loss: 2.5943801515693163

Epoch: 5| Step: 5
Training loss: 2.9861055319879344
Validation loss: 2.588985015351112

Epoch: 5| Step: 6
Training loss: 3.0687121231631735
Validation loss: 2.5902985471516886

Epoch: 5| Step: 7
Training loss: 2.9175649258826652
Validation loss: 2.5809186430002864

Epoch: 5| Step: 8
Training loss: 3.024230695270745
Validation loss: 2.5811134357672736

Epoch: 5| Step: 9
Training loss: 2.7111373080184795
Validation loss: 2.572726503016992

Epoch: 5| Step: 10
Training loss: 2.9738831162613923
Validation loss: 2.5748019134189697

Epoch: 145| Step: 0
Training loss: 2.5678310300491067
Validation loss: 2.5769873024552714

Epoch: 5| Step: 1
Training loss: 3.4377401094675117
Validation loss: 2.577724154407831

Epoch: 5| Step: 2
Training loss: 2.7398406416780468
Validation loss: 2.584483161364421

Epoch: 5| Step: 3
Training loss: 2.7984241478887393
Validation loss: 2.5938719488387125

Epoch: 5| Step: 4
Training loss: 3.3630770843954703
Validation loss: 2.5940372403371144

Epoch: 5| Step: 5
Training loss: 2.652665176354113
Validation loss: 2.5971398725387402

Epoch: 5| Step: 6
Training loss: 3.1278243462495157
Validation loss: 2.583874859718033

Epoch: 5| Step: 7
Training loss: 3.2785153573848635
Validation loss: 2.561710390079184

Epoch: 5| Step: 8
Training loss: 2.644670716612997
Validation loss: 2.5615893360757704

Epoch: 5| Step: 9
Training loss: 2.195912669399591
Validation loss: 2.5596836439326416

Epoch: 5| Step: 10
Training loss: 2.3861282042588208
Validation loss: 2.5616445566658532

Epoch: 146| Step: 0
Training loss: 2.846057500616241
Validation loss: 2.561865351070813

Epoch: 5| Step: 1
Training loss: 3.3455980844482163
Validation loss: 2.568769910480871

Epoch: 5| Step: 2
Training loss: 3.1186250894794116
Validation loss: 2.5621797274961686

Epoch: 5| Step: 3
Training loss: 3.091961738783972
Validation loss: 2.55680857709098

Epoch: 5| Step: 4
Training loss: 3.141576063095924
Validation loss: 2.557132366536904

Epoch: 5| Step: 5
Training loss: 3.0230510770298036
Validation loss: 2.5585545785863264

Epoch: 5| Step: 6
Training loss: 2.324728517166646
Validation loss: 2.563150589913686

Epoch: 5| Step: 7
Training loss: 2.633114126795537
Validation loss: 2.573496392826636

Epoch: 5| Step: 8
Training loss: 2.987783512724557
Validation loss: 2.5814738052970445

Epoch: 5| Step: 9
Training loss: 2.5376743688947103
Validation loss: 2.6086292828497233

Epoch: 5| Step: 10
Training loss: 2.396314942977805
Validation loss: 2.5973727716537494

Epoch: 147| Step: 0
Training loss: 2.4852601399872456
Validation loss: 2.6110729538596344

Epoch: 5| Step: 1
Training loss: 3.063095657653311
Validation loss: 2.620078813583428

Epoch: 5| Step: 2
Training loss: 2.9478117763518803
Validation loss: 2.590642049741166

Epoch: 5| Step: 3
Training loss: 3.000217111996432
Validation loss: 2.5695074048394084

Epoch: 5| Step: 4
Training loss: 3.3011431072454522
Validation loss: 2.557989725736018

Epoch: 5| Step: 5
Training loss: 2.6658260292015963
Validation loss: 2.5554650325073895

Epoch: 5| Step: 6
Training loss: 2.446003581614457
Validation loss: 2.561437941466965

Epoch: 5| Step: 7
Training loss: 2.6555893020223635
Validation loss: 2.5611535663579823

Epoch: 5| Step: 8
Training loss: 2.498358378251935
Validation loss: 2.553922695954089

Epoch: 5| Step: 9
Training loss: 3.3652257315889433
Validation loss: 2.55975341667773

Epoch: 5| Step: 10
Training loss: 3.2166899968488782
Validation loss: 2.558636213243166

Epoch: 148| Step: 0
Training loss: 2.865810968153341
Validation loss: 2.5732571613749156

Epoch: 5| Step: 1
Training loss: 2.5427086575539297
Validation loss: 2.605590004751568

Epoch: 5| Step: 2
Training loss: 2.8225780908072027
Validation loss: 2.6331824221138844

Epoch: 5| Step: 3
Training loss: 3.7487976689883777
Validation loss: 2.653797666556223

Epoch: 5| Step: 4
Training loss: 2.3412957120507203
Validation loss: 2.5963180901038796

Epoch: 5| Step: 5
Training loss: 2.9707064957759477
Validation loss: 2.5695407877269116

Epoch: 5| Step: 6
Training loss: 2.5400541745813907
Validation loss: 2.550580685108129

Epoch: 5| Step: 7
Training loss: 3.1554924084011895
Validation loss: 2.5577766903007597

Epoch: 5| Step: 8
Training loss: 2.916220676292676
Validation loss: 2.551498453214966

Epoch: 5| Step: 9
Training loss: 2.5439708979339586
Validation loss: 2.5524116326716357

Epoch: 5| Step: 10
Training loss: 3.03746951994497
Validation loss: 2.5548147241546952

Epoch: 149| Step: 0
Training loss: 2.7187111511962643
Validation loss: 2.5496725202877055

Epoch: 5| Step: 1
Training loss: 2.8399549040101895
Validation loss: 2.554927421664212

Epoch: 5| Step: 2
Training loss: 3.0819723029355752
Validation loss: 2.560706256384539

Epoch: 5| Step: 3
Training loss: 2.862666502528666
Validation loss: 2.565486095514753

Epoch: 5| Step: 4
Training loss: 2.6865746435334903
Validation loss: 2.578601604917674

Epoch: 5| Step: 5
Training loss: 2.678302996672722
Validation loss: 2.577816442754928

Epoch: 5| Step: 6
Training loss: 3.3591255982548605
Validation loss: 2.578085738523561

Epoch: 5| Step: 7
Training loss: 3.123613126090812
Validation loss: 2.5813828652800686

Epoch: 5| Step: 8
Training loss: 2.321437986585367
Validation loss: 2.577362200273618

Epoch: 5| Step: 9
Training loss: 2.8223903958416714
Validation loss: 2.5743760909501887

Epoch: 5| Step: 10
Training loss: 2.7010237624907245
Validation loss: 2.5889472761662793

Epoch: 150| Step: 0
Training loss: 2.8070639740299606
Validation loss: 2.584958195303778

Epoch: 5| Step: 1
Training loss: 2.9479415047793243
Validation loss: 2.577579211562961

Epoch: 5| Step: 2
Training loss: 2.557452650629368
Validation loss: 2.564896928931611

Epoch: 5| Step: 3
Training loss: 3.458841692471146
Validation loss: 2.557320045123428

Epoch: 5| Step: 4
Training loss: 1.6486598583507113
Validation loss: 2.554918592641229

Epoch: 5| Step: 5
Training loss: 3.3590621447707156
Validation loss: 2.553137434012135

Epoch: 5| Step: 6
Training loss: 2.223474764159798
Validation loss: 2.552529295345772

Epoch: 5| Step: 7
Training loss: 2.8891782697193937
Validation loss: 2.5544321043469354

Epoch: 5| Step: 8
Training loss: 3.0208670954078194
Validation loss: 2.549661727962503

Epoch: 5| Step: 9
Training loss: 3.0150465336335337
Validation loss: 2.5548047869242776

Epoch: 5| Step: 10
Training loss: 3.0383739328801944
Validation loss: 2.5607112561024112

Epoch: 151| Step: 0
Training loss: 2.459782986566786
Validation loss: 2.5658373406056896

Epoch: 5| Step: 1
Training loss: 2.8794221454633337
Validation loss: 2.5656222059212106

Epoch: 5| Step: 2
Training loss: 2.836342690686157
Validation loss: 2.563431979259008

Epoch: 5| Step: 3
Training loss: 2.942648899974808
Validation loss: 2.5711143782058956

Epoch: 5| Step: 4
Training loss: 3.2524642405204487
Validation loss: 2.58873370550489

Epoch: 5| Step: 5
Training loss: 2.8117584098526667
Validation loss: 2.579271143672946

Epoch: 5| Step: 6
Training loss: 2.8067312630795618
Validation loss: 2.5736407218997175

Epoch: 5| Step: 7
Training loss: 2.7249890353480937
Validation loss: 2.565891274823773

Epoch: 5| Step: 8
Training loss: 2.467588610232047
Validation loss: 2.5503311718709694

Epoch: 5| Step: 9
Training loss: 3.268020116597037
Validation loss: 2.5419285795791495

Epoch: 5| Step: 10
Training loss: 2.7900551277101355
Validation loss: 2.5515546457440426

Epoch: 152| Step: 0
Training loss: 3.184496792456697
Validation loss: 2.548800852275311

Epoch: 5| Step: 1
Training loss: 2.507425914213817
Validation loss: 2.5487608333108507

Epoch: 5| Step: 2
Training loss: 2.6257172467490646
Validation loss: 2.546998271202338

Epoch: 5| Step: 3
Training loss: 3.0179352286677052
Validation loss: 2.5487911490894914

Epoch: 5| Step: 4
Training loss: 2.6795704985674873
Validation loss: 2.5485374832199126

Epoch: 5| Step: 5
Training loss: 2.6308211314615497
Validation loss: 2.542465629726466

Epoch: 5| Step: 6
Training loss: 2.822646340427483
Validation loss: 2.5494427968362348

Epoch: 5| Step: 7
Training loss: 2.96872301591355
Validation loss: 2.55162337383348

Epoch: 5| Step: 8
Training loss: 2.8226472695569673
Validation loss: 2.5596970936570744

Epoch: 5| Step: 9
Training loss: 2.8973375068502243
Validation loss: 2.574685732600808

Epoch: 5| Step: 10
Training loss: 3.100831529397567
Validation loss: 2.5709167322812303

Epoch: 153| Step: 0
Training loss: 2.706921067410657
Validation loss: 2.570048327397193

Epoch: 5| Step: 1
Training loss: 2.982551217162999
Validation loss: 2.5595364785581807

Epoch: 5| Step: 2
Training loss: 2.839186475584097
Validation loss: 2.5577277990030116

Epoch: 5| Step: 3
Training loss: 2.346211780852609
Validation loss: 2.5515476025299426

Epoch: 5| Step: 4
Training loss: 2.971002788089149
Validation loss: 2.5459168599299926

Epoch: 5| Step: 5
Training loss: 3.0141280021293415
Validation loss: 2.547342019665399

Epoch: 5| Step: 6
Training loss: 2.9703852917994125
Validation loss: 2.54782360315015

Epoch: 5| Step: 7
Training loss: 3.0962466560009982
Validation loss: 2.548211053344362

Epoch: 5| Step: 8
Training loss: 2.2098918909065732
Validation loss: 2.5641472316965763

Epoch: 5| Step: 9
Training loss: 2.808942621923644
Validation loss: 2.558289393765508

Epoch: 5| Step: 10
Training loss: 3.1784598115087856
Validation loss: 2.5500993709677897

Epoch: 154| Step: 0
Training loss: 2.8303205703497305
Validation loss: 2.5445115440762445

Epoch: 5| Step: 1
Training loss: 2.5514546041574824
Validation loss: 2.538063148232372

Epoch: 5| Step: 2
Training loss: 2.4759254960049946
Validation loss: 2.535839594507133

Epoch: 5| Step: 3
Training loss: 2.573780815603298
Validation loss: 2.541392664779759

Epoch: 5| Step: 4
Training loss: 3.334267119903214
Validation loss: 2.5422386266901125

Epoch: 5| Step: 5
Training loss: 2.9166678474060577
Validation loss: 2.5480592039230308

Epoch: 5| Step: 6
Training loss: 3.023017321820592
Validation loss: 2.547783016418719

Epoch: 5| Step: 7
Training loss: 3.0900749187584498
Validation loss: 2.5423964211473944

Epoch: 5| Step: 8
Training loss: 2.2446873781506107
Validation loss: 2.5441393810981148

Epoch: 5| Step: 9
Training loss: 3.205739066477699
Validation loss: 2.5495312954276175

Epoch: 5| Step: 10
Training loss: 2.6749509539519756
Validation loss: 2.5426551702754114

Epoch: 155| Step: 0
Training loss: 2.8634567727365914
Validation loss: 2.54186006136718

Epoch: 5| Step: 1
Training loss: 3.057295600502997
Validation loss: 2.5372342068526024

Epoch: 5| Step: 2
Training loss: 3.0571655212754014
Validation loss: 2.537585898278602

Epoch: 5| Step: 3
Training loss: 2.6317258680890925
Validation loss: 2.538292980975292

Epoch: 5| Step: 4
Training loss: 2.9476089227043087
Validation loss: 2.5357914651229962

Epoch: 5| Step: 5
Training loss: 3.1149799685500024
Validation loss: 2.5358018084632157

Epoch: 5| Step: 6
Training loss: 2.4250923689721335
Validation loss: 2.5350808652988635

Epoch: 5| Step: 7
Training loss: 2.8519920548145112
Validation loss: 2.5327449411451877

Epoch: 5| Step: 8
Training loss: 2.779308112651868
Validation loss: 2.5330531783328376

Epoch: 5| Step: 9
Training loss: 2.2698663408362245
Validation loss: 2.5403362492566193

Epoch: 5| Step: 10
Training loss: 3.0415529377895867
Validation loss: 2.55132511537417

Epoch: 156| Step: 0
Training loss: 3.1176333765836826
Validation loss: 2.555733507632671

Epoch: 5| Step: 1
Training loss: 3.0410797563183953
Validation loss: 2.565265121061713

Epoch: 5| Step: 2
Training loss: 2.6647423019491243
Validation loss: 2.584828130537975

Epoch: 5| Step: 3
Training loss: 2.7093042736215898
Validation loss: 2.58043932561712

Epoch: 5| Step: 4
Training loss: 3.287554687509283
Validation loss: 2.554566861850662

Epoch: 5| Step: 5
Training loss: 2.621428739741503
Validation loss: 2.5409083792763716

Epoch: 5| Step: 6
Training loss: 2.4884860973985368
Validation loss: 2.53185529218243

Epoch: 5| Step: 7
Training loss: 3.239085282845059
Validation loss: 2.539009912796611

Epoch: 5| Step: 8
Training loss: 2.176625606720144
Validation loss: 2.5314938614999263

Epoch: 5| Step: 9
Training loss: 2.5693587646862244
Validation loss: 2.5361168249034938

Epoch: 5| Step: 10
Training loss: 3.0316212220339662
Validation loss: 2.531566602605095

Epoch: 157| Step: 0
Training loss: 2.4538442929962
Validation loss: 2.5290478843097284

Epoch: 5| Step: 1
Training loss: 3.035521025075721
Validation loss: 2.538220312444975

Epoch: 5| Step: 2
Training loss: 2.2363369737475045
Validation loss: 2.5403744905985164

Epoch: 5| Step: 3
Training loss: 2.509384850735646
Validation loss: 2.548616386849889

Epoch: 5| Step: 4
Training loss: 2.5614621921886176
Validation loss: 2.552333493222178

Epoch: 5| Step: 5
Training loss: 3.6136378096876967
Validation loss: 2.5554005711257726

Epoch: 5| Step: 6
Training loss: 3.3623462400768873
Validation loss: 2.5591179784183677

Epoch: 5| Step: 7
Training loss: 2.5503342428123092
Validation loss: 2.567196746350755

Epoch: 5| Step: 8
Training loss: 2.6854635107799756
Validation loss: 2.570197989455803

Epoch: 5| Step: 9
Training loss: 2.9455755708215006
Validation loss: 2.5519017757470444

Epoch: 5| Step: 10
Training loss: 2.878055441613313
Validation loss: 2.5422501811238076

Epoch: 158| Step: 0
Training loss: 2.4391927465624383
Validation loss: 2.5332160747162704

Epoch: 5| Step: 1
Training loss: 2.2669449742878576
Validation loss: 2.5328227709287736

Epoch: 5| Step: 2
Training loss: 2.9610929020585597
Validation loss: 2.5407464896609078

Epoch: 5| Step: 3
Training loss: 2.7795363729820965
Validation loss: 2.541628503605389

Epoch: 5| Step: 4
Training loss: 2.8319302244911895
Validation loss: 2.5351037046345737

Epoch: 5| Step: 5
Training loss: 3.4601815735025303
Validation loss: 2.5349666877825228

Epoch: 5| Step: 6
Training loss: 2.8601711811508483
Validation loss: 2.5258658367058553

Epoch: 5| Step: 7
Training loss: 2.977132747623568
Validation loss: 2.5454206256784873

Epoch: 5| Step: 8
Training loss: 2.9709326500540576
Validation loss: 2.5613381998281177

Epoch: 5| Step: 9
Training loss: 2.3589559018620783
Validation loss: 2.55485474261493

Epoch: 5| Step: 10
Training loss: 3.0201259091637467
Validation loss: 2.557870786805595

Epoch: 159| Step: 0
Training loss: 3.082125470131814
Validation loss: 2.5585142342289124

Epoch: 5| Step: 1
Training loss: 2.564278613367962
Validation loss: 2.5697277471274926

Epoch: 5| Step: 2
Training loss: 2.740997317001438
Validation loss: 2.5640990887579704

Epoch: 5| Step: 3
Training loss: 2.410623316587454
Validation loss: 2.5440242184856503

Epoch: 5| Step: 4
Training loss: 3.010660938177524
Validation loss: 2.5331246318676044

Epoch: 5| Step: 5
Training loss: 3.334939204266666
Validation loss: 2.5292467966370955

Epoch: 5| Step: 6
Training loss: 2.5147409722052085
Validation loss: 2.529823268781398

Epoch: 5| Step: 7
Training loss: 2.46537975643608
Validation loss: 2.535112616824306

Epoch: 5| Step: 8
Training loss: 2.5358789762746983
Validation loss: 2.523984621605055

Epoch: 5| Step: 9
Training loss: 3.1218105061296786
Validation loss: 2.530026104392058

Epoch: 5| Step: 10
Training loss: 3.04780008993103
Validation loss: 2.523551266568481

Epoch: 160| Step: 0
Training loss: 3.077947466227843
Validation loss: 2.5296749368211087

Epoch: 5| Step: 1
Training loss: 2.557117111764498
Validation loss: 2.523870497724542

Epoch: 5| Step: 2
Training loss: 2.7712450414741423
Validation loss: 2.5338747551309053

Epoch: 5| Step: 3
Training loss: 2.6337292260942573
Validation loss: 2.525081518435716

Epoch: 5| Step: 4
Training loss: 2.8585135407726794
Validation loss: 2.5285199086476298

Epoch: 5| Step: 5
Training loss: 2.9428214712533824
Validation loss: 2.5295408153358974

Epoch: 5| Step: 6
Training loss: 2.9582952219339416
Validation loss: 2.5273297680000177

Epoch: 5| Step: 7
Training loss: 2.3342965272431884
Validation loss: 2.5254133814292943

Epoch: 5| Step: 8
Training loss: 3.01778812603619
Validation loss: 2.524160394546189

Epoch: 5| Step: 9
Training loss: 2.978270353630846
Validation loss: 2.524171267974671

Epoch: 5| Step: 10
Training loss: 2.66839211987896
Validation loss: 2.5202804755135695

Epoch: 161| Step: 0
Training loss: 2.5245549706805344
Validation loss: 2.5236588486442746

Epoch: 5| Step: 1
Training loss: 2.3381584096977543
Validation loss: 2.5196603723972357

Epoch: 5| Step: 2
Training loss: 3.0006425487320594
Validation loss: 2.5427176308042974

Epoch: 5| Step: 3
Training loss: 2.785349621152512
Validation loss: 2.553383538486109

Epoch: 5| Step: 4
Training loss: 3.0858126458128647
Validation loss: 2.563561440527106

Epoch: 5| Step: 5
Training loss: 3.2875062427534
Validation loss: 2.558683683469175

Epoch: 5| Step: 6
Training loss: 2.8975572097567768
Validation loss: 2.5311398418261764

Epoch: 5| Step: 7
Training loss: 2.9642495827762643
Validation loss: 2.5184108386392023

Epoch: 5| Step: 8
Training loss: 2.7182908821494447
Validation loss: 2.5201187236185363

Epoch: 5| Step: 9
Training loss: 2.2452999403993172
Validation loss: 2.516139629077184

Epoch: 5| Step: 10
Training loss: 3.1112006114014514
Validation loss: 2.519127060754157

Epoch: 162| Step: 0
Training loss: 3.052552865185299
Validation loss: 2.5178232139486285

Epoch: 5| Step: 1
Training loss: 2.2415589837323644
Validation loss: 2.5160936548203368

Epoch: 5| Step: 2
Training loss: 2.9824861470849635
Validation loss: 2.520277320143242

Epoch: 5| Step: 3
Training loss: 3.050157861845471
Validation loss: 2.530109486342645

Epoch: 5| Step: 4
Training loss: 2.7415099434471384
Validation loss: 2.5416869881024504

Epoch: 5| Step: 5
Training loss: 2.9019747226069033
Validation loss: 2.5464037729722837

Epoch: 5| Step: 6
Training loss: 2.7963721819646823
Validation loss: 2.5482030209880677

Epoch: 5| Step: 7
Training loss: 2.5011104025101396
Validation loss: 2.5501778100867334

Epoch: 5| Step: 8
Training loss: 2.671939960604686
Validation loss: 2.549871589697667

Epoch: 5| Step: 9
Training loss: 2.954854468878455
Validation loss: 2.5300308121155437

Epoch: 5| Step: 10
Training loss: 2.985394688108529
Validation loss: 2.517878967775544

Epoch: 163| Step: 0
Training loss: 2.3481704732691795
Validation loss: 2.518755062603736

Epoch: 5| Step: 1
Training loss: 3.0645152098455166
Validation loss: 2.5167853216265867

Epoch: 5| Step: 2
Training loss: 3.004833142921063
Validation loss: 2.5174203778056987

Epoch: 5| Step: 3
Training loss: 3.0389328955935992
Validation loss: 2.5162997947403474

Epoch: 5| Step: 4
Training loss: 2.952943342162027
Validation loss: 2.511521556622251

Epoch: 5| Step: 5
Training loss: 2.4503173311212896
Validation loss: 2.512280583350066

Epoch: 5| Step: 6
Training loss: 2.420703038327516
Validation loss: 2.517512286188081

Epoch: 5| Step: 7
Training loss: 2.759170327636846
Validation loss: 2.515354521817996

Epoch: 5| Step: 8
Training loss: 3.0600554382687775
Validation loss: 2.5193967930398364

Epoch: 5| Step: 9
Training loss: 2.872738155787741
Validation loss: 2.5249932594335243

Epoch: 5| Step: 10
Training loss: 2.716719559776715
Validation loss: 2.5317588445606574

Epoch: 164| Step: 0
Training loss: 2.3605585224546646
Validation loss: 2.536875003765716

Epoch: 5| Step: 1
Training loss: 2.870418713161407
Validation loss: 2.5436262091092163

Epoch: 5| Step: 2
Training loss: 2.790067603820151
Validation loss: 2.5408421622632016

Epoch: 5| Step: 3
Training loss: 2.5906646026050764
Validation loss: 2.5409241248467835

Epoch: 5| Step: 4
Training loss: 2.765685689658963
Validation loss: 2.531568292750157

Epoch: 5| Step: 5
Training loss: 2.4778690201116076
Validation loss: 2.527937863821312

Epoch: 5| Step: 6
Training loss: 2.992617424339756
Validation loss: 2.510530223038848

Epoch: 5| Step: 7
Training loss: 2.7643492606523843
Validation loss: 2.5262769073027416

Epoch: 5| Step: 8
Training loss: 2.8618050343811983
Validation loss: 2.510296157261228

Epoch: 5| Step: 9
Training loss: 3.4824239289025773
Validation loss: 2.5088831651910692

Epoch: 5| Step: 10
Training loss: 2.7101147197357567
Validation loss: 2.5175496227236

Epoch: 165| Step: 0
Training loss: 2.9612122259794282
Validation loss: 2.5118909120488566

Epoch: 5| Step: 1
Training loss: 2.8677470729182093
Validation loss: 2.5111785748236097

Epoch: 5| Step: 2
Training loss: 2.758307480090666
Validation loss: 2.521460444375415

Epoch: 5| Step: 3
Training loss: 2.2440745424479527
Validation loss: 2.5283877081515045

Epoch: 5| Step: 4
Training loss: 3.4365066480212914
Validation loss: 2.548245391784458

Epoch: 5| Step: 5
Training loss: 2.814499208071718
Validation loss: 2.545796622849161

Epoch: 5| Step: 6
Training loss: 2.796788560607788
Validation loss: 2.538274517352195

Epoch: 5| Step: 7
Training loss: 2.904462531264609
Validation loss: 2.5273120834588956

Epoch: 5| Step: 8
Training loss: 2.8165615848449623
Validation loss: 2.5218788879781755

Epoch: 5| Step: 9
Training loss: 2.7504707280334837
Validation loss: 2.5084248049798017

Epoch: 5| Step: 10
Training loss: 2.1082160308934803
Validation loss: 2.510415989439947

Epoch: 166| Step: 0
Training loss: 3.048482148250687
Validation loss: 2.5080191641742635

Epoch: 5| Step: 1
Training loss: 2.2699373443291724
Validation loss: 2.511498279285923

Epoch: 5| Step: 2
Training loss: 3.086354983132883
Validation loss: 2.5079003291415893

Epoch: 5| Step: 3
Training loss: 2.8213870888776755
Validation loss: 2.516742257181841

Epoch: 5| Step: 4
Training loss: 3.1294498042907932
Validation loss: 2.5166714396924177

Epoch: 5| Step: 5
Training loss: 2.5909741726599886
Validation loss: 2.511389574004607

Epoch: 5| Step: 6
Training loss: 2.8664148937229137
Validation loss: 2.511115006173599

Epoch: 5| Step: 7
Training loss: 2.521179984562166
Validation loss: 2.513687069108323

Epoch: 5| Step: 8
Training loss: 2.4525855376310473
Validation loss: 2.5069708585055377

Epoch: 5| Step: 9
Training loss: 2.9059848459351416
Validation loss: 2.513050816517702

Epoch: 5| Step: 10
Training loss: 2.854362889433934
Validation loss: 2.5141187502439286

Epoch: 167| Step: 0
Training loss: 2.6889979601334866
Validation loss: 2.513125061563486

Epoch: 5| Step: 1
Training loss: 2.751237330808331
Validation loss: 2.5076298376740755

Epoch: 5| Step: 2
Training loss: 2.936827562350477
Validation loss: 2.5153571248446225

Epoch: 5| Step: 3
Training loss: 2.369455088653249
Validation loss: 2.5127246217738515

Epoch: 5| Step: 4
Training loss: 3.08528922309545
Validation loss: 2.507227989542315

Epoch: 5| Step: 5
Training loss: 2.5921125643742244
Validation loss: 2.5156466697717996

Epoch: 5| Step: 6
Training loss: 2.9982887791759687
Validation loss: 2.5226700722969007

Epoch: 5| Step: 7
Training loss: 2.8834150144734485
Validation loss: 2.526059952113541

Epoch: 5| Step: 8
Training loss: 2.9233236546575494
Validation loss: 2.5393823363842025

Epoch: 5| Step: 9
Training loss: 2.7683900276210607
Validation loss: 2.5337887855147097

Epoch: 5| Step: 10
Training loss: 2.5288686028884633
Validation loss: 2.520033519221311

Epoch: 168| Step: 0
Training loss: 2.7341208203568543
Validation loss: 2.509495451047187

Epoch: 5| Step: 1
Training loss: 3.099432302607964
Validation loss: 2.5214554837522996

Epoch: 5| Step: 2
Training loss: 2.5233588900294435
Validation loss: 2.513507108181054

Epoch: 5| Step: 3
Training loss: 2.8357459810180217
Validation loss: 2.505653965087767

Epoch: 5| Step: 4
Training loss: 2.9828616794150795
Validation loss: 2.5093020704733853

Epoch: 5| Step: 5
Training loss: 2.4214264485076202
Validation loss: 2.5150797589412885

Epoch: 5| Step: 6
Training loss: 2.9495558388173073
Validation loss: 2.5186028185132967

Epoch: 5| Step: 7
Training loss: 2.5918857355127733
Validation loss: 2.5106450355142034

Epoch: 5| Step: 8
Training loss: 3.2169424370337243
Validation loss: 2.5147729081624797

Epoch: 5| Step: 9
Training loss: 2.8103579523293734
Validation loss: 2.5330125583637124

Epoch: 5| Step: 10
Training loss: 2.2825781731312245
Validation loss: 2.5407409118431104

Epoch: 169| Step: 0
Training loss: 2.6552298887048065
Validation loss: 2.5373237981095857

Epoch: 5| Step: 1
Training loss: 2.331531771488165
Validation loss: 2.526495224871829

Epoch: 5| Step: 2
Training loss: 2.713713793625064
Validation loss: 2.5265388232114154

Epoch: 5| Step: 3
Training loss: 2.67591222734867
Validation loss: 2.512066164713974

Epoch: 5| Step: 4
Training loss: 2.9457377726276737
Validation loss: 2.510823101818184

Epoch: 5| Step: 5
Training loss: 2.791363960669639
Validation loss: 2.503607258890052

Epoch: 5| Step: 6
Training loss: 2.9234247840429455
Validation loss: 2.5032002341853734

Epoch: 5| Step: 7
Training loss: 2.5003878292621753
Validation loss: 2.4977880680563342

Epoch: 5| Step: 8
Training loss: 3.238433208512427
Validation loss: 2.495607853537566

Epoch: 5| Step: 9
Training loss: 2.91247187916028
Validation loss: 2.489879452729124

Epoch: 5| Step: 10
Training loss: 2.795332669845831
Validation loss: 2.496887625128798

Epoch: 170| Step: 0
Training loss: 2.8006809700819546
Validation loss: 2.4866569937021046

Epoch: 5| Step: 1
Training loss: 2.900335877797695
Validation loss: 2.498107713913244

Epoch: 5| Step: 2
Training loss: 2.909746753120856
Validation loss: 2.495613190152789

Epoch: 5| Step: 3
Training loss: 2.4616199334352555
Validation loss: 2.5172998326450147

Epoch: 5| Step: 4
Training loss: 2.7103084307050334
Validation loss: 2.524396444869994

Epoch: 5| Step: 5
Training loss: 2.460691118773939
Validation loss: 2.532856338225953

Epoch: 5| Step: 6
Training loss: 3.0221158867560654
Validation loss: 2.533266854857681

Epoch: 5| Step: 7
Training loss: 3.1721452870330356
Validation loss: 2.523015126524745

Epoch: 5| Step: 8
Training loss: 1.9624652762287138
Validation loss: 2.500981691874172

Epoch: 5| Step: 9
Training loss: 2.899010285489856
Validation loss: 2.4984473934489593

Epoch: 5| Step: 10
Training loss: 3.0996990611532524
Validation loss: 2.4789812496590273

Epoch: 171| Step: 0
Training loss: 2.337344967193868
Validation loss: 2.4974418811341823

Epoch: 5| Step: 1
Training loss: 2.4651169905069388
Validation loss: 2.492155626429872

Epoch: 5| Step: 2
Training loss: 3.3334647311697534
Validation loss: 2.505832573794174

Epoch: 5| Step: 3
Training loss: 2.2974490531776808
Validation loss: 2.4878670128433362

Epoch: 5| Step: 4
Training loss: 2.5422394112396374
Validation loss: 2.4967368867153814

Epoch: 5| Step: 5
Training loss: 3.2074322281394987
Validation loss: 2.5074871931878846

Epoch: 5| Step: 6
Training loss: 2.8164114138573066
Validation loss: 2.5038212674462783

Epoch: 5| Step: 7
Training loss: 3.0081989783157046
Validation loss: 2.5085539206282115

Epoch: 5| Step: 8
Training loss: 2.7838679647267286
Validation loss: 2.5138350380727053

Epoch: 5| Step: 9
Training loss: 2.5680600764297443
Validation loss: 2.495707177427767

Epoch: 5| Step: 10
Training loss: 2.9964629620943297
Validation loss: 2.491906792319238

Epoch: 172| Step: 0
Training loss: 2.591497063274659
Validation loss: 2.488532164466113

Epoch: 5| Step: 1
Training loss: 2.640271586406935
Validation loss: 2.482415194341183

Epoch: 5| Step: 2
Training loss: 2.8065454815989
Validation loss: 2.4918255152990594

Epoch: 5| Step: 3
Training loss: 2.6519959436618628
Validation loss: 2.4844299524965088

Epoch: 5| Step: 4
Training loss: 3.3855582496185264
Validation loss: 2.4816737349947458

Epoch: 5| Step: 5
Training loss: 2.9912957438802263
Validation loss: 2.480079687158472

Epoch: 5| Step: 6
Training loss: 2.8814192715982507
Validation loss: 2.490784218020661

Epoch: 5| Step: 7
Training loss: 3.0443134201547446
Validation loss: 2.494214161511927

Epoch: 5| Step: 8
Training loss: 2.1061504442361434
Validation loss: 2.4919665687407133

Epoch: 5| Step: 9
Training loss: 2.8082476364176054
Validation loss: 2.5069067720611433

Epoch: 5| Step: 10
Training loss: 2.2830840798466916
Validation loss: 2.5304270634231822

Epoch: 173| Step: 0
Training loss: 2.2051668917930907
Validation loss: 2.539034398430615

Epoch: 5| Step: 1
Training loss: 3.0809633752316894
Validation loss: 2.542974600166069

Epoch: 5| Step: 2
Training loss: 3.0193919634554724
Validation loss: 2.5315463319157923

Epoch: 5| Step: 3
Training loss: 2.8221919594624825
Validation loss: 2.545993969871289

Epoch: 5| Step: 4
Training loss: 2.677086282176807
Validation loss: 2.5162264523316376

Epoch: 5| Step: 5
Training loss: 2.3854963353164274
Validation loss: 2.5154442360130744

Epoch: 5| Step: 6
Training loss: 3.3012333848066415
Validation loss: 2.5016433073019555

Epoch: 5| Step: 7
Training loss: 2.872395870223727
Validation loss: 2.4863622870066795

Epoch: 5| Step: 8
Training loss: 2.9422275566822313
Validation loss: 2.48372622430301

Epoch: 5| Step: 9
Training loss: 2.475363745113792
Validation loss: 2.485461777915637

Epoch: 5| Step: 10
Training loss: 2.781578644612543
Validation loss: 2.483313481976298

Epoch: 174| Step: 0
Training loss: 2.4526741925672177
Validation loss: 2.4940174302439226

Epoch: 5| Step: 1
Training loss: 2.6950716215110986
Validation loss: 2.4894724964648964

Epoch: 5| Step: 2
Training loss: 2.74499958754017
Validation loss: 2.489060517486501

Epoch: 5| Step: 3
Training loss: 2.5474670283736027
Validation loss: 2.489663697943905

Epoch: 5| Step: 4
Training loss: 2.8902663549681944
Validation loss: 2.4895699912106863

Epoch: 5| Step: 5
Training loss: 2.838607330029407
Validation loss: 2.4882077133005045

Epoch: 5| Step: 6
Training loss: 2.7282105632355163
Validation loss: 2.48900622238635

Epoch: 5| Step: 7
Training loss: 3.025429397245906
Validation loss: 2.4971674469604603

Epoch: 5| Step: 8
Training loss: 2.929805010664139
Validation loss: 2.4945037402991788

Epoch: 5| Step: 9
Training loss: 2.866670567118039
Validation loss: 2.490553179703687

Epoch: 5| Step: 10
Training loss: 2.6991116051172583
Validation loss: 2.4972429577847706

Epoch: 175| Step: 0
Training loss: 2.8638520758164523
Validation loss: 2.509784202336152

Epoch: 5| Step: 1
Training loss: 2.9970149448087073
Validation loss: 2.4909306101775814

Epoch: 5| Step: 2
Training loss: 2.796779353887878
Validation loss: 2.4893983410169853

Epoch: 5| Step: 3
Training loss: 3.1211991656360834
Validation loss: 2.4856539778970212

Epoch: 5| Step: 4
Training loss: 3.082019646336284
Validation loss: 2.480535897581557

Epoch: 5| Step: 5
Training loss: 2.274942640482738
Validation loss: 2.4854205750942655

Epoch: 5| Step: 6
Training loss: 2.6221443265275513
Validation loss: 2.4812375425711712

Epoch: 5| Step: 7
Training loss: 2.484953039328111
Validation loss: 2.4743480637480806

Epoch: 5| Step: 8
Training loss: 3.019249985637003
Validation loss: 2.4899715437212135

Epoch: 5| Step: 9
Training loss: 2.9658474837720616
Validation loss: 2.482191476382724

Epoch: 5| Step: 10
Training loss: 1.6630291663093602
Validation loss: 2.4822098758853754

Epoch: 176| Step: 0
Training loss: 2.4942079204899428
Validation loss: 2.477895910646041

Epoch: 5| Step: 1
Training loss: 2.877850984831139
Validation loss: 2.4853909345508014

Epoch: 5| Step: 2
Training loss: 2.8999779404426014
Validation loss: 2.4871502193432296

Epoch: 5| Step: 3
Training loss: 2.472582100333456
Validation loss: 2.49430514791873

Epoch: 5| Step: 4
Training loss: 3.1124577408338516
Validation loss: 2.4924758835318648

Epoch: 5| Step: 5
Training loss: 2.7233681753661974
Validation loss: 2.5090365518276436

Epoch: 5| Step: 6
Training loss: 2.8075520542716688
Validation loss: 2.5117911329636344

Epoch: 5| Step: 7
Training loss: 2.9540549131130756
Validation loss: 2.517567571354426

Epoch: 5| Step: 8
Training loss: 2.86741400299559
Validation loss: 2.539339492619589

Epoch: 5| Step: 9
Training loss: 2.694717828136892
Validation loss: 2.5526301203592303

Epoch: 5| Step: 10
Training loss: 2.6617928510584368
Validation loss: 2.5402643668124028

Epoch: 177| Step: 0
Training loss: 2.333226190105262
Validation loss: 2.538154823236348

Epoch: 5| Step: 1
Training loss: 2.4422414586994323
Validation loss: 2.5672513080857486

Epoch: 5| Step: 2
Training loss: 2.789528003815309
Validation loss: 2.575707393338581

Epoch: 5| Step: 3
Training loss: 2.5265354473527055
Validation loss: 2.5390248346177544

Epoch: 5| Step: 4
Training loss: 3.0110766645418603
Validation loss: 2.517373294501454

Epoch: 5| Step: 5
Training loss: 2.6682120752590768
Validation loss: 2.5118597130756455

Epoch: 5| Step: 6
Training loss: 2.881799866344908
Validation loss: 2.508496381601746

Epoch: 5| Step: 7
Training loss: 2.676072509952174
Validation loss: 2.505751099314662

Epoch: 5| Step: 8
Training loss: 3.1138984326879835
Validation loss: 2.515208844856716

Epoch: 5| Step: 9
Training loss: 2.7264002011151307
Validation loss: 2.5134676114954706

Epoch: 5| Step: 10
Training loss: 3.54846733749255
Validation loss: 2.5471122425356794

Epoch: 178| Step: 0
Training loss: 2.6753537024413245
Validation loss: 2.525016236717534

Epoch: 5| Step: 1
Training loss: 2.5398742317240974
Validation loss: 2.531837344596143

Epoch: 5| Step: 2
Training loss: 3.009387270386459
Validation loss: 2.503172561627697

Epoch: 5| Step: 3
Training loss: 2.942774643052451
Validation loss: 2.500821470842559

Epoch: 5| Step: 4
Training loss: 2.6427253631375893
Validation loss: 2.4930924302708077

Epoch: 5| Step: 5
Training loss: 2.5523049913539686
Validation loss: 2.4843958567897446

Epoch: 5| Step: 6
Training loss: 2.7410098424412603
Validation loss: 2.5043543457421698

Epoch: 5| Step: 7
Training loss: 2.840975235602493
Validation loss: 2.5085348967790564

Epoch: 5| Step: 8
Training loss: 3.037583802876403
Validation loss: 2.509945356770017

Epoch: 5| Step: 9
Training loss: 2.789056601638327
Validation loss: 2.511113807616457

Epoch: 5| Step: 10
Training loss: 2.6511074774966725
Validation loss: 2.520450585018501

Epoch: 179| Step: 0
Training loss: 2.67564581089708
Validation loss: 2.516447779187682

Epoch: 5| Step: 1
Training loss: 2.825023826566159
Validation loss: 2.526120075767619

Epoch: 5| Step: 2
Training loss: 2.6867555873660476
Validation loss: 2.53038254324985

Epoch: 5| Step: 3
Training loss: 2.5357866487980916
Validation loss: 2.5244378716968168

Epoch: 5| Step: 4
Training loss: 2.8359896232081554
Validation loss: 2.5244742923770596

Epoch: 5| Step: 5
Training loss: 3.0009506626668725
Validation loss: 2.5038501184871156

Epoch: 5| Step: 6
Training loss: 2.7664391994803332
Validation loss: 2.497218043386773

Epoch: 5| Step: 7
Training loss: 3.230233309560146
Validation loss: 2.484119677940122

Epoch: 5| Step: 8
Training loss: 2.52080292065983
Validation loss: 2.4765465926315535

Epoch: 5| Step: 9
Training loss: 2.4513992751216387
Validation loss: 2.4855332979388733

Epoch: 5| Step: 10
Training loss: 2.997110087508957
Validation loss: 2.4925781853118045

Epoch: 180| Step: 0
Training loss: 2.7995059463048113
Validation loss: 2.480441042953904

Epoch: 5| Step: 1
Training loss: 2.4523343312403747
Validation loss: 2.5054720570792086

Epoch: 5| Step: 2
Training loss: 2.4582435031146668
Validation loss: 2.497621158187556

Epoch: 5| Step: 3
Training loss: 2.947744645310635
Validation loss: 2.4752873317423827

Epoch: 5| Step: 4
Training loss: 2.5838465232149113
Validation loss: 2.476665457032101

Epoch: 5| Step: 5
Training loss: 2.4537412999096553
Validation loss: 2.4743598916925698

Epoch: 5| Step: 6
Training loss: 2.725950768169634
Validation loss: 2.4720830840950114

Epoch: 5| Step: 7
Training loss: 2.4610488139817597
Validation loss: 2.477149295279657

Epoch: 5| Step: 8
Training loss: 3.1248588530135764
Validation loss: 2.486603201819702

Epoch: 5| Step: 9
Training loss: 3.116487735229036
Validation loss: 2.4918973043155757

Epoch: 5| Step: 10
Training loss: 3.095372554806894
Validation loss: 2.49113523457228

Epoch: 181| Step: 0
Training loss: 2.8236030128997927
Validation loss: 2.4936389104818564

Epoch: 5| Step: 1
Training loss: 2.7515928683752358
Validation loss: 2.4904384471994003

Epoch: 5| Step: 2
Training loss: 2.9354939205345185
Validation loss: 2.490671102892487

Epoch: 5| Step: 3
Training loss: 2.463122654148815
Validation loss: 2.48550215180964

Epoch: 5| Step: 4
Training loss: 2.100969762774276
Validation loss: 2.492700973993606

Epoch: 5| Step: 5
Training loss: 2.603487327977084
Validation loss: 2.5004094752429262

Epoch: 5| Step: 6
Training loss: 2.6718641135903036
Validation loss: 2.4990970365252134

Epoch: 5| Step: 7
Training loss: 2.486069491255291
Validation loss: 2.4968792202661394

Epoch: 5| Step: 8
Training loss: 3.4846128374020138
Validation loss: 2.4823410408158813

Epoch: 5| Step: 9
Training loss: 2.509862709394146
Validation loss: 2.4954028962778736

Epoch: 5| Step: 10
Training loss: 3.169144982394083
Validation loss: 2.498386867564519

Epoch: 182| Step: 0
Training loss: 2.6227308183738933
Validation loss: 2.508245138007058

Epoch: 5| Step: 1
Training loss: 2.6503042658185523
Validation loss: 2.4948666373106017

Epoch: 5| Step: 2
Training loss: 2.694618378975581
Validation loss: 2.4896379003947615

Epoch: 5| Step: 3
Training loss: 2.6296343085745355
Validation loss: 2.488472552280143

Epoch: 5| Step: 4
Training loss: 2.0238070942092117
Validation loss: 2.4916463614114632

Epoch: 5| Step: 5
Training loss: 2.950390230651288
Validation loss: 2.493910980066032

Epoch: 5| Step: 6
Training loss: 2.8499130704237574
Validation loss: 2.502862921509382

Epoch: 5| Step: 7
Training loss: 2.6089344680703084
Validation loss: 2.501812691989365

Epoch: 5| Step: 8
Training loss: 3.035513013690869
Validation loss: 2.499050217352964

Epoch: 5| Step: 9
Training loss: 3.096619325432667
Validation loss: 2.495102500900398

Epoch: 5| Step: 10
Training loss: 2.9106190972640014
Validation loss: 2.4860199064282864

Epoch: 183| Step: 0
Training loss: 2.3418677337590768
Validation loss: 2.479142498009886

Epoch: 5| Step: 1
Training loss: 3.0224134500005357
Validation loss: 2.47590013308551

Epoch: 5| Step: 2
Training loss: 2.416228177859639
Validation loss: 2.476137366410447

Epoch: 5| Step: 3
Training loss: 2.1579247204481193
Validation loss: 2.4745481002922203

Epoch: 5| Step: 4
Training loss: 2.9662080824663617
Validation loss: 2.4806799037396186

Epoch: 5| Step: 5
Training loss: 2.7148541127837293
Validation loss: 2.4948523900645276

Epoch: 5| Step: 6
Training loss: 3.094594666742031
Validation loss: 2.504762436699038

Epoch: 5| Step: 7
Training loss: 3.0960733956402593
Validation loss: 2.506929418122849

Epoch: 5| Step: 8
Training loss: 2.7915370019055477
Validation loss: 2.5078188656154423

Epoch: 5| Step: 9
Training loss: 2.789453644666315
Validation loss: 2.515404971540995

Epoch: 5| Step: 10
Training loss: 2.4865201889375235
Validation loss: 2.534357479492067

Epoch: 184| Step: 0
Training loss: 2.8484555392967934
Validation loss: 2.5163324872399153

Epoch: 5| Step: 1
Training loss: 1.9375781381909374
Validation loss: 2.5096461821206235

Epoch: 5| Step: 2
Training loss: 2.503997848668256
Validation loss: 2.5020794229283156

Epoch: 5| Step: 3
Training loss: 3.0729672357741
Validation loss: 2.4859368132239434

Epoch: 5| Step: 4
Training loss: 2.6138405422325413
Validation loss: 2.4624673599171274

Epoch: 5| Step: 5
Training loss: 2.2956559455960592
Validation loss: 2.466014929058007

Epoch: 5| Step: 6
Training loss: 3.287969339612957
Validation loss: 2.4565922912535028

Epoch: 5| Step: 7
Training loss: 2.949322548359656
Validation loss: 2.459019828065858

Epoch: 5| Step: 8
Training loss: 3.098022593209596
Validation loss: 2.4653719803785146

Epoch: 5| Step: 9
Training loss: 2.4127070007065807
Validation loss: 2.4651650131212066

Epoch: 5| Step: 10
Training loss: 2.9911406356515724
Validation loss: 2.462603108602472

Epoch: 185| Step: 0
Training loss: 2.762136727177274
Validation loss: 2.490482934606718

Epoch: 5| Step: 1
Training loss: 2.6676498825738157
Validation loss: 2.5162765840202064

Epoch: 5| Step: 2
Training loss: 2.3285041858716564
Validation loss: 2.5166164180343844

Epoch: 5| Step: 3
Training loss: 2.6661980535111933
Validation loss: 2.5304234658113405

Epoch: 5| Step: 4
Training loss: 2.4327581204784634
Validation loss: 2.4905488379190124

Epoch: 5| Step: 5
Training loss: 2.9505043309898635
Validation loss: 2.475824566715697

Epoch: 5| Step: 6
Training loss: 2.982619003646065
Validation loss: 2.474966267479866

Epoch: 5| Step: 7
Training loss: 3.001391247178571
Validation loss: 2.4896597129489804

Epoch: 5| Step: 8
Training loss: 2.9829543961694194
Validation loss: 2.492686940631681

Epoch: 5| Step: 9
Training loss: 2.495352239417732
Validation loss: 2.500857005841949

Epoch: 5| Step: 10
Training loss: 2.929410143121153
Validation loss: 2.5075591728036764

Epoch: 186| Step: 0
Training loss: 2.860086321295004
Validation loss: 2.5036487225182906

Epoch: 5| Step: 1
Training loss: 3.088268626057237
Validation loss: 2.4810999461161907

Epoch: 5| Step: 2
Training loss: 2.364134780978927
Validation loss: 2.487056256073226

Epoch: 5| Step: 3
Training loss: 2.922002779364651
Validation loss: 2.507993689338459

Epoch: 5| Step: 4
Training loss: 2.627933135042796
Validation loss: 2.5312505534931176

Epoch: 5| Step: 5
Training loss: 3.178878793811143
Validation loss: 2.538605644326114

Epoch: 5| Step: 6
Training loss: 2.6416788199192314
Validation loss: 2.5148394405289825

Epoch: 5| Step: 7
Training loss: 2.8941269565197207
Validation loss: 2.496572034232852

Epoch: 5| Step: 8
Training loss: 2.674034004839749
Validation loss: 2.4708524852818967

Epoch: 5| Step: 9
Training loss: 2.6250572198353446
Validation loss: 2.465304315788048

Epoch: 5| Step: 10
Training loss: 2.4498592920185636
Validation loss: 2.4679482060011546

Epoch: 187| Step: 0
Training loss: 2.918303076040583
Validation loss: 2.464029829134704

Epoch: 5| Step: 1
Training loss: 2.7165148086074002
Validation loss: 2.4618741650378144

Epoch: 5| Step: 2
Training loss: 2.8943777107978965
Validation loss: 2.457302184537258

Epoch: 5| Step: 3
Training loss: 2.786816288187811
Validation loss: 2.4598383258629712

Epoch: 5| Step: 4
Training loss: 2.5607189408720017
Validation loss: 2.4749103787212663

Epoch: 5| Step: 5
Training loss: 3.105953615351938
Validation loss: 2.496648399934281

Epoch: 5| Step: 6
Training loss: 2.4837013146937723
Validation loss: 2.503689022258246

Epoch: 5| Step: 7
Training loss: 2.4466613364443117
Validation loss: 2.507891970386591

Epoch: 5| Step: 8
Training loss: 2.8247868347764347
Validation loss: 2.4904794012748486

Epoch: 5| Step: 9
Training loss: 2.638945276650643
Validation loss: 2.4915729476956954

Epoch: 5| Step: 10
Training loss: 2.702563541734595
Validation loss: 2.4633041135836202

Epoch: 188| Step: 0
Training loss: 3.0716434923175058
Validation loss: 2.4618551793085848

Epoch: 5| Step: 1
Training loss: 2.6968768459061794
Validation loss: 2.4578689312437705

Epoch: 5| Step: 2
Training loss: 2.609168312886914
Validation loss: 2.4657059783241606

Epoch: 5| Step: 3
Training loss: 2.5721032302097573
Validation loss: 2.467770579628461

Epoch: 5| Step: 4
Training loss: 2.358428563148688
Validation loss: 2.4599691527302

Epoch: 5| Step: 5
Training loss: 3.2291496194368996
Validation loss: 2.451715516293125

Epoch: 5| Step: 6
Training loss: 2.621667836021879
Validation loss: 2.4509682879037458

Epoch: 5| Step: 7
Training loss: 2.5631165111729532
Validation loss: 2.4572792949887674

Epoch: 5| Step: 8
Training loss: 3.0991361337299503
Validation loss: 2.4663641623852324

Epoch: 5| Step: 9
Training loss: 2.707709949838578
Validation loss: 2.498833162510539

Epoch: 5| Step: 10
Training loss: 2.5998543295033762
Validation loss: 2.5207902397337545

Epoch: 189| Step: 0
Training loss: 2.7656968964105486
Validation loss: 2.5044058431445557

Epoch: 5| Step: 1
Training loss: 3.105491167863267
Validation loss: 2.5259235885182694

Epoch: 5| Step: 2
Training loss: 2.8088737846909346
Validation loss: 2.56128784110575

Epoch: 5| Step: 3
Training loss: 2.942688600367098
Validation loss: 2.546391932333366

Epoch: 5| Step: 4
Training loss: 2.574652905820359
Validation loss: 2.5103298919948176

Epoch: 5| Step: 5
Training loss: 2.974638549902068
Validation loss: 2.4625207222911514

Epoch: 5| Step: 6
Training loss: 2.987316020583684
Validation loss: 2.4594012023811698

Epoch: 5| Step: 7
Training loss: 2.438908585671861
Validation loss: 2.4854247422358706

Epoch: 5| Step: 8
Training loss: 2.5464266516973084
Validation loss: 2.5217339620357984

Epoch: 5| Step: 9
Training loss: 2.6191524587843213
Validation loss: 2.497260887086695

Epoch: 5| Step: 10
Training loss: 2.718282374362984
Validation loss: 2.497034356576652

Epoch: 190| Step: 0
Training loss: 2.8910965818345824
Validation loss: 2.484583649787015

Epoch: 5| Step: 1
Training loss: 2.7960474931888193
Validation loss: 2.488177051932756

Epoch: 5| Step: 2
Training loss: 2.530923893019761
Validation loss: 2.4827511805882096

Epoch: 5| Step: 3
Training loss: 2.9593730406870495
Validation loss: 2.4708081253388063

Epoch: 5| Step: 4
Training loss: 2.3289402296062933
Validation loss: 2.483021173336454

Epoch: 5| Step: 5
Training loss: 3.1289115839042396
Validation loss: 2.507107993227536

Epoch: 5| Step: 6
Training loss: 3.0750937470823105
Validation loss: 2.5620851043282586

Epoch: 5| Step: 7
Training loss: 3.01373310731499
Validation loss: 2.562876089746407

Epoch: 5| Step: 8
Training loss: 2.2366444193287416
Validation loss: 2.570445415641972

Epoch: 5| Step: 9
Training loss: 2.7960167958706057
Validation loss: 2.5524687612640626

Epoch: 5| Step: 10
Training loss: 2.6682798949813016
Validation loss: 2.5444427689752493

Epoch: 191| Step: 0
Training loss: 2.5725279191321433
Validation loss: 2.5172511644484827

Epoch: 5| Step: 1
Training loss: 2.56654940457024
Validation loss: 2.5092120426761424

Epoch: 5| Step: 2
Training loss: 3.101399684062855
Validation loss: 2.4975550478460584

Epoch: 5| Step: 3
Training loss: 2.4462649894336983
Validation loss: 2.5191671312010886

Epoch: 5| Step: 4
Training loss: 2.584048777128746
Validation loss: 2.539811840563421

Epoch: 5| Step: 5
Training loss: 2.55748994036623
Validation loss: 2.5587998704908475

Epoch: 5| Step: 6
Training loss: 2.931852878152876
Validation loss: 2.5990326389274174

Epoch: 5| Step: 7
Training loss: 2.6247701998441206
Validation loss: 2.578781433163623

Epoch: 5| Step: 8
Training loss: 2.8105825881862767
Validation loss: 2.574341815253349

Epoch: 5| Step: 9
Training loss: 3.1329974264992115
Validation loss: 2.515238353151751

Epoch: 5| Step: 10
Training loss: 3.1509990258392406
Validation loss: 2.5125961387761166

Epoch: 192| Step: 0
Training loss: 2.8882259826903094
Validation loss: 2.561950986942137

Epoch: 5| Step: 1
Training loss: 3.034039501810641
Validation loss: 2.5376304476547857

Epoch: 5| Step: 2
Training loss: 2.00894311324412
Validation loss: 2.5323537255637203

Epoch: 5| Step: 3
Training loss: 2.6063414889224825
Validation loss: 2.5373406854091187

Epoch: 5| Step: 4
Training loss: 2.5253020681858036
Validation loss: 2.519753291781879

Epoch: 5| Step: 5
Training loss: 2.992974957066619
Validation loss: 2.5161258436129685

Epoch: 5| Step: 6
Training loss: 2.674130029123246
Validation loss: 2.5060786712851786

Epoch: 5| Step: 7
Training loss: 2.6116706663424454
Validation loss: 2.492249695749553

Epoch: 5| Step: 8
Training loss: 3.0556603172915686
Validation loss: 2.4790878931403024

Epoch: 5| Step: 9
Training loss: 2.358927299009904
Validation loss: 2.479281962495319

Epoch: 5| Step: 10
Training loss: 3.196734347563401
Validation loss: 2.496359224998263

Epoch: 193| Step: 0
Training loss: 2.478774181253789
Validation loss: 2.5759315594143755

Epoch: 5| Step: 1
Training loss: 3.05876632729722
Validation loss: 2.5800209469750546

Epoch: 5| Step: 2
Training loss: 2.575220587457735
Validation loss: 2.512498822265767

Epoch: 5| Step: 3
Training loss: 2.76795800724039
Validation loss: 2.5106803651043377

Epoch: 5| Step: 4
Training loss: 2.7326387833290022
Validation loss: 2.50618053236999

Epoch: 5| Step: 5
Training loss: 2.9537228579571666
Validation loss: 2.517472423619092

Epoch: 5| Step: 6
Training loss: 2.747032905700924
Validation loss: 2.5334552925245317

Epoch: 5| Step: 7
Training loss: 2.438481646720771
Validation loss: 2.545357733426509

Epoch: 5| Step: 8
Training loss: 2.9460516288050624
Validation loss: 2.5508876484937315

Epoch: 5| Step: 9
Training loss: 3.2348959682900436
Validation loss: 2.578971001568533

Epoch: 5| Step: 10
Training loss: 2.5076193096342956
Validation loss: 2.56857838851972

Epoch: 194| Step: 0
Training loss: 2.7318668742551027
Validation loss: 2.5888608221281713

Epoch: 5| Step: 1
Training loss: 2.89063786684214
Validation loss: 2.6184047825716825

Epoch: 5| Step: 2
Training loss: 2.838216911193602
Validation loss: 2.63304532341254

Epoch: 5| Step: 3
Training loss: 2.8949163801012148
Validation loss: 2.6115176299253133

Epoch: 5| Step: 4
Training loss: 2.696101153442865
Validation loss: 2.575773638673605

Epoch: 5| Step: 5
Training loss: 2.8584973598679553
Validation loss: 2.526612917455853

Epoch: 5| Step: 6
Training loss: 2.809700908151582
Validation loss: 2.531542703488825

Epoch: 5| Step: 7
Training loss: 2.640735511047375
Validation loss: 2.5167850598419714

Epoch: 5| Step: 8
Training loss: 2.334453200494774
Validation loss: 2.5072142859597792

Epoch: 5| Step: 9
Training loss: 3.103886653551199
Validation loss: 2.51570136106518

Epoch: 5| Step: 10
Training loss: 3.023046345013844
Validation loss: 2.507470458581997

Epoch: 195| Step: 0
Training loss: 2.824286115800559
Validation loss: 2.4691350160798415

Epoch: 5| Step: 1
Training loss: 2.799033924743542
Validation loss: 2.4532149061766493

Epoch: 5| Step: 2
Training loss: 2.691033280749799
Validation loss: 2.461636984426908

Epoch: 5| Step: 3
Training loss: 2.46227119273542
Validation loss: 2.459940538432236

Epoch: 5| Step: 4
Training loss: 2.037426054379149
Validation loss: 2.451062972035446

Epoch: 5| Step: 5
Training loss: 3.064104088282669
Validation loss: 2.458119047436009

Epoch: 5| Step: 6
Training loss: 2.5175167576403537
Validation loss: 2.4498406003639572

Epoch: 5| Step: 7
Training loss: 2.676216034475467
Validation loss: 2.446628179262825

Epoch: 5| Step: 8
Training loss: 2.901203162436903
Validation loss: 2.443337817470068

Epoch: 5| Step: 9
Training loss: 2.9747464304337634
Validation loss: 2.4596481453632717

Epoch: 5| Step: 10
Training loss: 2.870403263856102
Validation loss: 2.475723752395591

Epoch: 196| Step: 0
Training loss: 2.7115903392601086
Validation loss: 2.4723215464190615

Epoch: 5| Step: 1
Training loss: 2.306951413063376
Validation loss: 2.4861461878074333

Epoch: 5| Step: 2
Training loss: 3.067347679677819
Validation loss: 2.4609069113939053

Epoch: 5| Step: 3
Training loss: 2.356853931851782
Validation loss: 2.483117277755316

Epoch: 5| Step: 4
Training loss: 2.7608788061460725
Validation loss: 2.4743920406012996

Epoch: 5| Step: 5
Training loss: 2.5833224532195644
Validation loss: 2.4741080435168405

Epoch: 5| Step: 6
Training loss: 2.9598438185650693
Validation loss: 2.4570810264792162

Epoch: 5| Step: 7
Training loss: 2.191174935220993
Validation loss: 2.4700561698461025

Epoch: 5| Step: 8
Training loss: 3.0164268890125303
Validation loss: 2.4570621456125767

Epoch: 5| Step: 9
Training loss: 3.2437159600796264
Validation loss: 2.445023464920127

Epoch: 5| Step: 10
Training loss: 2.523096776109424
Validation loss: 2.4526838960618087

Epoch: 197| Step: 0
Training loss: 2.442493605512606
Validation loss: 2.4543557362182624

Epoch: 5| Step: 1
Training loss: 2.332629869776815
Validation loss: 2.4649784328325333

Epoch: 5| Step: 2
Training loss: 2.74941455504764
Validation loss: 2.48624189508742

Epoch: 5| Step: 3
Training loss: 2.9315913410351926
Validation loss: 2.5103596302269766

Epoch: 5| Step: 4
Training loss: 3.0505566386085814
Validation loss: 2.5391606268840925

Epoch: 5| Step: 5
Training loss: 2.698628207802804
Validation loss: 2.533851103406716

Epoch: 5| Step: 6
Training loss: 2.6766274109745227
Validation loss: 2.5084651434751337

Epoch: 5| Step: 7
Training loss: 2.791851796706435
Validation loss: 2.482269174752075

Epoch: 5| Step: 8
Training loss: 2.7570848234381207
Validation loss: 2.454835438464399

Epoch: 5| Step: 9
Training loss: 3.045908613270514
Validation loss: 2.4471676202570625

Epoch: 5| Step: 10
Training loss: 2.2995220682902158
Validation loss: 2.449984625600057

Epoch: 198| Step: 0
Training loss: 2.505247807076102
Validation loss: 2.45993125072462

Epoch: 5| Step: 1
Training loss: 2.7473921114397677
Validation loss: 2.455475221076558

Epoch: 5| Step: 2
Training loss: 2.6974989716224727
Validation loss: 2.449652016173504

Epoch: 5| Step: 3
Training loss: 2.7081462110775574
Validation loss: 2.4576695837344142

Epoch: 5| Step: 4
Training loss: 3.154029593939055
Validation loss: 2.4570980328031755

Epoch: 5| Step: 5
Training loss: 3.001177715557492
Validation loss: 2.4775440251697556

Epoch: 5| Step: 6
Training loss: 1.9690926268815125
Validation loss: 2.5009313202261554

Epoch: 5| Step: 7
Training loss: 2.9578353211922535
Validation loss: 2.5240226038571723

Epoch: 5| Step: 8
Training loss: 2.9901933922628356
Validation loss: 2.5220584365396723

Epoch: 5| Step: 9
Training loss: 2.6460726371938756
Validation loss: 2.5189970948061617

Epoch: 5| Step: 10
Training loss: 2.6147115810193107
Validation loss: 2.5061778308173768

Epoch: 199| Step: 0
Training loss: 2.831430431957604
Validation loss: 2.4762896269087804

Epoch: 5| Step: 1
Training loss: 2.5564085969482226
Validation loss: 2.4681593973952523

Epoch: 5| Step: 2
Training loss: 2.679829585365066
Validation loss: 2.4677617691356133

Epoch: 5| Step: 3
Training loss: 2.4933239489224057
Validation loss: 2.463855382019379

Epoch: 5| Step: 4
Training loss: 2.4438044861478
Validation loss: 2.4590060893597747

Epoch: 5| Step: 5
Training loss: 2.3914993781444482
Validation loss: 2.475902723749579

Epoch: 5| Step: 6
Training loss: 3.163978556708628
Validation loss: 2.478805773898265

Epoch: 5| Step: 7
Training loss: 2.817400752759172
Validation loss: 2.4838582091688997

Epoch: 5| Step: 8
Training loss: 2.580109358547228
Validation loss: 2.4873677938007344

Epoch: 5| Step: 9
Training loss: 3.2348983267559186
Validation loss: 2.4886886441673375

Epoch: 5| Step: 10
Training loss: 2.49923160188357
Validation loss: 2.4940676496066168

Epoch: 200| Step: 0
Training loss: 3.0566601249877197
Validation loss: 2.4903726454519926

Epoch: 5| Step: 1
Training loss: 2.2144918279921235
Validation loss: 2.4991435932394097

Epoch: 5| Step: 2
Training loss: 3.385470502376433
Validation loss: 2.506202016821242

Epoch: 5| Step: 3
Training loss: 2.307706452595325
Validation loss: 2.502770037778306

Epoch: 5| Step: 4
Training loss: 2.3562769475959255
Validation loss: 2.5125683013557527

Epoch: 5| Step: 5
Training loss: 3.006002778418114
Validation loss: 2.5109620579019163

Epoch: 5| Step: 6
Training loss: 2.724774143063382
Validation loss: 2.5211620799520733

Epoch: 5| Step: 7
Training loss: 2.70873819895217
Validation loss: 2.513339358242283

Epoch: 5| Step: 8
Training loss: 3.0287902920034875
Validation loss: 2.4949593343907486

Epoch: 5| Step: 9
Training loss: 2.164103263168092
Validation loss: 2.473047238484775

Epoch: 5| Step: 10
Training loss: 2.563026002071083
Validation loss: 2.4710008239448578

Epoch: 201| Step: 0
Training loss: 2.67895337605959
Validation loss: 2.4561131314993716

Epoch: 5| Step: 1
Training loss: 2.568469282344195
Validation loss: 2.4553845905825513

Epoch: 5| Step: 2
Training loss: 3.025533260285571
Validation loss: 2.4509240141856337

Epoch: 5| Step: 3
Training loss: 2.6712693983702644
Validation loss: 2.4609739624801596

Epoch: 5| Step: 4
Training loss: 2.9424236508740793
Validation loss: 2.482445026354068

Epoch: 5| Step: 5
Training loss: 2.618905576759672
Validation loss: 2.4721515690434193

Epoch: 5| Step: 6
Training loss: 2.5508864002841327
Validation loss: 2.479030247243396

Epoch: 5| Step: 7
Training loss: 2.805581463063625
Validation loss: 2.5052011243441745

Epoch: 5| Step: 8
Training loss: 1.8237634780940046
Validation loss: 2.5043305180976385

Epoch: 5| Step: 9
Training loss: 2.8232160927916765
Validation loss: 2.5065079428707593

Epoch: 5| Step: 10
Training loss: 3.0494860294220296
Validation loss: 2.4784720031777843

Epoch: 202| Step: 0
Training loss: 2.5940926566770472
Validation loss: 2.4701431059319585

Epoch: 5| Step: 1
Training loss: 2.638052324795582
Validation loss: 2.462409109417611

Epoch: 5| Step: 2
Training loss: 2.825914899825741
Validation loss: 2.4629975176064907

Epoch: 5| Step: 3
Training loss: 2.7359496024325414
Validation loss: 2.452886588254666

Epoch: 5| Step: 4
Training loss: 3.1373744863504163
Validation loss: 2.459539362339479

Epoch: 5| Step: 5
Training loss: 2.7087076564237695
Validation loss: 2.4596751975767797

Epoch: 5| Step: 6
Training loss: 2.8390645423424132
Validation loss: 2.449973341298926

Epoch: 5| Step: 7
Training loss: 2.491066611852252
Validation loss: 2.4548940947648816

Epoch: 5| Step: 8
Training loss: 2.066079588022734
Validation loss: 2.4591451169780343

Epoch: 5| Step: 9
Training loss: 2.8163653620742553
Validation loss: 2.470577082591996

Epoch: 5| Step: 10
Training loss: 2.6050816467142375
Validation loss: 2.459911240139349

Epoch: 203| Step: 0
Training loss: 2.6498313994125176
Validation loss: 2.467432295828572

Epoch: 5| Step: 1
Training loss: 3.027876402233445
Validation loss: 2.4617476591284806

Epoch: 5| Step: 2
Training loss: 2.846450864516879
Validation loss: 2.4885284671407546

Epoch: 5| Step: 3
Training loss: 2.3645345091855594
Validation loss: 2.5054684031700147

Epoch: 5| Step: 4
Training loss: 2.7733786133438185
Validation loss: 2.5154749257967794

Epoch: 5| Step: 5
Training loss: 2.8953908861298654
Validation loss: 2.497908282193841

Epoch: 5| Step: 6
Training loss: 2.746074302029285
Validation loss: 2.4873110159299494

Epoch: 5| Step: 7
Training loss: 2.8116736151657067
Validation loss: 2.4880152798905453

Epoch: 5| Step: 8
Training loss: 2.1557925195102876
Validation loss: 2.4761035965405096

Epoch: 5| Step: 9
Training loss: 2.5199439841811255
Validation loss: 2.453769938961859

Epoch: 5| Step: 10
Training loss: 2.744865479221785
Validation loss: 2.4546296293187995

Epoch: 204| Step: 0
Training loss: 2.3124796892253636
Validation loss: 2.468880378517206

Epoch: 5| Step: 1
Training loss: 3.231972802076059
Validation loss: 2.457698345472807

Epoch: 5| Step: 2
Training loss: 2.667906373664589
Validation loss: 2.4565707642744745

Epoch: 5| Step: 3
Training loss: 2.152592528655014
Validation loss: 2.471958920732958

Epoch: 5| Step: 4
Training loss: 3.0332141293868315
Validation loss: 2.4792204599670447

Epoch: 5| Step: 5
Training loss: 2.3651119991179237
Validation loss: 2.4913104881386796

Epoch: 5| Step: 6
Training loss: 2.652339704957105
Validation loss: 2.5076698751051194

Epoch: 5| Step: 7
Training loss: 2.917654651246516
Validation loss: 2.5360452049757565

Epoch: 5| Step: 8
Training loss: 2.3041448439196426
Validation loss: 2.5195952320615795

Epoch: 5| Step: 9
Training loss: 2.579330347523654
Validation loss: 2.527455376008323

Epoch: 5| Step: 10
Training loss: 3.169262942719909
Validation loss: 2.512233208809394

Epoch: 205| Step: 0
Training loss: 2.710051817873655
Validation loss: 2.548283361520154

Epoch: 5| Step: 1
Training loss: 2.92404844668184
Validation loss: 2.5662059452603505

Epoch: 5| Step: 2
Training loss: 3.1574209326285243
Validation loss: 2.583871424330453

Epoch: 5| Step: 3
Training loss: 2.750668011073149
Validation loss: 2.5807655124711086

Epoch: 5| Step: 4
Training loss: 2.743033341158209
Validation loss: 2.5635882172144426

Epoch: 5| Step: 5
Training loss: 2.7886094866088604
Validation loss: 2.538465133328556

Epoch: 5| Step: 6
Training loss: 2.474253832920972
Validation loss: 2.4898928182475766

Epoch: 5| Step: 7
Training loss: 2.599723096920913
Validation loss: 2.455828679884021

Epoch: 5| Step: 8
Training loss: 2.126959626439214
Validation loss: 2.4717828499899492

Epoch: 5| Step: 9
Training loss: 2.7821334121658507
Validation loss: 2.486868637421503

Epoch: 5| Step: 10
Training loss: 2.647340350357986
Validation loss: 2.4874272459169475

Epoch: 206| Step: 0
Training loss: 2.550835648288152
Validation loss: 2.5146382589638976

Epoch: 5| Step: 1
Training loss: 1.814701190658383
Validation loss: 2.526167392847406

Epoch: 5| Step: 2
Training loss: 3.11973448601714
Validation loss: 2.540164861553797

Epoch: 5| Step: 3
Training loss: 2.488921701360682
Validation loss: 2.5423577191419415

Epoch: 5| Step: 4
Training loss: 2.247076678608974
Validation loss: 2.5385200601331737

Epoch: 5| Step: 5
Training loss: 2.7476616367767783
Validation loss: 2.5604805901515832

Epoch: 5| Step: 6
Training loss: 2.4510507743678125
Validation loss: 2.561356190923002

Epoch: 5| Step: 7
Training loss: 2.9607684004112893
Validation loss: 2.5775718555472427

Epoch: 5| Step: 8
Training loss: 3.304863241947181
Validation loss: 2.5695849881198223

Epoch: 5| Step: 9
Training loss: 3.0323877460682502
Validation loss: 2.6038485146061725

Epoch: 5| Step: 10
Training loss: 3.3161153677001307
Validation loss: 2.5731298687048687

Epoch: 207| Step: 0
Training loss: 3.201654608440843
Validation loss: 2.565571890318979

Epoch: 5| Step: 1
Training loss: 2.719363614696112
Validation loss: 2.5544154193605983

Epoch: 5| Step: 2
Training loss: 2.590901568734963
Validation loss: 2.565240163754767

Epoch: 5| Step: 3
Training loss: 3.090366247008502
Validation loss: 2.5741169281162066

Epoch: 5| Step: 4
Training loss: 2.8269887928533097
Validation loss: 2.554827738927953

Epoch: 5| Step: 5
Training loss: 2.738255303405513
Validation loss: 2.5567479738681134

Epoch: 5| Step: 6
Training loss: 2.3058175113062997
Validation loss: 2.5453121489300856

Epoch: 5| Step: 7
Training loss: 2.8418906704344975
Validation loss: 2.515438821209136

Epoch: 5| Step: 8
Training loss: 2.538271079332165
Validation loss: 2.474843189346986

Epoch: 5| Step: 9
Training loss: 2.6454825782065243
Validation loss: 2.456960914106304

Epoch: 5| Step: 10
Training loss: 2.2216611220034728
Validation loss: 2.443375224584073

Epoch: 208| Step: 0
Training loss: 2.6190612462337413
Validation loss: 2.4371112285219114

Epoch: 5| Step: 1
Training loss: 2.861771210094081
Validation loss: 2.4241957264142657

Epoch: 5| Step: 2
Training loss: 3.1309292809861775
Validation loss: 2.4252710175528165

Epoch: 5| Step: 3
Training loss: 1.9430753414057702
Validation loss: 2.4269082431696134

Epoch: 5| Step: 4
Training loss: 2.4436906304916115
Validation loss: 2.423899892455961

Epoch: 5| Step: 5
Training loss: 2.810936641639973
Validation loss: 2.4288843802846154

Epoch: 5| Step: 6
Training loss: 2.7065652113098086
Validation loss: 2.4485115079087176

Epoch: 5| Step: 7
Training loss: 2.9227995200324224
Validation loss: 2.4583018283344282

Epoch: 5| Step: 8
Training loss: 3.0925433955929362
Validation loss: 2.4770985228312226

Epoch: 5| Step: 9
Training loss: 2.800667094054988
Validation loss: 2.4691355061454927

Epoch: 5| Step: 10
Training loss: 2.3765428450735357
Validation loss: 2.475329220038282

Epoch: 209| Step: 0
Training loss: 2.559491321868701
Validation loss: 2.45399323562765

Epoch: 5| Step: 1
Training loss: 3.1820109358527087
Validation loss: 2.4450500697623747

Epoch: 5| Step: 2
Training loss: 2.7366533651117724
Validation loss: 2.4284296418993567

Epoch: 5| Step: 3
Training loss: 2.8317081240769464
Validation loss: 2.4279353567666

Epoch: 5| Step: 4
Training loss: 2.711404369949114
Validation loss: 2.422439000368225

Epoch: 5| Step: 5
Training loss: 2.3167968214874697
Validation loss: 2.431019736723182

Epoch: 5| Step: 6
Training loss: 2.720413313065239
Validation loss: 2.4359539304400943

Epoch: 5| Step: 7
Training loss: 2.2277198326817453
Validation loss: 2.4397917691863014

Epoch: 5| Step: 8
Training loss: 2.609530233003018
Validation loss: 2.444711676827159

Epoch: 5| Step: 9
Training loss: 3.138511136110442
Validation loss: 2.4563120114636723

Epoch: 5| Step: 10
Training loss: 2.573557281022677
Validation loss: 2.4718683314502803

Epoch: 210| Step: 0
Training loss: 2.732243606390965
Validation loss: 2.4772438257784875

Epoch: 5| Step: 1
Training loss: 2.691636738645226
Validation loss: 2.467700218431442

Epoch: 5| Step: 2
Training loss: 2.68614366593391
Validation loss: 2.470520175144618

Epoch: 5| Step: 3
Training loss: 2.8222072502883844
Validation loss: 2.47394746649557

Epoch: 5| Step: 4
Training loss: 2.7499852613574323
Validation loss: 2.467000443910803

Epoch: 5| Step: 5
Training loss: 2.3922042118537745
Validation loss: 2.473598652952004

Epoch: 5| Step: 6
Training loss: 2.743183096537515
Validation loss: 2.468995831421597

Epoch: 5| Step: 7
Training loss: 2.236805907272484
Validation loss: 2.4615319652090553

Epoch: 5| Step: 8
Training loss: 2.6765511623305005
Validation loss: 2.4527746488188047

Epoch: 5| Step: 9
Training loss: 2.8838786813030333
Validation loss: 2.451544341307643

Epoch: 5| Step: 10
Training loss: 2.819469040469502
Validation loss: 2.460469942329783

Epoch: 211| Step: 0
Training loss: 3.2802402940979682
Validation loss: 2.459278712948354

Epoch: 5| Step: 1
Training loss: 2.4500703684763505
Validation loss: 2.455961785065688

Epoch: 5| Step: 2
Training loss: 2.7359103878470856
Validation loss: 2.459791524436896

Epoch: 5| Step: 3
Training loss: 2.680403010541452
Validation loss: 2.462653726023169

Epoch: 5| Step: 4
Training loss: 2.590898347981401
Validation loss: 2.470880838332561

Epoch: 5| Step: 5
Training loss: 2.6394323782044067
Validation loss: 2.4740939989871813

Epoch: 5| Step: 6
Training loss: 2.5090272997469047
Validation loss: 2.477649445406837

Epoch: 5| Step: 7
Training loss: 2.2318930546081845
Validation loss: 2.47176565481201

Epoch: 5| Step: 8
Training loss: 3.0385933246652463
Validation loss: 2.4912910094974063

Epoch: 5| Step: 9
Training loss: 2.4805516026394074
Validation loss: 2.475135458069952

Epoch: 5| Step: 10
Training loss: 2.643518160851964
Validation loss: 2.474399122640119

Epoch: 212| Step: 0
Training loss: 2.962956930083738
Validation loss: 2.489820953931682

Epoch: 5| Step: 1
Training loss: 2.408847150362811
Validation loss: 2.4838840275255865

Epoch: 5| Step: 2
Training loss: 2.188302574067436
Validation loss: 2.500026271025743

Epoch: 5| Step: 3
Training loss: 2.5975142590716076
Validation loss: 2.489811849762201

Epoch: 5| Step: 4
Training loss: 2.4591937956891194
Validation loss: 2.4919734727532665

Epoch: 5| Step: 5
Training loss: 2.797762255882707
Validation loss: 2.5034860542472055

Epoch: 5| Step: 6
Training loss: 2.6242923691040216
Validation loss: 2.5149893722288423

Epoch: 5| Step: 7
Training loss: 2.436807974367876
Validation loss: 2.5100490301046907

Epoch: 5| Step: 8
Training loss: 3.196725546884958
Validation loss: 2.4941405725788686

Epoch: 5| Step: 9
Training loss: 3.015612982691405
Validation loss: 2.479654688242994

Epoch: 5| Step: 10
Training loss: 2.418984540267814
Validation loss: 2.4924116732995865

Epoch: 213| Step: 0
Training loss: 2.0314145535059556
Validation loss: 2.492016341809142

Epoch: 5| Step: 1
Training loss: 3.0658502742889957
Validation loss: 2.490140756660551

Epoch: 5| Step: 2
Training loss: 2.6701317169617855
Validation loss: 2.5096286978129627

Epoch: 5| Step: 3
Training loss: 2.0448018997980526
Validation loss: 2.5098602549047286

Epoch: 5| Step: 4
Training loss: 2.972625451548734
Validation loss: 2.5165923942597463

Epoch: 5| Step: 5
Training loss: 2.8066560005504817
Validation loss: 2.5415232149052067

Epoch: 5| Step: 6
Training loss: 2.3674612359133245
Validation loss: 2.5446628768075406

Epoch: 5| Step: 7
Training loss: 3.110460254919925
Validation loss: 2.5505268211431575

Epoch: 5| Step: 8
Training loss: 2.3972359794535296
Validation loss: 2.547702225405948

Epoch: 5| Step: 9
Training loss: 2.725898727461365
Validation loss: 2.5389924393572776

Epoch: 5| Step: 10
Training loss: 2.919640650650464
Validation loss: 2.545541975751617

Epoch: 214| Step: 0
Training loss: 2.7611997729145936
Validation loss: 2.511639196555114

Epoch: 5| Step: 1
Training loss: 2.1386204822235486
Validation loss: 2.5087501905012544

Epoch: 5| Step: 2
Training loss: 2.5351446824478487
Validation loss: 2.4897220253890424

Epoch: 5| Step: 3
Training loss: 2.5990499558030833
Validation loss: 2.4878497763249707

Epoch: 5| Step: 4
Training loss: 2.1509745097048794
Validation loss: 2.49114678213682

Epoch: 5| Step: 5
Training loss: 2.908276743370175
Validation loss: 2.488177923590823

Epoch: 5| Step: 6
Training loss: 3.1419501853796516
Validation loss: 2.505274016420394

Epoch: 5| Step: 7
Training loss: 2.854815908132034
Validation loss: 2.5389984339857956

Epoch: 5| Step: 8
Training loss: 2.7208454344063147
Validation loss: 2.566849213868459

Epoch: 5| Step: 9
Training loss: 2.6012381503244506
Validation loss: 2.588626945257702

Epoch: 5| Step: 10
Training loss: 3.025842149014782
Validation loss: 2.5807818224699766

Epoch: 215| Step: 0
Training loss: 2.491889194345722
Validation loss: 2.5629085232137654

Epoch: 5| Step: 1
Training loss: 3.296906963753895
Validation loss: 2.601591071209967

Epoch: 5| Step: 2
Training loss: 3.236589199072797
Validation loss: 2.5689243019289094

Epoch: 5| Step: 3
Training loss: 3.085367116244742
Validation loss: 2.5172211246985974

Epoch: 5| Step: 4
Training loss: 2.453735469983028
Validation loss: 2.4889184392832893

Epoch: 5| Step: 5
Training loss: 2.6284736175287042
Validation loss: 2.4754115176782725

Epoch: 5| Step: 6
Training loss: 2.4938150191853747
Validation loss: 2.4668038920661908

Epoch: 5| Step: 7
Training loss: 2.2495744090766716
Validation loss: 2.4701335639109026

Epoch: 5| Step: 8
Training loss: 1.7981617839658666
Validation loss: 2.505433861135064

Epoch: 5| Step: 9
Training loss: 2.8405435111902166
Validation loss: 2.5396450548810443

Epoch: 5| Step: 10
Training loss: 2.962274657101195
Validation loss: 2.562576156753097

Epoch: 216| Step: 0
Training loss: 2.9879282624443433
Validation loss: 2.5672926175719835

Epoch: 5| Step: 1
Training loss: 2.557874086229308
Validation loss: 2.514142525398711

Epoch: 5| Step: 2
Training loss: 2.5765689662391855
Validation loss: 2.4676925577296887

Epoch: 5| Step: 3
Training loss: 2.765204446142687
Validation loss: 2.4516598775774985

Epoch: 5| Step: 4
Training loss: 2.584153219575738
Validation loss: 2.4513984928730994

Epoch: 5| Step: 5
Training loss: 2.4726707132648684
Validation loss: 2.4605061074992767

Epoch: 5| Step: 6
Training loss: 2.1144486057100003
Validation loss: 2.4821758756871866

Epoch: 5| Step: 7
Training loss: 2.706930491676426
Validation loss: 2.495916153531046

Epoch: 5| Step: 8
Training loss: 2.626824426157358
Validation loss: 2.5167878844659755

Epoch: 5| Step: 9
Training loss: 3.02371285537544
Validation loss: 2.5387681006304765

Epoch: 5| Step: 10
Training loss: 2.622244069399943
Validation loss: 2.5357709299645848

Epoch: 217| Step: 0
Training loss: 2.686392178755707
Validation loss: 2.5171342726077692

Epoch: 5| Step: 1
Training loss: 2.1229020028049304
Validation loss: 2.515985513885965

Epoch: 5| Step: 2
Training loss: 2.412782990455877
Validation loss: 2.515222707713578

Epoch: 5| Step: 3
Training loss: 3.0893501823118394
Validation loss: 2.5131524143948125

Epoch: 5| Step: 4
Training loss: 2.1167727130947687
Validation loss: 2.5054498641799667

Epoch: 5| Step: 5
Training loss: 2.4851481835990787
Validation loss: 2.4969989145066562

Epoch: 5| Step: 6
Training loss: 3.1509787477038693
Validation loss: 2.4691758365539807

Epoch: 5| Step: 7
Training loss: 2.705416022725168
Validation loss: 2.4632279297461825

Epoch: 5| Step: 8
Training loss: 2.6925770022291564
Validation loss: 2.4558914154112594

Epoch: 5| Step: 9
Training loss: 2.7495889356471013
Validation loss: 2.4677451287391756

Epoch: 5| Step: 10
Training loss: 2.556195481891846
Validation loss: 2.4552131315694137

Epoch: 218| Step: 0
Training loss: 3.0878652997459266
Validation loss: 2.4626878708276223

Epoch: 5| Step: 1
Training loss: 3.0360340238531816
Validation loss: 2.4839655040201554

Epoch: 5| Step: 2
Training loss: 2.4510356971634524
Validation loss: 2.483196695002525

Epoch: 5| Step: 3
Training loss: 2.3750941609238136
Validation loss: 2.4906732150093163

Epoch: 5| Step: 4
Training loss: 2.9965062460500875
Validation loss: 2.490465729060427

Epoch: 5| Step: 5
Training loss: 2.5213148324524015
Validation loss: 2.506604085684104

Epoch: 5| Step: 6
Training loss: 2.1208732026655124
Validation loss: 2.510513302442516

Epoch: 5| Step: 7
Training loss: 2.2410069989933885
Validation loss: 2.5127319105240704

Epoch: 5| Step: 8
Training loss: 3.0042202193892034
Validation loss: 2.507235776890271

Epoch: 5| Step: 9
Training loss: 2.4231188133540567
Validation loss: 2.507372704904297

Epoch: 5| Step: 10
Training loss: 2.7137233700141916
Validation loss: 2.516642762122023

Epoch: 219| Step: 0
Training loss: 2.3350556919554815
Validation loss: 2.4979680201943193

Epoch: 5| Step: 1
Training loss: 2.958240579216627
Validation loss: 2.483692266538661

Epoch: 5| Step: 2
Training loss: 1.9452991408536646
Validation loss: 2.495288191557315

Epoch: 5| Step: 3
Training loss: 2.4780151727687563
Validation loss: 2.4848044224187236

Epoch: 5| Step: 4
Training loss: 2.839168337086316
Validation loss: 2.4806489664048548

Epoch: 5| Step: 5
Training loss: 2.5214429596351864
Validation loss: 2.48941916550354

Epoch: 5| Step: 6
Training loss: 2.5359503350253307
Validation loss: 2.482031954258854

Epoch: 5| Step: 7
Training loss: 2.9924655715376876
Validation loss: 2.479855321212744

Epoch: 5| Step: 8
Training loss: 3.0695051146006533
Validation loss: 2.498150768122552

Epoch: 5| Step: 9
Training loss: 2.4939898726893226
Validation loss: 2.4979179439041768

Epoch: 5| Step: 10
Training loss: 2.407969962385785
Validation loss: 2.4980713367663543

Epoch: 220| Step: 0
Training loss: 3.195905336632381
Validation loss: 2.512945716360508

Epoch: 5| Step: 1
Training loss: 2.8766723412921524
Validation loss: 2.528876766604321

Epoch: 5| Step: 2
Training loss: 1.8200145690460605
Validation loss: 2.5301686525242344

Epoch: 5| Step: 3
Training loss: 2.5094212395955275
Validation loss: 2.5380769317133476

Epoch: 5| Step: 4
Training loss: 2.636073416398076
Validation loss: 2.550662999118783

Epoch: 5| Step: 5
Training loss: 2.5411317814894994
Validation loss: 2.570162642623274

Epoch: 5| Step: 6
Training loss: 2.3652644135814467
Validation loss: 2.578289501303015

Epoch: 5| Step: 7
Training loss: 2.1802424336291075
Validation loss: 2.5864996670028972

Epoch: 5| Step: 8
Training loss: 2.798050276538401
Validation loss: 2.5733794039139206

Epoch: 5| Step: 9
Training loss: 2.4009936500983295
Validation loss: 2.5460458484494364

Epoch: 5| Step: 10
Training loss: 3.044089741320129
Validation loss: 2.539243851236203

Epoch: 221| Step: 0
Training loss: 2.5656244721685093
Validation loss: 2.523248496064064

Epoch: 5| Step: 1
Training loss: 2.460153024767654
Validation loss: 2.5183444942805453

Epoch: 5| Step: 2
Training loss: 2.05046198221648
Validation loss: 2.5073050899698344

Epoch: 5| Step: 3
Training loss: 2.78380184760798
Validation loss: 2.5241090493118947

Epoch: 5| Step: 4
Training loss: 2.3400465124349314
Validation loss: 2.5198329146205634

Epoch: 5| Step: 5
Training loss: 2.9346543184211544
Validation loss: 2.5018967467812203

Epoch: 5| Step: 6
Training loss: 3.0436684975492376
Validation loss: 2.4993511768010435

Epoch: 5| Step: 7
Training loss: 2.081055374897235
Validation loss: 2.4939078519819073

Epoch: 5| Step: 8
Training loss: 3.0713985162829642
Validation loss: 2.49828472360269

Epoch: 5| Step: 9
Training loss: 2.610648021710648
Validation loss: 2.4885577118143423

Epoch: 5| Step: 10
Training loss: 2.777633802073562
Validation loss: 2.462795335386905

Epoch: 222| Step: 0
Training loss: 2.374546409257827
Validation loss: 2.4460890542482225

Epoch: 5| Step: 1
Training loss: 2.559192010954216
Validation loss: 2.4508697622969318

Epoch: 5| Step: 2
Training loss: 2.5754748045559652
Validation loss: 2.467328954552952

Epoch: 5| Step: 3
Training loss: 2.8661176052201913
Validation loss: 2.463508513291127

Epoch: 5| Step: 4
Training loss: 2.6090350814806005
Validation loss: 2.483868057641875

Epoch: 5| Step: 5
Training loss: 2.9523756903207414
Validation loss: 2.498940000081375

Epoch: 5| Step: 6
Training loss: 2.8270775978819187
Validation loss: 2.5154442186873514

Epoch: 5| Step: 7
Training loss: 2.53282380333931
Validation loss: 2.508023698549336

Epoch: 5| Step: 8
Training loss: 2.388344768045138
Validation loss: 2.5066464140676494

Epoch: 5| Step: 9
Training loss: 2.3030270559532906
Validation loss: 2.496766122520258

Epoch: 5| Step: 10
Training loss: 2.8311220590681505
Validation loss: 2.5061005698855454

Epoch: 223| Step: 0
Training loss: 2.5146359222989534
Validation loss: 2.5250371629109645

Epoch: 5| Step: 1
Training loss: 2.422798423691757
Validation loss: 2.5105625444306856

Epoch: 5| Step: 2
Training loss: 2.429068826981018
Validation loss: 2.4980394294869814

Epoch: 5| Step: 3
Training loss: 2.935722624999272
Validation loss: 2.5007985900726135

Epoch: 5| Step: 4
Training loss: 2.703771436714766
Validation loss: 2.5065713818725213

Epoch: 5| Step: 5
Training loss: 2.990356682008406
Validation loss: 2.533571836106817

Epoch: 5| Step: 6
Training loss: 2.410585634139103
Validation loss: 2.5392975284917285

Epoch: 5| Step: 7
Training loss: 2.3666580665682853
Validation loss: 2.5678269816631927

Epoch: 5| Step: 8
Training loss: 2.851309151042183
Validation loss: 2.597335947419005

Epoch: 5| Step: 9
Training loss: 2.102981372026992
Validation loss: 2.5829552629501467

Epoch: 5| Step: 10
Training loss: 2.5017526205275384
Validation loss: 2.6169253148644938

Epoch: 224| Step: 0
Training loss: 2.4926938107667014
Validation loss: 2.646570192385137

Epoch: 5| Step: 1
Training loss: 2.944426790420422
Validation loss: 2.6481896297557395

Epoch: 5| Step: 2
Training loss: 2.389576401460721
Validation loss: 2.6761611212541023

Epoch: 5| Step: 3
Training loss: 2.5967764605063417
Validation loss: 2.6386372239149294

Epoch: 5| Step: 4
Training loss: 2.667019453157267
Validation loss: 2.6311164194012466

Epoch: 5| Step: 5
Training loss: 3.314916772732619
Validation loss: 2.6095978684254115

Epoch: 5| Step: 6
Training loss: 2.5056926764019205
Validation loss: 2.5468946323157757

Epoch: 5| Step: 7
Training loss: 2.0207911090437776
Validation loss: 2.495049233253021

Epoch: 5| Step: 8
Training loss: 2.8238542883512245
Validation loss: 2.454019491460173

Epoch: 5| Step: 9
Training loss: 1.8674037281433458
Validation loss: 2.4248229251068825

Epoch: 5| Step: 10
Training loss: 2.711969096882612
Validation loss: 2.4245659757671216

Epoch: 225| Step: 0
Training loss: 2.6667694032270193
Validation loss: 2.422722285662698

Epoch: 5| Step: 1
Training loss: 2.4894419886688484
Validation loss: 2.4330059194785356

Epoch: 5| Step: 2
Training loss: 2.665066079757246
Validation loss: 2.453658559625587

Epoch: 5| Step: 3
Training loss: 2.438749042239018
Validation loss: 2.471129520290378

Epoch: 5| Step: 4
Training loss: 2.5150537256831136
Validation loss: 2.4518546749991073

Epoch: 5| Step: 5
Training loss: 2.895034808013855
Validation loss: 2.45045515373457

Epoch: 5| Step: 6
Training loss: 2.8923059473250974
Validation loss: 2.4404108837031107

Epoch: 5| Step: 7
Training loss: 2.993695787803041
Validation loss: 2.425916076742169

Epoch: 5| Step: 8
Training loss: 2.2552363604653376
Validation loss: 2.4120169088585586

Epoch: 5| Step: 9
Training loss: 2.380589182717707
Validation loss: 2.413678292229329

Epoch: 5| Step: 10
Training loss: 3.0393036499057753
Validation loss: 2.4263991082806897

Epoch: 226| Step: 0
Training loss: 2.397254677036269
Validation loss: 2.4142838476932615

Epoch: 5| Step: 1
Training loss: 2.534769978066121
Validation loss: 2.430242238708561

Epoch: 5| Step: 2
Training loss: 2.6279704226508867
Validation loss: 2.4296647406996783

Epoch: 5| Step: 3
Training loss: 2.52080736593528
Validation loss: 2.4475699705269647

Epoch: 5| Step: 4
Training loss: 2.9202089506663316
Validation loss: 2.440809634972848

Epoch: 5| Step: 5
Training loss: 2.612996403746789
Validation loss: 2.4428143095988015

Epoch: 5| Step: 6
Training loss: 2.018562601089652
Validation loss: 2.4395439417219817

Epoch: 5| Step: 7
Training loss: 3.1585518780654316
Validation loss: 2.4524480249928255

Epoch: 5| Step: 8
Training loss: 2.1335199880403453
Validation loss: 2.4830260677475797

Epoch: 5| Step: 9
Training loss: 2.4757101716238585
Validation loss: 2.507089344933057

Epoch: 5| Step: 10
Training loss: 2.6700809099318086
Validation loss: 2.5455162439625036

Epoch: 227| Step: 0
Training loss: 2.4773831617287403
Validation loss: 2.5721950474761273

Epoch: 5| Step: 1
Training loss: 2.5307461272401013
Validation loss: 2.5701329360259635

Epoch: 5| Step: 2
Training loss: 3.131372287212596
Validation loss: 2.569857378054248

Epoch: 5| Step: 3
Training loss: 2.7252516779035765
Validation loss: 2.5516817910028613

Epoch: 5| Step: 4
Training loss: 2.7800446373628573
Validation loss: 2.5735262697924

Epoch: 5| Step: 5
Training loss: 2.528852386890907
Validation loss: 2.5441700693557037

Epoch: 5| Step: 6
Training loss: 2.389296517845621
Validation loss: 2.5326684653571756

Epoch: 5| Step: 7
Training loss: 1.9899782983756333
Validation loss: 2.5234588222884806

Epoch: 5| Step: 8
Training loss: 2.1386930560452275
Validation loss: 2.536717206429846

Epoch: 5| Step: 9
Training loss: 2.638942204879326
Validation loss: 2.5376143624065954

Epoch: 5| Step: 10
Training loss: 2.6842094503563927
Validation loss: 2.5155782377410962

Epoch: 228| Step: 0
Training loss: 3.1810491772051956
Validation loss: 2.4987107521184067

Epoch: 5| Step: 1
Training loss: 2.2453478296058114
Validation loss: 2.486507422871928

Epoch: 5| Step: 2
Training loss: 2.235854719270372
Validation loss: 2.508257686117638

Epoch: 5| Step: 3
Training loss: 2.4072856903552213
Validation loss: 2.4998577149211774

Epoch: 5| Step: 4
Training loss: 2.624466796490546
Validation loss: 2.5067197698455743

Epoch: 5| Step: 5
Training loss: 2.5705079349320408
Validation loss: 2.5085909193789067

Epoch: 5| Step: 6
Training loss: 2.8870889016004737
Validation loss: 2.505269550234478

Epoch: 5| Step: 7
Training loss: 1.915770410989767
Validation loss: 2.5043982640119484

Epoch: 5| Step: 8
Training loss: 2.752204011807159
Validation loss: 2.4955134361923923

Epoch: 5| Step: 9
Training loss: 2.388946941567356
Validation loss: 2.4968388763261964

Epoch: 5| Step: 10
Training loss: 2.465431590647289
Validation loss: 2.546500424998712

Epoch: 229| Step: 0
Training loss: 2.463052573389079
Validation loss: 2.5323503716298035

Epoch: 5| Step: 1
Training loss: 2.725324027018823
Validation loss: 2.5603107862209877

Epoch: 5| Step: 2
Training loss: 2.8104012181842704
Validation loss: 2.5140615109118767

Epoch: 5| Step: 3
Training loss: 2.9870904681691273
Validation loss: 2.5024235145775626

Epoch: 5| Step: 4
Training loss: 2.5052964372799202
Validation loss: 2.4564315951291507

Epoch: 5| Step: 5
Training loss: 2.5303151794547554
Validation loss: 2.434153263628231

Epoch: 5| Step: 6
Training loss: 2.093848382716544
Validation loss: 2.440225649105789

Epoch: 5| Step: 7
Training loss: 2.8341379893002774
Validation loss: 2.4412983175066714

Epoch: 5| Step: 8
Training loss: 2.56245115280115
Validation loss: 2.453287447792977

Epoch: 5| Step: 9
Training loss: 1.9652265475380168
Validation loss: 2.4694016337655236

Epoch: 5| Step: 10
Training loss: 2.026541549350794
Validation loss: 2.4915345890922795

Epoch: 230| Step: 0
Training loss: 1.9862564058962753
Validation loss: 2.5038791381336694

Epoch: 5| Step: 1
Training loss: 2.0657040533269515
Validation loss: 2.514829236261302

Epoch: 5| Step: 2
Training loss: 2.5028508144517634
Validation loss: 2.5547184418731863

Epoch: 5| Step: 3
Training loss: 2.572242360165529
Validation loss: 2.5687345509835136

Epoch: 5| Step: 4
Training loss: 2.853216323978688
Validation loss: 2.572549075702102

Epoch: 5| Step: 5
Training loss: 2.1741535118039397
Validation loss: 2.5799572750146025

Epoch: 5| Step: 6
Training loss: 2.6340271273224776
Validation loss: 2.536197854575337

Epoch: 5| Step: 7
Training loss: 2.3181007195972976
Validation loss: 2.5350811433969493

Epoch: 5| Step: 8
Training loss: 2.7616611674347453
Validation loss: 2.52484690188759

Epoch: 5| Step: 9
Training loss: 2.9320312890312747
Validation loss: 2.5064234842546567

Epoch: 5| Step: 10
Training loss: 2.6193451598863167
Validation loss: 2.5137494763794432

Epoch: 231| Step: 0
Training loss: 1.83919220420808
Validation loss: 2.5034691357060352

Epoch: 5| Step: 1
Training loss: 2.809542478463968
Validation loss: 2.4875909081379053

Epoch: 5| Step: 2
Training loss: 2.9259709499166013
Validation loss: 2.48494540808575

Epoch: 5| Step: 3
Training loss: 2.9260190248320668
Validation loss: 2.5064437689015526

Epoch: 5| Step: 4
Training loss: 2.1599721433468027
Validation loss: 2.5020000671131353

Epoch: 5| Step: 5
Training loss: 2.2486786671256165
Validation loss: 2.4835595337670715

Epoch: 5| Step: 6
Training loss: 2.559397796790166
Validation loss: 2.491677679726973

Epoch: 5| Step: 7
Training loss: 2.574534927886912
Validation loss: 2.4818000169796015

Epoch: 5| Step: 8
Training loss: 2.5939325475224275
Validation loss: 2.4718932669616605

Epoch: 5| Step: 9
Training loss: 2.16821507609622
Validation loss: 2.4780191754551466

Epoch: 5| Step: 10
Training loss: 2.2620489903886285
Validation loss: 2.490758623519636

Epoch: 232| Step: 0
Training loss: 2.0955726319825585
Validation loss: 2.506344862308672

Epoch: 5| Step: 1
Training loss: 2.379699173996983
Validation loss: 2.5257008224385826

Epoch: 5| Step: 2
Training loss: 1.6952489322399653
Validation loss: 2.5254306052005204

Epoch: 5| Step: 3
Training loss: 2.490496405484987
Validation loss: 2.5160494332768417

Epoch: 5| Step: 4
Training loss: 2.4696489459927036
Validation loss: 2.543582666803234

Epoch: 5| Step: 5
Training loss: 2.597699295490388
Validation loss: 2.5762271024498196

Epoch: 5| Step: 6
Training loss: 2.7578440548223524
Validation loss: 2.5946192159047343

Epoch: 5| Step: 7
Training loss: 2.369547457565686
Validation loss: 2.612087161438125

Epoch: 5| Step: 8
Training loss: 2.966035264220342
Validation loss: 2.6258127904504898

Epoch: 5| Step: 9
Training loss: 2.647127620887567
Validation loss: 2.628989280841625

Epoch: 5| Step: 10
Training loss: 2.46899422511943
Validation loss: 2.64848407696298

Epoch: 233| Step: 0
Training loss: 2.7322892435644595
Validation loss: 2.639407171785715

Epoch: 5| Step: 1
Training loss: 2.5614961658324735
Validation loss: 2.617725936119916

Epoch: 5| Step: 2
Training loss: 2.483869777146986
Validation loss: 2.61105566664825

Epoch: 5| Step: 3
Training loss: 2.691399163180075
Validation loss: 2.6052265473145853

Epoch: 5| Step: 4
Training loss: 2.249979654855933
Validation loss: 2.580326779623402

Epoch: 5| Step: 5
Training loss: 2.0768971652129014
Validation loss: 2.5528087483207607

Epoch: 5| Step: 6
Training loss: 2.407092058552129
Validation loss: 2.5310602292947078

Epoch: 5| Step: 7
Training loss: 2.5020037250628286
Validation loss: 2.5065785269185725

Epoch: 5| Step: 8
Training loss: 2.3272894057440254
Validation loss: 2.4921347450857363

Epoch: 5| Step: 9
Training loss: 2.2109827906414594
Validation loss: 2.448173704945575

Epoch: 5| Step: 10
Training loss: 2.5108887055836213
Validation loss: 2.44335661552927

Epoch: 234| Step: 0
Training loss: 2.187777038469906
Validation loss: 2.4363581110148878

Epoch: 5| Step: 1
Training loss: 2.3732174658976986
Validation loss: 2.420679972152863

Epoch: 5| Step: 2
Training loss: 2.1135614741716267
Validation loss: 2.4176293044606467

Epoch: 5| Step: 3
Training loss: 2.351755330743645
Validation loss: 2.42230256402005

Epoch: 5| Step: 4
Training loss: 2.9188530129790626
Validation loss: 2.4198085822584554

Epoch: 5| Step: 5
Training loss: 2.658710103455262
Validation loss: 2.4224683084475065

Epoch: 5| Step: 6
Training loss: 2.4458102856080304
Validation loss: 2.4328097719397226

Epoch: 5| Step: 7
Training loss: 2.1161170871768524
Validation loss: 2.477135133453076

Epoch: 5| Step: 8
Training loss: 2.4597467357242797
Validation loss: 2.526202682439471

Epoch: 5| Step: 9
Training loss: 2.4466165106445863
Validation loss: 2.577815373169045

Epoch: 5| Step: 10
Training loss: 2.9053556645401586
Validation loss: 2.615755261152931

Epoch: 235| Step: 0
Training loss: 2.441742945533077
Validation loss: 2.6370395707381897

Epoch: 5| Step: 1
Training loss: 2.2439633026318297
Validation loss: 2.631241892832667

Epoch: 5| Step: 2
Training loss: 2.5163135415556828
Validation loss: 2.6025191781308052

Epoch: 5| Step: 3
Training loss: 1.9330376335897201
Validation loss: 2.585937492068979

Epoch: 5| Step: 4
Training loss: 2.563196320247271
Validation loss: 2.5809061129178734

Epoch: 5| Step: 5
Training loss: 2.2799342293204106
Validation loss: 2.5709031767186414

Epoch: 5| Step: 6
Training loss: 2.3420279725291255
Validation loss: 2.577640573203881

Epoch: 5| Step: 7
Training loss: 2.4392794447217683
Validation loss: 2.5707470323052064

Epoch: 5| Step: 8
Training loss: 2.774816293907635
Validation loss: 2.5485860699983345

Epoch: 5| Step: 9
Training loss: 2.3652898150371873
Validation loss: 2.537926943699143

Epoch: 5| Step: 10
Training loss: 2.7548903418177417
Validation loss: 2.5409088746690585

Epoch: 236| Step: 0
Training loss: 1.7882155366742085
Validation loss: 2.538790113101771

Epoch: 5| Step: 1
Training loss: 2.65329047991142
Validation loss: 2.550078993250788

Epoch: 5| Step: 2
Training loss: 2.2184844596891096
Validation loss: 2.555104014780642

Epoch: 5| Step: 3
Training loss: 2.760419871970181
Validation loss: 2.573835469842274

Epoch: 5| Step: 4
Training loss: 2.656075056710307
Validation loss: 2.5964504001985036

Epoch: 5| Step: 5
Training loss: 2.181834923434327
Validation loss: 2.5643550741999843

Epoch: 5| Step: 6
Training loss: 2.3403672283923544
Validation loss: 2.55796424644663

Epoch: 5| Step: 7
Training loss: 2.604471773711947
Validation loss: 2.5488627478140535

Epoch: 5| Step: 8
Training loss: 2.325244017070492
Validation loss: 2.5470312168637155

Epoch: 5| Step: 9
Training loss: 2.057278815764518
Validation loss: 2.5494255452361574

Epoch: 5| Step: 10
Training loss: 2.6570723214433993
Validation loss: 2.5414911959667212

Epoch: 237| Step: 0
Training loss: 2.022352244257542
Validation loss: 2.515867596220735

Epoch: 5| Step: 1
Training loss: 2.469831784964415
Validation loss: 2.5198153738218148

Epoch: 5| Step: 2
Training loss: 2.2215100167010227
Validation loss: 2.4942040815136233

Epoch: 5| Step: 3
Training loss: 2.6681054723958373
Validation loss: 2.5054509879373157

Epoch: 5| Step: 4
Training loss: 2.2428113753948606
Validation loss: 2.512218691663085

Epoch: 5| Step: 5
Training loss: 2.27967341041525
Validation loss: 2.4741577727794093

Epoch: 5| Step: 6
Training loss: 2.3522109851599784
Validation loss: 2.43341423224121

Epoch: 5| Step: 7
Training loss: 2.5568445647448694
Validation loss: 2.4406475940291026

Epoch: 5| Step: 8
Training loss: 2.8011501606652964
Validation loss: 2.462068615847195

Epoch: 5| Step: 9
Training loss: 2.5534859260931633
Validation loss: 2.465777623259772

Epoch: 5| Step: 10
Training loss: 1.9512447003739188
Validation loss: 2.48337636968014

Epoch: 238| Step: 0
Training loss: 2.8628530559450796
Validation loss: 2.5484163859405315

Epoch: 5| Step: 1
Training loss: 2.690310937715073
Validation loss: 2.597384442068988

Epoch: 5| Step: 2
Training loss: 2.4284386077591655
Validation loss: 2.645121299258517

Epoch: 5| Step: 3
Training loss: 2.7939749232472755
Validation loss: 2.66183289462716

Epoch: 5| Step: 4
Training loss: 2.4830149640643686
Validation loss: 2.6212194430430737

Epoch: 5| Step: 5
Training loss: 2.137696204745131
Validation loss: 2.5585719449810362

Epoch: 5| Step: 6
Training loss: 2.1114573055416015
Validation loss: 2.525010661717237

Epoch: 5| Step: 7
Training loss: 2.218976721127062
Validation loss: 2.5135420553557792

Epoch: 5| Step: 8
Training loss: 2.404016324989123
Validation loss: 2.518684651848156

Epoch: 5| Step: 9
Training loss: 2.3190506609095434
Validation loss: 2.533946562869453

Epoch: 5| Step: 10
Training loss: 2.144690113402315
Validation loss: 2.5303380597801737

Epoch: 239| Step: 0
Training loss: 2.6259645778826557
Validation loss: 2.525706631399943

Epoch: 5| Step: 1
Training loss: 2.6014982564972726
Validation loss: 2.535424429693985

Epoch: 5| Step: 2
Training loss: 2.4595267960309535
Validation loss: 2.52872173158711

Epoch: 5| Step: 3
Training loss: 2.0631947358787923
Validation loss: 2.5636671126136092

Epoch: 5| Step: 4
Training loss: 2.6153879839888408
Validation loss: 2.5421488486250206

Epoch: 5| Step: 5
Training loss: 2.3968396160592564
Validation loss: 2.5459027261770775

Epoch: 5| Step: 6
Training loss: 2.285145399279794
Validation loss: 2.5246709320225906

Epoch: 5| Step: 7
Training loss: 2.4578235119126126
Validation loss: 2.5119580596121227

Epoch: 5| Step: 8
Training loss: 1.8721410571816508
Validation loss: 2.5153810539120958

Epoch: 5| Step: 9
Training loss: 1.9736567311298043
Validation loss: 2.4882904339499463

Epoch: 5| Step: 10
Training loss: 2.2693192453555997
Validation loss: 2.467550756692517

Epoch: 240| Step: 0
Training loss: 2.095598685727669
Validation loss: 2.482049349959261

Epoch: 5| Step: 1
Training loss: 2.6811599467344625
Validation loss: 2.4775456166159584

Epoch: 5| Step: 2
Training loss: 2.13234160538266
Validation loss: 2.484735495886646

Epoch: 5| Step: 3
Training loss: 2.0265022545347136
Validation loss: 2.4887021417546045

Epoch: 5| Step: 4
Training loss: 2.0771401732028827
Validation loss: 2.5055284285179815

Epoch: 5| Step: 5
Training loss: 2.882407224540116
Validation loss: 2.499114820194786

Epoch: 5| Step: 6
Training loss: 2.1587184100995627
Validation loss: 2.5114843979125467

Epoch: 5| Step: 7
Training loss: 2.5201710443123364
Validation loss: 2.5033287990063604

Epoch: 5| Step: 8
Training loss: 2.4269150988075516
Validation loss: 2.5011401150623125

Epoch: 5| Step: 9
Training loss: 2.2652875977888107
Validation loss: 2.511873134121462

Epoch: 5| Step: 10
Training loss: 2.2049565919508924
Validation loss: 2.545452853018341

Epoch: 241| Step: 0
Training loss: 2.0161960000021835
Validation loss: 2.5473867758166757

Epoch: 5| Step: 1
Training loss: 2.46522966317041
Validation loss: 2.5673494749464663

Epoch: 5| Step: 2
Training loss: 2.1912484885698538
Validation loss: 2.562640806782006

Epoch: 5| Step: 3
Training loss: 2.5334561000323284
Validation loss: 2.5277928653870627

Epoch: 5| Step: 4
Training loss: 2.589688533774927
Validation loss: 2.5063506885141185

Epoch: 5| Step: 5
Training loss: 2.022867836904699
Validation loss: 2.510696451367547

Epoch: 5| Step: 6
Training loss: 2.2961027962271823
Validation loss: 2.5234226988448474

Epoch: 5| Step: 7
Training loss: 2.3265115152053943
Validation loss: 2.521008566699286

Epoch: 5| Step: 8
Training loss: 2.5306003820155074
Validation loss: 2.529673460257681

Epoch: 5| Step: 9
Training loss: 1.9366483970257462
Validation loss: 2.515491465491398

Epoch: 5| Step: 10
Training loss: 2.2135525931294358
Validation loss: 2.519508614438023

Epoch: 242| Step: 0
Training loss: 2.136686948996384
Validation loss: 2.488660108730996

Epoch: 5| Step: 1
Training loss: 2.148213544790414
Validation loss: 2.48426284376931

Epoch: 5| Step: 2
Training loss: 2.359487366684747
Validation loss: 2.4805253077731733

Epoch: 5| Step: 3
Training loss: 2.0257231421914037
Validation loss: 2.4883680912678283

Epoch: 5| Step: 4
Training loss: 2.5285482233905436
Validation loss: 2.5058364583856867

Epoch: 5| Step: 5
Training loss: 2.229280973932197
Validation loss: 2.4967152335374116

Epoch: 5| Step: 6
Training loss: 2.44744117393365
Validation loss: 2.516631669747364

Epoch: 5| Step: 7
Training loss: 1.8273528987268977
Validation loss: 2.4952721056194482

Epoch: 5| Step: 8
Training loss: 2.493983372067694
Validation loss: 2.480668972474957

Epoch: 5| Step: 9
Training loss: 2.282307418938346
Validation loss: 2.4832272862358864

Epoch: 5| Step: 10
Training loss: 2.3005651816187926
Validation loss: 2.466436634282395

Epoch: 243| Step: 0
Training loss: 2.383183284740087
Validation loss: 2.462542435658481

Epoch: 5| Step: 1
Training loss: 2.5136409541246025
Validation loss: 2.451947408927334

Epoch: 5| Step: 2
Training loss: 1.7937157099300678
Validation loss: 2.4634883340390985

Epoch: 5| Step: 3
Training loss: 2.5392658797752783
Validation loss: 2.4608179477782564

Epoch: 5| Step: 4
Training loss: 2.4410098310973507
Validation loss: 2.472482808646614

Epoch: 5| Step: 5
Training loss: 1.5538576297815612
Validation loss: 2.471045960607601

Epoch: 5| Step: 6
Training loss: 2.33969029096883
Validation loss: 2.484795904463277

Epoch: 5| Step: 7
Training loss: 2.4928515276101977
Validation loss: 2.4991925637913908

Epoch: 5| Step: 8
Training loss: 2.3054313881566824
Validation loss: 2.5224354143959404

Epoch: 5| Step: 9
Training loss: 1.931313759945667
Validation loss: 2.5471125293850485

Epoch: 5| Step: 10
Training loss: 2.2421353962124435
Validation loss: 2.57344047917346

Epoch: 244| Step: 0
Training loss: 2.3700017032536693
Validation loss: 2.5936284546407387

Epoch: 5| Step: 1
Training loss: 2.1244462357575133
Validation loss: 2.6146637533602872

Epoch: 5| Step: 2
Training loss: 2.0612324374198505
Validation loss: 2.5720858973669922

Epoch: 5| Step: 3
Training loss: 1.9740508031868436
Validation loss: 2.567059276354167

Epoch: 5| Step: 4
Training loss: 2.088632735425549
Validation loss: 2.5482583244152197

Epoch: 5| Step: 5
Training loss: 2.2374629310648713
Validation loss: 2.4996226836105104

Epoch: 5| Step: 6
Training loss: 2.1602564645323277
Validation loss: 2.4963550576243216

Epoch: 5| Step: 7
Training loss: 2.4089492916535833
Validation loss: 2.48132859464062

Epoch: 5| Step: 8
Training loss: 2.061365913939673
Validation loss: 2.4922842471873046

Epoch: 5| Step: 9
Training loss: 2.5085401578612
Validation loss: 2.494538260002681

Epoch: 5| Step: 10
Training loss: 2.5946462530500756
Validation loss: 2.516953773871177

Epoch: 245| Step: 0
Training loss: 2.192370197625177
Validation loss: 2.541132289953783

Epoch: 5| Step: 1
Training loss: 2.1482719218865687
Validation loss: 2.5530029063243056

Epoch: 5| Step: 2
Training loss: 2.155785109672788
Validation loss: 2.582899961994518

Epoch: 5| Step: 3
Training loss: 2.4704485494463198
Validation loss: 2.5848159511668203

Epoch: 5| Step: 4
Training loss: 2.050715563494162
Validation loss: 2.593646175294682

Epoch: 5| Step: 5
Training loss: 2.548713348259843
Validation loss: 2.59109180081004

Epoch: 5| Step: 6
Training loss: 1.9746618971362437
Validation loss: 2.5642553250576263

Epoch: 5| Step: 7
Training loss: 1.9436277884673647
Validation loss: 2.5238611862574603

Epoch: 5| Step: 8
Training loss: 1.750427738776085
Validation loss: 2.4801806004034117

Epoch: 5| Step: 9
Training loss: 2.307641467121266
Validation loss: 2.4565086138215073

Epoch: 5| Step: 10
Training loss: 2.6624282791435436
Validation loss: 2.4561721471293483

Epoch: 246| Step: 0
Training loss: 1.9492895690651408
Validation loss: 2.425433042549577

Epoch: 5| Step: 1
Training loss: 1.846392661169994
Validation loss: 2.4001698315940945

Epoch: 5| Step: 2
Training loss: 2.0839421590660243
Validation loss: 2.4303708697663136

Epoch: 5| Step: 3
Training loss: 2.599613502092188
Validation loss: 2.4536582670749314

Epoch: 5| Step: 4
Training loss: 2.274840141800265
Validation loss: 2.486159260952803

Epoch: 5| Step: 5
Training loss: 2.08872154266678
Validation loss: 2.5438279078433452

Epoch: 5| Step: 6
Training loss: 2.2677797791337566
Validation loss: 2.5712992879726864

Epoch: 5| Step: 7
Training loss: 2.3751360201785
Validation loss: 2.6172958025917783

Epoch: 5| Step: 8
Training loss: 2.4178628482336735
Validation loss: 2.6411651507408735

Epoch: 5| Step: 9
Training loss: 1.947942526198585
Validation loss: 2.6180909925088964

Epoch: 5| Step: 10
Training loss: 2.439956894009155
Validation loss: 2.5953955749648574

Epoch: 247| Step: 0
Training loss: 2.0386276073660174
Validation loss: 2.5171812839985983

Epoch: 5| Step: 1
Training loss: 2.5545359341984852
Validation loss: 2.4887451330857084

Epoch: 5| Step: 2
Training loss: 2.0572825242495303
Validation loss: 2.443027132258197

Epoch: 5| Step: 3
Training loss: 1.9181172299841416
Validation loss: 2.412600139027535

Epoch: 5| Step: 4
Training loss: 2.2465461076410884
Validation loss: 2.411921760656323

Epoch: 5| Step: 5
Training loss: 1.7013172039405444
Validation loss: 2.3881074895018015

Epoch: 5| Step: 6
Training loss: 2.571032947805448
Validation loss: 2.4251245478302272

Epoch: 5| Step: 7
Training loss: 2.4909005504466806
Validation loss: 2.426044678281435

Epoch: 5| Step: 8
Training loss: 1.6596157495600432
Validation loss: 2.4463962990487844

Epoch: 5| Step: 9
Training loss: 2.4868595966668354
Validation loss: 2.458585818634748

Epoch: 5| Step: 10
Training loss: 2.0525593342725146
Validation loss: 2.498658921878728

Epoch: 248| Step: 0
Training loss: 2.228481496404149
Validation loss: 2.537142828999032

Epoch: 5| Step: 1
Training loss: 2.283579225131813
Validation loss: 2.6219808303860512

Epoch: 5| Step: 2
Training loss: 2.0956405530762554
Validation loss: 2.657198143770699

Epoch: 5| Step: 3
Training loss: 2.5302925653886708
Validation loss: 2.6905608760009017

Epoch: 5| Step: 4
Training loss: 1.6677876358508954
Validation loss: 2.685652978376547

Epoch: 5| Step: 5
Training loss: 2.213018401885199
Validation loss: 2.6462649788716113

Epoch: 5| Step: 6
Training loss: 2.463071061738938
Validation loss: 2.641126317756546

Epoch: 5| Step: 7
Training loss: 2.134712351197973
Validation loss: 2.6044195460112216

Epoch: 5| Step: 8
Training loss: 2.3622748131378883
Validation loss: 2.5343217713677393

Epoch: 5| Step: 9
Training loss: 2.1431668080512463
Validation loss: 2.4934834477666596

Epoch: 5| Step: 10
Training loss: 2.0997414338920115
Validation loss: 2.444187490386724

Epoch: 249| Step: 0
Training loss: 2.1562268905506987
Validation loss: 2.40530818262135

Epoch: 5| Step: 1
Training loss: 2.6427111990410275
Validation loss: 2.391224478679926

Epoch: 5| Step: 2
Training loss: 2.4252376715214323
Validation loss: 2.387632977635592

Epoch: 5| Step: 3
Training loss: 2.112131648707283
Validation loss: 2.3980934575317243

Epoch: 5| Step: 4
Training loss: 2.562935675824086
Validation loss: 2.4131036793634624

Epoch: 5| Step: 5
Training loss: 1.8455937751792366
Validation loss: 2.4299740020483402

Epoch: 5| Step: 6
Training loss: 2.053069779627456
Validation loss: 2.4580028072580014

Epoch: 5| Step: 7
Training loss: 1.8915228485131084
Validation loss: 2.5269737010147497

Epoch: 5| Step: 8
Training loss: 2.535382982174979
Validation loss: 2.5622872214987313

Epoch: 5| Step: 9
Training loss: 1.9439297093175607
Validation loss: 2.6020235141387404

Epoch: 5| Step: 10
Training loss: 1.7727762745707045
Validation loss: 2.61404048329163

Epoch: 250| Step: 0
Training loss: 1.7420415432265175
Validation loss: 2.616135436617772

Epoch: 5| Step: 1
Training loss: 2.169996588216464
Validation loss: 2.6178120518834374

Epoch: 5| Step: 2
Training loss: 1.773700240917827
Validation loss: 2.582857858947536

Epoch: 5| Step: 3
Training loss: 1.9464808865737353
Validation loss: 2.5524337193182185

Epoch: 5| Step: 4
Training loss: 2.5577536565109273
Validation loss: 2.5409511421053077

Epoch: 5| Step: 5
Training loss: 1.4227700403196666
Validation loss: 2.533974904993228

Epoch: 5| Step: 6
Training loss: 2.2034454112708213
Validation loss: 2.5050457093687717

Epoch: 5| Step: 7
Training loss: 2.195417299857573
Validation loss: 2.4854786545162115

Epoch: 5| Step: 8
Training loss: 2.446766576398804
Validation loss: 2.4729512237377125

Epoch: 5| Step: 9
Training loss: 2.4510891965015356
Validation loss: 2.434908263893284

Epoch: 5| Step: 10
Training loss: 2.256624113646158
Validation loss: 2.435911931777605

Epoch: 251| Step: 0
Training loss: 2.0060605966880036
Validation loss: 2.413547154884596

Epoch: 5| Step: 1
Training loss: 2.128189946330532
Validation loss: 2.4021419269293673

Epoch: 5| Step: 2
Training loss: 2.2873335939342527
Validation loss: 2.398214057437961

Epoch: 5| Step: 3
Training loss: 1.7153346026124692
Validation loss: 2.3967291524628105

Epoch: 5| Step: 4
Training loss: 2.2597489550081984
Validation loss: 2.3965187811420674

Epoch: 5| Step: 5
Training loss: 2.0441151424010013
Validation loss: 2.4138348143456874

Epoch: 5| Step: 6
Training loss: 1.877535440895225
Validation loss: 2.4403299443093487

Epoch: 5| Step: 7
Training loss: 2.0553551811065915
Validation loss: 2.46155442986804

Epoch: 5| Step: 8
Training loss: 2.2229869308259107
Validation loss: 2.4952566586242395

Epoch: 5| Step: 9
Training loss: 2.3640114404946933
Validation loss: 2.5151743489345066

Epoch: 5| Step: 10
Training loss: 2.228148741950066
Validation loss: 2.526242070335373

Epoch: 252| Step: 0
Training loss: 1.7776366946082032
Validation loss: 2.5080848780794884

Epoch: 5| Step: 1
Training loss: 2.0842238112583447
Validation loss: 2.4822439272574317

Epoch: 5| Step: 2
Training loss: 1.7659587038380877
Validation loss: 2.495175683366306

Epoch: 5| Step: 3
Training loss: 2.273611370136627
Validation loss: 2.4881201410671023

Epoch: 5| Step: 4
Training loss: 2.135249495747074
Validation loss: 2.4829954327359878

Epoch: 5| Step: 5
Training loss: 1.9831184553969503
Validation loss: 2.5041097086363693

Epoch: 5| Step: 6
Training loss: 2.237883474212371
Validation loss: 2.505464916040281

Epoch: 5| Step: 7
Training loss: 2.5925790372625337
Validation loss: 2.5208776858753636

Epoch: 5| Step: 8
Training loss: 1.7595646920264185
Validation loss: 2.5280490934578594

Epoch: 5| Step: 9
Training loss: 2.0292458844502077
Validation loss: 2.5175465036446116

Epoch: 5| Step: 10
Training loss: 2.107357614578659
Validation loss: 2.5042140453413597

Epoch: 253| Step: 0
Training loss: 1.4230558082536824
Validation loss: 2.490867445933945

Epoch: 5| Step: 1
Training loss: 1.8979078268214469
Validation loss: 2.491902019258642

Epoch: 5| Step: 2
Training loss: 2.3259144984149285
Validation loss: 2.480068947066524

Epoch: 5| Step: 3
Training loss: 2.3205888885392465
Validation loss: 2.4737164620176597

Epoch: 5| Step: 4
Training loss: 1.9384648166560072
Validation loss: 2.4716597855139915

Epoch: 5| Step: 5
Training loss: 1.9889659489574125
Validation loss: 2.4929265907080755

Epoch: 5| Step: 6
Training loss: 2.459114101584515
Validation loss: 2.5072073748349366

Epoch: 5| Step: 7
Training loss: 2.0431683007077734
Validation loss: 2.5205403273507065

Epoch: 5| Step: 8
Training loss: 2.058067182046755
Validation loss: 2.5040629473547327

Epoch: 5| Step: 9
Training loss: 2.06912946188524
Validation loss: 2.508083423558665

Epoch: 5| Step: 10
Training loss: 1.8306726163881828
Validation loss: 2.4897959951247532

Epoch: 254| Step: 0
Training loss: 2.024982819660916
Validation loss: 2.480495656792644

Epoch: 5| Step: 1
Training loss: 2.1618923502190266
Validation loss: 2.465696685300831

Epoch: 5| Step: 2
Training loss: 2.417161748313709
Validation loss: 2.455765104480518

Epoch: 5| Step: 3
Training loss: 1.638638192559264
Validation loss: 2.464902449472278

Epoch: 5| Step: 4
Training loss: 2.176233323420609
Validation loss: 2.4720708190327216

Epoch: 5| Step: 5
Training loss: 2.2733568524610455
Validation loss: 2.4706141312392913

Epoch: 5| Step: 6
Training loss: 1.4367710421381883
Validation loss: 2.4949193282939075

Epoch: 5| Step: 7
Training loss: 2.368438692194519
Validation loss: 2.503541127420901

Epoch: 5| Step: 8
Training loss: 2.1831739974181925
Validation loss: 2.515466587115988

Epoch: 5| Step: 9
Training loss: 1.8127879210043591
Validation loss: 2.5179744809315427

Epoch: 5| Step: 10
Training loss: 1.446377006499699
Validation loss: 2.5438277465971724

Epoch: 255| Step: 0
Training loss: 2.070788634628223
Validation loss: 2.542362685365893

Epoch: 5| Step: 1
Training loss: 1.5548250530484637
Validation loss: 2.489901853651596

Epoch: 5| Step: 2
Training loss: 2.2892548672302633
Validation loss: 2.4746155059096457

Epoch: 5| Step: 3
Training loss: 1.8290180731037384
Validation loss: 2.4658848034573957

Epoch: 5| Step: 4
Training loss: 1.8307156587177433
Validation loss: 2.4407125474048113

Epoch: 5| Step: 5
Training loss: 1.754084724572272
Validation loss: 2.4107716201689504

Epoch: 5| Step: 6
Training loss: 1.857576734824133
Validation loss: 2.3968937132762496

Epoch: 5| Step: 7
Training loss: 2.10716878168447
Validation loss: 2.4195057172455603

Epoch: 5| Step: 8
Training loss: 2.031973607214789
Validation loss: 2.422468509519982

Epoch: 5| Step: 9
Training loss: 2.486037843454547
Validation loss: 2.418775091337628

Epoch: 5| Step: 10
Training loss: 2.3696234227637203
Validation loss: 2.446748187499559

Epoch: 256| Step: 0
Training loss: 2.15811529887052
Validation loss: 2.479480147265377

Epoch: 5| Step: 1
Training loss: 2.066932423742399
Validation loss: 2.4940168134941945

Epoch: 5| Step: 2
Training loss: 1.947138959156865
Validation loss: 2.5472045620791826

Epoch: 5| Step: 3
Training loss: 2.059300339406182
Validation loss: 2.5640094572198118

Epoch: 5| Step: 4
Training loss: 2.337733978148046
Validation loss: 2.537503890507325

Epoch: 5| Step: 5
Training loss: 1.9993159197097414
Validation loss: 2.532367938986256

Epoch: 5| Step: 6
Training loss: 1.379727300154102
Validation loss: 2.5084184347699634

Epoch: 5| Step: 7
Training loss: 2.055965591751314
Validation loss: 2.504749976499912

Epoch: 5| Step: 8
Training loss: 1.6656339863432759
Validation loss: 2.485910255111283

Epoch: 5| Step: 9
Training loss: 2.1932500198835605
Validation loss: 2.473474128285117

Epoch: 5| Step: 10
Training loss: 2.1803717957621647
Validation loss: 2.4554201728860905

Epoch: 257| Step: 0
Training loss: 2.1455951546144214
Validation loss: 2.4512413959933976

Epoch: 5| Step: 1
Training loss: 2.350005689573502
Validation loss: 2.492204054345018

Epoch: 5| Step: 2
Training loss: 2.1222527641020448
Validation loss: 2.4981151992457122

Epoch: 5| Step: 3
Training loss: 1.590831103209259
Validation loss: 2.5038067097184595

Epoch: 5| Step: 4
Training loss: 1.836713521374749
Validation loss: 2.486362379803958

Epoch: 5| Step: 5
Training loss: 1.9245533462151623
Validation loss: 2.4650849104322186

Epoch: 5| Step: 6
Training loss: 1.5835000084267832
Validation loss: 2.444460180408446

Epoch: 5| Step: 7
Training loss: 2.1273048467367595
Validation loss: 2.4598999836576487

Epoch: 5| Step: 8
Training loss: 2.0555594447102
Validation loss: 2.4844703441900604

Epoch: 5| Step: 9
Training loss: 2.0397993488366457
Validation loss: 2.474912465961979

Epoch: 5| Step: 10
Training loss: 2.008435223264874
Validation loss: 2.4650309582450447

Epoch: 258| Step: 0
Training loss: 1.9388072003326287
Validation loss: 2.4669939584226155

Epoch: 5| Step: 1
Training loss: 2.0889120431500543
Validation loss: 2.487483627439421

Epoch: 5| Step: 2
Training loss: 2.1626057593442964
Validation loss: 2.493642010117365

Epoch: 5| Step: 3
Training loss: 2.3164201449770334
Validation loss: 2.487833224950666

Epoch: 5| Step: 4
Training loss: 1.955693806321394
Validation loss: 2.488467533108941

Epoch: 5| Step: 5
Training loss: 1.8674639253821639
Validation loss: 2.4871083415073816

Epoch: 5| Step: 6
Training loss: 1.9248147206502206
Validation loss: 2.5126824784258686

Epoch: 5| Step: 7
Training loss: 1.4722341241095545
Validation loss: 2.5362442123987576

Epoch: 5| Step: 8
Training loss: 1.9256906236599267
Validation loss: 2.546113167087077

Epoch: 5| Step: 9
Training loss: 1.9873527952177772
Validation loss: 2.5523630142570948

Epoch: 5| Step: 10
Training loss: 2.088664583186671
Validation loss: 2.5456170627473504

Epoch: 259| Step: 0
Training loss: 1.8905118167510915
Validation loss: 2.518965371170748

Epoch: 5| Step: 1
Training loss: 2.0725857903517335
Validation loss: 2.5075999362080656

Epoch: 5| Step: 2
Training loss: 1.8361137792491267
Validation loss: 2.479153408085056

Epoch: 5| Step: 3
Training loss: 1.9765404862093967
Validation loss: 2.4655648709414186

Epoch: 5| Step: 4
Training loss: 2.237274422809268
Validation loss: 2.4809531361196773

Epoch: 5| Step: 5
Training loss: 1.9781598659052118
Validation loss: 2.413573666949499

Epoch: 5| Step: 6
Training loss: 1.563540608072992
Validation loss: 2.427310600416004

Epoch: 5| Step: 7
Training loss: 1.5878804149041366
Validation loss: 2.404065723283065

Epoch: 5| Step: 8
Training loss: 2.232562096598264
Validation loss: 2.407931108804713

Epoch: 5| Step: 9
Training loss: 2.2026201034862964
Validation loss: 2.4244201169381703

Epoch: 5| Step: 10
Training loss: 1.6965164620713533
Validation loss: 2.4243545293115973

Epoch: 260| Step: 0
Training loss: 2.520812000363041
Validation loss: 2.46520989629948

Epoch: 5| Step: 1
Training loss: 1.7877454949238052
Validation loss: 2.4900651056201135

Epoch: 5| Step: 2
Training loss: 2.286204875085669
Validation loss: 2.5161258538018094

Epoch: 5| Step: 3
Training loss: 2.002026723113614
Validation loss: 2.5254677688402203

Epoch: 5| Step: 4
Training loss: 1.5475004068599036
Validation loss: 2.534109295601158

Epoch: 5| Step: 5
Training loss: 1.61471471764667
Validation loss: 2.5039963784637047

Epoch: 5| Step: 6
Training loss: 1.8339675398796331
Validation loss: 2.4872126616512857

Epoch: 5| Step: 7
Training loss: 1.9436127003938002
Validation loss: 2.4833322159023488

Epoch: 5| Step: 8
Training loss: 1.7884095178868327
Validation loss: 2.46429610345199

Epoch: 5| Step: 9
Training loss: 1.6448917673327366
Validation loss: 2.4752363688508825

Epoch: 5| Step: 10
Training loss: 2.045515001732926
Validation loss: 2.4885955270536697

Epoch: 261| Step: 0
Training loss: 2.283143603199236
Validation loss: 2.493286152959138

Epoch: 5| Step: 1
Training loss: 1.5410288530949596
Validation loss: 2.498180902754206

Epoch: 5| Step: 2
Training loss: 1.808793256726153
Validation loss: 2.511883071772831

Epoch: 5| Step: 3
Training loss: 1.9539228716985615
Validation loss: 2.5466039329515584

Epoch: 5| Step: 4
Training loss: 1.8725792835191746
Validation loss: 2.550389141170494

Epoch: 5| Step: 5
Training loss: 2.0958927634011935
Validation loss: 2.573638338196806

Epoch: 5| Step: 6
Training loss: 1.7214247957899365
Validation loss: 2.5248882675101374

Epoch: 5| Step: 7
Training loss: 1.7547294197272407
Validation loss: 2.511316517965746

Epoch: 5| Step: 8
Training loss: 2.4341377152450856
Validation loss: 2.5033975648595432

Epoch: 5| Step: 9
Training loss: 1.7477825284584658
Validation loss: 2.4887391245420134

Epoch: 5| Step: 10
Training loss: 1.6710563865932448
Validation loss: 2.4807178493999094

Epoch: 262| Step: 0
Training loss: 1.755023965481749
Validation loss: 2.4639402478703594

Epoch: 5| Step: 1
Training loss: 2.04268747877038
Validation loss: 2.4575798645168074

Epoch: 5| Step: 2
Training loss: 1.8335211903242465
Validation loss: 2.452926126056408

Epoch: 5| Step: 3
Training loss: 2.1354783832346445
Validation loss: 2.4682486686963236

Epoch: 5| Step: 4
Training loss: 1.7756888597573224
Validation loss: 2.454877494027912

Epoch: 5| Step: 5
Training loss: 1.9818825274624965
Validation loss: 2.472396441139564

Epoch: 5| Step: 6
Training loss: 1.8969575113013515
Validation loss: 2.4485017627502317

Epoch: 5| Step: 7
Training loss: 1.9517636857430645
Validation loss: 2.434486684246453

Epoch: 5| Step: 8
Training loss: 2.054738323322837
Validation loss: 2.4157534632390734

Epoch: 5| Step: 9
Training loss: 2.019385563153639
Validation loss: 2.423956286819684

Epoch: 5| Step: 10
Training loss: 1.4989928997296622
Validation loss: 2.4433186814092784

Epoch: 263| Step: 0
Training loss: 2.053240480470344
Validation loss: 2.478597083514309

Epoch: 5| Step: 1
Training loss: 1.6492296819356198
Validation loss: 2.4650209653518953

Epoch: 5| Step: 2
Training loss: 1.5964310478710597
Validation loss: 2.525008113315624

Epoch: 5| Step: 3
Training loss: 2.406597954499174
Validation loss: 2.552913185461

Epoch: 5| Step: 4
Training loss: 1.9590637251813146
Validation loss: 2.579081324472585

Epoch: 5| Step: 5
Training loss: 2.377774174361702
Validation loss: 2.5492625351817666

Epoch: 5| Step: 6
Training loss: 1.704790962918664
Validation loss: 2.562677329765933

Epoch: 5| Step: 7
Training loss: 1.5293024874178622
Validation loss: 2.4988724668008158

Epoch: 5| Step: 8
Training loss: 2.024736260087372
Validation loss: 2.484410303305765

Epoch: 5| Step: 9
Training loss: 1.8059285178079127
Validation loss: 2.4564904194312636

Epoch: 5| Step: 10
Training loss: 1.4733151851301565
Validation loss: 2.4585796613077213

Epoch: 264| Step: 0
Training loss: 2.011352031578282
Validation loss: 2.4543615114008035

Epoch: 5| Step: 1
Training loss: 1.7163180398477609
Validation loss: 2.461712196402218

Epoch: 5| Step: 2
Training loss: 1.9236592020143237
Validation loss: 2.458934214804786

Epoch: 5| Step: 3
Training loss: 2.2573362065879228
Validation loss: 2.4677143357106344

Epoch: 5| Step: 4
Training loss: 1.3819157338101962
Validation loss: 2.4770995929557333

Epoch: 5| Step: 5
Training loss: 1.8843512993835638
Validation loss: 2.4653942644682854

Epoch: 5| Step: 6
Training loss: 1.841782053041334
Validation loss: 2.504864989950927

Epoch: 5| Step: 7
Training loss: 1.5079391505362445
Validation loss: 2.531655707863749

Epoch: 5| Step: 8
Training loss: 2.2112121411452574
Validation loss: 2.5532244450184733

Epoch: 5| Step: 9
Training loss: 2.1226432297257785
Validation loss: 2.5557870963581877

Epoch: 5| Step: 10
Training loss: 1.4211679733882954
Validation loss: 2.518094908276416

Epoch: 265| Step: 0
Training loss: 2.120691981473416
Validation loss: 2.519994782523636

Epoch: 5| Step: 1
Training loss: 1.9364752982307725
Validation loss: 2.5018242507282187

Epoch: 5| Step: 2
Training loss: 1.6936954925887948
Validation loss: 2.517925821702452

Epoch: 5| Step: 3
Training loss: 2.014496835023955
Validation loss: 2.5463027054436815

Epoch: 5| Step: 4
Training loss: 1.8622548857312555
Validation loss: 2.5500624255542466

Epoch: 5| Step: 5
Training loss: 1.9642234718072398
Validation loss: 2.5435442459095934

Epoch: 5| Step: 6
Training loss: 2.216801822337541
Validation loss: 2.521357618494522

Epoch: 5| Step: 7
Training loss: 1.3845343349548556
Validation loss: 2.504554209975471

Epoch: 5| Step: 8
Training loss: 1.8975664188988723
Validation loss: 2.4954601557430087

Epoch: 5| Step: 9
Training loss: 1.6011243267309563
Validation loss: 2.430898173707533

Epoch: 5| Step: 10
Training loss: 1.3935328310112618
Validation loss: 2.4321573465457442

Epoch: 266| Step: 0
Training loss: 1.730653498929151
Validation loss: 2.4299561164414967

Epoch: 5| Step: 1
Training loss: 2.365384967271923
Validation loss: 2.442175747138205

Epoch: 5| Step: 2
Training loss: 2.0763859176472725
Validation loss: 2.4648410884276677

Epoch: 5| Step: 3
Training loss: 1.976383125700076
Validation loss: 2.4966975744760265

Epoch: 5| Step: 4
Training loss: 1.5269782758365322
Validation loss: 2.512164507250219

Epoch: 5| Step: 5
Training loss: 2.235309752093695
Validation loss: 2.5218308865853207

Epoch: 5| Step: 6
Training loss: 1.3453786428321233
Validation loss: 2.516133852029312

Epoch: 5| Step: 7
Training loss: 1.4969562803113436
Validation loss: 2.5289696514731337

Epoch: 5| Step: 8
Training loss: 1.877763364888292
Validation loss: 2.532859640882252

Epoch: 5| Step: 9
Training loss: 1.6297841439343133
Validation loss: 2.547697528198637

Epoch: 5| Step: 10
Training loss: 1.4574706205151846
Validation loss: 2.535580705954673

Epoch: 267| Step: 0
Training loss: 1.8086601887769844
Validation loss: 2.5180103068486113

Epoch: 5| Step: 1
Training loss: 2.08610939717748
Validation loss: 2.530183103157119

Epoch: 5| Step: 2
Training loss: 2.1479049854966097
Validation loss: 2.522104436241207

Epoch: 5| Step: 3
Training loss: 2.0263584807794874
Validation loss: 2.493927426343231

Epoch: 5| Step: 4
Training loss: 2.0366596665498813
Validation loss: 2.474972156157973

Epoch: 5| Step: 5
Training loss: 1.743740740789079
Validation loss: 2.4440388517421243

Epoch: 5| Step: 6
Training loss: 1.9022879778384403
Validation loss: 2.4174418788434

Epoch: 5| Step: 7
Training loss: 1.6971213539535603
Validation loss: 2.4096054591514173

Epoch: 5| Step: 8
Training loss: 1.5008598882912476
Validation loss: 2.4141019260484256

Epoch: 5| Step: 9
Training loss: 1.627300468085346
Validation loss: 2.438746849411188

Epoch: 5| Step: 10
Training loss: 1.02213174936726
Validation loss: 2.476955751243016

Epoch: 268| Step: 0
Training loss: 1.7250995911307434
Validation loss: 2.4960931424933226

Epoch: 5| Step: 1
Training loss: 1.9080615581682687
Validation loss: 2.508797439725154

Epoch: 5| Step: 2
Training loss: 1.9273880451309415
Validation loss: 2.5516467623623096

Epoch: 5| Step: 3
Training loss: 1.9691334911021217
Validation loss: 2.5455332511432247

Epoch: 5| Step: 4
Training loss: 1.4164868221942453
Validation loss: 2.5680879217761365

Epoch: 5| Step: 5
Training loss: 1.2670659469085686
Validation loss: 2.569281317260714

Epoch: 5| Step: 6
Training loss: 1.9536701509702488
Validation loss: 2.5603511653504385

Epoch: 5| Step: 7
Training loss: 2.2439988957230677
Validation loss: 2.566914229672138

Epoch: 5| Step: 8
Training loss: 1.2716056426035582
Validation loss: 2.5187046016094023

Epoch: 5| Step: 9
Training loss: 2.0174468331026105
Validation loss: 2.4664781828161697

Epoch: 5| Step: 10
Training loss: 1.6563702665604931
Validation loss: 2.466029618399042

Epoch: 269| Step: 0
Training loss: 1.8189831902103164
Validation loss: 2.447613953510745

Epoch: 5| Step: 1
Training loss: 1.8145968048728514
Validation loss: 2.4506181090816197

Epoch: 5| Step: 2
Training loss: 1.6670781422351248
Validation loss: 2.4445243256376386

Epoch: 5| Step: 3
Training loss: 1.6698680489771858
Validation loss: 2.4485212247589887

Epoch: 5| Step: 4
Training loss: 1.1115010266146979
Validation loss: 2.44777174926289

Epoch: 5| Step: 5
Training loss: 2.1174714858692285
Validation loss: 2.4395772214592832

Epoch: 5| Step: 6
Training loss: 1.560494547361695
Validation loss: 2.456050868216811

Epoch: 5| Step: 7
Training loss: 1.6538020343047877
Validation loss: 2.458674588788768

Epoch: 5| Step: 8
Training loss: 1.9721605339014041
Validation loss: 2.484943141508373

Epoch: 5| Step: 9
Training loss: 2.2490751696992075
Validation loss: 2.484820398665088

Epoch: 5| Step: 10
Training loss: 1.6928592634159025
Validation loss: 2.4691138850209344

Epoch: 270| Step: 0
Training loss: 1.5705997337194382
Validation loss: 2.4965019169016904

Epoch: 5| Step: 1
Training loss: 2.041107905733825
Validation loss: 2.4877638753292994

Epoch: 5| Step: 2
Training loss: 1.945877667180001
Validation loss: 2.520500727282617

Epoch: 5| Step: 3
Training loss: 1.5014791348405245
Validation loss: 2.539500588611676

Epoch: 5| Step: 4
Training loss: 1.843444152292347
Validation loss: 2.5093249339831583

Epoch: 5| Step: 5
Training loss: 1.4107791866735668
Validation loss: 2.499434862556882

Epoch: 5| Step: 6
Training loss: 1.5884876513026673
Validation loss: 2.509058213109074

Epoch: 5| Step: 7
Training loss: 1.8460171225550313
Validation loss: 2.5265284632579834

Epoch: 5| Step: 8
Training loss: 1.8271777967727407
Validation loss: 2.5256080477696385

Epoch: 5| Step: 9
Training loss: 1.8635469962893747
Validation loss: 2.519328419116684

Epoch: 5| Step: 10
Training loss: 1.9174242042969085
Validation loss: 2.5206087568849553

Epoch: 271| Step: 0
Training loss: 1.6590210388026854
Validation loss: 2.527123989132609

Epoch: 5| Step: 1
Training loss: 1.4157718001284891
Validation loss: 2.5387424718510183

Epoch: 5| Step: 2
Training loss: 1.9183586641037296
Validation loss: 2.5579134434557496

Epoch: 5| Step: 3
Training loss: 1.738758835924351
Validation loss: 2.582054237989557

Epoch: 5| Step: 4
Training loss: 1.9147662056420038
Validation loss: 2.575522594504597

Epoch: 5| Step: 5
Training loss: 1.722779353926754
Validation loss: 2.5433691805944503

Epoch: 5| Step: 6
Training loss: 1.790180906179419
Validation loss: 2.52614853716076

Epoch: 5| Step: 7
Training loss: 1.5955760442961389
Validation loss: 2.4677980170324068

Epoch: 5| Step: 8
Training loss: 1.1569878569405074
Validation loss: 2.4308726178249693

Epoch: 5| Step: 9
Training loss: 2.1503333032990724
Validation loss: 2.4088264557304084

Epoch: 5| Step: 10
Training loss: 2.096565744531418
Validation loss: 2.396028756994427

Epoch: 272| Step: 0
Training loss: 1.7207211375511524
Validation loss: 2.4083800400283506

Epoch: 5| Step: 1
Training loss: 1.644696732483728
Validation loss: 2.421819455888929

Epoch: 5| Step: 2
Training loss: 1.9334714292117494
Validation loss: 2.4001744511568157

Epoch: 5| Step: 3
Training loss: 1.754539460402396
Validation loss: 2.419639486638243

Epoch: 5| Step: 4
Training loss: 1.793919197104244
Validation loss: 2.4646885154117486

Epoch: 5| Step: 5
Training loss: 1.8891751113027535
Validation loss: 2.4831438481887758

Epoch: 5| Step: 6
Training loss: 1.916996291744524
Validation loss: 2.5058603346286525

Epoch: 5| Step: 7
Training loss: 1.189912954560863
Validation loss: 2.53867794283089

Epoch: 5| Step: 8
Training loss: 1.600421703913014
Validation loss: 2.5474116745574524

Epoch: 5| Step: 9
Training loss: 1.4854560529383498
Validation loss: 2.544367745059608

Epoch: 5| Step: 10
Training loss: 2.1359461306304808
Validation loss: 2.5473835231924955

Epoch: 273| Step: 0
Training loss: 1.8221234003397448
Validation loss: 2.533068327031104

Epoch: 5| Step: 1
Training loss: 1.51434728504975
Validation loss: 2.541264049394206

Epoch: 5| Step: 2
Training loss: 1.264363401834013
Validation loss: 2.4903105160620043

Epoch: 5| Step: 3
Training loss: 1.546568714991885
Validation loss: 2.5225868387573485

Epoch: 5| Step: 4
Training loss: 1.4537450636487155
Validation loss: 2.4967859481091415

Epoch: 5| Step: 5
Training loss: 1.9498515659471838
Validation loss: 2.4640658296912723

Epoch: 5| Step: 6
Training loss: 2.2045572373523106
Validation loss: 2.430755456496507

Epoch: 5| Step: 7
Training loss: 1.497957110046893
Validation loss: 2.3877900775740932

Epoch: 5| Step: 8
Training loss: 2.0719096231228717
Validation loss: 2.4036565856902854

Epoch: 5| Step: 9
Training loss: 1.7014357562540856
Validation loss: 2.42541494588218

Epoch: 5| Step: 10
Training loss: 1.9100070887329215
Validation loss: 2.416442704952788

Epoch: 274| Step: 0
Training loss: 2.1671718473082335
Validation loss: 2.453720443753443

Epoch: 5| Step: 1
Training loss: 1.6064040529465935
Validation loss: 2.4378976200468854

Epoch: 5| Step: 2
Training loss: 1.8955736576300206
Validation loss: 2.511043063145997

Epoch: 5| Step: 3
Training loss: 1.6261398279283905
Validation loss: 2.543801416975618

Epoch: 5| Step: 4
Training loss: 1.5985530956901621
Validation loss: 2.5641310378454665

Epoch: 5| Step: 5
Training loss: 1.3845703676029752
Validation loss: 2.5773420858546126

Epoch: 5| Step: 6
Training loss: 2.246536343961248
Validation loss: 2.56204473901816

Epoch: 5| Step: 7
Training loss: 1.5085246721727672
Validation loss: 2.518724069777642

Epoch: 5| Step: 8
Training loss: 1.8351076239017945
Validation loss: 2.4695531738758105

Epoch: 5| Step: 9
Training loss: 1.380109829056655
Validation loss: 2.4453122127411833

Epoch: 5| Step: 10
Training loss: 1.4640180778481648
Validation loss: 2.4144831528958886

Epoch: 275| Step: 0
Training loss: 1.8098505979597943
Validation loss: 2.42564829068519

Epoch: 5| Step: 1
Training loss: 1.9922983774483494
Validation loss: 2.4236094371584858

Epoch: 5| Step: 2
Training loss: 1.5083794985427723
Validation loss: 2.418065959840992

Epoch: 5| Step: 3
Training loss: 1.9993975447218093
Validation loss: 2.4369413441907053

Epoch: 5| Step: 4
Training loss: 1.4330430805202024
Validation loss: 2.4270476475454283

Epoch: 5| Step: 5
Training loss: 1.231723012930125
Validation loss: 2.4042598270043536

Epoch: 5| Step: 6
Training loss: 1.9247180410205047
Validation loss: 2.415846620449641

Epoch: 5| Step: 7
Training loss: 1.56826109239744
Validation loss: 2.4680049255306518

Epoch: 5| Step: 8
Training loss: 1.7716068448397646
Validation loss: 2.475558727768816

Epoch: 5| Step: 9
Training loss: 1.6112013148490898
Validation loss: 2.5424953369281136

Epoch: 5| Step: 10
Training loss: 1.8760563100200613
Validation loss: 2.5383938180048213

Epoch: 276| Step: 0
Training loss: 1.509780548140388
Validation loss: 2.5216074946106297

Epoch: 5| Step: 1
Training loss: 1.4565201340975324
Validation loss: 2.5526199094844686

Epoch: 5| Step: 2
Training loss: 1.6342744260225672
Validation loss: 2.544228184071828

Epoch: 5| Step: 3
Training loss: 1.7178801676354567
Validation loss: 2.5576711226569615

Epoch: 5| Step: 4
Training loss: 1.9290956523944156
Validation loss: 2.5204136876370824

Epoch: 5| Step: 5
Training loss: 1.5658702361323014
Validation loss: 2.5103107631401387

Epoch: 5| Step: 6
Training loss: 1.830968682876015
Validation loss: 2.490618059558297

Epoch: 5| Step: 7
Training loss: 1.6971833765537867
Validation loss: 2.444432600085269

Epoch: 5| Step: 8
Training loss: 1.7241006967207169
Validation loss: 2.4414266747717543

Epoch: 5| Step: 9
Training loss: 1.7274664674366806
Validation loss: 2.4329284992275233

Epoch: 5| Step: 10
Training loss: 1.7646537742681823
Validation loss: 2.4487381882498274

Epoch: 277| Step: 0
Training loss: 1.6106673301785936
Validation loss: 2.422456707595665

Epoch: 5| Step: 1
Training loss: 1.891209031371677
Validation loss: 2.4357788955385673

Epoch: 5| Step: 2
Training loss: 1.6522914436303948
Validation loss: 2.4246554289419486

Epoch: 5| Step: 3
Training loss: 1.233718794222234
Validation loss: 2.4327331505580694

Epoch: 5| Step: 4
Training loss: 1.8651000289068598
Validation loss: 2.4414952042976235

Epoch: 5| Step: 5
Training loss: 2.0486901075861588
Validation loss: 2.4595954945761345

Epoch: 5| Step: 6
Training loss: 1.6423566852677516
Validation loss: 2.465574679149793

Epoch: 5| Step: 7
Training loss: 1.6100699396520914
Validation loss: 2.503979348190134

Epoch: 5| Step: 8
Training loss: 1.807187615146729
Validation loss: 2.524201463684768

Epoch: 5| Step: 9
Training loss: 1.5627281022466812
Validation loss: 2.5518517843500064

Epoch: 5| Step: 10
Training loss: 1.5090676257310476
Validation loss: 2.561866415807907

Epoch: 278| Step: 0
Training loss: 2.1230959496182455
Validation loss: 2.548341210406366

Epoch: 5| Step: 1
Training loss: 1.6608281470085562
Validation loss: 2.530768282927754

Epoch: 5| Step: 2
Training loss: 1.3379854266138531
Validation loss: 2.4918944679381525

Epoch: 5| Step: 3
Training loss: 1.5664914077099426
Validation loss: 2.462195402789232

Epoch: 5| Step: 4
Training loss: 2.011465467785734
Validation loss: 2.4096822786659007

Epoch: 5| Step: 5
Training loss: 1.7655624108487846
Validation loss: 2.420961134680223

Epoch: 5| Step: 6
Training loss: 0.9489685482364483
Validation loss: 2.4052349837571736

Epoch: 5| Step: 7
Training loss: 1.6411057993869542
Validation loss: 2.4072604839046003

Epoch: 5| Step: 8
Training loss: 1.8016176743011398
Validation loss: 2.414406461709881

Epoch: 5| Step: 9
Training loss: 1.6064733624545795
Validation loss: 2.4653130393939344

Epoch: 5| Step: 10
Training loss: 1.652606988233804
Validation loss: 2.4849250645255023

Epoch: 279| Step: 0
Training loss: 1.4880773049136828
Validation loss: 2.5008603020644085

Epoch: 5| Step: 1
Training loss: 1.3040065244558265
Validation loss: 2.595758349730251

Epoch: 5| Step: 2
Training loss: 1.9640056422826515
Validation loss: 2.6220312250702116

Epoch: 5| Step: 3
Training loss: 1.3872274406030092
Validation loss: 2.6317174369886076

Epoch: 5| Step: 4
Training loss: 1.1423377150922864
Validation loss: 2.6332519939514274

Epoch: 5| Step: 5
Training loss: 1.470434237719554
Validation loss: 2.623218160154207

Epoch: 5| Step: 6
Training loss: 2.0178927889833025
Validation loss: 2.5924025305953586

Epoch: 5| Step: 7
Training loss: 1.728062388163652
Validation loss: 2.5753153645979223

Epoch: 5| Step: 8
Training loss: 1.6713370054732402
Validation loss: 2.5526569544679245

Epoch: 5| Step: 9
Training loss: 1.929044423305218
Validation loss: 2.50375313679694

Epoch: 5| Step: 10
Training loss: 1.7592686026401287
Validation loss: 2.483034058507334

Epoch: 280| Step: 0
Training loss: 1.255495484405139
Validation loss: 2.4686834976171825

Epoch: 5| Step: 1
Training loss: 1.604289417607112
Validation loss: 2.4643081731402767

Epoch: 5| Step: 2
Training loss: 1.7101743903664
Validation loss: 2.4230344999653317

Epoch: 5| Step: 3
Training loss: 1.313508146111909
Validation loss: 2.4277870551934098

Epoch: 5| Step: 4
Training loss: 1.55414775124392
Validation loss: 2.3775242170239586

Epoch: 5| Step: 5
Training loss: 1.6732563479952998
Validation loss: 2.404025602642631

Epoch: 5| Step: 6
Training loss: 1.8887228736974437
Validation loss: 2.39468286899429

Epoch: 5| Step: 7
Training loss: 2.1509379314935937
Validation loss: 2.4045144246237027

Epoch: 5| Step: 8
Training loss: 1.3054359253843593
Validation loss: 2.422586373216609

Epoch: 5| Step: 9
Training loss: 1.434108298778416
Validation loss: 2.4497844648953127

Epoch: 5| Step: 10
Training loss: 1.742091017989507
Validation loss: 2.470365622592692

Epoch: 281| Step: 0
Training loss: 1.4716441271054195
Validation loss: 2.5310255888271675

Epoch: 5| Step: 1
Training loss: 1.2847251748861572
Validation loss: 2.530706261404834

Epoch: 5| Step: 2
Training loss: 2.0600400183781225
Validation loss: 2.5779061948939064

Epoch: 5| Step: 3
Training loss: 1.7562163163073923
Validation loss: 2.5611548566093716

Epoch: 5| Step: 4
Training loss: 1.118095615740765
Validation loss: 2.54173474058443

Epoch: 5| Step: 5
Training loss: 1.6263860513365753
Validation loss: 2.5336802301631955

Epoch: 5| Step: 6
Training loss: 1.646473442213295
Validation loss: 2.51564529197772

Epoch: 5| Step: 7
Training loss: 1.7909339545046274
Validation loss: 2.465324167172066

Epoch: 5| Step: 8
Training loss: 1.7913103932264172
Validation loss: 2.417916858904912

Epoch: 5| Step: 9
Training loss: 1.5287811462024277
Validation loss: 2.397876939745342

Epoch: 5| Step: 10
Training loss: 1.2722982916006995
Validation loss: 2.381856736403301

Epoch: 282| Step: 0
Training loss: 2.0921425413581636
Validation loss: 2.3903155726114917

Epoch: 5| Step: 1
Training loss: 1.0135961368321578
Validation loss: 2.3924580660898753

Epoch: 5| Step: 2
Training loss: 1.4547784893617794
Validation loss: 2.4308015724835292

Epoch: 5| Step: 3
Training loss: 1.3938759511650698
Validation loss: 2.422787958743293

Epoch: 5| Step: 4
Training loss: 1.3877240472619843
Validation loss: 2.4451802714089994

Epoch: 5| Step: 5
Training loss: 1.3173278842387326
Validation loss: 2.468281477279681

Epoch: 5| Step: 6
Training loss: 1.61346619217914
Validation loss: 2.5156614820295715

Epoch: 5| Step: 7
Training loss: 1.7634162252854126
Validation loss: 2.537969695651023

Epoch: 5| Step: 8
Training loss: 2.1017179183498884
Validation loss: 2.5798076509509844

Epoch: 5| Step: 9
Training loss: 1.3764657964090796
Validation loss: 2.5668973331921094

Epoch: 5| Step: 10
Training loss: 1.5589725349605594
Validation loss: 2.573532270645535

Epoch: 283| Step: 0
Training loss: 1.5307117216715467
Validation loss: 2.5673894672773043

Epoch: 5| Step: 1
Training loss: 1.8968386726734396
Validation loss: 2.5652357135275277

Epoch: 5| Step: 2
Training loss: 1.6327586187936272
Validation loss: 2.492046440546252

Epoch: 5| Step: 3
Training loss: 1.6189203239000736
Validation loss: 2.53410088874631

Epoch: 5| Step: 4
Training loss: 1.05412130346185
Validation loss: 2.503993495897889

Epoch: 5| Step: 5
Training loss: 1.6161042791940277
Validation loss: 2.4676931021036386

Epoch: 5| Step: 6
Training loss: 1.3047967739371735
Validation loss: 2.478271012537793

Epoch: 5| Step: 7
Training loss: 1.4359028277605954
Validation loss: 2.45676247068139

Epoch: 5| Step: 8
Training loss: 1.765015691087693
Validation loss: 2.453958704491812

Epoch: 5| Step: 9
Training loss: 1.3471292100939518
Validation loss: 2.445166443933571

Epoch: 5| Step: 10
Training loss: 1.8616967971922558
Validation loss: 2.433742657888999

Epoch: 284| Step: 0
Training loss: 0.973672175400859
Validation loss: 2.479120219095346

Epoch: 5| Step: 1
Training loss: 1.7206014891104866
Validation loss: 2.5007681415118954

Epoch: 5| Step: 2
Training loss: 1.234740480808376
Validation loss: 2.5344374871299373

Epoch: 5| Step: 3
Training loss: 1.56914123580727
Validation loss: 2.553175815975205

Epoch: 5| Step: 4
Training loss: 1.6303498163060137
Validation loss: 2.540524222103938

Epoch: 5| Step: 5
Training loss: 1.7587176217878913
Validation loss: 2.511490970623277

Epoch: 5| Step: 6
Training loss: 1.7311857989694777
Validation loss: 2.4817564735470183

Epoch: 5| Step: 7
Training loss: 1.328440639911208
Validation loss: 2.4329024868021394

Epoch: 5| Step: 8
Training loss: 1.9651496300256357
Validation loss: 2.4480540184458013

Epoch: 5| Step: 9
Training loss: 1.113003023415955
Validation loss: 2.4173768887800215

Epoch: 5| Step: 10
Training loss: 1.7311140454615246
Validation loss: 2.4246057998712627

Epoch: 285| Step: 0
Training loss: 2.069160918485001
Validation loss: 2.417806173371595

Epoch: 5| Step: 1
Training loss: 1.3869639864854961
Validation loss: 2.4173767641706636

Epoch: 5| Step: 2
Training loss: 1.4172972042602276
Validation loss: 2.4029868215551753

Epoch: 5| Step: 3
Training loss: 1.7381088342775608
Validation loss: 2.4008517665469835

Epoch: 5| Step: 4
Training loss: 1.4413707697773768
Validation loss: 2.4039921384046457

Epoch: 5| Step: 5
Training loss: 1.3643838527949674
Validation loss: 2.432448327797745

Epoch: 5| Step: 6
Training loss: 1.5958032284811188
Validation loss: 2.442689121323927

Epoch: 5| Step: 7
Training loss: 1.1533474963389834
Validation loss: 2.4794854834384035

Epoch: 5| Step: 8
Training loss: 1.2358230113402044
Validation loss: 2.552659471249607

Epoch: 5| Step: 9
Training loss: 1.512619578150751
Validation loss: 2.5737760808267796

Epoch: 5| Step: 10
Training loss: 1.8860058434720497
Validation loss: 2.6123357261245177

Epoch: 286| Step: 0
Training loss: 1.267752002140511
Validation loss: 2.582158414613974

Epoch: 5| Step: 1
Training loss: 1.2299288094860648
Validation loss: 2.5696519220453222

Epoch: 5| Step: 2
Training loss: 1.3982321306024956
Validation loss: 2.553258358586553

Epoch: 5| Step: 3
Training loss: 2.009367225833644
Validation loss: 2.5427353170888773

Epoch: 5| Step: 4
Training loss: 1.4468125265982397
Validation loss: 2.4636200680320233

Epoch: 5| Step: 5
Training loss: 1.2297167705459757
Validation loss: 2.4533317896257714

Epoch: 5| Step: 6
Training loss: 1.915973005686003
Validation loss: 2.3969766033571775

Epoch: 5| Step: 7
Training loss: 1.262696350994111
Validation loss: 2.378665475639327

Epoch: 5| Step: 8
Training loss: 1.6164694403589508
Validation loss: 2.3837056880289094

Epoch: 5| Step: 9
Training loss: 1.8544185195922966
Validation loss: 2.4010238947544402

Epoch: 5| Step: 10
Training loss: 1.472507378214824
Validation loss: 2.434121783394327

Epoch: 287| Step: 0
Training loss: 1.586210631354709
Validation loss: 2.4542766109841674

Epoch: 5| Step: 1
Training loss: 0.9129966977823293
Validation loss: 2.4898588467707574

Epoch: 5| Step: 2
Training loss: 1.6669615802513804
Validation loss: 2.516976948808852

Epoch: 5| Step: 3
Training loss: 2.1032098036017017
Validation loss: 2.533012579617635

Epoch: 5| Step: 4
Training loss: 1.2132087818519663
Validation loss: 2.5246218433596375

Epoch: 5| Step: 5
Training loss: 1.4221272506810059
Validation loss: 2.5587739985078235

Epoch: 5| Step: 6
Training loss: 1.4780016147981527
Validation loss: 2.504758174814345

Epoch: 5| Step: 7
Training loss: 1.5729659706455699
Validation loss: 2.4768006418047825

Epoch: 5| Step: 8
Training loss: 1.6179918141104932
Validation loss: 2.4692648426993107

Epoch: 5| Step: 9
Training loss: 1.2314705781817803
Validation loss: 2.444105272621637

Epoch: 5| Step: 10
Training loss: 1.6845364155330564
Validation loss: 2.459338656456878

Epoch: 288| Step: 0
Training loss: 1.6183754800689873
Validation loss: 2.46431280146826

Epoch: 5| Step: 1
Training loss: 1.258305707632479
Validation loss: 2.4515885855232935

Epoch: 5| Step: 2
Training loss: 1.4031781447781215
Validation loss: 2.488986484693513

Epoch: 5| Step: 3
Training loss: 1.3654660531779201
Validation loss: 2.4707734577493015

Epoch: 5| Step: 4
Training loss: 1.3688563161868466
Validation loss: 2.4738049301660365

Epoch: 5| Step: 5
Training loss: 1.917783895313107
Validation loss: 2.4768356949446817

Epoch: 5| Step: 6
Training loss: 1.3594580000169625
Validation loss: 2.4774080489761183

Epoch: 5| Step: 7
Training loss: 1.4868844754276715
Validation loss: 2.493474798041676

Epoch: 5| Step: 8
Training loss: 1.530809767362934
Validation loss: 2.4931961298572607

Epoch: 5| Step: 9
Training loss: 1.853782128166883
Validation loss: 2.5027463277010806

Epoch: 5| Step: 10
Training loss: 1.4286514447146406
Validation loss: 2.5083696146943817

Epoch: 289| Step: 0
Training loss: 1.7902112046635326
Validation loss: 2.5235004209573195

Epoch: 5| Step: 1
Training loss: 1.535185291898879
Validation loss: 2.543250101233604

Epoch: 5| Step: 2
Training loss: 1.3318327814622242
Validation loss: 2.512655278623982

Epoch: 5| Step: 3
Training loss: 1.4134332089102815
Validation loss: 2.53703134831001

Epoch: 5| Step: 4
Training loss: 1.3622889364008777
Validation loss: 2.5156212395663045

Epoch: 5| Step: 5
Training loss: 1.8990992895708638
Validation loss: 2.482249653047365

Epoch: 5| Step: 6
Training loss: 1.2743630351524067
Validation loss: 2.4915962033404018

Epoch: 5| Step: 7
Training loss: 1.4676183033556383
Validation loss: 2.4990250183451055

Epoch: 5| Step: 8
Training loss: 1.619020243588251
Validation loss: 2.476247501212492

Epoch: 5| Step: 9
Training loss: 1.5430552784282086
Validation loss: 2.4338778288487184

Epoch: 5| Step: 10
Training loss: 1.5081860963956284
Validation loss: 2.436668614961508

Epoch: 290| Step: 0
Training loss: 1.476707007385975
Validation loss: 2.4197202885543345

Epoch: 5| Step: 1
Training loss: 1.5112475861056023
Validation loss: 2.429895253962499

Epoch: 5| Step: 2
Training loss: 1.2112582858563
Validation loss: 2.4756606454440577

Epoch: 5| Step: 3
Training loss: 1.8802653451097346
Validation loss: 2.479822097163761

Epoch: 5| Step: 4
Training loss: 1.450781624690733
Validation loss: 2.5301968626929896

Epoch: 5| Step: 5
Training loss: 1.915882226497899
Validation loss: 2.52418980835207

Epoch: 5| Step: 6
Training loss: 1.499004510517727
Validation loss: 2.540649429040576

Epoch: 5| Step: 7
Training loss: 1.5602854484659465
Validation loss: 2.4991630034965304

Epoch: 5| Step: 8
Training loss: 1.1403554310431012
Validation loss: 2.4941348710033378

Epoch: 5| Step: 9
Training loss: 1.074720230957388
Validation loss: 2.461295784350816

Epoch: 5| Step: 10
Training loss: 1.415889929092492
Validation loss: 2.454658812059839

Epoch: 291| Step: 0
Training loss: 1.576914861525272
Validation loss: 2.4357678717002265

Epoch: 5| Step: 1
Training loss: 1.8073188127426645
Validation loss: 2.4589725179278124

Epoch: 5| Step: 2
Training loss: 1.7676709229784144
Validation loss: 2.4307749435238932

Epoch: 5| Step: 3
Training loss: 1.3010611476411968
Validation loss: 2.4347131098702515

Epoch: 5| Step: 4
Training loss: 0.8716137621149792
Validation loss: 2.4281944401489346

Epoch: 5| Step: 5
Training loss: 1.6527279526638246
Validation loss: 2.430851019164027

Epoch: 5| Step: 6
Training loss: 1.3416661805493597
Validation loss: 2.4564570620033885

Epoch: 5| Step: 7
Training loss: 1.3995412807311696
Validation loss: 2.468479670777061

Epoch: 5| Step: 8
Training loss: 1.3857970277286145
Validation loss: 2.4580292132103385

Epoch: 5| Step: 9
Training loss: 1.3660866801517348
Validation loss: 2.4613387731767027

Epoch: 5| Step: 10
Training loss: 1.6663860164224102
Validation loss: 2.4735456674090877

Epoch: 292| Step: 0
Training loss: 1.2290773790333251
Validation loss: 2.4579491194255407

Epoch: 5| Step: 1
Training loss: 1.5767772698403864
Validation loss: 2.480097139967111

Epoch: 5| Step: 2
Training loss: 1.2941892458748774
Validation loss: 2.473431662352446

Epoch: 5| Step: 3
Training loss: 1.4454231013688779
Validation loss: 2.4955044370292803

Epoch: 5| Step: 4
Training loss: 1.523777068025225
Validation loss: 2.492989526419398

Epoch: 5| Step: 5
Training loss: 2.0886821620296163
Validation loss: 2.4526371603718933

Epoch: 5| Step: 6
Training loss: 1.1446552925463074
Validation loss: 2.4831456982798654

Epoch: 5| Step: 7
Training loss: 1.531016117840821
Validation loss: 2.443699198358634

Epoch: 5| Step: 8
Training loss: 1.5935333703110588
Validation loss: 2.457332564502044

Epoch: 5| Step: 9
Training loss: 1.2626169037279396
Validation loss: 2.4320945933070215

Epoch: 5| Step: 10
Training loss: 1.0193602904586365
Validation loss: 2.4597932274216032

Epoch: 293| Step: 0
Training loss: 1.6157858851474862
Validation loss: 2.4514588131241806

Epoch: 5| Step: 1
Training loss: 1.8244100792999287
Validation loss: 2.4329504124200314

Epoch: 5| Step: 2
Training loss: 1.3108601089203575
Validation loss: 2.4524536217337802

Epoch: 5| Step: 3
Training loss: 1.0320246705647578
Validation loss: 2.4275176854826

Epoch: 5| Step: 4
Training loss: 1.5400492801460348
Validation loss: 2.4487684357659316

Epoch: 5| Step: 5
Training loss: 1.4057129152179975
Validation loss: 2.425949133407697

Epoch: 5| Step: 6
Training loss: 1.0281065223216097
Validation loss: 2.439865960266097

Epoch: 5| Step: 7
Training loss: 1.3882091840544917
Validation loss: 2.4700645725697066

Epoch: 5| Step: 8
Training loss: 1.2444781410011048
Validation loss: 2.4514383736353182

Epoch: 5| Step: 9
Training loss: 1.7978747696339634
Validation loss: 2.4723629374698275

Epoch: 5| Step: 10
Training loss: 1.3704101945247358
Validation loss: 2.481201834043385

Epoch: 294| Step: 0
Training loss: 1.3913439488800328
Validation loss: 2.530186566858818

Epoch: 5| Step: 1
Training loss: 1.4310188973096747
Validation loss: 2.5034578477400555

Epoch: 5| Step: 2
Training loss: 1.3917731356677288
Validation loss: 2.4872701508920665

Epoch: 5| Step: 3
Training loss: 1.6891670469946387
Validation loss: 2.498579120886259

Epoch: 5| Step: 4
Training loss: 1.7697962547753197
Validation loss: 2.478179094505504

Epoch: 5| Step: 5
Training loss: 1.3166334822050205
Validation loss: 2.4953776178031024

Epoch: 5| Step: 6
Training loss: 1.0916265310427222
Validation loss: 2.4742723370397894

Epoch: 5| Step: 7
Training loss: 1.1775973668915138
Validation loss: 2.4944891210006332

Epoch: 5| Step: 8
Training loss: 1.34515281021896
Validation loss: 2.46997854241901

Epoch: 5| Step: 9
Training loss: 1.5767477087412793
Validation loss: 2.4810569494047323

Epoch: 5| Step: 10
Training loss: 1.4605880564178721
Validation loss: 2.475451976781546

Epoch: 295| Step: 0
Training loss: 1.5288535848288396
Validation loss: 2.4251211375680564

Epoch: 5| Step: 1
Training loss: 1.3948388708710224
Validation loss: 2.436314520934795

Epoch: 5| Step: 2
Training loss: 1.3892612413792829
Validation loss: 2.435936865429959

Epoch: 5| Step: 3
Training loss: 1.6348282632255564
Validation loss: 2.4525028503427495

Epoch: 5| Step: 4
Training loss: 0.9041109161651256
Validation loss: 2.4466571137590862

Epoch: 5| Step: 5
Training loss: 1.6192169723640866
Validation loss: 2.4879014844913745

Epoch: 5| Step: 6
Training loss: 1.395391033564034
Validation loss: 2.478562592099924

Epoch: 5| Step: 7
Training loss: 1.1143042431852332
Validation loss: 2.4717663051173755

Epoch: 5| Step: 8
Training loss: 1.5350632190422318
Validation loss: 2.461299059081487

Epoch: 5| Step: 9
Training loss: 1.6455771411813958
Validation loss: 2.447527899380482

Epoch: 5| Step: 10
Training loss: 1.1613856522380872
Validation loss: 2.4478057110071627

Epoch: 296| Step: 0
Training loss: 1.9126595474213495
Validation loss: 2.452192472180931

Epoch: 5| Step: 1
Training loss: 1.3665018596755159
Validation loss: 2.417719208330329

Epoch: 5| Step: 2
Training loss: 1.3076363776510316
Validation loss: 2.429346846853337

Epoch: 5| Step: 3
Training loss: 1.1073127168010428
Validation loss: 2.4366883482353567

Epoch: 5| Step: 4
Training loss: 1.3328024681581356
Validation loss: 2.4489347694896964

Epoch: 5| Step: 5
Training loss: 1.0264558037015108
Validation loss: 2.464907689277122

Epoch: 5| Step: 6
Training loss: 1.6300434195697417
Validation loss: 2.4521328505807394

Epoch: 5| Step: 7
Training loss: 1.6219278786331865
Validation loss: 2.464492951002646

Epoch: 5| Step: 8
Training loss: 1.0630438478636588
Validation loss: 2.4295472119516726

Epoch: 5| Step: 9
Training loss: 1.666012190427292
Validation loss: 2.4807375474724487

Epoch: 5| Step: 10
Training loss: 1.105186615112413
Validation loss: 2.4701476475640125

Epoch: 297| Step: 0
Training loss: 1.2297422656184211
Validation loss: 2.4356060005603988

Epoch: 5| Step: 1
Training loss: 0.7342790987420218
Validation loss: 2.47140032728392

Epoch: 5| Step: 2
Training loss: 1.3528202356798935
Validation loss: 2.454467447918995

Epoch: 5| Step: 3
Training loss: 1.5062463562474162
Validation loss: 2.4668809038873794

Epoch: 5| Step: 4
Training loss: 1.5793550437689952
Validation loss: 2.479200480985305

Epoch: 5| Step: 5
Training loss: 1.8088500004076096
Validation loss: 2.4657252702293277

Epoch: 5| Step: 6
Training loss: 1.3640524969793817
Validation loss: 2.4910217072561536

Epoch: 5| Step: 7
Training loss: 1.5586244202466746
Validation loss: 2.4882962725507136

Epoch: 5| Step: 8
Training loss: 1.4195976044467762
Validation loss: 2.49209869532061

Epoch: 5| Step: 9
Training loss: 1.370252780635179
Validation loss: 2.460929814079433

Epoch: 5| Step: 10
Training loss: 1.3227165050717808
Validation loss: 2.436060170726112

Epoch: 298| Step: 0
Training loss: 1.1794293354821792
Validation loss: 2.4136911227281845

Epoch: 5| Step: 1
Training loss: 1.5428468293899884
Validation loss: 2.4316750155120337

Epoch: 5| Step: 2
Training loss: 1.5849026465376588
Validation loss: 2.4346284066801793

Epoch: 5| Step: 3
Training loss: 1.4885823103007791
Validation loss: 2.4235948344898177

Epoch: 5| Step: 4
Training loss: 1.5302309031560815
Validation loss: 2.4460695194367137

Epoch: 5| Step: 5
Training loss: 1.8846578458497054
Validation loss: 2.432000460412881

Epoch: 5| Step: 6
Training loss: 0.9352286799146473
Validation loss: 2.42722342404301

Epoch: 5| Step: 7
Training loss: 0.9766959747651761
Validation loss: 2.444411133824785

Epoch: 5| Step: 8
Training loss: 1.182073037971427
Validation loss: 2.4758572303831783

Epoch: 5| Step: 9
Training loss: 1.576530103851563
Validation loss: 2.488120383199912

Epoch: 5| Step: 10
Training loss: 1.3085027406843823
Validation loss: 2.492580446489173

Epoch: 299| Step: 0
Training loss: 1.333087804161842
Validation loss: 2.467756982098366

Epoch: 5| Step: 1
Training loss: 1.454434532845412
Validation loss: 2.434140074418194

Epoch: 5| Step: 2
Training loss: 1.442651722298839
Validation loss: 2.401285765343426

Epoch: 5| Step: 3
Training loss: 1.2413678133891628
Validation loss: 2.3958986727314775

Epoch: 5| Step: 4
Training loss: 1.4532547759485048
Validation loss: 2.4008256788703006

Epoch: 5| Step: 5
Training loss: 1.4288509401991032
Validation loss: 2.4155467779811106

Epoch: 5| Step: 6
Training loss: 1.4894346238534677
Validation loss: 2.422510719554557

Epoch: 5| Step: 7
Training loss: 1.2935822751333068
Validation loss: 2.4218583248330483

Epoch: 5| Step: 8
Training loss: 0.9366361452766014
Validation loss: 2.4876998052287163

Epoch: 5| Step: 9
Training loss: 1.800181257870369
Validation loss: 2.4897913513587295

Epoch: 5| Step: 10
Training loss: 1.1461834748243889
Validation loss: 2.49510093709199

Epoch: 300| Step: 0
Training loss: 1.532586818183683
Validation loss: 2.4803727517426792

Epoch: 5| Step: 1
Training loss: 1.3641863772149572
Validation loss: 2.4879121320359685

Epoch: 5| Step: 2
Training loss: 1.670608325879323
Validation loss: 2.4999273176805272

Epoch: 5| Step: 3
Training loss: 1.2086344815019503
Validation loss: 2.485607401610393

Epoch: 5| Step: 4
Training loss: 0.9681282201507779
Validation loss: 2.438847243373554

Epoch: 5| Step: 5
Training loss: 1.3866244001931447
Validation loss: 2.4553922385243365

Epoch: 5| Step: 6
Training loss: 1.050394150007014
Validation loss: 2.451403903768981

Epoch: 5| Step: 7
Training loss: 1.5338350390896938
Validation loss: 2.415598778360214

Epoch: 5| Step: 8
Training loss: 1.1065577881655366
Validation loss: 2.453247562604929

Epoch: 5| Step: 9
Training loss: 1.6360209941962627
Validation loss: 2.438631603337113

Epoch: 5| Step: 10
Training loss: 1.572581838713036
Validation loss: 2.4091395934978257

Epoch: 301| Step: 0
Training loss: 1.6207175680102188
Validation loss: 2.439885455434723

Epoch: 5| Step: 1
Training loss: 1.6331706407186366
Validation loss: 2.4455710045786323

Epoch: 5| Step: 2
Training loss: 1.185331020155224
Validation loss: 2.45809567427046

Epoch: 5| Step: 3
Training loss: 1.237149127192641
Validation loss: 2.485919060065097

Epoch: 5| Step: 4
Training loss: 1.1884057957214196
Validation loss: 2.5255251049393332

Epoch: 5| Step: 5
Training loss: 1.1550686961960872
Validation loss: 2.521339366391258

Epoch: 5| Step: 6
Training loss: 1.3529673425041762
Validation loss: 2.503341039955934

Epoch: 5| Step: 7
Training loss: 1.3667412601831361
Validation loss: 2.5496676039963493

Epoch: 5| Step: 8
Training loss: 1.4236437517264753
Validation loss: 2.537566695040747

Epoch: 5| Step: 9
Training loss: 1.2373072406649122
Validation loss: 2.522065234798275

Epoch: 5| Step: 10
Training loss: 1.5696910938158766
Validation loss: 2.4678246916330817

Epoch: 302| Step: 0
Training loss: 1.2506750668136504
Validation loss: 2.480758935014203

Epoch: 5| Step: 1
Training loss: 1.4287061815058826
Validation loss: 2.47486352410636

Epoch: 5| Step: 2
Training loss: 1.709541413123831
Validation loss: 2.4072114674703657

Epoch: 5| Step: 3
Training loss: 1.2087103266551575
Validation loss: 2.3913496204632914

Epoch: 5| Step: 4
Training loss: 1.2734171391831097
Validation loss: 2.363390493516423

Epoch: 5| Step: 5
Training loss: 1.1624721954466104
Validation loss: 2.4002477530813917

Epoch: 5| Step: 6
Training loss: 1.5276546698397524
Validation loss: 2.4243511095066297

Epoch: 5| Step: 7
Training loss: 1.2959814555318994
Validation loss: 2.457105523081473

Epoch: 5| Step: 8
Training loss: 1.3721846454810465
Validation loss: 2.452656482950411

Epoch: 5| Step: 9
Training loss: 1.5865605074900238
Validation loss: 2.472963659630278

Epoch: 5| Step: 10
Training loss: 0.6638272710316325
Validation loss: 2.4805267707021095

Epoch: 303| Step: 0
Training loss: 1.6277927462367339
Validation loss: 2.5364361837184375

Epoch: 5| Step: 1
Training loss: 1.3338194447736953
Validation loss: 2.5824322361135117

Epoch: 5| Step: 2
Training loss: 0.9129441421485488
Validation loss: 2.6157061696332895

Epoch: 5| Step: 3
Training loss: 1.0726226601338957
Validation loss: 2.607347904188594

Epoch: 5| Step: 4
Training loss: 1.1061150376919555
Validation loss: 2.551347737951367

Epoch: 5| Step: 5
Training loss: 1.424041271608168
Validation loss: 2.531976083975906

Epoch: 5| Step: 6
Training loss: 1.442093517345028
Validation loss: 2.4725336546214405

Epoch: 5| Step: 7
Training loss: 1.702125185853094
Validation loss: 2.4719418004136

Epoch: 5| Step: 8
Training loss: 1.2982905372418752
Validation loss: 2.4413229687996507

Epoch: 5| Step: 9
Training loss: 1.317130503660087
Validation loss: 2.4310574810129237

Epoch: 5| Step: 10
Training loss: 1.5724715388258956
Validation loss: 2.412202214883951

Epoch: 304| Step: 0
Training loss: 1.8811258699647169
Validation loss: 2.437851510524121

Epoch: 5| Step: 1
Training loss: 1.3898947008988818
Validation loss: 2.4087462159201944

Epoch: 5| Step: 2
Training loss: 0.9324251146903487
Validation loss: 2.440557811559548

Epoch: 5| Step: 3
Training loss: 1.0448127475689628
Validation loss: 2.464124397879297

Epoch: 5| Step: 4
Training loss: 1.328356419765122
Validation loss: 2.4774396176499223

Epoch: 5| Step: 5
Training loss: 1.46736753616495
Validation loss: 2.4725397134330853

Epoch: 5| Step: 6
Training loss: 1.7364825940587467
Validation loss: 2.4972712965965704

Epoch: 5| Step: 7
Training loss: 1.2689075992212073
Validation loss: 2.50700352029266

Epoch: 5| Step: 8
Training loss: 1.27410632397057
Validation loss: 2.5020412079803416

Epoch: 5| Step: 9
Training loss: 1.210081819495044
Validation loss: 2.5280217456366527

Epoch: 5| Step: 10
Training loss: 0.94220405424894
Validation loss: 2.512838456089774

Epoch: 305| Step: 0
Training loss: 1.7830239547515265
Validation loss: 2.500182306143959

Epoch: 5| Step: 1
Training loss: 1.26977086080144
Validation loss: 2.461353225348664

Epoch: 5| Step: 2
Training loss: 1.3636635842640858
Validation loss: 2.4358284169434934

Epoch: 5| Step: 3
Training loss: 1.457620864489366
Validation loss: 2.430559121015505

Epoch: 5| Step: 4
Training loss: 1.053679882083342
Validation loss: 2.4264115434530567

Epoch: 5| Step: 5
Training loss: 1.15024802808918
Validation loss: 2.4345022635717664

Epoch: 5| Step: 6
Training loss: 1.1756104506829912
Validation loss: 2.4707143042474944

Epoch: 5| Step: 7
Training loss: 1.0188873713264919
Validation loss: 2.480680783199234

Epoch: 5| Step: 8
Training loss: 1.3900001922442626
Validation loss: 2.510368162542766

Epoch: 5| Step: 9
Training loss: 1.1428343395955465
Validation loss: 2.506677595086691

Epoch: 5| Step: 10
Training loss: 1.654839761012617
Validation loss: 2.526751413064013

Epoch: 306| Step: 0
Training loss: 1.3268954700502755
Validation loss: 2.5229800372314766

Epoch: 5| Step: 1
Training loss: 1.5931917596644618
Validation loss: 2.5099379342960595

Epoch: 5| Step: 2
Training loss: 1.2876511216590945
Validation loss: 2.4765206801822153

Epoch: 5| Step: 3
Training loss: 1.601389656974709
Validation loss: 2.4720047658504054

Epoch: 5| Step: 4
Training loss: 1.1013518328136693
Validation loss: 2.4464364206366804

Epoch: 5| Step: 5
Training loss: 1.0554415232706567
Validation loss: 2.4375122970300316

Epoch: 5| Step: 6
Training loss: 1.3378884865402618
Validation loss: 2.46127733578669

Epoch: 5| Step: 7
Training loss: 1.4822769596802665
Validation loss: 2.4496738326177074

Epoch: 5| Step: 8
Training loss: 0.7919133872683777
Validation loss: 2.4482145325024964

Epoch: 5| Step: 9
Training loss: 1.202111895181681
Validation loss: 2.432555966884235

Epoch: 5| Step: 10
Training loss: 1.4102669881099414
Validation loss: 2.422468595504917

Epoch: 307| Step: 0
Training loss: 1.2765279141880501
Validation loss: 2.4801521727764833

Epoch: 5| Step: 1
Training loss: 1.4881962629267471
Validation loss: 2.4762291743956273

Epoch: 5| Step: 2
Training loss: 1.2957835372891737
Validation loss: 2.4522212615692873

Epoch: 5| Step: 3
Training loss: 1.4800863854224822
Validation loss: 2.486732304093956

Epoch: 5| Step: 4
Training loss: 1.1700079731791815
Validation loss: 2.4948847131621825

Epoch: 5| Step: 5
Training loss: 0.7758133742335908
Validation loss: 2.4885300031436812

Epoch: 5| Step: 6
Training loss: 1.126301013159565
Validation loss: 2.4959085198586117

Epoch: 5| Step: 7
Training loss: 1.0742858865739227
Validation loss: 2.4706402571331822

Epoch: 5| Step: 8
Training loss: 1.6118634438664379
Validation loss: 2.4734297485076704

Epoch: 5| Step: 9
Training loss: 1.5777820176678015
Validation loss: 2.449224083020914

Epoch: 5| Step: 10
Training loss: 1.1690757379136707
Validation loss: 2.435406688677921

Epoch: 308| Step: 0
Training loss: 1.265729970464241
Validation loss: 2.4237040239330976

Epoch: 5| Step: 1
Training loss: 1.4656966104480096
Validation loss: 2.432141090772629

Epoch: 5| Step: 2
Training loss: 1.145833079020154
Validation loss: 2.410905190970569

Epoch: 5| Step: 3
Training loss: 1.4292729511536753
Validation loss: 2.4023048064907666

Epoch: 5| Step: 4
Training loss: 1.0827685436668162
Validation loss: 2.4468695215062706

Epoch: 5| Step: 5
Training loss: 1.2434776851490923
Validation loss: 2.457068223272541

Epoch: 5| Step: 6
Training loss: 1.4509089810659697
Validation loss: 2.4887064888212347

Epoch: 5| Step: 7
Training loss: 1.175303973791045
Validation loss: 2.506772582917478

Epoch: 5| Step: 8
Training loss: 1.0740276929705486
Validation loss: 2.516966982379364

Epoch: 5| Step: 9
Training loss: 1.4126916215263765
Validation loss: 2.5059909491405223

Epoch: 5| Step: 10
Training loss: 1.4238233526958346
Validation loss: 2.516252507587631

Epoch: 309| Step: 0
Training loss: 1.3399105222206735
Validation loss: 2.504609063648291

Epoch: 5| Step: 1
Training loss: 1.0253138922182239
Validation loss: 2.457521600401026

Epoch: 5| Step: 2
Training loss: 1.40805590490957
Validation loss: 2.446023760476799

Epoch: 5| Step: 3
Training loss: 1.15277308855035
Validation loss: 2.450380906628003

Epoch: 5| Step: 4
Training loss: 1.123922520804393
Validation loss: 2.452294733717828

Epoch: 5| Step: 5
Training loss: 1.1844769194943991
Validation loss: 2.433616885499921

Epoch: 5| Step: 6
Training loss: 1.677839602277968
Validation loss: 2.4164525072582848

Epoch: 5| Step: 7
Training loss: 1.5924475340532127
Validation loss: 2.412518124727751

Epoch: 5| Step: 8
Training loss: 1.006588569689603
Validation loss: 2.4489845629314386

Epoch: 5| Step: 9
Training loss: 1.003819502708046
Validation loss: 2.476671145515741

Epoch: 5| Step: 10
Training loss: 1.3988610590530766
Validation loss: 2.522488093563365

Epoch: 310| Step: 0
Training loss: 0.9003816219384488
Validation loss: 2.4809277811982993

Epoch: 5| Step: 1
Training loss: 1.147211783122756
Validation loss: 2.5120355833049435

Epoch: 5| Step: 2
Training loss: 1.1462166520720434
Validation loss: 2.4782479664975616

Epoch: 5| Step: 3
Training loss: 1.8017895041885927
Validation loss: 2.482040185264226

Epoch: 5| Step: 4
Training loss: 1.1366485888664726
Validation loss: 2.460902651689654

Epoch: 5| Step: 5
Training loss: 1.5817179051666128
Validation loss: 2.451914169530936

Epoch: 5| Step: 6
Training loss: 1.3410990092674295
Validation loss: 2.4007552393390705

Epoch: 5| Step: 7
Training loss: 1.5017146006705353
Validation loss: 2.3926728445443923

Epoch: 5| Step: 8
Training loss: 1.1066017410658986
Validation loss: 2.37976649812567

Epoch: 5| Step: 9
Training loss: 1.187480324030043
Validation loss: 2.366450798309153

Epoch: 5| Step: 10
Training loss: 1.0419117575639152
Validation loss: 2.4281857088274954

Epoch: 311| Step: 0
Training loss: 1.5027994417958648
Validation loss: 2.4464581237658694

Epoch: 5| Step: 1
Training loss: 1.1583565261403401
Validation loss: 2.508457300667733

Epoch: 5| Step: 2
Training loss: 1.1805513768340312
Validation loss: 2.555667270980937

Epoch: 5| Step: 3
Training loss: 1.3889692071367254
Validation loss: 2.5519897229469932

Epoch: 5| Step: 4
Training loss: 1.0183794084750624
Validation loss: 2.555142939600191

Epoch: 5| Step: 5
Training loss: 1.2970997718989057
Validation loss: 2.5478410517443066

Epoch: 5| Step: 6
Training loss: 1.2893095762265978
Validation loss: 2.5229041784516704

Epoch: 5| Step: 7
Training loss: 0.9478949589741451
Validation loss: 2.4631303935936146

Epoch: 5| Step: 8
Training loss: 1.4776182890916234
Validation loss: 2.448211843950959

Epoch: 5| Step: 9
Training loss: 1.1530437864738707
Validation loss: 2.392438352686431

Epoch: 5| Step: 10
Training loss: 1.4884468046606723
Validation loss: 2.4109884696586708

Epoch: 312| Step: 0
Training loss: 0.9944133272103493
Validation loss: 2.3846826652378628

Epoch: 5| Step: 1
Training loss: 1.5577257076714681
Validation loss: 2.4104294572788763

Epoch: 5| Step: 2
Training loss: 1.500602760007146
Validation loss: 2.4117622209703193

Epoch: 5| Step: 3
Training loss: 1.3832875960422177
Validation loss: 2.4502532810484126

Epoch: 5| Step: 4
Training loss: 1.0260940899825866
Validation loss: 2.4728840350407446

Epoch: 5| Step: 5
Training loss: 1.178240159778553
Validation loss: 2.4970591917009335

Epoch: 5| Step: 6
Training loss: 1.4545321470703085
Validation loss: 2.5009861160021987

Epoch: 5| Step: 7
Training loss: 1.0559066507846249
Validation loss: 2.452112941542452

Epoch: 5| Step: 8
Training loss: 1.114890023696667
Validation loss: 2.4675458456116366

Epoch: 5| Step: 9
Training loss: 1.1937501457973212
Validation loss: 2.440068845714004

Epoch: 5| Step: 10
Training loss: 1.3130646807884763
Validation loss: 2.411042472705168

Epoch: 313| Step: 0
Training loss: 1.1012390419353124
Validation loss: 2.4393657740707075

Epoch: 5| Step: 1
Training loss: 1.3434334315513239
Validation loss: 2.4201104729418352

Epoch: 5| Step: 2
Training loss: 1.5127534701235523
Validation loss: 2.4225112793728187

Epoch: 5| Step: 3
Training loss: 1.1826640591519184
Validation loss: 2.404163409971793

Epoch: 5| Step: 4
Training loss: 1.417251615745766
Validation loss: 2.3812952400517675

Epoch: 5| Step: 5
Training loss: 1.276300313258609
Validation loss: 2.3789870307381706

Epoch: 5| Step: 6
Training loss: 0.7088281128239134
Validation loss: 2.386648158360112

Epoch: 5| Step: 7
Training loss: 1.722600196393519
Validation loss: 2.4265923272528434

Epoch: 5| Step: 8
Training loss: 0.5538661140567626
Validation loss: 2.4413299572252822

Epoch: 5| Step: 9
Training loss: 0.9282827262564894
Validation loss: 2.493310079467244

Epoch: 5| Step: 10
Training loss: 1.5723043685783493
Validation loss: 2.501850522067423

Epoch: 314| Step: 0
Training loss: 1.4705878588732069
Validation loss: 2.5088731012121595

Epoch: 5| Step: 1
Training loss: 1.2183978721355861
Validation loss: 2.528529023500827

Epoch: 5| Step: 2
Training loss: 1.7475908590334845
Validation loss: 2.531934042358337

Epoch: 5| Step: 3
Training loss: 1.4457927009230467
Validation loss: 2.541170236840398

Epoch: 5| Step: 4
Training loss: 1.1474003682484866
Validation loss: 2.497602030536423

Epoch: 5| Step: 5
Training loss: 1.1597049233421137
Validation loss: 2.4587160797651273

Epoch: 5| Step: 6
Training loss: 1.1561732395570565
Validation loss: 2.421165422167317

Epoch: 5| Step: 7
Training loss: 0.925011101217928
Validation loss: 2.4242670837850175

Epoch: 5| Step: 8
Training loss: 1.0154777420098962
Validation loss: 2.407214300324965

Epoch: 5| Step: 9
Training loss: 1.130297058185609
Validation loss: 2.3677039021599233

Epoch: 5| Step: 10
Training loss: 0.9880517383997772
Validation loss: 2.402076074130882

Epoch: 315| Step: 0
Training loss: 1.2558874242803433
Validation loss: 2.3980058871775998

Epoch: 5| Step: 1
Training loss: 1.0921971332960188
Validation loss: 2.381866398510579

Epoch: 5| Step: 2
Training loss: 1.0660213013215147
Validation loss: 2.4247126145653812

Epoch: 5| Step: 3
Training loss: 1.887108551258941
Validation loss: 2.4802262439349745

Epoch: 5| Step: 4
Training loss: 1.088917109281616
Validation loss: 2.512941329610614

Epoch: 5| Step: 5
Training loss: 1.2222437055944175
Validation loss: 2.527037737102731

Epoch: 5| Step: 6
Training loss: 1.120000751699468
Validation loss: 2.568907794896779

Epoch: 5| Step: 7
Training loss: 0.8792397777536927
Validation loss: 2.553950666830121

Epoch: 5| Step: 8
Training loss: 0.9745826488186402
Validation loss: 2.5072201766075923

Epoch: 5| Step: 9
Training loss: 1.3103380107875404
Validation loss: 2.523788505455125

Epoch: 5| Step: 10
Training loss: 1.444766957191592
Validation loss: 2.5064800327197667

Epoch: 316| Step: 0
Training loss: 1.007109522533576
Validation loss: 2.4667486227760693

Epoch: 5| Step: 1
Training loss: 1.1971139734004732
Validation loss: 2.4641633111312626

Epoch: 5| Step: 2
Training loss: 0.9687854391199225
Validation loss: 2.456295799695291

Epoch: 5| Step: 3
Training loss: 1.8310415364111061
Validation loss: 2.470739942447627

Epoch: 5| Step: 4
Training loss: 1.3896070033187389
Validation loss: 2.45915739438297

Epoch: 5| Step: 5
Training loss: 1.013416765337906
Validation loss: 2.4941140720140123

Epoch: 5| Step: 6
Training loss: 1.2507697596311105
Validation loss: 2.4602734324916615

Epoch: 5| Step: 7
Training loss: 1.0445375680554059
Validation loss: 2.4728118257086016

Epoch: 5| Step: 8
Training loss: 1.0302713547816627
Validation loss: 2.473449296810252

Epoch: 5| Step: 9
Training loss: 1.123925755794378
Validation loss: 2.5082280083089703

Epoch: 5| Step: 10
Training loss: 1.3561637481827447
Validation loss: 2.4858490135155926

Epoch: 317| Step: 0
Training loss: 1.5471581094007876
Validation loss: 2.509684265945214

Epoch: 5| Step: 1
Training loss: 0.9234882721602893
Validation loss: 2.4790633526400616

Epoch: 5| Step: 2
Training loss: 1.4355845751320881
Validation loss: 2.494223693635587

Epoch: 5| Step: 3
Training loss: 1.1029016998182455
Validation loss: 2.4923163973536258

Epoch: 5| Step: 4
Training loss: 1.4761857455334548
Validation loss: 2.50669406192007

Epoch: 5| Step: 5
Training loss: 1.3682193459036252
Validation loss: 2.5226912831888764

Epoch: 5| Step: 6
Training loss: 1.0101418006612919
Validation loss: 2.4840516478276435

Epoch: 5| Step: 7
Training loss: 1.096826314253221
Validation loss: 2.428618022508441

Epoch: 5| Step: 8
Training loss: 1.1135807638319724
Validation loss: 2.4163292724270624

Epoch: 5| Step: 9
Training loss: 0.8345899683599233
Validation loss: 2.404314295730941

Epoch: 5| Step: 10
Training loss: 1.3347296803998536
Validation loss: 2.4083207756413674

Epoch: 318| Step: 0
Training loss: 1.0130555736138578
Validation loss: 2.4310395854501694

Epoch: 5| Step: 1
Training loss: 1.0767965563400208
Validation loss: 2.463253468938342

Epoch: 5| Step: 2
Training loss: 1.0311500038447738
Validation loss: 2.4757890995629808

Epoch: 5| Step: 3
Training loss: 1.6783866635700937
Validation loss: 2.520044485990846

Epoch: 5| Step: 4
Training loss: 1.4479731633349706
Validation loss: 2.5407534437537906

Epoch: 5| Step: 5
Training loss: 0.9266383714152406
Validation loss: 2.536631569639442

Epoch: 5| Step: 6
Training loss: 1.4196799805509424
Validation loss: 2.5869752265068757

Epoch: 5| Step: 7
Training loss: 0.7671360752250426
Validation loss: 2.578829864670872

Epoch: 5| Step: 8
Training loss: 1.3311563342459078
Validation loss: 2.5284770024935157

Epoch: 5| Step: 9
Training loss: 0.8994224456827181
Validation loss: 2.491716105061574

Epoch: 5| Step: 10
Training loss: 1.48286690647335
Validation loss: 2.4102911424192826

Epoch: 319| Step: 0
Training loss: 1.1071591343100675
Validation loss: 2.373833518273468

Epoch: 5| Step: 1
Training loss: 1.2726075914235946
Validation loss: 2.303143826954811

Epoch: 5| Step: 2
Training loss: 1.191993693626286
Validation loss: 2.3094718982380242

Epoch: 5| Step: 3
Training loss: 1.1234339304139114
Validation loss: 2.3534466953571718

Epoch: 5| Step: 4
Training loss: 1.0947562901920962
Validation loss: 2.3761555829348304

Epoch: 5| Step: 5
Training loss: 1.1915847394475056
Validation loss: 2.4371764360328063

Epoch: 5| Step: 6
Training loss: 1.1893964982608085
Validation loss: 2.475029046178346

Epoch: 5| Step: 7
Training loss: 1.6186421067502454
Validation loss: 2.5347903443417716

Epoch: 5| Step: 8
Training loss: 1.3258396007710194
Validation loss: 2.587609158744288

Epoch: 5| Step: 9
Training loss: 0.9448198973879697
Validation loss: 2.5959797682011767

Epoch: 5| Step: 10
Training loss: 1.3041417699434157
Validation loss: 2.560778862462321

Epoch: 320| Step: 0
Training loss: 1.3748917970565107
Validation loss: 2.5426220438952623

Epoch: 5| Step: 1
Training loss: 1.2357123168595723
Validation loss: 2.4968841332023652

Epoch: 5| Step: 2
Training loss: 1.0312654898665037
Validation loss: 2.4589465172420137

Epoch: 5| Step: 3
Training loss: 1.6795671996573025
Validation loss: 2.435029865704256

Epoch: 5| Step: 4
Training loss: 1.2826742304488383
Validation loss: 2.3630801465228526

Epoch: 5| Step: 5
Training loss: 1.4248294527491305
Validation loss: 2.365649490141898

Epoch: 5| Step: 6
Training loss: 1.1412071936978638
Validation loss: 2.386221598383736

Epoch: 5| Step: 7
Training loss: 0.9409661748362552
Validation loss: 2.404695157943193

Epoch: 5| Step: 8
Training loss: 0.7620629731036576
Validation loss: 2.402105448692478

Epoch: 5| Step: 9
Training loss: 1.2130698840962015
Validation loss: 2.4401547064059326

Epoch: 5| Step: 10
Training loss: 0.9614583596463405
Validation loss: 2.4743582184189927

Epoch: 321| Step: 0
Training loss: 1.299610699537432
Validation loss: 2.509317351318479

Epoch: 5| Step: 1
Training loss: 1.165665003522196
Validation loss: 2.5440620970442565

Epoch: 5| Step: 2
Training loss: 0.985655421124388
Validation loss: 2.571915598217844

Epoch: 5| Step: 3
Training loss: 1.3814156583981883
Validation loss: 2.582729666680371

Epoch: 5| Step: 4
Training loss: 1.028670002456204
Validation loss: 2.5729238041644273

Epoch: 5| Step: 5
Training loss: 1.6320820319792437
Validation loss: 2.5314374338037724

Epoch: 5| Step: 6
Training loss: 1.2195006284223362
Validation loss: 2.509753210069682

Epoch: 5| Step: 7
Training loss: 1.0094862058810892
Validation loss: 2.481484719667849

Epoch: 5| Step: 8
Training loss: 0.795302541254493
Validation loss: 2.4321043910310802

Epoch: 5| Step: 9
Training loss: 1.0834500482238
Validation loss: 2.3824879425769483

Epoch: 5| Step: 10
Training loss: 1.3045248512716994
Validation loss: 2.3593301131117057

Epoch: 322| Step: 0
Training loss: 1.3219392224305522
Validation loss: 2.368309010640016

Epoch: 5| Step: 1
Training loss: 1.4013019400370104
Validation loss: 2.39974405558704

Epoch: 5| Step: 2
Training loss: 1.082673911381271
Validation loss: 2.4461058639758972

Epoch: 5| Step: 3
Training loss: 1.0603212569707394
Validation loss: 2.4756665241862166

Epoch: 5| Step: 4
Training loss: 0.8994997462112722
Validation loss: 2.5259186843621686

Epoch: 5| Step: 5
Training loss: 1.6947142780487843
Validation loss: 2.5552805033918866

Epoch: 5| Step: 6
Training loss: 0.9317786476371931
Validation loss: 2.6061171369862968

Epoch: 5| Step: 7
Training loss: 1.2959586893432418
Validation loss: 2.6219772615976833

Epoch: 5| Step: 8
Training loss: 0.7971454984037137
Validation loss: 2.6296743826672158

Epoch: 5| Step: 9
Training loss: 0.8370727602257869
Validation loss: 2.6016499785086005

Epoch: 5| Step: 10
Training loss: 1.499032264708334
Validation loss: 2.571689990012729

Epoch: 323| Step: 0
Training loss: 1.201665265236371
Validation loss: 2.541336918391335

Epoch: 5| Step: 1
Training loss: 0.8707311927786137
Validation loss: 2.5047057010441542

Epoch: 5| Step: 2
Training loss: 1.3023162124916996
Validation loss: 2.481686410226717

Epoch: 5| Step: 3
Training loss: 0.9378701115231306
Validation loss: 2.4722115529989903

Epoch: 5| Step: 4
Training loss: 1.2838874281262302
Validation loss: 2.444891696747989

Epoch: 5| Step: 5
Training loss: 1.1327018946879246
Validation loss: 2.458929491903636

Epoch: 5| Step: 6
Training loss: 0.6495767260597339
Validation loss: 2.475402574891703

Epoch: 5| Step: 7
Training loss: 0.9518100234940108
Validation loss: 2.4581438616913767

Epoch: 5| Step: 8
Training loss: 1.2821210366004008
Validation loss: 2.4956917690783462

Epoch: 5| Step: 9
Training loss: 1.8064864799105498
Validation loss: 2.527233303887727

Epoch: 5| Step: 10
Training loss: 1.115367821293787
Validation loss: 2.4752146368553243

Epoch: 324| Step: 0
Training loss: 1.0092925212219053
Validation loss: 2.5047285532871673

Epoch: 5| Step: 1
Training loss: 1.0326121033409335
Validation loss: 2.49574344111633

Epoch: 5| Step: 2
Training loss: 1.1077642432975698
Validation loss: 2.5122821808540095

Epoch: 5| Step: 3
Training loss: 1.1761550055807737
Validation loss: 2.511414842900237

Epoch: 5| Step: 4
Training loss: 1.6435437352251319
Validation loss: 2.4938661698607714

Epoch: 5| Step: 5
Training loss: 1.1782868514454559
Validation loss: 2.494618696899846

Epoch: 5| Step: 6
Training loss: 1.27800768474722
Validation loss: 2.4802357357573297

Epoch: 5| Step: 7
Training loss: 0.8766586047032715
Validation loss: 2.468062973845373

Epoch: 5| Step: 8
Training loss: 1.4059404668291258
Validation loss: 2.454620296450005

Epoch: 5| Step: 9
Training loss: 1.0516894645053676
Validation loss: 2.4921259518056553

Epoch: 5| Step: 10
Training loss: 0.8340478377127188
Validation loss: 2.4378283699925167

Epoch: 325| Step: 0
Training loss: 1.1597218326306529
Validation loss: 2.4566496476053215

Epoch: 5| Step: 1
Training loss: 1.1566758273821878
Validation loss: 2.4249472273960304

Epoch: 5| Step: 2
Training loss: 1.4765901108839592
Validation loss: 2.42688736979834

Epoch: 5| Step: 3
Training loss: 0.9076327594088638
Validation loss: 2.4061309578317447

Epoch: 5| Step: 4
Training loss: 1.0699753613175396
Validation loss: 2.391981212699195

Epoch: 5| Step: 5
Training loss: 1.0241658771057645
Validation loss: 2.3724977689242603

Epoch: 5| Step: 6
Training loss: 1.5594002303106302
Validation loss: 2.4272338244515606

Epoch: 5| Step: 7
Training loss: 1.1128169111996222
Validation loss: 2.409813768883342

Epoch: 5| Step: 8
Training loss: 1.0470206885238518
Validation loss: 2.4125984473600037

Epoch: 5| Step: 9
Training loss: 1.1374327000421802
Validation loss: 2.460835023599693

Epoch: 5| Step: 10
Training loss: 0.9710169386618879
Validation loss: 2.5201420606966503

Epoch: 326| Step: 0
Training loss: 1.253069399316039
Validation loss: 2.50994402998015

Epoch: 5| Step: 1
Training loss: 0.9249489499516349
Validation loss: 2.5743729690216197

Epoch: 5| Step: 2
Training loss: 0.9610377933918383
Validation loss: 2.54052197685751

Epoch: 5| Step: 3
Training loss: 0.857653818931477
Validation loss: 2.512291724528556

Epoch: 5| Step: 4
Training loss: 1.2254020400970298
Validation loss: 2.493127996769962

Epoch: 5| Step: 5
Training loss: 1.3999840905784182
Validation loss: 2.451059639699758

Epoch: 5| Step: 6
Training loss: 1.4462153733443066
Validation loss: 2.3731077608317115

Epoch: 5| Step: 7
Training loss: 0.7829482122714503
Validation loss: 2.351108422014219

Epoch: 5| Step: 8
Training loss: 1.121413660427578
Validation loss: 2.3298677532869423

Epoch: 5| Step: 9
Training loss: 1.1756803146077028
Validation loss: 2.3140115052393093

Epoch: 5| Step: 10
Training loss: 1.5116080310108517
Validation loss: 2.372608537329377

Epoch: 327| Step: 0
Training loss: 1.3425379765145524
Validation loss: 2.4290818537553784

Epoch: 5| Step: 1
Training loss: 0.6783935463406617
Validation loss: 2.4304799109044404

Epoch: 5| Step: 2
Training loss: 1.6840142877656727
Validation loss: 2.469984087501482

Epoch: 5| Step: 3
Training loss: 1.0489701897646533
Validation loss: 2.539942209515554

Epoch: 5| Step: 4
Training loss: 0.8840307084506365
Validation loss: 2.555219400404483

Epoch: 5| Step: 5
Training loss: 1.1727213537148806
Validation loss: 2.5533729169675308

Epoch: 5| Step: 6
Training loss: 1.3462448026508964
Validation loss: 2.5502594786641817

Epoch: 5| Step: 7
Training loss: 1.032968591849598
Validation loss: 2.559648356223031

Epoch: 5| Step: 8
Training loss: 0.739269825927197
Validation loss: 2.507267154054175

Epoch: 5| Step: 9
Training loss: 1.2334003221945962
Validation loss: 2.4943670493394245

Epoch: 5| Step: 10
Training loss: 1.0886324368585416
Validation loss: 2.469090691731298

Epoch: 328| Step: 0
Training loss: 1.3068929978768251
Validation loss: 2.4193870793522163

Epoch: 5| Step: 1
Training loss: 0.9284860878283705
Validation loss: 2.4344686459284617

Epoch: 5| Step: 2
Training loss: 1.0201560258273537
Validation loss: 2.3901305100452945

Epoch: 5| Step: 3
Training loss: 1.1895827048990937
Validation loss: 2.3926201562494063

Epoch: 5| Step: 4
Training loss: 1.2285291128221731
Validation loss: 2.4114676518112805

Epoch: 5| Step: 5
Training loss: 1.002177609286912
Validation loss: 2.4685935368976284

Epoch: 5| Step: 6
Training loss: 1.0217874635306292
Validation loss: 2.5171746706400606

Epoch: 5| Step: 7
Training loss: 1.078839770015344
Validation loss: 2.5492034642034342

Epoch: 5| Step: 8
Training loss: 0.9912051646999384
Validation loss: 2.5656421164540126

Epoch: 5| Step: 9
Training loss: 1.615839299464249
Validation loss: 2.5501463396280966

Epoch: 5| Step: 10
Training loss: 0.8462126432594541
Validation loss: 2.5459894880167964

Epoch: 329| Step: 0
Training loss: 1.2871035400628836
Validation loss: 2.5263007232978527

Epoch: 5| Step: 1
Training loss: 1.2410738769538463
Validation loss: 2.511444490705868

Epoch: 5| Step: 2
Training loss: 1.3826474452247617
Validation loss: 2.4994827083981734

Epoch: 5| Step: 3
Training loss: 1.1921948433946101
Validation loss: 2.4748038359517865

Epoch: 5| Step: 4
Training loss: 1.0643489681696041
Validation loss: 2.4504398102702285

Epoch: 5| Step: 5
Training loss: 1.2303791316260584
Validation loss: 2.469721326690794

Epoch: 5| Step: 6
Training loss: 0.9639524597973962
Validation loss: 2.4211874746466195

Epoch: 5| Step: 7
Training loss: 0.9621979734985001
Validation loss: 2.4155882652403924

Epoch: 5| Step: 8
Training loss: 1.0390980076280014
Validation loss: 2.418182239043257

Epoch: 5| Step: 9
Training loss: 0.826122309503317
Validation loss: 2.4096985593434246

Epoch: 5| Step: 10
Training loss: 0.984962893334118
Validation loss: 2.4150169963387627

Epoch: 330| Step: 0
Training loss: 0.9078858836678576
Validation loss: 2.4921354790578167

Epoch: 5| Step: 1
Training loss: 1.1344369225113053
Validation loss: 2.483138851284078

Epoch: 5| Step: 2
Training loss: 1.581794476157072
Validation loss: 2.499290784097306

Epoch: 5| Step: 3
Training loss: 1.3070986277194463
Validation loss: 2.4952238610537996

Epoch: 5| Step: 4
Training loss: 1.1610759852742745
Validation loss: 2.499537510290066

Epoch: 5| Step: 5
Training loss: 0.7480305403477239
Validation loss: 2.485827436693403

Epoch: 5| Step: 6
Training loss: 1.2812398584476203
Validation loss: 2.4557093194950683

Epoch: 5| Step: 7
Training loss: 1.0834357995701274
Validation loss: 2.457630836791904

Epoch: 5| Step: 8
Training loss: 1.0386029137726065
Validation loss: 2.4741670692522626

Epoch: 5| Step: 9
Training loss: 0.7070379941839947
Validation loss: 2.4166299295939324

Epoch: 5| Step: 10
Training loss: 0.87086682293271
Validation loss: 2.4144193116988544

Epoch: 331| Step: 0
Training loss: 0.7357874334613802
Validation loss: 2.4533338549940207

Epoch: 5| Step: 1
Training loss: 1.1276450322288158
Validation loss: 2.459145238949668

Epoch: 5| Step: 2
Training loss: 0.8566279461257662
Validation loss: 2.46017407127489

Epoch: 5| Step: 3
Training loss: 1.0165675557922857
Validation loss: 2.5044407637733963

Epoch: 5| Step: 4
Training loss: 1.0606717480510393
Validation loss: 2.5292006962390077

Epoch: 5| Step: 5
Training loss: 1.2042256064768577
Validation loss: 2.545260455834416

Epoch: 5| Step: 6
Training loss: 1.2099089161032384
Validation loss: 2.560465573597602

Epoch: 5| Step: 7
Training loss: 1.1101444423619409
Validation loss: 2.5247239920346445

Epoch: 5| Step: 8
Training loss: 1.5584523990179755
Validation loss: 2.499475970772834

Epoch: 5| Step: 9
Training loss: 1.2533157241544692
Validation loss: 2.50413324763311

Epoch: 5| Step: 10
Training loss: 0.737910465197906
Validation loss: 2.4667559325357775

Epoch: 332| Step: 0
Training loss: 1.1024043876899747
Validation loss: 2.448097679621193

Epoch: 5| Step: 1
Training loss: 0.9080028682318939
Validation loss: 2.4337545425493405

Epoch: 5| Step: 2
Training loss: 1.0559008929931206
Validation loss: 2.3987378961802293

Epoch: 5| Step: 3
Training loss: 0.8235551232543655
Validation loss: 2.4202490835668526

Epoch: 5| Step: 4
Training loss: 0.9574627273416467
Validation loss: 2.4387430976316757

Epoch: 5| Step: 5
Training loss: 1.12927657128591
Validation loss: 2.4291502128329054

Epoch: 5| Step: 6
Training loss: 1.0610934090982405
Validation loss: 2.475312610836374

Epoch: 5| Step: 7
Training loss: 0.9937638503734895
Validation loss: 2.473083342050825

Epoch: 5| Step: 8
Training loss: 1.0283589152075936
Validation loss: 2.443988077461721

Epoch: 5| Step: 9
Training loss: 1.63013351642498
Validation loss: 2.4596321671679076

Epoch: 5| Step: 10
Training loss: 1.1516247073882946
Validation loss: 2.4911560193266338

Epoch: 333| Step: 0
Training loss: 0.9797505639812679
Validation loss: 2.4645316503925963

Epoch: 5| Step: 1
Training loss: 1.0740840203152326
Validation loss: 2.45931112206968

Epoch: 5| Step: 2
Training loss: 0.7283718591127748
Validation loss: 2.47898109350224

Epoch: 5| Step: 3
Training loss: 0.9257990195584993
Validation loss: 2.456728525272742

Epoch: 5| Step: 4
Training loss: 1.6605808567759863
Validation loss: 2.487221824809555

Epoch: 5| Step: 5
Training loss: 1.0573478207764213
Validation loss: 2.4865577392662868

Epoch: 5| Step: 6
Training loss: 1.290266734499028
Validation loss: 2.44793734274471

Epoch: 5| Step: 7
Training loss: 0.7639876783435893
Validation loss: 2.4755450528889944

Epoch: 5| Step: 8
Training loss: 1.2378060665603867
Validation loss: 2.4549441302202104

Epoch: 5| Step: 9
Training loss: 1.0638355388384422
Validation loss: 2.4465828001171923

Epoch: 5| Step: 10
Training loss: 0.7830879336000718
Validation loss: 2.4588395475763574

Epoch: 334| Step: 0
Training loss: 1.677003285963812
Validation loss: 2.4831681325894586

Epoch: 5| Step: 1
Training loss: 0.9155398111130284
Validation loss: 2.474905333599411

Epoch: 5| Step: 2
Training loss: 1.0538953844193237
Validation loss: 2.4429760777505196

Epoch: 5| Step: 3
Training loss: 0.7758620820282975
Validation loss: 2.4799710209182475

Epoch: 5| Step: 4
Training loss: 1.1428361650227574
Validation loss: 2.4526000565387394

Epoch: 5| Step: 5
Training loss: 0.8941557316735093
Validation loss: 2.4726326508503873

Epoch: 5| Step: 6
Training loss: 1.076427173275482
Validation loss: 2.4735371904874914

Epoch: 5| Step: 7
Training loss: 0.7818455905399395
Validation loss: 2.4611533479686925

Epoch: 5| Step: 8
Training loss: 0.9476773655135753
Validation loss: 2.4454178687657033

Epoch: 5| Step: 9
Training loss: 0.821030438828829
Validation loss: 2.4563773062442156

Epoch: 5| Step: 10
Training loss: 1.439637709316161
Validation loss: 2.473128281069734

Epoch: 335| Step: 0
Training loss: 1.0146614198707775
Validation loss: 2.4686245671582223

Epoch: 5| Step: 1
Training loss: 1.5391812351338008
Validation loss: 2.4604424153928957

Epoch: 5| Step: 2
Training loss: 1.13710555479246
Validation loss: 2.472190064031393

Epoch: 5| Step: 3
Training loss: 0.42423188626515224
Validation loss: 2.441022233323254

Epoch: 5| Step: 4
Training loss: 1.060191114129287
Validation loss: 2.4811589780687853

Epoch: 5| Step: 5
Training loss: 0.9129685270331047
Validation loss: 2.4683744727233763

Epoch: 5| Step: 6
Training loss: 1.16595443488352
Validation loss: 2.448970410960693

Epoch: 5| Step: 7
Training loss: 1.077209415594654
Validation loss: 2.4396355242704746

Epoch: 5| Step: 8
Training loss: 0.989225998994872
Validation loss: 2.446508370523306

Epoch: 5| Step: 9
Training loss: 1.1211048085800404
Validation loss: 2.454328576279036

Epoch: 5| Step: 10
Training loss: 1.0684702813920552
Validation loss: 2.4808685670391415

Epoch: 336| Step: 0
Training loss: 1.2220306258351818
Validation loss: 2.468683272270335

Epoch: 5| Step: 1
Training loss: 0.9990138018936745
Validation loss: 2.463371534434171

Epoch: 5| Step: 2
Training loss: 1.073311384363627
Validation loss: 2.4833688357928216

Epoch: 5| Step: 3
Training loss: 1.4319497642496384
Validation loss: 2.4685139852834745

Epoch: 5| Step: 4
Training loss: 0.9257926779254941
Validation loss: 2.478794712329874

Epoch: 5| Step: 5
Training loss: 0.9167911199414263
Validation loss: 2.45090636095829

Epoch: 5| Step: 6
Training loss: 0.8159801338479594
Validation loss: 2.4853793097005097

Epoch: 5| Step: 7
Training loss: 1.0793519156880553
Validation loss: 2.461182184746412

Epoch: 5| Step: 8
Training loss: 0.7277943822391794
Validation loss: 2.4519893211240005

Epoch: 5| Step: 9
Training loss: 1.3366619621980471
Validation loss: 2.4473388143439565

Epoch: 5| Step: 10
Training loss: 1.0496336615776218
Validation loss: 2.4242881668915133

Epoch: 337| Step: 0
Training loss: 1.0056393873514393
Validation loss: 2.4394034533309554

Epoch: 5| Step: 1
Training loss: 0.8594516026428183
Validation loss: 2.4599123083612575

Epoch: 5| Step: 2
Training loss: 1.1240837816732456
Validation loss: 2.470147690115827

Epoch: 5| Step: 3
Training loss: 1.1383595897184005
Validation loss: 2.441131286494437

Epoch: 5| Step: 4
Training loss: 1.119987872773318
Validation loss: 2.4271990900603666

Epoch: 5| Step: 5
Training loss: 1.0551936312696575
Validation loss: 2.438401377664531

Epoch: 5| Step: 6
Training loss: 0.8558173666829386
Validation loss: 2.4445696847919236

Epoch: 5| Step: 7
Training loss: 1.4968284615626857
Validation loss: 2.477029479159357

Epoch: 5| Step: 8
Training loss: 1.06526396779892
Validation loss: 2.4706001747644604

Epoch: 5| Step: 9
Training loss: 0.7147062826086238
Validation loss: 2.4856498266103717

Epoch: 5| Step: 10
Training loss: 0.9171590602436182
Validation loss: 2.4615565242678477

Epoch: 338| Step: 0
Training loss: 0.6903781898641719
Validation loss: 2.484974139895595

Epoch: 5| Step: 1
Training loss: 0.9673165206022113
Validation loss: 2.490912456230712

Epoch: 5| Step: 2
Training loss: 0.5905476090524681
Validation loss: 2.4708160772756695

Epoch: 5| Step: 3
Training loss: 0.9992214092490667
Validation loss: 2.4742714366521947

Epoch: 5| Step: 4
Training loss: 1.4763641224160784
Validation loss: 2.482675666822552

Epoch: 5| Step: 5
Training loss: 1.1541268212134552
Validation loss: 2.4669309897952862

Epoch: 5| Step: 6
Training loss: 1.0295824961168092
Validation loss: 2.4823469584730806

Epoch: 5| Step: 7
Training loss: 0.7186708406726432
Validation loss: 2.460892602967068

Epoch: 5| Step: 8
Training loss: 1.1878378036280737
Validation loss: 2.4379127737712487

Epoch: 5| Step: 9
Training loss: 1.5322691192454851
Validation loss: 2.426013109737246

Epoch: 5| Step: 10
Training loss: 0.6895909806448869
Validation loss: 2.4495556466803228

Epoch: 339| Step: 0
Training loss: 1.0582930922679932
Validation loss: 2.420143598312997

Epoch: 5| Step: 1
Training loss: 0.9519011660590666
Validation loss: 2.44592258884261

Epoch: 5| Step: 2
Training loss: 1.1186753615729874
Validation loss: 2.4715069949904502

Epoch: 5| Step: 3
Training loss: 1.3023190958839417
Validation loss: 2.489161957521011

Epoch: 5| Step: 4
Training loss: 0.6814946890097183
Validation loss: 2.486822548815982

Epoch: 5| Step: 5
Training loss: 1.0384375621739386
Validation loss: 2.454451131007902

Epoch: 5| Step: 6
Training loss: 0.7736325258920432
Validation loss: 2.4914771133611398

Epoch: 5| Step: 7
Training loss: 0.683128787359155
Validation loss: 2.502395756595004

Epoch: 5| Step: 8
Training loss: 1.1334550810849993
Validation loss: 2.4978280446279926

Epoch: 5| Step: 9
Training loss: 0.5277377881688697
Validation loss: 2.4886929778660463

Epoch: 5| Step: 10
Training loss: 1.7938863031258365
Validation loss: 2.4816420781393647

Epoch: 340| Step: 0
Training loss: 0.422810735339354
Validation loss: 2.444830836974675

Epoch: 5| Step: 1
Training loss: 0.8724332013833536
Validation loss: 2.3978813595220387

Epoch: 5| Step: 2
Training loss: 0.8567276840398119
Validation loss: 2.3939920695047383

Epoch: 5| Step: 3
Training loss: 1.1302357800691782
Validation loss: 2.362856623469923

Epoch: 5| Step: 4
Training loss: 1.0161217281754864
Validation loss: 2.370955866285212

Epoch: 5| Step: 5
Training loss: 1.3524127116214328
Validation loss: 2.3615168168825655

Epoch: 5| Step: 6
Training loss: 0.7016456087498437
Validation loss: 2.4020302460664174

Epoch: 5| Step: 7
Training loss: 1.0994273385693023
Validation loss: 2.427531259176074

Epoch: 5| Step: 8
Training loss: 1.1860993808838312
Validation loss: 2.5028405408197116

Epoch: 5| Step: 9
Training loss: 1.6134868795584307
Validation loss: 2.5140847497300154

Epoch: 5| Step: 10
Training loss: 0.6391374250293879
Validation loss: 2.5432619837162584

Epoch: 341| Step: 0
Training loss: 1.0754252368970283
Validation loss: 2.543562668256254

Epoch: 5| Step: 1
Training loss: 0.88655713999126
Validation loss: 2.55864860189683

Epoch: 5| Step: 2
Training loss: 0.9555844328149241
Validation loss: 2.5388544873016277

Epoch: 5| Step: 3
Training loss: 0.6661393618374964
Validation loss: 2.5213035328709865

Epoch: 5| Step: 4
Training loss: 1.6258964266804816
Validation loss: 2.5027481018417346

Epoch: 5| Step: 5
Training loss: 0.9367878434228851
Validation loss: 2.506757342807888

Epoch: 5| Step: 6
Training loss: 0.7384464543300537
Validation loss: 2.466785243586839

Epoch: 5| Step: 7
Training loss: 0.878603734830251
Validation loss: 2.449686589702981

Epoch: 5| Step: 8
Training loss: 1.058940985341965
Validation loss: 2.454882290515706

Epoch: 5| Step: 9
Training loss: 1.0323374245693624
Validation loss: 2.477526689411757

Epoch: 5| Step: 10
Training loss: 1.2326403634266996
Validation loss: 2.4729698174265544

Epoch: 342| Step: 0
Training loss: 0.9965463245953567
Validation loss: 2.4664504344996887

Epoch: 5| Step: 1
Training loss: 0.9167593923544791
Validation loss: 2.448664012623005

Epoch: 5| Step: 2
Training loss: 0.9541782750474409
Validation loss: 2.441722990626232

Epoch: 5| Step: 3
Training loss: 1.2555446675390203
Validation loss: 2.4553639206608295

Epoch: 5| Step: 4
Training loss: 0.6843405431843622
Validation loss: 2.490015074250263

Epoch: 5| Step: 5
Training loss: 0.8859021295823526
Validation loss: 2.5010076020233294

Epoch: 5| Step: 6
Training loss: 1.3667943770742035
Validation loss: 2.470831593024513

Epoch: 5| Step: 7
Training loss: 0.9497847890524684
Validation loss: 2.4890028728708358

Epoch: 5| Step: 8
Training loss: 0.9416070621047389
Validation loss: 2.4895326078291875

Epoch: 5| Step: 9
Training loss: 1.2454269682040304
Validation loss: 2.485891772650713

Epoch: 5| Step: 10
Training loss: 0.822731556574687
Validation loss: 2.5221915949074925

Epoch: 343| Step: 0
Training loss: 1.067070666685722
Validation loss: 2.471375738454964

Epoch: 5| Step: 1
Training loss: 0.8497787482147992
Validation loss: 2.4838660501749183

Epoch: 5| Step: 2
Training loss: 0.9338649212284795
Validation loss: 2.452413428194819

Epoch: 5| Step: 3
Training loss: 0.6903362723557656
Validation loss: 2.4739807279876063

Epoch: 5| Step: 4
Training loss: 0.9492206024026261
Validation loss: 2.467975950462197

Epoch: 5| Step: 5
Training loss: 1.0114840673492005
Validation loss: 2.46491769771024

Epoch: 5| Step: 6
Training loss: 0.9078261710892236
Validation loss: 2.4242525548725595

Epoch: 5| Step: 7
Training loss: 0.7095401151632936
Validation loss: 2.438137153121423

Epoch: 5| Step: 8
Training loss: 0.9125611454582834
Validation loss: 2.462905143531122

Epoch: 5| Step: 9
Training loss: 1.5984836664925473
Validation loss: 2.523182392702277

Epoch: 5| Step: 10
Training loss: 1.275706557302479
Validation loss: 2.494818292935089

Epoch: 344| Step: 0
Training loss: 0.4481849052046612
Validation loss: 2.487890984255185

Epoch: 5| Step: 1
Training loss: 0.8834233491544863
Validation loss: 2.544545821615456

Epoch: 5| Step: 2
Training loss: 1.393787559721648
Validation loss: 2.5156251182140847

Epoch: 5| Step: 3
Training loss: 1.1595407516569276
Validation loss: 2.480350782066289

Epoch: 5| Step: 4
Training loss: 0.8844678095452803
Validation loss: 2.4421536185958606

Epoch: 5| Step: 5
Training loss: 0.8129688524095484
Validation loss: 2.446629460753696

Epoch: 5| Step: 6
Training loss: 0.816232361595641
Validation loss: 2.4424890229558742

Epoch: 5| Step: 7
Training loss: 0.9303847831551
Validation loss: 2.4175155214613393

Epoch: 5| Step: 8
Training loss: 1.0545723181101168
Validation loss: 2.362740775667068

Epoch: 5| Step: 9
Training loss: 0.9582026572212728
Validation loss: 2.367811475647233

Epoch: 5| Step: 10
Training loss: 1.535739545202523
Validation loss: 2.368253862111716

Epoch: 345| Step: 0
Training loss: 0.900991574403613
Validation loss: 2.405425848028748

Epoch: 5| Step: 1
Training loss: 1.0266495016033739
Validation loss: 2.450264101608522

Epoch: 5| Step: 2
Training loss: 0.41773869966145044
Validation loss: 2.5241326115353773

Epoch: 5| Step: 3
Training loss: 0.8078996194461078
Validation loss: 2.5231338948722404

Epoch: 5| Step: 4
Training loss: 0.9839390288804326
Validation loss: 2.519259597621756

Epoch: 5| Step: 5
Training loss: 1.726833270490665
Validation loss: 2.509594069003707

Epoch: 5| Step: 6
Training loss: 1.136076231071034
Validation loss: 2.5398167643245824

Epoch: 5| Step: 7
Training loss: 0.7648381841844736
Validation loss: 2.5779120443375905

Epoch: 5| Step: 8
Training loss: 0.9660584375108858
Validation loss: 2.5210662025062067

Epoch: 5| Step: 9
Training loss: 0.7546100395050425
Validation loss: 2.4974579818386893

Epoch: 5| Step: 10
Training loss: 1.1264668544425596
Validation loss: 2.4447673939765378

Epoch: 346| Step: 0
Training loss: 0.6316701208622412
Validation loss: 2.4294111579184676

Epoch: 5| Step: 1
Training loss: 1.0491430282252778
Validation loss: 2.412245773597958

Epoch: 5| Step: 2
Training loss: 1.3139006543366387
Validation loss: 2.444144568580677

Epoch: 5| Step: 3
Training loss: 1.0240622208064947
Validation loss: 2.380215257598814

Epoch: 5| Step: 4
Training loss: 0.989108798373175
Validation loss: 2.3861457501145775

Epoch: 5| Step: 5
Training loss: 0.7342600225167861
Validation loss: 2.4186927341987925

Epoch: 5| Step: 6
Training loss: 0.9620910791476556
Validation loss: 2.440046930258523

Epoch: 5| Step: 7
Training loss: 1.4631239090059525
Validation loss: 2.4763233321261517

Epoch: 5| Step: 8
Training loss: 0.9378896221519362
Validation loss: 2.4844427478107773

Epoch: 5| Step: 9
Training loss: 0.9987054134056026
Validation loss: 2.526120576090118

Epoch: 5| Step: 10
Training loss: 0.7318461278730745
Validation loss: 2.4826391043446487

Epoch: 347| Step: 0
Training loss: 0.7291433784762311
Validation loss: 2.4810504288468334

Epoch: 5| Step: 1
Training loss: 1.3117528332751824
Validation loss: 2.4763808267413787

Epoch: 5| Step: 2
Training loss: 1.0402117805161528
Validation loss: 2.465772096269518

Epoch: 5| Step: 3
Training loss: 1.0299134118062943
Validation loss: 2.442679609544424

Epoch: 5| Step: 4
Training loss: 1.0322832075761068
Validation loss: 2.413944598191836

Epoch: 5| Step: 5
Training loss: 1.2025729312312474
Validation loss: 2.391641795085624

Epoch: 5| Step: 6
Training loss: 1.1076777732717804
Validation loss: 2.4197647539115814

Epoch: 5| Step: 7
Training loss: 0.8660927125228457
Validation loss: 2.4180565452205727

Epoch: 5| Step: 8
Training loss: 0.7740623570219916
Validation loss: 2.43439380804297

Epoch: 5| Step: 9
Training loss: 1.010082320644892
Validation loss: 2.4538637627797892

Epoch: 5| Step: 10
Training loss: 0.6741285234992637
Validation loss: 2.486521679785361

Epoch: 348| Step: 0
Training loss: 1.058137464545662
Validation loss: 2.485351279868929

Epoch: 5| Step: 1
Training loss: 1.200124193758436
Validation loss: 2.4843703667392454

Epoch: 5| Step: 2
Training loss: 0.7267935600807939
Validation loss: 2.501420302610006

Epoch: 5| Step: 3
Training loss: 0.8867702721235096
Validation loss: 2.4741041738703773

Epoch: 5| Step: 4
Training loss: 0.9514882464321891
Validation loss: 2.486765560560737

Epoch: 5| Step: 5
Training loss: 1.003834525191919
Validation loss: 2.478758111223038

Epoch: 5| Step: 6
Training loss: 0.7766799009066025
Validation loss: 2.454625628701623

Epoch: 5| Step: 7
Training loss: 0.8768366543031948
Validation loss: 2.435813457063874

Epoch: 5| Step: 8
Training loss: 1.5053035437579019
Validation loss: 2.3938874812585174

Epoch: 5| Step: 9
Training loss: 0.8965343719037675
Validation loss: 2.3863150253799685

Epoch: 5| Step: 10
Training loss: 0.8550830476705428
Validation loss: 2.382591944478909

Epoch: 349| Step: 0
Training loss: 0.7288962180539973
Validation loss: 2.4030336646068635

Epoch: 5| Step: 1
Training loss: 1.0326123342297169
Validation loss: 2.3840558027169516

Epoch: 5| Step: 2
Training loss: 0.9202753185798828
Validation loss: 2.435938892399492

Epoch: 5| Step: 3
Training loss: 0.9375949175786413
Validation loss: 2.4461750845862724

Epoch: 5| Step: 4
Training loss: 0.9126277324686289
Validation loss: 2.449666431070798

Epoch: 5| Step: 5
Training loss: 1.0540387454213271
Validation loss: 2.4433324327794437

Epoch: 5| Step: 6
Training loss: 1.0241438779372602
Validation loss: 2.4661236852845994

Epoch: 5| Step: 7
Training loss: 0.8844728638112888
Validation loss: 2.451305808249526

Epoch: 5| Step: 8
Training loss: 0.6334470934299008
Validation loss: 2.465390545961287

Epoch: 5| Step: 9
Training loss: 1.0986774079490627
Validation loss: 2.4852037007998447

Epoch: 5| Step: 10
Training loss: 1.5472220599853381
Validation loss: 2.492230888958778

Epoch: 350| Step: 0
Training loss: 1.032076071286413
Validation loss: 2.4929279990547437

Epoch: 5| Step: 1
Training loss: 1.1438362693561808
Validation loss: 2.4950858763955317

Epoch: 5| Step: 2
Training loss: 0.7084614320001575
Validation loss: 2.5034534976149314

Epoch: 5| Step: 3
Training loss: 0.8616756162111032
Validation loss: 2.4543973017705154

Epoch: 5| Step: 4
Training loss: 1.0890833892351337
Validation loss: 2.4389279605175145

Epoch: 5| Step: 5
Training loss: 0.7496162465920103
Validation loss: 2.4456581632281114

Epoch: 5| Step: 6
Training loss: 0.8863331969020644
Validation loss: 2.4270511628410034

Epoch: 5| Step: 7
Training loss: 0.8771439580435609
Validation loss: 2.443119537028664

Epoch: 5| Step: 8
Training loss: 1.4921342131202506
Validation loss: 2.443465143793625

Epoch: 5| Step: 9
Training loss: 0.8190286307844105
Validation loss: 2.4320951799066735

Epoch: 5| Step: 10
Training loss: 0.9600179350687603
Validation loss: 2.441053409272926

Epoch: 351| Step: 0
Training loss: 0.5704626904606969
Validation loss: 2.4443956422999364

Epoch: 5| Step: 1
Training loss: 0.8826630727511342
Validation loss: 2.4139674929603308

Epoch: 5| Step: 2
Training loss: 0.9582817782480354
Validation loss: 2.4539958196452756

Epoch: 5| Step: 3
Training loss: 0.9709083447654001
Validation loss: 2.423892954782971

Epoch: 5| Step: 4
Training loss: 1.0822005156732055
Validation loss: 2.4444311129329837

Epoch: 5| Step: 5
Training loss: 0.8348967945825505
Validation loss: 2.44188700743655

Epoch: 5| Step: 6
Training loss: 0.971236636881173
Validation loss: 2.434305388833217

Epoch: 5| Step: 7
Training loss: 0.8623976522341178
Validation loss: 2.400918366733698

Epoch: 5| Step: 8
Training loss: 0.8093266505819663
Validation loss: 2.4727021340274677

Epoch: 5| Step: 9
Training loss: 1.086597434209964
Validation loss: 2.449439192436075

Epoch: 5| Step: 10
Training loss: 1.5557011505897556
Validation loss: 2.4256571117277255

Epoch: 352| Step: 0
Training loss: 0.9299386270330238
Validation loss: 2.428078551735106

Epoch: 5| Step: 1
Training loss: 0.9353551488980041
Validation loss: 2.428319432911254

Epoch: 5| Step: 2
Training loss: 0.5915706441311612
Validation loss: 2.458209073399085

Epoch: 5| Step: 3
Training loss: 0.6855229430626788
Validation loss: 2.4424042238999335

Epoch: 5| Step: 4
Training loss: 0.9037137551116385
Validation loss: 2.463351145917525

Epoch: 5| Step: 5
Training loss: 0.8776313520950618
Validation loss: 2.4610161725276

Epoch: 5| Step: 6
Training loss: 1.1405167201654918
Validation loss: 2.4545165504923974

Epoch: 5| Step: 7
Training loss: 0.9206761145402759
Validation loss: 2.4562830184883593

Epoch: 5| Step: 8
Training loss: 0.854103148044778
Validation loss: 2.4842603170329367

Epoch: 5| Step: 9
Training loss: 1.6667962341808003
Validation loss: 2.4605335363055594

Epoch: 5| Step: 10
Training loss: 0.7790777907112307
Validation loss: 2.4291705422479652

Epoch: 353| Step: 0
Training loss: 0.7532504693456201
Validation loss: 2.4470012125095004

Epoch: 5| Step: 1
Training loss: 1.5966204804341795
Validation loss: 2.4359592440904425

Epoch: 5| Step: 2
Training loss: 1.0664149692723899
Validation loss: 2.414179448826881

Epoch: 5| Step: 3
Training loss: 0.66107294665256
Validation loss: 2.4187280030524976

Epoch: 5| Step: 4
Training loss: 0.8168344789128682
Validation loss: 2.4595234616123305

Epoch: 5| Step: 5
Training loss: 0.87537110497135
Validation loss: 2.4352061719386175

Epoch: 5| Step: 6
Training loss: 0.9062541106558342
Validation loss: 2.460670253803001

Epoch: 5| Step: 7
Training loss: 0.8323639397081819
Validation loss: 2.445104493765845

Epoch: 5| Step: 8
Training loss: 0.6094313864418422
Validation loss: 2.4718654762388375

Epoch: 5| Step: 9
Training loss: 0.9910126586436623
Validation loss: 2.435636909019968

Epoch: 5| Step: 10
Training loss: 1.1681404115202125
Validation loss: 2.451090432777421

Epoch: 354| Step: 0
Training loss: 0.8788295458065691
Validation loss: 2.456394727076771

Epoch: 5| Step: 1
Training loss: 1.1160624247596493
Validation loss: 2.4312393091231765

Epoch: 5| Step: 2
Training loss: 0.8514923276773991
Validation loss: 2.425819099047372

Epoch: 5| Step: 3
Training loss: 0.723321556868546
Validation loss: 2.443111713205517

Epoch: 5| Step: 4
Training loss: 1.7059268128325338
Validation loss: 2.4395570029354388

Epoch: 5| Step: 5
Training loss: 0.6256743607689002
Validation loss: 2.4611746225026563

Epoch: 5| Step: 6
Training loss: 1.0683367236872618
Validation loss: 2.4552269249127416

Epoch: 5| Step: 7
Training loss: 0.7315801233957798
Validation loss: 2.4673710610787487

Epoch: 5| Step: 8
Training loss: 0.7645980019335992
Validation loss: 2.4596855233037256

Epoch: 5| Step: 9
Training loss: 0.7664021809787817
Validation loss: 2.4584602738927286

Epoch: 5| Step: 10
Training loss: 0.8311175491818313
Validation loss: 2.440053326620633

Epoch: 355| Step: 0
Training loss: 1.047569158633625
Validation loss: 2.475121120034435

Epoch: 5| Step: 1
Training loss: 0.7177441234181963
Validation loss: 2.4567726636040184

Epoch: 5| Step: 2
Training loss: 0.8037064506989545
Validation loss: 2.4155112679253885

Epoch: 5| Step: 3
Training loss: 0.9427559069577659
Validation loss: 2.4905997406996487

Epoch: 5| Step: 4
Training loss: 1.021703401209037
Validation loss: 2.4608608196791453

Epoch: 5| Step: 5
Training loss: 1.5938511984616144
Validation loss: 2.4557842020152707

Epoch: 5| Step: 6
Training loss: 0.6935347214459231
Validation loss: 2.4931542394371675

Epoch: 5| Step: 7
Training loss: 0.8976413682412862
Validation loss: 2.44487719917308

Epoch: 5| Step: 8
Training loss: 0.6459939946539144
Validation loss: 2.4433287384047526

Epoch: 5| Step: 9
Training loss: 0.8088524077609839
Validation loss: 2.4109532321994593

Epoch: 5| Step: 10
Training loss: 0.9322661852772988
Validation loss: 2.431382011376586

Epoch: 356| Step: 0
Training loss: 1.3353601289981822
Validation loss: 2.460026348021934

Epoch: 5| Step: 1
Training loss: 0.37540342565141066
Validation loss: 2.425465968392501

Epoch: 5| Step: 2
Training loss: 0.8960288558915737
Validation loss: 2.4240078894584487

Epoch: 5| Step: 3
Training loss: 0.994901534532703
Validation loss: 2.4523362589349036

Epoch: 5| Step: 4
Training loss: 1.2424899998498449
Validation loss: 2.4837177563231574

Epoch: 5| Step: 5
Training loss: 0.7065666948722885
Validation loss: 2.506905467694935

Epoch: 5| Step: 6
Training loss: 0.6006967581874066
Validation loss: 2.5115120421748984

Epoch: 5| Step: 7
Training loss: 0.7459907660385827
Validation loss: 2.4869956122246935

Epoch: 5| Step: 8
Training loss: 1.0278855552238082
Validation loss: 2.4630271039324483

Epoch: 5| Step: 9
Training loss: 1.0663382819457288
Validation loss: 2.4488911305667487

Epoch: 5| Step: 10
Training loss: 1.0218992831176787
Validation loss: 2.4298426025948534

Epoch: 357| Step: 0
Training loss: 0.4202290320921089
Validation loss: 2.4204500624996577

Epoch: 5| Step: 1
Training loss: 0.9812654396834823
Validation loss: 2.365192369771065

Epoch: 5| Step: 2
Training loss: 1.4217913257166315
Validation loss: 2.3583209095248665

Epoch: 5| Step: 3
Training loss: 0.8363672738175207
Validation loss: 2.3827542409998363

Epoch: 5| Step: 4
Training loss: 1.1385272344783794
Validation loss: 2.38553329965748

Epoch: 5| Step: 5
Training loss: 0.9668342660166106
Validation loss: 2.3966093977722793

Epoch: 5| Step: 6
Training loss: 0.9055601322380862
Validation loss: 2.4432859310963306

Epoch: 5| Step: 7
Training loss: 1.0189790947878292
Validation loss: 2.452892014419337

Epoch: 5| Step: 8
Training loss: 0.7341966209478304
Validation loss: 2.4253852516653747

Epoch: 5| Step: 9
Training loss: 0.7443317157962965
Validation loss: 2.440372039747358

Epoch: 5| Step: 10
Training loss: 0.9059646091306679
Validation loss: 2.4296890304682477

Epoch: 358| Step: 0
Training loss: 0.7545357877460975
Validation loss: 2.493670573873984

Epoch: 5| Step: 1
Training loss: 0.8628068543953729
Validation loss: 2.5027102218217365

Epoch: 5| Step: 2
Training loss: 0.7995032183646196
Validation loss: 2.5196222490935094

Epoch: 5| Step: 3
Training loss: 0.8671195201175466
Validation loss: 2.4960626883997894

Epoch: 5| Step: 4
Training loss: 0.888974182354758
Validation loss: 2.4504126728386595

Epoch: 5| Step: 5
Training loss: 0.7446975426230847
Validation loss: 2.4334285979419015

Epoch: 5| Step: 6
Training loss: 1.486504803657148
Validation loss: 2.434594384318711

Epoch: 5| Step: 7
Training loss: 1.1681834760289123
Validation loss: 2.413155169337198

Epoch: 5| Step: 8
Training loss: 1.0321138405221408
Validation loss: 2.3765396002608816

Epoch: 5| Step: 9
Training loss: 0.6722863956059975
Validation loss: 2.342315268052406

Epoch: 5| Step: 10
Training loss: 0.7467571325149869
Validation loss: 2.3407637343529863

Epoch: 359| Step: 0
Training loss: 1.077315427367749
Validation loss: 2.3627072426291282

Epoch: 5| Step: 1
Training loss: 0.6905604863133565
Validation loss: 2.349563332637113

Epoch: 5| Step: 2
Training loss: 0.6966477549608256
Validation loss: 2.3638861208655295

Epoch: 5| Step: 3
Training loss: 0.8174987127428098
Validation loss: 2.380842823893458

Epoch: 5| Step: 4
Training loss: 0.6763343532082038
Validation loss: 2.4293315151724983

Epoch: 5| Step: 5
Training loss: 0.778085058022092
Validation loss: 2.457929022821705

Epoch: 5| Step: 6
Training loss: 1.0778078359058894
Validation loss: 2.5088572668917104

Epoch: 5| Step: 7
Training loss: 1.4918904433232187
Validation loss: 2.5334369656712328

Epoch: 5| Step: 8
Training loss: 0.8465447235775726
Validation loss: 2.539252351110832

Epoch: 5| Step: 9
Training loss: 1.031438521290782
Validation loss: 2.530689731496434

Epoch: 5| Step: 10
Training loss: 0.8267940406062263
Validation loss: 2.528946668546248

Epoch: 360| Step: 0
Training loss: 0.9242709753737951
Validation loss: 2.491152532744307

Epoch: 5| Step: 1
Training loss: 0.751771027946121
Validation loss: 2.4989370260209234

Epoch: 5| Step: 2
Training loss: 0.6193965058197062
Validation loss: 2.472854962671833

Epoch: 5| Step: 3
Training loss: 0.8187262320526608
Validation loss: 2.444010109674437

Epoch: 5| Step: 4
Training loss: 0.5091482640773741
Validation loss: 2.42967520135218

Epoch: 5| Step: 5
Training loss: 1.20232434074297
Validation loss: 2.4286291854155615

Epoch: 5| Step: 6
Training loss: 0.9956983192779831
Validation loss: 2.402539181540621

Epoch: 5| Step: 7
Training loss: 0.6281884640568707
Validation loss: 2.4029495709263204

Epoch: 5| Step: 8
Training loss: 0.9141971456360889
Validation loss: 2.4066012882125585

Epoch: 5| Step: 9
Training loss: 1.4506237694350073
Validation loss: 2.4531679439032033

Epoch: 5| Step: 10
Training loss: 1.0608550970917054
Validation loss: 2.4441158802013416

Epoch: 361| Step: 0
Training loss: 0.7417147285090432
Validation loss: 2.4426526104981447

Epoch: 5| Step: 1
Training loss: 0.6987481051711049
Validation loss: 2.470940032460799

Epoch: 5| Step: 2
Training loss: 0.4440917633207622
Validation loss: 2.4770560595242324

Epoch: 5| Step: 3
Training loss: 1.5934938711162827
Validation loss: 2.4965476399259217

Epoch: 5| Step: 4
Training loss: 0.9282983611577617
Validation loss: 2.463612208375066

Epoch: 5| Step: 5
Training loss: 0.9531310972425205
Validation loss: 2.5009592635977875

Epoch: 5| Step: 6
Training loss: 0.953912878364947
Validation loss: 2.4683378578343924

Epoch: 5| Step: 7
Training loss: 1.0162134666492046
Validation loss: 2.441461877726473

Epoch: 5| Step: 8
Training loss: 0.7866132512047949
Validation loss: 2.440258200437058

Epoch: 5| Step: 9
Training loss: 0.8243904477306859
Validation loss: 2.4348231842344163

Epoch: 5| Step: 10
Training loss: 0.7439037356447331
Validation loss: 2.412467429844306

Epoch: 362| Step: 0
Training loss: 0.5068341440746058
Validation loss: 2.39079814543652

Epoch: 5| Step: 1
Training loss: 1.0275536964475125
Validation loss: 2.384219867307303

Epoch: 5| Step: 2
Training loss: 0.5581333957736938
Validation loss: 2.397044018152789

Epoch: 5| Step: 3
Training loss: 0.7309426794892008
Validation loss: 2.386203284918635

Epoch: 5| Step: 4
Training loss: 0.8128235246203253
Validation loss: 2.4159226366611577

Epoch: 5| Step: 5
Training loss: 0.7260870659826117
Validation loss: 2.4027014451977426

Epoch: 5| Step: 6
Training loss: 0.6013345410318293
Validation loss: 2.4441337660309452

Epoch: 5| Step: 7
Training loss: 0.9466424209440428
Validation loss: 2.468165961876982

Epoch: 5| Step: 8
Training loss: 0.8719983728004287
Validation loss: 2.516542417594849

Epoch: 5| Step: 9
Training loss: 1.653147689000208
Validation loss: 2.4884288525964924

Epoch: 5| Step: 10
Training loss: 1.1196070792478294
Validation loss: 2.472469518024786

Epoch: 363| Step: 0
Training loss: 0.5806455309618436
Validation loss: 2.4825303007457937

Epoch: 5| Step: 1
Training loss: 0.6192302939768105
Validation loss: 2.4200390586880762

Epoch: 5| Step: 2
Training loss: 0.739495222905471
Validation loss: 2.4052451450996357

Epoch: 5| Step: 3
Training loss: 1.4977224065728163
Validation loss: 2.390778963612422

Epoch: 5| Step: 4
Training loss: 0.7145347552752608
Validation loss: 2.386205403555015

Epoch: 5| Step: 5
Training loss: 0.9191603697776972
Validation loss: 2.3827517911404983

Epoch: 5| Step: 6
Training loss: 1.1002798526409099
Validation loss: 2.389319212637569

Epoch: 5| Step: 7
Training loss: 1.2627216050197891
Validation loss: 2.4030878208131163

Epoch: 5| Step: 8
Training loss: 0.63694581271723
Validation loss: 2.4323760310486495

Epoch: 5| Step: 9
Training loss: 0.8429340726633258
Validation loss: 2.413607282469482

Epoch: 5| Step: 10
Training loss: 0.6195914375153124
Validation loss: 2.4195084975610253

Epoch: 364| Step: 0
Training loss: 0.9576829832045571
Validation loss: 2.4469295699457905

Epoch: 5| Step: 1
Training loss: 0.8787868503424527
Validation loss: 2.483960403496413

Epoch: 5| Step: 2
Training loss: 0.8095498812942272
Validation loss: 2.4677021637306167

Epoch: 5| Step: 3
Training loss: 1.4652132509234834
Validation loss: 2.456342806536151

Epoch: 5| Step: 4
Training loss: 0.8533034420986976
Validation loss: 2.4576518652595243

Epoch: 5| Step: 5
Training loss: 0.8422380251759274
Validation loss: 2.430023902332581

Epoch: 5| Step: 6
Training loss: 0.7779166635950214
Validation loss: 2.430249356047633

Epoch: 5| Step: 7
Training loss: 0.7436541872258421
Validation loss: 2.407741112322985

Epoch: 5| Step: 8
Training loss: 0.7014382369136059
Validation loss: 2.3802367578236665

Epoch: 5| Step: 9
Training loss: 0.724780574018158
Validation loss: 2.416944076972437

Epoch: 5| Step: 10
Training loss: 1.0117058476984062
Validation loss: 2.3877361219716686

Epoch: 365| Step: 0
Training loss: 1.231430888564168
Validation loss: 2.433231800693011

Epoch: 5| Step: 1
Training loss: 0.6616146748924677
Validation loss: 2.4147939816607153

Epoch: 5| Step: 2
Training loss: 0.716931322673915
Validation loss: 2.4531223466141783

Epoch: 5| Step: 3
Training loss: 0.8892339584666793
Validation loss: 2.4658095134188764

Epoch: 5| Step: 4
Training loss: 0.5907541537483886
Validation loss: 2.411097007239103

Epoch: 5| Step: 5
Training loss: 0.6388269638605192
Validation loss: 2.425837742239143

Epoch: 5| Step: 6
Training loss: 0.8154494962741813
Validation loss: 2.41137846744008

Epoch: 5| Step: 7
Training loss: 1.579661612671168
Validation loss: 2.4448965547690125

Epoch: 5| Step: 8
Training loss: 0.7780515429282715
Validation loss: 2.4163327370055816

Epoch: 5| Step: 9
Training loss: 1.0054926231413388
Validation loss: 2.455466957401323

Epoch: 5| Step: 10
Training loss: 0.4451764384090681
Validation loss: 2.461241627756343

Epoch: 366| Step: 0
Training loss: 0.9898658683732359
Validation loss: 2.4465383621601973

Epoch: 5| Step: 1
Training loss: 0.9948916193626856
Validation loss: 2.4912545595688744

Epoch: 5| Step: 2
Training loss: 0.7482078916794769
Validation loss: 2.4766063065861634

Epoch: 5| Step: 3
Training loss: 0.7211255332083871
Validation loss: 2.4573448332275096

Epoch: 5| Step: 4
Training loss: 1.1529749289348488
Validation loss: 2.49449195442779

Epoch: 5| Step: 5
Training loss: 0.6128548275551011
Validation loss: 2.4067017166266482

Epoch: 5| Step: 6
Training loss: 0.7844465853788262
Validation loss: 2.389102560131453

Epoch: 5| Step: 7
Training loss: 0.5379403085140018
Validation loss: 2.363176461166755

Epoch: 5| Step: 8
Training loss: 0.738868197491586
Validation loss: 2.356356661095441

Epoch: 5| Step: 9
Training loss: 0.9994685131550166
Validation loss: 2.3353711534119705

Epoch: 5| Step: 10
Training loss: 1.5758529775367762
Validation loss: 2.375282527696823

Epoch: 367| Step: 0
Training loss: 0.7928357694020541
Validation loss: 2.3926437608004525

Epoch: 5| Step: 1
Training loss: 1.595668610254404
Validation loss: 2.42120339101814

Epoch: 5| Step: 2
Training loss: 0.7644265195088964
Validation loss: 2.4543481884551395

Epoch: 5| Step: 3
Training loss: 0.8150053279211094
Validation loss: 2.5356628659071063

Epoch: 5| Step: 4
Training loss: 0.8938261026380073
Validation loss: 2.5323737782096605

Epoch: 5| Step: 5
Training loss: 0.8943392618371211
Validation loss: 2.5268090213650014

Epoch: 5| Step: 6
Training loss: 0.6916430008719354
Validation loss: 2.5167293999436144

Epoch: 5| Step: 7
Training loss: 0.7060992172782524
Validation loss: 2.501913023751514

Epoch: 5| Step: 8
Training loss: 0.5588673808398199
Validation loss: 2.436092787714345

Epoch: 5| Step: 9
Training loss: 0.9800855336036588
Validation loss: 2.422867016130199

Epoch: 5| Step: 10
Training loss: 1.0403362297360836
Validation loss: 2.387750227806426

Epoch: 368| Step: 0
Training loss: 1.0752770776521092
Validation loss: 2.367303177844463

Epoch: 5| Step: 1
Training loss: 0.7478772162727061
Validation loss: 2.3887807064484976

Epoch: 5| Step: 2
Training loss: 0.7537414686944315
Validation loss: 2.4374354805938374

Epoch: 5| Step: 3
Training loss: 0.8850005724199244
Validation loss: 2.428963397563441

Epoch: 5| Step: 4
Training loss: 0.6607990182944342
Validation loss: 2.4429924377239334

Epoch: 5| Step: 5
Training loss: 1.0354504437121397
Validation loss: 2.39810778894302

Epoch: 5| Step: 6
Training loss: 0.6097574745430169
Validation loss: 2.4376407074683266

Epoch: 5| Step: 7
Training loss: 0.5810897175463564
Validation loss: 2.4381895896234203

Epoch: 5| Step: 8
Training loss: 0.7362897544192561
Validation loss: 2.4353232359955497

Epoch: 5| Step: 9
Training loss: 0.8517513240784883
Validation loss: 2.4186629033955804

Epoch: 5| Step: 10
Training loss: 1.6741016569501819
Validation loss: 2.454083830799724

Epoch: 369| Step: 0
Training loss: 0.9219105923780775
Validation loss: 2.44659698633158

Epoch: 5| Step: 1
Training loss: 0.8225293676588793
Validation loss: 2.4541651851761634

Epoch: 5| Step: 2
Training loss: 0.8778148062523938
Validation loss: 2.4912994651130984

Epoch: 5| Step: 3
Training loss: 0.8079962619161535
Validation loss: 2.4910862888111605

Epoch: 5| Step: 4
Training loss: 0.8583616003610219
Validation loss: 2.4851601953413227

Epoch: 5| Step: 5
Training loss: 0.9917378044792141
Validation loss: 2.463185843985165

Epoch: 5| Step: 6
Training loss: 0.4264506057029177
Validation loss: 2.456367980537483

Epoch: 5| Step: 7
Training loss: 1.0835563845748206
Validation loss: 2.400893088095011

Epoch: 5| Step: 8
Training loss: 0.6627117556312008
Validation loss: 2.378402399313152

Epoch: 5| Step: 9
Training loss: 0.386816763739263
Validation loss: 2.377107010516804

Epoch: 5| Step: 10
Training loss: 1.5721662217461099
Validation loss: 2.3466393310667675

Epoch: 370| Step: 0
Training loss: 0.9084160667911801
Validation loss: 2.3344851703775404

Epoch: 5| Step: 1
Training loss: 0.5432257009988788
Validation loss: 2.358882585098467

Epoch: 5| Step: 2
Training loss: 0.8308340064275292
Validation loss: 2.354527926969433

Epoch: 5| Step: 3
Training loss: 0.5167869711090556
Validation loss: 2.400496383405531

Epoch: 5| Step: 4
Training loss: 0.90698229043993
Validation loss: 2.433839378325085

Epoch: 5| Step: 5
Training loss: 0.6615302329647786
Validation loss: 2.4397044944805706

Epoch: 5| Step: 6
Training loss: 0.6880023161605172
Validation loss: 2.462439745993553

Epoch: 5| Step: 7
Training loss: 1.1299277571144128
Validation loss: 2.4633184423469334

Epoch: 5| Step: 8
Training loss: 0.5848470586570526
Validation loss: 2.4909252851433266

Epoch: 5| Step: 9
Training loss: 1.4647443813952588
Validation loss: 2.4743006218913166

Epoch: 5| Step: 10
Training loss: 1.0516611832316058
Validation loss: 2.4720477395609546

Epoch: 371| Step: 0
Training loss: 0.8328989009161549
Validation loss: 2.476394327228071

Epoch: 5| Step: 1
Training loss: 0.6560867197269218
Validation loss: 2.45669711622125

Epoch: 5| Step: 2
Training loss: 0.49957087102219433
Validation loss: 2.4342842713739072

Epoch: 5| Step: 3
Training loss: 0.9478187755021027
Validation loss: 2.463613152721511

Epoch: 5| Step: 4
Training loss: 0.8912392555969527
Validation loss: 2.3814932600769705

Epoch: 5| Step: 5
Training loss: 1.5454293634025613
Validation loss: 2.427077203649831

Epoch: 5| Step: 6
Training loss: 0.5725462033647024
Validation loss: 2.38372138361098

Epoch: 5| Step: 7
Training loss: 0.8954662117816428
Validation loss: 2.4043355260764994

Epoch: 5| Step: 8
Training loss: 0.7644458565734357
Validation loss: 2.382340366249523

Epoch: 5| Step: 9
Training loss: 0.9935415445174237
Validation loss: 2.416006904842504

Epoch: 5| Step: 10
Training loss: 0.5028470165859453
Validation loss: 2.443116294594268

Epoch: 372| Step: 0
Training loss: 0.8689140796085677
Validation loss: 2.4575863873663195

Epoch: 5| Step: 1
Training loss: 0.9978984565639591
Validation loss: 2.47912734915569

Epoch: 5| Step: 2
Training loss: 0.5123197506061921
Validation loss: 2.513254972110363

Epoch: 5| Step: 3
Training loss: 0.803500290401195
Validation loss: 2.524398951236203

Epoch: 5| Step: 4
Training loss: 0.5628857879113168
Validation loss: 2.521836072150105

Epoch: 5| Step: 5
Training loss: 0.9763743104806502
Validation loss: 2.508547289123927

Epoch: 5| Step: 6
Training loss: 0.32474206721078114
Validation loss: 2.4383190052760826

Epoch: 5| Step: 7
Training loss: 1.5340558250345748
Validation loss: 2.4316244026727225

Epoch: 5| Step: 8
Training loss: 0.9670745142696618
Validation loss: 2.382299754899459

Epoch: 5| Step: 9
Training loss: 0.738909015484977
Validation loss: 2.359073776697561

Epoch: 5| Step: 10
Training loss: 0.7472473732553402
Validation loss: 2.3540554327081327

Epoch: 373| Step: 0
Training loss: 0.6668106435238081
Validation loss: 2.3599734385069633

Epoch: 5| Step: 1
Training loss: 0.9660349608328366
Validation loss: 2.365124264143638

Epoch: 5| Step: 2
Training loss: 0.8528490759141013
Validation loss: 2.332350665340383

Epoch: 5| Step: 3
Training loss: 0.5720204163238936
Validation loss: 2.3751786752532773

Epoch: 5| Step: 4
Training loss: 1.4255079033511107
Validation loss: 2.4008487593403074

Epoch: 5| Step: 5
Training loss: 0.7598323057278881
Validation loss: 2.4133110024926596

Epoch: 5| Step: 6
Training loss: 0.6637477353159745
Validation loss: 2.4344704487658695

Epoch: 5| Step: 7
Training loss: 0.9142266150621788
Validation loss: 2.460200219983293

Epoch: 5| Step: 8
Training loss: 0.95430863475073
Validation loss: 2.4741350536774704

Epoch: 5| Step: 9
Training loss: 0.6940567163383586
Validation loss: 2.5081826551065585

Epoch: 5| Step: 10
Training loss: 0.6792134791508208
Validation loss: 2.4906994433986194

Epoch: 374| Step: 0
Training loss: 0.8920633513594158
Validation loss: 2.460895296937153

Epoch: 5| Step: 1
Training loss: 0.6573880409605379
Validation loss: 2.4344875019410543

Epoch: 5| Step: 2
Training loss: 0.7636543915837558
Validation loss: 2.4030729014143035

Epoch: 5| Step: 3
Training loss: 0.7931295898881854
Validation loss: 2.4056280387315065

Epoch: 5| Step: 4
Training loss: 0.42581894034057954
Validation loss: 2.418683426421397

Epoch: 5| Step: 5
Training loss: 0.7052792925236402
Validation loss: 2.4672399123399416

Epoch: 5| Step: 6
Training loss: 0.9379279749248048
Validation loss: 2.46816613845299

Epoch: 5| Step: 7
Training loss: 0.8278296321767983
Validation loss: 2.463886665482922

Epoch: 5| Step: 8
Training loss: 0.7790885780765361
Validation loss: 2.49364437724935

Epoch: 5| Step: 9
Training loss: 0.3584862583258742
Validation loss: 2.498554233150492

Epoch: 5| Step: 10
Training loss: 1.7319151471652965
Validation loss: 2.478115588688602

Epoch: 375| Step: 0
Training loss: 0.9740723561879626
Validation loss: 2.493534565147197

Epoch: 5| Step: 1
Training loss: 0.5840198671916752
Validation loss: 2.4695460348587934

Epoch: 5| Step: 2
Training loss: 0.709942005435011
Validation loss: 2.4964180419435853

Epoch: 5| Step: 3
Training loss: 0.9096751107853353
Validation loss: 2.4680499009274572

Epoch: 5| Step: 4
Training loss: 0.6072616120410372
Validation loss: 2.4462069913498636

Epoch: 5| Step: 5
Training loss: 0.6709944477263753
Validation loss: 2.4231075753355875

Epoch: 5| Step: 6
Training loss: 0.582755336054621
Validation loss: 2.411114689309676

Epoch: 5| Step: 7
Training loss: 0.7649290853555405
Validation loss: 2.427228117804555

Epoch: 5| Step: 8
Training loss: 1.5506774713878368
Validation loss: 2.423675870521374

Epoch: 5| Step: 9
Training loss: 0.44060994792145997
Validation loss: 2.4221474067270767

Epoch: 5| Step: 10
Training loss: 1.0417363461395421
Validation loss: 2.4072337867598295

Epoch: 376| Step: 0
Training loss: 0.6337273660263407
Validation loss: 2.45728676071908

Epoch: 5| Step: 1
Training loss: 1.543226853041814
Validation loss: 2.45138878690489

Epoch: 5| Step: 2
Training loss: 0.8414568645870282
Validation loss: 2.427936765327831

Epoch: 5| Step: 3
Training loss: 0.9614582976523435
Validation loss: 2.4623969091308693

Epoch: 5| Step: 4
Training loss: 0.6584519275447913
Validation loss: 2.4393346427626064

Epoch: 5| Step: 5
Training loss: 0.5380486892574337
Validation loss: 2.452618643541916

Epoch: 5| Step: 6
Training loss: 0.6977451929892456
Validation loss: 2.4568600665969

Epoch: 5| Step: 7
Training loss: 0.704618732285788
Validation loss: 2.4587980091580657

Epoch: 5| Step: 8
Training loss: 0.7011545333205421
Validation loss: 2.4342209716082883

Epoch: 5| Step: 9
Training loss: 0.8457768432344526
Validation loss: 2.436298062452823

Epoch: 5| Step: 10
Training loss: 0.7517765779202196
Validation loss: 2.4315191315087628

Epoch: 377| Step: 0
Training loss: 0.864186153566141
Validation loss: 2.4249017411802503

Epoch: 5| Step: 1
Training loss: 0.9993871658758443
Validation loss: 2.4152430667509077

Epoch: 5| Step: 2
Training loss: 0.825559926035
Validation loss: 2.3906603622957805

Epoch: 5| Step: 3
Training loss: 1.0090004476994257
Validation loss: 2.394847445170761

Epoch: 5| Step: 4
Training loss: 0.6186087456735853
Validation loss: 2.3913371980793925

Epoch: 5| Step: 5
Training loss: 0.752901781804427
Validation loss: 2.407600506476846

Epoch: 5| Step: 6
Training loss: 1.6014729544564874
Validation loss: 2.426597899109738

Epoch: 5| Step: 7
Training loss: 0.41309661490707067
Validation loss: 2.477360692624078

Epoch: 5| Step: 8
Training loss: 0.3999731539121607
Validation loss: 2.5022593748334496

Epoch: 5| Step: 9
Training loss: 0.5741002745599959
Validation loss: 2.503954540748991

Epoch: 5| Step: 10
Training loss: 0.38168589578244255
Validation loss: 2.493194310874035

Epoch: 378| Step: 0
Training loss: 0.6196871490400574
Validation loss: 2.4886694066568436

Epoch: 5| Step: 1
Training loss: 1.5352877883273417
Validation loss: 2.463118249440486

Epoch: 5| Step: 2
Training loss: 0.9871907908984641
Validation loss: 2.4563595878408053

Epoch: 5| Step: 3
Training loss: 0.5863675891421737
Validation loss: 2.4193348912472965

Epoch: 5| Step: 4
Training loss: 0.6235594599086604
Validation loss: 2.4120043213534057

Epoch: 5| Step: 5
Training loss: 0.7231899455850619
Validation loss: 2.4168998227784697

Epoch: 5| Step: 6
Training loss: 0.7555544136972151
Validation loss: 2.3899406232583553

Epoch: 5| Step: 7
Training loss: 0.5449947458853882
Validation loss: 2.3851771582150465

Epoch: 5| Step: 8
Training loss: 0.6558015744502464
Validation loss: 2.3652788571973926

Epoch: 5| Step: 9
Training loss: 0.5673039655674921
Validation loss: 2.3964572716451378

Epoch: 5| Step: 10
Training loss: 1.160301892935601
Validation loss: 2.383222234132774

Epoch: 379| Step: 0
Training loss: 0.8745645052400859
Validation loss: 2.440021816390136

Epoch: 5| Step: 1
Training loss: 0.7330523816084521
Validation loss: 2.4886669807112267

Epoch: 5| Step: 2
Training loss: 0.5781021886913134
Validation loss: 2.4655762450490553

Epoch: 5| Step: 3
Training loss: 0.7518346519774358
Validation loss: 2.450360887102133

Epoch: 5| Step: 4
Training loss: 0.7214346380599183
Validation loss: 2.458520308785283

Epoch: 5| Step: 5
Training loss: 1.5235257636690875
Validation loss: 2.4574648099967797

Epoch: 5| Step: 6
Training loss: 0.6712562018024504
Validation loss: 2.4480640182882256

Epoch: 5| Step: 7
Training loss: 0.7327296309801055
Validation loss: 2.4219075285771043

Epoch: 5| Step: 8
Training loss: 0.6057485118694974
Validation loss: 2.405448252628125

Epoch: 5| Step: 9
Training loss: 0.8175610857198145
Validation loss: 2.385724038525885

Epoch: 5| Step: 10
Training loss: 0.83861977744541
Validation loss: 2.370869920075843

Epoch: 380| Step: 0
Training loss: 0.7278051107513878
Validation loss: 2.3562364930540727

Epoch: 5| Step: 1
Training loss: 0.8744224958628736
Validation loss: 2.3636564153085633

Epoch: 5| Step: 2
Training loss: 0.9611098592366596
Validation loss: 2.389194779996168

Epoch: 5| Step: 3
Training loss: 0.7358148136450864
Validation loss: 2.4055350159927524

Epoch: 5| Step: 4
Training loss: 0.785649235001845
Validation loss: 2.4096925834975043

Epoch: 5| Step: 5
Training loss: 0.5846720700289775
Validation loss: 2.437037673112992

Epoch: 5| Step: 6
Training loss: 0.7346036027638747
Validation loss: 2.458894312781423

Epoch: 5| Step: 7
Training loss: 0.8180347609094325
Validation loss: 2.4495141431385026

Epoch: 5| Step: 8
Training loss: 0.6431190973127758
Validation loss: 2.44119411670795

Epoch: 5| Step: 9
Training loss: 0.21921783895704292
Validation loss: 2.434190812937869

Epoch: 5| Step: 10
Training loss: 1.614946222029956
Validation loss: 2.423797033165272

Epoch: 381| Step: 0
Training loss: 0.9220896325554846
Validation loss: 2.4037215025035166

Epoch: 5| Step: 1
Training loss: 0.7515858335302905
Validation loss: 2.4171807170620316

Epoch: 5| Step: 2
Training loss: 0.6537396007826702
Validation loss: 2.368442197061359

Epoch: 5| Step: 3
Training loss: 1.4706334152013336
Validation loss: 2.4037503658264514

Epoch: 5| Step: 4
Training loss: 0.6813693230797847
Validation loss: 2.427800039215585

Epoch: 5| Step: 5
Training loss: 0.5673801599332223
Validation loss: 2.390701305595996

Epoch: 5| Step: 6
Training loss: 0.7749127277334735
Validation loss: 2.431886916543507

Epoch: 5| Step: 7
Training loss: 0.7760429040954419
Validation loss: 2.4131974572871395

Epoch: 5| Step: 8
Training loss: 0.7554638046844425
Validation loss: 2.4510002572619665

Epoch: 5| Step: 9
Training loss: 0.495255129406789
Validation loss: 2.420269860070294

Epoch: 5| Step: 10
Training loss: 0.9185106017467015
Validation loss: 2.503261134241989

Epoch: 382| Step: 0
Training loss: 0.9058375571034585
Validation loss: 2.4458516764338603

Epoch: 5| Step: 1
Training loss: 0.7476100193825908
Validation loss: 2.4570852401187815

Epoch: 5| Step: 2
Training loss: 0.723677866739093
Validation loss: 2.437347566157251

Epoch: 5| Step: 3
Training loss: 0.5222484691372827
Validation loss: 2.412195640516974

Epoch: 5| Step: 4
Training loss: 0.8270245924364029
Validation loss: 2.3826288086228233

Epoch: 5| Step: 5
Training loss: 0.610214559819146
Validation loss: 2.389585063580485

Epoch: 5| Step: 6
Training loss: 0.8111522206538773
Validation loss: 2.365992968092301

Epoch: 5| Step: 7
Training loss: 0.45260977227617644
Validation loss: 2.3907210477992282

Epoch: 5| Step: 8
Training loss: 1.471389509018518
Validation loss: 2.417284781092644

Epoch: 5| Step: 9
Training loss: 0.8304272085944416
Validation loss: 2.4691518807196298

Epoch: 5| Step: 10
Training loss: 0.7887383352224187
Validation loss: 2.4347553034728486

Epoch: 383| Step: 0
Training loss: 0.7562178124127553
Validation loss: 2.474580410960233

Epoch: 5| Step: 1
Training loss: 0.5188777513497709
Validation loss: 2.4649846428174764

Epoch: 5| Step: 2
Training loss: 0.8443950730316031
Validation loss: 2.4402217094454763

Epoch: 5| Step: 3
Training loss: 1.6652028649266322
Validation loss: 2.424618806215996

Epoch: 5| Step: 4
Training loss: 0.6594331833176869
Validation loss: 2.392033840046048

Epoch: 5| Step: 5
Training loss: 0.6218531782069204
Validation loss: 2.41529112226713

Epoch: 5| Step: 6
Training loss: 0.42230051268822644
Validation loss: 2.469373038965994

Epoch: 5| Step: 7
Training loss: 0.30282446228429316
Validation loss: 2.4533650469112342

Epoch: 5| Step: 8
Training loss: 0.9318439893468609
Validation loss: 2.4886079290661183

Epoch: 5| Step: 9
Training loss: 0.7741644554462479
Validation loss: 2.485214338240006

Epoch: 5| Step: 10
Training loss: 0.8067619472643917
Validation loss: 2.490758613227026

Epoch: 384| Step: 0
Training loss: 0.5122930492689111
Validation loss: 2.4653765120823348

Epoch: 5| Step: 1
Training loss: 0.662232266614554
Validation loss: 2.4662999168034476

Epoch: 5| Step: 2
Training loss: 0.4786024832232289
Validation loss: 2.4732787978225295

Epoch: 5| Step: 3
Training loss: 0.7469015491826535
Validation loss: 2.4176426664538675

Epoch: 5| Step: 4
Training loss: 0.8288967207523572
Validation loss: 2.3876514535387017

Epoch: 5| Step: 5
Training loss: 0.5642926737156133
Validation loss: 2.3937391533363974

Epoch: 5| Step: 6
Training loss: 0.6264963833368856
Validation loss: 2.3933334230576118

Epoch: 5| Step: 7
Training loss: 1.0030154420913315
Validation loss: 2.38206359617246

Epoch: 5| Step: 8
Training loss: 0.8197063568075376
Validation loss: 2.405332212353823

Epoch: 5| Step: 9
Training loss: 0.8681472072960433
Validation loss: 2.391346294433281

Epoch: 5| Step: 10
Training loss: 1.5370133599002849
Validation loss: 2.4066183007847104

Epoch: 385| Step: 0
Training loss: 0.617297923193373
Validation loss: 2.41475248818665

Epoch: 5| Step: 1
Training loss: 0.528384051470797
Validation loss: 2.473257932280107

Epoch: 5| Step: 2
Training loss: 0.7235217710645242
Validation loss: 2.4505243215821273

Epoch: 5| Step: 3
Training loss: 0.7789795882154767
Validation loss: 2.4640692505595205

Epoch: 5| Step: 4
Training loss: 0.6853768336153105
Validation loss: 2.488106925731729

Epoch: 5| Step: 5
Training loss: 0.7788222930564341
Validation loss: 2.5011479869640016

Epoch: 5| Step: 6
Training loss: 0.737429697920936
Validation loss: 2.4982720156010454

Epoch: 5| Step: 7
Training loss: 0.6065056566570561
Validation loss: 2.515052997889643

Epoch: 5| Step: 8
Training loss: 0.7539912358743499
Validation loss: 2.442621302775583

Epoch: 5| Step: 9
Training loss: 1.5646656287333023
Validation loss: 2.425028111462236

Epoch: 5| Step: 10
Training loss: 0.7193051143342976
Validation loss: 2.4113303182667005

Epoch: 386| Step: 0
Training loss: 1.0054690298037077
Validation loss: 2.389577814394711

Epoch: 5| Step: 1
Training loss: 0.6432424201578044
Validation loss: 2.3750588636978143

Epoch: 5| Step: 2
Training loss: 1.5695445901807938
Validation loss: 2.3911884203439717

Epoch: 5| Step: 3
Training loss: 0.42882812566717243
Validation loss: 2.378195284148092

Epoch: 5| Step: 4
Training loss: 0.7369848100605668
Validation loss: 2.3730762804806385

Epoch: 5| Step: 5
Training loss: 0.6890024543948259
Validation loss: 2.405093863122796

Epoch: 5| Step: 6
Training loss: 0.6176048268210471
Validation loss: 2.41049437674726

Epoch: 5| Step: 7
Training loss: 0.567354762948281
Validation loss: 2.4272369988539664

Epoch: 5| Step: 8
Training loss: 0.3814754101139101
Validation loss: 2.441487874034549

Epoch: 5| Step: 9
Training loss: 0.7356508413490074
Validation loss: 2.468870256349943

Epoch: 5| Step: 10
Training loss: 0.8611025006537143
Validation loss: 2.5043419572174543

Epoch: 387| Step: 0
Training loss: 0.4406084260461257
Validation loss: 2.502003566244396

Epoch: 5| Step: 1
Training loss: 0.5475010966372721
Validation loss: 2.4470625243145685

Epoch: 5| Step: 2
Training loss: 1.4624713047179467
Validation loss: 2.3754722954608947

Epoch: 5| Step: 3
Training loss: 0.6634191650502028
Validation loss: 2.4027545381988165

Epoch: 5| Step: 4
Training loss: 1.0275753905953757
Validation loss: 2.3347004285670323

Epoch: 5| Step: 5
Training loss: 0.5822595238273187
Validation loss: 2.366572190680583

Epoch: 5| Step: 6
Training loss: 0.7506525856304365
Validation loss: 2.4204649145063475

Epoch: 5| Step: 7
Training loss: 0.8535377621780587
Validation loss: 2.444876286911405

Epoch: 5| Step: 8
Training loss: 0.655322077348729
Validation loss: 2.424559738388674

Epoch: 5| Step: 9
Training loss: 0.8696523809932578
Validation loss: 2.485281137889027

Epoch: 5| Step: 10
Training loss: 0.5659412974962699
Validation loss: 2.5241786821107053

Epoch: 388| Step: 0
Training loss: 0.643976816940336
Validation loss: 2.4891430151384824

Epoch: 5| Step: 1
Training loss: 0.5567577038160446
Validation loss: 2.491745654931218

Epoch: 5| Step: 2
Training loss: 0.43120451079129773
Validation loss: 2.4963033664102277

Epoch: 5| Step: 3
Training loss: 1.574561372866106
Validation loss: 2.4985200285260456

Epoch: 5| Step: 4
Training loss: 0.7851431546613745
Validation loss: 2.4824141771114507

Epoch: 5| Step: 5
Training loss: 0.8141414860280756
Validation loss: 2.4681125839287095

Epoch: 5| Step: 6
Training loss: 0.5751552341144422
Validation loss: 2.48832545916745

Epoch: 5| Step: 7
Training loss: 0.6609262569183658
Validation loss: 2.4481281779977135

Epoch: 5| Step: 8
Training loss: 0.7638839076101323
Validation loss: 2.4289283934318817

Epoch: 5| Step: 9
Training loss: 0.7922020197935293
Validation loss: 2.443579502524233

Epoch: 5| Step: 10
Training loss: 0.6661321141011094
Validation loss: 2.4053196306340143

Epoch: 389| Step: 0
Training loss: 0.5722384137138519
Validation loss: 2.4330229597375994

Epoch: 5| Step: 1
Training loss: 0.899374133620597
Validation loss: 2.434843897971668

Epoch: 5| Step: 2
Training loss: 0.748778063036459
Validation loss: 2.4817423653853705

Epoch: 5| Step: 3
Training loss: 0.5743469562263563
Validation loss: 2.483463376267175

Epoch: 5| Step: 4
Training loss: 0.8978715523865097
Validation loss: 2.4787590317000023

Epoch: 5| Step: 5
Training loss: 0.7540849859218368
Validation loss: 2.473514966284308

Epoch: 5| Step: 6
Training loss: 0.5904590858058251
Validation loss: 2.5098148622499523

Epoch: 5| Step: 7
Training loss: 0.4137849057159027
Validation loss: 2.4880461544804255

Epoch: 5| Step: 8
Training loss: 0.5277437176784507
Validation loss: 2.474132723315393

Epoch: 5| Step: 9
Training loss: 0.4815804406004552
Validation loss: 2.4846201109077497

Epoch: 5| Step: 10
Training loss: 1.7033220929535757
Validation loss: 2.456159771823405

Epoch: 390| Step: 0
Training loss: 1.45821800684188
Validation loss: 2.447768394641862

Epoch: 5| Step: 1
Training loss: 0.8516009260834639
Validation loss: 2.4168557372264137

Epoch: 5| Step: 2
Training loss: 0.5772679910264112
Validation loss: 2.3855038209748898

Epoch: 5| Step: 3
Training loss: 0.8069883248360297
Validation loss: 2.375531390812113

Epoch: 5| Step: 4
Training loss: 0.7878159600635463
Validation loss: 2.3859681561609354

Epoch: 5| Step: 5
Training loss: 0.8209269810682615
Validation loss: 2.429767134770363

Epoch: 5| Step: 6
Training loss: 0.5962704817734877
Validation loss: 2.3806642377696403

Epoch: 5| Step: 7
Training loss: 0.36428957639578324
Validation loss: 2.3986342277517907

Epoch: 5| Step: 8
Training loss: 0.8123961895868823
Validation loss: 2.424420680545232

Epoch: 5| Step: 9
Training loss: 0.5115077042171909
Validation loss: 2.4422594254371437

Epoch: 5| Step: 10
Training loss: 0.6890615156170999
Validation loss: 2.509399135001902

Epoch: 391| Step: 0
Training loss: 1.4601072512386304
Validation loss: 2.4786602967036604

Epoch: 5| Step: 1
Training loss: 0.6277200399303794
Validation loss: 2.485765024562261

Epoch: 5| Step: 2
Training loss: 0.8523788039344529
Validation loss: 2.4733774429142468

Epoch: 5| Step: 3
Training loss: 0.8288974398361396
Validation loss: 2.4808806377364006

Epoch: 5| Step: 4
Training loss: 0.5502283012621458
Validation loss: 2.4375613435988464

Epoch: 5| Step: 5
Training loss: 0.7128509092372359
Validation loss: 2.4117279929632947

Epoch: 5| Step: 6
Training loss: 0.6171023636055132
Validation loss: 2.4126240167032087

Epoch: 5| Step: 7
Training loss: 0.7495213411688921
Validation loss: 2.3591807366324384

Epoch: 5| Step: 8
Training loss: 0.6358822904048507
Validation loss: 2.322485858204776

Epoch: 5| Step: 9
Training loss: 0.7878094156122413
Validation loss: 2.331517799437875

Epoch: 5| Step: 10
Training loss: 0.5709930957436902
Validation loss: 2.3771697928686812

Epoch: 392| Step: 0
Training loss: 0.6003064257241474
Validation loss: 2.3899280487382537

Epoch: 5| Step: 1
Training loss: 0.40522935007045524
Validation loss: 2.4086231674122116

Epoch: 5| Step: 2
Training loss: 0.9176965188093315
Validation loss: 2.4310121017430677

Epoch: 5| Step: 3
Training loss: 0.5671032530373639
Validation loss: 2.433164032524812

Epoch: 5| Step: 4
Training loss: 0.7930129466401027
Validation loss: 2.4874463791493326

Epoch: 5| Step: 5
Training loss: 0.6069474406669136
Validation loss: 2.477695123150505

Epoch: 5| Step: 6
Training loss: 1.5865584036545226
Validation loss: 2.522346437227906

Epoch: 5| Step: 7
Training loss: 0.49313578005225805
Validation loss: 2.507716432140223

Epoch: 5| Step: 8
Training loss: 0.5564984591789199
Validation loss: 2.4478766115813038

Epoch: 5| Step: 9
Training loss: 0.677320062383731
Validation loss: 2.35491716014633

Epoch: 5| Step: 10
Training loss: 1.0450973791171152
Validation loss: 2.3541334120651967

Epoch: 393| Step: 0
Training loss: 0.5260896251710501
Validation loss: 2.332585890398821

Epoch: 5| Step: 1
Training loss: 1.3453281804853445
Validation loss: 2.344367009918193

Epoch: 5| Step: 2
Training loss: 0.8563741134574376
Validation loss: 2.345731715331661

Epoch: 5| Step: 3
Training loss: 0.370281857216632
Validation loss: 2.3153851655068447

Epoch: 5| Step: 4
Training loss: 0.9520363453150046
Validation loss: 2.3428180539885783

Epoch: 5| Step: 5
Training loss: 0.7745489746183494
Validation loss: 2.354997920636803

Epoch: 5| Step: 6
Training loss: 1.0959362523202616
Validation loss: 2.396682116661651

Epoch: 5| Step: 7
Training loss: 0.6761365408565676
Validation loss: 2.472052845996906

Epoch: 5| Step: 8
Training loss: 0.5234286179429484
Validation loss: 2.4896469423873895

Epoch: 5| Step: 9
Training loss: 0.8680306537023371
Validation loss: 2.496960603322926

Epoch: 5| Step: 10
Training loss: 0.41097711437439555
Validation loss: 2.483375482916568

Epoch: 394| Step: 0
Training loss: 1.5303295249373645
Validation loss: 2.446007948492434

Epoch: 5| Step: 1
Training loss: 0.6769852909606067
Validation loss: 2.437499146504722

Epoch: 5| Step: 2
Training loss: 0.8086386405536152
Validation loss: 2.441834660307617

Epoch: 5| Step: 3
Training loss: 0.6704890349925965
Validation loss: 2.44482825742635

Epoch: 5| Step: 4
Training loss: 0.9277738542689536
Validation loss: 2.4132674369790763

Epoch: 5| Step: 5
Training loss: 0.603730543071864
Validation loss: 2.442432497576548

Epoch: 5| Step: 6
Training loss: 0.3210050724956773
Validation loss: 2.399093689412581

Epoch: 5| Step: 7
Training loss: 0.7914914054283492
Validation loss: 2.421835932315633

Epoch: 5| Step: 8
Training loss: 0.6939574335329682
Validation loss: 2.4616514671324605

Epoch: 5| Step: 9
Training loss: 0.5298462722614791
Validation loss: 2.424913349893354

Epoch: 5| Step: 10
Training loss: 0.9358886858863051
Validation loss: 2.406948848966547

Epoch: 395| Step: 0
Training loss: 0.6719741082837571
Validation loss: 2.423461901203104

Epoch: 5| Step: 1
Training loss: 0.8716916482845444
Validation loss: 2.4147231108770146

Epoch: 5| Step: 2
Training loss: 0.6836711294793271
Validation loss: 2.430383881650548

Epoch: 5| Step: 3
Training loss: 0.5656788594858112
Validation loss: 2.4850171131908114

Epoch: 5| Step: 4
Training loss: 0.623952751155926
Validation loss: 2.481981778517409

Epoch: 5| Step: 5
Training loss: 0.9735435207672282
Validation loss: 2.4974205964286207

Epoch: 5| Step: 6
Training loss: 0.6129515666823713
Validation loss: 2.5009566158588323

Epoch: 5| Step: 7
Training loss: 0.6476385871126055
Validation loss: 2.4864544007780913

Epoch: 5| Step: 8
Training loss: 0.6207413783448337
Validation loss: 2.4799018163527373

Epoch: 5| Step: 9
Training loss: 0.7640357358024499
Validation loss: 2.4346237882593718

Epoch: 5| Step: 10
Training loss: 1.4279271529233506
Validation loss: 2.4007372962293902

Epoch: 396| Step: 0
Training loss: 0.344161968024018
Validation loss: 2.3933361395152937

Epoch: 5| Step: 1
Training loss: 0.6801401363105423
Validation loss: 2.3461389837089226

Epoch: 5| Step: 2
Training loss: 0.5274946491367806
Validation loss: 2.337297776148734

Epoch: 5| Step: 3
Training loss: 0.8116409455387879
Validation loss: 2.3587284072752004

Epoch: 5| Step: 4
Training loss: 0.46080904318318633
Validation loss: 2.3353346528505665

Epoch: 5| Step: 5
Training loss: 0.8776532205668943
Validation loss: 2.3555840445138028

Epoch: 5| Step: 6
Training loss: 0.8052934013591841
Validation loss: 2.3449149279590173

Epoch: 5| Step: 7
Training loss: 0.7246818403423566
Validation loss: 2.3563653506798063

Epoch: 5| Step: 8
Training loss: 0.6018616564134098
Validation loss: 2.376834128785431

Epoch: 5| Step: 9
Training loss: 1.4155706298357524
Validation loss: 2.4320469860308873

Epoch: 5| Step: 10
Training loss: 0.8907411399205806
Validation loss: 2.424352751732685

Epoch: 397| Step: 0
Training loss: 0.65678129941591
Validation loss: 2.4311290123848543

Epoch: 5| Step: 1
Training loss: 0.6509953800277732
Validation loss: 2.40772472204903

Epoch: 5| Step: 2
Training loss: 0.9130735019102211
Validation loss: 2.4260049147828875

Epoch: 5| Step: 3
Training loss: 0.6905189467253908
Validation loss: 2.345026360262672

Epoch: 5| Step: 4
Training loss: 1.2884175854794726
Validation loss: 2.3546524305339833

Epoch: 5| Step: 5
Training loss: 0.5376356009276562
Validation loss: 2.394007441712374

Epoch: 5| Step: 6
Training loss: 0.6725174471566651
Validation loss: 2.357592499852335

Epoch: 5| Step: 7
Training loss: 0.7390082680158391
Validation loss: 2.351737044301048

Epoch: 5| Step: 8
Training loss: 0.6136524510602815
Validation loss: 2.3436333269728418

Epoch: 5| Step: 9
Training loss: 0.6716395120676956
Validation loss: 2.345583091531455

Epoch: 5| Step: 10
Training loss: 0.7379978584656489
Validation loss: 2.3250007039921514

Epoch: 398| Step: 0
Training loss: 0.7309345657270165
Validation loss: 2.3358054131100827

Epoch: 5| Step: 1
Training loss: 1.1732550569364764
Validation loss: 2.3889155631624277

Epoch: 5| Step: 2
Training loss: 0.6492963870710738
Validation loss: 2.3898905672116677

Epoch: 5| Step: 3
Training loss: 0.7542908236133937
Validation loss: 2.4246536558129232

Epoch: 5| Step: 4
Training loss: 0.7753092533337269
Validation loss: 2.4091261236872885

Epoch: 5| Step: 5
Training loss: 0.47716691820267043
Validation loss: 2.3485052848158654

Epoch: 5| Step: 6
Training loss: 0.6510224809998592
Validation loss: 2.324844311738955

Epoch: 5| Step: 7
Training loss: 0.8112306950510173
Validation loss: 2.349245509013628

Epoch: 5| Step: 8
Training loss: 0.6874016344619822
Validation loss: 2.3298997915908557

Epoch: 5| Step: 9
Training loss: 0.6210338155750764
Validation loss: 2.3742147204198325

Epoch: 5| Step: 10
Training loss: 0.8428544837641855
Validation loss: 2.385672578161369

Epoch: 399| Step: 0
Training loss: 0.8814741809934751
Validation loss: 2.406977004181416

Epoch: 5| Step: 1
Training loss: 0.5547175063492742
Validation loss: 2.4143699893268327

Epoch: 5| Step: 2
Training loss: 0.7172566532213354
Validation loss: 2.435217159368454

Epoch: 5| Step: 3
Training loss: 0.31166570876649197
Validation loss: 2.4284802081026933

Epoch: 5| Step: 4
Training loss: 0.8187974653972574
Validation loss: 2.4461641547603223

Epoch: 5| Step: 5
Training loss: 0.4255001645183133
Validation loss: 2.4784620805101834

Epoch: 5| Step: 6
Training loss: 0.6391312000310413
Validation loss: 2.44438033945904

Epoch: 5| Step: 7
Training loss: 0.9168540192370294
Validation loss: 2.4188993390335467

Epoch: 5| Step: 8
Training loss: 0.8028431839534277
Validation loss: 2.4334196678505324

Epoch: 5| Step: 9
Training loss: 0.5436859882428878
Validation loss: 2.440287636459662

Epoch: 5| Step: 10
Training loss: 1.1764842621625717
Validation loss: 2.361345217300661

Epoch: 400| Step: 0
Training loss: 0.6645912757885236
Validation loss: 2.390252826118853

Epoch: 5| Step: 1
Training loss: 0.7571458932463548
Validation loss: 2.485370120150827

Epoch: 5| Step: 2
Training loss: 0.8510547489077467
Validation loss: 2.4930482038326933

Epoch: 5| Step: 3
Training loss: 0.7921246324983491
Validation loss: 2.473861084836346

Epoch: 5| Step: 4
Training loss: 0.8697957516572398
Validation loss: 2.482273947228851

Epoch: 5| Step: 5
Training loss: 1.1545923568077456
Validation loss: 2.444819979784199

Epoch: 5| Step: 6
Training loss: 0.8939418266750163
Validation loss: 2.3658022389521696

Epoch: 5| Step: 7
Training loss: 0.7898805739877247
Validation loss: 2.280876204337481

Epoch: 5| Step: 8
Training loss: 0.8229873642953797
Validation loss: 2.2895246083600886

Epoch: 5| Step: 9
Training loss: 0.7706672687184425
Validation loss: 2.28515407918696

Epoch: 5| Step: 10
Training loss: 0.8107915669812376
Validation loss: 2.3375617551649435

Epoch: 401| Step: 0
Training loss: 0.7111939187893734
Validation loss: 2.3881299073604394

Epoch: 5| Step: 1
Training loss: 1.363499927197613
Validation loss: 2.432238219035963

Epoch: 5| Step: 2
Training loss: 0.616559131263157
Validation loss: 2.3963700351870396

Epoch: 5| Step: 3
Training loss: 0.6638506383087315
Validation loss: 2.3795727924970866

Epoch: 5| Step: 4
Training loss: 0.6679416896402756
Validation loss: 2.3258418601465762

Epoch: 5| Step: 5
Training loss: 0.6872340034546479
Validation loss: 2.338687838352344

Epoch: 5| Step: 6
Training loss: 0.7828561294793241
Validation loss: 2.3458274133578008

Epoch: 5| Step: 7
Training loss: 0.7665746599081246
Validation loss: 2.316274992307573

Epoch: 5| Step: 8
Training loss: 0.7824315101460689
Validation loss: 2.309323697821425

Epoch: 5| Step: 9
Training loss: 0.7748048428957691
Validation loss: 2.297674231304011

Epoch: 5| Step: 10
Training loss: 0.6689394094387696
Validation loss: 2.3061058200565703

Epoch: 402| Step: 0
Training loss: 0.6096036188718431
Validation loss: 2.32058714029213

Epoch: 5| Step: 1
Training loss: 0.8106626496876881
Validation loss: 2.4025551942430523

Epoch: 5| Step: 2
Training loss: 0.739676877047444
Validation loss: 2.405048911738066

Epoch: 5| Step: 3
Training loss: 0.7483994173622616
Validation loss: 2.4517885393417

Epoch: 5| Step: 4
Training loss: 0.917813421865227
Validation loss: 2.448847635335086

Epoch: 5| Step: 5
Training loss: 0.7713687085711236
Validation loss: 2.4017181176761713

Epoch: 5| Step: 6
Training loss: 0.4384955761021909
Validation loss: 2.3763415180642142

Epoch: 5| Step: 7
Training loss: 0.6869010049827866
Validation loss: 2.2930112576501855

Epoch: 5| Step: 8
Training loss: 0.4104837109496945
Validation loss: 2.266219326279781

Epoch: 5| Step: 9
Training loss: 0.7849515581674028
Validation loss: 2.2317294967012193

Epoch: 5| Step: 10
Training loss: 1.0373873867826509
Validation loss: 2.251682511521931

Epoch: 403| Step: 0
Training loss: 0.6358510054644336
Validation loss: 2.2286851225005515

Epoch: 5| Step: 1
Training loss: 0.6513072019119392
Validation loss: 2.274587792617322

Epoch: 5| Step: 2
Training loss: 0.8370178229554789
Validation loss: 2.2840185050270745

Epoch: 5| Step: 3
Training loss: 0.9043198782382365
Validation loss: 2.2455838456866832

Epoch: 5| Step: 4
Training loss: 0.5676592942735569
Validation loss: 2.269969949534678

Epoch: 5| Step: 5
Training loss: 0.5684483514204034
Validation loss: 2.316340373061776

Epoch: 5| Step: 6
Training loss: 0.8592726906651419
Validation loss: 2.333675158054547

Epoch: 5| Step: 7
Training loss: 0.6605719436950744
Validation loss: 2.365741198153497

Epoch: 5| Step: 8
Training loss: 0.8299912710190415
Validation loss: 2.359511527604505

Epoch: 5| Step: 9
Training loss: 0.6059633511345114
Validation loss: 2.276065001707544

Epoch: 5| Step: 10
Training loss: 0.39708543890321096
Validation loss: 2.2573067419798

Epoch: 404| Step: 0
Training loss: 0.5282061836098826
Validation loss: 2.2881103493034565

Epoch: 5| Step: 1
Training loss: 0.6086561658239994
Validation loss: 2.257780938719707

Epoch: 5| Step: 2
Training loss: 1.0094028315530679
Validation loss: 2.2372091355316175

Epoch: 5| Step: 3
Training loss: 0.4268161201362627
Validation loss: 2.2848984989364722

Epoch: 5| Step: 4
Training loss: 0.6121645193572084
Validation loss: 2.2903509280163292

Epoch: 5| Step: 5
Training loss: 0.7886851702132058
Validation loss: 2.2779296184438773

Epoch: 5| Step: 6
Training loss: 0.7053420399778663
Validation loss: 2.294028658114504

Epoch: 5| Step: 7
Training loss: 0.8196901049265335
Validation loss: 2.31078250232675

Epoch: 5| Step: 8
Training loss: 0.6836132155780451
Validation loss: 2.3537554289610814

Epoch: 5| Step: 9
Training loss: 0.4754613756303059
Validation loss: 2.29668817017707

Epoch: 5| Step: 10
Training loss: 0.5884109171790105
Validation loss: 2.270514094828862

Epoch: 405| Step: 0
Training loss: 0.6358399440535049
Validation loss: 2.212484450714643

Epoch: 5| Step: 1
Training loss: 0.7599221193413799
Validation loss: 2.232401973129044

Epoch: 5| Step: 2
Training loss: 0.5880065499511821
Validation loss: 2.2349361911340426

Epoch: 5| Step: 3
Training loss: 1.0017977885992007
Validation loss: 2.2051711519931096

Epoch: 5| Step: 4
Training loss: 0.39513926347730804
Validation loss: 2.21430419141813

Epoch: 5| Step: 5
Training loss: 0.8290605838205658
Validation loss: 2.239091306774353

Epoch: 5| Step: 6
Training loss: 0.6639566449336487
Validation loss: 2.2567019886153408

Epoch: 5| Step: 7
Training loss: 0.5778189699709226
Validation loss: 2.280791210250908

Epoch: 5| Step: 8
Training loss: 0.7090422131194669
Validation loss: 2.342339128360102

Epoch: 5| Step: 9
Training loss: 0.7543897116300332
Validation loss: 2.3137610914961777

Epoch: 5| Step: 10
Training loss: 0.49198694532993076
Validation loss: 2.3029497344700767

Epoch: 406| Step: 0
Training loss: 0.4355314619818297
Validation loss: 2.279555859992223

Epoch: 5| Step: 1
Training loss: 0.48990375266898906
Validation loss: 2.2633021706437737

Epoch: 5| Step: 2
Training loss: 0.6728222180349931
Validation loss: 2.2281520590403083

Epoch: 5| Step: 3
Training loss: 0.661705591640682
Validation loss: 2.2346144545818976

Epoch: 5| Step: 4
Training loss: 0.5533982997217449
Validation loss: 2.2503776569470806

Epoch: 5| Step: 5
Training loss: 0.7614748050631962
Validation loss: 2.2658290127621212

Epoch: 5| Step: 6
Training loss: 0.7527989770063448
Validation loss: 2.2461991445987572

Epoch: 5| Step: 7
Training loss: 0.6173120204038843
Validation loss: 2.280502721750309

Epoch: 5| Step: 8
Training loss: 0.4797609434534557
Validation loss: 2.2230238526970365

Epoch: 5| Step: 9
Training loss: 0.8854192210141903
Validation loss: 2.2309451923945867

Epoch: 5| Step: 10
Training loss: 0.9028204777392511
Validation loss: 2.306260154317818

Epoch: 407| Step: 0
Training loss: 0.39582862558409637
Validation loss: 2.258062711654915

Epoch: 5| Step: 1
Training loss: 0.8019644207351667
Validation loss: 2.285441154961777

Epoch: 5| Step: 2
Training loss: 0.6894853924773102
Validation loss: 2.273521663944673

Epoch: 5| Step: 3
Training loss: 0.540523318833112
Validation loss: 2.2615481059416145

Epoch: 5| Step: 4
Training loss: 0.4435974019898956
Validation loss: 2.246038801137263

Epoch: 5| Step: 5
Training loss: 0.5809694628364114
Validation loss: 2.2229724875832733

Epoch: 5| Step: 6
Training loss: 0.4695606533498108
Validation loss: 2.2275501938290487

Epoch: 5| Step: 7
Training loss: 0.7781200653900188
Validation loss: 2.2595793676663667

Epoch: 5| Step: 8
Training loss: 0.7389887895985593
Validation loss: 2.2601389193783232

Epoch: 5| Step: 9
Training loss: 0.5288774299376422
Validation loss: 2.2662109861888005

Epoch: 5| Step: 10
Training loss: 0.9464728115003586
Validation loss: 2.263438791569245

Epoch: 408| Step: 0
Training loss: 0.5803710506156123
Validation loss: 2.215590470533234

Epoch: 5| Step: 1
Training loss: 0.7472374423705336
Validation loss: 2.2434797038886707

Epoch: 5| Step: 2
Training loss: 0.6002197886279393
Validation loss: 2.2072461199963374

Epoch: 5| Step: 3
Training loss: 0.6601416682150886
Validation loss: 2.2227291058688343

Epoch: 5| Step: 4
Training loss: 0.32287659960508175
Validation loss: 2.2383707839624605

Epoch: 5| Step: 5
Training loss: 0.8702003790306401
Validation loss: 2.2434800387018847

Epoch: 5| Step: 6
Training loss: 0.3975218180300756
Validation loss: 2.2482866819128544

Epoch: 5| Step: 7
Training loss: 0.8187585917597157
Validation loss: 2.234107248372677

Epoch: 5| Step: 8
Training loss: 0.6436521603944749
Validation loss: 2.22370147278423

Epoch: 5| Step: 9
Training loss: 0.5655871552510157
Validation loss: 2.2108649240447726

Epoch: 5| Step: 10
Training loss: 0.5172462406971363
Validation loss: 2.2428084914833764

Epoch: 409| Step: 0
Training loss: 0.6417489542980465
Validation loss: 2.2319860067589667

Epoch: 5| Step: 1
Training loss: 0.5663366340737853
Validation loss: 2.2312518160162216

Epoch: 5| Step: 2
Training loss: 0.468981717375559
Validation loss: 2.2051602680928566

Epoch: 5| Step: 3
Training loss: 0.216686435441031
Validation loss: 2.2264865380861747

Epoch: 5| Step: 4
Training loss: 0.4487587273368025
Validation loss: 2.1936753249929186

Epoch: 5| Step: 5
Training loss: 0.7572401185749557
Validation loss: 2.243275735647435

Epoch: 5| Step: 6
Training loss: 0.6410128187156494
Validation loss: 2.235107320223216

Epoch: 5| Step: 7
Training loss: 0.5663010598207957
Validation loss: 2.2542661325991307

Epoch: 5| Step: 8
Training loss: 0.5592047810628443
Validation loss: 2.2420876522098725

Epoch: 5| Step: 9
Training loss: 0.9127049921307376
Validation loss: 2.239115824532893

Epoch: 5| Step: 10
Training loss: 0.8256491231462397
Validation loss: 2.247875359000857

Epoch: 410| Step: 0
Training loss: 0.8693120208789378
Validation loss: 2.2497475868756585

Epoch: 5| Step: 1
Training loss: 0.6321799802309348
Validation loss: 2.257242981313625

Epoch: 5| Step: 2
Training loss: 0.5145611625662346
Validation loss: 2.2672451310001893

Epoch: 5| Step: 3
Training loss: 0.5058864748261089
Validation loss: 2.2736266282713857

Epoch: 5| Step: 4
Training loss: 0.7887574918847576
Validation loss: 2.232459274718119

Epoch: 5| Step: 5
Training loss: 0.46888079407950306
Validation loss: 2.260653553740189

Epoch: 5| Step: 6
Training loss: 0.5286993334778808
Validation loss: 2.2168043746413004

Epoch: 5| Step: 7
Training loss: 0.6419848222022816
Validation loss: 2.1955837467112684

Epoch: 5| Step: 8
Training loss: 0.6342952452637612
Validation loss: 2.2066879796833954

Epoch: 5| Step: 9
Training loss: 0.7222794658846976
Validation loss: 2.1409804220744837

Epoch: 5| Step: 10
Training loss: 0.3094501322250281
Validation loss: 2.183500592117926

Epoch: 411| Step: 0
Training loss: 0.7009160204592523
Validation loss: 2.1911388233528912

Epoch: 5| Step: 1
Training loss: 0.6705984808237063
Validation loss: 2.2491029491620376

Epoch: 5| Step: 2
Training loss: 0.521367463568885
Validation loss: 2.256302174656407

Epoch: 5| Step: 3
Training loss: 0.4111985541401762
Validation loss: 2.227243498576478

Epoch: 5| Step: 4
Training loss: 0.671658503228014
Validation loss: 2.24549874077601

Epoch: 5| Step: 5
Training loss: 0.4772205499721642
Validation loss: 2.288203612139852

Epoch: 5| Step: 6
Training loss: 0.6089868042648439
Validation loss: 2.336018354763132

Epoch: 5| Step: 7
Training loss: 0.44757788806122634
Validation loss: 2.298445492203929

Epoch: 5| Step: 8
Training loss: 0.6821453772421987
Validation loss: 2.3101724231356404

Epoch: 5| Step: 9
Training loss: 0.6388271971186519
Validation loss: 2.291342789779411

Epoch: 5| Step: 10
Training loss: 0.7501173722296175
Validation loss: 2.277696950673763

Epoch: 412| Step: 0
Training loss: 0.4601261627775349
Validation loss: 2.2214050814167794

Epoch: 5| Step: 1
Training loss: 0.9836545154323434
Validation loss: 2.246275398574215

Epoch: 5| Step: 2
Training loss: 0.8569648932585208
Validation loss: 2.245800279275173

Epoch: 5| Step: 3
Training loss: 0.8080716128906852
Validation loss: 2.2253187993915775

Epoch: 5| Step: 4
Training loss: 0.6432568290620742
Validation loss: 2.273451609106627

Epoch: 5| Step: 5
Training loss: 0.5733670516227242
Validation loss: 2.276657178580323

Epoch: 5| Step: 6
Training loss: 0.2555927605573087
Validation loss: 2.2602974584395454

Epoch: 5| Step: 7
Training loss: 0.5091074059282091
Validation loss: 2.353429150812797

Epoch: 5| Step: 8
Training loss: 0.3097885998820154
Validation loss: 2.3260090309108086

Epoch: 5| Step: 9
Training loss: 0.5029635816097018
Validation loss: 2.380071377623597

Epoch: 5| Step: 10
Training loss: 0.5465362862287262
Validation loss: 2.359361892595332

Epoch: 413| Step: 0
Training loss: 0.7488846830640781
Validation loss: 2.277803506496627

Epoch: 5| Step: 1
Training loss: 0.2766930643715157
Validation loss: 2.262071657093438

Epoch: 5| Step: 2
Training loss: 0.3078239109615808
Validation loss: 2.2307951813868265

Epoch: 5| Step: 3
Training loss: 0.5601102610587531
Validation loss: 2.1893037382424287

Epoch: 5| Step: 4
Training loss: 0.5800647156061376
Validation loss: 2.240687292000294

Epoch: 5| Step: 5
Training loss: 0.6937981734862357
Validation loss: 2.2403361912122577

Epoch: 5| Step: 6
Training loss: 0.5280195921040878
Validation loss: 2.2147878359935484

Epoch: 5| Step: 7
Training loss: 0.732453897411949
Validation loss: 2.219093898088587

Epoch: 5| Step: 8
Training loss: 0.7411173684789991
Validation loss: 2.248679607679335

Epoch: 5| Step: 9
Training loss: 0.6817763884696658
Validation loss: 2.2725653845218923

Epoch: 5| Step: 10
Training loss: 0.672105926926958
Validation loss: 2.325486905618782

Epoch: 414| Step: 0
Training loss: 0.7465991959429299
Validation loss: 2.3426260710996805

Epoch: 5| Step: 1
Training loss: 0.49491285211998937
Validation loss: 2.2551012104447095

Epoch: 5| Step: 2
Training loss: 0.5614126610330142
Validation loss: 2.2848833129882062

Epoch: 5| Step: 3
Training loss: 0.6598569202666942
Validation loss: 2.2188214849926426

Epoch: 5| Step: 4
Training loss: 0.43881672873426963
Validation loss: 2.212374134167092

Epoch: 5| Step: 5
Training loss: 0.5532937067369955
Validation loss: 2.2068064242712384

Epoch: 5| Step: 6
Training loss: 0.3178899615851094
Validation loss: 2.181650179697562

Epoch: 5| Step: 7
Training loss: 0.5883724734639273
Validation loss: 2.169011846811884

Epoch: 5| Step: 8
Training loss: 0.7043488342109782
Validation loss: 2.2160947175453187

Epoch: 5| Step: 9
Training loss: 0.6725453426007825
Validation loss: 2.2139350170040877

Epoch: 5| Step: 10
Training loss: 0.7630161289595182
Validation loss: 2.248120914466361

Epoch: 415| Step: 0
Training loss: 0.6387680401279464
Validation loss: 2.2643590086652097

Epoch: 5| Step: 1
Training loss: 0.5567591223155675
Validation loss: 2.298302730813834

Epoch: 5| Step: 2
Training loss: 0.37330107491351494
Validation loss: 2.3248403221127547

Epoch: 5| Step: 3
Training loss: 0.44395104810279734
Validation loss: 2.3339549921552685

Epoch: 5| Step: 4
Training loss: 0.7498090023980837
Validation loss: 2.327960758234123

Epoch: 5| Step: 5
Training loss: 0.6082803969888024
Validation loss: 2.313584005173033

Epoch: 5| Step: 6
Training loss: 0.518854718956318
Validation loss: 2.2234099860212693

Epoch: 5| Step: 7
Training loss: 0.6472206187558083
Validation loss: 2.2181041135039132

Epoch: 5| Step: 8
Training loss: 0.707130088009668
Validation loss: 2.1592821141158387

Epoch: 5| Step: 9
Training loss: 0.5890880569054212
Validation loss: 2.1942531198892774

Epoch: 5| Step: 10
Training loss: 0.6349062250385823
Validation loss: 2.1620227296766736

Epoch: 416| Step: 0
Training loss: 0.7151307327288774
Validation loss: 2.1929924086963952

Epoch: 5| Step: 1
Training loss: 0.4157682229416452
Validation loss: 2.2285013820950894

Epoch: 5| Step: 2
Training loss: 0.588749888110302
Validation loss: 2.2105956811079857

Epoch: 5| Step: 3
Training loss: 0.5719371803540418
Validation loss: 2.2315909948036885

Epoch: 5| Step: 4
Training loss: 0.6306768572594236
Validation loss: 2.3057261884154894

Epoch: 5| Step: 5
Training loss: 0.7332668465761006
Validation loss: 2.363643960722192

Epoch: 5| Step: 6
Training loss: 0.5941906097272954
Validation loss: 2.295156844552492

Epoch: 5| Step: 7
Training loss: 0.5950837213854808
Validation loss: 2.2755786330613694

Epoch: 5| Step: 8
Training loss: 0.550030054008207
Validation loss: 2.2646992728155384

Epoch: 5| Step: 9
Training loss: 0.4629316512972231
Validation loss: 2.261414853351004

Epoch: 5| Step: 10
Training loss: 0.5271948710199333
Validation loss: 2.258288645846136

Epoch: 417| Step: 0
Training loss: 0.3287615505336057
Validation loss: 2.2589966466624833

Epoch: 5| Step: 1
Training loss: 0.6912158768631796
Validation loss: 2.2386433507256793

Epoch: 5| Step: 2
Training loss: 0.4573909778405305
Validation loss: 2.240787473336448

Epoch: 5| Step: 3
Training loss: 0.5974811222573762
Validation loss: 2.2193850102952886

Epoch: 5| Step: 4
Training loss: 0.6196185652979941
Validation loss: 2.2622417338577367

Epoch: 5| Step: 5
Training loss: 0.755931604369482
Validation loss: 2.2633824923193133

Epoch: 5| Step: 6
Training loss: 0.5365461135699331
Validation loss: 2.2825557721182035

Epoch: 5| Step: 7
Training loss: 0.49395342813011367
Validation loss: 2.2757765933635348

Epoch: 5| Step: 8
Training loss: 0.4952949340304767
Validation loss: 2.28654299829281

Epoch: 5| Step: 9
Training loss: 0.5345033156949608
Validation loss: 2.2587470821209656

Epoch: 5| Step: 10
Training loss: 0.7237503429932515
Validation loss: 2.2899492867111517

Epoch: 418| Step: 0
Training loss: 0.5002010060633899
Validation loss: 2.2849782544329154

Epoch: 5| Step: 1
Training loss: 0.6921776816057098
Validation loss: 2.3048633150337805

Epoch: 5| Step: 2
Training loss: 0.8090150629298717
Validation loss: 2.275153955485536

Epoch: 5| Step: 3
Training loss: 0.5242036081051646
Validation loss: 2.256213508506065

Epoch: 5| Step: 4
Training loss: 0.6015257886113208
Validation loss: 2.237548080388804

Epoch: 5| Step: 5
Training loss: 0.3583148162330435
Validation loss: 2.21651121865575

Epoch: 5| Step: 6
Training loss: 0.44946706791666236
Validation loss: 2.215074630636873

Epoch: 5| Step: 7
Training loss: 0.6112959978235656
Validation loss: 2.2306905783091917

Epoch: 5| Step: 8
Training loss: 0.6527995270516982
Validation loss: 2.2383980697913675

Epoch: 5| Step: 9
Training loss: 0.5633829921733605
Validation loss: 2.1918446483965806

Epoch: 5| Step: 10
Training loss: 0.4023000452692555
Validation loss: 2.2304229608070503

Epoch: 419| Step: 0
Training loss: 0.2791301790039688
Validation loss: 2.240736560043974

Epoch: 5| Step: 1
Training loss: 0.49975284786090374
Validation loss: 2.2513921611197376

Epoch: 5| Step: 2
Training loss: 0.6376324282334827
Validation loss: 2.2796089460716717

Epoch: 5| Step: 3
Training loss: 0.5918057381246368
Validation loss: 2.2707514116364043

Epoch: 5| Step: 4
Training loss: 0.5525854334650625
Validation loss: 2.30189718832914

Epoch: 5| Step: 5
Training loss: 0.5578965858319449
Validation loss: 2.308682810771449

Epoch: 5| Step: 6
Training loss: 0.6766254025790548
Validation loss: 2.270422061037861

Epoch: 5| Step: 7
Training loss: 0.6588565514763856
Validation loss: 2.258676134891554

Epoch: 5| Step: 8
Training loss: 0.6448797266476919
Validation loss: 2.198306977231132

Epoch: 5| Step: 9
Training loss: 0.4864888519282047
Validation loss: 2.2528468822392966

Epoch: 5| Step: 10
Training loss: 0.6066252461465729
Validation loss: 2.2161033266432963

Epoch: 420| Step: 0
Training loss: 0.5648791015874528
Validation loss: 2.2330510044424976

Epoch: 5| Step: 1
Training loss: 0.5934296295785105
Validation loss: 2.1921241427688596

Epoch: 5| Step: 2
Training loss: 0.5267650112951565
Validation loss: 2.1951850308461376

Epoch: 5| Step: 3
Training loss: 0.4876511590087488
Validation loss: 2.2196182696568014

Epoch: 5| Step: 4
Training loss: 0.17915197056187757
Validation loss: 2.2675028372780743

Epoch: 5| Step: 5
Training loss: 0.6016551850492313
Validation loss: 2.2430751084553497

Epoch: 5| Step: 6
Training loss: 0.7980959645174893
Validation loss: 2.3074659981994023

Epoch: 5| Step: 7
Training loss: 0.6833252079604654
Validation loss: 2.2800725611391806

Epoch: 5| Step: 8
Training loss: 0.5876180580912235
Validation loss: 2.3033549187349265

Epoch: 5| Step: 9
Training loss: 0.5426709572874716
Validation loss: 2.295372890958844

Epoch: 5| Step: 10
Training loss: 0.4852121256473594
Validation loss: 2.297239494408421

Epoch: 421| Step: 0
Training loss: 0.39274642904589857
Validation loss: 2.3198964553310413

Epoch: 5| Step: 1
Training loss: 0.3655307811399122
Validation loss: 2.2910617373017335

Epoch: 5| Step: 2
Training loss: 0.6904695707075874
Validation loss: 2.3201623998381806

Epoch: 5| Step: 3
Training loss: 0.6676304278300386
Validation loss: 2.310476497012797

Epoch: 5| Step: 4
Training loss: 0.8334579771921187
Validation loss: 2.2756322898657517

Epoch: 5| Step: 5
Training loss: 0.5418763182908932
Validation loss: 2.275030724873412

Epoch: 5| Step: 6
Training loss: 0.728197411796226
Validation loss: 2.2441905289118647

Epoch: 5| Step: 7
Training loss: 0.3930940037866112
Validation loss: 2.254554350384967

Epoch: 5| Step: 8
Training loss: 0.36660615067616165
Validation loss: 2.2509440899055484

Epoch: 5| Step: 9
Training loss: 0.24028078266762662
Validation loss: 2.223718208947565

Epoch: 5| Step: 10
Training loss: 0.7223127631345149
Validation loss: 2.2039931847116123

Epoch: 422| Step: 0
Training loss: 0.5315848585446672
Validation loss: 2.1959376365614074

Epoch: 5| Step: 1
Training loss: 0.5718186752014248
Validation loss: 2.213456374858989

Epoch: 5| Step: 2
Training loss: 0.6262999367363216
Validation loss: 2.1652610643119927

Epoch: 5| Step: 3
Training loss: 0.4173435633640022
Validation loss: 2.1966458019144746

Epoch: 5| Step: 4
Training loss: 0.3246475165185039
Validation loss: 2.177429877779504

Epoch: 5| Step: 5
Training loss: 0.7976893209836972
Validation loss: 2.212128871943719

Epoch: 5| Step: 6
Training loss: 0.8636874455877682
Validation loss: 2.21812576636086

Epoch: 5| Step: 7
Training loss: 0.4672109132341285
Validation loss: 2.2303692258672934

Epoch: 5| Step: 8
Training loss: 0.5543714348163385
Validation loss: 2.2841372469830783

Epoch: 5| Step: 9
Training loss: 0.5156458937139772
Validation loss: 2.228275473033355

Epoch: 5| Step: 10
Training loss: 0.34469808617570463
Validation loss: 2.2838758694740573

Epoch: 423| Step: 0
Training loss: 0.5790043149352502
Validation loss: 2.3333306630254076

Epoch: 5| Step: 1
Training loss: 0.4247531026454092
Validation loss: 2.2946796050054483

Epoch: 5| Step: 2
Training loss: 0.6460562495611709
Validation loss: 2.337297451484206

Epoch: 5| Step: 3
Training loss: 0.7296710631257118
Validation loss: 2.263922785479563

Epoch: 5| Step: 4
Training loss: 0.6043352900243869
Validation loss: 2.2483604215842505

Epoch: 5| Step: 5
Training loss: 0.4023566753200148
Validation loss: 2.282192618162437

Epoch: 5| Step: 6
Training loss: 0.3101955441775608
Validation loss: 2.228457520830654

Epoch: 5| Step: 7
Training loss: 0.6243445774490843
Validation loss: 2.262161696359695

Epoch: 5| Step: 8
Training loss: 0.751130007778722
Validation loss: 2.227063288318777

Epoch: 5| Step: 9
Training loss: 0.3826011930883802
Validation loss: 2.2232682820196445

Epoch: 5| Step: 10
Training loss: 0.5790287377303343
Validation loss: 2.2346042624723377

Epoch: 424| Step: 0
Training loss: 0.6050925778263013
Validation loss: 2.264076747175872

Epoch: 5| Step: 1
Training loss: 0.4069187272360994
Validation loss: 2.2936310721117996

Epoch: 5| Step: 2
Training loss: 0.5317093882491849
Validation loss: 2.3336931268400876

Epoch: 5| Step: 3
Training loss: 0.3644088145771731
Validation loss: 2.33940543298274

Epoch: 5| Step: 4
Training loss: 0.6900371207051471
Validation loss: 2.3588578515064578

Epoch: 5| Step: 5
Training loss: 0.6784156211723453
Validation loss: 2.336066087989116

Epoch: 5| Step: 6
Training loss: 0.6485979272408762
Validation loss: 2.313815182175524

Epoch: 5| Step: 7
Training loss: 0.356626657837104
Validation loss: 2.3040273444982358

Epoch: 5| Step: 8
Training loss: 0.39036853000239696
Validation loss: 2.3467102410667757

Epoch: 5| Step: 9
Training loss: 0.5143865682754186
Validation loss: 2.3351146118205124

Epoch: 5| Step: 10
Training loss: 0.7338454995727606
Validation loss: 2.2955438343336816

Epoch: 425| Step: 0
Training loss: 0.6487121460001134
Validation loss: 2.243780569973781

Epoch: 5| Step: 1
Training loss: 0.3412405991394698
Validation loss: 2.249933347774438

Epoch: 5| Step: 2
Training loss: 0.47588157473011095
Validation loss: 2.241616153601558

Epoch: 5| Step: 3
Training loss: 0.555567835301214
Validation loss: 2.237747689155769

Epoch: 5| Step: 4
Training loss: 0.6434696587061546
Validation loss: 2.2357834761703517

Epoch: 5| Step: 5
Training loss: 0.44489466154420104
Validation loss: 2.267204532929773

Epoch: 5| Step: 6
Training loss: 0.6297813629542491
Validation loss: 2.304731713078242

Epoch: 5| Step: 7
Training loss: 0.4698057841472683
Validation loss: 2.3390069650250136

Epoch: 5| Step: 8
Training loss: 0.5250241160530499
Validation loss: 2.3451858202419595

Epoch: 5| Step: 9
Training loss: 0.6007889319277215
Validation loss: 2.322236575755639

Epoch: 5| Step: 10
Training loss: 0.6349108720541614
Validation loss: 2.3621221775541437

Epoch: 426| Step: 0
Training loss: 0.5422463036125829
Validation loss: 2.347655483415872

Epoch: 5| Step: 1
Training loss: 0.4071883588475899
Validation loss: 2.300807436904704

Epoch: 5| Step: 2
Training loss: 0.6934708841409712
Validation loss: 2.2796439196353115

Epoch: 5| Step: 3
Training loss: 0.42100058110552663
Validation loss: 2.239628825163261

Epoch: 5| Step: 4
Training loss: 0.6679883809021409
Validation loss: 2.2384022003173656

Epoch: 5| Step: 5
Training loss: 0.4100157905945488
Validation loss: 2.250820146024769

Epoch: 5| Step: 6
Training loss: 0.473250008273238
Validation loss: 2.193451089159374

Epoch: 5| Step: 7
Training loss: 0.49596293669610564
Validation loss: 2.247698711075587

Epoch: 5| Step: 8
Training loss: 0.6305539835780972
Validation loss: 2.21463543867817

Epoch: 5| Step: 9
Training loss: 0.6613324538673365
Validation loss: 2.205097831111141

Epoch: 5| Step: 10
Training loss: 0.5915474444698734
Validation loss: 2.2776265661492534

Epoch: 427| Step: 0
Training loss: 0.641594641428971
Validation loss: 2.2647178301891704

Epoch: 5| Step: 1
Training loss: 0.6757974126569831
Validation loss: 2.258191279289946

Epoch: 5| Step: 2
Training loss: 0.29287993038389226
Validation loss: 2.277652611817142

Epoch: 5| Step: 3
Training loss: 0.44250281182166235
Validation loss: 2.2525553839159476

Epoch: 5| Step: 4
Training loss: 0.47777835334729607
Validation loss: 2.2246855600353945

Epoch: 5| Step: 5
Training loss: 0.5203039976232928
Validation loss: 2.228875455062066

Epoch: 5| Step: 6
Training loss: 0.5332279968050165
Validation loss: 2.2211228374652006

Epoch: 5| Step: 7
Training loss: 0.5428516343964842
Validation loss: 2.218595492159462

Epoch: 5| Step: 8
Training loss: 0.5185533369086255
Validation loss: 2.242307729700111

Epoch: 5| Step: 9
Training loss: 0.524682798381595
Validation loss: 2.267691802552736

Epoch: 5| Step: 10
Training loss: 0.6677500718194201
Validation loss: 2.266582567559756

Epoch: 428| Step: 0
Training loss: 0.3486065039872758
Validation loss: 2.311593977693699

Epoch: 5| Step: 1
Training loss: 0.3203401902488217
Validation loss: 2.2731684551033653

Epoch: 5| Step: 2
Training loss: 0.26208726360444834
Validation loss: 2.3213904931534426

Epoch: 5| Step: 3
Training loss: 0.47370189674163593
Validation loss: 2.265536857137927

Epoch: 5| Step: 4
Training loss: 0.6312635089826245
Validation loss: 2.2627404916776106

Epoch: 5| Step: 5
Training loss: 0.6417773512542463
Validation loss: 2.233471164489287

Epoch: 5| Step: 6
Training loss: 0.5930454692037457
Validation loss: 2.238480886155097

Epoch: 5| Step: 7
Training loss: 0.5584343902979478
Validation loss: 2.213091477151285

Epoch: 5| Step: 8
Training loss: 0.6994062204355416
Validation loss: 2.2238744854541728

Epoch: 5| Step: 9
Training loss: 0.5278089943515861
Validation loss: 2.1905098083743924

Epoch: 5| Step: 10
Training loss: 0.7449725049340798
Validation loss: 2.2365614455566556

Epoch: 429| Step: 0
Training loss: 0.6120682644747406
Validation loss: 2.238694624821252

Epoch: 5| Step: 1
Training loss: 0.2497746301124796
Validation loss: 2.2696309909200245

Epoch: 5| Step: 2
Training loss: 0.7577600755943562
Validation loss: 2.256761636411371

Epoch: 5| Step: 3
Training loss: 0.40772621001886733
Validation loss: 2.284552033698689

Epoch: 5| Step: 4
Training loss: 0.4031832556807905
Validation loss: 2.302010091855323

Epoch: 5| Step: 5
Training loss: 0.3215951823613284
Validation loss: 2.2710363198179393

Epoch: 5| Step: 6
Training loss: 0.4801317444198271
Validation loss: 2.282349344494496

Epoch: 5| Step: 7
Training loss: 0.6513500297151059
Validation loss: 2.2436501459205584

Epoch: 5| Step: 8
Training loss: 0.6070015486394241
Validation loss: 2.254742618030605

Epoch: 5| Step: 9
Training loss: 0.6629886246794248
Validation loss: 2.24782999224701

Epoch: 5| Step: 10
Training loss: 0.5541288221912838
Validation loss: 2.231974833948668

Epoch: 430| Step: 0
Training loss: 0.5951939141816058
Validation loss: 2.2168504173726586

Epoch: 5| Step: 1
Training loss: 0.36310700370329124
Validation loss: 2.225320212935588

Epoch: 5| Step: 2
Training loss: 0.5172691430596049
Validation loss: 2.224505602384782

Epoch: 5| Step: 3
Training loss: 0.3868585391694828
Validation loss: 2.270917681094371

Epoch: 5| Step: 4
Training loss: 0.6854530118062037
Validation loss: 2.2933692088399518

Epoch: 5| Step: 5
Training loss: 0.41034027694151565
Validation loss: 2.3048608246498836

Epoch: 5| Step: 6
Training loss: 0.70437515170782
Validation loss: 2.3002234534067187

Epoch: 5| Step: 7
Training loss: 0.4052589321987665
Validation loss: 2.3146621276741404

Epoch: 5| Step: 8
Training loss: 0.6622102373656211
Validation loss: 2.3536525153610914

Epoch: 5| Step: 9
Training loss: 0.5268724383996708
Validation loss: 2.3036815730448144

Epoch: 5| Step: 10
Training loss: 0.48024504190950645
Validation loss: 2.308499276443355

Epoch: 431| Step: 0
Training loss: 0.5384669400235039
Validation loss: 2.2789143838215282

Epoch: 5| Step: 1
Training loss: 0.2541958404562733
Validation loss: 2.239815432137322

Epoch: 5| Step: 2
Training loss: 0.5132496189723619
Validation loss: 2.293129658879648

Epoch: 5| Step: 3
Training loss: 0.2859026012073159
Validation loss: 2.257021351259365

Epoch: 5| Step: 4
Training loss: 0.608643508463614
Validation loss: 2.2325836741115888

Epoch: 5| Step: 5
Training loss: 0.42690601001663225
Validation loss: 2.229152705467313

Epoch: 5| Step: 6
Training loss: 0.6556093176610764
Validation loss: 2.2337082684807283

Epoch: 5| Step: 7
Training loss: 0.5779608931758964
Validation loss: 2.2514609244977084

Epoch: 5| Step: 8
Training loss: 0.5740737732022818
Validation loss: 2.2509198968803754

Epoch: 5| Step: 9
Training loss: 0.29584481285325775
Validation loss: 2.29495872424338

Epoch: 5| Step: 10
Training loss: 0.7892654460112092
Validation loss: 2.2524661150175445

Epoch: 432| Step: 0
Training loss: 0.43317291525925106
Validation loss: 2.255080708399394

Epoch: 5| Step: 1
Training loss: 0.5661142056733817
Validation loss: 2.2656228138676537

Epoch: 5| Step: 2
Training loss: 0.525623340898905
Validation loss: 2.2765480342332793

Epoch: 5| Step: 3
Training loss: 0.45488793979112074
Validation loss: 2.275265847230502

Epoch: 5| Step: 4
Training loss: 0.5573416328015658
Validation loss: 2.2730701582352544

Epoch: 5| Step: 5
Training loss: 0.342972102833133
Validation loss: 2.259568616782423

Epoch: 5| Step: 6
Training loss: 0.40872119352927283
Validation loss: 2.265851188800244

Epoch: 5| Step: 7
Training loss: 0.7080213242918663
Validation loss: 2.26689989134525

Epoch: 5| Step: 8
Training loss: 0.6151524322678104
Validation loss: 2.232428542411509

Epoch: 5| Step: 9
Training loss: 0.4950799871611041
Validation loss: 2.2484999445188074

Epoch: 5| Step: 10
Training loss: 0.532594018480488
Validation loss: 2.222193206213984

Epoch: 433| Step: 0
Training loss: 0.5965189865652687
Validation loss: 2.194994382026751

Epoch: 5| Step: 1
Training loss: 0.5396280500914737
Validation loss: 2.235015909168101

Epoch: 5| Step: 2
Training loss: 0.28505430620189776
Validation loss: 2.241480821693982

Epoch: 5| Step: 3
Training loss: 0.4861118341243756
Validation loss: 2.188167019125986

Epoch: 5| Step: 4
Training loss: 0.6383866772843209
Validation loss: 2.235139707480643

Epoch: 5| Step: 5
Training loss: 0.2362958633849184
Validation loss: 2.2614877018772264

Epoch: 5| Step: 6
Training loss: 0.726595108777128
Validation loss: 2.260386277420716

Epoch: 5| Step: 7
Training loss: 0.4261854335680551
Validation loss: 2.2599726044597666

Epoch: 5| Step: 8
Training loss: 0.47202951478307725
Validation loss: 2.2513078317644917

Epoch: 5| Step: 9
Training loss: 0.5274343342157747
Validation loss: 2.2684327902044723

Epoch: 5| Step: 10
Training loss: 0.5161265332732058
Validation loss: 2.244005430487016

Epoch: 434| Step: 0
Training loss: 0.5554511227070911
Validation loss: 2.2822574223376475

Epoch: 5| Step: 1
Training loss: 0.39724714448117393
Validation loss: 2.289836293158267

Epoch: 5| Step: 2
Training loss: 0.3114391081223222
Validation loss: 2.2265747444177406

Epoch: 5| Step: 3
Training loss: 0.5865412335612924
Validation loss: 2.2396389480481202

Epoch: 5| Step: 4
Training loss: 0.16941378804739407
Validation loss: 2.2566968242986865

Epoch: 5| Step: 5
Training loss: 0.13782154546622635
Validation loss: 2.2469738238099697

Epoch: 5| Step: 6
Training loss: 0.7182209306723731
Validation loss: 2.212862886207317

Epoch: 5| Step: 7
Training loss: 0.7155856259104452
Validation loss: 2.279281408501374

Epoch: 5| Step: 8
Training loss: 0.5031689713496804
Validation loss: 2.2761240621105627

Epoch: 5| Step: 9
Training loss: 0.6176751540109217
Validation loss: 2.3095372739970226

Epoch: 5| Step: 10
Training loss: 0.5001446991396736
Validation loss: 2.242964711160292

Epoch: 435| Step: 0
Training loss: 0.6079967023531052
Validation loss: 2.234624248554231

Epoch: 5| Step: 1
Training loss: 0.37222795325860203
Validation loss: 2.2814718844572255

Epoch: 5| Step: 2
Training loss: 0.4649590581641057
Validation loss: 2.2349783882035323

Epoch: 5| Step: 3
Training loss: 0.4867473924515076
Validation loss: 2.238039594362757

Epoch: 5| Step: 4
Training loss: 0.37383353090911714
Validation loss: 2.2482509491721614

Epoch: 5| Step: 5
Training loss: 0.497164344512132
Validation loss: 2.248121001132822

Epoch: 5| Step: 6
Training loss: 0.3509725388947456
Validation loss: 2.2454237482836867

Epoch: 5| Step: 7
Training loss: 0.6892269941592305
Validation loss: 2.2504608987982944

Epoch: 5| Step: 8
Training loss: 0.586473169246408
Validation loss: 2.2745838906657148

Epoch: 5| Step: 9
Training loss: 0.4035354668464793
Validation loss: 2.2623079973895464

Epoch: 5| Step: 10
Training loss: 0.5995896674778821
Validation loss: 2.3094915705474715

Epoch: 436| Step: 0
Training loss: 0.49197581446814925
Validation loss: 2.2991562966456596

Epoch: 5| Step: 1
Training loss: 0.46953436077693284
Validation loss: 2.3084153993680725

Epoch: 5| Step: 2
Training loss: 0.5617887981175294
Validation loss: 2.277144447461787

Epoch: 5| Step: 3
Training loss: 0.4597659011360318
Validation loss: 2.3273098808343087

Epoch: 5| Step: 4
Training loss: 0.6359309137551604
Validation loss: 2.288299717924174

Epoch: 5| Step: 5
Training loss: 0.34662683648229253
Validation loss: 2.2891027406496196

Epoch: 5| Step: 6
Training loss: 0.6393061763231769
Validation loss: 2.242826407566261

Epoch: 5| Step: 7
Training loss: 0.7116399794703459
Validation loss: 2.2284412407388707

Epoch: 5| Step: 8
Training loss: 0.43303007998614346
Validation loss: 2.258032376636364

Epoch: 5| Step: 9
Training loss: 0.2868522348907991
Validation loss: 2.2122710692878638

Epoch: 5| Step: 10
Training loss: 0.3076752138662304
Validation loss: 2.2458640531747447

Epoch: 437| Step: 0
Training loss: 0.4278496364862561
Validation loss: 2.252688413162883

Epoch: 5| Step: 1
Training loss: 0.1805953436400146
Validation loss: 2.251181731668919

Epoch: 5| Step: 2
Training loss: 0.41076301017653627
Validation loss: 2.240396159155281

Epoch: 5| Step: 3
Training loss: 0.43815235479723963
Validation loss: 2.2673281855079788

Epoch: 5| Step: 4
Training loss: 0.3444262701455948
Validation loss: 2.259253833140398

Epoch: 5| Step: 5
Training loss: 0.5287018700827247
Validation loss: 2.236267284470799

Epoch: 5| Step: 6
Training loss: 0.5121780256380764
Validation loss: 2.267808506271993

Epoch: 5| Step: 7
Training loss: 0.6084206517359901
Validation loss: 2.2972166683312096

Epoch: 5| Step: 8
Training loss: 0.6589658263105398
Validation loss: 2.235542944996642

Epoch: 5| Step: 9
Training loss: 0.6145274384722533
Validation loss: 2.292481309139094

Epoch: 5| Step: 10
Training loss: 0.6342233307403523
Validation loss: 2.2700498410376064

Epoch: 438| Step: 0
Training loss: 0.47752154109459627
Validation loss: 2.1981459072672624

Epoch: 5| Step: 1
Training loss: 0.5807911764204359
Validation loss: 2.184035394551404

Epoch: 5| Step: 2
Training loss: 0.3586175441119803
Validation loss: 2.2114953369648043

Epoch: 5| Step: 3
Training loss: 0.3657237359758031
Validation loss: 2.1978596342294425

Epoch: 5| Step: 4
Training loss: 0.5634043364621678
Validation loss: 2.2452796034763285

Epoch: 5| Step: 5
Training loss: 0.32438054701117663
Validation loss: 2.2458593387990358

Epoch: 5| Step: 6
Training loss: 0.43706371488201845
Validation loss: 2.2610761284325576

Epoch: 5| Step: 7
Training loss: 0.451085829683438
Validation loss: 2.239612325226464

Epoch: 5| Step: 8
Training loss: 0.3895843759138603
Validation loss: 2.2608019339468663

Epoch: 5| Step: 9
Training loss: 0.696838974983767
Validation loss: 2.256546303018791

Epoch: 5| Step: 10
Training loss: 0.6593060859717508
Validation loss: 2.252024843539107

Epoch: 439| Step: 0
Training loss: 0.36918853771760685
Validation loss: 2.274925585299039

Epoch: 5| Step: 1
Training loss: 0.4881071466949271
Validation loss: 2.2750847509609264

Epoch: 5| Step: 2
Training loss: 0.43083766975962834
Validation loss: 2.231227879402946

Epoch: 5| Step: 3
Training loss: 0.8576954468179178
Validation loss: 2.2587964499581235

Epoch: 5| Step: 4
Training loss: 0.5461458522406888
Validation loss: 2.2313192187286446

Epoch: 5| Step: 5
Training loss: 0.6413253352136724
Validation loss: 2.2426857394909545

Epoch: 5| Step: 6
Training loss: 0.5429074094963394
Validation loss: 2.2436296849220962

Epoch: 5| Step: 7
Training loss: 0.3535507985525887
Validation loss: 2.2481167749985884

Epoch: 5| Step: 8
Training loss: 0.15754782983592142
Validation loss: 2.2354431135029524

Epoch: 5| Step: 9
Training loss: 0.35506046868166086
Validation loss: 2.2398450095217446

Epoch: 5| Step: 10
Training loss: 0.3943457970182531
Validation loss: 2.2607315926826366

Epoch: 440| Step: 0
Training loss: 0.48910648038506205
Validation loss: 2.2672350884051387

Epoch: 5| Step: 1
Training loss: 0.42386859050191944
Validation loss: 2.284557034614325

Epoch: 5| Step: 2
Training loss: 0.2821861158909443
Validation loss: 2.2383270714262764

Epoch: 5| Step: 3
Training loss: 0.34800485213846055
Validation loss: 2.2587806013395264

Epoch: 5| Step: 4
Training loss: 0.6457628678262954
Validation loss: 2.221726529234868

Epoch: 5| Step: 5
Training loss: 0.34675672507966965
Validation loss: 2.300603834840357

Epoch: 5| Step: 6
Training loss: 0.3478360728992358
Validation loss: 2.304248024996282

Epoch: 5| Step: 7
Training loss: 0.6735036981179504
Validation loss: 2.300168688679706

Epoch: 5| Step: 8
Training loss: 0.6221848506669908
Validation loss: 2.3181760195576113

Epoch: 5| Step: 9
Training loss: 0.15362041405901292
Validation loss: 2.2996933107961643

Epoch: 5| Step: 10
Training loss: 0.7026483191512755
Validation loss: 2.2758973375469935

Epoch: 441| Step: 0
Training loss: 0.3770792458595471
Validation loss: 2.300053310356068

Epoch: 5| Step: 1
Training loss: 0.7371520433877945
Validation loss: 2.2930920278405553

Epoch: 5| Step: 2
Training loss: 0.4510958058356969
Validation loss: 2.270446937142793

Epoch: 5| Step: 3
Training loss: 0.4496954668941807
Validation loss: 2.2438908003120943

Epoch: 5| Step: 4
Training loss: 0.5029609151978355
Validation loss: 2.253922110144693

Epoch: 5| Step: 5
Training loss: 0.4285390591885927
Validation loss: 2.2489597440719162

Epoch: 5| Step: 6
Training loss: 0.6325064495948989
Validation loss: 2.2220500545650537

Epoch: 5| Step: 7
Training loss: 0.3588954587118709
Validation loss: 2.2213715879580436

Epoch: 5| Step: 8
Training loss: 0.28171957076170523
Validation loss: 2.2298632608564253

Epoch: 5| Step: 9
Training loss: 0.5719678188521271
Validation loss: 2.2327879718013177

Epoch: 5| Step: 10
Training loss: 0.4623807521399365
Validation loss: 2.250767359916191

Epoch: 442| Step: 0
Training loss: 0.3353719386296235
Validation loss: 2.242012940112909

Epoch: 5| Step: 1
Training loss: 0.5292280370563598
Validation loss: 2.2956329909817925

Epoch: 5| Step: 2
Training loss: 0.660837578040301
Validation loss: 2.303736455683235

Epoch: 5| Step: 3
Training loss: 0.5315176065405037
Validation loss: 2.2915509915359733

Epoch: 5| Step: 4
Training loss: 0.5941317485519951
Validation loss: 2.251218955527116

Epoch: 5| Step: 5
Training loss: 0.5577138893735131
Validation loss: 2.2511404319364705

Epoch: 5| Step: 6
Training loss: 0.5765664511444424
Validation loss: 2.235843099552201

Epoch: 5| Step: 7
Training loss: 0.4502808661272927
Validation loss: 2.211213661095178

Epoch: 5| Step: 8
Training loss: 0.3766423263463902
Validation loss: 2.2540094373281074

Epoch: 5| Step: 9
Training loss: 0.3588492860540607
Validation loss: 2.243013127975914

Epoch: 5| Step: 10
Training loss: 0.23690384499200015
Validation loss: 2.266588372717221

Epoch: 443| Step: 0
Training loss: 0.48744247109306427
Validation loss: 2.2569728169473424

Epoch: 5| Step: 1
Training loss: 0.40859853037851357
Validation loss: 2.2676645017836004

Epoch: 5| Step: 2
Training loss: 0.4154275310336638
Validation loss: 2.2742764238424087

Epoch: 5| Step: 3
Training loss: 0.5634334025390043
Validation loss: 2.2653647845137193

Epoch: 5| Step: 4
Training loss: 0.4668325466428341
Validation loss: 2.2446604554424843

Epoch: 5| Step: 5
Training loss: 0.45084750913249416
Validation loss: 2.234785415873207

Epoch: 5| Step: 6
Training loss: 0.2663004925359081
Validation loss: 2.259592491146578

Epoch: 5| Step: 7
Training loss: 0.24919563024780286
Validation loss: 2.2499720595617787

Epoch: 5| Step: 8
Training loss: 0.6974756047552807
Validation loss: 2.265730077833684

Epoch: 5| Step: 9
Training loss: 0.6124643850676569
Validation loss: 2.2578245528045224

Epoch: 5| Step: 10
Training loss: 0.5366753784157741
Validation loss: 2.288143973929047

Epoch: 444| Step: 0
Training loss: 0.45495220619745863
Validation loss: 2.2445131600250035

Epoch: 5| Step: 1
Training loss: 0.4270717766601564
Validation loss: 2.288701647029879

Epoch: 5| Step: 2
Training loss: 0.3614075444549191
Validation loss: 2.302093147995981

Epoch: 5| Step: 3
Training loss: 0.5363988997736151
Validation loss: 2.316207723675845

Epoch: 5| Step: 4
Training loss: 0.5889719906188154
Validation loss: 2.278630229609398

Epoch: 5| Step: 5
Training loss: 0.7777544403170135
Validation loss: 2.2611800038526457

Epoch: 5| Step: 6
Training loss: 0.166095041465583
Validation loss: 2.2813518713258105

Epoch: 5| Step: 7
Training loss: 0.4987607888080219
Validation loss: 2.2511640121912744

Epoch: 5| Step: 8
Training loss: 0.36858530003336837
Validation loss: 2.2669826921838654

Epoch: 5| Step: 9
Training loss: 0.5031668390920486
Validation loss: 2.259001283120481

Epoch: 5| Step: 10
Training loss: 0.43394610547831064
Validation loss: 2.2242698819128868

Epoch: 445| Step: 0
Training loss: 0.3655571149095813
Validation loss: 2.262604004209841

Epoch: 5| Step: 1
Training loss: 0.4976957392333324
Validation loss: 2.2943148178848065

Epoch: 5| Step: 2
Training loss: 0.5703548520183207
Validation loss: 2.287620590073464

Epoch: 5| Step: 3
Training loss: 0.4788014395247596
Validation loss: 2.262228301640388

Epoch: 5| Step: 4
Training loss: 0.4808489063155303
Validation loss: 2.3127596409251034

Epoch: 5| Step: 5
Training loss: 0.6137230126377452
Validation loss: 2.3143461707471213

Epoch: 5| Step: 6
Training loss: 0.4346053891545183
Validation loss: 2.333766147432367

Epoch: 5| Step: 7
Training loss: 0.5630283523419793
Validation loss: 2.314817946970836

Epoch: 5| Step: 8
Training loss: 0.44550677294779184
Validation loss: 2.305481628899513

Epoch: 5| Step: 9
Training loss: 0.41448007077162197
Validation loss: 2.3199631760970068

Epoch: 5| Step: 10
Training loss: 0.12736918423583915
Validation loss: 2.321443757822585

Epoch: 446| Step: 0
Training loss: 0.3973570366849474
Validation loss: 2.293668019214293

Epoch: 5| Step: 1
Training loss: 0.5654028060927114
Validation loss: 2.2623746816506003

Epoch: 5| Step: 2
Training loss: 0.35232500462032296
Validation loss: 2.3149166788182396

Epoch: 5| Step: 3
Training loss: 0.40120175704428684
Validation loss: 2.298388276948106

Epoch: 5| Step: 4
Training loss: 0.48359836335824213
Validation loss: 2.2885838876596734

Epoch: 5| Step: 5
Training loss: 0.4386176071500638
Validation loss: 2.3040574213802594

Epoch: 5| Step: 6
Training loss: 0.20829285983490256
Validation loss: 2.306638674461555

Epoch: 5| Step: 7
Training loss: 0.46643949738409257
Validation loss: 2.3199675111454767

Epoch: 5| Step: 8
Training loss: 0.6821734032286256
Validation loss: 2.268046702427592

Epoch: 5| Step: 9
Training loss: 0.5306730784189793
Validation loss: 2.2658379861636906

Epoch: 5| Step: 10
Training loss: 0.43329682364471583
Validation loss: 2.266339360799828

Epoch: 447| Step: 0
Training loss: 0.5739863437895566
Validation loss: 2.2700306920687408

Epoch: 5| Step: 1
Training loss: 0.6617574741242642
Validation loss: 2.275787250783258

Epoch: 5| Step: 2
Training loss: 0.3674916975549724
Validation loss: 2.2565100205434727

Epoch: 5| Step: 3
Training loss: 0.24020168423169375
Validation loss: 2.2776991522303214

Epoch: 5| Step: 4
Training loss: 0.38534490673351585
Validation loss: 2.3025875774496773

Epoch: 5| Step: 5
Training loss: 0.39644412132337564
Validation loss: 2.3306187742709334

Epoch: 5| Step: 6
Training loss: 0.6234546630332555
Validation loss: 2.2996313546681924

Epoch: 5| Step: 7
Training loss: 0.49966371671702037
Validation loss: 2.306850013211855

Epoch: 5| Step: 8
Training loss: 0.3284921635472531
Validation loss: 2.2912174026859997

Epoch: 5| Step: 9
Training loss: 0.4606395987237903
Validation loss: 2.2975408802526096

Epoch: 5| Step: 10
Training loss: 0.43249790794770643
Validation loss: 2.312037084885821

Epoch: 448| Step: 0
Training loss: 0.45538296946845985
Validation loss: 2.3139516092979426

Epoch: 5| Step: 1
Training loss: 0.3785180925381347
Validation loss: 2.2480528745614574

Epoch: 5| Step: 2
Training loss: 0.47556416111151023
Validation loss: 2.2801838742275713

Epoch: 5| Step: 3
Training loss: 0.6528649674911393
Validation loss: 2.283622403758086

Epoch: 5| Step: 4
Training loss: 0.5436045265719458
Validation loss: 2.3345013830215864

Epoch: 5| Step: 5
Training loss: 0.26566719673684996
Validation loss: 2.284020053412541

Epoch: 5| Step: 6
Training loss: 0.31932275494071727
Validation loss: 2.2527584812376102

Epoch: 5| Step: 7
Training loss: 0.5491882445978388
Validation loss: 2.2761606018419887

Epoch: 5| Step: 8
Training loss: 0.4788084107565331
Validation loss: 2.253217819668853

Epoch: 5| Step: 9
Training loss: 0.363922087151548
Validation loss: 2.2479819097059255

Epoch: 5| Step: 10
Training loss: 0.5520820137823877
Validation loss: 2.301711524653436

Epoch: 449| Step: 0
Training loss: 0.6082900733023664
Validation loss: 2.3068703285448904

Epoch: 5| Step: 1
Training loss: 0.42757395344474347
Validation loss: 2.2486259669871926

Epoch: 5| Step: 2
Training loss: 0.3418323280476079
Validation loss: 2.2932480182229518

Epoch: 5| Step: 3
Training loss: 0.37590846646418374
Validation loss: 2.2558437273533753

Epoch: 5| Step: 4
Training loss: 0.37612678202102034
Validation loss: 2.246047055765365

Epoch: 5| Step: 5
Training loss: 0.4741736872973996
Validation loss: 2.2480114492075485

Epoch: 5| Step: 6
Training loss: 0.29724819167319394
Validation loss: 2.1943303623697545

Epoch: 5| Step: 7
Training loss: 0.6023800236606672
Validation loss: 2.200268654603391

Epoch: 5| Step: 8
Training loss: 0.5729282175691417
Validation loss: 2.237337539099434

Epoch: 5| Step: 9
Training loss: 0.3703574253950396
Validation loss: 2.214260951422535

Epoch: 5| Step: 10
Training loss: 0.5524211845452978
Validation loss: 2.234898141167445

Epoch: 450| Step: 0
Training loss: 0.45393711516973123
Validation loss: 2.230021394439093

Epoch: 5| Step: 1
Training loss: 0.32808200236568824
Validation loss: 2.251400281112656

Epoch: 5| Step: 2
Training loss: 0.5121643805042656
Validation loss: 2.2174632824401326

Epoch: 5| Step: 3
Training loss: 0.5773528071249284
Validation loss: 2.2765978369736053

Epoch: 5| Step: 4
Training loss: 0.22399894028332074
Validation loss: 2.267334403152436

Epoch: 5| Step: 5
Training loss: 0.5591448486219772
Validation loss: 2.2488057238195327

Epoch: 5| Step: 6
Training loss: 0.3559713059900302
Validation loss: 2.2231456515443466

Epoch: 5| Step: 7
Training loss: 0.2142690949438255
Validation loss: 2.248642452658107

Epoch: 5| Step: 8
Training loss: 0.6816404501141431
Validation loss: 2.285370586038129

Epoch: 5| Step: 9
Training loss: 0.43625260385102393
Validation loss: 2.217619695119217

Epoch: 5| Step: 10
Training loss: 0.558464195326386
Validation loss: 2.2455135540230295

Epoch: 451| Step: 0
Training loss: 0.31600005367284634
Validation loss: 2.185134709390729

Epoch: 5| Step: 1
Training loss: 0.25236747736439324
Validation loss: 2.21546626717732

Epoch: 5| Step: 2
Training loss: 0.36968749777502863
Validation loss: 2.167428588682444

Epoch: 5| Step: 3
Training loss: 0.49518631371680166
Validation loss: 2.223190744796991

Epoch: 5| Step: 4
Training loss: 0.39687566757146003
Validation loss: 2.257076809369625

Epoch: 5| Step: 5
Training loss: 0.6096054032824689
Validation loss: 2.264386122572877

Epoch: 5| Step: 6
Training loss: 0.5135564057851022
Validation loss: 2.2840947085910086

Epoch: 5| Step: 7
Training loss: 0.41133886325074825
Validation loss: 2.3045531442119223

Epoch: 5| Step: 8
Training loss: 0.4637604761354178
Validation loss: 2.2705297237966033

Epoch: 5| Step: 9
Training loss: 0.6630473287182386
Validation loss: 2.281824681516686

Epoch: 5| Step: 10
Training loss: 0.3963083712788836
Validation loss: 2.2743140035250735

Epoch: 452| Step: 0
Training loss: 0.4109176108765196
Validation loss: 2.277326244497406

Epoch: 5| Step: 1
Training loss: 0.4553855217978043
Validation loss: 2.2542945002929646

Epoch: 5| Step: 2
Training loss: 0.40515041092601445
Validation loss: 2.2804457940650167

Epoch: 5| Step: 3
Training loss: 0.43258782280662345
Validation loss: 2.267080091085685

Epoch: 5| Step: 4
Training loss: 0.6043384707830934
Validation loss: 2.2272941652291096

Epoch: 5| Step: 5
Training loss: 0.47587044291697855
Validation loss: 2.315799360478145

Epoch: 5| Step: 6
Training loss: 0.3499471748031169
Validation loss: 2.260749491465375

Epoch: 5| Step: 7
Training loss: 0.4568958081778878
Validation loss: 2.29222377333435

Epoch: 5| Step: 8
Training loss: 0.38455969242216176
Validation loss: 2.3026152151178465

Epoch: 5| Step: 9
Training loss: 0.4162370334358342
Validation loss: 2.303249764275473

Epoch: 5| Step: 10
Training loss: 0.5112374932827601
Validation loss: 2.315105851321116

Epoch: 453| Step: 0
Training loss: 0.5505932967447548
Validation loss: 2.2722354359991424

Epoch: 5| Step: 1
Training loss: 0.3387663523573523
Validation loss: 2.28933823047003

Epoch: 5| Step: 2
Training loss: 0.5715001425455071
Validation loss: 2.271942446588349

Epoch: 5| Step: 3
Training loss: 0.5406722483632971
Validation loss: 2.296969187690714

Epoch: 5| Step: 4
Training loss: 0.3226574567536701
Validation loss: 2.2791189459997625

Epoch: 5| Step: 5
Training loss: 0.35021568447584617
Validation loss: 2.288943631904428

Epoch: 5| Step: 6
Training loss: 0.5412009297123272
Validation loss: 2.276434537660987

Epoch: 5| Step: 7
Training loss: 0.40133923064273475
Validation loss: 2.295936360870821

Epoch: 5| Step: 8
Training loss: 0.36683122110488087
Validation loss: 2.3114961850010927

Epoch: 5| Step: 9
Training loss: 0.33956356117789066
Validation loss: 2.3009471271168187

Epoch: 5| Step: 10
Training loss: 0.4746338951778259
Validation loss: 2.3238995363274197

Epoch: 454| Step: 0
Training loss: 0.48598934154635987
Validation loss: 2.35077511321464

Epoch: 5| Step: 1
Training loss: 0.6240811746598753
Validation loss: 2.3343738611420086

Epoch: 5| Step: 2
Training loss: 0.5268281464655773
Validation loss: 2.293626914184257

Epoch: 5| Step: 3
Training loss: 0.37014856935183654
Validation loss: 2.280273861349357

Epoch: 5| Step: 4
Training loss: 0.23821856502789499
Validation loss: 2.305677666133871

Epoch: 5| Step: 5
Training loss: 0.47569554062722436
Validation loss: 2.318237629360394

Epoch: 5| Step: 6
Training loss: 0.577950193422313
Validation loss: 2.2920463534604063

Epoch: 5| Step: 7
Training loss: 0.16903419582051868
Validation loss: 2.270556390573231

Epoch: 5| Step: 8
Training loss: 0.6074821957384982
Validation loss: 2.3259059320416915

Epoch: 5| Step: 9
Training loss: 0.13293648990754908
Validation loss: 2.288264171959105

Epoch: 5| Step: 10
Training loss: 0.21190853375373106
Validation loss: 2.2592990819882623

Epoch: 455| Step: 0
Training loss: 0.4355794441122982
Validation loss: 2.3026493555052494

Epoch: 5| Step: 1
Training loss: 0.26041098429520254
Validation loss: 2.3232468562997868

Epoch: 5| Step: 2
Training loss: 0.4106653958892874
Validation loss: 2.2950635090559977

Epoch: 5| Step: 3
Training loss: 0.4446174987093704
Validation loss: 2.2853925724569017

Epoch: 5| Step: 4
Training loss: 0.49165457681026753
Validation loss: 2.280690509885832

Epoch: 5| Step: 5
Training loss: 0.3449304966264864
Validation loss: 2.258763867045618

Epoch: 5| Step: 6
Training loss: 0.516867239408341
Validation loss: 2.2875787465571467

Epoch: 5| Step: 7
Training loss: 0.4917059313591501
Validation loss: 2.2613206733016247

Epoch: 5| Step: 8
Training loss: 0.21184501753699517
Validation loss: 2.2622875544233034

Epoch: 5| Step: 9
Training loss: 0.45201941146670327
Validation loss: 2.247927411856309

Epoch: 5| Step: 10
Training loss: 0.6284987035432977
Validation loss: 2.2916301362676963

Epoch: 456| Step: 0
Training loss: 0.4741231994896435
Validation loss: 2.302471176288958

Epoch: 5| Step: 1
Training loss: 0.6201577000638272
Validation loss: 2.283916248090416

Epoch: 5| Step: 2
Training loss: 0.36710109099795196
Validation loss: 2.2917108365572454

Epoch: 5| Step: 3
Training loss: 0.26447269192633327
Validation loss: 2.324036667611954

Epoch: 5| Step: 4
Training loss: 0.3952706838814027
Validation loss: 2.2837409617222724

Epoch: 5| Step: 5
Training loss: 0.4705236258883817
Validation loss: 2.31307233774644

Epoch: 5| Step: 6
Training loss: 0.5419519082988242
Validation loss: 2.2876845664314263

Epoch: 5| Step: 7
Training loss: 0.45425642100757513
Validation loss: 2.297394775796863

Epoch: 5| Step: 8
Training loss: 0.35515477913158794
Validation loss: 2.26480461093324

Epoch: 5| Step: 9
Training loss: 0.3387501759194343
Validation loss: 2.268367817112326

Epoch: 5| Step: 10
Training loss: 0.40804388052104357
Validation loss: 2.266293718307177

Epoch: 457| Step: 0
Training loss: 0.35060545673065396
Validation loss: 2.235067218879023

Epoch: 5| Step: 1
Training loss: 0.5120287240285907
Validation loss: 2.222992737388947

Epoch: 5| Step: 2
Training loss: 0.5776400207270375
Validation loss: 2.262440204753679

Epoch: 5| Step: 3
Training loss: 0.7145694560787845
Validation loss: 2.2013263876182743

Epoch: 5| Step: 4
Training loss: 0.19070638459266856
Validation loss: 2.257139606183654

Epoch: 5| Step: 5
Training loss: 0.3411478583685878
Validation loss: 2.2368431895654166

Epoch: 5| Step: 6
Training loss: 0.23240534940039612
Validation loss: 2.2988209074494317

Epoch: 5| Step: 7
Training loss: 0.25770034662533514
Validation loss: 2.29127740844834

Epoch: 5| Step: 8
Training loss: 0.4686398694682827
Validation loss: 2.3148636903377042

Epoch: 5| Step: 9
Training loss: 0.4424118470354386
Validation loss: 2.2592233390809695

Epoch: 5| Step: 10
Training loss: 0.46153647089186556
Validation loss: 2.3117282902347736

Epoch: 458| Step: 0
Training loss: 0.39123432319970153
Validation loss: 2.28315828336647

Epoch: 5| Step: 1
Training loss: 0.4576967236200106
Validation loss: 2.3019775186642635

Epoch: 5| Step: 2
Training loss: 0.5170235307658495
Validation loss: 2.248998091890088

Epoch: 5| Step: 3
Training loss: 0.4223070581313339
Validation loss: 2.273839649079539

Epoch: 5| Step: 4
Training loss: 0.28335661839190013
Validation loss: 2.293497126051309

Epoch: 5| Step: 5
Training loss: 0.3677448749846405
Validation loss: 2.257514644141911

Epoch: 5| Step: 6
Training loss: 0.28587630560342864
Validation loss: 2.245463814234824

Epoch: 5| Step: 7
Training loss: 0.6015908866228828
Validation loss: 2.251393530395593

Epoch: 5| Step: 8
Training loss: 0.296274493870807
Validation loss: 2.242776472444099

Epoch: 5| Step: 9
Training loss: 0.32527625877867433
Validation loss: 2.269140092238607

Epoch: 5| Step: 10
Training loss: 0.6744529591381975
Validation loss: 2.293102581028042

Epoch: 459| Step: 0
Training loss: 0.49374221300672433
Validation loss: 2.3138468012422226

Epoch: 5| Step: 1
Training loss: 0.41640856815573185
Validation loss: 2.3053021028086187

Epoch: 5| Step: 2
Training loss: 0.48863422605538936
Validation loss: 2.2749750511210465

Epoch: 5| Step: 3
Training loss: 0.2769192684339117
Validation loss: 2.27497632112275

Epoch: 5| Step: 4
Training loss: 0.359921620167865
Validation loss: 2.2939780525482014

Epoch: 5| Step: 5
Training loss: 0.29978649568814597
Validation loss: 2.295884642764553

Epoch: 5| Step: 6
Training loss: 0.4102447051079106
Validation loss: 2.246986269043783

Epoch: 5| Step: 7
Training loss: 0.4674882596882597
Validation loss: 2.274377431586721

Epoch: 5| Step: 8
Training loss: 0.3847735060451103
Validation loss: 2.2432911292614834

Epoch: 5| Step: 9
Training loss: 0.532758786131264
Validation loss: 2.2490490974305137

Epoch: 5| Step: 10
Training loss: 0.5201445093545878
Validation loss: 2.2806489382717476

Epoch: 460| Step: 0
Training loss: 0.5407991492641405
Validation loss: 2.2569592431916075

Epoch: 5| Step: 1
Training loss: 0.23331603985943697
Validation loss: 2.2652984202719506

Epoch: 5| Step: 2
Training loss: 0.1288724334749837
Validation loss: 2.2847283238138525

Epoch: 5| Step: 3
Training loss: 0.5150159649087301
Validation loss: 2.2829323775484083

Epoch: 5| Step: 4
Training loss: 0.5765326711903983
Validation loss: 2.2557986612064402

Epoch: 5| Step: 5
Training loss: 0.3607630047783754
Validation loss: 2.2583395658586474

Epoch: 5| Step: 6
Training loss: 0.6644598725619371
Validation loss: 2.2873500516839065

Epoch: 5| Step: 7
Training loss: 0.3650018492416672
Validation loss: 2.291720563267817

Epoch: 5| Step: 8
Training loss: 0.36360607186992766
Validation loss: 2.301504120637931

Epoch: 5| Step: 9
Training loss: 0.2520529674862354
Validation loss: 2.340533768332479

Epoch: 5| Step: 10
Training loss: 0.4015871545073259
Validation loss: 2.3163728729396076

Epoch: 461| Step: 0
Training loss: 0.393881025917739
Validation loss: 2.341836282841087

Epoch: 5| Step: 1
Training loss: 0.5357242549241124
Validation loss: 2.3155872536689412

Epoch: 5| Step: 2
Training loss: 0.37813069914629216
Validation loss: 2.279766349309117

Epoch: 5| Step: 3
Training loss: 0.5335307808802867
Validation loss: 2.268110126603061

Epoch: 5| Step: 4
Training loss: 0.31616793004867577
Validation loss: 2.265448332317514

Epoch: 5| Step: 5
Training loss: 0.2438346242114876
Validation loss: 2.2737730558306675

Epoch: 5| Step: 6
Training loss: 0.47813788315613376
Validation loss: 2.2707337576544475

Epoch: 5| Step: 7
Training loss: 0.4382354311188899
Validation loss: 2.2717523633385563

Epoch: 5| Step: 8
Training loss: 0.2958706380041511
Validation loss: 2.267389735931927

Epoch: 5| Step: 9
Training loss: 0.5300641006717234
Validation loss: 2.294535829447734

Epoch: 5| Step: 10
Training loss: 0.4521751807853998
Validation loss: 2.2696301773681715

Epoch: 462| Step: 0
Training loss: 0.46369450617565816
Validation loss: 2.307755900630314

Epoch: 5| Step: 1
Training loss: 0.5259744456433103
Validation loss: 2.2627926659566593

Epoch: 5| Step: 2
Training loss: 0.3968319050977998
Validation loss: 2.301355864961883

Epoch: 5| Step: 3
Training loss: 0.24068435921423847
Validation loss: 2.2785640994178284

Epoch: 5| Step: 4
Training loss: 0.3180612677866806
Validation loss: 2.2934431161965105

Epoch: 5| Step: 5
Training loss: 0.4694382542124289
Validation loss: 2.319622183630708

Epoch: 5| Step: 6
Training loss: 0.440227352110011
Validation loss: 2.3305828188548126

Epoch: 5| Step: 7
Training loss: 0.42869041237326383
Validation loss: 2.3172296825964414

Epoch: 5| Step: 8
Training loss: 0.30445002813920174
Validation loss: 2.2772896426970446

Epoch: 5| Step: 9
Training loss: 0.5439556949521787
Validation loss: 2.3082394428408093

Epoch: 5| Step: 10
Training loss: 0.3832612618647406
Validation loss: 2.28525404775621

Epoch: 463| Step: 0
Training loss: 0.13822932884989664
Validation loss: 2.292573576732002

Epoch: 5| Step: 1
Training loss: 0.2765811859973496
Validation loss: 2.2748787250037585

Epoch: 5| Step: 2
Training loss: 0.4450764950894333
Validation loss: 2.328765769949443

Epoch: 5| Step: 3
Training loss: 0.5539924134895251
Validation loss: 2.312409855649576

Epoch: 5| Step: 4
Training loss: 0.5002811356767816
Validation loss: 2.288036029632313

Epoch: 5| Step: 5
Training loss: 0.23501883924584158
Validation loss: 2.2735422009717663

Epoch: 5| Step: 6
Training loss: 0.4346668950455208
Validation loss: 2.2823067371151677

Epoch: 5| Step: 7
Training loss: 0.24034064353817114
Validation loss: 2.2846473348025946

Epoch: 5| Step: 8
Training loss: 0.4353504336630424
Validation loss: 2.2678814031998344

Epoch: 5| Step: 9
Training loss: 0.3766123362759787
Validation loss: 2.2906115826168727

Epoch: 5| Step: 10
Training loss: 0.6812799149690847
Validation loss: 2.288743948863245

Epoch: 464| Step: 0
Training loss: 0.5184981320677671
Validation loss: 2.2798336091734592

Epoch: 5| Step: 1
Training loss: 0.3038796940358203
Validation loss: 2.276507048010673

Epoch: 5| Step: 2
Training loss: 0.2855292454403167
Validation loss: 2.276197773957428

Epoch: 5| Step: 3
Training loss: 0.46866848554751145
Validation loss: 2.2838607014211454

Epoch: 5| Step: 4
Training loss: 0.5267486039637899
Validation loss: 2.3068876665324556

Epoch: 5| Step: 5
Training loss: 0.4608085096231235
Validation loss: 2.2762883466295047

Epoch: 5| Step: 6
Training loss: 0.13332755829429022
Validation loss: 2.3013917662533903

Epoch: 5| Step: 7
Training loss: 0.6923082147396594
Validation loss: 2.259983211910174

Epoch: 5| Step: 8
Training loss: 0.30247137889947295
Validation loss: 2.268343766973051

Epoch: 5| Step: 9
Training loss: 0.2778710872505087
Validation loss: 2.300238930667278

Epoch: 5| Step: 10
Training loss: 0.14805650755211586
Validation loss: 2.3276931032836554

Epoch: 465| Step: 0
Training loss: 0.27771591683173796
Validation loss: 2.3354188647388887

Epoch: 5| Step: 1
Training loss: 0.22968421369264683
Validation loss: 2.3459729700835346

Epoch: 5| Step: 2
Training loss: 0.4048328440591131
Validation loss: 2.3326325074580545

Epoch: 5| Step: 3
Training loss: 0.48257431525291655
Validation loss: 2.28726027164585

Epoch: 5| Step: 4
Training loss: 0.4219920737688271
Validation loss: 2.313858933329511

Epoch: 5| Step: 5
Training loss: 0.4302422497044076
Validation loss: 2.320612391701996

Epoch: 5| Step: 6
Training loss: 0.5215427208881899
Validation loss: 2.2874160350423

Epoch: 5| Step: 7
Training loss: 0.5178397614986896
Validation loss: 2.313111501259456

Epoch: 5| Step: 8
Training loss: 0.41847261023704774
Validation loss: 2.266026773496803

Epoch: 5| Step: 9
Training loss: 0.33937810369516047
Validation loss: 2.3006110158748014

Epoch: 5| Step: 10
Training loss: 0.4222684191418147
Validation loss: 2.2797645185914073

Epoch: 466| Step: 0
Training loss: 0.43936330937098267
Validation loss: 2.31307515511208

Epoch: 5| Step: 1
Training loss: 0.5591410110214328
Validation loss: 2.305424653872399

Epoch: 5| Step: 2
Training loss: 0.33161264847473115
Validation loss: 2.3092086825573173

Epoch: 5| Step: 3
Training loss: 0.3037612480859556
Validation loss: 2.2600540075111546

Epoch: 5| Step: 4
Training loss: 0.4144190386849953
Validation loss: 2.3127323733411154

Epoch: 5| Step: 5
Training loss: 0.13924561938050578
Validation loss: 2.2956898924310867

Epoch: 5| Step: 6
Training loss: 0.43348278309666904
Validation loss: 2.3063065754116914

Epoch: 5| Step: 7
Training loss: 0.5109510997397166
Validation loss: 2.324058192267207

Epoch: 5| Step: 8
Training loss: 0.48230023723207316
Validation loss: 2.3175939181657865

Epoch: 5| Step: 9
Training loss: 0.3898394123822243
Validation loss: 2.3210666939338966

Epoch: 5| Step: 10
Training loss: 0.32541351329449497
Validation loss: 2.3159559212949508

Epoch: 467| Step: 0
Training loss: 0.38206855342168705
Validation loss: 2.2753673960879213

Epoch: 5| Step: 1
Training loss: 0.4618880282720987
Validation loss: 2.2862171011549135

Epoch: 5| Step: 2
Training loss: 0.2616822231481359
Validation loss: 2.2824848185892486

Epoch: 5| Step: 3
Training loss: 0.4331705588508004
Validation loss: 2.2999364749612283

Epoch: 5| Step: 4
Training loss: 0.20412130123496905
Validation loss: 2.2610116747014892

Epoch: 5| Step: 5
Training loss: 0.4059028609534705
Validation loss: 2.235096806909105

Epoch: 5| Step: 6
Training loss: 0.4865002002166775
Validation loss: 2.277372078448589

Epoch: 5| Step: 7
Training loss: 0.2923238905130464
Validation loss: 2.297802789417675

Epoch: 5| Step: 8
Training loss: 0.5173777642297184
Validation loss: 2.3334572168796694

Epoch: 5| Step: 9
Training loss: 0.3961068220821825
Validation loss: 2.294485195402908

Epoch: 5| Step: 10
Training loss: 0.5060605860388095
Validation loss: 2.316585386441984

Epoch: 468| Step: 0
Training loss: 0.40524707386718345
Validation loss: 2.2728044232924294

Epoch: 5| Step: 1
Training loss: 0.2010814037401021
Validation loss: 2.3099803062621915

Epoch: 5| Step: 2
Training loss: 0.3862147852514118
Validation loss: 2.2767159826521737

Epoch: 5| Step: 3
Training loss: 0.6644648062583532
Validation loss: 2.2789789499300968

Epoch: 5| Step: 4
Training loss: 0.5012654146597294
Validation loss: 2.306958242904669

Epoch: 5| Step: 5
Training loss: 0.19488659197272992
Validation loss: 2.275705224567473

Epoch: 5| Step: 6
Training loss: 0.4323780440780003
Validation loss: 2.304092182951654

Epoch: 5| Step: 7
Training loss: 0.329288203350388
Validation loss: 2.261874208217744

Epoch: 5| Step: 8
Training loss: 0.3229211786426632
Validation loss: 2.258511785518937

Epoch: 5| Step: 9
Training loss: 0.3919927303384578
Validation loss: 2.2692176178966905

Epoch: 5| Step: 10
Training loss: 0.43691597854132735
Validation loss: 2.286646577862302

Epoch: 469| Step: 0
Training loss: 0.29378114596071764
Validation loss: 2.2699682441822286

Epoch: 5| Step: 1
Training loss: 0.34353832750257207
Validation loss: 2.30409763046361

Epoch: 5| Step: 2
Training loss: 0.5213723508831101
Validation loss: 2.303689859830575

Epoch: 5| Step: 3
Training loss: 0.3831958602854383
Validation loss: 2.2852439749242555

Epoch: 5| Step: 4
Training loss: 0.5692509739917302
Validation loss: 2.2766052330819866

Epoch: 5| Step: 5
Training loss: 0.5015406713756575
Validation loss: 2.254813818072628

Epoch: 5| Step: 6
Training loss: 0.3163887301645466
Validation loss: 2.21411131813842

Epoch: 5| Step: 7
Training loss: 0.4212555753072926
Validation loss: 2.2610296993906998

Epoch: 5| Step: 8
Training loss: 0.4872964617506989
Validation loss: 2.256491103118437

Epoch: 5| Step: 9
Training loss: 0.23162130915371779
Validation loss: 2.2708490378122876

Epoch: 5| Step: 10
Training loss: 0.27227968592847407
Validation loss: 2.319460902631442

Epoch: 470| Step: 0
Training loss: 0.2925637051908545
Validation loss: 2.2826850165927297

Epoch: 5| Step: 1
Training loss: 0.48910757716300923
Validation loss: 2.298702648246835

Epoch: 5| Step: 2
Training loss: 0.2666884479841106
Validation loss: 2.335928151112688

Epoch: 5| Step: 3
Training loss: 0.43407411857747935
Validation loss: 2.319443384519518

Epoch: 5| Step: 4
Training loss: 0.47507853925298277
Validation loss: 2.2997427215529305

Epoch: 5| Step: 5
Training loss: 0.49221806204232327
Validation loss: 2.310104502937797

Epoch: 5| Step: 6
Training loss: 0.31484794708559216
Validation loss: 2.2747445064571963

Epoch: 5| Step: 7
Training loss: 0.4655222388936497
Validation loss: 2.2510947101822816

Epoch: 5| Step: 8
Training loss: 0.4309962714868166
Validation loss: 2.2230628540441093

Epoch: 5| Step: 9
Training loss: 0.4348890528654761
Validation loss: 2.204599953094751

Epoch: 5| Step: 10
Training loss: 0.4032296732363339
Validation loss: 2.215121375369299

Epoch: 471| Step: 0
Training loss: 0.423095245273032
Validation loss: 2.2310501552599162

Epoch: 5| Step: 1
Training loss: 0.35752396089778804
Validation loss: 2.1982584574170976

Epoch: 5| Step: 2
Training loss: 0.4101786289467716
Validation loss: 2.248960801350125

Epoch: 5| Step: 3
Training loss: 0.3662828298573221
Validation loss: 2.264428687031039

Epoch: 5| Step: 4
Training loss: 0.3475606336799045
Validation loss: 2.230970263919107

Epoch: 5| Step: 5
Training loss: 0.5832198634367731
Validation loss: 2.2553800661347045

Epoch: 5| Step: 6
Training loss: 0.3117920007900589
Validation loss: 2.275855189499142

Epoch: 5| Step: 7
Training loss: 0.5726105103174017
Validation loss: 2.2288329658914194

Epoch: 5| Step: 8
Training loss: 0.3236717642697148
Validation loss: 2.2775136315466296

Epoch: 5| Step: 9
Training loss: 0.4015202102954513
Validation loss: 2.28074163283849

Epoch: 5| Step: 10
Training loss: 0.26904958727219563
Validation loss: 2.2498529641385336

Epoch: 472| Step: 0
Training loss: 0.2555810856347699
Validation loss: 2.256852172362078

Epoch: 5| Step: 1
Training loss: 0.47209086375390474
Validation loss: 2.271010194882831

Epoch: 5| Step: 2
Training loss: 0.500977603546905
Validation loss: 2.2686174030608512

Epoch: 5| Step: 3
Training loss: 0.24132008727801454
Validation loss: 2.315461897345634

Epoch: 5| Step: 4
Training loss: 0.2900264493209761
Validation loss: 2.30189261098592

Epoch: 5| Step: 5
Training loss: 0.36007135760220965
Validation loss: 2.287445017669781

Epoch: 5| Step: 6
Training loss: 0.371064375668476
Validation loss: 2.3258587155705057

Epoch: 5| Step: 7
Training loss: 0.49969762361254194
Validation loss: 2.2876308586409544

Epoch: 5| Step: 8
Training loss: 0.4757543809942611
Validation loss: 2.2788973060521354

Epoch: 5| Step: 9
Training loss: 0.4141635231721324
Validation loss: 2.297190536468514

Epoch: 5| Step: 10
Training loss: 0.46867985200523776
Validation loss: 2.272816725394024

Epoch: 473| Step: 0
Training loss: 0.432179214221583
Validation loss: 2.219693061037998

Epoch: 5| Step: 1
Training loss: 0.36941132888032613
Validation loss: 2.2419845845395043

Epoch: 5| Step: 2
Training loss: 0.3935269897407242
Validation loss: 2.264025353794385

Epoch: 5| Step: 3
Training loss: 0.27790021813848387
Validation loss: 2.220783440528282

Epoch: 5| Step: 4
Training loss: 0.4160932728116103
Validation loss: 2.2337766580933804

Epoch: 5| Step: 5
Training loss: 0.4077317103020917
Validation loss: 2.2587283485733645

Epoch: 5| Step: 6
Training loss: 0.46489806619230895
Validation loss: 2.295730675765246

Epoch: 5| Step: 7
Training loss: 0.4733240438554907
Validation loss: 2.3446777159350245

Epoch: 5| Step: 8
Training loss: 0.4941883139535442
Validation loss: 2.3139258204286484

Epoch: 5| Step: 9
Training loss: 0.4249176927414365
Validation loss: 2.353009080811818

Epoch: 5| Step: 10
Training loss: 0.26188661401618907
Validation loss: 2.3343248509330463

Epoch: 474| Step: 0
Training loss: 0.4225621455382491
Validation loss: 2.3212947291893657

Epoch: 5| Step: 1
Training loss: 0.5793738665770274
Validation loss: 2.2992616082112423

Epoch: 5| Step: 2
Training loss: 0.29430044779116427
Validation loss: 2.263329931799049

Epoch: 5| Step: 3
Training loss: 0.4970807147483356
Validation loss: 2.243815792925642

Epoch: 5| Step: 4
Training loss: 0.2669042748111396
Validation loss: 2.216128884778195

Epoch: 5| Step: 5
Training loss: 0.3540137348783749
Validation loss: 2.223037182753403

Epoch: 5| Step: 6
Training loss: 0.3894815685174012
Validation loss: 2.1646175813589412

Epoch: 5| Step: 7
Training loss: 0.5169289025980135
Validation loss: 2.2380203581516027

Epoch: 5| Step: 8
Training loss: 0.2915993539020068
Validation loss: 2.280084799289881

Epoch: 5| Step: 9
Training loss: 0.3861392910635262
Validation loss: 2.3230006815599924

Epoch: 5| Step: 10
Training loss: 0.43654117078838833
Validation loss: 2.330699287223485

Epoch: 475| Step: 0
Training loss: 0.2599138826334473
Validation loss: 2.3467738453513425

Epoch: 5| Step: 1
Training loss: 0.24058120781110745
Validation loss: 2.358224699329533

Epoch: 5| Step: 2
Training loss: 0.4191765669373361
Validation loss: 2.3345001261846794

Epoch: 5| Step: 3
Training loss: 0.46862083880819894
Validation loss: 2.3528535107858963

Epoch: 5| Step: 4
Training loss: 0.34081086853409165
Validation loss: 2.344957225902805

Epoch: 5| Step: 5
Training loss: 0.3643662442158095
Validation loss: 2.338811309665559

Epoch: 5| Step: 6
Training loss: 0.4121809621528125
Validation loss: 2.3202204565356133

Epoch: 5| Step: 7
Training loss: 0.45051819648044517
Validation loss: 2.273704320041066

Epoch: 5| Step: 8
Training loss: 0.29359416328226495
Validation loss: 2.2768941692412907

Epoch: 5| Step: 9
Training loss: 0.55661144514732
Validation loss: 2.2936463733879084

Epoch: 5| Step: 10
Training loss: 0.4753886289405763
Validation loss: 2.257290427479814

Epoch: 476| Step: 0
Training loss: 0.2751364651119157
Validation loss: 2.272643504001988

Epoch: 5| Step: 1
Training loss: 0.594731222801553
Validation loss: 2.289478932034276

Epoch: 5| Step: 2
Training loss: 0.2654520762182174
Validation loss: 2.324175328433087

Epoch: 5| Step: 3
Training loss: 0.442521113657072
Validation loss: 2.3423166881527493

Epoch: 5| Step: 4
Training loss: 0.3060209122980846
Validation loss: 2.321051589162595

Epoch: 5| Step: 5
Training loss: 0.32354712724632084
Validation loss: 2.3410976702032276

Epoch: 5| Step: 6
Training loss: 0.19064239946284742
Validation loss: 2.346224195216163

Epoch: 5| Step: 7
Training loss: 0.4279186600796861
Validation loss: 2.335654361708047

Epoch: 5| Step: 8
Training loss: 0.3786089409123597
Validation loss: 2.3367803528234448

Epoch: 5| Step: 9
Training loss: 0.47041098048363833
Validation loss: 2.3246945063913564

Epoch: 5| Step: 10
Training loss: 0.4418522429912324
Validation loss: 2.304117102765731

Epoch: 477| Step: 0
Training loss: 0.2851730498499291
Validation loss: 2.317654633231189

Epoch: 5| Step: 1
Training loss: 0.5252371070946229
Validation loss: 2.236759979612026

Epoch: 5| Step: 2
Training loss: 0.35722635476683534
Validation loss: 2.240231145033979

Epoch: 5| Step: 3
Training loss: 0.28656205409191055
Validation loss: 2.2639005339317735

Epoch: 5| Step: 4
Training loss: 0.2796739020851431
Validation loss: 2.255535134357198

Epoch: 5| Step: 5
Training loss: 0.5168071258520154
Validation loss: 2.3079635781395282

Epoch: 5| Step: 6
Training loss: 0.3130807606060261
Validation loss: 2.30502380842831

Epoch: 5| Step: 7
Training loss: 0.5369298183978236
Validation loss: 2.3351330800327426

Epoch: 5| Step: 8
Training loss: 0.4522495362725946
Validation loss: 2.314947426797282

Epoch: 5| Step: 9
Training loss: 0.36910627094244647
Validation loss: 2.324214918133955

Epoch: 5| Step: 10
Training loss: 0.1586044131767338
Validation loss: 2.336305954756225

Epoch: 478| Step: 0
Training loss: 0.54636310052492
Validation loss: 2.3313767190418533

Epoch: 5| Step: 1
Training loss: 0.30999041430973406
Validation loss: 2.345992799649757

Epoch: 5| Step: 2
Training loss: 0.350639147957531
Validation loss: 2.3219928133942367

Epoch: 5| Step: 3
Training loss: 0.2853835258363232
Validation loss: 2.3114461174117835

Epoch: 5| Step: 4
Training loss: 0.43167269488339055
Validation loss: 2.2351159168795993

Epoch: 5| Step: 5
Training loss: 0.46675341096539913
Validation loss: 2.30898632582188

Epoch: 5| Step: 6
Training loss: 0.3572687123138348
Validation loss: 2.283104913758042

Epoch: 5| Step: 7
Training loss: 0.3051614620664078
Validation loss: 2.242054604934653

Epoch: 5| Step: 8
Training loss: 0.3685387847008523
Validation loss: 2.2806497768381444

Epoch: 5| Step: 9
Training loss: 0.3877821279800636
Validation loss: 2.2875190875725577

Epoch: 5| Step: 10
Training loss: 0.3839554365396882
Validation loss: 2.2557177830857116

Epoch: 479| Step: 0
Training loss: 0.45791860984700034
Validation loss: 2.2532895480150144

Epoch: 5| Step: 1
Training loss: 0.49688349962462136
Validation loss: 2.3035946125784443

Epoch: 5| Step: 2
Training loss: 0.40860865038805
Validation loss: 2.2939002651133835

Epoch: 5| Step: 3
Training loss: 0.2180464278011185
Validation loss: 2.30630750969317

Epoch: 5| Step: 4
Training loss: 0.3473876386912246
Validation loss: 2.2861684740247163

Epoch: 5| Step: 5
Training loss: 0.4503217672629384
Validation loss: 2.296991266775362

Epoch: 5| Step: 6
Training loss: 0.287198280011774
Validation loss: 2.2927847111253716

Epoch: 5| Step: 7
Training loss: 0.4922438997924284
Validation loss: 2.3014454219249956

Epoch: 5| Step: 8
Training loss: 0.3842855450192482
Validation loss: 2.2869716156642195

Epoch: 5| Step: 9
Training loss: 0.32572410594610485
Validation loss: 2.2948033964337244

Epoch: 5| Step: 10
Training loss: 0.21561636285483526
Validation loss: 2.3155931064689477

Epoch: 480| Step: 0
Training loss: 0.40926245532834415
Validation loss: 2.298268458930095

Epoch: 5| Step: 1
Training loss: 0.13357372078019755
Validation loss: 2.2841829347261426

Epoch: 5| Step: 2
Training loss: 0.38864653231556995
Validation loss: 2.2999156140580665

Epoch: 5| Step: 3
Training loss: 0.30285875780052246
Validation loss: 2.2944087570345455

Epoch: 5| Step: 4
Training loss: 0.20311739797305048
Validation loss: 2.293098509344742

Epoch: 5| Step: 5
Training loss: 0.4961982677025099
Validation loss: 2.2899120814499483

Epoch: 5| Step: 6
Training loss: 0.24835151827931592
Validation loss: 2.294666493383072

Epoch: 5| Step: 7
Training loss: 0.4566398803339386
Validation loss: 2.291681600244216

Epoch: 5| Step: 8
Training loss: 0.26194208494473054
Validation loss: 2.2638065054219614

Epoch: 5| Step: 9
Training loss: 0.5572188202018923
Validation loss: 2.2775032380062825

Epoch: 5| Step: 10
Training loss: 0.4854106751946736
Validation loss: 2.260901760331896

Epoch: 481| Step: 0
Training loss: 0.36629092550927755
Validation loss: 2.2875298485841777

Epoch: 5| Step: 1
Training loss: 0.3125297532222651
Validation loss: 2.256928206123222

Epoch: 5| Step: 2
Training loss: 0.4028644710541437
Validation loss: 2.2907434748109794

Epoch: 5| Step: 3
Training loss: 0.3279564515416345
Validation loss: 2.2715954396896954

Epoch: 5| Step: 4
Training loss: 0.5547666358911684
Validation loss: 2.277556695260463

Epoch: 5| Step: 5
Training loss: 0.4588699198114036
Validation loss: 2.2924057545240246

Epoch: 5| Step: 6
Training loss: 0.3026288371553874
Validation loss: 2.225590228303604

Epoch: 5| Step: 7
Training loss: 0.4425873946509496
Validation loss: 2.2433563083898136

Epoch: 5| Step: 8
Training loss: 0.3723340639046309
Validation loss: 2.273096285998727

Epoch: 5| Step: 9
Training loss: 0.2181940677947008
Validation loss: 2.279621412191702

Epoch: 5| Step: 10
Training loss: 0.28375978679836106
Validation loss: 2.264865623796673

Epoch: 482| Step: 0
Training loss: 0.23740260925654727
Validation loss: 2.2625620866831

Epoch: 5| Step: 1
Training loss: 0.4367205283686643
Validation loss: 2.2618431042811893

Epoch: 5| Step: 2
Training loss: 0.3141185568130875
Validation loss: 2.263899096915902

Epoch: 5| Step: 3
Training loss: 0.4753599942196438
Validation loss: 2.303327225944042

Epoch: 5| Step: 4
Training loss: 0.3427668948513655
Validation loss: 2.2424740686262994

Epoch: 5| Step: 5
Training loss: 0.32658862141809303
Validation loss: 2.244591697882674

Epoch: 5| Step: 6
Training loss: 0.29948729075594044
Validation loss: 2.2807793608673865

Epoch: 5| Step: 7
Training loss: 0.382075281082606
Validation loss: 2.2458558994673665

Epoch: 5| Step: 8
Training loss: 0.45815169101833064
Validation loss: 2.238181800653809

Epoch: 5| Step: 9
Training loss: 0.30988916288404167
Validation loss: 2.272938649815935

Epoch: 5| Step: 10
Training loss: 0.46619595270642056
Validation loss: 2.2662927194537796

Epoch: 483| Step: 0
Training loss: 0.364438520917802
Validation loss: 2.294294909848999

Epoch: 5| Step: 1
Training loss: 0.11264705715686965
Validation loss: 2.225047179520722

Epoch: 5| Step: 2
Training loss: 0.4497089365236428
Validation loss: 2.288279340232048

Epoch: 5| Step: 3
Training loss: 0.4869019826284968
Validation loss: 2.2882610775697816

Epoch: 5| Step: 4
Training loss: 0.40665538442248855
Validation loss: 2.2653197312344697

Epoch: 5| Step: 5
Training loss: 0.622298625446955
Validation loss: 2.3278222414022527

Epoch: 5| Step: 6
Training loss: 0.2661963376962646
Validation loss: 2.292229221091607

Epoch: 5| Step: 7
Training loss: 0.12702429317179356
Validation loss: 2.283618728296599

Epoch: 5| Step: 8
Training loss: 0.2848917766726231
Validation loss: 2.2548523960454854

Epoch: 5| Step: 9
Training loss: 0.3677093368963248
Validation loss: 2.2948001276491943

Epoch: 5| Step: 10
Training loss: 0.28673100354362635
Validation loss: 2.2591333455468066

Epoch: 484| Step: 0
Training loss: 0.28421666537249635
Validation loss: 2.259475622891001

Epoch: 5| Step: 1
Training loss: 0.48981631261469294
Validation loss: 2.265518264038459

Epoch: 5| Step: 2
Training loss: 0.361910232548384
Validation loss: 2.2139278307138475

Epoch: 5| Step: 3
Training loss: 0.41331590965037895
Validation loss: 2.263999313280903

Epoch: 5| Step: 4
Training loss: 0.31624075010968133
Validation loss: 2.2699727729630697

Epoch: 5| Step: 5
Training loss: 0.38807392610527774
Validation loss: 2.2747167561282122

Epoch: 5| Step: 6
Training loss: 0.4583424075991221
Validation loss: 2.243380620978802

Epoch: 5| Step: 7
Training loss: 0.27961214318388045
Validation loss: 2.2852799616203487

Epoch: 5| Step: 8
Training loss: 0.3415751800905736
Validation loss: 2.283676526881707

Epoch: 5| Step: 9
Training loss: 0.32943225625340467
Validation loss: 2.287521311055883

Epoch: 5| Step: 10
Training loss: 0.3544028303531168
Validation loss: 2.2827296260653203

Epoch: 485| Step: 0
Training loss: 0.3878418383693757
Validation loss: 2.3101991916056104

Epoch: 5| Step: 1
Training loss: 0.511901444298163
Validation loss: 2.3037063014419514

Epoch: 5| Step: 2
Training loss: 0.2475396474476483
Validation loss: 2.293397188710935

Epoch: 5| Step: 3
Training loss: 0.3507042794007838
Validation loss: 2.28617913766742

Epoch: 5| Step: 4
Training loss: 0.3041936589156969
Validation loss: 2.2738620914258414

Epoch: 5| Step: 5
Training loss: 0.4460029269088192
Validation loss: 2.2586924368288224

Epoch: 5| Step: 6
Training loss: 0.35048839944288507
Validation loss: 2.252319286246972

Epoch: 5| Step: 7
Training loss: 0.2253037293455866
Validation loss: 2.2473804237267956

Epoch: 5| Step: 8
Training loss: 0.5614641241177213
Validation loss: 2.26018370275687

Epoch: 5| Step: 9
Training loss: 0.21404471497546113
Validation loss: 2.228968065086432

Epoch: 5| Step: 10
Training loss: 0.1722345817258062
Validation loss: 2.2237453817432704

Epoch: 486| Step: 0
Training loss: 0.4864661392413373
Validation loss: 2.2531492623748375

Epoch: 5| Step: 1
Training loss: 0.16366878451977998
Validation loss: 2.2322869578431432

Epoch: 5| Step: 2
Training loss: 0.3789179102096527
Validation loss: 2.2161052140002013

Epoch: 5| Step: 3
Training loss: 0.13519295375985058
Validation loss: 2.2525671427681826

Epoch: 5| Step: 4
Training loss: 0.2861703060439348
Validation loss: 2.283879405051866

Epoch: 5| Step: 5
Training loss: 0.5855110905702042
Validation loss: 2.2759489105923456

Epoch: 5| Step: 6
Training loss: 0.28461848461934797
Validation loss: 2.2515919937106155

Epoch: 5| Step: 7
Training loss: 0.2817678055920815
Validation loss: 2.2582171790277568

Epoch: 5| Step: 8
Training loss: 0.47199028956195765
Validation loss: 2.2502660605429594

Epoch: 5| Step: 9
Training loss: 0.3763008997633469
Validation loss: 2.306933939145762

Epoch: 5| Step: 10
Training loss: 0.33848290544786164
Validation loss: 2.2812926540862577

Epoch: 487| Step: 0
Training loss: 0.38759557944981493
Validation loss: 2.264083177564997

Epoch: 5| Step: 1
Training loss: 0.5149436842117261
Validation loss: 2.3086280035244195

Epoch: 5| Step: 2
Training loss: 0.2518552545707061
Validation loss: 2.277190345864795

Epoch: 5| Step: 3
Training loss: 0.26200273393886236
Validation loss: 2.2837046274716157

Epoch: 5| Step: 4
Training loss: 0.4313776760178597
Validation loss: 2.307010806224626

Epoch: 5| Step: 5
Training loss: 0.4635336550188112
Validation loss: 2.315135811684346

Epoch: 5| Step: 6
Training loss: 0.2622195050843903
Validation loss: 2.297138117841241

Epoch: 5| Step: 7
Training loss: 0.37653843893843275
Validation loss: 2.305062007631006

Epoch: 5| Step: 8
Training loss: 0.3318142125481957
Validation loss: 2.2876406732998347

Epoch: 5| Step: 9
Training loss: 0.28896152175999784
Validation loss: 2.2589821544780992

Epoch: 5| Step: 10
Training loss: 0.29781411357654664
Validation loss: 2.2997866049818265

Epoch: 488| Step: 0
Training loss: 0.4013256042175554
Validation loss: 2.270224794410203

Epoch: 5| Step: 1
Training loss: 0.23842396136502936
Validation loss: 2.313445626533196

Epoch: 5| Step: 2
Training loss: 0.35844073968435963
Validation loss: 2.284546120451097

Epoch: 5| Step: 3
Training loss: 0.2763789683280945
Validation loss: 2.2596598471991607

Epoch: 5| Step: 4
Training loss: 0.4221045258233084
Validation loss: 2.3270487296542406

Epoch: 5| Step: 5
Training loss: 0.31728089089900713
Validation loss: 2.25691828630264

Epoch: 5| Step: 6
Training loss: 0.2792973818474285
Validation loss: 2.262105471288842

Epoch: 5| Step: 7
Training loss: 0.4791204406029702
Validation loss: 2.248218493084404

Epoch: 5| Step: 8
Training loss: 0.4585388618648053
Validation loss: 2.2628922674400975

Epoch: 5| Step: 9
Training loss: 0.38136420415516104
Validation loss: 2.267458639398891

Epoch: 5| Step: 10
Training loss: 0.33586736434871883
Validation loss: 2.2554515682917637

Epoch: 489| Step: 0
Training loss: 0.22657696907932917
Validation loss: 2.258520197742193

Epoch: 5| Step: 1
Training loss: 0.3715244403978388
Validation loss: 2.322008971390051

Epoch: 5| Step: 2
Training loss: 0.5240025104178652
Validation loss: 2.278941334960895

Epoch: 5| Step: 3
Training loss: 0.4969748084871925
Validation loss: 2.3257650507963263

Epoch: 5| Step: 4
Training loss: 0.3483427320852009
Validation loss: 2.261122563890701

Epoch: 5| Step: 5
Training loss: 0.46045022197788044
Validation loss: 2.2822642053240108

Epoch: 5| Step: 6
Training loss: 0.32597207899993
Validation loss: 2.2587418589209274

Epoch: 5| Step: 7
Training loss: 0.21258201453966122
Validation loss: 2.2856074471562278

Epoch: 5| Step: 8
Training loss: 0.23936148752266032
Validation loss: 2.2600812470793326

Epoch: 5| Step: 9
Training loss: 0.2597301860527298
Validation loss: 2.3197170916295207

Epoch: 5| Step: 10
Training loss: 0.3041647436895506
Validation loss: 2.288659080619414

Epoch: 490| Step: 0
Training loss: 0.3984492992075194
Validation loss: 2.300539735237991

Epoch: 5| Step: 1
Training loss: 0.1965341319186613
Validation loss: 2.2958095184008736

Epoch: 5| Step: 2
Training loss: 0.42271191976024447
Validation loss: 2.2913046401739723

Epoch: 5| Step: 3
Training loss: 0.49972197134031554
Validation loss: 2.283749614413149

Epoch: 5| Step: 4
Training loss: 0.20896094181914945
Validation loss: 2.2689053548177123

Epoch: 5| Step: 5
Training loss: 0.5294598261710401
Validation loss: 2.273512750187979

Epoch: 5| Step: 6
Training loss: 0.19927331700715634
Validation loss: 2.2529384721803347

Epoch: 5| Step: 7
Training loss: 0.4158958835833312
Validation loss: 2.267733099584188

Epoch: 5| Step: 8
Training loss: 0.26114700267414814
Validation loss: 2.277799748488915

Epoch: 5| Step: 9
Training loss: 0.40190817578839616
Validation loss: 2.2749842397420452

Epoch: 5| Step: 10
Training loss: 0.24517652849557428
Validation loss: 2.305009887850189

Epoch: 491| Step: 0
Training loss: 0.5418257449158562
Validation loss: 2.302285833940863

Epoch: 5| Step: 1
Training loss: 0.25687369007509836
Validation loss: 2.332094895164652

Epoch: 5| Step: 2
Training loss: 0.18763817226037136
Validation loss: 2.3704262722263323

Epoch: 5| Step: 3
Training loss: 0.2283182188122434
Validation loss: 2.34726992211956

Epoch: 5| Step: 4
Training loss: 0.4222880919458402
Validation loss: 2.322898910662817

Epoch: 5| Step: 5
Training loss: 0.3244706749251393
Validation loss: 2.263129263164436

Epoch: 5| Step: 6
Training loss: 0.34479600893073403
Validation loss: 2.2967880218045105

Epoch: 5| Step: 7
Training loss: 0.23509755812063987
Validation loss: 2.2759645675704516

Epoch: 5| Step: 8
Training loss: 0.38386633873959514
Validation loss: 2.287775111285032

Epoch: 5| Step: 9
Training loss: 0.4162136555748076
Validation loss: 2.257185790412748

Epoch: 5| Step: 10
Training loss: 0.4971248544323972
Validation loss: 2.2773967784518567

Epoch: 492| Step: 0
Training loss: 0.4074220073988673
Validation loss: 2.2622617194171313

Epoch: 5| Step: 1
Training loss: 0.3509343575653666
Validation loss: 2.223084949573838

Epoch: 5| Step: 2
Training loss: 0.24907880429373336
Validation loss: 2.2881392514305707

Epoch: 5| Step: 3
Training loss: 0.3817875043586691
Validation loss: 2.2896408150724965

Epoch: 5| Step: 4
Training loss: 0.378163957559362
Validation loss: 2.2686073439395207

Epoch: 5| Step: 5
Training loss: 0.10119282402484067
Validation loss: 2.2889621915212524

Epoch: 5| Step: 6
Training loss: 0.39397754149644465
Validation loss: 2.286558182468167

Epoch: 5| Step: 7
Training loss: 0.273402593291945
Validation loss: 2.3062970952955917

Epoch: 5| Step: 8
Training loss: 0.40667152543891455
Validation loss: 2.335589835815263

Epoch: 5| Step: 9
Training loss: 0.38571850667768265
Validation loss: 2.282511978036218

Epoch: 5| Step: 10
Training loss: 0.36948382857659734
Validation loss: 2.2781444470238794

Epoch: 493| Step: 0
Training loss: 0.5314341955063132
Validation loss: 2.30978264164663

Epoch: 5| Step: 1
Training loss: 0.4124379768848625
Validation loss: 2.3225138855042236

Epoch: 5| Step: 2
Training loss: 0.14168030752630584
Validation loss: 2.3168519821140503

Epoch: 5| Step: 3
Training loss: 0.36734393013933925
Validation loss: 2.324322018285728

Epoch: 5| Step: 4
Training loss: 0.2924289562479847
Validation loss: 2.3044020676069814

Epoch: 5| Step: 5
Training loss: 0.3409020290401934
Validation loss: 2.318705766248922

Epoch: 5| Step: 6
Training loss: 0.3595527955470807
Validation loss: 2.289999035894486

Epoch: 5| Step: 7
Training loss: 0.3058300116269396
Validation loss: 2.300788548312054

Epoch: 5| Step: 8
Training loss: 0.1337785716712098
Validation loss: 2.294769122002116

Epoch: 5| Step: 9
Training loss: 0.3010772511901481
Validation loss: 2.2824891248561925

Epoch: 5| Step: 10
Training loss: 0.45996158543113863
Validation loss: 2.2814489320871423

Epoch: 494| Step: 0
Training loss: 0.4146918965374663
Validation loss: 2.328018014512546

Epoch: 5| Step: 1
Training loss: 0.32483259942466214
Validation loss: 2.305987482530929

Epoch: 5| Step: 2
Training loss: 0.3849676153880184
Validation loss: 2.3309552666269906

Epoch: 5| Step: 3
Training loss: 0.3037408403106573
Validation loss: 2.281490221691047

Epoch: 5| Step: 4
Training loss: 0.12853201816671528
Validation loss: 2.3290414442759757

Epoch: 5| Step: 5
Training loss: 0.23644346780024292
Validation loss: 2.296794913121161

Epoch: 5| Step: 6
Training loss: 0.2842207941167388
Validation loss: 2.2858435749241446

Epoch: 5| Step: 7
Training loss: 0.3411667273822955
Validation loss: 2.2845598652635055

Epoch: 5| Step: 8
Training loss: 0.5621164391705339
Validation loss: 2.299956689179805

Epoch: 5| Step: 9
Training loss: 0.3572858124115266
Validation loss: 2.289277185893657

Epoch: 5| Step: 10
Training loss: 0.22429601952825803
Validation loss: 2.264344343612293

Epoch: 495| Step: 0
Training loss: 0.361516212791001
Validation loss: 2.2874620767331533

Epoch: 5| Step: 1
Training loss: 0.32573041908129924
Validation loss: 2.2704123582555322

Epoch: 5| Step: 2
Training loss: 0.3300278868054618
Validation loss: 2.307527190141908

Epoch: 5| Step: 3
Training loss: 0.33456005430334224
Validation loss: 2.291883815944389

Epoch: 5| Step: 4
Training loss: 0.4504769327754911
Validation loss: 2.2742383464205203

Epoch: 5| Step: 5
Training loss: 0.24535191456211183
Validation loss: 2.2837194589474916

Epoch: 5| Step: 6
Training loss: 0.3221154296439191
Validation loss: 2.3052952663926214

Epoch: 5| Step: 7
Training loss: 0.32847206743212964
Validation loss: 2.326026129526162

Epoch: 5| Step: 8
Training loss: 0.25426473985835685
Validation loss: 2.317828468526642

Epoch: 5| Step: 9
Training loss: 0.35639079473918667
Validation loss: 2.293916533258582

Epoch: 5| Step: 10
Training loss: 0.38345640874250714
Validation loss: 2.293937185528697

Epoch: 496| Step: 0
Training loss: 0.2229716593359422
Validation loss: 2.28069946640509

Epoch: 5| Step: 1
Training loss: 0.3619131558649325
Validation loss: 2.2910736454019376

Epoch: 5| Step: 2
Training loss: 0.1881618144681294
Validation loss: 2.313061415157595

Epoch: 5| Step: 3
Training loss: 0.37897209696480383
Validation loss: 2.3364141059438306

Epoch: 5| Step: 4
Training loss: 0.2650907697958657
Validation loss: 2.3149853708905344

Epoch: 5| Step: 5
Training loss: 0.40073697996376784
Validation loss: 2.3252944978539114

Epoch: 5| Step: 6
Training loss: 0.4599208611849275
Validation loss: 2.3016415158443233

Epoch: 5| Step: 7
Training loss: 0.3747811871149027
Validation loss: 2.3543033148197177

Epoch: 5| Step: 8
Training loss: 0.2513207921128477
Validation loss: 2.2800800747159906

Epoch: 5| Step: 9
Training loss: 0.34013287533590975
Validation loss: 2.303172712958435

Epoch: 5| Step: 10
Training loss: 0.4073529127500285
Validation loss: 2.311355301961933

Epoch: 497| Step: 0
Training loss: 0.33362171493633774
Validation loss: 2.3148766399408407

Epoch: 5| Step: 1
Training loss: 0.33312651680391686
Validation loss: 2.256667829042692

Epoch: 5| Step: 2
Training loss: 0.3444979290408601
Validation loss: 2.2671811780244027

Epoch: 5| Step: 3
Training loss: 0.41128568004630633
Validation loss: 2.2799794767472887

Epoch: 5| Step: 4
Training loss: 0.1781033364724797
Validation loss: 2.234705362379754

Epoch: 5| Step: 5
Training loss: 0.4053983197205156
Validation loss: 2.247118813695413

Epoch: 5| Step: 6
Training loss: 0.45736598936589645
Validation loss: 2.2730398278182595

Epoch: 5| Step: 7
Training loss: 0.2923948898318327
Validation loss: 2.2371306069367893

Epoch: 5| Step: 8
Training loss: 0.40238346903771194
Validation loss: 2.2739743680417153

Epoch: 5| Step: 9
Training loss: 0.14971315454749382
Validation loss: 2.3144921383231254

Epoch: 5| Step: 10
Training loss: 0.31254827603334745
Validation loss: 2.312395953204847

Epoch: 498| Step: 0
Training loss: 0.39494490891172007
Validation loss: 2.3044579064977873

Epoch: 5| Step: 1
Training loss: 0.30397809412577065
Validation loss: 2.3094264310511305

Epoch: 5| Step: 2
Training loss: 0.2554788890774797
Validation loss: 2.32035221858464

Epoch: 5| Step: 3
Training loss: 0.34734244596482783
Validation loss: 2.324828938738671

Epoch: 5| Step: 4
Training loss: 0.3793358481250619
Validation loss: 2.2966565811054487

Epoch: 5| Step: 5
Training loss: 0.49783275713896297
Validation loss: 2.2565889105516233

Epoch: 5| Step: 6
Training loss: 0.39367272663270375
Validation loss: 2.244306350603755

Epoch: 5| Step: 7
Training loss: 0.3269946633663191
Validation loss: 2.2595597679635695

Epoch: 5| Step: 8
Training loss: 0.27800792094307997
Validation loss: 2.1987708777770014

Epoch: 5| Step: 9
Training loss: 0.2248772392225076
Validation loss: 2.265582941193197

Epoch: 5| Step: 10
Training loss: 0.24716447837532468
Validation loss: 2.27694001357886

Epoch: 499| Step: 0
Training loss: 0.3909303806611119
Validation loss: 2.2738170035687117

Epoch: 5| Step: 1
Training loss: 0.2977900832466681
Validation loss: 2.2680521884763416

Epoch: 5| Step: 2
Training loss: 0.471182124387409
Validation loss: 2.2838533532236407

Epoch: 5| Step: 3
Training loss: 0.40758385295765903
Validation loss: 2.2756438742722804

Epoch: 5| Step: 4
Training loss: 0.23828869167026503
Validation loss: 2.3152967489844203

Epoch: 5| Step: 5
Training loss: 0.3976185366690768
Validation loss: 2.2788666723912105

Epoch: 5| Step: 6
Training loss: 0.19357172547459894
Validation loss: 2.323014489638722

Epoch: 5| Step: 7
Training loss: 0.3305087356184789
Validation loss: 2.329014130106132

Epoch: 5| Step: 8
Training loss: 0.18699396910734112
Validation loss: 2.2900234698445114

Epoch: 5| Step: 9
Training loss: 0.32981883818258056
Validation loss: 2.3154058369341364

Epoch: 5| Step: 10
Training loss: 0.3031954545798206
Validation loss: 2.278760898104952

Epoch: 500| Step: 0
Training loss: 0.3528134659719294
Validation loss: 2.271622938675807

Epoch: 5| Step: 1
Training loss: 0.4531286502559566
Validation loss: 2.281175508517692

Epoch: 5| Step: 2
Training loss: 0.28685133880075403
Validation loss: 2.2712498685772515

Epoch: 5| Step: 3
Training loss: 0.12269148517919329
Validation loss: 2.310001385908595

Epoch: 5| Step: 4
Training loss: 0.264586649082964
Validation loss: 2.2624695736131994

Epoch: 5| Step: 5
Training loss: 0.17453876172688623
Validation loss: 2.275108625046995

Epoch: 5| Step: 6
Training loss: 0.30065859733769856
Validation loss: 2.297001283628655

Epoch: 5| Step: 7
Training loss: 0.3837387983880416
Validation loss: 2.2959960892167253

Epoch: 5| Step: 8
Training loss: 0.44151217109691904
Validation loss: 2.2968625895739927

Epoch: 5| Step: 9
Training loss: 0.3949692249683078
Validation loss: 2.2586252553831843

Epoch: 5| Step: 10
Training loss: 0.3188413937758368
Validation loss: 2.2922073461037193

Epoch: 501| Step: 0
Training loss: 0.3262946189134169
Validation loss: 2.27038078017134

Epoch: 5| Step: 1
Training loss: 0.26334312572158547
Validation loss: 2.32622317101085

Epoch: 5| Step: 2
Training loss: 0.2724188221748644
Validation loss: 2.2935771514777805

Epoch: 5| Step: 3
Training loss: 0.2648119263110453
Validation loss: 2.324403385733433

Epoch: 5| Step: 4
Training loss: 0.45104489872268516
Validation loss: 2.305233732731876

Epoch: 5| Step: 5
Training loss: 0.2739024704859007
Validation loss: 2.3246595632504556

Epoch: 5| Step: 6
Training loss: 0.39109632667244404
Validation loss: 2.2848942970679813

Epoch: 5| Step: 7
Training loss: 0.43917500490106187
Validation loss: 2.288983978802897

Epoch: 5| Step: 8
Training loss: 0.4314246867384146
Validation loss: 2.2830174042135782

Epoch: 5| Step: 9
Training loss: 0.11460284361401805
Validation loss: 2.2806033781362545

Epoch: 5| Step: 10
Training loss: 0.1695838668580141
Validation loss: 2.3264185775660717

Epoch: 502| Step: 0
Training loss: 0.23917157701581032
Validation loss: 2.2984279014751876

Epoch: 5| Step: 1
Training loss: 0.13773002592762285
Validation loss: 2.314078199594752

Epoch: 5| Step: 2
Training loss: 0.24920713343796766
Validation loss: 2.278567477846469

Epoch: 5| Step: 3
Training loss: 0.2833716581641428
Validation loss: 2.294329751731424

Epoch: 5| Step: 4
Training loss: 0.19199659821730292
Validation loss: 2.286426778775504

Epoch: 5| Step: 5
Training loss: 0.5108425997173137
Validation loss: 2.3230844822689476

Epoch: 5| Step: 6
Training loss: 0.40108806993945284
Validation loss: 2.3421301031242043

Epoch: 5| Step: 7
Training loss: 0.44342746295820257
Validation loss: 2.3297831055435974

Epoch: 5| Step: 8
Training loss: 0.37723268015509653
Validation loss: 2.3801520832741256

Epoch: 5| Step: 9
Training loss: 0.3021156386936253
Validation loss: 2.341136328760393

Epoch: 5| Step: 10
Training loss: 0.2730039838467029
Validation loss: 2.3264898429992993

Epoch: 503| Step: 0
Training loss: 0.3670276943406446
Validation loss: 2.340018302918471

Epoch: 5| Step: 1
Training loss: 0.41695119759062504
Validation loss: 2.2648658541418367

Epoch: 5| Step: 2
Training loss: 0.22519119205989735
Validation loss: 2.252947098657573

Epoch: 5| Step: 3
Training loss: 0.336497848609435
Validation loss: 2.257369395264536

Epoch: 5| Step: 4
Training loss: 0.25373235763329466
Validation loss: 2.2507279015071253

Epoch: 5| Step: 5
Training loss: 0.281582820849156
Validation loss: 2.241934323924719

Epoch: 5| Step: 6
Training loss: 0.5208440557011937
Validation loss: 2.268532279099837

Epoch: 5| Step: 7
Training loss: 0.20975607702877194
Validation loss: 2.2968641120005775

Epoch: 5| Step: 8
Training loss: 0.383941736502532
Validation loss: 2.2783403269270517

Epoch: 5| Step: 9
Training loss: 0.3958696005753836
Validation loss: 2.3079694519386464

Epoch: 5| Step: 10
Training loss: 0.20102820775502173
Validation loss: 2.3451749302531635

Epoch: 504| Step: 0
Training loss: 0.446067554753641
Validation loss: 2.3315011124756215

Epoch: 5| Step: 1
Training loss: 0.15784907460110614
Validation loss: 2.3446698867228077

Epoch: 5| Step: 2
Training loss: 0.27626912024943745
Validation loss: 2.33525819277997

Epoch: 5| Step: 3
Training loss: 0.30149870924175165
Validation loss: 2.2651956804218685

Epoch: 5| Step: 4
Training loss: 0.4408767528850599
Validation loss: 2.2708090646994936

Epoch: 5| Step: 5
Training loss: 0.3155257843366298
Validation loss: 2.28460381534109

Epoch: 5| Step: 6
Training loss: 0.3346580270137088
Validation loss: 2.236855542171359

Epoch: 5| Step: 7
Training loss: 0.2695763315286965
Validation loss: 2.197131583333066

Epoch: 5| Step: 8
Training loss: 0.3928308005914191
Validation loss: 2.221313203435081

Epoch: 5| Step: 9
Training loss: 0.3214340114890035
Validation loss: 2.236842777829812

Epoch: 5| Step: 10
Training loss: 0.4512852117690654
Validation loss: 2.2711417116833723

Epoch: 505| Step: 0
Training loss: 0.3016060259147482
Validation loss: 2.2970550156278797

Epoch: 5| Step: 1
Training loss: 0.41348624166296427
Validation loss: 2.3054659986314667

Epoch: 5| Step: 2
Training loss: 0.2824743958069457
Validation loss: 2.303319622917478

Epoch: 5| Step: 3
Training loss: 0.42515246307245474
Validation loss: 2.3094461245616387

Epoch: 5| Step: 4
Training loss: 0.4302773675033477
Validation loss: 2.2684399795618693

Epoch: 5| Step: 5
Training loss: 0.32739178161751775
Validation loss: 2.3085485620210773

Epoch: 5| Step: 6
Training loss: 0.31259150357494137
Validation loss: 2.2589552035343443

Epoch: 5| Step: 7
Training loss: 0.2488025583280379
Validation loss: 2.224026615087589

Epoch: 5| Step: 8
Training loss: 0.36879869802223436
Validation loss: 2.2422945244936456

Epoch: 5| Step: 9
Training loss: 0.4536845271371402
Validation loss: 2.243858615342822

Epoch: 5| Step: 10
Training loss: 0.15342521723203056
Validation loss: 2.2600683544354903

Epoch: 506| Step: 0
Training loss: 0.19542421007305383
Validation loss: 2.3290569903529956

Epoch: 5| Step: 1
Training loss: 0.49134078689008776
Validation loss: 2.3170014370219194

Epoch: 5| Step: 2
Training loss: 0.31907231126172636
Validation loss: 2.362783033886836

Epoch: 5| Step: 3
Training loss: 0.35322556793725574
Validation loss: 2.3529230559723966

Epoch: 5| Step: 4
Training loss: 0.4769720912602128
Validation loss: 2.3750692377970473

Epoch: 5| Step: 5
Training loss: 0.3021189679580187
Validation loss: 2.3576878969526076

Epoch: 5| Step: 6
Training loss: 0.1552781038362863
Validation loss: 2.3145032662735305

Epoch: 5| Step: 7
Training loss: 0.2933053689508834
Validation loss: 2.3557987927779256

Epoch: 5| Step: 8
Training loss: 0.3039559483036929
Validation loss: 2.3248139747493624

Epoch: 5| Step: 9
Training loss: 0.4035752162894252
Validation loss: 2.313438732732896

Epoch: 5| Step: 10
Training loss: 0.14446438711940177
Validation loss: 2.2953536594373767

Epoch: 507| Step: 0
Training loss: 0.33829251682468947
Validation loss: 2.2965758642792324

Epoch: 5| Step: 1
Training loss: 0.3713180867769925
Validation loss: 2.3270627648924314

Epoch: 5| Step: 2
Training loss: 0.26455524957600135
Validation loss: 2.3071637854408555

Epoch: 5| Step: 3
Training loss: 0.35822684938495297
Validation loss: 2.326373799184847

Epoch: 5| Step: 4
Training loss: 0.20295750608127477
Validation loss: 2.3309905058226446

Epoch: 5| Step: 5
Training loss: 0.18575438891587115
Validation loss: 2.3045986752837204

Epoch: 5| Step: 6
Training loss: 0.29313016895055727
Validation loss: 2.336109311586295

Epoch: 5| Step: 7
Training loss: 0.35323299258893853
Validation loss: 2.3391587065711246

Epoch: 5| Step: 8
Training loss: 0.27299817077928656
Validation loss: 2.332545817403216

Epoch: 5| Step: 9
Training loss: 0.5257435573993966
Validation loss: 2.316857914707835

Epoch: 5| Step: 10
Training loss: 0.2358531750688301
Validation loss: 2.342238601604001

Epoch: 508| Step: 0
Training loss: 0.32710780560408764
Validation loss: 2.2819480541591166

Epoch: 5| Step: 1
Training loss: 0.4203441891547758
Validation loss: 2.302656884481128

Epoch: 5| Step: 2
Training loss: 0.31994172478323424
Validation loss: 2.2985206631399033

Epoch: 5| Step: 3
Training loss: 0.32653572438179346
Validation loss: 2.274306965747947

Epoch: 5| Step: 4
Training loss: 0.368784737971232
Validation loss: 2.314450305988753

Epoch: 5| Step: 5
Training loss: 0.20022274852789035
Validation loss: 2.3008346146120795

Epoch: 5| Step: 6
Training loss: 0.2065503635390367
Validation loss: 2.2925546616748456

Epoch: 5| Step: 7
Training loss: 0.3371400821354527
Validation loss: 2.2877879889822847

Epoch: 5| Step: 8
Training loss: 0.2631097948433567
Validation loss: 2.3128862532332177

Epoch: 5| Step: 9
Training loss: 0.2903429872952179
Validation loss: 2.333349947130442

Epoch: 5| Step: 10
Training loss: 0.431226609466449
Validation loss: 2.345600516064046

Epoch: 509| Step: 0
Training loss: 0.11854733816679583
Validation loss: 2.319915974044452

Epoch: 5| Step: 1
Training loss: 0.3673893799668836
Validation loss: 2.286228686873487

Epoch: 5| Step: 2
Training loss: 0.39593800825464254
Validation loss: 2.293213091152836

Epoch: 5| Step: 3
Training loss: 0.33362383650958816
Validation loss: 2.3199754198531055

Epoch: 5| Step: 4
Training loss: 0.24708313588273348
Validation loss: 2.3173446792147687

Epoch: 5| Step: 5
Training loss: 0.32553222890616795
Validation loss: 2.288861358943086

Epoch: 5| Step: 6
Training loss: 0.36925650094881973
Validation loss: 2.2731264087104077

Epoch: 5| Step: 7
Training loss: 0.24619699008031032
Validation loss: 2.2791640313288055

Epoch: 5| Step: 8
Training loss: 0.30342878869356554
Validation loss: 2.2693542893813685

Epoch: 5| Step: 9
Training loss: 0.3904566592832366
Validation loss: 2.270283207258609

Epoch: 5| Step: 10
Training loss: 0.3223461166198805
Validation loss: 2.3086890491830507

Epoch: 510| Step: 0
Training loss: 0.3508981998276758
Validation loss: 2.2877676896554386

Epoch: 5| Step: 1
Training loss: 0.09116308071802012
Validation loss: 2.2808955972652503

Epoch: 5| Step: 2
Training loss: 0.3030781055829405
Validation loss: 2.290281773008242

Epoch: 5| Step: 3
Training loss: 0.38828530568512687
Validation loss: 2.283202913908636

Epoch: 5| Step: 4
Training loss: 0.26454809616263947
Validation loss: 2.2941968231110206

Epoch: 5| Step: 5
Training loss: 0.3387843643684335
Validation loss: 2.271796677421319

Epoch: 5| Step: 6
Training loss: 0.2412608014045721
Validation loss: 2.27793111638505

Epoch: 5| Step: 7
Training loss: 0.2396551919372338
Validation loss: 2.2950847653625726

Epoch: 5| Step: 8
Training loss: 0.42862983927160087
Validation loss: 2.3111019592377406

Epoch: 5| Step: 9
Training loss: 0.195348602772889
Validation loss: 2.2885789521129007

Epoch: 5| Step: 10
Training loss: 0.43634379400602635
Validation loss: 2.2862196107261132

Epoch: 511| Step: 0
Training loss: 0.295389486803527
Validation loss: 2.3062849473288236

Epoch: 5| Step: 1
Training loss: 0.3828788232765017
Validation loss: 2.2502468516640213

Epoch: 5| Step: 2
Training loss: 0.1956728376909977
Validation loss: 2.2616417114551144

Epoch: 5| Step: 3
Training loss: 0.37285577163198813
Validation loss: 2.2687508738806565

Epoch: 5| Step: 4
Training loss: 0.28798774726950116
Validation loss: 2.2424622174074846

Epoch: 5| Step: 5
Training loss: 0.22994325826785744
Validation loss: 2.2524087083585616

Epoch: 5| Step: 6
Training loss: 0.1998229681249369
Validation loss: 2.2623554336518357

Epoch: 5| Step: 7
Training loss: 0.46906066772184396
Validation loss: 2.2823085242328185

Epoch: 5| Step: 8
Training loss: 0.38284270498263756
Validation loss: 2.292679075494117

Epoch: 5| Step: 9
Training loss: 0.33406699424696634
Validation loss: 2.294563902629921

Epoch: 5| Step: 10
Training loss: 0.25620379089447604
Validation loss: 2.3222894876325375

Epoch: 512| Step: 0
Training loss: 0.1899075612802385
Validation loss: 2.256410574190746

Epoch: 5| Step: 1
Training loss: 0.3621628887382061
Validation loss: 2.2750671452535993

Epoch: 5| Step: 2
Training loss: 0.15997904766999185
Validation loss: 2.290853840231713

Epoch: 5| Step: 3
Training loss: 0.3064866377887728
Validation loss: 2.2996504860366884

Epoch: 5| Step: 4
Training loss: 0.25807573866752787
Validation loss: 2.3208379226892224

Epoch: 5| Step: 5
Training loss: 0.3587345968654759
Validation loss: 2.2857484251984435

Epoch: 5| Step: 6
Training loss: 0.4010466992281282
Validation loss: 2.2801561664868073

Epoch: 5| Step: 7
Training loss: 0.22751790877477684
Validation loss: 2.2895572414272105

Epoch: 5| Step: 8
Training loss: 0.28249175076551275
Validation loss: 2.2914062807000555

Epoch: 5| Step: 9
Training loss: 0.35765143354980006
Validation loss: 2.3099108482762842

Epoch: 5| Step: 10
Training loss: 0.33960363521424747
Validation loss: 2.295567164518776

Epoch: 513| Step: 0
Training loss: 0.3731151338611531
Validation loss: 2.2962826323588765

Epoch: 5| Step: 1
Training loss: 0.2538954659152537
Validation loss: 2.2968134757072503

Epoch: 5| Step: 2
Training loss: 0.32859403148571953
Validation loss: 2.3104471985714294

Epoch: 5| Step: 3
Training loss: 0.4660518878343987
Validation loss: 2.264849810290496

Epoch: 5| Step: 4
Training loss: 0.2805207387614997
Validation loss: 2.291256036820456

Epoch: 5| Step: 5
Training loss: 0.3453718095653459
Validation loss: 2.284030647393967

Epoch: 5| Step: 6
Training loss: 0.2697078568520991
Validation loss: 2.254526466388996

Epoch: 5| Step: 7
Training loss: 0.19521770084002088
Validation loss: 2.2840008480831258

Epoch: 5| Step: 8
Training loss: 0.24745894012006378
Validation loss: 2.2954854014565984

Epoch: 5| Step: 9
Training loss: 0.29623331187924823
Validation loss: 2.249266923186375

Epoch: 5| Step: 10
Training loss: 0.1668763344422037
Validation loss: 2.2901682327958306

Epoch: 514| Step: 0
Training loss: 0.3231448116168699
Validation loss: 2.2637087708807737

Epoch: 5| Step: 1
Training loss: 0.39549370257793104
Validation loss: 2.27676365807979

Epoch: 5| Step: 2
Training loss: 0.29705842525417153
Validation loss: 2.29295415109011

Epoch: 5| Step: 3
Training loss: 0.13211771204994696
Validation loss: 2.2590369252544007

Epoch: 5| Step: 4
Training loss: 0.4858107975083749
Validation loss: 2.2552657270816883

Epoch: 5| Step: 5
Training loss: 0.30616132367119575
Validation loss: 2.2660095352446348

Epoch: 5| Step: 6
Training loss: 0.40694796685801693
Validation loss: 2.3065913847915502

Epoch: 5| Step: 7
Training loss: 0.2403957398756565
Validation loss: 2.2672374278933396

Epoch: 5| Step: 8
Training loss: 0.19956902956592218
Validation loss: 2.253277887364974

Epoch: 5| Step: 9
Training loss: 0.15035907612612032
Validation loss: 2.258483284921091

Epoch: 5| Step: 10
Training loss: 0.22941763458251
Validation loss: 2.286969361660316

Epoch: 515| Step: 0
Training loss: 0.16656830177258272
Validation loss: 2.284424547892818

Epoch: 5| Step: 1
Training loss: 0.3095426095787356
Validation loss: 2.21652491751078

Epoch: 5| Step: 2
Training loss: 0.3536814516733048
Validation loss: 2.241763646228782

Epoch: 5| Step: 3
Training loss: 0.3173867562855935
Validation loss: 2.225096183805046

Epoch: 5| Step: 4
Training loss: 0.2866527533389142
Validation loss: 2.249869505198361

Epoch: 5| Step: 5
Training loss: 0.3686220876644005
Validation loss: 2.2324245541396737

Epoch: 5| Step: 6
Training loss: 0.29655934166306774
Validation loss: 2.2413243029995455

Epoch: 5| Step: 7
Training loss: 0.18337719909087855
Validation loss: 2.279078855842186

Epoch: 5| Step: 8
Training loss: 0.29070257464148924
Validation loss: 2.2808067125955875

Epoch: 5| Step: 9
Training loss: 0.3288258266210045
Validation loss: 2.273362170638472

Epoch: 5| Step: 10
Training loss: 0.29640005417915316
Validation loss: 2.267158523109457

Epoch: 516| Step: 0
Training loss: 0.3410545790054661
Validation loss: 2.2451089317367923

Epoch: 5| Step: 1
Training loss: 0.21339027147556397
Validation loss: 2.2967970907907826

Epoch: 5| Step: 2
Training loss: 0.32909226899651006
Validation loss: 2.2606288902341802

Epoch: 5| Step: 3
Training loss: 0.19417343821778474
Validation loss: 2.27060879849165

Epoch: 5| Step: 4
Training loss: 0.37047111076075817
Validation loss: 2.3035932570816064

Epoch: 5| Step: 5
Training loss: 0.1607225049136705
Validation loss: 2.2608743357577294

Epoch: 5| Step: 6
Training loss: 0.3389814112864058
Validation loss: 2.28822151674436

Epoch: 5| Step: 7
Training loss: 0.18982500760844445
Validation loss: 2.267632824384991

Epoch: 5| Step: 8
Training loss: 0.31595636102086877
Validation loss: 2.2604930799178424

Epoch: 5| Step: 9
Training loss: 0.4140763550365672
Validation loss: 2.276828527262027

Epoch: 5| Step: 10
Training loss: 0.26243361303453944
Validation loss: 2.281036699622321

Epoch: 517| Step: 0
Training loss: 0.21523046368819942
Validation loss: 2.276165280489113

Epoch: 5| Step: 1
Training loss: 0.18520810169796212
Validation loss: 2.2888335602373813

Epoch: 5| Step: 2
Training loss: 0.4189956208013874
Validation loss: 2.296929556415156

Epoch: 5| Step: 3
Training loss: 0.4464488338231789
Validation loss: 2.3341857529459933

Epoch: 5| Step: 4
Training loss: 0.14958581215983754
Validation loss: 2.3146744039010296

Epoch: 5| Step: 5
Training loss: 0.2453699518462743
Validation loss: 2.306519169993733

Epoch: 5| Step: 6
Training loss: 0.2355065290650503
Validation loss: 2.3311638334258586

Epoch: 5| Step: 7
Training loss: 0.21851833030872703
Validation loss: 2.3500413369125925

Epoch: 5| Step: 8
Training loss: 0.38526742425561794
Validation loss: 2.3326950932637103

Epoch: 5| Step: 9
Training loss: 0.42985059937234205
Validation loss: 2.3177072878746854

Epoch: 5| Step: 10
Training loss: 0.10516599186328382
Validation loss: 2.2867615765647784

Epoch: 518| Step: 0
Training loss: 0.23540611742796533
Validation loss: 2.2916286573492792

Epoch: 5| Step: 1
Training loss: 0.27682326733389623
Validation loss: 2.2753468124394547

Epoch: 5| Step: 2
Training loss: 0.29544750639559897
Validation loss: 2.30099398574164

Epoch: 5| Step: 3
Training loss: 0.3318862598470299
Validation loss: 2.30820436943326

Epoch: 5| Step: 4
Training loss: 0.39658895532067656
Validation loss: 2.283589661182654

Epoch: 5| Step: 5
Training loss: 0.21034869384226354
Validation loss: 2.2839783285750106

Epoch: 5| Step: 6
Training loss: 0.33336562010246035
Validation loss: 2.304227250411672

Epoch: 5| Step: 7
Training loss: 0.2797977517906132
Validation loss: 2.28849374896256

Epoch: 5| Step: 8
Training loss: 0.14174873990511358
Validation loss: 2.2852610905229107

Epoch: 5| Step: 9
Training loss: 0.4164890586290568
Validation loss: 2.2902405316442787

Epoch: 5| Step: 10
Training loss: 0.2264542567717625
Validation loss: 2.2955076360890603

Epoch: 519| Step: 0
Training loss: 0.20923321606264733
Validation loss: 2.2740620694401183

Epoch: 5| Step: 1
Training loss: 0.20985755149293897
Validation loss: 2.2780181933549835

Epoch: 5| Step: 2
Training loss: 0.34247064938050276
Validation loss: 2.2623271324731626

Epoch: 5| Step: 3
Training loss: 0.3316839421248401
Validation loss: 2.272292777252423

Epoch: 5| Step: 4
Training loss: 0.4670982983761326
Validation loss: 2.2646173977037227

Epoch: 5| Step: 5
Training loss: 0.0867693424850483
Validation loss: 2.2409856827614476

Epoch: 5| Step: 6
Training loss: 0.33613149453170194
Validation loss: 2.2876383165752423

Epoch: 5| Step: 7
Training loss: 0.23691986812764754
Validation loss: 2.249731329232661

Epoch: 5| Step: 8
Training loss: 0.28843521669006883
Validation loss: 2.277065185976538

Epoch: 5| Step: 9
Training loss: 0.2824311224556538
Validation loss: 2.2435414937923137

Epoch: 5| Step: 10
Training loss: 0.35294770625971816
Validation loss: 2.284845103777002

Epoch: 520| Step: 0
Training loss: 0.4292215074604059
Validation loss: 2.282318831302658

Epoch: 5| Step: 1
Training loss: 0.3625770634917371
Validation loss: 2.306652940583857

Epoch: 5| Step: 2
Training loss: 0.16765919149507894
Validation loss: 2.280283022153768

Epoch: 5| Step: 3
Training loss: 0.2697679475473867
Validation loss: 2.2606779141953783

Epoch: 5| Step: 4
Training loss: 0.17664343468524862
Validation loss: 2.2574021712087764

Epoch: 5| Step: 5
Training loss: 0.22088525228502495
Validation loss: 2.2647659002509637

Epoch: 5| Step: 6
Training loss: 0.34879196765607023
Validation loss: 2.281387371040791

Epoch: 5| Step: 7
Training loss: 0.3388890855733026
Validation loss: 2.307989485835449

Epoch: 5| Step: 8
Training loss: 0.25813680538678657
Validation loss: 2.270538441511743

Epoch: 5| Step: 9
Training loss: 0.3853369020282482
Validation loss: 2.2717911524551377

Epoch: 5| Step: 10
Training loss: 0.1394463390547862
Validation loss: 2.2937235616965483

Epoch: 521| Step: 0
Training loss: 0.29216035574014076
Validation loss: 2.3058513980420847

Epoch: 5| Step: 1
Training loss: 0.48440819288164016
Validation loss: 2.2485849677624596

Epoch: 5| Step: 2
Training loss: 0.30802750848024735
Validation loss: 2.2467398284885722

Epoch: 5| Step: 3
Training loss: 0.2831136364793214
Validation loss: 2.278505139110622

Epoch: 5| Step: 4
Training loss: 0.1801958563974418
Validation loss: 2.268896812742722

Epoch: 5| Step: 5
Training loss: 0.2458686025758847
Validation loss: 2.2848866977812565

Epoch: 5| Step: 6
Training loss: 0.24863769724228538
Validation loss: 2.2981989163726966

Epoch: 5| Step: 7
Training loss: 0.29065310537148314
Validation loss: 2.285010063853087

Epoch: 5| Step: 8
Training loss: 0.2630510297129362
Validation loss: 2.3129715797566552

Epoch: 5| Step: 9
Training loss: 0.2862603355815615
Validation loss: 2.312820669532541

Epoch: 5| Step: 10
Training loss: 0.4030514021528827
Validation loss: 2.3162209734608084

Epoch: 522| Step: 0
Training loss: 0.21650672088293896
Validation loss: 2.2915206657580223

Epoch: 5| Step: 1
Training loss: 0.35474622047109955
Validation loss: 2.2975442243608515

Epoch: 5| Step: 2
Training loss: 0.15326272283803422
Validation loss: 2.297070554414543

Epoch: 5| Step: 3
Training loss: 0.29074834544169437
Validation loss: 2.248295426011257

Epoch: 5| Step: 4
Training loss: 0.3365472095526271
Validation loss: 2.252781916532277

Epoch: 5| Step: 5
Training loss: 0.30901645730151445
Validation loss: 2.2951372177617437

Epoch: 5| Step: 6
Training loss: 0.26422640098534583
Validation loss: 2.235658761741332

Epoch: 5| Step: 7
Training loss: 0.40913261561614905
Validation loss: 2.2963183154425684

Epoch: 5| Step: 8
Training loss: 0.2727415629051369
Validation loss: 2.2733711081030696

Epoch: 5| Step: 9
Training loss: 0.24475345753009237
Validation loss: 2.2252138300074007

Epoch: 5| Step: 10
Training loss: 0.3658999737686644
Validation loss: 2.2428404263383808

Epoch: 523| Step: 0
Training loss: 0.3512023564604493
Validation loss: 2.234768939541739

Epoch: 5| Step: 1
Training loss: 0.2731930048363288
Validation loss: 2.254301425984122

Epoch: 5| Step: 2
Training loss: 0.152307249244813
Validation loss: 2.256763097283772

Epoch: 5| Step: 3
Training loss: 0.1251360480711951
Validation loss: 2.292200030535089

Epoch: 5| Step: 4
Training loss: 0.5175165679601482
Validation loss: 2.3230905473736163

Epoch: 5| Step: 5
Training loss: 0.4007252853016519
Validation loss: 2.3404411306457638

Epoch: 5| Step: 6
Training loss: 0.2011210090254277
Validation loss: 2.295258499064597

Epoch: 5| Step: 7
Training loss: 0.2047316030497936
Validation loss: 2.2921329188056254

Epoch: 5| Step: 8
Training loss: 0.32600230531886654
Validation loss: 2.2975799257883183

Epoch: 5| Step: 9
Training loss: 0.18450414894641595
Validation loss: 2.277099340722377

Epoch: 5| Step: 10
Training loss: 0.2249527421304039
Validation loss: 2.2765529406837666

Epoch: 524| Step: 0
Training loss: 0.12282365275719885
Validation loss: 2.2453742908001475

Epoch: 5| Step: 1
Training loss: 0.2261321897723832
Validation loss: 2.278922174576196

Epoch: 5| Step: 2
Training loss: 0.24984797683489848
Validation loss: 2.2807908359543054

Epoch: 5| Step: 3
Training loss: 0.3955305304890318
Validation loss: 2.2764261978316664

Epoch: 5| Step: 4
Training loss: 0.3389724985553537
Validation loss: 2.2687766722824314

Epoch: 5| Step: 5
Training loss: 0.15489775115388382
Validation loss: 2.2888443766722455

Epoch: 5| Step: 6
Training loss: 0.2550094114698552
Validation loss: 2.2707273263414365

Epoch: 5| Step: 7
Training loss: 0.32425612498493267
Validation loss: 2.265085969083144

Epoch: 5| Step: 8
Training loss: 0.33745625309519445
Validation loss: 2.2833919151124493

Epoch: 5| Step: 9
Training loss: 0.2216898457892659
Validation loss: 2.2920260924070135

Epoch: 5| Step: 10
Training loss: 0.4113604896035632
Validation loss: 2.304735477505002

Epoch: 525| Step: 0
Training loss: 0.16073192086232382
Validation loss: 2.3024713767063614

Epoch: 5| Step: 1
Training loss: 0.1917290592919379
Validation loss: 2.302974421188586

Epoch: 5| Step: 2
Training loss: 0.36399713346903645
Validation loss: 2.3379230676407157

Epoch: 5| Step: 3
Training loss: 0.18246481143054194
Validation loss: 2.3558000257372465

Epoch: 5| Step: 4
Training loss: 0.24538467068448203
Validation loss: 2.2866911851661533

Epoch: 5| Step: 5
Training loss: 0.35573479893229726
Validation loss: 2.292951073651522

Epoch: 5| Step: 6
Training loss: 0.35732618207827405
Validation loss: 2.2699555364427053

Epoch: 5| Step: 7
Training loss: 0.2765652112235242
Validation loss: 2.2421715595653025

Epoch: 5| Step: 8
Training loss: 0.27815939283422236
Validation loss: 2.2527899222694026

Epoch: 5| Step: 9
Training loss: 0.29736816702902047
Validation loss: 2.235871242923883

Epoch: 5| Step: 10
Training loss: 0.4323860911766181
Validation loss: 2.260342329411612

Epoch: 526| Step: 0
Training loss: 0.33031231850408876
Validation loss: 2.2207582851671313

Epoch: 5| Step: 1
Training loss: 0.32637517840535063
Validation loss: 2.2359231653397007

Epoch: 5| Step: 2
Training loss: 0.2678450485178433
Validation loss: 2.264976981349236

Epoch: 5| Step: 3
Training loss: 0.4074986050002671
Validation loss: 2.246333881826386

Epoch: 5| Step: 4
Training loss: 0.24736106109526415
Validation loss: 2.257888201672782

Epoch: 5| Step: 5
Training loss: 0.2674002926604111
Validation loss: 2.2722947527605295

Epoch: 5| Step: 6
Training loss: 0.35447831560216375
Validation loss: 2.3023739038701643

Epoch: 5| Step: 7
Training loss: 0.28920989531528624
Validation loss: 2.245411381160618

Epoch: 5| Step: 8
Training loss: 0.12280073979542044
Validation loss: 2.2410964412183896

Epoch: 5| Step: 9
Training loss: 0.19652555462662266
Validation loss: 2.25859043307826

Epoch: 5| Step: 10
Training loss: 0.25296815557569063
Validation loss: 2.235461695275991

Epoch: 527| Step: 0
Training loss: 0.24233870247085906
Validation loss: 2.251027834123749

Epoch: 5| Step: 1
Training loss: 0.1229612945977061
Validation loss: 2.2460672961403105

Epoch: 5| Step: 2
Training loss: 0.20576246611790291
Validation loss: 2.262635813196814

Epoch: 5| Step: 3
Training loss: 0.28118895821957407
Validation loss: 2.2881970142560846

Epoch: 5| Step: 4
Training loss: 0.26333852818401027
Validation loss: 2.2750372972736193

Epoch: 5| Step: 5
Training loss: 0.2683601229461508
Validation loss: 2.263159756419272

Epoch: 5| Step: 6
Training loss: 0.32233210947132485
Validation loss: 2.247390638316039

Epoch: 5| Step: 7
Training loss: 0.35615577957592187
Validation loss: 2.31586018389132

Epoch: 5| Step: 8
Training loss: 0.4348309196254334
Validation loss: 2.2912806844961846

Epoch: 5| Step: 9
Training loss: 0.2839519991253343
Validation loss: 2.2625601525322274

Epoch: 5| Step: 10
Training loss: 0.1916046671173516
Validation loss: 2.287974621170056

Epoch: 528| Step: 0
Training loss: 0.42987886849049567
Validation loss: 2.342856570357709

Epoch: 5| Step: 1
Training loss: 0.25182498956015836
Validation loss: 2.320992834748586

Epoch: 5| Step: 2
Training loss: 0.09578259243887831
Validation loss: 2.2980842267363926

Epoch: 5| Step: 3
Training loss: 0.28198024203956557
Validation loss: 2.2970520201332554

Epoch: 5| Step: 4
Training loss: 0.21681374836460857
Validation loss: 2.2982003007076415

Epoch: 5| Step: 5
Training loss: 0.18481788984804637
Validation loss: 2.2870036955346666

Epoch: 5| Step: 6
Training loss: 0.28570241749117553
Validation loss: 2.2614730918896466

Epoch: 5| Step: 7
Training loss: 0.33247812156115397
Validation loss: 2.2402331568255853

Epoch: 5| Step: 8
Training loss: 0.2891780776860591
Validation loss: 2.2643426442126198

Epoch: 5| Step: 9
Training loss: 0.27648714245793304
Validation loss: 2.289768611404999

Epoch: 5| Step: 10
Training loss: 0.29751967403128216
Validation loss: 2.290001544679611

Epoch: 529| Step: 0
Training loss: 0.3147772190991337
Validation loss: 2.2497602053556736

Epoch: 5| Step: 1
Training loss: 0.25937178161646623
Validation loss: 2.260993674246484

Epoch: 5| Step: 2
Training loss: 0.14548352698102618
Validation loss: 2.2810808339021573

Epoch: 5| Step: 3
Training loss: 0.14622058003962507
Validation loss: 2.2340122797328097

Epoch: 5| Step: 4
Training loss: 0.3181511718873799
Validation loss: 2.2779060507814566

Epoch: 5| Step: 5
Training loss: 0.2505312579729408
Validation loss: 2.2898374228079157

Epoch: 5| Step: 6
Training loss: 0.14641498829668145
Validation loss: 2.275853396187547

Epoch: 5| Step: 7
Training loss: 0.4753054157709786
Validation loss: 2.2621840721042195

Epoch: 5| Step: 8
Training loss: 0.1954208169037547
Validation loss: 2.2679978547019277

Epoch: 5| Step: 9
Training loss: 0.21802910307594972
Validation loss: 2.275134370512148

Epoch: 5| Step: 10
Training loss: 0.37727634625615875
Validation loss: 2.278170872188516

Epoch: 530| Step: 0
Training loss: 0.3940607797220602
Validation loss: 2.286661839828819

Epoch: 5| Step: 1
Training loss: 0.27595026224330904
Validation loss: 2.288180437115215

Epoch: 5| Step: 2
Training loss: 0.2064607244565467
Validation loss: 2.2737836789513786

Epoch: 5| Step: 3
Training loss: 0.33631952875119514
Validation loss: 2.27388181193831

Epoch: 5| Step: 4
Training loss: 0.2086231728851462
Validation loss: 2.2722068031907035

Epoch: 5| Step: 5
Training loss: 0.26176899100365125
Validation loss: 2.2571368473437077

Epoch: 5| Step: 6
Training loss: 0.2546015096961283
Validation loss: 2.271211097306414

Epoch: 5| Step: 7
Training loss: 0.23378635236018586
Validation loss: 2.2582612841876246

Epoch: 5| Step: 8
Training loss: 0.173494801635122
Validation loss: 2.23925256902701

Epoch: 5| Step: 9
Training loss: 0.3223256373158981
Validation loss: 2.2428527876347646

Epoch: 5| Step: 10
Training loss: 0.187717827787209
Validation loss: 2.2796562129420876

Epoch: 531| Step: 0
Training loss: 0.27924547856272564
Validation loss: 2.255629960016373

Epoch: 5| Step: 1
Training loss: 0.36129799794561746
Validation loss: 2.2636300491638988

Epoch: 5| Step: 2
Training loss: 0.24310500412083882
Validation loss: 2.2602918149120668

Epoch: 5| Step: 3
Training loss: 0.21924924929228246
Validation loss: 2.254704846599591

Epoch: 5| Step: 4
Training loss: 0.16984726374903597
Validation loss: 2.2605738552334405

Epoch: 5| Step: 5
Training loss: 0.1566024322276277
Validation loss: 2.2896851311563675

Epoch: 5| Step: 6
Training loss: 0.3421435859232552
Validation loss: 2.2917735577337246

Epoch: 5| Step: 7
Training loss: 0.29013594219934574
Validation loss: 2.2751859912752836

Epoch: 5| Step: 8
Training loss: 0.1602242662634576
Validation loss: 2.267119471260247

Epoch: 5| Step: 9
Training loss: 0.35052704382841243
Validation loss: 2.292629212262306

Epoch: 5| Step: 10
Training loss: 0.3208409927225907
Validation loss: 2.2707733345534895

Epoch: 532| Step: 0
Training loss: 0.28989130488587217
Validation loss: 2.2758275980273033

Epoch: 5| Step: 1
Training loss: 0.31884571676555273
Validation loss: 2.290589682107789

Epoch: 5| Step: 2
Training loss: 0.13475811978878513
Validation loss: 2.2951837669251294

Epoch: 5| Step: 3
Training loss: 0.2086467243463768
Validation loss: 2.292829042754803

Epoch: 5| Step: 4
Training loss: 0.3015211838006545
Validation loss: 2.296201400534155

Epoch: 5| Step: 5
Training loss: 0.48999698560137844
Validation loss: 2.297017370213009

Epoch: 5| Step: 6
Training loss: 0.22507369106259137
Validation loss: 2.2949398590060475

Epoch: 5| Step: 7
Training loss: 0.13049996539413242
Validation loss: 2.316346196843213

Epoch: 5| Step: 8
Training loss: 0.18566541398782666
Validation loss: 2.300586018802426

Epoch: 5| Step: 9
Training loss: 0.17345541204283715
Validation loss: 2.327942009843925

Epoch: 5| Step: 10
Training loss: 0.35399984423181374
Validation loss: 2.31795993023271

Epoch: 533| Step: 0
Training loss: 0.39105300343575455
Validation loss: 2.3124972140831144

Epoch: 5| Step: 1
Training loss: 0.2921589403933402
Validation loss: 2.2829329648561587

Epoch: 5| Step: 2
Training loss: 0.3206092227712523
Validation loss: 2.2662114036182954

Epoch: 5| Step: 3
Training loss: 0.21745807753406143
Validation loss: 2.2754910472905445

Epoch: 5| Step: 4
Training loss: 0.36235660890411137
Validation loss: 2.25196030492552

Epoch: 5| Step: 5
Training loss: 0.16299873007714077
Validation loss: 2.2694100089571796

Epoch: 5| Step: 6
Training loss: 0.1630739219031048
Validation loss: 2.270814484804686

Epoch: 5| Step: 7
Training loss: 0.26459985547530335
Validation loss: 2.3008608972885294

Epoch: 5| Step: 8
Training loss: 0.21828062073788226
Validation loss: 2.3034750920849167

Epoch: 5| Step: 9
Training loss: 0.21178439343807226
Validation loss: 2.275198871493985

Epoch: 5| Step: 10
Training loss: 0.1693657346158398
Validation loss: 2.276686210338844

Epoch: 534| Step: 0
Training loss: 0.3073825607463597
Validation loss: 2.2605311634713585

Epoch: 5| Step: 1
Training loss: 0.39924618053818833
Validation loss: 2.2697068041449104

Epoch: 5| Step: 2
Training loss: 0.17907517216897964
Validation loss: 2.254476220427027

Epoch: 5| Step: 3
Training loss: 0.20861921762163568
Validation loss: 2.263128816846797

Epoch: 5| Step: 4
Training loss: 0.3114849533179019
Validation loss: 2.2772264936044806

Epoch: 5| Step: 5
Training loss: 0.3393621101003961
Validation loss: 2.210571820032348

Epoch: 5| Step: 6
Training loss: 0.17069812479268556
Validation loss: 2.2605680261251258

Epoch: 5| Step: 7
Training loss: 0.31501864883305886
Validation loss: 2.2580702519197464

Epoch: 5| Step: 8
Training loss: 0.1619980498762404
Validation loss: 2.2767957444092266

Epoch: 5| Step: 9
Training loss: 0.206155390786946
Validation loss: 2.297967348123798

Epoch: 5| Step: 10
Training loss: 0.1963838376934582
Validation loss: 2.315676603992874

Epoch: 535| Step: 0
Training loss: 0.33038120913940183
Validation loss: 2.273937307269815

Epoch: 5| Step: 1
Training loss: 0.17457112100225755
Validation loss: 2.2960234366475936

Epoch: 5| Step: 2
Training loss: 0.19712463855045056
Validation loss: 2.2593264458294855

Epoch: 5| Step: 3
Training loss: 0.20941030467994678
Validation loss: 2.269359958100749

Epoch: 5| Step: 4
Training loss: 0.1429181290733357
Validation loss: 2.2676118248634314

Epoch: 5| Step: 5
Training loss: 0.29362193724982455
Validation loss: 2.2663348202336633

Epoch: 5| Step: 6
Training loss: 0.40022788113075236
Validation loss: 2.2802053698687046

Epoch: 5| Step: 7
Training loss: 0.24738690293238913
Validation loss: 2.26920549116548

Epoch: 5| Step: 8
Training loss: 0.2604903244118049
Validation loss: 2.2725919208093903

Epoch: 5| Step: 9
Training loss: 0.3297941577734557
Validation loss: 2.2491886209574035

Epoch: 5| Step: 10
Training loss: 0.3128193653889093
Validation loss: 2.2994452114806063

Epoch: 536| Step: 0
Training loss: 0.19928555210058582
Validation loss: 2.2823879591318366

Epoch: 5| Step: 1
Training loss: 0.32480357176221475
Validation loss: 2.2728487591608273

Epoch: 5| Step: 2
Training loss: 0.23619327954188438
Validation loss: 2.2673363976796157

Epoch: 5| Step: 3
Training loss: 0.1448919075059936
Validation loss: 2.254758222154134

Epoch: 5| Step: 4
Training loss: 0.11144123689009568
Validation loss: 2.265240346287381

Epoch: 5| Step: 5
Training loss: 0.2991761443678782
Validation loss: 2.2725105032225796

Epoch: 5| Step: 6
Training loss: 0.16696544343828934
Validation loss: 2.2782382624259605

Epoch: 5| Step: 7
Training loss: 0.26502867687457415
Validation loss: 2.260565617360803

Epoch: 5| Step: 8
Training loss: 0.40813983992487984
Validation loss: 2.201646199266276

Epoch: 5| Step: 9
Training loss: 0.3583203472327483
Validation loss: 2.2475880646749564

Epoch: 5| Step: 10
Training loss: 0.3923694568447866
Validation loss: 2.254028583149168

Epoch: 537| Step: 0
Training loss: 0.27234183548797697
Validation loss: 2.233235789964981

Epoch: 5| Step: 1
Training loss: 0.41462717599214405
Validation loss: 2.241832528834463

Epoch: 5| Step: 2
Training loss: 0.237833321220043
Validation loss: 2.2819880596459394

Epoch: 5| Step: 3
Training loss: 0.17240316345635373
Validation loss: 2.2866173109935644

Epoch: 5| Step: 4
Training loss: 0.2038454246417119
Validation loss: 2.2716050809907338

Epoch: 5| Step: 5
Training loss: 0.24137654198865682
Validation loss: 2.2816089011229224

Epoch: 5| Step: 6
Training loss: 0.32194371184464193
Validation loss: 2.2711912266183822

Epoch: 5| Step: 7
Training loss: 0.3592747672907032
Validation loss: 2.279886124306826

Epoch: 5| Step: 8
Training loss: 0.2490021116811572
Validation loss: 2.281572306507789

Epoch: 5| Step: 9
Training loss: 0.21812131491939366
Validation loss: 2.259590995797532

Epoch: 5| Step: 10
Training loss: 0.13475133986019272
Validation loss: 2.2688265772495515

Epoch: 538| Step: 0
Training loss: 0.2206546595199654
Validation loss: 2.293329939304329

Epoch: 5| Step: 1
Training loss: 0.17477568593607462
Validation loss: 2.2763104984813918

Epoch: 5| Step: 2
Training loss: 0.27112074725806745
Validation loss: 2.311386130591439

Epoch: 5| Step: 3
Training loss: 0.32820979793732397
Validation loss: 2.309200043109139

Epoch: 5| Step: 4
Training loss: 0.2495987324244227
Validation loss: 2.3250232909278985

Epoch: 5| Step: 5
Training loss: 0.32478405031854046
Validation loss: 2.2974360349137197

Epoch: 5| Step: 6
Training loss: 0.28651538049646147
Validation loss: 2.3108273714890952

Epoch: 5| Step: 7
Training loss: 0.2967350403992823
Validation loss: 2.2500471363120775

Epoch: 5| Step: 8
Training loss: 0.31450521144354715
Validation loss: 2.2354289204702447

Epoch: 5| Step: 9
Training loss: 0.11367585660246968
Validation loss: 2.2905952182512452

Epoch: 5| Step: 10
Training loss: 0.29328733288528874
Validation loss: 2.2807439101386717

Epoch: 539| Step: 0
Training loss: 0.2202663065457426
Validation loss: 2.2820072307995716

Epoch: 5| Step: 1
Training loss: 0.30946563732003624
Validation loss: 2.253737971927284

Epoch: 5| Step: 2
Training loss: 0.3468734307296585
Validation loss: 2.274745475678342

Epoch: 5| Step: 3
Training loss: 0.16972708224621946
Validation loss: 2.252019958782205

Epoch: 5| Step: 4
Training loss: 0.33777262440867367
Validation loss: 2.257924827316129

Epoch: 5| Step: 5
Training loss: 0.25082826500479233
Validation loss: 2.2901238644916133

Epoch: 5| Step: 6
Training loss: 0.2050580877778714
Validation loss: 2.3067971750605873

Epoch: 5| Step: 7
Training loss: 0.22583510934534884
Validation loss: 2.2866718907193295

Epoch: 5| Step: 8
Training loss: 0.193568290209365
Validation loss: 2.286426035391096

Epoch: 5| Step: 9
Training loss: 0.22937606146044526
Validation loss: 2.261083568510298

Epoch: 5| Step: 10
Training loss: 0.34051386218764934
Validation loss: 2.283393566372172

Epoch: 540| Step: 0
Training loss: 0.23253932357560683
Validation loss: 2.2528034289702212

Epoch: 5| Step: 1
Training loss: 0.21868096692863023
Validation loss: 2.2551145225493268

Epoch: 5| Step: 2
Training loss: 0.37883565186024476
Validation loss: 2.250884279973551

Epoch: 5| Step: 3
Training loss: 0.27880360988030606
Validation loss: 2.258842545834535

Epoch: 5| Step: 4
Training loss: 0.20445890037300438
Validation loss: 2.275818471387792

Epoch: 5| Step: 5
Training loss: 0.259455230093264
Validation loss: 2.2452775899265323

Epoch: 5| Step: 6
Training loss: 0.29981865368846483
Validation loss: 2.2762980818031258

Epoch: 5| Step: 7
Training loss: 0.3356755810278082
Validation loss: 2.2580097457363846

Epoch: 5| Step: 8
Training loss: 0.43711268787645624
Validation loss: 2.2790950093117273

Epoch: 5| Step: 9
Training loss: 0.36308792056259825
Validation loss: 2.2743836029078226

Epoch: 5| Step: 10
Training loss: 0.3079214982624588
Validation loss: 2.3195819590663733

Epoch: 541| Step: 0
Training loss: 0.37435746777579365
Validation loss: 2.3256622999188385

Epoch: 5| Step: 1
Training loss: 0.40536429983762456
Validation loss: 2.311830927698335

Epoch: 5| Step: 2
Training loss: 0.20876355849565822
Validation loss: 2.2895481381650495

Epoch: 5| Step: 3
Training loss: 0.24238865712363594
Validation loss: 2.238268744910817

Epoch: 5| Step: 4
Training loss: 0.36028717210058114
Validation loss: 2.174736816358594

Epoch: 5| Step: 5
Training loss: 0.4037079322381963
Validation loss: 2.1640255749673276

Epoch: 5| Step: 6
Training loss: 0.358260915705726
Validation loss: 2.1589442359172333

Epoch: 5| Step: 7
Training loss: 0.48586692542885934
Validation loss: 2.2126081343729505

Epoch: 5| Step: 8
Training loss: 0.2400889615618235
Validation loss: 2.265524843100411

Epoch: 5| Step: 9
Training loss: 0.38339488824104184
Validation loss: 2.337444921316987

Epoch: 5| Step: 10
Training loss: 0.30928725770864435
Validation loss: 2.380098612639826

Epoch: 542| Step: 0
Training loss: 0.29595845938784643
Validation loss: 2.3591114144963763

Epoch: 5| Step: 1
Training loss: 0.46565995565196555
Validation loss: 2.338162565185823

Epoch: 5| Step: 2
Training loss: 0.5664124060986846
Validation loss: 2.3481723008761626

Epoch: 5| Step: 3
Training loss: 0.31838620546703866
Validation loss: 2.2794609252257327

Epoch: 5| Step: 4
Training loss: 0.20496446093552798
Validation loss: 2.2717047649950524

Epoch: 5| Step: 5
Training loss: 0.2783450734685311
Validation loss: 2.282259629042967

Epoch: 5| Step: 6
Training loss: 0.4234762181109191
Validation loss: 2.2873781665454995

Epoch: 5| Step: 7
Training loss: 0.4123370007493457
Validation loss: 2.2544687107842987

Epoch: 5| Step: 8
Training loss: 0.41767147223421885
Validation loss: 2.3213312878937047

Epoch: 5| Step: 9
Training loss: 0.2117097634523265
Validation loss: 2.3002393151733975

Epoch: 5| Step: 10
Training loss: 0.2820578866357768
Validation loss: 2.4039951827359287

Epoch: 543| Step: 0
Training loss: 0.33799092783052925
Validation loss: 2.3998506241782107

Epoch: 5| Step: 1
Training loss: 0.41329153729563123
Validation loss: 2.3648237303423834

Epoch: 5| Step: 2
Training loss: 0.3735238665700978
Validation loss: 2.363666582402002

Epoch: 5| Step: 3
Training loss: 0.3446216477634742
Validation loss: 2.2850975767417174

Epoch: 5| Step: 4
Training loss: 0.2522321235666376
Validation loss: 2.3173508212937066

Epoch: 5| Step: 5
Training loss: 0.3336921886136845
Validation loss: 2.28781006142434

Epoch: 5| Step: 6
Training loss: 0.32915957021709186
Validation loss: 2.2803182627869343

Epoch: 5| Step: 7
Training loss: 0.3367902002843437
Validation loss: 2.3228413563064314

Epoch: 5| Step: 8
Training loss: 0.3853242565752992
Validation loss: 2.2609051835789185

Epoch: 5| Step: 9
Training loss: 0.23659019284187405
Validation loss: 2.2761991604101772

Epoch: 5| Step: 10
Training loss: 0.2833118756083507
Validation loss: 2.2545677362179437

Epoch: 544| Step: 0
Training loss: 0.2104777341141504
Validation loss: 2.2536409058748497

Epoch: 5| Step: 1
Training loss: 0.24602740013989596
Validation loss: 2.2296633216484105

Epoch: 5| Step: 2
Training loss: 0.27503347572403036
Validation loss: 2.2283474192369432

Epoch: 5| Step: 3
Training loss: 0.225448153474352
Validation loss: 2.224252044571347

Epoch: 5| Step: 4
Training loss: 0.14662295462140265
Validation loss: 2.210334640273296

Epoch: 5| Step: 5
Training loss: 0.40733612196803315
Validation loss: 2.284468817035348

Epoch: 5| Step: 6
Training loss: 0.34396612352429135
Validation loss: 2.220080366066656

Epoch: 5| Step: 7
Training loss: 0.3576788890201385
Validation loss: 2.230545088901209

Epoch: 5| Step: 8
Training loss: 0.45268038607986305
Validation loss: 2.2857662699641508

Epoch: 5| Step: 9
Training loss: 0.19445323758641223
Validation loss: 2.2953271053992146

Epoch: 5| Step: 10
Training loss: 0.2620517263674775
Validation loss: 2.279096470491759

Epoch: 545| Step: 0
Training loss: 0.3429271429453937
Validation loss: 2.2960934051731248

Epoch: 5| Step: 1
Training loss: 0.24414060211181535
Validation loss: 2.2862032233334304

Epoch: 5| Step: 2
Training loss: 0.18117633054122848
Validation loss: 2.2800948209871814

Epoch: 5| Step: 3
Training loss: 0.20964029357797526
Validation loss: 2.24873407475915

Epoch: 5| Step: 4
Training loss: 0.20611634620072897
Validation loss: 2.2529703698404133

Epoch: 5| Step: 5
Training loss: 0.41711047100774107
Validation loss: 2.253712981349006

Epoch: 5| Step: 6
Training loss: 0.40188166554975996
Validation loss: 2.2596330436029404

Epoch: 5| Step: 7
Training loss: 0.2512671276678833
Validation loss: 2.2716118630566524

Epoch: 5| Step: 8
Training loss: 0.2603917141721913
Validation loss: 2.3208531995135764

Epoch: 5| Step: 9
Training loss: 0.31747071442745883
Validation loss: 2.3358089241389477

Epoch: 5| Step: 10
Training loss: 0.34585897521053394
Validation loss: 2.3690091865715446

Epoch: 546| Step: 0
Training loss: 0.38402059234847225
Validation loss: 2.3830471537206543

Epoch: 5| Step: 1
Training loss: 0.25396437346483763
Validation loss: 2.37409977024088

Epoch: 5| Step: 2
Training loss: 0.35949468692837905
Validation loss: 2.3161428195534897

Epoch: 5| Step: 3
Training loss: 0.27028954303697744
Validation loss: 2.302029416439331

Epoch: 5| Step: 4
Training loss: 0.30370953918331384
Validation loss: 2.2684615424117958

Epoch: 5| Step: 5
Training loss: 0.2521316575924092
Validation loss: 2.2685760255065692

Epoch: 5| Step: 6
Training loss: 0.2936415258964262
Validation loss: 2.268391474831843

Epoch: 5| Step: 7
Training loss: 0.3507875165825619
Validation loss: 2.3100025167950022

Epoch: 5| Step: 8
Training loss: 0.21685640703362666
Validation loss: 2.2969499265643565

Epoch: 5| Step: 9
Training loss: 0.1951467478281276
Validation loss: 2.2989281089401667

Epoch: 5| Step: 10
Training loss: 0.2572613228473818
Validation loss: 2.346851262121552

Epoch: 547| Step: 0
Training loss: 0.2734947553363663
Validation loss: 2.3190799468324546

Epoch: 5| Step: 1
Training loss: 0.2623302802285279
Validation loss: 2.332727072954377

Epoch: 5| Step: 2
Training loss: 0.36251306839110436
Validation loss: 2.350775919131843

Epoch: 5| Step: 3
Training loss: 0.3945139324051151
Validation loss: 2.360380295804516

Epoch: 5| Step: 4
Training loss: 0.25066136260478694
Validation loss: 2.296147138320618

Epoch: 5| Step: 5
Training loss: 0.19188364012583864
Validation loss: 2.311531253101055

Epoch: 5| Step: 6
Training loss: 0.28251346933696403
Validation loss: 2.2976048771817217

Epoch: 5| Step: 7
Training loss: 0.30912959981736143
Validation loss: 2.3060764205069817

Epoch: 5| Step: 8
Training loss: 0.3092777301579944
Validation loss: 2.2906275708187858

Epoch: 5| Step: 9
Training loss: 0.3862163671337765
Validation loss: 2.324136730803679

Epoch: 5| Step: 10
Training loss: 0.39326265541952177
Validation loss: 2.334050361344797

Epoch: 548| Step: 0
Training loss: 0.21135419730582156
Validation loss: 2.3223483726190075

Epoch: 5| Step: 1
Training loss: 0.32184760986378164
Validation loss: 2.2654944009165834

Epoch: 5| Step: 2
Training loss: 0.3037318992127252
Validation loss: 2.339564700242336

Epoch: 5| Step: 3
Training loss: 0.38483157294674625
Validation loss: 2.295049675791173

Epoch: 5| Step: 4
Training loss: 0.4216985863483029
Validation loss: 2.3190188320025853

Epoch: 5| Step: 5
Training loss: 0.3675180327279549
Validation loss: 2.3213967945980527

Epoch: 5| Step: 6
Training loss: 0.24605184531307667
Validation loss: 2.264419380856176

Epoch: 5| Step: 7
Training loss: 0.1991790002548053
Validation loss: 2.2986215002709978

Epoch: 5| Step: 8
Training loss: 0.34641108248397934
Validation loss: 2.309728348867336

Epoch: 5| Step: 9
Training loss: 0.3171640082055126
Validation loss: 2.31836282509187

Epoch: 5| Step: 10
Training loss: 0.16655781787639803
Validation loss: 2.2553448788597183

Epoch: 549| Step: 0
Training loss: 0.26145651476000886
Validation loss: 2.315750146189092

Epoch: 5| Step: 1
Training loss: 0.21910022900454917
Validation loss: 2.325411440553248

Epoch: 5| Step: 2
Training loss: 0.1903470569236279
Validation loss: 2.3173610056920344

Epoch: 5| Step: 3
Training loss: 0.26931000350234136
Validation loss: 2.340612734317206

Epoch: 5| Step: 4
Training loss: 0.2750765314681687
Validation loss: 2.357719738803056

Epoch: 5| Step: 5
Training loss: 0.2861217848179243
Validation loss: 2.3721355657787413

Epoch: 5| Step: 6
Training loss: 0.29448868977779036
Validation loss: 2.33377836600884

Epoch: 5| Step: 7
Training loss: 0.3229276734701485
Validation loss: 2.286199658549753

Epoch: 5| Step: 8
Training loss: 0.30528179311025533
Validation loss: 2.3055532790827304

Epoch: 5| Step: 9
Training loss: 0.3454917433879715
Validation loss: 2.302210896185899

Epoch: 5| Step: 10
Training loss: 0.24038608536821016
Validation loss: 2.233978832418387

Epoch: 550| Step: 0
Training loss: 0.3108825668615062
Validation loss: 2.2370887865197675

Epoch: 5| Step: 1
Training loss: 0.30703900208526846
Validation loss: 2.2760570505234816

Epoch: 5| Step: 2
Training loss: 0.3068921824964851
Validation loss: 2.2579229224033353

Epoch: 5| Step: 3
Training loss: 0.2583586658598399
Validation loss: 2.337586853368597

Epoch: 5| Step: 4
Training loss: 0.31090859273982024
Validation loss: 2.3053837373349158

Epoch: 5| Step: 5
Training loss: 0.1303764227874527
Validation loss: 2.3873278643156772

Epoch: 5| Step: 6
Training loss: 0.3970462970066656
Validation loss: 2.39539537979092

Epoch: 5| Step: 7
Training loss: 0.2787400944835757
Validation loss: 2.3238192400976905

Epoch: 5| Step: 8
Training loss: 0.2601387671017592
Validation loss: 2.3761336250059544

Epoch: 5| Step: 9
Training loss: 0.15529597616660007
Validation loss: 2.3363827154793597

Epoch: 5| Step: 10
Training loss: 0.24778608444728228
Validation loss: 2.3081479381018832

Epoch: 551| Step: 0
Training loss: 0.2560962715979039
Validation loss: 2.3027598494538424

Epoch: 5| Step: 1
Training loss: 0.19055646930859502
Validation loss: 2.3068598483425005

Epoch: 5| Step: 2
Training loss: 0.2849449393766993
Validation loss: 2.2751838334850354

Epoch: 5| Step: 3
Training loss: 0.16406022933115236
Validation loss: 2.2997496697857884

Epoch: 5| Step: 4
Training loss: 0.21852541361853534
Validation loss: 2.2743029412929308

Epoch: 5| Step: 5
Training loss: 0.24686357646780643
Validation loss: 2.268130764622728

Epoch: 5| Step: 6
Training loss: 0.34672730884414515
Validation loss: 2.3149299658934734

Epoch: 5| Step: 7
Training loss: 0.24096454746854495
Validation loss: 2.3127205202275083

Epoch: 5| Step: 8
Training loss: 0.3162431296442889
Validation loss: 2.26550784205911

Epoch: 5| Step: 9
Training loss: 0.3190323205810902
Validation loss: 2.3100428604447254

Epoch: 5| Step: 10
Training loss: 0.3814203288329154
Validation loss: 2.316335449896464

Epoch: 552| Step: 0
Training loss: 0.1856385857654948
Validation loss: 2.2901182684383197

Epoch: 5| Step: 1
Training loss: 0.36082788842492924
Validation loss: 2.2952459933356852

Epoch: 5| Step: 2
Training loss: 0.23186276609222578
Validation loss: 2.3098836197586667

Epoch: 5| Step: 3
Training loss: 0.20462255284716732
Validation loss: 2.318261315049795

Epoch: 5| Step: 4
Training loss: 0.30890622796467154
Validation loss: 2.345073767470676

Epoch: 5| Step: 5
Training loss: 0.28638163609102685
Validation loss: 2.2883735428259455

Epoch: 5| Step: 6
Training loss: 0.3181865901945254
Validation loss: 2.3248713247907444

Epoch: 5| Step: 7
Training loss: 0.19718128705400864
Validation loss: 2.3327453677471133

Epoch: 5| Step: 8
Training loss: 0.2682078670945875
Validation loss: 2.278857952786496

Epoch: 5| Step: 9
Training loss: 0.33589766510165836
Validation loss: 2.253756727049418

Epoch: 5| Step: 10
Training loss: 0.2496741376507283
Validation loss: 2.2401350106449125

Epoch: 553| Step: 0
Training loss: 0.201320870786514
Validation loss: 2.255301574887815

Epoch: 5| Step: 1
Training loss: 0.2830489692747389
Validation loss: 2.2659913578368798

Epoch: 5| Step: 2
Training loss: 0.27995735714393954
Validation loss: 2.303922910899243

Epoch: 5| Step: 3
Training loss: 0.15064016916732106
Validation loss: 2.2602436272959308

Epoch: 5| Step: 4
Training loss: 0.30475090051913817
Validation loss: 2.256821764274504

Epoch: 5| Step: 5
Training loss: 0.2778911695241754
Validation loss: 2.331474921752852

Epoch: 5| Step: 6
Training loss: 0.2885774460562053
Validation loss: 2.330285063988289

Epoch: 5| Step: 7
Training loss: 0.2242113899724313
Validation loss: 2.3040609846824194

Epoch: 5| Step: 8
Training loss: 0.13995619520691316
Validation loss: 2.31462079516419

Epoch: 5| Step: 9
Training loss: 0.3881336108003483
Validation loss: 2.367429572732393

Epoch: 5| Step: 10
Training loss: 0.15554120709196115
Validation loss: 2.35565632123444

Epoch: 554| Step: 0
Training loss: 0.254609425402224
Validation loss: 2.3042496760517666

Epoch: 5| Step: 1
Training loss: 0.2618813792296137
Validation loss: 2.343851969698626

Epoch: 5| Step: 2
Training loss: 0.36114848027095064
Validation loss: 2.3303529669620424

Epoch: 5| Step: 3
Training loss: 0.12254886664586712
Validation loss: 2.3734064914476978

Epoch: 5| Step: 4
Training loss: 0.2227507106446427
Validation loss: 2.344732637771618

Epoch: 5| Step: 5
Training loss: 0.24268909011052678
Validation loss: 2.3799467700835444

Epoch: 5| Step: 6
Training loss: 0.20192731290215002
Validation loss: 2.357960407921135

Epoch: 5| Step: 7
Training loss: 0.27804651010076165
Validation loss: 2.3686363507893455

Epoch: 5| Step: 8
Training loss: 0.1386665423805149
Validation loss: 2.3329311879828363

Epoch: 5| Step: 9
Training loss: 0.17718996782955856
Validation loss: 2.31076752725515

Epoch: 5| Step: 10
Training loss: 0.38978809349274957
Validation loss: 2.2812080688488754

Epoch: 555| Step: 0
Training loss: 0.2689227269924782
Validation loss: 2.262226388735656

Epoch: 5| Step: 1
Training loss: 0.22515116322507267
Validation loss: 2.2926953109318675

Epoch: 5| Step: 2
Training loss: 0.26977050224466725
Validation loss: 2.261142846755586

Epoch: 5| Step: 3
Training loss: 0.20113063130221184
Validation loss: 2.266937418872167

Epoch: 5| Step: 4
Training loss: 0.2773467184633242
Validation loss: 2.30975904576597

Epoch: 5| Step: 5
Training loss: 0.1610303032527241
Validation loss: 2.275213251370316

Epoch: 5| Step: 6
Training loss: 0.40159711725665054
Validation loss: 2.284528417648261

Epoch: 5| Step: 7
Training loss: 0.1840834073690689
Validation loss: 2.265212052858716

Epoch: 5| Step: 8
Training loss: 0.2159255793768744
Validation loss: 2.297911765415643

Epoch: 5| Step: 9
Training loss: 0.3095677854031687
Validation loss: 2.2962484765794504

Epoch: 5| Step: 10
Training loss: 0.2692309102186421
Validation loss: 2.329216121574361

Epoch: 556| Step: 0
Training loss: 0.24661824177677288
Validation loss: 2.318314819698442

Epoch: 5| Step: 1
Training loss: 0.24879772952809315
Validation loss: 2.286657069424165

Epoch: 5| Step: 2
Training loss: 0.16822646021265197
Validation loss: 2.2648777915922387

Epoch: 5| Step: 3
Training loss: 0.2722240772043549
Validation loss: 2.2699317877320286

Epoch: 5| Step: 4
Training loss: 0.29654105125982644
Validation loss: 2.294689194563558

Epoch: 5| Step: 5
Training loss: 0.2551972068904328
Validation loss: 2.279444511737034

Epoch: 5| Step: 6
Training loss: 0.33166330931671917
Validation loss: 2.2739239926175383

Epoch: 5| Step: 7
Training loss: 0.22693624581421412
Validation loss: 2.28373770348398

Epoch: 5| Step: 8
Training loss: 0.3200739227905477
Validation loss: 2.2672122550883786

Epoch: 5| Step: 9
Training loss: 0.33335143899422487
Validation loss: 2.2499346227957897

Epoch: 5| Step: 10
Training loss: 0.3361463119571203
Validation loss: 2.2986777873957367

Epoch: 557| Step: 0
Training loss: 0.19547690148131894
Validation loss: 2.265634012681731

Epoch: 5| Step: 1
Training loss: 0.3498273095633374
Validation loss: 2.2716926887817253

Epoch: 5| Step: 2
Training loss: 0.21570541810305885
Validation loss: 2.2655939670766965

Epoch: 5| Step: 3
Training loss: 0.3059463659839041
Validation loss: 2.291658521359941

Epoch: 5| Step: 4
Training loss: 0.2633119316221704
Validation loss: 2.303829304052573

Epoch: 5| Step: 5
Training loss: 0.21019553451937534
Validation loss: 2.314379198202023

Epoch: 5| Step: 6
Training loss: 0.36549392698281036
Validation loss: 2.3102684350783234

Epoch: 5| Step: 7
Training loss: 0.3016201186601266
Validation loss: 2.300514121419139

Epoch: 5| Step: 8
Training loss: 0.25135673495288874
Validation loss: 2.309169352934469

Epoch: 5| Step: 9
Training loss: 0.21148008745946478
Validation loss: 2.3599300099807468

Epoch: 5| Step: 10
Training loss: 0.21829107373030812
Validation loss: 2.3562675602717884

Epoch: 558| Step: 0
Training loss: 0.2645322819265482
Validation loss: 2.3670521840999634

Epoch: 5| Step: 1
Training loss: 0.26944217039134005
Validation loss: 2.3437647993379365

Epoch: 5| Step: 2
Training loss: 0.29690644449047565
Validation loss: 2.3348908946392926

Epoch: 5| Step: 3
Training loss: 0.24880907893086754
Validation loss: 2.358947206605625

Epoch: 5| Step: 4
Training loss: 0.3459408045389502
Validation loss: 2.3283919788140603

Epoch: 5| Step: 5
Training loss: 0.32283923800022735
Validation loss: 2.3042649938740145

Epoch: 5| Step: 6
Training loss: 0.32161095909310844
Validation loss: 2.2404206603457997

Epoch: 5| Step: 7
Training loss: 0.30074007817658477
Validation loss: 2.240351227404165

Epoch: 5| Step: 8
Training loss: 0.26301696824862925
Validation loss: 2.2313363699636644

Epoch: 5| Step: 9
Training loss: 0.3072419678644609
Validation loss: 2.2345588379554693

Epoch: 5| Step: 10
Training loss: 0.21351098309247116
Validation loss: 2.244272217684095

Epoch: 559| Step: 0
Training loss: 0.18672352190184735
Validation loss: 2.2604781397121783

Epoch: 5| Step: 1
Training loss: 0.29435305023566616
Validation loss: 2.2950746491076375

Epoch: 5| Step: 2
Training loss: 0.1609821308619733
Validation loss: 2.270952051346001

Epoch: 5| Step: 3
Training loss: 0.25089583230303036
Validation loss: 2.3260347489110385

Epoch: 5| Step: 4
Training loss: 0.1510085255887605
Validation loss: 2.2992933549405516

Epoch: 5| Step: 5
Training loss: 0.23742168195540278
Validation loss: 2.2796018082454164

Epoch: 5| Step: 6
Training loss: 0.266037200411292
Validation loss: 2.2518459948779403

Epoch: 5| Step: 7
Training loss: 0.38720816651763545
Validation loss: 2.2967878867461056

Epoch: 5| Step: 8
Training loss: 0.21059000567860403
Validation loss: 2.2374655657847984

Epoch: 5| Step: 9
Training loss: 0.35010963749302204
Validation loss: 2.2622003042823846

Epoch: 5| Step: 10
Training loss: 0.26984569617333326
Validation loss: 2.214933708791693

Epoch: 560| Step: 0
Training loss: 0.20677202117892615
Validation loss: 2.238814034991808

Epoch: 5| Step: 1
Training loss: 0.178293522371425
Validation loss: 2.256975361307533

Epoch: 5| Step: 2
Training loss: 0.36818547275123037
Validation loss: 2.2463093595381136

Epoch: 5| Step: 3
Training loss: 0.18308571263863713
Validation loss: 2.2850540523921885

Epoch: 5| Step: 4
Training loss: 0.2153689553917535
Validation loss: 2.2810021683177943

Epoch: 5| Step: 5
Training loss: 0.3097082967732924
Validation loss: 2.2893785175038475

Epoch: 5| Step: 6
Training loss: 0.28914844678613005
Validation loss: 2.3030669201414358

Epoch: 5| Step: 7
Training loss: 0.2282208391606113
Validation loss: 2.381346190526257

Epoch: 5| Step: 8
Training loss: 0.2392447798935758
Validation loss: 2.38799678300889

Epoch: 5| Step: 9
Training loss: 0.21564088673047446
Validation loss: 2.3085022415368126

Epoch: 5| Step: 10
Training loss: 0.173264704792401
Validation loss: 2.324201860070915

Epoch: 561| Step: 0
Training loss: 0.182026811471944
Validation loss: 2.3164739400527345

Epoch: 5| Step: 1
Training loss: 0.21146394239857014
Validation loss: 2.3007335900602612

Epoch: 5| Step: 2
Training loss: 0.3013992030504989
Validation loss: 2.271966183308781

Epoch: 5| Step: 3
Training loss: 0.31293420428610436
Validation loss: 2.2681639106367495

Epoch: 5| Step: 4
Training loss: 0.24906416915181082
Validation loss: 2.30386371799106

Epoch: 5| Step: 5
Training loss: 0.17504447069690196
Validation loss: 2.234872719101957

Epoch: 5| Step: 6
Training loss: 0.28878168693916445
Validation loss: 2.266380312585341

Epoch: 5| Step: 7
Training loss: 0.19973281843093219
Validation loss: 2.2461408181985734

Epoch: 5| Step: 8
Training loss: 0.192874956695888
Validation loss: 2.286861606409269

Epoch: 5| Step: 9
Training loss: 0.2161749605676203
Validation loss: 2.238549470664328

Epoch: 5| Step: 10
Training loss: 0.35033606547808066
Validation loss: 2.2804338920170846

Epoch: 562| Step: 0
Training loss: 0.1423322438678357
Validation loss: 2.319041800551599

Epoch: 5| Step: 1
Training loss: 0.29880826547491074
Validation loss: 2.318566455458566

Epoch: 5| Step: 2
Training loss: 0.37142263194197966
Validation loss: 2.32805180907729

Epoch: 5| Step: 3
Training loss: 0.28289969401557075
Validation loss: 2.2946448248551916

Epoch: 5| Step: 4
Training loss: 0.16170680375134666
Validation loss: 2.289989094204675

Epoch: 5| Step: 5
Training loss: 0.25994825038431174
Validation loss: 2.3208620109810716

Epoch: 5| Step: 6
Training loss: 0.2042393014281717
Validation loss: 2.276570299546381

Epoch: 5| Step: 7
Training loss: 0.18344629737775153
Validation loss: 2.2896707828264447

Epoch: 5| Step: 8
Training loss: 0.17300409386661325
Validation loss: 2.245067376696732

Epoch: 5| Step: 9
Training loss: 0.21407389993314793
Validation loss: 2.2562966537890214

Epoch: 5| Step: 10
Training loss: 0.277407464244231
Validation loss: 2.2624581398765873

Epoch: 563| Step: 0
Training loss: 0.15057306247001703
Validation loss: 2.2842709548782856

Epoch: 5| Step: 1
Training loss: 0.1685804826927097
Validation loss: 2.278654230105257

Epoch: 5| Step: 2
Training loss: 0.21416319650561144
Validation loss: 2.3363790593757496

Epoch: 5| Step: 3
Training loss: 0.14230365986312934
Validation loss: 2.3585602423053174

Epoch: 5| Step: 4
Training loss: 0.18488523067824866
Validation loss: 2.3763519286376753

Epoch: 5| Step: 5
Training loss: 0.24062881807295405
Validation loss: 2.3132588300832606

Epoch: 5| Step: 6
Training loss: 0.23416784986749115
Validation loss: 2.336170616073008

Epoch: 5| Step: 7
Training loss: 0.2812686225235927
Validation loss: 2.339264721435769

Epoch: 5| Step: 8
Training loss: 0.2598907054836094
Validation loss: 2.299811034155391

Epoch: 5| Step: 9
Training loss: 0.22435883356206096
Validation loss: 2.295259250199184

Epoch: 5| Step: 10
Training loss: 0.39447846390015473
Validation loss: 2.3052022413014415

Epoch: 564| Step: 0
Training loss: 0.13661574843381663
Validation loss: 2.311157740524389

Epoch: 5| Step: 1
Training loss: 0.29396598210962477
Validation loss: 2.3130150337574262

Epoch: 5| Step: 2
Training loss: 0.1795857078984572
Validation loss: 2.2875305551870544

Epoch: 5| Step: 3
Training loss: 0.20159116585511752
Validation loss: 2.3042496120789515

Epoch: 5| Step: 4
Training loss: 0.06563773102681518
Validation loss: 2.317659842433361

Epoch: 5| Step: 5
Training loss: 0.22988820908272034
Validation loss: 2.3321053812358206

Epoch: 5| Step: 6
Training loss: 0.2343418892678315
Validation loss: 2.324950893314417

Epoch: 5| Step: 7
Training loss: 0.15984888938293365
Validation loss: 2.3008895283899564

Epoch: 5| Step: 8
Training loss: 0.36290066790362924
Validation loss: 2.3240210533425456

Epoch: 5| Step: 9
Training loss: 0.25728087087265283
Validation loss: 2.3099889938432514

Epoch: 5| Step: 10
Training loss: 0.2513643823332271
Validation loss: 2.2881799556301616

Epoch: 565| Step: 0
Training loss: 0.13585119193178627
Validation loss: 2.30932179617454

Epoch: 5| Step: 1
Training loss: 0.3225676652797438
Validation loss: 2.300513389273159

Epoch: 5| Step: 2
Training loss: 0.11226013792694242
Validation loss: 2.3193267521571084

Epoch: 5| Step: 3
Training loss: 0.21632800219674583
Validation loss: 2.317484296861502

Epoch: 5| Step: 4
Training loss: 0.09589733154218533
Validation loss: 2.33383148416162

Epoch: 5| Step: 5
Training loss: 0.14876445099013097
Validation loss: 2.349550527292363

Epoch: 5| Step: 6
Training loss: 0.18319574800779814
Validation loss: 2.3426536352940825

Epoch: 5| Step: 7
Training loss: 0.2869840724800373
Validation loss: 2.3385485268447517

Epoch: 5| Step: 8
Training loss: 0.37866480498642596
Validation loss: 2.341286208816201

Epoch: 5| Step: 9
Training loss: 0.19058031824846383
Validation loss: 2.309349855575852

Epoch: 5| Step: 10
Training loss: 0.1992151503144216
Validation loss: 2.3660024869446317

Epoch: 566| Step: 0
Training loss: 0.14659870136781614
Validation loss: 2.328391954591294

Epoch: 5| Step: 1
Training loss: 0.31927515320502775
Validation loss: 2.3086356246035256

Epoch: 5| Step: 2
Training loss: 0.19472252431219664
Validation loss: 2.2918277143195005

Epoch: 5| Step: 3
Training loss: 0.2503554826853016
Validation loss: 2.2999812057176654

Epoch: 5| Step: 4
Training loss: 0.20672766901960404
Validation loss: 2.319303700212789

Epoch: 5| Step: 5
Training loss: 0.26401995536222556
Validation loss: 2.33713947490448

Epoch: 5| Step: 6
Training loss: 0.18321001247318722
Validation loss: 2.3671817298216964

Epoch: 5| Step: 7
Training loss: 0.2444524756959684
Validation loss: 2.3775796718611795

Epoch: 5| Step: 8
Training loss: 0.28526520933580746
Validation loss: 2.3654614573902863

Epoch: 5| Step: 9
Training loss: 0.3248492968967797
Validation loss: 2.343293530712779

Epoch: 5| Step: 10
Training loss: 0.2048002813208313
Validation loss: 2.3348637392077642

Epoch: 567| Step: 0
Training loss: 0.3223522301102528
Validation loss: 2.303282116901424

Epoch: 5| Step: 1
Training loss: 0.11919642533128304
Validation loss: 2.3111191074095885

Epoch: 5| Step: 2
Training loss: 0.19307088041162201
Validation loss: 2.2951106843971574

Epoch: 5| Step: 3
Training loss: 0.27685132435651877
Validation loss: 2.3227775734786937

Epoch: 5| Step: 4
Training loss: 0.2601317786543813
Validation loss: 2.29268442321032

Epoch: 5| Step: 5
Training loss: 0.26667231365026295
Validation loss: 2.313819292191123

Epoch: 5| Step: 6
Training loss: 0.18146677824407195
Validation loss: 2.2810512781506898

Epoch: 5| Step: 7
Training loss: 0.22081836291319165
Validation loss: 2.2863289515712033

Epoch: 5| Step: 8
Training loss: 0.23896865498723102
Validation loss: 2.2784593757717913

Epoch: 5| Step: 9
Training loss: 0.28448456864668087
Validation loss: 2.3285077189194423

Epoch: 5| Step: 10
Training loss: 0.1886062571148015
Validation loss: 2.345755706460346

Epoch: 568| Step: 0
Training loss: 0.15221173728893692
Validation loss: 2.3206506358931276

Epoch: 5| Step: 1
Training loss: 0.2050167446014323
Validation loss: 2.3254854226009005

Epoch: 5| Step: 2
Training loss: 0.3092365571649007
Validation loss: 2.358228164206148

Epoch: 5| Step: 3
Training loss: 0.19031179642508103
Validation loss: 2.3498795040991056

Epoch: 5| Step: 4
Training loss: 0.20421358164731826
Validation loss: 2.3592174716215926

Epoch: 5| Step: 5
Training loss: 0.2363104853076301
Validation loss: 2.327421646866976

Epoch: 5| Step: 6
Training loss: 0.19548911692188878
Validation loss: 2.3301744774561635

Epoch: 5| Step: 7
Training loss: 0.2758783391085846
Validation loss: 2.3095325919131766

Epoch: 5| Step: 8
Training loss: 0.24110051766747018
Validation loss: 2.306145041847236

Epoch: 5| Step: 9
Training loss: 0.21622575676364722
Validation loss: 2.301003180760845

Epoch: 5| Step: 10
Training loss: 0.29452052817826146
Validation loss: 2.309345658232592

Epoch: 569| Step: 0
Training loss: 0.1918902117604606
Validation loss: 2.2550444370172666

Epoch: 5| Step: 1
Training loss: 0.1163648019516036
Validation loss: 2.2690682780078624

Epoch: 5| Step: 2
Training loss: 0.3067189256353745
Validation loss: 2.2931516435725934

Epoch: 5| Step: 3
Training loss: 0.12258282835977073
Validation loss: 2.34049496400036

Epoch: 5| Step: 4
Training loss: 0.3160462627483225
Validation loss: 2.3203515308155507

Epoch: 5| Step: 5
Training loss: 0.2866005833320378
Validation loss: 2.365589820102919

Epoch: 5| Step: 6
Training loss: 0.14634231672699066
Validation loss: 2.35310244828678

Epoch: 5| Step: 7
Training loss: 0.21273374464240738
Validation loss: 2.3463481740793184

Epoch: 5| Step: 8
Training loss: 0.26046832843785306
Validation loss: 2.3310854348662335

Epoch: 5| Step: 9
Training loss: 0.09367782079169613
Validation loss: 2.3562004362239803

Epoch: 5| Step: 10
Training loss: 0.2505135030857049
Validation loss: 2.342786842342072

Epoch: 570| Step: 0
Training loss: 0.16343907709254296
Validation loss: 2.3305649723897215

Epoch: 5| Step: 1
Training loss: 0.1774065221697393
Validation loss: 2.328946404949359

Epoch: 5| Step: 2
Training loss: 0.3051152527864648
Validation loss: 2.328774578999211

Epoch: 5| Step: 3
Training loss: 0.2362417031526686
Validation loss: 2.3139938600115366

Epoch: 5| Step: 4
Training loss: 0.14736352317593018
Validation loss: 2.3627791419566835

Epoch: 5| Step: 5
Training loss: 0.19338578708475193
Validation loss: 2.3226771691747494

Epoch: 5| Step: 6
Training loss: 0.1747993702852322
Validation loss: 2.3219256452718464

Epoch: 5| Step: 7
Training loss: 0.16418240343670587
Validation loss: 2.3435878202597054

Epoch: 5| Step: 8
Training loss: 0.25613376958754625
Validation loss: 2.351079105428386

Epoch: 5| Step: 9
Training loss: 0.15730781114430986
Validation loss: 2.337689195536889

Epoch: 5| Step: 10
Training loss: 0.3457771588379532
Validation loss: 2.345065936027792

Epoch: 571| Step: 0
Training loss: 0.11151308038322336
Validation loss: 2.3193987577487403

Epoch: 5| Step: 1
Training loss: 0.23294001613800466
Validation loss: 2.3679232211288586

Epoch: 5| Step: 2
Training loss: 0.16077821612855342
Validation loss: 2.3899976065392816

Epoch: 5| Step: 3
Training loss: 0.2883410084305623
Validation loss: 2.345027279664427

Epoch: 5| Step: 4
Training loss: 0.1730243551958788
Validation loss: 2.344478317363951

Epoch: 5| Step: 5
Training loss: 0.19773678175638235
Validation loss: 2.295084352626052

Epoch: 5| Step: 6
Training loss: 0.22882339748762082
Validation loss: 2.308484405387222

Epoch: 5| Step: 7
Training loss: 0.35294838176588156
Validation loss: 2.252185370950219

Epoch: 5| Step: 8
Training loss: 0.21135774006524607
Validation loss: 2.2811940740207852

Epoch: 5| Step: 9
Training loss: 0.2197661809171771
Validation loss: 2.283683568900453

Epoch: 5| Step: 10
Training loss: 0.1658328115652333
Validation loss: 2.2798849115764486

Epoch: 572| Step: 0
Training loss: 0.3305287191750876
Validation loss: 2.2891304425732226

Epoch: 5| Step: 1
Training loss: 0.13447959233764997
Validation loss: 2.3649151408304445

Epoch: 5| Step: 2
Training loss: 0.2265178208856163
Validation loss: 2.3197507736636402

Epoch: 5| Step: 3
Training loss: 0.12942459189116867
Validation loss: 2.336497824953896

Epoch: 5| Step: 4
Training loss: 0.1591585589937399
Validation loss: 2.353383000171692

Epoch: 5| Step: 5
Training loss: 0.2119012819998028
Validation loss: 2.3418208473247986

Epoch: 5| Step: 6
Training loss: 0.22503040492404103
Validation loss: 2.3231730758068334

Epoch: 5| Step: 7
Training loss: 0.1510115783966256
Validation loss: 2.3232629835045833

Epoch: 5| Step: 8
Training loss: 0.27962070978238845
Validation loss: 2.2954699368182983

Epoch: 5| Step: 9
Training loss: 0.169959458765757
Validation loss: 2.2768358359216196

Epoch: 5| Step: 10
Training loss: 0.3080812133333998
Validation loss: 2.2725636444543804

Epoch: 573| Step: 0
Training loss: 0.16505058519215748
Validation loss: 2.2724511351218126

Epoch: 5| Step: 1
Training loss: 0.16037792472335527
Validation loss: 2.2577120578385497

Epoch: 5| Step: 2
Training loss: 0.19936129201503572
Validation loss: 2.260178642808131

Epoch: 5| Step: 3
Training loss: 0.2542146423795785
Validation loss: 2.238438396066086

Epoch: 5| Step: 4
Training loss: 0.1762818466914208
Validation loss: 2.2847593148037104

Epoch: 5| Step: 5
Training loss: 0.15750534504570338
Validation loss: 2.2385623452357972

Epoch: 5| Step: 6
Training loss: 0.10801355232866891
Validation loss: 2.2565736667267187

Epoch: 5| Step: 7
Training loss: 0.38629601232290944
Validation loss: 2.297659540115981

Epoch: 5| Step: 8
Training loss: 0.18960252750262283
Validation loss: 2.2444162724173107

Epoch: 5| Step: 9
Training loss: 0.20761146752847606
Validation loss: 2.2952294726903095

Epoch: 5| Step: 10
Training loss: 0.23484354074992936
Validation loss: 2.295404934387845

Epoch: 574| Step: 0
Training loss: 0.22347819717948236
Validation loss: 2.2771591781247613

Epoch: 5| Step: 1
Training loss: 0.18714683770897528
Validation loss: 2.261515776639618

Epoch: 5| Step: 2
Training loss: 0.27287212231560765
Validation loss: 2.2730162996849512

Epoch: 5| Step: 3
Training loss: 0.1061447344371502
Validation loss: 2.269439196684614

Epoch: 5| Step: 4
Training loss: 0.1345731909323626
Validation loss: 2.247247748198678

Epoch: 5| Step: 5
Training loss: 0.22714093787161319
Validation loss: 2.299269686258434

Epoch: 5| Step: 6
Training loss: 0.17555985813998204
Validation loss: 2.2898876709414377

Epoch: 5| Step: 7
Training loss: 0.22106591511127638
Validation loss: 2.305814166966782

Epoch: 5| Step: 8
Training loss: 0.20748788031262777
Validation loss: 2.2707595312704565

Epoch: 5| Step: 9
Training loss: 0.24336575948260675
Validation loss: 2.325161396757824

Epoch: 5| Step: 10
Training loss: 0.23372789696621896
Validation loss: 2.2867021227244853

Epoch: 575| Step: 0
Training loss: 0.2301684216960242
Validation loss: 2.27121318606638

Epoch: 5| Step: 1
Training loss: 0.27161440033996403
Validation loss: 2.282336765223638

Epoch: 5| Step: 2
Training loss: 0.1423936591183541
Validation loss: 2.265055846399805

Epoch: 5| Step: 3
Training loss: 0.23978920139207677
Validation loss: 2.2803304939977913

Epoch: 5| Step: 4
Training loss: 0.258776524078072
Validation loss: 2.2854538551175283

Epoch: 5| Step: 5
Training loss: 0.24035058661005004
Validation loss: 2.2632244950272384

Epoch: 5| Step: 6
Training loss: 0.10825465090998675
Validation loss: 2.2847853128224913

Epoch: 5| Step: 7
Training loss: 0.12970579604273136
Validation loss: 2.300948337659549

Epoch: 5| Step: 8
Training loss: 0.12798367882493708
Validation loss: 2.304121423678527

Epoch: 5| Step: 9
Training loss: 0.22739554860552583
Validation loss: 2.3013639891283533

Epoch: 5| Step: 10
Training loss: 0.2588354536976973
Validation loss: 2.2967062631371515

Epoch: 576| Step: 0
Training loss: 0.22541851585150316
Validation loss: 2.2888095778561377

Epoch: 5| Step: 1
Training loss: 0.16395966963019465
Validation loss: 2.320787384735404

Epoch: 5| Step: 2
Training loss: 0.2911163130291682
Validation loss: 2.32258525970985

Epoch: 5| Step: 3
Training loss: 0.21728174442655812
Validation loss: 2.305365810336167

Epoch: 5| Step: 4
Training loss: 0.21104930634304397
Validation loss: 2.273752347818484

Epoch: 5| Step: 5
Training loss: 0.11641000879222763
Validation loss: 2.2657871198235346

Epoch: 5| Step: 6
Training loss: 0.22575735209882394
Validation loss: 2.3012522066355325

Epoch: 5| Step: 7
Training loss: 0.30005312389653993
Validation loss: 2.2966768375869067

Epoch: 5| Step: 8
Training loss: 0.18751937050897435
Validation loss: 2.248896625657134

Epoch: 5| Step: 9
Training loss: 0.2058409174076627
Validation loss: 2.243261651026584

Epoch: 5| Step: 10
Training loss: 0.15560070074108728
Validation loss: 2.2389248482075725

Epoch: 577| Step: 0
Training loss: 0.14642512076703262
Validation loss: 2.271052625878619

Epoch: 5| Step: 1
Training loss: 0.17748724345923392
Validation loss: 2.2758450424008414

Epoch: 5| Step: 2
Training loss: 0.20396446113291183
Validation loss: 2.2782527604007323

Epoch: 5| Step: 3
Training loss: 0.3002713575572746
Validation loss: 2.2633818195197453

Epoch: 5| Step: 4
Training loss: 0.14796167579304337
Validation loss: 2.284582857074518

Epoch: 5| Step: 5
Training loss: 0.30904214610701686
Validation loss: 2.2893581516537855

Epoch: 5| Step: 6
Training loss: 0.17995943349114968
Validation loss: 2.316354300529926

Epoch: 5| Step: 7
Training loss: 0.19047426533400266
Validation loss: 2.374597455955913

Epoch: 5| Step: 8
Training loss: 0.17553960297024387
Validation loss: 2.3409769006700105

Epoch: 5| Step: 9
Training loss: 0.2898243967057399
Validation loss: 2.3629372167594083

Epoch: 5| Step: 10
Training loss: 0.2239715559331092
Validation loss: 2.324442647847301

Epoch: 578| Step: 0
Training loss: 0.15654356915316558
Validation loss: 2.352363669892795

Epoch: 5| Step: 1
Training loss: 0.2162233447311561
Validation loss: 2.3081816884422155

Epoch: 5| Step: 2
Training loss: 0.2894873203768713
Validation loss: 2.316432237025419

Epoch: 5| Step: 3
Training loss: 0.19210215976564374
Validation loss: 2.3189010185742873

Epoch: 5| Step: 4
Training loss: 0.1833329580494623
Validation loss: 2.291303409711424

Epoch: 5| Step: 5
Training loss: 0.2677641729954463
Validation loss: 2.316942094158857

Epoch: 5| Step: 6
Training loss: 0.28369178706289655
Validation loss: 2.29921663487895

Epoch: 5| Step: 7
Training loss: 0.2285495961035692
Validation loss: 2.2981743852837204

Epoch: 5| Step: 8
Training loss: 0.13321470618592537
Validation loss: 2.3442009670412958

Epoch: 5| Step: 9
Training loss: 0.15771674518206671
Validation loss: 2.361532173598324

Epoch: 5| Step: 10
Training loss: 0.12642988067774372
Validation loss: 2.32567312557275

Epoch: 579| Step: 0
Training loss: 0.2287516882578768
Validation loss: 2.3302631710924007

Epoch: 5| Step: 1
Training loss: 0.2998013201098869
Validation loss: 2.355791619183622

Epoch: 5| Step: 2
Training loss: 0.1540173461216491
Validation loss: 2.3257343256845764

Epoch: 5| Step: 3
Training loss: 0.20444897010088559
Validation loss: 2.327712355071157

Epoch: 5| Step: 4
Training loss: 0.18386100026003407
Validation loss: 2.272457181938535

Epoch: 5| Step: 5
Training loss: 0.1915510661305118
Validation loss: 2.2801443278572675

Epoch: 5| Step: 6
Training loss: 0.1973263203375805
Validation loss: 2.296795906522731

Epoch: 5| Step: 7
Training loss: 0.22822177774164748
Validation loss: 2.274633832210446

Epoch: 5| Step: 8
Training loss: 0.2618857178509107
Validation loss: 2.291214354803364

Epoch: 5| Step: 9
Training loss: 0.3093735584071317
Validation loss: 2.2934788412232154

Epoch: 5| Step: 10
Training loss: 0.1817422398008481
Validation loss: 2.327525736534519

Epoch: 580| Step: 0
Training loss: 0.14852883640866882
Validation loss: 2.3181097842765013

Epoch: 5| Step: 1
Training loss: 0.15027633262604081
Validation loss: 2.3395930143946857

Epoch: 5| Step: 2
Training loss: 0.14425605917473766
Validation loss: 2.345816853657947

Epoch: 5| Step: 3
Training loss: 0.17649318845305575
Validation loss: 2.380782075576173

Epoch: 5| Step: 4
Training loss: 0.2672747542030033
Validation loss: 2.3361475709411907

Epoch: 5| Step: 5
Training loss: 0.28934045264077823
Validation loss: 2.3820391936814413

Epoch: 5| Step: 6
Training loss: 0.2307141985174982
Validation loss: 2.2970054778590985

Epoch: 5| Step: 7
Training loss: 0.3034273399671394
Validation loss: 2.342361555218854

Epoch: 5| Step: 8
Training loss: 0.12363361310172334
Validation loss: 2.333137184972422

Epoch: 5| Step: 9
Training loss: 0.20499731015557376
Validation loss: 2.312669164162352

Epoch: 5| Step: 10
Training loss: 0.17443631426443412
Validation loss: 2.349187782765785

Epoch: 581| Step: 0
Training loss: 0.26058842557880973
Validation loss: 2.3396243179570013

Epoch: 5| Step: 1
Training loss: 0.1430075657896338
Validation loss: 2.349366913057904

Epoch: 5| Step: 2
Training loss: 0.12785967884123184
Validation loss: 2.3457056507119094

Epoch: 5| Step: 3
Training loss: 0.23057900232389986
Validation loss: 2.3637492808742624

Epoch: 5| Step: 4
Training loss: 0.12067577305234582
Validation loss: 2.356843229568904

Epoch: 5| Step: 5
Training loss: 0.21484049881295791
Validation loss: 2.392502368416595

Epoch: 5| Step: 6
Training loss: 0.22725862403752792
Validation loss: 2.351639892124421

Epoch: 5| Step: 7
Training loss: 0.2742025299926611
Validation loss: 2.345996406348556

Epoch: 5| Step: 8
Training loss: 0.18276649124372016
Validation loss: 2.323032755530453

Epoch: 5| Step: 9
Training loss: 0.23530299528463305
Validation loss: 2.3195080990238117

Epoch: 5| Step: 10
Training loss: 0.18872985225475344
Validation loss: 2.3503221080324526

Epoch: 582| Step: 0
Training loss: 0.3165471034245698
Validation loss: 2.314709692706721

Epoch: 5| Step: 1
Training loss: 0.15052494020920185
Validation loss: 2.3261140164371157

Epoch: 5| Step: 2
Training loss: 0.25366843897657376
Validation loss: 2.2928385243285416

Epoch: 5| Step: 3
Training loss: 0.24344968298859873
Validation loss: 2.379574175279664

Epoch: 5| Step: 4
Training loss: 0.21358865515570183
Validation loss: 2.3663372119709836

Epoch: 5| Step: 5
Training loss: 0.16603603237608855
Validation loss: 2.384209602915784

Epoch: 5| Step: 6
Training loss: 0.2009751089060185
Validation loss: 2.348499480743722

Epoch: 5| Step: 7
Training loss: 0.15342911425437344
Validation loss: 2.3655230716680395

Epoch: 5| Step: 8
Training loss: 0.16004826813232728
Validation loss: 2.3749240945150865

Epoch: 5| Step: 9
Training loss: 0.27213398995398136
Validation loss: 2.340810217026114

Epoch: 5| Step: 10
Training loss: 0.19765668763425123
Validation loss: 2.2775776334803925

Epoch: 583| Step: 0
Training loss: 0.28762073780434694
Validation loss: 2.307279505973437

Epoch: 5| Step: 1
Training loss: 0.22249708844808747
Validation loss: 2.277620632388941

Epoch: 5| Step: 2
Training loss: 0.1678791139649618
Validation loss: 2.289894591980692

Epoch: 5| Step: 3
Training loss: 0.30467957706420556
Validation loss: 2.283884243275951

Epoch: 5| Step: 4
Training loss: 0.1700111352029525
Validation loss: 2.281734535340592

Epoch: 5| Step: 5
Training loss: 0.13704559222843052
Validation loss: 2.2788107706077994

Epoch: 5| Step: 6
Training loss: 0.2516508877120267
Validation loss: 2.290916560252202

Epoch: 5| Step: 7
Training loss: 0.3074630351062282
Validation loss: 2.315078021144939

Epoch: 5| Step: 8
Training loss: 0.20953448256830226
Validation loss: 2.322751528311226

Epoch: 5| Step: 9
Training loss: 0.12424345100775978
Validation loss: 2.3619173637012794

Epoch: 5| Step: 10
Training loss: 0.2700741455694213
Validation loss: 2.303283575259067

Epoch: 584| Step: 0
Training loss: 0.11994273224908147
Validation loss: 2.3043510178867384

Epoch: 5| Step: 1
Training loss: 0.2843288410368727
Validation loss: 2.312332394464552

Epoch: 5| Step: 2
Training loss: 0.1926144014434371
Validation loss: 2.336272026930892

Epoch: 5| Step: 3
Training loss: 0.25509532385614797
Validation loss: 2.3192076533212407

Epoch: 5| Step: 4
Training loss: 0.14970670975005484
Validation loss: 2.3299495745900978

Epoch: 5| Step: 5
Training loss: 0.14862360079838993
Validation loss: 2.2775062119358136

Epoch: 5| Step: 6
Training loss: 0.22462817403655588
Validation loss: 2.267679054924057

Epoch: 5| Step: 7
Training loss: 0.21564983522055964
Validation loss: 2.2821409312155283

Epoch: 5| Step: 8
Training loss: 0.3753762344634762
Validation loss: 2.26118149815086

Epoch: 5| Step: 9
Training loss: 0.15808453058965136
Validation loss: 2.255996297789775

Epoch: 5| Step: 10
Training loss: 0.19712318338779897
Validation loss: 2.307926024015883

Epoch: 585| Step: 0
Training loss: 0.15257600661729684
Validation loss: 2.259851462052701

Epoch: 5| Step: 1
Training loss: 0.26838889813338146
Validation loss: 2.3514878973851587

Epoch: 5| Step: 2
Training loss: 0.26176536201915146
Validation loss: 2.3104437078101876

Epoch: 5| Step: 3
Training loss: 0.1037496270106976
Validation loss: 2.339762546972924

Epoch: 5| Step: 4
Training loss: 0.27578537967604916
Validation loss: 2.3826601342504428

Epoch: 5| Step: 5
Training loss: 0.29513707425301383
Validation loss: 2.3635542647206607

Epoch: 5| Step: 6
Training loss: 0.2182206151435439
Validation loss: 2.341238005504102

Epoch: 5| Step: 7
Training loss: 0.15648552309968225
Validation loss: 2.3794398859418893

Epoch: 5| Step: 8
Training loss: 0.16744785714234936
Validation loss: 2.3339097531317945

Epoch: 5| Step: 9
Training loss: 0.16669919148619775
Validation loss: 2.3115331052404713

Epoch: 5| Step: 10
Training loss: 0.2317329582956573
Validation loss: 2.2839699382813246

Epoch: 586| Step: 0
Training loss: 0.16890705645718931
Validation loss: 2.275087531983136

Epoch: 5| Step: 1
Training loss: 0.2470170140733788
Validation loss: 2.2620229679233916

Epoch: 5| Step: 2
Training loss: 0.25154776085744335
Validation loss: 2.241548366865911

Epoch: 5| Step: 3
Training loss: 0.2947821128069891
Validation loss: 2.2854552079121535

Epoch: 5| Step: 4
Training loss: 0.2820529733887921
Validation loss: 2.2689122980547087

Epoch: 5| Step: 5
Training loss: 0.15686283332256712
Validation loss: 2.2982754194282387

Epoch: 5| Step: 6
Training loss: 0.16367012742231674
Validation loss: 2.3226148741403456

Epoch: 5| Step: 7
Training loss: 0.18403010559309194
Validation loss: 2.3126083654606986

Epoch: 5| Step: 8
Training loss: 0.24636687910630106
Validation loss: 2.3241661203005686

Epoch: 5| Step: 9
Training loss: 0.12053562180386886
Validation loss: 2.32252316200113

Epoch: 5| Step: 10
Training loss: 0.26138657513514546
Validation loss: 2.3092697211918103

Epoch: 587| Step: 0
Training loss: 0.3545426051749482
Validation loss: 2.329732141832997

Epoch: 5| Step: 1
Training loss: 0.19530573833205309
Validation loss: 2.2880267869831408

Epoch: 5| Step: 2
Training loss: 0.11947958833353432
Validation loss: 2.2771474393099855

Epoch: 5| Step: 3
Training loss: 0.20988965265972753
Validation loss: 2.27359583226189

Epoch: 5| Step: 4
Training loss: 0.2983127837700236
Validation loss: 2.270282380107573

Epoch: 5| Step: 5
Training loss: 0.20941451183826618
Validation loss: 2.2768625110351945

Epoch: 5| Step: 6
Training loss: 0.23854746565093202
Validation loss: 2.284068013557323

Epoch: 5| Step: 7
Training loss: 0.1524861416128529
Validation loss: 2.3039394203925285

Epoch: 5| Step: 8
Training loss: 0.1248385534171772
Validation loss: 2.3300148345964073

Epoch: 5| Step: 9
Training loss: 0.18202603377698465
Validation loss: 2.3601133167507036

Epoch: 5| Step: 10
Training loss: 0.16238479312976284
Validation loss: 2.3582487025117453

Epoch: 588| Step: 0
Training loss: 0.1793032767621918
Validation loss: 2.3509015270567755

Epoch: 5| Step: 1
Training loss: 0.3066561749640054
Validation loss: 2.356192274276787

Epoch: 5| Step: 2
Training loss: 0.26256162226674834
Validation loss: 2.3235918812312715

Epoch: 5| Step: 3
Training loss: 0.22689385682549487
Validation loss: 2.334650731499613

Epoch: 5| Step: 4
Training loss: 0.18824618594737355
Validation loss: 2.351436268329849

Epoch: 5| Step: 5
Training loss: 0.16996709178144437
Validation loss: 2.278082297587017

Epoch: 5| Step: 6
Training loss: 0.22734982885511998
Validation loss: 2.319726868891147

Epoch: 5| Step: 7
Training loss: 0.16887769283008483
Validation loss: 2.3392620769858725

Epoch: 5| Step: 8
Training loss: 0.17850345803832768
Validation loss: 2.295014544911033

Epoch: 5| Step: 9
Training loss: 0.21007983367667657
Validation loss: 2.2780739609766156

Epoch: 5| Step: 10
Training loss: 0.2456936914789019
Validation loss: 2.336274145857012

Epoch: 589| Step: 0
Training loss: 0.11935303857395853
Validation loss: 2.2937312099432305

Epoch: 5| Step: 1
Training loss: 0.22474386086634773
Validation loss: 2.3078509617012006

Epoch: 5| Step: 2
Training loss: 0.22214205244885182
Validation loss: 2.3555549724570333

Epoch: 5| Step: 3
Training loss: 0.2586093494515991
Validation loss: 2.3570931938842623

Epoch: 5| Step: 4
Training loss: 0.16764468714009073
Validation loss: 2.3153703165325488

Epoch: 5| Step: 5
Training loss: 0.2183678388234778
Validation loss: 2.32681307153128

Epoch: 5| Step: 6
Training loss: 0.19111943651675645
Validation loss: 2.300123669552883

Epoch: 5| Step: 7
Training loss: 0.24217736315278648
Validation loss: 2.2965383321292525

Epoch: 5| Step: 8
Training loss: 0.40694417699422425
Validation loss: 2.2723430094562835

Epoch: 5| Step: 9
Training loss: 0.2458867989134741
Validation loss: 2.281280302171531

Epoch: 5| Step: 10
Training loss: 0.23428987705659365
Validation loss: 2.2919272184246364

Epoch: 590| Step: 0
Training loss: 0.2207207292945731
Validation loss: 2.2542969134836617

Epoch: 5| Step: 1
Training loss: 0.18775813890116963
Validation loss: 2.257143260022888

Epoch: 5| Step: 2
Training loss: 0.23442841556941485
Validation loss: 2.254857863601983

Epoch: 5| Step: 3
Training loss: 0.14570658503251596
Validation loss: 2.2672968437523466

Epoch: 5| Step: 4
Training loss: 0.24028240282018073
Validation loss: 2.2898442074115213

Epoch: 5| Step: 5
Training loss: 0.23905931919450152
Validation loss: 2.2970783695262633

Epoch: 5| Step: 6
Training loss: 0.2923951956063983
Validation loss: 2.2839241160707315

Epoch: 5| Step: 7
Training loss: 0.21191779805771566
Validation loss: 2.3023510936218794

Epoch: 5| Step: 8
Training loss: 0.18427035263376915
Validation loss: 2.3348082994676775

Epoch: 5| Step: 9
Training loss: 0.26114954185109684
Validation loss: 2.3040858508704063

Epoch: 5| Step: 10
Training loss: 0.13981245985486712
Validation loss: 2.3290963881064877

Epoch: 591| Step: 0
Training loss: 0.14913215096579915
Validation loss: 2.335656199383054

Epoch: 5| Step: 1
Training loss: 0.2163469439883353
Validation loss: 2.327399489386547

Epoch: 5| Step: 2
Training loss: 0.17004880877657746
Validation loss: 2.310251374915073

Epoch: 5| Step: 3
Training loss: 0.22541302911752062
Validation loss: 2.304786485062257

Epoch: 5| Step: 4
Training loss: 0.1707518357496592
Validation loss: 2.336716406305699

Epoch: 5| Step: 5
Training loss: 0.24752974483175397
Validation loss: 2.3144354532319253

Epoch: 5| Step: 6
Training loss: 0.18772230281741395
Validation loss: 2.317664209166822

Epoch: 5| Step: 7
Training loss: 0.32433210252812217
Validation loss: 2.327538983020212

Epoch: 5| Step: 8
Training loss: 0.22861417454899843
Validation loss: 2.3264212008012675

Epoch: 5| Step: 9
Training loss: 0.3166563905546034
Validation loss: 2.273728483732903

Epoch: 5| Step: 10
Training loss: 0.1595323844387358
Validation loss: 2.256432691684889

Epoch: 592| Step: 0
Training loss: 0.2399889459895557
Validation loss: 2.2514910326517947

Epoch: 5| Step: 1
Training loss: 0.1884854171333258
Validation loss: 2.2644684472889773

Epoch: 5| Step: 2
Training loss: 0.20749229701233296
Validation loss: 2.244317630653668

Epoch: 5| Step: 3
Training loss: 0.2916901854274369
Validation loss: 2.255471678237983

Epoch: 5| Step: 4
Training loss: 0.18780495758589452
Validation loss: 2.3118841387176685

Epoch: 5| Step: 5
Training loss: 0.30212251913293425
Validation loss: 2.2604003106274932

Epoch: 5| Step: 6
Training loss: 0.2822711473775221
Validation loss: 2.333506687231936

Epoch: 5| Step: 7
Training loss: 0.1279047439369095
Validation loss: 2.3070901084407396

Epoch: 5| Step: 8
Training loss: 0.26911706475281016
Validation loss: 2.3538317676733076

Epoch: 5| Step: 9
Training loss: 0.19531517026983228
Validation loss: 2.3514543559629075

Epoch: 5| Step: 10
Training loss: 0.2924016295387311
Validation loss: 2.368500692285161

Epoch: 593| Step: 0
Training loss: 0.13582805963626782
Validation loss: 2.294498014770286

Epoch: 5| Step: 1
Training loss: 0.12719223539689553
Validation loss: 2.261625825531325

Epoch: 5| Step: 2
Training loss: 0.1709010205754844
Validation loss: 2.2527132173756765

Epoch: 5| Step: 3
Training loss: 0.25526493119629273
Validation loss: 2.2408963968511424

Epoch: 5| Step: 4
Training loss: 0.2495529678199969
Validation loss: 2.268007445170869

Epoch: 5| Step: 5
Training loss: 0.17127640480589587
Validation loss: 2.3046972531459384

Epoch: 5| Step: 6
Training loss: 0.2989904797889922
Validation loss: 2.3285816001172037

Epoch: 5| Step: 7
Training loss: 0.41979077089023226
Validation loss: 2.379224555112262

Epoch: 5| Step: 8
Training loss: 0.19971473511104534
Validation loss: 2.361712483238893

Epoch: 5| Step: 9
Training loss: 0.38566806902021894
Validation loss: 2.339261954242995

Epoch: 5| Step: 10
Training loss: 0.18042330809681714
Validation loss: 2.3025419626307664

Epoch: 594| Step: 0
Training loss: 0.16546919597497192
Validation loss: 2.299798911565763

Epoch: 5| Step: 1
Training loss: 0.2674211333897276
Validation loss: 2.2476091392147612

Epoch: 5| Step: 2
Training loss: 0.17205944784722665
Validation loss: 2.230335019311871

Epoch: 5| Step: 3
Training loss: 0.2629400056710986
Validation loss: 2.262257895929009

Epoch: 5| Step: 4
Training loss: 0.2427293653066347
Validation loss: 2.2431624127693004

Epoch: 5| Step: 5
Training loss: 0.3519048401526816
Validation loss: 2.2834029164709966

Epoch: 5| Step: 6
Training loss: 0.3854401770285829
Validation loss: 2.287466461887943

Epoch: 5| Step: 7
Training loss: 0.229712976612768
Validation loss: 2.3177037389160575

Epoch: 5| Step: 8
Training loss: 0.19666799341949043
Validation loss: 2.293783044779611

Epoch: 5| Step: 9
Training loss: 0.2159102067108617
Validation loss: 2.3260835769773593

Epoch: 5| Step: 10
Training loss: 0.22008177972588508
Validation loss: 2.3199378131937887

Epoch: 595| Step: 0
Training loss: 0.28874956409619607
Validation loss: 2.2960486210069107

Epoch: 5| Step: 1
Training loss: 0.17591772080085588
Validation loss: 2.3284551779053535

Epoch: 5| Step: 2
Training loss: 0.20849995308013314
Validation loss: 2.3044604629527767

Epoch: 5| Step: 3
Training loss: 0.15572905721203414
Validation loss: 2.267433770929439

Epoch: 5| Step: 4
Training loss: 0.2826266241706027
Validation loss: 2.2805891587092266

Epoch: 5| Step: 5
Training loss: 0.23040781993737255
Validation loss: 2.2675210523152094

Epoch: 5| Step: 6
Training loss: 0.17450307153284353
Validation loss: 2.2971168342202537

Epoch: 5| Step: 7
Training loss: 0.28515781767949855
Validation loss: 2.290827998372046

Epoch: 5| Step: 8
Training loss: 0.19962530165884196
Validation loss: 2.2684959741739523

Epoch: 5| Step: 9
Training loss: 0.18889072354405886
Validation loss: 2.284491090997991

Epoch: 5| Step: 10
Training loss: 0.21843181186577457
Validation loss: 2.2815566649777383

Epoch: 596| Step: 0
Training loss: 0.15246163599947468
Validation loss: 2.342105002708062

Epoch: 5| Step: 1
Training loss: 0.21387706367995285
Validation loss: 2.3036550204088946

Epoch: 5| Step: 2
Training loss: 0.20985374375758342
Validation loss: 2.3024810173195718

Epoch: 5| Step: 3
Training loss: 0.27985241465996424
Validation loss: 2.320587040865714

Epoch: 5| Step: 4
Training loss: 0.1995661455437312
Validation loss: 2.2990512824445313

Epoch: 5| Step: 5
Training loss: 0.3271198658778976
Validation loss: 2.2607151713546942

Epoch: 5| Step: 6
Training loss: 0.2068493061590234
Validation loss: 2.2958392582369833

Epoch: 5| Step: 7
Training loss: 0.14838264104117915
Validation loss: 2.2984518297855936

Epoch: 5| Step: 8
Training loss: 0.1571507122871734
Validation loss: 2.325454419014977

Epoch: 5| Step: 9
Training loss: 0.1248969905323488
Validation loss: 2.3004877450724375

Epoch: 5| Step: 10
Training loss: 0.2733562212443488
Validation loss: 2.33367490154493

Epoch: 597| Step: 0
Training loss: 0.1966753522590226
Validation loss: 2.352795907383852

Epoch: 5| Step: 1
Training loss: 0.2086239764283877
Validation loss: 2.326565095128753

Epoch: 5| Step: 2
Training loss: 0.1407755271286123
Validation loss: 2.3352947480532333

Epoch: 5| Step: 3
Training loss: 0.1838532298301048
Validation loss: 2.3048475840821863

Epoch: 5| Step: 4
Training loss: 0.3262674340161008
Validation loss: 2.2932404829507282

Epoch: 5| Step: 5
Training loss: 0.217926698477186
Validation loss: 2.2913953846159685

Epoch: 5| Step: 6
Training loss: 0.15239021619673276
Validation loss: 2.241096718619578

Epoch: 5| Step: 7
Training loss: 0.25181623185025326
Validation loss: 2.246934843586385

Epoch: 5| Step: 8
Training loss: 0.2572802337752444
Validation loss: 2.2802468517570307

Epoch: 5| Step: 9
Training loss: 0.2037469713155629
Validation loss: 2.3017819545633804

Epoch: 5| Step: 10
Training loss: 0.1951099203472836
Validation loss: 2.282042283879812

Epoch: 598| Step: 0
Training loss: 0.17086624932294278
Validation loss: 2.324777764143238

Epoch: 5| Step: 1
Training loss: 0.2357035177731426
Validation loss: 2.3866362985363314

Epoch: 5| Step: 2
Training loss: 0.16820992299688572
Validation loss: 2.388197060915169

Epoch: 5| Step: 3
Training loss: 0.27394027807596893
Validation loss: 2.329904396435019

Epoch: 5| Step: 4
Training loss: 0.32839776237003665
Validation loss: 2.32590506239653

Epoch: 5| Step: 5
Training loss: 0.1530126777636986
Validation loss: 2.312577649569706

Epoch: 5| Step: 6
Training loss: 0.12161394642561692
Validation loss: 2.3036600377231697

Epoch: 5| Step: 7
Training loss: 0.20810616545468819
Validation loss: 2.272135105633129

Epoch: 5| Step: 8
Training loss: 0.2186777046492311
Validation loss: 2.2321661080059187

Epoch: 5| Step: 9
Training loss: 0.14597273164438043
Validation loss: 2.230825271963603

Epoch: 5| Step: 10
Training loss: 0.17737992543700146
Validation loss: 2.2884578060827625

Epoch: 599| Step: 0
Training loss: 0.1771497438292195
Validation loss: 2.2654756719580753

Epoch: 5| Step: 1
Training loss: 0.23087134999878875
Validation loss: 2.2917299308509116

Epoch: 5| Step: 2
Training loss: 0.13564784387178377
Validation loss: 2.320309994156455

Epoch: 5| Step: 3
Training loss: 0.17891916536580188
Validation loss: 2.292383677964296

Epoch: 5| Step: 4
Training loss: 0.3173421745693182
Validation loss: 2.2483984877311545

Epoch: 5| Step: 5
Training loss: 0.26864836012820603
Validation loss: 2.2387217423761494

Epoch: 5| Step: 6
Training loss: 0.1784812201269786
Validation loss: 2.242302320719749

Epoch: 5| Step: 7
Training loss: 0.21960403416889598
Validation loss: 2.256340188625978

Epoch: 5| Step: 8
Training loss: 0.21323564551877747
Validation loss: 2.253068870587261

Epoch: 5| Step: 9
Training loss: 0.2882299289663418
Validation loss: 2.253800913240812

Epoch: 5| Step: 10
Training loss: 0.2002175109465323
Validation loss: 2.26181054117207

Epoch: 600| Step: 0
Training loss: 0.1560227410341656
Validation loss: 2.260467856107161

Epoch: 5| Step: 1
Training loss: 0.23329977719524814
Validation loss: 2.2683751264732557

Epoch: 5| Step: 2
Training loss: 0.16996009440685295
Validation loss: 2.2865749709383856

Epoch: 5| Step: 3
Training loss: 0.18061881658668416
Validation loss: 2.3205275963632195

Epoch: 5| Step: 4
Training loss: 0.31904042420716816
Validation loss: 2.341571400747831

Epoch: 5| Step: 5
Training loss: 0.17521066247553882
Validation loss: 2.319191114341688

Epoch: 5| Step: 6
Training loss: 0.127097568502905
Validation loss: 2.306826778799397

Epoch: 5| Step: 7
Training loss: 0.2637104571336257
Validation loss: 2.2518972780132747

Epoch: 5| Step: 8
Training loss: 0.20549949771292994
Validation loss: 2.262175503516104

Epoch: 5| Step: 9
Training loss: 0.1359834585109624
Validation loss: 2.285018561399061

Epoch: 5| Step: 10
Training loss: 0.2688992457389183
Validation loss: 2.280878795091112

Epoch: 601| Step: 0
Training loss: 0.22718175576463395
Validation loss: 2.271809538488469

Epoch: 5| Step: 1
Training loss: 0.13331302824107985
Validation loss: 2.272574094428129

Epoch: 5| Step: 2
Training loss: 0.21687468429784307
Validation loss: 2.2718908739960737

Epoch: 5| Step: 3
Training loss: 0.2944579865582371
Validation loss: 2.3076254040501656

Epoch: 5| Step: 4
Training loss: 0.16751815549826596
Validation loss: 2.3024773691786606

Epoch: 5| Step: 5
Training loss: 0.22311947137196755
Validation loss: 2.312103654907503

Epoch: 5| Step: 6
Training loss: 0.1627969637210691
Validation loss: 2.312760884081612

Epoch: 5| Step: 7
Training loss: 0.24851853290716555
Validation loss: 2.347418433113636

Epoch: 5| Step: 8
Training loss: 0.2280252934431085
Validation loss: 2.321457807069897

Epoch: 5| Step: 9
Training loss: 0.11265567994998613
Validation loss: 2.2966593265182484

Epoch: 5| Step: 10
Training loss: 0.20034902300669033
Validation loss: 2.2823534875850027

Epoch: 602| Step: 0
Training loss: 0.2285139947816784
Validation loss: 2.301014386200771

Epoch: 5| Step: 1
Training loss: 0.25472489942462
Validation loss: 2.3013347662796004

Epoch: 5| Step: 2
Training loss: 0.24441714077121116
Validation loss: 2.279390709327886

Epoch: 5| Step: 3
Training loss: 0.10320654195634381
Validation loss: 2.3095657170639

Epoch: 5| Step: 4
Training loss: 0.16018211341996422
Validation loss: 2.295913608933396

Epoch: 5| Step: 5
Training loss: 0.14412518757181791
Validation loss: 2.3200603171424237

Epoch: 5| Step: 6
Training loss: 0.2096196972341765
Validation loss: 2.322682083037161

Epoch: 5| Step: 7
Training loss: 0.2372642451231432
Validation loss: 2.3078748584062136

Epoch: 5| Step: 8
Training loss: 0.11242394956380487
Validation loss: 2.3023041896832153

Epoch: 5| Step: 9
Training loss: 0.1316240515307953
Validation loss: 2.2892827873624744

Epoch: 5| Step: 10
Training loss: 0.14260694134197688
Validation loss: 2.3025672154232653

Epoch: 603| Step: 0
Training loss: 0.16292594439849042
Validation loss: 2.2905278121502133

Epoch: 5| Step: 1
Training loss: 0.2148959876624062
Validation loss: 2.2665133739146617

Epoch: 5| Step: 2
Training loss: 0.21492072373764434
Validation loss: 2.275391394523368

Epoch: 5| Step: 3
Training loss: 0.2098827038879511
Validation loss: 2.258897522576952

Epoch: 5| Step: 4
Training loss: 0.19034381788857252
Validation loss: 2.2730454140364635

Epoch: 5| Step: 5
Training loss: 0.2954281131551624
Validation loss: 2.275411609347101

Epoch: 5| Step: 6
Training loss: 0.25438915693643105
Validation loss: 2.3062229209484224

Epoch: 5| Step: 7
Training loss: 0.12988943068773107
Validation loss: 2.295975385121872

Epoch: 5| Step: 8
Training loss: 0.11829140004810673
Validation loss: 2.291679655991003

Epoch: 5| Step: 9
Training loss: 0.12413090082617602
Validation loss: 2.295208179189

Epoch: 5| Step: 10
Training loss: 0.15432950169828957
Validation loss: 2.2643293574898604

Epoch: 604| Step: 0
Training loss: 0.1568640563764823
Validation loss: 2.2916856632582636

Epoch: 5| Step: 1
Training loss: 0.0976609419649223
Validation loss: 2.2834730690591627

Epoch: 5| Step: 2
Training loss: 0.1367367868787243
Validation loss: 2.294117261824418

Epoch: 5| Step: 3
Training loss: 0.13447249363354039
Validation loss: 2.2821508750788344

Epoch: 5| Step: 4
Training loss: 0.24172316153260465
Validation loss: 2.2611143353868317

Epoch: 5| Step: 5
Training loss: 0.29194118858151763
Validation loss: 2.261666764048283

Epoch: 5| Step: 6
Training loss: 0.15979270845402685
Validation loss: 2.2829835603463895

Epoch: 5| Step: 7
Training loss: 0.22558354298034985
Validation loss: 2.314457467599802

Epoch: 5| Step: 8
Training loss: 0.10941358294478942
Validation loss: 2.332588081913846

Epoch: 5| Step: 9
Training loss: 0.23926611905372983
Validation loss: 2.309973104135059

Epoch: 5| Step: 10
Training loss: 0.16261896789917668
Validation loss: 2.309496966472155

Epoch: 605| Step: 0
Training loss: 0.17568168999582467
Validation loss: 2.314718326680916

Epoch: 5| Step: 1
Training loss: 0.1266306302281902
Validation loss: 2.2902948582424565

Epoch: 5| Step: 2
Training loss: 0.29388030337680177
Validation loss: 2.315441977372453

Epoch: 5| Step: 3
Training loss: 0.21820808451445736
Validation loss: 2.2954402848950037

Epoch: 5| Step: 4
Training loss: 0.26063755522018406
Validation loss: 2.306449951233234

Epoch: 5| Step: 5
Training loss: 0.12458956285903394
Validation loss: 2.3446976679800144

Epoch: 5| Step: 6
Training loss: 0.2444947535423903
Validation loss: 2.3465723978283037

Epoch: 5| Step: 7
Training loss: 0.27166241358478005
Validation loss: 2.356611324866453

Epoch: 5| Step: 8
Training loss: 0.15785052011471845
Validation loss: 2.3217368948310324

Epoch: 5| Step: 9
Training loss: 0.13656486979464488
Validation loss: 2.316519366856537

Epoch: 5| Step: 10
Training loss: 0.18304417919562285
Validation loss: 2.302243171265242

Epoch: 606| Step: 0
Training loss: 0.18776411091683784
Validation loss: 2.282847127608071

Epoch: 5| Step: 1
Training loss: 0.2466930026389512
Validation loss: 2.280264568124962

Epoch: 5| Step: 2
Training loss: 0.30351707428692953
Validation loss: 2.284786869664681

Epoch: 5| Step: 3
Training loss: 0.29098413284210567
Validation loss: 2.2855199829545008

Epoch: 5| Step: 4
Training loss: 0.19704914489726078
Validation loss: 2.3055872453130277

Epoch: 5| Step: 5
Training loss: 0.22399894028332074
Validation loss: 2.2826042207010646

Epoch: 5| Step: 6
Training loss: 0.2018732787433857
Validation loss: 2.292043355614269

Epoch: 5| Step: 7
Training loss: 0.14529374396374645
Validation loss: 2.2971516416714075

Epoch: 5| Step: 8
Training loss: 0.24299010216703937
Validation loss: 2.307932817649166

Epoch: 5| Step: 9
Training loss: 0.14652798957028482
Validation loss: 2.2929827702326286

Epoch: 5| Step: 10
Training loss: 0.15561543594218025
Validation loss: 2.3164960068446985

Epoch: 607| Step: 0
Training loss: 0.23852742876570135
Validation loss: 2.2944747329315476

Epoch: 5| Step: 1
Training loss: 0.16945953610270628
Validation loss: 2.3052550437242156

Epoch: 5| Step: 2
Training loss: 0.1422093076016844
Validation loss: 2.2932256811915437

Epoch: 5| Step: 3
Training loss: 0.24367125596398637
Validation loss: 2.337349392847897

Epoch: 5| Step: 4
Training loss: 0.17258582189102864
Validation loss: 2.3052903332622785

Epoch: 5| Step: 5
Training loss: 0.18609281832752456
Validation loss: 2.319314490607193

Epoch: 5| Step: 6
Training loss: 0.21137950646296186
Validation loss: 2.345002687456488

Epoch: 5| Step: 7
Training loss: 0.2575052048333062
Validation loss: 2.318838280473069

Epoch: 5| Step: 8
Training loss: 0.1754242291362619
Validation loss: 2.299997814840854

Epoch: 5| Step: 9
Training loss: 0.14982759059413278
Validation loss: 2.2928759728072285

Epoch: 5| Step: 10
Training loss: 0.19666872268614985
Validation loss: 2.2585298880487823

Epoch: 608| Step: 0
Training loss: 0.13553243664623774
Validation loss: 2.340759287773986

Epoch: 5| Step: 1
Training loss: 0.2782972627431139
Validation loss: 2.308075232747602

Epoch: 5| Step: 2
Training loss: 0.24865350359984095
Validation loss: 2.2673243869586623

Epoch: 5| Step: 3
Training loss: 0.15945314543787945
Validation loss: 2.3022116845833747

Epoch: 5| Step: 4
Training loss: 0.30561887998245646
Validation loss: 2.3164419872033455

Epoch: 5| Step: 5
Training loss: 0.1467812010359119
Validation loss: 2.264872196265077

Epoch: 5| Step: 6
Training loss: 0.15203951142771469
Validation loss: 2.306302246365444

Epoch: 5| Step: 7
Training loss: 0.14486785303364227
Validation loss: 2.289897346060374

Epoch: 5| Step: 8
Training loss: 0.1421164654834041
Validation loss: 2.2880924090958117

Epoch: 5| Step: 9
Training loss: 0.21932732657754456
Validation loss: 2.2530471279924855

Epoch: 5| Step: 10
Training loss: 0.17604583325242454
Validation loss: 2.263101131954063

Epoch: 609| Step: 0
Training loss: 0.11739827512812491
Validation loss: 2.2834707147694373

Epoch: 5| Step: 1
Training loss: 0.16453109532898735
Validation loss: 2.254718153085303

Epoch: 5| Step: 2
Training loss: 0.10574124596877317
Validation loss: 2.274343833380996

Epoch: 5| Step: 3
Training loss: 0.1450420965755257
Validation loss: 2.2867733433808546

Epoch: 5| Step: 4
Training loss: 0.1674003019954978
Validation loss: 2.3017211066337335

Epoch: 5| Step: 5
Training loss: 0.21289709938773588
Validation loss: 2.2924819952050126

Epoch: 5| Step: 6
Training loss: 0.23137253208482628
Validation loss: 2.3376642245488055

Epoch: 5| Step: 7
Training loss: 0.24413169081553326
Validation loss: 2.3269903899684907

Epoch: 5| Step: 8
Training loss: 0.21141409015708199
Validation loss: 2.3323705579624714

Epoch: 5| Step: 9
Training loss: 0.13657102778626976
Validation loss: 2.3316851990383642

Epoch: 5| Step: 10
Training loss: 0.267846550618503
Validation loss: 2.3013072686358704

Epoch: 610| Step: 0
Training loss: 0.11585249638603877
Validation loss: 2.3234660729773853

Epoch: 5| Step: 1
Training loss: 0.1662612164359854
Validation loss: 2.3129571736034538

Epoch: 5| Step: 2
Training loss: 0.19477869520159763
Validation loss: 2.3656125358809885

Epoch: 5| Step: 3
Training loss: 0.13148003327924224
Validation loss: 2.3565766901739806

Epoch: 5| Step: 4
Training loss: 0.36653448435204977
Validation loss: 2.342717311414072

Epoch: 5| Step: 5
Training loss: 0.1578700656991899
Validation loss: 2.35556319102918

Epoch: 5| Step: 6
Training loss: 0.13907534373902805
Validation loss: 2.3300450692132566

Epoch: 5| Step: 7
Training loss: 0.12202219586968258
Validation loss: 2.3182628610223692

Epoch: 5| Step: 8
Training loss: 0.21732503117923477
Validation loss: 2.3335766233305035

Epoch: 5| Step: 9
Training loss: 0.12949213629213818
Validation loss: 2.3042137497517783

Epoch: 5| Step: 10
Training loss: 0.22295514339907793
Validation loss: 2.320189716008251

Epoch: 611| Step: 0
Training loss: 0.10995803985030131
Validation loss: 2.2966831940020356

Epoch: 5| Step: 1
Training loss: 0.2918513669732388
Validation loss: 2.3251760696411683

Epoch: 5| Step: 2
Training loss: 0.09732023127236199
Validation loss: 2.3217075551905744

Epoch: 5| Step: 3
Training loss: 0.0954253486243414
Validation loss: 2.3146558389069254

Epoch: 5| Step: 4
Training loss: 0.19108390913769951
Validation loss: 2.3202129027888625

Epoch: 5| Step: 5
Training loss: 0.22027327445359546
Validation loss: 2.3329085990388054

Epoch: 5| Step: 6
Training loss: 0.13499707236471037
Validation loss: 2.3125411475904456

Epoch: 5| Step: 7
Training loss: 0.23589561229516787
Validation loss: 2.308428274088548

Epoch: 5| Step: 8
Training loss: 0.2062609575713168
Validation loss: 2.3081825403300953

Epoch: 5| Step: 9
Training loss: 0.12857868015894014
Validation loss: 2.3025565759047537

Epoch: 5| Step: 10
Training loss: 0.13868798578726504
Validation loss: 2.29973306332947

Epoch: 612| Step: 0
Training loss: 0.15863819110378058
Validation loss: 2.321601102990207

Epoch: 5| Step: 1
Training loss: 0.24050889960881747
Validation loss: 2.289035962018267

Epoch: 5| Step: 2
Training loss: 0.2326617405629756
Validation loss: 2.3051781884405074

Epoch: 5| Step: 3
Training loss: 0.23457018354350412
Validation loss: 2.3080020452539274

Epoch: 5| Step: 4
Training loss: 0.16739387609179882
Validation loss: 2.2929389170299346

Epoch: 5| Step: 5
Training loss: 0.1551620155600113
Validation loss: 2.2820822556984948

Epoch: 5| Step: 6
Training loss: 0.19338056660131916
Validation loss: 2.243913069200352

Epoch: 5| Step: 7
Training loss: 0.14290140030008303
Validation loss: 2.277246205808501

Epoch: 5| Step: 8
Training loss: 0.14794098481786633
Validation loss: 2.25214021850764

Epoch: 5| Step: 9
Training loss: 0.27935090242697225
Validation loss: 2.260370234664734

Epoch: 5| Step: 10
Training loss: 0.08238577300640283
Validation loss: 2.2544512135835855

Epoch: 613| Step: 0
Training loss: 0.11344750716860226
Validation loss: 2.289961259930418

Epoch: 5| Step: 1
Training loss: 0.33655902012448996
Validation loss: 2.2746946005896245

Epoch: 5| Step: 2
Training loss: 0.14564222489759107
Validation loss: 2.314601328158024

Epoch: 5| Step: 3
Training loss: 0.21679419438534903
Validation loss: 2.348263451242779

Epoch: 5| Step: 4
Training loss: 0.19191298262627937
Validation loss: 2.3254511448084454

Epoch: 5| Step: 5
Training loss: 0.1476204054078701
Validation loss: 2.3527716099437153

Epoch: 5| Step: 6
Training loss: 0.12479842219498717
Validation loss: 2.346164200500951

Epoch: 5| Step: 7
Training loss: 0.14317030275075435
Validation loss: 2.303313312085854

Epoch: 5| Step: 8
Training loss: 0.19630349518964982
Validation loss: 2.301904073259878

Epoch: 5| Step: 9
Training loss: 0.1919566240872838
Validation loss: 2.2802646164687146

Epoch: 5| Step: 10
Training loss: 0.08769886236928441
Validation loss: 2.289231473274754

Epoch: 614| Step: 0
Training loss: 0.14912485044252838
Validation loss: 2.2975565569034755

Epoch: 5| Step: 1
Training loss: 0.10414821391775214
Validation loss: 2.2905561454282273

Epoch: 5| Step: 2
Training loss: 0.22800683985142095
Validation loss: 2.2555505130674818

Epoch: 5| Step: 3
Training loss: 0.26951770472007497
Validation loss: 2.270298981789877

Epoch: 5| Step: 4
Training loss: 0.3230922962255265
Validation loss: 2.276535871663357

Epoch: 5| Step: 5
Training loss: 0.11000812307486924
Validation loss: 2.2967164531313267

Epoch: 5| Step: 6
Training loss: 0.133382653326059
Validation loss: 2.320198580821927

Epoch: 5| Step: 7
Training loss: 0.09394471491506619
Validation loss: 2.305394943167368

Epoch: 5| Step: 8
Training loss: 0.119776265218522
Validation loss: 2.305265809798497

Epoch: 5| Step: 9
Training loss: 0.15991956387682207
Validation loss: 2.285966440768901

Epoch: 5| Step: 10
Training loss: 0.1768967835623157
Validation loss: 2.3429843866245235

Epoch: 615| Step: 0
Training loss: 0.17542305054019722
Validation loss: 2.328443490708666

Epoch: 5| Step: 1
Training loss: 0.1563878524165573
Validation loss: 2.295267810323794

Epoch: 5| Step: 2
Training loss: 0.18736314746315477
Validation loss: 2.2872235781662775

Epoch: 5| Step: 3
Training loss: 0.3011749217946744
Validation loss: 2.287351070482414

Epoch: 5| Step: 4
Training loss: 0.15723629441559156
Validation loss: 2.2779313223378166

Epoch: 5| Step: 5
Training loss: 0.10837951701231557
Validation loss: 2.260671132780875

Epoch: 5| Step: 6
Training loss: 0.2013896670591367
Validation loss: 2.3058724629018528

Epoch: 5| Step: 7
Training loss: 0.15060768316770912
Validation loss: 2.300983024758343

Epoch: 5| Step: 8
Training loss: 0.23919842819964096
Validation loss: 2.335038139878664

Epoch: 5| Step: 9
Training loss: 0.16403405192644363
Validation loss: 2.3304186430519973

Epoch: 5| Step: 10
Training loss: 0.20938561149295723
Validation loss: 2.3383336015178298

Epoch: 616| Step: 0
Training loss: 0.35081451105397354
Validation loss: 2.3701732899321675

Epoch: 5| Step: 1
Training loss: 0.1727338648805371
Validation loss: 2.336871765427784

Epoch: 5| Step: 2
Training loss: 0.14331607060615506
Validation loss: 2.312614216377075

Epoch: 5| Step: 3
Training loss: 0.11644885208472935
Validation loss: 2.2727858789313826

Epoch: 5| Step: 4
Training loss: 0.1841297644292039
Validation loss: 2.2624561421819753

Epoch: 5| Step: 5
Training loss: 0.16477879198043494
Validation loss: 2.2975690188133693

Epoch: 5| Step: 6
Training loss: 0.19369614298672497
Validation loss: 2.269031243590666

Epoch: 5| Step: 7
Training loss: 0.20115255985309516
Validation loss: 2.234731287667104

Epoch: 5| Step: 8
Training loss: 0.1628570778238315
Validation loss: 2.2847536865359173

Epoch: 5| Step: 9
Training loss: 0.09928276707622122
Validation loss: 2.3349537339224646

Epoch: 5| Step: 10
Training loss: 0.14594621986583706
Validation loss: 2.362576340685885

Epoch: 617| Step: 0
Training loss: 0.21590758410411687
Validation loss: 2.336212539847014

Epoch: 5| Step: 1
Training loss: 0.10241814704762232
Validation loss: 2.3575475317231556

Epoch: 5| Step: 2
Training loss: 0.2575205392423597
Validation loss: 2.3816562950744715

Epoch: 5| Step: 3
Training loss: 0.21374377517671045
Validation loss: 2.3610375260989547

Epoch: 5| Step: 4
Training loss: 0.2312458965865348
Validation loss: 2.3536791101016186

Epoch: 5| Step: 5
Training loss: 0.08132568408388552
Validation loss: 2.3165013544980813

Epoch: 5| Step: 6
Training loss: 0.156301126460225
Validation loss: 2.3445975003966883

Epoch: 5| Step: 7
Training loss: 0.25329153034166585
Validation loss: 2.3151667627154078

Epoch: 5| Step: 8
Training loss: 0.1600007604975806
Validation loss: 2.2924882525416583

Epoch: 5| Step: 9
Training loss: 0.2495281863517176
Validation loss: 2.3015690020490043

Epoch: 5| Step: 10
Training loss: 0.2409167870723349
Validation loss: 2.3296635360191185

Epoch: 618| Step: 0
Training loss: 0.15308336913301876
Validation loss: 2.333440276814021

Epoch: 5| Step: 1
Training loss: 0.16568792200556384
Validation loss: 2.3261288976711008

Epoch: 5| Step: 2
Training loss: 0.147296175583085
Validation loss: 2.334991745416532

Epoch: 5| Step: 3
Training loss: 0.25647799130413346
Validation loss: 2.341949473518671

Epoch: 5| Step: 4
Training loss: 0.18045949953489676
Validation loss: 2.34199117480362

Epoch: 5| Step: 5
Training loss: 0.24875669217572485
Validation loss: 2.3428207081028525

Epoch: 5| Step: 6
Training loss: 0.20655247371076932
Validation loss: 2.3257301758233533

Epoch: 5| Step: 7
Training loss: 0.2677204282727386
Validation loss: 2.2871292015459055

Epoch: 5| Step: 8
Training loss: 0.1278272466150256
Validation loss: 2.2905049337377954

Epoch: 5| Step: 9
Training loss: 0.32044954392098196
Validation loss: 2.302244565417321

Epoch: 5| Step: 10
Training loss: 0.1461851497068166
Validation loss: 2.27368397277537

Epoch: 619| Step: 0
Training loss: 0.13972605702237056
Validation loss: 2.305715778619325

Epoch: 5| Step: 1
Training loss: 0.10462646235135648
Validation loss: 2.2892791736215656

Epoch: 5| Step: 2
Training loss: 0.1800559557758631
Validation loss: 2.300237037113015

Epoch: 5| Step: 3
Training loss: 0.16400092536204358
Validation loss: 2.3384126933269918

Epoch: 5| Step: 4
Training loss: 0.19080802307849506
Validation loss: 2.332470056447368

Epoch: 5| Step: 5
Training loss: 0.17533226422811443
Validation loss: 2.321584853814618

Epoch: 5| Step: 6
Training loss: 0.22766031464539646
Validation loss: 2.3478688724284815

Epoch: 5| Step: 7
Training loss: 0.18139612498190025
Validation loss: 2.3098848528095277

Epoch: 5| Step: 8
Training loss: 0.2850496275675371
Validation loss: 2.2925319086056457

Epoch: 5| Step: 9
Training loss: 0.15704790473033375
Validation loss: 2.2568198729140456

Epoch: 5| Step: 10
Training loss: 0.15176197375234662
Validation loss: 2.282783461522053

Epoch: 620| Step: 0
Training loss: 0.15993024417462967
Validation loss: 2.2630314937107148

Epoch: 5| Step: 1
Training loss: 0.1840133640104732
Validation loss: 2.236172999703026

Epoch: 5| Step: 2
Training loss: 0.2493922625090528
Validation loss: 2.2519034414966366

Epoch: 5| Step: 3
Training loss: 0.15467039601333435
Validation loss: 2.2652185301045313

Epoch: 5| Step: 4
Training loss: 0.11272672879730718
Validation loss: 2.283279763349248

Epoch: 5| Step: 5
Training loss: 0.29662535862472983
Validation loss: 2.272517017763445

Epoch: 5| Step: 6
Training loss: 0.1834731517537263
Validation loss: 2.238624362768207

Epoch: 5| Step: 7
Training loss: 0.13735632732509123
Validation loss: 2.2627449828074737

Epoch: 5| Step: 8
Training loss: 0.14775421964482302
Validation loss: 2.2182276560234215

Epoch: 5| Step: 9
Training loss: 0.1540395304829523
Validation loss: 2.2477090764827743

Epoch: 5| Step: 10
Training loss: 0.2373328800487297
Validation loss: 2.239823922019168

Epoch: 621| Step: 0
Training loss: 0.11458584979574064
Validation loss: 2.277612121593202

Epoch: 5| Step: 1
Training loss: 0.1101706338176027
Validation loss: 2.250501009491189

Epoch: 5| Step: 2
Training loss: 0.09857704455590319
Validation loss: 2.259872488593126

Epoch: 5| Step: 3
Training loss: 0.25165298978692036
Validation loss: 2.2927088693547693

Epoch: 5| Step: 4
Training loss: 0.10860065980237937
Validation loss: 2.2558325753983732

Epoch: 5| Step: 5
Training loss: 0.23352938533964
Validation loss: 2.2889389060157352

Epoch: 5| Step: 6
Training loss: 0.18374051659952914
Validation loss: 2.2730210225872947

Epoch: 5| Step: 7
Training loss: 0.19084726180410166
Validation loss: 2.2731907546463392

Epoch: 5| Step: 8
Training loss: 0.10724799648966693
Validation loss: 2.270916276741424

Epoch: 5| Step: 9
Training loss: 0.18101293541264699
Validation loss: 2.3234205524881792

Epoch: 5| Step: 10
Training loss: 0.19564193598954885
Validation loss: 2.2684827179932667

Epoch: 622| Step: 0
Training loss: 0.08498377054700527
Validation loss: 2.250475189546326

Epoch: 5| Step: 1
Training loss: 0.16792685518540523
Validation loss: 2.3017452056446386

Epoch: 5| Step: 2
Training loss: 0.15789550142340986
Validation loss: 2.3015754947677425

Epoch: 5| Step: 3
Training loss: 0.15186144212952007
Validation loss: 2.296670145165242

Epoch: 5| Step: 4
Training loss: 0.2310496138646858
Validation loss: 2.2827506384072915

Epoch: 5| Step: 5
Training loss: 0.08909121769812273
Validation loss: 2.273330313825468

Epoch: 5| Step: 6
Training loss: 0.18586261387264225
Validation loss: 2.2790407953833305

Epoch: 5| Step: 7
Training loss: 0.13819746345494968
Validation loss: 2.3068666712313797

Epoch: 5| Step: 8
Training loss: 0.29662706663116695
Validation loss: 2.331506549276091

Epoch: 5| Step: 9
Training loss: 0.17717382045195493
Validation loss: 2.3068132816842732

Epoch: 5| Step: 10
Training loss: 0.16108887969386962
Validation loss: 2.3084665302309793

Epoch: 623| Step: 0
Training loss: 0.24382739000047704
Validation loss: 2.3024697900681073

Epoch: 5| Step: 1
Training loss: 0.15445705742622448
Validation loss: 2.328207112133579

Epoch: 5| Step: 2
Training loss: 0.13923143936964927
Validation loss: 2.323457174840359

Epoch: 5| Step: 3
Training loss: 0.17565398907763044
Validation loss: 2.259541918754911

Epoch: 5| Step: 4
Training loss: 0.1168146958677964
Validation loss: 2.2742611540039763

Epoch: 5| Step: 5
Training loss: 0.12692081333661714
Validation loss: 2.2829103629439307

Epoch: 5| Step: 6
Training loss: 0.23000284559884118
Validation loss: 2.289327496995715

Epoch: 5| Step: 7
Training loss: 0.22895840190704772
Validation loss: 2.277539340257662

Epoch: 5| Step: 8
Training loss: 0.1294560340250608
Validation loss: 2.2867151645396704

Epoch: 5| Step: 9
Training loss: 0.1454734889773562
Validation loss: 2.3021192420256575

Epoch: 5| Step: 10
Training loss: 0.09616626372186121
Validation loss: 2.3472510794861416

Epoch: 624| Step: 0
Training loss: 0.19578301974666526
Validation loss: 2.293042818120387

Epoch: 5| Step: 1
Training loss: 0.09299233361852614
Validation loss: 2.299494353867518

Epoch: 5| Step: 2
Training loss: 0.1845904747985767
Validation loss: 2.3478859267700294

Epoch: 5| Step: 3
Training loss: 0.11767923975250717
Validation loss: 2.299265992882891

Epoch: 5| Step: 4
Training loss: 0.1384160879574417
Validation loss: 2.304853047605225

Epoch: 5| Step: 5
Training loss: 0.17796133034288178
Validation loss: 2.2727444774409036

Epoch: 5| Step: 6
Training loss: 0.1490337668222563
Validation loss: 2.312958177243347

Epoch: 5| Step: 7
Training loss: 0.09749004525631805
Validation loss: 2.329213964308693

Epoch: 5| Step: 8
Training loss: 0.2414721260185313
Validation loss: 2.29745167210894

Epoch: 5| Step: 9
Training loss: 0.07350022320851345
Validation loss: 2.310510844676465

Epoch: 5| Step: 10
Training loss: 0.2702505217043405
Validation loss: 2.3108883590480507

Epoch: 625| Step: 0
Training loss: 0.1242811761397367
Validation loss: 2.3133998102457483

Epoch: 5| Step: 1
Training loss: 0.09363105798540822
Validation loss: 2.3215946430869256

Epoch: 5| Step: 2
Training loss: 0.10529715654766018
Validation loss: 2.332573192979619

Epoch: 5| Step: 3
Training loss: 0.19589568808424218
Validation loss: 2.3347722032392464

Epoch: 5| Step: 4
Training loss: 0.15539112069888522
Validation loss: 2.3214186639900016

Epoch: 5| Step: 5
Training loss: 0.1226159565642939
Validation loss: 2.3420402892089083

Epoch: 5| Step: 6
Training loss: 0.22945443512461686
Validation loss: 2.344713203188581

Epoch: 5| Step: 7
Training loss: 0.2253087971207123
Validation loss: 2.2699466662809034

Epoch: 5| Step: 8
Training loss: 0.2027904249265218
Validation loss: 2.3064438979454898

Epoch: 5| Step: 9
Training loss: 0.1393052131480751
Validation loss: 2.3185689847476194

Epoch: 5| Step: 10
Training loss: 0.16979402906631025
Validation loss: 2.334057769259859

Epoch: 626| Step: 0
Training loss: 0.12451481908790399
Validation loss: 2.276405502129711

Epoch: 5| Step: 1
Training loss: 0.1710528738583845
Validation loss: 2.3029431387583728

Epoch: 5| Step: 2
Training loss: 0.11794060077568438
Validation loss: 2.260515814108986

Epoch: 5| Step: 3
Training loss: 0.22003166209310834
Validation loss: 2.272258375381861

Epoch: 5| Step: 4
Training loss: 0.08534404276319565
Validation loss: 2.273565980752322

Epoch: 5| Step: 5
Training loss: 0.13774173711487062
Validation loss: 2.280361293491431

Epoch: 5| Step: 6
Training loss: 0.1393286905845122
Validation loss: 2.2896500523259733

Epoch: 5| Step: 7
Training loss: 0.12040298081649546
Validation loss: 2.256942134463693

Epoch: 5| Step: 8
Training loss: 0.14137485376901932
Validation loss: 2.307059378530426

Epoch: 5| Step: 9
Training loss: 0.16153337224369502
Validation loss: 2.2793372942432546

Epoch: 5| Step: 10
Training loss: 0.29775033700316966
Validation loss: 2.3282989362099555

Epoch: 627| Step: 0
Training loss: 0.24053577961224437
Validation loss: 2.313291267419072

Epoch: 5| Step: 1
Training loss: 0.12832252959218754
Validation loss: 2.3108211310843707

Epoch: 5| Step: 2
Training loss: 0.12883578166104456
Validation loss: 2.3062905219401757

Epoch: 5| Step: 3
Training loss: 0.17972880386317985
Validation loss: 2.2970122368263697

Epoch: 5| Step: 4
Training loss: 0.16147811189122527
Validation loss: 2.256031181726358

Epoch: 5| Step: 5
Training loss: 0.21983082311022284
Validation loss: 2.267936644637165

Epoch: 5| Step: 6
Training loss: 0.09762670546890721
Validation loss: 2.2838949866167684

Epoch: 5| Step: 7
Training loss: 0.10158836970607686
Validation loss: 2.2579646529947923

Epoch: 5| Step: 8
Training loss: 0.2581795333957423
Validation loss: 2.2605506816038186

Epoch: 5| Step: 9
Training loss: 0.11703967466449548
Validation loss: 2.252538582034793

Epoch: 5| Step: 10
Training loss: 0.16286856618581227
Validation loss: 2.2842736719685126

Epoch: 628| Step: 0
Training loss: 0.1518031026943891
Validation loss: 2.2794697662371015

Epoch: 5| Step: 1
Training loss: 0.13193062101977993
Validation loss: 2.28487209155133

Epoch: 5| Step: 2
Training loss: 0.13216197353569548
Validation loss: 2.2909439543304626

Epoch: 5| Step: 3
Training loss: 0.10964868992612327
Validation loss: 2.2980491020856153

Epoch: 5| Step: 4
Training loss: 0.22301842696827667
Validation loss: 2.2677369036665573

Epoch: 5| Step: 5
Training loss: 0.09706369872559663
Validation loss: 2.279943187686207

Epoch: 5| Step: 6
Training loss: 0.23148035033709052
Validation loss: 2.272172103845628

Epoch: 5| Step: 7
Training loss: 0.25568344532323634
Validation loss: 2.3124915280529197

Epoch: 5| Step: 8
Training loss: 0.2054177423991291
Validation loss: 2.2795013106322433

Epoch: 5| Step: 9
Training loss: 0.11880133344373742
Validation loss: 2.2977521643266874

Epoch: 5| Step: 10
Training loss: 0.20479985385846255
Validation loss: 2.2904350871868746

Epoch: 629| Step: 0
Training loss: 0.1396298362774597
Validation loss: 2.2871489914910423

Epoch: 5| Step: 1
Training loss: 0.12016571429298933
Validation loss: 2.298534225679782

Epoch: 5| Step: 2
Training loss: 0.1766031178450445
Validation loss: 2.2975687393040216

Epoch: 5| Step: 3
Training loss: 0.21833098675714133
Validation loss: 2.3326925045589606

Epoch: 5| Step: 4
Training loss: 0.2365897913248793
Validation loss: 2.328832769410663

Epoch: 5| Step: 5
Training loss: 0.20797425657587243
Validation loss: 2.309539984672805

Epoch: 5| Step: 6
Training loss: 0.1146148011678953
Validation loss: 2.36719181462864

Epoch: 5| Step: 7
Training loss: 0.17098027585873174
Validation loss: 2.3474395435172863

Epoch: 5| Step: 8
Training loss: 0.1412970853915974
Validation loss: 2.2987478301464788

Epoch: 5| Step: 9
Training loss: 0.09371559684049816
Validation loss: 2.3230227471881464

Epoch: 5| Step: 10
Training loss: 0.10042250883930104
Validation loss: 2.330040419536614

Epoch: 630| Step: 0
Training loss: 0.1695409429213941
Validation loss: 2.3420986404051694

Epoch: 5| Step: 1
Training loss: 0.28046308474543724
Validation loss: 2.3452164140404785

Epoch: 5| Step: 2
Training loss: 0.09106798139594292
Validation loss: 2.3155557032073424

Epoch: 5| Step: 3
Training loss: 0.10710830003461916
Validation loss: 2.353679851305961

Epoch: 5| Step: 4
Training loss: 0.08814046371088823
Validation loss: 2.311550665001098

Epoch: 5| Step: 5
Training loss: 0.14990154850155504
Validation loss: 2.3441655611637584

Epoch: 5| Step: 6
Training loss: 0.21152468475791256
Validation loss: 2.3250212576771276

Epoch: 5| Step: 7
Training loss: 0.20688273843254198
Validation loss: 2.319159518394729

Epoch: 5| Step: 8
Training loss: 0.12041641970862679
Validation loss: 2.2987417772085768

Epoch: 5| Step: 9
Training loss: 0.12000049567368576
Validation loss: 2.2936671652887055

Epoch: 5| Step: 10
Training loss: 0.09749045125804774
Validation loss: 2.3187468158759876

Epoch: 631| Step: 0
Training loss: 0.11413306574819813
Validation loss: 2.3106378176401696

Epoch: 5| Step: 1
Training loss: 0.21853940908637512
Validation loss: 2.33458097088181

Epoch: 5| Step: 2
Training loss: 0.11959407455010555
Validation loss: 2.3030305312403065

Epoch: 5| Step: 3
Training loss: 0.13150756348136677
Validation loss: 2.281965537126211

Epoch: 5| Step: 4
Training loss: 0.10274518503674021
Validation loss: 2.2703815186468934

Epoch: 5| Step: 5
Training loss: 0.1895413537410362
Validation loss: 2.3029180637494764

Epoch: 5| Step: 6
Training loss: 0.18456438852319929
Validation loss: 2.3063939438211993

Epoch: 5| Step: 7
Training loss: 0.2124706027088611
Validation loss: 2.3195162049267726

Epoch: 5| Step: 8
Training loss: 0.17018857393195605
Validation loss: 2.318644120788858

Epoch: 5| Step: 9
Training loss: 0.1732205584935933
Validation loss: 2.3043591148058367

Epoch: 5| Step: 10
Training loss: 0.1705741148219846
Validation loss: 2.284805902886355

Epoch: 632| Step: 0
Training loss: 0.12900143779093845
Validation loss: 2.288109296950356

Epoch: 5| Step: 1
Training loss: 0.17606352288568888
Validation loss: 2.320125006704107

Epoch: 5| Step: 2
Training loss: 0.09438442599200435
Validation loss: 2.3280334157328952

Epoch: 5| Step: 3
Training loss: 0.22893531276315185
Validation loss: 2.3151889794118152

Epoch: 5| Step: 4
Training loss: 0.14476621061557626
Validation loss: 2.3113238784086167

Epoch: 5| Step: 5
Training loss: 0.17883563251326873
Validation loss: 2.314231802785607

Epoch: 5| Step: 6
Training loss: 0.13480809827815593
Validation loss: 2.2865138119459214

Epoch: 5| Step: 7
Training loss: 0.21010579279880406
Validation loss: 2.331552027348803

Epoch: 5| Step: 8
Training loss: 0.16731264363996276
Validation loss: 2.2889478285794884

Epoch: 5| Step: 9
Training loss: 0.22676461346766755
Validation loss: 2.2818207127330656

Epoch: 5| Step: 10
Training loss: 0.13032672427094363
Validation loss: 2.291162791936484

Epoch: 633| Step: 0
Training loss: 0.13049329252745226
Validation loss: 2.3572094704169753

Epoch: 5| Step: 1
Training loss: 0.2261905494451703
Validation loss: 2.302779896388391

Epoch: 5| Step: 2
Training loss: 0.13258180497411692
Validation loss: 2.3118894392377007

Epoch: 5| Step: 3
Training loss: 0.08363529224808558
Validation loss: 2.3043083522825034

Epoch: 5| Step: 4
Training loss: 0.19809024606757022
Validation loss: 2.33817709453414

Epoch: 5| Step: 5
Training loss: 0.2162053656269323
Validation loss: 2.3276300922151485

Epoch: 5| Step: 6
Training loss: 0.10659975694054757
Validation loss: 2.326712149421636

Epoch: 5| Step: 7
Training loss: 0.15604593541282713
Validation loss: 2.3477458250514944

Epoch: 5| Step: 8
Training loss: 0.23158971892938113
Validation loss: 2.3342221701561394

Epoch: 5| Step: 9
Training loss: 0.1560553172341103
Validation loss: 2.2859633056999944

Epoch: 5| Step: 10
Training loss: 0.23503438066533586
Validation loss: 2.3027762715432676

Epoch: 634| Step: 0
Training loss: 0.13843078879025905
Validation loss: 2.3011600809201003

Epoch: 5| Step: 1
Training loss: 0.11968767707702048
Validation loss: 2.2834844733524293

Epoch: 5| Step: 2
Training loss: 0.07001356980019477
Validation loss: 2.296812913156111

Epoch: 5| Step: 3
Training loss: 0.1763332019475584
Validation loss: 2.354735049290863

Epoch: 5| Step: 4
Training loss: 0.2147312389889516
Validation loss: 2.320310210710942

Epoch: 5| Step: 5
Training loss: 0.21050588283054325
Validation loss: 2.316625308363095

Epoch: 5| Step: 6
Training loss: 0.1812626073826308
Validation loss: 2.3311860334816186

Epoch: 5| Step: 7
Training loss: 0.16173866697573355
Validation loss: 2.315387624641037

Epoch: 5| Step: 8
Training loss: 0.14144469154893738
Validation loss: 2.3079119895902758

Epoch: 5| Step: 9
Training loss: 0.1836293977258851
Validation loss: 2.2916369110890313

Epoch: 5| Step: 10
Training loss: 0.1216702007495952
Validation loss: 2.3241399175149513

Epoch: 635| Step: 0
Training loss: 0.1448230439831037
Validation loss: 2.294329057837674

Epoch: 5| Step: 1
Training loss: 0.13958035656853135
Validation loss: 2.306102896348956

Epoch: 5| Step: 2
Training loss: 0.21907539518824126
Validation loss: 2.2991956693231534

Epoch: 5| Step: 3
Training loss: 0.15936670842760936
Validation loss: 2.3278884618876896

Epoch: 5| Step: 4
Training loss: 0.10313215845000478
Validation loss: 2.3198507084281856

Epoch: 5| Step: 5
Training loss: 0.0963798168768462
Validation loss: 2.322191720597581

Epoch: 5| Step: 6
Training loss: 0.1279910646505885
Validation loss: 2.3430464598556084

Epoch: 5| Step: 7
Training loss: 0.1309504690097801
Validation loss: 2.3269954508881296

Epoch: 5| Step: 8
Training loss: 0.2007462805044745
Validation loss: 2.3533031696045907

Epoch: 5| Step: 9
Training loss: 0.10487089870848368
Validation loss: 2.352827836686936

Epoch: 5| Step: 10
Training loss: 0.2528136145351442
Validation loss: 2.3285502394832265

Epoch: 636| Step: 0
Training loss: 0.08733149006141779
Validation loss: 2.320159594393394

Epoch: 5| Step: 1
Training loss: 0.16967625788862717
Validation loss: 2.34408283563877

Epoch: 5| Step: 2
Training loss: 0.13239035414090966
Validation loss: 2.317033933159497

Epoch: 5| Step: 3
Training loss: 0.21266500959496926
Validation loss: 2.2758493927720163

Epoch: 5| Step: 4
Training loss: 0.1360121519268698
Validation loss: 2.2983958962874182

Epoch: 5| Step: 5
Training loss: 0.17358297033858777
Validation loss: 2.319656725216155

Epoch: 5| Step: 6
Training loss: 0.08463647701137178
Validation loss: 2.2663114487301192

Epoch: 5| Step: 7
Training loss: 0.23812373223555497
Validation loss: 2.309336087906194

Epoch: 5| Step: 8
Training loss: 0.23696713713970247
Validation loss: 2.331289215272712

Epoch: 5| Step: 9
Training loss: 0.09852839126275079
Validation loss: 2.294366002080447

Epoch: 5| Step: 10
Training loss: 0.12259501413801614
Validation loss: 2.316292201792755

Epoch: 637| Step: 0
Training loss: 0.1546050205841543
Validation loss: 2.307198770219115

Epoch: 5| Step: 1
Training loss: 0.1821675809240768
Validation loss: 2.3180353331963954

Epoch: 5| Step: 2
Training loss: 0.23822936290443208
Validation loss: 2.318852655064221

Epoch: 5| Step: 3
Training loss: 0.1185730484722649
Validation loss: 2.3179596935508258

Epoch: 5| Step: 4
Training loss: 0.12484931804476844
Validation loss: 2.3059600681626016

Epoch: 5| Step: 5
Training loss: 0.12117740602493222
Validation loss: 2.315870806570223

Epoch: 5| Step: 6
Training loss: 0.2375249272365557
Validation loss: 2.2865056030610647

Epoch: 5| Step: 7
Training loss: 0.13572897263564526
Validation loss: 2.32402639112652

Epoch: 5| Step: 8
Training loss: 0.14685807561761224
Validation loss: 2.303002714326088

Epoch: 5| Step: 9
Training loss: 0.23304728503803393
Validation loss: 2.3090843710845443

Epoch: 5| Step: 10
Training loss: 0.22856011731901069
Validation loss: 2.3102242452897235

Epoch: 638| Step: 0
Training loss: 0.1768212810397637
Validation loss: 2.3310548293712454

Epoch: 5| Step: 1
Training loss: 0.17814674328389568
Validation loss: 2.3673055862955334

Epoch: 5| Step: 2
Training loss: 0.09314307810217183
Validation loss: 2.340411986597506

Epoch: 5| Step: 3
Training loss: 0.14526641586661226
Validation loss: 2.3548205109543567

Epoch: 5| Step: 4
Training loss: 0.10963985187985868
Validation loss: 2.305787212502754

Epoch: 5| Step: 5
Training loss: 0.09942399333224103
Validation loss: 2.3239651625843294

Epoch: 5| Step: 6
Training loss: 0.19781616549538342
Validation loss: 2.32163575040232

Epoch: 5| Step: 7
Training loss: 0.2099773844110176
Validation loss: 2.2957873112589096

Epoch: 5| Step: 8
Training loss: 0.26860557767558135
Validation loss: 2.2996501819761224

Epoch: 5| Step: 9
Training loss: 0.15673364056048258
Validation loss: 2.296573360443339

Epoch: 5| Step: 10
Training loss: 0.16842872824148666
Validation loss: 2.2952240192093303

Epoch: 639| Step: 0
Training loss: 0.1714433810042048
Validation loss: 2.3221234208256507

Epoch: 5| Step: 1
Training loss: 0.2329236712423274
Validation loss: 2.3132394053654926

Epoch: 5| Step: 2
Training loss: 0.250546558285957
Validation loss: 2.265600705750268

Epoch: 5| Step: 3
Training loss: 0.12044337418518218
Validation loss: 2.276418892924669

Epoch: 5| Step: 4
Training loss: 0.12813286262903373
Validation loss: 2.2946801155706873

Epoch: 5| Step: 5
Training loss: 0.12771067180665413
Validation loss: 2.2988224709565923

Epoch: 5| Step: 6
Training loss: 0.10611424889940423
Validation loss: 2.2502799572072076

Epoch: 5| Step: 7
Training loss: 0.23065141131198552
Validation loss: 2.291178653211015

Epoch: 5| Step: 8
Training loss: 0.1395362323200381
Validation loss: 2.317859988604622

Epoch: 5| Step: 9
Training loss: 0.22902419075670402
Validation loss: 2.3425263686959283

Epoch: 5| Step: 10
Training loss: 0.1326358897149976
Validation loss: 2.3259878387034143

Epoch: 640| Step: 0
Training loss: 0.14765222407710846
Validation loss: 2.308464492947458

Epoch: 5| Step: 1
Training loss: 0.1352543056220483
Validation loss: 2.2947436940201738

Epoch: 5| Step: 2
Training loss: 0.1624131458885446
Validation loss: 2.272406585606173

Epoch: 5| Step: 3
Training loss: 0.16824077602066298
Validation loss: 2.2991351342916193

Epoch: 5| Step: 4
Training loss: 0.15582439751959187
Validation loss: 2.267349506790215

Epoch: 5| Step: 5
Training loss: 0.13748612306751426
Validation loss: 2.2928968094291684

Epoch: 5| Step: 6
Training loss: 0.1897694807418656
Validation loss: 2.3043502641531273

Epoch: 5| Step: 7
Training loss: 0.2300657612274878
Validation loss: 2.24877276843093

Epoch: 5| Step: 8
Training loss: 0.24205601876375432
Validation loss: 2.250408147552317

Epoch: 5| Step: 9
Training loss: 0.13379934368865312
Validation loss: 2.2529107138390847

Epoch: 5| Step: 10
Training loss: 0.1269337565979659
Validation loss: 2.2596509525054906

Epoch: 641| Step: 0
Training loss: 0.2346014835886375
Validation loss: 2.2638428764927605

Epoch: 5| Step: 1
Training loss: 0.2164759279308086
Validation loss: 2.256047364426157

Epoch: 5| Step: 2
Training loss: 0.19772157758026682
Validation loss: 2.2663173773164145

Epoch: 5| Step: 3
Training loss: 0.19501903421169584
Validation loss: 2.27578589364982

Epoch: 5| Step: 4
Training loss: 0.14009132048648607
Validation loss: 2.287302555443846

Epoch: 5| Step: 5
Training loss: 0.11702322572057004
Validation loss: 2.2460558496731147

Epoch: 5| Step: 6
Training loss: 0.1968373853081754
Validation loss: 2.2778709604988654

Epoch: 5| Step: 7
Training loss: 0.14954568637769716
Validation loss: 2.2419718371070507

Epoch: 5| Step: 8
Training loss: 0.09498202886443438
Validation loss: 2.2474956732438898

Epoch: 5| Step: 9
Training loss: 0.20913674691173936
Validation loss: 2.2129594714509038

Epoch: 5| Step: 10
Training loss: 0.17720766938341753
Validation loss: 2.2573030577410327

Epoch: 642| Step: 0
Training loss: 0.13246521001577694
Validation loss: 2.237398785934687

Epoch: 5| Step: 1
Training loss: 0.12715878334671812
Validation loss: 2.270495629429535

Epoch: 5| Step: 2
Training loss: 0.08621100230834627
Validation loss: 2.274501145624849

Epoch: 5| Step: 3
Training loss: 0.20373206938790545
Validation loss: 2.2717420373864776

Epoch: 5| Step: 4
Training loss: 0.173748587509973
Validation loss: 2.299567284257519

Epoch: 5| Step: 5
Training loss: 0.18945178788489972
Validation loss: 2.323907277211265

Epoch: 5| Step: 6
Training loss: 0.11230341454489373
Validation loss: 2.313243627782716

Epoch: 5| Step: 7
Training loss: 0.13415405161807126
Validation loss: 2.3161251363265336

Epoch: 5| Step: 8
Training loss: 0.2944317844518738
Validation loss: 2.324427410606099

Epoch: 5| Step: 9
Training loss: 0.1825826173587964
Validation loss: 2.2959253321943276

Epoch: 5| Step: 10
Training loss: 0.11180169620954548
Validation loss: 2.276945076812433

Epoch: 643| Step: 0
Training loss: 0.11384840511010942
Validation loss: 2.315672062743815

Epoch: 5| Step: 1
Training loss: 0.19173724885032914
Validation loss: 2.287180223174419

Epoch: 5| Step: 2
Training loss: 0.23440146296833106
Validation loss: 2.2498487856970577

Epoch: 5| Step: 3
Training loss: 0.12156576024760841
Validation loss: 2.2749279163150393

Epoch: 5| Step: 4
Training loss: 0.18084450036462257
Validation loss: 2.2757623499735082

Epoch: 5| Step: 5
Training loss: 0.1832018585812001
Validation loss: 2.292092348837379

Epoch: 5| Step: 6
Training loss: 0.10592208672814789
Validation loss: 2.276236098759494

Epoch: 5| Step: 7
Training loss: 0.12768938339625702
Validation loss: 2.314608255599983

Epoch: 5| Step: 8
Training loss: 0.22156752046672903
Validation loss: 2.2977607620240734

Epoch: 5| Step: 9
Training loss: 0.24105203467902786
Validation loss: 2.347482082096703

Epoch: 5| Step: 10
Training loss: 0.11056091485658137
Validation loss: 2.3496999622808645

Epoch: 644| Step: 0
Training loss: 0.18769183875133352
Validation loss: 2.3438848422512333

Epoch: 5| Step: 1
Training loss: 0.11433633730616131
Validation loss: 2.3238842558110058

Epoch: 5| Step: 2
Training loss: 0.15730045785609942
Validation loss: 2.3244612559948115

Epoch: 5| Step: 3
Training loss: 0.14671123104511977
Validation loss: 2.3242088691995684

Epoch: 5| Step: 4
Training loss: 0.1681432150613
Validation loss: 2.3304543171855245

Epoch: 5| Step: 5
Training loss: 0.1324908133349531
Validation loss: 2.3341493681172394

Epoch: 5| Step: 6
Training loss: 0.19333605192146147
Validation loss: 2.316918401068837

Epoch: 5| Step: 7
Training loss: 0.15939892841673534
Validation loss: 2.3152570045729015

Epoch: 5| Step: 8
Training loss: 0.27663395276516445
Validation loss: 2.341748316551484

Epoch: 5| Step: 9
Training loss: 0.12274833065653692
Validation loss: 2.343720763102744

Epoch: 5| Step: 10
Training loss: 0.16340390918716202
Validation loss: 2.325209851761792

Epoch: 645| Step: 0
Training loss: 0.054468350170165006
Validation loss: 2.3075319329551984

Epoch: 5| Step: 1
Training loss: 0.22293813329499226
Validation loss: 2.3216448675333523

Epoch: 5| Step: 2
Training loss: 0.17855983871076356
Validation loss: 2.2657901962529547

Epoch: 5| Step: 3
Training loss: 0.1999775516309544
Validation loss: 2.2853684591774197

Epoch: 5| Step: 4
Training loss: 0.15857601959262174
Validation loss: 2.2920832053122466

Epoch: 5| Step: 5
Training loss: 0.16259908818711274
Validation loss: 2.27831203864855

Epoch: 5| Step: 6
Training loss: 0.1294270528554081
Validation loss: 2.2988410969066044

Epoch: 5| Step: 7
Training loss: 0.2359002788185689
Validation loss: 2.2847219837906434

Epoch: 5| Step: 8
Training loss: 0.20565120914068058
Validation loss: 2.2913731324562057

Epoch: 5| Step: 9
Training loss: 0.1148005579477967
Validation loss: 2.304568318740166

Epoch: 5| Step: 10
Training loss: 0.13765181537547225
Validation loss: 2.3455038092301326

Epoch: 646| Step: 0
Training loss: 0.24980616505702616
Validation loss: 2.29641241097991

Epoch: 5| Step: 1
Training loss: 0.15833497145917982
Validation loss: 2.3234168792976275

Epoch: 5| Step: 2
Training loss: 0.18280388982988352
Validation loss: 2.2947698302859676

Epoch: 5| Step: 3
Training loss: 0.23149557412924085
Validation loss: 2.2761191558618967

Epoch: 5| Step: 4
Training loss: 0.16558086463985036
Validation loss: 2.283146704524363

Epoch: 5| Step: 5
Training loss: 0.12144350103289267
Validation loss: 2.2567740435728543

Epoch: 5| Step: 6
Training loss: 0.1511979171835277
Validation loss: 2.2428073621504017

Epoch: 5| Step: 7
Training loss: 0.16842111398121695
Validation loss: 2.2489283352729004

Epoch: 5| Step: 8
Training loss: 0.18565839126757006
Validation loss: 2.2548896488409786

Epoch: 5| Step: 9
Training loss: 0.13405047585066043
Validation loss: 2.2775461513656046

Epoch: 5| Step: 10
Training loss: 0.15127030009794046
Validation loss: 2.296985161774827

Epoch: 647| Step: 0
Training loss: 0.15881503644641912
Validation loss: 2.3066722140460953

Epoch: 5| Step: 1
Training loss: 0.11795574931324104
Validation loss: 2.33080666906389

Epoch: 5| Step: 2
Training loss: 0.1071180816300352
Validation loss: 2.3101060321740814

Epoch: 5| Step: 3
Training loss: 0.12013192977997739
Validation loss: 2.300101117305103

Epoch: 5| Step: 4
Training loss: 0.17864672231499346
Validation loss: 2.3298829015827387

Epoch: 5| Step: 5
Training loss: 0.11945874704911466
Validation loss: 2.305428872810396

Epoch: 5| Step: 6
Training loss: 0.23272949185455535
Validation loss: 2.2953822989215866

Epoch: 5| Step: 7
Training loss: 0.1610797332267468
Validation loss: 2.2984051680668514

Epoch: 5| Step: 8
Training loss: 0.1621047214621454
Validation loss: 2.264626572314615

Epoch: 5| Step: 9
Training loss: 0.310978212039532
Validation loss: 2.2674849092695197

Epoch: 5| Step: 10
Training loss: 0.152692408052245
Validation loss: 2.252166083677738

Epoch: 648| Step: 0
Training loss: 0.1406598180476381
Validation loss: 2.2618318300257347

Epoch: 5| Step: 1
Training loss: 0.12193992135773693
Validation loss: 2.23965147524795

Epoch: 5| Step: 2
Training loss: 0.0874897264299147
Validation loss: 2.281273570200948

Epoch: 5| Step: 3
Training loss: 0.12937624100306452
Validation loss: 2.2911423725727453

Epoch: 5| Step: 4
Training loss: 0.17208317590580066
Validation loss: 2.2690457136786955

Epoch: 5| Step: 5
Training loss: 0.22161951802934837
Validation loss: 2.286796856652254

Epoch: 5| Step: 6
Training loss: 0.2047330041347614
Validation loss: 2.2665385270528553

Epoch: 5| Step: 7
Training loss: 0.11691871255917978
Validation loss: 2.310699549106037

Epoch: 5| Step: 8
Training loss: 0.08775006021136883
Validation loss: 2.286600215636878

Epoch: 5| Step: 9
Training loss: 0.20033326396951517
Validation loss: 2.274380716196968

Epoch: 5| Step: 10
Training loss: 0.263231276684964
Validation loss: 2.2598204125224957

Epoch: 649| Step: 0
Training loss: 0.15020739552641163
Validation loss: 2.2559547668724167

Epoch: 5| Step: 1
Training loss: 0.12509574799344106
Validation loss: 2.300237053273432

Epoch: 5| Step: 2
Training loss: 0.16455264896951552
Validation loss: 2.2821626926277756

Epoch: 5| Step: 3
Training loss: 0.1230710702147654
Validation loss: 2.285826612851476

Epoch: 5| Step: 4
Training loss: 0.1591689217326142
Validation loss: 2.2966907252344897

Epoch: 5| Step: 5
Training loss: 0.29168749065084465
Validation loss: 2.2816350782977453

Epoch: 5| Step: 6
Training loss: 0.2348313656889888
Validation loss: 2.290463925282102

Epoch: 5| Step: 7
Training loss: 0.11648753451661933
Validation loss: 2.3378940139205753

Epoch: 5| Step: 8
Training loss: 0.14538741411069311
Validation loss: 2.333490183681284

Epoch: 5| Step: 9
Training loss: 0.1649851400554703
Validation loss: 2.317455894564774

Epoch: 5| Step: 10
Training loss: 0.13700816312324038
Validation loss: 2.285529252566408

Epoch: 650| Step: 0
Training loss: 0.10642882753164908
Validation loss: 2.277223602616979

Epoch: 5| Step: 1
Training loss: 0.14324173583164165
Validation loss: 2.2821530304942366

Epoch: 5| Step: 2
Training loss: 0.214548002771124
Validation loss: 2.2520108403891896

Epoch: 5| Step: 3
Training loss: 0.1508133137661621
Validation loss: 2.2750534721147586

Epoch: 5| Step: 4
Training loss: 0.16851020195007163
Validation loss: 2.2789036181258067

Epoch: 5| Step: 5
Training loss: 0.21935022125882966
Validation loss: 2.2294668118813625

Epoch: 5| Step: 6
Training loss: 0.2709821955235718
Validation loss: 2.2723560925044515

Epoch: 5| Step: 7
Training loss: 0.18921081542082765
Validation loss: 2.2847362406129648

Epoch: 5| Step: 8
Training loss: 0.1475096110671748
Validation loss: 2.2654400289952235

Epoch: 5| Step: 9
Training loss: 0.16676385226541007
Validation loss: 2.2383910244581893

Epoch: 5| Step: 10
Training loss: 0.2660205364474096
Validation loss: 2.252154310779298

Testing loss: 2.348743922336419
