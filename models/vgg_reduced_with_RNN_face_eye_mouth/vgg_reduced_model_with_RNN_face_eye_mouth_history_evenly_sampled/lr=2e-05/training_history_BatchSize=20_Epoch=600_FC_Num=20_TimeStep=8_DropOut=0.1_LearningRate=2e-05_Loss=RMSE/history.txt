Epoch: 1| Step: 0
Training loss: 5.81731945116682
Validation loss: 5.780708100902656

Epoch: 5| Step: 1
Training loss: 5.466473786897893
Validation loss: 5.759158416290634

Epoch: 5| Step: 2
Training loss: 6.143286363681202
Validation loss: 5.734208818019203

Epoch: 5| Step: 3
Training loss: 6.258826774856151
Validation loss: 5.706705464718158

Epoch: 5| Step: 4
Training loss: 6.950987206471556
Validation loss: 5.67708686165438

Epoch: 5| Step: 5
Training loss: 4.985833890263375
Validation loss: 5.644417447365332

Epoch: 5| Step: 6
Training loss: 4.778703796977591
Validation loss: 5.607490628195038

Epoch: 5| Step: 7
Training loss: 5.9260847684093285
Validation loss: 5.567524101937147

Epoch: 5| Step: 8
Training loss: 5.237111210561325
Validation loss: 5.522353561281714

Epoch: 5| Step: 9
Training loss: 4.929009005469657
Validation loss: 5.472443635367776

Epoch: 5| Step: 10
Training loss: 5.4656275963490835
Validation loss: 5.417899306574203

Epoch: 2| Step: 0
Training loss: 5.126142793105039
Validation loss: 5.358213918550078

Epoch: 5| Step: 1
Training loss: 4.470592199093505
Validation loss: 5.295168962326555

Epoch: 5| Step: 2
Training loss: 5.509650001002325
Validation loss: 5.229083269852538

Epoch: 5| Step: 3
Training loss: 4.862976505888772
Validation loss: 5.1600887702211775

Epoch: 5| Step: 4
Training loss: 4.750266619778765
Validation loss: 5.087888250759203

Epoch: 5| Step: 5
Training loss: 4.451669769762091
Validation loss: 5.0170130842721345

Epoch: 5| Step: 6
Training loss: 5.811589651703324
Validation loss: 4.947543846639586

Epoch: 5| Step: 7
Training loss: 4.264854277684959
Validation loss: 4.8769905311352115

Epoch: 5| Step: 8
Training loss: 5.403554961271554
Validation loss: 4.812294164953371

Epoch: 5| Step: 9
Training loss: 6.159027247722126
Validation loss: 4.752271533293214

Epoch: 5| Step: 10
Training loss: 4.601338664441339
Validation loss: 4.692591482765879

Epoch: 3| Step: 0
Training loss: 4.321402165716175
Validation loss: 4.6402386356419685

Epoch: 5| Step: 1
Training loss: 3.3607772384591947
Validation loss: 4.591137359974088

Epoch: 5| Step: 2
Training loss: 5.514077290931033
Validation loss: 4.541869917708735

Epoch: 5| Step: 3
Training loss: 4.831919540063803
Validation loss: 4.495751833383944

Epoch: 5| Step: 4
Training loss: 5.4234236998122825
Validation loss: 4.455338917047953

Epoch: 5| Step: 5
Training loss: 4.013440439647467
Validation loss: 4.421601821031023

Epoch: 5| Step: 6
Training loss: 4.205863656018533
Validation loss: 4.392719751056284

Epoch: 5| Step: 7
Training loss: 4.1286279156865815
Validation loss: 4.367656602660735

Epoch: 5| Step: 8
Training loss: 3.9504947883620827
Validation loss: 4.349365301790905

Epoch: 5| Step: 9
Training loss: 4.815330762742499
Validation loss: 4.326593552431183

Epoch: 5| Step: 10
Training loss: 5.158913589076256
Validation loss: 4.299367687803713

Epoch: 4| Step: 0
Training loss: 4.53954697352649
Validation loss: 4.263354916571376

Epoch: 5| Step: 1
Training loss: 3.12627567956407
Validation loss: 4.244206308055818

Epoch: 5| Step: 2
Training loss: 4.769333294033882
Validation loss: 4.230802760961936

Epoch: 5| Step: 3
Training loss: 4.008681175276309
Validation loss: 4.217301686843121

Epoch: 5| Step: 4
Training loss: 4.213526678196199
Validation loss: 4.201229767427599

Epoch: 5| Step: 5
Training loss: 4.154457795793137
Validation loss: 4.184769138062903

Epoch: 5| Step: 6
Training loss: 4.899055600145341
Validation loss: 4.163836340313256

Epoch: 5| Step: 7
Training loss: 3.6627819694845947
Validation loss: 4.143108085416732

Epoch: 5| Step: 8
Training loss: 4.13167817498241
Validation loss: 4.12735503070371

Epoch: 5| Step: 9
Training loss: 5.217028670908007
Validation loss: 4.105110267782006

Epoch: 5| Step: 10
Training loss: 4.338773003036112
Validation loss: 4.058787899144016

Epoch: 5| Step: 0
Training loss: 4.416434563829945
Validation loss: 4.024585706988404

Epoch: 5| Step: 1
Training loss: 4.161572941366458
Validation loss: 4.0023099628228715

Epoch: 5| Step: 2
Training loss: 4.290192335392226
Validation loss: 4.00899491770998

Epoch: 5| Step: 3
Training loss: 4.103165144480643
Validation loss: 4.012079864332751

Epoch: 5| Step: 4
Training loss: 4.414668056844594
Validation loss: 4.005354683776108

Epoch: 5| Step: 5
Training loss: 4.10958153963493
Validation loss: 3.9903393700594028

Epoch: 5| Step: 6
Training loss: 3.866549599179801
Validation loss: 3.973403758860313

Epoch: 5| Step: 7
Training loss: 4.253097751594612
Validation loss: 3.9606956600170116

Epoch: 5| Step: 8
Training loss: 4.09104538892782
Validation loss: 3.942066559734478

Epoch: 5| Step: 9
Training loss: 3.391171037856334
Validation loss: 3.92602549534767

Epoch: 5| Step: 10
Training loss: 4.352247968341152
Validation loss: 3.90991446481305

Epoch: 6| Step: 0
Training loss: 3.9360881878037195
Validation loss: 3.9094798842325753

Epoch: 5| Step: 1
Training loss: 4.417839878135329
Validation loss: 3.8927746190690944

Epoch: 5| Step: 2
Training loss: 4.684739787917058
Validation loss: 3.865953540458394

Epoch: 5| Step: 3
Training loss: 3.638610937618762
Validation loss: 3.8547694689621004

Epoch: 5| Step: 4
Training loss: 3.422298736116003
Validation loss: 3.8464902002186117

Epoch: 5| Step: 5
Training loss: 3.737350108735615
Validation loss: 3.8404748787878162

Epoch: 5| Step: 6
Training loss: 3.664547365556786
Validation loss: 3.832554935234744

Epoch: 5| Step: 7
Training loss: 4.1489087428025595
Validation loss: 3.8206949608556453

Epoch: 5| Step: 8
Training loss: 4.533930124007732
Validation loss: 3.8034761249807802

Epoch: 5| Step: 9
Training loss: 3.6989807890233055
Validation loss: 3.790968528571202

Epoch: 5| Step: 10
Training loss: 4.079223718656601
Validation loss: 3.7879019195133745

Epoch: 7| Step: 0
Training loss: 3.747311836593185
Validation loss: 3.775948481557393

Epoch: 5| Step: 1
Training loss: 4.292197827304877
Validation loss: 3.757390633378512

Epoch: 5| Step: 2
Training loss: 4.108345163778381
Validation loss: 3.7494890883591636

Epoch: 5| Step: 3
Training loss: 4.571099316286027
Validation loss: 3.7380560891149335

Epoch: 5| Step: 4
Training loss: 3.3650566846769263
Validation loss: 3.725160184550098

Epoch: 5| Step: 5
Training loss: 3.136545292867065
Validation loss: 3.7207523110905374

Epoch: 5| Step: 6
Training loss: 3.183238303345546
Validation loss: 3.7169019602452646

Epoch: 5| Step: 7
Training loss: 3.8416164028054274
Validation loss: 3.7082289159899924

Epoch: 5| Step: 8
Training loss: 4.216250661199061
Validation loss: 3.694970023192789

Epoch: 5| Step: 9
Training loss: 4.266019139228591
Validation loss: 3.6847551967815297

Epoch: 5| Step: 10
Training loss: 3.9574661241865954
Validation loss: 3.6778799985374087

Epoch: 8| Step: 0
Training loss: 4.202385025403241
Validation loss: 3.6704110555192297

Epoch: 5| Step: 1
Training loss: 4.231356850744197
Validation loss: 3.6603360709923316

Epoch: 5| Step: 2
Training loss: 3.590922561945082
Validation loss: 3.653253744481646

Epoch: 5| Step: 3
Training loss: 3.533094346463273
Validation loss: 3.6418338764748897

Epoch: 5| Step: 4
Training loss: 4.167273566233693
Validation loss: 3.6342556182418333

Epoch: 5| Step: 5
Training loss: 3.4519292219559707
Validation loss: 3.6223470932982025

Epoch: 5| Step: 6
Training loss: 4.384229244057971
Validation loss: 3.613796089651909

Epoch: 5| Step: 7
Training loss: 3.2566603857765295
Validation loss: 3.6086503894166517

Epoch: 5| Step: 8
Training loss: 3.8326967927159354
Validation loss: 3.5988251634285833

Epoch: 5| Step: 9
Training loss: 3.412682295740428
Validation loss: 3.5890197240209383

Epoch: 5| Step: 10
Training loss: 3.7960109905007444
Validation loss: 3.581331187840924

Epoch: 9| Step: 0
Training loss: 4.053440732871562
Validation loss: 3.5719299178399613

Epoch: 5| Step: 1
Training loss: 3.9670067510487312
Validation loss: 3.565351197635768

Epoch: 5| Step: 2
Training loss: 3.693508877444156
Validation loss: 3.558865085781347

Epoch: 5| Step: 3
Training loss: 4.064340731942531
Validation loss: 3.5487828192520916

Epoch: 5| Step: 4
Training loss: 3.6151001017575624
Validation loss: 3.539626070876206

Epoch: 5| Step: 5
Training loss: 3.9341160598879714
Validation loss: 3.530605058709267

Epoch: 5| Step: 6
Training loss: 2.896476308305945
Validation loss: 3.525340628647953

Epoch: 5| Step: 7
Training loss: 3.793282524354113
Validation loss: 3.5158460249065304

Epoch: 5| Step: 8
Training loss: 3.6184082607791517
Validation loss: 3.5071457228840615

Epoch: 5| Step: 9
Training loss: 3.6435248486951592
Validation loss: 3.5008550308553845

Epoch: 5| Step: 10
Training loss: 3.7663089874945506
Validation loss: 3.492443184646907

Epoch: 10| Step: 0
Training loss: 3.0326506534650366
Validation loss: 3.4850677385795836

Epoch: 5| Step: 1
Training loss: 3.835988838800098
Validation loss: 3.4783431732764813

Epoch: 5| Step: 2
Training loss: 3.669078005111471
Validation loss: 3.471270631948952

Epoch: 5| Step: 3
Training loss: 3.0246585873966834
Validation loss: 3.464497790633044

Epoch: 5| Step: 4
Training loss: 3.2198976118975455
Validation loss: 3.458199577151667

Epoch: 5| Step: 5
Training loss: 4.055450191319388
Validation loss: 3.4500922666151395

Epoch: 5| Step: 6
Training loss: 3.764819300394645
Validation loss: 3.4442581179177845

Epoch: 5| Step: 7
Training loss: 4.126153495651578
Validation loss: 3.438152301309636

Epoch: 5| Step: 8
Training loss: 3.1467724507810586
Validation loss: 3.430762006097945

Epoch: 5| Step: 9
Training loss: 4.256906619516707
Validation loss: 3.426591549820872

Epoch: 5| Step: 10
Training loss: 3.9734626484208952
Validation loss: 3.4171229767342948

Epoch: 11| Step: 0
Training loss: 3.2718344612124173
Validation loss: 3.410608896052345

Epoch: 5| Step: 1
Training loss: 3.1423181932491357
Validation loss: 3.4023989263043473

Epoch: 5| Step: 2
Training loss: 3.4210981767533872
Validation loss: 3.3957019727403934

Epoch: 5| Step: 3
Training loss: 3.7747423905143638
Validation loss: 3.390921045841975

Epoch: 5| Step: 4
Training loss: 3.2740674562117236
Validation loss: 3.3825655220891924

Epoch: 5| Step: 5
Training loss: 4.213551575122904
Validation loss: 3.37444599242684

Epoch: 5| Step: 6
Training loss: 4.0139367974460685
Validation loss: 3.36893004798626

Epoch: 5| Step: 7
Training loss: 4.224792899749805
Validation loss: 3.362014030791183

Epoch: 5| Step: 8
Training loss: 3.461596010821984
Validation loss: 3.3553304047667587

Epoch: 5| Step: 9
Training loss: 3.7466133083557787
Validation loss: 3.3480164851502474

Epoch: 5| Step: 10
Training loss: 2.7134381724199383
Validation loss: 3.3432205129050616

Epoch: 12| Step: 0
Training loss: 3.3472388774058226
Validation loss: 3.336298297382541

Epoch: 5| Step: 1
Training loss: 3.344562182320169
Validation loss: 3.3294981756557656

Epoch: 5| Step: 2
Training loss: 3.7760306662914482
Validation loss: 3.3235130169688247

Epoch: 5| Step: 3
Training loss: 3.149661297224107
Validation loss: 3.319058034957209

Epoch: 5| Step: 4
Training loss: 3.6592233419550375
Validation loss: 3.312939683365486

Epoch: 5| Step: 5
Training loss: 3.8647485305286855
Validation loss: 3.308301821227692

Epoch: 5| Step: 6
Training loss: 3.447779872673869
Validation loss: 3.3004529354419576

Epoch: 5| Step: 7
Training loss: 4.1766161320443524
Validation loss: 3.2948121887686073

Epoch: 5| Step: 8
Training loss: 3.5728976116654705
Validation loss: 3.2925489657292193

Epoch: 5| Step: 9
Training loss: 2.984754927653092
Validation loss: 3.2847335223693754

Epoch: 5| Step: 10
Training loss: 3.555109757715547
Validation loss: 3.2795656552347063

Epoch: 13| Step: 0
Training loss: 3.009539853786748
Validation loss: 3.273491707077735

Epoch: 5| Step: 1
Training loss: 3.472744952378804
Validation loss: 3.2716362064926545

Epoch: 5| Step: 2
Training loss: 3.051215107994503
Validation loss: 3.268753599690635

Epoch: 5| Step: 3
Training loss: 3.0989858075801986
Validation loss: 3.2654685522538345

Epoch: 5| Step: 4
Training loss: 3.4065190480219147
Validation loss: 3.260006084037603

Epoch: 5| Step: 5
Training loss: 3.6318368565557453
Validation loss: 3.2564502156860198

Epoch: 5| Step: 6
Training loss: 3.409209619247005
Validation loss: 3.248308806638808

Epoch: 5| Step: 7
Training loss: 3.980526849773786
Validation loss: 3.2487809172110698

Epoch: 5| Step: 8
Training loss: 4.182995095326947
Validation loss: 3.23974952446888

Epoch: 5| Step: 9
Training loss: 3.489332290653145
Validation loss: 3.2343222520817214

Epoch: 5| Step: 10
Training loss: 3.642681277862482
Validation loss: 3.23365141895336

Epoch: 14| Step: 0
Training loss: 3.400827834381865
Validation loss: 3.233586808233949

Epoch: 5| Step: 1
Training loss: 3.9297314256522404
Validation loss: 3.2243644777532685

Epoch: 5| Step: 2
Training loss: 3.6482213219714223
Validation loss: 3.2194188099438867

Epoch: 5| Step: 3
Training loss: 4.109235521857646
Validation loss: 3.2171103959536174

Epoch: 5| Step: 4
Training loss: 3.299971875157583
Validation loss: 3.210193882958805

Epoch: 5| Step: 5
Training loss: 3.4111445547142587
Validation loss: 3.206667117565506

Epoch: 5| Step: 6
Training loss: 3.5346605153538113
Validation loss: 3.2043888074937814

Epoch: 5| Step: 7
Training loss: 2.8934998109565964
Validation loss: 3.196895389926702

Epoch: 5| Step: 8
Training loss: 3.199563330420433
Validation loss: 3.19195173787498

Epoch: 5| Step: 9
Training loss: 3.5623100631675815
Validation loss: 3.1913556821800753

Epoch: 5| Step: 10
Training loss: 2.8786544793233046
Validation loss: 3.189406826538605

Epoch: 15| Step: 0
Training loss: 3.4352043115525714
Validation loss: 3.183817073101437

Epoch: 5| Step: 1
Training loss: 3.1511368834346265
Validation loss: 3.181904781032978

Epoch: 5| Step: 2
Training loss: 3.188277953711004
Validation loss: 3.178826899258115

Epoch: 5| Step: 3
Training loss: 3.4327092859710953
Validation loss: 3.1702738333941625

Epoch: 5| Step: 4
Training loss: 3.868627661525532
Validation loss: 3.168674068047212

Epoch: 5| Step: 5
Training loss: 3.42924673945653
Validation loss: 3.165836316574686

Epoch: 5| Step: 6
Training loss: 3.4911400506352384
Validation loss: 3.1641882138817623

Epoch: 5| Step: 7
Training loss: 3.6247049408894374
Validation loss: 3.1599920770087087

Epoch: 5| Step: 8
Training loss: 3.1740624913467927
Validation loss: 3.152795431959129

Epoch: 5| Step: 9
Training loss: 3.7155201453580524
Validation loss: 3.151496692585198

Epoch: 5| Step: 10
Training loss: 3.109497834659552
Validation loss: 3.149251630822894

Epoch: 16| Step: 0
Training loss: 3.2238888504519445
Validation loss: 3.146856678711421

Epoch: 5| Step: 1
Training loss: 3.9009071126565815
Validation loss: 3.1429901123218134

Epoch: 5| Step: 2
Training loss: 3.177854717393229
Validation loss: 3.1388438849514526

Epoch: 5| Step: 3
Training loss: 3.508207371157727
Validation loss: 3.1404061793990112

Epoch: 5| Step: 4
Training loss: 2.797396904185153
Validation loss: 3.141957062108548

Epoch: 5| Step: 5
Training loss: 3.1869329808360924
Validation loss: 3.137423995824401

Epoch: 5| Step: 6
Training loss: 3.55284631016971
Validation loss: 3.131269672683971

Epoch: 5| Step: 7
Training loss: 3.9266277558277554
Validation loss: 3.125987822572437

Epoch: 5| Step: 8
Training loss: 3.3181935449110345
Validation loss: 3.122144146427447

Epoch: 5| Step: 9
Training loss: 3.4713438491305473
Validation loss: 3.119727858599397

Epoch: 5| Step: 10
Training loss: 3.2203519223690833
Validation loss: 3.117021203671514

Epoch: 17| Step: 0
Training loss: 3.0284664311934715
Validation loss: 3.1116356911592704

Epoch: 5| Step: 1
Training loss: 3.9812231425243283
Validation loss: 3.1088572265977614

Epoch: 5| Step: 2
Training loss: 2.7453807702909003
Validation loss: 3.1058072725553254

Epoch: 5| Step: 3
Training loss: 3.9308068442623094
Validation loss: 3.1015643465439515

Epoch: 5| Step: 4
Training loss: 2.9195647056322516
Validation loss: 3.098896246384918

Epoch: 5| Step: 5
Training loss: 3.99513162942727
Validation loss: 3.102579897351801

Epoch: 5| Step: 6
Training loss: 3.613214077711769
Validation loss: 3.1058469550679173

Epoch: 5| Step: 7
Training loss: 2.7569215540305323
Validation loss: 3.089327293809799

Epoch: 5| Step: 8
Training loss: 3.9481950861338384
Validation loss: 3.0859545668678727

Epoch: 5| Step: 9
Training loss: 2.864797984086142
Validation loss: 3.083967396982572

Epoch: 5| Step: 10
Training loss: 2.832678232940429
Validation loss: 3.0813230353820105

Epoch: 18| Step: 0
Training loss: 3.2323301181274338
Validation loss: 3.080239689283079

Epoch: 5| Step: 1
Training loss: 2.830645539219132
Validation loss: 3.077731491145469

Epoch: 5| Step: 2
Training loss: 2.940507526057912
Validation loss: 3.074716545958084

Epoch: 5| Step: 3
Training loss: 3.2027522172557648
Validation loss: 3.07194260053714

Epoch: 5| Step: 4
Training loss: 3.2079131276456794
Validation loss: 3.0685355168796122

Epoch: 5| Step: 5
Training loss: 3.704218449497038
Validation loss: 3.0652775828800607

Epoch: 5| Step: 6
Training loss: 3.717420709068379
Validation loss: 3.062918415329023

Epoch: 5| Step: 7
Training loss: 2.7222800302747
Validation loss: 3.05974253811363

Epoch: 5| Step: 8
Training loss: 3.839890690280866
Validation loss: 3.076983175778356

Epoch: 5| Step: 9
Training loss: 3.4260419444084733
Validation loss: 3.0572278891210627

Epoch: 5| Step: 10
Training loss: 3.9005049305280632
Validation loss: 3.0562219759681337

Epoch: 19| Step: 0
Training loss: 3.1083452062576074
Validation loss: 3.055860546946185

Epoch: 5| Step: 1
Training loss: 3.507039212162381
Validation loss: 3.0533498182853465

Epoch: 5| Step: 2
Training loss: 3.6104351650027557
Validation loss: 3.0513287517602268

Epoch: 5| Step: 3
Training loss: 3.154974651446431
Validation loss: 3.0498667191773556

Epoch: 5| Step: 4
Training loss: 3.318551348184492
Validation loss: 3.0488875447036925

Epoch: 5| Step: 5
Training loss: 2.577118370745177
Validation loss: 3.045133869722662

Epoch: 5| Step: 6
Training loss: 3.259155874667681
Validation loss: 3.0381321353802697

Epoch: 5| Step: 7
Training loss: 3.8952210025010383
Validation loss: 3.0359995010254295

Epoch: 5| Step: 8
Training loss: 3.463928170496803
Validation loss: 3.0328000123706023

Epoch: 5| Step: 9
Training loss: 3.508040592789539
Validation loss: 3.030304516351919

Epoch: 5| Step: 10
Training loss: 3.042164295893706
Validation loss: 3.026766024113327

Epoch: 20| Step: 0
Training loss: 3.7002927355048785
Validation loss: 3.0220433033654577

Epoch: 5| Step: 1
Training loss: 2.9231044202352954
Validation loss: 3.0198817133636284

Epoch: 5| Step: 2
Training loss: 3.326166140629232
Validation loss: 3.0190830542007507

Epoch: 5| Step: 3
Training loss: 2.754801200298803
Validation loss: 3.0184802349146107

Epoch: 5| Step: 4
Training loss: 3.571227509424773
Validation loss: 3.0201540739496586

Epoch: 5| Step: 5
Training loss: 3.392342549931274
Validation loss: 3.0162842089708923

Epoch: 5| Step: 6
Training loss: 3.6743743831077924
Validation loss: 3.0090947175843032

Epoch: 5| Step: 7
Training loss: 3.293526635024784
Validation loss: 3.00550135172124

Epoch: 5| Step: 8
Training loss: 3.4048075290230995
Validation loss: 3.0080196578292866

Epoch: 5| Step: 9
Training loss: 2.9828002929437716
Validation loss: 3.0149824029615107

Epoch: 5| Step: 10
Training loss: 3.2116889909550057
Validation loss: 3.0132425690547495

Epoch: 21| Step: 0
Training loss: 3.298673455614008
Validation loss: 3.0125084781369993

Epoch: 5| Step: 1
Training loss: 2.7470557317201028
Validation loss: 3.008395859745138

Epoch: 5| Step: 2
Training loss: 2.9984773904553252
Validation loss: 2.9992177321061457

Epoch: 5| Step: 3
Training loss: 3.495854511280194
Validation loss: 2.9962489782898025

Epoch: 5| Step: 4
Training loss: 3.5659337143313365
Validation loss: 2.993215219007357

Epoch: 5| Step: 5
Training loss: 3.6314495196000345
Validation loss: 2.986067375542645

Epoch: 5| Step: 6
Training loss: 3.1798181155509258
Validation loss: 2.9875335738154702

Epoch: 5| Step: 7
Training loss: 3.246513697593107
Validation loss: 2.9879996402772826

Epoch: 5| Step: 8
Training loss: 3.608899634297769
Validation loss: 2.985510830466553

Epoch: 5| Step: 9
Training loss: 3.374065411054043
Validation loss: 2.978221989357226

Epoch: 5| Step: 10
Training loss: 2.866838563895852
Validation loss: 2.9808611781812977

Epoch: 22| Step: 0
Training loss: 3.8230637081185304
Validation loss: 2.9841108926321094

Epoch: 5| Step: 1
Training loss: 3.0747283939651116
Validation loss: 2.9776420716565655

Epoch: 5| Step: 2
Training loss: 2.8028820464145974
Validation loss: 2.9809045011967656

Epoch: 5| Step: 3
Training loss: 3.2637215501530754
Validation loss: 2.9741782715232263

Epoch: 5| Step: 4
Training loss: 3.080903943420103
Validation loss: 2.9718672072641166

Epoch: 5| Step: 5
Training loss: 2.63948034272748
Validation loss: 2.9689703677673105

Epoch: 5| Step: 6
Training loss: 3.466826859465402
Validation loss: 2.9668001793571044

Epoch: 5| Step: 7
Training loss: 3.258043459382876
Validation loss: 2.96491800431656

Epoch: 5| Step: 8
Training loss: 3.873698969822161
Validation loss: 2.9644316772063672

Epoch: 5| Step: 9
Training loss: 3.6728217020522407
Validation loss: 2.96391356308712

Epoch: 5| Step: 10
Training loss: 2.674770816004963
Validation loss: 2.9620663356411154

Epoch: 23| Step: 0
Training loss: 3.261974283590636
Validation loss: 2.9579720800121683

Epoch: 5| Step: 1
Training loss: 3.349689662849731
Validation loss: 2.9556062883244008

Epoch: 5| Step: 2
Training loss: 2.700681519149786
Validation loss: 2.956582874069333

Epoch: 5| Step: 3
Training loss: 3.4369381532140717
Validation loss: 2.9559880090415596

Epoch: 5| Step: 4
Training loss: 3.3941633334581724
Validation loss: 2.9595194692825113

Epoch: 5| Step: 5
Training loss: 3.5451734049021066
Validation loss: 2.9651998815926013

Epoch: 5| Step: 6
Training loss: 3.0686375366238283
Validation loss: 2.95203644152258

Epoch: 5| Step: 7
Training loss: 3.6659349809656976
Validation loss: 2.9473732044744922

Epoch: 5| Step: 8
Training loss: 2.9128742812502466
Validation loss: 2.947126619162755

Epoch: 5| Step: 9
Training loss: 2.9497247729172824
Validation loss: 2.949251209763045

Epoch: 5| Step: 10
Training loss: 3.4475287058785233
Validation loss: 2.9421826499179393

Epoch: 24| Step: 0
Training loss: 3.5298120051998834
Validation loss: 2.940539773355034

Epoch: 5| Step: 1
Training loss: 3.2635158316600967
Validation loss: 2.942860165765512

Epoch: 5| Step: 2
Training loss: 4.03371643790086
Validation loss: 2.941852636755946

Epoch: 5| Step: 3
Training loss: 3.0686723439011265
Validation loss: 2.9483725917282366

Epoch: 5| Step: 4
Training loss: 2.509308460916347
Validation loss: 2.9501819563518175

Epoch: 5| Step: 5
Training loss: 2.7589905899844167
Validation loss: 2.9603457702551865

Epoch: 5| Step: 6
Training loss: 2.809982020364712
Validation loss: 2.943704354467655

Epoch: 5| Step: 7
Training loss: 3.1853696398427043
Validation loss: 2.9291225338711198

Epoch: 5| Step: 8
Training loss: 3.739079915256011
Validation loss: 2.921055497491951

Epoch: 5| Step: 9
Training loss: 3.3802757001765555
Validation loss: 2.919545254995391

Epoch: 5| Step: 10
Training loss: 2.931339378051679
Validation loss: 2.9176678259177837

Epoch: 25| Step: 0
Training loss: 2.5064075372893684
Validation loss: 2.9172657141942664

Epoch: 5| Step: 1
Training loss: 3.427032764065585
Validation loss: 2.9222079158611445

Epoch: 5| Step: 2
Training loss: 3.334976522428811
Validation loss: 2.905245521461616

Epoch: 5| Step: 3
Training loss: 2.7462113031049284
Validation loss: 2.93060980036097

Epoch: 5| Step: 4
Training loss: 3.7067229099489127
Validation loss: 2.974092654653073

Epoch: 5| Step: 5
Training loss: 3.1852172456486447
Validation loss: 2.947641447160164

Epoch: 5| Step: 6
Training loss: 3.2796685176916127
Validation loss: 2.926090284124332

Epoch: 5| Step: 7
Training loss: 3.591729168152632
Validation loss: 2.908965679527626

Epoch: 5| Step: 8
Training loss: 2.798496479582229
Validation loss: 2.9004731760782545

Epoch: 5| Step: 9
Training loss: 3.0841764036360044
Validation loss: 2.9060225453431228

Epoch: 5| Step: 10
Training loss: 3.663334951171888
Validation loss: 2.9081389734020333

Epoch: 26| Step: 0
Training loss: 3.5366507221788916
Validation loss: 2.90122783641837

Epoch: 5| Step: 1
Training loss: 2.2685856909404793
Validation loss: 2.8942841441847635

Epoch: 5| Step: 2
Training loss: 2.8110469879489797
Validation loss: 2.8904051284956975

Epoch: 5| Step: 3
Training loss: 3.284443200707218
Validation loss: 2.89217781678708

Epoch: 5| Step: 4
Training loss: 3.348546945667459
Validation loss: 2.897968813008561

Epoch: 5| Step: 5
Training loss: 3.089192588278229
Validation loss: 2.9036569793868363

Epoch: 5| Step: 6
Training loss: 3.171567855020066
Validation loss: 2.901581994457606

Epoch: 5| Step: 7
Training loss: 3.31237562413906
Validation loss: 2.8964861398629194

Epoch: 5| Step: 8
Training loss: 3.243183911270562
Validation loss: 2.884338049954742

Epoch: 5| Step: 9
Training loss: 3.6939161698970717
Validation loss: 2.8830514204062156

Epoch: 5| Step: 10
Training loss: 3.2217011487141347
Validation loss: 2.882178690579625

Epoch: 27| Step: 0
Training loss: 2.470062389898574
Validation loss: 2.878823645071681

Epoch: 5| Step: 1
Training loss: 2.8277322907485583
Validation loss: 2.878923621649608

Epoch: 5| Step: 2
Training loss: 3.334152709072359
Validation loss: 2.8802078805748907

Epoch: 5| Step: 3
Training loss: 3.2107524586470393
Validation loss: 2.878585993747344

Epoch: 5| Step: 4
Training loss: 3.4800042764045487
Validation loss: 2.878641906241751

Epoch: 5| Step: 5
Training loss: 2.9970816086562126
Validation loss: 2.878816371321794

Epoch: 5| Step: 6
Training loss: 3.253262569512551
Validation loss: 2.8826208083406124

Epoch: 5| Step: 7
Training loss: 3.3872471169536826
Validation loss: 2.8784798922124586

Epoch: 5| Step: 8
Training loss: 3.7142579973674823
Validation loss: 2.877787207811849

Epoch: 5| Step: 9
Training loss: 2.797350027992147
Validation loss: 2.8708135639331958

Epoch: 5| Step: 10
Training loss: 3.4121096544969833
Validation loss: 2.8976272146045225

Epoch: 28| Step: 0
Training loss: 3.080892335510576
Validation loss: 2.87064211414684

Epoch: 5| Step: 1
Training loss: 2.8233114344240366
Validation loss: 2.8856155334677154

Epoch: 5| Step: 2
Training loss: 2.8379897581403584
Validation loss: 2.8722082291426703

Epoch: 5| Step: 3
Training loss: 3.5571283365326414
Validation loss: 2.8741252008759814

Epoch: 5| Step: 4
Training loss: 3.2070260460238686
Validation loss: 2.8702122779242343

Epoch: 5| Step: 5
Training loss: 3.098628503680427
Validation loss: 2.8750803161787744

Epoch: 5| Step: 6
Training loss: 3.5578698302329492
Validation loss: 2.917496201701938

Epoch: 5| Step: 7
Training loss: 3.3568490401283237
Validation loss: 2.882523387096899

Epoch: 5| Step: 8
Training loss: 3.252179222151381
Validation loss: 2.874718611733938

Epoch: 5| Step: 9
Training loss: 2.8516696857530794
Validation loss: 2.885595461308534

Epoch: 5| Step: 10
Training loss: 3.4609351577923086
Validation loss: 2.8983493149486885

Epoch: 29| Step: 0
Training loss: 3.630398906301079
Validation loss: 2.909373263187198

Epoch: 5| Step: 1
Training loss: 3.143282397097861
Validation loss: 2.8933498214566415

Epoch: 5| Step: 2
Training loss: 3.5376284896107126
Validation loss: 2.8822202138807604

Epoch: 5| Step: 3
Training loss: 2.637007905151878
Validation loss: 2.872456285342236

Epoch: 5| Step: 4
Training loss: 3.374385353916122
Validation loss: 2.87343335011885

Epoch: 5| Step: 5
Training loss: 3.019396385349289
Validation loss: 2.874219589639779

Epoch: 5| Step: 6
Training loss: 3.2731328927207715
Validation loss: 2.882105243491669

Epoch: 5| Step: 7
Training loss: 3.089860108304517
Validation loss: 2.877013268877405

Epoch: 5| Step: 8
Training loss: 3.6189843610861505
Validation loss: 2.8672798586469406

Epoch: 5| Step: 9
Training loss: 3.011308654492606
Validation loss: 2.8653159097330447

Epoch: 5| Step: 10
Training loss: 2.400849859447155
Validation loss: 2.8602063410439915

Epoch: 30| Step: 0
Training loss: 3.858314893663366
Validation loss: 2.8596039273627434

Epoch: 5| Step: 1
Training loss: 2.849849322167335
Validation loss: 2.854956588017094

Epoch: 5| Step: 2
Training loss: 2.99506831121475
Validation loss: 2.8548960575975952

Epoch: 5| Step: 3
Training loss: 3.9330820396667945
Validation loss: 2.8550846021071474

Epoch: 5| Step: 4
Training loss: 3.0454885605112016
Validation loss: 2.8534043397838356

Epoch: 5| Step: 5
Training loss: 2.8984779704679635
Validation loss: 2.8541077590610713

Epoch: 5| Step: 6
Training loss: 3.5201717560219317
Validation loss: 2.8576636942399056

Epoch: 5| Step: 7
Training loss: 3.0397250279498036
Validation loss: 2.8560129751912204

Epoch: 5| Step: 8
Training loss: 2.375619606708445
Validation loss: 2.85473856545516

Epoch: 5| Step: 9
Training loss: 2.9078802643043544
Validation loss: 2.8536987744531577

Epoch: 5| Step: 10
Training loss: 3.0184357347255166
Validation loss: 2.850235911595338

Epoch: 31| Step: 0
Training loss: 2.496207794306387
Validation loss: 2.852909055082126

Epoch: 5| Step: 1
Training loss: 3.636417036314662
Validation loss: 2.848067241888665

Epoch: 5| Step: 2
Training loss: 2.8327125729475378
Validation loss: 2.853532098286004

Epoch: 5| Step: 3
Training loss: 2.629246319885667
Validation loss: 2.843588160818664

Epoch: 5| Step: 4
Training loss: 3.0249694570465424
Validation loss: 2.842466743436239

Epoch: 5| Step: 5
Training loss: 3.413500427487454
Validation loss: 2.838418232014994

Epoch: 5| Step: 6
Training loss: 3.483025670191632
Validation loss: 2.83844904970996

Epoch: 5| Step: 7
Training loss: 3.5637803035800424
Validation loss: 2.837744109109613

Epoch: 5| Step: 8
Training loss: 2.9396711401708724
Validation loss: 2.836991715804689

Epoch: 5| Step: 9
Training loss: 3.133428118333994
Validation loss: 2.8345756817078342

Epoch: 5| Step: 10
Training loss: 3.3101892148704475
Validation loss: 2.8364785746995578

Epoch: 32| Step: 0
Training loss: 2.9540016447461714
Validation loss: 2.8347340417413527

Epoch: 5| Step: 1
Training loss: 3.32754984439286
Validation loss: 2.8318985690902196

Epoch: 5| Step: 2
Training loss: 3.2004228312565397
Validation loss: 2.834672013225998

Epoch: 5| Step: 3
Training loss: 3.4368852932712204
Validation loss: 2.8337061677130304

Epoch: 5| Step: 4
Training loss: 2.625720243190753
Validation loss: 2.839076012070237

Epoch: 5| Step: 5
Training loss: 3.5932283769282196
Validation loss: 2.844545808577824

Epoch: 5| Step: 6
Training loss: 2.7076402119605065
Validation loss: 2.8372696226140466

Epoch: 5| Step: 7
Training loss: 2.995738181211137
Validation loss: 2.8310807253523147

Epoch: 5| Step: 8
Training loss: 3.3046804297261096
Validation loss: 2.8329908615195474

Epoch: 5| Step: 9
Training loss: 3.331549516850611
Validation loss: 2.827902743962759

Epoch: 5| Step: 10
Training loss: 2.947672497957058
Validation loss: 2.829262860294636

Epoch: 33| Step: 0
Training loss: 2.815115411943577
Validation loss: 2.8271236293267545

Epoch: 5| Step: 1
Training loss: 3.0891581665723407
Validation loss: 2.8268713712180045

Epoch: 5| Step: 2
Training loss: 3.5466723951374726
Validation loss: 2.8240944121530407

Epoch: 5| Step: 3
Training loss: 3.309137040787509
Validation loss: 2.8247230658305327

Epoch: 5| Step: 4
Training loss: 2.4671223743581496
Validation loss: 2.828362194288219

Epoch: 5| Step: 5
Training loss: 3.4280303914204078
Validation loss: 2.8367152042496495

Epoch: 5| Step: 6
Training loss: 2.6706749078080994
Validation loss: 2.8374882881270143

Epoch: 5| Step: 7
Training loss: 3.451816500793657
Validation loss: 2.8279954564134235

Epoch: 5| Step: 8
Training loss: 3.1782185678577366
Validation loss: 2.8209461741850492

Epoch: 5| Step: 9
Training loss: 3.36289885470411
Validation loss: 2.8178955480550987

Epoch: 5| Step: 10
Training loss: 2.951921328718776
Validation loss: 2.815549120550295

Epoch: 34| Step: 0
Training loss: 3.4765812905478852
Validation loss: 2.8190810182514694

Epoch: 5| Step: 1
Training loss: 3.3441854888540954
Validation loss: 2.8329127116814496

Epoch: 5| Step: 2
Training loss: 2.982773755692665
Validation loss: 2.827783868938388

Epoch: 5| Step: 3
Training loss: 3.4637848656344046
Validation loss: 2.8106524434465405

Epoch: 5| Step: 4
Training loss: 2.8922289548074107
Validation loss: 2.8078956734255978

Epoch: 5| Step: 5
Training loss: 2.985243745753036
Validation loss: 2.8074135218614886

Epoch: 5| Step: 6
Training loss: 2.996096137293296
Validation loss: 2.806284893104075

Epoch: 5| Step: 7
Training loss: 3.105719636583375
Validation loss: 2.8050237463164818

Epoch: 5| Step: 8
Training loss: 3.0742085128284127
Validation loss: 2.804347123388391

Epoch: 5| Step: 9
Training loss: 2.9430499303369038
Validation loss: 2.808999471628581

Epoch: 5| Step: 10
Training loss: 3.088010453873565
Validation loss: 2.8152387585572796

Epoch: 35| Step: 0
Training loss: 2.856858109862598
Validation loss: 2.8168137086802965

Epoch: 5| Step: 1
Training loss: 3.021531877101147
Validation loss: 2.8147734519608036

Epoch: 5| Step: 2
Training loss: 3.0714843687901405
Validation loss: 2.820511358556032

Epoch: 5| Step: 3
Training loss: 2.7783638198208145
Validation loss: 2.8065052091001945

Epoch: 5| Step: 4
Training loss: 3.5644428242573762
Validation loss: 2.8361943968519405

Epoch: 5| Step: 5
Training loss: 3.4362023418475593
Validation loss: 2.887045653715508

Epoch: 5| Step: 6
Training loss: 2.623368528276221
Validation loss: 2.852475484374354

Epoch: 5| Step: 7
Training loss: 3.1878826435271055
Validation loss: 2.8310061581503367

Epoch: 5| Step: 8
Training loss: 3.3545845829706247
Validation loss: 2.9362173349876937

Epoch: 5| Step: 9
Training loss: 3.3778279077702758
Validation loss: 2.884055240296234

Epoch: 5| Step: 10
Training loss: 3.523192132835024
Validation loss: 2.823242759570453

Epoch: 36| Step: 0
Training loss: 3.147625006631674
Validation loss: 2.8513523349695564

Epoch: 5| Step: 1
Training loss: 3.39918022370649
Validation loss: 2.8667752242036704

Epoch: 5| Step: 2
Training loss: 2.8858307542457995
Validation loss: 2.828978163319778

Epoch: 5| Step: 3
Training loss: 3.7244122137446904
Validation loss: 2.8203024447159617

Epoch: 5| Step: 4
Training loss: 3.438297526003143
Validation loss: 2.8266366919846404

Epoch: 5| Step: 5
Training loss: 2.711666569802584
Validation loss: 2.8228791372913955

Epoch: 5| Step: 6
Training loss: 2.395845982614932
Validation loss: 2.843642848395342

Epoch: 5| Step: 7
Training loss: 2.70724684612243
Validation loss: 2.856782213874652

Epoch: 5| Step: 8
Training loss: 3.546579222593076
Validation loss: 2.8072636103477557

Epoch: 5| Step: 9
Training loss: 3.478429811459054
Validation loss: 2.799972290350222

Epoch: 5| Step: 10
Training loss: 2.9292037361009715
Validation loss: 2.7947645090835875

Epoch: 37| Step: 0
Training loss: 2.916324668088611
Validation loss: 2.796012778054492

Epoch: 5| Step: 1
Training loss: 3.014551792010525
Validation loss: 2.7975974970087045

Epoch: 5| Step: 2
Training loss: 3.184431506433297
Validation loss: 2.8016636544038325

Epoch: 5| Step: 3
Training loss: 2.442207388086057
Validation loss: 2.8085534539296333

Epoch: 5| Step: 4
Training loss: 3.26014768488271
Validation loss: 2.8046204870328584

Epoch: 5| Step: 5
Training loss: 3.4034438867450376
Validation loss: 2.8044688804306226

Epoch: 5| Step: 6
Training loss: 3.204416451971943
Validation loss: 2.8044413934121093

Epoch: 5| Step: 7
Training loss: 3.3271265099163694
Validation loss: 2.811108683248482

Epoch: 5| Step: 8
Training loss: 3.4561151185024652
Validation loss: 2.7967197771343786

Epoch: 5| Step: 9
Training loss: 3.2027846737078183
Validation loss: 2.7892686085170175

Epoch: 5| Step: 10
Training loss: 2.6684626154304563
Validation loss: 2.787080591824958

Epoch: 38| Step: 0
Training loss: 3.0758942397033633
Validation loss: 2.7847568865535552

Epoch: 5| Step: 1
Training loss: 3.3869316271764283
Validation loss: 2.7840603765361753

Epoch: 5| Step: 2
Training loss: 3.231824228407658
Validation loss: 2.7843086400222083

Epoch: 5| Step: 3
Training loss: 3.4024047145352503
Validation loss: 2.782073354987744

Epoch: 5| Step: 4
Training loss: 3.4969714549434707
Validation loss: 2.782018590557372

Epoch: 5| Step: 5
Training loss: 3.008659738883319
Validation loss: 2.7797292165062957

Epoch: 5| Step: 6
Training loss: 2.7535421793643944
Validation loss: 2.781111458100795

Epoch: 5| Step: 7
Training loss: 3.016013797343945
Validation loss: 2.7810798040811355

Epoch: 5| Step: 8
Training loss: 2.9254733688871397
Validation loss: 2.7779974026832597

Epoch: 5| Step: 9
Training loss: 2.817781871651618
Validation loss: 2.7755507648656703

Epoch: 5| Step: 10
Training loss: 2.926510484419538
Validation loss: 2.774281706891386

Epoch: 39| Step: 0
Training loss: 3.0585468235045585
Validation loss: 2.778336456544314

Epoch: 5| Step: 1
Training loss: 2.744692622695411
Validation loss: 2.7775773875102927

Epoch: 5| Step: 2
Training loss: 2.8940999357082005
Validation loss: 2.782503600222189

Epoch: 5| Step: 3
Training loss: 3.324846255541125
Validation loss: 2.783989114590025

Epoch: 5| Step: 4
Training loss: 2.9440507285681767
Validation loss: 2.7830731162747373

Epoch: 5| Step: 5
Training loss: 3.4742017638758638
Validation loss: 2.7885932108174742

Epoch: 5| Step: 6
Training loss: 2.833050059201117
Validation loss: 2.786100796860124

Epoch: 5| Step: 7
Training loss: 2.9124304570748745
Validation loss: 2.781677451059891

Epoch: 5| Step: 8
Training loss: 3.189434885415544
Validation loss: 2.7763163485276174

Epoch: 5| Step: 9
Training loss: 3.4676995963783623
Validation loss: 2.7715157121878344

Epoch: 5| Step: 10
Training loss: 3.1091195006325933
Validation loss: 2.766706212338481

Epoch: 40| Step: 0
Training loss: 3.1965929371190898
Validation loss: 2.7659526705228616

Epoch: 5| Step: 1
Training loss: 2.859776869919669
Validation loss: 2.7668809744982075

Epoch: 5| Step: 2
Training loss: 3.0783310254853715
Validation loss: 2.7683682044701543

Epoch: 5| Step: 3
Training loss: 3.2819704263994733
Validation loss: 2.7665755284575426

Epoch: 5| Step: 4
Training loss: 2.7935609416442264
Validation loss: 2.7663479761424865

Epoch: 5| Step: 5
Training loss: 3.011072230430163
Validation loss: 2.768954779568866

Epoch: 5| Step: 6
Training loss: 2.7002542941116956
Validation loss: 2.764518604082895

Epoch: 5| Step: 7
Training loss: 3.230923197469537
Validation loss: 2.7635327032692723

Epoch: 5| Step: 8
Training loss: 3.1101077955889416
Validation loss: 2.7667387757860427

Epoch: 5| Step: 9
Training loss: 3.2824488311753877
Validation loss: 2.7651580950354613

Epoch: 5| Step: 10
Training loss: 3.3887502523806994
Validation loss: 2.7644517144494243

Epoch: 41| Step: 0
Training loss: 3.263927547866179
Validation loss: 2.759819041914496

Epoch: 5| Step: 1
Training loss: 3.1758084266691577
Validation loss: 2.758544006818276

Epoch: 5| Step: 2
Training loss: 2.958160789365126
Validation loss: 2.7581638978106606

Epoch: 5| Step: 3
Training loss: 3.7524093517356505
Validation loss: 2.7583416901633386

Epoch: 5| Step: 4
Training loss: 2.586489892143057
Validation loss: 2.7550769350203517

Epoch: 5| Step: 5
Training loss: 2.618051961215582
Validation loss: 2.7636775984169097

Epoch: 5| Step: 6
Training loss: 2.9487223428461684
Validation loss: 2.7794896327608023

Epoch: 5| Step: 7
Training loss: 3.2463854717179608
Validation loss: 2.7829419131307334

Epoch: 5| Step: 8
Training loss: 2.720064393571553
Validation loss: 2.804333667737082

Epoch: 5| Step: 9
Training loss: 3.325550355035899
Validation loss: 2.835729051829667

Epoch: 5| Step: 10
Training loss: 3.114304665099114
Validation loss: 2.807793752118184

Epoch: 42| Step: 0
Training loss: 3.089834799192946
Validation loss: 2.818095732490879

Epoch: 5| Step: 1
Training loss: 2.8182634428514644
Validation loss: 2.812317603245906

Epoch: 5| Step: 2
Training loss: 2.9468923525739266
Validation loss: 2.7897268448346604

Epoch: 5| Step: 3
Training loss: 3.2822325189156754
Validation loss: 2.771234291951269

Epoch: 5| Step: 4
Training loss: 2.9527272758898158
Validation loss: 2.748948738098713

Epoch: 5| Step: 5
Training loss: 3.262345561029719
Validation loss: 2.751040740912095

Epoch: 5| Step: 6
Training loss: 3.0713656029313925
Validation loss: 2.760001250244899

Epoch: 5| Step: 7
Training loss: 3.0405666678970005
Validation loss: 2.7667429398916124

Epoch: 5| Step: 8
Training loss: 3.568177634602862
Validation loss: 2.7567698750947662

Epoch: 5| Step: 9
Training loss: 2.8320942207438824
Validation loss: 2.748938843306672

Epoch: 5| Step: 10
Training loss: 3.134843201434963
Validation loss: 2.7460623262230377

Epoch: 43| Step: 0
Training loss: 2.711816650663161
Validation loss: 2.742126887678542

Epoch: 5| Step: 1
Training loss: 3.135247784667848
Validation loss: 2.746332385327815

Epoch: 5| Step: 2
Training loss: 3.404091807506893
Validation loss: 2.75004806551128

Epoch: 5| Step: 3
Training loss: 2.8141633095653944
Validation loss: 2.766777914795284

Epoch: 5| Step: 4
Training loss: 3.4772748238822975
Validation loss: 2.7929425826432754

Epoch: 5| Step: 5
Training loss: 3.264124329284031
Validation loss: 2.81140694975316

Epoch: 5| Step: 6
Training loss: 3.376324429078258
Validation loss: 2.7591800826038315

Epoch: 5| Step: 7
Training loss: 2.1333865556435807
Validation loss: 2.746331632944511

Epoch: 5| Step: 8
Training loss: 2.918275952286111
Validation loss: 2.7406067137879226

Epoch: 5| Step: 9
Training loss: 3.4267512723915217
Validation loss: 2.7442363233173324

Epoch: 5| Step: 10
Training loss: 3.001114320432769
Validation loss: 2.750080474764875

Epoch: 44| Step: 0
Training loss: 2.648476569413615
Validation loss: 2.7512243049537894

Epoch: 5| Step: 1
Training loss: 3.1763113782913024
Validation loss: 2.7588216013817592

Epoch: 5| Step: 2
Training loss: 2.934465342340568
Validation loss: 2.765803351797512

Epoch: 5| Step: 3
Training loss: 3.014384276367695
Validation loss: 2.75702432197281

Epoch: 5| Step: 4
Training loss: 3.098529091393593
Validation loss: 2.7488106750197314

Epoch: 5| Step: 5
Training loss: 3.042303950466877
Validation loss: 2.741032375368858

Epoch: 5| Step: 6
Training loss: 2.9129039107770804
Validation loss: 2.7383051357415646

Epoch: 5| Step: 7
Training loss: 3.0203987247416357
Validation loss: 2.737215786235471

Epoch: 5| Step: 8
Training loss: 3.53134830304267
Validation loss: 2.733720473841018

Epoch: 5| Step: 9
Training loss: 3.1685966499737086
Validation loss: 2.731920990568483

Epoch: 5| Step: 10
Training loss: 3.220127440590291
Validation loss: 2.7322529958567134

Epoch: 45| Step: 0
Training loss: 3.269495372507006
Validation loss: 2.732882848644076

Epoch: 5| Step: 1
Training loss: 2.4816969346488618
Validation loss: 2.7328407814235436

Epoch: 5| Step: 2
Training loss: 3.291209338002549
Validation loss: 2.731226437738928

Epoch: 5| Step: 3
Training loss: 4.000059365785659
Validation loss: 2.7310331028000765

Epoch: 5| Step: 4
Training loss: 2.4685562637219034
Validation loss: 2.729329938841543

Epoch: 5| Step: 5
Training loss: 2.3628841350237373
Validation loss: 2.727427650838747

Epoch: 5| Step: 6
Training loss: 2.8479566376417487
Validation loss: 2.730231293415942

Epoch: 5| Step: 7
Training loss: 2.9022696525387444
Validation loss: 2.735079731168335

Epoch: 5| Step: 8
Training loss: 3.104822401044673
Validation loss: 2.737290277602987

Epoch: 5| Step: 9
Training loss: 3.343121335834714
Validation loss: 2.736421733779625

Epoch: 5| Step: 10
Training loss: 3.2420555731348024
Validation loss: 2.73050468339378

Epoch: 46| Step: 0
Training loss: 3.236530267713887
Validation loss: 2.726837280692772

Epoch: 5| Step: 1
Training loss: 2.9336868860569227
Validation loss: 2.7263674200960066

Epoch: 5| Step: 2
Training loss: 3.1337700424496813
Validation loss: 2.727740413819583

Epoch: 5| Step: 3
Training loss: 3.33811332982003
Validation loss: 2.724284047392074

Epoch: 5| Step: 4
Training loss: 2.982324345061333
Validation loss: 2.729589701122536

Epoch: 5| Step: 5
Training loss: 2.9379500997939694
Validation loss: 2.727190412641454

Epoch: 5| Step: 6
Training loss: 2.1680754214325706
Validation loss: 2.72584548098733

Epoch: 5| Step: 7
Training loss: 3.39017226892683
Validation loss: 2.7255062444736367

Epoch: 5| Step: 8
Training loss: 2.8743137701637633
Validation loss: 2.724987209275373

Epoch: 5| Step: 9
Training loss: 3.2221004492305387
Validation loss: 2.721537608229375

Epoch: 5| Step: 10
Training loss: 3.185330568941795
Validation loss: 2.7218958827396014

Epoch: 47| Step: 0
Training loss: 3.7786826253090506
Validation loss: 2.721463542910258

Epoch: 5| Step: 1
Training loss: 2.746936392070945
Validation loss: 2.7206672185705942

Epoch: 5| Step: 2
Training loss: 3.3521709467832217
Validation loss: 2.7181471025451

Epoch: 5| Step: 3
Training loss: 2.470711906327033
Validation loss: 2.7168308679765607

Epoch: 5| Step: 4
Training loss: 3.1113517267034827
Validation loss: 2.7194344301798528

Epoch: 5| Step: 5
Training loss: 3.5059045305239613
Validation loss: 2.718558100423735

Epoch: 5| Step: 6
Training loss: 2.9689915608960353
Validation loss: 2.7188372194309474

Epoch: 5| Step: 7
Training loss: 2.648880372954696
Validation loss: 2.715440687239463

Epoch: 5| Step: 8
Training loss: 2.447716259700149
Validation loss: 2.7181209373457436

Epoch: 5| Step: 9
Training loss: 2.6872967487924657
Validation loss: 2.7293337833652784

Epoch: 5| Step: 10
Training loss: 3.570326924034047
Validation loss: 2.7370583386280183

Epoch: 48| Step: 0
Training loss: 2.973532268158574
Validation loss: 2.7452554708823356

Epoch: 5| Step: 1
Training loss: 2.8859373281630636
Validation loss: 2.7620308887865406

Epoch: 5| Step: 2
Training loss: 3.5506642808102784
Validation loss: 2.7518429859122486

Epoch: 5| Step: 3
Training loss: 3.05953368729076
Validation loss: 2.7270225463290365

Epoch: 5| Step: 4
Training loss: 3.3357283729916243
Validation loss: 2.713128259391163

Epoch: 5| Step: 5
Training loss: 3.0986332741588845
Validation loss: 2.7131283803386315

Epoch: 5| Step: 6
Training loss: 2.471712483731449
Validation loss: 2.7130126141360438

Epoch: 5| Step: 7
Training loss: 3.0608528534429236
Validation loss: 2.710929707703351

Epoch: 5| Step: 8
Training loss: 2.8184421075110118
Validation loss: 2.7124406387973528

Epoch: 5| Step: 9
Training loss: 3.287153763904833
Validation loss: 2.717342438085895

Epoch: 5| Step: 10
Training loss: 2.9359490378631725
Validation loss: 2.714527600927882

Epoch: 49| Step: 0
Training loss: 3.259104081595562
Validation loss: 2.7180968921524085

Epoch: 5| Step: 1
Training loss: 2.2340791946621903
Validation loss: 2.7239586705770518

Epoch: 5| Step: 2
Training loss: 2.6023072789023445
Validation loss: 2.7281388939595055

Epoch: 5| Step: 3
Training loss: 3.3573031401706936
Validation loss: 2.7506484276815617

Epoch: 5| Step: 4
Training loss: 3.4116012116231342
Validation loss: 2.731894106151911

Epoch: 5| Step: 5
Training loss: 2.9890986103881736
Validation loss: 2.710862484975346

Epoch: 5| Step: 6
Training loss: 3.160214040484797
Validation loss: 2.7049163131440856

Epoch: 5| Step: 7
Training loss: 3.3466423573567283
Validation loss: 2.7071386666754416

Epoch: 5| Step: 8
Training loss: 2.682062903466631
Validation loss: 2.7093439461585636

Epoch: 5| Step: 9
Training loss: 2.9312460047322517
Validation loss: 2.717944172762624

Epoch: 5| Step: 10
Training loss: 3.4267971920382636
Validation loss: 2.724923473772686

Epoch: 50| Step: 0
Training loss: 3.069870934025518
Validation loss: 2.730910302108633

Epoch: 5| Step: 1
Training loss: 2.77092429181478
Validation loss: 2.7255330573934886

Epoch: 5| Step: 2
Training loss: 3.294446149943187
Validation loss: 2.7143447928568665

Epoch: 5| Step: 3
Training loss: 2.9866059437891304
Validation loss: 2.707949985764656

Epoch: 5| Step: 4
Training loss: 2.8672891125876325
Validation loss: 2.7007633865724734

Epoch: 5| Step: 5
Training loss: 3.5490855583912384
Validation loss: 2.7020240299449134

Epoch: 5| Step: 6
Training loss: 2.997082404158567
Validation loss: 2.7006010095713955

Epoch: 5| Step: 7
Training loss: 2.662269682615958
Validation loss: 2.7014008898461928

Epoch: 5| Step: 8
Training loss: 3.157327600214023
Validation loss: 2.698805612485067

Epoch: 5| Step: 9
Training loss: 2.9861847348464368
Validation loss: 2.6979261768658223

Epoch: 5| Step: 10
Training loss: 2.951111445133287
Validation loss: 2.6988370706944775

Epoch: 51| Step: 0
Training loss: 2.6302411571506683
Validation loss: 2.698979706660457

Epoch: 5| Step: 1
Training loss: 2.6035554600935544
Validation loss: 2.6966741046533964

Epoch: 5| Step: 2
Training loss: 3.468260721976926
Validation loss: 2.693963779246074

Epoch: 5| Step: 3
Training loss: 3.176685912910218
Validation loss: 2.694726640549134

Epoch: 5| Step: 4
Training loss: 2.958061492322024
Validation loss: 2.697311765592406

Epoch: 5| Step: 5
Training loss: 3.3352982134081026
Validation loss: 2.7069578560503342

Epoch: 5| Step: 6
Training loss: 3.01154157659188
Validation loss: 2.7191714868973613

Epoch: 5| Step: 7
Training loss: 3.4735389162702983
Validation loss: 2.756830625784051

Epoch: 5| Step: 8
Training loss: 3.150253340206611
Validation loss: 2.7231260166212774

Epoch: 5| Step: 9
Training loss: 2.9589178197444865
Validation loss: 2.7195320989374228

Epoch: 5| Step: 10
Training loss: 2.3701047138629323
Validation loss: 2.707056825379653

Epoch: 52| Step: 0
Training loss: 2.5892149102814033
Validation loss: 2.701559678246578

Epoch: 5| Step: 1
Training loss: 2.920818933586581
Validation loss: 2.6982657569022503

Epoch: 5| Step: 2
Training loss: 2.8769953893598696
Validation loss: 2.6955653469862346

Epoch: 5| Step: 3
Training loss: 3.3483071334317644
Validation loss: 2.6955544221538283

Epoch: 5| Step: 4
Training loss: 3.1544138789251583
Validation loss: 2.693514749434714

Epoch: 5| Step: 5
Training loss: 3.300197138822215
Validation loss: 2.69499495200479

Epoch: 5| Step: 6
Training loss: 3.340373393219376
Validation loss: 2.6956731244997676

Epoch: 5| Step: 7
Training loss: 2.6733206245741794
Validation loss: 2.692410819859539

Epoch: 5| Step: 8
Training loss: 2.7136784749069554
Validation loss: 2.6922947979475964

Epoch: 5| Step: 9
Training loss: 2.9116434892570062
Validation loss: 2.688799869737362

Epoch: 5| Step: 10
Training loss: 3.3979249063404002
Validation loss: 2.6905653790603243

Epoch: 53| Step: 0
Training loss: 3.0152586086824935
Validation loss: 2.6916135874227662

Epoch: 5| Step: 1
Training loss: 3.4821033685142884
Validation loss: 2.688828390184899

Epoch: 5| Step: 2
Training loss: 2.811372488566788
Validation loss: 2.6872226355422164

Epoch: 5| Step: 3
Training loss: 2.6204256437073767
Validation loss: 2.687449207479361

Epoch: 5| Step: 4
Training loss: 2.7643913491766297
Validation loss: 2.6879003722109305

Epoch: 5| Step: 5
Training loss: 3.3523345271499063
Validation loss: 2.6866737940606273

Epoch: 5| Step: 6
Training loss: 3.371541547152401
Validation loss: 2.686554158756167

Epoch: 5| Step: 7
Training loss: 2.7060211190571755
Validation loss: 2.690175655483909

Epoch: 5| Step: 8
Training loss: 3.1925418845635187
Validation loss: 2.69160393046489

Epoch: 5| Step: 9
Training loss: 2.5547436815902858
Validation loss: 2.6960030047976056

Epoch: 5| Step: 10
Training loss: 3.2717833060721015
Validation loss: 2.7103158748113447

Epoch: 54| Step: 0
Training loss: 3.357661320268317
Validation loss: 2.7068993993356036

Epoch: 5| Step: 1
Training loss: 2.859701336024832
Validation loss: 2.7214415695411738

Epoch: 5| Step: 2
Training loss: 2.7038072375598188
Validation loss: 2.7265655003246825

Epoch: 5| Step: 3
Training loss: 3.0125362409888923
Validation loss: 2.73220686499905

Epoch: 5| Step: 4
Training loss: 3.018205082522726
Validation loss: 2.689233400709924

Epoch: 5| Step: 5
Training loss: 2.9921073404834755
Validation loss: 2.6814060876253762

Epoch: 5| Step: 6
Training loss: 2.9733194621436834
Validation loss: 2.684335935596038

Epoch: 5| Step: 7
Training loss: 2.565818777444686
Validation loss: 2.684063484042016

Epoch: 5| Step: 8
Training loss: 3.104261631547768
Validation loss: 2.685672608058338

Epoch: 5| Step: 9
Training loss: 3.4632833207612803
Validation loss: 2.6850550739506858

Epoch: 5| Step: 10
Training loss: 3.2546069431453803
Validation loss: 2.6831508758896954

Epoch: 55| Step: 0
Training loss: 3.2099362782365874
Validation loss: 2.6818338326998394

Epoch: 5| Step: 1
Training loss: 2.9917777555307765
Validation loss: 2.684897775791453

Epoch: 5| Step: 2
Training loss: 3.1489950968903173
Validation loss: 2.6827377064759617

Epoch: 5| Step: 3
Training loss: 2.3169673349500606
Validation loss: 2.682194780287848

Epoch: 5| Step: 4
Training loss: 3.1904261004915555
Validation loss: 2.6780671656913144

Epoch: 5| Step: 5
Training loss: 3.2520718939460047
Validation loss: 2.6785737074663083

Epoch: 5| Step: 6
Training loss: 3.426195456715391
Validation loss: 2.683195648324587

Epoch: 5| Step: 7
Training loss: 2.7759553038217164
Validation loss: 2.6815841058563965

Epoch: 5| Step: 8
Training loss: 2.6235352925652533
Validation loss: 2.686575749498996

Epoch: 5| Step: 9
Training loss: 3.2183239108526687
Validation loss: 2.682673415391041

Epoch: 5| Step: 10
Training loss: 2.8813232875944825
Validation loss: 2.6847076848198705

Epoch: 56| Step: 0
Training loss: 2.9652137977751476
Validation loss: 2.680950740382677

Epoch: 5| Step: 1
Training loss: 3.531193150425617
Validation loss: 2.683867918935508

Epoch: 5| Step: 2
Training loss: 3.122928695876095
Validation loss: 2.6843064295600434

Epoch: 5| Step: 3
Training loss: 2.6067321550902287
Validation loss: 2.6794155005166904

Epoch: 5| Step: 4
Training loss: 3.1929767904420725
Validation loss: 2.682825238570773

Epoch: 5| Step: 5
Training loss: 2.7501126179610367
Validation loss: 2.6829429752455733

Epoch: 5| Step: 6
Training loss: 2.463287878103198
Validation loss: 2.684875316013732

Epoch: 5| Step: 7
Training loss: 3.3506149695441434
Validation loss: 2.697149191248223

Epoch: 5| Step: 8
Training loss: 3.2506019328303206
Validation loss: 2.686971444087037

Epoch: 5| Step: 9
Training loss: 2.81476434049842
Validation loss: 2.67659506437509

Epoch: 5| Step: 10
Training loss: 2.9148151151937096
Validation loss: 2.66854137875075

Epoch: 57| Step: 0
Training loss: 3.0650054647823235
Validation loss: 2.6692588686230954

Epoch: 5| Step: 1
Training loss: 2.9185762602825647
Validation loss: 2.6694288893794744

Epoch: 5| Step: 2
Training loss: 3.2581148807698517
Validation loss: 2.66561754384305

Epoch: 5| Step: 3
Training loss: 3.262617560713046
Validation loss: 2.669841605488682

Epoch: 5| Step: 4
Training loss: 3.262431650432339
Validation loss: 2.670620516131864

Epoch: 5| Step: 5
Training loss: 2.8193251130940458
Validation loss: 2.6696569541747603

Epoch: 5| Step: 6
Training loss: 2.6832348001842705
Validation loss: 2.6690905102143567

Epoch: 5| Step: 7
Training loss: 2.979110788385947
Validation loss: 2.6679854118854927

Epoch: 5| Step: 8
Training loss: 3.2010549415704563
Validation loss: 2.668900971478277

Epoch: 5| Step: 9
Training loss: 2.8129437414429734
Validation loss: 2.6643632504859807

Epoch: 5| Step: 10
Training loss: 2.6832287580437795
Validation loss: 2.665673331120777

Epoch: 58| Step: 0
Training loss: 2.670750610054401
Validation loss: 2.669964305597152

Epoch: 5| Step: 1
Training loss: 2.8919438832960265
Validation loss: 2.6731678798850704

Epoch: 5| Step: 2
Training loss: 3.21533955752014
Validation loss: 2.6858686927244326

Epoch: 5| Step: 3
Training loss: 3.0699903789953518
Validation loss: 2.704580847830722

Epoch: 5| Step: 4
Training loss: 2.4960976661806624
Validation loss: 2.715054397396118

Epoch: 5| Step: 5
Training loss: 3.3814105152663596
Validation loss: 2.7079816269615047

Epoch: 5| Step: 6
Training loss: 2.450017333455953
Validation loss: 2.6710631480361924

Epoch: 5| Step: 7
Training loss: 3.486928508790371
Validation loss: 2.6611353750480906

Epoch: 5| Step: 8
Training loss: 2.979462099876763
Validation loss: 2.658952626320864

Epoch: 5| Step: 9
Training loss: 3.1176338354289657
Validation loss: 2.6603171436477164

Epoch: 5| Step: 10
Training loss: 3.1806678104349273
Validation loss: 2.660689295552463

Epoch: 59| Step: 0
Training loss: 2.47307892813101
Validation loss: 2.659516690285744

Epoch: 5| Step: 1
Training loss: 2.9859322684105956
Validation loss: 2.6644021970236076

Epoch: 5| Step: 2
Training loss: 3.305521109122803
Validation loss: 2.6603854354125187

Epoch: 5| Step: 3
Training loss: 2.785226529426457
Validation loss: 2.6625776605113693

Epoch: 5| Step: 4
Training loss: 2.7668425040688125
Validation loss: 2.6699434341292503

Epoch: 5| Step: 5
Training loss: 3.3311626200998194
Validation loss: 2.6611497724763513

Epoch: 5| Step: 6
Training loss: 3.2261306436742005
Validation loss: 2.6589511154906305

Epoch: 5| Step: 7
Training loss: 2.8094927498961
Validation loss: 2.658616600203482

Epoch: 5| Step: 8
Training loss: 2.968860182474253
Validation loss: 2.657553466015782

Epoch: 5| Step: 9
Training loss: 3.476182689707795
Validation loss: 2.6608222153227756

Epoch: 5| Step: 10
Training loss: 2.5520147405216616
Validation loss: 2.660130241049697

Epoch: 60| Step: 0
Training loss: 3.325406392437731
Validation loss: 2.662693902807705

Epoch: 5| Step: 1
Training loss: 3.3740835005055505
Validation loss: 2.664451036949552

Epoch: 5| Step: 2
Training loss: 2.668772362787325
Validation loss: 2.660914784569344

Epoch: 5| Step: 3
Training loss: 2.783650337562666
Validation loss: 2.658819589945156

Epoch: 5| Step: 4
Training loss: 3.728417660528763
Validation loss: 2.6580674344913047

Epoch: 5| Step: 5
Training loss: 2.8428977276054135
Validation loss: 2.655871876507916

Epoch: 5| Step: 6
Training loss: 2.9543201107174144
Validation loss: 2.65442027048177

Epoch: 5| Step: 7
Training loss: 2.7277148415823316
Validation loss: 2.653328681719524

Epoch: 5| Step: 8
Training loss: 2.69840087865775
Validation loss: 2.652018794993908

Epoch: 5| Step: 9
Training loss: 2.830107778916415
Validation loss: 2.6541515383201757

Epoch: 5| Step: 10
Training loss: 2.779449222809752
Validation loss: 2.6551777865883315

Epoch: 61| Step: 0
Training loss: 3.128071762988621
Validation loss: 2.649824691912929

Epoch: 5| Step: 1
Training loss: 3.4133087653030927
Validation loss: 2.6516082133798164

Epoch: 5| Step: 2
Training loss: 2.6924279741519723
Validation loss: 2.654767032051363

Epoch: 5| Step: 3
Training loss: 3.067288916801497
Validation loss: 2.6508715152481614

Epoch: 5| Step: 4
Training loss: 3.2203738366383923
Validation loss: 2.648461034933199

Epoch: 5| Step: 5
Training loss: 3.008840568520117
Validation loss: 2.6508307596802103

Epoch: 5| Step: 6
Training loss: 2.953241901001352
Validation loss: 2.6524457709977898

Epoch: 5| Step: 7
Training loss: 2.5405151906511882
Validation loss: 2.652806879672925

Epoch: 5| Step: 8
Training loss: 2.747307412892678
Validation loss: 2.6655165367303444

Epoch: 5| Step: 9
Training loss: 3.3051331853073074
Validation loss: 2.6752167812551897

Epoch: 5| Step: 10
Training loss: 2.602537138689486
Validation loss: 2.6817609058564313

Epoch: 62| Step: 0
Training loss: 3.0651218324128946
Validation loss: 2.6769462892882103

Epoch: 5| Step: 1
Training loss: 2.7752519716531237
Validation loss: 2.6693148861703184

Epoch: 5| Step: 2
Training loss: 2.3807566294354983
Validation loss: 2.66598130527496

Epoch: 5| Step: 3
Training loss: 2.713477360310606
Validation loss: 2.6710564420249105

Epoch: 5| Step: 4
Training loss: 3.1232855099084054
Validation loss: 2.649156371294508

Epoch: 5| Step: 5
Training loss: 3.0429215825432183
Validation loss: 2.6511640400590366

Epoch: 5| Step: 6
Training loss: 2.8914061444541996
Validation loss: 2.654921745968698

Epoch: 5| Step: 7
Training loss: 2.879105994491111
Validation loss: 2.6590777445744234

Epoch: 5| Step: 8
Training loss: 3.7367847281279287
Validation loss: 2.6529418690401387

Epoch: 5| Step: 9
Training loss: 2.72885900806562
Validation loss: 2.6469794131071303

Epoch: 5| Step: 10
Training loss: 3.347388453772466
Validation loss: 2.6391761719118865

Epoch: 63| Step: 0
Training loss: 2.54373968248829
Validation loss: 2.639885559742468

Epoch: 5| Step: 1
Training loss: 3.216141319529137
Validation loss: 2.6389356669101285

Epoch: 5| Step: 2
Training loss: 3.243186557764125
Validation loss: 2.638775215406376

Epoch: 5| Step: 3
Training loss: 3.1821685783859865
Validation loss: 2.6395466279665674

Epoch: 5| Step: 4
Training loss: 2.766515383739848
Validation loss: 2.638135079441129

Epoch: 5| Step: 5
Training loss: 2.489807427401407
Validation loss: 2.6368949531676207

Epoch: 5| Step: 6
Training loss: 3.0354688721519962
Validation loss: 2.6356164799029127

Epoch: 5| Step: 7
Training loss: 3.0319156505758915
Validation loss: 2.6373996928801193

Epoch: 5| Step: 8
Training loss: 3.3412302095260236
Validation loss: 2.6446204285945853

Epoch: 5| Step: 9
Training loss: 3.0540664704988965
Validation loss: 2.649991936070623

Epoch: 5| Step: 10
Training loss: 2.7557303806019395
Validation loss: 2.656182524604019

Epoch: 64| Step: 0
Training loss: 2.4220072064154694
Validation loss: 2.67903536297139

Epoch: 5| Step: 1
Training loss: 3.32193061444729
Validation loss: 2.6685124512616767

Epoch: 5| Step: 2
Training loss: 3.2622832946130726
Validation loss: 2.6625084755894677

Epoch: 5| Step: 3
Training loss: 2.447303522034237
Validation loss: 2.6495044004127974

Epoch: 5| Step: 4
Training loss: 2.994563899570086
Validation loss: 2.650629338168605

Epoch: 5| Step: 5
Training loss: 3.2951911856911047
Validation loss: 2.6578881594752595

Epoch: 5| Step: 6
Training loss: 3.4143764604638327
Validation loss: 2.646636496692453

Epoch: 5| Step: 7
Training loss: 2.572048076678649
Validation loss: 2.6428810380574523

Epoch: 5| Step: 8
Training loss: 2.883563018940994
Validation loss: 2.653448004478783

Epoch: 5| Step: 9
Training loss: 2.9181645134926195
Validation loss: 2.643068803478818

Epoch: 5| Step: 10
Training loss: 3.1106242828337654
Validation loss: 2.640813686917885

Epoch: 65| Step: 0
Training loss: 3.1411621241757715
Validation loss: 2.64186128705742

Epoch: 5| Step: 1
Training loss: 2.7552995768812174
Validation loss: 2.6399777818181778

Epoch: 5| Step: 2
Training loss: 2.752208343215559
Validation loss: 2.6358767027730314

Epoch: 5| Step: 3
Training loss: 2.853003401739885
Validation loss: 2.63378163376047

Epoch: 5| Step: 4
Training loss: 3.260656345970632
Validation loss: 2.629958936396522

Epoch: 5| Step: 5
Training loss: 2.9899076137495157
Validation loss: 2.6289127202705487

Epoch: 5| Step: 6
Training loss: 2.6059686961778694
Validation loss: 2.62892770958821

Epoch: 5| Step: 7
Training loss: 2.8742343048811225
Validation loss: 2.631589220536435

Epoch: 5| Step: 8
Training loss: 3.2338663336992455
Validation loss: 2.628820786324742

Epoch: 5| Step: 9
Training loss: 3.2028187675165376
Validation loss: 2.6334949688613247

Epoch: 5| Step: 10
Training loss: 2.963437114853529
Validation loss: 2.632178918921717

Epoch: 66| Step: 0
Training loss: 3.105153807978538
Validation loss: 2.631989835057916

Epoch: 5| Step: 1
Training loss: 3.012170740392201
Validation loss: 2.6300577083812886

Epoch: 5| Step: 2
Training loss: 3.4394011355472354
Validation loss: 2.6307542736074585

Epoch: 5| Step: 3
Training loss: 3.112281399446133
Validation loss: 2.627473385685243

Epoch: 5| Step: 4
Training loss: 2.670129484687276
Validation loss: 2.622865857262279

Epoch: 5| Step: 5
Training loss: 2.4044850800246267
Validation loss: 2.6258119967000138

Epoch: 5| Step: 6
Training loss: 3.174975904238121
Validation loss: 2.62908755587204

Epoch: 5| Step: 7
Training loss: 2.6485884631857317
Validation loss: 2.628040954807519

Epoch: 5| Step: 8
Training loss: 3.034193831436297
Validation loss: 2.6465840801027056

Epoch: 5| Step: 9
Training loss: 3.0038259269779535
Validation loss: 2.6416017837710837

Epoch: 5| Step: 10
Training loss: 2.977229646825062
Validation loss: 2.6518246137832335

Epoch: 67| Step: 0
Training loss: 3.142713772612355
Validation loss: 2.671823764595953

Epoch: 5| Step: 1
Training loss: 2.267978471872463
Validation loss: 2.680052684873856

Epoch: 5| Step: 2
Training loss: 3.0190964715181754
Validation loss: 2.666225199406779

Epoch: 5| Step: 3
Training loss: 2.9536402015764636
Validation loss: 2.6378073049799013

Epoch: 5| Step: 4
Training loss: 2.5803080246267354
Validation loss: 2.632310059555872

Epoch: 5| Step: 5
Training loss: 3.077590353760403
Validation loss: 2.627009911942554

Epoch: 5| Step: 6
Training loss: 3.0023303517765547
Validation loss: 2.623065352755622

Epoch: 5| Step: 7
Training loss: 3.1235088605490957
Validation loss: 2.6279107298359485

Epoch: 5| Step: 8
Training loss: 3.321509147873776
Validation loss: 2.6250550947447984

Epoch: 5| Step: 9
Training loss: 3.1047655760993838
Validation loss: 2.627328370357846

Epoch: 5| Step: 10
Training loss: 2.891993513150149
Validation loss: 2.624937381964383

Epoch: 68| Step: 0
Training loss: 2.4023677669658214
Validation loss: 2.6255250260216965

Epoch: 5| Step: 1
Training loss: 2.4504300032081225
Validation loss: 2.623850727610944

Epoch: 5| Step: 2
Training loss: 2.9466339303984452
Validation loss: 2.6281257941834366

Epoch: 5| Step: 3
Training loss: 2.681666497024458
Validation loss: 2.6319023801994024

Epoch: 5| Step: 4
Training loss: 3.193139416879934
Validation loss: 2.638733225687363

Epoch: 5| Step: 5
Training loss: 3.2790624683568805
Validation loss: 2.644070569472119

Epoch: 5| Step: 6
Training loss: 3.112163271173354
Validation loss: 2.6647616277301975

Epoch: 5| Step: 7
Training loss: 3.139454485893073
Validation loss: 2.6752429348509317

Epoch: 5| Step: 8
Training loss: 3.2514067319691544
Validation loss: 2.656659042066557

Epoch: 5| Step: 9
Training loss: 3.4186921667476065
Validation loss: 2.6286879448559626

Epoch: 5| Step: 10
Training loss: 2.450486240014418
Validation loss: 2.6172442088918935

Epoch: 69| Step: 0
Training loss: 3.157116761497354
Validation loss: 2.6215513832488964

Epoch: 5| Step: 1
Training loss: 2.652253409239032
Validation loss: 2.6176986564948774

Epoch: 5| Step: 2
Training loss: 2.7709988900729283
Validation loss: 2.6180007271086416

Epoch: 5| Step: 3
Training loss: 3.1288045992870854
Validation loss: 2.620694885817619

Epoch: 5| Step: 4
Training loss: 3.0034823868909664
Validation loss: 2.620330665723971

Epoch: 5| Step: 5
Training loss: 2.723004924936425
Validation loss: 2.6166064711304413

Epoch: 5| Step: 6
Training loss: 3.0236459901669273
Validation loss: 2.6139183210278665

Epoch: 5| Step: 7
Training loss: 3.440685252979528
Validation loss: 2.6148141653578154

Epoch: 5| Step: 8
Training loss: 2.578648739415484
Validation loss: 2.613787663138699

Epoch: 5| Step: 9
Training loss: 2.8847962044016517
Validation loss: 2.618070547664933

Epoch: 5| Step: 10
Training loss: 3.1534465765697215
Validation loss: 2.6209122393641953

Epoch: 70| Step: 0
Training loss: 2.835330446283823
Validation loss: 2.6405218824744936

Epoch: 5| Step: 1
Training loss: 2.9157974764558072
Validation loss: 2.6537656512568426

Epoch: 5| Step: 2
Training loss: 2.5933003782746087
Validation loss: 2.721903311167055

Epoch: 5| Step: 3
Training loss: 3.244066838132124
Validation loss: 2.7649437090868827

Epoch: 5| Step: 4
Training loss: 3.3835851478511354
Validation loss: 2.673419254981711

Epoch: 5| Step: 5
Training loss: 2.2419158026600914
Validation loss: 2.650597506087815

Epoch: 5| Step: 6
Training loss: 3.3793820790321987
Validation loss: 2.605334943679151

Epoch: 5| Step: 7
Training loss: 2.974090110055015
Validation loss: 2.6116365826763306

Epoch: 5| Step: 8
Training loss: 2.909223614451009
Validation loss: 2.6214839672403

Epoch: 5| Step: 9
Training loss: 3.0229830930226327
Validation loss: 2.623716844515734

Epoch: 5| Step: 10
Training loss: 3.142098000729991
Validation loss: 2.6301024878733195

Epoch: 71| Step: 0
Training loss: 2.449918461435377
Validation loss: 2.6321611844860255

Epoch: 5| Step: 1
Training loss: 2.635190981724542
Validation loss: 2.6166372510208804

Epoch: 5| Step: 2
Training loss: 3.1145880623635884
Validation loss: 2.6145946478091253

Epoch: 5| Step: 3
Training loss: 2.961627648274909
Validation loss: 2.6138229810466025

Epoch: 5| Step: 4
Training loss: 3.241077499654189
Validation loss: 2.6111426278097856

Epoch: 5| Step: 5
Training loss: 2.9584435097679793
Validation loss: 2.60851038460619

Epoch: 5| Step: 6
Training loss: 3.207566025040276
Validation loss: 2.6087195757338426

Epoch: 5| Step: 7
Training loss: 2.804197815886925
Validation loss: 2.6087876851954226

Epoch: 5| Step: 8
Training loss: 3.239828478664726
Validation loss: 2.609678902483586

Epoch: 5| Step: 9
Training loss: 3.1517262285300878
Validation loss: 2.6331774772445486

Epoch: 5| Step: 10
Training loss: 2.664113332313794
Validation loss: 2.6398222833568528

Epoch: 72| Step: 0
Training loss: 2.7596497723991154
Validation loss: 2.6515007998671125

Epoch: 5| Step: 1
Training loss: 3.0358904683253884
Validation loss: 2.680794426416786

Epoch: 5| Step: 2
Training loss: 2.8524043264567798
Validation loss: 2.709296300627198

Epoch: 5| Step: 3
Training loss: 2.8267562673271014
Validation loss: 2.7290494853430904

Epoch: 5| Step: 4
Training loss: 2.8247490222813414
Validation loss: 2.6841659164021427

Epoch: 5| Step: 5
Training loss: 3.305931199970439
Validation loss: 2.6195188675629155

Epoch: 5| Step: 6
Training loss: 3.132822697877339
Validation loss: 2.604081124818386

Epoch: 5| Step: 7
Training loss: 2.543304561820555
Validation loss: 2.6035969625810464

Epoch: 5| Step: 8
Training loss: 3.2411175168726465
Validation loss: 2.606623357529435

Epoch: 5| Step: 9
Training loss: 2.966549670309117
Validation loss: 2.6135019568798348

Epoch: 5| Step: 10
Training loss: 3.011398278588396
Validation loss: 2.6190271021312745

Epoch: 73| Step: 0
Training loss: 3.0385117215596953
Validation loss: 2.629436817808531

Epoch: 5| Step: 1
Training loss: 3.093327194761346
Validation loss: 2.613809146809503

Epoch: 5| Step: 2
Training loss: 2.5701753991384373
Validation loss: 2.6083691339343336

Epoch: 5| Step: 3
Training loss: 3.26650988987585
Validation loss: 2.6043517554352613

Epoch: 5| Step: 4
Training loss: 2.979480504575997
Validation loss: 2.6008450354775907

Epoch: 5| Step: 5
Training loss: 2.844418289971641
Validation loss: 2.599357328901408

Epoch: 5| Step: 6
Training loss: 3.0954261631823603
Validation loss: 2.610984794463429

Epoch: 5| Step: 7
Training loss: 2.829091281101874
Validation loss: 2.6314770296694268

Epoch: 5| Step: 8
Training loss: 2.9219727525321875
Validation loss: 2.6526799067853872

Epoch: 5| Step: 9
Training loss: 2.5677252737315697
Validation loss: 2.6668525097164544

Epoch: 5| Step: 10
Training loss: 3.334751320279074
Validation loss: 2.6891248197901967

Epoch: 74| Step: 0
Training loss: 2.5443000180078057
Validation loss: 2.69301557883556

Epoch: 5| Step: 1
Training loss: 3.2216753952400174
Validation loss: 2.6786688062367876

Epoch: 5| Step: 2
Training loss: 3.7093157949117566
Validation loss: 2.715467444717633

Epoch: 5| Step: 3
Training loss: 2.5532582802693815
Validation loss: 2.6290603804856736

Epoch: 5| Step: 4
Training loss: 2.4001268035451173
Validation loss: 2.5990803261442967

Epoch: 5| Step: 5
Training loss: 2.976270606279234
Validation loss: 2.597324295045949

Epoch: 5| Step: 6
Training loss: 2.6977519177735885
Validation loss: 2.59294442274895

Epoch: 5| Step: 7
Training loss: 3.0697903176934562
Validation loss: 2.592046006703258

Epoch: 5| Step: 8
Training loss: 3.405043362020697
Validation loss: 2.5927053552715265

Epoch: 5| Step: 9
Training loss: 2.823700283469022
Validation loss: 2.5926959103340583

Epoch: 5| Step: 10
Training loss: 2.7510228422291947
Validation loss: 2.593217328761115

Epoch: 75| Step: 0
Training loss: 3.2512500999653065
Validation loss: 2.5924472277412685

Epoch: 5| Step: 1
Training loss: 2.832583459094255
Validation loss: 2.5928832888136975

Epoch: 5| Step: 2
Training loss: 2.4282131812384264
Validation loss: 2.5916646033159703

Epoch: 5| Step: 3
Training loss: 2.730924860196819
Validation loss: 2.5891686394507367

Epoch: 5| Step: 4
Training loss: 2.700418782428826
Validation loss: 2.590975249181886

Epoch: 5| Step: 5
Training loss: 2.836516182027404
Validation loss: 2.5829515092281725

Epoch: 5| Step: 6
Training loss: 2.585834973656735
Validation loss: 2.5844821386787027

Epoch: 5| Step: 7
Training loss: 3.6055149063015937
Validation loss: 2.585049849528761

Epoch: 5| Step: 8
Training loss: 2.6574605539432112
Validation loss: 2.5858290390280327

Epoch: 5| Step: 9
Training loss: 2.8596154617341925
Validation loss: 2.583843512939282

Epoch: 5| Step: 10
Training loss: 3.7683305952986488
Validation loss: 2.586678460532677

Epoch: 76| Step: 0
Training loss: 2.2615074889189564
Validation loss: 2.5864386780928967

Epoch: 5| Step: 1
Training loss: 3.0743758707962305
Validation loss: 2.592744731549118

Epoch: 5| Step: 2
Training loss: 2.9659209575037004
Validation loss: 2.588781570552068

Epoch: 5| Step: 3
Training loss: 2.9154458533688774
Validation loss: 2.5891305484669336

Epoch: 5| Step: 4
Training loss: 2.6635756061665727
Validation loss: 2.5890301279668457

Epoch: 5| Step: 5
Training loss: 3.45015509436473
Validation loss: 2.5972769763295953

Epoch: 5| Step: 6
Training loss: 2.4815911584574875
Validation loss: 2.608913021887001

Epoch: 5| Step: 7
Training loss: 3.5168678629904284
Validation loss: 2.6435216928015817

Epoch: 5| Step: 8
Training loss: 3.518265067744905
Validation loss: 2.6419768999226996

Epoch: 5| Step: 9
Training loss: 2.789436977688569
Validation loss: 2.6093168546316523

Epoch: 5| Step: 10
Training loss: 2.286698406247587
Validation loss: 2.5970012679459207

Epoch: 77| Step: 0
Training loss: 3.0204587156028357
Validation loss: 2.582793254413462

Epoch: 5| Step: 1
Training loss: 3.279186071962929
Validation loss: 2.580397863966341

Epoch: 5| Step: 2
Training loss: 2.465897856144588
Validation loss: 2.580210547516405

Epoch: 5| Step: 3
Training loss: 2.594694034715666
Validation loss: 2.577906775662115

Epoch: 5| Step: 4
Training loss: 2.643428690979428
Validation loss: 2.5769198636639086

Epoch: 5| Step: 5
Training loss: 3.0197183765694944
Validation loss: 2.5782299160856823

Epoch: 5| Step: 6
Training loss: 2.379941317371775
Validation loss: 2.5803616792323676

Epoch: 5| Step: 7
Training loss: 3.2760274833206404
Validation loss: 2.581384296375464

Epoch: 5| Step: 8
Training loss: 2.939418734225729
Validation loss: 2.584079676961032

Epoch: 5| Step: 9
Training loss: 3.564284563651392
Validation loss: 2.581852140608104

Epoch: 5| Step: 10
Training loss: 2.904545930446402
Validation loss: 2.583197712853004

Epoch: 78| Step: 0
Training loss: 2.8676333379632997
Validation loss: 2.5767476021620945

Epoch: 5| Step: 1
Training loss: 3.0653071091890647
Validation loss: 2.5756778104112885

Epoch: 5| Step: 2
Training loss: 2.975017316751811
Validation loss: 2.577423227407173

Epoch: 5| Step: 3
Training loss: 3.4143890294543193
Validation loss: 2.5780103273267527

Epoch: 5| Step: 4
Training loss: 2.752861095167998
Validation loss: 2.5740361340074207

Epoch: 5| Step: 5
Training loss: 2.808414204128277
Validation loss: 2.579133720359148

Epoch: 5| Step: 6
Training loss: 2.8285469878435756
Validation loss: 2.5732708739009

Epoch: 5| Step: 7
Training loss: 2.4601116429558405
Validation loss: 2.5750523199987945

Epoch: 5| Step: 8
Training loss: 2.936000684836825
Validation loss: 2.573850633496099

Epoch: 5| Step: 9
Training loss: 2.7510982401205584
Validation loss: 2.572630405796641

Epoch: 5| Step: 10
Training loss: 3.3332028045528967
Validation loss: 2.5750067464579027

Epoch: 79| Step: 0
Training loss: 3.1020236885548553
Validation loss: 2.571661075635435

Epoch: 5| Step: 1
Training loss: 3.2631737667371294
Validation loss: 2.5796019270475594

Epoch: 5| Step: 2
Training loss: 2.4699251299487783
Validation loss: 2.5740922289302097

Epoch: 5| Step: 3
Training loss: 2.9159021374642453
Validation loss: 2.573537812257608

Epoch: 5| Step: 4
Training loss: 3.136056794547562
Validation loss: 2.571010943161869

Epoch: 5| Step: 5
Training loss: 2.9594611762610414
Validation loss: 2.574622629694475

Epoch: 5| Step: 6
Training loss: 2.6181618769806247
Validation loss: 2.5826636632961066

Epoch: 5| Step: 7
Training loss: 2.7205560758112117
Validation loss: 2.596640488380999

Epoch: 5| Step: 8
Training loss: 2.2625870956601863
Validation loss: 2.5868294888872336

Epoch: 5| Step: 9
Training loss: 3.2098232294293982
Validation loss: 2.579234602702697

Epoch: 5| Step: 10
Training loss: 3.3940814283198084
Validation loss: 2.5825193997186067

Epoch: 80| Step: 0
Training loss: 3.066505770678014
Validation loss: 2.5739843375176332

Epoch: 5| Step: 1
Training loss: 3.2135116765350413
Validation loss: 2.5686570827412787

Epoch: 5| Step: 2
Training loss: 2.855263510867552
Validation loss: 2.5675524263017633

Epoch: 5| Step: 3
Training loss: 2.5851378342499096
Validation loss: 2.5644845628437065

Epoch: 5| Step: 4
Training loss: 2.9909541125359813
Validation loss: 2.5632488368112307

Epoch: 5| Step: 5
Training loss: 2.9212969039788286
Validation loss: 2.5619839439516574

Epoch: 5| Step: 6
Training loss: 2.952320291991766
Validation loss: 2.5625838439334547

Epoch: 5| Step: 7
Training loss: 2.948601219754412
Validation loss: 2.5643552621475996

Epoch: 5| Step: 8
Training loss: 2.5875086318899463
Validation loss: 2.5594464228053178

Epoch: 5| Step: 9
Training loss: 3.0042733909354706
Validation loss: 2.565679912667202

Epoch: 5| Step: 10
Training loss: 2.9372680247811664
Validation loss: 2.5620475907918365

Epoch: 81| Step: 0
Training loss: 3.5932141775310793
Validation loss: 2.5634147728008214

Epoch: 5| Step: 1
Training loss: 3.2002142357637804
Validation loss: 2.5670099336782752

Epoch: 5| Step: 2
Training loss: 2.7724131237071106
Validation loss: 2.572496973224468

Epoch: 5| Step: 3
Training loss: 2.76271283119556
Validation loss: 2.575420357314826

Epoch: 5| Step: 4
Training loss: 2.9555570084545164
Validation loss: 2.579342672066714

Epoch: 5| Step: 5
Training loss: 3.0182586396396314
Validation loss: 2.5676230855110056

Epoch: 5| Step: 6
Training loss: 2.544598269729248
Validation loss: 2.564894221257057

Epoch: 5| Step: 7
Training loss: 2.549858639108697
Validation loss: 2.5660952925970446

Epoch: 5| Step: 8
Training loss: 2.3721709216325895
Validation loss: 2.5602171869385306

Epoch: 5| Step: 9
Training loss: 2.8986345825642292
Validation loss: 2.559052251623621

Epoch: 5| Step: 10
Training loss: 3.2498962679227628
Validation loss: 2.5620004150427946

Epoch: 82| Step: 0
Training loss: 2.857356959222882
Validation loss: 2.5668526076186935

Epoch: 5| Step: 1
Training loss: 2.9907380819117493
Validation loss: 2.5684601834658904

Epoch: 5| Step: 2
Training loss: 3.0318788485717882
Validation loss: 2.5726351690890543

Epoch: 5| Step: 3
Training loss: 3.014523319753376
Validation loss: 2.5653615901177393

Epoch: 5| Step: 4
Training loss: 2.5223726559149853
Validation loss: 2.5675983168678407

Epoch: 5| Step: 5
Training loss: 2.312792785255371
Validation loss: 2.5943212056864606

Epoch: 5| Step: 6
Training loss: 2.8307947866536542
Validation loss: 2.5944009145255276

Epoch: 5| Step: 7
Training loss: 3.4877389313261937
Validation loss: 2.5803384397041165

Epoch: 5| Step: 8
Training loss: 2.962719544593202
Validation loss: 2.564603690860001

Epoch: 5| Step: 9
Training loss: 2.929031339280414
Validation loss: 2.5511650504383447

Epoch: 5| Step: 10
Training loss: 2.9545960975521526
Validation loss: 2.5523276404011614

Epoch: 83| Step: 0
Training loss: 3.2528503829739344
Validation loss: 2.551405691187535

Epoch: 5| Step: 1
Training loss: 2.5837050652437594
Validation loss: 2.5492157091316434

Epoch: 5| Step: 2
Training loss: 2.6497952292158167
Validation loss: 2.5469974075959256

Epoch: 5| Step: 3
Training loss: 3.4242030197990276
Validation loss: 2.5511576333333505

Epoch: 5| Step: 4
Training loss: 3.2382295648110717
Validation loss: 2.5509874047967

Epoch: 5| Step: 5
Training loss: 2.7683976924457254
Validation loss: 2.549844898201482

Epoch: 5| Step: 6
Training loss: 3.334949641955615
Validation loss: 2.551388120270328

Epoch: 5| Step: 7
Training loss: 2.9274612309521757
Validation loss: 2.5535254704252632

Epoch: 5| Step: 8
Training loss: 2.6743432852087468
Validation loss: 2.551205842623052

Epoch: 5| Step: 9
Training loss: 2.837795017047013
Validation loss: 2.5488582358009686

Epoch: 5| Step: 10
Training loss: 1.8205386827608105
Validation loss: 2.5513587276243257

Epoch: 84| Step: 0
Training loss: 3.4360788355299783
Validation loss: 2.55489987689803

Epoch: 5| Step: 1
Training loss: 2.3398716690868775
Validation loss: 2.564306933163985

Epoch: 5| Step: 2
Training loss: 2.9595418977654138
Validation loss: 2.571339806606606

Epoch: 5| Step: 3
Training loss: 2.2954393947729668
Validation loss: 2.5868839001446293

Epoch: 5| Step: 4
Training loss: 3.337926910185311
Validation loss: 2.6082885457111704

Epoch: 5| Step: 5
Training loss: 3.1813491116356563
Validation loss: 2.5577411998760513

Epoch: 5| Step: 6
Training loss: 2.884781989152554
Validation loss: 2.5412446863115568

Epoch: 5| Step: 7
Training loss: 2.6864347786454394
Validation loss: 2.5417142897538167

Epoch: 5| Step: 8
Training loss: 2.8704124005520817
Validation loss: 2.5454903769578086

Epoch: 5| Step: 9
Training loss: 2.81271887033569
Validation loss: 2.5428045628210065

Epoch: 5| Step: 10
Training loss: 3.040817107260739
Validation loss: 2.5504788834789918

Epoch: 85| Step: 0
Training loss: 3.093932637690249
Validation loss: 2.546928746929475

Epoch: 5| Step: 1
Training loss: 2.991281397105174
Validation loss: 2.555130476759337

Epoch: 5| Step: 2
Training loss: 2.9253604112598848
Validation loss: 2.5466806707650553

Epoch: 5| Step: 3
Training loss: 3.0991365953138583
Validation loss: 2.5467645573508575

Epoch: 5| Step: 4
Training loss: 3.0343351100260043
Validation loss: 2.543788075696892

Epoch: 5| Step: 5
Training loss: 2.7655096514941553
Validation loss: 2.540305663034751

Epoch: 5| Step: 6
Training loss: 2.621201719058617
Validation loss: 2.5346137479064765

Epoch: 5| Step: 7
Training loss: 3.0333370613941577
Validation loss: 2.540400031263848

Epoch: 5| Step: 8
Training loss: 2.8550741233489707
Validation loss: 2.5569649029304427

Epoch: 5| Step: 9
Training loss: 2.8999937254739168
Validation loss: 2.562659743097298

Epoch: 5| Step: 10
Training loss: 2.6973436746208916
Validation loss: 2.576046418171269

Epoch: 86| Step: 0
Training loss: 3.396885028392654
Validation loss: 2.5805734631489465

Epoch: 5| Step: 1
Training loss: 2.7656703449562126
Validation loss: 2.587052186848647

Epoch: 5| Step: 2
Training loss: 2.956635341571528
Validation loss: 2.6025196332290346

Epoch: 5| Step: 3
Training loss: 2.8309475634053145
Validation loss: 2.6105615871338506

Epoch: 5| Step: 4
Training loss: 1.932311771696089
Validation loss: 2.5846383807243143

Epoch: 5| Step: 5
Training loss: 3.227182250274883
Validation loss: 2.5641747201172698

Epoch: 5| Step: 6
Training loss: 2.941139725848279
Validation loss: 2.5509757281382184

Epoch: 5| Step: 7
Training loss: 2.961406419003583
Validation loss: 2.5454421178349635

Epoch: 5| Step: 8
Training loss: 2.926407832240432
Validation loss: 2.5440337574580325

Epoch: 5| Step: 9
Training loss: 2.610036891661913
Validation loss: 2.5387131468781794

Epoch: 5| Step: 10
Training loss: 3.1886705231491375
Validation loss: 2.538350703044722

Epoch: 87| Step: 0
Training loss: 2.6320725485012244
Validation loss: 2.5350718276001007

Epoch: 5| Step: 1
Training loss: 2.9603293405780886
Validation loss: 2.537563648048992

Epoch: 5| Step: 2
Training loss: 2.2680044373093784
Validation loss: 2.5372746743632506

Epoch: 5| Step: 3
Training loss: 3.0373671639991815
Validation loss: 2.537629292939009

Epoch: 5| Step: 4
Training loss: 3.468090097702372
Validation loss: 2.5438550393819668

Epoch: 5| Step: 5
Training loss: 3.281614301530762
Validation loss: 2.5423853352575776

Epoch: 5| Step: 6
Training loss: 3.192423738839834
Validation loss: 2.5425901149194523

Epoch: 5| Step: 7
Training loss: 2.778497255184952
Validation loss: 2.539017506240997

Epoch: 5| Step: 8
Training loss: 2.849319035339659
Validation loss: 2.5486868629070054

Epoch: 5| Step: 9
Training loss: 2.2975365341320226
Validation loss: 2.553270674433905

Epoch: 5| Step: 10
Training loss: 2.89767042842059
Validation loss: 2.56837724205093

Epoch: 88| Step: 0
Training loss: 3.019363378914208
Validation loss: 2.5579027365140043

Epoch: 5| Step: 1
Training loss: 2.8481809867829115
Validation loss: 2.5499839879127792

Epoch: 5| Step: 2
Training loss: 2.3654530028047023
Validation loss: 2.5449564975674535

Epoch: 5| Step: 3
Training loss: 3.328714954221818
Validation loss: 2.539579054268184

Epoch: 5| Step: 4
Training loss: 3.086459422339304
Validation loss: 2.529808762384304

Epoch: 5| Step: 5
Training loss: 2.977309245958393
Validation loss: 2.5270994443984907

Epoch: 5| Step: 6
Training loss: 2.885538771119492
Validation loss: 2.532045010387013

Epoch: 5| Step: 7
Training loss: 2.482360887115944
Validation loss: 2.532004439043889

Epoch: 5| Step: 8
Training loss: 2.9094766732221666
Validation loss: 2.5323216701561218

Epoch: 5| Step: 9
Training loss: 3.1422873884701064
Validation loss: 2.5304041504690993

Epoch: 5| Step: 10
Training loss: 2.598566202817393
Validation loss: 2.5259707012215347

Epoch: 89| Step: 0
Training loss: 2.794925798990519
Validation loss: 2.5312921805888737

Epoch: 5| Step: 1
Training loss: 3.086753563478223
Validation loss: 2.5294194967674883

Epoch: 5| Step: 2
Training loss: 2.8818450379494567
Validation loss: 2.5382993820066435

Epoch: 5| Step: 3
Training loss: 2.70210052657313
Validation loss: 2.5327221584788355

Epoch: 5| Step: 4
Training loss: 2.7997171463468127
Validation loss: 2.547143572334811

Epoch: 5| Step: 5
Training loss: 3.155859139290513
Validation loss: 2.546765593169292

Epoch: 5| Step: 6
Training loss: 2.359183701597763
Validation loss: 2.5455810503104157

Epoch: 5| Step: 7
Training loss: 3.2049483901226257
Validation loss: 2.550481178259386

Epoch: 5| Step: 8
Training loss: 3.1434759608326908
Validation loss: 2.5312961881538802

Epoch: 5| Step: 9
Training loss: 2.629649087100608
Validation loss: 2.5281833397108384

Epoch: 5| Step: 10
Training loss: 2.857277689885801
Validation loss: 2.5295379147526527

Epoch: 90| Step: 0
Training loss: 2.280866616837493
Validation loss: 2.531169220103703

Epoch: 5| Step: 1
Training loss: 2.8699007007819333
Validation loss: 2.5305380215541344

Epoch: 5| Step: 2
Training loss: 3.1404965502533706
Validation loss: 2.5255104845251948

Epoch: 5| Step: 3
Training loss: 2.56330942535495
Validation loss: 2.5220285028409313

Epoch: 5| Step: 4
Training loss: 2.780594480608127
Validation loss: 2.5221370016604836

Epoch: 5| Step: 5
Training loss: 2.9458450928650723
Validation loss: 2.521530649516065

Epoch: 5| Step: 6
Training loss: 3.264991078152815
Validation loss: 2.5218428557595316

Epoch: 5| Step: 7
Training loss: 2.146432280667607
Validation loss: 2.5234885165361534

Epoch: 5| Step: 8
Training loss: 3.257110154076176
Validation loss: 2.537564119848021

Epoch: 5| Step: 9
Training loss: 3.5278879550606357
Validation loss: 2.5399951256287068

Epoch: 5| Step: 10
Training loss: 2.595575907899951
Validation loss: 2.5518655636769396

Epoch: 91| Step: 0
Training loss: 2.7148414666694536
Validation loss: 2.5379871377476078

Epoch: 5| Step: 1
Training loss: 2.6185281081410983
Validation loss: 2.5233492683283756

Epoch: 5| Step: 2
Training loss: 2.7092988176206036
Validation loss: 2.528646548427917

Epoch: 5| Step: 3
Training loss: 2.3195417260678295
Validation loss: 2.5197096299568233

Epoch: 5| Step: 4
Training loss: 2.5146647450927535
Validation loss: 2.5165565298203765

Epoch: 5| Step: 5
Training loss: 3.0559758350056017
Validation loss: 2.5177244428066765

Epoch: 5| Step: 6
Training loss: 3.5971684658463925
Validation loss: 2.512314160822243

Epoch: 5| Step: 7
Training loss: 2.7521516012252505
Validation loss: 2.514447944151981

Epoch: 5| Step: 8
Training loss: 3.207824831872454
Validation loss: 2.519846926010155

Epoch: 5| Step: 9
Training loss: 3.167136575734534
Validation loss: 2.5163263255273334

Epoch: 5| Step: 10
Training loss: 2.705072131649498
Validation loss: 2.5315098134801666

Epoch: 92| Step: 0
Training loss: 2.470723293056272
Validation loss: 2.543042069159714

Epoch: 5| Step: 1
Training loss: 2.823516040716581
Validation loss: 2.5654780273100277

Epoch: 5| Step: 2
Training loss: 2.999333148591979
Validation loss: 2.6244151220228313

Epoch: 5| Step: 3
Training loss: 2.5647776646020515
Validation loss: 2.6852830326542847

Epoch: 5| Step: 4
Training loss: 3.232527642954253
Validation loss: 2.6095084144656515

Epoch: 5| Step: 5
Training loss: 2.907333664207495
Validation loss: 2.5371011276342843

Epoch: 5| Step: 6
Training loss: 3.3273899179960615
Validation loss: 2.5197843630064836

Epoch: 5| Step: 7
Training loss: 2.4642367091548527
Validation loss: 2.5292370549236214

Epoch: 5| Step: 8
Training loss: 2.411452478081754
Validation loss: 2.5499856839470816

Epoch: 5| Step: 9
Training loss: 3.392407911002353
Validation loss: 2.6115803056651417

Epoch: 5| Step: 10
Training loss: 3.437045119272731
Validation loss: 2.5527010299262622

Epoch: 93| Step: 0
Training loss: 3.164967047352569
Validation loss: 2.535008134017606

Epoch: 5| Step: 1
Training loss: 3.0806801352169004
Validation loss: 2.529696328145722

Epoch: 5| Step: 2
Training loss: 2.8487834609419553
Validation loss: 2.546373199224702

Epoch: 5| Step: 3
Training loss: 2.8142095668219933
Validation loss: 2.5710066146025543

Epoch: 5| Step: 4
Training loss: 3.4267793808543945
Validation loss: 2.6285291310236256

Epoch: 5| Step: 5
Training loss: 2.5071799172661553
Validation loss: 2.6711887686616933

Epoch: 5| Step: 6
Training loss: 2.6225560027944055
Validation loss: 2.6768564742836847

Epoch: 5| Step: 7
Training loss: 3.4088237033509587
Validation loss: 2.6773724181826015

Epoch: 5| Step: 8
Training loss: 2.615164541461676
Validation loss: 2.639696046527209

Epoch: 5| Step: 9
Training loss: 3.0270053994389277
Validation loss: 2.6104308908666507

Epoch: 5| Step: 10
Training loss: 2.5292400338991885
Validation loss: 2.573123436505379

Epoch: 94| Step: 0
Training loss: 2.6815272652489814
Validation loss: 2.543239287198761

Epoch: 5| Step: 1
Training loss: 3.2415228104889855
Validation loss: 2.528406337254835

Epoch: 5| Step: 2
Training loss: 2.9254443556560004
Validation loss: 2.53231576298377

Epoch: 5| Step: 3
Training loss: 2.8100146014285583
Validation loss: 2.530595589241659

Epoch: 5| Step: 4
Training loss: 3.3595302812040777
Validation loss: 2.533037532611967

Epoch: 5| Step: 5
Training loss: 3.050243217901565
Validation loss: 2.5324786410000795

Epoch: 5| Step: 6
Training loss: 2.4373186484144194
Validation loss: 2.5347503954601436

Epoch: 5| Step: 7
Training loss: 3.1292975820355586
Validation loss: 2.536408685772443

Epoch: 5| Step: 8
Training loss: 2.6724888503553084
Validation loss: 2.5345923586366856

Epoch: 5| Step: 9
Training loss: 2.9831347060190514
Validation loss: 2.534223339773297

Epoch: 5| Step: 10
Training loss: 2.7907690816252724
Validation loss: 2.5279514550649607

Epoch: 95| Step: 0
Training loss: 2.4908915531437144
Validation loss: 2.5280299567070483

Epoch: 5| Step: 1
Training loss: 3.0182611673856754
Validation loss: 2.52653798102286

Epoch: 5| Step: 2
Training loss: 2.6547576302284823
Validation loss: 2.5219537290479885

Epoch: 5| Step: 3
Training loss: 2.9236549219114405
Validation loss: 2.5174354494910487

Epoch: 5| Step: 4
Training loss: 2.8636537650434213
Validation loss: 2.5194667880731196

Epoch: 5| Step: 5
Training loss: 2.484527295320997
Validation loss: 2.5254119145558622

Epoch: 5| Step: 6
Training loss: 3.2112478584231923
Validation loss: 2.527392902445643

Epoch: 5| Step: 7
Training loss: 2.6328407535112355
Validation loss: 2.544864390625769

Epoch: 5| Step: 8
Training loss: 3.0123516758536932
Validation loss: 2.5301120873613616

Epoch: 5| Step: 9
Training loss: 3.3030427487615848
Validation loss: 2.543796319522947

Epoch: 5| Step: 10
Training loss: 3.022595349898983
Validation loss: 2.5677134315722827

Epoch: 96| Step: 0
Training loss: 2.855312108284797
Validation loss: 2.572105843083313

Epoch: 5| Step: 1
Training loss: 2.7032311038322856
Validation loss: 2.55456558834288

Epoch: 5| Step: 2
Training loss: 2.8335983675994565
Validation loss: 2.5330889519069753

Epoch: 5| Step: 3
Training loss: 2.793636044902663
Validation loss: 2.521859136144393

Epoch: 5| Step: 4
Training loss: 3.1007231145835945
Validation loss: 2.5137783470710833

Epoch: 5| Step: 5
Training loss: 3.2575951373361893
Validation loss: 2.508502454217329

Epoch: 5| Step: 6
Training loss: 2.7998392603921394
Validation loss: 2.504482542184646

Epoch: 5| Step: 7
Training loss: 3.043860719770184
Validation loss: 2.5103116506013055

Epoch: 5| Step: 8
Training loss: 2.934875777051082
Validation loss: 2.5033383670857483

Epoch: 5| Step: 9
Training loss: 2.7266299176557176
Validation loss: 2.509432823563023

Epoch: 5| Step: 10
Training loss: 2.553094302941894
Validation loss: 2.50062164350786

Epoch: 97| Step: 0
Training loss: 3.030672627942317
Validation loss: 2.501440822553102

Epoch: 5| Step: 1
Training loss: 3.0753142405651257
Validation loss: 2.51210936646851

Epoch: 5| Step: 2
Training loss: 2.577523271102267
Validation loss: 2.5217598734672975

Epoch: 5| Step: 3
Training loss: 2.3159088578548648
Validation loss: 2.5372703468529827

Epoch: 5| Step: 4
Training loss: 2.2914109405251066
Validation loss: 2.555624120913644

Epoch: 5| Step: 5
Training loss: 2.8124543080327062
Validation loss: 2.5847563973810987

Epoch: 5| Step: 6
Training loss: 3.2882100719996736
Validation loss: 2.5981164752012686

Epoch: 5| Step: 7
Training loss: 3.6730595402761406
Validation loss: 2.539287220592114

Epoch: 5| Step: 8
Training loss: 2.6609052368286856
Validation loss: 2.5144092187734457

Epoch: 5| Step: 9
Training loss: 2.805396540282671
Validation loss: 2.4989341330025314

Epoch: 5| Step: 10
Training loss: 2.7376972179701493
Validation loss: 2.4942760374398096

Epoch: 98| Step: 0
Training loss: 2.626035758443983
Validation loss: 2.497054984428551

Epoch: 5| Step: 1
Training loss: 2.3190605305235517
Validation loss: 2.497801634503516

Epoch: 5| Step: 2
Training loss: 2.8770403049206132
Validation loss: 2.4994902552554716

Epoch: 5| Step: 3
Training loss: 3.0196185771755237
Validation loss: 2.499504979664371

Epoch: 5| Step: 4
Training loss: 2.8654104437424666
Validation loss: 2.4980057617392055

Epoch: 5| Step: 5
Training loss: 2.930792109467339
Validation loss: 2.4955809242586184

Epoch: 5| Step: 6
Training loss: 2.767843703487835
Validation loss: 2.492201593779473

Epoch: 5| Step: 7
Training loss: 2.763079490122894
Validation loss: 2.4901630476489007

Epoch: 5| Step: 8
Training loss: 3.2866825726519475
Validation loss: 2.507119047468545

Epoch: 5| Step: 9
Training loss: 2.952115163763858
Validation loss: 2.510884048756038

Epoch: 5| Step: 10
Training loss: 3.1701205808889177
Validation loss: 2.5137799839066797

Epoch: 99| Step: 0
Training loss: 2.7784504033691033
Validation loss: 2.545207939779426

Epoch: 5| Step: 1
Training loss: 2.6776303772656633
Validation loss: 2.5491885179900957

Epoch: 5| Step: 2
Training loss: 2.8287504568870805
Validation loss: 2.541899586869351

Epoch: 5| Step: 3
Training loss: 2.8817806723352186
Validation loss: 2.519366552972116

Epoch: 5| Step: 4
Training loss: 2.9213093092728704
Validation loss: 2.5048175345184656

Epoch: 5| Step: 5
Training loss: 2.980881008769042
Validation loss: 2.488672186962734

Epoch: 5| Step: 6
Training loss: 2.8936751485746486
Validation loss: 2.4887224132357724

Epoch: 5| Step: 7
Training loss: 2.8038854275640013
Validation loss: 2.487318870787789

Epoch: 5| Step: 8
Training loss: 2.637409035076744
Validation loss: 2.4891704234587633

Epoch: 5| Step: 9
Training loss: 3.1568491149940736
Validation loss: 2.491941121152714

Epoch: 5| Step: 10
Training loss: 3.1073752255297924
Validation loss: 2.4897566083005147

Epoch: 100| Step: 0
Training loss: 3.33284886336307
Validation loss: 2.491881517473118

Epoch: 5| Step: 1
Training loss: 2.7392548532180987
Validation loss: 2.501293354395318

Epoch: 5| Step: 2
Training loss: 2.312884633836555
Validation loss: 2.5235240396584375

Epoch: 5| Step: 3
Training loss: 2.787417484995159
Validation loss: 2.5411274393617895

Epoch: 5| Step: 4
Training loss: 2.6341699558886376
Validation loss: 2.5494352419851687

Epoch: 5| Step: 5
Training loss: 2.5243531446651266
Validation loss: 2.517567778069445

Epoch: 5| Step: 6
Training loss: 3.2469692770935112
Validation loss: 2.4995895228214002

Epoch: 5| Step: 7
Training loss: 2.491781267403405
Validation loss: 2.4899186728728426

Epoch: 5| Step: 8
Training loss: 3.019828436317209
Validation loss: 2.4869187960034975

Epoch: 5| Step: 9
Training loss: 3.340644321082457
Validation loss: 2.491488069232861

Epoch: 5| Step: 10
Training loss: 2.958076806206772
Validation loss: 2.491121848962832

Epoch: 101| Step: 0
Training loss: 2.9476382030801074
Validation loss: 2.4892267325412702

Epoch: 5| Step: 1
Training loss: 2.4933538786743723
Validation loss: 2.494484609298228

Epoch: 5| Step: 2
Training loss: 2.951539921106233
Validation loss: 2.5014267306114855

Epoch: 5| Step: 3
Training loss: 2.8284350483426115
Validation loss: 2.510718588445856

Epoch: 5| Step: 4
Training loss: 2.890377054663879
Validation loss: 2.5183051457419072

Epoch: 5| Step: 5
Training loss: 3.022689529673508
Validation loss: 2.51709926021768

Epoch: 5| Step: 6
Training loss: 2.782498968626313
Validation loss: 2.5152445328182065

Epoch: 5| Step: 7
Training loss: 3.324315429429166
Validation loss: 2.5225910745858373

Epoch: 5| Step: 8
Training loss: 3.00452066594122
Validation loss: 2.5320232470723583

Epoch: 5| Step: 9
Training loss: 2.541958234562434
Validation loss: 2.5272748982492015

Epoch: 5| Step: 10
Training loss: 2.3750610343719987
Validation loss: 2.5101324393762687

Epoch: 102| Step: 0
Training loss: 2.692151413563328
Validation loss: 2.5092094465566777

Epoch: 5| Step: 1
Training loss: 2.6053164779341706
Validation loss: 2.496543691591077

Epoch: 5| Step: 2
Training loss: 2.8973625225534287
Validation loss: 2.496931892393809

Epoch: 5| Step: 3
Training loss: 3.4538791575185734
Validation loss: 2.495340206875376

Epoch: 5| Step: 4
Training loss: 2.8940750565671984
Validation loss: 2.495118101941918

Epoch: 5| Step: 5
Training loss: 2.693633952816369
Validation loss: 2.494256991029033

Epoch: 5| Step: 6
Training loss: 2.5446138232111655
Validation loss: 2.5008671517965797

Epoch: 5| Step: 7
Training loss: 3.0868715828202578
Validation loss: 2.494597496012065

Epoch: 5| Step: 8
Training loss: 2.8484627375737586
Validation loss: 2.498353553383729

Epoch: 5| Step: 9
Training loss: 2.6274139567332404
Validation loss: 2.4950836046452567

Epoch: 5| Step: 10
Training loss: 2.8291597106878044
Validation loss: 2.5068693700751172

Epoch: 103| Step: 0
Training loss: 2.8616835650073034
Validation loss: 2.508348544339753

Epoch: 5| Step: 1
Training loss: 2.7265427378290803
Validation loss: 2.50685016879503

Epoch: 5| Step: 2
Training loss: 2.933664780733363
Validation loss: 2.507979134363665

Epoch: 5| Step: 3
Training loss: 2.4984835794003537
Validation loss: 2.5117355991944663

Epoch: 5| Step: 4
Training loss: 2.9318613354314276
Validation loss: 2.5059383252238345

Epoch: 5| Step: 5
Training loss: 3.147654244277175
Validation loss: 2.5237348548886436

Epoch: 5| Step: 6
Training loss: 2.7515589890032524
Validation loss: 2.5164087667288126

Epoch: 5| Step: 7
Training loss: 2.8578208493569086
Validation loss: 2.5086564711509296

Epoch: 5| Step: 8
Training loss: 3.204602900764292
Validation loss: 2.4979838906988774

Epoch: 5| Step: 9
Training loss: 2.627735256911133
Validation loss: 2.4874835779698485

Epoch: 5| Step: 10
Training loss: 2.5247319447462666
Validation loss: 2.481065751949888

Epoch: 104| Step: 0
Training loss: 2.7927793211821283
Validation loss: 2.4829820600319996

Epoch: 5| Step: 1
Training loss: 3.3199215647612808
Validation loss: 2.4819563618005467

Epoch: 5| Step: 2
Training loss: 2.851218174042241
Validation loss: 2.4833922167834266

Epoch: 5| Step: 3
Training loss: 2.6672278250901362
Validation loss: 2.477006695318883

Epoch: 5| Step: 4
Training loss: 2.9202600595859254
Validation loss: 2.4787779644908254

Epoch: 5| Step: 5
Training loss: 2.9801812389483935
Validation loss: 2.482187202597167

Epoch: 5| Step: 6
Training loss: 2.826753146615069
Validation loss: 2.4856082886091007

Epoch: 5| Step: 7
Training loss: 2.109456152591134
Validation loss: 2.4900658427761093

Epoch: 5| Step: 8
Training loss: 2.609695323539064
Validation loss: 2.509190116058889

Epoch: 5| Step: 9
Training loss: 3.0909492839403097
Validation loss: 2.5353066668557327

Epoch: 5| Step: 10
Training loss: 2.9291965734511516
Validation loss: 2.5858358718803403

Epoch: 105| Step: 0
Training loss: 3.2060537951186694
Validation loss: 2.5494829026346455

Epoch: 5| Step: 1
Training loss: 2.4881203687749793
Validation loss: 2.527956544917209

Epoch: 5| Step: 2
Training loss: 2.2573818337235503
Validation loss: 2.505564579733209

Epoch: 5| Step: 3
Training loss: 2.6078604682912805
Validation loss: 2.512121901910477

Epoch: 5| Step: 4
Training loss: 2.7488953365746123
Validation loss: 2.4926830232063937

Epoch: 5| Step: 5
Training loss: 3.247478093520495
Validation loss: 2.476423455356634

Epoch: 5| Step: 6
Training loss: 3.11229626092168
Validation loss: 2.483693049970232

Epoch: 5| Step: 7
Training loss: 3.053842413023557
Validation loss: 2.486782887066597

Epoch: 5| Step: 8
Training loss: 3.098915027134166
Validation loss: 2.4822055566879664

Epoch: 5| Step: 9
Training loss: 2.788742944699078
Validation loss: 2.48886398348687

Epoch: 5| Step: 10
Training loss: 2.42503770621962
Validation loss: 2.4997906217778194

Epoch: 106| Step: 0
Training loss: 3.0864640571334316
Validation loss: 2.5567604884846458

Epoch: 5| Step: 1
Training loss: 2.630707575688602
Validation loss: 2.591111671955121

Epoch: 5| Step: 2
Training loss: 2.8216258026637
Validation loss: 2.603656149424968

Epoch: 5| Step: 3
Training loss: 2.864175238005934
Validation loss: 2.554992232120543

Epoch: 5| Step: 4
Training loss: 2.5934318439271657
Validation loss: 2.534398437001579

Epoch: 5| Step: 5
Training loss: 2.989277592530931
Validation loss: 2.505835792368449

Epoch: 5| Step: 6
Training loss: 2.2254607034409335
Validation loss: 2.500276996279841

Epoch: 5| Step: 7
Training loss: 3.0564155081339672
Validation loss: 2.4857081832662993

Epoch: 5| Step: 8
Training loss: 2.647489755122577
Validation loss: 2.4829869318056086

Epoch: 5| Step: 9
Training loss: 3.153784516002396
Validation loss: 2.482111558060367

Epoch: 5| Step: 10
Training loss: 3.1366948831108656
Validation loss: 2.4805557283527753

Epoch: 107| Step: 0
Training loss: 2.5745894725170944
Validation loss: 2.480510533227744

Epoch: 5| Step: 1
Training loss: 2.490328391301235
Validation loss: 2.4861946007915607

Epoch: 5| Step: 2
Training loss: 2.7206600977226256
Validation loss: 2.4870863158823817

Epoch: 5| Step: 3
Training loss: 3.0626989806013203
Validation loss: 2.488544752226137

Epoch: 5| Step: 4
Training loss: 2.844578213658933
Validation loss: 2.498268547159135

Epoch: 5| Step: 5
Training loss: 3.3793047543183485
Validation loss: 2.5117276114574123

Epoch: 5| Step: 6
Training loss: 3.0283017322470958
Validation loss: 2.491095417138379

Epoch: 5| Step: 7
Training loss: 2.706194947984454
Validation loss: 2.495441171791135

Epoch: 5| Step: 8
Training loss: 2.62231480543665
Validation loss: 2.507979691459205

Epoch: 5| Step: 9
Training loss: 2.9466690460759333
Validation loss: 2.5097945650121667

Epoch: 5| Step: 10
Training loss: 2.5102801674947814
Validation loss: 2.518214409555009

Epoch: 108| Step: 0
Training loss: 3.0825546071706444
Validation loss: 2.532066935509741

Epoch: 5| Step: 1
Training loss: 2.8045406037436638
Validation loss: 2.521396924480503

Epoch: 5| Step: 2
Training loss: 2.880928230109354
Validation loss: 2.532371535860379

Epoch: 5| Step: 3
Training loss: 2.9919656616525216
Validation loss: 2.542000410928865

Epoch: 5| Step: 4
Training loss: 3.103663273558716
Validation loss: 2.548431496631246

Epoch: 5| Step: 5
Training loss: 2.983296464091957
Validation loss: 2.5105023576049805

Epoch: 5| Step: 6
Training loss: 2.935525433429678
Validation loss: 2.4939859717016213

Epoch: 5| Step: 7
Training loss: 2.4557698564337325
Validation loss: 2.486203629528345

Epoch: 5| Step: 8
Training loss: 2.9059167486291444
Validation loss: 2.4868250765571136

Epoch: 5| Step: 9
Training loss: 1.795692519164283
Validation loss: 2.486644920115581

Epoch: 5| Step: 10
Training loss: 2.963848203192907
Validation loss: 2.5009032012526182

Epoch: 109| Step: 0
Training loss: 3.06389119215512
Validation loss: 2.489942354777992

Epoch: 5| Step: 1
Training loss: 2.631458330401816
Validation loss: 2.5179819102594654

Epoch: 5| Step: 2
Training loss: 2.9699091204472605
Validation loss: 2.5070332335594756

Epoch: 5| Step: 3
Training loss: 2.693099996291793
Validation loss: 2.5006122823769914

Epoch: 5| Step: 4
Training loss: 2.6091330410368263
Validation loss: 2.4920736657125695

Epoch: 5| Step: 5
Training loss: 2.698801629481227
Validation loss: 2.4999250452023674

Epoch: 5| Step: 6
Training loss: 2.67132259257764
Validation loss: 2.4943504877662774

Epoch: 5| Step: 7
Training loss: 3.162241168983705
Validation loss: 2.4972742788002296

Epoch: 5| Step: 8
Training loss: 2.591614085049396
Validation loss: 2.498825986084251

Epoch: 5| Step: 9
Training loss: 3.303802299532981
Validation loss: 2.513590074290491

Epoch: 5| Step: 10
Training loss: 2.3878421917694204
Validation loss: 2.5045135873900413

Epoch: 110| Step: 0
Training loss: 2.568515044741747
Validation loss: 2.482026211957037

Epoch: 5| Step: 1
Training loss: 2.688012362587974
Validation loss: 2.4884574205608465

Epoch: 5| Step: 2
Training loss: 2.79887906525302
Validation loss: 2.5085458164758907

Epoch: 5| Step: 3
Training loss: 2.8643272331661453
Validation loss: 2.4855694109523543

Epoch: 5| Step: 4
Training loss: 2.921095963523416
Validation loss: 2.4855466125656984

Epoch: 5| Step: 5
Training loss: 3.06119213593182
Validation loss: 2.4736291053412907

Epoch: 5| Step: 6
Training loss: 2.768726312609197
Validation loss: 2.472074758751171

Epoch: 5| Step: 7
Training loss: 3.2302747896540946
Validation loss: 2.474503805563672

Epoch: 5| Step: 8
Training loss: 2.908042764950048
Validation loss: 2.4867446097292194

Epoch: 5| Step: 9
Training loss: 2.6887157263138644
Validation loss: 2.4887002576800024

Epoch: 5| Step: 10
Training loss: 2.2174077876893814
Validation loss: 2.491042834633434

Epoch: 111| Step: 0
Training loss: 2.8911094465779543
Validation loss: 2.5130986153136776

Epoch: 5| Step: 1
Training loss: 2.63322133135928
Validation loss: 2.5152327952101694

Epoch: 5| Step: 2
Training loss: 2.620245669837142
Validation loss: 2.524665151141343

Epoch: 5| Step: 3
Training loss: 3.3801374540651485
Validation loss: 2.500552004712627

Epoch: 5| Step: 4
Training loss: 2.402458870463255
Validation loss: 2.489113921533394

Epoch: 5| Step: 5
Training loss: 3.160756887498258
Validation loss: 2.484277191991983

Epoch: 5| Step: 6
Training loss: 3.119424041503176
Validation loss: 2.4870621645727353

Epoch: 5| Step: 7
Training loss: 2.974765024602636
Validation loss: 2.5246209832688504

Epoch: 5| Step: 8
Training loss: 2.7707676031208663
Validation loss: 2.5156333065641023

Epoch: 5| Step: 9
Training loss: 2.600026636720808
Validation loss: 2.4990986337369807

Epoch: 5| Step: 10
Training loss: 2.1253918679136805
Validation loss: 2.4744768408694906

Epoch: 112| Step: 0
Training loss: 2.5404088602878865
Validation loss: 2.4797254204852797

Epoch: 5| Step: 1
Training loss: 2.6191430827903734
Validation loss: 2.4815770942945035

Epoch: 5| Step: 2
Training loss: 3.2105966651621154
Validation loss: 2.4846534317583617

Epoch: 5| Step: 3
Training loss: 2.9362312986022747
Validation loss: 2.487371865951176

Epoch: 5| Step: 4
Training loss: 2.8657811845089207
Validation loss: 2.4860607404569737

Epoch: 5| Step: 5
Training loss: 3.4179695870534688
Validation loss: 2.4799256735125708

Epoch: 5| Step: 6
Training loss: 2.3955424477724434
Validation loss: 2.477680261369344

Epoch: 5| Step: 7
Training loss: 3.081833827049867
Validation loss: 2.498246042190212

Epoch: 5| Step: 8
Training loss: 2.7007750069984975
Validation loss: 2.5083066902984625

Epoch: 5| Step: 9
Training loss: 2.4956629326104047
Validation loss: 2.5477821228915745

Epoch: 5| Step: 10
Training loss: 2.5852432471514435
Validation loss: 2.544651708105111

Epoch: 113| Step: 0
Training loss: 2.67001135005753
Validation loss: 2.552105938474599

Epoch: 5| Step: 1
Training loss: 2.8819765776000765
Validation loss: 2.5492942659464233

Epoch: 5| Step: 2
Training loss: 2.504567741819785
Validation loss: 2.5819196600764087

Epoch: 5| Step: 3
Training loss: 3.2089146834622677
Validation loss: 2.5934237133964446

Epoch: 5| Step: 4
Training loss: 3.09236499340576
Validation loss: 2.552294082093303

Epoch: 5| Step: 5
Training loss: 2.3732069173462906
Validation loss: 2.519677644651362

Epoch: 5| Step: 6
Training loss: 2.7575362718259555
Validation loss: 2.5046076756881037

Epoch: 5| Step: 7
Training loss: 2.6883909833307635
Validation loss: 2.5154982121961593

Epoch: 5| Step: 8
Training loss: 3.139482280789946
Validation loss: 2.5225818549423606

Epoch: 5| Step: 9
Training loss: 2.842577011152214
Validation loss: 2.5098353809755967

Epoch: 5| Step: 10
Training loss: 3.1159761986564116
Validation loss: 2.497813505340944

Epoch: 114| Step: 0
Training loss: 2.423724741732803
Validation loss: 2.495201491471332

Epoch: 5| Step: 1
Training loss: 2.0147388491588827
Validation loss: 2.470886852951496

Epoch: 5| Step: 2
Training loss: 2.6319417447423272
Validation loss: 2.4744937115797385

Epoch: 5| Step: 3
Training loss: 3.0568899034734645
Validation loss: 2.5186948496565678

Epoch: 5| Step: 4
Training loss: 3.114347076811406
Validation loss: 2.603916116454346

Epoch: 5| Step: 5
Training loss: 2.42606822603024
Validation loss: 2.5643086347211805

Epoch: 5| Step: 6
Training loss: 3.01052282513587
Validation loss: 2.557680849287255

Epoch: 5| Step: 7
Training loss: 3.28917702953432
Validation loss: 2.526339053294989

Epoch: 5| Step: 8
Training loss: 2.7518410155593203
Validation loss: 2.4866591618072835

Epoch: 5| Step: 9
Training loss: 2.9793492685834915
Validation loss: 2.4942937167285617

Epoch: 5| Step: 10
Training loss: 3.142467053467531
Validation loss: 2.489062461026225

Epoch: 115| Step: 0
Training loss: 3.5375938483955522
Validation loss: 2.488315078171335

Epoch: 5| Step: 1
Training loss: 2.76556086061748
Validation loss: 2.488937738729826

Epoch: 5| Step: 2
Training loss: 2.6445999474667454
Validation loss: 2.48136179231949

Epoch: 5| Step: 3
Training loss: 2.7012739955219383
Validation loss: 2.4747311522423154

Epoch: 5| Step: 4
Training loss: 3.0049039178552768
Validation loss: 2.459866540108002

Epoch: 5| Step: 5
Training loss: 2.6791147226031393
Validation loss: 2.481892777035649

Epoch: 5| Step: 6
Training loss: 2.746746739852997
Validation loss: 2.5390572648037817

Epoch: 5| Step: 7
Training loss: 2.464266411683994
Validation loss: 2.5562426925632153

Epoch: 5| Step: 8
Training loss: 2.8707942884324855
Validation loss: 2.578920341014043

Epoch: 5| Step: 9
Training loss: 2.808242882046389
Validation loss: 2.553572933256446

Epoch: 5| Step: 10
Training loss: 2.768092374869919
Validation loss: 2.484899378724472

Epoch: 116| Step: 0
Training loss: 3.094760768192157
Validation loss: 2.467387864005492

Epoch: 5| Step: 1
Training loss: 3.080940159816737
Validation loss: 2.47599439444396

Epoch: 5| Step: 2
Training loss: 2.829228644237597
Validation loss: 2.485670529343164

Epoch: 5| Step: 3
Training loss: 2.763741406755619
Validation loss: 2.4872098240544833

Epoch: 5| Step: 4
Training loss: 2.94647517642199
Validation loss: 2.489446023442872

Epoch: 5| Step: 5
Training loss: 2.9269062318994834
Validation loss: 2.494815325264626

Epoch: 5| Step: 6
Training loss: 3.0914203850743784
Validation loss: 2.488620955284759

Epoch: 5| Step: 7
Training loss: 2.826398459461785
Validation loss: 2.488937657358721

Epoch: 5| Step: 8
Training loss: 2.8834472619041636
Validation loss: 2.4888531432750374

Epoch: 5| Step: 9
Training loss: 2.3552295569692836
Validation loss: 2.489515732451387

Epoch: 5| Step: 10
Training loss: 2.818603927988953
Validation loss: 2.483102173282843

Epoch: 117| Step: 0
Training loss: 2.723943813618364
Validation loss: 2.478245243805583

Epoch: 5| Step: 1
Training loss: 3.1015769516154186
Validation loss: 2.471286178651774

Epoch: 5| Step: 2
Training loss: 2.6681815156113804
Validation loss: 2.4797775616840716

Epoch: 5| Step: 3
Training loss: 2.8822568445798584
Validation loss: 2.4768236438665285

Epoch: 5| Step: 4
Training loss: 3.005870479491347
Validation loss: 2.5053558548361434

Epoch: 5| Step: 5
Training loss: 2.6558225399963447
Validation loss: 2.5199966554087267

Epoch: 5| Step: 6
Training loss: 3.374299859787539
Validation loss: 2.597782084282106

Epoch: 5| Step: 7
Training loss: 2.7217072812951306
Validation loss: 2.5938761493019946

Epoch: 5| Step: 8
Training loss: 2.5969532868741676
Validation loss: 2.527871183322166

Epoch: 5| Step: 9
Training loss: 2.620965127304704
Validation loss: 2.503509610371999

Epoch: 5| Step: 10
Training loss: 2.688781610123075
Validation loss: 2.480767323187501

Epoch: 118| Step: 0
Training loss: 2.720229699870243
Validation loss: 2.474759324632677

Epoch: 5| Step: 1
Training loss: 2.621579803107756
Validation loss: 2.4786865891177667

Epoch: 5| Step: 2
Training loss: 2.6063224617743974
Validation loss: 2.4692877228900443

Epoch: 5| Step: 3
Training loss: 3.0558027880282603
Validation loss: 2.4697869312842

Epoch: 5| Step: 4
Training loss: 3.0071676776846723
Validation loss: 2.4685395019810663

Epoch: 5| Step: 5
Training loss: 2.936894131127503
Validation loss: 2.4745154079479983

Epoch: 5| Step: 6
Training loss: 3.156982034829673
Validation loss: 2.4775305454345538

Epoch: 5| Step: 7
Training loss: 2.234600882683285
Validation loss: 2.4825621987600193

Epoch: 5| Step: 8
Training loss: 3.1422587078871276
Validation loss: 2.5056968210840367

Epoch: 5| Step: 9
Training loss: 2.2629350149185425
Validation loss: 2.5095175885041465

Epoch: 5| Step: 10
Training loss: 3.080246402495334
Validation loss: 2.5141125749482094

Epoch: 119| Step: 0
Training loss: 2.2382610113750148
Validation loss: 2.5102180171229347

Epoch: 5| Step: 1
Training loss: 3.3934272401877488
Validation loss: 2.499184335935849

Epoch: 5| Step: 2
Training loss: 2.828525409489274
Validation loss: 2.479829164212011

Epoch: 5| Step: 3
Training loss: 2.92639447089831
Validation loss: 2.4727996326854464

Epoch: 5| Step: 4
Training loss: 2.875698170683438
Validation loss: 2.4651649907623487

Epoch: 5| Step: 5
Training loss: 3.217784996185613
Validation loss: 2.467283682352539

Epoch: 5| Step: 6
Training loss: 2.663530313355486
Validation loss: 2.4593191643441963

Epoch: 5| Step: 7
Training loss: 2.6903363718787583
Validation loss: 2.465062358348417

Epoch: 5| Step: 8
Training loss: 2.647473185027923
Validation loss: 2.4680069713483435

Epoch: 5| Step: 9
Training loss: 2.465079657484301
Validation loss: 2.46677905060601

Epoch: 5| Step: 10
Training loss: 2.696358563426511
Validation loss: 2.477545444847432

Epoch: 120| Step: 0
Training loss: 3.2498667763034077
Validation loss: 2.5006634888004404

Epoch: 5| Step: 1
Training loss: 2.6731059490289355
Validation loss: 2.489992532779445

Epoch: 5| Step: 2
Training loss: 3.1523035134320265
Validation loss: 2.4894416982637275

Epoch: 5| Step: 3
Training loss: 3.0961861314835413
Validation loss: 2.5337655346690036

Epoch: 5| Step: 4
Training loss: 2.5097092915309585
Validation loss: 2.522773351766921

Epoch: 5| Step: 5
Training loss: 2.296128651294321
Validation loss: 2.5371931526507066

Epoch: 5| Step: 6
Training loss: 2.7906105169281403
Validation loss: 2.52266620346463

Epoch: 5| Step: 7
Training loss: 2.957214914158751
Validation loss: 2.5350755773843643

Epoch: 5| Step: 8
Training loss: 2.3248899372260277
Validation loss: 2.5249832586502854

Epoch: 5| Step: 9
Training loss: 2.3254080670659167
Validation loss: 2.4687141134432387

Epoch: 5| Step: 10
Training loss: 3.2226713422942055
Validation loss: 2.4699832561291237

Epoch: 121| Step: 0
Training loss: 3.0786781394957297
Validation loss: 2.4534811745374805

Epoch: 5| Step: 1
Training loss: 2.8396417475117217
Validation loss: 2.4597320130313007

Epoch: 5| Step: 2
Training loss: 2.9477540275721568
Validation loss: 2.4679525387240533

Epoch: 5| Step: 3
Training loss: 2.501045961917831
Validation loss: 2.457996791358737

Epoch: 5| Step: 4
Training loss: 2.761362098639189
Validation loss: 2.471253471164804

Epoch: 5| Step: 5
Training loss: 3.013939104575012
Validation loss: 2.4677114445266897

Epoch: 5| Step: 6
Training loss: 2.798392369062424
Validation loss: 2.4676708824067393

Epoch: 5| Step: 7
Training loss: 2.935620457379938
Validation loss: 2.4797049255459775

Epoch: 5| Step: 8
Training loss: 2.3125017526980796
Validation loss: 2.485613775617327

Epoch: 5| Step: 9
Training loss: 3.0707873882305528
Validation loss: 2.498700441970314

Epoch: 5| Step: 10
Training loss: 2.347187826994344
Validation loss: 2.5057028749063464

Epoch: 122| Step: 0
Training loss: 2.6496744783668413
Validation loss: 2.4845656599574917

Epoch: 5| Step: 1
Training loss: 3.081068151961467
Validation loss: 2.4808948536171007

Epoch: 5| Step: 2
Training loss: 2.4740314245302115
Validation loss: 2.4771826783296502

Epoch: 5| Step: 3
Training loss: 3.2500334517884797
Validation loss: 2.469675875165323

Epoch: 5| Step: 4
Training loss: 2.29378161083756
Validation loss: 2.4713237509067163

Epoch: 5| Step: 5
Training loss: 2.77507052632657
Validation loss: 2.4611604375039726

Epoch: 5| Step: 6
Training loss: 2.5346316131236124
Validation loss: 2.467155981406417

Epoch: 5| Step: 7
Training loss: 2.5494942331826795
Validation loss: 2.464940811699972

Epoch: 5| Step: 8
Training loss: 3.084354042669983
Validation loss: 2.476005438496368

Epoch: 5| Step: 9
Training loss: 2.934854817999414
Validation loss: 2.469389935720658

Epoch: 5| Step: 10
Training loss: 2.8824909309979025
Validation loss: 2.4834486465566186

Epoch: 123| Step: 0
Training loss: 2.923582506278984
Validation loss: 2.4795164518329784

Epoch: 5| Step: 1
Training loss: 3.244871347754262
Validation loss: 2.4727794390573297

Epoch: 5| Step: 2
Training loss: 2.8293836964515093
Validation loss: 2.4769349177100213

Epoch: 5| Step: 3
Training loss: 2.3422765550739775
Validation loss: 2.4755517634793685

Epoch: 5| Step: 4
Training loss: 2.636542782033263
Validation loss: 2.4900958919926666

Epoch: 5| Step: 5
Training loss: 2.557119256220454
Validation loss: 2.4760548495831114

Epoch: 5| Step: 6
Training loss: 3.1229106785108396
Validation loss: 2.4722969335700133

Epoch: 5| Step: 7
Training loss: 2.8199720520636666
Validation loss: 2.466150107197403

Epoch: 5| Step: 8
Training loss: 2.3277032457354867
Validation loss: 2.463391070452392

Epoch: 5| Step: 9
Training loss: 2.5087359383060215
Validation loss: 2.4727618920933674

Epoch: 5| Step: 10
Training loss: 3.023288456991368
Validation loss: 2.477073723549384

Epoch: 124| Step: 0
Training loss: 2.748556278301435
Validation loss: 2.4838703138470173

Epoch: 5| Step: 1
Training loss: 2.294004761894625
Validation loss: 2.4934475563011986

Epoch: 5| Step: 2
Training loss: 3.08638032077984
Validation loss: 2.5184163386692275

Epoch: 5| Step: 3
Training loss: 2.2060706824896017
Validation loss: 2.5113377236886008

Epoch: 5| Step: 4
Training loss: 2.9300671954473034
Validation loss: 2.5451359360581454

Epoch: 5| Step: 5
Training loss: 2.4811750232505156
Validation loss: 2.5871294917233816

Epoch: 5| Step: 6
Training loss: 3.1505253308344456
Validation loss: 2.639453575439475

Epoch: 5| Step: 7
Training loss: 2.8659493998009173
Validation loss: 2.577516300838189

Epoch: 5| Step: 8
Training loss: 3.0631823655356873
Validation loss: 2.4729734270905768

Epoch: 5| Step: 9
Training loss: 2.902528738952353
Validation loss: 2.458768797345594

Epoch: 5| Step: 10
Training loss: 2.7885226200000957
Validation loss: 2.4650926821954497

Epoch: 125| Step: 0
Training loss: 2.60107435624237
Validation loss: 2.4835083597194316

Epoch: 5| Step: 1
Training loss: 2.726604209952503
Validation loss: 2.4953157234724577

Epoch: 5| Step: 2
Training loss: 3.4473389355696282
Validation loss: 2.5166017173411044

Epoch: 5| Step: 3
Training loss: 2.740483811677093
Validation loss: 2.488998509842023

Epoch: 5| Step: 4
Training loss: 2.902310069570307
Validation loss: 2.4808779892355597

Epoch: 5| Step: 5
Training loss: 3.092560818936831
Validation loss: 2.4685221933390893

Epoch: 5| Step: 6
Training loss: 3.099339993266286
Validation loss: 2.4671862317226525

Epoch: 5| Step: 7
Training loss: 2.522568780511423
Validation loss: 2.4836006570147036

Epoch: 5| Step: 8
Training loss: 3.0323372690136754
Validation loss: 2.5565759917042925

Epoch: 5| Step: 9
Training loss: 2.6718009358452757
Validation loss: 2.6315329708029447

Epoch: 5| Step: 10
Training loss: 2.629993231006803
Validation loss: 2.561813216438217

Epoch: 126| Step: 0
Training loss: 2.6611665888051435
Validation loss: 2.48833405261311

Epoch: 5| Step: 1
Training loss: 2.870554763130696
Validation loss: 2.4571205338267648

Epoch: 5| Step: 2
Training loss: 2.8950437022651148
Validation loss: 2.470879508204402

Epoch: 5| Step: 3
Training loss: 2.956080819384
Validation loss: 2.4540130782224296

Epoch: 5| Step: 4
Training loss: 2.0103729190579642
Validation loss: 2.456625187677933

Epoch: 5| Step: 5
Training loss: 2.9265318291029963
Validation loss: 2.4642907718392624

Epoch: 5| Step: 6
Training loss: 2.8622272211561652
Validation loss: 2.470212113760568

Epoch: 5| Step: 7
Training loss: 2.7731642897451065
Validation loss: 2.456209848294885

Epoch: 5| Step: 8
Training loss: 3.0185603743678233
Validation loss: 2.4726531520509756

Epoch: 5| Step: 9
Training loss: 2.735663758792713
Validation loss: 2.4691175023986043

Epoch: 5| Step: 10
Training loss: 2.904558735620513
Validation loss: 2.468812533866867

Epoch: 127| Step: 0
Training loss: 2.996983282939325
Validation loss: 2.4863466815484623

Epoch: 5| Step: 1
Training loss: 2.49811120207686
Validation loss: 2.494555339314934

Epoch: 5| Step: 2
Training loss: 3.0559850410175198
Validation loss: 2.4864430451057267

Epoch: 5| Step: 3
Training loss: 2.84991691869806
Validation loss: 2.511382525331787

Epoch: 5| Step: 4
Training loss: 2.972494714987302
Validation loss: 2.5457459566908094

Epoch: 5| Step: 5
Training loss: 2.5906681917683105
Validation loss: 2.5474712057244515

Epoch: 5| Step: 6
Training loss: 1.7667051404086542
Validation loss: 2.5159666725785623

Epoch: 5| Step: 7
Training loss: 2.788499620415366
Validation loss: 2.509622744887124

Epoch: 5| Step: 8
Training loss: 2.914880877984024
Validation loss: 2.472744744157178

Epoch: 5| Step: 9
Training loss: 3.136630122356651
Validation loss: 2.4581564053465925

Epoch: 5| Step: 10
Training loss: 2.55664043849073
Validation loss: 2.461623325938502

Epoch: 128| Step: 0
Training loss: 2.4802472834203573
Validation loss: 2.450438315255509

Epoch: 5| Step: 1
Training loss: 2.4248795115632786
Validation loss: 2.445918352304434

Epoch: 5| Step: 2
Training loss: 2.965289860109425
Validation loss: 2.460811501210746

Epoch: 5| Step: 3
Training loss: 2.474626620864087
Validation loss: 2.45792708491132

Epoch: 5| Step: 4
Training loss: 2.7532823221070246
Validation loss: 2.4536996354810423

Epoch: 5| Step: 5
Training loss: 2.8247388938484934
Validation loss: 2.454485150736147

Epoch: 5| Step: 6
Training loss: 2.5753264062906642
Validation loss: 2.476166028558822

Epoch: 5| Step: 7
Training loss: 3.1655822871528456
Validation loss: 2.484274046617695

Epoch: 5| Step: 8
Training loss: 2.7186182801357712
Validation loss: 2.4929103923503644

Epoch: 5| Step: 9
Training loss: 3.1428818825577842
Validation loss: 2.4706517323918185

Epoch: 5| Step: 10
Training loss: 3.0136471918545236
Validation loss: 2.4570397108309807

Epoch: 129| Step: 0
Training loss: 3.273036449692118
Validation loss: 2.4683735348721876

Epoch: 5| Step: 1
Training loss: 2.698824421720936
Validation loss: 2.453567690669865

Epoch: 5| Step: 2
Training loss: 2.4299567462854887
Validation loss: 2.4453793779663493

Epoch: 5| Step: 3
Training loss: 2.639100035089375
Validation loss: 2.445706185849226

Epoch: 5| Step: 4
Training loss: 2.8146621022942617
Validation loss: 2.4441331335469445

Epoch: 5| Step: 5
Training loss: 2.7340003928663505
Validation loss: 2.4386811635272823

Epoch: 5| Step: 6
Training loss: 2.980031312611582
Validation loss: 2.4350227544420076

Epoch: 5| Step: 7
Training loss: 2.618018721488067
Validation loss: 2.442426116366988

Epoch: 5| Step: 8
Training loss: 2.5814606328929415
Validation loss: 2.460344133202878

Epoch: 5| Step: 9
Training loss: 2.9834049905308557
Validation loss: 2.4851262411816277

Epoch: 5| Step: 10
Training loss: 2.5484792887186813
Validation loss: 2.527066001497543

Epoch: 130| Step: 0
Training loss: 2.4616653577025835
Validation loss: 2.5801599351463165

Epoch: 5| Step: 1
Training loss: 3.001239997182984
Validation loss: 2.6146231825048276

Epoch: 5| Step: 2
Training loss: 3.06793291514436
Validation loss: 2.6396568083054786

Epoch: 5| Step: 3
Training loss: 3.434559761055018
Validation loss: 2.5730272753978687

Epoch: 5| Step: 4
Training loss: 2.687452981227049
Validation loss: 2.455833873283211

Epoch: 5| Step: 5
Training loss: 2.6409738524650894
Validation loss: 2.4550659368388703

Epoch: 5| Step: 6
Training loss: 2.746411843685633
Validation loss: 2.463471124672736

Epoch: 5| Step: 7
Training loss: 3.0106197583463947
Validation loss: 2.4682956940585545

Epoch: 5| Step: 8
Training loss: 2.9500829781968965
Validation loss: 2.479910779096342

Epoch: 5| Step: 9
Training loss: 2.9447150395969914
Validation loss: 2.4733887427449477

Epoch: 5| Step: 10
Training loss: 2.2917747703254765
Validation loss: 2.462391294906844

Epoch: 131| Step: 0
Training loss: 2.8310034840359233
Validation loss: 2.450421508046858

Epoch: 5| Step: 1
Training loss: 2.71883295743811
Validation loss: 2.446014375382312

Epoch: 5| Step: 2
Training loss: 2.818369357170039
Validation loss: 2.4468083347858247

Epoch: 5| Step: 3
Training loss: 2.738458690254425
Validation loss: 2.441425326496371

Epoch: 5| Step: 4
Training loss: 3.1186870132843745
Validation loss: 2.46726848926021

Epoch: 5| Step: 5
Training loss: 2.4869695586706313
Validation loss: 2.474367265479737

Epoch: 5| Step: 6
Training loss: 2.6933749546322425
Validation loss: 2.4949458747648534

Epoch: 5| Step: 7
Training loss: 2.7978981746498977
Validation loss: 2.495523949557144

Epoch: 5| Step: 8
Training loss: 2.615912009914654
Validation loss: 2.463196312152958

Epoch: 5| Step: 9
Training loss: 2.504880813687068
Validation loss: 2.4632814109403616

Epoch: 5| Step: 10
Training loss: 3.1260420015702053
Validation loss: 2.4559650825662356

Epoch: 132| Step: 0
Training loss: 2.952905071485715
Validation loss: 2.4498686691855887

Epoch: 5| Step: 1
Training loss: 3.028365975349059
Validation loss: 2.44969773090621

Epoch: 5| Step: 2
Training loss: 2.2048993912491803
Validation loss: 2.452248959719649

Epoch: 5| Step: 3
Training loss: 3.269890149105813
Validation loss: 2.474859021686712

Epoch: 5| Step: 4
Training loss: 2.7109353892733137
Validation loss: 2.4627642878912126

Epoch: 5| Step: 5
Training loss: 2.586570823538978
Validation loss: 2.4501550013481688

Epoch: 5| Step: 6
Training loss: 2.4431615760077583
Validation loss: 2.467232167602443

Epoch: 5| Step: 7
Training loss: 2.3994037284830374
Validation loss: 2.4863658725878834

Epoch: 5| Step: 8
Training loss: 3.2423935422575614
Validation loss: 2.488093638200726

Epoch: 5| Step: 9
Training loss: 2.521557181184071
Validation loss: 2.4756184282715363

Epoch: 5| Step: 10
Training loss: 2.7328726864921737
Validation loss: 2.4562813903043565

Epoch: 133| Step: 0
Training loss: 2.8728008981846185
Validation loss: 2.439864403083573

Epoch: 5| Step: 1
Training loss: 2.9460322059792543
Validation loss: 2.444371711051917

Epoch: 5| Step: 2
Training loss: 3.023373625324549
Validation loss: 2.452647216786428

Epoch: 5| Step: 3
Training loss: 2.7579100162026142
Validation loss: 2.437963216103211

Epoch: 5| Step: 4
Training loss: 2.481375460972041
Validation loss: 2.4454266260967006

Epoch: 5| Step: 5
Training loss: 2.6055539416064386
Validation loss: 2.451185849011877

Epoch: 5| Step: 6
Training loss: 2.5072902242553097
Validation loss: 2.458743006166114

Epoch: 5| Step: 7
Training loss: 2.5215843174967123
Validation loss: 2.467852268675371

Epoch: 5| Step: 8
Training loss: 2.95440839702984
Validation loss: 2.4972734595928325

Epoch: 5| Step: 9
Training loss: 2.9745890165197117
Validation loss: 2.4999308561177007

Epoch: 5| Step: 10
Training loss: 2.398110134385885
Validation loss: 2.473952376267278

Epoch: 134| Step: 0
Training loss: 3.248355009014163
Validation loss: 2.4659111218873027

Epoch: 5| Step: 1
Training loss: 2.4123908616120757
Validation loss: 2.4695932908851224

Epoch: 5| Step: 2
Training loss: 2.9892964153420545
Validation loss: 2.497637675491856

Epoch: 5| Step: 3
Training loss: 2.3416851866545207
Validation loss: 2.486998804151569

Epoch: 5| Step: 4
Training loss: 2.4859802050611854
Validation loss: 2.4762760942752107

Epoch: 5| Step: 5
Training loss: 2.7905625014872952
Validation loss: 2.460897630458741

Epoch: 5| Step: 6
Training loss: 2.5814572156441353
Validation loss: 2.4541773516956176

Epoch: 5| Step: 7
Training loss: 2.489680066217907
Validation loss: 2.4406560832954898

Epoch: 5| Step: 8
Training loss: 2.848695416264434
Validation loss: 2.4298918208546287

Epoch: 5| Step: 9
Training loss: 2.9464452371497525
Validation loss: 2.435778926060869

Epoch: 5| Step: 10
Training loss: 2.87539570614532
Validation loss: 2.438357945545932

Epoch: 135| Step: 0
Training loss: 2.9823540840363605
Validation loss: 2.4492640687939535

Epoch: 5| Step: 1
Training loss: 2.8633270468178402
Validation loss: 2.4402601949267217

Epoch: 5| Step: 2
Training loss: 2.710343089608973
Validation loss: 2.450905946743454

Epoch: 5| Step: 3
Training loss: 2.656184655676037
Validation loss: 2.442249247521097

Epoch: 5| Step: 4
Training loss: 3.165178267052148
Validation loss: 2.478919682790293

Epoch: 5| Step: 5
Training loss: 2.5137843630740573
Validation loss: 2.4713618350360886

Epoch: 5| Step: 6
Training loss: 2.587807892250664
Validation loss: 2.539403209812819

Epoch: 5| Step: 7
Training loss: 2.9761648638395237
Validation loss: 2.5681246582841126

Epoch: 5| Step: 8
Training loss: 2.5223589502526553
Validation loss: 2.5087774622757277

Epoch: 5| Step: 9
Training loss: 2.7389005866670333
Validation loss: 2.4507231770306226

Epoch: 5| Step: 10
Training loss: 2.1432264350388563
Validation loss: 2.429277540364373

Epoch: 136| Step: 0
Training loss: 2.219029798461472
Validation loss: 2.4357461512036633

Epoch: 5| Step: 1
Training loss: 2.7190074579516117
Validation loss: 2.433616919736337

Epoch: 5| Step: 2
Training loss: 2.497121584369252
Validation loss: 2.4299625963362086

Epoch: 5| Step: 3
Training loss: 2.5745652100229273
Validation loss: 2.42493048085027

Epoch: 5| Step: 4
Training loss: 2.7970361929533842
Validation loss: 2.421311578700835

Epoch: 5| Step: 5
Training loss: 2.656877331424212
Validation loss: 2.4394168064024693

Epoch: 5| Step: 6
Training loss: 3.455121736051785
Validation loss: 2.451347869985674

Epoch: 5| Step: 7
Training loss: 2.8458207524376657
Validation loss: 2.4444640482150315

Epoch: 5| Step: 8
Training loss: 2.822872447738504
Validation loss: 2.4350165828033963

Epoch: 5| Step: 9
Training loss: 2.73979286775313
Validation loss: 2.438946123786392

Epoch: 5| Step: 10
Training loss: 2.802345084027073
Validation loss: 2.459139659523114

Epoch: 137| Step: 0
Training loss: 2.8392167061562246
Validation loss: 2.4784856158794355

Epoch: 5| Step: 1
Training loss: 3.0202441638491972
Validation loss: 2.50265571783838

Epoch: 5| Step: 2
Training loss: 3.071434689512528
Validation loss: 2.4831021516017158

Epoch: 5| Step: 3
Training loss: 2.7221534735460486
Validation loss: 2.449569625464353

Epoch: 5| Step: 4
Training loss: 3.0602865199666436
Validation loss: 2.4194767208230568

Epoch: 5| Step: 5
Training loss: 2.5658088348728976
Validation loss: 2.4205671904327373

Epoch: 5| Step: 6
Training loss: 2.657524700606238
Validation loss: 2.4169007259766793

Epoch: 5| Step: 7
Training loss: 2.4587500159802262
Validation loss: 2.413111871385859

Epoch: 5| Step: 8
Training loss: 2.4020351801002433
Validation loss: 2.4362938628441

Epoch: 5| Step: 9
Training loss: 2.1712911356190068
Validation loss: 2.4414825088896475

Epoch: 5| Step: 10
Training loss: 2.8930980104418276
Validation loss: 2.4395520312966577

Epoch: 138| Step: 0
Training loss: 2.7091601259060107
Validation loss: 2.445172686935439

Epoch: 5| Step: 1
Training loss: 2.409616567571709
Validation loss: 2.4802234582957974

Epoch: 5| Step: 2
Training loss: 2.8450646348526525
Validation loss: 2.4779311024459103

Epoch: 5| Step: 3
Training loss: 2.633478188051566
Validation loss: 2.4688142898182455

Epoch: 5| Step: 4
Training loss: 2.9771007141360495
Validation loss: 2.4699627260213237

Epoch: 5| Step: 5
Training loss: 2.728197017737233
Validation loss: 2.448699459116408

Epoch: 5| Step: 6
Training loss: 2.659400686998401
Validation loss: 2.448427428137734

Epoch: 5| Step: 7
Training loss: 2.4870723260870378
Validation loss: 2.4431146702274575

Epoch: 5| Step: 8
Training loss: 3.113610837714063
Validation loss: 2.43242211420351

Epoch: 5| Step: 9
Training loss: 2.1988546771386046
Validation loss: 2.4236874586624206

Epoch: 5| Step: 10
Training loss: 3.064220490144147
Validation loss: 2.43166656869068

Epoch: 139| Step: 0
Training loss: 2.533287170474765
Validation loss: 2.4206608200711393

Epoch: 5| Step: 1
Training loss: 3.0873762036420085
Validation loss: 2.4275124695227834

Epoch: 5| Step: 2
Training loss: 3.2030136461208416
Validation loss: 2.4308197545514374

Epoch: 5| Step: 3
Training loss: 2.7490341050803235
Validation loss: 2.4358553969077943

Epoch: 5| Step: 4
Training loss: 2.454752971084433
Validation loss: 2.435415917278209

Epoch: 5| Step: 5
Training loss: 1.6008675905236247
Validation loss: 2.47413799434467

Epoch: 5| Step: 6
Training loss: 2.7250130084365987
Validation loss: 2.470439488034744

Epoch: 5| Step: 7
Training loss: 2.7169347381167075
Validation loss: 2.5242801337416694

Epoch: 5| Step: 8
Training loss: 2.6493384705167182
Validation loss: 2.505077008044592

Epoch: 5| Step: 9
Training loss: 2.725498549325739
Validation loss: 2.481109933662459

Epoch: 5| Step: 10
Training loss: 3.104191432231107
Validation loss: 2.413447875448636

Epoch: 140| Step: 0
Training loss: 2.8885668876712516
Validation loss: 2.4148787128062756

Epoch: 5| Step: 1
Training loss: 2.104861594789889
Validation loss: 2.4242213690753265

Epoch: 5| Step: 2
Training loss: 2.442144810162516
Validation loss: 2.427546428504541

Epoch: 5| Step: 3
Training loss: 2.8989663682653335
Validation loss: 2.4096474327737276

Epoch: 5| Step: 4
Training loss: 2.6055734318831902
Validation loss: 2.3969255583801035

Epoch: 5| Step: 5
Training loss: 2.5883584114361455
Validation loss: 2.428779674340284

Epoch: 5| Step: 6
Training loss: 2.6141994442727654
Validation loss: 2.462679955104744

Epoch: 5| Step: 7
Training loss: 2.7777552561376764
Validation loss: 2.474195108703193

Epoch: 5| Step: 8
Training loss: 3.0977958657356757
Validation loss: 2.4927946535309253

Epoch: 5| Step: 9
Training loss: 3.056555291590407
Validation loss: 2.4295060590853805

Epoch: 5| Step: 10
Training loss: 2.7238370286081266
Validation loss: 2.408624397811328

Epoch: 141| Step: 0
Training loss: 2.850346219633212
Validation loss: 2.3980803404630264

Epoch: 5| Step: 1
Training loss: 1.9267177819309984
Validation loss: 2.3989485591363926

Epoch: 5| Step: 2
Training loss: 2.957377283770126
Validation loss: 2.4056638705091387

Epoch: 5| Step: 3
Training loss: 2.5848815237081304
Validation loss: 2.4048793049250325

Epoch: 5| Step: 4
Training loss: 2.856258674458159
Validation loss: 2.394463451828003

Epoch: 5| Step: 5
Training loss: 2.4216754461953243
Validation loss: 2.3973017903626443

Epoch: 5| Step: 6
Training loss: 2.7111541925283524
Validation loss: 2.438936768743576

Epoch: 5| Step: 7
Training loss: 2.618407645414422
Validation loss: 2.4579879666920688

Epoch: 5| Step: 8
Training loss: 3.218427475260734
Validation loss: 2.4971938627654455

Epoch: 5| Step: 9
Training loss: 2.797630080266067
Validation loss: 2.4419499121658137

Epoch: 5| Step: 10
Training loss: 2.7197035071116593
Validation loss: 2.41571337221942

Epoch: 142| Step: 0
Training loss: 2.4076277516537825
Validation loss: 2.408080586363709

Epoch: 5| Step: 1
Training loss: 2.9605100620113602
Validation loss: 2.40952360039876

Epoch: 5| Step: 2
Training loss: 3.159587643916504
Validation loss: 2.421179805484803

Epoch: 5| Step: 3
Training loss: 3.1546200613264417
Validation loss: 2.4187078381284794

Epoch: 5| Step: 4
Training loss: 2.488127459649655
Validation loss: 2.4228655665299126

Epoch: 5| Step: 5
Training loss: 2.332958759033279
Validation loss: 2.411277137132049

Epoch: 5| Step: 6
Training loss: 2.6698248956532162
Validation loss: 2.407184343251289

Epoch: 5| Step: 7
Training loss: 2.4489191045395136
Validation loss: 2.4285072931914145

Epoch: 5| Step: 8
Training loss: 2.8196330004835333
Validation loss: 2.4588164398325256

Epoch: 5| Step: 9
Training loss: 2.6064046983066502
Validation loss: 2.4979082524307072

Epoch: 5| Step: 10
Training loss: 2.4647415067381493
Validation loss: 2.5139583018387137

Epoch: 143| Step: 0
Training loss: 2.4470584961353703
Validation loss: 2.5645669813874283

Epoch: 5| Step: 1
Training loss: 2.519765727643066
Validation loss: 2.4673606127010315

Epoch: 5| Step: 2
Training loss: 3.057077082956479
Validation loss: 2.4243745023989804

Epoch: 5| Step: 3
Training loss: 3.3370478120144473
Validation loss: 2.403078331510113

Epoch: 5| Step: 4
Training loss: 2.6092600540153104
Validation loss: 2.413311634025088

Epoch: 5| Step: 5
Training loss: 3.1727477127414425
Validation loss: 2.39884492011722

Epoch: 5| Step: 6
Training loss: 2.365779243792389
Validation loss: 2.4019552161253594

Epoch: 5| Step: 7
Training loss: 2.740789943068225
Validation loss: 2.3990254078605786

Epoch: 5| Step: 8
Training loss: 3.0691757621564766
Validation loss: 2.402254092436535

Epoch: 5| Step: 9
Training loss: 2.1088432489478235
Validation loss: 2.4225154147748817

Epoch: 5| Step: 10
Training loss: 1.9176254431364288
Validation loss: 2.4372595680826903

Epoch: 144| Step: 0
Training loss: 2.8180735992393777
Validation loss: 2.5280202103044873

Epoch: 5| Step: 1
Training loss: 2.5583065425037477
Validation loss: 2.592509399389745

Epoch: 5| Step: 2
Training loss: 2.7311376098973037
Validation loss: 2.6003596072147395

Epoch: 5| Step: 3
Training loss: 2.9780324275068306
Validation loss: 2.657578799846438

Epoch: 5| Step: 4
Training loss: 2.4195824385818114
Validation loss: 2.5298224256595128

Epoch: 5| Step: 5
Training loss: 2.5765788672894905
Validation loss: 2.442077234743761

Epoch: 5| Step: 6
Training loss: 2.4299640068873587
Validation loss: 2.4017144361436618

Epoch: 5| Step: 7
Training loss: 2.9640465671109073
Validation loss: 2.396731769873795

Epoch: 5| Step: 8
Training loss: 2.8546226489922706
Validation loss: 2.4155048198414253

Epoch: 5| Step: 9
Training loss: 2.8002359665487604
Validation loss: 2.426986697341355

Epoch: 5| Step: 10
Training loss: 2.8138939687874034
Validation loss: 2.4238184577625033

Epoch: 145| Step: 0
Training loss: 2.4375613278229933
Validation loss: 2.41667435792994

Epoch: 5| Step: 1
Training loss: 2.9280491838441263
Validation loss: 2.4049305616424896

Epoch: 5| Step: 2
Training loss: 2.5846248187689422
Validation loss: 2.401657510969865

Epoch: 5| Step: 3
Training loss: 2.7876659497869034
Validation loss: 2.4134622643952053

Epoch: 5| Step: 4
Training loss: 3.0171896872766863
Validation loss: 2.442846019934853

Epoch: 5| Step: 5
Training loss: 1.6910904728324525
Validation loss: 2.466955055527365

Epoch: 5| Step: 6
Training loss: 2.329216822685273
Validation loss: 2.5290505001048977

Epoch: 5| Step: 7
Training loss: 2.9188383101310147
Validation loss: 2.61446185765995

Epoch: 5| Step: 8
Training loss: 2.692152387729893
Validation loss: 2.636073585616981

Epoch: 5| Step: 9
Training loss: 3.182832329622277
Validation loss: 2.67306681569109

Epoch: 5| Step: 10
Training loss: 2.862760280453088
Validation loss: 2.582393424311962

Epoch: 146| Step: 0
Training loss: 2.94694995643213
Validation loss: 2.514266469482864

Epoch: 5| Step: 1
Training loss: 2.7163610376167098
Validation loss: 2.4502447402844263

Epoch: 5| Step: 2
Training loss: 2.622879352460707
Validation loss: 2.411624155823964

Epoch: 5| Step: 3
Training loss: 2.791058165624451
Validation loss: 2.4097261669846968

Epoch: 5| Step: 4
Training loss: 3.0734663821842907
Validation loss: 2.4183489761151358

Epoch: 5| Step: 5
Training loss: 2.470563102041357
Validation loss: 2.4173119637829883

Epoch: 5| Step: 6
Training loss: 2.4054469960918032
Validation loss: 2.4213743816464817

Epoch: 5| Step: 7
Training loss: 3.2105206221265887
Validation loss: 2.422451041550955

Epoch: 5| Step: 8
Training loss: 3.0859084502192813
Validation loss: 2.4214327204253427

Epoch: 5| Step: 9
Training loss: 2.1990775948955466
Validation loss: 2.4189499195223965

Epoch: 5| Step: 10
Training loss: 2.121720307544339
Validation loss: 2.420228509732514

Epoch: 147| Step: 0
Training loss: 2.568187264016992
Validation loss: 2.4543246540339174

Epoch: 5| Step: 1
Training loss: 2.3008863234045225
Validation loss: 2.4912944382597177

Epoch: 5| Step: 2
Training loss: 3.473410697143762
Validation loss: 2.5274744116214087

Epoch: 5| Step: 3
Training loss: 2.2789994726511007
Validation loss: 2.526266810121698

Epoch: 5| Step: 4
Training loss: 2.550000291712127
Validation loss: 2.51481694011471

Epoch: 5| Step: 5
Training loss: 2.988826766741317
Validation loss: 2.4957724410049935

Epoch: 5| Step: 6
Training loss: 2.194546060047036
Validation loss: 2.4566354229124734

Epoch: 5| Step: 7
Training loss: 2.4884621451121673
Validation loss: 2.405392952685359

Epoch: 5| Step: 8
Training loss: 2.5490111771252826
Validation loss: 2.4016864311207327

Epoch: 5| Step: 9
Training loss: 2.9501600771646266
Validation loss: 2.397789134819996

Epoch: 5| Step: 10
Training loss: 3.1012526965177623
Validation loss: 2.3895781759426056

Epoch: 148| Step: 0
Training loss: 3.003340609587881
Validation loss: 2.3947679156153603

Epoch: 5| Step: 1
Training loss: 2.104018807330762
Validation loss: 2.3984591297476907

Epoch: 5| Step: 2
Training loss: 2.2292847171316232
Validation loss: 2.3995423504007607

Epoch: 5| Step: 3
Training loss: 3.134976445889854
Validation loss: 2.408328238790308

Epoch: 5| Step: 4
Training loss: 2.776668160595746
Validation loss: 2.428627721309532

Epoch: 5| Step: 5
Training loss: 3.169729625350899
Validation loss: 2.4655183310691418

Epoch: 5| Step: 6
Training loss: 2.467929172470229
Validation loss: 2.4911275996278754

Epoch: 5| Step: 7
Training loss: 2.1286609753346344
Validation loss: 2.5057813645550158

Epoch: 5| Step: 8
Training loss: 3.1365662724167342
Validation loss: 2.5468950369589205

Epoch: 5| Step: 9
Training loss: 2.8022502201872173
Validation loss: 2.482303916231657

Epoch: 5| Step: 10
Training loss: 2.2339535829303294
Validation loss: 2.447887905547963

Epoch: 149| Step: 0
Training loss: 2.657239572534533
Validation loss: 2.411234289216464

Epoch: 5| Step: 1
Training loss: 2.7867163612947956
Validation loss: 2.4207011278042265

Epoch: 5| Step: 2
Training loss: 2.7813290359754026
Validation loss: 2.4097975283462834

Epoch: 5| Step: 3
Training loss: 2.9778932815501076
Validation loss: 2.4198002942495673

Epoch: 5| Step: 4
Training loss: 2.623765473485993
Validation loss: 2.4191735715879417

Epoch: 5| Step: 5
Training loss: 2.867312893737065
Validation loss: 2.4134439404084085

Epoch: 5| Step: 6
Training loss: 2.542395086083726
Validation loss: 2.4084236960780148

Epoch: 5| Step: 7
Training loss: 2.241189236006044
Validation loss: 2.4137993720365376

Epoch: 5| Step: 8
Training loss: 2.7172968697102653
Validation loss: 2.4765740678959016

Epoch: 5| Step: 9
Training loss: 2.6559263144348564
Validation loss: 2.5162557612281353

Epoch: 5| Step: 10
Training loss: 2.8478262056514643
Validation loss: 2.5955286432401383

Epoch: 150| Step: 0
Training loss: 2.484403981933449
Validation loss: 2.5435927214512573

Epoch: 5| Step: 1
Training loss: 3.059801742513918
Validation loss: 2.494191226296084

Epoch: 5| Step: 2
Training loss: 2.56205829442072
Validation loss: 2.5191930532605276

Epoch: 5| Step: 3
Training loss: 2.551271540444783
Validation loss: 2.487576310047827

Epoch: 5| Step: 4
Training loss: 2.600893501662174
Validation loss: 2.4774294021385725

Epoch: 5| Step: 5
Training loss: 2.6840390831195315
Validation loss: 2.4095424973470085

Epoch: 5| Step: 6
Training loss: 1.7586788500917414
Validation loss: 2.393232270304528

Epoch: 5| Step: 7
Training loss: 2.589684851189234
Validation loss: 2.391617292017645

Epoch: 5| Step: 8
Training loss: 2.949237181751178
Validation loss: 2.391744620766488

Epoch: 5| Step: 9
Training loss: 2.8876148944141398
Validation loss: 2.3885400747287067

Epoch: 5| Step: 10
Training loss: 2.8817983771590754
Validation loss: 2.3918185395692886

Epoch: 151| Step: 0
Training loss: 2.4189369346279523
Validation loss: 2.3995917809680405

Epoch: 5| Step: 1
Training loss: 3.1220944439167497
Validation loss: 2.401471217270712

Epoch: 5| Step: 2
Training loss: 1.9812429145180872
Validation loss: 2.408675210830041

Epoch: 5| Step: 3
Training loss: 2.8922444523954245
Validation loss: 2.413817149014792

Epoch: 5| Step: 4
Training loss: 2.568023868592472
Validation loss: 2.4161650331863984

Epoch: 5| Step: 5
Training loss: 2.7225268208677464
Validation loss: 2.423135739053045

Epoch: 5| Step: 6
Training loss: 2.8210717022102134
Validation loss: 2.4602465963033966

Epoch: 5| Step: 7
Training loss: 2.401408688069107
Validation loss: 2.5306852159534237

Epoch: 5| Step: 8
Training loss: 2.7514265868430625
Validation loss: 2.619085961814833

Epoch: 5| Step: 9
Training loss: 2.7744225700272147
Validation loss: 2.5911236733247374

Epoch: 5| Step: 10
Training loss: 2.7759039428977568
Validation loss: 2.5552114442572

Epoch: 152| Step: 0
Training loss: 3.0048518682900514
Validation loss: 2.5235901168012664

Epoch: 5| Step: 1
Training loss: 2.6841675257412487
Validation loss: 2.5123073116870236

Epoch: 5| Step: 2
Training loss: 3.1600814074882826
Validation loss: 2.4763691036917743

Epoch: 5| Step: 3
Training loss: 2.50859974896365
Validation loss: 2.4196797456962598

Epoch: 5| Step: 4
Training loss: 2.548958049400531
Validation loss: 2.417761048515983

Epoch: 5| Step: 5
Training loss: 2.3386043775231227
Validation loss: 2.4069900237733437

Epoch: 5| Step: 6
Training loss: 2.4108045006074064
Validation loss: 2.402305836298756

Epoch: 5| Step: 7
Training loss: 2.5321011466242496
Validation loss: 2.412643493978922

Epoch: 5| Step: 8
Training loss: 2.387215969906179
Validation loss: 2.398565461769333

Epoch: 5| Step: 9
Training loss: 2.687854654730887
Validation loss: 2.3993249312085947

Epoch: 5| Step: 10
Training loss: 2.622483909564845
Validation loss: 2.413964908043729

Epoch: 153| Step: 0
Training loss: 2.772053031837959
Validation loss: 2.4144332064290124

Epoch: 5| Step: 1
Training loss: 2.226570423848291
Validation loss: 2.414510432956496

Epoch: 5| Step: 2
Training loss: 2.1315754527285797
Validation loss: 2.438708175004758

Epoch: 5| Step: 3
Training loss: 2.6754923643667285
Validation loss: 2.454696206443667

Epoch: 5| Step: 4
Training loss: 2.835620032161727
Validation loss: 2.4889357312317935

Epoch: 5| Step: 5
Training loss: 2.2022883131851945
Validation loss: 2.499185256070148

Epoch: 5| Step: 6
Training loss: 2.333749211806178
Validation loss: 2.5496126167003523

Epoch: 5| Step: 7
Training loss: 2.7504050216655593
Validation loss: 2.633875809393082

Epoch: 5| Step: 8
Training loss: 3.1148533698728267
Validation loss: 2.5865585383926173

Epoch: 5| Step: 9
Training loss: 2.8134589361865423
Validation loss: 2.483468842207344

Epoch: 5| Step: 10
Training loss: 3.0594803851390813
Validation loss: 2.4241558680773987

Epoch: 154| Step: 0
Training loss: 2.8740489879513262
Validation loss: 2.3927840493179806

Epoch: 5| Step: 1
Training loss: 2.4142448084857286
Validation loss: 2.40580601585451

Epoch: 5| Step: 2
Training loss: 2.2514679676465263
Validation loss: 2.411490894339566

Epoch: 5| Step: 3
Training loss: 2.8887372425413345
Validation loss: 2.4201113278026574

Epoch: 5| Step: 4
Training loss: 2.5202860803041203
Validation loss: 2.415319849985433

Epoch: 5| Step: 5
Training loss: 2.303258109936876
Validation loss: 2.4074919880294425

Epoch: 5| Step: 6
Training loss: 2.9284276262393067
Validation loss: 2.415860292614175

Epoch: 5| Step: 7
Training loss: 2.9570717248200085
Validation loss: 2.488686422203842

Epoch: 5| Step: 8
Training loss: 2.117168130821225
Validation loss: 2.613218994713628

Epoch: 5| Step: 9
Training loss: 3.158454200894474
Validation loss: 2.7418710405472466

Epoch: 5| Step: 10
Training loss: 3.060510573083606
Validation loss: 2.6710669199801806

Epoch: 155| Step: 0
Training loss: 2.328946781413594
Validation loss: 2.5113966206160376

Epoch: 5| Step: 1
Training loss: 3.205367777845088
Validation loss: 2.418151311562488

Epoch: 5| Step: 2
Training loss: 2.140582564552866
Validation loss: 2.4071236366739477

Epoch: 5| Step: 3
Training loss: 3.0721262459444123
Validation loss: 2.403292160848338

Epoch: 5| Step: 4
Training loss: 2.6593401717203804
Validation loss: 2.4117279270579677

Epoch: 5| Step: 5
Training loss: 2.2694949017501282
Validation loss: 2.41445333485204

Epoch: 5| Step: 6
Training loss: 2.590636625367368
Validation loss: 2.412274249047066

Epoch: 5| Step: 7
Training loss: 2.6813175148455435
Validation loss: 2.4026868691042282

Epoch: 5| Step: 8
Training loss: 2.5094526875062857
Validation loss: 2.387691403197525

Epoch: 5| Step: 9
Training loss: 3.200653313465175
Validation loss: 2.38944689076502

Epoch: 5| Step: 10
Training loss: 2.4296343144425054
Validation loss: 2.441751661973359

Epoch: 156| Step: 0
Training loss: 2.5128601233660564
Validation loss: 2.5146690890767114

Epoch: 5| Step: 1
Training loss: 2.9846426159768242
Validation loss: 2.605979249904431

Epoch: 5| Step: 2
Training loss: 2.7274756883469524
Validation loss: 2.65859318361782

Epoch: 5| Step: 3
Training loss: 3.1543373884782144
Validation loss: 2.6449694887840027

Epoch: 5| Step: 4
Training loss: 2.124378113347348
Validation loss: 2.551344164815354

Epoch: 5| Step: 5
Training loss: 2.4123945183498297
Validation loss: 2.464606391764823

Epoch: 5| Step: 6
Training loss: 2.3785003165436702
Validation loss: 2.4213086257565894

Epoch: 5| Step: 7
Training loss: 2.5925832675079894
Validation loss: 2.402396048966921

Epoch: 5| Step: 8
Training loss: 2.3389923635605214
Validation loss: 2.383710149138122

Epoch: 5| Step: 9
Training loss: 2.733071152588213
Validation loss: 2.3881394088276986

Epoch: 5| Step: 10
Training loss: 3.0548832433088213
Validation loss: 2.3819583399440574

Epoch: 157| Step: 0
Training loss: 3.1293675229101527
Validation loss: 2.385331788366328

Epoch: 5| Step: 1
Training loss: 3.069234022826777
Validation loss: 2.3927520408814993

Epoch: 5| Step: 2
Training loss: 2.628729486970412
Validation loss: 2.3868709715924257

Epoch: 5| Step: 3
Training loss: 2.373697927826871
Validation loss: 2.391800189642104

Epoch: 5| Step: 4
Training loss: 1.9680559054978386
Validation loss: 2.400993669317677

Epoch: 5| Step: 5
Training loss: 2.1825293606490646
Validation loss: 2.40923009828566

Epoch: 5| Step: 6
Training loss: 2.4587756152387166
Validation loss: 2.4229114570681936

Epoch: 5| Step: 7
Training loss: 2.875299355222185
Validation loss: 2.479057137591335

Epoch: 5| Step: 8
Training loss: 2.1900481505304503
Validation loss: 2.5073733868723456

Epoch: 5| Step: 9
Training loss: 2.9075091515853795
Validation loss: 2.545870031754875

Epoch: 5| Step: 10
Training loss: 2.7055036189503276
Validation loss: 2.5384787490012317

Epoch: 158| Step: 0
Training loss: 2.620690577692053
Validation loss: 2.515113931006065

Epoch: 5| Step: 1
Training loss: 2.953658767175897
Validation loss: 2.4851013275524987

Epoch: 5| Step: 2
Training loss: 3.11774150925478
Validation loss: 2.4903069644701676

Epoch: 5| Step: 3
Training loss: 2.40597017320773
Validation loss: 2.465809320039309

Epoch: 5| Step: 4
Training loss: 2.631289803029468
Validation loss: 2.447455508627259

Epoch: 5| Step: 5
Training loss: 2.27789844281201
Validation loss: 2.4280607102371086

Epoch: 5| Step: 6
Training loss: 2.6105597998450247
Validation loss: 2.420525947909483

Epoch: 5| Step: 7
Training loss: 2.169868475448369
Validation loss: 2.422856209709531

Epoch: 5| Step: 8
Training loss: 2.6982842468672734
Validation loss: 2.4082718957552185

Epoch: 5| Step: 9
Training loss: 2.318310834317029
Validation loss: 2.4160667526301713

Epoch: 5| Step: 10
Training loss: 2.3931323098613753
Validation loss: 2.429360846154723

Epoch: 159| Step: 0
Training loss: 2.7784624167305343
Validation loss: 2.427964033602927

Epoch: 5| Step: 1
Training loss: 3.039305846368706
Validation loss: 2.4466107680000277

Epoch: 5| Step: 2
Training loss: 2.254660653676851
Validation loss: 2.467213845515139

Epoch: 5| Step: 3
Training loss: 1.9505768289579686
Validation loss: 2.5174482705361396

Epoch: 5| Step: 4
Training loss: 2.415108167228048
Validation loss: 2.525283017212757

Epoch: 5| Step: 5
Training loss: 2.479793330471922
Validation loss: 2.512967867290162

Epoch: 5| Step: 6
Training loss: 2.3020119864568507
Validation loss: 2.5001398590918535

Epoch: 5| Step: 7
Training loss: 2.5549594372778706
Validation loss: 2.523702536616819

Epoch: 5| Step: 8
Training loss: 3.129169124461774
Validation loss: 2.541760894935721

Epoch: 5| Step: 9
Training loss: 2.6731168303811916
Validation loss: 2.476975086972931

Epoch: 5| Step: 10
Training loss: 2.4572866334387924
Validation loss: 2.4704199486043494

Epoch: 160| Step: 0
Training loss: 2.671919794432164
Validation loss: 2.465319956695433

Epoch: 5| Step: 1
Training loss: 2.381220351307437
Validation loss: 2.4493090528587724

Epoch: 5| Step: 2
Training loss: 3.01398261218001
Validation loss: 2.447803370241499

Epoch: 5| Step: 3
Training loss: 2.7940289385859556
Validation loss: 2.4334022205497936

Epoch: 5| Step: 4
Training loss: 2.5599123287089873
Validation loss: 2.446997736350344

Epoch: 5| Step: 5
Training loss: 2.3809958615192977
Validation loss: 2.472728579993092

Epoch: 5| Step: 6
Training loss: 2.308577432590916
Validation loss: 2.4671867938729304

Epoch: 5| Step: 7
Training loss: 2.6134795839232217
Validation loss: 2.468509148816594

Epoch: 5| Step: 8
Training loss: 2.5904348858143575
Validation loss: 2.513101477744735

Epoch: 5| Step: 9
Training loss: 2.048067982834259
Validation loss: 2.5516028334666516

Epoch: 5| Step: 10
Training loss: 2.5042589150531236
Validation loss: 2.6648540803354908

Epoch: 161| Step: 0
Training loss: 2.3566679930334753
Validation loss: 2.647547964601459

Epoch: 5| Step: 1
Training loss: 2.7659925658373665
Validation loss: 2.5949857801998193

Epoch: 5| Step: 2
Training loss: 2.569066821234943
Validation loss: 2.506892649486944

Epoch: 5| Step: 3
Training loss: 2.6273379132684944
Validation loss: 2.469647238385511

Epoch: 5| Step: 4
Training loss: 2.7612463130209655
Validation loss: 2.4306655005938222

Epoch: 5| Step: 5
Training loss: 2.485194520916464
Validation loss: 2.4218853979717796

Epoch: 5| Step: 6
Training loss: 2.7092661693851174
Validation loss: 2.4274991998761672

Epoch: 5| Step: 7
Training loss: 2.6080789602472776
Validation loss: 2.418908588484154

Epoch: 5| Step: 8
Training loss: 2.424497894531645
Validation loss: 2.4474568965270054

Epoch: 5| Step: 9
Training loss: 2.4692402606373074
Validation loss: 2.473010955051636

Epoch: 5| Step: 10
Training loss: 2.040173224406079
Validation loss: 2.561536474233317

Epoch: 162| Step: 0
Training loss: 2.8697571426410384
Validation loss: 2.599892644977057

Epoch: 5| Step: 1
Training loss: 2.5951234788862174
Validation loss: 2.585766451957439

Epoch: 5| Step: 2
Training loss: 2.4593289401286675
Validation loss: 2.5535782149929727

Epoch: 5| Step: 3
Training loss: 2.837316256720321
Validation loss: 2.5282022958196064

Epoch: 5| Step: 4
Training loss: 2.4367507369867196
Validation loss: 2.583569021386423

Epoch: 5| Step: 5
Training loss: 2.375583576984357
Validation loss: 2.5572649126027813

Epoch: 5| Step: 6
Training loss: 2.7881320288166997
Validation loss: 2.473506610520953

Epoch: 5| Step: 7
Training loss: 2.3035813602812163
Validation loss: 2.4364552589863617

Epoch: 5| Step: 8
Training loss: 1.8616922508719822
Validation loss: 2.408166634249457

Epoch: 5| Step: 9
Training loss: 2.4462897447291962
Validation loss: 2.4006400307723763

Epoch: 5| Step: 10
Training loss: 2.8709945972993696
Validation loss: 2.409456660323534

Epoch: 163| Step: 0
Training loss: 2.3301421777789764
Validation loss: 2.397460804904952

Epoch: 5| Step: 1
Training loss: 2.9010097061305182
Validation loss: 2.407875129118523

Epoch: 5| Step: 2
Training loss: 2.565948399037564
Validation loss: 2.4179129645362525

Epoch: 5| Step: 3
Training loss: 2.6963310639102307
Validation loss: 2.54671091265426

Epoch: 5| Step: 4
Training loss: 2.3063026070732926
Validation loss: 2.6981692993860413

Epoch: 5| Step: 5
Training loss: 2.732212890311555
Validation loss: 2.6304764448419227

Epoch: 5| Step: 6
Training loss: 2.5866283404404706
Validation loss: 2.5423577141000853

Epoch: 5| Step: 7
Training loss: 2.2118728869649855
Validation loss: 2.465297132230546

Epoch: 5| Step: 8
Training loss: 2.451325357806805
Validation loss: 2.4366995825368716

Epoch: 5| Step: 9
Training loss: 2.15509466649273
Validation loss: 2.4323795586689165

Epoch: 5| Step: 10
Training loss: 3.007454035812826
Validation loss: 2.407092566574433

Epoch: 164| Step: 0
Training loss: 2.6817138839683756
Validation loss: 2.3948689489128823

Epoch: 5| Step: 1
Training loss: 2.4691418686839337
Validation loss: 2.3899815767432564

Epoch: 5| Step: 2
Training loss: 2.429246574208646
Validation loss: 2.403951830444508

Epoch: 5| Step: 3
Training loss: 1.7912795143863725
Validation loss: 2.427981178935017

Epoch: 5| Step: 4
Training loss: 2.469210328269577
Validation loss: 2.489674185555103

Epoch: 5| Step: 5
Training loss: 2.397831545152203
Validation loss: 2.5808934635768095

Epoch: 5| Step: 6
Training loss: 2.081736015872982
Validation loss: 2.5975504802222744

Epoch: 5| Step: 7
Training loss: 2.7276128369005934
Validation loss: 2.575411666234905

Epoch: 5| Step: 8
Training loss: 2.4527657604199145
Validation loss: 2.51176512481828

Epoch: 5| Step: 9
Training loss: 2.803704474696487
Validation loss: 2.4416692304179515

Epoch: 5| Step: 10
Training loss: 3.350423837296763
Validation loss: 2.435748849830918

Epoch: 165| Step: 0
Training loss: 2.3894367132017713
Validation loss: 2.44415707971755

Epoch: 5| Step: 1
Training loss: 2.371068310169076
Validation loss: 2.4590573250224397

Epoch: 5| Step: 2
Training loss: 2.7234764669741702
Validation loss: 2.4783542991414667

Epoch: 5| Step: 3
Training loss: 2.439559457750598
Validation loss: 2.5158830990669574

Epoch: 5| Step: 4
Training loss: 2.809807230083062
Validation loss: 2.524844340628617

Epoch: 5| Step: 5
Training loss: 2.726075836733243
Validation loss: 2.556796216119402

Epoch: 5| Step: 6
Training loss: 2.554972128221513
Validation loss: 2.6708600416222747

Epoch: 5| Step: 7
Training loss: 2.7487889137306514
Validation loss: 2.529129337107544

Epoch: 5| Step: 8
Training loss: 2.203166880108092
Validation loss: 2.435787676999448

Epoch: 5| Step: 9
Training loss: 2.164665936780751
Validation loss: 2.4309525923676762

Epoch: 5| Step: 10
Training loss: 2.2077233773700744
Validation loss: 2.438193860619894

Epoch: 166| Step: 0
Training loss: 2.845196701785412
Validation loss: 2.4364520192573598

Epoch: 5| Step: 1
Training loss: 2.3577906866056795
Validation loss: 2.4668309052983313

Epoch: 5| Step: 2
Training loss: 2.7635680917185117
Validation loss: 2.4776142589188304

Epoch: 5| Step: 3
Training loss: 2.5450835685274806
Validation loss: 2.5622867572536023

Epoch: 5| Step: 4
Training loss: 1.9836868534722283
Validation loss: 2.6613191553333277

Epoch: 5| Step: 5
Training loss: 3.016700355243324
Validation loss: 2.773388586403015

Epoch: 5| Step: 6
Training loss: 2.313179328731899
Validation loss: 2.6724919881283977

Epoch: 5| Step: 7
Training loss: 2.4648133773262404
Validation loss: 2.5223869296453683

Epoch: 5| Step: 8
Training loss: 2.919266786098936
Validation loss: 2.4342996703292585

Epoch: 5| Step: 9
Training loss: 2.5269018432489694
Validation loss: 2.3925134174837646

Epoch: 5| Step: 10
Training loss: 2.574031840414238
Validation loss: 2.404372756299176

Epoch: 167| Step: 0
Training loss: 2.2229117462856913
Validation loss: 2.393083092426038

Epoch: 5| Step: 1
Training loss: 2.3528215959960606
Validation loss: 2.4125608850220237

Epoch: 5| Step: 2
Training loss: 2.555050138813919
Validation loss: 2.424069661210519

Epoch: 5| Step: 3
Training loss: 3.017312323952945
Validation loss: 2.4433202384888033

Epoch: 5| Step: 4
Training loss: 2.7104557719672853
Validation loss: 2.506555819388529

Epoch: 5| Step: 5
Training loss: 2.07277685361635
Validation loss: 2.570380404379815

Epoch: 5| Step: 6
Training loss: 2.5350714200584887
Validation loss: 2.6165086414636725

Epoch: 5| Step: 7
Training loss: 2.6520440405616594
Validation loss: 2.6310510384145482

Epoch: 5| Step: 8
Training loss: 2.374045933279884
Validation loss: 2.6922165114925796

Epoch: 5| Step: 9
Training loss: 2.7773489864852623
Validation loss: 2.6760802782513

Epoch: 5| Step: 10
Training loss: 2.1704712866637257
Validation loss: 2.5741105800496595

Epoch: 168| Step: 0
Training loss: 2.932716370492281
Validation loss: 2.4698488067705826

Epoch: 5| Step: 1
Training loss: 2.501549621968238
Validation loss: 2.4111104756085355

Epoch: 5| Step: 2
Training loss: 2.5757357536928285
Validation loss: 2.388427995603756

Epoch: 5| Step: 3
Training loss: 2.207958357542682
Validation loss: 2.3949590124685036

Epoch: 5| Step: 4
Training loss: 2.6467162533910495
Validation loss: 2.3968719849053657

Epoch: 5| Step: 5
Training loss: 2.57259585173251
Validation loss: 2.3990917958754427

Epoch: 5| Step: 6
Training loss: 2.6142822538080472
Validation loss: 2.4070934622696813

Epoch: 5| Step: 7
Training loss: 2.2136647149086826
Validation loss: 2.4380860719234034

Epoch: 5| Step: 8
Training loss: 2.0437846842864533
Validation loss: 2.4852127599570557

Epoch: 5| Step: 9
Training loss: 2.4585132102029537
Validation loss: 2.5578840345874387

Epoch: 5| Step: 10
Training loss: 2.779319779173675
Validation loss: 2.590166122741291

Epoch: 169| Step: 0
Training loss: 2.8358256840796545
Validation loss: 2.565521158034907

Epoch: 5| Step: 1
Training loss: 2.460825502783846
Validation loss: 2.548941077140135

Epoch: 5| Step: 2
Training loss: 1.818199535847081
Validation loss: 2.528533488651626

Epoch: 5| Step: 3
Training loss: 2.452452938083254
Validation loss: 2.4759111687571975

Epoch: 5| Step: 4
Training loss: 2.643966005848371
Validation loss: 2.438410028249265

Epoch: 5| Step: 5
Training loss: 2.246770448334624
Validation loss: 2.4385462309616117

Epoch: 5| Step: 6
Training loss: 2.589966922092199
Validation loss: 2.439625270256035

Epoch: 5| Step: 7
Training loss: 2.3604576203804855
Validation loss: 2.4648724249053346

Epoch: 5| Step: 8
Training loss: 2.550610289752084
Validation loss: 2.4648936100065075

Epoch: 5| Step: 9
Training loss: 2.062037444987367
Validation loss: 2.509332284712076

Epoch: 5| Step: 10
Training loss: 2.5877297635735976
Validation loss: 2.545139006217123

Epoch: 170| Step: 0
Training loss: 2.6456782278018425
Validation loss: 2.585981193609302

Epoch: 5| Step: 1
Training loss: 2.0835981073609293
Validation loss: 2.6172162552271527

Epoch: 5| Step: 2
Training loss: 2.387880033434919
Validation loss: 2.59650318806984

Epoch: 5| Step: 3
Training loss: 2.226206968599509
Validation loss: 2.5488741827039987

Epoch: 5| Step: 4
Training loss: 2.484467030865919
Validation loss: 2.5382992236917166

Epoch: 5| Step: 5
Training loss: 2.3668189438557365
Validation loss: 2.533763795400036

Epoch: 5| Step: 6
Training loss: 2.367280259533914
Validation loss: 2.5197538310129994

Epoch: 5| Step: 7
Training loss: 2.775124222320562
Validation loss: 2.47760216092602

Epoch: 5| Step: 8
Training loss: 2.3894361145202305
Validation loss: 2.446217018654754

Epoch: 5| Step: 9
Training loss: 2.249428358576608
Validation loss: 2.456409663891615

Epoch: 5| Step: 10
Training loss: 2.376274068310175
Validation loss: 2.4593824883887594

Epoch: 171| Step: 0
Training loss: 2.500313739163645
Validation loss: 2.473405964988973

Epoch: 5| Step: 1
Training loss: 2.4707781995140414
Validation loss: 2.508603923588672

Epoch: 5| Step: 2
Training loss: 2.241456660345026
Validation loss: 2.541927159552225

Epoch: 5| Step: 3
Training loss: 2.315146504126961
Validation loss: 2.5363461396208447

Epoch: 5| Step: 4
Training loss: 1.9813651740355334
Validation loss: 2.5390455534742573

Epoch: 5| Step: 5
Training loss: 2.670088053333622
Validation loss: 2.550829118665384

Epoch: 5| Step: 6
Training loss: 2.1482945620064497
Validation loss: 2.539207895815733

Epoch: 5| Step: 7
Training loss: 2.6009644516888297
Validation loss: 2.5416788766272824

Epoch: 5| Step: 8
Training loss: 2.2686972998180925
Validation loss: 2.5599136205874427

Epoch: 5| Step: 9
Training loss: 2.111882958217956
Validation loss: 2.545405753437077

Epoch: 5| Step: 10
Training loss: 2.646445366265784
Validation loss: 2.537086231380924

Epoch: 172| Step: 0
Training loss: 2.4730567547509374
Validation loss: 2.4955647626481072

Epoch: 5| Step: 1
Training loss: 2.3985410785986336
Validation loss: 2.517875774777694

Epoch: 5| Step: 2
Training loss: 2.2268051282963084
Validation loss: 2.487094009617812

Epoch: 5| Step: 3
Training loss: 2.425326441393108
Validation loss: 2.495763427367841

Epoch: 5| Step: 4
Training loss: 2.6912182657839843
Validation loss: 2.4427899042395587

Epoch: 5| Step: 5
Training loss: 1.8990429199374421
Validation loss: 2.4702283141098706

Epoch: 5| Step: 6
Training loss: 2.4840893851152352
Validation loss: 2.47111760322543

Epoch: 5| Step: 7
Training loss: 2.2842767571694824
Validation loss: 2.4908884171509316

Epoch: 5| Step: 8
Training loss: 2.4409903942702096
Validation loss: 2.5317891128020253

Epoch: 5| Step: 9
Training loss: 2.098020497101042
Validation loss: 2.5492768353439064

Epoch: 5| Step: 10
Training loss: 2.3627159262179935
Validation loss: 2.577245563901894

Epoch: 173| Step: 0
Training loss: 2.73940472812349
Validation loss: 2.5880546185073654

Epoch: 5| Step: 1
Training loss: 2.2986721352130837
Validation loss: 2.523674717074544

Epoch: 5| Step: 2
Training loss: 2.23302146622504
Validation loss: 2.4471352545945932

Epoch: 5| Step: 3
Training loss: 2.819467264677087
Validation loss: 2.434818424040445

Epoch: 5| Step: 4
Training loss: 2.514813973617018
Validation loss: 2.447331921641141

Epoch: 5| Step: 5
Training loss: 2.0605246592404303
Validation loss: 2.4526381397792165

Epoch: 5| Step: 6
Training loss: 2.6231510371746736
Validation loss: 2.4814443021045505

Epoch: 5| Step: 7
Training loss: 2.414724709752472
Validation loss: 2.522007578112545

Epoch: 5| Step: 8
Training loss: 2.43258719653582
Validation loss: 2.550370352985255

Epoch: 5| Step: 9
Training loss: 1.6726799569015631
Validation loss: 2.562809308960809

Epoch: 5| Step: 10
Training loss: 1.7419498435463148
Validation loss: 2.586805770318662

Epoch: 174| Step: 0
Training loss: 2.3563107429587493
Validation loss: 2.614541293701257

Epoch: 5| Step: 1
Training loss: 1.671396490052324
Validation loss: 2.591201483988985

Epoch: 5| Step: 2
Training loss: 2.5272409220653302
Validation loss: 2.6160611193109062

Epoch: 5| Step: 3
Training loss: 2.410324313395575
Validation loss: 2.5859362141828717

Epoch: 5| Step: 4
Training loss: 2.0587167431681985
Validation loss: 2.566877150751247

Epoch: 5| Step: 5
Training loss: 2.6175717199896456
Validation loss: 2.531899572814199

Epoch: 5| Step: 6
Training loss: 2.6862846997816985
Validation loss: 2.498214012973274

Epoch: 5| Step: 7
Training loss: 2.2207933070409
Validation loss: 2.5050033073721942

Epoch: 5| Step: 8
Training loss: 2.413158358541191
Validation loss: 2.4693225816023827

Epoch: 5| Step: 9
Training loss: 2.359669850096118
Validation loss: 2.4573370859935393

Epoch: 5| Step: 10
Training loss: 1.8637577623171124
Validation loss: 2.449667346781242

Epoch: 175| Step: 0
Training loss: 2.420713576890912
Validation loss: 2.4584847916849015

Epoch: 5| Step: 1
Training loss: 2.08137716643718
Validation loss: 2.4441315696430155

Epoch: 5| Step: 2
Training loss: 2.656350706098783
Validation loss: 2.450129244009058

Epoch: 5| Step: 3
Training loss: 2.042866749888571
Validation loss: 2.4996889556665605

Epoch: 5| Step: 4
Training loss: 2.3169922368920166
Validation loss: 2.541013636449587

Epoch: 5| Step: 5
Training loss: 2.0584971569932082
Validation loss: 2.5426658537056395

Epoch: 5| Step: 6
Training loss: 2.506387275874632
Validation loss: 2.5301433875292143

Epoch: 5| Step: 7
Training loss: 2.3278245155945134
Validation loss: 2.487452546440686

Epoch: 5| Step: 8
Training loss: 2.343221579428692
Validation loss: 2.5114302078650947

Epoch: 5| Step: 9
Training loss: 2.2466771703223642
Validation loss: 2.5358372298629908

Epoch: 5| Step: 10
Training loss: 2.3058185452932674
Validation loss: 2.6342372409013546

Epoch: 176| Step: 0
Training loss: 2.172850465238487
Validation loss: 2.5715608552195817

Epoch: 5| Step: 1
Training loss: 2.2183057313382184
Validation loss: 2.5696570380440997

Epoch: 5| Step: 2
Training loss: 2.2565055681291377
Validation loss: 2.526423043496592

Epoch: 5| Step: 3
Training loss: 2.2189731754299302
Validation loss: 2.5329754801179813

Epoch: 5| Step: 4
Training loss: 2.782049514209213
Validation loss: 2.5223463991139803

Epoch: 5| Step: 5
Training loss: 2.5792283904825095
Validation loss: 2.4594917849311217

Epoch: 5| Step: 6
Training loss: 1.9206138132342436
Validation loss: 2.3906597188816794

Epoch: 5| Step: 7
Training loss: 2.0068720533550706
Validation loss: 2.4058950221220696

Epoch: 5| Step: 8
Training loss: 2.209055392660908
Validation loss: 2.4098142529275397

Epoch: 5| Step: 9
Training loss: 2.523664434757572
Validation loss: 2.4053835460158726

Epoch: 5| Step: 10
Training loss: 2.1409961907657125
Validation loss: 2.423272251210678

Epoch: 177| Step: 0
Training loss: 2.5226306865551114
Validation loss: 2.4674916215173726

Epoch: 5| Step: 1
Training loss: 2.1960094065230225
Validation loss: 2.6135989020201515

Epoch: 5| Step: 2
Training loss: 2.039183982065773
Validation loss: 2.646054318163533

Epoch: 5| Step: 3
Training loss: 2.3258215242434828
Validation loss: 2.6995367660015823

Epoch: 5| Step: 4
Training loss: 2.377505336238035
Validation loss: 2.671977569562932

Epoch: 5| Step: 5
Training loss: 1.8578305281268888
Validation loss: 2.614380201106594

Epoch: 5| Step: 6
Training loss: 2.492413453768039
Validation loss: 2.531061805323417

Epoch: 5| Step: 7
Training loss: 2.1740316756677305
Validation loss: 2.475567292005707

Epoch: 5| Step: 8
Training loss: 2.0527536552823142
Validation loss: 2.4435504570961064

Epoch: 5| Step: 9
Training loss: 2.4045665846894484
Validation loss: 2.4397246870885327

Epoch: 5| Step: 10
Training loss: 2.3815954883885087
Validation loss: 2.441715237923498

Epoch: 178| Step: 0
Training loss: 2.6547598754285295
Validation loss: 2.4303910381308125

Epoch: 5| Step: 1
Training loss: 2.3202062511842922
Validation loss: 2.4302762966803413

Epoch: 5| Step: 2
Training loss: 2.6040462516919565
Validation loss: 2.466910437403566

Epoch: 5| Step: 3
Training loss: 2.2974512324589926
Validation loss: 2.6309953618146964

Epoch: 5| Step: 4
Training loss: 2.026890345682072
Validation loss: 2.6857850655000775

Epoch: 5| Step: 5
Training loss: 2.0586078795322735
Validation loss: 2.6936434054868363

Epoch: 5| Step: 6
Training loss: 1.9863913196874903
Validation loss: 2.5223692236623023

Epoch: 5| Step: 7
Training loss: 1.9453337028604165
Validation loss: 2.460609817630369

Epoch: 5| Step: 8
Training loss: 2.576372973132149
Validation loss: 2.410925394040501

Epoch: 5| Step: 9
Training loss: 2.615828705105349
Validation loss: 2.413356397514946

Epoch: 5| Step: 10
Training loss: 2.1913894951871744
Validation loss: 2.4333637546093554

Epoch: 179| Step: 0
Training loss: 2.3594801923531143
Validation loss: 2.4878615483224635

Epoch: 5| Step: 1
Training loss: 2.2395682637498697
Validation loss: 2.491642448523526

Epoch: 5| Step: 2
Training loss: 2.4988762237132134
Validation loss: 2.4958402214863944

Epoch: 5| Step: 3
Training loss: 1.887874588838078
Validation loss: 2.4988297102365626

Epoch: 5| Step: 4
Training loss: 2.2388548856582116
Validation loss: 2.444818013656564

Epoch: 5| Step: 5
Training loss: 1.8734759176481475
Validation loss: 2.466039313524109

Epoch: 5| Step: 6
Training loss: 2.6364943119177977
Validation loss: 2.4329964604605627

Epoch: 5| Step: 7
Training loss: 2.251495923680108
Validation loss: 2.4612619233385664

Epoch: 5| Step: 8
Training loss: 2.4562365000113564
Validation loss: 2.547265036078251

Epoch: 5| Step: 9
Training loss: 1.6443221079295427
Validation loss: 2.676510113899554

Epoch: 5| Step: 10
Training loss: 2.6862573634029414
Validation loss: 2.8091258958085654

Epoch: 180| Step: 0
Training loss: 2.2446269412277946
Validation loss: 2.5938218155372876

Epoch: 5| Step: 1
Training loss: 1.8987278343448846
Validation loss: 2.4468029661147925

Epoch: 5| Step: 2
Training loss: 2.1627905237045657
Validation loss: 2.427967037581979

Epoch: 5| Step: 3
Training loss: 2.1933791583452193
Validation loss: 2.4095765095653072

Epoch: 5| Step: 4
Training loss: 2.5401657759267313
Validation loss: 2.388343727923816

Epoch: 5| Step: 5
Training loss: 2.526844193438008
Validation loss: 2.4277701957129127

Epoch: 5| Step: 6
Training loss: 2.239518547599623
Validation loss: 2.443319508214433

Epoch: 5| Step: 7
Training loss: 2.17346506437241
Validation loss: 2.543353594301703

Epoch: 5| Step: 8
Training loss: 2.422109088044386
Validation loss: 2.5633906735643515

Epoch: 5| Step: 9
Training loss: 2.4787285895872913
Validation loss: 2.6529178119268875

Epoch: 5| Step: 10
Training loss: 2.3480324848338885
Validation loss: 2.618915914877836

Epoch: 181| Step: 0
Training loss: 1.570055888450754
Validation loss: 2.4986604557581784

Epoch: 5| Step: 1
Training loss: 1.5645776287166187
Validation loss: 2.403995545048152

Epoch: 5| Step: 2
Training loss: 2.5943483328959323
Validation loss: 2.3903631583949156

Epoch: 5| Step: 3
Training loss: 2.675378298525681
Validation loss: 2.3870055635215945

Epoch: 5| Step: 4
Training loss: 2.4921913266526263
Validation loss: 2.3853933166000174

Epoch: 5| Step: 5
Training loss: 2.1344350155704808
Validation loss: 2.400543545777681

Epoch: 5| Step: 6
Training loss: 2.449004679546504
Validation loss: 2.4531848085823906

Epoch: 5| Step: 7
Training loss: 2.1004680066631294
Validation loss: 2.497114869119162

Epoch: 5| Step: 8
Training loss: 2.206332637979056
Validation loss: 2.560114904311386

Epoch: 5| Step: 9
Training loss: 2.124401905936534
Validation loss: 2.613920994592967

Epoch: 5| Step: 10
Training loss: 2.507229365826946
Validation loss: 2.6439701626033143

Epoch: 182| Step: 0
Training loss: 2.0467540909095026
Validation loss: 2.645144843828969

Epoch: 5| Step: 1
Training loss: 1.7991489782814054
Validation loss: 2.5623678688060814

Epoch: 5| Step: 2
Training loss: 1.8617811902485102
Validation loss: 2.5053676591826766

Epoch: 5| Step: 3
Training loss: 2.6443109913641156
Validation loss: 2.469033335736221

Epoch: 5| Step: 4
Training loss: 2.5505045672108255
Validation loss: 2.4320106928152603

Epoch: 5| Step: 5
Training loss: 2.063658648940794
Validation loss: 2.400535337029512

Epoch: 5| Step: 6
Training loss: 2.276004665839268
Validation loss: 2.3802210128754138

Epoch: 5| Step: 7
Training loss: 2.3262929172236357
Validation loss: 2.3977625091687735

Epoch: 5| Step: 8
Training loss: 2.405726784633843
Validation loss: 2.409904566426542

Epoch: 5| Step: 9
Training loss: 2.0598034426051357
Validation loss: 2.51000117425581

Epoch: 5| Step: 10
Training loss: 1.9910535988751659
Validation loss: 2.605980795380376

Epoch: 183| Step: 0
Training loss: 2.2403434587176134
Validation loss: 2.6669923807108207

Epoch: 5| Step: 1
Training loss: 2.0082165500776092
Validation loss: 2.677067007062359

Epoch: 5| Step: 2
Training loss: 2.8062017491871667
Validation loss: 2.6370804325096793

Epoch: 5| Step: 3
Training loss: 2.0040323615592532
Validation loss: 2.4843805000511043

Epoch: 5| Step: 4
Training loss: 1.9815005411767714
Validation loss: 2.4123476827820927

Epoch: 5| Step: 5
Training loss: 2.505473439444473
Validation loss: 2.3574521240492565

Epoch: 5| Step: 6
Training loss: 1.470176085610845
Validation loss: 2.344488090869669

Epoch: 5| Step: 7
Training loss: 2.2671403749853947
Validation loss: 2.3374192589399523

Epoch: 5| Step: 8
Training loss: 2.361400416981688
Validation loss: 2.3810807531589164

Epoch: 5| Step: 9
Training loss: 2.2996999793706108
Validation loss: 2.4207848949972046

Epoch: 5| Step: 10
Training loss: 2.505316707516668
Validation loss: 2.454757471740638

Epoch: 184| Step: 0
Training loss: 1.9256970617373814
Validation loss: 2.4877930754054987

Epoch: 5| Step: 1
Training loss: 2.291972007061243
Validation loss: 2.5035302063752223

Epoch: 5| Step: 2
Training loss: 2.0855852036741793
Validation loss: 2.50098664697904

Epoch: 5| Step: 3
Training loss: 1.7742661880070734
Validation loss: 2.4515673011331165

Epoch: 5| Step: 4
Training loss: 2.533726552093515
Validation loss: 2.4256624719783413

Epoch: 5| Step: 5
Training loss: 2.3670309789295962
Validation loss: 2.3927683060420946

Epoch: 5| Step: 6
Training loss: 2.0017175452091984
Validation loss: 2.469063462336035

Epoch: 5| Step: 7
Training loss: 1.9676486370939343
Validation loss: 2.5566657715391945

Epoch: 5| Step: 8
Training loss: 2.2171240208082676
Validation loss: 2.590495808350032

Epoch: 5| Step: 9
Training loss: 2.3356332229906402
Validation loss: 2.6750667505807617

Epoch: 5| Step: 10
Training loss: 2.553795615081524
Validation loss: 2.6869954138454624

Epoch: 185| Step: 0
Training loss: 2.1966429239166003
Validation loss: 2.5788625140199257

Epoch: 5| Step: 1
Training loss: 2.3327536430522584
Validation loss: 2.525221358929781

Epoch: 5| Step: 2
Training loss: 2.786421350726882
Validation loss: 2.5063888786690725

Epoch: 5| Step: 3
Training loss: 2.3621441083612513
Validation loss: 2.4575780619415557

Epoch: 5| Step: 4
Training loss: 1.7589582989831356
Validation loss: 2.4235305943961465

Epoch: 5| Step: 5
Training loss: 1.837889911517695
Validation loss: 2.402220738520762

Epoch: 5| Step: 6
Training loss: 1.850661948059692
Validation loss: 2.451626969949082

Epoch: 5| Step: 7
Training loss: 2.2744095549614523
Validation loss: 2.440141957796808

Epoch: 5| Step: 8
Training loss: 2.2832754888888025
Validation loss: 2.486743084479112

Epoch: 5| Step: 9
Training loss: 1.7212914836818471
Validation loss: 2.5209818604485137

Epoch: 5| Step: 10
Training loss: 1.66976617455334
Validation loss: 2.5679437103913068

Epoch: 186| Step: 0
Training loss: 2.139333070594309
Validation loss: 2.5897616745835976

Epoch: 5| Step: 1
Training loss: 2.0333535672833047
Validation loss: 2.5476085120679217

Epoch: 5| Step: 2
Training loss: 2.240858687766549
Validation loss: 2.559776613746229

Epoch: 5| Step: 3
Training loss: 2.500477554485999
Validation loss: 2.5947315529820743

Epoch: 5| Step: 4
Training loss: 2.0469099434934748
Validation loss: 2.5863827111866575

Epoch: 5| Step: 5
Training loss: 1.629370314544157
Validation loss: 2.539443269233586

Epoch: 5| Step: 6
Training loss: 2.2526202309684296
Validation loss: 2.4331886440092583

Epoch: 5| Step: 7
Training loss: 2.318010414811074
Validation loss: 2.4087708629692304

Epoch: 5| Step: 8
Training loss: 2.0885430111646883
Validation loss: 2.3874410914394244

Epoch: 5| Step: 9
Training loss: 1.6808135760231562
Validation loss: 2.395297535125641

Epoch: 5| Step: 10
Training loss: 2.0446324767612527
Validation loss: 2.406815238612036

Epoch: 187| Step: 0
Training loss: 1.934720599187587
Validation loss: 2.4792886402226526

Epoch: 5| Step: 1
Training loss: 1.6585908577993065
Validation loss: 2.562482080964695

Epoch: 5| Step: 2
Training loss: 2.720964604044831
Validation loss: 2.6065822602486257

Epoch: 5| Step: 3
Training loss: 2.071013134136024
Validation loss: 2.6620895840871865

Epoch: 5| Step: 4
Training loss: 2.050057535992321
Validation loss: 2.6392375672152393

Epoch: 5| Step: 5
Training loss: 1.8652733603991916
Validation loss: 2.5718504880547135

Epoch: 5| Step: 6
Training loss: 1.9501034978152216
Validation loss: 2.4691762809282034

Epoch: 5| Step: 7
Training loss: 2.409015404056184
Validation loss: 2.418346102239628

Epoch: 5| Step: 8
Training loss: 2.2208014661877544
Validation loss: 2.358184042295175

Epoch: 5| Step: 9
Training loss: 1.7846316979684629
Validation loss: 2.366702553420529

Epoch: 5| Step: 10
Training loss: 1.9894572379479623
Validation loss: 2.4013896182228414

Epoch: 188| Step: 0
Training loss: 2.294617873814421
Validation loss: 2.42598778295909

Epoch: 5| Step: 1
Training loss: 2.0292562236514216
Validation loss: 2.4570924043849915

Epoch: 5| Step: 2
Training loss: 2.1016153662176085
Validation loss: 2.5203911195041053

Epoch: 5| Step: 3
Training loss: 2.04845222101225
Validation loss: 2.551264789865591

Epoch: 5| Step: 4
Training loss: 1.832258393414042
Validation loss: 2.525258661685609

Epoch: 5| Step: 5
Training loss: 1.6255358766077468
Validation loss: 2.5285893723278083

Epoch: 5| Step: 6
Training loss: 2.133590388705701
Validation loss: 2.5529453247450697

Epoch: 5| Step: 7
Training loss: 2.0382483015105985
Validation loss: 2.582824088867913

Epoch: 5| Step: 8
Training loss: 1.7772663476878696
Validation loss: 2.5416886019218285

Epoch: 5| Step: 9
Training loss: 2.205002113566175
Validation loss: 2.518277017161013

Epoch: 5| Step: 10
Training loss: 2.4383425112395347
Validation loss: 2.5750822834456355

Epoch: 189| Step: 0
Training loss: 2.157677882564881
Validation loss: 2.505869816312899

Epoch: 5| Step: 1
Training loss: 2.1905968679235226
Validation loss: 2.456891272179584

Epoch: 5| Step: 2
Training loss: 1.9212860197365227
Validation loss: 2.450574817114943

Epoch: 5| Step: 3
Training loss: 1.8097729391917274
Validation loss: 2.4168229605940894

Epoch: 5| Step: 4
Training loss: 2.197515285295569
Validation loss: 2.4038578603379

Epoch: 5| Step: 5
Training loss: 1.6893848206929336
Validation loss: 2.4230244227476905

Epoch: 5| Step: 6
Training loss: 1.775267274640098
Validation loss: 2.474062837337548

Epoch: 5| Step: 7
Training loss: 1.973264151092905
Validation loss: 2.5613770864577288

Epoch: 5| Step: 8
Training loss: 1.7554648765585743
Validation loss: 2.6321491798166705

Epoch: 5| Step: 9
Training loss: 2.553104481795565
Validation loss: 2.6990025942807967

Epoch: 5| Step: 10
Training loss: 2.129543719962263
Validation loss: 2.5972512971259167

Epoch: 190| Step: 0
Training loss: 2.3309279600358113
Validation loss: 2.4028727287447174

Epoch: 5| Step: 1
Training loss: 1.8937335979897039
Validation loss: 2.3246696439472636

Epoch: 5| Step: 2
Training loss: 2.3947686082399944
Validation loss: 2.3272144998021203

Epoch: 5| Step: 3
Training loss: 1.8175275725486222
Validation loss: 2.3277247585126095

Epoch: 5| Step: 4
Training loss: 2.179680280776015
Validation loss: 2.3382973930610467

Epoch: 5| Step: 5
Training loss: 2.1701671005110703
Validation loss: 2.3499228292661387

Epoch: 5| Step: 6
Training loss: 2.0669043937464027
Validation loss: 2.405694791752763

Epoch: 5| Step: 7
Training loss: 2.0163172043386335
Validation loss: 2.5960060841032604

Epoch: 5| Step: 8
Training loss: 2.267749080078692
Validation loss: 2.662236585714874

Epoch: 5| Step: 9
Training loss: 1.8122951786463146
Validation loss: 2.6867827707797303

Epoch: 5| Step: 10
Training loss: 1.6197391595538047
Validation loss: 2.6700046711696057

Epoch: 191| Step: 0
Training loss: 2.0268450584870275
Validation loss: 2.5723003120658356

Epoch: 5| Step: 1
Training loss: 1.844397285763711
Validation loss: 2.486611220776927

Epoch: 5| Step: 2
Training loss: 2.4336859377916724
Validation loss: 2.3933870971620688

Epoch: 5| Step: 3
Training loss: 1.844152762177744
Validation loss: 2.3502845768145053

Epoch: 5| Step: 4
Training loss: 1.9974298055678392
Validation loss: 2.332067600818285

Epoch: 5| Step: 5
Training loss: 2.0373229575908214
Validation loss: 2.337495125447485

Epoch: 5| Step: 6
Training loss: 2.252980377592674
Validation loss: 2.3470805742040524

Epoch: 5| Step: 7
Training loss: 2.104492640661204
Validation loss: 2.3648306792376093

Epoch: 5| Step: 8
Training loss: 1.6378007830946935
Validation loss: 2.4471927372665943

Epoch: 5| Step: 9
Training loss: 1.9574585712672283
Validation loss: 2.5546635622893303

Epoch: 5| Step: 10
Training loss: 1.3090978761629666
Validation loss: 2.6476755128070417

Epoch: 192| Step: 0
Training loss: 2.254114521525817
Validation loss: 2.7166794211987044

Epoch: 5| Step: 1
Training loss: 1.5060150026483483
Validation loss: 2.7187339811474325

Epoch: 5| Step: 2
Training loss: 2.1601835114619634
Validation loss: 2.695950264280961

Epoch: 5| Step: 3
Training loss: 2.3467022422059043
Validation loss: 2.610119808704918

Epoch: 5| Step: 4
Training loss: 2.186127695421678
Validation loss: 2.3964299048191213

Epoch: 5| Step: 5
Training loss: 2.0532135408723047
Validation loss: 2.31958918330385

Epoch: 5| Step: 6
Training loss: 2.2410085948283927
Validation loss: 2.3030247216528212

Epoch: 5| Step: 7
Training loss: 1.9529600760446353
Validation loss: 2.2990936352630524

Epoch: 5| Step: 8
Training loss: 1.7564403009995364
Validation loss: 2.3188058870129815

Epoch: 5| Step: 9
Training loss: 1.7731911912516434
Validation loss: 2.378421126386864

Epoch: 5| Step: 10
Training loss: 1.657849385303317
Validation loss: 2.494843807767835

Epoch: 193| Step: 0
Training loss: 1.8633540557136692
Validation loss: 2.526047517807559

Epoch: 5| Step: 1
Training loss: 2.0804897993443228
Validation loss: 2.6477385264755937

Epoch: 5| Step: 2
Training loss: 2.1318077543372986
Validation loss: 2.632678797070917

Epoch: 5| Step: 3
Training loss: 1.4345597590713333
Validation loss: 2.664182022334637

Epoch: 5| Step: 4
Training loss: 2.420473739346033
Validation loss: 2.684313571397115

Epoch: 5| Step: 5
Training loss: 1.8922886740287657
Validation loss: 2.4586938545357095

Epoch: 5| Step: 6
Training loss: 2.0503280284161574
Validation loss: 2.386935535637612

Epoch: 5| Step: 7
Training loss: 1.764632697317564
Validation loss: 2.356338274364565

Epoch: 5| Step: 8
Training loss: 2.1183739747661536
Validation loss: 2.3647111684043143

Epoch: 5| Step: 9
Training loss: 1.64663684722732
Validation loss: 2.3647159103588695

Epoch: 5| Step: 10
Training loss: 1.8684509982246587
Validation loss: 2.37378443583224

Epoch: 194| Step: 0
Training loss: 1.802518126969318
Validation loss: 2.3851121897207226

Epoch: 5| Step: 1
Training loss: 2.255279492906697
Validation loss: 2.4284733286442073

Epoch: 5| Step: 2
Training loss: 2.168774154484602
Validation loss: 2.4760751542021198

Epoch: 5| Step: 3
Training loss: 1.822215186889889
Validation loss: 2.5103785595720347

Epoch: 5| Step: 4
Training loss: 1.8860239838726653
Validation loss: 2.5897876626583205

Epoch: 5| Step: 5
Training loss: 1.7666368538962136
Validation loss: 2.586507673598554

Epoch: 5| Step: 6
Training loss: 1.8083446487682147
Validation loss: 2.64233497630169

Epoch: 5| Step: 7
Training loss: 1.8972140164785074
Validation loss: 2.622979775003781

Epoch: 5| Step: 8
Training loss: 2.1142321014602947
Validation loss: 2.5889702037372593

Epoch: 5| Step: 9
Training loss: 1.8199658370741647
Validation loss: 2.512552711735058

Epoch: 5| Step: 10
Training loss: 1.28466796875
Validation loss: 2.4735159094411374

Epoch: 195| Step: 0
Training loss: 1.3436081833634783
Validation loss: 2.442951120971954

Epoch: 5| Step: 1
Training loss: 2.2390093992103286
Validation loss: 2.4081789394803224

Epoch: 5| Step: 2
Training loss: 1.675376861081694
Validation loss: 2.3781565504897353

Epoch: 5| Step: 3
Training loss: 1.8254308165932263
Validation loss: 2.412920331629732

Epoch: 5| Step: 4
Training loss: 2.438240427875142
Validation loss: 2.4347348280002827

Epoch: 5| Step: 5
Training loss: 1.7201923907046583
Validation loss: 2.4575360359017826

Epoch: 5| Step: 6
Training loss: 1.6208986463683366
Validation loss: 2.469025652174421

Epoch: 5| Step: 7
Training loss: 1.943183561260409
Validation loss: 2.5181262916422744

Epoch: 5| Step: 8
Training loss: 1.8029537708028178
Validation loss: 2.520430917603069

Epoch: 5| Step: 9
Training loss: 1.798336927052685
Validation loss: 2.5424091092590335

Epoch: 5| Step: 10
Training loss: 1.862331828263162
Validation loss: 2.5831028587058307

Epoch: 196| Step: 0
Training loss: 2.367433138651461
Validation loss: 2.5815217006802835

Epoch: 5| Step: 1
Training loss: 1.7500077656164894
Validation loss: 2.5314279055973903

Epoch: 5| Step: 2
Training loss: 1.8371433924081155
Validation loss: 2.413349881530443

Epoch: 5| Step: 3
Training loss: 1.794666624962427
Validation loss: 2.380261262264031

Epoch: 5| Step: 4
Training loss: 1.3203801696410344
Validation loss: 2.3699185209095512

Epoch: 5| Step: 5
Training loss: 2.057966509525214
Validation loss: 2.3498486633548996

Epoch: 5| Step: 6
Training loss: 1.4116043728471814
Validation loss: 2.375245171776956

Epoch: 5| Step: 7
Training loss: 2.010480125361267
Validation loss: 2.4337924640504878

Epoch: 5| Step: 8
Training loss: 1.5704177137968371
Validation loss: 2.5267893364782776

Epoch: 5| Step: 9
Training loss: 2.319749449157485
Validation loss: 2.600665658381796

Epoch: 5| Step: 10
Training loss: 1.594799892704149
Validation loss: 2.626295333636359

Epoch: 197| Step: 0
Training loss: 2.1223194943294335
Validation loss: 2.7208496414246346

Epoch: 5| Step: 1
Training loss: 1.1420031543594595
Validation loss: 2.597429633836032

Epoch: 5| Step: 2
Training loss: 1.7804919855226122
Validation loss: 2.520743810260197

Epoch: 5| Step: 3
Training loss: 2.249261734960153
Validation loss: 2.4572486837967213

Epoch: 5| Step: 4
Training loss: 1.6199207152285908
Validation loss: 2.416781195924227

Epoch: 5| Step: 5
Training loss: 1.6447117359855268
Validation loss: 2.4158355916129106

Epoch: 5| Step: 6
Training loss: 1.844648110138635
Validation loss: 2.3868262709796526

Epoch: 5| Step: 7
Training loss: 1.526138571655808
Validation loss: 2.380547771501039

Epoch: 5| Step: 8
Training loss: 2.1731724877115566
Validation loss: 2.384541221702459

Epoch: 5| Step: 9
Training loss: 1.6736170169344475
Validation loss: 2.415656323773669

Epoch: 5| Step: 10
Training loss: 2.231188335688573
Validation loss: 2.4388119606306105

Epoch: 198| Step: 0
Training loss: 1.6343825243453933
Validation loss: 2.492706366198068

Epoch: 5| Step: 1
Training loss: 1.4317238901860554
Validation loss: 2.5701468697017127

Epoch: 5| Step: 2
Training loss: 2.1637913503061963
Validation loss: 2.6245290545696833

Epoch: 5| Step: 3
Training loss: 1.910009273186986
Validation loss: 2.6182106825621156

Epoch: 5| Step: 4
Training loss: 1.6830409441277998
Validation loss: 2.535586229404786

Epoch: 5| Step: 5
Training loss: 1.855172802261617
Validation loss: 2.424940964039703

Epoch: 5| Step: 6
Training loss: 2.1160275142589886
Validation loss: 2.375169539647483

Epoch: 5| Step: 7
Training loss: 1.8799527559025677
Validation loss: 2.3437881936957146

Epoch: 5| Step: 8
Training loss: 2.008881874147244
Validation loss: 2.3404458834358586

Epoch: 5| Step: 9
Training loss: 1.921128849237902
Validation loss: 2.3772462650658506

Epoch: 5| Step: 10
Training loss: 1.136453027243717
Validation loss: 2.4340939458499755

Epoch: 199| Step: 0
Training loss: 1.914041698109221
Validation loss: 2.50917753685159

Epoch: 5| Step: 1
Training loss: 1.9398700615538378
Validation loss: 2.567727866599053

Epoch: 5| Step: 2
Training loss: 2.1168295920237608
Validation loss: 2.601185674382376

Epoch: 5| Step: 3
Training loss: 1.9155277793819605
Validation loss: 2.514285332707753

Epoch: 5| Step: 4
Training loss: 1.5785268139837918
Validation loss: 2.422074875008492

Epoch: 5| Step: 5
Training loss: 2.005711268646679
Validation loss: 2.3819085886432116

Epoch: 5| Step: 6
Training loss: 1.5391652029402623
Validation loss: 2.3730568506174734

Epoch: 5| Step: 7
Training loss: 1.52953250088038
Validation loss: 2.4106667049643495

Epoch: 5| Step: 8
Training loss: 1.8242693287537854
Validation loss: 2.4913002512976434

Epoch: 5| Step: 9
Training loss: 1.8474490672564068
Validation loss: 2.5717377486147535

Epoch: 5| Step: 10
Training loss: 1.628805692573972
Validation loss: 2.626251724559733

Epoch: 200| Step: 0
Training loss: 1.6312139251344724
Validation loss: 2.6097423355575637

Epoch: 5| Step: 1
Training loss: 1.981277210518057
Validation loss: 2.6687343493879236

Epoch: 5| Step: 2
Training loss: 1.6815155018192
Validation loss: 2.5967026652698224

Epoch: 5| Step: 3
Training loss: 1.9500158969524606
Validation loss: 2.536240486579975

Epoch: 5| Step: 4
Training loss: 1.400476982401492
Validation loss: 2.4629589585701686

Epoch: 5| Step: 5
Training loss: 1.8055856294654185
Validation loss: 2.4151655247736334

Epoch: 5| Step: 6
Training loss: 2.0026270778686417
Validation loss: 2.382987562150644

Epoch: 5| Step: 7
Training loss: 1.7020942298543482
Validation loss: 2.341784631482159

Epoch: 5| Step: 8
Training loss: 1.6564207168982248
Validation loss: 2.348123019403532

Epoch: 5| Step: 9
Training loss: 1.7707321437273063
Validation loss: 2.38397350111034

Epoch: 5| Step: 10
Training loss: 1.7251499663691916
Validation loss: 2.4401603507789504

Epoch: 201| Step: 0
Training loss: 1.97912208774622
Validation loss: 2.4583558197480846

Epoch: 5| Step: 1
Training loss: 1.572036707544176
Validation loss: 2.5401207361084577

Epoch: 5| Step: 2
Training loss: 1.666520644784822
Validation loss: 2.6108975943527235

Epoch: 5| Step: 3
Training loss: 1.8559460477797536
Validation loss: 2.6210814554995205

Epoch: 5| Step: 4
Training loss: 1.5770090519869657
Validation loss: 2.571022154904289

Epoch: 5| Step: 5
Training loss: 1.6493882605802719
Validation loss: 2.530588661940144

Epoch: 5| Step: 6
Training loss: 2.0278143364152426
Validation loss: 2.439833392668895

Epoch: 5| Step: 7
Training loss: 1.9365213445131781
Validation loss: 2.403943268081877

Epoch: 5| Step: 8
Training loss: 1.9149033548454704
Validation loss: 2.384390250181833

Epoch: 5| Step: 9
Training loss: 1.4741696946433054
Validation loss: 2.411125230441467

Epoch: 5| Step: 10
Training loss: 1.652222324536088
Validation loss: 2.4482013279425345

Epoch: 202| Step: 0
Training loss: 1.7601438532907883
Validation loss: 2.483072450861051

Epoch: 5| Step: 1
Training loss: 1.4499354479660234
Validation loss: 2.534998939308281

Epoch: 5| Step: 2
Training loss: 1.3536125027333903
Validation loss: 2.5886530536613765

Epoch: 5| Step: 3
Training loss: 1.3112136349940227
Validation loss: 2.6117829590690946

Epoch: 5| Step: 4
Training loss: 2.393093056832958
Validation loss: 2.640945171477792

Epoch: 5| Step: 5
Training loss: 1.8062919981406653
Validation loss: 2.5495699599313326

Epoch: 5| Step: 6
Training loss: 1.5704266710672035
Validation loss: 2.487867873275003

Epoch: 5| Step: 7
Training loss: 1.7527680303897384
Validation loss: 2.4398169011839106

Epoch: 5| Step: 8
Training loss: 2.0370558880726843
Validation loss: 2.396328607829568

Epoch: 5| Step: 9
Training loss: 1.5893257665715383
Validation loss: 2.407292779189269

Epoch: 5| Step: 10
Training loss: 1.8195837960818801
Validation loss: 2.4109179176642925

Epoch: 203| Step: 0
Training loss: 1.1693214569800847
Validation loss: 2.4662620518002205

Epoch: 5| Step: 1
Training loss: 1.8092692948794087
Validation loss: 2.536245161541626

Epoch: 5| Step: 2
Training loss: 1.5646820853299452
Validation loss: 2.588565240911388

Epoch: 5| Step: 3
Training loss: 1.6547616713256776
Validation loss: 2.6563288359069217

Epoch: 5| Step: 4
Training loss: 1.8045319329129275
Validation loss: 2.6093557355971684

Epoch: 5| Step: 5
Training loss: 1.456420361291193
Validation loss: 2.5431404124508177

Epoch: 5| Step: 6
Training loss: 1.5432484819858043
Validation loss: 2.5106439822407087

Epoch: 5| Step: 7
Training loss: 2.400001041094236
Validation loss: 2.45732882127667

Epoch: 5| Step: 8
Training loss: 1.695223757622994
Validation loss: 2.4070538788248435

Epoch: 5| Step: 9
Training loss: 1.7037747045056688
Validation loss: 2.387258233021622

Epoch: 5| Step: 10
Training loss: 1.6873469106674794
Validation loss: 2.369466206783105

Epoch: 204| Step: 0
Training loss: 1.7738389556493632
Validation loss: 2.352575377588726

Epoch: 5| Step: 1
Training loss: 1.7326335928136714
Validation loss: 2.3849870275415213

Epoch: 5| Step: 2
Training loss: 1.892145538494813
Validation loss: 2.3997277671993955

Epoch: 5| Step: 3
Training loss: 1.6292749074636166
Validation loss: 2.474341356109728

Epoch: 5| Step: 4
Training loss: 1.321269484189529
Validation loss: 2.5465410804943773

Epoch: 5| Step: 5
Training loss: 1.572080613144133
Validation loss: 2.6053692268779116

Epoch: 5| Step: 6
Training loss: 1.375349997278192
Validation loss: 2.6199243787914455

Epoch: 5| Step: 7
Training loss: 1.86191174222785
Validation loss: 2.6546489390303067

Epoch: 5| Step: 8
Training loss: 2.0649863775141104
Validation loss: 2.5970870117289486

Epoch: 5| Step: 9
Training loss: 1.7614365582179532
Validation loss: 2.5012102284392768

Epoch: 5| Step: 10
Training loss: 1.6203587347955084
Validation loss: 2.424380019078835

Epoch: 205| Step: 0
Training loss: 1.9409929599310012
Validation loss: 2.3973329969776813

Epoch: 5| Step: 1
Training loss: 1.9209876764588287
Validation loss: 2.3533670249065013

Epoch: 5| Step: 2
Training loss: 1.98772382135704
Validation loss: 2.382128007474439

Epoch: 5| Step: 3
Training loss: 1.2251420756102547
Validation loss: 2.4209576391330514

Epoch: 5| Step: 4
Training loss: 1.6130298483275065
Validation loss: 2.4351776430250696

Epoch: 5| Step: 5
Training loss: 1.5861838013263045
Validation loss: 2.4920485689858043

Epoch: 5| Step: 6
Training loss: 1.5483436933293362
Validation loss: 2.5729589546404794

Epoch: 5| Step: 7
Training loss: 1.8349376796773127
Validation loss: 2.5972071278278794

Epoch: 5| Step: 8
Training loss: 1.7188328809695335
Validation loss: 2.569343638380404

Epoch: 5| Step: 9
Training loss: 1.5081770065958728
Validation loss: 2.5088884960487077

Epoch: 5| Step: 10
Training loss: 1.4813204205348203
Validation loss: 2.51550276162553

Epoch: 206| Step: 0
Training loss: 1.9640304065106438
Validation loss: 2.512263846998882

Epoch: 5| Step: 1
Training loss: 1.6377520156170142
Validation loss: 2.4880968220216135

Epoch: 5| Step: 2
Training loss: 1.2732688932606844
Validation loss: 2.5274552319753227

Epoch: 5| Step: 3
Training loss: 1.435344406693535
Validation loss: 2.496269851889823

Epoch: 5| Step: 4
Training loss: 1.2599384987671658
Validation loss: 2.520196604589973

Epoch: 5| Step: 5
Training loss: 1.6530204090859297
Validation loss: 2.534771911842782

Epoch: 5| Step: 6
Training loss: 1.0960620965282035
Validation loss: 2.513266715895218

Epoch: 5| Step: 7
Training loss: 2.09444916851389
Validation loss: 2.5389643915372804

Epoch: 5| Step: 8
Training loss: 1.6836224263663153
Validation loss: 2.5155489464286536

Epoch: 5| Step: 9
Training loss: 2.0113526242605677
Validation loss: 2.550371130007269

Epoch: 5| Step: 10
Training loss: 1.7748702391353663
Validation loss: 2.5199854292678645

Epoch: 207| Step: 0
Training loss: 1.2639758821854394
Validation loss: 2.4642344126062627

Epoch: 5| Step: 1
Training loss: 1.4392249497166316
Validation loss: 2.4467630496134207

Epoch: 5| Step: 2
Training loss: 2.0013687695172826
Validation loss: 2.4212948509493692

Epoch: 5| Step: 3
Training loss: 1.210707218054692
Validation loss: 2.4011549024835976

Epoch: 5| Step: 4
Training loss: 1.4132306091446694
Validation loss: 2.4172141021217723

Epoch: 5| Step: 5
Training loss: 1.2023759467044572
Validation loss: 2.491642108987864

Epoch: 5| Step: 6
Training loss: 2.1293111713540425
Validation loss: 2.5513763861621586

Epoch: 5| Step: 7
Training loss: 2.014413750607475
Validation loss: 2.6141893444366695

Epoch: 5| Step: 8
Training loss: 1.9230865753371753
Validation loss: 2.620204827312345

Epoch: 5| Step: 9
Training loss: 1.640121091931175
Validation loss: 2.631471801993426

Epoch: 5| Step: 10
Training loss: 1.4021546812831103
Validation loss: 2.5475489871284496

Epoch: 208| Step: 0
Training loss: 1.7451807831296602
Validation loss: 2.54510691038264

Epoch: 5| Step: 1
Training loss: 1.2441648663565064
Validation loss: 2.509123384850966

Epoch: 5| Step: 2
Training loss: 1.9115173857364993
Validation loss: 2.4942273917690754

Epoch: 5| Step: 3
Training loss: 1.383481224994217
Validation loss: 2.4546523869152312

Epoch: 5| Step: 4
Training loss: 1.5933785099078566
Validation loss: 2.4541487158308546

Epoch: 5| Step: 5
Training loss: 1.3938192478647953
Validation loss: 2.45973247578754

Epoch: 5| Step: 6
Training loss: 1.7969316556540353
Validation loss: 2.4463879156318242

Epoch: 5| Step: 7
Training loss: 1.4746987827303504
Validation loss: 2.4806661144748205

Epoch: 5| Step: 8
Training loss: 1.8471429930532959
Validation loss: 2.4902521910765016

Epoch: 5| Step: 9
Training loss: 1.387081002214069
Validation loss: 2.4920637987458854

Epoch: 5| Step: 10
Training loss: 1.8664031995171153
Validation loss: 2.519236632961042

Epoch: 209| Step: 0
Training loss: 1.908237421826669
Validation loss: 2.4946496911841987

Epoch: 5| Step: 1
Training loss: 1.706667095248844
Validation loss: 2.489513583825281

Epoch: 5| Step: 2
Training loss: 1.225740047659511
Validation loss: 2.5012069188409893

Epoch: 5| Step: 3
Training loss: 1.9232591436325694
Validation loss: 2.4538547822098153

Epoch: 5| Step: 4
Training loss: 1.5663493995148317
Validation loss: 2.475482754337779

Epoch: 5| Step: 5
Training loss: 1.7905886608117967
Validation loss: 2.4950774685459804

Epoch: 5| Step: 6
Training loss: 1.1261736258163366
Validation loss: 2.4857617975328847

Epoch: 5| Step: 7
Training loss: 1.2729694465812293
Validation loss: 2.5046391686839664

Epoch: 5| Step: 8
Training loss: 1.5042293845474697
Validation loss: 2.513021404953401

Epoch: 5| Step: 9
Training loss: 1.620693295206053
Validation loss: 2.552393657877221

Epoch: 5| Step: 10
Training loss: 1.6438711839686289
Validation loss: 2.5841491025144774

Epoch: 210| Step: 0
Training loss: 1.739415722232191
Validation loss: 2.5855711907472854

Epoch: 5| Step: 1
Training loss: 1.871541011608598
Validation loss: 2.590712087614135

Epoch: 5| Step: 2
Training loss: 1.387543854578844
Validation loss: 2.581194741330159

Epoch: 5| Step: 3
Training loss: 1.750957431465308
Validation loss: 2.5203565175230427

Epoch: 5| Step: 4
Training loss: 1.5577961116376398
Validation loss: 2.46547235805862

Epoch: 5| Step: 5
Training loss: 1.5230524603561988
Validation loss: 2.4281719107417326

Epoch: 5| Step: 6
Training loss: 1.4543424039236228
Validation loss: 2.414370975762911

Epoch: 5| Step: 7
Training loss: 1.4862533730997192
Validation loss: 2.402669773744481

Epoch: 5| Step: 8
Training loss: 1.0607115334956292
Validation loss: 2.431458441003795

Epoch: 5| Step: 9
Training loss: 1.6742629351105547
Validation loss: 2.486577670475346

Epoch: 5| Step: 10
Training loss: 1.8320795309053195
Validation loss: 2.5143746343916566

Epoch: 211| Step: 0
Training loss: 1.4767061193949431
Validation loss: 2.587219196253727

Epoch: 5| Step: 1
Training loss: 1.5676380365606963
Validation loss: 2.575275428156006

Epoch: 5| Step: 2
Training loss: 0.9480750332404443
Validation loss: 2.520448017766321

Epoch: 5| Step: 3
Training loss: 1.5898743422655566
Validation loss: 2.526206574270611

Epoch: 5| Step: 4
Training loss: 1.3335743130036746
Validation loss: 2.538719955573296

Epoch: 5| Step: 5
Training loss: 1.173166301083597
Validation loss: 2.5492598028561457

Epoch: 5| Step: 6
Training loss: 2.2210328084694306
Validation loss: 2.5435883119648612

Epoch: 5| Step: 7
Training loss: 1.8999044770773168
Validation loss: 2.521001029345765

Epoch: 5| Step: 8
Training loss: 1.7482952943026908
Validation loss: 2.4564774399046323

Epoch: 5| Step: 9
Training loss: 1.350563782836412
Validation loss: 2.401851531795276

Epoch: 5| Step: 10
Training loss: 1.72940871448141
Validation loss: 2.380148844458972

Epoch: 212| Step: 0
Training loss: 1.6158814984770267
Validation loss: 2.381031100880612

Epoch: 5| Step: 1
Training loss: 1.7693575001143944
Validation loss: 2.3804809029374474

Epoch: 5| Step: 2
Training loss: 1.7641666432294933
Validation loss: 2.4054811727932686

Epoch: 5| Step: 3
Training loss: 1.5956751845492183
Validation loss: 2.437758785127427

Epoch: 5| Step: 4
Training loss: 1.4055475811905915
Validation loss: 2.4787531323675545

Epoch: 5| Step: 5
Training loss: 1.5084167218560336
Validation loss: 2.5564244375857736

Epoch: 5| Step: 6
Training loss: 1.3138095135915024
Validation loss: 2.6456956734735573

Epoch: 5| Step: 7
Training loss: 1.4103007572766302
Validation loss: 2.6928532830090584

Epoch: 5| Step: 8
Training loss: 1.5925599685468579
Validation loss: 2.6540143211830185

Epoch: 5| Step: 9
Training loss: 1.5969109697266013
Validation loss: 2.5378261487293194

Epoch: 5| Step: 10
Training loss: 1.7131155425307854
Validation loss: 2.463428130390234

Epoch: 213| Step: 0
Training loss: 1.6178965465399158
Validation loss: 2.3871218682926534

Epoch: 5| Step: 1
Training loss: 1.7989387933773944
Validation loss: 2.3246839229296947

Epoch: 5| Step: 2
Training loss: 1.6666056939734035
Validation loss: 2.3740413665415057

Epoch: 5| Step: 3
Training loss: 1.5155304554818159
Validation loss: 2.4306960125570094

Epoch: 5| Step: 4
Training loss: 1.3644515209259556
Validation loss: 2.478198604827485

Epoch: 5| Step: 5
Training loss: 1.2988959502673691
Validation loss: 2.5749968572832955

Epoch: 5| Step: 6
Training loss: 1.5398213021525797
Validation loss: 2.6219670264812525

Epoch: 5| Step: 7
Training loss: 1.7845408507866165
Validation loss: 2.6474639606537624

Epoch: 5| Step: 8
Training loss: 1.5117625148855107
Validation loss: 2.5962406559491713

Epoch: 5| Step: 9
Training loss: 1.6384640949542049
Validation loss: 2.4720120636973886

Epoch: 5| Step: 10
Training loss: 1.5251436509810903
Validation loss: 2.413106747523986

Epoch: 214| Step: 0
Training loss: 1.4657706214772372
Validation loss: 2.3976118611971735

Epoch: 5| Step: 1
Training loss: 1.3120747740244172
Validation loss: 2.37113015500557

Epoch: 5| Step: 2
Training loss: 1.5966525107587763
Validation loss: 2.3851437256456625

Epoch: 5| Step: 3
Training loss: 1.4292233239927798
Validation loss: 2.457972209248422

Epoch: 5| Step: 4
Training loss: 1.4953028727413846
Validation loss: 2.527533862629366

Epoch: 5| Step: 5
Training loss: 1.827013639761419
Validation loss: 2.5754662788975713

Epoch: 5| Step: 6
Training loss: 1.5104224193945763
Validation loss: 2.5258811163025197

Epoch: 5| Step: 7
Training loss: 1.6296533568217102
Validation loss: 2.487251231207582

Epoch: 5| Step: 8
Training loss: 1.9456695474094965
Validation loss: 2.4995605343981313

Epoch: 5| Step: 9
Training loss: 1.599728757993558
Validation loss: 2.4551873019943073

Epoch: 5| Step: 10
Training loss: 1.209211731764768
Validation loss: 2.4240344542121854

Epoch: 215| Step: 0
Training loss: 1.5066918670746716
Validation loss: 2.4470937982646457

Epoch: 5| Step: 1
Training loss: 1.6484324378347184
Validation loss: 2.451277827001145

Epoch: 5| Step: 2
Training loss: 1.5116390236819406
Validation loss: 2.4673399495946584

Epoch: 5| Step: 3
Training loss: 0.9850820696474418
Validation loss: 2.476274981865941

Epoch: 5| Step: 4
Training loss: 1.6468545988437067
Validation loss: 2.48700708469071

Epoch: 5| Step: 5
Training loss: 1.9765950075876408
Validation loss: 2.551104633717227

Epoch: 5| Step: 6
Training loss: 1.3434367147347106
Validation loss: 2.5593237511749547

Epoch: 5| Step: 7
Training loss: 1.5981653423685083
Validation loss: 2.5947029220479356

Epoch: 5| Step: 8
Training loss: 1.657791571885015
Validation loss: 2.5272662779541593

Epoch: 5| Step: 9
Training loss: 1.0704665247223508
Validation loss: 2.5086713349009115

Epoch: 5| Step: 10
Training loss: 1.611719368339564
Validation loss: 2.4770841645926995

Epoch: 216| Step: 0
Training loss: 1.6812270095557922
Validation loss: 2.4540886946510807

Epoch: 5| Step: 1
Training loss: 1.7074746400617073
Validation loss: 2.442910182362107

Epoch: 5| Step: 2
Training loss: 1.496610547240562
Validation loss: 2.4637922124765104

Epoch: 5| Step: 3
Training loss: 1.5026023860328037
Validation loss: 2.504362766464441

Epoch: 5| Step: 4
Training loss: 1.6733591497691733
Validation loss: 2.533062632110869

Epoch: 5| Step: 5
Training loss: 1.3354381944386144
Validation loss: 2.528397433872604

Epoch: 5| Step: 6
Training loss: 1.4852576592913576
Validation loss: 2.5471299949280555

Epoch: 5| Step: 7
Training loss: 1.5844036633910232
Validation loss: 2.4906645369973948

Epoch: 5| Step: 8
Training loss: 1.295605785266035
Validation loss: 2.479619968577003

Epoch: 5| Step: 9
Training loss: 1.3463577870579144
Validation loss: 2.4587704426501764

Epoch: 5| Step: 10
Training loss: 1.4006947888031533
Validation loss: 2.450374294500626

Epoch: 217| Step: 0
Training loss: 1.6085471088600791
Validation loss: 2.4222217979718037

Epoch: 5| Step: 1
Training loss: 1.2756860458068946
Validation loss: 2.4221326475940614

Epoch: 5| Step: 2
Training loss: 1.7033318210279067
Validation loss: 2.4436982562828926

Epoch: 5| Step: 3
Training loss: 1.4250840245956
Validation loss: 2.4572056881002577

Epoch: 5| Step: 4
Training loss: 1.291019318498877
Validation loss: 2.482221367888367

Epoch: 5| Step: 5
Training loss: 1.91256886027914
Validation loss: 2.5622650406929397

Epoch: 5| Step: 6
Training loss: 1.1736847699517166
Validation loss: 2.6071791565966858

Epoch: 5| Step: 7
Training loss: 1.5369422366097325
Validation loss: 2.601219167647895

Epoch: 5| Step: 8
Training loss: 1.66178200497775
Validation loss: 2.6005288397154027

Epoch: 5| Step: 9
Training loss: 1.2189896665797
Validation loss: 2.5090315359882176

Epoch: 5| Step: 10
Training loss: 1.4645227512872874
Validation loss: 2.4383404252876337

Epoch: 218| Step: 0
Training loss: 1.8622126363999694
Validation loss: 2.395048946331147

Epoch: 5| Step: 1
Training loss: 1.2678301403462957
Validation loss: 2.4092039842810857

Epoch: 5| Step: 2
Training loss: 1.4987292470123548
Validation loss: 2.442283471854961

Epoch: 5| Step: 3
Training loss: 1.3675012283040724
Validation loss: 2.507418298200922

Epoch: 5| Step: 4
Training loss: 1.7379694626894244
Validation loss: 2.593632612007169

Epoch: 5| Step: 5
Training loss: 1.2836519382542857
Validation loss: 2.641229764020485

Epoch: 5| Step: 6
Training loss: 1.576770314337515
Validation loss: 2.6317160693066763

Epoch: 5| Step: 7
Training loss: 1.1571639289484756
Validation loss: 2.6055449692805035

Epoch: 5| Step: 8
Training loss: 1.4672078091614296
Validation loss: 2.531415610071819

Epoch: 5| Step: 9
Training loss: 1.4497331801279305
Validation loss: 2.4861383993643624

Epoch: 5| Step: 10
Training loss: 1.5637754956308383
Validation loss: 2.4181356480963268

Epoch: 219| Step: 0
Training loss: 1.494826694126862
Validation loss: 2.4053189080071378

Epoch: 5| Step: 1
Training loss: 1.6947706209113587
Validation loss: 2.3874767231677643

Epoch: 5| Step: 2
Training loss: 1.4341137018496002
Validation loss: 2.3889516391709957

Epoch: 5| Step: 3
Training loss: 1.2307970365950422
Validation loss: 2.409772774774261

Epoch: 5| Step: 4
Training loss: 1.5145654809346536
Validation loss: 2.4467668168612584

Epoch: 5| Step: 5
Training loss: 1.8791001313040232
Validation loss: 2.5178842938417105

Epoch: 5| Step: 6
Training loss: 1.0825772887339076
Validation loss: 2.618776059518467

Epoch: 5| Step: 7
Training loss: 1.4167620776341356
Validation loss: 2.666368911703977

Epoch: 5| Step: 8
Training loss: 1.111034924491274
Validation loss: 2.6675026401070348

Epoch: 5| Step: 9
Training loss: 1.5608171174116225
Validation loss: 2.646275482815338

Epoch: 5| Step: 10
Training loss: 1.4327524819486543
Validation loss: 2.5885266498169623

Epoch: 220| Step: 0
Training loss: 1.644751164825718
Validation loss: 2.534445661736133

Epoch: 5| Step: 1
Training loss: 1.4442138620285823
Validation loss: 2.46538254740877

Epoch: 5| Step: 2
Training loss: 1.1254518449226818
Validation loss: 2.451651853050682

Epoch: 5| Step: 3
Training loss: 1.3978602320748819
Validation loss: 2.439468987352733

Epoch: 5| Step: 4
Training loss: 1.1430916960606101
Validation loss: 2.4180281474075542

Epoch: 5| Step: 5
Training loss: 1.2909112331180894
Validation loss: 2.428672672234522

Epoch: 5| Step: 6
Training loss: 1.9268641647939952
Validation loss: 2.528197835153969

Epoch: 5| Step: 7
Training loss: 1.4556623067042946
Validation loss: 2.5692499720368005

Epoch: 5| Step: 8
Training loss: 1.5007181038149435
Validation loss: 2.579435293596166

Epoch: 5| Step: 9
Training loss: 1.2270661310221767
Validation loss: 2.5465533946002346

Epoch: 5| Step: 10
Training loss: 1.710111235631303
Validation loss: 2.475509329044924

Epoch: 221| Step: 0
Training loss: 2.0784981758232637
Validation loss: 2.432703695312149

Epoch: 5| Step: 1
Training loss: 1.264461689125452
Validation loss: 2.4216930489098525

Epoch: 5| Step: 2
Training loss: 1.218105928478215
Validation loss: 2.4297958701741993

Epoch: 5| Step: 3
Training loss: 1.1777201536215116
Validation loss: 2.44447736839907

Epoch: 5| Step: 4
Training loss: 1.4831949462343634
Validation loss: 2.4898435700602533

Epoch: 5| Step: 5
Training loss: 1.455141370794117
Validation loss: 2.5692848884007815

Epoch: 5| Step: 6
Training loss: 1.403297291396289
Validation loss: 2.567542654693377

Epoch: 5| Step: 7
Training loss: 1.4365958812088986
Validation loss: 2.5820216002059104

Epoch: 5| Step: 8
Training loss: 1.3752074518630961
Validation loss: 2.559532998985338

Epoch: 5| Step: 9
Training loss: 1.508546403549857
Validation loss: 2.5116377451133456

Epoch: 5| Step: 10
Training loss: 1.1487766725185335
Validation loss: 2.4682238272358963

Epoch: 222| Step: 0
Training loss: 1.4717841766261583
Validation loss: 2.4220691117515374

Epoch: 5| Step: 1
Training loss: 1.2248010804736544
Validation loss: 2.385409927484028

Epoch: 5| Step: 2
Training loss: 1.294479916095197
Validation loss: 2.4012416725778505

Epoch: 5| Step: 3
Training loss: 1.7048724248147715
Validation loss: 2.429956435056066

Epoch: 5| Step: 4
Training loss: 1.2932333776267428
Validation loss: 2.5035754477640566

Epoch: 5| Step: 5
Training loss: 1.109507485658854
Validation loss: 2.5745116606563445

Epoch: 5| Step: 6
Training loss: 1.750972681844382
Validation loss: 2.6075233982009207

Epoch: 5| Step: 7
Training loss: 1.6102072036284472
Validation loss: 2.611004583433283

Epoch: 5| Step: 8
Training loss: 1.2089661333374921
Validation loss: 2.5518558982644604

Epoch: 5| Step: 9
Training loss: 1.479929883816728
Validation loss: 2.533816291657456

Epoch: 5| Step: 10
Training loss: 1.4382382860454312
Validation loss: 2.444568477728317

Epoch: 223| Step: 0
Training loss: 1.6794372372155912
Validation loss: 2.4258770751943572

Epoch: 5| Step: 1
Training loss: 1.5431113647995676
Validation loss: 2.4021585802129524

Epoch: 5| Step: 2
Training loss: 1.5719216675400323
Validation loss: 2.416428012824894

Epoch: 5| Step: 3
Training loss: 1.4538475619221174
Validation loss: 2.4834473892263778

Epoch: 5| Step: 4
Training loss: 1.3810901583881547
Validation loss: 2.5126829640792825

Epoch: 5| Step: 5
Training loss: 1.5196728481031174
Validation loss: 2.5445716357574613

Epoch: 5| Step: 6
Training loss: 1.3415960747449271
Validation loss: 2.5780784356619026

Epoch: 5| Step: 7
Training loss: 1.274864707575339
Validation loss: 2.5638349103891773

Epoch: 5| Step: 8
Training loss: 1.3302820976355167
Validation loss: 2.533782851409223

Epoch: 5| Step: 9
Training loss: 1.1272875522662285
Validation loss: 2.5133925748548482

Epoch: 5| Step: 10
Training loss: 1.2731153864771454
Validation loss: 2.4898046174735526

Epoch: 224| Step: 0
Training loss: 1.257879598972117
Validation loss: 2.475982403466049

Epoch: 5| Step: 1
Training loss: 1.7130465115781528
Validation loss: 2.469280620481262

Epoch: 5| Step: 2
Training loss: 1.6254318837139101
Validation loss: 2.463959113487773

Epoch: 5| Step: 3
Training loss: 0.7857810424027668
Validation loss: 2.4720633720247354

Epoch: 5| Step: 4
Training loss: 1.5218719263065326
Validation loss: 2.4614758589059136

Epoch: 5| Step: 5
Training loss: 1.4648295897753085
Validation loss: 2.4655864306484023

Epoch: 5| Step: 6
Training loss: 1.2138757314097444
Validation loss: 2.50613433040698

Epoch: 5| Step: 7
Training loss: 1.5258411714084104
Validation loss: 2.570650087203451

Epoch: 5| Step: 8
Training loss: 1.3019503360218263
Validation loss: 2.587207393777423

Epoch: 5| Step: 9
Training loss: 1.572296104372659
Validation loss: 2.5956744336711113

Epoch: 5| Step: 10
Training loss: 1.1506996970145384
Validation loss: 2.5633320961836716

Epoch: 225| Step: 0
Training loss: 1.5616274113778077
Validation loss: 2.45433294871321

Epoch: 5| Step: 1
Training loss: 1.3295218807226117
Validation loss: 2.3917963936977125

Epoch: 5| Step: 2
Training loss: 1.5800696751164667
Validation loss: 2.3637740326957566

Epoch: 5| Step: 3
Training loss: 1.5922654661606472
Validation loss: 2.376770459567573

Epoch: 5| Step: 4
Training loss: 0.745534517500988
Validation loss: 2.4132235833186724

Epoch: 5| Step: 5
Training loss: 1.3722895871271121
Validation loss: 2.4353605735741137

Epoch: 5| Step: 6
Training loss: 1.5081412001560577
Validation loss: 2.5376961372871247

Epoch: 5| Step: 7
Training loss: 1.196806429101383
Validation loss: 2.5664181391466103

Epoch: 5| Step: 8
Training loss: 1.1700271788317642
Validation loss: 2.623331331616944

Epoch: 5| Step: 9
Training loss: 1.7910243442868115
Validation loss: 2.6209828665827817

Epoch: 5| Step: 10
Training loss: 1.2721259260913604
Validation loss: 2.5777877313555857

Epoch: 226| Step: 0
Training loss: 1.8230984043173153
Validation loss: 2.559119589259634

Epoch: 5| Step: 1
Training loss: 1.2139993167573617
Validation loss: 2.512172930366727

Epoch: 5| Step: 2
Training loss: 1.5692267008983296
Validation loss: 2.46063817201529

Epoch: 5| Step: 3
Training loss: 1.3749819667673997
Validation loss: 2.4260280772136387

Epoch: 5| Step: 4
Training loss: 1.3948978401705012
Validation loss: 2.407597357827269

Epoch: 5| Step: 5
Training loss: 0.991886423642501
Validation loss: 2.3868968562778745

Epoch: 5| Step: 6
Training loss: 1.26024600783618
Validation loss: 2.4220246034925896

Epoch: 5| Step: 7
Training loss: 0.9367466760947489
Validation loss: 2.4574060476187234

Epoch: 5| Step: 8
Training loss: 1.6303295622611527
Validation loss: 2.5417798637575406

Epoch: 5| Step: 9
Training loss: 1.6390837196162034
Validation loss: 2.613374292695364

Epoch: 5| Step: 10
Training loss: 1.1701081243911235
Validation loss: 2.5803251730795216

Epoch: 227| Step: 0
Training loss: 1.2399233931288849
Validation loss: 2.5297021056370403

Epoch: 5| Step: 1
Training loss: 1.4854948939001664
Validation loss: 2.448698783840219

Epoch: 5| Step: 2
Training loss: 1.6918688839596479
Validation loss: 2.4037738264197315

Epoch: 5| Step: 3
Training loss: 1.3688404663010323
Validation loss: 2.3633815856966485

Epoch: 5| Step: 4
Training loss: 1.5060544215446854
Validation loss: 2.3938171813391462

Epoch: 5| Step: 5
Training loss: 1.0342364561297408
Validation loss: 2.4473747228642027

Epoch: 5| Step: 6
Training loss: 1.3959454543598226
Validation loss: 2.4825345842674

Epoch: 5| Step: 7
Training loss: 1.0011731061805065
Validation loss: 2.559581811731678

Epoch: 5| Step: 8
Training loss: 1.5896921296424409
Validation loss: 2.6414912080307364

Epoch: 5| Step: 9
Training loss: 1.712661362445399
Validation loss: 2.656479786845001

Epoch: 5| Step: 10
Training loss: 0.9630577453064161
Validation loss: 2.6651769721187635

Epoch: 228| Step: 0
Training loss: 1.2294257693723727
Validation loss: 2.6161423765027054

Epoch: 5| Step: 1
Training loss: 1.015161848835172
Validation loss: 2.5397216234162343

Epoch: 5| Step: 2
Training loss: 1.8798196519422083
Validation loss: 2.4505847826099227

Epoch: 5| Step: 3
Training loss: 1.0702609307333077
Validation loss: 2.402893612816082

Epoch: 5| Step: 4
Training loss: 1.5731104127240172
Validation loss: 2.3376335483611745

Epoch: 5| Step: 5
Training loss: 1.4781150123952345
Validation loss: 2.32774635259009

Epoch: 5| Step: 6
Training loss: 1.3398731995841044
Validation loss: 2.3827269545674747

Epoch: 5| Step: 7
Training loss: 1.3810730246835854
Validation loss: 2.4636853533090974

Epoch: 5| Step: 8
Training loss: 1.654621547288744
Validation loss: 2.527966229704402

Epoch: 5| Step: 9
Training loss: 1.4309944057875075
Validation loss: 2.544034490060919

Epoch: 5| Step: 10
Training loss: 0.8473684639820039
Validation loss: 2.5204716131972407

Epoch: 229| Step: 0
Training loss: 1.6639943713358902
Validation loss: 2.49038626464787

Epoch: 5| Step: 1
Training loss: 1.3129942281353564
Validation loss: 2.525190692167587

Epoch: 5| Step: 2
Training loss: 1.3201021557350148
Validation loss: 2.4848039333799203

Epoch: 5| Step: 3
Training loss: 1.4777746321629546
Validation loss: 2.4700149030909637

Epoch: 5| Step: 4
Training loss: 0.952898342510715
Validation loss: 2.4643778208073255

Epoch: 5| Step: 5
Training loss: 1.6036018599299822
Validation loss: 2.463338456475814

Epoch: 5| Step: 6
Training loss: 1.4961270560200184
Validation loss: 2.4231699043134034

Epoch: 5| Step: 7
Training loss: 1.4240390950954793
Validation loss: 2.423795254119802

Epoch: 5| Step: 8
Training loss: 0.9679949494419279
Validation loss: 2.4292070013713

Epoch: 5| Step: 9
Training loss: 1.1139838962726458
Validation loss: 2.447234113353017

Epoch: 5| Step: 10
Training loss: 1.2685965045852534
Validation loss: 2.452151578081304

Epoch: 230| Step: 0
Training loss: 1.2733505312938243
Validation loss: 2.4630615568522063

Epoch: 5| Step: 1
Training loss: 1.377371866390362
Validation loss: 2.518250157742935

Epoch: 5| Step: 2
Training loss: 1.2085689884896786
Validation loss: 2.506698506647687

Epoch: 5| Step: 3
Training loss: 1.6453758118884
Validation loss: 2.5405421557493524

Epoch: 5| Step: 4
Training loss: 1.1771328783439015
Validation loss: 2.518009878219389

Epoch: 5| Step: 5
Training loss: 1.3608560934147107
Validation loss: 2.5152500377334306

Epoch: 5| Step: 6
Training loss: 1.4475083450050479
Validation loss: 2.442292485526702

Epoch: 5| Step: 7
Training loss: 1.2807555291233155
Validation loss: 2.410136299491492

Epoch: 5| Step: 8
Training loss: 1.3618677894853075
Validation loss: 2.4046062602534946

Epoch: 5| Step: 9
Training loss: 1.6533206009118178
Validation loss: 2.4193224456628433

Epoch: 5| Step: 10
Training loss: 0.5800538234565279
Validation loss: 2.430997394847769

Epoch: 231| Step: 0
Training loss: 1.2293154685690417
Validation loss: 2.471789389291258

Epoch: 5| Step: 1
Training loss: 1.5682796396245515
Validation loss: 2.4732082346793876

Epoch: 5| Step: 2
Training loss: 1.5730929075960374
Validation loss: 2.454607734202184

Epoch: 5| Step: 3
Training loss: 1.0507484629454389
Validation loss: 2.462330736475219

Epoch: 5| Step: 4
Training loss: 1.014067644244343
Validation loss: 2.4695260783056403

Epoch: 5| Step: 5
Training loss: 1.6733055055566355
Validation loss: 2.494127409700653

Epoch: 5| Step: 6
Training loss: 1.270079978316882
Validation loss: 2.519435315580412

Epoch: 5| Step: 7
Training loss: 1.3460787621193402
Validation loss: 2.5178830292711036

Epoch: 5| Step: 8
Training loss: 1.3210480576638188
Validation loss: 2.5310138980688115

Epoch: 5| Step: 9
Training loss: 0.9253892994360329
Validation loss: 2.5423245404835626

Epoch: 5| Step: 10
Training loss: 1.4065720507287554
Validation loss: 2.5297113398669455

Epoch: 232| Step: 0
Training loss: 1.0250317336031571
Validation loss: 2.5510023123317187

Epoch: 5| Step: 1
Training loss: 1.4297174335952358
Validation loss: 2.574778816869974

Epoch: 5| Step: 2
Training loss: 1.4780803326880276
Validation loss: 2.568809650661589

Epoch: 5| Step: 3
Training loss: 0.9264912518388324
Validation loss: 2.529983487240491

Epoch: 5| Step: 4
Training loss: 1.499399223815709
Validation loss: 2.510798315027265

Epoch: 5| Step: 5
Training loss: 1.6818156400516058
Validation loss: 2.4977588585824098

Epoch: 5| Step: 6
Training loss: 1.2920730115733894
Validation loss: 2.418248072523559

Epoch: 5| Step: 7
Training loss: 1.428881475318304
Validation loss: 2.4198677618215987

Epoch: 5| Step: 8
Training loss: 1.230575702197102
Validation loss: 2.439318905652154

Epoch: 5| Step: 9
Training loss: 0.9927113569333015
Validation loss: 2.4689806135615795

Epoch: 5| Step: 10
Training loss: 1.245516173819355
Validation loss: 2.465042481976042

Epoch: 233| Step: 0
Training loss: 1.219097625844385
Validation loss: 2.538525555979929

Epoch: 5| Step: 1
Training loss: 1.7135523493316878
Validation loss: 2.5779856773758936

Epoch: 5| Step: 2
Training loss: 1.5268113557196874
Validation loss: 2.569791495969554

Epoch: 5| Step: 3
Training loss: 0.8197741967504447
Validation loss: 2.5271486543467

Epoch: 5| Step: 4
Training loss: 1.6681410546385986
Validation loss: 2.4408353824765334

Epoch: 5| Step: 5
Training loss: 0.9503831667907304
Validation loss: 2.3727556590192656

Epoch: 5| Step: 6
Training loss: 1.257435522986035
Validation loss: 2.3645243317293447

Epoch: 5| Step: 7
Training loss: 0.9304731239196826
Validation loss: 2.3832793586855714

Epoch: 5| Step: 8
Training loss: 1.57680017742096
Validation loss: 2.408753046619984

Epoch: 5| Step: 9
Training loss: 1.4580556423469613
Validation loss: 2.4399738006187146

Epoch: 5| Step: 10
Training loss: 0.8729652178849756
Validation loss: 2.513253822516037

Epoch: 234| Step: 0
Training loss: 1.1585295604742574
Validation loss: 2.5806271152160187

Epoch: 5| Step: 1
Training loss: 1.1668898788999178
Validation loss: 2.608743301923807

Epoch: 5| Step: 2
Training loss: 0.9532303986353655
Validation loss: 2.5815323871214515

Epoch: 5| Step: 3
Training loss: 1.3231766913276466
Validation loss: 2.525839189424307

Epoch: 5| Step: 4
Training loss: 1.6144532756311554
Validation loss: 2.511034284011666

Epoch: 5| Step: 5
Training loss: 1.400558951036358
Validation loss: 2.4669175507930854

Epoch: 5| Step: 6
Training loss: 1.476798063995233
Validation loss: 2.42996062451726

Epoch: 5| Step: 7
Training loss: 1.3547698316007781
Validation loss: 2.394400259954918

Epoch: 5| Step: 8
Training loss: 1.3491940777173366
Validation loss: 2.3792691054650734

Epoch: 5| Step: 9
Training loss: 1.3126039009748875
Validation loss: 2.3901161570800387

Epoch: 5| Step: 10
Training loss: 1.0912413574261037
Validation loss: 2.392499584041475

Epoch: 235| Step: 0
Training loss: 1.4388317076336083
Validation loss: 2.41215817499801

Epoch: 5| Step: 1
Training loss: 1.3087211433005643
Validation loss: 2.498753504562364

Epoch: 5| Step: 2
Training loss: 1.1322928453501884
Validation loss: 2.5449593211444856

Epoch: 5| Step: 3
Training loss: 1.1238699111356558
Validation loss: 2.5907293789631747

Epoch: 5| Step: 4
Training loss: 1.1545897756062051
Validation loss: 2.5961485475721506

Epoch: 5| Step: 5
Training loss: 1.3523258853748314
Validation loss: 2.552887672576422

Epoch: 5| Step: 6
Training loss: 1.429068175871201
Validation loss: 2.4593575240160033

Epoch: 5| Step: 7
Training loss: 1.1654107395458284
Validation loss: 2.398813551490054

Epoch: 5| Step: 8
Training loss: 1.424883081424785
Validation loss: 2.3815150071180056

Epoch: 5| Step: 9
Training loss: 1.6924686046939705
Validation loss: 2.351247643001629

Epoch: 5| Step: 10
Training loss: 0.9574536072769194
Validation loss: 2.397956894320584

Epoch: 236| Step: 0
Training loss: 0.8056422375121518
Validation loss: 2.4296015347781905

Epoch: 5| Step: 1
Training loss: 1.0096327437840265
Validation loss: 2.490255435964729

Epoch: 5| Step: 2
Training loss: 1.5780499128853223
Validation loss: 2.5591443618270047

Epoch: 5| Step: 3
Training loss: 1.389497364059534
Validation loss: 2.638196472735492

Epoch: 5| Step: 4
Training loss: 1.7071876716089973
Validation loss: 2.6612141143972288

Epoch: 5| Step: 5
Training loss: 1.5964595724614845
Validation loss: 2.678353996143804

Epoch: 5| Step: 6
Training loss: 1.149176016297641
Validation loss: 2.598879531065835

Epoch: 5| Step: 7
Training loss: 0.9834374701321442
Validation loss: 2.5357693811264754

Epoch: 5| Step: 8
Training loss: 0.9191252869681185
Validation loss: 2.475555555783353

Epoch: 5| Step: 9
Training loss: 1.5199552204412492
Validation loss: 2.38468465837004

Epoch: 5| Step: 10
Training loss: 1.1549999593759506
Validation loss: 2.367033422315568

Epoch: 237| Step: 0
Training loss: 1.012866396601347
Validation loss: 2.389263916538956

Epoch: 5| Step: 1
Training loss: 1.0793950436955944
Validation loss: 2.4426011272913994

Epoch: 5| Step: 2
Training loss: 1.278049845456234
Validation loss: 2.50585914174266

Epoch: 5| Step: 3
Training loss: 1.1097036600185077
Validation loss: 2.5442826771260787

Epoch: 5| Step: 4
Training loss: 1.8094753151923026
Validation loss: 2.560426921435625

Epoch: 5| Step: 5
Training loss: 0.9739857668081473
Validation loss: 2.57581911802897

Epoch: 5| Step: 6
Training loss: 1.3863328853556618
Validation loss: 2.5215101039553627

Epoch: 5| Step: 7
Training loss: 1.3141426524643363
Validation loss: 2.498621080415422

Epoch: 5| Step: 8
Training loss: 1.1402469165160631
Validation loss: 2.4245391101990994

Epoch: 5| Step: 9
Training loss: 1.0679843948881507
Validation loss: 2.402774761788516

Epoch: 5| Step: 10
Training loss: 1.68931136225589
Validation loss: 2.398314806599175

Epoch: 238| Step: 0
Training loss: 1.2616973024795235
Validation loss: 2.42243484023045

Epoch: 5| Step: 1
Training loss: 0.971682570563405
Validation loss: 2.497012180316452

Epoch: 5| Step: 2
Training loss: 1.187362612757577
Validation loss: 2.5248737540819453

Epoch: 5| Step: 3
Training loss: 1.212244718754507
Validation loss: 2.5627767301892974

Epoch: 5| Step: 4
Training loss: 1.4060431434230574
Validation loss: 2.6257451099123084

Epoch: 5| Step: 5
Training loss: 1.1259713747644478
Validation loss: 2.5779197379965826

Epoch: 5| Step: 6
Training loss: 1.2226570787518407
Validation loss: 2.536164219302104

Epoch: 5| Step: 7
Training loss: 1.3223640709521034
Validation loss: 2.521413165041279

Epoch: 5| Step: 8
Training loss: 1.2061180932061406
Validation loss: 2.5162150657123834

Epoch: 5| Step: 9
Training loss: 1.7205605420760337
Validation loss: 2.4605100678187344

Epoch: 5| Step: 10
Training loss: 1.0282359727143382
Validation loss: 2.475890275697844

Epoch: 239| Step: 0
Training loss: 1.198495553611175
Validation loss: 2.4664520881923098

Epoch: 5| Step: 1
Training loss: 1.3250582124410315
Validation loss: 2.4764735377106497

Epoch: 5| Step: 2
Training loss: 1.0655496251808945
Validation loss: 2.4890986201669767

Epoch: 5| Step: 3
Training loss: 1.1525079642494391
Validation loss: 2.5037240603976834

Epoch: 5| Step: 4
Training loss: 0.831094061773808
Validation loss: 2.5225897351379625

Epoch: 5| Step: 5
Training loss: 1.4209018772778381
Validation loss: 2.560478407460182

Epoch: 5| Step: 6
Training loss: 1.2314618659362737
Validation loss: 2.5572952734297703

Epoch: 5| Step: 7
Training loss: 0.9808186974212671
Validation loss: 2.558562097492205

Epoch: 5| Step: 8
Training loss: 1.5355767603537365
Validation loss: 2.56687852002222

Epoch: 5| Step: 9
Training loss: 1.4578293974163903
Validation loss: 2.4780366127741593

Epoch: 5| Step: 10
Training loss: 1.3300881630494932
Validation loss: 2.4505186900961324

Epoch: 240| Step: 0
Training loss: 1.0089451538922332
Validation loss: 2.395480270016379

Epoch: 5| Step: 1
Training loss: 1.4888059637279252
Validation loss: 2.38945548254305

Epoch: 5| Step: 2
Training loss: 1.4086204471269135
Validation loss: 2.3902489118826447

Epoch: 5| Step: 3
Training loss: 1.351070468843617
Validation loss: 2.428401552246947

Epoch: 5| Step: 4
Training loss: 0.9882140004795081
Validation loss: 2.450801625135479

Epoch: 5| Step: 5
Training loss: 1.2510635619691894
Validation loss: 2.4868098564652286

Epoch: 5| Step: 6
Training loss: 1.7370795392990617
Validation loss: 2.4941632389622446

Epoch: 5| Step: 7
Training loss: 0.6627290239874681
Validation loss: 2.531929363486722

Epoch: 5| Step: 8
Training loss: 1.3619618849329564
Validation loss: 2.6033074278543933

Epoch: 5| Step: 9
Training loss: 0.8566283983992304
Validation loss: 2.5938100717672237

Epoch: 5| Step: 10
Training loss: 1.1345146282424776
Validation loss: 2.5190042132578365

Epoch: 241| Step: 0
Training loss: 1.2445869064577753
Validation loss: 2.4824332451941804

Epoch: 5| Step: 1
Training loss: 1.6182063482235225
Validation loss: 2.4499021184126915

Epoch: 5| Step: 2
Training loss: 1.3486668874536454
Validation loss: 2.401545740327509

Epoch: 5| Step: 3
Training loss: 1.4101299589881644
Validation loss: 2.4038156235162567

Epoch: 5| Step: 4
Training loss: 0.9417165347766788
Validation loss: 2.4484444657737283

Epoch: 5| Step: 5
Training loss: 1.0999615445784419
Validation loss: 2.480374000295787

Epoch: 5| Step: 6
Training loss: 1.3725901206191131
Validation loss: 2.511178764709405

Epoch: 5| Step: 7
Training loss: 1.4242496154420377
Validation loss: 2.5408358238881545

Epoch: 5| Step: 8
Training loss: 1.0276010865469682
Validation loss: 2.5374692480880054

Epoch: 5| Step: 9
Training loss: 0.8693217228156065
Validation loss: 2.539040841766699

Epoch: 5| Step: 10
Training loss: 0.8388574886094399
Validation loss: 2.5642564537867396

Epoch: 242| Step: 0
Training loss: 1.194300004569843
Validation loss: 2.5322400183485647

Epoch: 5| Step: 1
Training loss: 0.9254830761479638
Validation loss: 2.504240393981834

Epoch: 5| Step: 2
Training loss: 1.5574473512669325
Validation loss: 2.453246585530904

Epoch: 5| Step: 3
Training loss: 1.1737750100100723
Validation loss: 2.4542501641342658

Epoch: 5| Step: 4
Training loss: 1.333446433316996
Validation loss: 2.454208342777048

Epoch: 5| Step: 5
Training loss: 1.153854724350913
Validation loss: 2.443230969223542

Epoch: 5| Step: 6
Training loss: 0.9347678108365127
Validation loss: 2.44536739516952

Epoch: 5| Step: 7
Training loss: 0.701341358836323
Validation loss: 2.4822584637564007

Epoch: 5| Step: 8
Training loss: 1.5738537083542081
Validation loss: 2.511777182784

Epoch: 5| Step: 9
Training loss: 1.1864625514856677
Validation loss: 2.577295029914565

Epoch: 5| Step: 10
Training loss: 1.3045938423941266
Validation loss: 2.5966923660728813

Epoch: 243| Step: 0
Training loss: 1.5249124282957849
Validation loss: 2.5843414327077747

Epoch: 5| Step: 1
Training loss: 1.1165468206193563
Validation loss: 2.5889768401587574

Epoch: 5| Step: 2
Training loss: 1.1676587870440236
Validation loss: 2.5317957897499492

Epoch: 5| Step: 3
Training loss: 1.389914341764055
Validation loss: 2.5186253054634706

Epoch: 5| Step: 4
Training loss: 1.1011523301527109
Validation loss: 2.4696739309017666

Epoch: 5| Step: 5
Training loss: 0.7903068852404292
Validation loss: 2.4368061943008437

Epoch: 5| Step: 6
Training loss: 1.0250422585312775
Validation loss: 2.4583192376145804

Epoch: 5| Step: 7
Training loss: 1.2752430758921136
Validation loss: 2.434524281591816

Epoch: 5| Step: 8
Training loss: 1.3593476391373622
Validation loss: 2.4575978954123516

Epoch: 5| Step: 9
Training loss: 1.0135323900750293
Validation loss: 2.482991643535175

Epoch: 5| Step: 10
Training loss: 1.3019455290034
Validation loss: 2.5553819110806675

Epoch: 244| Step: 0
Training loss: 1.2232316098463158
Validation loss: 2.523458742030538

Epoch: 5| Step: 1
Training loss: 1.3500962876490576
Validation loss: 2.5127739846867008

Epoch: 5| Step: 2
Training loss: 1.1944167327376936
Validation loss: 2.4942139662232674

Epoch: 5| Step: 3
Training loss: 1.0733830756059906
Validation loss: 2.5010000156676924

Epoch: 5| Step: 4
Training loss: 0.9257672465750153
Validation loss: 2.532071189903158

Epoch: 5| Step: 5
Training loss: 1.3287040794382858
Validation loss: 2.5167782126876124

Epoch: 5| Step: 6
Training loss: 1.0060718497143828
Validation loss: 2.484560610193574

Epoch: 5| Step: 7
Training loss: 1.1678978123380859
Validation loss: 2.4871467735294166

Epoch: 5| Step: 8
Training loss: 1.5344961363295375
Validation loss: 2.4738684393845283

Epoch: 5| Step: 9
Training loss: 0.9437408623663531
Validation loss: 2.491533693913957

Epoch: 5| Step: 10
Training loss: 1.1579454724019929
Validation loss: 2.486952133474183

Epoch: 245| Step: 0
Training loss: 1.0952989237293593
Validation loss: 2.5195468223874653

Epoch: 5| Step: 1
Training loss: 1.422396302290059
Validation loss: 2.488886891570928

Epoch: 5| Step: 2
Training loss: 1.0161313481995442
Validation loss: 2.5120331401235223

Epoch: 5| Step: 3
Training loss: 1.184294792015931
Validation loss: 2.492572710549099

Epoch: 5| Step: 4
Training loss: 0.6127223973463589
Validation loss: 2.489651307369003

Epoch: 5| Step: 5
Training loss: 1.5935490799459342
Validation loss: 2.517354595971272

Epoch: 5| Step: 6
Training loss: 1.0657022129399183
Validation loss: 2.570237317559584

Epoch: 5| Step: 7
Training loss: 0.9969663500411229
Validation loss: 2.5925342266930724

Epoch: 5| Step: 8
Training loss: 1.1920821477054557
Validation loss: 2.568205711234396

Epoch: 5| Step: 9
Training loss: 1.1010207338728215
Validation loss: 2.6033831481287244

Epoch: 5| Step: 10
Training loss: 1.4017611172559927
Validation loss: 2.520552934269098

Epoch: 246| Step: 0
Training loss: 1.200491562139623
Validation loss: 2.4674306999374522

Epoch: 5| Step: 1
Training loss: 1.164683848202085
Validation loss: 2.453137308579324

Epoch: 5| Step: 2
Training loss: 1.1560307372174585
Validation loss: 2.4463631057889446

Epoch: 5| Step: 3
Training loss: 0.6912626774748063
Validation loss: 2.4301455570813024

Epoch: 5| Step: 4
Training loss: 1.5686261435928692
Validation loss: 2.4583956277948587

Epoch: 5| Step: 5
Training loss: 1.482703140776404
Validation loss: 2.478625040787411

Epoch: 5| Step: 6
Training loss: 1.1675416809908292
Validation loss: 2.526198809883943

Epoch: 5| Step: 7
Training loss: 1.1645162837199092
Validation loss: 2.5766090567509687

Epoch: 5| Step: 8
Training loss: 1.0758883177113716
Validation loss: 2.5682065068175772

Epoch: 5| Step: 9
Training loss: 0.9176990518667097
Validation loss: 2.557800420470151

Epoch: 5| Step: 10
Training loss: 1.0446047292698337
Validation loss: 2.531928147444447

Epoch: 247| Step: 0
Training loss: 1.2529019050164103
Validation loss: 2.5230643856511894

Epoch: 5| Step: 1
Training loss: 0.919191171510263
Validation loss: 2.474781240874149

Epoch: 5| Step: 2
Training loss: 0.9997096534270552
Validation loss: 2.4521051662783893

Epoch: 5| Step: 3
Training loss: 1.3025135041779716
Validation loss: 2.4741476535517997

Epoch: 5| Step: 4
Training loss: 0.9375957757982425
Validation loss: 2.502312736926959

Epoch: 5| Step: 5
Training loss: 1.005326272373885
Validation loss: 2.505701821090095

Epoch: 5| Step: 6
Training loss: 1.2999260184437897
Validation loss: 2.5398089577664775

Epoch: 5| Step: 7
Training loss: 1.133690802680545
Validation loss: 2.53541529008438

Epoch: 5| Step: 8
Training loss: 0.6738252501495512
Validation loss: 2.489609275954214

Epoch: 5| Step: 9
Training loss: 1.8142503639484706
Validation loss: 2.5270633648804215

Epoch: 5| Step: 10
Training loss: 0.9949162723067488
Validation loss: 2.527310535776707

Epoch: 248| Step: 0
Training loss: 1.0623077891901194
Validation loss: 2.534163952629093

Epoch: 5| Step: 1
Training loss: 1.2120133573689924
Validation loss: 2.5251420826524913

Epoch: 5| Step: 2
Training loss: 1.0414763785442926
Validation loss: 2.545999867460203

Epoch: 5| Step: 3
Training loss: 1.0129920870405047
Validation loss: 2.5413236166312876

Epoch: 5| Step: 4
Training loss: 1.2869075912194776
Validation loss: 2.5375265585111983

Epoch: 5| Step: 5
Training loss: 1.459868422418869
Validation loss: 2.514458590416863

Epoch: 5| Step: 6
Training loss: 0.8603790659843735
Validation loss: 2.5326059655145476

Epoch: 5| Step: 7
Training loss: 0.8912814214231509
Validation loss: 2.4950921984468066

Epoch: 5| Step: 8
Training loss: 1.2013450435705588
Validation loss: 2.472705724383521

Epoch: 5| Step: 9
Training loss: 1.0810318611030152
Validation loss: 2.461145400357792

Epoch: 5| Step: 10
Training loss: 1.3319873522911219
Validation loss: 2.453576952312733

Epoch: 249| Step: 0
Training loss: 1.2509265326829901
Validation loss: 2.422876989779901

Epoch: 5| Step: 1
Training loss: 1.4763092954195565
Validation loss: 2.4134020227231496

Epoch: 5| Step: 2
Training loss: 1.272999179036729
Validation loss: 2.4598042853291138

Epoch: 5| Step: 3
Training loss: 0.9324005354639592
Validation loss: 2.4934994403742063

Epoch: 5| Step: 4
Training loss: 0.6927991080979317
Validation loss: 2.54247725169456

Epoch: 5| Step: 5
Training loss: 1.0559148922746937
Validation loss: 2.56482481825475

Epoch: 5| Step: 6
Training loss: 1.025887911873698
Validation loss: 2.5383605643056235

Epoch: 5| Step: 7
Training loss: 1.1465478518848142
Validation loss: 2.540654076717596

Epoch: 5| Step: 8
Training loss: 0.9682772929006238
Validation loss: 2.4826239541086426

Epoch: 5| Step: 9
Training loss: 1.150873209276046
Validation loss: 2.4511946061302763

Epoch: 5| Step: 10
Training loss: 1.406967658131427
Validation loss: 2.4301724640523132

Epoch: 250| Step: 0
Training loss: 0.9843601649544033
Validation loss: 2.43811443063749

Epoch: 5| Step: 1
Training loss: 0.9097946824068286
Validation loss: 2.4685921151872545

Epoch: 5| Step: 2
Training loss: 1.5166430642663444
Validation loss: 2.4789985199185294

Epoch: 5| Step: 3
Training loss: 0.6711165338807493
Validation loss: 2.5352590754220965

Epoch: 5| Step: 4
Training loss: 1.0903291885878752
Validation loss: 2.585725142153962

Epoch: 5| Step: 5
Training loss: 0.9757552816143957
Validation loss: 2.584573885170072

Epoch: 5| Step: 6
Training loss: 1.4142943134294146
Validation loss: 2.54724570754176

Epoch: 5| Step: 7
Training loss: 0.9453563207132472
Validation loss: 2.484435704204802

Epoch: 5| Step: 8
Training loss: 1.3940185117162864
Validation loss: 2.470189491211617

Epoch: 5| Step: 9
Training loss: 1.2526384165225883
Validation loss: 2.439512231549592

Epoch: 5| Step: 10
Training loss: 1.0125947201539371
Validation loss: 2.4284920855275396

Epoch: 251| Step: 0
Training loss: 1.1173082833255077
Validation loss: 2.3853301219624288

Epoch: 5| Step: 1
Training loss: 1.2391386222787095
Validation loss: 2.433686046291695

Epoch: 5| Step: 2
Training loss: 1.4776758104215404
Validation loss: 2.528036898118487

Epoch: 5| Step: 3
Training loss: 0.8316401964063781
Validation loss: 2.567791131954004

Epoch: 5| Step: 4
Training loss: 0.715385606862084
Validation loss: 2.60626982852049

Epoch: 5| Step: 5
Training loss: 1.3039136407550145
Validation loss: 2.6352187067777306

Epoch: 5| Step: 6
Training loss: 1.1359448502209648
Validation loss: 2.624588503913166

Epoch: 5| Step: 7
Training loss: 0.9857510228646351
Validation loss: 2.591744651039238

Epoch: 5| Step: 8
Training loss: 1.1423428806807223
Validation loss: 2.4944976592980224

Epoch: 5| Step: 9
Training loss: 1.249085377819368
Validation loss: 2.4269788774953622

Epoch: 5| Step: 10
Training loss: 1.0928665953226493
Validation loss: 2.3553688826606884

Epoch: 252| Step: 0
Training loss: 0.879269944282308
Validation loss: 2.3493715555844696

Epoch: 5| Step: 1
Training loss: 0.8087777928053359
Validation loss: 2.3567359473479725

Epoch: 5| Step: 2
Training loss: 1.4166628706638116
Validation loss: 2.4077457136326372

Epoch: 5| Step: 3
Training loss: 1.3400945400935524
Validation loss: 2.4648426891157103

Epoch: 5| Step: 4
Training loss: 1.052779555899383
Validation loss: 2.5372576724493694

Epoch: 5| Step: 5
Training loss: 0.873194944383155
Validation loss: 2.6172941129541303

Epoch: 5| Step: 6
Training loss: 0.9707141775810657
Validation loss: 2.613718294118203

Epoch: 5| Step: 7
Training loss: 1.1516512066695477
Validation loss: 2.579638239706848

Epoch: 5| Step: 8
Training loss: 1.6442628038814688
Validation loss: 2.5580632226882742

Epoch: 5| Step: 9
Training loss: 1.1658269835038553
Validation loss: 2.5407594897227326

Epoch: 5| Step: 10
Training loss: 0.6300821151654353
Validation loss: 2.5314059448110346

Epoch: 253| Step: 0
Training loss: 1.529784454920243
Validation loss: 2.4871238958021324

Epoch: 5| Step: 1
Training loss: 1.12714028746336
Validation loss: 2.500943097278037

Epoch: 5| Step: 2
Training loss: 1.0241955577747301
Validation loss: 2.461678163035025

Epoch: 5| Step: 3
Training loss: 1.0790618474910298
Validation loss: 2.455355683757645

Epoch: 5| Step: 4
Training loss: 1.0257472989230163
Validation loss: 2.475029674910227

Epoch: 5| Step: 5
Training loss: 1.4388283107202549
Validation loss: 2.455090698937809

Epoch: 5| Step: 6
Training loss: 1.0341459130093398
Validation loss: 2.4411743568465387

Epoch: 5| Step: 7
Training loss: 0.9217774937675347
Validation loss: 2.4756056691575683

Epoch: 5| Step: 8
Training loss: 0.8469852657252559
Validation loss: 2.4579427331289816

Epoch: 5| Step: 9
Training loss: 0.9935603818585899
Validation loss: 2.4605204535986003

Epoch: 5| Step: 10
Training loss: 1.0914930763741495
Validation loss: 2.514420086959933

Epoch: 254| Step: 0
Training loss: 1.217588066425192
Validation loss: 2.5545859674018363

Epoch: 5| Step: 1
Training loss: 0.8733226502713936
Validation loss: 2.569697527702426

Epoch: 5| Step: 2
Training loss: 1.735383711277195
Validation loss: 2.5377126069097256

Epoch: 5| Step: 3
Training loss: 0.7556143666695341
Validation loss: 2.5210916286323206

Epoch: 5| Step: 4
Training loss: 0.7566012898600769
Validation loss: 2.5691725891853303

Epoch: 5| Step: 5
Training loss: 1.0175275735141693
Validation loss: 2.5067221230939927

Epoch: 5| Step: 6
Training loss: 1.059172243503282
Validation loss: 2.501929591620898

Epoch: 5| Step: 7
Training loss: 1.1545334523518525
Validation loss: 2.4422601035434917

Epoch: 5| Step: 8
Training loss: 1.2354796090691498
Validation loss: 2.4061103740870733

Epoch: 5| Step: 9
Training loss: 0.7168820198067919
Validation loss: 2.385464158162845

Epoch: 5| Step: 10
Training loss: 1.2191674911242445
Validation loss: 2.4151648602894635

Epoch: 255| Step: 0
Training loss: 1.2536623233248965
Validation loss: 2.4551438024000993

Epoch: 5| Step: 1
Training loss: 0.3126587583678596
Validation loss: 2.502945279699825

Epoch: 5| Step: 2
Training loss: 0.9065572941133234
Validation loss: 2.5461873446618855

Epoch: 5| Step: 3
Training loss: 0.6664354449872528
Validation loss: 2.5693517563086363

Epoch: 5| Step: 4
Training loss: 1.35419864127728
Validation loss: 2.5598842957873957

Epoch: 5| Step: 5
Training loss: 1.2967822489834933
Validation loss: 2.5846458683849747

Epoch: 5| Step: 6
Training loss: 1.2216532923151522
Validation loss: 2.5244544532048394

Epoch: 5| Step: 7
Training loss: 0.9345078083689766
Validation loss: 2.4581569784266297

Epoch: 5| Step: 8
Training loss: 1.5478535649139256
Validation loss: 2.4250483887469456

Epoch: 5| Step: 9
Training loss: 1.1126010891708975
Validation loss: 2.4178429083000967

Epoch: 5| Step: 10
Training loss: 0.6718681468170539
Validation loss: 2.4378395038703484

Epoch: 256| Step: 0
Training loss: 0.7985708853132163
Validation loss: 2.4738176773232627

Epoch: 5| Step: 1
Training loss: 0.9060384569237692
Validation loss: 2.5134756263415357

Epoch: 5| Step: 2
Training loss: 1.173701122350937
Validation loss: 2.5025691121648093

Epoch: 5| Step: 3
Training loss: 0.9763116438058296
Validation loss: 2.5107690491250527

Epoch: 5| Step: 4
Training loss: 0.9474263792197486
Validation loss: 2.473294618409318

Epoch: 5| Step: 5
Training loss: 0.9200837464673844
Validation loss: 2.485636807511646

Epoch: 5| Step: 6
Training loss: 0.8636876181173074
Validation loss: 2.4912003194908827

Epoch: 5| Step: 7
Training loss: 1.4888811479354598
Validation loss: 2.475766147948045

Epoch: 5| Step: 8
Training loss: 1.041269296510821
Validation loss: 2.510259002880095

Epoch: 5| Step: 9
Training loss: 1.2656364440400572
Validation loss: 2.4724481344691673

Epoch: 5| Step: 10
Training loss: 1.3021207219160036
Validation loss: 2.478907982089054

Epoch: 257| Step: 0
Training loss: 0.795446499251258
Validation loss: 2.4513396927947464

Epoch: 5| Step: 1
Training loss: 1.3845517702242673
Validation loss: 2.4403322843645494

Epoch: 5| Step: 2
Training loss: 1.3998653858044399
Validation loss: 2.4161597852914163

Epoch: 5| Step: 3
Training loss: 0.8581025152740583
Validation loss: 2.437421376212137

Epoch: 5| Step: 4
Training loss: 1.259057228757154
Validation loss: 2.4852714590295384

Epoch: 5| Step: 5
Training loss: 0.8617066051357057
Validation loss: 2.523306821360709

Epoch: 5| Step: 6
Training loss: 0.5386510744013845
Validation loss: 2.626464104125036

Epoch: 5| Step: 7
Training loss: 0.6933568390276026
Validation loss: 2.616484824511875

Epoch: 5| Step: 8
Training loss: 1.2667764676756124
Validation loss: 2.651489158799152

Epoch: 5| Step: 9
Training loss: 1.3131144311580354
Validation loss: 2.633985759763109

Epoch: 5| Step: 10
Training loss: 0.8963655214331198
Validation loss: 2.5857805066184296

Epoch: 258| Step: 0
Training loss: 1.3617598124193107
Validation loss: 2.483206976606187

Epoch: 5| Step: 1
Training loss: 0.9589671271301693
Validation loss: 2.4531410200563775

Epoch: 5| Step: 2
Training loss: 0.8580042223526357
Validation loss: 2.438923191254119

Epoch: 5| Step: 3
Training loss: 0.894541711204694
Validation loss: 2.412952285018575

Epoch: 5| Step: 4
Training loss: 1.75327410276374
Validation loss: 2.3758723864713702

Epoch: 5| Step: 5
Training loss: 0.8092018089428838
Validation loss: 2.417755113804504

Epoch: 5| Step: 6
Training loss: 0.7728572171389754
Validation loss: 2.4600154505575538

Epoch: 5| Step: 7
Training loss: 1.3849044751713857
Validation loss: 2.490432398477062

Epoch: 5| Step: 8
Training loss: 0.6508916580313242
Validation loss: 2.5376274047805834

Epoch: 5| Step: 9
Training loss: 0.8509397767113899
Validation loss: 2.5959981937058028

Epoch: 5| Step: 10
Training loss: 0.9362967080458184
Validation loss: 2.5947692198945056

Epoch: 259| Step: 0
Training loss: 0.975816670760644
Validation loss: 2.575542572831224

Epoch: 5| Step: 1
Training loss: 1.2786538874209992
Validation loss: 2.535692908595836

Epoch: 5| Step: 2
Training loss: 0.878228226971379
Validation loss: 2.4705063395497304

Epoch: 5| Step: 3
Training loss: 0.9053795020920966
Validation loss: 2.398274635716826

Epoch: 5| Step: 4
Training loss: 0.9726944268635719
Validation loss: 2.373626551488718

Epoch: 5| Step: 5
Training loss: 1.1327534101136418
Validation loss: 2.381768395780637

Epoch: 5| Step: 6
Training loss: 1.620406848658334
Validation loss: 2.450514154977717

Epoch: 5| Step: 7
Training loss: 0.8671322710475582
Validation loss: 2.552514773363415

Epoch: 5| Step: 8
Training loss: 0.929000889454345
Validation loss: 2.7155085990963967

Epoch: 5| Step: 9
Training loss: 1.2385325372400626
Validation loss: 2.6699996360682388

Epoch: 5| Step: 10
Training loss: 0.7486389446529892
Validation loss: 2.560279782763895

Epoch: 260| Step: 0
Training loss: 1.0347155514586701
Validation loss: 2.474788219762757

Epoch: 5| Step: 1
Training loss: 0.915904544691682
Validation loss: 2.403821785676308

Epoch: 5| Step: 2
Training loss: 1.1725660194078604
Validation loss: 2.3697582326804794

Epoch: 5| Step: 3
Training loss: 1.039994015859847
Validation loss: 2.3544652867238143

Epoch: 5| Step: 4
Training loss: 0.8758109966470159
Validation loss: 2.3865693159036856

Epoch: 5| Step: 5
Training loss: 1.1257909007985727
Validation loss: 2.4285907520758734

Epoch: 5| Step: 6
Training loss: 1.1755861139432031
Validation loss: 2.4514553678613176

Epoch: 5| Step: 7
Training loss: 0.804451583797108
Validation loss: 2.519663771711556

Epoch: 5| Step: 8
Training loss: 0.8593630356389275
Validation loss: 2.5529063307686544

Epoch: 5| Step: 9
Training loss: 1.2908089107241327
Validation loss: 2.5401008082041696

Epoch: 5| Step: 10
Training loss: 1.3102433468570232
Validation loss: 2.5655926515949226

Epoch: 261| Step: 0
Training loss: 1.315454065087081
Validation loss: 2.528594272318025

Epoch: 5| Step: 1
Training loss: 1.1317524652911368
Validation loss: 2.46435602270356

Epoch: 5| Step: 2
Training loss: 1.0315887010558313
Validation loss: 2.467640164291673

Epoch: 5| Step: 3
Training loss: 0.797972353659508
Validation loss: 2.477452031012411

Epoch: 5| Step: 4
Training loss: 1.2147003776116954
Validation loss: 2.4714737567389458

Epoch: 5| Step: 5
Training loss: 0.8276423001171501
Validation loss: 2.485939044863869

Epoch: 5| Step: 6
Training loss: 1.1485197076763196
Validation loss: 2.4920026049859993

Epoch: 5| Step: 7
Training loss: 1.1133432471429745
Validation loss: 2.4932053347763317

Epoch: 5| Step: 8
Training loss: 0.619200453891021
Validation loss: 2.509720392028243

Epoch: 5| Step: 9
Training loss: 1.099615771205587
Validation loss: 2.4857498588285036

Epoch: 5| Step: 10
Training loss: 0.9792260429289703
Validation loss: 2.5319967582487615

Epoch: 262| Step: 0
Training loss: 1.0155143677537
Validation loss: 2.5111449443935943

Epoch: 5| Step: 1
Training loss: 1.092965525908006
Validation loss: 2.5319377694515692

Epoch: 5| Step: 2
Training loss: 1.1956264108588692
Validation loss: 2.542304905144945

Epoch: 5| Step: 3
Training loss: 1.1655409468139466
Validation loss: 2.527142039174919

Epoch: 5| Step: 4
Training loss: 1.079041188480061
Validation loss: 2.5080075011024325

Epoch: 5| Step: 5
Training loss: 0.770970658794157
Validation loss: 2.569949788296977

Epoch: 5| Step: 6
Training loss: 1.1360865666993016
Validation loss: 2.5158213377847245

Epoch: 5| Step: 7
Training loss: 1.0415975293421706
Validation loss: 2.5385379655217815

Epoch: 5| Step: 8
Training loss: 0.7666784551654019
Validation loss: 2.503637830613004

Epoch: 5| Step: 9
Training loss: 0.8501305395752716
Validation loss: 2.504924174162403

Epoch: 5| Step: 10
Training loss: 1.0859755914168596
Validation loss: 2.480699515304964

Epoch: 263| Step: 0
Training loss: 0.896157664353532
Validation loss: 2.4477402284213854

Epoch: 5| Step: 1
Training loss: 1.1763893151961184
Validation loss: 2.457573767258965

Epoch: 5| Step: 2
Training loss: 1.0987612772114408
Validation loss: 2.426250580727906

Epoch: 5| Step: 3
Training loss: 0.893268009746248
Validation loss: 2.4124473496747436

Epoch: 5| Step: 4
Training loss: 1.0429069700766977
Validation loss: 2.4119290925551073

Epoch: 5| Step: 5
Training loss: 0.9558024711803635
Validation loss: 2.4086221168892847

Epoch: 5| Step: 6
Training loss: 1.0496702312151738
Validation loss: 2.3987775655523733

Epoch: 5| Step: 7
Training loss: 1.2395481884673112
Validation loss: 2.420779658176419

Epoch: 5| Step: 8
Training loss: 1.0558563537215722
Validation loss: 2.435875962943956

Epoch: 5| Step: 9
Training loss: 0.72479628134283
Validation loss: 2.4637418603732724

Epoch: 5| Step: 10
Training loss: 0.928001798936317
Validation loss: 2.4773194513058585

Epoch: 264| Step: 0
Training loss: 1.0692763499201103
Validation loss: 2.420535863951204

Epoch: 5| Step: 1
Training loss: 1.2166198307759615
Validation loss: 2.3927486401943323

Epoch: 5| Step: 2
Training loss: 1.0428768503226855
Validation loss: 2.3592420819133433

Epoch: 5| Step: 3
Training loss: 0.9100350557114538
Validation loss: 2.3391523959849083

Epoch: 5| Step: 4
Training loss: 1.205323922239405
Validation loss: 2.379648535155093

Epoch: 5| Step: 5
Training loss: 1.169663287642664
Validation loss: 2.4807677231157155

Epoch: 5| Step: 6
Training loss: 0.45874364505492676
Validation loss: 2.58878450205196

Epoch: 5| Step: 7
Training loss: 1.3107778058636042
Validation loss: 2.677930277937767

Epoch: 5| Step: 8
Training loss: 0.9245372091349172
Validation loss: 2.6823323220551853

Epoch: 5| Step: 9
Training loss: 0.8221010238192844
Validation loss: 2.6402962238398104

Epoch: 5| Step: 10
Training loss: 0.7484859442910532
Validation loss: 2.55686132512092

Epoch: 265| Step: 0
Training loss: 0.5186559430993892
Validation loss: 2.429025980506009

Epoch: 5| Step: 1
Training loss: 1.123349250224135
Validation loss: 2.358175476822384

Epoch: 5| Step: 2
Training loss: 1.0002832011705212
Validation loss: 2.3277033492633805

Epoch: 5| Step: 3
Training loss: 1.0088742599626384
Validation loss: 2.328651162297931

Epoch: 5| Step: 4
Training loss: 1.2277894413414672
Validation loss: 2.3601179185860843

Epoch: 5| Step: 5
Training loss: 0.8268713909367394
Validation loss: 2.441423225327409

Epoch: 5| Step: 6
Training loss: 0.9133584334992086
Validation loss: 2.527344487440829

Epoch: 5| Step: 7
Training loss: 1.0737245844896177
Validation loss: 2.555351414655567

Epoch: 5| Step: 8
Training loss: 0.9720743116005649
Validation loss: 2.5536054949229476

Epoch: 5| Step: 9
Training loss: 1.0827854433849071
Validation loss: 2.5481982995523937

Epoch: 5| Step: 10
Training loss: 1.2499431597184152
Validation loss: 2.532894677316577

Epoch: 266| Step: 0
Training loss: 0.8537397286843068
Validation loss: 2.4788082281108057

Epoch: 5| Step: 1
Training loss: 0.5497084646905998
Validation loss: 2.475931526325738

Epoch: 5| Step: 2
Training loss: 0.7811035400436406
Validation loss: 2.4780900030025266

Epoch: 5| Step: 3
Training loss: 1.3174209532649392
Validation loss: 2.46765910551226

Epoch: 5| Step: 4
Training loss: 1.125986196802614
Validation loss: 2.4756933858320243

Epoch: 5| Step: 5
Training loss: 1.0933066968367493
Validation loss: 2.4620694454667755

Epoch: 5| Step: 6
Training loss: 0.9527371977779524
Validation loss: 2.4422555184492216

Epoch: 5| Step: 7
Training loss: 0.97569217809834
Validation loss: 2.424617184259571

Epoch: 5| Step: 8
Training loss: 0.9034029206315504
Validation loss: 2.472258014572716

Epoch: 5| Step: 9
Training loss: 1.0015883348676888
Validation loss: 2.544366211530412

Epoch: 5| Step: 10
Training loss: 1.1128861110886268
Validation loss: 2.5638190095448445

Epoch: 267| Step: 0
Training loss: 1.3387807738883697
Validation loss: 2.6030355501570415

Epoch: 5| Step: 1
Training loss: 0.7982404267823934
Validation loss: 2.589469024701611

Epoch: 5| Step: 2
Training loss: 1.1559314288918119
Validation loss: 2.562919494323367

Epoch: 5| Step: 3
Training loss: 1.026269329135275
Validation loss: 2.512440974105885

Epoch: 5| Step: 4
Training loss: 1.129374687393221
Validation loss: 2.4852098344573803

Epoch: 5| Step: 5
Training loss: 0.6258935739432646
Validation loss: 2.434702348657733

Epoch: 5| Step: 6
Training loss: 0.9662338621166264
Validation loss: 2.399518434431283

Epoch: 5| Step: 7
Training loss: 0.8579714323858827
Validation loss: 2.423912884079688

Epoch: 5| Step: 8
Training loss: 1.1321797675622323
Validation loss: 2.4291653287818424

Epoch: 5| Step: 9
Training loss: 0.833415281716934
Validation loss: 2.459295096860206

Epoch: 5| Step: 10
Training loss: 0.7102830410649899
Validation loss: 2.4896045412229593

Epoch: 268| Step: 0
Training loss: 1.1311773139827594
Validation loss: 2.51347400460712

Epoch: 5| Step: 1
Training loss: 0.9781539157091166
Validation loss: 2.5426769534960867

Epoch: 5| Step: 2
Training loss: 0.6607900657976783
Validation loss: 2.5434940962960546

Epoch: 5| Step: 3
Training loss: 0.8718701653021755
Validation loss: 2.478451598207733

Epoch: 5| Step: 4
Training loss: 1.2506910797917357
Validation loss: 2.471947767856041

Epoch: 5| Step: 5
Training loss: 1.1254157251897605
Validation loss: 2.453103797914506

Epoch: 5| Step: 6
Training loss: 0.8273011193895784
Validation loss: 2.423538408443507

Epoch: 5| Step: 7
Training loss: 0.9356744794688139
Validation loss: 2.411252464667803

Epoch: 5| Step: 8
Training loss: 0.994323413884653
Validation loss: 2.415803431224797

Epoch: 5| Step: 9
Training loss: 0.8124134311040963
Validation loss: 2.386231179430737

Epoch: 5| Step: 10
Training loss: 0.836769616782926
Validation loss: 2.427989653095815

Epoch: 269| Step: 0
Training loss: 0.505414612596347
Validation loss: 2.455503281867017

Epoch: 5| Step: 1
Training loss: 0.8448589596050388
Validation loss: 2.4812734277781097

Epoch: 5| Step: 2
Training loss: 1.2344797790094924
Validation loss: 2.4904041846373324

Epoch: 5| Step: 3
Training loss: 1.1445873884683067
Validation loss: 2.5241451385575275

Epoch: 5| Step: 4
Training loss: 1.2404191487759142
Validation loss: 2.514334760823131

Epoch: 5| Step: 5
Training loss: 0.9337737735852275
Validation loss: 2.493343772577886

Epoch: 5| Step: 6
Training loss: 0.6259424018763149
Validation loss: 2.4597294522367563

Epoch: 5| Step: 7
Training loss: 1.012539210561045
Validation loss: 2.448967798086968

Epoch: 5| Step: 8
Training loss: 0.9047711243135816
Validation loss: 2.4307776930204583

Epoch: 5| Step: 9
Training loss: 1.057164540031644
Validation loss: 2.4299551574324916

Epoch: 5| Step: 10
Training loss: 0.5082556331639456
Validation loss: 2.4337904126462226

Epoch: 270| Step: 0
Training loss: 0.8334882989484302
Validation loss: 2.4131906869730737

Epoch: 5| Step: 1
Training loss: 0.7156062827515226
Validation loss: 2.4428410035667647

Epoch: 5| Step: 2
Training loss: 0.8707843111163399
Validation loss: 2.433616251336067

Epoch: 5| Step: 3
Training loss: 0.7877762385689435
Validation loss: 2.438426754763809

Epoch: 5| Step: 4
Training loss: 0.8933373025253235
Validation loss: 2.45261388443794

Epoch: 5| Step: 5
Training loss: 0.8241694286468583
Validation loss: 2.4495983295105734

Epoch: 5| Step: 6
Training loss: 0.9134988269453863
Validation loss: 2.4595064506911055

Epoch: 5| Step: 7
Training loss: 1.3559356237197628
Validation loss: 2.4732867107199032

Epoch: 5| Step: 8
Training loss: 1.0603088336569766
Validation loss: 2.4538079121068055

Epoch: 5| Step: 9
Training loss: 0.8384052821227748
Validation loss: 2.496777160172026

Epoch: 5| Step: 10
Training loss: 1.104602433831778
Validation loss: 2.46727889023148

Epoch: 271| Step: 0
Training loss: 1.0293049241969132
Validation loss: 2.5412819283876007

Epoch: 5| Step: 1
Training loss: 0.7040863882009006
Validation loss: 2.550540477965651

Epoch: 5| Step: 2
Training loss: 0.8315288477542568
Validation loss: 2.5469172303290666

Epoch: 5| Step: 3
Training loss: 0.857965492543859
Validation loss: 2.4888453385816973

Epoch: 5| Step: 4
Training loss: 1.0593572586959599
Validation loss: 2.5026670196659

Epoch: 5| Step: 5
Training loss: 1.1587354906443263
Validation loss: 2.450321275474657

Epoch: 5| Step: 6
Training loss: 0.972356114174808
Validation loss: 2.457454045136363

Epoch: 5| Step: 7
Training loss: 0.8439653616256062
Validation loss: 2.4960463311685666

Epoch: 5| Step: 8
Training loss: 0.7498483901964329
Validation loss: 2.5064480719012967

Epoch: 5| Step: 9
Training loss: 0.8264654913873489
Validation loss: 2.5394961306300425

Epoch: 5| Step: 10
Training loss: 1.2331418021865639
Validation loss: 2.504366365685016

Epoch: 272| Step: 0
Training loss: 1.194585441921907
Validation loss: 2.463743236497065

Epoch: 5| Step: 1
Training loss: 0.7147564860793832
Validation loss: 2.445789971864919

Epoch: 5| Step: 2
Training loss: 0.6208679220519223
Validation loss: 2.3941821125319334

Epoch: 5| Step: 3
Training loss: 1.023635670352783
Validation loss: 2.3940400041233887

Epoch: 5| Step: 4
Training loss: 0.8391123581037285
Validation loss: 2.4062182133096908

Epoch: 5| Step: 5
Training loss: 0.8525632524936572
Validation loss: 2.420621387529226

Epoch: 5| Step: 6
Training loss: 1.0782997432018937
Validation loss: 2.4654446571720228

Epoch: 5| Step: 7
Training loss: 0.40745742803654367
Validation loss: 2.4707257968015264

Epoch: 5| Step: 8
Training loss: 1.0692840981655538
Validation loss: 2.5277821114911743

Epoch: 5| Step: 9
Training loss: 1.2797775181000606
Validation loss: 2.5476274403691055

Epoch: 5| Step: 10
Training loss: 0.7228130273615013
Validation loss: 2.5102969456663144

Epoch: 273| Step: 0
Training loss: 0.7760594555823577
Validation loss: 2.506293537722336

Epoch: 5| Step: 1
Training loss: 0.8764914675948483
Validation loss: 2.5032285117002164

Epoch: 5| Step: 2
Training loss: 1.4043623228566242
Validation loss: 2.474536105931963

Epoch: 5| Step: 3
Training loss: 0.8299120209496815
Validation loss: 2.441000406245724

Epoch: 5| Step: 4
Training loss: 0.7185230726175668
Validation loss: 2.414033940509335

Epoch: 5| Step: 5
Training loss: 0.8030754905313239
Validation loss: 2.4289408657895235

Epoch: 5| Step: 6
Training loss: 0.7727539432737259
Validation loss: 2.4154285219565383

Epoch: 5| Step: 7
Training loss: 1.183751111538616
Validation loss: 2.462995611787347

Epoch: 5| Step: 8
Training loss: 0.9366353816331818
Validation loss: 2.4897758106392844

Epoch: 5| Step: 9
Training loss: 0.7375343621864212
Validation loss: 2.4876900605508103

Epoch: 5| Step: 10
Training loss: 0.7996860737581045
Validation loss: 2.476553024119107

Epoch: 274| Step: 0
Training loss: 0.6665088695299403
Validation loss: 2.4570477960151607

Epoch: 5| Step: 1
Training loss: 0.6712271871899195
Validation loss: 2.456561921962047

Epoch: 5| Step: 2
Training loss: 0.7784066529289598
Validation loss: 2.4748852301808957

Epoch: 5| Step: 3
Training loss: 0.9387859425984754
Validation loss: 2.460865210978507

Epoch: 5| Step: 4
Training loss: 0.9217980239541577
Validation loss: 2.4686495811275226

Epoch: 5| Step: 5
Training loss: 0.8561514999648303
Validation loss: 2.49849912239126

Epoch: 5| Step: 6
Training loss: 1.20849155617835
Validation loss: 2.50307060681272

Epoch: 5| Step: 7
Training loss: 1.1464669585326657
Validation loss: 2.5582527860907294

Epoch: 5| Step: 8
Training loss: 0.9368767892160057
Validation loss: 2.545069703124431

Epoch: 5| Step: 9
Training loss: 1.032632825403655
Validation loss: 2.54737010305469

Epoch: 5| Step: 10
Training loss: 0.6106385799760349
Validation loss: 2.495793990913002

Epoch: 275| Step: 0
Training loss: 0.9018563940253104
Validation loss: 2.4496006769334633

Epoch: 5| Step: 1
Training loss: 0.9905930571114272
Validation loss: 2.4676535017020504

Epoch: 5| Step: 2
Training loss: 1.140012655104281
Validation loss: 2.450131230986522

Epoch: 5| Step: 3
Training loss: 1.117597704718874
Validation loss: 2.493719556809082

Epoch: 5| Step: 4
Training loss: 0.8105773184700764
Validation loss: 2.5007003756801818

Epoch: 5| Step: 5
Training loss: 0.8269484457208853
Validation loss: 2.5476834380341384

Epoch: 5| Step: 6
Training loss: 0.9654805788351779
Validation loss: 2.543229084989694

Epoch: 5| Step: 7
Training loss: 0.6496644648752274
Validation loss: 2.528387393829202

Epoch: 5| Step: 8
Training loss: 0.7587658106556475
Validation loss: 2.47123156617028

Epoch: 5| Step: 9
Training loss: 0.9417820097463298
Validation loss: 2.441821825979471

Epoch: 5| Step: 10
Training loss: 0.7406726033167118
Validation loss: 2.4116940993167924

Epoch: 276| Step: 0
Training loss: 0.6720766607648221
Validation loss: 2.422971028506622

Epoch: 5| Step: 1
Training loss: 0.759161623265598
Validation loss: 2.4408001788886784

Epoch: 5| Step: 2
Training loss: 0.8350289657274296
Validation loss: 2.471673995307731

Epoch: 5| Step: 3
Training loss: 0.7483353021407477
Validation loss: 2.5297304355232013

Epoch: 5| Step: 4
Training loss: 0.9070718261685092
Validation loss: 2.535325587905874

Epoch: 5| Step: 5
Training loss: 0.8215440497171228
Validation loss: 2.5140312851880653

Epoch: 5| Step: 6
Training loss: 1.1998221404669016
Validation loss: 2.461570353406533

Epoch: 5| Step: 7
Training loss: 1.0605862717309897
Validation loss: 2.4742275576426613

Epoch: 5| Step: 8
Training loss: 1.0490204760804933
Validation loss: 2.4675115301092614

Epoch: 5| Step: 9
Training loss: 0.7987621625233964
Validation loss: 2.4808765275470916

Epoch: 5| Step: 10
Training loss: 0.9282579410273923
Validation loss: 2.449428676987138

Epoch: 277| Step: 0
Training loss: 0.34877957799719395
Validation loss: 2.4387145822367944

Epoch: 5| Step: 1
Training loss: 1.0018365208404743
Validation loss: 2.448011789107925

Epoch: 5| Step: 2
Training loss: 0.8495526875844333
Validation loss: 2.4859896991482238

Epoch: 5| Step: 3
Training loss: 0.861694292705344
Validation loss: 2.514080270644128

Epoch: 5| Step: 4
Training loss: 0.9713068414499599
Validation loss: 2.547352754893266

Epoch: 5| Step: 5
Training loss: 0.46483653728114493
Validation loss: 2.5360621255556977

Epoch: 5| Step: 6
Training loss: 1.1137664808259138
Validation loss: 2.4882299082723978

Epoch: 5| Step: 7
Training loss: 0.7556999491839097
Validation loss: 2.5086749534876978

Epoch: 5| Step: 8
Training loss: 1.0187996179397998
Validation loss: 2.466351721281593

Epoch: 5| Step: 9
Training loss: 1.029021311288101
Validation loss: 2.458000202942807

Epoch: 5| Step: 10
Training loss: 1.0603874185022237
Validation loss: 2.4172930671208817

Epoch: 278| Step: 0
Training loss: 0.8333440104436337
Validation loss: 2.4397840555297945

Epoch: 5| Step: 1
Training loss: 0.6332830163350803
Validation loss: 2.4126288504400395

Epoch: 5| Step: 2
Training loss: 0.9847661406876191
Validation loss: 2.4699268114153

Epoch: 5| Step: 3
Training loss: 0.7935824345012737
Validation loss: 2.4647271363215446

Epoch: 5| Step: 4
Training loss: 0.9944599590535698
Validation loss: 2.5156809961670974

Epoch: 5| Step: 5
Training loss: 0.7397635379157124
Validation loss: 2.51390408047694

Epoch: 5| Step: 6
Training loss: 0.8269215602553761
Validation loss: 2.558422629414101

Epoch: 5| Step: 7
Training loss: 0.9907537599271342
Validation loss: 2.524202210168603

Epoch: 5| Step: 8
Training loss: 0.6668543079673256
Validation loss: 2.481417439691841

Epoch: 5| Step: 9
Training loss: 1.1551255609539657
Validation loss: 2.449964347514653

Epoch: 5| Step: 10
Training loss: 1.0121679303078501
Validation loss: 2.4247360864384198

Epoch: 279| Step: 0
Training loss: 0.9094752436703168
Validation loss: 2.4506780489327924

Epoch: 5| Step: 1
Training loss: 0.8693140092705396
Validation loss: 2.4334921437638695

Epoch: 5| Step: 2
Training loss: 0.8528440089571153
Validation loss: 2.428491680157437

Epoch: 5| Step: 3
Training loss: 1.0922804087577036
Validation loss: 2.4782705522087234

Epoch: 5| Step: 4
Training loss: 1.3221148767003503
Validation loss: 2.5024143200040463

Epoch: 5| Step: 5
Training loss: 1.1431737146274776
Validation loss: 2.52794157652391

Epoch: 5| Step: 6
Training loss: 0.5210637028165398
Validation loss: 2.5315748315452007

Epoch: 5| Step: 7
Training loss: 0.654888625649609
Validation loss: 2.5157723607538887

Epoch: 5| Step: 8
Training loss: 0.7733204300258867
Validation loss: 2.4679508008574507

Epoch: 5| Step: 9
Training loss: 0.44224241272955656
Validation loss: 2.4336551562452127

Epoch: 5| Step: 10
Training loss: 0.7127791644190502
Validation loss: 2.430638730393194

Epoch: 280| Step: 0
Training loss: 0.8275502207518987
Validation loss: 2.442503719434691

Epoch: 5| Step: 1
Training loss: 0.9217513696563617
Validation loss: 2.426637688811064

Epoch: 5| Step: 2
Training loss: 0.5102659379188538
Validation loss: 2.4448782176027377

Epoch: 5| Step: 3
Training loss: 0.6732098825360586
Validation loss: 2.4404341975008594

Epoch: 5| Step: 4
Training loss: 0.46169287000698445
Validation loss: 2.4646150855954936

Epoch: 5| Step: 5
Training loss: 0.7019602346935898
Validation loss: 2.4837578453053477

Epoch: 5| Step: 6
Training loss: 0.7379707208139054
Validation loss: 2.4986773160579965

Epoch: 5| Step: 7
Training loss: 1.3915741499493044
Validation loss: 2.48727680923448

Epoch: 5| Step: 8
Training loss: 1.1033492511473075
Validation loss: 2.4870718952182336

Epoch: 5| Step: 9
Training loss: 1.0594719203848317
Validation loss: 2.4871967955989867

Epoch: 5| Step: 10
Training loss: 0.8135266786595687
Validation loss: 2.423731305981608

Epoch: 281| Step: 0
Training loss: 1.0218462622098414
Validation loss: 2.4106075792145947

Epoch: 5| Step: 1
Training loss: 0.6878500394096455
Validation loss: 2.3857524872057176

Epoch: 5| Step: 2
Training loss: 0.9034797156653006
Validation loss: 2.4294624595010768

Epoch: 5| Step: 3
Training loss: 0.6107696566063306
Validation loss: 2.46239984455547

Epoch: 5| Step: 4
Training loss: 1.2012258129880315
Validation loss: 2.459655002509999

Epoch: 5| Step: 5
Training loss: 0.9602022226748478
Validation loss: 2.507242328018906

Epoch: 5| Step: 6
Training loss: 0.6091520684167757
Validation loss: 2.541940641707684

Epoch: 5| Step: 7
Training loss: 0.8362133248445172
Validation loss: 2.5338981291652374

Epoch: 5| Step: 8
Training loss: 1.019142866150456
Validation loss: 2.5886496647236488

Epoch: 5| Step: 9
Training loss: 0.7242076407920998
Validation loss: 2.4861143491828592

Epoch: 5| Step: 10
Training loss: 0.7550982208656364
Validation loss: 2.5057544970363193

Epoch: 282| Step: 0
Training loss: 0.5065940029601814
Validation loss: 2.416062809652866

Epoch: 5| Step: 1
Training loss: 0.9761978689383435
Validation loss: 2.4074007832182116

Epoch: 5| Step: 2
Training loss: 0.46639746972386537
Validation loss: 2.408541094327292

Epoch: 5| Step: 3
Training loss: 1.1949712727497441
Validation loss: 2.390153296132426

Epoch: 5| Step: 4
Training loss: 1.024886176139452
Validation loss: 2.4286462500498667

Epoch: 5| Step: 5
Training loss: 0.8288739254731227
Validation loss: 2.4933574110173904

Epoch: 5| Step: 6
Training loss: 0.7603488438986606
Validation loss: 2.5494053210154237

Epoch: 5| Step: 7
Training loss: 0.8345054053079523
Validation loss: 2.554147132898274

Epoch: 5| Step: 8
Training loss: 1.1406784567651878
Validation loss: 2.5555048521854706

Epoch: 5| Step: 9
Training loss: 0.7735749710136753
Validation loss: 2.5173315243130956

Epoch: 5| Step: 10
Training loss: 0.6625443776580228
Validation loss: 2.497160655863658

Epoch: 283| Step: 0
Training loss: 0.8029409175338936
Validation loss: 2.465321352216023

Epoch: 5| Step: 1
Training loss: 0.48623881611551406
Validation loss: 2.4426686483349527

Epoch: 5| Step: 2
Training loss: 0.8279155970276781
Validation loss: 2.3581588610862356

Epoch: 5| Step: 3
Training loss: 1.0735932904818355
Validation loss: 2.3946720167497846

Epoch: 5| Step: 4
Training loss: 0.8031333433081529
Validation loss: 2.4438572851689613

Epoch: 5| Step: 5
Training loss: 0.8156610035166423
Validation loss: 2.4663210969190263

Epoch: 5| Step: 6
Training loss: 0.8109213825601328
Validation loss: 2.4811001558695414

Epoch: 5| Step: 7
Training loss: 0.9705239635282074
Validation loss: 2.515674569939559

Epoch: 5| Step: 8
Training loss: 0.6856472670035041
Validation loss: 2.532293613242577

Epoch: 5| Step: 9
Training loss: 0.4994627181823057
Validation loss: 2.547128704617732

Epoch: 5| Step: 10
Training loss: 1.392354125937901
Validation loss: 2.493764952022305

Epoch: 284| Step: 0
Training loss: 0.9292013355738171
Validation loss: 2.496918134357692

Epoch: 5| Step: 1
Training loss: 1.0859511120718366
Validation loss: 2.471029387457883

Epoch: 5| Step: 2
Training loss: 0.5912544357988289
Validation loss: 2.4374667897156232

Epoch: 5| Step: 3
Training loss: 0.728533419885195
Validation loss: 2.4076026265155503

Epoch: 5| Step: 4
Training loss: 0.8677469115975739
Validation loss: 2.4582126421646473

Epoch: 5| Step: 5
Training loss: 0.7767054558619442
Validation loss: 2.512223364385086

Epoch: 5| Step: 6
Training loss: 0.6511178061149585
Validation loss: 2.5165417513548585

Epoch: 5| Step: 7
Training loss: 0.5980957011318526
Validation loss: 2.56164406528321

Epoch: 5| Step: 8
Training loss: 0.9202389504749415
Validation loss: 2.5408999838186115

Epoch: 5| Step: 9
Training loss: 0.6544675234408037
Validation loss: 2.5388066917524874

Epoch: 5| Step: 10
Training loss: 1.3447532900479053
Validation loss: 2.469224351779579

Epoch: 285| Step: 0
Training loss: 0.6853619622272861
Validation loss: 2.440252267385348

Epoch: 5| Step: 1
Training loss: 0.6880533202532049
Validation loss: 2.4387076062898294

Epoch: 5| Step: 2
Training loss: 0.9082983151664761
Validation loss: 2.4226688286787033

Epoch: 5| Step: 3
Training loss: 0.8565762810083859
Validation loss: 2.3983605490626863

Epoch: 5| Step: 4
Training loss: 0.7672571574051603
Validation loss: 2.438476571436295

Epoch: 5| Step: 5
Training loss: 0.6012412117377257
Validation loss: 2.475350464781915

Epoch: 5| Step: 6
Training loss: 0.6718190413836272
Validation loss: 2.4813404786796216

Epoch: 5| Step: 7
Training loss: 1.046547909780446
Validation loss: 2.541904564073885

Epoch: 5| Step: 8
Training loss: 0.926170363921723
Validation loss: 2.5677031169381515

Epoch: 5| Step: 9
Training loss: 1.1491819291533976
Validation loss: 2.5162410156366075

Epoch: 5| Step: 10
Training loss: 0.8315050135499763
Validation loss: 2.4870490116481823

Epoch: 286| Step: 0
Training loss: 0.7525452895492226
Validation loss: 2.4505631024281462

Epoch: 5| Step: 1
Training loss: 1.0162846110551018
Validation loss: 2.416597414845555

Epoch: 5| Step: 2
Training loss: 0.901958432848988
Validation loss: 2.399869819754298

Epoch: 5| Step: 3
Training loss: 0.8709196592432883
Validation loss: 2.4236703199773415

Epoch: 5| Step: 4
Training loss: 1.050440282701193
Validation loss: 2.4606492605069326

Epoch: 5| Step: 5
Training loss: 0.6994722855021875
Validation loss: 2.4799667898244224

Epoch: 5| Step: 6
Training loss: 0.8573036546823036
Validation loss: 2.5238152703796732

Epoch: 5| Step: 7
Training loss: 0.5405329399887442
Validation loss: 2.5176966946723893

Epoch: 5| Step: 8
Training loss: 0.5467312760184178
Validation loss: 2.485053940367896

Epoch: 5| Step: 9
Training loss: 0.578711547233268
Validation loss: 2.5091984051008347

Epoch: 5| Step: 10
Training loss: 1.2118958157526705
Validation loss: 2.537381577083679

Epoch: 287| Step: 0
Training loss: 0.5451196017838869
Validation loss: 2.4786557292978357

Epoch: 5| Step: 1
Training loss: 0.8656364178507009
Validation loss: 2.416204531029032

Epoch: 5| Step: 2
Training loss: 0.9534909530754556
Validation loss: 2.3492786591145696

Epoch: 5| Step: 3
Training loss: 0.8944037400698899
Validation loss: 2.412828168036258

Epoch: 5| Step: 4
Training loss: 0.4192959400818354
Validation loss: 2.4607568068024026

Epoch: 5| Step: 5
Training loss: 0.9364975337959889
Validation loss: 2.497946597316339

Epoch: 5| Step: 6
Training loss: 0.9169385607946455
Validation loss: 2.523379786281052

Epoch: 5| Step: 7
Training loss: 0.8146927295863758
Validation loss: 2.5349062177205015

Epoch: 5| Step: 8
Training loss: 1.0978593740166689
Validation loss: 2.5483184555075358

Epoch: 5| Step: 9
Training loss: 0.9141481473525366
Validation loss: 2.525013698982174

Epoch: 5| Step: 10
Training loss: 0.5697276369437155
Validation loss: 2.447704510385024

Epoch: 288| Step: 0
Training loss: 0.8958575814684018
Validation loss: 2.432191171107325

Epoch: 5| Step: 1
Training loss: 0.8816131952605032
Validation loss: 2.39982733594628

Epoch: 5| Step: 2
Training loss: 0.7213301580039534
Validation loss: 2.411472640952664

Epoch: 5| Step: 3
Training loss: 0.9032471003376324
Validation loss: 2.389073041253904

Epoch: 5| Step: 4
Training loss: 0.6877396339320304
Validation loss: 2.4303815573326144

Epoch: 5| Step: 5
Training loss: 0.8118469841919579
Validation loss: 2.5451988232146907

Epoch: 5| Step: 6
Training loss: 1.0494541452357866
Validation loss: 2.58779888316286

Epoch: 5| Step: 7
Training loss: 0.9520307419245115
Validation loss: 2.6365213980398465

Epoch: 5| Step: 8
Training loss: 0.8207501288584417
Validation loss: 2.5320049716159536

Epoch: 5| Step: 9
Training loss: 0.7712313852892343
Validation loss: 2.4465018542895116

Epoch: 5| Step: 10
Training loss: 0.5411271073372373
Validation loss: 2.3879053113376743

Epoch: 289| Step: 0
Training loss: 1.057697437514023
Validation loss: 2.349012143204243

Epoch: 5| Step: 1
Training loss: 0.6148399178410967
Validation loss: 2.34720289081573

Epoch: 5| Step: 2
Training loss: 0.9563348533032814
Validation loss: 2.330708523441937

Epoch: 5| Step: 3
Training loss: 0.8289963079170131
Validation loss: 2.4230768318626503

Epoch: 5| Step: 4
Training loss: 0.9767857715958354
Validation loss: 2.4793914183937362

Epoch: 5| Step: 5
Training loss: 0.7491229810555436
Validation loss: 2.51530217635803

Epoch: 5| Step: 6
Training loss: 0.6420616230727982
Validation loss: 2.5184095488839855

Epoch: 5| Step: 7
Training loss: 0.7863218471164686
Validation loss: 2.5299067658438887

Epoch: 5| Step: 8
Training loss: 0.8935519525871739
Validation loss: 2.4703609059800153

Epoch: 5| Step: 9
Training loss: 0.7717612626761824
Validation loss: 2.3793538259829345

Epoch: 5| Step: 10
Training loss: 0.7606389143336392
Validation loss: 2.3164948421925757

Epoch: 290| Step: 0
Training loss: 1.0345600066446763
Validation loss: 2.383497053016551

Epoch: 5| Step: 1
Training loss: 0.9924479465623082
Validation loss: 2.4064572163429485

Epoch: 5| Step: 2
Training loss: 0.8419369185007254
Validation loss: 2.485333194508052

Epoch: 5| Step: 3
Training loss: 0.8523784193335938
Validation loss: 2.520382839809383

Epoch: 5| Step: 4
Training loss: 1.0324595322887498
Validation loss: 2.5420772161068506

Epoch: 5| Step: 5
Training loss: 0.7731140308018282
Validation loss: 2.5216570292967804

Epoch: 5| Step: 6
Training loss: 0.7261176439445576
Validation loss: 2.438944913414053

Epoch: 5| Step: 7
Training loss: 0.518860003286589
Validation loss: 2.3941541446841623

Epoch: 5| Step: 8
Training loss: 0.6484408550865056
Validation loss: 2.3477973398049596

Epoch: 5| Step: 9
Training loss: 0.6960398052647019
Validation loss: 2.329922581354324

Epoch: 5| Step: 10
Training loss: 0.8263597567861414
Validation loss: 2.3766153743256466

Epoch: 291| Step: 0
Training loss: 0.7766042287502644
Validation loss: 2.4544535813715913

Epoch: 5| Step: 1
Training loss: 0.8722513487245908
Validation loss: 2.529875331013443

Epoch: 5| Step: 2
Training loss: 0.8582577812559908
Validation loss: 2.546003363514656

Epoch: 5| Step: 3
Training loss: 1.2459792320700527
Validation loss: 2.5295986750438137

Epoch: 5| Step: 4
Training loss: 0.9344656157171061
Validation loss: 2.557276098647847

Epoch: 5| Step: 5
Training loss: 0.83241223849264
Validation loss: 2.4759525619244007

Epoch: 5| Step: 6
Training loss: 0.9871204781672059
Validation loss: 2.4422888242186107

Epoch: 5| Step: 7
Training loss: 0.48821560227639854
Validation loss: 2.3696275209095425

Epoch: 5| Step: 8
Training loss: 0.5546503457534195
Validation loss: 2.3734771501831093

Epoch: 5| Step: 9
Training loss: 0.6815565434492487
Validation loss: 2.3830282542971966

Epoch: 5| Step: 10
Training loss: 0.5253747420055075
Validation loss: 2.3858584926101996

Epoch: 292| Step: 0
Training loss: 0.7841243510597058
Validation loss: 2.4440452502440935

Epoch: 5| Step: 1
Training loss: 0.855231927289916
Validation loss: 2.454070454114138

Epoch: 5| Step: 2
Training loss: 0.4709383902892549
Validation loss: 2.5195361808340047

Epoch: 5| Step: 3
Training loss: 0.6069896178041093
Validation loss: 2.487510680964515

Epoch: 5| Step: 4
Training loss: 0.7197278875496622
Validation loss: 2.5483524746046755

Epoch: 5| Step: 5
Training loss: 0.8199296330288938
Validation loss: 2.4815538377337654

Epoch: 5| Step: 6
Training loss: 0.7774141749392758
Validation loss: 2.4770941750575424

Epoch: 5| Step: 7
Training loss: 0.3914664170853519
Validation loss: 2.4364235117712583

Epoch: 5| Step: 8
Training loss: 0.829923763508207
Validation loss: 2.4351161941083275

Epoch: 5| Step: 9
Training loss: 1.3205578367284632
Validation loss: 2.4533906542906267

Epoch: 5| Step: 10
Training loss: 0.8236341889378728
Validation loss: 2.434259829992406

Epoch: 293| Step: 0
Training loss: 0.5407277246685148
Validation loss: 2.477350078377066

Epoch: 5| Step: 1
Training loss: 0.7249152265511671
Validation loss: 2.513954321702164

Epoch: 5| Step: 2
Training loss: 0.5222000183577372
Validation loss: 2.518253306491086

Epoch: 5| Step: 3
Training loss: 0.894730158517369
Validation loss: 2.4861597899404377

Epoch: 5| Step: 4
Training loss: 0.2721185755043589
Validation loss: 2.478030436532215

Epoch: 5| Step: 5
Training loss: 0.9594328350316288
Validation loss: 2.4570891438717575

Epoch: 5| Step: 6
Training loss: 0.5217668147080531
Validation loss: 2.455009770479294

Epoch: 5| Step: 7
Training loss: 0.6954333168247491
Validation loss: 2.4523112040148205

Epoch: 5| Step: 8
Training loss: 1.0732350787412432
Validation loss: 2.4421543145772624

Epoch: 5| Step: 9
Training loss: 1.0050902157236778
Validation loss: 2.454621496481787

Epoch: 5| Step: 10
Training loss: 1.114701125198307
Validation loss: 2.4188555167336383

Epoch: 294| Step: 0
Training loss: 0.41483359243597634
Validation loss: 2.3720781371953685

Epoch: 5| Step: 1
Training loss: 0.7368601286134073
Validation loss: 2.343206696792488

Epoch: 5| Step: 2
Training loss: 0.8138371981356437
Validation loss: 2.3949280634049037

Epoch: 5| Step: 3
Training loss: 0.8710729143191138
Validation loss: 2.3638939054123482

Epoch: 5| Step: 4
Training loss: 0.9528939013867755
Validation loss: 2.4089115755689448

Epoch: 5| Step: 5
Training loss: 0.6168023126711577
Validation loss: 2.44755620839987

Epoch: 5| Step: 6
Training loss: 0.6908671977122125
Validation loss: 2.4438736848751317

Epoch: 5| Step: 7
Training loss: 1.003915096496315
Validation loss: 2.449937536528671

Epoch: 5| Step: 8
Training loss: 0.7063686574996455
Validation loss: 2.467431964390332

Epoch: 5| Step: 9
Training loss: 0.48908954094666096
Validation loss: 2.495160585105543

Epoch: 5| Step: 10
Training loss: 1.079588518698305
Validation loss: 2.5289071109041172

Epoch: 295| Step: 0
Training loss: 1.0151667221207938
Validation loss: 2.522559645138157

Epoch: 5| Step: 1
Training loss: 0.8311768205597577
Validation loss: 2.4648749356337922

Epoch: 5| Step: 2
Training loss: 0.7273281124413041
Validation loss: 2.4185561045348765

Epoch: 5| Step: 3
Training loss: 0.72649522695529
Validation loss: 2.426481005230778

Epoch: 5| Step: 4
Training loss: 0.5461337651994157
Validation loss: 2.3863234662139052

Epoch: 5| Step: 5
Training loss: 0.758412978597541
Validation loss: 2.394082542977916

Epoch: 5| Step: 6
Training loss: 1.0231946118255428
Validation loss: 2.418580260482542

Epoch: 5| Step: 7
Training loss: 0.8647537446504779
Validation loss: 2.4377564620571968

Epoch: 5| Step: 8
Training loss: 0.6909443664899718
Validation loss: 2.495276878911697

Epoch: 5| Step: 9
Training loss: 0.6220941224624301
Validation loss: 2.517327270468944

Epoch: 5| Step: 10
Training loss: 0.48362077936365333
Validation loss: 2.5472831064414403

Epoch: 296| Step: 0
Training loss: 0.7311164717741832
Validation loss: 2.506499040458229

Epoch: 5| Step: 1
Training loss: 0.8025909815519472
Validation loss: 2.4478796194009576

Epoch: 5| Step: 2
Training loss: 0.9758753991500607
Validation loss: 2.3764851346424996

Epoch: 5| Step: 3
Training loss: 0.7445956863747653
Validation loss: 2.3415452898180567

Epoch: 5| Step: 4
Training loss: 1.0425824082001809
Validation loss: 2.3373535623876385

Epoch: 5| Step: 5
Training loss: 0.4047694369992346
Validation loss: 2.386425327547187

Epoch: 5| Step: 6
Training loss: 0.7214176595313165
Validation loss: 2.445074990438175

Epoch: 5| Step: 7
Training loss: 0.7756015673224641
Validation loss: 2.4736965183822344

Epoch: 5| Step: 8
Training loss: 0.8180021904027661
Validation loss: 2.5037178512725102

Epoch: 5| Step: 9
Training loss: 0.819444324112648
Validation loss: 2.5230758145171044

Epoch: 5| Step: 10
Training loss: 0.41570530094178737
Validation loss: 2.4524204268310874

Epoch: 297| Step: 0
Training loss: 0.7671349874576368
Validation loss: 2.4317069322553344

Epoch: 5| Step: 1
Training loss: 0.8561193352566313
Validation loss: 2.3927215620235183

Epoch: 5| Step: 2
Training loss: 0.915343796705198
Validation loss: 2.367940701589605

Epoch: 5| Step: 3
Training loss: 0.6321220163022593
Validation loss: 2.384017536882718

Epoch: 5| Step: 4
Training loss: 0.23728394123331192
Validation loss: 2.391869893428834

Epoch: 5| Step: 5
Training loss: 0.5173771017989945
Validation loss: 2.4324190598671827

Epoch: 5| Step: 6
Training loss: 0.7596605321380645
Validation loss: 2.5164469081530667

Epoch: 5| Step: 7
Training loss: 0.6336972209765344
Validation loss: 2.5404474829968997

Epoch: 5| Step: 8
Training loss: 1.0273097507667226
Validation loss: 2.532649061863879

Epoch: 5| Step: 9
Training loss: 0.9057798481486687
Validation loss: 2.5798146617295212

Epoch: 5| Step: 10
Training loss: 0.9287204360877295
Validation loss: 2.6037495449262034

Epoch: 298| Step: 0
Training loss: 0.7287817665753542
Validation loss: 2.547140697835758

Epoch: 5| Step: 1
Training loss: 0.9270167737634558
Validation loss: 2.502718567152831

Epoch: 5| Step: 2
Training loss: 0.7029043487196136
Validation loss: 2.406575139823527

Epoch: 5| Step: 3
Training loss: 0.4129114526495808
Validation loss: 2.380709598962369

Epoch: 5| Step: 4
Training loss: 0.9213609070187213
Validation loss: 2.3156324266273636

Epoch: 5| Step: 5
Training loss: 0.7590147097774247
Validation loss: 2.2892484353161566

Epoch: 5| Step: 6
Training loss: 0.7007418192951756
Validation loss: 2.3208149641835925

Epoch: 5| Step: 7
Training loss: 0.6406725191309817
Validation loss: 2.376388309188189

Epoch: 5| Step: 8
Training loss: 0.5934428625281347
Validation loss: 2.438014615859487

Epoch: 5| Step: 9
Training loss: 0.9746842900229747
Validation loss: 2.5497576461868188

Epoch: 5| Step: 10
Training loss: 0.9132872660416729
Validation loss: 2.5988943759700627

Epoch: 299| Step: 0
Training loss: 0.7904696617264475
Validation loss: 2.5924384513430803

Epoch: 5| Step: 1
Training loss: 0.8387220476953331
Validation loss: 2.5464266667987094

Epoch: 5| Step: 2
Training loss: 0.7981323345806213
Validation loss: 2.4916414628410832

Epoch: 5| Step: 3
Training loss: 1.1494334566850948
Validation loss: 2.437892750182153

Epoch: 5| Step: 4
Training loss: 0.46097690607799496
Validation loss: 2.4319725590565664

Epoch: 5| Step: 5
Training loss: 0.7327506992983597
Validation loss: 2.374801493057656

Epoch: 5| Step: 6
Training loss: 0.7376224868697987
Validation loss: 2.4082771044196085

Epoch: 5| Step: 7
Training loss: 0.6408230080122037
Validation loss: 2.43862401111143

Epoch: 5| Step: 8
Training loss: 0.7285762485510338
Validation loss: 2.467821232339831

Epoch: 5| Step: 9
Training loss: 0.5213707789449362
Validation loss: 2.4647876254739267

Epoch: 5| Step: 10
Training loss: 0.7240721981237114
Validation loss: 2.504300700081028

Epoch: 300| Step: 0
Training loss: 0.8001894368949223
Validation loss: 2.498583568763123

Epoch: 5| Step: 1
Training loss: 0.9044703405777678
Validation loss: 2.5118922653666105

Epoch: 5| Step: 2
Training loss: 0.6846789656106773
Validation loss: 2.4550489148720684

Epoch: 5| Step: 3
Training loss: 0.9359271206542948
Validation loss: 2.4719299401567625

Epoch: 5| Step: 4
Training loss: 0.7200548104113259
Validation loss: 2.456281972693374

Epoch: 5| Step: 5
Training loss: 0.6786674430687528
Validation loss: 2.4437750888150602

Epoch: 5| Step: 6
Training loss: 0.6177122565193668
Validation loss: 2.436203302745

Epoch: 5| Step: 7
Training loss: 0.49345754823066873
Validation loss: 2.3688325654197797

Epoch: 5| Step: 8
Training loss: 0.9294133783970513
Validation loss: 2.3917480110906526

Epoch: 5| Step: 9
Training loss: 0.6715783196064231
Validation loss: 2.4166975058291222

Epoch: 5| Step: 10
Training loss: 0.5504184366621753
Validation loss: 2.411700445442722

Epoch: 301| Step: 0
Training loss: 0.8470238994595405
Validation loss: 2.467495005428285

Epoch: 5| Step: 1
Training loss: 0.8057955178030811
Validation loss: 2.4750680966506136

Epoch: 5| Step: 2
Training loss: 0.8522501977196865
Validation loss: 2.4944716722803433

Epoch: 5| Step: 3
Training loss: 0.9252849487923379
Validation loss: 2.518422462693709

Epoch: 5| Step: 4
Training loss: 0.9219835508414214
Validation loss: 2.5441421773674175

Epoch: 5| Step: 5
Training loss: 0.5162110610482583
Validation loss: 2.5158916656375334

Epoch: 5| Step: 6
Training loss: 0.5985429456754465
Validation loss: 2.502539669609725

Epoch: 5| Step: 7
Training loss: 0.49872513008733627
Validation loss: 2.4657246479624706

Epoch: 5| Step: 8
Training loss: 0.728117478622424
Validation loss: 2.4380619777979082

Epoch: 5| Step: 9
Training loss: 0.545157569584079
Validation loss: 2.387026278716722

Epoch: 5| Step: 10
Training loss: 0.6071016994919393
Validation loss: 2.333460357903036

Epoch: 302| Step: 0
Training loss: 0.653080621151608
Validation loss: 2.376540374787709

Epoch: 5| Step: 1
Training loss: 0.7922813931712795
Validation loss: 2.3696891242317077

Epoch: 5| Step: 2
Training loss: 0.7229276405256435
Validation loss: 2.4144329303614858

Epoch: 5| Step: 3
Training loss: 0.7279689670749921
Validation loss: 2.4364383679453203

Epoch: 5| Step: 4
Training loss: 0.6655345756826326
Validation loss: 2.4510781045059873

Epoch: 5| Step: 5
Training loss: 0.7166634001398681
Validation loss: 2.4887911325240286

Epoch: 5| Step: 6
Training loss: 0.8753206482970712
Validation loss: 2.4746313718210877

Epoch: 5| Step: 7
Training loss: 0.4256364943790983
Validation loss: 2.4891603611426607

Epoch: 5| Step: 8
Training loss: 0.6612032651340616
Validation loss: 2.517889005939795

Epoch: 5| Step: 9
Training loss: 0.8024669489486581
Validation loss: 2.484698435968253

Epoch: 5| Step: 10
Training loss: 0.8671850599649829
Validation loss: 2.4296597435433496

Epoch: 303| Step: 0
Training loss: 0.7506783517113831
Validation loss: 2.4221649409195645

Epoch: 5| Step: 1
Training loss: 0.9333338036422453
Validation loss: 2.3836910549298125

Epoch: 5| Step: 2
Training loss: 0.9310329862849923
Validation loss: 2.378314636421656

Epoch: 5| Step: 3
Training loss: 0.6299200475761574
Validation loss: 2.409308105551365

Epoch: 5| Step: 4
Training loss: 0.7558056716175174
Validation loss: 2.4290635710804707

Epoch: 5| Step: 5
Training loss: 0.866805636897592
Validation loss: 2.433459309662913

Epoch: 5| Step: 6
Training loss: 0.4791770412178884
Validation loss: 2.4548696690387044

Epoch: 5| Step: 7
Training loss: 0.6114103365575604
Validation loss: 2.501976505869717

Epoch: 5| Step: 8
Training loss: 0.6986281388670074
Validation loss: 2.5214252927767826

Epoch: 5| Step: 9
Training loss: 0.53447178415917
Validation loss: 2.4653208697112285

Epoch: 5| Step: 10
Training loss: 0.4934990679820032
Validation loss: 2.3967153599325797

Epoch: 304| Step: 0
Training loss: 0.6038318780700236
Validation loss: 2.35266706292921

Epoch: 5| Step: 1
Training loss: 0.7632771908701921
Validation loss: 2.37722041441474

Epoch: 5| Step: 2
Training loss: 0.8248257684238051
Validation loss: 2.3499721477230815

Epoch: 5| Step: 3
Training loss: 0.711141661788248
Validation loss: 2.3952107669709597

Epoch: 5| Step: 4
Training loss: 0.816551962082638
Validation loss: 2.4793427634800027

Epoch: 5| Step: 5
Training loss: 0.4523706899207304
Validation loss: 2.5291768867721505

Epoch: 5| Step: 6
Training loss: 0.6721302700818698
Validation loss: 2.506394343709673

Epoch: 5| Step: 7
Training loss: 0.6750913416907778
Validation loss: 2.4777030798860404

Epoch: 5| Step: 8
Training loss: 0.8280405685281108
Validation loss: 2.435660442446492

Epoch: 5| Step: 9
Training loss: 0.7352075119064411
Validation loss: 2.4161554551859026

Epoch: 5| Step: 10
Training loss: 0.7150764711874132
Validation loss: 2.3718988133363377

Epoch: 305| Step: 0
Training loss: 0.8040073075460592
Validation loss: 2.3267796641610508

Epoch: 5| Step: 1
Training loss: 0.897596479771591
Validation loss: 2.3383334195231127

Epoch: 5| Step: 2
Training loss: 0.436160250123992
Validation loss: 2.427228380798576

Epoch: 5| Step: 3
Training loss: 0.43557087442966225
Validation loss: 2.484462184179825

Epoch: 5| Step: 4
Training loss: 0.7971381332681836
Validation loss: 2.476199272156169

Epoch: 5| Step: 5
Training loss: 0.7142352239611188
Validation loss: 2.4962722663388117

Epoch: 5| Step: 6
Training loss: 0.9677400246403913
Validation loss: 2.518254046593943

Epoch: 5| Step: 7
Training loss: 0.830979986004871
Validation loss: 2.4810412031141738

Epoch: 5| Step: 8
Training loss: 0.6042454574991868
Validation loss: 2.4290408375965256

Epoch: 5| Step: 9
Training loss: 0.4585133022211167
Validation loss: 2.4106676663293807

Epoch: 5| Step: 10
Training loss: 0.6629184966558601
Validation loss: 2.3589703960584676

Epoch: 306| Step: 0
Training loss: 0.5693032204599051
Validation loss: 2.3784866699837037

Epoch: 5| Step: 1
Training loss: 0.7207075496217288
Validation loss: 2.4172404753354044

Epoch: 5| Step: 2
Training loss: 0.6492309771142663
Validation loss: 2.4002366942245486

Epoch: 5| Step: 3
Training loss: 0.5993253302255516
Validation loss: 2.472126313624724

Epoch: 5| Step: 4
Training loss: 0.646400653684871
Validation loss: 2.49810741014825

Epoch: 5| Step: 5
Training loss: 0.5784268235715967
Validation loss: 2.507104819233599

Epoch: 5| Step: 6
Training loss: 0.5744875843011263
Validation loss: 2.4903961521580014

Epoch: 5| Step: 7
Training loss: 0.7689830163263334
Validation loss: 2.4572649894343312

Epoch: 5| Step: 8
Training loss: 0.6457506608859943
Validation loss: 2.4080675652158434

Epoch: 5| Step: 9
Training loss: 0.9893357452393596
Validation loss: 2.3928215803384663

Epoch: 5| Step: 10
Training loss: 0.8612148357460065
Validation loss: 2.400834110332481

Epoch: 307| Step: 0
Training loss: 0.7715573433278445
Validation loss: 2.4052139723928256

Epoch: 5| Step: 1
Training loss: 0.6410777655218852
Validation loss: 2.4345577963238334

Epoch: 5| Step: 2
Training loss: 0.5426989646683843
Validation loss: 2.48038625995834

Epoch: 5| Step: 3
Training loss: 0.8951537119609204
Validation loss: 2.4811021655743914

Epoch: 5| Step: 4
Training loss: 0.7471250426745709
Validation loss: 2.5180841450336833

Epoch: 5| Step: 5
Training loss: 0.7151283156356936
Validation loss: 2.5070070011919063

Epoch: 5| Step: 6
Training loss: 0.5596456959595305
Validation loss: 2.516294744475904

Epoch: 5| Step: 7
Training loss: 0.9216893542591775
Validation loss: 2.4956444494426

Epoch: 5| Step: 8
Training loss: 0.3118312713874126
Validation loss: 2.424309903332645

Epoch: 5| Step: 9
Training loss: 0.5594479625151016
Validation loss: 2.3732872374702536

Epoch: 5| Step: 10
Training loss: 0.8102448785579395
Validation loss: 2.3538648248676446

Epoch: 308| Step: 0
Training loss: 0.8880923550946268
Validation loss: 2.3538138415315704

Epoch: 5| Step: 1
Training loss: 0.3224837403116746
Validation loss: 2.344101317405563

Epoch: 5| Step: 2
Training loss: 0.5372050529572537
Validation loss: 2.3952145933598845

Epoch: 5| Step: 3
Training loss: 0.770406931569259
Validation loss: 2.396185666500553

Epoch: 5| Step: 4
Training loss: 0.5377989902162701
Validation loss: 2.4106180970403877

Epoch: 5| Step: 5
Training loss: 0.6275767851959709
Validation loss: 2.4313097364320146

Epoch: 5| Step: 6
Training loss: 0.4276635098215699
Validation loss: 2.4459977112353055

Epoch: 5| Step: 7
Training loss: 0.6809960845773089
Validation loss: 2.4204650288947778

Epoch: 5| Step: 8
Training loss: 0.9392551522823109
Validation loss: 2.3459285813427853

Epoch: 5| Step: 9
Training loss: 0.8766845767714265
Validation loss: 2.3543154469559493

Epoch: 5| Step: 10
Training loss: 0.8082117477554381
Validation loss: 2.3281533233423892

Epoch: 309| Step: 0
Training loss: 0.709360028415605
Validation loss: 2.3630957518196145

Epoch: 5| Step: 1
Training loss: 0.7424804912277634
Validation loss: 2.4100182513485104

Epoch: 5| Step: 2
Training loss: 0.5985193191651332
Validation loss: 2.5000338070132058

Epoch: 5| Step: 3
Training loss: 0.7258263416880577
Validation loss: 2.5536745553234828

Epoch: 5| Step: 4
Training loss: 0.5754866323766257
Validation loss: 2.5627834174340687

Epoch: 5| Step: 5
Training loss: 0.7546755171746592
Validation loss: 2.5130161450917368

Epoch: 5| Step: 6
Training loss: 0.8946943509195656
Validation loss: 2.4799683523217975

Epoch: 5| Step: 7
Training loss: 0.5519336791503996
Validation loss: 2.464789819186721

Epoch: 5| Step: 8
Training loss: 0.7035587880027425
Validation loss: 2.4137736080367835

Epoch: 5| Step: 9
Training loss: 0.5859204607711274
Validation loss: 2.3660431602387417

Epoch: 5| Step: 10
Training loss: 0.5320287494348588
Validation loss: 2.3643042426023917

Epoch: 310| Step: 0
Training loss: 0.941243549390678
Validation loss: 2.356308296069772

Epoch: 5| Step: 1
Training loss: 0.4099904769861488
Validation loss: 2.383720891041865

Epoch: 5| Step: 2
Training loss: 0.6758195943372719
Validation loss: 2.3771822617867113

Epoch: 5| Step: 3
Training loss: 0.7063519919014636
Validation loss: 2.4454368138518903

Epoch: 5| Step: 4
Training loss: 0.6678372526959016
Validation loss: 2.421005115030776

Epoch: 5| Step: 5
Training loss: 0.6972588504066791
Validation loss: 2.3979050683737935

Epoch: 5| Step: 6
Training loss: 0.6390146624654439
Validation loss: 2.3817405447984004

Epoch: 5| Step: 7
Training loss: 0.22136105732383857
Validation loss: 2.371626378176381

Epoch: 5| Step: 8
Training loss: 0.5920528701696548
Validation loss: 2.382734434401322

Epoch: 5| Step: 9
Training loss: 0.740812091294001
Validation loss: 2.4200404464211616

Epoch: 5| Step: 10
Training loss: 0.8291320076284995
Validation loss: 2.459294128443434

Epoch: 311| Step: 0
Training loss: 0.6487319921004479
Validation loss: 2.455362680272055

Epoch: 5| Step: 1
Training loss: 0.7304716059175037
Validation loss: 2.452196825424101

Epoch: 5| Step: 2
Training loss: 0.753619322258876
Validation loss: 2.4171847632141334

Epoch: 5| Step: 3
Training loss: 0.4261976183590697
Validation loss: 2.429954413646369

Epoch: 5| Step: 4
Training loss: 0.22972796077267055
Validation loss: 2.421041537225617

Epoch: 5| Step: 5
Training loss: 0.8099751121912525
Validation loss: 2.398653790837438

Epoch: 5| Step: 6
Training loss: 0.673499516510312
Validation loss: 2.4429605162604133

Epoch: 5| Step: 7
Training loss: 0.7081316819847909
Validation loss: 2.4142277333792386

Epoch: 5| Step: 8
Training loss: 0.8329044828021541
Validation loss: 2.4231444869840786

Epoch: 5| Step: 9
Training loss: 0.4541756190138022
Validation loss: 2.4648841027871504

Epoch: 5| Step: 10
Training loss: 0.7692157466503575
Validation loss: 2.4457279415797557

Epoch: 312| Step: 0
Training loss: 0.6318635300709303
Validation loss: 2.456772788823935

Epoch: 5| Step: 1
Training loss: 0.688140440792739
Validation loss: 2.4838795048170508

Epoch: 5| Step: 2
Training loss: 0.6389772344288902
Validation loss: 2.4508577718252456

Epoch: 5| Step: 3
Training loss: 0.4512951670045338
Validation loss: 2.4465934503950835

Epoch: 5| Step: 4
Training loss: 0.9267631506489767
Validation loss: 2.4341132655460997

Epoch: 5| Step: 5
Training loss: 0.8989724266801078
Validation loss: 2.4190814634258615

Epoch: 5| Step: 6
Training loss: 0.7410702377086532
Validation loss: 2.448289098708673

Epoch: 5| Step: 7
Training loss: 0.28347180216780604
Validation loss: 2.4146070223643417

Epoch: 5| Step: 8
Training loss: 0.6376312363870559
Validation loss: 2.465864841185428

Epoch: 5| Step: 9
Training loss: 0.43080164642807456
Validation loss: 2.4295293152888995

Epoch: 5| Step: 10
Training loss: 0.5591156662064471
Validation loss: 2.386389563024157

Epoch: 313| Step: 0
Training loss: 0.8885397005823408
Validation loss: 2.380942231634954

Epoch: 5| Step: 1
Training loss: 0.6323931210951456
Validation loss: 2.4294024921747637

Epoch: 5| Step: 2
Training loss: 0.697719864118292
Validation loss: 2.4203095954506813

Epoch: 5| Step: 3
Training loss: 0.5927859561107327
Validation loss: 2.4710229825741306

Epoch: 5| Step: 4
Training loss: 0.41033586474773276
Validation loss: 2.4851587263714947

Epoch: 5| Step: 5
Training loss: 0.5622239495124385
Validation loss: 2.544216376636134

Epoch: 5| Step: 6
Training loss: 0.8271337730792208
Validation loss: 2.5636122755934725

Epoch: 5| Step: 7
Training loss: 0.4858429568397043
Validation loss: 2.535045188600881

Epoch: 5| Step: 8
Training loss: 0.6146651041191346
Validation loss: 2.4835007230056245

Epoch: 5| Step: 9
Training loss: 0.5743518078327661
Validation loss: 2.4536219152948515

Epoch: 5| Step: 10
Training loss: 0.7125537651255378
Validation loss: 2.4272527060380487

Epoch: 314| Step: 0
Training loss: 0.5850750233968747
Validation loss: 2.401450099048438

Epoch: 5| Step: 1
Training loss: 0.6648482442450666
Validation loss: 2.3867160877731

Epoch: 5| Step: 2
Training loss: 0.8603165064066124
Validation loss: 2.40906716125389

Epoch: 5| Step: 3
Training loss: 0.4786109362289681
Validation loss: 2.4130536103207696

Epoch: 5| Step: 4
Training loss: 0.722255533827685
Validation loss: 2.428707087883867

Epoch: 5| Step: 5
Training loss: 0.824612853215922
Validation loss: 2.4606537477739017

Epoch: 5| Step: 6
Training loss: 0.5764986566278136
Validation loss: 2.4346281076308527

Epoch: 5| Step: 7
Training loss: 0.7689329813461905
Validation loss: 2.4425634270376606

Epoch: 5| Step: 8
Training loss: 0.6070862115553065
Validation loss: 2.455479237536335

Epoch: 5| Step: 9
Training loss: 0.3040375256842993
Validation loss: 2.4564800406161136

Epoch: 5| Step: 10
Training loss: 0.44768594373714493
Validation loss: 2.451726346084446

Epoch: 315| Step: 0
Training loss: 0.6028021635254027
Validation loss: 2.4645286909816324

Epoch: 5| Step: 1
Training loss: 0.6008468929388522
Validation loss: 2.4845401592670373

Epoch: 5| Step: 2
Training loss: 0.41805303918025544
Validation loss: 2.4614320382136103

Epoch: 5| Step: 3
Training loss: 0.4591433959794238
Validation loss: 2.4957488811891295

Epoch: 5| Step: 4
Training loss: 0.7338749420784557
Validation loss: 2.419930893568859

Epoch: 5| Step: 5
Training loss: 0.8034054440929026
Validation loss: 2.4235000995893645

Epoch: 5| Step: 6
Training loss: 0.7660497538167631
Validation loss: 2.376615362460013

Epoch: 5| Step: 7
Training loss: 0.5956243744373539
Validation loss: 2.3343510470200806

Epoch: 5| Step: 8
Training loss: 0.7420194335176573
Validation loss: 2.322782522446901

Epoch: 5| Step: 9
Training loss: 0.30641500105511926
Validation loss: 2.2936307736801544

Epoch: 5| Step: 10
Training loss: 0.8363025260474793
Validation loss: 2.3454558663881677

Epoch: 316| Step: 0
Training loss: 0.6462325098190705
Validation loss: 2.4035088371839817

Epoch: 5| Step: 1
Training loss: 0.671283594707988
Validation loss: 2.395726875055067

Epoch: 5| Step: 2
Training loss: 0.7536225649904593
Validation loss: 2.474562037608832

Epoch: 5| Step: 3
Training loss: 0.6000644808135482
Validation loss: 2.5059011036725916

Epoch: 5| Step: 4
Training loss: 0.5113865013983147
Validation loss: 2.462348460324678

Epoch: 5| Step: 5
Training loss: 0.6167270536325214
Validation loss: 2.4219882183094423

Epoch: 5| Step: 6
Training loss: 0.8188078022711368
Validation loss: 2.381222099987172

Epoch: 5| Step: 7
Training loss: 0.6947945798234239
Validation loss: 2.359162314861321

Epoch: 5| Step: 8
Training loss: 0.43130146700815
Validation loss: 2.347849337690349

Epoch: 5| Step: 9
Training loss: 0.5875079408068398
Validation loss: 2.3621206849777088

Epoch: 5| Step: 10
Training loss: 0.6799529423278974
Validation loss: 2.3791918588937406

Epoch: 317| Step: 0
Training loss: 0.40907950984481034
Validation loss: 2.4303320172398775

Epoch: 5| Step: 1
Training loss: 0.49787359776300616
Validation loss: 2.4579698646056

Epoch: 5| Step: 2
Training loss: 0.26043520225681244
Validation loss: 2.475202121645745

Epoch: 5| Step: 3
Training loss: 0.5374943688563413
Validation loss: 2.459900539135641

Epoch: 5| Step: 4
Training loss: 0.6053272697289277
Validation loss: 2.503375141842305

Epoch: 5| Step: 5
Training loss: 0.7645537219086617
Validation loss: 2.445296061192984

Epoch: 5| Step: 6
Training loss: 0.850385570029224
Validation loss: 2.449630172848184

Epoch: 5| Step: 7
Training loss: 0.5630905971539393
Validation loss: 2.3853364925521574

Epoch: 5| Step: 8
Training loss: 0.7183512120407988
Validation loss: 2.3957878500824106

Epoch: 5| Step: 9
Training loss: 0.6649073443720441
Validation loss: 2.364389028223362

Epoch: 5| Step: 10
Training loss: 0.9141735433309995
Validation loss: 2.3822965620490018

Epoch: 318| Step: 0
Training loss: 0.5111375959359843
Validation loss: 2.392581990958584

Epoch: 5| Step: 1
Training loss: 0.3756026551428539
Validation loss: 2.400530666899799

Epoch: 5| Step: 2
Training loss: 0.7960659857074106
Validation loss: 2.432299053453821

Epoch: 5| Step: 3
Training loss: 0.4244690544780568
Validation loss: 2.4537375804598582

Epoch: 5| Step: 4
Training loss: 0.6343797655349405
Validation loss: 2.4725738088115956

Epoch: 5| Step: 5
Training loss: 0.22915464698452434
Validation loss: 2.4990882790267523

Epoch: 5| Step: 6
Training loss: 0.7263301765057589
Validation loss: 2.403379036182938

Epoch: 5| Step: 7
Training loss: 0.6937293341711769
Validation loss: 2.4245953374369895

Epoch: 5| Step: 8
Training loss: 0.5744129034327046
Validation loss: 2.3518484885592805

Epoch: 5| Step: 9
Training loss: 0.9418371013972585
Validation loss: 2.3268776785767917

Epoch: 5| Step: 10
Training loss: 0.6810951345612992
Validation loss: 2.355401358839895

Epoch: 319| Step: 0
Training loss: 0.8027145494672004
Validation loss: 2.3561342057462404

Epoch: 5| Step: 1
Training loss: 0.5934803249902973
Validation loss: 2.3800730137799

Epoch: 5| Step: 2
Training loss: 0.49717347099512954
Validation loss: 2.4143607216924146

Epoch: 5| Step: 3
Training loss: 0.5040378546557889
Validation loss: 2.4797192448312018

Epoch: 5| Step: 4
Training loss: 0.4880274456340237
Validation loss: 2.5262743119758895

Epoch: 5| Step: 5
Training loss: 0.7495995883193458
Validation loss: 2.5016938142293488

Epoch: 5| Step: 6
Training loss: 0.4966899263239412
Validation loss: 2.416853697699587

Epoch: 5| Step: 7
Training loss: 0.7026632488191435
Validation loss: 2.411121084807178

Epoch: 5| Step: 8
Training loss: 0.5034132623313735
Validation loss: 2.356815667078071

Epoch: 5| Step: 9
Training loss: 0.9379396679189034
Validation loss: 2.3400482280673955

Epoch: 5| Step: 10
Training loss: 0.2618757318017608
Validation loss: 2.317993386190495

Epoch: 320| Step: 0
Training loss: 0.6826254608133182
Validation loss: 2.348688357341965

Epoch: 5| Step: 1
Training loss: 0.556811283118378
Validation loss: 2.3809131052730197

Epoch: 5| Step: 2
Training loss: 0.6027351690894067
Validation loss: 2.4553264539612227

Epoch: 5| Step: 3
Training loss: 0.7199667707033799
Validation loss: 2.479517446471185

Epoch: 5| Step: 4
Training loss: 0.6725489319226005
Validation loss: 2.4826184357091443

Epoch: 5| Step: 5
Training loss: 0.6690038056799922
Validation loss: 2.448770104540211

Epoch: 5| Step: 6
Training loss: 0.666574797161429
Validation loss: 2.4001105540715675

Epoch: 5| Step: 7
Training loss: 0.733719106735441
Validation loss: 2.3879575373534228

Epoch: 5| Step: 8
Training loss: 0.4780520782461837
Validation loss: 2.3595448012961797

Epoch: 5| Step: 9
Training loss: 0.501052434280812
Validation loss: 2.361948393100615

Epoch: 5| Step: 10
Training loss: 0.45129092408691673
Validation loss: 2.3648410082285367

Epoch: 321| Step: 0
Training loss: 0.5310344258659442
Validation loss: 2.39382976273896

Epoch: 5| Step: 1
Training loss: 0.5087377482070754
Validation loss: 2.4412006287318273

Epoch: 5| Step: 2
Training loss: 0.579363630156489
Validation loss: 2.5167103696436426

Epoch: 5| Step: 3
Training loss: 0.759476398244446
Validation loss: 2.533035823205597

Epoch: 5| Step: 4
Training loss: 0.5851509919076749
Validation loss: 2.547274161350917

Epoch: 5| Step: 5
Training loss: 0.6984078377520407
Validation loss: 2.5398777987903447

Epoch: 5| Step: 6
Training loss: 0.7442051016040396
Validation loss: 2.487906337873106

Epoch: 5| Step: 7
Training loss: 0.6731675600501027
Validation loss: 2.43922486132159

Epoch: 5| Step: 8
Training loss: 0.6344505349651146
Validation loss: 2.362730476555884

Epoch: 5| Step: 9
Training loss: 0.6421523379238679
Validation loss: 2.364360540975547

Epoch: 5| Step: 10
Training loss: 0.2335348249514269
Validation loss: 2.361132557084103

Epoch: 322| Step: 0
Training loss: 0.3891056075209957
Validation loss: 2.351986674394815

Epoch: 5| Step: 1
Training loss: 0.3414297148193868
Validation loss: 2.433161862057883

Epoch: 5| Step: 2
Training loss: 0.6725364135257522
Validation loss: 2.4426590399190937

Epoch: 5| Step: 3
Training loss: 0.6676456049010911
Validation loss: 2.4499970289584425

Epoch: 5| Step: 4
Training loss: 0.5609818741187207
Validation loss: 2.455841254676508

Epoch: 5| Step: 5
Training loss: 0.6027601878089595
Validation loss: 2.434694240336978

Epoch: 5| Step: 6
Training loss: 0.7338967084680625
Validation loss: 2.4030106742007

Epoch: 5| Step: 7
Training loss: 0.7380287909409645
Validation loss: 2.3238058444360994

Epoch: 5| Step: 8
Training loss: 0.7154484260306633
Validation loss: 2.3242773594459027

Epoch: 5| Step: 9
Training loss: 0.5961666617542353
Validation loss: 2.36857320749327

Epoch: 5| Step: 10
Training loss: 0.5347236778465154
Validation loss: 2.3847894975692983

Epoch: 323| Step: 0
Training loss: 0.6611853258923125
Validation loss: 2.4249788536889465

Epoch: 5| Step: 1
Training loss: 0.4975432598532665
Validation loss: 2.4441150001715126

Epoch: 5| Step: 2
Training loss: 0.5067051772123962
Validation loss: 2.432453967393448

Epoch: 5| Step: 3
Training loss: 0.7610634748451522
Validation loss: 2.42462596015166

Epoch: 5| Step: 4
Training loss: 0.6854827068326211
Validation loss: 2.442233633113027

Epoch: 5| Step: 5
Training loss: 0.7108153772788116
Validation loss: 2.405202694416948

Epoch: 5| Step: 6
Training loss: 0.47893023531965984
Validation loss: 2.3959450990378564

Epoch: 5| Step: 7
Training loss: 0.7304186880327085
Validation loss: 2.395658444035459

Epoch: 5| Step: 8
Training loss: 0.516651086290333
Validation loss: 2.3846521907489504

Epoch: 5| Step: 9
Training loss: 0.643234891261111
Validation loss: 2.3759829489975637

Epoch: 5| Step: 10
Training loss: 0.27809214022824535
Validation loss: 2.334310813781666

Epoch: 324| Step: 0
Training loss: 0.6080125102086226
Validation loss: 2.353068709257517

Epoch: 5| Step: 1
Training loss: 0.6896065171215927
Validation loss: 2.3575681556108887

Epoch: 5| Step: 2
Training loss: 0.6789814800902578
Validation loss: 2.3856532707685156

Epoch: 5| Step: 3
Training loss: 0.6802301542589935
Validation loss: 2.381198240908398

Epoch: 5| Step: 4
Training loss: 0.21624021977981583
Validation loss: 2.428427383802283

Epoch: 5| Step: 5
Training loss: 0.5771179191150013
Validation loss: 2.4222873914863627

Epoch: 5| Step: 6
Training loss: 0.4155707151771628
Validation loss: 2.4172887146529156

Epoch: 5| Step: 7
Training loss: 0.7597027044057569
Validation loss: 2.474956943969834

Epoch: 5| Step: 8
Training loss: 0.4692338036235214
Validation loss: 2.467277221507174

Epoch: 5| Step: 9
Training loss: 0.5491324019077564
Validation loss: 2.4954144004649152

Epoch: 5| Step: 10
Training loss: 0.7284788066161175
Validation loss: 2.4701937821225126

Epoch: 325| Step: 0
Training loss: 0.8231546484402055
Validation loss: 2.450151643712251

Epoch: 5| Step: 1
Training loss: 0.3348436177939235
Validation loss: 2.435744351415494

Epoch: 5| Step: 2
Training loss: 0.4613139829478702
Validation loss: 2.4215461838533767

Epoch: 5| Step: 3
Training loss: 0.4511251879559826
Validation loss: 2.388069473236268

Epoch: 5| Step: 4
Training loss: 0.30704275114537705
Validation loss: 2.379989608229406

Epoch: 5| Step: 5
Training loss: 0.7526040170706806
Validation loss: 2.3491173216026233

Epoch: 5| Step: 6
Training loss: 0.7255126176758264
Validation loss: 2.381315820290459

Epoch: 5| Step: 7
Training loss: 0.4977937391664838
Validation loss: 2.4185227390600135

Epoch: 5| Step: 8
Training loss: 0.6375495545443826
Validation loss: 2.434856448475478

Epoch: 5| Step: 9
Training loss: 0.6573253404321254
Validation loss: 2.4381880145470074

Epoch: 5| Step: 10
Training loss: 0.6988236573760429
Validation loss: 2.438483667369672

Epoch: 326| Step: 0
Training loss: 0.5808777868435104
Validation loss: 2.42009492332036

Epoch: 5| Step: 1
Training loss: 0.45922862919385726
Validation loss: 2.4407539141300627

Epoch: 5| Step: 2
Training loss: 0.6892764375699119
Validation loss: 2.4042068285582237

Epoch: 5| Step: 3
Training loss: 0.5891081157395968
Validation loss: 2.449207798168139

Epoch: 5| Step: 4
Training loss: 0.4785576471055528
Validation loss: 2.4691251877511373

Epoch: 5| Step: 5
Training loss: 0.6075905078216175
Validation loss: 2.4404075525796274

Epoch: 5| Step: 6
Training loss: 0.3227044441308114
Validation loss: 2.4706224283002696

Epoch: 5| Step: 7
Training loss: 0.6733227811315413
Validation loss: 2.437328204255438

Epoch: 5| Step: 8
Training loss: 0.9044828944510354
Validation loss: 2.3827736256785634

Epoch: 5| Step: 9
Training loss: 0.5314957386951313
Validation loss: 2.367528897758687

Epoch: 5| Step: 10
Training loss: 0.5538932056263041
Validation loss: 2.403795297234585

Epoch: 327| Step: 0
Training loss: 0.5510702254376956
Validation loss: 2.38456731014362

Epoch: 5| Step: 1
Training loss: 0.8331634268802298
Validation loss: 2.3727355269342656

Epoch: 5| Step: 2
Training loss: 0.7412290307049353
Validation loss: 2.380819299394863

Epoch: 5| Step: 3
Training loss: 0.3456645340581646
Validation loss: 2.3367410061798717

Epoch: 5| Step: 4
Training loss: 0.6852314106376183
Validation loss: 2.367768258011648

Epoch: 5| Step: 5
Training loss: 0.5694982908991889
Validation loss: 2.3886373869550925

Epoch: 5| Step: 6
Training loss: 0.631130974945115
Validation loss: 2.4432052112895404

Epoch: 5| Step: 7
Training loss: 0.23877291686733287
Validation loss: 2.4208418215264187

Epoch: 5| Step: 8
Training loss: 0.740467970735583
Validation loss: 2.478307338438445

Epoch: 5| Step: 9
Training loss: 0.41707345853974687
Validation loss: 2.429202576852045

Epoch: 5| Step: 10
Training loss: 0.4030759500633475
Validation loss: 2.483307106968765

Epoch: 328| Step: 0
Training loss: 0.6503640475871347
Validation loss: 2.4851330976598605

Epoch: 5| Step: 1
Training loss: 0.5535954215304177
Validation loss: 2.451246362749044

Epoch: 5| Step: 2
Training loss: 0.5723405600169119
Validation loss: 2.417116849536435

Epoch: 5| Step: 3
Training loss: 0.29122571594277336
Validation loss: 2.385013655003465

Epoch: 5| Step: 4
Training loss: 0.5447587073174238
Validation loss: 2.368508801534537

Epoch: 5| Step: 5
Training loss: 0.5857508298434128
Validation loss: 2.3718083216111197

Epoch: 5| Step: 6
Training loss: 0.612194629372584
Validation loss: 2.3950715175756443

Epoch: 5| Step: 7
Training loss: 0.519731526026773
Validation loss: 2.389809881488322

Epoch: 5| Step: 8
Training loss: 0.6663802371029489
Validation loss: 2.4106785874730283

Epoch: 5| Step: 9
Training loss: 0.7345036738870561
Validation loss: 2.4169887365948606

Epoch: 5| Step: 10
Training loss: 0.5578471977063664
Validation loss: 2.4452120768744017

Epoch: 329| Step: 0
Training loss: 0.6499081675141725
Validation loss: 2.414725455044654

Epoch: 5| Step: 1
Training loss: 0.5710817661932801
Validation loss: 2.411739820814315

Epoch: 5| Step: 2
Training loss: 0.6715316560530901
Validation loss: 2.4174333091165012

Epoch: 5| Step: 3
Training loss: 0.6565594170782598
Validation loss: 2.447335645588614

Epoch: 5| Step: 4
Training loss: 0.5087589540560582
Validation loss: 2.441904336896867

Epoch: 5| Step: 5
Training loss: 0.5537810642837756
Validation loss: 2.402680492769066

Epoch: 5| Step: 6
Training loss: 0.4708205745313019
Validation loss: 2.406406953079925

Epoch: 5| Step: 7
Training loss: 0.5133512533401998
Validation loss: 2.388469417240946

Epoch: 5| Step: 8
Training loss: 0.7188052280603145
Validation loss: 2.3996356262801095

Epoch: 5| Step: 9
Training loss: 0.3821407184681043
Validation loss: 2.3808814481674228

Epoch: 5| Step: 10
Training loss: 0.5910239633197631
Validation loss: 2.369143895095735

Epoch: 330| Step: 0
Training loss: 0.48603796824936557
Validation loss: 2.420130063691326

Epoch: 5| Step: 1
Training loss: 0.5939422597308046
Validation loss: 2.477095093048003

Epoch: 5| Step: 2
Training loss: 0.6400435297661392
Validation loss: 2.460146034061196

Epoch: 5| Step: 3
Training loss: 0.5491997217650657
Validation loss: 2.4828665336796947

Epoch: 5| Step: 4
Training loss: 0.49336795935332045
Validation loss: 2.4431689138409243

Epoch: 5| Step: 5
Training loss: 0.3781091820742258
Validation loss: 2.3764696501704825

Epoch: 5| Step: 6
Training loss: 0.5254480550356293
Validation loss: 2.328679102182798

Epoch: 5| Step: 7
Training loss: 0.7028591077114735
Validation loss: 2.290937367695969

Epoch: 5| Step: 8
Training loss: 0.5094661198189959
Validation loss: 2.26688203094647

Epoch: 5| Step: 9
Training loss: 0.8117748105293418
Validation loss: 2.2891090973778625

Epoch: 5| Step: 10
Training loss: 0.5121806440656781
Validation loss: 2.3344175122452255

Epoch: 331| Step: 0
Training loss: 0.435001271043214
Validation loss: 2.3803321165517497

Epoch: 5| Step: 1
Training loss: 0.6790000903350029
Validation loss: 2.4430549561589094

Epoch: 5| Step: 2
Training loss: 0.8001493240113309
Validation loss: 2.481573428962601

Epoch: 5| Step: 3
Training loss: 0.6987544601448215
Validation loss: 2.4901554900255225

Epoch: 5| Step: 4
Training loss: 0.5697903267555824
Validation loss: 2.5157540161581284

Epoch: 5| Step: 5
Training loss: 0.2523897660523677
Validation loss: 2.502412734128786

Epoch: 5| Step: 6
Training loss: 0.6238808864574906
Validation loss: 2.4654381010420154

Epoch: 5| Step: 7
Training loss: 0.45150463829108245
Validation loss: 2.4447269073350992

Epoch: 5| Step: 8
Training loss: 0.30856583867421616
Validation loss: 2.444871543145208

Epoch: 5| Step: 9
Training loss: 0.6106225472657717
Validation loss: 2.4081361194753934

Epoch: 5| Step: 10
Training loss: 0.565468320696189
Validation loss: 2.3919517079113035

Epoch: 332| Step: 0
Training loss: 0.6719534185023266
Validation loss: 2.368812417309111

Epoch: 5| Step: 1
Training loss: 0.41867926626484464
Validation loss: 2.3540060337187376

Epoch: 5| Step: 2
Training loss: 0.5891538969011237
Validation loss: 2.4109093215575186

Epoch: 5| Step: 3
Training loss: 0.24581505874555185
Validation loss: 2.4388060729407175

Epoch: 5| Step: 4
Training loss: 0.7295752788239253
Validation loss: 2.4482415005791953

Epoch: 5| Step: 5
Training loss: 0.6053178660756066
Validation loss: 2.4357976719442354

Epoch: 5| Step: 6
Training loss: 0.4877209003963495
Validation loss: 2.4176088716341315

Epoch: 5| Step: 7
Training loss: 0.7122260771777837
Validation loss: 2.4040027560897923

Epoch: 5| Step: 8
Training loss: 0.49372680585441037
Validation loss: 2.3798565132772103

Epoch: 5| Step: 9
Training loss: 0.7404711503172892
Validation loss: 2.362780673991286

Epoch: 5| Step: 10
Training loss: 0.1883775915690298
Validation loss: 2.36709024115875

Epoch: 333| Step: 0
Training loss: 0.36528995927330643
Validation loss: 2.3809351445634777

Epoch: 5| Step: 1
Training loss: 0.5800053457720811
Validation loss: 2.3660223382606405

Epoch: 5| Step: 2
Training loss: 0.594804905834823
Validation loss: 2.3776362995986045

Epoch: 5| Step: 3
Training loss: 0.6028198379378482
Validation loss: 2.4261668527284406

Epoch: 5| Step: 4
Training loss: 0.42880453074369324
Validation loss: 2.4133781102544827

Epoch: 5| Step: 5
Training loss: 0.3378793130204899
Validation loss: 2.470054610419512

Epoch: 5| Step: 6
Training loss: 0.5484450010998503
Validation loss: 2.4469387592784417

Epoch: 5| Step: 7
Training loss: 0.6612450914254833
Validation loss: 2.462565992524749

Epoch: 5| Step: 8
Training loss: 0.822581975614303
Validation loss: 2.450475930971442

Epoch: 5| Step: 9
Training loss: 0.5310485401758807
Validation loss: 2.4384877486127627

Epoch: 5| Step: 10
Training loss: 0.437582723426188
Validation loss: 2.421100592411547

Epoch: 334| Step: 0
Training loss: 0.5590948244988251
Validation loss: 2.4313688964941917

Epoch: 5| Step: 1
Training loss: 0.41743145928293596
Validation loss: 2.4047510256254814

Epoch: 5| Step: 2
Training loss: 0.46203340758876776
Validation loss: 2.432678170516133

Epoch: 5| Step: 3
Training loss: 0.7480718145371439
Validation loss: 2.3840861364358763

Epoch: 5| Step: 4
Training loss: 0.6698196155141318
Validation loss: 2.4011759525696057

Epoch: 5| Step: 5
Training loss: 0.4321736802865738
Validation loss: 2.4047441057343453

Epoch: 5| Step: 6
Training loss: 0.6095024855847017
Validation loss: 2.3549518453726117

Epoch: 5| Step: 7
Training loss: 0.5997844775865383
Validation loss: 2.3661441209927694

Epoch: 5| Step: 8
Training loss: 0.6728574533855195
Validation loss: 2.390683890758157

Epoch: 5| Step: 9
Training loss: 0.329301654423503
Validation loss: 2.4171645578402545

Epoch: 5| Step: 10
Training loss: 0.4600761577028437
Validation loss: 2.453516553526055

Epoch: 335| Step: 0
Training loss: 0.5733623476181389
Validation loss: 2.431711180901665

Epoch: 5| Step: 1
Training loss: 0.6386221070103686
Validation loss: 2.40807680916283

Epoch: 5| Step: 2
Training loss: 0.8053597910284391
Validation loss: 2.444601842173195

Epoch: 5| Step: 3
Training loss: 0.4744228734422805
Validation loss: 2.4073734556041946

Epoch: 5| Step: 4
Training loss: 0.4169850047294689
Validation loss: 2.3909360557385586

Epoch: 5| Step: 5
Training loss: 0.6384768406962772
Validation loss: 2.4021322706027233

Epoch: 5| Step: 6
Training loss: 0.6039860691159793
Validation loss: 2.3798568703772296

Epoch: 5| Step: 7
Training loss: 0.4327481073892374
Validation loss: 2.4191397547055686

Epoch: 5| Step: 8
Training loss: 0.4134909806150036
Validation loss: 2.4290010271019007

Epoch: 5| Step: 9
Training loss: 0.48846220096797943
Validation loss: 2.4339957235693768

Epoch: 5| Step: 10
Training loss: 0.48689483653586174
Validation loss: 2.460175800046187

Epoch: 336| Step: 0
Training loss: 0.552063686693044
Validation loss: 2.4951490807757044

Epoch: 5| Step: 1
Training loss: 0.5012614014867574
Validation loss: 2.4892545127574026

Epoch: 5| Step: 2
Training loss: 0.40070133713836376
Validation loss: 2.4470935164530654

Epoch: 5| Step: 3
Training loss: 0.46582629441872875
Validation loss: 2.401541287263532

Epoch: 5| Step: 4
Training loss: 0.6065253605741163
Validation loss: 2.362149970072162

Epoch: 5| Step: 5
Training loss: 0.5930909715624871
Validation loss: 2.346489456160795

Epoch: 5| Step: 6
Training loss: 0.45828007981118113
Validation loss: 2.3542098544950205

Epoch: 5| Step: 7
Training loss: 0.6034003088941785
Validation loss: 2.366407462655708

Epoch: 5| Step: 8
Training loss: 0.4350254033333385
Validation loss: 2.4246386291003343

Epoch: 5| Step: 9
Training loss: 0.7202923438837187
Validation loss: 2.4276401923667854

Epoch: 5| Step: 10
Training loss: 0.6352393392758993
Validation loss: 2.4809530079868876

Epoch: 337| Step: 0
Training loss: 0.6283283540248465
Validation loss: 2.4591341395062463

Epoch: 5| Step: 1
Training loss: 0.6276570584076169
Validation loss: 2.5341872939002505

Epoch: 5| Step: 2
Training loss: 0.46106023285939124
Validation loss: 2.4511554284241197

Epoch: 5| Step: 3
Training loss: 0.6028394151436555
Validation loss: 2.4259545957825437

Epoch: 5| Step: 4
Training loss: 0.7362576559734111
Validation loss: 2.389988409585678

Epoch: 5| Step: 5
Training loss: 0.7098269329560241
Validation loss: 2.321551466177783

Epoch: 5| Step: 6
Training loss: 0.47538742214807184
Validation loss: 2.3110081794822523

Epoch: 5| Step: 7
Training loss: 0.4841199326352184
Validation loss: 2.3113798717307925

Epoch: 5| Step: 8
Training loss: 0.23737400125832794
Validation loss: 2.381865958297342

Epoch: 5| Step: 9
Training loss: 0.47154475586347155
Validation loss: 2.4924281644413875

Epoch: 5| Step: 10
Training loss: 0.4897184506770136
Validation loss: 2.562154549024402

Epoch: 338| Step: 0
Training loss: 0.5724247525667231
Validation loss: 2.535708302365996

Epoch: 5| Step: 1
Training loss: 0.6087206236940053
Validation loss: 2.4756017764807803

Epoch: 5| Step: 2
Training loss: 0.7165351826534369
Validation loss: 2.426710972078362

Epoch: 5| Step: 3
Training loss: 0.4599609860948671
Validation loss: 2.3777325448427375

Epoch: 5| Step: 4
Training loss: 0.17664317634086346
Validation loss: 2.3550276151633924

Epoch: 5| Step: 5
Training loss: 0.44613382657170225
Validation loss: 2.361741506093705

Epoch: 5| Step: 6
Training loss: 0.5032335863160818
Validation loss: 2.3228412371105183

Epoch: 5| Step: 7
Training loss: 0.5893039380595603
Validation loss: 2.3489626326968533

Epoch: 5| Step: 8
Training loss: 0.7026870635276524
Validation loss: 2.444703601179904

Epoch: 5| Step: 9
Training loss: 0.5561843608317942
Validation loss: 2.4592615554345727

Epoch: 5| Step: 10
Training loss: 0.49603497915500977
Validation loss: 2.4942535766174263

Epoch: 339| Step: 0
Training loss: 0.6495858101576328
Validation loss: 2.5663751743355845

Epoch: 5| Step: 1
Training loss: 0.6336323172499905
Validation loss: 2.505507215578609

Epoch: 5| Step: 2
Training loss: 0.6005522183512679
Validation loss: 2.468521740019592

Epoch: 5| Step: 3
Training loss: 0.5820197801931931
Validation loss: 2.4261244817589596

Epoch: 5| Step: 4
Training loss: 0.6335178494411438
Validation loss: 2.388874989544109

Epoch: 5| Step: 5
Training loss: 0.33233167856852514
Validation loss: 2.3760147107511633

Epoch: 5| Step: 6
Training loss: 0.5318050290084061
Validation loss: 2.35025527613122

Epoch: 5| Step: 7
Training loss: 0.21411628673905575
Validation loss: 2.3480587747415798

Epoch: 5| Step: 8
Training loss: 0.3053863287365156
Validation loss: 2.34188488051656

Epoch: 5| Step: 9
Training loss: 0.6756818841636081
Validation loss: 2.331947093598117

Epoch: 5| Step: 10
Training loss: 0.5334238566624373
Validation loss: 2.371013244201767

Epoch: 340| Step: 0
Training loss: 0.49787941903756583
Validation loss: 2.4257939319379163

Epoch: 5| Step: 1
Training loss: 0.5645417404572678
Validation loss: 2.449295267009332

Epoch: 5| Step: 2
Training loss: 0.3963160791865641
Validation loss: 2.471483079385684

Epoch: 5| Step: 3
Training loss: 0.3081265425691816
Validation loss: 2.510945651219206

Epoch: 5| Step: 4
Training loss: 0.6274470110097434
Validation loss: 2.488406829387624

Epoch: 5| Step: 5
Training loss: 0.5726494657314976
Validation loss: 2.462479197038074

Epoch: 5| Step: 6
Training loss: 0.5969231041901925
Validation loss: 2.4331204436990417

Epoch: 5| Step: 7
Training loss: 0.6517890124788092
Validation loss: 2.3901361728007986

Epoch: 5| Step: 8
Training loss: 0.5232600010783216
Validation loss: 2.3317520596416825

Epoch: 5| Step: 9
Training loss: 0.46329305353936867
Validation loss: 2.357588447661365

Epoch: 5| Step: 10
Training loss: 0.5486552010161307
Validation loss: 2.3803740452447584

Epoch: 341| Step: 0
Training loss: 0.5257799769211841
Validation loss: 2.3967726222935615

Epoch: 5| Step: 1
Training loss: 0.8027186334184948
Validation loss: 2.425744043453632

Epoch: 5| Step: 2
Training loss: 0.5314924864771716
Validation loss: 2.4575972236243433

Epoch: 5| Step: 3
Training loss: 0.3934694107846321
Validation loss: 2.4612827478797943

Epoch: 5| Step: 4
Training loss: 0.6262683872561622
Validation loss: 2.4699028011065836

Epoch: 5| Step: 5
Training loss: 0.5337515445481406
Validation loss: 2.442372741112956

Epoch: 5| Step: 6
Training loss: 0.4121234041691603
Validation loss: 2.4042489870655253

Epoch: 5| Step: 7
Training loss: 0.44933231410996693
Validation loss: 2.401195553134265

Epoch: 5| Step: 8
Training loss: 0.5960793729675695
Validation loss: 2.3535614843865735

Epoch: 5| Step: 9
Training loss: 0.460675957396062
Validation loss: 2.3247722504039996

Epoch: 5| Step: 10
Training loss: 0.31885645388373063
Validation loss: 2.364262490304046

Epoch: 342| Step: 0
Training loss: 0.39374836588323675
Validation loss: 2.3891816172910727

Epoch: 5| Step: 1
Training loss: 0.6403867697288491
Validation loss: 2.4527826043474796

Epoch: 5| Step: 2
Training loss: 0.5227930742338437
Validation loss: 2.4607498563582926

Epoch: 5| Step: 3
Training loss: 0.2798174028970369
Validation loss: 2.4861438326128704

Epoch: 5| Step: 4
Training loss: 0.5443731026337205
Validation loss: 2.4870876558969632

Epoch: 5| Step: 5
Training loss: 0.5893036346270379
Validation loss: 2.4597589142409673

Epoch: 5| Step: 6
Training loss: 0.3278870628150712
Validation loss: 2.4587237679137623

Epoch: 5| Step: 7
Training loss: 0.8733715503341141
Validation loss: 2.396066169785063

Epoch: 5| Step: 8
Training loss: 0.5565460124671388
Validation loss: 2.428207002850054

Epoch: 5| Step: 9
Training loss: 0.31792546757973167
Validation loss: 2.4198925689215454

Epoch: 5| Step: 10
Training loss: 0.457088792878995
Validation loss: 2.4297672466106692

Epoch: 343| Step: 0
Training loss: 0.16904643235385328
Validation loss: 2.461011259865327

Epoch: 5| Step: 1
Training loss: 0.32071955333268265
Validation loss: 2.465844117720514

Epoch: 5| Step: 2
Training loss: 0.5356024114414882
Validation loss: 2.482443846484991

Epoch: 5| Step: 3
Training loss: 0.4536421389891036
Validation loss: 2.4517616134174416

Epoch: 5| Step: 4
Training loss: 0.55282826519229
Validation loss: 2.4532220300176117

Epoch: 5| Step: 5
Training loss: 0.524273191032765
Validation loss: 2.4257279830230227

Epoch: 5| Step: 6
Training loss: 0.5567390756378904
Validation loss: 2.433056826002558

Epoch: 5| Step: 7
Training loss: 0.6982774205421848
Validation loss: 2.414195226630023

Epoch: 5| Step: 8
Training loss: 0.24825210041269716
Validation loss: 2.4582978842716816

Epoch: 5| Step: 9
Training loss: 0.7690467664836784
Validation loss: 2.4303796016760484

Epoch: 5| Step: 10
Training loss: 0.5941854185415196
Validation loss: 2.4172026595341016

Epoch: 344| Step: 0
Training loss: 0.35900963994262264
Validation loss: 2.416835510273609

Epoch: 5| Step: 1
Training loss: 0.36851110721266833
Validation loss: 2.4047144515738745

Epoch: 5| Step: 2
Training loss: 0.450378877034944
Validation loss: 2.439752931135143

Epoch: 5| Step: 3
Training loss: 0.40674132200572183
Validation loss: 2.429171186015273

Epoch: 5| Step: 4
Training loss: 0.3255722335924619
Validation loss: 2.484072806621386

Epoch: 5| Step: 5
Training loss: 0.5060006905313537
Validation loss: 2.465524699822687

Epoch: 5| Step: 6
Training loss: 0.6636111576895016
Validation loss: 2.4610634840050682

Epoch: 5| Step: 7
Training loss: 0.7077901571423174
Validation loss: 2.5130730930160796

Epoch: 5| Step: 8
Training loss: 0.4039248168927898
Validation loss: 2.4993611770621533

Epoch: 5| Step: 9
Training loss: 0.5748896409982418
Validation loss: 2.4633153763649305

Epoch: 5| Step: 10
Training loss: 0.760053526160452
Validation loss: 2.4419056738843183

Epoch: 345| Step: 0
Training loss: 0.6370229637911394
Validation loss: 2.393219199434288

Epoch: 5| Step: 1
Training loss: 0.5531077387643385
Validation loss: 2.3416784123919605

Epoch: 5| Step: 2
Training loss: 0.4135471051368588
Validation loss: 2.304840489380101

Epoch: 5| Step: 3
Training loss: 0.49258189067565855
Validation loss: 2.3750450305955093

Epoch: 5| Step: 4
Training loss: 0.4156253398807828
Validation loss: 2.46893956661296

Epoch: 5| Step: 5
Training loss: 0.576134864782265
Validation loss: 2.5178591389999374

Epoch: 5| Step: 6
Training loss: 0.2371078114088813
Validation loss: 2.5456011296810543

Epoch: 5| Step: 7
Training loss: 0.5036561626281113
Validation loss: 2.583502023318492

Epoch: 5| Step: 8
Training loss: 0.2275512921235228
Validation loss: 2.5776027027332735

Epoch: 5| Step: 9
Training loss: 0.7214326138767579
Validation loss: 2.5326331889285463

Epoch: 5| Step: 10
Training loss: 0.7539948327395912
Validation loss: 2.466250444891427

Epoch: 346| Step: 0
Training loss: 0.3701226226488088
Validation loss: 2.4559158283658267

Epoch: 5| Step: 1
Training loss: 0.4669868050922797
Validation loss: 2.410392528003986

Epoch: 5| Step: 2
Training loss: 0.3525993316784701
Validation loss: 2.3938876343987974

Epoch: 5| Step: 3
Training loss: 0.5020662469713386
Validation loss: 2.399336936666355

Epoch: 5| Step: 4
Training loss: 0.5775967581720729
Validation loss: 2.469999038144265

Epoch: 5| Step: 5
Training loss: 0.4602897424504278
Validation loss: 2.5040796545673087

Epoch: 5| Step: 6
Training loss: 0.6161843851840513
Validation loss: 2.511951128370046

Epoch: 5| Step: 7
Training loss: 0.5829553117228206
Validation loss: 2.507043610674138

Epoch: 5| Step: 8
Training loss: 0.3530613841928714
Validation loss: 2.453964368826529

Epoch: 5| Step: 9
Training loss: 0.5569023186418759
Validation loss: 2.424508518109043

Epoch: 5| Step: 10
Training loss: 0.7222992298649719
Validation loss: 2.4232804331898974

Epoch: 347| Step: 0
Training loss: 0.16226674105683303
Validation loss: 2.41948837304849

Epoch: 5| Step: 1
Training loss: 0.47860944178577874
Validation loss: 2.4139718015025156

Epoch: 5| Step: 2
Training loss: 0.4231586002323745
Validation loss: 2.426322904148287

Epoch: 5| Step: 3
Training loss: 0.5989421897592321
Validation loss: 2.425035902184012

Epoch: 5| Step: 4
Training loss: 0.4610166320117476
Validation loss: 2.4725085830004483

Epoch: 5| Step: 5
Training loss: 0.7027996158054932
Validation loss: 2.4962067231304363

Epoch: 5| Step: 6
Training loss: 0.7202274230892965
Validation loss: 2.48331292554133

Epoch: 5| Step: 7
Training loss: 0.487971291390384
Validation loss: 2.530639071352541

Epoch: 5| Step: 8
Training loss: 0.3382237176228093
Validation loss: 2.439810382314506

Epoch: 5| Step: 9
Training loss: 0.3265217942781672
Validation loss: 2.406922051440023

Epoch: 5| Step: 10
Training loss: 0.6078763285957139
Validation loss: 2.3914650670193036

Epoch: 348| Step: 0
Training loss: 0.3161846373790966
Validation loss: 2.410982001503762

Epoch: 5| Step: 1
Training loss: 0.4399121747906131
Validation loss: 2.3909109809013156

Epoch: 5| Step: 2
Training loss: 0.5628322838457283
Validation loss: 2.418044174692882

Epoch: 5| Step: 3
Training loss: 0.600805177447745
Validation loss: 2.4195732491873527

Epoch: 5| Step: 4
Training loss: 0.5871381030538282
Validation loss: 2.4008071329663125

Epoch: 5| Step: 5
Training loss: 0.2923639794694987
Validation loss: 2.3972265664423076

Epoch: 5| Step: 6
Training loss: 0.5841117643395161
Validation loss: 2.420313278356258

Epoch: 5| Step: 7
Training loss: 0.43319577347594806
Validation loss: 2.429186001059065

Epoch: 5| Step: 8
Training loss: 0.422048356501481
Validation loss: 2.4399525966793707

Epoch: 5| Step: 9
Training loss: 0.4424809058698062
Validation loss: 2.462553473933535

Epoch: 5| Step: 10
Training loss: 0.7280805173064611
Validation loss: 2.480230445644549

Epoch: 349| Step: 0
Training loss: 0.49551650879069936
Validation loss: 2.428320399956332

Epoch: 5| Step: 1
Training loss: 0.4810498453036723
Validation loss: 2.4383595943719687

Epoch: 5| Step: 2
Training loss: 0.400289420386448
Validation loss: 2.413464776556691

Epoch: 5| Step: 3
Training loss: 0.42500588048344795
Validation loss: 2.457466402970956

Epoch: 5| Step: 4
Training loss: 0.6207909715737633
Validation loss: 2.4514532820866837

Epoch: 5| Step: 5
Training loss: 0.5281289083573225
Validation loss: 2.4403686870353223

Epoch: 5| Step: 6
Training loss: 0.37400132554630233
Validation loss: 2.4275709007804216

Epoch: 5| Step: 7
Training loss: 0.5489825374278828
Validation loss: 2.4262133169236284

Epoch: 5| Step: 8
Training loss: 0.6982049678672739
Validation loss: 2.396640487180601

Epoch: 5| Step: 9
Training loss: 0.1958994438472621
Validation loss: 2.47396742468795

Epoch: 5| Step: 10
Training loss: 0.5369163304985605
Validation loss: 2.469500874933422

Epoch: 350| Step: 0
Training loss: 0.5398143280005412
Validation loss: 2.4519554073936964

Epoch: 5| Step: 1
Training loss: 0.38031669492139836
Validation loss: 2.4620779327167357

Epoch: 5| Step: 2
Training loss: 0.19286272054918369
Validation loss: 2.4457131303036315

Epoch: 5| Step: 3
Training loss: 0.5213723508831101
Validation loss: 2.41081454330134

Epoch: 5| Step: 4
Training loss: 0.434261958418238
Validation loss: 2.414700006689971

Epoch: 5| Step: 5
Training loss: 0.2999180632197737
Validation loss: 2.3833022081233146

Epoch: 5| Step: 6
Training loss: 0.6583442649859212
Validation loss: 2.3899824520346797

Epoch: 5| Step: 7
Training loss: 0.5553417377148897
Validation loss: 2.3679814563507113

Epoch: 5| Step: 8
Training loss: 0.6909805970400615
Validation loss: 2.4063044311350414

Epoch: 5| Step: 9
Training loss: 0.3755562550861445
Validation loss: 2.3963109081246965

Epoch: 5| Step: 10
Training loss: 0.5550151179806344
Validation loss: 2.392477359286351

Epoch: 351| Step: 0
Training loss: 0.49904831079652534
Validation loss: 2.417182550823548

Epoch: 5| Step: 1
Training loss: 0.5185885373434274
Validation loss: 2.4693964564427757

Epoch: 5| Step: 2
Training loss: 0.5593822489433931
Validation loss: 2.4209909710507485

Epoch: 5| Step: 3
Training loss: 0.45556885942491626
Validation loss: 2.4440150596571972

Epoch: 5| Step: 4
Training loss: 0.30971515287624213
Validation loss: 2.4406061987163024

Epoch: 5| Step: 5
Training loss: 0.6299504443387722
Validation loss: 2.4222918720292705

Epoch: 5| Step: 6
Training loss: 0.41645823470905324
Validation loss: 2.4572091028693226

Epoch: 5| Step: 7
Training loss: 0.3834415250285579
Validation loss: 2.4196274770232242

Epoch: 5| Step: 8
Training loss: 0.3895463164315846
Validation loss: 2.449552982887041

Epoch: 5| Step: 9
Training loss: 0.4871831830355255
Validation loss: 2.424105331967089

Epoch: 5| Step: 10
Training loss: 0.6863894162196812
Validation loss: 2.456340761962372

Epoch: 352| Step: 0
Training loss: 0.5697790028235855
Validation loss: 2.4572192928959424

Epoch: 5| Step: 1
Training loss: 0.4197929361795898
Validation loss: 2.5128032160154556

Epoch: 5| Step: 2
Training loss: 0.5758295885186033
Validation loss: 2.4822504379670334

Epoch: 5| Step: 3
Training loss: 0.5594499335366439
Validation loss: 2.4744365916808935

Epoch: 5| Step: 4
Training loss: 0.44100025376595875
Validation loss: 2.408876402446595

Epoch: 5| Step: 5
Training loss: 0.5304605003018826
Validation loss: 2.380404240640629

Epoch: 5| Step: 6
Training loss: 0.4832530872416074
Validation loss: 2.348839056509454

Epoch: 5| Step: 7
Training loss: 0.3308813828644214
Validation loss: 2.336403453773926

Epoch: 5| Step: 8
Training loss: 0.5138908760645251
Validation loss: 2.3462426054821925

Epoch: 5| Step: 9
Training loss: 0.41536461123602925
Validation loss: 2.3745190047541707

Epoch: 5| Step: 10
Training loss: 0.49169800653090395
Validation loss: 2.3750149392314968

Epoch: 353| Step: 0
Training loss: 0.40186218033628696
Validation loss: 2.423460070606224

Epoch: 5| Step: 1
Training loss: 0.5329165963875508
Validation loss: 2.3988120104069712

Epoch: 5| Step: 2
Training loss: 0.49801638640786966
Validation loss: 2.4250502884452936

Epoch: 5| Step: 3
Training loss: 0.5104293886532533
Validation loss: 2.3812560911915934

Epoch: 5| Step: 4
Training loss: 0.3745186617330781
Validation loss: 2.3416507269641924

Epoch: 5| Step: 5
Training loss: 0.5874238553313765
Validation loss: 2.287733498077353

Epoch: 5| Step: 6
Training loss: 0.2642022485390808
Validation loss: 2.3053437163778074

Epoch: 5| Step: 7
Training loss: 0.6636233280022145
Validation loss: 2.3538040610041855

Epoch: 5| Step: 8
Training loss: 0.40195668685120867
Validation loss: 2.389385255010051

Epoch: 5| Step: 9
Training loss: 0.6609557688106876
Validation loss: 2.424759993682015

Epoch: 5| Step: 10
Training loss: 0.423622468195081
Validation loss: 2.4380964175822326

Epoch: 354| Step: 0
Training loss: 0.18394694949928636
Validation loss: 2.4590344184501425

Epoch: 5| Step: 1
Training loss: 0.5371821683626848
Validation loss: 2.425740649915117

Epoch: 5| Step: 2
Training loss: 0.3013017535173506
Validation loss: 2.3993452130888153

Epoch: 5| Step: 3
Training loss: 0.4122246675891497
Validation loss: 2.429704092946612

Epoch: 5| Step: 4
Training loss: 0.5983324650950318
Validation loss: 2.402421370482113

Epoch: 5| Step: 5
Training loss: 0.4353119939566996
Validation loss: 2.418519376729109

Epoch: 5| Step: 6
Training loss: 0.36037852282064226
Validation loss: 2.4038337758741855

Epoch: 5| Step: 7
Training loss: 0.5117630102221065
Validation loss: 2.3921947340330334

Epoch: 5| Step: 8
Training loss: 0.5529501396123833
Validation loss: 2.4233859416426635

Epoch: 5| Step: 9
Training loss: 0.6654976763308547
Validation loss: 2.450891438720042

Epoch: 5| Step: 10
Training loss: 0.5283841360749403
Validation loss: 2.4316836436377516

Epoch: 355| Step: 0
Training loss: 0.4036733084731271
Validation loss: 2.462968737602772

Epoch: 5| Step: 1
Training loss: 0.5270375245685208
Validation loss: 2.4567716534964563

Epoch: 5| Step: 2
Training loss: 0.3590080626998241
Validation loss: 2.433929379657782

Epoch: 5| Step: 3
Training loss: 0.5147224098044421
Validation loss: 2.4463853817383945

Epoch: 5| Step: 4
Training loss: 0.422694734383133
Validation loss: 2.4596644580243368

Epoch: 5| Step: 5
Training loss: 0.5391497610479188
Validation loss: 2.455949053269098

Epoch: 5| Step: 6
Training loss: 0.25430237607382156
Validation loss: 2.456002024395012

Epoch: 5| Step: 7
Training loss: 0.6273249774181107
Validation loss: 2.465156389346716

Epoch: 5| Step: 8
Training loss: 0.380917295306587
Validation loss: 2.51353242310455

Epoch: 5| Step: 9
Training loss: 0.6053877499450948
Validation loss: 2.496094045793561

Epoch: 5| Step: 10
Training loss: 0.41070581584395055
Validation loss: 2.42901246582567

Epoch: 356| Step: 0
Training loss: 0.4523459676579483
Validation loss: 2.450463167010516

Epoch: 5| Step: 1
Training loss: 0.6615358642636325
Validation loss: 2.3591687066698435

Epoch: 5| Step: 2
Training loss: 0.4298219817129304
Validation loss: 2.399019680063714

Epoch: 5| Step: 3
Training loss: 0.21659241735279286
Validation loss: 2.3963811675172293

Epoch: 5| Step: 4
Training loss: 0.6131421800125463
Validation loss: 2.4144538774262942

Epoch: 5| Step: 5
Training loss: 0.432334359676733
Validation loss: 2.3861149590989776

Epoch: 5| Step: 6
Training loss: 0.5078264381256495
Validation loss: 2.4118584107620715

Epoch: 5| Step: 7
Training loss: 0.5491191594650987
Validation loss: 2.40631059544473

Epoch: 5| Step: 8
Training loss: 0.3328360285075989
Validation loss: 2.424346600517073

Epoch: 5| Step: 9
Training loss: 0.45444773943134537
Validation loss: 2.4433962991465137

Epoch: 5| Step: 10
Training loss: 0.32384254276220314
Validation loss: 2.4156737251993943

Epoch: 357| Step: 0
Training loss: 0.23510256531513277
Validation loss: 2.4491477773242396

Epoch: 5| Step: 1
Training loss: 0.32140121125911075
Validation loss: 2.3772688602954375

Epoch: 5| Step: 2
Training loss: 0.3671704957961213
Validation loss: 2.3838049543387503

Epoch: 5| Step: 3
Training loss: 0.6471292097585861
Validation loss: 2.3477388037488645

Epoch: 5| Step: 4
Training loss: 0.6823375822347127
Validation loss: 2.3675674290079285

Epoch: 5| Step: 5
Training loss: 0.4428464636635744
Validation loss: 2.4285588281588444

Epoch: 5| Step: 6
Training loss: 0.3923218683106017
Validation loss: 2.465743342412292

Epoch: 5| Step: 7
Training loss: 0.40226296660137
Validation loss: 2.514996841974395

Epoch: 5| Step: 8
Training loss: 0.5059555728127805
Validation loss: 2.5265259326223544

Epoch: 5| Step: 9
Training loss: 0.5918188814912316
Validation loss: 2.567360595833669

Epoch: 5| Step: 10
Training loss: 0.2768119495237367
Validation loss: 2.5286387013014293

Epoch: 358| Step: 0
Training loss: 0.4408534479089257
Validation loss: 2.4432666818328914

Epoch: 5| Step: 1
Training loss: 0.6043498375436769
Validation loss: 2.4190076215492766

Epoch: 5| Step: 2
Training loss: 0.3142410653193886
Validation loss: 2.3384321419024636

Epoch: 5| Step: 3
Training loss: 0.5147244652430867
Validation loss: 2.319916697857027

Epoch: 5| Step: 4
Training loss: 0.3651717637193992
Validation loss: 2.3839217335733127

Epoch: 5| Step: 5
Training loss: 0.5803635533995329
Validation loss: 2.4758231455335062

Epoch: 5| Step: 6
Training loss: 0.34101309147229025
Validation loss: 2.488479490711348

Epoch: 5| Step: 7
Training loss: 0.40659409402450564
Validation loss: 2.509500464937793

Epoch: 5| Step: 8
Training loss: 0.5398789180446512
Validation loss: 2.5074965071827386

Epoch: 5| Step: 9
Training loss: 0.5052199280447199
Validation loss: 2.4889668117342776

Epoch: 5| Step: 10
Training loss: 0.4878630716623449
Validation loss: 2.420281930581312

Epoch: 359| Step: 0
Training loss: 0.3237181095853824
Validation loss: 2.374596334240212

Epoch: 5| Step: 1
Training loss: 0.41730996381106944
Validation loss: 2.391632313964156

Epoch: 5| Step: 2
Training loss: 0.6226877594636849
Validation loss: 2.3590522273142467

Epoch: 5| Step: 3
Training loss: 0.5718276395103807
Validation loss: 2.3916279105090914

Epoch: 5| Step: 4
Training loss: 0.5411601785833411
Validation loss: 2.419164823603937

Epoch: 5| Step: 5
Training loss: 0.4034942547437588
Validation loss: 2.423162825426976

Epoch: 5| Step: 6
Training loss: 0.38219768432622325
Validation loss: 2.4575037869721865

Epoch: 5| Step: 7
Training loss: 0.2834814085591507
Validation loss: 2.417502667781404

Epoch: 5| Step: 8
Training loss: 0.5478701392847416
Validation loss: 2.409073069480769

Epoch: 5| Step: 9
Training loss: 0.3192455152063655
Validation loss: 2.3475515860184895

Epoch: 5| Step: 10
Training loss: 0.5974651355228046
Validation loss: 2.3270641080955414

Epoch: 360| Step: 0
Training loss: 0.3998348565731845
Validation loss: 2.315125681723191

Epoch: 5| Step: 1
Training loss: 0.40220925018138604
Validation loss: 2.335028899376878

Epoch: 5| Step: 2
Training loss: 0.4493267427087518
Validation loss: 2.3660401263978965

Epoch: 5| Step: 3
Training loss: 0.375774477859986
Validation loss: 2.379555487446545

Epoch: 5| Step: 4
Training loss: 0.5822675084634218
Validation loss: 2.460284024025434

Epoch: 5| Step: 5
Training loss: 0.5520018991354739
Validation loss: 2.4994207736652108

Epoch: 5| Step: 6
Training loss: 0.5422372075142013
Validation loss: 2.475180278007562

Epoch: 5| Step: 7
Training loss: 0.35154005614800954
Validation loss: 2.485020416496779

Epoch: 5| Step: 8
Training loss: 0.42459111599937976
Validation loss: 2.4588170518574173

Epoch: 5| Step: 9
Training loss: 0.5335103920744051
Validation loss: 2.4705849667865856

Epoch: 5| Step: 10
Training loss: 0.28192353397467546
Validation loss: 2.396035221647983

Epoch: 361| Step: 0
Training loss: 0.5417536580094723
Validation loss: 2.4191332177377913

Epoch: 5| Step: 1
Training loss: 0.39853179040341385
Validation loss: 2.417574208919733

Epoch: 5| Step: 2
Training loss: 0.17406268849182882
Validation loss: 2.391221482148179

Epoch: 5| Step: 3
Training loss: 0.44722636021337864
Validation loss: 2.4225342476838665

Epoch: 5| Step: 4
Training loss: 0.3266225431081966
Validation loss: 2.4200540175613225

Epoch: 5| Step: 5
Training loss: 0.556515381760703
Validation loss: 2.4219252539801843

Epoch: 5| Step: 6
Training loss: 0.5083202464602662
Validation loss: 2.4727729282929114

Epoch: 5| Step: 7
Training loss: 0.5719646925499625
Validation loss: 2.466434695780672

Epoch: 5| Step: 8
Training loss: 0.5300647191353292
Validation loss: 2.5126034064724867

Epoch: 5| Step: 9
Training loss: 0.46487006746051396
Validation loss: 2.4724080907416277

Epoch: 5| Step: 10
Training loss: 0.39277435257101806
Validation loss: 2.4735889786459966

Epoch: 362| Step: 0
Training loss: 0.3760933830788775
Validation loss: 2.4209536225832204

Epoch: 5| Step: 1
Training loss: 0.5505579773189574
Validation loss: 2.399763912485134

Epoch: 5| Step: 2
Training loss: 0.4849344068837382
Validation loss: 2.378875748929996

Epoch: 5| Step: 3
Training loss: 0.23469589835529647
Validation loss: 2.4156936331596524

Epoch: 5| Step: 4
Training loss: 0.25290668044153214
Validation loss: 2.45225289417082

Epoch: 5| Step: 5
Training loss: 0.5511013751020254
Validation loss: 2.4877861051756502

Epoch: 5| Step: 6
Training loss: 0.3824988267294648
Validation loss: 2.530313158178848

Epoch: 5| Step: 7
Training loss: 0.564214768291359
Validation loss: 2.4959894816127957

Epoch: 5| Step: 8
Training loss: 0.3951511988801567
Validation loss: 2.4155835011030904

Epoch: 5| Step: 9
Training loss: 0.6486904156615032
Validation loss: 2.377570432263638

Epoch: 5| Step: 10
Training loss: 0.4583811753041426
Validation loss: 2.372967799948966

Epoch: 363| Step: 0
Training loss: 0.5620475114681609
Validation loss: 2.305848554061421

Epoch: 5| Step: 1
Training loss: 0.5079523920894502
Validation loss: 2.2914379253688653

Epoch: 5| Step: 2
Training loss: 0.3802756702767034
Validation loss: 2.344680598101949

Epoch: 5| Step: 3
Training loss: 0.27257207429161173
Validation loss: 2.418969737991192

Epoch: 5| Step: 4
Training loss: 0.5712869758241805
Validation loss: 2.4778638553077834

Epoch: 5| Step: 5
Training loss: 0.23488547047821348
Validation loss: 2.525734665058678

Epoch: 5| Step: 6
Training loss: 0.4397495202717379
Validation loss: 2.5236079086936645

Epoch: 5| Step: 7
Training loss: 0.4610336979198763
Validation loss: 2.5081979294841745

Epoch: 5| Step: 8
Training loss: 0.36964073817315113
Validation loss: 2.4698745764346386

Epoch: 5| Step: 9
Training loss: 0.41806178973686936
Validation loss: 2.4636514460551346

Epoch: 5| Step: 10
Training loss: 0.6425726754093691
Validation loss: 2.453013523971359

Epoch: 364| Step: 0
Training loss: 0.1966256250139938
Validation loss: 2.4271397016129597

Epoch: 5| Step: 1
Training loss: 0.47694056788854894
Validation loss: 2.4494429833034808

Epoch: 5| Step: 2
Training loss: 0.354967770355912
Validation loss: 2.467209039750325

Epoch: 5| Step: 3
Training loss: 0.42924993950916146
Validation loss: 2.4883631986068955

Epoch: 5| Step: 4
Training loss: 0.557155464736237
Validation loss: 2.4885190937421897

Epoch: 5| Step: 5
Training loss: 0.4866578236956607
Validation loss: 2.464567610852669

Epoch: 5| Step: 6
Training loss: 0.39325403509598006
Validation loss: 2.44036979059967

Epoch: 5| Step: 7
Training loss: 0.5790900861300913
Validation loss: 2.420294417837902

Epoch: 5| Step: 8
Training loss: 0.45157639835181074
Validation loss: 2.411152043453608

Epoch: 5| Step: 9
Training loss: 0.4513520875829051
Validation loss: 2.3680412122760597

Epoch: 5| Step: 10
Training loss: 0.36866123618207197
Validation loss: 2.395071018242546

Epoch: 365| Step: 0
Training loss: 0.502067404477186
Validation loss: 2.3877335338887375

Epoch: 5| Step: 1
Training loss: 0.465497878982514
Validation loss: 2.396106879484624

Epoch: 5| Step: 2
Training loss: 0.13839012725066951
Validation loss: 2.427263823999223

Epoch: 5| Step: 3
Training loss: 0.35461282910372693
Validation loss: 2.4611663685891494

Epoch: 5| Step: 4
Training loss: 0.2949316263165693
Validation loss: 2.473422599431838

Epoch: 5| Step: 5
Training loss: 0.4758942405692845
Validation loss: 2.4419804075366747

Epoch: 5| Step: 6
Training loss: 0.31692003990920575
Validation loss: 2.471122859937319

Epoch: 5| Step: 7
Training loss: 0.4641365313321348
Validation loss: 2.438732423582406

Epoch: 5| Step: 8
Training loss: 0.7320243875839377
Validation loss: 2.442792994933884

Epoch: 5| Step: 9
Training loss: 0.47503487622066676
Validation loss: 2.4059914390215194

Epoch: 5| Step: 10
Training loss: 0.32627152160019174
Validation loss: 2.39813203327113

Epoch: 366| Step: 0
Training loss: 0.4218696664543677
Validation loss: 2.361577539701871

Epoch: 5| Step: 1
Training loss: 0.4763183437329812
Validation loss: 2.386728470835563

Epoch: 5| Step: 2
Training loss: 0.33879424967445976
Validation loss: 2.401115867089813

Epoch: 5| Step: 3
Training loss: 0.23865668627769132
Validation loss: 2.4363853434362484

Epoch: 5| Step: 4
Training loss: 0.4947093058519559
Validation loss: 2.4492554978895984

Epoch: 5| Step: 5
Training loss: 0.3118498237401413
Validation loss: 2.4383082694404097

Epoch: 5| Step: 6
Training loss: 0.32617680894237944
Validation loss: 2.480994689027732

Epoch: 5| Step: 7
Training loss: 0.5694891852607091
Validation loss: 2.4617781248191597

Epoch: 5| Step: 8
Training loss: 0.5291012898807379
Validation loss: 2.4857221281404547

Epoch: 5| Step: 9
Training loss: 0.5165941205417125
Validation loss: 2.4621392189352425

Epoch: 5| Step: 10
Training loss: 0.5205658384690788
Validation loss: 2.4233147995283453

Epoch: 367| Step: 0
Training loss: 0.22068391564417722
Validation loss: 2.385054494236473

Epoch: 5| Step: 1
Training loss: 0.5674335765616849
Validation loss: 2.381946861450585

Epoch: 5| Step: 2
Training loss: 0.3931201210992811
Validation loss: 2.398316231487994

Epoch: 5| Step: 3
Training loss: 0.206610458926811
Validation loss: 2.4552367242999615

Epoch: 5| Step: 4
Training loss: 0.28154614539707906
Validation loss: 2.4504391213499828

Epoch: 5| Step: 5
Training loss: 0.5319570996655201
Validation loss: 2.5159174013476324

Epoch: 5| Step: 6
Training loss: 0.6772019771406803
Validation loss: 2.4637487867685155

Epoch: 5| Step: 7
Training loss: 0.19077114889224264
Validation loss: 2.483453339345146

Epoch: 5| Step: 8
Training loss: 0.44866936301847193
Validation loss: 2.4595781563469203

Epoch: 5| Step: 9
Training loss: 0.43132383709589744
Validation loss: 2.4359752133869685

Epoch: 5| Step: 10
Training loss: 0.5247526301299431
Validation loss: 2.4733220344391293

Epoch: 368| Step: 0
Training loss: 0.44165410197877447
Validation loss: 2.4425860834695503

Epoch: 5| Step: 1
Training loss: 0.4938669766310453
Validation loss: 2.4170368335056325

Epoch: 5| Step: 2
Training loss: 0.3498770046401577
Validation loss: 2.40236332396263

Epoch: 5| Step: 3
Training loss: 0.4077570727744718
Validation loss: 2.422873967321859

Epoch: 5| Step: 4
Training loss: 0.2327885660247573
Validation loss: 2.4249169296009687

Epoch: 5| Step: 5
Training loss: 0.44509219693260654
Validation loss: 2.4516557680693922

Epoch: 5| Step: 6
Training loss: 0.27912875097105955
Validation loss: 2.445092636488449

Epoch: 5| Step: 7
Training loss: 0.49831911014376845
Validation loss: 2.437310151730917

Epoch: 5| Step: 8
Training loss: 0.32306389631197285
Validation loss: 2.439744337325665

Epoch: 5| Step: 9
Training loss: 0.5483895446591059
Validation loss: 2.462482804381562

Epoch: 5| Step: 10
Training loss: 0.543214509082912
Validation loss: 2.4139651342505926

Epoch: 369| Step: 0
Training loss: 0.2480664583420419
Validation loss: 2.4686200092237

Epoch: 5| Step: 1
Training loss: 0.5185929049042209
Validation loss: 2.483170742513465

Epoch: 5| Step: 2
Training loss: 0.3406555302088032
Validation loss: 2.454180439017374

Epoch: 5| Step: 3
Training loss: 0.31751980685982195
Validation loss: 2.5015223554315753

Epoch: 5| Step: 4
Training loss: 0.38777809316269496
Validation loss: 2.457937125940665

Epoch: 5| Step: 5
Training loss: 0.407582043246329
Validation loss: 2.447334497503021

Epoch: 5| Step: 6
Training loss: 0.43218879931207
Validation loss: 2.414845915974961

Epoch: 5| Step: 7
Training loss: 0.4287557209233778
Validation loss: 2.3388530849891636

Epoch: 5| Step: 8
Training loss: 0.3483970015558564
Validation loss: 2.3402642321410387

Epoch: 5| Step: 9
Training loss: 0.5313513603004223
Validation loss: 2.374079467059884

Epoch: 5| Step: 10
Training loss: 0.5960872474805706
Validation loss: 2.417246216166912

Epoch: 370| Step: 0
Training loss: 0.5479933883222892
Validation loss: 2.428622915193197

Epoch: 5| Step: 1
Training loss: 0.5105757141140415
Validation loss: 2.4703715388415373

Epoch: 5| Step: 2
Training loss: 0.5088206041630394
Validation loss: 2.5516109284646524

Epoch: 5| Step: 3
Training loss: 0.4478984004739271
Validation loss: 2.552305420250383

Epoch: 5| Step: 4
Training loss: 0.36320414801683476
Validation loss: 2.5015261145132266

Epoch: 5| Step: 5
Training loss: 0.4748491537094809
Validation loss: 2.456082919636652

Epoch: 5| Step: 6
Training loss: 0.4172564345995601
Validation loss: 2.4221295982757973

Epoch: 5| Step: 7
Training loss: 0.3359864886737668
Validation loss: 2.4051817669752267

Epoch: 5| Step: 8
Training loss: 0.3479384552058735
Validation loss: 2.381497497116283

Epoch: 5| Step: 9
Training loss: 0.2463549030580597
Validation loss: 2.4109457601629134

Epoch: 5| Step: 10
Training loss: 0.35375159381197385
Validation loss: 2.410589933571071

Epoch: 371| Step: 0
Training loss: 0.4595746404506454
Validation loss: 2.421981421232018

Epoch: 5| Step: 1
Training loss: 0.4330917407830869
Validation loss: 2.4452375033353735

Epoch: 5| Step: 2
Training loss: 0.4877530865407838
Validation loss: 2.45261367747472

Epoch: 5| Step: 3
Training loss: 0.3036000334461983
Validation loss: 2.4663827194599666

Epoch: 5| Step: 4
Training loss: 0.34732222852043915
Validation loss: 2.4302965491642037

Epoch: 5| Step: 5
Training loss: 0.41707790664028616
Validation loss: 2.4160700950305447

Epoch: 5| Step: 6
Training loss: 0.5448222462354646
Validation loss: 2.4452133737854775

Epoch: 5| Step: 7
Training loss: 0.4565366693561895
Validation loss: 2.4500687581372005

Epoch: 5| Step: 8
Training loss: 0.32925042654051845
Validation loss: 2.4112758240946555

Epoch: 5| Step: 9
Training loss: 0.3039400150595858
Validation loss: 2.438903956435595

Epoch: 5| Step: 10
Training loss: 0.3354700962105379
Validation loss: 2.405114534444591

Epoch: 372| Step: 0
Training loss: 0.42276317210010506
Validation loss: 2.4299677774965103

Epoch: 5| Step: 1
Training loss: 0.31552178187000507
Validation loss: 2.397472311775312

Epoch: 5| Step: 2
Training loss: 0.47591377880471786
Validation loss: 2.409591324860012

Epoch: 5| Step: 3
Training loss: 0.7038000680855135
Validation loss: 2.445518116236528

Epoch: 5| Step: 4
Training loss: 0.37749803520474473
Validation loss: 2.4573119996438746

Epoch: 5| Step: 5
Training loss: 0.46012959556906535
Validation loss: 2.49702002211097

Epoch: 5| Step: 6
Training loss: 0.1744310445517028
Validation loss: 2.484393431830607

Epoch: 5| Step: 7
Training loss: 0.32180370402284814
Validation loss: 2.5200013574530478

Epoch: 5| Step: 8
Training loss: 0.5117050634985355
Validation loss: 2.4683772161697415

Epoch: 5| Step: 9
Training loss: 0.17620702147651346
Validation loss: 2.4137348266341485

Epoch: 5| Step: 10
Training loss: 0.2665511003183178
Validation loss: 2.4193625632371267

Epoch: 373| Step: 0
Training loss: 0.5169072535736691
Validation loss: 2.4021687964571714

Epoch: 5| Step: 1
Training loss: 0.4019848231800461
Validation loss: 2.373947439235458

Epoch: 5| Step: 2
Training loss: 0.40275880090177363
Validation loss: 2.3554350894895606

Epoch: 5| Step: 3
Training loss: 0.17496084452152016
Validation loss: 2.3628829654338923

Epoch: 5| Step: 4
Training loss: 0.4241768593241134
Validation loss: 2.3845804020987122

Epoch: 5| Step: 5
Training loss: 0.5449121672609889
Validation loss: 2.3930065906663365

Epoch: 5| Step: 6
Training loss: 0.3507554645873954
Validation loss: 2.436861278987852

Epoch: 5| Step: 7
Training loss: 0.2637272246864066
Validation loss: 2.442873962385836

Epoch: 5| Step: 8
Training loss: 0.4932334322343793
Validation loss: 2.4309151111537135

Epoch: 5| Step: 9
Training loss: 0.41871722221195434
Validation loss: 2.44297697288211

Epoch: 5| Step: 10
Training loss: 0.2300993982399205
Validation loss: 2.3993759518522935

Epoch: 374| Step: 0
Training loss: 0.4945285917575256
Validation loss: 2.417404739605786

Epoch: 5| Step: 1
Training loss: 0.38445540571863773
Validation loss: 2.405567436217658

Epoch: 5| Step: 2
Training loss: 0.38443949476210454
Validation loss: 2.450500739713538

Epoch: 5| Step: 3
Training loss: 0.28934159852334324
Validation loss: 2.4543604052491497

Epoch: 5| Step: 4
Training loss: 0.533888100886924
Validation loss: 2.4797970449564284

Epoch: 5| Step: 5
Training loss: 0.42316925237207964
Validation loss: 2.467760965063599

Epoch: 5| Step: 6
Training loss: 0.2805078702330812
Validation loss: 2.472060563705635

Epoch: 5| Step: 7
Training loss: 0.29902343351337973
Validation loss: 2.518128413309028

Epoch: 5| Step: 8
Training loss: 0.4557048591307408
Validation loss: 2.492234787550378

Epoch: 5| Step: 9
Training loss: 0.3834830269992875
Validation loss: 2.480884284458059

Epoch: 5| Step: 10
Training loss: 0.32732013353176764
Validation loss: 2.443363773359071

Epoch: 375| Step: 0
Training loss: 0.3376897975808873
Validation loss: 2.370352828692331

Epoch: 5| Step: 1
Training loss: 0.44458912772657383
Validation loss: 2.3863996547499933

Epoch: 5| Step: 2
Training loss: 0.2405166982942656
Validation loss: 2.3932553642860355

Epoch: 5| Step: 3
Training loss: 0.5341307567104984
Validation loss: 2.378140137960731

Epoch: 5| Step: 4
Training loss: 0.324907272663802
Validation loss: 2.4620932130249185

Epoch: 5| Step: 5
Training loss: 0.4189620470381608
Validation loss: 2.478987265824459

Epoch: 5| Step: 6
Training loss: 0.46688934431803303
Validation loss: 2.483281453211418

Epoch: 5| Step: 7
Training loss: 0.25535507589545947
Validation loss: 2.4815616994509027

Epoch: 5| Step: 8
Training loss: 0.4417206311396676
Validation loss: 2.4901946476552856

Epoch: 5| Step: 9
Training loss: 0.5301536017187899
Validation loss: 2.430701327154546

Epoch: 5| Step: 10
Training loss: 0.30857727151646747
Validation loss: 2.333552070295803

Epoch: 376| Step: 0
Training loss: 0.45517978433200373
Validation loss: 2.3157013238635655

Epoch: 5| Step: 1
Training loss: 0.4901508700920989
Validation loss: 2.32314893202456

Epoch: 5| Step: 2
Training loss: 0.3085907199565999
Validation loss: 2.30925027068999

Epoch: 5| Step: 3
Training loss: 0.28829799541437406
Validation loss: 2.328189458874866

Epoch: 5| Step: 4
Training loss: 0.18721119175099998
Validation loss: 2.3766313766965816

Epoch: 5| Step: 5
Training loss: 0.2703652539897418
Validation loss: 2.4159064085388993

Epoch: 5| Step: 6
Training loss: 0.6118288274845202
Validation loss: 2.431481576788427

Epoch: 5| Step: 7
Training loss: 0.38056051804253077
Validation loss: 2.4513914254344766

Epoch: 5| Step: 8
Training loss: 0.3000103000025058
Validation loss: 2.445447484845696

Epoch: 5| Step: 9
Training loss: 0.45570423784648195
Validation loss: 2.4452361487738576

Epoch: 5| Step: 10
Training loss: 0.521507919865833
Validation loss: 2.4364050863699687

Epoch: 377| Step: 0
Training loss: 0.4680242960830285
Validation loss: 2.4451499952327107

Epoch: 5| Step: 1
Training loss: 0.371210381098911
Validation loss: 2.41371339245675

Epoch: 5| Step: 2
Training loss: 0.3643156317672633
Validation loss: 2.4563269007718262

Epoch: 5| Step: 3
Training loss: 0.34837347691206083
Validation loss: 2.460634561967531

Epoch: 5| Step: 4
Training loss: 0.418359912120428
Validation loss: 2.4216160969614298

Epoch: 5| Step: 5
Training loss: 0.38757312684545525
Validation loss: 2.392538143892893

Epoch: 5| Step: 6
Training loss: 0.4638930464112199
Validation loss: 2.41366712921499

Epoch: 5| Step: 7
Training loss: 0.36515982779960654
Validation loss: 2.4224095818709586

Epoch: 5| Step: 8
Training loss: 0.591377562982379
Validation loss: 2.4349648639202197

Epoch: 5| Step: 9
Training loss: 0.35575272671531827
Validation loss: 2.458847905221503

Epoch: 5| Step: 10
Training loss: 0.33043093138028956
Validation loss: 2.439880375189931

Epoch: 378| Step: 0
Training loss: 0.24872176653493017
Validation loss: 2.4454865223178213

Epoch: 5| Step: 1
Training loss: 0.4266701964080857
Validation loss: 2.4202416539997316

Epoch: 5| Step: 2
Training loss: 0.3705057806704345
Validation loss: 2.4236872524023507

Epoch: 5| Step: 3
Training loss: 0.5873141583261666
Validation loss: 2.383684019050832

Epoch: 5| Step: 4
Training loss: 0.281028103714422
Validation loss: 2.384721427274705

Epoch: 5| Step: 5
Training loss: 0.10936899679602896
Validation loss: 2.3653925658894313

Epoch: 5| Step: 6
Training loss: 0.368978898885921
Validation loss: 2.3844910533848322

Epoch: 5| Step: 7
Training loss: 0.5763589329065424
Validation loss: 2.348480797799841

Epoch: 5| Step: 8
Training loss: 0.45512532329154953
Validation loss: 2.412627270364897

Epoch: 5| Step: 9
Training loss: 0.3573566439778895
Validation loss: 2.4493688782130847

Epoch: 5| Step: 10
Training loss: 0.3818250103335759
Validation loss: 2.498779444997568

Epoch: 379| Step: 0
Training loss: 0.25078703258656987
Validation loss: 2.5659690084023805

Epoch: 5| Step: 1
Training loss: 0.47150542710782184
Validation loss: 2.5666321243797894

Epoch: 5| Step: 2
Training loss: 0.5905032733839428
Validation loss: 2.5517761122565465

Epoch: 5| Step: 3
Training loss: 0.2819906918852893
Validation loss: 2.552757015216218

Epoch: 5| Step: 4
Training loss: 0.19162374906573298
Validation loss: 2.487383597953509

Epoch: 5| Step: 5
Training loss: 0.4158624537209052
Validation loss: 2.462560548897354

Epoch: 5| Step: 6
Training loss: 0.3127555993964041
Validation loss: 2.484067823969763

Epoch: 5| Step: 7
Training loss: 0.333800527376852
Validation loss: 2.45875970644447

Epoch: 5| Step: 8
Training loss: 0.4281703869227522
Validation loss: 2.485348104908922

Epoch: 5| Step: 9
Training loss: 0.4724551001413271
Validation loss: 2.4805170536546055

Epoch: 5| Step: 10
Training loss: 0.4558953735991216
Validation loss: 2.49743970493919

Epoch: 380| Step: 0
Training loss: 0.4114538103973703
Validation loss: 2.4939420047326597

Epoch: 5| Step: 1
Training loss: 0.2906650377197475
Validation loss: 2.4685485412884054

Epoch: 5| Step: 2
Training loss: 0.46251199423212636
Validation loss: 2.451599777687938

Epoch: 5| Step: 3
Training loss: 0.2477260301761032
Validation loss: 2.4651296395946574

Epoch: 5| Step: 4
Training loss: 0.49983085811263295
Validation loss: 2.3746407889716603

Epoch: 5| Step: 5
Training loss: 0.4493831996938936
Validation loss: 2.3806914132380657

Epoch: 5| Step: 6
Training loss: 0.3734357913628598
Validation loss: 2.368337581372334

Epoch: 5| Step: 7
Training loss: 0.47641148285010915
Validation loss: 2.332617741899897

Epoch: 5| Step: 8
Training loss: 0.3921169209899015
Validation loss: 2.3242078720724764

Epoch: 5| Step: 9
Training loss: 0.31651741006086737
Validation loss: 2.342957985889198

Epoch: 5| Step: 10
Training loss: 0.3300818268156419
Validation loss: 2.361054785545417

Epoch: 381| Step: 0
Training loss: 0.43345645071020095
Validation loss: 2.4078689922373893

Epoch: 5| Step: 1
Training loss: 0.3816615338098348
Validation loss: 2.441783393983822

Epoch: 5| Step: 2
Training loss: 0.5408057346218407
Validation loss: 2.464258949413667

Epoch: 5| Step: 3
Training loss: 0.21723200973159262
Validation loss: 2.3988194571848522

Epoch: 5| Step: 4
Training loss: 0.19413141769896136
Validation loss: 2.3759710262267753

Epoch: 5| Step: 5
Training loss: 0.2138051243440709
Validation loss: 2.3869640810391837

Epoch: 5| Step: 6
Training loss: 0.13978184816423095
Validation loss: 2.346041109064923

Epoch: 5| Step: 7
Training loss: 0.3863418360669447
Validation loss: 2.3673362180273574

Epoch: 5| Step: 8
Training loss: 0.5244238655410122
Validation loss: 2.416456981115114

Epoch: 5| Step: 9
Training loss: 0.44599353847185114
Validation loss: 2.4410652305092055

Epoch: 5| Step: 10
Training loss: 0.4852771817170134
Validation loss: 2.413833464465348

Epoch: 382| Step: 0
Training loss: 0.2950572151732149
Validation loss: 2.4512216962081665

Epoch: 5| Step: 1
Training loss: 0.42420819376532387
Validation loss: 2.4428472288990113

Epoch: 5| Step: 2
Training loss: 0.27317317721056444
Validation loss: 2.3853921236555258

Epoch: 5| Step: 3
Training loss: 0.30120920724214745
Validation loss: 2.422148014787245

Epoch: 5| Step: 4
Training loss: 0.21405012763250583
Validation loss: 2.381776302709321

Epoch: 5| Step: 5
Training loss: 0.5467216549185924
Validation loss: 2.4158147509746732

Epoch: 5| Step: 6
Training loss: 0.3752188441350378
Validation loss: 2.3841308077770362

Epoch: 5| Step: 7
Training loss: 0.5287639003757212
Validation loss: 2.3846901088362564

Epoch: 5| Step: 8
Training loss: 0.426949167887646
Validation loss: 2.419054370034141

Epoch: 5| Step: 9
Training loss: 0.3978626554924905
Validation loss: 2.46671451911168

Epoch: 5| Step: 10
Training loss: 0.27991740777605695
Validation loss: 2.4990239217044476

Epoch: 383| Step: 0
Training loss: 0.248978375116311
Validation loss: 2.497836887626078

Epoch: 5| Step: 1
Training loss: 0.45881448401658836
Validation loss: 2.5337002293084683

Epoch: 5| Step: 2
Training loss: 0.4194313022608661
Validation loss: 2.441709683764612

Epoch: 5| Step: 3
Training loss: 0.374857239569924
Validation loss: 2.4116175458639177

Epoch: 5| Step: 4
Training loss: 0.3755896026067496
Validation loss: 2.3558101679730177

Epoch: 5| Step: 5
Training loss: 0.4093723981352379
Validation loss: 2.3586301072532705

Epoch: 5| Step: 6
Training loss: 0.2946652186152823
Validation loss: 2.374857904212926

Epoch: 5| Step: 7
Training loss: 0.4602078627443937
Validation loss: 2.438211149562417

Epoch: 5| Step: 8
Training loss: 0.43361687813325417
Validation loss: 2.470312867623121

Epoch: 5| Step: 9
Training loss: 0.3941546238208101
Validation loss: 2.5229242284696736

Epoch: 5| Step: 10
Training loss: 0.3779094010460433
Validation loss: 2.5778020632270766

Epoch: 384| Step: 0
Training loss: 0.4524171496253048
Validation loss: 2.572370350527427

Epoch: 5| Step: 1
Training loss: 0.5319886962184491
Validation loss: 2.55231191294983

Epoch: 5| Step: 2
Training loss: 0.21595373388013708
Validation loss: 2.4757020283026634

Epoch: 5| Step: 3
Training loss: 0.2551209517507737
Validation loss: 2.400051104179248

Epoch: 5| Step: 4
Training loss: 0.42313085058948496
Validation loss: 2.376482876541562

Epoch: 5| Step: 5
Training loss: 0.40703281761057936
Validation loss: 2.396046599481474

Epoch: 5| Step: 6
Training loss: 0.19916593562142293
Validation loss: 2.43536074200194

Epoch: 5| Step: 7
Training loss: 0.4393048014935678
Validation loss: 2.4525302918266347

Epoch: 5| Step: 8
Training loss: 0.5024103835364672
Validation loss: 2.4906345157423755

Epoch: 5| Step: 9
Training loss: 0.4361075654091562
Validation loss: 2.4608312096521714

Epoch: 5| Step: 10
Training loss: 0.40876375603933
Validation loss: 2.4669113841246695

Epoch: 385| Step: 0
Training loss: 0.31769325918905794
Validation loss: 2.404512767782355

Epoch: 5| Step: 1
Training loss: 0.3433771170067283
Validation loss: 2.3363167374007325

Epoch: 5| Step: 2
Training loss: 0.5253677363178326
Validation loss: 2.3064746777372047

Epoch: 5| Step: 3
Training loss: 0.508301777980681
Validation loss: 2.3081904194450744

Epoch: 5| Step: 4
Training loss: 0.33444132414477656
Validation loss: 2.3412909834326276

Epoch: 5| Step: 5
Training loss: 0.24354508816203138
Validation loss: 2.3523259096881155

Epoch: 5| Step: 6
Training loss: 0.2809826321783545
Validation loss: 2.3858318649064603

Epoch: 5| Step: 7
Training loss: 0.41199115666602026
Validation loss: 2.441214992718563

Epoch: 5| Step: 8
Training loss: 0.39526137221140395
Validation loss: 2.504457013973298

Epoch: 5| Step: 9
Training loss: 0.32330973861491447
Validation loss: 2.4668950435219545

Epoch: 5| Step: 10
Training loss: 0.4985059679175369
Validation loss: 2.4296612349887816

Epoch: 386| Step: 0
Training loss: 0.4048372794208037
Validation loss: 2.3868753311945827

Epoch: 5| Step: 1
Training loss: 0.493519600095406
Validation loss: 2.3658699986305027

Epoch: 5| Step: 2
Training loss: 0.2446553412067424
Validation loss: 2.340475612526828

Epoch: 5| Step: 3
Training loss: 0.4415378543160848
Validation loss: 2.2834572676532012

Epoch: 5| Step: 4
Training loss: 0.3270182564054621
Validation loss: 2.3261095853873393

Epoch: 5| Step: 5
Training loss: 0.37631901589634936
Validation loss: 2.375763667265746

Epoch: 5| Step: 6
Training loss: 0.26805813747083834
Validation loss: 2.392576054866616

Epoch: 5| Step: 7
Training loss: 0.2973664632792982
Validation loss: 2.429222082140846

Epoch: 5| Step: 8
Training loss: 0.31533838137520376
Validation loss: 2.4369191481291423

Epoch: 5| Step: 9
Training loss: 0.3233587049250124
Validation loss: 2.4037348394217815

Epoch: 5| Step: 10
Training loss: 0.5622887214601414
Validation loss: 2.372404774664663

Epoch: 387| Step: 0
Training loss: 0.379834326466736
Validation loss: 2.3496584801857425

Epoch: 5| Step: 1
Training loss: 0.5912598039326367
Validation loss: 2.3025337284971314

Epoch: 5| Step: 2
Training loss: 0.4390181698938359
Validation loss: 2.408411089793018

Epoch: 5| Step: 3
Training loss: 0.22927123451168924
Validation loss: 2.409847839506338

Epoch: 5| Step: 4
Training loss: 0.35875011101830656
Validation loss: 2.450383169603575

Epoch: 5| Step: 5
Training loss: 0.3831610941414623
Validation loss: 2.4504233493651

Epoch: 5| Step: 6
Training loss: 0.3447483477314283
Validation loss: 2.440970521432658

Epoch: 5| Step: 7
Training loss: 0.10836917894728314
Validation loss: 2.473436155969168

Epoch: 5| Step: 8
Training loss: 0.443024193525035
Validation loss: 2.4843587923208106

Epoch: 5| Step: 9
Training loss: 0.24209983069535268
Validation loss: 2.436782016506284

Epoch: 5| Step: 10
Training loss: 0.4160718387359665
Validation loss: 2.4068519916387396

Epoch: 388| Step: 0
Training loss: 0.23219357024378867
Validation loss: 2.396644637539032

Epoch: 5| Step: 1
Training loss: 0.3998168928541016
Validation loss: 2.398573188274446

Epoch: 5| Step: 2
Training loss: 0.34632999890364985
Validation loss: 2.395446789676294

Epoch: 5| Step: 3
Training loss: 0.39869481547931285
Validation loss: 2.417567402083217

Epoch: 5| Step: 4
Training loss: 0.2620176203031454
Validation loss: 2.4379221253824674

Epoch: 5| Step: 5
Training loss: 0.4400449031978945
Validation loss: 2.4899218430344137

Epoch: 5| Step: 6
Training loss: 0.2804357743070934
Validation loss: 2.499472659903856

Epoch: 5| Step: 7
Training loss: 0.41903422374752625
Validation loss: 2.4647970186541843

Epoch: 5| Step: 8
Training loss: 0.3224064028193171
Validation loss: 2.436064310752623

Epoch: 5| Step: 9
Training loss: 0.356930692272161
Validation loss: 2.420764233581831

Epoch: 5| Step: 10
Training loss: 0.6081432217478103
Validation loss: 2.373843499224854

Epoch: 389| Step: 0
Training loss: 0.2057283538287237
Validation loss: 2.3303068554665325

Epoch: 5| Step: 1
Training loss: 0.4171899688304759
Validation loss: 2.3097950425883518

Epoch: 5| Step: 2
Training loss: 0.551970476335384
Validation loss: 2.3158920927400257

Epoch: 5| Step: 3
Training loss: 0.41181094315478184
Validation loss: 2.3630876478617577

Epoch: 5| Step: 4
Training loss: 0.21701794599343444
Validation loss: 2.398925334014944

Epoch: 5| Step: 5
Training loss: 0.2246834840004451
Validation loss: 2.4942183694649045

Epoch: 5| Step: 6
Training loss: 0.31035005582296077
Validation loss: 2.4620187421030866

Epoch: 5| Step: 7
Training loss: 0.3239396284086095
Validation loss: 2.4073633783218136

Epoch: 5| Step: 8
Training loss: 0.4138329427394388
Validation loss: 2.3618957857200082

Epoch: 5| Step: 9
Training loss: 0.4192678281625022
Validation loss: 2.3272632954052304

Epoch: 5| Step: 10
Training loss: 0.45717507732042545
Validation loss: 2.289034140954116

Epoch: 390| Step: 0
Training loss: 0.3555880755008529
Validation loss: 2.3231744562952334

Epoch: 5| Step: 1
Training loss: 0.31648447694496656
Validation loss: 2.3331403571928693

Epoch: 5| Step: 2
Training loss: 0.3241770154450103
Validation loss: 2.362012059185002

Epoch: 5| Step: 3
Training loss: 0.40989985853817673
Validation loss: 2.436248928366515

Epoch: 5| Step: 4
Training loss: 0.2498352208092192
Validation loss: 2.5132761135356945

Epoch: 5| Step: 5
Training loss: 0.2940842183045645
Validation loss: 2.511668302786963

Epoch: 5| Step: 6
Training loss: 0.3613343315622458
Validation loss: 2.5097134985302088

Epoch: 5| Step: 7
Training loss: 0.4310281473138143
Validation loss: 2.4378036023871723

Epoch: 5| Step: 8
Training loss: 0.36079873146338454
Validation loss: 2.3879090721342315

Epoch: 5| Step: 9
Training loss: 0.6086491149477868
Validation loss: 2.33019628537114

Epoch: 5| Step: 10
Training loss: 0.452946479752565
Validation loss: 2.3465473151591882

Epoch: 391| Step: 0
Training loss: 0.4571434437559613
Validation loss: 2.3256490055401384

Epoch: 5| Step: 1
Training loss: 0.5033877462644657
Validation loss: 2.4102750901703955

Epoch: 5| Step: 2
Training loss: 0.3719436750391367
Validation loss: 2.5195840702687224

Epoch: 5| Step: 3
Training loss: 0.40316422145985625
Validation loss: 2.5545809958376653

Epoch: 5| Step: 4
Training loss: 0.3816590155364886
Validation loss: 2.544511042332338

Epoch: 5| Step: 5
Training loss: 0.3095955582682672
Validation loss: 2.539680553652443

Epoch: 5| Step: 6
Training loss: 0.45246133214957557
Validation loss: 2.4721606386976225

Epoch: 5| Step: 7
Training loss: 0.41961978425712526
Validation loss: 2.377176576261537

Epoch: 5| Step: 8
Training loss: 0.2590580531936211
Validation loss: 2.334849712707618

Epoch: 5| Step: 9
Training loss: 0.35411608792962684
Validation loss: 2.2788216723028745

Epoch: 5| Step: 10
Training loss: 0.2899974317889113
Validation loss: 2.3073650939993855

Epoch: 392| Step: 0
Training loss: 0.17459165922749398
Validation loss: 2.347898476956721

Epoch: 5| Step: 1
Training loss: 0.408394508580082
Validation loss: 2.4325893664616185

Epoch: 5| Step: 2
Training loss: 0.4027860673055043
Validation loss: 2.4585127586875855

Epoch: 5| Step: 3
Training loss: 0.24188919307900203
Validation loss: 2.484821155947965

Epoch: 5| Step: 4
Training loss: 0.49463994728410926
Validation loss: 2.5052200271742513

Epoch: 5| Step: 5
Training loss: 0.18656870906727535
Validation loss: 2.50258663350147

Epoch: 5| Step: 6
Training loss: 0.5721224452756185
Validation loss: 2.49698256854194

Epoch: 5| Step: 7
Training loss: 0.3020711093380525
Validation loss: 2.4360756163356974

Epoch: 5| Step: 8
Training loss: 0.4516843057310739
Validation loss: 2.365386997257281

Epoch: 5| Step: 9
Training loss: 0.42269926434009103
Validation loss: 2.305567084352514

Epoch: 5| Step: 10
Training loss: 0.17927317951011107
Validation loss: 2.3815081402760407

Epoch: 393| Step: 0
Training loss: 0.3077434099182842
Validation loss: 2.4390298245957465

Epoch: 5| Step: 1
Training loss: 0.3738323151643595
Validation loss: 2.4701282355572416

Epoch: 5| Step: 2
Training loss: 0.22887544750199043
Validation loss: 2.4742080766215993

Epoch: 5| Step: 3
Training loss: 0.47019042588448906
Validation loss: 2.4600742068796433

Epoch: 5| Step: 4
Training loss: 0.43748106234299156
Validation loss: 2.4685636891159466

Epoch: 5| Step: 5
Training loss: 0.35680935180713164
Validation loss: 2.4241681762198675

Epoch: 5| Step: 6
Training loss: 0.43655487561787176
Validation loss: 2.401659708840972

Epoch: 5| Step: 7
Training loss: 0.26490492550247785
Validation loss: 2.3397674413887084

Epoch: 5| Step: 8
Training loss: 0.40124223903625295
Validation loss: 2.351104913115334

Epoch: 5| Step: 9
Training loss: 0.1698267549892433
Validation loss: 2.363025778597612

Epoch: 5| Step: 10
Training loss: 0.4197648930432306
Validation loss: 2.349751147252884

Epoch: 394| Step: 0
Training loss: 0.37712251484235104
Validation loss: 2.406507229277087

Epoch: 5| Step: 1
Training loss: 0.29371362724751887
Validation loss: 2.4411166883475026

Epoch: 5| Step: 2
Training loss: 0.5375704918701856
Validation loss: 2.4251130231121905

Epoch: 5| Step: 3
Training loss: 0.2194916210856328
Validation loss: 2.4815836594400014

Epoch: 5| Step: 4
Training loss: 0.3190645937425922
Validation loss: 2.467935023922832

Epoch: 5| Step: 5
Training loss: 0.22731626842659072
Validation loss: 2.4528577836816767

Epoch: 5| Step: 6
Training loss: 0.3233550528702652
Validation loss: 2.4228055861769398

Epoch: 5| Step: 7
Training loss: 0.4761639476238288
Validation loss: 2.394843321671267

Epoch: 5| Step: 8
Training loss: 0.3649528764979565
Validation loss: 2.355783788275097

Epoch: 5| Step: 9
Training loss: 0.248889243675823
Validation loss: 2.385012795086846

Epoch: 5| Step: 10
Training loss: 0.35568105205616246
Validation loss: 2.380551766841477

Epoch: 395| Step: 0
Training loss: 0.2809445126117617
Validation loss: 2.3735525219347866

Epoch: 5| Step: 1
Training loss: 0.24312339197475297
Validation loss: 2.4224733593301306

Epoch: 5| Step: 2
Training loss: 0.27037772345438854
Validation loss: 2.4489524076179365

Epoch: 5| Step: 3
Training loss: 0.25474657239564075
Validation loss: 2.444713520348659

Epoch: 5| Step: 4
Training loss: 0.4754231074323454
Validation loss: 2.4503108694825295

Epoch: 5| Step: 5
Training loss: 0.43250722757816273
Validation loss: 2.4172062485395314

Epoch: 5| Step: 6
Training loss: 0.2614449164505687
Validation loss: 2.4497643672413894

Epoch: 5| Step: 7
Training loss: 0.32995037563685276
Validation loss: 2.4195077166571948

Epoch: 5| Step: 8
Training loss: 0.3007879875716569
Validation loss: 2.3979145556976644

Epoch: 5| Step: 9
Training loss: 0.49324873395680946
Validation loss: 2.369773370473163

Epoch: 5| Step: 10
Training loss: 0.44330742821561253
Validation loss: 2.367410177200613

Epoch: 396| Step: 0
Training loss: 0.20107530850174907
Validation loss: 2.3586658524981305

Epoch: 5| Step: 1
Training loss: 0.4423548371688357
Validation loss: 2.388866578115815

Epoch: 5| Step: 2
Training loss: 0.3043768840003014
Validation loss: 2.418476393177866

Epoch: 5| Step: 3
Training loss: 0.16592650545913554
Validation loss: 2.4640592178719367

Epoch: 5| Step: 4
Training loss: 0.3379117595259078
Validation loss: 2.4682890281360494

Epoch: 5| Step: 5
Training loss: 0.44852621350716126
Validation loss: 2.5262254513425

Epoch: 5| Step: 6
Training loss: 0.0777127505421032
Validation loss: 2.511313775490125

Epoch: 5| Step: 7
Training loss: 0.46111323352629113
Validation loss: 2.5015395325849483

Epoch: 5| Step: 8
Training loss: 0.41562239997452066
Validation loss: 2.524669929787496

Epoch: 5| Step: 9
Training loss: 0.46100090689890566
Validation loss: 2.4296951307014636

Epoch: 5| Step: 10
Training loss: 0.32292606996360623
Validation loss: 2.392043440950203

Epoch: 397| Step: 0
Training loss: 0.3726804041681967
Validation loss: 2.3520720489930866

Epoch: 5| Step: 1
Training loss: 0.16866913310442222
Validation loss: 2.3377775985869587

Epoch: 5| Step: 2
Training loss: 0.2213375964226946
Validation loss: 2.355974037380645

Epoch: 5| Step: 3
Training loss: 0.44643952151901856
Validation loss: 2.364718532848629

Epoch: 5| Step: 4
Training loss: 0.39219804650826395
Validation loss: 2.4231582803710747

Epoch: 5| Step: 5
Training loss: 0.38334690472517624
Validation loss: 2.4551253535528734

Epoch: 5| Step: 6
Training loss: 0.3539437078396004
Validation loss: 2.4515316869595765

Epoch: 5| Step: 7
Training loss: 0.5129230683663462
Validation loss: 2.4805464465215468

Epoch: 5| Step: 8
Training loss: 0.5066182986761459
Validation loss: 2.4269229769574037

Epoch: 5| Step: 9
Training loss: 0.3318795586935626
Validation loss: 2.4109497944487916

Epoch: 5| Step: 10
Training loss: 0.262430731398785
Validation loss: 2.390248165393795

Epoch: 398| Step: 0
Training loss: 0.3818152926978709
Validation loss: 2.3932644935189504

Epoch: 5| Step: 1
Training loss: 0.2950013539921674
Validation loss: 2.439133515079309

Epoch: 5| Step: 2
Training loss: 0.3585156864807116
Validation loss: 2.4020706001461303

Epoch: 5| Step: 3
Training loss: 0.16608291272131503
Validation loss: 2.411675978218386

Epoch: 5| Step: 4
Training loss: 0.5069431198950524
Validation loss: 2.4423979336728485

Epoch: 5| Step: 5
Training loss: 0.3767954244473018
Validation loss: 2.4588468615600325

Epoch: 5| Step: 6
Training loss: 0.43875673854033026
Validation loss: 2.471698556276833

Epoch: 5| Step: 7
Training loss: 0.26323056907617365
Validation loss: 2.433736148557192

Epoch: 5| Step: 8
Training loss: 0.27425794131188086
Validation loss: 2.3985207332700096

Epoch: 5| Step: 9
Training loss: 0.3213168888738367
Validation loss: 2.4070077296237025

Epoch: 5| Step: 10
Training loss: 0.363512211875215
Validation loss: 2.392644096169836

Epoch: 399| Step: 0
Training loss: 0.3148696107868856
Validation loss: 2.402178846439254

Epoch: 5| Step: 1
Training loss: 0.5254142500660213
Validation loss: 2.3956287263671894

Epoch: 5| Step: 2
Training loss: 0.29664414615465207
Validation loss: 2.409184663821655

Epoch: 5| Step: 3
Training loss: 0.329240051018563
Validation loss: 2.4138868452319855

Epoch: 5| Step: 4
Training loss: 0.19220196506679602
Validation loss: 2.4183487916614066

Epoch: 5| Step: 5
Training loss: 0.398762570335497
Validation loss: 2.427575276791151

Epoch: 5| Step: 6
Training loss: 0.31622335069123575
Validation loss: 2.4270670317809606

Epoch: 5| Step: 7
Training loss: 0.1708105351676673
Validation loss: 2.4234456854834523

Epoch: 5| Step: 8
Training loss: 0.45139706759094006
Validation loss: 2.385000987325416

Epoch: 5| Step: 9
Training loss: 0.3756907776477164
Validation loss: 2.3985986805413355

Epoch: 5| Step: 10
Training loss: 0.21830969161666197
Validation loss: 2.4138485733111232

Epoch: 400| Step: 0
Training loss: 0.31827960740996586
Validation loss: 2.446910814003195

Epoch: 5| Step: 1
Training loss: 0.5467539517085851
Validation loss: 2.4636912564638496

Epoch: 5| Step: 2
Training loss: 0.31363935195086007
Validation loss: 2.4690756302009107

Epoch: 5| Step: 3
Training loss: 0.24213604226581653
Validation loss: 2.4587113752131424

Epoch: 5| Step: 4
Training loss: 0.3456577766977242
Validation loss: 2.464980442161144

Epoch: 5| Step: 5
Training loss: 0.4081037665096801
Validation loss: 2.4177328889917495

Epoch: 5| Step: 6
Training loss: 0.292809621192191
Validation loss: 2.383944597286248

Epoch: 5| Step: 7
Training loss: 0.28492173257902126
Validation loss: 2.3610122824858077

Epoch: 5| Step: 8
Training loss: 0.1810009058605625
Validation loss: 2.3700963166734312

Epoch: 5| Step: 9
Training loss: 0.25611340673672384
Validation loss: 2.400155333052103

Epoch: 5| Step: 10
Training loss: 0.45802282703247127
Validation loss: 2.3995720770255873

Epoch: 401| Step: 0
Training loss: 0.4334984408265864
Validation loss: 2.4115934349828114

Epoch: 5| Step: 1
Training loss: 0.3301288407769279
Validation loss: 2.4288901664230327

Epoch: 5| Step: 2
Training loss: 0.38986079803680423
Validation loss: 2.4308136228646164

Epoch: 5| Step: 3
Training loss: 0.3716708063456724
Validation loss: 2.4301776772039347

Epoch: 5| Step: 4
Training loss: 0.19086649754553991
Validation loss: 2.4043294110823226

Epoch: 5| Step: 5
Training loss: 0.1494862188997262
Validation loss: 2.427987496217087

Epoch: 5| Step: 6
Training loss: 0.37373771411261003
Validation loss: 2.390874395110267

Epoch: 5| Step: 7
Training loss: 0.3900420989642814
Validation loss: 2.371000566597841

Epoch: 5| Step: 8
Training loss: 0.23840318749146247
Validation loss: 2.3243746279111694

Epoch: 5| Step: 9
Training loss: 0.375129558117334
Validation loss: 2.3452152531296937

Epoch: 5| Step: 10
Training loss: 0.3029589527586182
Validation loss: 2.3807800452574264

Epoch: 402| Step: 0
Training loss: 0.35671322304065234
Validation loss: 2.406425286439369

Epoch: 5| Step: 1
Training loss: 0.35952368024129294
Validation loss: 2.4553731076622194

Epoch: 5| Step: 2
Training loss: 0.17764327051328652
Validation loss: 2.483836983006887

Epoch: 5| Step: 3
Training loss: 0.16657806937432637
Validation loss: 2.5095486970730274

Epoch: 5| Step: 4
Training loss: 0.2338183309005926
Validation loss: 2.5220961123639296

Epoch: 5| Step: 5
Training loss: 0.279905323366465
Validation loss: 2.4713311036696983

Epoch: 5| Step: 6
Training loss: 0.507427421698087
Validation loss: 2.450658707616713

Epoch: 5| Step: 7
Training loss: 0.2945301410036938
Validation loss: 2.4147200171667818

Epoch: 5| Step: 8
Training loss: 0.11184189018798675
Validation loss: 2.356512124961711

Epoch: 5| Step: 9
Training loss: 0.443051268949802
Validation loss: 2.333846928579229

Epoch: 5| Step: 10
Training loss: 0.4393285956370903
Validation loss: 2.2812090533047624

Epoch: 403| Step: 0
Training loss: 0.3263997977656727
Validation loss: 2.3271650141155904

Epoch: 5| Step: 1
Training loss: 0.3118544825606809
Validation loss: 2.289095726501406

Epoch: 5| Step: 2
Training loss: 0.5347279972188421
Validation loss: 2.344271683144566

Epoch: 5| Step: 3
Training loss: 0.4353220064065864
Validation loss: 2.374939192903987

Epoch: 5| Step: 4
Training loss: 0.2624684598684723
Validation loss: 2.440498155207258

Epoch: 5| Step: 5
Training loss: 0.20186468840621144
Validation loss: 2.489064226381076

Epoch: 5| Step: 6
Training loss: 0.2602046182706767
Validation loss: 2.4979852536035176

Epoch: 5| Step: 7
Training loss: 0.24466569513479705
Validation loss: 2.4861643249993977

Epoch: 5| Step: 8
Training loss: 0.23532837243013624
Validation loss: 2.4706089699469307

Epoch: 5| Step: 9
Training loss: 0.4016421598988714
Validation loss: 2.442650244853204

Epoch: 5| Step: 10
Training loss: 0.18552828243864297
Validation loss: 2.4172522189430805

Epoch: 404| Step: 0
Training loss: 0.25534098285375034
Validation loss: 2.4026209005321704

Epoch: 5| Step: 1
Training loss: 0.4427268099201629
Validation loss: 2.417496314617276

Epoch: 5| Step: 2
Training loss: 0.2862601533904778
Validation loss: 2.463906423200485

Epoch: 5| Step: 3
Training loss: 0.38404515387873717
Validation loss: 2.4565123760380785

Epoch: 5| Step: 4
Training loss: 0.3127082488453594
Validation loss: 2.493303879367072

Epoch: 5| Step: 5
Training loss: 0.26181754340010593
Validation loss: 2.4785042797591696

Epoch: 5| Step: 6
Training loss: 0.4427510932766703
Validation loss: 2.446885008893567

Epoch: 5| Step: 7
Training loss: 0.3832391385606573
Validation loss: 2.38416349970468

Epoch: 5| Step: 8
Training loss: 0.190389081097942
Validation loss: 2.375615347314967

Epoch: 5| Step: 9
Training loss: 0.25174272608926557
Validation loss: 2.422166323201034

Epoch: 5| Step: 10
Training loss: 0.3845722080259556
Validation loss: 2.4236300563364637

Epoch: 405| Step: 0
Training loss: 0.35179203805260395
Validation loss: 2.4207790195906225

Epoch: 5| Step: 1
Training loss: 0.23518398856370762
Validation loss: 2.441154220862341

Epoch: 5| Step: 2
Training loss: 0.40319596930061574
Validation loss: 2.4161872702987046

Epoch: 5| Step: 3
Training loss: 0.3122445612243622
Validation loss: 2.421602015834667

Epoch: 5| Step: 4
Training loss: 0.3061105800050196
Validation loss: 2.3927662585729195

Epoch: 5| Step: 5
Training loss: 0.39471276517270143
Validation loss: 2.4136720097209503

Epoch: 5| Step: 6
Training loss: 0.2554143865295825
Validation loss: 2.4182792473625216

Epoch: 5| Step: 7
Training loss: 0.1766985535738254
Validation loss: 2.411297504004721

Epoch: 5| Step: 8
Training loss: 0.37569383171456217
Validation loss: 2.447849417456328

Epoch: 5| Step: 9
Training loss: 0.2714909340045556
Validation loss: 2.4412928296066783

Epoch: 5| Step: 10
Training loss: 0.3830912606596964
Validation loss: 2.3794827795411995

Epoch: 406| Step: 0
Training loss: 0.18299066632211047
Validation loss: 2.3570816334575437

Epoch: 5| Step: 1
Training loss: 0.2560834704064713
Validation loss: 2.348347259272977

Epoch: 5| Step: 2
Training loss: 0.37416157773528397
Validation loss: 2.3495992081801966

Epoch: 5| Step: 3
Training loss: 0.32053918493177835
Validation loss: 2.3910123053031245

Epoch: 5| Step: 4
Training loss: 0.38729847697685676
Validation loss: 2.392949751353139

Epoch: 5| Step: 5
Training loss: 0.250943964759716
Validation loss: 2.4329249228779863

Epoch: 5| Step: 6
Training loss: 0.38395669784997916
Validation loss: 2.5076905044120763

Epoch: 5| Step: 7
Training loss: 0.17736316524216592
Validation loss: 2.4962528382255

Epoch: 5| Step: 8
Training loss: 0.42929072701075704
Validation loss: 2.51019614116582

Epoch: 5| Step: 9
Training loss: 0.36950314598396056
Validation loss: 2.4843785456253333

Epoch: 5| Step: 10
Training loss: 0.27243655789591564
Validation loss: 2.4149185968728317

Epoch: 407| Step: 0
Training loss: 0.3163967366613319
Validation loss: 2.435768341640505

Epoch: 5| Step: 1
Training loss: 0.2676359935473124
Validation loss: 2.4085831695193654

Epoch: 5| Step: 2
Training loss: 0.4461144370712112
Validation loss: 2.3874493070895713

Epoch: 5| Step: 3
Training loss: 0.1978508040779844
Validation loss: 2.3645704904301192

Epoch: 5| Step: 4
Training loss: 0.15568556164469394
Validation loss: 2.373728752470327

Epoch: 5| Step: 5
Training loss: 0.30944054949526606
Validation loss: 2.3829186017644823

Epoch: 5| Step: 6
Training loss: 0.35361327619323474
Validation loss: 2.369196723234798

Epoch: 5| Step: 7
Training loss: 0.18268475837881978
Validation loss: 2.37198621376818

Epoch: 5| Step: 8
Training loss: 0.2790216543756679
Validation loss: 2.436829797968163

Epoch: 5| Step: 9
Training loss: 0.4115065192323816
Validation loss: 2.4302331750682935

Epoch: 5| Step: 10
Training loss: 0.4416065942949175
Validation loss: 2.426299384229713

Epoch: 408| Step: 0
Training loss: 0.48497095669963897
Validation loss: 2.433584034120026

Epoch: 5| Step: 1
Training loss: 0.3822781862728476
Validation loss: 2.4351825493756105

Epoch: 5| Step: 2
Training loss: 0.2214081819863246
Validation loss: 2.4595176724921743

Epoch: 5| Step: 3
Training loss: 0.3733488727887697
Validation loss: 2.4436335238991513

Epoch: 5| Step: 4
Training loss: 0.423613357624844
Validation loss: 2.416644448109951

Epoch: 5| Step: 5
Training loss: 0.3107991063936991
Validation loss: 2.384398330926776

Epoch: 5| Step: 6
Training loss: 0.19822745432859992
Validation loss: 2.3585547950414947

Epoch: 5| Step: 7
Training loss: 0.17835729033847184
Validation loss: 2.3621740256173522

Epoch: 5| Step: 8
Training loss: 0.17186090021386977
Validation loss: 2.4085976226518886

Epoch: 5| Step: 9
Training loss: 0.2929372770570265
Validation loss: 2.439771890788591

Epoch: 5| Step: 10
Training loss: 0.2380826701064436
Validation loss: 2.447302226230804

Epoch: 409| Step: 0
Training loss: 0.40990685646458386
Validation loss: 2.4676791644304874

Epoch: 5| Step: 1
Training loss: 0.2718008104583834
Validation loss: 2.418148785716825

Epoch: 5| Step: 2
Training loss: 0.4113755404394327
Validation loss: 2.4406919380932663

Epoch: 5| Step: 3
Training loss: 0.3354778249834153
Validation loss: 2.4167415414935918

Epoch: 5| Step: 4
Training loss: 0.2167554248672126
Validation loss: 2.4023401622677065

Epoch: 5| Step: 5
Training loss: 0.40080154546022834
Validation loss: 2.3930432675934044

Epoch: 5| Step: 6
Training loss: 0.3521699743302093
Validation loss: 2.3947006765463166

Epoch: 5| Step: 7
Training loss: 0.17497598789872032
Validation loss: 2.3997103975691756

Epoch: 5| Step: 8
Training loss: 0.27501103097292606
Validation loss: 2.4580541180667494

Epoch: 5| Step: 9
Training loss: 0.2356036328181985
Validation loss: 2.4421754453389877

Epoch: 5| Step: 10
Training loss: 0.2953118278859074
Validation loss: 2.454516861741006

Epoch: 410| Step: 0
Training loss: 0.2630194327188094
Validation loss: 2.4635161380936257

Epoch: 5| Step: 1
Training loss: 0.1475336893248059
Validation loss: 2.434414550181112

Epoch: 5| Step: 2
Training loss: 0.1993841998898513
Validation loss: 2.428996160509141

Epoch: 5| Step: 3
Training loss: 0.43631239190760795
Validation loss: 2.407317752613111

Epoch: 5| Step: 4
Training loss: 0.25832394241881457
Validation loss: 2.40928367361966

Epoch: 5| Step: 5
Training loss: 0.4288897999317055
Validation loss: 2.341679570403324

Epoch: 5| Step: 6
Training loss: 0.2002002529372057
Validation loss: 2.319360021495287

Epoch: 5| Step: 7
Training loss: 0.29053771697687303
Validation loss: 2.3536722922088433

Epoch: 5| Step: 8
Training loss: 0.4077213126942833
Validation loss: 2.369819154324162

Epoch: 5| Step: 9
Training loss: 0.38575568839481766
Validation loss: 2.3882818286189047

Epoch: 5| Step: 10
Training loss: 0.24823362724377424
Validation loss: 2.427973091987516

Epoch: 411| Step: 0
Training loss: 0.14930304597869729
Validation loss: 2.431427273033017

Epoch: 5| Step: 1
Training loss: 0.396299535200283
Validation loss: 2.4131483245390477

Epoch: 5| Step: 2
Training loss: 0.2677630878120596
Validation loss: 2.42697560874368

Epoch: 5| Step: 3
Training loss: 0.28246376602767637
Validation loss: 2.380101674876659

Epoch: 5| Step: 4
Training loss: 0.3228758265705878
Validation loss: 2.3680112359840604

Epoch: 5| Step: 5
Training loss: 0.26233245293636337
Validation loss: 2.3556512922342776

Epoch: 5| Step: 6
Training loss: 0.44368013046814025
Validation loss: 2.3632822870496146

Epoch: 5| Step: 7
Training loss: 0.21223724789104859
Validation loss: 2.400284177310148

Epoch: 5| Step: 8
Training loss: 0.25952154179282644
Validation loss: 2.486081275807512

Epoch: 5| Step: 9
Training loss: 0.3560682627924859
Validation loss: 2.4930337857764218

Epoch: 5| Step: 10
Training loss: 0.35712061625438163
Validation loss: 2.5230613368949157

Epoch: 412| Step: 0
Training loss: 0.2182400498525335
Validation loss: 2.463458982199315

Epoch: 5| Step: 1
Training loss: 0.41107460026667364
Validation loss: 2.48111027153964

Epoch: 5| Step: 2
Training loss: 0.3395971741030247
Validation loss: 2.4306064768748907

Epoch: 5| Step: 3
Training loss: 0.13553426447535746
Validation loss: 2.3739822400386292

Epoch: 5| Step: 4
Training loss: 0.260703294689385
Validation loss: 2.2979340875758267

Epoch: 5| Step: 5
Training loss: 0.3500084863212913
Validation loss: 2.314333995797368

Epoch: 5| Step: 6
Training loss: 0.25787459694908993
Validation loss: 2.342374450209706

Epoch: 5| Step: 7
Training loss: 0.31401844664621026
Validation loss: 2.359712870027361

Epoch: 5| Step: 8
Training loss: 0.25421096417040545
Validation loss: 2.430932917465246

Epoch: 5| Step: 9
Training loss: 0.26624931568183174
Validation loss: 2.4610845800182215

Epoch: 5| Step: 10
Training loss: 0.4478807176165919
Validation loss: 2.484043647440765

Epoch: 413| Step: 0
Training loss: 0.3753752618954533
Validation loss: 2.5048780298794053

Epoch: 5| Step: 1
Training loss: 0.30993599457787685
Validation loss: 2.4515656164857154

Epoch: 5| Step: 2
Training loss: 0.3560397623672288
Validation loss: 2.4352479832818212

Epoch: 5| Step: 3
Training loss: 0.28486329537366456
Validation loss: 2.4074301955712785

Epoch: 5| Step: 4
Training loss: 0.20417469484900322
Validation loss: 2.3688897675012477

Epoch: 5| Step: 5
Training loss: 0.39222819356557354
Validation loss: 2.3808895556266645

Epoch: 5| Step: 6
Training loss: 0.31576499006188746
Validation loss: 2.3948762109852852

Epoch: 5| Step: 7
Training loss: 0.15768721725326632
Validation loss: 2.4635114874560116

Epoch: 5| Step: 8
Training loss: 0.29459204767216257
Validation loss: 2.514734749503955

Epoch: 5| Step: 9
Training loss: 0.43042688044972405
Validation loss: 2.553556526773864

Epoch: 5| Step: 10
Training loss: 0.18412408930092955
Validation loss: 2.512083965767861

Epoch: 414| Step: 0
Training loss: 0.2778429857182806
Validation loss: 2.425372303866766

Epoch: 5| Step: 1
Training loss: 0.3402282797511605
Validation loss: 2.3952400496613917

Epoch: 5| Step: 2
Training loss: 0.23875203292790048
Validation loss: 2.371615121540277

Epoch: 5| Step: 3
Training loss: 0.22624135276171228
Validation loss: 2.374353944851649

Epoch: 5| Step: 4
Training loss: 0.37553992740941233
Validation loss: 2.4116534603289184

Epoch: 5| Step: 5
Training loss: 0.45119463049901287
Validation loss: 2.4577128508662534

Epoch: 5| Step: 6
Training loss: 0.4327503972307891
Validation loss: 2.472946247704497

Epoch: 5| Step: 7
Training loss: 0.3097620710094485
Validation loss: 2.4975410468908796

Epoch: 5| Step: 8
Training loss: 0.22072031578697868
Validation loss: 2.4383037988777203

Epoch: 5| Step: 9
Training loss: 0.18806635238705322
Validation loss: 2.42050707580907

Epoch: 5| Step: 10
Training loss: 0.4818595357805753
Validation loss: 2.376476664258296

Epoch: 415| Step: 0
Training loss: 0.3491199199950221
Validation loss: 2.322727611376468

Epoch: 5| Step: 1
Training loss: 0.3914084017574532
Validation loss: 2.3031086158389504

Epoch: 5| Step: 2
Training loss: 0.2822251105353681
Validation loss: 2.3396691544742154

Epoch: 5| Step: 3
Training loss: 0.19869724905186026
Validation loss: 2.3512878006780045

Epoch: 5| Step: 4
Training loss: 0.37570811013927996
Validation loss: 2.430560471099555

Epoch: 5| Step: 5
Training loss: 0.32626545871269824
Validation loss: 2.49316859510089

Epoch: 5| Step: 6
Training loss: 0.2799891182794506
Validation loss: 2.470655904209456

Epoch: 5| Step: 7
Training loss: 0.3296667503769701
Validation loss: 2.460646630862584

Epoch: 5| Step: 8
Training loss: 0.20555971003338538
Validation loss: 2.3976718762424176

Epoch: 5| Step: 9
Training loss: 0.3020341835925438
Validation loss: 2.376998884883422

Epoch: 5| Step: 10
Training loss: 0.408024671324046
Validation loss: 2.3672190234660344

Epoch: 416| Step: 0
Training loss: 0.39915902125788966
Validation loss: 2.3644107178994007

Epoch: 5| Step: 1
Training loss: 0.20586033554866442
Validation loss: 2.3706805349301776

Epoch: 5| Step: 2
Training loss: 0.3181720603841545
Validation loss: 2.3552359126459224

Epoch: 5| Step: 3
Training loss: 0.22438995590413022
Validation loss: 2.4022331275684947

Epoch: 5| Step: 4
Training loss: 0.33945229884706674
Validation loss: 2.476444524820691

Epoch: 5| Step: 5
Training loss: 0.16030470434088642
Validation loss: 2.4968052077912897

Epoch: 5| Step: 6
Training loss: 0.26848765143443437
Validation loss: 2.504502028779618

Epoch: 5| Step: 7
Training loss: 0.4240918020471135
Validation loss: 2.531419237161863

Epoch: 5| Step: 8
Training loss: 0.4416984671114646
Validation loss: 2.4942483080128626

Epoch: 5| Step: 9
Training loss: 0.32150848919337927
Validation loss: 2.378105419563916

Epoch: 5| Step: 10
Training loss: 0.3233881272304625
Validation loss: 2.3190957702743833

Epoch: 417| Step: 0
Training loss: 0.44443482357115677
Validation loss: 2.2990654272709956

Epoch: 5| Step: 1
Training loss: 0.41519955393072655
Validation loss: 2.2570475699626336

Epoch: 5| Step: 2
Training loss: 0.2685611516001166
Validation loss: 2.273790445499368

Epoch: 5| Step: 3
Training loss: 0.11723734669717538
Validation loss: 2.3504795618019205

Epoch: 5| Step: 4
Training loss: 0.41210841680478616
Validation loss: 2.3852612524099683

Epoch: 5| Step: 5
Training loss: 0.23310436093499035
Validation loss: 2.4642839275920836

Epoch: 5| Step: 6
Training loss: 0.3428927265623455
Validation loss: 2.517316924544105

Epoch: 5| Step: 7
Training loss: 0.349478414717584
Validation loss: 2.506520844357804

Epoch: 5| Step: 8
Training loss: 0.2405812697492755
Validation loss: 2.4859059010923796

Epoch: 5| Step: 9
Training loss: 0.23590931155590272
Validation loss: 2.429271989427963

Epoch: 5| Step: 10
Training loss: 0.32051474303958855
Validation loss: 2.413991853061434

Epoch: 418| Step: 0
Training loss: 0.4183737316927279
Validation loss: 2.42094149029614

Epoch: 5| Step: 1
Training loss: 0.4302896788341777
Validation loss: 2.384313739386438

Epoch: 5| Step: 2
Training loss: 0.25465495422329465
Validation loss: 2.4048092421125076

Epoch: 5| Step: 3
Training loss: 0.2836346331465571
Validation loss: 2.417786082934533

Epoch: 5| Step: 4
Training loss: 0.31287389084241796
Validation loss: 2.4246801722565325

Epoch: 5| Step: 5
Training loss: 0.2903950622482311
Validation loss: 2.4484245141791443

Epoch: 5| Step: 6
Training loss: 0.21078240909639473
Validation loss: 2.429834970246378

Epoch: 5| Step: 7
Training loss: 0.15019344432844628
Validation loss: 2.447735083832965

Epoch: 5| Step: 8
Training loss: 0.39255398348695564
Validation loss: 2.457148875787792

Epoch: 5| Step: 9
Training loss: 0.272471793447272
Validation loss: 2.450936152863018

Epoch: 5| Step: 10
Training loss: 0.14094484565944693
Validation loss: 2.4420446588440217

Epoch: 419| Step: 0
Training loss: 0.21546459658729644
Validation loss: 2.3860449475167256

Epoch: 5| Step: 1
Training loss: 0.3469832689555638
Validation loss: 2.363048255938474

Epoch: 5| Step: 2
Training loss: 0.310275529078542
Validation loss: 2.354112740117813

Epoch: 5| Step: 3
Training loss: 0.4322316193144762
Validation loss: 2.369785883717387

Epoch: 5| Step: 4
Training loss: 0.48541698360296337
Validation loss: 2.4074224197553122

Epoch: 5| Step: 5
Training loss: 0.1798001641055282
Validation loss: 2.4786172152650554

Epoch: 5| Step: 6
Training loss: 0.3446358407356029
Validation loss: 2.5563563951553196

Epoch: 5| Step: 7
Training loss: 0.3551494715556043
Validation loss: 2.5860211649717475

Epoch: 5| Step: 8
Training loss: 0.18783328119087964
Validation loss: 2.5464154977782325

Epoch: 5| Step: 9
Training loss: 0.2636718467429817
Validation loss: 2.5130762533514144

Epoch: 5| Step: 10
Training loss: 0.20894259632375523
Validation loss: 2.447145485521578

Epoch: 420| Step: 0
Training loss: 0.4032466534832221
Validation loss: 2.4353678617513035

Epoch: 5| Step: 1
Training loss: 0.21947141456371574
Validation loss: 2.3925489318821227

Epoch: 5| Step: 2
Training loss: 0.2911517957555678
Validation loss: 2.373348481155983

Epoch: 5| Step: 3
Training loss: 0.27575000013142204
Validation loss: 2.4080206103570005

Epoch: 5| Step: 4
Training loss: 0.340500788395763
Validation loss: 2.380414852609917

Epoch: 5| Step: 5
Training loss: 0.32983762116477855
Validation loss: 2.3356169287464885

Epoch: 5| Step: 6
Training loss: 0.2465945627786248
Validation loss: 2.369821410931722

Epoch: 5| Step: 7
Training loss: 0.3538281866213795
Validation loss: 2.347528781746972

Epoch: 5| Step: 8
Training loss: 0.39428699599698447
Validation loss: 2.3577209634182923

Epoch: 5| Step: 9
Training loss: 0.2882475318935367
Validation loss: 2.3515360257729125

Epoch: 5| Step: 10
Training loss: 0.1896318693614139
Validation loss: 2.363260972117291

Epoch: 421| Step: 0
Training loss: 0.37523143302531403
Validation loss: 2.3856818626760137

Epoch: 5| Step: 1
Training loss: 0.41067150993492046
Validation loss: 2.3529945716848113

Epoch: 5| Step: 2
Training loss: 0.1993619927435436
Validation loss: 2.414116118885938

Epoch: 5| Step: 3
Training loss: 0.34478871593000243
Validation loss: 2.4074836661383237

Epoch: 5| Step: 4
Training loss: 0.30827887683540806
Validation loss: 2.4404758454798103

Epoch: 5| Step: 5
Training loss: 0.4061411198181653
Validation loss: 2.4193111168933963

Epoch: 5| Step: 6
Training loss: 0.22466565132023694
Validation loss: 2.4282914042725534

Epoch: 5| Step: 7
Training loss: 0.2894578240923074
Validation loss: 2.381031716749197

Epoch: 5| Step: 8
Training loss: 0.27420422822588064
Validation loss: 2.342039684979417

Epoch: 5| Step: 9
Training loss: 0.2049124366282417
Validation loss: 2.3763807694638284

Epoch: 5| Step: 10
Training loss: 0.1571180312599833
Validation loss: 2.347311079459768

Epoch: 422| Step: 0
Training loss: 0.2730735127303502
Validation loss: 2.3909405987856327

Epoch: 5| Step: 1
Training loss: 0.33635656699541644
Validation loss: 2.444809804139078

Epoch: 5| Step: 2
Training loss: 0.34558591633741975
Validation loss: 2.5178525714583624

Epoch: 5| Step: 3
Training loss: 0.18931790078054445
Validation loss: 2.5153677417816276

Epoch: 5| Step: 4
Training loss: 0.4582871030842765
Validation loss: 2.506107518843182

Epoch: 5| Step: 5
Training loss: 0.303413932780817
Validation loss: 2.419453560308747

Epoch: 5| Step: 6
Training loss: 0.23756957478113758
Validation loss: 2.3583527689176793

Epoch: 5| Step: 7
Training loss: 0.24451478896631004
Validation loss: 2.344230330274624

Epoch: 5| Step: 8
Training loss: 0.18962421753658432
Validation loss: 2.2846789412414514

Epoch: 5| Step: 9
Training loss: 0.3508023308789351
Validation loss: 2.2746241383776282

Epoch: 5| Step: 10
Training loss: 0.3617754049403139
Validation loss: 2.2890356411482125

Epoch: 423| Step: 0
Training loss: 0.23133939419924895
Validation loss: 2.3101532071734785

Epoch: 5| Step: 1
Training loss: 0.20440922596358246
Validation loss: 2.371035768000977

Epoch: 5| Step: 2
Training loss: 0.3761183632315508
Validation loss: 2.430280963448189

Epoch: 5| Step: 3
Training loss: 0.3245857872868148
Validation loss: 2.469937312251622

Epoch: 5| Step: 4
Training loss: 0.4074788764147603
Validation loss: 2.5223108218000516

Epoch: 5| Step: 5
Training loss: 0.18922843587011112
Validation loss: 2.4282472074910584

Epoch: 5| Step: 6
Training loss: 0.3832742280935017
Validation loss: 2.4030567326712897

Epoch: 5| Step: 7
Training loss: 0.2649260750260176
Validation loss: 2.3845611992856957

Epoch: 5| Step: 8
Training loss: 0.36940640766207233
Validation loss: 2.3730162824127934

Epoch: 5| Step: 9
Training loss: 0.2787667291479426
Validation loss: 2.3866722333740844

Epoch: 5| Step: 10
Training loss: 0.12698523775513812
Validation loss: 2.4193499275896

Epoch: 424| Step: 0
Training loss: 0.35201895010396783
Validation loss: 2.3825463388238135

Epoch: 5| Step: 1
Training loss: 0.3130722171397187
Validation loss: 2.431336879361556

Epoch: 5| Step: 2
Training loss: 0.3841885921064958
Validation loss: 2.4418518305583494

Epoch: 5| Step: 3
Training loss: 0.19819857676711505
Validation loss: 2.448385723541969

Epoch: 5| Step: 4
Training loss: 0.22160004348812554
Validation loss: 2.4695644797859426

Epoch: 5| Step: 5
Training loss: 0.3231139490499356
Validation loss: 2.432463922813042

Epoch: 5| Step: 6
Training loss: 0.3251368725019476
Validation loss: 2.3878780461907003

Epoch: 5| Step: 7
Training loss: 0.157360132713111
Validation loss: 2.344570382215812

Epoch: 5| Step: 8
Training loss: 0.28081050283119574
Validation loss: 2.348357696243801

Epoch: 5| Step: 9
Training loss: 0.29202286932254257
Validation loss: 2.3472962052776705

Epoch: 5| Step: 10
Training loss: 0.2615722844243288
Validation loss: 2.3445562046653174

Epoch: 425| Step: 0
Training loss: 0.47536748611947627
Validation loss: 2.402779778048907

Epoch: 5| Step: 1
Training loss: 0.32289559028918746
Validation loss: 2.4132944344007803

Epoch: 5| Step: 2
Training loss: 0.21249365762053146
Validation loss: 2.4122274292112658

Epoch: 5| Step: 3
Training loss: 0.27134605012397883
Validation loss: 2.42301552043877

Epoch: 5| Step: 4
Training loss: 0.17139100615526576
Validation loss: 2.415938408385721

Epoch: 5| Step: 5
Training loss: 0.3119244042905338
Validation loss: 2.395607866447196

Epoch: 5| Step: 6
Training loss: 0.12252045984218829
Validation loss: 2.3416005013529406

Epoch: 5| Step: 7
Training loss: 0.264586649082964
Validation loss: 2.3326873771456786

Epoch: 5| Step: 8
Training loss: 0.3517442657217485
Validation loss: 2.3300660564574676

Epoch: 5| Step: 9
Training loss: 0.25253657128092893
Validation loss: 2.3251552240417412

Epoch: 5| Step: 10
Training loss: 0.2555531569396549
Validation loss: 2.3616959455772997

Epoch: 426| Step: 0
Training loss: 0.3231639248702306
Validation loss: 2.4167971450269645

Epoch: 5| Step: 1
Training loss: 0.28278816339728363
Validation loss: 2.4118345207234966

Epoch: 5| Step: 2
Training loss: 0.31774669035246633
Validation loss: 2.4151627192905036

Epoch: 5| Step: 3
Training loss: 0.12920091646654794
Validation loss: 2.415331339703398

Epoch: 5| Step: 4
Training loss: 0.22452590054674518
Validation loss: 2.3883346233543765

Epoch: 5| Step: 5
Training loss: 0.270854094822165
Validation loss: 2.325737974822645

Epoch: 5| Step: 6
Training loss: 0.3224098229749653
Validation loss: 2.319573132236689

Epoch: 5| Step: 7
Training loss: 0.3576657239893222
Validation loss: 2.3263652510328034

Epoch: 5| Step: 8
Training loss: 0.2024455260075203
Validation loss: 2.328452754316985

Epoch: 5| Step: 9
Training loss: 0.33156186753625255
Validation loss: 2.3582001034240307

Epoch: 5| Step: 10
Training loss: 0.20869386392162834
Validation loss: 2.369875605648434

Epoch: 427| Step: 0
Training loss: 0.34436281805767693
Validation loss: 2.3972407084029554

Epoch: 5| Step: 1
Training loss: 0.34588353250399434
Validation loss: 2.4015310803592587

Epoch: 5| Step: 2
Training loss: 0.1890146746716004
Validation loss: 2.400238868830904

Epoch: 5| Step: 3
Training loss: 0.21171348501887235
Validation loss: 2.374857414460748

Epoch: 5| Step: 4
Training loss: 0.40547526286339103
Validation loss: 2.3593940492331082

Epoch: 5| Step: 5
Training loss: 0.17632071050588605
Validation loss: 2.392883067584561

Epoch: 5| Step: 6
Training loss: 0.30865104964207735
Validation loss: 2.4219806321283572

Epoch: 5| Step: 7
Training loss: 0.1917075491060554
Validation loss: 2.4692566469754613

Epoch: 5| Step: 8
Training loss: 0.31819998372693503
Validation loss: 2.4615521657063226

Epoch: 5| Step: 9
Training loss: 0.2800854707230771
Validation loss: 2.434915311791487

Epoch: 5| Step: 10
Training loss: 0.2573972160557455
Validation loss: 2.493293231198859

Epoch: 428| Step: 0
Training loss: 0.2363698780598257
Validation loss: 2.447505523847357

Epoch: 5| Step: 1
Training loss: 0.23352490274906942
Validation loss: 2.4472995413909495

Epoch: 5| Step: 2
Training loss: 0.31677830567599896
Validation loss: 2.4528418490472492

Epoch: 5| Step: 3
Training loss: 0.26495259391766085
Validation loss: 2.4444298491674603

Epoch: 5| Step: 4
Training loss: 0.34080437565572325
Validation loss: 2.4492677945138617

Epoch: 5| Step: 5
Training loss: 0.18311529514648836
Validation loss: 2.4061438051359016

Epoch: 5| Step: 6
Training loss: 0.2775426205347271
Validation loss: 2.429445108035426

Epoch: 5| Step: 7
Training loss: 0.2639578222426896
Validation loss: 2.420510985068431

Epoch: 5| Step: 8
Training loss: 0.215497911013858
Validation loss: 2.402316055384994

Epoch: 5| Step: 9
Training loss: 0.4067331705310387
Validation loss: 2.449744203493515

Epoch: 5| Step: 10
Training loss: 0.39981843955461494
Validation loss: 2.4242490090813753

Epoch: 429| Step: 0
Training loss: 0.24722161014278116
Validation loss: 2.4715112125605203

Epoch: 5| Step: 1
Training loss: 0.25732943042783263
Validation loss: 2.4437422386633445

Epoch: 5| Step: 2
Training loss: 0.36954540685267134
Validation loss: 2.5066619698528037

Epoch: 5| Step: 3
Training loss: 0.16429796238465474
Validation loss: 2.5036342559442804

Epoch: 5| Step: 4
Training loss: 0.254920576666876
Validation loss: 2.4638257983560368

Epoch: 5| Step: 5
Training loss: 0.27340804350091724
Validation loss: 2.392565923830874

Epoch: 5| Step: 6
Training loss: 0.37377032687177314
Validation loss: 2.3930463298707005

Epoch: 5| Step: 7
Training loss: 0.35791036441895807
Validation loss: 2.3512951046762383

Epoch: 5| Step: 8
Training loss: 0.16799920937020024
Validation loss: 2.360412148036874

Epoch: 5| Step: 9
Training loss: 0.3511903276358499
Validation loss: 2.342934047630441

Epoch: 5| Step: 10
Training loss: 0.20721778922964962
Validation loss: 2.3702789970298963

Epoch: 430| Step: 0
Training loss: 0.23636180858326342
Validation loss: 2.374636147805757

Epoch: 5| Step: 1
Training loss: 0.35340668912471196
Validation loss: 2.400560535068629

Epoch: 5| Step: 2
Training loss: 0.2881403208980731
Validation loss: 2.391334985360616

Epoch: 5| Step: 3
Training loss: 0.39019740543382736
Validation loss: 2.4365943559867174

Epoch: 5| Step: 4
Training loss: 0.2407036129613163
Validation loss: 2.430082602086782

Epoch: 5| Step: 5
Training loss: 0.30727692207695545
Validation loss: 2.4452115421735963

Epoch: 5| Step: 6
Training loss: 0.37978701131244524
Validation loss: 2.4327206049073244

Epoch: 5| Step: 7
Training loss: 0.20175728294694503
Validation loss: 2.4542893671249955

Epoch: 5| Step: 8
Training loss: 0.30354092123105464
Validation loss: 2.4099403925952494

Epoch: 5| Step: 9
Training loss: 0.1407222080686846
Validation loss: 2.400232822971768

Epoch: 5| Step: 10
Training loss: 0.14417713834813292
Validation loss: 2.443409944110036

Epoch: 431| Step: 0
Training loss: 0.17144144168151018
Validation loss: 2.4167031386879625

Epoch: 5| Step: 1
Training loss: 0.3086862304794241
Validation loss: 2.4322579661199275

Epoch: 5| Step: 2
Training loss: 0.23623905394945457
Validation loss: 2.3907255596212185

Epoch: 5| Step: 3
Training loss: 0.3237438745729255
Validation loss: 2.3716247848362153

Epoch: 5| Step: 4
Training loss: 0.3885370528669055
Validation loss: 2.378346927010201

Epoch: 5| Step: 5
Training loss: 0.28704573775906045
Validation loss: 2.3815396744078394

Epoch: 5| Step: 6
Training loss: 0.26269261809034383
Validation loss: 2.4332314719713777

Epoch: 5| Step: 7
Training loss: 0.2946057172379772
Validation loss: 2.4446948354913025

Epoch: 5| Step: 8
Training loss: 0.25292364871795386
Validation loss: 2.4444085197482854

Epoch: 5| Step: 9
Training loss: 0.15434893200739322
Validation loss: 2.4254416178346268

Epoch: 5| Step: 10
Training loss: 0.3484167075688988
Validation loss: 2.4312557702170423

Epoch: 432| Step: 0
Training loss: 0.23483272202995184
Validation loss: 2.4302996557467518

Epoch: 5| Step: 1
Training loss: 0.21653239123450663
Validation loss: 2.419231424055166

Epoch: 5| Step: 2
Training loss: 0.18176944840531203
Validation loss: 2.394110927136889

Epoch: 5| Step: 3
Training loss: 0.2957022113861524
Validation loss: 2.3526909925981156

Epoch: 5| Step: 4
Training loss: 0.26104090577603506
Validation loss: 2.3758181418703725

Epoch: 5| Step: 5
Training loss: 0.18325281953594122
Validation loss: 2.37384559757361

Epoch: 5| Step: 6
Training loss: 0.10853230741564038
Validation loss: 2.4074124630109894

Epoch: 5| Step: 7
Training loss: 0.4778315422699572
Validation loss: 2.4131791270401837

Epoch: 5| Step: 8
Training loss: 0.27886393143195304
Validation loss: 2.4131095277754957

Epoch: 5| Step: 9
Training loss: 0.1482676613573665
Validation loss: 2.4058615103616043

Epoch: 5| Step: 10
Training loss: 0.3835605591440039
Validation loss: 2.42645154329195

Epoch: 433| Step: 0
Training loss: 0.1385943034633006
Validation loss: 2.357263325397639

Epoch: 5| Step: 1
Training loss: 0.39039906643605393
Validation loss: 2.339950440487352

Epoch: 5| Step: 2
Training loss: 0.3426238600368526
Validation loss: 2.3758515438116357

Epoch: 5| Step: 3
Training loss: 0.37505594472014686
Validation loss: 2.3907197422377413

Epoch: 5| Step: 4
Training loss: 0.21302625727724006
Validation loss: 2.3990958426146776

Epoch: 5| Step: 5
Training loss: 0.17457929923962526
Validation loss: 2.4449532281716153

Epoch: 5| Step: 6
Training loss: 0.27499776915165564
Validation loss: 2.4300222238496425

Epoch: 5| Step: 7
Training loss: 0.2024222652441847
Validation loss: 2.43819122988883

Epoch: 5| Step: 8
Training loss: 0.2059987159389225
Validation loss: 2.443671542304686

Epoch: 5| Step: 9
Training loss: 0.30958767670750237
Validation loss: 2.4327019291031062

Epoch: 5| Step: 10
Training loss: 0.3015445461759454
Validation loss: 2.440961509180888

Epoch: 434| Step: 0
Training loss: 0.288136481037732
Validation loss: 2.438065532942424

Epoch: 5| Step: 1
Training loss: 0.21740841744732353
Validation loss: 2.431711915716419

Epoch: 5| Step: 2
Training loss: 0.2956297129483199
Validation loss: 2.3798238505176266

Epoch: 5| Step: 3
Training loss: 0.24599640298409767
Validation loss: 2.373958358682216

Epoch: 5| Step: 4
Training loss: 0.32211126618867536
Validation loss: 2.3443730806539187

Epoch: 5| Step: 5
Training loss: 0.2983178413131917
Validation loss: 2.3393858872961535

Epoch: 5| Step: 6
Training loss: 0.31320083232905455
Validation loss: 2.3554795445093997

Epoch: 5| Step: 7
Training loss: 0.340160463453349
Validation loss: 2.358838541996319

Epoch: 5| Step: 8
Training loss: 0.26787029103524945
Validation loss: 2.4054849295577303

Epoch: 5| Step: 9
Training loss: 0.17447749476319743
Validation loss: 2.4287359624949976

Epoch: 5| Step: 10
Training loss: 0.2043407444141483
Validation loss: 2.4644089925721233

Epoch: 435| Step: 0
Training loss: 0.36620888264397455
Validation loss: 2.468996274789884

Epoch: 5| Step: 1
Training loss: 0.2570881928325188
Validation loss: 2.4102496086543606

Epoch: 5| Step: 2
Training loss: 0.22135860027286175
Validation loss: 2.425476921201755

Epoch: 5| Step: 3
Training loss: 0.28999017374064073
Validation loss: 2.365332966321633

Epoch: 5| Step: 4
Training loss: 0.3519710286420701
Validation loss: 2.349571311937723

Epoch: 5| Step: 5
Training loss: 0.34206753504759113
Validation loss: 2.3561670717811034

Epoch: 5| Step: 6
Training loss: 0.25318278901033253
Validation loss: 2.3456526637444006

Epoch: 5| Step: 7
Training loss: 0.2903054808721776
Validation loss: 2.3381542130858834

Epoch: 5| Step: 8
Training loss: 0.14897383243004353
Validation loss: 2.364454343861767

Epoch: 5| Step: 9
Training loss: 0.10571950667119236
Validation loss: 2.384318679976395

Epoch: 5| Step: 10
Training loss: 0.1591135133206798
Validation loss: 2.3893241109568693

Epoch: 436| Step: 0
Training loss: 0.2982445047884328
Validation loss: 2.3940230445895847

Epoch: 5| Step: 1
Training loss: 0.15839456231284094
Validation loss: 2.374679324656893

Epoch: 5| Step: 2
Training loss: 0.30701916406348567
Validation loss: 2.368086515932401

Epoch: 5| Step: 3
Training loss: 0.14169606311105226
Validation loss: 2.3696251267190873

Epoch: 5| Step: 4
Training loss: 0.19043024503186112
Validation loss: 2.344144963719339

Epoch: 5| Step: 5
Training loss: 0.2463647470493995
Validation loss: 2.3833575570254975

Epoch: 5| Step: 6
Training loss: 0.3287070992076264
Validation loss: 2.382361946296263

Epoch: 5| Step: 7
Training loss: 0.3019340025458988
Validation loss: 2.380716983911889

Epoch: 5| Step: 8
Training loss: 0.20146467141362714
Validation loss: 2.3965818508332064

Epoch: 5| Step: 9
Training loss: 0.33675361904148016
Validation loss: 2.4641978740482213

Epoch: 5| Step: 10
Training loss: 0.3122465178499392
Validation loss: 2.4114825883746436

Epoch: 437| Step: 0
Training loss: 0.3176051608093324
Validation loss: 2.401114836771461

Epoch: 5| Step: 1
Training loss: 0.21151050693654383
Validation loss: 2.3816867599972147

Epoch: 5| Step: 2
Training loss: 0.44801239905378176
Validation loss: 2.347764331488513

Epoch: 5| Step: 3
Training loss: 0.26177594997436554
Validation loss: 2.3824336705148195

Epoch: 5| Step: 4
Training loss: 0.2171516951542899
Validation loss: 2.420364002740168

Epoch: 5| Step: 5
Training loss: 0.2187731338938603
Validation loss: 2.422270572045957

Epoch: 5| Step: 6
Training loss: 0.19463706528194508
Validation loss: 2.432767406546805

Epoch: 5| Step: 7
Training loss: 0.3399058318160538
Validation loss: 2.4418700657794137

Epoch: 5| Step: 8
Training loss: 0.11737992859152417
Validation loss: 2.4447026374695353

Epoch: 5| Step: 9
Training loss: 0.23902964709065277
Validation loss: 2.4470581561756

Epoch: 5| Step: 10
Training loss: 0.19809343366331378
Validation loss: 2.42785313824399

Epoch: 438| Step: 0
Training loss: 0.3248082282905015
Validation loss: 2.3990488222252884

Epoch: 5| Step: 1
Training loss: 0.3321630216427388
Validation loss: 2.387906454178134

Epoch: 5| Step: 2
Training loss: 0.2039164018113516
Validation loss: 2.3993291859086674

Epoch: 5| Step: 3
Training loss: 0.23340535652407418
Validation loss: 2.4170796289388767

Epoch: 5| Step: 4
Training loss: 0.31443049663371636
Validation loss: 2.485759347091673

Epoch: 5| Step: 5
Training loss: 0.39665395182712637
Validation loss: 2.574014349251501

Epoch: 5| Step: 6
Training loss: 0.34274352722956514
Validation loss: 2.521421089559161

Epoch: 5| Step: 7
Training loss: 0.13796076652135633
Validation loss: 2.463544194707714

Epoch: 5| Step: 8
Training loss: 0.15010701102575977
Validation loss: 2.3962328511287447

Epoch: 5| Step: 9
Training loss: 0.32671826676816884
Validation loss: 2.36104739610077

Epoch: 5| Step: 10
Training loss: 0.24911086847665986
Validation loss: 2.2789088086149207

Epoch: 439| Step: 0
Training loss: 0.3945355934432749
Validation loss: 2.305745891570974

Epoch: 5| Step: 1
Training loss: 0.3552666812902333
Validation loss: 2.377773313578965

Epoch: 5| Step: 2
Training loss: 0.4209834143583724
Validation loss: 2.418859223050271

Epoch: 5| Step: 3
Training loss: 0.3016703704260625
Validation loss: 2.503871592218347

Epoch: 5| Step: 4
Training loss: 0.31355420158313413
Validation loss: 2.551313972822045

Epoch: 5| Step: 5
Training loss: 0.4649379538600392
Validation loss: 2.513059593708105

Epoch: 5| Step: 6
Training loss: 0.21281173539269396
Validation loss: 2.3930977232656683

Epoch: 5| Step: 7
Training loss: 0.26198106402297205
Validation loss: 2.297099377564293

Epoch: 5| Step: 8
Training loss: 0.3259450843565012
Validation loss: 2.24437253027552

Epoch: 5| Step: 9
Training loss: 0.5812802429945191
Validation loss: 2.249672073932586

Epoch: 5| Step: 10
Training loss: 0.262976258658581
Validation loss: 2.310608404745908

Epoch: 440| Step: 0
Training loss: 0.27480321150371817
Validation loss: 2.4596944335989193

Epoch: 5| Step: 1
Training loss: 0.3618469225412237
Validation loss: 2.6209091503703035

Epoch: 5| Step: 2
Training loss: 0.46574463619454554
Validation loss: 2.655327397719472

Epoch: 5| Step: 3
Training loss: 0.4669323329626885
Validation loss: 2.5275815954627494

Epoch: 5| Step: 4
Training loss: 0.40270947990839717
Validation loss: 2.302992862723217

Epoch: 5| Step: 5
Training loss: 0.3692541805578217
Validation loss: 2.1690474573205223

Epoch: 5| Step: 6
Training loss: 0.5629286192672809
Validation loss: 2.0793146353225103

Epoch: 5| Step: 7
Training loss: 0.38017951734202865
Validation loss: 2.122937094494238

Epoch: 5| Step: 8
Training loss: 0.465330013819161
Validation loss: 2.156353980540459

Epoch: 5| Step: 9
Training loss: 0.5366887335456025
Validation loss: 2.2601167644240925

Epoch: 5| Step: 10
Training loss: 0.3889989961939709
Validation loss: 2.3932218496066677

Epoch: 441| Step: 0
Training loss: 0.42383891852210626
Validation loss: 2.5498930176956516

Epoch: 5| Step: 1
Training loss: 0.4046706347099453
Validation loss: 2.6431488055606605

Epoch: 5| Step: 2
Training loss: 0.7283590521807121
Validation loss: 2.6399581384117163

Epoch: 5| Step: 3
Training loss: 0.44540742230553804
Validation loss: 2.3957981708045355

Epoch: 5| Step: 4
Training loss: 0.36427086200810355
Validation loss: 2.221037372393304

Epoch: 5| Step: 5
Training loss: 0.4353844378223586
Validation loss: 2.1849814582061073

Epoch: 5| Step: 6
Training loss: 0.817225761320189
Validation loss: 2.179312036292431

Epoch: 5| Step: 7
Training loss: 0.34614029952332587
Validation loss: 2.241005666270095

Epoch: 5| Step: 8
Training loss: 0.3691914437649886
Validation loss: 2.3178253925918026

Epoch: 5| Step: 9
Training loss: 0.5539424620764101
Validation loss: 2.4244923072746887

Epoch: 5| Step: 10
Training loss: 0.405525607053127
Validation loss: 2.3986471707857784

Epoch: 442| Step: 0
Training loss: 0.2994520617395758
Validation loss: 2.3507653494894134

Epoch: 5| Step: 1
Training loss: 0.5378077457712136
Validation loss: 2.3001908713543004

Epoch: 5| Step: 2
Training loss: 0.31067160734523785
Validation loss: 2.294196586771219

Epoch: 5| Step: 3
Training loss: 0.5595884736261247
Validation loss: 2.2288622628654275

Epoch: 5| Step: 4
Training loss: 0.5647618330652617
Validation loss: 2.2391218617636155

Epoch: 5| Step: 5
Training loss: 0.39793472731714596
Validation loss: 2.300011122896461

Epoch: 5| Step: 6
Training loss: 0.394436324379997
Validation loss: 2.4047940210395873

Epoch: 5| Step: 7
Training loss: 0.5480584554611095
Validation loss: 2.570102939814485

Epoch: 5| Step: 8
Training loss: 0.8235918888367011
Validation loss: 2.603669117967963

Epoch: 5| Step: 9
Training loss: 0.311186234269534
Validation loss: 2.41525455763022

Epoch: 5| Step: 10
Training loss: 0.5280479815150222
Validation loss: 2.276639299012757

Epoch: 443| Step: 0
Training loss: 0.38414656511345296
Validation loss: 2.2397922769441294

Epoch: 5| Step: 1
Training loss: 0.4398885646505291
Validation loss: 2.1776510802399707

Epoch: 5| Step: 2
Training loss: 0.5707284377357361
Validation loss: 2.2138527484498582

Epoch: 5| Step: 3
Training loss: 0.19253445956268908
Validation loss: 2.325268111536176

Epoch: 5| Step: 4
Training loss: 0.3419706284433857
Validation loss: 2.4128043609131278

Epoch: 5| Step: 5
Training loss: 0.5129582484713145
Validation loss: 2.444566276487417

Epoch: 5| Step: 6
Training loss: 0.3917414351210499
Validation loss: 2.4851757932921723

Epoch: 5| Step: 7
Training loss: 0.4974858284134701
Validation loss: 2.5476453360881615

Epoch: 5| Step: 8
Training loss: 0.5143720547022803
Validation loss: 2.5486289937015063

Epoch: 5| Step: 9
Training loss: 0.32271007753881387
Validation loss: 2.440975425066684

Epoch: 5| Step: 10
Training loss: 0.2661875210018826
Validation loss: 2.3594479624612084

Epoch: 444| Step: 0
Training loss: 0.1807340125681087
Validation loss: 2.308333479458994

Epoch: 5| Step: 1
Training loss: 0.28202910594178043
Validation loss: 2.2949365636058325

Epoch: 5| Step: 2
Training loss: 0.32004575554986653
Validation loss: 2.282149481008427

Epoch: 5| Step: 3
Training loss: 0.42916725916343207
Validation loss: 2.305562714999962

Epoch: 5| Step: 4
Training loss: 0.3647712586491356
Validation loss: 2.348403864859493

Epoch: 5| Step: 5
Training loss: 0.27552124064270567
Validation loss: 2.397144335768901

Epoch: 5| Step: 6
Training loss: 0.36515897084676446
Validation loss: 2.4842936803751123

Epoch: 5| Step: 7
Training loss: 0.38614222390143255
Validation loss: 2.469777666072313

Epoch: 5| Step: 8
Training loss: 0.29186522871811293
Validation loss: 2.4820706807514568

Epoch: 5| Step: 9
Training loss: 0.36791745129966374
Validation loss: 2.438015868754778

Epoch: 5| Step: 10
Training loss: 0.4229853464681696
Validation loss: 2.4114504464765854

Epoch: 445| Step: 0
Training loss: 0.44636713592964317
Validation loss: 2.374427007391239

Epoch: 5| Step: 1
Training loss: 0.3562469348440986
Validation loss: 2.3802590984862726

Epoch: 5| Step: 2
Training loss: 0.33653265331045507
Validation loss: 2.3502219440055443

Epoch: 5| Step: 3
Training loss: 0.19437471319220379
Validation loss: 2.3295053828992374

Epoch: 5| Step: 4
Training loss: 0.349831569113712
Validation loss: 2.3443920347205194

Epoch: 5| Step: 5
Training loss: 0.16458247301222886
Validation loss: 2.3740278736086435

Epoch: 5| Step: 6
Training loss: 0.3693791179136984
Validation loss: 2.4176712373945164

Epoch: 5| Step: 7
Training loss: 0.38728122072597576
Validation loss: 2.453255157644085

Epoch: 5| Step: 8
Training loss: 0.2366400779952046
Validation loss: 2.492275653475476

Epoch: 5| Step: 9
Training loss: 0.3314535500756535
Validation loss: 2.540142801450068

Epoch: 5| Step: 10
Training loss: 0.43528510468234743
Validation loss: 2.4515151246292763

Epoch: 446| Step: 0
Training loss: 0.27665836644696196
Validation loss: 2.381408838511397

Epoch: 5| Step: 1
Training loss: 0.23247600373905633
Validation loss: 2.277893113841947

Epoch: 5| Step: 2
Training loss: 0.3948860838959566
Validation loss: 2.238012191904425

Epoch: 5| Step: 3
Training loss: 0.5164152216745158
Validation loss: 2.228100422097129

Epoch: 5| Step: 4
Training loss: 0.36325421796740226
Validation loss: 2.280012304899434

Epoch: 5| Step: 5
Training loss: 0.27511926903966993
Validation loss: 2.280374155720708

Epoch: 5| Step: 6
Training loss: 0.19747946262716404
Validation loss: 2.3458354179337944

Epoch: 5| Step: 7
Training loss: 0.3026450486835497
Validation loss: 2.419627093477413

Epoch: 5| Step: 8
Training loss: 0.3573822249635884
Validation loss: 2.457483783743906

Epoch: 5| Step: 9
Training loss: 0.268525458392505
Validation loss: 2.48017974454041

Epoch: 5| Step: 10
Training loss: 0.587575859894233
Validation loss: 2.5007249170817145

Epoch: 447| Step: 0
Training loss: 0.2872006796634224
Validation loss: 2.4090692624432255

Epoch: 5| Step: 1
Training loss: 0.29507944811220593
Validation loss: 2.352006295757854

Epoch: 5| Step: 2
Training loss: 0.2506108272378888
Validation loss: 2.305053942931828

Epoch: 5| Step: 3
Training loss: 0.4487614999694894
Validation loss: 2.2718152761236583

Epoch: 5| Step: 4
Training loss: 0.33815265704584235
Validation loss: 2.2764501575143306

Epoch: 5| Step: 5
Training loss: 0.4747298758793002
Validation loss: 2.3338308140956694

Epoch: 5| Step: 6
Training loss: 0.3671334206547647
Validation loss: 2.3687955082183128

Epoch: 5| Step: 7
Training loss: 0.2267301777536672
Validation loss: 2.4704682847785433

Epoch: 5| Step: 8
Training loss: 0.37437512071381474
Validation loss: 2.5355321712663685

Epoch: 5| Step: 9
Training loss: 0.3497837100829015
Validation loss: 2.5967435121618587

Epoch: 5| Step: 10
Training loss: 0.4335226739587732
Validation loss: 2.6310623548268395

Epoch: 448| Step: 0
Training loss: 0.37805309794271275
Validation loss: 2.56226489561509

Epoch: 5| Step: 1
Training loss: 0.27602594558765303
Validation loss: 2.4728409856690377

Epoch: 5| Step: 2
Training loss: 0.2039483147564388
Validation loss: 2.3196630344098454

Epoch: 5| Step: 3
Training loss: 0.349667059545566
Validation loss: 2.2381736355683817

Epoch: 5| Step: 4
Training loss: 0.37723333192510544
Validation loss: 2.1878893703464986

Epoch: 5| Step: 5
Training loss: 0.3095337036821222
Validation loss: 2.1659899371407696

Epoch: 5| Step: 6
Training loss: 0.2583571085961676
Validation loss: 2.231194269703306

Epoch: 5| Step: 7
Training loss: 0.2992709998185549
Validation loss: 2.3054240711824114

Epoch: 5| Step: 8
Training loss: 0.27415379301000936
Validation loss: 2.360204921077633

Epoch: 5| Step: 9
Training loss: 0.4035213052768965
Validation loss: 2.3860994748036464

Epoch: 5| Step: 10
Training loss: 0.3313581263211549
Validation loss: 2.453529911289067

Epoch: 449| Step: 0
Training loss: 0.36592084457452406
Validation loss: 2.3990374671792347

Epoch: 5| Step: 1
Training loss: 0.18509498580579317
Validation loss: 2.3659515538668066

Epoch: 5| Step: 2
Training loss: 0.2875491945015323
Validation loss: 2.3486636293688683

Epoch: 5| Step: 3
Training loss: 0.25082467080574405
Validation loss: 2.305684378831454

Epoch: 5| Step: 4
Training loss: 0.39200689024976115
Validation loss: 2.2752168266067647

Epoch: 5| Step: 5
Training loss: 0.3982880255869975
Validation loss: 2.257425408957617

Epoch: 5| Step: 6
Training loss: 0.20696961187096533
Validation loss: 2.285157118885572

Epoch: 5| Step: 7
Training loss: 0.3780205393173631
Validation loss: 2.3545336780727193

Epoch: 5| Step: 8
Training loss: 0.17978779440150688
Validation loss: 2.3753984264978323

Epoch: 5| Step: 9
Training loss: 0.20153595098962415
Validation loss: 2.3810711169338177

Epoch: 5| Step: 10
Training loss: 0.34592919581783305
Validation loss: 2.4967708816616585

Epoch: 450| Step: 0
Training loss: 0.2890641495941107
Validation loss: 2.4738017295057384

Epoch: 5| Step: 1
Training loss: 0.2518621176840061
Validation loss: 2.4950480721879194

Epoch: 5| Step: 2
Training loss: 0.2751534164083516
Validation loss: 2.4561062801209124

Epoch: 5| Step: 3
Training loss: 0.24809132575693274
Validation loss: 2.424593990375471

Epoch: 5| Step: 4
Training loss: 0.24223664000571254
Validation loss: 2.3725955991998102

Epoch: 5| Step: 5
Training loss: 0.2074085432462948
Validation loss: 2.3791156431948983

Epoch: 5| Step: 6
Training loss: 0.29739676601755805
Validation loss: 2.3167605431157474

Epoch: 5| Step: 7
Training loss: 0.30761023619533134
Validation loss: 2.2766112159395333

Epoch: 5| Step: 8
Training loss: 0.4036691371794612
Validation loss: 2.259523941196217

Epoch: 5| Step: 9
Training loss: 0.21206662184489594
Validation loss: 2.269026136428895

Epoch: 5| Step: 10
Training loss: 0.2568260887201271
Validation loss: 2.2452072572745276

Epoch: 451| Step: 0
Training loss: 0.1756588668767438
Validation loss: 2.2468943286519463

Epoch: 5| Step: 1
Training loss: 0.1636641411786357
Validation loss: 2.3221789288088606

Epoch: 5| Step: 2
Training loss: 0.28867264826236133
Validation loss: 2.314906736164465

Epoch: 5| Step: 3
Training loss: 0.27765412492427227
Validation loss: 2.341403216689539

Epoch: 5| Step: 4
Training loss: 0.14807498106477351
Validation loss: 2.4072886157730786

Epoch: 5| Step: 5
Training loss: 0.22132096696098602
Validation loss: 2.4300816568421824

Epoch: 5| Step: 6
Training loss: 0.37401301914774576
Validation loss: 2.470929289993361

Epoch: 5| Step: 7
Training loss: 0.22216862269714024
Validation loss: 2.4220439077934275

Epoch: 5| Step: 8
Training loss: 0.28022709905379517
Validation loss: 2.4161563670180657

Epoch: 5| Step: 9
Training loss: 0.2822094288413334
Validation loss: 2.372680607168327

Epoch: 5| Step: 10
Training loss: 0.31245962120491383
Validation loss: 2.406608746573935

Epoch: 452| Step: 0
Training loss: 0.21641178124034724
Validation loss: 2.34395341325443

Epoch: 5| Step: 1
Training loss: 0.3070673069638807
Validation loss: 2.360866392275022

Epoch: 5| Step: 2
Training loss: 0.2391805329370953
Validation loss: 2.37257593794852

Epoch: 5| Step: 3
Training loss: 0.295160336120335
Validation loss: 2.367004725909527

Epoch: 5| Step: 4
Training loss: 0.2609948923188504
Validation loss: 2.40447638095556

Epoch: 5| Step: 5
Training loss: 0.31021955021923797
Validation loss: 2.375849001590265

Epoch: 5| Step: 6
Training loss: 0.2462131725163234
Validation loss: 2.385532345357936

Epoch: 5| Step: 7
Training loss: 0.3624442106922583
Validation loss: 2.3470248438525347

Epoch: 5| Step: 8
Training loss: 0.12404362071254425
Validation loss: 2.3175941515665315

Epoch: 5| Step: 9
Training loss: 0.18425245010760388
Validation loss: 2.3224773586615193

Epoch: 5| Step: 10
Training loss: 0.11217319835020917
Validation loss: 2.3477142825309745

Epoch: 453| Step: 0
Training loss: 0.24658938104232384
Validation loss: 2.3749365358233456

Epoch: 5| Step: 1
Training loss: 0.18155518439913645
Validation loss: 2.3833809919330142

Epoch: 5| Step: 2
Training loss: 0.3282133846227598
Validation loss: 2.3633228059357725

Epoch: 5| Step: 3
Training loss: 0.11707321793441959
Validation loss: 2.3893452011633474

Epoch: 5| Step: 4
Training loss: 0.30079826703174783
Validation loss: 2.4104153517495446

Epoch: 5| Step: 5
Training loss: 0.29875208317257806
Validation loss: 2.4379037291843195

Epoch: 5| Step: 6
Training loss: 0.16889657436609973
Validation loss: 2.4065557316794375

Epoch: 5| Step: 7
Training loss: 0.19525645405582945
Validation loss: 2.4000952124082144

Epoch: 5| Step: 8
Training loss: 0.3041782525002871
Validation loss: 2.37317397618152

Epoch: 5| Step: 9
Training loss: 0.2072892201261698
Validation loss: 2.351844985124778

Epoch: 5| Step: 10
Training loss: 0.2531830538592607
Validation loss: 2.3483579855373478

Epoch: 454| Step: 0
Training loss: 0.2718134744678887
Validation loss: 2.3470559346967237

Epoch: 5| Step: 1
Training loss: 0.1581812419591714
Validation loss: 2.320129108856973

Epoch: 5| Step: 2
Training loss: 0.1838597946998602
Validation loss: 2.3413679108460372

Epoch: 5| Step: 3
Training loss: 0.29132153606661676
Validation loss: 2.3232808529567666

Epoch: 5| Step: 4
Training loss: 0.2261055251128486
Validation loss: 2.3440377297386825

Epoch: 5| Step: 5
Training loss: 0.23286767088270108
Validation loss: 2.3328061856096043

Epoch: 5| Step: 6
Training loss: 0.1650792022287197
Validation loss: 2.365884559911074

Epoch: 5| Step: 7
Training loss: 0.2563700784232224
Validation loss: 2.3734800022388076

Epoch: 5| Step: 8
Training loss: 0.11856718892984161
Validation loss: 2.406175043041021

Epoch: 5| Step: 9
Training loss: 0.2581203818658581
Validation loss: 2.438698288176437

Epoch: 5| Step: 10
Training loss: 0.38630052550870386
Validation loss: 2.4651140349185905

Epoch: 455| Step: 0
Training loss: 0.23679836243779298
Validation loss: 2.464196601173522

Epoch: 5| Step: 1
Training loss: 0.1764925816178507
Validation loss: 2.446264670847279

Epoch: 5| Step: 2
Training loss: 0.18347568977120782
Validation loss: 2.4428416007040084

Epoch: 5| Step: 3
Training loss: 0.19612416415282596
Validation loss: 2.4333505885121642

Epoch: 5| Step: 4
Training loss: 0.2579161551202889
Validation loss: 2.373462074357413

Epoch: 5| Step: 5
Training loss: 0.22141654407258302
Validation loss: 2.346609156489201

Epoch: 5| Step: 6
Training loss: 0.29256724501626485
Validation loss: 2.334097956336257

Epoch: 5| Step: 7
Training loss: 0.27401655736376207
Validation loss: 2.3477927847962694

Epoch: 5| Step: 8
Training loss: 0.1491442531845767
Validation loss: 2.2993219406148464

Epoch: 5| Step: 9
Training loss: 0.20836137443816086
Validation loss: 2.2904090536805133

Epoch: 5| Step: 10
Training loss: 0.36946465132042744
Validation loss: 2.3486432351033812

Epoch: 456| Step: 0
Training loss: 0.11978582483711794
Validation loss: 2.300735583211585

Epoch: 5| Step: 1
Training loss: 0.18173676684372264
Validation loss: 2.3545184216126827

Epoch: 5| Step: 2
Training loss: 0.22305321859768792
Validation loss: 2.36979643451509

Epoch: 5| Step: 3
Training loss: 0.3164993667159291
Validation loss: 2.3795725700236168

Epoch: 5| Step: 4
Training loss: 0.2257586969509503
Validation loss: 2.3992380469161154

Epoch: 5| Step: 5
Training loss: 0.18475621060345523
Validation loss: 2.4211601030500187

Epoch: 5| Step: 6
Training loss: 0.30802628698198564
Validation loss: 2.4218097552278093

Epoch: 5| Step: 7
Training loss: 0.20556892520330744
Validation loss: 2.422310144959529

Epoch: 5| Step: 8
Training loss: 0.3159035586530113
Validation loss: 2.444119699254414

Epoch: 5| Step: 9
Training loss: 0.2656313671022137
Validation loss: 2.424916248759171

Epoch: 5| Step: 10
Training loss: 0.14207963153019829
Validation loss: 2.381726973852023

Epoch: 457| Step: 0
Training loss: 0.24446673928640422
Validation loss: 2.360046510646542

Epoch: 5| Step: 1
Training loss: 0.22735934056574159
Validation loss: 2.330032555994683

Epoch: 5| Step: 2
Training loss: 0.1831069742776648
Validation loss: 2.3490937380413786

Epoch: 5| Step: 3
Training loss: 0.17409091544595534
Validation loss: 2.3650514895344648

Epoch: 5| Step: 4
Training loss: 0.18077663316823805
Validation loss: 2.375039559613966

Epoch: 5| Step: 5
Training loss: 0.17069418554227767
Validation loss: 2.375855859970722

Epoch: 5| Step: 6
Training loss: 0.16062197193490238
Validation loss: 2.385012803686014

Epoch: 5| Step: 7
Training loss: 0.1901175263470212
Validation loss: 2.421224770801167

Epoch: 5| Step: 8
Training loss: 0.44196004645336046
Validation loss: 2.416650020625487

Epoch: 5| Step: 9
Training loss: 0.24374789120911228
Validation loss: 2.425795414663495

Epoch: 5| Step: 10
Training loss: 0.1815614527772258
Validation loss: 2.417858026020848

Epoch: 458| Step: 0
Training loss: 0.16784932637295394
Validation loss: 2.4069317513919635

Epoch: 5| Step: 1
Training loss: 0.23549211824038524
Validation loss: 2.3843468153389593

Epoch: 5| Step: 2
Training loss: 0.2229805809416197
Validation loss: 2.384170516964263

Epoch: 5| Step: 3
Training loss: 0.1545478855432083
Validation loss: 2.3419794949501327

Epoch: 5| Step: 4
Training loss: 0.31606415516240977
Validation loss: 2.328885132933017

Epoch: 5| Step: 5
Training loss: 0.2966711197520661
Validation loss: 2.3246456800269324

Epoch: 5| Step: 6
Training loss: 0.1505525695503742
Validation loss: 2.34743000072098

Epoch: 5| Step: 7
Training loss: 0.32432811684904106
Validation loss: 2.364524697108045

Epoch: 5| Step: 8
Training loss: 0.185918215545
Validation loss: 2.364091565532322

Epoch: 5| Step: 9
Training loss: 0.1532067893026276
Validation loss: 2.364901357339819

Epoch: 5| Step: 10
Training loss: 0.24917065625733806
Validation loss: 2.380344437510142

Epoch: 459| Step: 0
Training loss: 0.15022812771317792
Validation loss: 2.379332669032347

Epoch: 5| Step: 1
Training loss: 0.13623790652299048
Validation loss: 2.416549680492861

Epoch: 5| Step: 2
Training loss: 0.2732168124497916
Validation loss: 2.374956142450205

Epoch: 5| Step: 3
Training loss: 0.17317594919813306
Validation loss: 2.360836785305122

Epoch: 5| Step: 4
Training loss: 0.33192124507926707
Validation loss: 2.3727673343185933

Epoch: 5| Step: 5
Training loss: 0.21348992259667204
Validation loss: 2.358026750729101

Epoch: 5| Step: 6
Training loss: 0.3559915449994875
Validation loss: 2.3784528501918483

Epoch: 5| Step: 7
Training loss: 0.1396646156810072
Validation loss: 2.363532894753873

Epoch: 5| Step: 8
Training loss: 0.18482243509327867
Validation loss: 2.370901123716405

Epoch: 5| Step: 9
Training loss: 0.3007933750433458
Validation loss: 2.3637119769536805

Epoch: 5| Step: 10
Training loss: 0.13070126133722754
Validation loss: 2.379317277437298

Epoch: 460| Step: 0
Training loss: 0.26571922874833753
Validation loss: 2.3734088629210306

Epoch: 5| Step: 1
Training loss: 0.10314879106863917
Validation loss: 2.3637946315405536

Epoch: 5| Step: 2
Training loss: 0.3167707086709423
Validation loss: 2.400146466617531

Epoch: 5| Step: 3
Training loss: 0.08157802445004178
Validation loss: 2.401021169376967

Epoch: 5| Step: 4
Training loss: 0.28985861100094146
Validation loss: 2.397316320598976

Epoch: 5| Step: 5
Training loss: 0.20306818424263567
Validation loss: 2.383307251922703

Epoch: 5| Step: 6
Training loss: 0.21757313364765424
Validation loss: 2.3759452536854666

Epoch: 5| Step: 7
Training loss: 0.13552232816865245
Validation loss: 2.3720575875880763

Epoch: 5| Step: 8
Training loss: 0.19381631939017643
Validation loss: 2.3970756960241517

Epoch: 5| Step: 9
Training loss: 0.27427118457598326
Validation loss: 2.392192675356242

Epoch: 5| Step: 10
Training loss: 0.26806651742512494
Validation loss: 2.3647302890257644

Epoch: 461| Step: 0
Training loss: 0.2443537659090654
Validation loss: 2.386792198793635

Epoch: 5| Step: 1
Training loss: 0.23408000182862324
Validation loss: 2.396104521381657

Epoch: 5| Step: 2
Training loss: 0.10089127482304965
Validation loss: 2.4154031775941003

Epoch: 5| Step: 3
Training loss: 0.145901914348309
Validation loss: 2.4000745480591563

Epoch: 5| Step: 4
Training loss: 0.18037542018854658
Validation loss: 2.3755730572853286

Epoch: 5| Step: 5
Training loss: 0.41133842853853214
Validation loss: 2.4038965515331188

Epoch: 5| Step: 6
Training loss: 0.2131051898374455
Validation loss: 2.391608723012887

Epoch: 5| Step: 7
Training loss: 0.1452789490944861
Validation loss: 2.403217096699047

Epoch: 5| Step: 8
Training loss: 0.3098628830689265
Validation loss: 2.419514407839916

Epoch: 5| Step: 9
Training loss: 0.13155641947216185
Validation loss: 2.413072793563503

Epoch: 5| Step: 10
Training loss: 0.15610176445793436
Validation loss: 2.425168990211676

Epoch: 462| Step: 0
Training loss: 0.27021746425647025
Validation loss: 2.426955536114002

Epoch: 5| Step: 1
Training loss: 0.21424681357959832
Validation loss: 2.437750004983

Epoch: 5| Step: 2
Training loss: 0.11001146283895578
Validation loss: 2.425739840897371

Epoch: 5| Step: 3
Training loss: 0.23472528507763038
Validation loss: 2.3832919580660348

Epoch: 5| Step: 4
Training loss: 0.29026028195322195
Validation loss: 2.398095790694741

Epoch: 5| Step: 5
Training loss: 0.3309041021170883
Validation loss: 2.369394064598333

Epoch: 5| Step: 6
Training loss: 0.12607002487712426
Validation loss: 2.3623250294801217

Epoch: 5| Step: 7
Training loss: 0.2517968661704492
Validation loss: 2.3491115954353154

Epoch: 5| Step: 8
Training loss: 0.21199866333294934
Validation loss: 2.391379057101301

Epoch: 5| Step: 9
Training loss: 0.2441571191938009
Validation loss: 2.3578203807533757

Epoch: 5| Step: 10
Training loss: 0.11741002333925721
Validation loss: 2.424527475903133

Epoch: 463| Step: 0
Training loss: 0.22334642688304734
Validation loss: 2.3976471332762754

Epoch: 5| Step: 1
Training loss: 0.33497636275738446
Validation loss: 2.400895566425626

Epoch: 5| Step: 2
Training loss: 0.14780370398796633
Validation loss: 2.429339372295071

Epoch: 5| Step: 3
Training loss: 0.2825932743735436
Validation loss: 2.4377424941432557

Epoch: 5| Step: 4
Training loss: 0.25154108169550415
Validation loss: 2.4485477120237724

Epoch: 5| Step: 5
Training loss: 0.14462107367366409
Validation loss: 2.442697226720396

Epoch: 5| Step: 6
Training loss: 0.11298588360325414
Validation loss: 2.4302976725977397

Epoch: 5| Step: 7
Training loss: 0.1670824498514313
Validation loss: 2.42788448435114

Epoch: 5| Step: 8
Training loss: 0.2857362257673846
Validation loss: 2.401382565874994

Epoch: 5| Step: 9
Training loss: 0.18396719024162875
Validation loss: 2.3936546361949946

Epoch: 5| Step: 10
Training loss: 0.15006833407442227
Validation loss: 2.401827841619691

Epoch: 464| Step: 0
Training loss: 0.181245384075318
Validation loss: 2.3728226091554308

Epoch: 5| Step: 1
Training loss: 0.195307331016806
Validation loss: 2.3466242251177607

Epoch: 5| Step: 2
Training loss: 0.2598516135479639
Validation loss: 2.3564105850681907

Epoch: 5| Step: 3
Training loss: 0.30938691202986096
Validation loss: 2.391944123999875

Epoch: 5| Step: 4
Training loss: 0.16679400680541662
Validation loss: 2.356897290882916

Epoch: 5| Step: 5
Training loss: 0.30778023168213536
Validation loss: 2.416084943720939

Epoch: 5| Step: 6
Training loss: 0.201254355549327
Validation loss: 2.4066993838175286

Epoch: 5| Step: 7
Training loss: 0.16802936391781106
Validation loss: 2.3898708959195596

Epoch: 5| Step: 8
Training loss: 0.26085711742976847
Validation loss: 2.43199026591623

Epoch: 5| Step: 9
Training loss: 0.16689671469789696
Validation loss: 2.433485498389135

Epoch: 5| Step: 10
Training loss: 0.1779053253680494
Validation loss: 2.416694428436854

Epoch: 465| Step: 0
Training loss: 0.14338795067898666
Validation loss: 2.4300948459250096

Epoch: 5| Step: 1
Training loss: 0.11989750971838771
Validation loss: 2.3867775942845437

Epoch: 5| Step: 2
Training loss: 0.21550337360423225
Validation loss: 2.391927182295163

Epoch: 5| Step: 3
Training loss: 0.13416016060394179
Validation loss: 2.359371961931091

Epoch: 5| Step: 4
Training loss: 0.12710405328040367
Validation loss: 2.3844206030308337

Epoch: 5| Step: 5
Training loss: 0.2932839795789886
Validation loss: 2.332503949174432

Epoch: 5| Step: 6
Training loss: 0.29445892275646035
Validation loss: 2.355798837395176

Epoch: 5| Step: 7
Training loss: 0.1811802989026116
Validation loss: 2.3487741590811004

Epoch: 5| Step: 8
Training loss: 0.3324428363471437
Validation loss: 2.3875556086746417

Epoch: 5| Step: 9
Training loss: 0.19260501132248284
Validation loss: 2.364212378548516

Epoch: 5| Step: 10
Training loss: 0.20576951782045766
Validation loss: 2.3835369459274016

Epoch: 466| Step: 0
Training loss: 0.25493498520336744
Validation loss: 2.40212726206169

Epoch: 5| Step: 1
Training loss: 0.11643320753951289
Validation loss: 2.3984553972512916

Epoch: 5| Step: 2
Training loss: 0.2078686996704892
Validation loss: 2.412513588309123

Epoch: 5| Step: 3
Training loss: 0.2278273152346865
Validation loss: 2.4026130392614733

Epoch: 5| Step: 4
Training loss: 0.27564025278770704
Validation loss: 2.354962966657721

Epoch: 5| Step: 5
Training loss: 0.1567571099876558
Validation loss: 2.316335924975594

Epoch: 5| Step: 6
Training loss: 0.21733814407786775
Validation loss: 2.307484698810529

Epoch: 5| Step: 7
Training loss: 0.21868847935564395
Validation loss: 2.334443381681905

Epoch: 5| Step: 8
Training loss: 0.1664575417141319
Validation loss: 2.3382235326928655

Epoch: 5| Step: 9
Training loss: 0.3398423797755187
Validation loss: 2.39010831581862

Epoch: 5| Step: 10
Training loss: 0.1656447137940261
Validation loss: 2.4249560988266325

Epoch: 467| Step: 0
Training loss: 0.29246621582762644
Validation loss: 2.4570498942564423

Epoch: 5| Step: 1
Training loss: 0.1393687508554885
Validation loss: 2.450471628026427

Epoch: 5| Step: 2
Training loss: 0.24746252298788068
Validation loss: 2.4690258395913145

Epoch: 5| Step: 3
Training loss: 0.13242939080934302
Validation loss: 2.435134724011441

Epoch: 5| Step: 4
Training loss: 0.13639182785758872
Validation loss: 2.3964026842414117

Epoch: 5| Step: 5
Training loss: 0.27822956144923044
Validation loss: 2.365435078029588

Epoch: 5| Step: 6
Training loss: 0.23326626630520275
Validation loss: 2.378316950721741

Epoch: 5| Step: 7
Training loss: 0.26317630396781094
Validation loss: 2.341019056223049

Epoch: 5| Step: 8
Training loss: 0.1882372408990934
Validation loss: 2.311782909759528

Epoch: 5| Step: 9
Training loss: 0.12502570930976556
Validation loss: 2.2875342450962295

Epoch: 5| Step: 10
Training loss: 0.3149625076203713
Validation loss: 2.3373571769333017

Epoch: 468| Step: 0
Training loss: 0.2208286704764731
Validation loss: 2.3491565913626826

Epoch: 5| Step: 1
Training loss: 0.2625688723631034
Validation loss: 2.36803886303361

Epoch: 5| Step: 2
Training loss: 0.18504138151861374
Validation loss: 2.4173268992319814

Epoch: 5| Step: 3
Training loss: 0.22907868325545513
Validation loss: 2.4471112893763927

Epoch: 5| Step: 4
Training loss: 0.22212877871101253
Validation loss: 2.501580702547056

Epoch: 5| Step: 5
Training loss: 0.28499185709446717
Validation loss: 2.4738656123887437

Epoch: 5| Step: 6
Training loss: 0.25028177117979206
Validation loss: 2.390810769530936

Epoch: 5| Step: 7
Training loss: 0.19276535419186283
Validation loss: 2.31331745317513

Epoch: 5| Step: 8
Training loss: 0.2527952831285859
Validation loss: 2.206402364128858

Epoch: 5| Step: 9
Training loss: 0.38096355089418865
Validation loss: 2.201705269204009

Epoch: 5| Step: 10
Training loss: 0.2978719985705047
Validation loss: 2.2161641978653037

Epoch: 469| Step: 0
Training loss: 0.2207882640990619
Validation loss: 2.2559637258560032

Epoch: 5| Step: 1
Training loss: 0.3985501111530651
Validation loss: 2.260920601166141

Epoch: 5| Step: 2
Training loss: 0.3032087731369776
Validation loss: 2.368954604091776

Epoch: 5| Step: 3
Training loss: 0.2349481409509144
Validation loss: 2.3934092791935346

Epoch: 5| Step: 4
Training loss: 0.29656061039233184
Validation loss: 2.4768362745707715

Epoch: 5| Step: 5
Training loss: 0.25749901294519073
Validation loss: 2.476228679522068

Epoch: 5| Step: 6
Training loss: 0.27590982719588525
Validation loss: 2.452114290214226

Epoch: 5| Step: 7
Training loss: 0.14735136950907834
Validation loss: 2.431850745333791

Epoch: 5| Step: 8
Training loss: 0.17777884629130458
Validation loss: 2.440992461678777

Epoch: 5| Step: 9
Training loss: 0.2232282385552415
Validation loss: 2.4162572058394787

Epoch: 5| Step: 10
Training loss: 0.17375923248845546
Validation loss: 2.4135019488054934

Epoch: 470| Step: 0
Training loss: 0.19621543072600953
Validation loss: 2.373236379176341

Epoch: 5| Step: 1
Training loss: 0.336906632051215
Validation loss: 2.3980520353589183

Epoch: 5| Step: 2
Training loss: 0.29791161604025757
Validation loss: 2.38281050960539

Epoch: 5| Step: 3
Training loss: 0.18159808409295677
Validation loss: 2.406498433118424

Epoch: 5| Step: 4
Training loss: 0.3747007248670654
Validation loss: 2.3736083087965283

Epoch: 5| Step: 5
Training loss: 0.22941086322431456
Validation loss: 2.3840712626495044

Epoch: 5| Step: 6
Training loss: 0.2894606554542163
Validation loss: 2.41318992845875

Epoch: 5| Step: 7
Training loss: 0.1482524848145965
Validation loss: 2.462001025772191

Epoch: 5| Step: 8
Training loss: 0.26594144540318787
Validation loss: 2.4770911406154035

Epoch: 5| Step: 9
Training loss: 0.16282721801650168
Validation loss: 2.4871252017812346

Epoch: 5| Step: 10
Training loss: 0.19643708716084243
Validation loss: 2.506128954818838

Epoch: 471| Step: 0
Training loss: 0.2700791663871729
Validation loss: 2.485862735872807

Epoch: 5| Step: 1
Training loss: 0.1464274931776159
Validation loss: 2.4638547847725136

Epoch: 5| Step: 2
Training loss: 0.2335184339480082
Validation loss: 2.4416927534764454

Epoch: 5| Step: 3
Training loss: 0.19477562549315833
Validation loss: 2.41145870683858

Epoch: 5| Step: 4
Training loss: 0.3440804843550592
Validation loss: 2.3905737014361472

Epoch: 5| Step: 5
Training loss: 0.2512827241520123
Validation loss: 2.3792851772639634

Epoch: 5| Step: 6
Training loss: 0.22407636009028253
Validation loss: 2.3604675232171557

Epoch: 5| Step: 7
Training loss: 0.2467092053896694
Validation loss: 2.349680937561348

Epoch: 5| Step: 8
Training loss: 0.314971330980516
Validation loss: 2.351634492604415

Epoch: 5| Step: 9
Training loss: 0.09690817891581194
Validation loss: 2.3521284673918146

Epoch: 5| Step: 10
Training loss: 0.17933719115254265
Validation loss: 2.3899749487601767

Epoch: 472| Step: 0
Training loss: 0.3061901111822376
Validation loss: 2.335442125900801

Epoch: 5| Step: 1
Training loss: 0.14881277956409622
Validation loss: 2.370241971095209

Epoch: 5| Step: 2
Training loss: 0.29623743662370516
Validation loss: 2.3734322578024316

Epoch: 5| Step: 3
Training loss: 0.2595282882989951
Validation loss: 2.352014079294624

Epoch: 5| Step: 4
Training loss: 0.18509087998063278
Validation loss: 2.35718141300606

Epoch: 5| Step: 5
Training loss: 0.1823835765653494
Validation loss: 2.3922410854060905

Epoch: 5| Step: 6
Training loss: 0.1547676040372681
Validation loss: 2.4176714346244506

Epoch: 5| Step: 7
Training loss: 0.14653169503432184
Validation loss: 2.4381769795205064

Epoch: 5| Step: 8
Training loss: 0.20149027062525177
Validation loss: 2.442519061322273

Epoch: 5| Step: 9
Training loss: 0.2693443894529735
Validation loss: 2.4399325840514603

Epoch: 5| Step: 10
Training loss: 0.2617904507933966
Validation loss: 2.475329575275342

Epoch: 473| Step: 0
Training loss: 0.14673286342685163
Validation loss: 2.4696874036929044

Epoch: 5| Step: 1
Training loss: 0.2781091792718201
Validation loss: 2.4731207050792663

Epoch: 5| Step: 2
Training loss: 0.3020045435307887
Validation loss: 2.480383965959573

Epoch: 5| Step: 3
Training loss: 0.2812723839647412
Validation loss: 2.4696152649096486

Epoch: 5| Step: 4
Training loss: 0.1578264697661925
Validation loss: 2.4863356303295796

Epoch: 5| Step: 5
Training loss: 0.16491881622954713
Validation loss: 2.4894704904278835

Epoch: 5| Step: 6
Training loss: 0.10007000983314031
Validation loss: 2.4423015411524682

Epoch: 5| Step: 7
Training loss: 0.1773978390321747
Validation loss: 2.457203824738174

Epoch: 5| Step: 8
Training loss: 0.14524141670093516
Validation loss: 2.45671686601756

Epoch: 5| Step: 9
Training loss: 0.2870461919900074
Validation loss: 2.422287514784749

Epoch: 5| Step: 10
Training loss: 0.1987110287767534
Validation loss: 2.422489753262168

Epoch: 474| Step: 0
Training loss: 0.1466532623727206
Validation loss: 2.3968399765117554

Epoch: 5| Step: 1
Training loss: 0.22217660405071546
Validation loss: 2.3711308220992957

Epoch: 5| Step: 2
Training loss: 0.15687838202132667
Validation loss: 2.346099292459185

Epoch: 5| Step: 3
Training loss: 0.1554955207836575
Validation loss: 2.393590277487477

Epoch: 5| Step: 4
Training loss: 0.3038080311705317
Validation loss: 2.3574322440645954

Epoch: 5| Step: 5
Training loss: 0.16386062258822642
Validation loss: 2.3544738602499247

Epoch: 5| Step: 6
Training loss: 0.13341080313655762
Validation loss: 2.372913239382318

Epoch: 5| Step: 7
Training loss: 0.2887506865208379
Validation loss: 2.406719781440442

Epoch: 5| Step: 8
Training loss: 0.20854245458816725
Validation loss: 2.3779566225415305

Epoch: 5| Step: 9
Training loss: 0.1723210712652575
Validation loss: 2.389348740812699

Epoch: 5| Step: 10
Training loss: 0.34803720026237955
Validation loss: 2.39978362500114

Epoch: 475| Step: 0
Training loss: 0.2042477371756996
Validation loss: 2.402616724218643

Epoch: 5| Step: 1
Training loss: 0.1539647051858865
Validation loss: 2.4051510837591397

Epoch: 5| Step: 2
Training loss: 0.3092236427972496
Validation loss: 2.3866607528462476

Epoch: 5| Step: 3
Training loss: 0.18870489096188325
Validation loss: 2.3908079992701095

Epoch: 5| Step: 4
Training loss: 0.22896712278191633
Validation loss: 2.3240693157796852

Epoch: 5| Step: 5
Training loss: 0.1764612502559208
Validation loss: 2.3397335440348717

Epoch: 5| Step: 6
Training loss: 0.24632617026538584
Validation loss: 2.368882858650567

Epoch: 5| Step: 7
Training loss: 0.11681827154617208
Validation loss: 2.3346507078908254

Epoch: 5| Step: 8
Training loss: 0.26761599084834087
Validation loss: 2.3658933965427056

Epoch: 5| Step: 9
Training loss: 0.15754313614296234
Validation loss: 2.3873783665796644

Epoch: 5| Step: 10
Training loss: 0.22015055967873193
Validation loss: 2.4160302267897458

Epoch: 476| Step: 0
Training loss: 0.2741574754208187
Validation loss: 2.4278615867175457

Epoch: 5| Step: 1
Training loss: 0.19644081360889265
Validation loss: 2.408628066653406

Epoch: 5| Step: 2
Training loss: 0.11465683570009375
Validation loss: 2.428398167700599

Epoch: 5| Step: 3
Training loss: 0.13369189165471682
Validation loss: 2.430115390031257

Epoch: 5| Step: 4
Training loss: 0.1803213115866261
Validation loss: 2.4135621391230884

Epoch: 5| Step: 5
Training loss: 0.23093640031668894
Validation loss: 2.3956065180678743

Epoch: 5| Step: 6
Training loss: 0.14134705790474378
Validation loss: 2.3822088672909683

Epoch: 5| Step: 7
Training loss: 0.32878497146213115
Validation loss: 2.410893532883736

Epoch: 5| Step: 8
Training loss: 0.2610351402662324
Validation loss: 2.399357430002097

Epoch: 5| Step: 9
Training loss: 0.18120584443342705
Validation loss: 2.444926741810866

Epoch: 5| Step: 10
Training loss: 0.20302452757012057
Validation loss: 2.48006474508334

Epoch: 477| Step: 0
Training loss: 0.2723977347186645
Validation loss: 2.4551731220821122

Epoch: 5| Step: 1
Training loss: 0.25555637851584884
Validation loss: 2.446520181644012

Epoch: 5| Step: 2
Training loss: 0.1699197155168488
Validation loss: 2.440109128075071

Epoch: 5| Step: 3
Training loss: 0.1717366290135006
Validation loss: 2.4382344652048267

Epoch: 5| Step: 4
Training loss: 0.1702319090140705
Validation loss: 2.4172487954534807

Epoch: 5| Step: 5
Training loss: 0.14812779743836543
Validation loss: 2.4724067531399077

Epoch: 5| Step: 6
Training loss: 0.2142381977293624
Validation loss: 2.426483742160227

Epoch: 5| Step: 7
Training loss: 0.2937383334907061
Validation loss: 2.3952566008216074

Epoch: 5| Step: 8
Training loss: 0.20043006717019188
Validation loss: 2.343852140327117

Epoch: 5| Step: 9
Training loss: 0.19276041645880465
Validation loss: 2.3587838241569425

Epoch: 5| Step: 10
Training loss: 0.2321635341212736
Validation loss: 2.3175616555409033

Epoch: 478| Step: 0
Training loss: 0.20679626084291625
Validation loss: 2.323568746925769

Epoch: 5| Step: 1
Training loss: 0.30642926166188655
Validation loss: 2.294425306494712

Epoch: 5| Step: 2
Training loss: 0.19922175124656522
Validation loss: 2.298571739739029

Epoch: 5| Step: 3
Training loss: 0.2287220959502694
Validation loss: 2.313686876104546

Epoch: 5| Step: 4
Training loss: 0.07913205948199362
Validation loss: 2.351895430153991

Epoch: 5| Step: 5
Training loss: 0.16272689792086234
Validation loss: 2.4211633394168977

Epoch: 5| Step: 6
Training loss: 0.18981885511331284
Validation loss: 2.4601587519530734

Epoch: 5| Step: 7
Training loss: 0.19428428845348197
Validation loss: 2.4869378274863068

Epoch: 5| Step: 8
Training loss: 0.2774938392170073
Validation loss: 2.4920003160224877

Epoch: 5| Step: 9
Training loss: 0.23665733107155318
Validation loss: 2.4678123607367777

Epoch: 5| Step: 10
Training loss: 0.246982242131214
Validation loss: 2.450960179003683

Epoch: 479| Step: 0
Training loss: 0.2798926794278805
Validation loss: 2.407408905195358

Epoch: 5| Step: 1
Training loss: 0.1731136942177515
Validation loss: 2.3325668937019857

Epoch: 5| Step: 2
Training loss: 0.32681975293496285
Validation loss: 2.337587217474266

Epoch: 5| Step: 3
Training loss: 0.2120332602403513
Validation loss: 2.334743380976282

Epoch: 5| Step: 4
Training loss: 0.25502502741664396
Validation loss: 2.3334474103555856

Epoch: 5| Step: 5
Training loss: 0.1078779077458489
Validation loss: 2.3530754834131353

Epoch: 5| Step: 6
Training loss: 0.16868979364604642
Validation loss: 2.420183484594579

Epoch: 5| Step: 7
Training loss: 0.27575645767598006
Validation loss: 2.444654095966902

Epoch: 5| Step: 8
Training loss: 0.1520057498838803
Validation loss: 2.471018065944401

Epoch: 5| Step: 9
Training loss: 0.16685191057249896
Validation loss: 2.475414863835966

Epoch: 5| Step: 10
Training loss: 0.19090928548203293
Validation loss: 2.4743573398204015

Epoch: 480| Step: 0
Training loss: 0.13551219831919917
Validation loss: 2.4639766617533883

Epoch: 5| Step: 1
Training loss: 0.24123248108321071
Validation loss: 2.375793998950505

Epoch: 5| Step: 2
Training loss: 0.27470946787198675
Validation loss: 2.3405206671365564

Epoch: 5| Step: 3
Training loss: 0.314468158338874
Validation loss: 2.3136146362331624

Epoch: 5| Step: 4
Training loss: 0.26669404937304664
Validation loss: 2.3229111875048862

Epoch: 5| Step: 5
Training loss: 0.21977807182976686
Validation loss: 2.294999827760876

Epoch: 5| Step: 6
Training loss: 0.2070176282036161
Validation loss: 2.3177739588392394

Epoch: 5| Step: 7
Training loss: 0.09739313920862644
Validation loss: 2.355048678858454

Epoch: 5| Step: 8
Training loss: 0.2136963375252314
Validation loss: 2.416969248195762

Epoch: 5| Step: 9
Training loss: 0.11727881847222205
Validation loss: 2.4425677806490187

Epoch: 5| Step: 10
Training loss: 0.20947224721446261
Validation loss: 2.469412327856207

Epoch: 481| Step: 0
Training loss: 0.4083119297581242
Validation loss: 2.4443208576829454

Epoch: 5| Step: 1
Training loss: 0.13678152822858836
Validation loss: 2.4197035937707008

Epoch: 5| Step: 2
Training loss: 0.09119568437879391
Validation loss: 2.4014902768613258

Epoch: 5| Step: 3
Training loss: 0.3210473586305457
Validation loss: 2.3406542650077777

Epoch: 5| Step: 4
Training loss: 0.24269993468039316
Validation loss: 2.3624292239675353

Epoch: 5| Step: 5
Training loss: 0.1738152499199136
Validation loss: 2.363680412138546

Epoch: 5| Step: 6
Training loss: 0.20972595372487338
Validation loss: 2.3668268638992243

Epoch: 5| Step: 7
Training loss: 0.19703670476007482
Validation loss: 2.3957782687314784

Epoch: 5| Step: 8
Training loss: 0.132236874176897
Validation loss: 2.4378146296392766

Epoch: 5| Step: 9
Training loss: 0.23240432352424512
Validation loss: 2.4505313073058734

Epoch: 5| Step: 10
Training loss: 0.28172751791242934
Validation loss: 2.446768543056182

Epoch: 482| Step: 0
Training loss: 0.20237534913285637
Validation loss: 2.415131331199924

Epoch: 5| Step: 1
Training loss: 0.2616462322373509
Validation loss: 2.429220400993216

Epoch: 5| Step: 2
Training loss: 0.12153847615139247
Validation loss: 2.363976271136099

Epoch: 5| Step: 3
Training loss: 0.2777068890412175
Validation loss: 2.3661683493725523

Epoch: 5| Step: 4
Training loss: 0.1287913605193123
Validation loss: 2.3645770616887747

Epoch: 5| Step: 5
Training loss: 0.2650168694219031
Validation loss: 2.292860841092545

Epoch: 5| Step: 6
Training loss: 0.200192056024629
Validation loss: 2.364257814939747

Epoch: 5| Step: 7
Training loss: 0.26381762679395643
Validation loss: 2.354486496181138

Epoch: 5| Step: 8
Training loss: 0.18017348621426404
Validation loss: 2.3854892639241414

Epoch: 5| Step: 9
Training loss: 0.1166585747716835
Validation loss: 2.434989191362192

Epoch: 5| Step: 10
Training loss: 0.18435534315875876
Validation loss: 2.4464255433260216

Epoch: 483| Step: 0
Training loss: 0.130845403637127
Validation loss: 2.4417605285203527

Epoch: 5| Step: 1
Training loss: 0.1852494013534685
Validation loss: 2.45771934415609

Epoch: 5| Step: 2
Training loss: 0.1413561437150426
Validation loss: 2.4265399496935545

Epoch: 5| Step: 3
Training loss: 0.09122862348280837
Validation loss: 2.4274125013062884

Epoch: 5| Step: 4
Training loss: 0.2601513544257804
Validation loss: 2.4012742126900735

Epoch: 5| Step: 5
Training loss: 0.2000551710177688
Validation loss: 2.415824334570703

Epoch: 5| Step: 6
Training loss: 0.26343111419630794
Validation loss: 2.411770663095383

Epoch: 5| Step: 7
Training loss: 0.33532413777102804
Validation loss: 2.384830315916411

Epoch: 5| Step: 8
Training loss: 0.17905462808598452
Validation loss: 2.366661782052411

Epoch: 5| Step: 9
Training loss: 0.16278137962129632
Validation loss: 2.333894001566971

Epoch: 5| Step: 10
Training loss: 0.14207337143053725
Validation loss: 2.313722697969284

Epoch: 484| Step: 0
Training loss: 0.25811993446182707
Validation loss: 2.3559424646509473

Epoch: 5| Step: 1
Training loss: 0.12031253963321181
Validation loss: 2.3553636092392405

Epoch: 5| Step: 2
Training loss: 0.23945169183946277
Validation loss: 2.3823011527790507

Epoch: 5| Step: 3
Training loss: 0.25145805868235466
Validation loss: 2.376326209583713

Epoch: 5| Step: 4
Training loss: 0.13801726450594654
Validation loss: 2.3809719046145297

Epoch: 5| Step: 5
Training loss: 0.13504113493397535
Validation loss: 2.4085215647169425

Epoch: 5| Step: 6
Training loss: 0.17674297460166535
Validation loss: 2.3899471462143147

Epoch: 5| Step: 7
Training loss: 0.24837440733222152
Validation loss: 2.3366576058247177

Epoch: 5| Step: 8
Training loss: 0.1179867628063289
Validation loss: 2.371729620337684

Epoch: 5| Step: 9
Training loss: 0.26281702845115884
Validation loss: 2.3786305800710443

Epoch: 5| Step: 10
Training loss: 0.08735640613257839
Validation loss: 2.393054991214516

Epoch: 485| Step: 0
Training loss: 0.16542959562296833
Validation loss: 2.3814731544906693

Epoch: 5| Step: 1
Training loss: 0.13770208950815593
Validation loss: 2.4136344035478303

Epoch: 5| Step: 2
Training loss: 0.17557493393888757
Validation loss: 2.434183212127261

Epoch: 5| Step: 3
Training loss: 0.3108809731250523
Validation loss: 2.452602500912261

Epoch: 5| Step: 4
Training loss: 0.11519485539513488
Validation loss: 2.4701673046081547

Epoch: 5| Step: 5
Training loss: 0.11936672050913526
Validation loss: 2.4671607166153997

Epoch: 5| Step: 6
Training loss: 0.11437188266065272
Validation loss: 2.4593014858995144

Epoch: 5| Step: 7
Training loss: 0.10408894550094673
Validation loss: 2.458943291507223

Epoch: 5| Step: 8
Training loss: 0.30176830582135783
Validation loss: 2.4654352279854175

Epoch: 5| Step: 9
Training loss: 0.2554234146582346
Validation loss: 2.4498995494361546

Epoch: 5| Step: 10
Training loss: 0.17033804977451722
Validation loss: 2.4206196961719795

Epoch: 486| Step: 0
Training loss: 0.17000836330766522
Validation loss: 2.398514873868865

Epoch: 5| Step: 1
Training loss: 0.27318007749668805
Validation loss: 2.352870434203766

Epoch: 5| Step: 2
Training loss: 0.18318520399338253
Validation loss: 2.3772776443654955

Epoch: 5| Step: 3
Training loss: 0.24982692270587875
Validation loss: 2.3841557141353045

Epoch: 5| Step: 4
Training loss: 0.16578020345373712
Validation loss: 2.3776887031933507

Epoch: 5| Step: 5
Training loss: 0.12382159366290249
Validation loss: 2.3547340879533474

Epoch: 5| Step: 6
Training loss: 0.21178181648544508
Validation loss: 2.3917916668462116

Epoch: 5| Step: 7
Training loss: 0.2958392974874664
Validation loss: 2.3764511385750824

Epoch: 5| Step: 8
Training loss: 0.12120019556552426
Validation loss: 2.3682177322339597

Epoch: 5| Step: 9
Training loss: 0.09188199662147242
Validation loss: 2.3940517764053824

Epoch: 5| Step: 10
Training loss: 0.11884446543388674
Validation loss: 2.3836956752389225

Epoch: 487| Step: 0
Training loss: 0.16476875379982217
Validation loss: 2.4222705297114517

Epoch: 5| Step: 1
Training loss: 0.11683960375426879
Validation loss: 2.3944378662850165

Epoch: 5| Step: 2
Training loss: 0.139872324810576
Validation loss: 2.416286890749988

Epoch: 5| Step: 3
Training loss: 0.1306022138433866
Validation loss: 2.3946719177229605

Epoch: 5| Step: 4
Training loss: 0.2456555324971487
Validation loss: 2.4105315533247578

Epoch: 5| Step: 5
Training loss: 0.1971756002641191
Validation loss: 2.4252929692785217

Epoch: 5| Step: 6
Training loss: 0.2652174263034877
Validation loss: 2.3888792006129305

Epoch: 5| Step: 7
Training loss: 0.19207059630954296
Validation loss: 2.3896768314145724

Epoch: 5| Step: 8
Training loss: 0.2176506312042818
Validation loss: 2.37858237209662

Epoch: 5| Step: 9
Training loss: 0.2557532986030144
Validation loss: 2.4217279723675462

Epoch: 5| Step: 10
Training loss: 0.13631251472576258
Validation loss: 2.441868445832936

Epoch: 488| Step: 0
Training loss: 0.12767284031037243
Validation loss: 2.424313679563385

Epoch: 5| Step: 1
Training loss: 0.10781919520777489
Validation loss: 2.4147586383620245

Epoch: 5| Step: 2
Training loss: 0.2440547486904767
Validation loss: 2.37646042028115

Epoch: 5| Step: 3
Training loss: 0.15083391944782792
Validation loss: 2.3616542985972804

Epoch: 5| Step: 4
Training loss: 0.21682926314081968
Validation loss: 2.3626432675857774

Epoch: 5| Step: 5
Training loss: 0.15738246130886363
Validation loss: 2.359516994933052

Epoch: 5| Step: 6
Training loss: 0.09322888860003953
Validation loss: 2.354907835985852

Epoch: 5| Step: 7
Training loss: 0.24841463805517489
Validation loss: 2.3372664447170575

Epoch: 5| Step: 8
Training loss: 0.2516450847099086
Validation loss: 2.340703248107155

Epoch: 5| Step: 9
Training loss: 0.2584786911119104
Validation loss: 2.354428707882325

Epoch: 5| Step: 10
Training loss: 0.09910095179320384
Validation loss: 2.3833195779381815

Epoch: 489| Step: 0
Training loss: 0.14078734881096502
Validation loss: 2.368860140683709

Epoch: 5| Step: 1
Training loss: 0.22476335306249162
Validation loss: 2.4021079236377703

Epoch: 5| Step: 2
Training loss: 0.241974952705947
Validation loss: 2.429236574999315

Epoch: 5| Step: 3
Training loss: 0.17702967985623524
Validation loss: 2.4490360092987267

Epoch: 5| Step: 4
Training loss: 0.2028631944000791
Validation loss: 2.4430450606876297

Epoch: 5| Step: 5
Training loss: 0.11227474228053858
Validation loss: 2.3929358154422524

Epoch: 5| Step: 6
Training loss: 0.13315968854036972
Validation loss: 2.403994442381789

Epoch: 5| Step: 7
Training loss: 0.2705238144751563
Validation loss: 2.3985338906837548

Epoch: 5| Step: 8
Training loss: 0.12261104601171882
Validation loss: 2.3968295870082725

Epoch: 5| Step: 9
Training loss: 0.11256992283073998
Validation loss: 2.3686042606392195

Epoch: 5| Step: 10
Training loss: 0.24775969784605428
Validation loss: 2.3952715057584726

Epoch: 490| Step: 0
Training loss: 0.20598385935923355
Validation loss: 2.365066082953485

Epoch: 5| Step: 1
Training loss: 0.1337287585936227
Validation loss: 2.382151337173508

Epoch: 5| Step: 2
Training loss: 0.1451476266699619
Validation loss: 2.4033355621069954

Epoch: 5| Step: 3
Training loss: 0.25718059549067374
Validation loss: 2.4414902749317613

Epoch: 5| Step: 4
Training loss: 0.15974045487588895
Validation loss: 2.416894888860036

Epoch: 5| Step: 5
Training loss: 0.07805023788485238
Validation loss: 2.401700371762231

Epoch: 5| Step: 6
Training loss: 0.10763835767987476
Validation loss: 2.373693780547419

Epoch: 5| Step: 7
Training loss: 0.24347379789675516
Validation loss: 2.3919611963409637

Epoch: 5| Step: 8
Training loss: 0.24502776137054033
Validation loss: 2.4013508257830427

Epoch: 5| Step: 9
Training loss: 0.12290590400438567
Validation loss: 2.4046460316467515

Epoch: 5| Step: 10
Training loss: 0.2907839115027169
Validation loss: 2.424921655314388

Epoch: 491| Step: 0
Training loss: 0.14704806905579246
Validation loss: 2.384415047926308

Epoch: 5| Step: 1
Training loss: 0.17717262195510777
Validation loss: 2.4257975800964435

Epoch: 5| Step: 2
Training loss: 0.18781406206760354
Validation loss: 2.416024385447778

Epoch: 5| Step: 3
Training loss: 0.16724035439204127
Validation loss: 2.402659332092429

Epoch: 5| Step: 4
Training loss: 0.14357178125659262
Validation loss: 2.3696820381244637

Epoch: 5| Step: 5
Training loss: 0.14966577009826001
Validation loss: 2.3794583764403874

Epoch: 5| Step: 6
Training loss: 0.1930017921791968
Validation loss: 2.374872732071794

Epoch: 5| Step: 7
Training loss: 0.27636213264290804
Validation loss: 2.326965348238435

Epoch: 5| Step: 8
Training loss: 0.12208106565796965
Validation loss: 2.345712749139084

Epoch: 5| Step: 9
Training loss: 0.19356637528715456
Validation loss: 2.338033693375577

Epoch: 5| Step: 10
Training loss: 0.3336092308794162
Validation loss: 2.3261583600844524

Epoch: 492| Step: 0
Training loss: 0.20457196214413947
Validation loss: 2.3392948348570193

Epoch: 5| Step: 1
Training loss: 0.15870640023628166
Validation loss: 2.343148786760134

Epoch: 5| Step: 2
Training loss: 0.2725803154736817
Validation loss: 2.4030297061120023

Epoch: 5| Step: 3
Training loss: 0.17785891686308208
Validation loss: 2.421480257941994

Epoch: 5| Step: 4
Training loss: 0.15531902723585048
Validation loss: 2.4523094299741826

Epoch: 5| Step: 5
Training loss: 0.2408150114665585
Validation loss: 2.4281961557918383

Epoch: 5| Step: 6
Training loss: 0.09664607186105387
Validation loss: 2.4425513548567985

Epoch: 5| Step: 7
Training loss: 0.13904584908184636
Validation loss: 2.4101315766981894

Epoch: 5| Step: 8
Training loss: 0.15866907402770622
Validation loss: 2.3650373664704563

Epoch: 5| Step: 9
Training loss: 0.123066590258605
Validation loss: 2.339874693032026

Epoch: 5| Step: 10
Training loss: 0.3003471387680516
Validation loss: 2.3705795108060053

Epoch: 493| Step: 0
Training loss: 0.18220185156251983
Validation loss: 2.328568850586909

Epoch: 5| Step: 1
Training loss: 0.14938909658650204
Validation loss: 2.3504649541676828

Epoch: 5| Step: 2
Training loss: 0.10504525868932607
Validation loss: 2.3459897644671797

Epoch: 5| Step: 3
Training loss: 0.2621518153298558
Validation loss: 2.3723203441438314

Epoch: 5| Step: 4
Training loss: 0.23242418304066723
Validation loss: 2.381442919899186

Epoch: 5| Step: 5
Training loss: 0.19812699903568723
Validation loss: 2.4069089611826677

Epoch: 5| Step: 6
Training loss: 0.16466791981182927
Validation loss: 2.4292229775915724

Epoch: 5| Step: 7
Training loss: 0.24141162755217263
Validation loss: 2.3994599111501436

Epoch: 5| Step: 8
Training loss: 0.16826380276178146
Validation loss: 2.390562953863634

Epoch: 5| Step: 9
Training loss: 0.11397337763067374
Validation loss: 2.3812843773949344

Epoch: 5| Step: 10
Training loss: 0.18649391619753752
Validation loss: 2.40747851006544

Epoch: 494| Step: 0
Training loss: 0.15224895217688403
Validation loss: 2.401677888434964

Epoch: 5| Step: 1
Training loss: 0.21595463952472613
Validation loss: 2.3448687480470625

Epoch: 5| Step: 2
Training loss: 0.2754186791814394
Validation loss: 2.333164549215038

Epoch: 5| Step: 3
Training loss: 0.22809477305362516
Validation loss: 2.350600289174448

Epoch: 5| Step: 4
Training loss: 0.1224619952069468
Validation loss: 2.346454128516875

Epoch: 5| Step: 5
Training loss: 0.15302897673358176
Validation loss: 2.36402010031522

Epoch: 5| Step: 6
Training loss: 0.08632708695594545
Validation loss: 2.390742211736147

Epoch: 5| Step: 7
Training loss: 0.28316679096630826
Validation loss: 2.3781799649627198

Epoch: 5| Step: 8
Training loss: 0.1299815985374732
Validation loss: 2.392955297625969

Epoch: 5| Step: 9
Training loss: 0.10930544054798373
Validation loss: 2.4008334888655347

Epoch: 5| Step: 10
Training loss: 0.16524893491368572
Validation loss: 2.4001667458280544

Epoch: 495| Step: 0
Training loss: 0.11449176116676567
Validation loss: 2.4296030352282876

Epoch: 5| Step: 1
Training loss: 0.12309307411833405
Validation loss: 2.4102379213372056

Epoch: 5| Step: 2
Training loss: 0.17424889333680044
Validation loss: 2.35127218897352

Epoch: 5| Step: 3
Training loss: 0.3075600465049937
Validation loss: 2.3266265334722136

Epoch: 5| Step: 4
Training loss: 0.16593663075321782
Validation loss: 2.3306241608806286

Epoch: 5| Step: 5
Training loss: 0.12575083477414362
Validation loss: 2.3363881329651037

Epoch: 5| Step: 6
Training loss: 0.17672504732563304
Validation loss: 2.330457111887434

Epoch: 5| Step: 7
Training loss: 0.15959504705043556
Validation loss: 2.3257684375443195

Epoch: 5| Step: 8
Training loss: 0.2925367221644427
Validation loss: 2.3883861455071833

Epoch: 5| Step: 9
Training loss: 0.13092151276806596
Validation loss: 2.4063944299802693

Epoch: 5| Step: 10
Training loss: 0.1531494792522752
Validation loss: 2.4222538890184846

Epoch: 496| Step: 0
Training loss: 0.20957834738538492
Validation loss: 2.43650835667854

Epoch: 5| Step: 1
Training loss: 0.12174109123508493
Validation loss: 2.4380089822917124

Epoch: 5| Step: 2
Training loss: 0.2537016704649431
Validation loss: 2.4111825572726144

Epoch: 5| Step: 3
Training loss: 0.1405822039757907
Validation loss: 2.4079273569213617

Epoch: 5| Step: 4
Training loss: 0.2646093022876028
Validation loss: 2.395139545786541

Epoch: 5| Step: 5
Training loss: 0.0785771932757185
Validation loss: 2.3397367400458835

Epoch: 5| Step: 6
Training loss: 0.10413170068710972
Validation loss: 2.3503732434614246

Epoch: 5| Step: 7
Training loss: 0.23471332608587667
Validation loss: 2.353600195827801

Epoch: 5| Step: 8
Training loss: 0.16876737783281257
Validation loss: 2.3505399349885603

Epoch: 5| Step: 9
Training loss: 0.23910334524890103
Validation loss: 2.3822514312365413

Epoch: 5| Step: 10
Training loss: 0.12037874447860318
Validation loss: 2.4060472782028057

Epoch: 497| Step: 0
Training loss: 0.21451454950552482
Validation loss: 2.3890856487103664

Epoch: 5| Step: 1
Training loss: 0.06773614847002056
Validation loss: 2.4056868733904015

Epoch: 5| Step: 2
Training loss: 0.11031026827145952
Validation loss: 2.4353225675372507

Epoch: 5| Step: 3
Training loss: 0.17663535201761826
Validation loss: 2.394561995958781

Epoch: 5| Step: 4
Training loss: 0.09104633918173775
Validation loss: 2.374797356881358

Epoch: 5| Step: 5
Training loss: 0.36198888623844117
Validation loss: 2.3591400085961785

Epoch: 5| Step: 6
Training loss: 0.17756294534688472
Validation loss: 2.321415437099799

Epoch: 5| Step: 7
Training loss: 0.1180258249692966
Validation loss: 2.3391980711808453

Epoch: 5| Step: 8
Training loss: 0.1582187950944921
Validation loss: 2.355393155485064

Epoch: 5| Step: 9
Training loss: 0.0962162953819737
Validation loss: 2.3772828929006127

Epoch: 5| Step: 10
Training loss: 0.1646164895915905
Validation loss: 2.364730047268007

Epoch: 498| Step: 0
Training loss: 0.11543096728833743
Validation loss: 2.3851832363251244

Epoch: 5| Step: 1
Training loss: 0.28003288872035736
Validation loss: 2.3883553978658645

Epoch: 5| Step: 2
Training loss: 0.16500679806771826
Validation loss: 2.39177013650896

Epoch: 5| Step: 3
Training loss: 0.18760257140615774
Validation loss: 2.4047545170126967

Epoch: 5| Step: 4
Training loss: 0.23161964450147643
Validation loss: 2.390191301778428

Epoch: 5| Step: 5
Training loss: 0.1027357938980343
Validation loss: 2.3803380379433845

Epoch: 5| Step: 6
Training loss: 0.10156450361329546
Validation loss: 2.425786415784047

Epoch: 5| Step: 7
Training loss: 0.11724627133695494
Validation loss: 2.382928912598716

Epoch: 5| Step: 8
Training loss: 0.1519064924865589
Validation loss: 2.3856047592738614

Epoch: 5| Step: 9
Training loss: 0.3391637905726853
Validation loss: 2.3753992720873796

Epoch: 5| Step: 10
Training loss: 0.10873021652195165
Validation loss: 2.364051151456469

Epoch: 499| Step: 0
Training loss: 0.16219413793353624
Validation loss: 2.3591948127137607

Epoch: 5| Step: 1
Training loss: 0.24534162755419106
Validation loss: 2.3188765318127644

Epoch: 5| Step: 2
Training loss: 0.24041387783352483
Validation loss: 2.3656147455669516

Epoch: 5| Step: 3
Training loss: 0.11965805010115287
Validation loss: 2.3498820929620097

Epoch: 5| Step: 4
Training loss: 0.2149206110710161
Validation loss: 2.3229236872146783

Epoch: 5| Step: 5
Training loss: 0.23825205952433662
Validation loss: 2.357615375870229

Epoch: 5| Step: 6
Training loss: 0.13455298136378238
Validation loss: 2.373939676856767

Epoch: 5| Step: 7
Training loss: 0.14197381515964053
Validation loss: 2.378129636577742

Epoch: 5| Step: 8
Training loss: 0.1773810385266921
Validation loss: 2.421003827388787

Epoch: 5| Step: 9
Training loss: 0.13212534609986576
Validation loss: 2.469399244952025

Epoch: 5| Step: 10
Training loss: 0.12819216642437126
Validation loss: 2.4567575510784487

Epoch: 500| Step: 0
Training loss: 0.11005279725455969
Validation loss: 2.4501430429535738

Epoch: 5| Step: 1
Training loss: 0.11247947194313007
Validation loss: 2.4793789687287338

Epoch: 5| Step: 2
Training loss: 0.09930856480583211
Validation loss: 2.4565672077338947

Epoch: 5| Step: 3
Training loss: 0.12227753407549709
Validation loss: 2.4513496925678995

Epoch: 5| Step: 4
Training loss: 0.19168931116356078
Validation loss: 2.38790714718258

Epoch: 5| Step: 5
Training loss: 0.164647948104837
Validation loss: 2.400353943924237

Epoch: 5| Step: 6
Training loss: 0.22939520876781566
Validation loss: 2.3999692106280164

Epoch: 5| Step: 7
Training loss: 0.1694714836386902
Validation loss: 2.4002791606405545

Epoch: 5| Step: 8
Training loss: 0.2424100192014127
Validation loss: 2.424218619545305

Epoch: 5| Step: 9
Training loss: 0.25314678169064264
Validation loss: 2.421511379523761

Epoch: 5| Step: 10
Training loss: 0.23478110416305767
Validation loss: 2.438094232053633

Epoch: 501| Step: 0
Training loss: 0.17079528965527024
Validation loss: 2.380935985494818

Epoch: 5| Step: 1
Training loss: 0.23065512605131502
Validation loss: 2.3746565164001097

Epoch: 5| Step: 2
Training loss: 0.1272383566763554
Validation loss: 2.380949082342989

Epoch: 5| Step: 3
Training loss: 0.12870247947676405
Validation loss: 2.3663260910568433

Epoch: 5| Step: 4
Training loss: 0.2352561440684042
Validation loss: 2.3262821272394993

Epoch: 5| Step: 5
Training loss: 0.20844849840569465
Validation loss: 2.3334004612977677

Epoch: 5| Step: 6
Training loss: 0.15256034297230878
Validation loss: 2.3596654163287156

Epoch: 5| Step: 7
Training loss: 0.30481915197257353
Validation loss: 2.3779626878430102

Epoch: 5| Step: 8
Training loss: 0.1608016049129872
Validation loss: 2.42259962638597

Epoch: 5| Step: 9
Training loss: 0.07799644025335042
Validation loss: 2.4128513257405952

Epoch: 5| Step: 10
Training loss: 0.36962132717006796
Validation loss: 2.4066980022395543

Epoch: 502| Step: 0
Training loss: 0.1596830401758953
Validation loss: 2.417845949240719

Epoch: 5| Step: 1
Training loss: 0.15759273797942694
Validation loss: 2.403889885131512

Epoch: 5| Step: 2
Training loss: 0.1404818163534707
Validation loss: 2.342513865241188

Epoch: 5| Step: 3
Training loss: 0.2522749656490854
Validation loss: 2.3362694833391524

Epoch: 5| Step: 4
Training loss: 0.16272761904555588
Validation loss: 2.3609185665296013

Epoch: 5| Step: 5
Training loss: 0.21773698099614214
Validation loss: 2.368785722448952

Epoch: 5| Step: 6
Training loss: 0.2861838571891865
Validation loss: 2.42551659347472

Epoch: 5| Step: 7
Training loss: 0.23090680566220856
Validation loss: 2.417937733377405

Epoch: 5| Step: 8
Training loss: 0.17197872954805377
Validation loss: 2.3908193585522284

Epoch: 5| Step: 9
Training loss: 0.18939111618986654
Validation loss: 2.4174783409366563

Epoch: 5| Step: 10
Training loss: 0.26260199892560887
Validation loss: 2.403758813159529

Epoch: 503| Step: 0
Training loss: 0.14550948302058908
Validation loss: 2.417813436000979

Epoch: 5| Step: 1
Training loss: 0.2259647359695928
Validation loss: 2.389801304393699

Epoch: 5| Step: 2
Training loss: 0.21908323417034736
Validation loss: 2.4173467087361233

Epoch: 5| Step: 3
Training loss: 0.23553725392191552
Validation loss: 2.392588580646317

Epoch: 5| Step: 4
Training loss: 0.13425102669573696
Validation loss: 2.387893138361929

Epoch: 5| Step: 5
Training loss: 0.24256016915127124
Validation loss: 2.329486405652174

Epoch: 5| Step: 6
Training loss: 0.23957403655604345
Validation loss: 2.292432912737149

Epoch: 5| Step: 7
Training loss: 0.10926569006367103
Validation loss: 2.3071662588937727

Epoch: 5| Step: 8
Training loss: 0.26133071544600667
Validation loss: 2.3105528076945614

Epoch: 5| Step: 9
Training loss: 0.16234678096713812
Validation loss: 2.3646861239182373

Epoch: 5| Step: 10
Training loss: 0.1507215018312843
Validation loss: 2.4142647229194334

Epoch: 504| Step: 0
Training loss: 0.1521306748605119
Validation loss: 2.3946647599462403

Epoch: 5| Step: 1
Training loss: 0.25375528983066054
Validation loss: 2.4304818527680627

Epoch: 5| Step: 2
Training loss: 0.2018607483548483
Validation loss: 2.406512176502979

Epoch: 5| Step: 3
Training loss: 0.12322153834333029
Validation loss: 2.418056233519675

Epoch: 5| Step: 4
Training loss: 0.16185866928020387
Validation loss: 2.3764077673704453

Epoch: 5| Step: 5
Training loss: 0.14447871103836013
Validation loss: 2.402583978211833

Epoch: 5| Step: 6
Training loss: 0.2072279193916444
Validation loss: 2.3877395426818295

Epoch: 5| Step: 7
Training loss: 0.23898344852184372
Validation loss: 2.36487410991219

Epoch: 5| Step: 8
Training loss: 0.19005420542151033
Validation loss: 2.384785485947309

Epoch: 5| Step: 9
Training loss: 0.12360971635827524
Validation loss: 2.363073353041574

Epoch: 5| Step: 10
Training loss: 0.15566039302430462
Validation loss: 2.3686609032650283

Epoch: 505| Step: 0
Training loss: 0.2172933255492247
Validation loss: 2.3606377590604968

Epoch: 5| Step: 1
Training loss: 0.164609949358068
Validation loss: 2.364052620854447

Epoch: 5| Step: 2
Training loss: 0.16811734103196652
Validation loss: 2.3605762779149604

Epoch: 5| Step: 3
Training loss: 0.14948468627331074
Validation loss: 2.381769632518151

Epoch: 5| Step: 4
Training loss: 0.175119904329633
Validation loss: 2.3729869296656694

Epoch: 5| Step: 5
Training loss: 0.09971083821530335
Validation loss: 2.36391839110452

Epoch: 5| Step: 6
Training loss: 0.2362842519090394
Validation loss: 2.39225434165647

Epoch: 5| Step: 7
Training loss: 0.1253368933996167
Validation loss: 2.400924086797618

Epoch: 5| Step: 8
Training loss: 0.3093667549421781
Validation loss: 2.399938780164456

Epoch: 5| Step: 9
Training loss: 0.12747262155872943
Validation loss: 2.4502886919959304

Epoch: 5| Step: 10
Training loss: 0.18024075378189025
Validation loss: 2.44135106309434

Epoch: 506| Step: 0
Training loss: 0.14017893989217786
Validation loss: 2.4347885159952383

Epoch: 5| Step: 1
Training loss: 0.104613127195999
Validation loss: 2.447636620275666

Epoch: 5| Step: 2
Training loss: 0.1784021388288656
Validation loss: 2.5046548137019076

Epoch: 5| Step: 3
Training loss: 0.3275230199061717
Validation loss: 2.456358406400632

Epoch: 5| Step: 4
Training loss: 0.14172250252732155
Validation loss: 2.449359077329619

Epoch: 5| Step: 5
Training loss: 0.25120203302849253
Validation loss: 2.47083727989455

Epoch: 5| Step: 6
Training loss: 0.16261379631514572
Validation loss: 2.3764920979833666

Epoch: 5| Step: 7
Training loss: 0.19226979067868957
Validation loss: 2.354471375520272

Epoch: 5| Step: 8
Training loss: 0.14734386697928356
Validation loss: 2.3405768097521302

Epoch: 5| Step: 9
Training loss: 0.1317909870517119
Validation loss: 2.346268337982133

Epoch: 5| Step: 10
Training loss: 0.29280644053293153
Validation loss: 2.3448788446336275

Epoch: 507| Step: 0
Training loss: 0.24218671552469503
Validation loss: 2.3870314284897667

Epoch: 5| Step: 1
Training loss: 0.15538171675527454
Validation loss: 2.4494096282834827

Epoch: 5| Step: 2
Training loss: 0.1420793431128197
Validation loss: 2.4808106752373265

Epoch: 5| Step: 3
Training loss: 0.21870345233495653
Validation loss: 2.4982939302960596

Epoch: 5| Step: 4
Training loss: 0.25043464666444737
Validation loss: 2.5210598301728147

Epoch: 5| Step: 5
Training loss: 0.32542760531242776
Validation loss: 2.481481432317401

Epoch: 5| Step: 6
Training loss: 0.1929776826713812
Validation loss: 2.4502992748995345

Epoch: 5| Step: 7
Training loss: 0.13534429263673567
Validation loss: 2.3369639456449063

Epoch: 5| Step: 8
Training loss: 0.1935037594030818
Validation loss: 2.2977581133208327

Epoch: 5| Step: 9
Training loss: 0.16211340795808774
Validation loss: 2.265181760390521

Epoch: 5| Step: 10
Training loss: 0.16669489514688884
Validation loss: 2.2624092655392936

Epoch: 508| Step: 0
Training loss: 0.29629337908643766
Validation loss: 2.2688791691883976

Epoch: 5| Step: 1
Training loss: 0.25815462762137914
Validation loss: 2.3844043088809963

Epoch: 5| Step: 2
Training loss: 0.14277305081128566
Validation loss: 2.4339860693302837

Epoch: 5| Step: 3
Training loss: 0.30296635507283315
Validation loss: 2.5164354298243077

Epoch: 5| Step: 4
Training loss: 0.2641300036131984
Validation loss: 2.5609236089554708

Epoch: 5| Step: 5
Training loss: 0.17896283225294912
Validation loss: 2.53715051846588

Epoch: 5| Step: 6
Training loss: 0.17503586193036877
Validation loss: 2.509002054829147

Epoch: 5| Step: 7
Training loss: 0.21431655356755744
Validation loss: 2.4613543330446968

Epoch: 5| Step: 8
Training loss: 0.13551298179454607
Validation loss: 2.3586193040656647

Epoch: 5| Step: 9
Training loss: 0.09828425657528343
Validation loss: 2.2801684294859963

Epoch: 5| Step: 10
Training loss: 0.2399881077591672
Validation loss: 2.2108244426952326

Epoch: 509| Step: 0
Training loss: 0.287355097245342
Validation loss: 2.1879632110740834

Epoch: 5| Step: 1
Training loss: 0.3175535945638433
Validation loss: 2.2243595194192545

Epoch: 5| Step: 2
Training loss: 0.26758031078476113
Validation loss: 2.289452531571311

Epoch: 5| Step: 3
Training loss: 0.23676887900478333
Validation loss: 2.4176035399200235

Epoch: 5| Step: 4
Training loss: 0.2911764890787784
Validation loss: 2.529201425536281

Epoch: 5| Step: 5
Training loss: 0.4122716575124817
Validation loss: 2.569635117394197

Epoch: 5| Step: 6
Training loss: 0.13156448250633745
Validation loss: 2.4895057930449047

Epoch: 5| Step: 7
Training loss: 0.19368828628949136
Validation loss: 2.4462652928243456

Epoch: 5| Step: 8
Training loss: 0.16735814245470143
Validation loss: 2.3670740551512943

Epoch: 5| Step: 9
Training loss: 0.10864160944474666
Validation loss: 2.353094761500316

Epoch: 5| Step: 10
Training loss: 0.287572228128485
Validation loss: 2.3182410580692596

Epoch: 510| Step: 0
Training loss: 0.242395081313316
Validation loss: 2.334096503227742

Epoch: 5| Step: 1
Training loss: 0.24133567827876476
Validation loss: 2.3918023295809925

Epoch: 5| Step: 2
Training loss: 0.1284916742379173
Validation loss: 2.4237915352547805

Epoch: 5| Step: 3
Training loss: 0.23642224415934396
Validation loss: 2.497805723770133

Epoch: 5| Step: 4
Training loss: 0.1454807102641904
Validation loss: 2.4795437204910593

Epoch: 5| Step: 5
Training loss: 0.22774033383250422
Validation loss: 2.4621663551887654

Epoch: 5| Step: 6
Training loss: 0.3195301130503081
Validation loss: 2.4601180590527907

Epoch: 5| Step: 7
Training loss: 0.28246363414204656
Validation loss: 2.3590573631702125

Epoch: 5| Step: 8
Training loss: 0.24355136713060488
Validation loss: 2.262260712550776

Epoch: 5| Step: 9
Training loss: 0.22017621972486978
Validation loss: 2.19874647912677

Epoch: 5| Step: 10
Training loss: 0.3209433739485858
Validation loss: 2.175808725720972

Epoch: 511| Step: 0
Training loss: 0.3344872130407541
Validation loss: 2.193861955276788

Epoch: 5| Step: 1
Training loss: 0.24408609925785987
Validation loss: 2.2284744490549153

Epoch: 5| Step: 2
Training loss: 0.21411497315247824
Validation loss: 2.3309712404165963

Epoch: 5| Step: 3
Training loss: 0.20249423797380492
Validation loss: 2.439444329935674

Epoch: 5| Step: 4
Training loss: 0.32566953568665497
Validation loss: 2.4741222278513337

Epoch: 5| Step: 5
Training loss: 0.15656159445411288
Validation loss: 2.5303535990941244

Epoch: 5| Step: 6
Training loss: 0.22344310493375058
Validation loss: 2.458908179308396

Epoch: 5| Step: 7
Training loss: 0.2811137637678416
Validation loss: 2.4145103628800606

Epoch: 5| Step: 8
Training loss: 0.15434588486909046
Validation loss: 2.3362089487694537

Epoch: 5| Step: 9
Training loss: 0.13715998430137816
Validation loss: 2.321307202262769

Epoch: 5| Step: 10
Training loss: 0.10491045901809526
Validation loss: 2.2653475372632514

Epoch: 512| Step: 0
Training loss: 0.2378252857345281
Validation loss: 2.245691635853632

Epoch: 5| Step: 1
Training loss: 0.22083955109737874
Validation loss: 2.2570721260809696

Epoch: 5| Step: 2
Training loss: 0.21308637071770006
Validation loss: 2.2577014448272785

Epoch: 5| Step: 3
Training loss: 0.2753603086626192
Validation loss: 2.2459946266048822

Epoch: 5| Step: 4
Training loss: 0.15669057244756646
Validation loss: 2.3006172056928826

Epoch: 5| Step: 5
Training loss: 0.3029467791243335
Validation loss: 2.366050599904313

Epoch: 5| Step: 6
Training loss: 0.1663987507272039
Validation loss: 2.4257005892093106

Epoch: 5| Step: 7
Training loss: 0.11774043922526095
Validation loss: 2.4973483954261755

Epoch: 5| Step: 8
Training loss: 0.18583269691857243
Validation loss: 2.541449099918067

Epoch: 5| Step: 9
Training loss: 0.20554174062303654
Validation loss: 2.521000073955107

Epoch: 5| Step: 10
Training loss: 0.2759383011068637
Validation loss: 2.496944514811908

Epoch: 513| Step: 0
Training loss: 0.20798606938011616
Validation loss: 2.507963006138572

Epoch: 5| Step: 1
Training loss: 0.14297593156047847
Validation loss: 2.4195223265102386

Epoch: 5| Step: 2
Training loss: 0.3221767996704829
Validation loss: 2.3987003615401643

Epoch: 5| Step: 3
Training loss: 0.18172941806340986
Validation loss: 2.3231665915833575

Epoch: 5| Step: 4
Training loss: 0.2244254146722526
Validation loss: 2.272422057718437

Epoch: 5| Step: 5
Training loss: 0.23905888286671517
Validation loss: 2.2812644799582484

Epoch: 5| Step: 6
Training loss: 0.22817666435478967
Validation loss: 2.346527575769058

Epoch: 5| Step: 7
Training loss: 0.25758859274700857
Validation loss: 2.3170863082953415

Epoch: 5| Step: 8
Training loss: 0.14246267713567706
Validation loss: 2.3507634562838935

Epoch: 5| Step: 9
Training loss: 0.1803244001074739
Validation loss: 2.3763349591098106

Epoch: 5| Step: 10
Training loss: 0.2503056892439983
Validation loss: 2.367768985602381

Epoch: 514| Step: 0
Training loss: 0.15931502831384475
Validation loss: 2.3791965105681165

Epoch: 5| Step: 1
Training loss: 0.20712610986558425
Validation loss: 2.3504262439887147

Epoch: 5| Step: 2
Training loss: 0.17808784716453085
Validation loss: 2.3307844167240117

Epoch: 5| Step: 3
Training loss: 0.1299364008097833
Validation loss: 2.3483422334518766

Epoch: 5| Step: 4
Training loss: 0.24007354563135797
Validation loss: 2.2933067210640616

Epoch: 5| Step: 5
Training loss: 0.21124080645007734
Validation loss: 2.3259178832920027

Epoch: 5| Step: 6
Training loss: 0.19014231198963952
Validation loss: 2.359615712150371

Epoch: 5| Step: 7
Training loss: 0.1431209343120366
Validation loss: 2.374060699259152

Epoch: 5| Step: 8
Training loss: 0.2667353088476971
Validation loss: 2.3502676339587323

Epoch: 5| Step: 9
Training loss: 0.17929513219846532
Validation loss: 2.3871768086038934

Epoch: 5| Step: 10
Training loss: 0.22823583967191083
Validation loss: 2.3902390970372096

Epoch: 515| Step: 0
Training loss: 0.1703735738580535
Validation loss: 2.4041766959207043

Epoch: 5| Step: 1
Training loss: 0.1408392281069834
Validation loss: 2.403080479008272

Epoch: 5| Step: 2
Training loss: 0.2608344811245666
Validation loss: 2.376060306904858

Epoch: 5| Step: 3
Training loss: 0.21113111299435963
Validation loss: 2.3492166826247183

Epoch: 5| Step: 4
Training loss: 0.2119884624051995
Validation loss: 2.307503344831008

Epoch: 5| Step: 5
Training loss: 0.2075453887986182
Validation loss: 2.3023571443084783

Epoch: 5| Step: 6
Training loss: 0.10427769366697029
Validation loss: 2.3104887699590027

Epoch: 5| Step: 7
Training loss: 0.0971364109032741
Validation loss: 2.266742784448377

Epoch: 5| Step: 8
Training loss: 0.211025758222459
Validation loss: 2.2908006085026624

Epoch: 5| Step: 9
Training loss: 0.11444634589992249
Validation loss: 2.278910008927907

Epoch: 5| Step: 10
Training loss: 0.17959989609829483
Validation loss: 2.29360922837759

Epoch: 516| Step: 0
Training loss: 0.1887003109118736
Validation loss: 2.3297368765805406

Epoch: 5| Step: 1
Training loss: 0.15717476530609703
Validation loss: 2.3739915778325704

Epoch: 5| Step: 2
Training loss: 0.1400602710364379
Validation loss: 2.3793737038203555

Epoch: 5| Step: 3
Training loss: 0.20367262453468807
Validation loss: 2.392199281119742

Epoch: 5| Step: 4
Training loss: 0.14649964570874935
Validation loss: 2.406833271684399

Epoch: 5| Step: 5
Training loss: 0.22068372151649396
Validation loss: 2.4229152873244493

Epoch: 5| Step: 6
Training loss: 0.20303674761418977
Validation loss: 2.417700138830921

Epoch: 5| Step: 7
Training loss: 0.12420830877675046
Validation loss: 2.3881659818187875

Epoch: 5| Step: 8
Training loss: 0.18303349415499315
Validation loss: 2.3845698591967213

Epoch: 5| Step: 9
Training loss: 0.2260367937192687
Validation loss: 2.3904734421447515

Epoch: 5| Step: 10
Training loss: 0.13955053485611024
Validation loss: 2.36933120388303

Epoch: 517| Step: 0
Training loss: 0.12918376671620113
Validation loss: 2.398736425585797

Epoch: 5| Step: 1
Training loss: 0.12317968951150458
Validation loss: 2.40477579037854

Epoch: 5| Step: 2
Training loss: 0.1895620681727591
Validation loss: 2.4044229607952974

Epoch: 5| Step: 3
Training loss: 0.1883620769286374
Validation loss: 2.4188060288605224

Epoch: 5| Step: 4
Training loss: 0.12157732406757345
Validation loss: 2.4078001120200474

Epoch: 5| Step: 5
Training loss: 0.2048748643931696
Validation loss: 2.340919061418024

Epoch: 5| Step: 6
Training loss: 0.20481127680150446
Validation loss: 2.3404280015469623

Epoch: 5| Step: 7
Training loss: 0.14757215335329277
Validation loss: 2.3161889053312277

Epoch: 5| Step: 8
Training loss: 0.16747219410020778
Validation loss: 2.2972389766002466

Epoch: 5| Step: 9
Training loss: 0.1065839730509317
Validation loss: 2.3145123179048728

Epoch: 5| Step: 10
Training loss: 0.2850247955411203
Validation loss: 2.3404909638107654

Epoch: 518| Step: 0
Training loss: 0.11382413544271001
Validation loss: 2.369457704815785

Epoch: 5| Step: 1
Training loss: 0.09707112494268774
Validation loss: 2.3755287872740385

Epoch: 5| Step: 2
Training loss: 0.17606837875997633
Validation loss: 2.373718665195449

Epoch: 5| Step: 3
Training loss: 0.12660441558127733
Validation loss: 2.389040324223831

Epoch: 5| Step: 4
Training loss: 0.10000548887835134
Validation loss: 2.388204847801417

Epoch: 5| Step: 5
Training loss: 0.18844100142305162
Validation loss: 2.4170555937566713

Epoch: 5| Step: 6
Training loss: 0.2119464937347519
Validation loss: 2.3854550334680256

Epoch: 5| Step: 7
Training loss: 0.09558123981949963
Validation loss: 2.3921745158426293

Epoch: 5| Step: 8
Training loss: 0.22470495429440646
Validation loss: 2.3859001227172394

Epoch: 5| Step: 9
Training loss: 0.26466334395991364
Validation loss: 2.373916083950923

Epoch: 5| Step: 10
Training loss: 0.11276265765056366
Validation loss: 2.3601468339615113

Epoch: 519| Step: 0
Training loss: 0.13064504265453442
Validation loss: 2.3834779705459654

Epoch: 5| Step: 1
Training loss: 0.1161593875830714
Validation loss: 2.3499862124165793

Epoch: 5| Step: 2
Training loss: 0.15864076833494006
Validation loss: 2.3402988250763923

Epoch: 5| Step: 3
Training loss: 0.1523280074470983
Validation loss: 2.319998017038149

Epoch: 5| Step: 4
Training loss: 0.14893763135447213
Validation loss: 2.3199488804907165

Epoch: 5| Step: 5
Training loss: 0.188926850671501
Validation loss: 2.296891593915019

Epoch: 5| Step: 6
Training loss: 0.1330412759571549
Validation loss: 2.3099971608943224

Epoch: 5| Step: 7
Training loss: 0.23315627811249187
Validation loss: 2.297525005435478

Epoch: 5| Step: 8
Training loss: 0.24614466791338493
Validation loss: 2.331752956791252

Epoch: 5| Step: 9
Training loss: 0.08888269121521042
Validation loss: 2.330150361110339

Epoch: 5| Step: 10
Training loss: 0.14196315505304985
Validation loss: 2.3250503107211986

Epoch: 520| Step: 0
Training loss: 0.07425606881070512
Validation loss: 2.332582423976167

Epoch: 5| Step: 1
Training loss: 0.15456592666384597
Validation loss: 2.3558262882704586

Epoch: 5| Step: 2
Training loss: 0.1229345399246151
Validation loss: 2.3446867735372106

Epoch: 5| Step: 3
Training loss: 0.22835497629716836
Validation loss: 2.363505021961409

Epoch: 5| Step: 4
Training loss: 0.15767551675843078
Validation loss: 2.3320879454645

Epoch: 5| Step: 5
Training loss: 0.20724554487289984
Validation loss: 2.3544209072842968

Epoch: 5| Step: 6
Training loss: 0.11978760527553707
Validation loss: 2.33564004908716

Epoch: 5| Step: 7
Training loss: 0.22889115378168814
Validation loss: 2.3367501269103133

Epoch: 5| Step: 8
Training loss: 0.14176754924082516
Validation loss: 2.371719281353039

Epoch: 5| Step: 9
Training loss: 0.08411823461371022
Validation loss: 2.356671863509044

Epoch: 5| Step: 10
Training loss: 0.17169881048014032
Validation loss: 2.3950327100388376

Epoch: 521| Step: 0
Training loss: 0.22875753460654177
Validation loss: 2.384640561812673

Epoch: 5| Step: 1
Training loss: 0.1328554785133635
Validation loss: 2.358380799348684

Epoch: 5| Step: 2
Training loss: 0.05847194647678363
Validation loss: 2.3898146873511594

Epoch: 5| Step: 3
Training loss: 0.1356388151256586
Validation loss: 2.4112870662232484

Epoch: 5| Step: 4
Training loss: 0.15081656813203417
Validation loss: 2.3626411549475232

Epoch: 5| Step: 5
Training loss: 0.17574624666747987
Validation loss: 2.3967760531035505

Epoch: 5| Step: 6
Training loss: 0.0946024740680663
Validation loss: 2.424648229628267

Epoch: 5| Step: 7
Training loss: 0.14260227834883102
Validation loss: 2.408848252936335

Epoch: 5| Step: 8
Training loss: 0.10470163442076974
Validation loss: 2.4213862671935327

Epoch: 5| Step: 9
Training loss: 0.28916863477671095
Validation loss: 2.3628891334406044

Epoch: 5| Step: 10
Training loss: 0.1687857640744638
Validation loss: 2.38423847664612

Epoch: 522| Step: 0
Training loss: 0.15721106600954024
Validation loss: 2.358387270454525

Epoch: 5| Step: 1
Training loss: 0.23776096857152407
Validation loss: 2.3801935530745513

Epoch: 5| Step: 2
Training loss: 0.0951366103157392
Validation loss: 2.360084542720192

Epoch: 5| Step: 3
Training loss: 0.17761295488900533
Validation loss: 2.3536709513923957

Epoch: 5| Step: 4
Training loss: 0.14623662979192478
Validation loss: 2.3613433374630604

Epoch: 5| Step: 5
Training loss: 0.24025755669621096
Validation loss: 2.356865470552982

Epoch: 5| Step: 6
Training loss: 0.15295145895609102
Validation loss: 2.3765836615905083

Epoch: 5| Step: 7
Training loss: 0.09451424508798843
Validation loss: 2.3766027797313405

Epoch: 5| Step: 8
Training loss: 0.11840054988707213
Validation loss: 2.3583064969433645

Epoch: 5| Step: 9
Training loss: 0.09475920793045392
Validation loss: 2.408842099111584

Epoch: 5| Step: 10
Training loss: 0.26473980554579746
Validation loss: 2.388355104293242

Epoch: 523| Step: 0
Training loss: 0.1622985746882827
Validation loss: 2.394032544620432

Epoch: 5| Step: 1
Training loss: 0.11769762271774961
Validation loss: 2.430722076016778

Epoch: 5| Step: 2
Training loss: 0.13126229415943166
Validation loss: 2.452436618222371

Epoch: 5| Step: 3
Training loss: 0.19910070250357056
Validation loss: 2.427329610256402

Epoch: 5| Step: 4
Training loss: 0.15197757583066196
Validation loss: 2.367274594627887

Epoch: 5| Step: 5
Training loss: 0.14034787661317394
Validation loss: 2.3748188737714244

Epoch: 5| Step: 6
Training loss: 0.2860131648274877
Validation loss: 2.3696317910660887

Epoch: 5| Step: 7
Training loss: 0.207833615642854
Validation loss: 2.3202931536685605

Epoch: 5| Step: 8
Training loss: 0.07482279117728956
Validation loss: 2.348785423130399

Epoch: 5| Step: 9
Training loss: 0.14266398862215673
Validation loss: 2.3525848537459106

Epoch: 5| Step: 10
Training loss: 0.11890579751137896
Validation loss: 2.307643187959585

Epoch: 524| Step: 0
Training loss: 0.1377839553880606
Validation loss: 2.340739396348456

Epoch: 5| Step: 1
Training loss: 0.20108929578031806
Validation loss: 2.37067156204323

Epoch: 5| Step: 2
Training loss: 0.14314843778189162
Validation loss: 2.3907853293336383

Epoch: 5| Step: 3
Training loss: 0.21453102934201557
Validation loss: 2.3959595545779764

Epoch: 5| Step: 4
Training loss: 0.08862900516878242
Validation loss: 2.3991090203831225

Epoch: 5| Step: 5
Training loss: 0.21600943689295343
Validation loss: 2.44576779636016

Epoch: 5| Step: 6
Training loss: 0.17619872850672144
Validation loss: 2.480400796491881

Epoch: 5| Step: 7
Training loss: 0.08222044403255005
Validation loss: 2.4461396884996187

Epoch: 5| Step: 8
Training loss: 0.14999084469551652
Validation loss: 2.4856202940023353

Epoch: 5| Step: 9
Training loss: 0.09221912221532905
Validation loss: 2.4756822901643933

Epoch: 5| Step: 10
Training loss: 0.2285702876385564
Validation loss: 2.4492905129614133

Epoch: 525| Step: 0
Training loss: 0.07349919684897387
Validation loss: 2.4537498285031707

Epoch: 5| Step: 1
Training loss: 0.2533643956235382
Validation loss: 2.4502341655155515

Epoch: 5| Step: 2
Training loss: 0.10494541203876001
Validation loss: 2.4278333373818715

Epoch: 5| Step: 3
Training loss: 0.10222048087973913
Validation loss: 2.4317120780714423

Epoch: 5| Step: 4
Training loss: 0.13280084502747705
Validation loss: 2.4439192040125524

Epoch: 5| Step: 5
Training loss: 0.223460451694581
Validation loss: 2.427150524346067

Epoch: 5| Step: 6
Training loss: 0.18240072303359925
Validation loss: 2.4539014179226184

Epoch: 5| Step: 7
Training loss: 0.08087043041632878
Validation loss: 2.4234035425114584

Epoch: 5| Step: 8
Training loss: 0.23196927247932236
Validation loss: 2.430332782271184

Epoch: 5| Step: 9
Training loss: 0.2396810719251027
Validation loss: 2.428007942009468

Epoch: 5| Step: 10
Training loss: 0.08541777168359702
Validation loss: 2.396623558350346

Epoch: 526| Step: 0
Training loss: 0.1097633670425316
Validation loss: 2.3720423281952407

Epoch: 5| Step: 1
Training loss: 0.20087557332301856
Validation loss: 2.30268412886968

Epoch: 5| Step: 2
Training loss: 0.24886848266149586
Validation loss: 2.339181840127134

Epoch: 5| Step: 3
Training loss: 0.15196137859415199
Validation loss: 2.3558212079429013

Epoch: 5| Step: 4
Training loss: 0.1722245995765934
Validation loss: 2.404933058198252

Epoch: 5| Step: 5
Training loss: 0.2562140416293011
Validation loss: 2.408582128026202

Epoch: 5| Step: 6
Training loss: 0.23788761237230363
Validation loss: 2.400722055746667

Epoch: 5| Step: 7
Training loss: 0.12164638914784981
Validation loss: 2.3866024395483754

Epoch: 5| Step: 8
Training loss: 0.18716325919758395
Validation loss: 2.3991570493810848

Epoch: 5| Step: 9
Training loss: 0.10900690092051346
Validation loss: 2.348776841938053

Epoch: 5| Step: 10
Training loss: 0.11006109019903203
Validation loss: 2.3353919500872733

Epoch: 527| Step: 0
Training loss: 0.15108776759204978
Validation loss: 2.324266027912614

Epoch: 5| Step: 1
Training loss: 0.23194312628179847
Validation loss: 2.3728329238851775

Epoch: 5| Step: 2
Training loss: 0.08677252485420922
Validation loss: 2.381255464615119

Epoch: 5| Step: 3
Training loss: 0.21694187092533396
Validation loss: 2.3869247410735848

Epoch: 5| Step: 4
Training loss: 0.2140442189534195
Validation loss: 2.418812212714039

Epoch: 5| Step: 5
Training loss: 0.1671105294546633
Validation loss: 2.4152457450331624

Epoch: 5| Step: 6
Training loss: 0.09236974724609982
Validation loss: 2.413633220312969

Epoch: 5| Step: 7
Training loss: 0.1574074610791733
Validation loss: 2.405915480907872

Epoch: 5| Step: 8
Training loss: 0.12417821162697644
Validation loss: 2.397089662945346

Epoch: 5| Step: 9
Training loss: 0.15377562638844988
Validation loss: 2.414841558565483

Epoch: 5| Step: 10
Training loss: 0.12128724896953332
Validation loss: 2.413042909220948

Epoch: 528| Step: 0
Training loss: 0.09255611665095173
Validation loss: 2.382371624648067

Epoch: 5| Step: 1
Training loss: 0.10590682620203852
Validation loss: 2.3823174354869896

Epoch: 5| Step: 2
Training loss: 0.1398728907714177
Validation loss: 2.356794287134809

Epoch: 5| Step: 3
Training loss: 0.20166626152051736
Validation loss: 2.3568050962405147

Epoch: 5| Step: 4
Training loss: 0.21974290575070185
Validation loss: 2.3798940391871057

Epoch: 5| Step: 5
Training loss: 0.27645663643704044
Validation loss: 2.415519301605785

Epoch: 5| Step: 6
Training loss: 0.15722533634252628
Validation loss: 2.4155645240574835

Epoch: 5| Step: 7
Training loss: 0.20331936486982538
Validation loss: 2.465407980053825

Epoch: 5| Step: 8
Training loss: 0.08544228116891464
Validation loss: 2.4644316182515578

Epoch: 5| Step: 9
Training loss: 0.09298568338964971
Validation loss: 2.508323358002113

Epoch: 5| Step: 10
Training loss: 0.10766710985799759
Validation loss: 2.5086694269910073

Epoch: 529| Step: 0
Training loss: 0.1906428586692822
Validation loss: 2.456675815565518

Epoch: 5| Step: 1
Training loss: 0.2045727724951192
Validation loss: 2.411349748581631

Epoch: 5| Step: 2
Training loss: 0.14856917413717843
Validation loss: 2.397823202028791

Epoch: 5| Step: 3
Training loss: 0.15492341638587945
Validation loss: 2.388096449571082

Epoch: 5| Step: 4
Training loss: 0.14862111931619973
Validation loss: 2.340569734084513

Epoch: 5| Step: 5
Training loss: 0.08440345068148467
Validation loss: 2.339892008329642

Epoch: 5| Step: 6
Training loss: 0.12826743930904808
Validation loss: 2.3590586710403376

Epoch: 5| Step: 7
Training loss: 0.17394612625449146
Validation loss: 2.356820120347367

Epoch: 5| Step: 8
Training loss: 0.14774624589727087
Validation loss: 2.37688829842853

Epoch: 5| Step: 9
Training loss: 0.14472240617063212
Validation loss: 2.390129787652847

Epoch: 5| Step: 10
Training loss: 0.24893594588623777
Validation loss: 2.380835016158927

Epoch: 530| Step: 0
Training loss: 0.10072067181117506
Validation loss: 2.354931106038641

Epoch: 5| Step: 1
Training loss: 0.1136545615431356
Validation loss: 2.3377936321314743

Epoch: 5| Step: 2
Training loss: 0.1059641242399941
Validation loss: 2.3333003262266936

Epoch: 5| Step: 3
Training loss: 0.12225229812238683
Validation loss: 2.3045633584680827

Epoch: 5| Step: 4
Training loss: 0.19861488824052262
Validation loss: 2.322559502685133

Epoch: 5| Step: 5
Training loss: 0.2802683600520729
Validation loss: 2.307063858392229

Epoch: 5| Step: 6
Training loss: 0.1841641554042721
Validation loss: 2.3302129013647

Epoch: 5| Step: 7
Training loss: 0.2181759949701998
Validation loss: 2.3056715700958055

Epoch: 5| Step: 8
Training loss: 0.2618000701281291
Validation loss: 2.3125566122524797

Epoch: 5| Step: 9
Training loss: 0.10941685999515234
Validation loss: 2.375223029501538

Epoch: 5| Step: 10
Training loss: 0.15441266073473175
Validation loss: 2.393671959268586

Epoch: 531| Step: 0
Training loss: 0.09441228722863128
Validation loss: 2.403244291296255

Epoch: 5| Step: 1
Training loss: 0.08528325175549645
Validation loss: 2.3847713483323987

Epoch: 5| Step: 2
Training loss: 0.1484741617403584
Validation loss: 2.3753381163538956

Epoch: 5| Step: 3
Training loss: 0.08743047794202544
Validation loss: 2.3952862720005967

Epoch: 5| Step: 4
Training loss: 0.17733936640493428
Validation loss: 2.3710277706522254

Epoch: 5| Step: 5
Training loss: 0.23007813180039402
Validation loss: 2.3665126679446145

Epoch: 5| Step: 6
Training loss: 0.23192291235169735
Validation loss: 2.369352173689779

Epoch: 5| Step: 7
Training loss: 0.15830226429192215
Validation loss: 2.348380473907755

Epoch: 5| Step: 8
Training loss: 0.19912229334613482
Validation loss: 2.3944840671720806

Epoch: 5| Step: 9
Training loss: 0.17213713098750577
Validation loss: 2.4023530362471046

Epoch: 5| Step: 10
Training loss: 0.13968641925026723
Validation loss: 2.455996405827952

Epoch: 532| Step: 0
Training loss: 0.21160481121406616
Validation loss: 2.456512272720696

Epoch: 5| Step: 1
Training loss: 0.2242477823528412
Validation loss: 2.506134240387711

Epoch: 5| Step: 2
Training loss: 0.11951626905047566
Validation loss: 2.465864931635126

Epoch: 5| Step: 3
Training loss: 0.08877475878406928
Validation loss: 2.428767159989147

Epoch: 5| Step: 4
Training loss: 0.16820812357001289
Validation loss: 2.3892513368478943

Epoch: 5| Step: 5
Training loss: 0.09402756034931038
Validation loss: 2.363572446720254

Epoch: 5| Step: 6
Training loss: 0.30205815994125185
Validation loss: 2.3276439802166236

Epoch: 5| Step: 7
Training loss: 0.15968417747422783
Validation loss: 2.298823223714653

Epoch: 5| Step: 8
Training loss: 0.08730520945911423
Validation loss: 2.3753639853311865

Epoch: 5| Step: 9
Training loss: 0.08887956868371928
Validation loss: 2.371207109570095

Epoch: 5| Step: 10
Training loss: 0.1232185755265752
Validation loss: 2.3846606654201405

Epoch: 533| Step: 0
Training loss: 0.1887914172261895
Validation loss: 2.3651552192237495

Epoch: 5| Step: 1
Training loss: 0.12761946914029706
Validation loss: 2.3650660677780238

Epoch: 5| Step: 2
Training loss: 0.08687606527426639
Validation loss: 2.405224115171443

Epoch: 5| Step: 3
Training loss: 0.10318041454113049
Validation loss: 2.43123397883028

Epoch: 5| Step: 4
Training loss: 0.19182373759991447
Validation loss: 2.3997238668154877

Epoch: 5| Step: 5
Training loss: 0.14977287392343341
Validation loss: 2.418915192298399

Epoch: 5| Step: 6
Training loss: 0.08560931602900006
Validation loss: 2.4044470929343134

Epoch: 5| Step: 7
Training loss: 0.21571862945321174
Validation loss: 2.3693283489972794

Epoch: 5| Step: 8
Training loss: 0.1343240136625242
Validation loss: 2.3439417628659194

Epoch: 5| Step: 9
Training loss: 0.07650369117751384
Validation loss: 2.309707656318586

Epoch: 5| Step: 10
Training loss: 0.2490494434016751
Validation loss: 2.3400316369942074

Epoch: 534| Step: 0
Training loss: 0.09412305834212605
Validation loss: 2.344536504004145

Epoch: 5| Step: 1
Training loss: 0.13917618374799914
Validation loss: 2.3368532264837194

Epoch: 5| Step: 2
Training loss: 0.12616089339046396
Validation loss: 2.3524117127958384

Epoch: 5| Step: 3
Training loss: 0.13073144894263025
Validation loss: 2.3858609043578016

Epoch: 5| Step: 4
Training loss: 0.23618812985877558
Validation loss: 2.381051561198693

Epoch: 5| Step: 5
Training loss: 0.22780740656345758
Validation loss: 2.427267624679443

Epoch: 5| Step: 6
Training loss: 0.2006083623576951
Validation loss: 2.3958157945787257

Epoch: 5| Step: 7
Training loss: 0.17974912581808195
Validation loss: 2.3507033374912396

Epoch: 5| Step: 8
Training loss: 0.15108315676268358
Validation loss: 2.3444037747266875

Epoch: 5| Step: 9
Training loss: 0.07047032485077594
Validation loss: 2.308609774129834

Epoch: 5| Step: 10
Training loss: 0.11566274436063029
Validation loss: 2.314665303063141

Epoch: 535| Step: 0
Training loss: 0.1743873003241223
Validation loss: 2.2917633938628708

Epoch: 5| Step: 1
Training loss: 0.2098981630386919
Validation loss: 2.3483131571667686

Epoch: 5| Step: 2
Training loss: 0.14626408861639262
Validation loss: 2.3998532192233286

Epoch: 5| Step: 3
Training loss: 0.0569927128649284
Validation loss: 2.3978730491804487

Epoch: 5| Step: 4
Training loss: 0.13101528615799674
Validation loss: 2.4016808954040436

Epoch: 5| Step: 5
Training loss: 0.21120532129072417
Validation loss: 2.420873432089602

Epoch: 5| Step: 6
Training loss: 0.0793559053171004
Validation loss: 2.442260529721689

Epoch: 5| Step: 7
Training loss: 0.1124759860370095
Validation loss: 2.415976554883706

Epoch: 5| Step: 8
Training loss: 0.0862125146909112
Validation loss: 2.38904388149421

Epoch: 5| Step: 9
Training loss: 0.14269319228323585
Validation loss: 2.3732996446913033

Epoch: 5| Step: 10
Training loss: 0.23879208292486914
Validation loss: 2.3601347681897717

Epoch: 536| Step: 0
Training loss: 0.22430615897847103
Validation loss: 2.343133560111766

Epoch: 5| Step: 1
Training loss: 0.2208808419718492
Validation loss: 2.327010942053737

Epoch: 5| Step: 2
Training loss: 0.195781849542843
Validation loss: 2.3438782911840614

Epoch: 5| Step: 3
Training loss: 0.14556194425004257
Validation loss: 2.3660274589868213

Epoch: 5| Step: 4
Training loss: 0.1017913166469662
Validation loss: 2.3556049674659887

Epoch: 5| Step: 5
Training loss: 0.07526100991960138
Validation loss: 2.374338689149821

Epoch: 5| Step: 6
Training loss: 0.1490962631746967
Validation loss: 2.388934823799911

Epoch: 5| Step: 7
Training loss: 0.08632106687423467
Validation loss: 2.3868814382760104

Epoch: 5| Step: 8
Training loss: 0.15815307272813897
Validation loss: 2.3772713260498883

Epoch: 5| Step: 9
Training loss: 0.12142048870086108
Validation loss: 2.381753835812113

Epoch: 5| Step: 10
Training loss: 0.10828037104036582
Validation loss: 2.386796484427281

Epoch: 537| Step: 0
Training loss: 0.069875484933177
Validation loss: 2.344592549364773

Epoch: 5| Step: 1
Training loss: 0.13167299161378476
Validation loss: 2.3568108156808396

Epoch: 5| Step: 2
Training loss: 0.07127819892987841
Validation loss: 2.329161232850187

Epoch: 5| Step: 3
Training loss: 0.13791584049099367
Validation loss: 2.3208802402403097

Epoch: 5| Step: 4
Training loss: 0.2767985182758319
Validation loss: 2.3280503252156146

Epoch: 5| Step: 5
Training loss: 0.19011044274164562
Validation loss: 2.32356523726115

Epoch: 5| Step: 6
Training loss: 0.07774395104950454
Validation loss: 2.3480689962708055

Epoch: 5| Step: 7
Training loss: 0.1607101793275473
Validation loss: 2.3276903322466707

Epoch: 5| Step: 8
Training loss: 0.1733073298088584
Validation loss: 2.353705587997956

Epoch: 5| Step: 9
Training loss: 0.08757541878183182
Validation loss: 2.442525852152329

Epoch: 5| Step: 10
Training loss: 0.114594854964075
Validation loss: 2.4318881267390537

Epoch: 538| Step: 0
Training loss: 0.155649832598023
Validation loss: 2.4605397038507273

Epoch: 5| Step: 1
Training loss: 0.09592828247354888
Validation loss: 2.419254007049932

Epoch: 5| Step: 2
Training loss: 0.24338991331755705
Validation loss: 2.3993170201389806

Epoch: 5| Step: 3
Training loss: 0.10234945113922886
Validation loss: 2.398254219179868

Epoch: 5| Step: 4
Training loss: 0.15520313758815482
Validation loss: 2.379557499956322

Epoch: 5| Step: 5
Training loss: 0.19821510693724884
Validation loss: 2.368593133051668

Epoch: 5| Step: 6
Training loss: 0.10430185863289453
Validation loss: 2.3360004120943794

Epoch: 5| Step: 7
Training loss: 0.15465568518752262
Validation loss: 2.3490616111969396

Epoch: 5| Step: 8
Training loss: 0.2008409185101633
Validation loss: 2.319698941642602

Epoch: 5| Step: 9
Training loss: 0.12059941450359628
Validation loss: 2.3646088300136876

Epoch: 5| Step: 10
Training loss: 0.06538279475680091
Validation loss: 2.340802424709868

Epoch: 539| Step: 0
Training loss: 0.1568059210835906
Validation loss: 2.4141361926086047

Epoch: 5| Step: 1
Training loss: 0.19567253307697016
Validation loss: 2.386714240807807

Epoch: 5| Step: 2
Training loss: 0.09120592168866395
Validation loss: 2.364989550237744

Epoch: 5| Step: 3
Training loss: 0.15082542928469872
Validation loss: 2.3968761733676702

Epoch: 5| Step: 4
Training loss: 0.11234028708090825
Validation loss: 2.3435467670884695

Epoch: 5| Step: 5
Training loss: 0.11576155720933276
Validation loss: 2.324743252331357

Epoch: 5| Step: 6
Training loss: 0.19327388183500732
Validation loss: 2.3221565465970158

Epoch: 5| Step: 7
Training loss: 0.09119845188462378
Validation loss: 2.259072848828725

Epoch: 5| Step: 8
Training loss: 0.1513806552433032
Validation loss: 2.2926404239662497

Epoch: 5| Step: 9
Training loss: 0.20463654342487445
Validation loss: 2.287459608591411

Epoch: 5| Step: 10
Training loss: 0.18326369506394766
Validation loss: 2.30325375234337

Epoch: 540| Step: 0
Training loss: 0.21049722004592888
Validation loss: 2.3070455588548024

Epoch: 5| Step: 1
Training loss: 0.08421536494991366
Validation loss: 2.3143265806887725

Epoch: 5| Step: 2
Training loss: 0.11701671155434526
Validation loss: 2.3459940503296077

Epoch: 5| Step: 3
Training loss: 0.14204079479463944
Validation loss: 2.328478252101893

Epoch: 5| Step: 4
Training loss: 0.1444446974710343
Validation loss: 2.350839126608333

Epoch: 5| Step: 5
Training loss: 0.10636711310427134
Validation loss: 2.3675775159618095

Epoch: 5| Step: 6
Training loss: 0.15625632988505933
Validation loss: 2.349666778845486

Epoch: 5| Step: 7
Training loss: 0.1313743918624399
Validation loss: 2.3458994054744973

Epoch: 5| Step: 8
Training loss: 0.20874584703540253
Validation loss: 2.308117730423483

Epoch: 5| Step: 9
Training loss: 0.1914897366834933
Validation loss: 2.311967364350727

Epoch: 5| Step: 10
Training loss: 0.16489685861839493
Validation loss: 2.318151212168546

Epoch: 541| Step: 0
Training loss: 0.10960982862991789
Validation loss: 2.3663819247769844

Epoch: 5| Step: 1
Training loss: 0.12964326954535443
Validation loss: 2.3677554466396806

Epoch: 5| Step: 2
Training loss: 0.19622965051148752
Validation loss: 2.3563016234156438

Epoch: 5| Step: 3
Training loss: 0.08405597263027056
Validation loss: 2.3682282104532115

Epoch: 5| Step: 4
Training loss: 0.12357525683528164
Validation loss: 2.3427392717670745

Epoch: 5| Step: 5
Training loss: 0.10373699611582123
Validation loss: 2.344003058003821

Epoch: 5| Step: 6
Training loss: 0.2284993059901126
Validation loss: 2.3715923389441187

Epoch: 5| Step: 7
Training loss: 0.19403100171213827
Validation loss: 2.400072518572501

Epoch: 5| Step: 8
Training loss: 0.11266593880860311
Validation loss: 2.434805797530841

Epoch: 5| Step: 9
Training loss: 0.1688982672044455
Validation loss: 2.4205216505041522

Epoch: 5| Step: 10
Training loss: 0.15937363329469684
Validation loss: 2.4310093145475293

Epoch: 542| Step: 0
Training loss: 0.11724828891837512
Validation loss: 2.389680854403859

Epoch: 5| Step: 1
Training loss: 0.20211591781507002
Validation loss: 2.3923697204433343

Epoch: 5| Step: 2
Training loss: 0.1331758297784275
Validation loss: 2.3507674837060195

Epoch: 5| Step: 3
Training loss: 0.0839679696449999
Validation loss: 2.3561971361959464

Epoch: 5| Step: 4
Training loss: 0.15275245032709825
Validation loss: 2.326842396374782

Epoch: 5| Step: 5
Training loss: 0.12248127994989565
Validation loss: 2.3437200138265744

Epoch: 5| Step: 6
Training loss: 0.1499639129939678
Validation loss: 2.3373366182048896

Epoch: 5| Step: 7
Training loss: 0.0970908870422261
Validation loss: 2.3510564465952593

Epoch: 5| Step: 8
Training loss: 0.11074424183334414
Validation loss: 2.3940128093791806

Epoch: 5| Step: 9
Training loss: 0.24526350813838743
Validation loss: 2.4598575626938333

Epoch: 5| Step: 10
Training loss: 0.146667893211111
Validation loss: 2.491699956965861

Epoch: 543| Step: 0
Training loss: 0.19999630969338444
Validation loss: 2.537671542263137

Epoch: 5| Step: 1
Training loss: 0.1817635766104705
Validation loss: 2.5668539169778697

Epoch: 5| Step: 2
Training loss: 0.19648578142758652
Validation loss: 2.5073648791287324

Epoch: 5| Step: 3
Training loss: 0.11873468046127728
Validation loss: 2.4383002735199413

Epoch: 5| Step: 4
Training loss: 0.17934414982090605
Validation loss: 2.347854461473363

Epoch: 5| Step: 5
Training loss: 0.24503464087752685
Validation loss: 2.3080961742925665

Epoch: 5| Step: 6
Training loss: 0.15192446720376057
Validation loss: 2.268197992582314

Epoch: 5| Step: 7
Training loss: 0.19875299012136127
Validation loss: 2.2914287943361185

Epoch: 5| Step: 8
Training loss: 0.20516851340580142
Validation loss: 2.290518910291302

Epoch: 5| Step: 9
Training loss: 0.11237806328055533
Validation loss: 2.3707481319298944

Epoch: 5| Step: 10
Training loss: 0.23462544411915454
Validation loss: 2.399759556534066

Epoch: 544| Step: 0
Training loss: 0.11557913382779564
Validation loss: 2.4504952899458172

Epoch: 5| Step: 1
Training loss: 0.227935560162226
Validation loss: 2.4700690743876943

Epoch: 5| Step: 2
Training loss: 0.20320548700399357
Validation loss: 2.4314798012568137

Epoch: 5| Step: 3
Training loss: 0.1669241225525066
Validation loss: 2.424379905932566

Epoch: 5| Step: 4
Training loss: 0.20158909614807702
Validation loss: 2.3405955612631626

Epoch: 5| Step: 5
Training loss: 0.20440058728836366
Validation loss: 2.3418318426774634

Epoch: 5| Step: 6
Training loss: 0.14981341131440026
Validation loss: 2.321983266488657

Epoch: 5| Step: 7
Training loss: 0.23664764998377572
Validation loss: 2.2982561720377723

Epoch: 5| Step: 8
Training loss: 0.1762879433354414
Validation loss: 2.310943801038059

Epoch: 5| Step: 9
Training loss: 0.1944942117383818
Validation loss: 2.3817237339493618

Epoch: 5| Step: 10
Training loss: 0.1627299655402985
Validation loss: 2.4313024793216833

Epoch: 545| Step: 0
Training loss: 0.11545266472996664
Validation loss: 2.495569821990794

Epoch: 5| Step: 1
Training loss: 0.24691456194059014
Validation loss: 2.5420839265412014

Epoch: 5| Step: 2
Training loss: 0.17693031702987866
Validation loss: 2.513598373300591

Epoch: 5| Step: 3
Training loss: 0.21906934996818217
Validation loss: 2.4580544497265207

Epoch: 5| Step: 4
Training loss: 0.22153785974772214
Validation loss: 2.411092676547449

Epoch: 5| Step: 5
Training loss: 0.11212720114510027
Validation loss: 2.3357077832114155

Epoch: 5| Step: 6
Training loss: 0.23604701797168917
Validation loss: 2.30027906662955

Epoch: 5| Step: 7
Training loss: 0.15383138941821786
Validation loss: 2.2701896268989707

Epoch: 5| Step: 8
Training loss: 0.13515075992172298
Validation loss: 2.261930507040298

Epoch: 5| Step: 9
Training loss: 0.15015238928619878
Validation loss: 2.287426052358554

Epoch: 5| Step: 10
Training loss: 0.14792820494830328
Validation loss: 2.293919749099547

Epoch: 546| Step: 0
Training loss: 0.10823103720297163
Validation loss: 2.3476570335098725

Epoch: 5| Step: 1
Training loss: 0.15071995704945823
Validation loss: 2.3951678242999463

Epoch: 5| Step: 2
Training loss: 0.15475152429490915
Validation loss: 2.462710114663861

Epoch: 5| Step: 3
Training loss: 0.22414042404022197
Validation loss: 2.4515172715268694

Epoch: 5| Step: 4
Training loss: 0.24579194651303934
Validation loss: 2.435270071407647

Epoch: 5| Step: 5
Training loss: 0.1251131305757392
Validation loss: 2.3964548197477424

Epoch: 5| Step: 6
Training loss: 0.0905361755573107
Validation loss: 2.330837189827015

Epoch: 5| Step: 7
Training loss: 0.15041379007057132
Validation loss: 2.32907597274999

Epoch: 5| Step: 8
Training loss: 0.18868712290561596
Validation loss: 2.3294914168533767

Epoch: 5| Step: 9
Training loss: 0.11031422363128783
Validation loss: 2.3185829170726806

Epoch: 5| Step: 10
Training loss: 0.16558370502764094
Validation loss: 2.2920821908540607

Epoch: 547| Step: 0
Training loss: 0.19634397886713104
Validation loss: 2.3138785971473914

Epoch: 5| Step: 1
Training loss: 0.21893280769457638
Validation loss: 2.304893108225332

Epoch: 5| Step: 2
Training loss: 0.10361557759320905
Validation loss: 2.3450896429044517

Epoch: 5| Step: 3
Training loss: 0.1154308260943805
Validation loss: 2.4061003788836057

Epoch: 5| Step: 4
Training loss: 0.15921580016161668
Validation loss: 2.4160414616508152

Epoch: 5| Step: 5
Training loss: 0.11849902101456378
Validation loss: 2.396977768076086

Epoch: 5| Step: 6
Training loss: 0.09698895397165766
Validation loss: 2.386013302628143

Epoch: 5| Step: 7
Training loss: 0.22600319490294912
Validation loss: 2.372820277611898

Epoch: 5| Step: 8
Training loss: 0.08851892749655726
Validation loss: 2.3494656622960135

Epoch: 5| Step: 9
Training loss: 0.20514331871296293
Validation loss: 2.3606715853881903

Epoch: 5| Step: 10
Training loss: 0.20665098752033426
Validation loss: 2.3116936989390235

Epoch: 548| Step: 0
Training loss: 0.09688566883620879
Validation loss: 2.292326721566418

Epoch: 5| Step: 1
Training loss: 0.2098755241362506
Validation loss: 2.330619662231904

Epoch: 5| Step: 2
Training loss: 0.12829733574640145
Validation loss: 2.3046026159651434

Epoch: 5| Step: 3
Training loss: 0.08952880681284361
Validation loss: 2.348293944901939

Epoch: 5| Step: 4
Training loss: 0.2378596813453276
Validation loss: 2.36154372852206

Epoch: 5| Step: 5
Training loss: 0.16296487300719564
Validation loss: 2.3808825653068495

Epoch: 5| Step: 6
Training loss: 0.08538333532763359
Validation loss: 2.3914555380291778

Epoch: 5| Step: 7
Training loss: 0.21831420506309235
Validation loss: 2.455159772215115

Epoch: 5| Step: 8
Training loss: 0.16606856231406072
Validation loss: 2.4540898730053713

Epoch: 5| Step: 9
Training loss: 0.07662291746086543
Validation loss: 2.4824179026487676

Epoch: 5| Step: 10
Training loss: 0.06543113578787695
Validation loss: 2.4462290811294807

Epoch: 549| Step: 0
Training loss: 0.09748274171289169
Validation loss: 2.4403170484901398

Epoch: 5| Step: 1
Training loss: 0.09495485462837447
Validation loss: 2.428144707093448

Epoch: 5| Step: 2
Training loss: 0.20365847628015954
Validation loss: 2.425136255373879

Epoch: 5| Step: 3
Training loss: 0.09637245818662751
Validation loss: 2.4034452026098183

Epoch: 5| Step: 4
Training loss: 0.12221173296140778
Validation loss: 2.380186506856885

Epoch: 5| Step: 5
Training loss: 0.20352015206542534
Validation loss: 2.3551149428568405

Epoch: 5| Step: 6
Training loss: 0.1064142435561157
Validation loss: 2.3454540639901382

Epoch: 5| Step: 7
Training loss: 0.12226254395329203
Validation loss: 2.338713079032079

Epoch: 5| Step: 8
Training loss: 0.1755419161460758
Validation loss: 2.3000852590437293

Epoch: 5| Step: 9
Training loss: 0.15510383075816936
Validation loss: 2.3236452984424916

Epoch: 5| Step: 10
Training loss: 0.19637558581618764
Validation loss: 2.361208659462641

Epoch: 550| Step: 0
Training loss: 0.07303338487260906
Validation loss: 2.3736248709268626

Epoch: 5| Step: 1
Training loss: 0.15009597300849573
Validation loss: 2.4151926336612326

Epoch: 5| Step: 2
Training loss: 0.15149120664611
Validation loss: 2.4425875901124576

Epoch: 5| Step: 3
Training loss: 0.18613001890377714
Validation loss: 2.4194339672602534

Epoch: 5| Step: 4
Training loss: 0.05816708031095569
Validation loss: 2.4280480596719216

Epoch: 5| Step: 5
Training loss: 0.09568074509662311
Validation loss: 2.4167774911942344

Epoch: 5| Step: 6
Training loss: 0.19109469963268214
Validation loss: 2.418133103681266

Epoch: 5| Step: 7
Training loss: 0.2038824283087403
Validation loss: 2.404022112329599

Epoch: 5| Step: 8
Training loss: 0.16105232540510728
Validation loss: 2.3936796073209687

Epoch: 5| Step: 9
Training loss: 0.09032983003975827
Validation loss: 2.376077100099689

Epoch: 5| Step: 10
Training loss: 0.22463929350246692
Validation loss: 2.3788471495783163

Epoch: 551| Step: 0
Training loss: 0.09540830178933049
Validation loss: 2.375606634257749

Epoch: 5| Step: 1
Training loss: 0.2181915409333509
Validation loss: 2.3653596979810834

Epoch: 5| Step: 2
Training loss: 0.1026350298886858
Validation loss: 2.358182009370701

Epoch: 5| Step: 3
Training loss: 0.15281504698153933
Validation loss: 2.3539079318320613

Epoch: 5| Step: 4
Training loss: 0.15764309813137778
Validation loss: 2.3811012361985733

Epoch: 5| Step: 5
Training loss: 0.08822389043147819
Validation loss: 2.390040651759066

Epoch: 5| Step: 6
Training loss: 0.1908813304819391
Validation loss: 2.4162540976479936

Epoch: 5| Step: 7
Training loss: 0.10499945180613603
Validation loss: 2.4403617441806826

Epoch: 5| Step: 8
Training loss: 0.2420729550852509
Validation loss: 2.4302805499374758

Epoch: 5| Step: 9
Training loss: 0.14097342110566707
Validation loss: 2.3965501316682003

Epoch: 5| Step: 10
Training loss: 0.08202561858692979
Validation loss: 2.3837761307431924

Epoch: 552| Step: 0
Training loss: 0.09810103216359806
Validation loss: 2.3318153386244083

Epoch: 5| Step: 1
Training loss: 0.11286037049560188
Validation loss: 2.295312801831755

Epoch: 5| Step: 2
Training loss: 0.10358070630885108
Validation loss: 2.3066354646830196

Epoch: 5| Step: 3
Training loss: 0.13171102469473236
Validation loss: 2.275384788782088

Epoch: 5| Step: 4
Training loss: 0.21509945131510774
Validation loss: 2.3125697399510954

Epoch: 5| Step: 5
Training loss: 0.14493627116836746
Validation loss: 2.319201197805226

Epoch: 5| Step: 6
Training loss: 0.10512269166919322
Validation loss: 2.3708343772151306

Epoch: 5| Step: 7
Training loss: 0.0783614811466855
Validation loss: 2.358844070659853

Epoch: 5| Step: 8
Training loss: 0.17896475772258186
Validation loss: 2.4065057538427626

Epoch: 5| Step: 9
Training loss: 0.1398023011141671
Validation loss: 2.4284708219797286

Epoch: 5| Step: 10
Training loss: 0.24721519835872813
Validation loss: 2.427629072433196

Epoch: 553| Step: 0
Training loss: 0.09648622557375035
Validation loss: 2.405980604753263

Epoch: 5| Step: 1
Training loss: 0.19627567264568926
Validation loss: 2.3653624736603263

Epoch: 5| Step: 2
Training loss: 0.13827762841476873
Validation loss: 2.3232098532383985

Epoch: 5| Step: 3
Training loss: 0.10881916653497144
Validation loss: 2.302976398764017

Epoch: 5| Step: 4
Training loss: 0.2536971918835928
Validation loss: 2.3006156851927337

Epoch: 5| Step: 5
Training loss: 0.13547800276681282
Validation loss: 2.315661811134697

Epoch: 5| Step: 6
Training loss: 0.10988607382113023
Validation loss: 2.3578616485825954

Epoch: 5| Step: 7
Training loss: 0.11228251445646463
Validation loss: 2.383480195398993

Epoch: 5| Step: 8
Training loss: 0.10563778136163639
Validation loss: 2.4054795768326898

Epoch: 5| Step: 9
Training loss: 0.13047618416489853
Validation loss: 2.4218868026419345

Epoch: 5| Step: 10
Training loss: 0.20024416257741418
Validation loss: 2.444531231500494

Epoch: 554| Step: 0
Training loss: 0.13872745904312153
Validation loss: 2.442865405267182

Epoch: 5| Step: 1
Training loss: 0.26938272613367353
Validation loss: 2.4295132724945843

Epoch: 5| Step: 2
Training loss: 0.09019187157412703
Validation loss: 2.425735156409819

Epoch: 5| Step: 3
Training loss: 0.12052341326194475
Validation loss: 2.4215504079797974

Epoch: 5| Step: 4
Training loss: 0.08235214682805009
Validation loss: 2.459867322790225

Epoch: 5| Step: 5
Training loss: 0.19296609011836213
Validation loss: 2.4207753485132835

Epoch: 5| Step: 6
Training loss: 0.11629589565602262
Validation loss: 2.4564465943380838

Epoch: 5| Step: 7
Training loss: 0.1285699155743071
Validation loss: 2.411848563743182

Epoch: 5| Step: 8
Training loss: 0.23479067181667265
Validation loss: 2.3927108417774825

Epoch: 5| Step: 9
Training loss: 0.09633877401435104
Validation loss: 2.427099834584798

Epoch: 5| Step: 10
Training loss: 0.1329955424448243
Validation loss: 2.436997127484963

Epoch: 555| Step: 0
Training loss: 0.12182103453910066
Validation loss: 2.433715546004351

Epoch: 5| Step: 1
Training loss: 0.11333753568674605
Validation loss: 2.453235632870197

Epoch: 5| Step: 2
Training loss: 0.15039377704636447
Validation loss: 2.4201221703141744

Epoch: 5| Step: 3
Training loss: 0.07601429767077088
Validation loss: 2.402491998054236

Epoch: 5| Step: 4
Training loss: 0.10577463897094838
Validation loss: 2.3670322775202384

Epoch: 5| Step: 5
Training loss: 0.11813912246691076
Validation loss: 2.3521100536032606

Epoch: 5| Step: 6
Training loss: 0.24710066989565116
Validation loss: 2.3461195520339313

Epoch: 5| Step: 7
Training loss: 0.1498787019457746
Validation loss: 2.33862421914281

Epoch: 5| Step: 8
Training loss: 0.2230486924853992
Validation loss: 2.311475279527797

Epoch: 5| Step: 9
Training loss: 0.08729825668204261
Validation loss: 2.3680208507892484

Epoch: 5| Step: 10
Training loss: 0.10836576708344767
Validation loss: 2.3612403398344624

Epoch: 556| Step: 0
Training loss: 0.10938508123531604
Validation loss: 2.3414738913775834

Epoch: 5| Step: 1
Training loss: 0.11785014676718945
Validation loss: 2.39980380579207

Epoch: 5| Step: 2
Training loss: 0.13480839534359262
Validation loss: 2.4073821740221155

Epoch: 5| Step: 3
Training loss: 0.20320599115059726
Validation loss: 2.3803382280351055

Epoch: 5| Step: 4
Training loss: 0.17524718640418369
Validation loss: 2.3837701044312944

Epoch: 5| Step: 5
Training loss: 0.14110545364370086
Validation loss: 2.3700386485703357

Epoch: 5| Step: 6
Training loss: 0.17910466831056118
Validation loss: 2.362268867087648

Epoch: 5| Step: 7
Training loss: 0.08063474704353679
Validation loss: 2.3756542357148556

Epoch: 5| Step: 8
Training loss: 0.10282930441172616
Validation loss: 2.39037844883625

Epoch: 5| Step: 9
Training loss: 0.13331533359560033
Validation loss: 2.366821973448806

Epoch: 5| Step: 10
Training loss: 0.12677228224915518
Validation loss: 2.373152616140107

Epoch: 557| Step: 0
Training loss: 0.19749047900742475
Validation loss: 2.3706552047533154

Epoch: 5| Step: 1
Training loss: 0.14080421630885517
Validation loss: 2.3991600119588266

Epoch: 5| Step: 2
Training loss: 0.1337800893071594
Validation loss: 2.4023596882385214

Epoch: 5| Step: 3
Training loss: 0.1923213705714121
Validation loss: 2.387564471400375

Epoch: 5| Step: 4
Training loss: 0.12781642675779967
Validation loss: 2.327558187619593

Epoch: 5| Step: 5
Training loss: 0.15722953011691593
Validation loss: 2.3033977656079005

Epoch: 5| Step: 6
Training loss: 0.07872018002562356
Validation loss: 2.306056639577397

Epoch: 5| Step: 7
Training loss: 0.14851122832073696
Validation loss: 2.3033981451347882

Epoch: 5| Step: 8
Training loss: 0.19772266094004953
Validation loss: 2.2898561904166304

Epoch: 5| Step: 9
Training loss: 0.10997214539698903
Validation loss: 2.310531643760504

Epoch: 5| Step: 10
Training loss: 0.1016879865386193
Validation loss: 2.3382556308336335

Epoch: 558| Step: 0
Training loss: 0.1741459009938071
Validation loss: 2.370949471652828

Epoch: 5| Step: 1
Training loss: 0.10640115872076869
Validation loss: 2.3776681988421657

Epoch: 5| Step: 2
Training loss: 0.21527502814881808
Validation loss: 2.367034780473169

Epoch: 5| Step: 3
Training loss: 0.18602820756405405
Validation loss: 2.3886568601938274

Epoch: 5| Step: 4
Training loss: 0.11395357659743538
Validation loss: 2.3666228948349897

Epoch: 5| Step: 5
Training loss: 0.12444519809159889
Validation loss: 2.362340442256473

Epoch: 5| Step: 6
Training loss: 0.1358219433857446
Validation loss: 2.3291810360418173

Epoch: 5| Step: 7
Training loss: 0.14823712452119508
Validation loss: 2.3593759377150425

Epoch: 5| Step: 8
Training loss: 0.13692455469217163
Validation loss: 2.3810793890163477

Epoch: 5| Step: 9
Training loss: 0.08597036567706866
Validation loss: 2.339455587370355

Epoch: 5| Step: 10
Training loss: 0.08497742514835711
Validation loss: 2.3914234860826515

Epoch: 559| Step: 0
Training loss: 0.07617636508423516
Validation loss: 2.399398267633726

Epoch: 5| Step: 1
Training loss: 0.11557717977583121
Validation loss: 2.3985199401888244

Epoch: 5| Step: 2
Training loss: 0.12035158980708817
Validation loss: 2.42736259486482

Epoch: 5| Step: 3
Training loss: 0.17302155083349266
Validation loss: 2.400061660255667

Epoch: 5| Step: 4
Training loss: 0.10285226128409986
Validation loss: 2.4012436957382066

Epoch: 5| Step: 5
Training loss: 0.1686731362130037
Validation loss: 2.3702132545877714

Epoch: 5| Step: 6
Training loss: 0.17646358829425354
Validation loss: 2.3766829783503165

Epoch: 5| Step: 7
Training loss: 0.18881138526539454
Validation loss: 2.3263929007253847

Epoch: 5| Step: 8
Training loss: 0.11874177882321653
Validation loss: 2.3174523048436817

Epoch: 5| Step: 9
Training loss: 0.19861440057483185
Validation loss: 2.2835232899603994

Epoch: 5| Step: 10
Training loss: 0.08360981586299433
Validation loss: 2.269640394044698

Epoch: 560| Step: 0
Training loss: 0.16246915441977444
Validation loss: 2.2547005560570144

Epoch: 5| Step: 1
Training loss: 0.20306751464823034
Validation loss: 2.2763546968014636

Epoch: 5| Step: 2
Training loss: 0.11785644497112592
Validation loss: 2.2727372030002084

Epoch: 5| Step: 3
Training loss: 0.12995586635325843
Validation loss: 2.3316629075298274

Epoch: 5| Step: 4
Training loss: 0.1816698276466421
Validation loss: 2.365144907321953

Epoch: 5| Step: 5
Training loss: 0.1731378641151977
Validation loss: 2.449327364441465

Epoch: 5| Step: 6
Training loss: 0.08256273154598777
Validation loss: 2.4359456636863146

Epoch: 5| Step: 7
Training loss: 0.11395528061858821
Validation loss: 2.4635339715268536

Epoch: 5| Step: 8
Training loss: 0.1458362227108233
Validation loss: 2.45506081699954

Epoch: 5| Step: 9
Training loss: 0.18667682113091216
Validation loss: 2.4199470059800166

Epoch: 5| Step: 10
Training loss: 0.08745338505298525
Validation loss: 2.3474177287021702

Epoch: 561| Step: 0
Training loss: 0.10783457374580971
Validation loss: 2.3583685517023114

Epoch: 5| Step: 1
Training loss: 0.20657131099809464
Validation loss: 2.3063163728431375

Epoch: 5| Step: 2
Training loss: 0.13569331489993283
Validation loss: 2.3103247341657775

Epoch: 5| Step: 3
Training loss: 0.14541291976567422
Validation loss: 2.326596071242435

Epoch: 5| Step: 4
Training loss: 0.10567014944626921
Validation loss: 2.349671220023885

Epoch: 5| Step: 5
Training loss: 0.11265890402716469
Validation loss: 2.3675562949230042

Epoch: 5| Step: 6
Training loss: 0.11039523720470837
Validation loss: 2.396661942744742

Epoch: 5| Step: 7
Training loss: 0.18422737758192964
Validation loss: 2.4041321363315458

Epoch: 5| Step: 8
Training loss: 0.07063322959272966
Validation loss: 2.422854147458496

Epoch: 5| Step: 9
Training loss: 0.12263782189667853
Validation loss: 2.4239525412322016

Epoch: 5| Step: 10
Training loss: 0.18398570770947267
Validation loss: 2.393341741663947

Epoch: 562| Step: 0
Training loss: 0.1254613082930622
Validation loss: 2.392123186205753

Epoch: 5| Step: 1
Training loss: 0.11050255328406709
Validation loss: 2.390311411800001

Epoch: 5| Step: 2
Training loss: 0.19662146629934046
Validation loss: 2.3820891305922007

Epoch: 5| Step: 3
Training loss: 0.108155179504513
Validation loss: 2.353279391594358

Epoch: 5| Step: 4
Training loss: 0.19829087058942424
Validation loss: 2.3286230613427032

Epoch: 5| Step: 5
Training loss: 0.09035465369603805
Validation loss: 2.3181521555000275

Epoch: 5| Step: 6
Training loss: 0.10001225433665102
Validation loss: 2.320598208635062

Epoch: 5| Step: 7
Training loss: 0.09906286022951111
Validation loss: 2.340676437481514

Epoch: 5| Step: 8
Training loss: 0.11648360888550933
Validation loss: 2.325251086452736

Epoch: 5| Step: 9
Training loss: 0.11883319995634335
Validation loss: 2.294062440728991

Epoch: 5| Step: 10
Training loss: 0.2057333153093103
Validation loss: 2.343061473712438

Epoch: 563| Step: 0
Training loss: 0.08130695256600375
Validation loss: 2.331234942800551

Epoch: 5| Step: 1
Training loss: 0.10068234203311643
Validation loss: 2.328935707615638

Epoch: 5| Step: 2
Training loss: 0.0789956337236728
Validation loss: 2.306922119860314

Epoch: 5| Step: 3
Training loss: 0.06794158787435231
Validation loss: 2.3028638718542105

Epoch: 5| Step: 4
Training loss: 0.09090998027546647
Validation loss: 2.380243470007176

Epoch: 5| Step: 5
Training loss: 0.09014372400605981
Validation loss: 2.3645115976500466

Epoch: 5| Step: 6
Training loss: 0.18100436353824317
Validation loss: 2.349062497370292

Epoch: 5| Step: 7
Training loss: 0.20836775713874875
Validation loss: 2.389165625477891

Epoch: 5| Step: 8
Training loss: 0.21514310788343943
Validation loss: 2.4032549426874232

Epoch: 5| Step: 9
Training loss: 0.08619009900392974
Validation loss: 2.38734176477321

Epoch: 5| Step: 10
Training loss: 0.1009734845015126
Validation loss: 2.3657647945623035

Epoch: 564| Step: 0
Training loss: 0.12198348199647711
Validation loss: 2.390160349435648

Epoch: 5| Step: 1
Training loss: 0.18338294811875133
Validation loss: 2.3410607740815093

Epoch: 5| Step: 2
Training loss: 0.11593283708146092
Validation loss: 2.3280299083942464

Epoch: 5| Step: 3
Training loss: 0.13335585242581927
Validation loss: 2.3420087300502157

Epoch: 5| Step: 4
Training loss: 0.12414973128944949
Validation loss: 2.344557124251441

Epoch: 5| Step: 5
Training loss: 0.14137953748302015
Validation loss: 2.3283421421418042

Epoch: 5| Step: 6
Training loss: 0.24056812301559588
Validation loss: 2.37123365554229

Epoch: 5| Step: 7
Training loss: 0.11904886104405608
Validation loss: 2.3607640292007814

Epoch: 5| Step: 8
Training loss: 0.10380848357947488
Validation loss: 2.3983342274509223

Epoch: 5| Step: 9
Training loss: 0.09026199925321673
Validation loss: 2.373106581156555

Epoch: 5| Step: 10
Training loss: 0.11957497840932396
Validation loss: 2.3964955174965086

Epoch: 565| Step: 0
Training loss: 0.11965496791412764
Validation loss: 2.376779567447538

Epoch: 5| Step: 1
Training loss: 0.10907333786763809
Validation loss: 2.395536696665288

Epoch: 5| Step: 2
Training loss: 0.2012064635531639
Validation loss: 2.35185296513216

Epoch: 5| Step: 3
Training loss: 0.10334778620540916
Validation loss: 2.3581368323358882

Epoch: 5| Step: 4
Training loss: 0.05810130529153122
Validation loss: 2.3501385546263345

Epoch: 5| Step: 5
Training loss: 0.0775447997077418
Validation loss: 2.317664992584094

Epoch: 5| Step: 6
Training loss: 0.10003772430090906
Validation loss: 2.3289680680554548

Epoch: 5| Step: 7
Training loss: 0.2560409309422161
Validation loss: 2.2861278425054374

Epoch: 5| Step: 8
Training loss: 0.11485174469141608
Validation loss: 2.340025397782458

Epoch: 5| Step: 9
Training loss: 0.14498188030959225
Validation loss: 2.3216624778002655

Epoch: 5| Step: 10
Training loss: 0.08514677747485018
Validation loss: 2.3929275993448296

Epoch: 566| Step: 0
Training loss: 0.11148527832039537
Validation loss: 2.408923928077383

Epoch: 5| Step: 1
Training loss: 0.15132691247480878
Validation loss: 2.425561558721675

Epoch: 5| Step: 2
Training loss: 0.09716941602386273
Validation loss: 2.4110173512525668

Epoch: 5| Step: 3
Training loss: 0.1781540202878003
Validation loss: 2.392632525363209

Epoch: 5| Step: 4
Training loss: 0.11010731191693078
Validation loss: 2.3499950979212643

Epoch: 5| Step: 5
Training loss: 0.098366618938801
Validation loss: 2.342955725292064

Epoch: 5| Step: 6
Training loss: 0.24568139451669052
Validation loss: 2.342388846723161

Epoch: 5| Step: 7
Training loss: 0.1442248085667065
Validation loss: 2.307547583947698

Epoch: 5| Step: 8
Training loss: 0.1075518385451012
Validation loss: 2.348641120241535

Epoch: 5| Step: 9
Training loss: 0.1476842566072281
Validation loss: 2.3743397184005834

Epoch: 5| Step: 10
Training loss: 0.08248131899945332
Validation loss: 2.3860090800546137

Epoch: 567| Step: 0
Training loss: 0.13057796623966197
Validation loss: 2.406515975334907

Epoch: 5| Step: 1
Training loss: 0.18249441293433824
Validation loss: 2.4255730348040156

Epoch: 5| Step: 2
Training loss: 0.12191459260242893
Validation loss: 2.4242573231233893

Epoch: 5| Step: 3
Training loss: 0.11947293526450231
Validation loss: 2.416764726406756

Epoch: 5| Step: 4
Training loss: 0.12964982812727008
Validation loss: 2.405509733647665

Epoch: 5| Step: 5
Training loss: 0.14839745910072974
Validation loss: 2.369002576745405

Epoch: 5| Step: 6
Training loss: 0.1008185271511863
Validation loss: 2.3683079887812672

Epoch: 5| Step: 7
Training loss: 0.15237951470204467
Validation loss: 2.3257159691270313

Epoch: 5| Step: 8
Training loss: 0.11063758949530018
Validation loss: 2.3346131498502745

Epoch: 5| Step: 9
Training loss: 0.207308331894742
Validation loss: 2.3329859286715644

Epoch: 5| Step: 10
Training loss: 0.11435740768131007
Validation loss: 2.3158868567301307

Epoch: 568| Step: 0
Training loss: 0.10337558306410821
Validation loss: 2.313710911978284

Epoch: 5| Step: 1
Training loss: 0.11724782027066841
Validation loss: 2.31162747809744

Epoch: 5| Step: 2
Training loss: 0.09005266757048959
Validation loss: 2.309856601240462

Epoch: 5| Step: 3
Training loss: 0.20536799154147076
Validation loss: 2.3084237363491478

Epoch: 5| Step: 4
Training loss: 0.09604644017844867
Validation loss: 2.319750093452188

Epoch: 5| Step: 5
Training loss: 0.08640057794361895
Validation loss: 2.3240120507424296

Epoch: 5| Step: 6
Training loss: 0.19840344790151643
Validation loss: 2.3671966577466006

Epoch: 5| Step: 7
Training loss: 0.16211959507909926
Validation loss: 2.3592920949553036

Epoch: 5| Step: 8
Training loss: 0.11121282546434288
Validation loss: 2.3613447032360657

Epoch: 5| Step: 9
Training loss: 0.10673571703065309
Validation loss: 2.3578417728662755

Epoch: 5| Step: 10
Training loss: 0.11431215901112785
Validation loss: 2.354548823920364

Epoch: 569| Step: 0
Training loss: 0.13315982142683322
Validation loss: 2.366893074079303

Epoch: 5| Step: 1
Training loss: 0.08489208336263265
Validation loss: 2.334743658780279

Epoch: 5| Step: 2
Training loss: 0.09946638015970485
Validation loss: 2.319750573633973

Epoch: 5| Step: 3
Training loss: 0.19028288244348157
Validation loss: 2.298542142329311

Epoch: 5| Step: 4
Training loss: 0.10465205521291221
Validation loss: 2.3599841564678017

Epoch: 5| Step: 5
Training loss: 0.13997908442374143
Validation loss: 2.354488097852712

Epoch: 5| Step: 6
Training loss: 0.12485505432445858
Validation loss: 2.3576955790939147

Epoch: 5| Step: 7
Training loss: 0.13054649469398974
Validation loss: 2.3721683052201947

Epoch: 5| Step: 8
Training loss: 0.11676496784367803
Validation loss: 2.378861026848312

Epoch: 5| Step: 9
Training loss: 0.07120199634920676
Validation loss: 2.353717475424906

Epoch: 5| Step: 10
Training loss: 0.2387284631651903
Validation loss: 2.3747904608992187

Epoch: 570| Step: 0
Training loss: 0.06406243719702642
Validation loss: 2.3769390866730773

Epoch: 5| Step: 1
Training loss: 0.07451948297927669
Validation loss: 2.3577828525508715

Epoch: 5| Step: 2
Training loss: 0.2053476379176246
Validation loss: 2.382459968728402

Epoch: 5| Step: 3
Training loss: 0.11439272259895544
Validation loss: 2.3917733938866097

Epoch: 5| Step: 4
Training loss: 0.17844962730216485
Validation loss: 2.4075954645892543

Epoch: 5| Step: 5
Training loss: 0.09048703272464766
Validation loss: 2.3848831402983386

Epoch: 5| Step: 6
Training loss: 0.17733132070938543
Validation loss: 2.3929231350641316

Epoch: 5| Step: 7
Training loss: 0.10309812636335633
Validation loss: 2.3842952317056754

Epoch: 5| Step: 8
Training loss: 0.11391131117059215
Validation loss: 2.368165987261578

Epoch: 5| Step: 9
Training loss: 0.1157715046471136
Validation loss: 2.3224972817626823

Epoch: 5| Step: 10
Training loss: 0.14050695312466266
Validation loss: 2.3244325049545242

Epoch: 571| Step: 0
Training loss: 0.1364584624918358
Validation loss: 2.3351626698180277

Epoch: 5| Step: 1
Training loss: 0.10146274160606857
Validation loss: 2.355853641704003

Epoch: 5| Step: 2
Training loss: 0.19324177720562444
Validation loss: 2.3779607074041107

Epoch: 5| Step: 3
Training loss: 0.0799736731533571
Validation loss: 2.405980953181021

Epoch: 5| Step: 4
Training loss: 0.11022188365273586
Validation loss: 2.4039468496891367

Epoch: 5| Step: 5
Training loss: 0.18031042387046434
Validation loss: 2.453166277598052

Epoch: 5| Step: 6
Training loss: 0.11536197548179827
Validation loss: 2.4360559465026888

Epoch: 5| Step: 7
Training loss: 0.1273277258005975
Validation loss: 2.4287943017786318

Epoch: 5| Step: 8
Training loss: 0.07640592063548082
Validation loss: 2.432474653879237

Epoch: 5| Step: 9
Training loss: 0.08387395619572213
Validation loss: 2.3919358937782276

Epoch: 5| Step: 10
Training loss: 0.21448549398087416
Validation loss: 2.360139525584946

Epoch: 572| Step: 0
Training loss: 0.11339496380554179
Validation loss: 2.351985612199867

Epoch: 5| Step: 1
Training loss: 0.13320534472140225
Validation loss: 2.3204209336991664

Epoch: 5| Step: 2
Training loss: 0.09671686883215494
Validation loss: 2.353533933024783

Epoch: 5| Step: 3
Training loss: 0.16553875931617482
Validation loss: 2.328267888883582

Epoch: 5| Step: 4
Training loss: 0.10641201618440388
Validation loss: 2.3352607495489774

Epoch: 5| Step: 5
Training loss: 0.16979773141018917
Validation loss: 2.3692660930219143

Epoch: 5| Step: 6
Training loss: 0.07724389677142587
Validation loss: 2.355842034114876

Epoch: 5| Step: 7
Training loss: 0.14432108264511725
Validation loss: 2.36586759738676

Epoch: 5| Step: 8
Training loss: 0.16167369574287205
Validation loss: 2.3858219050953777

Epoch: 5| Step: 9
Training loss: 0.10054394854812145
Validation loss: 2.340113783786022

Epoch: 5| Step: 10
Training loss: 0.16090499494118338
Validation loss: 2.3587840273976015

Epoch: 573| Step: 0
Training loss: 0.11660298964810753
Validation loss: 2.3697788322468094

Epoch: 5| Step: 1
Training loss: 0.1662776338047483
Validation loss: 2.380174580369698

Epoch: 5| Step: 2
Training loss: 0.09006109588694627
Validation loss: 2.4099734545766367

Epoch: 5| Step: 3
Training loss: 0.12966221166426226
Validation loss: 2.408298270024958

Epoch: 5| Step: 4
Training loss: 0.07120620144712068
Validation loss: 2.419621434580353

Epoch: 5| Step: 5
Training loss: 0.23571293735531346
Validation loss: 2.430758421167187

Epoch: 5| Step: 6
Training loss: 0.12911663082905525
Validation loss: 2.4360993780945814

Epoch: 5| Step: 7
Training loss: 0.11425279948657004
Validation loss: 2.396648348252895

Epoch: 5| Step: 8
Training loss: 0.15196004866489682
Validation loss: 2.41522885054987

Epoch: 5| Step: 9
Training loss: 0.08781193813639725
Validation loss: 2.3531315609934267

Epoch: 5| Step: 10
Training loss: 0.08374418521825379
Validation loss: 2.330092136489564

Epoch: 574| Step: 0
Training loss: 0.14564411768445945
Validation loss: 2.2958476085035535

Epoch: 5| Step: 1
Training loss: 0.1690645734092223
Validation loss: 2.3117887056545183

Epoch: 5| Step: 2
Training loss: 0.17977619055543545
Validation loss: 2.3242867629165933

Epoch: 5| Step: 3
Training loss: 0.10098375888762236
Validation loss: 2.3911680617729574

Epoch: 5| Step: 4
Training loss: 0.13003691515950083
Validation loss: 2.4070421232705286

Epoch: 5| Step: 5
Training loss: 0.13315703078325067
Validation loss: 2.4378198351243214

Epoch: 5| Step: 6
Training loss: 0.12002279480484776
Validation loss: 2.4475984492639893

Epoch: 5| Step: 7
Training loss: 0.11593027844905976
Validation loss: 2.4618226328961352

Epoch: 5| Step: 8
Training loss: 0.14605404905968836
Validation loss: 2.4918605525563398

Epoch: 5| Step: 9
Training loss: 0.14933342097599503
Validation loss: 2.4427588931821402

Epoch: 5| Step: 10
Training loss: 0.18425782812432648
Validation loss: 2.4036885929011738

Epoch: 575| Step: 0
Training loss: 0.10916612469226797
Validation loss: 2.4031764274383645

Epoch: 5| Step: 1
Training loss: 0.09411194590046833
Validation loss: 2.3328777625133847

Epoch: 5| Step: 2
Training loss: 0.1726991498736948
Validation loss: 2.3408760438139216

Epoch: 5| Step: 3
Training loss: 0.15793084626547585
Validation loss: 2.3533109744523095

Epoch: 5| Step: 4
Training loss: 0.2064970520059645
Validation loss: 2.347320475298453

Epoch: 5| Step: 5
Training loss: 0.08879319453662797
Validation loss: 2.3831397628168784

Epoch: 5| Step: 6
Training loss: 0.1386499857752401
Validation loss: 2.3990415118728916

Epoch: 5| Step: 7
Training loss: 0.0965104693288946
Validation loss: 2.4324811549936896

Epoch: 5| Step: 8
Training loss: 0.1309972435346371
Validation loss: 2.4328688375691785

Epoch: 5| Step: 9
Training loss: 0.10516710768047718
Validation loss: 2.443344383586888

Epoch: 5| Step: 10
Training loss: 0.20104535763239756
Validation loss: 2.40198594176674

Epoch: 576| Step: 0
Training loss: 0.09806121782056643
Validation loss: 2.3821641978441668

Epoch: 5| Step: 1
Training loss: 0.09563978200926422
Validation loss: 2.358015496034393

Epoch: 5| Step: 2
Training loss: 0.08708573916648701
Validation loss: 2.331878182730838

Epoch: 5| Step: 3
Training loss: 0.12795932077129113
Validation loss: 2.3551507828169784

Epoch: 5| Step: 4
Training loss: 0.12513793844691687
Validation loss: 2.363790018967991

Epoch: 5| Step: 5
Training loss: 0.17620958487131694
Validation loss: 2.3298419760901488

Epoch: 5| Step: 6
Training loss: 0.09074970289778088
Validation loss: 2.350664106658068

Epoch: 5| Step: 7
Training loss: 0.2416291491733914
Validation loss: 2.356633303150063

Epoch: 5| Step: 8
Training loss: 0.106752800193952
Validation loss: 2.357140534594277

Epoch: 5| Step: 9
Training loss: 0.06840130337561216
Validation loss: 2.387564566426999

Epoch: 5| Step: 10
Training loss: 0.14762424117005535
Validation loss: 2.384698788704867

Epoch: 577| Step: 0
Training loss: 0.211422257250871
Validation loss: 2.3736459189061825

Epoch: 5| Step: 1
Training loss: 0.11307181532048304
Validation loss: 2.4263635378100408

Epoch: 5| Step: 2
Training loss: 0.2191870444733319
Validation loss: 2.4283943735404137

Epoch: 5| Step: 3
Training loss: 0.11601795072183123
Validation loss: 2.4177423218379945

Epoch: 5| Step: 4
Training loss: 0.0871546261050729
Validation loss: 2.369559747507457

Epoch: 5| Step: 5
Training loss: 0.08432276607896216
Validation loss: 2.3778722241958468

Epoch: 5| Step: 6
Training loss: 0.20065461480888808
Validation loss: 2.3620849971698705

Epoch: 5| Step: 7
Training loss: 0.08536137016041359
Validation loss: 2.3300098795344453

Epoch: 5| Step: 8
Training loss: 0.16239046522455824
Validation loss: 2.332284670477902

Epoch: 5| Step: 9
Training loss: 0.11064409203707326
Validation loss: 2.3635628990999544

Epoch: 5| Step: 10
Training loss: 0.12938210049784515
Validation loss: 2.3508548775030045

Epoch: 578| Step: 0
Training loss: 0.11642594442882472
Validation loss: 2.3515666481542654

Epoch: 5| Step: 1
Training loss: 0.14462865305278902
Validation loss: 2.3812872658545063

Epoch: 5| Step: 2
Training loss: 0.10873828058838565
Validation loss: 2.407263643644406

Epoch: 5| Step: 3
Training loss: 0.2791212236488066
Validation loss: 2.4516926195497004

Epoch: 5| Step: 4
Training loss: 0.11319653039682918
Validation loss: 2.4067527587763555

Epoch: 5| Step: 5
Training loss: 0.078107390803397
Validation loss: 2.39298145931907

Epoch: 5| Step: 6
Training loss: 0.11334061711264587
Validation loss: 2.3809929382514703

Epoch: 5| Step: 7
Training loss: 0.1261406650266722
Validation loss: 2.345787096086075

Epoch: 5| Step: 8
Training loss: 0.1300795363157766
Validation loss: 2.34786646369339

Epoch: 5| Step: 9
Training loss: 0.18301338423447655
Validation loss: 2.3467331035441856

Epoch: 5| Step: 10
Training loss: 0.13723829191590747
Validation loss: 2.360218560377406

Epoch: 579| Step: 0
Training loss: 0.12911764786276345
Validation loss: 2.37749596857372

Epoch: 5| Step: 1
Training loss: 0.12092491654917038
Validation loss: 2.37121074224558

Epoch: 5| Step: 2
Training loss: 0.11475484692890855
Validation loss: 2.3656174662196388

Epoch: 5| Step: 3
Training loss: 0.11548087861625445
Validation loss: 2.365500974942932

Epoch: 5| Step: 4
Training loss: 0.09121878690251659
Validation loss: 2.3519292917458023

Epoch: 5| Step: 5
Training loss: 0.10956581109876168
Validation loss: 2.3639988608980023

Epoch: 5| Step: 6
Training loss: 0.1259927295690421
Validation loss: 2.3461410762403805

Epoch: 5| Step: 7
Training loss: 0.21403285364226116
Validation loss: 2.343136201286436

Epoch: 5| Step: 8
Training loss: 0.1816646293447883
Validation loss: 2.315944796450116

Epoch: 5| Step: 9
Training loss: 0.20920475365257424
Validation loss: 2.332111828513746

Epoch: 5| Step: 10
Training loss: 0.06886777516210063
Validation loss: 2.3312377679078287

Epoch: 580| Step: 0
Training loss: 0.11566480164193488
Validation loss: 2.3469996401305577

Epoch: 5| Step: 1
Training loss: 0.11928321560326242
Validation loss: 2.375146928224418

Epoch: 5| Step: 2
Training loss: 0.1883788374311876
Validation loss: 2.3801861417282537

Epoch: 5| Step: 3
Training loss: 0.12875151739800336
Validation loss: 2.395934554249468

Epoch: 5| Step: 4
Training loss: 0.1368020893586746
Validation loss: 2.4333814560866647

Epoch: 5| Step: 5
Training loss: 0.11312267286583655
Validation loss: 2.39509272281291

Epoch: 5| Step: 6
Training loss: 0.12156861778937718
Validation loss: 2.4264050318872514

Epoch: 5| Step: 7
Training loss: 0.17750339380565855
Validation loss: 2.451893866626135

Epoch: 5| Step: 8
Training loss: 0.10699768410219694
Validation loss: 2.4022224705794297

Epoch: 5| Step: 9
Training loss: 0.16532259630837956
Validation loss: 2.360364580777619

Epoch: 5| Step: 10
Training loss: 0.07233907214833171
Validation loss: 2.376562030692921

Epoch: 581| Step: 0
Training loss: 0.09181119421613992
Validation loss: 2.332261020032361

Epoch: 5| Step: 1
Training loss: 0.19349576012638556
Validation loss: 2.3567467023318547

Epoch: 5| Step: 2
Training loss: 0.1873389386791308
Validation loss: 2.367538271833515

Epoch: 5| Step: 3
Training loss: 0.1332794493769379
Validation loss: 2.3704149961018373

Epoch: 5| Step: 4
Training loss: 0.09906506951727094
Validation loss: 2.3833318371993597

Epoch: 5| Step: 5
Training loss: 0.2108981219376056
Validation loss: 2.3958897343684993

Epoch: 5| Step: 6
Training loss: 0.09828152750518872
Validation loss: 2.4275347320566674

Epoch: 5| Step: 7
Training loss: 0.19556915586049753
Validation loss: 2.4242943431061494

Epoch: 5| Step: 8
Training loss: 0.07507548135038807
Validation loss: 2.4212097651610014

Epoch: 5| Step: 9
Training loss: 0.11006224100725807
Validation loss: 2.3763217004945933

Epoch: 5| Step: 10
Training loss: 0.1338413025157744
Validation loss: 2.3278917326661066

Epoch: 582| Step: 0
Training loss: 0.11759692830644647
Validation loss: 2.3333625974739096

Epoch: 5| Step: 1
Training loss: 0.1706192078760074
Validation loss: 2.2935761108544157

Epoch: 5| Step: 2
Training loss: 0.1685878080181805
Validation loss: 2.2701436312779197

Epoch: 5| Step: 3
Training loss: 0.13148043703108137
Validation loss: 2.3306836140568783

Epoch: 5| Step: 4
Training loss: 0.0829241078144265
Validation loss: 2.338317208780233

Epoch: 5| Step: 5
Training loss: 0.196635353599703
Validation loss: 2.342638735917699

Epoch: 5| Step: 6
Training loss: 0.2174547283834113
Validation loss: 2.3527806331176198

Epoch: 5| Step: 7
Training loss: 0.13768733116447773
Validation loss: 2.3455618928295974

Epoch: 5| Step: 8
Training loss: 0.08103672368558049
Validation loss: 2.370573904341586

Epoch: 5| Step: 9
Training loss: 0.14431163495491378
Validation loss: 2.383078782594642

Epoch: 5| Step: 10
Training loss: 0.10105379792106854
Validation loss: 2.3658832151798106

Epoch: 583| Step: 0
Training loss: 0.12424646434272323
Validation loss: 2.3338180568545837

Epoch: 5| Step: 1
Training loss: 0.17280286437000345
Validation loss: 2.2895359153270975

Epoch: 5| Step: 2
Training loss: 0.09669802713324503
Validation loss: 2.2811022879370366

Epoch: 5| Step: 3
Training loss: 0.1349077995128243
Validation loss: 2.2399327235732396

Epoch: 5| Step: 4
Training loss: 0.12368360654139744
Validation loss: 2.2701424963455534

Epoch: 5| Step: 5
Training loss: 0.14136094004942248
Validation loss: 2.270918401332924

Epoch: 5| Step: 6
Training loss: 0.17459881769817245
Validation loss: 2.2830394627021655

Epoch: 5| Step: 7
Training loss: 0.11060002720613257
Validation loss: 2.3218101434881797

Epoch: 5| Step: 8
Training loss: 0.11489391950285499
Validation loss: 2.3795878296084645

Epoch: 5| Step: 9
Training loss: 0.21485864414259728
Validation loss: 2.428987956621199

Epoch: 5| Step: 10
Training loss: 0.16675313492213018
Validation loss: 2.4425763451077316

Epoch: 584| Step: 0
Training loss: 0.12072814848681418
Validation loss: 2.4126649719294124

Epoch: 5| Step: 1
Training loss: 0.07112202606034278
Validation loss: 2.3811726506401674

Epoch: 5| Step: 2
Training loss: 0.10022304868593411
Validation loss: 2.3245432582262953

Epoch: 5| Step: 3
Training loss: 0.09057068615364701
Validation loss: 2.293817112654391

Epoch: 5| Step: 4
Training loss: 0.12120042993239907
Validation loss: 2.2653412830442865

Epoch: 5| Step: 5
Training loss: 0.13162956332812437
Validation loss: 2.2465043903219732

Epoch: 5| Step: 6
Training loss: 0.1658646626467392
Validation loss: 2.2655734646501298

Epoch: 5| Step: 7
Training loss: 0.2036348784265266
Validation loss: 2.275296435853025

Epoch: 5| Step: 8
Training loss: 0.20944692991685798
Validation loss: 2.298714949481434

Epoch: 5| Step: 9
Training loss: 0.13680632375070098
Validation loss: 2.3116735014063376

Epoch: 5| Step: 10
Training loss: 0.0949360114822824
Validation loss: 2.3461220346816876

Epoch: 585| Step: 0
Training loss: 0.0849417028906566
Validation loss: 2.3896908260241054

Epoch: 5| Step: 1
Training loss: 0.12696097423056937
Validation loss: 2.3893764773621102

Epoch: 5| Step: 2
Training loss: 0.1433276827443676
Validation loss: 2.3766327822249242

Epoch: 5| Step: 3
Training loss: 0.084712327954713
Validation loss: 2.4021792338381673

Epoch: 5| Step: 4
Training loss: 0.21435692858361813
Validation loss: 2.373604711112194

Epoch: 5| Step: 5
Training loss: 0.17836134230689604
Validation loss: 2.3992414282542387

Epoch: 5| Step: 6
Training loss: 0.1206532742662679
Validation loss: 2.3861726504296215

Epoch: 5| Step: 7
Training loss: 0.08115841651164858
Validation loss: 2.3344473395217444

Epoch: 5| Step: 8
Training loss: 0.24659786362383912
Validation loss: 2.3248813891315896

Epoch: 5| Step: 9
Training loss: 0.12681567747798822
Validation loss: 2.304844154914022

Epoch: 5| Step: 10
Training loss: 0.0764739940912297
Validation loss: 2.3640294671569477

Epoch: 586| Step: 0
Training loss: 0.07121017088401574
Validation loss: 2.394893014077528

Epoch: 5| Step: 1
Training loss: 0.10520435235624676
Validation loss: 2.357581424680861

Epoch: 5| Step: 2
Training loss: 0.13058759450360422
Validation loss: 2.3642954428616814

Epoch: 5| Step: 3
Training loss: 0.12025935590823317
Validation loss: 2.3592391849363086

Epoch: 5| Step: 4
Training loss: 0.10201798601087048
Validation loss: 2.3433466454167786

Epoch: 5| Step: 5
Training loss: 0.18669853180791762
Validation loss: 2.323577170761215

Epoch: 5| Step: 6
Training loss: 0.10759838947400156
Validation loss: 2.3038735675391915

Epoch: 5| Step: 7
Training loss: 0.0784683787596507
Validation loss: 2.3316508884211706

Epoch: 5| Step: 8
Training loss: 0.055725419376777434
Validation loss: 2.3251084272974487

Epoch: 5| Step: 9
Training loss: 0.158610819381888
Validation loss: 2.3508104817052957

Epoch: 5| Step: 10
Training loss: 0.17613161455915813
Validation loss: 2.3548745642716775

Epoch: 587| Step: 0
Training loss: 0.18937805497503443
Validation loss: 2.391534117563334

Epoch: 5| Step: 1
Training loss: 0.09582878154677142
Validation loss: 2.3790791481017584

Epoch: 5| Step: 2
Training loss: 0.15735120749013293
Validation loss: 2.40989346784417

Epoch: 5| Step: 3
Training loss: 0.15390267295359716
Validation loss: 2.4056426327043177

Epoch: 5| Step: 4
Training loss: 0.22141176577624905
Validation loss: 2.3681975420864645

Epoch: 5| Step: 5
Training loss: 0.121621539119838
Validation loss: 2.3721065382450197

Epoch: 5| Step: 6
Training loss: 0.18441582324789974
Validation loss: 2.3705431208657504

Epoch: 5| Step: 7
Training loss: 0.08389202574084315
Validation loss: 2.338008495800611

Epoch: 5| Step: 8
Training loss: 0.10953429236927928
Validation loss: 2.297083661801029

Epoch: 5| Step: 9
Training loss: 0.08103470096290143
Validation loss: 2.335188129193872

Epoch: 5| Step: 10
Training loss: 0.09723712147305447
Validation loss: 2.3515719518940665

Epoch: 588| Step: 0
Training loss: 0.09594701810615587
Validation loss: 2.3244779366960144

Epoch: 5| Step: 1
Training loss: 0.11926558070367516
Validation loss: 2.3620545583639894

Epoch: 5| Step: 2
Training loss: 0.16146924702357626
Validation loss: 2.3603109833749927

Epoch: 5| Step: 3
Training loss: 0.18952470587292577
Validation loss: 2.3483817849949395

Epoch: 5| Step: 4
Training loss: 0.11041864533570832
Validation loss: 2.3838921962480093

Epoch: 5| Step: 5
Training loss: 0.09559031084825823
Validation loss: 2.3938449276929585

Epoch: 5| Step: 6
Training loss: 0.0886795557367433
Validation loss: 2.389639765954626

Epoch: 5| Step: 7
Training loss: 0.13039279428532335
Validation loss: 2.3950679810320166

Epoch: 5| Step: 8
Training loss: 0.11606915022702104
Validation loss: 2.3493047419285755

Epoch: 5| Step: 9
Training loss: 0.10545467353415222
Validation loss: 2.318574308131893

Epoch: 5| Step: 10
Training loss: 0.18689460174753758
Validation loss: 2.3497987037960053

Epoch: 589| Step: 0
Training loss: 0.12021016190039979
Validation loss: 2.2973766369277935

Epoch: 5| Step: 1
Training loss: 0.13495140124800514
Validation loss: 2.336255478172481

Epoch: 5| Step: 2
Training loss: 0.10680331389349121
Validation loss: 2.341294087119703

Epoch: 5| Step: 3
Training loss: 0.12150421103295304
Validation loss: 2.336011152800198

Epoch: 5| Step: 4
Training loss: 0.10020337918176597
Validation loss: 2.3516609613624335

Epoch: 5| Step: 5
Training loss: 0.07543606117795601
Validation loss: 2.3710305861891556

Epoch: 5| Step: 6
Training loss: 0.06970065861861811
Validation loss: 2.367928942946301

Epoch: 5| Step: 7
Training loss: 0.11390344981295557
Validation loss: 2.3803559592717454

Epoch: 5| Step: 8
Training loss: 0.18320759277752213
Validation loss: 2.3645349713279855

Epoch: 5| Step: 9
Training loss: 0.08857574461576323
Validation loss: 2.353892897850543

Epoch: 5| Step: 10
Training loss: 0.23670174880713335
Validation loss: 2.338915755344189

Epoch: 590| Step: 0
Training loss: 0.12214183238109699
Validation loss: 2.3483021992573274

Epoch: 5| Step: 1
Training loss: 0.10780201321891185
Validation loss: 2.3208075145503986

Epoch: 5| Step: 2
Training loss: 0.08969486899956129
Validation loss: 2.325496355460372

Epoch: 5| Step: 3
Training loss: 0.09015649803762182
Validation loss: 2.305861472020432

Epoch: 5| Step: 4
Training loss: 0.2105910935970968
Validation loss: 2.299625761127077

Epoch: 5| Step: 5
Training loss: 0.08140347021156308
Validation loss: 2.340631095621669

Epoch: 5| Step: 6
Training loss: 0.164620738341089
Validation loss: 2.321011551185262

Epoch: 5| Step: 7
Training loss: 0.10614049208385783
Validation loss: 2.3621824062013634

Epoch: 5| Step: 8
Training loss: 0.12829038134471304
Validation loss: 2.3591882014702144

Epoch: 5| Step: 9
Training loss: 0.11545817819110772
Validation loss: 2.3790120717682273

Epoch: 5| Step: 10
Training loss: 0.08393381504227262
Validation loss: 2.399666094774634

Epoch: 591| Step: 0
Training loss: 0.10830422766578994
Validation loss: 2.4205370750558926

Epoch: 5| Step: 1
Training loss: 0.08709061831232309
Validation loss: 2.4194864477915057

Epoch: 5| Step: 2
Training loss: 0.09198853592803144
Validation loss: 2.414057575681035

Epoch: 5| Step: 3
Training loss: 0.18445298840761276
Validation loss: 2.3882017090044454

Epoch: 5| Step: 4
Training loss: 0.073305134744346
Validation loss: 2.3639146916426457

Epoch: 5| Step: 5
Training loss: 0.0791434247895215
Validation loss: 2.391191348301563

Epoch: 5| Step: 6
Training loss: 0.12426097155323522
Validation loss: 2.3619202356853304

Epoch: 5| Step: 7
Training loss: 0.10274684380698171
Validation loss: 2.4077615197537328

Epoch: 5| Step: 8
Training loss: 0.15164519590537406
Validation loss: 2.4238983234298943

Epoch: 5| Step: 9
Training loss: 0.16365657839615574
Validation loss: 2.3921731498547567

Epoch: 5| Step: 10
Training loss: 0.09246610632672553
Validation loss: 2.431022533397743

Epoch: 592| Step: 0
Training loss: 0.157326287576249
Validation loss: 2.3972067831708936

Epoch: 5| Step: 1
Training loss: 0.06070727014749285
Validation loss: 2.3581201924100483

Epoch: 5| Step: 2
Training loss: 0.12799853008653744
Validation loss: 2.3420918035783576

Epoch: 5| Step: 3
Training loss: 0.11687675044462481
Validation loss: 2.3392212766794467

Epoch: 5| Step: 4
Training loss: 0.07814226853732843
Validation loss: 2.371920183587892

Epoch: 5| Step: 5
Training loss: 0.0832726601049811
Validation loss: 2.314052054298194

Epoch: 5| Step: 6
Training loss: 0.06553128169545147
Validation loss: 2.348967224181393

Epoch: 5| Step: 7
Training loss: 0.19005025573887388
Validation loss: 2.386448164051329

Epoch: 5| Step: 8
Training loss: 0.17055650018117796
Validation loss: 2.378554918706711

Epoch: 5| Step: 9
Training loss: 0.1426735780560195
Validation loss: 2.364199453026178

Epoch: 5| Step: 10
Training loss: 0.07408505243265295
Validation loss: 2.3724808701611515

Epoch: 593| Step: 0
Training loss: 0.07370406429589099
Validation loss: 2.422441607991007

Epoch: 5| Step: 1
Training loss: 0.12779503936232803
Validation loss: 2.4098034188249158

Epoch: 5| Step: 2
Training loss: 0.14929030784723524
Validation loss: 2.414276762396619

Epoch: 5| Step: 3
Training loss: 0.06459782713999937
Validation loss: 2.3790137172739154

Epoch: 5| Step: 4
Training loss: 0.08707453347402043
Validation loss: 2.382073116455537

Epoch: 5| Step: 5
Training loss: 0.11615864995909893
Validation loss: 2.3743102586541935

Epoch: 5| Step: 6
Training loss: 0.07551149058375342
Validation loss: 2.4111187817920765

Epoch: 5| Step: 7
Training loss: 0.06992477898454533
Validation loss: 2.3393895913017797

Epoch: 5| Step: 8
Training loss: 0.17367044004670326
Validation loss: 2.363561562267337

Epoch: 5| Step: 9
Training loss: 0.10568630774077588
Validation loss: 2.3020652663008634

Epoch: 5| Step: 10
Training loss: 0.17541923332111076
Validation loss: 2.3232441483749837

Epoch: 594| Step: 0
Training loss: 0.07167018624722302
Validation loss: 2.334937326239646

Epoch: 5| Step: 1
Training loss: 0.11710286660587717
Validation loss: 2.3268147275089563

Epoch: 5| Step: 2
Training loss: 0.15012312916797751
Validation loss: 2.317793317902562

Epoch: 5| Step: 3
Training loss: 0.07159690169041331
Validation loss: 2.3568754268251477

Epoch: 5| Step: 4
Training loss: 0.08511466609919452
Validation loss: 2.415539864606818

Epoch: 5| Step: 5
Training loss: 0.18291076480827378
Validation loss: 2.4517465175803936

Epoch: 5| Step: 6
Training loss: 0.1327678801812042
Validation loss: 2.4499334178530425

Epoch: 5| Step: 7
Training loss: 0.1745182279494624
Validation loss: 2.452045180808511

Epoch: 5| Step: 8
Training loss: 0.11290170951728208
Validation loss: 2.407306090464825

Epoch: 5| Step: 9
Training loss: 0.14960177479455528
Validation loss: 2.405705146167094

Epoch: 5| Step: 10
Training loss: 0.09617516821112027
Validation loss: 2.4062384488068633

Epoch: 595| Step: 0
Training loss: 0.06857854925077864
Validation loss: 2.3552038064525753

Epoch: 5| Step: 1
Training loss: 0.2057305177008454
Validation loss: 2.318887525404575

Epoch: 5| Step: 2
Training loss: 0.22593070597742074
Validation loss: 2.2569430590789135

Epoch: 5| Step: 3
Training loss: 0.13173393259301078
Validation loss: 2.2753379970961944

Epoch: 5| Step: 4
Training loss: 0.13480136231638182
Validation loss: 2.297428412948998

Epoch: 5| Step: 5
Training loss: 0.10342602180631348
Validation loss: 2.3518696246013335

Epoch: 5| Step: 6
Training loss: 0.15154760130183054
Validation loss: 2.382744070355197

Epoch: 5| Step: 7
Training loss: 0.13236667332067828
Validation loss: 2.445320336701053

Epoch: 5| Step: 8
Training loss: 0.17041279591262062
Validation loss: 2.475092124695284

Epoch: 5| Step: 9
Training loss: 0.14864191611403016
Validation loss: 2.4190217580498037

Epoch: 5| Step: 10
Training loss: 0.07860494059985379
Validation loss: 2.381733709821589

Epoch: 596| Step: 0
Training loss: 0.21532782725687344
Validation loss: 2.3244609146482595

Epoch: 5| Step: 1
Training loss: 0.15982508730334782
Validation loss: 2.2685457677876264

Epoch: 5| Step: 2
Training loss: 0.12381419229795142
Validation loss: 2.257649326059245

Epoch: 5| Step: 3
Training loss: 0.15329947603379404
Validation loss: 2.2589653720265566

Epoch: 5| Step: 4
Training loss: 0.11777081747604354
Validation loss: 2.2315864536123295

Epoch: 5| Step: 5
Training loss: 0.11859653871697702
Validation loss: 2.2584761419082438

Epoch: 5| Step: 6
Training loss: 0.10443541508619025
Validation loss: 2.2867467636985075

Epoch: 5| Step: 7
Training loss: 0.06642469332330429
Validation loss: 2.3477603928225212

Epoch: 5| Step: 8
Training loss: 0.08172660696412987
Validation loss: 2.373283024930666

Epoch: 5| Step: 9
Training loss: 0.16916461448489528
Validation loss: 2.4515134472661857

Epoch: 5| Step: 10
Training loss: 0.12229077458327055
Validation loss: 2.4609048039402657

Epoch: 597| Step: 0
Training loss: 0.18529664282153344
Validation loss: 2.4623087557470127

Epoch: 5| Step: 1
Training loss: 0.06572417275888327
Validation loss: 2.3746835187958535

Epoch: 5| Step: 2
Training loss: 0.12187859548253588
Validation loss: 2.2992154649584733

Epoch: 5| Step: 3
Training loss: 0.08487390851114653
Validation loss: 2.278305177506596

Epoch: 5| Step: 4
Training loss: 0.1925854076068557
Validation loss: 2.2533633185171453

Epoch: 5| Step: 5
Training loss: 0.20028153400338508
Validation loss: 2.224537764841719

Epoch: 5| Step: 6
Training loss: 0.18182416072613997
Validation loss: 2.2173877689818506

Epoch: 5| Step: 7
Training loss: 0.08513900577862726
Validation loss: 2.2939140818403825

Epoch: 5| Step: 8
Training loss: 0.11519592257830019
Validation loss: 2.3691843846100262

Epoch: 5| Step: 9
Training loss: 0.10958068529964886
Validation loss: 2.393454427759712

Epoch: 5| Step: 10
Training loss: 0.11506855478134988
Validation loss: 2.415391143731513

Epoch: 598| Step: 0
Training loss: 0.19085783145450583
Validation loss: 2.4162132096241797

Epoch: 5| Step: 1
Training loss: 0.24976630016590032
Validation loss: 2.3968989231359505

Epoch: 5| Step: 2
Training loss: 0.1679405255224388
Validation loss: 2.312341200706614

Epoch: 5| Step: 3
Training loss: 0.10043641430268589
Validation loss: 2.2832125269670995

Epoch: 5| Step: 4
Training loss: 0.14772342536407898
Validation loss: 2.1992474914385105

Epoch: 5| Step: 5
Training loss: 0.11966918345127948
Validation loss: 2.2036471068589876

Epoch: 5| Step: 6
Training loss: 0.17105301541915677
Validation loss: 2.1827992772968607

Epoch: 5| Step: 7
Training loss: 0.17470279046632128
Validation loss: 2.2396180314516636

Epoch: 5| Step: 8
Training loss: 0.0859117035728825
Validation loss: 2.3146051681863704

Epoch: 5| Step: 9
Training loss: 0.08486206505960814
Validation loss: 2.353309290821008

Epoch: 5| Step: 10
Training loss: 0.22380906867747472
Validation loss: 2.432922651039781

Epoch: 599| Step: 0
Training loss: 0.12931220836707924
Validation loss: 2.426719879846289

Epoch: 5| Step: 1
Training loss: 0.1569819650598883
Validation loss: 2.408822401924301

Epoch: 5| Step: 2
Training loss: 0.2105855831878461
Validation loss: 2.4052849768070614

Epoch: 5| Step: 3
Training loss: 0.1794747772739079
Validation loss: 2.3754906332428884

Epoch: 5| Step: 4
Training loss: 0.10802746778448968
Validation loss: 2.3803524940254164

Epoch: 5| Step: 5
Training loss: 0.09344689723829319
Validation loss: 2.312645932786469

Epoch: 5| Step: 6
Training loss: 0.13958720885656614
Validation loss: 2.342778473899659

Epoch: 5| Step: 7
Training loss: 0.12901828694378045
Validation loss: 2.3358094092509925

Epoch: 5| Step: 8
Training loss: 0.1251729498900281
Validation loss: 2.363245543106185

Epoch: 5| Step: 9
Training loss: 0.14676250121298015
Validation loss: 2.3868019660529844

Epoch: 5| Step: 10
Training loss: 0.0963022542200314
Validation loss: 2.3982334037431574

Epoch: 600| Step: 0
Training loss: 0.17021632716396443
Validation loss: 2.411360612415398

Epoch: 5| Step: 1
Training loss: 0.1391779971816388
Validation loss: 2.413016551750204

Epoch: 5| Step: 2
Training loss: 0.09929576291647824
Validation loss: 2.4549538785226352

Epoch: 5| Step: 3
Training loss: 0.1502316551240011
Validation loss: 2.449759025978269

Epoch: 5| Step: 4
Training loss: 0.14449806090063616
Validation loss: 2.411254515577343

Epoch: 5| Step: 5
Training loss: 0.18124342117208705
Validation loss: 2.4101355846909382

Epoch: 5| Step: 6
Training loss: 0.1713640790370021
Validation loss: 2.3731800029343364

Epoch: 5| Step: 7
Training loss: 0.1539002826424563
Validation loss: 2.3283429701375615

Epoch: 5| Step: 8
Training loss: 0.14366355971500896
Validation loss: 2.3043332931219904

Epoch: 5| Step: 9
Training loss: 0.12299850815114462
Validation loss: 2.332314699800801

Epoch: 5| Step: 10
Training loss: 0.10235783592869875
Validation loss: 2.358337278445043

Testing loss: 2.7905007390114696
