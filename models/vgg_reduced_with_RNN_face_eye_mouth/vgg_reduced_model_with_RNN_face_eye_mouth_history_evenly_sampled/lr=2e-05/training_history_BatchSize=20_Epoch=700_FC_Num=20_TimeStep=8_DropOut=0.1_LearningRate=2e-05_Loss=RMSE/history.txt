Epoch: 1| Step: 0
Training loss: 6.374245692487336
Validation loss: 5.7521213828832485

Epoch: 5| Step: 1
Training loss: 5.6396324573637235
Validation loss: 5.738924925109935

Epoch: 5| Step: 2
Training loss: 5.4464259056066915
Validation loss: 5.726274351014714

Epoch: 5| Step: 3
Training loss: 5.6606839330890075
Validation loss: 5.712057306279512

Epoch: 5| Step: 4
Training loss: 6.1757939125621295
Validation loss: 5.695673814647382

Epoch: 5| Step: 5
Training loss: 5.799545125553389
Validation loss: 5.6778385391217965

Epoch: 5| Step: 6
Training loss: 5.80135630830146
Validation loss: 5.656618624667906

Epoch: 5| Step: 7
Training loss: 3.975363919855399
Validation loss: 5.632286739145988

Epoch: 5| Step: 8
Training loss: 5.165528982277425
Validation loss: 5.605271469268527

Epoch: 5| Step: 9
Training loss: 6.2165431415193355
Validation loss: 5.574069017751023

Epoch: 5| Step: 10
Training loss: 6.157933658471701
Validation loss: 5.539724630360309

Epoch: 2| Step: 0
Training loss: 5.822275125264809
Validation loss: 5.501713177361411

Epoch: 5| Step: 1
Training loss: 4.906674895141447
Validation loss: 5.459786189885496

Epoch: 5| Step: 2
Training loss: 5.323504013035647
Validation loss: 5.414638985371827

Epoch: 5| Step: 3
Training loss: 4.183637061371277
Validation loss: 5.368260096848551

Epoch: 5| Step: 4
Training loss: 6.588303182957385
Validation loss: 5.320439017330796

Epoch: 5| Step: 5
Training loss: 5.605940678631374
Validation loss: 5.271808763420509

Epoch: 5| Step: 6
Training loss: 4.871677929585388
Validation loss: 5.22628674217377

Epoch: 5| Step: 7
Training loss: 5.136198509182878
Validation loss: 5.183365806417463

Epoch: 5| Step: 8
Training loss: 5.1087011423707835
Validation loss: 5.140515459907536

Epoch: 5| Step: 9
Training loss: 5.774612162724248
Validation loss: 5.098117657212803

Epoch: 5| Step: 10
Training loss: 4.878235354693462
Validation loss: 5.0558097037295715

Epoch: 3| Step: 0
Training loss: 5.441430611429224
Validation loss: 5.007598185871467

Epoch: 5| Step: 1
Training loss: 5.9541892554689095
Validation loss: 4.950476120347383

Epoch: 5| Step: 2
Training loss: 4.788657838735649
Validation loss: 4.893999870807965

Epoch: 5| Step: 3
Training loss: 4.994365951115528
Validation loss: 4.855662225040436

Epoch: 5| Step: 4
Training loss: 3.3260728123551924
Validation loss: 4.8070760951523885

Epoch: 5| Step: 5
Training loss: 4.394443792532513
Validation loss: 4.76701697925247

Epoch: 5| Step: 6
Training loss: 4.93464268930075
Validation loss: 4.733973189288641

Epoch: 5| Step: 7
Training loss: 4.32667754169463
Validation loss: 4.700883695356336

Epoch: 5| Step: 8
Training loss: 4.841913478073559
Validation loss: 4.667347736731303

Epoch: 5| Step: 9
Training loss: 5.392579539795179
Validation loss: 4.633560619119304

Epoch: 5| Step: 10
Training loss: 4.6899177927974645
Validation loss: 4.602281474675574

Epoch: 4| Step: 0
Training loss: 4.381399433455411
Validation loss: 4.572491910901468

Epoch: 5| Step: 1
Training loss: 3.9511803227634603
Validation loss: 4.546899697712035

Epoch: 5| Step: 2
Training loss: 5.362506985604242
Validation loss: 4.523874888972169

Epoch: 5| Step: 3
Training loss: 5.49738821959469
Validation loss: 4.494887137507446

Epoch: 5| Step: 4
Training loss: 4.657773786228433
Validation loss: 4.474197281418929

Epoch: 5| Step: 5
Training loss: 4.04593461941491
Validation loss: 4.452241741408061

Epoch: 5| Step: 6
Training loss: 4.71340295858005
Validation loss: 4.431609356581775

Epoch: 5| Step: 7
Training loss: 4.656551069728564
Validation loss: 4.411468734038372

Epoch: 5| Step: 8
Training loss: 4.177720906725018
Validation loss: 4.395147173925563

Epoch: 5| Step: 9
Training loss: 4.402081621383043
Validation loss: 4.380269366503628

Epoch: 5| Step: 10
Training loss: 4.1259484790094545
Validation loss: 4.370299991577433

Epoch: 5| Step: 0
Training loss: 3.7826304792551877
Validation loss: 4.347137294306948

Epoch: 5| Step: 1
Training loss: 4.5209831998158965
Validation loss: 4.339557072657271

Epoch: 5| Step: 2
Training loss: 4.775945376136524
Validation loss: 4.3295042077139705

Epoch: 5| Step: 3
Training loss: 4.856454640204444
Validation loss: 4.3155644012492935

Epoch: 5| Step: 4
Training loss: 4.432467118349444
Validation loss: 4.297284291929981

Epoch: 5| Step: 5
Training loss: 4.1756490145836205
Validation loss: 4.277796930682991

Epoch: 5| Step: 6
Training loss: 4.808174468291401
Validation loss: 4.266443233510449

Epoch: 5| Step: 7
Training loss: 4.30839497997419
Validation loss: 4.254184400237416

Epoch: 5| Step: 8
Training loss: 4.815392553820269
Validation loss: 4.23816147531952

Epoch: 5| Step: 9
Training loss: 3.4994601787073387
Validation loss: 4.222873263978827

Epoch: 5| Step: 10
Training loss: 4.310570990318248
Validation loss: 4.216048612625635

Epoch: 6| Step: 0
Training loss: 4.203829454572329
Validation loss: 4.202195682937657

Epoch: 5| Step: 1
Training loss: 5.06243576197429
Validation loss: 4.191225540107718

Epoch: 5| Step: 2
Training loss: 4.238362704430408
Validation loss: 4.18093247838552

Epoch: 5| Step: 3
Training loss: 4.833194577209467
Validation loss: 4.171738615622301

Epoch: 5| Step: 4
Training loss: 3.7822801432026476
Validation loss: 4.157563212945546

Epoch: 5| Step: 5
Training loss: 4.671829274441785
Validation loss: 4.144897177565467

Epoch: 5| Step: 6
Training loss: 3.652588535204496
Validation loss: 4.134274272733252

Epoch: 5| Step: 7
Training loss: 4.019996727330029
Validation loss: 4.124486548822126

Epoch: 5| Step: 8
Training loss: 4.396335350164771
Validation loss: 4.115205524215215

Epoch: 5| Step: 9
Training loss: 3.5228004302541644
Validation loss: 4.103146115653508

Epoch: 5| Step: 10
Training loss: 4.540919437825374
Validation loss: 4.095161633593139

Epoch: 7| Step: 0
Training loss: 3.578373662978674
Validation loss: 4.0847587926788504

Epoch: 5| Step: 1
Training loss: 4.027183433324046
Validation loss: 4.074953916968431

Epoch: 5| Step: 2
Training loss: 4.545601682882458
Validation loss: 4.064166793730556

Epoch: 5| Step: 3
Training loss: 3.812456724828037
Validation loss: 4.052010907742398

Epoch: 5| Step: 4
Training loss: 3.329551140487129
Validation loss: 4.043786765980331

Epoch: 5| Step: 5
Training loss: 4.328811315663483
Validation loss: 4.035614932014804

Epoch: 5| Step: 6
Training loss: 4.055522619546261
Validation loss: 4.024060804235293

Epoch: 5| Step: 7
Training loss: 4.180464570726513
Validation loss: 4.016598867760623

Epoch: 5| Step: 8
Training loss: 4.923322386078404
Validation loss: 4.0054378540035644

Epoch: 5| Step: 9
Training loss: 4.324550433304636
Validation loss: 3.9994618671686233

Epoch: 5| Step: 10
Training loss: 4.695935809357955
Validation loss: 3.9933867647838377

Epoch: 8| Step: 0
Training loss: 4.144232794022291
Validation loss: 3.9834636085808626

Epoch: 5| Step: 1
Training loss: 4.959735298169175
Validation loss: 3.976016693207455

Epoch: 5| Step: 2
Training loss: 3.1976432227776415
Validation loss: 3.964448231253393

Epoch: 5| Step: 3
Training loss: 4.488107437207795
Validation loss: 3.95574634687636

Epoch: 5| Step: 4
Training loss: 3.643234823721074
Validation loss: 3.943427769200195

Epoch: 5| Step: 5
Training loss: 4.606444794923916
Validation loss: 3.937111575775218

Epoch: 5| Step: 6
Training loss: 3.351612437483085
Validation loss: 3.928320267235332

Epoch: 5| Step: 7
Training loss: 3.523996516032234
Validation loss: 3.9190059283577074

Epoch: 5| Step: 8
Training loss: 4.348642132927076
Validation loss: 3.914523413851499

Epoch: 5| Step: 9
Training loss: 4.405457120941936
Validation loss: 3.904450900641568

Epoch: 5| Step: 10
Training loss: 4.002213819138298
Validation loss: 3.890158233733213

Epoch: 9| Step: 0
Training loss: 4.434857723530046
Validation loss: 3.880727799930183

Epoch: 5| Step: 1
Training loss: 3.119944335734382
Validation loss: 3.875553463388722

Epoch: 5| Step: 2
Training loss: 3.84015046579891
Validation loss: 3.872461305741132

Epoch: 5| Step: 3
Training loss: 3.7662742973022465
Validation loss: 3.854655213171357

Epoch: 5| Step: 4
Training loss: 4.699427776808934
Validation loss: 3.850781870048763

Epoch: 5| Step: 5
Training loss: 4.256614250471769
Validation loss: 3.83857864725167

Epoch: 5| Step: 6
Training loss: 3.4902627919240485
Validation loss: 3.8355745787506006

Epoch: 5| Step: 7
Training loss: 4.115680454955147
Validation loss: 3.829416322003851

Epoch: 5| Step: 8
Training loss: 4.709418360277016
Validation loss: 3.81392941305965

Epoch: 5| Step: 9
Training loss: 3.416661022150603
Validation loss: 3.8075868393865164

Epoch: 5| Step: 10
Training loss: 3.9214200063667
Validation loss: 3.799409712435011

Epoch: 10| Step: 0
Training loss: 4.005192723965167
Validation loss: 3.789688464261516

Epoch: 5| Step: 1
Training loss: 3.347618788305928
Validation loss: 3.7840551312205797

Epoch: 5| Step: 2
Training loss: 3.539549535118849
Validation loss: 3.7772129535580383

Epoch: 5| Step: 3
Training loss: 3.947582113270809
Validation loss: 3.7705078614541816

Epoch: 5| Step: 4
Training loss: 3.8013440114431845
Validation loss: 3.766502303024726

Epoch: 5| Step: 5
Training loss: 4.192032140695957
Validation loss: 3.7618613609800793

Epoch: 5| Step: 6
Training loss: 4.412720170620297
Validation loss: 3.7546546979290527

Epoch: 5| Step: 7
Training loss: 4.302087791508296
Validation loss: 3.744299831139473

Epoch: 5| Step: 8
Training loss: 3.649607305435301
Validation loss: 3.754745742773338

Epoch: 5| Step: 9
Training loss: 3.938110909678176
Validation loss: 3.755134403723665

Epoch: 5| Step: 10
Training loss: 4.106714816327231
Validation loss: 3.7442864620882026

Epoch: 11| Step: 0
Training loss: 3.916347301259431
Validation loss: 3.726759100360619

Epoch: 5| Step: 1
Training loss: 4.001258413728438
Validation loss: 3.7165603830165

Epoch: 5| Step: 2
Training loss: 3.3802377535926356
Validation loss: 3.713306877914052

Epoch: 5| Step: 3
Training loss: 3.8310037804497545
Validation loss: 3.7156673072449924

Epoch: 5| Step: 4
Training loss: 3.9013680430615456
Validation loss: 3.6952883190987342

Epoch: 5| Step: 5
Training loss: 3.8718265952224256
Validation loss: 3.691284206838573

Epoch: 5| Step: 6
Training loss: 3.808972962892157
Validation loss: 3.6901359209661697

Epoch: 5| Step: 7
Training loss: 4.112773229920059
Validation loss: 3.687668461581522

Epoch: 5| Step: 8
Training loss: 3.6462136787747617
Validation loss: 3.6787604996691647

Epoch: 5| Step: 9
Training loss: 4.464088195790917
Validation loss: 3.666829361946446

Epoch: 5| Step: 10
Training loss: 3.6276917822399346
Validation loss: 3.653490616743802

Epoch: 12| Step: 0
Training loss: 3.3088349994136497
Validation loss: 3.639994271283001

Epoch: 5| Step: 1
Training loss: 3.9073117453536286
Validation loss: 3.630403179975789

Epoch: 5| Step: 2
Training loss: 3.9791702084084504
Validation loss: 3.618592704017927

Epoch: 5| Step: 3
Training loss: 3.6608750524009954
Validation loss: 3.6114983991226364

Epoch: 5| Step: 4
Training loss: 3.24379622292339
Validation loss: 3.6035802263196857

Epoch: 5| Step: 5
Training loss: 3.8233783799976298
Validation loss: 3.6010348452860472

Epoch: 5| Step: 6
Training loss: 3.621262037199936
Validation loss: 3.594901682115578

Epoch: 5| Step: 7
Training loss: 3.5676188585334034
Validation loss: 3.58740423142646

Epoch: 5| Step: 8
Training loss: 4.499754793056154
Validation loss: 3.577753503678834

Epoch: 5| Step: 9
Training loss: 3.5357004663546885
Validation loss: 3.565037771733434

Epoch: 5| Step: 10
Training loss: 4.492031671889655
Validation loss: 3.5586679858648624

Epoch: 13| Step: 0
Training loss: 3.1151664128558454
Validation loss: 3.5492946085127364

Epoch: 5| Step: 1
Training loss: 3.334393682311328
Validation loss: 3.5471662356891525

Epoch: 5| Step: 2
Training loss: 4.098018837479152
Validation loss: 3.5481520791220307

Epoch: 5| Step: 3
Training loss: 3.329641363861651
Validation loss: 3.5441632027039347

Epoch: 5| Step: 4
Training loss: 4.457149146323605
Validation loss: 3.525158697957557

Epoch: 5| Step: 5
Training loss: 3.775230471415578
Validation loss: 3.5129510749794317

Epoch: 5| Step: 6
Training loss: 3.3980085431059464
Validation loss: 3.5085408061988077

Epoch: 5| Step: 7
Training loss: 4.170639026446189
Validation loss: 3.5106003320923818

Epoch: 5| Step: 8
Training loss: 4.224043851928232
Validation loss: 3.5084534180221483

Epoch: 5| Step: 9
Training loss: 3.772748359002875
Validation loss: 3.4986909082328794

Epoch: 5| Step: 10
Training loss: 2.8777388090967095
Validation loss: 3.4809286690829255

Epoch: 14| Step: 0
Training loss: 3.5423191741041045
Validation loss: 3.472582667739563

Epoch: 5| Step: 1
Training loss: 3.7308555202805707
Validation loss: 3.4734758892977533

Epoch: 5| Step: 2
Training loss: 3.162633200995349
Validation loss: 3.4861269033740214

Epoch: 5| Step: 3
Training loss: 4.223448672828474
Validation loss: 3.4454343970142034

Epoch: 5| Step: 4
Training loss: 3.1510917890781602
Validation loss: 3.446876858085325

Epoch: 5| Step: 5
Training loss: 4.377625032095698
Validation loss: 3.4584205864520787

Epoch: 5| Step: 6
Training loss: 4.148751974309375
Validation loss: 3.4577197733859864

Epoch: 5| Step: 7
Training loss: 3.4375104037040716
Validation loss: 3.443252058603609

Epoch: 5| Step: 8
Training loss: 3.9474984033833826
Validation loss: 3.427716179770122

Epoch: 5| Step: 9
Training loss: 3.5929081469802036
Validation loss: 3.4158902435340806

Epoch: 5| Step: 10
Training loss: 2.5399410664487307
Validation loss: 3.4086953678785523

Epoch: 15| Step: 0
Training loss: 3.3352453152453734
Validation loss: 3.4095272883459584

Epoch: 5| Step: 1
Training loss: 3.4078159757278956
Validation loss: 3.3950736542846474

Epoch: 5| Step: 2
Training loss: 3.302290965069698
Validation loss: 3.3846481872154115

Epoch: 5| Step: 3
Training loss: 3.568713207689886
Validation loss: 3.384895174486383

Epoch: 5| Step: 4
Training loss: 3.957056676212425
Validation loss: 3.383789914827169

Epoch: 5| Step: 5
Training loss: 4.3942102747363645
Validation loss: 3.3675578887032374

Epoch: 5| Step: 6
Training loss: 3.6061873458629288
Validation loss: 3.3607858353375235

Epoch: 5| Step: 7
Training loss: 3.7163467976640465
Validation loss: 3.357973263138514

Epoch: 5| Step: 8
Training loss: 3.5545321587795278
Validation loss: 3.3477346610428915

Epoch: 5| Step: 9
Training loss: 3.3810648643592147
Validation loss: 3.342555134192193

Epoch: 5| Step: 10
Training loss: 3.177712616848912
Validation loss: 3.3745406114282783

Epoch: 16| Step: 0
Training loss: 3.9690110728983297
Validation loss: 3.3252165867009875

Epoch: 5| Step: 1
Training loss: 3.234610581226528
Validation loss: 3.317974412495548

Epoch: 5| Step: 2
Training loss: 3.7419986557746565
Validation loss: 3.3119720824621885

Epoch: 5| Step: 3
Training loss: 3.52009264737361
Validation loss: 3.3059073147242892

Epoch: 5| Step: 4
Training loss: 4.226232152639962
Validation loss: 3.299095035814307

Epoch: 5| Step: 5
Training loss: 2.9553509754549556
Validation loss: 3.297301355392536

Epoch: 5| Step: 6
Training loss: 3.304112305420482
Validation loss: 3.2915198679026285

Epoch: 5| Step: 7
Training loss: 3.506917656690226
Validation loss: 3.279855159592391

Epoch: 5| Step: 8
Training loss: 3.2165684390182316
Validation loss: 3.2653181203972172

Epoch: 5| Step: 9
Training loss: 3.3846605287889067
Validation loss: 3.2584567403501588

Epoch: 5| Step: 10
Training loss: 3.6681827243065968
Validation loss: 3.2503262743366528

Epoch: 17| Step: 0
Training loss: 3.687410256538376
Validation loss: 3.2438409579511007

Epoch: 5| Step: 1
Training loss: 4.027775886505969
Validation loss: 3.241027458452384

Epoch: 5| Step: 2
Training loss: 3.756215983663636
Validation loss: 3.24112543926148

Epoch: 5| Step: 3
Training loss: 4.111008004164275
Validation loss: 3.2657086180669674

Epoch: 5| Step: 4
Training loss: 2.696457771569023
Validation loss: 3.221944832086064

Epoch: 5| Step: 5
Training loss: 2.631008990705578
Validation loss: 3.219820960469851

Epoch: 5| Step: 6
Training loss: 3.611962385993524
Validation loss: 3.223741680776873

Epoch: 5| Step: 7
Training loss: 3.582075977774184
Validation loss: 3.2221052071702503

Epoch: 5| Step: 8
Training loss: 3.6985655452608017
Validation loss: 3.217828398249205

Epoch: 5| Step: 9
Training loss: 2.9803271578731994
Validation loss: 3.2124050966039817

Epoch: 5| Step: 10
Training loss: 3.086120291016304
Validation loss: 3.2094439462170623

Epoch: 18| Step: 0
Training loss: 3.3424061008636907
Validation loss: 3.2097854960897627

Epoch: 5| Step: 1
Training loss: 3.056706924450701
Validation loss: 3.1979363740714137

Epoch: 5| Step: 2
Training loss: 3.901324286959058
Validation loss: 3.1925898318852477

Epoch: 5| Step: 3
Training loss: 4.013894030880449
Validation loss: 3.184788866136476

Epoch: 5| Step: 4
Training loss: 3.4674021533673116
Validation loss: 3.1785772438742086

Epoch: 5| Step: 5
Training loss: 3.386390256515245
Validation loss: 3.1759015969811046

Epoch: 5| Step: 6
Training loss: 3.080637569575981
Validation loss: 3.1742073494621756

Epoch: 5| Step: 7
Training loss: 3.6022227048340816
Validation loss: 3.1692450552973828

Epoch: 5| Step: 8
Training loss: 3.182326362949323
Validation loss: 3.164407834160028

Epoch: 5| Step: 9
Training loss: 3.031413280376074
Validation loss: 3.16273355045993

Epoch: 5| Step: 10
Training loss: 3.6212662508635782
Validation loss: 3.172330374151827

Epoch: 19| Step: 0
Training loss: 3.669992426934601
Validation loss: 3.1968789193375113

Epoch: 5| Step: 1
Training loss: 3.634145184612106
Validation loss: 3.1512052673376587

Epoch: 5| Step: 2
Training loss: 3.455052730969427
Validation loss: 3.1516636735485637

Epoch: 5| Step: 3
Training loss: 3.7306326146111193
Validation loss: 3.1546393571198816

Epoch: 5| Step: 4
Training loss: 3.3759624380489894
Validation loss: 3.158229358712866

Epoch: 5| Step: 5
Training loss: 3.138393387371004
Validation loss: 3.153392627773166

Epoch: 5| Step: 6
Training loss: 2.9606237723388444
Validation loss: 3.1456292231586156

Epoch: 5| Step: 7
Training loss: 3.79587984583497
Validation loss: 3.1447200526113788

Epoch: 5| Step: 8
Training loss: 3.1330007748619604
Validation loss: 3.1450674706667963

Epoch: 5| Step: 9
Training loss: 2.7167907319866744
Validation loss: 3.1300133686788594

Epoch: 5| Step: 10
Training loss: 3.7991459338462055
Validation loss: 3.1284725264522772

Epoch: 20| Step: 0
Training loss: 2.7339771090248943
Validation loss: 3.1254653625182676

Epoch: 5| Step: 1
Training loss: 3.2556748363644545
Validation loss: 3.128326016043945

Epoch: 5| Step: 2
Training loss: 3.4354202915139367
Validation loss: 3.1285340996513686

Epoch: 5| Step: 3
Training loss: 3.6496442804358704
Validation loss: 3.123832839072059

Epoch: 5| Step: 4
Training loss: 3.0632326456429992
Validation loss: 3.1193359103459235

Epoch: 5| Step: 5
Training loss: 2.886584453014033
Validation loss: 3.1133717840418904

Epoch: 5| Step: 6
Training loss: 3.7252491810040427
Validation loss: 3.109786469509389

Epoch: 5| Step: 7
Training loss: 3.0491606135767424
Validation loss: 3.1057114059323054

Epoch: 5| Step: 8
Training loss: 3.124448498698692
Validation loss: 3.103750630592675

Epoch: 5| Step: 9
Training loss: 3.628198725093422
Validation loss: 3.099866700258807

Epoch: 5| Step: 10
Training loss: 4.469365431015574
Validation loss: 3.0988931904280794

Epoch: 21| Step: 0
Training loss: 3.546000637555697
Validation loss: 3.0914910601402394

Epoch: 5| Step: 1
Training loss: 3.2580520944288485
Validation loss: 3.0887548435374215

Epoch: 5| Step: 2
Training loss: 2.9164391201812583
Validation loss: 3.0871622683439446

Epoch: 5| Step: 3
Training loss: 4.22585483909395
Validation loss: 3.08657962156433

Epoch: 5| Step: 4
Training loss: 3.3325718645730573
Validation loss: 3.0813886490162132

Epoch: 5| Step: 5
Training loss: 3.0233304105812535
Validation loss: 3.0808246842429186

Epoch: 5| Step: 6
Training loss: 3.542014804259885
Validation loss: 3.0917848403308077

Epoch: 5| Step: 7
Training loss: 3.1036551307931166
Validation loss: 3.0738447141888865

Epoch: 5| Step: 8
Training loss: 3.3820148611255427
Validation loss: 3.071792904851944

Epoch: 5| Step: 9
Training loss: 3.083710535706908
Validation loss: 3.0719477212336743

Epoch: 5| Step: 10
Training loss: 3.231436606355377
Validation loss: 3.0686404522831268

Epoch: 22| Step: 0
Training loss: 2.461866802774279
Validation loss: 3.0688309766765616

Epoch: 5| Step: 1
Training loss: 2.6843508522803847
Validation loss: 3.0683416596600845

Epoch: 5| Step: 2
Training loss: 3.5886175242666405
Validation loss: 3.0674484426697015

Epoch: 5| Step: 3
Training loss: 3.5811553516496497
Validation loss: 3.071942774120213

Epoch: 5| Step: 4
Training loss: 3.256305153758556
Validation loss: 3.0654091795085074

Epoch: 5| Step: 5
Training loss: 3.466015399376965
Validation loss: 3.058948814376715

Epoch: 5| Step: 6
Training loss: 3.4370519172625262
Validation loss: 3.0569436080497203

Epoch: 5| Step: 7
Training loss: 3.387650974189166
Validation loss: 3.0603876687429485

Epoch: 5| Step: 8
Training loss: 3.3696125971497977
Validation loss: 3.060167887507841

Epoch: 5| Step: 9
Training loss: 2.9906774948758574
Validation loss: 3.058852866240493

Epoch: 5| Step: 10
Training loss: 4.2511377494639
Validation loss: 3.056979648744156

Epoch: 23| Step: 0
Training loss: 3.4063467309498363
Validation loss: 3.0520154881134967

Epoch: 5| Step: 1
Training loss: 3.821594148112243
Validation loss: 3.0500087427248994

Epoch: 5| Step: 2
Training loss: 2.282602719087852
Validation loss: 3.0465295722554133

Epoch: 5| Step: 3
Training loss: 3.434784527590714
Validation loss: 3.0436279218151756

Epoch: 5| Step: 4
Training loss: 3.456879382919543
Validation loss: 3.0411222467659424

Epoch: 5| Step: 5
Training loss: 2.7366055355454018
Validation loss: 3.039639241588165

Epoch: 5| Step: 6
Training loss: 3.316935035416703
Validation loss: 3.036438762991718

Epoch: 5| Step: 7
Training loss: 3.7564661861925246
Validation loss: 3.035997960813811

Epoch: 5| Step: 8
Training loss: 2.883026197829816
Validation loss: 3.0341743932234935

Epoch: 5| Step: 9
Training loss: 3.6540117504262923
Validation loss: 3.0337265464533605

Epoch: 5| Step: 10
Training loss: 3.427739522120423
Validation loss: 3.032817636926036

Epoch: 24| Step: 0
Training loss: 3.4149544465139114
Validation loss: 3.032942091267204

Epoch: 5| Step: 1
Training loss: 3.7045195323847753
Validation loss: 3.0325856067351564

Epoch: 5| Step: 2
Training loss: 3.2628923143720185
Validation loss: 3.03846475490772

Epoch: 5| Step: 3
Training loss: 3.2080480935922364
Validation loss: 3.0275365201115245

Epoch: 5| Step: 4
Training loss: 3.6039985808645962
Validation loss: 3.0234831348436946

Epoch: 5| Step: 5
Training loss: 3.0455408549921423
Validation loss: 3.0229705164158376

Epoch: 5| Step: 6
Training loss: 2.8279720707637868
Validation loss: 3.02153878183838

Epoch: 5| Step: 7
Training loss: 3.267991080357158
Validation loss: 3.0185365040589143

Epoch: 5| Step: 8
Training loss: 2.675263247504987
Validation loss: 3.018468527084197

Epoch: 5| Step: 9
Training loss: 3.565642192508261
Validation loss: 3.0174900701429297

Epoch: 5| Step: 10
Training loss: 3.6321910695807818
Validation loss: 3.015981269001743

Epoch: 25| Step: 0
Training loss: 3.4536219450729906
Validation loss: 3.0136960526493546

Epoch: 5| Step: 1
Training loss: 3.227383192860676
Validation loss: 3.0121910423215756

Epoch: 5| Step: 2
Training loss: 3.1348073035585995
Validation loss: 3.01077283615924

Epoch: 5| Step: 3
Training loss: 3.6715940976745527
Validation loss: 3.012816072913899

Epoch: 5| Step: 4
Training loss: 3.503690408886499
Validation loss: 3.0145563043453496

Epoch: 5| Step: 5
Training loss: 3.241897606815893
Validation loss: 3.016085868795517

Epoch: 5| Step: 6
Training loss: 2.968218464700166
Validation loss: 3.014204136530223

Epoch: 5| Step: 7
Training loss: 3.3460789350831415
Validation loss: 3.0121072081036333

Epoch: 5| Step: 8
Training loss: 2.9083669192352355
Validation loss: 3.0081978278214905

Epoch: 5| Step: 9
Training loss: 3.3568033000282527
Validation loss: 3.004549741526085

Epoch: 5| Step: 10
Training loss: 3.3969095938990685
Validation loss: 3.004103365828252

Epoch: 26| Step: 0
Training loss: 2.9238643299987874
Validation loss: 3.003799210195657

Epoch: 5| Step: 1
Training loss: 3.49185704794892
Validation loss: 3.007498181074981

Epoch: 5| Step: 2
Training loss: 3.8367426817716
Validation loss: 3.013232240430372

Epoch: 5| Step: 3
Training loss: 2.7727612167873064
Validation loss: 3.009374450397992

Epoch: 5| Step: 4
Training loss: 2.9574875674788546
Validation loss: 3.0027996530698844

Epoch: 5| Step: 5
Training loss: 2.9569380429291514
Validation loss: 2.996337723249947

Epoch: 5| Step: 6
Training loss: 3.5341829256167814
Validation loss: 2.996575422766161

Epoch: 5| Step: 7
Training loss: 3.3575994013020707
Validation loss: 2.9942872249717754

Epoch: 5| Step: 8
Training loss: 3.434418979463843
Validation loss: 2.9955239316763023

Epoch: 5| Step: 9
Training loss: 3.384279844684637
Validation loss: 2.991350768352431

Epoch: 5| Step: 10
Training loss: 3.2524485534305385
Validation loss: 2.989729015746402

Epoch: 27| Step: 0
Training loss: 3.0984833852935907
Validation loss: 2.988095837038671

Epoch: 5| Step: 1
Training loss: 3.6249810580054675
Validation loss: 2.987443463753403

Epoch: 5| Step: 2
Training loss: 3.318760839182364
Validation loss: 2.984745577956208

Epoch: 5| Step: 3
Training loss: 3.481714028023699
Validation loss: 2.9839788946173873

Epoch: 5| Step: 4
Training loss: 3.097168238178394
Validation loss: 2.983939824339446

Epoch: 5| Step: 5
Training loss: 2.0354790898267834
Validation loss: 2.9831407079096635

Epoch: 5| Step: 6
Training loss: 3.159955861230007
Validation loss: 2.994642027780909

Epoch: 5| Step: 7
Training loss: 3.3845110498699653
Validation loss: 3.0010546587371767

Epoch: 5| Step: 8
Training loss: 3.2541301599881542
Validation loss: 2.9981034977145917

Epoch: 5| Step: 9
Training loss: 3.330590709267089
Validation loss: 2.989631382897396

Epoch: 5| Step: 10
Training loss: 3.9281241793999615
Validation loss: 2.977570346520525

Epoch: 28| Step: 0
Training loss: 3.7712293525815888
Validation loss: 2.9770723848791656

Epoch: 5| Step: 1
Training loss: 3.3069996782503988
Validation loss: 2.9778016538213277

Epoch: 5| Step: 2
Training loss: 3.4616690179054332
Validation loss: 2.979097005963502

Epoch: 5| Step: 3
Training loss: 3.594349288729075
Validation loss: 2.97772567518808

Epoch: 5| Step: 4
Training loss: 2.791117191802459
Validation loss: 2.9769477908164106

Epoch: 5| Step: 5
Training loss: 2.9110091425320657
Validation loss: 2.97161807866277

Epoch: 5| Step: 6
Training loss: 3.2446923564737506
Validation loss: 2.971945022081235

Epoch: 5| Step: 7
Training loss: 2.518991622505023
Validation loss: 2.971178896446046

Epoch: 5| Step: 8
Training loss: 4.001639268668261
Validation loss: 2.969520821966231

Epoch: 5| Step: 9
Training loss: 3.069594592933376
Validation loss: 2.97088315325654

Epoch: 5| Step: 10
Training loss: 2.7703366420014497
Validation loss: 2.9695870100893633

Epoch: 29| Step: 0
Training loss: 3.204459456686244
Validation loss: 2.9749664798349986

Epoch: 5| Step: 1
Training loss: 2.9946113510027788
Validation loss: 2.9623547688504934

Epoch: 5| Step: 2
Training loss: 2.958253635532889
Validation loss: 2.961600304981342

Epoch: 5| Step: 3
Training loss: 3.8823510861009867
Validation loss: 2.957385292705574

Epoch: 5| Step: 4
Training loss: 3.354550325869914
Validation loss: 2.958202182948274

Epoch: 5| Step: 5
Training loss: 2.993212491961386
Validation loss: 2.9583372323754173

Epoch: 5| Step: 6
Training loss: 3.2641111816749517
Validation loss: 2.957111900858444

Epoch: 5| Step: 7
Training loss: 2.8953215515028172
Validation loss: 2.954881269013941

Epoch: 5| Step: 8
Training loss: 3.5195529272362402
Validation loss: 2.9537824775740886

Epoch: 5| Step: 9
Training loss: 3.308205609934936
Validation loss: 2.95572119863496

Epoch: 5| Step: 10
Training loss: 3.131527149475609
Validation loss: 2.9529200005985246

Epoch: 30| Step: 0
Training loss: 3.713393127695072
Validation loss: 2.9531596843077925

Epoch: 5| Step: 1
Training loss: 3.6841307943364106
Validation loss: 2.949844481948867

Epoch: 5| Step: 2
Training loss: 2.3484370857893224
Validation loss: 2.9635512215246385

Epoch: 5| Step: 3
Training loss: 3.1274499063726213
Validation loss: 2.9701650980611203

Epoch: 5| Step: 4
Training loss: 3.2307784129281263
Validation loss: 2.959685002244855

Epoch: 5| Step: 5
Training loss: 3.416420687373022
Validation loss: 2.947255816701874

Epoch: 5| Step: 6
Training loss: 3.244411505425988
Validation loss: 2.946318514353733

Epoch: 5| Step: 7
Training loss: 2.4372481191535726
Validation loss: 2.947376043517404

Epoch: 5| Step: 8
Training loss: 3.355153825078875
Validation loss: 2.947658576365502

Epoch: 5| Step: 9
Training loss: 3.585193166170733
Validation loss: 2.9503380570107427

Epoch: 5| Step: 10
Training loss: 3.1336425290511247
Validation loss: 2.946725056986192

Epoch: 31| Step: 0
Training loss: 2.8354118427475687
Validation loss: 2.9462987539395806

Epoch: 5| Step: 1
Training loss: 3.6693119275093395
Validation loss: 2.94336615653105

Epoch: 5| Step: 2
Training loss: 3.4853915113114025
Validation loss: 2.939974260996738

Epoch: 5| Step: 3
Training loss: 3.4734904571353793
Validation loss: 2.937007373144477

Epoch: 5| Step: 4
Training loss: 3.001291950509377
Validation loss: 2.9368564255912597

Epoch: 5| Step: 5
Training loss: 3.203434924507092
Validation loss: 2.9349279809833617

Epoch: 5| Step: 6
Training loss: 3.0541323574441086
Validation loss: 2.9348186315308213

Epoch: 5| Step: 7
Training loss: 2.97056347520626
Validation loss: 2.933976321444629

Epoch: 5| Step: 8
Training loss: 3.1939079350129784
Validation loss: 2.9370750743035092

Epoch: 5| Step: 9
Training loss: 3.7193318400685698
Validation loss: 2.9361749809905846

Epoch: 5| Step: 10
Training loss: 2.6529000194760792
Validation loss: 2.9353358784897234

Epoch: 32| Step: 0
Training loss: 3.9457918083694072
Validation loss: 2.936856368851461

Epoch: 5| Step: 1
Training loss: 3.11257677711256
Validation loss: 2.9342678845503056

Epoch: 5| Step: 2
Training loss: 2.9704135450165805
Validation loss: 2.9345662921900297

Epoch: 5| Step: 3
Training loss: 3.5149253318528655
Validation loss: 2.9306362536072945

Epoch: 5| Step: 4
Training loss: 3.5812486898210136
Validation loss: 2.9268051895230696

Epoch: 5| Step: 5
Training loss: 2.586211129546812
Validation loss: 2.9267557540592275

Epoch: 5| Step: 6
Training loss: 2.860936306630776
Validation loss: 2.9271628907246834

Epoch: 5| Step: 7
Training loss: 3.5214808543902256
Validation loss: 2.924160592306616

Epoch: 5| Step: 8
Training loss: 2.5203791647961182
Validation loss: 2.9191204970266043

Epoch: 5| Step: 9
Training loss: 3.536946790593167
Validation loss: 2.9231789332284244

Epoch: 5| Step: 10
Training loss: 2.876616148109096
Validation loss: 2.9251808888865938

Epoch: 33| Step: 0
Training loss: 3.1460979089361323
Validation loss: 2.929821576513102

Epoch: 5| Step: 1
Training loss: 3.1959462178638156
Validation loss: 2.9314679858252375

Epoch: 5| Step: 2
Training loss: 3.6010050642194575
Validation loss: 2.9281688063229945

Epoch: 5| Step: 3
Training loss: 3.228839061895478
Validation loss: 2.915436243589012

Epoch: 5| Step: 4
Training loss: 2.8916485598067787
Validation loss: 2.9165054388062446

Epoch: 5| Step: 5
Training loss: 3.17852101967213
Validation loss: 2.9169235860524605

Epoch: 5| Step: 6
Training loss: 3.1395838895483776
Validation loss: 2.9163048081714082

Epoch: 5| Step: 7
Training loss: 3.6638966992571103
Validation loss: 2.91570705296645

Epoch: 5| Step: 8
Training loss: 2.8826077189504193
Validation loss: 2.9129881032465477

Epoch: 5| Step: 9
Training loss: 3.4334195974926063
Validation loss: 2.912926490481471

Epoch: 5| Step: 10
Training loss: 2.8346818818802157
Validation loss: 2.912464335592613

Epoch: 34| Step: 0
Training loss: 3.405530241069569
Validation loss: 2.9128787891540924

Epoch: 5| Step: 1
Training loss: 2.5010063053434464
Validation loss: 2.9104083292094423

Epoch: 5| Step: 2
Training loss: 2.685134911584184
Validation loss: 2.916879950839356

Epoch: 5| Step: 3
Training loss: 3.6258954224778868
Validation loss: 2.917278110266999

Epoch: 5| Step: 4
Training loss: 2.902074624235874
Validation loss: 2.905158125478835

Epoch: 5| Step: 5
Training loss: 3.295128237554452
Validation loss: 2.8973534354507935

Epoch: 5| Step: 6
Training loss: 2.9196991188024732
Validation loss: 2.897689842754634

Epoch: 5| Step: 7
Training loss: 4.007312527826937
Validation loss: 2.8970676877201598

Epoch: 5| Step: 8
Training loss: 2.9290297113111796
Validation loss: 2.8917134309709494

Epoch: 5| Step: 9
Training loss: 3.468400404900417
Validation loss: 2.8925278998353963

Epoch: 5| Step: 10
Training loss: 3.1591356135835964
Validation loss: 2.891894472440137

Epoch: 35| Step: 0
Training loss: 3.138762571855812
Validation loss: 2.889478984545926

Epoch: 5| Step: 1
Training loss: 2.788944359422327
Validation loss: 2.8861908848887046

Epoch: 5| Step: 2
Training loss: 3.2379699483776374
Validation loss: 2.883862775173316

Epoch: 5| Step: 3
Training loss: 3.2943933195278916
Validation loss: 2.8805310305299425

Epoch: 5| Step: 4
Training loss: 3.2135260698546917
Validation loss: 2.8821244762566756

Epoch: 5| Step: 5
Training loss: 3.6536133217084465
Validation loss: 2.878462744995171

Epoch: 5| Step: 6
Training loss: 2.76446008663856
Validation loss: 2.875461667923344

Epoch: 5| Step: 7
Training loss: 3.7355819730816116
Validation loss: 2.873339649300374

Epoch: 5| Step: 8
Training loss: 2.9695757871849238
Validation loss: 2.872790760688135

Epoch: 5| Step: 9
Training loss: 2.6625440638661377
Validation loss: 2.8741015340722456

Epoch: 5| Step: 10
Training loss: 3.338576262597822
Validation loss: 2.878892670867909

Epoch: 36| Step: 0
Training loss: 3.0908596524451384
Validation loss: 2.876361749134989

Epoch: 5| Step: 1
Training loss: 3.1656847150768184
Validation loss: 2.872548594176255

Epoch: 5| Step: 2
Training loss: 3.1616031083585927
Validation loss: 2.867179748769671

Epoch: 5| Step: 3
Training loss: 4.002693938036817
Validation loss: 2.864138020705549

Epoch: 5| Step: 4
Training loss: 3.677279127633873
Validation loss: 2.869684651555505

Epoch: 5| Step: 5
Training loss: 3.207102915326708
Validation loss: 2.8628162405481894

Epoch: 5| Step: 6
Training loss: 2.5452633304424843
Validation loss: 2.8599379821485313

Epoch: 5| Step: 7
Training loss: 2.7558902600867237
Validation loss: 2.8622261140950576

Epoch: 5| Step: 8
Training loss: 3.4282785358664225
Validation loss: 2.8590555329178446

Epoch: 5| Step: 9
Training loss: 2.8398311567486423
Validation loss: 2.8585712153297878

Epoch: 5| Step: 10
Training loss: 2.4837076502406665
Validation loss: 2.8621123594923725

Epoch: 37| Step: 0
Training loss: 3.2550307731521495
Validation loss: 2.8689800778134216

Epoch: 5| Step: 1
Training loss: 3.280855572926866
Validation loss: 2.884574175115127

Epoch: 5| Step: 2
Training loss: 3.3982452688987554
Validation loss: 2.8574636844871755

Epoch: 5| Step: 3
Training loss: 2.8301975812112214
Validation loss: 2.8543912420326687

Epoch: 5| Step: 4
Training loss: 3.1569028877834535
Validation loss: 2.859773723386219

Epoch: 5| Step: 5
Training loss: 3.21722227710456
Validation loss: 2.8645178060038

Epoch: 5| Step: 6
Training loss: 3.3701720850896733
Validation loss: 2.8788421178915815

Epoch: 5| Step: 7
Training loss: 3.230842319646904
Validation loss: 2.872563357245713

Epoch: 5| Step: 8
Training loss: 2.723278439768922
Validation loss: 2.8658340477153907

Epoch: 5| Step: 9
Training loss: 3.3804066055682895
Validation loss: 2.859334934527056

Epoch: 5| Step: 10
Training loss: 2.7807600468470612
Validation loss: 2.853898329426659

Epoch: 38| Step: 0
Training loss: 3.391255684836235
Validation loss: 2.848687221444773

Epoch: 5| Step: 1
Training loss: 3.5364004738091
Validation loss: 2.8452869486824506

Epoch: 5| Step: 2
Training loss: 3.2978242348308817
Validation loss: 2.8470589958549124

Epoch: 5| Step: 3
Training loss: 3.524382132631063
Validation loss: 2.846778237212928

Epoch: 5| Step: 4
Training loss: 2.7714632986502603
Validation loss: 2.8538265054011696

Epoch: 5| Step: 5
Training loss: 3.3672966817692496
Validation loss: 2.8519422052725636

Epoch: 5| Step: 6
Training loss: 2.757088714804972
Validation loss: 2.844120539238977

Epoch: 5| Step: 7
Training loss: 2.9358299865039466
Validation loss: 2.840624310640616

Epoch: 5| Step: 8
Training loss: 2.3965142208563255
Validation loss: 2.8420198395441214

Epoch: 5| Step: 9
Training loss: 3.0036581306521084
Validation loss: 2.843691063826538

Epoch: 5| Step: 10
Training loss: 3.4647496155828694
Validation loss: 2.8486098617614677

Epoch: 39| Step: 0
Training loss: 3.007861644789257
Validation loss: 2.8403646283657835

Epoch: 5| Step: 1
Training loss: 3.476009161986468
Validation loss: 2.838580728115169

Epoch: 5| Step: 2
Training loss: 2.061727783830921
Validation loss: 2.8369340209360536

Epoch: 5| Step: 3
Training loss: 3.101429972471651
Validation loss: 2.8372583805101153

Epoch: 5| Step: 4
Training loss: 3.1653218341651725
Validation loss: 2.8331747939641025

Epoch: 5| Step: 5
Training loss: 3.50077157371459
Validation loss: 2.833128839118847

Epoch: 5| Step: 6
Training loss: 2.698047080011665
Validation loss: 2.833372461156167

Epoch: 5| Step: 7
Training loss: 3.617994445037373
Validation loss: 2.8288058409427643

Epoch: 5| Step: 8
Training loss: 3.08969713868746
Validation loss: 2.8292936689804895

Epoch: 5| Step: 9
Training loss: 3.083788777986243
Validation loss: 2.8271875817031664

Epoch: 5| Step: 10
Training loss: 3.505774502802762
Validation loss: 2.828905964863676

Epoch: 40| Step: 0
Training loss: 3.357391339529917
Validation loss: 2.8288163961623356

Epoch: 5| Step: 1
Training loss: 3.0607137336355286
Validation loss: 2.825818302439482

Epoch: 5| Step: 2
Training loss: 3.0313451693037905
Validation loss: 2.8259259856610295

Epoch: 5| Step: 3
Training loss: 2.9091052724201902
Validation loss: 2.8270799583243043

Epoch: 5| Step: 4
Training loss: 3.2319854902753797
Validation loss: 2.825159135220928

Epoch: 5| Step: 5
Training loss: 3.016468938034333
Validation loss: 2.8267976515789037

Epoch: 5| Step: 6
Training loss: 2.99860763027391
Validation loss: 2.8248328363921527

Epoch: 5| Step: 7
Training loss: 3.1341612236167045
Validation loss: 2.8333617935223114

Epoch: 5| Step: 8
Training loss: 3.104878764219777
Validation loss: 2.85423961055471

Epoch: 5| Step: 9
Training loss: 3.7965946800456303
Validation loss: 2.883001454325752

Epoch: 5| Step: 10
Training loss: 2.8143828976914484
Validation loss: 2.824972571870445

Epoch: 41| Step: 0
Training loss: 2.9680268059314323
Validation loss: 2.826728297788567

Epoch: 5| Step: 1
Training loss: 2.7182316779286895
Validation loss: 2.8247275782768013

Epoch: 5| Step: 2
Training loss: 2.653728230513317
Validation loss: 2.8331487337330055

Epoch: 5| Step: 3
Training loss: 2.6877421780077593
Validation loss: 2.8432142926633706

Epoch: 5| Step: 4
Training loss: 2.833310426357644
Validation loss: 2.8481606841109457

Epoch: 5| Step: 5
Training loss: 3.3539167196526694
Validation loss: 2.8437784025172785

Epoch: 5| Step: 6
Training loss: 3.2707047811786683
Validation loss: 2.8278967788448957

Epoch: 5| Step: 7
Training loss: 3.3428403383514986
Validation loss: 2.821927517625366

Epoch: 5| Step: 8
Training loss: 3.7905227836041906
Validation loss: 2.819624420248629

Epoch: 5| Step: 9
Training loss: 3.4893126121763816
Validation loss: 2.8215928550478075

Epoch: 5| Step: 10
Training loss: 3.326003853837543
Validation loss: 2.8500097848507995

Epoch: 42| Step: 0
Training loss: 3.3064385863316903
Validation loss: 2.836232905510112

Epoch: 5| Step: 1
Training loss: 2.4271930020376677
Validation loss: 2.822898552888734

Epoch: 5| Step: 2
Training loss: 2.594376270107325
Validation loss: 2.817998366717666

Epoch: 5| Step: 3
Training loss: 3.219679911087187
Validation loss: 2.8224046392104936

Epoch: 5| Step: 4
Training loss: 3.1402779003039996
Validation loss: 2.809130131235407

Epoch: 5| Step: 5
Training loss: 3.0862859215389857
Validation loss: 2.810028143004551

Epoch: 5| Step: 6
Training loss: 2.9269982774714443
Validation loss: 2.806819254965306

Epoch: 5| Step: 7
Training loss: 3.357716421507442
Validation loss: 2.806375835908163

Epoch: 5| Step: 8
Training loss: 3.515846618448821
Validation loss: 2.8089959396608477

Epoch: 5| Step: 9
Training loss: 3.067453232387699
Validation loss: 2.8080674275209305

Epoch: 5| Step: 10
Training loss: 3.5735811258866725
Validation loss: 2.809121890353777

Epoch: 43| Step: 0
Training loss: 2.7029470043342965
Validation loss: 2.805769517711199

Epoch: 5| Step: 1
Training loss: 3.237547272443847
Validation loss: 2.8050426503148147

Epoch: 5| Step: 2
Training loss: 3.0854321802450304
Validation loss: 2.8013917364013476

Epoch: 5| Step: 3
Training loss: 3.027800967237541
Validation loss: 2.8007645726277683

Epoch: 5| Step: 4
Training loss: 3.2741940154495524
Validation loss: 2.7993300687210962

Epoch: 5| Step: 5
Training loss: 3.3824705166881572
Validation loss: 2.800828118193218

Epoch: 5| Step: 6
Training loss: 3.0021079922540697
Validation loss: 2.7997443436958047

Epoch: 5| Step: 7
Training loss: 3.4608772909812884
Validation loss: 2.802000114454618

Epoch: 5| Step: 8
Training loss: 2.821187314278095
Validation loss: 2.801882850607226

Epoch: 5| Step: 9
Training loss: 3.357295470551693
Validation loss: 2.8027255811307143

Epoch: 5| Step: 10
Training loss: 2.645634430945782
Validation loss: 2.80143070058135

Epoch: 44| Step: 0
Training loss: 2.8013720454567705
Validation loss: 2.814955521103221

Epoch: 5| Step: 1
Training loss: 2.6882290405773226
Validation loss: 2.8520792588549013

Epoch: 5| Step: 2
Training loss: 3.208121668451401
Validation loss: 2.9008602410288766

Epoch: 5| Step: 3
Training loss: 3.0861933734901026
Validation loss: 2.867703789908166

Epoch: 5| Step: 4
Training loss: 3.4856965847369974
Validation loss: 2.8278385430407886

Epoch: 5| Step: 5
Training loss: 3.22775534685679
Validation loss: 2.7916051839181155

Epoch: 5| Step: 6
Training loss: 3.3034633957567157
Validation loss: 2.788486996626936

Epoch: 5| Step: 7
Training loss: 3.335760965076108
Validation loss: 2.7939232393468627

Epoch: 5| Step: 8
Training loss: 3.0087328010704613
Validation loss: 2.8022563634030777

Epoch: 5| Step: 9
Training loss: 2.879247761608836
Validation loss: 2.8159441206187448

Epoch: 5| Step: 10
Training loss: 3.2670171225303135
Validation loss: 2.8134616379110056

Epoch: 45| Step: 0
Training loss: 2.8116686969954015
Validation loss: 2.8097825844903657

Epoch: 5| Step: 1
Training loss: 3.324067987593668
Validation loss: 2.8031335898028913

Epoch: 5| Step: 2
Training loss: 3.3992683184338373
Validation loss: 2.799322146538233

Epoch: 5| Step: 3
Training loss: 3.0874180585976183
Validation loss: 2.7938269884145557

Epoch: 5| Step: 4
Training loss: 3.0557484845221112
Validation loss: 2.7905958678323155

Epoch: 5| Step: 5
Training loss: 2.5476749778604337
Validation loss: 2.7874622032104215

Epoch: 5| Step: 6
Training loss: 3.4262344252000303
Validation loss: 2.7881412797221006

Epoch: 5| Step: 7
Training loss: 3.330601160583679
Validation loss: 2.78336640566072

Epoch: 5| Step: 8
Training loss: 3.2330524486437198
Validation loss: 2.781429719574

Epoch: 5| Step: 9
Training loss: 3.040344124942321
Validation loss: 2.779689493444741

Epoch: 5| Step: 10
Training loss: 2.774478083150165
Validation loss: 2.7807923848762983

Epoch: 46| Step: 0
Training loss: 3.203710288561859
Validation loss: 2.793555477674909

Epoch: 5| Step: 1
Training loss: 3.325628786219302
Validation loss: 2.800806547791427

Epoch: 5| Step: 2
Training loss: 3.1260516113882364
Validation loss: 2.7997618365921864

Epoch: 5| Step: 3
Training loss: 3.2051108554468324
Validation loss: 2.7806095751538633

Epoch: 5| Step: 4
Training loss: 2.4459802855276536
Validation loss: 2.7769274413659115

Epoch: 5| Step: 5
Training loss: 3.15518895812124
Validation loss: 2.7793439818848036

Epoch: 5| Step: 6
Training loss: 2.8715220436818996
Validation loss: 2.781283404324928

Epoch: 5| Step: 7
Training loss: 3.3488454053159957
Validation loss: 2.785429341528701

Epoch: 5| Step: 8
Training loss: 3.059986873922681
Validation loss: 2.793230581714101

Epoch: 5| Step: 9
Training loss: 3.531690316894419
Validation loss: 2.801433200683562

Epoch: 5| Step: 10
Training loss: 2.721690287054396
Validation loss: 2.797843989361091

Epoch: 47| Step: 0
Training loss: 2.1732474182949093
Validation loss: 2.786418750670787

Epoch: 5| Step: 1
Training loss: 2.686637385124377
Validation loss: 2.7829247124677763

Epoch: 5| Step: 2
Training loss: 3.9267425119386066
Validation loss: 2.7797282158510614

Epoch: 5| Step: 3
Training loss: 3.0544508430145965
Validation loss: 2.7777708201851072

Epoch: 5| Step: 4
Training loss: 2.8380406675429164
Validation loss: 2.7760306922236855

Epoch: 5| Step: 5
Training loss: 3.2311032466655707
Validation loss: 2.7748504575097632

Epoch: 5| Step: 6
Training loss: 3.489514721248089
Validation loss: 2.7716175884374716

Epoch: 5| Step: 7
Training loss: 3.265739913451776
Validation loss: 2.77578779133762

Epoch: 5| Step: 8
Training loss: 2.320093215187839
Validation loss: 2.7724719347036744

Epoch: 5| Step: 9
Training loss: 3.479918773623963
Validation loss: 2.7742236698384573

Epoch: 5| Step: 10
Training loss: 3.157394654849109
Validation loss: 2.7765866375171977

Epoch: 48| Step: 0
Training loss: 3.1249417108821618
Validation loss: 2.8051339066517573

Epoch: 5| Step: 1
Training loss: 2.743844773169887
Validation loss: 2.837481493878474

Epoch: 5| Step: 2
Training loss: 3.1826622846509567
Validation loss: 2.792144445847635

Epoch: 5| Step: 3
Training loss: 3.3098436176894475
Validation loss: 2.7782269416865226

Epoch: 5| Step: 4
Training loss: 2.740116217438742
Validation loss: 2.7799869119728995

Epoch: 5| Step: 5
Training loss: 2.7340591684230224
Validation loss: 2.770310961396449

Epoch: 5| Step: 6
Training loss: 2.9476291439893867
Validation loss: 2.7684462451026817

Epoch: 5| Step: 7
Training loss: 3.1236511371136824
Validation loss: 2.7661594537005496

Epoch: 5| Step: 8
Training loss: 3.417731855629886
Validation loss: 2.7643995332910554

Epoch: 5| Step: 9
Training loss: 2.7894634738629183
Validation loss: 2.765902282448448

Epoch: 5| Step: 10
Training loss: 3.7782249014672082
Validation loss: 2.763904048835297

Epoch: 49| Step: 0
Training loss: 2.855697518302672
Validation loss: 2.7608308604812093

Epoch: 5| Step: 1
Training loss: 3.3238581137918803
Validation loss: 2.762670183524022

Epoch: 5| Step: 2
Training loss: 2.7203691418582983
Validation loss: 2.76503739123339

Epoch: 5| Step: 3
Training loss: 3.300699483547158
Validation loss: 2.766315913165056

Epoch: 5| Step: 4
Training loss: 2.918978310912508
Validation loss: 2.7609406308119246

Epoch: 5| Step: 5
Training loss: 3.375882210046132
Validation loss: 2.768829693294673

Epoch: 5| Step: 6
Training loss: 2.3915285883619783
Validation loss: 2.767846629424902

Epoch: 5| Step: 7
Training loss: 3.426039299983901
Validation loss: 2.774784518183448

Epoch: 5| Step: 8
Training loss: 3.3737831747848626
Validation loss: 2.760394844871324

Epoch: 5| Step: 9
Training loss: 3.1530996784747325
Validation loss: 2.755703073534114

Epoch: 5| Step: 10
Training loss: 2.905592320997535
Validation loss: 2.7562906985840145

Epoch: 50| Step: 0
Training loss: 3.0524694482772494
Validation loss: 2.7612587688909938

Epoch: 5| Step: 1
Training loss: 3.224795543488338
Validation loss: 2.765409715793388

Epoch: 5| Step: 2
Training loss: 2.835888738712168
Validation loss: 2.76798418572999

Epoch: 5| Step: 3
Training loss: 2.8417371396213134
Validation loss: 2.771284151993908

Epoch: 5| Step: 4
Training loss: 2.305670163422413
Validation loss: 2.7650033224154447

Epoch: 5| Step: 5
Training loss: 3.3805030886248497
Validation loss: 2.763466885374217

Epoch: 5| Step: 6
Training loss: 3.5142867190218916
Validation loss: 2.762711250907808

Epoch: 5| Step: 7
Training loss: 2.5238503511079253
Validation loss: 2.7614194831976664

Epoch: 5| Step: 8
Training loss: 3.425278316800897
Validation loss: 2.7656614832913418

Epoch: 5| Step: 9
Training loss: 3.387753866332396
Validation loss: 2.7700500442061213

Epoch: 5| Step: 10
Training loss: 3.295916955966494
Validation loss: 2.7616971470477756

Epoch: 51| Step: 0
Training loss: 2.846891742745001
Validation loss: 2.7534069145312476

Epoch: 5| Step: 1
Training loss: 3.3767972328823586
Validation loss: 2.7533394383756566

Epoch: 5| Step: 2
Training loss: 2.647974924746721
Validation loss: 2.7468196670458256

Epoch: 5| Step: 3
Training loss: 2.737937132888983
Validation loss: 2.7453198689502694

Epoch: 5| Step: 4
Training loss: 2.8993907091093853
Validation loss: 2.7454944881479553

Epoch: 5| Step: 5
Training loss: 3.6305583564366772
Validation loss: 2.74755699961428

Epoch: 5| Step: 6
Training loss: 2.7470608523599553
Validation loss: 2.750905543193589

Epoch: 5| Step: 7
Training loss: 2.843928069523564
Validation loss: 2.7483087748047272

Epoch: 5| Step: 8
Training loss: 3.11422014617391
Validation loss: 2.7436486290810227

Epoch: 5| Step: 9
Training loss: 3.3372508552510736
Validation loss: 2.7409085214773325

Epoch: 5| Step: 10
Training loss: 3.479840394229529
Validation loss: 2.740351071805002

Epoch: 52| Step: 0
Training loss: 2.778748233604127
Validation loss: 2.7394264357492233

Epoch: 5| Step: 1
Training loss: 3.3547896918201556
Validation loss: 2.739495304570714

Epoch: 5| Step: 2
Training loss: 2.8391172799518674
Validation loss: 2.741363933670793

Epoch: 5| Step: 3
Training loss: 2.7625896801783343
Validation loss: 2.74029694234922

Epoch: 5| Step: 4
Training loss: 2.744621044745568
Validation loss: 2.741121085513881

Epoch: 5| Step: 5
Training loss: 3.217227612801625
Validation loss: 2.742373658106376

Epoch: 5| Step: 6
Training loss: 2.8903269021228817
Validation loss: 2.7416269824317774

Epoch: 5| Step: 7
Training loss: 3.11746512876095
Validation loss: 2.73949319058044

Epoch: 5| Step: 8
Training loss: 3.3212498676844158
Validation loss: 2.740814129645247

Epoch: 5| Step: 9
Training loss: 3.618763524690697
Validation loss: 2.740418201697009

Epoch: 5| Step: 10
Training loss: 2.992760665618346
Validation loss: 2.7385732291374008

Epoch: 53| Step: 0
Training loss: 3.093127101266193
Validation loss: 2.7337689296734853

Epoch: 5| Step: 1
Training loss: 3.043005731282022
Validation loss: 2.7315391017511783

Epoch: 5| Step: 2
Training loss: 3.2291942144059758
Validation loss: 2.730451962393303

Epoch: 5| Step: 3
Training loss: 2.9244078403560336
Validation loss: 2.7318570377108062

Epoch: 5| Step: 4
Training loss: 2.8476601013241276
Validation loss: 2.7314788791542206

Epoch: 5| Step: 5
Training loss: 3.665115563000562
Validation loss: 2.738778828606751

Epoch: 5| Step: 6
Training loss: 3.194759852737385
Validation loss: 2.7394461208870724

Epoch: 5| Step: 7
Training loss: 3.3630431973770896
Validation loss: 2.7358479094649186

Epoch: 5| Step: 8
Training loss: 2.5484172621437384
Validation loss: 2.739432174259923

Epoch: 5| Step: 9
Training loss: 2.8158198789839783
Validation loss: 2.746280151607481

Epoch: 5| Step: 10
Training loss: 2.5729221441748584
Validation loss: 2.735434006153824

Epoch: 54| Step: 0
Training loss: 3.3475002755470533
Validation loss: 2.7339375829583203

Epoch: 5| Step: 1
Training loss: 3.5639055390603738
Validation loss: 2.731537372972139

Epoch: 5| Step: 2
Training loss: 2.6009404352298278
Validation loss: 2.7361483869034346

Epoch: 5| Step: 3
Training loss: 2.516795105425082
Validation loss: 2.7299670959019875

Epoch: 5| Step: 4
Training loss: 3.47308449952732
Validation loss: 2.7305298154571447

Epoch: 5| Step: 5
Training loss: 2.3798516560652914
Validation loss: 2.726920012785083

Epoch: 5| Step: 6
Training loss: 3.072248396973708
Validation loss: 2.7266372871149964

Epoch: 5| Step: 7
Training loss: 2.626121826239682
Validation loss: 2.730329837898176

Epoch: 5| Step: 8
Training loss: 3.286287346617172
Validation loss: 2.7346404159809583

Epoch: 5| Step: 9
Training loss: 3.059847714742443
Validation loss: 2.726781405025979

Epoch: 5| Step: 10
Training loss: 3.3456613657183025
Validation loss: 2.736710386282873

Epoch: 55| Step: 0
Training loss: 2.8417549261293917
Validation loss: 2.7404365148367202

Epoch: 5| Step: 1
Training loss: 2.7194916163106813
Validation loss: 2.74294875662962

Epoch: 5| Step: 2
Training loss: 2.5015543873814425
Validation loss: 2.7319559833619715

Epoch: 5| Step: 3
Training loss: 3.3151388633492527
Validation loss: 2.7300123682755735

Epoch: 5| Step: 4
Training loss: 2.852955767823816
Validation loss: 2.724663238398744

Epoch: 5| Step: 5
Training loss: 3.0863620900548487
Validation loss: 2.72599522981264

Epoch: 5| Step: 6
Training loss: 2.82876883075294
Validation loss: 2.7239592606750302

Epoch: 5| Step: 7
Training loss: 3.4708861226024426
Validation loss: 2.7260495473253816

Epoch: 5| Step: 8
Training loss: 3.6525216941528664
Validation loss: 2.726515058513787

Epoch: 5| Step: 9
Training loss: 3.1693635967202205
Validation loss: 2.7200794941465047

Epoch: 5| Step: 10
Training loss: 2.8856283355819197
Validation loss: 2.716594532310222

Epoch: 56| Step: 0
Training loss: 3.1035249972817107
Validation loss: 2.716986710855427

Epoch: 5| Step: 1
Training loss: 2.574408702180568
Validation loss: 2.7189816715787187

Epoch: 5| Step: 2
Training loss: 3.3088354317444795
Validation loss: 2.714623882331558

Epoch: 5| Step: 3
Training loss: 2.4662528627420586
Validation loss: 2.7148409133061784

Epoch: 5| Step: 4
Training loss: 2.757912350324784
Validation loss: 2.733255371009355

Epoch: 5| Step: 5
Training loss: 3.7170439581397425
Validation loss: 2.7513912667840836

Epoch: 5| Step: 6
Training loss: 2.8866110486082577
Validation loss: 2.734520488565993

Epoch: 5| Step: 7
Training loss: 2.947139911738632
Validation loss: 2.7160092727127334

Epoch: 5| Step: 8
Training loss: 2.961414791882434
Validation loss: 2.707277238468982

Epoch: 5| Step: 9
Training loss: 3.1281807542952134
Validation loss: 2.7015279139112685

Epoch: 5| Step: 10
Training loss: 3.369887541753787
Validation loss: 2.699868349628006

Epoch: 57| Step: 0
Training loss: 3.2899661600987216
Validation loss: 2.6997677057075005

Epoch: 5| Step: 1
Training loss: 3.1233336011085138
Validation loss: 2.6997004899254384

Epoch: 5| Step: 2
Training loss: 2.80747749312798
Validation loss: 2.6995316929159645

Epoch: 5| Step: 3
Training loss: 2.468956467891696
Validation loss: 2.6971481561533914

Epoch: 5| Step: 4
Training loss: 3.4954051783505506
Validation loss: 2.6976299018666374

Epoch: 5| Step: 5
Training loss: 3.0693559782494795
Validation loss: 2.6969527100133845

Epoch: 5| Step: 6
Training loss: 2.6384060356580035
Validation loss: 2.7000745444753678

Epoch: 5| Step: 7
Training loss: 2.8839167105807504
Validation loss: 2.7039800587655622

Epoch: 5| Step: 8
Training loss: 3.195101929234152
Validation loss: 2.7124498246135476

Epoch: 5| Step: 9
Training loss: 3.1677902303083934
Validation loss: 2.7171892389845524

Epoch: 5| Step: 10
Training loss: 3.097451817812809
Validation loss: 2.721526839464821

Epoch: 58| Step: 0
Training loss: 2.9882549209930795
Validation loss: 2.709453787050018

Epoch: 5| Step: 1
Training loss: 2.992950581191998
Validation loss: 2.6976576865435544

Epoch: 5| Step: 2
Training loss: 3.467887290003029
Validation loss: 2.6929292014430866

Epoch: 5| Step: 3
Training loss: 2.712428142105598
Validation loss: 2.6915715352565788

Epoch: 5| Step: 4
Training loss: 2.4554938280777217
Validation loss: 2.6929631539386927

Epoch: 5| Step: 5
Training loss: 3.088507632260482
Validation loss: 2.689935663659064

Epoch: 5| Step: 6
Training loss: 2.988314280607891
Validation loss: 2.690077974420883

Epoch: 5| Step: 7
Training loss: 2.825943585015617
Validation loss: 2.690973692139484

Epoch: 5| Step: 8
Training loss: 2.962068608418617
Validation loss: 2.689314092355954

Epoch: 5| Step: 9
Training loss: 3.557183431130242
Validation loss: 2.688748625037392

Epoch: 5| Step: 10
Training loss: 3.059984848134544
Validation loss: 2.6888801100763384

Epoch: 59| Step: 0
Training loss: 3.3694488649757726
Validation loss: 2.6915573462763827

Epoch: 5| Step: 1
Training loss: 2.908232146272675
Validation loss: 2.689443257247966

Epoch: 5| Step: 2
Training loss: 3.07730571861813
Validation loss: 2.686760340117943

Epoch: 5| Step: 3
Training loss: 2.8404454744219367
Validation loss: 2.6861511913236917

Epoch: 5| Step: 4
Training loss: 2.755132134482971
Validation loss: 2.699584110858939

Epoch: 5| Step: 5
Training loss: 2.921356481554721
Validation loss: 2.7169899661363077

Epoch: 5| Step: 6
Training loss: 3.1283845502278016
Validation loss: 2.727251802485687

Epoch: 5| Step: 7
Training loss: 2.7754362399213743
Validation loss: 2.6935681429610003

Epoch: 5| Step: 8
Training loss: 3.1889479097434514
Validation loss: 2.6847183023869228

Epoch: 5| Step: 9
Training loss: 3.363784096728245
Validation loss: 2.686125240331256

Epoch: 5| Step: 10
Training loss: 2.8584653314153243
Validation loss: 2.686558783041066

Epoch: 60| Step: 0
Training loss: 3.3569467684400562
Validation loss: 2.689488613148229

Epoch: 5| Step: 1
Training loss: 3.137619478298888
Validation loss: 2.687707256272528

Epoch: 5| Step: 2
Training loss: 3.432034951287698
Validation loss: 2.688129254082616

Epoch: 5| Step: 3
Training loss: 2.887594417993488
Validation loss: 2.6881176819893544

Epoch: 5| Step: 4
Training loss: 2.677523347982553
Validation loss: 2.6868774120269787

Epoch: 5| Step: 5
Training loss: 2.8669739521547775
Validation loss: 2.686177070486723

Epoch: 5| Step: 6
Training loss: 2.635842048983577
Validation loss: 2.6839677282273318

Epoch: 5| Step: 7
Training loss: 3.3192860890545743
Validation loss: 2.682507309497269

Epoch: 5| Step: 8
Training loss: 3.1173150746333187
Validation loss: 2.683278976951769

Epoch: 5| Step: 9
Training loss: 3.099986100934772
Validation loss: 2.685048818215683

Epoch: 5| Step: 10
Training loss: 2.4554991683508027
Validation loss: 2.6948729977259336

Epoch: 61| Step: 0
Training loss: 3.4963864337158257
Validation loss: 2.7148327110516415

Epoch: 5| Step: 1
Training loss: 3.3351824082300197
Validation loss: 2.716115170543486

Epoch: 5| Step: 2
Training loss: 2.818486771906273
Validation loss: 2.7115571371640086

Epoch: 5| Step: 3
Training loss: 3.0116362603712146
Validation loss: 2.720940112886626

Epoch: 5| Step: 4
Training loss: 2.525740195830663
Validation loss: 2.7112788411357345

Epoch: 5| Step: 5
Training loss: 3.094688812536011
Validation loss: 2.714554356073514

Epoch: 5| Step: 6
Training loss: 2.41180828238461
Validation loss: 2.7280291579204525

Epoch: 5| Step: 7
Training loss: 3.3021582626040473
Validation loss: 2.7150221762398012

Epoch: 5| Step: 8
Training loss: 3.035995387037389
Validation loss: 2.7064572840504852

Epoch: 5| Step: 9
Training loss: 3.3922026870647626
Validation loss: 2.6931678356266464

Epoch: 5| Step: 10
Training loss: 2.5718705577047185
Validation loss: 2.6927430934181364

Epoch: 62| Step: 0
Training loss: 3.2471222975161953
Validation loss: 2.687063194543419

Epoch: 5| Step: 1
Training loss: 2.8210274168005407
Validation loss: 2.6847445973715414

Epoch: 5| Step: 2
Training loss: 3.240667000390795
Validation loss: 2.679100567167469

Epoch: 5| Step: 3
Training loss: 2.8903417500053052
Validation loss: 2.6750768285326987

Epoch: 5| Step: 4
Training loss: 2.8334026515185453
Validation loss: 2.6759122465095424

Epoch: 5| Step: 5
Training loss: 2.4818383468192344
Validation loss: 2.673248348725971

Epoch: 5| Step: 6
Training loss: 3.7706591880306917
Validation loss: 2.672153818401695

Epoch: 5| Step: 7
Training loss: 3.310833349745589
Validation loss: 2.670007356745151

Epoch: 5| Step: 8
Training loss: 2.8745808503158234
Validation loss: 2.6710419156353082

Epoch: 5| Step: 9
Training loss: 2.441382812387499
Validation loss: 2.669443174851759

Epoch: 5| Step: 10
Training loss: 3.0298557811193465
Validation loss: 2.670912903240384

Epoch: 63| Step: 0
Training loss: 3.231937392884249
Validation loss: 2.670360059663907

Epoch: 5| Step: 1
Training loss: 3.117450597841202
Validation loss: 2.6739848155176826

Epoch: 5| Step: 2
Training loss: 3.2718691471488364
Validation loss: 2.6746970860342456

Epoch: 5| Step: 3
Training loss: 2.7264766297030487
Validation loss: 2.6688167996034116

Epoch: 5| Step: 4
Training loss: 3.1915003787181977
Validation loss: 2.6683848729801896

Epoch: 5| Step: 5
Training loss: 2.6109618883803076
Validation loss: 2.6689446823827594

Epoch: 5| Step: 6
Training loss: 3.1131443199380744
Validation loss: 2.669163942675427

Epoch: 5| Step: 7
Training loss: 3.292177732043085
Validation loss: 2.667464514427508

Epoch: 5| Step: 8
Training loss: 3.3408452902548436
Validation loss: 2.667273522231233

Epoch: 5| Step: 9
Training loss: 2.6415582395939152
Validation loss: 2.6649373225517135

Epoch: 5| Step: 10
Training loss: 2.183500721268549
Validation loss: 2.664407950867552

Epoch: 64| Step: 0
Training loss: 2.7370018248825483
Validation loss: 2.6644903526319696

Epoch: 5| Step: 1
Training loss: 2.8687950845470964
Validation loss: 2.665830419214199

Epoch: 5| Step: 2
Training loss: 2.5528461691580655
Validation loss: 2.664189203684904

Epoch: 5| Step: 3
Training loss: 3.4206153258081096
Validation loss: 2.6642755746728017

Epoch: 5| Step: 4
Training loss: 2.7758790350841
Validation loss: 2.667786786596808

Epoch: 5| Step: 5
Training loss: 3.579325645270368
Validation loss: 2.6673571848781936

Epoch: 5| Step: 6
Training loss: 3.157473789568414
Validation loss: 2.6683991409839076

Epoch: 5| Step: 7
Training loss: 2.936236657720907
Validation loss: 2.6624231719400635

Epoch: 5| Step: 8
Training loss: 2.937126460572978
Validation loss: 2.662107726324642

Epoch: 5| Step: 9
Training loss: 2.5617577943330576
Validation loss: 2.6619690085927967

Epoch: 5| Step: 10
Training loss: 3.327046394182896
Validation loss: 2.660913331696386

Epoch: 65| Step: 0
Training loss: 2.4491468111756083
Validation loss: 2.6584657580599798

Epoch: 5| Step: 1
Training loss: 3.0191130552095458
Validation loss: 2.6570050492892476

Epoch: 5| Step: 2
Training loss: 3.0558723824902123
Validation loss: 2.6645760269050114

Epoch: 5| Step: 3
Training loss: 2.8619859791964717
Validation loss: 2.7227706241340517

Epoch: 5| Step: 4
Training loss: 3.2095255102358187
Validation loss: 2.8368318000184916

Epoch: 5| Step: 5
Training loss: 3.1361468068034126
Validation loss: 2.7876316057331274

Epoch: 5| Step: 6
Training loss: 3.1138457548715923
Validation loss: 2.7148655652473814

Epoch: 5| Step: 7
Training loss: 2.8080476911793184
Validation loss: 2.65308331117733

Epoch: 5| Step: 8
Training loss: 3.2027157405753637
Validation loss: 2.651833335750613

Epoch: 5| Step: 9
Training loss: 3.208961491378389
Validation loss: 2.652298452899782

Epoch: 5| Step: 10
Training loss: 3.1428550280526713
Validation loss: 2.6565449714350393

Epoch: 66| Step: 0
Training loss: 3.063318571346386
Validation loss: 2.676910835021216

Epoch: 5| Step: 1
Training loss: 3.1772715695176017
Validation loss: 2.712102851546064

Epoch: 5| Step: 2
Training loss: 3.193279487007223
Validation loss: 2.7151611746910733

Epoch: 5| Step: 3
Training loss: 3.116817595827382
Validation loss: 2.6532634393695105

Epoch: 5| Step: 4
Training loss: 3.436579494338905
Validation loss: 2.6425903641141644

Epoch: 5| Step: 5
Training loss: 2.8194025743337305
Validation loss: 2.6555780824055417

Epoch: 5| Step: 6
Training loss: 3.054518126648285
Validation loss: 2.699382927231421

Epoch: 5| Step: 7
Training loss: 2.919093802418712
Validation loss: 2.7214867981642668

Epoch: 5| Step: 8
Training loss: 2.8154764320391097
Validation loss: 2.722272238426419

Epoch: 5| Step: 9
Training loss: 2.6994952931046012
Validation loss: 2.7431335827188823

Epoch: 5| Step: 10
Training loss: 2.813453597425581
Validation loss: 2.7149048156315345

Epoch: 67| Step: 0
Training loss: 3.371115533044483
Validation loss: 2.6903335150617496

Epoch: 5| Step: 1
Training loss: 2.274331877137926
Validation loss: 2.680379025825871

Epoch: 5| Step: 2
Training loss: 3.0741894343722156
Validation loss: 2.6633547509563176

Epoch: 5| Step: 3
Training loss: 2.8660713538733056
Validation loss: 2.6564700060268667

Epoch: 5| Step: 4
Training loss: 3.190564944666962
Validation loss: 2.660795176170765

Epoch: 5| Step: 5
Training loss: 3.280411967480853
Validation loss: 2.665235287787267

Epoch: 5| Step: 6
Training loss: 3.01283190153293
Validation loss: 2.6700587412611374

Epoch: 5| Step: 7
Training loss: 3.0907661614035993
Validation loss: 2.6741873308567636

Epoch: 5| Step: 8
Training loss: 3.2257747104067582
Validation loss: 2.676097400234848

Epoch: 5| Step: 9
Training loss: 2.4167207076070376
Validation loss: 2.6689941384494067

Epoch: 5| Step: 10
Training loss: 3.1135521822296934
Validation loss: 2.6631850797885517

Epoch: 68| Step: 0
Training loss: 2.468672063056033
Validation loss: 2.6597111137857365

Epoch: 5| Step: 1
Training loss: 3.0908291061782487
Validation loss: 2.66303994419779

Epoch: 5| Step: 2
Training loss: 2.8152278810619134
Validation loss: 2.6607762541891287

Epoch: 5| Step: 3
Training loss: 2.2600734702127
Validation loss: 2.6632510955893585

Epoch: 5| Step: 4
Training loss: 3.430114163425658
Validation loss: 2.6715633870511555

Epoch: 5| Step: 5
Training loss: 2.733130820455924
Validation loss: 2.669020523032096

Epoch: 5| Step: 6
Training loss: 2.7805481786012898
Validation loss: 2.7075786823381773

Epoch: 5| Step: 7
Training loss: 3.4890339584994026
Validation loss: 2.739560827166468

Epoch: 5| Step: 8
Training loss: 3.240670826071988
Validation loss: 2.7188501911233454

Epoch: 5| Step: 9
Training loss: 3.15871582399213
Validation loss: 2.695672227687205

Epoch: 5| Step: 10
Training loss: 3.278508666999348
Validation loss: 2.6844072721057204

Epoch: 69| Step: 0
Training loss: 2.3084937782393786
Validation loss: 2.6941348491674355

Epoch: 5| Step: 1
Training loss: 2.428889986991731
Validation loss: 2.7057882146161916

Epoch: 5| Step: 2
Training loss: 3.0948715488974345
Validation loss: 2.677026298843974

Epoch: 5| Step: 3
Training loss: 2.980763112102126
Validation loss: 2.663212116816348

Epoch: 5| Step: 4
Training loss: 3.28469493407478
Validation loss: 2.651491572101161

Epoch: 5| Step: 5
Training loss: 2.9890290565035595
Validation loss: 2.642840150537066

Epoch: 5| Step: 6
Training loss: 3.1102611103409807
Validation loss: 2.638606344085614

Epoch: 5| Step: 7
Training loss: 2.9957020489855775
Validation loss: 2.636604678148692

Epoch: 5| Step: 8
Training loss: 3.1121363048171173
Validation loss: 2.636582119104732

Epoch: 5| Step: 9
Training loss: 3.1896761777102616
Validation loss: 2.634070885537564

Epoch: 5| Step: 10
Training loss: 3.3119001025277823
Validation loss: 2.632981941547596

Epoch: 70| Step: 0
Training loss: 2.988337098640698
Validation loss: 2.6314994035377435

Epoch: 5| Step: 1
Training loss: 3.2412022575866755
Validation loss: 2.633622147335134

Epoch: 5| Step: 2
Training loss: 3.1635300176458556
Validation loss: 2.636213111659617

Epoch: 5| Step: 3
Training loss: 2.558250532353194
Validation loss: 2.632475322511936

Epoch: 5| Step: 4
Training loss: 2.9341564222996803
Validation loss: 2.63346453592047

Epoch: 5| Step: 5
Training loss: 3.222872566130198
Validation loss: 2.63213952968051

Epoch: 5| Step: 6
Training loss: 2.9144239431611854
Validation loss: 2.6308382293523502

Epoch: 5| Step: 7
Training loss: 2.683909035364933
Validation loss: 2.6315550217380106

Epoch: 5| Step: 8
Training loss: 2.683391624512559
Validation loss: 2.6323861639027584

Epoch: 5| Step: 9
Training loss: 3.157405830483174
Validation loss: 2.6337936295291535

Epoch: 5| Step: 10
Training loss: 3.2202074029126506
Validation loss: 2.634683328881538

Epoch: 71| Step: 0
Training loss: 3.0862658362216
Validation loss: 2.63104304459785

Epoch: 5| Step: 1
Training loss: 3.176786782020923
Validation loss: 2.6326307164192277

Epoch: 5| Step: 2
Training loss: 3.189972610356048
Validation loss: 2.6329182076292446

Epoch: 5| Step: 3
Training loss: 3.3479317158944553
Validation loss: 2.6320423640449144

Epoch: 5| Step: 4
Training loss: 3.167411181281741
Validation loss: 2.63318378319265

Epoch: 5| Step: 5
Training loss: 3.0357176900892644
Validation loss: 2.6380957169372548

Epoch: 5| Step: 6
Training loss: 2.4122890637144843
Validation loss: 2.6439816283093998

Epoch: 5| Step: 7
Training loss: 2.754461484087548
Validation loss: 2.6895772647478626

Epoch: 5| Step: 8
Training loss: 2.9558188448617986
Validation loss: 2.687276193200284

Epoch: 5| Step: 9
Training loss: 2.735074983646374
Validation loss: 2.6546911608243966

Epoch: 5| Step: 10
Training loss: 2.7702794967553044
Validation loss: 2.6409798495535686

Epoch: 72| Step: 0
Training loss: 2.904725361906111
Validation loss: 2.636875382316897

Epoch: 5| Step: 1
Training loss: 3.4538374636189317
Validation loss: 2.633032282433944

Epoch: 5| Step: 2
Training loss: 2.36564177856139
Validation loss: 2.637700207107122

Epoch: 5| Step: 3
Training loss: 2.813160458476679
Validation loss: 2.6287935955028185

Epoch: 5| Step: 4
Training loss: 3.1500791146167626
Validation loss: 2.6279350958673264

Epoch: 5| Step: 5
Training loss: 2.7955475965803362
Validation loss: 2.6297396682235217

Epoch: 5| Step: 6
Training loss: 3.081259279063028
Validation loss: 2.6351405400387535

Epoch: 5| Step: 7
Training loss: 3.239238970117794
Validation loss: 2.634903684008777

Epoch: 5| Step: 8
Training loss: 3.294116271643792
Validation loss: 2.6391559807481975

Epoch: 5| Step: 9
Training loss: 2.8343535063915963
Validation loss: 2.6471967952368964

Epoch: 5| Step: 10
Training loss: 2.490426041949924
Validation loss: 2.6516397316816507

Epoch: 73| Step: 0
Training loss: 3.6877468479099837
Validation loss: 2.653761124395076

Epoch: 5| Step: 1
Training loss: 3.1313655870008414
Validation loss: 2.6466076736537665

Epoch: 5| Step: 2
Training loss: 2.732655534985737
Validation loss: 2.633269839328067

Epoch: 5| Step: 3
Training loss: 2.738982063326647
Validation loss: 2.6279881282994695

Epoch: 5| Step: 4
Training loss: 2.9227159891189833
Validation loss: 2.625216874062213

Epoch: 5| Step: 5
Training loss: 2.967510888353665
Validation loss: 2.6218910616611124

Epoch: 5| Step: 6
Training loss: 3.088314020131126
Validation loss: 2.6227160106393943

Epoch: 5| Step: 7
Training loss: 2.7831953296217584
Validation loss: 2.621639082683417

Epoch: 5| Step: 8
Training loss: 3.1520304660099314
Validation loss: 2.625130807847106

Epoch: 5| Step: 9
Training loss: 2.484249951556377
Validation loss: 2.6304619233848

Epoch: 5| Step: 10
Training loss: 2.8150352071996254
Validation loss: 2.6429122355734544

Epoch: 74| Step: 0
Training loss: 2.4974021765688366
Validation loss: 2.669454518662757

Epoch: 5| Step: 1
Training loss: 2.855834102610104
Validation loss: 2.7010120301871594

Epoch: 5| Step: 2
Training loss: 3.083279239764269
Validation loss: 2.71942294227986

Epoch: 5| Step: 3
Training loss: 3.3444804882108294
Validation loss: 2.736600244517477

Epoch: 5| Step: 4
Training loss: 3.4255035531422724
Validation loss: 2.695524061215749

Epoch: 5| Step: 5
Training loss: 3.1997125079234565
Validation loss: 2.6309283339662404

Epoch: 5| Step: 6
Training loss: 2.704622768815318
Validation loss: 2.6116073458749356

Epoch: 5| Step: 7
Training loss: 2.8387407052254536
Validation loss: 2.615032233172088

Epoch: 5| Step: 8
Training loss: 2.9412653713254278
Validation loss: 2.6195061448413473

Epoch: 5| Step: 9
Training loss: 2.950712480013848
Validation loss: 2.626702310915674

Epoch: 5| Step: 10
Training loss: 2.9116983513799486
Validation loss: 2.6305083362143584

Epoch: 75| Step: 0
Training loss: 3.032106416198619
Validation loss: 2.6415537015172115

Epoch: 5| Step: 1
Training loss: 3.34867054764208
Validation loss: 2.6252511583564417

Epoch: 5| Step: 2
Training loss: 2.6318070390632817
Validation loss: 2.6210432189410304

Epoch: 5| Step: 3
Training loss: 3.012111375996288
Validation loss: 2.6183895293632955

Epoch: 5| Step: 4
Training loss: 2.6526476499143166
Validation loss: 2.613924085960503

Epoch: 5| Step: 5
Training loss: 3.03721896154784
Validation loss: 2.612834592858713

Epoch: 5| Step: 6
Training loss: 3.1896681050289946
Validation loss: 2.6117709633080963

Epoch: 5| Step: 7
Training loss: 3.120790622013164
Validation loss: 2.6089367094687987

Epoch: 5| Step: 8
Training loss: 2.7545627541947333
Validation loss: 2.610701421015041

Epoch: 5| Step: 9
Training loss: 3.363952498845628
Validation loss: 2.6090203748490928

Epoch: 5| Step: 10
Training loss: 2.343979786098929
Validation loss: 2.617415791501626

Epoch: 76| Step: 0
Training loss: 3.027576540948835
Validation loss: 2.6357004461227267

Epoch: 5| Step: 1
Training loss: 2.9217982970589
Validation loss: 2.6589715979175463

Epoch: 5| Step: 2
Training loss: 2.5694625051969124
Validation loss: 2.642103234450176

Epoch: 5| Step: 3
Training loss: 2.8457138490703904
Validation loss: 2.644149110185591

Epoch: 5| Step: 4
Training loss: 3.2847810183947046
Validation loss: 2.61582378427406

Epoch: 5| Step: 5
Training loss: 3.1405250950955326
Validation loss: 2.6041156204306914

Epoch: 5| Step: 6
Training loss: 3.1631983954615133
Validation loss: 2.605744779469505

Epoch: 5| Step: 7
Training loss: 2.679358103445036
Validation loss: 2.6081642366420232

Epoch: 5| Step: 8
Training loss: 3.040690086742363
Validation loss: 2.6203429833143277

Epoch: 5| Step: 9
Training loss: 2.8761113548102677
Validation loss: 2.6220176775975226

Epoch: 5| Step: 10
Training loss: 2.892948021377939
Validation loss: 2.640731602581422

Epoch: 77| Step: 0
Training loss: 2.5667763360443665
Validation loss: 2.6271098770099557

Epoch: 5| Step: 1
Training loss: 2.4499332535662948
Validation loss: 2.6216217077068014

Epoch: 5| Step: 2
Training loss: 2.8931303147608953
Validation loss: 2.60954942243711

Epoch: 5| Step: 3
Training loss: 3.454916096840277
Validation loss: 2.6072667613019127

Epoch: 5| Step: 4
Training loss: 3.518799835990476
Validation loss: 2.5998576939750273

Epoch: 5| Step: 5
Training loss: 2.850141113535509
Validation loss: 2.5976480942020688

Epoch: 5| Step: 6
Training loss: 2.8928698921259066
Validation loss: 2.60207620372771

Epoch: 5| Step: 7
Training loss: 2.6542224101666037
Validation loss: 2.598999773436956

Epoch: 5| Step: 8
Training loss: 3.0355100290518906
Validation loss: 2.597468276728235

Epoch: 5| Step: 9
Training loss: 2.9257222514703995
Validation loss: 2.594962686458569

Epoch: 5| Step: 10
Training loss: 3.116502117634248
Validation loss: 2.5965701764898474

Epoch: 78| Step: 0
Training loss: 3.154821393599437
Validation loss: 2.5953151578034466

Epoch: 5| Step: 1
Training loss: 3.1395629301633776
Validation loss: 2.593354745700497

Epoch: 5| Step: 2
Training loss: 2.819461345360957
Validation loss: 2.596179870198308

Epoch: 5| Step: 3
Training loss: 3.2718398535880167
Validation loss: 2.5925611738427627

Epoch: 5| Step: 4
Training loss: 2.8288799142441285
Validation loss: 2.5950039381220646

Epoch: 5| Step: 5
Training loss: 2.8390232249321423
Validation loss: 2.603806853673496

Epoch: 5| Step: 6
Training loss: 2.8419925163540976
Validation loss: 2.597782605342794

Epoch: 5| Step: 7
Training loss: 2.682864427369473
Validation loss: 2.5928843467459743

Epoch: 5| Step: 8
Training loss: 2.739835507543918
Validation loss: 2.5918135003513214

Epoch: 5| Step: 9
Training loss: 2.919231994170901
Validation loss: 2.5901110499768483

Epoch: 5| Step: 10
Training loss: 3.167663333719127
Validation loss: 2.588973525910995

Epoch: 79| Step: 0
Training loss: 2.84870545952104
Validation loss: 2.589312764245778

Epoch: 5| Step: 1
Training loss: 2.66016431630798
Validation loss: 2.59018838034956

Epoch: 5| Step: 2
Training loss: 3.5215579007767213
Validation loss: 2.5882261799581436

Epoch: 5| Step: 3
Training loss: 2.8065651901397026
Validation loss: 2.5871030934564287

Epoch: 5| Step: 4
Training loss: 2.8626230271733517
Validation loss: 2.58447336399877

Epoch: 5| Step: 5
Training loss: 3.0438293885329024
Validation loss: 2.585693874320331

Epoch: 5| Step: 6
Training loss: 2.591092966329528
Validation loss: 2.5856546058195136

Epoch: 5| Step: 7
Training loss: 3.1019911001484823
Validation loss: 2.587692218092998

Epoch: 5| Step: 8
Training loss: 3.338516560587559
Validation loss: 2.586339660726155

Epoch: 5| Step: 9
Training loss: 2.5907254336483616
Validation loss: 2.585647968802953

Epoch: 5| Step: 10
Training loss: 2.8655051303032826
Validation loss: 2.590289648666775

Epoch: 80| Step: 0
Training loss: 2.7396452767412436
Validation loss: 2.606235268957131

Epoch: 5| Step: 1
Training loss: 2.659335330438649
Validation loss: 2.64167187627691

Epoch: 5| Step: 2
Training loss: 2.9240596987869987
Validation loss: 2.659151160456996

Epoch: 5| Step: 3
Training loss: 3.26107821999433
Validation loss: 2.6573395937909927

Epoch: 5| Step: 4
Training loss: 3.0005610259311366
Validation loss: 2.6519421839159563

Epoch: 5| Step: 5
Training loss: 2.7608105840262898
Validation loss: 2.6564840301744357

Epoch: 5| Step: 6
Training loss: 3.1931889946424046
Validation loss: 2.6390456386427665

Epoch: 5| Step: 7
Training loss: 2.8391671614389424
Validation loss: 2.6408481065554636

Epoch: 5| Step: 8
Training loss: 3.1869446513765345
Validation loss: 2.634571731012821

Epoch: 5| Step: 9
Training loss: 2.7829336149664186
Validation loss: 2.6157215208168094

Epoch: 5| Step: 10
Training loss: 3.2157645592836284
Validation loss: 2.6201593395511935

Epoch: 81| Step: 0
Training loss: 2.864728741278727
Validation loss: 2.6047461874342632

Epoch: 5| Step: 1
Training loss: 3.0890008714748154
Validation loss: 2.6061840789627095

Epoch: 5| Step: 2
Training loss: 2.7723761448485646
Validation loss: 2.6026155212421664

Epoch: 5| Step: 3
Training loss: 3.5004185017651817
Validation loss: 2.60684296905427

Epoch: 5| Step: 4
Training loss: 3.030618503506165
Validation loss: 2.6043348695311446

Epoch: 5| Step: 5
Training loss: 2.790616668312818
Validation loss: 2.6019465808313886

Epoch: 5| Step: 6
Training loss: 2.901977844584866
Validation loss: 2.5973874761314795

Epoch: 5| Step: 7
Training loss: 2.97891870991772
Validation loss: 2.600119466498049

Epoch: 5| Step: 8
Training loss: 2.8114958772040555
Validation loss: 2.601999762636676

Epoch: 5| Step: 9
Training loss: 2.912779497480017
Validation loss: 2.596383570619993

Epoch: 5| Step: 10
Training loss: 2.661129407968006
Validation loss: 2.603037857204107

Epoch: 82| Step: 0
Training loss: 2.6799296722863604
Validation loss: 2.6147847179955206

Epoch: 5| Step: 1
Training loss: 2.7548754562501485
Validation loss: 2.6433058356555956

Epoch: 5| Step: 2
Training loss: 2.6724512917600265
Validation loss: 2.690570241326985

Epoch: 5| Step: 3
Training loss: 3.2339216273901954
Validation loss: 2.659058252148355

Epoch: 5| Step: 4
Training loss: 3.3019097379828004
Validation loss: 2.6036651223520804

Epoch: 5| Step: 5
Training loss: 2.7859357302195287
Validation loss: 2.588001502787097

Epoch: 5| Step: 6
Training loss: 3.1976220474632164
Validation loss: 2.5836003982869853

Epoch: 5| Step: 7
Training loss: 2.948743203330363
Validation loss: 2.583262966228394

Epoch: 5| Step: 8
Training loss: 2.2996550881877234
Validation loss: 2.5821585536099696

Epoch: 5| Step: 9
Training loss: 3.3673807960487845
Validation loss: 2.5835594209967967

Epoch: 5| Step: 10
Training loss: 2.98475812280254
Validation loss: 2.5862075183376385

Epoch: 83| Step: 0
Training loss: 3.2184894048881754
Validation loss: 2.5872733585350693

Epoch: 5| Step: 1
Training loss: 3.219035311896003
Validation loss: 2.5835670933730537

Epoch: 5| Step: 2
Training loss: 2.797710698760896
Validation loss: 2.5838215479412723

Epoch: 5| Step: 3
Training loss: 2.957881588539556
Validation loss: 2.5829122645422236

Epoch: 5| Step: 4
Training loss: 2.7332868754307698
Validation loss: 2.5834820450192635

Epoch: 5| Step: 5
Training loss: 2.3438738980923635
Validation loss: 2.5833315424229837

Epoch: 5| Step: 6
Training loss: 3.1237134192356213
Validation loss: 2.5855766510316984

Epoch: 5| Step: 7
Training loss: 3.0203418901950476
Validation loss: 2.584209980781139

Epoch: 5| Step: 8
Training loss: 3.3464390289985393
Validation loss: 2.582925559565212

Epoch: 5| Step: 9
Training loss: 2.6548948533669052
Validation loss: 2.583087400015949

Epoch: 5| Step: 10
Training loss: 2.8160412005531614
Validation loss: 2.5941957678053202

Epoch: 84| Step: 0
Training loss: 3.2416015095442696
Validation loss: 2.6027095706885297

Epoch: 5| Step: 1
Training loss: 3.0401625027641024
Validation loss: 2.601248399000239

Epoch: 5| Step: 2
Training loss: 2.9313309192672112
Validation loss: 2.5982565392931476

Epoch: 5| Step: 3
Training loss: 2.8617545477367026
Validation loss: 2.6104728173039606

Epoch: 5| Step: 4
Training loss: 2.864267301755079
Validation loss: 2.6442646288394456

Epoch: 5| Step: 5
Training loss: 2.999750444840911
Validation loss: 2.6397248585988735

Epoch: 5| Step: 6
Training loss: 2.7675548652096857
Validation loss: 2.606568033510587

Epoch: 5| Step: 7
Training loss: 3.171963093854406
Validation loss: 2.6136349331204443

Epoch: 5| Step: 8
Training loss: 2.9107603124645376
Validation loss: 2.6176788794458914

Epoch: 5| Step: 9
Training loss: 3.0795619340959224
Validation loss: 2.620856028495942

Epoch: 5| Step: 10
Training loss: 2.500820692776804
Validation loss: 2.6258218712122283

Epoch: 85| Step: 0
Training loss: 2.782806560974809
Validation loss: 2.626572646192298

Epoch: 5| Step: 1
Training loss: 2.5304175055774807
Validation loss: 2.6400106003748283

Epoch: 5| Step: 2
Training loss: 3.0832727443481285
Validation loss: 2.6575222310438384

Epoch: 5| Step: 3
Training loss: 3.543941276003488
Validation loss: 2.6711911924782212

Epoch: 5| Step: 4
Training loss: 2.888071282751333
Validation loss: 2.665911250892457

Epoch: 5| Step: 5
Training loss: 2.943086870991102
Validation loss: 2.6366604015923643

Epoch: 5| Step: 6
Training loss: 2.526584988920379
Validation loss: 2.623806756936463

Epoch: 5| Step: 7
Training loss: 3.1020393677604643
Validation loss: 2.620831578064655

Epoch: 5| Step: 8
Training loss: 3.39005946351959
Validation loss: 2.6158026631103484

Epoch: 5| Step: 9
Training loss: 2.866103962814186
Validation loss: 2.6120049556088487

Epoch: 5| Step: 10
Training loss: 2.7037896899142093
Validation loss: 2.6145039126237983

Epoch: 86| Step: 0
Training loss: 2.3005153327469072
Validation loss: 2.613580859063978

Epoch: 5| Step: 1
Training loss: 2.702643908428219
Validation loss: 2.612748714351595

Epoch: 5| Step: 2
Training loss: 2.7556879002397627
Validation loss: 2.609788959205087

Epoch: 5| Step: 3
Training loss: 2.846425233857105
Validation loss: 2.610807365501562

Epoch: 5| Step: 4
Training loss: 3.176035290231348
Validation loss: 2.611967577492596

Epoch: 5| Step: 5
Training loss: 3.025785574305424
Validation loss: 2.6121424362831105

Epoch: 5| Step: 6
Training loss: 3.3197674472205865
Validation loss: 2.612503964008539

Epoch: 5| Step: 7
Training loss: 3.4121588456094623
Validation loss: 2.619447896496926

Epoch: 5| Step: 8
Training loss: 3.37055139168059
Validation loss: 2.6153988104330956

Epoch: 5| Step: 9
Training loss: 2.6313953604154894
Validation loss: 2.6123692677975434

Epoch: 5| Step: 10
Training loss: 2.7833330733095454
Validation loss: 2.606670390529452

Epoch: 87| Step: 0
Training loss: 3.2200615442211316
Validation loss: 2.6118465864283733

Epoch: 5| Step: 1
Training loss: 2.55394470428615
Validation loss: 2.6108771766419974

Epoch: 5| Step: 2
Training loss: 2.750260080696844
Validation loss: 2.609144649024085

Epoch: 5| Step: 3
Training loss: 2.968876564941919
Validation loss: 2.607673883866674

Epoch: 5| Step: 4
Training loss: 3.4710452072729647
Validation loss: 2.6105919649645832

Epoch: 5| Step: 5
Training loss: 3.0756492921691203
Validation loss: 2.6126538625404034

Epoch: 5| Step: 6
Training loss: 2.617942131906655
Validation loss: 2.6157698191708763

Epoch: 5| Step: 7
Training loss: 2.6287183311829483
Validation loss: 2.620884990947652

Epoch: 5| Step: 8
Training loss: 2.88637993957459
Validation loss: 2.6311555579638792

Epoch: 5| Step: 9
Training loss: 3.1098034434132713
Validation loss: 2.6328509151976216

Epoch: 5| Step: 10
Training loss: 3.083797282462206
Validation loss: 2.639818077340218

Epoch: 88| Step: 0
Training loss: 2.9317226004528223
Validation loss: 2.6352062933368763

Epoch: 5| Step: 1
Training loss: 2.5582555649293415
Validation loss: 2.635266841384626

Epoch: 5| Step: 2
Training loss: 3.655483458934328
Validation loss: 2.6298444572776583

Epoch: 5| Step: 3
Training loss: 2.7679220024982754
Validation loss: 2.6198941727749587

Epoch: 5| Step: 4
Training loss: 3.210461212251837
Validation loss: 2.614846587956456

Epoch: 5| Step: 5
Training loss: 2.098612476816609
Validation loss: 2.609486804021228

Epoch: 5| Step: 6
Training loss: 2.7537937871817046
Validation loss: 2.6100479200486517

Epoch: 5| Step: 7
Training loss: 3.2273316286404694
Validation loss: 2.6176931691965204

Epoch: 5| Step: 8
Training loss: 3.1359576564382423
Validation loss: 2.6150089703998565

Epoch: 5| Step: 9
Training loss: 3.1823830016536143
Validation loss: 2.6090863442568692

Epoch: 5| Step: 10
Training loss: 2.513543351688339
Validation loss: 2.6066562940941234

Epoch: 89| Step: 0
Training loss: 2.9848213860573027
Validation loss: 2.6034760098695604

Epoch: 5| Step: 1
Training loss: 3.1949923851626876
Validation loss: 2.6069451490855853

Epoch: 5| Step: 2
Training loss: 2.786825356718224
Validation loss: 2.609579671076518

Epoch: 5| Step: 3
Training loss: 3.0086476937536895
Validation loss: 2.6182656871362497

Epoch: 5| Step: 4
Training loss: 2.8834702483141035
Validation loss: 2.6147322648872096

Epoch: 5| Step: 5
Training loss: 3.3229209078738773
Validation loss: 2.6086775808264244

Epoch: 5| Step: 6
Training loss: 2.733369653351927
Validation loss: 2.6084314813841774

Epoch: 5| Step: 7
Training loss: 2.5054869519991882
Validation loss: 2.6087100482470333

Epoch: 5| Step: 8
Training loss: 2.835345245814673
Validation loss: 2.61161064416061

Epoch: 5| Step: 9
Training loss: 3.069756299762116
Validation loss: 2.6165452659237487

Epoch: 5| Step: 10
Training loss: 2.9359693394548994
Validation loss: 2.610726705738347

Epoch: 90| Step: 0
Training loss: 2.892000767941195
Validation loss: 2.609726179047599

Epoch: 5| Step: 1
Training loss: 2.8844227829237195
Validation loss: 2.6034844260796626

Epoch: 5| Step: 2
Training loss: 3.325176526883426
Validation loss: 2.6042091126623133

Epoch: 5| Step: 3
Training loss: 2.7539323088583134
Validation loss: 2.6058156456145953

Epoch: 5| Step: 4
Training loss: 3.009575186119018
Validation loss: 2.6053520612271646

Epoch: 5| Step: 5
Training loss: 2.543368306684037
Validation loss: 2.611997140041394

Epoch: 5| Step: 6
Training loss: 3.203185587984527
Validation loss: 2.614807931780376

Epoch: 5| Step: 7
Training loss: 2.9089605345555243
Validation loss: 2.632245386077491

Epoch: 5| Step: 8
Training loss: 3.4368893167600234
Validation loss: 2.647056452552848

Epoch: 5| Step: 9
Training loss: 2.8865609958269363
Validation loss: 2.625977487996034

Epoch: 5| Step: 10
Training loss: 2.1904941231327246
Validation loss: 2.610357789041466

Epoch: 91| Step: 0
Training loss: 2.9943930363375637
Validation loss: 2.6026928169544963

Epoch: 5| Step: 1
Training loss: 2.929499017374447
Validation loss: 2.5889893089010987

Epoch: 5| Step: 2
Training loss: 2.6675879456627967
Validation loss: 2.590816520697822

Epoch: 5| Step: 3
Training loss: 3.2527165430394933
Validation loss: 2.588629829148479

Epoch: 5| Step: 4
Training loss: 2.790028124431657
Validation loss: 2.574856240321245

Epoch: 5| Step: 5
Training loss: 3.1436858942309924
Validation loss: 2.563408383229923

Epoch: 5| Step: 6
Training loss: 2.7881046648615793
Validation loss: 2.55210472903262

Epoch: 5| Step: 7
Training loss: 3.091149055631394
Validation loss: 2.5506397628872564

Epoch: 5| Step: 8
Training loss: 3.0935836901420006
Validation loss: 2.5546759335798974

Epoch: 5| Step: 9
Training loss: 2.834010959450604
Validation loss: 2.5559295889144473

Epoch: 5| Step: 10
Training loss: 2.5082996881537185
Validation loss: 2.557421657632711

Epoch: 92| Step: 0
Training loss: 2.6492549568656187
Validation loss: 2.5568033812388578

Epoch: 5| Step: 1
Training loss: 3.14099452943031
Validation loss: 2.56970187043854

Epoch: 5| Step: 2
Training loss: 3.2726108718170206
Validation loss: 2.5742583064765756

Epoch: 5| Step: 3
Training loss: 2.716047675948886
Validation loss: 2.589629478130242

Epoch: 5| Step: 4
Training loss: 2.9149312624016313
Validation loss: 2.5921099454587018

Epoch: 5| Step: 5
Training loss: 3.076491953833846
Validation loss: 2.6179802707880793

Epoch: 5| Step: 6
Training loss: 3.2463099732439002
Validation loss: 2.6256986822081094

Epoch: 5| Step: 7
Training loss: 2.223290753431047
Validation loss: 2.6011893643395463

Epoch: 5| Step: 8
Training loss: 3.179971518239043
Validation loss: 2.5984657799539157

Epoch: 5| Step: 9
Training loss: 2.8792674693354114
Validation loss: 2.553348064308894

Epoch: 5| Step: 10
Training loss: 2.477046113072799
Validation loss: 2.5516590307299403

Epoch: 93| Step: 0
Training loss: 2.338334094876931
Validation loss: 2.553163755716681

Epoch: 5| Step: 1
Training loss: 2.714120892131014
Validation loss: 2.5590604562951484

Epoch: 5| Step: 2
Training loss: 2.669953039806455
Validation loss: 2.559527123564613

Epoch: 5| Step: 3
Training loss: 2.7532228311742886
Validation loss: 2.5557200129751023

Epoch: 5| Step: 4
Training loss: 2.753914388008809
Validation loss: 2.5549946713480804

Epoch: 5| Step: 5
Training loss: 3.1042843653406558
Validation loss: 2.5504196828589816

Epoch: 5| Step: 6
Training loss: 3.2160450949187993
Validation loss: 2.5488374357800345

Epoch: 5| Step: 7
Training loss: 3.166038517807425
Validation loss: 2.5498082798855592

Epoch: 5| Step: 8
Training loss: 3.037958488868854
Validation loss: 2.548951641694048

Epoch: 5| Step: 9
Training loss: 3.1036145702839626
Validation loss: 2.556620291398544

Epoch: 5| Step: 10
Training loss: 3.169455070228904
Validation loss: 2.588700322046844

Epoch: 94| Step: 0
Training loss: 2.7667280680572284
Validation loss: 2.640963064854852

Epoch: 5| Step: 1
Training loss: 2.8121647952914253
Validation loss: 2.6548551194112915

Epoch: 5| Step: 2
Training loss: 2.3457611610417843
Validation loss: 2.6446749614413845

Epoch: 5| Step: 3
Training loss: 2.8444886977342847
Validation loss: 2.6527064198092707

Epoch: 5| Step: 4
Training loss: 2.8058626481071243
Validation loss: 2.6268898157244154

Epoch: 5| Step: 5
Training loss: 3.0636034164941597
Validation loss: 2.6315321320162135

Epoch: 5| Step: 6
Training loss: 2.968876083105925
Validation loss: 2.6275312951289984

Epoch: 5| Step: 7
Training loss: 3.0424782353972906
Validation loss: 2.6275756688694005

Epoch: 5| Step: 8
Training loss: 2.81109287241806
Validation loss: 2.6001697712033778

Epoch: 5| Step: 9
Training loss: 3.1858353101235446
Validation loss: 2.570873107724797

Epoch: 5| Step: 10
Training loss: 3.3639323704166255
Validation loss: 2.5437785136314437

Epoch: 95| Step: 0
Training loss: 3.0184109325604247
Validation loss: 2.547987010123197

Epoch: 5| Step: 1
Training loss: 3.4251015139940817
Validation loss: 2.558460434082567

Epoch: 5| Step: 2
Training loss: 2.3972417478722705
Validation loss: 2.5748877701881585

Epoch: 5| Step: 3
Training loss: 3.4891956322737654
Validation loss: 2.603771692327943

Epoch: 5| Step: 4
Training loss: 2.8963989327523456
Validation loss: 2.563880453533341

Epoch: 5| Step: 5
Training loss: 2.355562477081654
Validation loss: 2.553152499691756

Epoch: 5| Step: 6
Training loss: 3.3105356401911137
Validation loss: 2.5477870211874314

Epoch: 5| Step: 7
Training loss: 2.815779321232857
Validation loss: 2.545566375894386

Epoch: 5| Step: 8
Training loss: 2.9518355526490314
Validation loss: 2.5523325440355387

Epoch: 5| Step: 9
Training loss: 2.9294674396518676
Validation loss: 2.568103308537713

Epoch: 5| Step: 10
Training loss: 2.4021110111791413
Validation loss: 2.6055918721935574

Epoch: 96| Step: 0
Training loss: 3.204141595061937
Validation loss: 2.60829224429463

Epoch: 5| Step: 1
Training loss: 2.6736700263419797
Validation loss: 2.5943032366691097

Epoch: 5| Step: 2
Training loss: 3.2403191388099244
Validation loss: 2.6126981877216786

Epoch: 5| Step: 3
Training loss: 3.1123580042303267
Validation loss: 2.5675545410740166

Epoch: 5| Step: 4
Training loss: 2.6009783848000394
Validation loss: 2.541440967508934

Epoch: 5| Step: 5
Training loss: 2.909693329110512
Validation loss: 2.5387171366697023

Epoch: 5| Step: 6
Training loss: 2.490981907561765
Validation loss: 2.5391396161682733

Epoch: 5| Step: 7
Training loss: 3.1543930180781214
Validation loss: 2.5358411614996847

Epoch: 5| Step: 8
Training loss: 3.077102723746049
Validation loss: 2.5341667265217485

Epoch: 5| Step: 9
Training loss: 2.6099126570253315
Validation loss: 2.531098117522883

Epoch: 5| Step: 10
Training loss: 2.6901609864685936
Validation loss: 2.5314039292165718

Epoch: 97| Step: 0
Training loss: 2.9336665686701364
Validation loss: 2.532666677760014

Epoch: 5| Step: 1
Training loss: 2.9313984261941024
Validation loss: 2.540409272018971

Epoch: 5| Step: 2
Training loss: 2.9668555388888174
Validation loss: 2.557552951769022

Epoch: 5| Step: 3
Training loss: 2.790122463861091
Validation loss: 2.555311830358945

Epoch: 5| Step: 4
Training loss: 3.5596595282029537
Validation loss: 2.5536176655348233

Epoch: 5| Step: 5
Training loss: 2.9580450499575095
Validation loss: 2.5406490920180733

Epoch: 5| Step: 6
Training loss: 2.656830129664037
Validation loss: 2.5362665954987182

Epoch: 5| Step: 7
Training loss: 2.5463501559125983
Validation loss: 2.5288257198846273

Epoch: 5| Step: 8
Training loss: 2.791020664987358
Validation loss: 2.5284561803058345

Epoch: 5| Step: 9
Training loss: 3.1658773609730493
Validation loss: 2.528587947851321

Epoch: 5| Step: 10
Training loss: 2.470529035986294
Validation loss: 2.5288409162096883

Epoch: 98| Step: 0
Training loss: 2.9662116191067236
Validation loss: 2.5262505865564444

Epoch: 5| Step: 1
Training loss: 2.844448129664789
Validation loss: 2.529375071363443

Epoch: 5| Step: 2
Training loss: 2.639923995831295
Validation loss: 2.5293070401571716

Epoch: 5| Step: 3
Training loss: 3.3884978060029227
Validation loss: 2.5279519104038237

Epoch: 5| Step: 4
Training loss: 2.4183349332096515
Validation loss: 2.5330713531164406

Epoch: 5| Step: 5
Training loss: 2.585007699183909
Validation loss: 2.534015353735635

Epoch: 5| Step: 6
Training loss: 2.5542153204992135
Validation loss: 2.5413950646049717

Epoch: 5| Step: 7
Training loss: 3.5651831979214212
Validation loss: 2.543056113969723

Epoch: 5| Step: 8
Training loss: 3.2204073000321847
Validation loss: 2.5530093761624886

Epoch: 5| Step: 9
Training loss: 2.7510535216205447
Validation loss: 2.550278354116846

Epoch: 5| Step: 10
Training loss: 2.614645107395681
Validation loss: 2.554542466389064

Epoch: 99| Step: 0
Training loss: 2.906160578838953
Validation loss: 2.5519734408986765

Epoch: 5| Step: 1
Training loss: 3.0767163766610905
Validation loss: 2.546293773018026

Epoch: 5| Step: 2
Training loss: 3.0054286477150556
Validation loss: 2.550799989932206

Epoch: 5| Step: 3
Training loss: 2.9847934289762277
Validation loss: 2.539710779215873

Epoch: 5| Step: 4
Training loss: 2.656940505091376
Validation loss: 2.5373308636303586

Epoch: 5| Step: 5
Training loss: 3.1005903973885247
Validation loss: 2.534343529105984

Epoch: 5| Step: 6
Training loss: 3.1820355118185155
Validation loss: 2.530765776285033

Epoch: 5| Step: 7
Training loss: 2.3798878215350445
Validation loss: 2.5247990046455673

Epoch: 5| Step: 8
Training loss: 2.991434425825047
Validation loss: 2.5250230473185673

Epoch: 5| Step: 9
Training loss: 2.862865381367677
Validation loss: 2.5252591378140004

Epoch: 5| Step: 10
Training loss: 2.4845582906418535
Validation loss: 2.525858323488901

Epoch: 100| Step: 0
Training loss: 3.0664320634860944
Validation loss: 2.527583510396651

Epoch: 5| Step: 1
Training loss: 2.864355700147126
Validation loss: 2.5229112574273937

Epoch: 5| Step: 2
Training loss: 2.948994326105154
Validation loss: 2.5265270386342285

Epoch: 5| Step: 3
Training loss: 2.9774586687654527
Validation loss: 2.5247227105815773

Epoch: 5| Step: 4
Training loss: 2.8673237032852406
Validation loss: 2.526728913206069

Epoch: 5| Step: 5
Training loss: 2.4626782270503376
Validation loss: 2.524977165767902

Epoch: 5| Step: 6
Training loss: 2.7665053006494906
Validation loss: 2.522815909836652

Epoch: 5| Step: 7
Training loss: 2.7943579573379274
Validation loss: 2.5234217631659126

Epoch: 5| Step: 8
Training loss: 3.195436955572138
Validation loss: 2.52623296651201

Epoch: 5| Step: 9
Training loss: 3.0404957821275223
Validation loss: 2.5374188450439674

Epoch: 5| Step: 10
Training loss: 2.6142197820998745
Validation loss: 2.532907918079975

Epoch: 101| Step: 0
Training loss: 2.7831503558594015
Validation loss: 2.5449020451329156

Epoch: 5| Step: 1
Training loss: 3.108964289084978
Validation loss: 2.55272759615241

Epoch: 5| Step: 2
Training loss: 3.288917375203507
Validation loss: 2.5808196105303995

Epoch: 5| Step: 3
Training loss: 3.5037357284576425
Validation loss: 2.566916218132239

Epoch: 5| Step: 4
Training loss: 3.0809672444505076
Validation loss: 2.539977009471947

Epoch: 5| Step: 5
Training loss: 2.252084190610804
Validation loss: 2.529158590748221

Epoch: 5| Step: 6
Training loss: 2.9115411317865596
Validation loss: 2.5230580960949642

Epoch: 5| Step: 7
Training loss: 2.4576272650952187
Validation loss: 2.5199546682665845

Epoch: 5| Step: 8
Training loss: 2.835046549419944
Validation loss: 2.5202281286092765

Epoch: 5| Step: 9
Training loss: 2.272461042416467
Validation loss: 2.5203824482015267

Epoch: 5| Step: 10
Training loss: 3.2144407295510034
Validation loss: 2.5220252713870472

Epoch: 102| Step: 0
Training loss: 2.4752902544695785
Validation loss: 2.524417938808938

Epoch: 5| Step: 1
Training loss: 2.783319367775363
Validation loss: 2.518456020373321

Epoch: 5| Step: 2
Training loss: 2.9005165560834603
Validation loss: 2.517188923432178

Epoch: 5| Step: 3
Training loss: 2.6283694848682932
Validation loss: 2.5114259460668964

Epoch: 5| Step: 4
Training loss: 2.9702274862180595
Validation loss: 2.525381540440532

Epoch: 5| Step: 5
Training loss: 3.056142475132353
Validation loss: 2.531300724381672

Epoch: 5| Step: 6
Training loss: 2.7690560130870017
Validation loss: 2.5313349250899333

Epoch: 5| Step: 7
Training loss: 3.0259488343768473
Validation loss: 2.5407893813387554

Epoch: 5| Step: 8
Training loss: 3.210297383826386
Validation loss: 2.5308664107970484

Epoch: 5| Step: 9
Training loss: 2.7510188556165005
Validation loss: 2.5292761279789975

Epoch: 5| Step: 10
Training loss: 3.214238087740262
Validation loss: 2.534172612181812

Epoch: 103| Step: 0
Training loss: 3.1306232974976345
Validation loss: 2.519959155731743

Epoch: 5| Step: 1
Training loss: 3.4058566085011415
Validation loss: 2.5185494687135184

Epoch: 5| Step: 2
Training loss: 3.029306319496883
Validation loss: 2.519240689214914

Epoch: 5| Step: 3
Training loss: 2.6572534797423875
Validation loss: 2.515432762281443

Epoch: 5| Step: 4
Training loss: 2.7429056558547846
Validation loss: 2.5192739551348486

Epoch: 5| Step: 5
Training loss: 2.9695194251174555
Validation loss: 2.517109431857591

Epoch: 5| Step: 6
Training loss: 2.240206916993344
Validation loss: 2.5218264105834622

Epoch: 5| Step: 7
Training loss: 3.0859144765260598
Validation loss: 2.524122976025333

Epoch: 5| Step: 8
Training loss: 2.926662500794153
Validation loss: 2.520844061786382

Epoch: 5| Step: 9
Training loss: 2.712458027457792
Validation loss: 2.5195338303963823

Epoch: 5| Step: 10
Training loss: 2.5247468651516853
Validation loss: 2.522578405697592

Epoch: 104| Step: 0
Training loss: 2.827982019003071
Validation loss: 2.5222947587893936

Epoch: 5| Step: 1
Training loss: 2.9904552256069414
Validation loss: 2.5257011320201213

Epoch: 5| Step: 2
Training loss: 2.6679585625606195
Validation loss: 2.528677500744929

Epoch: 5| Step: 3
Training loss: 3.2175234337155634
Validation loss: 2.5242979928772296

Epoch: 5| Step: 4
Training loss: 3.0822034432351675
Validation loss: 2.5259315242589753

Epoch: 5| Step: 5
Training loss: 2.5543039016405302
Validation loss: 2.5245639028461633

Epoch: 5| Step: 6
Training loss: 2.6496437948972775
Validation loss: 2.5328273135319854

Epoch: 5| Step: 7
Training loss: 2.856340810054212
Validation loss: 2.530971255007842

Epoch: 5| Step: 8
Training loss: 3.028638521001401
Validation loss: 2.5284668968618447

Epoch: 5| Step: 9
Training loss: 2.917405734202314
Validation loss: 2.5244578765293175

Epoch: 5| Step: 10
Training loss: 2.7460083168165004
Validation loss: 2.517432919898268

Epoch: 105| Step: 0
Training loss: 2.7486596742563116
Validation loss: 2.511139239569516

Epoch: 5| Step: 1
Training loss: 2.9159096598295204
Validation loss: 2.5119216064634386

Epoch: 5| Step: 2
Training loss: 2.3906162236869135
Validation loss: 2.508789905537464

Epoch: 5| Step: 3
Training loss: 2.6709870764827817
Validation loss: 2.5103380761711795

Epoch: 5| Step: 4
Training loss: 2.9118581825977587
Validation loss: 2.5086126478682775

Epoch: 5| Step: 5
Training loss: 2.892388543015037
Validation loss: 2.506997313154219

Epoch: 5| Step: 6
Training loss: 3.0220756519373757
Validation loss: 2.508230868632754

Epoch: 5| Step: 7
Training loss: 2.5307966226580847
Validation loss: 2.5104408223851955

Epoch: 5| Step: 8
Training loss: 3.018022286031356
Validation loss: 2.510111976187818

Epoch: 5| Step: 9
Training loss: 3.413199798038217
Validation loss: 2.514618140329935

Epoch: 5| Step: 10
Training loss: 3.0058336758769824
Validation loss: 2.5142494965380395

Epoch: 106| Step: 0
Training loss: 3.2509673219585555
Validation loss: 2.521085250770357

Epoch: 5| Step: 1
Training loss: 3.069660146584202
Validation loss: 2.51924861242554

Epoch: 5| Step: 2
Training loss: 3.017190319437283
Validation loss: 2.5258320328896375

Epoch: 5| Step: 3
Training loss: 2.9794403341726814
Validation loss: 2.5324785134496537

Epoch: 5| Step: 4
Training loss: 2.5920042114576813
Validation loss: 2.5255923681079198

Epoch: 5| Step: 5
Training loss: 2.3916541982008965
Validation loss: 2.5243067614278782

Epoch: 5| Step: 6
Training loss: 3.107776633583573
Validation loss: 2.537097772902995

Epoch: 5| Step: 7
Training loss: 2.962121731715869
Validation loss: 2.5410085702295166

Epoch: 5| Step: 8
Training loss: 2.4870949496867474
Validation loss: 2.5420221896752917

Epoch: 5| Step: 9
Training loss: 3.1171327361456678
Validation loss: 2.540632032970358

Epoch: 5| Step: 10
Training loss: 2.3140073451566052
Validation loss: 2.5310809277606654

Epoch: 107| Step: 0
Training loss: 2.743563141249345
Validation loss: 2.5350528358891156

Epoch: 5| Step: 1
Training loss: 2.65502255072778
Validation loss: 2.542231436655555

Epoch: 5| Step: 2
Training loss: 2.9931202522792986
Validation loss: 2.53718606754833

Epoch: 5| Step: 3
Training loss: 2.849003058622358
Validation loss: 2.552999201950471

Epoch: 5| Step: 4
Training loss: 2.7448228307085247
Validation loss: 2.5550492949862003

Epoch: 5| Step: 5
Training loss: 2.698294584888685
Validation loss: 2.5600919125881627

Epoch: 5| Step: 6
Training loss: 3.0656675189974747
Validation loss: 2.5402838746179106

Epoch: 5| Step: 7
Training loss: 3.354672569522405
Validation loss: 2.5315905480781122

Epoch: 5| Step: 8
Training loss: 2.6309855203610697
Validation loss: 2.517995666217708

Epoch: 5| Step: 9
Training loss: 2.9659569702216757
Validation loss: 2.519641856686066

Epoch: 5| Step: 10
Training loss: 2.7824119112478223
Validation loss: 2.5215137315685117

Epoch: 108| Step: 0
Training loss: 3.05753266112006
Validation loss: 2.5139080229610635

Epoch: 5| Step: 1
Training loss: 2.401453464194578
Validation loss: 2.516823863766349

Epoch: 5| Step: 2
Training loss: 2.6283693034489084
Validation loss: 2.5140694851153276

Epoch: 5| Step: 3
Training loss: 2.9101590354957305
Validation loss: 2.524696769648141

Epoch: 5| Step: 4
Training loss: 3.087769401627089
Validation loss: 2.5298260778344983

Epoch: 5| Step: 5
Training loss: 2.787113737705722
Validation loss: 2.534492709589677

Epoch: 5| Step: 6
Training loss: 2.9474774000807566
Validation loss: 2.5187097885214436

Epoch: 5| Step: 7
Training loss: 2.919564868956991
Validation loss: 2.517907726973572

Epoch: 5| Step: 8
Training loss: 3.315406244164171
Validation loss: 2.515416781725947

Epoch: 5| Step: 9
Training loss: 2.7614516327348704
Validation loss: 2.513315201141192

Epoch: 5| Step: 10
Training loss: 2.6100642042192153
Validation loss: 2.5182990621523276

Epoch: 109| Step: 0
Training loss: 2.8173631796326344
Validation loss: 2.514306504214959

Epoch: 5| Step: 1
Training loss: 2.4614824932869825
Validation loss: 2.5218759114893974

Epoch: 5| Step: 2
Training loss: 2.762776173729372
Validation loss: 2.5268289556821943

Epoch: 5| Step: 3
Training loss: 2.9410456908826452
Validation loss: 2.5281644351755905

Epoch: 5| Step: 4
Training loss: 2.9132638609027826
Validation loss: 2.5167028713684907

Epoch: 5| Step: 5
Training loss: 3.008157447752486
Validation loss: 2.519036916964643

Epoch: 5| Step: 6
Training loss: 2.4777444131122532
Validation loss: 2.5135086855265034

Epoch: 5| Step: 7
Training loss: 2.8704248596360946
Validation loss: 2.517343688006863

Epoch: 5| Step: 8
Training loss: 3.0620017132894457
Validation loss: 2.507879703605077

Epoch: 5| Step: 9
Training loss: 2.564149465254234
Validation loss: 2.5124894533490556

Epoch: 5| Step: 10
Training loss: 3.566748779159768
Validation loss: 2.5067958407292426

Epoch: 110| Step: 0
Training loss: 2.524067141750725
Validation loss: 2.508166259373273

Epoch: 5| Step: 1
Training loss: 3.121110402851772
Validation loss: 2.505650056681019

Epoch: 5| Step: 2
Training loss: 2.775200425891728
Validation loss: 2.500522013483048

Epoch: 5| Step: 3
Training loss: 2.5991862674262305
Validation loss: 2.5094961068989727

Epoch: 5| Step: 4
Training loss: 2.9730359109454088
Validation loss: 2.5068181901969533

Epoch: 5| Step: 5
Training loss: 3.0534073666866064
Validation loss: 2.508392697240515

Epoch: 5| Step: 6
Training loss: 2.6705671533863082
Validation loss: 2.504731094686897

Epoch: 5| Step: 7
Training loss: 2.747807148642195
Validation loss: 2.5073296965775578

Epoch: 5| Step: 8
Training loss: 2.9214457640306883
Validation loss: 2.5196775815695935

Epoch: 5| Step: 9
Training loss: 3.2353195801411228
Validation loss: 2.514966540846641

Epoch: 5| Step: 10
Training loss: 2.64712482881219
Validation loss: 2.5163169535417196

Epoch: 111| Step: 0
Training loss: 2.6990730036515367
Validation loss: 2.522523251694071

Epoch: 5| Step: 1
Training loss: 2.5002718777641038
Validation loss: 2.507278072114925

Epoch: 5| Step: 2
Training loss: 2.8889884646282136
Validation loss: 2.5169579376958597

Epoch: 5| Step: 3
Training loss: 2.7882702126876406
Validation loss: 2.50939234329397

Epoch: 5| Step: 4
Training loss: 2.9762156527226367
Validation loss: 2.5094442286975807

Epoch: 5| Step: 5
Training loss: 2.503971188278922
Validation loss: 2.5196718869073256

Epoch: 5| Step: 6
Training loss: 3.4682864317563333
Validation loss: 2.514237279128125

Epoch: 5| Step: 7
Training loss: 2.375791016407756
Validation loss: 2.5127669960108863

Epoch: 5| Step: 8
Training loss: 3.1520685881786457
Validation loss: 2.510371905314868

Epoch: 5| Step: 9
Training loss: 3.153697426350571
Validation loss: 2.5068985460037023

Epoch: 5| Step: 10
Training loss: 2.729589405273367
Validation loss: 2.505700771365894

Epoch: 112| Step: 0
Training loss: 2.656872485654759
Validation loss: 2.5021198749926334

Epoch: 5| Step: 1
Training loss: 3.010040488493569
Validation loss: 2.5123338407573472

Epoch: 5| Step: 2
Training loss: 2.9929829229956777
Validation loss: 2.5135047857637414

Epoch: 5| Step: 3
Training loss: 2.9162466745893125
Validation loss: 2.5244405719877925

Epoch: 5| Step: 4
Training loss: 2.1912763424479733
Validation loss: 2.5301589984584667

Epoch: 5| Step: 5
Training loss: 2.594113244048767
Validation loss: 2.5078978717093556

Epoch: 5| Step: 6
Training loss: 2.5869438310799007
Validation loss: 2.5147563820917704

Epoch: 5| Step: 7
Training loss: 3.3989338830194527
Validation loss: 2.525628234163017

Epoch: 5| Step: 8
Training loss: 3.2090617917567417
Validation loss: 2.525349303136846

Epoch: 5| Step: 9
Training loss: 2.4676830062328685
Validation loss: 2.5102085222456365

Epoch: 5| Step: 10
Training loss: 3.148913931946325
Validation loss: 2.5021987782530615

Epoch: 113| Step: 0
Training loss: 2.727922335478431
Validation loss: 2.5084320612555926

Epoch: 5| Step: 1
Training loss: 2.6091069980435817
Validation loss: 2.506821467843053

Epoch: 5| Step: 2
Training loss: 3.0298587713281844
Validation loss: 2.5194155110101217

Epoch: 5| Step: 3
Training loss: 2.8609954744774533
Validation loss: 2.5150757510194826

Epoch: 5| Step: 4
Training loss: 2.358560990127843
Validation loss: 2.507676767575928

Epoch: 5| Step: 5
Training loss: 3.121269899059657
Validation loss: 2.5101513643067443

Epoch: 5| Step: 6
Training loss: 2.664245509688395
Validation loss: 2.509997846629189

Epoch: 5| Step: 7
Training loss: 2.705836969797479
Validation loss: 2.5212104123459507

Epoch: 5| Step: 8
Training loss: 3.2650569439956447
Validation loss: 2.507739798761845

Epoch: 5| Step: 9
Training loss: 2.769174485572003
Validation loss: 2.5227328498005823

Epoch: 5| Step: 10
Training loss: 3.1539340445347603
Validation loss: 2.5300734892659955

Epoch: 114| Step: 0
Training loss: 2.773724006575734
Validation loss: 2.5143332344666347

Epoch: 5| Step: 1
Training loss: 2.312166860142634
Validation loss: 2.505902766625876

Epoch: 5| Step: 2
Training loss: 3.2254051368020096
Validation loss: 2.4979114042419943

Epoch: 5| Step: 3
Training loss: 3.122457461773649
Validation loss: 2.4945265462338293

Epoch: 5| Step: 4
Training loss: 3.098719141515275
Validation loss: 2.504666707842013

Epoch: 5| Step: 5
Training loss: 2.7175130551471174
Validation loss: 2.5036348559892865

Epoch: 5| Step: 6
Training loss: 2.8870078059567614
Validation loss: 2.503518722073735

Epoch: 5| Step: 7
Training loss: 2.0534742130938857
Validation loss: 2.5082178778202793

Epoch: 5| Step: 8
Training loss: 3.4209957299538964
Validation loss: 2.516154003374364

Epoch: 5| Step: 9
Training loss: 2.775542070523847
Validation loss: 2.508352051989648

Epoch: 5| Step: 10
Training loss: 2.7600876714078164
Validation loss: 2.5171425680804407

Epoch: 115| Step: 0
Training loss: 2.6558474067320694
Validation loss: 2.4992164922231916

Epoch: 5| Step: 1
Training loss: 3.3245822156429425
Validation loss: 2.521190934905346

Epoch: 5| Step: 2
Training loss: 2.7783165366846045
Validation loss: 2.5276161806900346

Epoch: 5| Step: 3
Training loss: 3.1574259163206384
Validation loss: 2.519644851075879

Epoch: 5| Step: 4
Training loss: 2.5496040186380844
Validation loss: 2.5270470886036227

Epoch: 5| Step: 5
Training loss: 2.387444069092391
Validation loss: 2.506467587196048

Epoch: 5| Step: 6
Training loss: 2.5791326229907408
Validation loss: 2.5166497573523525

Epoch: 5| Step: 7
Training loss: 2.6004254029790475
Validation loss: 2.5136152843484485

Epoch: 5| Step: 8
Training loss: 3.078904880928949
Validation loss: 2.5102919670678614

Epoch: 5| Step: 9
Training loss: 2.824387077074426
Validation loss: 2.4988198540450597

Epoch: 5| Step: 10
Training loss: 3.158252043336358
Validation loss: 2.49730486337734

Epoch: 116| Step: 0
Training loss: 2.9667812846755446
Validation loss: 2.499195625765374

Epoch: 5| Step: 1
Training loss: 2.759405524321543
Validation loss: 2.4943006420503493

Epoch: 5| Step: 2
Training loss: 3.1509279004622006
Validation loss: 2.498138007102228

Epoch: 5| Step: 3
Training loss: 2.653887247641346
Validation loss: 2.4976062040412437

Epoch: 5| Step: 4
Training loss: 3.217453482527983
Validation loss: 2.5077418504996905

Epoch: 5| Step: 5
Training loss: 2.54570120693882
Validation loss: 2.5227172711663672

Epoch: 5| Step: 6
Training loss: 2.853437585827554
Validation loss: 2.548890323624148

Epoch: 5| Step: 7
Training loss: 2.998533208213115
Validation loss: 2.578424267693899

Epoch: 5| Step: 8
Training loss: 2.568477636595254
Validation loss: 2.5331644414270587

Epoch: 5| Step: 9
Training loss: 2.6525848234170315
Validation loss: 2.5135163682505324

Epoch: 5| Step: 10
Training loss: 3.094387412634794
Validation loss: 2.5049625825632638

Epoch: 117| Step: 0
Training loss: 2.125619237096165
Validation loss: 2.502058247347424

Epoch: 5| Step: 1
Training loss: 2.918773943457734
Validation loss: 2.5022628408171723

Epoch: 5| Step: 2
Training loss: 3.1581996523732454
Validation loss: 2.49581006681057

Epoch: 5| Step: 3
Training loss: 2.755725968211905
Validation loss: 2.496433311797113

Epoch: 5| Step: 4
Training loss: 2.9791938584871835
Validation loss: 2.5020303889978606

Epoch: 5| Step: 5
Training loss: 2.8619654860211488
Validation loss: 2.4987399689325196

Epoch: 5| Step: 6
Training loss: 3.0843832616878966
Validation loss: 2.5013542783305955

Epoch: 5| Step: 7
Training loss: 3.0792715967561803
Validation loss: 2.514687897288661

Epoch: 5| Step: 8
Training loss: 3.308901001266378
Validation loss: 2.5374815203421495

Epoch: 5| Step: 9
Training loss: 2.4667169432628326
Validation loss: 2.558982337538613

Epoch: 5| Step: 10
Training loss: 2.347647922393196
Validation loss: 2.5692081462119924

Epoch: 118| Step: 0
Training loss: 3.395325246296326
Validation loss: 2.6009195381870813

Epoch: 5| Step: 1
Training loss: 2.9241727066593692
Validation loss: 2.587714638649614

Epoch: 5| Step: 2
Training loss: 2.8788151513105245
Validation loss: 2.578959892972979

Epoch: 5| Step: 3
Training loss: 2.5206379670240673
Validation loss: 2.555146160775392

Epoch: 5| Step: 4
Training loss: 2.446184581725904
Validation loss: 2.539382896685964

Epoch: 5| Step: 5
Training loss: 2.2216996479185758
Validation loss: 2.5247048788204904

Epoch: 5| Step: 6
Training loss: 2.460161843752324
Validation loss: 2.5210581914539802

Epoch: 5| Step: 7
Training loss: 3.664037903660448
Validation loss: 2.519054248449362

Epoch: 5| Step: 8
Training loss: 2.527350259150476
Validation loss: 2.5208788645358036

Epoch: 5| Step: 9
Training loss: 3.1684375797026787
Validation loss: 2.497786178518845

Epoch: 5| Step: 10
Training loss: 2.8120838281229066
Validation loss: 2.5003031844192587

Epoch: 119| Step: 0
Training loss: 2.7356810148350994
Validation loss: 2.4933730985493

Epoch: 5| Step: 1
Training loss: 3.236515682036903
Validation loss: 2.489060215707277

Epoch: 5| Step: 2
Training loss: 3.019983018486329
Validation loss: 2.4854465494753404

Epoch: 5| Step: 3
Training loss: 3.0509323883717134
Validation loss: 2.486011446261292

Epoch: 5| Step: 4
Training loss: 3.1568193583096478
Validation loss: 2.485097789148031

Epoch: 5| Step: 5
Training loss: 2.6534466479975682
Validation loss: 2.4895088664182525

Epoch: 5| Step: 6
Training loss: 2.556809969802153
Validation loss: 2.4849063436397616

Epoch: 5| Step: 7
Training loss: 2.875886034228853
Validation loss: 2.484224734512303

Epoch: 5| Step: 8
Training loss: 2.289787828536333
Validation loss: 2.4828961134973957

Epoch: 5| Step: 9
Training loss: 2.620621708349976
Validation loss: 2.484733055782623

Epoch: 5| Step: 10
Training loss: 3.0006657497481166
Validation loss: 2.491042569114387

Epoch: 120| Step: 0
Training loss: 2.820398133898388
Validation loss: 2.5116445236045988

Epoch: 5| Step: 1
Training loss: 2.9629519411606124
Validation loss: 2.5325876740178823

Epoch: 5| Step: 2
Training loss: 2.888953968276884
Validation loss: 2.5353483522335782

Epoch: 5| Step: 3
Training loss: 2.811096689022229
Validation loss: 2.538926961987059

Epoch: 5| Step: 4
Training loss: 2.9248972882878626
Validation loss: 2.521379378294121

Epoch: 5| Step: 5
Training loss: 2.9065425274380816
Validation loss: 2.4963022850055356

Epoch: 5| Step: 6
Training loss: 2.9373735441219457
Validation loss: 2.4919678773256972

Epoch: 5| Step: 7
Training loss: 2.4264672825020694
Validation loss: 2.4898920964846427

Epoch: 5| Step: 8
Training loss: 3.074192381458547
Validation loss: 2.482360251978966

Epoch: 5| Step: 9
Training loss: 2.670682317438735
Validation loss: 2.4885844168006486

Epoch: 5| Step: 10
Training loss: 2.7640834326676544
Validation loss: 2.491168480628364

Epoch: 121| Step: 0
Training loss: 2.574796620457381
Validation loss: 2.4894038217310275

Epoch: 5| Step: 1
Training loss: 3.0687553203715336
Validation loss: 2.488490010098507

Epoch: 5| Step: 2
Training loss: 2.926963577445303
Validation loss: 2.48283596329883

Epoch: 5| Step: 3
Training loss: 2.8728040518668103
Validation loss: 2.4845754994353073

Epoch: 5| Step: 4
Training loss: 3.043707506952404
Validation loss: 2.4910408946971097

Epoch: 5| Step: 5
Training loss: 3.1812127131766985
Validation loss: 2.4883500103188037

Epoch: 5| Step: 6
Training loss: 2.8299803996671073
Validation loss: 2.489653654096931

Epoch: 5| Step: 7
Training loss: 2.727175056269146
Validation loss: 2.520350730814608

Epoch: 5| Step: 8
Training loss: 2.921602124206506
Validation loss: 2.530719099297506

Epoch: 5| Step: 9
Training loss: 2.733962545622507
Validation loss: 2.5319909738433775

Epoch: 5| Step: 10
Training loss: 2.0741370233502123
Validation loss: 2.525390625

Epoch: 122| Step: 0
Training loss: 3.2794227962162448
Validation loss: 2.5113399684855406

Epoch: 5| Step: 1
Training loss: 2.826830319969338
Validation loss: 2.520108944585107

Epoch: 5| Step: 2
Training loss: 3.049037850379906
Validation loss: 2.5412398076872824

Epoch: 5| Step: 3
Training loss: 2.908225259895196
Validation loss: 2.5218095840797874

Epoch: 5| Step: 4
Training loss: 3.1031422471472805
Validation loss: 2.495993125774921

Epoch: 5| Step: 5
Training loss: 2.615391448063793
Validation loss: 2.4906109150444666

Epoch: 5| Step: 6
Training loss: 2.5983390197626433
Validation loss: 2.4806208583194382

Epoch: 5| Step: 7
Training loss: 2.497056372480155
Validation loss: 2.478232922345633

Epoch: 5| Step: 8
Training loss: 2.630397243451208
Validation loss: 2.4798894545362637

Epoch: 5| Step: 9
Training loss: 2.972678065376588
Validation loss: 2.487240499407132

Epoch: 5| Step: 10
Training loss: 2.5262914055663934
Validation loss: 2.4868148923837534

Epoch: 123| Step: 0
Training loss: 3.157742742176608
Validation loss: 2.4846134144916365

Epoch: 5| Step: 1
Training loss: 2.2985982852922424
Validation loss: 2.494249212495124

Epoch: 5| Step: 2
Training loss: 2.6510864333974005
Validation loss: 2.5010990751985633

Epoch: 5| Step: 3
Training loss: 3.162357577407668
Validation loss: 2.5053948429404755

Epoch: 5| Step: 4
Training loss: 2.680904634725365
Validation loss: 2.499657201337549

Epoch: 5| Step: 5
Training loss: 2.2144339046024344
Validation loss: 2.5057369610190037

Epoch: 5| Step: 6
Training loss: 3.144786753255252
Validation loss: 2.510652351234392

Epoch: 5| Step: 7
Training loss: 3.0221561210390973
Validation loss: 2.5061900864933206

Epoch: 5| Step: 8
Training loss: 3.298560123161074
Validation loss: 2.494655730708638

Epoch: 5| Step: 9
Training loss: 2.378671919583107
Validation loss: 2.4810894687587703

Epoch: 5| Step: 10
Training loss: 2.8488467309120065
Validation loss: 2.4789773281557967

Epoch: 124| Step: 0
Training loss: 3.0625889045111276
Validation loss: 2.4722515843554165

Epoch: 5| Step: 1
Training loss: 3.167237598416288
Validation loss: 2.4745148412465006

Epoch: 5| Step: 2
Training loss: 2.5253948733831724
Validation loss: 2.480751660831841

Epoch: 5| Step: 3
Training loss: 2.625791702771797
Validation loss: 2.480364424249459

Epoch: 5| Step: 4
Training loss: 2.9889207342721082
Validation loss: 2.4876005295361057

Epoch: 5| Step: 5
Training loss: 2.8138610089916636
Validation loss: 2.495202951446524

Epoch: 5| Step: 6
Training loss: 2.2598747154550898
Validation loss: 2.4944705613051514

Epoch: 5| Step: 7
Training loss: 3.0362146365924145
Validation loss: 2.5242824736663105

Epoch: 5| Step: 8
Training loss: 3.0196553706903804
Validation loss: 2.5564157781964894

Epoch: 5| Step: 9
Training loss: 2.678371540058978
Validation loss: 2.5323010289071983

Epoch: 5| Step: 10
Training loss: 2.6420292478122125
Validation loss: 2.509109817293371

Epoch: 125| Step: 0
Training loss: 2.7906126528271344
Validation loss: 2.5107614019000777

Epoch: 5| Step: 1
Training loss: 2.764019947576241
Validation loss: 2.519364910607955

Epoch: 5| Step: 2
Training loss: 2.743253842898234
Validation loss: 2.5005719607326395

Epoch: 5| Step: 3
Training loss: 2.9462128333173934
Validation loss: 2.5011841707434317

Epoch: 5| Step: 4
Training loss: 2.8301308615794696
Validation loss: 2.487568352944793

Epoch: 5| Step: 5
Training loss: 2.1772131873529506
Validation loss: 2.4744761218622116

Epoch: 5| Step: 6
Training loss: 3.054239615852443
Validation loss: 2.4836775092840897

Epoch: 5| Step: 7
Training loss: 2.351917835649399
Validation loss: 2.4939320254015303

Epoch: 5| Step: 8
Training loss: 2.736682376080803
Validation loss: 2.486158786616817

Epoch: 5| Step: 9
Training loss: 3.603803289246377
Validation loss: 2.490639295349256

Epoch: 5| Step: 10
Training loss: 2.6655425046652783
Validation loss: 2.493044193398196

Epoch: 126| Step: 0
Training loss: 3.0812151738610916
Validation loss: 2.5330295958557603

Epoch: 5| Step: 1
Training loss: 2.5595144231546003
Validation loss: 2.554884421154928

Epoch: 5| Step: 2
Training loss: 3.221642093028605
Validation loss: 2.518338573664245

Epoch: 5| Step: 3
Training loss: 2.705274840545896
Validation loss: 2.52877496207775

Epoch: 5| Step: 4
Training loss: 2.5820354975262907
Validation loss: 2.5055566899888277

Epoch: 5| Step: 5
Training loss: 2.5890484217259253
Validation loss: 2.4901054254676294

Epoch: 5| Step: 6
Training loss: 2.5537510826791943
Validation loss: 2.4904461954306676

Epoch: 5| Step: 7
Training loss: 2.664450250860906
Validation loss: 2.5025790693473233

Epoch: 5| Step: 8
Training loss: 3.1490499123293993
Validation loss: 2.5048565704052757

Epoch: 5| Step: 9
Training loss: 3.1811502077530243
Validation loss: 2.5121345219916367

Epoch: 5| Step: 10
Training loss: 2.5304207090909485
Validation loss: 2.506548007426978

Epoch: 127| Step: 0
Training loss: 2.396085001677969
Validation loss: 2.5116604567125735

Epoch: 5| Step: 1
Training loss: 2.4191674633684026
Validation loss: 2.5106919126297327

Epoch: 5| Step: 2
Training loss: 2.768707281949928
Validation loss: 2.513209856003698

Epoch: 5| Step: 3
Training loss: 2.920238669060689
Validation loss: 2.5121329820522464

Epoch: 5| Step: 4
Training loss: 2.553838652996612
Validation loss: 2.4975320683778044

Epoch: 5| Step: 5
Training loss: 3.0507567107987956
Validation loss: 2.4984926078500025

Epoch: 5| Step: 6
Training loss: 2.631984048331252
Validation loss: 2.4829667740510617

Epoch: 5| Step: 7
Training loss: 2.9529498012989825
Validation loss: 2.4890426671309718

Epoch: 5| Step: 8
Training loss: 3.025701419438118
Validation loss: 2.4879514336832855

Epoch: 5| Step: 9
Training loss: 2.7536183741103337
Validation loss: 2.4873461209020684

Epoch: 5| Step: 10
Training loss: 3.395072727014299
Validation loss: 2.485754510144648

Epoch: 128| Step: 0
Training loss: 2.9581304847767993
Validation loss: 2.5039374774278667

Epoch: 5| Step: 1
Training loss: 2.483928808294737
Validation loss: 2.531436517797181

Epoch: 5| Step: 2
Training loss: 2.644130749711486
Validation loss: 2.602264580553499

Epoch: 5| Step: 3
Training loss: 3.0930890234571735
Validation loss: 2.6356723448502355

Epoch: 5| Step: 4
Training loss: 2.731580603382122
Validation loss: 2.581201758273197

Epoch: 5| Step: 5
Training loss: 2.5225025251846604
Validation loss: 2.5056434573940076

Epoch: 5| Step: 6
Training loss: 2.9312320147452637
Validation loss: 2.4759389140698866

Epoch: 5| Step: 7
Training loss: 2.819598754852665
Validation loss: 2.4775006061288023

Epoch: 5| Step: 8
Training loss: 3.0073428889687746
Validation loss: 2.4861097954713944

Epoch: 5| Step: 9
Training loss: 3.183878168612285
Validation loss: 2.492629316114491

Epoch: 5| Step: 10
Training loss: 2.7497262818490777
Validation loss: 2.4827856695723622

Epoch: 129| Step: 0
Training loss: 2.4682021680038027
Validation loss: 2.4745292967562067

Epoch: 5| Step: 1
Training loss: 2.993184772562936
Validation loss: 2.4763142000732206

Epoch: 5| Step: 2
Training loss: 3.033250757986823
Validation loss: 2.473680647511114

Epoch: 5| Step: 3
Training loss: 2.956163407523336
Validation loss: 2.481666246557107

Epoch: 5| Step: 4
Training loss: 2.6491650507576923
Validation loss: 2.4883746101646627

Epoch: 5| Step: 5
Training loss: 2.7956432848340285
Validation loss: 2.530697583912836

Epoch: 5| Step: 6
Training loss: 2.824167844701367
Validation loss: 2.6179550982290114

Epoch: 5| Step: 7
Training loss: 2.835934809743903
Validation loss: 2.6784829707660025

Epoch: 5| Step: 8
Training loss: 2.9576803928542406
Validation loss: 2.756450800403334

Epoch: 5| Step: 9
Training loss: 2.7788935762105127
Validation loss: 2.8743930655743144

Epoch: 5| Step: 10
Training loss: 3.380188380076212
Validation loss: 2.8402882984213007

Epoch: 130| Step: 0
Training loss: 2.352397276270327
Validation loss: 2.7231518625996016

Epoch: 5| Step: 1
Training loss: 3.013941794154261
Validation loss: 2.62147140563654

Epoch: 5| Step: 2
Training loss: 2.8942236691862346
Validation loss: 2.522238806796406

Epoch: 5| Step: 3
Training loss: 2.5883485554454055
Validation loss: 2.481512810736641

Epoch: 5| Step: 4
Training loss: 3.3565701862954307
Validation loss: 2.4677107713364097

Epoch: 5| Step: 5
Training loss: 2.945785039337704
Validation loss: 2.4787855661114824

Epoch: 5| Step: 6
Training loss: 3.252372755864681
Validation loss: 2.478809462972834

Epoch: 5| Step: 7
Training loss: 2.3901991121995407
Validation loss: 2.4781735455184295

Epoch: 5| Step: 8
Training loss: 3.008748966433986
Validation loss: 2.4691582027235404

Epoch: 5| Step: 9
Training loss: 3.2163594081044566
Validation loss: 2.4739097776111447

Epoch: 5| Step: 10
Training loss: 2.256053410892094
Validation loss: 2.471859900632991

Epoch: 131| Step: 0
Training loss: 3.0855536499799023
Validation loss: 2.4679923098771037

Epoch: 5| Step: 1
Training loss: 2.555319518324227
Validation loss: 2.479453172585047

Epoch: 5| Step: 2
Training loss: 2.9377207571636745
Validation loss: 2.4906831188782794

Epoch: 5| Step: 3
Training loss: 2.8268261872420095
Validation loss: 2.5178702450578725

Epoch: 5| Step: 4
Training loss: 2.780824778765342
Validation loss: 2.608271259702944

Epoch: 5| Step: 5
Training loss: 2.9793750361063855
Validation loss: 2.6762748998832273

Epoch: 5| Step: 6
Training loss: 2.8116686121992864
Validation loss: 2.6432173983226415

Epoch: 5| Step: 7
Training loss: 3.1627183861398183
Validation loss: 2.6131592484529946

Epoch: 5| Step: 8
Training loss: 3.085633081800707
Validation loss: 2.561774595617544

Epoch: 5| Step: 9
Training loss: 2.582674578280222
Validation loss: 2.5032550683698855

Epoch: 5| Step: 10
Training loss: 2.8223549165427197
Validation loss: 2.467742799614928

Epoch: 132| Step: 0
Training loss: 2.933726870263181
Validation loss: 2.4640166614683907

Epoch: 5| Step: 1
Training loss: 2.8764928176288924
Validation loss: 2.4603044249342694

Epoch: 5| Step: 2
Training loss: 2.900577218061435
Validation loss: 2.4580789235910743

Epoch: 5| Step: 3
Training loss: 2.829911484429255
Validation loss: 2.4542349378854547

Epoch: 5| Step: 4
Training loss: 2.839289426158525
Validation loss: 2.4644029850292357

Epoch: 5| Step: 5
Training loss: 2.6830930728643367
Validation loss: 2.459051824628861

Epoch: 5| Step: 6
Training loss: 2.7780013238177292
Validation loss: 2.467409561555675

Epoch: 5| Step: 7
Training loss: 2.817918516958749
Validation loss: 2.486618503592503

Epoch: 5| Step: 8
Training loss: 2.3822600177574675
Validation loss: 2.4928117797554172

Epoch: 5| Step: 9
Training loss: 2.835854100874252
Validation loss: 2.497032223146849

Epoch: 5| Step: 10
Training loss: 3.317415728558733
Validation loss: 2.490425265783393

Epoch: 133| Step: 0
Training loss: 3.055476328275408
Validation loss: 2.4818630540751343

Epoch: 5| Step: 1
Training loss: 2.5240496669422745
Validation loss: 2.4622699350028485

Epoch: 5| Step: 2
Training loss: 2.3997792023182365
Validation loss: 2.462284641479714

Epoch: 5| Step: 3
Training loss: 2.5364918063629416
Validation loss: 2.463737162816735

Epoch: 5| Step: 4
Training loss: 3.1352753126824315
Validation loss: 2.4650818601670514

Epoch: 5| Step: 5
Training loss: 3.0029878043156706
Validation loss: 2.4651734018383475

Epoch: 5| Step: 6
Training loss: 2.4925861099658086
Validation loss: 2.4652356260621624

Epoch: 5| Step: 7
Training loss: 3.268129839154015
Validation loss: 2.4644167383798323

Epoch: 5| Step: 8
Training loss: 3.193548410402598
Validation loss: 2.4660600738127694

Epoch: 5| Step: 9
Training loss: 2.792316067067283
Validation loss: 2.4723503202046286

Epoch: 5| Step: 10
Training loss: 2.614208746796279
Validation loss: 2.4747369554981513

Epoch: 134| Step: 0
Training loss: 2.5679246193645415
Validation loss: 2.468959632780081

Epoch: 5| Step: 1
Training loss: 2.8675357284914176
Validation loss: 2.494388111382299

Epoch: 5| Step: 2
Training loss: 3.418162940912121
Validation loss: 2.515278214434491

Epoch: 5| Step: 3
Training loss: 3.0448120958702387
Validation loss: 2.5472934232479507

Epoch: 5| Step: 4
Training loss: 2.6853261628053624
Validation loss: 2.5377616423733436

Epoch: 5| Step: 5
Training loss: 2.669644501125597
Validation loss: 2.527332488531612

Epoch: 5| Step: 6
Training loss: 2.382452365363026
Validation loss: 2.502920520392422

Epoch: 5| Step: 7
Training loss: 2.566345585725889
Validation loss: 2.489655862840591

Epoch: 5| Step: 8
Training loss: 3.157750896473965
Validation loss: 2.482848750307052

Epoch: 5| Step: 9
Training loss: 2.698284953741794
Validation loss: 2.478982089389398

Epoch: 5| Step: 10
Training loss: 2.686073456896651
Validation loss: 2.470971591431005

Epoch: 135| Step: 0
Training loss: 2.8063465195265342
Validation loss: 2.4619310276288653

Epoch: 5| Step: 1
Training loss: 2.526021006915891
Validation loss: 2.457663402206347

Epoch: 5| Step: 2
Training loss: 2.7729011984225798
Validation loss: 2.4553680855643436

Epoch: 5| Step: 3
Training loss: 2.7311739249731732
Validation loss: 2.4585126669246367

Epoch: 5| Step: 4
Training loss: 2.282579530999552
Validation loss: 2.4599418421684587

Epoch: 5| Step: 5
Training loss: 3.143492495113277
Validation loss: 2.461328290859284

Epoch: 5| Step: 6
Training loss: 2.7029765534846475
Validation loss: 2.459266314183455

Epoch: 5| Step: 7
Training loss: 3.168590931407932
Validation loss: 2.452333090103277

Epoch: 5| Step: 8
Training loss: 2.7120357344644646
Validation loss: 2.4588563441622164

Epoch: 5| Step: 9
Training loss: 2.949242355555365
Validation loss: 2.473670704587515

Epoch: 5| Step: 10
Training loss: 3.003732266986903
Validation loss: 2.4855746917648927

Epoch: 136| Step: 0
Training loss: 2.905692098248577
Validation loss: 2.5085965114528523

Epoch: 5| Step: 1
Training loss: 2.7925387391602454
Validation loss: 2.5151734682854583

Epoch: 5| Step: 2
Training loss: 2.672497147075961
Validation loss: 2.542862755120357

Epoch: 5| Step: 3
Training loss: 2.647401410105163
Validation loss: 2.524952400146297

Epoch: 5| Step: 4
Training loss: 2.741975085951504
Validation loss: 2.509469782794228

Epoch: 5| Step: 5
Training loss: 2.971631869891324
Validation loss: 2.509209450643448

Epoch: 5| Step: 6
Training loss: 3.1963314306502992
Validation loss: 2.495996732956092

Epoch: 5| Step: 7
Training loss: 2.6858724056964056
Validation loss: 2.4820249719816747

Epoch: 5| Step: 8
Training loss: 2.454764043341821
Validation loss: 2.4851221503933454

Epoch: 5| Step: 9
Training loss: 2.9055654068101706
Validation loss: 2.4747623427695773

Epoch: 5| Step: 10
Training loss: 2.7265514821701635
Validation loss: 2.466795395094866

Epoch: 137| Step: 0
Training loss: 2.5429654685378695
Validation loss: 2.468167118968945

Epoch: 5| Step: 1
Training loss: 2.864505854628112
Validation loss: 2.45657519741996

Epoch: 5| Step: 2
Training loss: 2.605792024108312
Validation loss: 2.4607070359179692

Epoch: 5| Step: 3
Training loss: 3.2231860655865203
Validation loss: 2.4625874847934326

Epoch: 5| Step: 4
Training loss: 3.049237083948773
Validation loss: 2.4611256350581128

Epoch: 5| Step: 5
Training loss: 2.583723336180479
Validation loss: 2.4576602957896463

Epoch: 5| Step: 6
Training loss: 2.4983373835426703
Validation loss: 2.464683903911626

Epoch: 5| Step: 7
Training loss: 2.9343166552705995
Validation loss: 2.4718451100744834

Epoch: 5| Step: 8
Training loss: 2.776592340775914
Validation loss: 2.4760631729336358

Epoch: 5| Step: 9
Training loss: 3.141087739930454
Validation loss: 2.467133836884066

Epoch: 5| Step: 10
Training loss: 2.199016012871603
Validation loss: 2.484269228449687

Epoch: 138| Step: 0
Training loss: 2.6424389990746366
Validation loss: 2.4697416750757744

Epoch: 5| Step: 1
Training loss: 3.4690921374148505
Validation loss: 2.4580980386090765

Epoch: 5| Step: 2
Training loss: 2.2779910703623028
Validation loss: 2.4629511342752495

Epoch: 5| Step: 3
Training loss: 2.105527859284494
Validation loss: 2.4536616805120195

Epoch: 5| Step: 4
Training loss: 2.950631032144481
Validation loss: 2.465935970011621

Epoch: 5| Step: 5
Training loss: 3.4679389899056066
Validation loss: 2.4583454535011557

Epoch: 5| Step: 6
Training loss: 2.7376495808185455
Validation loss: 2.4549293860350443

Epoch: 5| Step: 7
Training loss: 2.7292032215106663
Validation loss: 2.4653300591235894

Epoch: 5| Step: 8
Training loss: 2.538499317799496
Validation loss: 2.478837621590175

Epoch: 5| Step: 9
Training loss: 2.704050864711863
Validation loss: 2.4952670890808237

Epoch: 5| Step: 10
Training loss: 2.576082472446523
Validation loss: 2.5041810482381286

Epoch: 139| Step: 0
Training loss: 2.5766800038764437
Validation loss: 2.495583771341596

Epoch: 5| Step: 1
Training loss: 3.089925077696676
Validation loss: 2.536473392292705

Epoch: 5| Step: 2
Training loss: 2.3776968652064334
Validation loss: 2.5075792877536025

Epoch: 5| Step: 3
Training loss: 3.28571473589592
Validation loss: 2.4762898588103597

Epoch: 5| Step: 4
Training loss: 2.365904507571371
Validation loss: 2.466292269423148

Epoch: 5| Step: 5
Training loss: 2.658673336643715
Validation loss: 2.4591983158434885

Epoch: 5| Step: 6
Training loss: 2.5046452281333247
Validation loss: 2.4480415523582084

Epoch: 5| Step: 7
Training loss: 2.852461999611654
Validation loss: 2.4510204870309202

Epoch: 5| Step: 8
Training loss: 2.749312835150129
Validation loss: 2.4443350171702503

Epoch: 5| Step: 9
Training loss: 3.0532043446721198
Validation loss: 2.455960607609529

Epoch: 5| Step: 10
Training loss: 3.120608792208467
Validation loss: 2.4688719748783927

Epoch: 140| Step: 0
Training loss: 2.37431707100166
Validation loss: 2.4843802523942804

Epoch: 5| Step: 1
Training loss: 2.9307078301359413
Validation loss: 2.5044697443318364

Epoch: 5| Step: 2
Training loss: 2.82214312964053
Validation loss: 2.509610874235839

Epoch: 5| Step: 3
Training loss: 2.5837313642784823
Validation loss: 2.5017316215111087

Epoch: 5| Step: 4
Training loss: 2.5672028348978997
Validation loss: 2.4983239739263574

Epoch: 5| Step: 5
Training loss: 2.698015267670389
Validation loss: 2.4881319169371676

Epoch: 5| Step: 6
Training loss: 2.89382971371629
Validation loss: 2.4792398266343914

Epoch: 5| Step: 7
Training loss: 3.0764904038955216
Validation loss: 2.458120243673879

Epoch: 5| Step: 8
Training loss: 2.724496402927824
Validation loss: 2.4499701393271582

Epoch: 5| Step: 9
Training loss: 3.31553798493044
Validation loss: 2.4526713787713335

Epoch: 5| Step: 10
Training loss: 2.466356783380796
Validation loss: 2.4548355637831323

Epoch: 141| Step: 0
Training loss: 3.0761021197448293
Validation loss: 2.451799364628008

Epoch: 5| Step: 1
Training loss: 3.38589907608094
Validation loss: 2.459075540036313

Epoch: 5| Step: 2
Training loss: 2.802619618050267
Validation loss: 2.468145230727163

Epoch: 5| Step: 3
Training loss: 2.9545894806255975
Validation loss: 2.472385354524701

Epoch: 5| Step: 4
Training loss: 2.747742680114098
Validation loss: 2.492821325468821

Epoch: 5| Step: 5
Training loss: 2.325537658379931
Validation loss: 2.501174185458375

Epoch: 5| Step: 6
Training loss: 2.295430462261943
Validation loss: 2.5176939148527175

Epoch: 5| Step: 7
Training loss: 2.9556092807918852
Validation loss: 2.4989290281505614

Epoch: 5| Step: 8
Training loss: 2.9096577671856108
Validation loss: 2.483413405970877

Epoch: 5| Step: 9
Training loss: 2.5522464207031788
Validation loss: 2.4760847116345723

Epoch: 5| Step: 10
Training loss: 2.1559101887399765
Validation loss: 2.4820342792701644

Epoch: 142| Step: 0
Training loss: 2.8300029778886095
Validation loss: 2.475661413813123

Epoch: 5| Step: 1
Training loss: 2.7507464522869585
Validation loss: 2.470116473492391

Epoch: 5| Step: 2
Training loss: 2.4473799962675127
Validation loss: 2.473342586415225

Epoch: 5| Step: 3
Training loss: 2.8889495117804
Validation loss: 2.4823740571351176

Epoch: 5| Step: 4
Training loss: 2.369603601615739
Validation loss: 2.4749004842440723

Epoch: 5| Step: 5
Training loss: 2.9144468488678066
Validation loss: 2.4768014243110454

Epoch: 5| Step: 6
Training loss: 3.0611229739581414
Validation loss: 2.4758535255196894

Epoch: 5| Step: 7
Training loss: 2.726638574276739
Validation loss: 2.461299760585726

Epoch: 5| Step: 8
Training loss: 2.327569267971329
Validation loss: 2.477991729663069

Epoch: 5| Step: 9
Training loss: 2.9570688222617147
Validation loss: 2.482726978846792

Epoch: 5| Step: 10
Training loss: 2.949760013452432
Validation loss: 2.480962027899137

Epoch: 143| Step: 0
Training loss: 2.627773908281154
Validation loss: 2.485499957940673

Epoch: 5| Step: 1
Training loss: 3.253784323946167
Validation loss: 2.4734107960266196

Epoch: 5| Step: 2
Training loss: 2.334950624552455
Validation loss: 2.4733550980777865

Epoch: 5| Step: 3
Training loss: 2.796829990472333
Validation loss: 2.466795374309675

Epoch: 5| Step: 4
Training loss: 2.738740237700467
Validation loss: 2.4840893407381897

Epoch: 5| Step: 5
Training loss: 2.703103126040471
Validation loss: 2.499116191715039

Epoch: 5| Step: 6
Training loss: 2.7110404838767175
Validation loss: 2.510673905655438

Epoch: 5| Step: 7
Training loss: 3.2367466878640543
Validation loss: 2.5129530279333707

Epoch: 5| Step: 8
Training loss: 2.3122698695141297
Validation loss: 2.505119828883215

Epoch: 5| Step: 9
Training loss: 2.651411788874397
Validation loss: 2.488026320557652

Epoch: 5| Step: 10
Training loss: 2.6964960568012115
Validation loss: 2.4702028169330204

Epoch: 144| Step: 0
Training loss: 2.5520842467844878
Validation loss: 2.45411208299756

Epoch: 5| Step: 1
Training loss: 2.7686562171363467
Validation loss: 2.4509121076589246

Epoch: 5| Step: 2
Training loss: 3.0026878396005405
Validation loss: 2.469991882252424

Epoch: 5| Step: 3
Training loss: 2.915845392039976
Validation loss: 2.4859019925753105

Epoch: 5| Step: 4
Training loss: 2.358769623351836
Validation loss: 2.5366124865194726

Epoch: 5| Step: 5
Training loss: 3.0316410402372154
Validation loss: 2.5982620849067533

Epoch: 5| Step: 6
Training loss: 2.2947823469885003
Validation loss: 2.6683097559809896

Epoch: 5| Step: 7
Training loss: 3.180593900342973
Validation loss: 2.6083715930287017

Epoch: 5| Step: 8
Training loss: 2.9029098513144356
Validation loss: 2.481918446437874

Epoch: 5| Step: 9
Training loss: 2.4864233437739665
Validation loss: 2.4619751403737213

Epoch: 5| Step: 10
Training loss: 3.0625354998341066
Validation loss: 2.4635691416300842

Epoch: 145| Step: 0
Training loss: 2.635562264462674
Validation loss: 2.467786412673034

Epoch: 5| Step: 1
Training loss: 3.1719089750528005
Validation loss: 2.4754481718913595

Epoch: 5| Step: 2
Training loss: 3.0221103643616862
Validation loss: 2.4817481605103495

Epoch: 5| Step: 3
Training loss: 2.9282328745574797
Validation loss: 2.501551011625155

Epoch: 5| Step: 4
Training loss: 2.514624924040553
Validation loss: 2.5381995353409947

Epoch: 5| Step: 5
Training loss: 2.7918620444484596
Validation loss: 2.541179452600287

Epoch: 5| Step: 6
Training loss: 2.6282401296683715
Validation loss: 2.5309125279555675

Epoch: 5| Step: 7
Training loss: 3.2258978429276666
Validation loss: 2.5426228918472495

Epoch: 5| Step: 8
Training loss: 2.4291543160893942
Validation loss: 2.587052997446022

Epoch: 5| Step: 9
Training loss: 2.6986350105952
Validation loss: 2.625684737724293

Epoch: 5| Step: 10
Training loss: 2.753888935007623
Validation loss: 2.6158792104694255

Epoch: 146| Step: 0
Training loss: 2.6885305690918155
Validation loss: 2.545133197287874

Epoch: 5| Step: 1
Training loss: 2.798593430085936
Validation loss: 2.4872586780933776

Epoch: 5| Step: 2
Training loss: 2.8685264683154434
Validation loss: 2.4552234624880445

Epoch: 5| Step: 3
Training loss: 2.1349482200829373
Validation loss: 2.458356205072753

Epoch: 5| Step: 4
Training loss: 2.746050252339313
Validation loss: 2.4623778977601325

Epoch: 5| Step: 5
Training loss: 3.1499375776130685
Validation loss: 2.465303155792593

Epoch: 5| Step: 6
Training loss: 2.6935896965176482
Validation loss: 2.4624647374197473

Epoch: 5| Step: 7
Training loss: 2.8882632943488566
Validation loss: 2.454233401310249

Epoch: 5| Step: 8
Training loss: 3.0312293926993634
Validation loss: 2.452557975511368

Epoch: 5| Step: 9
Training loss: 3.2039057082589917
Validation loss: 2.4547287523054715

Epoch: 5| Step: 10
Training loss: 2.0705688317876345
Validation loss: 2.476895651369732

Epoch: 147| Step: 0
Training loss: 2.7472550824647977
Validation loss: 2.498674853658984

Epoch: 5| Step: 1
Training loss: 2.749964800522685
Validation loss: 2.511156071213432

Epoch: 5| Step: 2
Training loss: 2.5801148105181912
Validation loss: 2.5670522117651347

Epoch: 5| Step: 3
Training loss: 2.8533475122663967
Validation loss: 2.5144292921787543

Epoch: 5| Step: 4
Training loss: 2.662499648976191
Validation loss: 2.493640040332858

Epoch: 5| Step: 5
Training loss: 2.7386907905226816
Validation loss: 2.472287568884844

Epoch: 5| Step: 6
Training loss: 3.054095198630816
Validation loss: 2.472331643049871

Epoch: 5| Step: 7
Training loss: 2.3981259420123124
Validation loss: 2.4830224153955016

Epoch: 5| Step: 8
Training loss: 2.691295693484019
Validation loss: 2.492516093412831

Epoch: 5| Step: 9
Training loss: 2.8653623504246295
Validation loss: 2.49705184488295

Epoch: 5| Step: 10
Training loss: 2.8928085740198664
Validation loss: 2.498387207209673

Epoch: 148| Step: 0
Training loss: 2.724503403657134
Validation loss: 2.4875659084055033

Epoch: 5| Step: 1
Training loss: 2.6007551710449017
Validation loss: 2.483666991190137

Epoch: 5| Step: 2
Training loss: 2.6010673899531396
Validation loss: 2.482006611391025

Epoch: 5| Step: 3
Training loss: 3.035534377336823
Validation loss: 2.469650413807304

Epoch: 5| Step: 4
Training loss: 2.9512230939983706
Validation loss: 2.471331406576508

Epoch: 5| Step: 5
Training loss: 2.605938870454449
Validation loss: 2.4631901580247066

Epoch: 5| Step: 6
Training loss: 2.1457088273849565
Validation loss: 2.471932209850925

Epoch: 5| Step: 7
Training loss: 2.7311369988221847
Validation loss: 2.48612664086238

Epoch: 5| Step: 8
Training loss: 2.5960950247032213
Validation loss: 2.48982553998228

Epoch: 5| Step: 9
Training loss: 3.0102963187021308
Validation loss: 2.4961393675261796

Epoch: 5| Step: 10
Training loss: 2.817426224346002
Validation loss: 2.495511224414786

Epoch: 149| Step: 0
Training loss: 2.847545396612072
Validation loss: 2.4897340845684544

Epoch: 5| Step: 1
Training loss: 2.4276154443729463
Validation loss: 2.4750043753175834

Epoch: 5| Step: 2
Training loss: 2.633416352794276
Validation loss: 2.4706292414988424

Epoch: 5| Step: 3
Training loss: 3.262562314896306
Validation loss: 2.4646223085872667

Epoch: 5| Step: 4
Training loss: 2.2602714691171997
Validation loss: 2.487438958591341

Epoch: 5| Step: 5
Training loss: 2.372259566702755
Validation loss: 2.4917014508877418

Epoch: 5| Step: 6
Training loss: 2.822303977626518
Validation loss: 2.50721418779924

Epoch: 5| Step: 7
Training loss: 2.9144331054654367
Validation loss: 2.524025757592479

Epoch: 5| Step: 8
Training loss: 2.225272249860348
Validation loss: 2.5049391767305145

Epoch: 5| Step: 9
Training loss: 3.35914320035129
Validation loss: 2.50359178140338

Epoch: 5| Step: 10
Training loss: 2.415084079518769
Validation loss: 2.4951681717489786

Epoch: 150| Step: 0
Training loss: 2.7668156189251967
Validation loss: 2.4913429796428908

Epoch: 5| Step: 1
Training loss: 2.638228463189023
Validation loss: 2.5011130495737923

Epoch: 5| Step: 2
Training loss: 2.458750306882388
Validation loss: 2.4953389257431744

Epoch: 5| Step: 3
Training loss: 2.851026510789082
Validation loss: 2.510899581350774

Epoch: 5| Step: 4
Training loss: 2.7208237029095534
Validation loss: 2.503922800585275

Epoch: 5| Step: 5
Training loss: 2.773073242337271
Validation loss: 2.476379593774008

Epoch: 5| Step: 6
Training loss: 3.0889846629870057
Validation loss: 2.4636397540056856

Epoch: 5| Step: 7
Training loss: 2.4698817881972523
Validation loss: 2.461142199379583

Epoch: 5| Step: 8
Training loss: 2.638781202918772
Validation loss: 2.476987398130091

Epoch: 5| Step: 9
Training loss: 2.8476981119393896
Validation loss: 2.4752312234110065

Epoch: 5| Step: 10
Training loss: 2.345333632463556
Validation loss: 2.4634638743703428

Epoch: 151| Step: 0
Training loss: 2.9562103462382465
Validation loss: 2.450351439628625

Epoch: 5| Step: 1
Training loss: 2.29962346685157
Validation loss: 2.4497954884486424

Epoch: 5| Step: 2
Training loss: 2.4418946777050796
Validation loss: 2.4610696799099707

Epoch: 5| Step: 3
Training loss: 2.6981988904076855
Validation loss: 2.472035393432888

Epoch: 5| Step: 4
Training loss: 2.6884465879299784
Validation loss: 2.4960588871966944

Epoch: 5| Step: 5
Training loss: 2.438372333637989
Validation loss: 2.5317121909453126

Epoch: 5| Step: 6
Training loss: 2.641757880079181
Validation loss: 2.5501876185767447

Epoch: 5| Step: 7
Training loss: 2.4178652148042596
Validation loss: 2.554365461099894

Epoch: 5| Step: 8
Training loss: 3.1970263970138135
Validation loss: 2.547415531973674

Epoch: 5| Step: 9
Training loss: 3.223829539021485
Validation loss: 2.4919305237440854

Epoch: 5| Step: 10
Training loss: 2.7946502532234327
Validation loss: 2.462577580363151

Epoch: 152| Step: 0
Training loss: 2.224365113791876
Validation loss: 2.4365697262953616

Epoch: 5| Step: 1
Training loss: 2.1015559199914415
Validation loss: 2.433812098982885

Epoch: 5| Step: 2
Training loss: 2.846073249619501
Validation loss: 2.434323317256522

Epoch: 5| Step: 3
Training loss: 3.2460276462696185
Validation loss: 2.441690791130337

Epoch: 5| Step: 4
Training loss: 2.4842294134511826
Validation loss: 2.4466942039843014

Epoch: 5| Step: 5
Training loss: 3.0885525596559504
Validation loss: 2.450008976032355

Epoch: 5| Step: 6
Training loss: 2.8406814955663244
Validation loss: 2.4882991429077403

Epoch: 5| Step: 7
Training loss: 2.8036959709849576
Validation loss: 2.5791091547013454

Epoch: 5| Step: 8
Training loss: 2.7229375926475745
Validation loss: 2.603289621310298

Epoch: 5| Step: 9
Training loss: 2.8562140998837955
Validation loss: 2.5913679984397127

Epoch: 5| Step: 10
Training loss: 2.9567827450380895
Validation loss: 2.6207229901959384

Epoch: 153| Step: 0
Training loss: 2.9543929027307887
Validation loss: 2.573379744619624

Epoch: 5| Step: 1
Training loss: 1.9394891433982349
Validation loss: 2.5287323420889556

Epoch: 5| Step: 2
Training loss: 3.0691077122932984
Validation loss: 2.489177037581337

Epoch: 5| Step: 3
Training loss: 2.771129496719984
Validation loss: 2.4818578407706147

Epoch: 5| Step: 4
Training loss: 2.4402834332112975
Validation loss: 2.487284170495702

Epoch: 5| Step: 5
Training loss: 2.7104921002535884
Validation loss: 2.489034864061882

Epoch: 5| Step: 6
Training loss: 2.5973311371386028
Validation loss: 2.4794163604459345

Epoch: 5| Step: 7
Training loss: 2.785373160327526
Validation loss: 2.48916956296239

Epoch: 5| Step: 8
Training loss: 2.7106762850894586
Validation loss: 2.5080423276305073

Epoch: 5| Step: 9
Training loss: 3.243781375917017
Validation loss: 2.5455263302505635

Epoch: 5| Step: 10
Training loss: 2.6457202216372804
Validation loss: 2.550024877407163

Epoch: 154| Step: 0
Training loss: 3.2846368658057106
Validation loss: 2.5379598222651523

Epoch: 5| Step: 1
Training loss: 2.366645776181859
Validation loss: 2.527157458148749

Epoch: 5| Step: 2
Training loss: 2.635500297174381
Validation loss: 2.5213596988049614

Epoch: 5| Step: 3
Training loss: 3.057328509358414
Validation loss: 2.5071134791966285

Epoch: 5| Step: 4
Training loss: 2.408123624530462
Validation loss: 2.483975444954178

Epoch: 5| Step: 5
Training loss: 2.5887308851095394
Validation loss: 2.4596237413119315

Epoch: 5| Step: 6
Training loss: 2.2011038525148385
Validation loss: 2.4659829771000252

Epoch: 5| Step: 7
Training loss: 2.920179231969533
Validation loss: 2.4467137830543653

Epoch: 5| Step: 8
Training loss: 2.587506051908778
Validation loss: 2.4719814741977846

Epoch: 5| Step: 9
Training loss: 2.937164125111049
Validation loss: 2.4696222532064027

Epoch: 5| Step: 10
Training loss: 2.5141311854243393
Validation loss: 2.4933017509709208

Epoch: 155| Step: 0
Training loss: 2.6653926806264883
Validation loss: 2.4998629747801315

Epoch: 5| Step: 1
Training loss: 2.2099078581230582
Validation loss: 2.5240502428358846

Epoch: 5| Step: 2
Training loss: 3.137860955984085
Validation loss: 2.529952033096996

Epoch: 5| Step: 3
Training loss: 3.0594133664960554
Validation loss: 2.5268387198689433

Epoch: 5| Step: 4
Training loss: 2.4733810447279314
Validation loss: 2.4867282154322603

Epoch: 5| Step: 5
Training loss: 2.311623381374681
Validation loss: 2.4668245939579543

Epoch: 5| Step: 6
Training loss: 2.5571618652550616
Validation loss: 2.4695893004942344

Epoch: 5| Step: 7
Training loss: 2.943767273805642
Validation loss: 2.4659550116498297

Epoch: 5| Step: 8
Training loss: 2.510780550805705
Validation loss: 2.4690427574116622

Epoch: 5| Step: 9
Training loss: 3.0271419728623146
Validation loss: 2.4775314394639385

Epoch: 5| Step: 10
Training loss: 2.609125365234256
Validation loss: 2.4730038270531214

Epoch: 156| Step: 0
Training loss: 2.814436606068152
Validation loss: 2.4780185092033244

Epoch: 5| Step: 1
Training loss: 2.6517492422996685
Validation loss: 2.480627904489743

Epoch: 5| Step: 2
Training loss: 2.830376166425452
Validation loss: 2.503975116711265

Epoch: 5| Step: 3
Training loss: 2.238406405852711
Validation loss: 2.52797067049651

Epoch: 5| Step: 4
Training loss: 2.899438237994951
Validation loss: 2.5647604211918793

Epoch: 5| Step: 5
Training loss: 2.318323792310654
Validation loss: 2.5421451637307717

Epoch: 5| Step: 6
Training loss: 2.6526000133646424
Validation loss: 2.500911843736998

Epoch: 5| Step: 7
Training loss: 3.0398853433469823
Validation loss: 2.48023724692073

Epoch: 5| Step: 8
Training loss: 2.2598565692454935
Validation loss: 2.468543246900324

Epoch: 5| Step: 9
Training loss: 3.1854898434789765
Validation loss: 2.465586003303257

Epoch: 5| Step: 10
Training loss: 2.4204071518950743
Validation loss: 2.461245660846104

Epoch: 157| Step: 0
Training loss: 2.6106434554346576
Validation loss: 2.4593381415059974

Epoch: 5| Step: 1
Training loss: 2.261376864036048
Validation loss: 2.485630860556909

Epoch: 5| Step: 2
Training loss: 2.4553688623718384
Validation loss: 2.480768767889119

Epoch: 5| Step: 3
Training loss: 2.5114036825196955
Validation loss: 2.5214177526020114

Epoch: 5| Step: 4
Training loss: 2.9749453499526806
Validation loss: 2.5719013023225172

Epoch: 5| Step: 5
Training loss: 2.6226223668150275
Validation loss: 2.696246180928553

Epoch: 5| Step: 6
Training loss: 2.645640829297137
Validation loss: 2.723513449923823

Epoch: 5| Step: 7
Training loss: 2.855931277198912
Validation loss: 2.598268412446793

Epoch: 5| Step: 8
Training loss: 2.8455534864890897
Validation loss: 2.554976021382608

Epoch: 5| Step: 9
Training loss: 2.6135048535398435
Validation loss: 2.5230984018194382

Epoch: 5| Step: 10
Training loss: 3.202893355762672
Validation loss: 2.4840644874039652

Epoch: 158| Step: 0
Training loss: 2.3109973458671433
Validation loss: 2.466738394168576

Epoch: 5| Step: 1
Training loss: 2.3872913728804748
Validation loss: 2.4667181758635337

Epoch: 5| Step: 2
Training loss: 2.4413326160770836
Validation loss: 2.4686256876881134

Epoch: 5| Step: 3
Training loss: 2.886023906246578
Validation loss: 2.4656926563723593

Epoch: 5| Step: 4
Training loss: 2.671659940575097
Validation loss: 2.4457127110163777

Epoch: 5| Step: 5
Training loss: 2.7242427018613853
Validation loss: 2.454104037239308

Epoch: 5| Step: 6
Training loss: 2.813673156204154
Validation loss: 2.502609377046086

Epoch: 5| Step: 7
Training loss: 2.6964518474776034
Validation loss: 2.545918624126188

Epoch: 5| Step: 8
Training loss: 2.724983610751361
Validation loss: 2.5987247144455883

Epoch: 5| Step: 9
Training loss: 2.476644713183414
Validation loss: 2.6353694271620545

Epoch: 5| Step: 10
Training loss: 3.188886752185113
Validation loss: 2.6875893820503265

Epoch: 159| Step: 0
Training loss: 2.8018431625582583
Validation loss: 2.6637752855558596

Epoch: 5| Step: 1
Training loss: 2.6632022307700853
Validation loss: 2.6079724532347974

Epoch: 5| Step: 2
Training loss: 2.493988725522031
Validation loss: 2.543531679369635

Epoch: 5| Step: 3
Training loss: 2.997127906541759
Validation loss: 2.5001448435508875

Epoch: 5| Step: 4
Training loss: 2.7590427842398735
Validation loss: 2.4516368820200283

Epoch: 5| Step: 5
Training loss: 2.6593358683592765
Validation loss: 2.4447831882932554

Epoch: 5| Step: 6
Training loss: 3.066946421868869
Validation loss: 2.452194069102804

Epoch: 5| Step: 7
Training loss: 2.527993073103867
Validation loss: 2.4545354728738156

Epoch: 5| Step: 8
Training loss: 2.5563382756070245
Validation loss: 2.486304504562275

Epoch: 5| Step: 9
Training loss: 2.4160777942056852
Validation loss: 2.519011766254514

Epoch: 5| Step: 10
Training loss: 2.4003493054824494
Validation loss: 2.549220823906021

Epoch: 160| Step: 0
Training loss: 2.6437062902421973
Validation loss: 2.5905079580482377

Epoch: 5| Step: 1
Training loss: 2.8685776669136436
Validation loss: 2.5696517973377366

Epoch: 5| Step: 2
Training loss: 2.325688463230389
Validation loss: 2.532197940616364

Epoch: 5| Step: 3
Training loss: 3.176874439480357
Validation loss: 2.493226666778295

Epoch: 5| Step: 4
Training loss: 2.7464821596425604
Validation loss: 2.4709522253226326

Epoch: 5| Step: 5
Training loss: 2.419152483117231
Validation loss: 2.4713251949047845

Epoch: 5| Step: 6
Training loss: 2.4408888123539962
Validation loss: 2.488884560600608

Epoch: 5| Step: 7
Training loss: 2.8873572772535074
Validation loss: 2.5062961972121425

Epoch: 5| Step: 8
Training loss: 2.6524956593671223
Validation loss: 2.4881541661627784

Epoch: 5| Step: 9
Training loss: 2.29301980268842
Validation loss: 2.4836863541511898

Epoch: 5| Step: 10
Training loss: 2.5710994362224895
Validation loss: 2.4761919457547767

Epoch: 161| Step: 0
Training loss: 2.578152373197486
Validation loss: 2.530765405530635

Epoch: 5| Step: 1
Training loss: 3.410909003760375
Validation loss: 2.542634927491991

Epoch: 5| Step: 2
Training loss: 2.126636323901711
Validation loss: 2.527914418196501

Epoch: 5| Step: 3
Training loss: 2.6745962818706106
Validation loss: 2.5556156644563206

Epoch: 5| Step: 4
Training loss: 2.446555507258655
Validation loss: 2.5299299133273947

Epoch: 5| Step: 5
Training loss: 2.745126306931891
Validation loss: 2.5427617963786417

Epoch: 5| Step: 6
Training loss: 3.019115582240233
Validation loss: 2.4876273808313476

Epoch: 5| Step: 7
Training loss: 2.1825745853644296
Validation loss: 2.4704118438826326

Epoch: 5| Step: 8
Training loss: 2.9464952436557965
Validation loss: 2.4464772384139772

Epoch: 5| Step: 9
Training loss: 2.4134904004544824
Validation loss: 2.456104812562346

Epoch: 5| Step: 10
Training loss: 2.3324479285148896
Validation loss: 2.4585280997360393

Epoch: 162| Step: 0
Training loss: 2.9409519771843424
Validation loss: 2.452222761769634

Epoch: 5| Step: 1
Training loss: 2.3054344906357223
Validation loss: 2.4560970447164134

Epoch: 5| Step: 2
Training loss: 2.7727450513767185
Validation loss: 2.504312781190929

Epoch: 5| Step: 3
Training loss: 2.916961618677707
Validation loss: 2.546924400592844

Epoch: 5| Step: 4
Training loss: 2.7975648849639745
Validation loss: 2.593143811870544

Epoch: 5| Step: 5
Training loss: 2.609408167097173
Validation loss: 2.5885694767258283

Epoch: 5| Step: 6
Training loss: 3.0340185991294253
Validation loss: 2.5351999208510225

Epoch: 5| Step: 7
Training loss: 2.2748597405762037
Validation loss: 2.4930658630358495

Epoch: 5| Step: 8
Training loss: 2.7396471042729074
Validation loss: 2.461279456462003

Epoch: 5| Step: 9
Training loss: 2.1001304086429693
Validation loss: 2.4570462831100914

Epoch: 5| Step: 10
Training loss: 2.5641079951497785
Validation loss: 2.4444387500481577

Epoch: 163| Step: 0
Training loss: 2.430007962500317
Validation loss: 2.443180774158729

Epoch: 5| Step: 1
Training loss: 2.7979579086464343
Validation loss: 2.4384015511391253

Epoch: 5| Step: 2
Training loss: 2.567653312377326
Validation loss: 2.4464409444519317

Epoch: 5| Step: 3
Training loss: 3.2284693959844355
Validation loss: 2.443301703512141

Epoch: 5| Step: 4
Training loss: 2.2148196372144224
Validation loss: 2.4519337916090214

Epoch: 5| Step: 5
Training loss: 2.4429927462432266
Validation loss: 2.457772405947568

Epoch: 5| Step: 6
Training loss: 2.716284324404546
Validation loss: 2.500936844345916

Epoch: 5| Step: 7
Training loss: 2.048876882723875
Validation loss: 2.5232420149407657

Epoch: 5| Step: 8
Training loss: 3.037469676929968
Validation loss: 2.565655523951475

Epoch: 5| Step: 9
Training loss: 2.5140749497754395
Validation loss: 2.618188677863071

Epoch: 5| Step: 10
Training loss: 2.744544860823468
Validation loss: 2.6574575942553103

Epoch: 164| Step: 0
Training loss: 2.286695903928517
Validation loss: 2.68069681521577

Epoch: 5| Step: 1
Training loss: 2.5422718599152208
Validation loss: 2.6552222085754833

Epoch: 5| Step: 2
Training loss: 2.694653593600104
Validation loss: 2.6189211764268974

Epoch: 5| Step: 3
Training loss: 2.6629575524265103
Validation loss: 2.5651534633835227

Epoch: 5| Step: 4
Training loss: 2.552898188663647
Validation loss: 2.5076319620876966

Epoch: 5| Step: 5
Training loss: 3.0209322858366674
Validation loss: 2.476732582480226

Epoch: 5| Step: 6
Training loss: 2.1563584673593112
Validation loss: 2.452615534916732

Epoch: 5| Step: 7
Training loss: 2.9107278761684343
Validation loss: 2.465506838156828

Epoch: 5| Step: 8
Training loss: 2.557560136820753
Validation loss: 2.4551545439760107

Epoch: 5| Step: 9
Training loss: 2.604169026691639
Validation loss: 2.467386855126587

Epoch: 5| Step: 10
Training loss: 2.6230110626161935
Validation loss: 2.4696630936545403

Epoch: 165| Step: 0
Training loss: 2.4179468600710483
Validation loss: 2.502316648497304

Epoch: 5| Step: 1
Training loss: 2.7370977306485753
Validation loss: 2.541527102945738

Epoch: 5| Step: 2
Training loss: 2.7678343143488577
Validation loss: 2.5810651067042567

Epoch: 5| Step: 3
Training loss: 2.5590578546457428
Validation loss: 2.6029126507795013

Epoch: 5| Step: 4
Training loss: 2.29214062269002
Validation loss: 2.612920166352154

Epoch: 5| Step: 5
Training loss: 2.5367843971886583
Validation loss: 2.600336208250831

Epoch: 5| Step: 6
Training loss: 2.688376172980398
Validation loss: 2.5816390107733977

Epoch: 5| Step: 7
Training loss: 3.166903202525306
Validation loss: 2.566175050988585

Epoch: 5| Step: 8
Training loss: 2.432901691230181
Validation loss: 2.523961645086783

Epoch: 5| Step: 9
Training loss: 2.234234145199686
Validation loss: 2.505301203752479

Epoch: 5| Step: 10
Training loss: 2.3484681513874217
Validation loss: 2.5072867048951752

Epoch: 166| Step: 0
Training loss: 2.4652224097205564
Validation loss: 2.4818511224401014

Epoch: 5| Step: 1
Training loss: 2.3127064999320344
Validation loss: 2.4849792001673747

Epoch: 5| Step: 2
Training loss: 2.4443215991951117
Validation loss: 2.474241452211205

Epoch: 5| Step: 3
Training loss: 2.749858939280996
Validation loss: 2.4833711657464383

Epoch: 5| Step: 4
Training loss: 2.3486120020842582
Validation loss: 2.5107272645344234

Epoch: 5| Step: 5
Training loss: 2.8044957172417546
Validation loss: 2.516523429685986

Epoch: 5| Step: 6
Training loss: 2.45560043714923
Validation loss: 2.53493709765043

Epoch: 5| Step: 7
Training loss: 2.252405787793519
Validation loss: 2.5351199241290825

Epoch: 5| Step: 8
Training loss: 2.357401142171413
Validation loss: 2.5348852182632937

Epoch: 5| Step: 9
Training loss: 3.0092540110572195
Validation loss: 2.513232478421866

Epoch: 5| Step: 10
Training loss: 3.0482467302298435
Validation loss: 2.5033910896911844

Epoch: 167| Step: 0
Training loss: 2.475683977040447
Validation loss: 2.490345356394639

Epoch: 5| Step: 1
Training loss: 2.5485570303029403
Validation loss: 2.4816445486582124

Epoch: 5| Step: 2
Training loss: 2.6228098133754707
Validation loss: 2.4827381483546

Epoch: 5| Step: 3
Training loss: 2.1984981352273523
Validation loss: 2.475784693573548

Epoch: 5| Step: 4
Training loss: 2.5769932892800447
Validation loss: 2.4712657382088885

Epoch: 5| Step: 5
Training loss: 2.2835003975036154
Validation loss: 2.492402092074031

Epoch: 5| Step: 6
Training loss: 2.722344313584625
Validation loss: 2.5037559812425583

Epoch: 5| Step: 7
Training loss: 2.954438739796768
Validation loss: 2.51620818338487

Epoch: 5| Step: 8
Training loss: 2.726910325738927
Validation loss: 2.5241772145197534

Epoch: 5| Step: 9
Training loss: 2.704231609001583
Validation loss: 2.5101960175896108

Epoch: 5| Step: 10
Training loss: 2.4198749774763595
Validation loss: 2.5219574617419465

Epoch: 168| Step: 0
Training loss: 2.900152721987594
Validation loss: 2.545435086914925

Epoch: 5| Step: 1
Training loss: 2.254348156216345
Validation loss: 2.5730674928283332

Epoch: 5| Step: 2
Training loss: 2.393948905788382
Validation loss: 2.622693174757422

Epoch: 5| Step: 3
Training loss: 2.5882725617331728
Validation loss: 2.6143484483601873

Epoch: 5| Step: 4
Training loss: 2.6019615806599115
Validation loss: 2.5875893629963906

Epoch: 5| Step: 5
Training loss: 2.129202893789397
Validation loss: 2.5395350831914256

Epoch: 5| Step: 6
Training loss: 3.052802321250801
Validation loss: 2.484266543831353

Epoch: 5| Step: 7
Training loss: 2.449533056020147
Validation loss: 2.471932885521414

Epoch: 5| Step: 8
Training loss: 2.5221278332130335
Validation loss: 2.4441326153924336

Epoch: 5| Step: 9
Training loss: 2.4739971171233544
Validation loss: 2.4563235985385523

Epoch: 5| Step: 10
Training loss: 2.7738232841282926
Validation loss: 2.4649990886941224

Epoch: 169| Step: 0
Training loss: 2.5369534697876173
Validation loss: 2.489577518689239

Epoch: 5| Step: 1
Training loss: 2.459221135407402
Validation loss: 2.505252803885082

Epoch: 5| Step: 2
Training loss: 2.6759884941982732
Validation loss: 2.541053587753278

Epoch: 5| Step: 3
Training loss: 2.263438992044899
Validation loss: 2.5551981826189385

Epoch: 5| Step: 4
Training loss: 2.6407299133767603
Validation loss: 2.571654499201605

Epoch: 5| Step: 5
Training loss: 2.4408361639091285
Validation loss: 2.590259172287218

Epoch: 5| Step: 6
Training loss: 2.698574668344588
Validation loss: 2.5852734187319704

Epoch: 5| Step: 7
Training loss: 2.533500800955303
Validation loss: 2.5679463898923593

Epoch: 5| Step: 8
Training loss: 2.548848049042099
Validation loss: 2.5447582047152175

Epoch: 5| Step: 9
Training loss: 2.7820600551537664
Validation loss: 2.5239235247929126

Epoch: 5| Step: 10
Training loss: 2.261573800035947
Validation loss: 2.526577331222229

Epoch: 170| Step: 0
Training loss: 2.4365080746948036
Validation loss: 2.478475599656587

Epoch: 5| Step: 1
Training loss: 2.4686935032041646
Validation loss: 2.4402424088749637

Epoch: 5| Step: 2
Training loss: 2.518112185159903
Validation loss: 2.428075609132291

Epoch: 5| Step: 3
Training loss: 2.3731592975877738
Validation loss: 2.4139392838727454

Epoch: 5| Step: 4
Training loss: 2.6736357837766107
Validation loss: 2.416546144616666

Epoch: 5| Step: 5
Training loss: 2.4694585628365773
Validation loss: 2.4283482361204602

Epoch: 5| Step: 6
Training loss: 2.74847283007201
Validation loss: 2.4756445728068237

Epoch: 5| Step: 7
Training loss: 2.989400257703347
Validation loss: 2.576970073095798

Epoch: 5| Step: 8
Training loss: 2.656472409978697
Validation loss: 2.5898496041576426

Epoch: 5| Step: 9
Training loss: 2.4311132632836285
Validation loss: 2.548656571034881

Epoch: 5| Step: 10
Training loss: 2.577608831348362
Validation loss: 2.5068446065731393

Epoch: 171| Step: 0
Training loss: 2.4875472826273843
Validation loss: 2.466691814079351

Epoch: 5| Step: 1
Training loss: 2.6054879663951214
Validation loss: 2.4468388733311777

Epoch: 5| Step: 2
Training loss: 2.3054636537346247
Validation loss: 2.4503411655906193

Epoch: 5| Step: 3
Training loss: 2.3741942594921377
Validation loss: 2.4668438885466393

Epoch: 5| Step: 4
Training loss: 2.4658200224319136
Validation loss: 2.4759881095676928

Epoch: 5| Step: 5
Training loss: 2.4368753855593175
Validation loss: 2.4784624337466608

Epoch: 5| Step: 6
Training loss: 2.599067293277131
Validation loss: 2.4999931243063607

Epoch: 5| Step: 7
Training loss: 2.8272885935142216
Validation loss: 2.5480173743477548

Epoch: 5| Step: 8
Training loss: 2.731529193636278
Validation loss: 2.5828557596829063

Epoch: 5| Step: 9
Training loss: 2.2430113232650357
Validation loss: 2.5453565298427283

Epoch: 5| Step: 10
Training loss: 2.709962345157292
Validation loss: 2.528232332858936

Epoch: 172| Step: 0
Training loss: 2.1541328540659483
Validation loss: 2.504360860390471

Epoch: 5| Step: 1
Training loss: 2.2294294137091826
Validation loss: 2.48218150454925

Epoch: 5| Step: 2
Training loss: 3.0290695685592754
Validation loss: 2.4834957175285357

Epoch: 5| Step: 3
Training loss: 1.8964631288636762
Validation loss: 2.4971625787263503

Epoch: 5| Step: 4
Training loss: 2.59647015331971
Validation loss: 2.50851305622081

Epoch: 5| Step: 5
Training loss: 2.9153081363985125
Validation loss: 2.510792689057372

Epoch: 5| Step: 6
Training loss: 2.2604136547531475
Validation loss: 2.5130229117038314

Epoch: 5| Step: 7
Training loss: 2.347355015576645
Validation loss: 2.5415590977276903

Epoch: 5| Step: 8
Training loss: 2.7036553011538427
Validation loss: 2.505622292493628

Epoch: 5| Step: 9
Training loss: 2.3387754418331355
Validation loss: 2.51023277154154

Epoch: 5| Step: 10
Training loss: 2.9346686170618606
Validation loss: 2.503678771520749

Epoch: 173| Step: 0
Training loss: 2.4286019699997206
Validation loss: 2.4858706685281464

Epoch: 5| Step: 1
Training loss: 2.08964078398887
Validation loss: 2.4681878821337873

Epoch: 5| Step: 2
Training loss: 2.545859292288718
Validation loss: 2.4749122256445277

Epoch: 5| Step: 3
Training loss: 2.3475845503688193
Validation loss: 2.4711419134789923

Epoch: 5| Step: 4
Training loss: 2.8365249235583625
Validation loss: 2.46214809327898

Epoch: 5| Step: 5
Training loss: 2.5166301733069996
Validation loss: 2.4771599248757505

Epoch: 5| Step: 6
Training loss: 2.7820394017208043
Validation loss: 2.4866257698912024

Epoch: 5| Step: 7
Training loss: 2.74412064188676
Validation loss: 2.5061896880646013

Epoch: 5| Step: 8
Training loss: 2.4424520221164174
Validation loss: 2.4891012326271693

Epoch: 5| Step: 9
Training loss: 2.621871355347493
Validation loss: 2.49916975632677

Epoch: 5| Step: 10
Training loss: 1.902716566835354
Validation loss: 2.5023652670237366

Epoch: 174| Step: 0
Training loss: 2.613332522677601
Validation loss: 2.5333027094084035

Epoch: 5| Step: 1
Training loss: 2.749934282384596
Validation loss: 2.547794129133283

Epoch: 5| Step: 2
Training loss: 1.8154007292228798
Validation loss: 2.5551890364830268

Epoch: 5| Step: 3
Training loss: 2.1829946716355404
Validation loss: 2.5667343950012067

Epoch: 5| Step: 4
Training loss: 2.718161596006686
Validation loss: 2.555130245993285

Epoch: 5| Step: 5
Training loss: 2.5707589083573517
Validation loss: 2.5386177040660027

Epoch: 5| Step: 6
Training loss: 1.6634926693396204
Validation loss: 2.5260962793814805

Epoch: 5| Step: 7
Training loss: 2.453967976150547
Validation loss: 2.4959560296403454

Epoch: 5| Step: 8
Training loss: 2.2758257404853977
Validation loss: 2.485042659536715

Epoch: 5| Step: 9
Training loss: 2.8809815254824005
Validation loss: 2.467316913149325

Epoch: 5| Step: 10
Training loss: 3.048956370420946
Validation loss: 2.462522238599787

Epoch: 175| Step: 0
Training loss: 2.289525737043796
Validation loss: 2.466476009963741

Epoch: 5| Step: 1
Training loss: 2.3397831216386127
Validation loss: 2.492698946900184

Epoch: 5| Step: 2
Training loss: 2.6456087472670107
Validation loss: 2.515807878698589

Epoch: 5| Step: 3
Training loss: 2.546089847043169
Validation loss: 2.5368959372356663

Epoch: 5| Step: 4
Training loss: 2.6157187824459136
Validation loss: 2.510962134475373

Epoch: 5| Step: 5
Training loss: 2.8194977066780256
Validation loss: 2.5230725447775018

Epoch: 5| Step: 6
Training loss: 2.133293349169504
Validation loss: 2.496822045709159

Epoch: 5| Step: 7
Training loss: 2.3520101837145337
Validation loss: 2.4720349796472676

Epoch: 5| Step: 8
Training loss: 2.8019479957617643
Validation loss: 2.496336176498815

Epoch: 5| Step: 9
Training loss: 2.2450832050766594
Validation loss: 2.4884132137378234

Epoch: 5| Step: 10
Training loss: 2.2244451795473683
Validation loss: 2.5083473720559

Epoch: 176| Step: 0
Training loss: 2.440736431552597
Validation loss: 2.52571224343467

Epoch: 5| Step: 1
Training loss: 2.6374281091519487
Validation loss: 2.5501063503235586

Epoch: 5| Step: 2
Training loss: 2.390574236561474
Validation loss: 2.5262044512698565

Epoch: 5| Step: 3
Training loss: 2.4563070664316484
Validation loss: 2.5320745968551304

Epoch: 5| Step: 4
Training loss: 2.6128401904400524
Validation loss: 2.496484473007366

Epoch: 5| Step: 5
Training loss: 2.8637466780977534
Validation loss: 2.4885324941242786

Epoch: 5| Step: 6
Training loss: 2.2216531806454447
Validation loss: 2.479372033781715

Epoch: 5| Step: 7
Training loss: 2.2914623400602303
Validation loss: 2.493221393947206

Epoch: 5| Step: 8
Training loss: 2.353836531545113
Validation loss: 2.480757432435875

Epoch: 5| Step: 9
Training loss: 2.517572348198134
Validation loss: 2.475800774620447

Epoch: 5| Step: 10
Training loss: 2.0627339548299006
Validation loss: 2.50177283954862

Epoch: 177| Step: 0
Training loss: 2.4296782760199713
Validation loss: 2.5276378328563314

Epoch: 5| Step: 1
Training loss: 2.355490613238086
Validation loss: 2.5456172742341914

Epoch: 5| Step: 2
Training loss: 2.318754038845771
Validation loss: 2.5577276005452765

Epoch: 5| Step: 3
Training loss: 2.2956050553923726
Validation loss: 2.562082302126445

Epoch: 5| Step: 4
Training loss: 2.199712179603437
Validation loss: 2.555076852188518

Epoch: 5| Step: 5
Training loss: 2.7794768435341703
Validation loss: 2.5393370191722084

Epoch: 5| Step: 6
Training loss: 2.5941696746674756
Validation loss: 2.514843295916844

Epoch: 5| Step: 7
Training loss: 2.4480068974740585
Validation loss: 2.5010804825523176

Epoch: 5| Step: 8
Training loss: 2.309512296113281
Validation loss: 2.5114420612404005

Epoch: 5| Step: 9
Training loss: 2.7754887262196832
Validation loss: 2.5004272998168737

Epoch: 5| Step: 10
Training loss: 2.1344680788178088
Validation loss: 2.516026957438811

Epoch: 178| Step: 0
Training loss: 2.349439403953186
Validation loss: 2.5263947511063716

Epoch: 5| Step: 1
Training loss: 2.208026708752347
Validation loss: 2.531827442739355

Epoch: 5| Step: 2
Training loss: 2.848405653063534
Validation loss: 2.556480422562343

Epoch: 5| Step: 3
Training loss: 2.7814589861243144
Validation loss: 2.511447800083199

Epoch: 5| Step: 4
Training loss: 2.8465887300541484
Validation loss: 2.4862140626486324

Epoch: 5| Step: 5
Training loss: 2.097248627396081
Validation loss: 2.5011179342060648

Epoch: 5| Step: 6
Training loss: 2.688190903679507
Validation loss: 2.4917367532769283

Epoch: 5| Step: 7
Training loss: 2.2329525988374193
Validation loss: 2.487770329342332

Epoch: 5| Step: 8
Training loss: 2.4107619750134806
Validation loss: 2.54976912934633

Epoch: 5| Step: 9
Training loss: 2.002167838142823
Validation loss: 2.5787387538711988

Epoch: 5| Step: 10
Training loss: 2.0258976771583086
Validation loss: 2.5857096118925065

Epoch: 179| Step: 0
Training loss: 2.513698242807994
Validation loss: 2.5966995484638624

Epoch: 5| Step: 1
Training loss: 2.373698430036
Validation loss: 2.57817800696688

Epoch: 5| Step: 2
Training loss: 2.547625846412323
Validation loss: 2.5267669130525205

Epoch: 5| Step: 3
Training loss: 2.3651489948010975
Validation loss: 2.5167240154080757

Epoch: 5| Step: 4
Training loss: 2.4495316933681806
Validation loss: 2.521167771248383

Epoch: 5| Step: 5
Training loss: 2.531794265819649
Validation loss: 2.5191227794118274

Epoch: 5| Step: 6
Training loss: 2.5025441575703713
Validation loss: 2.5102583421213014

Epoch: 5| Step: 7
Training loss: 2.4739173216515695
Validation loss: 2.521142890925344

Epoch: 5| Step: 8
Training loss: 2.1481229794636763
Validation loss: 2.5075048212485913

Epoch: 5| Step: 9
Training loss: 2.5570376723896775
Validation loss: 2.4824982061114125

Epoch: 5| Step: 10
Training loss: 1.9239953602558428
Validation loss: 2.4559719040672436

Epoch: 180| Step: 0
Training loss: 2.956610827372059
Validation loss: 2.4301308607658574

Epoch: 5| Step: 1
Training loss: 2.4362834926943338
Validation loss: 2.4410248074415057

Epoch: 5| Step: 2
Training loss: 2.545687720530345
Validation loss: 2.4748330345942255

Epoch: 5| Step: 3
Training loss: 2.0875769184126622
Validation loss: 2.4744447536712575

Epoch: 5| Step: 4
Training loss: 2.287630017030314
Validation loss: 2.501829864075216

Epoch: 5| Step: 5
Training loss: 2.688232322099064
Validation loss: 2.52706501035707

Epoch: 5| Step: 6
Training loss: 2.1951431806437163
Validation loss: 2.579980371907243

Epoch: 5| Step: 7
Training loss: 2.8019371041829473
Validation loss: 2.614985638795125

Epoch: 5| Step: 8
Training loss: 2.2051082909736324
Validation loss: 2.5708056501467427

Epoch: 5| Step: 9
Training loss: 2.186679577246599
Validation loss: 2.491924647363329

Epoch: 5| Step: 10
Training loss: 2.0480121045723467
Validation loss: 2.4599338436160014

Epoch: 181| Step: 0
Training loss: 1.8144916903993245
Validation loss: 2.458055872316983

Epoch: 5| Step: 1
Training loss: 2.8413431231388095
Validation loss: 2.448288139027439

Epoch: 5| Step: 2
Training loss: 2.2853322540059575
Validation loss: 2.4613791136421677

Epoch: 5| Step: 3
Training loss: 2.2274911115235687
Validation loss: 2.4567069306146716

Epoch: 5| Step: 4
Training loss: 1.8638980252527926
Validation loss: 2.4626059120912998

Epoch: 5| Step: 5
Training loss: 2.299347876274473
Validation loss: 2.507935539465054

Epoch: 5| Step: 6
Training loss: 2.3736530299013507
Validation loss: 2.5716309915779534

Epoch: 5| Step: 7
Training loss: 2.666551607351789
Validation loss: 2.637109746590931

Epoch: 5| Step: 8
Training loss: 2.4521274360659806
Validation loss: 2.7644725131906642

Epoch: 5| Step: 9
Training loss: 3.1130792224384884
Validation loss: 2.8603880744193804

Epoch: 5| Step: 10
Training loss: 2.964994765947685
Validation loss: 2.774125456421493

Epoch: 182| Step: 0
Training loss: 2.325410015090081
Validation loss: 2.5938785183602855

Epoch: 5| Step: 1
Training loss: 2.8501760796479854
Validation loss: 2.448803454661489

Epoch: 5| Step: 2
Training loss: 2.297706090340514
Validation loss: 2.4435152254778827

Epoch: 5| Step: 3
Training loss: 2.7161254491921967
Validation loss: 2.4707293454125008

Epoch: 5| Step: 4
Training loss: 1.9437265327239046
Validation loss: 2.465701214328436

Epoch: 5| Step: 5
Training loss: 2.717796684711255
Validation loss: 2.468513763036761

Epoch: 5| Step: 6
Training loss: 2.04125729822932
Validation loss: 2.4544511565978167

Epoch: 5| Step: 7
Training loss: 2.7068639926514844
Validation loss: 2.418972238074198

Epoch: 5| Step: 8
Training loss: 2.6770014966833
Validation loss: 2.4387846202271213

Epoch: 5| Step: 9
Training loss: 2.0833778249440273
Validation loss: 2.4949218067300123

Epoch: 5| Step: 10
Training loss: 2.6804992513941976
Validation loss: 2.5424366784328263

Epoch: 183| Step: 0
Training loss: 2.00026987162387
Validation loss: 2.6528293422996256

Epoch: 5| Step: 1
Training loss: 3.500623647440625
Validation loss: 2.7968518591949114

Epoch: 5| Step: 2
Training loss: 2.5569074125806766
Validation loss: 2.8643113366068595

Epoch: 5| Step: 3
Training loss: 2.334452894103631
Validation loss: 2.6975023036417287

Epoch: 5| Step: 4
Training loss: 2.4928438763259604
Validation loss: 2.6037913062183997

Epoch: 5| Step: 5
Training loss: 2.116455627293482
Validation loss: 2.488646143234667

Epoch: 5| Step: 6
Training loss: 2.2618178377204194
Validation loss: 2.452921677954885

Epoch: 5| Step: 7
Training loss: 2.5761039441503315
Validation loss: 2.452600777778133

Epoch: 5| Step: 8
Training loss: 2.5743871237257956
Validation loss: 2.437648000922672

Epoch: 5| Step: 9
Training loss: 2.5408716886717158
Validation loss: 2.449446453899197

Epoch: 5| Step: 10
Training loss: 2.4438828259051517
Validation loss: 2.461885146953229

Epoch: 184| Step: 0
Training loss: 2.1876732893833903
Validation loss: 2.460546771060182

Epoch: 5| Step: 1
Training loss: 1.9774925245295651
Validation loss: 2.468094451710012

Epoch: 5| Step: 2
Training loss: 2.3968068895274053
Validation loss: 2.4708497741541806

Epoch: 5| Step: 3
Training loss: 2.5038412148157496
Validation loss: 2.5189242125906652

Epoch: 5| Step: 4
Training loss: 2.708592348673293
Validation loss: 2.5767683599509956

Epoch: 5| Step: 5
Training loss: 2.7050881726460507
Validation loss: 2.6009210975118546

Epoch: 5| Step: 6
Training loss: 2.2874543982791313
Validation loss: 2.626295606956473

Epoch: 5| Step: 7
Training loss: 2.7256379841803797
Validation loss: 2.613408325250788

Epoch: 5| Step: 8
Training loss: 2.197939566783718
Validation loss: 2.613936518085671

Epoch: 5| Step: 9
Training loss: 2.5633153781171076
Validation loss: 2.656222796557189

Epoch: 5| Step: 10
Training loss: 2.727245343677722
Validation loss: 2.639549361042368

Epoch: 185| Step: 0
Training loss: 2.3369343649543812
Validation loss: 2.6315102465048557

Epoch: 5| Step: 1
Training loss: 2.553311878774892
Validation loss: 2.6359379522073256

Epoch: 5| Step: 2
Training loss: 2.651937956520087
Validation loss: 2.6125643895771136

Epoch: 5| Step: 3
Training loss: 2.7930976464465846
Validation loss: 2.6021503263671057

Epoch: 5| Step: 4
Training loss: 2.23225782697777
Validation loss: 2.565101799850076

Epoch: 5| Step: 5
Training loss: 2.3733466567333443
Validation loss: 2.5496605817120224

Epoch: 5| Step: 6
Training loss: 2.2935788124502934
Validation loss: 2.538463386170493

Epoch: 5| Step: 7
Training loss: 2.537647780451297
Validation loss: 2.52688670830986

Epoch: 5| Step: 8
Training loss: 2.5344185483227264
Validation loss: 2.5043229761016095

Epoch: 5| Step: 9
Training loss: 1.8035687698819476
Validation loss: 2.4777802113007685

Epoch: 5| Step: 10
Training loss: 2.4995197788592205
Validation loss: 2.46616021869924

Epoch: 186| Step: 0
Training loss: 2.344145677863347
Validation loss: 2.468894319792892

Epoch: 5| Step: 1
Training loss: 2.3623013569310443
Validation loss: 2.481680949657947

Epoch: 5| Step: 2
Training loss: 2.13543897167435
Validation loss: 2.477671946037918

Epoch: 5| Step: 3
Training loss: 2.154878816140192
Validation loss: 2.5104046168034095

Epoch: 5| Step: 4
Training loss: 2.8636802405756954
Validation loss: 2.5375837615618786

Epoch: 5| Step: 5
Training loss: 1.6690015253250896
Validation loss: 2.559157463021225

Epoch: 5| Step: 6
Training loss: 2.0369257345842704
Validation loss: 2.60613597578048

Epoch: 5| Step: 7
Training loss: 2.37880903274004
Validation loss: 2.632782472035321

Epoch: 5| Step: 8
Training loss: 2.7318731579134004
Validation loss: 2.640758983079147

Epoch: 5| Step: 9
Training loss: 2.6465547334109107
Validation loss: 2.642198404903679

Epoch: 5| Step: 10
Training loss: 2.6100721512975937
Validation loss: 2.6553292045971553

Epoch: 187| Step: 0
Training loss: 2.5387785297933814
Validation loss: 2.635643280323929

Epoch: 5| Step: 1
Training loss: 2.5443667364771065
Validation loss: 2.5714321555991457

Epoch: 5| Step: 2
Training loss: 2.451885614928859
Validation loss: 2.5342218658599944

Epoch: 5| Step: 3
Training loss: 2.324823175904966
Validation loss: 2.5288407621179916

Epoch: 5| Step: 4
Training loss: 2.4640155253168934
Validation loss: 2.510149230790957

Epoch: 5| Step: 5
Training loss: 1.9590080465177806
Validation loss: 2.5087159062064877

Epoch: 5| Step: 6
Training loss: 2.4659109087626896
Validation loss: 2.492458493745383

Epoch: 5| Step: 7
Training loss: 2.0674373599691576
Validation loss: 2.5030793319427467

Epoch: 5| Step: 8
Training loss: 2.2715915382409015
Validation loss: 2.5142610460246053

Epoch: 5| Step: 9
Training loss: 1.9589061778502805
Validation loss: 2.5197685662217744

Epoch: 5| Step: 10
Training loss: 2.49526041892586
Validation loss: 2.508090244364759

Epoch: 188| Step: 0
Training loss: 2.092409302490301
Validation loss: 2.523392019367104

Epoch: 5| Step: 1
Training loss: 2.0280043273668937
Validation loss: 2.52611664353231

Epoch: 5| Step: 2
Training loss: 2.1727998808811586
Validation loss: 2.5205120101208287

Epoch: 5| Step: 3
Training loss: 2.462229071879968
Validation loss: 2.5405831063887887

Epoch: 5| Step: 4
Training loss: 2.53972065538422
Validation loss: 2.529793437093579

Epoch: 5| Step: 5
Training loss: 2.592917986789837
Validation loss: 2.53535889556791

Epoch: 5| Step: 6
Training loss: 2.1633918907496685
Validation loss: 2.531243654823225

Epoch: 5| Step: 7
Training loss: 2.3672633394990887
Validation loss: 2.521033041587678

Epoch: 5| Step: 8
Training loss: 2.5499530750519783
Validation loss: 2.5102753420518678

Epoch: 5| Step: 9
Training loss: 1.7031929632502911
Validation loss: 2.5116466344154866

Epoch: 5| Step: 10
Training loss: 2.610428374787602
Validation loss: 2.5217982145371853

Epoch: 189| Step: 0
Training loss: 1.9938403883388316
Validation loss: 2.544890620601365

Epoch: 5| Step: 1
Training loss: 2.180462005725081
Validation loss: 2.5939141429246195

Epoch: 5| Step: 2
Training loss: 2.859893585039315
Validation loss: 2.592619052260536

Epoch: 5| Step: 3
Training loss: 1.5783437445088058
Validation loss: 2.5932366151813544

Epoch: 5| Step: 4
Training loss: 2.450922274704579
Validation loss: 2.571532456797577

Epoch: 5| Step: 5
Training loss: 2.234311296315165
Validation loss: 2.551799654100055

Epoch: 5| Step: 6
Training loss: 2.3027476277184373
Validation loss: 2.524932675401721

Epoch: 5| Step: 7
Training loss: 2.1670873551446608
Validation loss: 2.5025616657644627

Epoch: 5| Step: 8
Training loss: 2.661855549791638
Validation loss: 2.4806090188893584

Epoch: 5| Step: 9
Training loss: 1.992780410199565
Validation loss: 2.491815258968536

Epoch: 5| Step: 10
Training loss: 2.6281768104263445
Validation loss: 2.489141264258526

Epoch: 190| Step: 0
Training loss: 2.250316279752079
Validation loss: 2.473402472042338

Epoch: 5| Step: 1
Training loss: 2.036182108403559
Validation loss: 2.480012353559682

Epoch: 5| Step: 2
Training loss: 2.471592582454932
Validation loss: 2.4896784866470876

Epoch: 5| Step: 3
Training loss: 2.5637648647403775
Validation loss: 2.489986524157088

Epoch: 5| Step: 4
Training loss: 2.1651425747695208
Validation loss: 2.473515335255594

Epoch: 5| Step: 5
Training loss: 2.0037779887833183
Validation loss: 2.488006943974101

Epoch: 5| Step: 6
Training loss: 2.110315296968301
Validation loss: 2.5225560800063187

Epoch: 5| Step: 7
Training loss: 2.4028651222224817
Validation loss: 2.5336141733281585

Epoch: 5| Step: 8
Training loss: 2.2283091336602756
Validation loss: 2.558226751242657

Epoch: 5| Step: 9
Training loss: 2.722920343405808
Validation loss: 2.6075092975284457

Epoch: 5| Step: 10
Training loss: 1.7002400453172604
Validation loss: 2.6025442261461764

Epoch: 191| Step: 0
Training loss: 2.0632731982431167
Validation loss: 2.657545472815072

Epoch: 5| Step: 1
Training loss: 2.2890606251992107
Validation loss: 2.703953595298369

Epoch: 5| Step: 2
Training loss: 2.306729204381167
Validation loss: 2.69404763219464

Epoch: 5| Step: 3
Training loss: 2.0471202907206445
Validation loss: 2.638842579237916

Epoch: 5| Step: 4
Training loss: 2.2962260464834623
Validation loss: 2.5695989826323355

Epoch: 5| Step: 5
Training loss: 2.492251213000731
Validation loss: 2.5174428600427077

Epoch: 5| Step: 6
Training loss: 2.504794958406953
Validation loss: 2.4869656559485303

Epoch: 5| Step: 7
Training loss: 1.8203050343110718
Validation loss: 2.4627796862530174

Epoch: 5| Step: 8
Training loss: 2.3752336889039563
Validation loss: 2.4653288039914325

Epoch: 5| Step: 9
Training loss: 2.2694306080444506
Validation loss: 2.4486629792783616

Epoch: 5| Step: 10
Training loss: 2.2524213477828696
Validation loss: 2.4579600656849023

Epoch: 192| Step: 0
Training loss: 2.2160236640245072
Validation loss: 2.457562207984908

Epoch: 5| Step: 1
Training loss: 2.4740499272038474
Validation loss: 2.4587754723957604

Epoch: 5| Step: 2
Training loss: 2.0345981879795185
Validation loss: 2.4786473360471173

Epoch: 5| Step: 3
Training loss: 2.0445128344186396
Validation loss: 2.5290815716520476

Epoch: 5| Step: 4
Training loss: 2.4300661435956337
Validation loss: 2.574951846274525

Epoch: 5| Step: 5
Training loss: 2.5415047974452087
Validation loss: 2.5869434237821576

Epoch: 5| Step: 6
Training loss: 1.6871576315109604
Validation loss: 2.5549903256885145

Epoch: 5| Step: 7
Training loss: 2.391853764711107
Validation loss: 2.5173924674538917

Epoch: 5| Step: 8
Training loss: 2.2472194869133904
Validation loss: 2.5112845942002853

Epoch: 5| Step: 9
Training loss: 2.478115232816404
Validation loss: 2.4973218642284065

Epoch: 5| Step: 10
Training loss: 2.592030058362713
Validation loss: 2.4575610443350944

Epoch: 193| Step: 0
Training loss: 2.17338081686341
Validation loss: 2.4906239771065333

Epoch: 5| Step: 1
Training loss: 2.2910700512703404
Validation loss: 2.511057208319962

Epoch: 5| Step: 2
Training loss: 2.2639438047814915
Validation loss: 2.555960535811285

Epoch: 5| Step: 3
Training loss: 2.539427839551425
Validation loss: 2.582747536061545

Epoch: 5| Step: 4
Training loss: 2.0490318757049706
Validation loss: 2.5767504595517035

Epoch: 5| Step: 5
Training loss: 2.013152505994053
Validation loss: 2.575981797066558

Epoch: 5| Step: 6
Training loss: 2.2442698097064366
Validation loss: 2.5335596410425767

Epoch: 5| Step: 7
Training loss: 2.419570909716431
Validation loss: 2.521166750334286

Epoch: 5| Step: 8
Training loss: 2.033184714696608
Validation loss: 2.486260406910053

Epoch: 5| Step: 9
Training loss: 2.4976004528964095
Validation loss: 2.4850791593138353

Epoch: 5| Step: 10
Training loss: 2.1986897511601518
Validation loss: 2.5087189524693487

Epoch: 194| Step: 0
Training loss: 1.7548193646797465
Validation loss: 2.5404742782726366

Epoch: 5| Step: 1
Training loss: 2.15559288737599
Validation loss: 2.5724403432326324

Epoch: 5| Step: 2
Training loss: 2.165492827990856
Validation loss: 2.595652080881434

Epoch: 5| Step: 3
Training loss: 2.1207210993220253
Validation loss: 2.5940093498773367

Epoch: 5| Step: 4
Training loss: 2.2435510191178007
Validation loss: 2.5470705665017506

Epoch: 5| Step: 5
Training loss: 1.6999762589535947
Validation loss: 2.540974199067191

Epoch: 5| Step: 6
Training loss: 2.201007772588806
Validation loss: 2.5073574091404036

Epoch: 5| Step: 7
Training loss: 2.4676696731375243
Validation loss: 2.502519830698901

Epoch: 5| Step: 8
Training loss: 2.196473490026437
Validation loss: 2.517809267662472

Epoch: 5| Step: 9
Training loss: 2.7965710011224187
Validation loss: 2.5161129475637667

Epoch: 5| Step: 10
Training loss: 2.5422056491722116
Validation loss: 2.5250686173612213

Epoch: 195| Step: 0
Training loss: 2.2474121470354693
Validation loss: 2.518222206704114

Epoch: 5| Step: 1
Training loss: 2.061125094745335
Validation loss: 2.506506725745912

Epoch: 5| Step: 2
Training loss: 2.25794259194851
Validation loss: 2.4958280125689885

Epoch: 5| Step: 3
Training loss: 2.236985075960951
Validation loss: 2.502003430992561

Epoch: 5| Step: 4
Training loss: 1.8310367186618324
Validation loss: 2.4980888527052785

Epoch: 5| Step: 5
Training loss: 1.8301538148451981
Validation loss: 2.5190484170235985

Epoch: 5| Step: 6
Training loss: 2.6140720328495206
Validation loss: 2.5513010687433435

Epoch: 5| Step: 7
Training loss: 2.48931863141056
Validation loss: 2.5667713900892086

Epoch: 5| Step: 8
Training loss: 2.25650831524369
Validation loss: 2.604659714487753

Epoch: 5| Step: 9
Training loss: 2.2856488601653355
Validation loss: 2.619018035985818

Epoch: 5| Step: 10
Training loss: 2.1103267076856573
Validation loss: 2.588217781486486

Epoch: 196| Step: 0
Training loss: 1.319890152233053
Validation loss: 2.569821463893322

Epoch: 5| Step: 1
Training loss: 2.5098615694817563
Validation loss: 2.55573042813261

Epoch: 5| Step: 2
Training loss: 1.6902976686966322
Validation loss: 2.5438434408408237

Epoch: 5| Step: 3
Training loss: 2.400925529357788
Validation loss: 2.5448322681578013

Epoch: 5| Step: 4
Training loss: 2.3433504908527314
Validation loss: 2.531322667091494

Epoch: 5| Step: 5
Training loss: 2.1506951694188263
Validation loss: 2.534240161747102

Epoch: 5| Step: 6
Training loss: 2.0784213206192432
Validation loss: 2.508264594348515

Epoch: 5| Step: 7
Training loss: 2.1515023859583953
Validation loss: 2.4931675853434196

Epoch: 5| Step: 8
Training loss: 2.6117658797429755
Validation loss: 2.519867508022313

Epoch: 5| Step: 9
Training loss: 2.5008328957723074
Validation loss: 2.5258440399416657

Epoch: 5| Step: 10
Training loss: 2.0107367331610093
Validation loss: 2.529565641435741

Epoch: 197| Step: 0
Training loss: 2.2635336859243895
Validation loss: 2.522462592076895

Epoch: 5| Step: 1
Training loss: 1.8892274215053746
Validation loss: 2.512334172394464

Epoch: 5| Step: 2
Training loss: 2.0162862240209134
Validation loss: 2.506062614713299

Epoch: 5| Step: 3
Training loss: 2.513244734888074
Validation loss: 2.5227094706347075

Epoch: 5| Step: 4
Training loss: 2.9226704702921062
Validation loss: 2.518266916408306

Epoch: 5| Step: 5
Training loss: 2.7870231460031727
Validation loss: 2.5246504800521867

Epoch: 5| Step: 6
Training loss: 1.4863651787328578
Validation loss: 2.5280959191203713

Epoch: 5| Step: 7
Training loss: 1.9335832691871884
Validation loss: 2.530037946640616

Epoch: 5| Step: 8
Training loss: 1.5706259950694625
Validation loss: 2.557242413549358

Epoch: 5| Step: 9
Training loss: 2.1502347330102025
Validation loss: 2.586001319148556

Epoch: 5| Step: 10
Training loss: 2.008065411858693
Validation loss: 2.586373116285147

Epoch: 198| Step: 0
Training loss: 1.9447738330624789
Validation loss: 2.568787913397825

Epoch: 5| Step: 1
Training loss: 2.0509128492002406
Validation loss: 2.5404327052607303

Epoch: 5| Step: 2
Training loss: 1.7069026802581442
Validation loss: 2.483559192094123

Epoch: 5| Step: 3
Training loss: 2.098324347858819
Validation loss: 2.482246209725781

Epoch: 5| Step: 4
Training loss: 2.40500618630484
Validation loss: 2.485185208958314

Epoch: 5| Step: 5
Training loss: 2.2019913374187325
Validation loss: 2.529779315611785

Epoch: 5| Step: 6
Training loss: 2.612428443330266
Validation loss: 2.574373325529125

Epoch: 5| Step: 7
Training loss: 2.305249885866042
Validation loss: 2.581559967488596

Epoch: 5| Step: 8
Training loss: 2.363559674972943
Validation loss: 2.538190625909951

Epoch: 5| Step: 9
Training loss: 2.1603095498624283
Validation loss: 2.497221079037093

Epoch: 5| Step: 10
Training loss: 1.7846733124492502
Validation loss: 2.482258709559346

Epoch: 199| Step: 0
Training loss: 2.7552261976926067
Validation loss: 2.478876252165112

Epoch: 5| Step: 1
Training loss: 1.7039243589590698
Validation loss: 2.50248893491368

Epoch: 5| Step: 2
Training loss: 2.020597018028369
Validation loss: 2.528397285837513

Epoch: 5| Step: 3
Training loss: 1.5196970871205824
Validation loss: 2.5680816511464686

Epoch: 5| Step: 4
Training loss: 2.1648523975476306
Validation loss: 2.6014680217987833

Epoch: 5| Step: 5
Training loss: 2.237430750451872
Validation loss: 2.652329178151087

Epoch: 5| Step: 6
Training loss: 1.9334605778003862
Validation loss: 2.6472718392461068

Epoch: 5| Step: 7
Training loss: 2.4556389822771787
Validation loss: 2.6141217807368995

Epoch: 5| Step: 8
Training loss: 1.9800284533912673
Validation loss: 2.5577876643788366

Epoch: 5| Step: 9
Training loss: 2.214361229061554
Validation loss: 2.486680109750397

Epoch: 5| Step: 10
Training loss: 2.7078627153022947
Validation loss: 2.4509087594281764

Epoch: 200| Step: 0
Training loss: 2.069885209812205
Validation loss: 2.471987618366027

Epoch: 5| Step: 1
Training loss: 2.207142946910812
Validation loss: 2.4565843913708547

Epoch: 5| Step: 2
Training loss: 2.429225865510258
Validation loss: 2.477968970188668

Epoch: 5| Step: 3
Training loss: 2.417121504589796
Validation loss: 2.5170140620803196

Epoch: 5| Step: 4
Training loss: 2.2913337350082306
Validation loss: 2.5657836625388186

Epoch: 5| Step: 5
Training loss: 2.005263911546296
Validation loss: 2.615043835560475

Epoch: 5| Step: 6
Training loss: 2.450870425468826
Validation loss: 2.64524664529788

Epoch: 5| Step: 7
Training loss: 2.009926362278232
Validation loss: 2.579298825249022

Epoch: 5| Step: 8
Training loss: 1.8579810551312967
Validation loss: 2.5381075326724885

Epoch: 5| Step: 9
Training loss: 1.3718918002062275
Validation loss: 2.508171629572888

Epoch: 5| Step: 10
Training loss: 2.4967733541526824
Validation loss: 2.4923667775083045

Epoch: 201| Step: 0
Training loss: 2.1797612222215714
Validation loss: 2.4894215036968865

Epoch: 5| Step: 1
Training loss: 2.279915719900596
Validation loss: 2.485557652852885

Epoch: 5| Step: 2
Training loss: 2.1133745493715486
Validation loss: 2.469903300880437

Epoch: 5| Step: 3
Training loss: 1.816297564792749
Validation loss: 2.4793097796917984

Epoch: 5| Step: 4
Training loss: 1.8823266886535353
Validation loss: 2.460831242989078

Epoch: 5| Step: 5
Training loss: 2.6397534800074007
Validation loss: 2.465971738977672

Epoch: 5| Step: 6
Training loss: 2.1225987499256744
Validation loss: 2.486443195638642

Epoch: 5| Step: 7
Training loss: 2.152672605782581
Validation loss: 2.4982271697123952

Epoch: 5| Step: 8
Training loss: 2.161690634381616
Validation loss: 2.5363075888901734

Epoch: 5| Step: 9
Training loss: 2.3730361247505987
Validation loss: 2.544027706170277

Epoch: 5| Step: 10
Training loss: 1.3834544701372316
Validation loss: 2.586479104270678

Epoch: 202| Step: 0
Training loss: 2.1650033826559305
Validation loss: 2.6158073507277844

Epoch: 5| Step: 1
Training loss: 2.5838596259097066
Validation loss: 2.6503252087588827

Epoch: 5| Step: 2
Training loss: 2.0026007670029324
Validation loss: 2.66107156686637

Epoch: 5| Step: 3
Training loss: 1.333866767669861
Validation loss: 2.6740115516040577

Epoch: 5| Step: 4
Training loss: 2.359206237820424
Validation loss: 2.7277010868544824

Epoch: 5| Step: 5
Training loss: 2.5380577564326217
Validation loss: 2.7217914022602767

Epoch: 5| Step: 6
Training loss: 2.24758612106011
Validation loss: 2.576579535914971

Epoch: 5| Step: 7
Training loss: 1.98336165378557
Validation loss: 2.483390843805383

Epoch: 5| Step: 8
Training loss: 1.7769024311515118
Validation loss: 2.431349522831572

Epoch: 5| Step: 9
Training loss: 1.9286376939217726
Validation loss: 2.4012112854650955

Epoch: 5| Step: 10
Training loss: 2.5641954907059805
Validation loss: 2.4059519280168566

Epoch: 203| Step: 0
Training loss: 2.1507915015760948
Validation loss: 2.4096113873368785

Epoch: 5| Step: 1
Training loss: 2.337336806858149
Validation loss: 2.425992138841377

Epoch: 5| Step: 2
Training loss: 2.5015089249696634
Validation loss: 2.4745540573055065

Epoch: 5| Step: 3
Training loss: 2.508293129566025
Validation loss: 2.589170583095736

Epoch: 5| Step: 4
Training loss: 1.6484009797448567
Validation loss: 2.734238346277162

Epoch: 5| Step: 5
Training loss: 2.232813042439741
Validation loss: 2.8496758751816254

Epoch: 5| Step: 6
Training loss: 2.8063524665051904
Validation loss: 2.9087315212023284

Epoch: 5| Step: 7
Training loss: 1.9778522610777556
Validation loss: 2.7698017327707003

Epoch: 5| Step: 8
Training loss: 2.0963985714839675
Validation loss: 2.61108575301845

Epoch: 5| Step: 9
Training loss: 2.0242297414807355
Validation loss: 2.5092496416636254

Epoch: 5| Step: 10
Training loss: 2.174089469177617
Validation loss: 2.4354263805970184

Epoch: 204| Step: 0
Training loss: 2.2615764355727594
Validation loss: 2.432928975511744

Epoch: 5| Step: 1
Training loss: 2.1044609191412587
Validation loss: 2.4462919465152124

Epoch: 5| Step: 2
Training loss: 2.1461655689799652
Validation loss: 2.4650410842175794

Epoch: 5| Step: 3
Training loss: 2.566299505931505
Validation loss: 2.512642272935525

Epoch: 5| Step: 4
Training loss: 2.578647999745564
Validation loss: 2.5926192134386348

Epoch: 5| Step: 5
Training loss: 1.8578047332729657
Validation loss: 2.514256515760883

Epoch: 5| Step: 6
Training loss: 2.1151200789324522
Validation loss: 2.454628788568309

Epoch: 5| Step: 7
Training loss: 2.231474374126948
Validation loss: 2.4730672889453524

Epoch: 5| Step: 8
Training loss: 2.2709456483089245
Validation loss: 2.504075493899265

Epoch: 5| Step: 9
Training loss: 2.2024482066270608
Validation loss: 2.506708552766689

Epoch: 5| Step: 10
Training loss: 1.9569662543980315
Validation loss: 2.547326533161541

Epoch: 205| Step: 0
Training loss: 2.495972536394442
Validation loss: 2.5805849611787592

Epoch: 5| Step: 1
Training loss: 1.885661395578006
Validation loss: 2.6164034172626773

Epoch: 5| Step: 2
Training loss: 1.9338462587649161
Validation loss: 2.6325137728188137

Epoch: 5| Step: 3
Training loss: 2.0202571663650923
Validation loss: 2.6108980980674312

Epoch: 5| Step: 4
Training loss: 2.6175757276771403
Validation loss: 2.5648520845150706

Epoch: 5| Step: 5
Training loss: 2.399599570406929
Validation loss: 2.513733535605558

Epoch: 5| Step: 6
Training loss: 1.7263985810639044
Validation loss: 2.486190164778447

Epoch: 5| Step: 7
Training loss: 2.4044057540969397
Validation loss: 2.458883175192886

Epoch: 5| Step: 8
Training loss: 1.8701601506569496
Validation loss: 2.4375023411943855

Epoch: 5| Step: 9
Training loss: 2.0203791891303706
Validation loss: 2.47199362147692

Epoch: 5| Step: 10
Training loss: 2.2168347326062565
Validation loss: 2.5210366698872892

Epoch: 206| Step: 0
Training loss: 1.6682753270011843
Validation loss: 2.603804798866662

Epoch: 5| Step: 1
Training loss: 2.1086455037400467
Validation loss: 2.683974494630362

Epoch: 5| Step: 2
Training loss: 1.8093126487200828
Validation loss: 2.676068614777297

Epoch: 5| Step: 3
Training loss: 2.2937360841084704
Validation loss: 2.6473935189185096

Epoch: 5| Step: 4
Training loss: 2.4130570870391894
Validation loss: 2.5993121459924495

Epoch: 5| Step: 5
Training loss: 1.9207049273796073
Validation loss: 2.529703893302265

Epoch: 5| Step: 6
Training loss: 2.0347655172012953
Validation loss: 2.5088436999386605

Epoch: 5| Step: 7
Training loss: 2.176805676241662
Validation loss: 2.490591166394069

Epoch: 5| Step: 8
Training loss: 2.509899376299853
Validation loss: 2.4695932784281367

Epoch: 5| Step: 9
Training loss: 1.8732426991490347
Validation loss: 2.4560892627547526

Epoch: 5| Step: 10
Training loss: 2.3703859583134617
Validation loss: 2.4603225734055774

Epoch: 207| Step: 0
Training loss: 2.311149099488109
Validation loss: 2.471619960316591

Epoch: 5| Step: 1
Training loss: 1.5974544780137467
Validation loss: 2.501087084653951

Epoch: 5| Step: 2
Training loss: 2.103480715094487
Validation loss: 2.494041047532093

Epoch: 5| Step: 3
Training loss: 1.711176607328924
Validation loss: 2.531827937883742

Epoch: 5| Step: 4
Training loss: 1.888314845552144
Validation loss: 2.5633122277154703

Epoch: 5| Step: 5
Training loss: 2.258556837257274
Validation loss: 2.5609307735387086

Epoch: 5| Step: 6
Training loss: 1.9734508764639687
Validation loss: 2.559950700225582

Epoch: 5| Step: 7
Training loss: 2.204130443811387
Validation loss: 2.5689553806871688

Epoch: 5| Step: 8
Training loss: 1.6810969626960368
Validation loss: 2.582386855354846

Epoch: 5| Step: 9
Training loss: 2.4133826227406083
Validation loss: 2.6068548281775357

Epoch: 5| Step: 10
Training loss: 2.2070855868242036
Validation loss: 2.5674184642108715

Epoch: 208| Step: 0
Training loss: 2.0536371019180852
Validation loss: 2.5509418626119342

Epoch: 5| Step: 1
Training loss: 2.2051890559037863
Validation loss: 2.506352739343396

Epoch: 5| Step: 2
Training loss: 1.9614677168313919
Validation loss: 2.4744597980614973

Epoch: 5| Step: 3
Training loss: 1.9098165947301307
Validation loss: 2.4483329933827642

Epoch: 5| Step: 4
Training loss: 2.1272066664052933
Validation loss: 2.4519322504550565

Epoch: 5| Step: 5
Training loss: 2.111244447022132
Validation loss: 2.490824906014873

Epoch: 5| Step: 6
Training loss: 2.117649605070092
Validation loss: 2.5583254006720333

Epoch: 5| Step: 7
Training loss: 2.1919853003002046
Validation loss: 2.588966361694955

Epoch: 5| Step: 8
Training loss: 1.9268052046487152
Validation loss: 2.6127784937365983

Epoch: 5| Step: 9
Training loss: 2.0196729127055217
Validation loss: 2.6527378786750213

Epoch: 5| Step: 10
Training loss: 1.6182523897843768
Validation loss: 2.6194063603505717

Epoch: 209| Step: 0
Training loss: 2.0300755553443066
Validation loss: 2.6272849057668415

Epoch: 5| Step: 1
Training loss: 1.6485122736021838
Validation loss: 2.5926014343461885

Epoch: 5| Step: 2
Training loss: 2.396580278363245
Validation loss: 2.5423782968924025

Epoch: 5| Step: 3
Training loss: 2.3272203569588656
Validation loss: 2.5372841669731594

Epoch: 5| Step: 4
Training loss: 1.7295710385751801
Validation loss: 2.538560592985644

Epoch: 5| Step: 5
Training loss: 1.9981416771138771
Validation loss: 2.528321573878212

Epoch: 5| Step: 6
Training loss: 1.6426691309045498
Validation loss: 2.485469622114426

Epoch: 5| Step: 7
Training loss: 1.9345632877443761
Validation loss: 2.522605973100746

Epoch: 5| Step: 8
Training loss: 2.2153537169873414
Validation loss: 2.5084000639875903

Epoch: 5| Step: 9
Training loss: 2.2599648113380724
Validation loss: 2.5181378376008268

Epoch: 5| Step: 10
Training loss: 1.5581997251437667
Validation loss: 2.5127866683184705

Epoch: 210| Step: 0
Training loss: 1.6464929908536063
Validation loss: 2.5277128472324577

Epoch: 5| Step: 1
Training loss: 1.9494441634050796
Validation loss: 2.5285388865663605

Epoch: 5| Step: 2
Training loss: 1.9888815582514423
Validation loss: 2.5568928693426276

Epoch: 5| Step: 3
Training loss: 2.3763586474789014
Validation loss: 2.580404507532087

Epoch: 5| Step: 4
Training loss: 2.0431220906990464
Validation loss: 2.5737331138382453

Epoch: 5| Step: 5
Training loss: 1.8346379002341542
Validation loss: 2.517491448667687

Epoch: 5| Step: 6
Training loss: 1.8879737234267142
Validation loss: 2.5176449202818034

Epoch: 5| Step: 7
Training loss: 1.6759906629061028
Validation loss: 2.4908655851107175

Epoch: 5| Step: 8
Training loss: 2.1178151006346315
Validation loss: 2.466547263558294

Epoch: 5| Step: 9
Training loss: 2.0324632982457076
Validation loss: 2.451717612824

Epoch: 5| Step: 10
Training loss: 2.263206717199158
Validation loss: 2.4907795822725767

Epoch: 211| Step: 0
Training loss: 1.6901000443590986
Validation loss: 2.529386423064902

Epoch: 5| Step: 1
Training loss: 2.0913037485533703
Validation loss: 2.568765203893386

Epoch: 5| Step: 2
Training loss: 1.7324013004564978
Validation loss: 2.602588468382546

Epoch: 5| Step: 3
Training loss: 1.8111353373646195
Validation loss: 2.5870120599792075

Epoch: 5| Step: 4
Training loss: 1.8131069614021968
Validation loss: 2.5882270327793693

Epoch: 5| Step: 5
Training loss: 1.8864870422751376
Validation loss: 2.571081066602286

Epoch: 5| Step: 6
Training loss: 2.084450638298009
Validation loss: 2.553012599527558

Epoch: 5| Step: 7
Training loss: 2.1333078780245027
Validation loss: 2.5166131597667274

Epoch: 5| Step: 8
Training loss: 2.239338516930436
Validation loss: 2.526944473820912

Epoch: 5| Step: 9
Training loss: 2.0192843789889428
Validation loss: 2.55210731064811

Epoch: 5| Step: 10
Training loss: 1.9111699883807576
Validation loss: 2.563906454469207

Epoch: 212| Step: 0
Training loss: 1.5740015528476137
Validation loss: 2.583785094641529

Epoch: 5| Step: 1
Training loss: 1.8008324208302138
Validation loss: 2.5459580121060084

Epoch: 5| Step: 2
Training loss: 1.9671238435197766
Validation loss: 2.5928046832380205

Epoch: 5| Step: 3
Training loss: 2.0526742100632265
Validation loss: 2.57620057903216

Epoch: 5| Step: 4
Training loss: 1.7560681313394786
Validation loss: 2.5716203517181926

Epoch: 5| Step: 5
Training loss: 2.2149709836553297
Validation loss: 2.5573320015738688

Epoch: 5| Step: 6
Training loss: 2.435459260810099
Validation loss: 2.5691024805107396

Epoch: 5| Step: 7
Training loss: 2.0486981375218027
Validation loss: 2.566429001355247

Epoch: 5| Step: 8
Training loss: 2.0349725504905467
Validation loss: 2.565671256538205

Epoch: 5| Step: 9
Training loss: 1.8542006485928941
Validation loss: 2.5039817378002525

Epoch: 5| Step: 10
Training loss: 1.2407748749188134
Validation loss: 2.477081422510004

Epoch: 213| Step: 0
Training loss: 2.1322555094158115
Validation loss: 2.412638569951457

Epoch: 5| Step: 1
Training loss: 1.603559263427789
Validation loss: 2.4144843017374136

Epoch: 5| Step: 2
Training loss: 1.8407665619224898
Validation loss: 2.468930854782516

Epoch: 5| Step: 3
Training loss: 2.166330849469959
Validation loss: 2.4975248635775924

Epoch: 5| Step: 4
Training loss: 1.69112797445633
Validation loss: 2.526047124033239

Epoch: 5| Step: 5
Training loss: 2.062684137620934
Validation loss: 2.5810914177392332

Epoch: 5| Step: 6
Training loss: 1.8947374369316394
Validation loss: 2.6002860339473934

Epoch: 5| Step: 7
Training loss: 2.5569750142404026
Validation loss: 2.6109647505470783

Epoch: 5| Step: 8
Training loss: 1.8708354476996059
Validation loss: 2.5792789366473627

Epoch: 5| Step: 9
Training loss: 1.4285633274257388
Validation loss: 2.528775460861188

Epoch: 5| Step: 10
Training loss: 1.880656800893396
Validation loss: 2.4985723685118084

Epoch: 214| Step: 0
Training loss: 1.7076978276765609
Validation loss: 2.4787835762473205

Epoch: 5| Step: 1
Training loss: 2.2351613828352788
Validation loss: 2.460965991241856

Epoch: 5| Step: 2
Training loss: 2.37606205533612
Validation loss: 2.494779889691251

Epoch: 5| Step: 3
Training loss: 1.2725862337432883
Validation loss: 2.5110620353231994

Epoch: 5| Step: 4
Training loss: 1.6747760736896065
Validation loss: 2.5675815531923556

Epoch: 5| Step: 5
Training loss: 1.7048278834706192
Validation loss: 2.6077242030868373

Epoch: 5| Step: 6
Training loss: 1.8346327020657998
Validation loss: 2.6222012254318003

Epoch: 5| Step: 7
Training loss: 2.2279836302178153
Validation loss: 2.612005159757478

Epoch: 5| Step: 8
Training loss: 1.8373179987865904
Validation loss: 2.5716712039287053

Epoch: 5| Step: 9
Training loss: 1.5059864272611652
Validation loss: 2.550080242860913

Epoch: 5| Step: 10
Training loss: 2.3480586819374896
Validation loss: 2.5113478472067157

Epoch: 215| Step: 0
Training loss: 1.5619653931617097
Validation loss: 2.5121034148287857

Epoch: 5| Step: 1
Training loss: 1.9194583740808504
Validation loss: 2.5006637010135555

Epoch: 5| Step: 2
Training loss: 1.9364014249021397
Validation loss: 2.475834609713261

Epoch: 5| Step: 3
Training loss: 1.64003023538398
Validation loss: 2.482024664182613

Epoch: 5| Step: 4
Training loss: 2.1817755866588966
Validation loss: 2.4953422482610934

Epoch: 5| Step: 5
Training loss: 2.1920253266799627
Validation loss: 2.4781191308556028

Epoch: 5| Step: 6
Training loss: 1.675329543192278
Validation loss: 2.5078231406993194

Epoch: 5| Step: 7
Training loss: 1.9927737102828025
Validation loss: 2.511785499011037

Epoch: 5| Step: 8
Training loss: 1.5697018778873635
Validation loss: 2.5617599539182345

Epoch: 5| Step: 9
Training loss: 1.9555992018941655
Validation loss: 2.5542607059587112

Epoch: 5| Step: 10
Training loss: 1.8233885744619531
Validation loss: 2.5670978556180444

Epoch: 216| Step: 0
Training loss: 1.657679534670905
Validation loss: 2.594561721018064

Epoch: 5| Step: 1
Training loss: 1.804954740215747
Validation loss: 2.6153723916738962

Epoch: 5| Step: 2
Training loss: 2.28276137360666
Validation loss: 2.660374394059275

Epoch: 5| Step: 3
Training loss: 2.2282784258008252
Validation loss: 2.6498202608711456

Epoch: 5| Step: 4
Training loss: 1.9879772500975754
Validation loss: 2.5832677615203234

Epoch: 5| Step: 5
Training loss: 1.768388189506999
Validation loss: 2.555696419973617

Epoch: 5| Step: 6
Training loss: 1.8908229125290394
Validation loss: 2.4905486485190345

Epoch: 5| Step: 7
Training loss: 2.1006013735776405
Validation loss: 2.462313003908684

Epoch: 5| Step: 8
Training loss: 1.1789548506176655
Validation loss: 2.4469913371873027

Epoch: 5| Step: 9
Training loss: 1.8070834550189763
Validation loss: 2.4390267238773355

Epoch: 5| Step: 10
Training loss: 1.5151211402478202
Validation loss: 2.4780003817053453

Epoch: 217| Step: 0
Training loss: 1.7756663025534054
Validation loss: 2.5324704170214036

Epoch: 5| Step: 1
Training loss: 2.4378936645312828
Validation loss: 2.6200288069837754

Epoch: 5| Step: 2
Training loss: 1.6329588025999828
Validation loss: 2.7026318208033673

Epoch: 5| Step: 3
Training loss: 1.8107588066825449
Validation loss: 2.7364777648538907

Epoch: 5| Step: 4
Training loss: 2.1527514616748977
Validation loss: 2.6726298095699015

Epoch: 5| Step: 5
Training loss: 1.9569901330705959
Validation loss: 2.5615554147091384

Epoch: 5| Step: 6
Training loss: 1.9525278628189224
Validation loss: 2.4740690348824144

Epoch: 5| Step: 7
Training loss: 1.6420239977831184
Validation loss: 2.4464884214774867

Epoch: 5| Step: 8
Training loss: 1.6325576802414012
Validation loss: 2.4095513962357824

Epoch: 5| Step: 9
Training loss: 1.5202564382067045
Validation loss: 2.3861956838116805

Epoch: 5| Step: 10
Training loss: 1.5313523705964995
Validation loss: 2.3942201784332733

Epoch: 218| Step: 0
Training loss: 1.8287712324347885
Validation loss: 2.372625958419105

Epoch: 5| Step: 1
Training loss: 1.8864967104966284
Validation loss: 2.392741544163926

Epoch: 5| Step: 2
Training loss: 1.82963271608763
Validation loss: 2.420646829763047

Epoch: 5| Step: 3
Training loss: 1.553548424335911
Validation loss: 2.4765895144463443

Epoch: 5| Step: 4
Training loss: 1.611841034607168
Validation loss: 2.5561509692347273

Epoch: 5| Step: 5
Training loss: 1.9772443236181387
Validation loss: 2.65490567513712

Epoch: 5| Step: 6
Training loss: 2.19778628813833
Validation loss: 2.680042443406939

Epoch: 5| Step: 7
Training loss: 2.007971850057306
Validation loss: 2.6655664478388994

Epoch: 5| Step: 8
Training loss: 2.110514806164552
Validation loss: 2.59726617403869

Epoch: 5| Step: 9
Training loss: 1.4613271591399508
Validation loss: 2.5611370012341115

Epoch: 5| Step: 10
Training loss: 1.6487044710318137
Validation loss: 2.5113573194017453

Epoch: 219| Step: 0
Training loss: 2.0760228129550184
Validation loss: 2.49713743972068

Epoch: 5| Step: 1
Training loss: 1.509942956061686
Validation loss: 2.473410690305665

Epoch: 5| Step: 2
Training loss: 2.0043909033348712
Validation loss: 2.451355846354738

Epoch: 5| Step: 3
Training loss: 1.645846459380654
Validation loss: 2.4596192490389694

Epoch: 5| Step: 4
Training loss: 1.6764441115076842
Validation loss: 2.4974148458828798

Epoch: 5| Step: 5
Training loss: 1.7462701559029923
Validation loss: 2.525864063071041

Epoch: 5| Step: 6
Training loss: 1.448776547811598
Validation loss: 2.554047996365679

Epoch: 5| Step: 7
Training loss: 1.8613006493701068
Validation loss: 2.6069388485059948

Epoch: 5| Step: 8
Training loss: 1.4349883154150795
Validation loss: 2.6086186356721006

Epoch: 5| Step: 9
Training loss: 1.8485295044677916
Validation loss: 2.604698968116483

Epoch: 5| Step: 10
Training loss: 2.4925423970342377
Validation loss: 2.602905528869056

Epoch: 220| Step: 0
Training loss: 1.6576221468237642
Validation loss: 2.5434993848510583

Epoch: 5| Step: 1
Training loss: 1.5073106157772167
Validation loss: 2.5232531686804887

Epoch: 5| Step: 2
Training loss: 1.8285290524242956
Validation loss: 2.5101566526401156

Epoch: 5| Step: 3
Training loss: 1.7140699304716949
Validation loss: 2.5112953355432386

Epoch: 5| Step: 4
Training loss: 2.1391039268210443
Validation loss: 2.514439469521627

Epoch: 5| Step: 5
Training loss: 1.535116879489786
Validation loss: 2.5148546709076363

Epoch: 5| Step: 6
Training loss: 2.0682100957181593
Validation loss: 2.53000545556082

Epoch: 5| Step: 7
Training loss: 1.494179718902365
Validation loss: 2.527000948583233

Epoch: 5| Step: 8
Training loss: 2.0312703058254873
Validation loss: 2.5244963462124517

Epoch: 5| Step: 9
Training loss: 1.7851084362613454
Validation loss: 2.5638443996525107

Epoch: 5| Step: 10
Training loss: 1.4481596251173232
Validation loss: 2.5853946429389594

Epoch: 221| Step: 0
Training loss: 1.2972993271426267
Validation loss: 2.582521338441035

Epoch: 5| Step: 1
Training loss: 1.6339112012120012
Validation loss: 2.6021134303348186

Epoch: 5| Step: 2
Training loss: 1.951041552341157
Validation loss: 2.6162545360916662

Epoch: 5| Step: 3
Training loss: 1.5470690364709578
Validation loss: 2.582758432328144

Epoch: 5| Step: 4
Training loss: 1.8780596247258148
Validation loss: 2.5493223057061636

Epoch: 5| Step: 5
Training loss: 1.4945063124798075
Validation loss: 2.5386938713809526

Epoch: 5| Step: 6
Training loss: 2.1230085802879644
Validation loss: 2.50941735340202

Epoch: 5| Step: 7
Training loss: 1.9635666930798676
Validation loss: 2.510941891435037

Epoch: 5| Step: 8
Training loss: 1.9206120132518665
Validation loss: 2.5245506853420134

Epoch: 5| Step: 9
Training loss: 1.1177766753554252
Validation loss: 2.53939031284862

Epoch: 5| Step: 10
Training loss: 2.098342413888947
Validation loss: 2.5673599617536698

Epoch: 222| Step: 0
Training loss: 1.661264350433023
Validation loss: 2.5360454051302432

Epoch: 5| Step: 1
Training loss: 1.6043871278085242
Validation loss: 2.5416638427939247

Epoch: 5| Step: 2
Training loss: 1.7836671457382087
Validation loss: 2.547719035863125

Epoch: 5| Step: 3
Training loss: 1.1757087051469064
Validation loss: 2.586962547878055

Epoch: 5| Step: 4
Training loss: 1.5247995401175607
Validation loss: 2.605380561360541

Epoch: 5| Step: 5
Training loss: 2.023973430813487
Validation loss: 2.600125887128878

Epoch: 5| Step: 6
Training loss: 1.9525002052414477
Validation loss: 2.59224872455615

Epoch: 5| Step: 7
Training loss: 1.3698098455849714
Validation loss: 2.5849291754496666

Epoch: 5| Step: 8
Training loss: 1.855979768753775
Validation loss: 2.5850874839636706

Epoch: 5| Step: 9
Training loss: 1.9475421919555482
Validation loss: 2.5979215461957557

Epoch: 5| Step: 10
Training loss: 1.776558302150521
Validation loss: 2.5621057252574135

Epoch: 223| Step: 0
Training loss: 1.544453430530804
Validation loss: 2.5870008105102853

Epoch: 5| Step: 1
Training loss: 1.9184414345215777
Validation loss: 2.5892126938906372

Epoch: 5| Step: 2
Training loss: 1.0331953946204784
Validation loss: 2.6076059527555775

Epoch: 5| Step: 3
Training loss: 1.5802673302007804
Validation loss: 2.5934961676359434

Epoch: 5| Step: 4
Training loss: 1.9387905375843748
Validation loss: 2.60096377208306

Epoch: 5| Step: 5
Training loss: 1.3935927965263786
Validation loss: 2.5802785630008236

Epoch: 5| Step: 6
Training loss: 1.5704104264883403
Validation loss: 2.573425584068629

Epoch: 5| Step: 7
Training loss: 1.8101104901769283
Validation loss: 2.5665031026873546

Epoch: 5| Step: 8
Training loss: 1.8281834258826095
Validation loss: 2.518556259139451

Epoch: 5| Step: 9
Training loss: 1.8196085604290406
Validation loss: 2.529347351713351

Epoch: 5| Step: 10
Training loss: 2.0475246184828784
Validation loss: 2.530046072131885

Epoch: 224| Step: 0
Training loss: 1.5449340665507423
Validation loss: 2.5214938670691005

Epoch: 5| Step: 1
Training loss: 1.660032523537497
Validation loss: 2.5530340142165837

Epoch: 5| Step: 2
Training loss: 1.7559859895299321
Validation loss: 2.6161868003455644

Epoch: 5| Step: 3
Training loss: 1.3914115909942981
Validation loss: 2.643715241662682

Epoch: 5| Step: 4
Training loss: 2.1775686158188265
Validation loss: 2.6385628087710282

Epoch: 5| Step: 5
Training loss: 1.7529363520503531
Validation loss: 2.629303980650554

Epoch: 5| Step: 6
Training loss: 1.5379097586350625
Validation loss: 2.623839563782183

Epoch: 5| Step: 7
Training loss: 1.8456783232460607
Validation loss: 2.6119050710337994

Epoch: 5| Step: 8
Training loss: 1.6474182448991843
Validation loss: 2.591666001036662

Epoch: 5| Step: 9
Training loss: 1.4614498443610742
Validation loss: 2.5565950802356365

Epoch: 5| Step: 10
Training loss: 1.7149945238431912
Validation loss: 2.529374992306772

Epoch: 225| Step: 0
Training loss: 1.267855950283971
Validation loss: 2.5060290353178147

Epoch: 5| Step: 1
Training loss: 1.3328308658743173
Validation loss: 2.498756739436743

Epoch: 5| Step: 2
Training loss: 1.9266397601474075
Validation loss: 2.5286831883060303

Epoch: 5| Step: 3
Training loss: 1.7933321981296468
Validation loss: 2.5322445954063295

Epoch: 5| Step: 4
Training loss: 1.7683185522963982
Validation loss: 2.5474867255644242

Epoch: 5| Step: 5
Training loss: 1.946588855858327
Validation loss: 2.563280846503404

Epoch: 5| Step: 6
Training loss: 1.7261620657012597
Validation loss: 2.5831185356443074

Epoch: 5| Step: 7
Training loss: 1.236554358636076
Validation loss: 2.613985543294832

Epoch: 5| Step: 8
Training loss: 1.9605334348155201
Validation loss: 2.6135261031354733

Epoch: 5| Step: 9
Training loss: 1.7392028422935162
Validation loss: 2.5834870373758387

Epoch: 5| Step: 10
Training loss: 1.3691058841493338
Validation loss: 2.574728590594727

Epoch: 226| Step: 0
Training loss: 1.2562768221596579
Validation loss: 2.560507689411981

Epoch: 5| Step: 1
Training loss: 1.5533808292173024
Validation loss: 2.501548576650579

Epoch: 5| Step: 2
Training loss: 1.807534090725744
Validation loss: 2.5065720078063705

Epoch: 5| Step: 3
Training loss: 1.4684555894931242
Validation loss: 2.5284998741050995

Epoch: 5| Step: 4
Training loss: 1.6105094540782476
Validation loss: 2.5286560714002597

Epoch: 5| Step: 5
Training loss: 1.5109615351630192
Validation loss: 2.576501510528006

Epoch: 5| Step: 6
Training loss: 1.660631968835717
Validation loss: 2.5752027788373297

Epoch: 5| Step: 7
Training loss: 1.8000366922453457
Validation loss: 2.615079769796292

Epoch: 5| Step: 8
Training loss: 1.8029220334596088
Validation loss: 2.6128541465660895

Epoch: 5| Step: 9
Training loss: 1.8327931851070922
Validation loss: 2.6054806350570012

Epoch: 5| Step: 10
Training loss: 1.7837513543640426
Validation loss: 2.5723876475691485

Epoch: 227| Step: 0
Training loss: 1.5238417651463907
Validation loss: 2.5055984907196955

Epoch: 5| Step: 1
Training loss: 1.216626101736434
Validation loss: 2.5134687946507355

Epoch: 5| Step: 2
Training loss: 1.7886971846166737
Validation loss: 2.4890993241359207

Epoch: 5| Step: 3
Training loss: 1.6803499556671944
Validation loss: 2.50705120226097

Epoch: 5| Step: 4
Training loss: 1.8265798184476911
Validation loss: 2.5095351369226413

Epoch: 5| Step: 5
Training loss: 1.900503031747553
Validation loss: 2.5343774040021305

Epoch: 5| Step: 6
Training loss: 1.352912933787765
Validation loss: 2.5559147020939004

Epoch: 5| Step: 7
Training loss: 1.336133708264893
Validation loss: 2.571303376754547

Epoch: 5| Step: 8
Training loss: 1.4569177660071788
Validation loss: 2.5843383138896034

Epoch: 5| Step: 9
Training loss: 1.7862771019237687
Validation loss: 2.598428858241939

Epoch: 5| Step: 10
Training loss: 1.7908909545238882
Validation loss: 2.571546206434306

Epoch: 228| Step: 0
Training loss: 1.6329123726558203
Validation loss: 2.542446076144387

Epoch: 5| Step: 1
Training loss: 1.6280381338775505
Validation loss: 2.495702904188394

Epoch: 5| Step: 2
Training loss: 1.3681736032941563
Validation loss: 2.476804955936765

Epoch: 5| Step: 3
Training loss: 1.7964781613210314
Validation loss: 2.5195235922308243

Epoch: 5| Step: 4
Training loss: 1.6298387086088342
Validation loss: 2.541954149004922

Epoch: 5| Step: 5
Training loss: 1.4746437321380403
Validation loss: 2.5717061023722856

Epoch: 5| Step: 6
Training loss: 1.9829351052088735
Validation loss: 2.595450525719732

Epoch: 5| Step: 7
Training loss: 1.608877605128778
Validation loss: 2.6192929498106454

Epoch: 5| Step: 8
Training loss: 1.6511411506532363
Validation loss: 2.681843890957683

Epoch: 5| Step: 9
Training loss: 1.655821978845752
Validation loss: 2.6555307677694717

Epoch: 5| Step: 10
Training loss: 1.0403266616549507
Validation loss: 2.62415758631131

Epoch: 229| Step: 0
Training loss: 2.0649504698570005
Validation loss: 2.59492957380849

Epoch: 5| Step: 1
Training loss: 1.5376248688892742
Validation loss: 2.5704981640868705

Epoch: 5| Step: 2
Training loss: 1.7238228582374788
Validation loss: 2.550230704312338

Epoch: 5| Step: 3
Training loss: 1.6571518943568386
Validation loss: 2.5334384481365486

Epoch: 5| Step: 4
Training loss: 1.6665928903781244
Validation loss: 2.522202509349376

Epoch: 5| Step: 5
Training loss: 1.0625245147569695
Validation loss: 2.5315986766873615

Epoch: 5| Step: 6
Training loss: 1.2425565831062841
Validation loss: 2.5382456081450626

Epoch: 5| Step: 7
Training loss: 1.5930233963315685
Validation loss: 2.5519231736382646

Epoch: 5| Step: 8
Training loss: 1.5380040900841982
Validation loss: 2.5549036477520217

Epoch: 5| Step: 9
Training loss: 1.882687766347734
Validation loss: 2.5615313745425676

Epoch: 5| Step: 10
Training loss: 1.164156455530173
Validation loss: 2.573819071003118

Epoch: 230| Step: 0
Training loss: 1.282859489147178
Validation loss: 2.5455041111574537

Epoch: 5| Step: 1
Training loss: 1.305881798791591
Validation loss: 2.570377799227394

Epoch: 5| Step: 2
Training loss: 1.5454182556807898
Validation loss: 2.568727600784034

Epoch: 5| Step: 3
Training loss: 1.6156124977793893
Validation loss: 2.5849763651508173

Epoch: 5| Step: 4
Training loss: 1.4356951786171537
Validation loss: 2.569813631764288

Epoch: 5| Step: 5
Training loss: 1.4636778400463502
Validation loss: 2.589254892615283

Epoch: 5| Step: 6
Training loss: 1.7208614211603481
Validation loss: 2.6169668041828538

Epoch: 5| Step: 7
Training loss: 1.3564408743712266
Validation loss: 2.5669604811948794

Epoch: 5| Step: 8
Training loss: 2.155778805761133
Validation loss: 2.5325965616570016

Epoch: 5| Step: 9
Training loss: 1.7865424919509372
Validation loss: 2.4750944810842084

Epoch: 5| Step: 10
Training loss: 1.428044109432586
Validation loss: 2.4275290894812374

Epoch: 231| Step: 0
Training loss: 1.3723529565279315
Validation loss: 2.444422843384909

Epoch: 5| Step: 1
Training loss: 1.6966737125502742
Validation loss: 2.4457873367261285

Epoch: 5| Step: 2
Training loss: 1.0047440057648322
Validation loss: 2.486403265947807

Epoch: 5| Step: 3
Training loss: 1.1811542613473995
Validation loss: 2.5197804149641727

Epoch: 5| Step: 4
Training loss: 1.837641927207424
Validation loss: 2.5723103491421244

Epoch: 5| Step: 5
Training loss: 1.5112677796030258
Validation loss: 2.6589916193277223

Epoch: 5| Step: 6
Training loss: 1.9358119378923972
Validation loss: 2.679943594714728

Epoch: 5| Step: 7
Training loss: 1.7843189905465402
Validation loss: 2.7020197290978

Epoch: 5| Step: 8
Training loss: 1.9095873775462937
Validation loss: 2.716458222317857

Epoch: 5| Step: 9
Training loss: 1.35271047889958
Validation loss: 2.677679931410751

Epoch: 5| Step: 10
Training loss: 1.6126174115158476
Validation loss: 2.642376708923965

Epoch: 232| Step: 0
Training loss: 1.4996562404915954
Validation loss: 2.583972358329978

Epoch: 5| Step: 1
Training loss: 1.733961863757274
Validation loss: 2.5386204932892613

Epoch: 5| Step: 2
Training loss: 1.787068617725984
Validation loss: 2.5213182839341717

Epoch: 5| Step: 3
Training loss: 1.598708797040213
Validation loss: 2.4822095438383043

Epoch: 5| Step: 4
Training loss: 1.496130243160097
Validation loss: 2.4643422554902896

Epoch: 5| Step: 5
Training loss: 1.4868544900962024
Validation loss: 2.4356394130458816

Epoch: 5| Step: 6
Training loss: 1.5124559600975962
Validation loss: 2.4746565882066416

Epoch: 5| Step: 7
Training loss: 1.7722321165573305
Validation loss: 2.4956405176556564

Epoch: 5| Step: 8
Training loss: 1.7141608961963595
Validation loss: 2.5366286630152484

Epoch: 5| Step: 9
Training loss: 1.1112334038403764
Validation loss: 2.542520246263089

Epoch: 5| Step: 10
Training loss: 1.5648340721040597
Validation loss: 2.612885258136956

Epoch: 233| Step: 0
Training loss: 1.2500710467175178
Validation loss: 2.588364286286052

Epoch: 5| Step: 1
Training loss: 1.6024022575718655
Validation loss: 2.6079108389607075

Epoch: 5| Step: 2
Training loss: 1.233415689596906
Validation loss: 2.5966412308239715

Epoch: 5| Step: 3
Training loss: 1.4698005328146426
Validation loss: 2.584585075769498

Epoch: 5| Step: 4
Training loss: 1.4000177246061658
Validation loss: 2.5518560107816857

Epoch: 5| Step: 5
Training loss: 1.766151619754253
Validation loss: 2.5255919285846993

Epoch: 5| Step: 6
Training loss: 1.5762180855747236
Validation loss: 2.5040959327050833

Epoch: 5| Step: 7
Training loss: 1.424224086799604
Validation loss: 2.495107007375651

Epoch: 5| Step: 8
Training loss: 1.5039609428468024
Validation loss: 2.4812888590220914

Epoch: 5| Step: 9
Training loss: 1.8622469480512307
Validation loss: 2.4813831641492543

Epoch: 5| Step: 10
Training loss: 1.771944467841201
Validation loss: 2.452557128824238

Epoch: 234| Step: 0
Training loss: 1.6645553646992484
Validation loss: 2.471375993638971

Epoch: 5| Step: 1
Training loss: 1.6848254732026662
Validation loss: 2.4684940946426344

Epoch: 5| Step: 2
Training loss: 1.1651418917122824
Validation loss: 2.5403681106901566

Epoch: 5| Step: 3
Training loss: 1.734471567575738
Validation loss: 2.576470006379561

Epoch: 5| Step: 4
Training loss: 1.5845040293263428
Validation loss: 2.591168329210599

Epoch: 5| Step: 5
Training loss: 1.7093036811079731
Validation loss: 2.5906146170280437

Epoch: 5| Step: 6
Training loss: 1.0102955001594915
Validation loss: 2.5944626421331667

Epoch: 5| Step: 7
Training loss: 1.562851980618758
Validation loss: 2.619521820204156

Epoch: 5| Step: 8
Training loss: 1.516888121621646
Validation loss: 2.6248063261637795

Epoch: 5| Step: 9
Training loss: 1.633654071819763
Validation loss: 2.6214274987156885

Epoch: 5| Step: 10
Training loss: 1.3089341361463398
Validation loss: 2.600151609917932

Epoch: 235| Step: 0
Training loss: 1.7484579785658758
Validation loss: 2.553576669928048

Epoch: 5| Step: 1
Training loss: 1.3874852171101788
Validation loss: 2.5301010216142172

Epoch: 5| Step: 2
Training loss: 1.3965360618576188
Validation loss: 2.4927679206301994

Epoch: 5| Step: 3
Training loss: 1.4463479122163545
Validation loss: 2.4774053853799676

Epoch: 5| Step: 4
Training loss: 1.1977266354416853
Validation loss: 2.4922168056315606

Epoch: 5| Step: 5
Training loss: 1.8105506938083378
Validation loss: 2.525303240720481

Epoch: 5| Step: 6
Training loss: 1.8593839116243571
Validation loss: 2.532335128536408

Epoch: 5| Step: 7
Training loss: 1.1373205525469086
Validation loss: 2.5490459080828165

Epoch: 5| Step: 8
Training loss: 1.3128465467440784
Validation loss: 2.5506513471076064

Epoch: 5| Step: 9
Training loss: 1.3706273864363505
Validation loss: 2.6195868616327584

Epoch: 5| Step: 10
Training loss: 1.6876810471230153
Validation loss: 2.6217786552678475

Epoch: 236| Step: 0
Training loss: 1.3863581228786164
Validation loss: 2.6461635338660154

Epoch: 5| Step: 1
Training loss: 1.289278047053519
Validation loss: 2.6066500990343493

Epoch: 5| Step: 2
Training loss: 1.561944939252218
Validation loss: 2.5912502027666777

Epoch: 5| Step: 3
Training loss: 1.340103658040268
Validation loss: 2.55271012070244

Epoch: 5| Step: 4
Training loss: 1.7181020035354746
Validation loss: 2.5424224870158647

Epoch: 5| Step: 5
Training loss: 1.52861793228326
Validation loss: 2.5046622968682843

Epoch: 5| Step: 6
Training loss: 1.5792675603409911
Validation loss: 2.4937336696867556

Epoch: 5| Step: 7
Training loss: 1.7973059096088355
Validation loss: 2.480323577061372

Epoch: 5| Step: 8
Training loss: 1.3959182552106724
Validation loss: 2.5244576815492286

Epoch: 5| Step: 9
Training loss: 1.30950645387799
Validation loss: 2.5522672893699583

Epoch: 5| Step: 10
Training loss: 1.3274840210637204
Validation loss: 2.5663021881482506

Epoch: 237| Step: 0
Training loss: 1.5633641714268691
Validation loss: 2.595626865613251

Epoch: 5| Step: 1
Training loss: 1.648985134476465
Validation loss: 2.576976659840104

Epoch: 5| Step: 2
Training loss: 1.4720670700290597
Validation loss: 2.561179454342027

Epoch: 5| Step: 3
Training loss: 1.0371756954504054
Validation loss: 2.5728057080806606

Epoch: 5| Step: 4
Training loss: 1.979559876047311
Validation loss: 2.578390810412194

Epoch: 5| Step: 5
Training loss: 0.9496788824857194
Validation loss: 2.569211923007068

Epoch: 5| Step: 6
Training loss: 1.6142396458539934
Validation loss: 2.5522673908200297

Epoch: 5| Step: 7
Training loss: 1.5060245804268853
Validation loss: 2.5627547606917975

Epoch: 5| Step: 8
Training loss: 1.2108285178088534
Validation loss: 2.554463865234483

Epoch: 5| Step: 9
Training loss: 1.5316346133132865
Validation loss: 2.5291127994267293

Epoch: 5| Step: 10
Training loss: 1.033211086076666
Validation loss: 2.535759423854185

Epoch: 238| Step: 0
Training loss: 1.2709561377219363
Validation loss: 2.5182479303041023

Epoch: 5| Step: 1
Training loss: 1.7649857030402953
Validation loss: 2.5243621831631105

Epoch: 5| Step: 2
Training loss: 1.6148845104578529
Validation loss: 2.5244938765011824

Epoch: 5| Step: 3
Training loss: 1.645799741120503
Validation loss: 2.5163112879511416

Epoch: 5| Step: 4
Training loss: 1.327593394081505
Validation loss: 2.528867148156744

Epoch: 5| Step: 5
Training loss: 0.6893156092801287
Validation loss: 2.5522516439126446

Epoch: 5| Step: 6
Training loss: 1.856170906924985
Validation loss: 2.5838691200137696

Epoch: 5| Step: 7
Training loss: 1.1762251412078593
Validation loss: 2.5965460502735898

Epoch: 5| Step: 8
Training loss: 1.6442534513363338
Validation loss: 2.5968914210294916

Epoch: 5| Step: 9
Training loss: 1.2886265797906484
Validation loss: 2.583617269874182

Epoch: 5| Step: 10
Training loss: 1.1367857608510095
Validation loss: 2.5794641531293756

Epoch: 239| Step: 0
Training loss: 1.4433258424407411
Validation loss: 2.536269722890472

Epoch: 5| Step: 1
Training loss: 1.3967732164137527
Validation loss: 2.5602494838639376

Epoch: 5| Step: 2
Training loss: 1.4706654334842726
Validation loss: 2.5672944599468037

Epoch: 5| Step: 3
Training loss: 1.149723085981349
Validation loss: 2.574537894279394

Epoch: 5| Step: 4
Training loss: 1.6546531032484857
Validation loss: 2.563440204915303

Epoch: 5| Step: 5
Training loss: 1.3514070366327768
Validation loss: 2.565373449129436

Epoch: 5| Step: 6
Training loss: 1.4952234670188442
Validation loss: 2.5606094737789387

Epoch: 5| Step: 7
Training loss: 1.524291283442428
Validation loss: 2.541846218723336

Epoch: 5| Step: 8
Training loss: 1.3918404999779412
Validation loss: 2.5195667831282242

Epoch: 5| Step: 9
Training loss: 1.3483374159569972
Validation loss: 2.559258598136611

Epoch: 5| Step: 10
Training loss: 1.31092958504762
Validation loss: 2.540485360392339

Epoch: 240| Step: 0
Training loss: 1.1804485266295652
Validation loss: 2.568027666096804

Epoch: 5| Step: 1
Training loss: 1.3824128688789448
Validation loss: 2.5798190043283578

Epoch: 5| Step: 2
Training loss: 1.416117486907373
Validation loss: 2.581782406037788

Epoch: 5| Step: 3
Training loss: 1.514801824342663
Validation loss: 2.588568057525737

Epoch: 5| Step: 4
Training loss: 1.303779331656357
Validation loss: 2.548365095839801

Epoch: 5| Step: 5
Training loss: 1.526174502618235
Validation loss: 2.5183922221241724

Epoch: 5| Step: 6
Training loss: 1.4841401566899628
Validation loss: 2.508758884637807

Epoch: 5| Step: 7
Training loss: 1.287030601116914
Validation loss: 2.5066308980729577

Epoch: 5| Step: 8
Training loss: 1.6590283680169575
Validation loss: 2.5247799833845317

Epoch: 5| Step: 9
Training loss: 1.4278584438119857
Validation loss: 2.5359914780881136

Epoch: 5| Step: 10
Training loss: 1.3330211373246568
Validation loss: 2.6021772778737664

Epoch: 241| Step: 0
Training loss: 0.8789633838309244
Validation loss: 2.6084161089192985

Epoch: 5| Step: 1
Training loss: 1.2426666199471978
Validation loss: 2.6534981986269197

Epoch: 5| Step: 2
Training loss: 1.3189732457528394
Validation loss: 2.6622521327392925

Epoch: 5| Step: 3
Training loss: 1.3142019318078344
Validation loss: 2.6356238062019313

Epoch: 5| Step: 4
Training loss: 1.9884362900397687
Validation loss: 2.6092612782303815

Epoch: 5| Step: 5
Training loss: 1.0228341340580949
Validation loss: 2.5953689002368123

Epoch: 5| Step: 6
Training loss: 1.623460627401208
Validation loss: 2.554257046567001

Epoch: 5| Step: 7
Training loss: 1.6807331467770392
Validation loss: 2.5260377404136243

Epoch: 5| Step: 8
Training loss: 1.3570698453150731
Validation loss: 2.5213426770159764

Epoch: 5| Step: 9
Training loss: 1.0420925731978885
Validation loss: 2.51228623353991

Epoch: 5| Step: 10
Training loss: 1.5994191784438574
Validation loss: 2.5079294971653963

Epoch: 242| Step: 0
Training loss: 1.4298800979711461
Validation loss: 2.513333303433531

Epoch: 5| Step: 1
Training loss: 1.3967968571117388
Validation loss: 2.5430968658594524

Epoch: 5| Step: 2
Training loss: 1.3116775842492592
Validation loss: 2.5954856960813806

Epoch: 5| Step: 3
Training loss: 1.806305791395806
Validation loss: 2.6501809311680367

Epoch: 5| Step: 4
Training loss: 1.4546899060025584
Validation loss: 2.6730579913338826

Epoch: 5| Step: 5
Training loss: 1.748547428006015
Validation loss: 2.646081889670516

Epoch: 5| Step: 6
Training loss: 1.2757472522548274
Validation loss: 2.6200781110495144

Epoch: 5| Step: 7
Training loss: 1.1155850315147084
Validation loss: 2.62019754008739

Epoch: 5| Step: 8
Training loss: 1.2104846230546147
Validation loss: 2.557185202125214

Epoch: 5| Step: 9
Training loss: 1.3705433667352263
Validation loss: 2.5268357421206447

Epoch: 5| Step: 10
Training loss: 1.2101928882704498
Validation loss: 2.5343529153541913

Epoch: 243| Step: 0
Training loss: 1.0195389085971627
Validation loss: 2.52468233635358

Epoch: 5| Step: 1
Training loss: 1.4321546269372465
Validation loss: 2.5180069938788057

Epoch: 5| Step: 2
Training loss: 0.5386211689520426
Validation loss: 2.536756153153642

Epoch: 5| Step: 3
Training loss: 1.3955826415600863
Validation loss: 2.5572799279015563

Epoch: 5| Step: 4
Training loss: 1.1824295310864883
Validation loss: 2.581189720703157

Epoch: 5| Step: 5
Training loss: 1.078680752137273
Validation loss: 2.5823610002856046

Epoch: 5| Step: 6
Training loss: 1.6049656880356442
Validation loss: 2.6221137559819643

Epoch: 5| Step: 7
Training loss: 1.6455772136236313
Validation loss: 2.631585114366055

Epoch: 5| Step: 8
Training loss: 1.7162664329592268
Validation loss: 2.646574431260973

Epoch: 5| Step: 9
Training loss: 1.7197831949833655
Validation loss: 2.6538499744796273

Epoch: 5| Step: 10
Training loss: 1.380740580109293
Validation loss: 2.6108851526667833

Epoch: 244| Step: 0
Training loss: 1.4157183315339719
Validation loss: 2.568225084662923

Epoch: 5| Step: 1
Training loss: 1.6213058149131494
Validation loss: 2.567092437918406

Epoch: 5| Step: 2
Training loss: 1.1843972075702869
Validation loss: 2.547493272811314

Epoch: 5| Step: 3
Training loss: 1.5055418953895614
Validation loss: 2.567395289257167

Epoch: 5| Step: 4
Training loss: 0.9833484928665176
Validation loss: 2.5474816395113447

Epoch: 5| Step: 5
Training loss: 1.4145319881119145
Validation loss: 2.5630223676971653

Epoch: 5| Step: 6
Training loss: 1.7134255908118752
Validation loss: 2.6016639049923427

Epoch: 5| Step: 7
Training loss: 1.1092773179582267
Validation loss: 2.5798801904707624

Epoch: 5| Step: 8
Training loss: 1.4391723524613413
Validation loss: 2.6056749670878276

Epoch: 5| Step: 9
Training loss: 1.2938609200073499
Validation loss: 2.587198705630161

Epoch: 5| Step: 10
Training loss: 1.092853942032943
Validation loss: 2.5736720226128034

Epoch: 245| Step: 0
Training loss: 1.407531493463053
Validation loss: 2.5496547981666495

Epoch: 5| Step: 1
Training loss: 0.8748350669183292
Validation loss: 2.5585188193935675

Epoch: 5| Step: 2
Training loss: 1.7929442825808763
Validation loss: 2.533500247447848

Epoch: 5| Step: 3
Training loss: 1.239395939529364
Validation loss: 2.536957728112691

Epoch: 5| Step: 4
Training loss: 1.1624017427819953
Validation loss: 2.5265334037738856

Epoch: 5| Step: 5
Training loss: 1.4831931780204546
Validation loss: 2.579810200869238

Epoch: 5| Step: 6
Training loss: 1.3867574766957083
Validation loss: 2.5674040144635666

Epoch: 5| Step: 7
Training loss: 1.5231904440850548
Validation loss: 2.5603838510819346

Epoch: 5| Step: 8
Training loss: 1.145168816893999
Validation loss: 2.5673484703995557

Epoch: 5| Step: 9
Training loss: 1.191860675135576
Validation loss: 2.5696903980371557

Epoch: 5| Step: 10
Training loss: 1.5670687446973408
Validation loss: 2.5675107445639664

Epoch: 246| Step: 0
Training loss: 1.7776553373425819
Validation loss: 2.5415906684631366

Epoch: 5| Step: 1
Training loss: 1.269031743304166
Validation loss: 2.517847371580342

Epoch: 5| Step: 2
Training loss: 1.0196309826474166
Validation loss: 2.5416665419308373

Epoch: 5| Step: 3
Training loss: 1.306194873723473
Validation loss: 2.5688009661572644

Epoch: 5| Step: 4
Training loss: 1.1722036282378916
Validation loss: 2.5877342405024386

Epoch: 5| Step: 5
Training loss: 1.5788338457255238
Validation loss: 2.6184995173594863

Epoch: 5| Step: 6
Training loss: 1.5130895269648514
Validation loss: 2.6488109522186747

Epoch: 5| Step: 7
Training loss: 1.1575780922106464
Validation loss: 2.6530233881280063

Epoch: 5| Step: 8
Training loss: 1.4601757491163505
Validation loss: 2.6416183945772342

Epoch: 5| Step: 9
Training loss: 1.1035786028420254
Validation loss: 2.6040949369006543

Epoch: 5| Step: 10
Training loss: 1.231792646003916
Validation loss: 2.611609810754891

Epoch: 247| Step: 0
Training loss: 1.675771361990969
Validation loss: 2.56892381992228

Epoch: 5| Step: 1
Training loss: 1.0341648176383171
Validation loss: 2.5775037228853095

Epoch: 5| Step: 2
Training loss: 1.3049211578376305
Validation loss: 2.535057580796375

Epoch: 5| Step: 3
Training loss: 1.2367732254725308
Validation loss: 2.5180919822916

Epoch: 5| Step: 4
Training loss: 1.2913006397225346
Validation loss: 2.5224407826742916

Epoch: 5| Step: 5
Training loss: 1.3769119148310154
Validation loss: 2.5225735448358066

Epoch: 5| Step: 6
Training loss: 1.398225651043916
Validation loss: 2.546897452737552

Epoch: 5| Step: 7
Training loss: 1.3218687467675168
Validation loss: 2.5735262179921463

Epoch: 5| Step: 8
Training loss: 1.1060574854351088
Validation loss: 2.5766220654124066

Epoch: 5| Step: 9
Training loss: 1.36585619822168
Validation loss: 2.572277092394003

Epoch: 5| Step: 10
Training loss: 1.4399284085385318
Validation loss: 2.5809227145562437

Epoch: 248| Step: 0
Training loss: 1.4419791057623124
Validation loss: 2.5815228079569317

Epoch: 5| Step: 1
Training loss: 0.9947891368467642
Validation loss: 2.5713054236355872

Epoch: 5| Step: 2
Training loss: 1.4387581336672275
Validation loss: 2.5613626816986756

Epoch: 5| Step: 3
Training loss: 1.565062138844207
Validation loss: 2.5500433011915677

Epoch: 5| Step: 4
Training loss: 1.2322825792912149
Validation loss: 2.5301149254780713

Epoch: 5| Step: 5
Training loss: 1.4224186790565754
Validation loss: 2.5158151952004384

Epoch: 5| Step: 6
Training loss: 1.2551056541560486
Validation loss: 2.501890547978949

Epoch: 5| Step: 7
Training loss: 1.4589437660377205
Validation loss: 2.5394625905281636

Epoch: 5| Step: 8
Training loss: 0.8733498817676576
Validation loss: 2.557142183440106

Epoch: 5| Step: 9
Training loss: 0.9237594740282417
Validation loss: 2.529660958585223

Epoch: 5| Step: 10
Training loss: 1.7247852136434627
Validation loss: 2.5291283031888967

Epoch: 249| Step: 0
Training loss: 1.3929032511991752
Validation loss: 2.5484919576110894

Epoch: 5| Step: 1
Training loss: 1.2465680693499361
Validation loss: 2.5813168860545384

Epoch: 5| Step: 2
Training loss: 1.594965602061384
Validation loss: 2.5846670249509955

Epoch: 5| Step: 3
Training loss: 1.3098529735351017
Validation loss: 2.60037608613455

Epoch: 5| Step: 4
Training loss: 1.1928702443042156
Validation loss: 2.576593037734647

Epoch: 5| Step: 5
Training loss: 1.5414609857770023
Validation loss: 2.5546210350193057

Epoch: 5| Step: 6
Training loss: 0.9471676176042788
Validation loss: 2.5717000673519523

Epoch: 5| Step: 7
Training loss: 1.3814723962075606
Validation loss: 2.5787671897453284

Epoch: 5| Step: 8
Training loss: 0.8820128743882075
Validation loss: 2.5497170872253565

Epoch: 5| Step: 9
Training loss: 1.3926561074271269
Validation loss: 2.5468059887530385

Epoch: 5| Step: 10
Training loss: 1.2866998000564829
Validation loss: 2.545104350877535

Epoch: 250| Step: 0
Training loss: 1.4477546473174747
Validation loss: 2.507138809595725

Epoch: 5| Step: 1
Training loss: 1.0921613327187958
Validation loss: 2.512448366736904

Epoch: 5| Step: 2
Training loss: 0.9775865602338951
Validation loss: 2.5219492329335247

Epoch: 5| Step: 3
Training loss: 1.5135939842610646
Validation loss: 2.497583420068875

Epoch: 5| Step: 4
Training loss: 0.7582571160787183
Validation loss: 2.50762142383344

Epoch: 5| Step: 5
Training loss: 1.1591875546838393
Validation loss: 2.555096390380953

Epoch: 5| Step: 6
Training loss: 1.7330172611264034
Validation loss: 2.5595940500785415

Epoch: 5| Step: 7
Training loss: 1.6883094400420449
Validation loss: 2.5877650864207875

Epoch: 5| Step: 8
Training loss: 1.11718056416526
Validation loss: 2.592952242354737

Epoch: 5| Step: 9
Training loss: 0.9901520884858168
Validation loss: 2.617936110442619

Epoch: 5| Step: 10
Training loss: 1.3335330138094361
Validation loss: 2.627838148414081

Epoch: 251| Step: 0
Training loss: 1.2162909519871732
Validation loss: 2.6204637493780987

Epoch: 5| Step: 1
Training loss: 1.5252015684148257
Validation loss: 2.6204599495974494

Epoch: 5| Step: 2
Training loss: 1.0966260426445795
Validation loss: 2.572695565227763

Epoch: 5| Step: 3
Training loss: 0.9651435046645925
Validation loss: 2.568536791800474

Epoch: 5| Step: 4
Training loss: 1.4301474409854227
Validation loss: 2.5641980131587987

Epoch: 5| Step: 5
Training loss: 0.8024311467517975
Validation loss: 2.555233322097683

Epoch: 5| Step: 6
Training loss: 1.403985128166358
Validation loss: 2.5574771732034196

Epoch: 5| Step: 7
Training loss: 1.684419575457036
Validation loss: 2.535722970137811

Epoch: 5| Step: 8
Training loss: 1.0999771505930396
Validation loss: 2.531288887028045

Epoch: 5| Step: 9
Training loss: 1.5585698864479522
Validation loss: 2.5565961973053932

Epoch: 5| Step: 10
Training loss: 0.9460443863405742
Validation loss: 2.5882050732861415

Epoch: 252| Step: 0
Training loss: 1.3809160061760748
Validation loss: 2.6235242505182006

Epoch: 5| Step: 1
Training loss: 1.1389788938380379
Validation loss: 2.6107812140121496

Epoch: 5| Step: 2
Training loss: 1.2842107384702508
Validation loss: 2.6072863734814393

Epoch: 5| Step: 3
Training loss: 1.4591092180104297
Validation loss: 2.5805972986051278

Epoch: 5| Step: 4
Training loss: 1.423811882355485
Validation loss: 2.5601203628125586

Epoch: 5| Step: 5
Training loss: 1.0440555011202977
Validation loss: 2.5593536303139652

Epoch: 5| Step: 6
Training loss: 0.8688974104488075
Validation loss: 2.563611115580377

Epoch: 5| Step: 7
Training loss: 1.1086009374147623
Validation loss: 2.5325760709454985

Epoch: 5| Step: 8
Training loss: 1.295858099395148
Validation loss: 2.5637171236092966

Epoch: 5| Step: 9
Training loss: 1.5424328609798525
Validation loss: 2.5584097100856886

Epoch: 5| Step: 10
Training loss: 1.2371123178662058
Validation loss: 2.5980672516865417

Epoch: 253| Step: 0
Training loss: 1.247674925395046
Validation loss: 2.604278993870722

Epoch: 5| Step: 1
Training loss: 1.4844554678538726
Validation loss: 2.6124957897970558

Epoch: 5| Step: 2
Training loss: 1.6725205930801998
Validation loss: 2.5983936182018437

Epoch: 5| Step: 3
Training loss: 1.164031469968395
Validation loss: 2.6044446456376122

Epoch: 5| Step: 4
Training loss: 0.635454971430481
Validation loss: 2.6185672224073873

Epoch: 5| Step: 5
Training loss: 1.2446938427057885
Validation loss: 2.625942752383292

Epoch: 5| Step: 6
Training loss: 1.2791177172826755
Validation loss: 2.6230649246783386

Epoch: 5| Step: 7
Training loss: 1.111403370540712
Validation loss: 2.6111666397768327

Epoch: 5| Step: 8
Training loss: 1.4429060413756265
Validation loss: 2.5917302404751354

Epoch: 5| Step: 9
Training loss: 1.093211559185969
Validation loss: 2.553978427609139

Epoch: 5| Step: 10
Training loss: 1.204637047964191
Validation loss: 2.5216962381021713

Epoch: 254| Step: 0
Training loss: 1.1811777768939151
Validation loss: 2.5289218262327404

Epoch: 5| Step: 1
Training loss: 1.3108305076977702
Validation loss: 2.5224993644633957

Epoch: 5| Step: 2
Training loss: 1.1122335221966424
Validation loss: 2.5222903486599257

Epoch: 5| Step: 3
Training loss: 1.334484135187206
Validation loss: 2.5512394072064293

Epoch: 5| Step: 4
Training loss: 1.243397249585135
Validation loss: 2.5693080602795715

Epoch: 5| Step: 5
Training loss: 1.509532520612303
Validation loss: 2.5853910424883844

Epoch: 5| Step: 6
Training loss: 0.9295917750211383
Validation loss: 2.6272627780092535

Epoch: 5| Step: 7
Training loss: 1.1912626586433623
Validation loss: 2.643505224876485

Epoch: 5| Step: 8
Training loss: 0.8250643473875339
Validation loss: 2.6655873978191775

Epoch: 5| Step: 9
Training loss: 1.2169308902423246
Validation loss: 2.6507373382660577

Epoch: 5| Step: 10
Training loss: 1.691771012018025
Validation loss: 2.6166555242051053

Epoch: 255| Step: 0
Training loss: 1.2161861252355723
Validation loss: 2.567124857062813

Epoch: 5| Step: 1
Training loss: 1.197878707063168
Validation loss: 2.5303576562704406

Epoch: 5| Step: 2
Training loss: 1.0096718248374292
Validation loss: 2.501199684652712

Epoch: 5| Step: 3
Training loss: 1.1554258863482716
Validation loss: 2.4901626003280084

Epoch: 5| Step: 4
Training loss: 1.2614674509833546
Validation loss: 2.524216518240582

Epoch: 5| Step: 5
Training loss: 1.032167431194216
Validation loss: 2.5267818752147697

Epoch: 5| Step: 6
Training loss: 1.065468623973449
Validation loss: 2.570627746190427

Epoch: 5| Step: 7
Training loss: 1.3509313178996436
Validation loss: 2.5691302482012004

Epoch: 5| Step: 8
Training loss: 1.7706857582383444
Validation loss: 2.592848491499703

Epoch: 5| Step: 9
Training loss: 0.8405083444193604
Validation loss: 2.6131390093071585

Epoch: 5| Step: 10
Training loss: 1.5528955915716787
Validation loss: 2.6044002882649417

Epoch: 256| Step: 0
Training loss: 1.1938732183485263
Validation loss: 2.6100516888231406

Epoch: 5| Step: 1
Training loss: 1.3053118645153001
Validation loss: 2.6202713408932063

Epoch: 5| Step: 2
Training loss: 1.283069621069565
Validation loss: 2.5964464349432257

Epoch: 5| Step: 3
Training loss: 0.8670438011637267
Validation loss: 2.5668696671880857

Epoch: 5| Step: 4
Training loss: 1.1331346251157315
Validation loss: 2.5923414857405733

Epoch: 5| Step: 5
Training loss: 1.441264737426896
Validation loss: 2.574784272162704

Epoch: 5| Step: 6
Training loss: 1.4056060164184427
Validation loss: 2.5719613087650472

Epoch: 5| Step: 7
Training loss: 1.3247429364432368
Validation loss: 2.5658792223763762

Epoch: 5| Step: 8
Training loss: 1.2291261644748745
Validation loss: 2.570543843491246

Epoch: 5| Step: 9
Training loss: 1.270879458022926
Validation loss: 2.566225384734518

Epoch: 5| Step: 10
Training loss: 1.0336638434784768
Validation loss: 2.5496280581481088

Epoch: 257| Step: 0
Training loss: 1.1054269088537112
Validation loss: 2.560974097968134

Epoch: 5| Step: 1
Training loss: 1.1517741719171333
Validation loss: 2.5935219937413474

Epoch: 5| Step: 2
Training loss: 1.4470441187978467
Validation loss: 2.615728104068254

Epoch: 5| Step: 3
Training loss: 0.8698999409850219
Validation loss: 2.631415921911127

Epoch: 5| Step: 4
Training loss: 0.825231607756254
Validation loss: 2.6568675168503213

Epoch: 5| Step: 5
Training loss: 1.2126603207337394
Validation loss: 2.647845514595516

Epoch: 5| Step: 6
Training loss: 1.381932770803828
Validation loss: 2.660953330694864

Epoch: 5| Step: 7
Training loss: 1.2906500548362314
Validation loss: 2.629283423114847

Epoch: 5| Step: 8
Training loss: 1.1491423020651133
Validation loss: 2.626094710951579

Epoch: 5| Step: 9
Training loss: 1.4039359656889643
Validation loss: 2.6002302467778553

Epoch: 5| Step: 10
Training loss: 1.3723593410825454
Validation loss: 2.603952261353496

Epoch: 258| Step: 0
Training loss: 0.9869647700216794
Validation loss: 2.554603238845651

Epoch: 5| Step: 1
Training loss: 1.3155461792882006
Validation loss: 2.5648862211565158

Epoch: 5| Step: 2
Training loss: 1.1649644672721626
Validation loss: 2.5524797521367035

Epoch: 5| Step: 3
Training loss: 1.2374340251714095
Validation loss: 2.5698113891632715

Epoch: 5| Step: 4
Training loss: 1.4670656163753735
Validation loss: 2.560022909141396

Epoch: 5| Step: 5
Training loss: 1.897808268941368
Validation loss: 2.560083913502939

Epoch: 5| Step: 6
Training loss: 1.0598136376353837
Validation loss: 2.5837582648232646

Epoch: 5| Step: 7
Training loss: 0.8969542491604435
Validation loss: 2.58171713609393

Epoch: 5| Step: 8
Training loss: 0.7158261412087897
Validation loss: 2.5572288536713477

Epoch: 5| Step: 9
Training loss: 1.449700206150783
Validation loss: 2.595788300329235

Epoch: 5| Step: 10
Training loss: 0.6725608961903153
Validation loss: 2.577850738882991

Epoch: 259| Step: 0
Training loss: 1.7091775141978884
Validation loss: 2.6072065708712153

Epoch: 5| Step: 1
Training loss: 1.2203075530944665
Validation loss: 2.6223650871436393

Epoch: 5| Step: 2
Training loss: 1.1482684471630242
Validation loss: 2.5974452766151686

Epoch: 5| Step: 3
Training loss: 1.1508966184797933
Validation loss: 2.625607525712672

Epoch: 5| Step: 4
Training loss: 0.981175809837608
Validation loss: 2.619956858506065

Epoch: 5| Step: 5
Training loss: 1.4527213243481423
Validation loss: 2.6336102821986986

Epoch: 5| Step: 6
Training loss: 1.1176550360371318
Validation loss: 2.6549683192550044

Epoch: 5| Step: 7
Training loss: 1.6037094240712244
Validation loss: 2.6376797461116532

Epoch: 5| Step: 8
Training loss: 1.0250667968942768
Validation loss: 2.579662202065195

Epoch: 5| Step: 9
Training loss: 0.9129542291476529
Validation loss: 2.587118592066189

Epoch: 5| Step: 10
Training loss: 0.7084211313773884
Validation loss: 2.5496701121658103

Epoch: 260| Step: 0
Training loss: 1.240018474379708
Validation loss: 2.5245844433561264

Epoch: 5| Step: 1
Training loss: 1.2355006433328568
Validation loss: 2.552582796673144

Epoch: 5| Step: 2
Training loss: 1.124859377231453
Validation loss: 2.57029886744243

Epoch: 5| Step: 3
Training loss: 1.3671016993166287
Validation loss: 2.6089797712632845

Epoch: 5| Step: 4
Training loss: 0.8971841777658953
Validation loss: 2.6132505708665548

Epoch: 5| Step: 5
Training loss: 1.2554132550169257
Validation loss: 2.6338686728991982

Epoch: 5| Step: 6
Training loss: 0.8036003917439647
Validation loss: 2.641330810826048

Epoch: 5| Step: 7
Training loss: 1.2563924414506018
Validation loss: 2.637080607496871

Epoch: 5| Step: 8
Training loss: 1.58348946889032
Validation loss: 2.6293723339835977

Epoch: 5| Step: 9
Training loss: 1.036658294915825
Validation loss: 2.6273163665369688

Epoch: 5| Step: 10
Training loss: 1.0594093587249185
Validation loss: 2.5683544081373944

Epoch: 261| Step: 0
Training loss: 1.173806696488321
Validation loss: 2.5629302533272527

Epoch: 5| Step: 1
Training loss: 0.9861877643689532
Validation loss: 2.5628514082669236

Epoch: 5| Step: 2
Training loss: 1.2413474067200254
Validation loss: 2.544376218245164

Epoch: 5| Step: 3
Training loss: 1.0067420419890472
Validation loss: 2.5374536194930397

Epoch: 5| Step: 4
Training loss: 1.0500377307652229
Validation loss: 2.528948386798932

Epoch: 5| Step: 5
Training loss: 1.2069774232979473
Validation loss: 2.5477753610543763

Epoch: 5| Step: 6
Training loss: 1.1415026697770059
Validation loss: 2.5863210900873215

Epoch: 5| Step: 7
Training loss: 0.8558567856680258
Validation loss: 2.5506229500700606

Epoch: 5| Step: 8
Training loss: 1.3384066067055433
Validation loss: 2.6020316808535164

Epoch: 5| Step: 9
Training loss: 1.2482616735210872
Validation loss: 2.5976746626263143

Epoch: 5| Step: 10
Training loss: 1.627710868898249
Validation loss: 2.621905237521429

Epoch: 262| Step: 0
Training loss: 0.954447750823625
Validation loss: 2.614601127022392

Epoch: 5| Step: 1
Training loss: 1.277044838744705
Validation loss: 2.611468768957428

Epoch: 5| Step: 2
Training loss: 1.0341402069711125
Validation loss: 2.6062921364782135

Epoch: 5| Step: 3
Training loss: 1.244613773078851
Validation loss: 2.592252387676172

Epoch: 5| Step: 4
Training loss: 0.9499455561848116
Validation loss: 2.5772625586564724

Epoch: 5| Step: 5
Training loss: 1.5009833927036365
Validation loss: 2.5754183326173483

Epoch: 5| Step: 6
Training loss: 1.0303614863516408
Validation loss: 2.606888219103536

Epoch: 5| Step: 7
Training loss: 0.9755424970973244
Validation loss: 2.5831169616029963

Epoch: 5| Step: 8
Training loss: 0.9915359039538866
Validation loss: 2.5773286267518403

Epoch: 5| Step: 9
Training loss: 1.3704204155806965
Validation loss: 2.5987145268452667

Epoch: 5| Step: 10
Training loss: 1.2939832689008435
Validation loss: 2.627516290039627

Epoch: 263| Step: 0
Training loss: 1.0779234103382753
Validation loss: 2.6243367253214647

Epoch: 5| Step: 1
Training loss: 1.156518131818193
Validation loss: 2.654488667597608

Epoch: 5| Step: 2
Training loss: 0.978224172226351
Validation loss: 2.624047526994055

Epoch: 5| Step: 3
Training loss: 1.0976926315631628
Validation loss: 2.6368792177484157

Epoch: 5| Step: 4
Training loss: 1.176218097428449
Validation loss: 2.669070788355003

Epoch: 5| Step: 5
Training loss: 1.0889651130468627
Validation loss: 2.6647593428544862

Epoch: 5| Step: 6
Training loss: 1.3658862215469456
Validation loss: 2.6487761066360447

Epoch: 5| Step: 7
Training loss: 1.2942869721397223
Validation loss: 2.6335829539257554

Epoch: 5| Step: 8
Training loss: 0.7237724138653315
Validation loss: 2.6052067395483167

Epoch: 5| Step: 9
Training loss: 1.2519762629187454
Validation loss: 2.574045520926514

Epoch: 5| Step: 10
Training loss: 1.279319611558451
Validation loss: 2.5604433840198397

Epoch: 264| Step: 0
Training loss: 0.6973461457249172
Validation loss: 2.5469802300210724

Epoch: 5| Step: 1
Training loss: 1.1066605576572555
Validation loss: 2.5701138946765796

Epoch: 5| Step: 2
Training loss: 1.0458790610804358
Validation loss: 2.545394035562397

Epoch: 5| Step: 3
Training loss: 1.1256042023579629
Validation loss: 2.5849462615096335

Epoch: 5| Step: 4
Training loss: 1.4516134296265881
Validation loss: 2.576339921072352

Epoch: 5| Step: 5
Training loss: 1.2461240280442987
Validation loss: 2.58962451048481

Epoch: 5| Step: 6
Training loss: 0.6693628942995994
Validation loss: 2.6080253312943373

Epoch: 5| Step: 7
Training loss: 1.249672799201612
Validation loss: 2.62759713151919

Epoch: 5| Step: 8
Training loss: 1.1493436391512957
Validation loss: 2.632348764516456

Epoch: 5| Step: 9
Training loss: 1.1578349514121644
Validation loss: 2.6601823955426336

Epoch: 5| Step: 10
Training loss: 1.4259342477307004
Validation loss: 2.6547001669462253

Epoch: 265| Step: 0
Training loss: 0.8310573411982088
Validation loss: 2.639328287441538

Epoch: 5| Step: 1
Training loss: 0.9881065726929578
Validation loss: 2.606200224969964

Epoch: 5| Step: 2
Training loss: 1.1146819287955747
Validation loss: 2.5869413397248184

Epoch: 5| Step: 3
Training loss: 1.055151886605463
Validation loss: 2.5771129576972833

Epoch: 5| Step: 4
Training loss: 1.2415916885336205
Validation loss: 2.5568760329722813

Epoch: 5| Step: 5
Training loss: 1.1124617387857194
Validation loss: 2.561849233859211

Epoch: 5| Step: 6
Training loss: 1.1213033128054477
Validation loss: 2.5597660077384905

Epoch: 5| Step: 7
Training loss: 1.536054896605503
Validation loss: 2.567814973244446

Epoch: 5| Step: 8
Training loss: 1.1523148872510904
Validation loss: 2.5747674283241904

Epoch: 5| Step: 9
Training loss: 1.1362999737853114
Validation loss: 2.568987254410841

Epoch: 5| Step: 10
Training loss: 0.9933660521228476
Validation loss: 2.578130729621693

Epoch: 266| Step: 0
Training loss: 1.489719366873494
Validation loss: 2.6039732069122805

Epoch: 5| Step: 1
Training loss: 1.152912271204268
Validation loss: 2.609390794189079

Epoch: 5| Step: 2
Training loss: 1.2388834647177276
Validation loss: 2.6311562731294895

Epoch: 5| Step: 3
Training loss: 1.0608622888077954
Validation loss: 2.5879107465869193

Epoch: 5| Step: 4
Training loss: 0.9891454966164293
Validation loss: 2.6071559034021554

Epoch: 5| Step: 5
Training loss: 0.9782638987434407
Validation loss: 2.5801881303104377

Epoch: 5| Step: 6
Training loss: 0.8591190997503473
Validation loss: 2.6013437997279216

Epoch: 5| Step: 7
Training loss: 0.9907985186308966
Validation loss: 2.5491868043290307

Epoch: 5| Step: 8
Training loss: 1.3430089903478728
Validation loss: 2.535280305366724

Epoch: 5| Step: 9
Training loss: 1.143671331149486
Validation loss: 2.559542097547517

Epoch: 5| Step: 10
Training loss: 1.0164373816751817
Validation loss: 2.5246859319920865

Epoch: 267| Step: 0
Training loss: 1.1646197732445984
Validation loss: 2.5673340272482337

Epoch: 5| Step: 1
Training loss: 1.5969166431110817
Validation loss: 2.5490901294523183

Epoch: 5| Step: 2
Training loss: 1.0041607485922595
Validation loss: 2.5603415169521857

Epoch: 5| Step: 3
Training loss: 1.3150068593299575
Validation loss: 2.583163438093497

Epoch: 5| Step: 4
Training loss: 0.7263464657770855
Validation loss: 2.569832333663725

Epoch: 5| Step: 5
Training loss: 1.4222580110911365
Validation loss: 2.567282818512307

Epoch: 5| Step: 6
Training loss: 0.8511566454858496
Validation loss: 2.5685808298164474

Epoch: 5| Step: 7
Training loss: 1.021935503740445
Validation loss: 2.547420141140628

Epoch: 5| Step: 8
Training loss: 0.9784371654859597
Validation loss: 2.5494919174029502

Epoch: 5| Step: 9
Training loss: 0.9789511801964426
Validation loss: 2.5652399239044055

Epoch: 5| Step: 10
Training loss: 0.7430392948839298
Validation loss: 2.5521218942152863

Epoch: 268| Step: 0
Training loss: 0.9071428898885354
Validation loss: 2.587866397062423

Epoch: 5| Step: 1
Training loss: 0.975212873548666
Validation loss: 2.5806650823675374

Epoch: 5| Step: 2
Training loss: 0.904950591524777
Validation loss: 2.587417720679187

Epoch: 5| Step: 3
Training loss: 1.318403952516029
Validation loss: 2.5922250466722203

Epoch: 5| Step: 4
Training loss: 0.9631362818330113
Validation loss: 2.6008455421249073

Epoch: 5| Step: 5
Training loss: 0.8113825890411396
Validation loss: 2.6001542720035373

Epoch: 5| Step: 6
Training loss: 1.1878566206455845
Validation loss: 2.5644142150363765

Epoch: 5| Step: 7
Training loss: 1.314279712047258
Validation loss: 2.5661802997942416

Epoch: 5| Step: 8
Training loss: 1.2341811112342684
Validation loss: 2.5486753497245047

Epoch: 5| Step: 9
Training loss: 1.3805905610568827
Validation loss: 2.579908202871274

Epoch: 5| Step: 10
Training loss: 0.936565505625319
Validation loss: 2.5592323306028786

Epoch: 269| Step: 0
Training loss: 1.454204281572763
Validation loss: 2.5719554477810345

Epoch: 5| Step: 1
Training loss: 0.9294660609052847
Validation loss: 2.5776587319752546

Epoch: 5| Step: 2
Training loss: 0.7427283875984534
Validation loss: 2.5826115430153274

Epoch: 5| Step: 3
Training loss: 1.2173006291635953
Validation loss: 2.603898611403617

Epoch: 5| Step: 4
Training loss: 1.0857112841008936
Validation loss: 2.612293134772465

Epoch: 5| Step: 5
Training loss: 1.0218194882308325
Validation loss: 2.621711734028449

Epoch: 5| Step: 6
Training loss: 1.0954493264405303
Validation loss: 2.6172989340506683

Epoch: 5| Step: 7
Training loss: 1.0036108272500588
Validation loss: 2.5918624417971796

Epoch: 5| Step: 8
Training loss: 1.146648908568167
Validation loss: 2.5898846050922733

Epoch: 5| Step: 9
Training loss: 0.9246116686503653
Validation loss: 2.5784635419121806

Epoch: 5| Step: 10
Training loss: 1.1428443533318011
Validation loss: 2.566127709353413

Epoch: 270| Step: 0
Training loss: 0.7698231642030033
Validation loss: 2.5289181494360724

Epoch: 5| Step: 1
Training loss: 0.6687926849219006
Validation loss: 2.560729854286422

Epoch: 5| Step: 2
Training loss: 0.9757278232287606
Validation loss: 2.530580557439308

Epoch: 5| Step: 3
Training loss: 1.2251897042193398
Validation loss: 2.5489922450189946

Epoch: 5| Step: 4
Training loss: 1.4599647751569544
Validation loss: 2.5355139130128146

Epoch: 5| Step: 5
Training loss: 1.0262276276021172
Validation loss: 2.563719594534384

Epoch: 5| Step: 6
Training loss: 1.2045788093744965
Validation loss: 2.5765251508240348

Epoch: 5| Step: 7
Training loss: 1.075918953697223
Validation loss: 2.5635031860656645

Epoch: 5| Step: 8
Training loss: 1.0512733866917225
Validation loss: 2.591162622481591

Epoch: 5| Step: 9
Training loss: 1.152824586022655
Validation loss: 2.579506169696882

Epoch: 5| Step: 10
Training loss: 0.9839504476879153
Validation loss: 2.5723088133354515

Epoch: 271| Step: 0
Training loss: 0.8913321782729721
Validation loss: 2.5845635535117726

Epoch: 5| Step: 1
Training loss: 1.1219520074878506
Validation loss: 2.5866161883770387

Epoch: 5| Step: 2
Training loss: 1.0043078854824168
Validation loss: 2.587082341296358

Epoch: 5| Step: 3
Training loss: 0.8594754593825901
Validation loss: 2.5825353164576184

Epoch: 5| Step: 4
Training loss: 1.0629803749670088
Validation loss: 2.5879325401733384

Epoch: 5| Step: 5
Training loss: 0.9676008792399322
Validation loss: 2.5673374822683193

Epoch: 5| Step: 6
Training loss: 1.3316704941138757
Validation loss: 2.5588067474669947

Epoch: 5| Step: 7
Training loss: 1.4259204535266918
Validation loss: 2.53919041717623

Epoch: 5| Step: 8
Training loss: 1.1125000471479427
Validation loss: 2.550925482421744

Epoch: 5| Step: 9
Training loss: 0.757761019501689
Validation loss: 2.545304270592612

Epoch: 5| Step: 10
Training loss: 1.0988727494070198
Validation loss: 2.548778091421745

Epoch: 272| Step: 0
Training loss: 0.9247644047085741
Validation loss: 2.570731190669183

Epoch: 5| Step: 1
Training loss: 1.1182823418439625
Validation loss: 2.624113096153845

Epoch: 5| Step: 2
Training loss: 0.8619478725196211
Validation loss: 2.635190262789671

Epoch: 5| Step: 3
Training loss: 1.388523099202326
Validation loss: 2.6448467491344974

Epoch: 5| Step: 4
Training loss: 0.9976011053391997
Validation loss: 2.6137143570216597

Epoch: 5| Step: 5
Training loss: 0.8537814426915477
Validation loss: 2.570701013456153

Epoch: 5| Step: 6
Training loss: 0.8780505953181386
Validation loss: 2.5634610524604393

Epoch: 5| Step: 7
Training loss: 1.2828099128799277
Validation loss: 2.51683441849326

Epoch: 5| Step: 8
Training loss: 0.8002393796526491
Validation loss: 2.528879279681297

Epoch: 5| Step: 9
Training loss: 1.2695459922521442
Validation loss: 2.5170937990679283

Epoch: 5| Step: 10
Training loss: 1.2017739376559153
Validation loss: 2.4833894687619495

Epoch: 273| Step: 0
Training loss: 1.2691436645433842
Validation loss: 2.4790848383881396

Epoch: 5| Step: 1
Training loss: 1.1237468627784057
Validation loss: 2.4930487282736506

Epoch: 5| Step: 2
Training loss: 0.6628814966385889
Validation loss: 2.4976877194241096

Epoch: 5| Step: 3
Training loss: 0.7024532500082216
Validation loss: 2.5241893624908536

Epoch: 5| Step: 4
Training loss: 1.2952397159241038
Validation loss: 2.57246464370598

Epoch: 5| Step: 5
Training loss: 1.0718941244749234
Validation loss: 2.5781306629982583

Epoch: 5| Step: 6
Training loss: 0.857506854249569
Validation loss: 2.5929979187033485

Epoch: 5| Step: 7
Training loss: 1.0124899969666463
Validation loss: 2.5994498807958917

Epoch: 5| Step: 8
Training loss: 0.8824104473831378
Validation loss: 2.590076240163048

Epoch: 5| Step: 9
Training loss: 0.9308254426253463
Validation loss: 2.583548223474027

Epoch: 5| Step: 10
Training loss: 1.5755365880593573
Validation loss: 2.5658549639442163

Epoch: 274| Step: 0
Training loss: 0.7299555643483765
Validation loss: 2.557627134852683

Epoch: 5| Step: 1
Training loss: 1.0752350594556432
Validation loss: 2.536737808712842

Epoch: 5| Step: 2
Training loss: 0.8521659882491354
Validation loss: 2.5479655097514704

Epoch: 5| Step: 3
Training loss: 1.3854328049410538
Validation loss: 2.5755418043986276

Epoch: 5| Step: 4
Training loss: 1.034714860200116
Validation loss: 2.561784804027785

Epoch: 5| Step: 5
Training loss: 1.080974517303121
Validation loss: 2.5785443772498398

Epoch: 5| Step: 6
Training loss: 1.185814414089007
Validation loss: 2.6139398742393354

Epoch: 5| Step: 7
Training loss: 0.6820749030721471
Validation loss: 2.6044777918538577

Epoch: 5| Step: 8
Training loss: 0.9313160072845841
Validation loss: 2.5692793735366797

Epoch: 5| Step: 9
Training loss: 1.2923085812135056
Validation loss: 2.5912238959475022

Epoch: 5| Step: 10
Training loss: 0.9315709181964759
Validation loss: 2.574984163481912

Epoch: 275| Step: 0
Training loss: 0.7464175096045488
Validation loss: 2.563487350167714

Epoch: 5| Step: 1
Training loss: 0.9648503291720429
Validation loss: 2.552310610192617

Epoch: 5| Step: 2
Training loss: 1.0508303719422625
Validation loss: 2.5153807649729067

Epoch: 5| Step: 3
Training loss: 1.0747212292479913
Validation loss: 2.4908951841799825

Epoch: 5| Step: 4
Training loss: 1.4087968016654757
Validation loss: 2.5118188238610886

Epoch: 5| Step: 5
Training loss: 0.7300722402597738
Validation loss: 2.4863401537258176

Epoch: 5| Step: 6
Training loss: 0.8650999632168106
Validation loss: 2.4917756056984115

Epoch: 5| Step: 7
Training loss: 1.1992216824672768
Validation loss: 2.5333463595896832

Epoch: 5| Step: 8
Training loss: 1.1644208727659882
Validation loss: 2.5507049481294444

Epoch: 5| Step: 9
Training loss: 0.8471954077418773
Validation loss: 2.600676322346787

Epoch: 5| Step: 10
Training loss: 1.2130430067478184
Validation loss: 2.6280327411273467

Epoch: 276| Step: 0
Training loss: 0.9379657224358141
Validation loss: 2.6415529561693942

Epoch: 5| Step: 1
Training loss: 1.157353827967077
Validation loss: 2.6310501585502477

Epoch: 5| Step: 2
Training loss: 0.9226325527058263
Validation loss: 2.583439319340501

Epoch: 5| Step: 3
Training loss: 1.3131616377950672
Validation loss: 2.561153754540537

Epoch: 5| Step: 4
Training loss: 1.1585103185636214
Validation loss: 2.542524141349551

Epoch: 5| Step: 5
Training loss: 1.0519283797466124
Validation loss: 2.5171659714526022

Epoch: 5| Step: 6
Training loss: 0.9998409621612222
Validation loss: 2.488053944164242

Epoch: 5| Step: 7
Training loss: 1.1735015262452428
Validation loss: 2.5115442478365595

Epoch: 5| Step: 8
Training loss: 0.8752126094825947
Validation loss: 2.5151993382420095

Epoch: 5| Step: 9
Training loss: 0.9637495005763401
Validation loss: 2.5428770912723966

Epoch: 5| Step: 10
Training loss: 0.7932863398131875
Validation loss: 2.5924977782275302

Epoch: 277| Step: 0
Training loss: 1.211636347769598
Validation loss: 2.6052786811000495

Epoch: 5| Step: 1
Training loss: 1.1124173208652894
Validation loss: 2.631700546456593

Epoch: 5| Step: 2
Training loss: 1.060847961512713
Validation loss: 2.6225802123178092

Epoch: 5| Step: 3
Training loss: 1.2322165050570792
Validation loss: 2.5918482977131365

Epoch: 5| Step: 4
Training loss: 1.136886427005594
Validation loss: 2.5610748938281205

Epoch: 5| Step: 5
Training loss: 0.9622038274100155
Validation loss: 2.5616155599246833

Epoch: 5| Step: 6
Training loss: 1.0486145370348838
Validation loss: 2.4930405336140082

Epoch: 5| Step: 7
Training loss: 0.7143740752607153
Validation loss: 2.4843073669502367

Epoch: 5| Step: 8
Training loss: 1.2544838593996588
Validation loss: 2.51630786882575

Epoch: 5| Step: 9
Training loss: 0.7522069329293981
Validation loss: 2.510843890023943

Epoch: 5| Step: 10
Training loss: 0.8046802779679136
Validation loss: 2.4898547776581315

Epoch: 278| Step: 0
Training loss: 1.0643311596912044
Validation loss: 2.5449343430064766

Epoch: 5| Step: 1
Training loss: 0.9642081696247096
Validation loss: 2.564980531599552

Epoch: 5| Step: 2
Training loss: 0.9588731751775801
Validation loss: 2.619568734163695

Epoch: 5| Step: 3
Training loss: 0.8593492677477398
Validation loss: 2.611895288192015

Epoch: 5| Step: 4
Training loss: 1.1169632906777007
Validation loss: 2.597438458017396

Epoch: 5| Step: 5
Training loss: 1.0252436069269668
Validation loss: 2.60558037825382

Epoch: 5| Step: 6
Training loss: 1.4546849890993536
Validation loss: 2.570393928788694

Epoch: 5| Step: 7
Training loss: 1.1529882148312418
Validation loss: 2.5262410017465027

Epoch: 5| Step: 8
Training loss: 0.903145240108101
Validation loss: 2.512505270900839

Epoch: 5| Step: 9
Training loss: 0.8731823161160185
Validation loss: 2.469590005353031

Epoch: 5| Step: 10
Training loss: 0.7902614436131087
Validation loss: 2.46695281866498

Epoch: 279| Step: 0
Training loss: 0.981118036617472
Validation loss: 2.4959719571038184

Epoch: 5| Step: 1
Training loss: 1.2299668030019413
Validation loss: 2.530948704540065

Epoch: 5| Step: 2
Training loss: 1.0301241653563056
Validation loss: 2.560167789497998

Epoch: 5| Step: 3
Training loss: 1.209009074758418
Validation loss: 2.5816473492186884

Epoch: 5| Step: 4
Training loss: 0.62125214770155
Validation loss: 2.569013621285628

Epoch: 5| Step: 5
Training loss: 0.7181427505065641
Validation loss: 2.574655488226181

Epoch: 5| Step: 6
Training loss: 1.3058938941877676
Validation loss: 2.575001239865916

Epoch: 5| Step: 7
Training loss: 0.7355663294961923
Validation loss: 2.556363640732414

Epoch: 5| Step: 8
Training loss: 1.1491818772863742
Validation loss: 2.5776447503890387

Epoch: 5| Step: 9
Training loss: 1.2067897024094005
Validation loss: 2.537476942627552

Epoch: 5| Step: 10
Training loss: 0.4364625858503342
Validation loss: 2.5437190361322353

Epoch: 280| Step: 0
Training loss: 0.9133530170055255
Validation loss: 2.5471563364402314

Epoch: 5| Step: 1
Training loss: 0.9687643665355937
Validation loss: 2.5602272463519897

Epoch: 5| Step: 2
Training loss: 0.8516954090795059
Validation loss: 2.538777126180807

Epoch: 5| Step: 3
Training loss: 1.1141155663648048
Validation loss: 2.5559402730283964

Epoch: 5| Step: 4
Training loss: 0.9710631288225763
Validation loss: 2.563901094519367

Epoch: 5| Step: 5
Training loss: 0.7816982127970136
Validation loss: 2.553521821023494

Epoch: 5| Step: 6
Training loss: 1.0401669132648215
Validation loss: 2.516569724114275

Epoch: 5| Step: 7
Training loss: 1.1304634732094905
Validation loss: 2.545214862545087

Epoch: 5| Step: 8
Training loss: 1.1702879777078448
Validation loss: 2.5314320152326006

Epoch: 5| Step: 9
Training loss: 0.7775105819717987
Validation loss: 2.5402770756651454

Epoch: 5| Step: 10
Training loss: 1.0988012566181908
Validation loss: 2.5123618522045614

Epoch: 281| Step: 0
Training loss: 1.0155889651434855
Validation loss: 2.5172415290768457

Epoch: 5| Step: 1
Training loss: 1.0655985138138153
Validation loss: 2.534586155340442

Epoch: 5| Step: 2
Training loss: 0.7550085833989999
Validation loss: 2.5513231810812553

Epoch: 5| Step: 3
Training loss: 1.2288563654548668
Validation loss: 2.5477329653348613

Epoch: 5| Step: 4
Training loss: 1.282480439897659
Validation loss: 2.594594526132686

Epoch: 5| Step: 5
Training loss: 0.9560858591860346
Validation loss: 2.563820757422634

Epoch: 5| Step: 6
Training loss: 0.8611463497669897
Validation loss: 2.546113927787833

Epoch: 5| Step: 7
Training loss: 1.0155121373775864
Validation loss: 2.5783666831175758

Epoch: 5| Step: 8
Training loss: 0.5864561455811731
Validation loss: 2.5757799065020417

Epoch: 5| Step: 9
Training loss: 1.0909243459790887
Validation loss: 2.5481317452925056

Epoch: 5| Step: 10
Training loss: 0.6849549610061033
Validation loss: 2.5361871459209704

Epoch: 282| Step: 0
Training loss: 0.8865413740435822
Validation loss: 2.5124788446565796

Epoch: 5| Step: 1
Training loss: 1.0817504959263997
Validation loss: 2.527226942032469

Epoch: 5| Step: 2
Training loss: 0.6707996812123614
Validation loss: 2.538483186551521

Epoch: 5| Step: 3
Training loss: 0.9234233074098052
Validation loss: 2.535616711798181

Epoch: 5| Step: 4
Training loss: 0.873319305994012
Validation loss: 2.5503482665632253

Epoch: 5| Step: 5
Training loss: 1.1987572195016691
Validation loss: 2.592554103592802

Epoch: 5| Step: 6
Training loss: 0.8689518069785328
Validation loss: 2.5667923803696473

Epoch: 5| Step: 7
Training loss: 0.7893796226867487
Validation loss: 2.6094505844875284

Epoch: 5| Step: 8
Training loss: 1.0717466449903044
Validation loss: 2.57848193847769

Epoch: 5| Step: 9
Training loss: 1.196329967811494
Validation loss: 2.569137414845

Epoch: 5| Step: 10
Training loss: 0.9454876130642734
Validation loss: 2.567013764640521

Epoch: 283| Step: 0
Training loss: 0.7971379089482671
Validation loss: 2.538339975193625

Epoch: 5| Step: 1
Training loss: 1.1099369613686536
Validation loss: 2.5281818967531193

Epoch: 5| Step: 2
Training loss: 1.0475123159371922
Validation loss: 2.5378056982221078

Epoch: 5| Step: 3
Training loss: 0.9342934129492767
Validation loss: 2.550469533458861

Epoch: 5| Step: 4
Training loss: 0.920340181721297
Validation loss: 2.5190993982898666

Epoch: 5| Step: 5
Training loss: 0.8658586235012148
Validation loss: 2.5359043893468463

Epoch: 5| Step: 6
Training loss: 0.8142844192355955
Validation loss: 2.5527118932594233

Epoch: 5| Step: 7
Training loss: 1.2481687005749302
Validation loss: 2.5686846022443204

Epoch: 5| Step: 8
Training loss: 0.9756683528634912
Validation loss: 2.568821147455065

Epoch: 5| Step: 9
Training loss: 0.9761127809709154
Validation loss: 2.5415007615943472

Epoch: 5| Step: 10
Training loss: 0.7264043574350589
Validation loss: 2.5404409307102562

Epoch: 284| Step: 0
Training loss: 1.0002351722752842
Validation loss: 2.5751843399313774

Epoch: 5| Step: 1
Training loss: 1.1283283800573296
Validation loss: 2.5413713956119057

Epoch: 5| Step: 2
Training loss: 1.1993219784719862
Validation loss: 2.53434640395798

Epoch: 5| Step: 3
Training loss: 0.9005274472160146
Validation loss: 2.528966151131706

Epoch: 5| Step: 4
Training loss: 1.1519135787555626
Validation loss: 2.5482767750560327

Epoch: 5| Step: 5
Training loss: 0.745721174754031
Validation loss: 2.515749062625582

Epoch: 5| Step: 6
Training loss: 0.79123871094664
Validation loss: 2.556593365522583

Epoch: 5| Step: 7
Training loss: 0.5698156674878526
Validation loss: 2.555647267187646

Epoch: 5| Step: 8
Training loss: 1.01981680075689
Validation loss: 2.549337971152242

Epoch: 5| Step: 9
Training loss: 0.9140915499252494
Validation loss: 2.5462135650363664

Epoch: 5| Step: 10
Training loss: 0.8562674778177789
Validation loss: 2.571157914415773

Epoch: 285| Step: 0
Training loss: 0.7216155936102034
Validation loss: 2.581924783540457

Epoch: 5| Step: 1
Training loss: 0.9666934796155341
Validation loss: 2.5550760745908527

Epoch: 5| Step: 2
Training loss: 0.8005900084854335
Validation loss: 2.5625324792451827

Epoch: 5| Step: 3
Training loss: 1.1154787560786428
Validation loss: 2.5380152297005076

Epoch: 5| Step: 4
Training loss: 1.004093494097191
Validation loss: 2.5382174278404435

Epoch: 5| Step: 5
Training loss: 1.0691179166479117
Validation loss: 2.5592856877979107

Epoch: 5| Step: 6
Training loss: 0.7630622166856403
Validation loss: 2.576269695978516

Epoch: 5| Step: 7
Training loss: 1.0852602486591136
Validation loss: 2.5703075244440363

Epoch: 5| Step: 8
Training loss: 0.7312978842943724
Validation loss: 2.5546239713484464

Epoch: 5| Step: 9
Training loss: 1.1104700298739403
Validation loss: 2.5687518086347327

Epoch: 5| Step: 10
Training loss: 0.8911354208508283
Validation loss: 2.5473253466104753

Epoch: 286| Step: 0
Training loss: 0.9887832452270404
Validation loss: 2.578270617139219

Epoch: 5| Step: 1
Training loss: 0.8783075624795547
Validation loss: 2.58291645900778

Epoch: 5| Step: 2
Training loss: 0.7324049884121038
Validation loss: 2.5563792911088523

Epoch: 5| Step: 3
Training loss: 0.8708503280392851
Validation loss: 2.5746244419306685

Epoch: 5| Step: 4
Training loss: 1.1740607159753058
Validation loss: 2.561482136058264

Epoch: 5| Step: 5
Training loss: 0.9466973241914686
Validation loss: 2.558757647415904

Epoch: 5| Step: 6
Training loss: 0.8198748192953453
Validation loss: 2.5441886907152336

Epoch: 5| Step: 7
Training loss: 0.9631060809951398
Validation loss: 2.555691783602226

Epoch: 5| Step: 8
Training loss: 1.0296482593891223
Validation loss: 2.5639739620806434

Epoch: 5| Step: 9
Training loss: 0.9329762351841531
Validation loss: 2.511364758096948

Epoch: 5| Step: 10
Training loss: 0.86404226600175
Validation loss: 2.502526849015859

Epoch: 287| Step: 0
Training loss: 0.9041245957590827
Validation loss: 2.5430267802695994

Epoch: 5| Step: 1
Training loss: 0.8716411153818112
Validation loss: 2.5368309251853627

Epoch: 5| Step: 2
Training loss: 1.0410148234122734
Validation loss: 2.5442051656680666

Epoch: 5| Step: 3
Training loss: 0.5962719312269241
Validation loss: 2.569398623472453

Epoch: 5| Step: 4
Training loss: 0.7945141320649198
Validation loss: 2.5782511173449425

Epoch: 5| Step: 5
Training loss: 1.1704250266316498
Validation loss: 2.5874193674057073

Epoch: 5| Step: 6
Training loss: 0.7775687270744942
Validation loss: 2.6083288907516446

Epoch: 5| Step: 7
Training loss: 1.186114155072831
Validation loss: 2.6013060358388973

Epoch: 5| Step: 8
Training loss: 1.0806030322390836
Validation loss: 2.612589232364394

Epoch: 5| Step: 9
Training loss: 0.847813675145292
Validation loss: 2.5927727463539796

Epoch: 5| Step: 10
Training loss: 0.6111736163290448
Validation loss: 2.5762267840131985

Epoch: 288| Step: 0
Training loss: 0.9182775749014868
Validation loss: 2.539472750326477

Epoch: 5| Step: 1
Training loss: 0.8602264694392445
Validation loss: 2.5428127241393965

Epoch: 5| Step: 2
Training loss: 0.8427313554320165
Validation loss: 2.546880630818105

Epoch: 5| Step: 3
Training loss: 1.0353856246460218
Validation loss: 2.505627187263625

Epoch: 5| Step: 4
Training loss: 0.9582910770277497
Validation loss: 2.542778999930333

Epoch: 5| Step: 5
Training loss: 0.8410429089448599
Validation loss: 2.5425662004417755

Epoch: 5| Step: 6
Training loss: 1.0076542811434395
Validation loss: 2.5184015232731456

Epoch: 5| Step: 7
Training loss: 0.8979369718080513
Validation loss: 2.5751832219651742

Epoch: 5| Step: 8
Training loss: 0.870542137765067
Validation loss: 2.6070708924692916

Epoch: 5| Step: 9
Training loss: 0.9957568328128793
Validation loss: 2.6219044328102075

Epoch: 5| Step: 10
Training loss: 0.9606643226433014
Validation loss: 2.603533213369325

Epoch: 289| Step: 0
Training loss: 0.8816426045163588
Validation loss: 2.571794538617751

Epoch: 5| Step: 1
Training loss: 0.8371637566116105
Validation loss: 2.5943231978443806

Epoch: 5| Step: 2
Training loss: 0.6713437930169562
Validation loss: 2.5887202630452575

Epoch: 5| Step: 3
Training loss: 0.6601890014108438
Validation loss: 2.5747353832071247

Epoch: 5| Step: 4
Training loss: 0.8282556610673901
Validation loss: 2.5759885087482717

Epoch: 5| Step: 5
Training loss: 0.6163964815900819
Validation loss: 2.566589595653414

Epoch: 5| Step: 6
Training loss: 1.0631782386541906
Validation loss: 2.522951894723017

Epoch: 5| Step: 7
Training loss: 1.3196752692090996
Validation loss: 2.5623109709266787

Epoch: 5| Step: 8
Training loss: 0.8583734398023992
Validation loss: 2.526497654068081

Epoch: 5| Step: 9
Training loss: 0.7244740485735701
Validation loss: 2.5598836738760733

Epoch: 5| Step: 10
Training loss: 1.2972214936810957
Validation loss: 2.55282492763048

Epoch: 290| Step: 0
Training loss: 0.8547227995171504
Validation loss: 2.5662081770261604

Epoch: 5| Step: 1
Training loss: 1.0247043601949843
Validation loss: 2.571613938671741

Epoch: 5| Step: 2
Training loss: 0.7410875300629564
Validation loss: 2.5849673898316063

Epoch: 5| Step: 3
Training loss: 1.2884584340891356
Validation loss: 2.5794255282421727

Epoch: 5| Step: 4
Training loss: 0.6985902785571385
Validation loss: 2.577978028166204

Epoch: 5| Step: 5
Training loss: 0.9399765364782456
Validation loss: 2.5717556500117085

Epoch: 5| Step: 6
Training loss: 0.8463457234279371
Validation loss: 2.5813552343569484

Epoch: 5| Step: 7
Training loss: 0.9927639825893403
Validation loss: 2.5661781798934395

Epoch: 5| Step: 8
Training loss: 0.8497621946904775
Validation loss: 2.596904769858517

Epoch: 5| Step: 9
Training loss: 0.9341225503128542
Validation loss: 2.569457212211492

Epoch: 5| Step: 10
Training loss: 0.5300578316589902
Validation loss: 2.563024627741219

Epoch: 291| Step: 0
Training loss: 0.8894150529368648
Validation loss: 2.573211644709362

Epoch: 5| Step: 1
Training loss: 0.8689876121674018
Validation loss: 2.5605798127872013

Epoch: 5| Step: 2
Training loss: 0.8530412486121649
Validation loss: 2.57817587306648

Epoch: 5| Step: 3
Training loss: 1.1948020692930639
Validation loss: 2.525938127377078

Epoch: 5| Step: 4
Training loss: 0.7261040174145367
Validation loss: 2.552216954570301

Epoch: 5| Step: 5
Training loss: 1.035522856662238
Validation loss: 2.5405908974501976

Epoch: 5| Step: 6
Training loss: 1.2021871106568816
Validation loss: 2.5476317190915965

Epoch: 5| Step: 7
Training loss: 0.8635338461183956
Validation loss: 2.552100351330034

Epoch: 5| Step: 8
Training loss: 0.669983307715909
Validation loss: 2.5616709050455913

Epoch: 5| Step: 9
Training loss: 0.7591586789933312
Validation loss: 2.56948186914944

Epoch: 5| Step: 10
Training loss: 0.4614514863458492
Validation loss: 2.579667216721014

Epoch: 292| Step: 0
Training loss: 0.9002622566649408
Validation loss: 2.574428931133034

Epoch: 5| Step: 1
Training loss: 0.92132044130788
Validation loss: 2.5858690841235057

Epoch: 5| Step: 2
Training loss: 0.9394679395494961
Validation loss: 2.5714451002246363

Epoch: 5| Step: 3
Training loss: 0.8958254451552272
Validation loss: 2.560502821458383

Epoch: 5| Step: 4
Training loss: 0.8645436994055088
Validation loss: 2.5807546897430638

Epoch: 5| Step: 5
Training loss: 1.01639721197146
Validation loss: 2.5701158043538834

Epoch: 5| Step: 6
Training loss: 0.54556490786796
Validation loss: 2.567629022281742

Epoch: 5| Step: 7
Training loss: 0.8682754496637574
Validation loss: 2.532223926194154

Epoch: 5| Step: 8
Training loss: 1.0093594883532926
Validation loss: 2.5239614206124505

Epoch: 5| Step: 9
Training loss: 0.7913993752304284
Validation loss: 2.5677027075867986

Epoch: 5| Step: 10
Training loss: 0.9108283381544712
Validation loss: 2.5205361770722474

Epoch: 293| Step: 0
Training loss: 0.7260603040786929
Validation loss: 2.562849389144533

Epoch: 5| Step: 1
Training loss: 0.8523873699995199
Validation loss: 2.5795041539210675

Epoch: 5| Step: 2
Training loss: 0.7589802347758442
Validation loss: 2.570056928385025

Epoch: 5| Step: 3
Training loss: 0.5877566517608045
Validation loss: 2.56341867414157

Epoch: 5| Step: 4
Training loss: 0.7924528275779636
Validation loss: 2.584239063273093

Epoch: 5| Step: 5
Training loss: 1.1231627296729334
Validation loss: 2.572093611941681

Epoch: 5| Step: 6
Training loss: 0.9626408498677989
Validation loss: 2.5536893497938777

Epoch: 5| Step: 7
Training loss: 0.8631805084964025
Validation loss: 2.542883071702367

Epoch: 5| Step: 8
Training loss: 0.7265479383752698
Validation loss: 2.509963106474933

Epoch: 5| Step: 9
Training loss: 1.037750218563475
Validation loss: 2.519416836882275

Epoch: 5| Step: 10
Training loss: 1.1456518838728025
Validation loss: 2.4952116455245954

Epoch: 294| Step: 0
Training loss: 1.1846787921139719
Validation loss: 2.475434116323612

Epoch: 5| Step: 1
Training loss: 0.837480351231801
Validation loss: 2.5029916910904575

Epoch: 5| Step: 2
Training loss: 0.7971227298205948
Validation loss: 2.499638567198317

Epoch: 5| Step: 3
Training loss: 0.7659281694831443
Validation loss: 2.5076766540987365

Epoch: 5| Step: 4
Training loss: 1.1055056292849057
Validation loss: 2.5425121989532116

Epoch: 5| Step: 5
Training loss: 0.7618620517622431
Validation loss: 2.5785522166633714

Epoch: 5| Step: 6
Training loss: 0.5747304699314514
Validation loss: 2.569184886619808

Epoch: 5| Step: 7
Training loss: 0.573450158002883
Validation loss: 2.579225066690076

Epoch: 5| Step: 8
Training loss: 1.0267758848774196
Validation loss: 2.5603112247905973

Epoch: 5| Step: 9
Training loss: 1.1418364897416005
Validation loss: 2.5911467607166405

Epoch: 5| Step: 10
Training loss: 0.4097070141123217
Validation loss: 2.5634996188719277

Epoch: 295| Step: 0
Training loss: 0.6564269508488281
Validation loss: 2.532781008557603

Epoch: 5| Step: 1
Training loss: 0.8778706871295043
Validation loss: 2.545586884402079

Epoch: 5| Step: 2
Training loss: 0.7371180822427228
Validation loss: 2.540212138038176

Epoch: 5| Step: 3
Training loss: 1.172604092448883
Validation loss: 2.5399125163585228

Epoch: 5| Step: 4
Training loss: 0.7738066283720293
Validation loss: 2.5794864106530024

Epoch: 5| Step: 5
Training loss: 0.8247789765997532
Validation loss: 2.5515060913802627

Epoch: 5| Step: 6
Training loss: 1.0876314412627632
Validation loss: 2.5429183067552303

Epoch: 5| Step: 7
Training loss: 0.9458936055903003
Validation loss: 2.5515879334590443

Epoch: 5| Step: 8
Training loss: 0.5825058455030664
Validation loss: 2.5699798371702065

Epoch: 5| Step: 9
Training loss: 0.8815978141670164
Validation loss: 2.5602531807514683

Epoch: 5| Step: 10
Training loss: 0.8661258832079458
Validation loss: 2.5617898897042855

Epoch: 296| Step: 0
Training loss: 1.0920314912062998
Validation loss: 2.577413920923606

Epoch: 5| Step: 1
Training loss: 0.6716013506359448
Validation loss: 2.5618866947621646

Epoch: 5| Step: 2
Training loss: 0.7827566115478716
Validation loss: 2.5596441406547896

Epoch: 5| Step: 3
Training loss: 0.9318162284754475
Validation loss: 2.537884139004422

Epoch: 5| Step: 4
Training loss: 0.9744745134452882
Validation loss: 2.536199355643249

Epoch: 5| Step: 5
Training loss: 0.7499140849177295
Validation loss: 2.536164070709524

Epoch: 5| Step: 6
Training loss: 1.0154820268205904
Validation loss: 2.532564187420974

Epoch: 5| Step: 7
Training loss: 0.7339027590848313
Validation loss: 2.556256463264586

Epoch: 5| Step: 8
Training loss: 0.9306770636019686
Validation loss: 2.5454819261129438

Epoch: 5| Step: 9
Training loss: 0.7928815897126937
Validation loss: 2.5609981228447243

Epoch: 5| Step: 10
Training loss: 0.5504064163747484
Validation loss: 2.571580135581516

Epoch: 297| Step: 0
Training loss: 0.6761457088879573
Validation loss: 2.560467431898429

Epoch: 5| Step: 1
Training loss: 0.667339943616154
Validation loss: 2.538100227908795

Epoch: 5| Step: 2
Training loss: 0.6690979720738719
Validation loss: 2.548283072790527

Epoch: 5| Step: 3
Training loss: 0.8618457994500665
Validation loss: 2.5262950679199627

Epoch: 5| Step: 4
Training loss: 1.0223690017130593
Validation loss: 2.5175722555329507

Epoch: 5| Step: 5
Training loss: 1.1120181229473036
Validation loss: 2.5279406516446685

Epoch: 5| Step: 6
Training loss: 0.6325401143783976
Validation loss: 2.5214928483204653

Epoch: 5| Step: 7
Training loss: 0.8570892801172755
Validation loss: 2.5282662703699144

Epoch: 5| Step: 8
Training loss: 1.2246692405560116
Validation loss: 2.5283891682287853

Epoch: 5| Step: 9
Training loss: 0.5633612503191945
Validation loss: 2.5314285071560416

Epoch: 5| Step: 10
Training loss: 0.8490749388265542
Validation loss: 2.55666550681896

Epoch: 298| Step: 0
Training loss: 0.8631044439786344
Validation loss: 2.547319720801037

Epoch: 5| Step: 1
Training loss: 0.7762752070611159
Validation loss: 2.558408292192186

Epoch: 5| Step: 2
Training loss: 0.8794454319449615
Validation loss: 2.571068827095678

Epoch: 5| Step: 3
Training loss: 0.8045511222751398
Validation loss: 2.592613719534097

Epoch: 5| Step: 4
Training loss: 0.6471610086601244
Validation loss: 2.5907094653037843

Epoch: 5| Step: 5
Training loss: 1.0304885133550088
Validation loss: 2.573374225580166

Epoch: 5| Step: 6
Training loss: 0.6765487369961135
Validation loss: 2.554417834048674

Epoch: 5| Step: 7
Training loss: 1.0354632803992794
Validation loss: 2.551978859553387

Epoch: 5| Step: 8
Training loss: 0.902220019820406
Validation loss: 2.5370317919143592

Epoch: 5| Step: 9
Training loss: 0.8502001582821932
Validation loss: 2.5321874357541714

Epoch: 5| Step: 10
Training loss: 0.6728381417185894
Validation loss: 2.533949997651459

Epoch: 299| Step: 0
Training loss: 0.9059815173526988
Validation loss: 2.5398404271132913

Epoch: 5| Step: 1
Training loss: 0.9033806528094299
Validation loss: 2.5327088104619473

Epoch: 5| Step: 2
Training loss: 0.6340363524090298
Validation loss: 2.5346885467268656

Epoch: 5| Step: 3
Training loss: 0.7146142476533887
Validation loss: 2.5715437290726193

Epoch: 5| Step: 4
Training loss: 0.7182305988595324
Validation loss: 2.578231584589941

Epoch: 5| Step: 5
Training loss: 0.9097565194735231
Validation loss: 2.5689316238280107

Epoch: 5| Step: 6
Training loss: 0.9753964596208339
Validation loss: 2.552028786179062

Epoch: 5| Step: 7
Training loss: 1.091623527946078
Validation loss: 2.561139762178945

Epoch: 5| Step: 8
Training loss: 0.6514743791081649
Validation loss: 2.573404480530124

Epoch: 5| Step: 9
Training loss: 0.8525200456069177
Validation loss: 2.5573223778737026

Epoch: 5| Step: 10
Training loss: 0.7658628755944938
Validation loss: 2.5396573297439162

Epoch: 300| Step: 0
Training loss: 0.9621043989987541
Validation loss: 2.5215525542260453

Epoch: 5| Step: 1
Training loss: 0.6710325326409431
Validation loss: 2.5283400229836026

Epoch: 5| Step: 2
Training loss: 0.7472483304420828
Validation loss: 2.549585897355177

Epoch: 5| Step: 3
Training loss: 0.9435384829122059
Validation loss: 2.5679676261371363

Epoch: 5| Step: 4
Training loss: 0.8174609439747955
Validation loss: 2.5412915472602355

Epoch: 5| Step: 5
Training loss: 0.7647197198101312
Validation loss: 2.5685783745466333

Epoch: 5| Step: 6
Training loss: 0.8317428948844501
Validation loss: 2.563197907521877

Epoch: 5| Step: 7
Training loss: 1.2781924540061051
Validation loss: 2.5582883621118673

Epoch: 5| Step: 8
Training loss: 0.6902791767012375
Validation loss: 2.5566392021144217

Epoch: 5| Step: 9
Training loss: 0.506548702751022
Validation loss: 2.525439138369767

Epoch: 5| Step: 10
Training loss: 0.6161813139407134
Validation loss: 2.5416840630522155

Epoch: 301| Step: 0
Training loss: 0.7414580525026775
Validation loss: 2.543728991474112

Epoch: 5| Step: 1
Training loss: 0.7217531076542091
Validation loss: 2.50148858185874

Epoch: 5| Step: 2
Training loss: 0.5820058010605299
Validation loss: 2.504496198273637

Epoch: 5| Step: 3
Training loss: 0.7851123323066944
Validation loss: 2.5216340544448674

Epoch: 5| Step: 4
Training loss: 0.8261689891719693
Validation loss: 2.5562449701346317

Epoch: 5| Step: 5
Training loss: 0.8972576189161416
Validation loss: 2.533254210011511

Epoch: 5| Step: 6
Training loss: 0.9660005006018817
Validation loss: 2.5564944366652353

Epoch: 5| Step: 7
Training loss: 0.9795416594131869
Validation loss: 2.5367768561793094

Epoch: 5| Step: 8
Training loss: 1.072946134489742
Validation loss: 2.5352227975401345

Epoch: 5| Step: 9
Training loss: 0.5295881195012153
Validation loss: 2.517738933298279

Epoch: 5| Step: 10
Training loss: 0.8285359496591711
Validation loss: 2.530937168910022

Epoch: 302| Step: 0
Training loss: 0.9847218644112058
Validation loss: 2.5451821985696954

Epoch: 5| Step: 1
Training loss: 0.574775322265455
Validation loss: 2.529575913953794

Epoch: 5| Step: 2
Training loss: 1.0723520046107073
Validation loss: 2.535251001019259

Epoch: 5| Step: 3
Training loss: 0.7890375341110545
Validation loss: 2.561249678798054

Epoch: 5| Step: 4
Training loss: 0.9297425710571579
Validation loss: 2.527895076583946

Epoch: 5| Step: 5
Training loss: 0.34875496826598096
Validation loss: 2.538203159301958

Epoch: 5| Step: 6
Training loss: 0.8016329074447605
Validation loss: 2.556923646165655

Epoch: 5| Step: 7
Training loss: 0.7363150921788837
Validation loss: 2.546041547930493

Epoch: 5| Step: 8
Training loss: 0.9874655029452097
Validation loss: 2.5359764893894683

Epoch: 5| Step: 9
Training loss: 0.9516082326738965
Validation loss: 2.5509534811369683

Epoch: 5| Step: 10
Training loss: 0.5511705091690671
Validation loss: 2.563724896365607

Epoch: 303| Step: 0
Training loss: 1.0017128818109806
Validation loss: 2.5426841422708413

Epoch: 5| Step: 1
Training loss: 0.6110864228502086
Validation loss: 2.5263318119210454

Epoch: 5| Step: 2
Training loss: 0.7602464973220996
Validation loss: 2.529505728392919

Epoch: 5| Step: 3
Training loss: 1.3388238255708396
Validation loss: 2.5393324983099133

Epoch: 5| Step: 4
Training loss: 0.8602112602639256
Validation loss: 2.522485300730216

Epoch: 5| Step: 5
Training loss: 0.7760109906032767
Validation loss: 2.5256378781410365

Epoch: 5| Step: 6
Training loss: 0.6014632601437638
Validation loss: 2.5342180687842673

Epoch: 5| Step: 7
Training loss: 0.9187970584054208
Validation loss: 2.559544142816509

Epoch: 5| Step: 8
Training loss: 0.28193681356337613
Validation loss: 2.528695076382626

Epoch: 5| Step: 9
Training loss: 0.48103683506700834
Validation loss: 2.5656658428206125

Epoch: 5| Step: 10
Training loss: 0.8011416112874253
Validation loss: 2.580493219899197

Epoch: 304| Step: 0
Training loss: 0.8498547079225334
Validation loss: 2.5873952182841595

Epoch: 5| Step: 1
Training loss: 0.981835313428381
Validation loss: 2.5593910766595065

Epoch: 5| Step: 2
Training loss: 0.7930123453417998
Validation loss: 2.5506376918838356

Epoch: 5| Step: 3
Training loss: 0.4901306072917404
Validation loss: 2.526105630308161

Epoch: 5| Step: 4
Training loss: 0.7893060365032099
Validation loss: 2.519830478999292

Epoch: 5| Step: 5
Training loss: 0.8615407529901329
Validation loss: 2.515541809536778

Epoch: 5| Step: 6
Training loss: 0.9548135402659044
Validation loss: 2.5152603901214468

Epoch: 5| Step: 7
Training loss: 0.9057390153615218
Validation loss: 2.519104078602338

Epoch: 5| Step: 8
Training loss: 0.7121692927310853
Validation loss: 2.531125780524144

Epoch: 5| Step: 9
Training loss: 0.7519546310607889
Validation loss: 2.550557833593851

Epoch: 5| Step: 10
Training loss: 0.6521296806642753
Validation loss: 2.585396067847373

Epoch: 305| Step: 0
Training loss: 0.82948001630785
Validation loss: 2.586743329772927

Epoch: 5| Step: 1
Training loss: 0.6102163912821853
Validation loss: 2.6078773381256637

Epoch: 5| Step: 2
Training loss: 0.9411862064745071
Validation loss: 2.589975473265073

Epoch: 5| Step: 3
Training loss: 0.8257902449855086
Validation loss: 2.5773182958903713

Epoch: 5| Step: 4
Training loss: 0.6351640126034331
Validation loss: 2.563166999997989

Epoch: 5| Step: 5
Training loss: 0.9341062471847142
Validation loss: 2.5597916343418685

Epoch: 5| Step: 6
Training loss: 0.6128908846619386
Validation loss: 2.532093314253629

Epoch: 5| Step: 7
Training loss: 0.8227941486240524
Validation loss: 2.5315540778760273

Epoch: 5| Step: 8
Training loss: 0.7914728797512356
Validation loss: 2.5448400603137733

Epoch: 5| Step: 9
Training loss: 0.8357940622069043
Validation loss: 2.552396597270984

Epoch: 5| Step: 10
Training loss: 0.9362373750494984
Validation loss: 2.548204884207239

Epoch: 306| Step: 0
Training loss: 0.9167590997794082
Validation loss: 2.551243470860528

Epoch: 5| Step: 1
Training loss: 0.8322396532276688
Validation loss: 2.534112681603289

Epoch: 5| Step: 2
Training loss: 0.9111119765733728
Validation loss: 2.5454312113901763

Epoch: 5| Step: 3
Training loss: 0.6893842624930877
Validation loss: 2.532556113536646

Epoch: 5| Step: 4
Training loss: 0.6805508052785569
Validation loss: 2.5417312225207302

Epoch: 5| Step: 5
Training loss: 0.8029821157447229
Validation loss: 2.539064447671981

Epoch: 5| Step: 6
Training loss: 0.5788823656928629
Validation loss: 2.550881333069489

Epoch: 5| Step: 7
Training loss: 1.034319499851979
Validation loss: 2.5380130110222856

Epoch: 5| Step: 8
Training loss: 0.7837296235935591
Validation loss: 2.517280687502688

Epoch: 5| Step: 9
Training loss: 0.6954705133803567
Validation loss: 2.5304083894217713

Epoch: 5| Step: 10
Training loss: 0.6978640726304313
Validation loss: 2.4820019685446355

Epoch: 307| Step: 0
Training loss: 0.8346575269384041
Validation loss: 2.5306656746772203

Epoch: 5| Step: 1
Training loss: 0.6312365039478028
Validation loss: 2.5407773934555924

Epoch: 5| Step: 2
Training loss: 0.8201610970422036
Validation loss: 2.570300583983691

Epoch: 5| Step: 3
Training loss: 0.9208436142590618
Validation loss: 2.5690521622202116

Epoch: 5| Step: 4
Training loss: 0.5394947696110529
Validation loss: 2.5729777442750716

Epoch: 5| Step: 5
Training loss: 0.8446062123556383
Validation loss: 2.532189979967759

Epoch: 5| Step: 6
Training loss: 0.9182175968600311
Validation loss: 2.585785951589304

Epoch: 5| Step: 7
Training loss: 0.9570235894344233
Validation loss: 2.5749373900171886

Epoch: 5| Step: 8
Training loss: 0.27280576481321445
Validation loss: 2.5791861668678755

Epoch: 5| Step: 9
Training loss: 0.8094823257986147
Validation loss: 2.589276419937666

Epoch: 5| Step: 10
Training loss: 0.7914985218841574
Validation loss: 2.5941784140795474

Epoch: 308| Step: 0
Training loss: 0.6034010991437673
Validation loss: 2.566926080512033

Epoch: 5| Step: 1
Training loss: 0.5216453960863814
Validation loss: 2.5199643548128163

Epoch: 5| Step: 2
Training loss: 0.7090187169524668
Validation loss: 2.5385298096480806

Epoch: 5| Step: 3
Training loss: 0.9622222561581728
Validation loss: 2.516959447182461

Epoch: 5| Step: 4
Training loss: 0.7769678251583713
Validation loss: 2.5168896941036247

Epoch: 5| Step: 5
Training loss: 1.0959187395781427
Validation loss: 2.5425536683912906

Epoch: 5| Step: 6
Training loss: 0.7617355344830455
Validation loss: 2.55750422459721

Epoch: 5| Step: 7
Training loss: 0.579906605238512
Validation loss: 2.574679542263561

Epoch: 5| Step: 8
Training loss: 0.9145501946866446
Validation loss: 2.5728102289145918

Epoch: 5| Step: 9
Training loss: 0.5837358181801138
Validation loss: 2.5754094762891695

Epoch: 5| Step: 10
Training loss: 0.774490564327008
Validation loss: 2.5804412768307197

Epoch: 309| Step: 0
Training loss: 0.881750937047925
Validation loss: 2.561409456834567

Epoch: 5| Step: 1
Training loss: 0.6410246277153124
Validation loss: 2.586699215932938

Epoch: 5| Step: 2
Training loss: 0.721576110262113
Validation loss: 2.552305916444271

Epoch: 5| Step: 3
Training loss: 0.9904311547017425
Validation loss: 2.5405568652401103

Epoch: 5| Step: 4
Training loss: 0.4870248269963108
Validation loss: 2.5378771113894407

Epoch: 5| Step: 5
Training loss: 0.791970926509766
Validation loss: 2.5531498438249365

Epoch: 5| Step: 6
Training loss: 0.9020197563291535
Validation loss: 2.577517446636319

Epoch: 5| Step: 7
Training loss: 0.9109136679723331
Validation loss: 2.560481824673006

Epoch: 5| Step: 8
Training loss: 0.44654111192977336
Validation loss: 2.5484561910150254

Epoch: 5| Step: 9
Training loss: 0.82188667753213
Validation loss: 2.541000386469436

Epoch: 5| Step: 10
Training loss: 0.5185736816146004
Validation loss: 2.5551129655700886

Epoch: 310| Step: 0
Training loss: 0.9235965365898781
Validation loss: 2.5809110402289326

Epoch: 5| Step: 1
Training loss: 0.5406736539435453
Validation loss: 2.5425881780144404

Epoch: 5| Step: 2
Training loss: 0.847381863813995
Validation loss: 2.5378354685580575

Epoch: 5| Step: 3
Training loss: 0.6633081751953541
Validation loss: 2.5176664158558415

Epoch: 5| Step: 4
Training loss: 0.8301780012294235
Validation loss: 2.5303688809728193

Epoch: 5| Step: 5
Training loss: 0.7897902805480895
Validation loss: 2.5198636821950036

Epoch: 5| Step: 6
Training loss: 0.6135014424202152
Validation loss: 2.540347981883436

Epoch: 5| Step: 7
Training loss: 0.48389340116042057
Validation loss: 2.5514201250322537

Epoch: 5| Step: 8
Training loss: 0.653301997134725
Validation loss: 2.5557388852132936

Epoch: 5| Step: 9
Training loss: 0.8846896646325604
Validation loss: 2.5307383332218825

Epoch: 5| Step: 10
Training loss: 0.9378079226571846
Validation loss: 2.5394272610879502

Epoch: 311| Step: 0
Training loss: 0.5301669243891183
Validation loss: 2.564728267035013

Epoch: 5| Step: 1
Training loss: 0.8025297474918194
Validation loss: 2.550293407534506

Epoch: 5| Step: 2
Training loss: 0.9188419815003385
Validation loss: 2.567744122630403

Epoch: 5| Step: 3
Training loss: 0.7820981571565512
Validation loss: 2.5750999883666092

Epoch: 5| Step: 4
Training loss: 0.7371665572570931
Validation loss: 2.572744541024547

Epoch: 5| Step: 5
Training loss: 0.7922654815153085
Validation loss: 2.58843191369793

Epoch: 5| Step: 6
Training loss: 0.3784265529520312
Validation loss: 2.5619559201888027

Epoch: 5| Step: 7
Training loss: 0.795844477597112
Validation loss: 2.573725532672386

Epoch: 5| Step: 8
Training loss: 0.8963558129770757
Validation loss: 2.573526074545284

Epoch: 5| Step: 9
Training loss: 0.7625667058189184
Validation loss: 2.5854012330098395

Epoch: 5| Step: 10
Training loss: 0.5811840266041782
Validation loss: 2.590348870373822

Epoch: 312| Step: 0
Training loss: 0.7639580700113345
Validation loss: 2.554052481644788

Epoch: 5| Step: 1
Training loss: 0.6022187406298318
Validation loss: 2.569571638538941

Epoch: 5| Step: 2
Training loss: 0.7409726690974066
Validation loss: 2.5443998482030237

Epoch: 5| Step: 3
Training loss: 0.9789376329169712
Validation loss: 2.565272390445063

Epoch: 5| Step: 4
Training loss: 0.40090245353131587
Validation loss: 2.5544197363917247

Epoch: 5| Step: 5
Training loss: 0.5983013087745925
Validation loss: 2.56434597671914

Epoch: 5| Step: 6
Training loss: 0.7290643256892609
Validation loss: 2.5657493919576013

Epoch: 5| Step: 7
Training loss: 0.9627926604478123
Validation loss: 2.53571490428923

Epoch: 5| Step: 8
Training loss: 0.6464379054767805
Validation loss: 2.5554955065096796

Epoch: 5| Step: 9
Training loss: 0.8688200970369642
Validation loss: 2.5675330947264112

Epoch: 5| Step: 10
Training loss: 0.5536049770042611
Validation loss: 2.579388623208852

Epoch: 313| Step: 0
Training loss: 0.33024437233362613
Validation loss: 2.598653770352061

Epoch: 5| Step: 1
Training loss: 0.8187169861871528
Validation loss: 2.5889643366987145

Epoch: 5| Step: 2
Training loss: 0.9232842616756614
Validation loss: 2.6110566219790434

Epoch: 5| Step: 3
Training loss: 0.6934024851117137
Validation loss: 2.6055638269702355

Epoch: 5| Step: 4
Training loss: 0.6087771686546188
Validation loss: 2.574272247699174

Epoch: 5| Step: 5
Training loss: 0.9253262717662815
Validation loss: 2.5354371638179867

Epoch: 5| Step: 6
Training loss: 0.883117926772423
Validation loss: 2.52662808143054

Epoch: 5| Step: 7
Training loss: 0.7335945202515675
Validation loss: 2.5035720859968427

Epoch: 5| Step: 8
Training loss: 0.9083525832058372
Validation loss: 2.521128077824188

Epoch: 5| Step: 9
Training loss: 0.6310903403937841
Validation loss: 2.536743310442046

Epoch: 5| Step: 10
Training loss: 0.3925248864357098
Validation loss: 2.5505309603129493

Epoch: 314| Step: 0
Training loss: 0.9583370720057883
Validation loss: 2.5597669521657025

Epoch: 5| Step: 1
Training loss: 0.8260381423535074
Validation loss: 2.5689950980405047

Epoch: 5| Step: 2
Training loss: 0.752049665322669
Validation loss: 2.590669213991173

Epoch: 5| Step: 3
Training loss: 0.7914537511580623
Validation loss: 2.5893399100160988

Epoch: 5| Step: 4
Training loss: 0.7361934953648346
Validation loss: 2.548025495325509

Epoch: 5| Step: 5
Training loss: 0.7663940148733094
Validation loss: 2.507424545194007

Epoch: 5| Step: 6
Training loss: 0.582568439179574
Validation loss: 2.5042270262121713

Epoch: 5| Step: 7
Training loss: 0.5636126851326789
Validation loss: 2.5381574725727143

Epoch: 5| Step: 8
Training loss: 0.7960663226403403
Validation loss: 2.567361944875792

Epoch: 5| Step: 9
Training loss: 0.4394023781192046
Validation loss: 2.599485072985542

Epoch: 5| Step: 10
Training loss: 0.9602667786041809
Validation loss: 2.621766049118025

Epoch: 315| Step: 0
Training loss: 0.7317733945609417
Validation loss: 2.6364064001906296

Epoch: 5| Step: 1
Training loss: 1.0858298049326844
Validation loss: 2.5934071033102013

Epoch: 5| Step: 2
Training loss: 0.5488831027585479
Validation loss: 2.5632112757956564

Epoch: 5| Step: 3
Training loss: 0.37896336783695944
Validation loss: 2.531042885823979

Epoch: 5| Step: 4
Training loss: 1.0274220135833505
Validation loss: 2.5151778623542036

Epoch: 5| Step: 5
Training loss: 0.8375558606776948
Validation loss: 2.5095306093647767

Epoch: 5| Step: 6
Training loss: 0.8599807684988108
Validation loss: 2.5158707066818

Epoch: 5| Step: 7
Training loss: 0.684230486099911
Validation loss: 2.508599326902031

Epoch: 5| Step: 8
Training loss: 0.7758529399466294
Validation loss: 2.5488696143866294

Epoch: 5| Step: 9
Training loss: 0.6151495254377723
Validation loss: 2.5824707802931948

Epoch: 5| Step: 10
Training loss: 0.4825215719272902
Validation loss: 2.5735050116775104

Epoch: 316| Step: 0
Training loss: 0.6595177129907509
Validation loss: 2.609174862562894

Epoch: 5| Step: 1
Training loss: 0.8152315001718073
Validation loss: 2.60641898790223

Epoch: 5| Step: 2
Training loss: 0.5668254222029918
Validation loss: 2.611149144061133

Epoch: 5| Step: 3
Training loss: 0.3696901983644708
Validation loss: 2.601125657637304

Epoch: 5| Step: 4
Training loss: 0.8097182484967842
Validation loss: 2.534643251795248

Epoch: 5| Step: 5
Training loss: 0.6025876809263471
Validation loss: 2.5242293434366254

Epoch: 5| Step: 6
Training loss: 0.8090147682275436
Validation loss: 2.482436816312541

Epoch: 5| Step: 7
Training loss: 0.8152116129850075
Validation loss: 2.465902632236041

Epoch: 5| Step: 8
Training loss: 0.9251938255963287
Validation loss: 2.4538007996308275

Epoch: 5| Step: 9
Training loss: 0.7761373695571131
Validation loss: 2.448868639771775

Epoch: 5| Step: 10
Training loss: 0.8167032313108599
Validation loss: 2.5262157299446306

Epoch: 317| Step: 0
Training loss: 0.4085443886285755
Validation loss: 2.5208124580085065

Epoch: 5| Step: 1
Training loss: 0.96301110927912
Validation loss: 2.542938558372392

Epoch: 5| Step: 2
Training loss: 0.5121459633612733
Validation loss: 2.578377075401225

Epoch: 5| Step: 3
Training loss: 0.7432212456697895
Validation loss: 2.5940571818171776

Epoch: 5| Step: 4
Training loss: 0.6013663826838253
Validation loss: 2.598101185767977

Epoch: 5| Step: 5
Training loss: 0.6695510015612217
Validation loss: 2.5972814456853532

Epoch: 5| Step: 6
Training loss: 0.8987156313079997
Validation loss: 2.582606711265659

Epoch: 5| Step: 7
Training loss: 0.4767020912222969
Validation loss: 2.552579366876993

Epoch: 5| Step: 8
Training loss: 0.8271366915718916
Validation loss: 2.511760712531442

Epoch: 5| Step: 9
Training loss: 0.8678276517298781
Validation loss: 2.5005410065348865

Epoch: 5| Step: 10
Training loss: 0.6948317891269445
Validation loss: 2.5048728419590023

Epoch: 318| Step: 0
Training loss: 0.9495241906056038
Validation loss: 2.502363631429738

Epoch: 5| Step: 1
Training loss: 0.6971900535683779
Validation loss: 2.484111628751627

Epoch: 5| Step: 2
Training loss: 0.788099135202089
Validation loss: 2.5202457845326194

Epoch: 5| Step: 3
Training loss: 0.6716740773536019
Validation loss: 2.538223919206043

Epoch: 5| Step: 4
Training loss: 0.7880849542812562
Validation loss: 2.5743562878010144

Epoch: 5| Step: 5
Training loss: 0.8351414535539191
Validation loss: 2.580718773258563

Epoch: 5| Step: 6
Training loss: 0.6283675072008696
Validation loss: 2.617703450403981

Epoch: 5| Step: 7
Training loss: 0.6322210397087276
Validation loss: 2.607236877665199

Epoch: 5| Step: 8
Training loss: 0.7836689313000996
Validation loss: 2.627975792889135

Epoch: 5| Step: 9
Training loss: 0.4058411264585164
Validation loss: 2.595719091266193

Epoch: 5| Step: 10
Training loss: 0.5536508678974138
Validation loss: 2.544573948962616

Epoch: 319| Step: 0
Training loss: 0.8871626226115736
Validation loss: 2.524024392497873

Epoch: 5| Step: 1
Training loss: 0.8114184370177964
Validation loss: 2.505704952866995

Epoch: 5| Step: 2
Training loss: 0.7241297777289261
Validation loss: 2.506688461511143

Epoch: 5| Step: 3
Training loss: 0.647883534785378
Validation loss: 2.4918571986471143

Epoch: 5| Step: 4
Training loss: 0.713421516790822
Validation loss: 2.4716064280464005

Epoch: 5| Step: 5
Training loss: 0.2903132443166991
Validation loss: 2.483688019075971

Epoch: 5| Step: 6
Training loss: 0.8328325236992612
Validation loss: 2.529008915179544

Epoch: 5| Step: 7
Training loss: 0.5467824040086939
Validation loss: 2.5338376621843293

Epoch: 5| Step: 8
Training loss: 0.7674301820243463
Validation loss: 2.577722738187534

Epoch: 5| Step: 9
Training loss: 0.807175207454286
Validation loss: 2.5907497565620132

Epoch: 5| Step: 10
Training loss: 0.5276406476688061
Validation loss: 2.6019466281247308

Epoch: 320| Step: 0
Training loss: 0.699179770805703
Validation loss: 2.59065307608307

Epoch: 5| Step: 1
Training loss: 0.6911420586796023
Validation loss: 2.5749246949270272

Epoch: 5| Step: 2
Training loss: 0.6781982681140931
Validation loss: 2.5814281077704098

Epoch: 5| Step: 3
Training loss: 0.8429267894069788
Validation loss: 2.521493192986966

Epoch: 5| Step: 4
Training loss: 0.6301919341252452
Validation loss: 2.4973135850408923

Epoch: 5| Step: 5
Training loss: 0.8998004692149333
Validation loss: 2.523074641963365

Epoch: 5| Step: 6
Training loss: 0.6284773886686613
Validation loss: 2.4964699649178774

Epoch: 5| Step: 7
Training loss: 0.5475451314518638
Validation loss: 2.494152159677876

Epoch: 5| Step: 8
Training loss: 0.7608793279513144
Validation loss: 2.4876614497662994

Epoch: 5| Step: 9
Training loss: 0.7172455176196441
Validation loss: 2.5083484717746827

Epoch: 5| Step: 10
Training loss: 0.3511239495422957
Validation loss: 2.5490784622057463

Epoch: 321| Step: 0
Training loss: 0.7043004700732393
Validation loss: 2.57468422808238

Epoch: 5| Step: 1
Training loss: 0.6994119941874721
Validation loss: 2.5711073900687818

Epoch: 5| Step: 2
Training loss: 0.45831955180978395
Validation loss: 2.574730652675231

Epoch: 5| Step: 3
Training loss: 0.7048541741011526
Validation loss: 2.5716893370627867

Epoch: 5| Step: 4
Training loss: 0.42563931260432275
Validation loss: 2.5585887531581477

Epoch: 5| Step: 5
Training loss: 0.600684106758654
Validation loss: 2.5447237164608625

Epoch: 5| Step: 6
Training loss: 0.8013092161366735
Validation loss: 2.5500108096532825

Epoch: 5| Step: 7
Training loss: 0.7185452210989223
Validation loss: 2.538643189696965

Epoch: 5| Step: 8
Training loss: 1.009470263730447
Validation loss: 2.5507401756393335

Epoch: 5| Step: 9
Training loss: 0.6052805454246701
Validation loss: 2.527947585188372

Epoch: 5| Step: 10
Training loss: 0.7429786882026644
Validation loss: 2.5163379602299067

Epoch: 322| Step: 0
Training loss: 0.6836762296781844
Validation loss: 2.5188914514434777

Epoch: 5| Step: 1
Training loss: 0.7230753739983468
Validation loss: 2.5099571957084406

Epoch: 5| Step: 2
Training loss: 0.8294592850610786
Validation loss: 2.5541820730481994

Epoch: 5| Step: 3
Training loss: 0.5135730604850328
Validation loss: 2.5901360784278635

Epoch: 5| Step: 4
Training loss: 0.6073509003120421
Validation loss: 2.6001684322812357

Epoch: 5| Step: 5
Training loss: 0.3465353006915148
Validation loss: 2.620160385491893

Epoch: 5| Step: 6
Training loss: 0.662995254990124
Validation loss: 2.5831382815438584

Epoch: 5| Step: 7
Training loss: 0.7977151368884583
Validation loss: 2.548755393732853

Epoch: 5| Step: 8
Training loss: 0.9714553343969091
Validation loss: 2.560237589102101

Epoch: 5| Step: 9
Training loss: 0.7322862423243245
Validation loss: 2.521907482625981

Epoch: 5| Step: 10
Training loss: 0.5000005066392239
Validation loss: 2.5394557252718006

Epoch: 323| Step: 0
Training loss: 0.4485435387052151
Validation loss: 2.4970137778351122

Epoch: 5| Step: 1
Training loss: 0.574304924551594
Validation loss: 2.488876916691898

Epoch: 5| Step: 2
Training loss: 0.32139727037020804
Validation loss: 2.5017276680361227

Epoch: 5| Step: 3
Training loss: 0.7974884813248178
Validation loss: 2.5106013495657047

Epoch: 5| Step: 4
Training loss: 0.811590786375951
Validation loss: 2.5336941821777286

Epoch: 5| Step: 5
Training loss: 0.6443370873428543
Validation loss: 2.5552180359219676

Epoch: 5| Step: 6
Training loss: 0.357151450326264
Validation loss: 2.5648643416936365

Epoch: 5| Step: 7
Training loss: 0.9218863793656792
Validation loss: 2.585983273483627

Epoch: 5| Step: 8
Training loss: 0.897826310292883
Validation loss: 2.593735004079745

Epoch: 5| Step: 9
Training loss: 0.5296636345362234
Validation loss: 2.5960658562945347

Epoch: 5| Step: 10
Training loss: 0.856851201022568
Validation loss: 2.559598395934586

Epoch: 324| Step: 0
Training loss: 0.762215359512176
Validation loss: 2.5270527808487215

Epoch: 5| Step: 1
Training loss: 0.5979099607811568
Validation loss: 2.512692447565691

Epoch: 5| Step: 2
Training loss: 0.522682499475859
Validation loss: 2.5285355083085257

Epoch: 5| Step: 3
Training loss: 0.6934948426201327
Validation loss: 2.514496876631078

Epoch: 5| Step: 4
Training loss: 0.6812743812537788
Validation loss: 2.5273757468220817

Epoch: 5| Step: 5
Training loss: 0.6439069556584387
Validation loss: 2.541152356052316

Epoch: 5| Step: 6
Training loss: 0.7818633914027802
Validation loss: 2.557941331606395

Epoch: 5| Step: 7
Training loss: 0.47915087203931983
Validation loss: 2.551961479936125

Epoch: 5| Step: 8
Training loss: 0.8769086388941865
Validation loss: 2.5593925711363554

Epoch: 5| Step: 9
Training loss: 0.5035890867447602
Validation loss: 2.5740780666287533

Epoch: 5| Step: 10
Training loss: 0.7191454172881258
Validation loss: 2.555494266068283

Epoch: 325| Step: 0
Training loss: 0.38336511545837343
Validation loss: 2.5708969852509824

Epoch: 5| Step: 1
Training loss: 0.732341222772944
Validation loss: 2.582728439815392

Epoch: 5| Step: 2
Training loss: 0.5813750081329903
Validation loss: 2.5591907016819326

Epoch: 5| Step: 3
Training loss: 0.9340235147926459
Validation loss: 2.5466475947346208

Epoch: 5| Step: 4
Training loss: 0.6535677590926028
Validation loss: 2.5688408086490444

Epoch: 5| Step: 5
Training loss: 0.7165002442976435
Validation loss: 2.557726967084121

Epoch: 5| Step: 6
Training loss: 0.7761407485963966
Validation loss: 2.528880486038458

Epoch: 5| Step: 7
Training loss: 0.32647539053862246
Validation loss: 2.5150507696579054

Epoch: 5| Step: 8
Training loss: 0.7154614224113858
Validation loss: 2.537505000826979

Epoch: 5| Step: 9
Training loss: 0.5908910787778214
Validation loss: 2.525390290509313

Epoch: 5| Step: 10
Training loss: 0.6697463536891236
Validation loss: 2.5373657908384906

Epoch: 326| Step: 0
Training loss: 0.6231362449144074
Validation loss: 2.5391286402465845

Epoch: 5| Step: 1
Training loss: 1.1115504680987243
Validation loss: 2.533627640526406

Epoch: 5| Step: 2
Training loss: 0.6116218470654515
Validation loss: 2.536299890803082

Epoch: 5| Step: 3
Training loss: 0.37561753210048254
Validation loss: 2.543056711769634

Epoch: 5| Step: 4
Training loss: 0.6288744521543376
Validation loss: 2.553084415246719

Epoch: 5| Step: 5
Training loss: 0.4804248324535916
Validation loss: 2.5847677379479514

Epoch: 5| Step: 6
Training loss: 0.5813519655026618
Validation loss: 2.5641201369075457

Epoch: 5| Step: 7
Training loss: 0.6876795707619243
Validation loss: 2.545130104458248

Epoch: 5| Step: 8
Training loss: 0.6468405995459252
Validation loss: 2.54398380392371

Epoch: 5| Step: 9
Training loss: 0.6422158469373553
Validation loss: 2.5167876124954645

Epoch: 5| Step: 10
Training loss: 0.597926608500307
Validation loss: 2.5462640920098027

Epoch: 327| Step: 0
Training loss: 0.602698059372462
Validation loss: 2.541799596951217

Epoch: 5| Step: 1
Training loss: 0.6453074549738711
Validation loss: 2.5248588263034843

Epoch: 5| Step: 2
Training loss: 0.5708432014568364
Validation loss: 2.521794589366454

Epoch: 5| Step: 3
Training loss: 0.8422090446250118
Validation loss: 2.5198782000622764

Epoch: 5| Step: 4
Training loss: 0.6863253485374329
Validation loss: 2.552532255172555

Epoch: 5| Step: 5
Training loss: 0.6423142653787421
Validation loss: 2.5712616521302194

Epoch: 5| Step: 6
Training loss: 0.539167283419925
Validation loss: 2.545850768151357

Epoch: 5| Step: 7
Training loss: 0.8047107211716047
Validation loss: 2.5412415428483537

Epoch: 5| Step: 8
Training loss: 0.4946552506837457
Validation loss: 2.5627699749039756

Epoch: 5| Step: 9
Training loss: 0.5511639395074286
Validation loss: 2.562700162243719

Epoch: 5| Step: 10
Training loss: 0.7145405110539611
Validation loss: 2.541450841997363

Epoch: 328| Step: 0
Training loss: 0.5824090640260071
Validation loss: 2.5438920678921835

Epoch: 5| Step: 1
Training loss: 0.6484408780664903
Validation loss: 2.5247336059581467

Epoch: 5| Step: 2
Training loss: 0.6328359999826123
Validation loss: 2.5306532903532974

Epoch: 5| Step: 3
Training loss: 0.6929451793287452
Validation loss: 2.538433203572649

Epoch: 5| Step: 4
Training loss: 0.5163179423072284
Validation loss: 2.550697287463603

Epoch: 5| Step: 5
Training loss: 0.7024391432022601
Validation loss: 2.5703810746176834

Epoch: 5| Step: 6
Training loss: 0.4723102469618324
Validation loss: 2.5676519485117213

Epoch: 5| Step: 7
Training loss: 0.8709563074178863
Validation loss: 2.5636448537468657

Epoch: 5| Step: 8
Training loss: 0.6906259735238649
Validation loss: 2.5896079849269533

Epoch: 5| Step: 9
Training loss: 0.6981659320726656
Validation loss: 2.597729288845096

Epoch: 5| Step: 10
Training loss: 0.5462887755452215
Validation loss: 2.5975819556959627

Epoch: 329| Step: 0
Training loss: 0.7765671574474032
Validation loss: 2.558736176430023

Epoch: 5| Step: 1
Training loss: 0.7290414339333963
Validation loss: 2.527415421750866

Epoch: 5| Step: 2
Training loss: 0.627454301872283
Validation loss: 2.5226495624386356

Epoch: 5| Step: 3
Training loss: 0.7549448320936122
Validation loss: 2.495338441851049

Epoch: 5| Step: 4
Training loss: 0.672791454802847
Validation loss: 2.515110453172402

Epoch: 5| Step: 5
Training loss: 0.45650575863568416
Validation loss: 2.5120795060763563

Epoch: 5| Step: 6
Training loss: 0.2679102291566778
Validation loss: 2.5231664124593443

Epoch: 5| Step: 7
Training loss: 0.8069741434755314
Validation loss: 2.545931250378226

Epoch: 5| Step: 8
Training loss: 0.7430555387201833
Validation loss: 2.5355675630675583

Epoch: 5| Step: 9
Training loss: 0.4934056360781039
Validation loss: 2.6105142186562977

Epoch: 5| Step: 10
Training loss: 0.6437523267759476
Validation loss: 2.602850117947646

Epoch: 330| Step: 0
Training loss: 0.5110253739691869
Validation loss: 2.6067396038748663

Epoch: 5| Step: 1
Training loss: 0.6331417028063462
Validation loss: 2.597956680145094

Epoch: 5| Step: 2
Training loss: 0.5816611835235873
Validation loss: 2.540103700762549

Epoch: 5| Step: 3
Training loss: 0.8714156304521964
Validation loss: 2.520106608923532

Epoch: 5| Step: 4
Training loss: 0.457469290109114
Validation loss: 2.4992382139981353

Epoch: 5| Step: 5
Training loss: 0.9022846615423313
Validation loss: 2.500262827029642

Epoch: 5| Step: 6
Training loss: 0.617682946205047
Validation loss: 2.4945629599144397

Epoch: 5| Step: 7
Training loss: 0.6598803829761931
Validation loss: 2.5016751030308995

Epoch: 5| Step: 8
Training loss: 0.7448697260429703
Validation loss: 2.511545362487418

Epoch: 5| Step: 9
Training loss: 0.42919052167289556
Validation loss: 2.519235539012881

Epoch: 5| Step: 10
Training loss: 0.48746594835835105
Validation loss: 2.544141228147696

Epoch: 331| Step: 0
Training loss: 0.48879582565873464
Validation loss: 2.562209326192319

Epoch: 5| Step: 1
Training loss: 0.48329580739564953
Validation loss: 2.580123397324257

Epoch: 5| Step: 2
Training loss: 0.5494926203908183
Validation loss: 2.5607865550379447

Epoch: 5| Step: 3
Training loss: 0.5301779139348136
Validation loss: 2.54171796720373

Epoch: 5| Step: 4
Training loss: 0.4587745024350732
Validation loss: 2.5518642456226384

Epoch: 5| Step: 5
Training loss: 0.7993665526825837
Validation loss: 2.5363379716452634

Epoch: 5| Step: 6
Training loss: 0.7812387847095381
Validation loss: 2.537389238042499

Epoch: 5| Step: 7
Training loss: 0.965553732899432
Validation loss: 2.531225159023248

Epoch: 5| Step: 8
Training loss: 0.6737401490207908
Validation loss: 2.508780343943213

Epoch: 5| Step: 9
Training loss: 0.6773058281197027
Validation loss: 2.5021282386860526

Epoch: 5| Step: 10
Training loss: 0.40572548898475513
Validation loss: 2.5089969827229073

Epoch: 332| Step: 0
Training loss: 0.8216887781625499
Validation loss: 2.530666302249322

Epoch: 5| Step: 1
Training loss: 0.6872526937787885
Validation loss: 2.555354842235941

Epoch: 5| Step: 2
Training loss: 0.4094124907878432
Validation loss: 2.555460964531143

Epoch: 5| Step: 3
Training loss: 0.7096042917874418
Validation loss: 2.5597454906473285

Epoch: 5| Step: 4
Training loss: 0.676256883413429
Validation loss: 2.5760767880277893

Epoch: 5| Step: 5
Training loss: 0.5554327458169283
Validation loss: 2.5773355945394134

Epoch: 5| Step: 6
Training loss: 0.569090801878018
Validation loss: 2.566730480721907

Epoch: 5| Step: 7
Training loss: 0.6425776148275187
Validation loss: 2.560313573840242

Epoch: 5| Step: 8
Training loss: 0.6706104132282654
Validation loss: 2.5391792122873196

Epoch: 5| Step: 9
Training loss: 0.46480455954620703
Validation loss: 2.5491589833229655

Epoch: 5| Step: 10
Training loss: 0.5923930020435445
Validation loss: 2.539475667071479

Epoch: 333| Step: 0
Training loss: 0.6505398736574465
Validation loss: 2.516574862453992

Epoch: 5| Step: 1
Training loss: 0.502012256746249
Validation loss: 2.5213504848265282

Epoch: 5| Step: 2
Training loss: 0.7963040120057402
Validation loss: 2.5408947312203085

Epoch: 5| Step: 3
Training loss: 0.6889710294255229
Validation loss: 2.5545494019936243

Epoch: 5| Step: 4
Training loss: 0.4815681873309978
Validation loss: 2.557222092753068

Epoch: 5| Step: 5
Training loss: 0.6333980912011464
Validation loss: 2.561799422568536

Epoch: 5| Step: 6
Training loss: 0.3975373740590027
Validation loss: 2.5820924422986598

Epoch: 5| Step: 7
Training loss: 0.599596253291888
Validation loss: 2.550372772508394

Epoch: 5| Step: 8
Training loss: 0.7595423980943188
Validation loss: 2.55525691134876

Epoch: 5| Step: 9
Training loss: 0.8030634667242803
Validation loss: 2.5348084161517352

Epoch: 5| Step: 10
Training loss: 0.3254944396444994
Validation loss: 2.5480460670453575

Epoch: 334| Step: 0
Training loss: 0.47578216201870205
Validation loss: 2.513127817874067

Epoch: 5| Step: 1
Training loss: 0.8032048092978332
Validation loss: 2.4945564296984895

Epoch: 5| Step: 2
Training loss: 0.2448983830649564
Validation loss: 2.5540867756769354

Epoch: 5| Step: 3
Training loss: 0.49779508621304885
Validation loss: 2.562550824109276

Epoch: 5| Step: 4
Training loss: 0.5686122161474746
Validation loss: 2.5581709678326052

Epoch: 5| Step: 5
Training loss: 0.7318629866346225
Validation loss: 2.5762561715670826

Epoch: 5| Step: 6
Training loss: 0.7405879804155563
Validation loss: 2.610232607170987

Epoch: 5| Step: 7
Training loss: 0.2785906766806472
Validation loss: 2.590370549427857

Epoch: 5| Step: 8
Training loss: 0.4583750474616141
Validation loss: 2.578569239591892

Epoch: 5| Step: 9
Training loss: 0.9456901426499612
Validation loss: 2.598179517631518

Epoch: 5| Step: 10
Training loss: 0.5712337369294155
Validation loss: 2.5545178699802533

Epoch: 335| Step: 0
Training loss: 0.6407480354323616
Validation loss: 2.563211711868653

Epoch: 5| Step: 1
Training loss: 0.528528591992196
Validation loss: 2.5256536174076096

Epoch: 5| Step: 2
Training loss: 0.7476135672221464
Validation loss: 2.4985336556405144

Epoch: 5| Step: 3
Training loss: 0.7594508129312674
Validation loss: 2.523876783224734

Epoch: 5| Step: 4
Training loss: 0.6110742303768587
Validation loss: 2.51603127818297

Epoch: 5| Step: 5
Training loss: 0.6228912781056849
Validation loss: 2.517191882547967

Epoch: 5| Step: 6
Training loss: 0.6070228811740247
Validation loss: 2.558665489224956

Epoch: 5| Step: 7
Training loss: 0.544400693985625
Validation loss: 2.5636976131171645

Epoch: 5| Step: 8
Training loss: 0.5651232163929105
Validation loss: 2.554800897516086

Epoch: 5| Step: 9
Training loss: 0.4116096902265472
Validation loss: 2.564540729238966

Epoch: 5| Step: 10
Training loss: 0.5763691968375445
Validation loss: 2.588801179180525

Epoch: 336| Step: 0
Training loss: 0.6287606112151649
Validation loss: 2.565250129517474

Epoch: 5| Step: 1
Training loss: 0.4310975606984267
Validation loss: 2.568018811234397

Epoch: 5| Step: 2
Training loss: 0.4542303907531911
Validation loss: 2.5594302683250816

Epoch: 5| Step: 3
Training loss: 0.5572233128444555
Validation loss: 2.5516423677987827

Epoch: 5| Step: 4
Training loss: 0.7396271965738224
Validation loss: 2.5422240852527738

Epoch: 5| Step: 5
Training loss: 0.2693800156385264
Validation loss: 2.54091920726722

Epoch: 5| Step: 6
Training loss: 0.641930111354988
Validation loss: 2.5420831996791837

Epoch: 5| Step: 7
Training loss: 0.6837072005815724
Validation loss: 2.5352056989459877

Epoch: 5| Step: 8
Training loss: 0.6492950330370078
Validation loss: 2.5540274258121842

Epoch: 5| Step: 9
Training loss: 0.4901337387319671
Validation loss: 2.536483503421754

Epoch: 5| Step: 10
Training loss: 0.8604112446377833
Validation loss: 2.5545339621942063

Epoch: 337| Step: 0
Training loss: 0.6885196753456017
Validation loss: 2.5474307351484313

Epoch: 5| Step: 1
Training loss: 0.8552115415140459
Validation loss: 2.5206060799499816

Epoch: 5| Step: 2
Training loss: 0.3194886755152696
Validation loss: 2.545288233840048

Epoch: 5| Step: 3
Training loss: 0.5485253364236835
Validation loss: 2.534275445143134

Epoch: 5| Step: 4
Training loss: 0.6557843736270137
Validation loss: 2.540375269668797

Epoch: 5| Step: 5
Training loss: 0.778899968924493
Validation loss: 2.544487906591693

Epoch: 5| Step: 6
Training loss: 0.5415804562065468
Validation loss: 2.5317166352928626

Epoch: 5| Step: 7
Training loss: 0.5453335973817486
Validation loss: 2.5322047556932734

Epoch: 5| Step: 8
Training loss: 0.528976061677771
Validation loss: 2.551703213846413

Epoch: 5| Step: 9
Training loss: 0.4444233232022665
Validation loss: 2.58016824707338

Epoch: 5| Step: 10
Training loss: 0.42783516519387393
Validation loss: 2.5768728602030495

Epoch: 338| Step: 0
Training loss: 0.7271838248979251
Validation loss: 2.5656359937268256

Epoch: 5| Step: 1
Training loss: 0.5958663966824379
Validation loss: 2.5508897348716975

Epoch: 5| Step: 2
Training loss: 0.31015319582494766
Validation loss: 2.5305358728078797

Epoch: 5| Step: 3
Training loss: 0.3472130554366717
Validation loss: 2.5249346004672244

Epoch: 5| Step: 4
Training loss: 0.4143229511132297
Validation loss: 2.5263019237828632

Epoch: 5| Step: 5
Training loss: 0.7302335064549095
Validation loss: 2.5285664361310713

Epoch: 5| Step: 6
Training loss: 0.6698610150243578
Validation loss: 2.5270028213482045

Epoch: 5| Step: 7
Training loss: 0.588635172772433
Validation loss: 2.5255984204262463

Epoch: 5| Step: 8
Training loss: 0.6740485231721647
Validation loss: 2.5218850656043634

Epoch: 5| Step: 9
Training loss: 0.555212041497745
Validation loss: 2.5466022014442222

Epoch: 5| Step: 10
Training loss: 0.6871270772226992
Validation loss: 2.5529489719583673

Epoch: 339| Step: 0
Training loss: 0.7637543304495406
Validation loss: 2.5547819039536623

Epoch: 5| Step: 1
Training loss: 0.2261166131165482
Validation loss: 2.54146441242132

Epoch: 5| Step: 2
Training loss: 0.4585435739131203
Validation loss: 2.548520833074999

Epoch: 5| Step: 3
Training loss: 0.5882507944519152
Validation loss: 2.54752859303619

Epoch: 5| Step: 4
Training loss: 0.5077454155846921
Validation loss: 2.564449302208699

Epoch: 5| Step: 5
Training loss: 0.8373644405940028
Validation loss: 2.544275303437013

Epoch: 5| Step: 6
Training loss: 0.4015470783819901
Validation loss: 2.5631084070032846

Epoch: 5| Step: 7
Training loss: 0.5257795518051316
Validation loss: 2.549160748292427

Epoch: 5| Step: 8
Training loss: 0.5742088368916055
Validation loss: 2.5485693708810784

Epoch: 5| Step: 9
Training loss: 0.6812632918154834
Validation loss: 2.5574152210104257

Epoch: 5| Step: 10
Training loss: 0.5958003980919544
Validation loss: 2.5439035916374864

Epoch: 340| Step: 0
Training loss: 0.7311487144032651
Validation loss: 2.5556666284825758

Epoch: 5| Step: 1
Training loss: 0.5132670965231962
Validation loss: 2.558837805841164

Epoch: 5| Step: 2
Training loss: 0.3763127396954538
Validation loss: 2.5637938751704437

Epoch: 5| Step: 3
Training loss: 0.6352676753693087
Validation loss: 2.5695939173998137

Epoch: 5| Step: 4
Training loss: 0.45380447678066327
Validation loss: 2.5501008739059357

Epoch: 5| Step: 5
Training loss: 0.5857547729401927
Validation loss: 2.5419360710148777

Epoch: 5| Step: 6
Training loss: 0.6405470265642925
Validation loss: 2.570516712404541

Epoch: 5| Step: 7
Training loss: 0.2686958080923053
Validation loss: 2.5192673325144104

Epoch: 5| Step: 8
Training loss: 0.7354882912342409
Validation loss: 2.545583818811648

Epoch: 5| Step: 9
Training loss: 0.5897100688697025
Validation loss: 2.5539596668322497

Epoch: 5| Step: 10
Training loss: 0.6587735429570561
Validation loss: 2.5598639348729866

Epoch: 341| Step: 0
Training loss: 0.578783382087448
Validation loss: 2.566295327261991

Epoch: 5| Step: 1
Training loss: 0.6720150868064817
Validation loss: 2.5505118625818515

Epoch: 5| Step: 2
Training loss: 0.4003417380656611
Validation loss: 2.561450976633712

Epoch: 5| Step: 3
Training loss: 0.6805279676420668
Validation loss: 2.565549085397068

Epoch: 5| Step: 4
Training loss: 0.47564079704568524
Validation loss: 2.5653848064276645

Epoch: 5| Step: 5
Training loss: 0.7805873731061532
Validation loss: 2.550074441668909

Epoch: 5| Step: 6
Training loss: 0.33413130891026316
Validation loss: 2.5555557120862464

Epoch: 5| Step: 7
Training loss: 0.6237717241697258
Validation loss: 2.564274446401551

Epoch: 5| Step: 8
Training loss: 0.3366396131697273
Validation loss: 2.541897415201522

Epoch: 5| Step: 9
Training loss: 0.6230655057507242
Validation loss: 2.5803034543361907

Epoch: 5| Step: 10
Training loss: 0.6997496012311415
Validation loss: 2.569927332462726

Epoch: 342| Step: 0
Training loss: 0.4701203184891242
Validation loss: 2.5523032576876337

Epoch: 5| Step: 1
Training loss: 0.5503353721982148
Validation loss: 2.552317721611714

Epoch: 5| Step: 2
Training loss: 0.5310217142478557
Validation loss: 2.558103629277728

Epoch: 5| Step: 3
Training loss: 0.7819727415592679
Validation loss: 2.564688627045922

Epoch: 5| Step: 4
Training loss: 0.43298267572007626
Validation loss: 2.5480342647249397

Epoch: 5| Step: 5
Training loss: 0.6447349688777283
Validation loss: 2.573034481004779

Epoch: 5| Step: 6
Training loss: 0.3778168660204259
Validation loss: 2.5559842657912237

Epoch: 5| Step: 7
Training loss: 0.4313393486454492
Validation loss: 2.5527038961554758

Epoch: 5| Step: 8
Training loss: 0.7526911297002451
Validation loss: 2.5695475366854756

Epoch: 5| Step: 9
Training loss: 0.4536257968978631
Validation loss: 2.5511314366413127

Epoch: 5| Step: 10
Training loss: 0.7333436582300853
Validation loss: 2.5232141821928624

Epoch: 343| Step: 0
Training loss: 0.5118763804620892
Validation loss: 2.522167377240939

Epoch: 5| Step: 1
Training loss: 0.6851175817106455
Validation loss: 2.552982086850152

Epoch: 5| Step: 2
Training loss: 0.30850317386280546
Validation loss: 2.5293611239040685

Epoch: 5| Step: 3
Training loss: 0.5488610308682422
Validation loss: 2.5351308152707888

Epoch: 5| Step: 4
Training loss: 0.43264899556700137
Validation loss: 2.542224471479265

Epoch: 5| Step: 5
Training loss: 0.6760994046501311
Validation loss: 2.5208918450186366

Epoch: 5| Step: 6
Training loss: 0.39986092489190445
Validation loss: 2.5218591081887802

Epoch: 5| Step: 7
Training loss: 0.5054788225871346
Validation loss: 2.550980397200084

Epoch: 5| Step: 8
Training loss: 0.7929711553227067
Validation loss: 2.547408185467621

Epoch: 5| Step: 9
Training loss: 0.6669696675599786
Validation loss: 2.5701511987115135

Epoch: 5| Step: 10
Training loss: 0.6195970411351297
Validation loss: 2.5776296995613426

Epoch: 344| Step: 0
Training loss: 0.5254734356932448
Validation loss: 2.5632408145726484

Epoch: 5| Step: 1
Training loss: 0.39757624272841485
Validation loss: 2.5362168741014517

Epoch: 5| Step: 2
Training loss: 0.5639812780850859
Validation loss: 2.5104163279682297

Epoch: 5| Step: 3
Training loss: 0.5519210438945219
Validation loss: 2.494100161725843

Epoch: 5| Step: 4
Training loss: 0.6384041134492628
Validation loss: 2.523118168337276

Epoch: 5| Step: 5
Training loss: 0.5599309215344437
Validation loss: 2.5370185716630687

Epoch: 5| Step: 6
Training loss: 0.6294714478932661
Validation loss: 2.5492526275962306

Epoch: 5| Step: 7
Training loss: 0.6628538014710588
Validation loss: 2.597791736717013

Epoch: 5| Step: 8
Training loss: 0.46900284623541094
Validation loss: 2.5705524283600845

Epoch: 5| Step: 9
Training loss: 0.751676830707972
Validation loss: 2.574470264361609

Epoch: 5| Step: 10
Training loss: 0.5104027052027365
Validation loss: 2.5604847402638176

Epoch: 345| Step: 0
Training loss: 0.6983382365715428
Validation loss: 2.5786983326065855

Epoch: 5| Step: 1
Training loss: 0.45847524447258553
Validation loss: 2.5940744706341476

Epoch: 5| Step: 2
Training loss: 0.5996971687384278
Validation loss: 2.5531337850598295

Epoch: 5| Step: 3
Training loss: 0.28108796114259255
Validation loss: 2.552468950086911

Epoch: 5| Step: 4
Training loss: 0.3359444417901622
Validation loss: 2.5253685581635925

Epoch: 5| Step: 5
Training loss: 0.738404399954911
Validation loss: 2.5248938184123806

Epoch: 5| Step: 6
Training loss: 0.6949684920818873
Validation loss: 2.5352721117111376

Epoch: 5| Step: 7
Training loss: 0.36848071821173006
Validation loss: 2.521318035330031

Epoch: 5| Step: 8
Training loss: 0.4237451603987258
Validation loss: 2.5054818881251513

Epoch: 5| Step: 9
Training loss: 0.7733469438040264
Validation loss: 2.5093605687266853

Epoch: 5| Step: 10
Training loss: 0.6496978139861387
Validation loss: 2.516826296694925

Epoch: 346| Step: 0
Training loss: 0.9474553812839557
Validation loss: 2.5341899413146916

Epoch: 5| Step: 1
Training loss: 0.323728926757086
Validation loss: 2.577078540832131

Epoch: 5| Step: 2
Training loss: 0.792352521513432
Validation loss: 2.5473227772575453

Epoch: 5| Step: 3
Training loss: 0.31541845579198435
Validation loss: 2.58124952065254

Epoch: 5| Step: 4
Training loss: 0.30900882619378506
Validation loss: 2.5686994549785185

Epoch: 5| Step: 5
Training loss: 0.5341281621934455
Validation loss: 2.5620795414468533

Epoch: 5| Step: 6
Training loss: 0.4811714585109369
Validation loss: 2.555730183377397

Epoch: 5| Step: 7
Training loss: 0.5712185808051392
Validation loss: 2.5421264638690073

Epoch: 5| Step: 8
Training loss: 0.6386604191397204
Validation loss: 2.558722765739173

Epoch: 5| Step: 9
Training loss: 0.5056602940542365
Validation loss: 2.543578387316887

Epoch: 5| Step: 10
Training loss: 0.4253709198282143
Validation loss: 2.513016663325299

Epoch: 347| Step: 0
Training loss: 0.5910495281895602
Validation loss: 2.5399075281849615

Epoch: 5| Step: 1
Training loss: 0.42849649614394936
Validation loss: 2.543462735654568

Epoch: 5| Step: 2
Training loss: 0.3443569330575181
Validation loss: 2.5524006696289696

Epoch: 5| Step: 3
Training loss: 0.5530682960367772
Validation loss: 2.569110343746031

Epoch: 5| Step: 4
Training loss: 0.6556482280765731
Validation loss: 2.6034079948255626

Epoch: 5| Step: 5
Training loss: 0.5986283568174438
Validation loss: 2.591272688504063

Epoch: 5| Step: 6
Training loss: 0.6511054935957091
Validation loss: 2.5902281996916736

Epoch: 5| Step: 7
Training loss: 0.42087730124523937
Validation loss: 2.5827628161331164

Epoch: 5| Step: 8
Training loss: 0.49594363246652456
Validation loss: 2.5333734880199987

Epoch: 5| Step: 9
Training loss: 0.6017536503673561
Validation loss: 2.531742166090635

Epoch: 5| Step: 10
Training loss: 0.8269951147952279
Validation loss: 2.523134676217752

Epoch: 348| Step: 0
Training loss: 0.626171539934798
Validation loss: 2.5417428579330106

Epoch: 5| Step: 1
Training loss: 0.5507046801864002
Validation loss: 2.5435394296503935

Epoch: 5| Step: 2
Training loss: 0.42164388259893076
Validation loss: 2.539663579705782

Epoch: 5| Step: 3
Training loss: 0.26853116019101075
Validation loss: 2.5532350279957554

Epoch: 5| Step: 4
Training loss: 0.40797483640562654
Validation loss: 2.5496134502613903

Epoch: 5| Step: 5
Training loss: 0.47270861248928864
Validation loss: 2.585438527179612

Epoch: 5| Step: 6
Training loss: 0.6998584740485105
Validation loss: 2.630079108862724

Epoch: 5| Step: 7
Training loss: 0.5877936907470852
Validation loss: 2.5893425567326616

Epoch: 5| Step: 8
Training loss: 0.6542677915571548
Validation loss: 2.615399739672216

Epoch: 5| Step: 9
Training loss: 0.8309404269967061
Validation loss: 2.612219852468831

Epoch: 5| Step: 10
Training loss: 0.4619363533432109
Validation loss: 2.607184008196966

Epoch: 349| Step: 0
Training loss: 0.5531830062192357
Validation loss: 2.5744638897819243

Epoch: 5| Step: 1
Training loss: 0.6925287348504184
Validation loss: 2.5954712455425226

Epoch: 5| Step: 2
Training loss: 0.5020677606322944
Validation loss: 2.5788670103187488

Epoch: 5| Step: 3
Training loss: 0.5573751321721011
Validation loss: 2.557787920964627

Epoch: 5| Step: 4
Training loss: 0.6523173892240088
Validation loss: 2.5661537599484987

Epoch: 5| Step: 5
Training loss: 0.49781838954164354
Validation loss: 2.5906320772564566

Epoch: 5| Step: 6
Training loss: 0.6944460882061472
Validation loss: 2.5841985207053293

Epoch: 5| Step: 7
Training loss: 0.5929477190351631
Validation loss: 2.565969775705379

Epoch: 5| Step: 8
Training loss: 0.5954886879106779
Validation loss: 2.5881166628973653

Epoch: 5| Step: 9
Training loss: 0.1501687134205623
Validation loss: 2.5842482315907853

Epoch: 5| Step: 10
Training loss: 0.4450811487851471
Validation loss: 2.570126259924187

Epoch: 350| Step: 0
Training loss: 0.6255633676145408
Validation loss: 2.59449155831807

Epoch: 5| Step: 1
Training loss: 0.447261976868523
Validation loss: 2.593341444830932

Epoch: 5| Step: 2
Training loss: 0.40342203109125335
Validation loss: 2.566394204965694

Epoch: 5| Step: 3
Training loss: 0.4856987676475651
Validation loss: 2.566709388556615

Epoch: 5| Step: 4
Training loss: 0.4970916113946242
Validation loss: 2.536740257408265

Epoch: 5| Step: 5
Training loss: 0.441618927213937
Validation loss: 2.568939234110179

Epoch: 5| Step: 6
Training loss: 0.37619176873419913
Validation loss: 2.5350218891070018

Epoch: 5| Step: 7
Training loss: 0.8260775392751748
Validation loss: 2.5244226397268283

Epoch: 5| Step: 8
Training loss: 0.691151437303083
Validation loss: 2.522030814359666

Epoch: 5| Step: 9
Training loss: 0.3537143549130018
Validation loss: 2.526817982087301

Epoch: 5| Step: 10
Training loss: 0.7023614552338002
Validation loss: 2.5265077564147416

Epoch: 351| Step: 0
Training loss: 0.5149182186190782
Validation loss: 2.5482030189759515

Epoch: 5| Step: 1
Training loss: 0.397941898208405
Validation loss: 2.5595219282231185

Epoch: 5| Step: 2
Training loss: 0.6626435996918941
Validation loss: 2.5550437433754842

Epoch: 5| Step: 3
Training loss: 0.6295258449418036
Validation loss: 2.5702484020134415

Epoch: 5| Step: 4
Training loss: 0.40487471120175705
Validation loss: 2.551332115995022

Epoch: 5| Step: 5
Training loss: 0.4084269079047645
Validation loss: 2.5624972067556855

Epoch: 5| Step: 6
Training loss: 0.8686984534031048
Validation loss: 2.5636402167503016

Epoch: 5| Step: 7
Training loss: 0.3636642815834829
Validation loss: 2.5906707735482186

Epoch: 5| Step: 8
Training loss: 0.532103105977741
Validation loss: 2.6000652346066913

Epoch: 5| Step: 9
Training loss: 0.5309524263705329
Validation loss: 2.570590124451078

Epoch: 5| Step: 10
Training loss: 0.6192972845444541
Validation loss: 2.5898685840495053

Epoch: 352| Step: 0
Training loss: 0.7771327820318149
Validation loss: 2.5843548433846264

Epoch: 5| Step: 1
Training loss: 0.3566302929955763
Validation loss: 2.5804183430232577

Epoch: 5| Step: 2
Training loss: 0.36207954012234106
Validation loss: 2.551666521729439

Epoch: 5| Step: 3
Training loss: 0.6851372432356028
Validation loss: 2.5462388387167585

Epoch: 5| Step: 4
Training loss: 0.47472819658003046
Validation loss: 2.5449824541106274

Epoch: 5| Step: 5
Training loss: 0.22971900931416223
Validation loss: 2.5162542553947254

Epoch: 5| Step: 6
Training loss: 0.4317942039720481
Validation loss: 2.5465526858763328

Epoch: 5| Step: 7
Training loss: 0.4591890893101009
Validation loss: 2.547890453730179

Epoch: 5| Step: 8
Training loss: 0.6237798940875933
Validation loss: 2.5781556476599805

Epoch: 5| Step: 9
Training loss: 0.6450060858180643
Validation loss: 2.6131919711804974

Epoch: 5| Step: 10
Training loss: 0.6508775555080812
Validation loss: 2.6006627735440406

Epoch: 353| Step: 0
Training loss: 0.22351773395363397
Validation loss: 2.6061100808878157

Epoch: 5| Step: 1
Training loss: 0.603600875610983
Validation loss: 2.562175170895509

Epoch: 5| Step: 2
Training loss: 0.29667085605558263
Validation loss: 2.5615550854412965

Epoch: 5| Step: 3
Training loss: 0.7175826669049833
Validation loss: 2.550425279716429

Epoch: 5| Step: 4
Training loss: 0.47526566141099996
Validation loss: 2.5648385258863495

Epoch: 5| Step: 5
Training loss: 0.2436816134865759
Validation loss: 2.5591101646217185

Epoch: 5| Step: 6
Training loss: 0.5168015033632887
Validation loss: 2.5953340187022014

Epoch: 5| Step: 7
Training loss: 0.559562643108437
Validation loss: 2.5645187113748835

Epoch: 5| Step: 8
Training loss: 0.6309263117092497
Validation loss: 2.5963248894272626

Epoch: 5| Step: 9
Training loss: 0.8135447754029204
Validation loss: 2.585445872712159

Epoch: 5| Step: 10
Training loss: 0.571334915277271
Validation loss: 2.6012049352309736

Epoch: 354| Step: 0
Training loss: 0.6836617136276298
Validation loss: 2.5555053778536387

Epoch: 5| Step: 1
Training loss: 0.45814027477160074
Validation loss: 2.532770788514246

Epoch: 5| Step: 2
Training loss: 0.740347981856638
Validation loss: 2.5538453947646413

Epoch: 5| Step: 3
Training loss: 0.4225023514778114
Validation loss: 2.5751790119171214

Epoch: 5| Step: 4
Training loss: 0.4440772005422341
Validation loss: 2.5315226462851665

Epoch: 5| Step: 5
Training loss: 0.4359216488926793
Validation loss: 2.53641506300587

Epoch: 5| Step: 6
Training loss: 0.6451242435541802
Validation loss: 2.557981526650056

Epoch: 5| Step: 7
Training loss: 0.5224787628840728
Validation loss: 2.5801567904080986

Epoch: 5| Step: 8
Training loss: 0.642078704157172
Validation loss: 2.5692972052537297

Epoch: 5| Step: 9
Training loss: 0.2992439493469506
Validation loss: 2.597491337829654

Epoch: 5| Step: 10
Training loss: 0.491576542177814
Validation loss: 2.619463474339385

Epoch: 355| Step: 0
Training loss: 0.4452021612698413
Validation loss: 2.599710458767917

Epoch: 5| Step: 1
Training loss: 0.49067560226540297
Validation loss: 2.5762350175774382

Epoch: 5| Step: 2
Training loss: 0.787171657171132
Validation loss: 2.537990781456398

Epoch: 5| Step: 3
Training loss: 0.39471336920281574
Validation loss: 2.5323829986480493

Epoch: 5| Step: 4
Training loss: 0.39014643918414055
Validation loss: 2.483645373993161

Epoch: 5| Step: 5
Training loss: 0.5756704702652937
Validation loss: 2.5315299396480317

Epoch: 5| Step: 6
Training loss: 0.3066323880589686
Validation loss: 2.503513652170512

Epoch: 5| Step: 7
Training loss: 0.7688513138542453
Validation loss: 2.5398897056292817

Epoch: 5| Step: 8
Training loss: 0.43734723216827653
Validation loss: 2.526522385263573

Epoch: 5| Step: 9
Training loss: 0.6096714472453776
Validation loss: 2.585728680668949

Epoch: 5| Step: 10
Training loss: 0.5563250801764864
Validation loss: 2.5797695867118504

Epoch: 356| Step: 0
Training loss: 0.6119591621754688
Validation loss: 2.5997393639162962

Epoch: 5| Step: 1
Training loss: 0.5494305979399647
Validation loss: 2.5968293582414894

Epoch: 5| Step: 2
Training loss: 0.42356426621860105
Validation loss: 2.5621783927351984

Epoch: 5| Step: 3
Training loss: 0.3562539200818065
Validation loss: 2.567810437625714

Epoch: 5| Step: 4
Training loss: 0.4276139250868081
Validation loss: 2.5624813646408757

Epoch: 5| Step: 5
Training loss: 0.47823007588378696
Validation loss: 2.5633452647347124

Epoch: 5| Step: 6
Training loss: 0.5866686518953431
Validation loss: 2.56936603645643

Epoch: 5| Step: 7
Training loss: 0.7769091747620618
Validation loss: 2.567540221895092

Epoch: 5| Step: 8
Training loss: 0.39756503604775095
Validation loss: 2.567164232745276

Epoch: 5| Step: 9
Training loss: 0.27159244115494563
Validation loss: 2.586194098433503

Epoch: 5| Step: 10
Training loss: 0.7070692484218413
Validation loss: 2.5827557833310997

Epoch: 357| Step: 0
Training loss: 0.49855053436144303
Validation loss: 2.5853227199888416

Epoch: 5| Step: 1
Training loss: 0.3069779915275298
Validation loss: 2.5932066795982696

Epoch: 5| Step: 2
Training loss: 0.4499260185939821
Validation loss: 2.5605723436086

Epoch: 5| Step: 3
Training loss: 0.5199751427559698
Validation loss: 2.5889577646095385

Epoch: 5| Step: 4
Training loss: 0.24413935851722288
Validation loss: 2.574377326774774

Epoch: 5| Step: 5
Training loss: 0.609081344273828
Validation loss: 2.577663290047469

Epoch: 5| Step: 6
Training loss: 0.5844553703486279
Validation loss: 2.5515155220011096

Epoch: 5| Step: 7
Training loss: 0.4873375126671
Validation loss: 2.5429781457452614

Epoch: 5| Step: 8
Training loss: 0.699420537548458
Validation loss: 2.5583718856285533

Epoch: 5| Step: 9
Training loss: 0.6208872901801411
Validation loss: 2.555087104415349

Epoch: 5| Step: 10
Training loss: 0.45743127580294535
Validation loss: 2.5745744456500357

Epoch: 358| Step: 0
Training loss: 0.5970290888867253
Validation loss: 2.558880085701348

Epoch: 5| Step: 1
Training loss: 0.4395178175038884
Validation loss: 2.5387915808286885

Epoch: 5| Step: 2
Training loss: 0.34841633334680316
Validation loss: 2.554175448598708

Epoch: 5| Step: 3
Training loss: 0.7139748884748544
Validation loss: 2.5355033106683464

Epoch: 5| Step: 4
Training loss: 0.46072188684776944
Validation loss: 2.554582869458161

Epoch: 5| Step: 5
Training loss: 0.4929889783623472
Validation loss: 2.554599581449918

Epoch: 5| Step: 6
Training loss: 0.4579694524451823
Validation loss: 2.5635547143104986

Epoch: 5| Step: 7
Training loss: 0.5411193142347909
Validation loss: 2.571725858142559

Epoch: 5| Step: 8
Training loss: 0.4364440128857096
Validation loss: 2.5647787488709257

Epoch: 5| Step: 9
Training loss: 0.43624008506285084
Validation loss: 2.5595935122295157

Epoch: 5| Step: 10
Training loss: 0.6005447993882181
Validation loss: 2.545735199581659

Epoch: 359| Step: 0
Training loss: 0.6108100328863031
Validation loss: 2.565154177462039

Epoch: 5| Step: 1
Training loss: 0.3874407492223085
Validation loss: 2.5453829788428366

Epoch: 5| Step: 2
Training loss: 0.5982632266239164
Validation loss: 2.5494768220473256

Epoch: 5| Step: 3
Training loss: 0.29968386026346056
Validation loss: 2.539990664477799

Epoch: 5| Step: 4
Training loss: 0.38528509944441075
Validation loss: 2.559883404481267

Epoch: 5| Step: 5
Training loss: 0.6629348605248964
Validation loss: 2.5555726895717275

Epoch: 5| Step: 6
Training loss: 0.42901152411456833
Validation loss: 2.5482279273470616

Epoch: 5| Step: 7
Training loss: 0.42207008725451134
Validation loss: 2.55664907806713

Epoch: 5| Step: 8
Training loss: 0.4983611966267417
Validation loss: 2.5707583703511374

Epoch: 5| Step: 9
Training loss: 0.4822221257502791
Validation loss: 2.5618635498228417

Epoch: 5| Step: 10
Training loss: 0.6389883348104639
Validation loss: 2.5875720377845486

Epoch: 360| Step: 0
Training loss: 0.2898526861247622
Validation loss: 2.5915568222393817

Epoch: 5| Step: 1
Training loss: 0.6205027425461008
Validation loss: 2.5954219753167953

Epoch: 5| Step: 2
Training loss: 0.31569781879741515
Validation loss: 2.5931926572770356

Epoch: 5| Step: 3
Training loss: 0.5872296390974319
Validation loss: 2.572907632173623

Epoch: 5| Step: 4
Training loss: 0.5437021585223423
Validation loss: 2.5577699228122075

Epoch: 5| Step: 5
Training loss: 0.5796441918001741
Validation loss: 2.580804217632114

Epoch: 5| Step: 6
Training loss: 0.4358249341229545
Validation loss: 2.5711439154263265

Epoch: 5| Step: 7
Training loss: 0.3282072554530221
Validation loss: 2.601684249171895

Epoch: 5| Step: 8
Training loss: 0.5437698492176187
Validation loss: 2.567477738178409

Epoch: 5| Step: 9
Training loss: 0.6196077191373165
Validation loss: 2.5670265258181457

Epoch: 5| Step: 10
Training loss: 0.3714031134614594
Validation loss: 2.5464324727772922

Epoch: 361| Step: 0
Training loss: 0.4589317453930924
Validation loss: 2.5562460428540197

Epoch: 5| Step: 1
Training loss: 0.45624183882638575
Validation loss: 2.5558281116777373

Epoch: 5| Step: 2
Training loss: 0.45673122502508856
Validation loss: 2.5344312996390292

Epoch: 5| Step: 3
Training loss: 0.5593449003763068
Validation loss: 2.5244348708059388

Epoch: 5| Step: 4
Training loss: 0.4035994185146721
Validation loss: 2.535510526859744

Epoch: 5| Step: 5
Training loss: 0.6078812557842233
Validation loss: 2.5632425528431564

Epoch: 5| Step: 6
Training loss: 0.46697933828688404
Validation loss: 2.541029492346598

Epoch: 5| Step: 7
Training loss: 0.6881652777626925
Validation loss: 2.5662518788853155

Epoch: 5| Step: 8
Training loss: 0.2950312683134555
Validation loss: 2.5760048430215825

Epoch: 5| Step: 9
Training loss: 0.38844749069562184
Validation loss: 2.5770820260611416

Epoch: 5| Step: 10
Training loss: 0.4130505485797006
Validation loss: 2.5720394948084673

Epoch: 362| Step: 0
Training loss: 0.1585917115667723
Validation loss: 2.5529600918095916

Epoch: 5| Step: 1
Training loss: 0.41121138231947896
Validation loss: 2.551149814248362

Epoch: 5| Step: 2
Training loss: 0.445930036042589
Validation loss: 2.5516465543893094

Epoch: 5| Step: 3
Training loss: 0.5412721817457709
Validation loss: 2.548618925727758

Epoch: 5| Step: 4
Training loss: 0.23862838473749545
Validation loss: 2.557461737045593

Epoch: 5| Step: 5
Training loss: 0.5730524220162387
Validation loss: 2.563478906648954

Epoch: 5| Step: 6
Training loss: 0.564439159603338
Validation loss: 2.5713726338091933

Epoch: 5| Step: 7
Training loss: 0.5565943916260988
Validation loss: 2.5868156817396013

Epoch: 5| Step: 8
Training loss: 0.5382786179078172
Validation loss: 2.5920439316937123

Epoch: 5| Step: 9
Training loss: 0.5714941716218181
Validation loss: 2.592068315423545

Epoch: 5| Step: 10
Training loss: 0.5136665372970058
Validation loss: 2.5691890126932453

Epoch: 363| Step: 0
Training loss: 0.513308407371348
Validation loss: 2.5381925217296057

Epoch: 5| Step: 1
Training loss: 0.33420545388373873
Validation loss: 2.5458810863591728

Epoch: 5| Step: 2
Training loss: 0.24070162420105196
Validation loss: 2.5187752952680587

Epoch: 5| Step: 3
Training loss: 0.4791080155620342
Validation loss: 2.5511032750732046

Epoch: 5| Step: 4
Training loss: 0.5093389018554928
Validation loss: 2.5281383520997935

Epoch: 5| Step: 5
Training loss: 0.6824486432996824
Validation loss: 2.5474403992362458

Epoch: 5| Step: 6
Training loss: 0.4040710813845779
Validation loss: 2.5461999222594405

Epoch: 5| Step: 7
Training loss: 0.5987288629786894
Validation loss: 2.5791120184206098

Epoch: 5| Step: 8
Training loss: 0.33053362189357316
Validation loss: 2.5920696031439565

Epoch: 5| Step: 9
Training loss: 0.4162805099016811
Validation loss: 2.6336965093442823

Epoch: 5| Step: 10
Training loss: 0.5590009738848807
Validation loss: 2.589204101088576

Epoch: 364| Step: 0
Training loss: 0.1692812781901668
Validation loss: 2.5622788280538686

Epoch: 5| Step: 1
Training loss: 0.4302216764078857
Validation loss: 2.571185511844201

Epoch: 5| Step: 2
Training loss: 0.5248406236424276
Validation loss: 2.5423970533865154

Epoch: 5| Step: 3
Training loss: 0.29013288630853284
Validation loss: 2.5512120024937537

Epoch: 5| Step: 4
Training loss: 0.4811717217431658
Validation loss: 2.5782961164946987

Epoch: 5| Step: 5
Training loss: 0.5479842244648093
Validation loss: 2.590975920028945

Epoch: 5| Step: 6
Training loss: 0.35162641156262797
Validation loss: 2.5839557594188958

Epoch: 5| Step: 7
Training loss: 0.5928457300889949
Validation loss: 2.569794366081779

Epoch: 5| Step: 8
Training loss: 0.5519037644438481
Validation loss: 2.608344061261114

Epoch: 5| Step: 9
Training loss: 0.3749633214814966
Validation loss: 2.6322979070430725

Epoch: 5| Step: 10
Training loss: 0.6924796312483367
Validation loss: 2.628105482029672

Epoch: 365| Step: 0
Training loss: 0.5283901147334299
Validation loss: 2.6061734886857675

Epoch: 5| Step: 1
Training loss: 0.42877457478775577
Validation loss: 2.594688149990633

Epoch: 5| Step: 2
Training loss: 0.465638579100181
Validation loss: 2.5542573215735818

Epoch: 5| Step: 3
Training loss: 0.36944684441742204
Validation loss: 2.562254443985072

Epoch: 5| Step: 4
Training loss: 0.5890586124362714
Validation loss: 2.5180736953185168

Epoch: 5| Step: 5
Training loss: 0.6209351439064146
Validation loss: 2.493176797565717

Epoch: 5| Step: 6
Training loss: 0.39234678369805376
Validation loss: 2.5102960714762035

Epoch: 5| Step: 7
Training loss: 0.582370607919992
Validation loss: 2.5291437186693675

Epoch: 5| Step: 8
Training loss: 0.38053140457274237
Validation loss: 2.543492805149166

Epoch: 5| Step: 9
Training loss: 0.43378957845424454
Validation loss: 2.550872693053357

Epoch: 5| Step: 10
Training loss: 0.48205217102748127
Validation loss: 2.5707823381943764

Epoch: 366| Step: 0
Training loss: 0.4088247211649197
Validation loss: 2.556264821325068

Epoch: 5| Step: 1
Training loss: 0.3313350559293139
Validation loss: 2.5658678292995654

Epoch: 5| Step: 2
Training loss: 0.473037849422068
Validation loss: 2.530896503330931

Epoch: 5| Step: 3
Training loss: 0.4564095531684947
Validation loss: 2.5351129363802833

Epoch: 5| Step: 4
Training loss: 0.3959455163832137
Validation loss: 2.5096341987022797

Epoch: 5| Step: 5
Training loss: 0.5300030941243093
Validation loss: 2.522885410661266

Epoch: 5| Step: 6
Training loss: 0.4575975121612628
Validation loss: 2.5266997095608135

Epoch: 5| Step: 7
Training loss: 0.4806211586489904
Validation loss: 2.5345196639115923

Epoch: 5| Step: 8
Training loss: 0.43667337117010646
Validation loss: 2.568488410245213

Epoch: 5| Step: 9
Training loss: 0.6339418905881448
Validation loss: 2.5640397456833965

Epoch: 5| Step: 10
Training loss: 0.4421941257964401
Validation loss: 2.5575073310309855

Epoch: 367| Step: 0
Training loss: 0.5728198027366388
Validation loss: 2.5275974970785566

Epoch: 5| Step: 1
Training loss: 0.26433650421898097
Validation loss: 2.550283342110558

Epoch: 5| Step: 2
Training loss: 0.5101517716542735
Validation loss: 2.55263415970453

Epoch: 5| Step: 3
Training loss: 0.49658647233295566
Validation loss: 2.5167048475496827

Epoch: 5| Step: 4
Training loss: 0.4893916360115055
Validation loss: 2.52825641942281

Epoch: 5| Step: 5
Training loss: 0.3145390150397466
Validation loss: 2.53756618990311

Epoch: 5| Step: 6
Training loss: 0.33118414809083396
Validation loss: 2.5176216242080245

Epoch: 5| Step: 7
Training loss: 0.6642027314165255
Validation loss: 2.545891939521177

Epoch: 5| Step: 8
Training loss: 0.33084036492114627
Validation loss: 2.5623068547884875

Epoch: 5| Step: 9
Training loss: 0.4481780893542451
Validation loss: 2.5671571599567176

Epoch: 5| Step: 10
Training loss: 0.47201414077900733
Validation loss: 2.5770860907464215

Epoch: 368| Step: 0
Training loss: 0.486901768400264
Validation loss: 2.5714679565414986

Epoch: 5| Step: 1
Training loss: 0.4806094080029157
Validation loss: 2.5802632970309185

Epoch: 5| Step: 2
Training loss: 0.3836467178041757
Validation loss: 2.5791099668011612

Epoch: 5| Step: 3
Training loss: 0.5804909672342392
Validation loss: 2.5409154560173213

Epoch: 5| Step: 4
Training loss: 0.5331312976568054
Validation loss: 2.5599474215043103

Epoch: 5| Step: 5
Training loss: 0.33995711967799275
Validation loss: 2.544282345622889

Epoch: 5| Step: 6
Training loss: 0.4684951407283352
Validation loss: 2.5553645591229093

Epoch: 5| Step: 7
Training loss: 0.36755583935757663
Validation loss: 2.5625089404622727

Epoch: 5| Step: 8
Training loss: 0.3222801089644357
Validation loss: 2.573849363553479

Epoch: 5| Step: 9
Training loss: 0.5098929995132373
Validation loss: 2.5869936705603505

Epoch: 5| Step: 10
Training loss: 0.4298970491789415
Validation loss: 2.58990043598269

Epoch: 369| Step: 0
Training loss: 0.5477560303433142
Validation loss: 2.5867487419940405

Epoch: 5| Step: 1
Training loss: 0.29026201457983525
Validation loss: 2.5864848748563

Epoch: 5| Step: 2
Training loss: 0.4473076346712311
Validation loss: 2.5593551448461693

Epoch: 5| Step: 3
Training loss: 0.5235197942010147
Validation loss: 2.54365953708518

Epoch: 5| Step: 4
Training loss: 0.43426772309187867
Validation loss: 2.5578645166861054

Epoch: 5| Step: 5
Training loss: 0.34894352378544763
Validation loss: 2.5612934872813393

Epoch: 5| Step: 6
Training loss: 0.5410268348606679
Validation loss: 2.54467729046643

Epoch: 5| Step: 7
Training loss: 0.46545592637083283
Validation loss: 2.5345642778026347

Epoch: 5| Step: 8
Training loss: 0.26287933200653363
Validation loss: 2.5526878310699286

Epoch: 5| Step: 9
Training loss: 0.4121715263759435
Validation loss: 2.576558772624883

Epoch: 5| Step: 10
Training loss: 0.5825967281891358
Validation loss: 2.5857378466792285

Epoch: 370| Step: 0
Training loss: 0.5309841107704936
Validation loss: 2.5760976159076914

Epoch: 5| Step: 1
Training loss: 0.20437838749892542
Validation loss: 2.5709069420490662

Epoch: 5| Step: 2
Training loss: 0.6448574743342458
Validation loss: 2.5689614860227805

Epoch: 5| Step: 3
Training loss: 0.4577550617679843
Validation loss: 2.5852841402382047

Epoch: 5| Step: 4
Training loss: 0.44319035337361
Validation loss: 2.5551614343379585

Epoch: 5| Step: 5
Training loss: 0.29674159365319064
Validation loss: 2.5663200135800484

Epoch: 5| Step: 6
Training loss: 0.6091165972857528
Validation loss: 2.5533236245711035

Epoch: 5| Step: 7
Training loss: 0.38716309960846335
Validation loss: 2.537263975305636

Epoch: 5| Step: 8
Training loss: 0.49860960640793883
Validation loss: 2.5667854613665466

Epoch: 5| Step: 9
Training loss: 0.37057726203620783
Validation loss: 2.589871048831766

Epoch: 5| Step: 10
Training loss: 0.3257650705248915
Validation loss: 2.5796395654337174

Epoch: 371| Step: 0
Training loss: 0.4750566298206563
Validation loss: 2.580735432724505

Epoch: 5| Step: 1
Training loss: 0.23190247176320372
Validation loss: 2.5987362229232907

Epoch: 5| Step: 2
Training loss: 0.6225529928516438
Validation loss: 2.592311698051081

Epoch: 5| Step: 3
Training loss: 0.5216251140514828
Validation loss: 2.57474743800884

Epoch: 5| Step: 4
Training loss: 0.5493336857091289
Validation loss: 2.5281528376604956

Epoch: 5| Step: 5
Training loss: 0.2822038978002988
Validation loss: 2.570459082329475

Epoch: 5| Step: 6
Training loss: 0.17839372341742654
Validation loss: 2.552008002958525

Epoch: 5| Step: 7
Training loss: 0.2978081093031177
Validation loss: 2.583838315889582

Epoch: 5| Step: 8
Training loss: 0.47753898448982457
Validation loss: 2.576291573113567

Epoch: 5| Step: 9
Training loss: 0.45446588811450034
Validation loss: 2.5707449889685092

Epoch: 5| Step: 10
Training loss: 0.6237131699599586
Validation loss: 2.5839721033521434

Epoch: 372| Step: 0
Training loss: 0.2888009976274029
Validation loss: 2.5669641973798263

Epoch: 5| Step: 1
Training loss: 0.38836049781319304
Validation loss: 2.5619669704267327

Epoch: 5| Step: 2
Training loss: 0.6258025976533091
Validation loss: 2.5961887800931986

Epoch: 5| Step: 3
Training loss: 0.5969474928207908
Validation loss: 2.55422500709402

Epoch: 5| Step: 4
Training loss: 0.29782949897469596
Validation loss: 2.561808203860241

Epoch: 5| Step: 5
Training loss: 0.45003557991724613
Validation loss: 2.5170364145210224

Epoch: 5| Step: 6
Training loss: 0.5964404186747793
Validation loss: 2.5275737480728084

Epoch: 5| Step: 7
Training loss: 0.2464288065521232
Validation loss: 2.523582298650149

Epoch: 5| Step: 8
Training loss: 0.4913378906007378
Validation loss: 2.5226698487238814

Epoch: 5| Step: 9
Training loss: 0.27781253471417205
Validation loss: 2.5333635162710006

Epoch: 5| Step: 10
Training loss: 0.4088248669600027
Validation loss: 2.566948007317868

Epoch: 373| Step: 0
Training loss: 0.23890655579930975
Validation loss: 2.5929937055711627

Epoch: 5| Step: 1
Training loss: 0.5559257333677834
Validation loss: 2.5761766715496712

Epoch: 5| Step: 2
Training loss: 0.7201737110870753
Validation loss: 2.5783902377072483

Epoch: 5| Step: 3
Training loss: 0.3507989326726962
Validation loss: 2.582600095699757

Epoch: 5| Step: 4
Training loss: 0.44021706195896787
Validation loss: 2.570306232303992

Epoch: 5| Step: 5
Training loss: 0.24222419060916264
Validation loss: 2.5383294977701514

Epoch: 5| Step: 6
Training loss: 0.3673745348584429
Validation loss: 2.5071163228974114

Epoch: 5| Step: 7
Training loss: 0.3723786245606969
Validation loss: 2.5381372585612136

Epoch: 5| Step: 8
Training loss: 0.3402050005630206
Validation loss: 2.537231938486606

Epoch: 5| Step: 9
Training loss: 0.5366180669752986
Validation loss: 2.5414178229860713

Epoch: 5| Step: 10
Training loss: 0.4133255716653884
Validation loss: 2.541534325233806

Epoch: 374| Step: 0
Training loss: 0.5276822451942402
Validation loss: 2.5464952081139045

Epoch: 5| Step: 1
Training loss: 0.14609088180908814
Validation loss: 2.5726297182076774

Epoch: 5| Step: 2
Training loss: 0.351107748284781
Validation loss: 2.589104137927121

Epoch: 5| Step: 3
Training loss: 0.39652950988334806
Validation loss: 2.5931776012887005

Epoch: 5| Step: 4
Training loss: 0.44073181616175267
Validation loss: 2.5956505578980384

Epoch: 5| Step: 5
Training loss: 0.3978701460275874
Validation loss: 2.5779455998195737

Epoch: 5| Step: 6
Training loss: 0.5426053539499187
Validation loss: 2.58146086627071

Epoch: 5| Step: 7
Training loss: 0.5623267489759907
Validation loss: 2.5830173464574187

Epoch: 5| Step: 8
Training loss: 0.33080534420637886
Validation loss: 2.5296074680387757

Epoch: 5| Step: 9
Training loss: 0.46910252031235977
Validation loss: 2.555674695561913

Epoch: 5| Step: 10
Training loss: 0.4429370195976398
Validation loss: 2.5363337405811186

Epoch: 375| Step: 0
Training loss: 0.48672955961760855
Validation loss: 2.5636281537199506

Epoch: 5| Step: 1
Training loss: 0.47620587998124075
Validation loss: 2.5849823671921985

Epoch: 5| Step: 2
Training loss: 0.4513358276512851
Validation loss: 2.566849787150891

Epoch: 5| Step: 3
Training loss: 0.5502569530382263
Validation loss: 2.6016646371333083

Epoch: 5| Step: 4
Training loss: 0.39404720412841515
Validation loss: 2.572546618240401

Epoch: 5| Step: 5
Training loss: 0.5834816647585078
Validation loss: 2.5769983240516274

Epoch: 5| Step: 6
Training loss: 0.4063179802870476
Validation loss: 2.5673390569970294

Epoch: 5| Step: 7
Training loss: 0.47249851274508586
Validation loss: 2.564687152148422

Epoch: 5| Step: 8
Training loss: 0.26033402403175304
Validation loss: 2.5675781519186556

Epoch: 5| Step: 9
Training loss: 0.1789717933165564
Validation loss: 2.587896547966632

Epoch: 5| Step: 10
Training loss: 0.31726121186900114
Validation loss: 2.5708642766236456

Epoch: 376| Step: 0
Training loss: 0.1813951700196326
Validation loss: 2.5722367758962177

Epoch: 5| Step: 1
Training loss: 0.18319608353541983
Validation loss: 2.569609948123175

Epoch: 5| Step: 2
Training loss: 0.4405763978058097
Validation loss: 2.606120753069513

Epoch: 5| Step: 3
Training loss: 0.527980194329024
Validation loss: 2.5735943045413805

Epoch: 5| Step: 4
Training loss: 0.3551014899864187
Validation loss: 2.565581946723513

Epoch: 5| Step: 5
Training loss: 0.4348551813035583
Validation loss: 2.5957247168677022

Epoch: 5| Step: 6
Training loss: 0.43438198852406024
Validation loss: 2.5475612198827173

Epoch: 5| Step: 7
Training loss: 0.5645721732393779
Validation loss: 2.54094941986202

Epoch: 5| Step: 8
Training loss: 0.38785367176943464
Validation loss: 2.5473449523083085

Epoch: 5| Step: 9
Training loss: 0.43230938779365047
Validation loss: 2.5569829438455938

Epoch: 5| Step: 10
Training loss: 0.5494618676763477
Validation loss: 2.5350952707395713

Epoch: 377| Step: 0
Training loss: 0.48994196952010366
Validation loss: 2.560969736427824

Epoch: 5| Step: 1
Training loss: 0.4520127193688913
Validation loss: 2.536409235612996

Epoch: 5| Step: 2
Training loss: 0.3546839213925957
Validation loss: 2.545074694275313

Epoch: 5| Step: 3
Training loss: 0.3695578462735746
Validation loss: 2.5397243548997817

Epoch: 5| Step: 4
Training loss: 0.5195109427936162
Validation loss: 2.5672975755044676

Epoch: 5| Step: 5
Training loss: 0.30502347273477465
Validation loss: 2.566824312912841

Epoch: 5| Step: 6
Training loss: 0.5167897968571612
Validation loss: 2.534899777527886

Epoch: 5| Step: 7
Training loss: 0.507797240981682
Validation loss: 2.5434641568400385

Epoch: 5| Step: 8
Training loss: 0.18622331290457056
Validation loss: 2.5678642754922585

Epoch: 5| Step: 9
Training loss: 0.34127829312141356
Validation loss: 2.5648669254590217

Epoch: 5| Step: 10
Training loss: 0.45783012213007257
Validation loss: 2.5768781643203744

Epoch: 378| Step: 0
Training loss: 0.4193886143255408
Validation loss: 2.560087002787063

Epoch: 5| Step: 1
Training loss: 0.46053547218190455
Validation loss: 2.5958728072326536

Epoch: 5| Step: 2
Training loss: 0.4527429252389821
Validation loss: 2.570217870526338

Epoch: 5| Step: 3
Training loss: 0.43562427397548426
Validation loss: 2.577960621455716

Epoch: 5| Step: 4
Training loss: 0.2561285044913005
Validation loss: 2.592676165043226

Epoch: 5| Step: 5
Training loss: 0.3438393953431233
Validation loss: 2.5743960453120036

Epoch: 5| Step: 6
Training loss: 0.42351286453222825
Validation loss: 2.5895136526912244

Epoch: 5| Step: 7
Training loss: 0.31667124871444113
Validation loss: 2.575409645512315

Epoch: 5| Step: 8
Training loss: 0.3487076558791642
Validation loss: 2.5712667320240237

Epoch: 5| Step: 9
Training loss: 0.6137832239485463
Validation loss: 2.5572487232891654

Epoch: 5| Step: 10
Training loss: 0.3995583979961291
Validation loss: 2.5644376378615283

Epoch: 379| Step: 0
Training loss: 0.36639141467548325
Validation loss: 2.5659516301269334

Epoch: 5| Step: 1
Training loss: 0.4138892369069735
Validation loss: 2.5322692795862993

Epoch: 5| Step: 2
Training loss: 0.5563936990866551
Validation loss: 2.5465494905760635

Epoch: 5| Step: 3
Training loss: 0.3170487979114137
Validation loss: 2.546628657137189

Epoch: 5| Step: 4
Training loss: 0.2400584235581414
Validation loss: 2.5377984638075137

Epoch: 5| Step: 5
Training loss: 0.354220914426029
Validation loss: 2.5819849646164776

Epoch: 5| Step: 6
Training loss: 0.4216179064344231
Validation loss: 2.5800608288407525

Epoch: 5| Step: 7
Training loss: 0.42171478761477144
Validation loss: 2.5781767312009163

Epoch: 5| Step: 8
Training loss: 0.6180944659692162
Validation loss: 2.5848735834840766

Epoch: 5| Step: 9
Training loss: 0.3442705179906527
Validation loss: 2.559535645223953

Epoch: 5| Step: 10
Training loss: 0.4445508500053836
Validation loss: 2.516603349284267

Epoch: 380| Step: 0
Training loss: 0.46052307960441596
Validation loss: 2.5174285338390616

Epoch: 5| Step: 1
Training loss: 0.32407470168830005
Validation loss: 2.518693073516641

Epoch: 5| Step: 2
Training loss: 0.48415952935213424
Validation loss: 2.5487628661087465

Epoch: 5| Step: 3
Training loss: 0.3228714883128206
Validation loss: 2.5399882527279085

Epoch: 5| Step: 4
Training loss: 0.3680298456873131
Validation loss: 2.5549673209620902

Epoch: 5| Step: 5
Training loss: 0.5175370685919906
Validation loss: 2.5703336169562347

Epoch: 5| Step: 6
Training loss: 0.33200183064892486
Validation loss: 2.5931764223713167

Epoch: 5| Step: 7
Training loss: 0.427360981344507
Validation loss: 2.60239421519358

Epoch: 5| Step: 8
Training loss: 0.5634263146803491
Validation loss: 2.589522021219907

Epoch: 5| Step: 9
Training loss: 0.35849748121225355
Validation loss: 2.589076010153483

Epoch: 5| Step: 10
Training loss: 0.42745821673337775
Validation loss: 2.553250892338739

Epoch: 381| Step: 0
Training loss: 0.546883991712491
Validation loss: 2.56430065278858

Epoch: 5| Step: 1
Training loss: 0.3113933758100924
Validation loss: 2.521463717222256

Epoch: 5| Step: 2
Training loss: 0.4249004738340656
Validation loss: 2.5431423237337314

Epoch: 5| Step: 3
Training loss: 0.38370872219641916
Validation loss: 2.544970813866482

Epoch: 5| Step: 4
Training loss: 0.3027718059410692
Validation loss: 2.5413007656065774

Epoch: 5| Step: 5
Training loss: 0.39151214948707724
Validation loss: 2.586940679723428

Epoch: 5| Step: 6
Training loss: 0.5043110958490645
Validation loss: 2.6174931163622697

Epoch: 5| Step: 7
Training loss: 0.4717785433527154
Validation loss: 2.6300256784900236

Epoch: 5| Step: 8
Training loss: 0.4498066579532903
Validation loss: 2.636511228135995

Epoch: 5| Step: 9
Training loss: 0.29995732351580795
Validation loss: 2.601890576536429

Epoch: 5| Step: 10
Training loss: 0.49399335272366923
Validation loss: 2.5698638523461326

Epoch: 382| Step: 0
Training loss: 0.5268185013042173
Validation loss: 2.5515363243042475

Epoch: 5| Step: 1
Training loss: 0.2796063076212363
Validation loss: 2.5163754028235292

Epoch: 5| Step: 2
Training loss: 0.4804096030449112
Validation loss: 2.5246399163684066

Epoch: 5| Step: 3
Training loss: 0.43838007147743124
Validation loss: 2.533271911766488

Epoch: 5| Step: 4
Training loss: 0.43301361382933823
Validation loss: 2.5568799432873317

Epoch: 5| Step: 5
Training loss: 0.3052450482914267
Validation loss: 2.6052130571094816

Epoch: 5| Step: 6
Training loss: 0.341856281022595
Validation loss: 2.6470866914600273

Epoch: 5| Step: 7
Training loss: 0.4579648646408187
Validation loss: 2.653830074637661

Epoch: 5| Step: 8
Training loss: 0.618280481160158
Validation loss: 2.6438425713917364

Epoch: 5| Step: 9
Training loss: 0.5666501802495839
Validation loss: 2.592262803409245

Epoch: 5| Step: 10
Training loss: 0.2571150854607296
Validation loss: 2.532589090171125

Epoch: 383| Step: 0
Training loss: 0.24063286644598844
Validation loss: 2.52600318330494

Epoch: 5| Step: 1
Training loss: 0.23674417554323182
Validation loss: 2.524678355861037

Epoch: 5| Step: 2
Training loss: 0.5636354219171482
Validation loss: 2.516322637458021

Epoch: 5| Step: 3
Training loss: 0.26656549510189936
Validation loss: 2.5334832019899594

Epoch: 5| Step: 4
Training loss: 0.4958528699819324
Validation loss: 2.5255228372225167

Epoch: 5| Step: 5
Training loss: 0.48413667660910314
Validation loss: 2.5552932057834115

Epoch: 5| Step: 6
Training loss: 0.5644032809415601
Validation loss: 2.577180360101318

Epoch: 5| Step: 7
Training loss: 0.5243722341325856
Validation loss: 2.578463926687391

Epoch: 5| Step: 8
Training loss: 0.44414828183997956
Validation loss: 2.56739925644384

Epoch: 5| Step: 9
Training loss: 0.2955967085529247
Validation loss: 2.556128313947288

Epoch: 5| Step: 10
Training loss: 0.4172452565192678
Validation loss: 2.5568189777875605

Epoch: 384| Step: 0
Training loss: 0.528714750210642
Validation loss: 2.522534229743874

Epoch: 5| Step: 1
Training loss: 0.4233751645252594
Validation loss: 2.5084548468471417

Epoch: 5| Step: 2
Training loss: 0.3171268898505773
Validation loss: 2.5090244173412857

Epoch: 5| Step: 3
Training loss: 0.35691760401781186
Validation loss: 2.5183582136469043

Epoch: 5| Step: 4
Training loss: 0.32790719478278024
Validation loss: 2.5646066782360255

Epoch: 5| Step: 5
Training loss: 0.45863942921216544
Validation loss: 2.584436444003224

Epoch: 5| Step: 6
Training loss: 0.419474412133164
Validation loss: 2.602577129620388

Epoch: 5| Step: 7
Training loss: 0.4886156844195012
Validation loss: 2.6233548293971385

Epoch: 5| Step: 8
Training loss: 0.49327214633490696
Validation loss: 2.6471770167948905

Epoch: 5| Step: 9
Training loss: 0.3961998054529913
Validation loss: 2.625259938337106

Epoch: 5| Step: 10
Training loss: 0.41146929239414193
Validation loss: 2.5989401066989877

Epoch: 385| Step: 0
Training loss: 0.5276725309264572
Validation loss: 2.555404128557617

Epoch: 5| Step: 1
Training loss: 0.32197468658353223
Validation loss: 2.5082641630318014

Epoch: 5| Step: 2
Training loss: 0.25773940350592645
Validation loss: 2.4999751325621578

Epoch: 5| Step: 3
Training loss: 0.3874121720240727
Validation loss: 2.5272299644609575

Epoch: 5| Step: 4
Training loss: 0.47528705957712003
Validation loss: 2.551104909566092

Epoch: 5| Step: 5
Training loss: 0.345898955316226
Validation loss: 2.538812773660615

Epoch: 5| Step: 6
Training loss: 0.337388972722717
Validation loss: 2.5627527950117965

Epoch: 5| Step: 7
Training loss: 0.6993887071399757
Validation loss: 2.5804225951914805

Epoch: 5| Step: 8
Training loss: 0.4130930618140729
Validation loss: 2.6059682825079067

Epoch: 5| Step: 9
Training loss: 0.36203725152110056
Validation loss: 2.6216328125284134

Epoch: 5| Step: 10
Training loss: 0.3050774255566266
Validation loss: 2.620836650892524

Epoch: 386| Step: 0
Training loss: 0.31422485927976523
Validation loss: 2.621307455785357

Epoch: 5| Step: 1
Training loss: 0.31311185066801217
Validation loss: 2.5992467259382686

Epoch: 5| Step: 2
Training loss: 0.4824897780101512
Validation loss: 2.578945368722755

Epoch: 5| Step: 3
Training loss: 0.603855864284626
Validation loss: 2.5666391222045406

Epoch: 5| Step: 4
Training loss: 0.408541124211557
Validation loss: 2.5233165773330724

Epoch: 5| Step: 5
Training loss: 0.5358881157457251
Validation loss: 2.557046114118461

Epoch: 5| Step: 6
Training loss: 0.5125978795067622
Validation loss: 2.5409413726219108

Epoch: 5| Step: 7
Training loss: 0.2161951564139951
Validation loss: 2.558406657856015

Epoch: 5| Step: 8
Training loss: 0.292221158174887
Validation loss: 2.54269189059787

Epoch: 5| Step: 9
Training loss: 0.441246290677611
Validation loss: 2.5596164157841876

Epoch: 5| Step: 10
Training loss: 0.20052782682303233
Validation loss: 2.5459671037995313

Epoch: 387| Step: 0
Training loss: 0.3053684328437232
Validation loss: 2.5456034469861297

Epoch: 5| Step: 1
Training loss: 0.5709200979920435
Validation loss: 2.551251927742074

Epoch: 5| Step: 2
Training loss: 0.31106342085444677
Validation loss: 2.5410942365688634

Epoch: 5| Step: 3
Training loss: 0.26453367609577777
Validation loss: 2.5446289010715972

Epoch: 5| Step: 4
Training loss: 0.3301517020840686
Validation loss: 2.537844751986649

Epoch: 5| Step: 5
Training loss: 0.5236702017435132
Validation loss: 2.570330384393555

Epoch: 5| Step: 6
Training loss: 0.2386236154492128
Validation loss: 2.55013841892346

Epoch: 5| Step: 7
Training loss: 0.5467709578590689
Validation loss: 2.5554090212723426

Epoch: 5| Step: 8
Training loss: 0.5374171259665108
Validation loss: 2.528118337856718

Epoch: 5| Step: 9
Training loss: 0.2847058253038
Validation loss: 2.537381501812686

Epoch: 5| Step: 10
Training loss: 0.3137113458447654
Validation loss: 2.525943136540079

Epoch: 388| Step: 0
Training loss: 0.4376211679787158
Validation loss: 2.529005789959654

Epoch: 5| Step: 1
Training loss: 0.5097591063568636
Validation loss: 2.5521674736037

Epoch: 5| Step: 2
Training loss: 0.41092925117829376
Validation loss: 2.54668990987043

Epoch: 5| Step: 3
Training loss: 0.29596868002319476
Validation loss: 2.547445457193655

Epoch: 5| Step: 4
Training loss: 0.30601836806376054
Validation loss: 2.561086375293285

Epoch: 5| Step: 5
Training loss: 0.49209751335900265
Validation loss: 2.5352751240429816

Epoch: 5| Step: 6
Training loss: 0.48965062193046627
Validation loss: 2.513190687865082

Epoch: 5| Step: 7
Training loss: 0.35838118259564145
Validation loss: 2.558609845635985

Epoch: 5| Step: 8
Training loss: 0.3330177685991641
Validation loss: 2.5714770034036087

Epoch: 5| Step: 9
Training loss: 0.2666310583992073
Validation loss: 2.594789589479252

Epoch: 5| Step: 10
Training loss: 0.31906662530128294
Validation loss: 2.5802012684740543

Epoch: 389| Step: 0
Training loss: 0.2694659776019671
Validation loss: 2.5812522677818537

Epoch: 5| Step: 1
Training loss: 0.370360885549443
Validation loss: 2.5744982315667397

Epoch: 5| Step: 2
Training loss: 0.48851674313877097
Validation loss: 2.574492643228521

Epoch: 5| Step: 3
Training loss: 0.5012441296126677
Validation loss: 2.5552493064676822

Epoch: 5| Step: 4
Training loss: 0.43270513187461407
Validation loss: 2.5801294017123997

Epoch: 5| Step: 5
Training loss: 0.3447332408571522
Validation loss: 2.5567564225695594

Epoch: 5| Step: 6
Training loss: 0.32723685820458415
Validation loss: 2.5576914168322213

Epoch: 5| Step: 7
Training loss: 0.2957945411505023
Validation loss: 2.5515165136912614

Epoch: 5| Step: 8
Training loss: 0.3636269718889081
Validation loss: 2.527721567425571

Epoch: 5| Step: 9
Training loss: 0.24238740454050187
Validation loss: 2.524906612753895

Epoch: 5| Step: 10
Training loss: 0.49859564971801007
Validation loss: 2.529564078663454

Epoch: 390| Step: 0
Training loss: 0.2311928978217903
Validation loss: 2.536393132512721

Epoch: 5| Step: 1
Training loss: 0.4077927200957554
Validation loss: 2.550710301134192

Epoch: 5| Step: 2
Training loss: 0.17816484114483663
Validation loss: 2.581278683177957

Epoch: 5| Step: 3
Training loss: 0.3084316673036509
Validation loss: 2.5833136249813267

Epoch: 5| Step: 4
Training loss: 0.3617480956134877
Validation loss: 2.5898918093324

Epoch: 5| Step: 5
Training loss: 0.3188992118339153
Validation loss: 2.5650467101569125

Epoch: 5| Step: 6
Training loss: 0.45435345954157247
Validation loss: 2.5680107949121087

Epoch: 5| Step: 7
Training loss: 0.46586519101120616
Validation loss: 2.550214440186103

Epoch: 5| Step: 8
Training loss: 0.40343163457221964
Validation loss: 2.545300940774019

Epoch: 5| Step: 9
Training loss: 0.5130971732359664
Validation loss: 2.543741041034008

Epoch: 5| Step: 10
Training loss: 0.506563146309555
Validation loss: 2.5369985900870073

Epoch: 391| Step: 0
Training loss: 0.23260229785326195
Validation loss: 2.544492570430572

Epoch: 5| Step: 1
Training loss: 0.47488825261560774
Validation loss: 2.5298094950530885

Epoch: 5| Step: 2
Training loss: 0.41690117872473675
Validation loss: 2.557991609888472

Epoch: 5| Step: 3
Training loss: 0.3140516146391351
Validation loss: 2.5642577864662672

Epoch: 5| Step: 4
Training loss: 0.3246061813803337
Validation loss: 2.5505534301181987

Epoch: 5| Step: 5
Training loss: 0.2022160955899488
Validation loss: 2.5464174549275995

Epoch: 5| Step: 6
Training loss: 0.32683640587719454
Validation loss: 2.571200898016034

Epoch: 5| Step: 7
Training loss: 0.2465541257270165
Validation loss: 2.5804649068640297

Epoch: 5| Step: 8
Training loss: 0.539585550836354
Validation loss: 2.566197280915695

Epoch: 5| Step: 9
Training loss: 0.6302468600726416
Validation loss: 2.5949727099736615

Epoch: 5| Step: 10
Training loss: 0.3704772244839254
Validation loss: 2.5937885455022442

Epoch: 392| Step: 0
Training loss: 0.3730467751388017
Validation loss: 2.6192566113987388

Epoch: 5| Step: 1
Training loss: 0.3930634303009918
Validation loss: 2.6440888450415754

Epoch: 5| Step: 2
Training loss: 0.17300132685907707
Validation loss: 2.5819142039731866

Epoch: 5| Step: 3
Training loss: 0.5230989072757276
Validation loss: 2.556413205444664

Epoch: 5| Step: 4
Training loss: 0.47070991542872537
Validation loss: 2.5441618186794566

Epoch: 5| Step: 5
Training loss: 0.3742927398485068
Validation loss: 2.534545152060515

Epoch: 5| Step: 6
Training loss: 0.30163803933356115
Validation loss: 2.5128744684733504

Epoch: 5| Step: 7
Training loss: 0.2805076179030933
Validation loss: 2.5312111604830956

Epoch: 5| Step: 8
Training loss: 0.5977178803624708
Validation loss: 2.5313621606541483

Epoch: 5| Step: 9
Training loss: 0.13137368295328783
Validation loss: 2.522989852893908

Epoch: 5| Step: 10
Training loss: 0.44535658434112746
Validation loss: 2.5406529435570047

Epoch: 393| Step: 0
Training loss: 0.35076239987639696
Validation loss: 2.56176446522375

Epoch: 5| Step: 1
Training loss: 0.3536334605386439
Validation loss: 2.5730245633265456

Epoch: 5| Step: 2
Training loss: 0.3808305387095301
Validation loss: 2.5809274555914734

Epoch: 5| Step: 3
Training loss: 0.22607702826119824
Validation loss: 2.5675527967365

Epoch: 5| Step: 4
Training loss: 0.3575368810849914
Validation loss: 2.5773505043479132

Epoch: 5| Step: 5
Training loss: 0.14761199540281272
Validation loss: 2.536058053244342

Epoch: 5| Step: 6
Training loss: 0.7222565653982204
Validation loss: 2.5353133062270525

Epoch: 5| Step: 7
Training loss: 0.35801774264568287
Validation loss: 2.5591298803876477

Epoch: 5| Step: 8
Training loss: 0.1749585609249074
Validation loss: 2.518922563831577

Epoch: 5| Step: 9
Training loss: 0.47698977342875204
Validation loss: 2.489304226767915

Epoch: 5| Step: 10
Training loss: 0.4058494977878153
Validation loss: 2.4976574156416578

Epoch: 394| Step: 0
Training loss: 0.4876040225431831
Validation loss: 2.4961340520632658

Epoch: 5| Step: 1
Training loss: 0.36935775668178084
Validation loss: 2.509728101160393

Epoch: 5| Step: 2
Training loss: 0.35847179275403873
Validation loss: 2.5560281123650315

Epoch: 5| Step: 3
Training loss: 0.13398270619857325
Validation loss: 2.5683631879788433

Epoch: 5| Step: 4
Training loss: 0.3955194542195781
Validation loss: 2.518538272766655

Epoch: 5| Step: 5
Training loss: 0.49431245251427575
Validation loss: 2.5658588800587063

Epoch: 5| Step: 6
Training loss: 0.38279060378999236
Validation loss: 2.549145293957077

Epoch: 5| Step: 7
Training loss: 0.39047478648660483
Validation loss: 2.5387655801756934

Epoch: 5| Step: 8
Training loss: 0.24928989740144802
Validation loss: 2.5327040368612157

Epoch: 5| Step: 9
Training loss: 0.4050437000328133
Validation loss: 2.530051228699602

Epoch: 5| Step: 10
Training loss: 0.38233133165702443
Validation loss: 2.53874250820408

Epoch: 395| Step: 0
Training loss: 0.35603484466219343
Validation loss: 2.533654250414983

Epoch: 5| Step: 1
Training loss: 0.45886107066831605
Validation loss: 2.539847085923397

Epoch: 5| Step: 2
Training loss: 0.5304580282889058
Validation loss: 2.547254761426944

Epoch: 5| Step: 3
Training loss: 0.30328577339930185
Validation loss: 2.57255205335328

Epoch: 5| Step: 4
Training loss: 0.3485660756238799
Validation loss: 2.584458937193685

Epoch: 5| Step: 5
Training loss: 0.4214237236668936
Validation loss: 2.612349075524487

Epoch: 5| Step: 6
Training loss: 0.2936169130081296
Validation loss: 2.5933632787828285

Epoch: 5| Step: 7
Training loss: 0.3183230865016855
Validation loss: 2.5658515004334626

Epoch: 5| Step: 8
Training loss: 0.44097634707379796
Validation loss: 2.595060816645383

Epoch: 5| Step: 9
Training loss: 0.36269154420866123
Validation loss: 2.555112986640176

Epoch: 5| Step: 10
Training loss: 0.21849094958024065
Validation loss: 2.538789016976299

Epoch: 396| Step: 0
Training loss: 0.27431357230504666
Validation loss: 2.5554064289473146

Epoch: 5| Step: 1
Training loss: 0.3775143966076955
Validation loss: 2.5437046603804965

Epoch: 5| Step: 2
Training loss: 0.5563666221435263
Validation loss: 2.570535468030471

Epoch: 5| Step: 3
Training loss: 0.18489756158012072
Validation loss: 2.578047630961404

Epoch: 5| Step: 4
Training loss: 0.43631915405121835
Validation loss: 2.594607798841091

Epoch: 5| Step: 5
Training loss: 0.3558312548383866
Validation loss: 2.636308944983644

Epoch: 5| Step: 6
Training loss: 0.5472920598596333
Validation loss: 2.6371654165892116

Epoch: 5| Step: 7
Training loss: 0.36804737700766377
Validation loss: 2.6182181574398267

Epoch: 5| Step: 8
Training loss: 0.4217751349470592
Validation loss: 2.6207043120186126

Epoch: 5| Step: 9
Training loss: 0.3197353093856419
Validation loss: 2.6081392779858277

Epoch: 5| Step: 10
Training loss: 0.28729283705803305
Validation loss: 2.5703375352236897

Epoch: 397| Step: 0
Training loss: 0.3637794646884617
Validation loss: 2.5782475576296964

Epoch: 5| Step: 1
Training loss: 0.34022357148318993
Validation loss: 2.577404547764231

Epoch: 5| Step: 2
Training loss: 0.28818872202256535
Validation loss: 2.573351900247425

Epoch: 5| Step: 3
Training loss: 0.22547052577027268
Validation loss: 2.5543773842096185

Epoch: 5| Step: 4
Training loss: 0.542525158268024
Validation loss: 2.543875388853804

Epoch: 5| Step: 5
Training loss: 0.20581244742713997
Validation loss: 2.5573106709946147

Epoch: 5| Step: 6
Training loss: 0.2708755775052944
Validation loss: 2.5664082378547635

Epoch: 5| Step: 7
Training loss: 0.311740166064687
Validation loss: 2.5516051232173567

Epoch: 5| Step: 8
Training loss: 0.5468469612563126
Validation loss: 2.553750168151129

Epoch: 5| Step: 9
Training loss: 0.571876028716616
Validation loss: 2.549051077004116

Epoch: 5| Step: 10
Training loss: 0.19623347581860445
Validation loss: 2.5446360299286654

Epoch: 398| Step: 0
Training loss: 0.33719004508994493
Validation loss: 2.5657481379887632

Epoch: 5| Step: 1
Training loss: 0.2305287024543512
Validation loss: 2.5377640183569077

Epoch: 5| Step: 2
Training loss: 0.3915164693337721
Validation loss: 2.5473609187486534

Epoch: 5| Step: 3
Training loss: 0.4342650466457764
Validation loss: 2.5638042915266523

Epoch: 5| Step: 4
Training loss: 0.3882764213461328
Validation loss: 2.5772899877649693

Epoch: 5| Step: 5
Training loss: 0.30890100610707494
Validation loss: 2.583347595074916

Epoch: 5| Step: 6
Training loss: 0.5020697788398035
Validation loss: 2.577323322069528

Epoch: 5| Step: 7
Training loss: 0.3507612103725589
Validation loss: 2.6038902605274945

Epoch: 5| Step: 8
Training loss: 0.3148386233080393
Validation loss: 2.5908247732038086

Epoch: 5| Step: 9
Training loss: 0.4297921140073346
Validation loss: 2.611553409478445

Epoch: 5| Step: 10
Training loss: 0.36658710741862416
Validation loss: 2.588799267442338

Epoch: 399| Step: 0
Training loss: 0.2789806095874402
Validation loss: 2.588749307741772

Epoch: 5| Step: 1
Training loss: 0.5469276947792073
Validation loss: 2.5263078906821455

Epoch: 5| Step: 2
Training loss: 0.4123371453025491
Validation loss: 2.5470402362832294

Epoch: 5| Step: 3
Training loss: 0.3421025026915642
Validation loss: 2.555748212946617

Epoch: 5| Step: 4
Training loss: 0.3252400891518849
Validation loss: 2.549283216086574

Epoch: 5| Step: 5
Training loss: 0.16054152458909685
Validation loss: 2.588990227814931

Epoch: 5| Step: 6
Training loss: 0.42107247916376783
Validation loss: 2.5848988610024115

Epoch: 5| Step: 7
Training loss: 0.30695706944347617
Validation loss: 2.594535105895448

Epoch: 5| Step: 8
Training loss: 0.4900552034665572
Validation loss: 2.6184436353102845

Epoch: 5| Step: 9
Training loss: 0.319385139804534
Validation loss: 2.611001933883064

Epoch: 5| Step: 10
Training loss: 0.3307277336490053
Validation loss: 2.5724520350736753

Epoch: 400| Step: 0
Training loss: 0.25080099533163414
Validation loss: 2.603428856138647

Epoch: 5| Step: 1
Training loss: 0.23171445432296578
Validation loss: 2.583986678221777

Epoch: 5| Step: 2
Training loss: 0.2690181686131336
Validation loss: 2.5628737790562566

Epoch: 5| Step: 3
Training loss: 0.18611453708141318
Validation loss: 2.537818081483789

Epoch: 5| Step: 4
Training loss: 0.35400422194894327
Validation loss: 2.5578383115094923

Epoch: 5| Step: 5
Training loss: 0.6102052559020156
Validation loss: 2.588344117711666

Epoch: 5| Step: 6
Training loss: 0.426354503573985
Validation loss: 2.578233419147906

Epoch: 5| Step: 7
Training loss: 0.3209218764843498
Validation loss: 2.578158332457587

Epoch: 5| Step: 8
Training loss: 0.2872312767070465
Validation loss: 2.579597179600887

Epoch: 5| Step: 9
Training loss: 0.465494629830997
Validation loss: 2.578853323572673

Epoch: 5| Step: 10
Training loss: 0.39928801769866357
Validation loss: 2.5843560625336166

Epoch: 401| Step: 0
Training loss: 0.2877648973188051
Validation loss: 2.564870449770783

Epoch: 5| Step: 1
Training loss: 0.46042716336547534
Validation loss: 2.5902891498519005

Epoch: 5| Step: 2
Training loss: 0.26458640972862035
Validation loss: 2.5453001511249296

Epoch: 5| Step: 3
Training loss: 0.2916064569224757
Validation loss: 2.56257253274577

Epoch: 5| Step: 4
Training loss: 0.242281418709639
Validation loss: 2.53734892694437

Epoch: 5| Step: 5
Training loss: 0.24451178756628797
Validation loss: 2.540620691152776

Epoch: 5| Step: 6
Training loss: 0.49124034694962077
Validation loss: 2.527825831647246

Epoch: 5| Step: 7
Training loss: 0.33365833809665374
Validation loss: 2.5420586518913995

Epoch: 5| Step: 8
Training loss: 0.4289866887941835
Validation loss: 2.573227542308511

Epoch: 5| Step: 9
Training loss: 0.30342601400807667
Validation loss: 2.5742494003470684

Epoch: 5| Step: 10
Training loss: 0.6039459521430457
Validation loss: 2.57698236714443

Epoch: 402| Step: 0
Training loss: 0.34709453208452623
Validation loss: 2.5537556804113777

Epoch: 5| Step: 1
Training loss: 0.4843407126565956
Validation loss: 2.5510537363277344

Epoch: 5| Step: 2
Training loss: 0.23026145890960742
Validation loss: 2.5578548468809053

Epoch: 5| Step: 3
Training loss: 0.3808791326631014
Validation loss: 2.55791136180448

Epoch: 5| Step: 4
Training loss: 0.43067634547703165
Validation loss: 2.568795570013438

Epoch: 5| Step: 5
Training loss: 0.35912882624711295
Validation loss: 2.5370966548266565

Epoch: 5| Step: 6
Training loss: 0.19670149900985678
Validation loss: 2.5536151878467015

Epoch: 5| Step: 7
Training loss: 0.37020933267390166
Validation loss: 2.590580736288773

Epoch: 5| Step: 8
Training loss: 0.4070137986672279
Validation loss: 2.557876952675373

Epoch: 5| Step: 9
Training loss: 0.3310675041846036
Validation loss: 2.5965487358022834

Epoch: 5| Step: 10
Training loss: 0.4001977409411987
Validation loss: 2.6040993566530615

Epoch: 403| Step: 0
Training loss: 0.3792374529979074
Validation loss: 2.5967090291895376

Epoch: 5| Step: 1
Training loss: 0.29010393078769886
Validation loss: 2.58217241792651

Epoch: 5| Step: 2
Training loss: 0.36347058192380094
Validation loss: 2.546122178179578

Epoch: 5| Step: 3
Training loss: 0.33948050192123314
Validation loss: 2.5352584042415005

Epoch: 5| Step: 4
Training loss: 0.4308937135156834
Validation loss: 2.5084046916999942

Epoch: 5| Step: 5
Training loss: 0.3164493154722981
Validation loss: 2.513730653497138

Epoch: 5| Step: 6
Training loss: 0.39673268477376666
Validation loss: 2.4924293884412005

Epoch: 5| Step: 7
Training loss: 0.29054942327634825
Validation loss: 2.518453744255332

Epoch: 5| Step: 8
Training loss: 0.3820100080205185
Validation loss: 2.556337449253077

Epoch: 5| Step: 9
Training loss: 0.30015642737046283
Validation loss: 2.57683857145503

Epoch: 5| Step: 10
Training loss: 0.45894776867923487
Validation loss: 2.6059954316118987

Epoch: 404| Step: 0
Training loss: 0.19630178723439873
Validation loss: 2.6299556767184034

Epoch: 5| Step: 1
Training loss: 0.4888540341615311
Validation loss: 2.631672318695954

Epoch: 5| Step: 2
Training loss: 0.19341387125255347
Validation loss: 2.6192425934673635

Epoch: 5| Step: 3
Training loss: 0.37535698111746985
Validation loss: 2.5661516410247938

Epoch: 5| Step: 4
Training loss: 0.3752170173209152
Validation loss: 2.5802549213253627

Epoch: 5| Step: 5
Training loss: 0.36549941049703083
Validation loss: 2.557730457132401

Epoch: 5| Step: 6
Training loss: 0.4836662706467269
Validation loss: 2.5543215177375194

Epoch: 5| Step: 7
Training loss: 0.4232286001294446
Validation loss: 2.5423524806474838

Epoch: 5| Step: 8
Training loss: 0.3809543002259777
Validation loss: 2.5573577728625936

Epoch: 5| Step: 9
Training loss: 0.3185663194245914
Validation loss: 2.5806873752297177

Epoch: 5| Step: 10
Training loss: 0.23328651553865404
Validation loss: 2.5856065827436514

Epoch: 405| Step: 0
Training loss: 0.4935208078401811
Validation loss: 2.594146739685444

Epoch: 5| Step: 1
Training loss: 0.34681878321695037
Validation loss: 2.5978794250916217

Epoch: 5| Step: 2
Training loss: 0.30184130454916663
Validation loss: 2.619466115820228

Epoch: 5| Step: 3
Training loss: 0.2873891518274621
Validation loss: 2.6163472212281693

Epoch: 5| Step: 4
Training loss: 0.32100795054319614
Validation loss: 2.58101874588878

Epoch: 5| Step: 5
Training loss: 0.5165344656221573
Validation loss: 2.5521788735971933

Epoch: 5| Step: 6
Training loss: 0.08743124489346896
Validation loss: 2.552808525378777

Epoch: 5| Step: 7
Training loss: 0.2978206931205053
Validation loss: 2.528055467948276

Epoch: 5| Step: 8
Training loss: 0.3733122316248063
Validation loss: 2.535448576345634

Epoch: 5| Step: 9
Training loss: 0.2551544320671882
Validation loss: 2.5102454215455876

Epoch: 5| Step: 10
Training loss: 0.40058663385368837
Validation loss: 2.5142647748445968

Epoch: 406| Step: 0
Training loss: 0.31435736388683705
Validation loss: 2.5105027558598416

Epoch: 5| Step: 1
Training loss: 0.2941827417138371
Validation loss: 2.537211235132632

Epoch: 5| Step: 2
Training loss: 0.4721329684929586
Validation loss: 2.535467659125734

Epoch: 5| Step: 3
Training loss: 0.2915987151326939
Validation loss: 2.560324767342596

Epoch: 5| Step: 4
Training loss: 0.23304941904263207
Validation loss: 2.594787042425407

Epoch: 5| Step: 5
Training loss: 0.19088192572704063
Validation loss: 2.577305944756987

Epoch: 5| Step: 6
Training loss: 0.585033635126198
Validation loss: 2.5872797208764227

Epoch: 5| Step: 7
Training loss: 0.35677318386593704
Validation loss: 2.5802704158624876

Epoch: 5| Step: 8
Training loss: 0.3327037172329701
Validation loss: 2.567479797595171

Epoch: 5| Step: 9
Training loss: 0.2777358493685319
Validation loss: 2.55387951691256

Epoch: 5| Step: 10
Training loss: 0.4079907243436257
Validation loss: 2.551087748092235

Epoch: 407| Step: 0
Training loss: 0.3566351189245759
Validation loss: 2.5651434172921297

Epoch: 5| Step: 1
Training loss: 0.36927391350469907
Validation loss: 2.540834565695621

Epoch: 5| Step: 2
Training loss: 0.485764540774193
Validation loss: 2.5380818457092404

Epoch: 5| Step: 3
Training loss: 0.33518797406417894
Validation loss: 2.554550878228252

Epoch: 5| Step: 4
Training loss: 0.1501351825213205
Validation loss: 2.5391798534045713

Epoch: 5| Step: 5
Training loss: 0.27083221154102893
Validation loss: 2.5410280062387938

Epoch: 5| Step: 6
Training loss: 0.34522803037242844
Validation loss: 2.5207201370320647

Epoch: 5| Step: 7
Training loss: 0.24035407395014022
Validation loss: 2.524383762700068

Epoch: 5| Step: 8
Training loss: 0.4662354736519729
Validation loss: 2.5218997253343627

Epoch: 5| Step: 9
Training loss: 0.30279786459372654
Validation loss: 2.5391576413739454

Epoch: 5| Step: 10
Training loss: 0.4232991516901425
Validation loss: 2.5341508762437566

Epoch: 408| Step: 0
Training loss: 0.26481845363562456
Validation loss: 2.5745293525733652

Epoch: 5| Step: 1
Training loss: 0.2130697266927257
Validation loss: 2.5809756948566567

Epoch: 5| Step: 2
Training loss: 0.3101635612567722
Validation loss: 2.5807476000617315

Epoch: 5| Step: 3
Training loss: 0.5247192915281558
Validation loss: 2.583517902249884

Epoch: 5| Step: 4
Training loss: 0.31235078587128623
Validation loss: 2.5982327718560025

Epoch: 5| Step: 5
Training loss: 0.1942847390520414
Validation loss: 2.5492369807330566

Epoch: 5| Step: 6
Training loss: 0.2851247639452314
Validation loss: 2.545000782942378

Epoch: 5| Step: 7
Training loss: 0.4122879581499875
Validation loss: 2.503697797454186

Epoch: 5| Step: 8
Training loss: 0.49201284064617434
Validation loss: 2.5063417367013887

Epoch: 5| Step: 9
Training loss: 0.21617863111343671
Validation loss: 2.50158130308464

Epoch: 5| Step: 10
Training loss: 0.5245909152898259
Validation loss: 2.5168519444166466

Epoch: 409| Step: 0
Training loss: 0.4433573920251807
Validation loss: 2.517160184538668

Epoch: 5| Step: 1
Training loss: 0.41357038151605896
Validation loss: 2.5633456937841093

Epoch: 5| Step: 2
Training loss: 0.3948604230300383
Validation loss: 2.590812659624244

Epoch: 5| Step: 3
Training loss: 0.36346566226445653
Validation loss: 2.6128775256574377

Epoch: 5| Step: 4
Training loss: 0.5077813359014629
Validation loss: 2.630321240425762

Epoch: 5| Step: 5
Training loss: 0.14579822055129113
Validation loss: 2.6396791934512573

Epoch: 5| Step: 6
Training loss: 0.39421431397955925
Validation loss: 2.559863930867085

Epoch: 5| Step: 7
Training loss: 0.2988423861422916
Validation loss: 2.580283913272189

Epoch: 5| Step: 8
Training loss: 0.3993312871170212
Validation loss: 2.544487938832561

Epoch: 5| Step: 9
Training loss: 0.22800340874010233
Validation loss: 2.545816717638557

Epoch: 5| Step: 10
Training loss: 0.17819544963370632
Validation loss: 2.5028510782059694

Epoch: 410| Step: 0
Training loss: 0.3391574968255166
Validation loss: 2.5026736688002553

Epoch: 5| Step: 1
Training loss: 0.3120063458906894
Validation loss: 2.506749406705545

Epoch: 5| Step: 2
Training loss: 0.3619839464416351
Validation loss: 2.5417954223824126

Epoch: 5| Step: 3
Training loss: 0.46181980647260923
Validation loss: 2.5422735953802973

Epoch: 5| Step: 4
Training loss: 0.3810785494342211
Validation loss: 2.5758432970533627

Epoch: 5| Step: 5
Training loss: 0.37425342391211885
Validation loss: 2.5826440547229574

Epoch: 5| Step: 6
Training loss: 0.38415149145019284
Validation loss: 2.5979769295137785

Epoch: 5| Step: 7
Training loss: 0.38470640549737384
Validation loss: 2.57788194969339

Epoch: 5| Step: 8
Training loss: 0.22997010161081308
Validation loss: 2.5374252060991163

Epoch: 5| Step: 9
Training loss: 0.11916398773010946
Validation loss: 2.5349035675144505

Epoch: 5| Step: 10
Training loss: 0.35450650020741253
Validation loss: 2.5344658106142175

Epoch: 411| Step: 0
Training loss: 0.4800133756919704
Validation loss: 2.559094309553582

Epoch: 5| Step: 1
Training loss: 0.10188192333058374
Validation loss: 2.5225172860054235

Epoch: 5| Step: 2
Training loss: 0.22041722574926284
Validation loss: 2.506895663195733

Epoch: 5| Step: 3
Training loss: 0.547664671654917
Validation loss: 2.529134843224044

Epoch: 5| Step: 4
Training loss: 0.1369877145067964
Validation loss: 2.5462746898206334

Epoch: 5| Step: 5
Training loss: 0.3920981286338663
Validation loss: 2.5642400476751956

Epoch: 5| Step: 6
Training loss: 0.3428454527235008
Validation loss: 2.543561507162516

Epoch: 5| Step: 7
Training loss: 0.14193944410574164
Validation loss: 2.555468988620618

Epoch: 5| Step: 8
Training loss: 0.23711147998711282
Validation loss: 2.5845925705278394

Epoch: 5| Step: 9
Training loss: 0.3614648920979403
Validation loss: 2.565812023174409

Epoch: 5| Step: 10
Training loss: 0.47484813383136787
Validation loss: 2.5548353159639454

Epoch: 412| Step: 0
Training loss: 0.2947912874432788
Validation loss: 2.5531801878174027

Epoch: 5| Step: 1
Training loss: 0.21922826425484515
Validation loss: 2.5094993881984795

Epoch: 5| Step: 2
Training loss: 0.2667253507301298
Validation loss: 2.506861577498353

Epoch: 5| Step: 3
Training loss: 0.47225397504221034
Validation loss: 2.5148808178494098

Epoch: 5| Step: 4
Training loss: 0.33829286920974544
Validation loss: 2.543053092709002

Epoch: 5| Step: 5
Training loss: 0.4377942798534454
Validation loss: 2.573079754710391

Epoch: 5| Step: 6
Training loss: 0.3828744059740839
Validation loss: 2.5848556876411024

Epoch: 5| Step: 7
Training loss: 0.4118436526176765
Validation loss: 2.617947939879092

Epoch: 5| Step: 8
Training loss: 0.24689684119365002
Validation loss: 2.603459711078074

Epoch: 5| Step: 9
Training loss: 0.41100800493199563
Validation loss: 2.5796899087614555

Epoch: 5| Step: 10
Training loss: 0.4028790995525076
Validation loss: 2.563731625135618

Epoch: 413| Step: 0
Training loss: 0.2654821628911482
Validation loss: 2.5206304722960757

Epoch: 5| Step: 1
Training loss: 0.4212027597964586
Validation loss: 2.5415730559164773

Epoch: 5| Step: 2
Training loss: 0.1615485751830658
Validation loss: 2.514264006037209

Epoch: 5| Step: 3
Training loss: 0.40494389751766235
Validation loss: 2.5126555867519738

Epoch: 5| Step: 4
Training loss: 0.39848779847049454
Validation loss: 2.555927853694579

Epoch: 5| Step: 5
Training loss: 0.3976019157057458
Validation loss: 2.598462246944773

Epoch: 5| Step: 6
Training loss: 0.2511580141553046
Validation loss: 2.6109753096079165

Epoch: 5| Step: 7
Training loss: 0.3860420896147325
Validation loss: 2.6163418623962524

Epoch: 5| Step: 8
Training loss: 0.3552746504835799
Validation loss: 2.6069962503832094

Epoch: 5| Step: 9
Training loss: 0.5102705811326645
Validation loss: 2.5876775120203583

Epoch: 5| Step: 10
Training loss: 0.20769921994152343
Validation loss: 2.568813643607586

Epoch: 414| Step: 0
Training loss: 0.42034791137822564
Validation loss: 2.5372094608402644

Epoch: 5| Step: 1
Training loss: 0.4371437938730905
Validation loss: 2.5467912962296126

Epoch: 5| Step: 2
Training loss: 0.3133888002939619
Validation loss: 2.568838731860829

Epoch: 5| Step: 3
Training loss: 0.256004554385785
Validation loss: 2.53711112915323

Epoch: 5| Step: 4
Training loss: 0.4775319947263828
Validation loss: 2.5606579626519763

Epoch: 5| Step: 5
Training loss: 0.19891041849447602
Validation loss: 2.5617275229217893

Epoch: 5| Step: 6
Training loss: 0.09053905065695902
Validation loss: 2.5780658256474225

Epoch: 5| Step: 7
Training loss: 0.32787888242987634
Validation loss: 2.558862328665943

Epoch: 5| Step: 8
Training loss: 0.30484914159968324
Validation loss: 2.571313569268783

Epoch: 5| Step: 9
Training loss: 0.42795776386512174
Validation loss: 2.588204942538939

Epoch: 5| Step: 10
Training loss: 0.3614932945705919
Validation loss: 2.581015874849044

Epoch: 415| Step: 0
Training loss: 0.2764924914442531
Validation loss: 2.554365378802142

Epoch: 5| Step: 1
Training loss: 0.3292351969271054
Validation loss: 2.5353894747307626

Epoch: 5| Step: 2
Training loss: 0.18427239448277088
Validation loss: 2.5286652415233797

Epoch: 5| Step: 3
Training loss: 0.4431310897806844
Validation loss: 2.5063476751728944

Epoch: 5| Step: 4
Training loss: 0.30239107909863544
Validation loss: 2.5168397386211114

Epoch: 5| Step: 5
Training loss: 0.35793532299953684
Validation loss: 2.511561167611742

Epoch: 5| Step: 6
Training loss: 0.32157420343764365
Validation loss: 2.4949283285399555

Epoch: 5| Step: 7
Training loss: 0.4178442725096361
Validation loss: 2.5476386584155235

Epoch: 5| Step: 8
Training loss: 0.30962847816044503
Validation loss: 2.5321238235089822

Epoch: 5| Step: 9
Training loss: 0.39020215990743556
Validation loss: 2.5234367482102873

Epoch: 5| Step: 10
Training loss: 0.3209544355275537
Validation loss: 2.534266221474137

Epoch: 416| Step: 0
Training loss: 0.2337502099102526
Validation loss: 2.539864038204116

Epoch: 5| Step: 1
Training loss: 0.36617492498711024
Validation loss: 2.568441418674318

Epoch: 5| Step: 2
Training loss: 0.2990819812675718
Validation loss: 2.5522102838365774

Epoch: 5| Step: 3
Training loss: 0.3398187891245028
Validation loss: 2.551947016504394

Epoch: 5| Step: 4
Training loss: 0.37466085515798225
Validation loss: 2.535217760702069

Epoch: 5| Step: 5
Training loss: 0.17904415229679993
Validation loss: 2.529155285286236

Epoch: 5| Step: 6
Training loss: 0.2667577656220643
Validation loss: 2.517552263194565

Epoch: 5| Step: 7
Training loss: 0.23298710925334862
Validation loss: 2.4949979385768435

Epoch: 5| Step: 8
Training loss: 0.2859189532992849
Validation loss: 2.5115082806867357

Epoch: 5| Step: 9
Training loss: 0.35902779848888605
Validation loss: 2.492686921605083

Epoch: 5| Step: 10
Training loss: 0.5888554206545524
Validation loss: 2.5009355291780393

Epoch: 417| Step: 0
Training loss: 0.5263977891169009
Validation loss: 2.502169248350383

Epoch: 5| Step: 1
Training loss: 0.24819901073625225
Validation loss: 2.5006355441740618

Epoch: 5| Step: 2
Training loss: 0.3782423436334822
Validation loss: 2.5208320858358295

Epoch: 5| Step: 3
Training loss: 0.19474169290696874
Validation loss: 2.5194861038282887

Epoch: 5| Step: 4
Training loss: 0.3322680134062916
Validation loss: 2.524365849331157

Epoch: 5| Step: 5
Training loss: 0.24099547303467092
Validation loss: 2.5374772053083743

Epoch: 5| Step: 6
Training loss: 0.3426299813843336
Validation loss: 2.5432986731015412

Epoch: 5| Step: 7
Training loss: 0.2123587903498958
Validation loss: 2.5528576484671484

Epoch: 5| Step: 8
Training loss: 0.09810958069179677
Validation loss: 2.5483333082352075

Epoch: 5| Step: 9
Training loss: 0.17679281573117345
Validation loss: 2.538115981809472

Epoch: 5| Step: 10
Training loss: 0.5391733636052017
Validation loss: 2.5350113458879706

Epoch: 418| Step: 0
Training loss: 0.30868497538301737
Validation loss: 2.5412288166249506

Epoch: 5| Step: 1
Training loss: 0.3597187181475581
Validation loss: 2.5378094384109113

Epoch: 5| Step: 2
Training loss: 0.306154363646833
Validation loss: 2.526879421836141

Epoch: 5| Step: 3
Training loss: 0.32038977318933975
Validation loss: 2.5442167635678183

Epoch: 5| Step: 4
Training loss: 0.18694497453750772
Validation loss: 2.5179123148121394

Epoch: 5| Step: 5
Training loss: 0.48219403589433535
Validation loss: 2.520073100690192

Epoch: 5| Step: 6
Training loss: 0.2592013403925191
Validation loss: 2.5141598977609245

Epoch: 5| Step: 7
Training loss: 0.35637057840393427
Validation loss: 2.5239143912759583

Epoch: 5| Step: 8
Training loss: 0.3708238724598253
Validation loss: 2.503861437448645

Epoch: 5| Step: 9
Training loss: 0.31934489666331345
Validation loss: 2.5397015066459177

Epoch: 5| Step: 10
Training loss: 0.24600776805184948
Validation loss: 2.5285667600628923

Epoch: 419| Step: 0
Training loss: 0.5279256083125881
Validation loss: 2.553740688561561

Epoch: 5| Step: 1
Training loss: 0.3452943766917105
Validation loss: 2.560663902555888

Epoch: 5| Step: 2
Training loss: 0.2749756059881144
Validation loss: 2.572115916301496

Epoch: 5| Step: 3
Training loss: 0.31338648229697513
Validation loss: 2.57792867520208

Epoch: 5| Step: 4
Training loss: 0.35403381221334673
Validation loss: 2.566532824328969

Epoch: 5| Step: 5
Training loss: 0.18384548946649007
Validation loss: 2.5520928636129776

Epoch: 5| Step: 6
Training loss: 0.3308417499085789
Validation loss: 2.5587038538905382

Epoch: 5| Step: 7
Training loss: 0.19580638430372016
Validation loss: 2.545435753649617

Epoch: 5| Step: 8
Training loss: 0.43098038455178045
Validation loss: 2.5248462581462334

Epoch: 5| Step: 9
Training loss: 0.2335318818340945
Validation loss: 2.5180567851970257

Epoch: 5| Step: 10
Training loss: 0.1893204883452939
Validation loss: 2.5061786778020005

Epoch: 420| Step: 0
Training loss: 0.4780319104546374
Validation loss: 2.5036771997577674

Epoch: 5| Step: 1
Training loss: 0.36910592778943335
Validation loss: 2.5023271066417343

Epoch: 5| Step: 2
Training loss: 0.14238193155861265
Validation loss: 2.5202905717565898

Epoch: 5| Step: 3
Training loss: 0.3324612469784329
Validation loss: 2.53535030326437

Epoch: 5| Step: 4
Training loss: 0.22181269986629215
Validation loss: 2.5464998164298174

Epoch: 5| Step: 5
Training loss: 0.459920585789922
Validation loss: 2.525825331549434

Epoch: 5| Step: 6
Training loss: 0.3687160815787312
Validation loss: 2.544572339995664

Epoch: 5| Step: 7
Training loss: 0.15856836096953564
Validation loss: 2.567677742771833

Epoch: 5| Step: 8
Training loss: 0.32796163125056665
Validation loss: 2.559844033978171

Epoch: 5| Step: 9
Training loss: 0.21055825898034325
Validation loss: 2.579492542743427

Epoch: 5| Step: 10
Training loss: 0.1984347549759243
Validation loss: 2.5811046238110733

Epoch: 421| Step: 0
Training loss: 0.2902737576653988
Validation loss: 2.555776291234655

Epoch: 5| Step: 1
Training loss: 0.36135451761717846
Validation loss: 2.576273340522098

Epoch: 5| Step: 2
Training loss: 0.19123382976836692
Validation loss: 2.572081621449349

Epoch: 5| Step: 3
Training loss: 0.23258564892978045
Validation loss: 2.570488424620644

Epoch: 5| Step: 4
Training loss: 0.33851506299857653
Validation loss: 2.5370868043153627

Epoch: 5| Step: 5
Training loss: 0.45436483975244374
Validation loss: 2.5483603153506373

Epoch: 5| Step: 6
Training loss: 0.44482184031548894
Validation loss: 2.5144631692552872

Epoch: 5| Step: 7
Training loss: 0.4193198390619216
Validation loss: 2.5336808585063535

Epoch: 5| Step: 8
Training loss: 0.19680821860445577
Validation loss: 2.520360229187534

Epoch: 5| Step: 9
Training loss: 0.2329380330611123
Validation loss: 2.5186120313470086

Epoch: 5| Step: 10
Training loss: 0.21849872428283754
Validation loss: 2.5150571505907338

Epoch: 422| Step: 0
Training loss: 0.20121670195746869
Validation loss: 2.5389438926438586

Epoch: 5| Step: 1
Training loss: 0.3179439689671021
Validation loss: 2.541168045633457

Epoch: 5| Step: 2
Training loss: 0.4538137528791366
Validation loss: 2.5383928868344556

Epoch: 5| Step: 3
Training loss: 0.15408663973575498
Validation loss: 2.53971618870409

Epoch: 5| Step: 4
Training loss: 0.3458065589437194
Validation loss: 2.5284717291574967

Epoch: 5| Step: 5
Training loss: 0.3249098409711283
Validation loss: 2.5329936083964766

Epoch: 5| Step: 6
Training loss: 0.31702105519394624
Validation loss: 2.474615764903467

Epoch: 5| Step: 7
Training loss: 0.45084785617252243
Validation loss: 2.524991972025274

Epoch: 5| Step: 8
Training loss: 0.2823886603824931
Validation loss: 2.480877662693707

Epoch: 5| Step: 9
Training loss: 0.29612685348136797
Validation loss: 2.487555227430781

Epoch: 5| Step: 10
Training loss: 0.23483007279528093
Validation loss: 2.506324260283445

Epoch: 423| Step: 0
Training loss: 0.09951810301571772
Validation loss: 2.519015360827745

Epoch: 5| Step: 1
Training loss: 0.3161245316373373
Validation loss: 2.5450564621732013

Epoch: 5| Step: 2
Training loss: 0.3684713361376139
Validation loss: 2.5425556053225917

Epoch: 5| Step: 3
Training loss: 0.3639659172269499
Validation loss: 2.543203376168721

Epoch: 5| Step: 4
Training loss: 0.39797438091462606
Validation loss: 2.602418891059156

Epoch: 5| Step: 5
Training loss: 0.19055772047470476
Validation loss: 2.5504158214423596

Epoch: 5| Step: 6
Training loss: 0.3034403291485915
Validation loss: 2.5716978144335627

Epoch: 5| Step: 7
Training loss: 0.18700375054418114
Validation loss: 2.551979281472626

Epoch: 5| Step: 8
Training loss: 0.41796386573290684
Validation loss: 2.5405793062069213

Epoch: 5| Step: 9
Training loss: 0.48311811854308967
Validation loss: 2.511796550527874

Epoch: 5| Step: 10
Training loss: 0.2861094156014924
Validation loss: 2.525636896590594

Epoch: 424| Step: 0
Training loss: 0.4655082825170732
Validation loss: 2.4729862920478727

Epoch: 5| Step: 1
Training loss: 0.3476408408532636
Validation loss: 2.4952634775058127

Epoch: 5| Step: 2
Training loss: 0.43232445037194495
Validation loss: 2.534153400276663

Epoch: 5| Step: 3
Training loss: 0.3279380947214517
Validation loss: 2.554941812535019

Epoch: 5| Step: 4
Training loss: 0.33673497844629763
Validation loss: 2.55818909744903

Epoch: 5| Step: 5
Training loss: 0.29802144943319403
Validation loss: 2.5768147320722505

Epoch: 5| Step: 6
Training loss: 0.2055718246796932
Validation loss: 2.578242327424637

Epoch: 5| Step: 7
Training loss: 0.3025040150013391
Validation loss: 2.568958758681941

Epoch: 5| Step: 8
Training loss: 0.18870471328960195
Validation loss: 2.541994267059825

Epoch: 5| Step: 9
Training loss: 0.31727497322834464
Validation loss: 2.543906855261509

Epoch: 5| Step: 10
Training loss: 0.22079537582023476
Validation loss: 2.539867715304911

Epoch: 425| Step: 0
Training loss: 0.3146211400376866
Validation loss: 2.5692953154228686

Epoch: 5| Step: 1
Training loss: 0.3666588244177508
Validation loss: 2.5691460084048856

Epoch: 5| Step: 2
Training loss: 0.44318505780051887
Validation loss: 2.580450687143615

Epoch: 5| Step: 3
Training loss: 0.5175360320626814
Validation loss: 2.509736956367238

Epoch: 5| Step: 4
Training loss: 0.49985874684175
Validation loss: 2.5430202426935815

Epoch: 5| Step: 5
Training loss: 0.34637709830910596
Validation loss: 2.532335193327595

Epoch: 5| Step: 6
Training loss: 0.26589797523024594
Validation loss: 2.530139510872803

Epoch: 5| Step: 7
Training loss: 0.3205035849227906
Validation loss: 2.5180276291096133

Epoch: 5| Step: 8
Training loss: 0.27188866515182447
Validation loss: 2.5337316111202557

Epoch: 5| Step: 9
Training loss: 0.2534213497693382
Validation loss: 2.5630565692173324

Epoch: 5| Step: 10
Training loss: 0.2577581637372628
Validation loss: 2.51013828947255

Epoch: 426| Step: 0
Training loss: 0.31881765133873197
Validation loss: 2.5178178414251846

Epoch: 5| Step: 1
Training loss: 0.2764673489612408
Validation loss: 2.525531289888053

Epoch: 5| Step: 2
Training loss: 0.25896453666366714
Validation loss: 2.513904037645987

Epoch: 5| Step: 3
Training loss: 0.3951336633299103
Validation loss: 2.5271426163927138

Epoch: 5| Step: 4
Training loss: 0.3426732843481475
Validation loss: 2.5700525643037553

Epoch: 5| Step: 5
Training loss: 0.37158377568039735
Validation loss: 2.553108720211273

Epoch: 5| Step: 6
Training loss: 0.20614104246734677
Validation loss: 2.555535459134751

Epoch: 5| Step: 7
Training loss: 0.328336499942397
Validation loss: 2.5657839517970027

Epoch: 5| Step: 8
Training loss: 0.4789970934088806
Validation loss: 2.607188920752623

Epoch: 5| Step: 9
Training loss: 0.5822055734807274
Validation loss: 2.6059804559856734

Epoch: 5| Step: 10
Training loss: 0.49320791823778504
Validation loss: 2.570404854484301

Epoch: 427| Step: 0
Training loss: 0.3529359585785952
Validation loss: 2.5494426379563286

Epoch: 5| Step: 1
Training loss: 0.30258722728430626
Validation loss: 2.568230754517494

Epoch: 5| Step: 2
Training loss: 0.4102077270175269
Validation loss: 2.559879360050623

Epoch: 5| Step: 3
Training loss: 0.23310522391886132
Validation loss: 2.5566643777467424

Epoch: 5| Step: 4
Training loss: 0.3158018438238901
Validation loss: 2.559526858138708

Epoch: 5| Step: 5
Training loss: 0.45300760063738127
Validation loss: 2.551038489423523

Epoch: 5| Step: 6
Training loss: 0.4120334356406971
Validation loss: 2.558238498022539

Epoch: 5| Step: 7
Training loss: 0.41967514241446174
Validation loss: 2.5559139578508994

Epoch: 5| Step: 8
Training loss: 0.21083414229952746
Validation loss: 2.515792569511986

Epoch: 5| Step: 9
Training loss: 0.35199666235571425
Validation loss: 2.4949398159058154

Epoch: 5| Step: 10
Training loss: 0.46699692018951444
Validation loss: 2.5123804276902395

Epoch: 428| Step: 0
Training loss: 0.2852952827239118
Validation loss: 2.494404446599203

Epoch: 5| Step: 1
Training loss: 0.32659778084976304
Validation loss: 2.480702891533405

Epoch: 5| Step: 2
Training loss: 0.30515187894676166
Validation loss: 2.509492088016334

Epoch: 5| Step: 3
Training loss: 0.35134594923615503
Validation loss: 2.5090724348647466

Epoch: 5| Step: 4
Training loss: 0.3421413538574394
Validation loss: 2.5425468392094492

Epoch: 5| Step: 5
Training loss: 0.3126579004956194
Validation loss: 2.5513600951756357

Epoch: 5| Step: 6
Training loss: 0.26216895254957007
Validation loss: 2.5700635074105644

Epoch: 5| Step: 7
Training loss: 0.3005299819113519
Validation loss: 2.5461489288387527

Epoch: 5| Step: 8
Training loss: 0.3584645597492157
Validation loss: 2.5266471582815417

Epoch: 5| Step: 9
Training loss: 0.41311288299335025
Validation loss: 2.547354160825355

Epoch: 5| Step: 10
Training loss: 0.5126481679403134
Validation loss: 2.5392373261320045

Epoch: 429| Step: 0
Training loss: 0.16830033464163333
Validation loss: 2.568517368322725

Epoch: 5| Step: 1
Training loss: 0.31249279967595966
Validation loss: 2.5212457418326757

Epoch: 5| Step: 2
Training loss: 0.3156747486074529
Validation loss: 2.4871134912369453

Epoch: 5| Step: 3
Training loss: 0.275473048002973
Validation loss: 2.5314625709409757

Epoch: 5| Step: 4
Training loss: 0.3732904168492786
Validation loss: 2.5105200451657543

Epoch: 5| Step: 5
Training loss: 0.5008875003641912
Validation loss: 2.5494857151653334

Epoch: 5| Step: 6
Training loss: 0.42237379468941744
Validation loss: 2.5565034397456907

Epoch: 5| Step: 7
Training loss: 0.2339135554771194
Validation loss: 2.5356482089090466

Epoch: 5| Step: 8
Training loss: 0.2837062444433979
Validation loss: 2.547047193322863

Epoch: 5| Step: 9
Training loss: 0.2613637993928906
Validation loss: 2.5480326232316903

Epoch: 5| Step: 10
Training loss: 0.29658529300547826
Validation loss: 2.5751367726785683

Epoch: 430| Step: 0
Training loss: 0.4039588657839281
Validation loss: 2.589181885515968

Epoch: 5| Step: 1
Training loss: 0.45060259751440224
Validation loss: 2.6173996333848133

Epoch: 5| Step: 2
Training loss: 0.2804033994913477
Validation loss: 2.600453337011367

Epoch: 5| Step: 3
Training loss: 0.4142167146072255
Validation loss: 2.5884525243035035

Epoch: 5| Step: 4
Training loss: 0.1509940316184406
Validation loss: 2.591228524146633

Epoch: 5| Step: 5
Training loss: 0.39298767817814845
Validation loss: 2.562502879279455

Epoch: 5| Step: 6
Training loss: 0.1724557925501267
Validation loss: 2.5648947390038335

Epoch: 5| Step: 7
Training loss: 0.42522565657175687
Validation loss: 2.542788496188583

Epoch: 5| Step: 8
Training loss: 0.2713966365071323
Validation loss: 2.5452761462800177

Epoch: 5| Step: 9
Training loss: 0.2636127405612587
Validation loss: 2.5224924535477986

Epoch: 5| Step: 10
Training loss: 0.31641763501818243
Validation loss: 2.537798916369417

Epoch: 431| Step: 0
Training loss: 0.30179255017078355
Validation loss: 2.555104018794006

Epoch: 5| Step: 1
Training loss: 0.2953442208344167
Validation loss: 2.5875586061328715

Epoch: 5| Step: 2
Training loss: 0.46564651541956986
Validation loss: 2.5908296514713647

Epoch: 5| Step: 3
Training loss: 0.3480390198888296
Validation loss: 2.553931554518762

Epoch: 5| Step: 4
Training loss: 0.37929526740223574
Validation loss: 2.6045015404440006

Epoch: 5| Step: 5
Training loss: 0.2866275013300025
Validation loss: 2.547816553646755

Epoch: 5| Step: 6
Training loss: 0.24221202510819276
Validation loss: 2.5870470616476298

Epoch: 5| Step: 7
Training loss: 0.39752320497785393
Validation loss: 2.551066098995847

Epoch: 5| Step: 8
Training loss: 0.24740204385022677
Validation loss: 2.558188341842133

Epoch: 5| Step: 9
Training loss: 0.22299742910534692
Validation loss: 2.5715633664600195

Epoch: 5| Step: 10
Training loss: 0.2553135385807349
Validation loss: 2.5531202605953545

Epoch: 432| Step: 0
Training loss: 0.26501896387748364
Validation loss: 2.566544841743274

Epoch: 5| Step: 1
Training loss: 0.39204885380167137
Validation loss: 2.5683549721003724

Epoch: 5| Step: 2
Training loss: 0.18771284658599802
Validation loss: 2.5719793282169343

Epoch: 5| Step: 3
Training loss: 0.2709454875811397
Validation loss: 2.577918886240597

Epoch: 5| Step: 4
Training loss: 0.18640337570097595
Validation loss: 2.572690167038801

Epoch: 5| Step: 5
Training loss: 0.3667095807639462
Validation loss: 2.5646281140688596

Epoch: 5| Step: 6
Training loss: 0.4113930356648598
Validation loss: 2.553698196117395

Epoch: 5| Step: 7
Training loss: 0.1666522106716178
Validation loss: 2.5791025803612317

Epoch: 5| Step: 8
Training loss: 0.3853517318702012
Validation loss: 2.5509139501982467

Epoch: 5| Step: 9
Training loss: 0.23555625624819246
Validation loss: 2.6036962255687093

Epoch: 5| Step: 10
Training loss: 0.37768641485941795
Validation loss: 2.584587381927602

Epoch: 433| Step: 0
Training loss: 0.1829728829057972
Validation loss: 2.585935977243485

Epoch: 5| Step: 1
Training loss: 0.2946758507239338
Validation loss: 2.550301110627987

Epoch: 5| Step: 2
Training loss: 0.39851316967648825
Validation loss: 2.5809230979715263

Epoch: 5| Step: 3
Training loss: 0.29360742253924205
Validation loss: 2.54651048826079

Epoch: 5| Step: 4
Training loss: 0.24567207661818002
Validation loss: 2.561608914666837

Epoch: 5| Step: 5
Training loss: 0.29942231537057395
Validation loss: 2.5828902727664445

Epoch: 5| Step: 6
Training loss: 0.18793658251612969
Validation loss: 2.557897462704825

Epoch: 5| Step: 7
Training loss: 0.276697709281457
Validation loss: 2.5731903471325492

Epoch: 5| Step: 8
Training loss: 0.3828439310366276
Validation loss: 2.594023223493869

Epoch: 5| Step: 9
Training loss: 0.4452155660233075
Validation loss: 2.6086014491449063

Epoch: 5| Step: 10
Training loss: 0.2704705305608345
Validation loss: 2.6056140855987064

Epoch: 434| Step: 0
Training loss: 0.3092808136957642
Validation loss: 2.6262944072761885

Epoch: 5| Step: 1
Training loss: 0.2794219717225998
Validation loss: 2.5943354234943055

Epoch: 5| Step: 2
Training loss: 0.5082163158818904
Validation loss: 2.601051064241274

Epoch: 5| Step: 3
Training loss: 0.21417969467995168
Validation loss: 2.585800180636045

Epoch: 5| Step: 4
Training loss: 0.23888687651517274
Validation loss: 2.5975801308552913

Epoch: 5| Step: 5
Training loss: 0.19741277588442357
Validation loss: 2.5985049525245043

Epoch: 5| Step: 6
Training loss: 0.20464549980523444
Validation loss: 2.5911646546642704

Epoch: 5| Step: 7
Training loss: 0.35803278842677744
Validation loss: 2.612851797656393

Epoch: 5| Step: 8
Training loss: 0.22118779362639907
Validation loss: 2.5750473630591197

Epoch: 5| Step: 9
Training loss: 0.33710136183036726
Validation loss: 2.587499040172768

Epoch: 5| Step: 10
Training loss: 0.28103779363590986
Validation loss: 2.587512183570643

Epoch: 435| Step: 0
Training loss: 0.3659199894039172
Validation loss: 2.5610335315983193

Epoch: 5| Step: 1
Training loss: 0.36958290529423427
Validation loss: 2.5830218722462495

Epoch: 5| Step: 2
Training loss: 0.2203460606924672
Validation loss: 2.5588552264184004

Epoch: 5| Step: 3
Training loss: 0.15839761388073023
Validation loss: 2.53934861709566

Epoch: 5| Step: 4
Training loss: 0.1894326936382034
Validation loss: 2.529836950725457

Epoch: 5| Step: 5
Training loss: 0.38183355696538546
Validation loss: 2.5717748102896674

Epoch: 5| Step: 6
Training loss: 0.2056067692144879
Validation loss: 2.5582618315851433

Epoch: 5| Step: 7
Training loss: 0.2840323049614044
Validation loss: 2.549469819348674

Epoch: 5| Step: 8
Training loss: 0.22781066074858577
Validation loss: 2.5737355283317886

Epoch: 5| Step: 9
Training loss: 0.4180821238260691
Validation loss: 2.604404154787683

Epoch: 5| Step: 10
Training loss: 0.40011581666460755
Validation loss: 2.636571637314393

Epoch: 436| Step: 0
Training loss: 0.36825252856327195
Validation loss: 2.602711926781462

Epoch: 5| Step: 1
Training loss: 0.08532928224004836
Validation loss: 2.55996121834309

Epoch: 5| Step: 2
Training loss: 0.23699906373945637
Validation loss: 2.5507514905519764

Epoch: 5| Step: 3
Training loss: 0.24552468702399075
Validation loss: 2.5343332182535465

Epoch: 5| Step: 4
Training loss: 0.2669038700461704
Validation loss: 2.5465829232452295

Epoch: 5| Step: 5
Training loss: 0.14271881399744185
Validation loss: 2.579662887779705

Epoch: 5| Step: 6
Training loss: 0.3256185601086362
Validation loss: 2.560984281540218

Epoch: 5| Step: 7
Training loss: 0.19155843679092271
Validation loss: 2.545631406550758

Epoch: 5| Step: 8
Training loss: 0.540006778021059
Validation loss: 2.586976744687746

Epoch: 5| Step: 9
Training loss: 0.2855635960349784
Validation loss: 2.591101606789995

Epoch: 5| Step: 10
Training loss: 0.3620078626642905
Validation loss: 2.600404764036809

Epoch: 437| Step: 0
Training loss: 0.2728312720343435
Validation loss: 2.577283361038465

Epoch: 5| Step: 1
Training loss: 0.2500074802710104
Validation loss: 2.586530842830063

Epoch: 5| Step: 2
Training loss: 0.31111039908905713
Validation loss: 2.54691334397425

Epoch: 5| Step: 3
Training loss: 0.21630454651639264
Validation loss: 2.5617141193843826

Epoch: 5| Step: 4
Training loss: 0.44304962092776107
Validation loss: 2.5594454892778615

Epoch: 5| Step: 5
Training loss: 0.31432208298406944
Validation loss: 2.559806678885315

Epoch: 5| Step: 6
Training loss: 0.4038505117300026
Validation loss: 2.5288791570180575

Epoch: 5| Step: 7
Training loss: 0.08762329559872475
Validation loss: 2.5589808147711954

Epoch: 5| Step: 8
Training loss: 0.368098488388958
Validation loss: 2.5624329562937223

Epoch: 5| Step: 9
Training loss: 0.17466809887536222
Validation loss: 2.5929885420619048

Epoch: 5| Step: 10
Training loss: 0.15036989663684733
Validation loss: 2.59178359877721

Epoch: 438| Step: 0
Training loss: 0.2013590969232667
Validation loss: 2.5989912203909897

Epoch: 5| Step: 1
Training loss: 0.302492106311046
Validation loss: 2.6301634009897357

Epoch: 5| Step: 2
Training loss: 0.19703896408347824
Validation loss: 2.6340133120917786

Epoch: 5| Step: 3
Training loss: 0.4145176383385198
Validation loss: 2.599554876059171

Epoch: 5| Step: 4
Training loss: 0.18919982888005324
Validation loss: 2.569790339743389

Epoch: 5| Step: 5
Training loss: 0.3358814059598875
Validation loss: 2.5605042171663053

Epoch: 5| Step: 6
Training loss: 0.41171307062216694
Validation loss: 2.5700918327884907

Epoch: 5| Step: 7
Training loss: 0.198176199167078
Validation loss: 2.5102650906356927

Epoch: 5| Step: 8
Training loss: 0.36566147337050775
Validation loss: 2.527912913223149

Epoch: 5| Step: 9
Training loss: 0.1888451603823068
Validation loss: 2.5363923405957562

Epoch: 5| Step: 10
Training loss: 0.28600654810631937
Validation loss: 2.5238405951673397

Epoch: 439| Step: 0
Training loss: 0.2830773699192859
Validation loss: 2.5300165997492843

Epoch: 5| Step: 1
Training loss: 0.32498669734653085
Validation loss: 2.529674425547185

Epoch: 5| Step: 2
Training loss: 0.22535533595715598
Validation loss: 2.557745425596774

Epoch: 5| Step: 3
Training loss: 0.36769215419429674
Validation loss: 2.551265133524564

Epoch: 5| Step: 4
Training loss: 0.366103296354886
Validation loss: 2.5686909722035023

Epoch: 5| Step: 5
Training loss: 0.1693506395058148
Validation loss: 2.5556931648846732

Epoch: 5| Step: 6
Training loss: 0.2731326720166256
Validation loss: 2.5934017148697963

Epoch: 5| Step: 7
Training loss: 0.39172163570818624
Validation loss: 2.5798181735708847

Epoch: 5| Step: 8
Training loss: 0.280585205319339
Validation loss: 2.607040205154881

Epoch: 5| Step: 9
Training loss: 0.20400460235345463
Validation loss: 2.6079804941740505

Epoch: 5| Step: 10
Training loss: 0.12731199892579373
Validation loss: 2.562808286629088

Epoch: 440| Step: 0
Training loss: 0.24796394403580133
Validation loss: 2.597812961881739

Epoch: 5| Step: 1
Training loss: 0.37933525889102926
Validation loss: 2.5601179344769305

Epoch: 5| Step: 2
Training loss: 0.15983566903264662
Validation loss: 2.558744602536022

Epoch: 5| Step: 3
Training loss: 0.23627122871954032
Validation loss: 2.5976612733429527

Epoch: 5| Step: 4
Training loss: 0.30946124348612436
Validation loss: 2.554350623374513

Epoch: 5| Step: 5
Training loss: 0.23751735968891424
Validation loss: 2.58162194949755

Epoch: 5| Step: 6
Training loss: 0.4495755312964153
Validation loss: 2.5745956058155692

Epoch: 5| Step: 7
Training loss: 0.3955247475094933
Validation loss: 2.595188108387594

Epoch: 5| Step: 8
Training loss: 0.3464201156910836
Validation loss: 2.5861014349597564

Epoch: 5| Step: 9
Training loss: 0.15015101852393878
Validation loss: 2.546860968196749

Epoch: 5| Step: 10
Training loss: 0.2120538066203025
Validation loss: 2.5637688185457344

Epoch: 441| Step: 0
Training loss: 0.3010580226168503
Validation loss: 2.5782959504439504

Epoch: 5| Step: 1
Training loss: 0.19227132132352517
Validation loss: 2.5930620188651683

Epoch: 5| Step: 2
Training loss: 0.3182910073479039
Validation loss: 2.5600998335405145

Epoch: 5| Step: 3
Training loss: 0.23770229169493523
Validation loss: 2.581639905491754

Epoch: 5| Step: 4
Training loss: 0.13706877724153824
Validation loss: 2.5764445934290596

Epoch: 5| Step: 5
Training loss: 0.15873551562643223
Validation loss: 2.563132535398951

Epoch: 5| Step: 6
Training loss: 0.26480867665627683
Validation loss: 2.5745030038505994

Epoch: 5| Step: 7
Training loss: 0.19914247885342856
Validation loss: 2.576255794422961

Epoch: 5| Step: 8
Training loss: 0.5762169254600346
Validation loss: 2.555468048122593

Epoch: 5| Step: 9
Training loss: 0.33059739569101504
Validation loss: 2.5055574246334333

Epoch: 5| Step: 10
Training loss: 0.2893746726608897
Validation loss: 2.5481799766169506

Epoch: 442| Step: 0
Training loss: 0.33240221281434024
Validation loss: 2.526200122047684

Epoch: 5| Step: 1
Training loss: 0.28208316473108286
Validation loss: 2.537170662535554

Epoch: 5| Step: 2
Training loss: 0.16838388928331177
Validation loss: 2.560575601505742

Epoch: 5| Step: 3
Training loss: 0.5025630762832007
Validation loss: 2.5663401304760316

Epoch: 5| Step: 4
Training loss: 0.24657242255799072
Validation loss: 2.577033913866096

Epoch: 5| Step: 5
Training loss: 0.28963209428935616
Validation loss: 2.5680797304729475

Epoch: 5| Step: 6
Training loss: 0.1505497796254048
Validation loss: 2.592412589720685

Epoch: 5| Step: 7
Training loss: 0.23921917973236215
Validation loss: 2.5997325863426286

Epoch: 5| Step: 8
Training loss: 0.3283041283444067
Validation loss: 2.601302275089642

Epoch: 5| Step: 9
Training loss: 0.16547113212441317
Validation loss: 2.5908261624720157

Epoch: 5| Step: 10
Training loss: 0.34689790546981336
Validation loss: 2.580891379600737

Epoch: 443| Step: 0
Training loss: 0.42579563361554545
Validation loss: 2.5608635125590453

Epoch: 5| Step: 1
Training loss: 0.1774384896726779
Validation loss: 2.543842134754504

Epoch: 5| Step: 2
Training loss: 0.357860608593986
Validation loss: 2.510656375407489

Epoch: 5| Step: 3
Training loss: 0.2419916022095826
Validation loss: 2.5323334955954784

Epoch: 5| Step: 4
Training loss: 0.39052731246165906
Validation loss: 2.5292217352912307

Epoch: 5| Step: 5
Training loss: 0.24135775866090436
Validation loss: 2.5368113958799263

Epoch: 5| Step: 6
Training loss: 0.32158581094058414
Validation loss: 2.569392413412849

Epoch: 5| Step: 7
Training loss: 0.1213296008588312
Validation loss: 2.5516656345856625

Epoch: 5| Step: 8
Training loss: 0.2780452372799366
Validation loss: 2.592964384003395

Epoch: 5| Step: 9
Training loss: 0.29550535071155004
Validation loss: 2.6195418622573765

Epoch: 5| Step: 10
Training loss: 0.3078049828245632
Validation loss: 2.600985026065745

Epoch: 444| Step: 0
Training loss: 0.27087655395040955
Validation loss: 2.6131301297371348

Epoch: 5| Step: 1
Training loss: 0.14351084422422336
Validation loss: 2.608311730818614

Epoch: 5| Step: 2
Training loss: 0.39073679277989465
Validation loss: 2.5583116801884316

Epoch: 5| Step: 3
Training loss: 0.4497819604072269
Validation loss: 2.5464435521222657

Epoch: 5| Step: 4
Training loss: 0.34880345973931426
Validation loss: 2.521166319191156

Epoch: 5| Step: 5
Training loss: 0.19422581682061674
Validation loss: 2.5368399530802206

Epoch: 5| Step: 6
Training loss: 0.272506149533204
Validation loss: 2.4767239373951218

Epoch: 5| Step: 7
Training loss: 0.2509485073216978
Validation loss: 2.528357739879065

Epoch: 5| Step: 8
Training loss: 0.2410824700001742
Validation loss: 2.5798541333986247

Epoch: 5| Step: 9
Training loss: 0.21826789727736
Validation loss: 2.580339233533531

Epoch: 5| Step: 10
Training loss: 0.2620172648601774
Validation loss: 2.596324065926076

Epoch: 445| Step: 0
Training loss: 0.24150534666798773
Validation loss: 2.630600540580337

Epoch: 5| Step: 1
Training loss: 0.36071118447212963
Validation loss: 2.623992970426278

Epoch: 5| Step: 2
Training loss: 0.29280698760878443
Validation loss: 2.621290014062106

Epoch: 5| Step: 3
Training loss: 0.23979926830680023
Validation loss: 2.6281760076353917

Epoch: 5| Step: 4
Training loss: 0.4530639278427781
Validation loss: 2.596833742479682

Epoch: 5| Step: 5
Training loss: 0.24466388322901772
Validation loss: 2.5770505722830763

Epoch: 5| Step: 6
Training loss: 0.23083202374312908
Validation loss: 2.5677822712839853

Epoch: 5| Step: 7
Training loss: 0.16812061497312494
Validation loss: 2.552782900980351

Epoch: 5| Step: 8
Training loss: 0.3494014334701923
Validation loss: 2.5811954060286593

Epoch: 5| Step: 9
Training loss: 0.15825688072849645
Validation loss: 2.548837765684979

Epoch: 5| Step: 10
Training loss: 0.22114832881795854
Validation loss: 2.5643414599578693

Epoch: 446| Step: 0
Training loss: 0.22816620709300053
Validation loss: 2.5908186663271695

Epoch: 5| Step: 1
Training loss: 0.17069967973492742
Validation loss: 2.6106445808014818

Epoch: 5| Step: 2
Training loss: 0.37213154286458766
Validation loss: 2.5817027693550654

Epoch: 5| Step: 3
Training loss: 0.22884536656068277
Validation loss: 2.550077625012451

Epoch: 5| Step: 4
Training loss: 0.3736141146314983
Validation loss: 2.5782319236601023

Epoch: 5| Step: 5
Training loss: 0.24855068435574731
Validation loss: 2.5491070876461874

Epoch: 5| Step: 6
Training loss: 0.25758439868324934
Validation loss: 2.5611053200987715

Epoch: 5| Step: 7
Training loss: 0.3695535923209935
Validation loss: 2.5301058629478765

Epoch: 5| Step: 8
Training loss: 0.23254130204267906
Validation loss: 2.5468835287620064

Epoch: 5| Step: 9
Training loss: 0.36942226020435687
Validation loss: 2.532355246626461

Epoch: 5| Step: 10
Training loss: 0.2209739289608128
Validation loss: 2.5610651290367294

Epoch: 447| Step: 0
Training loss: 0.43324939697364534
Validation loss: 2.595451541120346

Epoch: 5| Step: 1
Training loss: 0.2588352665950779
Validation loss: 2.594033567878139

Epoch: 5| Step: 2
Training loss: 0.19694506215982213
Validation loss: 2.5834435556207254

Epoch: 5| Step: 3
Training loss: 0.2088821553306516
Validation loss: 2.609235025274052

Epoch: 5| Step: 4
Training loss: 0.24801769235110185
Validation loss: 2.5918928214333277

Epoch: 5| Step: 5
Training loss: 0.21215751832208418
Validation loss: 2.541883896760795

Epoch: 5| Step: 6
Training loss: 0.22436149021216648
Validation loss: 2.5103685546915915

Epoch: 5| Step: 7
Training loss: 0.2277516857392602
Validation loss: 2.526129794489051

Epoch: 5| Step: 8
Training loss: 0.26707925723224246
Validation loss: 2.498748815372135

Epoch: 5| Step: 9
Training loss: 0.3659076299293555
Validation loss: 2.50311201071036

Epoch: 5| Step: 10
Training loss: 0.48057674341802853
Validation loss: 2.5107090658502065

Epoch: 448| Step: 0
Training loss: 0.36952637392984466
Validation loss: 2.543652834838894

Epoch: 5| Step: 1
Training loss: 0.2582486682379285
Validation loss: 2.5330451161279157

Epoch: 5| Step: 2
Training loss: 0.2867427743102795
Validation loss: 2.54812464180974

Epoch: 5| Step: 3
Training loss: 0.14322254136685778
Validation loss: 2.5668988632479603

Epoch: 5| Step: 4
Training loss: 0.28048326035051185
Validation loss: 2.58634912887564

Epoch: 5| Step: 5
Training loss: 0.3727596035672595
Validation loss: 2.6040957028144054

Epoch: 5| Step: 6
Training loss: 0.3403747838230126
Validation loss: 2.6213942783193254

Epoch: 5| Step: 7
Training loss: 0.35996225308174246
Validation loss: 2.633054987754442

Epoch: 5| Step: 8
Training loss: 0.23902741062473642
Validation loss: 2.5693397011360637

Epoch: 5| Step: 9
Training loss: 0.17005193599813329
Validation loss: 2.577703589301036

Epoch: 5| Step: 10
Training loss: 0.21937009930910417
Validation loss: 2.5912214265159395

Epoch: 449| Step: 0
Training loss: 0.18635541528106145
Validation loss: 2.578399010220624

Epoch: 5| Step: 1
Training loss: 0.46616262977501527
Validation loss: 2.600976717088623

Epoch: 5| Step: 2
Training loss: 0.3971508981991115
Validation loss: 2.527097946041016

Epoch: 5| Step: 3
Training loss: 0.26212008151659405
Validation loss: 2.5438125924346657

Epoch: 5| Step: 4
Training loss: 0.3090509576831095
Validation loss: 2.5389691594260126

Epoch: 5| Step: 5
Training loss: 0.17608743068996724
Validation loss: 2.577958548036584

Epoch: 5| Step: 6
Training loss: 0.19694252748285784
Validation loss: 2.5643861843414064

Epoch: 5| Step: 7
Training loss: 0.12755989909289034
Validation loss: 2.5909754668608915

Epoch: 5| Step: 8
Training loss: 0.28453886791758964
Validation loss: 2.6028962893652707

Epoch: 5| Step: 9
Training loss: 0.3835817315730276
Validation loss: 2.6023552075603598

Epoch: 5| Step: 10
Training loss: 0.12584096427014815
Validation loss: 2.577209670631835

Epoch: 450| Step: 0
Training loss: 0.3858312769513021
Validation loss: 2.6226113453621234

Epoch: 5| Step: 1
Training loss: 0.16741250775148575
Validation loss: 2.5814931625710997

Epoch: 5| Step: 2
Training loss: 0.18218309143582134
Validation loss: 2.56029403140382

Epoch: 5| Step: 3
Training loss: 0.36979929374387027
Validation loss: 2.5777830332769773

Epoch: 5| Step: 4
Training loss: 0.2765381489825469
Validation loss: 2.597622299250039

Epoch: 5| Step: 5
Training loss: 0.25704693557973207
Validation loss: 2.601298140821543

Epoch: 5| Step: 6
Training loss: 0.23041268652800428
Validation loss: 2.5833509234869223

Epoch: 5| Step: 7
Training loss: 0.28754190056686346
Validation loss: 2.580562912812135

Epoch: 5| Step: 8
Training loss: 0.37027978470907
Validation loss: 2.6044060683599506

Epoch: 5| Step: 9
Training loss: 0.3301064067213654
Validation loss: 2.626676735894868

Epoch: 5| Step: 10
Training loss: 0.16577405183177513
Validation loss: 2.61250690298949

Epoch: 451| Step: 0
Training loss: 0.22285294628465924
Validation loss: 2.6195372312345304

Epoch: 5| Step: 1
Training loss: 0.39116229299089317
Validation loss: 2.5902788914651853

Epoch: 5| Step: 2
Training loss: 0.31725380256228697
Validation loss: 2.5306059112707

Epoch: 5| Step: 3
Training loss: 0.17466140714270864
Validation loss: 2.533888320600769

Epoch: 5| Step: 4
Training loss: 0.34721197179393015
Validation loss: 2.5167027715407397

Epoch: 5| Step: 5
Training loss: 0.22032267770187186
Validation loss: 2.541761075476565

Epoch: 5| Step: 6
Training loss: 0.22738552234098536
Validation loss: 2.561671295345442

Epoch: 5| Step: 7
Training loss: 0.1521206530468677
Validation loss: 2.550802042210743

Epoch: 5| Step: 8
Training loss: 0.27078841215898447
Validation loss: 2.5800768839569894

Epoch: 5| Step: 9
Training loss: 0.34597049223273635
Validation loss: 2.580624152842758

Epoch: 5| Step: 10
Training loss: 0.29629228523528506
Validation loss: 2.589308351431611

Epoch: 452| Step: 0
Training loss: 0.15018891766133463
Validation loss: 2.6145261258122976

Epoch: 5| Step: 1
Training loss: 0.19223336161058227
Validation loss: 2.6014429959416363

Epoch: 5| Step: 2
Training loss: 0.23923409792091938
Validation loss: 2.60499913714593

Epoch: 5| Step: 3
Training loss: 0.16827258641177273
Validation loss: 2.6009510418858874

Epoch: 5| Step: 4
Training loss: 0.15939458137719892
Validation loss: 2.6104651886516255

Epoch: 5| Step: 5
Training loss: 0.3791970385798975
Validation loss: 2.5912347056190255

Epoch: 5| Step: 6
Training loss: 0.3631027972907083
Validation loss: 2.5900771339464272

Epoch: 5| Step: 7
Training loss: 0.37657810986087004
Validation loss: 2.589708038522531

Epoch: 5| Step: 8
Training loss: 0.2956315401172422
Validation loss: 2.582316420431585

Epoch: 5| Step: 9
Training loss: 0.3081383544008776
Validation loss: 2.5863611335115704

Epoch: 5| Step: 10
Training loss: 0.152146333770507
Validation loss: 2.582888083206284

Epoch: 453| Step: 0
Training loss: 0.12636699352220035
Validation loss: 2.5917701929082138

Epoch: 5| Step: 1
Training loss: 0.15818150690512986
Validation loss: 2.5994953246281214

Epoch: 5| Step: 2
Training loss: 0.20783916316680143
Validation loss: 2.5824789760813767

Epoch: 5| Step: 3
Training loss: 0.1881936375976837
Validation loss: 2.6069345412491267

Epoch: 5| Step: 4
Training loss: 0.32502987522582333
Validation loss: 2.579484657488652

Epoch: 5| Step: 5
Training loss: 0.09958256566411502
Validation loss: 2.5382835552624874

Epoch: 5| Step: 6
Training loss: 0.21398178931878412
Validation loss: 2.5606495929005098

Epoch: 5| Step: 7
Training loss: 0.4244504130947544
Validation loss: 2.5648251600968255

Epoch: 5| Step: 8
Training loss: 0.3833237756525842
Validation loss: 2.54506172884661

Epoch: 5| Step: 9
Training loss: 0.22263976922862305
Validation loss: 2.5177898392584517

Epoch: 5| Step: 10
Training loss: 0.4332131786228959
Validation loss: 2.5391058391346206

Epoch: 454| Step: 0
Training loss: 0.32064931885102527
Validation loss: 2.548853720762492

Epoch: 5| Step: 1
Training loss: 0.23176044626570252
Validation loss: 2.5309372433597503

Epoch: 5| Step: 2
Training loss: 0.2545320135705781
Validation loss: 2.503940424048329

Epoch: 5| Step: 3
Training loss: 0.17270417044683906
Validation loss: 2.544975036615352

Epoch: 5| Step: 4
Training loss: 0.3157991778509782
Validation loss: 2.5324152678933762

Epoch: 5| Step: 5
Training loss: 0.12779017113479146
Validation loss: 2.57828821664335

Epoch: 5| Step: 6
Training loss: 0.3463922948095403
Validation loss: 2.561762653897512

Epoch: 5| Step: 7
Training loss: 0.22564734411686274
Validation loss: 2.525296242050877

Epoch: 5| Step: 8
Training loss: 0.34342556511826294
Validation loss: 2.5160007633098056

Epoch: 5| Step: 9
Training loss: 0.10721226963471228
Validation loss: 2.549596721674878

Epoch: 5| Step: 10
Training loss: 0.3645496988676421
Validation loss: 2.5284129090684475

Epoch: 455| Step: 0
Training loss: 0.18296478970848815
Validation loss: 2.546526289797346

Epoch: 5| Step: 1
Training loss: 0.22701350080362873
Validation loss: 2.554157887702186

Epoch: 5| Step: 2
Training loss: 0.3929005906924659
Validation loss: 2.563295171473791

Epoch: 5| Step: 3
Training loss: 0.10810319541463724
Validation loss: 2.5650958602285225

Epoch: 5| Step: 4
Training loss: 0.2582107704404205
Validation loss: 2.573632169247095

Epoch: 5| Step: 5
Training loss: 0.18768373070589453
Validation loss: 2.593617213112261

Epoch: 5| Step: 6
Training loss: 0.28134336511318037
Validation loss: 2.5743258856972044

Epoch: 5| Step: 7
Training loss: 0.34133778939739345
Validation loss: 2.5997832130991587

Epoch: 5| Step: 8
Training loss: 0.2902812781242023
Validation loss: 2.5722619374037197

Epoch: 5| Step: 9
Training loss: 0.21055573779191636
Validation loss: 2.5886100617557513

Epoch: 5| Step: 10
Training loss: 0.34710294648441725
Validation loss: 2.5930353003583955

Epoch: 456| Step: 0
Training loss: 0.3113460932850875
Validation loss: 2.6009278438970447

Epoch: 5| Step: 1
Training loss: 0.39814380966618906
Validation loss: 2.564903778565847

Epoch: 5| Step: 2
Training loss: 0.19471167657671573
Validation loss: 2.575838015189044

Epoch: 5| Step: 3
Training loss: 0.21865905846818473
Validation loss: 2.593322144361987

Epoch: 5| Step: 4
Training loss: 0.32528043898606784
Validation loss: 2.5942810850197415

Epoch: 5| Step: 5
Training loss: 0.36869419693995814
Validation loss: 2.580884537631236

Epoch: 5| Step: 6
Training loss: 0.16517387053435653
Validation loss: 2.6053911829038356

Epoch: 5| Step: 7
Training loss: 0.24303976965155777
Validation loss: 2.5829472984428663

Epoch: 5| Step: 8
Training loss: 0.16551130774136055
Validation loss: 2.5958707165179637

Epoch: 5| Step: 9
Training loss: 0.13588954967745728
Validation loss: 2.5789024038595825

Epoch: 5| Step: 10
Training loss: 0.20844334241008194
Validation loss: 2.561197261375534

Epoch: 457| Step: 0
Training loss: 0.14688925420297796
Validation loss: 2.568720161534749

Epoch: 5| Step: 1
Training loss: 0.42194779085977097
Validation loss: 2.5416597708842716

Epoch: 5| Step: 2
Training loss: 0.2588485793285279
Validation loss: 2.5222214118150066

Epoch: 5| Step: 3
Training loss: 0.3707892925742141
Validation loss: 2.561496506117097

Epoch: 5| Step: 4
Training loss: 0.21550811868507216
Validation loss: 2.5541909432595347

Epoch: 5| Step: 5
Training loss: 0.22577476030150517
Validation loss: 2.5116654213707914

Epoch: 5| Step: 6
Training loss: 0.1962499911769938
Validation loss: 2.5623068988113906

Epoch: 5| Step: 7
Training loss: 0.18428206768763356
Validation loss: 2.5748651562994596

Epoch: 5| Step: 8
Training loss: 0.3022048996074995
Validation loss: 2.589788196216411

Epoch: 5| Step: 9
Training loss: 0.12677149617965586
Validation loss: 2.5568492802410545

Epoch: 5| Step: 10
Training loss: 0.276915528579686
Validation loss: 2.603725943075435

Epoch: 458| Step: 0
Training loss: 0.2273665826349877
Validation loss: 2.602125265693169

Epoch: 5| Step: 1
Training loss: 0.1870784789760436
Validation loss: 2.5785133663443824

Epoch: 5| Step: 2
Training loss: 0.3759709939915857
Validation loss: 2.580937226685635

Epoch: 5| Step: 3
Training loss: 0.18003229563455272
Validation loss: 2.5537195940144897

Epoch: 5| Step: 4
Training loss: 0.28228803974838695
Validation loss: 2.5486007622340145

Epoch: 5| Step: 5
Training loss: 0.22763575189975088
Validation loss: 2.5450230578028292

Epoch: 5| Step: 6
Training loss: 0.4069992638611756
Validation loss: 2.524758336156112

Epoch: 5| Step: 7
Training loss: 0.2637393723737655
Validation loss: 2.533781664586458

Epoch: 5| Step: 8
Training loss: 0.3754405374520001
Validation loss: 2.556671692641824

Epoch: 5| Step: 9
Training loss: 0.2046146696409945
Validation loss: 2.548547375479001

Epoch: 5| Step: 10
Training loss: 0.13470871041429303
Validation loss: 2.5438845066341735

Epoch: 459| Step: 0
Training loss: 0.15236229661384496
Validation loss: 2.547890208221843

Epoch: 5| Step: 1
Training loss: 0.18465896778169275
Validation loss: 2.541689005376513

Epoch: 5| Step: 2
Training loss: 0.3530842061237198
Validation loss: 2.5222708002794474

Epoch: 5| Step: 3
Training loss: 0.25386560554909565
Validation loss: 2.551416913722385

Epoch: 5| Step: 4
Training loss: 0.16514000260546835
Validation loss: 2.534453283016643

Epoch: 5| Step: 5
Training loss: 0.1089771690515857
Validation loss: 2.5567875599946275

Epoch: 5| Step: 6
Training loss: 0.46816980695005145
Validation loss: 2.5536038846190525

Epoch: 5| Step: 7
Training loss: 0.16155440346188196
Validation loss: 2.5502506555961886

Epoch: 5| Step: 8
Training loss: 0.3964988818591829
Validation loss: 2.553337215730786

Epoch: 5| Step: 9
Training loss: 0.24469539934076825
Validation loss: 2.6074287210752294

Epoch: 5| Step: 10
Training loss: 0.20622885154901463
Validation loss: 2.6335877160004153

Epoch: 460| Step: 0
Training loss: 0.19719043091713215
Validation loss: 2.6213705165146446

Epoch: 5| Step: 1
Training loss: 0.2985967850144115
Validation loss: 2.624937770670378

Epoch: 5| Step: 2
Training loss: 0.20683589751591716
Validation loss: 2.6527837722697134

Epoch: 5| Step: 3
Training loss: 0.27028900551538315
Validation loss: 2.6000908283392605

Epoch: 5| Step: 4
Training loss: 0.21589460863362803
Validation loss: 2.616771157357798

Epoch: 5| Step: 5
Training loss: 0.20985713433182943
Validation loss: 2.6180036197702727

Epoch: 5| Step: 6
Training loss: 0.17912251340573662
Validation loss: 2.6114140934194325

Epoch: 5| Step: 7
Training loss: 0.30503138673816604
Validation loss: 2.597464731012065

Epoch: 5| Step: 8
Training loss: 0.2725072431695361
Validation loss: 2.594266130214881

Epoch: 5| Step: 9
Training loss: 0.3414706717145832
Validation loss: 2.5807726835588913

Epoch: 5| Step: 10
Training loss: 0.24420323141365288
Validation loss: 2.5779991688478585

Epoch: 461| Step: 0
Training loss: 0.22734356123139715
Validation loss: 2.5676880737322803

Epoch: 5| Step: 1
Training loss: 0.41764510628290064
Validation loss: 2.5577424958580304

Epoch: 5| Step: 2
Training loss: 0.3214113878016578
Validation loss: 2.563302791489303

Epoch: 5| Step: 3
Training loss: 0.1780822409789851
Validation loss: 2.5716465081688793

Epoch: 5| Step: 4
Training loss: 0.27711388639397255
Validation loss: 2.6012078879637173

Epoch: 5| Step: 5
Training loss: 0.15253562947804816
Validation loss: 2.605220174679899

Epoch: 5| Step: 6
Training loss: 0.3564816600086725
Validation loss: 2.591570655567155

Epoch: 5| Step: 7
Training loss: 0.14341468211920894
Validation loss: 2.5757866430942897

Epoch: 5| Step: 8
Training loss: 0.18851622722480532
Validation loss: 2.5631748394343474

Epoch: 5| Step: 9
Training loss: 0.1562320281660424
Validation loss: 2.532672351301579

Epoch: 5| Step: 10
Training loss: 0.18917761758022034
Validation loss: 2.5365897011953367

Epoch: 462| Step: 0
Training loss: 0.25560044152012
Validation loss: 2.4841419187252582

Epoch: 5| Step: 1
Training loss: 0.2668689742066895
Validation loss: 2.477547439845007

Epoch: 5| Step: 2
Training loss: 0.3885501306684051
Validation loss: 2.4969304016013187

Epoch: 5| Step: 3
Training loss: 0.2103846333610603
Validation loss: 2.4915133310926065

Epoch: 5| Step: 4
Training loss: 0.1366005863725335
Validation loss: 2.529518774569731

Epoch: 5| Step: 5
Training loss: 0.3083291911585834
Validation loss: 2.5383103304572723

Epoch: 5| Step: 6
Training loss: 0.13636613059201158
Validation loss: 2.55797459032909

Epoch: 5| Step: 7
Training loss: 0.21124245534211356
Validation loss: 2.584439517817136

Epoch: 5| Step: 8
Training loss: 0.08563143239607102
Validation loss: 2.604465912063793

Epoch: 5| Step: 9
Training loss: 0.13465457293611877
Validation loss: 2.6003102664467224

Epoch: 5| Step: 10
Training loss: 0.42782349724912205
Validation loss: 2.5807759179424274

Epoch: 463| Step: 0
Training loss: 0.09009580396513313
Validation loss: 2.630763029374962

Epoch: 5| Step: 1
Training loss: 0.18524450460254716
Validation loss: 2.6255353078063934

Epoch: 5| Step: 2
Training loss: 0.22095942174022518
Validation loss: 2.5824118693221028

Epoch: 5| Step: 3
Training loss: 0.1995744521614611
Validation loss: 2.575359459412474

Epoch: 5| Step: 4
Training loss: 0.34413591310217595
Validation loss: 2.5926567241550087

Epoch: 5| Step: 5
Training loss: 0.2107615796943229
Validation loss: 2.5709786298569686

Epoch: 5| Step: 6
Training loss: 0.25638999952558134
Validation loss: 2.5731627976081155

Epoch: 5| Step: 7
Training loss: 0.29497125982652883
Validation loss: 2.574744149255038

Epoch: 5| Step: 8
Training loss: 0.43378703646334854
Validation loss: 2.5359460355827452

Epoch: 5| Step: 9
Training loss: 0.2314472842233103
Validation loss: 2.5458729625689704

Epoch: 5| Step: 10
Training loss: 0.23094059440077921
Validation loss: 2.5409534132046594

Epoch: 464| Step: 0
Training loss: 0.22879850371024066
Validation loss: 2.5571360107859045

Epoch: 5| Step: 1
Training loss: 0.15589738038272644
Validation loss: 2.5433733737475066

Epoch: 5| Step: 2
Training loss: 0.23102907182287674
Validation loss: 2.5567298220003325

Epoch: 5| Step: 3
Training loss: 0.3282575453125644
Validation loss: 2.5785633707605804

Epoch: 5| Step: 4
Training loss: 0.16264949006756477
Validation loss: 2.5934500819246376

Epoch: 5| Step: 5
Training loss: 0.093570393137958
Validation loss: 2.5651316071878973

Epoch: 5| Step: 6
Training loss: 0.273248961707583
Validation loss: 2.5849394124211447

Epoch: 5| Step: 7
Training loss: 0.41082667100016723
Validation loss: 2.583474966295584

Epoch: 5| Step: 8
Training loss: 0.20692090026607451
Validation loss: 2.5983291236850548

Epoch: 5| Step: 9
Training loss: 0.182925855917008
Validation loss: 2.5929481699141044

Epoch: 5| Step: 10
Training loss: 0.2990831396500506
Validation loss: 2.583636378899871

Epoch: 465| Step: 0
Training loss: 0.247577696595524
Validation loss: 2.5753910896304073

Epoch: 5| Step: 1
Training loss: 0.23179093641613763
Validation loss: 2.56701665783215

Epoch: 5| Step: 2
Training loss: 0.25248151272427843
Validation loss: 2.5569443062137545

Epoch: 5| Step: 3
Training loss: 0.22318653904941127
Validation loss: 2.5557089577951886

Epoch: 5| Step: 4
Training loss: 0.2946682780723038
Validation loss: 2.5333919883742446

Epoch: 5| Step: 5
Training loss: 0.3308726797840378
Validation loss: 2.532471180301691

Epoch: 5| Step: 6
Training loss: 0.3583908911801862
Validation loss: 2.553049258742859

Epoch: 5| Step: 7
Training loss: 0.1609729494014745
Validation loss: 2.5474824194271477

Epoch: 5| Step: 8
Training loss: 0.21015662898770446
Validation loss: 2.580006344237258

Epoch: 5| Step: 9
Training loss: 0.21844646989362906
Validation loss: 2.564633960310303

Epoch: 5| Step: 10
Training loss: 0.19136478987104982
Validation loss: 2.572801519053105

Epoch: 466| Step: 0
Training loss: 0.2875866329237247
Validation loss: 2.5666519511674233

Epoch: 5| Step: 1
Training loss: 0.2488186611369989
Validation loss: 2.538982101442254

Epoch: 5| Step: 2
Training loss: 0.2066276232517708
Validation loss: 2.5319423592059493

Epoch: 5| Step: 3
Training loss: 0.38399585462235053
Validation loss: 2.552567601586626

Epoch: 5| Step: 4
Training loss: 0.2802357930811407
Validation loss: 2.5461057740305004

Epoch: 5| Step: 5
Training loss: 0.21753368951234886
Validation loss: 2.5550449413926253

Epoch: 5| Step: 6
Training loss: 0.16372608138436612
Validation loss: 2.580224410874078

Epoch: 5| Step: 7
Training loss: 0.2243369814213943
Validation loss: 2.575268088455897

Epoch: 5| Step: 8
Training loss: 0.1778223113619762
Validation loss: 2.596955055886524

Epoch: 5| Step: 9
Training loss: 0.2509271298423681
Validation loss: 2.5855235131598433

Epoch: 5| Step: 10
Training loss: 0.163566816931121
Validation loss: 2.5683085171066096

Epoch: 467| Step: 0
Training loss: 0.16400735927561502
Validation loss: 2.6187748231092387

Epoch: 5| Step: 1
Training loss: 0.10018777744596287
Validation loss: 2.5712281963669383

Epoch: 5| Step: 2
Training loss: 0.10258359396214745
Validation loss: 2.5631472402712063

Epoch: 5| Step: 3
Training loss: 0.2958661304122689
Validation loss: 2.5811776155389827

Epoch: 5| Step: 4
Training loss: 0.18347961855303166
Validation loss: 2.5780303723919955

Epoch: 5| Step: 5
Training loss: 0.21828638914498757
Validation loss: 2.589836724795384

Epoch: 5| Step: 6
Training loss: 0.34096785141892294
Validation loss: 2.577352149051818

Epoch: 5| Step: 7
Training loss: 0.42159207004933164
Validation loss: 2.566841243831138

Epoch: 5| Step: 8
Training loss: 0.1863185896123018
Validation loss: 2.566134399854003

Epoch: 5| Step: 9
Training loss: 0.2820638960016193
Validation loss: 2.549627261795208

Epoch: 5| Step: 10
Training loss: 0.29272420213430805
Validation loss: 2.5737309702760727

Epoch: 468| Step: 0
Training loss: 0.1891896982515811
Validation loss: 2.558009890104063

Epoch: 5| Step: 1
Training loss: 0.2947895182518915
Validation loss: 2.5531945383317804

Epoch: 5| Step: 2
Training loss: 0.11739090909026069
Validation loss: 2.5832470807678884

Epoch: 5| Step: 3
Training loss: 0.1663622659213665
Validation loss: 2.5615349990220824

Epoch: 5| Step: 4
Training loss: 0.20624524385574863
Validation loss: 2.5751504622538373

Epoch: 5| Step: 5
Training loss: 0.14535815588193746
Validation loss: 2.5685582572149936

Epoch: 5| Step: 6
Training loss: 0.38226009917655557
Validation loss: 2.5802770657176954

Epoch: 5| Step: 7
Training loss: 0.2511504791544164
Validation loss: 2.59221454375746

Epoch: 5| Step: 8
Training loss: 0.3600052821248688
Validation loss: 2.5959576471524657

Epoch: 5| Step: 9
Training loss: 0.2803904724333256
Validation loss: 2.5788051271182244

Epoch: 5| Step: 10
Training loss: 0.16727847382693087
Validation loss: 2.6095541026217157

Epoch: 469| Step: 0
Training loss: 0.2736530544246457
Validation loss: 2.597965003715031

Epoch: 5| Step: 1
Training loss: 0.32139575195599956
Validation loss: 2.582750662259976

Epoch: 5| Step: 2
Training loss: 0.301674210902363
Validation loss: 2.5916821059296096

Epoch: 5| Step: 3
Training loss: 0.23165652138521609
Validation loss: 2.5630252138819936

Epoch: 5| Step: 4
Training loss: 0.3855621690431789
Validation loss: 2.5834809167512947

Epoch: 5| Step: 5
Training loss: 0.2440037610758859
Validation loss: 2.604023103427925

Epoch: 5| Step: 6
Training loss: 0.1191807429199098
Validation loss: 2.6090148879680783

Epoch: 5| Step: 7
Training loss: 0.17806181247012068
Validation loss: 2.6117808673484317

Epoch: 5| Step: 8
Training loss: 0.13438376630976065
Validation loss: 2.6029744276843005

Epoch: 5| Step: 9
Training loss: 0.20928448670658223
Validation loss: 2.6133431957752316

Epoch: 5| Step: 10
Training loss: 0.16320317445957863
Validation loss: 2.597820545780124

Epoch: 470| Step: 0
Training loss: 0.1645110787056867
Validation loss: 2.5893821247360984

Epoch: 5| Step: 1
Training loss: 0.3830305568355473
Validation loss: 2.608651330840589

Epoch: 5| Step: 2
Training loss: 0.22317786771146078
Validation loss: 2.634196036248982

Epoch: 5| Step: 3
Training loss: 0.15625929804793315
Validation loss: 2.6006995615163193

Epoch: 5| Step: 4
Training loss: 0.07833859927002829
Validation loss: 2.6314005814236063

Epoch: 5| Step: 5
Training loss: 0.25033908438510466
Validation loss: 2.621636191588389

Epoch: 5| Step: 6
Training loss: 0.29060190990972923
Validation loss: 2.6441472680357343

Epoch: 5| Step: 7
Training loss: 0.2973928201971496
Validation loss: 2.629825153703244

Epoch: 5| Step: 8
Training loss: 0.31584440197249397
Validation loss: 2.5618596911451474

Epoch: 5| Step: 9
Training loss: 0.1430122676656593
Validation loss: 2.6079228465791444

Epoch: 5| Step: 10
Training loss: 0.13242332857172512
Validation loss: 2.5818189561281346

Epoch: 471| Step: 0
Training loss: 0.1398254419841564
Validation loss: 2.577125774809366

Epoch: 5| Step: 1
Training loss: 0.2545738247366731
Validation loss: 2.593649414381492

Epoch: 5| Step: 2
Training loss: 0.3021316558182087
Validation loss: 2.595217512381321

Epoch: 5| Step: 3
Training loss: 0.44431970587626235
Validation loss: 2.5906846962146446

Epoch: 5| Step: 4
Training loss: 0.2124009844857055
Validation loss: 2.5780463034214907

Epoch: 5| Step: 5
Training loss: 0.1801362446565003
Validation loss: 2.5919129732740314

Epoch: 5| Step: 6
Training loss: 0.1321048678052811
Validation loss: 2.6055842538483085

Epoch: 5| Step: 7
Training loss: 0.2222224325975442
Validation loss: 2.579394258585543

Epoch: 5| Step: 8
Training loss: 0.11169513639569732
Validation loss: 2.5788429282376955

Epoch: 5| Step: 9
Training loss: 0.23107719924393613
Validation loss: 2.5478908179679127

Epoch: 5| Step: 10
Training loss: 0.24105779906375546
Validation loss: 2.5860631302720742

Epoch: 472| Step: 0
Training loss: 0.1744672352473804
Validation loss: 2.554055737820994

Epoch: 5| Step: 1
Training loss: 0.2680582347520759
Validation loss: 2.5546154503648557

Epoch: 5| Step: 2
Training loss: 0.24104818652777832
Validation loss: 2.5503746562568517

Epoch: 5| Step: 3
Training loss: 0.1144318396464297
Validation loss: 2.6054165786912105

Epoch: 5| Step: 4
Training loss: 0.13799138399754204
Validation loss: 2.5981540150899867

Epoch: 5| Step: 5
Training loss: 0.12656739396181724
Validation loss: 2.600813112554839

Epoch: 5| Step: 6
Training loss: 0.2677178957575865
Validation loss: 2.5849242424090213

Epoch: 5| Step: 7
Training loss: 0.23352964854957906
Validation loss: 2.577502344339533

Epoch: 5| Step: 8
Training loss: 0.4464599148782667
Validation loss: 2.5961092318091055

Epoch: 5| Step: 9
Training loss: 0.10847371726448032
Validation loss: 2.57303721050174

Epoch: 5| Step: 10
Training loss: 0.2674492852987887
Validation loss: 2.5538217041372664

Epoch: 473| Step: 0
Training loss: 0.16979291560487944
Validation loss: 2.5398152946666537

Epoch: 5| Step: 1
Training loss: 0.2223674088582094
Validation loss: 2.5633874852515

Epoch: 5| Step: 2
Training loss: 0.1371341525346864
Validation loss: 2.5515107182766914

Epoch: 5| Step: 3
Training loss: 0.14053565737035378
Validation loss: 2.5593757361848306

Epoch: 5| Step: 4
Training loss: 0.3852666507058592
Validation loss: 2.586560455255923

Epoch: 5| Step: 5
Training loss: 0.3717966349761887
Validation loss: 2.554365280446288

Epoch: 5| Step: 6
Training loss: 0.1030950098067705
Validation loss: 2.560628400086901

Epoch: 5| Step: 7
Training loss: 0.24626751471937378
Validation loss: 2.5787491317315787

Epoch: 5| Step: 8
Training loss: 0.1545404069596247
Validation loss: 2.5721784956531786

Epoch: 5| Step: 9
Training loss: 0.2636029188622589
Validation loss: 2.552115632071082

Epoch: 5| Step: 10
Training loss: 0.1240654183472104
Validation loss: 2.5747151785677556

Epoch: 474| Step: 0
Training loss: 0.3898846476780841
Validation loss: 2.5157856284539313

Epoch: 5| Step: 1
Training loss: 0.10776281870688764
Validation loss: 2.5658130053423305

Epoch: 5| Step: 2
Training loss: 0.1558617895221357
Validation loss: 2.5578256508231196

Epoch: 5| Step: 3
Training loss: 0.1280236081437468
Validation loss: 2.5665160771676936

Epoch: 5| Step: 4
Training loss: 0.19946701811275125
Validation loss: 2.5965314999913423

Epoch: 5| Step: 5
Training loss: 0.3219376947398292
Validation loss: 2.6010118008986334

Epoch: 5| Step: 6
Training loss: 0.08638096849112613
Validation loss: 2.594314372454592

Epoch: 5| Step: 7
Training loss: 0.18824565163120507
Validation loss: 2.6005251852962057

Epoch: 5| Step: 8
Training loss: 0.3532751435127909
Validation loss: 2.588800981124317

Epoch: 5| Step: 9
Training loss: 0.2682540320318263
Validation loss: 2.5840024812540983

Epoch: 5| Step: 10
Training loss: 0.10590638651153825
Validation loss: 2.5716786495944493

Epoch: 475| Step: 0
Training loss: 0.2996067051973718
Validation loss: 2.5717813425551217

Epoch: 5| Step: 1
Training loss: 0.1310923409983012
Validation loss: 2.586593401493644

Epoch: 5| Step: 2
Training loss: 0.3540852630785899
Validation loss: 2.593085472593353

Epoch: 5| Step: 3
Training loss: 0.25688655340010924
Validation loss: 2.5573917879997996

Epoch: 5| Step: 4
Training loss: 0.2617027790263847
Validation loss: 2.589908183610731

Epoch: 5| Step: 5
Training loss: 0.16756331505056102
Validation loss: 2.601558045882295

Epoch: 5| Step: 6
Training loss: 0.21148356645737457
Validation loss: 2.614425598205441

Epoch: 5| Step: 7
Training loss: 0.2786687844471069
Validation loss: 2.5836579277338942

Epoch: 5| Step: 8
Training loss: 0.1170695108253236
Validation loss: 2.5892796080552807

Epoch: 5| Step: 9
Training loss: 0.24105564323091178
Validation loss: 2.560957225362789

Epoch: 5| Step: 10
Training loss: 0.12616307845025101
Validation loss: 2.5275266835072756

Epoch: 476| Step: 0
Training loss: 0.1574987283061171
Validation loss: 2.5050008675661335

Epoch: 5| Step: 1
Training loss: 0.13399539824313256
Validation loss: 2.4831707610967744

Epoch: 5| Step: 2
Training loss: 0.25760024899317424
Validation loss: 2.486844440700843

Epoch: 5| Step: 3
Training loss: 0.4037058836865616
Validation loss: 2.5067912586239993

Epoch: 5| Step: 4
Training loss: 0.17375195902639373
Validation loss: 2.5122233878558236

Epoch: 5| Step: 5
Training loss: 0.25348427259782547
Validation loss: 2.575977908781504

Epoch: 5| Step: 6
Training loss: 0.22170776659890631
Validation loss: 2.599181393993182

Epoch: 5| Step: 7
Training loss: 0.1561376823618307
Validation loss: 2.6330159046882047

Epoch: 5| Step: 8
Training loss: 0.18461904941930893
Validation loss: 2.6073732061922477

Epoch: 5| Step: 9
Training loss: 0.29393105456475865
Validation loss: 2.6069564816333686

Epoch: 5| Step: 10
Training loss: 0.26602336519382686
Validation loss: 2.6500040122783655

Epoch: 477| Step: 0
Training loss: 0.2651573159101436
Validation loss: 2.593187909996279

Epoch: 5| Step: 1
Training loss: 0.09174199695952318
Validation loss: 2.5578772252882582

Epoch: 5| Step: 2
Training loss: 0.2243331288476237
Validation loss: 2.532902899917739

Epoch: 5| Step: 3
Training loss: 0.16508686344038156
Validation loss: 2.5255859285268016

Epoch: 5| Step: 4
Training loss: 0.13581548399703858
Validation loss: 2.519610240881211

Epoch: 5| Step: 5
Training loss: 0.38109317352514077
Validation loss: 2.527648008742444

Epoch: 5| Step: 6
Training loss: 0.1392303758106168
Validation loss: 2.5577939752792966

Epoch: 5| Step: 7
Training loss: 0.37385848269872457
Validation loss: 2.554764802301386

Epoch: 5| Step: 8
Training loss: 0.19750991651531627
Validation loss: 2.6078891327031135

Epoch: 5| Step: 9
Training loss: 0.291485132478677
Validation loss: 2.604060334690713

Epoch: 5| Step: 10
Training loss: 0.1992240979841877
Validation loss: 2.581592319152845

Epoch: 478| Step: 0
Training loss: 0.17885418138372516
Validation loss: 2.6181042557700094

Epoch: 5| Step: 1
Training loss: 0.12134079958462456
Validation loss: 2.5888033954284677

Epoch: 5| Step: 2
Training loss: 0.14300822354059403
Validation loss: 2.5653923068138105

Epoch: 5| Step: 3
Training loss: 0.19569296020485377
Validation loss: 2.5400109495302092

Epoch: 5| Step: 4
Training loss: 0.1768246940407357
Validation loss: 2.5414277046256095

Epoch: 5| Step: 5
Training loss: 0.09975337390912223
Validation loss: 2.543981320883685

Epoch: 5| Step: 6
Training loss: 0.35181081267721587
Validation loss: 2.5354801989001716

Epoch: 5| Step: 7
Training loss: 0.42088687818899967
Validation loss: 2.5204333851926757

Epoch: 5| Step: 8
Training loss: 0.15888436543715398
Validation loss: 2.565246687676006

Epoch: 5| Step: 9
Training loss: 0.30437517052553636
Validation loss: 2.573814150534159

Epoch: 5| Step: 10
Training loss: 0.31751329527449296
Validation loss: 2.577721010676188

Epoch: 479| Step: 0
Training loss: 0.19936276821355461
Validation loss: 2.5858630583637203

Epoch: 5| Step: 1
Training loss: 0.4111884797527135
Validation loss: 2.528123332052389

Epoch: 5| Step: 2
Training loss: 0.25531654431747935
Validation loss: 2.5083257424517655

Epoch: 5| Step: 3
Training loss: 0.21628581631087856
Validation loss: 2.4883751361057334

Epoch: 5| Step: 4
Training loss: 0.24969049756300168
Validation loss: 2.4951205555214995

Epoch: 5| Step: 5
Training loss: 0.12366016004119953
Validation loss: 2.540005488185882

Epoch: 5| Step: 6
Training loss: 0.23870002187280112
Validation loss: 2.5390172093897982

Epoch: 5| Step: 7
Training loss: 0.2409193616439454
Validation loss: 2.5836059044119795

Epoch: 5| Step: 8
Training loss: 0.26892426463135904
Validation loss: 2.6142658694096528

Epoch: 5| Step: 9
Training loss: 0.152661377567868
Validation loss: 2.6514211957932323

Epoch: 5| Step: 10
Training loss: 0.20945797493088655
Validation loss: 2.632838992057393

Epoch: 480| Step: 0
Training loss: 0.20171561413786657
Validation loss: 2.656656684603009

Epoch: 5| Step: 1
Training loss: 0.25120599256918064
Validation loss: 2.6199985620531816

Epoch: 5| Step: 2
Training loss: 0.21210992788450006
Validation loss: 2.581194527792315

Epoch: 5| Step: 3
Training loss: 0.3115308395989166
Validation loss: 2.5883717943674127

Epoch: 5| Step: 4
Training loss: 0.2997491145116916
Validation loss: 2.5407232944148737

Epoch: 5| Step: 5
Training loss: 0.20558595904147764
Validation loss: 2.5148787561352823

Epoch: 5| Step: 6
Training loss: 0.2564739969543482
Validation loss: 2.4846198075573946

Epoch: 5| Step: 7
Training loss: 0.1653843827797247
Validation loss: 2.556310717962793

Epoch: 5| Step: 8
Training loss: 0.358010708578147
Validation loss: 2.595395770542299

Epoch: 5| Step: 9
Training loss: 0.19019385186255605
Validation loss: 2.588045778675339

Epoch: 5| Step: 10
Training loss: 0.24267287991360928
Validation loss: 2.646626532263679

Epoch: 481| Step: 0
Training loss: 0.19871447824541005
Validation loss: 2.6223248964629717

Epoch: 5| Step: 1
Training loss: 0.37450887388021714
Validation loss: 2.6256553898213384

Epoch: 5| Step: 2
Training loss: 0.31767755760636707
Validation loss: 2.5644541376788537

Epoch: 5| Step: 3
Training loss: 0.1933027145907304
Validation loss: 2.518554711929636

Epoch: 5| Step: 4
Training loss: 0.22739518000068654
Validation loss: 2.5276296945521377

Epoch: 5| Step: 5
Training loss: 0.3112277478188014
Validation loss: 2.519806235842394

Epoch: 5| Step: 6
Training loss: 0.22533358045417262
Validation loss: 2.5100174538241213

Epoch: 5| Step: 7
Training loss: 0.19687068230571914
Validation loss: 2.523844235175195

Epoch: 5| Step: 8
Training loss: 0.2029641046058521
Validation loss: 2.5618779307511974

Epoch: 5| Step: 9
Training loss: 0.3275774747267532
Validation loss: 2.6270967363067674

Epoch: 5| Step: 10
Training loss: 0.19601919116975924
Validation loss: 2.6653136222690916

Epoch: 482| Step: 0
Training loss: 0.1867016345523382
Validation loss: 2.654709175934587

Epoch: 5| Step: 1
Training loss: 0.2258891920097174
Validation loss: 2.626071144945996

Epoch: 5| Step: 2
Training loss: 0.2564054006298626
Validation loss: 2.573513549810266

Epoch: 5| Step: 3
Training loss: 0.2620905185744503
Validation loss: 2.560959238469154

Epoch: 5| Step: 4
Training loss: 0.27367605974426573
Validation loss: 2.5142980173821856

Epoch: 5| Step: 5
Training loss: 0.35773662612250073
Validation loss: 2.528500707529011

Epoch: 5| Step: 6
Training loss: 0.3930787647271071
Validation loss: 2.5364282788222754

Epoch: 5| Step: 7
Training loss: 0.1824690886342623
Validation loss: 2.574962527126572

Epoch: 5| Step: 8
Training loss: 0.23829355364443303
Validation loss: 2.5934516052117393

Epoch: 5| Step: 9
Training loss: 0.30312876699014324
Validation loss: 2.651392312124301

Epoch: 5| Step: 10
Training loss: 0.26456331805619315
Validation loss: 2.6505726742460003

Epoch: 483| Step: 0
Training loss: 0.3124744762487682
Validation loss: 2.684647667418521

Epoch: 5| Step: 1
Training loss: 0.3851718791088735
Validation loss: 2.679311730217763

Epoch: 5| Step: 2
Training loss: 0.3228826222880567
Validation loss: 2.6400423814311957

Epoch: 5| Step: 3
Training loss: 0.2519335184674602
Validation loss: 2.5266682774452613

Epoch: 5| Step: 4
Training loss: 0.2543349827868753
Validation loss: 2.509514633108751

Epoch: 5| Step: 5
Training loss: 0.26167981726459133
Validation loss: 2.4531516167810197

Epoch: 5| Step: 6
Training loss: 0.27418013950239445
Validation loss: 2.4684841905444155

Epoch: 5| Step: 7
Training loss: 0.19801526165313846
Validation loss: 2.492037244720063

Epoch: 5| Step: 8
Training loss: 0.17531251931147884
Validation loss: 2.493312111204842

Epoch: 5| Step: 9
Training loss: 0.17239811791080795
Validation loss: 2.5426484447124347

Epoch: 5| Step: 10
Training loss: 0.3268794761847217
Validation loss: 2.5856052045519897

Epoch: 484| Step: 0
Training loss: 0.3292916990984299
Validation loss: 2.6066220750318307

Epoch: 5| Step: 1
Training loss: 0.17059894477235868
Validation loss: 2.6197858043937696

Epoch: 5| Step: 2
Training loss: 0.25660239505385957
Validation loss: 2.6554613350485203

Epoch: 5| Step: 3
Training loss: 0.2776122606730491
Validation loss: 2.622259028401638

Epoch: 5| Step: 4
Training loss: 0.2282089392506754
Validation loss: 2.617829431580081

Epoch: 5| Step: 5
Training loss: 0.16105078140803203
Validation loss: 2.574012413085422

Epoch: 5| Step: 6
Training loss: 0.2500915806638226
Validation loss: 2.5516699838980106

Epoch: 5| Step: 7
Training loss: 0.22278433177623475
Validation loss: 2.5456407592350407

Epoch: 5| Step: 8
Training loss: 0.2348497827025365
Validation loss: 2.522570834924161

Epoch: 5| Step: 9
Training loss: 0.3322313154756334
Validation loss: 2.5117794006513647

Epoch: 5| Step: 10
Training loss: 0.4052124712944403
Validation loss: 2.51728617268894

Epoch: 485| Step: 0
Training loss: 0.19705848393701944
Validation loss: 2.515690274220698

Epoch: 5| Step: 1
Training loss: 0.2124327889907992
Validation loss: 2.518603266381365

Epoch: 5| Step: 2
Training loss: 0.4170610786366892
Validation loss: 2.550174952579088

Epoch: 5| Step: 3
Training loss: 0.28244454964224075
Validation loss: 2.5783084002431647

Epoch: 5| Step: 4
Training loss: 0.17409096894228107
Validation loss: 2.590788416462855

Epoch: 5| Step: 5
Training loss: 0.3056308862396258
Validation loss: 2.62572034180282

Epoch: 5| Step: 6
Training loss: 0.26335908209083675
Validation loss: 2.6107526991880956

Epoch: 5| Step: 7
Training loss: 0.29356138687458777
Validation loss: 2.5677678255807384

Epoch: 5| Step: 8
Training loss: 0.26729935373851804
Validation loss: 2.538845820493332

Epoch: 5| Step: 9
Training loss: 0.13906700630601787
Validation loss: 2.556966634438714

Epoch: 5| Step: 10
Training loss: 0.2520713824337087
Validation loss: 2.5876267435266667

Epoch: 486| Step: 0
Training loss: 0.2963773421135062
Validation loss: 2.593102819298123

Epoch: 5| Step: 1
Training loss: 0.4479973650103377
Validation loss: 2.6026702023452435

Epoch: 5| Step: 2
Training loss: 0.3158640985090886
Validation loss: 2.6192179987755626

Epoch: 5| Step: 3
Training loss: 0.16614851961884056
Validation loss: 2.5768149688554525

Epoch: 5| Step: 4
Training loss: 0.20458132195762654
Validation loss: 2.5742291590290494

Epoch: 5| Step: 5
Training loss: 0.21479476890549845
Validation loss: 2.5913259231646233

Epoch: 5| Step: 6
Training loss: 0.1508072124128134
Validation loss: 2.570451942309653

Epoch: 5| Step: 7
Training loss: 0.23081791016430353
Validation loss: 2.564859718896075

Epoch: 5| Step: 8
Training loss: 0.21898708948799891
Validation loss: 2.5814672752132277

Epoch: 5| Step: 9
Training loss: 0.24143185711200477
Validation loss: 2.557191710004266

Epoch: 5| Step: 10
Training loss: 0.30209870819998147
Validation loss: 2.5700244724105556

Epoch: 487| Step: 0
Training loss: 0.260417064030662
Validation loss: 2.592637550101258

Epoch: 5| Step: 1
Training loss: 0.18017409615904614
Validation loss: 2.5890616703865725

Epoch: 5| Step: 2
Training loss: 0.26395461852619256
Validation loss: 2.607369830770587

Epoch: 5| Step: 3
Training loss: 0.2313184430673847
Validation loss: 2.5966867929187

Epoch: 5| Step: 4
Training loss: 0.18544563743986142
Validation loss: 2.583973336571552

Epoch: 5| Step: 5
Training loss: 0.38118319316932214
Validation loss: 2.578580698836753

Epoch: 5| Step: 6
Training loss: 0.12382951729650589
Validation loss: 2.5598645097197745

Epoch: 5| Step: 7
Training loss: 0.3263735233516008
Validation loss: 2.5587236303977146

Epoch: 5| Step: 8
Training loss: 0.25223764722197756
Validation loss: 2.581417495381066

Epoch: 5| Step: 9
Training loss: 0.14020189902754726
Validation loss: 2.5779988257693622

Epoch: 5| Step: 10
Training loss: 0.20669225613797437
Validation loss: 2.6231215573278925

Epoch: 488| Step: 0
Training loss: 0.2743435290498992
Validation loss: 2.642814885921842

Epoch: 5| Step: 1
Training loss: 0.2213919196003831
Validation loss: 2.639344618246941

Epoch: 5| Step: 2
Training loss: 0.22010978341025783
Validation loss: 2.6360499823924277

Epoch: 5| Step: 3
Training loss: 0.27146215828206
Validation loss: 2.5979773945354374

Epoch: 5| Step: 4
Training loss: 0.20078251018202917
Validation loss: 2.569491393430753

Epoch: 5| Step: 5
Training loss: 0.14300263581731099
Validation loss: 2.564657106237545

Epoch: 5| Step: 6
Training loss: 0.16946662558860054
Validation loss: 2.5419569133880495

Epoch: 5| Step: 7
Training loss: 0.386662411680049
Validation loss: 2.522758990796858

Epoch: 5| Step: 8
Training loss: 0.14995604432318915
Validation loss: 2.526369910590282

Epoch: 5| Step: 9
Training loss: 0.28935927544007145
Validation loss: 2.536532582859762

Epoch: 5| Step: 10
Training loss: 0.1937683865836645
Validation loss: 2.541532764777494

Epoch: 489| Step: 0
Training loss: 0.1468643220104199
Validation loss: 2.562700490364069

Epoch: 5| Step: 1
Training loss: 0.20882009127569948
Validation loss: 2.5558968040929884

Epoch: 5| Step: 2
Training loss: 0.2572728636018975
Validation loss: 2.610351161800924

Epoch: 5| Step: 3
Training loss: 0.3530059850201587
Validation loss: 2.6238704127078925

Epoch: 5| Step: 4
Training loss: 0.22926982089669384
Validation loss: 2.5971328019211493

Epoch: 5| Step: 5
Training loss: 0.17584700414223697
Validation loss: 2.592958826070796

Epoch: 5| Step: 6
Training loss: 0.2897298429667813
Validation loss: 2.5902411721215435

Epoch: 5| Step: 7
Training loss: 0.25023767974700717
Validation loss: 2.554325560429967

Epoch: 5| Step: 8
Training loss: 0.13017495363262854
Validation loss: 2.572741942750126

Epoch: 5| Step: 9
Training loss: 0.16698371017979066
Validation loss: 2.5277052385909085

Epoch: 5| Step: 10
Training loss: 0.2156386063608892
Validation loss: 2.520322750177946

Epoch: 490| Step: 0
Training loss: 0.33393843931665385
Validation loss: 2.506114647821505

Epoch: 5| Step: 1
Training loss: 0.10812586804686482
Validation loss: 2.477126596370154

Epoch: 5| Step: 2
Training loss: 0.185168935445826
Validation loss: 2.4996534640597114

Epoch: 5| Step: 3
Training loss: 0.2593153729899092
Validation loss: 2.5054180020087937

Epoch: 5| Step: 4
Training loss: 0.28607600302369957
Validation loss: 2.565479045580019

Epoch: 5| Step: 5
Training loss: 0.14108647022498447
Validation loss: 2.5838578047720575

Epoch: 5| Step: 6
Training loss: 0.14955910019730662
Validation loss: 2.597822008280818

Epoch: 5| Step: 7
Training loss: 0.19311201283387705
Validation loss: 2.6322034908789034

Epoch: 5| Step: 8
Training loss: 0.3529252871654402
Validation loss: 2.6457603456795877

Epoch: 5| Step: 9
Training loss: 0.30632157948940286
Validation loss: 2.602723677664618

Epoch: 5| Step: 10
Training loss: 0.17819703845542476
Validation loss: 2.5890754457531653

Epoch: 491| Step: 0
Training loss: 0.26730827312414296
Validation loss: 2.5769727650975445

Epoch: 5| Step: 1
Training loss: 0.23124533274812156
Validation loss: 2.553128320658649

Epoch: 5| Step: 2
Training loss: 0.16816228983052217
Validation loss: 2.496025745308238

Epoch: 5| Step: 3
Training loss: 0.2842932143346517
Validation loss: 2.527568210155976

Epoch: 5| Step: 4
Training loss: 0.2883936128053884
Validation loss: 2.5401616862247023

Epoch: 5| Step: 5
Training loss: 0.20714377997778877
Validation loss: 2.5403300357662983

Epoch: 5| Step: 6
Training loss: 0.18622186257810955
Validation loss: 2.5437374652756186

Epoch: 5| Step: 7
Training loss: 0.22023155673396733
Validation loss: 2.5983377928681315

Epoch: 5| Step: 8
Training loss: 0.19228250047390866
Validation loss: 2.5998812145867944

Epoch: 5| Step: 9
Training loss: 0.2770330273463105
Validation loss: 2.6059837220430055

Epoch: 5| Step: 10
Training loss: 0.36861735803179646
Validation loss: 2.592982222399999

Epoch: 492| Step: 0
Training loss: 0.15386251685091057
Validation loss: 2.598773608846915

Epoch: 5| Step: 1
Training loss: 0.19073373046538597
Validation loss: 2.5815159408479063

Epoch: 5| Step: 2
Training loss: 0.3663606058089396
Validation loss: 2.5415544194275785

Epoch: 5| Step: 3
Training loss: 0.36619136503686217
Validation loss: 2.535440425700982

Epoch: 5| Step: 4
Training loss: 0.1474723874629907
Validation loss: 2.584684634461372

Epoch: 5| Step: 5
Training loss: 0.14144837874170776
Validation loss: 2.6034489817067668

Epoch: 5| Step: 6
Training loss: 0.2099807907299305
Validation loss: 2.6261549848810093

Epoch: 5| Step: 7
Training loss: 0.3115136315407833
Validation loss: 2.6080412565288933

Epoch: 5| Step: 8
Training loss: 0.21786870711458672
Validation loss: 2.574267521793508

Epoch: 5| Step: 9
Training loss: 0.2396172140186804
Validation loss: 2.5844181798438597

Epoch: 5| Step: 10
Training loss: 0.19709772575267265
Validation loss: 2.5590353132514982

Epoch: 493| Step: 0
Training loss: 0.3369796910151667
Validation loss: 2.5443588924926583

Epoch: 5| Step: 1
Training loss: 0.2246039514301461
Validation loss: 2.5403844507215823

Epoch: 5| Step: 2
Training loss: 0.2032293546820129
Validation loss: 2.543506577852808

Epoch: 5| Step: 3
Training loss: 0.19041879084784455
Validation loss: 2.5122097298906514

Epoch: 5| Step: 4
Training loss: 0.17816984883592912
Validation loss: 2.532015614933808

Epoch: 5| Step: 5
Training loss: 0.18233784817229376
Validation loss: 2.507750024721095

Epoch: 5| Step: 6
Training loss: 0.433375913869347
Validation loss: 2.517657336009272

Epoch: 5| Step: 7
Training loss: 0.19181149265811598
Validation loss: 2.516264346906551

Epoch: 5| Step: 8
Training loss: 0.2462695114761382
Validation loss: 2.562191141475093

Epoch: 5| Step: 9
Training loss: 0.2843003033428405
Validation loss: 2.6004250737036814

Epoch: 5| Step: 10
Training loss: 0.25392395838093534
Validation loss: 2.5933219011775344

Epoch: 494| Step: 0
Training loss: 0.233879391868046
Validation loss: 2.540128225811147

Epoch: 5| Step: 1
Training loss: 0.16757946591852246
Validation loss: 2.5480662296145256

Epoch: 5| Step: 2
Training loss: 0.4154507737935181
Validation loss: 2.5050009913986293

Epoch: 5| Step: 3
Training loss: 0.13913283498162918
Validation loss: 2.4932678573026372

Epoch: 5| Step: 4
Training loss: 0.190175488344335
Validation loss: 2.5456832930211246

Epoch: 5| Step: 5
Training loss: 0.20092334951109933
Validation loss: 2.5602689825824454

Epoch: 5| Step: 6
Training loss: 0.2324615973500249
Validation loss: 2.55547042670413

Epoch: 5| Step: 7
Training loss: 0.31559528220367855
Validation loss: 2.575063329468056

Epoch: 5| Step: 8
Training loss: 0.14557639048485665
Validation loss: 2.588670707360499

Epoch: 5| Step: 9
Training loss: 0.25148770126603204
Validation loss: 2.5668251154161204

Epoch: 5| Step: 10
Training loss: 0.13756712228859636
Validation loss: 2.577724795883763

Epoch: 495| Step: 0
Training loss: 0.2001039808399212
Validation loss: 2.598754745289897

Epoch: 5| Step: 1
Training loss: 0.22015029739443834
Validation loss: 2.5971683255833033

Epoch: 5| Step: 2
Training loss: 0.273314598256014
Validation loss: 2.6009694331592055

Epoch: 5| Step: 3
Training loss: 0.319183103052692
Validation loss: 2.5682929828443584

Epoch: 5| Step: 4
Training loss: 0.2841599709923618
Validation loss: 2.5612305458825135

Epoch: 5| Step: 5
Training loss: 0.13854565047031311
Validation loss: 2.5940145117252373

Epoch: 5| Step: 6
Training loss: 0.3601815254130278
Validation loss: 2.610121812377267

Epoch: 5| Step: 7
Training loss: 0.2567879809727287
Validation loss: 2.614425596244291

Epoch: 5| Step: 8
Training loss: 0.3064135178166523
Validation loss: 2.612804372580544

Epoch: 5| Step: 9
Training loss: 0.23847910999184008
Validation loss: 2.579205956788389

Epoch: 5| Step: 10
Training loss: 0.1720834194478319
Validation loss: 2.534254064145599

Epoch: 496| Step: 0
Training loss: 0.14887092705751548
Validation loss: 2.5141550247015454

Epoch: 5| Step: 1
Training loss: 0.3076784829727158
Validation loss: 2.490658918043173

Epoch: 5| Step: 2
Training loss: 0.2320430938831847
Validation loss: 2.4815438235643104

Epoch: 5| Step: 3
Training loss: 0.2570563556271639
Validation loss: 2.5309104980403343

Epoch: 5| Step: 4
Training loss: 0.19050490043312043
Validation loss: 2.5263690262331675

Epoch: 5| Step: 5
Training loss: 0.44559023377748513
Validation loss: 2.6002205826905165

Epoch: 5| Step: 6
Training loss: 0.18179703203037956
Validation loss: 2.6073303813735387

Epoch: 5| Step: 7
Training loss: 0.17214868711276446
Validation loss: 2.625570425704899

Epoch: 5| Step: 8
Training loss: 0.2803330175360769
Validation loss: 2.637006985957575

Epoch: 5| Step: 9
Training loss: 0.26297243384298613
Validation loss: 2.6413655333380985

Epoch: 5| Step: 10
Training loss: 0.2053341947122435
Validation loss: 2.632411522764573

Epoch: 497| Step: 0
Training loss: 0.12482869062201253
Validation loss: 2.6211609051236078

Epoch: 5| Step: 1
Training loss: 0.36263451382485523
Validation loss: 2.56970776349876

Epoch: 5| Step: 2
Training loss: 0.2788594428356415
Validation loss: 2.5842889578925576

Epoch: 5| Step: 3
Training loss: 0.21753475982964723
Validation loss: 2.5811825840463256

Epoch: 5| Step: 4
Training loss: 0.18983232754225146
Validation loss: 2.5825535299051965

Epoch: 5| Step: 5
Training loss: 0.3817048494147865
Validation loss: 2.5760542701624614

Epoch: 5| Step: 6
Training loss: 0.2606084244760671
Validation loss: 2.5426956099881046

Epoch: 5| Step: 7
Training loss: 0.2147336851301966
Validation loss: 2.5280299638056527

Epoch: 5| Step: 8
Training loss: 0.40120086565171525
Validation loss: 2.5177367308629726

Epoch: 5| Step: 9
Training loss: 0.2841238642131561
Validation loss: 2.526912075869269

Epoch: 5| Step: 10
Training loss: 0.30725805723801375
Validation loss: 2.527330859458981

Epoch: 498| Step: 0
Training loss: 0.25968041133730957
Validation loss: 2.514666234546911

Epoch: 5| Step: 1
Training loss: 0.1561001416636123
Validation loss: 2.5296129416975415

Epoch: 5| Step: 2
Training loss: 0.19134429980094206
Validation loss: 2.56471115873617

Epoch: 5| Step: 3
Training loss: 0.11861803398616692
Validation loss: 2.589030059643498

Epoch: 5| Step: 4
Training loss: 0.18925199942622342
Validation loss: 2.5933399323531505

Epoch: 5| Step: 5
Training loss: 0.1674746409478263
Validation loss: 2.5755748179276123

Epoch: 5| Step: 6
Training loss: 0.22079443941452778
Validation loss: 2.5589734253290706

Epoch: 5| Step: 7
Training loss: 0.3600860899733123
Validation loss: 2.5150053361327114

Epoch: 5| Step: 8
Training loss: 0.23656873828317182
Validation loss: 2.481566866889258

Epoch: 5| Step: 9
Training loss: 0.2137528292290239
Validation loss: 2.4844974305265928

Epoch: 5| Step: 10
Training loss: 0.3804488684063498
Validation loss: 2.488749025806685

Epoch: 499| Step: 0
Training loss: 0.17151337749818882
Validation loss: 2.5170311386051347

Epoch: 5| Step: 1
Training loss: 0.21776438809738988
Validation loss: 2.5683809192542575

Epoch: 5| Step: 2
Training loss: 0.3053313446281217
Validation loss: 2.5706894772015447

Epoch: 5| Step: 3
Training loss: 0.25354303643810805
Validation loss: 2.5678506588896726

Epoch: 5| Step: 4
Training loss: 0.14183917662531498
Validation loss: 2.5436890328061073

Epoch: 5| Step: 5
Training loss: 0.12387067292457643
Validation loss: 2.5448163755107847

Epoch: 5| Step: 6
Training loss: 0.11869517287265768
Validation loss: 2.5300455695458273

Epoch: 5| Step: 7
Training loss: 0.3931615110220745
Validation loss: 2.5419282056623356

Epoch: 5| Step: 8
Training loss: 0.14309507219512227
Validation loss: 2.5495979986700843

Epoch: 5| Step: 9
Training loss: 0.2597275182551795
Validation loss: 2.56113607633069

Epoch: 5| Step: 10
Training loss: 0.279373331875696
Validation loss: 2.5678176948115143

Epoch: 500| Step: 0
Training loss: 0.11713876505597993
Validation loss: 2.55365514479211

Epoch: 5| Step: 1
Training loss: 0.24643741559339913
Validation loss: 2.58499017939546

Epoch: 5| Step: 2
Training loss: 0.15175716861504795
Validation loss: 2.5484708417494684

Epoch: 5| Step: 3
Training loss: 0.32981774256972496
Validation loss: 2.591116577385627

Epoch: 5| Step: 4
Training loss: 0.27564255033570656
Validation loss: 2.591696368879731

Epoch: 5| Step: 5
Training loss: 0.23270774539137848
Validation loss: 2.5919605639924126

Epoch: 5| Step: 6
Training loss: 0.1649213630780362
Validation loss: 2.5716884917166616

Epoch: 5| Step: 7
Training loss: 0.09441356959468789
Validation loss: 2.5649924633356207

Epoch: 5| Step: 8
Training loss: 0.1922982315569839
Validation loss: 2.5581621900897833

Epoch: 5| Step: 9
Training loss: 0.25353851097502317
Validation loss: 2.5357720481199686

Epoch: 5| Step: 10
Training loss: 0.27145271665559645
Validation loss: 2.5472637559006244

Epoch: 501| Step: 0
Training loss: 0.2676600031636904
Validation loss: 2.5573543424531953

Epoch: 5| Step: 1
Training loss: 0.17958544860074976
Validation loss: 2.573485946963826

Epoch: 5| Step: 2
Training loss: 0.21497239682797084
Validation loss: 2.562772426735491

Epoch: 5| Step: 3
Training loss: 0.19262146065620886
Validation loss: 2.5732197912822783

Epoch: 5| Step: 4
Training loss: 0.33881559171534414
Validation loss: 2.5801590945626374

Epoch: 5| Step: 5
Training loss: 0.24192518980163275
Validation loss: 2.595820658360223

Epoch: 5| Step: 6
Training loss: 0.1836349664240042
Validation loss: 2.56683503657315

Epoch: 5| Step: 7
Training loss: 0.1464599906970956
Validation loss: 2.5660959834354817

Epoch: 5| Step: 8
Training loss: 0.1275263463058816
Validation loss: 2.5591971608855966

Epoch: 5| Step: 9
Training loss: 0.25325077252397266
Validation loss: 2.5378379904416652

Epoch: 5| Step: 10
Training loss: 0.15352937695008834
Validation loss: 2.5336155727180327

Epoch: 502| Step: 0
Training loss: 0.16001872228815814
Validation loss: 2.545689159607653

Epoch: 5| Step: 1
Training loss: 0.21555872638138995
Validation loss: 2.510228928476783

Epoch: 5| Step: 2
Training loss: 0.12192982027593254
Validation loss: 2.5576035353870816

Epoch: 5| Step: 3
Training loss: 0.19392684548960307
Validation loss: 2.576181304888757

Epoch: 5| Step: 4
Training loss: 0.15171059447073476
Validation loss: 2.559355654698409

Epoch: 5| Step: 5
Training loss: 0.1368546015310596
Validation loss: 2.552506819331627

Epoch: 5| Step: 6
Training loss: 0.29142260416074756
Validation loss: 2.577851337564466

Epoch: 5| Step: 7
Training loss: 0.38818178956194327
Validation loss: 2.572878264662504

Epoch: 5| Step: 8
Training loss: 0.1820394485493769
Validation loss: 2.5853835599606305

Epoch: 5| Step: 9
Training loss: 0.09743781455725105
Validation loss: 2.5658907512833395

Epoch: 5| Step: 10
Training loss: 0.2848719394480934
Validation loss: 2.553891581821579

Epoch: 503| Step: 0
Training loss: 0.2275556304531773
Validation loss: 2.5477085655655136

Epoch: 5| Step: 1
Training loss: 0.23565099195910585
Validation loss: 2.5943641157972337

Epoch: 5| Step: 2
Training loss: 0.3491980621218029
Validation loss: 2.6075329693502343

Epoch: 5| Step: 3
Training loss: 0.22298824922752367
Validation loss: 2.6263404505928887

Epoch: 5| Step: 4
Training loss: 0.14856296181235876
Validation loss: 2.564792761861642

Epoch: 5| Step: 5
Training loss: 0.1786754969074219
Validation loss: 2.6264340975281133

Epoch: 5| Step: 6
Training loss: 0.27595761956970194
Validation loss: 2.606152904117613

Epoch: 5| Step: 7
Training loss: 0.168052175784958
Validation loss: 2.5922113078226046

Epoch: 5| Step: 8
Training loss: 0.17516486925123345
Validation loss: 2.5728734006843816

Epoch: 5| Step: 9
Training loss: 0.29379194954365423
Validation loss: 2.578640713389006

Epoch: 5| Step: 10
Training loss: 0.09869305970697799
Validation loss: 2.572467473962721

Epoch: 504| Step: 0
Training loss: 0.16462205084872414
Validation loss: 2.584750346463136

Epoch: 5| Step: 1
Training loss: 0.34312570842815704
Validation loss: 2.5746095307735057

Epoch: 5| Step: 2
Training loss: 0.1452665825560215
Validation loss: 2.5812051708942265

Epoch: 5| Step: 3
Training loss: 0.2580223096749599
Validation loss: 2.564403039384275

Epoch: 5| Step: 4
Training loss: 0.16943329692891532
Validation loss: 2.5555608161778793

Epoch: 5| Step: 5
Training loss: 0.11128370754176432
Validation loss: 2.5806992591807156

Epoch: 5| Step: 6
Training loss: 0.16756981782396901
Validation loss: 2.590047516691211

Epoch: 5| Step: 7
Training loss: 0.3329088393991286
Validation loss: 2.5924259319450607

Epoch: 5| Step: 8
Training loss: 0.17351154366390376
Validation loss: 2.5926238648562703

Epoch: 5| Step: 9
Training loss: 0.2417354286890377
Validation loss: 2.5899850518517473

Epoch: 5| Step: 10
Training loss: 0.17133710963760718
Validation loss: 2.592266623753565

Epoch: 505| Step: 0
Training loss: 0.18234408964503018
Validation loss: 2.5994083628869222

Epoch: 5| Step: 1
Training loss: 0.1637509601051634
Validation loss: 2.6152684862773286

Epoch: 5| Step: 2
Training loss: 0.14343436382123032
Validation loss: 2.5760530324056163

Epoch: 5| Step: 3
Training loss: 0.17026063978177267
Validation loss: 2.562314556784021

Epoch: 5| Step: 4
Training loss: 0.243141916331288
Validation loss: 2.567108091793524

Epoch: 5| Step: 5
Training loss: 0.20805720965064337
Validation loss: 2.551423443348046

Epoch: 5| Step: 6
Training loss: 0.20018535682300367
Validation loss: 2.5245384395916775

Epoch: 5| Step: 7
Training loss: 0.32478859242780156
Validation loss: 2.5576026984159674

Epoch: 5| Step: 8
Training loss: 0.3422803674381928
Validation loss: 2.5591990877246

Epoch: 5| Step: 9
Training loss: 0.14430025689499723
Validation loss: 2.607220668264507

Epoch: 5| Step: 10
Training loss: 0.28426357224135834
Validation loss: 2.588873529090098

Epoch: 506| Step: 0
Training loss: 0.24499350539182377
Validation loss: 2.590503198920167

Epoch: 5| Step: 1
Training loss: 0.17161919240787196
Validation loss: 2.616620218076214

Epoch: 5| Step: 2
Training loss: 0.2084631346619775
Validation loss: 2.618528793468174

Epoch: 5| Step: 3
Training loss: 0.18044851693352273
Validation loss: 2.613817594481032

Epoch: 5| Step: 4
Training loss: 0.25692392154874455
Validation loss: 2.603271805781417

Epoch: 5| Step: 5
Training loss: 0.33488977415893095
Validation loss: 2.5641304089656884

Epoch: 5| Step: 6
Training loss: 0.14794197316572666
Validation loss: 2.5701356985285657

Epoch: 5| Step: 7
Training loss: 0.2835182015750514
Validation loss: 2.5186422489200404

Epoch: 5| Step: 8
Training loss: 0.15467352707687013
Validation loss: 2.5528885261565457

Epoch: 5| Step: 9
Training loss: 0.18211515032080625
Validation loss: 2.535023593634626

Epoch: 5| Step: 10
Training loss: 0.14063478806657534
Validation loss: 2.5480218174207456

Epoch: 507| Step: 0
Training loss: 0.15745256304680846
Validation loss: 2.5632013541147693

Epoch: 5| Step: 1
Training loss: 0.2888523962065434
Validation loss: 2.5559015835254706

Epoch: 5| Step: 2
Training loss: 0.22778206648139251
Validation loss: 2.6059563785240516

Epoch: 5| Step: 3
Training loss: 0.22110146047404405
Validation loss: 2.6235200349846166

Epoch: 5| Step: 4
Training loss: 0.19108268091265362
Validation loss: 2.5849807000700733

Epoch: 5| Step: 5
Training loss: 0.1920933457924652
Validation loss: 2.600049921137079

Epoch: 5| Step: 6
Training loss: 0.22375837907073104
Validation loss: 2.570719781698895

Epoch: 5| Step: 7
Training loss: 0.3413155572751166
Validation loss: 2.5706315924546863

Epoch: 5| Step: 8
Training loss: 0.15040339378547393
Validation loss: 2.543326963423345

Epoch: 5| Step: 9
Training loss: 0.17575706209554215
Validation loss: 2.5295904571573264

Epoch: 5| Step: 10
Training loss: 0.14049332467398348
Validation loss: 2.530220217763344

Epoch: 508| Step: 0
Training loss: 0.3647512004040319
Validation loss: 2.5452460716658787

Epoch: 5| Step: 1
Training loss: 0.17568461092897772
Validation loss: 2.53769725863512

Epoch: 5| Step: 2
Training loss: 0.1633106613592189
Validation loss: 2.569410816308106

Epoch: 5| Step: 3
Training loss: 0.15129596511258359
Validation loss: 2.563515808711352

Epoch: 5| Step: 4
Training loss: 0.31148232215604815
Validation loss: 2.5508330955362815

Epoch: 5| Step: 5
Training loss: 0.13555272691610495
Validation loss: 2.6016425693484346

Epoch: 5| Step: 6
Training loss: 0.09265916713606244
Validation loss: 2.566100659452723

Epoch: 5| Step: 7
Training loss: 0.19830939370483777
Validation loss: 2.5472906007485556

Epoch: 5| Step: 8
Training loss: 0.18346068450204628
Validation loss: 2.560103653814083

Epoch: 5| Step: 9
Training loss: 0.14558130366937258
Validation loss: 2.511188223249788

Epoch: 5| Step: 10
Training loss: 0.2788442264908932
Validation loss: 2.49092074331443

Epoch: 509| Step: 0
Training loss: 0.15526656369523154
Validation loss: 2.5107740221827517

Epoch: 5| Step: 1
Training loss: 0.1236087444194342
Validation loss: 2.519463337616305

Epoch: 5| Step: 2
Training loss: 0.135865429978571
Validation loss: 2.519678827434225

Epoch: 5| Step: 3
Training loss: 0.34785483614169904
Validation loss: 2.5313446065728327

Epoch: 5| Step: 4
Training loss: 0.18208478132307962
Validation loss: 2.543342125519312

Epoch: 5| Step: 5
Training loss: 0.2793459682399997
Validation loss: 2.6103851993967715

Epoch: 5| Step: 6
Training loss: 0.12783040860911515
Validation loss: 2.6128113899957763

Epoch: 5| Step: 7
Training loss: 0.09942664889268528
Validation loss: 2.6174685894631624

Epoch: 5| Step: 8
Training loss: 0.18393321814302138
Validation loss: 2.598756080994443

Epoch: 5| Step: 9
Training loss: 0.14646193014488046
Validation loss: 2.5926281044223667

Epoch: 5| Step: 10
Training loss: 0.36186106788420125
Validation loss: 2.615254970430444

Epoch: 510| Step: 0
Training loss: 0.34376783758179374
Validation loss: 2.5882759675076095

Epoch: 5| Step: 1
Training loss: 0.15128931072597887
Validation loss: 2.566327606632957

Epoch: 5| Step: 2
Training loss: 0.16214153246604035
Validation loss: 2.5420841141184627

Epoch: 5| Step: 3
Training loss: 0.2944535585533345
Validation loss: 2.522984379091836

Epoch: 5| Step: 4
Training loss: 0.10394130309126788
Validation loss: 2.533949764956507

Epoch: 5| Step: 5
Training loss: 0.12112670496157951
Validation loss: 2.5474545023180797

Epoch: 5| Step: 6
Training loss: 0.2653795398444225
Validation loss: 2.5439621145275244

Epoch: 5| Step: 7
Training loss: 0.12371487417603418
Validation loss: 2.5423745921634215

Epoch: 5| Step: 8
Training loss: 0.1166771345111476
Validation loss: 2.557750207588725

Epoch: 5| Step: 9
Training loss: 0.2780774445542307
Validation loss: 2.563185487346888

Epoch: 5| Step: 10
Training loss: 0.13172262054856462
Validation loss: 2.5543933056895636

Epoch: 511| Step: 0
Training loss: 0.18050844862296891
Validation loss: 2.5712079113239596

Epoch: 5| Step: 1
Training loss: 0.1508467803628559
Validation loss: 2.578419821330688

Epoch: 5| Step: 2
Training loss: 0.16168413344595434
Validation loss: 2.583902221610906

Epoch: 5| Step: 3
Training loss: 0.3957590506103711
Validation loss: 2.5419252690392966

Epoch: 5| Step: 4
Training loss: 0.26648874655576554
Validation loss: 2.5403291466819025

Epoch: 5| Step: 5
Training loss: 0.2333442114241398
Validation loss: 2.5300043936279515

Epoch: 5| Step: 6
Training loss: 0.202759882253953
Validation loss: 2.562790718865089

Epoch: 5| Step: 7
Training loss: 0.20606086143175395
Validation loss: 2.5364111145708983

Epoch: 5| Step: 8
Training loss: 0.10877938390170629
Validation loss: 2.5211964283621295

Epoch: 5| Step: 9
Training loss: 0.1456983841643803
Validation loss: 2.537494652305669

Epoch: 5| Step: 10
Training loss: 0.07864592152973729
Validation loss: 2.550846460269522

Epoch: 512| Step: 0
Training loss: 0.44254288293194693
Validation loss: 2.554215321502904

Epoch: 5| Step: 1
Training loss: 0.24520399828481668
Validation loss: 2.5559133259462943

Epoch: 5| Step: 2
Training loss: 0.20714299766883407
Validation loss: 2.578653278836716

Epoch: 5| Step: 3
Training loss: 0.16836625016550585
Validation loss: 2.5496874340023936

Epoch: 5| Step: 4
Training loss: 0.15611976321816418
Validation loss: 2.525870901834643

Epoch: 5| Step: 5
Training loss: 0.15664803946396305
Validation loss: 2.5790524705957747

Epoch: 5| Step: 6
Training loss: 0.1375478604316187
Validation loss: 2.604926411378962

Epoch: 5| Step: 7
Training loss: 0.09733438857055769
Validation loss: 2.5551439795470903

Epoch: 5| Step: 8
Training loss: 0.17764659432615448
Validation loss: 2.5902657588894082

Epoch: 5| Step: 9
Training loss: 0.16795267538290326
Validation loss: 2.5936795247468054

Epoch: 5| Step: 10
Training loss: 0.13462440721174126
Validation loss: 2.5998216627421784

Epoch: 513| Step: 0
Training loss: 0.15467258776446458
Validation loss: 2.580150742365245

Epoch: 5| Step: 1
Training loss: 0.12775161230223223
Validation loss: 2.5921426797345513

Epoch: 5| Step: 2
Training loss: 0.18517228511796754
Validation loss: 2.5982802643328156

Epoch: 5| Step: 3
Training loss: 0.3624802033181737
Validation loss: 2.651699792345871

Epoch: 5| Step: 4
Training loss: 0.11279805489834656
Validation loss: 2.6125713477794115

Epoch: 5| Step: 5
Training loss: 0.26735513681835044
Validation loss: 2.6030707667493522

Epoch: 5| Step: 6
Training loss: 0.20671427951860377
Validation loss: 2.6118734334639706

Epoch: 5| Step: 7
Training loss: 0.17324606279341628
Validation loss: 2.583573308556645

Epoch: 5| Step: 8
Training loss: 0.15346329697475564
Validation loss: 2.576136073748825

Epoch: 5| Step: 9
Training loss: 0.24773912787953284
Validation loss: 2.523685223848542

Epoch: 5| Step: 10
Training loss: 0.16166981887468462
Validation loss: 2.557080684812489

Epoch: 514| Step: 0
Training loss: 0.16356623615885288
Validation loss: 2.5735553146283072

Epoch: 5| Step: 1
Training loss: 0.2783395057886567
Validation loss: 2.570484436769567

Epoch: 5| Step: 2
Training loss: 0.4100091216189156
Validation loss: 2.5509970111925004

Epoch: 5| Step: 3
Training loss: 0.21853230918334113
Validation loss: 2.5904144196377845

Epoch: 5| Step: 4
Training loss: 0.14203066429168493
Validation loss: 2.5889680331821014

Epoch: 5| Step: 5
Training loss: 0.08884489387650672
Validation loss: 2.6111784812269816

Epoch: 5| Step: 6
Training loss: 0.2403789798369415
Validation loss: 2.5811221384384035

Epoch: 5| Step: 7
Training loss: 0.11412241648844794
Validation loss: 2.5730192886285774

Epoch: 5| Step: 8
Training loss: 0.1270291027718123
Validation loss: 2.566693909538723

Epoch: 5| Step: 9
Training loss: 0.15117662801835857
Validation loss: 2.5892871288289836

Epoch: 5| Step: 10
Training loss: 0.10021318885954975
Validation loss: 2.5390455867939195

Epoch: 515| Step: 0
Training loss: 0.07479815442114833
Validation loss: 2.568100450511247

Epoch: 5| Step: 1
Training loss: 0.18561989200833767
Validation loss: 2.5627068786988567

Epoch: 5| Step: 2
Training loss: 0.10445775150903679
Validation loss: 2.5636803104433312

Epoch: 5| Step: 3
Training loss: 0.2543789058872813
Validation loss: 2.559409035365433

Epoch: 5| Step: 4
Training loss: 0.12864373671281362
Validation loss: 2.563530036364633

Epoch: 5| Step: 5
Training loss: 0.18070179313304083
Validation loss: 2.5999964983011776

Epoch: 5| Step: 6
Training loss: 0.2930519240251249
Validation loss: 2.602075933774982

Epoch: 5| Step: 7
Training loss: 0.25443791698608115
Validation loss: 2.5704148914818266

Epoch: 5| Step: 8
Training loss: 0.10616889112236007
Validation loss: 2.554627613154575

Epoch: 5| Step: 9
Training loss: 0.36938583464634844
Validation loss: 2.5493550151849966

Epoch: 5| Step: 10
Training loss: 0.15966899533189668
Validation loss: 2.5196966993428944

Epoch: 516| Step: 0
Training loss: 0.18992008589698636
Validation loss: 2.5717952144680556

Epoch: 5| Step: 1
Training loss: 0.11801525866525996
Validation loss: 2.5678853836293576

Epoch: 5| Step: 2
Training loss: 0.3912887465392028
Validation loss: 2.5833637250315973

Epoch: 5| Step: 3
Training loss: 0.23313389234483553
Validation loss: 2.602763959126909

Epoch: 5| Step: 4
Training loss: 0.319539603051873
Validation loss: 2.61676802624702

Epoch: 5| Step: 5
Training loss: 0.12356164143229782
Validation loss: 2.635612166500797

Epoch: 5| Step: 6
Training loss: 0.1600231629514413
Validation loss: 2.6215026907148418

Epoch: 5| Step: 7
Training loss: 0.2320712755019853
Validation loss: 2.6168206060741994

Epoch: 5| Step: 8
Training loss: 0.12955530363183781
Validation loss: 2.5748798021330113

Epoch: 5| Step: 9
Training loss: 0.14605504379983983
Validation loss: 2.5628446121657076

Epoch: 5| Step: 10
Training loss: 0.16818356639014373
Validation loss: 2.5246567818884422

Epoch: 517| Step: 0
Training loss: 0.23866645756893037
Validation loss: 2.4989894567823803

Epoch: 5| Step: 1
Training loss: 0.11458739811738883
Validation loss: 2.5278823531459147

Epoch: 5| Step: 2
Training loss: 0.10402236470218282
Validation loss: 2.5612471804667902

Epoch: 5| Step: 3
Training loss: 0.18865020935576263
Validation loss: 2.5702372537238434

Epoch: 5| Step: 4
Training loss: 0.41051754252345624
Validation loss: 2.5549583355468672

Epoch: 5| Step: 5
Training loss: 0.1910869114323546
Validation loss: 2.553616326800474

Epoch: 5| Step: 6
Training loss: 0.12486254689624068
Validation loss: 2.5349525379799895

Epoch: 5| Step: 7
Training loss: 0.16052272201922982
Validation loss: 2.515792090063462

Epoch: 5| Step: 8
Training loss: 0.21802660847551603
Validation loss: 2.52041792915208

Epoch: 5| Step: 9
Training loss: 0.20091856591406723
Validation loss: 2.5217859086574244

Epoch: 5| Step: 10
Training loss: 0.2061850239534806
Validation loss: 2.529170008293583

Epoch: 518| Step: 0
Training loss: 0.27373506159064565
Validation loss: 2.5142032205668228

Epoch: 5| Step: 1
Training loss: 0.13180788942723215
Validation loss: 2.547641779897588

Epoch: 5| Step: 2
Training loss: 0.11393830056466377
Validation loss: 2.5496496581201815

Epoch: 5| Step: 3
Training loss: 0.33631520883390503
Validation loss: 2.559328235722509

Epoch: 5| Step: 4
Training loss: 0.17737631309781338
Validation loss: 2.5454139708735912

Epoch: 5| Step: 5
Training loss: 0.17786348285772116
Validation loss: 2.532784882183146

Epoch: 5| Step: 6
Training loss: 0.2165792249025944
Validation loss: 2.5489614931212343

Epoch: 5| Step: 7
Training loss: 0.15935255388132072
Validation loss: 2.5526932597575067

Epoch: 5| Step: 8
Training loss: 0.07677144883145028
Validation loss: 2.5412043395247794

Epoch: 5| Step: 9
Training loss: 0.2755445902172398
Validation loss: 2.5596392340010437

Epoch: 5| Step: 10
Training loss: 0.08372154249658
Validation loss: 2.5479448292189972

Epoch: 519| Step: 0
Training loss: 0.17864755642637337
Validation loss: 2.568563986219113

Epoch: 5| Step: 1
Training loss: 0.3335173838844484
Validation loss: 2.5859901207987694

Epoch: 5| Step: 2
Training loss: 0.16072454459981325
Validation loss: 2.5684577939569637

Epoch: 5| Step: 3
Training loss: 0.1496594103815818
Validation loss: 2.5528356257422735

Epoch: 5| Step: 4
Training loss: 0.11623514948993402
Validation loss: 2.520622871770904

Epoch: 5| Step: 5
Training loss: 0.2360640224471322
Validation loss: 2.5792423972784464

Epoch: 5| Step: 6
Training loss: 0.1739860738595105
Validation loss: 2.5621659696192327

Epoch: 5| Step: 7
Training loss: 0.26751524471801585
Validation loss: 2.5461221640832523

Epoch: 5| Step: 8
Training loss: 0.1488310653416092
Validation loss: 2.568113645522703

Epoch: 5| Step: 9
Training loss: 0.08021667462124812
Validation loss: 2.582700700202958

Epoch: 5| Step: 10
Training loss: 0.15474129906876613
Validation loss: 2.5690944286526056

Epoch: 520| Step: 0
Training loss: 0.14247165911541568
Validation loss: 2.5866265861700977

Epoch: 5| Step: 1
Training loss: 0.1278153119325855
Validation loss: 2.609350672871212

Epoch: 5| Step: 2
Training loss: 0.14813796992598785
Validation loss: 2.6033236005656635

Epoch: 5| Step: 3
Training loss: 0.13490168986500994
Validation loss: 2.566853411611249

Epoch: 5| Step: 4
Training loss: 0.19032619304911905
Validation loss: 2.57209860148503

Epoch: 5| Step: 5
Training loss: 0.16845721922048504
Validation loss: 2.5299340983552137

Epoch: 5| Step: 6
Training loss: 0.33223666400566715
Validation loss: 2.5260116922122244

Epoch: 5| Step: 7
Training loss: 0.16707110631547686
Validation loss: 2.519812243049565

Epoch: 5| Step: 8
Training loss: 0.35275503923924745
Validation loss: 2.537165042501704

Epoch: 5| Step: 9
Training loss: 0.11622732511745715
Validation loss: 2.5491351304705265

Epoch: 5| Step: 10
Training loss: 0.10333507464833018
Validation loss: 2.572450059861846

Epoch: 521| Step: 0
Training loss: 0.23160286864248408
Validation loss: 2.5504071285845864

Epoch: 5| Step: 1
Training loss: 0.11283991195972982
Validation loss: 2.575067624825832

Epoch: 5| Step: 2
Training loss: 0.08146738786915834
Validation loss: 2.5951498657065133

Epoch: 5| Step: 3
Training loss: 0.1550511622591075
Validation loss: 2.593152907677029

Epoch: 5| Step: 4
Training loss: 0.1250942366740899
Validation loss: 2.6056606989927067

Epoch: 5| Step: 5
Training loss: 0.39008494237668295
Validation loss: 2.596337347072534

Epoch: 5| Step: 6
Training loss: 0.26417788236306755
Validation loss: 2.6021015047750717

Epoch: 5| Step: 7
Training loss: 0.15795641370801133
Validation loss: 2.6271605231399295

Epoch: 5| Step: 8
Training loss: 0.1526793061125598
Validation loss: 2.5676221319920587

Epoch: 5| Step: 9
Training loss: 0.10872092261806636
Validation loss: 2.548467032204472

Epoch: 5| Step: 10
Training loss: 0.17979751204635305
Validation loss: 2.540110912968086

Epoch: 522| Step: 0
Training loss: 0.17452306811929152
Validation loss: 2.5329960571691457

Epoch: 5| Step: 1
Training loss: 0.24478356199172246
Validation loss: 2.535200935102807

Epoch: 5| Step: 2
Training loss: 0.22024857290240765
Validation loss: 2.5252609880135606

Epoch: 5| Step: 3
Training loss: 0.19853420079081568
Validation loss: 2.5431185475140055

Epoch: 5| Step: 4
Training loss: 0.20881797725912088
Validation loss: 2.520456325726672

Epoch: 5| Step: 5
Training loss: 0.10955965683882678
Validation loss: 2.5361136846875203

Epoch: 5| Step: 6
Training loss: 0.12397574837016054
Validation loss: 2.5576951093985807

Epoch: 5| Step: 7
Training loss: 0.37159033225934474
Validation loss: 2.55977094719912

Epoch: 5| Step: 8
Training loss: 0.15434649430156358
Validation loss: 2.545705835322394

Epoch: 5| Step: 9
Training loss: 0.09630447848487565
Validation loss: 2.5619672521106134

Epoch: 5| Step: 10
Training loss: 0.06750660043914548
Validation loss: 2.5493756380206505

Epoch: 523| Step: 0
Training loss: 0.1761893409647709
Validation loss: 2.566528155591786

Epoch: 5| Step: 1
Training loss: 0.1722794131515453
Validation loss: 2.5580040131893513

Epoch: 5| Step: 2
Training loss: 0.30300937590712707
Validation loss: 2.558493009699279

Epoch: 5| Step: 3
Training loss: 0.10893813232335751
Validation loss: 2.5678378908256554

Epoch: 5| Step: 4
Training loss: 0.10699740556942842
Validation loss: 2.536797905665442

Epoch: 5| Step: 5
Training loss: 0.11447360373070566
Validation loss: 2.527298340677389

Epoch: 5| Step: 6
Training loss: 0.09492229120139724
Validation loss: 2.515464547793733

Epoch: 5| Step: 7
Training loss: 0.151981853132796
Validation loss: 2.5483194705741106

Epoch: 5| Step: 8
Training loss: 0.1278561242277824
Validation loss: 2.5512158149739768

Epoch: 5| Step: 9
Training loss: 0.33335123783941417
Validation loss: 2.5580486439295225

Epoch: 5| Step: 10
Training loss: 0.18326711004987195
Validation loss: 2.53645812950547

Epoch: 524| Step: 0
Training loss: 0.28122444831491544
Validation loss: 2.5472111281674343

Epoch: 5| Step: 1
Training loss: 0.08650948355983182
Validation loss: 2.514649175605383

Epoch: 5| Step: 2
Training loss: 0.10679679115057711
Validation loss: 2.525420723904747

Epoch: 5| Step: 3
Training loss: 0.1458143806630556
Validation loss: 2.5228766869622765

Epoch: 5| Step: 4
Training loss: 0.18923937153607953
Validation loss: 2.536663186542262

Epoch: 5| Step: 5
Training loss: 0.3629868247449634
Validation loss: 2.5666999922870053

Epoch: 5| Step: 6
Training loss: 0.23780778059368216
Validation loss: 2.5669916236770467

Epoch: 5| Step: 7
Training loss: 0.1532512800955088
Validation loss: 2.5506225038039663

Epoch: 5| Step: 8
Training loss: 0.10978659602579956
Validation loss: 2.563738508882056

Epoch: 5| Step: 9
Training loss: 0.16575428644559714
Validation loss: 2.5781086801538797

Epoch: 5| Step: 10
Training loss: 0.29340016707488403
Validation loss: 2.5512305392938903

Epoch: 525| Step: 0
Training loss: 0.4357204177048622
Validation loss: 2.5699911766057193

Epoch: 5| Step: 1
Training loss: 0.10982523789289965
Validation loss: 2.5217415287136915

Epoch: 5| Step: 2
Training loss: 0.1933825122592204
Validation loss: 2.535229949812769

Epoch: 5| Step: 3
Training loss: 0.12611321127743233
Validation loss: 2.51436011227609

Epoch: 5| Step: 4
Training loss: 0.10937558752992048
Validation loss: 2.5444520313197416

Epoch: 5| Step: 5
Training loss: 0.16944692817567414
Validation loss: 2.5222623158509734

Epoch: 5| Step: 6
Training loss: 0.12351309160847157
Validation loss: 2.5807246004332036

Epoch: 5| Step: 7
Training loss: 0.14179269453459525
Validation loss: 2.5823946056701663

Epoch: 5| Step: 8
Training loss: 0.17408152658617707
Validation loss: 2.575145295445745

Epoch: 5| Step: 9
Training loss: 0.23360090372365144
Validation loss: 2.6064242953339396

Epoch: 5| Step: 10
Training loss: 0.15646532837913277
Validation loss: 2.595632224742451

Epoch: 526| Step: 0
Training loss: 0.3446542485713652
Validation loss: 2.5570014548512456

Epoch: 5| Step: 1
Training loss: 0.20773985891000782
Validation loss: 2.542678809673955

Epoch: 5| Step: 2
Training loss: 0.20110918197758906
Validation loss: 2.520550297958663

Epoch: 5| Step: 3
Training loss: 0.17064030907843303
Validation loss: 2.540467672571661

Epoch: 5| Step: 4
Training loss: 0.22252099630589572
Validation loss: 2.5454985769999783

Epoch: 5| Step: 5
Training loss: 0.12287987244885819
Validation loss: 2.543411655100913

Epoch: 5| Step: 6
Training loss: 0.11809626123726576
Validation loss: 2.5759361762754898

Epoch: 5| Step: 7
Training loss: 0.1900003532983607
Validation loss: 2.559450040220994

Epoch: 5| Step: 8
Training loss: 0.23109166775655823
Validation loss: 2.6167488069641673

Epoch: 5| Step: 9
Training loss: 0.17628304596127917
Validation loss: 2.5833205607479233

Epoch: 5| Step: 10
Training loss: 0.11171113601828067
Validation loss: 2.59210031637193

Epoch: 527| Step: 0
Training loss: 0.22282009621414373
Validation loss: 2.5939162065548023

Epoch: 5| Step: 1
Training loss: 0.3343959636890386
Validation loss: 2.5739362500883822

Epoch: 5| Step: 2
Training loss: 0.1823290218952665
Validation loss: 2.5965350780828316

Epoch: 5| Step: 3
Training loss: 0.23493578895946385
Validation loss: 2.5800473153593804

Epoch: 5| Step: 4
Training loss: 0.2254977115659834
Validation loss: 2.561321150459187

Epoch: 5| Step: 5
Training loss: 0.19239099359302753
Validation loss: 2.5509747935208478

Epoch: 5| Step: 6
Training loss: 0.12602444411539027
Validation loss: 2.543331319939631

Epoch: 5| Step: 7
Training loss: 0.13457150922445235
Validation loss: 2.540183862478681

Epoch: 5| Step: 8
Training loss: 0.24042622728747534
Validation loss: 2.53425161507111

Epoch: 5| Step: 9
Training loss: 0.12462397358322447
Validation loss: 2.523590927465758

Epoch: 5| Step: 10
Training loss: 0.13414587347197204
Validation loss: 2.5231957890830325

Epoch: 528| Step: 0
Training loss: 0.10766050536572214
Validation loss: 2.553468599402719

Epoch: 5| Step: 1
Training loss: 0.15245374963164618
Validation loss: 2.5547768148631174

Epoch: 5| Step: 2
Training loss: 0.3408783040811558
Validation loss: 2.5499907911449253

Epoch: 5| Step: 3
Training loss: 0.20936249902044113
Validation loss: 2.5479049535212166

Epoch: 5| Step: 4
Training loss: 0.12941474036981362
Validation loss: 2.5749053141596923

Epoch: 5| Step: 5
Training loss: 0.15849509788289637
Validation loss: 2.561065858269233

Epoch: 5| Step: 6
Training loss: 0.23078500740747798
Validation loss: 2.584841944335085

Epoch: 5| Step: 7
Training loss: 0.11325810870215867
Validation loss: 2.5634469464335043

Epoch: 5| Step: 8
Training loss: 0.25719124182925884
Validation loss: 2.542206496254656

Epoch: 5| Step: 9
Training loss: 0.20829454100570777
Validation loss: 2.5446999983368217

Epoch: 5| Step: 10
Training loss: 0.13370784326885343
Validation loss: 2.522179355999136

Epoch: 529| Step: 0
Training loss: 0.12323067954452256
Validation loss: 2.553727384651665

Epoch: 5| Step: 1
Training loss: 0.1555565945296369
Validation loss: 2.577573772131511

Epoch: 5| Step: 2
Training loss: 0.21118543323793662
Validation loss: 2.574740090829478

Epoch: 5| Step: 3
Training loss: 0.3193612511543929
Validation loss: 2.5914729442377964

Epoch: 5| Step: 4
Training loss: 0.22831837381628123
Validation loss: 2.6173492425741363

Epoch: 5| Step: 5
Training loss: 0.10397137773482076
Validation loss: 2.622546444438439

Epoch: 5| Step: 6
Training loss: 0.1560909057335142
Validation loss: 2.623896718059075

Epoch: 5| Step: 7
Training loss: 0.1572937732885985
Validation loss: 2.5987001603569944

Epoch: 5| Step: 8
Training loss: 0.2192413737667294
Validation loss: 2.5649660411320956

Epoch: 5| Step: 9
Training loss: 0.12563489075531048
Validation loss: 2.5877131912411713

Epoch: 5| Step: 10
Training loss: 0.19321063129298519
Validation loss: 2.5474994235449846

Epoch: 530| Step: 0
Training loss: 0.09919747101892182
Validation loss: 2.5336888691090933

Epoch: 5| Step: 1
Training loss: 0.2212209871229921
Validation loss: 2.532166247205188

Epoch: 5| Step: 2
Training loss: 0.22145882077281584
Validation loss: 2.5296217647929966

Epoch: 5| Step: 3
Training loss: 0.1252673835826041
Validation loss: 2.5756475184634424

Epoch: 5| Step: 4
Training loss: 0.14822155528678174
Validation loss: 2.572750795805172

Epoch: 5| Step: 5
Training loss: 0.1745318462546058
Validation loss: 2.586017409751988

Epoch: 5| Step: 6
Training loss: 0.14027070077060494
Validation loss: 2.6205854646684084

Epoch: 5| Step: 7
Training loss: 0.19445937755459106
Validation loss: 2.602060416372173

Epoch: 5| Step: 8
Training loss: 0.17082230098115686
Validation loss: 2.6198662483635604

Epoch: 5| Step: 9
Training loss: 0.19038490355687684
Validation loss: 2.577763499958677

Epoch: 5| Step: 10
Training loss: 0.38190602003308644
Validation loss: 2.582406863966929

Epoch: 531| Step: 0
Training loss: 0.211757039200835
Validation loss: 2.5596452984594458

Epoch: 5| Step: 1
Training loss: 0.1418682480982552
Validation loss: 2.5890000600735004

Epoch: 5| Step: 2
Training loss: 0.37510167174112957
Validation loss: 2.5814804083564096

Epoch: 5| Step: 3
Training loss: 0.19540389783484632
Validation loss: 2.5913431124760513

Epoch: 5| Step: 4
Training loss: 0.10960151003831503
Validation loss: 2.585993104287368

Epoch: 5| Step: 5
Training loss: 0.2129272289480596
Validation loss: 2.5830511973792225

Epoch: 5| Step: 6
Training loss: 0.1503901233912438
Validation loss: 2.6033110468556244

Epoch: 5| Step: 7
Training loss: 0.184400147000097
Validation loss: 2.6064554197214966

Epoch: 5| Step: 8
Training loss: 0.16500307853312135
Validation loss: 2.635304329714571

Epoch: 5| Step: 9
Training loss: 0.11269304878169452
Validation loss: 2.6393367690215546

Epoch: 5| Step: 10
Training loss: 0.18672057913039908
Validation loss: 2.6078993046154886

Epoch: 532| Step: 0
Training loss: 0.19013254506879626
Validation loss: 2.607912254515817

Epoch: 5| Step: 1
Training loss: 0.15187793209832645
Validation loss: 2.6291683227113656

Epoch: 5| Step: 2
Training loss: 0.1473924086030215
Validation loss: 2.6199386465094854

Epoch: 5| Step: 3
Training loss: 0.1866767213517518
Validation loss: 2.6210073879830933

Epoch: 5| Step: 4
Training loss: 0.16097186749356784
Validation loss: 2.5941098701502523

Epoch: 5| Step: 5
Training loss: 0.22893414115889132
Validation loss: 2.5962062778804644

Epoch: 5| Step: 6
Training loss: 0.37000206437694877
Validation loss: 2.574363483713029

Epoch: 5| Step: 7
Training loss: 0.11819653025583593
Validation loss: 2.561026280714252

Epoch: 5| Step: 8
Training loss: 0.12008905468987899
Validation loss: 2.5237071972185356

Epoch: 5| Step: 9
Training loss: 0.13455937677471705
Validation loss: 2.543216264884745

Epoch: 5| Step: 10
Training loss: 0.26782842748989977
Validation loss: 2.5432112761348207

Epoch: 533| Step: 0
Training loss: 0.2659709584831669
Validation loss: 2.519297503558616

Epoch: 5| Step: 1
Training loss: 0.19176330156021384
Validation loss: 2.5099005141522497

Epoch: 5| Step: 2
Training loss: 0.32324135771584395
Validation loss: 2.5179553460095883

Epoch: 5| Step: 3
Training loss: 0.17697416942502303
Validation loss: 2.5257591641855144

Epoch: 5| Step: 4
Training loss: 0.12668566038934906
Validation loss: 2.5133673023828873

Epoch: 5| Step: 5
Training loss: 0.26451679066291833
Validation loss: 2.5391336592301847

Epoch: 5| Step: 6
Training loss: 0.11366495557089791
Validation loss: 2.5377688339596296

Epoch: 5| Step: 7
Training loss: 0.17040498064373907
Validation loss: 2.5373910415091645

Epoch: 5| Step: 8
Training loss: 0.19750285283877209
Validation loss: 2.568358620388856

Epoch: 5| Step: 9
Training loss: 0.24089973080694455
Validation loss: 2.5403388206300095

Epoch: 5| Step: 10
Training loss: 0.17983570413960878
Validation loss: 2.565926423725334

Epoch: 534| Step: 0
Training loss: 0.16301268799961605
Validation loss: 2.562294249199209

Epoch: 5| Step: 1
Training loss: 0.2531042049248945
Validation loss: 2.6083226534696125

Epoch: 5| Step: 2
Training loss: 0.21975795097798306
Validation loss: 2.633746470094343

Epoch: 5| Step: 3
Training loss: 0.14860729494745833
Validation loss: 2.581822356017866

Epoch: 5| Step: 4
Training loss: 0.10677509667638459
Validation loss: 2.601584227510421

Epoch: 5| Step: 5
Training loss: 0.3575676375874995
Validation loss: 2.6036026903036498

Epoch: 5| Step: 6
Training loss: 0.17928628079898046
Validation loss: 2.540011722656179

Epoch: 5| Step: 7
Training loss: 0.2074474972634398
Validation loss: 2.513050502317385

Epoch: 5| Step: 8
Training loss: 0.23863939042359913
Validation loss: 2.5034846846089436

Epoch: 5| Step: 9
Training loss: 0.18815597386918828
Validation loss: 2.491744508788425

Epoch: 5| Step: 10
Training loss: 0.20698376776853183
Validation loss: 2.497637348061891

Epoch: 535| Step: 0
Training loss: 0.23650538677256533
Validation loss: 2.5066326438956255

Epoch: 5| Step: 1
Training loss: 0.09538669239095221
Validation loss: 2.549238351433887

Epoch: 5| Step: 2
Training loss: 0.22072034110379243
Validation loss: 2.5896168313059125

Epoch: 5| Step: 3
Training loss: 0.32241052779982987
Validation loss: 2.6001312892413373

Epoch: 5| Step: 4
Training loss: 0.1492678356823557
Validation loss: 2.614525543863289

Epoch: 5| Step: 5
Training loss: 0.23454054707926164
Validation loss: 2.62577662623229

Epoch: 5| Step: 6
Training loss: 0.16194073396418004
Validation loss: 2.585002638855017

Epoch: 5| Step: 7
Training loss: 0.18208414708995185
Validation loss: 2.5965345162911992

Epoch: 5| Step: 8
Training loss: 0.11099356440169836
Validation loss: 2.6087641584065016

Epoch: 5| Step: 9
Training loss: 0.1462927900585558
Validation loss: 2.577726436867978

Epoch: 5| Step: 10
Training loss: 0.2064928034470534
Validation loss: 2.5834796445963186

Epoch: 536| Step: 0
Training loss: 0.18248309347801997
Validation loss: 2.5969992664900663

Epoch: 5| Step: 1
Training loss: 0.328159727801944
Validation loss: 2.5862456503901674

Epoch: 5| Step: 2
Training loss: 0.20239790666695898
Validation loss: 2.6022361625432335

Epoch: 5| Step: 3
Training loss: 0.1333475904056963
Validation loss: 2.5936152886146346

Epoch: 5| Step: 4
Training loss: 0.22524445354076905
Validation loss: 2.6217449494244613

Epoch: 5| Step: 5
Training loss: 0.1347387674078649
Validation loss: 2.5979838503102815

Epoch: 5| Step: 6
Training loss: 0.08540532210753597
Validation loss: 2.591008833867866

Epoch: 5| Step: 7
Training loss: 0.29643695286188176
Validation loss: 2.593999292002515

Epoch: 5| Step: 8
Training loss: 0.09809463333298474
Validation loss: 2.5911253528194726

Epoch: 5| Step: 9
Training loss: 0.12686850588719742
Validation loss: 2.603116237974905

Epoch: 5| Step: 10
Training loss: 0.10861209913329736
Validation loss: 2.600187610944092

Epoch: 537| Step: 0
Training loss: 0.18666560561937248
Validation loss: 2.5770038502517525

Epoch: 5| Step: 1
Training loss: 0.1781294696648625
Validation loss: 2.57256737704113

Epoch: 5| Step: 2
Training loss: 0.15117080007954575
Validation loss: 2.546675458276129

Epoch: 5| Step: 3
Training loss: 0.1557349657384508
Validation loss: 2.5496962761123547

Epoch: 5| Step: 4
Training loss: 0.15035213869756991
Validation loss: 2.5668142274177543

Epoch: 5| Step: 5
Training loss: 0.2201728357818347
Validation loss: 2.5390829843052938

Epoch: 5| Step: 6
Training loss: 0.1319041746645487
Validation loss: 2.5946842492286715

Epoch: 5| Step: 7
Training loss: 0.10526805343731538
Validation loss: 2.571884078763112

Epoch: 5| Step: 8
Training loss: 0.3031811647392197
Validation loss: 2.5842804042716887

Epoch: 5| Step: 9
Training loss: 0.11818567582759626
Validation loss: 2.5687517886745277

Epoch: 5| Step: 10
Training loss: 0.2744801940512687
Validation loss: 2.6056719043044456

Epoch: 538| Step: 0
Training loss: 0.3831322949634427
Validation loss: 2.5872462215516268

Epoch: 5| Step: 1
Training loss: 0.1019474309303143
Validation loss: 2.578828051413539

Epoch: 5| Step: 2
Training loss: 0.18458962717872018
Validation loss: 2.557850373781826

Epoch: 5| Step: 3
Training loss: 0.097376039945071
Validation loss: 2.5722806543917804

Epoch: 5| Step: 4
Training loss: 0.16526246609896283
Validation loss: 2.5346949490222284

Epoch: 5| Step: 5
Training loss: 0.15586481299988153
Validation loss: 2.524653944743999

Epoch: 5| Step: 6
Training loss: 0.2316033994409137
Validation loss: 2.539149793413216

Epoch: 5| Step: 7
Training loss: 0.11272169313456566
Validation loss: 2.585740112151072

Epoch: 5| Step: 8
Training loss: 0.137781914065468
Validation loss: 2.5719715604711277

Epoch: 5| Step: 9
Training loss: 0.1142787099132983
Validation loss: 2.617202445783261

Epoch: 5| Step: 10
Training loss: 0.16020759480553773
Validation loss: 2.6447825494264245

Epoch: 539| Step: 0
Training loss: 0.2773619363759035
Validation loss: 2.6285822889873947

Epoch: 5| Step: 1
Training loss: 0.07853642254662109
Validation loss: 2.5961854158042184

Epoch: 5| Step: 2
Training loss: 0.14456355532893048
Validation loss: 2.5366421046082612

Epoch: 5| Step: 3
Training loss: 0.16455589761901654
Validation loss: 2.561391414068158

Epoch: 5| Step: 4
Training loss: 0.12426923814425489
Validation loss: 2.5371555464147812

Epoch: 5| Step: 5
Training loss: 0.3340789705575072
Validation loss: 2.5421957796325025

Epoch: 5| Step: 6
Training loss: 0.16480168646597942
Validation loss: 2.5310196968618706

Epoch: 5| Step: 7
Training loss: 0.10528789130868106
Validation loss: 2.5565288162685342

Epoch: 5| Step: 8
Training loss: 0.16138647515948998
Validation loss: 2.5886579479055185

Epoch: 5| Step: 9
Training loss: 0.20441658859689463
Validation loss: 2.5773664584785743

Epoch: 5| Step: 10
Training loss: 0.1620234526006014
Validation loss: 2.5911726676222138

Epoch: 540| Step: 0
Training loss: 0.22357954198718963
Validation loss: 2.573677279039302

Epoch: 5| Step: 1
Training loss: 0.1420347100225659
Validation loss: 2.575951204155852

Epoch: 5| Step: 2
Training loss: 0.2880355790946832
Validation loss: 2.5378672421890776

Epoch: 5| Step: 3
Training loss: 0.31700285249022364
Validation loss: 2.523014013892845

Epoch: 5| Step: 4
Training loss: 0.1037931141835983
Validation loss: 2.526343754697201

Epoch: 5| Step: 5
Training loss: 0.1544467885845441
Validation loss: 2.52720039431389

Epoch: 5| Step: 6
Training loss: 0.0734368027491645
Validation loss: 2.54746023047773

Epoch: 5| Step: 7
Training loss: 0.13817217614549698
Validation loss: 2.548248937072264

Epoch: 5| Step: 8
Training loss: 0.1320136320898535
Validation loss: 2.5507444421050054

Epoch: 5| Step: 9
Training loss: 0.132518906616448
Validation loss: 2.5263611111471

Epoch: 5| Step: 10
Training loss: 0.1376742624195541
Validation loss: 2.5869857011439654

Epoch: 541| Step: 0
Training loss: 0.1435727088671354
Validation loss: 2.542575890077215

Epoch: 5| Step: 1
Training loss: 0.1665511805300558
Validation loss: 2.563106503107316

Epoch: 5| Step: 2
Training loss: 0.10893138260279282
Validation loss: 2.5652583008743446

Epoch: 5| Step: 3
Training loss: 0.13081838905376167
Validation loss: 2.56449676879656

Epoch: 5| Step: 4
Training loss: 0.11849435248226552
Validation loss: 2.5428488332480996

Epoch: 5| Step: 5
Training loss: 0.16562125543643916
Validation loss: 2.544047629514827

Epoch: 5| Step: 6
Training loss: 0.30386215076325246
Validation loss: 2.540184146073498

Epoch: 5| Step: 7
Training loss: 0.19131734301279732
Validation loss: 2.492686707170173

Epoch: 5| Step: 8
Training loss: 0.21761293013021438
Validation loss: 2.490431713928765

Epoch: 5| Step: 9
Training loss: 0.2280745692228451
Validation loss: 2.5036383763869545

Epoch: 5| Step: 10
Training loss: 0.18147657020460772
Validation loss: 2.4904598533409428

Epoch: 542| Step: 0
Training loss: 0.15554872138107284
Validation loss: 2.4939359079705197

Epoch: 5| Step: 1
Training loss: 0.13087522353806302
Validation loss: 2.5422447013963088

Epoch: 5| Step: 2
Training loss: 0.11994820625672171
Validation loss: 2.515912240776261

Epoch: 5| Step: 3
Training loss: 0.21172712140582958
Validation loss: 2.562567747747706

Epoch: 5| Step: 4
Training loss: 0.18588053167189014
Validation loss: 2.5648411606538706

Epoch: 5| Step: 5
Training loss: 0.2012820821566319
Validation loss: 2.579931920262987

Epoch: 5| Step: 6
Training loss: 0.14855758302059954
Validation loss: 2.5720673194997357

Epoch: 5| Step: 7
Training loss: 0.21112390511750018
Validation loss: 2.5955305628620797

Epoch: 5| Step: 8
Training loss: 0.16759989959349902
Validation loss: 2.5939934511631355

Epoch: 5| Step: 9
Training loss: 0.14390442214368274
Validation loss: 2.6069514063809462

Epoch: 5| Step: 10
Training loss: 0.3312489212666347
Validation loss: 2.6176617053952427

Epoch: 543| Step: 0
Training loss: 0.14681469866444818
Validation loss: 2.621285796891456

Epoch: 5| Step: 1
Training loss: 0.18638089110621736
Validation loss: 2.6295757776201483

Epoch: 5| Step: 2
Training loss: 0.31786727317002406
Validation loss: 2.6350523131669306

Epoch: 5| Step: 3
Training loss: 0.17486577058961222
Validation loss: 2.6375480637756117

Epoch: 5| Step: 4
Training loss: 0.16052116132434935
Validation loss: 2.657734087034819

Epoch: 5| Step: 5
Training loss: 0.2969740024926262
Validation loss: 2.637435354601022

Epoch: 5| Step: 6
Training loss: 0.18186372980940466
Validation loss: 2.5958459803812497

Epoch: 5| Step: 7
Training loss: 0.12602284786196863
Validation loss: 2.616219091284613

Epoch: 5| Step: 8
Training loss: 0.18172201773607433
Validation loss: 2.61433061993745

Epoch: 5| Step: 9
Training loss: 0.10847661919157904
Validation loss: 2.5571790335849607

Epoch: 5| Step: 10
Training loss: 0.19988858986758354
Validation loss: 2.50624776439185

Epoch: 544| Step: 0
Training loss: 0.3409668571846865
Validation loss: 2.5030254167278367

Epoch: 5| Step: 1
Training loss: 0.17001926437435863
Validation loss: 2.4991668153652733

Epoch: 5| Step: 2
Training loss: 0.23331448309970426
Validation loss: 2.5217867625989747

Epoch: 5| Step: 3
Training loss: 0.23257007201799756
Validation loss: 2.5376929257841327

Epoch: 5| Step: 4
Training loss: 0.2075389808067306
Validation loss: 2.5525174128169366

Epoch: 5| Step: 5
Training loss: 0.126806254894917
Validation loss: 2.590664563517112

Epoch: 5| Step: 6
Training loss: 0.16771686319512763
Validation loss: 2.556333487965275

Epoch: 5| Step: 7
Training loss: 0.255783870709229
Validation loss: 2.5729088682053427

Epoch: 5| Step: 8
Training loss: 0.1934424327905451
Validation loss: 2.6012441237137187

Epoch: 5| Step: 9
Training loss: 0.16189895899955156
Validation loss: 2.564978914444254

Epoch: 5| Step: 10
Training loss: 0.18972568961797412
Validation loss: 2.5592367331695263

Epoch: 545| Step: 0
Training loss: 0.20621686582575988
Validation loss: 2.564605869040822

Epoch: 5| Step: 1
Training loss: 0.1373666262751593
Validation loss: 2.551881218533549

Epoch: 5| Step: 2
Training loss: 0.14399628610134768
Validation loss: 2.5407762058640544

Epoch: 5| Step: 3
Training loss: 0.18349756602640177
Validation loss: 2.5548164049406292

Epoch: 5| Step: 4
Training loss: 0.19370341279233944
Validation loss: 2.563048563380887

Epoch: 5| Step: 5
Training loss: 0.17762731115124844
Validation loss: 2.5541955938977736

Epoch: 5| Step: 6
Training loss: 0.18018733868838158
Validation loss: 2.540062754505572

Epoch: 5| Step: 7
Training loss: 0.22866342117744615
Validation loss: 2.5185937013271467

Epoch: 5| Step: 8
Training loss: 0.16322556531759735
Validation loss: 2.501065863770614

Epoch: 5| Step: 9
Training loss: 0.34186505318909094
Validation loss: 2.4612800293356694

Epoch: 5| Step: 10
Training loss: 0.2661544627951178
Validation loss: 2.521536861546441

Epoch: 546| Step: 0
Training loss: 0.3984271029443482
Validation loss: 2.5207229857233004

Epoch: 5| Step: 1
Training loss: 0.12051444537736478
Validation loss: 2.575453667042915

Epoch: 5| Step: 2
Training loss: 0.14168176681553532
Validation loss: 2.5653865532386275

Epoch: 5| Step: 3
Training loss: 0.162954391604055
Validation loss: 2.55172431300642

Epoch: 5| Step: 4
Training loss: 0.1642223215486054
Validation loss: 2.5570818648316997

Epoch: 5| Step: 5
Training loss: 0.216064366917135
Validation loss: 2.545715115729771

Epoch: 5| Step: 6
Training loss: 0.1635002310515005
Validation loss: 2.547354185985192

Epoch: 5| Step: 7
Training loss: 0.1204962486827286
Validation loss: 2.5238470823717645

Epoch: 5| Step: 8
Training loss: 0.1656891979549985
Validation loss: 2.5426420700056713

Epoch: 5| Step: 9
Training loss: 0.1220305950401206
Validation loss: 2.5536323137626034

Epoch: 5| Step: 10
Training loss: 0.15969368963693928
Validation loss: 2.560345836507331

Epoch: 547| Step: 0
Training loss: 0.12856413496755373
Validation loss: 2.5882543229102266

Epoch: 5| Step: 1
Training loss: 0.1349253606207967
Validation loss: 2.5812799812468135

Epoch: 5| Step: 2
Training loss: 0.15676438776708765
Validation loss: 2.56768093998501

Epoch: 5| Step: 3
Training loss: 0.16503564842349552
Validation loss: 2.5747479413281935

Epoch: 5| Step: 4
Training loss: 0.14913714059603042
Validation loss: 2.5577933653883016

Epoch: 5| Step: 5
Training loss: 0.11987008287296508
Validation loss: 2.572850962894259

Epoch: 5| Step: 6
Training loss: 0.18206093468338563
Validation loss: 2.555862522310907

Epoch: 5| Step: 7
Training loss: 0.1739767489327154
Validation loss: 2.5908743312252227

Epoch: 5| Step: 8
Training loss: 0.40020513192040996
Validation loss: 2.577391652465279

Epoch: 5| Step: 9
Training loss: 0.19527853670461887
Validation loss: 2.5818651715065233

Epoch: 5| Step: 10
Training loss: 0.15400924915244876
Validation loss: 2.5666664141380635

Epoch: 548| Step: 0
Training loss: 0.1298749462413034
Validation loss: 2.6095526388369206

Epoch: 5| Step: 1
Training loss: 0.21799808940520485
Validation loss: 2.5604922004365913

Epoch: 5| Step: 2
Training loss: 0.21764849170404943
Validation loss: 2.5694115533989734

Epoch: 5| Step: 3
Training loss: 0.12508188486255972
Validation loss: 2.532170950949795

Epoch: 5| Step: 4
Training loss: 0.2049157544355292
Validation loss: 2.5335463369012294

Epoch: 5| Step: 5
Training loss: 0.34799500366781505
Validation loss: 2.5219243460885017

Epoch: 5| Step: 6
Training loss: 0.23631917132606184
Validation loss: 2.506402668591403

Epoch: 5| Step: 7
Training loss: 0.16711380082841895
Validation loss: 2.552916264342606

Epoch: 5| Step: 8
Training loss: 0.1508942753639709
Validation loss: 2.5578867827569223

Epoch: 5| Step: 9
Training loss: 0.16268430010835766
Validation loss: 2.5782189812905822

Epoch: 5| Step: 10
Training loss: 0.1276563607405669
Validation loss: 2.5981144149072746

Epoch: 549| Step: 0
Training loss: 0.17037798515008046
Validation loss: 2.5612001601366683

Epoch: 5| Step: 1
Training loss: 0.19888554551453674
Validation loss: 2.6122091100085174

Epoch: 5| Step: 2
Training loss: 0.14278415921470805
Validation loss: 2.5833741408772655

Epoch: 5| Step: 3
Training loss: 0.15846389307083958
Validation loss: 2.584407621395201

Epoch: 5| Step: 4
Training loss: 0.22352130891998986
Validation loss: 2.5511135573375

Epoch: 5| Step: 5
Training loss: 0.13642483863149937
Validation loss: 2.5467000629824383

Epoch: 5| Step: 6
Training loss: 0.20422643282214095
Validation loss: 2.563923470148415

Epoch: 5| Step: 7
Training loss: 0.1283336696321036
Validation loss: 2.544502473377456

Epoch: 5| Step: 8
Training loss: 0.11493908904923408
Validation loss: 2.539421949918895

Epoch: 5| Step: 9
Training loss: 0.33285787568575925
Validation loss: 2.561057742605469

Epoch: 5| Step: 10
Training loss: 0.1401258058984196
Validation loss: 2.559624573075943

Epoch: 550| Step: 0
Training loss: 0.14831066987362926
Validation loss: 2.57233217610982

Epoch: 5| Step: 1
Training loss: 0.19995752494509764
Validation loss: 2.549902651338316

Epoch: 5| Step: 2
Training loss: 0.18032374935329934
Validation loss: 2.568915271524679

Epoch: 5| Step: 3
Training loss: 0.060768180602889146
Validation loss: 2.564585323694002

Epoch: 5| Step: 4
Training loss: 0.1705265358239542
Validation loss: 2.587589227264353

Epoch: 5| Step: 5
Training loss: 0.13649730459545778
Validation loss: 2.5954753653865095

Epoch: 5| Step: 6
Training loss: 0.30674257223825424
Validation loss: 2.5835843660591333

Epoch: 5| Step: 7
Training loss: 0.15051041204572324
Validation loss: 2.6096169939985208

Epoch: 5| Step: 8
Training loss: 0.19002770275261077
Validation loss: 2.603007761035881

Epoch: 5| Step: 9
Training loss: 0.1990347554860501
Validation loss: 2.5632959972099303

Epoch: 5| Step: 10
Training loss: 0.1463716709172108
Validation loss: 2.5747128257305794

Epoch: 551| Step: 0
Training loss: 0.23892246801292646
Validation loss: 2.565278206736401

Epoch: 5| Step: 1
Training loss: 0.07883195495374948
Validation loss: 2.5910335251566

Epoch: 5| Step: 2
Training loss: 0.11560288601191333
Validation loss: 2.5742416892452735

Epoch: 5| Step: 3
Training loss: 0.15091634489567896
Validation loss: 2.577151487428139

Epoch: 5| Step: 4
Training loss: 0.1376347307083546
Validation loss: 2.567797996830678

Epoch: 5| Step: 5
Training loss: 0.3249368413664256
Validation loss: 2.571764497988824

Epoch: 5| Step: 6
Training loss: 0.18410985518827272
Validation loss: 2.5878987739049273

Epoch: 5| Step: 7
Training loss: 0.07106268552526951
Validation loss: 2.5785186283121493

Epoch: 5| Step: 8
Training loss: 0.16549386892854337
Validation loss: 2.607237093986517

Epoch: 5| Step: 9
Training loss: 0.16050627304085302
Validation loss: 2.583051742253657

Epoch: 5| Step: 10
Training loss: 0.11992216172323836
Validation loss: 2.6125620669013143

Epoch: 552| Step: 0
Training loss: 0.0775506304032001
Validation loss: 2.614341596870822

Epoch: 5| Step: 1
Training loss: 0.10685022579376996
Validation loss: 2.6288490183739786

Epoch: 5| Step: 2
Training loss: 0.19086357961513337
Validation loss: 2.5955436129941907

Epoch: 5| Step: 3
Training loss: 0.14082252352562052
Validation loss: 2.6142328865236815

Epoch: 5| Step: 4
Training loss: 0.11585532603195096
Validation loss: 2.6198776492936924

Epoch: 5| Step: 5
Training loss: 0.13222708427292443
Validation loss: 2.6188243700633675

Epoch: 5| Step: 6
Training loss: 0.1120849782203789
Validation loss: 2.5742542124293673

Epoch: 5| Step: 7
Training loss: 0.20820849771348734
Validation loss: 2.6206645876787205

Epoch: 5| Step: 8
Training loss: 0.15817640808944428
Validation loss: 2.5577095779127395

Epoch: 5| Step: 9
Training loss: 0.2285161466674067
Validation loss: 2.5952450747420204

Epoch: 5| Step: 10
Training loss: 0.3147261009293413
Validation loss: 2.545527418942871

Epoch: 553| Step: 0
Training loss: 0.1334485014527789
Validation loss: 2.554895118670389

Epoch: 5| Step: 1
Training loss: 0.11532072291221386
Validation loss: 2.544947362473455

Epoch: 5| Step: 2
Training loss: 0.18000420358504593
Validation loss: 2.5710341169339745

Epoch: 5| Step: 3
Training loss: 0.08974632910696556
Validation loss: 2.5712850893505106

Epoch: 5| Step: 4
Training loss: 0.1872948975137637
Validation loss: 2.5882639078664944

Epoch: 5| Step: 5
Training loss: 0.30222173786786793
Validation loss: 2.5716964557035094

Epoch: 5| Step: 6
Training loss: 0.22559333557944775
Validation loss: 2.597049944555521

Epoch: 5| Step: 7
Training loss: 0.09856716180630558
Validation loss: 2.6036133648859354

Epoch: 5| Step: 8
Training loss: 0.1794984071336803
Validation loss: 2.6079380971087303

Epoch: 5| Step: 9
Training loss: 0.05766022618404975
Validation loss: 2.601431690620197

Epoch: 5| Step: 10
Training loss: 0.11203312174644686
Validation loss: 2.579852348685251

Epoch: 554| Step: 0
Training loss: 0.19506574301940455
Validation loss: 2.580740432877746

Epoch: 5| Step: 1
Training loss: 0.15224057151464152
Validation loss: 2.59173692868424

Epoch: 5| Step: 2
Training loss: 0.29565871949672
Validation loss: 2.57917147889148

Epoch: 5| Step: 3
Training loss: 0.12179760798734725
Validation loss: 2.557230343396786

Epoch: 5| Step: 4
Training loss: 0.2265819015088239
Validation loss: 2.536663544307032

Epoch: 5| Step: 5
Training loss: 0.1257661792659027
Validation loss: 2.5490268102885256

Epoch: 5| Step: 6
Training loss: 0.13037259390321507
Validation loss: 2.5432906322867157

Epoch: 5| Step: 7
Training loss: 0.11922195660239694
Validation loss: 2.5597780599255606

Epoch: 5| Step: 8
Training loss: 0.09471115498249169
Validation loss: 2.5464176341315303

Epoch: 5| Step: 9
Training loss: 0.11854241227478071
Validation loss: 2.5305138229795694

Epoch: 5| Step: 10
Training loss: 0.1678521172769783
Validation loss: 2.518141491451473

Epoch: 555| Step: 0
Training loss: 0.33383588110985846
Validation loss: 2.5308585411777837

Epoch: 5| Step: 1
Training loss: 0.1893766386445915
Validation loss: 2.5349747327517105

Epoch: 5| Step: 2
Training loss: 0.20105766091113014
Validation loss: 2.5355612519500808

Epoch: 5| Step: 3
Training loss: 0.10567320768228648
Validation loss: 2.5359726777554403

Epoch: 5| Step: 4
Training loss: 0.21541477957611604
Validation loss: 2.5607864544259327

Epoch: 5| Step: 5
Training loss: 0.07001945237563624
Validation loss: 2.595703727958948

Epoch: 5| Step: 6
Training loss: 0.05616268809031488
Validation loss: 2.5678617875899112

Epoch: 5| Step: 7
Training loss: 0.10126906425199182
Validation loss: 2.5631160580802805

Epoch: 5| Step: 8
Training loss: 0.19280288069485257
Validation loss: 2.5664064517823126

Epoch: 5| Step: 9
Training loss: 0.06268366262751031
Validation loss: 2.5669658712092893

Epoch: 5| Step: 10
Training loss: 0.1322830530301034
Validation loss: 2.58425433303759

Epoch: 556| Step: 0
Training loss: 0.1796109928126273
Validation loss: 2.596323207865208

Epoch: 5| Step: 1
Training loss: 0.15504910800536406
Validation loss: 2.5592214658974664

Epoch: 5| Step: 2
Training loss: 0.16437964780023848
Validation loss: 2.581405356525875

Epoch: 5| Step: 3
Training loss: 0.12346809059460355
Validation loss: 2.563654477712966

Epoch: 5| Step: 4
Training loss: 0.13779020759525007
Validation loss: 2.5761949799573722

Epoch: 5| Step: 5
Training loss: 0.12663418982344724
Validation loss: 2.573603146197252

Epoch: 5| Step: 6
Training loss: 0.11243520698732558
Validation loss: 2.5760266587136456

Epoch: 5| Step: 7
Training loss: 0.13929513107551747
Validation loss: 2.605320152200796

Epoch: 5| Step: 8
Training loss: 0.28123692641072373
Validation loss: 2.603324057492782

Epoch: 5| Step: 9
Training loss: 0.20117955054297404
Validation loss: 2.569041956742393

Epoch: 5| Step: 10
Training loss: 0.13083279752570987
Validation loss: 2.5547967115790597

Epoch: 557| Step: 0
Training loss: 0.2902485768269321
Validation loss: 2.5710977581043517

Epoch: 5| Step: 1
Training loss: 0.1166285216892453
Validation loss: 2.5624306387009037

Epoch: 5| Step: 2
Training loss: 0.17832687675034525
Validation loss: 2.580546421367097

Epoch: 5| Step: 3
Training loss: 0.09943811335545327
Validation loss: 2.5646141019278472

Epoch: 5| Step: 4
Training loss: 0.20577431537468865
Validation loss: 2.580504001004858

Epoch: 5| Step: 5
Training loss: 0.13077794573311557
Validation loss: 2.5656486363555158

Epoch: 5| Step: 6
Training loss: 0.18504962547130865
Validation loss: 2.592029493616576

Epoch: 5| Step: 7
Training loss: 0.14024806500398806
Validation loss: 2.580073121079136

Epoch: 5| Step: 8
Training loss: 0.10666949174894318
Validation loss: 2.597875106761588

Epoch: 5| Step: 9
Training loss: 0.19293058419506773
Validation loss: 2.566828586601964

Epoch: 5| Step: 10
Training loss: 0.16280115126450526
Validation loss: 2.6223192013239904

Epoch: 558| Step: 0
Training loss: 0.22059579788362013
Validation loss: 2.5996436222705355

Epoch: 5| Step: 1
Training loss: 0.20062141661845562
Validation loss: 2.612918404224022

Epoch: 5| Step: 2
Training loss: 0.16384612869967555
Validation loss: 2.609911936038565

Epoch: 5| Step: 3
Training loss: 0.13099752791361746
Validation loss: 2.599881570554675

Epoch: 5| Step: 4
Training loss: 0.1774122966933982
Validation loss: 2.5749320744349404

Epoch: 5| Step: 5
Training loss: 0.20865920429329302
Validation loss: 2.547388477605704

Epoch: 5| Step: 6
Training loss: 0.3181039569580145
Validation loss: 2.570130888211141

Epoch: 5| Step: 7
Training loss: 0.13318368288824006
Validation loss: 2.554938096924695

Epoch: 5| Step: 8
Training loss: 0.19079496123510223
Validation loss: 2.5457473131588446

Epoch: 5| Step: 9
Training loss: 0.14432814219566475
Validation loss: 2.5688640643708913

Epoch: 5| Step: 10
Training loss: 0.17089024115389667
Validation loss: 2.5901051568188276

Epoch: 559| Step: 0
Training loss: 0.11822866612663128
Validation loss: 2.5995429560202097

Epoch: 5| Step: 1
Training loss: 0.24788157895303145
Validation loss: 2.639146529140096

Epoch: 5| Step: 2
Training loss: 0.16458472515877784
Validation loss: 2.6902393622809493

Epoch: 5| Step: 3
Training loss: 0.18797181292644133
Validation loss: 2.663522417016239

Epoch: 5| Step: 4
Training loss: 0.13240611789994788
Validation loss: 2.6384232330594344

Epoch: 5| Step: 5
Training loss: 0.1272342942827979
Validation loss: 2.598174783409386

Epoch: 5| Step: 6
Training loss: 0.15359710200737442
Validation loss: 2.590832865383794

Epoch: 5| Step: 7
Training loss: 0.16388022992651075
Validation loss: 2.530376889902784

Epoch: 5| Step: 8
Training loss: 0.12622992594391363
Validation loss: 2.5334761176433296

Epoch: 5| Step: 9
Training loss: 0.22058851084855577
Validation loss: 2.512105118068686

Epoch: 5| Step: 10
Training loss: 0.2111879116295932
Validation loss: 2.5489526494681334

Epoch: 560| Step: 0
Training loss: 0.1910387130545035
Validation loss: 2.5586171389377057

Epoch: 5| Step: 1
Training loss: 0.11019754633351622
Validation loss: 2.5924504322317037

Epoch: 5| Step: 2
Training loss: 0.1932709906128771
Validation loss: 2.628089591071596

Epoch: 5| Step: 3
Training loss: 0.2070638073207209
Validation loss: 2.6325467175353494

Epoch: 5| Step: 4
Training loss: 0.13552923445008797
Validation loss: 2.623930046487502

Epoch: 5| Step: 5
Training loss: 0.12465459069031996
Validation loss: 2.5910078755977195

Epoch: 5| Step: 6
Training loss: 0.157656242419754
Validation loss: 2.613885231265133

Epoch: 5| Step: 7
Training loss: 0.10950303672772164
Validation loss: 2.613571332132769

Epoch: 5| Step: 8
Training loss: 0.10029648363292884
Validation loss: 2.55244539332438

Epoch: 5| Step: 9
Training loss: 0.2536832270124945
Validation loss: 2.5644607760637466

Epoch: 5| Step: 10
Training loss: 0.184249134259668
Validation loss: 2.5480256708948965

Epoch: 561| Step: 0
Training loss: 0.10062854290435315
Validation loss: 2.543956752361901

Epoch: 5| Step: 1
Training loss: 0.1972298353607016
Validation loss: 2.5504778371066945

Epoch: 5| Step: 2
Training loss: 0.13009217962453
Validation loss: 2.5638844211591154

Epoch: 5| Step: 3
Training loss: 0.19103134184226236
Validation loss: 2.543653461726438

Epoch: 5| Step: 4
Training loss: 0.2810273083571917
Validation loss: 2.5576540749040837

Epoch: 5| Step: 5
Training loss: 0.18518028183798926
Validation loss: 2.5636729335468824

Epoch: 5| Step: 6
Training loss: 0.14653273737781594
Validation loss: 2.592532765164855

Epoch: 5| Step: 7
Training loss: 0.2020728757862725
Validation loss: 2.5577328306030656

Epoch: 5| Step: 8
Training loss: 0.15363182324581529
Validation loss: 2.570830423538902

Epoch: 5| Step: 9
Training loss: 0.1548308656992551
Validation loss: 2.5603407429560225

Epoch: 5| Step: 10
Training loss: 0.09441353506967606
Validation loss: 2.547309216405344

Epoch: 562| Step: 0
Training loss: 0.20964600652796028
Validation loss: 2.5523099964802385

Epoch: 5| Step: 1
Training loss: 0.1388714522767853
Validation loss: 2.5627690305830924

Epoch: 5| Step: 2
Training loss: 0.10270227884553122
Validation loss: 2.5686113428355735

Epoch: 5| Step: 3
Training loss: 0.2842202698350801
Validation loss: 2.591235382335018

Epoch: 5| Step: 4
Training loss: 0.10677560256758062
Validation loss: 2.6165881290201227

Epoch: 5| Step: 5
Training loss: 0.1804636281595402
Validation loss: 2.609612708353738

Epoch: 5| Step: 6
Training loss: 0.18990549174564322
Validation loss: 2.629656463171408

Epoch: 5| Step: 7
Training loss: 0.1258506589318713
Validation loss: 2.6369656316042476

Epoch: 5| Step: 8
Training loss: 0.11376089873737312
Validation loss: 2.602024671805864

Epoch: 5| Step: 9
Training loss: 0.12405702556643655
Validation loss: 2.5777441276060222

Epoch: 5| Step: 10
Training loss: 0.12628198902958884
Validation loss: 2.586965238400464

Epoch: 563| Step: 0
Training loss: 0.1861365535075938
Validation loss: 2.58289740520113

Epoch: 5| Step: 1
Training loss: 0.1954315394989166
Validation loss: 2.5611809537811006

Epoch: 5| Step: 2
Training loss: 0.11473108152841707
Validation loss: 2.554707393397562

Epoch: 5| Step: 3
Training loss: 0.13799084406563056
Validation loss: 2.5662795575432904

Epoch: 5| Step: 4
Training loss: 0.1974303530316949
Validation loss: 2.594074317452612

Epoch: 5| Step: 5
Training loss: 0.23103032955139569
Validation loss: 2.604784044158006

Epoch: 5| Step: 6
Training loss: 0.11645292683979527
Validation loss: 2.6205251223119346

Epoch: 5| Step: 7
Training loss: 0.14799901546009037
Validation loss: 2.616692723667736

Epoch: 5| Step: 8
Training loss: 0.2364332501233433
Validation loss: 2.582413338563747

Epoch: 5| Step: 9
Training loss: 0.167369004684916
Validation loss: 2.563071690617798

Epoch: 5| Step: 10
Training loss: 0.08117083190857231
Validation loss: 2.5764794829379722

Epoch: 564| Step: 0
Training loss: 0.1821418737136514
Validation loss: 2.5648917989403928

Epoch: 5| Step: 1
Training loss: 0.2432788899478108
Validation loss: 2.5502501147713854

Epoch: 5| Step: 2
Training loss: 0.17271813668711036
Validation loss: 2.5336862171237984

Epoch: 5| Step: 3
Training loss: 0.09497608669683023
Validation loss: 2.5356443325804316

Epoch: 5| Step: 4
Training loss: 0.1535967139484899
Validation loss: 2.5589593156029222

Epoch: 5| Step: 5
Training loss: 0.10181533081142383
Validation loss: 2.604479777719518

Epoch: 5| Step: 6
Training loss: 0.12691825241024765
Validation loss: 2.5875556606119745

Epoch: 5| Step: 7
Training loss: 0.10056576480242323
Validation loss: 2.600685256267157

Epoch: 5| Step: 8
Training loss: 0.15053108393822512
Validation loss: 2.6261646286984845

Epoch: 5| Step: 9
Training loss: 0.10793845207035231
Validation loss: 2.595610665686567

Epoch: 5| Step: 10
Training loss: 0.2531165092127379
Validation loss: 2.592656757774493

Epoch: 565| Step: 0
Training loss: 0.07332273504678465
Validation loss: 2.5456807960294165

Epoch: 5| Step: 1
Training loss: 0.11917034935290385
Validation loss: 2.565086530507468

Epoch: 5| Step: 2
Training loss: 0.09268216612581284
Validation loss: 2.5217153080394947

Epoch: 5| Step: 3
Training loss: 0.16249695371560133
Validation loss: 2.565853378313305

Epoch: 5| Step: 4
Training loss: 0.13105532934540484
Validation loss: 2.5233002794279917

Epoch: 5| Step: 5
Training loss: 0.1600482215802354
Validation loss: 2.5666899162915358

Epoch: 5| Step: 6
Training loss: 0.2471093309072575
Validation loss: 2.600484633418314

Epoch: 5| Step: 7
Training loss: 0.23565498357325546
Validation loss: 2.6036883318912794

Epoch: 5| Step: 8
Training loss: 0.15510654477315358
Validation loss: 2.611293225936412

Epoch: 5| Step: 9
Training loss: 0.10875832039420105
Validation loss: 2.581513990446582

Epoch: 5| Step: 10
Training loss: 0.17901568667975187
Validation loss: 2.5888923101666483

Epoch: 566| Step: 0
Training loss: 0.183533212136501
Validation loss: 2.5815934626453774

Epoch: 5| Step: 1
Training loss: 0.09148519440698512
Validation loss: 2.5432076169727647

Epoch: 5| Step: 2
Training loss: 0.12184909230354164
Validation loss: 2.567019445160042

Epoch: 5| Step: 3
Training loss: 0.09765205851142829
Validation loss: 2.5669901436112443

Epoch: 5| Step: 4
Training loss: 0.150804939780859
Validation loss: 2.554270022027713

Epoch: 5| Step: 5
Training loss: 0.23662630296641624
Validation loss: 2.57696927673628

Epoch: 5| Step: 6
Training loss: 0.08136020668913133
Validation loss: 2.5468298709690322

Epoch: 5| Step: 7
Training loss: 0.16522655896938934
Validation loss: 2.5437211848284744

Epoch: 5| Step: 8
Training loss: 0.19228243266473044
Validation loss: 2.548498106940402

Epoch: 5| Step: 9
Training loss: 0.10187126413908361
Validation loss: 2.521602749811081

Epoch: 5| Step: 10
Training loss: 0.14183779118281845
Validation loss: 2.5357278715083216

Epoch: 567| Step: 0
Training loss: 0.1210810131634823
Validation loss: 2.5079736502881165

Epoch: 5| Step: 1
Training loss: 0.19083695509928927
Validation loss: 2.523453387092927

Epoch: 5| Step: 2
Training loss: 0.11200377328857006
Validation loss: 2.5190321093138155

Epoch: 5| Step: 3
Training loss: 0.21697741371492998
Validation loss: 2.5275137198558117

Epoch: 5| Step: 4
Training loss: 0.27303177842303766
Validation loss: 2.5369989942875364

Epoch: 5| Step: 5
Training loss: 0.1480256062833614
Validation loss: 2.573926068955729

Epoch: 5| Step: 6
Training loss: 0.12440191550969729
Validation loss: 2.5917954872412565

Epoch: 5| Step: 7
Training loss: 0.09021932943010717
Validation loss: 2.6076332632471058

Epoch: 5| Step: 8
Training loss: 0.1273908697608104
Validation loss: 2.6009124256040703

Epoch: 5| Step: 9
Training loss: 0.14577278231185234
Validation loss: 2.582029441969508

Epoch: 5| Step: 10
Training loss: 0.16514856892663582
Validation loss: 2.6200619625021644

Epoch: 568| Step: 0
Training loss: 0.1379444087665883
Validation loss: 2.602414391122352

Epoch: 5| Step: 1
Training loss: 0.1861004852370076
Validation loss: 2.598824955165895

Epoch: 5| Step: 2
Training loss: 0.19360957671367304
Validation loss: 2.5741958165257075

Epoch: 5| Step: 3
Training loss: 0.10824929536508632
Validation loss: 2.5653739577855754

Epoch: 5| Step: 4
Training loss: 0.1551938962835778
Validation loss: 2.5292387557478015

Epoch: 5| Step: 5
Training loss: 0.19775937861653287
Validation loss: 2.5366642396237284

Epoch: 5| Step: 6
Training loss: 0.08972632986461224
Validation loss: 2.546104535559271

Epoch: 5| Step: 7
Training loss: 0.0754723492597326
Validation loss: 2.5607656817148667

Epoch: 5| Step: 8
Training loss: 0.13960066558449002
Validation loss: 2.566018119328009

Epoch: 5| Step: 9
Training loss: 0.230803852214205
Validation loss: 2.562535361489438

Epoch: 5| Step: 10
Training loss: 0.16094135701085308
Validation loss: 2.558798888135738

Epoch: 569| Step: 0
Training loss: 0.1541294444960091
Validation loss: 2.550528459523456

Epoch: 5| Step: 1
Training loss: 0.2845141091543875
Validation loss: 2.5301315386814625

Epoch: 5| Step: 2
Training loss: 0.18192001103690733
Validation loss: 2.523047614651851

Epoch: 5| Step: 3
Training loss: 0.09260374410877575
Validation loss: 2.5020350407869505

Epoch: 5| Step: 4
Training loss: 0.18431194326291447
Validation loss: 2.564760270757584

Epoch: 5| Step: 5
Training loss: 0.18242363694052788
Validation loss: 2.545558441945937

Epoch: 5| Step: 6
Training loss: 0.14106018889185687
Validation loss: 2.5417807543516933

Epoch: 5| Step: 7
Training loss: 0.11351213275239648
Validation loss: 2.5701326936397835

Epoch: 5| Step: 8
Training loss: 0.14181034218595281
Validation loss: 2.5690433667712234

Epoch: 5| Step: 9
Training loss: 0.12152445628721027
Validation loss: 2.5510239016726834

Epoch: 5| Step: 10
Training loss: 0.13278255405535316
Validation loss: 2.5765493809322435

Epoch: 570| Step: 0
Training loss: 0.13106642185895853
Validation loss: 2.5516892563161084

Epoch: 5| Step: 1
Training loss: 0.1921811378015191
Validation loss: 2.567433774603473

Epoch: 5| Step: 2
Training loss: 0.19402865936397895
Validation loss: 2.5669021695437317

Epoch: 5| Step: 3
Training loss: 0.16628075353766622
Validation loss: 2.540317644061403

Epoch: 5| Step: 4
Training loss: 0.14370884046919477
Validation loss: 2.564588868385351

Epoch: 5| Step: 5
Training loss: 0.244788523241246
Validation loss: 2.5746426199831483

Epoch: 5| Step: 6
Training loss: 0.1856600566795445
Validation loss: 2.5690812394269433

Epoch: 5| Step: 7
Training loss: 0.1799032740185302
Validation loss: 2.5684387157345334

Epoch: 5| Step: 8
Training loss: 0.14281057326229554
Validation loss: 2.560439602300669

Epoch: 5| Step: 9
Training loss: 0.14245107293918244
Validation loss: 2.5557873982830968

Epoch: 5| Step: 10
Training loss: 0.08069241812770005
Validation loss: 2.5563853231872233

Epoch: 571| Step: 0
Training loss: 0.11912809368581538
Validation loss: 2.5659483820528535

Epoch: 5| Step: 1
Training loss: 0.10337340283515012
Validation loss: 2.568888700057204

Epoch: 5| Step: 2
Training loss: 0.23594304703513794
Validation loss: 2.5721520914528395

Epoch: 5| Step: 3
Training loss: 0.07879659355721486
Validation loss: 2.531748904930771

Epoch: 5| Step: 4
Training loss: 0.11359183305253653
Validation loss: 2.5719898160818535

Epoch: 5| Step: 5
Training loss: 0.16981706456124418
Validation loss: 2.551077155202177

Epoch: 5| Step: 6
Training loss: 0.10753373477540454
Validation loss: 2.552751108131613

Epoch: 5| Step: 7
Training loss: 0.23602510366943624
Validation loss: 2.567808681481509

Epoch: 5| Step: 8
Training loss: 0.20145827341391123
Validation loss: 2.562841807293246

Epoch: 5| Step: 9
Training loss: 0.13092405941018742
Validation loss: 2.574483818568521

Epoch: 5| Step: 10
Training loss: 0.18811413404064395
Validation loss: 2.565096020637463

Epoch: 572| Step: 0
Training loss: 0.10679309358997291
Validation loss: 2.530678199751036

Epoch: 5| Step: 1
Training loss: 0.10778826306372807
Validation loss: 2.5449741380730018

Epoch: 5| Step: 2
Training loss: 0.26319626192026224
Validation loss: 2.543457938391789

Epoch: 5| Step: 3
Training loss: 0.09366513424466287
Validation loss: 2.525863688552286

Epoch: 5| Step: 4
Training loss: 0.09694437918919666
Validation loss: 2.542824490708105

Epoch: 5| Step: 5
Training loss: 0.2218207360117386
Validation loss: 2.5674011526630416

Epoch: 5| Step: 6
Training loss: 0.12646247979388595
Validation loss: 2.5613577993557617

Epoch: 5| Step: 7
Training loss: 0.09296879527948383
Validation loss: 2.572285903695128

Epoch: 5| Step: 8
Training loss: 0.17443622883976262
Validation loss: 2.55221318527139

Epoch: 5| Step: 9
Training loss: 0.1361073446874498
Validation loss: 2.5697861677478477

Epoch: 5| Step: 10
Training loss: 0.15586095895177465
Validation loss: 2.5479813726947826

Epoch: 573| Step: 0
Training loss: 0.2709720772763422
Validation loss: 2.5401578200637838

Epoch: 5| Step: 1
Training loss: 0.1731927812005785
Validation loss: 2.5154728660983134

Epoch: 5| Step: 2
Training loss: 0.12045252519414412
Validation loss: 2.554291311757485

Epoch: 5| Step: 3
Training loss: 0.10807191798503225
Validation loss: 2.542268009820543

Epoch: 5| Step: 4
Training loss: 0.1563221883909568
Validation loss: 2.536277460489889

Epoch: 5| Step: 5
Training loss: 0.08226489953865068
Validation loss: 2.5105952656888615

Epoch: 5| Step: 6
Training loss: 0.14694911983777384
Validation loss: 2.5345664367885616

Epoch: 5| Step: 7
Training loss: 0.16458114321273556
Validation loss: 2.5695203431979428

Epoch: 5| Step: 8
Training loss: 0.11261640907015918
Validation loss: 2.5548640234044697

Epoch: 5| Step: 9
Training loss: 0.12439589629799643
Validation loss: 2.542946786805967

Epoch: 5| Step: 10
Training loss: 0.1389336734001096
Validation loss: 2.5708358017000865

Epoch: 574| Step: 0
Training loss: 0.08749031456067473
Validation loss: 2.550503832445792

Epoch: 5| Step: 1
Training loss: 0.09312859365870732
Validation loss: 2.5605716627936763

Epoch: 5| Step: 2
Training loss: 0.056360016215949126
Validation loss: 2.547481421134877

Epoch: 5| Step: 3
Training loss: 0.09619246157924126
Validation loss: 2.5553466512492458

Epoch: 5| Step: 4
Training loss: 0.16502327815310333
Validation loss: 2.5568428983267446

Epoch: 5| Step: 5
Training loss: 0.19628578866534363
Validation loss: 2.5763627051077953

Epoch: 5| Step: 6
Training loss: 0.12233483835627074
Validation loss: 2.572759343914337

Epoch: 5| Step: 7
Training loss: 0.1516720685437906
Validation loss: 2.564409564435479

Epoch: 5| Step: 8
Training loss: 0.24893589350924025
Validation loss: 2.570781736869456

Epoch: 5| Step: 9
Training loss: 0.13974032680040238
Validation loss: 2.5574424369557787

Epoch: 5| Step: 10
Training loss: 0.1007589315497367
Validation loss: 2.564547336410675

Epoch: 575| Step: 0
Training loss: 0.15497127258092308
Validation loss: 2.5894343052609425

Epoch: 5| Step: 1
Training loss: 0.06319428549488627
Validation loss: 2.560466939288643

Epoch: 5| Step: 2
Training loss: 0.12745627685546218
Validation loss: 2.5629486993722708

Epoch: 5| Step: 3
Training loss: 0.09579876577763417
Validation loss: 2.5653210989794

Epoch: 5| Step: 4
Training loss: 0.3007196388061036
Validation loss: 2.5218390507190565

Epoch: 5| Step: 5
Training loss: 0.10851044924691804
Validation loss: 2.5566493197261706

Epoch: 5| Step: 6
Training loss: 0.12014390679271662
Validation loss: 2.5338690104239108

Epoch: 5| Step: 7
Training loss: 0.11387587558323879
Validation loss: 2.5203010433045896

Epoch: 5| Step: 8
Training loss: 0.08220428711001394
Validation loss: 2.523121230741678

Epoch: 5| Step: 9
Training loss: 0.13704824253104983
Validation loss: 2.5401860681592456

Epoch: 5| Step: 10
Training loss: 0.19077139298627474
Validation loss: 2.544600730758247

Epoch: 576| Step: 0
Training loss: 0.2352245985550505
Validation loss: 2.558645982294487

Epoch: 5| Step: 1
Training loss: 0.08578522423273856
Validation loss: 2.5702574037956047

Epoch: 5| Step: 2
Training loss: 0.20238886002644427
Validation loss: 2.5839415197193683

Epoch: 5| Step: 3
Training loss: 0.19489050098575197
Validation loss: 2.5817058873850844

Epoch: 5| Step: 4
Training loss: 0.08824320644383091
Validation loss: 2.5545320483952136

Epoch: 5| Step: 5
Training loss: 0.137852288447193
Validation loss: 2.540410626290841

Epoch: 5| Step: 6
Training loss: 0.14556649963916407
Validation loss: 2.524850247512345

Epoch: 5| Step: 7
Training loss: 0.14737469633368802
Validation loss: 2.5047184035270917

Epoch: 5| Step: 8
Training loss: 0.12273541267947062
Validation loss: 2.5031771045260984

Epoch: 5| Step: 9
Training loss: 0.1069654782979254
Validation loss: 2.510860569473623

Epoch: 5| Step: 10
Training loss: 0.18793445163255154
Validation loss: 2.5412937373518947

Epoch: 577| Step: 0
Training loss: 0.13805811006760108
Validation loss: 2.5937678680812626

Epoch: 5| Step: 1
Training loss: 0.19897327071599633
Validation loss: 2.63331335213857

Epoch: 5| Step: 2
Training loss: 0.09896911752648825
Validation loss: 2.6031823353385

Epoch: 5| Step: 3
Training loss: 0.066791346945868
Validation loss: 2.5813299708020754

Epoch: 5| Step: 4
Training loss: 0.15151724606772174
Validation loss: 2.550201622023293

Epoch: 5| Step: 5
Training loss: 0.08960203640428567
Validation loss: 2.5767039519581796

Epoch: 5| Step: 6
Training loss: 0.2187105381657613
Validation loss: 2.5581958738499746

Epoch: 5| Step: 7
Training loss: 0.28324592529995557
Validation loss: 2.5781121739341613

Epoch: 5| Step: 8
Training loss: 0.09200408558934733
Validation loss: 2.5719532130281713

Epoch: 5| Step: 9
Training loss: 0.12067310274688241
Validation loss: 2.591327918614568

Epoch: 5| Step: 10
Training loss: 0.13177078191155597
Validation loss: 2.5845761893543617

Epoch: 578| Step: 0
Training loss: 0.15521926054689122
Validation loss: 2.5833450307855794

Epoch: 5| Step: 1
Training loss: 0.12848149747988438
Validation loss: 2.583863524161902

Epoch: 5| Step: 2
Training loss: 0.24724770762776174
Validation loss: 2.575272788136078

Epoch: 5| Step: 3
Training loss: 0.14846585655403913
Validation loss: 2.5856378298200537

Epoch: 5| Step: 4
Training loss: 0.2252342984414078
Validation loss: 2.567716349934288

Epoch: 5| Step: 5
Training loss: 0.10144900895068708
Validation loss: 2.547147943962569

Epoch: 5| Step: 6
Training loss: 0.1795580024142695
Validation loss: 2.545476412049953

Epoch: 5| Step: 7
Training loss: 0.08720213853923686
Validation loss: 2.518308701621715

Epoch: 5| Step: 8
Training loss: 0.08274931769111345
Validation loss: 2.5364466305553064

Epoch: 5| Step: 9
Training loss: 0.0887096969252349
Validation loss: 2.548650864675785

Epoch: 5| Step: 10
Training loss: 0.1669352529186
Validation loss: 2.5323715226998584

Epoch: 579| Step: 0
Training loss: 0.14964146232629622
Validation loss: 2.5366068551423693

Epoch: 5| Step: 1
Training loss: 0.1114055882711139
Validation loss: 2.5400217167516415

Epoch: 5| Step: 2
Training loss: 0.07626380324986799
Validation loss: 2.538159032074033

Epoch: 5| Step: 3
Training loss: 0.0909287410463629
Validation loss: 2.5761642253804173

Epoch: 5| Step: 4
Training loss: 0.21864963681452326
Validation loss: 2.5752414322173167

Epoch: 5| Step: 5
Training loss: 0.13095375472257495
Validation loss: 2.5761047223668623

Epoch: 5| Step: 6
Training loss: 0.09985900901103023
Validation loss: 2.5693761718010415

Epoch: 5| Step: 7
Training loss: 0.08873071251914857
Validation loss: 2.5779262024821947

Epoch: 5| Step: 8
Training loss: 0.10912185563531068
Validation loss: 2.562518280068141

Epoch: 5| Step: 9
Training loss: 0.3141891959360677
Validation loss: 2.527147107325254

Epoch: 5| Step: 10
Training loss: 0.10273524091812546
Validation loss: 2.56115061249064

Epoch: 580| Step: 0
Training loss: 0.1416850665943191
Validation loss: 2.5317170899545443

Epoch: 5| Step: 1
Training loss: 0.18857357512986014
Validation loss: 2.531038078694839

Epoch: 5| Step: 2
Training loss: 0.11573333127645691
Validation loss: 2.5601355255885405

Epoch: 5| Step: 3
Training loss: 0.0682302413314652
Validation loss: 2.5681029381823843

Epoch: 5| Step: 4
Training loss: 0.22458592997384513
Validation loss: 2.540793476841133

Epoch: 5| Step: 5
Training loss: 0.17113965041503806
Validation loss: 2.554249923484779

Epoch: 5| Step: 6
Training loss: 0.16058145461602624
Validation loss: 2.553789392176461

Epoch: 5| Step: 7
Training loss: 0.18276903907422462
Validation loss: 2.581889913996482

Epoch: 5| Step: 8
Training loss: 0.11368819018076334
Validation loss: 2.567615428394406

Epoch: 5| Step: 9
Training loss: 0.10199836132980712
Validation loss: 2.5332180805197937

Epoch: 5| Step: 10
Training loss: 0.11905253781044364
Validation loss: 2.5461804668283

Epoch: 581| Step: 0
Training loss: 0.091021335815573
Validation loss: 2.555775354360484

Epoch: 5| Step: 1
Training loss: 0.207905883171782
Validation loss: 2.5360226571684605

Epoch: 5| Step: 2
Training loss: 0.062443499060225754
Validation loss: 2.5114789664049555

Epoch: 5| Step: 3
Training loss: 0.09377621244510156
Validation loss: 2.5044018549922775

Epoch: 5| Step: 4
Training loss: 0.13369003863641765
Validation loss: 2.553641079970442

Epoch: 5| Step: 5
Training loss: 0.14417684766710967
Validation loss: 2.5786226957484275

Epoch: 5| Step: 6
Training loss: 0.06964807366935621
Validation loss: 2.5969118608407347

Epoch: 5| Step: 7
Training loss: 0.0998732027451916
Validation loss: 2.5991025148127913

Epoch: 5| Step: 8
Training loss: 0.10923275041961357
Validation loss: 2.6033542145052646

Epoch: 5| Step: 9
Training loss: 0.2033696260480823
Validation loss: 2.6004159289017066

Epoch: 5| Step: 10
Training loss: 0.2530030839980863
Validation loss: 2.5783829605650936

Epoch: 582| Step: 0
Training loss: 0.17694079164551157
Validation loss: 2.5672102066441997

Epoch: 5| Step: 1
Training loss: 0.07147767968429962
Validation loss: 2.5656108486746567

Epoch: 5| Step: 2
Training loss: 0.08249056042326434
Validation loss: 2.573597125586752

Epoch: 5| Step: 3
Training loss: 0.17739913050517492
Validation loss: 2.5758210035710767

Epoch: 5| Step: 4
Training loss: 0.2601413877211248
Validation loss: 2.5286430729852367

Epoch: 5| Step: 5
Training loss: 0.1961976213168588
Validation loss: 2.5462163539935725

Epoch: 5| Step: 6
Training loss: 0.08424698723855914
Validation loss: 2.541642601616068

Epoch: 5| Step: 7
Training loss: 0.13012622310583952
Validation loss: 2.516259654180291

Epoch: 5| Step: 8
Training loss: 0.11153845827858544
Validation loss: 2.5386774737634417

Epoch: 5| Step: 9
Training loss: 0.0717141723314641
Validation loss: 2.602596699321681

Epoch: 5| Step: 10
Training loss: 0.16119843504970768
Validation loss: 2.598394001012395

Epoch: 583| Step: 0
Training loss: 0.15426334185723337
Validation loss: 2.6445877603061265

Epoch: 5| Step: 1
Training loss: 0.16452622725671426
Validation loss: 2.625174909664154

Epoch: 5| Step: 2
Training loss: 0.13120740897682956
Validation loss: 2.624178041370374

Epoch: 5| Step: 3
Training loss: 0.07948079566496496
Validation loss: 2.584798473470587

Epoch: 5| Step: 4
Training loss: 0.1278759792659549
Validation loss: 2.576227906502113

Epoch: 5| Step: 5
Training loss: 0.18543406620967115
Validation loss: 2.5639560173510274

Epoch: 5| Step: 6
Training loss: 0.10023659158814271
Validation loss: 2.539484933147094

Epoch: 5| Step: 7
Training loss: 0.25337215884196107
Validation loss: 2.531935785921787

Epoch: 5| Step: 8
Training loss: 0.17087477383950928
Validation loss: 2.555155909057225

Epoch: 5| Step: 9
Training loss: 0.09166359864685474
Validation loss: 2.5352487157108436

Epoch: 5| Step: 10
Training loss: 0.1055200813910921
Validation loss: 2.558481386333958

Epoch: 584| Step: 0
Training loss: 0.22428251615807104
Validation loss: 2.5421408606469016

Epoch: 5| Step: 1
Training loss: 0.08261934428635075
Validation loss: 2.550394808458521

Epoch: 5| Step: 2
Training loss: 0.06278940341966552
Validation loss: 2.53981705906357

Epoch: 5| Step: 3
Training loss: 0.09184016566438968
Validation loss: 2.5475383966313623

Epoch: 5| Step: 4
Training loss: 0.11103457515299446
Validation loss: 2.5537696381921706

Epoch: 5| Step: 5
Training loss: 0.21156186840464583
Validation loss: 2.572337661631324

Epoch: 5| Step: 6
Training loss: 0.09974945727477942
Validation loss: 2.526696485095671

Epoch: 5| Step: 7
Training loss: 0.16974901307659027
Validation loss: 2.5284963203905697

Epoch: 5| Step: 8
Training loss: 0.17064640534454525
Validation loss: 2.5290100728175884

Epoch: 5| Step: 9
Training loss: 0.23334322958776188
Validation loss: 2.5157944052741925

Epoch: 5| Step: 10
Training loss: 0.07893346362070898
Validation loss: 2.5571801774678375

Epoch: 585| Step: 0
Training loss: 0.1315477895667521
Validation loss: 2.530352014012485

Epoch: 5| Step: 1
Training loss: 0.1354531291020426
Validation loss: 2.5615129708346753

Epoch: 5| Step: 2
Training loss: 0.1270948645826831
Validation loss: 2.5472550170608517

Epoch: 5| Step: 3
Training loss: 0.17971835700748134
Validation loss: 2.5396266465133186

Epoch: 5| Step: 4
Training loss: 0.17397537852247622
Validation loss: 2.5603635492105625

Epoch: 5| Step: 5
Training loss: 0.2730917788625502
Validation loss: 2.5531358053389654

Epoch: 5| Step: 6
Training loss: 0.09435402477614793
Validation loss: 2.540097086023711

Epoch: 5| Step: 7
Training loss: 0.12027472732907907
Validation loss: 2.517980744496838

Epoch: 5| Step: 8
Training loss: 0.16183776967684768
Validation loss: 2.531703228305914

Epoch: 5| Step: 9
Training loss: 0.0882586166392139
Validation loss: 2.538083030521215

Epoch: 5| Step: 10
Training loss: 0.09522029176433475
Validation loss: 2.559359146532435

Epoch: 586| Step: 0
Training loss: 0.08564712222539607
Validation loss: 2.540783907541702

Epoch: 5| Step: 1
Training loss: 0.14810266500397604
Validation loss: 2.5393822051423305

Epoch: 5| Step: 2
Training loss: 0.2470962601255935
Validation loss: 2.5391940912140103

Epoch: 5| Step: 3
Training loss: 0.16267998933473288
Validation loss: 2.521835319882987

Epoch: 5| Step: 4
Training loss: 0.11255670548880177
Validation loss: 2.519533543459691

Epoch: 5| Step: 5
Training loss: 0.10312942220858544
Validation loss: 2.505944108384435

Epoch: 5| Step: 6
Training loss: 0.10577796712596098
Validation loss: 2.5051403850408778

Epoch: 5| Step: 7
Training loss: 0.061040981014787374
Validation loss: 2.5395124533059152

Epoch: 5| Step: 8
Training loss: 0.12219452832269559
Validation loss: 2.5367315186977515

Epoch: 5| Step: 9
Training loss: 0.2156334236130555
Validation loss: 2.581278776535647

Epoch: 5| Step: 10
Training loss: 0.15927457614086948
Validation loss: 2.574424102448525

Epoch: 587| Step: 0
Training loss: 0.10279634985127897
Validation loss: 2.541872367893328

Epoch: 5| Step: 1
Training loss: 0.14158571088789915
Validation loss: 2.5669206234996835

Epoch: 5| Step: 2
Training loss: 0.10972318830153668
Validation loss: 2.5439673134290524

Epoch: 5| Step: 3
Training loss: 0.08405795865927149
Validation loss: 2.5419880253496925

Epoch: 5| Step: 4
Training loss: 0.3043331506577292
Validation loss: 2.548691143874409

Epoch: 5| Step: 5
Training loss: 0.10065603128709691
Validation loss: 2.5466285162019573

Epoch: 5| Step: 6
Training loss: 0.152711150167029
Validation loss: 2.5522097057590725

Epoch: 5| Step: 7
Training loss: 0.09488255644065256
Validation loss: 2.5449048929470526

Epoch: 5| Step: 8
Training loss: 0.14515483208775798
Validation loss: 2.564602065470079

Epoch: 5| Step: 9
Training loss: 0.192637550826385
Validation loss: 2.5634077146692675

Epoch: 5| Step: 10
Training loss: 0.1626131376852176
Validation loss: 2.5710102830595374

Epoch: 588| Step: 0
Training loss: 0.19849643470399314
Validation loss: 2.5500107171615407

Epoch: 5| Step: 1
Training loss: 0.08105717505808764
Validation loss: 2.562820428542505

Epoch: 5| Step: 2
Training loss: 0.14999466330253663
Validation loss: 2.540551609914232

Epoch: 5| Step: 3
Training loss: 0.12998476544392737
Validation loss: 2.520457184187224

Epoch: 5| Step: 4
Training loss: 0.19475978847163708
Validation loss: 2.5576200201539483

Epoch: 5| Step: 5
Training loss: 0.10600617583098897
Validation loss: 2.5246547834992734

Epoch: 5| Step: 6
Training loss: 0.1334128205907868
Validation loss: 2.552544833644833

Epoch: 5| Step: 7
Training loss: 0.10678904705618207
Validation loss: 2.568726113734317

Epoch: 5| Step: 8
Training loss: 0.24608537114729534
Validation loss: 2.594093447285737

Epoch: 5| Step: 9
Training loss: 0.09708095373240974
Validation loss: 2.5766537651991643

Epoch: 5| Step: 10
Training loss: 0.15199494779222986
Validation loss: 2.5589833553879076

Epoch: 589| Step: 0
Training loss: 0.10770381860690935
Validation loss: 2.5719530515517515

Epoch: 5| Step: 1
Training loss: 0.09744396979377097
Validation loss: 2.5414455532144307

Epoch: 5| Step: 2
Training loss: 0.14414435875458137
Validation loss: 2.536005844996608

Epoch: 5| Step: 3
Training loss: 0.1660878641372172
Validation loss: 2.5185358939141835

Epoch: 5| Step: 4
Training loss: 0.17424433952192683
Validation loss: 2.519226803692572

Epoch: 5| Step: 5
Training loss: 0.10304503266406251
Validation loss: 2.5433655932255674

Epoch: 5| Step: 6
Training loss: 0.17625122820649447
Validation loss: 2.5193081924209166

Epoch: 5| Step: 7
Training loss: 0.10256862214312744
Validation loss: 2.5458355988421144

Epoch: 5| Step: 8
Training loss: 0.26004114096018477
Validation loss: 2.530913699916864

Epoch: 5| Step: 9
Training loss: 0.16844199293156553
Validation loss: 2.5811261192898285

Epoch: 5| Step: 10
Training loss: 0.1459132504890708
Validation loss: 2.5937170487925214

Epoch: 590| Step: 0
Training loss: 0.13619078464932416
Validation loss: 2.5451246294203953

Epoch: 5| Step: 1
Training loss: 0.09336060379528459
Validation loss: 2.5447380864557423

Epoch: 5| Step: 2
Training loss: 0.11040239935443216
Validation loss: 2.5522722122049175

Epoch: 5| Step: 3
Training loss: 0.20148721072452316
Validation loss: 2.5408148562855395

Epoch: 5| Step: 4
Training loss: 0.11900079447942878
Validation loss: 2.5243830893896178

Epoch: 5| Step: 5
Training loss: 0.24914184448001153
Validation loss: 2.519741765434723

Epoch: 5| Step: 6
Training loss: 0.15872197957066322
Validation loss: 2.5343449685555086

Epoch: 5| Step: 7
Training loss: 0.14021089298789383
Validation loss: 2.5484313316524823

Epoch: 5| Step: 8
Training loss: 0.08840579472165344
Validation loss: 2.5158408924613083

Epoch: 5| Step: 9
Training loss: 0.10453116946509527
Validation loss: 2.5227838795702002

Epoch: 5| Step: 10
Training loss: 0.08895649980763111
Validation loss: 2.5411749683075042

Epoch: 591| Step: 0
Training loss: 0.09500445572699795
Validation loss: 2.542276216222755

Epoch: 5| Step: 1
Training loss: 0.10895369911534947
Validation loss: 2.538377612359875

Epoch: 5| Step: 2
Training loss: 0.13028705045387737
Validation loss: 2.5732737640425416

Epoch: 5| Step: 3
Training loss: 0.15178568423294925
Validation loss: 2.554453324481288

Epoch: 5| Step: 4
Training loss: 0.10401256507325495
Validation loss: 2.590609682938543

Epoch: 5| Step: 5
Training loss: 0.16474859080884155
Validation loss: 2.5562427677802697

Epoch: 5| Step: 6
Training loss: 0.1158159861472261
Validation loss: 2.5474760140470614

Epoch: 5| Step: 7
Training loss: 0.10615801317925322
Validation loss: 2.567780979370783

Epoch: 5| Step: 8
Training loss: 0.15338946562724556
Validation loss: 2.537470035122468

Epoch: 5| Step: 9
Training loss: 0.30039930244284174
Validation loss: 2.5329881759485535

Epoch: 5| Step: 10
Training loss: 0.12920576037211415
Validation loss: 2.534648826848713

Epoch: 592| Step: 0
Training loss: 0.07092064543820324
Validation loss: 2.556879430936136

Epoch: 5| Step: 1
Training loss: 0.17750102224189937
Validation loss: 2.5734794459219454

Epoch: 5| Step: 2
Training loss: 0.1389687677661772
Validation loss: 2.590009451005696

Epoch: 5| Step: 3
Training loss: 0.1319157252999047
Validation loss: 2.5752580743555282

Epoch: 5| Step: 4
Training loss: 0.22890558958772037
Validation loss: 2.5615986455078184

Epoch: 5| Step: 5
Training loss: 0.1653985504248026
Validation loss: 2.5798210394842895

Epoch: 5| Step: 6
Training loss: 0.08897664068333999
Validation loss: 2.5825355512272954

Epoch: 5| Step: 7
Training loss: 0.09651286731520874
Validation loss: 2.5668886352267357

Epoch: 5| Step: 8
Training loss: 0.1976494312994959
Validation loss: 2.5595915270948897

Epoch: 5| Step: 9
Training loss: 0.08395437048391625
Validation loss: 2.5503489988600485

Epoch: 5| Step: 10
Training loss: 0.11166128284445834
Validation loss: 2.546572953389349

Epoch: 593| Step: 0
Training loss: 0.10454396720756935
Validation loss: 2.5248230569483465

Epoch: 5| Step: 1
Training loss: 0.08110486626002827
Validation loss: 2.506564969109868

Epoch: 5| Step: 2
Training loss: 0.11114587841089628
Validation loss: 2.5036406413987766

Epoch: 5| Step: 3
Training loss: 0.20286824431603
Validation loss: 2.493215508270004

Epoch: 5| Step: 4
Training loss: 0.07872382974230306
Validation loss: 2.5634046358876947

Epoch: 5| Step: 5
Training loss: 0.11145891069844997
Validation loss: 2.587827828238023

Epoch: 5| Step: 6
Training loss: 0.16455757285571646
Validation loss: 2.582607521273014

Epoch: 5| Step: 7
Training loss: 0.16483704205283994
Validation loss: 2.624964463305435

Epoch: 5| Step: 8
Training loss: 0.14073414011152455
Validation loss: 2.6051454131428367

Epoch: 5| Step: 9
Training loss: 0.22882531040293128
Validation loss: 2.5917914327658025

Epoch: 5| Step: 10
Training loss: 0.18463420266710476
Validation loss: 2.5801310262631363

Epoch: 594| Step: 0
Training loss: 0.10688813432078781
Validation loss: 2.5297553770626178

Epoch: 5| Step: 1
Training loss: 0.08281194634972242
Validation loss: 2.5713134924985543

Epoch: 5| Step: 2
Training loss: 0.20703626122797605
Validation loss: 2.5305873844699227

Epoch: 5| Step: 3
Training loss: 0.08532188191894653
Validation loss: 2.538970033840891

Epoch: 5| Step: 4
Training loss: 0.10998741766103581
Validation loss: 2.4998078723627133

Epoch: 5| Step: 5
Training loss: 0.27541597398467876
Validation loss: 2.5153898734208986

Epoch: 5| Step: 6
Training loss: 0.14970754335916797
Validation loss: 2.5228157381018534

Epoch: 5| Step: 7
Training loss: 0.09730876613140897
Validation loss: 2.5178997277627864

Epoch: 5| Step: 8
Training loss: 0.1430991268822253
Validation loss: 2.5195084068647255

Epoch: 5| Step: 9
Training loss: 0.09913346725429222
Validation loss: 2.5255501065345216

Epoch: 5| Step: 10
Training loss: 0.06093488658595097
Validation loss: 2.5370789580326565

Epoch: 595| Step: 0
Training loss: 0.09600616181083152
Validation loss: 2.5030505959465397

Epoch: 5| Step: 1
Training loss: 0.15475609804434615
Validation loss: 2.530473527979576

Epoch: 5| Step: 2
Training loss: 0.2668358328931735
Validation loss: 2.542045818824229

Epoch: 5| Step: 3
Training loss: 0.1549941976868653
Validation loss: 2.5050818271268405

Epoch: 5| Step: 4
Training loss: 0.10646859185677605
Validation loss: 2.510055968131223

Epoch: 5| Step: 5
Training loss: 0.11770870017385568
Validation loss: 2.501842324471882

Epoch: 5| Step: 6
Training loss: 0.09960788837894265
Validation loss: 2.5120557777310593

Epoch: 5| Step: 7
Training loss: 0.0897027443347981
Validation loss: 2.5599658780265786

Epoch: 5| Step: 8
Training loss: 0.194353975005261
Validation loss: 2.5829091439983567

Epoch: 5| Step: 9
Training loss: 0.07261059875310759
Validation loss: 2.5705248171535513

Epoch: 5| Step: 10
Training loss: 0.1082880471863584
Validation loss: 2.5477009635606187

Epoch: 596| Step: 0
Training loss: 0.10938980649454734
Validation loss: 2.578369135032132

Epoch: 5| Step: 1
Training loss: 0.1305983273981231
Validation loss: 2.571096999311418

Epoch: 5| Step: 2
Training loss: 0.08289682597911957
Validation loss: 2.577756878427542

Epoch: 5| Step: 3
Training loss: 0.07797883486936188
Validation loss: 2.525834328747955

Epoch: 5| Step: 4
Training loss: 0.19723612498664697
Validation loss: 2.5188452337825114

Epoch: 5| Step: 5
Training loss: 0.18058951618362656
Validation loss: 2.5073995949581946

Epoch: 5| Step: 6
Training loss: 0.12465791907690897
Validation loss: 2.5129172502980124

Epoch: 5| Step: 7
Training loss: 0.2218372440450796
Validation loss: 2.539038449308394

Epoch: 5| Step: 8
Training loss: 0.16828774501659727
Validation loss: 2.5398577246409233

Epoch: 5| Step: 9
Training loss: 0.10516094397091165
Validation loss: 2.5873748935318632

Epoch: 5| Step: 10
Training loss: 0.07884120774470113
Validation loss: 2.553748420407779

Epoch: 597| Step: 0
Training loss: 0.09213276042077945
Validation loss: 2.56619587232006

Epoch: 5| Step: 1
Training loss: 0.07779762699470917
Validation loss: 2.609987910642699

Epoch: 5| Step: 2
Training loss: 0.1424512886877974
Validation loss: 2.597729088508952

Epoch: 5| Step: 3
Training loss: 0.10850099918184473
Validation loss: 2.5624063626280518

Epoch: 5| Step: 4
Training loss: 0.14864006150121914
Validation loss: 2.551001699309548

Epoch: 5| Step: 5
Training loss: 0.1468918663851357
Validation loss: 2.560662958459491

Epoch: 5| Step: 6
Training loss: 0.09508203389510331
Validation loss: 2.525798991380134

Epoch: 5| Step: 7
Training loss: 0.14824890402956475
Validation loss: 2.5291099976906253

Epoch: 5| Step: 8
Training loss: 0.09433147783183032
Validation loss: 2.549425483896033

Epoch: 5| Step: 9
Training loss: 0.17017427421680967
Validation loss: 2.5584479378015934

Epoch: 5| Step: 10
Training loss: 0.23502743827144215
Validation loss: 2.5471364978003215

Epoch: 598| Step: 0
Training loss: 0.07903811771446151
Validation loss: 2.548979633929451

Epoch: 5| Step: 1
Training loss: 0.18116887677776802
Validation loss: 2.5963646926606447

Epoch: 5| Step: 2
Training loss: 0.09210153507520569
Validation loss: 2.5970932977115657

Epoch: 5| Step: 3
Training loss: 0.10685698059635729
Validation loss: 2.572977443370985

Epoch: 5| Step: 4
Training loss: 0.12068481383576642
Validation loss: 2.6072846213113694

Epoch: 5| Step: 5
Training loss: 0.13322437458079436
Validation loss: 2.5797762269268407

Epoch: 5| Step: 6
Training loss: 0.12058285644074898
Validation loss: 2.558227683210613

Epoch: 5| Step: 7
Training loss: 0.24939868553992217
Validation loss: 2.5150002302632353

Epoch: 5| Step: 8
Training loss: 0.18611769960098645
Validation loss: 2.507214173484161

Epoch: 5| Step: 9
Training loss: 0.17900873605358963
Validation loss: 2.520403265634814

Epoch: 5| Step: 10
Training loss: 0.09634208979399599
Validation loss: 2.5434682137658267

Epoch: 599| Step: 0
Training loss: 0.11636047199203946
Validation loss: 2.5917507442350876

Epoch: 5| Step: 1
Training loss: 0.10258846455285944
Validation loss: 2.6068836698436786

Epoch: 5| Step: 2
Training loss: 0.1569995900402366
Validation loss: 2.6219987935396607

Epoch: 5| Step: 3
Training loss: 0.0797497745582853
Validation loss: 2.6121855806666985

Epoch: 5| Step: 4
Training loss: 0.17999360713931215
Validation loss: 2.631466646399692

Epoch: 5| Step: 5
Training loss: 0.1482527863504404
Validation loss: 2.627662064772711

Epoch: 5| Step: 6
Training loss: 0.11863041506352318
Validation loss: 2.58858911865249

Epoch: 5| Step: 7
Training loss: 0.2644949746087164
Validation loss: 2.5543361559070963

Epoch: 5| Step: 8
Training loss: 0.09981572524994538
Validation loss: 2.542798769730933

Epoch: 5| Step: 9
Training loss: 0.17610328633262756
Validation loss: 2.5446169342991314

Epoch: 5| Step: 10
Training loss: 0.12430868611783193
Validation loss: 2.5525747137962527

Epoch: 600| Step: 0
Training loss: 0.12650404510325516
Validation loss: 2.56948756316934

Epoch: 5| Step: 1
Training loss: 0.15463652830622654
Validation loss: 2.5686363322611534

Epoch: 5| Step: 2
Training loss: 0.1488796475355249
Validation loss: 2.573105234768238

Epoch: 5| Step: 3
Training loss: 0.11283111752824694
Validation loss: 2.562441755423714

Epoch: 5| Step: 4
Training loss: 0.16407883653594538
Validation loss: 2.562872938804776

Epoch: 5| Step: 5
Training loss: 0.1182332112408927
Validation loss: 2.528850206806537

Epoch: 5| Step: 6
Training loss: 0.15977869073656137
Validation loss: 2.5468121965099706

Epoch: 5| Step: 7
Training loss: 0.22418132296821594
Validation loss: 2.551412772473106

Epoch: 5| Step: 8
Training loss: 0.18273835064109226
Validation loss: 2.539831022788608

Epoch: 5| Step: 9
Training loss: 0.10496897080021468
Validation loss: 2.544201109917406

Epoch: 5| Step: 10
Training loss: 0.09307360025883131
Validation loss: 2.553722615706364

Epoch: 601| Step: 0
Training loss: 0.2255739316181281
Validation loss: 2.5782991014290837

Epoch: 5| Step: 1
Training loss: 0.09422368840897316
Validation loss: 2.5837512860779976

Epoch: 5| Step: 2
Training loss: 0.09826499037280652
Validation loss: 2.5492622344953584

Epoch: 5| Step: 3
Training loss: 0.17432620985314823
Validation loss: 2.586098928914719

Epoch: 5| Step: 4
Training loss: 0.10083455775472504
Validation loss: 2.5437100512969195

Epoch: 5| Step: 5
Training loss: 0.1275819244916912
Validation loss: 2.5501058712945652

Epoch: 5| Step: 6
Training loss: 0.21482564676481092
Validation loss: 2.5349207010147556

Epoch: 5| Step: 7
Training loss: 0.08926734852508307
Validation loss: 2.538244336548509

Epoch: 5| Step: 8
Training loss: 0.09498093557272484
Validation loss: 2.5340601687233155

Epoch: 5| Step: 9
Training loss: 0.12392695872030764
Validation loss: 2.529495140391686

Epoch: 5| Step: 10
Training loss: 0.09749195106154258
Validation loss: 2.520414223166888

Epoch: 602| Step: 0
Training loss: 0.1235422841002242
Validation loss: 2.508470504858941

Epoch: 5| Step: 1
Training loss: 0.2165791130987351
Validation loss: 2.509565705896957

Epoch: 5| Step: 2
Training loss: 0.1550174077799218
Validation loss: 2.5387290918692718

Epoch: 5| Step: 3
Training loss: 0.1379847291892837
Validation loss: 2.5771788610182034

Epoch: 5| Step: 4
Training loss: 0.07654539557053407
Validation loss: 2.5394704789124565

Epoch: 5| Step: 5
Training loss: 0.23126869061689911
Validation loss: 2.5575166733647463

Epoch: 5| Step: 6
Training loss: 0.09467850773826492
Validation loss: 2.5656131573993126

Epoch: 5| Step: 7
Training loss: 0.18437452881962973
Validation loss: 2.5614453273022755

Epoch: 5| Step: 8
Training loss: 0.0928650353638749
Validation loss: 2.580313469223166

Epoch: 5| Step: 9
Training loss: 0.18502656362532877
Validation loss: 2.561784469785804

Epoch: 5| Step: 10
Training loss: 0.08362355736930044
Validation loss: 2.5678727644924364

Epoch: 603| Step: 0
Training loss: 0.08451639817932013
Validation loss: 2.5400012909869227

Epoch: 5| Step: 1
Training loss: 0.20686844056151635
Validation loss: 2.5296295946817065

Epoch: 5| Step: 2
Training loss: 0.11657444017070517
Validation loss: 2.511396668083366

Epoch: 5| Step: 3
Training loss: 0.07348149305893786
Validation loss: 2.518752628993652

Epoch: 5| Step: 4
Training loss: 0.11338638901968938
Validation loss: 2.5542843854887654

Epoch: 5| Step: 5
Training loss: 0.10639295690325268
Validation loss: 2.529365657520948

Epoch: 5| Step: 6
Training loss: 0.17390616947319587
Validation loss: 2.545779192467146

Epoch: 5| Step: 7
Training loss: 0.2180256601781378
Validation loss: 2.5522199629740987

Epoch: 5| Step: 8
Training loss: 0.14819096495753728
Validation loss: 2.5525088295612073

Epoch: 5| Step: 9
Training loss: 0.10890774887290418
Validation loss: 2.5944633387577305

Epoch: 5| Step: 10
Training loss: 0.12726370893737293
Validation loss: 2.598232096715826

Epoch: 604| Step: 0
Training loss: 0.14399861444901094
Validation loss: 2.5988703985814623

Epoch: 5| Step: 1
Training loss: 0.0890453512429885
Validation loss: 2.561238483332257

Epoch: 5| Step: 2
Training loss: 0.07506372965270815
Validation loss: 2.5669503682708976

Epoch: 5| Step: 3
Training loss: 0.13315519130449746
Validation loss: 2.5690105751679995

Epoch: 5| Step: 4
Training loss: 0.0850040063544971
Validation loss: 2.579238848870831

Epoch: 5| Step: 5
Training loss: 0.268415519027562
Validation loss: 2.566763370869852

Epoch: 5| Step: 6
Training loss: 0.11143844141404709
Validation loss: 2.5520563719787925

Epoch: 5| Step: 7
Training loss: 0.0777620078338402
Validation loss: 2.564856939216384

Epoch: 5| Step: 8
Training loss: 0.10126874237341858
Validation loss: 2.5533623727147248

Epoch: 5| Step: 9
Training loss: 0.1569395169823916
Validation loss: 2.5524066126786487

Epoch: 5| Step: 10
Training loss: 0.1586817518378596
Validation loss: 2.5596999931155513

Epoch: 605| Step: 0
Training loss: 0.10691919621779038
Validation loss: 2.5522296722090423

Epoch: 5| Step: 1
Training loss: 0.16444552080057045
Validation loss: 2.5610180342914344

Epoch: 5| Step: 2
Training loss: 0.10418390985663845
Validation loss: 2.5345277396328094

Epoch: 5| Step: 3
Training loss: 0.24043656191383808
Validation loss: 2.570008156487649

Epoch: 5| Step: 4
Training loss: 0.08815517347767754
Validation loss: 2.5646619783011664

Epoch: 5| Step: 5
Training loss: 0.15391271790599245
Validation loss: 2.5552505244541157

Epoch: 5| Step: 6
Training loss: 0.17253978002777726
Validation loss: 2.5745498504295456

Epoch: 5| Step: 7
Training loss: 0.1103489588540049
Validation loss: 2.5647552114621703

Epoch: 5| Step: 8
Training loss: 0.06289883480034199
Validation loss: 2.562679805695085

Epoch: 5| Step: 9
Training loss: 0.10369670971478258
Validation loss: 2.548322885983452

Epoch: 5| Step: 10
Training loss: 0.11703532988512258
Validation loss: 2.561817873753823

Epoch: 606| Step: 0
Training loss: 0.08950121515597267
Validation loss: 2.5310549127227535

Epoch: 5| Step: 1
Training loss: 0.06709733904485814
Validation loss: 2.5574305136005617

Epoch: 5| Step: 2
Training loss: 0.20533683443942147
Validation loss: 2.5750549672137244

Epoch: 5| Step: 3
Training loss: 0.2189743475331249
Validation loss: 2.6316155661187013

Epoch: 5| Step: 4
Training loss: 0.10225535608582538
Validation loss: 2.612135102030162

Epoch: 5| Step: 5
Training loss: 0.130000312259189
Validation loss: 2.621276424616155

Epoch: 5| Step: 6
Training loss: 0.09419418449640818
Validation loss: 2.598574082457592

Epoch: 5| Step: 7
Training loss: 0.09486522553972374
Validation loss: 2.5909009770269282

Epoch: 5| Step: 8
Training loss: 0.09028422662991424
Validation loss: 2.5803157364769045

Epoch: 5| Step: 9
Training loss: 0.07809247889749353
Validation loss: 2.565582340425353

Epoch: 5| Step: 10
Training loss: 0.1678773054446073
Validation loss: 2.538335199053278

Epoch: 607| Step: 0
Training loss: 0.08555705214628855
Validation loss: 2.539830493371634

Epoch: 5| Step: 1
Training loss: 0.1267880466887542
Validation loss: 2.5450713379666556

Epoch: 5| Step: 2
Training loss: 0.1369161134966199
Validation loss: 2.5901678053313097

Epoch: 5| Step: 3
Training loss: 0.09490313246815925
Validation loss: 2.5632480256871393

Epoch: 5| Step: 4
Training loss: 0.12538986948564085
Validation loss: 2.5736277783563932

Epoch: 5| Step: 5
Training loss: 0.18087243100986786
Validation loss: 2.6155951332898875

Epoch: 5| Step: 6
Training loss: 0.10171217160260387
Validation loss: 2.590807751639273

Epoch: 5| Step: 7
Training loss: 0.0936757081435039
Validation loss: 2.6071377475160995

Epoch: 5| Step: 8
Training loss: 0.10142443515906151
Validation loss: 2.5543613542381025

Epoch: 5| Step: 9
Training loss: 0.26243210834198455
Validation loss: 2.534134868556093

Epoch: 5| Step: 10
Training loss: 0.17388494505883342
Validation loss: 2.523467579532204

Epoch: 608| Step: 0
Training loss: 0.1617268737650661
Validation loss: 2.5256735425734447

Epoch: 5| Step: 1
Training loss: 0.23101164835350826
Validation loss: 2.5237110136638807

Epoch: 5| Step: 2
Training loss: 0.10500835669278379
Validation loss: 2.5069615394899403

Epoch: 5| Step: 3
Training loss: 0.11912803505211436
Validation loss: 2.527021680805413

Epoch: 5| Step: 4
Training loss: 0.09346042056898542
Validation loss: 2.535816337190937

Epoch: 5| Step: 5
Training loss: 0.06881308871445291
Validation loss: 2.544718821335412

Epoch: 5| Step: 6
Training loss: 0.14061811218347656
Validation loss: 2.540849999951838

Epoch: 5| Step: 7
Training loss: 0.11060297017927195
Validation loss: 2.578348614841576

Epoch: 5| Step: 8
Training loss: 0.08173748617571737
Validation loss: 2.5681010923945196

Epoch: 5| Step: 9
Training loss: 0.17383124316558424
Validation loss: 2.5681825219227323

Epoch: 5| Step: 10
Training loss: 0.07612297126614558
Validation loss: 2.5712536638647467

Epoch: 609| Step: 0
Training loss: 0.07753239826419153
Validation loss: 2.5742198975148582

Epoch: 5| Step: 1
Training loss: 0.12339459968460419
Validation loss: 2.578645808571599

Epoch: 5| Step: 2
Training loss: 0.12081870637597576
Validation loss: 2.584047732444853

Epoch: 5| Step: 3
Training loss: 0.07885407656255451
Validation loss: 2.6023352902621495

Epoch: 5| Step: 4
Training loss: 0.10236193480804347
Validation loss: 2.5893208938238277

Epoch: 5| Step: 5
Training loss: 0.14330908467523262
Validation loss: 2.5907089037332036

Epoch: 5| Step: 6
Training loss: 0.16837732945093176
Validation loss: 2.5730308782038462

Epoch: 5| Step: 7
Training loss: 0.15080082054814545
Validation loss: 2.566224148980149

Epoch: 5| Step: 8
Training loss: 0.0986116830458681
Validation loss: 2.55642398731831

Epoch: 5| Step: 9
Training loss: 0.22321555511931093
Validation loss: 2.549503405781505

Epoch: 5| Step: 10
Training loss: 0.182208159029514
Validation loss: 2.5573760977068583

Epoch: 610| Step: 0
Training loss: 0.12142402845850694
Validation loss: 2.536603402734144

Epoch: 5| Step: 1
Training loss: 0.1650067529145385
Validation loss: 2.5719168790831253

Epoch: 5| Step: 2
Training loss: 0.08271551278304258
Validation loss: 2.5603125685353723

Epoch: 5| Step: 3
Training loss: 0.07656186174107198
Validation loss: 2.59068569616588

Epoch: 5| Step: 4
Training loss: 0.18900599265752924
Validation loss: 2.5897294012151235

Epoch: 5| Step: 5
Training loss: 0.10412633880158681
Validation loss: 2.5936162256583413

Epoch: 5| Step: 6
Training loss: 0.11143437552177023
Validation loss: 2.566767026414477

Epoch: 5| Step: 7
Training loss: 0.169199405173796
Validation loss: 2.5634079431900196

Epoch: 5| Step: 8
Training loss: 0.12568269505509236
Validation loss: 2.5495537247724074

Epoch: 5| Step: 9
Training loss: 0.10549816410192721
Validation loss: 2.5512427111868115

Epoch: 5| Step: 10
Training loss: 0.24043203766431087
Validation loss: 2.572860509578351

Epoch: 611| Step: 0
Training loss: 0.06269180029541362
Validation loss: 2.5439896336165173

Epoch: 5| Step: 1
Training loss: 0.12686529789552237
Validation loss: 2.5403246881359376

Epoch: 5| Step: 2
Training loss: 0.10278839949930194
Validation loss: 2.5551972495460196

Epoch: 5| Step: 3
Training loss: 0.1682380635287739
Validation loss: 2.538011920621784

Epoch: 5| Step: 4
Training loss: 0.07759009766845607
Validation loss: 2.551657276530796

Epoch: 5| Step: 5
Training loss: 0.06733428202584739
Validation loss: 2.553358136477111

Epoch: 5| Step: 6
Training loss: 0.1741854124717467
Validation loss: 2.572413568995506

Epoch: 5| Step: 7
Training loss: 0.1380655033472207
Validation loss: 2.5773057507909023

Epoch: 5| Step: 8
Training loss: 0.13296792808933156
Validation loss: 2.5736332211472033

Epoch: 5| Step: 9
Training loss: 0.10343434183479837
Validation loss: 2.588625035866711

Epoch: 5| Step: 10
Training loss: 0.21916226298896455
Validation loss: 2.5549894025735473

Epoch: 612| Step: 0
Training loss: 0.11513070923164825
Validation loss: 2.544295100403701

Epoch: 5| Step: 1
Training loss: 0.1155806486989563
Validation loss: 2.5480009411483797

Epoch: 5| Step: 2
Training loss: 0.1368956579335355
Validation loss: 2.5262267721182896

Epoch: 5| Step: 3
Training loss: 0.14531338265879007
Validation loss: 2.5211145479237023

Epoch: 5| Step: 4
Training loss: 0.1268207299855343
Validation loss: 2.5140949942387465

Epoch: 5| Step: 5
Training loss: 0.12278192999921636
Validation loss: 2.524377002167531

Epoch: 5| Step: 6
Training loss: 0.261271607199035
Validation loss: 2.4966196063478083

Epoch: 5| Step: 7
Training loss: 0.185232548746915
Validation loss: 2.516261651086152

Epoch: 5| Step: 8
Training loss: 0.09502925391799447
Validation loss: 2.5490664821276656

Epoch: 5| Step: 9
Training loss: 0.08034276265947604
Validation loss: 2.56386740172106

Epoch: 5| Step: 10
Training loss: 0.06444517722400604
Validation loss: 2.578156772292207

Epoch: 613| Step: 0
Training loss: 0.13476726282202586
Validation loss: 2.602024309234429

Epoch: 5| Step: 1
Training loss: 0.10510540115411549
Validation loss: 2.621957192205837

Epoch: 5| Step: 2
Training loss: 0.12545103418354214
Validation loss: 2.642619721847026

Epoch: 5| Step: 3
Training loss: 0.132466102911114
Validation loss: 2.6393253618146235

Epoch: 5| Step: 4
Training loss: 0.23163961953882523
Validation loss: 2.6148437516078857

Epoch: 5| Step: 5
Training loss: 0.0852575359249112
Validation loss: 2.6008375471398852

Epoch: 5| Step: 6
Training loss: 0.13117729540469258
Validation loss: 2.5748435776874006

Epoch: 5| Step: 7
Training loss: 0.14895713351062143
Validation loss: 2.582771654194831

Epoch: 5| Step: 8
Training loss: 0.1530144367726967
Validation loss: 2.5649310289943337

Epoch: 5| Step: 9
Training loss: 0.11977370704559338
Validation loss: 2.5813817648952835

Epoch: 5| Step: 10
Training loss: 0.09077873611416525
Validation loss: 2.561086701618395

Epoch: 614| Step: 0
Training loss: 0.09305749872576423
Validation loss: 2.5768816135079446

Epoch: 5| Step: 1
Training loss: 0.15848824627922695
Validation loss: 2.5851279511051604

Epoch: 5| Step: 2
Training loss: 0.21303068156122465
Validation loss: 2.5851834671924694

Epoch: 5| Step: 3
Training loss: 0.11293263066354742
Validation loss: 2.588990095126962

Epoch: 5| Step: 4
Training loss: 0.11416136102228307
Validation loss: 2.611970327648203

Epoch: 5| Step: 5
Training loss: 0.13568176324306144
Validation loss: 2.6049027995238943

Epoch: 5| Step: 6
Training loss: 0.13913752053860137
Validation loss: 2.598496828001356

Epoch: 5| Step: 7
Training loss: 0.0925887075645055
Validation loss: 2.619277731137206

Epoch: 5| Step: 8
Training loss: 0.17290895662200761
Validation loss: 2.6184753863705796

Epoch: 5| Step: 9
Training loss: 0.0890991672944831
Validation loss: 2.575101230812633

Epoch: 5| Step: 10
Training loss: 0.10868111687666927
Validation loss: 2.5805566481567026

Epoch: 615| Step: 0
Training loss: 0.12600516209028415
Validation loss: 2.5865268098366396

Epoch: 5| Step: 1
Training loss: 0.13416526972396875
Validation loss: 2.5660587693075168

Epoch: 5| Step: 2
Training loss: 0.23140991519701576
Validation loss: 2.5736038175880864

Epoch: 5| Step: 3
Training loss: 0.08875450913633441
Validation loss: 2.5902441324037144

Epoch: 5| Step: 4
Training loss: 0.2004421944843129
Validation loss: 2.545976794085265

Epoch: 5| Step: 5
Training loss: 0.20270539923782743
Validation loss: 2.555424163347434

Epoch: 5| Step: 6
Training loss: 0.14799774431671558
Validation loss: 2.5806048873994083

Epoch: 5| Step: 7
Training loss: 0.09490163100580068
Validation loss: 2.550234391597193

Epoch: 5| Step: 8
Training loss: 0.08767933349483527
Validation loss: 2.554339703781299

Epoch: 5| Step: 9
Training loss: 0.12306327180756017
Validation loss: 2.5854741686329312

Epoch: 5| Step: 10
Training loss: 0.06625800555596542
Validation loss: 2.5829950032363502

Epoch: 616| Step: 0
Training loss: 0.10874547478973018
Validation loss: 2.5884354207808453

Epoch: 5| Step: 1
Training loss: 0.13443930828114445
Validation loss: 2.5788819425872007

Epoch: 5| Step: 2
Training loss: 0.18917281266519892
Validation loss: 2.5641820745745627

Epoch: 5| Step: 3
Training loss: 0.1318941835375981
Validation loss: 2.5536220868167314

Epoch: 5| Step: 4
Training loss: 0.21383898475061497
Validation loss: 2.522225318937087

Epoch: 5| Step: 5
Training loss: 0.2169818346934222
Validation loss: 2.5129949412902755

Epoch: 5| Step: 6
Training loss: 0.1536870445866797
Validation loss: 2.5092559392678115

Epoch: 5| Step: 7
Training loss: 0.1151623662543299
Validation loss: 2.514967803570812

Epoch: 5| Step: 8
Training loss: 0.14329836142104613
Validation loss: 2.5347425358766906

Epoch: 5| Step: 9
Training loss: 0.12272475479905373
Validation loss: 2.559402192060594

Epoch: 5| Step: 10
Training loss: 0.09780319602274581
Validation loss: 2.5693693660183285

Epoch: 617| Step: 0
Training loss: 0.12692597172197786
Validation loss: 2.581863607126985

Epoch: 5| Step: 1
Training loss: 0.20392412933069273
Validation loss: 2.5631195210365387

Epoch: 5| Step: 2
Training loss: 0.18329094203419263
Validation loss: 2.5764794879130566

Epoch: 5| Step: 3
Training loss: 0.10892244360209935
Validation loss: 2.5544364931074934

Epoch: 5| Step: 4
Training loss: 0.1309253611662179
Validation loss: 2.551681991940184

Epoch: 5| Step: 5
Training loss: 0.11259722961847847
Validation loss: 2.530138082202842

Epoch: 5| Step: 6
Training loss: 0.200684735371482
Validation loss: 2.510412822181421

Epoch: 5| Step: 7
Training loss: 0.07081400320308559
Validation loss: 2.4833528600152026

Epoch: 5| Step: 8
Training loss: 0.18215765227640113
Validation loss: 2.505098302402988

Epoch: 5| Step: 9
Training loss: 0.07916545348063948
Validation loss: 2.5251609763116125

Epoch: 5| Step: 10
Training loss: 0.09385221095152078
Validation loss: 2.552202322326705

Epoch: 618| Step: 0
Training loss: 0.18086561352905595
Validation loss: 2.5467695099483114

Epoch: 5| Step: 1
Training loss: 0.14253025035009959
Validation loss: 2.5859581980236137

Epoch: 5| Step: 2
Training loss: 0.2958483637877814
Validation loss: 2.6126018121428816

Epoch: 5| Step: 3
Training loss: 0.10830520366310982
Validation loss: 2.5977924689624263

Epoch: 5| Step: 4
Training loss: 0.13737952768858347
Validation loss: 2.5703466479027934

Epoch: 5| Step: 5
Training loss: 0.16815700073124232
Validation loss: 2.561593033031227

Epoch: 5| Step: 6
Training loss: 0.16938575487021165
Validation loss: 2.526445666323121

Epoch: 5| Step: 7
Training loss: 0.1697713579911795
Validation loss: 2.5414112449562536

Epoch: 5| Step: 8
Training loss: 0.1759608887308764
Validation loss: 2.5249543505798013

Epoch: 5| Step: 9
Training loss: 0.1244109587529255
Validation loss: 2.4935035847612657

Epoch: 5| Step: 10
Training loss: 0.12285556377329467
Validation loss: 2.503840057827611

Epoch: 619| Step: 0
Training loss: 0.13045423335560496
Validation loss: 2.4792307766733708

Epoch: 5| Step: 1
Training loss: 0.18903057916578644
Validation loss: 2.503891267863328

Epoch: 5| Step: 2
Training loss: 0.14954861958587864
Validation loss: 2.533860218811615

Epoch: 5| Step: 3
Training loss: 0.12960740339125873
Validation loss: 2.5486786223262716

Epoch: 5| Step: 4
Training loss: 0.18212123578566405
Validation loss: 2.5692256341733826

Epoch: 5| Step: 5
Training loss: 0.1827394922493225
Validation loss: 2.5723508428806907

Epoch: 5| Step: 6
Training loss: 0.1379453944724339
Validation loss: 2.583709110579595

Epoch: 5| Step: 7
Training loss: 0.2441344756305632
Validation loss: 2.5762019070256303

Epoch: 5| Step: 8
Training loss: 0.09446074855729704
Validation loss: 2.562721741069108

Epoch: 5| Step: 9
Training loss: 0.12048298875300392
Validation loss: 2.557956559414551

Epoch: 5| Step: 10
Training loss: 0.12313731215490446
Validation loss: 2.552632744628796

Epoch: 620| Step: 0
Training loss: 0.234014384680894
Validation loss: 2.5382174934914934

Epoch: 5| Step: 1
Training loss: 0.2177684253064514
Validation loss: 2.532284603054292

Epoch: 5| Step: 2
Training loss: 0.1149482407397513
Validation loss: 2.5500129892403267

Epoch: 5| Step: 3
Training loss: 0.11352292129948435
Validation loss: 2.554795377476389

Epoch: 5| Step: 4
Training loss: 0.1599388216727305
Validation loss: 2.515281052471763

Epoch: 5| Step: 5
Training loss: 0.14108893900597325
Validation loss: 2.552419848645258

Epoch: 5| Step: 6
Training loss: 0.10480353060100529
Validation loss: 2.5766600562578112

Epoch: 5| Step: 7
Training loss: 0.1572094665141566
Validation loss: 2.579595535831466

Epoch: 5| Step: 8
Training loss: 0.13453435403563577
Validation loss: 2.569565667845236

Epoch: 5| Step: 9
Training loss: 0.10403525189053106
Validation loss: 2.5331914625074035

Epoch: 5| Step: 10
Training loss: 0.11714055392560957
Validation loss: 2.5222405824722864

Epoch: 621| Step: 0
Training loss: 0.09556247632935146
Validation loss: 2.543726300572628

Epoch: 5| Step: 1
Training loss: 0.18832634587603928
Validation loss: 2.53912865539139

Epoch: 5| Step: 2
Training loss: 0.07090662575298964
Validation loss: 2.5520248978140074

Epoch: 5| Step: 3
Training loss: 0.10394895471945957
Validation loss: 2.5531891674413227

Epoch: 5| Step: 4
Training loss: 0.15313655021468847
Validation loss: 2.540305274498153

Epoch: 5| Step: 5
Training loss: 0.19965022242104025
Validation loss: 2.5572437729417095

Epoch: 5| Step: 6
Training loss: 0.17973128075677505
Validation loss: 2.542993640584094

Epoch: 5| Step: 7
Training loss: 0.11443885903095771
Validation loss: 2.5425515600484627

Epoch: 5| Step: 8
Training loss: 0.12668777023629121
Validation loss: 2.545575595880844

Epoch: 5| Step: 9
Training loss: 0.11463556851063987
Validation loss: 2.537054490408784

Epoch: 5| Step: 10
Training loss: 0.08825000298563544
Validation loss: 2.5650709707359702

Epoch: 622| Step: 0
Training loss: 0.07185254731062814
Validation loss: 2.529445698389849

Epoch: 5| Step: 1
Training loss: 0.18294263593099844
Validation loss: 2.495780778718776

Epoch: 5| Step: 2
Training loss: 0.10762904737030836
Validation loss: 2.518923796329985

Epoch: 5| Step: 3
Training loss: 0.08605274687426044
Validation loss: 2.5059944406532897

Epoch: 5| Step: 4
Training loss: 0.234961744831883
Validation loss: 2.5301881520441047

Epoch: 5| Step: 5
Training loss: 0.12875782484516618
Validation loss: 2.514085587422711

Epoch: 5| Step: 6
Training loss: 0.07084826817153339
Validation loss: 2.532386203724501

Epoch: 5| Step: 7
Training loss: 0.13275585649614413
Validation loss: 2.561537054709689

Epoch: 5| Step: 8
Training loss: 0.09590393524570975
Validation loss: 2.592365145254891

Epoch: 5| Step: 9
Training loss: 0.1694504622271743
Validation loss: 2.592616526806067

Epoch: 5| Step: 10
Training loss: 0.11791070068825125
Validation loss: 2.6001290175750453

Epoch: 623| Step: 0
Training loss: 0.1640607288809953
Validation loss: 2.582168440177369

Epoch: 5| Step: 1
Training loss: 0.11893112101089055
Validation loss: 2.5687560362026742

Epoch: 5| Step: 2
Training loss: 0.21676964631795154
Validation loss: 2.5608607375514523

Epoch: 5| Step: 3
Training loss: 0.07689260969214874
Validation loss: 2.519688383790672

Epoch: 5| Step: 4
Training loss: 0.08219085788031706
Validation loss: 2.512477476349326

Epoch: 5| Step: 5
Training loss: 0.1559597179967283
Validation loss: 2.4745763566099273

Epoch: 5| Step: 6
Training loss: 0.12587444839100975
Validation loss: 2.46953293812945

Epoch: 5| Step: 7
Training loss: 0.12403636024012568
Validation loss: 2.4571893893723873

Epoch: 5| Step: 8
Training loss: 0.1011531309858419
Validation loss: 2.4694179089883352

Epoch: 5| Step: 9
Training loss: 0.11572245505271193
Validation loss: 2.5364163188424036

Epoch: 5| Step: 10
Training loss: 0.17541620709396047
Validation loss: 2.5315517001148367

Epoch: 624| Step: 0
Training loss: 0.10911804482410073
Validation loss: 2.5457721826184185

Epoch: 5| Step: 1
Training loss: 0.12950602352510426
Validation loss: 2.5705741686542236

Epoch: 5| Step: 2
Training loss: 0.10574495829097001
Validation loss: 2.6096417199439137

Epoch: 5| Step: 3
Training loss: 0.21077494185547224
Validation loss: 2.5899758979029714

Epoch: 5| Step: 4
Training loss: 0.0792725299004295
Validation loss: 2.5469039753284117

Epoch: 5| Step: 5
Training loss: 0.09813358948099862
Validation loss: 2.5265165071492275

Epoch: 5| Step: 6
Training loss: 0.07861163747739355
Validation loss: 2.4927797033401347

Epoch: 5| Step: 7
Training loss: 0.10846348262966911
Validation loss: 2.49758175619538

Epoch: 5| Step: 8
Training loss: 0.19850597777001616
Validation loss: 2.5091486469389164

Epoch: 5| Step: 9
Training loss: 0.2157059189402385
Validation loss: 2.514399167736523

Epoch: 5| Step: 10
Training loss: 0.09986042194686104
Validation loss: 2.5478887774309893

Epoch: 625| Step: 0
Training loss: 0.156124314780064
Validation loss: 2.5405414826849335

Epoch: 5| Step: 1
Training loss: 0.15901174052020883
Validation loss: 2.5302364062503906

Epoch: 5| Step: 2
Training loss: 0.0846162798838754
Validation loss: 2.514720020989724

Epoch: 5| Step: 3
Training loss: 0.13117549916225676
Validation loss: 2.5181597290652826

Epoch: 5| Step: 4
Training loss: 0.15920069035240833
Validation loss: 2.5312534252747705

Epoch: 5| Step: 5
Training loss: 0.10838633976692491
Validation loss: 2.512971217508183

Epoch: 5| Step: 6
Training loss: 0.14754300644228655
Validation loss: 2.504638602656952

Epoch: 5| Step: 7
Training loss: 0.09605750819373865
Validation loss: 2.5023936502745503

Epoch: 5| Step: 8
Training loss: 0.11322655672886536
Validation loss: 2.5277766952262914

Epoch: 5| Step: 9
Training loss: 0.09293420815105399
Validation loss: 2.510872562354214

Epoch: 5| Step: 10
Training loss: 0.21927586426630383
Validation loss: 2.5035662604931055

Epoch: 626| Step: 0
Training loss: 0.08061207141828837
Validation loss: 2.5337027315303526

Epoch: 5| Step: 1
Training loss: 0.11184218996446313
Validation loss: 2.5136327439859247

Epoch: 5| Step: 2
Training loss: 0.12540374312900238
Validation loss: 2.5113696192167243

Epoch: 5| Step: 3
Training loss: 0.22781307274022994
Validation loss: 2.5376056186241454

Epoch: 5| Step: 4
Training loss: 0.11702293921630115
Validation loss: 2.5163042418580988

Epoch: 5| Step: 5
Training loss: 0.16314418689020568
Validation loss: 2.51977399919146

Epoch: 5| Step: 6
Training loss: 0.11093286148636096
Validation loss: 2.5217595339202856

Epoch: 5| Step: 7
Training loss: 0.12484363745086333
Validation loss: 2.533592574259586

Epoch: 5| Step: 8
Training loss: 0.09977369219098012
Validation loss: 2.5281970437120176

Epoch: 5| Step: 9
Training loss: 0.11872651093719
Validation loss: 2.5105319978057117

Epoch: 5| Step: 10
Training loss: 0.16985809291053613
Validation loss: 2.5448460925443137

Epoch: 627| Step: 0
Training loss: 0.07960326134320311
Validation loss: 2.495818443431282

Epoch: 5| Step: 1
Training loss: 0.13736645677926818
Validation loss: 2.523729182586988

Epoch: 5| Step: 2
Training loss: 0.14331271740181126
Validation loss: 2.546437610256925

Epoch: 5| Step: 3
Training loss: 0.12316923642384027
Validation loss: 2.5429400796567143

Epoch: 5| Step: 4
Training loss: 0.08479950904410265
Validation loss: 2.515451769633947

Epoch: 5| Step: 5
Training loss: 0.07555905524491904
Validation loss: 2.5139192578851386

Epoch: 5| Step: 6
Training loss: 0.11922346424516284
Validation loss: 2.529425731991725

Epoch: 5| Step: 7
Training loss: 0.10408191710251276
Validation loss: 2.5339978615371326

Epoch: 5| Step: 8
Training loss: 0.25363275029451776
Validation loss: 2.515708361970348

Epoch: 5| Step: 9
Training loss: 0.08065974868249498
Validation loss: 2.5003078394217892

Epoch: 5| Step: 10
Training loss: 0.10147637603693295
Validation loss: 2.530208613459765

Epoch: 628| Step: 0
Training loss: 0.232344927191558
Validation loss: 2.512382980737358

Epoch: 5| Step: 1
Training loss: 0.12096952403714464
Validation loss: 2.519326004377066

Epoch: 5| Step: 2
Training loss: 0.07444581946129211
Validation loss: 2.5183333137102677

Epoch: 5| Step: 3
Training loss: 0.18348260315276144
Validation loss: 2.5365044067696676

Epoch: 5| Step: 4
Training loss: 0.08735622222698938
Validation loss: 2.5531008445946695

Epoch: 5| Step: 5
Training loss: 0.068351384104571
Validation loss: 2.554801529695839

Epoch: 5| Step: 6
Training loss: 0.13263265269561342
Validation loss: 2.5326771907566954

Epoch: 5| Step: 7
Training loss: 0.17195478668172595
Validation loss: 2.5405859963799036

Epoch: 5| Step: 8
Training loss: 0.09284299451449367
Validation loss: 2.542648404886321

Epoch: 5| Step: 9
Training loss: 0.0982000753646909
Validation loss: 2.5252991200962085

Epoch: 5| Step: 10
Training loss: 0.09085438202105912
Validation loss: 2.5553327522449996

Epoch: 629| Step: 0
Training loss: 0.07642726084200387
Validation loss: 2.5522866632471026

Epoch: 5| Step: 1
Training loss: 0.15239982306637218
Validation loss: 2.6003238629301992

Epoch: 5| Step: 2
Training loss: 0.13629994278717308
Validation loss: 2.5523490558150037

Epoch: 5| Step: 3
Training loss: 0.1336740291606934
Validation loss: 2.5491295941390644

Epoch: 5| Step: 4
Training loss: 0.12177057469206994
Validation loss: 2.576373746292129

Epoch: 5| Step: 5
Training loss: 0.21418661709890957
Validation loss: 2.5545699869096197

Epoch: 5| Step: 6
Training loss: 0.11411624680749868
Validation loss: 2.551929556805436

Epoch: 5| Step: 7
Training loss: 0.11007146396206613
Validation loss: 2.5322627759933662

Epoch: 5| Step: 8
Training loss: 0.1475384237059969
Validation loss: 2.534417907012565

Epoch: 5| Step: 9
Training loss: 0.15992461293965154
Validation loss: 2.5140106885367937

Epoch: 5| Step: 10
Training loss: 0.12154676316517644
Validation loss: 2.521259676227726

Epoch: 630| Step: 0
Training loss: 0.12157171657578311
Validation loss: 2.527887127738648

Epoch: 5| Step: 1
Training loss: 0.1189071995099488
Validation loss: 2.4958997511724297

Epoch: 5| Step: 2
Training loss: 0.09501730160581903
Validation loss: 2.52279514813258

Epoch: 5| Step: 3
Training loss: 0.1614190651199775
Validation loss: 2.5228294443311428

Epoch: 5| Step: 4
Training loss: 0.17497298061879096
Validation loss: 2.521264106462557

Epoch: 5| Step: 5
Training loss: 0.11589644456389989
Validation loss: 2.5045030994785034

Epoch: 5| Step: 6
Training loss: 0.19846011618645587
Validation loss: 2.5145228177791714

Epoch: 5| Step: 7
Training loss: 0.12260100782017708
Validation loss: 2.524233241357069

Epoch: 5| Step: 8
Training loss: 0.0894398629464857
Validation loss: 2.5324818489923984

Epoch: 5| Step: 9
Training loss: 0.1611559591140918
Validation loss: 2.5743168095106697

Epoch: 5| Step: 10
Training loss: 0.09110516310625312
Validation loss: 2.5330771502357123

Epoch: 631| Step: 0
Training loss: 0.058347177255292086
Validation loss: 2.562761875140348

Epoch: 5| Step: 1
Training loss: 0.14600514540154244
Validation loss: 2.558439670041773

Epoch: 5| Step: 2
Training loss: 0.11584908785715083
Validation loss: 2.593681333551896

Epoch: 5| Step: 3
Training loss: 0.09296537421212325
Validation loss: 2.57622428527947

Epoch: 5| Step: 4
Training loss: 0.11319234664420509
Validation loss: 2.5589015875389927

Epoch: 5| Step: 5
Training loss: 0.23522371167225306
Validation loss: 2.5576910970902036

Epoch: 5| Step: 6
Training loss: 0.09441967539108757
Validation loss: 2.491441651917202

Epoch: 5| Step: 7
Training loss: 0.09357882309814232
Validation loss: 2.506016268891588

Epoch: 5| Step: 8
Training loss: 0.1857128806113442
Validation loss: 2.5085103541142875

Epoch: 5| Step: 9
Training loss: 0.15555915695895803
Validation loss: 2.5145482203513723

Epoch: 5| Step: 10
Training loss: 0.0968385364372985
Validation loss: 2.5472760443715705

Epoch: 632| Step: 0
Training loss: 0.10278500172543235
Validation loss: 2.5648876364684736

Epoch: 5| Step: 1
Training loss: 0.16393302167912216
Validation loss: 2.5535357228570157

Epoch: 5| Step: 2
Training loss: 0.1339910472176118
Validation loss: 2.561809615869124

Epoch: 5| Step: 3
Training loss: 0.10454673769247297
Validation loss: 2.539365318295047

Epoch: 5| Step: 4
Training loss: 0.12526571820381602
Validation loss: 2.499511472079581

Epoch: 5| Step: 5
Training loss: 0.16580333600349242
Validation loss: 2.487961422061788

Epoch: 5| Step: 6
Training loss: 0.1408567109070259
Validation loss: 2.496024576994205

Epoch: 5| Step: 7
Training loss: 0.21339760355792564
Validation loss: 2.508954284255275

Epoch: 5| Step: 8
Training loss: 0.11674630639642754
Validation loss: 2.518254155522406

Epoch: 5| Step: 9
Training loss: 0.08672856777908206
Validation loss: 2.508854897252943

Epoch: 5| Step: 10
Training loss: 0.112137005886694
Validation loss: 2.515715790857146

Epoch: 633| Step: 0
Training loss: 0.09608627034362369
Validation loss: 2.5511303634042637

Epoch: 5| Step: 1
Training loss: 0.09228761356856484
Validation loss: 2.5586490182074546

Epoch: 5| Step: 2
Training loss: 0.08995520892768287
Validation loss: 2.568003423467386

Epoch: 5| Step: 3
Training loss: 0.1578835332222529
Validation loss: 2.5740058874779113

Epoch: 5| Step: 4
Training loss: 0.1796223895653759
Validation loss: 2.56157508263124

Epoch: 5| Step: 5
Training loss: 0.237199108357386
Validation loss: 2.531495728915708

Epoch: 5| Step: 6
Training loss: 0.10557765988931565
Validation loss: 2.533884975780295

Epoch: 5| Step: 7
Training loss: 0.1564288069915491
Validation loss: 2.5130906849548675

Epoch: 5| Step: 8
Training loss: 0.21254812039363294
Validation loss: 2.4987996270321227

Epoch: 5| Step: 9
Training loss: 0.06058093236002467
Validation loss: 2.4994306890284532

Epoch: 5| Step: 10
Training loss: 0.14961758633382602
Validation loss: 2.4936847661889727

Epoch: 634| Step: 0
Training loss: 0.14413866646529302
Validation loss: 2.5060836695064226

Epoch: 5| Step: 1
Training loss: 0.16724395734551104
Validation loss: 2.521545105934316

Epoch: 5| Step: 2
Training loss: 0.30348851194509563
Validation loss: 2.5334725962066957

Epoch: 5| Step: 3
Training loss: 0.18151147414291194
Validation loss: 2.510898263233174

Epoch: 5| Step: 4
Training loss: 0.13810145899233636
Validation loss: 2.4825327110021105

Epoch: 5| Step: 5
Training loss: 0.18309669982257995
Validation loss: 2.4975410961612408

Epoch: 5| Step: 6
Training loss: 0.20680179115968678
Validation loss: 2.502230406070542

Epoch: 5| Step: 7
Training loss: 0.20599272099037141
Validation loss: 2.5372958763288387

Epoch: 5| Step: 8
Training loss: 0.24435194406748845
Validation loss: 2.5290455305479185

Epoch: 5| Step: 9
Training loss: 0.11714539168730433
Validation loss: 2.602050019167901

Epoch: 5| Step: 10
Training loss: 0.16688867896875548
Validation loss: 2.6146819501325993

Epoch: 635| Step: 0
Training loss: 0.19948140762272198
Validation loss: 2.6346830495594955

Epoch: 5| Step: 1
Training loss: 0.18053678204573878
Validation loss: 2.6728485901214145

Epoch: 5| Step: 2
Training loss: 0.21774506490996853
Validation loss: 2.6380620164688113

Epoch: 5| Step: 3
Training loss: 0.2607671318552386
Validation loss: 2.635506479864166

Epoch: 5| Step: 4
Training loss: 0.20050770646431915
Validation loss: 2.593113820841241

Epoch: 5| Step: 5
Training loss: 0.17240962413205566
Validation loss: 2.5563331851020057

Epoch: 5| Step: 6
Training loss: 0.18945302668303465
Validation loss: 2.522452104093993

Epoch: 5| Step: 7
Training loss: 0.22950173216105832
Validation loss: 2.4997904474356485

Epoch: 5| Step: 8
Training loss: 0.199374026203468
Validation loss: 2.527582337905515

Epoch: 5| Step: 9
Training loss: 0.09654211602286839
Validation loss: 2.5022557018895033

Epoch: 5| Step: 10
Training loss: 0.1667394119193974
Validation loss: 2.513135467589187

Epoch: 636| Step: 0
Training loss: 0.22534997166842274
Validation loss: 2.5304730599240637

Epoch: 5| Step: 1
Training loss: 0.14420679119284494
Validation loss: 2.530864234473458

Epoch: 5| Step: 2
Training loss: 0.1985441548287297
Validation loss: 2.5502994891905644

Epoch: 5| Step: 3
Training loss: 0.18740401195203069
Validation loss: 2.574430463683308

Epoch: 5| Step: 4
Training loss: 0.16474973836235493
Validation loss: 2.5318643302248254

Epoch: 5| Step: 5
Training loss: 0.22819037807011003
Validation loss: 2.477465668461904

Epoch: 5| Step: 6
Training loss: 0.14527598096483185
Validation loss: 2.4712118779110814

Epoch: 5| Step: 7
Training loss: 0.20123399312471615
Validation loss: 2.450577486597377

Epoch: 5| Step: 8
Training loss: 0.24023139765685503
Validation loss: 2.4765115529977275

Epoch: 5| Step: 9
Training loss: 0.2859872310937451
Validation loss: 2.484493700368638

Epoch: 5| Step: 10
Training loss: 0.19256844254424257
Validation loss: 2.524130287722259

Epoch: 637| Step: 0
Training loss: 0.2145922055231224
Validation loss: 2.5737494693979017

Epoch: 5| Step: 1
Training loss: 0.3439651812783034
Validation loss: 2.6135435005431065

Epoch: 5| Step: 2
Training loss: 0.12588436242139428
Validation loss: 2.424706434658319

Epoch: 5| Step: 3
Training loss: 0.39428196953886757
Validation loss: 2.390927929270538

Epoch: 5| Step: 4
Training loss: 0.30936189007195525
Validation loss: 2.4004215554316244

Epoch: 5| Step: 5
Training loss: 0.2778065406623577
Validation loss: 2.437610037386337

Epoch: 5| Step: 6
Training loss: 0.2131486606328978
Validation loss: 2.533202346760019

Epoch: 5| Step: 7
Training loss: 0.3658044008133672
Validation loss: 2.652600884147957

Epoch: 5| Step: 8
Training loss: 0.32905679052966
Validation loss: 2.606300340966339

Epoch: 5| Step: 9
Training loss: 0.29109317591104295
Validation loss: 2.5738882802869414

Epoch: 5| Step: 10
Training loss: 0.31066838172606664
Validation loss: 2.5125645230829767

Epoch: 638| Step: 0
Training loss: 0.24414530940330162
Validation loss: 2.485112738614683

Epoch: 5| Step: 1
Training loss: 0.5126038387984609
Validation loss: 2.4464435039614885

Epoch: 5| Step: 2
Training loss: 0.41440988759143765
Validation loss: 2.5138717632956404

Epoch: 5| Step: 3
Training loss: 0.29163599136804047
Validation loss: 2.525314525958225

Epoch: 5| Step: 4
Training loss: 0.4502187131149712
Validation loss: 2.6390515478276244

Epoch: 5| Step: 5
Training loss: 0.855537794976065
Validation loss: 2.690266439976369

Epoch: 5| Step: 6
Training loss: 0.5212676780319274
Validation loss: 2.5869250323888946

Epoch: 5| Step: 7
Training loss: 0.3328090421291044
Validation loss: 2.5215773268054544

Epoch: 5| Step: 8
Training loss: 0.7997108190132127
Validation loss: 2.497871429004445

Epoch: 5| Step: 9
Training loss: 0.43010843639636526
Validation loss: 2.4151870572523615

Epoch: 5| Step: 10
Training loss: 0.8701555476953868
Validation loss: 2.3882985847192346

Epoch: 639| Step: 0
Training loss: 0.4727517338927218
Validation loss: 2.4314103663049997

Epoch: 5| Step: 1
Training loss: 0.6145575297051955
Validation loss: 2.5948444266062602

Epoch: 5| Step: 2
Training loss: 0.9372294671411086
Validation loss: 2.7464607262078804

Epoch: 5| Step: 3
Training loss: 0.9947119609331079
Validation loss: 2.6970496720494173

Epoch: 5| Step: 4
Training loss: 0.4077569265975948
Validation loss: 2.4691407914765957

Epoch: 5| Step: 5
Training loss: 0.8646512100661267
Validation loss: 2.3561907009647802

Epoch: 5| Step: 6
Training loss: 0.9213079227783829
Validation loss: 2.3184771938370528

Epoch: 5| Step: 7
Training loss: 0.7199401124578474
Validation loss: 2.372275677885176

Epoch: 5| Step: 8
Training loss: 1.035669163721678
Validation loss: 2.5475554516975825

Epoch: 5| Step: 9
Training loss: 0.6718879964591712
Validation loss: 2.502062923675379

Epoch: 5| Step: 10
Training loss: 0.5845815099885782
Validation loss: 2.4660478733959006

Epoch: 640| Step: 0
Training loss: 0.7048576623198559
Validation loss: 2.415329900440105

Epoch: 5| Step: 1
Training loss: 0.8827312060710388
Validation loss: 2.4095473149226296

Epoch: 5| Step: 2
Training loss: 0.6333808465962211
Validation loss: 2.3554067529899805

Epoch: 5| Step: 3
Training loss: 0.8139657224800296
Validation loss: 2.3821587994434514

Epoch: 5| Step: 4
Training loss: 0.5395648384852192
Validation loss: 2.359661149865425

Epoch: 5| Step: 5
Training loss: 0.642156909297564
Validation loss: 2.3913579690194493

Epoch: 5| Step: 6
Training loss: 0.6757086786541849
Validation loss: 2.4445123876776784

Epoch: 5| Step: 7
Training loss: 0.6478425019268622
Validation loss: 2.424208632380023

Epoch: 5| Step: 8
Training loss: 0.46518044339308806
Validation loss: 2.485250157772566

Epoch: 5| Step: 9
Training loss: 0.8188713857343605
Validation loss: 2.5426677310648267

Epoch: 5| Step: 10
Training loss: 1.0851432036019986
Validation loss: 2.553472600274291

Epoch: 641| Step: 0
Training loss: 0.779598130052241
Validation loss: 2.622132172852304

Epoch: 5| Step: 1
Training loss: 0.6031196307402859
Validation loss: 2.5740466341580697

Epoch: 5| Step: 2
Training loss: 0.354888127423105
Validation loss: 2.515342778608004

Epoch: 5| Step: 3
Training loss: 0.39739601673540287
Validation loss: 2.460857873824147

Epoch: 5| Step: 4
Training loss: 0.6305882015777211
Validation loss: 2.43498415459672

Epoch: 5| Step: 5
Training loss: 0.7153933554132023
Validation loss: 2.4963386109093806

Epoch: 5| Step: 6
Training loss: 0.8738852279756432
Validation loss: 2.517797574593501

Epoch: 5| Step: 7
Training loss: 0.8351958719530619
Validation loss: 2.5242425341863735

Epoch: 5| Step: 8
Training loss: 0.4274024023502168
Validation loss: 2.517266367505047

Epoch: 5| Step: 9
Training loss: 0.6145140048433936
Validation loss: 2.505060385260994

Epoch: 5| Step: 10
Training loss: 1.0323634638808616
Validation loss: 2.56206230589356

Epoch: 642| Step: 0
Training loss: 0.7050572653773018
Validation loss: 2.5238283210851313

Epoch: 5| Step: 1
Training loss: 0.4193850079463677
Validation loss: 2.496910364113946

Epoch: 5| Step: 2
Training loss: 0.8011406440915653
Validation loss: 2.4782149629658097

Epoch: 5| Step: 3
Training loss: 0.8463817102889918
Validation loss: 2.4321009847584936

Epoch: 5| Step: 4
Training loss: 0.7264895248681804
Validation loss: 2.3785389352050306

Epoch: 5| Step: 5
Training loss: 0.882475391941788
Validation loss: 2.3252091714935132

Epoch: 5| Step: 6
Training loss: 0.4356066401921313
Validation loss: 2.3117389718229417

Epoch: 5| Step: 7
Training loss: 0.446010644657395
Validation loss: 2.2922280562724975

Epoch: 5| Step: 8
Training loss: 0.3930456499578424
Validation loss: 2.327714479586464

Epoch: 5| Step: 9
Training loss: 0.7125921591334583
Validation loss: 2.416371809850366

Epoch: 5| Step: 10
Training loss: 0.4975086819787354
Validation loss: 2.424970165763091

Epoch: 643| Step: 0
Training loss: 0.3070975501424234
Validation loss: 2.4824379781125194

Epoch: 5| Step: 1
Training loss: 0.48629679444900126
Validation loss: 2.5272258900905764

Epoch: 5| Step: 2
Training loss: 0.47326265008244467
Validation loss: 2.5493144468009157

Epoch: 5| Step: 3
Training loss: 0.611741970980779
Validation loss: 2.5147593007438243

Epoch: 5| Step: 4
Training loss: 0.5038687522006846
Validation loss: 2.4668077653700955

Epoch: 5| Step: 5
Training loss: 0.369782711869826
Validation loss: 2.433407025128123

Epoch: 5| Step: 6
Training loss: 0.39972437809988765
Validation loss: 2.3470127346524654

Epoch: 5| Step: 7
Training loss: 0.44223986878335514
Validation loss: 2.2937074721298623

Epoch: 5| Step: 8
Training loss: 0.5178336898068684
Validation loss: 2.291383055274643

Epoch: 5| Step: 9
Training loss: 0.5564382620271403
Validation loss: 2.306712025241713

Epoch: 5| Step: 10
Training loss: 0.2698484019909473
Validation loss: 2.3875109477243943

Epoch: 644| Step: 0
Training loss: 0.25775913206345485
Validation loss: 2.4441585303256046

Epoch: 5| Step: 1
Training loss: 0.4339941083776266
Validation loss: 2.4824534893810326

Epoch: 5| Step: 2
Training loss: 0.39898378657859135
Validation loss: 2.4851202146037807

Epoch: 5| Step: 3
Training loss: 0.3214516271920554
Validation loss: 2.4573688478284073

Epoch: 5| Step: 4
Training loss: 0.47918011985082004
Validation loss: 2.4642139370774196

Epoch: 5| Step: 5
Training loss: 0.3471739241334698
Validation loss: 2.46167317879432

Epoch: 5| Step: 6
Training loss: 0.38919777490919744
Validation loss: 2.493199783757655

Epoch: 5| Step: 7
Training loss: 0.34302814508092666
Validation loss: 2.482563639835482

Epoch: 5| Step: 8
Training loss: 0.3623626128004319
Validation loss: 2.494859320000945

Epoch: 5| Step: 9
Training loss: 0.35757140903612733
Validation loss: 2.4938292692739674

Epoch: 5| Step: 10
Training loss: 0.2709054331299073
Validation loss: 2.454881248301215

Epoch: 645| Step: 0
Training loss: 0.3471400039075955
Validation loss: 2.4641118289434374

Epoch: 5| Step: 1
Training loss: 0.4278944926411847
Validation loss: 2.444033819990367

Epoch: 5| Step: 2
Training loss: 0.2588746846904888
Validation loss: 2.4238005764445703

Epoch: 5| Step: 3
Training loss: 0.37638228682600405
Validation loss: 2.4208329249581415

Epoch: 5| Step: 4
Training loss: 0.26710910483584
Validation loss: 2.4306322681218338

Epoch: 5| Step: 5
Training loss: 0.2584475296915717
Validation loss: 2.4679458687583606

Epoch: 5| Step: 6
Training loss: 0.4530669043557498
Validation loss: 2.4934248854682575

Epoch: 5| Step: 7
Training loss: 0.30418656814256895
Validation loss: 2.492705558859405

Epoch: 5| Step: 8
Training loss: 0.36378632577108183
Validation loss: 2.5584204249261626

Epoch: 5| Step: 9
Training loss: 0.36013845536300343
Validation loss: 2.5317756829094025

Epoch: 5| Step: 10
Training loss: 0.29879245669850474
Validation loss: 2.510693151210742

Epoch: 646| Step: 0
Training loss: 0.31097982923605305
Validation loss: 2.4897808956458523

Epoch: 5| Step: 1
Training loss: 0.30969858971534253
Validation loss: 2.46299547907733

Epoch: 5| Step: 2
Training loss: 0.3098047012946684
Validation loss: 2.454114373871448

Epoch: 5| Step: 3
Training loss: 0.36178611391753124
Validation loss: 2.459230063543246

Epoch: 5| Step: 4
Training loss: 0.2236738791927253
Validation loss: 2.4553769039855213

Epoch: 5| Step: 5
Training loss: 0.20862919938401975
Validation loss: 2.547625301005165

Epoch: 5| Step: 6
Training loss: 0.35162045742834014
Validation loss: 2.5485506497539814

Epoch: 5| Step: 7
Training loss: 0.31660592878038357
Validation loss: 2.541535425723105

Epoch: 5| Step: 8
Training loss: 0.24600622346321177
Validation loss: 2.586747781650194

Epoch: 5| Step: 9
Training loss: 0.3627037873148484
Validation loss: 2.5568523263086

Epoch: 5| Step: 10
Training loss: 0.35548757146954457
Validation loss: 2.5646007339690797

Epoch: 647| Step: 0
Training loss: 0.2546721717106737
Validation loss: 2.568845025092804

Epoch: 5| Step: 1
Training loss: 0.2655092155326308
Validation loss: 2.518582876088945

Epoch: 5| Step: 2
Training loss: 0.1726603339217143
Validation loss: 2.5140641438294193

Epoch: 5| Step: 3
Training loss: 0.1970837009142888
Validation loss: 2.451579065398343

Epoch: 5| Step: 4
Training loss: 0.2801705680035064
Validation loss: 2.4995897520484998

Epoch: 5| Step: 5
Training loss: 0.2953260191593137
Validation loss: 2.465697225956538

Epoch: 5| Step: 6
Training loss: 0.29266565538925365
Validation loss: 2.4757380910830338

Epoch: 5| Step: 7
Training loss: 0.22872645279065104
Validation loss: 2.482571889214818

Epoch: 5| Step: 8
Training loss: 0.23675168912993966
Validation loss: 2.46379626324213

Epoch: 5| Step: 9
Training loss: 0.22224952961278682
Validation loss: 2.515060291104604

Epoch: 5| Step: 10
Training loss: 0.32504282632506876
Validation loss: 2.563026761252985

Epoch: 648| Step: 0
Training loss: 0.16319528214823575
Validation loss: 2.562970180580131

Epoch: 5| Step: 1
Training loss: 0.22232048752049907
Validation loss: 2.5543026811954

Epoch: 5| Step: 2
Training loss: 0.17734216025560004
Validation loss: 2.550371829628441

Epoch: 5| Step: 3
Training loss: 0.20413058133971626
Validation loss: 2.560851772814816

Epoch: 5| Step: 4
Training loss: 0.14141002065152009
Validation loss: 2.49482637231783

Epoch: 5| Step: 5
Training loss: 0.27589961961614223
Validation loss: 2.4580843917445874

Epoch: 5| Step: 6
Training loss: 0.27584360622645565
Validation loss: 2.418881849264154

Epoch: 5| Step: 7
Training loss: 0.3047218547917549
Validation loss: 2.419312418152185

Epoch: 5| Step: 8
Training loss: 0.17640724508749894
Validation loss: 2.4326171938231664

Epoch: 5| Step: 9
Training loss: 0.19147870580279977
Validation loss: 2.4391139986603463

Epoch: 5| Step: 10
Training loss: 0.2419730359766579
Validation loss: 2.4301482461039186

Epoch: 649| Step: 0
Training loss: 0.27987581551770774
Validation loss: 2.4707983845963017

Epoch: 5| Step: 1
Training loss: 0.19819806928129718
Validation loss: 2.52172179613648

Epoch: 5| Step: 2
Training loss: 0.23486675489874537
Validation loss: 2.5481719114654044

Epoch: 5| Step: 3
Training loss: 0.2898226486092571
Validation loss: 2.555526982320539

Epoch: 5| Step: 4
Training loss: 0.17474691405934667
Validation loss: 2.5382651870155604

Epoch: 5| Step: 5
Training loss: 0.30340177740206337
Validation loss: 2.519953823877552

Epoch: 5| Step: 6
Training loss: 0.3111637753814757
Validation loss: 2.4911972713585633

Epoch: 5| Step: 7
Training loss: 0.17603269712651376
Validation loss: 2.455095984222428

Epoch: 5| Step: 8
Training loss: 0.20986922279208547
Validation loss: 2.4151267625375126

Epoch: 5| Step: 9
Training loss: 0.21911881214181114
Validation loss: 2.383892555969699

Epoch: 5| Step: 10
Training loss: 0.29695853513683407
Validation loss: 2.3740470120612067

Epoch: 650| Step: 0
Training loss: 0.2336770633132997
Validation loss: 2.3942921657692873

Epoch: 5| Step: 1
Training loss: 0.31858246832419257
Validation loss: 2.402468860542179

Epoch: 5| Step: 2
Training loss: 0.26385615937787826
Validation loss: 2.4053380735332124

Epoch: 5| Step: 3
Training loss: 0.22694833556750102
Validation loss: 2.464514993387515

Epoch: 5| Step: 4
Training loss: 0.27503194515043766
Validation loss: 2.5505190714895707

Epoch: 5| Step: 5
Training loss: 0.30699353653785744
Validation loss: 2.564597171300844

Epoch: 5| Step: 6
Training loss: 0.20291178773978125
Validation loss: 2.587159308360876

Epoch: 5| Step: 7
Training loss: 0.35572459896091047
Validation loss: 2.57315687958268

Epoch: 5| Step: 8
Training loss: 0.27269807019360465
Validation loss: 2.5366363363544204

Epoch: 5| Step: 9
Training loss: 0.16051897980719187
Validation loss: 2.480788188606803

Epoch: 5| Step: 10
Training loss: 0.14251214943926252
Validation loss: 2.4620844332369454

Epoch: 651| Step: 0
Training loss: 0.3041986921621207
Validation loss: 2.420727186618849

Epoch: 5| Step: 1
Training loss: 0.1740752349643061
Validation loss: 2.392643305426614

Epoch: 5| Step: 2
Training loss: 0.2593809017980678
Validation loss: 2.3897283562764526

Epoch: 5| Step: 3
Training loss: 0.3337531153572784
Validation loss: 2.3810519305013504

Epoch: 5| Step: 4
Training loss: 0.34838958077155113
Validation loss: 2.3862569646970524

Epoch: 5| Step: 5
Training loss: 0.2708559240798579
Validation loss: 2.4187109850336057

Epoch: 5| Step: 6
Training loss: 0.182524907669229
Validation loss: 2.4403331447479175

Epoch: 5| Step: 7
Training loss: 0.21221583278360304
Validation loss: 2.494576826257604

Epoch: 5| Step: 8
Training loss: 0.21996345465738484
Validation loss: 2.5514937474225823

Epoch: 5| Step: 9
Training loss: 0.391629187163693
Validation loss: 2.545756519398675

Epoch: 5| Step: 10
Training loss: 0.23482624166353894
Validation loss: 2.521411593657465

Epoch: 652| Step: 0
Training loss: 0.2926921937889119
Validation loss: 2.4713884239727437

Epoch: 5| Step: 1
Training loss: 0.22883848059428458
Validation loss: 2.4143748466446184

Epoch: 5| Step: 2
Training loss: 0.19018313757725577
Validation loss: 2.423355364616061

Epoch: 5| Step: 3
Training loss: 0.2914043237249203
Validation loss: 2.412232716481458

Epoch: 5| Step: 4
Training loss: 0.2742325939585541
Validation loss: 2.413162271206422

Epoch: 5| Step: 5
Training loss: 0.36438718242138735
Validation loss: 2.414071274438216

Epoch: 5| Step: 6
Training loss: 0.28085641342108414
Validation loss: 2.4169926054054978

Epoch: 5| Step: 7
Training loss: 0.29848159693932974
Validation loss: 2.456670006168852

Epoch: 5| Step: 8
Training loss: 0.29992391346633457
Validation loss: 2.476092207634212

Epoch: 5| Step: 9
Training loss: 0.22246386766387874
Validation loss: 2.5189696100357937

Epoch: 5| Step: 10
Training loss: 0.22618107916990934
Validation loss: 2.5590815138298835

Epoch: 653| Step: 0
Training loss: 0.2758676982392118
Validation loss: 2.559091157962656

Epoch: 5| Step: 1
Training loss: 0.40209030761336223
Validation loss: 2.5487192677201977

Epoch: 5| Step: 2
Training loss: 0.22163003205730952
Validation loss: 2.481136678513892

Epoch: 5| Step: 3
Training loss: 0.26535188434277507
Validation loss: 2.4544337559164284

Epoch: 5| Step: 4
Training loss: 0.25249011457090353
Validation loss: 2.449525797430218

Epoch: 5| Step: 5
Training loss: 0.25698247870042895
Validation loss: 2.421437609630152

Epoch: 5| Step: 6
Training loss: 0.26155513659632695
Validation loss: 2.383142978203911

Epoch: 5| Step: 7
Training loss: 0.2604435271079975
Validation loss: 2.3907998911319646

Epoch: 5| Step: 8
Training loss: 0.31020238951135326
Validation loss: 2.3989198560466574

Epoch: 5| Step: 9
Training loss: 0.2786512047555926
Validation loss: 2.4164660412598447

Epoch: 5| Step: 10
Training loss: 0.28567032656797403
Validation loss: 2.4052802189080076

Epoch: 654| Step: 0
Training loss: 0.303936877337694
Validation loss: 2.4474651474438143

Epoch: 5| Step: 1
Training loss: 0.19008731876251014
Validation loss: 2.4588969641091305

Epoch: 5| Step: 2
Training loss: 0.24033254462927062
Validation loss: 2.4515776275467323

Epoch: 5| Step: 3
Training loss: 0.2958746293061178
Validation loss: 2.479496960152176

Epoch: 5| Step: 4
Training loss: 0.19251624190562402
Validation loss: 2.4867806159785464

Epoch: 5| Step: 5
Training loss: 0.21799893529111383
Validation loss: 2.4850929730929217

Epoch: 5| Step: 6
Training loss: 0.1463859100014077
Validation loss: 2.486110593608925

Epoch: 5| Step: 7
Training loss: 0.19121459201519447
Validation loss: 2.4357917485511695

Epoch: 5| Step: 8
Training loss: 0.19947500203784388
Validation loss: 2.431514419672054

Epoch: 5| Step: 9
Training loss: 0.2209919078260219
Validation loss: 2.423400254656027

Epoch: 5| Step: 10
Training loss: 0.2183054852394802
Validation loss: 2.4375661100052515

Epoch: 655| Step: 0
Training loss: 0.22766518269636335
Validation loss: 2.4030116194254467

Epoch: 5| Step: 1
Training loss: 0.17030152845477986
Validation loss: 2.418559765730925

Epoch: 5| Step: 2
Training loss: 0.22143679180026632
Validation loss: 2.397937590686837

Epoch: 5| Step: 3
Training loss: 0.165806144495497
Validation loss: 2.4261304800035624

Epoch: 5| Step: 4
Training loss: 0.17916226330787216
Validation loss: 2.4047404219049597

Epoch: 5| Step: 5
Training loss: 0.17036478373116215
Validation loss: 2.4101208474666453

Epoch: 5| Step: 6
Training loss: 0.1654987873212318
Validation loss: 2.4340988370067733

Epoch: 5| Step: 7
Training loss: 0.17369250032214828
Validation loss: 2.4519819788435253

Epoch: 5| Step: 8
Training loss: 0.12408507685178813
Validation loss: 2.4604482919441315

Epoch: 5| Step: 9
Training loss: 0.22019440752770228
Validation loss: 2.482652511423534

Epoch: 5| Step: 10
Training loss: 0.16729942857705432
Validation loss: 2.4613309749784

Epoch: 656| Step: 0
Training loss: 0.28109086355918855
Validation loss: 2.4778397910288046

Epoch: 5| Step: 1
Training loss: 0.2302163406780377
Validation loss: 2.455314989302109

Epoch: 5| Step: 2
Training loss: 0.1704134954436872
Validation loss: 2.450167713029377

Epoch: 5| Step: 3
Training loss: 0.16375635738990238
Validation loss: 2.4648047231986903

Epoch: 5| Step: 4
Training loss: 0.1860949002349692
Validation loss: 2.4601626878222227

Epoch: 5| Step: 5
Training loss: 0.1732085845854213
Validation loss: 2.4422383242690415

Epoch: 5| Step: 6
Training loss: 0.17818203815959072
Validation loss: 2.439409060032485

Epoch: 5| Step: 7
Training loss: 0.13104086005635304
Validation loss: 2.447733632202436

Epoch: 5| Step: 8
Training loss: 0.13594937464490253
Validation loss: 2.458039644933073

Epoch: 5| Step: 9
Training loss: 0.13985126278052784
Validation loss: 2.4414944467016215

Epoch: 5| Step: 10
Training loss: 0.14919496191858211
Validation loss: 2.4573953857811497

Epoch: 657| Step: 0
Training loss: 0.17466384925493134
Validation loss: 2.4497161897570363

Epoch: 5| Step: 1
Training loss: 0.1850658707207067
Validation loss: 2.4605914498782178

Epoch: 5| Step: 2
Training loss: 0.13513256648278843
Validation loss: 2.448404807435359

Epoch: 5| Step: 3
Training loss: 0.14279079905726774
Validation loss: 2.461123698623114

Epoch: 5| Step: 4
Training loss: 0.2303110892693884
Validation loss: 2.471074453570343

Epoch: 5| Step: 5
Training loss: 0.13474535444095254
Validation loss: 2.454752605559144

Epoch: 5| Step: 6
Training loss: 0.1614054079116908
Validation loss: 2.461282427070912

Epoch: 5| Step: 7
Training loss: 0.19633519403958127
Validation loss: 2.485633377133317

Epoch: 5| Step: 8
Training loss: 0.17655094961347456
Validation loss: 2.4358906656431647

Epoch: 5| Step: 9
Training loss: 0.14012374552046952
Validation loss: 2.4253060712996994

Epoch: 5| Step: 10
Training loss: 0.1263030869814398
Validation loss: 2.4368107812321624

Epoch: 658| Step: 0
Training loss: 0.17775760750311734
Validation loss: 2.42076286638508

Epoch: 5| Step: 1
Training loss: 0.13551623935399665
Validation loss: 2.43160618655811

Epoch: 5| Step: 2
Training loss: 0.10417609221809562
Validation loss: 2.4265663578359953

Epoch: 5| Step: 3
Training loss: 0.12860395648262862
Validation loss: 2.4529678793943703

Epoch: 5| Step: 4
Training loss: 0.14069694427098103
Validation loss: 2.4777465455602363

Epoch: 5| Step: 5
Training loss: 0.23799225996007775
Validation loss: 2.4378561238817342

Epoch: 5| Step: 6
Training loss: 0.19271912200901728
Validation loss: 2.44287293603691

Epoch: 5| Step: 7
Training loss: 0.1766213738767121
Validation loss: 2.4640969034439086

Epoch: 5| Step: 8
Training loss: 0.09056255207330116
Validation loss: 2.460120821606191

Epoch: 5| Step: 9
Training loss: 0.16822603393054977
Validation loss: 2.4753798149139903

Epoch: 5| Step: 10
Training loss: 0.1419043624843125
Validation loss: 2.4336602457981624

Epoch: 659| Step: 0
Training loss: 0.09092389117167368
Validation loss: 2.4635942927796917

Epoch: 5| Step: 1
Training loss: 0.14633201304747448
Validation loss: 2.461824758308506

Epoch: 5| Step: 2
Training loss: 0.17872603931092798
Validation loss: 2.478307705661809

Epoch: 5| Step: 3
Training loss: 0.11719331726894344
Validation loss: 2.4733743241021307

Epoch: 5| Step: 4
Training loss: 0.0834180400154097
Validation loss: 2.4428834078190786

Epoch: 5| Step: 5
Training loss: 0.1986801308653988
Validation loss: 2.4474140587695294

Epoch: 5| Step: 6
Training loss: 0.10662502027927309
Validation loss: 2.435847495024482

Epoch: 5| Step: 7
Training loss: 0.20820032085655987
Validation loss: 2.457172209966334

Epoch: 5| Step: 8
Training loss: 0.1256496193826719
Validation loss: 2.44885090368082

Epoch: 5| Step: 9
Training loss: 0.09697238849091995
Validation loss: 2.4372031181192697

Epoch: 5| Step: 10
Training loss: 0.13701343793599313
Validation loss: 2.4324553617448457

Epoch: 660| Step: 0
Training loss: 0.1488083798784611
Validation loss: 2.4028470636373154

Epoch: 5| Step: 1
Training loss: 0.1882310167153798
Validation loss: 2.438422271276446

Epoch: 5| Step: 2
Training loss: 0.15986369324609498
Validation loss: 2.4205105603564623

Epoch: 5| Step: 3
Training loss: 0.14148633148803783
Validation loss: 2.413997988182857

Epoch: 5| Step: 4
Training loss: 0.11365840871426962
Validation loss: 2.4555347312456037

Epoch: 5| Step: 5
Training loss: 0.11527905567792138
Validation loss: 2.4678487029421423

Epoch: 5| Step: 6
Training loss: 0.15969000381402954
Validation loss: 2.4649757334446507

Epoch: 5| Step: 7
Training loss: 0.15591088689016847
Validation loss: 2.4786601105323918

Epoch: 5| Step: 8
Training loss: 0.12113976373443816
Validation loss: 2.4705024274234213

Epoch: 5| Step: 9
Training loss: 0.19853336579228026
Validation loss: 2.4866007769512266

Epoch: 5| Step: 10
Training loss: 0.1351878628115254
Validation loss: 2.5250206085813103

Epoch: 661| Step: 0
Training loss: 0.12147052278076394
Validation loss: 2.481123731826493

Epoch: 5| Step: 1
Training loss: 0.1004967988966955
Validation loss: 2.4686271831118285

Epoch: 5| Step: 2
Training loss: 0.12433739595100135
Validation loss: 2.471388265261541

Epoch: 5| Step: 3
Training loss: 0.10994121330570945
Validation loss: 2.45829843072602

Epoch: 5| Step: 4
Training loss: 0.12712132242438492
Validation loss: 2.4391754099240686

Epoch: 5| Step: 5
Training loss: 0.21335909858442662
Validation loss: 2.4593193780400493

Epoch: 5| Step: 6
Training loss: 0.16508290312351678
Validation loss: 2.4487325448042205

Epoch: 5| Step: 7
Training loss: 0.1939306393822706
Validation loss: 2.4247739829895365

Epoch: 5| Step: 8
Training loss: 0.13969277298338895
Validation loss: 2.4527167989166756

Epoch: 5| Step: 9
Training loss: 0.09686234106909099
Validation loss: 2.4627539407209316

Epoch: 5| Step: 10
Training loss: 0.11026175819866837
Validation loss: 2.4588869150094252

Epoch: 662| Step: 0
Training loss: 0.06640819238178125
Validation loss: 2.467857137334265

Epoch: 5| Step: 1
Training loss: 0.10856936270128233
Validation loss: 2.4865311300489976

Epoch: 5| Step: 2
Training loss: 0.1385729799759641
Validation loss: 2.460771785377675

Epoch: 5| Step: 3
Training loss: 0.14008045728606652
Validation loss: 2.4900610769969664

Epoch: 5| Step: 4
Training loss: 0.1444222774031581
Validation loss: 2.485960519655104

Epoch: 5| Step: 5
Training loss: 0.19702324281496303
Validation loss: 2.4623639935103494

Epoch: 5| Step: 6
Training loss: 0.15011680123534824
Validation loss: 2.493197238315579

Epoch: 5| Step: 7
Training loss: 0.1194972267223116
Validation loss: 2.468651599670165

Epoch: 5| Step: 8
Training loss: 0.14240896301414188
Validation loss: 2.468432129634551

Epoch: 5| Step: 9
Training loss: 0.13782226175435128
Validation loss: 2.4596769324311776

Epoch: 5| Step: 10
Training loss: 0.11903579587035053
Validation loss: 2.4378816691267664

Epoch: 663| Step: 0
Training loss: 0.13400264037167772
Validation loss: 2.4434876921932376

Epoch: 5| Step: 1
Training loss: 0.14215162579220247
Validation loss: 2.4379508519449544

Epoch: 5| Step: 2
Training loss: 0.089852555506879
Validation loss: 2.4482780715140717

Epoch: 5| Step: 3
Training loss: 0.09243008168432862
Validation loss: 2.4522545637101696

Epoch: 5| Step: 4
Training loss: 0.07674904244191355
Validation loss: 2.446641738093784

Epoch: 5| Step: 5
Training loss: 0.17530651093349006
Validation loss: 2.467915894721776

Epoch: 5| Step: 6
Training loss: 0.12274385788971703
Validation loss: 2.4697182458208715

Epoch: 5| Step: 7
Training loss: 0.08054993489981027
Validation loss: 2.449667370851341

Epoch: 5| Step: 8
Training loss: 0.14778331229492545
Validation loss: 2.448925039101062

Epoch: 5| Step: 9
Training loss: 0.21796219176677373
Validation loss: 2.445429916312255

Epoch: 5| Step: 10
Training loss: 0.10213130530090964
Validation loss: 2.453937886748001

Epoch: 664| Step: 0
Training loss: 0.12235241907958762
Validation loss: 2.449950494197006

Epoch: 5| Step: 1
Training loss: 0.14438494158860837
Validation loss: 2.449968425328786

Epoch: 5| Step: 2
Training loss: 0.0820797963906286
Validation loss: 2.4497784853241797

Epoch: 5| Step: 3
Training loss: 0.12152400796205189
Validation loss: 2.424110831281004

Epoch: 5| Step: 4
Training loss: 0.07196577794969282
Validation loss: 2.4604379772328855

Epoch: 5| Step: 5
Training loss: 0.22642890510125135
Validation loss: 2.4474760567953693

Epoch: 5| Step: 6
Training loss: 0.11645398249400665
Validation loss: 2.4550977170915953

Epoch: 5| Step: 7
Training loss: 0.18495483307800203
Validation loss: 2.4552614371680113

Epoch: 5| Step: 8
Training loss: 0.1032851505480799
Validation loss: 2.4369168663385685

Epoch: 5| Step: 9
Training loss: 0.12324750529089655
Validation loss: 2.44732332668589

Epoch: 5| Step: 10
Training loss: 0.14017842167385527
Validation loss: 2.4607713170869614

Epoch: 665| Step: 0
Training loss: 0.12583825555178396
Validation loss: 2.4136167261285495

Epoch: 5| Step: 1
Training loss: 0.11612463399123131
Validation loss: 2.421099204227245

Epoch: 5| Step: 2
Training loss: 0.14598891071523465
Validation loss: 2.4502460408093953

Epoch: 5| Step: 3
Training loss: 0.10291645898810886
Validation loss: 2.448343854889511

Epoch: 5| Step: 4
Training loss: 0.0959495417977689
Validation loss: 2.4295376856527318

Epoch: 5| Step: 5
Training loss: 0.20206495763533058
Validation loss: 2.4788372316926734

Epoch: 5| Step: 6
Training loss: 0.1559687288181487
Validation loss: 2.477721360621946

Epoch: 5| Step: 7
Training loss: 0.12774258683432518
Validation loss: 2.4813259879448624

Epoch: 5| Step: 8
Training loss: 0.10155529675248494
Validation loss: 2.474395077835411

Epoch: 5| Step: 9
Training loss: 0.12916057236456024
Validation loss: 2.4552688808422816

Epoch: 5| Step: 10
Training loss: 0.09162950984120004
Validation loss: 2.438506941507738

Epoch: 666| Step: 0
Training loss: 0.16284817364287557
Validation loss: 2.470440309914031

Epoch: 5| Step: 1
Training loss: 0.11965394050080931
Validation loss: 2.4547255930896497

Epoch: 5| Step: 2
Training loss: 0.1176264885196085
Validation loss: 2.447107057515199

Epoch: 5| Step: 3
Training loss: 0.07602427009535861
Validation loss: 2.4973430296694303

Epoch: 5| Step: 4
Training loss: 0.09672193374847692
Validation loss: 2.4387979914035753

Epoch: 5| Step: 5
Training loss: 0.09422575911899052
Validation loss: 2.4331708473569345

Epoch: 5| Step: 6
Training loss: 0.07148297274626464
Validation loss: 2.4459378306765642

Epoch: 5| Step: 7
Training loss: 0.17870239070612393
Validation loss: 2.4468091279315805

Epoch: 5| Step: 8
Training loss: 0.08286304753081343
Validation loss: 2.4531438296559256

Epoch: 5| Step: 9
Training loss: 0.18952393928888178
Validation loss: 2.4636375729265967

Epoch: 5| Step: 10
Training loss: 0.14178870758200549
Validation loss: 2.4399456211198736

Epoch: 667| Step: 0
Training loss: 0.13915976808728073
Validation loss: 2.4312757509312815

Epoch: 5| Step: 1
Training loss: 0.08505230408460972
Validation loss: 2.437313367178999

Epoch: 5| Step: 2
Training loss: 0.10501379770353018
Validation loss: 2.4398232093608283

Epoch: 5| Step: 3
Training loss: 0.1549551478603256
Validation loss: 2.4133547361211556

Epoch: 5| Step: 4
Training loss: 0.1348705505246134
Validation loss: 2.4196450469585598

Epoch: 5| Step: 5
Training loss: 0.12039427470765342
Validation loss: 2.4344583069671244

Epoch: 5| Step: 6
Training loss: 0.127560307951638
Validation loss: 2.425111881420025

Epoch: 5| Step: 7
Training loss: 0.10358077823902297
Validation loss: 2.4248445251281376

Epoch: 5| Step: 8
Training loss: 0.1710021385549228
Validation loss: 2.4477302649609176

Epoch: 5| Step: 9
Training loss: 0.1763860523446565
Validation loss: 2.4538829889872535

Epoch: 5| Step: 10
Training loss: 0.1130738785594591
Validation loss: 2.441753244200268

Epoch: 668| Step: 0
Training loss: 0.1095214017203602
Validation loss: 2.4479446793530637

Epoch: 5| Step: 1
Training loss: 0.196008367681578
Validation loss: 2.454753241573112

Epoch: 5| Step: 2
Training loss: 0.19085981258884005
Validation loss: 2.4701175051272504

Epoch: 5| Step: 3
Training loss: 0.08803918786327276
Validation loss: 2.464839996339713

Epoch: 5| Step: 4
Training loss: 0.11180999687515739
Validation loss: 2.4787973635737313

Epoch: 5| Step: 5
Training loss: 0.12065907109570477
Validation loss: 2.4845146665696287

Epoch: 5| Step: 6
Training loss: 0.10883075404911016
Validation loss: 2.4685699046209204

Epoch: 5| Step: 7
Training loss: 0.1103208254314682
Validation loss: 2.4598103843535317

Epoch: 5| Step: 8
Training loss: 0.13383542948940344
Validation loss: 2.4459650754015554

Epoch: 5| Step: 9
Training loss: 0.1458228049281124
Validation loss: 2.4668523557327178

Epoch: 5| Step: 10
Training loss: 0.06144505571371115
Validation loss: 2.448868483788534

Epoch: 669| Step: 0
Training loss: 0.12502246148242696
Validation loss: 2.4584244248366014

Epoch: 5| Step: 1
Training loss: 0.13247028608077221
Validation loss: 2.420574225013899

Epoch: 5| Step: 2
Training loss: 0.1171724230286372
Validation loss: 2.400723740832824

Epoch: 5| Step: 3
Training loss: 0.08692426300197185
Validation loss: 2.4098526144507986

Epoch: 5| Step: 4
Training loss: 0.11818604225468045
Validation loss: 2.4137936230072494

Epoch: 5| Step: 5
Training loss: 0.161084439501621
Validation loss: 2.411477393012528

Epoch: 5| Step: 6
Training loss: 0.13151758397907054
Validation loss: 2.434897055018835

Epoch: 5| Step: 7
Training loss: 0.1615630791947038
Validation loss: 2.4315159083983557

Epoch: 5| Step: 8
Training loss: 0.09642787854573921
Validation loss: 2.43947119844764

Epoch: 5| Step: 9
Training loss: 0.10512570824707712
Validation loss: 2.4676122882686355

Epoch: 5| Step: 10
Training loss: 0.1778912742512431
Validation loss: 2.4405290762909426

Epoch: 670| Step: 0
Training loss: 0.13313717985625972
Validation loss: 2.4406706416568573

Epoch: 5| Step: 1
Training loss: 0.09508370391727237
Validation loss: 2.4613488752803905

Epoch: 5| Step: 2
Training loss: 0.09448280630107415
Validation loss: 2.4524752967017402

Epoch: 5| Step: 3
Training loss: 0.10294475228020483
Validation loss: 2.4442429997513133

Epoch: 5| Step: 4
Training loss: 0.20973912432190694
Validation loss: 2.4759599439110125

Epoch: 5| Step: 5
Training loss: 0.1567505091950939
Validation loss: 2.439128457967991

Epoch: 5| Step: 6
Training loss: 0.08731578557950029
Validation loss: 2.4905693275147116

Epoch: 5| Step: 7
Training loss: 0.10914284898407543
Validation loss: 2.466850297525876

Epoch: 5| Step: 8
Training loss: 0.08202652690551039
Validation loss: 2.4452294388605487

Epoch: 5| Step: 9
Training loss: 0.11496198108651796
Validation loss: 2.4210033837027787

Epoch: 5| Step: 10
Training loss: 0.0861676288485454
Validation loss: 2.443539256914728

Epoch: 671| Step: 0
Training loss: 0.10269386323128936
Validation loss: 2.439658314025765

Epoch: 5| Step: 1
Training loss: 0.10011263944555653
Validation loss: 2.431863737176674

Epoch: 5| Step: 2
Training loss: 0.21306268930580635
Validation loss: 2.435077979488421

Epoch: 5| Step: 3
Training loss: 0.13811261271472924
Validation loss: 2.4686011480709427

Epoch: 5| Step: 4
Training loss: 0.1416553132215351
Validation loss: 2.4450225558585674

Epoch: 5| Step: 5
Training loss: 0.08025894161775445
Validation loss: 2.4669162788020755

Epoch: 5| Step: 6
Training loss: 0.14287785809370726
Validation loss: 2.455624905195954

Epoch: 5| Step: 7
Training loss: 0.0989544458838722
Validation loss: 2.4890235549241386

Epoch: 5| Step: 8
Training loss: 0.11676337262388971
Validation loss: 2.488269653076928

Epoch: 5| Step: 9
Training loss: 0.10865028439739993
Validation loss: 2.4682038537600928

Epoch: 5| Step: 10
Training loss: 0.15157240215870726
Validation loss: 2.4648337852102777

Epoch: 672| Step: 0
Training loss: 0.16660997921790188
Validation loss: 2.5185356872786255

Epoch: 5| Step: 1
Training loss: 0.13516054477372866
Validation loss: 2.4851405725561246

Epoch: 5| Step: 2
Training loss: 0.17390172985916846
Validation loss: 2.470885903603439

Epoch: 5| Step: 3
Training loss: 0.13833844704564494
Validation loss: 2.463704469573005

Epoch: 5| Step: 4
Training loss: 0.11914894200046179
Validation loss: 2.422047356259088

Epoch: 5| Step: 5
Training loss: 0.10232651798397781
Validation loss: 2.4424015370872176

Epoch: 5| Step: 6
Training loss: 0.08192838736395822
Validation loss: 2.4422603664933487

Epoch: 5| Step: 7
Training loss: 0.10127648097059308
Validation loss: 2.4129214466852895

Epoch: 5| Step: 8
Training loss: 0.07640777031530752
Validation loss: 2.415200864240996

Epoch: 5| Step: 9
Training loss: 0.15702671476239255
Validation loss: 2.444119651004948

Epoch: 5| Step: 10
Training loss: 0.10290226417205077
Validation loss: 2.419604750239698

Epoch: 673| Step: 0
Training loss: 0.09421882033147765
Validation loss: 2.433187976018147

Epoch: 5| Step: 1
Training loss: 0.08196978309727837
Validation loss: 2.4404635476254417

Epoch: 5| Step: 2
Training loss: 0.13070277195191343
Validation loss: 2.416773089002321

Epoch: 5| Step: 3
Training loss: 0.1160376402648913
Validation loss: 2.4398062948778354

Epoch: 5| Step: 4
Training loss: 0.21196382351458892
Validation loss: 2.4364252637081045

Epoch: 5| Step: 5
Training loss: 0.09621821673723399
Validation loss: 2.4332335338560176

Epoch: 5| Step: 6
Training loss: 0.0959814898771272
Validation loss: 2.494836244799918

Epoch: 5| Step: 7
Training loss: 0.09688063651268966
Validation loss: 2.4827025460831846

Epoch: 5| Step: 8
Training loss: 0.10301343543741551
Validation loss: 2.4812522678432556

Epoch: 5| Step: 9
Training loss: 0.13862287300316634
Validation loss: 2.4479510220901055

Epoch: 5| Step: 10
Training loss: 0.13243429947127697
Validation loss: 2.4779675538573596

Epoch: 674| Step: 0
Training loss: 0.14102240543496072
Validation loss: 2.459216761239696

Epoch: 5| Step: 1
Training loss: 0.13536933765695075
Validation loss: 2.47312987328425

Epoch: 5| Step: 2
Training loss: 0.10366928643543025
Validation loss: 2.443038814872187

Epoch: 5| Step: 3
Training loss: 0.0841354242681563
Validation loss: 2.428312394373961

Epoch: 5| Step: 4
Training loss: 0.12458012515607883
Validation loss: 2.4426212660415128

Epoch: 5| Step: 5
Training loss: 0.09625852247536257
Validation loss: 2.466161857513332

Epoch: 5| Step: 6
Training loss: 0.16829208370142745
Validation loss: 2.4299531750573418

Epoch: 5| Step: 7
Training loss: 0.11290550397874051
Validation loss: 2.4210190561469678

Epoch: 5| Step: 8
Training loss: 0.13974151977048543
Validation loss: 2.451585735973074

Epoch: 5| Step: 9
Training loss: 0.11253937373305306
Validation loss: 2.473697181134498

Epoch: 5| Step: 10
Training loss: 0.19030219480804392
Validation loss: 2.4407514158764134

Epoch: 675| Step: 0
Training loss: 0.0649266405456682
Validation loss: 2.4350665197757486

Epoch: 5| Step: 1
Training loss: 0.13098870476819288
Validation loss: 2.448937080909307

Epoch: 5| Step: 2
Training loss: 0.09126465806251276
Validation loss: 2.4754523641053687

Epoch: 5| Step: 3
Training loss: 0.17780631569162514
Validation loss: 2.44008137039405

Epoch: 5| Step: 4
Training loss: 0.15336424811574303
Validation loss: 2.4582421953490985

Epoch: 5| Step: 5
Training loss: 0.12240768731996911
Validation loss: 2.4435992188068614

Epoch: 5| Step: 6
Training loss: 0.10464764110237941
Validation loss: 2.428427546376897

Epoch: 5| Step: 7
Training loss: 0.09300459623483401
Validation loss: 2.4207919977813277

Epoch: 5| Step: 8
Training loss: 0.1365344644767505
Validation loss: 2.4208982108820165

Epoch: 5| Step: 9
Training loss: 0.13980649792931754
Validation loss: 2.4095980084697888

Epoch: 5| Step: 10
Training loss: 0.11870794602541584
Validation loss: 2.4086698928674872

Epoch: 676| Step: 0
Training loss: 0.07719112072591607
Validation loss: 2.3991693319000063

Epoch: 5| Step: 1
Training loss: 0.10604840834349213
Validation loss: 2.4289064998933525

Epoch: 5| Step: 2
Training loss: 0.09976488484292531
Validation loss: 2.438705017110946

Epoch: 5| Step: 3
Training loss: 0.10160710199046624
Validation loss: 2.421005522713336

Epoch: 5| Step: 4
Training loss: 0.11714099517591792
Validation loss: 2.4458167465588647

Epoch: 5| Step: 5
Training loss: 0.12024950090337465
Validation loss: 2.437244861545005

Epoch: 5| Step: 6
Training loss: 0.1519648902868873
Validation loss: 2.4424156085111153

Epoch: 5| Step: 7
Training loss: 0.11190979817972391
Validation loss: 2.4497490995070295

Epoch: 5| Step: 8
Training loss: 0.18031371917841338
Validation loss: 2.4345271837560842

Epoch: 5| Step: 9
Training loss: 0.05338703590162653
Validation loss: 2.4333511658539204

Epoch: 5| Step: 10
Training loss: 0.15497291921533146
Validation loss: 2.445454753968365

Epoch: 677| Step: 0
Training loss: 0.14728022864708165
Validation loss: 2.4673025717598907

Epoch: 5| Step: 1
Training loss: 0.08117279674072779
Validation loss: 2.460960587306798

Epoch: 5| Step: 2
Training loss: 0.08284852789411726
Validation loss: 2.447137829615878

Epoch: 5| Step: 3
Training loss: 0.12767985023059147
Validation loss: 2.4111677570713352

Epoch: 5| Step: 4
Training loss: 0.10144062707838186
Validation loss: 2.4422044142197183

Epoch: 5| Step: 5
Training loss: 0.19806621050827333
Validation loss: 2.446199578789213

Epoch: 5| Step: 6
Training loss: 0.10450343044795664
Validation loss: 2.460920289984219

Epoch: 5| Step: 7
Training loss: 0.07817739577435336
Validation loss: 2.4667708840369547

Epoch: 5| Step: 8
Training loss: 0.08796259529492273
Validation loss: 2.4763591198004025

Epoch: 5| Step: 9
Training loss: 0.1125133814403275
Validation loss: 2.416042519558635

Epoch: 5| Step: 10
Training loss: 0.07070614639697143
Validation loss: 2.4085538053064637

Epoch: 678| Step: 0
Training loss: 0.0707695925188502
Validation loss: 2.4348453604456184

Epoch: 5| Step: 1
Training loss: 0.20511740353772148
Validation loss: 2.450408362459096

Epoch: 5| Step: 2
Training loss: 0.08112460016793496
Validation loss: 2.43388076127661

Epoch: 5| Step: 3
Training loss: 0.1029417441688289
Validation loss: 2.4610794299910075

Epoch: 5| Step: 4
Training loss: 0.06768519857589717
Validation loss: 2.4380341673669776

Epoch: 5| Step: 5
Training loss: 0.12264955420349886
Validation loss: 2.4528004473604903

Epoch: 5| Step: 6
Training loss: 0.08831773664336394
Validation loss: 2.4543179376315805

Epoch: 5| Step: 7
Training loss: 0.11280481268059908
Validation loss: 2.471054220944701

Epoch: 5| Step: 8
Training loss: 0.12046756659692165
Validation loss: 2.4630600492022707

Epoch: 5| Step: 9
Training loss: 0.12642954919304583
Validation loss: 2.4727702094216455

Epoch: 5| Step: 10
Training loss: 0.12041205755064564
Validation loss: 2.4741236007919514

Epoch: 679| Step: 0
Training loss: 0.12445527835762252
Validation loss: 2.480943446575432

Epoch: 5| Step: 1
Training loss: 0.08616983100441725
Validation loss: 2.477586898662999

Epoch: 5| Step: 2
Training loss: 0.09390241432607813
Validation loss: 2.4679689242632836

Epoch: 5| Step: 3
Training loss: 0.12585120654696658
Validation loss: 2.495856580068409

Epoch: 5| Step: 4
Training loss: 0.09180066932790543
Validation loss: 2.4534503863879467

Epoch: 5| Step: 5
Training loss: 0.11289984111059875
Validation loss: 2.4682429041952334

Epoch: 5| Step: 6
Training loss: 0.14010803248048456
Validation loss: 2.452350957033171

Epoch: 5| Step: 7
Training loss: 0.08606100689926706
Validation loss: 2.4748703924429294

Epoch: 5| Step: 8
Training loss: 0.08088232868694321
Validation loss: 2.468305350162734

Epoch: 5| Step: 9
Training loss: 0.1776913601311435
Validation loss: 2.443973096198877

Epoch: 5| Step: 10
Training loss: 0.15415119585389397
Validation loss: 2.4613424509346853

Epoch: 680| Step: 0
Training loss: 0.07214252193634739
Validation loss: 2.4528645176692936

Epoch: 5| Step: 1
Training loss: 0.19548098926052968
Validation loss: 2.4936647663615705

Epoch: 5| Step: 2
Training loss: 0.13186340045988545
Validation loss: 2.478929911809565

Epoch: 5| Step: 3
Training loss: 0.07300968779048005
Validation loss: 2.4667766041716415

Epoch: 5| Step: 4
Training loss: 0.11773411899480597
Validation loss: 2.4620437607105936

Epoch: 5| Step: 5
Training loss: 0.1635381231764382
Validation loss: 2.463306916274634

Epoch: 5| Step: 6
Training loss: 0.12519902537727495
Validation loss: 2.4533673392663906

Epoch: 5| Step: 7
Training loss: 0.11840554853786792
Validation loss: 2.4710720030888633

Epoch: 5| Step: 8
Training loss: 0.09434048146110552
Validation loss: 2.4558640062646764

Epoch: 5| Step: 9
Training loss: 0.06905321115386633
Validation loss: 2.4608167143057535

Epoch: 5| Step: 10
Training loss: 0.06896840659709837
Validation loss: 2.43130526143621

Epoch: 681| Step: 0
Training loss: 0.12387648083540787
Validation loss: 2.440832952051513

Epoch: 5| Step: 1
Training loss: 0.09769210157338007
Validation loss: 2.452908409897376

Epoch: 5| Step: 2
Training loss: 0.1612255061013738
Validation loss: 2.475313206354363

Epoch: 5| Step: 3
Training loss: 0.10599507910033877
Validation loss: 2.4358960278438766

Epoch: 5| Step: 4
Training loss: 0.06833657838270776
Validation loss: 2.4824030784367195

Epoch: 5| Step: 5
Training loss: 0.11986081358103859
Validation loss: 2.479351031330921

Epoch: 5| Step: 6
Training loss: 0.082411006237991
Validation loss: 2.5016822067237943

Epoch: 5| Step: 7
Training loss: 0.1457389110052721
Validation loss: 2.490683121966156

Epoch: 5| Step: 8
Training loss: 0.08955137737246316
Validation loss: 2.5022116517553594

Epoch: 5| Step: 9
Training loss: 0.06829830575350677
Validation loss: 2.4710852680285917

Epoch: 5| Step: 10
Training loss: 0.1854199828876442
Validation loss: 2.4895102710345958

Epoch: 682| Step: 0
Training loss: 0.09090679419627717
Validation loss: 2.485386283069981

Epoch: 5| Step: 1
Training loss: 0.20711978782571755
Validation loss: 2.455394876928215

Epoch: 5| Step: 2
Training loss: 0.11535110461269796
Validation loss: 2.452995283277716

Epoch: 5| Step: 3
Training loss: 0.08559449788543627
Validation loss: 2.470130824490934

Epoch: 5| Step: 4
Training loss: 0.10305463510783378
Validation loss: 2.4596797314382006

Epoch: 5| Step: 5
Training loss: 0.11507683831587812
Validation loss: 2.4732215876712837

Epoch: 5| Step: 6
Training loss: 0.07788673366766695
Validation loss: 2.4731066492412683

Epoch: 5| Step: 7
Training loss: 0.13618028735134363
Validation loss: 2.4747462171637844

Epoch: 5| Step: 8
Training loss: 0.1236445730199217
Validation loss: 2.448603819832135

Epoch: 5| Step: 9
Training loss: 0.15777028883691424
Validation loss: 2.457597034814327

Epoch: 5| Step: 10
Training loss: 0.11758077909952898
Validation loss: 2.469701639367547

Epoch: 683| Step: 0
Training loss: 0.10504919065005269
Validation loss: 2.4967396857610047

Epoch: 5| Step: 1
Training loss: 0.1724330339506716
Validation loss: 2.51354252452421

Epoch: 5| Step: 2
Training loss: 0.13580431991305317
Validation loss: 2.477172104716124

Epoch: 5| Step: 3
Training loss: 0.10711423430907935
Validation loss: 2.488869000828529

Epoch: 5| Step: 4
Training loss: 0.15193192743558917
Validation loss: 2.4901986271614533

Epoch: 5| Step: 5
Training loss: 0.07922525507084481
Validation loss: 2.4755066634057883

Epoch: 5| Step: 6
Training loss: 0.10013261975268872
Validation loss: 2.4387981333142528

Epoch: 5| Step: 7
Training loss: 0.15952141478332366
Validation loss: 2.415060422547356

Epoch: 5| Step: 8
Training loss: 0.12869681337280664
Validation loss: 2.418336444890417

Epoch: 5| Step: 9
Training loss: 0.141711889235486
Validation loss: 2.3989284737422008

Epoch: 5| Step: 10
Training loss: 0.1550720155987476
Validation loss: 2.421070935284984

Epoch: 684| Step: 0
Training loss: 0.12202426423336722
Validation loss: 2.3969451386199894

Epoch: 5| Step: 1
Training loss: 0.10907268040124182
Validation loss: 2.433246400313853

Epoch: 5| Step: 2
Training loss: 0.11250077833462722
Validation loss: 2.424498651623005

Epoch: 5| Step: 3
Training loss: 0.11742371752493219
Validation loss: 2.4382696858593564

Epoch: 5| Step: 4
Training loss: 0.16959135203144957
Validation loss: 2.4672144170108723

Epoch: 5| Step: 5
Training loss: 0.12281677135533255
Validation loss: 2.4312980269828293

Epoch: 5| Step: 6
Training loss: 0.13116251294668488
Validation loss: 2.4724927013934046

Epoch: 5| Step: 7
Training loss: 0.16798329844789356
Validation loss: 2.4398290609723396

Epoch: 5| Step: 8
Training loss: 0.1898575722799767
Validation loss: 2.46524539398395

Epoch: 5| Step: 9
Training loss: 0.13062081013124546
Validation loss: 2.4619186255605165

Epoch: 5| Step: 10
Training loss: 0.1605746224364644
Validation loss: 2.4662906145838934

Epoch: 685| Step: 0
Training loss: 0.0846439290045292
Validation loss: 2.4473067138769538

Epoch: 5| Step: 1
Training loss: 0.0825867294639467
Validation loss: 2.4652972954934493

Epoch: 5| Step: 2
Training loss: 0.10121069553659919
Validation loss: 2.475923369236586

Epoch: 5| Step: 3
Training loss: 0.2334957319039062
Validation loss: 2.483416252034752

Epoch: 5| Step: 4
Training loss: 0.10728313850409636
Validation loss: 2.4577441134219202

Epoch: 5| Step: 5
Training loss: 0.1467418823247138
Validation loss: 2.4257197273929427

Epoch: 5| Step: 6
Training loss: 0.18299369961154105
Validation loss: 2.433314154598946

Epoch: 5| Step: 7
Training loss: 0.11303165908757376
Validation loss: 2.467567841505209

Epoch: 5| Step: 8
Training loss: 0.12253948457844026
Validation loss: 2.434452855248197

Epoch: 5| Step: 9
Training loss: 0.122731504770976
Validation loss: 2.4426931178765248

Epoch: 5| Step: 10
Training loss: 0.08423971018827442
Validation loss: 2.4712776317372547

Epoch: 686| Step: 0
Training loss: 0.10074857414948765
Validation loss: 2.4693290329434174

Epoch: 5| Step: 1
Training loss: 0.11593560050169187
Validation loss: 2.4799909037579675

Epoch: 5| Step: 2
Training loss: 0.08824715356754784
Validation loss: 2.4474760463207392

Epoch: 5| Step: 3
Training loss: 0.19839900724776466
Validation loss: 2.453838764201416

Epoch: 5| Step: 4
Training loss: 0.1363652359148878
Validation loss: 2.445041476222376

Epoch: 5| Step: 5
Training loss: 0.10788730016801908
Validation loss: 2.4347870671751286

Epoch: 5| Step: 6
Training loss: 0.10164063914018162
Validation loss: 2.431111668859391

Epoch: 5| Step: 7
Training loss: 0.12819726638843926
Validation loss: 2.437430818058194

Epoch: 5| Step: 8
Training loss: 0.08405016661948148
Validation loss: 2.439519273502849

Epoch: 5| Step: 9
Training loss: 0.08038199444681832
Validation loss: 2.4059896873000994

Epoch: 5| Step: 10
Training loss: 0.11284140995740068
Validation loss: 2.408912364696798

Epoch: 687| Step: 0
Training loss: 0.09706182289225107
Validation loss: 2.4425983701127203

Epoch: 5| Step: 1
Training loss: 0.09584080271360647
Validation loss: 2.4307458811444858

Epoch: 5| Step: 2
Training loss: 0.17534823064598037
Validation loss: 2.404480397308677

Epoch: 5| Step: 3
Training loss: 0.11768092148187095
Validation loss: 2.436417956071306

Epoch: 5| Step: 4
Training loss: 0.15176688305861505
Validation loss: 2.457242035898064

Epoch: 5| Step: 5
Training loss: 0.11644934394202423
Validation loss: 2.468952014405073

Epoch: 5| Step: 6
Training loss: 0.10382606632037351
Validation loss: 2.4541381265454456

Epoch: 5| Step: 7
Training loss: 0.11353843778064189
Validation loss: 2.484329032305001

Epoch: 5| Step: 8
Training loss: 0.13573163492364498
Validation loss: 2.4700979107374095

Epoch: 5| Step: 9
Training loss: 0.13484088206197406
Validation loss: 2.4669197767757747

Epoch: 5| Step: 10
Training loss: 0.05599900746689971
Validation loss: 2.4637482654555876

Epoch: 688| Step: 0
Training loss: 0.13581491484296726
Validation loss: 2.449148801043609

Epoch: 5| Step: 1
Training loss: 0.10456869408399247
Validation loss: 2.4715061999164867

Epoch: 5| Step: 2
Training loss: 0.09113216184080503
Validation loss: 2.4475881620988615

Epoch: 5| Step: 3
Training loss: 0.10848843215274243
Validation loss: 2.436603052442

Epoch: 5| Step: 4
Training loss: 0.11047026908348026
Validation loss: 2.4452358908619054

Epoch: 5| Step: 5
Training loss: 0.12904808881858285
Validation loss: 2.426138295187353

Epoch: 5| Step: 6
Training loss: 0.13562240392643807
Validation loss: 2.4420381968365583

Epoch: 5| Step: 7
Training loss: 0.10887423901395993
Validation loss: 2.4397863987354804

Epoch: 5| Step: 8
Training loss: 0.10602168119304156
Validation loss: 2.423822957157706

Epoch: 5| Step: 9
Training loss: 0.16035494458143382
Validation loss: 2.4151323703995775

Epoch: 5| Step: 10
Training loss: 0.1355572407961123
Validation loss: 2.4406546327065297

Epoch: 689| Step: 0
Training loss: 0.15664987061153063
Validation loss: 2.4228770183485393

Epoch: 5| Step: 1
Training loss: 0.12475880807874337
Validation loss: 2.4079562243937276

Epoch: 5| Step: 2
Training loss: 0.12321966769563364
Validation loss: 2.4240846713562543

Epoch: 5| Step: 3
Training loss: 0.1591814778233112
Validation loss: 2.4411224843489547

Epoch: 5| Step: 4
Training loss: 0.07471595037736421
Validation loss: 2.44948054104193

Epoch: 5| Step: 5
Training loss: 0.10474526871799612
Validation loss: 2.4452595819532323

Epoch: 5| Step: 6
Training loss: 0.11429496715306628
Validation loss: 2.466341826770624

Epoch: 5| Step: 7
Training loss: 0.12699104623038251
Validation loss: 2.479101842679225

Epoch: 5| Step: 8
Training loss: 0.1445183361573314
Validation loss: 2.4890518544512883

Epoch: 5| Step: 9
Training loss: 0.11084136877817324
Validation loss: 2.48086821672867

Epoch: 5| Step: 10
Training loss: 0.1036772276266259
Validation loss: 2.431138731749143

Epoch: 690| Step: 0
Training loss: 0.08909673701978704
Validation loss: 2.464295891748173

Epoch: 5| Step: 1
Training loss: 0.12870624950479143
Validation loss: 2.42648880607907

Epoch: 5| Step: 2
Training loss: 0.08638235121658425
Validation loss: 2.403990691286191

Epoch: 5| Step: 3
Training loss: 0.21181782062035442
Validation loss: 2.430534960712738

Epoch: 5| Step: 4
Training loss: 0.1538229799354671
Validation loss: 2.4215212010121694

Epoch: 5| Step: 5
Training loss: 0.13870410813213838
Validation loss: 2.4493798434544733

Epoch: 5| Step: 6
Training loss: 0.07080602297617287
Validation loss: 2.43533359970743

Epoch: 5| Step: 7
Training loss: 0.07326601276714063
Validation loss: 2.443004605317531

Epoch: 5| Step: 8
Training loss: 0.1767355393766046
Validation loss: 2.4300661362108618

Epoch: 5| Step: 9
Training loss: 0.11123676483179491
Validation loss: 2.465682840315458

Epoch: 5| Step: 10
Training loss: 0.11232881286889106
Validation loss: 2.446672803669852

Epoch: 691| Step: 0
Training loss: 0.08359146805794856
Validation loss: 2.476068250381143

Epoch: 5| Step: 1
Training loss: 0.0777728818043007
Validation loss: 2.4612263062255852

Epoch: 5| Step: 2
Training loss: 0.11730015029160798
Validation loss: 2.453433873582339

Epoch: 5| Step: 3
Training loss: 0.14774229983614515
Validation loss: 2.4482934337616045

Epoch: 5| Step: 4
Training loss: 0.12126607707813893
Validation loss: 2.429575600691911

Epoch: 5| Step: 5
Training loss: 0.08385526913555907
Validation loss: 2.4378874970057813

Epoch: 5| Step: 6
Training loss: 0.1180626063212597
Validation loss: 2.4114721019600482

Epoch: 5| Step: 7
Training loss: 0.17639037663123555
Validation loss: 2.415113550095512

Epoch: 5| Step: 8
Training loss: 0.10131754587605221
Validation loss: 2.4132596884699273

Epoch: 5| Step: 9
Training loss: 0.09328748436961784
Validation loss: 2.417094832041357

Epoch: 5| Step: 10
Training loss: 0.09698608762569651
Validation loss: 2.4166039793592007

Epoch: 692| Step: 0
Training loss: 0.15351564878118976
Validation loss: 2.396103742479623

Epoch: 5| Step: 1
Training loss: 0.09796210077831603
Validation loss: 2.411737139834519

Epoch: 5| Step: 2
Training loss: 0.13265553483219822
Validation loss: 2.4140494877547223

Epoch: 5| Step: 3
Training loss: 0.13349154031350746
Validation loss: 2.410453807402755

Epoch: 5| Step: 4
Training loss: 0.08841326872760957
Validation loss: 2.4289921941918897

Epoch: 5| Step: 5
Training loss: 0.17019949628806408
Validation loss: 2.441930096479552

Epoch: 5| Step: 6
Training loss: 0.11618410329588674
Validation loss: 2.4709651718723618

Epoch: 5| Step: 7
Training loss: 0.10161426948715277
Validation loss: 2.439216686581084

Epoch: 5| Step: 8
Training loss: 0.07309590991340696
Validation loss: 2.4529273227364796

Epoch: 5| Step: 9
Training loss: 0.10623154479918019
Validation loss: 2.466281030111459

Epoch: 5| Step: 10
Training loss: 0.13377526483600446
Validation loss: 2.462395757135829

Epoch: 693| Step: 0
Training loss: 0.12287912590224777
Validation loss: 2.437127969735896

Epoch: 5| Step: 1
Training loss: 0.1094557344968296
Validation loss: 2.465822189104537

Epoch: 5| Step: 2
Training loss: 0.10171027619946595
Validation loss: 2.4428743569738565

Epoch: 5| Step: 3
Training loss: 0.13797129710774264
Validation loss: 2.427673415637019

Epoch: 5| Step: 4
Training loss: 0.10595679392985825
Validation loss: 2.458500186088941

Epoch: 5| Step: 5
Training loss: 0.08477409140324375
Validation loss: 2.4114302334534408

Epoch: 5| Step: 6
Training loss: 0.10254747719524683
Validation loss: 2.423513338241563

Epoch: 5| Step: 7
Training loss: 0.08261573138655998
Validation loss: 2.4374553291386114

Epoch: 5| Step: 8
Training loss: 0.16874597619698847
Validation loss: 2.433380211867285

Epoch: 5| Step: 9
Training loss: 0.10634660518886982
Validation loss: 2.436392686946617

Epoch: 5| Step: 10
Training loss: 0.13643210880402962
Validation loss: 2.454565701694308

Epoch: 694| Step: 0
Training loss: 0.1208305497986169
Validation loss: 2.4449636978593965

Epoch: 5| Step: 1
Training loss: 0.10088504835339564
Validation loss: 2.45594534655753

Epoch: 5| Step: 2
Training loss: 0.05870301469833616
Validation loss: 2.4512886095719857

Epoch: 5| Step: 3
Training loss: 0.17006205662918755
Validation loss: 2.436401340454427

Epoch: 5| Step: 4
Training loss: 0.12262604289846014
Validation loss: 2.4535775719137214

Epoch: 5| Step: 5
Training loss: 0.09780821420646267
Validation loss: 2.426741718106734

Epoch: 5| Step: 6
Training loss: 0.07191343769815313
Validation loss: 2.4512033245201907

Epoch: 5| Step: 7
Training loss: 0.07361074858246058
Validation loss: 2.4171989082541137

Epoch: 5| Step: 8
Training loss: 0.09789712762508102
Validation loss: 2.4229791099299196

Epoch: 5| Step: 9
Training loss: 0.09755700313428439
Validation loss: 2.4406616892202457

Epoch: 5| Step: 10
Training loss: 0.1388054526733016
Validation loss: 2.4368006515719713

Epoch: 695| Step: 0
Training loss: 0.053965045474348806
Validation loss: 2.431974718462309

Epoch: 5| Step: 1
Training loss: 0.13068874821598148
Validation loss: 2.445597044213571

Epoch: 5| Step: 2
Training loss: 0.12096367279253677
Validation loss: 2.424878134000113

Epoch: 5| Step: 3
Training loss: 0.12219795039065941
Validation loss: 2.4142629941908442

Epoch: 5| Step: 4
Training loss: 0.12207004928560489
Validation loss: 2.4061922978169563

Epoch: 5| Step: 5
Training loss: 0.07600375414563185
Validation loss: 2.442461123333691

Epoch: 5| Step: 6
Training loss: 0.11320972651101864
Validation loss: 2.4304220171299913

Epoch: 5| Step: 7
Training loss: 0.06757760915945228
Validation loss: 2.42359313145645

Epoch: 5| Step: 8
Training loss: 0.16658182083100492
Validation loss: 2.4375212221192015

Epoch: 5| Step: 9
Training loss: 0.1031651095575874
Validation loss: 2.4571021441643577

Epoch: 5| Step: 10
Training loss: 0.0518915320388653
Validation loss: 2.453079949529564

Epoch: 696| Step: 0
Training loss: 0.1627626412557527
Validation loss: 2.448943702151325

Epoch: 5| Step: 1
Training loss: 0.14978996686961354
Validation loss: 2.4476155298532514

Epoch: 5| Step: 2
Training loss: 0.07589167937849481
Validation loss: 2.4487022513029504

Epoch: 5| Step: 3
Training loss: 0.11015228829124919
Validation loss: 2.4652610170668043

Epoch: 5| Step: 4
Training loss: 0.07241029370553088
Validation loss: 2.4661538588636085

Epoch: 5| Step: 5
Training loss: 0.11502312030008775
Validation loss: 2.4574235289679582

Epoch: 5| Step: 6
Training loss: 0.08438587416671334
Validation loss: 2.4576333481380286

Epoch: 5| Step: 7
Training loss: 0.059014058617627055
Validation loss: 2.456425364565257

Epoch: 5| Step: 8
Training loss: 0.07930247963515227
Validation loss: 2.431397174341492

Epoch: 5| Step: 9
Training loss: 0.06577697793267694
Validation loss: 2.4401571480125406

Epoch: 5| Step: 10
Training loss: 0.12576336526185383
Validation loss: 2.4478396272460254

Epoch: 697| Step: 0
Training loss: 0.16486656609597836
Validation loss: 2.4503099676138476

Epoch: 5| Step: 1
Training loss: 0.09800952906832891
Validation loss: 2.456426424910245

Epoch: 5| Step: 2
Training loss: 0.1313388708076488
Validation loss: 2.461340594870596

Epoch: 5| Step: 3
Training loss: 0.09320641420704577
Validation loss: 2.453770870902126

Epoch: 5| Step: 4
Training loss: 0.08566423611377634
Validation loss: 2.4541202718433555

Epoch: 5| Step: 5
Training loss: 0.10969915634423541
Validation loss: 2.4627444502248155

Epoch: 5| Step: 6
Training loss: 0.09061061584661059
Validation loss: 2.4608557507019935

Epoch: 5| Step: 7
Training loss: 0.10515319897021781
Validation loss: 2.469800616247899

Epoch: 5| Step: 8
Training loss: 0.12775171436365126
Validation loss: 2.4791445920283213

Epoch: 5| Step: 9
Training loss: 0.08239402481261292
Validation loss: 2.44602107161344

Epoch: 5| Step: 10
Training loss: 0.1631090695999258
Validation loss: 2.4603070955823876

Epoch: 698| Step: 0
Training loss: 0.06764499822927793
Validation loss: 2.436565027908046

Epoch: 5| Step: 1
Training loss: 0.07519230279224991
Validation loss: 2.4457475954701007

Epoch: 5| Step: 2
Training loss: 0.10167611626220298
Validation loss: 2.4449534861133855

Epoch: 5| Step: 3
Training loss: 0.1337536535254268
Validation loss: 2.452318576148731

Epoch: 5| Step: 4
Training loss: 0.0983323440040643
Validation loss: 2.4634359786667135

Epoch: 5| Step: 5
Training loss: 0.1361684555504187
Validation loss: 2.4355215410496034

Epoch: 5| Step: 6
Training loss: 0.15706787631164623
Validation loss: 2.450357311085991

Epoch: 5| Step: 7
Training loss: 0.07611364804542423
Validation loss: 2.42195379609992

Epoch: 5| Step: 8
Training loss: 0.07429146028416644
Validation loss: 2.454536248900364

Epoch: 5| Step: 9
Training loss: 0.18373548839642767
Validation loss: 2.470095560479569

Epoch: 5| Step: 10
Training loss: 0.0947501752859321
Validation loss: 2.4629024163687707

Epoch: 699| Step: 0
Training loss: 0.17776123305061647
Validation loss: 2.473119273013878

Epoch: 5| Step: 1
Training loss: 0.13960909122423257
Validation loss: 2.4767824184474754

Epoch: 5| Step: 2
Training loss: 0.08489525108293756
Validation loss: 2.4808743507715416

Epoch: 5| Step: 3
Training loss: 0.07550312799327658
Validation loss: 2.475122760683609

Epoch: 5| Step: 4
Training loss: 0.11728053373681689
Validation loss: 2.4629288634708195

Epoch: 5| Step: 5
Training loss: 0.116317752025954
Validation loss: 2.4604521846306264

Epoch: 5| Step: 6
Training loss: 0.10168191418607578
Validation loss: 2.457693267626077

Epoch: 5| Step: 7
Training loss: 0.10224367920393725
Validation loss: 2.4460876938699223

Epoch: 5| Step: 8
Training loss: 0.05599462085432653
Validation loss: 2.434070704295111

Epoch: 5| Step: 9
Training loss: 0.07615249338304093
Validation loss: 2.422329847036112

Epoch: 5| Step: 10
Training loss: 0.12734816052106562
Validation loss: 2.442379354434373

Epoch: 700| Step: 0
Training loss: 0.13337297545650995
Validation loss: 2.3986230235810013

Epoch: 5| Step: 1
Training loss: 0.08156863967762946
Validation loss: 2.4238640891118615

Epoch: 5| Step: 2
Training loss: 0.1050164892810684
Validation loss: 2.4260127028961933

Epoch: 5| Step: 3
Training loss: 0.18470191300658229
Validation loss: 2.415629745419518

Epoch: 5| Step: 4
Training loss: 0.09970714875456249
Validation loss: 2.4212513607958432

Epoch: 5| Step: 5
Training loss: 0.08072012772512296
Validation loss: 2.456211539150576

Epoch: 5| Step: 6
Training loss: 0.10036933131321304
Validation loss: 2.432970312833448

Epoch: 5| Step: 7
Training loss: 0.11152695585135766
Validation loss: 2.457123760389463

Epoch: 5| Step: 8
Training loss: 0.11794630983533252
Validation loss: 2.4563828616788945

Epoch: 5| Step: 9
Training loss: 0.11580227072882661
Validation loss: 2.4513435528840533

Epoch: 5| Step: 10
Training loss: 0.0572693699650438
Validation loss: 2.441225640160839

Testing loss: 2.826333271659319
