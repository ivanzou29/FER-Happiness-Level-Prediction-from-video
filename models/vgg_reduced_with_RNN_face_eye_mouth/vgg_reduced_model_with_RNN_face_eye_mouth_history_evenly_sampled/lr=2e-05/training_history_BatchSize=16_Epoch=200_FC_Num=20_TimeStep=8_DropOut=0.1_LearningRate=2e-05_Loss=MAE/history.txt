Epoch: 1| Step: 0
Training loss: 3.9175188541412354
Validation loss: 5.1729604300632275

Epoch: 6| Step: 1
Training loss: 5.992710590362549
Validation loss: 5.151696620448943

Epoch: 6| Step: 2
Training loss: 5.3918681144714355
Validation loss: 5.129641712352794

Epoch: 6| Step: 3
Training loss: 4.243406772613525
Validation loss: 5.106206919557305

Epoch: 6| Step: 4
Training loss: 5.089333534240723
Validation loss: 5.080406993948003

Epoch: 6| Step: 5
Training loss: 5.00933313369751
Validation loss: 5.051534673219086

Epoch: 6| Step: 6
Training loss: 5.6927595138549805
Validation loss: 5.020055447855303

Epoch: 6| Step: 7
Training loss: 4.290824890136719
Validation loss: 4.985388581470777

Epoch: 6| Step: 8
Training loss: 4.02588415145874
Validation loss: 4.947205005153533

Epoch: 6| Step: 9
Training loss: 4.970220565795898
Validation loss: 4.905846244545393

Epoch: 6| Step: 10
Training loss: 4.008444309234619
Validation loss: 4.860479565076931

Epoch: 6| Step: 11
Training loss: 4.90802526473999
Validation loss: 4.812842599807247

Epoch: 6| Step: 12
Training loss: 5.070991516113281
Validation loss: 4.762803913444601

Epoch: 6| Step: 13
Training loss: 3.7951266765594482
Validation loss: 4.711448700197281

Epoch: 2| Step: 0
Training loss: 4.61175537109375
Validation loss: 4.658825602582706

Epoch: 6| Step: 1
Training loss: 5.081917762756348
Validation loss: 4.60429342844153

Epoch: 6| Step: 2
Training loss: 4.1878581047058105
Validation loss: 4.55005338627805

Epoch: 6| Step: 3
Training loss: 5.237590789794922
Validation loss: 4.494730521273869

Epoch: 6| Step: 4
Training loss: 3.1312968730926514
Validation loss: 4.438714799060617

Epoch: 6| Step: 5
Training loss: 3.171262264251709
Validation loss: 4.384505128347746

Epoch: 6| Step: 6
Training loss: 4.170368671417236
Validation loss: 4.333119684650052

Epoch: 6| Step: 7
Training loss: 4.17545223236084
Validation loss: 4.282130272157731

Epoch: 6| Step: 8
Training loss: 3.8765759468078613
Validation loss: 4.231408488365911

Epoch: 6| Step: 9
Training loss: 4.790584087371826
Validation loss: 4.183801317727694

Epoch: 6| Step: 10
Training loss: 5.17244815826416
Validation loss: 4.136900450593682

Epoch: 6| Step: 11
Training loss: 3.4105985164642334
Validation loss: 4.093355599270072

Epoch: 6| Step: 12
Training loss: 3.265850067138672
Validation loss: 4.056055402243009

Epoch: 6| Step: 13
Training loss: 3.4463226795196533
Validation loss: 4.022842817409064

Epoch: 3| Step: 0
Training loss: 4.191359519958496
Validation loss: 3.9922531599639566

Epoch: 6| Step: 1
Training loss: 3.3820605278015137
Validation loss: 3.9679558200220906

Epoch: 6| Step: 2
Training loss: 2.6612439155578613
Validation loss: 3.943635648296725

Epoch: 6| Step: 3
Training loss: 3.6632847785949707
Validation loss: 3.920919987463182

Epoch: 6| Step: 4
Training loss: 4.109086036682129
Validation loss: 3.899848561133108

Epoch: 6| Step: 5
Training loss: 3.5246710777282715
Validation loss: 3.8737809119686

Epoch: 6| Step: 6
Training loss: 4.235476493835449
Validation loss: 3.856882115846039

Epoch: 6| Step: 7
Training loss: 4.447833061218262
Validation loss: 3.8338538805643716

Epoch: 6| Step: 8
Training loss: 3.115675687789917
Validation loss: 3.816886845455375

Epoch: 6| Step: 9
Training loss: 3.743649959564209
Validation loss: 3.8026999145425777

Epoch: 6| Step: 10
Training loss: 3.3367042541503906
Validation loss: 3.7963740184742916

Epoch: 6| Step: 11
Training loss: 3.8901748657226562
Validation loss: 3.7683671456511303

Epoch: 6| Step: 12
Training loss: 3.300516366958618
Validation loss: 3.761526999935027

Epoch: 6| Step: 13
Training loss: 5.576425552368164
Validation loss: 3.756677755745508

Epoch: 4| Step: 0
Training loss: 4.246427536010742
Validation loss: 3.727039037212249

Epoch: 6| Step: 1
Training loss: 4.887138366699219
Validation loss: 3.703425407409668

Epoch: 6| Step: 2
Training loss: 2.407773971557617
Validation loss: 3.6990513981029554

Epoch: 6| Step: 3
Training loss: 3.7510247230529785
Validation loss: 3.724978898161201

Epoch: 6| Step: 4
Training loss: 4.295742511749268
Validation loss: 3.6724415235621954

Epoch: 6| Step: 5
Training loss: 3.7317769527435303
Validation loss: 3.6586450248636226

Epoch: 6| Step: 6
Training loss: 2.339005947113037
Validation loss: 3.665048086515037

Epoch: 6| Step: 7
Training loss: 4.122044563293457
Validation loss: 3.6624168888215096

Epoch: 6| Step: 8
Training loss: 4.008724689483643
Validation loss: 3.6401701229874805

Epoch: 6| Step: 9
Training loss: 3.4970483779907227
Validation loss: 3.620051173753636

Epoch: 6| Step: 10
Training loss: 2.0928173065185547
Validation loss: 3.6039022143169115

Epoch: 6| Step: 11
Training loss: 2.463998317718506
Validation loss: 3.5871893616132837

Epoch: 6| Step: 12
Training loss: 3.954411268234253
Validation loss: 3.5816019888847106

Epoch: 6| Step: 13
Training loss: 4.467591762542725
Validation loss: 3.584300312944638

Epoch: 5| Step: 0
Training loss: 2.1666746139526367
Validation loss: 3.5563158860770603

Epoch: 6| Step: 1
Training loss: 3.984154224395752
Validation loss: 3.548560119444324

Epoch: 6| Step: 2
Training loss: 4.506584644317627
Validation loss: 3.550726193253712

Epoch: 6| Step: 3
Training loss: 3.3172552585601807
Validation loss: 3.5483175093127834

Epoch: 6| Step: 4
Training loss: 2.8510074615478516
Validation loss: 3.5395608204667286

Epoch: 6| Step: 5
Training loss: 2.6880531311035156
Validation loss: 3.5269829791079284

Epoch: 6| Step: 6
Training loss: 3.4778599739074707
Validation loss: 3.502111481082055

Epoch: 6| Step: 7
Training loss: 3.8973147869110107
Validation loss: 3.4826058008337535

Epoch: 6| Step: 8
Training loss: 3.94569730758667
Validation loss: 3.477386074681436

Epoch: 6| Step: 9
Training loss: 2.8331263065338135
Validation loss: 3.4838284010528238

Epoch: 6| Step: 10
Training loss: 2.524888038635254
Validation loss: 3.4539214821271997

Epoch: 6| Step: 11
Training loss: 4.908397674560547
Validation loss: 3.4437665375330115

Epoch: 6| Step: 12
Training loss: 3.905806541442871
Validation loss: 3.43528813187794

Epoch: 6| Step: 13
Training loss: 2.7734646797180176
Validation loss: 3.42238276491883

Epoch: 6| Step: 0
Training loss: 3.1569530963897705
Validation loss: 3.415580072710591

Epoch: 6| Step: 1
Training loss: 2.437047004699707
Validation loss: 3.4054106896923435

Epoch: 6| Step: 2
Training loss: 3.5964908599853516
Validation loss: 3.3981443323114866

Epoch: 6| Step: 3
Training loss: 2.9020471572875977
Validation loss: 3.3911453934126

Epoch: 6| Step: 4
Training loss: 3.4515151977539062
Validation loss: 3.3797705916948217

Epoch: 6| Step: 5
Training loss: 3.98280930519104
Validation loss: 3.375413515234506

Epoch: 6| Step: 6
Training loss: 3.2767646312713623
Validation loss: 3.3643185143829673

Epoch: 6| Step: 7
Training loss: 3.813824415206909
Validation loss: 3.356839482502271

Epoch: 6| Step: 8
Training loss: 3.4156832695007324
Validation loss: 3.3521947219807613

Epoch: 6| Step: 9
Training loss: 3.0028748512268066
Validation loss: 3.346692910758398

Epoch: 6| Step: 10
Training loss: 3.3327431678771973
Validation loss: 3.3396759392112814

Epoch: 6| Step: 11
Training loss: 3.225618362426758
Validation loss: 3.3310802136698077

Epoch: 6| Step: 12
Training loss: 3.0966384410858154
Validation loss: 3.3167164402623333

Epoch: 6| Step: 13
Training loss: 4.0478901863098145
Validation loss: 3.3082614560281076

Epoch: 7| Step: 0
Training loss: 3.674027919769287
Validation loss: 3.298798338059456

Epoch: 6| Step: 1
Training loss: 3.2289440631866455
Validation loss: 3.287001097074119

Epoch: 6| Step: 2
Training loss: 3.339897632598877
Validation loss: 3.285244813529394

Epoch: 6| Step: 3
Training loss: 3.3851842880249023
Validation loss: 3.2792426642551216

Epoch: 6| Step: 4
Training loss: 3.0749292373657227
Validation loss: 3.2716645938093945

Epoch: 6| Step: 5
Training loss: 4.031735420227051
Validation loss: 3.259787215981432

Epoch: 6| Step: 6
Training loss: 2.988193988800049
Validation loss: 3.2493277800980436

Epoch: 6| Step: 7
Training loss: 3.2140631675720215
Validation loss: 3.2479819943827968

Epoch: 6| Step: 8
Training loss: 3.1917238235473633
Validation loss: 3.2530889177835114

Epoch: 6| Step: 9
Training loss: 3.2738211154937744
Validation loss: 3.2323538231593307

Epoch: 6| Step: 10
Training loss: 3.534330368041992
Validation loss: 3.248561259238951

Epoch: 6| Step: 11
Training loss: 3.1186158657073975
Validation loss: 3.238120702005202

Epoch: 6| Step: 12
Training loss: 2.108884811401367
Validation loss: 3.234272772266019

Epoch: 6| Step: 13
Training loss: 3.154578924179077
Validation loss: 3.228207439504644

Epoch: 8| Step: 0
Training loss: 3.875450611114502
Validation loss: 3.2209777319303123

Epoch: 6| Step: 1
Training loss: 2.5814690589904785
Validation loss: 3.208707937630274

Epoch: 6| Step: 2
Training loss: 3.619028091430664
Validation loss: 3.1981430207529375

Epoch: 6| Step: 3
Training loss: 2.72238826751709
Validation loss: 3.190902192105529

Epoch: 6| Step: 4
Training loss: 2.928584098815918
Validation loss: 3.1853184136011268

Epoch: 6| Step: 5
Training loss: 3.9034018516540527
Validation loss: 3.178101739575786

Epoch: 6| Step: 6
Training loss: 3.0957844257354736
Validation loss: 3.166714124782111

Epoch: 6| Step: 7
Training loss: 2.9061641693115234
Validation loss: 3.162443768593573

Epoch: 6| Step: 8
Training loss: 2.7807064056396484
Validation loss: 3.1594793232538367

Epoch: 6| Step: 9
Training loss: 3.1727824211120605
Validation loss: 3.1460363685443835

Epoch: 6| Step: 10
Training loss: 3.4004998207092285
Validation loss: 3.1408939002662577

Epoch: 6| Step: 11
Training loss: 2.992612838745117
Validation loss: 3.136451886546227

Epoch: 6| Step: 12
Training loss: 3.202526569366455
Validation loss: 3.134218185178695

Epoch: 6| Step: 13
Training loss: 3.3225932121276855
Validation loss: 3.126575680189235

Epoch: 9| Step: 0
Training loss: 3.033998489379883
Validation loss: 3.1173360604111866

Epoch: 6| Step: 1
Training loss: 2.6806113719940186
Validation loss: 3.1080802871334936

Epoch: 6| Step: 2
Training loss: 2.804680824279785
Validation loss: 3.1080200851604505

Epoch: 6| Step: 3
Training loss: 2.7803094387054443
Validation loss: 3.099707067653697

Epoch: 6| Step: 4
Training loss: 3.210719585418701
Validation loss: 3.0919470453775055

Epoch: 6| Step: 5
Training loss: 1.609028697013855
Validation loss: 3.0858452012462

Epoch: 6| Step: 6
Training loss: 3.6186633110046387
Validation loss: 3.0830257708026516

Epoch: 6| Step: 7
Training loss: 3.357480764389038
Validation loss: 3.0853264203635593

Epoch: 6| Step: 8
Training loss: 2.981398105621338
Validation loss: 3.083156680548063

Epoch: 6| Step: 9
Training loss: 3.493598461151123
Validation loss: 3.072392168865409

Epoch: 6| Step: 10
Training loss: 3.5396294593811035
Validation loss: 3.062775683659379

Epoch: 6| Step: 11
Training loss: 3.0878067016601562
Validation loss: 3.0587725613706853

Epoch: 6| Step: 12
Training loss: 4.094242095947266
Validation loss: 3.052718457355294

Epoch: 6| Step: 13
Training loss: 3.4793875217437744
Validation loss: 3.0478573460732736

Epoch: 10| Step: 0
Training loss: 1.9746203422546387
Validation loss: 3.046000352469824

Epoch: 6| Step: 1
Training loss: 3.9606986045837402
Validation loss: 3.04059858475962

Epoch: 6| Step: 2
Training loss: 3.17494797706604
Validation loss: 3.0369530211212816

Epoch: 6| Step: 3
Training loss: 3.9655771255493164
Validation loss: 3.0277752209735174

Epoch: 6| Step: 4
Training loss: 3.6144325733184814
Validation loss: 3.0233121918093775

Epoch: 6| Step: 5
Training loss: 3.6750741004943848
Validation loss: 3.0200270119533745

Epoch: 6| Step: 6
Training loss: 3.0121734142303467
Validation loss: 3.0222097878815024

Epoch: 6| Step: 7
Training loss: 3.1943626403808594
Validation loss: 3.0132962426831646

Epoch: 6| Step: 8
Training loss: 2.4918975830078125
Validation loss: 3.005654773404521

Epoch: 6| Step: 9
Training loss: 2.5026695728302
Validation loss: 3.007064873172391

Epoch: 6| Step: 10
Training loss: 2.1183595657348633
Validation loss: 3.0032292796719458

Epoch: 6| Step: 11
Training loss: 3.6073157787323
Validation loss: 3.0020914231577227

Epoch: 6| Step: 12
Training loss: 2.6376140117645264
Validation loss: 2.994608099742602

Epoch: 6| Step: 13
Training loss: 3.152726173400879
Validation loss: 2.9923929193968415

Epoch: 11| Step: 0
Training loss: 2.9893851280212402
Validation loss: 2.993426210136824

Epoch: 6| Step: 1
Training loss: 3.058012008666992
Validation loss: 2.9827612856382966

Epoch: 6| Step: 2
Training loss: 3.598813056945801
Validation loss: 2.9825254383907525

Epoch: 6| Step: 3
Training loss: 3.1350502967834473
Validation loss: 3.0141550187141664

Epoch: 6| Step: 4
Training loss: 3.416317939758301
Validation loss: 2.9793474033314693

Epoch: 6| Step: 5
Training loss: 3.300525188446045
Validation loss: 2.964421644005724

Epoch: 6| Step: 6
Training loss: 2.961859941482544
Validation loss: 2.9621096503350044

Epoch: 6| Step: 7
Training loss: 3.5315768718719482
Validation loss: 2.966805442687004

Epoch: 6| Step: 8
Training loss: 2.374566078186035
Validation loss: 2.970969912826374

Epoch: 6| Step: 9
Training loss: 2.6520004272460938
Validation loss: 2.9630911145158993

Epoch: 6| Step: 10
Training loss: 1.988741159439087
Validation loss: 2.950501790610693

Epoch: 6| Step: 11
Training loss: 3.3762807846069336
Validation loss: 2.946777538586688

Epoch: 6| Step: 12
Training loss: 3.2506117820739746
Validation loss: 2.9548346842488935

Epoch: 6| Step: 13
Training loss: 2.88240909576416
Validation loss: 2.9405031486224105

Epoch: 12| Step: 0
Training loss: 2.485938549041748
Validation loss: 2.939883416698825

Epoch: 6| Step: 1
Training loss: 2.7275633811950684
Validation loss: 2.9396237275933705

Epoch: 6| Step: 2
Training loss: 3.693835973739624
Validation loss: 2.939395932741063

Epoch: 6| Step: 3
Training loss: 2.9396800994873047
Validation loss: 2.9403566647601385

Epoch: 6| Step: 4
Training loss: 2.272156238555908
Validation loss: 2.9372347093397573

Epoch: 6| Step: 5
Training loss: 2.699481248855591
Validation loss: 2.9372347683034916

Epoch: 6| Step: 6
Training loss: 3.710134983062744
Validation loss: 2.9361355407263643

Epoch: 6| Step: 7
Training loss: 2.6084516048431396
Validation loss: 2.936547669031287

Epoch: 6| Step: 8
Training loss: 3.502809524536133
Validation loss: 2.9301379880597516

Epoch: 6| Step: 9
Training loss: 3.1237030029296875
Validation loss: 2.9242262840270996

Epoch: 6| Step: 10
Training loss: 3.782390832901001
Validation loss: 2.923194387907623

Epoch: 6| Step: 11
Training loss: 2.7717485427856445
Validation loss: 2.9221573901432816

Epoch: 6| Step: 12
Training loss: 2.9657537937164307
Validation loss: 2.9159926368344213

Epoch: 6| Step: 13
Training loss: 2.9715938568115234
Validation loss: 2.9162361955129974

Epoch: 13| Step: 0
Training loss: 2.906986713409424
Validation loss: 2.913822712436799

Epoch: 6| Step: 1
Training loss: 3.0399398803710938
Validation loss: 2.9130107049019105

Epoch: 6| Step: 2
Training loss: 3.561889171600342
Validation loss: 2.907866680493919

Epoch: 6| Step: 3
Training loss: 3.0358686447143555
Validation loss: 2.9053464551125803

Epoch: 6| Step: 4
Training loss: 2.327408790588379
Validation loss: 2.9034991469434512

Epoch: 6| Step: 5
Training loss: 2.4215087890625
Validation loss: 2.9050571457032235

Epoch: 6| Step: 6
Training loss: 3.0587522983551025
Validation loss: 2.9048622218511437

Epoch: 6| Step: 7
Training loss: 2.624155282974243
Validation loss: 2.9016556406533844

Epoch: 6| Step: 8
Training loss: 2.8534340858459473
Validation loss: 2.9016131098552416

Epoch: 6| Step: 9
Training loss: 2.370349645614624
Validation loss: 2.9335222628808792

Epoch: 6| Step: 10
Training loss: 4.305326461791992
Validation loss: 2.9413962159105527

Epoch: 6| Step: 11
Training loss: 2.3383326530456543
Validation loss: 2.9090919930447816

Epoch: 6| Step: 12
Training loss: 3.7713658809661865
Validation loss: 2.8921552012043614

Epoch: 6| Step: 13
Training loss: 3.821439504623413
Validation loss: 2.8902937904480965

Epoch: 14| Step: 0
Training loss: 2.4074220657348633
Validation loss: 2.8925036345758746

Epoch: 6| Step: 1
Training loss: 3.3900833129882812
Validation loss: 2.8944889191658265

Epoch: 6| Step: 2
Training loss: 2.8938169479370117
Validation loss: 2.8932894788762575

Epoch: 6| Step: 3
Training loss: 3.332797050476074
Validation loss: 2.889646481442195

Epoch: 6| Step: 4
Training loss: 2.5284008979797363
Validation loss: 2.886708092945878

Epoch: 6| Step: 5
Training loss: 2.8318493366241455
Validation loss: 2.8823681082776798

Epoch: 6| Step: 6
Training loss: 2.885192632675171
Validation loss: 2.8823176942845827

Epoch: 6| Step: 7
Training loss: 2.66776442527771
Validation loss: 2.8801228692454677

Epoch: 6| Step: 8
Training loss: 2.487123966217041
Validation loss: 2.8785225499060845

Epoch: 6| Step: 9
Training loss: 3.5837550163269043
Validation loss: 2.877001921335856

Epoch: 6| Step: 10
Training loss: 3.8161566257476807
Validation loss: 2.8761371592039704

Epoch: 6| Step: 11
Training loss: 2.3251991271972656
Validation loss: 2.8747638271700953

Epoch: 6| Step: 12
Training loss: 3.414950370788574
Validation loss: 2.877196519605575

Epoch: 6| Step: 13
Training loss: 3.496351480484009
Validation loss: 2.8781277159208893

Epoch: 15| Step: 0
Training loss: 2.856180191040039
Validation loss: 2.8747587050161054

Epoch: 6| Step: 1
Training loss: 3.866848945617676
Validation loss: 2.867337255067723

Epoch: 6| Step: 2
Training loss: 2.7039756774902344
Validation loss: 2.8656302446960122

Epoch: 6| Step: 3
Training loss: 2.7333858013153076
Validation loss: 2.8694389404789096

Epoch: 6| Step: 4
Training loss: 3.6303257942199707
Validation loss: 2.8936361420539116

Epoch: 6| Step: 5
Training loss: 3.1769661903381348
Validation loss: 2.865773308661676

Epoch: 6| Step: 6
Training loss: 2.3225536346435547
Validation loss: 2.871324610966508

Epoch: 6| Step: 7
Training loss: 3.2421936988830566
Validation loss: 2.883758980740783

Epoch: 6| Step: 8
Training loss: 3.3556160926818848
Validation loss: 2.9072099244722756

Epoch: 6| Step: 9
Training loss: 2.898871421813965
Validation loss: 2.9276403868070213

Epoch: 6| Step: 10
Training loss: 3.058234691619873
Validation loss: 2.884400242118425

Epoch: 6| Step: 11
Training loss: 2.3236865997314453
Validation loss: 2.8793022299325592

Epoch: 6| Step: 12
Training loss: 2.3090715408325195
Validation loss: 2.8787143307347454

Epoch: 6| Step: 13
Training loss: 3.7428579330444336
Validation loss: 2.8772887491410777

Epoch: 16| Step: 0
Training loss: 3.2935335636138916
Validation loss: 2.8691565349537838

Epoch: 6| Step: 1
Training loss: 4.1143341064453125
Validation loss: 2.8689111740358415

Epoch: 6| Step: 2
Training loss: 2.5311317443847656
Validation loss: 2.864528061241232

Epoch: 6| Step: 3
Training loss: 3.093060255050659
Validation loss: 2.863252370588241

Epoch: 6| Step: 4
Training loss: 2.059906005859375
Validation loss: 2.875477562668503

Epoch: 6| Step: 5
Training loss: 3.446561336517334
Validation loss: 2.8867372441035446

Epoch: 6| Step: 6
Training loss: 2.875077247619629
Validation loss: 2.8909393254146782

Epoch: 6| Step: 7
Training loss: 2.651482105255127
Validation loss: 2.8770383865602556

Epoch: 6| Step: 8
Training loss: 3.0963563919067383
Validation loss: 2.8696155676277737

Epoch: 6| Step: 9
Training loss: 3.137852191925049
Validation loss: 2.8679935214340047

Epoch: 6| Step: 10
Training loss: 2.252869129180908
Validation loss: 2.8639161432943037

Epoch: 6| Step: 11
Training loss: 2.4126291275024414
Validation loss: 2.860864987937353

Epoch: 6| Step: 12
Training loss: 3.4541893005371094
Validation loss: 2.856912315532725

Epoch: 6| Step: 13
Training loss: 3.564000368118286
Validation loss: 2.857756507012152

Epoch: 17| Step: 0
Training loss: 4.034595966339111
Validation loss: 2.8635591460812475

Epoch: 6| Step: 1
Training loss: 2.952143907546997
Validation loss: 2.8508370999367005

Epoch: 6| Step: 2
Training loss: 2.9887704849243164
Validation loss: 2.857301265962662

Epoch: 6| Step: 3
Training loss: 2.236067056655884
Validation loss: 2.8554058126223985

Epoch: 6| Step: 4
Training loss: 2.9033329486846924
Validation loss: 2.8565683134140505

Epoch: 6| Step: 5
Training loss: 2.4462764263153076
Validation loss: 2.859841203176847

Epoch: 6| Step: 6
Training loss: 3.275437831878662
Validation loss: 2.860348606622347

Epoch: 6| Step: 7
Training loss: 3.0945796966552734
Validation loss: 2.852936734435379

Epoch: 6| Step: 8
Training loss: 3.2026405334472656
Validation loss: 2.8513516790123394

Epoch: 6| Step: 9
Training loss: 2.7694931030273438
Validation loss: 2.8507438936541156

Epoch: 6| Step: 10
Training loss: 2.551032543182373
Validation loss: 2.8465138942964616

Epoch: 6| Step: 11
Training loss: 2.730891704559326
Validation loss: 2.843067871626987

Epoch: 6| Step: 12
Training loss: 2.8307690620422363
Validation loss: 2.8327809815765708

Epoch: 6| Step: 13
Training loss: 3.9341516494750977
Validation loss: 2.8160887636164182

Epoch: 18| Step: 0
Training loss: 2.98101806640625
Validation loss: 2.8164928856716362

Epoch: 6| Step: 1
Training loss: 2.946399211883545
Validation loss: 2.840036646012337

Epoch: 6| Step: 2
Training loss: 3.5400185585021973
Validation loss: 2.8894436795224427

Epoch: 6| Step: 3
Training loss: 2.7929115295410156
Validation loss: 2.887697542867353

Epoch: 6| Step: 4
Training loss: 2.358034372329712
Validation loss: 2.858771859958608

Epoch: 6| Step: 5
Training loss: 3.687162399291992
Validation loss: 2.8369461464625534

Epoch: 6| Step: 6
Training loss: 2.9685535430908203
Validation loss: 2.8072253375925045

Epoch: 6| Step: 7
Training loss: 3.0774078369140625
Validation loss: 2.8121621454915693

Epoch: 6| Step: 8
Training loss: 3.100131034851074
Validation loss: 2.8147800045628704

Epoch: 6| Step: 9
Training loss: 3.2362589836120605
Validation loss: 2.820877931451285

Epoch: 6| Step: 10
Training loss: 2.329380750656128
Validation loss: 2.814716557020782

Epoch: 6| Step: 11
Training loss: 2.460275650024414
Validation loss: 2.8101480904445855

Epoch: 6| Step: 12
Training loss: 2.985504627227783
Validation loss: 2.8025046702354186

Epoch: 6| Step: 13
Training loss: 2.9547510147094727
Validation loss: 2.803052668930382

Epoch: 19| Step: 0
Training loss: 2.881159782409668
Validation loss: 2.8020039886556645

Epoch: 6| Step: 1
Training loss: 2.19461727142334
Validation loss: 2.8028566452764694

Epoch: 6| Step: 2
Training loss: 2.9877359867095947
Validation loss: 2.800363027921287

Epoch: 6| Step: 3
Training loss: 3.3590402603149414
Validation loss: 2.8019227802112536

Epoch: 6| Step: 4
Training loss: 2.6549854278564453
Validation loss: 2.7960877213426816

Epoch: 6| Step: 5
Training loss: 3.609414577484131
Validation loss: 2.797002120684552

Epoch: 6| Step: 6
Training loss: 3.0960588455200195
Validation loss: 2.7934530832434215

Epoch: 6| Step: 7
Training loss: 3.8014824390411377
Validation loss: 2.7925911898254068

Epoch: 6| Step: 8
Training loss: 2.4324111938476562
Validation loss: 2.791750902770668

Epoch: 6| Step: 9
Training loss: 2.2602555751800537
Validation loss: 2.7931862287623908

Epoch: 6| Step: 10
Training loss: 2.997927665710449
Validation loss: 2.7920598727400585

Epoch: 6| Step: 11
Training loss: 2.40012788772583
Validation loss: 2.789325673093078

Epoch: 6| Step: 12
Training loss: 3.6147637367248535
Validation loss: 2.787120644764234

Epoch: 6| Step: 13
Training loss: 2.6382691860198975
Validation loss: 2.787193303467125

Epoch: 20| Step: 0
Training loss: 3.083744525909424
Validation loss: 2.7860131084278064

Epoch: 6| Step: 1
Training loss: 3.889461040496826
Validation loss: 2.783821854540097

Epoch: 6| Step: 2
Training loss: 3.7595181465148926
Validation loss: 2.781993335293185

Epoch: 6| Step: 3
Training loss: 3.5444047451019287
Validation loss: 2.78079758151885

Epoch: 6| Step: 4
Training loss: 2.2104544639587402
Validation loss: 2.778720471166795

Epoch: 6| Step: 5
Training loss: 3.076267719268799
Validation loss: 2.7769939514898483

Epoch: 6| Step: 6
Training loss: 2.8275163173675537
Validation loss: 2.7759679927620837

Epoch: 6| Step: 7
Training loss: 2.224745273590088
Validation loss: 2.774671907066017

Epoch: 6| Step: 8
Training loss: 2.5086371898651123
Validation loss: 2.7740126553402153

Epoch: 6| Step: 9
Training loss: 3.5484654903411865
Validation loss: 2.7718383624989498

Epoch: 6| Step: 10
Training loss: 2.4848780632019043
Validation loss: 2.7715753073333413

Epoch: 6| Step: 11
Training loss: 2.241854667663574
Validation loss: 2.767748758357058

Epoch: 6| Step: 12
Training loss: 3.343252658843994
Validation loss: 2.7660267224875827

Epoch: 6| Step: 13
Training loss: 1.538788914680481
Validation loss: 2.7647856461104525

Epoch: 21| Step: 0
Training loss: 3.3245420455932617
Validation loss: 2.7654796467032483

Epoch: 6| Step: 1
Training loss: 3.037445068359375
Validation loss: 2.7634790456423195

Epoch: 6| Step: 2
Training loss: 2.6033926010131836
Validation loss: 2.7616793750434794

Epoch: 6| Step: 3
Training loss: 3.256315231323242
Validation loss: 2.7613406770972797

Epoch: 6| Step: 4
Training loss: 2.675194263458252
Validation loss: 2.76008693633541

Epoch: 6| Step: 5
Training loss: 2.7807750701904297
Validation loss: 2.759796478415048

Epoch: 6| Step: 6
Training loss: 3.0016746520996094
Validation loss: 2.75861846247027

Epoch: 6| Step: 7
Training loss: 3.1783220767974854
Validation loss: 2.758119757457446

Epoch: 6| Step: 8
Training loss: 2.3899569511413574
Validation loss: 2.7579118974747194

Epoch: 6| Step: 9
Training loss: 2.9024276733398438
Validation loss: 2.756090053948023

Epoch: 6| Step: 10
Training loss: 3.3252203464508057
Validation loss: 2.7547963075740363

Epoch: 6| Step: 11
Training loss: 2.417820453643799
Validation loss: 2.75641345208691

Epoch: 6| Step: 12
Training loss: 2.9052114486694336
Validation loss: 2.7556436548950853

Epoch: 6| Step: 13
Training loss: 2.9384632110595703
Validation loss: 2.755279989652736

Epoch: 22| Step: 0
Training loss: 3.333786964416504
Validation loss: 2.7553879830145065

Epoch: 6| Step: 1
Training loss: 2.1288342475891113
Validation loss: 2.755737481578704

Epoch: 6| Step: 2
Training loss: 3.51308274269104
Validation loss: 2.7547859145749

Epoch: 6| Step: 3
Training loss: 2.8113198280334473
Validation loss: 2.753016774372388

Epoch: 6| Step: 4
Training loss: 3.837512493133545
Validation loss: 2.7519168059031167

Epoch: 6| Step: 5
Training loss: 2.7499840259552
Validation loss: 2.751355665986256

Epoch: 6| Step: 6
Training loss: 2.5112009048461914
Validation loss: 2.75091141270053

Epoch: 6| Step: 7
Training loss: 3.0767078399658203
Validation loss: 2.7509725709115305

Epoch: 6| Step: 8
Training loss: 2.6346898078918457
Validation loss: 2.7479866730269564

Epoch: 6| Step: 9
Training loss: 2.882877826690674
Validation loss: 2.7471629650362077

Epoch: 6| Step: 10
Training loss: 2.534890651702881
Validation loss: 2.746723449358376

Epoch: 6| Step: 11
Training loss: 2.792600631713867
Validation loss: 2.7464555566028883

Epoch: 6| Step: 12
Training loss: 2.535861015319824
Validation loss: 2.746046661048807

Epoch: 6| Step: 13
Training loss: 3.6004323959350586
Validation loss: 2.7460744406587336

Epoch: 23| Step: 0
Training loss: 3.1163268089294434
Validation loss: 2.745202415732927

Epoch: 6| Step: 1
Training loss: 3.5854694843292236
Validation loss: 2.743556148262434

Epoch: 6| Step: 2
Training loss: 2.5879759788513184
Validation loss: 2.7430986845365135

Epoch: 6| Step: 3
Training loss: 2.3091440200805664
Validation loss: 2.7420537369225615

Epoch: 6| Step: 4
Training loss: 2.582184314727783
Validation loss: 2.7412504867840837

Epoch: 6| Step: 5
Training loss: 3.4231324195861816
Validation loss: 2.74119302534288

Epoch: 6| Step: 6
Training loss: 2.2698957920074463
Validation loss: 2.740789915925713

Epoch: 6| Step: 7
Training loss: 2.919076442718506
Validation loss: 2.741298831919188

Epoch: 6| Step: 8
Training loss: 3.219299793243408
Validation loss: 2.744331439336141

Epoch: 6| Step: 9
Training loss: 3.645232677459717
Validation loss: 2.7452384502657

Epoch: 6| Step: 10
Training loss: 2.437934398651123
Validation loss: 2.7421120136014876

Epoch: 6| Step: 11
Training loss: 2.636411428451538
Validation loss: 2.7381483457421743

Epoch: 6| Step: 12
Training loss: 3.4882736206054688
Validation loss: 2.7361996173858643

Epoch: 6| Step: 13
Training loss: 1.94221031665802
Validation loss: 2.7354424204877628

Epoch: 24| Step: 0
Training loss: 2.5332093238830566
Validation loss: 2.7356710972324496

Epoch: 6| Step: 1
Training loss: 2.5436158180236816
Validation loss: 2.735438323790027

Epoch: 6| Step: 2
Training loss: 3.256885051727295
Validation loss: 2.7334446240496892

Epoch: 6| Step: 3
Training loss: 2.6660213470458984
Validation loss: 2.7337667070409304

Epoch: 6| Step: 4
Training loss: 2.827242374420166
Validation loss: 2.7330831276473178

Epoch: 6| Step: 5
Training loss: 2.7292919158935547
Validation loss: 2.731236393733691

Epoch: 6| Step: 6
Training loss: 3.2967867851257324
Validation loss: 2.731376027548185

Epoch: 6| Step: 7
Training loss: 3.593317985534668
Validation loss: 2.73020294661163

Epoch: 6| Step: 8
Training loss: 2.4804482460021973
Validation loss: 2.7292083001905874

Epoch: 6| Step: 9
Training loss: 3.107269287109375
Validation loss: 2.727316246237806

Epoch: 6| Step: 10
Training loss: 2.734569787979126
Validation loss: 2.726905971445063

Epoch: 6| Step: 11
Training loss: 2.785186767578125
Validation loss: 2.728222134292767

Epoch: 6| Step: 12
Training loss: 2.7856199741363525
Validation loss: 2.726094574056646

Epoch: 6| Step: 13
Training loss: 3.329618453979492
Validation loss: 2.7272873232441563

Epoch: 25| Step: 0
Training loss: 2.28507137298584
Validation loss: 2.724950228967974

Epoch: 6| Step: 1
Training loss: 3.408592700958252
Validation loss: 2.724634772987776

Epoch: 6| Step: 2
Training loss: 2.3462276458740234
Validation loss: 2.722962810147193

Epoch: 6| Step: 3
Training loss: 2.726811647415161
Validation loss: 2.721960675331854

Epoch: 6| Step: 4
Training loss: 2.892289638519287
Validation loss: 2.721557935078939

Epoch: 6| Step: 5
Training loss: 2.439953327178955
Validation loss: 2.7191518993787867

Epoch: 6| Step: 6
Training loss: 3.8356761932373047
Validation loss: 2.719405174255371

Epoch: 6| Step: 7
Training loss: 3.10603666305542
Validation loss: 2.7163574362313874

Epoch: 6| Step: 8
Training loss: 2.2706212997436523
Validation loss: 2.717178390872094

Epoch: 6| Step: 9
Training loss: 3.5358593463897705
Validation loss: 2.7183102587217927

Epoch: 6| Step: 10
Training loss: 2.5922319889068604
Validation loss: 2.717238215989964

Epoch: 6| Step: 11
Training loss: 3.4097228050231934
Validation loss: 2.7143438939125306

Epoch: 6| Step: 12
Training loss: 2.628959894180298
Validation loss: 2.7148148244427097

Epoch: 6| Step: 13
Training loss: 2.8742525577545166
Validation loss: 2.714847892843267

Epoch: 26| Step: 0
Training loss: 3.047255039215088
Validation loss: 2.7134099647562993

Epoch: 6| Step: 1
Training loss: 4.525709629058838
Validation loss: 2.7132679236832487

Epoch: 6| Step: 2
Training loss: 2.5674641132354736
Validation loss: 2.7130259134436168

Epoch: 6| Step: 3
Training loss: 3.043386459350586
Validation loss: 2.7125033024818666

Epoch: 6| Step: 4
Training loss: 2.519989013671875
Validation loss: 2.7113664944966636

Epoch: 6| Step: 5
Training loss: 2.974846839904785
Validation loss: 2.711148618369974

Epoch: 6| Step: 6
Training loss: 2.5320000648498535
Validation loss: 2.7089590795578493

Epoch: 6| Step: 7
Training loss: 2.652998447418213
Validation loss: 2.710078985460343

Epoch: 6| Step: 8
Training loss: 2.996227264404297
Validation loss: 2.7080419653205463

Epoch: 6| Step: 9
Training loss: 3.123509407043457
Validation loss: 2.707195779328705

Epoch: 6| Step: 10
Training loss: 2.728079080581665
Validation loss: 2.711097922376407

Epoch: 6| Step: 11
Training loss: 2.5743279457092285
Validation loss: 2.7167297665790846

Epoch: 6| Step: 12
Training loss: 2.175018072128296
Validation loss: 2.709869643693329

Epoch: 6| Step: 13
Training loss: 2.7507731914520264
Validation loss: 2.7040416271455827

Epoch: 27| Step: 0
Training loss: 2.6200344562530518
Validation loss: 2.707147608521164

Epoch: 6| Step: 1
Training loss: 3.6557188034057617
Validation loss: 2.698657594701295

Epoch: 6| Step: 2
Training loss: 3.2421796321868896
Validation loss: 2.7019239805077993

Epoch: 6| Step: 3
Training loss: 2.7091634273529053
Validation loss: 2.702525684910436

Epoch: 6| Step: 4
Training loss: 3.56210994720459
Validation loss: 2.7069071364659134

Epoch: 6| Step: 5
Training loss: 2.6654088497161865
Validation loss: 2.7037657819768435

Epoch: 6| Step: 6
Training loss: 2.588322162628174
Validation loss: 2.7018201428074993

Epoch: 6| Step: 7
Training loss: 3.0222482681274414
Validation loss: 2.701427457153156

Epoch: 6| Step: 8
Training loss: 3.5705726146698
Validation loss: 2.7006757028641237

Epoch: 6| Step: 9
Training loss: 2.7761929035186768
Validation loss: 2.6974839702729256

Epoch: 6| Step: 10
Training loss: 2.4435925483703613
Validation loss: 2.6975481715253604

Epoch: 6| Step: 11
Training loss: 2.260439395904541
Validation loss: 2.697189400272985

Epoch: 6| Step: 12
Training loss: 2.4782443046569824
Validation loss: 2.698744322663994

Epoch: 6| Step: 13
Training loss: 2.379178524017334
Validation loss: 2.701172664601316

Epoch: 28| Step: 0
Training loss: 3.264272451400757
Validation loss: 2.7264763334746003

Epoch: 6| Step: 1
Training loss: 3.4649152755737305
Validation loss: 2.7280932293143323

Epoch: 6| Step: 2
Training loss: 2.069122076034546
Validation loss: 2.7191268218460904

Epoch: 6| Step: 3
Training loss: 3.573428153991699
Validation loss: 2.7340129626694547

Epoch: 6| Step: 4
Training loss: 2.8650193214416504
Validation loss: 2.753019350831227

Epoch: 6| Step: 5
Training loss: 2.5546536445617676
Validation loss: 2.8036871187148558

Epoch: 6| Step: 6
Training loss: 3.06912899017334
Validation loss: 2.7270536499638713

Epoch: 6| Step: 7
Training loss: 2.660688877105713
Validation loss: 2.7011050203795075

Epoch: 6| Step: 8
Training loss: 3.012681484222412
Validation loss: 2.7050825652255805

Epoch: 6| Step: 9
Training loss: 3.0466926097869873
Validation loss: 2.728282864375781

Epoch: 6| Step: 10
Training loss: 3.0038511753082275
Validation loss: 2.7478490183430333

Epoch: 6| Step: 11
Training loss: 2.9894027709960938
Validation loss: 2.7780108272388415

Epoch: 6| Step: 12
Training loss: 1.982100248336792
Validation loss: 2.7622784388962613

Epoch: 6| Step: 13
Training loss: 2.8042287826538086
Validation loss: 2.7755124902212494

Epoch: 29| Step: 0
Training loss: 2.860347270965576
Validation loss: 2.793572246387441

Epoch: 6| Step: 1
Training loss: 2.9292688369750977
Validation loss: 2.7964284855832338

Epoch: 6| Step: 2
Training loss: 2.4761600494384766
Validation loss: 2.786712687502625

Epoch: 6| Step: 3
Training loss: 2.8514516353607178
Validation loss: 2.7482488975729993

Epoch: 6| Step: 4
Training loss: 2.732637882232666
Validation loss: 2.7434488599018385

Epoch: 6| Step: 5
Training loss: 2.3826169967651367
Validation loss: 2.8470463829655803

Epoch: 6| Step: 6
Training loss: 2.6851015090942383
Validation loss: 2.9094828046778196

Epoch: 6| Step: 7
Training loss: 2.762850522994995
Validation loss: 2.828669091706635

Epoch: 6| Step: 8
Training loss: 2.9703402519226074
Validation loss: 2.738916781640822

Epoch: 6| Step: 9
Training loss: 3.4357573986053467
Validation loss: 2.7190821222079697

Epoch: 6| Step: 10
Training loss: 2.946392059326172
Validation loss: 2.7065385772335913

Epoch: 6| Step: 11
Training loss: 3.1281275749206543
Validation loss: 2.707776746442241

Epoch: 6| Step: 12
Training loss: 3.302454948425293
Validation loss: 2.7025316633203977

Epoch: 6| Step: 13
Training loss: 3.100937843322754
Validation loss: 2.724096428963446

Epoch: 30| Step: 0
Training loss: 3.5206310749053955
Validation loss: 2.750115822720271

Epoch: 6| Step: 1
Training loss: 2.2412993907928467
Validation loss: 2.689789428505846

Epoch: 6| Step: 2
Training loss: 2.513195514678955
Validation loss: 2.697878752985308

Epoch: 6| Step: 3
Training loss: 2.8711414337158203
Validation loss: 2.7254176473104827

Epoch: 6| Step: 4
Training loss: 3.387421131134033
Validation loss: 2.745060451569096

Epoch: 6| Step: 5
Training loss: 2.340470314025879
Validation loss: 2.7511878705793813

Epoch: 6| Step: 6
Training loss: 2.7096080780029297
Validation loss: 2.761627745884721

Epoch: 6| Step: 7
Training loss: 3.3422341346740723
Validation loss: 2.7649311814256894

Epoch: 6| Step: 8
Training loss: 3.026625156402588
Validation loss: 2.736348380324661

Epoch: 6| Step: 9
Training loss: 3.2537574768066406
Validation loss: 2.713308636860181

Epoch: 6| Step: 10
Training loss: 2.720395565032959
Validation loss: 2.704898072827247

Epoch: 6| Step: 11
Training loss: 2.3498716354370117
Validation loss: 2.7027647469633367

Epoch: 6| Step: 12
Training loss: 2.9651002883911133
Validation loss: 2.6989995023255706

Epoch: 6| Step: 13
Training loss: 3.17838191986084
Validation loss: 2.703404857266334

Epoch: 31| Step: 0
Training loss: 3.043957233428955
Validation loss: 2.7036359899787494

Epoch: 6| Step: 1
Training loss: 2.537677764892578
Validation loss: 2.6986522187468824

Epoch: 6| Step: 2
Training loss: 2.4543848037719727
Validation loss: 2.696076718709802

Epoch: 6| Step: 3
Training loss: 3.053730010986328
Validation loss: 2.6914570408482708

Epoch: 6| Step: 4
Training loss: 1.9098554849624634
Validation loss: 2.6846792492815243

Epoch: 6| Step: 5
Training loss: 3.021993637084961
Validation loss: 2.6868676293280815

Epoch: 6| Step: 6
Training loss: 3.2699599266052246
Validation loss: 2.690080342754241

Epoch: 6| Step: 7
Training loss: 3.0694966316223145
Validation loss: 2.6951143305788756

Epoch: 6| Step: 8
Training loss: 2.138741970062256
Validation loss: 2.6927336287754837

Epoch: 6| Step: 9
Training loss: 2.5054690837860107
Validation loss: 2.6978803757698304

Epoch: 6| Step: 10
Training loss: 3.5666513442993164
Validation loss: 2.708161151537331

Epoch: 6| Step: 11
Training loss: 2.4556093215942383
Validation loss: 2.7057641424158567

Epoch: 6| Step: 12
Training loss: 3.4598441123962402
Validation loss: 2.691594877550679

Epoch: 6| Step: 13
Training loss: 3.8722238540649414
Validation loss: 2.682449238274687

Epoch: 32| Step: 0
Training loss: 2.020885944366455
Validation loss: 2.664367301489717

Epoch: 6| Step: 1
Training loss: 3.6625471115112305
Validation loss: 2.6663085670881372

Epoch: 6| Step: 2
Training loss: 3.711440086364746
Validation loss: 2.670921661520517

Epoch: 6| Step: 3
Training loss: 1.9578826427459717
Validation loss: 2.6764262158383607

Epoch: 6| Step: 4
Training loss: 3.23724365234375
Validation loss: 2.676044284656484

Epoch: 6| Step: 5
Training loss: 3.2121143341064453
Validation loss: 2.66353710492452

Epoch: 6| Step: 6
Training loss: 2.802034854888916
Validation loss: 2.6555019527353267

Epoch: 6| Step: 7
Training loss: 2.662909746170044
Validation loss: 2.6577135311659945

Epoch: 6| Step: 8
Training loss: 2.987063407897949
Validation loss: 2.6590237207310174

Epoch: 6| Step: 9
Training loss: 1.9919219017028809
Validation loss: 2.66183316323065

Epoch: 6| Step: 10
Training loss: 3.0643153190612793
Validation loss: 2.6590048830996276

Epoch: 6| Step: 11
Training loss: 2.92225980758667
Validation loss: 2.657877693894089

Epoch: 6| Step: 12
Training loss: 2.348196268081665
Validation loss: 2.657281082163575

Epoch: 6| Step: 13
Training loss: 3.1712968349456787
Validation loss: 2.656752214636854

Epoch: 33| Step: 0
Training loss: 3.215587615966797
Validation loss: 2.657798946544688

Epoch: 6| Step: 1
Training loss: 3.086430311203003
Validation loss: 2.669615578907792

Epoch: 6| Step: 2
Training loss: 3.218494176864624
Validation loss: 2.6628172346340713

Epoch: 6| Step: 3
Training loss: 2.930988073348999
Validation loss: 2.6564934561329503

Epoch: 6| Step: 4
Training loss: 2.804105758666992
Validation loss: 2.6517810642078357

Epoch: 6| Step: 5
Training loss: 2.489297389984131
Validation loss: 2.652598234914964

Epoch: 6| Step: 6
Training loss: 2.6196537017822266
Validation loss: 2.6596090665427585

Epoch: 6| Step: 7
Training loss: 2.9497804641723633
Validation loss: 2.6594924875485

Epoch: 6| Step: 8
Training loss: 2.91599702835083
Validation loss: 2.6530404475427445

Epoch: 6| Step: 9
Training loss: 2.9097487926483154
Validation loss: 2.636064483273414

Epoch: 6| Step: 10
Training loss: 2.3541884422302246
Validation loss: 2.624898628521991

Epoch: 6| Step: 11
Training loss: 2.9720101356506348
Validation loss: 2.6273823297151955

Epoch: 6| Step: 12
Training loss: 1.989858865737915
Validation loss: 2.636362555206463

Epoch: 6| Step: 13
Training loss: 2.7297401428222656
Validation loss: 2.68859278258457

Epoch: 34| Step: 0
Training loss: 1.9662480354309082
Validation loss: 2.705042839050293

Epoch: 6| Step: 1
Training loss: 2.764540672302246
Validation loss: 2.6533169182397986

Epoch: 6| Step: 2
Training loss: 3.556833505630493
Validation loss: 2.6342405555068806

Epoch: 6| Step: 3
Training loss: 3.3713278770446777
Validation loss: 2.623114252603182

Epoch: 6| Step: 4
Training loss: 2.7347466945648193
Validation loss: 2.628248465958462

Epoch: 6| Step: 5
Training loss: 2.62094783782959
Validation loss: 2.642888371662427

Epoch: 6| Step: 6
Training loss: 2.803408145904541
Validation loss: 2.6399419615345616

Epoch: 6| Step: 7
Training loss: 3.646714687347412
Validation loss: 2.6406991558690227

Epoch: 6| Step: 8
Training loss: 2.470331907272339
Validation loss: 2.634304905450472

Epoch: 6| Step: 9
Training loss: 2.588970184326172
Validation loss: 2.623323404660789

Epoch: 6| Step: 10
Training loss: 3.1941299438476562
Validation loss: 2.6196833759225826

Epoch: 6| Step: 11
Training loss: 2.42954683303833
Validation loss: 2.6160553578407533

Epoch: 6| Step: 12
Training loss: 1.9862308502197266
Validation loss: 2.612432208112491

Epoch: 6| Step: 13
Training loss: 3.3065185546875
Validation loss: 2.6370074415719635

Epoch: 35| Step: 0
Training loss: 2.787743330001831
Validation loss: 2.6617568257034465

Epoch: 6| Step: 1
Training loss: 2.8838913440704346
Validation loss: 2.697692007146856

Epoch: 6| Step: 2
Training loss: 3.139530658721924
Validation loss: 2.759907994219052

Epoch: 6| Step: 3
Training loss: 2.6711645126342773
Validation loss: 2.742258374409009

Epoch: 6| Step: 4
Training loss: 3.6934762001037598
Validation loss: 2.6531531759487685

Epoch: 6| Step: 5
Training loss: 2.6249947547912598
Validation loss: 2.6087760848383748

Epoch: 6| Step: 6
Training loss: 1.921980381011963
Validation loss: 2.6090653993750132

Epoch: 6| Step: 7
Training loss: 2.6288270950317383
Validation loss: 2.616503054095853

Epoch: 6| Step: 8
Training loss: 3.303328275680542
Validation loss: 2.6393157025819183

Epoch: 6| Step: 9
Training loss: 3.001300573348999
Validation loss: 2.6278945374232467

Epoch: 6| Step: 10
Training loss: 2.2790091037750244
Validation loss: 2.6403298993264475

Epoch: 6| Step: 11
Training loss: 2.9901914596557617
Validation loss: 2.629756817253687

Epoch: 6| Step: 12
Training loss: 2.531900405883789
Validation loss: 2.6236312927738314

Epoch: 6| Step: 13
Training loss: 2.557677745819092
Validation loss: 2.6218204703382266

Epoch: 36| Step: 0
Training loss: 2.3345894813537598
Validation loss: 2.613052652728173

Epoch: 6| Step: 1
Training loss: 2.362271547317505
Validation loss: 2.610022388478761

Epoch: 6| Step: 2
Training loss: 2.9793028831481934
Validation loss: 2.605632684564078

Epoch: 6| Step: 3
Training loss: 2.559596538543701
Validation loss: 2.6034930957260953

Epoch: 6| Step: 4
Training loss: 2.574146032333374
Validation loss: 2.6021944963803856

Epoch: 6| Step: 5
Training loss: 2.9884724617004395
Validation loss: 2.597223138296476

Epoch: 6| Step: 6
Training loss: 2.7103681564331055
Validation loss: 2.6111984996385473

Epoch: 6| Step: 7
Training loss: 2.9867804050445557
Validation loss: 2.640064941939487

Epoch: 6| Step: 8
Training loss: 2.545741558074951
Validation loss: 2.66474776370551

Epoch: 6| Step: 9
Training loss: 2.905083417892456
Validation loss: 2.6805153303248908

Epoch: 6| Step: 10
Training loss: 2.714766263961792
Validation loss: 2.6670730549802064

Epoch: 6| Step: 11
Training loss: 3.0006046295166016
Validation loss: 2.613400338798441

Epoch: 6| Step: 12
Training loss: 2.7387428283691406
Validation loss: 2.598438634667345

Epoch: 6| Step: 13
Training loss: 3.9288320541381836
Validation loss: 2.593025320319719

Epoch: 37| Step: 0
Training loss: 2.704646348953247
Validation loss: 2.5876243781018

Epoch: 6| Step: 1
Training loss: 2.6291913986206055
Validation loss: 2.590098673297513

Epoch: 6| Step: 2
Training loss: 3.046505928039551
Validation loss: 2.590127880855273

Epoch: 6| Step: 3
Training loss: 1.9318863153457642
Validation loss: 2.588458068909184

Epoch: 6| Step: 4
Training loss: 2.5786921977996826
Validation loss: 2.588066126710625

Epoch: 6| Step: 5
Training loss: 3.4152817726135254
Validation loss: 2.5870797659761164

Epoch: 6| Step: 6
Training loss: 3.027418613433838
Validation loss: 2.5997145816844

Epoch: 6| Step: 7
Training loss: 2.9285387992858887
Validation loss: 2.6075770829313543

Epoch: 6| Step: 8
Training loss: 1.9941229820251465
Validation loss: 2.635772628168906

Epoch: 6| Step: 9
Training loss: 2.768655300140381
Validation loss: 2.644467220511488

Epoch: 6| Step: 10
Training loss: 2.758805513381958
Validation loss: 2.6384126088952504

Epoch: 6| Step: 11
Training loss: 3.3641955852508545
Validation loss: 2.6059428953355357

Epoch: 6| Step: 12
Training loss: 2.453134775161743
Validation loss: 2.583866698767549

Epoch: 6| Step: 13
Training loss: 3.2435262203216553
Validation loss: 2.590380689149262

Epoch: 38| Step: 0
Training loss: 2.702009677886963
Validation loss: 2.637626553094515

Epoch: 6| Step: 1
Training loss: 2.656251907348633
Validation loss: 2.6710141346018803

Epoch: 6| Step: 2
Training loss: 3.1060190200805664
Validation loss: 2.74011145868609

Epoch: 6| Step: 3
Training loss: 2.600846290588379
Validation loss: 2.719371231653357

Epoch: 6| Step: 4
Training loss: 2.8866701126098633
Validation loss: 2.6308189207507717

Epoch: 6| Step: 5
Training loss: 3.0372977256774902
Validation loss: 2.590236799691313

Epoch: 6| Step: 6
Training loss: 3.632420063018799
Validation loss: 2.577191657917474

Epoch: 6| Step: 7
Training loss: 2.932765007019043
Validation loss: 2.585330178660731

Epoch: 6| Step: 8
Training loss: 2.346534013748169
Validation loss: 2.6393359091974076

Epoch: 6| Step: 9
Training loss: 3.1807351112365723
Validation loss: 2.74961434384828

Epoch: 6| Step: 10
Training loss: 3.015636444091797
Validation loss: 2.7275588358602216

Epoch: 6| Step: 11
Training loss: 1.9292078018188477
Validation loss: 2.6110926648621917

Epoch: 6| Step: 12
Training loss: 3.2793259620666504
Validation loss: 2.5818822973517963

Epoch: 6| Step: 13
Training loss: 1.733664631843567
Validation loss: 2.5803340711901264

Epoch: 39| Step: 0
Training loss: 2.45400333404541
Validation loss: 2.5784080310534407

Epoch: 6| Step: 1
Training loss: 2.377040386199951
Validation loss: 2.574060055517381

Epoch: 6| Step: 2
Training loss: 2.469590902328491
Validation loss: 2.572240780758601

Epoch: 6| Step: 3
Training loss: 2.667541265487671
Validation loss: 2.5708063058955695

Epoch: 6| Step: 4
Training loss: 2.998157024383545
Validation loss: 2.5732444999038533

Epoch: 6| Step: 5
Training loss: 2.665463924407959
Validation loss: 2.571793261394706

Epoch: 6| Step: 6
Training loss: 3.129023790359497
Validation loss: 2.5660090395199355

Epoch: 6| Step: 7
Training loss: 3.1149168014526367
Validation loss: 2.5670391616000923

Epoch: 6| Step: 8
Training loss: 2.5204405784606934
Validation loss: 2.5712799154302126

Epoch: 6| Step: 9
Training loss: 2.5668249130249023
Validation loss: 2.5630813593505533

Epoch: 6| Step: 10
Training loss: 3.633329391479492
Validation loss: 2.563651782210155

Epoch: 6| Step: 11
Training loss: 2.911346197128296
Validation loss: 2.563784001975931

Epoch: 6| Step: 12
Training loss: 1.8347597122192383
Validation loss: 2.606445430427469

Epoch: 6| Step: 13
Training loss: 3.5257985591888428
Validation loss: 2.6173330250606743

Epoch: 40| Step: 0
Training loss: 3.084207057952881
Validation loss: 2.564909032596055

Epoch: 6| Step: 1
Training loss: 3.2026634216308594
Validation loss: 2.5641465956164944

Epoch: 6| Step: 2
Training loss: 2.682595729827881
Validation loss: 2.559214489434355

Epoch: 6| Step: 3
Training loss: 2.1067278385162354
Validation loss: 2.559032315848976

Epoch: 6| Step: 4
Training loss: 2.8232481479644775
Validation loss: 2.563590180489325

Epoch: 6| Step: 5
Training loss: 2.4545533657073975
Validation loss: 2.5664846704852198

Epoch: 6| Step: 6
Training loss: 2.225241184234619
Validation loss: 2.5762953783876155

Epoch: 6| Step: 7
Training loss: 3.5670366287231445
Validation loss: 2.591243144004576

Epoch: 6| Step: 8
Training loss: 2.545929193496704
Validation loss: 2.6094561879352858

Epoch: 6| Step: 9
Training loss: 2.677600860595703
Validation loss: 2.632360173809913

Epoch: 6| Step: 10
Training loss: 3.0008468627929688
Validation loss: 2.6139036814371743

Epoch: 6| Step: 11
Training loss: 3.647937774658203
Validation loss: 2.584725626053349

Epoch: 6| Step: 12
Training loss: 2.3162999153137207
Validation loss: 2.5582371655330864

Epoch: 6| Step: 13
Training loss: 1.8590712547302246
Validation loss: 2.557791648372527

Epoch: 41| Step: 0
Training loss: 2.596971035003662
Validation loss: 2.5551992821437057

Epoch: 6| Step: 1
Training loss: 1.9181334972381592
Validation loss: 2.554833271170175

Epoch: 6| Step: 2
Training loss: 2.9036121368408203
Validation loss: 2.5531190877319663

Epoch: 6| Step: 3
Training loss: 3.146730422973633
Validation loss: 2.550170362636607

Epoch: 6| Step: 4
Training loss: 2.305634021759033
Validation loss: 2.5535282524683143

Epoch: 6| Step: 5
Training loss: 2.714834690093994
Validation loss: 2.5485806644603772

Epoch: 6| Step: 6
Training loss: 1.8004173040390015
Validation loss: 2.5535168058128765

Epoch: 6| Step: 7
Training loss: 2.5565924644470215
Validation loss: 2.559999606942618

Epoch: 6| Step: 8
Training loss: 4.08142614364624
Validation loss: 2.5670567661203365

Epoch: 6| Step: 9
Training loss: 3.4526665210723877
Validation loss: 2.5654984725418912

Epoch: 6| Step: 10
Training loss: 2.460681676864624
Validation loss: 2.5660185762630996

Epoch: 6| Step: 11
Training loss: 2.8407397270202637
Validation loss: 2.5705519619808403

Epoch: 6| Step: 12
Training loss: 2.8951706886291504
Validation loss: 2.5589523853794223

Epoch: 6| Step: 13
Training loss: 2.4751229286193848
Validation loss: 2.5510530394892537

Epoch: 42| Step: 0
Training loss: 2.8111839294433594
Validation loss: 2.5504968320169756

Epoch: 6| Step: 1
Training loss: 1.9966554641723633
Validation loss: 2.541522284989716

Epoch: 6| Step: 2
Training loss: 2.3776261806488037
Validation loss: 2.5398059122024046

Epoch: 6| Step: 3
Training loss: 2.3376288414001465
Validation loss: 2.5363364014574277

Epoch: 6| Step: 4
Training loss: 3.282482624053955
Validation loss: 2.5392934430030083

Epoch: 6| Step: 5
Training loss: 2.959622621536255
Validation loss: 2.540414382052678

Epoch: 6| Step: 6
Training loss: 2.8766467571258545
Validation loss: 2.5479683799128376

Epoch: 6| Step: 7
Training loss: 2.4977126121520996
Validation loss: 2.5353878672404955

Epoch: 6| Step: 8
Training loss: 1.8844887018203735
Validation loss: 2.537515358258319

Epoch: 6| Step: 9
Training loss: 3.370712995529175
Validation loss: 2.531819194875738

Epoch: 6| Step: 10
Training loss: 2.774782657623291
Validation loss: 2.5377411714164158

Epoch: 6| Step: 11
Training loss: 2.69519305229187
Validation loss: 2.551166093477639

Epoch: 6| Step: 12
Training loss: 2.9978389739990234
Validation loss: 2.5561012298830095

Epoch: 6| Step: 13
Training loss: 3.801212787628174
Validation loss: 2.5709856761399137

Epoch: 43| Step: 0
Training loss: 2.8888437747955322
Validation loss: 2.5834092376052693

Epoch: 6| Step: 1
Training loss: 2.8729751110076904
Validation loss: 2.607420075324274

Epoch: 6| Step: 2
Training loss: 2.796438217163086
Validation loss: 2.609691717291391

Epoch: 6| Step: 3
Training loss: 2.7325544357299805
Validation loss: 2.582591425987982

Epoch: 6| Step: 4
Training loss: 2.428708553314209
Validation loss: 2.5623922040385585

Epoch: 6| Step: 5
Training loss: 1.9849224090576172
Validation loss: 2.553718033657279

Epoch: 6| Step: 6
Training loss: 3.367845296859741
Validation loss: 2.5501502226757746

Epoch: 6| Step: 7
Training loss: 3.0629897117614746
Validation loss: 2.5489681536151516

Epoch: 6| Step: 8
Training loss: 3.0995373725891113
Validation loss: 2.550293650678409

Epoch: 6| Step: 9
Training loss: 1.6380854845046997
Validation loss: 2.542267240503783

Epoch: 6| Step: 10
Training loss: 2.8498024940490723
Validation loss: 2.537092219116867

Epoch: 6| Step: 11
Training loss: 2.713669538497925
Validation loss: 2.5381120071616223

Epoch: 6| Step: 12
Training loss: 2.6243393421173096
Validation loss: 2.5294767836088776

Epoch: 6| Step: 13
Training loss: 3.250868082046509
Validation loss: 2.5287050303592475

Epoch: 44| Step: 0
Training loss: 2.9237794876098633
Validation loss: 2.527731687791886

Epoch: 6| Step: 1
Training loss: 2.92270565032959
Validation loss: 2.538937576355473

Epoch: 6| Step: 2
Training loss: 2.664431095123291
Validation loss: 2.531602826169742

Epoch: 6| Step: 3
Training loss: 2.79110050201416
Validation loss: 2.5343983993735364

Epoch: 6| Step: 4
Training loss: 2.3327624797821045
Validation loss: 2.5383899622066046

Epoch: 6| Step: 5
Training loss: 2.8735785484313965
Validation loss: 2.53240623781758

Epoch: 6| Step: 6
Training loss: 2.55438232421875
Validation loss: 2.5277963992088073

Epoch: 6| Step: 7
Training loss: 2.9936470985412598
Validation loss: 2.5273075180668987

Epoch: 6| Step: 8
Training loss: 2.538811683654785
Validation loss: 2.534157000562196

Epoch: 6| Step: 9
Training loss: 2.635200262069702
Validation loss: 2.534169417555614

Epoch: 6| Step: 10
Training loss: 2.283231496810913
Validation loss: 2.528534091928954

Epoch: 6| Step: 11
Training loss: 3.225674867630005
Validation loss: 2.5209889719563146

Epoch: 6| Step: 12
Training loss: 2.4064016342163086
Validation loss: 2.5210756947917323

Epoch: 6| Step: 13
Training loss: 2.873026132583618
Validation loss: 2.5193836970995833

Epoch: 45| Step: 0
Training loss: 3.263625144958496
Validation loss: 2.518850600847634

Epoch: 6| Step: 1
Training loss: 3.0957682132720947
Validation loss: 2.5141280927965717

Epoch: 6| Step: 2
Training loss: 2.4589438438415527
Validation loss: 2.5151168736078406

Epoch: 6| Step: 3
Training loss: 2.875157356262207
Validation loss: 2.511447424529701

Epoch: 6| Step: 4
Training loss: 2.9331440925598145
Validation loss: 2.510062468949185

Epoch: 6| Step: 5
Training loss: 2.032461404800415
Validation loss: 2.514001977059149

Epoch: 6| Step: 6
Training loss: 2.192206382751465
Validation loss: 2.514784674490652

Epoch: 6| Step: 7
Training loss: 2.231203317642212
Validation loss: 2.5141673370074202

Epoch: 6| Step: 8
Training loss: 2.922898054122925
Validation loss: 2.5202141936107347

Epoch: 6| Step: 9
Training loss: 2.982069969177246
Validation loss: 2.522540746196624

Epoch: 6| Step: 10
Training loss: 2.3589162826538086
Validation loss: 2.517421832648657

Epoch: 6| Step: 11
Training loss: 3.3032824993133545
Validation loss: 2.519153730843657

Epoch: 6| Step: 12
Training loss: 2.4640541076660156
Validation loss: 2.521287287435224

Epoch: 6| Step: 13
Training loss: 2.642455816268921
Validation loss: 2.5245048102512153

Epoch: 46| Step: 0
Training loss: 2.6769814491271973
Validation loss: 2.5267378950631745

Epoch: 6| Step: 1
Training loss: 2.277891159057617
Validation loss: 2.5267747986701226

Epoch: 6| Step: 2
Training loss: 2.387946128845215
Validation loss: 2.5259783396156887

Epoch: 6| Step: 3
Training loss: 2.893521308898926
Validation loss: 2.5244363046461538

Epoch: 6| Step: 4
Training loss: 2.7812469005584717
Validation loss: 2.5161689122517905

Epoch: 6| Step: 5
Training loss: 2.7799205780029297
Validation loss: 2.515906128832089

Epoch: 6| Step: 6
Training loss: 1.981963038444519
Validation loss: 2.511161745235484

Epoch: 6| Step: 7
Training loss: 3.088845729827881
Validation loss: 2.51704817177147

Epoch: 6| Step: 8
Training loss: 3.0109381675720215
Validation loss: 2.5252428772628948

Epoch: 6| Step: 9
Training loss: 2.738687753677368
Validation loss: 2.5312267503430768

Epoch: 6| Step: 10
Training loss: 2.3674206733703613
Validation loss: 2.530990900531892

Epoch: 6| Step: 11
Training loss: 3.732163667678833
Validation loss: 2.533981489878829

Epoch: 6| Step: 12
Training loss: 2.456173896789551
Validation loss: 2.52514241075003

Epoch: 6| Step: 13
Training loss: 3.262038230895996
Validation loss: 2.518774781175839

Epoch: 47| Step: 0
Training loss: 2.5734944343566895
Validation loss: 2.5077201115187777

Epoch: 6| Step: 1
Training loss: 2.9947547912597656
Validation loss: 2.506681865261447

Epoch: 6| Step: 2
Training loss: 2.8200950622558594
Validation loss: 2.5069381601067

Epoch: 6| Step: 3
Training loss: 1.9348361492156982
Validation loss: 2.520537814786357

Epoch: 6| Step: 4
Training loss: 3.6816186904907227
Validation loss: 2.5374193524801605

Epoch: 6| Step: 5
Training loss: 3.0567984580993652
Validation loss: 2.5534473978063112

Epoch: 6| Step: 6
Training loss: 2.3780550956726074
Validation loss: 2.556147475396433

Epoch: 6| Step: 7
Training loss: 2.30460786819458
Validation loss: 2.5382914632879277

Epoch: 6| Step: 8
Training loss: 2.8532445430755615
Validation loss: 2.524953862672211

Epoch: 6| Step: 9
Training loss: 3.149627685546875
Validation loss: 2.51011493385479

Epoch: 6| Step: 10
Training loss: 2.4667317867279053
Validation loss: 2.4963466146940827

Epoch: 6| Step: 11
Training loss: 2.175497531890869
Validation loss: 2.4959558107519664

Epoch: 6| Step: 12
Training loss: 2.142836332321167
Validation loss: 2.498315131792458

Epoch: 6| Step: 13
Training loss: 3.6327853202819824
Validation loss: 2.4976676151316655

Epoch: 48| Step: 0
Training loss: 2.722658157348633
Validation loss: 2.4962759094853557

Epoch: 6| Step: 1
Training loss: 2.879481554031372
Validation loss: 2.4952569443692445

Epoch: 6| Step: 2
Training loss: 3.0600969791412354
Validation loss: 2.4935619036356607

Epoch: 6| Step: 3
Training loss: 3.3218092918395996
Validation loss: 2.4896562458366476

Epoch: 6| Step: 4
Training loss: 2.127035140991211
Validation loss: 2.492636698548512

Epoch: 6| Step: 5
Training loss: 2.047280788421631
Validation loss: 2.4881388064353698

Epoch: 6| Step: 6
Training loss: 3.098066806793213
Validation loss: 2.491278027975431

Epoch: 6| Step: 7
Training loss: 2.4577925205230713
Validation loss: 2.487031188062442

Epoch: 6| Step: 8
Training loss: 2.7634429931640625
Validation loss: 2.4872365459319083

Epoch: 6| Step: 9
Training loss: 2.5296101570129395
Validation loss: 2.487264935688306

Epoch: 6| Step: 10
Training loss: 2.037067413330078
Validation loss: 2.4868284297245804

Epoch: 6| Step: 11
Training loss: 2.552694082260132
Validation loss: 2.488636565464799

Epoch: 6| Step: 12
Training loss: 2.9632434844970703
Validation loss: 2.495882631630026

Epoch: 6| Step: 13
Training loss: 3.600209951400757
Validation loss: 2.5081899909562964

Epoch: 49| Step: 0
Training loss: 3.1774652004241943
Validation loss: 2.4983854909096994

Epoch: 6| Step: 1
Training loss: 2.334609031677246
Validation loss: 2.495381373231129

Epoch: 6| Step: 2
Training loss: 2.4166038036346436
Validation loss: 2.493497484473772

Epoch: 6| Step: 3
Training loss: 1.897092342376709
Validation loss: 2.494249532299657

Epoch: 6| Step: 4
Training loss: 3.0655617713928223
Validation loss: 2.4989382964308544

Epoch: 6| Step: 5
Training loss: 2.617992639541626
Validation loss: 2.5005183553182952

Epoch: 6| Step: 6
Training loss: 2.5966057777404785
Validation loss: 2.497212899628506

Epoch: 6| Step: 7
Training loss: 2.3481335639953613
Validation loss: 2.4886211041481263

Epoch: 6| Step: 8
Training loss: 2.203584671020508
Validation loss: 2.4863597167435514

Epoch: 6| Step: 9
Training loss: 3.1835474967956543
Validation loss: 2.4798414861002276

Epoch: 6| Step: 10
Training loss: 2.538418769836426
Validation loss: 2.4823575019836426

Epoch: 6| Step: 11
Training loss: 2.996366262435913
Validation loss: 2.4807625919260006

Epoch: 6| Step: 12
Training loss: 3.091123580932617
Validation loss: 2.479305910807784

Epoch: 6| Step: 13
Training loss: 3.45717716217041
Validation loss: 2.4768133753089496

Epoch: 50| Step: 0
Training loss: 2.797145366668701
Validation loss: 2.4772622226386942

Epoch: 6| Step: 1
Training loss: 2.1533212661743164
Validation loss: 2.4801350742258053

Epoch: 6| Step: 2
Training loss: 2.6859779357910156
Validation loss: 2.477384305769397

Epoch: 6| Step: 3
Training loss: 2.3290958404541016
Validation loss: 2.482011397679647

Epoch: 6| Step: 4
Training loss: 3.1616320610046387
Validation loss: 2.479404651990501

Epoch: 6| Step: 5
Training loss: 3.0654425621032715
Validation loss: 2.488377035305064

Epoch: 6| Step: 6
Training loss: 2.4979639053344727
Validation loss: 2.4970338395846787

Epoch: 6| Step: 7
Training loss: 2.574096202850342
Validation loss: 2.5348136322472685

Epoch: 6| Step: 8
Training loss: 2.1839659214019775
Validation loss: 2.525464839832757

Epoch: 6| Step: 9
Training loss: 3.109795093536377
Validation loss: 2.4883114676321707

Epoch: 6| Step: 10
Training loss: 2.5678255558013916
Validation loss: 2.479340781447708

Epoch: 6| Step: 11
Training loss: 3.0910863876342773
Validation loss: 2.4724681531229327

Epoch: 6| Step: 12
Training loss: 3.135481119155884
Validation loss: 2.476446549097697

Epoch: 6| Step: 13
Training loss: 2.02895450592041
Validation loss: 2.4850893276993946

Epoch: 51| Step: 0
Training loss: 3.099882125854492
Validation loss: 2.4972801054677656

Epoch: 6| Step: 1
Training loss: 3.095733880996704
Validation loss: 2.5265251641632407

Epoch: 6| Step: 2
Training loss: 2.003511428833008
Validation loss: 2.6169668525777836

Epoch: 6| Step: 3
Training loss: 2.8672666549682617
Validation loss: 2.6441172374192106

Epoch: 6| Step: 4
Training loss: 3.9551358222961426
Validation loss: 2.63668482277983

Epoch: 6| Step: 5
Training loss: 3.016753673553467
Validation loss: 2.5797872594607774

Epoch: 6| Step: 6
Training loss: 2.902669668197632
Validation loss: 2.517366829738822

Epoch: 6| Step: 7
Training loss: 1.9394956827163696
Validation loss: 2.471476529234199

Epoch: 6| Step: 8
Training loss: 1.874694585800171
Validation loss: 2.469833694478517

Epoch: 6| Step: 9
Training loss: 2.132711172103882
Validation loss: 2.5084034166028424

Epoch: 6| Step: 10
Training loss: 3.1109800338745117
Validation loss: 2.5664089597681516

Epoch: 6| Step: 11
Training loss: 2.5428457260131836
Validation loss: 2.5041253054013817

Epoch: 6| Step: 12
Training loss: 2.58686900138855
Validation loss: 2.4747749554213656

Epoch: 6| Step: 13
Training loss: 3.1058716773986816
Validation loss: 2.463241538693828

Epoch: 52| Step: 0
Training loss: 2.357081413269043
Validation loss: 2.4743074806787635

Epoch: 6| Step: 1
Training loss: 2.4023823738098145
Validation loss: 2.479699029717394

Epoch: 6| Step: 2
Training loss: 2.6093807220458984
Validation loss: 2.5200588651882705

Epoch: 6| Step: 3
Training loss: 2.465475559234619
Validation loss: 2.5461942124110397

Epoch: 6| Step: 4
Training loss: 3.0169084072113037
Validation loss: 2.5623125799240603

Epoch: 6| Step: 5
Training loss: 3.0050134658813477
Validation loss: 2.5639341774807183

Epoch: 6| Step: 6
Training loss: 2.5754120349884033
Validation loss: 2.533578480443647

Epoch: 6| Step: 7
Training loss: 2.7107396125793457
Validation loss: 2.4961118800665743

Epoch: 6| Step: 8
Training loss: 3.2253851890563965
Validation loss: 2.4636156251353603

Epoch: 6| Step: 9
Training loss: 3.2314202785491943
Validation loss: 2.4604734861722557

Epoch: 6| Step: 10
Training loss: 2.523550033569336
Validation loss: 2.4675202215871503

Epoch: 6| Step: 11
Training loss: 2.3530735969543457
Validation loss: 2.472020249212942

Epoch: 6| Step: 12
Training loss: 2.4405713081359863
Validation loss: 2.4749442505580124

Epoch: 6| Step: 13
Training loss: 3.4372661113739014
Validation loss: 2.4695841548263386

Epoch: 53| Step: 0
Training loss: 2.078977108001709
Validation loss: 2.467510461807251

Epoch: 6| Step: 1
Training loss: 1.7305141687393188
Validation loss: 2.460160014449909

Epoch: 6| Step: 2
Training loss: 2.507079601287842
Validation loss: 2.4567693894909275

Epoch: 6| Step: 3
Training loss: 2.75523042678833
Validation loss: 2.454645541406447

Epoch: 6| Step: 4
Training loss: 2.6477036476135254
Validation loss: 2.454583119320613

Epoch: 6| Step: 5
Training loss: 2.2133429050445557
Validation loss: 2.45484572328547

Epoch: 6| Step: 6
Training loss: 3.1057159900665283
Validation loss: 2.4736768097005863

Epoch: 6| Step: 7
Training loss: 2.2047457695007324
Validation loss: 2.4691228123121363

Epoch: 6| Step: 8
Training loss: 3.0372304916381836
Validation loss: 2.460339541076332

Epoch: 6| Step: 9
Training loss: 2.9547390937805176
Validation loss: 2.4475730901123374

Epoch: 6| Step: 10
Training loss: 3.338043689727783
Validation loss: 2.444601769088417

Epoch: 6| Step: 11
Training loss: 3.150042772293091
Validation loss: 2.4416231391250447

Epoch: 6| Step: 12
Training loss: 3.359750509262085
Validation loss: 2.445496866779943

Epoch: 6| Step: 13
Training loss: 2.281257390975952
Validation loss: 2.445332755324661

Epoch: 54| Step: 0
Training loss: 2.895048141479492
Validation loss: 2.4454808337714082

Epoch: 6| Step: 1
Training loss: 2.5339832305908203
Validation loss: 2.4503680211241528

Epoch: 6| Step: 2
Training loss: 2.63500714302063
Validation loss: 2.447234553675498

Epoch: 6| Step: 3
Training loss: 1.1333363056182861
Validation loss: 2.4390223103184856

Epoch: 6| Step: 4
Training loss: 3.485055923461914
Validation loss: 2.432273059762934

Epoch: 6| Step: 5
Training loss: 2.5746326446533203
Validation loss: 2.4244575961943595

Epoch: 6| Step: 6
Training loss: 2.534656047821045
Validation loss: 2.4199080569769746

Epoch: 6| Step: 7
Training loss: 2.582531452178955
Validation loss: 2.4315304217800016

Epoch: 6| Step: 8
Training loss: 2.5933618545532227
Validation loss: 2.4324806210815266

Epoch: 6| Step: 9
Training loss: 3.2154505252838135
Validation loss: 2.4633058399282475

Epoch: 6| Step: 10
Training loss: 2.6026196479797363
Validation loss: 2.467577234391243

Epoch: 6| Step: 11
Training loss: 2.5937461853027344
Validation loss: 2.4660028514041694

Epoch: 6| Step: 12
Training loss: 2.7250418663024902
Validation loss: 2.4657415523323962

Epoch: 6| Step: 13
Training loss: 3.463322162628174
Validation loss: 2.4797285923393826

Epoch: 55| Step: 0
Training loss: 2.78507137298584
Validation loss: 2.4930404334939937

Epoch: 6| Step: 1
Training loss: 2.2275335788726807
Validation loss: 2.4774858361931256

Epoch: 6| Step: 2
Training loss: 1.9155373573303223
Validation loss: 2.4664436207022717

Epoch: 6| Step: 3
Training loss: 1.7713961601257324
Validation loss: 2.4443113573135866

Epoch: 6| Step: 4
Training loss: 2.7574357986450195
Validation loss: 2.427878367003574

Epoch: 6| Step: 5
Training loss: 3.9004967212677
Validation loss: 2.4281533789891068

Epoch: 6| Step: 6
Training loss: 2.711538076400757
Validation loss: 2.4163835407585226

Epoch: 6| Step: 7
Training loss: 2.0571329593658447
Validation loss: 2.4185927990944154

Epoch: 6| Step: 8
Training loss: 2.8831911087036133
Validation loss: 2.4158614937977125

Epoch: 6| Step: 9
Training loss: 2.853773355484009
Validation loss: 2.4075600383102254

Epoch: 6| Step: 10
Training loss: 1.9965027570724487
Validation loss: 2.406839668109853

Epoch: 6| Step: 11
Training loss: 3.2949771881103516
Validation loss: 2.4106110680487847

Epoch: 6| Step: 12
Training loss: 2.7300331592559814
Validation loss: 2.409853753223214

Epoch: 6| Step: 13
Training loss: 3.776129722595215
Validation loss: 2.4102270744180165

Epoch: 56| Step: 0
Training loss: 3.1069483757019043
Validation loss: 2.4102751875436432

Epoch: 6| Step: 1
Training loss: 2.172760009765625
Validation loss: 2.4083356472753708

Epoch: 6| Step: 2
Training loss: 2.3729748725891113
Validation loss: 2.41224197418459

Epoch: 6| Step: 3
Training loss: 2.4085702896118164
Validation loss: 2.411490950533139

Epoch: 6| Step: 4
Training loss: 2.809377908706665
Validation loss: 2.4110825702708256

Epoch: 6| Step: 5
Training loss: 1.9175796508789062
Validation loss: 2.409825063520862

Epoch: 6| Step: 6
Training loss: 3.2066094875335693
Validation loss: 2.411121776027064

Epoch: 6| Step: 7
Training loss: 2.484187364578247
Validation loss: 2.4109624047433176

Epoch: 6| Step: 8
Training loss: 2.8386666774749756
Validation loss: 2.406180433047715

Epoch: 6| Step: 9
Training loss: 2.0508108139038086
Validation loss: 2.410519019249947

Epoch: 6| Step: 10
Training loss: 3.5808472633361816
Validation loss: 2.409779481990363

Epoch: 6| Step: 11
Training loss: 2.275043487548828
Validation loss: 2.4102286754115934

Epoch: 6| Step: 12
Training loss: 3.0125250816345215
Validation loss: 2.40874251755335

Epoch: 6| Step: 13
Training loss: 2.9407901763916016
Validation loss: 2.418411798374627

Epoch: 57| Step: 0
Training loss: 2.8991174697875977
Validation loss: 2.4164328139315367

Epoch: 6| Step: 1
Training loss: 2.2240827083587646
Validation loss: 2.4189835799637662

Epoch: 6| Step: 2
Training loss: 2.898132085800171
Validation loss: 2.4218068661228305

Epoch: 6| Step: 3
Training loss: 3.483370542526245
Validation loss: 2.42411663968076

Epoch: 6| Step: 4
Training loss: 2.5516748428344727
Validation loss: 2.418266927042315

Epoch: 6| Step: 5
Training loss: 2.272371530532837
Validation loss: 2.430103907021143

Epoch: 6| Step: 6
Training loss: 2.3819570541381836
Validation loss: 2.431981868641351

Epoch: 6| Step: 7
Training loss: 2.9404306411743164
Validation loss: 2.419259496914443

Epoch: 6| Step: 8
Training loss: 2.2374539375305176
Validation loss: 2.4097056286309355

Epoch: 6| Step: 9
Training loss: 2.188615322113037
Validation loss: 2.401366851663077

Epoch: 6| Step: 10
Training loss: 2.5175259113311768
Validation loss: 2.397439836173929

Epoch: 6| Step: 11
Training loss: 2.8490395545959473
Validation loss: 2.395069870897519

Epoch: 6| Step: 12
Training loss: 2.9044790267944336
Validation loss: 2.4011782138578353

Epoch: 6| Step: 13
Training loss: 2.445849657058716
Validation loss: 2.400449550280007

Epoch: 58| Step: 0
Training loss: 2.3051249980926514
Validation loss: 2.39436202151801

Epoch: 6| Step: 1
Training loss: 3.0802154541015625
Validation loss: 2.4040825597701536

Epoch: 6| Step: 2
Training loss: 2.7592315673828125
Validation loss: 2.4072535922450404

Epoch: 6| Step: 3
Training loss: 2.907778024673462
Validation loss: 2.4245727318589405

Epoch: 6| Step: 4
Training loss: 2.9221134185791016
Validation loss: 2.4332365451320523

Epoch: 6| Step: 5
Training loss: 2.2344183921813965
Validation loss: 2.4491775317858626

Epoch: 6| Step: 6
Training loss: 2.7690839767456055
Validation loss: 2.444652985501033

Epoch: 6| Step: 7
Training loss: 2.993110418319702
Validation loss: 2.4630353835321244

Epoch: 6| Step: 8
Training loss: 2.4546937942504883
Validation loss: 2.46867940502782

Epoch: 6| Step: 9
Training loss: 1.8108162879943848
Validation loss: 2.4210198438295754

Epoch: 6| Step: 10
Training loss: 2.9078025817871094
Validation loss: 2.3957025876609226

Epoch: 6| Step: 11
Training loss: 2.647152900695801
Validation loss: 2.390427617616551

Epoch: 6| Step: 12
Training loss: 2.3781909942626953
Validation loss: 2.398536359110186

Epoch: 6| Step: 13
Training loss: 3.116727113723755
Validation loss: 2.431114340341219

Epoch: 59| Step: 0
Training loss: 2.8003244400024414
Validation loss: 2.4636995100205943

Epoch: 6| Step: 1
Training loss: 3.162851572036743
Validation loss: 2.490765287030128

Epoch: 6| Step: 2
Training loss: 3.255676746368408
Validation loss: 2.512537851128527

Epoch: 6| Step: 3
Training loss: 2.223524332046509
Validation loss: 2.5101045588011384

Epoch: 6| Step: 4
Training loss: 2.6049644947052
Validation loss: 2.499084395747031

Epoch: 6| Step: 5
Training loss: 2.3028714656829834
Validation loss: 2.4931465887254283

Epoch: 6| Step: 6
Training loss: 2.625782012939453
Validation loss: 2.4920776197987218

Epoch: 6| Step: 7
Training loss: 2.055443048477173
Validation loss: 2.4826083978017173

Epoch: 6| Step: 8
Training loss: 2.9587185382843018
Validation loss: 2.4666866102526264

Epoch: 6| Step: 9
Training loss: 2.7455358505249023
Validation loss: 2.456024410904095

Epoch: 6| Step: 10
Training loss: 2.6132733821868896
Validation loss: 2.439826362876482

Epoch: 6| Step: 11
Training loss: 3.0084991455078125
Validation loss: 2.4145130649689706

Epoch: 6| Step: 12
Training loss: 2.2683887481689453
Validation loss: 2.389368834034089

Epoch: 6| Step: 13
Training loss: 3.225722074508667
Validation loss: 2.4328770073511268

Epoch: 60| Step: 0
Training loss: 2.893726348876953
Validation loss: 2.50709371412954

Epoch: 6| Step: 1
Training loss: 2.978476047515869
Validation loss: 2.5718650843507502

Epoch: 6| Step: 2
Training loss: 2.9737374782562256
Validation loss: 2.595668092850716

Epoch: 6| Step: 3
Training loss: 3.025904655456543
Validation loss: 2.521187492596206

Epoch: 6| Step: 4
Training loss: 2.6925907135009766
Validation loss: 2.477766890679636

Epoch: 6| Step: 5
Training loss: 2.6910433769226074
Validation loss: 2.439453427509595

Epoch: 6| Step: 6
Training loss: 1.7116892337799072
Validation loss: 2.406397663136964

Epoch: 6| Step: 7
Training loss: 2.4364821910858154
Validation loss: 2.3986554812359553

Epoch: 6| Step: 8
Training loss: 2.158965587615967
Validation loss: 2.3968789628756944

Epoch: 6| Step: 9
Training loss: 2.3889122009277344
Validation loss: 2.4229836438291814

Epoch: 6| Step: 10
Training loss: 3.044538736343384
Validation loss: 2.468150446491857

Epoch: 6| Step: 11
Training loss: 2.935448169708252
Validation loss: 2.4451232200027793

Epoch: 6| Step: 12
Training loss: 3.09546160697937
Validation loss: 2.429451049015086

Epoch: 6| Step: 13
Training loss: 2.4855458736419678
Validation loss: 2.4265826568808606

Epoch: 61| Step: 0
Training loss: 1.8026779890060425
Validation loss: 2.397767625829225

Epoch: 6| Step: 1
Training loss: 2.843353509902954
Validation loss: 2.390368115517401

Epoch: 6| Step: 2
Training loss: 1.7704353332519531
Validation loss: 2.381601564345821

Epoch: 6| Step: 3
Training loss: 2.5849509239196777
Validation loss: 2.3972508343317176

Epoch: 6| Step: 4
Training loss: 2.942394256591797
Validation loss: 2.41312817347947

Epoch: 6| Step: 5
Training loss: 3.391327142715454
Validation loss: 2.462777458211427

Epoch: 6| Step: 6
Training loss: 2.034313440322876
Validation loss: 2.487191912948444

Epoch: 6| Step: 7
Training loss: 2.7138466835021973
Validation loss: 2.5076730635858353

Epoch: 6| Step: 8
Training loss: 2.9684486389160156
Validation loss: 2.5169086174298356

Epoch: 6| Step: 9
Training loss: 3.1130261421203613
Validation loss: 2.5357213609962055

Epoch: 6| Step: 10
Training loss: 2.3706912994384766
Validation loss: 2.531846559175881

Epoch: 6| Step: 11
Training loss: 3.1104817390441895
Validation loss: 2.477088128366778

Epoch: 6| Step: 12
Training loss: 2.5116822719573975
Validation loss: 2.4446830493147655

Epoch: 6| Step: 13
Training loss: 3.210237741470337
Validation loss: 2.41917089749408

Epoch: 62| Step: 0
Training loss: 2.6019036769866943
Validation loss: 2.400451898574829

Epoch: 6| Step: 1
Training loss: 2.9265377521514893
Validation loss: 2.3861543132412817

Epoch: 6| Step: 2
Training loss: 3.46128511428833
Validation loss: 2.3944709275358464

Epoch: 6| Step: 3
Training loss: 3.2542529106140137
Validation loss: 2.4105341178114696

Epoch: 6| Step: 4
Training loss: 2.016890525817871
Validation loss: 2.4387753868615754

Epoch: 6| Step: 5
Training loss: 2.6125190258026123
Validation loss: 2.469319194875738

Epoch: 6| Step: 6
Training loss: 2.5986855030059814
Validation loss: 2.4751831164924045

Epoch: 6| Step: 7
Training loss: 2.4173097610473633
Validation loss: 2.476975012851018

Epoch: 6| Step: 8
Training loss: 2.383714199066162
Validation loss: 2.4501257788750435

Epoch: 6| Step: 9
Training loss: 2.3738632202148438
Validation loss: 2.414379442891767

Epoch: 6| Step: 10
Training loss: 3.263035297393799
Validation loss: 2.404308456246571

Epoch: 6| Step: 11
Training loss: 2.4120070934295654
Validation loss: 2.3914756544174685

Epoch: 6| Step: 12
Training loss: 2.25700044631958
Validation loss: 2.3739479177741596

Epoch: 6| Step: 13
Training loss: 2.9927213191986084
Validation loss: 2.363209867990145

Epoch: 63| Step: 0
Training loss: 2.343903064727783
Validation loss: 2.3618266556852605

Epoch: 6| Step: 1
Training loss: 2.2549779415130615
Validation loss: 2.3877953867758475

Epoch: 6| Step: 2
Training loss: 1.661123275756836
Validation loss: 2.4067888054796445

Epoch: 6| Step: 3
Training loss: 2.9969615936279297
Validation loss: 2.3981086912975518

Epoch: 6| Step: 4
Training loss: 2.467437505722046
Validation loss: 2.3833381514395438

Epoch: 6| Step: 5
Training loss: 2.3295772075653076
Validation loss: 2.393930294180429

Epoch: 6| Step: 6
Training loss: 2.80228853225708
Validation loss: 2.3905623010409776

Epoch: 6| Step: 7
Training loss: 2.8054137229919434
Validation loss: 2.3851339765774306

Epoch: 6| Step: 8
Training loss: 2.198552131652832
Validation loss: 2.389632999256093

Epoch: 6| Step: 9
Training loss: 3.3904550075531006
Validation loss: 2.4161594324214484

Epoch: 6| Step: 10
Training loss: 3.045839786529541
Validation loss: 2.3914019369309947

Epoch: 6| Step: 11
Training loss: 2.388439178466797
Validation loss: 2.3639459456166914

Epoch: 6| Step: 12
Training loss: 3.3318233489990234
Validation loss: 2.356820862780335

Epoch: 6| Step: 13
Training loss: 2.7725822925567627
Validation loss: 2.3449177818913616

Epoch: 64| Step: 0
Training loss: 3.233586311340332
Validation loss: 2.35174346739246

Epoch: 6| Step: 1
Training loss: 2.1569032669067383
Validation loss: 2.3590407576612247

Epoch: 6| Step: 2
Training loss: 3.0156002044677734
Validation loss: 2.3543429297785603

Epoch: 6| Step: 3
Training loss: 2.495795249938965
Validation loss: 2.3702843086693877

Epoch: 6| Step: 4
Training loss: 2.170868396759033
Validation loss: 2.3596076247512654

Epoch: 6| Step: 5
Training loss: 2.5633113384246826
Validation loss: 2.3542667947789675

Epoch: 6| Step: 6
Training loss: 2.619843006134033
Validation loss: 2.3492380880540416

Epoch: 6| Step: 7
Training loss: 2.502703905105591
Validation loss: 2.347966727390084

Epoch: 6| Step: 8
Training loss: 2.4939560890197754
Validation loss: 2.3537285840639504

Epoch: 6| Step: 9
Training loss: 2.7130565643310547
Validation loss: 2.3516868109344156

Epoch: 6| Step: 10
Training loss: 2.692450523376465
Validation loss: 2.362355391184489

Epoch: 6| Step: 11
Training loss: 2.6086373329162598
Validation loss: 2.376315652683217

Epoch: 6| Step: 12
Training loss: 2.7331109046936035
Validation loss: 2.3883572906576176

Epoch: 6| Step: 13
Training loss: 3.071880340576172
Validation loss: 2.4092273148157264

Epoch: 65| Step: 0
Training loss: 2.31742525100708
Validation loss: 2.4020235653846496

Epoch: 6| Step: 1
Training loss: 2.44911527633667
Validation loss: 2.389406528524173

Epoch: 6| Step: 2
Training loss: 3.2605953216552734
Validation loss: 2.3841088792329193

Epoch: 6| Step: 3
Training loss: 2.6359057426452637
Validation loss: 2.400506632302397

Epoch: 6| Step: 4
Training loss: 2.7741928100585938
Validation loss: 2.4071848213031726

Epoch: 6| Step: 5
Training loss: 2.438436508178711
Validation loss: 2.3876393533522084

Epoch: 6| Step: 6
Training loss: 2.8945722579956055
Validation loss: 2.3621263439937303

Epoch: 6| Step: 7
Training loss: 2.124969482421875
Validation loss: 2.3481357379626204

Epoch: 6| Step: 8
Training loss: 2.8487720489501953
Validation loss: 2.3420838950782694

Epoch: 6| Step: 9
Training loss: 1.8771185874938965
Validation loss: 2.3399811073016097

Epoch: 6| Step: 10
Training loss: 3.267766237258911
Validation loss: 2.339289170439525

Epoch: 6| Step: 11
Training loss: 2.453886032104492
Validation loss: 2.337734935104206

Epoch: 6| Step: 12
Training loss: 2.521165370941162
Validation loss: 2.3480868160083728

Epoch: 6| Step: 13
Training loss: 2.784010171890259
Validation loss: 2.354756403994817

Epoch: 66| Step: 0
Training loss: 2.6436116695404053
Validation loss: 2.373288805766772

Epoch: 6| Step: 1
Training loss: 2.879851818084717
Validation loss: 2.3947108432810795

Epoch: 6| Step: 2
Training loss: 2.354050397872925
Validation loss: 2.4443341044969458

Epoch: 6| Step: 3
Training loss: 3.123924970626831
Validation loss: 2.3966960189163045

Epoch: 6| Step: 4
Training loss: 2.6637401580810547
Validation loss: 2.3768037134601223

Epoch: 6| Step: 5
Training loss: 2.3258004188537598
Validation loss: 2.3616502490094913

Epoch: 6| Step: 6
Training loss: 2.6425836086273193
Validation loss: 2.3585732393367316

Epoch: 6| Step: 7
Training loss: 1.8596265316009521
Validation loss: 2.351918658902568

Epoch: 6| Step: 8
Training loss: 2.882550001144409
Validation loss: 2.344735391678349

Epoch: 6| Step: 9
Training loss: 3.0136349201202393
Validation loss: 2.341956707739061

Epoch: 6| Step: 10
Training loss: 2.6782379150390625
Validation loss: 2.3483105449266333

Epoch: 6| Step: 11
Training loss: 1.8575375080108643
Validation loss: 2.350159465625722

Epoch: 6| Step: 12
Training loss: 2.2676944732666016
Validation loss: 2.3590334871763825

Epoch: 6| Step: 13
Training loss: 3.788088798522949
Validation loss: 2.365291646731797

Epoch: 67| Step: 0
Training loss: 2.8570494651794434
Validation loss: 2.3654653500485163

Epoch: 6| Step: 1
Training loss: 2.1366994380950928
Validation loss: 2.37152365715273

Epoch: 6| Step: 2
Training loss: 2.668294906616211
Validation loss: 2.3777513760392384

Epoch: 6| Step: 3
Training loss: 3.114664077758789
Validation loss: 2.389555618327151

Epoch: 6| Step: 4
Training loss: 2.2566704750061035
Validation loss: 2.364399404935939

Epoch: 6| Step: 5
Training loss: 2.5197463035583496
Validation loss: 2.363657657818128

Epoch: 6| Step: 6
Training loss: 2.5757246017456055
Validation loss: 2.348912618493521

Epoch: 6| Step: 7
Training loss: 2.3965930938720703
Validation loss: 2.3464839484101985

Epoch: 6| Step: 8
Training loss: 2.511119842529297
Validation loss: 2.3397955458651305

Epoch: 6| Step: 9
Training loss: 2.198777437210083
Validation loss: 2.337213570071805

Epoch: 6| Step: 10
Training loss: 3.5084517002105713
Validation loss: 2.341788822604764

Epoch: 6| Step: 11
Training loss: 2.703369140625
Validation loss: 2.34726470516574

Epoch: 6| Step: 12
Training loss: 2.4396777153015137
Validation loss: 2.3546711116708736

Epoch: 6| Step: 13
Training loss: 2.575429677963257
Validation loss: 2.354690700448969

Epoch: 68| Step: 0
Training loss: 2.5978403091430664
Validation loss: 2.3541752753719205

Epoch: 6| Step: 1
Training loss: 2.773543357849121
Validation loss: 2.3568367342795096

Epoch: 6| Step: 2
Training loss: 3.1669046878814697
Validation loss: 2.369250561601372

Epoch: 6| Step: 3
Training loss: 1.86641263961792
Validation loss: 2.382847488567393

Epoch: 6| Step: 4
Training loss: 2.593895673751831
Validation loss: 2.3927447693322295

Epoch: 6| Step: 5
Training loss: 2.0730056762695312
Validation loss: 2.3876348567265335

Epoch: 6| Step: 6
Training loss: 2.6421756744384766
Validation loss: 2.388306070399541

Epoch: 6| Step: 7
Training loss: 2.865367889404297
Validation loss: 2.3778839713783673

Epoch: 6| Step: 8
Training loss: 2.5471742153167725
Validation loss: 2.362453132547358

Epoch: 6| Step: 9
Training loss: 2.7713255882263184
Validation loss: 2.3657386046583935

Epoch: 6| Step: 10
Training loss: 2.6854519844055176
Validation loss: 2.3542111381407707

Epoch: 6| Step: 11
Training loss: 2.0616586208343506
Validation loss: 2.351127004110685

Epoch: 6| Step: 12
Training loss: 3.2395191192626953
Validation loss: 2.3779044330761

Epoch: 6| Step: 13
Training loss: 2.6038548946380615
Validation loss: 2.3600609635794036

Epoch: 69| Step: 0
Training loss: 2.418403148651123
Validation loss: 2.349235875632173

Epoch: 6| Step: 1
Training loss: 2.2058820724487305
Validation loss: 2.3640927294249177

Epoch: 6| Step: 2
Training loss: 3.2864794731140137
Validation loss: 2.3725043983869654

Epoch: 6| Step: 3
Training loss: 2.1819748878479004
Validation loss: 2.3809549731592976

Epoch: 6| Step: 4
Training loss: 3.254927635192871
Validation loss: 2.381238822014101

Epoch: 6| Step: 5
Training loss: 2.686920166015625
Validation loss: 2.399129239461755

Epoch: 6| Step: 6
Training loss: 2.2426581382751465
Validation loss: 2.427598717392132

Epoch: 6| Step: 7
Training loss: 2.4665608406066895
Validation loss: 2.427199555981544

Epoch: 6| Step: 8
Training loss: 2.147174596786499
Validation loss: 2.4175064691933255

Epoch: 6| Step: 9
Training loss: 2.6849465370178223
Validation loss: 2.4147601255806546

Epoch: 6| Step: 10
Training loss: 3.006542205810547
Validation loss: 2.3968971570332847

Epoch: 6| Step: 11
Training loss: 2.460728883743286
Validation loss: 2.3800498362510436

Epoch: 6| Step: 12
Training loss: 3.287295341491699
Validation loss: 2.3815123163243777

Epoch: 6| Step: 13
Training loss: 2.1968352794647217
Validation loss: 2.390372904398108

Epoch: 70| Step: 0
Training loss: 2.1516811847686768
Validation loss: 2.4391071334961922

Epoch: 6| Step: 1
Training loss: 2.447749614715576
Validation loss: 2.4871553092874508

Epoch: 6| Step: 2
Training loss: 2.8762125968933105
Validation loss: 2.518036416781846

Epoch: 6| Step: 3
Training loss: 2.9445834159851074
Validation loss: 2.5422887212486676

Epoch: 6| Step: 4
Training loss: 2.5486879348754883
Validation loss: 2.5125923848921254

Epoch: 6| Step: 5
Training loss: 2.7797250747680664
Validation loss: 2.4747077470184653

Epoch: 6| Step: 6
Training loss: 3.2531471252441406
Validation loss: 2.4525562101794827

Epoch: 6| Step: 7
Training loss: 2.3578028678894043
Validation loss: 2.4235453528742634

Epoch: 6| Step: 8
Training loss: 2.8403215408325195
Validation loss: 2.420251402803647

Epoch: 6| Step: 9
Training loss: 2.7880821228027344
Validation loss: 2.399108717518468

Epoch: 6| Step: 10
Training loss: 2.661689043045044
Validation loss: 2.33916478003225

Epoch: 6| Step: 11
Training loss: 2.104416847229004
Validation loss: 2.3418865460221485

Epoch: 6| Step: 12
Training loss: 2.636920690536499
Validation loss: 2.338082044355331

Epoch: 6| Step: 13
Training loss: 2.308243751525879
Validation loss: 2.3347029378337245

Epoch: 71| Step: 0
Training loss: 2.108463764190674
Validation loss: 2.3331138574948875

Epoch: 6| Step: 1
Training loss: 2.544684648513794
Validation loss: 2.32612039965968

Epoch: 6| Step: 2
Training loss: 2.234828472137451
Validation loss: 2.3280748321164038

Epoch: 6| Step: 3
Training loss: 2.427811622619629
Validation loss: 2.3317959693170365

Epoch: 6| Step: 4
Training loss: 2.7017836570739746
Validation loss: 2.334447260825865

Epoch: 6| Step: 5
Training loss: 2.5102109909057617
Validation loss: 2.3353935723663657

Epoch: 6| Step: 6
Training loss: 2.351365089416504
Validation loss: 2.326883485240321

Epoch: 6| Step: 7
Training loss: 3.0469422340393066
Validation loss: 2.3250744496622393

Epoch: 6| Step: 8
Training loss: 3.517475128173828
Validation loss: 2.3205110180762505

Epoch: 6| Step: 9
Training loss: 3.4053702354431152
Validation loss: 2.3274635345705095

Epoch: 6| Step: 10
Training loss: 2.1819324493408203
Validation loss: 2.347672424008769

Epoch: 6| Step: 11
Training loss: 2.4238505363464355
Validation loss: 2.3707217926620157

Epoch: 6| Step: 12
Training loss: 2.572948455810547
Validation loss: 2.3729627504143664

Epoch: 6| Step: 13
Training loss: 2.389540433883667
Validation loss: 2.3755964771393807

Epoch: 72| Step: 0
Training loss: 3.1015524864196777
Validation loss: 2.3658020509186612

Epoch: 6| Step: 1
Training loss: 2.611633539199829
Validation loss: 2.333953701039796

Epoch: 6| Step: 2
Training loss: 2.2032270431518555
Validation loss: 2.31334940848812

Epoch: 6| Step: 3
Training loss: 2.5429539680480957
Validation loss: 2.3122198350967897

Epoch: 6| Step: 4
Training loss: 3.1310415267944336
Validation loss: 2.2975967020116825

Epoch: 6| Step: 5
Training loss: 2.1504273414611816
Validation loss: 2.2944844691984114

Epoch: 6| Step: 6
Training loss: 1.5649909973144531
Validation loss: 2.2966302248739425

Epoch: 6| Step: 7
Training loss: 2.9638848304748535
Validation loss: 2.2969316397943804

Epoch: 6| Step: 8
Training loss: 2.891940116882324
Validation loss: 2.299871165265319

Epoch: 6| Step: 9
Training loss: 3.2879300117492676
Validation loss: 2.297412969732797

Epoch: 6| Step: 10
Training loss: 2.580357551574707
Validation loss: 2.3011369064290035

Epoch: 6| Step: 11
Training loss: 2.1039721965789795
Validation loss: 2.2979108697624615

Epoch: 6| Step: 12
Training loss: 2.506537914276123
Validation loss: 2.2912848969941497

Epoch: 6| Step: 13
Training loss: 2.5242996215820312
Validation loss: 2.2982745785867014

Epoch: 73| Step: 0
Training loss: 2.5276246070861816
Validation loss: 2.3238596659834667

Epoch: 6| Step: 1
Training loss: 2.7509946823120117
Validation loss: 2.356275063689037

Epoch: 6| Step: 2
Training loss: 1.9798794984817505
Validation loss: 2.4009437535398748

Epoch: 6| Step: 3
Training loss: 2.205435276031494
Validation loss: 2.4128963511477233

Epoch: 6| Step: 4
Training loss: 3.1244401931762695
Validation loss: 2.3782899866821947

Epoch: 6| Step: 5
Training loss: 2.9391212463378906
Validation loss: 2.378314595068655

Epoch: 6| Step: 6
Training loss: 2.3674964904785156
Validation loss: 2.38229287311595

Epoch: 6| Step: 7
Training loss: 2.258185625076294
Validation loss: 2.3905921623271

Epoch: 6| Step: 8
Training loss: 2.7715325355529785
Validation loss: 2.4163894063682965

Epoch: 6| Step: 9
Training loss: 3.626551866531372
Validation loss: 2.4399543577624905

Epoch: 6| Step: 10
Training loss: 2.1563796997070312
Validation loss: 2.4170465084814254

Epoch: 6| Step: 11
Training loss: 2.3192477226257324
Validation loss: 2.357794448893557

Epoch: 6| Step: 12
Training loss: 2.7338452339172363
Validation loss: 2.3272770656052457

Epoch: 6| Step: 13
Training loss: 2.5212104320526123
Validation loss: 2.2963959888745378

Epoch: 74| Step: 0
Training loss: 2.847029209136963
Validation loss: 2.295362857080275

Epoch: 6| Step: 1
Training loss: 2.8294334411621094
Validation loss: 2.278781944705594

Epoch: 6| Step: 2
Training loss: 2.706279754638672
Validation loss: 2.2852040926615396

Epoch: 6| Step: 3
Training loss: 2.306016683578491
Validation loss: 2.2879165577632126

Epoch: 6| Step: 4
Training loss: 2.7101805210113525
Validation loss: 2.2942059142615205

Epoch: 6| Step: 5
Training loss: 2.954618453979492
Validation loss: 2.296676407578171

Epoch: 6| Step: 6
Training loss: 2.677300453186035
Validation loss: 2.300349235534668

Epoch: 6| Step: 7
Training loss: 2.510244607925415
Validation loss: 2.305884890658881

Epoch: 6| Step: 8
Training loss: 1.77720308303833
Validation loss: 2.3097673539192445

Epoch: 6| Step: 9
Training loss: 2.2405433654785156
Validation loss: 2.3006223273533646

Epoch: 6| Step: 10
Training loss: 2.5620241165161133
Validation loss: 2.2929046589841127

Epoch: 6| Step: 11
Training loss: 2.9029006958007812
Validation loss: 2.3058220263450377

Epoch: 6| Step: 12
Training loss: 2.7250819206237793
Validation loss: 2.325249307899065

Epoch: 6| Step: 13
Training loss: 2.5191824436187744
Validation loss: 2.3318096258307017

Epoch: 75| Step: 0
Training loss: 2.8251028060913086
Validation loss: 2.3519139315492366

Epoch: 6| Step: 1
Training loss: 3.0074079036712646
Validation loss: 2.3594029411192863

Epoch: 6| Step: 2
Training loss: 2.015573501586914
Validation loss: 2.321256786264399

Epoch: 6| Step: 3
Training loss: 2.6380200386047363
Validation loss: 2.340413083312332

Epoch: 6| Step: 4
Training loss: 1.6363837718963623
Validation loss: 2.3338983904930855

Epoch: 6| Step: 5
Training loss: 2.5020253658294678
Validation loss: 2.354297158538654

Epoch: 6| Step: 6
Training loss: 3.2162528038024902
Validation loss: 2.365516169096834

Epoch: 6| Step: 7
Training loss: 2.181839942932129
Validation loss: 2.36539432566653

Epoch: 6| Step: 8
Training loss: 2.6243486404418945
Validation loss: 2.3402159444747435

Epoch: 6| Step: 9
Training loss: 2.2800705432891846
Validation loss: 2.3228866900167158

Epoch: 6| Step: 10
Training loss: 2.202324628829956
Validation loss: 2.3079123215008805

Epoch: 6| Step: 11
Training loss: 3.077287435531616
Validation loss: 2.295812528620484

Epoch: 6| Step: 12
Training loss: 2.97245454788208
Validation loss: 2.2871947737150293

Epoch: 6| Step: 13
Training loss: 3.036318778991699
Validation loss: 2.276892669739262

Epoch: 76| Step: 0
Training loss: 3.1679904460906982
Validation loss: 2.2745751514229724

Epoch: 6| Step: 1
Training loss: 2.4078269004821777
Validation loss: 2.2716285541493404

Epoch: 6| Step: 2
Training loss: 2.6025896072387695
Validation loss: 2.269894210241174

Epoch: 6| Step: 3
Training loss: 3.166633129119873
Validation loss: 2.268405722033593

Epoch: 6| Step: 4
Training loss: 2.332447052001953
Validation loss: 2.2654268818516887

Epoch: 6| Step: 5
Training loss: 2.9582595825195312
Validation loss: 2.271883579992479

Epoch: 6| Step: 6
Training loss: 2.5122978687286377
Validation loss: 2.2674049895296813

Epoch: 6| Step: 7
Training loss: 2.375916004180908
Validation loss: 2.269996025229013

Epoch: 6| Step: 8
Training loss: 2.550905704498291
Validation loss: 2.271492153085688

Epoch: 6| Step: 9
Training loss: 2.6138014793395996
Validation loss: 2.2628839631234445

Epoch: 6| Step: 10
Training loss: 2.225972890853882
Validation loss: 2.2656143198731127

Epoch: 6| Step: 11
Training loss: 2.1627678871154785
Validation loss: 2.26856404735196

Epoch: 6| Step: 12
Training loss: 2.090355634689331
Validation loss: 2.2734874320286576

Epoch: 6| Step: 13
Training loss: 3.0004472732543945
Validation loss: 2.292875902627104

Epoch: 77| Step: 0
Training loss: 2.6975717544555664
Validation loss: 2.2838131637983423

Epoch: 6| Step: 1
Training loss: 2.3430099487304688
Validation loss: 2.2767997608389905

Epoch: 6| Step: 2
Training loss: 2.765629529953003
Validation loss: 2.2609716743551274

Epoch: 6| Step: 3
Training loss: 2.5663528442382812
Validation loss: 2.2618275457812893

Epoch: 6| Step: 4
Training loss: 2.2730817794799805
Validation loss: 2.2579066625205417

Epoch: 6| Step: 5
Training loss: 2.6199307441711426
Validation loss: 2.2574597366394533

Epoch: 6| Step: 6
Training loss: 3.114494800567627
Validation loss: 2.256647562467924

Epoch: 6| Step: 7
Training loss: 1.534193515777588
Validation loss: 2.256819427654307

Epoch: 6| Step: 8
Training loss: 1.9536120891571045
Validation loss: 2.26142781524248

Epoch: 6| Step: 9
Training loss: 2.4747209548950195
Validation loss: 2.267546166655838

Epoch: 6| Step: 10
Training loss: 2.5066699981689453
Validation loss: 2.2641431593125865

Epoch: 6| Step: 11
Training loss: 2.9556779861450195
Validation loss: 2.2725288996132473

Epoch: 6| Step: 12
Training loss: 2.967261552810669
Validation loss: 2.268323931642758

Epoch: 6| Step: 13
Training loss: 3.4204485416412354
Validation loss: 2.2701163945659513

Epoch: 78| Step: 0
Training loss: 2.037907838821411
Validation loss: 2.283274307045885

Epoch: 6| Step: 1
Training loss: 2.409177780151367
Validation loss: 2.322184124300557

Epoch: 6| Step: 2
Training loss: 2.614896059036255
Validation loss: 2.406846305375458

Epoch: 6| Step: 3
Training loss: 3.1153550148010254
Validation loss: 2.4369460100768716

Epoch: 6| Step: 4
Training loss: 1.8138978481292725
Validation loss: 2.3869564174323954

Epoch: 6| Step: 5
Training loss: 2.217815399169922
Validation loss: 2.3004700663269206

Epoch: 6| Step: 6
Training loss: 2.9254262447357178
Validation loss: 2.260104194764168

Epoch: 6| Step: 7
Training loss: 2.869755268096924
Validation loss: 2.2503234519753406

Epoch: 6| Step: 8
Training loss: 3.2125182151794434
Validation loss: 2.2569889996641423

Epoch: 6| Step: 9
Training loss: 2.8319764137268066
Validation loss: 2.273168820206837

Epoch: 6| Step: 10
Training loss: 2.2014079093933105
Validation loss: 2.2874950029516734

Epoch: 6| Step: 11
Training loss: 2.771684408187866
Validation loss: 2.313257941635706

Epoch: 6| Step: 12
Training loss: 3.1177711486816406
Validation loss: 2.3187243297535884

Epoch: 6| Step: 13
Training loss: 1.9788464307785034
Validation loss: 2.2937999797123734

Epoch: 79| Step: 0
Training loss: 2.871861696243286
Validation loss: 2.28741438927189

Epoch: 6| Step: 1
Training loss: 1.8515681028366089
Validation loss: 2.2736627747935634

Epoch: 6| Step: 2
Training loss: 2.6910433769226074
Validation loss: 2.271503640759376

Epoch: 6| Step: 3
Training loss: 2.133805990219116
Validation loss: 2.270541324410387

Epoch: 6| Step: 4
Training loss: 3.093494415283203
Validation loss: 2.2570795730877946

Epoch: 6| Step: 5
Training loss: 2.1185050010681152
Validation loss: 2.25194913084789

Epoch: 6| Step: 6
Training loss: 2.3530170917510986
Validation loss: 2.2467375083636214

Epoch: 6| Step: 7
Training loss: 2.915494441986084
Validation loss: 2.2449442161026822

Epoch: 6| Step: 8
Training loss: 2.3528571128845215
Validation loss: 2.259376125950967

Epoch: 6| Step: 9
Training loss: 2.539379596710205
Validation loss: 2.2834576624695972

Epoch: 6| Step: 10
Training loss: 2.723412036895752
Validation loss: 2.294599651008524

Epoch: 6| Step: 11
Training loss: 3.444120407104492
Validation loss: 2.3336971575214016

Epoch: 6| Step: 12
Training loss: 2.7294297218322754
Validation loss: 2.3740288288362565

Epoch: 6| Step: 13
Training loss: 1.6470038890838623
Validation loss: 2.3544085730788527

Epoch: 80| Step: 0
Training loss: 2.488103151321411
Validation loss: 2.3047715181945474

Epoch: 6| Step: 1
Training loss: 2.2874581813812256
Validation loss: 2.291605208509712

Epoch: 6| Step: 2
Training loss: 2.0175564289093018
Validation loss: 2.282004997294436

Epoch: 6| Step: 3
Training loss: 2.727048873901367
Validation loss: 2.269188545083487

Epoch: 6| Step: 4
Training loss: 3.475412607192993
Validation loss: 2.2622053738563292

Epoch: 6| Step: 5
Training loss: 1.9465038776397705
Validation loss: 2.2529402214993715

Epoch: 6| Step: 6
Training loss: 2.799764633178711
Validation loss: 2.2583253857909993

Epoch: 6| Step: 7
Training loss: 2.159693717956543
Validation loss: 2.2530859003784838

Epoch: 6| Step: 8
Training loss: 2.560365915298462
Validation loss: 2.260299259616483

Epoch: 6| Step: 9
Training loss: 2.1760780811309814
Validation loss: 2.2644750520747197

Epoch: 6| Step: 10
Training loss: 2.8986382484436035
Validation loss: 2.279139349537511

Epoch: 6| Step: 11
Training loss: 3.1175546646118164
Validation loss: 2.270119228670674

Epoch: 6| Step: 12
Training loss: 2.16363525390625
Validation loss: 2.295698501730478

Epoch: 6| Step: 13
Training loss: 2.9070489406585693
Validation loss: 2.2977123209225234

Epoch: 81| Step: 0
Training loss: 3.423380136489868
Validation loss: 2.3079582901411158

Epoch: 6| Step: 1
Training loss: 2.1617722511291504
Validation loss: 2.2902617146891933

Epoch: 6| Step: 2
Training loss: 2.6100854873657227
Validation loss: 2.2737730574864212

Epoch: 6| Step: 3
Training loss: 2.3342785835266113
Validation loss: 2.2589410915169665

Epoch: 6| Step: 4
Training loss: 2.4253034591674805
Validation loss: 2.249233176631312

Epoch: 6| Step: 5
Training loss: 2.3075687885284424
Validation loss: 2.248263592361122

Epoch: 6| Step: 6
Training loss: 2.760289192199707
Validation loss: 2.24759848912557

Epoch: 6| Step: 7
Training loss: 2.3348708152770996
Validation loss: 2.246763793371057

Epoch: 6| Step: 8
Training loss: 1.8304578065872192
Validation loss: 2.2496865077685286

Epoch: 6| Step: 9
Training loss: 3.29160737991333
Validation loss: 2.258232024408156

Epoch: 6| Step: 10
Training loss: 1.9905930757522583
Validation loss: 2.2623083719643216

Epoch: 6| Step: 11
Training loss: 2.8168792724609375
Validation loss: 2.2710531873087727

Epoch: 6| Step: 12
Training loss: 2.7125232219696045
Validation loss: 2.2777077638974754

Epoch: 6| Step: 13
Training loss: 2.9284465312957764
Validation loss: 2.294297372141192

Epoch: 82| Step: 0
Training loss: 2.8531885147094727
Validation loss: 2.2884931718149493

Epoch: 6| Step: 1
Training loss: 3.2090625762939453
Validation loss: 2.282994111378988

Epoch: 6| Step: 2
Training loss: 1.833275318145752
Validation loss: 2.2701058336483535

Epoch: 6| Step: 3
Training loss: 2.656686782836914
Validation loss: 2.268088545850528

Epoch: 6| Step: 4
Training loss: 2.4751710891723633
Validation loss: 2.263608532567178

Epoch: 6| Step: 5
Training loss: 3.3498966693878174
Validation loss: 2.2638516502995647

Epoch: 6| Step: 6
Training loss: 2.3729898929595947
Validation loss: 2.2730460295113186

Epoch: 6| Step: 7
Training loss: 2.190471649169922
Validation loss: 2.272542712508991

Epoch: 6| Step: 8
Training loss: 2.4929513931274414
Validation loss: 2.275322134776782

Epoch: 6| Step: 9
Training loss: 1.88986337184906
Validation loss: 2.2877119330949682

Epoch: 6| Step: 10
Training loss: 2.695840358734131
Validation loss: 2.2753827956414994

Epoch: 6| Step: 11
Training loss: 2.690186023712158
Validation loss: 2.259835881571616

Epoch: 6| Step: 12
Training loss: 2.538679361343384
Validation loss: 2.263540934490901

Epoch: 6| Step: 13
Training loss: 1.9177987575531006
Validation loss: 2.2471605885413384

Epoch: 83| Step: 0
Training loss: 2.4946441650390625
Validation loss: 2.248426410459703

Epoch: 6| Step: 1
Training loss: 2.492387056350708
Validation loss: 2.247163854619508

Epoch: 6| Step: 2
Training loss: 3.26550030708313
Validation loss: 2.240488783005745

Epoch: 6| Step: 3
Training loss: 1.9481184482574463
Validation loss: 2.2426613505168627

Epoch: 6| Step: 4
Training loss: 2.2197437286376953
Validation loss: 2.230968681714868

Epoch: 6| Step: 5
Training loss: 2.450615406036377
Validation loss: 2.22819278060749

Epoch: 6| Step: 6
Training loss: 2.7605113983154297
Validation loss: 2.224066183131228

Epoch: 6| Step: 7
Training loss: 2.764101266860962
Validation loss: 2.241453778359198

Epoch: 6| Step: 8
Training loss: 2.482184886932373
Validation loss: 2.2471953848356843

Epoch: 6| Step: 9
Training loss: 2.5545461177825928
Validation loss: 2.2632174132972636

Epoch: 6| Step: 10
Training loss: 2.5202386379241943
Validation loss: 2.264449986078406

Epoch: 6| Step: 11
Training loss: 2.731017589569092
Validation loss: 2.2603707339174006

Epoch: 6| Step: 12
Training loss: 2.1528072357177734
Validation loss: 2.2550340403792677

Epoch: 6| Step: 13
Training loss: 2.6524624824523926
Validation loss: 2.2616447043675247

Epoch: 84| Step: 0
Training loss: 2.7790660858154297
Validation loss: 2.256596529355613

Epoch: 6| Step: 1
Training loss: 2.2058253288269043
Validation loss: 2.2520067396984307

Epoch: 6| Step: 2
Training loss: 2.9669992923736572
Validation loss: 2.2358059883117676

Epoch: 6| Step: 3
Training loss: 1.9966658353805542
Validation loss: 2.238307863153437

Epoch: 6| Step: 4
Training loss: 2.5268495082855225
Validation loss: 2.2306340920027865

Epoch: 6| Step: 5
Training loss: 2.310089111328125
Validation loss: 2.2243112825578257

Epoch: 6| Step: 6
Training loss: 2.587810516357422
Validation loss: 2.2184487594071256

Epoch: 6| Step: 7
Training loss: 3.1279921531677246
Validation loss: 2.217695182369601

Epoch: 6| Step: 8
Training loss: 2.345489025115967
Validation loss: 2.219129664923555

Epoch: 6| Step: 9
Training loss: 2.821683883666992
Validation loss: 2.2322072944333478

Epoch: 6| Step: 10
Training loss: 2.8993711471557617
Validation loss: 2.234450024943198

Epoch: 6| Step: 11
Training loss: 2.030897855758667
Validation loss: 2.246174327788814

Epoch: 6| Step: 12
Training loss: 2.433372974395752
Validation loss: 2.238826536363171

Epoch: 6| Step: 13
Training loss: 2.18215012550354
Validation loss: 2.2341805324759534

Epoch: 85| Step: 0
Training loss: 1.775038242340088
Validation loss: 2.232632247350549

Epoch: 6| Step: 1
Training loss: 2.2863597869873047
Validation loss: 2.2310562505516955

Epoch: 6| Step: 2
Training loss: 3.8209917545318604
Validation loss: 2.2264610875037407

Epoch: 6| Step: 3
Training loss: 2.231329917907715
Validation loss: 2.222506053986088

Epoch: 6| Step: 4
Training loss: 2.371783494949341
Validation loss: 2.219388859246367

Epoch: 6| Step: 5
Training loss: 2.450185537338257
Validation loss: 2.235126487670406

Epoch: 6| Step: 6
Training loss: 3.230639934539795
Validation loss: 2.2301439956952165

Epoch: 6| Step: 7
Training loss: 2.8988149166107178
Validation loss: 2.265904657302364

Epoch: 6| Step: 8
Training loss: 2.285618305206299
Validation loss: 2.2904197426252466

Epoch: 6| Step: 9
Training loss: 3.369839668273926
Validation loss: 2.3426765088112123

Epoch: 6| Step: 10
Training loss: 2.558706760406494
Validation loss: 2.4606112895473355

Epoch: 6| Step: 11
Training loss: 1.9130440950393677
Validation loss: 2.448325216129262

Epoch: 6| Step: 12
Training loss: 1.806659460067749
Validation loss: 2.358083212247459

Epoch: 6| Step: 13
Training loss: 2.444871425628662
Validation loss: 2.276293803286809

Epoch: 86| Step: 0
Training loss: 2.483999729156494
Validation loss: 2.2250693741665093

Epoch: 6| Step: 1
Training loss: 2.8510143756866455
Validation loss: 2.2102906268130065

Epoch: 6| Step: 2
Training loss: 2.39544677734375
Validation loss: 2.2121252552155526

Epoch: 6| Step: 3
Training loss: 2.048959732055664
Validation loss: 2.226780124889907

Epoch: 6| Step: 4
Training loss: 2.009333610534668
Validation loss: 2.2469315990324943

Epoch: 6| Step: 5
Training loss: 2.285670280456543
Validation loss: 2.257814197130101

Epoch: 6| Step: 6
Training loss: 2.203408718109131
Validation loss: 2.2771551788494153

Epoch: 6| Step: 7
Training loss: 3.2233402729034424
Validation loss: 2.2813251556888705

Epoch: 6| Step: 8
Training loss: 3.7266197204589844
Validation loss: 2.2631431984645065

Epoch: 6| Step: 9
Training loss: 3.1151435375213623
Validation loss: 2.2334043748917116

Epoch: 6| Step: 10
Training loss: 2.45011568069458
Validation loss: 2.2138278048525573

Epoch: 6| Step: 11
Training loss: 2.855180025100708
Validation loss: 2.211141176121209

Epoch: 6| Step: 12
Training loss: 1.7961204051971436
Validation loss: 2.21170989928707

Epoch: 6| Step: 13
Training loss: 1.8866162300109863
Validation loss: 2.2316554118228216

Epoch: 87| Step: 0
Training loss: 2.588975429534912
Validation loss: 2.2907412872519544

Epoch: 6| Step: 1
Training loss: 2.6242947578430176
Validation loss: 2.3853938810286985

Epoch: 6| Step: 2
Training loss: 2.3946259021759033
Validation loss: 2.486698422380673

Epoch: 6| Step: 3
Training loss: 2.739086151123047
Validation loss: 2.5747012886949765

Epoch: 6| Step: 4
Training loss: 2.0370168685913086
Validation loss: 2.525623583024548

Epoch: 6| Step: 5
Training loss: 1.6511540412902832
Validation loss: 2.4460249229144027

Epoch: 6| Step: 6
Training loss: 2.3058295249938965
Validation loss: 2.3058001443903935

Epoch: 6| Step: 7
Training loss: 2.6441166400909424
Validation loss: 2.2301725161972867

Epoch: 6| Step: 8
Training loss: 2.4302005767822266
Validation loss: 2.206810482086674

Epoch: 6| Step: 9
Training loss: 3.0981802940368652
Validation loss: 2.2189555142515447

Epoch: 6| Step: 10
Training loss: 2.44873046875
Validation loss: 2.281239217327487

Epoch: 6| Step: 11
Training loss: 2.9143025875091553
Validation loss: 2.2676256600246636

Epoch: 6| Step: 12
Training loss: 3.3904786109924316
Validation loss: 2.2330472764148506

Epoch: 6| Step: 13
Training loss: 2.9080452919006348
Validation loss: 2.222926265449934

Epoch: 88| Step: 0
Training loss: 2.3075811862945557
Validation loss: 2.2238546545787523

Epoch: 6| Step: 1
Training loss: 2.1681129932403564
Validation loss: 2.2372167379625383

Epoch: 6| Step: 2
Training loss: 3.083967685699463
Validation loss: 2.248079284544914

Epoch: 6| Step: 3
Training loss: 3.4184675216674805
Validation loss: 2.256844502623363

Epoch: 6| Step: 4
Training loss: 2.498249053955078
Validation loss: 2.2871929368665143

Epoch: 6| Step: 5
Training loss: 2.4517641067504883
Validation loss: 2.3150647122372865

Epoch: 6| Step: 6
Training loss: 2.077976703643799
Validation loss: 2.313202186297345

Epoch: 6| Step: 7
Training loss: 3.290374755859375
Validation loss: 2.3027505733633555

Epoch: 6| Step: 8
Training loss: 1.82781982421875
Validation loss: 2.272151021547215

Epoch: 6| Step: 9
Training loss: 2.117049217224121
Validation loss: 2.2749167360285276

Epoch: 6| Step: 10
Training loss: 2.902040958404541
Validation loss: 2.27511413123018

Epoch: 6| Step: 11
Training loss: 2.4478766918182373
Validation loss: 2.25934612366461

Epoch: 6| Step: 12
Training loss: 2.5455117225646973
Validation loss: 2.2514814215321697

Epoch: 6| Step: 13
Training loss: 2.0928966999053955
Validation loss: 2.2398733554347867

Epoch: 89| Step: 0
Training loss: 3.2371153831481934
Validation loss: 2.2280960083007812

Epoch: 6| Step: 1
Training loss: 2.6282215118408203
Validation loss: 2.22807861528089

Epoch: 6| Step: 2
Training loss: 2.9006130695343018
Validation loss: 2.219448381854642

Epoch: 6| Step: 3
Training loss: 2.1049866676330566
Validation loss: 2.2146069208780923

Epoch: 6| Step: 4
Training loss: 2.0292062759399414
Validation loss: 2.2160707596809632

Epoch: 6| Step: 5
Training loss: 2.3243348598480225
Validation loss: 2.2289831843427432

Epoch: 6| Step: 6
Training loss: 2.4843039512634277
Validation loss: 2.236718011158769

Epoch: 6| Step: 7
Training loss: 2.2056243419647217
Validation loss: 2.260086621007612

Epoch: 6| Step: 8
Training loss: 2.354083776473999
Validation loss: 2.315629087468629

Epoch: 6| Step: 9
Training loss: 2.780365467071533
Validation loss: 2.323050311816636

Epoch: 6| Step: 10
Training loss: 2.8024742603302
Validation loss: 2.277513104100381

Epoch: 6| Step: 11
Training loss: 2.6455116271972656
Validation loss: 2.2483919410295385

Epoch: 6| Step: 12
Training loss: 2.5922651290893555
Validation loss: 2.2251518593039563

Epoch: 6| Step: 13
Training loss: 1.282514214515686
Validation loss: 2.2040914143285444

Epoch: 90| Step: 0
Training loss: 3.410184383392334
Validation loss: 2.1824341422768048

Epoch: 6| Step: 1
Training loss: 2.3789732456207275
Validation loss: 2.191521633055902

Epoch: 6| Step: 2
Training loss: 2.3581554889678955
Validation loss: 2.1915737095699517

Epoch: 6| Step: 3
Training loss: 2.351518154144287
Validation loss: 2.1921303861884662

Epoch: 6| Step: 4
Training loss: 2.4120960235595703
Validation loss: 2.204696601436984

Epoch: 6| Step: 5
Training loss: 2.440443754196167
Validation loss: 2.2109639644622803

Epoch: 6| Step: 6
Training loss: 2.6427652835845947
Validation loss: 2.2382580695613736

Epoch: 6| Step: 7
Training loss: 2.439945936203003
Validation loss: 2.240189754834739

Epoch: 6| Step: 8
Training loss: 2.3845765590667725
Validation loss: 2.2330007578736994

Epoch: 6| Step: 9
Training loss: 2.3535914421081543
Validation loss: 2.223690968687816

Epoch: 6| Step: 10
Training loss: 2.5223193168640137
Validation loss: 2.228665182667394

Epoch: 6| Step: 11
Training loss: 2.2526073455810547
Validation loss: 2.2249749142636537

Epoch: 6| Step: 12
Training loss: 2.198394298553467
Validation loss: 2.215419157858818

Epoch: 6| Step: 13
Training loss: 2.894782066345215
Validation loss: 2.2074160524593887

Epoch: 91| Step: 0
Training loss: 2.3794124126434326
Validation loss: 2.2120903563755814

Epoch: 6| Step: 1
Training loss: 2.297077178955078
Validation loss: 2.228167023710025

Epoch: 6| Step: 2
Training loss: 2.7172389030456543
Validation loss: 2.231153400995398

Epoch: 6| Step: 3
Training loss: 2.5633606910705566
Validation loss: 2.2120718930357244

Epoch: 6| Step: 4
Training loss: 2.6233677864074707
Validation loss: 2.2089373898762528

Epoch: 6| Step: 5
Training loss: 2.569927930831909
Validation loss: 2.2068890153720813

Epoch: 6| Step: 6
Training loss: 2.0117268562316895
Validation loss: 2.198409052305324

Epoch: 6| Step: 7
Training loss: 2.356419563293457
Validation loss: 2.197832833054245

Epoch: 6| Step: 8
Training loss: 2.296210527420044
Validation loss: 2.1921302221154653

Epoch: 6| Step: 9
Training loss: 3.2881107330322266
Validation loss: 2.1950269975969867

Epoch: 6| Step: 10
Training loss: 2.3265151977539062
Validation loss: 2.1955840177433465

Epoch: 6| Step: 11
Training loss: 2.619037389755249
Validation loss: 2.198389668618479

Epoch: 6| Step: 12
Training loss: 2.4022927284240723
Validation loss: 2.2054443179920153

Epoch: 6| Step: 13
Training loss: 2.2957072257995605
Validation loss: 2.209189686723935

Epoch: 92| Step: 0
Training loss: 2.2179102897644043
Validation loss: 2.193763973892376

Epoch: 6| Step: 1
Training loss: 2.320676565170288
Validation loss: 2.1876358678264003

Epoch: 6| Step: 2
Training loss: 2.6023378372192383
Validation loss: 2.184623020951466

Epoch: 6| Step: 3
Training loss: 2.523129940032959
Validation loss: 2.1778035189515803

Epoch: 6| Step: 4
Training loss: 2.7644004821777344
Validation loss: 2.1794041907915505

Epoch: 6| Step: 5
Training loss: 2.8335564136505127
Validation loss: 2.171872268440903

Epoch: 6| Step: 6
Training loss: 2.4734139442443848
Validation loss: 2.1739793233974005

Epoch: 6| Step: 7
Training loss: 2.3356313705444336
Validation loss: 2.170380198827354

Epoch: 6| Step: 8
Training loss: 2.643967628479004
Validation loss: 2.1667406187262586

Epoch: 6| Step: 9
Training loss: 3.0192317962646484
Validation loss: 2.1887474957332818

Epoch: 6| Step: 10
Training loss: 1.8915650844573975
Validation loss: 2.1949372163382908

Epoch: 6| Step: 11
Training loss: 2.855750322341919
Validation loss: 2.234969669772733

Epoch: 6| Step: 12
Training loss: 2.221470355987549
Validation loss: 2.2475958742121214

Epoch: 6| Step: 13
Training loss: 1.737780213356018
Validation loss: 2.245015908313054

Epoch: 93| Step: 0
Training loss: 2.554903745651245
Validation loss: 2.2398708148669173

Epoch: 6| Step: 1
Training loss: 2.4893434047698975
Validation loss: 2.21359747199602

Epoch: 6| Step: 2
Training loss: 1.9166792631149292
Validation loss: 2.2010378658130603

Epoch: 6| Step: 3
Training loss: 2.2394566535949707
Validation loss: 2.1950474951856878

Epoch: 6| Step: 4
Training loss: 1.8022184371948242
Validation loss: 2.1785852139995945

Epoch: 6| Step: 5
Training loss: 2.470794916152954
Validation loss: 2.1725639656025875

Epoch: 6| Step: 6
Training loss: 2.971069812774658
Validation loss: 2.1808944773930374

Epoch: 6| Step: 7
Training loss: 1.9658551216125488
Validation loss: 2.188261447414275

Epoch: 6| Step: 8
Training loss: 2.4169015884399414
Validation loss: 2.1982178713685725

Epoch: 6| Step: 9
Training loss: 2.4919073581695557
Validation loss: 2.196187521821709

Epoch: 6| Step: 10
Training loss: 2.302799701690674
Validation loss: 2.208866319348735

Epoch: 6| Step: 11
Training loss: 3.050208568572998
Validation loss: 2.226909755378641

Epoch: 6| Step: 12
Training loss: 2.929225206375122
Validation loss: 2.2581903831933134

Epoch: 6| Step: 13
Training loss: 3.6526811122894287
Validation loss: 2.2509119754196494

Epoch: 94| Step: 0
Training loss: 2.684269666671753
Validation loss: 2.2104659747051936

Epoch: 6| Step: 1
Training loss: 2.8573100566864014
Validation loss: 2.1920301504032587

Epoch: 6| Step: 2
Training loss: 1.8491175174713135
Validation loss: 2.177444983554143

Epoch: 6| Step: 3
Training loss: 3.068089723587036
Validation loss: 2.1737169732329664

Epoch: 6| Step: 4
Training loss: 2.617255687713623
Validation loss: 2.162610141179895

Epoch: 6| Step: 5
Training loss: 2.4796979427337646
Validation loss: 2.1665298810569187

Epoch: 6| Step: 6
Training loss: 3.0130085945129395
Validation loss: 2.158290534891108

Epoch: 6| Step: 7
Training loss: 2.374363899230957
Validation loss: 2.1630215362835954

Epoch: 6| Step: 8
Training loss: 2.6175055503845215
Validation loss: 2.168606350498815

Epoch: 6| Step: 9
Training loss: 1.9991261959075928
Validation loss: 2.1688569156072472

Epoch: 6| Step: 10
Training loss: 2.589035987854004
Validation loss: 2.167862794732535

Epoch: 6| Step: 11
Training loss: 2.561318874359131
Validation loss: 2.17546514029144

Epoch: 6| Step: 12
Training loss: 1.9293087720870972
Validation loss: 2.180195462319159

Epoch: 6| Step: 13
Training loss: 2.024801015853882
Validation loss: 2.1845321168181715

Epoch: 95| Step: 0
Training loss: 3.039916515350342
Validation loss: 2.202339028799406

Epoch: 6| Step: 1
Training loss: 2.4408445358276367
Validation loss: 2.200037958801434

Epoch: 6| Step: 2
Training loss: 2.663501739501953
Validation loss: 2.2096631501310613

Epoch: 6| Step: 3
Training loss: 2.973113536834717
Validation loss: 2.2106954564330397

Epoch: 6| Step: 4
Training loss: 2.412353038787842
Validation loss: 2.2552714501657793

Epoch: 6| Step: 5
Training loss: 2.00807523727417
Validation loss: 2.2749201072159635

Epoch: 6| Step: 6
Training loss: 2.985726833343506
Validation loss: 2.274468175826534

Epoch: 6| Step: 7
Training loss: 2.7951269149780273
Validation loss: 2.2465257131925194

Epoch: 6| Step: 8
Training loss: 1.4017446041107178
Validation loss: 2.216298703224428

Epoch: 6| Step: 9
Training loss: 2.5129008293151855
Validation loss: 2.2035750445499214

Epoch: 6| Step: 10
Training loss: 2.827444553375244
Validation loss: 2.201247630580779

Epoch: 6| Step: 11
Training loss: 2.332772970199585
Validation loss: 2.1896080586218063

Epoch: 6| Step: 12
Training loss: 2.0276906490325928
Validation loss: 2.1644556676187823

Epoch: 6| Step: 13
Training loss: 2.4544472694396973
Validation loss: 2.1666170422748854

Epoch: 96| Step: 0
Training loss: 3.1784653663635254
Validation loss: 2.1590775943571523

Epoch: 6| Step: 1
Training loss: 2.3878984451293945
Validation loss: 2.1526961941872873

Epoch: 6| Step: 2
Training loss: 2.2713189125061035
Validation loss: 2.1512750758919665

Epoch: 6| Step: 3
Training loss: 2.6748945713043213
Validation loss: 2.150842538443945

Epoch: 6| Step: 4
Training loss: 2.7342753410339355
Validation loss: 2.1498045844416462

Epoch: 6| Step: 5
Training loss: 2.870882511138916
Validation loss: 2.14966110772984

Epoch: 6| Step: 6
Training loss: 2.649491310119629
Validation loss: 2.1472529724080074

Epoch: 6| Step: 7
Training loss: 2.5914087295532227
Validation loss: 2.145556648572286

Epoch: 6| Step: 8
Training loss: 2.5345234870910645
Validation loss: 2.1513044090681177

Epoch: 6| Step: 9
Training loss: 2.319174289703369
Validation loss: 2.1623601221269175

Epoch: 6| Step: 10
Training loss: 1.5302526950836182
Validation loss: 2.1579690825554634

Epoch: 6| Step: 11
Training loss: 1.7823336124420166
Validation loss: 2.183543764134889

Epoch: 6| Step: 12
Training loss: 2.4128870964050293
Validation loss: 2.2015870617282007

Epoch: 6| Step: 13
Training loss: 2.5536296367645264
Validation loss: 2.2142042831708024

Epoch: 97| Step: 0
Training loss: 2.089641571044922
Validation loss: 2.2096629270943264

Epoch: 6| Step: 1
Training loss: 2.5176212787628174
Validation loss: 2.201204248653945

Epoch: 6| Step: 2
Training loss: 1.7418546676635742
Validation loss: 2.1800445946314

Epoch: 6| Step: 3
Training loss: 2.124483108520508
Validation loss: 2.160709616958454

Epoch: 6| Step: 4
Training loss: 2.2583200931549072
Validation loss: 2.1507101674233713

Epoch: 6| Step: 5
Training loss: 2.3299944400787354
Validation loss: 2.153156724027408

Epoch: 6| Step: 6
Training loss: 1.960055947303772
Validation loss: 2.1531367250668105

Epoch: 6| Step: 7
Training loss: 2.6346166133880615
Validation loss: 2.1657945648316415

Epoch: 6| Step: 8
Training loss: 3.2030327320098877
Validation loss: 2.1644254115320023

Epoch: 6| Step: 9
Training loss: 2.621398448944092
Validation loss: 2.151421498226863

Epoch: 6| Step: 10
Training loss: 2.895801305770874
Validation loss: 2.1457195487073673

Epoch: 6| Step: 11
Training loss: 2.680818557739258
Validation loss: 2.1443663848343717

Epoch: 6| Step: 12
Training loss: 2.671114444732666
Validation loss: 2.1392373782332226

Epoch: 6| Step: 13
Training loss: 2.511319637298584
Validation loss: 2.1377796511496268

Epoch: 98| Step: 0
Training loss: 2.616581916809082
Validation loss: 2.1403901679541475

Epoch: 6| Step: 1
Training loss: 2.455839157104492
Validation loss: 2.1675652457821752

Epoch: 6| Step: 2
Training loss: 2.0537819862365723
Validation loss: 2.1989873839962866

Epoch: 6| Step: 3
Training loss: 2.7608890533447266
Validation loss: 2.2115848218241045

Epoch: 6| Step: 4
Training loss: 2.23032283782959
Validation loss: 2.221276347355176

Epoch: 6| Step: 5
Training loss: 2.4162609577178955
Validation loss: 2.229269878838652

Epoch: 6| Step: 6
Training loss: 2.3400657176971436
Validation loss: 2.18235767784939

Epoch: 6| Step: 7
Training loss: 2.682286500930786
Validation loss: 2.149537594087662

Epoch: 6| Step: 8
Training loss: 2.5971693992614746
Validation loss: 2.1434785883913756

Epoch: 6| Step: 9
Training loss: 2.5654478073120117
Validation loss: 2.1387040179262877

Epoch: 6| Step: 10
Training loss: 2.220273494720459
Validation loss: 2.1365306685047765

Epoch: 6| Step: 11
Training loss: 2.3061106204986572
Validation loss: 2.144276060083861

Epoch: 6| Step: 12
Training loss: 2.5794291496276855
Validation loss: 2.130586885636853

Epoch: 6| Step: 13
Training loss: 2.7219879627227783
Validation loss: 2.1281766647933633

Epoch: 99| Step: 0
Training loss: 3.0228819847106934
Validation loss: 2.1320826417656353

Epoch: 6| Step: 1
Training loss: 2.2445011138916016
Validation loss: 2.136573754331117

Epoch: 6| Step: 2
Training loss: 3.096724033355713
Validation loss: 2.1362663417734127

Epoch: 6| Step: 3
Training loss: 2.685732364654541
Validation loss: 2.14720384792615

Epoch: 6| Step: 4
Training loss: 2.019188404083252
Validation loss: 2.1555029128187444

Epoch: 6| Step: 5
Training loss: 2.130939483642578
Validation loss: 2.14884433438701

Epoch: 6| Step: 6
Training loss: 2.521543502807617
Validation loss: 2.154499673074292

Epoch: 6| Step: 7
Training loss: 2.0813679695129395
Validation loss: 2.139452456146158

Epoch: 6| Step: 8
Training loss: 2.3699371814727783
Validation loss: 2.1336489339028635

Epoch: 6| Step: 9
Training loss: 2.191983222961426
Validation loss: 2.1488564424617316

Epoch: 6| Step: 10
Training loss: 2.276271104812622
Validation loss: 2.1491721701878372

Epoch: 6| Step: 11
Training loss: 2.563660144805908
Validation loss: 2.152898075760052

Epoch: 6| Step: 12
Training loss: 2.3236265182495117
Validation loss: 2.1583086008666665

Epoch: 6| Step: 13
Training loss: 2.6728062629699707
Validation loss: 2.1646378347950597

Epoch: 100| Step: 0
Training loss: 1.8356186151504517
Validation loss: 2.1587631087149344

Epoch: 6| Step: 1
Training loss: 1.8484539985656738
Validation loss: 2.167937640220888

Epoch: 6| Step: 2
Training loss: 2.0512142181396484
Validation loss: 2.1502882793385494

Epoch: 6| Step: 3
Training loss: 2.392620086669922
Validation loss: 2.1563199130437707

Epoch: 6| Step: 4
Training loss: 2.9316470623016357
Validation loss: 2.1618944034781507

Epoch: 6| Step: 5
Training loss: 2.937549591064453
Validation loss: 2.158127773192621

Epoch: 6| Step: 6
Training loss: 2.971529006958008
Validation loss: 2.1729190529033704

Epoch: 6| Step: 7
Training loss: 2.6995253562927246
Validation loss: 2.166833887818039

Epoch: 6| Step: 8
Training loss: 2.396108865737915
Validation loss: 2.162213889501428

Epoch: 6| Step: 9
Training loss: 2.625471353530884
Validation loss: 2.1622238159179688

Epoch: 6| Step: 10
Training loss: 2.2202048301696777
Validation loss: 2.159976315754716

Epoch: 6| Step: 11
Training loss: 2.7680153846740723
Validation loss: 2.153247279505576

Epoch: 6| Step: 12
Training loss: 2.455380916595459
Validation loss: 2.1484919773635043

Epoch: 6| Step: 13
Training loss: 1.9715380668640137
Validation loss: 2.148439945713166

Epoch: 101| Step: 0
Training loss: 2.5743677616119385
Validation loss: 2.1469528059805594

Epoch: 6| Step: 1
Training loss: 1.7998534440994263
Validation loss: 2.1669991029206144

Epoch: 6| Step: 2
Training loss: 1.3822332620620728
Validation loss: 2.1858088406183387

Epoch: 6| Step: 3
Training loss: 2.5962204933166504
Validation loss: 2.177387414440032

Epoch: 6| Step: 4
Training loss: 2.1935689449310303
Validation loss: 2.166305088227795

Epoch: 6| Step: 5
Training loss: 3.3461244106292725
Validation loss: 2.1622309428389355

Epoch: 6| Step: 6
Training loss: 2.9095683097839355
Validation loss: 2.142625665151945

Epoch: 6| Step: 7
Training loss: 2.680995464324951
Validation loss: 2.1314563917857345

Epoch: 6| Step: 8
Training loss: 2.518341541290283
Validation loss: 2.1385905717008855

Epoch: 6| Step: 9
Training loss: 2.2342076301574707
Validation loss: 2.132505862943588

Epoch: 6| Step: 10
Training loss: 3.0680787563323975
Validation loss: 2.1243689957485405

Epoch: 6| Step: 11
Training loss: 2.3645315170288086
Validation loss: 2.1337997105813797

Epoch: 6| Step: 12
Training loss: 2.0855331420898438
Validation loss: 2.1367960553015433

Epoch: 6| Step: 13
Training loss: 2.20094895362854
Validation loss: 2.1519530383489465

Epoch: 102| Step: 0
Training loss: 1.8197681903839111
Validation loss: 2.1656805187143306

Epoch: 6| Step: 1
Training loss: 2.418827533721924
Validation loss: 2.1800246264344905

Epoch: 6| Step: 2
Training loss: 2.706207752227783
Validation loss: 2.1779514897254204

Epoch: 6| Step: 3
Training loss: 2.6391806602478027
Validation loss: 2.1830843161511164

Epoch: 6| Step: 4
Training loss: 2.1814887523651123
Validation loss: 2.165287143440657

Epoch: 6| Step: 5
Training loss: 2.7832725048065186
Validation loss: 2.1638526788321872

Epoch: 6| Step: 6
Training loss: 1.7488207817077637
Validation loss: 2.148299970934468

Epoch: 6| Step: 7
Training loss: 2.2117512226104736
Validation loss: 2.1219808029872116

Epoch: 6| Step: 8
Training loss: 1.5950775146484375
Validation loss: 2.1184264190735353

Epoch: 6| Step: 9
Training loss: 2.7702369689941406
Validation loss: 2.121904114241241

Epoch: 6| Step: 10
Training loss: 3.2055249214172363
Validation loss: 2.1310178259367585

Epoch: 6| Step: 11
Training loss: 2.543020009994507
Validation loss: 2.1522765415970997

Epoch: 6| Step: 12
Training loss: 2.7745041847229004
Validation loss: 2.181728423282664

Epoch: 6| Step: 13
Training loss: 3.0434272289276123
Validation loss: 2.173392977765811

Epoch: 103| Step: 0
Training loss: 2.62943172454834
Validation loss: 2.1818767388661704

Epoch: 6| Step: 1
Training loss: 2.313000202178955
Validation loss: 2.194993024231285

Epoch: 6| Step: 2
Training loss: 3.130927085876465
Validation loss: 2.1794862593373945

Epoch: 6| Step: 3
Training loss: 1.5163052082061768
Validation loss: 2.1841673005011772

Epoch: 6| Step: 4
Training loss: 2.6148409843444824
Validation loss: 2.1752164850952806

Epoch: 6| Step: 5
Training loss: 2.926368236541748
Validation loss: 2.1546007856245963

Epoch: 6| Step: 6
Training loss: 2.544025421142578
Validation loss: 2.154083328862344

Epoch: 6| Step: 7
Training loss: 2.7428669929504395
Validation loss: 2.140728239090212

Epoch: 6| Step: 8
Training loss: 1.7636549472808838
Validation loss: 2.1529706831901305

Epoch: 6| Step: 9
Training loss: 2.2987301349639893
Validation loss: 2.157972164051507

Epoch: 6| Step: 10
Training loss: 2.847334146499634
Validation loss: 2.1386926084436397

Epoch: 6| Step: 11
Training loss: 2.321174144744873
Validation loss: 2.1668315728505454

Epoch: 6| Step: 12
Training loss: 2.5752246379852295
Validation loss: 2.165946668194186

Epoch: 6| Step: 13
Training loss: 2.6794545650482178
Validation loss: 2.168380550158921

Epoch: 104| Step: 0
Training loss: 2.407985210418701
Validation loss: 2.16995322063405

Epoch: 6| Step: 1
Training loss: 2.528043270111084
Validation loss: 2.1485540174668833

Epoch: 6| Step: 2
Training loss: 2.426833152770996
Validation loss: 2.140928958051948

Epoch: 6| Step: 3
Training loss: 2.4880590438842773
Validation loss: 2.1331677565010647

Epoch: 6| Step: 4
Training loss: 1.9816988706588745
Validation loss: 2.1299253253526587

Epoch: 6| Step: 5
Training loss: 2.2506320476531982
Validation loss: 2.124584751744424

Epoch: 6| Step: 6
Training loss: 2.239339590072632
Validation loss: 2.114347573249571

Epoch: 6| Step: 7
Training loss: 2.3272929191589355
Validation loss: 2.099168962047946

Epoch: 6| Step: 8
Training loss: 2.35321044921875
Validation loss: 2.0907872107721146

Epoch: 6| Step: 9
Training loss: 2.1862218379974365
Validation loss: 2.095997561690628

Epoch: 6| Step: 10
Training loss: 2.714498996734619
Validation loss: 2.100600614342638

Epoch: 6| Step: 11
Training loss: 2.4607815742492676
Validation loss: 2.1027434692587903

Epoch: 6| Step: 12
Training loss: 2.7400851249694824
Validation loss: 2.103114838241249

Epoch: 6| Step: 13
Training loss: 3.2702431678771973
Validation loss: 2.101460474793629

Epoch: 105| Step: 0
Training loss: 2.4856302738189697
Validation loss: 2.090788487465151

Epoch: 6| Step: 1
Training loss: 1.6996430158615112
Validation loss: 2.1005140453256588

Epoch: 6| Step: 2
Training loss: 2.536250114440918
Validation loss: 2.0944784777138823

Epoch: 6| Step: 3
Training loss: 2.593785047531128
Validation loss: 2.111957016811576

Epoch: 6| Step: 4
Training loss: 2.059051513671875
Validation loss: 2.149540576883542

Epoch: 6| Step: 5
Training loss: 3.2025108337402344
Validation loss: 2.186008099586733

Epoch: 6| Step: 6
Training loss: 2.5107033252716064
Validation loss: 2.16516863658864

Epoch: 6| Step: 7
Training loss: 3.178694248199463
Validation loss: 2.1372915006452993

Epoch: 6| Step: 8
Training loss: 1.7218631505966187
Validation loss: 2.1229479902534076

Epoch: 6| Step: 9
Training loss: 2.2790958881378174
Validation loss: 2.112008674170381

Epoch: 6| Step: 10
Training loss: 2.4361672401428223
Validation loss: 2.1035568150140906

Epoch: 6| Step: 11
Training loss: 2.2004177570343018
Validation loss: 2.1031918269331737

Epoch: 6| Step: 12
Training loss: 2.7271416187286377
Validation loss: 2.0972635258910475

Epoch: 6| Step: 13
Training loss: 2.525254487991333
Validation loss: 2.0995002292817637

Epoch: 106| Step: 0
Training loss: 2.757840871810913
Validation loss: 2.1038024707507064

Epoch: 6| Step: 1
Training loss: 2.8269386291503906
Validation loss: 2.106946324789396

Epoch: 6| Step: 2
Training loss: 2.3941097259521484
Validation loss: 2.1092476793514785

Epoch: 6| Step: 3
Training loss: 1.9486083984375
Validation loss: 2.100817916213825

Epoch: 6| Step: 4
Training loss: 2.5852627754211426
Validation loss: 2.093807330695532

Epoch: 6| Step: 5
Training loss: 2.4276373386383057
Validation loss: 2.0941195693067325

Epoch: 6| Step: 6
Training loss: 1.8933429718017578
Validation loss: 2.104688016317224

Epoch: 6| Step: 7
Training loss: 2.2514700889587402
Validation loss: 2.1102129464508383

Epoch: 6| Step: 8
Training loss: 2.4171714782714844
Validation loss: 2.1236646483021397

Epoch: 6| Step: 9
Training loss: 2.2842087745666504
Validation loss: 2.156198319568429

Epoch: 6| Step: 10
Training loss: 2.3515138626098633
Validation loss: 2.1734309350290606

Epoch: 6| Step: 11
Training loss: 3.1968867778778076
Validation loss: 2.22421670088204

Epoch: 6| Step: 12
Training loss: 2.603327751159668
Validation loss: 2.233659428934897

Epoch: 6| Step: 13
Training loss: 2.130375862121582
Validation loss: 2.2140756371200725

Epoch: 107| Step: 0
Training loss: 3.2190933227539062
Validation loss: 2.2196377374792613

Epoch: 6| Step: 1
Training loss: 2.691215991973877
Validation loss: 2.1897370597367645

Epoch: 6| Step: 2
Training loss: 1.8089091777801514
Validation loss: 2.1488898800265406

Epoch: 6| Step: 3
Training loss: 2.6126914024353027
Validation loss: 2.111409071953066

Epoch: 6| Step: 4
Training loss: 1.9014174938201904
Validation loss: 2.0987002234305105

Epoch: 6| Step: 5
Training loss: 2.0040783882141113
Validation loss: 2.0955286256728636

Epoch: 6| Step: 6
Training loss: 2.4800455570220947
Validation loss: 2.0817644826827513

Epoch: 6| Step: 7
Training loss: 2.581745147705078
Validation loss: 2.089502816559166

Epoch: 6| Step: 8
Training loss: 2.44187068939209
Validation loss: 2.0913888818474224

Epoch: 6| Step: 9
Training loss: 2.5361626148223877
Validation loss: 2.0910182665753108

Epoch: 6| Step: 10
Training loss: 2.7490363121032715
Validation loss: 2.085375580736386

Epoch: 6| Step: 11
Training loss: 2.683560371398926
Validation loss: 2.0955587202502834

Epoch: 6| Step: 12
Training loss: 2.072406053543091
Validation loss: 2.107782058818366

Epoch: 6| Step: 13
Training loss: 2.1418581008911133
Validation loss: 2.1105216523652435

Epoch: 108| Step: 0
Training loss: 2.6480624675750732
Validation loss: 2.0994732482458955

Epoch: 6| Step: 1
Training loss: 2.330772638320923
Validation loss: 2.099056569478845

Epoch: 6| Step: 2
Training loss: 2.1653530597686768
Validation loss: 2.0941394605944232

Epoch: 6| Step: 3
Training loss: 2.3074333667755127
Validation loss: 2.092368109251863

Epoch: 6| Step: 4
Training loss: 2.1411571502685547
Validation loss: 2.0919847744767384

Epoch: 6| Step: 5
Training loss: 2.962820053100586
Validation loss: 2.0862388341657576

Epoch: 6| Step: 6
Training loss: 3.22739839553833
Validation loss: 2.090536859727675

Epoch: 6| Step: 7
Training loss: 3.001591205596924
Validation loss: 2.0962905089060464

Epoch: 6| Step: 8
Training loss: 2.011702537536621
Validation loss: 2.1099351606061383

Epoch: 6| Step: 9
Training loss: 2.96701979637146
Validation loss: 2.139344569175474

Epoch: 6| Step: 10
Training loss: 2.1314096450805664
Validation loss: 2.1734830102612896

Epoch: 6| Step: 11
Training loss: 1.9648833274841309
Validation loss: 2.1791799940088743

Epoch: 6| Step: 12
Training loss: 1.8661547899246216
Validation loss: 2.1782405414888935

Epoch: 6| Step: 13
Training loss: 2.300395965576172
Validation loss: 2.1328229955447617

Epoch: 109| Step: 0
Training loss: 2.0513978004455566
Validation loss: 2.1150618009669806

Epoch: 6| Step: 1
Training loss: 2.1299471855163574
Validation loss: 2.1093755050372054

Epoch: 6| Step: 2
Training loss: 2.622610569000244
Validation loss: 2.104166817921464

Epoch: 6| Step: 3
Training loss: 2.7028675079345703
Validation loss: 2.100362995619415

Epoch: 6| Step: 4
Training loss: 2.3781051635742188
Validation loss: 2.1006919978767313

Epoch: 6| Step: 5
Training loss: 2.8224241733551025
Validation loss: 2.097628189671424

Epoch: 6| Step: 6
Training loss: 2.207399845123291
Validation loss: 2.10291358476044

Epoch: 6| Step: 7
Training loss: 2.698683977127075
Validation loss: 2.1072096542645524

Epoch: 6| Step: 8
Training loss: 2.1648154258728027
Validation loss: 2.102314696517042

Epoch: 6| Step: 9
Training loss: 1.8297803401947021
Validation loss: 2.1055801735129407

Epoch: 6| Step: 10
Training loss: 2.6884605884552
Validation loss: 2.112293630517939

Epoch: 6| Step: 11
Training loss: 2.7954933643341064
Validation loss: 2.1209413979643132

Epoch: 6| Step: 12
Training loss: 2.4001283645629883
Validation loss: 2.1198442379633584

Epoch: 6| Step: 13
Training loss: 2.395087718963623
Validation loss: 2.1160753593649915

Epoch: 110| Step: 0
Training loss: 2.7081491947174072
Validation loss: 2.114876618949316

Epoch: 6| Step: 1
Training loss: 2.5237045288085938
Validation loss: 2.1061380781153196

Epoch: 6| Step: 2
Training loss: 1.9901480674743652
Validation loss: 2.0992822326639646

Epoch: 6| Step: 3
Training loss: 2.5694780349731445
Validation loss: 2.1025644950969244

Epoch: 6| Step: 4
Training loss: 2.4931883811950684
Validation loss: 2.0969272992944203

Epoch: 6| Step: 5
Training loss: 2.0465352535247803
Validation loss: 2.0857787362990843

Epoch: 6| Step: 6
Training loss: 2.229743003845215
Validation loss: 2.0752021984387468

Epoch: 6| Step: 7
Training loss: 2.0192511081695557
Validation loss: 2.087901933218843

Epoch: 6| Step: 8
Training loss: 2.368321418762207
Validation loss: 2.102283513674172

Epoch: 6| Step: 9
Training loss: 2.216108798980713
Validation loss: 2.124076254906193

Epoch: 6| Step: 10
Training loss: 2.7494397163391113
Validation loss: 2.11567779766616

Epoch: 6| Step: 11
Training loss: 2.2893240451812744
Validation loss: 2.130515134462746

Epoch: 6| Step: 12
Training loss: 3.0829148292541504
Validation loss: 2.1332510466216714

Epoch: 6| Step: 13
Training loss: 1.8412901163101196
Validation loss: 2.1263748009999595

Epoch: 111| Step: 0
Training loss: 2.4829344749450684
Validation loss: 2.101582342578519

Epoch: 6| Step: 1
Training loss: 2.305042028427124
Validation loss: 2.0846720075094574

Epoch: 6| Step: 2
Training loss: 2.4270310401916504
Validation loss: 2.0773981950616323

Epoch: 6| Step: 3
Training loss: 2.125284433364868
Validation loss: 2.073268068734036

Epoch: 6| Step: 4
Training loss: 2.684499740600586
Validation loss: 2.0797591260684434

Epoch: 6| Step: 5
Training loss: 2.6630477905273438
Validation loss: 2.0881885533691733

Epoch: 6| Step: 6
Training loss: 2.316415786743164
Validation loss: 2.081173909607754

Epoch: 6| Step: 7
Training loss: 2.1336119174957275
Validation loss: 2.0859094409532446

Epoch: 6| Step: 8
Training loss: 2.541285276412964
Validation loss: 2.0918448535344933

Epoch: 6| Step: 9
Training loss: 2.48958158493042
Validation loss: 2.1013321415070565

Epoch: 6| Step: 10
Training loss: 1.9628076553344727
Validation loss: 2.1064694466129428

Epoch: 6| Step: 11
Training loss: 2.6204934120178223
Validation loss: 2.108403416090114

Epoch: 6| Step: 12
Training loss: 2.5277509689331055
Validation loss: 2.0885522057933192

Epoch: 6| Step: 13
Training loss: 1.86256742477417
Validation loss: 2.075604490054551

Epoch: 112| Step: 0
Training loss: 1.8011835813522339
Validation loss: 2.068968742124496

Epoch: 6| Step: 1
Training loss: 3.4488463401794434
Validation loss: 2.06636550605938

Epoch: 6| Step: 2
Training loss: 2.9705986976623535
Validation loss: 2.078520558213675

Epoch: 6| Step: 3
Training loss: 2.4491658210754395
Validation loss: 2.0703577597935996

Epoch: 6| Step: 4
Training loss: 2.228457450866699
Validation loss: 2.078866897090789

Epoch: 6| Step: 5
Training loss: 2.1739063262939453
Validation loss: 2.0642614133896364

Epoch: 6| Step: 6
Training loss: 2.13822078704834
Validation loss: 2.062934280723654

Epoch: 6| Step: 7
Training loss: 2.4200944900512695
Validation loss: 2.067087506735197

Epoch: 6| Step: 8
Training loss: 2.617645263671875
Validation loss: 2.0826106609836703

Epoch: 6| Step: 9
Training loss: 2.646493434906006
Validation loss: 2.094419684461368

Epoch: 6| Step: 10
Training loss: 2.086754560470581
Validation loss: 2.1012510894447245

Epoch: 6| Step: 11
Training loss: 2.4020822048187256
Validation loss: 2.1258805413399973

Epoch: 6| Step: 12
Training loss: 1.8406925201416016
Validation loss: 2.1241057252371185

Epoch: 6| Step: 13
Training loss: 2.407944679260254
Validation loss: 2.0901550631369314

Epoch: 113| Step: 0
Training loss: 2.635185480117798
Validation loss: 2.078397630363382

Epoch: 6| Step: 1
Training loss: 2.4315638542175293
Validation loss: 2.069524008740661

Epoch: 6| Step: 2
Training loss: 1.8997485637664795
Validation loss: 2.0638223924944477

Epoch: 6| Step: 3
Training loss: 2.3723061084747314
Validation loss: 2.0637233308566514

Epoch: 6| Step: 4
Training loss: 1.1741485595703125
Validation loss: 2.05567907005228

Epoch: 6| Step: 5
Training loss: 2.8464903831481934
Validation loss: 2.061126370583811

Epoch: 6| Step: 6
Training loss: 2.8350882530212402
Validation loss: 2.0599368720926265

Epoch: 6| Step: 7
Training loss: 2.5801842212677
Validation loss: 2.066969924075629

Epoch: 6| Step: 8
Training loss: 2.258962392807007
Validation loss: 2.0658641553694204

Epoch: 6| Step: 9
Training loss: 2.255260467529297
Validation loss: 2.071708353616858

Epoch: 6| Step: 10
Training loss: 1.9139409065246582
Validation loss: 2.0829974835918796

Epoch: 6| Step: 11
Training loss: 2.725390911102295
Validation loss: 2.0783345673673894

Epoch: 6| Step: 12
Training loss: 2.4185733795166016
Validation loss: 2.0893326677301878

Epoch: 6| Step: 13
Training loss: 3.235074043273926
Validation loss: 2.104824625035768

Epoch: 114| Step: 0
Training loss: 2.6160547733306885
Validation loss: 2.124477932530065

Epoch: 6| Step: 1
Training loss: 2.7514657974243164
Validation loss: 2.1258949131094

Epoch: 6| Step: 2
Training loss: 3.086399555206299
Validation loss: 2.1298649285429265

Epoch: 6| Step: 3
Training loss: 2.091855049133301
Validation loss: 2.1076801207757767

Epoch: 6| Step: 4
Training loss: 2.111077308654785
Validation loss: 2.0863444574417604

Epoch: 6| Step: 5
Training loss: 1.9597289562225342
Validation loss: 2.0726270098840036

Epoch: 6| Step: 6
Training loss: 1.8223469257354736
Validation loss: 2.06028643602966

Epoch: 6| Step: 7
Training loss: 2.114481210708618
Validation loss: 2.0680692311256164

Epoch: 6| Step: 8
Training loss: 2.5520401000976562
Validation loss: 2.0809758709323023

Epoch: 6| Step: 9
Training loss: 2.827211380004883
Validation loss: 2.0966279660501788

Epoch: 6| Step: 10
Training loss: 2.1982994079589844
Validation loss: 2.1077546201726443

Epoch: 6| Step: 11
Training loss: 2.3705873489379883
Validation loss: 2.0950832905307895

Epoch: 6| Step: 12
Training loss: 2.5338501930236816
Validation loss: 2.085716694913885

Epoch: 6| Step: 13
Training loss: 2.300445556640625
Validation loss: 2.0702766321038686

Epoch: 115| Step: 0
Training loss: 1.9505043029785156
Validation loss: 2.054000973701477

Epoch: 6| Step: 1
Training loss: 2.520573139190674
Validation loss: 2.0437235191304195

Epoch: 6| Step: 2
Training loss: 1.8238182067871094
Validation loss: 2.0504776816214285

Epoch: 6| Step: 3
Training loss: 2.1498613357543945
Validation loss: 2.0524933184346845

Epoch: 6| Step: 4
Training loss: 2.7874417304992676
Validation loss: 2.0596557637696624

Epoch: 6| Step: 5
Training loss: 2.247439384460449
Validation loss: 2.053505838558238

Epoch: 6| Step: 6
Training loss: 3.339061737060547
Validation loss: 2.0388504138556858

Epoch: 6| Step: 7
Training loss: 1.666457176208496
Validation loss: 2.0398596948192966

Epoch: 6| Step: 8
Training loss: 2.0919017791748047
Validation loss: 2.05158213005271

Epoch: 6| Step: 9
Training loss: 3.0574750900268555
Validation loss: 2.064380435533421

Epoch: 6| Step: 10
Training loss: 2.8232345581054688
Validation loss: 2.101647379577801

Epoch: 6| Step: 11
Training loss: 2.4499130249023438
Validation loss: 2.176244230680568

Epoch: 6| Step: 12
Training loss: 2.2344939708709717
Validation loss: 2.231336575682445

Epoch: 6| Step: 13
Training loss: 2.629256248474121
Validation loss: 2.264387817792995

Epoch: 116| Step: 0
Training loss: 2.21444034576416
Validation loss: 2.2908213241125948

Epoch: 6| Step: 1
Training loss: 1.9307548999786377
Validation loss: 2.2690295045093825

Epoch: 6| Step: 2
Training loss: 2.9468772411346436
Validation loss: 2.2686954262436076

Epoch: 6| Step: 3
Training loss: 2.7675628662109375
Validation loss: 2.166368474242508

Epoch: 6| Step: 4
Training loss: 2.896138906478882
Validation loss: 2.1218122307972243

Epoch: 6| Step: 5
Training loss: 2.090913772583008
Validation loss: 2.0965566263403943

Epoch: 6| Step: 6
Training loss: 2.1217565536499023
Validation loss: 2.087211993432814

Epoch: 6| Step: 7
Training loss: 2.2084403038024902
Validation loss: 2.0706412638387373

Epoch: 6| Step: 8
Training loss: 2.2719545364379883
Validation loss: 2.0698345476581204

Epoch: 6| Step: 9
Training loss: 2.496140956878662
Validation loss: 2.0664995075553976

Epoch: 6| Step: 10
Training loss: 2.0463216304779053
Validation loss: 2.073098382642192

Epoch: 6| Step: 11
Training loss: 2.3068184852600098
Validation loss: 2.0822590884341987

Epoch: 6| Step: 12
Training loss: 2.55796480178833
Validation loss: 2.088640389903899

Epoch: 6| Step: 13
Training loss: 3.097805976867676
Validation loss: 2.08383862433895

Epoch: 117| Step: 0
Training loss: 2.0284218788146973
Validation loss: 2.1338976608809603

Epoch: 6| Step: 1
Training loss: 2.613832473754883
Validation loss: 2.1589021144374723

Epoch: 6| Step: 2
Training loss: 2.6976070404052734
Validation loss: 2.174490213394165

Epoch: 6| Step: 3
Training loss: 2.7454380989074707
Validation loss: 2.1284388444756948

Epoch: 6| Step: 4
Training loss: 2.371528387069702
Validation loss: 2.10995114362368

Epoch: 6| Step: 5
Training loss: 1.9401522874832153
Validation loss: 2.0818258741850495

Epoch: 6| Step: 6
Training loss: 2.7532005310058594
Validation loss: 2.0624167996068157

Epoch: 6| Step: 7
Training loss: 2.123990058898926
Validation loss: 2.0575256245110625

Epoch: 6| Step: 8
Training loss: 2.90071439743042
Validation loss: 2.057476733320503

Epoch: 6| Step: 9
Training loss: 2.4368643760681152
Validation loss: 2.0673485250883203

Epoch: 6| Step: 10
Training loss: 2.2112154960632324
Validation loss: 2.0554262386855258

Epoch: 6| Step: 11
Training loss: 2.738538980484009
Validation loss: 2.063888511350078

Epoch: 6| Step: 12
Training loss: 1.6514918804168701
Validation loss: 2.0691504260545135

Epoch: 6| Step: 13
Training loss: 2.278576135635376
Validation loss: 2.080747345442413

Epoch: 118| Step: 0
Training loss: 2.7454910278320312
Validation loss: 2.09242848683429

Epoch: 6| Step: 1
Training loss: 2.4341983795166016
Validation loss: 2.1081343671326995

Epoch: 6| Step: 2
Training loss: 2.202545642852783
Validation loss: 2.110935777746221

Epoch: 6| Step: 3
Training loss: 2.516772747039795
Validation loss: 2.119919890998512

Epoch: 6| Step: 4
Training loss: 2.5036301612854004
Validation loss: 2.1272873993842834

Epoch: 6| Step: 5
Training loss: 2.227795124053955
Validation loss: 2.133238879583215

Epoch: 6| Step: 6
Training loss: 3.115691661834717
Validation loss: 2.105658015897197

Epoch: 6| Step: 7
Training loss: 2.936133861541748
Validation loss: 2.095405476067656

Epoch: 6| Step: 8
Training loss: 1.9892792701721191
Validation loss: 2.0704352612136514

Epoch: 6| Step: 9
Training loss: 1.5676789283752441
Validation loss: 2.0804953280315606

Epoch: 6| Step: 10
Training loss: 2.360663890838623
Validation loss: 2.072391199809249

Epoch: 6| Step: 11
Training loss: 2.161738872528076
Validation loss: 2.0686217277280745

Epoch: 6| Step: 12
Training loss: 1.8835010528564453
Validation loss: 2.0684338410695395

Epoch: 6| Step: 13
Training loss: 2.370455503463745
Validation loss: 2.064113555415984

Epoch: 119| Step: 0
Training loss: 2.8669004440307617
Validation loss: 2.0627867957597137

Epoch: 6| Step: 1
Training loss: 1.5991103649139404
Validation loss: 2.0420484081391366

Epoch: 6| Step: 2
Training loss: 2.217564344406128
Validation loss: 2.040854295094808

Epoch: 6| Step: 3
Training loss: 1.093064785003662
Validation loss: 2.040030989595639

Epoch: 6| Step: 4
Training loss: 1.8798859119415283
Validation loss: 2.042392876840407

Epoch: 6| Step: 5
Training loss: 2.5336050987243652
Validation loss: 2.038236356550647

Epoch: 6| Step: 6
Training loss: 2.753735065460205
Validation loss: 2.0495302369517665

Epoch: 6| Step: 7
Training loss: 2.8709964752197266
Validation loss: 2.0580772097392748

Epoch: 6| Step: 8
Training loss: 2.239983558654785
Validation loss: 2.0548220116605043

Epoch: 6| Step: 9
Training loss: 2.454644203186035
Validation loss: 2.0577779944225023

Epoch: 6| Step: 10
Training loss: 2.725832223892212
Validation loss: 2.0614182397883427

Epoch: 6| Step: 11
Training loss: 1.9743092060089111
Validation loss: 2.0618215760877057

Epoch: 6| Step: 12
Training loss: 2.659237861633301
Validation loss: 2.061989402258268

Epoch: 6| Step: 13
Training loss: 3.26900577545166
Validation loss: 2.0642858910304245

Epoch: 120| Step: 0
Training loss: 2.5946223735809326
Validation loss: 2.0680267939003567

Epoch: 6| Step: 1
Training loss: 3.22308611869812
Validation loss: 2.0733575256921912

Epoch: 6| Step: 2
Training loss: 1.632644772529602
Validation loss: 2.0667321271793817

Epoch: 6| Step: 3
Training loss: 1.6007373332977295
Validation loss: 2.0664646766519033

Epoch: 6| Step: 4
Training loss: 2.1724841594696045
Validation loss: 2.0668587351358063

Epoch: 6| Step: 5
Training loss: 2.5955123901367188
Validation loss: 2.0644602596118884

Epoch: 6| Step: 6
Training loss: 2.434055805206299
Validation loss: 2.056708810149982

Epoch: 6| Step: 7
Training loss: 3.1723363399505615
Validation loss: 2.037376501226938

Epoch: 6| Step: 8
Training loss: 3.1630311012268066
Validation loss: 2.0313081972060667

Epoch: 6| Step: 9
Training loss: 2.223886013031006
Validation loss: 2.0366151063672957

Epoch: 6| Step: 10
Training loss: 1.880706548690796
Validation loss: 2.043736029696721

Epoch: 6| Step: 11
Training loss: 2.370802164077759
Validation loss: 2.033278365289011

Epoch: 6| Step: 12
Training loss: 1.5038681030273438
Validation loss: 2.031659585173412

Epoch: 6| Step: 13
Training loss: 2.1745340824127197
Validation loss: 2.035871846701509

Epoch: 121| Step: 0
Training loss: 2.755911350250244
Validation loss: 2.0432010722416702

Epoch: 6| Step: 1
Training loss: 2.590078353881836
Validation loss: 2.0450796696447555

Epoch: 6| Step: 2
Training loss: 1.9216969013214111
Validation loss: 2.0614795120813514

Epoch: 6| Step: 3
Training loss: 2.4879379272460938
Validation loss: 2.063498818746177

Epoch: 6| Step: 4
Training loss: 1.9371992349624634
Validation loss: 2.0720121168321177

Epoch: 6| Step: 5
Training loss: 2.1484105587005615
Validation loss: 2.0725589183069046

Epoch: 6| Step: 6
Training loss: 2.6368725299835205
Validation loss: 2.0649329898177937

Epoch: 6| Step: 7
Training loss: 2.3210949897766113
Validation loss: 2.068504710351267

Epoch: 6| Step: 8
Training loss: 2.476350784301758
Validation loss: 2.05450725811784

Epoch: 6| Step: 9
Training loss: 1.7769304513931274
Validation loss: 2.0401177816493536

Epoch: 6| Step: 10
Training loss: 2.6704792976379395
Validation loss: 2.024808447848084

Epoch: 6| Step: 11
Training loss: 1.989992618560791
Validation loss: 2.035773733610748

Epoch: 6| Step: 12
Training loss: 2.6492199897766113
Validation loss: 2.0316119091485136

Epoch: 6| Step: 13
Training loss: 2.1199629306793213
Validation loss: 2.029702018666011

Epoch: 122| Step: 0
Training loss: 2.7288599014282227
Validation loss: 2.0439888251725065

Epoch: 6| Step: 1
Training loss: 2.108952045440674
Validation loss: 2.067343306797807

Epoch: 6| Step: 2
Training loss: 2.0830941200256348
Validation loss: 2.0717141500083347

Epoch: 6| Step: 3
Training loss: 2.4258475303649902
Validation loss: 2.061060454255791

Epoch: 6| Step: 4
Training loss: 1.699753761291504
Validation loss: 2.0506970651688112

Epoch: 6| Step: 5
Training loss: 2.682851791381836
Validation loss: 2.0435158257843344

Epoch: 6| Step: 6
Training loss: 2.455535411834717
Validation loss: 2.0312124580465336

Epoch: 6| Step: 7
Training loss: 3.2401139736175537
Validation loss: 2.021512267410114

Epoch: 6| Step: 8
Training loss: 2.3712222576141357
Validation loss: 2.018129655109939

Epoch: 6| Step: 9
Training loss: 1.6884453296661377
Validation loss: 2.0216811292914936

Epoch: 6| Step: 10
Training loss: 2.5175352096557617
Validation loss: 2.0166811455962477

Epoch: 6| Step: 11
Training loss: 2.593404769897461
Validation loss: 2.0210624946061

Epoch: 6| Step: 12
Training loss: 1.8939369916915894
Validation loss: 2.020416810948362

Epoch: 6| Step: 13
Training loss: 1.6517333984375
Validation loss: 2.0309434372891664

Epoch: 123| Step: 0
Training loss: 3.443726062774658
Validation loss: 2.021434840335641

Epoch: 6| Step: 1
Training loss: 2.6701197624206543
Validation loss: 2.020572139370826

Epoch: 6| Step: 2
Training loss: 1.8945395946502686
Validation loss: 2.027341522196288

Epoch: 6| Step: 3
Training loss: 2.7817022800445557
Validation loss: 2.0152384286285727

Epoch: 6| Step: 4
Training loss: 2.0617189407348633
Validation loss: 2.0198638951906593

Epoch: 6| Step: 5
Training loss: 2.0571680068969727
Validation loss: 2.0201824685578704

Epoch: 6| Step: 6
Training loss: 2.442697763442993
Validation loss: 2.0283125421052337

Epoch: 6| Step: 7
Training loss: 2.4877219200134277
Validation loss: 2.032376285522215

Epoch: 6| Step: 8
Training loss: 1.697837471961975
Validation loss: 2.051578511473953

Epoch: 6| Step: 9
Training loss: 1.9164787530899048
Validation loss: 2.0664940085462344

Epoch: 6| Step: 10
Training loss: 2.0555944442749023
Validation loss: 2.071707567861003

Epoch: 6| Step: 11
Training loss: 2.765653133392334
Validation loss: 2.080969916876926

Epoch: 6| Step: 12
Training loss: 2.2958571910858154
Validation loss: 2.0690789632899786

Epoch: 6| Step: 13
Training loss: 1.90151047706604
Validation loss: 2.0537079329131753

Epoch: 124| Step: 0
Training loss: 2.7424216270446777
Validation loss: 2.0389104171465804

Epoch: 6| Step: 1
Training loss: 2.3900227546691895
Validation loss: 2.028115819859248

Epoch: 6| Step: 2
Training loss: 2.4962968826293945
Validation loss: 2.0195621726333455

Epoch: 6| Step: 3
Training loss: 1.7122113704681396
Validation loss: 2.011668033497308

Epoch: 6| Step: 4
Training loss: 2.629786491394043
Validation loss: 2.0244799813916607

Epoch: 6| Step: 5
Training loss: 1.778153419494629
Validation loss: 2.0280478308277745

Epoch: 6| Step: 6
Training loss: 2.072845458984375
Validation loss: 2.015585978825887

Epoch: 6| Step: 7
Training loss: 2.3479089736938477
Validation loss: 2.013876586832026

Epoch: 6| Step: 8
Training loss: 1.832778811454773
Validation loss: 2.01046875856256

Epoch: 6| Step: 9
Training loss: 2.432445764541626
Validation loss: 2.0082649928267284

Epoch: 6| Step: 10
Training loss: 2.68742036819458
Validation loss: 2.015472415954836

Epoch: 6| Step: 11
Training loss: 2.8296871185302734
Validation loss: 2.031654323301008

Epoch: 6| Step: 12
Training loss: 2.3250133991241455
Validation loss: 2.044308481677886

Epoch: 6| Step: 13
Training loss: 2.6557111740112305
Validation loss: 2.0499646753393193

Epoch: 125| Step: 0
Training loss: 2.5619683265686035
Validation loss: 2.056214424871629

Epoch: 6| Step: 1
Training loss: 2.3882503509521484
Validation loss: 2.063969894122052

Epoch: 6| Step: 2
Training loss: 2.2424960136413574
Validation loss: 2.066895141396471

Epoch: 6| Step: 3
Training loss: 2.0628857612609863
Validation loss: 2.0874608985839354

Epoch: 6| Step: 4
Training loss: 2.258695125579834
Validation loss: 2.056939119933754

Epoch: 6| Step: 5
Training loss: 2.0212812423706055
Validation loss: 2.0534956942322435

Epoch: 6| Step: 6
Training loss: 2.5061774253845215
Validation loss: 2.0181396648448002

Epoch: 6| Step: 7
Training loss: 2.3850409984588623
Validation loss: 2.012849618029851

Epoch: 6| Step: 8
Training loss: 2.396803379058838
Validation loss: 2.0137483061000867

Epoch: 6| Step: 9
Training loss: 2.0368216037750244
Validation loss: 2.0079849586691907

Epoch: 6| Step: 10
Training loss: 2.5314998626708984
Validation loss: 2.0117859276392127

Epoch: 6| Step: 11
Training loss: 2.7964541912078857
Validation loss: 2.017222028906627

Epoch: 6| Step: 12
Training loss: 2.0423614978790283
Validation loss: 2.014245133246145

Epoch: 6| Step: 13
Training loss: 2.827657461166382
Validation loss: 2.02510400741331

Epoch: 126| Step: 0
Training loss: 1.6870439052581787
Validation loss: 2.0369370419492006

Epoch: 6| Step: 1
Training loss: 1.7404377460479736
Validation loss: 2.05352069101026

Epoch: 6| Step: 2
Training loss: 2.000056266784668
Validation loss: 2.065486054266653

Epoch: 6| Step: 3
Training loss: 2.0313363075256348
Validation loss: 2.067814806456207

Epoch: 6| Step: 4
Training loss: 2.814328193664551
Validation loss: 2.073498461836128

Epoch: 6| Step: 5
Training loss: 2.4643030166625977
Validation loss: 2.089606527359255

Epoch: 6| Step: 6
Training loss: 2.8994345664978027
Validation loss: 2.107241089626025

Epoch: 6| Step: 7
Training loss: 2.5297622680664062
Validation loss: 2.0834735055123605

Epoch: 6| Step: 8
Training loss: 2.4506478309631348
Validation loss: 2.075314644844301

Epoch: 6| Step: 9
Training loss: 1.8756496906280518
Validation loss: 2.0529496144222956

Epoch: 6| Step: 10
Training loss: 2.6833229064941406
Validation loss: 2.0373267512167654

Epoch: 6| Step: 11
Training loss: 2.14304256439209
Validation loss: 2.036542110545661

Epoch: 6| Step: 12
Training loss: 2.8636505603790283
Validation loss: 2.031947376907513

Epoch: 6| Step: 13
Training loss: 2.3467941284179688
Validation loss: 2.0407760771371986

Epoch: 127| Step: 0
Training loss: 2.3617990016937256
Validation loss: 2.039924080653857

Epoch: 6| Step: 1
Training loss: 2.0276288986206055
Validation loss: 2.0200341645107476

Epoch: 6| Step: 2
Training loss: 1.8836617469787598
Validation loss: 2.0220489219952653

Epoch: 6| Step: 3
Training loss: 1.9365806579589844
Validation loss: 2.020708437888853

Epoch: 6| Step: 4
Training loss: 2.273226737976074
Validation loss: 2.012554391737907

Epoch: 6| Step: 5
Training loss: 2.4524309635162354
Validation loss: 2.023653890496941

Epoch: 6| Step: 6
Training loss: 1.9347543716430664
Validation loss: 2.027981663262972

Epoch: 6| Step: 7
Training loss: 1.919992208480835
Validation loss: 2.0239867856425624

Epoch: 6| Step: 8
Training loss: 2.454113483428955
Validation loss: 2.040605639898649

Epoch: 6| Step: 9
Training loss: 2.2781827449798584
Validation loss: 2.0162396661696897

Epoch: 6| Step: 10
Training loss: 2.6829473972320557
Validation loss: 2.0132125577619

Epoch: 6| Step: 11
Training loss: 2.8603830337524414
Validation loss: 2.013953833169835

Epoch: 6| Step: 12
Training loss: 2.50986385345459
Validation loss: 2.018114618075791

Epoch: 6| Step: 13
Training loss: 2.753878593444824
Validation loss: 2.0209610128915436

Epoch: 128| Step: 0
Training loss: 2.3086533546447754
Validation loss: 2.023254698322665

Epoch: 6| Step: 1
Training loss: 1.7722949981689453
Validation loss: 2.0252442385560725

Epoch: 6| Step: 2
Training loss: 2.1972548961639404
Validation loss: 2.0199494259331816

Epoch: 6| Step: 3
Training loss: 2.911569833755493
Validation loss: 2.028266001773137

Epoch: 6| Step: 4
Training loss: 2.7372238636016846
Validation loss: 2.0148558898638655

Epoch: 6| Step: 5
Training loss: 1.6012300252914429
Validation loss: 2.0216454344411052

Epoch: 6| Step: 6
Training loss: 1.7627403736114502
Validation loss: 2.0175084144838396

Epoch: 6| Step: 7
Training loss: 2.623408079147339
Validation loss: 2.0030766148721018

Epoch: 6| Step: 8
Training loss: 2.2228615283966064
Validation loss: 2.0088897084677093

Epoch: 6| Step: 9
Training loss: 2.6764755249023438
Validation loss: 2.0074046837386263

Epoch: 6| Step: 10
Training loss: 2.443126916885376
Validation loss: 1.9930312325877528

Epoch: 6| Step: 11
Training loss: 2.387873411178589
Validation loss: 2.0015205849883375

Epoch: 6| Step: 12
Training loss: 2.4384303092956543
Validation loss: 1.9985835936761671

Epoch: 6| Step: 13
Training loss: 1.8390328884124756
Validation loss: 2.003030566759007

Epoch: 129| Step: 0
Training loss: 2.3454816341400146
Validation loss: 1.9947047554036623

Epoch: 6| Step: 1
Training loss: 2.075934410095215
Validation loss: 2.006173636323662

Epoch: 6| Step: 2
Training loss: 1.8471131324768066
Validation loss: 2.003226487867294

Epoch: 6| Step: 3
Training loss: 1.950271487236023
Validation loss: 2.00164726216306

Epoch: 6| Step: 4
Training loss: 1.386880874633789
Validation loss: 1.998963112472206

Epoch: 6| Step: 5
Training loss: 2.0995211601257324
Validation loss: 1.9997599894000637

Epoch: 6| Step: 6
Training loss: 1.8928253650665283
Validation loss: 2.0101251448354414

Epoch: 6| Step: 7
Training loss: 2.808314085006714
Validation loss: 2.015300496931999

Epoch: 6| Step: 8
Training loss: 2.4853532314300537
Validation loss: 2.0241535171385734

Epoch: 6| Step: 9
Training loss: 2.372283458709717
Validation loss: 2.0454797770387385

Epoch: 6| Step: 10
Training loss: 2.839686632156372
Validation loss: 2.0476467147950204

Epoch: 6| Step: 11
Training loss: 2.838222026824951
Validation loss: 2.0849559768553703

Epoch: 6| Step: 12
Training loss: 2.441554069519043
Validation loss: 2.105804089576967

Epoch: 6| Step: 13
Training loss: 2.885138750076294
Validation loss: 2.1167832382263674

Epoch: 130| Step: 0
Training loss: 2.3220133781433105
Validation loss: 2.119776177149947

Epoch: 6| Step: 1
Training loss: 2.3295412063598633
Validation loss: 2.085553361523536

Epoch: 6| Step: 2
Training loss: 2.2347800731658936
Validation loss: 2.044599938136275

Epoch: 6| Step: 3
Training loss: 2.34928297996521
Validation loss: 2.0347433372210433

Epoch: 6| Step: 4
Training loss: 2.3603029251098633
Validation loss: 2.0209377888710267

Epoch: 6| Step: 5
Training loss: 2.138798713684082
Validation loss: 2.0217109726321314

Epoch: 6| Step: 6
Training loss: 2.2690324783325195
Validation loss: 2.028343298101938

Epoch: 6| Step: 7
Training loss: 2.3822617530822754
Validation loss: 2.0215017205925396

Epoch: 6| Step: 8
Training loss: 2.2493343353271484
Validation loss: 2.029505773257184

Epoch: 6| Step: 9
Training loss: 2.1708271503448486
Validation loss: 2.0270641798614175

Epoch: 6| Step: 10
Training loss: 2.1272387504577637
Validation loss: 2.019047773012551

Epoch: 6| Step: 11
Training loss: 2.2235679626464844
Validation loss: 2.045100400524755

Epoch: 6| Step: 12
Training loss: 2.5226707458496094
Validation loss: 2.0547504655776487

Epoch: 6| Step: 13
Training loss: 3.064877510070801
Validation loss: 2.071763123235395

Epoch: 131| Step: 0
Training loss: 2.2735652923583984
Validation loss: 2.08484124880965

Epoch: 6| Step: 1
Training loss: 1.7702430486679077
Validation loss: 2.1019996520011657

Epoch: 6| Step: 2
Training loss: 2.9350380897521973
Validation loss: 2.111502837109309

Epoch: 6| Step: 3
Training loss: 2.0552968978881836
Validation loss: 2.1144718008656658

Epoch: 6| Step: 4
Training loss: 2.2891674041748047
Validation loss: 2.082945981333333

Epoch: 6| Step: 5
Training loss: 2.815824031829834
Validation loss: 2.067355386672481

Epoch: 6| Step: 6
Training loss: 2.4140572547912598
Validation loss: 2.04763283780826

Epoch: 6| Step: 7
Training loss: 2.014115810394287
Validation loss: 2.040762221941384

Epoch: 6| Step: 8
Training loss: 2.260432243347168
Validation loss: 2.023299679961256

Epoch: 6| Step: 9
Training loss: 2.1314666271209717
Validation loss: 2.03425201805689

Epoch: 6| Step: 10
Training loss: 2.3570797443389893
Validation loss: 2.0423403247710197

Epoch: 6| Step: 11
Training loss: 2.5296709537506104
Validation loss: 2.0545012630442137

Epoch: 6| Step: 12
Training loss: 2.106400966644287
Validation loss: 2.041347361380054

Epoch: 6| Step: 13
Training loss: 2.518526315689087
Validation loss: 2.034095041213497

Epoch: 132| Step: 0
Training loss: 2.198258638381958
Validation loss: 2.0262633446724183

Epoch: 6| Step: 1
Training loss: 2.0506324768066406
Validation loss: 2.029124270203293

Epoch: 6| Step: 2
Training loss: 2.4632978439331055
Validation loss: 2.0299879504788305

Epoch: 6| Step: 3
Training loss: 2.2204322814941406
Validation loss: 2.031242706442392

Epoch: 6| Step: 4
Training loss: 2.3410820960998535
Validation loss: 2.064732902793474

Epoch: 6| Step: 5
Training loss: 2.6516051292419434
Validation loss: 2.0786398751761324

Epoch: 6| Step: 6
Training loss: 2.7153878211975098
Validation loss: 2.116409751676744

Epoch: 6| Step: 7
Training loss: 2.211559772491455
Validation loss: 2.185263777291903

Epoch: 6| Step: 8
Training loss: 2.880457878112793
Validation loss: 2.257573864793265

Epoch: 6| Step: 9
Training loss: 2.3502211570739746
Validation loss: 2.1958112280855895

Epoch: 6| Step: 10
Training loss: 2.0753045082092285
Validation loss: 2.1257039962276334

Epoch: 6| Step: 11
Training loss: 2.817192316055298
Validation loss: 2.0674771749845116

Epoch: 6| Step: 12
Training loss: 1.6074488162994385
Validation loss: 2.0132024185631865

Epoch: 6| Step: 13
Training loss: 2.605881929397583
Validation loss: 2.0051201812682615

Epoch: 133| Step: 0
Training loss: 2.437243938446045
Validation loss: 1.9971142174095236

Epoch: 6| Step: 1
Training loss: 2.404158592224121
Validation loss: 2.0051996336188367

Epoch: 6| Step: 2
Training loss: 1.7690362930297852
Validation loss: 2.0409406051840833

Epoch: 6| Step: 3
Training loss: 2.2181358337402344
Validation loss: 2.059104266987052

Epoch: 6| Step: 4
Training loss: 2.3311586380004883
Validation loss: 2.0620282657684816

Epoch: 6| Step: 5
Training loss: 2.11299467086792
Validation loss: 2.0337808426990303

Epoch: 6| Step: 6
Training loss: 2.588724136352539
Validation loss: 2.0157639647042878

Epoch: 6| Step: 7
Training loss: 2.897618293762207
Validation loss: 2.0012836853663125

Epoch: 6| Step: 8
Training loss: 2.4079208374023438
Validation loss: 2.003618951766722

Epoch: 6| Step: 9
Training loss: 2.076287031173706
Validation loss: 2.0051505616916123

Epoch: 6| Step: 10
Training loss: 2.667130947113037
Validation loss: 1.992918131172016

Epoch: 6| Step: 11
Training loss: 2.105837821960449
Validation loss: 1.9988860930165937

Epoch: 6| Step: 12
Training loss: 2.479250907897949
Validation loss: 1.983658359896752

Epoch: 6| Step: 13
Training loss: 2.5119967460632324
Validation loss: 1.986707091331482

Epoch: 134| Step: 0
Training loss: 1.6968320608139038
Validation loss: 2.001068092161609

Epoch: 6| Step: 1
Training loss: 2.2420411109924316
Validation loss: 2.0071902172539824

Epoch: 6| Step: 2
Training loss: 2.146212100982666
Validation loss: 2.0080118358776136

Epoch: 6| Step: 3
Training loss: 1.6284453868865967
Validation loss: 2.0549235318296697

Epoch: 6| Step: 4
Training loss: 2.3120391368865967
Validation loss: 2.0775232750882386

Epoch: 6| Step: 5
Training loss: 2.886620283126831
Validation loss: 2.0965800118702713

Epoch: 6| Step: 6
Training loss: 2.572394847869873
Validation loss: 2.046751788867417

Epoch: 6| Step: 7
Training loss: 1.9018081426620483
Validation loss: 2.041713547962968

Epoch: 6| Step: 8
Training loss: 2.709737539291382
Validation loss: 2.0156592963844218

Epoch: 6| Step: 9
Training loss: 2.3059680461883545
Validation loss: 1.9910332079856627

Epoch: 6| Step: 10
Training loss: 2.4695937633514404
Validation loss: 1.9950361046739804

Epoch: 6| Step: 11
Training loss: 2.5836057662963867
Validation loss: 1.9931262244460404

Epoch: 6| Step: 12
Training loss: 2.544724464416504
Validation loss: 1.9941300205005112

Epoch: 6| Step: 13
Training loss: 1.8447551727294922
Validation loss: 1.9960381677073817

Epoch: 135| Step: 0
Training loss: 1.3151564598083496
Validation loss: 2.0049461164782123

Epoch: 6| Step: 1
Training loss: 3.2090775966644287
Validation loss: 2.0022165544571413

Epoch: 6| Step: 2
Training loss: 2.1735804080963135
Validation loss: 2.008812690293917

Epoch: 6| Step: 3
Training loss: 2.699734687805176
Validation loss: 2.015976177748813

Epoch: 6| Step: 4
Training loss: 2.1599316596984863
Validation loss: 2.011423413471509

Epoch: 6| Step: 5
Training loss: 1.2744743824005127
Validation loss: 2.000829137781615

Epoch: 6| Step: 6
Training loss: 2.622959852218628
Validation loss: 2.0116991298173064

Epoch: 6| Step: 7
Training loss: 2.354623794555664
Validation loss: 2.015891008479621

Epoch: 6| Step: 8
Training loss: 2.9386839866638184
Validation loss: 2.014679023014602

Epoch: 6| Step: 9
Training loss: 2.2258100509643555
Validation loss: 2.0241407502082085

Epoch: 6| Step: 10
Training loss: 1.9771339893341064
Validation loss: 2.028893418209527

Epoch: 6| Step: 11
Training loss: 2.6709530353546143
Validation loss: 2.0097383927273493

Epoch: 6| Step: 12
Training loss: 2.308915138244629
Validation loss: 2.0215045175244732

Epoch: 6| Step: 13
Training loss: 2.0756821632385254
Validation loss: 2.0109587946245746

Epoch: 136| Step: 0
Training loss: 1.8685857057571411
Validation loss: 2.0097649494806924

Epoch: 6| Step: 1
Training loss: 2.6768317222595215
Validation loss: 2.0050528664742746

Epoch: 6| Step: 2
Training loss: 1.7424418926239014
Validation loss: 2.000652782378658

Epoch: 6| Step: 3
Training loss: 2.0193705558776855
Validation loss: 2.0130215678163754

Epoch: 6| Step: 4
Training loss: 1.4916044473648071
Validation loss: 2.014028021084365

Epoch: 6| Step: 5
Training loss: 2.342928171157837
Validation loss: 2.01201908434591

Epoch: 6| Step: 6
Training loss: 2.2662458419799805
Validation loss: 2.0087575425383863

Epoch: 6| Step: 7
Training loss: 2.547070026397705
Validation loss: 2.0089027497076217

Epoch: 6| Step: 8
Training loss: 2.438873291015625
Validation loss: 2.0083742603178947

Epoch: 6| Step: 9
Training loss: 2.388662099838257
Validation loss: 1.999602610065091

Epoch: 6| Step: 10
Training loss: 2.705838680267334
Validation loss: 1.997489942017422

Epoch: 6| Step: 11
Training loss: 2.07112455368042
Validation loss: 2.0078279766985165

Epoch: 6| Step: 12
Training loss: 2.6386895179748535
Validation loss: 1.9925831722956833

Epoch: 6| Step: 13
Training loss: 2.123347759246826
Validation loss: 2.0161644386988815

Epoch: 137| Step: 0
Training loss: 2.589344024658203
Validation loss: 2.0464908230689263

Epoch: 6| Step: 1
Training loss: 2.430487871170044
Validation loss: 2.0639784964182044

Epoch: 6| Step: 2
Training loss: 2.587845802307129
Validation loss: 2.0707409907412786

Epoch: 6| Step: 3
Training loss: 2.3205318450927734
Validation loss: 2.0476059990544475

Epoch: 6| Step: 4
Training loss: 2.071650981903076
Validation loss: 2.0128089945803405

Epoch: 6| Step: 5
Training loss: 1.9520156383514404
Validation loss: 2.005741680822065

Epoch: 6| Step: 6
Training loss: 2.195178270339966
Validation loss: 2.003159374319097

Epoch: 6| Step: 7
Training loss: 2.062044143676758
Validation loss: 1.980088205747707

Epoch: 6| Step: 8
Training loss: 2.2778987884521484
Validation loss: 1.9815567385765813

Epoch: 6| Step: 9
Training loss: 2.000621795654297
Validation loss: 1.9928345064963064

Epoch: 6| Step: 10
Training loss: 2.794327735900879
Validation loss: 2.005470710415994

Epoch: 6| Step: 11
Training loss: 2.4351203441619873
Validation loss: 2.014511669835737

Epoch: 6| Step: 12
Training loss: 1.993088722229004
Validation loss: 2.011123186798506

Epoch: 6| Step: 13
Training loss: 2.349600076675415
Validation loss: 1.9950900923821233

Epoch: 138| Step: 0
Training loss: 2.264460325241089
Validation loss: 1.9926039095847838

Epoch: 6| Step: 1
Training loss: 1.641456127166748
Validation loss: 1.9913316144738147

Epoch: 6| Step: 2
Training loss: 1.543839454650879
Validation loss: 1.9973943220671786

Epoch: 6| Step: 3
Training loss: 3.072728157043457
Validation loss: 1.9903482698625135

Epoch: 6| Step: 4
Training loss: 2.538485527038574
Validation loss: 2.0053674367166336

Epoch: 6| Step: 5
Training loss: 2.0613856315612793
Validation loss: 2.018156277236118

Epoch: 6| Step: 6
Training loss: 2.486186981201172
Validation loss: 2.014921731846307

Epoch: 6| Step: 7
Training loss: 2.021141529083252
Validation loss: 2.000359550599129

Epoch: 6| Step: 8
Training loss: 2.2680864334106445
Validation loss: 2.009559383956335

Epoch: 6| Step: 9
Training loss: 2.720348358154297
Validation loss: 1.9969350689200944

Epoch: 6| Step: 10
Training loss: 2.1453232765197754
Validation loss: 2.0016196722625406

Epoch: 6| Step: 11
Training loss: 2.292900323867798
Validation loss: 2.0091371177345194

Epoch: 6| Step: 12
Training loss: 1.9797747135162354
Validation loss: 2.0597741116759596

Epoch: 6| Step: 13
Training loss: 2.8550870418548584
Validation loss: 2.0809298446101527

Epoch: 139| Step: 0
Training loss: 2.271205186843872
Validation loss: 2.0497119670273154

Epoch: 6| Step: 1
Training loss: 2.1507134437561035
Validation loss: 2.039623616844095

Epoch: 6| Step: 2
Training loss: 2.7663843631744385
Validation loss: 2.03372517196081

Epoch: 6| Step: 3
Training loss: 2.4304943084716797
Validation loss: 2.0145159536792385

Epoch: 6| Step: 4
Training loss: 2.7238974571228027
Validation loss: 1.9968346139436126

Epoch: 6| Step: 5
Training loss: 2.269172430038452
Validation loss: 1.9924369165974278

Epoch: 6| Step: 6
Training loss: 2.126581907272339
Validation loss: 1.9983665379144813

Epoch: 6| Step: 7
Training loss: 2.521726608276367
Validation loss: 1.9993290593547206

Epoch: 6| Step: 8
Training loss: 1.425464391708374
Validation loss: 2.0053340106882076

Epoch: 6| Step: 9
Training loss: 2.1132445335388184
Validation loss: 2.0076385467283187

Epoch: 6| Step: 10
Training loss: 2.2164149284362793
Validation loss: 2.0057025532568655

Epoch: 6| Step: 11
Training loss: 1.9430372714996338
Validation loss: 2.0129381366955337

Epoch: 6| Step: 12
Training loss: 2.0323097705841064
Validation loss: 1.9973081093962475

Epoch: 6| Step: 13
Training loss: 2.1235671043395996
Validation loss: 1.9968609681693457

Epoch: 140| Step: 0
Training loss: 2.009263277053833
Validation loss: 1.9873716959389307

Epoch: 6| Step: 1
Training loss: 2.6690163612365723
Validation loss: 1.9918436401633806

Epoch: 6| Step: 2
Training loss: 2.1274404525756836
Validation loss: 1.9962055196044266

Epoch: 6| Step: 3
Training loss: 2.460239887237549
Validation loss: 2.0030156450886882

Epoch: 6| Step: 4
Training loss: 1.8540160655975342
Validation loss: 1.9980358103270173

Epoch: 6| Step: 5
Training loss: 2.0385491847991943
Validation loss: 1.9937142633622693

Epoch: 6| Step: 6
Training loss: 2.455913543701172
Validation loss: 1.9763962914866786

Epoch: 6| Step: 7
Training loss: 2.380574941635132
Validation loss: 1.9749999533417404

Epoch: 6| Step: 8
Training loss: 2.349254846572876
Validation loss: 1.9590681957942184

Epoch: 6| Step: 9
Training loss: 1.5419013500213623
Validation loss: 1.966867454590336

Epoch: 6| Step: 10
Training loss: 2.430363655090332
Validation loss: 1.9778514382659749

Epoch: 6| Step: 11
Training loss: 1.6525824069976807
Validation loss: 1.9812503130205217

Epoch: 6| Step: 12
Training loss: 2.3890230655670166
Validation loss: 1.9874172633694065

Epoch: 6| Step: 13
Training loss: 2.8320634365081787
Validation loss: 2.0196024961369012

Epoch: 141| Step: 0
Training loss: 2.0836637020111084
Validation loss: 2.0138096681205173

Epoch: 6| Step: 1
Training loss: 2.1450657844543457
Validation loss: 2.0020384557785524

Epoch: 6| Step: 2
Training loss: 3.600290298461914
Validation loss: 1.9924320405529392

Epoch: 6| Step: 3
Training loss: 2.016739845275879
Validation loss: 1.9794045789267427

Epoch: 6| Step: 4
Training loss: 1.6323248147964478
Validation loss: 1.9878395475367063

Epoch: 6| Step: 5
Training loss: 2.0223522186279297
Validation loss: 1.9715889602579095

Epoch: 6| Step: 6
Training loss: 2.354139804840088
Validation loss: 1.986226563812584

Epoch: 6| Step: 7
Training loss: 2.517922878265381
Validation loss: 1.976882783315515

Epoch: 6| Step: 8
Training loss: 1.5863876342773438
Validation loss: 1.9789765009316065

Epoch: 6| Step: 9
Training loss: 2.102599620819092
Validation loss: 1.9932167248059345

Epoch: 6| Step: 10
Training loss: 1.9947502613067627
Validation loss: 1.983327284935982

Epoch: 6| Step: 11
Training loss: 1.707473874092102
Validation loss: 1.9874623001262706

Epoch: 6| Step: 12
Training loss: 2.903343677520752
Validation loss: 1.9792445218691261

Epoch: 6| Step: 13
Training loss: 2.2273104190826416
Validation loss: 1.9887600688524143

Epoch: 142| Step: 0
Training loss: 2.8671774864196777
Validation loss: 1.971527986629035

Epoch: 6| Step: 1
Training loss: 2.114208221435547
Validation loss: 1.9811646707596318

Epoch: 6| Step: 2
Training loss: 2.4550418853759766
Validation loss: 1.977705394068072

Epoch: 6| Step: 3
Training loss: 2.267969846725464
Validation loss: 1.9936697047243837

Epoch: 6| Step: 4
Training loss: 2.0577685832977295
Validation loss: 1.9989264216474307

Epoch: 6| Step: 5
Training loss: 2.4281511306762695
Validation loss: 1.9797230023209766

Epoch: 6| Step: 6
Training loss: 2.096461772918701
Validation loss: 1.996143348755375

Epoch: 6| Step: 7
Training loss: 1.8761768341064453
Validation loss: 1.9858989766848985

Epoch: 6| Step: 8
Training loss: 2.4143106937408447
Validation loss: 2.0046205289902224

Epoch: 6| Step: 9
Training loss: 2.0030357837677
Validation loss: 2.010192117383403

Epoch: 6| Step: 10
Training loss: 1.772460699081421
Validation loss: 2.0213914212360176

Epoch: 6| Step: 11
Training loss: 1.9054276943206787
Validation loss: 2.034933884938558

Epoch: 6| Step: 12
Training loss: 2.550534725189209
Validation loss: 2.014996426079863

Epoch: 6| Step: 13
Training loss: 2.048666477203369
Validation loss: 2.0223631294824744

Epoch: 143| Step: 0
Training loss: 2.636859893798828
Validation loss: 2.021414556810933

Epoch: 6| Step: 1
Training loss: 2.0793604850769043
Validation loss: 2.017020585716412

Epoch: 6| Step: 2
Training loss: 2.5272905826568604
Validation loss: 2.002442482979067

Epoch: 6| Step: 3
Training loss: 2.342883348464966
Validation loss: 1.999318988092484

Epoch: 6| Step: 4
Training loss: 2.7590737342834473
Validation loss: 1.9926188222823604

Epoch: 6| Step: 5
Training loss: 2.05118989944458
Validation loss: 1.9887803703226068

Epoch: 6| Step: 6
Training loss: 1.8374104499816895
Validation loss: 1.9819749452734505

Epoch: 6| Step: 7
Training loss: 1.964193344116211
Validation loss: 1.963597087449925

Epoch: 6| Step: 8
Training loss: 1.725986361503601
Validation loss: 1.9744741121927898

Epoch: 6| Step: 9
Training loss: 1.5688862800598145
Validation loss: 2.0002563127907376

Epoch: 6| Step: 10
Training loss: 2.60085391998291
Validation loss: 2.0026372812127553

Epoch: 6| Step: 11
Training loss: 1.7527546882629395
Validation loss: 2.018408607411128

Epoch: 6| Step: 12
Training loss: 2.236555576324463
Validation loss: 2.0465475589998308

Epoch: 6| Step: 13
Training loss: 3.4851155281066895
Validation loss: 2.1084417476448962

Epoch: 144| Step: 0
Training loss: 2.545135021209717
Validation loss: 2.149223086654499

Epoch: 6| Step: 1
Training loss: 2.2380805015563965
Validation loss: 2.1745432346097884

Epoch: 6| Step: 2
Training loss: 3.042310953140259
Validation loss: 2.1598721832357426

Epoch: 6| Step: 3
Training loss: 2.2892417907714844
Validation loss: 2.1501375423964633

Epoch: 6| Step: 4
Training loss: 2.3553638458251953
Validation loss: 2.1229583089069655

Epoch: 6| Step: 5
Training loss: 2.2781167030334473
Validation loss: 2.1048563077885616

Epoch: 6| Step: 6
Training loss: 2.0817418098449707
Validation loss: 2.108484370734102

Epoch: 6| Step: 7
Training loss: 1.7050354480743408
Validation loss: 2.1219485216243292

Epoch: 6| Step: 8
Training loss: 2.873929023742676
Validation loss: 2.2103450887946674

Epoch: 6| Step: 9
Training loss: 1.6607844829559326
Validation loss: 2.1726047415887155

Epoch: 6| Step: 10
Training loss: 1.83884596824646
Validation loss: 2.0850229583760744

Epoch: 6| Step: 11
Training loss: 2.4659481048583984
Validation loss: 2.0195520116436865

Epoch: 6| Step: 12
Training loss: 2.37103533744812
Validation loss: 2.0226959349006735

Epoch: 6| Step: 13
Training loss: 1.7794102430343628
Validation loss: 2.028615105536676

Epoch: 145| Step: 0
Training loss: 1.9907724857330322
Validation loss: 2.0527825919530724

Epoch: 6| Step: 1
Training loss: 2.0092196464538574
Validation loss: 2.0573464093669767

Epoch: 6| Step: 2
Training loss: 2.82863712310791
Validation loss: 2.0383670201865574

Epoch: 6| Step: 3
Training loss: 2.608001947402954
Validation loss: 1.9945115171453005

Epoch: 6| Step: 4
Training loss: 1.9346864223480225
Validation loss: 1.956849689124733

Epoch: 6| Step: 5
Training loss: 2.723620891571045
Validation loss: 1.981142795214089

Epoch: 6| Step: 6
Training loss: 2.230973720550537
Validation loss: 2.002895103987827

Epoch: 6| Step: 7
Training loss: 2.1186044216156006
Validation loss: 2.0251718490354476

Epoch: 6| Step: 8
Training loss: 1.9171706438064575
Validation loss: 2.054428922232761

Epoch: 6| Step: 9
Training loss: 1.8295035362243652
Validation loss: 2.0950279646022345

Epoch: 6| Step: 10
Training loss: 2.1970365047454834
Validation loss: 2.099345108514191

Epoch: 6| Step: 11
Training loss: 3.5073509216308594
Validation loss: 2.1054489574124737

Epoch: 6| Step: 12
Training loss: 1.5908222198486328
Validation loss: 2.0481927805049445

Epoch: 6| Step: 13
Training loss: 2.4798593521118164
Validation loss: 2.0317649661853747

Epoch: 146| Step: 0
Training loss: 2.218517303466797
Validation loss: 2.0027481138065295

Epoch: 6| Step: 1
Training loss: 1.9841535091400146
Validation loss: 1.9939637748144006

Epoch: 6| Step: 2
Training loss: 2.135714292526245
Validation loss: 1.9889924192941317

Epoch: 6| Step: 3
Training loss: 2.283149242401123
Validation loss: 1.9743645832102785

Epoch: 6| Step: 4
Training loss: 2.9926838874816895
Validation loss: 1.951708278348369

Epoch: 6| Step: 5
Training loss: 2.221546173095703
Validation loss: 1.941475369596994

Epoch: 6| Step: 6
Training loss: 2.1973214149475098
Validation loss: 1.932967847393405

Epoch: 6| Step: 7
Training loss: 1.848113775253296
Validation loss: 1.9274774225809241

Epoch: 6| Step: 8
Training loss: 1.4253735542297363
Validation loss: 1.9255728413981776

Epoch: 6| Step: 9
Training loss: 1.7613742351531982
Validation loss: 1.9246078255355998

Epoch: 6| Step: 10
Training loss: 1.9114552736282349
Validation loss: 1.932765499238045

Epoch: 6| Step: 11
Training loss: 2.1784939765930176
Validation loss: 1.930870698344323

Epoch: 6| Step: 12
Training loss: 2.986539363861084
Validation loss: 1.9264112864771197

Epoch: 6| Step: 13
Training loss: 2.6821632385253906
Validation loss: 1.9274448681903142

Epoch: 147| Step: 0
Training loss: 2.5324859619140625
Validation loss: 1.9224899174064718

Epoch: 6| Step: 1
Training loss: 2.0199403762817383
Validation loss: 1.9340137896999237

Epoch: 6| Step: 2
Training loss: 3.0723013877868652
Validation loss: 1.9468152382040536

Epoch: 6| Step: 3
Training loss: 2.2975780963897705
Validation loss: 1.9543880595955798

Epoch: 6| Step: 4
Training loss: 2.076500654220581
Validation loss: 1.959045587047454

Epoch: 6| Step: 5
Training loss: 1.400028944015503
Validation loss: 1.972497050480176

Epoch: 6| Step: 6
Training loss: 2.311142921447754
Validation loss: 1.9744842847188313

Epoch: 6| Step: 7
Training loss: 2.454066753387451
Validation loss: 1.9713101669024395

Epoch: 6| Step: 8
Training loss: 1.7145276069641113
Validation loss: 1.971859198744579

Epoch: 6| Step: 9
Training loss: 2.3118295669555664
Validation loss: 1.9499488722893499

Epoch: 6| Step: 10
Training loss: 2.3516221046447754
Validation loss: 1.9575373152250886

Epoch: 6| Step: 11
Training loss: 1.6610872745513916
Validation loss: 1.9552698776286135

Epoch: 6| Step: 12
Training loss: 2.3982136249542236
Validation loss: 1.9447230549268826

Epoch: 6| Step: 13
Training loss: 1.835335373878479
Validation loss: 1.9548379169997347

Epoch: 148| Step: 0
Training loss: 2.4123826026916504
Validation loss: 1.983692971608972

Epoch: 6| Step: 1
Training loss: 2.2356371879577637
Validation loss: 2.011701435171148

Epoch: 6| Step: 2
Training loss: 1.6440587043762207
Validation loss: 2.0175698290589037

Epoch: 6| Step: 3
Training loss: 2.7073748111724854
Validation loss: 1.9875639228410618

Epoch: 6| Step: 4
Training loss: 2.122802257537842
Validation loss: 1.981859258426133

Epoch: 6| Step: 5
Training loss: 1.2639597654342651
Validation loss: 1.9731955143713182

Epoch: 6| Step: 6
Training loss: 1.633772850036621
Validation loss: 1.9781689823314708

Epoch: 6| Step: 7
Training loss: 2.7900257110595703
Validation loss: 2.005026823730879

Epoch: 6| Step: 8
Training loss: 2.461566209793091
Validation loss: 2.0224721662459837

Epoch: 6| Step: 9
Training loss: 2.1708550453186035
Validation loss: 2.0221557745369534

Epoch: 6| Step: 10
Training loss: 2.300816059112549
Validation loss: 2.013737195281572

Epoch: 6| Step: 11
Training loss: 2.60915470123291
Validation loss: 2.0078408769381944

Epoch: 6| Step: 12
Training loss: 2.481991767883301
Validation loss: 1.9901608523502146

Epoch: 6| Step: 13
Training loss: 2.2905454635620117
Validation loss: 1.985374948029877

Epoch: 149| Step: 0
Training loss: 2.176337242126465
Validation loss: 1.9832971044766006

Epoch: 6| Step: 1
Training loss: 2.3625736236572266
Validation loss: 1.9914566099002797

Epoch: 6| Step: 2
Training loss: 1.0416444540023804
Validation loss: 2.0295443560487483

Epoch: 6| Step: 3
Training loss: 2.276224136352539
Validation loss: 2.0599592411389915

Epoch: 6| Step: 4
Training loss: 2.8471901416778564
Validation loss: 2.05470787068849

Epoch: 6| Step: 5
Training loss: 2.3295445442199707
Validation loss: 2.030360439772247

Epoch: 6| Step: 6
Training loss: 2.1568431854248047
Validation loss: 2.019823620396276

Epoch: 6| Step: 7
Training loss: 2.2142677307128906
Validation loss: 1.9961231267580422

Epoch: 6| Step: 8
Training loss: 1.9582078456878662
Validation loss: 2.0049031216611146

Epoch: 6| Step: 9
Training loss: 2.421204090118408
Validation loss: 1.9760236176111365

Epoch: 6| Step: 10
Training loss: 1.900683879852295
Validation loss: 1.9857400924928728

Epoch: 6| Step: 11
Training loss: 2.315042018890381
Validation loss: 1.983015896171652

Epoch: 6| Step: 12
Training loss: 2.7566487789154053
Validation loss: 1.9703271773553663

Epoch: 6| Step: 13
Training loss: 2.0001349449157715
Validation loss: 1.963196676264527

Epoch: 150| Step: 0
Training loss: 1.5155985355377197
Validation loss: 1.9609910147164458

Epoch: 6| Step: 1
Training loss: 2.0428366661071777
Validation loss: 1.943614516206967

Epoch: 6| Step: 2
Training loss: 1.4524787664413452
Validation loss: 1.9409640078903527

Epoch: 6| Step: 3
Training loss: 3.0244693756103516
Validation loss: 1.924425232794977

Epoch: 6| Step: 4
Training loss: 1.9825587272644043
Validation loss: 1.9376860613464026

Epoch: 6| Step: 5
Training loss: 1.5472006797790527
Validation loss: 1.92457075272837

Epoch: 6| Step: 6
Training loss: 2.452200412750244
Validation loss: 1.9340059629050634

Epoch: 6| Step: 7
Training loss: 2.6219100952148438
Validation loss: 1.930831673324749

Epoch: 6| Step: 8
Training loss: 2.1509439945220947
Validation loss: 1.9390484466347644

Epoch: 6| Step: 9
Training loss: 2.6408441066741943
Validation loss: 1.9487334951277702

Epoch: 6| Step: 10
Training loss: 2.062589645385742
Validation loss: 1.945587263312391

Epoch: 6| Step: 11
Training loss: 2.0319318771362305
Validation loss: 1.9639558343477146

Epoch: 6| Step: 12
Training loss: 2.0005764961242676
Validation loss: 1.9535575323207404

Epoch: 6| Step: 13
Training loss: 3.065315008163452
Validation loss: 1.9538022266921176

Epoch: 151| Step: 0
Training loss: 1.6139439344406128
Validation loss: 1.9638736248016357

Epoch: 6| Step: 1
Training loss: 2.121201992034912
Validation loss: 1.9559132437552176

Epoch: 6| Step: 2
Training loss: 2.1633238792419434
Validation loss: 1.9681237372018958

Epoch: 6| Step: 3
Training loss: 1.9440938234329224
Validation loss: 1.9715767496375627

Epoch: 6| Step: 4
Training loss: 2.204056978225708
Validation loss: 1.9830801563878213

Epoch: 6| Step: 5
Training loss: 2.3174691200256348
Validation loss: 1.959737382909303

Epoch: 6| Step: 6
Training loss: 2.3993287086486816
Validation loss: 1.973197147410403

Epoch: 6| Step: 7
Training loss: 1.9973171949386597
Validation loss: 1.9684652064436226

Epoch: 6| Step: 8
Training loss: 2.465500593185425
Validation loss: 1.9757339159647624

Epoch: 6| Step: 9
Training loss: 1.9565426111221313
Validation loss: 1.9883834726067

Epoch: 6| Step: 10
Training loss: 2.485170364379883
Validation loss: 1.9790963895859257

Epoch: 6| Step: 11
Training loss: 1.8023314476013184
Validation loss: 1.9851013896285847

Epoch: 6| Step: 12
Training loss: 2.724001407623291
Validation loss: 1.9926296523822251

Epoch: 6| Step: 13
Training loss: 1.4447131156921387
Validation loss: 2.0161203645890757

Epoch: 152| Step: 0
Training loss: 2.16257381439209
Validation loss: 2.048631065635271

Epoch: 6| Step: 1
Training loss: 2.0828912258148193
Validation loss: 2.041514132612495

Epoch: 6| Step: 2
Training loss: 2.345791816711426
Validation loss: 2.031156793717415

Epoch: 6| Step: 3
Training loss: 2.4482903480529785
Validation loss: 2.0277024956159693

Epoch: 6| Step: 4
Training loss: 1.5506572723388672
Validation loss: 2.029421241052689

Epoch: 6| Step: 5
Training loss: 2.999692440032959
Validation loss: 2.020261113361646

Epoch: 6| Step: 6
Training loss: 1.5495359897613525
Validation loss: 1.9942149577602264

Epoch: 6| Step: 7
Training loss: 2.035292148590088
Validation loss: 1.9729156455686014

Epoch: 6| Step: 8
Training loss: 2.3701305389404297
Validation loss: 1.9800250094424012

Epoch: 6| Step: 9
Training loss: 2.7530455589294434
Validation loss: 1.956787524684783

Epoch: 6| Step: 10
Training loss: 1.5858124494552612
Validation loss: 1.9720405917013846

Epoch: 6| Step: 11
Training loss: 2.184642791748047
Validation loss: 1.96817244509215

Epoch: 6| Step: 12
Training loss: 1.9919612407684326
Validation loss: 1.9701806422202819

Epoch: 6| Step: 13
Training loss: 1.5558923482894897
Validation loss: 1.9707785844802856

Epoch: 153| Step: 0
Training loss: 2.0596418380737305
Validation loss: 1.9926462173461914

Epoch: 6| Step: 1
Training loss: 1.9482533931732178
Validation loss: 1.9982752287259666

Epoch: 6| Step: 2
Training loss: 2.696967124938965
Validation loss: 1.9932492932965677

Epoch: 6| Step: 3
Training loss: 2.51983380317688
Validation loss: 2.0063894179559525

Epoch: 6| Step: 4
Training loss: 1.8564156293869019
Validation loss: 2.0097690115692797

Epoch: 6| Step: 5
Training loss: 2.252938985824585
Validation loss: 2.0032122981163765

Epoch: 6| Step: 6
Training loss: 2.176274538040161
Validation loss: 2.0249942041212514

Epoch: 6| Step: 7
Training loss: 2.743096113204956
Validation loss: 2.0114344563535465

Epoch: 6| Step: 8
Training loss: 2.134063243865967
Validation loss: 1.995972615416332

Epoch: 6| Step: 9
Training loss: 1.7182066440582275
Validation loss: 2.0115273203901065

Epoch: 6| Step: 10
Training loss: 1.387587547302246
Validation loss: 2.022730223594173

Epoch: 6| Step: 11
Training loss: 1.8377588987350464
Validation loss: 2.0146110275740265

Epoch: 6| Step: 12
Training loss: 1.9123423099517822
Validation loss: 2.0195713581577426

Epoch: 6| Step: 13
Training loss: 2.0101511478424072
Validation loss: 2.007992905955161

Epoch: 154| Step: 0
Training loss: 2.5184292793273926
Validation loss: 2.003933100290196

Epoch: 6| Step: 1
Training loss: 2.216075897216797
Validation loss: 1.9840001188298708

Epoch: 6| Step: 2
Training loss: 1.5940486192703247
Validation loss: 1.9568633059019684

Epoch: 6| Step: 3
Training loss: 2.4200167655944824
Validation loss: 1.9518123672854515

Epoch: 6| Step: 4
Training loss: 2.2940258979797363
Validation loss: 1.9591153193545598

Epoch: 6| Step: 5
Training loss: 1.4440901279449463
Validation loss: 1.9526581751402987

Epoch: 6| Step: 6
Training loss: 1.8017200231552124
Validation loss: 1.939312022219422

Epoch: 6| Step: 7
Training loss: 2.164827585220337
Validation loss: 1.9302838797210364

Epoch: 6| Step: 8
Training loss: 1.8717482089996338
Validation loss: 1.9291354520346529

Epoch: 6| Step: 9
Training loss: 1.6081925630569458
Validation loss: 1.9424908135526924

Epoch: 6| Step: 10
Training loss: 2.5516037940979004
Validation loss: 1.9509395630128923

Epoch: 6| Step: 11
Training loss: 2.0655555725097656
Validation loss: 1.9514624200841433

Epoch: 6| Step: 12
Training loss: 2.906385660171509
Validation loss: 1.9621638559526013

Epoch: 6| Step: 13
Training loss: 1.8004510402679443
Validation loss: 1.9601093248654438

Epoch: 155| Step: 0
Training loss: 2.254220485687256
Validation loss: 1.9766146726505731

Epoch: 6| Step: 1
Training loss: 2.2913389205932617
Validation loss: 1.9945546170716644

Epoch: 6| Step: 2
Training loss: 2.2680373191833496
Validation loss: 2.0033584205053185

Epoch: 6| Step: 3
Training loss: 2.330515146255493
Validation loss: 1.994628716540593

Epoch: 6| Step: 4
Training loss: 2.140566349029541
Validation loss: 2.0171244387985556

Epoch: 6| Step: 5
Training loss: 2.5741961002349854
Validation loss: 2.03050664676133

Epoch: 6| Step: 6
Training loss: 1.5541472434997559
Validation loss: 2.0396756254216677

Epoch: 6| Step: 7
Training loss: 1.821138620376587
Validation loss: 2.0156115203775387

Epoch: 6| Step: 8
Training loss: 2.3664793968200684
Validation loss: 2.0123817830957393

Epoch: 6| Step: 9
Training loss: 1.4901351928710938
Validation loss: 2.0135261499753563

Epoch: 6| Step: 10
Training loss: 1.9202880859375
Validation loss: 2.0044602886323006

Epoch: 6| Step: 11
Training loss: 2.152522563934326
Validation loss: 2.0048491493348153

Epoch: 6| Step: 12
Training loss: 2.381716251373291
Validation loss: 2.013594477407394

Epoch: 6| Step: 13
Training loss: 1.590185284614563
Validation loss: 2.014251684629789

Epoch: 156| Step: 0
Training loss: 2.449580192565918
Validation loss: 1.9948322619161298

Epoch: 6| Step: 1
Training loss: 2.7361185550689697
Validation loss: 2.0344038330098635

Epoch: 6| Step: 2
Training loss: 2.128497838973999
Validation loss: 2.0336408204929803

Epoch: 6| Step: 3
Training loss: 2.301990270614624
Validation loss: 2.058498751732611

Epoch: 6| Step: 4
Training loss: 1.4800735712051392
Validation loss: 2.059208695606519

Epoch: 6| Step: 5
Training loss: 1.6642078161239624
Validation loss: 2.035330225062627

Epoch: 6| Step: 6
Training loss: 2.28531551361084
Validation loss: 2.0136791865030923

Epoch: 6| Step: 7
Training loss: 2.056683301925659
Validation loss: 2.010512307126035

Epoch: 6| Step: 8
Training loss: 1.815406084060669
Validation loss: 2.002114208795691

Epoch: 6| Step: 9
Training loss: 2.107800006866455
Validation loss: 1.9792643529112621

Epoch: 6| Step: 10
Training loss: 1.7853566408157349
Validation loss: 1.97539000357351

Epoch: 6| Step: 11
Training loss: 2.298612117767334
Validation loss: 1.979056219900808

Epoch: 6| Step: 12
Training loss: 2.289639472961426
Validation loss: 1.9875963964769918

Epoch: 6| Step: 13
Training loss: 1.413175106048584
Validation loss: 1.9625472612278436

Epoch: 157| Step: 0
Training loss: 2.003814458847046
Validation loss: 1.9558198887814757

Epoch: 6| Step: 1
Training loss: 2.1274290084838867
Validation loss: 1.9670517188246532

Epoch: 6| Step: 2
Training loss: 2.7262656688690186
Validation loss: 1.9824409869409376

Epoch: 6| Step: 3
Training loss: 1.8873871564865112
Validation loss: 1.9826983033969838

Epoch: 6| Step: 4
Training loss: 1.4595777988433838
Validation loss: 1.9842045307159424

Epoch: 6| Step: 5
Training loss: 2.3023154735565186
Validation loss: 1.9751711622361214

Epoch: 6| Step: 6
Training loss: 2.7580418586730957
Validation loss: 1.9573282221312165

Epoch: 6| Step: 7
Training loss: 0.793889582157135
Validation loss: 1.9653285382896342

Epoch: 6| Step: 8
Training loss: 2.439906358718872
Validation loss: 1.9532067314271004

Epoch: 6| Step: 9
Training loss: 1.7344356775283813
Validation loss: 1.9558839797973633

Epoch: 6| Step: 10
Training loss: 2.8015379905700684
Validation loss: 1.9472308287056543

Epoch: 6| Step: 11
Training loss: 1.4739055633544922
Validation loss: 1.9456087594391198

Epoch: 6| Step: 12
Training loss: 2.021676540374756
Validation loss: 1.943227134725099

Epoch: 6| Step: 13
Training loss: 2.642991781234741
Validation loss: 1.9617806250049221

Epoch: 158| Step: 0
Training loss: 2.447336435317993
Validation loss: 1.9878234196734685

Epoch: 6| Step: 1
Training loss: 2.248541831970215
Validation loss: 1.9818019405488045

Epoch: 6| Step: 2
Training loss: 2.4434773921966553
Validation loss: 1.9915606732009559

Epoch: 6| Step: 3
Training loss: 2.722405195236206
Validation loss: 1.993082627173393

Epoch: 6| Step: 4
Training loss: 1.7846393585205078
Validation loss: 1.9956754766484743

Epoch: 6| Step: 5
Training loss: 2.105349540710449
Validation loss: 1.997024054168373

Epoch: 6| Step: 6
Training loss: 1.3094673156738281
Validation loss: 1.9963083523575977

Epoch: 6| Step: 7
Training loss: 1.4289997816085815
Validation loss: 2.0048323677432154

Epoch: 6| Step: 8
Training loss: 2.1061811447143555
Validation loss: 2.003581016294418

Epoch: 6| Step: 9
Training loss: 2.1388792991638184
Validation loss: 1.9981183569918397

Epoch: 6| Step: 10
Training loss: 1.9949532747268677
Validation loss: 1.992152137141074

Epoch: 6| Step: 11
Training loss: 1.9131819009780884
Validation loss: 1.9759596111953899

Epoch: 6| Step: 12
Training loss: 2.2164621353149414
Validation loss: 1.97657528743949

Epoch: 6| Step: 13
Training loss: 2.262356758117676
Validation loss: 1.991056626842868

Epoch: 159| Step: 0
Training loss: 1.8402225971221924
Validation loss: 2.0702535926654773

Epoch: 6| Step: 1
Training loss: 2.243680000305176
Validation loss: 2.1327388466045423

Epoch: 6| Step: 2
Training loss: 2.6936941146850586
Validation loss: 2.168067214309528

Epoch: 6| Step: 3
Training loss: 2.472550868988037
Validation loss: 2.164288943813693

Epoch: 6| Step: 4
Training loss: 2.5705578327178955
Validation loss: 2.1189266609889206

Epoch: 6| Step: 5
Training loss: 2.6793899536132812
Validation loss: 2.0380727296234458

Epoch: 6| Step: 6
Training loss: 1.7782385349273682
Validation loss: 1.9925080768523677

Epoch: 6| Step: 7
Training loss: 2.191760540008545
Validation loss: 1.9917786223914034

Epoch: 6| Step: 8
Training loss: 2.236043930053711
Validation loss: 1.9766750592057423

Epoch: 6| Step: 9
Training loss: 1.403747797012329
Validation loss: 1.9688230663217523

Epoch: 6| Step: 10
Training loss: 2.1385011672973633
Validation loss: 1.974294541984476

Epoch: 6| Step: 11
Training loss: 2.2819957733154297
Validation loss: 1.977018512705321

Epoch: 6| Step: 12
Training loss: 1.315576434135437
Validation loss: 1.9861619857049757

Epoch: 6| Step: 13
Training loss: 2.2871310710906982
Validation loss: 1.9898246770264

Epoch: 160| Step: 0
Training loss: 2.4409756660461426
Validation loss: 1.9926405260639806

Epoch: 6| Step: 1
Training loss: 1.4145665168762207
Validation loss: 1.9875641881778676

Epoch: 6| Step: 2
Training loss: 2.0094048976898193
Validation loss: 1.9899974971689203

Epoch: 6| Step: 3
Training loss: 1.847346544265747
Validation loss: 1.9954392961276475

Epoch: 6| Step: 4
Training loss: 1.7527437210083008
Validation loss: 2.0015276670455933

Epoch: 6| Step: 5
Training loss: 2.134335994720459
Validation loss: 2.0139267354883175

Epoch: 6| Step: 6
Training loss: 2.2788186073303223
Validation loss: 2.0106687135593866

Epoch: 6| Step: 7
Training loss: 1.9873664379119873
Validation loss: 2.032728966846261

Epoch: 6| Step: 8
Training loss: 2.3717989921569824
Validation loss: 2.021853400814918

Epoch: 6| Step: 9
Training loss: 2.564802408218384
Validation loss: 2.027960092790665

Epoch: 6| Step: 10
Training loss: 1.8322699069976807
Validation loss: 2.012636971730058

Epoch: 6| Step: 11
Training loss: 2.284113645553589
Validation loss: 2.0352889812120827

Epoch: 6| Step: 12
Training loss: 1.837633490562439
Validation loss: 2.026640046027399

Epoch: 6| Step: 13
Training loss: 1.4333863258361816
Validation loss: 2.015494187672933

Epoch: 161| Step: 0
Training loss: 2.3279566764831543
Validation loss: 2.015456062491222

Epoch: 6| Step: 1
Training loss: 2.6124978065490723
Validation loss: 2.021986643473307

Epoch: 6| Step: 2
Training loss: 1.5510234832763672
Validation loss: 2.007423690570298

Epoch: 6| Step: 3
Training loss: 2.2391958236694336
Validation loss: 1.993816001440889

Epoch: 6| Step: 4
Training loss: 1.931373953819275
Validation loss: 1.9926355602920696

Epoch: 6| Step: 5
Training loss: 1.6053577661514282
Validation loss: 1.9765121052342076

Epoch: 6| Step: 6
Training loss: 1.412285327911377
Validation loss: 1.969194463504258

Epoch: 6| Step: 7
Training loss: 1.8536269664764404
Validation loss: 1.9833568642216344

Epoch: 6| Step: 8
Training loss: 2.1860687732696533
Validation loss: 1.9832583729938795

Epoch: 6| Step: 9
Training loss: 2.45955753326416
Validation loss: 1.9854043017151535

Epoch: 6| Step: 10
Training loss: 1.4247684478759766
Validation loss: 1.9946236148957284

Epoch: 6| Step: 11
Training loss: 2.312795639038086
Validation loss: 1.9901966023188766

Epoch: 6| Step: 12
Training loss: 2.429887294769287
Validation loss: 1.988498733889672

Epoch: 6| Step: 13
Training loss: 1.718180775642395
Validation loss: 1.9736412904595817

Epoch: 162| Step: 0
Training loss: 2.103952407836914
Validation loss: 1.970646499305643

Epoch: 6| Step: 1
Training loss: 1.3620848655700684
Validation loss: 1.9623551445622598

Epoch: 6| Step: 2
Training loss: 1.757577896118164
Validation loss: 1.9496506080832532

Epoch: 6| Step: 3
Training loss: 1.8143644332885742
Validation loss: 1.946758734282627

Epoch: 6| Step: 4
Training loss: 1.7020295858383179
Validation loss: 1.9742762529721825

Epoch: 6| Step: 5
Training loss: 2.320270538330078
Validation loss: 1.9719909801278064

Epoch: 6| Step: 6
Training loss: 1.8072893619537354
Validation loss: 1.980844941190494

Epoch: 6| Step: 7
Training loss: 2.6485989093780518
Validation loss: 1.9813055171761462

Epoch: 6| Step: 8
Training loss: 2.317064046859741
Validation loss: 1.9771178858254546

Epoch: 6| Step: 9
Training loss: 2.61852765083313
Validation loss: 1.9640509159334245

Epoch: 6| Step: 10
Training loss: 2.53350567817688
Validation loss: 1.9690315877237627

Epoch: 6| Step: 11
Training loss: 1.589310884475708
Validation loss: 1.9738207094130977

Epoch: 6| Step: 12
Training loss: 1.8631268739700317
Validation loss: 1.9754860131971297

Epoch: 6| Step: 13
Training loss: 1.5140738487243652
Validation loss: 1.9757537893069688

Epoch: 163| Step: 0
Training loss: 1.580307960510254
Validation loss: 1.9836679197126819

Epoch: 6| Step: 1
Training loss: 1.6871936321258545
Validation loss: 1.9806470076243083

Epoch: 6| Step: 2
Training loss: 2.5076634883880615
Validation loss: 1.9866124994011336

Epoch: 6| Step: 3
Training loss: 2.4198076725006104
Validation loss: 2.0068243459988664

Epoch: 6| Step: 4
Training loss: 1.392103910446167
Validation loss: 1.9963491719256166

Epoch: 6| Step: 5
Training loss: 2.471543312072754
Validation loss: 2.018280607397838

Epoch: 6| Step: 6
Training loss: 1.911089539527893
Validation loss: 2.0165226459503174

Epoch: 6| Step: 7
Training loss: 2.340064287185669
Validation loss: 2.022537777500768

Epoch: 6| Step: 8
Training loss: 2.1142284870147705
Validation loss: 2.016449207900673

Epoch: 6| Step: 9
Training loss: 2.3366246223449707
Validation loss: 2.015741443121305

Epoch: 6| Step: 10
Training loss: 1.9596128463745117
Validation loss: 2.0083187549344954

Epoch: 6| Step: 11
Training loss: 1.4811540842056274
Validation loss: 2.008323338723952

Epoch: 6| Step: 12
Training loss: 2.116971254348755
Validation loss: 2.002843654283913

Epoch: 6| Step: 13
Training loss: 1.7139846086502075
Validation loss: 1.9991775071749123

Epoch: 164| Step: 0
Training loss: 1.7374707460403442
Validation loss: 2.0001180941058743

Epoch: 6| Step: 1
Training loss: 1.7996585369110107
Validation loss: 1.9719927246852587

Epoch: 6| Step: 2
Training loss: 2.275716781616211
Validation loss: 1.957539794265583

Epoch: 6| Step: 3
Training loss: 1.554649829864502
Validation loss: 1.9978188122472456

Epoch: 6| Step: 4
Training loss: 2.2116751670837402
Validation loss: 2.05512600047614

Epoch: 6| Step: 5
Training loss: 1.4524381160736084
Validation loss: 2.0420881125234787

Epoch: 6| Step: 6
Training loss: 1.9939274787902832
Validation loss: 2.0234123276126

Epoch: 6| Step: 7
Training loss: 3.1385788917541504
Validation loss: 1.9972887962095198

Epoch: 6| Step: 8
Training loss: 1.7591904401779175
Validation loss: 1.9977679585897794

Epoch: 6| Step: 9
Training loss: 2.1924941539764404
Validation loss: 1.9909878879465082

Epoch: 6| Step: 10
Training loss: 2.562859535217285
Validation loss: 2.016570073302074

Epoch: 6| Step: 11
Training loss: 2.0995469093322754
Validation loss: 2.0591972489510812

Epoch: 6| Step: 12
Training loss: 2.391284942626953
Validation loss: 2.0961515852200088

Epoch: 6| Step: 13
Training loss: 1.2651362419128418
Validation loss: 2.1198869341163227

Epoch: 165| Step: 0
Training loss: 2.5205464363098145
Validation loss: 2.126213768477081

Epoch: 6| Step: 1
Training loss: 2.74042010307312
Validation loss: 2.0809035480663343

Epoch: 6| Step: 2
Training loss: 1.7797200679779053
Validation loss: 2.0593014647883754

Epoch: 6| Step: 3
Training loss: 2.4997031688690186
Validation loss: 2.04036424749641

Epoch: 6| Step: 4
Training loss: 1.6494648456573486
Validation loss: 2.0694004963803034

Epoch: 6| Step: 5
Training loss: 1.6734449863433838
Validation loss: 2.109819657059126

Epoch: 6| Step: 6
Training loss: 2.0877065658569336
Validation loss: 2.124266411668511

Epoch: 6| Step: 7
Training loss: 2.2033209800720215
Validation loss: 2.1394727537708897

Epoch: 6| Step: 8
Training loss: 2.3701043128967285
Validation loss: 2.150281721545804

Epoch: 6| Step: 9
Training loss: 2.5032007694244385
Validation loss: 2.080070980133549

Epoch: 6| Step: 10
Training loss: 1.517825961112976
Validation loss: 1.9823005122523154

Epoch: 6| Step: 11
Training loss: 1.6471424102783203
Validation loss: 1.99233772805942

Epoch: 6| Step: 12
Training loss: 2.5960850715637207
Validation loss: 2.007917732320806

Epoch: 6| Step: 13
Training loss: 2.6363039016723633
Validation loss: 2.050290410236646

Epoch: 166| Step: 0
Training loss: 2.2290170192718506
Validation loss: 2.058364842527656

Epoch: 6| Step: 1
Training loss: 1.9453320503234863
Validation loss: 2.0466839856998895

Epoch: 6| Step: 2
Training loss: 2.562763214111328
Validation loss: 1.9910760861571117

Epoch: 6| Step: 3
Training loss: 1.772825002670288
Validation loss: 1.9678598680803854

Epoch: 6| Step: 4
Training loss: 1.7115219831466675
Validation loss: 1.9467036672817764

Epoch: 6| Step: 5
Training loss: 1.638949990272522
Validation loss: 1.9542219254278368

Epoch: 6| Step: 6
Training loss: 2.2710325717926025
Validation loss: 1.981184482574463

Epoch: 6| Step: 7
Training loss: 1.8751269578933716
Validation loss: 1.9939762815352409

Epoch: 6| Step: 8
Training loss: 2.283827304840088
Validation loss: 2.02036843633139

Epoch: 6| Step: 9
Training loss: 1.9434922933578491
Validation loss: 2.014609795744701

Epoch: 6| Step: 10
Training loss: 1.9702348709106445
Validation loss: 1.999885694954985

Epoch: 6| Step: 11
Training loss: 2.3809432983398438
Validation loss: 2.0162712117677093

Epoch: 6| Step: 12
Training loss: 2.1765878200531006
Validation loss: 2.0118849149314304

Epoch: 6| Step: 13
Training loss: 1.6040894985198975
Validation loss: 2.013385010021989

Epoch: 167| Step: 0
Training loss: 1.557690143585205
Validation loss: 2.008504657335179

Epoch: 6| Step: 1
Training loss: 2.2563905715942383
Validation loss: 2.014503138039702

Epoch: 6| Step: 2
Training loss: 1.657364845275879
Validation loss: 2.0056019290801017

Epoch: 6| Step: 3
Training loss: 1.8723986148834229
Validation loss: 2.0192432224109607

Epoch: 6| Step: 4
Training loss: 1.9513953924179077
Validation loss: 2.033030915003951

Epoch: 6| Step: 5
Training loss: 2.395658016204834
Validation loss: 2.037626535661759

Epoch: 6| Step: 6
Training loss: 1.9006149768829346
Validation loss: 2.0503946196648384

Epoch: 6| Step: 7
Training loss: 1.8454465866088867
Validation loss: 2.04563142407325

Epoch: 6| Step: 8
Training loss: 2.189377784729004
Validation loss: 2.028025201571885

Epoch: 6| Step: 9
Training loss: 1.9118927717208862
Validation loss: 2.0194170936461417

Epoch: 6| Step: 10
Training loss: 1.838902235031128
Validation loss: 2.007053259880312

Epoch: 6| Step: 11
Training loss: 2.4515371322631836
Validation loss: 1.980977637793428

Epoch: 6| Step: 12
Training loss: 2.3341317176818848
Validation loss: 1.9813265569748417

Epoch: 6| Step: 13
Training loss: 1.7854218482971191
Validation loss: 1.9848290848475632

Epoch: 168| Step: 0
Training loss: 1.938024878501892
Validation loss: 1.9687268028977096

Epoch: 6| Step: 1
Training loss: 1.5581488609313965
Validation loss: 1.9744804879670501

Epoch: 6| Step: 2
Training loss: 2.298311233520508
Validation loss: 1.9808110639613161

Epoch: 6| Step: 3
Training loss: 2.531765937805176
Validation loss: 1.978623579907161

Epoch: 6| Step: 4
Training loss: 2.0008182525634766
Validation loss: 1.9750364083115772

Epoch: 6| Step: 5
Training loss: 1.5636006593704224
Validation loss: 1.9629459252921484

Epoch: 6| Step: 6
Training loss: 1.2986629009246826
Validation loss: 1.9869544967528312

Epoch: 6| Step: 7
Training loss: 1.5045582056045532
Validation loss: 1.99300766247575

Epoch: 6| Step: 8
Training loss: 1.9188601970672607
Validation loss: 1.98677408823403

Epoch: 6| Step: 9
Training loss: 2.0827078819274902
Validation loss: 1.9894298391957437

Epoch: 6| Step: 10
Training loss: 1.9351696968078613
Validation loss: 2.0001589470012213

Epoch: 6| Step: 11
Training loss: 2.1161952018737793
Validation loss: 1.9972051651247087

Epoch: 6| Step: 12
Training loss: 2.3235855102539062
Validation loss: 2.0247312489376275

Epoch: 6| Step: 13
Training loss: 2.5121922492980957
Validation loss: 2.023539147069377

Epoch: 169| Step: 0
Training loss: 1.6703513860702515
Validation loss: 2.0315007471269175

Epoch: 6| Step: 1
Training loss: 2.8001370429992676
Validation loss: 2.03180698169175

Epoch: 6| Step: 2
Training loss: 2.317760467529297
Validation loss: 2.011752405474263

Epoch: 6| Step: 3
Training loss: 1.101767659187317
Validation loss: 1.9760832068740681

Epoch: 6| Step: 4
Training loss: 1.953195571899414
Validation loss: 2.001053034618337

Epoch: 6| Step: 5
Training loss: 2.5506515502929688
Validation loss: 1.983833634725181

Epoch: 6| Step: 6
Training loss: 1.866170883178711
Validation loss: 1.9725442048042052

Epoch: 6| Step: 7
Training loss: 2.5335135459899902
Validation loss: 1.9636028915323236

Epoch: 6| Step: 8
Training loss: 1.5624226331710815
Validation loss: 1.9493906741501184

Epoch: 6| Step: 9
Training loss: 1.4577049016952515
Validation loss: 1.9533977354726484

Epoch: 6| Step: 10
Training loss: 2.1143431663513184
Validation loss: 1.950341054188308

Epoch: 6| Step: 11
Training loss: 2.034369468688965
Validation loss: 1.9696542716795398

Epoch: 6| Step: 12
Training loss: 1.8318018913269043
Validation loss: 1.950001948623247

Epoch: 6| Step: 13
Training loss: 1.1870802640914917
Validation loss: 1.9575842106214134

Epoch: 170| Step: 0
Training loss: 1.6932852268218994
Validation loss: 1.9830099292980727

Epoch: 6| Step: 1
Training loss: 1.5624312162399292
Validation loss: 1.9826400074907529

Epoch: 6| Step: 2
Training loss: 2.8202595710754395
Validation loss: 2.007614717688612

Epoch: 6| Step: 3
Training loss: 1.1191096305847168
Validation loss: 2.025558784443845

Epoch: 6| Step: 4
Training loss: 2.2483391761779785
Validation loss: 2.0348749904222387

Epoch: 6| Step: 5
Training loss: 1.3594651222229004
Validation loss: 2.042711801426385

Epoch: 6| Step: 6
Training loss: 1.667421817779541
Validation loss: 2.0205633819744153

Epoch: 6| Step: 7
Training loss: 2.4024577140808105
Validation loss: 2.015381000375235

Epoch: 6| Step: 8
Training loss: 2.0301120281219482
Validation loss: 1.9866512795930267

Epoch: 6| Step: 9
Training loss: 2.282576560974121
Validation loss: 1.9851872305716238

Epoch: 6| Step: 10
Training loss: 2.4696998596191406
Validation loss: 2.0052291013861216

Epoch: 6| Step: 11
Training loss: 1.8316500186920166
Validation loss: 1.9964349064775693

Epoch: 6| Step: 12
Training loss: 1.529223084449768
Validation loss: 2.016646881257334

Epoch: 6| Step: 13
Training loss: 1.5495095252990723
Validation loss: 2.0278455672725553

Epoch: 171| Step: 0
Training loss: 2.063669443130493
Validation loss: 2.052678044124316

Epoch: 6| Step: 1
Training loss: 2.221418619155884
Validation loss: 2.0402857103655414

Epoch: 6| Step: 2
Training loss: 2.470224142074585
Validation loss: 2.0175996083085255

Epoch: 6| Step: 3
Training loss: 1.9576303958892822
Validation loss: 1.9997201068426973

Epoch: 6| Step: 4
Training loss: 2.1062111854553223
Validation loss: 1.9969872505434099

Epoch: 6| Step: 5
Training loss: 2.205477714538574
Validation loss: 2.004921382473361

Epoch: 6| Step: 6
Training loss: 1.3875689506530762
Validation loss: 2.0242492537344656

Epoch: 6| Step: 7
Training loss: 1.9453364610671997
Validation loss: 2.0336209497144146

Epoch: 6| Step: 8
Training loss: 2.355639696121216
Validation loss: 1.993288169624985

Epoch: 6| Step: 9
Training loss: 1.7139285802841187
Validation loss: 1.9940171536578928

Epoch: 6| Step: 10
Training loss: 1.7275667190551758
Validation loss: 1.9714402678192302

Epoch: 6| Step: 11
Training loss: 2.050434112548828
Validation loss: 1.9461084232535413

Epoch: 6| Step: 12
Training loss: 1.3050868511199951
Validation loss: 1.9490618346839823

Epoch: 6| Step: 13
Training loss: 2.0321693420410156
Validation loss: 1.949195610579624

Epoch: 172| Step: 0
Training loss: 1.5299065113067627
Validation loss: 1.9581356599766722

Epoch: 6| Step: 1
Training loss: 2.382578134536743
Validation loss: 1.9719529331371348

Epoch: 6| Step: 2
Training loss: 1.364052414894104
Validation loss: 1.9775862116967478

Epoch: 6| Step: 3
Training loss: 1.9684178829193115
Validation loss: 1.9882862273082937

Epoch: 6| Step: 4
Training loss: 2.1915221214294434
Validation loss: 2.01221279944143

Epoch: 6| Step: 5
Training loss: 2.559389591217041
Validation loss: 2.0170379223362094

Epoch: 6| Step: 6
Training loss: 1.6341196298599243
Validation loss: 2.0407811159728677

Epoch: 6| Step: 7
Training loss: 2.1696207523345947
Validation loss: 2.037571204605923

Epoch: 6| Step: 8
Training loss: 1.0323004722595215
Validation loss: 2.0229571775723527

Epoch: 6| Step: 9
Training loss: 2.2560653686523438
Validation loss: 1.9996424054586759

Epoch: 6| Step: 10
Training loss: 1.921401858329773
Validation loss: 1.9769915034694057

Epoch: 6| Step: 11
Training loss: 1.7135670185089111
Validation loss: 1.9695423341566516

Epoch: 6| Step: 12
Training loss: 2.296360969543457
Validation loss: 1.9718673126671904

Epoch: 6| Step: 13
Training loss: 2.075251579284668
Validation loss: 1.9439084042784989

Epoch: 173| Step: 0
Training loss: 1.914401888847351
Validation loss: 1.9306725045686126

Epoch: 6| Step: 1
Training loss: 2.484943389892578
Validation loss: 1.9485204835091867

Epoch: 6| Step: 2
Training loss: 1.872116208076477
Validation loss: 1.9413415565285632

Epoch: 6| Step: 3
Training loss: 1.5567588806152344
Validation loss: 1.9882671961220362

Epoch: 6| Step: 4
Training loss: 1.736797571182251
Validation loss: 2.0307667422038254

Epoch: 6| Step: 5
Training loss: 1.673172950744629
Validation loss: 2.0317044617027364

Epoch: 6| Step: 6
Training loss: 2.344576835632324
Validation loss: 2.029637475167551

Epoch: 6| Step: 7
Training loss: 2.0580530166625977
Validation loss: 2.007728415150796

Epoch: 6| Step: 8
Training loss: 1.383905053138733
Validation loss: 1.9679621035052883

Epoch: 6| Step: 9
Training loss: 1.6652531623840332
Validation loss: 1.9664664883767404

Epoch: 6| Step: 10
Training loss: 1.6064634323120117
Validation loss: 1.95013992504407

Epoch: 6| Step: 11
Training loss: 2.6888508796691895
Validation loss: 1.9599430612338486

Epoch: 6| Step: 12
Training loss: 2.719001054763794
Validation loss: 1.966354282953406

Epoch: 6| Step: 13
Training loss: 1.2354336977005005
Validation loss: 1.9964845116420458

Epoch: 174| Step: 0
Training loss: 2.3555727005004883
Validation loss: 2.0026190345005324

Epoch: 6| Step: 1
Training loss: 2.597642421722412
Validation loss: 2.0058994690577188

Epoch: 6| Step: 2
Training loss: 2.304199457168579
Validation loss: 2.030506839034378

Epoch: 6| Step: 3
Training loss: 1.6543036699295044
Validation loss: 2.0717072743241505

Epoch: 6| Step: 4
Training loss: 1.8492012023925781
Validation loss: 2.0696990438686904

Epoch: 6| Step: 5
Training loss: 2.329799175262451
Validation loss: 2.0349938536203034

Epoch: 6| Step: 6
Training loss: 1.5236773490905762
Validation loss: 2.0080410703536002

Epoch: 6| Step: 7
Training loss: 1.4996329545974731
Validation loss: 2.0012426466070194

Epoch: 6| Step: 8
Training loss: 2.010173797607422
Validation loss: 2.021011696066908

Epoch: 6| Step: 9
Training loss: 1.852818489074707
Validation loss: 2.0210538910281275

Epoch: 6| Step: 10
Training loss: 2.164351463317871
Validation loss: 1.98138443885311

Epoch: 6| Step: 11
Training loss: 0.8392161726951599
Validation loss: 1.96216574663757

Epoch: 6| Step: 12
Training loss: 2.633859157562256
Validation loss: 1.947959005191762

Epoch: 6| Step: 13
Training loss: 1.850212574005127
Validation loss: 1.9664574874344694

Epoch: 175| Step: 0
Training loss: 2.1593027114868164
Validation loss: 1.9554498580194288

Epoch: 6| Step: 1
Training loss: 2.250922918319702
Validation loss: 1.954480851850202

Epoch: 6| Step: 2
Training loss: 1.3448549509048462
Validation loss: 1.9635755144139773

Epoch: 6| Step: 3
Training loss: 1.1476415395736694
Validation loss: 1.9559310264484857

Epoch: 6| Step: 4
Training loss: 1.934943437576294
Validation loss: 1.9505793074125886

Epoch: 6| Step: 5
Training loss: 1.9066495895385742
Validation loss: 1.9567189998524164

Epoch: 6| Step: 6
Training loss: 2.056178569793701
Validation loss: 1.9745431151441348

Epoch: 6| Step: 7
Training loss: 1.8932069540023804
Validation loss: 1.9864265752095047

Epoch: 6| Step: 8
Training loss: 2.0067636966705322
Validation loss: 1.9895649725391018

Epoch: 6| Step: 9
Training loss: 2.3019442558288574
Validation loss: 1.9719883575234363

Epoch: 6| Step: 10
Training loss: 1.6833845376968384
Validation loss: 1.9417087416495047

Epoch: 6| Step: 11
Training loss: 2.055680990219116
Validation loss: 1.9384803874518282

Epoch: 6| Step: 12
Training loss: 2.357862710952759
Validation loss: 1.9443027870629424

Epoch: 6| Step: 13
Training loss: 1.6471991539001465
Validation loss: 1.9367257266916253

Epoch: 176| Step: 0
Training loss: 1.9523322582244873
Validation loss: 1.9483030585832493

Epoch: 6| Step: 1
Training loss: 1.4230254888534546
Validation loss: 1.9654849293411418

Epoch: 6| Step: 2
Training loss: 1.583179235458374
Validation loss: 1.9424526614527549

Epoch: 6| Step: 3
Training loss: 2.280412197113037
Validation loss: 1.9681013117554367

Epoch: 6| Step: 4
Training loss: 2.6102254390716553
Validation loss: 1.9853601891507384

Epoch: 6| Step: 5
Training loss: 1.8395230770111084
Validation loss: 1.982708320822767

Epoch: 6| Step: 6
Training loss: 1.708225131034851
Validation loss: 2.0068637145462858

Epoch: 6| Step: 7
Training loss: 1.8111417293548584
Validation loss: 2.0087500272258634

Epoch: 6| Step: 8
Training loss: 1.834197759628296
Validation loss: 1.981630084335163

Epoch: 6| Step: 9
Training loss: 1.922924280166626
Validation loss: 1.9952486099735383

Epoch: 6| Step: 10
Training loss: 1.8309892416000366
Validation loss: 1.971329407025409

Epoch: 6| Step: 11
Training loss: 1.999241828918457
Validation loss: 1.9519838466439197

Epoch: 6| Step: 12
Training loss: 1.9246244430541992
Validation loss: 1.9555953702618998

Epoch: 6| Step: 13
Training loss: 1.8836042881011963
Validation loss: 1.9577500640705068

Epoch: 177| Step: 0
Training loss: 1.2236804962158203
Validation loss: 1.973448032973915

Epoch: 6| Step: 1
Training loss: 1.6225303411483765
Validation loss: 1.9690157495519167

Epoch: 6| Step: 2
Training loss: 2.5547614097595215
Validation loss: 1.959913884439776

Epoch: 6| Step: 3
Training loss: 1.4179155826568604
Validation loss: 1.9499909967504523

Epoch: 6| Step: 4
Training loss: 2.3462514877319336
Validation loss: 1.9772867746250604

Epoch: 6| Step: 5
Training loss: 1.9298086166381836
Validation loss: 1.980327795910579

Epoch: 6| Step: 6
Training loss: 1.6614348888397217
Validation loss: 1.9676351752332462

Epoch: 6| Step: 7
Training loss: 1.645704984664917
Validation loss: 2.003994118782782

Epoch: 6| Step: 8
Training loss: 1.9463547468185425
Validation loss: 1.9990573929202171

Epoch: 6| Step: 9
Training loss: 1.7592754364013672
Validation loss: 1.9759625106729486

Epoch: 6| Step: 10
Training loss: 2.5041871070861816
Validation loss: 1.9608582168497064

Epoch: 6| Step: 11
Training loss: 2.1201698780059814
Validation loss: 1.9379444609406173

Epoch: 6| Step: 12
Training loss: 1.7047476768493652
Validation loss: 1.9232692667233047

Epoch: 6| Step: 13
Training loss: 1.5781148672103882
Validation loss: 1.931249192965928

Epoch: 178| Step: 0
Training loss: 1.9963455200195312
Validation loss: 1.9586769893605223

Epoch: 6| Step: 1
Training loss: 2.2071821689605713
Validation loss: 1.970133222559447

Epoch: 6| Step: 2
Training loss: 1.726330041885376
Validation loss: 1.9940316548911474

Epoch: 6| Step: 3
Training loss: 1.4761443138122559
Validation loss: 2.0176514502494567

Epoch: 6| Step: 4
Training loss: 2.298320770263672
Validation loss: 2.0145954816572127

Epoch: 6| Step: 5
Training loss: 1.8034758567810059
Validation loss: 2.0004577123990623

Epoch: 6| Step: 6
Training loss: 1.785576581954956
Validation loss: 1.9909301688594203

Epoch: 6| Step: 7
Training loss: 2.1485419273376465
Validation loss: 1.9949478833906111

Epoch: 6| Step: 8
Training loss: 1.8154001235961914
Validation loss: 1.9737432990022885

Epoch: 6| Step: 9
Training loss: 2.0314407348632812
Validation loss: 1.9364102271295363

Epoch: 6| Step: 10
Training loss: 1.5117982625961304
Validation loss: 1.931467338274884

Epoch: 6| Step: 11
Training loss: 1.9490275382995605
Validation loss: 1.9369594230446765

Epoch: 6| Step: 12
Training loss: 1.5721092224121094
Validation loss: 1.933802702093637

Epoch: 6| Step: 13
Training loss: 1.8947443962097168
Validation loss: 1.9459232809723064

Epoch: 179| Step: 0
Training loss: 1.1798112392425537
Validation loss: 1.9444231410180368

Epoch: 6| Step: 1
Training loss: 2.4518744945526123
Validation loss: 1.9518845247965988

Epoch: 6| Step: 2
Training loss: 1.0607818365097046
Validation loss: 1.9320992667187926

Epoch: 6| Step: 3
Training loss: 1.5530076026916504
Validation loss: 1.9213875186058782

Epoch: 6| Step: 4
Training loss: 2.35166335105896
Validation loss: 1.9260757405270812

Epoch: 6| Step: 5
Training loss: 1.8011155128479004
Validation loss: 1.9458277135766961

Epoch: 6| Step: 6
Training loss: 2.105727195739746
Validation loss: 1.953146929381996

Epoch: 6| Step: 7
Training loss: 2.0738468170166016
Validation loss: 1.9596152203057402

Epoch: 6| Step: 8
Training loss: 1.5037353038787842
Validation loss: 1.9792669716701712

Epoch: 6| Step: 9
Training loss: 2.115142345428467
Validation loss: 1.981920963333499

Epoch: 6| Step: 10
Training loss: 1.5287479162216187
Validation loss: 2.0087170562436505

Epoch: 6| Step: 11
Training loss: 1.6706303358078003
Validation loss: 2.0766764033225273

Epoch: 6| Step: 12
Training loss: 2.679966926574707
Validation loss: 2.1283394162372877

Epoch: 6| Step: 13
Training loss: 2.560124397277832
Validation loss: 2.0902502870046966

Epoch: 180| Step: 0
Training loss: 1.7253644466400146
Validation loss: 2.0743080608306395

Epoch: 6| Step: 1
Training loss: 1.725658893585205
Validation loss: 2.0492514282144527

Epoch: 6| Step: 2
Training loss: 1.9624570608139038
Validation loss: 2.023454071373068

Epoch: 6| Step: 3
Training loss: 2.694207191467285
Validation loss: 2.0331346052949146

Epoch: 6| Step: 4
Training loss: 1.9298412799835205
Validation loss: 1.99770950758329

Epoch: 6| Step: 5
Training loss: 1.8620820045471191
Validation loss: 1.9906376689992926

Epoch: 6| Step: 6
Training loss: 1.1811062097549438
Validation loss: 1.9911415628207627

Epoch: 6| Step: 7
Training loss: 2.19712495803833
Validation loss: 1.9694705470915763

Epoch: 6| Step: 8
Training loss: 1.8093754053115845
Validation loss: 1.9560021713215818

Epoch: 6| Step: 9
Training loss: 1.9434117078781128
Validation loss: 1.9485342784594464

Epoch: 6| Step: 10
Training loss: 1.6304059028625488
Validation loss: 1.912251510927754

Epoch: 6| Step: 11
Training loss: 1.6646108627319336
Validation loss: 1.900932324829922

Epoch: 6| Step: 12
Training loss: 1.8481470346450806
Validation loss: 1.9046874610326623

Epoch: 6| Step: 13
Training loss: 1.8211569786071777
Validation loss: 1.9149432387403262

Epoch: 181| Step: 0
Training loss: 2.159708023071289
Validation loss: 1.8901110361981135

Epoch: 6| Step: 1
Training loss: 2.6046457290649414
Validation loss: 1.9075427119449904

Epoch: 6| Step: 2
Training loss: 1.1733137369155884
Validation loss: 1.9209920052559144

Epoch: 6| Step: 3
Training loss: 2.1378066539764404
Validation loss: 1.9231075638084

Epoch: 6| Step: 4
Training loss: 1.3926982879638672
Validation loss: 1.9065921678338

Epoch: 6| Step: 5
Training loss: 2.3664615154266357
Validation loss: 1.942652553640386

Epoch: 6| Step: 6
Training loss: 1.7467992305755615
Validation loss: 1.9461271506483837

Epoch: 6| Step: 7
Training loss: 1.3187229633331299
Validation loss: 1.9749203946000786

Epoch: 6| Step: 8
Training loss: 1.7978299856185913
Validation loss: 1.957978908733655

Epoch: 6| Step: 9
Training loss: 2.329519748687744
Validation loss: 1.9703490182917605

Epoch: 6| Step: 10
Training loss: 2.100339889526367
Validation loss: 1.9909062065104002

Epoch: 6| Step: 11
Training loss: 1.547639012336731
Validation loss: 2.00099318258224

Epoch: 6| Step: 12
Training loss: 1.4601430892944336
Validation loss: 1.9837454852237497

Epoch: 6| Step: 13
Training loss: 1.4345442056655884
Validation loss: 1.9876770050294938

Epoch: 182| Step: 0
Training loss: 1.3306578397750854
Validation loss: 1.9810738102082284

Epoch: 6| Step: 1
Training loss: 1.6874501705169678
Validation loss: 1.9865743729376024

Epoch: 6| Step: 2
Training loss: 1.892364501953125
Validation loss: 2.0105056403785624

Epoch: 6| Step: 3
Training loss: 1.5743776559829712
Validation loss: 2.0031822189208

Epoch: 6| Step: 4
Training loss: 2.219818592071533
Validation loss: 1.983227211941955

Epoch: 6| Step: 5
Training loss: 1.7608739137649536
Validation loss: 2.0157762265974477

Epoch: 6| Step: 6
Training loss: 2.635458469390869
Validation loss: 2.0212082632126345

Epoch: 6| Step: 7
Training loss: 2.3125243186950684
Validation loss: 2.059179441903227

Epoch: 6| Step: 8
Training loss: 1.6653497219085693
Validation loss: 2.0580633788980465

Epoch: 6| Step: 9
Training loss: 1.3309228420257568
Validation loss: 2.0280932457216325

Epoch: 6| Step: 10
Training loss: 1.8813796043395996
Validation loss: 1.9819307070906445

Epoch: 6| Step: 11
Training loss: 2.1448450088500977
Validation loss: 1.9392691376388713

Epoch: 6| Step: 12
Training loss: 2.244302272796631
Validation loss: 1.9384614139474847

Epoch: 6| Step: 13
Training loss: 1.0106735229492188
Validation loss: 1.9409063170033116

Epoch: 183| Step: 0
Training loss: 1.8684251308441162
Validation loss: 1.9405997523697474

Epoch: 6| Step: 1
Training loss: 1.4853055477142334
Validation loss: 1.9127911829179334

Epoch: 6| Step: 2
Training loss: 1.5242923498153687
Validation loss: 1.896828314309479

Epoch: 6| Step: 3
Training loss: 2.1241707801818848
Validation loss: 1.908421379263683

Epoch: 6| Step: 4
Training loss: 1.7195932865142822
Validation loss: 1.9463542404995169

Epoch: 6| Step: 5
Training loss: 1.605405330657959
Validation loss: 1.9639267075446345

Epoch: 6| Step: 6
Training loss: 2.183244466781616
Validation loss: 1.9465662587073542

Epoch: 6| Step: 7
Training loss: 2.2088499069213867
Validation loss: 1.9540839515706545

Epoch: 6| Step: 8
Training loss: 1.4280792474746704
Validation loss: 1.9364986817042034

Epoch: 6| Step: 9
Training loss: 1.8703224658966064
Validation loss: 1.914795857603832

Epoch: 6| Step: 10
Training loss: 2.53352952003479
Validation loss: 1.907643057966745

Epoch: 6| Step: 11
Training loss: 1.8684386014938354
Validation loss: 1.9158470066644813

Epoch: 6| Step: 12
Training loss: 1.7271751165390015
Validation loss: 1.9376651010205668

Epoch: 6| Step: 13
Training loss: 2.777282238006592
Validation loss: 1.967012361813617

Epoch: 184| Step: 0
Training loss: 2.0247998237609863
Validation loss: 1.9618786470864409

Epoch: 6| Step: 1
Training loss: 2.2023491859436035
Validation loss: 1.9981238918919717

Epoch: 6| Step: 2
Training loss: 1.7710405588150024
Validation loss: 2.0231092309439056

Epoch: 6| Step: 3
Training loss: 2.2191286087036133
Validation loss: 2.0386506421591646

Epoch: 6| Step: 4
Training loss: 2.08565616607666
Validation loss: 2.017490243399015

Epoch: 6| Step: 5
Training loss: 1.7820934057235718
Validation loss: 1.9898060470499017

Epoch: 6| Step: 6
Training loss: 1.8983721733093262
Validation loss: 1.9620959604940107

Epoch: 6| Step: 7
Training loss: 1.85209059715271
Validation loss: 1.9733801734062932

Epoch: 6| Step: 8
Training loss: 1.5780131816864014
Validation loss: 1.9641592297502743

Epoch: 6| Step: 9
Training loss: 1.506041407585144
Validation loss: 1.9484971607885053

Epoch: 6| Step: 10
Training loss: 1.9605859518051147
Validation loss: 1.9406059095936437

Epoch: 6| Step: 11
Training loss: 1.5744138956069946
Validation loss: 1.922583737680989

Epoch: 6| Step: 12
Training loss: 1.4859299659729004
Validation loss: 1.9283187286828154

Epoch: 6| Step: 13
Training loss: 1.7571890354156494
Validation loss: 1.916428554442621

Epoch: 185| Step: 0
Training loss: 1.8904627561569214
Validation loss: 1.9326616987105338

Epoch: 6| Step: 1
Training loss: 2.1536178588867188
Validation loss: 1.9309587247910038

Epoch: 6| Step: 2
Training loss: 1.1401100158691406
Validation loss: 1.912421880229827

Epoch: 6| Step: 3
Training loss: 2.2116482257843018
Validation loss: 1.9216513941364903

Epoch: 6| Step: 4
Training loss: 1.2946256399154663
Validation loss: 1.9225144514473536

Epoch: 6| Step: 5
Training loss: 1.9626915454864502
Validation loss: 1.9280277118887952

Epoch: 6| Step: 6
Training loss: 1.0709595680236816
Validation loss: 1.929528054370675

Epoch: 6| Step: 7
Training loss: 2.1080503463745117
Validation loss: 1.9369162744091404

Epoch: 6| Step: 8
Training loss: 1.8059014081954956
Validation loss: 1.966203833139071

Epoch: 6| Step: 9
Training loss: 2.0173263549804688
Validation loss: 1.9529428161600584

Epoch: 6| Step: 10
Training loss: 2.0304622650146484
Validation loss: 1.9321800457533969

Epoch: 6| Step: 11
Training loss: 1.8717422485351562
Validation loss: 1.9295572952557636

Epoch: 6| Step: 12
Training loss: 1.4747685194015503
Validation loss: 1.9271817809791976

Epoch: 6| Step: 13
Training loss: 1.869488000869751
Validation loss: 1.9489129563813568

Epoch: 186| Step: 0
Training loss: 1.9862853288650513
Validation loss: 1.9607685868458082

Epoch: 6| Step: 1
Training loss: 2.026590347290039
Validation loss: 1.9568408984009937

Epoch: 6| Step: 2
Training loss: 1.2360434532165527
Validation loss: 1.943922964475488

Epoch: 6| Step: 3
Training loss: 2.475506067276001
Validation loss: 1.9322792381368659

Epoch: 6| Step: 4
Training loss: 1.5491232872009277
Validation loss: 1.9392443574884886

Epoch: 6| Step: 5
Training loss: 2.0290231704711914
Validation loss: 1.9446837543159403

Epoch: 6| Step: 6
Training loss: 1.7300705909729004
Validation loss: 1.961795683830015

Epoch: 6| Step: 7
Training loss: 0.8350478410720825
Validation loss: 1.9868887675705778

Epoch: 6| Step: 8
Training loss: 1.74552583694458
Validation loss: 2.0203489052352084

Epoch: 6| Step: 9
Training loss: 1.4967076778411865
Validation loss: 1.9975030319665068

Epoch: 6| Step: 10
Training loss: 1.6813979148864746
Validation loss: 1.9776500604485954

Epoch: 6| Step: 11
Training loss: 1.7451584339141846
Validation loss: 1.9432540068062403

Epoch: 6| Step: 12
Training loss: 2.102628231048584
Validation loss: 1.9504588380936654

Epoch: 6| Step: 13
Training loss: 2.257417917251587
Validation loss: 1.9398129447813957

Epoch: 187| Step: 0
Training loss: 1.7433912754058838
Validation loss: 1.932272118906821

Epoch: 6| Step: 1
Training loss: 1.5579675436019897
Validation loss: 1.9502917669152702

Epoch: 6| Step: 2
Training loss: 1.5537571907043457
Validation loss: 1.9617537657419841

Epoch: 6| Step: 3
Training loss: 2.0282645225524902
Validation loss: 1.9506484065004575

Epoch: 6| Step: 4
Training loss: 1.8667981624603271
Validation loss: 1.947929633561001

Epoch: 6| Step: 5
Training loss: 1.7167048454284668
Validation loss: 1.9637153815197688

Epoch: 6| Step: 6
Training loss: 1.5107519626617432
Validation loss: 1.9593894071476434

Epoch: 6| Step: 7
Training loss: 1.436870813369751
Validation loss: 1.9491734684154551

Epoch: 6| Step: 8
Training loss: 1.4847538471221924
Validation loss: 1.971460626971337

Epoch: 6| Step: 9
Training loss: 2.267702579498291
Validation loss: 1.963988842502717

Epoch: 6| Step: 10
Training loss: 1.6103312969207764
Validation loss: 1.9282261069102953

Epoch: 6| Step: 11
Training loss: 1.6808209419250488
Validation loss: 1.9221347480691888

Epoch: 6| Step: 12
Training loss: 2.3747477531433105
Validation loss: 1.9335200876318

Epoch: 6| Step: 13
Training loss: 1.8802770376205444
Validation loss: 1.9207916541766095

Epoch: 188| Step: 0
Training loss: 2.298114776611328
Validation loss: 1.9273709161307222

Epoch: 6| Step: 1
Training loss: 2.3503177165985107
Validation loss: 1.8916107493062173

Epoch: 6| Step: 2
Training loss: 2.1428325176239014
Validation loss: 1.8856121045286938

Epoch: 6| Step: 3
Training loss: 0.8797450661659241
Validation loss: 1.8727952536716257

Epoch: 6| Step: 4
Training loss: 2.31809663772583
Validation loss: 1.8905898678687312

Epoch: 6| Step: 5
Training loss: 1.259397029876709
Validation loss: 1.8872330086205595

Epoch: 6| Step: 6
Training loss: 1.6375732421875
Validation loss: 1.9405684676221622

Epoch: 6| Step: 7
Training loss: 2.0079524517059326
Validation loss: 1.9936181165838753

Epoch: 6| Step: 8
Training loss: 1.984430193901062
Validation loss: 2.03062597397835

Epoch: 6| Step: 9
Training loss: 1.7727627754211426
Validation loss: 2.059022726551179

Epoch: 6| Step: 10
Training loss: 1.968588948249817
Validation loss: 2.033573232671266

Epoch: 6| Step: 11
Training loss: 1.3088493347167969
Validation loss: 1.9757202415056125

Epoch: 6| Step: 12
Training loss: 1.161985993385315
Validation loss: 1.96753869646339

Epoch: 6| Step: 13
Training loss: 2.1791012287139893
Validation loss: 1.9758442909486833

Epoch: 189| Step: 0
Training loss: 1.3931998014450073
Validation loss: 1.9684706631527151

Epoch: 6| Step: 1
Training loss: 1.8439557552337646
Validation loss: 1.9730240016855218

Epoch: 6| Step: 2
Training loss: 2.4088997840881348
Validation loss: 1.974070696420567

Epoch: 6| Step: 3
Training loss: 0.7898920774459839
Validation loss: 1.9311414367409163

Epoch: 6| Step: 4
Training loss: 1.2246966361999512
Validation loss: 1.9284214306903142

Epoch: 6| Step: 5
Training loss: 1.8955731391906738
Validation loss: 1.9257221093741796

Epoch: 6| Step: 6
Training loss: 1.5747320652008057
Validation loss: 1.9134627824188561

Epoch: 6| Step: 7
Training loss: 1.7010959386825562
Validation loss: 1.878564529521491

Epoch: 6| Step: 8
Training loss: 1.8527437448501587
Validation loss: 1.903494401644635

Epoch: 6| Step: 9
Training loss: 2.0728886127471924
Validation loss: 1.8973954698090911

Epoch: 6| Step: 10
Training loss: 1.9141258001327515
Validation loss: 1.9269836461672218

Epoch: 6| Step: 11
Training loss: 2.0557942390441895
Validation loss: 1.9342469323065974

Epoch: 6| Step: 12
Training loss: 1.6865589618682861
Validation loss: 1.959627874435917

Epoch: 6| Step: 13
Training loss: 1.7131083011627197
Validation loss: 1.968772361355443

Epoch: 190| Step: 0
Training loss: 1.3793754577636719
Validation loss: 1.99490249541498

Epoch: 6| Step: 1
Training loss: 1.831531286239624
Validation loss: 2.0095604645308627

Epoch: 6| Step: 2
Training loss: 1.6279616355895996
Validation loss: 1.9798280064777662

Epoch: 6| Step: 3
Training loss: 1.4129955768585205
Validation loss: 1.955602410019085

Epoch: 6| Step: 4
Training loss: 1.6487677097320557
Validation loss: 1.9581397201425286

Epoch: 6| Step: 5
Training loss: 2.495306968688965
Validation loss: 1.9229655804172638

Epoch: 6| Step: 6
Training loss: 1.8550372123718262
Validation loss: 1.9295105818779237

Epoch: 6| Step: 7
Training loss: 1.3631868362426758
Validation loss: 1.906395003359805

Epoch: 6| Step: 8
Training loss: 1.7357521057128906
Validation loss: 1.9187092345247987

Epoch: 6| Step: 9
Training loss: 1.8988181352615356
Validation loss: 1.9403037409628592

Epoch: 6| Step: 10
Training loss: 2.371549129486084
Validation loss: 1.9331923928312076

Epoch: 6| Step: 11
Training loss: 1.4277846813201904
Validation loss: 1.9297013718594787

Epoch: 6| Step: 12
Training loss: 1.35616135597229
Validation loss: 1.925825954765402

Epoch: 6| Step: 13
Training loss: 2.1518144607543945
Validation loss: 1.9304791906828522

Epoch: 191| Step: 0
Training loss: 1.7164738178253174
Validation loss: 1.9309047960465955

Epoch: 6| Step: 1
Training loss: 1.680159330368042
Validation loss: 1.9810989479864798

Epoch: 6| Step: 2
Training loss: 1.829919457435608
Validation loss: 2.0242465465299544

Epoch: 6| Step: 3
Training loss: 2.184666633605957
Validation loss: 2.0515800932402253

Epoch: 6| Step: 4
Training loss: 1.6598150730133057
Validation loss: 2.0385337952644593

Epoch: 6| Step: 5
Training loss: 2.4406986236572266
Validation loss: 2.016371311679963

Epoch: 6| Step: 6
Training loss: 0.9437927007675171
Validation loss: 1.9696672757466633

Epoch: 6| Step: 7
Training loss: 1.8154454231262207
Validation loss: 1.917183353054908

Epoch: 6| Step: 8
Training loss: 0.9210461974143982
Validation loss: 1.914466360563873

Epoch: 6| Step: 9
Training loss: 1.7667163610458374
Validation loss: 1.8980827562270626

Epoch: 6| Step: 10
Training loss: 1.984445571899414
Validation loss: 1.8785381701684767

Epoch: 6| Step: 11
Training loss: 1.9396497011184692
Validation loss: 1.8669233565689416

Epoch: 6| Step: 12
Training loss: 1.3075761795043945
Validation loss: 1.8858481812220749

Epoch: 6| Step: 13
Training loss: 2.191739082336426
Validation loss: 1.8919116655985515

Epoch: 192| Step: 0
Training loss: 1.5026450157165527
Validation loss: 1.9332257945050475

Epoch: 6| Step: 1
Training loss: 1.2195720672607422
Validation loss: 1.9727305955784296

Epoch: 6| Step: 2
Training loss: 1.3719866275787354
Validation loss: 1.985010843123159

Epoch: 6| Step: 3
Training loss: 1.215808391571045
Validation loss: 2.0033183020930134

Epoch: 6| Step: 4
Training loss: 1.613552451133728
Validation loss: 2.001445839481969

Epoch: 6| Step: 5
Training loss: 1.9770424365997314
Validation loss: 2.006595988427439

Epoch: 6| Step: 6
Training loss: 1.819892406463623
Validation loss: 1.9756246254008303

Epoch: 6| Step: 7
Training loss: 2.3541259765625
Validation loss: 1.9600549820930726

Epoch: 6| Step: 8
Training loss: 0.9123817682266235
Validation loss: 1.9157884992578977

Epoch: 6| Step: 9
Training loss: 1.5571134090423584
Validation loss: 1.919512979445919

Epoch: 6| Step: 10
Training loss: 2.1584904193878174
Validation loss: 1.9158240133716213

Epoch: 6| Step: 11
Training loss: 1.9020752906799316
Validation loss: 1.9429012985639675

Epoch: 6| Step: 12
Training loss: 2.257049798965454
Validation loss: 1.9840627818979242

Epoch: 6| Step: 13
Training loss: 2.4800965785980225
Validation loss: 2.028423511853782

Epoch: 193| Step: 0
Training loss: 1.7420854568481445
Validation loss: 2.0335695794833604

Epoch: 6| Step: 1
Training loss: 1.945487141609192
Validation loss: 2.033808039080712

Epoch: 6| Step: 2
Training loss: 1.6167094707489014
Validation loss: 1.9616736622266873

Epoch: 6| Step: 3
Training loss: 1.4178690910339355
Validation loss: 1.8923017542849305

Epoch: 6| Step: 4
Training loss: 1.1070010662078857
Validation loss: 1.8691570630637548

Epoch: 6| Step: 5
Training loss: 1.9719560146331787
Validation loss: 1.8457463223447081

Epoch: 6| Step: 6
Training loss: 1.7864289283752441
Validation loss: 1.8690967431632421

Epoch: 6| Step: 7
Training loss: 2.3401002883911133
Validation loss: 1.8655256507217244

Epoch: 6| Step: 8
Training loss: 2.007842779159546
Validation loss: 1.8744334636196014

Epoch: 6| Step: 9
Training loss: 1.7242896556854248
Validation loss: 1.8814757600907357

Epoch: 6| Step: 10
Training loss: 1.9391484260559082
Validation loss: 1.9037003940151584

Epoch: 6| Step: 11
Training loss: 1.561122179031372
Validation loss: 1.9082348859438332

Epoch: 6| Step: 12
Training loss: 1.7756550312042236
Validation loss: 1.9426673086740638

Epoch: 6| Step: 13
Training loss: 1.8582024574279785
Validation loss: 1.94503874932566

Epoch: 194| Step: 0
Training loss: 1.5408215522766113
Validation loss: 1.947006429395368

Epoch: 6| Step: 1
Training loss: 1.878962516784668
Validation loss: 1.941272613822773

Epoch: 6| Step: 2
Training loss: 1.944016933441162
Validation loss: 1.9363706009362334

Epoch: 6| Step: 3
Training loss: 1.1892681121826172
Validation loss: 1.934431840014714

Epoch: 6| Step: 4
Training loss: 1.8508411645889282
Validation loss: 1.9234081775911394

Epoch: 6| Step: 5
Training loss: 2.531898021697998
Validation loss: 1.952611538671678

Epoch: 6| Step: 6
Training loss: 2.118126630783081
Validation loss: 1.9556108033785256

Epoch: 6| Step: 7
Training loss: 1.7378394603729248
Validation loss: 1.9247398338010233

Epoch: 6| Step: 8
Training loss: 1.241836428642273
Validation loss: 1.9018392703866447

Epoch: 6| Step: 9
Training loss: 1.0009775161743164
Validation loss: 1.9092627212565432

Epoch: 6| Step: 10
Training loss: 1.476407766342163
Validation loss: 1.8954197668260144

Epoch: 6| Step: 11
Training loss: 1.3644700050354004
Validation loss: 1.9086581571127779

Epoch: 6| Step: 12
Training loss: 1.7622814178466797
Validation loss: 1.91092897230579

Epoch: 6| Step: 13
Training loss: 1.824561595916748
Validation loss: 1.921774156631962

Epoch: 195| Step: 0
Training loss: 1.7847962379455566
Validation loss: 1.935690136365993

Epoch: 6| Step: 1
Training loss: 1.4363503456115723
Validation loss: 1.9464320380200621

Epoch: 6| Step: 2
Training loss: 1.568598985671997
Validation loss: 1.9258634544187976

Epoch: 6| Step: 3
Training loss: 2.357144832611084
Validation loss: 1.8986656409437939

Epoch: 6| Step: 4
Training loss: 1.3038710355758667
Validation loss: 1.893715477117928

Epoch: 6| Step: 5
Training loss: 1.0813404321670532
Validation loss: 1.8692560965015041

Epoch: 6| Step: 6
Training loss: 0.9653989672660828
Validation loss: 1.8732967338254374

Epoch: 6| Step: 7
Training loss: 2.4342293739318848
Validation loss: 1.889559873970606

Epoch: 6| Step: 8
Training loss: 1.9056819677352905
Validation loss: 1.9097904518086424

Epoch: 6| Step: 9
Training loss: 1.775494933128357
Validation loss: 1.9304535286400908

Epoch: 6| Step: 10
Training loss: 1.9640882015228271
Validation loss: 1.9517483506151425

Epoch: 6| Step: 11
Training loss: 2.088318109512329
Validation loss: 1.978919316363591

Epoch: 6| Step: 12
Training loss: 2.0507779121398926
Validation loss: 1.9814989284802509

Epoch: 6| Step: 13
Training loss: 1.0817474126815796
Validation loss: 1.9345122639850905

Epoch: 196| Step: 0
Training loss: 1.675020694732666
Validation loss: 1.930346591498262

Epoch: 6| Step: 1
Training loss: 1.6977653503417969
Validation loss: 1.932248543667537

Epoch: 6| Step: 2
Training loss: 1.553358554840088
Validation loss: 1.9510713392688381

Epoch: 6| Step: 3
Training loss: 1.115321397781372
Validation loss: 1.9651553707738076

Epoch: 6| Step: 4
Training loss: 1.889968752861023
Validation loss: 1.9443711849950975

Epoch: 6| Step: 5
Training loss: 1.7983653545379639
Validation loss: 1.945003177530022

Epoch: 6| Step: 6
Training loss: 2.100831985473633
Validation loss: 1.9471260296401156

Epoch: 6| Step: 7
Training loss: 1.5266422033309937
Validation loss: 1.949603283277122

Epoch: 6| Step: 8
Training loss: 1.3451602458953857
Validation loss: 1.9608306448946717

Epoch: 6| Step: 9
Training loss: 1.5198787450790405
Validation loss: 1.947611407567096

Epoch: 6| Step: 10
Training loss: 2.116577625274658
Validation loss: 1.9661402599785918

Epoch: 6| Step: 11
Training loss: 1.8571537733078003
Validation loss: 1.9929872738417758

Epoch: 6| Step: 12
Training loss: 1.8692764043807983
Validation loss: 1.973023514593801

Epoch: 6| Step: 13
Training loss: 0.8882297873497009
Validation loss: 1.961270450263895

Epoch: 197| Step: 0
Training loss: 1.5330215692520142
Validation loss: 1.929222288952079

Epoch: 6| Step: 1
Training loss: 1.6967219114303589
Validation loss: 1.8698886722646735

Epoch: 6| Step: 2
Training loss: 2.224090099334717
Validation loss: 1.8786100008154427

Epoch: 6| Step: 3
Training loss: 1.526444435119629
Validation loss: 1.8774514390576271

Epoch: 6| Step: 4
Training loss: 0.9335841536521912
Validation loss: 1.8967452485074279

Epoch: 6| Step: 5
Training loss: 1.9633371829986572
Validation loss: 1.900921844667004

Epoch: 6| Step: 6
Training loss: 2.1408491134643555
Validation loss: 1.9136563629232428

Epoch: 6| Step: 7
Training loss: 1.7814478874206543
Validation loss: 1.9375175301746657

Epoch: 6| Step: 8
Training loss: 1.855900764465332
Validation loss: 1.9727622821766844

Epoch: 6| Step: 9
Training loss: 1.2958307266235352
Validation loss: 2.0065639711195424

Epoch: 6| Step: 10
Training loss: 1.4398894309997559
Validation loss: 2.0072356936752156

Epoch: 6| Step: 11
Training loss: 2.106504440307617
Validation loss: 2.0308789104543705

Epoch: 6| Step: 12
Training loss: 1.5279070138931274
Validation loss: 1.9752836573508479

Epoch: 6| Step: 13
Training loss: 1.4839953184127808
Validation loss: 1.9316646142672467

Epoch: 198| Step: 0
Training loss: 1.5093473196029663
Validation loss: 1.8895355193845687

Epoch: 6| Step: 1
Training loss: 1.5292019844055176
Validation loss: 1.8953872931900846

Epoch: 6| Step: 2
Training loss: 1.6623187065124512
Validation loss: 1.8999737590871832

Epoch: 6| Step: 3
Training loss: 1.8368110656738281
Validation loss: 1.8769207180187266

Epoch: 6| Step: 4
Training loss: 1.2567654848098755
Validation loss: 1.8824891685157694

Epoch: 6| Step: 5
Training loss: 1.7025245428085327
Validation loss: 1.8880106890073387

Epoch: 6| Step: 6
Training loss: 2.1032893657684326
Validation loss: 1.9175016290398055

Epoch: 6| Step: 7
Training loss: 1.146310806274414
Validation loss: 1.9493494149177306

Epoch: 6| Step: 8
Training loss: 1.8828155994415283
Validation loss: 1.951033712715231

Epoch: 6| Step: 9
Training loss: 2.1378726959228516
Validation loss: 1.9689525968285018

Epoch: 6| Step: 10
Training loss: 1.8157933950424194
Validation loss: 1.919590982057715

Epoch: 6| Step: 11
Training loss: 1.1390407085418701
Validation loss: 1.8874840223661034

Epoch: 6| Step: 12
Training loss: 1.5748248100280762
Validation loss: 1.865463859291487

Epoch: 6| Step: 13
Training loss: 2.390481948852539
Validation loss: 1.8749569590373705

Epoch: 199| Step: 0
Training loss: 2.056572198867798
Validation loss: 1.8829204933617705

Epoch: 6| Step: 1
Training loss: 1.5037345886230469
Validation loss: 1.8823434306729225

Epoch: 6| Step: 2
Training loss: 1.6165803670883179
Validation loss: 1.9009126565789665

Epoch: 6| Step: 3
Training loss: 0.7986105680465698
Validation loss: 1.9427985363109137

Epoch: 6| Step: 4
Training loss: 1.9835164546966553
Validation loss: 1.9888002308466102

Epoch: 6| Step: 5
Training loss: 1.6075531244277954
Validation loss: 2.0157402843557377

Epoch: 6| Step: 6
Training loss: 1.6726491451263428
Validation loss: 2.0024424650335826

Epoch: 6| Step: 7
Training loss: 1.859858751296997
Validation loss: 1.9842765279995498

Epoch: 6| Step: 8
Training loss: 1.998413324356079
Validation loss: 1.9867821893384379

Epoch: 6| Step: 9
Training loss: 1.6844851970672607
Validation loss: 1.9637155904564807

Epoch: 6| Step: 10
Training loss: 1.4751092195510864
Validation loss: 1.9326289353832122

Epoch: 6| Step: 11
Training loss: 1.8032556772232056
Validation loss: 1.8720711431195658

Epoch: 6| Step: 12
Training loss: 1.6810147762298584
Validation loss: 1.8721838817801526

Epoch: 6| Step: 13
Training loss: 1.2817025184631348
Validation loss: 1.8591220776240032

Epoch: 200| Step: 0
Training loss: 1.9208190441131592
Validation loss: 1.840074973721658

Epoch: 6| Step: 1
Training loss: 2.1530771255493164
Validation loss: 1.8251304600828437

Epoch: 6| Step: 2
Training loss: 1.7375340461730957
Validation loss: 1.8572995624234598

Epoch: 6| Step: 3
Training loss: 1.593319296836853
Validation loss: 1.8673104752776444

Epoch: 6| Step: 4
Training loss: 1.8201111555099487
Validation loss: 1.9026859191156202

Epoch: 6| Step: 5
Training loss: 2.133061647415161
Validation loss: 1.9234756359490015

Epoch: 6| Step: 6
Training loss: 1.6231420040130615
Validation loss: 1.951724353656974

Epoch: 6| Step: 7
Training loss: 1.5891802310943604
Validation loss: 1.9877708214585499

Epoch: 6| Step: 8
Training loss: 1.8800128698349
Validation loss: 1.9621005378743654

Epoch: 6| Step: 9
Training loss: 1.6148909330368042
Validation loss: 1.9212925972477082

Epoch: 6| Step: 10
Training loss: 1.091867208480835
Validation loss: 1.9184940835481048

Epoch: 6| Step: 11
Training loss: 1.1241918802261353
Validation loss: 1.9149062120786278

Epoch: 6| Step: 12
Training loss: 1.437200665473938
Validation loss: 1.9107215199419247

Epoch: 6| Step: 13
Training loss: 2.346463203430176
Validation loss: 1.9498396688891995

Testing loss: 2.2853054099612766
