Epoch: 1| Step: 0
Training loss: 4.698959381479992
Validation loss: 5.806521782171922

Epoch: 6| Step: 1
Training loss: 5.532612261074915
Validation loss: 5.792209642580631

Epoch: 6| Step: 2
Training loss: 5.576781380874488
Validation loss: 5.777508561696274

Epoch: 6| Step: 3
Training loss: 5.467155354839498
Validation loss: 5.760120295731983

Epoch: 6| Step: 4
Training loss: 5.593616334820603
Validation loss: 5.74129007779945

Epoch: 6| Step: 5
Training loss: 5.143094382793521
Validation loss: 5.718917683734592

Epoch: 6| Step: 6
Training loss: 6.308774245192693
Validation loss: 5.693299866678089

Epoch: 6| Step: 7
Training loss: 5.184645085488069
Validation loss: 5.664265532286416

Epoch: 6| Step: 8
Training loss: 5.8619642716473725
Validation loss: 5.631933236757

Epoch: 6| Step: 9
Training loss: 5.0702955718852625
Validation loss: 5.595107875664752

Epoch: 6| Step: 10
Training loss: 6.714573613403494
Validation loss: 5.553874086964352

Epoch: 6| Step: 11
Training loss: 5.9333725888671704
Validation loss: 5.509537330225546

Epoch: 6| Step: 12
Training loss: 6.395185936915721
Validation loss: 5.459972453293728

Epoch: 6| Step: 13
Training loss: 5.846289750886314
Validation loss: 5.4079711192600675

Epoch: 2| Step: 0
Training loss: 6.001883211234523
Validation loss: 5.352437272450571

Epoch: 6| Step: 1
Training loss: 5.687507377871245
Validation loss: 5.294638117818395

Epoch: 6| Step: 2
Training loss: 5.594508114380576
Validation loss: 5.235754332298322

Epoch: 6| Step: 3
Training loss: 3.8942613881239665
Validation loss: 5.175383366224061

Epoch: 6| Step: 4
Training loss: 5.616802770095662
Validation loss: 5.1187420707203595

Epoch: 6| Step: 5
Training loss: 5.621937066202607
Validation loss: 5.058366285733951

Epoch: 6| Step: 6
Training loss: 5.203205646428309
Validation loss: 5.00117046848551

Epoch: 6| Step: 7
Training loss: 4.147601084612655
Validation loss: 4.938029748762448

Epoch: 6| Step: 8
Training loss: 5.0860998828004025
Validation loss: 4.875005477510945

Epoch: 6| Step: 9
Training loss: 4.376897781750738
Validation loss: 4.810232243174308

Epoch: 6| Step: 10
Training loss: 5.701296662196337
Validation loss: 4.74494536906092

Epoch: 6| Step: 11
Training loss: 4.757977662876287
Validation loss: 4.670267907852437

Epoch: 6| Step: 12
Training loss: 4.380145072102194
Validation loss: 4.60733994321191

Epoch: 6| Step: 13
Training loss: 3.1021380527060485
Validation loss: 4.557450261557345

Epoch: 3| Step: 0
Training loss: 3.7806760494237053
Validation loss: 4.52281890872473

Epoch: 6| Step: 1
Training loss: 3.9598019870226113
Validation loss: 4.487816271875495

Epoch: 6| Step: 2
Training loss: 5.483555224411433
Validation loss: 4.452704101198888

Epoch: 6| Step: 3
Training loss: 4.478625715843232
Validation loss: 4.426303076223442

Epoch: 6| Step: 4
Training loss: 4.7477126386368695
Validation loss: 4.401546873000354

Epoch: 6| Step: 5
Training loss: 3.436998087913818
Validation loss: 4.369600381912641

Epoch: 6| Step: 6
Training loss: 4.517861838529485
Validation loss: 4.340832356954924

Epoch: 6| Step: 7
Training loss: 5.025009929590236
Validation loss: 4.309049924358839

Epoch: 6| Step: 8
Training loss: 5.049084442538641
Validation loss: 4.275629596155958

Epoch: 6| Step: 9
Training loss: 3.976681810548975
Validation loss: 4.249590140358419

Epoch: 6| Step: 10
Training loss: 4.41662523262214
Validation loss: 4.22501457446301

Epoch: 6| Step: 11
Training loss: 3.327406541527882
Validation loss: 4.204128477551047

Epoch: 6| Step: 12
Training loss: 5.4398174389892215
Validation loss: 4.175134055412329

Epoch: 6| Step: 13
Training loss: 3.7356160547699204
Validation loss: 4.141899204136791

Epoch: 4| Step: 0
Training loss: 5.778722922137714
Validation loss: 4.109149855730598

Epoch: 6| Step: 1
Training loss: 4.643734901372872
Validation loss: 4.084448640521056

Epoch: 6| Step: 2
Training loss: 4.384063052705521
Validation loss: 4.059997375885897

Epoch: 6| Step: 3
Training loss: 4.056584203086202
Validation loss: 4.034583538994082

Epoch: 6| Step: 4
Training loss: 3.549852373519115
Validation loss: 4.0091097703803245

Epoch: 6| Step: 5
Training loss: 3.352086450841263
Validation loss: 3.9925459323637527

Epoch: 6| Step: 6
Training loss: 4.012797388007183
Validation loss: 3.9736732498171214

Epoch: 6| Step: 7
Training loss: 4.016098291432892
Validation loss: 3.9564222574523464

Epoch: 6| Step: 8
Training loss: 3.8051008121404295
Validation loss: 3.9444557964695606

Epoch: 6| Step: 9
Training loss: 4.195348416251055
Validation loss: 3.9280551049586183

Epoch: 6| Step: 10
Training loss: 3.715409389236463
Validation loss: 3.9118876226212436

Epoch: 6| Step: 11
Training loss: 3.98259069843546
Validation loss: 3.894643298563363

Epoch: 6| Step: 12
Training loss: 3.920064439827787
Validation loss: 3.8964140882888105

Epoch: 6| Step: 13
Training loss: 4.119143866315699
Validation loss: 3.874245005402638

Epoch: 5| Step: 0
Training loss: 4.599965775403954
Validation loss: 3.8630036716442513

Epoch: 6| Step: 1
Training loss: 3.4505188372144384
Validation loss: 3.8382231826397186

Epoch: 6| Step: 2
Training loss: 3.8014793578187906
Validation loss: 3.8341183003611756

Epoch: 6| Step: 3
Training loss: 3.7504806210559223
Validation loss: 3.807577436094921

Epoch: 6| Step: 4
Training loss: 3.8069224598239857
Validation loss: 3.798008781766262

Epoch: 6| Step: 5
Training loss: 4.108744641826537
Validation loss: 3.7811860896361966

Epoch: 6| Step: 6
Training loss: 3.980601120414628
Validation loss: 3.7656622260055266

Epoch: 6| Step: 7
Training loss: 4.093719715268467
Validation loss: 3.750305145591497

Epoch: 6| Step: 8
Training loss: 2.1150304637906405
Validation loss: 3.73354142848038

Epoch: 6| Step: 9
Training loss: 4.842217184383842
Validation loss: 3.752745407520822

Epoch: 6| Step: 10
Training loss: 4.163991272623112
Validation loss: 3.7172598013784697

Epoch: 6| Step: 11
Training loss: 2.7619091869343855
Validation loss: 3.719058320371068

Epoch: 6| Step: 12
Training loss: 4.286758109541718
Validation loss: 3.7290778168702197

Epoch: 6| Step: 13
Training loss: 5.113449851593895
Validation loss: 3.7125022510587895

Epoch: 6| Step: 0
Training loss: 3.2578122072654243
Validation loss: 3.6797803815636523

Epoch: 6| Step: 1
Training loss: 4.033938671956534
Validation loss: 3.6704537941266553

Epoch: 6| Step: 2
Training loss: 5.011878590105024
Validation loss: 3.6982711009749676

Epoch: 6| Step: 3
Training loss: 3.460662210852436
Validation loss: 3.6507822554622424

Epoch: 6| Step: 4
Training loss: 4.431543785439294
Validation loss: 3.6388783626304475

Epoch: 6| Step: 5
Training loss: 3.898965375552322
Validation loss: 3.6274201938834256

Epoch: 6| Step: 6
Training loss: 2.7911738250082405
Validation loss: 3.617663046558471

Epoch: 6| Step: 7
Training loss: 3.47365683525043
Validation loss: 3.6142406754533902

Epoch: 6| Step: 8
Training loss: 3.922508887626737
Validation loss: 3.6030217024270925

Epoch: 6| Step: 9
Training loss: 3.5805755619278994
Validation loss: 3.590096811275795

Epoch: 6| Step: 10
Training loss: 4.240262263841956
Validation loss: 3.576749376803005

Epoch: 6| Step: 11
Training loss: 3.6897622620620303
Validation loss: 3.5644845132405183

Epoch: 6| Step: 12
Training loss: 3.3102655611948
Validation loss: 3.5504495420732693

Epoch: 6| Step: 13
Training loss: 3.87453137917389
Validation loss: 3.543749777300555

Epoch: 7| Step: 0
Training loss: 3.239338333007739
Validation loss: 3.5356065638151084

Epoch: 6| Step: 1
Training loss: 3.856148425082926
Validation loss: 3.5288660828991953

Epoch: 6| Step: 2
Training loss: 3.938074947947829
Validation loss: 3.5169683160156127

Epoch: 6| Step: 3
Training loss: 3.872160825116437
Validation loss: 3.512706326949125

Epoch: 6| Step: 4
Training loss: 3.623040425996619
Validation loss: 3.500992896352454

Epoch: 6| Step: 5
Training loss: 3.845189763063046
Validation loss: 3.4901421844044287

Epoch: 6| Step: 6
Training loss: 3.7543100384013197
Validation loss: 3.4818671886249937

Epoch: 6| Step: 7
Training loss: 3.299316948222632
Validation loss: 3.4755868005082022

Epoch: 6| Step: 8
Training loss: 3.686081694353272
Validation loss: 3.470049281347059

Epoch: 6| Step: 9
Training loss: 3.7934504634246946
Validation loss: 3.462539422489853

Epoch: 6| Step: 10
Training loss: 3.672995148914934
Validation loss: 3.459646488396308

Epoch: 6| Step: 11
Training loss: 3.7753641016107897
Validation loss: 3.4548898928034237

Epoch: 6| Step: 12
Training loss: 3.7889970596797404
Validation loss: 3.4462086431958885

Epoch: 6| Step: 13
Training loss: 3.4569215918783898
Validation loss: 3.437848385396471

Epoch: 8| Step: 0
Training loss: 3.9449440963516635
Validation loss: 3.4287286175235656

Epoch: 6| Step: 1
Training loss: 4.004603121520118
Validation loss: 3.4203131825556072

Epoch: 6| Step: 2
Training loss: 3.832285959098335
Validation loss: 3.408662633820874

Epoch: 6| Step: 3
Training loss: 3.024201052748691
Validation loss: 3.4043606917391696

Epoch: 6| Step: 4
Training loss: 3.0158125270587126
Validation loss: 3.3971201043259907

Epoch: 6| Step: 5
Training loss: 3.718119848378906
Validation loss: 3.391523237406334

Epoch: 6| Step: 6
Training loss: 3.1851585614605606
Validation loss: 3.3868119966824572

Epoch: 6| Step: 7
Training loss: 3.096365699500617
Validation loss: 3.3909009580450244

Epoch: 6| Step: 8
Training loss: 3.454233397302086
Validation loss: 3.397509557467027

Epoch: 6| Step: 9
Training loss: 3.4845969638347287
Validation loss: 3.392501351946747

Epoch: 6| Step: 10
Training loss: 4.512968238777972
Validation loss: 3.3825382588619233

Epoch: 6| Step: 11
Training loss: 3.6936559210090447
Validation loss: 3.3706604295008673

Epoch: 6| Step: 12
Training loss: 3.6500716215448743
Validation loss: 3.3605374926431453

Epoch: 6| Step: 13
Training loss: 3.8575734246337334
Validation loss: 3.3598380248336834

Epoch: 9| Step: 0
Training loss: 3.428939424929228
Validation loss: 3.352355863131008

Epoch: 6| Step: 1
Training loss: 3.2476953991844417
Validation loss: 3.345757982592704

Epoch: 6| Step: 2
Training loss: 3.3520039443309217
Validation loss: 3.341340985243

Epoch: 6| Step: 3
Training loss: 4.180772073798886
Validation loss: 3.3355906339487347

Epoch: 6| Step: 4
Training loss: 2.949836635915431
Validation loss: 3.3327044037234708

Epoch: 6| Step: 5
Training loss: 3.5497238212934956
Validation loss: 3.3168942263394072

Epoch: 6| Step: 6
Training loss: 3.7382552286515986
Validation loss: 3.3113499535546467

Epoch: 6| Step: 7
Training loss: 2.8042088687284985
Validation loss: 3.3085277420179127

Epoch: 6| Step: 8
Training loss: 4.143038985297074
Validation loss: 3.29902031775887

Epoch: 6| Step: 9
Training loss: 4.100302773437872
Validation loss: 3.2947693580785495

Epoch: 6| Step: 10
Training loss: 3.0545491921414385
Validation loss: 3.2966809892434017

Epoch: 6| Step: 11
Training loss: 4.012159700312966
Validation loss: 3.282494990378865

Epoch: 6| Step: 12
Training loss: 3.3269952280270036
Validation loss: 3.2800685882825396

Epoch: 6| Step: 13
Training loss: 3.48587742731919
Validation loss: 3.27703045141711

Epoch: 10| Step: 0
Training loss: 3.9961777544933876
Validation loss: 3.2685000644111892

Epoch: 6| Step: 1
Training loss: 3.238096004106661
Validation loss: 3.263127403357776

Epoch: 6| Step: 2
Training loss: 3.7389351682426613
Validation loss: 3.2754162785986196

Epoch: 6| Step: 3
Training loss: 3.3573278532682886
Validation loss: 3.260690260807282

Epoch: 6| Step: 4
Training loss: 2.367132205128475
Validation loss: 3.253230197430977

Epoch: 6| Step: 5
Training loss: 3.161197523810541
Validation loss: 3.254962366799341

Epoch: 6| Step: 6
Training loss: 4.495775571115605
Validation loss: 3.254294440503166

Epoch: 6| Step: 7
Training loss: 2.8779881746156533
Validation loss: 3.250362639471705

Epoch: 6| Step: 8
Training loss: 2.8582938396368656
Validation loss: 3.2651351920144265

Epoch: 6| Step: 9
Training loss: 4.101732232351132
Validation loss: 3.242434142548897

Epoch: 6| Step: 10
Training loss: 3.8471421571212585
Validation loss: 3.239336593490884

Epoch: 6| Step: 11
Training loss: 3.8476334469501956
Validation loss: 3.243948077989799

Epoch: 6| Step: 12
Training loss: 2.83962814583033
Validation loss: 3.2484843093504825

Epoch: 6| Step: 13
Training loss: 3.823650625732693
Validation loss: 3.2331193854011833

Epoch: 11| Step: 0
Training loss: 2.978030185851345
Validation loss: 3.2230430874508023

Epoch: 6| Step: 1
Training loss: 3.089828163233047
Validation loss: 3.2232247285185833

Epoch: 6| Step: 2
Training loss: 3.8500900703892453
Validation loss: 3.221570889597211

Epoch: 6| Step: 3
Training loss: 3.348373211676508
Validation loss: 3.2176321039549163

Epoch: 6| Step: 4
Training loss: 2.9800258722398283
Validation loss: 3.212185127395312

Epoch: 6| Step: 5
Training loss: 3.3343587887485193
Validation loss: 3.212171060077585

Epoch: 6| Step: 6
Training loss: 3.5179348965379242
Validation loss: 3.2074385936095413

Epoch: 6| Step: 7
Training loss: 3.779044524843807
Validation loss: 3.1983263881545763

Epoch: 6| Step: 8
Training loss: 3.7201166286439045
Validation loss: 3.1925905545826287

Epoch: 6| Step: 9
Training loss: 2.956191635362185
Validation loss: 3.1926878683058653

Epoch: 6| Step: 10
Training loss: 3.6655848091959626
Validation loss: 3.190427799178405

Epoch: 6| Step: 11
Training loss: 3.7386438718047357
Validation loss: 3.1846459608772757

Epoch: 6| Step: 12
Training loss: 3.4785657961534873
Validation loss: 3.18108633751699

Epoch: 6| Step: 13
Training loss: 4.099078023569513
Validation loss: 3.1717008757795537

Epoch: 12| Step: 0
Training loss: 3.5131284538432586
Validation loss: 3.165711996237569

Epoch: 6| Step: 1
Training loss: 2.966313858341522
Validation loss: 3.1638292517068445

Epoch: 6| Step: 2
Training loss: 3.1835468686636337
Validation loss: 3.1604941703949407

Epoch: 6| Step: 3
Training loss: 3.4772058470307035
Validation loss: 3.1583166334716313

Epoch: 6| Step: 4
Training loss: 2.762454009212667
Validation loss: 3.154109734793975

Epoch: 6| Step: 5
Training loss: 3.2521353822331194
Validation loss: 3.149569411634442

Epoch: 6| Step: 6
Training loss: 3.3832604373789774
Validation loss: 3.14312836523234

Epoch: 6| Step: 7
Training loss: 3.9927088328035345
Validation loss: 3.139520921150835

Epoch: 6| Step: 8
Training loss: 2.8249554655902736
Validation loss: 3.1373616140860583

Epoch: 6| Step: 9
Training loss: 3.0958901141279034
Validation loss: 3.1398147291201504

Epoch: 6| Step: 10
Training loss: 3.8083522309238567
Validation loss: 3.13202102806758

Epoch: 6| Step: 11
Training loss: 3.7877728656639844
Validation loss: 3.1267117937155176

Epoch: 6| Step: 12
Training loss: 3.768769150617285
Validation loss: 3.127276151553833

Epoch: 6| Step: 13
Training loss: 3.8998653877697635
Validation loss: 3.1277693014408228

Epoch: 13| Step: 0
Training loss: 3.882426375104294
Validation loss: 3.1230477139372566

Epoch: 6| Step: 1
Training loss: 3.815685004934863
Validation loss: 3.117883133025006

Epoch: 6| Step: 2
Training loss: 3.170579767970438
Validation loss: 3.114515753181011

Epoch: 6| Step: 3
Training loss: 3.1822629803469145
Validation loss: 3.109059701665687

Epoch: 6| Step: 4
Training loss: 3.0234737739062703
Validation loss: 3.103857157252007

Epoch: 6| Step: 5
Training loss: 3.1408704974886548
Validation loss: 3.1028892667546812

Epoch: 6| Step: 6
Training loss: 3.416589286362142
Validation loss: 3.102223963538617

Epoch: 6| Step: 7
Training loss: 2.926661849079497
Validation loss: 3.1007513815093857

Epoch: 6| Step: 8
Training loss: 3.290096745561414
Validation loss: 3.1029525555092405

Epoch: 6| Step: 9
Training loss: 2.953784364426964
Validation loss: 3.0979288938105207

Epoch: 6| Step: 10
Training loss: 3.7953338635009453
Validation loss: 3.0891971973950323

Epoch: 6| Step: 11
Training loss: 2.9624080981715375
Validation loss: 3.087602319608317

Epoch: 6| Step: 12
Training loss: 3.5113343228909173
Validation loss: 3.085180621088718

Epoch: 6| Step: 13
Training loss: 4.367853922486831
Validation loss: 3.0816587077424438

Epoch: 14| Step: 0
Training loss: 2.5154428356865783
Validation loss: 3.08047684173854

Epoch: 6| Step: 1
Training loss: 3.1181187971385644
Validation loss: 3.078493009565856

Epoch: 6| Step: 2
Training loss: 3.6647106646604817
Validation loss: 3.073847052773387

Epoch: 6| Step: 3
Training loss: 3.0328148017886356
Validation loss: 3.0733251657133414

Epoch: 6| Step: 4
Training loss: 3.6658594080911144
Validation loss: 3.071393583309193

Epoch: 6| Step: 5
Training loss: 3.2599733353910945
Validation loss: 3.0677034757658443

Epoch: 6| Step: 6
Training loss: 2.7350985196517015
Validation loss: 3.0662152053891316

Epoch: 6| Step: 7
Training loss: 2.8422926637425547
Validation loss: 3.061690077122927

Epoch: 6| Step: 8
Training loss: 3.753254686031873
Validation loss: 3.0570191625298766

Epoch: 6| Step: 9
Training loss: 3.455580308818031
Validation loss: 3.0682971373334285

Epoch: 6| Step: 10
Training loss: 3.1352928027318763
Validation loss: 3.0684839802220165

Epoch: 6| Step: 11
Training loss: 3.8921907637010853
Validation loss: 3.052132824740754

Epoch: 6| Step: 12
Training loss: 3.413568596282113
Validation loss: 3.0621951087261796

Epoch: 6| Step: 13
Training loss: 4.50448279152182
Validation loss: 3.108573755510792

Epoch: 15| Step: 0
Training loss: 3.4096773036286545
Validation loss: 3.0483860119606487

Epoch: 6| Step: 1
Training loss: 3.1460294009785237
Validation loss: 3.0395794066219395

Epoch: 6| Step: 2
Training loss: 3.2350018027534944
Validation loss: 3.0418151963048827

Epoch: 6| Step: 3
Training loss: 3.2345641444826767
Validation loss: 3.118725521658973

Epoch: 6| Step: 4
Training loss: 3.601368400324854
Validation loss: 3.1139361597118405

Epoch: 6| Step: 5
Training loss: 3.6060662234335195
Validation loss: 3.0401667612128302

Epoch: 6| Step: 6
Training loss: 2.4227511882170907
Validation loss: 3.0390746709023833

Epoch: 6| Step: 7
Training loss: 2.9181890238562476
Validation loss: 3.0877907308430674

Epoch: 6| Step: 8
Training loss: 4.188382639313269
Validation loss: 3.11811949845412

Epoch: 6| Step: 9
Training loss: 3.646982037461575
Validation loss: 3.0583402322487547

Epoch: 6| Step: 10
Training loss: 3.114881078124713
Validation loss: 3.047081988308211

Epoch: 6| Step: 11
Training loss: 3.570794605117813
Validation loss: 3.038757008556082

Epoch: 6| Step: 12
Training loss: 3.379118631556941
Validation loss: 3.0351163666955783

Epoch: 6| Step: 13
Training loss: 2.839595064925889
Validation loss: 3.0306946000693973

Epoch: 16| Step: 0
Training loss: 3.3209535226806
Validation loss: 3.0265745508795585

Epoch: 6| Step: 1
Training loss: 3.0098571961451133
Validation loss: 3.0219495199860993

Epoch: 6| Step: 2
Training loss: 3.561744877610011
Validation loss: 3.028468081896225

Epoch: 6| Step: 3
Training loss: 3.6463690373263193
Validation loss: 3.006051236419506

Epoch: 6| Step: 4
Training loss: 3.169570611940158
Validation loss: 2.992649970198981

Epoch: 6| Step: 5
Training loss: 3.248265023398098
Validation loss: 2.9883433646043267

Epoch: 6| Step: 6
Training loss: 2.32054388774195
Validation loss: 2.9810445265362415

Epoch: 6| Step: 7
Training loss: 2.9268273799393927
Validation loss: 2.9791867196472146

Epoch: 6| Step: 8
Training loss: 3.3971006372888284
Validation loss: 2.9813558404788605

Epoch: 6| Step: 9
Training loss: 3.7270751856371356
Validation loss: 2.982354673723987

Epoch: 6| Step: 10
Training loss: 3.1977440272813693
Validation loss: 2.9784470238359586

Epoch: 6| Step: 11
Training loss: 4.020066473112378
Validation loss: 2.9739560552751065

Epoch: 6| Step: 12
Training loss: 3.0855539590570977
Validation loss: 2.970052980447825

Epoch: 6| Step: 13
Training loss: 2.93127398450592
Validation loss: 2.9581488454009253

Epoch: 17| Step: 0
Training loss: 3.8559903890561196
Validation loss: 2.956570205772342

Epoch: 6| Step: 1
Training loss: 3.652540101673894
Validation loss: 2.9552856430573535

Epoch: 6| Step: 2
Training loss: 2.7560630198610845
Validation loss: 2.9531637800050876

Epoch: 6| Step: 3
Training loss: 3.127362388309436
Validation loss: 2.9516000833697484

Epoch: 6| Step: 4
Training loss: 2.7445613660715567
Validation loss: 2.9578595366250764

Epoch: 6| Step: 5
Training loss: 3.2471434437253337
Validation loss: 2.960962106518753

Epoch: 6| Step: 6
Training loss: 2.8529922036627013
Validation loss: 2.9533044869358043

Epoch: 6| Step: 7
Training loss: 3.304000602740586
Validation loss: 2.949765275422325

Epoch: 6| Step: 8
Training loss: 2.7764555507449513
Validation loss: 2.944915696882243

Epoch: 6| Step: 9
Training loss: 3.1569836962922038
Validation loss: 2.9424401718183844

Epoch: 6| Step: 10
Training loss: 3.279488808409387
Validation loss: 2.9356937776823915

Epoch: 6| Step: 11
Training loss: 3.3513096711802084
Validation loss: 2.9348185389370545

Epoch: 6| Step: 12
Training loss: 3.3101565150570758
Validation loss: 2.9289866713275483

Epoch: 6| Step: 13
Training loss: 4.259544202392292
Validation loss: 2.9306680496734936

Epoch: 18| Step: 0
Training loss: 2.3127294890484187
Validation loss: 2.926161492619072

Epoch: 6| Step: 1
Training loss: 2.7236022619241687
Validation loss: 2.9274301864616636

Epoch: 6| Step: 2
Training loss: 2.749447680408239
Validation loss: 2.9270257775937245

Epoch: 6| Step: 3
Training loss: 3.807827446946967
Validation loss: 2.9240219767973064

Epoch: 6| Step: 4
Training loss: 3.1952226621501314
Validation loss: 2.920044426509126

Epoch: 6| Step: 5
Training loss: 3.272220649423817
Validation loss: 2.920029833258168

Epoch: 6| Step: 6
Training loss: 3.2038615054559676
Validation loss: 2.9189807683009206

Epoch: 6| Step: 7
Training loss: 2.4164655755225537
Validation loss: 2.9150994081998527

Epoch: 6| Step: 8
Training loss: 3.413041090772962
Validation loss: 2.9190414997410574

Epoch: 6| Step: 9
Training loss: 4.194568646229274
Validation loss: 2.916457839967103

Epoch: 6| Step: 10
Training loss: 3.046839004695231
Validation loss: 2.911222669178792

Epoch: 6| Step: 11
Training loss: 3.687107129909132
Validation loss: 2.9098505075774876

Epoch: 6| Step: 12
Training loss: 3.871371878016307
Validation loss: 2.9100379890637855

Epoch: 6| Step: 13
Training loss: 2.081232715798397
Validation loss: 2.9078504619245256

Epoch: 19| Step: 0
Training loss: 3.4221616302702373
Validation loss: 2.9106040304521823

Epoch: 6| Step: 1
Training loss: 3.486639133974367
Validation loss: 2.9086121323230576

Epoch: 6| Step: 2
Training loss: 3.4071670837546395
Validation loss: 2.909076913749729

Epoch: 6| Step: 3
Training loss: 3.679341488260018
Validation loss: 2.907380726408252

Epoch: 6| Step: 4
Training loss: 3.249277474711265
Validation loss: 2.9054440569393503

Epoch: 6| Step: 5
Training loss: 2.524122493588689
Validation loss: 2.900542977971637

Epoch: 6| Step: 6
Training loss: 3.508530167398718
Validation loss: 2.9006509371760925

Epoch: 6| Step: 7
Training loss: 3.477051432657308
Validation loss: 2.89827749477745

Epoch: 6| Step: 8
Training loss: 2.6071423327152448
Validation loss: 2.9036357941084465

Epoch: 6| Step: 9
Training loss: 2.684509032414901
Validation loss: 2.8958598726097713

Epoch: 6| Step: 10
Training loss: 3.347952510228033
Validation loss: 2.897844308767938

Epoch: 6| Step: 11
Training loss: 2.7111282501391174
Validation loss: 2.8954650622308753

Epoch: 6| Step: 12
Training loss: 3.258731556888858
Validation loss: 2.8914437856867594

Epoch: 6| Step: 13
Training loss: 3.393211116825714
Validation loss: 2.8888522178803506

Epoch: 20| Step: 0
Training loss: 2.836986169210557
Validation loss: 2.891802926532527

Epoch: 6| Step: 1
Training loss: 3.672378310751139
Validation loss: 2.891309459903693

Epoch: 6| Step: 2
Training loss: 3.2745167266469752
Validation loss: 2.891955641497995

Epoch: 6| Step: 3
Training loss: 3.3237433446593
Validation loss: 2.887802291663464

Epoch: 6| Step: 4
Training loss: 3.2922074239930894
Validation loss: 2.891709767755327

Epoch: 6| Step: 5
Training loss: 3.342736491679776
Validation loss: 2.8969573534225184

Epoch: 6| Step: 6
Training loss: 3.643489382078578
Validation loss: 2.899535329640064

Epoch: 6| Step: 7
Training loss: 2.671704113944327
Validation loss: 2.8924574719953644

Epoch: 6| Step: 8
Training loss: 3.34498644633605
Validation loss: 2.886819536575331

Epoch: 6| Step: 9
Training loss: 2.3827088380371513
Validation loss: 2.883138635555911

Epoch: 6| Step: 10
Training loss: 2.9397678143428427
Validation loss: 2.8837365515498314

Epoch: 6| Step: 11
Training loss: 3.6183085012498983
Validation loss: 2.8860323974460904

Epoch: 6| Step: 12
Training loss: 3.2262255328734915
Validation loss: 2.8949272105578516

Epoch: 6| Step: 13
Training loss: 2.6898576907268357
Validation loss: 2.9014213762581003

Epoch: 21| Step: 0
Training loss: 3.4181552683483525
Validation loss: 2.882927524884053

Epoch: 6| Step: 1
Training loss: 3.0823214820965936
Validation loss: 2.879592999487424

Epoch: 6| Step: 2
Training loss: 2.610330737851838
Validation loss: 2.881183877323725

Epoch: 6| Step: 3
Training loss: 2.9406855740120594
Validation loss: 2.887152054922495

Epoch: 6| Step: 4
Training loss: 3.559700518451924
Validation loss: 2.9193219141830657

Epoch: 6| Step: 5
Training loss: 3.830793797276034
Validation loss: 2.930953098402283

Epoch: 6| Step: 6
Training loss: 3.024813553289777
Validation loss: 2.879062129823647

Epoch: 6| Step: 7
Training loss: 2.487543928055613
Validation loss: 2.870308630804132

Epoch: 6| Step: 8
Training loss: 3.5629994895521424
Validation loss: 2.870688991995113

Epoch: 6| Step: 9
Training loss: 3.1726295813872376
Validation loss: 2.869978813961291

Epoch: 6| Step: 10
Training loss: 3.541296651622465
Validation loss: 2.872638477978819

Epoch: 6| Step: 11
Training loss: 2.474985480988427
Validation loss: 2.8731289884037974

Epoch: 6| Step: 12
Training loss: 3.3176229916090714
Validation loss: 2.876875830318337

Epoch: 6| Step: 13
Training loss: 3.5735205463455513
Validation loss: 2.8737064401237467

Epoch: 22| Step: 0
Training loss: 2.8037257338624717
Validation loss: 2.87118251502317

Epoch: 6| Step: 1
Training loss: 3.427078540802516
Validation loss: 2.869323605348731

Epoch: 6| Step: 2
Training loss: 3.701870347599247
Validation loss: 2.861507906626326

Epoch: 6| Step: 3
Training loss: 3.57148706660732
Validation loss: 2.858609251255807

Epoch: 6| Step: 4
Training loss: 3.2352271685073593
Validation loss: 2.859618409419354

Epoch: 6| Step: 5
Training loss: 3.087083203063487
Validation loss: 2.870646248094398

Epoch: 6| Step: 6
Training loss: 3.451826723207696
Validation loss: 2.8791902056204712

Epoch: 6| Step: 7
Training loss: 2.6229886114561873
Validation loss: 2.8576037325268304

Epoch: 6| Step: 8
Training loss: 2.984931774030635
Validation loss: 2.855390439194784

Epoch: 6| Step: 9
Training loss: 3.3441063521689465
Validation loss: 2.862138864510086

Epoch: 6| Step: 10
Training loss: 3.2027961376053984
Validation loss: 2.8495340106297764

Epoch: 6| Step: 11
Training loss: 3.360782204360539
Validation loss: 2.8497658839745363

Epoch: 6| Step: 12
Training loss: 2.949436204990223
Validation loss: 2.8489889131370747

Epoch: 6| Step: 13
Training loss: 1.6100324010254217
Validation loss: 2.8489135089568065

Epoch: 23| Step: 0
Training loss: 3.537779586041796
Validation loss: 2.8481744538676375

Epoch: 6| Step: 1
Training loss: 3.59295459735403
Validation loss: 2.84634091079829

Epoch: 6| Step: 2
Training loss: 3.347552837612926
Validation loss: 2.847411965658133

Epoch: 6| Step: 3
Training loss: 4.032566535717698
Validation loss: 2.844256154419274

Epoch: 6| Step: 4
Training loss: 2.4920281146990866
Validation loss: 2.846089203007927

Epoch: 6| Step: 5
Training loss: 2.7173498648096017
Validation loss: 2.8501456505014198

Epoch: 6| Step: 6
Training loss: 3.1288964965515897
Validation loss: 2.85599180183522

Epoch: 6| Step: 7
Training loss: 2.959500973365702
Validation loss: 2.8675430952249834

Epoch: 6| Step: 8
Training loss: 2.9363108723884537
Validation loss: 2.8756180857236475

Epoch: 6| Step: 9
Training loss: 3.195357268749642
Validation loss: 2.906001295266619

Epoch: 6| Step: 10
Training loss: 2.93472889806523
Validation loss: 2.8771839843826603

Epoch: 6| Step: 11
Training loss: 3.11441015742341
Validation loss: 2.853172377563524

Epoch: 6| Step: 12
Training loss: 2.8127543016542718
Validation loss: 2.8327824716400847

Epoch: 6| Step: 13
Training loss: 3.0861136470692316
Validation loss: 2.8319608131506455

Epoch: 24| Step: 0
Training loss: 2.775236164388076
Validation loss: 2.8371750816558836

Epoch: 6| Step: 1
Training loss: 3.5116332046901233
Validation loss: 2.8759130826518673

Epoch: 6| Step: 2
Training loss: 3.290504411333597
Validation loss: 2.888413391771352

Epoch: 6| Step: 3
Training loss: 3.3212047858959854
Validation loss: 2.8488051828181837

Epoch: 6| Step: 4
Training loss: 2.553062458743109
Validation loss: 2.836390245679459

Epoch: 6| Step: 5
Training loss: 3.1300898490904228
Validation loss: 2.8354764797704157

Epoch: 6| Step: 6
Training loss: 2.3969562939481515
Validation loss: 2.8299275316454704

Epoch: 6| Step: 7
Training loss: 2.8174920601381737
Validation loss: 2.8304929472359817

Epoch: 6| Step: 8
Training loss: 3.2486595910919855
Validation loss: 2.8396941223144228

Epoch: 6| Step: 9
Training loss: 2.8265570409077845
Validation loss: 2.8486592125503085

Epoch: 6| Step: 10
Training loss: 3.505656167944409
Validation loss: 2.8363416358879525

Epoch: 6| Step: 11
Training loss: 3.170831217286803
Validation loss: 2.830402207802464

Epoch: 6| Step: 12
Training loss: 4.096586220440017
Validation loss: 2.8280129758070083

Epoch: 6| Step: 13
Training loss: 3.3790870221242275
Validation loss: 2.824313419669361

Epoch: 25| Step: 0
Training loss: 3.7644243661024017
Validation loss: 2.822338265824967

Epoch: 6| Step: 1
Training loss: 2.6353358280212857
Validation loss: 2.821546602534939

Epoch: 6| Step: 2
Training loss: 2.8022881661085224
Validation loss: 2.8226491423468456

Epoch: 6| Step: 3
Training loss: 3.3521335355430435
Validation loss: 2.8215560446291734

Epoch: 6| Step: 4
Training loss: 2.8244187322490526
Validation loss: 2.82399381534025

Epoch: 6| Step: 5
Training loss: 2.8620048061306504
Validation loss: 2.820211852825841

Epoch: 6| Step: 6
Training loss: 3.4286981428663297
Validation loss: 2.8165923831894335

Epoch: 6| Step: 7
Training loss: 2.5732770247879007
Validation loss: 2.8176425957027997

Epoch: 6| Step: 8
Training loss: 3.010794610363021
Validation loss: 2.814642700925501

Epoch: 6| Step: 9
Training loss: 3.8620596131554477
Validation loss: 2.814929726618778

Epoch: 6| Step: 10
Training loss: 3.232958644773533
Validation loss: 2.814378784944055

Epoch: 6| Step: 11
Training loss: 3.0274848757428274
Validation loss: 2.8096113230370623

Epoch: 6| Step: 12
Training loss: 3.3817041004027337
Validation loss: 2.8069920156291026

Epoch: 6| Step: 13
Training loss: 2.8869072177672392
Validation loss: 2.806342732089319

Epoch: 26| Step: 0
Training loss: 3.087379601482445
Validation loss: 2.8029268910754697

Epoch: 6| Step: 1
Training loss: 3.284159505727092
Validation loss: 2.8001841858084737

Epoch: 6| Step: 2
Training loss: 3.599010564679928
Validation loss: 2.7987878193127194

Epoch: 6| Step: 3
Training loss: 2.7648326363708007
Validation loss: 2.797483209312552

Epoch: 6| Step: 4
Training loss: 3.2065377268044752
Validation loss: 2.796657113567354

Epoch: 6| Step: 5
Training loss: 3.0726663433639523
Validation loss: 2.7944192651490236

Epoch: 6| Step: 6
Training loss: 3.4712356047285464
Validation loss: 2.794025538170933

Epoch: 6| Step: 7
Training loss: 2.7793636139760207
Validation loss: 2.7919784510151975

Epoch: 6| Step: 8
Training loss: 3.283392651662709
Validation loss: 2.788880706705599

Epoch: 6| Step: 9
Training loss: 3.120169606611704
Validation loss: 2.7847633749182084

Epoch: 6| Step: 10
Training loss: 3.6986474116602746
Validation loss: 2.7914265290737

Epoch: 6| Step: 11
Training loss: 2.7377896160052817
Validation loss: 2.783378068066954

Epoch: 6| Step: 12
Training loss: 1.9241305505670894
Validation loss: 2.786215554211514

Epoch: 6| Step: 13
Training loss: 3.3407695000337805
Validation loss: 2.789786005777521

Epoch: 27| Step: 0
Training loss: 3.497559377672064
Validation loss: 2.7958261073632107

Epoch: 6| Step: 1
Training loss: 2.9672722601975194
Validation loss: 2.7915728049247512

Epoch: 6| Step: 2
Training loss: 2.862603704581272
Validation loss: 2.8024658540987684

Epoch: 6| Step: 3
Training loss: 3.3764588770396484
Validation loss: 2.802378056681424

Epoch: 6| Step: 4
Training loss: 3.337846482254557
Validation loss: 2.798689438316245

Epoch: 6| Step: 5
Training loss: 2.577242798575652
Validation loss: 2.782214539591536

Epoch: 6| Step: 6
Training loss: 3.4450232282721927
Validation loss: 2.7712725534021403

Epoch: 6| Step: 7
Training loss: 3.346784124200278
Validation loss: 2.7686730684715366

Epoch: 6| Step: 8
Training loss: 3.4316725840678863
Validation loss: 2.767293558460945

Epoch: 6| Step: 9
Training loss: 3.245075162419727
Validation loss: 2.768043293653846

Epoch: 6| Step: 10
Training loss: 2.6684539487773824
Validation loss: 2.7728939519178835

Epoch: 6| Step: 11
Training loss: 2.6341569224242445
Validation loss: 2.767448858856523

Epoch: 6| Step: 12
Training loss: 2.855792693876849
Validation loss: 2.7647347783078393

Epoch: 6| Step: 13
Training loss: 2.999074475255638
Validation loss: 2.765824640900176

Epoch: 28| Step: 0
Training loss: 3.2796472904090317
Validation loss: 2.772838042805558

Epoch: 6| Step: 1
Training loss: 3.090737311286802
Validation loss: 2.781567288023917

Epoch: 6| Step: 2
Training loss: 2.7974742907995287
Validation loss: 2.7913544035891227

Epoch: 6| Step: 3
Training loss: 2.8998634963959065
Validation loss: 2.7937314315729043

Epoch: 6| Step: 4
Training loss: 3.3653158486854653
Validation loss: 2.801794282791241

Epoch: 6| Step: 5
Training loss: 3.2058561265328676
Validation loss: 2.806106416409257

Epoch: 6| Step: 6
Training loss: 3.2956054557280092
Validation loss: 2.786007856117265

Epoch: 6| Step: 7
Training loss: 2.855069780983412
Validation loss: 2.780066702212843

Epoch: 6| Step: 8
Training loss: 2.211833435340672
Validation loss: 2.7649447503261246

Epoch: 6| Step: 9
Training loss: 2.908979057470046
Validation loss: 2.7609928439147717

Epoch: 6| Step: 10
Training loss: 2.9513815925857014
Validation loss: 2.7586735001837845

Epoch: 6| Step: 11
Training loss: 3.678335666376321
Validation loss: 2.7596302035096145

Epoch: 6| Step: 12
Training loss: 3.540819148963486
Validation loss: 2.76021923087384

Epoch: 6| Step: 13
Training loss: 3.0519373384695068
Validation loss: 2.760850993787592

Epoch: 29| Step: 0
Training loss: 3.7790705176883286
Validation loss: 2.7617238350979925

Epoch: 6| Step: 1
Training loss: 2.2510761230693705
Validation loss: 2.7593776831775676

Epoch: 6| Step: 2
Training loss: 2.8762562536431093
Validation loss: 2.7573905370321987

Epoch: 6| Step: 3
Training loss: 3.1911746516523714
Validation loss: 2.7550703627845

Epoch: 6| Step: 4
Training loss: 3.071686493065679
Validation loss: 2.7551345435371943

Epoch: 6| Step: 5
Training loss: 2.638671332866802
Validation loss: 2.751296575817271

Epoch: 6| Step: 6
Training loss: 3.1907320279245384
Validation loss: 2.751729427000132

Epoch: 6| Step: 7
Training loss: 3.4854976744205572
Validation loss: 2.7508363794296615

Epoch: 6| Step: 8
Training loss: 3.165078082575346
Validation loss: 2.753345794072501

Epoch: 6| Step: 9
Training loss: 3.48137176136366
Validation loss: 2.7528972996832852

Epoch: 6| Step: 10
Training loss: 2.6032235739408995
Validation loss: 2.7553445446741582

Epoch: 6| Step: 11
Training loss: 3.1708824972651386
Validation loss: 2.752931271540263

Epoch: 6| Step: 12
Training loss: 3.227286121423648
Validation loss: 2.7476196185480415

Epoch: 6| Step: 13
Training loss: 2.49966771778587
Validation loss: 2.7448927801614165

Epoch: 30| Step: 0
Training loss: 2.663649003948409
Validation loss: 2.7462792288468543

Epoch: 6| Step: 1
Training loss: 3.002951600529804
Validation loss: 2.7450317211213413

Epoch: 6| Step: 2
Training loss: 3.89603926714431
Validation loss: 2.751654404166127

Epoch: 6| Step: 3
Training loss: 2.7794149109685753
Validation loss: 2.751353213378576

Epoch: 6| Step: 4
Training loss: 2.8221968592941677
Validation loss: 2.7537286376928884

Epoch: 6| Step: 5
Training loss: 2.8151954450227357
Validation loss: 2.7494382200563208

Epoch: 6| Step: 6
Training loss: 3.15445847230218
Validation loss: 2.7412188288914465

Epoch: 6| Step: 7
Training loss: 2.9015244653496306
Validation loss: 2.7385242189296752

Epoch: 6| Step: 8
Training loss: 2.697456634851711
Validation loss: 2.7383222318989264

Epoch: 6| Step: 9
Training loss: 3.5613405448995756
Validation loss: 2.7395506776207585

Epoch: 6| Step: 10
Training loss: 3.2152904696084734
Validation loss: 2.743240057678128

Epoch: 6| Step: 11
Training loss: 3.3272318469879494
Validation loss: 2.7524521318357116

Epoch: 6| Step: 12
Training loss: 2.458178617705929
Validation loss: 2.7675387564629514

Epoch: 6| Step: 13
Training loss: 3.6764701497694765
Validation loss: 2.7491720562271973

Epoch: 31| Step: 0
Training loss: 3.6658772283413263
Validation loss: 2.7330318441724972

Epoch: 6| Step: 1
Training loss: 2.987184171063208
Validation loss: 2.735681870418598

Epoch: 6| Step: 2
Training loss: 3.3380116217006925
Validation loss: 2.7360543668054422

Epoch: 6| Step: 3
Training loss: 3.619940284953051
Validation loss: 2.7429622194662193

Epoch: 6| Step: 4
Training loss: 2.9674928914782797
Validation loss: 2.7401853252707498

Epoch: 6| Step: 5
Training loss: 2.5562478063149587
Validation loss: 2.7404233179006376

Epoch: 6| Step: 6
Training loss: 3.1646200560062425
Validation loss: 2.736483365275072

Epoch: 6| Step: 7
Training loss: 2.6223368986920232
Validation loss: 2.740145621179025

Epoch: 6| Step: 8
Training loss: 2.856006242964303
Validation loss: 2.7377502039749593

Epoch: 6| Step: 9
Training loss: 2.8918421476768192
Validation loss: 2.7357803722485694

Epoch: 6| Step: 10
Training loss: 2.8920470992456835
Validation loss: 2.736416599788878

Epoch: 6| Step: 11
Training loss: 2.9670268629482517
Validation loss: 2.738676801669455

Epoch: 6| Step: 12
Training loss: 3.495514720511976
Validation loss: 2.7405616108136805

Epoch: 6| Step: 13
Training loss: 2.5794366447711847
Validation loss: 2.7327621817902616

Epoch: 32| Step: 0
Training loss: 3.4057712043438695
Validation loss: 2.729353116738365

Epoch: 6| Step: 1
Training loss: 3.9139055841175727
Validation loss: 2.7267023392643512

Epoch: 6| Step: 2
Training loss: 2.761275842700251
Validation loss: 2.7251786467242964

Epoch: 6| Step: 3
Training loss: 2.133411700577593
Validation loss: 2.7281354508850946

Epoch: 6| Step: 4
Training loss: 3.513411846791631
Validation loss: 2.727141419721057

Epoch: 6| Step: 5
Training loss: 2.694796393918341
Validation loss: 2.724632324893649

Epoch: 6| Step: 6
Training loss: 2.5502063518132436
Validation loss: 2.7261220718090633

Epoch: 6| Step: 7
Training loss: 3.1045708275860826
Validation loss: 2.7245947154202015

Epoch: 6| Step: 8
Training loss: 2.332867598601554
Validation loss: 2.727144662880678

Epoch: 6| Step: 9
Training loss: 3.3884090090768217
Validation loss: 2.733960878388826

Epoch: 6| Step: 10
Training loss: 3.041099983275191
Validation loss: 2.7393336371590196

Epoch: 6| Step: 11
Training loss: 3.007439607567218
Validation loss: 2.7353463468363413

Epoch: 6| Step: 12
Training loss: 3.48278224789884
Validation loss: 2.733283377875452

Epoch: 6| Step: 13
Training loss: 3.0028001115336767
Validation loss: 2.72517820552476

Epoch: 33| Step: 0
Training loss: 3.2767666659872496
Validation loss: 2.718610503253406

Epoch: 6| Step: 1
Training loss: 2.7665351189129095
Validation loss: 2.7188014665729185

Epoch: 6| Step: 2
Training loss: 2.9753453927735563
Validation loss: 2.718587917446485

Epoch: 6| Step: 3
Training loss: 2.305866314985639
Validation loss: 2.7222717788630004

Epoch: 6| Step: 4
Training loss: 2.967726038974492
Validation loss: 2.7249952473730237

Epoch: 6| Step: 5
Training loss: 2.846602465987345
Validation loss: 2.730356406271519

Epoch: 6| Step: 6
Training loss: 3.483232524696845
Validation loss: 2.737900810138541

Epoch: 6| Step: 7
Training loss: 2.8434300504679726
Validation loss: 2.7292315479999507

Epoch: 6| Step: 8
Training loss: 2.5326274373563504
Validation loss: 2.7304011426366204

Epoch: 6| Step: 9
Training loss: 3.3771541926115587
Validation loss: 2.7279428883397645

Epoch: 6| Step: 10
Training loss: 2.752175077824189
Validation loss: 2.726721953608685

Epoch: 6| Step: 11
Training loss: 3.6395491291455806
Validation loss: 2.7295792402521344

Epoch: 6| Step: 12
Training loss: 3.60217796246982
Validation loss: 2.7275406528268813

Epoch: 6| Step: 13
Training loss: 3.121605211730079
Validation loss: 2.7259063377774986

Epoch: 34| Step: 0
Training loss: 3.1406127018474232
Validation loss: 2.7187179093947544

Epoch: 6| Step: 1
Training loss: 3.1097448694508962
Validation loss: 2.718443957397141

Epoch: 6| Step: 2
Training loss: 3.122627883870098
Validation loss: 2.720462650490451

Epoch: 6| Step: 3
Training loss: 3.0104803762767274
Validation loss: 2.718192039852549

Epoch: 6| Step: 4
Training loss: 3.099756748130893
Validation loss: 2.7170766004654925

Epoch: 6| Step: 5
Training loss: 3.2611903693470685
Validation loss: 2.719406182642015

Epoch: 6| Step: 6
Training loss: 2.6603136282145132
Validation loss: 2.719211264370555

Epoch: 6| Step: 7
Training loss: 2.841614308998235
Validation loss: 2.715126858664121

Epoch: 6| Step: 8
Training loss: 3.1345249737261764
Validation loss: 2.7106723479008776

Epoch: 6| Step: 9
Training loss: 3.1475968291619236
Validation loss: 2.7118578689534343

Epoch: 6| Step: 10
Training loss: 3.550737873815436
Validation loss: 2.709701019212172

Epoch: 6| Step: 11
Training loss: 2.802445729774059
Validation loss: 2.7103459527653513

Epoch: 6| Step: 12
Training loss: 2.7267321339825745
Validation loss: 2.71247444535855

Epoch: 6| Step: 13
Training loss: 2.873265282104605
Validation loss: 2.708868181852755

Epoch: 35| Step: 0
Training loss: 2.1566667015905048
Validation loss: 2.7054154693292127

Epoch: 6| Step: 1
Training loss: 2.3460417669014118
Validation loss: 2.7007414251406834

Epoch: 6| Step: 2
Training loss: 3.083008276498619
Validation loss: 2.706230856970713

Epoch: 6| Step: 3
Training loss: 3.63759909688193
Validation loss: 2.7028352808716023

Epoch: 6| Step: 4
Training loss: 3.3757894087279907
Validation loss: 2.701360544531797

Epoch: 6| Step: 5
Training loss: 2.6157661791839493
Validation loss: 2.7013533291359026

Epoch: 6| Step: 6
Training loss: 3.0852638764878826
Validation loss: 2.7105485027625726

Epoch: 6| Step: 7
Training loss: 2.647168420878909
Validation loss: 2.71732519012105

Epoch: 6| Step: 8
Training loss: 3.214670206718547
Validation loss: 2.7096069509159135

Epoch: 6| Step: 9
Training loss: 2.83119279748928
Validation loss: 2.7071386022799353

Epoch: 6| Step: 10
Training loss: 3.140504445661202
Validation loss: 2.696466558329342

Epoch: 6| Step: 11
Training loss: 2.8690678306158612
Validation loss: 2.694900716648766

Epoch: 6| Step: 12
Training loss: 3.1593565807314987
Validation loss: 2.6936993451634477

Epoch: 6| Step: 13
Training loss: 4.426456948640082
Validation loss: 2.689860900687176

Epoch: 36| Step: 0
Training loss: 3.232107353467075
Validation loss: 2.6892965283112438

Epoch: 6| Step: 1
Training loss: 2.9981194005885667
Validation loss: 2.693272546025665

Epoch: 6| Step: 2
Training loss: 2.930159467191816
Validation loss: 2.7030886021039677

Epoch: 6| Step: 3
Training loss: 3.2195675006205797
Validation loss: 2.6989540110479875

Epoch: 6| Step: 4
Training loss: 2.9264565517394496
Validation loss: 2.686874118354979

Epoch: 6| Step: 5
Training loss: 2.8114088696970216
Validation loss: 2.685908148277441

Epoch: 6| Step: 6
Training loss: 2.3946949341230606
Validation loss: 2.686266114815466

Epoch: 6| Step: 7
Training loss: 2.5425383735394065
Validation loss: 2.686353928937736

Epoch: 6| Step: 8
Training loss: 3.1094283669650777
Validation loss: 2.692583864107016

Epoch: 6| Step: 9
Training loss: 3.0951932372870457
Validation loss: 2.6976780394907216

Epoch: 6| Step: 10
Training loss: 3.7045652268792133
Validation loss: 2.7025939336270404

Epoch: 6| Step: 11
Training loss: 2.863636114552585
Validation loss: 2.6965267328921425

Epoch: 6| Step: 12
Training loss: 3.454724247882347
Validation loss: 2.687481370018549

Epoch: 6| Step: 13
Training loss: 3.043063396113146
Validation loss: 2.686394019611681

Epoch: 37| Step: 0
Training loss: 2.964381165535242
Validation loss: 2.6872554199389636

Epoch: 6| Step: 1
Training loss: 3.1514708339691797
Validation loss: 2.6954871869053445

Epoch: 6| Step: 2
Training loss: 3.499172385322299
Validation loss: 2.702586285173665

Epoch: 6| Step: 3
Training loss: 3.2244804259498903
Validation loss: 2.7057478124961905

Epoch: 6| Step: 4
Training loss: 3.5430064341297993
Validation loss: 2.6874863914456175

Epoch: 6| Step: 5
Training loss: 3.225647729691203
Validation loss: 2.6744667220121436

Epoch: 6| Step: 6
Training loss: 2.6309724711214346
Validation loss: 2.6754826195163632

Epoch: 6| Step: 7
Training loss: 2.364499117209999
Validation loss: 2.67482020268675

Epoch: 6| Step: 8
Training loss: 2.9325737735610216
Validation loss: 2.6761962980707463

Epoch: 6| Step: 9
Training loss: 2.9946040263340548
Validation loss: 2.6749605646486025

Epoch: 6| Step: 10
Training loss: 2.9116115541124326
Validation loss: 2.675156606506716

Epoch: 6| Step: 11
Training loss: 2.9245205086797523
Validation loss: 2.671762562532663

Epoch: 6| Step: 12
Training loss: 2.8723487239143615
Validation loss: 2.6724088555623835

Epoch: 6| Step: 13
Training loss: 2.8403459233506108
Validation loss: 2.6778237383638674

Epoch: 38| Step: 0
Training loss: 3.2377936682932624
Validation loss: 2.682185577833738

Epoch: 6| Step: 1
Training loss: 2.7786574549671785
Validation loss: 2.6876697138518444

Epoch: 6| Step: 2
Training loss: 3.0972935583303385
Validation loss: 2.696283220757975

Epoch: 6| Step: 3
Training loss: 3.5207243832918063
Validation loss: 2.6830960620805295

Epoch: 6| Step: 4
Training loss: 2.53186771720417
Validation loss: 2.6744635779288175

Epoch: 6| Step: 5
Training loss: 2.739949500460854
Validation loss: 2.68531026152475

Epoch: 6| Step: 6
Training loss: 3.0132903712369243
Validation loss: 2.670791067409985

Epoch: 6| Step: 7
Training loss: 2.976112632096739
Validation loss: 2.668374438295274

Epoch: 6| Step: 8
Training loss: 2.6528493317900574
Validation loss: 2.6680096089090024

Epoch: 6| Step: 9
Training loss: 3.20150328730817
Validation loss: 2.670000027815597

Epoch: 6| Step: 10
Training loss: 3.2378188517500552
Validation loss: 2.6698119843962305

Epoch: 6| Step: 11
Training loss: 2.9588902625297475
Validation loss: 2.673006777645979

Epoch: 6| Step: 12
Training loss: 2.9657240052172877
Validation loss: 2.6752794030317424

Epoch: 6| Step: 13
Training loss: 3.2202198413176726
Validation loss: 2.6725229714014147

Epoch: 39| Step: 0
Training loss: 3.3108159228799345
Validation loss: 2.676454919357067

Epoch: 6| Step: 1
Training loss: 2.638558386021676
Validation loss: 2.6740558970423804

Epoch: 6| Step: 2
Training loss: 2.708203434885674
Validation loss: 2.6726854159485756

Epoch: 6| Step: 3
Training loss: 3.2813377731935964
Validation loss: 2.6709514068182076

Epoch: 6| Step: 4
Training loss: 3.225779440674444
Validation loss: 2.6698043226889263

Epoch: 6| Step: 5
Training loss: 2.4762779096391023
Validation loss: 2.671926432072981

Epoch: 6| Step: 6
Training loss: 3.1094982947053356
Validation loss: 2.668759430107871

Epoch: 6| Step: 7
Training loss: 2.592012305889823
Validation loss: 2.666690188606667

Epoch: 6| Step: 8
Training loss: 3.4386970516497817
Validation loss: 2.6668736360842904

Epoch: 6| Step: 9
Training loss: 2.972399907331859
Validation loss: 2.6677964557748166

Epoch: 6| Step: 10
Training loss: 3.178166806106395
Validation loss: 2.6717629808884125

Epoch: 6| Step: 11
Training loss: 3.2167621881668103
Validation loss: 2.6810636320656918

Epoch: 6| Step: 12
Training loss: 3.0325814695177926
Validation loss: 2.6844026040039566

Epoch: 6| Step: 13
Training loss: 2.6719037327699406
Validation loss: 2.688581005541159

Epoch: 40| Step: 0
Training loss: 3.038711645275801
Validation loss: 2.6917737360502665

Epoch: 6| Step: 1
Training loss: 3.324811548614638
Validation loss: 2.690604744778344

Epoch: 6| Step: 2
Training loss: 2.899303707850636
Validation loss: 2.669884863139166

Epoch: 6| Step: 3
Training loss: 3.150855562793682
Validation loss: 2.660678978106831

Epoch: 6| Step: 4
Training loss: 2.266362458272473
Validation loss: 2.6560582120062657

Epoch: 6| Step: 5
Training loss: 3.1877519096612317
Validation loss: 2.6523209207989376

Epoch: 6| Step: 6
Training loss: 2.7866177997532877
Validation loss: 2.6527983938066537

Epoch: 6| Step: 7
Training loss: 2.747255863523288
Validation loss: 2.652878242598544

Epoch: 6| Step: 8
Training loss: 3.2281767937935655
Validation loss: 2.653420716271775

Epoch: 6| Step: 9
Training loss: 3.060009936646927
Validation loss: 2.65007861789477

Epoch: 6| Step: 10
Training loss: 2.7854069707944724
Validation loss: 2.6537122828716977

Epoch: 6| Step: 11
Training loss: 2.935026060440327
Validation loss: 2.6500825377272244

Epoch: 6| Step: 12
Training loss: 3.246276189311384
Validation loss: 2.6505353747846225

Epoch: 6| Step: 13
Training loss: 3.4913917676070887
Validation loss: 2.6525731107550343

Epoch: 41| Step: 0
Training loss: 2.716833645032219
Validation loss: 2.6588606309100573

Epoch: 6| Step: 1
Training loss: 3.663056257794318
Validation loss: 2.658134686509736

Epoch: 6| Step: 2
Training loss: 3.1280627691307714
Validation loss: 2.6761098366676155

Epoch: 6| Step: 3
Training loss: 2.845653525648741
Validation loss: 2.666641143579267

Epoch: 6| Step: 4
Training loss: 2.5289866371329683
Validation loss: 2.663035147186457

Epoch: 6| Step: 5
Training loss: 2.494636217555713
Validation loss: 2.6566961908997206

Epoch: 6| Step: 6
Training loss: 2.631449451271981
Validation loss: 2.6581319330007274

Epoch: 6| Step: 7
Training loss: 3.0052910875444367
Validation loss: 2.656371656378929

Epoch: 6| Step: 8
Training loss: 2.739203326385475
Validation loss: 2.673014338102136

Epoch: 6| Step: 9
Training loss: 2.7705666741191677
Validation loss: 2.672643446769411

Epoch: 6| Step: 10
Training loss: 3.2850904968430825
Validation loss: 2.656938220243964

Epoch: 6| Step: 11
Training loss: 3.1606692356350488
Validation loss: 2.6443456379036108

Epoch: 6| Step: 12
Training loss: 3.4363731618091404
Validation loss: 2.646522955001585

Epoch: 6| Step: 13
Training loss: 3.4718218424218685
Validation loss: 2.6458379079946965

Epoch: 42| Step: 0
Training loss: 3.314173725425359
Validation loss: 2.646707590112793

Epoch: 6| Step: 1
Training loss: 3.270758140007421
Validation loss: 2.6466021523341503

Epoch: 6| Step: 2
Training loss: 2.753175982242468
Validation loss: 2.6470136993029034

Epoch: 6| Step: 3
Training loss: 3.0252372648650265
Validation loss: 2.648178898645813

Epoch: 6| Step: 4
Training loss: 3.1572303382574853
Validation loss: 2.6499672098079485

Epoch: 6| Step: 5
Training loss: 2.7509895625025638
Validation loss: 2.644182127110698

Epoch: 6| Step: 6
Training loss: 2.1113159292258774
Validation loss: 2.6468089343585137

Epoch: 6| Step: 7
Training loss: 2.745737413536079
Validation loss: 2.6426144841999317

Epoch: 6| Step: 8
Training loss: 2.5953257726321888
Validation loss: 2.6422271838669222

Epoch: 6| Step: 9
Training loss: 3.450248244932552
Validation loss: 2.6473689669032505

Epoch: 6| Step: 10
Training loss: 3.3411150381086814
Validation loss: 2.651725232373539

Epoch: 6| Step: 11
Training loss: 2.7633298844276446
Validation loss: 2.654633558970656

Epoch: 6| Step: 12
Training loss: 3.3534305941644194
Validation loss: 2.655624373879747

Epoch: 6| Step: 13
Training loss: 3.1504823466770344
Validation loss: 2.6669882271557177

Epoch: 43| Step: 0
Training loss: 2.838244128017287
Validation loss: 2.666503077021741

Epoch: 6| Step: 1
Training loss: 3.423274620565463
Validation loss: 2.6650874405693634

Epoch: 6| Step: 2
Training loss: 2.6859383592498807
Validation loss: 2.656420738528484

Epoch: 6| Step: 3
Training loss: 3.3995881336052185
Validation loss: 2.6542010826485756

Epoch: 6| Step: 4
Training loss: 2.7035411889177055
Validation loss: 2.6509785664696834

Epoch: 6| Step: 5
Training loss: 2.7274806709199058
Validation loss: 2.6459611059731474

Epoch: 6| Step: 6
Training loss: 2.5203058515864245
Validation loss: 2.6399738605773835

Epoch: 6| Step: 7
Training loss: 3.360403923551296
Validation loss: 2.6398052261746785

Epoch: 6| Step: 8
Training loss: 2.963555218085138
Validation loss: 2.636468749232118

Epoch: 6| Step: 9
Training loss: 3.0617160961609766
Validation loss: 2.6403850600045766

Epoch: 6| Step: 10
Training loss: 3.087596283310987
Validation loss: 2.640157118464846

Epoch: 6| Step: 11
Training loss: 3.1281770959073554
Validation loss: 2.63547220057697

Epoch: 6| Step: 12
Training loss: 3.094882488084365
Validation loss: 2.6337959305613023

Epoch: 6| Step: 13
Training loss: 2.3157236466908175
Validation loss: 2.638301620665416

Epoch: 44| Step: 0
Training loss: 3.1330920924664007
Validation loss: 2.637242922559446

Epoch: 6| Step: 1
Training loss: 3.510653494402954
Validation loss: 2.6414552021747038

Epoch: 6| Step: 2
Training loss: 3.0211273751805683
Validation loss: 2.635412164058695

Epoch: 6| Step: 3
Training loss: 2.876499448434375
Validation loss: 2.6346808242867503

Epoch: 6| Step: 4
Training loss: 3.276890356190475
Validation loss: 2.635229021757808

Epoch: 6| Step: 5
Training loss: 2.85555341310664
Validation loss: 2.6335883633381907

Epoch: 6| Step: 6
Training loss: 3.237246505651754
Validation loss: 2.6316281835368147

Epoch: 6| Step: 7
Training loss: 1.7404263066244094
Validation loss: 2.6285347819854885

Epoch: 6| Step: 8
Training loss: 2.788573235518453
Validation loss: 2.6289860687184436

Epoch: 6| Step: 9
Training loss: 3.326749275522203
Validation loss: 2.6316533051894755

Epoch: 6| Step: 10
Training loss: 3.2219323287288644
Validation loss: 2.628785988809801

Epoch: 6| Step: 11
Training loss: 2.840677131199655
Validation loss: 2.6305161552575322

Epoch: 6| Step: 12
Training loss: 2.728298476254203
Validation loss: 2.635321303184107

Epoch: 6| Step: 13
Training loss: 2.937022880602751
Validation loss: 2.6276772583018677

Epoch: 45| Step: 0
Training loss: 2.5278555633351507
Validation loss: 2.6240139528788213

Epoch: 6| Step: 1
Training loss: 2.5566035093872936
Validation loss: 2.6325645949597734

Epoch: 6| Step: 2
Training loss: 3.1062296385068944
Validation loss: 2.655930013281478

Epoch: 6| Step: 3
Training loss: 3.1854804129716103
Validation loss: 2.6960277262921837

Epoch: 6| Step: 4
Training loss: 2.761539178214298
Validation loss: 2.7434601699560055

Epoch: 6| Step: 5
Training loss: 2.3271644197940486
Validation loss: 2.746742170230756

Epoch: 6| Step: 6
Training loss: 2.8869782409905063
Validation loss: 2.725469291386857

Epoch: 6| Step: 7
Training loss: 3.5709786158903953
Validation loss: 2.6639049823756795

Epoch: 6| Step: 8
Training loss: 3.4359868273765652
Validation loss: 2.634168398727825

Epoch: 6| Step: 9
Training loss: 2.7407423596716254
Validation loss: 2.6224687118530574

Epoch: 6| Step: 10
Training loss: 2.6305253143165634
Validation loss: 2.6270958678040923

Epoch: 6| Step: 11
Training loss: 3.5945308997873933
Validation loss: 2.6329752008607126

Epoch: 6| Step: 12
Training loss: 2.95847413350335
Validation loss: 2.635318720398769

Epoch: 6| Step: 13
Training loss: 3.4087140331602006
Validation loss: 2.6462093070315675

Epoch: 46| Step: 0
Training loss: 2.828035974945499
Validation loss: 2.6344795148026803

Epoch: 6| Step: 1
Training loss: 3.576789840065748
Validation loss: 2.633303581654883

Epoch: 6| Step: 2
Training loss: 2.9345139280668877
Validation loss: 2.638557058806782

Epoch: 6| Step: 3
Training loss: 3.318226596629897
Validation loss: 2.6363836931026396

Epoch: 6| Step: 4
Training loss: 3.0376381171578926
Validation loss: 2.633358903765672

Epoch: 6| Step: 5
Training loss: 3.0532471365887504
Validation loss: 2.6349495671569287

Epoch: 6| Step: 6
Training loss: 2.973503723850359
Validation loss: 2.6350678269740113

Epoch: 6| Step: 7
Training loss: 2.8471314165061727
Validation loss: 2.630431186361

Epoch: 6| Step: 8
Training loss: 3.3686888284030365
Validation loss: 2.6352300996577624

Epoch: 6| Step: 9
Training loss: 1.9470338980060777
Validation loss: 2.6389558495591494

Epoch: 6| Step: 10
Training loss: 3.3209573994574564
Validation loss: 2.651497545400934

Epoch: 6| Step: 11
Training loss: 3.1583430837784348
Validation loss: 2.658046536156319

Epoch: 6| Step: 12
Training loss: 2.4593039283032057
Validation loss: 2.6639703009258486

Epoch: 6| Step: 13
Training loss: 2.3176105835835905
Validation loss: 2.679382710610097

Epoch: 47| Step: 0
Training loss: 2.5063405693603538
Validation loss: 2.7159528986554466

Epoch: 6| Step: 1
Training loss: 2.974911690050418
Validation loss: 2.817905132025082

Epoch: 6| Step: 2
Training loss: 3.0599656809957967
Validation loss: 2.7529454142508807

Epoch: 6| Step: 3
Training loss: 3.06814428749635
Validation loss: 2.663842092246121

Epoch: 6| Step: 4
Training loss: 2.5042492040994864
Validation loss: 2.6313038054951545

Epoch: 6| Step: 5
Training loss: 3.027003036522705
Validation loss: 2.6273586636128603

Epoch: 6| Step: 6
Training loss: 3.4041479781784494
Validation loss: 2.6289327472903823

Epoch: 6| Step: 7
Training loss: 2.845800645527883
Validation loss: 2.6338546636290414

Epoch: 6| Step: 8
Training loss: 2.4101285515527517
Validation loss: 2.629668776074586

Epoch: 6| Step: 9
Training loss: 3.3146756782511537
Validation loss: 2.6412585059779183

Epoch: 6| Step: 10
Training loss: 2.8815731703102823
Validation loss: 2.6597930355222057

Epoch: 6| Step: 11
Training loss: 3.276851503417825
Validation loss: 2.641876144685104

Epoch: 6| Step: 12
Training loss: 3.1250390622558624
Validation loss: 2.628234006943575

Epoch: 6| Step: 13
Training loss: 3.822130765178058
Validation loss: 2.6225268564448663

Epoch: 48| Step: 0
Training loss: 2.6128133631498245
Validation loss: 2.6243669896133133

Epoch: 6| Step: 1
Training loss: 3.142894930426592
Validation loss: 2.618661587869034

Epoch: 6| Step: 2
Training loss: 2.675217261359775
Validation loss: 2.6168722257595975

Epoch: 6| Step: 3
Training loss: 3.0381918790291746
Validation loss: 2.6239416017159174

Epoch: 6| Step: 4
Training loss: 3.149087162055638
Validation loss: 2.6391067212762973

Epoch: 6| Step: 5
Training loss: 2.6715677542015115
Validation loss: 2.655530653852659

Epoch: 6| Step: 6
Training loss: 3.297519132776984
Validation loss: 2.6821328858163223

Epoch: 6| Step: 7
Training loss: 2.7930640997983334
Validation loss: 2.6654629217620864

Epoch: 6| Step: 8
Training loss: 3.1381115321220037
Validation loss: 2.646032931591197

Epoch: 6| Step: 9
Training loss: 3.214648253567572
Validation loss: 2.626356484398608

Epoch: 6| Step: 10
Training loss: 2.8383466087773033
Validation loss: 2.615797298262523

Epoch: 6| Step: 11
Training loss: 2.832130588236221
Validation loss: 2.609981370864999

Epoch: 6| Step: 12
Training loss: 3.1840445544513734
Validation loss: 2.611518398570449

Epoch: 6| Step: 13
Training loss: 2.969991324055648
Validation loss: 2.6106339575550144

Epoch: 49| Step: 0
Training loss: 3.6771420626322415
Validation loss: 2.611010307179154

Epoch: 6| Step: 1
Training loss: 3.1680092391544057
Validation loss: 2.610458030386388

Epoch: 6| Step: 2
Training loss: 2.289365260181334
Validation loss: 2.6091355780162746

Epoch: 6| Step: 3
Training loss: 3.0055357403747376
Validation loss: 2.608271533928907

Epoch: 6| Step: 4
Training loss: 3.105976336760569
Validation loss: 2.609605265805237

Epoch: 6| Step: 5
Training loss: 3.164877101446554
Validation loss: 2.6077698477883917

Epoch: 6| Step: 6
Training loss: 2.6064471419532733
Validation loss: 2.6085609894035944

Epoch: 6| Step: 7
Training loss: 2.9726148645074137
Validation loss: 2.605893728860985

Epoch: 6| Step: 8
Training loss: 2.1294974809762923
Validation loss: 2.6091355593475734

Epoch: 6| Step: 9
Training loss: 3.0294508166276954
Validation loss: 2.6036469588627154

Epoch: 6| Step: 10
Training loss: 3.2971886942086415
Validation loss: 2.6037630358216903

Epoch: 6| Step: 11
Training loss: 3.439835881820507
Validation loss: 2.60907526955442

Epoch: 6| Step: 12
Training loss: 2.51231270466827
Validation loss: 2.6198569962633718

Epoch: 6| Step: 13
Training loss: 2.5199200470668943
Validation loss: 2.624677794566514

Epoch: 50| Step: 0
Training loss: 2.8308678914422742
Validation loss: 2.6358835517784804

Epoch: 6| Step: 1
Training loss: 2.7774922563254347
Validation loss: 2.67674103474103

Epoch: 6| Step: 2
Training loss: 2.570032539310114
Validation loss: 2.663553634562062

Epoch: 6| Step: 3
Training loss: 3.08014221705273
Validation loss: 2.6640253292670164

Epoch: 6| Step: 4
Training loss: 2.8145596062492846
Validation loss: 2.6257895245774554

Epoch: 6| Step: 5
Training loss: 2.958875436319726
Validation loss: 2.6199706857223823

Epoch: 6| Step: 6
Training loss: 2.9623034705793803
Validation loss: 2.613361024067383

Epoch: 6| Step: 7
Training loss: 2.934299754842632
Validation loss: 2.6128246800572894

Epoch: 6| Step: 8
Training loss: 2.7397712865448614
Validation loss: 2.604112410113454

Epoch: 6| Step: 9
Training loss: 3.0631660204314075
Validation loss: 2.6042763566737257

Epoch: 6| Step: 10
Training loss: 3.182983639535136
Validation loss: 2.604815918415614

Epoch: 6| Step: 11
Training loss: 3.3227753962957705
Validation loss: 2.6050709456732313

Epoch: 6| Step: 12
Training loss: 2.68852985965265
Validation loss: 2.601761442485436

Epoch: 6| Step: 13
Training loss: 3.702852392021206
Validation loss: 2.602410809293187

Epoch: 51| Step: 0
Training loss: 3.2846955147522867
Validation loss: 2.6096876867198224

Epoch: 6| Step: 1
Training loss: 3.3223887694880196
Validation loss: 2.6040394804054614

Epoch: 6| Step: 2
Training loss: 2.7207285379399107
Validation loss: 2.599406067412191

Epoch: 6| Step: 3
Training loss: 3.143084876987148
Validation loss: 2.600697950799665

Epoch: 6| Step: 4
Training loss: 3.146995346662283
Validation loss: 2.601616929293637

Epoch: 6| Step: 5
Training loss: 3.206218435269669
Validation loss: 2.5998647325303024

Epoch: 6| Step: 6
Training loss: 2.759003552226109
Validation loss: 2.6019094621898033

Epoch: 6| Step: 7
Training loss: 2.6463322106566545
Validation loss: 2.5981047873528134

Epoch: 6| Step: 8
Training loss: 3.03972361613282
Validation loss: 2.5984871860783243

Epoch: 6| Step: 9
Training loss: 2.889006290332552
Validation loss: 2.6007102194278158

Epoch: 6| Step: 10
Training loss: 2.2830696686964203
Validation loss: 2.5972682675782934

Epoch: 6| Step: 11
Training loss: 2.7451239619380123
Validation loss: 2.598396290968149

Epoch: 6| Step: 12
Training loss: 2.976285025411752
Validation loss: 2.5970481050275493

Epoch: 6| Step: 13
Training loss: 3.180115467110475
Validation loss: 2.605126158794198

Epoch: 52| Step: 0
Training loss: 2.886906391905529
Validation loss: 2.6046812773837624

Epoch: 6| Step: 1
Training loss: 2.8410949049784024
Validation loss: 2.607050182726336

Epoch: 6| Step: 2
Training loss: 2.982807486736227
Validation loss: 2.6083308957997446

Epoch: 6| Step: 3
Training loss: 2.528102471966801
Validation loss: 2.616542114947018

Epoch: 6| Step: 4
Training loss: 2.9993368051540914
Validation loss: 2.610494556091066

Epoch: 6| Step: 5
Training loss: 2.5877115209248776
Validation loss: 2.609900369772687

Epoch: 6| Step: 6
Training loss: 2.217972202708159
Validation loss: 2.60420073521797

Epoch: 6| Step: 7
Training loss: 2.6631890708165096
Validation loss: 2.6118992947741684

Epoch: 6| Step: 8
Training loss: 2.792204041263915
Validation loss: 2.6097475173683278

Epoch: 6| Step: 9
Training loss: 2.9535854727390896
Validation loss: 2.5926225091824766

Epoch: 6| Step: 10
Training loss: 3.6186867031431955
Validation loss: 2.5904606880092467

Epoch: 6| Step: 11
Training loss: 3.2713397822524133
Validation loss: 2.5922425830825118

Epoch: 6| Step: 12
Training loss: 3.2620701766145688
Validation loss: 2.5930709552915268

Epoch: 6| Step: 13
Training loss: 3.5893352426502125
Validation loss: 2.5974510573823815

Epoch: 53| Step: 0
Training loss: 2.512118816402478
Validation loss: 2.5981102400440808

Epoch: 6| Step: 1
Training loss: 3.4670936822769254
Validation loss: 2.6032031068733335

Epoch: 6| Step: 2
Training loss: 3.2667862137179555
Validation loss: 2.6024642377332134

Epoch: 6| Step: 3
Training loss: 2.420337902943018
Validation loss: 2.606271845972732

Epoch: 6| Step: 4
Training loss: 3.3473867443660317
Validation loss: 2.6041638997381136

Epoch: 6| Step: 5
Training loss: 3.3234810823166425
Validation loss: 2.615911221980131

Epoch: 6| Step: 6
Training loss: 2.707929453935282
Validation loss: 2.60814192700387

Epoch: 6| Step: 7
Training loss: 3.310781933026795
Validation loss: 2.604653013693864

Epoch: 6| Step: 8
Training loss: 2.6539537265541067
Validation loss: 2.6002992490134713

Epoch: 6| Step: 9
Training loss: 3.3282449190268184
Validation loss: 2.599054902474279

Epoch: 6| Step: 10
Training loss: 3.0308631571478046
Validation loss: 2.5935771403685304

Epoch: 6| Step: 11
Training loss: 2.274961085563095
Validation loss: 2.5968314886603423

Epoch: 6| Step: 12
Training loss: 2.8757595219992127
Validation loss: 2.6028267591020056

Epoch: 6| Step: 13
Training loss: 2.3113272502691853
Validation loss: 2.622455398813914

Epoch: 54| Step: 0
Training loss: 3.2758963370218366
Validation loss: 2.646412041430177

Epoch: 6| Step: 1
Training loss: 2.7723126776578857
Validation loss: 2.6480881563455507

Epoch: 6| Step: 2
Training loss: 2.599575074024738
Validation loss: 2.6782725397209526

Epoch: 6| Step: 3
Training loss: 3.4036614617842864
Validation loss: 2.6979910052819944

Epoch: 6| Step: 4
Training loss: 2.725228581771902
Validation loss: 2.6826610781916944

Epoch: 6| Step: 5
Training loss: 3.0141832136677826
Validation loss: 2.6359623033638804

Epoch: 6| Step: 6
Training loss: 2.9739988806388302
Validation loss: 2.611084898826773

Epoch: 6| Step: 7
Training loss: 2.79843215643683
Validation loss: 2.6001851776319636

Epoch: 6| Step: 8
Training loss: 2.71065324068036
Validation loss: 2.5983935807100855

Epoch: 6| Step: 9
Training loss: 3.1902859050857755
Validation loss: 2.594650126203797

Epoch: 6| Step: 10
Training loss: 3.4048578059548937
Validation loss: 2.595001809166592

Epoch: 6| Step: 11
Training loss: 2.693204813084621
Validation loss: 2.5900034833799057

Epoch: 6| Step: 12
Training loss: 3.1267173625791798
Validation loss: 2.5915905626092006

Epoch: 6| Step: 13
Training loss: 1.7476180077957182
Validation loss: 2.5921291916568214

Epoch: 55| Step: 0
Training loss: 3.277953026463493
Validation loss: 2.5906711852077895

Epoch: 6| Step: 1
Training loss: 2.6024218906843366
Validation loss: 2.5897037451742126

Epoch: 6| Step: 2
Training loss: 2.806495020307578
Validation loss: 2.587581065495615

Epoch: 6| Step: 3
Training loss: 3.2615285486740597
Validation loss: 2.5889501091988065

Epoch: 6| Step: 4
Training loss: 2.7679252756760024
Validation loss: 2.5861566287963917

Epoch: 6| Step: 5
Training loss: 2.5302063474075442
Validation loss: 2.5838165076136455

Epoch: 6| Step: 6
Training loss: 2.7724432224139033
Validation loss: 2.5850949435475945

Epoch: 6| Step: 7
Training loss: 3.1931622645588704
Validation loss: 2.587994611264187

Epoch: 6| Step: 8
Training loss: 2.902410945396856
Validation loss: 2.5944135251833846

Epoch: 6| Step: 9
Training loss: 2.9514374932170235
Validation loss: 2.592326804065007

Epoch: 6| Step: 10
Training loss: 3.605716188480807
Validation loss: 2.5953615106811716

Epoch: 6| Step: 11
Training loss: 2.630957065685781
Validation loss: 2.5902633073491224

Epoch: 6| Step: 12
Training loss: 2.936593423103918
Validation loss: 2.599932717011994

Epoch: 6| Step: 13
Training loss: 2.403584676166352
Validation loss: 2.6127097131464785

Epoch: 56| Step: 0
Training loss: 3.1270385196803145
Validation loss: 2.6106754977575597

Epoch: 6| Step: 1
Training loss: 2.542946342217183
Validation loss: 2.6171602745152245

Epoch: 6| Step: 2
Training loss: 3.055114247984403
Validation loss: 2.6223989648936015

Epoch: 6| Step: 3
Training loss: 2.9433762234089778
Validation loss: 2.6157004684142455

Epoch: 6| Step: 4
Training loss: 2.666595507705488
Validation loss: 2.593785931738262

Epoch: 6| Step: 5
Training loss: 3.031378359878916
Validation loss: 2.587423425759734

Epoch: 6| Step: 6
Training loss: 2.3888364596367606
Validation loss: 2.578856238275121

Epoch: 6| Step: 7
Training loss: 3.1677706617708568
Validation loss: 2.5789200388151783

Epoch: 6| Step: 8
Training loss: 2.875041132093673
Validation loss: 2.578055342612328

Epoch: 6| Step: 9
Training loss: 2.7512676611770654
Validation loss: 2.5817025171320904

Epoch: 6| Step: 10
Training loss: 3.0779375512999203
Validation loss: 2.5807597737984764

Epoch: 6| Step: 11
Training loss: 2.8928141784168595
Validation loss: 2.5772535355847506

Epoch: 6| Step: 12
Training loss: 3.148383734080699
Validation loss: 2.5845084922975294

Epoch: 6| Step: 13
Training loss: 3.587165439437186
Validation loss: 2.588415476597595

Epoch: 57| Step: 0
Training loss: 3.005357409150912
Validation loss: 2.5800936156307452

Epoch: 6| Step: 1
Training loss: 2.7728821104338817
Validation loss: 2.576107063981169

Epoch: 6| Step: 2
Training loss: 2.7681349232595474
Validation loss: 2.5746457027514493

Epoch: 6| Step: 3
Training loss: 2.9855462616936435
Validation loss: 2.5786023694558455

Epoch: 6| Step: 4
Training loss: 2.5916149130148254
Validation loss: 2.57474801152406

Epoch: 6| Step: 5
Training loss: 3.1458837408275633
Validation loss: 2.576294586242743

Epoch: 6| Step: 6
Training loss: 2.814191182618747
Validation loss: 2.5787788881928932

Epoch: 6| Step: 7
Training loss: 3.417306297410618
Validation loss: 2.5744241054359587

Epoch: 6| Step: 8
Training loss: 2.732266381442812
Validation loss: 2.5737315420256373

Epoch: 6| Step: 9
Training loss: 3.1961488258840056
Validation loss: 2.571057845391828

Epoch: 6| Step: 10
Training loss: 2.641248369843774
Validation loss: 2.5709892564181827

Epoch: 6| Step: 11
Training loss: 2.7001963720612747
Validation loss: 2.573436303133505

Epoch: 6| Step: 12
Training loss: 3.211968546446147
Validation loss: 2.582260517070697

Epoch: 6| Step: 13
Training loss: 2.922966248428662
Validation loss: 2.5848821197694316

Epoch: 58| Step: 0
Training loss: 2.72110567312068
Validation loss: 2.584515270117585

Epoch: 6| Step: 1
Training loss: 2.5350076546638083
Validation loss: 2.577360509323658

Epoch: 6| Step: 2
Training loss: 2.5735604308366673
Validation loss: 2.571518120888652

Epoch: 6| Step: 3
Training loss: 2.643544405976035
Validation loss: 2.5713740615028393

Epoch: 6| Step: 4
Training loss: 2.5994299777271257
Validation loss: 2.5730163035472633

Epoch: 6| Step: 5
Training loss: 3.1370198828541658
Validation loss: 2.5712096741199866

Epoch: 6| Step: 6
Training loss: 2.8668563609975797
Validation loss: 2.5808768374139026

Epoch: 6| Step: 7
Training loss: 3.1852904496636194
Validation loss: 2.588865020819498

Epoch: 6| Step: 8
Training loss: 3.088335327323466
Validation loss: 2.5900894311074762

Epoch: 6| Step: 9
Training loss: 2.955279820549828
Validation loss: 2.608405883491937

Epoch: 6| Step: 10
Training loss: 2.3700123666690143
Validation loss: 2.623753618492696

Epoch: 6| Step: 11
Training loss: 3.3572443393105913
Validation loss: 2.646950147311959

Epoch: 6| Step: 12
Training loss: 3.973875805692395
Validation loss: 2.6807603331895806

Epoch: 6| Step: 13
Training loss: 2.8180696228772533
Validation loss: 2.62257985943086

Epoch: 59| Step: 0
Training loss: 2.7190709417922556
Validation loss: 2.582866909091074

Epoch: 6| Step: 1
Training loss: 3.1541549225508345
Validation loss: 2.567785924379701

Epoch: 6| Step: 2
Training loss: 2.840300259634599
Validation loss: 2.562949248520429

Epoch: 6| Step: 3
Training loss: 3.122275881760568
Validation loss: 2.5631073902920067

Epoch: 6| Step: 4
Training loss: 2.858173055205191
Validation loss: 2.570678136358602

Epoch: 6| Step: 5
Training loss: 3.2822455939365685
Validation loss: 2.5856230733943804

Epoch: 6| Step: 6
Training loss: 3.2114346530044138
Validation loss: 2.591454845662116

Epoch: 6| Step: 7
Training loss: 2.8749956877302916
Validation loss: 2.587306961548065

Epoch: 6| Step: 8
Training loss: 2.812595450582991
Validation loss: 2.59960791547718

Epoch: 6| Step: 9
Training loss: 2.681164037220107
Validation loss: 2.5999437054313033

Epoch: 6| Step: 10
Training loss: 3.605218252487814
Validation loss: 2.6044379511807345

Epoch: 6| Step: 11
Training loss: 2.3676234684202027
Validation loss: 2.5950312508357825

Epoch: 6| Step: 12
Training loss: 2.6506576010064817
Validation loss: 2.5937595933108404

Epoch: 6| Step: 13
Training loss: 3.01629362451819
Validation loss: 2.5890677035546394

Epoch: 60| Step: 0
Training loss: 2.764672239168118
Validation loss: 2.5867315330539737

Epoch: 6| Step: 1
Training loss: 2.916516291057017
Validation loss: 2.597288689618204

Epoch: 6| Step: 2
Training loss: 3.343171827295344
Validation loss: 2.613043445654135

Epoch: 6| Step: 3
Training loss: 2.5288189174973907
Validation loss: 2.5999107844062763

Epoch: 6| Step: 4
Training loss: 3.211289732239177
Validation loss: 2.596091652392742

Epoch: 6| Step: 5
Training loss: 2.7927835042915987
Validation loss: 2.599221423239483

Epoch: 6| Step: 6
Training loss: 2.4456722494582177
Validation loss: 2.5943326862660188

Epoch: 6| Step: 7
Training loss: 2.950066652999744
Validation loss: 2.5884495758381765

Epoch: 6| Step: 8
Training loss: 3.318597040764324
Validation loss: 2.592121774074265

Epoch: 6| Step: 9
Training loss: 2.9924856490553546
Validation loss: 2.5858200170972987

Epoch: 6| Step: 10
Training loss: 2.860137170823332
Validation loss: 2.5856814204224072

Epoch: 6| Step: 11
Training loss: 2.869137134900447
Validation loss: 2.586838174310416

Epoch: 6| Step: 12
Training loss: 3.187711521685016
Validation loss: 2.581891287717281

Epoch: 6| Step: 13
Training loss: 2.8789478231712504
Validation loss: 2.583594104282553

Epoch: 61| Step: 0
Training loss: 2.547364451177971
Validation loss: 2.5862267479932037

Epoch: 6| Step: 1
Training loss: 3.0940579347814707
Validation loss: 2.5804497731366878

Epoch: 6| Step: 2
Training loss: 3.4607623811596913
Validation loss: 2.586554780979605

Epoch: 6| Step: 3
Training loss: 2.574106494730904
Validation loss: 2.5769443417546465

Epoch: 6| Step: 4
Training loss: 2.6128542427202426
Validation loss: 2.581208933114975

Epoch: 6| Step: 5
Training loss: 2.088720857792478
Validation loss: 2.5731366017737898

Epoch: 6| Step: 6
Training loss: 2.9878392110763117
Validation loss: 2.5575309784965845

Epoch: 6| Step: 7
Training loss: 2.978213675780903
Validation loss: 2.55655950923043

Epoch: 6| Step: 8
Training loss: 2.9351911195984046
Validation loss: 2.577730671596964

Epoch: 6| Step: 9
Training loss: 2.977667015381704
Validation loss: 2.5899239549659225

Epoch: 6| Step: 10
Training loss: 2.8780983524973482
Validation loss: 2.6019123589467363

Epoch: 6| Step: 11
Training loss: 2.8063770188979396
Validation loss: 2.592085195191722

Epoch: 6| Step: 12
Training loss: 3.5277659014671308
Validation loss: 2.590777688049395

Epoch: 6| Step: 13
Training loss: 3.211268349933279
Validation loss: 2.5788839764944473

Epoch: 62| Step: 0
Training loss: 2.662538870227744
Validation loss: 2.5587469650468493

Epoch: 6| Step: 1
Training loss: 2.830323434416675
Validation loss: 2.5586034280342975

Epoch: 6| Step: 2
Training loss: 3.3174763852438183
Validation loss: 2.5622799436462294

Epoch: 6| Step: 3
Training loss: 3.2057133335163597
Validation loss: 2.556840757649642

Epoch: 6| Step: 4
Training loss: 2.4066829539599413
Validation loss: 2.564168973308065

Epoch: 6| Step: 5
Training loss: 2.9099458554398905
Validation loss: 2.561119313899764

Epoch: 6| Step: 6
Training loss: 3.4455811272562418
Validation loss: 2.5643272737967013

Epoch: 6| Step: 7
Training loss: 2.640798077751738
Validation loss: 2.5541743364924723

Epoch: 6| Step: 8
Training loss: 2.964842463356111
Validation loss: 2.55805186896216

Epoch: 6| Step: 9
Training loss: 3.0794131299509897
Validation loss: 2.5632490563447727

Epoch: 6| Step: 10
Training loss: 2.9877843107025437
Validation loss: 2.561755483634946

Epoch: 6| Step: 11
Training loss: 2.6055692227277842
Validation loss: 2.575906783080423

Epoch: 6| Step: 12
Training loss: 2.8186748959840133
Validation loss: 2.5874388090038476

Epoch: 6| Step: 13
Training loss: 2.790402728858541
Validation loss: 2.624328512747088

Epoch: 63| Step: 0
Training loss: 2.7570706415213353
Validation loss: 2.6536480546779555

Epoch: 6| Step: 1
Training loss: 2.672392321024041
Validation loss: 2.680056387250411

Epoch: 6| Step: 2
Training loss: 2.930447004416036
Validation loss: 2.6885988755734855

Epoch: 6| Step: 3
Training loss: 3.6491596560960047
Validation loss: 2.7004318587341936

Epoch: 6| Step: 4
Training loss: 2.8834798397115504
Validation loss: 2.6266129826981928

Epoch: 6| Step: 5
Training loss: 3.058227517136327
Validation loss: 2.598449754596349

Epoch: 6| Step: 6
Training loss: 3.2617957922693916
Validation loss: 2.5819485946069096

Epoch: 6| Step: 7
Training loss: 2.6599399742007934
Validation loss: 2.5804666484341263

Epoch: 6| Step: 8
Training loss: 2.427947473111793
Validation loss: 2.587582606108218

Epoch: 6| Step: 9
Training loss: 3.1901177521500688
Validation loss: 2.604240867952247

Epoch: 6| Step: 10
Training loss: 3.1142423479253067
Validation loss: 2.582065536809764

Epoch: 6| Step: 11
Training loss: 2.5948801910438144
Validation loss: 2.571396366122151

Epoch: 6| Step: 12
Training loss: 2.853844468988075
Validation loss: 2.5612536094609384

Epoch: 6| Step: 13
Training loss: 2.8772594032488596
Validation loss: 2.5537204463126595

Epoch: 64| Step: 0
Training loss: 2.8130381599113496
Validation loss: 2.554329360233867

Epoch: 6| Step: 1
Training loss: 2.2990678971706733
Validation loss: 2.549667909662353

Epoch: 6| Step: 2
Training loss: 2.3959444987726095
Validation loss: 2.5449548153063697

Epoch: 6| Step: 3
Training loss: 3.589909765655582
Validation loss: 2.539270959063446

Epoch: 6| Step: 4
Training loss: 2.9586506167482605
Validation loss: 2.5429670744889896

Epoch: 6| Step: 5
Training loss: 2.5572815769926236
Validation loss: 2.544057495901171

Epoch: 6| Step: 6
Training loss: 2.863716872984004
Validation loss: 2.5624877905385945

Epoch: 6| Step: 7
Training loss: 3.355460934080318
Validation loss: 2.5688262890599405

Epoch: 6| Step: 8
Training loss: 2.6119180496585885
Validation loss: 2.5704572252679796

Epoch: 6| Step: 9
Training loss: 2.5401246651521183
Validation loss: 2.5577759927050185

Epoch: 6| Step: 10
Training loss: 2.8163149074180893
Validation loss: 2.5689486326677695

Epoch: 6| Step: 11
Training loss: 3.149394531189438
Validation loss: 2.559378626992378

Epoch: 6| Step: 12
Training loss: 3.109290347073162
Validation loss: 2.559547828703612

Epoch: 6| Step: 13
Training loss: 3.5792241303194516
Validation loss: 2.5486084623962797

Epoch: 65| Step: 0
Training loss: 2.8233553462275656
Validation loss: 2.54757626319175

Epoch: 6| Step: 1
Training loss: 2.924728387464705
Validation loss: 2.5452940716245025

Epoch: 6| Step: 2
Training loss: 3.0909175043960544
Validation loss: 2.5437884123035155

Epoch: 6| Step: 3
Training loss: 3.040107135641637
Validation loss: 2.537218330268868

Epoch: 6| Step: 4
Training loss: 3.2475403501428066
Validation loss: 2.541801256085743

Epoch: 6| Step: 5
Training loss: 2.883998389160299
Validation loss: 2.545808134952374

Epoch: 6| Step: 6
Training loss: 3.0858823360872485
Validation loss: 2.5427386795056455

Epoch: 6| Step: 7
Training loss: 3.0771275177307773
Validation loss: 2.552417667095917

Epoch: 6| Step: 8
Training loss: 2.5747237455453824
Validation loss: 2.5631213651607334

Epoch: 6| Step: 9
Training loss: 2.511720838293747
Validation loss: 2.5777709797423136

Epoch: 6| Step: 10
Training loss: 3.0868091752486766
Validation loss: 2.5977802062916764

Epoch: 6| Step: 11
Training loss: 2.361044488852047
Validation loss: 2.6303396417393166

Epoch: 6| Step: 12
Training loss: 2.986918219576735
Validation loss: 2.6100589199045388

Epoch: 6| Step: 13
Training loss: 2.7684312796294073
Validation loss: 2.556462009067578

Epoch: 66| Step: 0
Training loss: 3.1873943834945524
Validation loss: 2.533137710514423

Epoch: 6| Step: 1
Training loss: 2.3912645868154603
Validation loss: 2.5409766931171283

Epoch: 6| Step: 2
Training loss: 2.8905550561639273
Validation loss: 2.5573615310702964

Epoch: 6| Step: 3
Training loss: 3.104619669449247
Validation loss: 2.5834059617401572

Epoch: 6| Step: 4
Training loss: 2.242940317768952
Validation loss: 2.6176513946428215

Epoch: 6| Step: 5
Training loss: 3.155970494953121
Validation loss: 2.6148867867145213

Epoch: 6| Step: 6
Training loss: 3.482367514604813
Validation loss: 2.5821162825972297

Epoch: 6| Step: 7
Training loss: 3.2730256688748667
Validation loss: 2.5632830158069324

Epoch: 6| Step: 8
Training loss: 2.462400068395117
Validation loss: 2.5555599785377545

Epoch: 6| Step: 9
Training loss: 3.415109713845952
Validation loss: 2.5537590734922655

Epoch: 6| Step: 10
Training loss: 3.330620345106861
Validation loss: 2.5558235267012273

Epoch: 6| Step: 11
Training loss: 2.329761109446074
Validation loss: 2.5702644545877815

Epoch: 6| Step: 12
Training loss: 2.4864763693654113
Validation loss: 2.6060869932551496

Epoch: 6| Step: 13
Training loss: 3.2023056843252515
Validation loss: 2.680565476782178

Epoch: 67| Step: 0
Training loss: 3.298634425744543
Validation loss: 2.7990436140535215

Epoch: 6| Step: 1
Training loss: 3.06103511730589
Validation loss: 2.854317951137631

Epoch: 6| Step: 2
Training loss: 3.368487963278545
Validation loss: 2.8606632405272396

Epoch: 6| Step: 3
Training loss: 2.7317816943500333
Validation loss: 2.7163085913905105

Epoch: 6| Step: 4
Training loss: 2.9863766653183927
Validation loss: 2.6129453422846765

Epoch: 6| Step: 5
Training loss: 2.5413042237388215
Validation loss: 2.573157011094504

Epoch: 6| Step: 6
Training loss: 2.6899868304699575
Validation loss: 2.563051156978566

Epoch: 6| Step: 7
Training loss: 2.617622908627685
Validation loss: 2.55393006889193

Epoch: 6| Step: 8
Training loss: 2.8571214811342873
Validation loss: 2.570091183422486

Epoch: 6| Step: 9
Training loss: 3.337004229695238
Validation loss: 2.57096168231048

Epoch: 6| Step: 10
Training loss: 2.643908113120844
Validation loss: 2.564070207760049

Epoch: 6| Step: 11
Training loss: 3.0242300645818117
Validation loss: 2.5539574514654957

Epoch: 6| Step: 12
Training loss: 3.066144681817684
Validation loss: 2.5502653985567676

Epoch: 6| Step: 13
Training loss: 3.208992101900314
Validation loss: 2.5496143511907463

Epoch: 68| Step: 0
Training loss: 3.346941129314303
Validation loss: 2.5451021993198943

Epoch: 6| Step: 1
Training loss: 2.6261804741975827
Validation loss: 2.548178750723609

Epoch: 6| Step: 2
Training loss: 2.503873875448856
Validation loss: 2.542732730999193

Epoch: 6| Step: 3
Training loss: 3.044276924660198
Validation loss: 2.543772059620071

Epoch: 6| Step: 4
Training loss: 2.7768333599189106
Validation loss: 2.5409285026347805

Epoch: 6| Step: 5
Training loss: 3.008961485342722
Validation loss: 2.537140116966006

Epoch: 6| Step: 6
Training loss: 3.0711112888236145
Validation loss: 2.5402267737486497

Epoch: 6| Step: 7
Training loss: 2.807976879133366
Validation loss: 2.541491077947047

Epoch: 6| Step: 8
Training loss: 2.776669019245496
Validation loss: 2.547389703376163

Epoch: 6| Step: 9
Training loss: 2.9112407532508664
Validation loss: 2.5586522745457425

Epoch: 6| Step: 10
Training loss: 3.3644648827329964
Validation loss: 2.5738360505329743

Epoch: 6| Step: 11
Training loss: 2.699129536502792
Validation loss: 2.5700902557564813

Epoch: 6| Step: 12
Training loss: 2.6249913715039086
Validation loss: 2.5551157357834033

Epoch: 6| Step: 13
Training loss: 3.199966883488003
Validation loss: 2.5450623276863795

Epoch: 69| Step: 0
Training loss: 3.147831330740577
Validation loss: 2.532728522220067

Epoch: 6| Step: 1
Training loss: 2.238302447100491
Validation loss: 2.525863094802926

Epoch: 6| Step: 2
Training loss: 2.9946634193271455
Validation loss: 2.5268897925252105

Epoch: 6| Step: 3
Training loss: 3.105353587192489
Validation loss: 2.5240768668532745

Epoch: 6| Step: 4
Training loss: 2.830716626450393
Validation loss: 2.524122762737565

Epoch: 6| Step: 5
Training loss: 2.166529051983185
Validation loss: 2.520817136157388

Epoch: 6| Step: 6
Training loss: 3.04023120051148
Validation loss: 2.5248971446834214

Epoch: 6| Step: 7
Training loss: 3.0445610454100795
Validation loss: 2.5228754919605083

Epoch: 6| Step: 8
Training loss: 2.870348276944286
Validation loss: 2.52273748526407

Epoch: 6| Step: 9
Training loss: 3.5304284954709537
Validation loss: 2.528899857622661

Epoch: 6| Step: 10
Training loss: 3.0536832988136022
Validation loss: 2.533155956545962

Epoch: 6| Step: 11
Training loss: 2.6139284709492365
Validation loss: 2.53392758397089

Epoch: 6| Step: 12
Training loss: 2.790257045841199
Validation loss: 2.551492971244826

Epoch: 6| Step: 13
Training loss: 2.6082630643631677
Validation loss: 2.5476566003443852

Epoch: 70| Step: 0
Training loss: 3.075457506338043
Validation loss: 2.5501494962416946

Epoch: 6| Step: 1
Training loss: 3.321998939821739
Validation loss: 2.5564090702834594

Epoch: 6| Step: 2
Training loss: 3.0311781098011052
Validation loss: 2.545077097679693

Epoch: 6| Step: 3
Training loss: 2.605526581770093
Validation loss: 2.53509405722719

Epoch: 6| Step: 4
Training loss: 3.1335926178592755
Validation loss: 2.537440998541777

Epoch: 6| Step: 5
Training loss: 2.5244257736672258
Validation loss: 2.535694573748081

Epoch: 6| Step: 6
Training loss: 3.143339284228466
Validation loss: 2.541115425834102

Epoch: 6| Step: 7
Training loss: 2.194656002400392
Validation loss: 2.5445760052551534

Epoch: 6| Step: 8
Training loss: 3.2165872659584984
Validation loss: 2.542934089279387

Epoch: 6| Step: 9
Training loss: 3.0384728023836574
Validation loss: 2.566305938252178

Epoch: 6| Step: 10
Training loss: 2.7167605432621897
Validation loss: 2.5471859486769266

Epoch: 6| Step: 11
Training loss: 3.151535592368555
Validation loss: 2.5505787422096886

Epoch: 6| Step: 12
Training loss: 2.611438415069964
Validation loss: 2.538918600366824

Epoch: 6| Step: 13
Training loss: 1.7148249805439928
Validation loss: 2.530466974181418

Epoch: 71| Step: 0
Training loss: 2.936761154432896
Validation loss: 2.5246032096860866

Epoch: 6| Step: 1
Training loss: 2.9651493121114885
Validation loss: 2.5248414097734866

Epoch: 6| Step: 2
Training loss: 2.780511307933295
Validation loss: 2.5170093748259386

Epoch: 6| Step: 3
Training loss: 3.0558734747673406
Validation loss: 2.5189274602358123

Epoch: 6| Step: 4
Training loss: 2.8724498219170256
Validation loss: 2.518806347005135

Epoch: 6| Step: 5
Training loss: 3.617753909360592
Validation loss: 2.5223227500743532

Epoch: 6| Step: 6
Training loss: 2.8099373056334507
Validation loss: 2.524916299086303

Epoch: 6| Step: 7
Training loss: 3.0405887801550677
Validation loss: 2.5243008720607008

Epoch: 6| Step: 8
Training loss: 2.367965117287815
Validation loss: 2.5216910278505824

Epoch: 6| Step: 9
Training loss: 2.6316552038186707
Validation loss: 2.522239830325815

Epoch: 6| Step: 10
Training loss: 2.8807474819371968
Validation loss: 2.5175827195489746

Epoch: 6| Step: 11
Training loss: 2.9257554994068746
Validation loss: 2.5225931315210985

Epoch: 6| Step: 12
Training loss: 2.708848219614824
Validation loss: 2.519972314915281

Epoch: 6| Step: 13
Training loss: 2.4683205919196616
Validation loss: 2.519411608688568

Epoch: 72| Step: 0
Training loss: 2.8761484920489466
Validation loss: 2.5302694131172787

Epoch: 6| Step: 1
Training loss: 2.5258881092917838
Validation loss: 2.54096048174878

Epoch: 6| Step: 2
Training loss: 3.027172374181525
Validation loss: 2.5621821868964947

Epoch: 6| Step: 3
Training loss: 3.003951014072348
Validation loss: 2.5721568925085223

Epoch: 6| Step: 4
Training loss: 3.1305370866948494
Validation loss: 2.566549453514706

Epoch: 6| Step: 5
Training loss: 2.9783142221866217
Validation loss: 2.5564716861467685

Epoch: 6| Step: 6
Training loss: 2.646420951730802
Validation loss: 2.5224853220728387

Epoch: 6| Step: 7
Training loss: 2.8174310478431566
Validation loss: 2.5128376582799143

Epoch: 6| Step: 8
Training loss: 3.290924197774918
Validation loss: 2.5151385182966766

Epoch: 6| Step: 9
Training loss: 2.5433493708766926
Validation loss: 2.528657177494265

Epoch: 6| Step: 10
Training loss: 2.8070271968414153
Validation loss: 2.5331241612658064

Epoch: 6| Step: 11
Training loss: 3.135644103933545
Validation loss: 2.540863795556951

Epoch: 6| Step: 12
Training loss: 2.4553008907859812
Validation loss: 2.5449718584736654

Epoch: 6| Step: 13
Training loss: 3.3913754806054226
Validation loss: 2.5444693680246946

Epoch: 73| Step: 0
Training loss: 2.929188759631373
Validation loss: 2.549290095605418

Epoch: 6| Step: 1
Training loss: 2.7131177067038
Validation loss: 2.5521292221300027

Epoch: 6| Step: 2
Training loss: 2.9886603619811574
Validation loss: 2.593763598749772

Epoch: 6| Step: 3
Training loss: 2.849853003207811
Validation loss: 2.5725189133364035

Epoch: 6| Step: 4
Training loss: 3.375567353209633
Validation loss: 2.5501624845597175

Epoch: 6| Step: 5
Training loss: 2.2839422147358905
Validation loss: 2.5351237506971085

Epoch: 6| Step: 6
Training loss: 3.067875406910962
Validation loss: 2.529861446099846

Epoch: 6| Step: 7
Training loss: 2.479458147966916
Validation loss: 2.5315402315376945

Epoch: 6| Step: 8
Training loss: 3.531000989388214
Validation loss: 2.5438918310678367

Epoch: 6| Step: 9
Training loss: 2.5410841185642847
Validation loss: 2.56003967474565

Epoch: 6| Step: 10
Training loss: 2.6625725391517725
Validation loss: 2.583463888478316

Epoch: 6| Step: 11
Training loss: 3.3901155853821527
Validation loss: 2.595549851353937

Epoch: 6| Step: 12
Training loss: 2.8218847737190584
Validation loss: 2.5782590113439836

Epoch: 6| Step: 13
Training loss: 2.574544188516773
Validation loss: 2.5665055010083555

Epoch: 74| Step: 0
Training loss: 2.4617202724886695
Validation loss: 2.544569737638072

Epoch: 6| Step: 1
Training loss: 3.382150492743693
Validation loss: 2.523896348623032

Epoch: 6| Step: 2
Training loss: 3.3404450527788607
Validation loss: 2.517958000818159

Epoch: 6| Step: 3
Training loss: 1.8847776422463394
Validation loss: 2.5117512622708422

Epoch: 6| Step: 4
Training loss: 3.703206121787489
Validation loss: 2.514800728315041

Epoch: 6| Step: 5
Training loss: 2.7640056287263786
Validation loss: 2.512294981767962

Epoch: 6| Step: 6
Training loss: 2.8134302931916473
Validation loss: 2.5126241942331444

Epoch: 6| Step: 7
Training loss: 2.8163827162353274
Validation loss: 2.5138175686222395

Epoch: 6| Step: 8
Training loss: 3.184507872979184
Validation loss: 2.515113578330303

Epoch: 6| Step: 9
Training loss: 2.423572658997696
Validation loss: 2.5167941988591993

Epoch: 6| Step: 10
Training loss: 2.730343620696644
Validation loss: 2.525041579411116

Epoch: 6| Step: 11
Training loss: 2.8773107779004463
Validation loss: 2.5368822231291506

Epoch: 6| Step: 12
Training loss: 3.014562548126574
Validation loss: 2.5358283454941106

Epoch: 6| Step: 13
Training loss: 2.0630883042505124
Validation loss: 2.5328214014659127

Epoch: 75| Step: 0
Training loss: 3.171819226004788
Validation loss: 2.5276633115427893

Epoch: 6| Step: 1
Training loss: 2.441496678012804
Validation loss: 2.531753406931783

Epoch: 6| Step: 2
Training loss: 3.0619322581406636
Validation loss: 2.5388346766893575

Epoch: 6| Step: 3
Training loss: 2.6518390607949627
Validation loss: 2.54959976534665

Epoch: 6| Step: 4
Training loss: 3.005892053814403
Validation loss: 2.5531021863606664

Epoch: 6| Step: 5
Training loss: 2.653952289189822
Validation loss: 2.5422789610960295

Epoch: 6| Step: 6
Training loss: 3.1533931984840717
Validation loss: 2.520869862362893

Epoch: 6| Step: 7
Training loss: 2.7802780681929296
Validation loss: 2.5161856651539005

Epoch: 6| Step: 8
Training loss: 2.634212857253441
Validation loss: 2.5107879493466365

Epoch: 6| Step: 9
Training loss: 2.7670446513012616
Validation loss: 2.5124578771282957

Epoch: 6| Step: 10
Training loss: 3.0050975089351106
Validation loss: 2.5153051167995324

Epoch: 6| Step: 11
Training loss: 3.0499624406346757
Validation loss: 2.5101749595018696

Epoch: 6| Step: 12
Training loss: 3.2078935065727663
Validation loss: 2.509184825688455

Epoch: 6| Step: 13
Training loss: 2.2683419609419606
Validation loss: 2.5104013611960903

Epoch: 76| Step: 0
Training loss: 2.8087694646333192
Validation loss: 2.5148641018609004

Epoch: 6| Step: 1
Training loss: 3.034488167503822
Validation loss: 2.5248921705054155

Epoch: 6| Step: 2
Training loss: 3.0889490040144487
Validation loss: 2.5666828776538666

Epoch: 6| Step: 3
Training loss: 3.079398419473273
Validation loss: 2.602153377532257

Epoch: 6| Step: 4
Training loss: 2.11131265442268
Validation loss: 2.6494891404672436

Epoch: 6| Step: 5
Training loss: 3.1846284086045444
Validation loss: 2.6895123879438527

Epoch: 6| Step: 6
Training loss: 3.111065275747743
Validation loss: 2.616738662594045

Epoch: 6| Step: 7
Training loss: 2.2495409179276256
Validation loss: 2.552069768478242

Epoch: 6| Step: 8
Training loss: 2.4709660687959416
Validation loss: 2.5197674429996137

Epoch: 6| Step: 9
Training loss: 2.6623216237952603
Validation loss: 2.5032868600126545

Epoch: 6| Step: 10
Training loss: 3.2913969549106232
Validation loss: 2.503255807786451

Epoch: 6| Step: 11
Training loss: 2.7905506256547365
Validation loss: 2.502287866859853

Epoch: 6| Step: 12
Training loss: 3.5749118820748027
Validation loss: 2.503800426053566

Epoch: 6| Step: 13
Training loss: 2.276792272991062
Validation loss: 2.502994768901463

Epoch: 77| Step: 0
Training loss: 3.143396625414223
Validation loss: 2.5061054586066103

Epoch: 6| Step: 1
Training loss: 3.0787177894756588
Validation loss: 2.5085821326849036

Epoch: 6| Step: 2
Training loss: 1.9916267952326427
Validation loss: 2.5051801767473134

Epoch: 6| Step: 3
Training loss: 2.9835306141444415
Validation loss: 2.504709878065313

Epoch: 6| Step: 4
Training loss: 3.00285854844598
Validation loss: 2.5070927551568376

Epoch: 6| Step: 5
Training loss: 3.101204262903207
Validation loss: 2.5033391607543964

Epoch: 6| Step: 6
Training loss: 2.8297468561511754
Validation loss: 2.5029415237738206

Epoch: 6| Step: 7
Training loss: 2.547992484544243
Validation loss: 2.501470107916035

Epoch: 6| Step: 8
Training loss: 3.2046762571318967
Validation loss: 2.5028742152313153

Epoch: 6| Step: 9
Training loss: 2.6525094116791803
Validation loss: 2.502157562109178

Epoch: 6| Step: 10
Training loss: 2.8112919226167037
Validation loss: 2.5059280703879305

Epoch: 6| Step: 11
Training loss: 3.4042055486530876
Validation loss: 2.509893725843865

Epoch: 6| Step: 12
Training loss: 2.475127661909386
Validation loss: 2.520785956131192

Epoch: 6| Step: 13
Training loss: 2.469323876232359
Validation loss: 2.529186333753192

Epoch: 78| Step: 0
Training loss: 3.559630861539208
Validation loss: 2.5479811654287494

Epoch: 6| Step: 1
Training loss: 3.1313812715649485
Validation loss: 2.5517129099774642

Epoch: 6| Step: 2
Training loss: 2.833033227921588
Validation loss: 2.541995781849664

Epoch: 6| Step: 3
Training loss: 2.0617757739485194
Validation loss: 2.536549573462869

Epoch: 6| Step: 4
Training loss: 3.0162863525021173
Validation loss: 2.545405820917053

Epoch: 6| Step: 5
Training loss: 2.6167378053491257
Validation loss: 2.5381153262826954

Epoch: 6| Step: 6
Training loss: 3.0839246921671104
Validation loss: 2.5298066049116437

Epoch: 6| Step: 7
Training loss: 2.738788291144633
Validation loss: 2.5242162419923737

Epoch: 6| Step: 8
Training loss: 2.887190474397077
Validation loss: 2.5114066555976526

Epoch: 6| Step: 9
Training loss: 2.6905513562836076
Validation loss: 2.5169031474047756

Epoch: 6| Step: 10
Training loss: 2.6697482741202343
Validation loss: 2.512035856810485

Epoch: 6| Step: 11
Training loss: 2.851449791758044
Validation loss: 2.508116404074429

Epoch: 6| Step: 12
Training loss: 3.001640824780875
Validation loss: 2.5018340797130736

Epoch: 6| Step: 13
Training loss: 2.3387621893837798
Validation loss: 2.499942294346947

Epoch: 79| Step: 0
Training loss: 2.6432411732267846
Validation loss: 2.5015738486198402

Epoch: 6| Step: 1
Training loss: 2.2890336487289624
Validation loss: 2.498718068409255

Epoch: 6| Step: 2
Training loss: 2.9335852977158527
Validation loss: 2.499266473769375

Epoch: 6| Step: 3
Training loss: 2.571307050770254
Validation loss: 2.4989162157058638

Epoch: 6| Step: 4
Training loss: 3.147071561006393
Validation loss: 2.507311543783106

Epoch: 6| Step: 5
Training loss: 2.80193667872979
Validation loss: 2.512405220300665

Epoch: 6| Step: 6
Training loss: 3.028871212437598
Validation loss: 2.5211981879943903

Epoch: 6| Step: 7
Training loss: 2.8240884035878366
Validation loss: 2.5403175956207082

Epoch: 6| Step: 8
Training loss: 3.383499886182555
Validation loss: 2.5632525613777473

Epoch: 6| Step: 9
Training loss: 2.7891723440215275
Validation loss: 2.5372021949181986

Epoch: 6| Step: 10
Training loss: 2.7862548373536757
Validation loss: 2.5220001575939337

Epoch: 6| Step: 11
Training loss: 3.0453722255559335
Validation loss: 2.5026295051462757

Epoch: 6| Step: 12
Training loss: 2.525285451635845
Validation loss: 2.505518180189993

Epoch: 6| Step: 13
Training loss: 3.2126102591863206
Validation loss: 2.498277070487349

Epoch: 80| Step: 0
Training loss: 2.4890488139876017
Validation loss: 2.494771802450935

Epoch: 6| Step: 1
Training loss: 2.2947826586763123
Validation loss: 2.496301000259181

Epoch: 6| Step: 2
Training loss: 3.224307697123899
Validation loss: 2.496852158387514

Epoch: 6| Step: 3
Training loss: 2.340026950191923
Validation loss: 2.4947010888477577

Epoch: 6| Step: 4
Training loss: 2.7320725692840275
Validation loss: 2.4969690366592756

Epoch: 6| Step: 5
Training loss: 3.1992267985819085
Validation loss: 2.499408916615628

Epoch: 6| Step: 6
Training loss: 2.8918569877794016
Validation loss: 2.4994844766500113

Epoch: 6| Step: 7
Training loss: 2.4170072797824256
Validation loss: 2.513277085633046

Epoch: 6| Step: 8
Training loss: 3.104990873215879
Validation loss: 2.5317449193469463

Epoch: 6| Step: 9
Training loss: 3.038871229571031
Validation loss: 2.551454910614178

Epoch: 6| Step: 10
Training loss: 3.0342623500165615
Validation loss: 2.5651367671817358

Epoch: 6| Step: 11
Training loss: 2.800858883599787
Validation loss: 2.556857435833108

Epoch: 6| Step: 12
Training loss: 3.096330895535624
Validation loss: 2.5769602023986695

Epoch: 6| Step: 13
Training loss: 3.2088460306168582
Validation loss: 2.560259468051454

Epoch: 81| Step: 0
Training loss: 2.629259831087239
Validation loss: 2.5328955416828487

Epoch: 6| Step: 1
Training loss: 3.0951146670593794
Validation loss: 2.5086970961411588

Epoch: 6| Step: 2
Training loss: 2.7199581574980227
Validation loss: 2.497961271299435

Epoch: 6| Step: 3
Training loss: 3.063584427641596
Validation loss: 2.4968954950362403

Epoch: 6| Step: 4
Training loss: 3.008138267413329
Validation loss: 2.4907114746868952

Epoch: 6| Step: 5
Training loss: 2.816065075826818
Validation loss: 2.4912776308992144

Epoch: 6| Step: 6
Training loss: 2.2597379822882546
Validation loss: 2.493466233622583

Epoch: 6| Step: 7
Training loss: 2.680273320081931
Validation loss: 2.4909299782549

Epoch: 6| Step: 8
Training loss: 3.087009832724286
Validation loss: 2.4943474414279536

Epoch: 6| Step: 9
Training loss: 2.340804219737653
Validation loss: 2.495169053294079

Epoch: 6| Step: 10
Training loss: 3.0124254399486805
Validation loss: 2.506995972533009

Epoch: 6| Step: 11
Training loss: 3.071785532210215
Validation loss: 2.5145594524150776

Epoch: 6| Step: 12
Training loss: 2.8017794268184226
Validation loss: 2.533962353722721

Epoch: 6| Step: 13
Training loss: 3.3445762968070523
Validation loss: 2.550306099582419

Epoch: 82| Step: 0
Training loss: 3.326225204174654
Validation loss: 2.5328402469507894

Epoch: 6| Step: 1
Training loss: 3.2755072339204707
Validation loss: 2.5261802061093723

Epoch: 6| Step: 2
Training loss: 3.0772018984863263
Validation loss: 2.5094939380924917

Epoch: 6| Step: 3
Training loss: 2.5462436946740263
Validation loss: 2.5059769676956503

Epoch: 6| Step: 4
Training loss: 2.472245747267369
Validation loss: 2.504875046493862

Epoch: 6| Step: 5
Training loss: 1.9194239051125992
Validation loss: 2.5026714838378568

Epoch: 6| Step: 6
Training loss: 2.5839194176453657
Validation loss: 2.503826148331011

Epoch: 6| Step: 7
Training loss: 3.0081016500626063
Validation loss: 2.4997414834685445

Epoch: 6| Step: 8
Training loss: 2.729651420193234
Validation loss: 2.5019164154140823

Epoch: 6| Step: 9
Training loss: 2.6591460652770227
Validation loss: 2.510316852812697

Epoch: 6| Step: 10
Training loss: 2.948298794587402
Validation loss: 2.511962918563176

Epoch: 6| Step: 11
Training loss: 2.786554999175099
Validation loss: 2.5168004358221454

Epoch: 6| Step: 12
Training loss: 3.4073394992837014
Validation loss: 2.5220909934046327

Epoch: 6| Step: 13
Training loss: 2.487424310654077
Validation loss: 2.514774509690054

Epoch: 83| Step: 0
Training loss: 2.881954902926137
Validation loss: 2.49895683336096

Epoch: 6| Step: 1
Training loss: 2.3962137556046263
Validation loss: 2.493293555086454

Epoch: 6| Step: 2
Training loss: 2.8171634582069154
Validation loss: 2.4925740085307493

Epoch: 6| Step: 3
Training loss: 2.7250473053352113
Validation loss: 2.4902431914309986

Epoch: 6| Step: 4
Training loss: 2.8217592200842314
Validation loss: 2.4907333251857917

Epoch: 6| Step: 5
Training loss: 2.679245892940789
Validation loss: 2.494297440967149

Epoch: 6| Step: 6
Training loss: 2.665865738117168
Validation loss: 2.4930656686855492

Epoch: 6| Step: 7
Training loss: 3.1485002005039227
Validation loss: 2.494913629525598

Epoch: 6| Step: 8
Training loss: 2.294425852312568
Validation loss: 2.49515711747576

Epoch: 6| Step: 9
Training loss: 2.7571531377469394
Validation loss: 2.5136204001704368

Epoch: 6| Step: 10
Training loss: 2.71971385137851
Validation loss: 2.557631830863758

Epoch: 6| Step: 11
Training loss: 3.3240434575734588
Validation loss: 2.6307855096867487

Epoch: 6| Step: 12
Training loss: 3.543191618886076
Validation loss: 2.6981622968395347

Epoch: 6| Step: 13
Training loss: 2.9991460220489876
Validation loss: 2.7664434965537685

Epoch: 84| Step: 0
Training loss: 2.506201681303922
Validation loss: 2.770084644183988

Epoch: 6| Step: 1
Training loss: 3.1588838370937986
Validation loss: 2.694524041015645

Epoch: 6| Step: 2
Training loss: 2.979895140319915
Validation loss: 2.5457076963410934

Epoch: 6| Step: 3
Training loss: 2.9999629654187863
Validation loss: 2.4950954904691143

Epoch: 6| Step: 4
Training loss: 2.6158591472141546
Validation loss: 2.491869277843211

Epoch: 6| Step: 5
Training loss: 3.2422277976599587
Validation loss: 2.5004767783637503

Epoch: 6| Step: 6
Training loss: 2.523862537219689
Validation loss: 2.5119906953352324

Epoch: 6| Step: 7
Training loss: 3.164432004851752
Validation loss: 2.523266262425253

Epoch: 6| Step: 8
Training loss: 2.294033342785959
Validation loss: 2.532414575965541

Epoch: 6| Step: 9
Training loss: 2.879398464325044
Validation loss: 2.5365525630533785

Epoch: 6| Step: 10
Training loss: 3.112153158817147
Validation loss: 2.531289198964495

Epoch: 6| Step: 11
Training loss: 2.597054089041322
Validation loss: 2.5304806450467727

Epoch: 6| Step: 12
Training loss: 3.0626465120107706
Validation loss: 2.5295131279068612

Epoch: 6| Step: 13
Training loss: 3.316095380287936
Validation loss: 2.5279130704138035

Epoch: 85| Step: 0
Training loss: 2.851545109107928
Validation loss: 2.5211135239374474

Epoch: 6| Step: 1
Training loss: 3.394112898109358
Validation loss: 2.520884369350733

Epoch: 6| Step: 2
Training loss: 2.9102996176409257
Validation loss: 2.5174966334967603

Epoch: 6| Step: 3
Training loss: 2.831055361223618
Validation loss: 2.515446714609445

Epoch: 6| Step: 4
Training loss: 3.102125448261712
Validation loss: 2.513808833851481

Epoch: 6| Step: 5
Training loss: 2.748623416721666
Validation loss: 2.5073702142368037

Epoch: 6| Step: 6
Training loss: 2.8871666918187553
Validation loss: 2.5056992233799873

Epoch: 6| Step: 7
Training loss: 2.594090634694228
Validation loss: 2.516502697566083

Epoch: 6| Step: 8
Training loss: 2.690577231236776
Validation loss: 2.528052791800025

Epoch: 6| Step: 9
Training loss: 3.6076773742509363
Validation loss: 2.5548593463884606

Epoch: 6| Step: 10
Training loss: 2.6383479305625817
Validation loss: 2.5694349536168017

Epoch: 6| Step: 11
Training loss: 2.3503629850512504
Validation loss: 2.597498160729957

Epoch: 6| Step: 12
Training loss: 2.3109230644595407
Validation loss: 2.6254658371148967

Epoch: 6| Step: 13
Training loss: 3.411834758151566
Validation loss: 2.6156890826006016

Epoch: 86| Step: 0
Training loss: 3.5578839026428417
Validation loss: 2.545399019530729

Epoch: 6| Step: 1
Training loss: 3.038880958136098
Validation loss: 2.499047887655643

Epoch: 6| Step: 2
Training loss: 2.642789596813818
Validation loss: 2.5123850501117757

Epoch: 6| Step: 3
Training loss: 3.0363443570259547
Validation loss: 2.5150449197757103

Epoch: 6| Step: 4
Training loss: 3.1712666947673798
Validation loss: 2.5350614549883637

Epoch: 6| Step: 5
Training loss: 2.371294845776347
Validation loss: 2.6172109735985423

Epoch: 6| Step: 6
Training loss: 3.5039233969584624
Validation loss: 2.6912530590856334

Epoch: 6| Step: 7
Training loss: 3.8659902857990445
Validation loss: 2.743536962409999

Epoch: 6| Step: 8
Training loss: 2.1666113650771552
Validation loss: 2.75171963257714

Epoch: 6| Step: 9
Training loss: 3.414722928694001
Validation loss: 2.6976992181006594

Epoch: 6| Step: 10
Training loss: 2.1525835571730014
Validation loss: 2.676976231741727

Epoch: 6| Step: 11
Training loss: 2.5351737422956813
Validation loss: 2.6297384671898136

Epoch: 6| Step: 12
Training loss: 2.6071430643010665
Validation loss: 2.596988460576117

Epoch: 6| Step: 13
Training loss: 2.6518406791183287
Validation loss: 2.5795785494902352

Epoch: 87| Step: 0
Training loss: 3.499713613509956
Validation loss: 2.5773941072967244

Epoch: 6| Step: 1
Training loss: 2.562608111822374
Validation loss: 2.5714198888513926

Epoch: 6| Step: 2
Training loss: 3.5769078212567313
Validation loss: 2.5773870690460146

Epoch: 6| Step: 3
Training loss: 2.983862867901425
Validation loss: 2.572388829536065

Epoch: 6| Step: 4
Training loss: 2.9060527775612885
Validation loss: 2.575719891480816

Epoch: 6| Step: 5
Training loss: 2.6423960508113202
Validation loss: 2.5799622612740274

Epoch: 6| Step: 6
Training loss: 2.4784167354927433
Validation loss: 2.577652492087633

Epoch: 6| Step: 7
Training loss: 3.0508442382562033
Validation loss: 2.567386059757882

Epoch: 6| Step: 8
Training loss: 1.971305097391716
Validation loss: 2.588644120800174

Epoch: 6| Step: 9
Training loss: 3.230011581305654
Validation loss: 2.739356359815225

Epoch: 6| Step: 10
Training loss: 2.9231057252507395
Validation loss: 2.7789401797757396

Epoch: 6| Step: 11
Training loss: 2.685887052318563
Validation loss: 2.8127366981578885

Epoch: 6| Step: 12
Training loss: 2.808018313736711
Validation loss: 2.840265807376883

Epoch: 6| Step: 13
Training loss: 3.678158193226193
Validation loss: 2.750004339540997

Epoch: 88| Step: 0
Training loss: 2.251847779985329
Validation loss: 2.6235077616262013

Epoch: 6| Step: 1
Training loss: 2.189600998226185
Validation loss: 2.52013429797084

Epoch: 6| Step: 2
Training loss: 2.4315284549931566
Validation loss: 2.4915383941110307

Epoch: 6| Step: 3
Training loss: 3.14070820105122
Validation loss: 2.494711179169442

Epoch: 6| Step: 4
Training loss: 3.1763022207796117
Validation loss: 2.5121385733849944

Epoch: 6| Step: 5
Training loss: 2.5021139743865213
Validation loss: 2.5158842219853277

Epoch: 6| Step: 6
Training loss: 3.400960332220217
Validation loss: 2.529685046747686

Epoch: 6| Step: 7
Training loss: 3.321209954539729
Validation loss: 2.5408398981272255

Epoch: 6| Step: 8
Training loss: 3.0166255891929206
Validation loss: 2.537101708649042

Epoch: 6| Step: 9
Training loss: 2.4037087633044525
Validation loss: 2.5400783942975087

Epoch: 6| Step: 10
Training loss: 3.0987542264170136
Validation loss: 2.5389533441774557

Epoch: 6| Step: 11
Training loss: 3.313226440235394
Validation loss: 2.525595223484394

Epoch: 6| Step: 12
Training loss: 2.8020980059347105
Validation loss: 2.497203323972159

Epoch: 6| Step: 13
Training loss: 3.0774617521386785
Validation loss: 2.4874141289341494

Epoch: 89| Step: 0
Training loss: 3.3173806564148864
Validation loss: 2.490226814504652

Epoch: 6| Step: 1
Training loss: 2.945664281099562
Validation loss: 2.4979180845087785

Epoch: 6| Step: 2
Training loss: 2.224041177128305
Validation loss: 2.5030506113096367

Epoch: 6| Step: 3
Training loss: 3.0400367097143963
Validation loss: 2.515723777140749

Epoch: 6| Step: 4
Training loss: 2.6849104359498224
Validation loss: 2.531571523162085

Epoch: 6| Step: 5
Training loss: 2.775308499070806
Validation loss: 2.5379626839297704

Epoch: 6| Step: 6
Training loss: 2.7412357254456823
Validation loss: 2.567621409114631

Epoch: 6| Step: 7
Training loss: 3.2897841144447946
Validation loss: 2.587939200058613

Epoch: 6| Step: 8
Training loss: 2.4303162181424076
Validation loss: 2.5642037009158773

Epoch: 6| Step: 9
Training loss: 3.0370917905439496
Validation loss: 2.53910004063471

Epoch: 6| Step: 10
Training loss: 2.1239286975997556
Validation loss: 2.5123061045148014

Epoch: 6| Step: 11
Training loss: 2.780990331293477
Validation loss: 2.4956593752815155

Epoch: 6| Step: 12
Training loss: 3.1447385352389934
Validation loss: 2.498072908977748

Epoch: 6| Step: 13
Training loss: 3.1640383872537994
Validation loss: 2.4937080514855263

Epoch: 90| Step: 0
Training loss: 3.019770959417099
Validation loss: 2.489373365614876

Epoch: 6| Step: 1
Training loss: 2.946925199855762
Validation loss: 2.488211741833459

Epoch: 6| Step: 2
Training loss: 2.9933404120663867
Validation loss: 2.495102341642688

Epoch: 6| Step: 3
Training loss: 2.5606155910044404
Validation loss: 2.5003620285503674

Epoch: 6| Step: 4
Training loss: 2.1893325758865725
Validation loss: 2.4996090367926778

Epoch: 6| Step: 5
Training loss: 2.7476107882376892
Validation loss: 2.505651530007839

Epoch: 6| Step: 6
Training loss: 2.7906950972789133
Validation loss: 2.50094944655082

Epoch: 6| Step: 7
Training loss: 2.592472635122902
Validation loss: 2.502465231393107

Epoch: 6| Step: 8
Training loss: 3.5117937022729877
Validation loss: 2.512141128718906

Epoch: 6| Step: 9
Training loss: 2.97537440019741
Validation loss: 2.508258614166331

Epoch: 6| Step: 10
Training loss: 3.110837352909162
Validation loss: 2.5150507095180465

Epoch: 6| Step: 11
Training loss: 2.6795369542487317
Validation loss: 2.509701154335755

Epoch: 6| Step: 12
Training loss: 2.6851333133271718
Validation loss: 2.5088870920631483

Epoch: 6| Step: 13
Training loss: 2.124374970909987
Validation loss: 2.5189851731737276

Epoch: 91| Step: 0
Training loss: 2.737879137234692
Validation loss: 2.519465602646879

Epoch: 6| Step: 1
Training loss: 2.8921514656216845
Validation loss: 2.522141789162481

Epoch: 6| Step: 2
Training loss: 2.502546062979214
Validation loss: 2.5056711164755114

Epoch: 6| Step: 3
Training loss: 2.974252039385133
Validation loss: 2.521235589930697

Epoch: 6| Step: 4
Training loss: 2.7844231324151094
Validation loss: 2.515138624302218

Epoch: 6| Step: 5
Training loss: 2.599149942820239
Validation loss: 2.509041294846861

Epoch: 6| Step: 6
Training loss: 2.9361301231029393
Validation loss: 2.50822715639486

Epoch: 6| Step: 7
Training loss: 2.295384552761509
Validation loss: 2.5164811655644135

Epoch: 6| Step: 8
Training loss: 3.070050643354078
Validation loss: 2.506887422784895

Epoch: 6| Step: 9
Training loss: 3.2087284852136193
Validation loss: 2.492804136576511

Epoch: 6| Step: 10
Training loss: 2.7932049417995293
Validation loss: 2.4880550940678825

Epoch: 6| Step: 11
Training loss: 2.7599412520693747
Validation loss: 2.483108459769254

Epoch: 6| Step: 12
Training loss: 3.1582653296672407
Validation loss: 2.4792552503720886

Epoch: 6| Step: 13
Training loss: 2.351990923714804
Validation loss: 2.4793504450547563

Epoch: 92| Step: 0
Training loss: 2.314656669583391
Validation loss: 2.475882728350024

Epoch: 6| Step: 1
Training loss: 3.249061889237448
Validation loss: 2.4739482043090786

Epoch: 6| Step: 2
Training loss: 2.750169922173915
Validation loss: 2.4724732414383706

Epoch: 6| Step: 3
Training loss: 2.451387215080326
Validation loss: 2.4777514105559946

Epoch: 6| Step: 4
Training loss: 3.5391821430521513
Validation loss: 2.479164268993674

Epoch: 6| Step: 5
Training loss: 2.8826325316453363
Validation loss: 2.4868862023695937

Epoch: 6| Step: 6
Training loss: 3.2361969906858907
Validation loss: 2.4995871849089117

Epoch: 6| Step: 7
Training loss: 3.387056221697241
Validation loss: 2.5024956623781613

Epoch: 6| Step: 8
Training loss: 2.4101232096727383
Validation loss: 2.5005768223292133

Epoch: 6| Step: 9
Training loss: 2.828686400274628
Validation loss: 2.5106134325221037

Epoch: 6| Step: 10
Training loss: 2.384192695497815
Validation loss: 2.5053301912417583

Epoch: 6| Step: 11
Training loss: 2.5254840877789175
Validation loss: 2.5038166466208964

Epoch: 6| Step: 12
Training loss: 2.4899292283935397
Validation loss: 2.4993126524200178

Epoch: 6| Step: 13
Training loss: 2.8116762438394107
Validation loss: 2.498237357645919

Epoch: 93| Step: 0
Training loss: 2.1096774414256676
Validation loss: 2.483777998704055

Epoch: 6| Step: 1
Training loss: 2.5576831857177735
Validation loss: 2.4882922019130858

Epoch: 6| Step: 2
Training loss: 3.3673693260434794
Validation loss: 2.489629230101088

Epoch: 6| Step: 3
Training loss: 2.639830520565123
Validation loss: 2.500173718559309

Epoch: 6| Step: 4
Training loss: 3.2094804934033516
Validation loss: 2.508545446525311

Epoch: 6| Step: 5
Training loss: 2.9018920711267437
Validation loss: 2.5156834322390718

Epoch: 6| Step: 6
Training loss: 2.2452236978255837
Validation loss: 2.5086540890594686

Epoch: 6| Step: 7
Training loss: 2.9259817057289923
Validation loss: 2.512543559330702

Epoch: 6| Step: 8
Training loss: 2.7934762773682613
Validation loss: 2.5170930647348775

Epoch: 6| Step: 9
Training loss: 3.0631358206759627
Validation loss: 2.5000882102416893

Epoch: 6| Step: 10
Training loss: 2.9594302404901582
Validation loss: 2.5011433120003743

Epoch: 6| Step: 11
Training loss: 3.0981672714517097
Validation loss: 2.5097117012225416

Epoch: 6| Step: 12
Training loss: 2.6325830195451316
Validation loss: 2.5010222078200974

Epoch: 6| Step: 13
Training loss: 2.2759319660161914
Validation loss: 2.501432625664648

Epoch: 94| Step: 0
Training loss: 2.007263821097105
Validation loss: 2.4871169005046045

Epoch: 6| Step: 1
Training loss: 3.2048936380480977
Validation loss: 2.5059064158095596

Epoch: 6| Step: 2
Training loss: 2.418513567899257
Validation loss: 2.517187871369178

Epoch: 6| Step: 3
Training loss: 2.9169411847943243
Validation loss: 2.5208913945062887

Epoch: 6| Step: 4
Training loss: 3.380652744759783
Validation loss: 2.5288239245022326

Epoch: 6| Step: 5
Training loss: 2.969735875314237
Validation loss: 2.5417576855427098

Epoch: 6| Step: 6
Training loss: 3.100225895680514
Validation loss: 2.5357125668261857

Epoch: 6| Step: 7
Training loss: 3.5117429195671317
Validation loss: 2.5206968195443995

Epoch: 6| Step: 8
Training loss: 2.2639459110039843
Validation loss: 2.5067489812642973

Epoch: 6| Step: 9
Training loss: 2.558638291298847
Validation loss: 2.4891511422951407

Epoch: 6| Step: 10
Training loss: 2.683338936114731
Validation loss: 2.482876437712633

Epoch: 6| Step: 11
Training loss: 2.3512612590287003
Validation loss: 2.4721297710418693

Epoch: 6| Step: 12
Training loss: 3.1293347621286536
Validation loss: 2.4722940467081647

Epoch: 6| Step: 13
Training loss: 2.128948470230716
Validation loss: 2.4797477161898525

Epoch: 95| Step: 0
Training loss: 2.6161502433819175
Validation loss: 2.4781023779334914

Epoch: 6| Step: 1
Training loss: 2.5506853491615242
Validation loss: 2.4755077378430426

Epoch: 6| Step: 2
Training loss: 2.971540404536586
Validation loss: 2.4780402740265637

Epoch: 6| Step: 3
Training loss: 3.3555602659595207
Validation loss: 2.479783206328235

Epoch: 6| Step: 4
Training loss: 3.020078069170444
Validation loss: 2.489566899892108

Epoch: 6| Step: 5
Training loss: 2.299088844935475
Validation loss: 2.5035546278769703

Epoch: 6| Step: 6
Training loss: 3.0341575285339064
Validation loss: 2.513478349629049

Epoch: 6| Step: 7
Training loss: 2.369617184653808
Validation loss: 2.514917675610045

Epoch: 6| Step: 8
Training loss: 2.856193064449799
Validation loss: 2.5390385977327563

Epoch: 6| Step: 9
Training loss: 3.04839345801452
Validation loss: 2.5407528060606337

Epoch: 6| Step: 10
Training loss: 2.645933604906035
Validation loss: 2.526091303505257

Epoch: 6| Step: 11
Training loss: 2.966748657236545
Validation loss: 2.5174485169765575

Epoch: 6| Step: 12
Training loss: 2.390346336329734
Validation loss: 2.515050196800205

Epoch: 6| Step: 13
Training loss: 3.0091928460598587
Validation loss: 2.5056219374587267

Epoch: 96| Step: 0
Training loss: 2.5425559088187213
Validation loss: 2.5096663702357693

Epoch: 6| Step: 1
Training loss: 2.9205782863767697
Validation loss: 2.495031618912606

Epoch: 6| Step: 2
Training loss: 2.7558534920870943
Validation loss: 2.4960774052971426

Epoch: 6| Step: 3
Training loss: 2.665566654617731
Validation loss: 2.4932109130312368

Epoch: 6| Step: 4
Training loss: 2.901240142844966
Validation loss: 2.4961991478595884

Epoch: 6| Step: 5
Training loss: 2.62231244153822
Validation loss: 2.489031648481679

Epoch: 6| Step: 6
Training loss: 2.7442224673627353
Validation loss: 2.4778812885467634

Epoch: 6| Step: 7
Training loss: 2.903133567247181
Validation loss: 2.4799111347108758

Epoch: 6| Step: 8
Training loss: 3.2203954546228126
Validation loss: 2.4739605533263904

Epoch: 6| Step: 9
Training loss: 2.9595454423718293
Validation loss: 2.476127215929844

Epoch: 6| Step: 10
Training loss: 3.0248989939574873
Validation loss: 2.4765007208276755

Epoch: 6| Step: 11
Training loss: 2.2621506985114586
Validation loss: 2.4909298753358815

Epoch: 6| Step: 12
Training loss: 3.182935251107716
Validation loss: 2.4925880949822687

Epoch: 6| Step: 13
Training loss: 1.6445577805071228
Validation loss: 2.5037353338524135

Epoch: 97| Step: 0
Training loss: 3.1598125030326227
Validation loss: 2.5132138567004745

Epoch: 6| Step: 1
Training loss: 2.0991454565600334
Validation loss: 2.5298799498431563

Epoch: 6| Step: 2
Training loss: 2.8550138306825543
Validation loss: 2.556918173821738

Epoch: 6| Step: 3
Training loss: 2.8730490325981872
Validation loss: 2.5821451513831

Epoch: 6| Step: 4
Training loss: 2.728515625
Validation loss: 2.5718131094840793

Epoch: 6| Step: 5
Training loss: 2.558615368467829
Validation loss: 2.5481692021160587

Epoch: 6| Step: 6
Training loss: 2.504183796989595
Validation loss: 2.5255025768994144

Epoch: 6| Step: 7
Training loss: 2.5687857038332367
Validation loss: 2.50397127069723

Epoch: 6| Step: 8
Training loss: 3.0301272485785353
Validation loss: 2.5011021358635044

Epoch: 6| Step: 9
Training loss: 2.7322063456477355
Validation loss: 2.4936532767202464

Epoch: 6| Step: 10
Training loss: 2.9119431712400807
Validation loss: 2.4833275394023864

Epoch: 6| Step: 11
Training loss: 2.2551708144898592
Validation loss: 2.4737498799937376

Epoch: 6| Step: 12
Training loss: 3.3369302098947182
Validation loss: 2.4730691299886973

Epoch: 6| Step: 13
Training loss: 3.557704575769285
Validation loss: 2.481497046676693

Epoch: 98| Step: 0
Training loss: 2.4416203031163226
Validation loss: 2.476348099583234

Epoch: 6| Step: 1
Training loss: 3.014925070064028
Validation loss: 2.478085985947196

Epoch: 6| Step: 2
Training loss: 2.878164291527827
Validation loss: 2.482400134134946

Epoch: 6| Step: 3
Training loss: 2.4432509632286297
Validation loss: 2.4879914312641453

Epoch: 6| Step: 4
Training loss: 2.7878333196086027
Validation loss: 2.4989330989015275

Epoch: 6| Step: 5
Training loss: 2.639292002444959
Validation loss: 2.502509604880591

Epoch: 6| Step: 6
Training loss: 3.044221475732432
Validation loss: 2.5048576829147846

Epoch: 6| Step: 7
Training loss: 2.8459345213594993
Validation loss: 2.507789524563352

Epoch: 6| Step: 8
Training loss: 2.912216624607472
Validation loss: 2.499045795952851

Epoch: 6| Step: 9
Training loss: 2.3702589196201367
Validation loss: 2.5101265473922636

Epoch: 6| Step: 10
Training loss: 3.2123720254901
Validation loss: 2.531669343956413

Epoch: 6| Step: 11
Training loss: 3.23911546147684
Validation loss: 2.5412405204149238

Epoch: 6| Step: 12
Training loss: 2.7104280636249944
Validation loss: 2.539367111272264

Epoch: 6| Step: 13
Training loss: 2.1176935133170747
Validation loss: 2.5255538044758032

Epoch: 99| Step: 0
Training loss: 2.37306204582985
Validation loss: 2.5092303789066377

Epoch: 6| Step: 1
Training loss: 2.5658149676787407
Validation loss: 2.497152301197993

Epoch: 6| Step: 2
Training loss: 3.1162138448454786
Validation loss: 2.4877457343414258

Epoch: 6| Step: 3
Training loss: 3.312712464626385
Validation loss: 2.4816235530435455

Epoch: 6| Step: 4
Training loss: 2.65787268048508
Validation loss: 2.480271624088925

Epoch: 6| Step: 5
Training loss: 2.2988600684112424
Validation loss: 2.4799817790077574

Epoch: 6| Step: 6
Training loss: 2.7200505445496383
Validation loss: 2.4740747599037953

Epoch: 6| Step: 7
Training loss: 2.554442227689734
Validation loss: 2.476371574812551

Epoch: 6| Step: 8
Training loss: 3.0143202098507467
Validation loss: 2.480337088128808

Epoch: 6| Step: 9
Training loss: 2.966181075255456
Validation loss: 2.490070430434778

Epoch: 6| Step: 10
Training loss: 2.6671579226355053
Validation loss: 2.5142415698093106

Epoch: 6| Step: 11
Training loss: 3.3798448615050067
Validation loss: 2.5455144170459425

Epoch: 6| Step: 12
Training loss: 3.0296837604533073
Validation loss: 2.537561342597228

Epoch: 6| Step: 13
Training loss: 1.9385786438014645
Validation loss: 2.5274665375265566

Epoch: 100| Step: 0
Training loss: 3.2707540579419825
Validation loss: 2.547253748955388

Epoch: 6| Step: 1
Training loss: 2.923131009809977
Validation loss: 2.5113183069790312

Epoch: 6| Step: 2
Training loss: 2.8279599304921628
Validation loss: 2.485125354526663

Epoch: 6| Step: 3
Training loss: 2.90576512383486
Validation loss: 2.4758018649799873

Epoch: 6| Step: 4
Training loss: 3.004092603838391
Validation loss: 2.473121880066789

Epoch: 6| Step: 5
Training loss: 3.058305943615023
Validation loss: 2.4697430276151375

Epoch: 6| Step: 6
Training loss: 2.789916604959398
Validation loss: 2.47410193673635

Epoch: 6| Step: 7
Training loss: 2.5294558913273533
Validation loss: 2.4700769119424195

Epoch: 6| Step: 8
Training loss: 2.1901437315086763
Validation loss: 2.470298908408452

Epoch: 6| Step: 9
Training loss: 2.2082371480855625
Validation loss: 2.476503555167268

Epoch: 6| Step: 10
Training loss: 2.7870719067755676
Validation loss: 2.4715385487956665

Epoch: 6| Step: 11
Training loss: 2.8383634085488874
Validation loss: 2.486792053870275

Epoch: 6| Step: 12
Training loss: 2.747729317672729
Validation loss: 2.4898204339590895

Epoch: 6| Step: 13
Training loss: 2.9413584265804333
Validation loss: 2.4915910011408773

Epoch: 101| Step: 0
Training loss: 1.9861625970007726
Validation loss: 2.5032862486190224

Epoch: 6| Step: 1
Training loss: 2.762820271011951
Validation loss: 2.5038300677759286

Epoch: 6| Step: 2
Training loss: 2.820465506421342
Validation loss: 2.4941982156286224

Epoch: 6| Step: 3
Training loss: 2.5841100407013657
Validation loss: 2.4916849415607913

Epoch: 6| Step: 4
Training loss: 1.7798197843639205
Validation loss: 2.496116964552669

Epoch: 6| Step: 5
Training loss: 2.730768582931888
Validation loss: 2.494254767859093

Epoch: 6| Step: 6
Training loss: 3.280976492972256
Validation loss: 2.491530889019798

Epoch: 6| Step: 7
Training loss: 2.340420506995837
Validation loss: 2.4873168805355115

Epoch: 6| Step: 8
Training loss: 3.0314403356198274
Validation loss: 2.4857209472485153

Epoch: 6| Step: 9
Training loss: 2.847038296183689
Validation loss: 2.4956924306121024

Epoch: 6| Step: 10
Training loss: 2.797762596753078
Validation loss: 2.485687009515187

Epoch: 6| Step: 11
Training loss: 3.195260567464591
Validation loss: 2.487655240740507

Epoch: 6| Step: 12
Training loss: 3.1976724504460736
Validation loss: 2.4847550527437403

Epoch: 6| Step: 13
Training loss: 3.1914999304927845
Validation loss: 2.4854885594863965

Epoch: 102| Step: 0
Training loss: 2.6857661487186535
Validation loss: 2.48316972043121

Epoch: 6| Step: 1
Training loss: 2.815964239516561
Validation loss: 2.4838242150200145

Epoch: 6| Step: 2
Training loss: 3.6077589240046724
Validation loss: 2.4803791309329215

Epoch: 6| Step: 3
Training loss: 1.9921770880931962
Validation loss: 2.4849955193447073

Epoch: 6| Step: 4
Training loss: 2.0213187771845944
Validation loss: 2.4843526694610603

Epoch: 6| Step: 5
Training loss: 2.736024892861077
Validation loss: 2.474695619693659

Epoch: 6| Step: 6
Training loss: 2.598478671795456
Validation loss: 2.4818949947519164

Epoch: 6| Step: 7
Training loss: 2.5050484228879055
Validation loss: 2.4813769523280262

Epoch: 6| Step: 8
Training loss: 3.1154347322423264
Validation loss: 2.494551681747765

Epoch: 6| Step: 9
Training loss: 2.4019006832277316
Validation loss: 2.5006831292017346

Epoch: 6| Step: 10
Training loss: 2.7442603468656896
Validation loss: 2.5124790650549937

Epoch: 6| Step: 11
Training loss: 2.980618814312785
Validation loss: 2.502817166357164

Epoch: 6| Step: 12
Training loss: 2.865267825565219
Validation loss: 2.5010477987662543

Epoch: 6| Step: 13
Training loss: 3.6205279948407774
Validation loss: 2.497325761031778

Epoch: 103| Step: 0
Training loss: 3.022816360109929
Validation loss: 2.4875034595056706

Epoch: 6| Step: 1
Training loss: 2.9714426779150167
Validation loss: 2.472299775839826

Epoch: 6| Step: 2
Training loss: 2.353563844812043
Validation loss: 2.4646800111476734

Epoch: 6| Step: 3
Training loss: 2.95351088490312
Validation loss: 2.463700055499218

Epoch: 6| Step: 4
Training loss: 2.59227848824545
Validation loss: 2.457574664375696

Epoch: 6| Step: 5
Training loss: 2.427701279283414
Validation loss: 2.45704458656854

Epoch: 6| Step: 6
Training loss: 2.6898442180011575
Validation loss: 2.4644372751590864

Epoch: 6| Step: 7
Training loss: 2.004298359541937
Validation loss: 2.4579125661799623

Epoch: 6| Step: 8
Training loss: 2.9469044883118323
Validation loss: 2.466566913177702

Epoch: 6| Step: 9
Training loss: 2.894767803044818
Validation loss: 2.474402000829607

Epoch: 6| Step: 10
Training loss: 3.0420149163978327
Validation loss: 2.4815324291496577

Epoch: 6| Step: 11
Training loss: 2.8866257504154267
Validation loss: 2.4952561284829

Epoch: 6| Step: 12
Training loss: 3.14032223888538
Validation loss: 2.5111489545055545

Epoch: 6| Step: 13
Training loss: 2.8255197738903304
Validation loss: 2.5337633269405346

Epoch: 104| Step: 0
Training loss: 2.513471451648244
Validation loss: 2.531817349468241

Epoch: 6| Step: 1
Training loss: 2.8540807186653336
Validation loss: 2.5098346266436957

Epoch: 6| Step: 2
Training loss: 2.4766175658063845
Validation loss: 2.5098771788822276

Epoch: 6| Step: 3
Training loss: 2.61998815286302
Validation loss: 2.495911856511767

Epoch: 6| Step: 4
Training loss: 2.46378319317789
Validation loss: 2.4988882371772636

Epoch: 6| Step: 5
Training loss: 2.710986925713431
Validation loss: 2.4915711944076033

Epoch: 6| Step: 6
Training loss: 3.2099264738985025
Validation loss: 2.4789167550347164

Epoch: 6| Step: 7
Training loss: 2.3904705122353933
Validation loss: 2.481879855984231

Epoch: 6| Step: 8
Training loss: 2.8292412846818564
Validation loss: 2.4721364006827558

Epoch: 6| Step: 9
Training loss: 2.6264439199209537
Validation loss: 2.4694344955485636

Epoch: 6| Step: 10
Training loss: 3.4835308061565073
Validation loss: 2.4861198144505523

Epoch: 6| Step: 11
Training loss: 3.163270752357782
Validation loss: 2.476785225552941

Epoch: 6| Step: 12
Training loss: 2.7641754662096987
Validation loss: 2.4832253887159474

Epoch: 6| Step: 13
Training loss: 1.9909184022561393
Validation loss: 2.4893462489154836

Epoch: 105| Step: 0
Training loss: 2.1887668755805008
Validation loss: 2.4888426563243033

Epoch: 6| Step: 1
Training loss: 3.2648891368229687
Validation loss: 2.4849880981738015

Epoch: 6| Step: 2
Training loss: 2.325224842971865
Validation loss: 2.48109084197707

Epoch: 6| Step: 3
Training loss: 2.711970855151186
Validation loss: 2.488013375718274

Epoch: 6| Step: 4
Training loss: 3.007478452686167
Validation loss: 2.47134245227617

Epoch: 6| Step: 5
Training loss: 2.3150391943231634
Validation loss: 2.4744333871754125

Epoch: 6| Step: 6
Training loss: 2.9779949596149735
Validation loss: 2.485994579465066

Epoch: 6| Step: 7
Training loss: 2.8722034619339913
Validation loss: 2.489369733388693

Epoch: 6| Step: 8
Training loss: 2.9714887333899775
Validation loss: 2.5006269804439905

Epoch: 6| Step: 9
Training loss: 2.694050103484159
Validation loss: 2.49223896181399

Epoch: 6| Step: 10
Training loss: 2.830665753779337
Validation loss: 2.4814581459327845

Epoch: 6| Step: 11
Training loss: 2.781153730805138
Validation loss: 2.495225548589089

Epoch: 6| Step: 12
Training loss: 2.805734677991216
Validation loss: 2.5009121994405543

Epoch: 6| Step: 13
Training loss: 2.6442503110790403
Validation loss: 2.502537773415762

Epoch: 106| Step: 0
Training loss: 2.325286876248659
Validation loss: 2.5104333145746276

Epoch: 6| Step: 1
Training loss: 3.232769996359969
Validation loss: 2.505588287697718

Epoch: 6| Step: 2
Training loss: 3.025394407680011
Validation loss: 2.5011917442408964

Epoch: 6| Step: 3
Training loss: 2.268440654251632
Validation loss: 2.506110749339818

Epoch: 6| Step: 4
Training loss: 2.7232952490034252
Validation loss: 2.5124105222569653

Epoch: 6| Step: 5
Training loss: 2.8076381622857824
Validation loss: 2.497942857479195

Epoch: 6| Step: 6
Training loss: 2.403978638152613
Validation loss: 2.4846054922675735

Epoch: 6| Step: 7
Training loss: 2.2265772768835315
Validation loss: 2.465328343325534

Epoch: 6| Step: 8
Training loss: 3.1622683112273036
Validation loss: 2.46094033976344

Epoch: 6| Step: 9
Training loss: 2.7191570459589824
Validation loss: 2.4610606943844195

Epoch: 6| Step: 10
Training loss: 3.128017951894306
Validation loss: 2.46260525936693

Epoch: 6| Step: 11
Training loss: 3.1662409312181983
Validation loss: 2.4643906172467824

Epoch: 6| Step: 12
Training loss: 2.446056313778025
Validation loss: 2.4636782649261963

Epoch: 6| Step: 13
Training loss: 2.9720089341718614
Validation loss: 2.462711568917404

Epoch: 107| Step: 0
Training loss: 2.3091768667582473
Validation loss: 2.467845605190986

Epoch: 6| Step: 1
Training loss: 3.1451163748601694
Validation loss: 2.468958901782599

Epoch: 6| Step: 2
Training loss: 2.2094251225031916
Validation loss: 2.488109257430572

Epoch: 6| Step: 3
Training loss: 2.5091302089603835
Validation loss: 2.498102716153414

Epoch: 6| Step: 4
Training loss: 2.9185176062524225
Validation loss: 2.5314462510465066

Epoch: 6| Step: 5
Training loss: 1.9980015903386383
Validation loss: 2.5282506305158656

Epoch: 6| Step: 6
Training loss: 3.291642072239672
Validation loss: 2.53271732417069

Epoch: 6| Step: 7
Training loss: 3.15290700803534
Validation loss: 2.536862610342506

Epoch: 6| Step: 8
Training loss: 3.1672957113455493
Validation loss: 2.5340094909792605

Epoch: 6| Step: 9
Training loss: 2.8525810199434822
Validation loss: 2.5123630940439403

Epoch: 6| Step: 10
Training loss: 2.3779097350613134
Validation loss: 2.4828220177026754

Epoch: 6| Step: 11
Training loss: 3.216620175778391
Validation loss: 2.46610739247956

Epoch: 6| Step: 12
Training loss: 2.940491147699184
Validation loss: 2.464630861938542

Epoch: 6| Step: 13
Training loss: 1.9664157168524603
Validation loss: 2.4585667762298673

Epoch: 108| Step: 0
Training loss: 2.478147559045235
Validation loss: 2.4697834581313183

Epoch: 6| Step: 1
Training loss: 2.352820987997706
Validation loss: 2.459155354234252

Epoch: 6| Step: 2
Training loss: 2.4612887661633476
Validation loss: 2.465750262145589

Epoch: 6| Step: 3
Training loss: 2.586765306630448
Validation loss: 2.4748189579227144

Epoch: 6| Step: 4
Training loss: 2.9957193988751474
Validation loss: 2.485305416878628

Epoch: 6| Step: 5
Training loss: 2.819973489352667
Validation loss: 2.505150458898545

Epoch: 6| Step: 6
Training loss: 1.932828316280749
Validation loss: 2.5105675224925688

Epoch: 6| Step: 7
Training loss: 2.949803659403168
Validation loss: 2.516444444804418

Epoch: 6| Step: 8
Training loss: 2.9535254151487655
Validation loss: 2.5318250854862194

Epoch: 6| Step: 9
Training loss: 3.123989704852657
Validation loss: 2.5263423827370017

Epoch: 6| Step: 10
Training loss: 2.7774889944220735
Validation loss: 2.510331081735115

Epoch: 6| Step: 11
Training loss: 3.0617014563973197
Validation loss: 2.501852147237549

Epoch: 6| Step: 12
Training loss: 2.912807327231537
Validation loss: 2.500324140064984

Epoch: 6| Step: 13
Training loss: 2.885245105770658
Validation loss: 2.492923361122952

Epoch: 109| Step: 0
Training loss: 2.88572318495224
Validation loss: 2.4769827831351776

Epoch: 6| Step: 1
Training loss: 2.3221210662534135
Validation loss: 2.490715445647718

Epoch: 6| Step: 2
Training loss: 2.779746774488558
Validation loss: 2.4794233366276317

Epoch: 6| Step: 3
Training loss: 2.727071195438923
Validation loss: 2.4835350291943175

Epoch: 6| Step: 4
Training loss: 2.455727332806568
Validation loss: 2.4834587237567827

Epoch: 6| Step: 5
Training loss: 3.2013390004612168
Validation loss: 2.4904736213198464

Epoch: 6| Step: 6
Training loss: 2.331437282863204
Validation loss: 2.4909921122632026

Epoch: 6| Step: 7
Training loss: 2.6861175707538107
Validation loss: 2.4851922607556842

Epoch: 6| Step: 8
Training loss: 1.9389426490206991
Validation loss: 2.4852754675652817

Epoch: 6| Step: 9
Training loss: 3.072832078362162
Validation loss: 2.481570946492626

Epoch: 6| Step: 10
Training loss: 3.0673187647523776
Validation loss: 2.4862136378179436

Epoch: 6| Step: 11
Training loss: 2.917627194597568
Validation loss: 2.4757384359063717

Epoch: 6| Step: 12
Training loss: 2.719290580938404
Validation loss: 2.485117033674781

Epoch: 6| Step: 13
Training loss: 3.2049771048312774
Validation loss: 2.4805012915345683

Epoch: 110| Step: 0
Training loss: 2.315347722347211
Validation loss: 2.503227925383614

Epoch: 6| Step: 1
Training loss: 2.544998507396208
Validation loss: 2.5364369094192156

Epoch: 6| Step: 2
Training loss: 2.2301650500265913
Validation loss: 2.5717642039206727

Epoch: 6| Step: 3
Training loss: 3.016010002898772
Validation loss: 2.5955274718107697

Epoch: 6| Step: 4
Training loss: 2.2341314863342268
Validation loss: 2.6052623217525106

Epoch: 6| Step: 5
Training loss: 2.927154829751728
Validation loss: 2.5860457611298084

Epoch: 6| Step: 6
Training loss: 3.0132908459709147
Validation loss: 2.564507808086197

Epoch: 6| Step: 7
Training loss: 2.6442790735274273
Validation loss: 2.54005875774412

Epoch: 6| Step: 8
Training loss: 2.8950316785485795
Validation loss: 2.501443407262796

Epoch: 6| Step: 9
Training loss: 2.6211306801026333
Validation loss: 2.4924061693708683

Epoch: 6| Step: 10
Training loss: 2.7802336475243696
Validation loss: 2.485686742392674

Epoch: 6| Step: 11
Training loss: 3.0261202794870616
Validation loss: 2.496146941951409

Epoch: 6| Step: 12
Training loss: 3.4332721025753647
Validation loss: 2.513365825419004

Epoch: 6| Step: 13
Training loss: 2.945616364930801
Validation loss: 2.5134320247806987

Epoch: 111| Step: 0
Training loss: 2.1844041988838883
Validation loss: 2.49521461375112

Epoch: 6| Step: 1
Training loss: 2.947152693640726
Validation loss: 2.48840570128144

Epoch: 6| Step: 2
Training loss: 2.5746708705886876
Validation loss: 2.484154124188674

Epoch: 6| Step: 3
Training loss: 2.9995204224321266
Validation loss: 2.474572261849235

Epoch: 6| Step: 4
Training loss: 2.2694118028418035
Validation loss: 2.4767206685679635

Epoch: 6| Step: 5
Training loss: 2.157389464127133
Validation loss: 2.475800152297265

Epoch: 6| Step: 6
Training loss: 3.2685027515854386
Validation loss: 2.46893532284433

Epoch: 6| Step: 7
Training loss: 2.7917272836357583
Validation loss: 2.479569327363501

Epoch: 6| Step: 8
Training loss: 2.9870824865261145
Validation loss: 2.5062030694042514

Epoch: 6| Step: 9
Training loss: 2.857266842331772
Validation loss: 2.521399616843896

Epoch: 6| Step: 10
Training loss: 2.866845716015432
Validation loss: 2.516798427120431

Epoch: 6| Step: 11
Training loss: 3.3376227595580104
Validation loss: 2.5221853153720306

Epoch: 6| Step: 12
Training loss: 2.4129523530153603
Validation loss: 2.5371005264101774

Epoch: 6| Step: 13
Training loss: 2.294660785513831
Validation loss: 2.5364806153259805

Epoch: 112| Step: 0
Training loss: 2.8091318943976393
Validation loss: 2.5564740818449656

Epoch: 6| Step: 1
Training loss: 2.436429791380498
Validation loss: 2.5193915770152953

Epoch: 6| Step: 2
Training loss: 2.9801484382065797
Validation loss: 2.5221532532107434

Epoch: 6| Step: 3
Training loss: 2.428111261159551
Validation loss: 2.492835910326854

Epoch: 6| Step: 4
Training loss: 2.4085147652928742
Validation loss: 2.4739725706838223

Epoch: 6| Step: 5
Training loss: 3.2258033875481607
Validation loss: 2.473786137044102

Epoch: 6| Step: 6
Training loss: 2.966878843399429
Validation loss: 2.471759947260132

Epoch: 6| Step: 7
Training loss: 3.0532704063938634
Validation loss: 2.4727002771592104

Epoch: 6| Step: 8
Training loss: 3.1300756814600317
Validation loss: 2.4826306992614295

Epoch: 6| Step: 9
Training loss: 2.831695831430043
Validation loss: 2.483855235628355

Epoch: 6| Step: 10
Training loss: 2.1155650548739473
Validation loss: 2.4746484559218827

Epoch: 6| Step: 11
Training loss: 3.024470347544957
Validation loss: 2.4767583964502444

Epoch: 6| Step: 12
Training loss: 2.5488506681534213
Validation loss: 2.4879777015850677

Epoch: 6| Step: 13
Training loss: 2.244815469307323
Validation loss: 2.5003100490069614

Epoch: 113| Step: 0
Training loss: 2.745954485600099
Validation loss: 2.5005750886820888

Epoch: 6| Step: 1
Training loss: 2.4913876963152144
Validation loss: 2.5072709566694162

Epoch: 6| Step: 2
Training loss: 2.807341613513938
Validation loss: 2.4811075700707987

Epoch: 6| Step: 3
Training loss: 2.6225232747138807
Validation loss: 2.4952189217316225

Epoch: 6| Step: 4
Training loss: 2.814642111623113
Validation loss: 2.4925273784759243

Epoch: 6| Step: 5
Training loss: 3.1260795254540295
Validation loss: 2.495952690478444

Epoch: 6| Step: 6
Training loss: 2.960468345654545
Validation loss: 2.497820688781569

Epoch: 6| Step: 7
Training loss: 3.2520510730369265
Validation loss: 2.50739041556461

Epoch: 6| Step: 8
Training loss: 2.667244987561029
Validation loss: 2.5090186801079106

Epoch: 6| Step: 9
Training loss: 2.5143448314900296
Validation loss: 2.512981643553957

Epoch: 6| Step: 10
Training loss: 2.505029768471859
Validation loss: 2.5138443112115354

Epoch: 6| Step: 11
Training loss: 2.711065899449371
Validation loss: 2.5094539982104456

Epoch: 6| Step: 12
Training loss: 2.8888947128171987
Validation loss: 2.5102692727038325

Epoch: 6| Step: 13
Training loss: 1.673627202584067
Validation loss: 2.5112828087359556

Epoch: 114| Step: 0
Training loss: 2.9088684099896547
Validation loss: 2.518938142526382

Epoch: 6| Step: 1
Training loss: 2.3612336170603574
Validation loss: 2.5358450860535555

Epoch: 6| Step: 2
Training loss: 2.263430881261464
Validation loss: 2.549308917898227

Epoch: 6| Step: 3
Training loss: 2.541234797907447
Validation loss: 2.551262465644477

Epoch: 6| Step: 4
Training loss: 2.6686131605314256
Validation loss: 2.5915829476198224

Epoch: 6| Step: 5
Training loss: 2.248566382705946
Validation loss: 2.5636901752716827

Epoch: 6| Step: 6
Training loss: 3.38193604565952
Validation loss: 2.5742525005161863

Epoch: 6| Step: 7
Training loss: 2.601422646918957
Validation loss: 2.5491183524829806

Epoch: 6| Step: 8
Training loss: 3.0381363190434394
Validation loss: 2.5475347014190532

Epoch: 6| Step: 9
Training loss: 2.9181141849006123
Validation loss: 2.544480548610316

Epoch: 6| Step: 10
Training loss: 3.161844413264031
Validation loss: 2.545403639399297

Epoch: 6| Step: 11
Training loss: 3.3086085944084793
Validation loss: 2.5478023650281876

Epoch: 6| Step: 12
Training loss: 2.2902967230781326
Validation loss: 2.5364892159290644

Epoch: 6| Step: 13
Training loss: 2.770066654766738
Validation loss: 2.5010492830043964

Epoch: 115| Step: 0
Training loss: 2.9243484880028694
Validation loss: 2.49297160239026

Epoch: 6| Step: 1
Training loss: 3.216304702026737
Validation loss: 2.482144982818964

Epoch: 6| Step: 2
Training loss: 2.7685204128720557
Validation loss: 2.4945213419237207

Epoch: 6| Step: 3
Training loss: 2.119349428077167
Validation loss: 2.4945695245408634

Epoch: 6| Step: 4
Training loss: 2.5618518847101828
Validation loss: 2.5063434210981077

Epoch: 6| Step: 5
Training loss: 2.875016419736994
Validation loss: 2.511713699710585

Epoch: 6| Step: 6
Training loss: 2.7799356333738925
Validation loss: 2.5190034576007214

Epoch: 6| Step: 7
Training loss: 2.2508577195444435
Validation loss: 2.523542689427625

Epoch: 6| Step: 8
Training loss: 2.631561072439421
Validation loss: 2.5162685108532448

Epoch: 6| Step: 9
Training loss: 2.6513500121738818
Validation loss: 2.51234340158276

Epoch: 6| Step: 10
Training loss: 2.7147152657602254
Validation loss: 2.4996022728417486

Epoch: 6| Step: 11
Training loss: 3.159607263134293
Validation loss: 2.507800782809177

Epoch: 6| Step: 12
Training loss: 3.0474237974808553
Validation loss: 2.503048771834137

Epoch: 6| Step: 13
Training loss: 2.30968479251819
Validation loss: 2.5177745507778924

Epoch: 116| Step: 0
Training loss: 2.3844113848348667
Validation loss: 2.512669636123899

Epoch: 6| Step: 1
Training loss: 3.3297688181133656
Validation loss: 2.545808261834957

Epoch: 6| Step: 2
Training loss: 2.7633046907137664
Validation loss: 2.534726026727624

Epoch: 6| Step: 3
Training loss: 2.4948721748587195
Validation loss: 2.5578540971888426

Epoch: 6| Step: 4
Training loss: 2.7611529729813697
Validation loss: 2.54861667252407

Epoch: 6| Step: 5
Training loss: 2.086547076705461
Validation loss: 2.551236175571843

Epoch: 6| Step: 6
Training loss: 2.4479589796805685
Validation loss: 2.5330986798189987

Epoch: 6| Step: 7
Training loss: 3.216239172112585
Validation loss: 2.5297988617078606

Epoch: 6| Step: 8
Training loss: 2.5083430314325397
Validation loss: 2.50955565997849

Epoch: 6| Step: 9
Training loss: 2.932069994789637
Validation loss: 2.48654684157408

Epoch: 6| Step: 10
Training loss: 2.139121425533167
Validation loss: 2.4822179111011144

Epoch: 6| Step: 11
Training loss: 2.596425710066727
Validation loss: 2.4639680031263866

Epoch: 6| Step: 12
Training loss: 3.528044063967649
Validation loss: 2.467123551682865

Epoch: 6| Step: 13
Training loss: 2.7427990875316057
Validation loss: 2.471795163671805

Epoch: 117| Step: 0
Training loss: 2.36446634638991
Validation loss: 2.4694501590890643

Epoch: 6| Step: 1
Training loss: 3.0798344391751793
Validation loss: 2.4595363781597155

Epoch: 6| Step: 2
Training loss: 2.0201887170999036
Validation loss: 2.47455061985159

Epoch: 6| Step: 3
Training loss: 2.3799831915510308
Validation loss: 2.4948375313281437

Epoch: 6| Step: 4
Training loss: 3.248294969948387
Validation loss: 2.49765939457486

Epoch: 6| Step: 5
Training loss: 1.9152398672847901
Validation loss: 2.5350137406299775

Epoch: 6| Step: 6
Training loss: 2.948279386565588
Validation loss: 2.549293962246874

Epoch: 6| Step: 7
Training loss: 2.486300316210843
Validation loss: 2.5411115376681153

Epoch: 6| Step: 8
Training loss: 3.2360349072246373
Validation loss: 2.5409597755006086

Epoch: 6| Step: 9
Training loss: 2.333436373297446
Validation loss: 2.5275082629511076

Epoch: 6| Step: 10
Training loss: 2.939640969392464
Validation loss: 2.5387168771466273

Epoch: 6| Step: 11
Training loss: 3.2053408517966213
Validation loss: 2.5186567651760026

Epoch: 6| Step: 12
Training loss: 2.7893030399491257
Validation loss: 2.5089591888735456

Epoch: 6| Step: 13
Training loss: 2.688085359211456
Validation loss: 2.5055122916798593

Epoch: 118| Step: 0
Training loss: 2.6340262221737887
Validation loss: 2.4983872328626284

Epoch: 6| Step: 1
Training loss: 2.6135541149059356
Validation loss: 2.4877938699115347

Epoch: 6| Step: 2
Training loss: 3.323357547861827
Validation loss: 2.490429832192026

Epoch: 6| Step: 3
Training loss: 2.0609589801909656
Validation loss: 2.4885059060227444

Epoch: 6| Step: 4
Training loss: 2.8698815933418307
Validation loss: 2.4924648697745173

Epoch: 6| Step: 5
Training loss: 2.748649785885204
Validation loss: 2.5036805378330196

Epoch: 6| Step: 6
Training loss: 2.9444458999470244
Validation loss: 2.5045793144570823

Epoch: 6| Step: 7
Training loss: 2.777948799166795
Validation loss: 2.5044710100452083

Epoch: 6| Step: 8
Training loss: 3.236657116133025
Validation loss: 2.5076824352950715

Epoch: 6| Step: 9
Training loss: 2.1303138489150255
Validation loss: 2.5071702462570156

Epoch: 6| Step: 10
Training loss: 2.6243167169562436
Validation loss: 2.50739834452596

Epoch: 6| Step: 11
Training loss: 3.044900107412973
Validation loss: 2.5055290086686814

Epoch: 6| Step: 12
Training loss: 2.174422492166248
Validation loss: 2.5040636384145127

Epoch: 6| Step: 13
Training loss: 1.9309693067690337
Validation loss: 2.509799561961988

Epoch: 119| Step: 0
Training loss: 2.709178870822997
Validation loss: 2.5171821934804415

Epoch: 6| Step: 1
Training loss: 2.379684045479785
Validation loss: 2.5103419844276678

Epoch: 6| Step: 2
Training loss: 2.729899378448788
Validation loss: 2.528170672481154

Epoch: 6| Step: 3
Training loss: 3.276990760098731
Validation loss: 2.5446614552840927

Epoch: 6| Step: 4
Training loss: 2.1447787116019037
Validation loss: 2.5493918602354295

Epoch: 6| Step: 5
Training loss: 2.291961708727631
Validation loss: 2.56663829417289

Epoch: 6| Step: 6
Training loss: 2.9446115646279267
Validation loss: 2.568862961617519

Epoch: 6| Step: 7
Training loss: 2.875545615792067
Validation loss: 2.5581408964973975

Epoch: 6| Step: 8
Training loss: 2.4822643599220173
Validation loss: 2.5540174764846175

Epoch: 6| Step: 9
Training loss: 2.5493857522799925
Validation loss: 2.5430734561586092

Epoch: 6| Step: 10
Training loss: 3.1124767379197866
Validation loss: 2.5304687298999173

Epoch: 6| Step: 11
Training loss: 2.977529934236992
Validation loss: 2.5238933338835583

Epoch: 6| Step: 12
Training loss: 2.3627370160409757
Validation loss: 2.5005604382394107

Epoch: 6| Step: 13
Training loss: 2.5578728745034147
Validation loss: 2.4936111626610185

Epoch: 120| Step: 0
Training loss: 2.7892546600907364
Validation loss: 2.4920749428654387

Epoch: 6| Step: 1
Training loss: 3.012778881033013
Validation loss: 2.485933661699453

Epoch: 6| Step: 2
Training loss: 2.913976100428277
Validation loss: 2.4944001629060115

Epoch: 6| Step: 3
Training loss: 2.8268023185149374
Validation loss: 2.498768816058898

Epoch: 6| Step: 4
Training loss: 2.8494596069386047
Validation loss: 2.5167510245542064

Epoch: 6| Step: 5
Training loss: 2.435403949670627
Validation loss: 2.520904615942394

Epoch: 6| Step: 6
Training loss: 2.6566047880304624
Validation loss: 2.5440197281224415

Epoch: 6| Step: 7
Training loss: 2.5166548048670383
Validation loss: 2.5418704546469444

Epoch: 6| Step: 8
Training loss: 2.3042943586823013
Validation loss: 2.5242380837886738

Epoch: 6| Step: 9
Training loss: 2.8721378841188363
Validation loss: 2.5223287792385727

Epoch: 6| Step: 10
Training loss: 2.812244149332796
Validation loss: 2.532454489819844

Epoch: 6| Step: 11
Training loss: 3.0420512822811387
Validation loss: 2.5410846986683384

Epoch: 6| Step: 12
Training loss: 1.8563941976623008
Validation loss: 2.566882080522826

Epoch: 6| Step: 13
Training loss: 2.5566339106577227
Validation loss: 2.5760855097043325

Epoch: 121| Step: 0
Training loss: 2.9533029331109395
Validation loss: 2.6048868551020696

Epoch: 6| Step: 1
Training loss: 2.798639348352774
Validation loss: 2.6155027086919667

Epoch: 6| Step: 2
Training loss: 2.0989690611559624
Validation loss: 2.6245744612248973

Epoch: 6| Step: 3
Training loss: 2.6711083812597414
Validation loss: 2.646731344320114

Epoch: 6| Step: 4
Training loss: 1.9187249520620848
Validation loss: 2.6435797927924867

Epoch: 6| Step: 5
Training loss: 3.1999379748055334
Validation loss: 2.6218445539757047

Epoch: 6| Step: 6
Training loss: 3.170183303779993
Validation loss: 2.585688341905921

Epoch: 6| Step: 7
Training loss: 2.9889499290154764
Validation loss: 2.535189049219424

Epoch: 6| Step: 8
Training loss: 2.1653375828463255
Validation loss: 2.5547908669097388

Epoch: 6| Step: 9
Training loss: 2.8954752053391664
Validation loss: 2.6205009534789676

Epoch: 6| Step: 10
Training loss: 2.3588743373361925
Validation loss: 2.677109939202303

Epoch: 6| Step: 11
Training loss: 3.2585234746715193
Validation loss: 2.659629749557016

Epoch: 6| Step: 12
Training loss: 2.5574102328926815
Validation loss: 2.644495881731842

Epoch: 6| Step: 13
Training loss: 3.003329019434036
Validation loss: 2.6168445943509413

Epoch: 122| Step: 0
Training loss: 2.8998286361049708
Validation loss: 2.533479456932168

Epoch: 6| Step: 1
Training loss: 2.7177610681480555
Validation loss: 2.488813359375408

Epoch: 6| Step: 2
Training loss: 2.144361478829068
Validation loss: 2.4729319550300746

Epoch: 6| Step: 3
Training loss: 2.875057717448836
Validation loss: 2.460551999302617

Epoch: 6| Step: 4
Training loss: 2.819202151690213
Validation loss: 2.460980747179509

Epoch: 6| Step: 5
Training loss: 2.4001457766129373
Validation loss: 2.4660063877845175

Epoch: 6| Step: 6
Training loss: 2.9202301781217335
Validation loss: 2.4686082181642495

Epoch: 6| Step: 7
Training loss: 2.9513119576593967
Validation loss: 2.474886585606518

Epoch: 6| Step: 8
Training loss: 3.0096347589776222
Validation loss: 2.482506013203752

Epoch: 6| Step: 9
Training loss: 2.7560671721910905
Validation loss: 2.4798255066345507

Epoch: 6| Step: 10
Training loss: 2.3608642324393054
Validation loss: 2.4782862255895926

Epoch: 6| Step: 11
Training loss: 2.589709984732498
Validation loss: 2.4793951453711136

Epoch: 6| Step: 12
Training loss: 3.0113946366718327
Validation loss: 2.4820972499943297

Epoch: 6| Step: 13
Training loss: 2.574216341935046
Validation loss: 2.4890503156804966

Epoch: 123| Step: 0
Training loss: 2.8402238719978405
Validation loss: 2.5086915196199766

Epoch: 6| Step: 1
Training loss: 2.5642727558189575
Validation loss: 2.5439810558512663

Epoch: 6| Step: 2
Training loss: 3.009310738104199
Validation loss: 2.594972706021958

Epoch: 6| Step: 3
Training loss: 2.5846628234076428
Validation loss: 2.6156458195851733

Epoch: 6| Step: 4
Training loss: 2.8279698787741547
Validation loss: 2.6318825589020296

Epoch: 6| Step: 5
Training loss: 2.4482100507090028
Validation loss: 2.6309993841328683

Epoch: 6| Step: 6
Training loss: 2.6745738180189056
Validation loss: 2.624037224725025

Epoch: 6| Step: 7
Training loss: 3.2757970640791068
Validation loss: 2.558721038425059

Epoch: 6| Step: 8
Training loss: 2.3324705186229817
Validation loss: 2.5233254219364962

Epoch: 6| Step: 9
Training loss: 2.7438988195566014
Validation loss: 2.49820392448532

Epoch: 6| Step: 10
Training loss: 2.4746113019181526
Validation loss: 2.4870640086566755

Epoch: 6| Step: 11
Training loss: 3.1031065972004357
Validation loss: 2.487944800846107

Epoch: 6| Step: 12
Training loss: 2.347088280141033
Validation loss: 2.4850341712835684

Epoch: 6| Step: 13
Training loss: 2.826600817942017
Validation loss: 2.476683061218896

Epoch: 124| Step: 0
Training loss: 2.8975713623316834
Validation loss: 2.4749667802149284

Epoch: 6| Step: 1
Training loss: 2.408752230300227
Validation loss: 2.4796418475441317

Epoch: 6| Step: 2
Training loss: 2.3992570601360734
Validation loss: 2.483581135453495

Epoch: 6| Step: 3
Training loss: 2.9234148343714823
Validation loss: 2.4813898155590524

Epoch: 6| Step: 4
Training loss: 2.1456832709818423
Validation loss: 2.4916643896314397

Epoch: 6| Step: 5
Training loss: 2.3234901119552895
Validation loss: 2.482877166677633

Epoch: 6| Step: 6
Training loss: 2.382923761490529
Validation loss: 2.5033763871156105

Epoch: 6| Step: 7
Training loss: 2.662330668621163
Validation loss: 2.5042338022409547

Epoch: 6| Step: 8
Training loss: 2.583160292049525
Validation loss: 2.5095906866957995

Epoch: 6| Step: 9
Training loss: 2.8579985427158663
Validation loss: 2.5207832295513155

Epoch: 6| Step: 10
Training loss: 3.23300923430578
Validation loss: 2.5524571255312742

Epoch: 6| Step: 11
Training loss: 3.2077707234972963
Validation loss: 2.5915927428384644

Epoch: 6| Step: 12
Training loss: 2.8933369879399202
Validation loss: 2.5885466614797554

Epoch: 6| Step: 13
Training loss: 2.2233081257242824
Validation loss: 2.5806036038923743

Epoch: 125| Step: 0
Training loss: 2.5400717270102695
Validation loss: 2.5694625111833176

Epoch: 6| Step: 1
Training loss: 2.363385360568358
Validation loss: 2.546993622017045

Epoch: 6| Step: 2
Training loss: 2.4573513483548655
Validation loss: 2.52857400213343

Epoch: 6| Step: 3
Training loss: 2.2736194446027533
Validation loss: 2.5222537744750735

Epoch: 6| Step: 4
Training loss: 3.071004464407396
Validation loss: 2.5172738437333084

Epoch: 6| Step: 5
Training loss: 2.6148091455545623
Validation loss: 2.517675345985885

Epoch: 6| Step: 6
Training loss: 2.337605368947333
Validation loss: 2.512081249643188

Epoch: 6| Step: 7
Training loss: 3.0826590204485056
Validation loss: 2.4965203485382106

Epoch: 6| Step: 8
Training loss: 3.4402630885010854
Validation loss: 2.4993441028960928

Epoch: 6| Step: 9
Training loss: 2.4467331534593346
Validation loss: 2.502052713408157

Epoch: 6| Step: 10
Training loss: 2.717552535208144
Validation loss: 2.498705941268451

Epoch: 6| Step: 11
Training loss: 2.628318142682745
Validation loss: 2.5063497710104023

Epoch: 6| Step: 12
Training loss: 2.149143505269924
Validation loss: 2.509248167384438

Epoch: 6| Step: 13
Training loss: 2.8790523331534166
Validation loss: 2.5202180982360325

Epoch: 126| Step: 0
Training loss: 2.980539783516242
Validation loss: 2.510009533136372

Epoch: 6| Step: 1
Training loss: 2.1419054642874267
Validation loss: 2.5021869589569783

Epoch: 6| Step: 2
Training loss: 3.0891347040238455
Validation loss: 2.492705159818033

Epoch: 6| Step: 3
Training loss: 3.0582839594570617
Validation loss: 2.5050151113332255

Epoch: 6| Step: 4
Training loss: 2.4216302563458583
Validation loss: 2.5147275363911867

Epoch: 6| Step: 5
Training loss: 2.9256575472952076
Validation loss: 2.503998926749457

Epoch: 6| Step: 6
Training loss: 2.5086278807944624
Validation loss: 2.5225127888628323

Epoch: 6| Step: 7
Training loss: 2.5295581579570974
Validation loss: 2.533823190911262

Epoch: 6| Step: 8
Training loss: 2.284046914562475
Validation loss: 2.5268094038602507

Epoch: 6| Step: 9
Training loss: 2.952448691779061
Validation loss: 2.5216797167385683

Epoch: 6| Step: 10
Training loss: 2.3286106703926177
Validation loss: 2.5217922877971386

Epoch: 6| Step: 11
Training loss: 2.172541673829049
Validation loss: 2.5389064572378532

Epoch: 6| Step: 12
Training loss: 2.5796241794072294
Validation loss: 2.552036579466422

Epoch: 6| Step: 13
Training loss: 2.747327633172447
Validation loss: 2.5623217745073283

Epoch: 127| Step: 0
Training loss: 2.087236778430319
Validation loss: 2.584790812683947

Epoch: 6| Step: 1
Training loss: 2.7894412512821
Validation loss: 2.593827232755836

Epoch: 6| Step: 2
Training loss: 2.262954611444032
Validation loss: 2.5949119044006834

Epoch: 6| Step: 3
Training loss: 3.377406922137188
Validation loss: 2.592559177364343

Epoch: 6| Step: 4
Training loss: 2.908941683680712
Validation loss: 2.607182474250549

Epoch: 6| Step: 5
Training loss: 2.8427985978790384
Validation loss: 2.6158497701964394

Epoch: 6| Step: 6
Training loss: 1.836988432381082
Validation loss: 2.613283527891429

Epoch: 6| Step: 7
Training loss: 2.1409733621079594
Validation loss: 2.6073319019591596

Epoch: 6| Step: 8
Training loss: 2.4714391041916324
Validation loss: 2.599345588442832

Epoch: 6| Step: 9
Training loss: 3.070011502719665
Validation loss: 2.6293917686065584

Epoch: 6| Step: 10
Training loss: 2.055656639683748
Validation loss: 2.606875477025586

Epoch: 6| Step: 11
Training loss: 2.974194483336124
Validation loss: 2.6077691586507656

Epoch: 6| Step: 12
Training loss: 2.412627549826817
Validation loss: 2.5990857856662175

Epoch: 6| Step: 13
Training loss: 3.387268373798098
Validation loss: 2.621394707647396

Epoch: 128| Step: 0
Training loss: 2.4887604783439676
Validation loss: 2.615519631294355

Epoch: 6| Step: 1
Training loss: 3.114413219556525
Validation loss: 2.647074586447497

Epoch: 6| Step: 2
Training loss: 3.0853700526543664
Validation loss: 2.6324445106368697

Epoch: 6| Step: 3
Training loss: 2.5987557515075657
Validation loss: 2.552023648904954

Epoch: 6| Step: 4
Training loss: 3.12347374838271
Validation loss: 2.5132373711209874

Epoch: 6| Step: 5
Training loss: 2.7084046770137977
Validation loss: 2.508070280703308

Epoch: 6| Step: 6
Training loss: 2.1273646941679245
Validation loss: 2.4940219366239726

Epoch: 6| Step: 7
Training loss: 2.5981387959348696
Validation loss: 2.491668987722369

Epoch: 6| Step: 8
Training loss: 2.4678248349910756
Validation loss: 2.4919326383941693

Epoch: 6| Step: 9
Training loss: 2.9997192887264013
Validation loss: 2.5108287654981765

Epoch: 6| Step: 10
Training loss: 2.629773658614831
Validation loss: 2.496482476712399

Epoch: 6| Step: 11
Training loss: 2.2814557753470703
Validation loss: 2.5037336474451117

Epoch: 6| Step: 12
Training loss: 2.2825438083484904
Validation loss: 2.507699918860253

Epoch: 6| Step: 13
Training loss: 2.892146849179135
Validation loss: 2.5174331704136086

Epoch: 129| Step: 0
Training loss: 3.109895288845039
Validation loss: 2.5144749762171235

Epoch: 6| Step: 1
Training loss: 2.6668833008827635
Validation loss: 2.509338076397011

Epoch: 6| Step: 2
Training loss: 3.198659174868084
Validation loss: 2.517439007617654

Epoch: 6| Step: 3
Training loss: 2.8972433668734303
Validation loss: 2.510259514023369

Epoch: 6| Step: 4
Training loss: 2.2810128493693402
Validation loss: 2.5027760382452344

Epoch: 6| Step: 5
Training loss: 2.599557831652333
Validation loss: 2.4969347261291466

Epoch: 6| Step: 6
Training loss: 2.2920144481902573
Validation loss: 2.504248588845937

Epoch: 6| Step: 7
Training loss: 2.719004827373747
Validation loss: 2.5387939947251548

Epoch: 6| Step: 8
Training loss: 2.4059539216434067
Validation loss: 2.555203861313441

Epoch: 6| Step: 9
Training loss: 2.1512437283714325
Validation loss: 2.606180002606328

Epoch: 6| Step: 10
Training loss: 2.521148682933539
Validation loss: 2.5774423191952067

Epoch: 6| Step: 11
Training loss: 3.4432699156168387
Validation loss: 2.5600246035319048

Epoch: 6| Step: 12
Training loss: 2.3366681745508893
Validation loss: 2.5173459345768268

Epoch: 6| Step: 13
Training loss: 2.7309618765182524
Validation loss: 2.5039518664860174

Epoch: 130| Step: 0
Training loss: 2.979933544416416
Validation loss: 2.501555606915836

Epoch: 6| Step: 1
Training loss: 2.90763018250228
Validation loss: 2.5254004962621215

Epoch: 6| Step: 2
Training loss: 2.414492571893777
Validation loss: 2.5640419003470507

Epoch: 6| Step: 3
Training loss: 2.147699513698636
Validation loss: 2.586784342848388

Epoch: 6| Step: 4
Training loss: 2.6258994786647873
Validation loss: 2.6270742215019705

Epoch: 6| Step: 5
Training loss: 2.729186798099107
Validation loss: 2.574707014820919

Epoch: 6| Step: 6
Training loss: 1.6587302153154133
Validation loss: 2.5328800650285315

Epoch: 6| Step: 7
Training loss: 2.8549694036925346
Validation loss: 2.5196774309873016

Epoch: 6| Step: 8
Training loss: 2.970668132909462
Validation loss: 2.530254979188436

Epoch: 6| Step: 9
Training loss: 2.9696836910646875
Validation loss: 2.5338735794804106

Epoch: 6| Step: 10
Training loss: 2.8324019827385536
Validation loss: 2.5501862941261866

Epoch: 6| Step: 11
Training loss: 2.6089940506855225
Validation loss: 2.5504512273429882

Epoch: 6| Step: 12
Training loss: 2.720145032045411
Validation loss: 2.5468787263668964

Epoch: 6| Step: 13
Training loss: 2.9850729880043767
Validation loss: 2.54428654331663

Epoch: 131| Step: 0
Training loss: 2.075246093128692
Validation loss: 2.551492879811573

Epoch: 6| Step: 1
Training loss: 3.252617588835063
Validation loss: 2.54187499721798

Epoch: 6| Step: 2
Training loss: 2.630890911907304
Validation loss: 2.53033459679243

Epoch: 6| Step: 3
Training loss: 2.3902793085818796
Validation loss: 2.525551004881996

Epoch: 6| Step: 4
Training loss: 2.7862127368158593
Validation loss: 2.5138795841120154

Epoch: 6| Step: 5
Training loss: 2.119848177169886
Validation loss: 2.5139316807952854

Epoch: 6| Step: 6
Training loss: 2.2979902816513844
Validation loss: 2.5132166445356408

Epoch: 6| Step: 7
Training loss: 3.1100883240745625
Validation loss: 2.505434103641087

Epoch: 6| Step: 8
Training loss: 3.0136994059622255
Validation loss: 2.5222437323373006

Epoch: 6| Step: 9
Training loss: 2.0888631926752943
Validation loss: 2.5145718650258315

Epoch: 6| Step: 10
Training loss: 2.5331758307969636
Validation loss: 2.5248602985750423

Epoch: 6| Step: 11
Training loss: 3.0150425798183473
Validation loss: 2.5325507418991187

Epoch: 6| Step: 12
Training loss: 2.5648528671451194
Validation loss: 2.54925224344019

Epoch: 6| Step: 13
Training loss: 2.7119210957101814
Validation loss: 2.56271258777192

Epoch: 132| Step: 0
Training loss: 2.7765336068989437
Validation loss: 2.5670509274738893

Epoch: 6| Step: 1
Training loss: 2.679859389416896
Validation loss: 2.594523886081042

Epoch: 6| Step: 2
Training loss: 2.626119919705138
Validation loss: 2.6077129554726417

Epoch: 6| Step: 3
Training loss: 2.5938788692218844
Validation loss: 2.6275924332256926

Epoch: 6| Step: 4
Training loss: 2.826265261042414
Validation loss: 2.62753386507979

Epoch: 6| Step: 5
Training loss: 2.9933931396842106
Validation loss: 2.636599384797836

Epoch: 6| Step: 6
Training loss: 2.460068903632603
Validation loss: 2.6092194472815677

Epoch: 6| Step: 7
Training loss: 2.115763167542135
Validation loss: 2.587148726417102

Epoch: 6| Step: 8
Training loss: 2.5721159292586604
Validation loss: 2.5470837189789344

Epoch: 6| Step: 9
Training loss: 2.5279663828352943
Validation loss: 2.541873206009767

Epoch: 6| Step: 10
Training loss: 2.5243121541628035
Validation loss: 2.5202058217698062

Epoch: 6| Step: 11
Training loss: 2.8436322869052324
Validation loss: 2.5089937702474145

Epoch: 6| Step: 12
Training loss: 2.5286220519299336
Validation loss: 2.5000871243215963

Epoch: 6| Step: 13
Training loss: 2.357374340927669
Validation loss: 2.4945081913318656

Epoch: 133| Step: 0
Training loss: 2.396948734427508
Validation loss: 2.4863823076814526

Epoch: 6| Step: 1
Training loss: 2.5980978683585683
Validation loss: 2.490585066575996

Epoch: 6| Step: 2
Training loss: 2.983194007674787
Validation loss: 2.498951479777894

Epoch: 6| Step: 3
Training loss: 2.034580259032397
Validation loss: 2.4984012167624603

Epoch: 6| Step: 4
Training loss: 2.9767034702510573
Validation loss: 2.4941861333215822

Epoch: 6| Step: 5
Training loss: 3.4954399648385506
Validation loss: 2.494750502158102

Epoch: 6| Step: 6
Training loss: 2.6120907476647215
Validation loss: 2.4994871813344215

Epoch: 6| Step: 7
Training loss: 2.746739969417332
Validation loss: 2.5027946111254344

Epoch: 6| Step: 8
Training loss: 2.1884406111086516
Validation loss: 2.504975882955645

Epoch: 6| Step: 9
Training loss: 2.869145444654308
Validation loss: 2.524849610879387

Epoch: 6| Step: 10
Training loss: 2.3459539604905317
Validation loss: 2.544206626744361

Epoch: 6| Step: 11
Training loss: 2.035984449218539
Validation loss: 2.5566358960833506

Epoch: 6| Step: 12
Training loss: 2.3193365542762336
Validation loss: 2.5830331033142766

Epoch: 6| Step: 13
Training loss: 2.685544122867908
Validation loss: 2.599411550905931

Epoch: 134| Step: 0
Training loss: 2.616142952702434
Validation loss: 2.6004404372140737

Epoch: 6| Step: 1
Training loss: 2.9025827876728054
Validation loss: 2.5970404764264887

Epoch: 6| Step: 2
Training loss: 2.284711954337884
Validation loss: 2.609516994932522

Epoch: 6| Step: 3
Training loss: 2.5474628167999853
Validation loss: 2.619819427801768

Epoch: 6| Step: 4
Training loss: 2.6385226938133055
Validation loss: 2.578949962295372

Epoch: 6| Step: 5
Training loss: 2.374019822086922
Validation loss: 2.5507276405309462

Epoch: 6| Step: 6
Training loss: 2.7614287530347688
Validation loss: 2.541482233516941

Epoch: 6| Step: 7
Training loss: 2.852422213617965
Validation loss: 2.5146954484673567

Epoch: 6| Step: 8
Training loss: 1.9627566467413613
Validation loss: 2.5127093412444164

Epoch: 6| Step: 9
Training loss: 2.556666549656089
Validation loss: 2.53272809051457

Epoch: 6| Step: 10
Training loss: 2.76049034932002
Validation loss: 2.536061651960931

Epoch: 6| Step: 11
Training loss: 2.8200658970431474
Validation loss: 2.555362469375829

Epoch: 6| Step: 12
Training loss: 2.6621390192028396
Validation loss: 2.549460931203027

Epoch: 6| Step: 13
Training loss: 2.4399151696639474
Validation loss: 2.554349979039518

Epoch: 135| Step: 0
Training loss: 2.0401197009403735
Validation loss: 2.5812003548861155

Epoch: 6| Step: 1
Training loss: 2.4079489716924356
Validation loss: 2.576879162167729

Epoch: 6| Step: 2
Training loss: 2.4851905875545492
Validation loss: 2.583569578059084

Epoch: 6| Step: 3
Training loss: 2.4588765551719383
Validation loss: 2.5699247896969717

Epoch: 6| Step: 4
Training loss: 2.295400029143662
Validation loss: 2.5628763488236577

Epoch: 6| Step: 5
Training loss: 2.9242837534310953
Validation loss: 2.562450419460789

Epoch: 6| Step: 6
Training loss: 1.965659546662239
Validation loss: 2.5858082052604

Epoch: 6| Step: 7
Training loss: 3.3559467654638016
Validation loss: 2.6053155529706795

Epoch: 6| Step: 8
Training loss: 2.6119839537333585
Validation loss: 2.605687648133685

Epoch: 6| Step: 9
Training loss: 1.9857550200295992
Validation loss: 2.602505108463814

Epoch: 6| Step: 10
Training loss: 2.590245648668631
Validation loss: 2.607719358390158

Epoch: 6| Step: 11
Training loss: 2.7561656151826996
Validation loss: 2.598522872755093

Epoch: 6| Step: 12
Training loss: 3.140106917583766
Validation loss: 2.5662856892242196

Epoch: 6| Step: 13
Training loss: 2.322469614115541
Validation loss: 2.572125940641879

Epoch: 136| Step: 0
Training loss: 3.0393654640419983
Validation loss: 2.549170356543491

Epoch: 6| Step: 1
Training loss: 2.684513206610022
Validation loss: 2.559405671811272

Epoch: 6| Step: 2
Training loss: 2.37671709730334
Validation loss: 2.5601084103721576

Epoch: 6| Step: 3
Training loss: 2.306907903188054
Validation loss: 2.579402847790319

Epoch: 6| Step: 4
Training loss: 2.1672827382740927
Validation loss: 2.5722983088317424

Epoch: 6| Step: 5
Training loss: 3.0228065798427504
Validation loss: 2.5657703531300196

Epoch: 6| Step: 6
Training loss: 2.84343793225686
Validation loss: 2.534513570690075

Epoch: 6| Step: 7
Training loss: 2.841211212739297
Validation loss: 2.5252975790480052

Epoch: 6| Step: 8
Training loss: 2.4850807387132483
Validation loss: 2.511807844907383

Epoch: 6| Step: 9
Training loss: 3.01600225589172
Validation loss: 2.5411975732996606

Epoch: 6| Step: 10
Training loss: 2.3530206056820155
Validation loss: 2.540361601592828

Epoch: 6| Step: 11
Training loss: 2.0613143287183995
Validation loss: 2.5637828238072102

Epoch: 6| Step: 12
Training loss: 2.5157876287931136
Validation loss: 2.5546310602713276

Epoch: 6| Step: 13
Training loss: 1.7202454736664183
Validation loss: 2.522994785097447

Epoch: 137| Step: 0
Training loss: 2.4873347855339354
Validation loss: 2.513348160945296

Epoch: 6| Step: 1
Training loss: 2.432881699633256
Validation loss: 2.5460318724914988

Epoch: 6| Step: 2
Training loss: 2.7149830295320396
Validation loss: 2.5824664074086505

Epoch: 6| Step: 3
Training loss: 2.5172256211106077
Validation loss: 2.6011220779758726

Epoch: 6| Step: 4
Training loss: 2.9626031785211784
Validation loss: 2.5992054562951017

Epoch: 6| Step: 5
Training loss: 2.952214176254912
Validation loss: 2.5859536296640218

Epoch: 6| Step: 6
Training loss: 2.7363939951252667
Validation loss: 2.587997790064371

Epoch: 6| Step: 7
Training loss: 2.2452938878104933
Validation loss: 2.5686973416478724

Epoch: 6| Step: 8
Training loss: 2.6197493583240847
Validation loss: 2.5492135489761103

Epoch: 6| Step: 9
Training loss: 2.6855550426012162
Validation loss: 2.5401595882597574

Epoch: 6| Step: 10
Training loss: 1.9850492158068562
Validation loss: 2.5381038782731467

Epoch: 6| Step: 11
Training loss: 2.498693697105663
Validation loss: 2.5423197879630184

Epoch: 6| Step: 12
Training loss: 2.6466904000468117
Validation loss: 2.5388361731689577

Epoch: 6| Step: 13
Training loss: 1.6712021231231058
Validation loss: 2.537449051831327

Epoch: 138| Step: 0
Training loss: 1.9490468899296105
Validation loss: 2.5483550519734077

Epoch: 6| Step: 1
Training loss: 2.4754297210943292
Validation loss: 2.5400237070879124

Epoch: 6| Step: 2
Training loss: 2.469095133546583
Validation loss: 2.546426585754524

Epoch: 6| Step: 3
Training loss: 2.918272357552743
Validation loss: 2.5571463018764287

Epoch: 6| Step: 4
Training loss: 2.2469593271021546
Validation loss: 2.579021459338545

Epoch: 6| Step: 5
Training loss: 2.834930997947315
Validation loss: 2.60244760654093

Epoch: 6| Step: 6
Training loss: 2.0579773995406905
Validation loss: 2.6047648609540333

Epoch: 6| Step: 7
Training loss: 2.516089355070721
Validation loss: 2.611028034560167

Epoch: 6| Step: 8
Training loss: 2.5716241429147213
Validation loss: 2.625487577722455

Epoch: 6| Step: 9
Training loss: 2.6884308910543604
Validation loss: 2.620103136013271

Epoch: 6| Step: 10
Training loss: 3.1925990888233313
Validation loss: 2.6278236874969494

Epoch: 6| Step: 11
Training loss: 2.2291551987777876
Validation loss: 2.58788259989848

Epoch: 6| Step: 12
Training loss: 2.104608193583436
Validation loss: 2.590060282663031

Epoch: 6| Step: 13
Training loss: 3.0676290418721748
Validation loss: 2.5487596041764533

Epoch: 139| Step: 0
Training loss: 2.4721333943766637
Validation loss: 2.562664464899591

Epoch: 6| Step: 1
Training loss: 2.1330675803994747
Validation loss: 2.5414531731739864

Epoch: 6| Step: 2
Training loss: 2.4327015718566103
Validation loss: 2.51782826012907

Epoch: 6| Step: 3
Training loss: 2.0242550645321797
Validation loss: 2.505643825726764

Epoch: 6| Step: 4
Training loss: 2.761590806298628
Validation loss: 2.5047721968380086

Epoch: 6| Step: 5
Training loss: 2.512332633597872
Validation loss: 2.51062795792935

Epoch: 6| Step: 6
Training loss: 2.8004936804840592
Validation loss: 2.5437564344753825

Epoch: 6| Step: 7
Training loss: 2.747098432356967
Validation loss: 2.5829456612718054

Epoch: 6| Step: 8
Training loss: 3.0842336079230748
Validation loss: 2.6048033138300752

Epoch: 6| Step: 9
Training loss: 2.6373905936596063
Validation loss: 2.5851107710433663

Epoch: 6| Step: 10
Training loss: 2.3523969722163347
Validation loss: 2.553823031219746

Epoch: 6| Step: 11
Training loss: 3.019719797739577
Validation loss: 2.5302184978413282

Epoch: 6| Step: 12
Training loss: 1.992956873111783
Validation loss: 2.50263027752778

Epoch: 6| Step: 13
Training loss: 2.6078805812865014
Validation loss: 2.501936422030997

Epoch: 140| Step: 0
Training loss: 2.6973843337778374
Validation loss: 2.4946272008407995

Epoch: 6| Step: 1
Training loss: 2.5585151019639376
Validation loss: 2.5119099298726537

Epoch: 6| Step: 2
Training loss: 1.7852617562332542
Validation loss: 2.499833224486565

Epoch: 6| Step: 3
Training loss: 2.7646261879292786
Validation loss: 2.504286256211784

Epoch: 6| Step: 4
Training loss: 2.3103920891993552
Validation loss: 2.4912549269418656

Epoch: 6| Step: 5
Training loss: 2.1837036978622746
Validation loss: 2.496236586481015

Epoch: 6| Step: 6
Training loss: 3.336747868401248
Validation loss: 2.485280797484292

Epoch: 6| Step: 7
Training loss: 2.348765994794548
Validation loss: 2.49280255795685

Epoch: 6| Step: 8
Training loss: 1.6824873897992507
Validation loss: 2.4964613676438634

Epoch: 6| Step: 9
Training loss: 2.7668584454568768
Validation loss: 2.507097014095465

Epoch: 6| Step: 10
Training loss: 2.727727690230603
Validation loss: 2.5084338497710488

Epoch: 6| Step: 11
Training loss: 2.8782318857498215
Validation loss: 2.525057658452272

Epoch: 6| Step: 12
Training loss: 2.5148133099773644
Validation loss: 2.5219365831848064

Epoch: 6| Step: 13
Training loss: 2.3556359581250907
Validation loss: 2.5277695817020818

Epoch: 141| Step: 0
Training loss: 2.0551798995600516
Validation loss: 2.525990422934986

Epoch: 6| Step: 1
Training loss: 2.5502495437889414
Validation loss: 2.519019283099705

Epoch: 6| Step: 2
Training loss: 2.604317703953379
Validation loss: 2.5151340517898984

Epoch: 6| Step: 3
Training loss: 2.6156504202533792
Validation loss: 2.516098998930174

Epoch: 6| Step: 4
Training loss: 2.3048378071020785
Validation loss: 2.526989466454329

Epoch: 6| Step: 5
Training loss: 2.3132333365969497
Validation loss: 2.510268100295689

Epoch: 6| Step: 6
Training loss: 2.557054269082723
Validation loss: 2.5260729749841224

Epoch: 6| Step: 7
Training loss: 2.2485481452359637
Validation loss: 2.530423230765838

Epoch: 6| Step: 8
Training loss: 2.547669830800777
Validation loss: 2.534042631814399

Epoch: 6| Step: 9
Training loss: 1.524923685384399
Validation loss: 2.545180948569278

Epoch: 6| Step: 10
Training loss: 3.1494575154463607
Validation loss: 2.5430949505100577

Epoch: 6| Step: 11
Training loss: 2.899775029368186
Validation loss: 2.555184222608523

Epoch: 6| Step: 12
Training loss: 2.7567810204468626
Validation loss: 2.570694478445528

Epoch: 6| Step: 13
Training loss: 2.1512471640444586
Validation loss: 2.5876900930290576

Epoch: 142| Step: 0
Training loss: 2.812011930714417
Validation loss: 2.588782148880491

Epoch: 6| Step: 1
Training loss: 1.8335940724694806
Validation loss: 2.570906000716977

Epoch: 6| Step: 2
Training loss: 2.94077167530304
Validation loss: 2.569229836016049

Epoch: 6| Step: 3
Training loss: 2.4186783890879973
Validation loss: 2.5588033731022204

Epoch: 6| Step: 4
Training loss: 2.5757058555761883
Validation loss: 2.5455204355930086

Epoch: 6| Step: 5
Training loss: 2.706291681193343
Validation loss: 2.530129644927692

Epoch: 6| Step: 6
Training loss: 2.1031116320793113
Validation loss: 2.5339102823840345

Epoch: 6| Step: 7
Training loss: 1.4151445327110281
Validation loss: 2.518872842042772

Epoch: 6| Step: 8
Training loss: 2.3297880236751176
Validation loss: 2.522412255052789

Epoch: 6| Step: 9
Training loss: 2.6798566314439274
Validation loss: 2.511650623312456

Epoch: 6| Step: 10
Training loss: 2.2607889059360162
Validation loss: 2.514014414668899

Epoch: 6| Step: 11
Training loss: 2.889969210081188
Validation loss: 2.520516406070985

Epoch: 6| Step: 12
Training loss: 2.8559077352051125
Validation loss: 2.5030782642195235

Epoch: 6| Step: 13
Training loss: 1.8256688368619973
Validation loss: 2.53479876003515

Epoch: 143| Step: 0
Training loss: 3.2476199311626903
Validation loss: 2.548060782517007

Epoch: 6| Step: 1
Training loss: 2.1985500803022258
Validation loss: 2.5709653558173313

Epoch: 6| Step: 2
Training loss: 1.9060641964271532
Validation loss: 2.5665928489091243

Epoch: 6| Step: 3
Training loss: 2.1885138205914814
Validation loss: 2.56998926184816

Epoch: 6| Step: 4
Training loss: 2.5142471615510824
Validation loss: 2.59864503661887

Epoch: 6| Step: 5
Training loss: 2.8474707104764896
Validation loss: 2.5905409471059166

Epoch: 6| Step: 6
Training loss: 2.1245454414232046
Validation loss: 2.6146620414315507

Epoch: 6| Step: 7
Training loss: 2.0655755895571377
Validation loss: 2.609453020948999

Epoch: 6| Step: 8
Training loss: 2.0410525377941973
Validation loss: 2.5954057983113774

Epoch: 6| Step: 9
Training loss: 2.6476344688782545
Validation loss: 2.5881094398483167

Epoch: 6| Step: 10
Training loss: 1.860332466888545
Validation loss: 2.5688771806129385

Epoch: 6| Step: 11
Training loss: 3.4155538343884246
Validation loss: 2.5603857064382614

Epoch: 6| Step: 12
Training loss: 2.060313134698873
Validation loss: 2.5435564999396996

Epoch: 6| Step: 13
Training loss: 2.5861236413073256
Validation loss: 2.5435572729958786

Epoch: 144| Step: 0
Training loss: 2.356002418199474
Validation loss: 2.537349745337362

Epoch: 6| Step: 1
Training loss: 2.3315502801750543
Validation loss: 2.509856504219634

Epoch: 6| Step: 2
Training loss: 2.4598613989947493
Validation loss: 2.4996195278033295

Epoch: 6| Step: 3
Training loss: 2.6296759239662766
Validation loss: 2.4918079306407104

Epoch: 6| Step: 4
Training loss: 2.438927941334315
Validation loss: 2.493419252171265

Epoch: 6| Step: 5
Training loss: 1.5176412012058496
Validation loss: 2.492828424568114

Epoch: 6| Step: 6
Training loss: 1.9753210820785763
Validation loss: 2.5061843888031703

Epoch: 6| Step: 7
Training loss: 2.5665474537829085
Validation loss: 2.504402412883571

Epoch: 6| Step: 8
Training loss: 2.539583968385946
Validation loss: 2.505802438080627

Epoch: 6| Step: 9
Training loss: 2.80184375821254
Validation loss: 2.503633484896476

Epoch: 6| Step: 10
Training loss: 2.7594479474527014
Validation loss: 2.52717094250926

Epoch: 6| Step: 11
Training loss: 2.8593191339423805
Validation loss: 2.5281200039417713

Epoch: 6| Step: 12
Training loss: 2.088209650629675
Validation loss: 2.535394149239295

Epoch: 6| Step: 13
Training loss: 2.087363337994482
Validation loss: 2.55872453012321

Epoch: 145| Step: 0
Training loss: 1.5697043080904272
Validation loss: 2.5569508412752606

Epoch: 6| Step: 1
Training loss: 2.448816975275951
Validation loss: 2.5623886650464094

Epoch: 6| Step: 2
Training loss: 2.825913971770618
Validation loss: 2.579345971853732

Epoch: 6| Step: 3
Training loss: 2.283728311536976
Validation loss: 2.5712839178435294

Epoch: 6| Step: 4
Training loss: 2.383268719132959
Validation loss: 2.5665780828707367

Epoch: 6| Step: 5
Training loss: 2.783900851413442
Validation loss: 2.5384346093952526

Epoch: 6| Step: 6
Training loss: 2.160810430159918
Validation loss: 2.5251292945803137

Epoch: 6| Step: 7
Training loss: 2.6434465491192625
Validation loss: 2.5218423317154257

Epoch: 6| Step: 8
Training loss: 1.9403743956799049
Validation loss: 2.5211348374086886

Epoch: 6| Step: 9
Training loss: 2.057031143368125
Validation loss: 2.5340657303903593

Epoch: 6| Step: 10
Training loss: 2.902015800995666
Validation loss: 2.5390938715736016

Epoch: 6| Step: 11
Training loss: 2.4756468996746883
Validation loss: 2.5444006139500392

Epoch: 6| Step: 12
Training loss: 2.4922191653736263
Validation loss: 2.533317055134484

Epoch: 6| Step: 13
Training loss: 2.012205787145484
Validation loss: 2.524767089907823

Epoch: 146| Step: 0
Training loss: 2.760515568718851
Validation loss: 2.5200101551965295

Epoch: 6| Step: 1
Training loss: 2.2037614484761163
Validation loss: 2.532547719746963

Epoch: 6| Step: 2
Training loss: 2.0156037085539715
Validation loss: 2.5301028870182583

Epoch: 6| Step: 3
Training loss: 2.4805306494491144
Validation loss: 2.5261723959742195

Epoch: 6| Step: 4
Training loss: 2.4190677246857333
Validation loss: 2.5468782427045102

Epoch: 6| Step: 5
Training loss: 2.090442265163799
Validation loss: 2.5399539585977515

Epoch: 6| Step: 6
Training loss: 2.5918921745619867
Validation loss: 2.5412008933625745

Epoch: 6| Step: 7
Training loss: 2.5893576325449428
Validation loss: 2.5305055703272896

Epoch: 6| Step: 8
Training loss: 2.3881904322733565
Validation loss: 2.5284324064129478

Epoch: 6| Step: 9
Training loss: 2.320346305421089
Validation loss: 2.5201731154297713

Epoch: 6| Step: 10
Training loss: 2.1484501508860485
Validation loss: 2.5290675972323062

Epoch: 6| Step: 11
Training loss: 2.2580165044892606
Validation loss: 2.5296536922637447

Epoch: 6| Step: 12
Training loss: 2.8332382260983975
Validation loss: 2.5446078488638295

Epoch: 6| Step: 13
Training loss: 1.749950203868292
Validation loss: 2.548163475550145

Epoch: 147| Step: 0
Training loss: 2.8944546461586564
Validation loss: 2.5423964433312256

Epoch: 6| Step: 1
Training loss: 2.264457980853697
Validation loss: 2.5665738237473485

Epoch: 6| Step: 2
Training loss: 2.2871091665109855
Validation loss: 2.57309767167894

Epoch: 6| Step: 3
Training loss: 2.6573575571809194
Validation loss: 2.585752709030627

Epoch: 6| Step: 4
Training loss: 2.2159536228284678
Validation loss: 2.6183982657743496

Epoch: 6| Step: 5
Training loss: 2.258528757496238
Validation loss: 2.6094111331439485

Epoch: 6| Step: 6
Training loss: 1.9286517247635326
Validation loss: 2.6031859131516644

Epoch: 6| Step: 7
Training loss: 2.596160687603318
Validation loss: 2.5974681795110297

Epoch: 6| Step: 8
Training loss: 2.2218194066642947
Validation loss: 2.580185699002613

Epoch: 6| Step: 9
Training loss: 2.22762746940687
Validation loss: 2.583634299120774

Epoch: 6| Step: 10
Training loss: 2.630390445460302
Validation loss: 2.585484216291232

Epoch: 6| Step: 11
Training loss: 2.513267786940355
Validation loss: 2.569806963811396

Epoch: 6| Step: 12
Training loss: 2.216408797253559
Validation loss: 2.5709056686580114

Epoch: 6| Step: 13
Training loss: 2.624347605697421
Validation loss: 2.568397840909529

Epoch: 148| Step: 0
Training loss: 1.9621404476390027
Validation loss: 2.5684986488638177

Epoch: 6| Step: 1
Training loss: 2.4049439291653347
Validation loss: 2.5816926506266125

Epoch: 6| Step: 2
Training loss: 2.485668109753042
Validation loss: 2.6000488572464246

Epoch: 6| Step: 3
Training loss: 1.8220499939408694
Validation loss: 2.559435272538813

Epoch: 6| Step: 4
Training loss: 2.6627121352813856
Validation loss: 2.5400785759672155

Epoch: 6| Step: 5
Training loss: 2.643035871582003
Validation loss: 2.540204528484999

Epoch: 6| Step: 6
Training loss: 2.4281513227413094
Validation loss: 2.543471266787202

Epoch: 6| Step: 7
Training loss: 2.5027137332765808
Validation loss: 2.5341344016826537

Epoch: 6| Step: 8
Training loss: 1.9417740225958016
Validation loss: 2.5376779218792516

Epoch: 6| Step: 9
Training loss: 2.1981986951147854
Validation loss: 2.537537153412414

Epoch: 6| Step: 10
Training loss: 2.788334684749746
Validation loss: 2.5436200167578478

Epoch: 6| Step: 11
Training loss: 1.8591334081821416
Validation loss: 2.540504412402818

Epoch: 6| Step: 12
Training loss: 2.439075058899241
Validation loss: 2.5106176078832743

Epoch: 6| Step: 13
Training loss: 2.9501033441577835
Validation loss: 2.477883212920523

Epoch: 149| Step: 0
Training loss: 2.181452320411062
Validation loss: 2.4512430735426505

Epoch: 6| Step: 1
Training loss: 1.3278275549419611
Validation loss: 2.4637760093474297

Epoch: 6| Step: 2
Training loss: 2.371811483183576
Validation loss: 2.4823441370019834

Epoch: 6| Step: 3
Training loss: 2.615327908906636
Validation loss: 2.5016505842729058

Epoch: 6| Step: 4
Training loss: 2.8039340651592104
Validation loss: 2.5089692928678597

Epoch: 6| Step: 5
Training loss: 2.179204853177933
Validation loss: 2.5190475662245753

Epoch: 6| Step: 6
Training loss: 3.111746185817727
Validation loss: 2.5157784800051903

Epoch: 6| Step: 7
Training loss: 2.610107775834352
Validation loss: 2.5316265033308616

Epoch: 6| Step: 8
Training loss: 1.4656680623379632
Validation loss: 2.536417681310632

Epoch: 6| Step: 9
Training loss: 2.505224300553055
Validation loss: 2.5618614363569407

Epoch: 6| Step: 10
Training loss: 2.2467352175041104
Validation loss: 2.5630596229112275

Epoch: 6| Step: 11
Training loss: 2.768411557973505
Validation loss: 2.592562397043492

Epoch: 6| Step: 12
Training loss: 2.125455807438437
Validation loss: 2.568730300425784

Epoch: 6| Step: 13
Training loss: 2.164454125178832
Validation loss: 2.5474682485713487

Epoch: 150| Step: 0
Training loss: 2.531124912514968
Validation loss: 2.523080970089212

Epoch: 6| Step: 1
Training loss: 1.879602442059145
Validation loss: 2.503154447304825

Epoch: 6| Step: 2
Training loss: 2.541990405451018
Validation loss: 2.4882483084566713

Epoch: 6| Step: 3
Training loss: 2.238390535412862
Validation loss: 2.5038555767824144

Epoch: 6| Step: 4
Training loss: 2.4689218968289786
Validation loss: 2.4933621617563815

Epoch: 6| Step: 5
Training loss: 2.160848165280475
Validation loss: 2.491390499312585

Epoch: 6| Step: 6
Training loss: 2.0764247277383734
Validation loss: 2.4915650537738534

Epoch: 6| Step: 7
Training loss: 2.5845435496930613
Validation loss: 2.4836280439209393

Epoch: 6| Step: 8
Training loss: 2.300068613770415
Validation loss: 2.4899490996678986

Epoch: 6| Step: 9
Training loss: 1.5083380065058751
Validation loss: 2.4953880171903835

Epoch: 6| Step: 10
Training loss: 2.578095499505698
Validation loss: 2.5004064055278055

Epoch: 6| Step: 11
Training loss: 2.433709351563112
Validation loss: 2.5197985440629944

Epoch: 6| Step: 12
Training loss: 2.800162147186678
Validation loss: 2.4992184001690525

Epoch: 6| Step: 13
Training loss: 1.6331970638079647
Validation loss: 2.5099776111325425

Epoch: 151| Step: 0
Training loss: 2.321948569609609
Validation loss: 2.5022410653848466

Epoch: 6| Step: 1
Training loss: 1.9595929281670503
Validation loss: 2.502505496921378

Epoch: 6| Step: 2
Training loss: 2.380677213889909
Validation loss: 2.494760979688824

Epoch: 6| Step: 3
Training loss: 1.6069005813847321
Validation loss: 2.4924609849140547

Epoch: 6| Step: 4
Training loss: 1.917209886888097
Validation loss: 2.510246839579851

Epoch: 6| Step: 5
Training loss: 2.5023927682011102
Validation loss: 2.514431804401862

Epoch: 6| Step: 6
Training loss: 2.4040157299384
Validation loss: 2.5095325523745897

Epoch: 6| Step: 7
Training loss: 2.5829777216465613
Validation loss: 2.5247209559443102

Epoch: 6| Step: 8
Training loss: 2.3482521049939247
Validation loss: 2.53049446780308

Epoch: 6| Step: 9
Training loss: 2.5582051455247594
Validation loss: 2.548289892635935

Epoch: 6| Step: 10
Training loss: 2.490334135563035
Validation loss: 2.5354440374276606

Epoch: 6| Step: 11
Training loss: 2.4972465611074313
Validation loss: 2.50609962927365

Epoch: 6| Step: 12
Training loss: 2.346814707706671
Validation loss: 2.4775082727198954

Epoch: 6| Step: 13
Training loss: 1.8406529681893322
Validation loss: 2.4408950573691897

Epoch: 152| Step: 0
Training loss: 2.18509912890125
Validation loss: 2.441449972306749

Epoch: 6| Step: 1
Training loss: 2.209703404300959
Validation loss: 2.4319638829381582

Epoch: 6| Step: 2
Training loss: 2.022981334507772
Validation loss: 2.428828789589871

Epoch: 6| Step: 3
Training loss: 2.4673807717131195
Validation loss: 2.4302187493374205

Epoch: 6| Step: 4
Training loss: 2.4436019423334243
Validation loss: 2.4421837650112237

Epoch: 6| Step: 5
Training loss: 2.306261772808017
Validation loss: 2.4388580619809805

Epoch: 6| Step: 6
Training loss: 2.0860675671205584
Validation loss: 2.449425124729133

Epoch: 6| Step: 7
Training loss: 2.6408434895971875
Validation loss: 2.468272387139693

Epoch: 6| Step: 8
Training loss: 1.735861613677657
Validation loss: 2.4785953107043395

Epoch: 6| Step: 9
Training loss: 2.600485272237289
Validation loss: 2.5079395710641044

Epoch: 6| Step: 10
Training loss: 3.0175405160479967
Validation loss: 2.5107534376113736

Epoch: 6| Step: 11
Training loss: 2.389140048118809
Validation loss: 2.5117989490312937

Epoch: 6| Step: 12
Training loss: 1.8104251298022536
Validation loss: 2.5160207292572196

Epoch: 6| Step: 13
Training loss: 1.1978305896295733
Validation loss: 2.5296297051472165

Epoch: 153| Step: 0
Training loss: 2.3623557556359973
Validation loss: 2.548049462698792

Epoch: 6| Step: 1
Training loss: 1.9455868937298757
Validation loss: 2.581733747908453

Epoch: 6| Step: 2
Training loss: 2.2614750179013248
Validation loss: 2.5901694344733097

Epoch: 6| Step: 3
Training loss: 2.170578384316249
Validation loss: 2.576699743399903

Epoch: 6| Step: 4
Training loss: 1.9476983939154668
Validation loss: 2.5732060446104654

Epoch: 6| Step: 5
Training loss: 2.116652192294074
Validation loss: 2.538386675656793

Epoch: 6| Step: 6
Training loss: 2.5959219054597167
Validation loss: 2.5322312600581456

Epoch: 6| Step: 7
Training loss: 2.184386517190109
Validation loss: 2.5100190706422882

Epoch: 6| Step: 8
Training loss: 2.598273687193952
Validation loss: 2.495284766228018

Epoch: 6| Step: 9
Training loss: 2.0721071921572483
Validation loss: 2.4611597573136277

Epoch: 6| Step: 10
Training loss: 2.4287318469206984
Validation loss: 2.4563483213453527

Epoch: 6| Step: 11
Training loss: 2.481148598085913
Validation loss: 2.4461450250893226

Epoch: 6| Step: 12
Training loss: 2.2845512436955318
Validation loss: 2.4576888855235373

Epoch: 6| Step: 13
Training loss: 2.4313349887928384
Validation loss: 2.4584812723247786

Epoch: 154| Step: 0
Training loss: 2.8585937766893275
Validation loss: 2.4498713145845477

Epoch: 6| Step: 1
Training loss: 2.2604655481728355
Validation loss: 2.4652915823253063

Epoch: 6| Step: 2
Training loss: 2.4799629236341616
Validation loss: 2.46156190866892

Epoch: 6| Step: 3
Training loss: 2.085291616048557
Validation loss: 2.4606021275606293

Epoch: 6| Step: 4
Training loss: 2.451152226950635
Validation loss: 2.4791360903024873

Epoch: 6| Step: 5
Training loss: 2.4586971681830896
Validation loss: 2.4967881007447246

Epoch: 6| Step: 6
Training loss: 2.0245417229405884
Validation loss: 2.556957792404739

Epoch: 6| Step: 7
Training loss: 2.219598097635438
Validation loss: 2.5611568705613657

Epoch: 6| Step: 8
Training loss: 2.0877115656380383
Validation loss: 2.582830452243545

Epoch: 6| Step: 9
Training loss: 1.9330225245253263
Validation loss: 2.5865657528878176

Epoch: 6| Step: 10
Training loss: 2.0349655208431683
Validation loss: 2.580145554768647

Epoch: 6| Step: 11
Training loss: 2.041826618183019
Validation loss: 2.5797311452750313

Epoch: 6| Step: 12
Training loss: 1.8216136816939186
Validation loss: 2.5829241680326045

Epoch: 6| Step: 13
Training loss: 3.020085805722377
Validation loss: 2.5841390499129995

Epoch: 155| Step: 0
Training loss: 1.8241696075420395
Validation loss: 2.6043844726703336

Epoch: 6| Step: 1
Training loss: 2.424192439633248
Validation loss: 2.610250396798037

Epoch: 6| Step: 2
Training loss: 2.706339077441591
Validation loss: 2.6021317326055975

Epoch: 6| Step: 3
Training loss: 1.9237742150203587
Validation loss: 2.585616705985069

Epoch: 6| Step: 4
Training loss: 2.054637371655618
Validation loss: 2.570508815572891

Epoch: 6| Step: 5
Training loss: 2.568870626991125
Validation loss: 2.544176619091856

Epoch: 6| Step: 6
Training loss: 2.092614620446639
Validation loss: 2.5215550634190143

Epoch: 6| Step: 7
Training loss: 2.3610504466721918
Validation loss: 2.5023066308489277

Epoch: 6| Step: 8
Training loss: 2.357107930110425
Validation loss: 2.4741509123081946

Epoch: 6| Step: 9
Training loss: 2.4659724968508083
Validation loss: 2.471080512328684

Epoch: 6| Step: 10
Training loss: 2.2933107085368727
Validation loss: 2.456927939745763

Epoch: 6| Step: 11
Training loss: 1.9095792620545626
Validation loss: 2.4465622407793153

Epoch: 6| Step: 12
Training loss: 1.6768290482920567
Validation loss: 2.446219202690209

Epoch: 6| Step: 13
Training loss: 1.8934276394572347
Validation loss: 2.440270112196394

Epoch: 156| Step: 0
Training loss: 2.576310137435975
Validation loss: 2.4373930189006288

Epoch: 6| Step: 1
Training loss: 2.574441671487501
Validation loss: 2.443456200021847

Epoch: 6| Step: 2
Training loss: 2.143927483954977
Validation loss: 2.457051688872129

Epoch: 6| Step: 3
Training loss: 2.313220247020237
Validation loss: 2.470923235014313

Epoch: 6| Step: 4
Training loss: 2.021306274234623
Validation loss: 2.497745418147866

Epoch: 6| Step: 5
Training loss: 1.9780035382384773
Validation loss: 2.5086883057314213

Epoch: 6| Step: 6
Training loss: 2.178398598955806
Validation loss: 2.562446074439853

Epoch: 6| Step: 7
Training loss: 2.4373749920994547
Validation loss: 2.567984478138428

Epoch: 6| Step: 8
Training loss: 1.6444354176631535
Validation loss: 2.5628503249331858

Epoch: 6| Step: 9
Training loss: 2.2683510001244573
Validation loss: 2.591138995025478

Epoch: 6| Step: 10
Training loss: 2.035446761295025
Validation loss: 2.600091072369592

Epoch: 6| Step: 11
Training loss: 2.030736535538281
Validation loss: 2.6023788976965916

Epoch: 6| Step: 12
Training loss: 2.5934418644623025
Validation loss: 2.5953997630846297

Epoch: 6| Step: 13
Training loss: 1.5952703666540695
Validation loss: 2.585790436840749

Epoch: 157| Step: 0
Training loss: 2.0951198822172006
Validation loss: 2.5687611978980076

Epoch: 6| Step: 1
Training loss: 2.271952035639418
Validation loss: 2.5652957614629024

Epoch: 6| Step: 2
Training loss: 1.9517834137491796
Validation loss: 2.5599354462245976

Epoch: 6| Step: 3
Training loss: 1.9984208071252347
Validation loss: 2.540000363938436

Epoch: 6| Step: 4
Training loss: 1.972872943118416
Validation loss: 2.516817559633592

Epoch: 6| Step: 5
Training loss: 1.8175866670159797
Validation loss: 2.508968914294503

Epoch: 6| Step: 6
Training loss: 2.66206925180695
Validation loss: 2.5107202752668822

Epoch: 6| Step: 7
Training loss: 1.9458987413586284
Validation loss: 2.4760317927517455

Epoch: 6| Step: 8
Training loss: 2.8014715346946844
Validation loss: 2.46990418313933

Epoch: 6| Step: 9
Training loss: 2.253582539443577
Validation loss: 2.4770858769051136

Epoch: 6| Step: 10
Training loss: 2.1647862074661424
Validation loss: 2.494699208276112

Epoch: 6| Step: 11
Training loss: 2.0131366362497447
Validation loss: 2.511801498586886

Epoch: 6| Step: 12
Training loss: 2.3995509840232105
Validation loss: 2.5157340837604623

Epoch: 6| Step: 13
Training loss: 1.9002009235353738
Validation loss: 2.521189180860631

Epoch: 158| Step: 0
Training loss: 2.568083286313334
Validation loss: 2.5467713560970116

Epoch: 6| Step: 1
Training loss: 1.714102200210928
Validation loss: 2.553057145313156

Epoch: 6| Step: 2
Training loss: 2.5258475212656037
Validation loss: 2.569868846218683

Epoch: 6| Step: 3
Training loss: 2.14484518563959
Validation loss: 2.5330353819376907

Epoch: 6| Step: 4
Training loss: 1.951749882127952
Validation loss: 2.5289884232765316

Epoch: 6| Step: 5
Training loss: 2.581876210508153
Validation loss: 2.5269193906557255

Epoch: 6| Step: 6
Training loss: 2.416745173615103
Validation loss: 2.5254720404412296

Epoch: 6| Step: 7
Training loss: 2.1191882150114254
Validation loss: 2.5177851565029403

Epoch: 6| Step: 8
Training loss: 2.085164702059959
Validation loss: 2.5204927378268356

Epoch: 6| Step: 9
Training loss: 1.8650267800052414
Validation loss: 2.474664500842262

Epoch: 6| Step: 10
Training loss: 1.8472148860062296
Validation loss: 2.4959863571606484

Epoch: 6| Step: 11
Training loss: 2.078768408275766
Validation loss: 2.530896303782184

Epoch: 6| Step: 12
Training loss: 1.909211344346718
Validation loss: 2.508749732699153

Epoch: 6| Step: 13
Training loss: 2.2280852882730606
Validation loss: 2.507788649499179

Epoch: 159| Step: 0
Training loss: 2.310586704868556
Validation loss: 2.5188080172140785

Epoch: 6| Step: 1
Training loss: 1.933530740963593
Validation loss: 2.530076229139187

Epoch: 6| Step: 2
Training loss: 1.951242378801593
Validation loss: 2.543985773021098

Epoch: 6| Step: 3
Training loss: 2.2172805863370932
Validation loss: 2.532730066844523

Epoch: 6| Step: 4
Training loss: 2.1978118895615686
Validation loss: 2.519355158158319

Epoch: 6| Step: 5
Training loss: 1.9728093758251215
Validation loss: 2.509143335024938

Epoch: 6| Step: 6
Training loss: 2.065415604635795
Validation loss: 2.524317674848996

Epoch: 6| Step: 7
Training loss: 2.4479108661555835
Validation loss: 2.5341865463111857

Epoch: 6| Step: 8
Training loss: 2.514941199584142
Validation loss: 2.534110100877247

Epoch: 6| Step: 9
Training loss: 2.374173673130925
Validation loss: 2.496898205605272

Epoch: 6| Step: 10
Training loss: 2.206023777934743
Validation loss: 2.4628435323457456

Epoch: 6| Step: 11
Training loss: 1.9534455913644027
Validation loss: 2.4336088214937517

Epoch: 6| Step: 12
Training loss: 1.7776100713715803
Validation loss: 2.4427563912068444

Epoch: 6| Step: 13
Training loss: 2.1049323876184984
Validation loss: 2.447257846382265

Epoch: 160| Step: 0
Training loss: 2.301572291294463
Validation loss: 2.462477483417931

Epoch: 6| Step: 1
Training loss: 2.0985818025079763
Validation loss: 2.4811773965936568

Epoch: 6| Step: 2
Training loss: 1.7190787261102796
Validation loss: 2.476608301305107

Epoch: 6| Step: 3
Training loss: 1.9602314563249215
Validation loss: 2.4772030037162116

Epoch: 6| Step: 4
Training loss: 2.3158505884575287
Validation loss: 2.471119799488694

Epoch: 6| Step: 5
Training loss: 2.103662285610943
Validation loss: 2.484889036031695

Epoch: 6| Step: 6
Training loss: 2.402542428585765
Validation loss: 2.4951110299065355

Epoch: 6| Step: 7
Training loss: 2.045129628818045
Validation loss: 2.519056617653041

Epoch: 6| Step: 8
Training loss: 1.8942690953045782
Validation loss: 2.5286051165415286

Epoch: 6| Step: 9
Training loss: 1.9694709063451386
Validation loss: 2.516073404158133

Epoch: 6| Step: 10
Training loss: 2.4604972324429415
Validation loss: 2.53708261289782

Epoch: 6| Step: 11
Training loss: 1.9150948990497398
Validation loss: 2.5264372877475947

Epoch: 6| Step: 12
Training loss: 2.527294506318462
Validation loss: 2.524149261065652

Epoch: 6| Step: 13
Training loss: 2.0886947182554265
Validation loss: 2.541364495161383

Epoch: 161| Step: 0
Training loss: 1.9692922178525039
Validation loss: 2.538428919444653

Epoch: 6| Step: 1
Training loss: 1.7935954808262458
Validation loss: 2.487335116381473

Epoch: 6| Step: 2
Training loss: 1.5099096389916589
Validation loss: 2.4974164328787967

Epoch: 6| Step: 3
Training loss: 1.5965205028637914
Validation loss: 2.499762546378408

Epoch: 6| Step: 4
Training loss: 2.1144725100285657
Validation loss: 2.516490775322782

Epoch: 6| Step: 5
Training loss: 2.0011629061597525
Validation loss: 2.5048718205443286

Epoch: 6| Step: 6
Training loss: 2.8182392478080605
Validation loss: 2.500581261526601

Epoch: 6| Step: 7
Training loss: 1.7265008423441652
Validation loss: 2.497016598130663

Epoch: 6| Step: 8
Training loss: 2.332386596801327
Validation loss: 2.516869897004264

Epoch: 6| Step: 9
Training loss: 2.004881861148094
Validation loss: 2.5084895772297617

Epoch: 6| Step: 10
Training loss: 2.3234540947717206
Validation loss: 2.5473698685664643

Epoch: 6| Step: 11
Training loss: 2.3500873590018276
Validation loss: 2.5454512818713364

Epoch: 6| Step: 12
Training loss: 2.7975844011026236
Validation loss: 2.517111255965298

Epoch: 6| Step: 13
Training loss: 1.8319277866323747
Validation loss: 2.50509924799602

Epoch: 162| Step: 0
Training loss: 1.8189559924740821
Validation loss: 2.488844464067219

Epoch: 6| Step: 1
Training loss: 1.8672335950197452
Validation loss: 2.4985644094899553

Epoch: 6| Step: 2
Training loss: 2.4041419765674514
Validation loss: 2.5173415229062606

Epoch: 6| Step: 3
Training loss: 2.368482380346272
Validation loss: 2.5148273962266097

Epoch: 6| Step: 4
Training loss: 2.306962471261948
Validation loss: 2.5254701645108772

Epoch: 6| Step: 5
Training loss: 2.062333996189953
Validation loss: 2.5007189609008775

Epoch: 6| Step: 6
Training loss: 1.5433594800465826
Validation loss: 2.5028517363110026

Epoch: 6| Step: 7
Training loss: 2.0820359450067256
Validation loss: 2.473421380536963

Epoch: 6| Step: 8
Training loss: 2.064354727284891
Validation loss: 2.467691125111411

Epoch: 6| Step: 9
Training loss: 2.1932519765836496
Validation loss: 2.453377141117768

Epoch: 6| Step: 10
Training loss: 1.877165116515941
Validation loss: 2.4565976562716063

Epoch: 6| Step: 11
Training loss: 2.671239319968752
Validation loss: 2.4731922922611544

Epoch: 6| Step: 12
Training loss: 1.4346828221814225
Validation loss: 2.453619702846609

Epoch: 6| Step: 13
Training loss: 2.381326180588651
Validation loss: 2.435635543856374

Epoch: 163| Step: 0
Training loss: 1.4492087145352501
Validation loss: 2.414312527402455

Epoch: 6| Step: 1
Training loss: 1.8790042082377558
Validation loss: 2.4319309364919883

Epoch: 6| Step: 2
Training loss: 1.9932623861864114
Validation loss: 2.449018050403947

Epoch: 6| Step: 3
Training loss: 1.8214914327080187
Validation loss: 2.4712339360955853

Epoch: 6| Step: 4
Training loss: 2.153451070470127
Validation loss: 2.475968120034743

Epoch: 6| Step: 5
Training loss: 1.6099933806573548
Validation loss: 2.5045987869926805

Epoch: 6| Step: 6
Training loss: 2.4163832882006955
Validation loss: 2.522095139599827

Epoch: 6| Step: 7
Training loss: 2.212738382029911
Validation loss: 2.5248493265775362

Epoch: 6| Step: 8
Training loss: 1.8885229105227546
Validation loss: 2.5460324313299063

Epoch: 6| Step: 9
Training loss: 2.652148322432614
Validation loss: 2.5401669910531677

Epoch: 6| Step: 10
Training loss: 1.4868517641269923
Validation loss: 2.553757963212447

Epoch: 6| Step: 11
Training loss: 2.4438331687413988
Validation loss: 2.5052930808919127

Epoch: 6| Step: 12
Training loss: 2.3120762204736645
Validation loss: 2.483503578259845

Epoch: 6| Step: 13
Training loss: 2.482591192562406
Validation loss: 2.450034014733804

Epoch: 164| Step: 0
Training loss: 1.8359356169995331
Validation loss: 2.4486941762530687

Epoch: 6| Step: 1
Training loss: 1.9525903198804018
Validation loss: 2.4477134119260597

Epoch: 6| Step: 2
Training loss: 2.212343665165485
Validation loss: 2.4716679291878934

Epoch: 6| Step: 3
Training loss: 1.5088764449311665
Validation loss: 2.4890814060816946

Epoch: 6| Step: 4
Training loss: 2.20150502483861
Validation loss: 2.5311618132771465

Epoch: 6| Step: 5
Training loss: 2.082719356345776
Validation loss: 2.5525976230815255

Epoch: 6| Step: 6
Training loss: 2.174375124210662
Validation loss: 2.5518626412522694

Epoch: 6| Step: 7
Training loss: 1.6577534599469441
Validation loss: 2.5561840837648298

Epoch: 6| Step: 8
Training loss: 2.4675869676903455
Validation loss: 2.57759438700878

Epoch: 6| Step: 9
Training loss: 2.389498675930106
Validation loss: 2.574587659260538

Epoch: 6| Step: 10
Training loss: 1.6688894549330897
Validation loss: 2.561984750973049

Epoch: 6| Step: 11
Training loss: 1.8837084399462816
Validation loss: 2.571463851073049

Epoch: 6| Step: 12
Training loss: 2.166972383302925
Validation loss: 2.5353994041329293

Epoch: 6| Step: 13
Training loss: 2.1688739708198925
Validation loss: 2.5281534399984293

Epoch: 165| Step: 0
Training loss: 1.7552711256739324
Validation loss: 2.45889655436815

Epoch: 6| Step: 1
Training loss: 2.2194659730039263
Validation loss: 2.4195074771940974

Epoch: 6| Step: 2
Training loss: 2.0673083119399998
Validation loss: 2.4050866484240547

Epoch: 6| Step: 3
Training loss: 2.1658227695365495
Validation loss: 2.4275166325756397

Epoch: 6| Step: 4
Training loss: 1.9067387814099857
Validation loss: 2.4234737056371514

Epoch: 6| Step: 5
Training loss: 1.858858373339179
Validation loss: 2.4539484612269815

Epoch: 6| Step: 6
Training loss: 1.8804628265122743
Validation loss: 2.456419714254621

Epoch: 6| Step: 7
Training loss: 2.2424137652603067
Validation loss: 2.4268850236455375

Epoch: 6| Step: 8
Training loss: 2.597653863661968
Validation loss: 2.431557174853848

Epoch: 6| Step: 9
Training loss: 2.3111947990002446
Validation loss: 2.429377397011227

Epoch: 6| Step: 10
Training loss: 1.7458713056976307
Validation loss: 2.4345944280184275

Epoch: 6| Step: 11
Training loss: 1.9913969378667071
Validation loss: 2.431251953100596

Epoch: 6| Step: 12
Training loss: 1.8887431339363807
Validation loss: 2.454198240529744

Epoch: 6| Step: 13
Training loss: 1.7842993484734473
Validation loss: 2.4428082468496717

Epoch: 166| Step: 0
Training loss: 1.7642523231788356
Validation loss: 2.4618399631281016

Epoch: 6| Step: 1
Training loss: 2.253545193371572
Validation loss: 2.4733703009427073

Epoch: 6| Step: 2
Training loss: 1.8969504729438136
Validation loss: 2.511972209839337

Epoch: 6| Step: 3
Training loss: 1.9300462644101752
Validation loss: 2.520459472735844

Epoch: 6| Step: 4
Training loss: 1.9870179965390213
Validation loss: 2.5838573081881284

Epoch: 6| Step: 5
Training loss: 1.7357465115335895
Validation loss: 2.5928125022764954

Epoch: 6| Step: 6
Training loss: 2.0730577225991627
Validation loss: 2.5841989115709403

Epoch: 6| Step: 7
Training loss: 2.2896694381207645
Validation loss: 2.5951075504462797

Epoch: 6| Step: 8
Training loss: 2.053227475191283
Validation loss: 2.5580006137127405

Epoch: 6| Step: 9
Training loss: 1.51928897289301
Validation loss: 2.568400960119487

Epoch: 6| Step: 10
Training loss: 2.4308355139913402
Validation loss: 2.5655795485384116

Epoch: 6| Step: 11
Training loss: 2.0348760078765586
Validation loss: 2.5347751270466325

Epoch: 6| Step: 12
Training loss: 1.9217601214554598
Validation loss: 2.5374480617155606

Epoch: 6| Step: 13
Training loss: 1.8610320841520729
Validation loss: 2.492675459853308

Epoch: 167| Step: 0
Training loss: 2.076879371824436
Validation loss: 2.4829321585193673

Epoch: 6| Step: 1
Training loss: 2.291459530803683
Validation loss: 2.4643672161798014

Epoch: 6| Step: 2
Training loss: 1.8425555481941793
Validation loss: 2.4691778715380837

Epoch: 6| Step: 3
Training loss: 2.347637360507929
Validation loss: 2.455290235468928

Epoch: 6| Step: 4
Training loss: 1.610533954384414
Validation loss: 2.4714274552086017

Epoch: 6| Step: 5
Training loss: 2.0442142810814965
Validation loss: 2.4868718259033082

Epoch: 6| Step: 6
Training loss: 2.0703318469025267
Validation loss: 2.5030705596995984

Epoch: 6| Step: 7
Training loss: 2.25027856162052
Validation loss: 2.5119314796261616

Epoch: 6| Step: 8
Training loss: 1.665765669788923
Validation loss: 2.522787908780584

Epoch: 6| Step: 9
Training loss: 1.228540853899335
Validation loss: 2.522315903723403

Epoch: 6| Step: 10
Training loss: 2.198675437474073
Validation loss: 2.533050553008067

Epoch: 6| Step: 11
Training loss: 1.8327179294913278
Validation loss: 2.5264857617400143

Epoch: 6| Step: 12
Training loss: 2.0463858449465744
Validation loss: 2.5110651736870784

Epoch: 6| Step: 13
Training loss: 1.3609771057041984
Validation loss: 2.50052607856498

Epoch: 168| Step: 0
Training loss: 1.8002911146840874
Validation loss: 2.4499564618378917

Epoch: 6| Step: 1
Training loss: 1.8655821471029121
Validation loss: 2.448301340501423

Epoch: 6| Step: 2
Training loss: 1.851570290335833
Validation loss: 2.4536958637276975

Epoch: 6| Step: 3
Training loss: 2.3606726507337097
Validation loss: 2.425662340396445

Epoch: 6| Step: 4
Training loss: 1.9896577218680627
Validation loss: 2.435108019787459

Epoch: 6| Step: 5
Training loss: 2.235607634176453
Validation loss: 2.416021475913049

Epoch: 6| Step: 6
Training loss: 1.1753674155898015
Validation loss: 2.421729836560995

Epoch: 6| Step: 7
Training loss: 1.7510193853040494
Validation loss: 2.392195935373539

Epoch: 6| Step: 8
Training loss: 2.0465766747578362
Validation loss: 2.410797417845809

Epoch: 6| Step: 9
Training loss: 1.8240085782970352
Validation loss: 2.4417032644431202

Epoch: 6| Step: 10
Training loss: 1.6802504904515998
Validation loss: 2.4257820658733347

Epoch: 6| Step: 11
Training loss: 2.2987458790446063
Validation loss: 2.450307070018428

Epoch: 6| Step: 12
Training loss: 2.1914457429805307
Validation loss: 2.4724277337024554

Epoch: 6| Step: 13
Training loss: 1.5410047175380377
Validation loss: 2.4943153775664313

Epoch: 169| Step: 0
Training loss: 2.3805198771610967
Validation loss: 2.518057954487807

Epoch: 6| Step: 1
Training loss: 1.779064376832745
Validation loss: 2.5181850481192494

Epoch: 6| Step: 2
Training loss: 1.570396307231897
Validation loss: 2.5418057029643677

Epoch: 6| Step: 3
Training loss: 1.8913207862450367
Validation loss: 2.5530372907706678

Epoch: 6| Step: 4
Training loss: 1.8405883319097336
Validation loss: 2.5285819356392265

Epoch: 6| Step: 5
Training loss: 2.2117519428722825
Validation loss: 2.534213635399054

Epoch: 6| Step: 6
Training loss: 1.9919860139570296
Validation loss: 2.5438903053138566

Epoch: 6| Step: 7
Training loss: 1.8758012966751447
Validation loss: 2.515886184543817

Epoch: 6| Step: 8
Training loss: 2.325063035992334
Validation loss: 2.5107834965425964

Epoch: 6| Step: 9
Training loss: 1.8882688863631236
Validation loss: 2.502076140094881

Epoch: 6| Step: 10
Training loss: 1.5737899309808439
Validation loss: 2.4884118909207635

Epoch: 6| Step: 11
Training loss: 1.6079589391514164
Validation loss: 2.4893231648341483

Epoch: 6| Step: 12
Training loss: 1.646261360749109
Validation loss: 2.493617507984663

Epoch: 6| Step: 13
Training loss: 1.4101038788345734
Validation loss: 2.4583144186330554

Epoch: 170| Step: 0
Training loss: 1.810529229367222
Validation loss: 2.475198898452462

Epoch: 6| Step: 1
Training loss: 2.0158409771794696
Validation loss: 2.4659534366345577

Epoch: 6| Step: 2
Training loss: 1.435678738097726
Validation loss: 2.4381724929451885

Epoch: 6| Step: 3
Training loss: 1.981223179006893
Validation loss: 2.4606268928124204

Epoch: 6| Step: 4
Training loss: 1.819306189579998
Validation loss: 2.4532843671848132

Epoch: 6| Step: 5
Training loss: 1.9800811930106066
Validation loss: 2.4701405839526003

Epoch: 6| Step: 6
Training loss: 1.94449215179531
Validation loss: 2.468417090050237

Epoch: 6| Step: 7
Training loss: 1.5866081435900146
Validation loss: 2.4849686189777387

Epoch: 6| Step: 8
Training loss: 1.9954772713900188
Validation loss: 2.4790140899367787

Epoch: 6| Step: 9
Training loss: 2.356572994688871
Validation loss: 2.4837719120862656

Epoch: 6| Step: 10
Training loss: 1.8603413739263324
Validation loss: 2.4504592704870887

Epoch: 6| Step: 11
Training loss: 2.049102270296859
Validation loss: 2.4444411066209013

Epoch: 6| Step: 12
Training loss: 1.4472241106141002
Validation loss: 2.4702329245998524

Epoch: 6| Step: 13
Training loss: 1.826775207404083
Validation loss: 2.460893741602116

Epoch: 171| Step: 0
Training loss: 1.9901760343586683
Validation loss: 2.530893628611935

Epoch: 6| Step: 1
Training loss: 2.259856252740545
Validation loss: 2.5250755648828114

Epoch: 6| Step: 2
Training loss: 2.317552151221804
Validation loss: 2.5300576001721775

Epoch: 6| Step: 3
Training loss: 1.8891531519440778
Validation loss: 2.510569963015712

Epoch: 6| Step: 4
Training loss: 1.8471384754493507
Validation loss: 2.5203885633801235

Epoch: 6| Step: 5
Training loss: 1.5607442528103905
Validation loss: 2.501345901800258

Epoch: 6| Step: 6
Training loss: 1.7800316910655016
Validation loss: 2.5235020321846116

Epoch: 6| Step: 7
Training loss: 1.4906312506522672
Validation loss: 2.527164469416534

Epoch: 6| Step: 8
Training loss: 1.2369811636925354
Validation loss: 2.541925741541593

Epoch: 6| Step: 9
Training loss: 2.0336350743436213
Validation loss: 2.5426405021631253

Epoch: 6| Step: 10
Training loss: 1.9761175325744715
Validation loss: 2.5065686296027128

Epoch: 6| Step: 11
Training loss: 2.1177802012855422
Validation loss: 2.495428783192473

Epoch: 6| Step: 12
Training loss: 1.8533275577171586
Validation loss: 2.504632717196687

Epoch: 6| Step: 13
Training loss: 1.7180759842292916
Validation loss: 2.475010483496754

Epoch: 172| Step: 0
Training loss: 1.4577893286986552
Validation loss: 2.4418698348084975

Epoch: 6| Step: 1
Training loss: 2.5143094621348054
Validation loss: 2.434580382467817

Epoch: 6| Step: 2
Training loss: 1.9033915240694796
Validation loss: 2.4212877305820926

Epoch: 6| Step: 3
Training loss: 1.975360972578142
Validation loss: 2.452404408862343

Epoch: 6| Step: 4
Training loss: 1.731390645067258
Validation loss: 2.4319952646086875

Epoch: 6| Step: 5
Training loss: 1.7256782304124467
Validation loss: 2.462578821281972

Epoch: 6| Step: 6
Training loss: 1.7418992697917621
Validation loss: 2.470122224280412

Epoch: 6| Step: 7
Training loss: 1.4657823327701687
Validation loss: 2.4959927837497844

Epoch: 6| Step: 8
Training loss: 2.2333846665171753
Validation loss: 2.521501005923363

Epoch: 6| Step: 9
Training loss: 1.5147134458264802
Validation loss: 2.525447086799124

Epoch: 6| Step: 10
Training loss: 1.6728659571859517
Validation loss: 2.520379009169919

Epoch: 6| Step: 11
Training loss: 1.5669298319586171
Validation loss: 2.5180184467174973

Epoch: 6| Step: 12
Training loss: 2.1411309305679365
Validation loss: 2.5098836771526396

Epoch: 6| Step: 13
Training loss: 1.6928836985983355
Validation loss: 2.516576840773108

Epoch: 173| Step: 0
Training loss: 1.5457690360106224
Validation loss: 2.505864402304234

Epoch: 6| Step: 1
Training loss: 1.7401251111049383
Validation loss: 2.49442010493575

Epoch: 6| Step: 2
Training loss: 1.4805746317420412
Validation loss: 2.5040029053053137

Epoch: 6| Step: 3
Training loss: 1.972382056187563
Validation loss: 2.4806355066422396

Epoch: 6| Step: 4
Training loss: 2.058954370171837
Validation loss: 2.45983013208209

Epoch: 6| Step: 5
Training loss: 1.4148190829540166
Validation loss: 2.4305509065817006

Epoch: 6| Step: 6
Training loss: 1.8324750350563073
Validation loss: 2.4636685938083516

Epoch: 6| Step: 7
Training loss: 2.1325122216647006
Validation loss: 2.469209036694798

Epoch: 6| Step: 8
Training loss: 1.87716778372223
Validation loss: 2.490500190473166

Epoch: 6| Step: 9
Training loss: 1.8625244907074665
Validation loss: 2.4860376057593743

Epoch: 6| Step: 10
Training loss: 1.9344914982092003
Validation loss: 2.4977155697580975

Epoch: 6| Step: 11
Training loss: 1.8742563680393316
Validation loss: 2.5112765386733464

Epoch: 6| Step: 12
Training loss: 2.0019446693800087
Validation loss: 2.528106243242893

Epoch: 6| Step: 13
Training loss: 1.7828285183132615
Validation loss: 2.535545370957447

Epoch: 174| Step: 0
Training loss: 1.2712044825324218
Validation loss: 2.5244017785117925

Epoch: 6| Step: 1
Training loss: 1.653534660707409
Validation loss: 2.5192442346156083

Epoch: 6| Step: 2
Training loss: 1.546954990977471
Validation loss: 2.518105420006624

Epoch: 6| Step: 3
Training loss: 1.6932816537094655
Validation loss: 2.510475346587428

Epoch: 6| Step: 4
Training loss: 2.0319260865908504
Validation loss: 2.5197061055596994

Epoch: 6| Step: 5
Training loss: 1.629160177440679
Validation loss: 2.521721914064757

Epoch: 6| Step: 6
Training loss: 1.6589771346941797
Validation loss: 2.5364756876155203

Epoch: 6| Step: 7
Training loss: 1.8007885318368906
Validation loss: 2.5487475360970966

Epoch: 6| Step: 8
Training loss: 1.7304192873944648
Validation loss: 2.525161021997344

Epoch: 6| Step: 9
Training loss: 1.8647406598711416
Validation loss: 2.5306917904598096

Epoch: 6| Step: 10
Training loss: 1.6785064093337019
Validation loss: 2.5546828738396457

Epoch: 6| Step: 11
Training loss: 2.1745437582020393
Validation loss: 2.5594365406186412

Epoch: 6| Step: 12
Training loss: 2.191231950162196
Validation loss: 2.5619869563966082

Epoch: 6| Step: 13
Training loss: 1.8939792104061448
Validation loss: 2.5411009596877268

Epoch: 175| Step: 0
Training loss: 1.5115679682959415
Validation loss: 2.5142724486306562

Epoch: 6| Step: 1
Training loss: 1.8855761746820425
Validation loss: 2.5189726286325795

Epoch: 6| Step: 2
Training loss: 1.105565043322961
Validation loss: 2.505563351918312

Epoch: 6| Step: 3
Training loss: 1.835032593128424
Validation loss: 2.5385393682567052

Epoch: 6| Step: 4
Training loss: 1.9225006325749223
Validation loss: 2.5246883456669127

Epoch: 6| Step: 5
Training loss: 2.1191684140963094
Validation loss: 2.5172780823914778

Epoch: 6| Step: 6
Training loss: 1.6300911013180188
Validation loss: 2.5065245315075493

Epoch: 6| Step: 7
Training loss: 2.0744326493774095
Validation loss: 2.4907082736226287

Epoch: 6| Step: 8
Training loss: 2.2232690914925333
Validation loss: 2.493169964750899

Epoch: 6| Step: 9
Training loss: 1.8015716208419785
Validation loss: 2.4817504134777444

Epoch: 6| Step: 10
Training loss: 1.1542282987772576
Validation loss: 2.463999115568526

Epoch: 6| Step: 11
Training loss: 1.433143149925188
Validation loss: 2.482886826992467

Epoch: 6| Step: 12
Training loss: 1.5589986098444175
Validation loss: 2.4919951434715815

Epoch: 6| Step: 13
Training loss: 2.3398740126447084
Validation loss: 2.5082939482406013

Epoch: 176| Step: 0
Training loss: 1.9717824681451477
Validation loss: 2.5228752511310018

Epoch: 6| Step: 1
Training loss: 1.9703959290812818
Validation loss: 2.5295131339878116

Epoch: 6| Step: 2
Training loss: 1.5200599201839733
Validation loss: 2.5136341432810214

Epoch: 6| Step: 3
Training loss: 1.1214851467086067
Validation loss: 2.4952677093742777

Epoch: 6| Step: 4
Training loss: 2.2341620070302035
Validation loss: 2.5127773167988665

Epoch: 6| Step: 5
Training loss: 2.0168293748062327
Validation loss: 2.5182807654848594

Epoch: 6| Step: 6
Training loss: 1.7581520939328288
Validation loss: 2.5038496147383844

Epoch: 6| Step: 7
Training loss: 1.4257442939880909
Validation loss: 2.500733542754598

Epoch: 6| Step: 8
Training loss: 1.7326360696970553
Validation loss: 2.4870767378494434

Epoch: 6| Step: 9
Training loss: 1.9216628539066036
Validation loss: 2.483578375254212

Epoch: 6| Step: 10
Training loss: 1.6192252915796979
Validation loss: 2.5227559045799817

Epoch: 6| Step: 11
Training loss: 1.7492306925684113
Validation loss: 2.4874550719956745

Epoch: 6| Step: 12
Training loss: 1.7339621387558946
Validation loss: 2.5468093478087326

Epoch: 6| Step: 13
Training loss: 1.0400102924791295
Validation loss: 2.545416589489777

Epoch: 177| Step: 0
Training loss: 1.1361559756145643
Validation loss: 2.551256632473213

Epoch: 6| Step: 1
Training loss: 1.865812873006896
Validation loss: 2.5906465993189336

Epoch: 6| Step: 2
Training loss: 1.8342521561361294
Validation loss: 2.5790458295113714

Epoch: 6| Step: 3
Training loss: 1.7160302578141338
Validation loss: 2.5767538044445666

Epoch: 6| Step: 4
Training loss: 2.2642496077764744
Validation loss: 2.5777660946633705

Epoch: 6| Step: 5
Training loss: 1.5129654349484105
Validation loss: 2.5548579616448968

Epoch: 6| Step: 6
Training loss: 1.6816630965624375
Validation loss: 2.5607622899089364

Epoch: 6| Step: 7
Training loss: 1.9637747979495428
Validation loss: 2.5313282129987478

Epoch: 6| Step: 8
Training loss: 1.3029524178881744
Validation loss: 2.507772772551671

Epoch: 6| Step: 9
Training loss: 1.4991070950801118
Validation loss: 2.4949182606749427

Epoch: 6| Step: 10
Training loss: 1.673378028133414
Validation loss: 2.456309515987591

Epoch: 6| Step: 11
Training loss: 1.596418801555443
Validation loss: 2.4893855037204333

Epoch: 6| Step: 12
Training loss: 1.9177350369952415
Validation loss: 2.4766001102149433

Epoch: 6| Step: 13
Training loss: 2.008709658850873
Validation loss: 2.4366934309267902

Epoch: 178| Step: 0
Training loss: 2.0215702351935025
Validation loss: 2.463977656421881

Epoch: 6| Step: 1
Training loss: 1.5135862658502595
Validation loss: 2.456275022633351

Epoch: 6| Step: 2
Training loss: 1.839401548338555
Validation loss: 2.444130089649845

Epoch: 6| Step: 3
Training loss: 1.6815039460643209
Validation loss: 2.4380237530949294

Epoch: 6| Step: 4
Training loss: 2.1283079093942074
Validation loss: 2.464694824420889

Epoch: 6| Step: 5
Training loss: 1.430826036052873
Validation loss: 2.4779659161262844

Epoch: 6| Step: 6
Training loss: 1.7893120870612718
Validation loss: 2.4763115518647454

Epoch: 6| Step: 7
Training loss: 1.4905274429226283
Validation loss: 2.534091350827159

Epoch: 6| Step: 8
Training loss: 1.1233802366982533
Validation loss: 2.5396819338011007

Epoch: 6| Step: 9
Training loss: 1.8580094139263046
Validation loss: 2.573635894226652

Epoch: 6| Step: 10
Training loss: 1.604058381756643
Validation loss: 2.5995852809346105

Epoch: 6| Step: 11
Training loss: 1.8771762933550564
Validation loss: 2.599795245437274

Epoch: 6| Step: 12
Training loss: 1.5666414688329509
Validation loss: 2.5679061970829915

Epoch: 6| Step: 13
Training loss: 1.9782353736493894
Validation loss: 2.5737771789849364

Epoch: 179| Step: 0
Training loss: 1.2563227010917875
Validation loss: 2.5485207526003757

Epoch: 6| Step: 1
Training loss: 1.6953017414648188
Validation loss: 2.5129532156447425

Epoch: 6| Step: 2
Training loss: 1.8520111313067231
Validation loss: 2.5109062291045134

Epoch: 6| Step: 3
Training loss: 2.219004871612331
Validation loss: 2.4989580669865523

Epoch: 6| Step: 4
Training loss: 1.452660270948775
Validation loss: 2.4835529108776155

Epoch: 6| Step: 5
Training loss: 1.7212523537524826
Validation loss: 2.4621153299967173

Epoch: 6| Step: 6
Training loss: 1.8315268271499454
Validation loss: 2.5089233890269327

Epoch: 6| Step: 7
Training loss: 1.4998613929287088
Validation loss: 2.498117853074953

Epoch: 6| Step: 8
Training loss: 1.33519202062235
Validation loss: 2.5092371567494176

Epoch: 6| Step: 9
Training loss: 1.8633412605394535
Validation loss: 2.510438145841049

Epoch: 6| Step: 10
Training loss: 1.1655904483532096
Validation loss: 2.523476782732735

Epoch: 6| Step: 11
Training loss: 1.7336517750612006
Validation loss: 2.5144880718321945

Epoch: 6| Step: 12
Training loss: 1.6551826924794129
Validation loss: 2.5120435261795007

Epoch: 6| Step: 13
Training loss: 2.2554245302617737
Validation loss: 2.517403501484449

Epoch: 180| Step: 0
Training loss: 1.2579995721109751
Validation loss: 2.4955602744632377

Epoch: 6| Step: 1
Training loss: 1.953977231059956
Validation loss: 2.4912660540986993

Epoch: 6| Step: 2
Training loss: 2.0288779860838777
Validation loss: 2.504955368432008

Epoch: 6| Step: 3
Training loss: 1.801638847910302
Validation loss: 2.5326966416087284

Epoch: 6| Step: 4
Training loss: 1.303948015809196
Validation loss: 2.5109900560650016

Epoch: 6| Step: 5
Training loss: 1.3795184108505218
Validation loss: 2.5213927979806523

Epoch: 6| Step: 6
Training loss: 1.7558375135509892
Validation loss: 2.5191799658212815

Epoch: 6| Step: 7
Training loss: 1.799681619461343
Validation loss: 2.5184781630461823

Epoch: 6| Step: 8
Training loss: 1.1537641661198959
Validation loss: 2.51052566817258

Epoch: 6| Step: 9
Training loss: 1.832553813399188
Validation loss: 2.5052980489585392

Epoch: 6| Step: 10
Training loss: 1.7721445352925604
Validation loss: 2.509998714794939

Epoch: 6| Step: 11
Training loss: 1.8528747415342333
Validation loss: 2.500859556814057

Epoch: 6| Step: 12
Training loss: 1.545986961003795
Validation loss: 2.5007542836137735

Epoch: 6| Step: 13
Training loss: 1.5864422375502665
Validation loss: 2.458571563434678

Epoch: 181| Step: 0
Training loss: 1.5750703614276653
Validation loss: 2.47603273080835

Epoch: 6| Step: 1
Training loss: 2.0828199771366283
Validation loss: 2.4460413462305803

Epoch: 6| Step: 2
Training loss: 1.54542458092103
Validation loss: 2.4744641805090497

Epoch: 6| Step: 3
Training loss: 1.7158136427374635
Validation loss: 2.4742015981106724

Epoch: 6| Step: 4
Training loss: 1.0684214683773725
Validation loss: 2.4738357857283075

Epoch: 6| Step: 5
Training loss: 1.6881144076215937
Validation loss: 2.4678357582224337

Epoch: 6| Step: 6
Training loss: 1.2492626399572007
Validation loss: 2.4889527964584706

Epoch: 6| Step: 7
Training loss: 1.5772473755973524
Validation loss: 2.4819682743373463

Epoch: 6| Step: 8
Training loss: 1.7382623221406286
Validation loss: 2.4744939001365234

Epoch: 6| Step: 9
Training loss: 1.7832735847850545
Validation loss: 2.5052032753771796

Epoch: 6| Step: 10
Training loss: 2.119032502822068
Validation loss: 2.472530170292558

Epoch: 6| Step: 11
Training loss: 1.2604923961157355
Validation loss: 2.4978952900389912

Epoch: 6| Step: 12
Training loss: 1.5285248153414135
Validation loss: 2.506692406139406

Epoch: 6| Step: 13
Training loss: 1.808241873800023
Validation loss: 2.547856559269474

Epoch: 182| Step: 0
Training loss: 1.4573010560451947
Validation loss: 2.545766406351607

Epoch: 6| Step: 1
Training loss: 1.9890946858357375
Validation loss: 2.5392649923374835

Epoch: 6| Step: 2
Training loss: 1.6452658998967051
Validation loss: 2.550764587365006

Epoch: 6| Step: 3
Training loss: 1.8976374694724107
Validation loss: 2.5556338081874856

Epoch: 6| Step: 4
Training loss: 1.7191749740944737
Validation loss: 2.527354296296314

Epoch: 6| Step: 5
Training loss: 1.0679665354082744
Validation loss: 2.500934085875317

Epoch: 6| Step: 6
Training loss: 1.5619028857834056
Validation loss: 2.4501349370770975

Epoch: 6| Step: 7
Training loss: 1.4512388231896856
Validation loss: 2.4646981143981463

Epoch: 6| Step: 8
Training loss: 1.7409737639929044
Validation loss: 2.449556815441278

Epoch: 6| Step: 9
Training loss: 1.6207569186021626
Validation loss: 2.4706948821662196

Epoch: 6| Step: 10
Training loss: 1.7983618514045043
Validation loss: 2.482728773488673

Epoch: 6| Step: 11
Training loss: 1.3667915860902602
Validation loss: 2.4753020613409102

Epoch: 6| Step: 12
Training loss: 1.874830874126941
Validation loss: 2.4800833862255707

Epoch: 6| Step: 13
Training loss: 1.4600416078256233
Validation loss: 2.4605514366784162

Epoch: 183| Step: 0
Training loss: 1.2603671744641947
Validation loss: 2.479534081787745

Epoch: 6| Step: 1
Training loss: 1.4214544827221185
Validation loss: 2.514765609016887

Epoch: 6| Step: 2
Training loss: 1.8108951435286673
Validation loss: 2.51174025648458

Epoch: 6| Step: 3
Training loss: 1.3742157259978853
Validation loss: 2.524093643709733

Epoch: 6| Step: 4
Training loss: 1.534250705757992
Validation loss: 2.5358916909301463

Epoch: 6| Step: 5
Training loss: 1.7315900971217388
Validation loss: 2.5332135882058635

Epoch: 6| Step: 6
Training loss: 2.2287262692474465
Validation loss: 2.539249217296487

Epoch: 6| Step: 7
Training loss: 1.2655540729004575
Validation loss: 2.537481948713166

Epoch: 6| Step: 8
Training loss: 1.521772834748141
Validation loss: 2.494019862292196

Epoch: 6| Step: 9
Training loss: 1.1858024510222358
Validation loss: 2.533672294408418

Epoch: 6| Step: 10
Training loss: 1.9225213429391093
Validation loss: 2.51277850027916

Epoch: 6| Step: 11
Training loss: 1.8685073337752973
Validation loss: 2.4699090428232515

Epoch: 6| Step: 12
Training loss: 1.7042410457331645
Validation loss: 2.4573963421665606

Epoch: 6| Step: 13
Training loss: 1.3085880564096055
Validation loss: 2.482136675731232

Epoch: 184| Step: 0
Training loss: 1.8338225824492282
Validation loss: 2.4855163165032828

Epoch: 6| Step: 1
Training loss: 1.6141227393343136
Validation loss: 2.5175209958895377

Epoch: 6| Step: 2
Training loss: 1.5991163972974929
Validation loss: 2.5405335572623042

Epoch: 6| Step: 3
Training loss: 1.7832614183037612
Validation loss: 2.5300916469501624

Epoch: 6| Step: 4
Training loss: 1.4321694431752283
Validation loss: 2.536874178145716

Epoch: 6| Step: 5
Training loss: 1.460985641910255
Validation loss: 2.5042560732261863

Epoch: 6| Step: 6
Training loss: 1.5190697290263824
Validation loss: 2.500266337820299

Epoch: 6| Step: 7
Training loss: 0.8704567192203517
Validation loss: 2.4899535526648835

Epoch: 6| Step: 8
Training loss: 1.96903226736277
Validation loss: 2.5122320260926836

Epoch: 6| Step: 9
Training loss: 1.4235837122237027
Validation loss: 2.504567818588739

Epoch: 6| Step: 10
Training loss: 1.5062890138757417
Validation loss: 2.516397419647943

Epoch: 6| Step: 11
Training loss: 1.5070124267541656
Validation loss: 2.5207298536900407

Epoch: 6| Step: 12
Training loss: 1.7869768270730921
Validation loss: 2.5356806438615473

Epoch: 6| Step: 13
Training loss: 1.7451516154969966
Validation loss: 2.547040370150057

Epoch: 185| Step: 0
Training loss: 1.7101347969420886
Validation loss: 2.527997133561536

Epoch: 6| Step: 1
Training loss: 1.772418027416194
Validation loss: 2.52544444138595

Epoch: 6| Step: 2
Training loss: 1.8557732583188884
Validation loss: 2.4894669469057815

Epoch: 6| Step: 3
Training loss: 1.3355080879249301
Validation loss: 2.5043592716531644

Epoch: 6| Step: 4
Training loss: 1.4154875092758734
Validation loss: 2.479116668017758

Epoch: 6| Step: 5
Training loss: 2.0668051898841675
Validation loss: 2.4959127814474606

Epoch: 6| Step: 6
Training loss: 1.1651542715327217
Validation loss: 2.4825856709921355

Epoch: 6| Step: 7
Training loss: 1.6504577984203217
Validation loss: 2.4797378275744055

Epoch: 6| Step: 8
Training loss: 1.3532797427599021
Validation loss: 2.4762886578912315

Epoch: 6| Step: 9
Training loss: 1.4256886909436075
Validation loss: 2.4545563367269763

Epoch: 6| Step: 10
Training loss: 1.635155999210519
Validation loss: 2.4754856385166315

Epoch: 6| Step: 11
Training loss: 1.6897752752376405
Validation loss: 2.4587700266322012

Epoch: 6| Step: 12
Training loss: 1.2841046793683464
Validation loss: 2.4759883943029597

Epoch: 6| Step: 13
Training loss: 1.660216206982576
Validation loss: 2.479033833605161

Epoch: 186| Step: 0
Training loss: 1.1806564898756842
Validation loss: 2.4747140780358183

Epoch: 6| Step: 1
Training loss: 1.9822667253789117
Validation loss: 2.517980584649868

Epoch: 6| Step: 2
Training loss: 1.1336286564401101
Validation loss: 2.5533262907995784

Epoch: 6| Step: 3
Training loss: 1.369254680241778
Validation loss: 2.5401328865528656

Epoch: 6| Step: 4
Training loss: 1.6440482619596628
Validation loss: 2.5458046295667662

Epoch: 6| Step: 5
Training loss: 1.5289284370695482
Validation loss: 2.539685525363812

Epoch: 6| Step: 6
Training loss: 1.2618902698063414
Validation loss: 2.492321712215356

Epoch: 6| Step: 7
Training loss: 1.8780309974135394
Validation loss: 2.47876990390332

Epoch: 6| Step: 8
Training loss: 2.043958843421529
Validation loss: 2.463526335332526

Epoch: 6| Step: 9
Training loss: 1.6567310138591342
Validation loss: 2.4378681194119447

Epoch: 6| Step: 10
Training loss: 1.348488813111293
Validation loss: 2.4452610539238955

Epoch: 6| Step: 11
Training loss: 1.5218572783956004
Validation loss: 2.45029183914594

Epoch: 6| Step: 12
Training loss: 1.3244094036218934
Validation loss: 2.4308309526970495

Epoch: 6| Step: 13
Training loss: 1.9327459769492663
Validation loss: 2.470955099227016

Epoch: 187| Step: 0
Training loss: 1.3650236608389865
Validation loss: 2.4942482525105314

Epoch: 6| Step: 1
Training loss: 1.3154481293221694
Validation loss: 2.474067860862818

Epoch: 6| Step: 2
Training loss: 1.6780660210444305
Validation loss: 2.5032425730161934

Epoch: 6| Step: 3
Training loss: 1.8992518809295293
Validation loss: 2.52596690645878

Epoch: 6| Step: 4
Training loss: 1.8034398774187714
Validation loss: 2.532972259593443

Epoch: 6| Step: 5
Training loss: 1.6799308423158346
Validation loss: 2.531050263625152

Epoch: 6| Step: 6
Training loss: 1.4718069364518793
Validation loss: 2.5443265097297747

Epoch: 6| Step: 7
Training loss: 1.2935457814788536
Validation loss: 2.5682425932931983

Epoch: 6| Step: 8
Training loss: 1.1903860758552869
Validation loss: 2.5485339556857562

Epoch: 6| Step: 9
Training loss: 1.6271338024770212
Validation loss: 2.5628525996334135

Epoch: 6| Step: 10
Training loss: 1.2609006041998592
Validation loss: 2.547246464381772

Epoch: 6| Step: 11
Training loss: 1.4091606112409651
Validation loss: 2.5285388992398885

Epoch: 6| Step: 12
Training loss: 1.8430709881660645
Validation loss: 2.5130750853131563

Epoch: 6| Step: 13
Training loss: 1.5138296131269053
Validation loss: 2.5107078099186397

Epoch: 188| Step: 0
Training loss: 1.0865968308114524
Validation loss: 2.4986921652986043

Epoch: 6| Step: 1
Training loss: 1.2960858069435723
Validation loss: 2.485346902177724

Epoch: 6| Step: 2
Training loss: 1.9586272594018426
Validation loss: 2.525404342633018

Epoch: 6| Step: 3
Training loss: 1.3198678436013032
Validation loss: 2.5409483685565224

Epoch: 6| Step: 4
Training loss: 1.7447282542382023
Validation loss: 2.553041934975121

Epoch: 6| Step: 5
Training loss: 1.4010475565090486
Validation loss: 2.5683538282036547

Epoch: 6| Step: 6
Training loss: 1.3655613410829908
Validation loss: 2.5652838431298584

Epoch: 6| Step: 7
Training loss: 1.6690882336450954
Validation loss: 2.544650027153726

Epoch: 6| Step: 8
Training loss: 1.4828682731212801
Validation loss: 2.532439148651881

Epoch: 6| Step: 9
Training loss: 1.5061317524061695
Validation loss: 2.495819176833645

Epoch: 6| Step: 10
Training loss: 1.8703237713288516
Validation loss: 2.4851797643298625

Epoch: 6| Step: 11
Training loss: 1.4730943589711893
Validation loss: 2.4656117312206107

Epoch: 6| Step: 12
Training loss: 1.577918086320339
Validation loss: 2.4514670432514114

Epoch: 6| Step: 13
Training loss: 1.2235110283944248
Validation loss: 2.4381441254431917

Epoch: 189| Step: 0
Training loss: 1.3553643529963333
Validation loss: 2.4455636770977067

Epoch: 6| Step: 1
Training loss: 1.1380961878406433
Validation loss: 2.477653207597768

Epoch: 6| Step: 2
Training loss: 1.2856338680185877
Validation loss: 2.4613040169987666

Epoch: 6| Step: 3
Training loss: 1.2682991034658804
Validation loss: 2.4569274639400933

Epoch: 6| Step: 4
Training loss: 1.6020316576550246
Validation loss: 2.458332914981907

Epoch: 6| Step: 5
Training loss: 1.2185148354598887
Validation loss: 2.480032006066961

Epoch: 6| Step: 6
Training loss: 1.4723467514264965
Validation loss: 2.500048745613273

Epoch: 6| Step: 7
Training loss: 1.3404010470050125
Validation loss: 2.5070184286106554

Epoch: 6| Step: 8
Training loss: 1.540074514345039
Validation loss: 2.493535038080116

Epoch: 6| Step: 9
Training loss: 1.6430265016513836
Validation loss: 2.496519284684569

Epoch: 6| Step: 10
Training loss: 2.1442948786088687
Validation loss: 2.5218720810847346

Epoch: 6| Step: 11
Training loss: 1.7112876498954857
Validation loss: 2.545473179141714

Epoch: 6| Step: 12
Training loss: 1.716186484365275
Validation loss: 2.5450180564775082

Epoch: 6| Step: 13
Training loss: 1.1074846845304098
Validation loss: 2.5319569328612928

Epoch: 190| Step: 0
Training loss: 1.9773393393549867
Validation loss: 2.55066442131783

Epoch: 6| Step: 1
Training loss: 1.3486914155838632
Validation loss: 2.560348621084566

Epoch: 6| Step: 2
Training loss: 1.5731289785559883
Validation loss: 2.509225434972689

Epoch: 6| Step: 3
Training loss: 1.1601057972839044
Validation loss: 2.5128732972806893

Epoch: 6| Step: 4
Training loss: 0.7850301840622202
Validation loss: 2.47146064169927

Epoch: 6| Step: 5
Training loss: 1.5931943785091047
Validation loss: 2.4518299999396906

Epoch: 6| Step: 6
Training loss: 2.0688550893592867
Validation loss: 2.445978903078672

Epoch: 6| Step: 7
Training loss: 1.4798959716115156
Validation loss: 2.461488078859566

Epoch: 6| Step: 8
Training loss: 1.1257162992654433
Validation loss: 2.4629778082843594

Epoch: 6| Step: 9
Training loss: 1.2259658042407726
Validation loss: 2.45345386489873

Epoch: 6| Step: 10
Training loss: 1.764651815203256
Validation loss: 2.4694551753874996

Epoch: 6| Step: 11
Training loss: 1.5817452631409623
Validation loss: 2.4697865700599198

Epoch: 6| Step: 12
Training loss: 1.4240539957696239
Validation loss: 2.484004836116738

Epoch: 6| Step: 13
Training loss: 1.2549028090728027
Validation loss: 2.4894782931613277

Epoch: 191| Step: 0
Training loss: 1.2828824877958567
Validation loss: 2.5338716672766335

Epoch: 6| Step: 1
Training loss: 1.359240645861437
Validation loss: 2.5258251635716507

Epoch: 6| Step: 2
Training loss: 1.2515860508906764
Validation loss: 2.52158382237422

Epoch: 6| Step: 3
Training loss: 1.5223167796517427
Validation loss: 2.5349974971962035

Epoch: 6| Step: 4
Training loss: 1.5541788160379324
Validation loss: 2.5777046803159975

Epoch: 6| Step: 5
Training loss: 1.7285403147512814
Validation loss: 2.544652794149227

Epoch: 6| Step: 6
Training loss: 1.088486568145516
Validation loss: 2.528308680717803

Epoch: 6| Step: 7
Training loss: 2.132708983651486
Validation loss: 2.495475037482325

Epoch: 6| Step: 8
Training loss: 1.2532205102914495
Validation loss: 2.473728465015683

Epoch: 6| Step: 9
Training loss: 1.6464243523821753
Validation loss: 2.459753817718856

Epoch: 6| Step: 10
Training loss: 1.1578849368273874
Validation loss: 2.4806437391807807

Epoch: 6| Step: 11
Training loss: 1.7127656967207754
Validation loss: 2.4744184130765308

Epoch: 6| Step: 12
Training loss: 1.2152281027435519
Validation loss: 2.468330133678975

Epoch: 6| Step: 13
Training loss: 1.1942398144896733
Validation loss: 2.469978699663916

Epoch: 192| Step: 0
Training loss: 1.3315458783802323
Validation loss: 2.4621523081385326

Epoch: 6| Step: 1
Training loss: 1.1363212178722915
Validation loss: 2.4589311318877787

Epoch: 6| Step: 2
Training loss: 1.331409656102614
Validation loss: 2.514250719091481

Epoch: 6| Step: 3
Training loss: 1.5095851143807077
Validation loss: 2.5192324963080566

Epoch: 6| Step: 4
Training loss: 1.566234094001639
Validation loss: 2.495671615840944

Epoch: 6| Step: 5
Training loss: 1.737271888084494
Validation loss: 2.510304819491097

Epoch: 6| Step: 6
Training loss: 1.5048557999431162
Validation loss: 2.5067085762890624

Epoch: 6| Step: 7
Training loss: 1.5252961387139734
Validation loss: 2.5100637058517226

Epoch: 6| Step: 8
Training loss: 1.695802116887791
Validation loss: 2.4859891376404732

Epoch: 6| Step: 9
Training loss: 0.864211121068376
Validation loss: 2.484836799359035

Epoch: 6| Step: 10
Training loss: 1.3349887981730628
Validation loss: 2.467477481145539

Epoch: 6| Step: 11
Training loss: 1.1362507174482273
Validation loss: 2.4495671817273768

Epoch: 6| Step: 12
Training loss: 1.8996290070580035
Validation loss: 2.442398678917736

Epoch: 6| Step: 13
Training loss: 1.4475196275714501
Validation loss: 2.453046140754636

Epoch: 193| Step: 0
Training loss: 1.6982398008447146
Validation loss: 2.415002871426969

Epoch: 6| Step: 1
Training loss: 0.9120996380762069
Validation loss: 2.4407546488482756

Epoch: 6| Step: 2
Training loss: 1.3411870956246077
Validation loss: 2.472443455009576

Epoch: 6| Step: 3
Training loss: 1.101336408639298
Validation loss: 2.450938484360822

Epoch: 6| Step: 4
Training loss: 1.4657101116397182
Validation loss: 2.4635020852115077

Epoch: 6| Step: 5
Training loss: 1.7772527985829143
Validation loss: 2.4540170396183694

Epoch: 6| Step: 6
Training loss: 1.1658210528156157
Validation loss: 2.461783325453482

Epoch: 6| Step: 7
Training loss: 1.8702427595325
Validation loss: 2.448122949926057

Epoch: 6| Step: 8
Training loss: 1.4615070232492753
Validation loss: 2.453093826976858

Epoch: 6| Step: 9
Training loss: 1.1605639528027858
Validation loss: 2.5097737170418113

Epoch: 6| Step: 10
Training loss: 1.7687415914706341
Validation loss: 2.5147025816444963

Epoch: 6| Step: 11
Training loss: 1.1398516606977356
Validation loss: 2.508106188808245

Epoch: 6| Step: 12
Training loss: 1.4989508297511285
Validation loss: 2.533619491612679

Epoch: 6| Step: 13
Training loss: 1.2655191730477178
Validation loss: 2.5133618188440994

Epoch: 194| Step: 0
Training loss: 1.6676978576953823
Validation loss: 2.5471945961661144

Epoch: 6| Step: 1
Training loss: 1.0899234865614318
Validation loss: 2.5096583565040897

Epoch: 6| Step: 2
Training loss: 1.387570315804529
Validation loss: 2.5129127165915164

Epoch: 6| Step: 3
Training loss: 1.365083088494377
Validation loss: 2.55786871113315

Epoch: 6| Step: 4
Training loss: 1.526921128440106
Validation loss: 2.5408935729432325

Epoch: 6| Step: 5
Training loss: 0.9028794981226387
Validation loss: 2.5421532495152577

Epoch: 6| Step: 6
Training loss: 1.1211879571018173
Validation loss: 2.5684145548399337

Epoch: 6| Step: 7
Training loss: 1.0346302927528677
Validation loss: 2.539019156086824

Epoch: 6| Step: 8
Training loss: 2.007274867411303
Validation loss: 2.526088417228691

Epoch: 6| Step: 9
Training loss: 1.165848098554131
Validation loss: 2.5255308828370766

Epoch: 6| Step: 10
Training loss: 1.61945880115064
Validation loss: 2.5034162877612203

Epoch: 6| Step: 11
Training loss: 1.3586967793335594
Validation loss: 2.503474729492324

Epoch: 6| Step: 12
Training loss: 1.7319723447041018
Validation loss: 2.4680516044461704

Epoch: 6| Step: 13
Training loss: 1.4560430617095397
Validation loss: 2.4575512349173856

Epoch: 195| Step: 0
Training loss: 0.9933572916900834
Validation loss: 2.4483572241203895

Epoch: 6| Step: 1
Training loss: 1.337526413843892
Validation loss: 2.4559192136124848

Epoch: 6| Step: 2
Training loss: 1.1718215930212976
Validation loss: 2.4549364767052997

Epoch: 6| Step: 3
Training loss: 1.7008141755827653
Validation loss: 2.4621703742692618

Epoch: 6| Step: 4
Training loss: 1.3930153180530953
Validation loss: 2.469485406882576

Epoch: 6| Step: 5
Training loss: 1.0266109507375198
Validation loss: 2.486865641193281

Epoch: 6| Step: 6
Training loss: 1.627828776819554
Validation loss: 2.4898186027280156

Epoch: 6| Step: 7
Training loss: 1.8824618950947625
Validation loss: 2.5038100158802785

Epoch: 6| Step: 8
Training loss: 1.1963309642693534
Validation loss: 2.5180774500535876

Epoch: 6| Step: 9
Training loss: 1.1955107480869855
Validation loss: 2.5613084649504327

Epoch: 6| Step: 10
Training loss: 1.32426776626477
Validation loss: 2.5469654982408994

Epoch: 6| Step: 11
Training loss: 1.561788015275115
Validation loss: 2.541997208897855

Epoch: 6| Step: 12
Training loss: 1.458218660841555
Validation loss: 2.5424654431856806

Epoch: 6| Step: 13
Training loss: 1.765314463085745
Validation loss: 2.5288808428767684

Epoch: 196| Step: 0
Training loss: 1.1519595782751486
Validation loss: 2.5434861699944364

Epoch: 6| Step: 1
Training loss: 1.6893486211130657
Validation loss: 2.5110846326806953

Epoch: 6| Step: 2
Training loss: 1.491510287493306
Validation loss: 2.5422300117556893

Epoch: 6| Step: 3
Training loss: 1.0534962461030812
Validation loss: 2.521887443330732

Epoch: 6| Step: 4
Training loss: 1.6192344205812714
Validation loss: 2.548793148670974

Epoch: 6| Step: 5
Training loss: 1.5393430192779503
Validation loss: 2.517289567062043

Epoch: 6| Step: 6
Training loss: 1.8839499175993786
Validation loss: 2.524599628146263

Epoch: 6| Step: 7
Training loss: 1.3556409391149424
Validation loss: 2.5137497486786597

Epoch: 6| Step: 8
Training loss: 1.319588547360946
Validation loss: 2.5308133965008435

Epoch: 6| Step: 9
Training loss: 1.139919480859913
Validation loss: 2.5344453992468674

Epoch: 6| Step: 10
Training loss: 0.9928255807833152
Validation loss: 2.5317253270126687

Epoch: 6| Step: 11
Training loss: 1.4703002215692653
Validation loss: 2.5228977579208767

Epoch: 6| Step: 12
Training loss: 1.2619213024333793
Validation loss: 2.527744988469916

Epoch: 6| Step: 13
Training loss: 1.0911771759168827
Validation loss: 2.503050578535029

Epoch: 197| Step: 0
Training loss: 0.9256688947141394
Validation loss: 2.4744686240750142

Epoch: 6| Step: 1
Training loss: 1.3956745066832925
Validation loss: 2.4485677128703163

Epoch: 6| Step: 2
Training loss: 1.5992483399993644
Validation loss: 2.4379056346389776

Epoch: 6| Step: 3
Training loss: 1.2286685429967696
Validation loss: 2.438462134020878

Epoch: 6| Step: 4
Training loss: 1.3126091684626007
Validation loss: 2.4494996404774136

Epoch: 6| Step: 5
Training loss: 1.277543731806891
Validation loss: 2.466718478297507

Epoch: 6| Step: 6
Training loss: 1.6740209052262889
Validation loss: 2.4383794398627305

Epoch: 6| Step: 7
Training loss: 1.6132471113310625
Validation loss: 2.4581481240904806

Epoch: 6| Step: 8
Training loss: 1.4965005426173272
Validation loss: 2.469725688481868

Epoch: 6| Step: 9
Training loss: 0.8504105572167205
Validation loss: 2.488063891431374

Epoch: 6| Step: 10
Training loss: 1.3256048189647704
Validation loss: 2.5360948721195773

Epoch: 6| Step: 11
Training loss: 1.716634245754613
Validation loss: 2.5220516311473142

Epoch: 6| Step: 12
Training loss: 1.420781480098426
Validation loss: 2.5356359864224145

Epoch: 6| Step: 13
Training loss: 0.833900965644743
Validation loss: 2.521237866587751

Epoch: 198| Step: 0
Training loss: 1.440674469402554
Validation loss: 2.51474251768367

Epoch: 6| Step: 1
Training loss: 1.675034576742364
Validation loss: 2.5145611896745126

Epoch: 6| Step: 2
Training loss: 1.1188307194919096
Validation loss: 2.4892952030978788

Epoch: 6| Step: 3
Training loss: 1.1475916751485165
Validation loss: 2.5041336300088104

Epoch: 6| Step: 4
Training loss: 1.773407251041242
Validation loss: 2.507708569612074

Epoch: 6| Step: 5
Training loss: 1.0413711255754363
Validation loss: 2.4785143175873756

Epoch: 6| Step: 6
Training loss: 1.1821516965223617
Validation loss: 2.494186006896452

Epoch: 6| Step: 7
Training loss: 1.6658792384000627
Validation loss: 2.442829658980859

Epoch: 6| Step: 8
Training loss: 1.3603331159996401
Validation loss: 2.4901828532284838

Epoch: 6| Step: 9
Training loss: 1.1406426624341508
Validation loss: 2.4871300499778464

Epoch: 6| Step: 10
Training loss: 1.7099911933806002
Validation loss: 2.456556255268046

Epoch: 6| Step: 11
Training loss: 1.1076628138643252
Validation loss: 2.4885101236281124

Epoch: 6| Step: 12
Training loss: 1.434786349883498
Validation loss: 2.477363909900264

Epoch: 6| Step: 13
Training loss: 0.6145685377333567
Validation loss: 2.4806776952715013

Epoch: 199| Step: 0
Training loss: 1.4719322306851415
Validation loss: 2.4947939945155024

Epoch: 6| Step: 1
Training loss: 1.6124465667388077
Validation loss: 2.48962143195962

Epoch: 6| Step: 2
Training loss: 0.694444800747674
Validation loss: 2.457336270164355

Epoch: 6| Step: 3
Training loss: 1.4590869954288168
Validation loss: 2.4817327037146537

Epoch: 6| Step: 4
Training loss: 1.1634026007447626
Validation loss: 2.4943089507666407

Epoch: 6| Step: 5
Training loss: 1.0088956468227914
Validation loss: 2.5027935381591875

Epoch: 6| Step: 6
Training loss: 0.8055927776820754
Validation loss: 2.4851303495002406

Epoch: 6| Step: 7
Training loss: 1.6196987538403982
Validation loss: 2.476508754898706

Epoch: 6| Step: 8
Training loss: 1.7518018574302068
Validation loss: 2.4919839228673055

Epoch: 6| Step: 9
Training loss: 1.4799963365973419
Validation loss: 2.48532973792293

Epoch: 6| Step: 10
Training loss: 1.263413557627286
Validation loss: 2.5058605637936497

Epoch: 6| Step: 11
Training loss: 1.519212076356286
Validation loss: 2.4970607635229354

Epoch: 6| Step: 12
Training loss: 1.4514858886737139
Validation loss: 2.54376228988463

Epoch: 6| Step: 13
Training loss: 0.6682725851136272
Validation loss: 2.5443048061258544

Epoch: 200| Step: 0
Training loss: 1.215957866685387
Validation loss: 2.578532295458942

Epoch: 6| Step: 1
Training loss: 1.077547720452036
Validation loss: 2.5676065341690166

Epoch: 6| Step: 2
Training loss: 0.9205427726907367
Validation loss: 2.555307667832268

Epoch: 6| Step: 3
Training loss: 1.4048964025783321
Validation loss: 2.545234050382915

Epoch: 6| Step: 4
Training loss: 1.0367814459740314
Validation loss: 2.5327558232679053

Epoch: 6| Step: 5
Training loss: 1.772302541669902
Validation loss: 2.518091499717577

Epoch: 6| Step: 6
Training loss: 1.181079321343041
Validation loss: 2.51286128181226

Epoch: 6| Step: 7
Training loss: 1.287929244846484
Validation loss: 2.505080094550663

Epoch: 6| Step: 8
Training loss: 1.2240329097456162
Validation loss: 2.520574242309714

Epoch: 6| Step: 9
Training loss: 1.4112815699327892
Validation loss: 2.502032903424139

Epoch: 6| Step: 10
Training loss: 1.78966228975578
Validation loss: 2.474794908579635

Epoch: 6| Step: 11
Training loss: 1.5013847317296452
Validation loss: 2.495871627897035

Epoch: 6| Step: 12
Training loss: 1.4832391508970029
Validation loss: 2.423819890398765

Epoch: 6| Step: 13
Training loss: 0.7617234058726899
Validation loss: 2.5008590391365844

Epoch: 201| Step: 0
Training loss: 1.2761544106429545
Validation loss: 2.4949542594246754

Epoch: 6| Step: 1
Training loss: 1.7360333599058322
Validation loss: 2.490883538703375

Epoch: 6| Step: 2
Training loss: 1.2908447891295076
Validation loss: 2.48399634225304

Epoch: 6| Step: 3
Training loss: 0.7130849495021273
Validation loss: 2.509222961469531

Epoch: 6| Step: 4
Training loss: 1.3110765276584555
Validation loss: 2.5005558852047174

Epoch: 6| Step: 5
Training loss: 1.7787321264316607
Validation loss: 2.5198160646310583

Epoch: 6| Step: 6
Training loss: 1.410536653982912
Validation loss: 2.4911213663097755

Epoch: 6| Step: 7
Training loss: 0.7026959275674458
Validation loss: 2.492309725730619

Epoch: 6| Step: 8
Training loss: 1.3874830262116769
Validation loss: 2.5173634976743577

Epoch: 6| Step: 9
Training loss: 1.8216191133375106
Validation loss: 2.532947886911538

Epoch: 6| Step: 10
Training loss: 1.21980826575335
Validation loss: 2.5003376343087167

Epoch: 6| Step: 11
Training loss: 1.3370224412077576
Validation loss: 2.5087500453943474

Epoch: 6| Step: 12
Training loss: 1.0706051614307344
Validation loss: 2.5109568233348716

Epoch: 6| Step: 13
Training loss: 0.5496946397483594
Validation loss: 2.4908726372940517

Epoch: 202| Step: 0
Training loss: 0.5152818231375289
Validation loss: 2.4945764110725945

Epoch: 6| Step: 1
Training loss: 1.6081373029372419
Validation loss: 2.5055965201031647

Epoch: 6| Step: 2
Training loss: 1.5122528315583994
Validation loss: 2.483825583629969

Epoch: 6| Step: 3
Training loss: 1.4773538880628232
Validation loss: 2.472014922887782

Epoch: 6| Step: 4
Training loss: 1.4697186948242489
Validation loss: 2.5119750174227247

Epoch: 6| Step: 5
Training loss: 1.1515214475356164
Validation loss: 2.4897782669093202

Epoch: 6| Step: 6
Training loss: 1.2715365022676781
Validation loss: 2.4877835871701635

Epoch: 6| Step: 7
Training loss: 1.1646853835012716
Validation loss: 2.4571938772194253

Epoch: 6| Step: 8
Training loss: 1.5759357336950832
Validation loss: 2.460039320287258

Epoch: 6| Step: 9
Training loss: 1.2911228706725657
Validation loss: 2.4850511585929294

Epoch: 6| Step: 10
Training loss: 1.2339786907377883
Validation loss: 2.4855212632454027

Epoch: 6| Step: 11
Training loss: 1.4791924201263598
Validation loss: 2.461031326612217

Epoch: 6| Step: 12
Training loss: 1.0845936755345393
Validation loss: 2.4981845745056965

Epoch: 6| Step: 13
Training loss: 0.9168915292176963
Validation loss: 2.4956212582304396

Epoch: 203| Step: 0
Training loss: 1.7683643931694109
Validation loss: 2.5138079007130556

Epoch: 6| Step: 1
Training loss: 1.4310056519466723
Validation loss: 2.5406361847289123

Epoch: 6| Step: 2
Training loss: 1.6433886547848806
Validation loss: 2.5496109837645493

Epoch: 6| Step: 3
Training loss: 1.4568026365869031
Validation loss: 2.557709550850129

Epoch: 6| Step: 4
Training loss: 0.9361052628651103
Validation loss: 2.517369710822451

Epoch: 6| Step: 5
Training loss: 1.3150701335871984
Validation loss: 2.5520547275476124

Epoch: 6| Step: 6
Training loss: 1.5153207375209499
Validation loss: 2.523746760179456

Epoch: 6| Step: 7
Training loss: 1.2503810301832357
Validation loss: 2.500292890065707

Epoch: 6| Step: 8
Training loss: 0.9959905234311155
Validation loss: 2.479536057091702

Epoch: 6| Step: 9
Training loss: 0.9694656067050152
Validation loss: 2.5307185968451074

Epoch: 6| Step: 10
Training loss: 1.3050457582453563
Validation loss: 2.5148845936616544

Epoch: 6| Step: 11
Training loss: 1.144291094168107
Validation loss: 2.559162424442721

Epoch: 6| Step: 12
Training loss: 1.2353110808121404
Validation loss: 2.541306650884838

Epoch: 6| Step: 13
Training loss: 0.5903539408995111
Validation loss: 2.5398244497334432

Epoch: 204| Step: 0
Training loss: 1.1749570879303564
Validation loss: 2.527674235827479

Epoch: 6| Step: 1
Training loss: 1.3053893982325988
Validation loss: 2.5419691690190316

Epoch: 6| Step: 2
Training loss: 1.233269884865935
Validation loss: 2.5360621220176367

Epoch: 6| Step: 3
Training loss: 1.3120079026274982
Validation loss: 2.5118545967295662

Epoch: 6| Step: 4
Training loss: 1.266769598032897
Validation loss: 2.506086562455138

Epoch: 6| Step: 5
Training loss: 1.9585373007967095
Validation loss: 2.4880983273801682

Epoch: 6| Step: 6
Training loss: 0.8848152062542495
Validation loss: 2.478302722798169

Epoch: 6| Step: 7
Training loss: 1.0045434732860892
Validation loss: 2.4421521258568

Epoch: 6| Step: 8
Training loss: 1.423349224079296
Validation loss: 2.443672334370368

Epoch: 6| Step: 9
Training loss: 1.0546845612661604
Validation loss: 2.4727805784393406

Epoch: 6| Step: 10
Training loss: 1.1619558024511842
Validation loss: 2.48940885549158

Epoch: 6| Step: 11
Training loss: 1.3318765500085155
Validation loss: 2.496978841634684

Epoch: 6| Step: 12
Training loss: 1.367946653770404
Validation loss: 2.5227887857554085

Epoch: 6| Step: 13
Training loss: 1.2883255672755383
Validation loss: 2.554030242372251

Epoch: 205| Step: 0
Training loss: 1.1033322342255372
Validation loss: 2.5131196346219005

Epoch: 6| Step: 1
Training loss: 1.2632647983326701
Validation loss: 2.4880923677623223

Epoch: 6| Step: 2
Training loss: 1.09873008466949
Validation loss: 2.4643178854409014

Epoch: 6| Step: 3
Training loss: 0.8158782638851553
Validation loss: 2.491228839208598

Epoch: 6| Step: 4
Training loss: 1.3629156021274167
Validation loss: 2.457675484648744

Epoch: 6| Step: 5
Training loss: 0.8250747863511266
Validation loss: 2.4343122594452526

Epoch: 6| Step: 6
Training loss: 1.3893818388447552
Validation loss: 2.4724237209270057

Epoch: 6| Step: 7
Training loss: 1.28221647515727
Validation loss: 2.4348466923595744

Epoch: 6| Step: 8
Training loss: 1.9040102072890943
Validation loss: 2.452415554966982

Epoch: 6| Step: 9
Training loss: 0.8906336332203899
Validation loss: 2.4480046878053736

Epoch: 6| Step: 10
Training loss: 1.2790126339166887
Validation loss: 2.4946938470976896

Epoch: 6| Step: 11
Training loss: 1.5766801924390805
Validation loss: 2.494350707710938

Epoch: 6| Step: 12
Training loss: 1.296598703757454
Validation loss: 2.527952596454317

Epoch: 6| Step: 13
Training loss: 1.405036317756405
Validation loss: 2.5416471637587468

Epoch: 206| Step: 0
Training loss: 0.9592983873822788
Validation loss: 2.532734486125281

Epoch: 6| Step: 1
Training loss: 1.4837293324883019
Validation loss: 2.5501014469322865

Epoch: 6| Step: 2
Training loss: 1.3958454511125948
Validation loss: 2.541397919375182

Epoch: 6| Step: 3
Training loss: 1.215148298844052
Validation loss: 2.5242725487757234

Epoch: 6| Step: 4
Training loss: 0.8769584264786162
Validation loss: 2.530363230634683

Epoch: 6| Step: 5
Training loss: 1.3352179122980388
Validation loss: 2.511659286995208

Epoch: 6| Step: 6
Training loss: 0.7556103830998346
Validation loss: 2.4768920525968245

Epoch: 6| Step: 7
Training loss: 1.2891921469486813
Validation loss: 2.476406878339159

Epoch: 6| Step: 8
Training loss: 1.112549979983837
Validation loss: 2.4996123885056285

Epoch: 6| Step: 9
Training loss: 1.6260160057622044
Validation loss: 2.4885608950415024

Epoch: 6| Step: 10
Training loss: 1.2903093261384073
Validation loss: 2.4662787406638853

Epoch: 6| Step: 11
Training loss: 1.1804986148391476
Validation loss: 2.4725822444524472

Epoch: 6| Step: 12
Training loss: 1.3960075791571291
Validation loss: 2.4851643278458857

Epoch: 6| Step: 13
Training loss: 1.4738150573037907
Validation loss: 2.484939889683236

Epoch: 207| Step: 0
Training loss: 0.9019002443773662
Validation loss: 2.4892418600989816

Epoch: 6| Step: 1
Training loss: 1.4154936571642736
Validation loss: 2.4996793356714893

Epoch: 6| Step: 2
Training loss: 1.4954982598338307
Validation loss: 2.4976384514699084

Epoch: 6| Step: 3
Training loss: 1.0787682203962035
Validation loss: 2.5038797616689386

Epoch: 6| Step: 4
Training loss: 1.346533885695164
Validation loss: 2.509530288594347

Epoch: 6| Step: 5
Training loss: 0.9919509004855024
Validation loss: 2.512553717783269

Epoch: 6| Step: 6
Training loss: 1.146310250415844
Validation loss: 2.520795557614843

Epoch: 6| Step: 7
Training loss: 1.004394887313075
Validation loss: 2.5193890727905464

Epoch: 6| Step: 8
Training loss: 1.0847161100060423
Validation loss: 2.540039649907768

Epoch: 6| Step: 9
Training loss: 2.150205682186708
Validation loss: 2.5490529360833745

Epoch: 6| Step: 10
Training loss: 1.2598206027550505
Validation loss: 2.5171810741964693

Epoch: 6| Step: 11
Training loss: 1.1816903600393327
Validation loss: 2.5316967131326944

Epoch: 6| Step: 12
Training loss: 0.7777341696079353
Validation loss: 2.489518440242825

Epoch: 6| Step: 13
Training loss: 0.6639658240462409
Validation loss: 2.4978177477711916

Epoch: 208| Step: 0
Training loss: 0.8054051578552659
Validation loss: 2.5178035952478646

Epoch: 6| Step: 1
Training loss: 1.1729521823382238
Validation loss: 2.495726554832954

Epoch: 6| Step: 2
Training loss: 1.0607769402205567
Validation loss: 2.4766639426542163

Epoch: 6| Step: 3
Training loss: 1.1834292659468033
Validation loss: 2.4847728647744467

Epoch: 6| Step: 4
Training loss: 1.575703491047481
Validation loss: 2.4549704834422794

Epoch: 6| Step: 5
Training loss: 1.1441139267567202
Validation loss: 2.4468584365754547

Epoch: 6| Step: 6
Training loss: 1.163141077946184
Validation loss: 2.449501478302247

Epoch: 6| Step: 7
Training loss: 1.435012572628862
Validation loss: 2.434041984601334

Epoch: 6| Step: 8
Training loss: 1.8069216288009793
Validation loss: 2.451913919640401

Epoch: 6| Step: 9
Training loss: 1.0166245456996135
Validation loss: 2.4501562496049107

Epoch: 6| Step: 10
Training loss: 1.364246016105272
Validation loss: 2.4538038688818307

Epoch: 6| Step: 11
Training loss: 1.018612736540957
Validation loss: 2.444596951056908

Epoch: 6| Step: 12
Training loss: 1.19732113284803
Validation loss: 2.497481438280193

Epoch: 6| Step: 13
Training loss: 1.0529201251688833
Validation loss: 2.4812395191020347

Epoch: 209| Step: 0
Training loss: 1.1426544946432486
Validation loss: 2.499554292879132

Epoch: 6| Step: 1
Training loss: 1.0096933719012078
Validation loss: 2.5065644802255345

Epoch: 6| Step: 2
Training loss: 1.0098417094801895
Validation loss: 2.5002792961223417

Epoch: 6| Step: 3
Training loss: 1.383669269898117
Validation loss: 2.53244089186757

Epoch: 6| Step: 4
Training loss: 0.9263343929089333
Validation loss: 2.525417493746048

Epoch: 6| Step: 5
Training loss: 1.2490963530563806
Validation loss: 2.5047244592024374

Epoch: 6| Step: 6
Training loss: 1.0495475134669212
Validation loss: 2.5228931161468853

Epoch: 6| Step: 7
Training loss: 0.9864388583126262
Validation loss: 2.522538760385938

Epoch: 6| Step: 8
Training loss: 0.9129144354519781
Validation loss: 2.522961961477425

Epoch: 6| Step: 9
Training loss: 1.6872557004062743
Validation loss: 2.518635880123621

Epoch: 6| Step: 10
Training loss: 1.107368589057799
Validation loss: 2.4789887689586565

Epoch: 6| Step: 11
Training loss: 1.8742494988473235
Validation loss: 2.4464924474516674

Epoch: 6| Step: 12
Training loss: 1.1316772033657823
Validation loss: 2.4400276055363843

Epoch: 6| Step: 13
Training loss: 1.4403360834258037
Validation loss: 2.4169438765010627

Epoch: 210| Step: 0
Training loss: 1.0370517865587816
Validation loss: 2.405315242644165

Epoch: 6| Step: 1
Training loss: 1.5570521941357847
Validation loss: 2.383611938275093

Epoch: 6| Step: 2
Training loss: 1.4269534792143859
Validation loss: 2.403792970136857

Epoch: 6| Step: 3
Training loss: 1.3516939132396473
Validation loss: 2.4398118265755175

Epoch: 6| Step: 4
Training loss: 1.3344214688145217
Validation loss: 2.4452819675538024

Epoch: 6| Step: 5
Training loss: 0.6316197303991526
Validation loss: 2.429612822951751

Epoch: 6| Step: 6
Training loss: 1.8319834883916126
Validation loss: 2.472483178808799

Epoch: 6| Step: 7
Training loss: 1.2359470545499496
Validation loss: 2.4912727429233366

Epoch: 6| Step: 8
Training loss: 1.0328557777282703
Validation loss: 2.5023541308254833

Epoch: 6| Step: 9
Training loss: 0.8658704292702092
Validation loss: 2.5422450210642107

Epoch: 6| Step: 10
Training loss: 1.3081139439290117
Validation loss: 2.5318342977972126

Epoch: 6| Step: 11
Training loss: 1.327811215301991
Validation loss: 2.5428791973289924

Epoch: 6| Step: 12
Training loss: 0.6885765706467001
Validation loss: 2.5378834864482083

Epoch: 6| Step: 13
Training loss: 0.9454468245478631
Validation loss: 2.5439284947413974

Epoch: 211| Step: 0
Training loss: 0.9094424416090124
Validation loss: 2.4782212504704244

Epoch: 6| Step: 1
Training loss: 0.7184559593799348
Validation loss: 2.5138979005747446

Epoch: 6| Step: 2
Training loss: 1.2784252662791347
Validation loss: 2.486769481122372

Epoch: 6| Step: 3
Training loss: 1.6226167074352609
Validation loss: 2.461440674515782

Epoch: 6| Step: 4
Training loss: 1.2876454280458225
Validation loss: 2.4477856515677794

Epoch: 6| Step: 5
Training loss: 1.271951709655383
Validation loss: 2.4496529653783665

Epoch: 6| Step: 6
Training loss: 0.9823810424813011
Validation loss: 2.4304850572088235

Epoch: 6| Step: 7
Training loss: 1.1652759141771956
Validation loss: 2.4348854965368707

Epoch: 6| Step: 8
Training loss: 0.9684721332867732
Validation loss: 2.4622572368655047

Epoch: 6| Step: 9
Training loss: 1.3091325248590144
Validation loss: 2.4689198792861005

Epoch: 6| Step: 10
Training loss: 0.9989965888300213
Validation loss: 2.4981595730346378

Epoch: 6| Step: 11
Training loss: 1.7763504774116126
Validation loss: 2.5577757371203247

Epoch: 6| Step: 12
Training loss: 1.3417752415496995
Validation loss: 2.5630955508020175

Epoch: 6| Step: 13
Training loss: 1.2824154647123143
Validation loss: 2.599496966662354

Epoch: 212| Step: 0
Training loss: 1.209573186362493
Validation loss: 2.563603609482957

Epoch: 6| Step: 1
Training loss: 1.1916885791889118
Validation loss: 2.5616059192912104

Epoch: 6| Step: 2
Training loss: 1.6860910821207231
Validation loss: 2.5697067618690275

Epoch: 6| Step: 3
Training loss: 1.4122333815115655
Validation loss: 2.5006390534162453

Epoch: 6| Step: 4
Training loss: 1.0341550195505846
Validation loss: 2.482711145051456

Epoch: 6| Step: 5
Training loss: 0.7984670928427882
Validation loss: 2.4555900034163822

Epoch: 6| Step: 6
Training loss: 1.1899731130527753
Validation loss: 2.465755818816169

Epoch: 6| Step: 7
Training loss: 1.0534149404694235
Validation loss: 2.473603651509986

Epoch: 6| Step: 8
Training loss: 1.0747104143837312
Validation loss: 2.472596451018539

Epoch: 6| Step: 9
Training loss: 1.1298782229845477
Validation loss: 2.459080286634926

Epoch: 6| Step: 10
Training loss: 1.6185104929360261
Validation loss: 2.4729491991154062

Epoch: 6| Step: 11
Training loss: 0.7633388798177627
Validation loss: 2.4416796790138875

Epoch: 6| Step: 12
Training loss: 1.2848889383049342
Validation loss: 2.4807074158996665

Epoch: 6| Step: 13
Training loss: 1.232054835585415
Validation loss: 2.516003581681775

Epoch: 213| Step: 0
Training loss: 1.2842044262261862
Validation loss: 2.492377068598619

Epoch: 6| Step: 1
Training loss: 1.2593268524886325
Validation loss: 2.500292293320008

Epoch: 6| Step: 2
Training loss: 0.5467369177744096
Validation loss: 2.5199234134757638

Epoch: 6| Step: 3
Training loss: 1.3947752837894345
Validation loss: 2.506112872995249

Epoch: 6| Step: 4
Training loss: 0.9673421227723812
Validation loss: 2.510484738338219

Epoch: 6| Step: 5
Training loss: 1.4011949174112
Validation loss: 2.5021580672231343

Epoch: 6| Step: 6
Training loss: 1.0962190280484299
Validation loss: 2.5212140464912736

Epoch: 6| Step: 7
Training loss: 1.0248638434809576
Validation loss: 2.4746570025898627

Epoch: 6| Step: 8
Training loss: 1.2986483571405483
Validation loss: 2.4981266488670237

Epoch: 6| Step: 9
Training loss: 1.6427282022142609
Validation loss: 2.436084166786048

Epoch: 6| Step: 10
Training loss: 0.916871409236895
Validation loss: 2.4394886569892713

Epoch: 6| Step: 11
Training loss: 1.0148736375220953
Validation loss: 2.437389146184064

Epoch: 6| Step: 12
Training loss: 1.3018599153213388
Validation loss: 2.461908384174863

Epoch: 6| Step: 13
Training loss: 0.9214206804526941
Validation loss: 2.4613598532901766

Epoch: 214| Step: 0
Training loss: 1.3583047095405216
Validation loss: 2.434784660720927

Epoch: 6| Step: 1
Training loss: 1.2636849404179908
Validation loss: 2.4768176436642926

Epoch: 6| Step: 2
Training loss: 1.3054114063756415
Validation loss: 2.4232926468636204

Epoch: 6| Step: 3
Training loss: 1.157448946030816
Validation loss: 2.4465713508071807

Epoch: 6| Step: 4
Training loss: 1.666128103343344
Validation loss: 2.4744340077702347

Epoch: 6| Step: 5
Training loss: 1.3283551185062736
Validation loss: 2.466770869487177

Epoch: 6| Step: 6
Training loss: 0.48714907804815155
Validation loss: 2.4508341986567523

Epoch: 6| Step: 7
Training loss: 1.193315171142619
Validation loss: 2.4827692197052778

Epoch: 6| Step: 8
Training loss: 0.8341701041680186
Validation loss: 2.483873419480112

Epoch: 6| Step: 9
Training loss: 1.010189712572026
Validation loss: 2.4768601053659856

Epoch: 6| Step: 10
Training loss: 0.8740764580526935
Validation loss: 2.447825757190746

Epoch: 6| Step: 11
Training loss: 1.1141178133422565
Validation loss: 2.5024441241297857

Epoch: 6| Step: 12
Training loss: 1.2475094302170744
Validation loss: 2.5082028151393927

Epoch: 6| Step: 13
Training loss: 1.2342881280775158
Validation loss: 2.4972045363919997

Epoch: 215| Step: 0
Training loss: 1.439795113133794
Validation loss: 2.524826421896786

Epoch: 6| Step: 1
Training loss: 0.848389304181419
Validation loss: 2.5136196770614614

Epoch: 6| Step: 2
Training loss: 1.884176053351813
Validation loss: 2.492460327665419

Epoch: 6| Step: 3
Training loss: 0.9504139914189982
Validation loss: 2.4951468234672864

Epoch: 6| Step: 4
Training loss: 1.149510978301175
Validation loss: 2.502192186256566

Epoch: 6| Step: 5
Training loss: 1.0379204461146185
Validation loss: 2.4585529286322156

Epoch: 6| Step: 6
Training loss: 0.9274262890482938
Validation loss: 2.4794889636799216

Epoch: 6| Step: 7
Training loss: 1.0796992653234692
Validation loss: 2.452946758515828

Epoch: 6| Step: 8
Training loss: 0.906170118034048
Validation loss: 2.459895256357688

Epoch: 6| Step: 9
Training loss: 0.876240600121943
Validation loss: 2.4408680690422004

Epoch: 6| Step: 10
Training loss: 1.0298744622363514
Validation loss: 2.4576484250274664

Epoch: 6| Step: 11
Training loss: 1.2097902339197426
Validation loss: 2.467922071345613

Epoch: 6| Step: 12
Training loss: 1.2234738087534063
Validation loss: 2.451588673362587

Epoch: 6| Step: 13
Training loss: 1.1150835406221942
Validation loss: 2.491662388445783

Epoch: 216| Step: 0
Training loss: 1.0975985800366905
Validation loss: 2.486043340858037

Epoch: 6| Step: 1
Training loss: 1.1808079836127097
Validation loss: 2.4554228655517476

Epoch: 6| Step: 2
Training loss: 0.9919269249634614
Validation loss: 2.4967980624999173

Epoch: 6| Step: 3
Training loss: 0.8652174971680247
Validation loss: 2.4500703004633473

Epoch: 6| Step: 4
Training loss: 1.544867088995799
Validation loss: 2.468869228347458

Epoch: 6| Step: 5
Training loss: 1.043049327009432
Validation loss: 2.480552714681061

Epoch: 6| Step: 6
Training loss: 1.131056167266937
Validation loss: 2.4739979336758364

Epoch: 6| Step: 7
Training loss: 0.9759948911963097
Validation loss: 2.482546729993694

Epoch: 6| Step: 8
Training loss: 0.9128390870993981
Validation loss: 2.471373647189914

Epoch: 6| Step: 9
Training loss: 1.331556397759565
Validation loss: 2.472867777965119

Epoch: 6| Step: 10
Training loss: 0.7176942119860902
Validation loss: 2.454186795931737

Epoch: 6| Step: 11
Training loss: 1.771811121843764
Validation loss: 2.47116127861952

Epoch: 6| Step: 12
Training loss: 0.7537805719327884
Validation loss: 2.493340990283881

Epoch: 6| Step: 13
Training loss: 0.9683080095622706
Validation loss: 2.480868878081731

Epoch: 217| Step: 0
Training loss: 1.1265835742857535
Validation loss: 2.4930227045576103

Epoch: 6| Step: 1
Training loss: 1.0063256821692692
Validation loss: 2.439683395383109

Epoch: 6| Step: 2
Training loss: 1.1435480679549286
Validation loss: 2.4963091359479535

Epoch: 6| Step: 3
Training loss: 1.1444608386777986
Validation loss: 2.4981663306296826

Epoch: 6| Step: 4
Training loss: 1.4568954281743265
Validation loss: 2.499644941322338

Epoch: 6| Step: 5
Training loss: 0.6199225893839786
Validation loss: 2.4833047462426214

Epoch: 6| Step: 6
Training loss: 1.2343121283249245
Validation loss: 2.4932854229245547

Epoch: 6| Step: 7
Training loss: 1.0562477156936052
Validation loss: 2.444420890571883

Epoch: 6| Step: 8
Training loss: 0.9367703459387864
Validation loss: 2.476055705836534

Epoch: 6| Step: 9
Training loss: 1.3423989179409064
Validation loss: 2.4747435729749894

Epoch: 6| Step: 10
Training loss: 1.0673085960839055
Validation loss: 2.465982658462016

Epoch: 6| Step: 11
Training loss: 0.7664018698906436
Validation loss: 2.4493368629650165

Epoch: 6| Step: 12
Training loss: 0.8472072976957056
Validation loss: 2.44510964388911

Epoch: 6| Step: 13
Training loss: 1.8664493777759994
Validation loss: 2.4522872114961998

Epoch: 218| Step: 0
Training loss: 0.9237240174166337
Validation loss: 2.444085606573619

Epoch: 6| Step: 1
Training loss: 1.683791571587491
Validation loss: 2.453578440451943

Epoch: 6| Step: 2
Training loss: 0.8723087134440682
Validation loss: 2.4711440516245338

Epoch: 6| Step: 3
Training loss: 1.0237906043415743
Validation loss: 2.4675461905408436

Epoch: 6| Step: 4
Training loss: 0.7012024131649054
Validation loss: 2.4841952922884425

Epoch: 6| Step: 5
Training loss: 1.2265047679362129
Validation loss: 2.491098618734286

Epoch: 6| Step: 6
Training loss: 1.3156598519173812
Validation loss: 2.4746085721169933

Epoch: 6| Step: 7
Training loss: 1.1625069074528067
Validation loss: 2.5048176286789907

Epoch: 6| Step: 8
Training loss: 1.1785445076068266
Validation loss: 2.4854385246975204

Epoch: 6| Step: 9
Training loss: 1.0942891563153656
Validation loss: 2.4651567387700615

Epoch: 6| Step: 10
Training loss: 1.1650887899985658
Validation loss: 2.48432866493976

Epoch: 6| Step: 11
Training loss: 0.95089752188446
Validation loss: 2.4475619263065043

Epoch: 6| Step: 12
Training loss: 0.4870213848995933
Validation loss: 2.4430864031339006

Epoch: 6| Step: 13
Training loss: 1.4612021792951362
Validation loss: 2.4941022657993877

Epoch: 219| Step: 0
Training loss: 0.6746399784711882
Validation loss: 2.507906429267144

Epoch: 6| Step: 1
Training loss: 0.9218986637505099
Validation loss: 2.4970281000165193

Epoch: 6| Step: 2
Training loss: 0.872965354441711
Validation loss: 2.480237683111362

Epoch: 6| Step: 3
Training loss: 1.0545396489249634
Validation loss: 2.478251029522462

Epoch: 6| Step: 4
Training loss: 0.7087416220141213
Validation loss: 2.463081464302073

Epoch: 6| Step: 5
Training loss: 1.0146467339186553
Validation loss: 2.4636643003776095

Epoch: 6| Step: 6
Training loss: 1.235936589487852
Validation loss: 2.4313600110308866

Epoch: 6| Step: 7
Training loss: 1.233304054110319
Validation loss: 2.450109478779507

Epoch: 6| Step: 8
Training loss: 1.2297838515034918
Validation loss: 2.4579663194763737

Epoch: 6| Step: 9
Training loss: 1.278458974616402
Validation loss: 2.4464102060262376

Epoch: 6| Step: 10
Training loss: 1.5258654686908315
Validation loss: 2.450008689324191

Epoch: 6| Step: 11
Training loss: 1.3913691383480298
Validation loss: 2.4637336582433043

Epoch: 6| Step: 12
Training loss: 0.5822534329094915
Validation loss: 2.4794781538228654

Epoch: 6| Step: 13
Training loss: 1.3029097363261541
Validation loss: 2.4578212224098115

Epoch: 220| Step: 0
Training loss: 0.6061723620067027
Validation loss: 2.4587540343891217

Epoch: 6| Step: 1
Training loss: 1.129057771750442
Validation loss: 2.501999842717728

Epoch: 6| Step: 2
Training loss: 0.6536138357003102
Validation loss: 2.473970693007954

Epoch: 6| Step: 3
Training loss: 0.7066332081267908
Validation loss: 2.4689366415596106

Epoch: 6| Step: 4
Training loss: 1.0275812490968699
Validation loss: 2.502481571254348

Epoch: 6| Step: 5
Training loss: 0.9528025722768415
Validation loss: 2.485420168694438

Epoch: 6| Step: 6
Training loss: 1.2240177167189943
Validation loss: 2.4631038789207116

Epoch: 6| Step: 7
Training loss: 1.5705989747143538
Validation loss: 2.481724356509106

Epoch: 6| Step: 8
Training loss: 1.6299598268812345
Validation loss: 2.470775771565618

Epoch: 6| Step: 9
Training loss: 1.1151878761445229
Validation loss: 2.476307384916434

Epoch: 6| Step: 10
Training loss: 0.8722701746082683
Validation loss: 2.489939842556657

Epoch: 6| Step: 11
Training loss: 1.160877145094259
Validation loss: 2.468924370211771

Epoch: 6| Step: 12
Training loss: 1.0498208120127954
Validation loss: 2.491098885791039

Epoch: 6| Step: 13
Training loss: 1.1021264979389191
Validation loss: 2.47323704686715

Epoch: 221| Step: 0
Training loss: 0.983087545458684
Validation loss: 2.477096319449609

Epoch: 6| Step: 1
Training loss: 1.051597873495222
Validation loss: 2.4681459349596695

Epoch: 6| Step: 2
Training loss: 1.0383470409666178
Validation loss: 2.5189362810672313

Epoch: 6| Step: 3
Training loss: 1.2466328091707193
Validation loss: 2.4380299144923736

Epoch: 6| Step: 4
Training loss: 0.9865802706983913
Validation loss: 2.4559660011474294

Epoch: 6| Step: 5
Training loss: 1.0242317553872227
Validation loss: 2.448796639364112

Epoch: 6| Step: 6
Training loss: 0.6607447151408616
Validation loss: 2.464256106192219

Epoch: 6| Step: 7
Training loss: 1.0836876815425256
Validation loss: 2.4203417340943747

Epoch: 6| Step: 8
Training loss: 1.2420186821765646
Validation loss: 2.4392861783589974

Epoch: 6| Step: 9
Training loss: 1.0234486819522726
Validation loss: 2.4604926459079732

Epoch: 6| Step: 10
Training loss: 1.4035092666613602
Validation loss: 2.4577057765508767

Epoch: 6| Step: 11
Training loss: 1.0044442008296237
Validation loss: 2.4434970004359062

Epoch: 6| Step: 12
Training loss: 1.0785984160891404
Validation loss: 2.4810440167673624

Epoch: 6| Step: 13
Training loss: 1.0588568891773915
Validation loss: 2.50429876785557

Epoch: 222| Step: 0
Training loss: 0.922002169356204
Validation loss: 2.515268041504602

Epoch: 6| Step: 1
Training loss: 1.073384797025443
Validation loss: 2.468920651829734

Epoch: 6| Step: 2
Training loss: 0.9554059610766595
Validation loss: 2.502803157963774

Epoch: 6| Step: 3
Training loss: 0.9138476127326591
Validation loss: 2.479919260075572

Epoch: 6| Step: 4
Training loss: 0.9130679205274589
Validation loss: 2.4844338860307817

Epoch: 6| Step: 5
Training loss: 1.0482542147798457
Validation loss: 2.473076857483666

Epoch: 6| Step: 6
Training loss: 0.8042344234429704
Validation loss: 2.4688071476261944

Epoch: 6| Step: 7
Training loss: 0.8028322703123694
Validation loss: 2.495108508504793

Epoch: 6| Step: 8
Training loss: 1.5479452110865808
Validation loss: 2.513113359961109

Epoch: 6| Step: 9
Training loss: 1.5570649031903558
Validation loss: 2.5096204142783347

Epoch: 6| Step: 10
Training loss: 0.49600097209216043
Validation loss: 2.4703370602258623

Epoch: 6| Step: 11
Training loss: 1.052887008444529
Validation loss: 2.468588615429229

Epoch: 6| Step: 12
Training loss: 1.3975922997964016
Validation loss: 2.4607586976865212

Epoch: 6| Step: 13
Training loss: 0.8082396980665078
Validation loss: 2.460005811935697

Epoch: 223| Step: 0
Training loss: 1.198416227030043
Validation loss: 2.457208530611532

Epoch: 6| Step: 1
Training loss: 1.1826309467904421
Validation loss: 2.4335342110511182

Epoch: 6| Step: 2
Training loss: 0.7852165996075575
Validation loss: 2.4240145005325417

Epoch: 6| Step: 3
Training loss: 1.0855532178937126
Validation loss: 2.4797241922824296

Epoch: 6| Step: 4
Training loss: 0.4695902446175045
Validation loss: 2.454296752118903

Epoch: 6| Step: 5
Training loss: 0.9799921465578505
Validation loss: 2.4521540035607834

Epoch: 6| Step: 6
Training loss: 0.8713052946082409
Validation loss: 2.446512537403922

Epoch: 6| Step: 7
Training loss: 1.0343514246717405
Validation loss: 2.425555543744692

Epoch: 6| Step: 8
Training loss: 1.4132361763872427
Validation loss: 2.418098685963832

Epoch: 6| Step: 9
Training loss: 0.649649120039378
Validation loss: 2.4662533856045443

Epoch: 6| Step: 10
Training loss: 1.5029389676705447
Validation loss: 2.450785435495012

Epoch: 6| Step: 11
Training loss: 0.9351045203819993
Validation loss: 2.4611443701703357

Epoch: 6| Step: 12
Training loss: 1.0064346001986064
Validation loss: 2.484233401997107

Epoch: 6| Step: 13
Training loss: 1.374402176335469
Validation loss: 2.498772945550576

Epoch: 224| Step: 0
Training loss: 1.0092097805609146
Validation loss: 2.4902981194403093

Epoch: 6| Step: 1
Training loss: 0.8490371004474709
Validation loss: 2.5167438941270426

Epoch: 6| Step: 2
Training loss: 0.9648372016715411
Validation loss: 2.4960615216436595

Epoch: 6| Step: 3
Training loss: 1.2976672958096824
Validation loss: 2.4737372117674052

Epoch: 6| Step: 4
Training loss: 1.009357008168398
Validation loss: 2.4746627438622517

Epoch: 6| Step: 5
Training loss: 0.8420976424539034
Validation loss: 2.4270343574005797

Epoch: 6| Step: 6
Training loss: 0.7872532412527986
Validation loss: 2.473888773347731

Epoch: 6| Step: 7
Training loss: 1.6531336995059966
Validation loss: 2.4389936683974307

Epoch: 6| Step: 8
Training loss: 1.1549849420036558
Validation loss: 2.4582276054771195

Epoch: 6| Step: 9
Training loss: 0.7876413975279953
Validation loss: 2.4353545438502615

Epoch: 6| Step: 10
Training loss: 0.9384115555842016
Validation loss: 2.4151042237472278

Epoch: 6| Step: 11
Training loss: 1.1235656071017455
Validation loss: 2.4552844301027927

Epoch: 6| Step: 12
Training loss: 0.7161012439140061
Validation loss: 2.4652420153044265

Epoch: 6| Step: 13
Training loss: 1.0130680468751778
Validation loss: 2.5061978034160246

Epoch: 225| Step: 0
Training loss: 0.9063823866337352
Validation loss: 2.46551288980104

Epoch: 6| Step: 1
Training loss: 0.8154215372557698
Validation loss: 2.497672597344785

Epoch: 6| Step: 2
Training loss: 0.9879675205119898
Validation loss: 2.485226386798385

Epoch: 6| Step: 3
Training loss: 1.0766076176771604
Validation loss: 2.5163340460041

Epoch: 6| Step: 4
Training loss: 1.044119096927221
Validation loss: 2.4580454782096397

Epoch: 6| Step: 5
Training loss: 1.2662043246347063
Validation loss: 2.4352655773714003

Epoch: 6| Step: 6
Training loss: 0.5763545118623085
Validation loss: 2.4446920041220768

Epoch: 6| Step: 7
Training loss: 0.9645714626584244
Validation loss: 2.472709241123409

Epoch: 6| Step: 8
Training loss: 1.4614857343668506
Validation loss: 2.459372819141542

Epoch: 6| Step: 9
Training loss: 1.3022706265850938
Validation loss: 2.445645487857791

Epoch: 6| Step: 10
Training loss: 1.2760935039760577
Validation loss: 2.442069602840774

Epoch: 6| Step: 11
Training loss: 0.5375455992230325
Validation loss: 2.485599011205796

Epoch: 6| Step: 12
Training loss: 0.701487924227162
Validation loss: 2.474544596525708

Epoch: 6| Step: 13
Training loss: 0.8453622884419364
Validation loss: 2.4761946137621456

Epoch: 226| Step: 0
Training loss: 1.1366646350682097
Validation loss: 2.4737777096538576

Epoch: 6| Step: 1
Training loss: 0.9624411750751531
Validation loss: 2.4898446882482146

Epoch: 6| Step: 2
Training loss: 1.114435714976118
Validation loss: 2.4892252546423888

Epoch: 6| Step: 3
Training loss: 0.8820051366760254
Validation loss: 2.482024493756942

Epoch: 6| Step: 4
Training loss: 0.7614778969300225
Validation loss: 2.495650180441135

Epoch: 6| Step: 5
Training loss: 0.8632090611719372
Validation loss: 2.471883038900202

Epoch: 6| Step: 6
Training loss: 1.3240918123963419
Validation loss: 2.480474766174984

Epoch: 6| Step: 7
Training loss: 0.991811996651181
Validation loss: 2.514219810433221

Epoch: 6| Step: 8
Training loss: 1.2823721460931063
Validation loss: 2.5063696230768606

Epoch: 6| Step: 9
Training loss: 1.0300727829633711
Validation loss: 2.478690330083334

Epoch: 6| Step: 10
Training loss: 0.5501046590496456
Validation loss: 2.4930585023932648

Epoch: 6| Step: 11
Training loss: 1.2107199196537717
Validation loss: 2.4599439817116973

Epoch: 6| Step: 12
Training loss: 0.8848530639826465
Validation loss: 2.46404208636262

Epoch: 6| Step: 13
Training loss: 0.833616546347754
Validation loss: 2.4585241018129773

Epoch: 227| Step: 0
Training loss: 0.8037282170121901
Validation loss: 2.4725289789526768

Epoch: 6| Step: 1
Training loss: 0.8249475953768839
Validation loss: 2.4606459661580606

Epoch: 6| Step: 2
Training loss: 1.148547264614587
Validation loss: 2.4771843973008245

Epoch: 6| Step: 3
Training loss: 1.05570680318268
Validation loss: 2.4571997286752336

Epoch: 6| Step: 4
Training loss: 1.0036228833876428
Validation loss: 2.4524259269402577

Epoch: 6| Step: 5
Training loss: 0.5450936323630603
Validation loss: 2.450567395797267

Epoch: 6| Step: 6
Training loss: 0.9064324951580803
Validation loss: 2.441136836193306

Epoch: 6| Step: 7
Training loss: 1.0914238307795714
Validation loss: 2.441602853517009

Epoch: 6| Step: 8
Training loss: 1.073118499487338
Validation loss: 2.490668597581995

Epoch: 6| Step: 9
Training loss: 0.6384467331811003
Validation loss: 2.4516692018480817

Epoch: 6| Step: 10
Training loss: 1.4475680510183628
Validation loss: 2.468101850448283

Epoch: 6| Step: 11
Training loss: 0.6715600584118012
Validation loss: 2.4792453613434735

Epoch: 6| Step: 12
Training loss: 1.0654054074269956
Validation loss: 2.4848989918414772

Epoch: 6| Step: 13
Training loss: 1.6460264390418833
Validation loss: 2.4651357483226497

Epoch: 228| Step: 0
Training loss: 1.2696322826384323
Validation loss: 2.47997272865307

Epoch: 6| Step: 1
Training loss: 1.2275266806039467
Validation loss: 2.482232407473382

Epoch: 6| Step: 2
Training loss: 1.0849941190217427
Validation loss: 2.4857966335524497

Epoch: 6| Step: 3
Training loss: 1.2290898422974794
Validation loss: 2.4989688808044495

Epoch: 6| Step: 4
Training loss: 0.9523381596840063
Validation loss: 2.518223419184591

Epoch: 6| Step: 5
Training loss: 1.323558631586893
Validation loss: 2.494422562285147

Epoch: 6| Step: 6
Training loss: 0.8760940660068247
Validation loss: 2.4875129503554154

Epoch: 6| Step: 7
Training loss: 0.6683760176637149
Validation loss: 2.488644478536508

Epoch: 6| Step: 8
Training loss: 0.5138581666984692
Validation loss: 2.4547202814204283

Epoch: 6| Step: 9
Training loss: 0.6672956410302666
Validation loss: 2.485962506868292

Epoch: 6| Step: 10
Training loss: 0.9493240486420531
Validation loss: 2.4758512961790937

Epoch: 6| Step: 11
Training loss: 0.8174892342584761
Validation loss: 2.449656572772103

Epoch: 6| Step: 12
Training loss: 1.0639566085937895
Validation loss: 2.4705869684424075

Epoch: 6| Step: 13
Training loss: 0.7843802493706239
Validation loss: 2.486452916333934

Epoch: 229| Step: 0
Training loss: 0.8578010016332548
Validation loss: 2.4662673167824836

Epoch: 6| Step: 1
Training loss: 1.1426552770926852
Validation loss: 2.4525790736059037

Epoch: 6| Step: 2
Training loss: 0.7020841736227227
Validation loss: 2.486279955896793

Epoch: 6| Step: 3
Training loss: 1.123822761870241
Validation loss: 2.482139984936241

Epoch: 6| Step: 4
Training loss: 0.6000674110531874
Validation loss: 2.4794300026006084

Epoch: 6| Step: 5
Training loss: 0.9688515148503195
Validation loss: 2.5118418803241687

Epoch: 6| Step: 6
Training loss: 0.8290613027622221
Validation loss: 2.5262776369366726

Epoch: 6| Step: 7
Training loss: 1.0001408954544844
Validation loss: 2.5104270817064003

Epoch: 6| Step: 8
Training loss: 1.622128517167643
Validation loss: 2.478964488084933

Epoch: 6| Step: 9
Training loss: 0.5502871738998625
Validation loss: 2.5266571803814113

Epoch: 6| Step: 10
Training loss: 0.9198970912826404
Validation loss: 2.5144182257245187

Epoch: 6| Step: 11
Training loss: 0.5475952310348899
Validation loss: 2.4595983666368704

Epoch: 6| Step: 12
Training loss: 1.4139174076061218
Validation loss: 2.500781384251794

Epoch: 6| Step: 13
Training loss: 0.9009079512382545
Validation loss: 2.4877638639938

Epoch: 230| Step: 0
Training loss: 0.9158969956874461
Validation loss: 2.4585647126507952

Epoch: 6| Step: 1
Training loss: 1.0871806541812863
Validation loss: 2.448494391688665

Epoch: 6| Step: 2
Training loss: 0.8220740885793977
Validation loss: 2.4453453426861054

Epoch: 6| Step: 3
Training loss: 0.9094598094811518
Validation loss: 2.424512947493693

Epoch: 6| Step: 4
Training loss: 1.4297425306391558
Validation loss: 2.4265202902528773

Epoch: 6| Step: 5
Training loss: 0.9284151811719387
Validation loss: 2.4717479435188414

Epoch: 6| Step: 6
Training loss: 1.2622747465818027
Validation loss: 2.4649265563305076

Epoch: 6| Step: 7
Training loss: 0.8464082945118887
Validation loss: 2.4658939990853135

Epoch: 6| Step: 8
Training loss: 0.5832291379468579
Validation loss: 2.455889583412106

Epoch: 6| Step: 9
Training loss: 1.0077238413529837
Validation loss: 2.4664078091763457

Epoch: 6| Step: 10
Training loss: 0.6288558039365615
Validation loss: 2.4439662328155376

Epoch: 6| Step: 11
Training loss: 0.766691749273018
Validation loss: 2.4400049390067067

Epoch: 6| Step: 12
Training loss: 1.1851090403579525
Validation loss: 2.4499168080931804

Epoch: 6| Step: 13
Training loss: 0.8574730373403149
Validation loss: 2.4099745289770453

Epoch: 231| Step: 0
Training loss: 0.960550276729708
Validation loss: 2.425444926176356

Epoch: 6| Step: 1
Training loss: 1.2350083669772873
Validation loss: 2.4619268654975275

Epoch: 6| Step: 2
Training loss: 0.6888432601610621
Validation loss: 2.4462519179245947

Epoch: 6| Step: 3
Training loss: 1.3516366309855563
Validation loss: 2.4790547911737124

Epoch: 6| Step: 4
Training loss: 0.9335325532272712
Validation loss: 2.4710311682896235

Epoch: 6| Step: 5
Training loss: 0.8968275821924141
Validation loss: 2.460968948686785

Epoch: 6| Step: 6
Training loss: 0.7676425353536619
Validation loss: 2.4448262147576965

Epoch: 6| Step: 7
Training loss: 0.9857578555245672
Validation loss: 2.458341735803237

Epoch: 6| Step: 8
Training loss: 0.9717853737868222
Validation loss: 2.4515952581635276

Epoch: 6| Step: 9
Training loss: 0.8296585997524822
Validation loss: 2.4709033990438836

Epoch: 6| Step: 10
Training loss: 0.6935943635137345
Validation loss: 2.4768274890807773

Epoch: 6| Step: 11
Training loss: 0.7335290703580836
Validation loss: 2.4402913648536138

Epoch: 6| Step: 12
Training loss: 1.1974560833485552
Validation loss: 2.4492440364758483

Epoch: 6| Step: 13
Training loss: 1.0071238449296487
Validation loss: 2.4713500477220665

Epoch: 232| Step: 0
Training loss: 0.7709383807043914
Validation loss: 2.501585316229711

Epoch: 6| Step: 1
Training loss: 0.6517612117670687
Validation loss: 2.476271221722207

Epoch: 6| Step: 2
Training loss: 0.9676945997782262
Validation loss: 2.471330093288497

Epoch: 6| Step: 3
Training loss: 1.2874624783872364
Validation loss: 2.500632236890768

Epoch: 6| Step: 4
Training loss: 0.7401714851819823
Validation loss: 2.529675863093128

Epoch: 6| Step: 5
Training loss: 1.1697332010353083
Validation loss: 2.5269444170076825

Epoch: 6| Step: 6
Training loss: 0.7534358479225782
Validation loss: 2.5034567817143296

Epoch: 6| Step: 7
Training loss: 0.5782341725137268
Validation loss: 2.5240592489010467

Epoch: 6| Step: 8
Training loss: 0.7688038287661875
Validation loss: 2.4797954063659806

Epoch: 6| Step: 9
Training loss: 0.9607729887285348
Validation loss: 2.4721303600674633

Epoch: 6| Step: 10
Training loss: 1.1402712756854485
Validation loss: 2.4860521391532386

Epoch: 6| Step: 11
Training loss: 1.5095840088248507
Validation loss: 2.4737622590183994

Epoch: 6| Step: 12
Training loss: 0.8361623229976631
Validation loss: 2.4267058410117155

Epoch: 6| Step: 13
Training loss: 0.4022627628629846
Validation loss: 2.4083275404849553

Epoch: 233| Step: 0
Training loss: 1.1514540519011283
Validation loss: 2.439219999361716

Epoch: 6| Step: 1
Training loss: 1.2940743781444883
Validation loss: 2.425077571734002

Epoch: 6| Step: 2
Training loss: 0.8918885085774358
Validation loss: 2.4195150435807795

Epoch: 6| Step: 3
Training loss: 0.9498313528244309
Validation loss: 2.4226517790833255

Epoch: 6| Step: 4
Training loss: 0.9503433410196088
Validation loss: 2.392057482534707

Epoch: 6| Step: 5
Training loss: 0.6718575009573355
Validation loss: 2.407861481883087

Epoch: 6| Step: 6
Training loss: 0.9580624377185762
Validation loss: 2.412288943624648

Epoch: 6| Step: 7
Training loss: 0.6500488391281077
Validation loss: 2.4148802584986333

Epoch: 6| Step: 8
Training loss: 0.961641410488273
Validation loss: 2.382853745443622

Epoch: 6| Step: 9
Training loss: 0.5521111091488293
Validation loss: 2.431270931069546

Epoch: 6| Step: 10
Training loss: 0.3501624628628246
Validation loss: 2.4864716235133084

Epoch: 6| Step: 11
Training loss: 0.7472575433017878
Validation loss: 2.4649810162547316

Epoch: 6| Step: 12
Training loss: 1.235982307171651
Validation loss: 2.4996838913283543

Epoch: 6| Step: 13
Training loss: 1.604712760748754
Validation loss: 2.4791966487580965

Epoch: 234| Step: 0
Training loss: 1.2963017035300897
Validation loss: 2.502404918453664

Epoch: 6| Step: 1
Training loss: 1.064299014073311
Validation loss: 2.467343113439483

Epoch: 6| Step: 2
Training loss: 0.890660870816833
Validation loss: 2.439797490579032

Epoch: 6| Step: 3
Training loss: 1.0472214538297073
Validation loss: 2.4267435699973925

Epoch: 6| Step: 4
Training loss: 1.0243193343505557
Validation loss: 2.413173066857496

Epoch: 6| Step: 5
Training loss: 0.7007643171325141
Validation loss: 2.4006674521214455

Epoch: 6| Step: 6
Training loss: 0.94401230735151
Validation loss: 2.4351419507512415

Epoch: 6| Step: 7
Training loss: 0.5429820875546844
Validation loss: 2.4546896028071354

Epoch: 6| Step: 8
Training loss: 0.9294595519073958
Validation loss: 2.4556937510018093

Epoch: 6| Step: 9
Training loss: 0.9702174239947446
Validation loss: 2.453980682183719

Epoch: 6| Step: 10
Training loss: 0.51476496439521
Validation loss: 2.474842696785983

Epoch: 6| Step: 11
Training loss: 1.0308566643786596
Validation loss: 2.441775877177284

Epoch: 6| Step: 12
Training loss: 0.7875592860354647
Validation loss: 2.441777402693493

Epoch: 6| Step: 13
Training loss: 1.0888231756099616
Validation loss: 2.460403225001467

Epoch: 235| Step: 0
Training loss: 1.1714055964994854
Validation loss: 2.4599370248023575

Epoch: 6| Step: 1
Training loss: 0.4773119989252401
Validation loss: 2.4566310237913522

Epoch: 6| Step: 2
Training loss: 1.268781845745438
Validation loss: 2.4706338154418974

Epoch: 6| Step: 3
Training loss: 0.7410908276288979
Validation loss: 2.4533285309068873

Epoch: 6| Step: 4
Training loss: 0.7679797570496286
Validation loss: 2.443038772897567

Epoch: 6| Step: 5
Training loss: 0.8055664373262094
Validation loss: 2.4587215949858736

Epoch: 6| Step: 6
Training loss: 1.1882525619264124
Validation loss: 2.452989846106565

Epoch: 6| Step: 7
Training loss: 0.992313497157568
Validation loss: 2.4490778033116585

Epoch: 6| Step: 8
Training loss: 0.7091292976667416
Validation loss: 2.482528252955491

Epoch: 6| Step: 9
Training loss: 0.8382631554121639
Validation loss: 2.461149982551374

Epoch: 6| Step: 10
Training loss: 1.2359944596891703
Validation loss: 2.5022561009446225

Epoch: 6| Step: 11
Training loss: 0.8169512230262821
Validation loss: 2.479971340860182

Epoch: 6| Step: 12
Training loss: 0.46366486001753987
Validation loss: 2.536033149176897

Epoch: 6| Step: 13
Training loss: 0.8215757543191888
Validation loss: 2.48584006599462

Epoch: 236| Step: 0
Training loss: 0.4059819657755229
Validation loss: 2.434389289221019

Epoch: 6| Step: 1
Training loss: 0.5746671003213177
Validation loss: 2.4798005247606896

Epoch: 6| Step: 2
Training loss: 1.021131698965606
Validation loss: 2.4650968025823965

Epoch: 6| Step: 3
Training loss: 1.1233898932672137
Validation loss: 2.449608666317562

Epoch: 6| Step: 4
Training loss: 0.7142941389268236
Validation loss: 2.4684943091020366

Epoch: 6| Step: 5
Training loss: 0.788565904319558
Validation loss: 2.440433791750818

Epoch: 6| Step: 6
Training loss: 1.1770787984484972
Validation loss: 2.43759238186623

Epoch: 6| Step: 7
Training loss: 0.7315205228511897
Validation loss: 2.451822142221069

Epoch: 6| Step: 8
Training loss: 1.0613127975845347
Validation loss: 2.4236353145002423

Epoch: 6| Step: 9
Training loss: 0.9037693536567114
Validation loss: 2.469183862272365

Epoch: 6| Step: 10
Training loss: 0.9485652542169785
Validation loss: 2.4728005294620066

Epoch: 6| Step: 11
Training loss: 0.8569443748208926
Validation loss: 2.4548799711179234

Epoch: 6| Step: 12
Training loss: 0.8808656679592631
Validation loss: 2.46713918521331

Epoch: 6| Step: 13
Training loss: 1.0970578446103385
Validation loss: 2.4516571339849054

Epoch: 237| Step: 0
Training loss: 0.8974961366278079
Validation loss: 2.40771899365205

Epoch: 6| Step: 1
Training loss: 1.0750666930336066
Validation loss: 2.4318943864342817

Epoch: 6| Step: 2
Training loss: 0.537012653311863
Validation loss: 2.4406696448425316

Epoch: 6| Step: 3
Training loss: 0.8934171977343275
Validation loss: 2.43129864224435

Epoch: 6| Step: 4
Training loss: 0.3350154954614598
Validation loss: 2.4448005396932744

Epoch: 6| Step: 5
Training loss: 0.9257470619552681
Validation loss: 2.457229892899268

Epoch: 6| Step: 6
Training loss: 0.6253898835043767
Validation loss: 2.467496679200128

Epoch: 6| Step: 7
Training loss: 1.0095723481839483
Validation loss: 2.450259510043285

Epoch: 6| Step: 8
Training loss: 0.9080282719785779
Validation loss: 2.459054807311591

Epoch: 6| Step: 9
Training loss: 1.1984060310698397
Validation loss: 2.437542488752232

Epoch: 6| Step: 10
Training loss: 0.8941195010935159
Validation loss: 2.468991720656566

Epoch: 6| Step: 11
Training loss: 0.7982751102625798
Validation loss: 2.4330473144987557

Epoch: 6| Step: 12
Training loss: 1.0083678733542638
Validation loss: 2.4229372154249518

Epoch: 6| Step: 13
Training loss: 1.0245455502036689
Validation loss: 2.4641517546784795

Epoch: 238| Step: 0
Training loss: 0.5834700957695417
Validation loss: 2.4760806271335047

Epoch: 6| Step: 1
Training loss: 0.3865593668472259
Validation loss: 2.436915722812475

Epoch: 6| Step: 2
Training loss: 1.1241330409034411
Validation loss: 2.4521120988835876

Epoch: 6| Step: 3
Training loss: 0.9349852211952093
Validation loss: 2.4602496499583557

Epoch: 6| Step: 4
Training loss: 0.8993175011573379
Validation loss: 2.44455537407592

Epoch: 6| Step: 5
Training loss: 0.5599033236926669
Validation loss: 2.457826635854908

Epoch: 6| Step: 6
Training loss: 0.9091576267274359
Validation loss: 2.4482630746172473

Epoch: 6| Step: 7
Training loss: 0.7316293726767111
Validation loss: 2.458434153082029

Epoch: 6| Step: 8
Training loss: 0.9327804981665607
Validation loss: 2.4794201995713276

Epoch: 6| Step: 9
Training loss: 0.7108430904540156
Validation loss: 2.477013999128488

Epoch: 6| Step: 10
Training loss: 0.836358258605619
Validation loss: 2.4916093548968528

Epoch: 6| Step: 11
Training loss: 1.0828146181732643
Validation loss: 2.4995766332503475

Epoch: 6| Step: 12
Training loss: 1.2541519352162842
Validation loss: 2.490266691123266

Epoch: 6| Step: 13
Training loss: 1.1720236111824145
Validation loss: 2.4989738614438557

Epoch: 239| Step: 0
Training loss: 0.8462003519209417
Validation loss: 2.463873590695777

Epoch: 6| Step: 1
Training loss: 0.9594171794354434
Validation loss: 2.45512508623779

Epoch: 6| Step: 2
Training loss: 0.6908111166133022
Validation loss: 2.453499665004906

Epoch: 6| Step: 3
Training loss: 0.6626371682515465
Validation loss: 2.45072580686216

Epoch: 6| Step: 4
Training loss: 0.7227140661257657
Validation loss: 2.449168048562891

Epoch: 6| Step: 5
Training loss: 0.644036189601061
Validation loss: 2.481361558825603

Epoch: 6| Step: 6
Training loss: 0.7830767065746636
Validation loss: 2.4720971960487796

Epoch: 6| Step: 7
Training loss: 1.3058144733127572
Validation loss: 2.496242881996978

Epoch: 6| Step: 8
Training loss: 0.8262112655447821
Validation loss: 2.490521623876713

Epoch: 6| Step: 9
Training loss: 1.1521130347030477
Validation loss: 2.4938500449389527

Epoch: 6| Step: 10
Training loss: 0.35619113168038063
Validation loss: 2.5279562822612065

Epoch: 6| Step: 11
Training loss: 1.129684655065898
Validation loss: 2.516720060018311

Epoch: 6| Step: 12
Training loss: 0.9545598408308513
Validation loss: 2.526993430117906

Epoch: 6| Step: 13
Training loss: 0.7172165974883093
Validation loss: 2.464346414582473

Epoch: 240| Step: 0
Training loss: 0.7400187075028736
Validation loss: 2.4764060957082257

Epoch: 6| Step: 1
Training loss: 0.8869477367077848
Validation loss: 2.472625325285979

Epoch: 6| Step: 2
Training loss: 0.8203301564087541
Validation loss: 2.40185900864156

Epoch: 6| Step: 3
Training loss: 0.561669159929909
Validation loss: 2.419169952649879

Epoch: 6| Step: 4
Training loss: 0.9414017230039786
Validation loss: 2.4313294267374723

Epoch: 6| Step: 5
Training loss: 0.694097142529373
Validation loss: 2.4555217372710674

Epoch: 6| Step: 6
Training loss: 1.4233787884627045
Validation loss: 2.489694855853564

Epoch: 6| Step: 7
Training loss: 0.6597980001218077
Validation loss: 2.438057380602461

Epoch: 6| Step: 8
Training loss: 0.9321816590829819
Validation loss: 2.4491314689354797

Epoch: 6| Step: 9
Training loss: 0.7826132515069791
Validation loss: 2.4367543666372504

Epoch: 6| Step: 10
Training loss: 1.202420759306489
Validation loss: 2.4542433603060863

Epoch: 6| Step: 11
Training loss: 0.7419255647725215
Validation loss: 2.476771206554977

Epoch: 6| Step: 12
Training loss: 0.9280782283210861
Validation loss: 2.468455793348531

Epoch: 6| Step: 13
Training loss: 0.8859555493220022
Validation loss: 2.5007660563736773

Epoch: 241| Step: 0
Training loss: 1.2122010560542638
Validation loss: 2.536925929953603

Epoch: 6| Step: 1
Training loss: 0.8708969030646909
Validation loss: 2.5510807357466367

Epoch: 6| Step: 2
Training loss: 0.9050949891963737
Validation loss: 2.5440132213141133

Epoch: 6| Step: 3
Training loss: 0.9425573632063835
Validation loss: 2.5752216217854733

Epoch: 6| Step: 4
Training loss: 1.0156727706238335
Validation loss: 2.541552661280227

Epoch: 6| Step: 5
Training loss: 0.8263978761741696
Validation loss: 2.493102384170435

Epoch: 6| Step: 6
Training loss: 0.8845672048091731
Validation loss: 2.505698689309281

Epoch: 6| Step: 7
Training loss: 1.1423160611087906
Validation loss: 2.464087824917263

Epoch: 6| Step: 8
Training loss: 0.5548027617285404
Validation loss: 2.4504617279810392

Epoch: 6| Step: 9
Training loss: 0.30338424333119013
Validation loss: 2.456623763215423

Epoch: 6| Step: 10
Training loss: 0.8150964478603592
Validation loss: 2.4577669089368497

Epoch: 6| Step: 11
Training loss: 0.9711820161805671
Validation loss: 2.467033069575453

Epoch: 6| Step: 12
Training loss: 0.7305156672297003
Validation loss: 2.490764291138716

Epoch: 6| Step: 13
Training loss: 0.9110549942589852
Validation loss: 2.4421868527985846

Epoch: 242| Step: 0
Training loss: 1.0351584380504588
Validation loss: 2.485441004336004

Epoch: 6| Step: 1
Training loss: 1.0213744357813284
Validation loss: 2.498416468851611

Epoch: 6| Step: 2
Training loss: 0.4585713577652432
Validation loss: 2.4475679259567706

Epoch: 6| Step: 3
Training loss: 0.8040831064548173
Validation loss: 2.4137578837687292

Epoch: 6| Step: 4
Training loss: 0.6907933422687785
Validation loss: 2.367955385466658

Epoch: 6| Step: 5
Training loss: 1.1608019229795432
Validation loss: 2.4246843412296

Epoch: 6| Step: 6
Training loss: 0.8770731140834084
Validation loss: 2.4271771344494186

Epoch: 6| Step: 7
Training loss: 1.1643096354264666
Validation loss: 2.425643041112585

Epoch: 6| Step: 8
Training loss: 0.6788422382058512
Validation loss: 2.4530666143981805

Epoch: 6| Step: 9
Training loss: 0.6650710133230915
Validation loss: 2.473594823446571

Epoch: 6| Step: 10
Training loss: 1.156190406706992
Validation loss: 2.511974950065254

Epoch: 6| Step: 11
Training loss: 0.8106808838886432
Validation loss: 2.508176730945238

Epoch: 6| Step: 12
Training loss: 0.7215005241862698
Validation loss: 2.490673884051798

Epoch: 6| Step: 13
Training loss: 0.7588916056309606
Validation loss: 2.4779051113609487

Epoch: 243| Step: 0
Training loss: 0.6645695938037405
Validation loss: 2.488073288440239

Epoch: 6| Step: 1
Training loss: 0.6799428832735799
Validation loss: 2.4944774511932715

Epoch: 6| Step: 2
Training loss: 0.8426263886459944
Validation loss: 2.468476389994057

Epoch: 6| Step: 3
Training loss: 1.145421641979511
Validation loss: 2.4579941901661106

Epoch: 6| Step: 4
Training loss: 0.6118831369796093
Validation loss: 2.4681154221882178

Epoch: 6| Step: 5
Training loss: 0.5710224801196284
Validation loss: 2.460620878119368

Epoch: 6| Step: 6
Training loss: 0.467796149926898
Validation loss: 2.4620594941783938

Epoch: 6| Step: 7
Training loss: 1.2727248180972617
Validation loss: 2.4598562557863684

Epoch: 6| Step: 8
Training loss: 0.8466040765600649
Validation loss: 2.4656372977086205

Epoch: 6| Step: 9
Training loss: 1.2482774309612494
Validation loss: 2.5179124950266663

Epoch: 6| Step: 10
Training loss: 0.8127957319372862
Validation loss: 2.457642778571871

Epoch: 6| Step: 11
Training loss: 0.6688507458747331
Validation loss: 2.4535460389355968

Epoch: 6| Step: 12
Training loss: 0.6028968577194391
Validation loss: 2.4468489294785294

Epoch: 6| Step: 13
Training loss: 0.8974713313483577
Validation loss: 2.4214630993998787

Epoch: 244| Step: 0
Training loss: 1.0393225552373397
Validation loss: 2.422414592925218

Epoch: 6| Step: 1
Training loss: 0.626643261734509
Validation loss: 2.4180682922863315

Epoch: 6| Step: 2
Training loss: 0.8007067389829576
Validation loss: 2.427568228703867

Epoch: 6| Step: 3
Training loss: 0.63381562963446
Validation loss: 2.4902184520182606

Epoch: 6| Step: 4
Training loss: 0.7800127150037199
Validation loss: 2.4701358295474747

Epoch: 6| Step: 5
Training loss: 0.6357825950520205
Validation loss: 2.4529884571569225

Epoch: 6| Step: 6
Training loss: 1.116134948012828
Validation loss: 2.4846306063945054

Epoch: 6| Step: 7
Training loss: 0.9580921443175605
Validation loss: 2.491326226119242

Epoch: 6| Step: 8
Training loss: 0.8971756075792038
Validation loss: 2.4862523352650174

Epoch: 6| Step: 9
Training loss: 0.7660822767860875
Validation loss: 2.481029830673658

Epoch: 6| Step: 10
Training loss: 0.9669455057586609
Validation loss: 2.4759795923441823

Epoch: 6| Step: 11
Training loss: 0.598222003512833
Validation loss: 2.4820247777997206

Epoch: 6| Step: 12
Training loss: 0.8280809498713244
Validation loss: 2.49249662213617

Epoch: 6| Step: 13
Training loss: 0.9140954949056267
Validation loss: 2.449241383595771

Epoch: 245| Step: 0
Training loss: 0.8671301745463392
Validation loss: 2.4301256588544264

Epoch: 6| Step: 1
Training loss: 0.5046586917178211
Validation loss: 2.4086443523279337

Epoch: 6| Step: 2
Training loss: 0.6216505661644509
Validation loss: 2.3913028642579373

Epoch: 6| Step: 3
Training loss: 0.490336631657593
Validation loss: 2.3934912820515017

Epoch: 6| Step: 4
Training loss: 0.8547121647652959
Validation loss: 2.33883939234093

Epoch: 6| Step: 5
Training loss: 1.1460882539103796
Validation loss: 2.380895580077137

Epoch: 6| Step: 6
Training loss: 0.8811258729131333
Validation loss: 2.4036941506576763

Epoch: 6| Step: 7
Training loss: 0.7779220270368222
Validation loss: 2.416947704016463

Epoch: 6| Step: 8
Training loss: 1.1613184184603187
Validation loss: 2.453033279387838

Epoch: 6| Step: 9
Training loss: 0.5421308185510544
Validation loss: 2.417899500129736

Epoch: 6| Step: 10
Training loss: 0.7762679126534028
Validation loss: 2.432696065617113

Epoch: 6| Step: 11
Training loss: 1.178674730504905
Validation loss: 2.464566001144272

Epoch: 6| Step: 12
Training loss: 0.6269189938200285
Validation loss: 2.4668194538357806

Epoch: 6| Step: 13
Training loss: 0.9631937722042799
Validation loss: 2.4749298060475335

Epoch: 246| Step: 0
Training loss: 0.7062433816380252
Validation loss: 2.487017288693242

Epoch: 6| Step: 1
Training loss: 0.6324176733997774
Validation loss: 2.4956119892869513

Epoch: 6| Step: 2
Training loss: 0.7245845739022403
Validation loss: 2.4984122802825808

Epoch: 6| Step: 3
Training loss: 0.8145079377023524
Validation loss: 2.510697772654359

Epoch: 6| Step: 4
Training loss: 0.6106180082485084
Validation loss: 2.5044080736817795

Epoch: 6| Step: 5
Training loss: 0.7147940946749176
Validation loss: 2.5285287690153826

Epoch: 6| Step: 6
Training loss: 0.7017037544695314
Validation loss: 2.5093923892667847

Epoch: 6| Step: 7
Training loss: 1.2287756518832609
Validation loss: 2.4928230264572235

Epoch: 6| Step: 8
Training loss: 1.2855153611109995
Validation loss: 2.4679284598656093

Epoch: 6| Step: 9
Training loss: 0.6631283416448127
Validation loss: 2.4863138216082508

Epoch: 6| Step: 10
Training loss: 0.9061389723542621
Validation loss: 2.463730353450965

Epoch: 6| Step: 11
Training loss: 0.8897357985715566
Validation loss: 2.4363037015552296

Epoch: 6| Step: 12
Training loss: 0.5068600746243328
Validation loss: 2.441701515243334

Epoch: 6| Step: 13
Training loss: 0.8708351675193733
Validation loss: 2.4444659758235123

Epoch: 247| Step: 0
Training loss: 0.2564449016861193
Validation loss: 2.434285166542218

Epoch: 6| Step: 1
Training loss: 0.8747712926330962
Validation loss: 2.438590885519002

Epoch: 6| Step: 2
Training loss: 0.691372714333902
Validation loss: 2.4460820081511945

Epoch: 6| Step: 3
Training loss: 0.7260554195143204
Validation loss: 2.4669912586421834

Epoch: 6| Step: 4
Training loss: 0.7493110512370964
Validation loss: 2.459342128724069

Epoch: 6| Step: 5
Training loss: 0.9931530196964748
Validation loss: 2.4467120060029885

Epoch: 6| Step: 6
Training loss: 0.6286505896244304
Validation loss: 2.492228378015682

Epoch: 6| Step: 7
Training loss: 0.798903520006081
Validation loss: 2.4619260782634886

Epoch: 6| Step: 8
Training loss: 0.9732551416143205
Validation loss: 2.472619363626008

Epoch: 6| Step: 9
Training loss: 0.8644723054918723
Validation loss: 2.468111425253121

Epoch: 6| Step: 10
Training loss: 1.2879093445333518
Validation loss: 2.4682719592209437

Epoch: 6| Step: 11
Training loss: 0.8319867260979028
Validation loss: 2.4672954184379825

Epoch: 6| Step: 12
Training loss: 0.5937827502805348
Validation loss: 2.4755565147320473

Epoch: 6| Step: 13
Training loss: 0.6852167100665936
Validation loss: 2.475966655965436

Epoch: 248| Step: 0
Training loss: 1.1256677447245997
Validation loss: 2.478644711017213

Epoch: 6| Step: 1
Training loss: 0.7077404280257463
Validation loss: 2.474419156965959

Epoch: 6| Step: 2
Training loss: 0.7929566856932285
Validation loss: 2.5130208754992442

Epoch: 6| Step: 3
Training loss: 0.915330968522668
Validation loss: 2.5158954740684583

Epoch: 6| Step: 4
Training loss: 0.589200458510765
Validation loss: 2.4714037348879363

Epoch: 6| Step: 5
Training loss: 0.5167651431259895
Validation loss: 2.498086186530327

Epoch: 6| Step: 6
Training loss: 0.6816892196690941
Validation loss: 2.5283504201282856

Epoch: 6| Step: 7
Training loss: 0.7363308772432814
Validation loss: 2.4788924031308337

Epoch: 6| Step: 8
Training loss: 0.7952290909053156
Validation loss: 2.46262178927202

Epoch: 6| Step: 9
Training loss: 0.9574038033431582
Validation loss: 2.4643267561001956

Epoch: 6| Step: 10
Training loss: 0.9784039644959509
Validation loss: 2.4648540967181294

Epoch: 6| Step: 11
Training loss: 0.7559549433890397
Validation loss: 2.490966522471213

Epoch: 6| Step: 12
Training loss: 0.7982783209283493
Validation loss: 2.4932844348069825

Epoch: 6| Step: 13
Training loss: 0.669616607424005
Validation loss: 2.475677426280226

Epoch: 249| Step: 0
Training loss: 0.5869571460518611
Validation loss: 2.4840127953463735

Epoch: 6| Step: 1
Training loss: 1.0864669277671715
Validation loss: 2.4621118408157874

Epoch: 6| Step: 2
Training loss: 0.7288176291543462
Validation loss: 2.4584152961639596

Epoch: 6| Step: 3
Training loss: 1.0217585879404338
Validation loss: 2.4559303693398777

Epoch: 6| Step: 4
Training loss: 0.7378323921259077
Validation loss: 2.3938874255711404

Epoch: 6| Step: 5
Training loss: 0.7223235318050383
Validation loss: 2.425769475818121

Epoch: 6| Step: 6
Training loss: 0.6355184228644317
Validation loss: 2.430983510427709

Epoch: 6| Step: 7
Training loss: 1.0996440658382163
Validation loss: 2.410541562591683

Epoch: 6| Step: 8
Training loss: 0.7799109236276875
Validation loss: 2.4000223961164586

Epoch: 6| Step: 9
Training loss: 0.6582920908584192
Validation loss: 2.421772274362026

Epoch: 6| Step: 10
Training loss: 0.6715978671879553
Validation loss: 2.440288910774719

Epoch: 6| Step: 11
Training loss: 0.717338253624195
Validation loss: 2.462395142877069

Epoch: 6| Step: 12
Training loss: 0.8554698647966481
Validation loss: 2.478724515648416

Epoch: 6| Step: 13
Training loss: 0.5694208359928793
Validation loss: 2.457309439457216

Epoch: 250| Step: 0
Training loss: 0.7529445305337162
Validation loss: 2.483952797070648

Epoch: 6| Step: 1
Training loss: 0.8665632458259572
Validation loss: 2.497688975744235

Epoch: 6| Step: 2
Training loss: 0.665018089736756
Validation loss: 2.4732739639357075

Epoch: 6| Step: 3
Training loss: 0.8275035829841053
Validation loss: 2.449525075808719

Epoch: 6| Step: 4
Training loss: 0.8016181108543639
Validation loss: 2.463369462651791

Epoch: 6| Step: 5
Training loss: 0.34734957809809747
Validation loss: 2.4036541368704616

Epoch: 6| Step: 6
Training loss: 0.6887194482358516
Validation loss: 2.4291418627689767

Epoch: 6| Step: 7
Training loss: 0.9830167876466172
Validation loss: 2.386992974076796

Epoch: 6| Step: 8
Training loss: 0.707330208478755
Validation loss: 2.4373323957710205

Epoch: 6| Step: 9
Training loss: 0.827813323766832
Validation loss: 2.4380664403919683

Epoch: 6| Step: 10
Training loss: 0.45805740901279524
Validation loss: 2.441226965443333

Epoch: 6| Step: 11
Training loss: 0.9392594675171269
Validation loss: 2.4505555147376694

Epoch: 6| Step: 12
Training loss: 1.0671371917260526
Validation loss: 2.460015193152963

Epoch: 6| Step: 13
Training loss: 0.533221401697838
Validation loss: 2.4118038147859004

Epoch: 251| Step: 0
Training loss: 0.35727772124780094
Validation loss: 2.4504513147389173

Epoch: 6| Step: 1
Training loss: 0.9375643072325123
Validation loss: 2.4426267215696895

Epoch: 6| Step: 2
Training loss: 0.7306300510463585
Validation loss: 2.432243685205063

Epoch: 6| Step: 3
Training loss: 0.8820891666234489
Validation loss: 2.4556209505697706

Epoch: 6| Step: 4
Training loss: 0.9486110924316921
Validation loss: 2.4617120636230125

Epoch: 6| Step: 5
Training loss: 0.6800230885891507
Validation loss: 2.494516990602393

Epoch: 6| Step: 6
Training loss: 1.2177043243594565
Validation loss: 2.46773427678828

Epoch: 6| Step: 7
Training loss: 0.5771630248212722
Validation loss: 2.464762284198724

Epoch: 6| Step: 8
Training loss: 0.7851729130281552
Validation loss: 2.4576676748267983

Epoch: 6| Step: 9
Training loss: 0.6005798091420691
Validation loss: 2.4658976674503195

Epoch: 6| Step: 10
Training loss: 0.7094432512295031
Validation loss: 2.4619068648848415

Epoch: 6| Step: 11
Training loss: 0.5649377399084926
Validation loss: 2.451269572184256

Epoch: 6| Step: 12
Training loss: 0.7873912524265736
Validation loss: 2.4639023309967807

Epoch: 6| Step: 13
Training loss: 0.5855484242892748
Validation loss: 2.4514237986959126

Epoch: 252| Step: 0
Training loss: 0.7013513871880107
Validation loss: 2.47130566247725

Epoch: 6| Step: 1
Training loss: 0.6596881629004462
Validation loss: 2.4521400329751875

Epoch: 6| Step: 2
Training loss: 0.636918721069406
Validation loss: 2.421077234595788

Epoch: 6| Step: 3
Training loss: 0.62877165497333
Validation loss: 2.4450159743266755

Epoch: 6| Step: 4
Training loss: 1.0358969287781492
Validation loss: 2.4329260213889734

Epoch: 6| Step: 5
Training loss: 0.6558658292815189
Validation loss: 2.4318179317662807

Epoch: 6| Step: 6
Training loss: 0.6952244777898745
Validation loss: 2.4137074751426058

Epoch: 6| Step: 7
Training loss: 0.7334778357955559
Validation loss: 2.468547705278488

Epoch: 6| Step: 8
Training loss: 0.7795384924011779
Validation loss: 2.4452197964731974

Epoch: 6| Step: 9
Training loss: 1.0352984636612057
Validation loss: 2.4667844641388568

Epoch: 6| Step: 10
Training loss: 0.6623358325165568
Validation loss: 2.4620878662294

Epoch: 6| Step: 11
Training loss: 0.5628871644950773
Validation loss: 2.4872237708167737

Epoch: 6| Step: 12
Training loss: 0.8612450107601582
Validation loss: 2.488743010061726

Epoch: 6| Step: 13
Training loss: 0.83863310384481
Validation loss: 2.465099002129903

Epoch: 253| Step: 0
Training loss: 0.6710606674548759
Validation loss: 2.4362137879373864

Epoch: 6| Step: 1
Training loss: 0.9587366906924578
Validation loss: 2.4151429714842836

Epoch: 6| Step: 2
Training loss: 0.5766275963566658
Validation loss: 2.4012645646178776

Epoch: 6| Step: 3
Training loss: 0.5471804991687642
Validation loss: 2.377132808478193

Epoch: 6| Step: 4
Training loss: 0.8138898552927551
Validation loss: 2.3996039763271524

Epoch: 6| Step: 5
Training loss: 0.5651900816502741
Validation loss: 2.3829396036946737

Epoch: 6| Step: 6
Training loss: 0.7434425584092652
Validation loss: 2.4025197898779815

Epoch: 6| Step: 7
Training loss: 0.5172246913848698
Validation loss: 2.4478422099047923

Epoch: 6| Step: 8
Training loss: 0.8284117723957451
Validation loss: 2.4429556071663603

Epoch: 6| Step: 9
Training loss: 0.6844323817892453
Validation loss: 2.460654608344714

Epoch: 6| Step: 10
Training loss: 0.8508961721660785
Validation loss: 2.4909905680014015

Epoch: 6| Step: 11
Training loss: 1.0014155620797311
Validation loss: 2.494939619132652

Epoch: 6| Step: 12
Training loss: 0.7375948505507343
Validation loss: 2.4959080268326788

Epoch: 6| Step: 13
Training loss: 0.7923564331989427
Validation loss: 2.5025727078186204

Epoch: 254| Step: 0
Training loss: 0.8452487632428757
Validation loss: 2.4680869189552395

Epoch: 6| Step: 1
Training loss: 0.43164468133323636
Validation loss: 2.4724276906714353

Epoch: 6| Step: 2
Training loss: 0.6461980364215644
Validation loss: 2.453301854914201

Epoch: 6| Step: 3
Training loss: 0.7723649805705994
Validation loss: 2.4650049200618125

Epoch: 6| Step: 4
Training loss: 0.8011205187127742
Validation loss: 2.4556373213027194

Epoch: 6| Step: 5
Training loss: 0.8604847418492397
Validation loss: 2.4643381442446946

Epoch: 6| Step: 6
Training loss: 0.7280775292111241
Validation loss: 2.480356247630613

Epoch: 6| Step: 7
Training loss: 0.6444853332809837
Validation loss: 2.46407904339287

Epoch: 6| Step: 8
Training loss: 0.9420325384290966
Validation loss: 2.5168716520219867

Epoch: 6| Step: 9
Training loss: 0.5755341184529797
Validation loss: 2.5132181817709065

Epoch: 6| Step: 10
Training loss: 0.5385318300196145
Validation loss: 2.5044373683639796

Epoch: 6| Step: 11
Training loss: 1.1356026849984369
Validation loss: 2.5008397220019694

Epoch: 6| Step: 12
Training loss: 0.4947568646957556
Validation loss: 2.4660432857490955

Epoch: 6| Step: 13
Training loss: 0.773501807727933
Validation loss: 2.466427631929869

Epoch: 255| Step: 0
Training loss: 0.8208528464720204
Validation loss: 2.43316165027921

Epoch: 6| Step: 1
Training loss: 0.6421057869559966
Validation loss: 2.423078126867108

Epoch: 6| Step: 2
Training loss: 0.8237611485654469
Validation loss: 2.4197752234590504

Epoch: 6| Step: 3
Training loss: 0.6353796703220261
Validation loss: 2.4167067645023947

Epoch: 6| Step: 4
Training loss: 0.6319172495858114
Validation loss: 2.439730273612253

Epoch: 6| Step: 5
Training loss: 0.6288486241068001
Validation loss: 2.4171248158344176

Epoch: 6| Step: 6
Training loss: 1.0780788356461808
Validation loss: 2.4413964633540406

Epoch: 6| Step: 7
Training loss: 0.8312990073765408
Validation loss: 2.4524298830598097

Epoch: 6| Step: 8
Training loss: 0.6956882104661833
Validation loss: 2.468402643405164

Epoch: 6| Step: 9
Training loss: 0.6326023035280063
Validation loss: 2.4762595768355657

Epoch: 6| Step: 10
Training loss: 0.6327983242378038
Validation loss: 2.484631892016359

Epoch: 6| Step: 11
Training loss: 0.72997679438352
Validation loss: 2.5090763410056716

Epoch: 6| Step: 12
Training loss: 0.8351958362700275
Validation loss: 2.500602752051587

Epoch: 6| Step: 13
Training loss: 0.4537134296087693
Validation loss: 2.441482794498989

Epoch: 256| Step: 0
Training loss: 0.677427546719712
Validation loss: 2.471593092778143

Epoch: 6| Step: 1
Training loss: 0.9612364885350401
Validation loss: 2.4915661588421028

Epoch: 6| Step: 2
Training loss: 0.7310671064100115
Validation loss: 2.494664886053093

Epoch: 6| Step: 3
Training loss: 0.6435774247779418
Validation loss: 2.485380173056389

Epoch: 6| Step: 4
Training loss: 0.5929764175421898
Validation loss: 2.4998886986023936

Epoch: 6| Step: 5
Training loss: 0.5014525711949893
Validation loss: 2.4792550389115977

Epoch: 6| Step: 6
Training loss: 0.43830569194019536
Validation loss: 2.459497074829756

Epoch: 6| Step: 7
Training loss: 0.43760220151352697
Validation loss: 2.48400300421056

Epoch: 6| Step: 8
Training loss: 0.7674137939350753
Validation loss: 2.4992289061545234

Epoch: 6| Step: 9
Training loss: 0.45911207654603664
Validation loss: 2.4665378832796057

Epoch: 6| Step: 10
Training loss: 0.564339702258567
Validation loss: 2.448104585875908

Epoch: 6| Step: 11
Training loss: 1.2404325552168276
Validation loss: 2.477131585739319

Epoch: 6| Step: 12
Training loss: 0.7528392376235021
Validation loss: 2.4481882824794168

Epoch: 6| Step: 13
Training loss: 0.9827428638429146
Validation loss: 2.4718878552832284

Epoch: 257| Step: 0
Training loss: 0.8969699982098613
Validation loss: 2.490499041698466

Epoch: 6| Step: 1
Training loss: 0.8017745393780811
Validation loss: 2.489752887051558

Epoch: 6| Step: 2
Training loss: 0.6817137889344929
Validation loss: 2.468838425456261

Epoch: 6| Step: 3
Training loss: 0.48452747160205045
Validation loss: 2.4565052158201177

Epoch: 6| Step: 4
Training loss: 0.8028189807123918
Validation loss: 2.4981015934519863

Epoch: 6| Step: 5
Training loss: 0.5736655340580655
Validation loss: 2.4687630043087077

Epoch: 6| Step: 6
Training loss: 0.39959537336145484
Validation loss: 2.460124908637255

Epoch: 6| Step: 7
Training loss: 0.47824331826678707
Validation loss: 2.472425983428073

Epoch: 6| Step: 8
Training loss: 0.7855461253385984
Validation loss: 2.4651102972694194

Epoch: 6| Step: 9
Training loss: 0.5742476060325002
Validation loss: 2.439983445875771

Epoch: 6| Step: 10
Training loss: 0.763719093833717
Validation loss: 2.4262546556045432

Epoch: 6| Step: 11
Training loss: 1.251742007446981
Validation loss: 2.4585309151709143

Epoch: 6| Step: 12
Training loss: 0.603209359193979
Validation loss: 2.4811707652791815

Epoch: 6| Step: 13
Training loss: 0.2956864255274036
Validation loss: 2.4855069696504914

Epoch: 258| Step: 0
Training loss: 0.6842931602700354
Validation loss: 2.492298737983249

Epoch: 6| Step: 1
Training loss: 0.7682603905146138
Validation loss: 2.4783189623245616

Epoch: 6| Step: 2
Training loss: 0.7117553031571072
Validation loss: 2.5136663900858722

Epoch: 6| Step: 3
Training loss: 1.0089690794691828
Validation loss: 2.506284201867893

Epoch: 6| Step: 4
Training loss: 0.7118749620874678
Validation loss: 2.4910624520903046

Epoch: 6| Step: 5
Training loss: 0.6204654706773673
Validation loss: 2.4723773697877927

Epoch: 6| Step: 6
Training loss: 0.5931628988717441
Validation loss: 2.4736108016171476

Epoch: 6| Step: 7
Training loss: 0.49614165668009663
Validation loss: 2.45773407942721

Epoch: 6| Step: 8
Training loss: 0.5678370851811344
Validation loss: 2.4204603643844034

Epoch: 6| Step: 9
Training loss: 0.6137474863346625
Validation loss: 2.4522611263373917

Epoch: 6| Step: 10
Training loss: 0.5564190875454893
Validation loss: 2.420757417711814

Epoch: 6| Step: 11
Training loss: 0.7424800095612565
Validation loss: 2.463335911919026

Epoch: 6| Step: 12
Training loss: 0.6665687166220079
Validation loss: 2.415362519285258

Epoch: 6| Step: 13
Training loss: 1.2399541583355247
Validation loss: 2.421487219996105

Epoch: 259| Step: 0
Training loss: 0.5461706257466034
Validation loss: 2.4100090488881274

Epoch: 6| Step: 1
Training loss: 0.4152473734761677
Validation loss: 2.4179994248300174

Epoch: 6| Step: 2
Training loss: 0.9824841822741394
Validation loss: 2.3989639530158184

Epoch: 6| Step: 3
Training loss: 0.5400912930442027
Validation loss: 2.420034974934571

Epoch: 6| Step: 4
Training loss: 0.948290744092213
Validation loss: 2.424144369422916

Epoch: 6| Step: 5
Training loss: 0.6608111501997621
Validation loss: 2.424913378438001

Epoch: 6| Step: 6
Training loss: 0.987895996030881
Validation loss: 2.448717129300622

Epoch: 6| Step: 7
Training loss: 0.7419173702748109
Validation loss: 2.449413513917066

Epoch: 6| Step: 8
Training loss: 0.4602521553548544
Validation loss: 2.45646791576677

Epoch: 6| Step: 9
Training loss: 0.41867495974688973
Validation loss: 2.4419528978902436

Epoch: 6| Step: 10
Training loss: 0.45483445942025147
Validation loss: 2.4430721655787115

Epoch: 6| Step: 11
Training loss: 0.9966943164539003
Validation loss: 2.4688391897181896

Epoch: 6| Step: 12
Training loss: 0.7609065102409874
Validation loss: 2.4526373986908934

Epoch: 6| Step: 13
Training loss: 0.3331870103094352
Validation loss: 2.4550511829429222

Epoch: 260| Step: 0
Training loss: 0.9119246824769138
Validation loss: 2.4901323774128388

Epoch: 6| Step: 1
Training loss: 0.655838769403861
Validation loss: 2.4850027021834644

Epoch: 6| Step: 2
Training loss: 0.757672641078869
Validation loss: 2.49775825199391

Epoch: 6| Step: 3
Training loss: 0.6451721472893768
Validation loss: 2.5027953476051032

Epoch: 6| Step: 4
Training loss: 0.38441451265029436
Validation loss: 2.4892316286543625

Epoch: 6| Step: 5
Training loss: 0.9727474614161472
Validation loss: 2.4770111969396633

Epoch: 6| Step: 6
Training loss: 0.8255970355141445
Validation loss: 2.46915179869648

Epoch: 6| Step: 7
Training loss: 0.34170992153922597
Validation loss: 2.464389051634434

Epoch: 6| Step: 8
Training loss: 0.6835079030219766
Validation loss: 2.4676297128977533

Epoch: 6| Step: 9
Training loss: 0.5383069368608884
Validation loss: 2.4389420338501777

Epoch: 6| Step: 10
Training loss: 0.686056615962182
Validation loss: 2.43166907364226

Epoch: 6| Step: 11
Training loss: 0.4122197514107497
Validation loss: 2.429512101741577

Epoch: 6| Step: 12
Training loss: 0.7709785058381239
Validation loss: 2.4172561451324333

Epoch: 6| Step: 13
Training loss: 0.9534155605996487
Validation loss: 2.4384180947762286

Epoch: 261| Step: 0
Training loss: 0.6549711482413053
Validation loss: 2.3797159722157564

Epoch: 6| Step: 1
Training loss: 0.3833620836353874
Validation loss: 2.4065682454175787

Epoch: 6| Step: 2
Training loss: 1.1784815908846502
Validation loss: 2.3706339193445127

Epoch: 6| Step: 3
Training loss: 0.36081950500734916
Validation loss: 2.395492409253096

Epoch: 6| Step: 4
Training loss: 0.5493536499961144
Validation loss: 2.424622387415811

Epoch: 6| Step: 5
Training loss: 0.5489065039656106
Validation loss: 2.390339963540682

Epoch: 6| Step: 6
Training loss: 0.7501248017425097
Validation loss: 2.4175097282470053

Epoch: 6| Step: 7
Training loss: 0.5382468922671951
Validation loss: 2.4340498396840027

Epoch: 6| Step: 8
Training loss: 0.7393392016659787
Validation loss: 2.458420211406748

Epoch: 6| Step: 9
Training loss: 0.7325237559349411
Validation loss: 2.455799079908708

Epoch: 6| Step: 10
Training loss: 0.6025613196418501
Validation loss: 2.4721587015732673

Epoch: 6| Step: 11
Training loss: 0.7149272098702796
Validation loss: 2.486288224910039

Epoch: 6| Step: 12
Training loss: 0.5304847703629828
Validation loss: 2.4760664550532185

Epoch: 6| Step: 13
Training loss: 1.1847103378924182
Validation loss: 2.467520033965145

Epoch: 262| Step: 0
Training loss: 0.7315109895726793
Validation loss: 2.512476676384113

Epoch: 6| Step: 1
Training loss: 0.6921606958508201
Validation loss: 2.5195999582570545

Epoch: 6| Step: 2
Training loss: 0.6067610209139586
Validation loss: 2.4728682916536444

Epoch: 6| Step: 3
Training loss: 0.8903681066680814
Validation loss: 2.4962086528900382

Epoch: 6| Step: 4
Training loss: 0.5855121849121268
Validation loss: 2.4933359099674166

Epoch: 6| Step: 5
Training loss: 0.47557550375770913
Validation loss: 2.456398966419561

Epoch: 6| Step: 6
Training loss: 0.3259416327209926
Validation loss: 2.4636593711436077

Epoch: 6| Step: 7
Training loss: 0.7189534770042896
Validation loss: 2.4394859152088753

Epoch: 6| Step: 8
Training loss: 0.5478117957276574
Validation loss: 2.462066676769777

Epoch: 6| Step: 9
Training loss: 0.42909904413261263
Validation loss: 2.4449300615343583

Epoch: 6| Step: 10
Training loss: 0.7695150615712771
Validation loss: 2.4431390550286807

Epoch: 6| Step: 11
Training loss: 0.8180153790639464
Validation loss: 2.446735675467025

Epoch: 6| Step: 12
Training loss: 1.0699553624762346
Validation loss: 2.4693192697551694

Epoch: 6| Step: 13
Training loss: 0.39279684929331893
Validation loss: 2.4760525562305884

Epoch: 263| Step: 0
Training loss: 0.5436929497441841
Validation loss: 2.4891297043001894

Epoch: 6| Step: 1
Training loss: 0.9984771338582414
Validation loss: 2.477942235634754

Epoch: 6| Step: 2
Training loss: 0.6239904117351919
Validation loss: 2.5122160904869273

Epoch: 6| Step: 3
Training loss: 0.6701802903619747
Validation loss: 2.482141337949503

Epoch: 6| Step: 4
Training loss: 0.6195041780461764
Validation loss: 2.457589978942308

Epoch: 6| Step: 5
Training loss: 0.9843761504635824
Validation loss: 2.448376663195288

Epoch: 6| Step: 6
Training loss: 0.8992907908703333
Validation loss: 2.4167368575975274

Epoch: 6| Step: 7
Training loss: 0.5213638909417817
Validation loss: 2.469517173378815

Epoch: 6| Step: 8
Training loss: 0.5873852455396746
Validation loss: 2.437656478549967

Epoch: 6| Step: 9
Training loss: 0.39526836540917987
Validation loss: 2.4611517408448047

Epoch: 6| Step: 10
Training loss: 0.5358148962866345
Validation loss: 2.500918893218509

Epoch: 6| Step: 11
Training loss: 0.643252080182338
Validation loss: 2.471715729103366

Epoch: 6| Step: 12
Training loss: 0.435144811921662
Validation loss: 2.495262904214995

Epoch: 6| Step: 13
Training loss: 0.8529912529370555
Validation loss: 2.4826610222762624

Epoch: 264| Step: 0
Training loss: 0.7299911651337987
Validation loss: 2.469982817089676

Epoch: 6| Step: 1
Training loss: 0.6884179489400247
Validation loss: 2.4969859679282522

Epoch: 6| Step: 2
Training loss: 0.5967629182645449
Validation loss: 2.485918195865107

Epoch: 6| Step: 3
Training loss: 0.5980716084773239
Validation loss: 2.4431065462785324

Epoch: 6| Step: 4
Training loss: 0.9170384339522256
Validation loss: 2.466936073568249

Epoch: 6| Step: 5
Training loss: 0.4591170910445643
Validation loss: 2.4469175643570438

Epoch: 6| Step: 6
Training loss: 0.5230318746773298
Validation loss: 2.4431630198617

Epoch: 6| Step: 7
Training loss: 0.5569503993014353
Validation loss: 2.467471588087888

Epoch: 6| Step: 8
Training loss: 0.5892735940339096
Validation loss: 2.435668593862565

Epoch: 6| Step: 9
Training loss: 0.7542564883055777
Validation loss: 2.4308538793102303

Epoch: 6| Step: 10
Training loss: 0.5223724575523984
Validation loss: 2.420088124103364

Epoch: 6| Step: 11
Training loss: 0.6624738427162606
Validation loss: 2.4268012430599666

Epoch: 6| Step: 12
Training loss: 0.4821956273875475
Validation loss: 2.446560507627776

Epoch: 6| Step: 13
Training loss: 1.186655095335089
Validation loss: 2.446753764273582

Epoch: 265| Step: 0
Training loss: 0.4352022013210185
Validation loss: 2.4615454440290483

Epoch: 6| Step: 1
Training loss: 0.27408486437048557
Validation loss: 2.427633389465694

Epoch: 6| Step: 2
Training loss: 0.652163817666188
Validation loss: 2.4335490474658545

Epoch: 6| Step: 3
Training loss: 0.6051727555848602
Validation loss: 2.465263700803708

Epoch: 6| Step: 4
Training loss: 0.7399845154534042
Validation loss: 2.4630855042670965

Epoch: 6| Step: 5
Training loss: 0.6884103729680101
Validation loss: 2.461421170927809

Epoch: 6| Step: 6
Training loss: 0.7809319420930049
Validation loss: 2.4517549715533695

Epoch: 6| Step: 7
Training loss: 0.41227922961826396
Validation loss: 2.455699536609098

Epoch: 6| Step: 8
Training loss: 0.5167569826260586
Validation loss: 2.473672700637297

Epoch: 6| Step: 9
Training loss: 0.7664482983983569
Validation loss: 2.456888939026608

Epoch: 6| Step: 10
Training loss: 0.9875349461130295
Validation loss: 2.4609065618880015

Epoch: 6| Step: 11
Training loss: 0.7450279892393715
Validation loss: 2.474536981877061

Epoch: 6| Step: 12
Training loss: 0.684655503918703
Validation loss: 2.4356862996399977

Epoch: 6| Step: 13
Training loss: 0.594869912696691
Validation loss: 2.430555315462053

Epoch: 266| Step: 0
Training loss: 0.8918476078609382
Validation loss: 2.447748220735898

Epoch: 6| Step: 1
Training loss: 0.6720440895753835
Validation loss: 2.474999769054811

Epoch: 6| Step: 2
Training loss: 0.788478899884486
Validation loss: 2.4620790718448555

Epoch: 6| Step: 3
Training loss: 0.8072544376443883
Validation loss: 2.489983274800095

Epoch: 6| Step: 4
Training loss: 0.5479099834116734
Validation loss: 2.452495525279466

Epoch: 6| Step: 5
Training loss: 0.5623817584481059
Validation loss: 2.4459806759461973

Epoch: 6| Step: 6
Training loss: 0.5539557775137443
Validation loss: 2.452190868462599

Epoch: 6| Step: 7
Training loss: 0.3796125494994402
Validation loss: 2.4244590118625395

Epoch: 6| Step: 8
Training loss: 0.5775067916074427
Validation loss: 2.4572975231825023

Epoch: 6| Step: 9
Training loss: 0.749503448142479
Validation loss: 2.430579275161004

Epoch: 6| Step: 10
Training loss: 0.560527841065398
Validation loss: 2.433154790115313

Epoch: 6| Step: 11
Training loss: 0.7337986734028404
Validation loss: 2.4329676385207057

Epoch: 6| Step: 12
Training loss: 0.3990501480759954
Validation loss: 2.470438949454608

Epoch: 6| Step: 13
Training loss: 0.786580554147213
Validation loss: 2.4244405187959

Epoch: 267| Step: 0
Training loss: 0.5606499553897112
Validation loss: 2.437016460458394

Epoch: 6| Step: 1
Training loss: 0.33522293698941097
Validation loss: 2.4320780609416697

Epoch: 6| Step: 2
Training loss: 0.6167446430841125
Validation loss: 2.4287223575345536

Epoch: 6| Step: 3
Training loss: 0.35404961652623185
Validation loss: 2.4456437661114268

Epoch: 6| Step: 4
Training loss: 0.6384405948080301
Validation loss: 2.420501726118797

Epoch: 6| Step: 5
Training loss: 0.4386838155532768
Validation loss: 2.4214026290475097

Epoch: 6| Step: 6
Training loss: 0.7117719678526868
Validation loss: 2.441802979358413

Epoch: 6| Step: 7
Training loss: 0.6108741659131804
Validation loss: 2.436523126583288

Epoch: 6| Step: 8
Training loss: 0.5917798785799953
Validation loss: 2.409509844931681

Epoch: 6| Step: 9
Training loss: 0.5491147904744071
Validation loss: 2.4025543400713363

Epoch: 6| Step: 10
Training loss: 0.7378725404073159
Validation loss: 2.4316462295691017

Epoch: 6| Step: 11
Training loss: 1.0037103602846962
Validation loss: 2.452416092801184

Epoch: 6| Step: 12
Training loss: 0.8490123536566957
Validation loss: 2.4570684110798195

Epoch: 6| Step: 13
Training loss: 0.7164447137622049
Validation loss: 2.4550109327277654

Epoch: 268| Step: 0
Training loss: 0.6514972974321547
Validation loss: 2.436802342744735

Epoch: 6| Step: 1
Training loss: 0.5435537027781179
Validation loss: 2.4862136336933736

Epoch: 6| Step: 2
Training loss: 0.7282372318592952
Validation loss: 2.4664387286940714

Epoch: 6| Step: 3
Training loss: 0.6466965802474036
Validation loss: 2.4660124168912403

Epoch: 6| Step: 4
Training loss: 0.5097570308969349
Validation loss: 2.471432131405359

Epoch: 6| Step: 5
Training loss: 0.6530552484600939
Validation loss: 2.451521994067515

Epoch: 6| Step: 6
Training loss: 1.099102275997426
Validation loss: 2.4490257464910927

Epoch: 6| Step: 7
Training loss: 0.6529117783747078
Validation loss: 2.4689571469724196

Epoch: 6| Step: 8
Training loss: 0.49966519292264594
Validation loss: 2.462569916218119

Epoch: 6| Step: 9
Training loss: 0.5226086844338406
Validation loss: 2.454260592595179

Epoch: 6| Step: 10
Training loss: 0.5682160239327092
Validation loss: 2.4130307764695798

Epoch: 6| Step: 11
Training loss: 0.4074951310832276
Validation loss: 2.485608687758416

Epoch: 6| Step: 12
Training loss: 0.5942101452325054
Validation loss: 2.456216125329843

Epoch: 6| Step: 13
Training loss: 0.45370855244581526
Validation loss: 2.4503695571933317

Epoch: 269| Step: 0
Training loss: 0.7079150750821704
Validation loss: 2.4281354561365456

Epoch: 6| Step: 1
Training loss: 0.5290353276619896
Validation loss: 2.4414281522035033

Epoch: 6| Step: 2
Training loss: 0.8108189137801384
Validation loss: 2.4642581910135357

Epoch: 6| Step: 3
Training loss: 0.6244595575210132
Validation loss: 2.4412389076553485

Epoch: 6| Step: 4
Training loss: 0.25458185836741404
Validation loss: 2.478593131408199

Epoch: 6| Step: 5
Training loss: 0.6455065659411422
Validation loss: 2.4520378172622563

Epoch: 6| Step: 6
Training loss: 0.7339368284050709
Validation loss: 2.487975347609066

Epoch: 6| Step: 7
Training loss: 0.4663112939886233
Validation loss: 2.487769916112876

Epoch: 6| Step: 8
Training loss: 0.6835055921112326
Validation loss: 2.492810645415357

Epoch: 6| Step: 9
Training loss: 0.8374048349771617
Validation loss: 2.48491175585345

Epoch: 6| Step: 10
Training loss: 0.4911102737817104
Validation loss: 2.4532262643929608

Epoch: 6| Step: 11
Training loss: 0.5550554693700497
Validation loss: 2.4607931729894905

Epoch: 6| Step: 12
Training loss: 0.5779262407257443
Validation loss: 2.446405687393752

Epoch: 6| Step: 13
Training loss: 0.7337385219605526
Validation loss: 2.453895989549914

Epoch: 270| Step: 0
Training loss: 0.621755786951649
Validation loss: 2.4621367783028925

Epoch: 6| Step: 1
Training loss: 0.8273407803663175
Validation loss: 2.4531418409384083

Epoch: 6| Step: 2
Training loss: 0.5196864534460416
Validation loss: 2.438908969338868

Epoch: 6| Step: 3
Training loss: 0.3878302735613844
Validation loss: 2.4337821838380242

Epoch: 6| Step: 4
Training loss: 0.602372676684191
Validation loss: 2.4408343773269805

Epoch: 6| Step: 5
Training loss: 0.4096471078719605
Validation loss: 2.4691087621239736

Epoch: 6| Step: 6
Training loss: 0.6734268541667334
Validation loss: 2.417067270381594

Epoch: 6| Step: 7
Training loss: 1.0252188983805155
Validation loss: 2.4397414791956114

Epoch: 6| Step: 8
Training loss: 0.41661297531698277
Validation loss: 2.4216208328215783

Epoch: 6| Step: 9
Training loss: 0.5455378397466939
Validation loss: 2.4157118440399077

Epoch: 6| Step: 10
Training loss: 0.5761945816996824
Validation loss: 2.401130144160375

Epoch: 6| Step: 11
Training loss: 0.7852005447874545
Validation loss: 2.436078528227821

Epoch: 6| Step: 12
Training loss: 0.4729649347580524
Validation loss: 2.4449845668489263

Epoch: 6| Step: 13
Training loss: 0.7745674433590846
Validation loss: 2.3821380828158136

Epoch: 271| Step: 0
Training loss: 0.5469722661304904
Validation loss: 2.425976968248098

Epoch: 6| Step: 1
Training loss: 0.5969798929607992
Validation loss: 2.4813148554737774

Epoch: 6| Step: 2
Training loss: 0.7055836606143391
Validation loss: 2.4867962547952174

Epoch: 6| Step: 3
Training loss: 0.9093213816038649
Validation loss: 2.4740205939359403

Epoch: 6| Step: 4
Training loss: 0.6779628665314482
Validation loss: 2.490996162536774

Epoch: 6| Step: 5
Training loss: 0.6192865290041656
Validation loss: 2.474946347381514

Epoch: 6| Step: 6
Training loss: 1.0259187046993727
Validation loss: 2.45972017832358

Epoch: 6| Step: 7
Training loss: 0.3642316302587641
Validation loss: 2.452671808366679

Epoch: 6| Step: 8
Training loss: 0.7884322567167051
Validation loss: 2.4550846806017375

Epoch: 6| Step: 9
Training loss: 0.2900903059263798
Validation loss: 2.4477785244731702

Epoch: 6| Step: 10
Training loss: 0.5711745448957323
Validation loss: 2.423901276392164

Epoch: 6| Step: 11
Training loss: 0.37474066986216303
Validation loss: 2.4462334114490782

Epoch: 6| Step: 12
Training loss: 0.37188231356826074
Validation loss: 2.436571954751344

Epoch: 6| Step: 13
Training loss: 0.25552773275960255
Validation loss: 2.4493228114171157

Epoch: 272| Step: 0
Training loss: 0.46082535688810383
Validation loss: 2.433097433077957

Epoch: 6| Step: 1
Training loss: 0.7295700909995707
Validation loss: 2.486975945679642

Epoch: 6| Step: 2
Training loss: 0.6306044119431632
Validation loss: 2.5279383992783466

Epoch: 6| Step: 3
Training loss: 0.8684371329983173
Validation loss: 2.514654976453681

Epoch: 6| Step: 4
Training loss: 0.6920569208430639
Validation loss: 2.5029511312307995

Epoch: 6| Step: 5
Training loss: 0.5661245763789314
Validation loss: 2.460101484709331

Epoch: 6| Step: 6
Training loss: 0.45243213560905665
Validation loss: 2.4603949023354907

Epoch: 6| Step: 7
Training loss: 0.45692599135953627
Validation loss: 2.466516739325023

Epoch: 6| Step: 8
Training loss: 0.5533226306676863
Validation loss: 2.3998926458310015

Epoch: 6| Step: 9
Training loss: 0.5587948523831135
Validation loss: 2.434400708945042

Epoch: 6| Step: 10
Training loss: 0.6329985215665477
Validation loss: 2.4585538253916543

Epoch: 6| Step: 11
Training loss: 0.7233393147290111
Validation loss: 2.464194210955463

Epoch: 6| Step: 12
Training loss: 0.5421272728089302
Validation loss: 2.4525889243385834

Epoch: 6| Step: 13
Training loss: 0.6044302617462971
Validation loss: 2.4522965124734153

Epoch: 273| Step: 0
Training loss: 0.7821676586894549
Validation loss: 2.4661526233820315

Epoch: 6| Step: 1
Training loss: 0.5162352793998605
Validation loss: 2.47833557413588

Epoch: 6| Step: 2
Training loss: 0.474148907616594
Validation loss: 2.51236232669544

Epoch: 6| Step: 3
Training loss: 0.5205585104351708
Validation loss: 2.458116906304349

Epoch: 6| Step: 4
Training loss: 0.6304984699037093
Validation loss: 2.480026146459475

Epoch: 6| Step: 5
Training loss: 0.32601014427699176
Validation loss: 2.437888469719706

Epoch: 6| Step: 6
Training loss: 0.5228655522911269
Validation loss: 2.451956254811382

Epoch: 6| Step: 7
Training loss: 0.4791862459605416
Validation loss: 2.427438139557461

Epoch: 6| Step: 8
Training loss: 0.6091253551777243
Validation loss: 2.43877233802214

Epoch: 6| Step: 9
Training loss: 0.7580412293371044
Validation loss: 2.442175956035728

Epoch: 6| Step: 10
Training loss: 0.7597049012225262
Validation loss: 2.4362275131165085

Epoch: 6| Step: 11
Training loss: 0.46495401052477886
Validation loss: 2.4170165404510615

Epoch: 6| Step: 12
Training loss: 0.46500860224222046
Validation loss: 2.3852635250396585

Epoch: 6| Step: 13
Training loss: 1.0584859194857401
Validation loss: 2.4402034981517033

Epoch: 274| Step: 0
Training loss: 0.4749729663283502
Validation loss: 2.426328396322852

Epoch: 6| Step: 1
Training loss: 0.22369187420524878
Validation loss: 2.4255845298565593

Epoch: 6| Step: 2
Training loss: 0.5476024965905762
Validation loss: 2.4368597051569316

Epoch: 6| Step: 3
Training loss: 0.6139649388898895
Validation loss: 2.4526608714310862

Epoch: 6| Step: 4
Training loss: 0.27557615699417903
Validation loss: 2.441792290337776

Epoch: 6| Step: 5
Training loss: 0.5813591167615367
Validation loss: 2.4261385160325

Epoch: 6| Step: 6
Training loss: 0.8360380664833159
Validation loss: 2.4010441462675463

Epoch: 6| Step: 7
Training loss: 0.715667625057335
Validation loss: 2.411913545459404

Epoch: 6| Step: 8
Training loss: 0.7886986979684086
Validation loss: 2.441666494760994

Epoch: 6| Step: 9
Training loss: 0.7443396835212865
Validation loss: 2.4253460983551838

Epoch: 6| Step: 10
Training loss: 0.5606151898056295
Validation loss: 2.4093194776314104

Epoch: 6| Step: 11
Training loss: 0.7982987046214167
Validation loss: 2.4339717121862527

Epoch: 6| Step: 12
Training loss: 0.45354979433175513
Validation loss: 2.4423390491611476

Epoch: 6| Step: 13
Training loss: 0.2584700723715019
Validation loss: 2.4450045381258088

Epoch: 275| Step: 0
Training loss: 0.4473593334664174
Validation loss: 2.4384870852272433

Epoch: 6| Step: 1
Training loss: 0.4543337648720393
Validation loss: 2.447566922524667

Epoch: 6| Step: 2
Training loss: 0.820071811788003
Validation loss: 2.4287488907784414

Epoch: 6| Step: 3
Training loss: 0.5093765820437711
Validation loss: 2.4688158058959004

Epoch: 6| Step: 4
Training loss: 0.5961188944741693
Validation loss: 2.4303955158647663

Epoch: 6| Step: 5
Training loss: 0.3868400499090033
Validation loss: 2.4349120926501944

Epoch: 6| Step: 6
Training loss: 0.5381368346469163
Validation loss: 2.4555506666756233

Epoch: 6| Step: 7
Training loss: 0.5596157674651988
Validation loss: 2.445596082427674

Epoch: 6| Step: 8
Training loss: 0.9232394578932505
Validation loss: 2.4487493944893117

Epoch: 6| Step: 9
Training loss: 0.599369386242939
Validation loss: 2.4394509359577983

Epoch: 6| Step: 10
Training loss: 0.7407507793642567
Validation loss: 2.433819905037174

Epoch: 6| Step: 11
Training loss: 0.28846309994617286
Validation loss: 2.435052209535167

Epoch: 6| Step: 12
Training loss: 0.6051943003154128
Validation loss: 2.4475736333618183

Epoch: 6| Step: 13
Training loss: 0.2208568409037936
Validation loss: 2.4441978180863324

Epoch: 276| Step: 0
Training loss: 0.34430658190438634
Validation loss: 2.4257221259303665

Epoch: 6| Step: 1
Training loss: 0.6523267092734754
Validation loss: 2.434853028680181

Epoch: 6| Step: 2
Training loss: 0.484092968695391
Validation loss: 2.441357511694293

Epoch: 6| Step: 3
Training loss: 0.5971923473806189
Validation loss: 2.4676609360459487

Epoch: 6| Step: 4
Training loss: 0.8521535729431229
Validation loss: 2.4587696210406746

Epoch: 6| Step: 5
Training loss: 0.7059371238325856
Validation loss: 2.4348380564902823

Epoch: 6| Step: 6
Training loss: 0.3832053095981805
Validation loss: 2.4256694072325224

Epoch: 6| Step: 7
Training loss: 0.5509738450116873
Validation loss: 2.4652240288796

Epoch: 6| Step: 8
Training loss: 0.6480443980863487
Validation loss: 2.4694797594626863

Epoch: 6| Step: 9
Training loss: 0.47200010801168596
Validation loss: 2.465337166674329

Epoch: 6| Step: 10
Training loss: 0.47849754766455654
Validation loss: 2.4239630783593533

Epoch: 6| Step: 11
Training loss: 0.3337541534043948
Validation loss: 2.463441485401769

Epoch: 6| Step: 12
Training loss: 0.5705507904131503
Validation loss: 2.4375040082159707

Epoch: 6| Step: 13
Training loss: 0.9145496732966794
Validation loss: 2.4560729435707223

Epoch: 277| Step: 0
Training loss: 0.5214427116981303
Validation loss: 2.438267679752988

Epoch: 6| Step: 1
Training loss: 0.5336656066857001
Validation loss: 2.452663590644123

Epoch: 6| Step: 2
Training loss: 0.4324299426476305
Validation loss: 2.438947060339826

Epoch: 6| Step: 3
Training loss: 0.5638568725276706
Validation loss: 2.4500826379912217

Epoch: 6| Step: 4
Training loss: 0.8356373328223977
Validation loss: 2.4825141073563692

Epoch: 6| Step: 5
Training loss: 0.5539519577644598
Validation loss: 2.465906021446393

Epoch: 6| Step: 6
Training loss: 0.585995378814547
Validation loss: 2.439949914259168

Epoch: 6| Step: 7
Training loss: 0.5692736949889446
Validation loss: 2.45520232446732

Epoch: 6| Step: 8
Training loss: 0.6274374163905245
Validation loss: 2.4594563761935073

Epoch: 6| Step: 9
Training loss: 0.408535142418827
Validation loss: 2.458248807171075

Epoch: 6| Step: 10
Training loss: 0.6937332864414851
Validation loss: 2.4391665980928963

Epoch: 6| Step: 11
Training loss: 0.5871788861920401
Validation loss: 2.4446420849710724

Epoch: 6| Step: 12
Training loss: 0.6291292636271343
Validation loss: 2.467263256547197

Epoch: 6| Step: 13
Training loss: 0.28815286149962765
Validation loss: 2.455343651502088

Epoch: 278| Step: 0
Training loss: 0.6222828213122982
Validation loss: 2.471526926213095

Epoch: 6| Step: 1
Training loss: 0.3633438384581829
Validation loss: 2.4759601452987954

Epoch: 6| Step: 2
Training loss: 1.0312698246755385
Validation loss: 2.497670337184971

Epoch: 6| Step: 3
Training loss: 0.6507557940684952
Validation loss: 2.4674668545144622

Epoch: 6| Step: 4
Training loss: 0.5999800937052494
Validation loss: 2.4837594425756353

Epoch: 6| Step: 5
Training loss: 0.3814787108317025
Validation loss: 2.493024112849983

Epoch: 6| Step: 6
Training loss: 0.7088177277567562
Validation loss: 2.4579510448025643

Epoch: 6| Step: 7
Training loss: 0.6839920627373279
Validation loss: 2.4698316261531823

Epoch: 6| Step: 8
Training loss: 0.5487485671839333
Validation loss: 2.506446164856089

Epoch: 6| Step: 9
Training loss: 0.4435634731428789
Validation loss: 2.482775768275052

Epoch: 6| Step: 10
Training loss: 0.2614970193158763
Validation loss: 2.4564383224505795

Epoch: 6| Step: 11
Training loss: 0.4402043343341453
Validation loss: 2.4382743415338135

Epoch: 6| Step: 12
Training loss: 0.4521069105946987
Validation loss: 2.4571011727965577

Epoch: 6| Step: 13
Training loss: 0.4972115186815528
Validation loss: 2.4245744362235335

Epoch: 279| Step: 0
Training loss: 0.46066232323025064
Validation loss: 2.410896351841628

Epoch: 6| Step: 1
Training loss: 0.9427937140535628
Validation loss: 2.471183396906996

Epoch: 6| Step: 2
Training loss: 0.7063903432842681
Validation loss: 2.432420986481434

Epoch: 6| Step: 3
Training loss: 0.4607083672452789
Validation loss: 2.483472039183204

Epoch: 6| Step: 4
Training loss: 0.2773284907911634
Validation loss: 2.498100266529082

Epoch: 6| Step: 5
Training loss: 0.40467645269213187
Validation loss: 2.5021620169443684

Epoch: 6| Step: 6
Training loss: 0.6089730526579361
Validation loss: 2.4854524545812886

Epoch: 6| Step: 7
Training loss: 0.6160146941841365
Validation loss: 2.530606458319842

Epoch: 6| Step: 8
Training loss: 0.19500357037723537
Validation loss: 2.461876882925861

Epoch: 6| Step: 9
Training loss: 0.7155433108418747
Validation loss: 2.4924852423074113

Epoch: 6| Step: 10
Training loss: 0.4416445198744343
Validation loss: 2.460472395034831

Epoch: 6| Step: 11
Training loss: 0.6229486657113423
Validation loss: 2.4246043766867977

Epoch: 6| Step: 12
Training loss: 0.7325375478319265
Validation loss: 2.4264675582569386

Epoch: 6| Step: 13
Training loss: 0.4578194301979032
Validation loss: 2.450966763924188

Epoch: 280| Step: 0
Training loss: 0.7101673524028574
Validation loss: 2.47762987385113

Epoch: 6| Step: 1
Training loss: 0.454523362359788
Validation loss: 2.4556455489093882

Epoch: 6| Step: 2
Training loss: 0.6561127927941457
Validation loss: 2.4636253261732746

Epoch: 6| Step: 3
Training loss: 0.6698740060681093
Validation loss: 2.4983107048205735

Epoch: 6| Step: 4
Training loss: 0.40705390398533514
Validation loss: 2.5001538301126893

Epoch: 6| Step: 5
Training loss: 0.5734554589393134
Validation loss: 2.5049852743451404

Epoch: 6| Step: 6
Training loss: 0.6770424732692776
Validation loss: 2.446933533380124

Epoch: 6| Step: 7
Training loss: 0.558512995291242
Validation loss: 2.480231706672848

Epoch: 6| Step: 8
Training loss: 0.8441229808257311
Validation loss: 2.4543266773073484

Epoch: 6| Step: 9
Training loss: 0.7287217735726088
Validation loss: 2.4290962894041255

Epoch: 6| Step: 10
Training loss: 0.4148661174599099
Validation loss: 2.4233040300155833

Epoch: 6| Step: 11
Training loss: 0.23641532676300495
Validation loss: 2.44960475430644

Epoch: 6| Step: 12
Training loss: 0.448980334495895
Validation loss: 2.473938138109732

Epoch: 6| Step: 13
Training loss: 0.38363240468724347
Validation loss: 2.4735915898676777

Epoch: 281| Step: 0
Training loss: 0.5936487011076864
Validation loss: 2.4570099856297407

Epoch: 6| Step: 1
Training loss: 0.643529772818891
Validation loss: 2.4768164523165614

Epoch: 6| Step: 2
Training loss: 0.5758085236631014
Validation loss: 2.453414353365492

Epoch: 6| Step: 3
Training loss: 0.5210821193329329
Validation loss: 2.4856849715450187

Epoch: 6| Step: 4
Training loss: 0.6418931551021447
Validation loss: 2.4509934512109566

Epoch: 6| Step: 5
Training loss: 0.3801639565824592
Validation loss: 2.433512336826727

Epoch: 6| Step: 6
Training loss: 0.5531191076622172
Validation loss: 2.40073699936553

Epoch: 6| Step: 7
Training loss: 0.6167768246832639
Validation loss: 2.436702472641462

Epoch: 6| Step: 8
Training loss: 0.6678354230631778
Validation loss: 2.4089083786140804

Epoch: 6| Step: 9
Training loss: 0.47471810496491534
Validation loss: 2.40524312583801

Epoch: 6| Step: 10
Training loss: 0.47904722307585046
Validation loss: 2.4551544698387273

Epoch: 6| Step: 11
Training loss: 0.5600350199546382
Validation loss: 2.4620555904967873

Epoch: 6| Step: 12
Training loss: 0.6377694056230386
Validation loss: 2.5060808614607164

Epoch: 6| Step: 13
Training loss: 0.4967647430159643
Validation loss: 2.4890631371964194

Epoch: 282| Step: 0
Training loss: 0.7029943980676141
Validation loss: 2.5178571476883196

Epoch: 6| Step: 1
Training loss: 0.5123796344928114
Validation loss: 2.498021098344364

Epoch: 6| Step: 2
Training loss: 0.5640017542794858
Validation loss: 2.501077950768307

Epoch: 6| Step: 3
Training loss: 0.6818555039609082
Validation loss: 2.4573157251593036

Epoch: 6| Step: 4
Training loss: 0.5859245807494997
Validation loss: 2.458165327963397

Epoch: 6| Step: 5
Training loss: 0.6219555615714121
Validation loss: 2.411826915891703

Epoch: 6| Step: 6
Training loss: 0.6894106108873934
Validation loss: 2.4338724751047396

Epoch: 6| Step: 7
Training loss: 0.6479863125288579
Validation loss: 2.3977599923168333

Epoch: 6| Step: 8
Training loss: 0.5434654763003431
Validation loss: 2.431937726317322

Epoch: 6| Step: 9
Training loss: 0.5138372002917125
Validation loss: 2.461126359007331

Epoch: 6| Step: 10
Training loss: 0.5135684181142578
Validation loss: 2.4725516744489906

Epoch: 6| Step: 11
Training loss: 0.40829466746984827
Validation loss: 2.4582811579130492

Epoch: 6| Step: 12
Training loss: 0.7974884065843683
Validation loss: 2.444141979916929

Epoch: 6| Step: 13
Training loss: 0.5971793222790683
Validation loss: 2.4458592637806507

Epoch: 283| Step: 0
Training loss: 0.6631666536039569
Validation loss: 2.4000585663393688

Epoch: 6| Step: 1
Training loss: 0.8383642605283809
Validation loss: 2.4063121535657896

Epoch: 6| Step: 2
Training loss: 0.5559960632184846
Validation loss: 2.4441377025321676

Epoch: 6| Step: 3
Training loss: 0.5161008661918859
Validation loss: 2.42479134277112

Epoch: 6| Step: 4
Training loss: 0.5887001015642486
Validation loss: 2.4351031327632797

Epoch: 6| Step: 5
Training loss: 0.46568525103726227
Validation loss: 2.49237470797746

Epoch: 6| Step: 6
Training loss: 0.8237998584946309
Validation loss: 2.486097064936904

Epoch: 6| Step: 7
Training loss: 0.7853760672547907
Validation loss: 2.517909880387523

Epoch: 6| Step: 8
Training loss: 0.6706572519743436
Validation loss: 2.5730506008866625

Epoch: 6| Step: 9
Training loss: 0.6287868220503897
Validation loss: 2.5059826852945553

Epoch: 6| Step: 10
Training loss: 0.3182685582098214
Validation loss: 2.4657563282679855

Epoch: 6| Step: 11
Training loss: 0.48033349529237596
Validation loss: 2.4483705335946873

Epoch: 6| Step: 12
Training loss: 0.44400560445405807
Validation loss: 2.4606534445945245

Epoch: 6| Step: 13
Training loss: 0.3803860584297529
Validation loss: 2.4334632760736468

Epoch: 284| Step: 0
Training loss: 0.722247157420384
Validation loss: 2.4930612664929446

Epoch: 6| Step: 1
Training loss: 0.5563518109533903
Validation loss: 2.420548583962335

Epoch: 6| Step: 2
Training loss: 0.8326772411790778
Validation loss: 2.3986483646194996

Epoch: 6| Step: 3
Training loss: 0.3597754859194199
Validation loss: 2.4006502014191113

Epoch: 6| Step: 4
Training loss: 0.6838843681559789
Validation loss: 2.4089239482976863

Epoch: 6| Step: 5
Training loss: 0.7921518712806667
Validation loss: 2.475624358891605

Epoch: 6| Step: 6
Training loss: 0.8075555226632968
Validation loss: 2.437477967841337

Epoch: 6| Step: 7
Training loss: 0.37546032229778553
Validation loss: 2.460858758284209

Epoch: 6| Step: 8
Training loss: 0.25121862709069925
Validation loss: 2.4678671169252655

Epoch: 6| Step: 9
Training loss: 0.5297274369119438
Validation loss: 2.500773845391432

Epoch: 6| Step: 10
Training loss: 0.41245842565202834
Validation loss: 2.519384698277384

Epoch: 6| Step: 11
Training loss: 0.557118261103521
Validation loss: 2.4848868261460204

Epoch: 6| Step: 12
Training loss: 0.4222512686491858
Validation loss: 2.492537908549781

Epoch: 6| Step: 13
Training loss: 0.4143810486388018
Validation loss: 2.4779956879011533

Epoch: 285| Step: 0
Training loss: 0.6450617138961586
Validation loss: 2.4732317987950636

Epoch: 6| Step: 1
Training loss: 0.28991547594175876
Validation loss: 2.4525945970632304

Epoch: 6| Step: 2
Training loss: 0.3467441552624632
Validation loss: 2.4283600402911967

Epoch: 6| Step: 3
Training loss: 0.6806011417155143
Validation loss: 2.4552293536190692

Epoch: 6| Step: 4
Training loss: 0.7105039175678572
Validation loss: 2.43472210207985

Epoch: 6| Step: 5
Training loss: 0.40118448596065215
Validation loss: 2.4296262498799583

Epoch: 6| Step: 6
Training loss: 0.5613274008176163
Validation loss: 2.413551904453213

Epoch: 6| Step: 7
Training loss: 0.4945132995047451
Validation loss: 2.4543579934398965

Epoch: 6| Step: 8
Training loss: 0.6460680586332282
Validation loss: 2.420834183039297

Epoch: 6| Step: 9
Training loss: 0.5712160243108061
Validation loss: 2.4341711805337254

Epoch: 6| Step: 10
Training loss: 0.2626883637030391
Validation loss: 2.4205088307929885

Epoch: 6| Step: 11
Training loss: 0.8008045844423199
Validation loss: 2.452307031306118

Epoch: 6| Step: 12
Training loss: 0.712985892005118
Validation loss: 2.433818724505725

Epoch: 6| Step: 13
Training loss: 0.6276892977602097
Validation loss: 2.4799968073821383

Epoch: 286| Step: 0
Training loss: 0.6355018219925448
Validation loss: 2.48224753376302

Epoch: 6| Step: 1
Training loss: 0.332350992070946
Validation loss: 2.4602261068631104

Epoch: 6| Step: 2
Training loss: 0.7292355414059993
Validation loss: 2.477017616353696

Epoch: 6| Step: 3
Training loss: 0.3106821233506317
Validation loss: 2.471866950515699

Epoch: 6| Step: 4
Training loss: 0.578894824328393
Validation loss: 2.472490969828592

Epoch: 6| Step: 5
Training loss: 0.54249640028502
Validation loss: 2.4587785669770685

Epoch: 6| Step: 6
Training loss: 0.672817744275822
Validation loss: 2.4390709444790244

Epoch: 6| Step: 7
Training loss: 0.5285256316484589
Validation loss: 2.4292508999752114

Epoch: 6| Step: 8
Training loss: 0.6576096437144462
Validation loss: 2.431692497344902

Epoch: 6| Step: 9
Training loss: 0.504445637480034
Validation loss: 2.4209533080785097

Epoch: 6| Step: 10
Training loss: 0.47088776128968807
Validation loss: 2.41204102613511

Epoch: 6| Step: 11
Training loss: 0.326415810196212
Validation loss: 2.3859061124888346

Epoch: 6| Step: 12
Training loss: 0.7631994088377553
Validation loss: 2.398120998866372

Epoch: 6| Step: 13
Training loss: 0.3803875470306226
Validation loss: 2.4137061039486913

Epoch: 287| Step: 0
Training loss: 0.585436237818063
Validation loss: 2.389195679182147

Epoch: 6| Step: 1
Training loss: 0.3982925899503028
Validation loss: 2.4144716814390716

Epoch: 6| Step: 2
Training loss: 0.433077668305199
Validation loss: 2.4205814385627216

Epoch: 6| Step: 3
Training loss: 0.6378507322508893
Validation loss: 2.4242149806432787

Epoch: 6| Step: 4
Training loss: 0.39270712028471216
Validation loss: 2.457847305926632

Epoch: 6| Step: 5
Training loss: 0.9247343687173484
Validation loss: 2.4750135898890266

Epoch: 6| Step: 6
Training loss: 0.5530948070324415
Validation loss: 2.500344559295421

Epoch: 6| Step: 7
Training loss: 0.5814154522769087
Validation loss: 2.525865033368696

Epoch: 6| Step: 8
Training loss: 0.5032807541483273
Validation loss: 2.4831827266546185

Epoch: 6| Step: 9
Training loss: 0.5288459010890544
Validation loss: 2.4988358299403597

Epoch: 6| Step: 10
Training loss: 0.580792125716045
Validation loss: 2.4896174335105172

Epoch: 6| Step: 11
Training loss: 0.3540172916381036
Validation loss: 2.4836606803123846

Epoch: 6| Step: 12
Training loss: 0.4844821380751579
Validation loss: 2.5001410526558763

Epoch: 6| Step: 13
Training loss: 0.39140986747364426
Validation loss: 2.455276303611279

Epoch: 288| Step: 0
Training loss: 0.5286866784563456
Validation loss: 2.4944240777007893

Epoch: 6| Step: 1
Training loss: 0.45828151048665233
Validation loss: 2.4754230883637343

Epoch: 6| Step: 2
Training loss: 0.30636409269144027
Validation loss: 2.4738116024698105

Epoch: 6| Step: 3
Training loss: 0.687194019198232
Validation loss: 2.4845584134295655

Epoch: 6| Step: 4
Training loss: 0.4289137723224866
Validation loss: 2.447758166318459

Epoch: 6| Step: 5
Training loss: 0.5139219886269579
Validation loss: 2.496685859543097

Epoch: 6| Step: 6
Training loss: 0.7049357093418288
Validation loss: 2.457624972280183

Epoch: 6| Step: 7
Training loss: 0.40244675215956693
Validation loss: 2.4830030018279827

Epoch: 6| Step: 8
Training loss: 0.35775374550661415
Validation loss: 2.4879526382466612

Epoch: 6| Step: 9
Training loss: 0.3415170123252784
Validation loss: 2.4457641360618227

Epoch: 6| Step: 10
Training loss: 0.6950747051157026
Validation loss: 2.4643606103705102

Epoch: 6| Step: 11
Training loss: 0.32311496363018677
Validation loss: 2.4682614315654314

Epoch: 6| Step: 12
Training loss: 0.6522528533653815
Validation loss: 2.4420839575172253

Epoch: 6| Step: 13
Training loss: 0.804627277379934
Validation loss: 2.463242685663661

Epoch: 289| Step: 0
Training loss: 0.44299213811903276
Validation loss: 2.4241647704287397

Epoch: 6| Step: 1
Training loss: 0.5685986149708977
Validation loss: 2.4548596316494886

Epoch: 6| Step: 2
Training loss: 0.49111151779322426
Validation loss: 2.43969892313445

Epoch: 6| Step: 3
Training loss: 0.5217149203452105
Validation loss: 2.458537583046316

Epoch: 6| Step: 4
Training loss: 0.3779006868024078
Validation loss: 2.4279064245903075

Epoch: 6| Step: 5
Training loss: 0.7772123139411601
Validation loss: 2.473807334933337

Epoch: 6| Step: 6
Training loss: 0.5409732072086968
Validation loss: 2.4754478384194853

Epoch: 6| Step: 7
Training loss: 0.25019234470152774
Validation loss: 2.42670508566539

Epoch: 6| Step: 8
Training loss: 0.6989544843254101
Validation loss: 2.458878877055478

Epoch: 6| Step: 9
Training loss: 0.3413133197942925
Validation loss: 2.4424299107719185

Epoch: 6| Step: 10
Training loss: 0.4638522015208792
Validation loss: 2.4243174822249682

Epoch: 6| Step: 11
Training loss: 0.6135267021629685
Validation loss: 2.4967154635418063

Epoch: 6| Step: 12
Training loss: 0.4484679873001942
Validation loss: 2.4565220857653998

Epoch: 6| Step: 13
Training loss: 0.5715672524798467
Validation loss: 2.459502724845869

Epoch: 290| Step: 0
Training loss: 0.7887650864090863
Validation loss: 2.4721746506568607

Epoch: 6| Step: 1
Training loss: 0.4995698121298255
Validation loss: 2.437624656533472

Epoch: 6| Step: 2
Training loss: 0.5414664252942344
Validation loss: 2.4568350118980162

Epoch: 6| Step: 3
Training loss: 0.17452510660709503
Validation loss: 2.4478669848579035

Epoch: 6| Step: 4
Training loss: 0.6196596395026731
Validation loss: 2.4543410689274388

Epoch: 6| Step: 5
Training loss: 0.5349672638155905
Validation loss: 2.4473715879374773

Epoch: 6| Step: 6
Training loss: 0.5842425435952984
Validation loss: 2.4483732994558265

Epoch: 6| Step: 7
Training loss: 0.5816783475203973
Validation loss: 2.447613805303075

Epoch: 6| Step: 8
Training loss: 0.4566582682050761
Validation loss: 2.4449327143739596

Epoch: 6| Step: 9
Training loss: 0.6667062529096021
Validation loss: 2.470402526014143

Epoch: 6| Step: 10
Training loss: 0.4192050226660487
Validation loss: 2.5016061391842337

Epoch: 6| Step: 11
Training loss: 0.3006199490921894
Validation loss: 2.456000849567713

Epoch: 6| Step: 12
Training loss: 0.265045599972771
Validation loss: 2.44076714795197

Epoch: 6| Step: 13
Training loss: 0.19305739278018236
Validation loss: 2.423753603774894

Epoch: 291| Step: 0
Training loss: 0.6673064936494135
Validation loss: 2.5017232370214817

Epoch: 6| Step: 1
Training loss: 0.665529314067608
Validation loss: 2.4909663598615475

Epoch: 6| Step: 2
Training loss: 0.6005863840985383
Validation loss: 2.466769601577612

Epoch: 6| Step: 3
Training loss: 0.35024508427336326
Validation loss: 2.434468795462924

Epoch: 6| Step: 4
Training loss: 0.26837014533450654
Validation loss: 2.430374603879897

Epoch: 6| Step: 5
Training loss: 0.630214113151171
Validation loss: 2.437907454914636

Epoch: 6| Step: 6
Training loss: 0.4078614114244984
Validation loss: 2.4009812621291307

Epoch: 6| Step: 7
Training loss: 0.17775732458156052
Validation loss: 2.441911424969225

Epoch: 6| Step: 8
Training loss: 0.5090395846984574
Validation loss: 2.4608794153888205

Epoch: 6| Step: 9
Training loss: 0.8948696112888128
Validation loss: 2.464149390426307

Epoch: 6| Step: 10
Training loss: 0.5282135465982108
Validation loss: 2.449939341586311

Epoch: 6| Step: 11
Training loss: 0.32561138673760665
Validation loss: 2.4604590207817

Epoch: 6| Step: 12
Training loss: 0.24497516666791697
Validation loss: 2.469257064341331

Epoch: 6| Step: 13
Training loss: 0.49724388464595
Validation loss: 2.4634949848541066

Epoch: 292| Step: 0
Training loss: 0.28655496903552335
Validation loss: 2.448220383953242

Epoch: 6| Step: 1
Training loss: 0.3611084760158121
Validation loss: 2.472356917109537

Epoch: 6| Step: 2
Training loss: 0.7430947230068905
Validation loss: 2.4643545590175453

Epoch: 6| Step: 3
Training loss: 0.5524480502703654
Validation loss: 2.4315300291117823

Epoch: 6| Step: 4
Training loss: 0.16849105049174523
Validation loss: 2.4631991482714906

Epoch: 6| Step: 5
Training loss: 0.45111826788745807
Validation loss: 2.4636300026108637

Epoch: 6| Step: 6
Training loss: 0.4601092089456682
Validation loss: 2.439368441369087

Epoch: 6| Step: 7
Training loss: 0.5360696890937015
Validation loss: 2.4414856054391465

Epoch: 6| Step: 8
Training loss: 0.8041785028472727
Validation loss: 2.4538804638780154

Epoch: 6| Step: 9
Training loss: 0.4508264879240525
Validation loss: 2.405725432335277

Epoch: 6| Step: 10
Training loss: 0.480454623006913
Validation loss: 2.474817067422429

Epoch: 6| Step: 11
Training loss: 0.37889366522270923
Validation loss: 2.457386761082268

Epoch: 6| Step: 12
Training loss: 0.3330840194179871
Validation loss: 2.45008263537535

Epoch: 6| Step: 13
Training loss: 0.7216742364370418
Validation loss: 2.4515758059182446

Epoch: 293| Step: 0
Training loss: 0.3862983267837497
Validation loss: 2.4448010225778196

Epoch: 6| Step: 1
Training loss: 0.57269023986947
Validation loss: 2.4612758499588163

Epoch: 6| Step: 2
Training loss: 0.2793867860138523
Validation loss: 2.4246685217203696

Epoch: 6| Step: 3
Training loss: 0.6937011735934531
Validation loss: 2.4297089169716375

Epoch: 6| Step: 4
Training loss: 0.2367591710091785
Validation loss: 2.419549870269633

Epoch: 6| Step: 5
Training loss: 0.5168023395321508
Validation loss: 2.448654082236227

Epoch: 6| Step: 6
Training loss: 0.5655598861139864
Validation loss: 2.4114514947042696

Epoch: 6| Step: 7
Training loss: 0.7344521015356095
Validation loss: 2.477350210835533

Epoch: 6| Step: 8
Training loss: 0.38009073015032835
Validation loss: 2.4675164848945847

Epoch: 6| Step: 9
Training loss: 0.3503028874605512
Validation loss: 2.4674404425457372

Epoch: 6| Step: 10
Training loss: 0.7879896518734594
Validation loss: 2.432998219079921

Epoch: 6| Step: 11
Training loss: 0.4375480216782687
Validation loss: 2.4441916989833374

Epoch: 6| Step: 12
Training loss: 0.35047155230316374
Validation loss: 2.4515354474023656

Epoch: 6| Step: 13
Training loss: 0.5121105819676286
Validation loss: 2.46733523758836

Epoch: 294| Step: 0
Training loss: 0.5044414723683822
Validation loss: 2.4300721326383568

Epoch: 6| Step: 1
Training loss: 0.6080650040454103
Validation loss: 2.4241276649206225

Epoch: 6| Step: 2
Training loss: 0.5294160884598026
Validation loss: 2.428551915934781

Epoch: 6| Step: 3
Training loss: 0.40788492093192225
Validation loss: 2.4358778181516425

Epoch: 6| Step: 4
Training loss: 0.6520150092977526
Validation loss: 2.4567138679740563

Epoch: 6| Step: 5
Training loss: 0.4344659572847128
Validation loss: 2.44470937504495

Epoch: 6| Step: 6
Training loss: 0.4656652996365837
Validation loss: 2.4599447185145156

Epoch: 6| Step: 7
Training loss: 0.6149412395349246
Validation loss: 2.4550432102260316

Epoch: 6| Step: 8
Training loss: 0.32893463565000414
Validation loss: 2.48571866487674

Epoch: 6| Step: 9
Training loss: 0.4533197872186762
Validation loss: 2.4913540117370765

Epoch: 6| Step: 10
Training loss: 0.7347682954860346
Validation loss: 2.463592449338546

Epoch: 6| Step: 11
Training loss: 0.4767122033543965
Validation loss: 2.4815160825491036

Epoch: 6| Step: 12
Training loss: 0.2493938384075222
Validation loss: 2.4726396534289257

Epoch: 6| Step: 13
Training loss: 0.2952450377493848
Validation loss: 2.464931342104308

Epoch: 295| Step: 0
Training loss: 0.45249115250299715
Validation loss: 2.4510775125131117

Epoch: 6| Step: 1
Training loss: 0.6338293359595144
Validation loss: 2.423513777236782

Epoch: 6| Step: 2
Training loss: 0.244103421237588
Validation loss: 2.401879720611688

Epoch: 6| Step: 3
Training loss: 0.6455447003188166
Validation loss: 2.431298262121355

Epoch: 6| Step: 4
Training loss: 0.6017920811499466
Validation loss: 2.436631324255827

Epoch: 6| Step: 5
Training loss: 0.49375245902499376
Validation loss: 2.445510774969171

Epoch: 6| Step: 6
Training loss: 0.4573236817758565
Validation loss: 2.4300690521390993

Epoch: 6| Step: 7
Training loss: 0.3733254436137502
Validation loss: 2.420064579078205

Epoch: 6| Step: 8
Training loss: 0.3925387993848786
Validation loss: 2.41873918616601

Epoch: 6| Step: 9
Training loss: 0.3645745094684732
Validation loss: 2.4768986746661406

Epoch: 6| Step: 10
Training loss: 0.7766751812057487
Validation loss: 2.4521877279316153

Epoch: 6| Step: 11
Training loss: 0.3592071141054623
Validation loss: 2.44346781763352

Epoch: 6| Step: 12
Training loss: 0.2593138071056199
Validation loss: 2.4593723656991964

Epoch: 6| Step: 13
Training loss: 0.6516242027797392
Validation loss: 2.48733892473236

Epoch: 296| Step: 0
Training loss: 0.41120080091235167
Validation loss: 2.477049939312472

Epoch: 6| Step: 1
Training loss: 0.508632027962562
Validation loss: 2.4811150586447286

Epoch: 6| Step: 2
Training loss: 0.3880159219861963
Validation loss: 2.476701608259343

Epoch: 6| Step: 3
Training loss: 0.5601710478505296
Validation loss: 2.4795963281784226

Epoch: 6| Step: 4
Training loss: 0.28455024496626646
Validation loss: 2.477210587402245

Epoch: 6| Step: 5
Training loss: 0.4192787923906455
Validation loss: 2.4922820721462777

Epoch: 6| Step: 6
Training loss: 0.34804157805345587
Validation loss: 2.457605881747647

Epoch: 6| Step: 7
Training loss: 0.26995281754277656
Validation loss: 2.4519919867140136

Epoch: 6| Step: 8
Training loss: 0.5338119552175397
Validation loss: 2.5031401335480363

Epoch: 6| Step: 9
Training loss: 0.45087373469053293
Validation loss: 2.479030979407638

Epoch: 6| Step: 10
Training loss: 0.7617585000645902
Validation loss: 2.4591173218827245

Epoch: 6| Step: 11
Training loss: 0.7441567246505203
Validation loss: 2.4704705905789734

Epoch: 6| Step: 12
Training loss: 0.44544341856598696
Validation loss: 2.4372557282875222

Epoch: 6| Step: 13
Training loss: 0.4077888467294342
Validation loss: 2.428367396193817

Epoch: 297| Step: 0
Training loss: 0.22602217468624128
Validation loss: 2.4601031989424236

Epoch: 6| Step: 1
Training loss: 0.5091862217550082
Validation loss: 2.4304952147729106

Epoch: 6| Step: 2
Training loss: 0.4047399847689467
Validation loss: 2.4523232438312483

Epoch: 6| Step: 3
Training loss: 0.3455339438054043
Validation loss: 2.4334027067497424

Epoch: 6| Step: 4
Training loss: 0.3857966903618721
Validation loss: 2.4416452629979273

Epoch: 6| Step: 5
Training loss: 0.21969651758562003
Validation loss: 2.4556298766573215

Epoch: 6| Step: 6
Training loss: 0.5973643668506157
Validation loss: 2.408148779363701

Epoch: 6| Step: 7
Training loss: 0.7251078081544169
Validation loss: 2.442876172497704

Epoch: 6| Step: 8
Training loss: 0.579317872688714
Validation loss: 2.4666851968271564

Epoch: 6| Step: 9
Training loss: 0.3011055473783914
Validation loss: 2.4558654165534772

Epoch: 6| Step: 10
Training loss: 0.5212651624235279
Validation loss: 2.47546108716033

Epoch: 6| Step: 11
Training loss: 0.7212958650864739
Validation loss: 2.4494210658965025

Epoch: 6| Step: 12
Training loss: 0.5934665907026637
Validation loss: 2.467872936322027

Epoch: 6| Step: 13
Training loss: 0.23655356538950478
Validation loss: 2.480772599237868

Epoch: 298| Step: 0
Training loss: 0.5063656957313477
Validation loss: 2.454788316078433

Epoch: 6| Step: 1
Training loss: 0.5749031970181555
Validation loss: 2.4830939158570646

Epoch: 6| Step: 2
Training loss: 0.26000455036216225
Validation loss: 2.447819102028909

Epoch: 6| Step: 3
Training loss: 0.29936959570384947
Validation loss: 2.436065242099763

Epoch: 6| Step: 4
Training loss: 0.6031285498321901
Validation loss: 2.471292330254198

Epoch: 6| Step: 5
Training loss: 0.45274962299990534
Validation loss: 2.4695605308723367

Epoch: 6| Step: 6
Training loss: 0.6435873576136434
Validation loss: 2.453258743021075

Epoch: 6| Step: 7
Training loss: 0.5604647798931994
Validation loss: 2.4528254241205905

Epoch: 6| Step: 8
Training loss: 0.5774874909602599
Validation loss: 2.4406852324930863

Epoch: 6| Step: 9
Training loss: 0.27120143224846477
Validation loss: 2.4390388681600816

Epoch: 6| Step: 10
Training loss: 0.4973468723133195
Validation loss: 2.425477603471614

Epoch: 6| Step: 11
Training loss: 0.3636770655735878
Validation loss: 2.4183591475504462

Epoch: 6| Step: 12
Training loss: 0.35357842493497577
Validation loss: 2.3941814711350493

Epoch: 6| Step: 13
Training loss: 0.7500942091582646
Validation loss: 2.4226314415273436

Epoch: 299| Step: 0
Training loss: 0.5522924752830861
Validation loss: 2.403110428566492

Epoch: 6| Step: 1
Training loss: 0.6740989472532519
Validation loss: 2.443109423557255

Epoch: 6| Step: 2
Training loss: 0.3089455398093774
Validation loss: 2.424900170687998

Epoch: 6| Step: 3
Training loss: 0.48704225128153533
Validation loss: 2.4256460881278237

Epoch: 6| Step: 4
Training loss: 0.43890275187200045
Validation loss: 2.4118753687139685

Epoch: 6| Step: 5
Training loss: 0.4176278194479608
Validation loss: 2.4351427998088546

Epoch: 6| Step: 6
Training loss: 0.4385491631773999
Validation loss: 2.4050685153821107

Epoch: 6| Step: 7
Training loss: 0.44645904709472184
Validation loss: 2.430315531429182

Epoch: 6| Step: 8
Training loss: 0.5667637190266823
Validation loss: 2.4258241654104724

Epoch: 6| Step: 9
Training loss: 0.5604659763136741
Validation loss: 2.447117254512531

Epoch: 6| Step: 10
Training loss: 0.2649726289658
Validation loss: 2.427105307044962

Epoch: 6| Step: 11
Training loss: 0.7395430988238653
Validation loss: 2.4447557689083506

Epoch: 6| Step: 12
Training loss: 0.43754693188302696
Validation loss: 2.4624038778304516

Epoch: 6| Step: 13
Training loss: 0.16696708334344967
Validation loss: 2.4479175823334756

Epoch: 300| Step: 0
Training loss: 0.6386490564032178
Validation loss: 2.445598774378964

Epoch: 6| Step: 1
Training loss: 0.1796718051524449
Validation loss: 2.460049630938427

Epoch: 6| Step: 2
Training loss: 0.2948189486335512
Validation loss: 2.4365377070087413

Epoch: 6| Step: 3
Training loss: 0.4102641372476443
Validation loss: 2.452641380078138

Epoch: 6| Step: 4
Training loss: 0.28468639386126526
Validation loss: 2.4425101293053055

Epoch: 6| Step: 5
Training loss: 0.6920683540807011
Validation loss: 2.432363105180325

Epoch: 6| Step: 6
Training loss: 0.5870148989461663
Validation loss: 2.427688312685053

Epoch: 6| Step: 7
Training loss: 0.2821975613909429
Validation loss: 2.4350978856759915

Epoch: 6| Step: 8
Training loss: 0.723234903791828
Validation loss: 2.4057689314242623

Epoch: 6| Step: 9
Training loss: 0.3289072838628834
Validation loss: 2.4528967157618218

Epoch: 6| Step: 10
Training loss: 0.3264811756774174
Validation loss: 2.3845469047194388

Epoch: 6| Step: 11
Training loss: 0.3690393702585705
Validation loss: 2.410458170085142

Epoch: 6| Step: 12
Training loss: 0.7707816484667949
Validation loss: 2.397100399435975

Epoch: 6| Step: 13
Training loss: 0.11275774335518794
Validation loss: 2.398135633713082

Epoch: 301| Step: 0
Training loss: 0.4901600511602335
Validation loss: 2.391797746368691

Epoch: 6| Step: 1
Training loss: 0.5874819174479529
Validation loss: 2.392832757033323

Epoch: 6| Step: 2
Training loss: 0.6640039754771525
Validation loss: 2.4420530340757534

Epoch: 6| Step: 3
Training loss: 0.3138345712118878
Validation loss: 2.4291228787200603

Epoch: 6| Step: 4
Training loss: 0.3511365853676765
Validation loss: 2.4451299444118506

Epoch: 6| Step: 5
Training loss: 0.351105987002828
Validation loss: 2.4439620705097873

Epoch: 6| Step: 6
Training loss: 0.30484437571920353
Validation loss: 2.4462751328263295

Epoch: 6| Step: 7
Training loss: 0.6320126741789279
Validation loss: 2.4464808442030637

Epoch: 6| Step: 8
Training loss: 0.5540304994243999
Validation loss: 2.4395120161186767

Epoch: 6| Step: 9
Training loss: 0.4225451303959571
Validation loss: 2.425709113876008

Epoch: 6| Step: 10
Training loss: 0.3235672298967699
Validation loss: 2.410455203313081

Epoch: 6| Step: 11
Training loss: 0.46583189240143485
Validation loss: 2.4366321286052264

Epoch: 6| Step: 12
Training loss: 0.4242138667378804
Validation loss: 2.486024071534055

Epoch: 6| Step: 13
Training loss: 0.6719626436068274
Validation loss: 2.449120051951974

Epoch: 302| Step: 0
Training loss: 0.5439756100775874
Validation loss: 2.469744685850223

Epoch: 6| Step: 1
Training loss: 0.416733994607386
Validation loss: 2.472089643342802

Epoch: 6| Step: 2
Training loss: 0.6510512516587716
Validation loss: 2.466128410001205

Epoch: 6| Step: 3
Training loss: 0.5558265756780578
Validation loss: 2.4576101878486987

Epoch: 6| Step: 4
Training loss: 0.4523742639135616
Validation loss: 2.4579668816493108

Epoch: 6| Step: 5
Training loss: 0.3111915135489664
Validation loss: 2.4321413964521557

Epoch: 6| Step: 6
Training loss: 0.40277839072316035
Validation loss: 2.4471929258317573

Epoch: 6| Step: 7
Training loss: 0.3714163131217195
Validation loss: 2.4538660591091803

Epoch: 6| Step: 8
Training loss: 0.3975308518462837
Validation loss: 2.473877632279939

Epoch: 6| Step: 9
Training loss: 0.5220960251812307
Validation loss: 2.4563226748726352

Epoch: 6| Step: 10
Training loss: 0.41632621883529347
Validation loss: 2.4368422056876944

Epoch: 6| Step: 11
Training loss: 0.4822385493689477
Validation loss: 2.443978195209234

Epoch: 6| Step: 12
Training loss: 0.5330714248266125
Validation loss: 2.4457896275360858

Epoch: 6| Step: 13
Training loss: 0.6055326366559287
Validation loss: 2.4284869064971266

Epoch: 303| Step: 0
Training loss: 0.5651435193776063
Validation loss: 2.449908031757408

Epoch: 6| Step: 1
Training loss: 0.22521507857987558
Validation loss: 2.427683970406159

Epoch: 6| Step: 2
Training loss: 0.4304075450275326
Validation loss: 2.4308792587418617

Epoch: 6| Step: 3
Training loss: 0.542747891742226
Validation loss: 2.424049510052124

Epoch: 6| Step: 4
Training loss: 0.24495501681876772
Validation loss: 2.4057468857324333

Epoch: 6| Step: 5
Training loss: 0.3679141909248517
Validation loss: 2.4043046459965653

Epoch: 6| Step: 6
Training loss: 0.36878296009756906
Validation loss: 2.4372774774048978

Epoch: 6| Step: 7
Training loss: 0.4710216473365081
Validation loss: 2.422826855532812

Epoch: 6| Step: 8
Training loss: 0.5220290065284438
Validation loss: 2.425070476744755

Epoch: 6| Step: 9
Training loss: 0.5352958441446323
Validation loss: 2.4201096625716327

Epoch: 6| Step: 10
Training loss: 0.5016890844403477
Validation loss: 2.4152982873787314

Epoch: 6| Step: 11
Training loss: 0.787182522917396
Validation loss: 2.4180666722972615

Epoch: 6| Step: 12
Training loss: 0.2940792652989893
Validation loss: 2.41865889257448

Epoch: 6| Step: 13
Training loss: 0.3087500043822686
Validation loss: 2.39533776984871

Epoch: 304| Step: 0
Training loss: 0.23961929728607853
Validation loss: 2.38647011946066

Epoch: 6| Step: 1
Training loss: 0.8029871633080824
Validation loss: 2.4059705450787208

Epoch: 6| Step: 2
Training loss: 0.37588087573468343
Validation loss: 2.4256201424010917

Epoch: 6| Step: 3
Training loss: 0.39354558134311257
Validation loss: 2.3905409162022146

Epoch: 6| Step: 4
Training loss: 0.15035975746344785
Validation loss: 2.4298705985696967

Epoch: 6| Step: 5
Training loss: 0.5298752106101231
Validation loss: 2.4563903384830392

Epoch: 6| Step: 6
Training loss: 0.31876182861445906
Validation loss: 2.4298048679205237

Epoch: 6| Step: 7
Training loss: 0.47929270959363873
Validation loss: 2.4630128910909312

Epoch: 6| Step: 8
Training loss: 0.6901665041617109
Validation loss: 2.457957780481281

Epoch: 6| Step: 9
Training loss: 0.4018427868831611
Validation loss: 2.4829128567900978

Epoch: 6| Step: 10
Training loss: 0.587769581446241
Validation loss: 2.4547420157457114

Epoch: 6| Step: 11
Training loss: 0.3649625531674977
Validation loss: 2.4567695998880668

Epoch: 6| Step: 12
Training loss: 0.398602058984996
Validation loss: 2.4471846059039235

Epoch: 6| Step: 13
Training loss: 0.31616440702214704
Validation loss: 2.4110087103097935

Epoch: 305| Step: 0
Training loss: 0.6523885197609952
Validation loss: 2.4604424153928957

Epoch: 6| Step: 1
Training loss: 0.4728786796348007
Validation loss: 2.4263443360265002

Epoch: 6| Step: 2
Training loss: 0.5621547699201112
Validation loss: 2.4481923632518403

Epoch: 6| Step: 3
Training loss: 0.5756356799349528
Validation loss: 2.424790558282316

Epoch: 6| Step: 4
Training loss: 0.5769011456649283
Validation loss: 2.4186046165226855

Epoch: 6| Step: 5
Training loss: 0.3463282993762823
Validation loss: 2.4470561515120197

Epoch: 6| Step: 6
Training loss: 0.31312805482664846
Validation loss: 2.454580952524318

Epoch: 6| Step: 7
Training loss: 0.3265904350743993
Validation loss: 2.4489634783599303

Epoch: 6| Step: 8
Training loss: 0.3342371981978904
Validation loss: 2.4531986378881188

Epoch: 6| Step: 9
Training loss: 0.539388972396487
Validation loss: 2.4784124241663594

Epoch: 6| Step: 10
Training loss: 0.4236811721516044
Validation loss: 2.4519269970365865

Epoch: 6| Step: 11
Training loss: 0.4312299613166981
Validation loss: 2.4382452928397496

Epoch: 6| Step: 12
Training loss: 0.4593539109871269
Validation loss: 2.4082204386979105

Epoch: 6| Step: 13
Training loss: 0.2788913557205574
Validation loss: 2.404422074767425

Epoch: 306| Step: 0
Training loss: 0.48556605920310847
Validation loss: 2.411048601508791

Epoch: 6| Step: 1
Training loss: 0.33083246024774865
Validation loss: 2.4417787150776316

Epoch: 6| Step: 2
Training loss: 0.24949578758785124
Validation loss: 2.421983730324619

Epoch: 6| Step: 3
Training loss: 0.47700454972054673
Validation loss: 2.458314012966359

Epoch: 6| Step: 4
Training loss: 0.19509683145793055
Validation loss: 2.4178499677721472

Epoch: 6| Step: 5
Training loss: 0.22739371376663253
Validation loss: 2.464415675231196

Epoch: 6| Step: 6
Training loss: 0.46400244096204357
Validation loss: 2.453081307075316

Epoch: 6| Step: 7
Training loss: 0.7045154175340431
Validation loss: 2.4527364161414895

Epoch: 6| Step: 8
Training loss: 0.48814709155489944
Validation loss: 2.475569556811646

Epoch: 6| Step: 9
Training loss: 0.2517116483589932
Validation loss: 2.4398062948778354

Epoch: 6| Step: 10
Training loss: 0.4319083647806261
Validation loss: 2.4538951203405444

Epoch: 6| Step: 11
Training loss: 0.5227431061197532
Validation loss: 2.397023431242357

Epoch: 6| Step: 12
Training loss: 0.6738664256834518
Validation loss: 2.4038263400975333

Epoch: 6| Step: 13
Training loss: 0.7522780868063808
Validation loss: 2.439743436804903

Epoch: 307| Step: 0
Training loss: 0.30432843790176806
Validation loss: 2.4020662985394945

Epoch: 6| Step: 1
Training loss: 0.28568446214454857
Validation loss: 2.4168850883487325

Epoch: 6| Step: 2
Training loss: 0.5495885827443088
Validation loss: 2.4342451216556693

Epoch: 6| Step: 3
Training loss: 0.29539091189415173
Validation loss: 2.4157457142140886

Epoch: 6| Step: 4
Training loss: 0.5172922172446156
Validation loss: 2.4359373348114235

Epoch: 6| Step: 5
Training loss: 0.6237069582565834
Validation loss: 2.4327406336575415

Epoch: 6| Step: 6
Training loss: 0.23127576194780344
Validation loss: 2.4487491610265124

Epoch: 6| Step: 7
Training loss: 0.5665362504873828
Validation loss: 2.46098993300551

Epoch: 6| Step: 8
Training loss: 0.4479983961223519
Validation loss: 2.4530157082261503

Epoch: 6| Step: 9
Training loss: 0.5086464123628524
Validation loss: 2.4605057542897333

Epoch: 6| Step: 10
Training loss: 0.3217075717979429
Validation loss: 2.4394185982265095

Epoch: 6| Step: 11
Training loss: 0.5606026438972929
Validation loss: 2.4533028737652227

Epoch: 6| Step: 12
Training loss: 0.4502871868529249
Validation loss: 2.45247452472703

Epoch: 6| Step: 13
Training loss: 0.2796186181177015
Validation loss: 2.4318133401612996

Epoch: 308| Step: 0
Training loss: 0.4064552632204006
Validation loss: 2.431346079124212

Epoch: 6| Step: 1
Training loss: 0.768591214660694
Validation loss: 2.3846256334306504

Epoch: 6| Step: 2
Training loss: 0.5500415136102376
Validation loss: 2.3893117206922874

Epoch: 6| Step: 3
Training loss: 0.4482906207344785
Validation loss: 2.379535689775703

Epoch: 6| Step: 4
Training loss: 0.25562954546517574
Validation loss: 2.408448332589907

Epoch: 6| Step: 5
Training loss: 0.23538302769192618
Validation loss: 2.441492491546335

Epoch: 6| Step: 6
Training loss: 0.38914066586573687
Validation loss: 2.425059340799339

Epoch: 6| Step: 7
Training loss: 0.5770691173285193
Validation loss: 2.41758646308591

Epoch: 6| Step: 8
Training loss: 0.41933856638140754
Validation loss: 2.4228039354952773

Epoch: 6| Step: 9
Training loss: 0.3024703936039043
Validation loss: 2.433420337885069

Epoch: 6| Step: 10
Training loss: 0.3357715640439494
Validation loss: 2.440181938481065

Epoch: 6| Step: 11
Training loss: 0.5309113938063726
Validation loss: 2.440582127369377

Epoch: 6| Step: 12
Training loss: 0.31611675393710453
Validation loss: 2.423538738479879

Epoch: 6| Step: 13
Training loss: 0.32082003415192145
Validation loss: 2.3996259385008676

Epoch: 309| Step: 0
Training loss: 0.5511177604166919
Validation loss: 2.394200636942079

Epoch: 6| Step: 1
Training loss: 0.49031569273804493
Validation loss: 2.3667514263586953

Epoch: 6| Step: 2
Training loss: 0.5229267931207161
Validation loss: 2.403319706609867

Epoch: 6| Step: 3
Training loss: 0.4507785089630939
Validation loss: 2.3955585805495865

Epoch: 6| Step: 4
Training loss: 0.2499295224745511
Validation loss: 2.3878402807209547

Epoch: 6| Step: 5
Training loss: 0.6204374672720716
Validation loss: 2.4237001896346175

Epoch: 6| Step: 6
Training loss: 0.43403839818888285
Validation loss: 2.3982741931706286

Epoch: 6| Step: 7
Training loss: 0.5232210423439206
Validation loss: 2.4001478690565983

Epoch: 6| Step: 8
Training loss: 0.3770006377166697
Validation loss: 2.436835666762149

Epoch: 6| Step: 9
Training loss: 0.5115206968533397
Validation loss: 2.464317896884249

Epoch: 6| Step: 10
Training loss: 0.4413838338645822
Validation loss: 2.4578498040135504

Epoch: 6| Step: 11
Training loss: 0.33011830102319484
Validation loss: 2.437057094653807

Epoch: 6| Step: 12
Training loss: 0.20940206801111533
Validation loss: 2.428918560731763

Epoch: 6| Step: 13
Training loss: 0.34536498175831853
Validation loss: 2.4040203389116557

Epoch: 310| Step: 0
Training loss: 0.6019707322562564
Validation loss: 2.388362053957936

Epoch: 6| Step: 1
Training loss: 0.21290653064350382
Validation loss: 2.3987598972767987

Epoch: 6| Step: 2
Training loss: 0.4200430052174982
Validation loss: 2.3984415767028846

Epoch: 6| Step: 3
Training loss: 0.5558343502370902
Validation loss: 2.4132517009143686

Epoch: 6| Step: 4
Training loss: 0.46413739816969096
Validation loss: 2.3910999425502584

Epoch: 6| Step: 5
Training loss: 0.447834635771114
Validation loss: 2.434304580029053

Epoch: 6| Step: 6
Training loss: 0.5514915161275713
Validation loss: 2.3975894154473014

Epoch: 6| Step: 7
Training loss: 0.27461586859067477
Validation loss: 2.439909083950287

Epoch: 6| Step: 8
Training loss: 0.3915374969817089
Validation loss: 2.441183315016751

Epoch: 6| Step: 9
Training loss: 0.44575984971657845
Validation loss: 2.4080017653436894

Epoch: 6| Step: 10
Training loss: 0.3849916326864505
Validation loss: 2.397881547688452

Epoch: 6| Step: 11
Training loss: 0.22958491460846395
Validation loss: 2.4182275357317238

Epoch: 6| Step: 12
Training loss: 0.4638813217418985
Validation loss: 2.442126268889113

Epoch: 6| Step: 13
Training loss: 0.4732224564605219
Validation loss: 2.454944693085217

Epoch: 311| Step: 0
Training loss: 0.24871869607899189
Validation loss: 2.402589166129269

Epoch: 6| Step: 1
Training loss: 0.4349900351128386
Validation loss: 2.4241916158222496

Epoch: 6| Step: 2
Training loss: 0.41400601343611243
Validation loss: 2.415882784557237

Epoch: 6| Step: 3
Training loss: 0.36577154629826103
Validation loss: 2.4297707790735505

Epoch: 6| Step: 4
Training loss: 0.46931233054998905
Validation loss: 2.4299848780956337

Epoch: 6| Step: 5
Training loss: 0.689541214024454
Validation loss: 2.466999396943627

Epoch: 6| Step: 6
Training loss: 0.41520610364987415
Validation loss: 2.429870826460989

Epoch: 6| Step: 7
Training loss: 0.32879165637513763
Validation loss: 2.455227455344079

Epoch: 6| Step: 8
Training loss: 0.41433568255860004
Validation loss: 2.4389986501087573

Epoch: 6| Step: 9
Training loss: 0.5163378556244137
Validation loss: 2.43320733293544

Epoch: 6| Step: 10
Training loss: 0.2306770094969519
Validation loss: 2.466007038569055

Epoch: 6| Step: 11
Training loss: 0.5594641300137015
Validation loss: 2.4651597036667523

Epoch: 6| Step: 12
Training loss: 0.4945167949185009
Validation loss: 2.4321790964568835

Epoch: 6| Step: 13
Training loss: 0.17576508447701494
Validation loss: 2.4860765766363584

Epoch: 312| Step: 0
Training loss: 0.35208047220470823
Validation loss: 2.45124581786015

Epoch: 6| Step: 1
Training loss: 0.4030455976844182
Validation loss: 2.4543927268158248

Epoch: 6| Step: 2
Training loss: 0.2829992283795422
Validation loss: 2.440854917166058

Epoch: 6| Step: 3
Training loss: 0.5191629294490041
Validation loss: 2.467912151966914

Epoch: 6| Step: 4
Training loss: 0.346068603945434
Validation loss: 2.4462911773050924

Epoch: 6| Step: 5
Training loss: 0.5834496132441628
Validation loss: 2.4506248439929754

Epoch: 6| Step: 6
Training loss: 0.4277671383367898
Validation loss: 2.497240790655732

Epoch: 6| Step: 7
Training loss: 0.2221522147493249
Validation loss: 2.4597805196254097

Epoch: 6| Step: 8
Training loss: 0.41169801402851114
Validation loss: 2.4415676147949834

Epoch: 6| Step: 9
Training loss: 0.33101217171310704
Validation loss: 2.4807311578362374

Epoch: 6| Step: 10
Training loss: 0.6451131101612819
Validation loss: 2.4916396746187046

Epoch: 6| Step: 11
Training loss: 0.4252039644327458
Validation loss: 2.485161928394497

Epoch: 6| Step: 12
Training loss: 0.4223980663286006
Validation loss: 2.4611095164559034

Epoch: 6| Step: 13
Training loss: 0.5428739780624577
Validation loss: 2.454119859737915

Epoch: 313| Step: 0
Training loss: 0.7013772647721161
Validation loss: 2.440317316376776

Epoch: 6| Step: 1
Training loss: 0.36221386370021874
Validation loss: 2.434220389733579

Epoch: 6| Step: 2
Training loss: 0.4552975563524148
Validation loss: 2.4624813567599397

Epoch: 6| Step: 3
Training loss: 0.36959377106711416
Validation loss: 2.414384254915925

Epoch: 6| Step: 4
Training loss: 0.38923822287626497
Validation loss: 2.408748870295396

Epoch: 6| Step: 5
Training loss: 0.24749484172416397
Validation loss: 2.3954850527310216

Epoch: 6| Step: 6
Training loss: 0.5728490673990209
Validation loss: 2.4270451135296245

Epoch: 6| Step: 7
Training loss: 0.24853316270669498
Validation loss: 2.4212259545613715

Epoch: 6| Step: 8
Training loss: 0.41608707727746613
Validation loss: 2.4547563192935478

Epoch: 6| Step: 9
Training loss: 0.476184225821914
Validation loss: 2.462645887225329

Epoch: 6| Step: 10
Training loss: 0.46965855921086797
Validation loss: 2.4258203418608266

Epoch: 6| Step: 11
Training loss: 0.4734493568874499
Validation loss: 2.471739614453224

Epoch: 6| Step: 12
Training loss: 0.2046788461326372
Validation loss: 2.424439704057231

Epoch: 6| Step: 13
Training loss: 0.17804085852319576
Validation loss: 2.4773418183358853

Epoch: 314| Step: 0
Training loss: 0.38622537602323537
Validation loss: 2.450761117882926

Epoch: 6| Step: 1
Training loss: 0.35032713324400183
Validation loss: 2.431966552029822

Epoch: 6| Step: 2
Training loss: 0.4588659904881981
Validation loss: 2.3935436191405763

Epoch: 6| Step: 3
Training loss: 0.3601115805175657
Validation loss: 2.410171181926409

Epoch: 6| Step: 4
Training loss: 0.5787257861763233
Validation loss: 2.400478577197139

Epoch: 6| Step: 5
Training loss: 0.4081727158020446
Validation loss: 2.384122476925197

Epoch: 6| Step: 6
Training loss: 0.40562589095712864
Validation loss: 2.4131594209000133

Epoch: 6| Step: 7
Training loss: 0.3337823133863302
Validation loss: 2.3788318507561557

Epoch: 6| Step: 8
Training loss: 0.3939133138904656
Validation loss: 2.4118986870317882

Epoch: 6| Step: 9
Training loss: 0.5043997898178509
Validation loss: 2.393369926806782

Epoch: 6| Step: 10
Training loss: 0.2979645186565397
Validation loss: 2.4114670437157804

Epoch: 6| Step: 11
Training loss: 0.45911850288378336
Validation loss: 2.411659998968251

Epoch: 6| Step: 12
Training loss: 0.5724116324644275
Validation loss: 2.4259284430587704

Epoch: 6| Step: 13
Training loss: 0.0749091922359617
Validation loss: 2.4413494239018307

Epoch: 315| Step: 0
Training loss: 0.41521900539716194
Validation loss: 2.460298459469068

Epoch: 6| Step: 1
Training loss: 0.11409601346280689
Validation loss: 2.460864579148597

Epoch: 6| Step: 2
Training loss: 0.6240466476207346
Validation loss: 2.438529323916299

Epoch: 6| Step: 3
Training loss: 0.4247025991959838
Validation loss: 2.4614600516658673

Epoch: 6| Step: 4
Training loss: 0.41317012280743
Validation loss: 2.45449117811465

Epoch: 6| Step: 5
Training loss: 0.41879420901127673
Validation loss: 2.454914806758999

Epoch: 6| Step: 6
Training loss: 0.5624790982495582
Validation loss: 2.459046729768867

Epoch: 6| Step: 7
Training loss: 0.39158565650657245
Validation loss: 2.469882892587365

Epoch: 6| Step: 8
Training loss: 0.4281679507798455
Validation loss: 2.4328894815388935

Epoch: 6| Step: 9
Training loss: 0.31136449508067626
Validation loss: 2.466656610550984

Epoch: 6| Step: 10
Training loss: 0.3779559458991985
Validation loss: 2.4712617079858994

Epoch: 6| Step: 11
Training loss: 0.565856772299225
Validation loss: 2.49869852644702

Epoch: 6| Step: 12
Training loss: 0.2292837779319218
Validation loss: 2.4955887094280205

Epoch: 6| Step: 13
Training loss: 0.20316099801564216
Validation loss: 2.5283060550293643

Epoch: 316| Step: 0
Training loss: 0.27210240719044826
Validation loss: 2.4378903120913944

Epoch: 6| Step: 1
Training loss: 0.13681565665040388
Validation loss: 2.478988422002065

Epoch: 6| Step: 2
Training loss: 0.5058049353096687
Validation loss: 2.454565741905154

Epoch: 6| Step: 3
Training loss: 0.1643216436601792
Validation loss: 2.474660450773551

Epoch: 6| Step: 4
Training loss: 0.4104270949063533
Validation loss: 2.4573529048887406

Epoch: 6| Step: 5
Training loss: 0.5179207873110169
Validation loss: 2.481696717198306

Epoch: 6| Step: 6
Training loss: 0.43902322722490295
Validation loss: 2.436595090380971

Epoch: 6| Step: 7
Training loss: 0.46092398672177165
Validation loss: 2.4733146907044214

Epoch: 6| Step: 8
Training loss: 0.3521011887862623
Validation loss: 2.4692166854240183

Epoch: 6| Step: 9
Training loss: 0.6178913207803248
Validation loss: 2.431434360280297

Epoch: 6| Step: 10
Training loss: 0.6620537838624541
Validation loss: 2.4332313982197227

Epoch: 6| Step: 11
Training loss: 0.3301130987294892
Validation loss: 2.4179943881921266

Epoch: 6| Step: 12
Training loss: 0.3827369576480127
Validation loss: 2.4104644492708944

Epoch: 6| Step: 13
Training loss: 0.18313644147224234
Validation loss: 2.4472303641094064

Epoch: 317| Step: 0
Training loss: 0.18758308040264887
Validation loss: 2.4260155993916563

Epoch: 6| Step: 1
Training loss: 0.3061628202991214
Validation loss: 2.445951892237521

Epoch: 6| Step: 2
Training loss: 0.2778175765904985
Validation loss: 2.4695474741867733

Epoch: 6| Step: 3
Training loss: 0.3210905093472714
Validation loss: 2.451810976166152

Epoch: 6| Step: 4
Training loss: 0.558681187755458
Validation loss: 2.443842078089429

Epoch: 6| Step: 5
Training loss: 0.6075737079598619
Validation loss: 2.4380193303807207

Epoch: 6| Step: 6
Training loss: 0.49268842365236865
Validation loss: 2.4603434564338036

Epoch: 6| Step: 7
Training loss: 0.3019483760840291
Validation loss: 2.448711000028807

Epoch: 6| Step: 8
Training loss: 0.5217837785041675
Validation loss: 2.4077091440781304

Epoch: 6| Step: 9
Training loss: 0.3951483329079394
Validation loss: 2.460669071306965

Epoch: 6| Step: 10
Training loss: 0.4440048325561317
Validation loss: 2.478498865965919

Epoch: 6| Step: 11
Training loss: 0.4928297061371719
Validation loss: 2.441857560772606

Epoch: 6| Step: 12
Training loss: 0.4115483410890004
Validation loss: 2.4538059636284184

Epoch: 6| Step: 13
Training loss: 0.27610878608230216
Validation loss: 2.4129782144974747

Epoch: 318| Step: 0
Training loss: 0.46089136571669764
Validation loss: 2.4621479110652746

Epoch: 6| Step: 1
Training loss: 0.5444003655253745
Validation loss: 2.430929087714028

Epoch: 6| Step: 2
Training loss: 0.6184233593203552
Validation loss: 2.4923692019099186

Epoch: 6| Step: 3
Training loss: 0.2713546305681145
Validation loss: 2.485881886818889

Epoch: 6| Step: 4
Training loss: 0.34384846360843935
Validation loss: 2.471638915638896

Epoch: 6| Step: 5
Training loss: 0.5373173536432204
Validation loss: 2.488814889022121

Epoch: 6| Step: 6
Training loss: 0.28378094886685673
Validation loss: 2.4818577044209142

Epoch: 6| Step: 7
Training loss: 0.31688968789935607
Validation loss: 2.4584925102757422

Epoch: 6| Step: 8
Training loss: 0.4003650191888496
Validation loss: 2.433571220012786

Epoch: 6| Step: 9
Training loss: 0.38925307635131073
Validation loss: 2.454276679402885

Epoch: 6| Step: 10
Training loss: 0.36918278609805816
Validation loss: 2.4042391632621025

Epoch: 6| Step: 11
Training loss: 0.3233230351417189
Validation loss: 2.4027857513488273

Epoch: 6| Step: 12
Training loss: 0.48460293605818694
Validation loss: 2.436528595239466

Epoch: 6| Step: 13
Training loss: 0.28746921021990385
Validation loss: 2.4017252885893403

Epoch: 319| Step: 0
Training loss: 0.36589638997882884
Validation loss: 2.416578010280829

Epoch: 6| Step: 1
Training loss: 0.49489565977836086
Validation loss: 2.4012704194446686

Epoch: 6| Step: 2
Training loss: 0.42587657176433946
Validation loss: 2.4598410793507504

Epoch: 6| Step: 3
Training loss: 0.6754028716336654
Validation loss: 2.4427710871265695

Epoch: 6| Step: 4
Training loss: 0.4471274249859179
Validation loss: 2.4654499166210497

Epoch: 6| Step: 5
Training loss: 0.22165051238871838
Validation loss: 2.4614675560100956

Epoch: 6| Step: 6
Training loss: 0.21485385870993917
Validation loss: 2.454405550246044

Epoch: 6| Step: 7
Training loss: 0.3744602491280892
Validation loss: 2.4280377561937336

Epoch: 6| Step: 8
Training loss: 0.5095052236714123
Validation loss: 2.44519472524938

Epoch: 6| Step: 9
Training loss: 0.34374175278567154
Validation loss: 2.4166687934266413

Epoch: 6| Step: 10
Training loss: 0.5581698910301224
Validation loss: 2.4273217693357716

Epoch: 6| Step: 11
Training loss: 0.3953083430135735
Validation loss: 2.4314959243858647

Epoch: 6| Step: 12
Training loss: 0.46560241593245355
Validation loss: 2.44347369618903

Epoch: 6| Step: 13
Training loss: 0.4235197430797298
Validation loss: 2.506292436079001

Epoch: 320| Step: 0
Training loss: 0.423386127973289
Validation loss: 2.4829748140447965

Epoch: 6| Step: 1
Training loss: 0.4943102820531515
Validation loss: 2.497179139101842

Epoch: 6| Step: 2
Training loss: 0.23290526986744428
Validation loss: 2.4544370857601376

Epoch: 6| Step: 3
Training loss: 0.7052634463240355
Validation loss: 2.4456329445015825

Epoch: 6| Step: 4
Training loss: 0.3745249083184597
Validation loss: 2.4407337562959848

Epoch: 6| Step: 5
Training loss: 0.33031175459937345
Validation loss: 2.399026573722034

Epoch: 6| Step: 6
Training loss: 0.5093412423210498
Validation loss: 2.4226126064638382

Epoch: 6| Step: 7
Training loss: 0.4793942384452804
Validation loss: 2.384043741813819

Epoch: 6| Step: 8
Training loss: 0.4740248640405969
Validation loss: 2.4150115697327914

Epoch: 6| Step: 9
Training loss: 0.4388782555848627
Validation loss: 2.42605365823881

Epoch: 6| Step: 10
Training loss: 0.5618934009666203
Validation loss: 2.4600108672928367

Epoch: 6| Step: 11
Training loss: 0.31168951791401145
Validation loss: 2.45704613077615

Epoch: 6| Step: 12
Training loss: 0.2672771794136186
Validation loss: 2.463408132600244

Epoch: 6| Step: 13
Training loss: 0.5232642726929131
Validation loss: 2.482975344743352

Epoch: 321| Step: 0
Training loss: 0.3762871784395492
Validation loss: 2.479691958977018

Epoch: 6| Step: 1
Training loss: 0.279510109871275
Validation loss: 2.482280049913009

Epoch: 6| Step: 2
Training loss: 0.37487953953349185
Validation loss: 2.471379784051973

Epoch: 6| Step: 3
Training loss: 0.6485756186954011
Validation loss: 2.484466713566661

Epoch: 6| Step: 4
Training loss: 0.37584460035776457
Validation loss: 2.4814675106189186

Epoch: 6| Step: 5
Training loss: 0.304024120900066
Validation loss: 2.47049093798111

Epoch: 6| Step: 6
Training loss: 0.4599467475791878
Validation loss: 2.4380050506162614

Epoch: 6| Step: 7
Training loss: 0.24810887860886865
Validation loss: 2.44531795266917

Epoch: 6| Step: 8
Training loss: 0.2703217510338247
Validation loss: 2.4430523705380445

Epoch: 6| Step: 9
Training loss: 0.2690243307813069
Validation loss: 2.4549255075655063

Epoch: 6| Step: 10
Training loss: 0.44868430812373616
Validation loss: 2.4439645660059455

Epoch: 6| Step: 11
Training loss: 0.5964047411888811
Validation loss: 2.423148395691438

Epoch: 6| Step: 12
Training loss: 0.4726840870123838
Validation loss: 2.4690033416750685

Epoch: 6| Step: 13
Training loss: 0.4002154269360102
Validation loss: 2.4664133950284186

Epoch: 322| Step: 0
Training loss: 0.3068112912833206
Validation loss: 2.4600293680814582

Epoch: 6| Step: 1
Training loss: 0.34303661578689654
Validation loss: 2.4251788957257294

Epoch: 6| Step: 2
Training loss: 0.4045901317627637
Validation loss: 2.4178718670606067

Epoch: 6| Step: 3
Training loss: 0.2903278338978647
Validation loss: 2.405502050737637

Epoch: 6| Step: 4
Training loss: 0.33697705992915183
Validation loss: 2.4299439510307854

Epoch: 6| Step: 5
Training loss: 0.4708225842602039
Validation loss: 2.4011874928838464

Epoch: 6| Step: 6
Training loss: 0.6198084265315517
Validation loss: 2.4173101221656355

Epoch: 6| Step: 7
Training loss: 0.3038415045525288
Validation loss: 2.3880921168888767

Epoch: 6| Step: 8
Training loss: 0.30382670560364483
Validation loss: 2.3945371405614315

Epoch: 6| Step: 9
Training loss: 0.47766111721445315
Validation loss: 2.407260096258447

Epoch: 6| Step: 10
Training loss: 0.3837023921101608
Validation loss: 2.413449984508587

Epoch: 6| Step: 11
Training loss: 0.3316480781787048
Validation loss: 2.4259936756036584

Epoch: 6| Step: 12
Training loss: 0.34368268350894915
Validation loss: 2.4190562723200872

Epoch: 6| Step: 13
Training loss: 0.7210221656984599
Validation loss: 2.402957172380324

Epoch: 323| Step: 0
Training loss: 0.24460951219991653
Validation loss: 2.4328387106102345

Epoch: 6| Step: 1
Training loss: 0.427576671774214
Validation loss: 2.4043598739417904

Epoch: 6| Step: 2
Training loss: 0.5566162371730593
Validation loss: 2.4697348210218557

Epoch: 6| Step: 3
Training loss: 0.5192641238356552
Validation loss: 2.4466788757032787

Epoch: 6| Step: 4
Training loss: 0.49621931874823805
Validation loss: 2.4642045708044034

Epoch: 6| Step: 5
Training loss: 0.43308093701442785
Validation loss: 2.4318076758872578

Epoch: 6| Step: 6
Training loss: 0.47365813826660075
Validation loss: 2.492756591919108

Epoch: 6| Step: 7
Training loss: 0.3259739532274849
Validation loss: 2.464303060018901

Epoch: 6| Step: 8
Training loss: 0.3604936397179245
Validation loss: 2.4708020708410112

Epoch: 6| Step: 9
Training loss: 0.4543932234456082
Validation loss: 2.4298505714838456

Epoch: 6| Step: 10
Training loss: 0.23766606291175502
Validation loss: 2.394858733374878

Epoch: 6| Step: 11
Training loss: 0.24578137478397838
Validation loss: 2.3925163534635505

Epoch: 6| Step: 12
Training loss: 0.433911731041099
Validation loss: 2.407326006922073

Epoch: 6| Step: 13
Training loss: 0.1787946848769774
Validation loss: 2.411062826142517

Epoch: 324| Step: 0
Training loss: 0.41552685962832586
Validation loss: 2.3982428512853664

Epoch: 6| Step: 1
Training loss: 0.38776045475385934
Validation loss: 2.42817088451323

Epoch: 6| Step: 2
Training loss: 0.3717974565905827
Validation loss: 2.417148069722754

Epoch: 6| Step: 3
Training loss: 0.3735752657629688
Validation loss: 2.4068456034374006

Epoch: 6| Step: 4
Training loss: 0.5879513528578122
Validation loss: 2.4325827154590316

Epoch: 6| Step: 5
Training loss: 0.2774463248966578
Validation loss: 2.4402467398377823

Epoch: 6| Step: 6
Training loss: 0.3836801194734622
Validation loss: 2.4396845470692163

Epoch: 6| Step: 7
Training loss: 0.4977242715241529
Validation loss: 2.4584162805689456

Epoch: 6| Step: 8
Training loss: 0.49506105484743707
Validation loss: 2.4756682203928264

Epoch: 6| Step: 9
Training loss: 0.11232226275706189
Validation loss: 2.4648889578075903

Epoch: 6| Step: 10
Training loss: 0.43313397267503206
Validation loss: 2.461946544184081

Epoch: 6| Step: 11
Training loss: 0.16615578400900058
Validation loss: 2.4445307983770945

Epoch: 6| Step: 12
Training loss: 0.3192367749719801
Validation loss: 2.463153179851692

Epoch: 6| Step: 13
Training loss: 0.15024875786263103
Validation loss: 2.450400073326794

Epoch: 325| Step: 0
Training loss: 0.22376175873509338
Validation loss: 2.4575546346019714

Epoch: 6| Step: 1
Training loss: 0.3837836461740597
Validation loss: 2.451228844667329

Epoch: 6| Step: 2
Training loss: 0.30691513603171267
Validation loss: 2.452714655159498

Epoch: 6| Step: 3
Training loss: 0.5103425893421744
Validation loss: 2.4707597231815672

Epoch: 6| Step: 4
Training loss: 0.44029993484686325
Validation loss: 2.4340577858463566

Epoch: 6| Step: 5
Training loss: 0.2923405715508624
Validation loss: 2.4373424427571937

Epoch: 6| Step: 6
Training loss: 0.3417628898073406
Validation loss: 2.4470389491576032

Epoch: 6| Step: 7
Training loss: 0.3424293007764586
Validation loss: 2.479652476794041

Epoch: 6| Step: 8
Training loss: 0.3974305312314625
Validation loss: 2.4319777754649636

Epoch: 6| Step: 9
Training loss: 0.275821781151836
Validation loss: 2.4375759877533723

Epoch: 6| Step: 10
Training loss: 0.4077735538813212
Validation loss: 2.4360298553938535

Epoch: 6| Step: 11
Training loss: 0.5692842175398558
Validation loss: 2.4334287559683516

Epoch: 6| Step: 12
Training loss: 0.38186551733152574
Validation loss: 2.387213931098678

Epoch: 6| Step: 13
Training loss: 0.47843035502614495
Validation loss: 2.460671372745863

Epoch: 326| Step: 0
Training loss: 0.38240181049083927
Validation loss: 2.448371025984165

Epoch: 6| Step: 1
Training loss: 0.22292712950588287
Validation loss: 2.424611399554778

Epoch: 6| Step: 2
Training loss: 0.5192107739497438
Validation loss: 2.4262053762406026

Epoch: 6| Step: 3
Training loss: 0.26845440466058307
Validation loss: 2.4447119746430133

Epoch: 6| Step: 4
Training loss: 0.2883869731949026
Validation loss: 2.45102875523804

Epoch: 6| Step: 5
Training loss: 0.6184823902448016
Validation loss: 2.4245327987352807

Epoch: 6| Step: 6
Training loss: 0.3687174758468819
Validation loss: 2.459377007485506

Epoch: 6| Step: 7
Training loss: 0.23682430293494944
Validation loss: 2.4640340355733272

Epoch: 6| Step: 8
Training loss: 0.48305602613946186
Validation loss: 2.4666072434909005

Epoch: 6| Step: 9
Training loss: 0.30635052218447945
Validation loss: 2.435410204539802

Epoch: 6| Step: 10
Training loss: 0.3805182665614662
Validation loss: 2.460030495652766

Epoch: 6| Step: 11
Training loss: 0.1662019525468489
Validation loss: 2.4559465219333045

Epoch: 6| Step: 12
Training loss: 0.5770186070065038
Validation loss: 2.45825990852618

Epoch: 6| Step: 13
Training loss: 0.23078344971648654
Validation loss: 2.447490689809864

Epoch: 327| Step: 0
Training loss: 0.24373484649994093
Validation loss: 2.4043817204364957

Epoch: 6| Step: 1
Training loss: 0.1727389545342582
Validation loss: 2.455356320659498

Epoch: 6| Step: 2
Training loss: 0.651029576507206
Validation loss: 2.4306729046277575

Epoch: 6| Step: 3
Training loss: 0.5658048133188919
Validation loss: 2.4117016296258456

Epoch: 6| Step: 4
Training loss: 0.38011674126130507
Validation loss: 2.4097198185850557

Epoch: 6| Step: 5
Training loss: 0.5145469435155772
Validation loss: 2.4609890267166485

Epoch: 6| Step: 6
Training loss: 0.15542375737813774
Validation loss: 2.424702924421802

Epoch: 6| Step: 7
Training loss: 0.25128088583348773
Validation loss: 2.4481114894931624

Epoch: 6| Step: 8
Training loss: 0.4909631547835448
Validation loss: 2.467634112669873

Epoch: 6| Step: 9
Training loss: 0.30395353385808765
Validation loss: 2.4954511152947347

Epoch: 6| Step: 10
Training loss: 0.19210977106724478
Validation loss: 2.469745603977402

Epoch: 6| Step: 11
Training loss: 0.23363520372446156
Validation loss: 2.494943342920858

Epoch: 6| Step: 12
Training loss: 0.40139033489817477
Validation loss: 2.490622311671697

Epoch: 6| Step: 13
Training loss: 0.5092063554424111
Validation loss: 2.4811406730647785

Epoch: 328| Step: 0
Training loss: 0.18415862293679228
Validation loss: 2.508546149635758

Epoch: 6| Step: 1
Training loss: 0.5689781464970809
Validation loss: 2.480143997525212

Epoch: 6| Step: 2
Training loss: 0.359372056036791
Validation loss: 2.48234202606031

Epoch: 6| Step: 3
Training loss: 0.3661424903481878
Validation loss: 2.4964200598555406

Epoch: 6| Step: 4
Training loss: 0.5294422358270784
Validation loss: 2.470160157765983

Epoch: 6| Step: 5
Training loss: 0.4893010285987076
Validation loss: 2.495040539636512

Epoch: 6| Step: 6
Training loss: 0.37596724857832403
Validation loss: 2.4830494576442814

Epoch: 6| Step: 7
Training loss: 0.26344976607033754
Validation loss: 2.443521216179284

Epoch: 6| Step: 8
Training loss: 0.39318843866423286
Validation loss: 2.4575863435538587

Epoch: 6| Step: 9
Training loss: 0.4877575316363334
Validation loss: 2.469948558279168

Epoch: 6| Step: 10
Training loss: 0.2724699613656024
Validation loss: 2.4714413644821573

Epoch: 6| Step: 11
Training loss: 0.33938097960822655
Validation loss: 2.459307647673864

Epoch: 6| Step: 12
Training loss: 0.12866203698983228
Validation loss: 2.458629334491309

Epoch: 6| Step: 13
Training loss: 0.13798933224503893
Validation loss: 2.5000712179479114

Epoch: 329| Step: 0
Training loss: 0.18930848489472532
Validation loss: 2.453740274971945

Epoch: 6| Step: 1
Training loss: 0.24571061964385318
Validation loss: 2.471901300450954

Epoch: 6| Step: 2
Training loss: 0.23874783563631463
Validation loss: 2.4610630699372296

Epoch: 6| Step: 3
Training loss: 0.45844886869702217
Validation loss: 2.476085586514153

Epoch: 6| Step: 4
Training loss: 0.1924043246407246
Validation loss: 2.4711777512927156

Epoch: 6| Step: 5
Training loss: 0.3542790468350505
Validation loss: 2.4597985177141886

Epoch: 6| Step: 6
Training loss: 0.36307921995912334
Validation loss: 2.467766072059172

Epoch: 6| Step: 7
Training loss: 0.31434073720296546
Validation loss: 2.443857324506988

Epoch: 6| Step: 8
Training loss: 0.1690869151376522
Validation loss: 2.4594655708399316

Epoch: 6| Step: 9
Training loss: 0.680107250170603
Validation loss: 2.437827976690967

Epoch: 6| Step: 10
Training loss: 0.17989627485399637
Validation loss: 2.4400429388276126

Epoch: 6| Step: 11
Training loss: 0.4654032601662803
Validation loss: 2.456756730621914

Epoch: 6| Step: 12
Training loss: 0.6068864529409975
Validation loss: 2.4467868977503078

Epoch: 6| Step: 13
Training loss: 0.3934123157988399
Validation loss: 2.429046980090881

Epoch: 330| Step: 0
Training loss: 0.25569606257265154
Validation loss: 2.4188853472811416

Epoch: 6| Step: 1
Training loss: 0.20085328068013703
Validation loss: 2.4297345025033144

Epoch: 6| Step: 2
Training loss: 0.3235767857015775
Validation loss: 2.451219151100666

Epoch: 6| Step: 3
Training loss: 0.5211288440331071
Validation loss: 2.456491084216622

Epoch: 6| Step: 4
Training loss: 0.39246275615754855
Validation loss: 2.4429607681161913

Epoch: 6| Step: 5
Training loss: 0.13702157407242072
Validation loss: 2.475052259433537

Epoch: 6| Step: 6
Training loss: 0.34285167877066647
Validation loss: 2.468799106145339

Epoch: 6| Step: 7
Training loss: 0.48920115982348616
Validation loss: 2.49596920444441

Epoch: 6| Step: 8
Training loss: 0.4497363881356766
Validation loss: 2.4715247412029586

Epoch: 6| Step: 9
Training loss: 0.30252875451492145
Validation loss: 2.490803211734996

Epoch: 6| Step: 10
Training loss: 0.21102723226361939
Validation loss: 2.48689208962504

Epoch: 6| Step: 11
Training loss: 0.4385712655137257
Validation loss: 2.498540839062778

Epoch: 6| Step: 12
Training loss: 0.3688289396199848
Validation loss: 2.5085830391526662

Epoch: 6| Step: 13
Training loss: 0.7143167940258198
Validation loss: 2.4665553622699354

Epoch: 331| Step: 0
Training loss: 0.43801109229046936
Validation loss: 2.429643162955672

Epoch: 6| Step: 1
Training loss: 0.4512217440436809
Validation loss: 2.437172541934261

Epoch: 6| Step: 2
Training loss: 0.2826868547410704
Validation loss: 2.427700990996737

Epoch: 6| Step: 3
Training loss: 0.3267518329700289
Validation loss: 2.392557797541268

Epoch: 6| Step: 4
Training loss: 0.27339936399187037
Validation loss: 2.4202628050085333

Epoch: 6| Step: 5
Training loss: 0.4072900260671109
Validation loss: 2.378243146399522

Epoch: 6| Step: 6
Training loss: 0.31735685975997174
Validation loss: 2.421496350250841

Epoch: 6| Step: 7
Training loss: 0.33313481434505343
Validation loss: 2.4026166121815167

Epoch: 6| Step: 8
Training loss: 0.5058090891938132
Validation loss: 2.4361575215765403

Epoch: 6| Step: 9
Training loss: 0.4063152480913407
Validation loss: 2.4300907991143745

Epoch: 6| Step: 10
Training loss: 0.19964611738032753
Validation loss: 2.44750917630417

Epoch: 6| Step: 11
Training loss: 0.5089711396142571
Validation loss: 2.4900668465845524

Epoch: 6| Step: 12
Training loss: 0.35301424796268477
Validation loss: 2.4472996016244157

Epoch: 6| Step: 13
Training loss: 0.3384749151102821
Validation loss: 2.452361079957374

Epoch: 332| Step: 0
Training loss: 0.25648140460829405
Validation loss: 2.4533408875781566

Epoch: 6| Step: 1
Training loss: 0.4403445886922452
Validation loss: 2.4799633769297755

Epoch: 6| Step: 2
Training loss: 0.23076319877676169
Validation loss: 2.4684864036903478

Epoch: 6| Step: 3
Training loss: 0.27717046293951303
Validation loss: 2.4845258904671566

Epoch: 6| Step: 4
Training loss: 0.2171219201871513
Validation loss: 2.4630763283380017

Epoch: 6| Step: 5
Training loss: 0.6286435733766133
Validation loss: 2.468142518703051

Epoch: 6| Step: 6
Training loss: 0.4742680802053462
Validation loss: 2.450531868045995

Epoch: 6| Step: 7
Training loss: 0.45497670496529924
Validation loss: 2.4786190356372506

Epoch: 6| Step: 8
Training loss: 0.45503146214752355
Validation loss: 2.4613628175527347

Epoch: 6| Step: 9
Training loss: 0.36954115275689453
Validation loss: 2.4636693503088245

Epoch: 6| Step: 10
Training loss: 0.35979002332431725
Validation loss: 2.4328963066237286

Epoch: 6| Step: 11
Training loss: 0.4422358927851486
Validation loss: 2.435388126106232

Epoch: 6| Step: 12
Training loss: 0.3763227974053457
Validation loss: 2.4252718505106423

Epoch: 6| Step: 13
Training loss: 0.2365729663629852
Validation loss: 2.4575087368984607

Epoch: 333| Step: 0
Training loss: 0.5490929178617291
Validation loss: 2.446269018919534

Epoch: 6| Step: 1
Training loss: 0.29160279045689597
Validation loss: 2.3836593400732924

Epoch: 6| Step: 2
Training loss: 0.3724644693288197
Validation loss: 2.4186851790187847

Epoch: 6| Step: 3
Training loss: 0.38058038910512865
Validation loss: 2.4411149082718175

Epoch: 6| Step: 4
Training loss: 0.49544230063008504
Validation loss: 2.4230400286892757

Epoch: 6| Step: 5
Training loss: 0.2934163933415663
Validation loss: 2.458860344672917

Epoch: 6| Step: 6
Training loss: 0.4141404060632328
Validation loss: 2.432854734110254

Epoch: 6| Step: 7
Training loss: 0.23394644816746069
Validation loss: 2.4289774634566768

Epoch: 6| Step: 8
Training loss: 0.5622930410914132
Validation loss: 2.4685362347784268

Epoch: 6| Step: 9
Training loss: 0.39440470261720223
Validation loss: 2.4565539990227077

Epoch: 6| Step: 10
Training loss: 0.22197540657430698
Validation loss: 2.46477317939802

Epoch: 6| Step: 11
Training loss: 0.35197020308269045
Validation loss: 2.4468522497373177

Epoch: 6| Step: 12
Training loss: 0.2522272939613799
Validation loss: 2.427889089193867

Epoch: 6| Step: 13
Training loss: 0.10967745854530978
Validation loss: 2.457484982377399

Epoch: 334| Step: 0
Training loss: 0.26386235738832914
Validation loss: 2.440695949470282

Epoch: 6| Step: 1
Training loss: 0.4787965689387596
Validation loss: 2.4407404817195717

Epoch: 6| Step: 2
Training loss: 0.2024537696872276
Validation loss: 2.4311952650526307

Epoch: 6| Step: 3
Training loss: 0.28266648058409083
Validation loss: 2.44050941714072

Epoch: 6| Step: 4
Training loss: 0.4878474635632311
Validation loss: 2.461844641915757

Epoch: 6| Step: 5
Training loss: 0.353428550660878
Validation loss: 2.457929951099012

Epoch: 6| Step: 6
Training loss: 0.26031539219306293
Validation loss: 2.4439713727498527

Epoch: 6| Step: 7
Training loss: 0.4997285314560061
Validation loss: 2.4190005400206167

Epoch: 6| Step: 8
Training loss: 0.4001200250020182
Validation loss: 2.437061335550851

Epoch: 6| Step: 9
Training loss: 0.35599679816338486
Validation loss: 2.4439391179096495

Epoch: 6| Step: 10
Training loss: 0.3253670888863007
Validation loss: 2.4306504271977762

Epoch: 6| Step: 11
Training loss: 0.4350183127922313
Validation loss: 2.444073746450995

Epoch: 6| Step: 12
Training loss: 0.44478517396582024
Validation loss: 2.4295928359479784

Epoch: 6| Step: 13
Training loss: 0.22420656323958554
Validation loss: 2.45780659822554

Epoch: 335| Step: 0
Training loss: 0.4385056687785706
Validation loss: 2.444944271493767

Epoch: 6| Step: 1
Training loss: 0.6408333788385198
Validation loss: 2.4353855870840655

Epoch: 6| Step: 2
Training loss: 0.3223210027104664
Validation loss: 2.4410976073388104

Epoch: 6| Step: 3
Training loss: 0.15698013185340645
Validation loss: 2.4194110807765834

Epoch: 6| Step: 4
Training loss: 0.4759569542077923
Validation loss: 2.421733716322999

Epoch: 6| Step: 5
Training loss: 0.219353210299012
Validation loss: 2.4586108270777784

Epoch: 6| Step: 6
Training loss: 0.5171780749611786
Validation loss: 2.4700642887084014

Epoch: 6| Step: 7
Training loss: 0.28356883672570943
Validation loss: 2.457812030999421

Epoch: 6| Step: 8
Training loss: 0.3004022414958773
Validation loss: 2.4392817863102265

Epoch: 6| Step: 9
Training loss: 0.3410085688294672
Validation loss: 2.437677375391477

Epoch: 6| Step: 10
Training loss: 0.17000940962127534
Validation loss: 2.40029674296942

Epoch: 6| Step: 11
Training loss: 0.34631138970032366
Validation loss: 2.445858092466692

Epoch: 6| Step: 12
Training loss: 0.2672972214038112
Validation loss: 2.3967702038770846

Epoch: 6| Step: 13
Training loss: 0.46647460538836305
Validation loss: 2.4258252539268206

Epoch: 336| Step: 0
Training loss: 0.3294198169836664
Validation loss: 2.4519341711467897

Epoch: 6| Step: 1
Training loss: 0.2685028303537066
Validation loss: 2.4119719169674743

Epoch: 6| Step: 2
Training loss: 0.4541091426093654
Validation loss: 2.4346681230527185

Epoch: 6| Step: 3
Training loss: 0.4080334726083035
Validation loss: 2.4499616143185223

Epoch: 6| Step: 4
Training loss: 0.14475567894173993
Validation loss: 2.408941512227354

Epoch: 6| Step: 5
Training loss: 0.21968121378547584
Validation loss: 2.4167758968591495

Epoch: 6| Step: 6
Training loss: 0.2476357334194683
Validation loss: 2.42888835099984

Epoch: 6| Step: 7
Training loss: 0.3927349327786129
Validation loss: 2.4095526953175854

Epoch: 6| Step: 8
Training loss: 0.44357800239755596
Validation loss: 2.394421661716563

Epoch: 6| Step: 9
Training loss: 0.3372568901756509
Validation loss: 2.3931785150635676

Epoch: 6| Step: 10
Training loss: 0.514550158040018
Validation loss: 2.3927686874647303

Epoch: 6| Step: 11
Training loss: 0.3331212496591131
Validation loss: 2.3726165752716177

Epoch: 6| Step: 12
Training loss: 0.4330423474681627
Validation loss: 2.4108655802549115

Epoch: 6| Step: 13
Training loss: 0.41006425098242455
Validation loss: 2.4234822614093106

Epoch: 337| Step: 0
Training loss: 0.5924335743492044
Validation loss: 2.430055027378393

Epoch: 6| Step: 1
Training loss: 0.14005070881318613
Validation loss: 2.4291363547927443

Epoch: 6| Step: 2
Training loss: 0.5271117653798901
Validation loss: 2.430420636379438

Epoch: 6| Step: 3
Training loss: 0.31713692163185603
Validation loss: 2.3922533921813187

Epoch: 6| Step: 4
Training loss: 0.4504617494270056
Validation loss: 2.453432612364306

Epoch: 6| Step: 5
Training loss: 0.16118954902299126
Validation loss: 2.4438637476114895

Epoch: 6| Step: 6
Training loss: 0.43268581216370805
Validation loss: 2.439140012109252

Epoch: 6| Step: 7
Training loss: 0.3620076774328372
Validation loss: 2.457875509649822

Epoch: 6| Step: 8
Training loss: 0.23886750752263064
Validation loss: 2.4403588342478373

Epoch: 6| Step: 9
Training loss: 0.344837549082112
Validation loss: 2.4246064268757435

Epoch: 6| Step: 10
Training loss: 0.3710360231172038
Validation loss: 2.461003306456824

Epoch: 6| Step: 11
Training loss: 0.23227845904232303
Validation loss: 2.4811212241083624

Epoch: 6| Step: 12
Training loss: 0.359906301424381
Validation loss: 2.469133739001522

Epoch: 6| Step: 13
Training loss: 0.3475759499212363
Validation loss: 2.517357527905098

Epoch: 338| Step: 0
Training loss: 0.44657284585168083
Validation loss: 2.494646992559228

Epoch: 6| Step: 1
Training loss: 0.25054238015910746
Validation loss: 2.4749721072151916

Epoch: 6| Step: 2
Training loss: 0.4358497558670087
Validation loss: 2.496341469965204

Epoch: 6| Step: 3
Training loss: 0.3326949050612383
Validation loss: 2.497808059501208

Epoch: 6| Step: 4
Training loss: 0.5115263482557564
Validation loss: 2.4604575391483743

Epoch: 6| Step: 5
Training loss: 0.52312693706049
Validation loss: 2.456344956520015

Epoch: 6| Step: 6
Training loss: 0.3578463883989367
Validation loss: 2.4612847878275037

Epoch: 6| Step: 7
Training loss: 0.35223378624499035
Validation loss: 2.4337549744304314

Epoch: 6| Step: 8
Training loss: 0.27306247606580775
Validation loss: 2.4764351036135297

Epoch: 6| Step: 9
Training loss: 0.2611215524806534
Validation loss: 2.43184887519425

Epoch: 6| Step: 10
Training loss: 0.38423532646445796
Validation loss: 2.3922244501546546

Epoch: 6| Step: 11
Training loss: 0.19277793469347815
Validation loss: 2.4372534930937406

Epoch: 6| Step: 12
Training loss: 0.27807610489172124
Validation loss: 2.386133052991765

Epoch: 6| Step: 13
Training loss: 0.26917734269374866
Validation loss: 2.4052715744080553

Epoch: 339| Step: 0
Training loss: 0.14395152923534243
Validation loss: 2.4497758618010517

Epoch: 6| Step: 1
Training loss: 0.25158732866292866
Validation loss: 2.4382968827370717

Epoch: 6| Step: 2
Training loss: 0.6082090569845718
Validation loss: 2.41947508482365

Epoch: 6| Step: 3
Training loss: 0.46440382584327455
Validation loss: 2.4603203357230767

Epoch: 6| Step: 4
Training loss: 0.46436053894034696
Validation loss: 2.4350593544011296

Epoch: 6| Step: 5
Training loss: 0.3247062625732502
Validation loss: 2.4389320354986914

Epoch: 6| Step: 6
Training loss: 0.2718031952844887
Validation loss: 2.464681041417529

Epoch: 6| Step: 7
Training loss: 0.18017324843862012
Validation loss: 2.4412368861365814

Epoch: 6| Step: 8
Training loss: 0.4565143759846472
Validation loss: 2.4424926356822607

Epoch: 6| Step: 9
Training loss: 0.2635630206301285
Validation loss: 2.458268613330104

Epoch: 6| Step: 10
Training loss: 0.13404698813447313
Validation loss: 2.4315917626469714

Epoch: 6| Step: 11
Training loss: 0.4501823704776977
Validation loss: 2.4494160554059197

Epoch: 6| Step: 12
Training loss: 0.3775319611364512
Validation loss: 2.437963074143934

Epoch: 6| Step: 13
Training loss: 0.1431574743193955
Validation loss: 2.4151614773616306

Epoch: 340| Step: 0
Training loss: 0.3080942118624131
Validation loss: 2.4305358604262137

Epoch: 6| Step: 1
Training loss: 0.26612086853970157
Validation loss: 2.433745737425215

Epoch: 6| Step: 2
Training loss: 0.28000079993576493
Validation loss: 2.409475904655157

Epoch: 6| Step: 3
Training loss: 0.2805215089952501
Validation loss: 2.428060796815886

Epoch: 6| Step: 4
Training loss: 0.3669750532420889
Validation loss: 2.4103255344174466

Epoch: 6| Step: 5
Training loss: 0.5628037956873685
Validation loss: 2.395692027357967

Epoch: 6| Step: 6
Training loss: 0.40570295622183206
Validation loss: 2.399823991754604

Epoch: 6| Step: 7
Training loss: 0.4061218022766276
Validation loss: 2.3853474791597598

Epoch: 6| Step: 8
Training loss: 0.33292909290261075
Validation loss: 2.3843155392891657

Epoch: 6| Step: 9
Training loss: 0.25274605878800205
Validation loss: 2.378333958117374

Epoch: 6| Step: 10
Training loss: 0.4706851433449429
Validation loss: 2.3594783984951655

Epoch: 6| Step: 11
Training loss: 0.26014827567127885
Validation loss: 2.3626524852637125

Epoch: 6| Step: 12
Training loss: 0.21456112044524564
Validation loss: 2.345361524456494

Epoch: 6| Step: 13
Training loss: 0.38436696656678865
Validation loss: 2.3781827289128272

Epoch: 341| Step: 0
Training loss: 0.5090462003736377
Validation loss: 2.393201216962376

Epoch: 6| Step: 1
Training loss: 0.2414369103797035
Validation loss: 2.4153807899765676

Epoch: 6| Step: 2
Training loss: 0.3918210791340604
Validation loss: 2.4110391637401776

Epoch: 6| Step: 3
Training loss: 0.3072553656305875
Validation loss: 2.396717229140888

Epoch: 6| Step: 4
Training loss: 0.15719142070908695
Validation loss: 2.4034598925020187

Epoch: 6| Step: 5
Training loss: 0.2615810572969871
Validation loss: 2.429894834055897

Epoch: 6| Step: 6
Training loss: 0.20013829791749999
Validation loss: 2.4363988045926033

Epoch: 6| Step: 7
Training loss: 0.25998525011424417
Validation loss: 2.4175480355263974

Epoch: 6| Step: 8
Training loss: 0.35069905318430694
Validation loss: 2.413047010119613

Epoch: 6| Step: 9
Training loss: 0.3325986837995869
Validation loss: 2.4479970303977967

Epoch: 6| Step: 10
Training loss: 0.28111989932862846
Validation loss: 2.4469692390975197

Epoch: 6| Step: 11
Training loss: 0.28473152249480604
Validation loss: 2.436250684638064

Epoch: 6| Step: 12
Training loss: 0.6062520528542281
Validation loss: 2.428950767003721

Epoch: 6| Step: 13
Training loss: 0.3221504467989049
Validation loss: 2.4665342236620362

Epoch: 342| Step: 0
Training loss: 0.30534480182707424
Validation loss: 2.409900295292151

Epoch: 6| Step: 1
Training loss: 0.16710644432733135
Validation loss: 2.4016858354927466

Epoch: 6| Step: 2
Training loss: 0.34181884695003145
Validation loss: 2.424814896876371

Epoch: 6| Step: 3
Training loss: 0.29894012646056667
Validation loss: 2.440745734007269

Epoch: 6| Step: 4
Training loss: 0.43138183845222
Validation loss: 2.423048712955478

Epoch: 6| Step: 5
Training loss: 0.15838917047789158
Validation loss: 2.43027095583625

Epoch: 6| Step: 6
Training loss: 0.26920489580547435
Validation loss: 2.444790966920036

Epoch: 6| Step: 7
Training loss: 0.3648877870828876
Validation loss: 2.4388258703860637

Epoch: 6| Step: 8
Training loss: 0.15962645081321547
Validation loss: 2.4172703841438294

Epoch: 6| Step: 9
Training loss: 0.41725836305596786
Validation loss: 2.419302479611496

Epoch: 6| Step: 10
Training loss: 0.5074442188256498
Validation loss: 2.3844518247514612

Epoch: 6| Step: 11
Training loss: 0.23488256807503288
Validation loss: 2.4199202249997698

Epoch: 6| Step: 12
Training loss: 0.408854571623713
Validation loss: 2.4043426539968995

Epoch: 6| Step: 13
Training loss: 0.5000621637801652
Validation loss: 2.4122654898587244

Epoch: 343| Step: 0
Training loss: 0.4081085314502248
Validation loss: 2.3957421890477666

Epoch: 6| Step: 1
Training loss: 0.33247626158938687
Validation loss: 2.3891622540228217

Epoch: 6| Step: 2
Training loss: 0.35452194719479024
Validation loss: 2.39449866161491

Epoch: 6| Step: 3
Training loss: 0.21611092277856833
Validation loss: 2.4064346560115815

Epoch: 6| Step: 4
Training loss: 0.2563721272732147
Validation loss: 2.4091426337187802

Epoch: 6| Step: 5
Training loss: 0.6556742276746597
Validation loss: 2.4122013444668498

Epoch: 6| Step: 6
Training loss: 0.37498386666243466
Validation loss: 2.3798812570039614

Epoch: 6| Step: 7
Training loss: 0.40859001478891227
Validation loss: 2.449505998550055

Epoch: 6| Step: 8
Training loss: 0.2945091568125607
Validation loss: 2.4257872517353825

Epoch: 6| Step: 9
Training loss: 0.2933823019077156
Validation loss: 2.4119020947313388

Epoch: 6| Step: 10
Training loss: 0.20636416873316105
Validation loss: 2.4103334465816393

Epoch: 6| Step: 11
Training loss: 0.21555054318942066
Validation loss: 2.4551152509020477

Epoch: 6| Step: 12
Training loss: 0.14533344804862436
Validation loss: 2.41454824155124

Epoch: 6| Step: 13
Training loss: 0.20684629852020486
Validation loss: 2.411261918612662

Epoch: 344| Step: 0
Training loss: 0.38646616537926826
Validation loss: 2.39512154562173

Epoch: 6| Step: 1
Training loss: 0.23211726094051804
Validation loss: 2.4418425002961404

Epoch: 6| Step: 2
Training loss: 0.2173735363841345
Validation loss: 2.438213493228277

Epoch: 6| Step: 3
Training loss: 0.3176067325333672
Validation loss: 2.4105625211377446

Epoch: 6| Step: 4
Training loss: 0.4248115626688622
Validation loss: 2.424268453499855

Epoch: 6| Step: 5
Training loss: 0.3746710566395582
Validation loss: 2.436966108987649

Epoch: 6| Step: 6
Training loss: 0.3814291775323829
Validation loss: 2.428792906380968

Epoch: 6| Step: 7
Training loss: 0.382556518293537
Validation loss: 2.4403863124898213

Epoch: 6| Step: 8
Training loss: 0.14225522147301622
Validation loss: 2.4424958243654333

Epoch: 6| Step: 9
Training loss: 0.3264088940182356
Validation loss: 2.440665139740886

Epoch: 6| Step: 10
Training loss: 0.357807889017438
Validation loss: 2.4717365941811664

Epoch: 6| Step: 11
Training loss: 0.47770068782084496
Validation loss: 2.4751463531813305

Epoch: 6| Step: 12
Training loss: 0.21437889440352303
Validation loss: 2.4294804194420365

Epoch: 6| Step: 13
Training loss: 0.28466622824815657
Validation loss: 2.448575220867222

Epoch: 345| Step: 0
Training loss: 0.42000030849649816
Validation loss: 2.449906089595154

Epoch: 6| Step: 1
Training loss: 0.4939988879150738
Validation loss: 2.426132965839157

Epoch: 6| Step: 2
Training loss: 0.38943835262033216
Validation loss: 2.4042952276052127

Epoch: 6| Step: 3
Training loss: 0.20383715500281036
Validation loss: 2.38704953691527

Epoch: 6| Step: 4
Training loss: 0.2447116886864556
Validation loss: 2.385940828047118

Epoch: 6| Step: 5
Training loss: 0.29502822524755545
Validation loss: 2.364854228902514

Epoch: 6| Step: 6
Training loss: 0.4164975379376495
Validation loss: 2.3959505214806054

Epoch: 6| Step: 7
Training loss: 0.23988751437733932
Validation loss: 2.370364324394536

Epoch: 6| Step: 8
Training loss: 0.5157807432840719
Validation loss: 2.3974575092740693

Epoch: 6| Step: 9
Training loss: 0.294523032602478
Validation loss: 2.419705305898505

Epoch: 6| Step: 10
Training loss: 0.23812126041589812
Validation loss: 2.398017827611576

Epoch: 6| Step: 11
Training loss: 0.3775067784793428
Validation loss: 2.3910142524154367

Epoch: 6| Step: 12
Training loss: 0.28664947837118065
Validation loss: 2.4202802495791733

Epoch: 6| Step: 13
Training loss: 0.30644135773479214
Validation loss: 2.3901793377983838

Epoch: 346| Step: 0
Training loss: 0.3350686992654547
Validation loss: 2.4383242685624458

Epoch: 6| Step: 1
Training loss: 0.5843672246976703
Validation loss: 2.4399275228174613

Epoch: 6| Step: 2
Training loss: 0.2842287499722221
Validation loss: 2.4206140544226367

Epoch: 6| Step: 3
Training loss: 0.3453737942422259
Validation loss: 2.4559101956724856

Epoch: 6| Step: 4
Training loss: 0.2823887923031383
Validation loss: 2.4159833354299165

Epoch: 6| Step: 5
Training loss: 0.25955214368669427
Validation loss: 2.467962450669051

Epoch: 6| Step: 6
Training loss: 0.4720507755427116
Validation loss: 2.4774035341065193

Epoch: 6| Step: 7
Training loss: 0.2903685833209267
Validation loss: 2.4720975864908

Epoch: 6| Step: 8
Training loss: 0.5134151963296121
Validation loss: 2.4737239465394087

Epoch: 6| Step: 9
Training loss: 0.36176030886288923
Validation loss: 2.4652769125043785

Epoch: 6| Step: 10
Training loss: 0.3731616577594861
Validation loss: 2.454667563576875

Epoch: 6| Step: 11
Training loss: 0.4092485465511549
Validation loss: 2.4533112022033468

Epoch: 6| Step: 12
Training loss: 0.20463976558246488
Validation loss: 2.438871480056924

Epoch: 6| Step: 13
Training loss: 0.23529241934682318
Validation loss: 2.4687254688876474

Epoch: 347| Step: 0
Training loss: 0.2428941875992805
Validation loss: 2.4810319354987165

Epoch: 6| Step: 1
Training loss: 0.46442933402636044
Validation loss: 2.4338457636146336

Epoch: 6| Step: 2
Training loss: 0.2831105837404297
Validation loss: 2.4251565856666337

Epoch: 6| Step: 3
Training loss: 0.19808717125847125
Validation loss: 2.43135530521226

Epoch: 6| Step: 4
Training loss: 0.22851880389227716
Validation loss: 2.405172964903218

Epoch: 6| Step: 5
Training loss: 0.2889432790121775
Validation loss: 2.414455819437645

Epoch: 6| Step: 6
Training loss: 0.28406013517161277
Validation loss: 2.395192197927098

Epoch: 6| Step: 7
Training loss: 0.49380419892398836
Validation loss: 2.3897378213507876

Epoch: 6| Step: 8
Training loss: 0.35161395226246167
Validation loss: 2.398106451590569

Epoch: 6| Step: 9
Training loss: 0.4885807797107505
Validation loss: 2.3494543234897587

Epoch: 6| Step: 10
Training loss: 0.2117782632297143
Validation loss: 2.3908482800584667

Epoch: 6| Step: 11
Training loss: 0.45851653584662644
Validation loss: 2.40269948621689

Epoch: 6| Step: 12
Training loss: 0.38191380401974023
Validation loss: 2.395329251612846

Epoch: 6| Step: 13
Training loss: 0.23248673984440849
Validation loss: 2.404583658034661

Epoch: 348| Step: 0
Training loss: 0.26261900747253847
Validation loss: 2.398999322764554

Epoch: 6| Step: 1
Training loss: 0.2614136240957116
Validation loss: 2.41600502880548

Epoch: 6| Step: 2
Training loss: 0.6443430539120051
Validation loss: 2.3961622220184107

Epoch: 6| Step: 3
Training loss: 0.2244701949419188
Validation loss: 2.412131524089136

Epoch: 6| Step: 4
Training loss: 0.34364919918493714
Validation loss: 2.4271565094926846

Epoch: 6| Step: 5
Training loss: 0.4057061149241642
Validation loss: 2.42059905029202

Epoch: 6| Step: 6
Training loss: 0.1407038613236058
Validation loss: 2.4418343584662434

Epoch: 6| Step: 7
Training loss: 0.3681750308560739
Validation loss: 2.4587413545871892

Epoch: 6| Step: 8
Training loss: 0.29522126519238256
Validation loss: 2.452688578205025

Epoch: 6| Step: 9
Training loss: 0.3800256847811323
Validation loss: 2.4656038436003818

Epoch: 6| Step: 10
Training loss: 0.24887188058121545
Validation loss: 2.451607970219681

Epoch: 6| Step: 11
Training loss: 0.4784554735641017
Validation loss: 2.4559273630292586

Epoch: 6| Step: 12
Training loss: 0.3110422945026893
Validation loss: 2.487564475896118

Epoch: 6| Step: 13
Training loss: 0.30179073561532194
Validation loss: 2.4539773773155633

Epoch: 349| Step: 0
Training loss: 0.2394846716507061
Validation loss: 2.4931937484182405

Epoch: 6| Step: 1
Training loss: 0.3009343191277819
Validation loss: 2.4773642814027776

Epoch: 6| Step: 2
Training loss: 0.34645741819091486
Validation loss: 2.4581504831640766

Epoch: 6| Step: 3
Training loss: 0.32973355021380596
Validation loss: 2.462212813692968

Epoch: 6| Step: 4
Training loss: 0.5778712411651388
Validation loss: 2.464505347397858

Epoch: 6| Step: 5
Training loss: 0.2024214002750179
Validation loss: 2.417339539621188

Epoch: 6| Step: 6
Training loss: 0.35150356858437515
Validation loss: 2.3853659566441947

Epoch: 6| Step: 7
Training loss: 0.2336254053770562
Validation loss: 2.3931360228075893

Epoch: 6| Step: 8
Training loss: 0.2960539808716616
Validation loss: 2.349354558403791

Epoch: 6| Step: 9
Training loss: 0.410256727717885
Validation loss: 2.3821341111217627

Epoch: 6| Step: 10
Training loss: 0.5052836909247261
Validation loss: 2.392900099479062

Epoch: 6| Step: 11
Training loss: 0.463363840161711
Validation loss: 2.382557586854413

Epoch: 6| Step: 12
Training loss: 0.27642134280749486
Validation loss: 2.377153973144854

Epoch: 6| Step: 13
Training loss: 0.3281106150970793
Validation loss: 2.4301459189232792

Epoch: 350| Step: 0
Training loss: 0.300081243541019
Validation loss: 2.4388776619125863

Epoch: 6| Step: 1
Training loss: 0.3343258946449509
Validation loss: 2.442660239005278

Epoch: 6| Step: 2
Training loss: 0.2769148559386749
Validation loss: 2.452153790547326

Epoch: 6| Step: 3
Training loss: 0.28795446208295883
Validation loss: 2.4485476177933596

Epoch: 6| Step: 4
Training loss: 0.29842129608422513
Validation loss: 2.4455306161532575

Epoch: 6| Step: 5
Training loss: 0.4512474855421604
Validation loss: 2.444490768214935

Epoch: 6| Step: 6
Training loss: 0.2302772647840512
Validation loss: 2.4237310902057456

Epoch: 6| Step: 7
Training loss: 0.26680046738179003
Validation loss: 2.4068809905044355

Epoch: 6| Step: 8
Training loss: 0.49916077756300103
Validation loss: 2.415703795611857

Epoch: 6| Step: 9
Training loss: 0.2583074009989926
Validation loss: 2.3933813478381696

Epoch: 6| Step: 10
Training loss: 0.5092940213479996
Validation loss: 2.3850634930912005

Epoch: 6| Step: 11
Training loss: 0.39324981012115456
Validation loss: 2.385946922477853

Epoch: 6| Step: 12
Training loss: 0.40699465069078977
Validation loss: 2.4079675094353226

Epoch: 6| Step: 13
Training loss: 0.26127706807283235
Validation loss: 2.3895383913990207

Epoch: 351| Step: 0
Training loss: 0.24540825390334572
Validation loss: 2.4274119626846624

Epoch: 6| Step: 1
Training loss: 0.3046774495741346
Validation loss: 2.4619962858458937

Epoch: 6| Step: 2
Training loss: 0.354592616459904
Validation loss: 2.455968885281376

Epoch: 6| Step: 3
Training loss: 0.38404111860087925
Validation loss: 2.4408541819528744

Epoch: 6| Step: 4
Training loss: 0.3787086207381431
Validation loss: 2.4279471584571444

Epoch: 6| Step: 5
Training loss: 0.562236909799608
Validation loss: 2.462796260789055

Epoch: 6| Step: 6
Training loss: 0.36656029885127933
Validation loss: 2.4812392948955284

Epoch: 6| Step: 7
Training loss: 0.3408168584872659
Validation loss: 2.4717755628750413

Epoch: 6| Step: 8
Training loss: 0.364144949520076
Validation loss: 2.4639944138204566

Epoch: 6| Step: 9
Training loss: 0.44058128505319893
Validation loss: 2.5039618795999354

Epoch: 6| Step: 10
Training loss: 0.2784413392458387
Validation loss: 2.46257230332806

Epoch: 6| Step: 11
Training loss: 0.3861541093848924
Validation loss: 2.418401078960071

Epoch: 6| Step: 12
Training loss: 0.20523426832785155
Validation loss: 2.4296150889159596

Epoch: 6| Step: 13
Training loss: 0.16650711123606493
Validation loss: 2.4291482582957418

Epoch: 352| Step: 0
Training loss: 0.2648657016040176
Validation loss: 2.4391939110924454

Epoch: 6| Step: 1
Training loss: 0.5149950745726666
Validation loss: 2.3775644042398425

Epoch: 6| Step: 2
Training loss: 0.32531127923961767
Validation loss: 2.416615384469707

Epoch: 6| Step: 3
Training loss: 0.24031822168014808
Validation loss: 2.4112202237471947

Epoch: 6| Step: 4
Training loss: 0.3930448538042607
Validation loss: 2.37838335626962

Epoch: 6| Step: 5
Training loss: 0.23714693736602685
Validation loss: 2.414734232913047

Epoch: 6| Step: 6
Training loss: 0.32414720504234806
Validation loss: 2.404992169954638

Epoch: 6| Step: 7
Training loss: 0.22964717420167916
Validation loss: 2.419632787855038

Epoch: 6| Step: 8
Training loss: 0.26834708772873367
Validation loss: 2.38187131296383

Epoch: 6| Step: 9
Training loss: 0.19388443528267213
Validation loss: 2.429735434166525

Epoch: 6| Step: 10
Training loss: 0.38780226301257914
Validation loss: 2.4363560544051825

Epoch: 6| Step: 11
Training loss: 0.2279213407764802
Validation loss: 2.4553000022355866

Epoch: 6| Step: 12
Training loss: 0.5590878682060888
Validation loss: 2.447332691571674

Epoch: 6| Step: 13
Training loss: 0.33782152340294974
Validation loss: 2.4470599240706536

Epoch: 353| Step: 0
Training loss: 0.20653625008407392
Validation loss: 2.4566841158723953

Epoch: 6| Step: 1
Training loss: 0.40571761092386227
Validation loss: 2.456181525245276

Epoch: 6| Step: 2
Training loss: 0.22731071278003484
Validation loss: 2.4519887486935255

Epoch: 6| Step: 3
Training loss: 0.35679790876726175
Validation loss: 2.4359657216976403

Epoch: 6| Step: 4
Training loss: 0.24056178166635786
Validation loss: 2.4156239561728627

Epoch: 6| Step: 5
Training loss: 0.195059813120071
Validation loss: 2.474920350847485

Epoch: 6| Step: 6
Training loss: 0.3127244858294356
Validation loss: 2.4771263448833274

Epoch: 6| Step: 7
Training loss: 0.4580420052264471
Validation loss: 2.4608225222473177

Epoch: 6| Step: 8
Training loss: 0.3249445799195496
Validation loss: 2.5001179318658417

Epoch: 6| Step: 9
Training loss: 0.43795703108777234
Validation loss: 2.4716118984261484

Epoch: 6| Step: 10
Training loss: 0.23007571117125822
Validation loss: 2.4660530338386226

Epoch: 6| Step: 11
Training loss: 0.2724241416449588
Validation loss: 2.483557251473463

Epoch: 6| Step: 12
Training loss: 0.535613261642828
Validation loss: 2.465557214002769

Epoch: 6| Step: 13
Training loss: 0.1584960909295214
Validation loss: 2.4524088829906194

Epoch: 354| Step: 0
Training loss: 0.2273218485189734
Validation loss: 2.475009235345376

Epoch: 6| Step: 1
Training loss: 0.19617511041693303
Validation loss: 2.467691573648804

Epoch: 6| Step: 2
Training loss: 0.29375017856024327
Validation loss: 2.470523559058043

Epoch: 6| Step: 3
Training loss: 0.27042456492413436
Validation loss: 2.4647262334871307

Epoch: 6| Step: 4
Training loss: 0.40213640666527395
Validation loss: 2.4369634295920415

Epoch: 6| Step: 5
Training loss: 0.3164435588362862
Validation loss: 2.428443488137327

Epoch: 6| Step: 6
Training loss: 0.320775116658838
Validation loss: 2.4423750346007864

Epoch: 6| Step: 7
Training loss: 0.3496176755974669
Validation loss: 2.439736671855341

Epoch: 6| Step: 8
Training loss: 0.2947462076625865
Validation loss: 2.4837957836806757

Epoch: 6| Step: 9
Training loss: 0.30399754239095944
Validation loss: 2.4504379898882935

Epoch: 6| Step: 10
Training loss: 0.307386850981822
Validation loss: 2.452809351311465

Epoch: 6| Step: 11
Training loss: 0.4997640589501224
Validation loss: 2.462558130544586

Epoch: 6| Step: 12
Training loss: 0.5127285610498835
Validation loss: 2.4454534854901935

Epoch: 6| Step: 13
Training loss: 0.38092484522790904
Validation loss: 2.462556274355723

Epoch: 355| Step: 0
Training loss: 0.19758011516384755
Validation loss: 2.473563303904276

Epoch: 6| Step: 1
Training loss: 0.2831190707994286
Validation loss: 2.4506061623620097

Epoch: 6| Step: 2
Training loss: 0.28649482350141753
Validation loss: 2.4301667896241472

Epoch: 6| Step: 3
Training loss: 0.40822353038253484
Validation loss: 2.4699317364449125

Epoch: 6| Step: 4
Training loss: 0.3836681573493881
Validation loss: 2.4403468971837547

Epoch: 6| Step: 5
Training loss: 0.3591134736853319
Validation loss: 2.4318857400810563

Epoch: 6| Step: 6
Training loss: 0.3353781701242745
Validation loss: 2.4060262941767236

Epoch: 6| Step: 7
Training loss: 0.3129782950345092
Validation loss: 2.4284237147859398

Epoch: 6| Step: 8
Training loss: 0.25217173946629173
Validation loss: 2.430844242122753

Epoch: 6| Step: 9
Training loss: 0.48634398101328574
Validation loss: 2.415166529991351

Epoch: 6| Step: 10
Training loss: 0.30272457968339056
Validation loss: 2.446837540610902

Epoch: 6| Step: 11
Training loss: 0.31539690065790216
Validation loss: 2.4604219796808957

Epoch: 6| Step: 12
Training loss: 0.25205394295058475
Validation loss: 2.4384584164974146

Epoch: 6| Step: 13
Training loss: 0.2843582143126334
Validation loss: 2.4404574370173724

Epoch: 356| Step: 0
Training loss: 0.21504007386013926
Validation loss: 2.4339351174643173

Epoch: 6| Step: 1
Training loss: 0.5214295662069817
Validation loss: 2.4203609993871495

Epoch: 6| Step: 2
Training loss: 0.41663586582145923
Validation loss: 2.411942916599378

Epoch: 6| Step: 3
Training loss: 0.1479414191881214
Validation loss: 2.4207075985837734

Epoch: 6| Step: 4
Training loss: 0.282194749563715
Validation loss: 2.4155112716400233

Epoch: 6| Step: 5
Training loss: 0.1866988311102696
Validation loss: 2.3872376304503775

Epoch: 6| Step: 6
Training loss: 0.36703646373983795
Validation loss: 2.402423444937204

Epoch: 6| Step: 7
Training loss: 0.2797562882208419
Validation loss: 2.388205426932624

Epoch: 6| Step: 8
Training loss: 0.3456533148275113
Validation loss: 2.415643360972524

Epoch: 6| Step: 9
Training loss: 0.4958356050498062
Validation loss: 2.4095462637386644

Epoch: 6| Step: 10
Training loss: 0.1771331511340187
Validation loss: 2.390666015217394

Epoch: 6| Step: 11
Training loss: 0.2567538431180844
Validation loss: 2.3972223005244606

Epoch: 6| Step: 12
Training loss: 0.32644567590254836
Validation loss: 2.3989230834114617

Epoch: 6| Step: 13
Training loss: 0.10426393874668595
Validation loss: 2.4172559351419163

Epoch: 357| Step: 0
Training loss: 0.24213983466639774
Validation loss: 2.4330995477587956

Epoch: 6| Step: 1
Training loss: 0.5218893471761551
Validation loss: 2.373221419566945

Epoch: 6| Step: 2
Training loss: 0.25231898159672145
Validation loss: 2.420522482978091

Epoch: 6| Step: 3
Training loss: 0.22761108830196602
Validation loss: 2.3977986910290916

Epoch: 6| Step: 4
Training loss: 0.286661252485387
Validation loss: 2.420766851480814

Epoch: 6| Step: 5
Training loss: 0.3004644757034737
Validation loss: 2.425937114871624

Epoch: 6| Step: 6
Training loss: 0.4484871255351512
Validation loss: 2.433114828828333

Epoch: 6| Step: 7
Training loss: 0.2895168651253876
Validation loss: 2.431351767670638

Epoch: 6| Step: 8
Training loss: 0.30446029407967395
Validation loss: 2.433419505082681

Epoch: 6| Step: 9
Training loss: 0.18395052393936898
Validation loss: 2.453908409180934

Epoch: 6| Step: 10
Training loss: 0.36872721537010444
Validation loss: 2.4333800970324417

Epoch: 6| Step: 11
Training loss: 0.1625116481641021
Validation loss: 2.440380050415101

Epoch: 6| Step: 12
Training loss: 0.22097118943661262
Validation loss: 2.4380321205832787

Epoch: 6| Step: 13
Training loss: 0.46211975227886704
Validation loss: 2.4024739222587925

Epoch: 358| Step: 0
Training loss: 0.11128084952462607
Validation loss: 2.4179423963927036

Epoch: 6| Step: 1
Training loss: 0.2230537112870251
Validation loss: 2.4226349293684186

Epoch: 6| Step: 2
Training loss: 0.2758241852360259
Validation loss: 2.403613536866029

Epoch: 6| Step: 3
Training loss: 0.2861868511116784
Validation loss: 2.4488111022191417

Epoch: 6| Step: 4
Training loss: 0.4520225926508709
Validation loss: 2.3902004829354664

Epoch: 6| Step: 5
Training loss: 0.338172155853819
Validation loss: 2.422797421640509

Epoch: 6| Step: 6
Training loss: 0.3565163319526321
Validation loss: 2.4193518317624347

Epoch: 6| Step: 7
Training loss: 0.29749246431471715
Validation loss: 2.4124847894497563

Epoch: 6| Step: 8
Training loss: 0.19071664952098571
Validation loss: 2.4240548328762244

Epoch: 6| Step: 9
Training loss: 0.27198373713768914
Validation loss: 2.4288386712064387

Epoch: 6| Step: 10
Training loss: 0.2781424372275247
Validation loss: 2.4124764465256807

Epoch: 6| Step: 11
Training loss: 0.36090642704498155
Validation loss: 2.4289388255918802

Epoch: 6| Step: 12
Training loss: 0.5424845890194282
Validation loss: 2.3980602638326243

Epoch: 6| Step: 13
Training loss: 0.2102709322572329
Validation loss: 2.4243588141068075

Epoch: 359| Step: 0
Training loss: 0.17557514081100875
Validation loss: 2.430348125304254

Epoch: 6| Step: 1
Training loss: 0.16697239897972863
Validation loss: 2.3997985840780993

Epoch: 6| Step: 2
Training loss: 0.5023813758629642
Validation loss: 2.450275734023538

Epoch: 6| Step: 3
Training loss: 0.14347533543553004
Validation loss: 2.4538302353946326

Epoch: 6| Step: 4
Training loss: 0.262237603875537
Validation loss: 2.4448608056740193

Epoch: 6| Step: 5
Training loss: 0.23863320856877945
Validation loss: 2.4493385480986807

Epoch: 6| Step: 6
Training loss: 0.3947606505671873
Validation loss: 2.4560192187711265

Epoch: 6| Step: 7
Training loss: 0.3058838587250936
Validation loss: 2.4510067212670963

Epoch: 6| Step: 8
Training loss: 0.2366254292089738
Validation loss: 2.4234933982544304

Epoch: 6| Step: 9
Training loss: 0.36715389666094106
Validation loss: 2.475938933742897

Epoch: 6| Step: 10
Training loss: 0.31037883890752976
Validation loss: 2.4756736093101446

Epoch: 6| Step: 11
Training loss: 0.38497020878652055
Validation loss: 2.489478440936234

Epoch: 6| Step: 12
Training loss: 0.44158314224016343
Validation loss: 2.4363469514267693

Epoch: 6| Step: 13
Training loss: 0.17632188838362853
Validation loss: 2.413830156140159

Epoch: 360| Step: 0
Training loss: 0.29144033380971773
Validation loss: 2.444466546344991

Epoch: 6| Step: 1
Training loss: 0.3648414334013294
Validation loss: 2.450356188479496

Epoch: 6| Step: 2
Training loss: 0.3756100540234339
Validation loss: 2.460952350905651

Epoch: 6| Step: 3
Training loss: 0.4660327195184213
Validation loss: 2.428673834419816

Epoch: 6| Step: 4
Training loss: 0.2558655192096085
Validation loss: 2.4343842722762656

Epoch: 6| Step: 5
Training loss: 0.2302016957794753
Validation loss: 2.4384256865916973

Epoch: 6| Step: 6
Training loss: 0.15954031784933362
Validation loss: 2.443385832185519

Epoch: 6| Step: 7
Training loss: 0.33216103653810586
Validation loss: 2.4445703266013483

Epoch: 6| Step: 8
Training loss: 0.2958013797123
Validation loss: 2.433540660349058

Epoch: 6| Step: 9
Training loss: 0.3131405702401216
Validation loss: 2.4085956705953118

Epoch: 6| Step: 10
Training loss: 0.20859018029862478
Validation loss: 2.4241505433600627

Epoch: 6| Step: 11
Training loss: 0.16578910183446577
Validation loss: 2.422769755550821

Epoch: 6| Step: 12
Training loss: 0.2712427477372513
Validation loss: 2.392640691579104

Epoch: 6| Step: 13
Training loss: 0.4667546560436306
Validation loss: 2.3942395805670085

Epoch: 361| Step: 0
Training loss: 0.38785271127964627
Validation loss: 2.3593849052075133

Epoch: 6| Step: 1
Training loss: 0.5960437988710672
Validation loss: 2.363314947370952

Epoch: 6| Step: 2
Training loss: 0.15831140062505392
Validation loss: 2.3481697641703883

Epoch: 6| Step: 3
Training loss: 0.339500341434897
Validation loss: 2.407610996976598

Epoch: 6| Step: 4
Training loss: 0.19907451531994225
Validation loss: 2.388933572528535

Epoch: 6| Step: 5
Training loss: 0.3617593820708998
Validation loss: 2.4534798506497753

Epoch: 6| Step: 6
Training loss: 0.39942626188343533
Validation loss: 2.4433250555661434

Epoch: 6| Step: 7
Training loss: 0.2818748367968846
Validation loss: 2.412271203208185

Epoch: 6| Step: 8
Training loss: 0.28333529315064987
Validation loss: 2.446974586450195

Epoch: 6| Step: 9
Training loss: 0.20461455129955797
Validation loss: 2.441790113891636

Epoch: 6| Step: 10
Training loss: 0.28157496222585787
Validation loss: 2.4511189171541923

Epoch: 6| Step: 11
Training loss: 0.21291396686785702
Validation loss: 2.4524272048789

Epoch: 6| Step: 12
Training loss: 0.15840436945483974
Validation loss: 2.4446123710438306

Epoch: 6| Step: 13
Training loss: 0.22771330943753454
Validation loss: 2.4618679086772226

Epoch: 362| Step: 0
Training loss: 0.22949394063077053
Validation loss: 2.4422155969041017

Epoch: 6| Step: 1
Training loss: 0.2094163707882736
Validation loss: 2.4655233231335187

Epoch: 6| Step: 2
Training loss: 0.15256972548124628
Validation loss: 2.434484212732575

Epoch: 6| Step: 3
Training loss: 0.2918112458924981
Validation loss: 2.408596956355765

Epoch: 6| Step: 4
Training loss: 0.4004979059662289
Validation loss: 2.4263482337678752

Epoch: 6| Step: 5
Training loss: 0.49969605804138206
Validation loss: 2.4164918317200503

Epoch: 6| Step: 6
Training loss: 0.31654977486689323
Validation loss: 2.392516848507962

Epoch: 6| Step: 7
Training loss: 0.3394114715691527
Validation loss: 2.4218615893767708

Epoch: 6| Step: 8
Training loss: 0.33300928915373207
Validation loss: 2.4207813774857665

Epoch: 6| Step: 9
Training loss: 0.19244565760241972
Validation loss: 2.4344221676452467

Epoch: 6| Step: 10
Training loss: 0.3130627809790967
Validation loss: 2.4231887318712357

Epoch: 6| Step: 11
Training loss: 0.19899617645769352
Validation loss: 2.4021738401297648

Epoch: 6| Step: 12
Training loss: 0.40554464067326057
Validation loss: 2.430142564762131

Epoch: 6| Step: 13
Training loss: 0.2429034433574475
Validation loss: 2.4140302097927284

Epoch: 363| Step: 0
Training loss: 0.15984666955916066
Validation loss: 2.42339499809797

Epoch: 6| Step: 1
Training loss: 0.21463770956733777
Validation loss: 2.398363287618222

Epoch: 6| Step: 2
Training loss: 0.3388796977171684
Validation loss: 2.3970652925694598

Epoch: 6| Step: 3
Training loss: 0.20811390745541786
Validation loss: 2.402688503730932

Epoch: 6| Step: 4
Training loss: 0.2200011000551551
Validation loss: 2.3551305514034087

Epoch: 6| Step: 5
Training loss: 0.38501276512162874
Validation loss: 2.3244072580969086

Epoch: 6| Step: 6
Training loss: 0.37092978217974726
Validation loss: 2.3441483255530926

Epoch: 6| Step: 7
Training loss: 0.2753862015389214
Validation loss: 2.3420264816504095

Epoch: 6| Step: 8
Training loss: 0.21110071825827326
Validation loss: 2.353545228212588

Epoch: 6| Step: 9
Training loss: 0.5247438839214779
Validation loss: 2.3479655861236144

Epoch: 6| Step: 10
Training loss: 0.2516869314247456
Validation loss: 2.3554801322308143

Epoch: 6| Step: 11
Training loss: 0.3686694614907768
Validation loss: 2.3936384879079857

Epoch: 6| Step: 12
Training loss: 0.3542216506051739
Validation loss: 2.3595465956468944

Epoch: 6| Step: 13
Training loss: 0.2622423485638855
Validation loss: 2.3699180741500223

Epoch: 364| Step: 0
Training loss: 0.3039891970685088
Validation loss: 2.4009701025450085

Epoch: 6| Step: 1
Training loss: 0.24205367174702794
Validation loss: 2.4275512504809114

Epoch: 6| Step: 2
Training loss: 0.38942675869533505
Validation loss: 2.3993210280328565

Epoch: 6| Step: 3
Training loss: 0.23532378954864316
Validation loss: 2.4497545721261362

Epoch: 6| Step: 4
Training loss: 0.4899576173426704
Validation loss: 2.434530054325901

Epoch: 6| Step: 5
Training loss: 0.3126556128248045
Validation loss: 2.4626072092113036

Epoch: 6| Step: 6
Training loss: 0.30173515802668704
Validation loss: 2.4493400647179877

Epoch: 6| Step: 7
Training loss: 0.1534312023377674
Validation loss: 2.4809733195347925

Epoch: 6| Step: 8
Training loss: 0.4097533472365492
Validation loss: 2.472833600073576

Epoch: 6| Step: 9
Training loss: 0.3465156704467903
Validation loss: 2.450366228099555

Epoch: 6| Step: 10
Training loss: 0.12990399238160844
Validation loss: 2.426792818361152

Epoch: 6| Step: 11
Training loss: 0.36100860077051367
Validation loss: 2.380971276348188

Epoch: 6| Step: 12
Training loss: 0.2538420375910388
Validation loss: 2.4433473686565335

Epoch: 6| Step: 13
Training loss: 0.154668950885709
Validation loss: 2.423773362340128

Epoch: 365| Step: 0
Training loss: 0.2688314364383709
Validation loss: 2.423603367620977

Epoch: 6| Step: 1
Training loss: 0.15903742113806296
Validation loss: 2.4053255672507268

Epoch: 6| Step: 2
Training loss: 0.5714559197267672
Validation loss: 2.440277160367045

Epoch: 6| Step: 3
Training loss: 0.25172980709878967
Validation loss: 2.440669329727276

Epoch: 6| Step: 4
Training loss: 0.3664697165110092
Validation loss: 2.4320634827680414

Epoch: 6| Step: 5
Training loss: 0.10991369150549092
Validation loss: 2.3991743567672814

Epoch: 6| Step: 6
Training loss: 0.32936827947720176
Validation loss: 2.407693943999872

Epoch: 6| Step: 7
Training loss: 0.16725163633354354
Validation loss: 2.4074877935443477

Epoch: 6| Step: 8
Training loss: 0.23320112307406501
Validation loss: 2.4095872335071213

Epoch: 6| Step: 9
Training loss: 0.23754690704666662
Validation loss: 2.441227106162668

Epoch: 6| Step: 10
Training loss: 0.3814761327587089
Validation loss: 2.419467931551594

Epoch: 6| Step: 11
Training loss: 0.3853272149523956
Validation loss: 2.430096775964361

Epoch: 6| Step: 12
Training loss: 0.3160435988371965
Validation loss: 2.423864578811552

Epoch: 6| Step: 13
Training loss: 0.16159620410314954
Validation loss: 2.451173239877809

Epoch: 366| Step: 0
Training loss: 0.37305230740890793
Validation loss: 2.4493457528170217

Epoch: 6| Step: 1
Training loss: 0.2375139091208381
Validation loss: 2.4383914454349034

Epoch: 6| Step: 2
Training loss: 0.2359862416174691
Validation loss: 2.4447698183929565

Epoch: 6| Step: 3
Training loss: 0.26175604027935334
Validation loss: 2.4416216386843437

Epoch: 6| Step: 4
Training loss: 0.34408459851414297
Validation loss: 2.4253981248765144

Epoch: 6| Step: 5
Training loss: 0.22348082262475144
Validation loss: 2.4483961387632793

Epoch: 6| Step: 6
Training loss: 0.23462916738815845
Validation loss: 2.4198995779194235

Epoch: 6| Step: 7
Training loss: 0.2970029028379784
Validation loss: 2.446619732722803

Epoch: 6| Step: 8
Training loss: 0.39174674142189475
Validation loss: 2.450440511221532

Epoch: 6| Step: 9
Training loss: 0.24848596502012565
Validation loss: 2.449757438980429

Epoch: 6| Step: 10
Training loss: 0.3785778077248718
Validation loss: 2.451992681993929

Epoch: 6| Step: 11
Training loss: 0.28719407733030977
Validation loss: 2.4381531449545757

Epoch: 6| Step: 12
Training loss: 0.5835336329942077
Validation loss: 2.4264559067940086

Epoch: 6| Step: 13
Training loss: 0.2457027129031851
Validation loss: 2.3760712781413798

Epoch: 367| Step: 0
Training loss: 0.358469381768647
Validation loss: 2.3805884364305054

Epoch: 6| Step: 1
Training loss: 0.273782770969262
Validation loss: 2.367181247889876

Epoch: 6| Step: 2
Training loss: 0.3133421993184907
Validation loss: 2.398851725576078

Epoch: 6| Step: 3
Training loss: 0.1894225656304391
Validation loss: 2.413758749376153

Epoch: 6| Step: 4
Training loss: 0.6469433356784666
Validation loss: 2.409859813285352

Epoch: 6| Step: 5
Training loss: 0.44215612940497134
Validation loss: 2.379168546508623

Epoch: 6| Step: 6
Training loss: 0.346110690974543
Validation loss: 2.4344619589906693

Epoch: 6| Step: 7
Training loss: 0.2894471418866625
Validation loss: 2.48767886381106

Epoch: 6| Step: 8
Training loss: 0.4281439018253586
Validation loss: 2.4883490470280893

Epoch: 6| Step: 9
Training loss: 0.5700073470930451
Validation loss: 2.482016648998985

Epoch: 6| Step: 10
Training loss: 0.37693525677169865
Validation loss: 2.4662131648897057

Epoch: 6| Step: 11
Training loss: 0.3229954748995589
Validation loss: 2.4476787021219497

Epoch: 6| Step: 12
Training loss: 0.19083719910915065
Validation loss: 2.3745254038091126

Epoch: 6| Step: 13
Training loss: 0.32271381769800417
Validation loss: 2.422577189925624

Epoch: 368| Step: 0
Training loss: 0.6010421384901006
Validation loss: 2.427596345951334

Epoch: 6| Step: 1
Training loss: 0.29671311984312637
Validation loss: 2.383923012209207

Epoch: 6| Step: 2
Training loss: 0.2909983687437027
Validation loss: 2.4019970864920057

Epoch: 6| Step: 3
Training loss: 0.2799268965998676
Validation loss: 2.4281544980558367

Epoch: 6| Step: 4
Training loss: 0.4147301275828188
Validation loss: 2.4231662500828786

Epoch: 6| Step: 5
Training loss: 0.4685509258976346
Validation loss: 2.427805609356709

Epoch: 6| Step: 6
Training loss: 0.3150092236742764
Validation loss: 2.4214016063025325

Epoch: 6| Step: 7
Training loss: 0.27936935818072445
Validation loss: 2.3973834900501516

Epoch: 6| Step: 8
Training loss: 0.3212990686777415
Validation loss: 2.4349657830537503

Epoch: 6| Step: 9
Training loss: 0.22832919936428892
Validation loss: 2.4203013758885437

Epoch: 6| Step: 10
Training loss: 0.22928151951701617
Validation loss: 2.4335076788894128

Epoch: 6| Step: 11
Training loss: 0.28098373259686404
Validation loss: 2.415859016025248

Epoch: 6| Step: 12
Training loss: 0.5736777942907434
Validation loss: 2.4182074143407557

Epoch: 6| Step: 13
Training loss: 0.23840417974095443
Validation loss: 2.486299623307119

Epoch: 369| Step: 0
Training loss: 0.519812916287559
Validation loss: 2.452455893250139

Epoch: 6| Step: 1
Training loss: 0.1887651516978138
Validation loss: 2.469187861624492

Epoch: 6| Step: 2
Training loss: 0.21778880693743824
Validation loss: 2.5117638939104485

Epoch: 6| Step: 3
Training loss: 0.397935139225625
Validation loss: 2.464645252679644

Epoch: 6| Step: 4
Training loss: 0.2385170114191409
Validation loss: 2.492511582253191

Epoch: 6| Step: 5
Training loss: 0.3674530529994272
Validation loss: 2.503583513734177

Epoch: 6| Step: 6
Training loss: 0.4590531480276755
Validation loss: 2.5213585600233106

Epoch: 6| Step: 7
Training loss: 0.25854799090500974
Validation loss: 2.5250666731076383

Epoch: 6| Step: 8
Training loss: 0.37299298601229036
Validation loss: 2.475456174167229

Epoch: 6| Step: 9
Training loss: 0.44710362928112407
Validation loss: 2.469294662279801

Epoch: 6| Step: 10
Training loss: 0.30228293199011086
Validation loss: 2.4139820296131496

Epoch: 6| Step: 11
Training loss: 0.16379365578417024
Validation loss: 2.3973708075325293

Epoch: 6| Step: 12
Training loss: 0.2033355611896671
Validation loss: 2.4196511841684645

Epoch: 6| Step: 13
Training loss: 0.22079583136752112
Validation loss: 2.3658318398592404

Epoch: 370| Step: 0
Training loss: 0.4676758220335647
Validation loss: 2.403436380311482

Epoch: 6| Step: 1
Training loss: 0.6770478655010778
Validation loss: 2.3662290904184076

Epoch: 6| Step: 2
Training loss: 0.1657547303218097
Validation loss: 2.4018209666752512

Epoch: 6| Step: 3
Training loss: 0.2690604700948989
Validation loss: 2.36453468970572

Epoch: 6| Step: 4
Training loss: 0.14929257858298445
Validation loss: 2.4136917100829978

Epoch: 6| Step: 5
Training loss: 0.29183458138243856
Validation loss: 2.3732646394397316

Epoch: 6| Step: 6
Training loss: 0.3426899387134394
Validation loss: 2.3896992576160963

Epoch: 6| Step: 7
Training loss: 0.16681694852479337
Validation loss: 2.4256796843084736

Epoch: 6| Step: 8
Training loss: 0.3202213762506396
Validation loss: 2.4268248209691046

Epoch: 6| Step: 9
Training loss: 0.31713191752769965
Validation loss: 2.4243072215813397

Epoch: 6| Step: 10
Training loss: 0.26119792414646514
Validation loss: 2.420676074816064

Epoch: 6| Step: 11
Training loss: 0.3181583026999243
Validation loss: 2.445367384685857

Epoch: 6| Step: 12
Training loss: 0.23676123222143364
Validation loss: 2.4465876615912903

Epoch: 6| Step: 13
Training loss: 0.5110054285933117
Validation loss: 2.470182963242422

Epoch: 371| Step: 0
Training loss: 0.5468230359048589
Validation loss: 2.456073881943704

Epoch: 6| Step: 1
Training loss: 0.3123044594292109
Validation loss: 2.4485519733286494

Epoch: 6| Step: 2
Training loss: 0.34325479470618214
Validation loss: 2.457643629765712

Epoch: 6| Step: 3
Training loss: 0.22674068481527804
Validation loss: 2.4500732893714643

Epoch: 6| Step: 4
Training loss: 0.2264480630662506
Validation loss: 2.4634084489695427

Epoch: 6| Step: 5
Training loss: 0.30806667851473696
Validation loss: 2.46282331069195

Epoch: 6| Step: 6
Training loss: 0.3113096932922433
Validation loss: 2.4576584922302636

Epoch: 6| Step: 7
Training loss: 0.33672206770817964
Validation loss: 2.4667891366660064

Epoch: 6| Step: 8
Training loss: 0.3525982328936458
Validation loss: 2.4306750989386106

Epoch: 6| Step: 9
Training loss: 0.26141510614965635
Validation loss: 2.451929385620825

Epoch: 6| Step: 10
Training loss: 0.2516175334275539
Validation loss: 2.449378082467123

Epoch: 6| Step: 11
Training loss: 0.3321853280198297
Validation loss: 2.4448340414829497

Epoch: 6| Step: 12
Training loss: 0.2995470412364656
Validation loss: 2.4371581630634833

Epoch: 6| Step: 13
Training loss: 0.14847298248238314
Validation loss: 2.477157117159981

Epoch: 372| Step: 0
Training loss: 0.27175505612187145
Validation loss: 2.46775790771762

Epoch: 6| Step: 1
Training loss: 0.27750835101131566
Validation loss: 2.483210041773296

Epoch: 6| Step: 2
Training loss: 0.5848235667947765
Validation loss: 2.460078932793635

Epoch: 6| Step: 3
Training loss: 0.31546358097672833
Validation loss: 2.4826430608525643

Epoch: 6| Step: 4
Training loss: 0.1878054038943051
Validation loss: 2.4679204404524926

Epoch: 6| Step: 5
Training loss: 0.17837572187452733
Validation loss: 2.465663294382566

Epoch: 6| Step: 6
Training loss: 0.24933920642850038
Validation loss: 2.4380463460362014

Epoch: 6| Step: 7
Training loss: 0.1888192574593371
Validation loss: 2.470115544605505

Epoch: 6| Step: 8
Training loss: 0.17461104296201227
Validation loss: 2.4502011634055356

Epoch: 6| Step: 9
Training loss: 0.2516213383784841
Validation loss: 2.4275890782680998

Epoch: 6| Step: 10
Training loss: 0.3859233575615835
Validation loss: 2.4463468930625494

Epoch: 6| Step: 11
Training loss: 0.2918312369136429
Validation loss: 2.4366155623208154

Epoch: 6| Step: 12
Training loss: 0.4444171873151952
Validation loss: 2.4184630050501426

Epoch: 6| Step: 13
Training loss: 0.16217181715177245
Validation loss: 2.4014782960463714

Epoch: 373| Step: 0
Training loss: 0.3149644118785304
Validation loss: 2.423506587225563

Epoch: 6| Step: 1
Training loss: 0.3160880101390371
Validation loss: 2.4321297484539257

Epoch: 6| Step: 2
Training loss: 0.17216083752019112
Validation loss: 2.4083885381841914

Epoch: 6| Step: 3
Training loss: 0.1839648615052097
Validation loss: 2.4243588712091606

Epoch: 6| Step: 4
Training loss: 0.3694105826342341
Validation loss: 2.4228177329373204

Epoch: 6| Step: 5
Training loss: 0.2527522344631958
Validation loss: 2.4213019003570437

Epoch: 6| Step: 6
Training loss: 0.12357810936041548
Validation loss: 2.416828454202838

Epoch: 6| Step: 7
Training loss: 0.5177072040179681
Validation loss: 2.41892108653978

Epoch: 6| Step: 8
Training loss: 0.1618479723809538
Validation loss: 2.4041527290158475

Epoch: 6| Step: 9
Training loss: 0.4334145596682874
Validation loss: 2.428755117926335

Epoch: 6| Step: 10
Training loss: 0.13712711654166737
Validation loss: 2.444014324345707

Epoch: 6| Step: 11
Training loss: 0.3538981523071587
Validation loss: 2.428805279160429

Epoch: 6| Step: 12
Training loss: 0.26328243176112975
Validation loss: 2.4427130821750875

Epoch: 6| Step: 13
Training loss: 0.192223700936376
Validation loss: 2.4397530146720556

Epoch: 374| Step: 0
Training loss: 0.20896692292259136
Validation loss: 2.428555645455798

Epoch: 6| Step: 1
Training loss: 0.24133490647074163
Validation loss: 2.3822100661341885

Epoch: 6| Step: 2
Training loss: 0.1594128918949474
Validation loss: 2.447336553790978

Epoch: 6| Step: 3
Training loss: 0.28288248260587534
Validation loss: 2.4633145396196885

Epoch: 6| Step: 4
Training loss: 0.2102910485175097
Validation loss: 2.449184198651479

Epoch: 6| Step: 5
Training loss: 0.5506692596642742
Validation loss: 2.475518129568978

Epoch: 6| Step: 6
Training loss: 0.25655654389208615
Validation loss: 2.449173691528367

Epoch: 6| Step: 7
Training loss: 0.26141111598527894
Validation loss: 2.463784115087409

Epoch: 6| Step: 8
Training loss: 0.41874046030138323
Validation loss: 2.44764041498226

Epoch: 6| Step: 9
Training loss: 0.30883342754772936
Validation loss: 2.4557940002226957

Epoch: 6| Step: 10
Training loss: 0.114884917510047
Validation loss: 2.4425914199515115

Epoch: 6| Step: 11
Training loss: 0.22482955755278033
Validation loss: 2.444957669799268

Epoch: 6| Step: 12
Training loss: 0.08955888576296073
Validation loss: 2.467048556119572

Epoch: 6| Step: 13
Training loss: 0.2289646090563494
Validation loss: 2.433256888765627

Epoch: 375| Step: 0
Training loss: 0.3548260842364188
Validation loss: 2.4206673523841227

Epoch: 6| Step: 1
Training loss: 0.13461675576085497
Validation loss: 2.4497686877799794

Epoch: 6| Step: 2
Training loss: 0.3555023680499434
Validation loss: 2.4591984941058636

Epoch: 6| Step: 3
Training loss: 0.13560600447682825
Validation loss: 2.447095341418189

Epoch: 6| Step: 4
Training loss: 0.20176393918745447
Validation loss: 2.4578635554411323

Epoch: 6| Step: 5
Training loss: 0.08616459437469097
Validation loss: 2.4361905802861727

Epoch: 6| Step: 6
Training loss: 0.1314855015321684
Validation loss: 2.4624365071361254

Epoch: 6| Step: 7
Training loss: 0.23025108015322732
Validation loss: 2.457527568434131

Epoch: 6| Step: 8
Training loss: 0.5442594104158303
Validation loss: 2.437277674100097

Epoch: 6| Step: 9
Training loss: 0.2980635217139982
Validation loss: 2.461167139400013

Epoch: 6| Step: 10
Training loss: 0.24618139674089773
Validation loss: 2.449808230249886

Epoch: 6| Step: 11
Training loss: 0.09581288058123864
Validation loss: 2.421297375101307

Epoch: 6| Step: 12
Training loss: 0.2614734695936876
Validation loss: 2.44505767558627

Epoch: 6| Step: 13
Training loss: 0.40159733988509716
Validation loss: 2.428671013929202

Epoch: 376| Step: 0
Training loss: 0.3031977644822209
Validation loss: 2.4437827138182673

Epoch: 6| Step: 1
Training loss: 0.22767268501814658
Validation loss: 2.4491468938687344

Epoch: 6| Step: 2
Training loss: 0.19154737096974808
Validation loss: 2.4367660551272925

Epoch: 6| Step: 3
Training loss: 0.35145344632242215
Validation loss: 2.379454079744893

Epoch: 6| Step: 4
Training loss: 0.45372746963366944
Validation loss: 2.4234340533432106

Epoch: 6| Step: 5
Training loss: 0.1746871062634284
Validation loss: 2.401053663896519

Epoch: 6| Step: 6
Training loss: 0.2508964559164107
Validation loss: 2.3998974603450067

Epoch: 6| Step: 7
Training loss: 0.3570791383509487
Validation loss: 2.438477425115127

Epoch: 6| Step: 8
Training loss: 0.2588602507942486
Validation loss: 2.4097045468772245

Epoch: 6| Step: 9
Training loss: 0.19106395437680979
Validation loss: 2.419541181921766

Epoch: 6| Step: 10
Training loss: 0.09030654135189808
Validation loss: 2.4203573319125757

Epoch: 6| Step: 11
Training loss: 0.2750904259698088
Validation loss: 2.4230049739006843

Epoch: 6| Step: 12
Training loss: 0.3526801041161067
Validation loss: 2.377432317619533

Epoch: 6| Step: 13
Training loss: 0.16593176462746778
Validation loss: 2.4277927235681696

Epoch: 377| Step: 0
Training loss: 0.2500532957727116
Validation loss: 2.3788089594564923

Epoch: 6| Step: 1
Training loss: 0.2636183083834897
Validation loss: 2.4313812519474025

Epoch: 6| Step: 2
Training loss: 0.34386880945535797
Validation loss: 2.4368623015565953

Epoch: 6| Step: 3
Training loss: 0.27446002507406264
Validation loss: 2.4413002743926344

Epoch: 6| Step: 4
Training loss: 0.2301463361185972
Validation loss: 2.4389418803854626

Epoch: 6| Step: 5
Training loss: 0.20268720434545456
Validation loss: 2.443540003385254

Epoch: 6| Step: 6
Training loss: 0.10220451274606757
Validation loss: 2.4634725873226557

Epoch: 6| Step: 7
Training loss: 0.16640526542909587
Validation loss: 2.4305679376836618

Epoch: 6| Step: 8
Training loss: 0.159749911218717
Validation loss: 2.434781825724247

Epoch: 6| Step: 9
Training loss: 0.4345231962915064
Validation loss: 2.4329092117457045

Epoch: 6| Step: 10
Training loss: 0.28470382333766886
Validation loss: 2.455107999940263

Epoch: 6| Step: 11
Training loss: 0.4494306810763825
Validation loss: 2.469871051506736

Epoch: 6| Step: 12
Training loss: 0.13961120589325343
Validation loss: 2.437166107506579

Epoch: 6| Step: 13
Training loss: 0.17010816140651666
Validation loss: 2.4116806469628087

Epoch: 378| Step: 0
Training loss: 0.14630287370052944
Validation loss: 2.436342904478502

Epoch: 6| Step: 1
Training loss: 0.3194780645899778
Validation loss: 2.450798415877521

Epoch: 6| Step: 2
Training loss: 0.150166722616211
Validation loss: 2.4485147500041484

Epoch: 6| Step: 3
Training loss: 0.17170799334490167
Validation loss: 2.40160593781133

Epoch: 6| Step: 4
Training loss: 0.2133904809671276
Validation loss: 2.4217627767601546

Epoch: 6| Step: 5
Training loss: 0.27339204682905216
Validation loss: 2.4225735009376748

Epoch: 6| Step: 6
Training loss: 0.20353045711541534
Validation loss: 2.4327751050415225

Epoch: 6| Step: 7
Training loss: 0.512921325276113
Validation loss: 2.4407641082598697

Epoch: 6| Step: 8
Training loss: 0.22965200824690007
Validation loss: 2.436860743506724

Epoch: 6| Step: 9
Training loss: 0.297567839020343
Validation loss: 2.4235242982887573

Epoch: 6| Step: 10
Training loss: 0.2536180768240799
Validation loss: 2.400329530859741

Epoch: 6| Step: 11
Training loss: 0.28902728923072163
Validation loss: 2.4427706001675666

Epoch: 6| Step: 12
Training loss: 0.2704817556232689
Validation loss: 2.433250605182269

Epoch: 6| Step: 13
Training loss: 0.3285182798552768
Validation loss: 2.4320041804289874

Epoch: 379| Step: 0
Training loss: 0.300741614170125
Validation loss: 2.4283032823569526

Epoch: 6| Step: 1
Training loss: 0.17212837140376688
Validation loss: 2.45831551153426

Epoch: 6| Step: 2
Training loss: 0.2909213047662256
Validation loss: 2.446947288532376

Epoch: 6| Step: 3
Training loss: 0.12247853114706783
Validation loss: 2.4064992651168837

Epoch: 6| Step: 4
Training loss: 0.5112378721967213
Validation loss: 2.4267330776923335

Epoch: 6| Step: 5
Training loss: 0.31618451955898286
Validation loss: 2.4261759949591006

Epoch: 6| Step: 6
Training loss: 0.1846361194340756
Validation loss: 2.3996905538493545

Epoch: 6| Step: 7
Training loss: 0.41172865144524656
Validation loss: 2.421581646171689

Epoch: 6| Step: 8
Training loss: 0.1537398290565206
Validation loss: 2.4290199783296536

Epoch: 6| Step: 9
Training loss: 0.17049351268463583
Validation loss: 2.4117634285085283

Epoch: 6| Step: 10
Training loss: 0.17058882869631517
Validation loss: 2.3915634902932306

Epoch: 6| Step: 11
Training loss: 0.26136107700304795
Validation loss: 2.404514080781239

Epoch: 6| Step: 12
Training loss: 0.16484418909638124
Validation loss: 2.4026162155166975

Epoch: 6| Step: 13
Training loss: 0.24389417798056287
Validation loss: 2.4241855466848397

Epoch: 380| Step: 0
Training loss: 0.4614994050886922
Validation loss: 2.412778999611185

Epoch: 6| Step: 1
Training loss: 0.1902617080446937
Validation loss: 2.4082143963762577

Epoch: 6| Step: 2
Training loss: 0.29431659910871744
Validation loss: 2.4252523974881637

Epoch: 6| Step: 3
Training loss: 0.22660978415780453
Validation loss: 2.441289715485725

Epoch: 6| Step: 4
Training loss: 0.19227095319486748
Validation loss: 2.419706124880003

Epoch: 6| Step: 5
Training loss: 0.1599330568061642
Validation loss: 2.4582834542874994

Epoch: 6| Step: 6
Training loss: 0.2376535700283893
Validation loss: 2.4314100267932686

Epoch: 6| Step: 7
Training loss: 0.2408058920175684
Validation loss: 2.4434600883029773

Epoch: 6| Step: 8
Training loss: 0.3094361191882301
Validation loss: 2.4074606341031237

Epoch: 6| Step: 9
Training loss: 0.22271993629757303
Validation loss: 2.3932990477117055

Epoch: 6| Step: 10
Training loss: 0.22593318750426103
Validation loss: 2.441992352362981

Epoch: 6| Step: 11
Training loss: 0.1954997309673146
Validation loss: 2.4546811375311277

Epoch: 6| Step: 12
Training loss: 0.29553268035513486
Validation loss: 2.440042993461615

Epoch: 6| Step: 13
Training loss: 0.458691198987713
Validation loss: 2.459837767244333

Epoch: 381| Step: 0
Training loss: 0.46078915552683664
Validation loss: 2.4285585568639214

Epoch: 6| Step: 1
Training loss: 0.31865133460139633
Validation loss: 2.422217905761759

Epoch: 6| Step: 2
Training loss: 0.127213402015612
Validation loss: 2.4459808923795374

Epoch: 6| Step: 3
Training loss: 0.22178146781765562
Validation loss: 2.423700885626351

Epoch: 6| Step: 4
Training loss: 0.48256360030150713
Validation loss: 2.3680997823590952

Epoch: 6| Step: 5
Training loss: 0.26008127867785347
Validation loss: 2.353637793444848

Epoch: 6| Step: 6
Training loss: 0.33527667454144994
Validation loss: 2.396698050833944

Epoch: 6| Step: 7
Training loss: 0.2679285414087677
Validation loss: 2.3688810113087895

Epoch: 6| Step: 8
Training loss: 0.1751094697114837
Validation loss: 2.362333876171016

Epoch: 6| Step: 9
Training loss: 0.20175374701836227
Validation loss: 2.4136110350830036

Epoch: 6| Step: 10
Training loss: 0.2225282619105886
Validation loss: 2.425820133668481

Epoch: 6| Step: 11
Training loss: 0.18936887814601083
Validation loss: 2.435361784148856

Epoch: 6| Step: 12
Training loss: 0.1491087742920997
Validation loss: 2.404908676693892

Epoch: 6| Step: 13
Training loss: 0.33632632973930615
Validation loss: 2.443804796662649

Epoch: 382| Step: 0
Training loss: 0.19610258515656165
Validation loss: 2.430416260481459

Epoch: 6| Step: 1
Training loss: 0.324534871058679
Validation loss: 2.43678758189678

Epoch: 6| Step: 2
Training loss: 0.3253834154628615
Validation loss: 2.4695041502029

Epoch: 6| Step: 3
Training loss: 0.22840878850225876
Validation loss: 2.4161968518866637

Epoch: 6| Step: 4
Training loss: 0.1958381731284113
Validation loss: 2.4212781177883556

Epoch: 6| Step: 5
Training loss: 0.23348678927707298
Validation loss: 2.401541900541082

Epoch: 6| Step: 6
Training loss: 0.3133549320587887
Validation loss: 2.458306643169241

Epoch: 6| Step: 7
Training loss: 0.28778289114527317
Validation loss: 2.426893806653915

Epoch: 6| Step: 8
Training loss: 0.5063821161034265
Validation loss: 2.40771344838043

Epoch: 6| Step: 9
Training loss: 0.1221265586970258
Validation loss: 2.4235088382715335

Epoch: 6| Step: 10
Training loss: 0.33709403497088525
Validation loss: 2.4168477156787187

Epoch: 6| Step: 11
Training loss: 0.23669129832513677
Validation loss: 2.420652820929106

Epoch: 6| Step: 12
Training loss: 0.1899412689600745
Validation loss: 2.393386924709331

Epoch: 6| Step: 13
Training loss: 0.20814706502114805
Validation loss: 2.394467138085109

Epoch: 383| Step: 0
Training loss: 0.13525372722076798
Validation loss: 2.3818539142899366

Epoch: 6| Step: 1
Training loss: 0.14008166730479285
Validation loss: 2.382033056965567

Epoch: 6| Step: 2
Training loss: 0.2560065188518545
Validation loss: 2.3924443652006153

Epoch: 6| Step: 3
Training loss: 0.15664482301333035
Validation loss: 2.394237920898363

Epoch: 6| Step: 4
Training loss: 0.21764350230779614
Validation loss: 2.3939337795096667

Epoch: 6| Step: 5
Training loss: 0.1604337497899992
Validation loss: 2.359378737819041

Epoch: 6| Step: 6
Training loss: 0.4049199228535927
Validation loss: 2.3810637093957214

Epoch: 6| Step: 7
Training loss: 0.244059526325236
Validation loss: 2.4160154408986796

Epoch: 6| Step: 8
Training loss: 0.39315908535925753
Validation loss: 2.378931389407133

Epoch: 6| Step: 9
Training loss: 0.3403935315295006
Validation loss: 2.36718968547302

Epoch: 6| Step: 10
Training loss: 0.4722105872911847
Validation loss: 2.365910012138118

Epoch: 6| Step: 11
Training loss: 0.27036956669837015
Validation loss: 2.4623118448466133

Epoch: 6| Step: 12
Training loss: 0.22011455612166803
Validation loss: 2.4620065227007726

Epoch: 6| Step: 13
Training loss: 0.15906308589969792
Validation loss: 2.4463231569594397

Epoch: 384| Step: 0
Training loss: 0.25071121913626276
Validation loss: 2.4821021890906207

Epoch: 6| Step: 1
Training loss: 0.20523500345843237
Validation loss: 2.4585337869111648

Epoch: 6| Step: 2
Training loss: 0.13493248381485476
Validation loss: 2.4896498626731756

Epoch: 6| Step: 3
Training loss: 0.4773240180549557
Validation loss: 2.4912706426343347

Epoch: 6| Step: 4
Training loss: 0.21236881561491588
Validation loss: 2.4590231767204807

Epoch: 6| Step: 5
Training loss: 0.36306362401598175
Validation loss: 2.4745945107443794

Epoch: 6| Step: 6
Training loss: 0.21741695907030173
Validation loss: 2.472652876262822

Epoch: 6| Step: 7
Training loss: 0.3152890674364112
Validation loss: 2.4832946839029355

Epoch: 6| Step: 8
Training loss: 0.34208965296063454
Validation loss: 2.4242518897066394

Epoch: 6| Step: 9
Training loss: 0.3344205049942002
Validation loss: 2.4218925589230262

Epoch: 6| Step: 10
Training loss: 0.1970336135099321
Validation loss: 2.41143881813526

Epoch: 6| Step: 11
Training loss: 0.24796742946703404
Validation loss: 2.3814715211801776

Epoch: 6| Step: 12
Training loss: 0.21709541866198775
Validation loss: 2.3942910275829448

Epoch: 6| Step: 13
Training loss: 0.19996814399576146
Validation loss: 2.3810758909076406

Epoch: 385| Step: 0
Training loss: 0.2013364137505724
Validation loss: 2.396014188456002

Epoch: 6| Step: 1
Training loss: 0.1686025019045442
Validation loss: 2.388346749534039

Epoch: 6| Step: 2
Training loss: 0.2536541053603295
Validation loss: 2.372655400990951

Epoch: 6| Step: 3
Training loss: 0.3287854360113277
Validation loss: 2.3614763934822127

Epoch: 6| Step: 4
Training loss: 0.19501851845193183
Validation loss: 2.3867017701294877

Epoch: 6| Step: 5
Training loss: 0.19472906709856685
Validation loss: 2.4332617752835213

Epoch: 6| Step: 6
Training loss: 0.16132203753349592
Validation loss: 2.4229529404314625

Epoch: 6| Step: 7
Training loss: 0.3235886091802949
Validation loss: 2.4417308566965343

Epoch: 6| Step: 8
Training loss: 0.12536256333554077
Validation loss: 2.4776273646661404

Epoch: 6| Step: 9
Training loss: 0.4596735062274758
Validation loss: 2.4957419367738645

Epoch: 6| Step: 10
Training loss: 0.29071341574543064
Validation loss: 2.506578388845302

Epoch: 6| Step: 11
Training loss: 0.20023911159835336
Validation loss: 2.4780777831889558

Epoch: 6| Step: 12
Training loss: 0.3619825468202844
Validation loss: 2.4694263834399552

Epoch: 6| Step: 13
Training loss: 0.3938551671498783
Validation loss: 2.5035029061126486

Epoch: 386| Step: 0
Training loss: 0.15747330537760215
Validation loss: 2.4931255777335033

Epoch: 6| Step: 1
Training loss: 0.4629270000088445
Validation loss: 2.4818184219668438

Epoch: 6| Step: 2
Training loss: 0.3814812888872733
Validation loss: 2.4549042907458074

Epoch: 6| Step: 3
Training loss: 0.24244102928521374
Validation loss: 2.4542349880252146

Epoch: 6| Step: 4
Training loss: 0.15977158523671475
Validation loss: 2.432401378262006

Epoch: 6| Step: 5
Training loss: 0.39706327898407545
Validation loss: 2.407198507650552

Epoch: 6| Step: 6
Training loss: 0.16735332322720367
Validation loss: 2.4179172299987943

Epoch: 6| Step: 7
Training loss: 0.23418068778211748
Validation loss: 2.437309177734357

Epoch: 6| Step: 8
Training loss: 0.10481280311416671
Validation loss: 2.3903131154866744

Epoch: 6| Step: 9
Training loss: 0.25431457844651495
Validation loss: 2.4459299362108156

Epoch: 6| Step: 10
Training loss: 0.17403856676228605
Validation loss: 2.4115074647232198

Epoch: 6| Step: 11
Training loss: 0.25004638301202886
Validation loss: 2.4347387575859694

Epoch: 6| Step: 12
Training loss: 0.29937728586299794
Validation loss: 2.460428843006558

Epoch: 6| Step: 13
Training loss: 0.30800127543767436
Validation loss: 2.4429918584631154

Epoch: 387| Step: 0
Training loss: 0.24807806644918337
Validation loss: 2.4175162584700387

Epoch: 6| Step: 1
Training loss: 0.5309318543527464
Validation loss: 2.4476296708046443

Epoch: 6| Step: 2
Training loss: 0.26125452519107056
Validation loss: 2.434618834977524

Epoch: 6| Step: 3
Training loss: 0.24000633860949744
Validation loss: 2.4191098311233183

Epoch: 6| Step: 4
Training loss: 0.1998239841633183
Validation loss: 2.3886321794681837

Epoch: 6| Step: 5
Training loss: 0.16404632079865336
Validation loss: 2.4145532322903547

Epoch: 6| Step: 6
Training loss: 0.20788697865645386
Validation loss: 2.426367889848036

Epoch: 6| Step: 7
Training loss: 0.1127183551799923
Validation loss: 2.41566941120269

Epoch: 6| Step: 8
Training loss: 0.1271272492223841
Validation loss: 2.41877120259035

Epoch: 6| Step: 9
Training loss: 0.2340995123188002
Validation loss: 2.4077607704426556

Epoch: 6| Step: 10
Training loss: 0.19978362762048357
Validation loss: 2.4155162418162694

Epoch: 6| Step: 11
Training loss: 0.41415630933346254
Validation loss: 2.4299955399296467

Epoch: 6| Step: 12
Training loss: 0.16114851557191154
Validation loss: 2.463932732588864

Epoch: 6| Step: 13
Training loss: 0.20717454845344274
Validation loss: 2.402817488490051

Epoch: 388| Step: 0
Training loss: 0.23249708289193005
Validation loss: 2.4667538212453533

Epoch: 6| Step: 1
Training loss: 0.3243321829303662
Validation loss: 2.436021620995572

Epoch: 6| Step: 2
Training loss: 0.4411832195354803
Validation loss: 2.456296415479345

Epoch: 6| Step: 3
Training loss: 0.3213694045886534
Validation loss: 2.419368341948313

Epoch: 6| Step: 4
Training loss: 0.3045231302430529
Validation loss: 2.4507297468968487

Epoch: 6| Step: 5
Training loss: 0.21999852621603544
Validation loss: 2.45144919001026

Epoch: 6| Step: 6
Training loss: 0.20400168060213533
Validation loss: 2.467139839855495

Epoch: 6| Step: 7
Training loss: 0.2717909694028951
Validation loss: 2.451036839331608

Epoch: 6| Step: 8
Training loss: 0.1202151085473374
Validation loss: 2.4179149938922255

Epoch: 6| Step: 9
Training loss: 0.16593566539705706
Validation loss: 2.43944071164394

Epoch: 6| Step: 10
Training loss: 0.1767616008120753
Validation loss: 2.415895091340799

Epoch: 6| Step: 11
Training loss: 0.18236860400077398
Validation loss: 2.4230854937788107

Epoch: 6| Step: 12
Training loss: 0.33399952190473453
Validation loss: 2.3819978474948176

Epoch: 6| Step: 13
Training loss: 0.3133616489355475
Validation loss: 2.3906529705296817

Epoch: 389| Step: 0
Training loss: 0.2075070904761234
Validation loss: 2.4043722455697183

Epoch: 6| Step: 1
Training loss: 0.12758939926826368
Validation loss: 2.3812653347903208

Epoch: 6| Step: 2
Training loss: 0.31642230899700596
Validation loss: 2.3941022492677364

Epoch: 6| Step: 3
Training loss: 0.1495966450228008
Validation loss: 2.4090758299117754

Epoch: 6| Step: 4
Training loss: 0.3002732433260402
Validation loss: 2.3822090739139004

Epoch: 6| Step: 5
Training loss: 0.3153349081494752
Validation loss: 2.4436268693846617

Epoch: 6| Step: 6
Training loss: 0.3307647786028474
Validation loss: 2.376757012329499

Epoch: 6| Step: 7
Training loss: 0.4761517896789434
Validation loss: 2.433740515852531

Epoch: 6| Step: 8
Training loss: 0.3145155282030606
Validation loss: 2.44249496684308

Epoch: 6| Step: 9
Training loss: 0.15061625980606155
Validation loss: 2.4309625940097677

Epoch: 6| Step: 10
Training loss: 0.2229404643241083
Validation loss: 2.4386731457020896

Epoch: 6| Step: 11
Training loss: 0.2095954730598784
Validation loss: 2.43874923881553

Epoch: 6| Step: 12
Training loss: 0.2464937864220718
Validation loss: 2.424357655140242

Epoch: 6| Step: 13
Training loss: 0.15681396273420714
Validation loss: 2.431693220568425

Epoch: 390| Step: 0
Training loss: 0.4508223728086247
Validation loss: 2.423284432130125

Epoch: 6| Step: 1
Training loss: 0.10303603492706641
Validation loss: 2.4243843979411426

Epoch: 6| Step: 2
Training loss: 0.21952647954027116
Validation loss: 2.4088244006250408

Epoch: 6| Step: 3
Training loss: 0.2780935333967839
Validation loss: 2.397072083830017

Epoch: 6| Step: 4
Training loss: 0.20050151017623907
Validation loss: 2.4194716877902613

Epoch: 6| Step: 5
Training loss: 0.15608744510216785
Validation loss: 2.386467959163906

Epoch: 6| Step: 6
Training loss: 0.25941322918174886
Validation loss: 2.401527809529112

Epoch: 6| Step: 7
Training loss: 0.3035975057356858
Validation loss: 2.3901050990759356

Epoch: 6| Step: 8
Training loss: 0.14893548652418087
Validation loss: 2.4096541694230784

Epoch: 6| Step: 9
Training loss: 0.4037290999964326
Validation loss: 2.4073630588468853

Epoch: 6| Step: 10
Training loss: 0.1654077508607133
Validation loss: 2.421629001324885

Epoch: 6| Step: 11
Training loss: 0.14970817789433677
Validation loss: 2.406780363992323

Epoch: 6| Step: 12
Training loss: 0.3155285352650763
Validation loss: 2.4215708551883406

Epoch: 6| Step: 13
Training loss: 0.17055321839331403
Validation loss: 2.4882035302133474

Epoch: 391| Step: 0
Training loss: 0.27670014614505306
Validation loss: 2.447518283331123

Epoch: 6| Step: 1
Training loss: 0.4809441889098815
Validation loss: 2.441783335714093

Epoch: 6| Step: 2
Training loss: 0.18113276537774686
Validation loss: 2.4243402245758046

Epoch: 6| Step: 3
Training loss: 0.1457028713684329
Validation loss: 2.411884317455993

Epoch: 6| Step: 4
Training loss: 0.19047727723783742
Validation loss: 2.410229136666445

Epoch: 6| Step: 5
Training loss: 0.20256082423398855
Validation loss: 2.42222154501803

Epoch: 6| Step: 6
Training loss: 0.31672098259687065
Validation loss: 2.413439866208966

Epoch: 6| Step: 7
Training loss: 0.14344881006916058
Validation loss: 2.411565614844708

Epoch: 6| Step: 8
Training loss: 0.30258381699089437
Validation loss: 2.382617681975812

Epoch: 6| Step: 9
Training loss: 0.25600336114718375
Validation loss: 2.419411101174143

Epoch: 6| Step: 10
Training loss: 0.3180980897325026
Validation loss: 2.4051347195369437

Epoch: 6| Step: 11
Training loss: 0.1594849917516764
Validation loss: 2.40034893594468

Epoch: 6| Step: 12
Training loss: 0.3483850790371853
Validation loss: 2.4695689601965722

Epoch: 6| Step: 13
Training loss: 0.2190806070373118
Validation loss: 2.4343651616659363

Epoch: 392| Step: 0
Training loss: 0.1379940161353575
Validation loss: 2.421079010344082

Epoch: 6| Step: 1
Training loss: 0.3109298479873464
Validation loss: 2.4326272992762794

Epoch: 6| Step: 2
Training loss: 0.16689838317925923
Validation loss: 2.418036592836426

Epoch: 6| Step: 3
Training loss: 0.2356352303507594
Validation loss: 2.4390362898437274

Epoch: 6| Step: 4
Training loss: 0.23718170621326923
Validation loss: 2.4450675713002226

Epoch: 6| Step: 5
Training loss: 0.16652507032201933
Validation loss: 2.4245753957747773

Epoch: 6| Step: 6
Training loss: 0.10747913221817268
Validation loss: 2.4078166636176332

Epoch: 6| Step: 7
Training loss: 0.4032931006906256
Validation loss: 2.41979505529795

Epoch: 6| Step: 8
Training loss: 0.15309809112584397
Validation loss: 2.4037621054836915

Epoch: 6| Step: 9
Training loss: 0.25890950692982395
Validation loss: 2.3749429332135636

Epoch: 6| Step: 10
Training loss: 0.4834234211948534
Validation loss: 2.415063320501656

Epoch: 6| Step: 11
Training loss: 0.2654547426189175
Validation loss: 2.413391377874416

Epoch: 6| Step: 12
Training loss: 0.1440839288955538
Validation loss: 2.42535654592367

Epoch: 6| Step: 13
Training loss: 0.2574979857717825
Validation loss: 2.4173859582030355

Epoch: 393| Step: 0
Training loss: 0.13816699949448
Validation loss: 2.4789104537814723

Epoch: 6| Step: 1
Training loss: 0.1308121524838982
Validation loss: 2.468016168937318

Epoch: 6| Step: 2
Training loss: 0.2579653749066088
Validation loss: 2.4657809263479202

Epoch: 6| Step: 3
Training loss: 0.1588790547047089
Validation loss: 2.4520578983734502

Epoch: 6| Step: 4
Training loss: 0.2507531771292178
Validation loss: 2.438385749129983

Epoch: 6| Step: 5
Training loss: 0.26851245894908793
Validation loss: 2.454454200751284

Epoch: 6| Step: 6
Training loss: 0.16680745173919753
Validation loss: 2.4404591387870154

Epoch: 6| Step: 7
Training loss: 0.14061858904318286
Validation loss: 2.438904609196282

Epoch: 6| Step: 8
Training loss: 0.20893168453632496
Validation loss: 2.4406719168223243

Epoch: 6| Step: 9
Training loss: 0.261937903699516
Validation loss: 2.437613464356611

Epoch: 6| Step: 10
Training loss: 0.2546448601677568
Validation loss: 2.428579401092941

Epoch: 6| Step: 11
Training loss: 0.2445506200949061
Validation loss: 2.444567342500706

Epoch: 6| Step: 12
Training loss: 0.38478171610225026
Validation loss: 2.4637958095733605

Epoch: 6| Step: 13
Training loss: 0.58342818499476
Validation loss: 2.4627485162463856

Epoch: 394| Step: 0
Training loss: 0.33417804300693965
Validation loss: 2.482302058283805

Epoch: 6| Step: 1
Training loss: 0.331019216792139
Validation loss: 2.473849999603837

Epoch: 6| Step: 2
Training loss: 0.1415191410517031
Validation loss: 2.4950049449153133

Epoch: 6| Step: 3
Training loss: 0.4430688082331625
Validation loss: 2.4633954777949816

Epoch: 6| Step: 4
Training loss: 0.17118704268557022
Validation loss: 2.4649638027492196

Epoch: 6| Step: 5
Training loss: 0.18887462976067215
Validation loss: 2.456213008732848

Epoch: 6| Step: 6
Training loss: 0.2556111828210578
Validation loss: 2.4305990441607297

Epoch: 6| Step: 7
Training loss: 0.3124426550702205
Validation loss: 2.431529998536145

Epoch: 6| Step: 8
Training loss: 0.245994063274731
Validation loss: 2.4193460832116087

Epoch: 6| Step: 9
Training loss: 0.1548844629611076
Validation loss: 2.4164290652588765

Epoch: 6| Step: 10
Training loss: 0.1337529015226354
Validation loss: 2.436310695434119

Epoch: 6| Step: 11
Training loss: 0.22616428698524937
Validation loss: 2.435414734099289

Epoch: 6| Step: 12
Training loss: 0.19946623370988775
Validation loss: 2.419120421931222

Epoch: 6| Step: 13
Training loss: 0.28915424437503956
Validation loss: 2.4123593333101736

Epoch: 395| Step: 0
Training loss: 0.15918632212661013
Validation loss: 2.461512446722067

Epoch: 6| Step: 1
Training loss: 0.2950692850515342
Validation loss: 2.420879246905708

Epoch: 6| Step: 2
Training loss: 0.19781943283466993
Validation loss: 2.4272407747555973

Epoch: 6| Step: 3
Training loss: 0.1443366015861627
Validation loss: 2.4013451697231547

Epoch: 6| Step: 4
Training loss: 0.29423412442871494
Validation loss: 2.3972177137720334

Epoch: 6| Step: 5
Training loss: 0.21813862378221854
Validation loss: 2.422438624146443

Epoch: 6| Step: 6
Training loss: 0.14777084021588674
Validation loss: 2.4115805008377746

Epoch: 6| Step: 7
Training loss: 0.28870628936415843
Validation loss: 2.4061121939107175

Epoch: 6| Step: 8
Training loss: 0.21637290015928926
Validation loss: 2.4207540923736097

Epoch: 6| Step: 9
Training loss: 0.43737361989944207
Validation loss: 2.4122698407626113

Epoch: 6| Step: 10
Training loss: 0.11129115980052649
Validation loss: 2.375965358303988

Epoch: 6| Step: 11
Training loss: 0.30210565068031026
Validation loss: 2.3823522302417675

Epoch: 6| Step: 12
Training loss: 0.1854524271658861
Validation loss: 2.414297874342462

Epoch: 6| Step: 13
Training loss: 0.1431133076210434
Validation loss: 2.3830038864279413

Epoch: 396| Step: 0
Training loss: 0.1736520936728378
Validation loss: 2.393248738942366

Epoch: 6| Step: 1
Training loss: 0.4515700131751567
Validation loss: 2.400241510718636

Epoch: 6| Step: 2
Training loss: 0.2329876209089464
Validation loss: 2.4177669503425383

Epoch: 6| Step: 3
Training loss: 0.2904011299956946
Validation loss: 2.417338536367609

Epoch: 6| Step: 4
Training loss: 0.22815950472393423
Validation loss: 2.3821887133977686

Epoch: 6| Step: 5
Training loss: 0.294077656504294
Validation loss: 2.4197755243439785

Epoch: 6| Step: 6
Training loss: 0.16784919875595466
Validation loss: 2.4290782949611196

Epoch: 6| Step: 7
Training loss: 0.22094348040125622
Validation loss: 2.387156455555777

Epoch: 6| Step: 8
Training loss: 0.1403819606571952
Validation loss: 2.390732724902481

Epoch: 6| Step: 9
Training loss: 0.18288211678876115
Validation loss: 2.3760914974090177

Epoch: 6| Step: 10
Training loss: 0.22038922732348487
Validation loss: 2.3803562026734735

Epoch: 6| Step: 11
Training loss: 0.12044247335118921
Validation loss: 2.3926944321168975

Epoch: 6| Step: 12
Training loss: 0.3835740785546539
Validation loss: 2.3852407707006917

Epoch: 6| Step: 13
Training loss: 0.04972145661917739
Validation loss: 2.3925119516355737

Epoch: 397| Step: 0
Training loss: 0.16096552632561795
Validation loss: 2.373766273732579

Epoch: 6| Step: 1
Training loss: 0.4130893463643423
Validation loss: 2.405277534591855

Epoch: 6| Step: 2
Training loss: 0.2100491183319421
Validation loss: 2.430845984370462

Epoch: 6| Step: 3
Training loss: 0.16720253818830708
Validation loss: 2.4124990077406956

Epoch: 6| Step: 4
Training loss: 0.11628333008732317
Validation loss: 2.407433014324986

Epoch: 6| Step: 5
Training loss: 0.2336773662119616
Validation loss: 2.4101938631095066

Epoch: 6| Step: 6
Training loss: 0.13305806150465177
Validation loss: 2.408115430443023

Epoch: 6| Step: 7
Training loss: 0.23642578156513402
Validation loss: 2.437823678763216

Epoch: 6| Step: 8
Training loss: 0.1423125209950736
Validation loss: 2.461455710899633

Epoch: 6| Step: 9
Training loss: 0.5335381541744122
Validation loss: 2.4126942744182824

Epoch: 6| Step: 10
Training loss: 0.15465065681115778
Validation loss: 2.4713540643155407

Epoch: 6| Step: 11
Training loss: 0.16405390535276526
Validation loss: 2.450621796651873

Epoch: 6| Step: 12
Training loss: 0.23825872815116897
Validation loss: 2.4239327211981423

Epoch: 6| Step: 13
Training loss: 0.14356792155397072
Validation loss: 2.437215386142914

Epoch: 398| Step: 0
Training loss: 0.12083488143416994
Validation loss: 2.426156848222957

Epoch: 6| Step: 1
Training loss: 0.09643046691648768
Validation loss: 2.413613046812843

Epoch: 6| Step: 2
Training loss: 0.1375558160070537
Validation loss: 2.3684513099073534

Epoch: 6| Step: 3
Training loss: 0.16882057215412774
Validation loss: 2.4049176566891

Epoch: 6| Step: 4
Training loss: 0.5108787397840919
Validation loss: 2.400811553755602

Epoch: 6| Step: 5
Training loss: 0.12463465586630813
Validation loss: 2.4079653780067196

Epoch: 6| Step: 6
Training loss: 0.12900506191616776
Validation loss: 2.409864817457363

Epoch: 6| Step: 7
Training loss: 0.37604488396082825
Validation loss: 2.430999800305467

Epoch: 6| Step: 8
Training loss: 0.3097104378182305
Validation loss: 2.3872432393931735

Epoch: 6| Step: 9
Training loss: 0.29795472906738035
Validation loss: 2.3999040128542077

Epoch: 6| Step: 10
Training loss: 0.13813114855963524
Validation loss: 2.356336547745249

Epoch: 6| Step: 11
Training loss: 0.1530915941564325
Validation loss: 2.373839284162535

Epoch: 6| Step: 12
Training loss: 0.2041996989160162
Validation loss: 2.378642407600138

Epoch: 6| Step: 13
Training loss: 0.12402718831195218
Validation loss: 2.4032747551094893

Epoch: 399| Step: 0
Training loss: 0.19701233267062104
Validation loss: 2.395772628407466

Epoch: 6| Step: 1
Training loss: 0.37541656404522766
Validation loss: 2.409189484773097

Epoch: 6| Step: 2
Training loss: 0.17986533445590008
Validation loss: 2.3702070850900743

Epoch: 6| Step: 3
Training loss: 0.2022869538531827
Validation loss: 2.388058466409078

Epoch: 6| Step: 4
Training loss: 0.1686598731360902
Validation loss: 2.3914767576415086

Epoch: 6| Step: 5
Training loss: 0.26940269445124654
Validation loss: 2.3863409902223194

Epoch: 6| Step: 6
Training loss: 0.13575515410700695
Validation loss: 2.41424472459713

Epoch: 6| Step: 7
Training loss: 0.0903073457547265
Validation loss: 2.423351400703274

Epoch: 6| Step: 8
Training loss: 0.1495750781356337
Validation loss: 2.40376899300699

Epoch: 6| Step: 9
Training loss: 0.15065540190914767
Validation loss: 2.4210789875780865

Epoch: 6| Step: 10
Training loss: 0.09190274281961744
Validation loss: 2.43531580188679

Epoch: 6| Step: 11
Training loss: 0.2088407575594692
Validation loss: 2.4377329898795916

Epoch: 6| Step: 12
Training loss: 0.2339475389375602
Validation loss: 2.4036634153886647

Epoch: 6| Step: 13
Training loss: 0.6211235471091625
Validation loss: 2.41087573860119

Epoch: 400| Step: 0
Training loss: 0.34342472986389944
Validation loss: 2.415738809898907

Epoch: 6| Step: 1
Training loss: 0.4955775962471002
Validation loss: 2.4370010386952496

Epoch: 6| Step: 2
Training loss: 0.13364592782485765
Validation loss: 2.4256868012954467

Epoch: 6| Step: 3
Training loss: 0.18748956889700988
Validation loss: 2.418844105227807

Epoch: 6| Step: 4
Training loss: 0.13537773770974587
Validation loss: 2.4204248612769774

Epoch: 6| Step: 5
Training loss: 0.1241192485152935
Validation loss: 2.423063317857349

Epoch: 6| Step: 6
Training loss: 0.21599706256158333
Validation loss: 2.43498791953778

Epoch: 6| Step: 7
Training loss: 0.12969455125322318
Validation loss: 2.448872957048941

Epoch: 6| Step: 8
Training loss: 0.28776215283774875
Validation loss: 2.4581846050019123

Epoch: 6| Step: 9
Training loss: 0.21638113833270536
Validation loss: 2.4698034458205873

Epoch: 6| Step: 10
Training loss: 0.37685630226883315
Validation loss: 2.4244615538683343

Epoch: 6| Step: 11
Training loss: 0.18644834674609634
Validation loss: 2.4237875133529534

Epoch: 6| Step: 12
Training loss: 0.14246767808946464
Validation loss: 2.466814487257902

Epoch: 6| Step: 13
Training loss: 0.19622825515757578
Validation loss: 2.4311003444100625

Epoch: 401| Step: 0
Training loss: 0.1450495640646075
Validation loss: 2.414005423160242

Epoch: 6| Step: 1
Training loss: 0.21823942680790864
Validation loss: 2.4371218023765078

Epoch: 6| Step: 2
Training loss: 0.20220915025477523
Validation loss: 2.411182043732669

Epoch: 6| Step: 3
Training loss: 0.17960074652495955
Validation loss: 2.4340725590355796

Epoch: 6| Step: 4
Training loss: 0.4462799472003163
Validation loss: 2.39957192745321

Epoch: 6| Step: 5
Training loss: 0.1332766542503227
Validation loss: 2.4267604999944554

Epoch: 6| Step: 6
Training loss: 0.39468033494886606
Validation loss: 2.3891392658731934

Epoch: 6| Step: 7
Training loss: 0.14794755689235276
Validation loss: 2.4376052037567315

Epoch: 6| Step: 8
Training loss: 0.2280759249118063
Validation loss: 2.398415036056362

Epoch: 6| Step: 9
Training loss: 0.19799988130785054
Validation loss: 2.3855123737582655

Epoch: 6| Step: 10
Training loss: 0.210826155627682
Validation loss: 2.39012478131166

Epoch: 6| Step: 11
Training loss: 0.15983564572564268
Validation loss: 2.4092116128217733

Epoch: 6| Step: 12
Training loss: 0.2769263713273404
Validation loss: 2.400261193678676

Epoch: 6| Step: 13
Training loss: 0.11818694058724138
Validation loss: 2.4166302393571315

Epoch: 402| Step: 0
Training loss: 0.11559822942150616
Validation loss: 2.432046278724192

Epoch: 6| Step: 1
Training loss: 0.31676408760308505
Validation loss: 2.456036253845508

Epoch: 6| Step: 2
Training loss: 0.20580976854858202
Validation loss: 2.4660713489569

Epoch: 6| Step: 3
Training loss: 0.503644357683715
Validation loss: 2.426783199907501

Epoch: 6| Step: 4
Training loss: 0.28127976101134844
Validation loss: 2.4367552908821812

Epoch: 6| Step: 5
Training loss: 0.20692757943861476
Validation loss: 2.4367943965896646

Epoch: 6| Step: 6
Training loss: 0.15737715907202748
Validation loss: 2.4525530124572117

Epoch: 6| Step: 7
Training loss: 0.10649056304001603
Validation loss: 2.4342527149008975

Epoch: 6| Step: 8
Training loss: 0.22367545308546552
Validation loss: 2.417354885849326

Epoch: 6| Step: 9
Training loss: 0.1619126493532659
Validation loss: 2.4170203683817237

Epoch: 6| Step: 10
Training loss: 0.30313551383121096
Validation loss: 2.3908028549510405

Epoch: 6| Step: 11
Training loss: 0.14629419060594825
Validation loss: 2.4075170898307987

Epoch: 6| Step: 12
Training loss: 0.15025276206456217
Validation loss: 2.4064814660397085

Epoch: 6| Step: 13
Training loss: 0.12939994368839366
Validation loss: 2.400812919500212

Epoch: 403| Step: 0
Training loss: 0.2579804075993149
Validation loss: 2.404535822189997

Epoch: 6| Step: 1
Training loss: 0.24263732421229542
Validation loss: 2.38719581479195

Epoch: 6| Step: 2
Training loss: 0.2626582264868392
Validation loss: 2.3967243107262943

Epoch: 6| Step: 3
Training loss: 0.16512584097761435
Validation loss: 2.404871174404661

Epoch: 6| Step: 4
Training loss: 0.30564372083356733
Validation loss: 2.394686127762658

Epoch: 6| Step: 5
Training loss: 0.2530345036779304
Validation loss: 2.3889398664383754

Epoch: 6| Step: 6
Training loss: 0.14396481737678193
Validation loss: 2.400294100608453

Epoch: 6| Step: 7
Training loss: 0.09822469730042925
Validation loss: 2.390896577936574

Epoch: 6| Step: 8
Training loss: 0.16220218805090822
Validation loss: 2.3832455961481296

Epoch: 6| Step: 9
Training loss: 0.1012084962777904
Validation loss: 2.4099708834600504

Epoch: 6| Step: 10
Training loss: 0.48138077556757947
Validation loss: 2.435486520650186

Epoch: 6| Step: 11
Training loss: 0.2296840109527696
Validation loss: 2.4076398804872343

Epoch: 6| Step: 12
Training loss: 0.17406056968056935
Validation loss: 2.4055984354310693

Epoch: 6| Step: 13
Training loss: 0.2108834691961511
Validation loss: 2.42532754228867

Epoch: 404| Step: 0
Training loss: 0.18685539026299597
Validation loss: 2.4237674399702445

Epoch: 6| Step: 1
Training loss: 0.21145731842724513
Validation loss: 2.4158477192980743

Epoch: 6| Step: 2
Training loss: 0.49992432617693017
Validation loss: 2.4257704576186145

Epoch: 6| Step: 3
Training loss: 0.2960104022316632
Validation loss: 2.432863780607617

Epoch: 6| Step: 4
Training loss: 0.24417606096590833
Validation loss: 2.4440597726835387

Epoch: 6| Step: 5
Training loss: 0.20251950470273675
Validation loss: 2.418680205020074

Epoch: 6| Step: 6
Training loss: 0.2627319111908436
Validation loss: 2.4322362353595266

Epoch: 6| Step: 7
Training loss: 0.12996074661594015
Validation loss: 2.416809674686209

Epoch: 6| Step: 8
Training loss: 0.22987405376229203
Validation loss: 2.4624685800697796

Epoch: 6| Step: 9
Training loss: 0.1552618850153153
Validation loss: 2.4185220638381986

Epoch: 6| Step: 10
Training loss: 0.1249764017837463
Validation loss: 2.4046960124205676

Epoch: 6| Step: 11
Training loss: 0.15547640149059444
Validation loss: 2.3998040643136203

Epoch: 6| Step: 12
Training loss: 0.16840168693414215
Validation loss: 2.4371847380576224

Epoch: 6| Step: 13
Training loss: 0.1315213157997042
Validation loss: 2.4028723025155156

Epoch: 405| Step: 0
Training loss: 0.10196643976253537
Validation loss: 2.422279154293261

Epoch: 6| Step: 1
Training loss: 0.2003961253759105
Validation loss: 2.4352371623219766

Epoch: 6| Step: 2
Training loss: 0.20869267685984919
Validation loss: 2.421041961844439

Epoch: 6| Step: 3
Training loss: 0.13042761616805815
Validation loss: 2.4269958935240585

Epoch: 6| Step: 4
Training loss: 0.235977448624537
Validation loss: 2.427915951482291

Epoch: 6| Step: 5
Training loss: 0.09907755341761272
Validation loss: 2.4299470137533112

Epoch: 6| Step: 6
Training loss: 0.5047200750461456
Validation loss: 2.4162642190167043

Epoch: 6| Step: 7
Training loss: 0.17290366190433798
Validation loss: 2.4152801540486766

Epoch: 6| Step: 8
Training loss: 0.2244068891608864
Validation loss: 2.4040277450290253

Epoch: 6| Step: 9
Training loss: 0.18326877686513005
Validation loss: 2.4119165162836183

Epoch: 6| Step: 10
Training loss: 0.1212876482587791
Validation loss: 2.4410064356763925

Epoch: 6| Step: 11
Training loss: 0.3618272993375936
Validation loss: 2.3963001450953887

Epoch: 6| Step: 12
Training loss: 0.18269322082353107
Validation loss: 2.4127364280653087

Epoch: 6| Step: 13
Training loss: 0.15249185210098787
Validation loss: 2.4058892680572166

Epoch: 406| Step: 0
Training loss: 0.17313707338850257
Validation loss: 2.4168119956149425

Epoch: 6| Step: 1
Training loss: 0.3201874046749976
Validation loss: 2.4057697807249574

Epoch: 6| Step: 2
Training loss: 0.1892834523000285
Validation loss: 2.399288046852577

Epoch: 6| Step: 3
Training loss: 0.3326151146098945
Validation loss: 2.3953197743843098

Epoch: 6| Step: 4
Training loss: 0.13050042927057542
Validation loss: 2.3999741537059407

Epoch: 6| Step: 5
Training loss: 0.1060461557233796
Validation loss: 2.380964684117666

Epoch: 6| Step: 6
Training loss: 0.47779307406388877
Validation loss: 2.431391349884681

Epoch: 6| Step: 7
Training loss: 0.1401211666821519
Validation loss: 2.4077425742233136

Epoch: 6| Step: 8
Training loss: 0.18878540864293883
Validation loss: 2.4106409667722257

Epoch: 6| Step: 9
Training loss: 0.18617675678801732
Validation loss: 2.4198002317424256

Epoch: 6| Step: 10
Training loss: 0.2147025771586921
Validation loss: 2.4136592162953456

Epoch: 6| Step: 11
Training loss: 0.1982000898189707
Validation loss: 2.400950200099065

Epoch: 6| Step: 12
Training loss: 0.20078884622476043
Validation loss: 2.3993006626055893

Epoch: 6| Step: 13
Training loss: 0.2646646670612072
Validation loss: 2.418539141486186

Epoch: 407| Step: 0
Training loss: 0.15455090459488222
Validation loss: 2.3925675750158284

Epoch: 6| Step: 1
Training loss: 0.2324223478296423
Validation loss: 2.3843122658091485

Epoch: 6| Step: 2
Training loss: 0.4409016450920916
Validation loss: 2.3958442020749335

Epoch: 6| Step: 3
Training loss: 0.295965709530093
Validation loss: 2.394564902661599

Epoch: 6| Step: 4
Training loss: 0.2613340653683748
Validation loss: 2.395490149003155

Epoch: 6| Step: 5
Training loss: 0.21204426716347818
Validation loss: 2.377207321288633

Epoch: 6| Step: 6
Training loss: 0.22066252681058018
Validation loss: 2.409542048358684

Epoch: 6| Step: 7
Training loss: 0.15559933009296095
Validation loss: 2.4111412812835096

Epoch: 6| Step: 8
Training loss: 0.15870718070636777
Validation loss: 2.415591405596644

Epoch: 6| Step: 9
Training loss: 0.22547553196975512
Validation loss: 2.401523279037699

Epoch: 6| Step: 10
Training loss: 0.10712991833969426
Validation loss: 2.408885714594026

Epoch: 6| Step: 11
Training loss: 0.15984057508132724
Validation loss: 2.4046934218020164

Epoch: 6| Step: 12
Training loss: 0.22329369699155757
Validation loss: 2.4118318670868923

Epoch: 6| Step: 13
Training loss: 0.13207100292342389
Validation loss: 2.4017892003552124

Epoch: 408| Step: 0
Training loss: 0.15713490011804443
Validation loss: 2.4362520568229824

Epoch: 6| Step: 1
Training loss: 0.1545645709413863
Validation loss: 2.4047451142422887

Epoch: 6| Step: 2
Training loss: 0.21646596380802924
Validation loss: 2.462779147559207

Epoch: 6| Step: 3
Training loss: 0.1950140484768387
Validation loss: 2.4240621291344966

Epoch: 6| Step: 4
Training loss: 0.19975444352145424
Validation loss: 2.4225631514234243

Epoch: 6| Step: 5
Training loss: 0.1305763685923792
Validation loss: 2.385403145472667

Epoch: 6| Step: 6
Training loss: 0.2720350813664323
Validation loss: 2.383717699557196

Epoch: 6| Step: 7
Training loss: 0.29136948545352437
Validation loss: 2.42186621625659

Epoch: 6| Step: 8
Training loss: 0.5129583065702354
Validation loss: 2.416190316506139

Epoch: 6| Step: 9
Training loss: 0.1763700584270893
Validation loss: 2.422792294983237

Epoch: 6| Step: 10
Training loss: 0.14789344819160674
Validation loss: 2.4032961503791057

Epoch: 6| Step: 11
Training loss: 0.10298540066112954
Validation loss: 2.41334654067405

Epoch: 6| Step: 12
Training loss: 0.11208927393022476
Validation loss: 2.388132056492372

Epoch: 6| Step: 13
Training loss: 0.20980257671390298
Validation loss: 2.3791985546297036

Epoch: 409| Step: 0
Training loss: 0.23262948292763938
Validation loss: 2.4008526229261453

Epoch: 6| Step: 1
Training loss: 0.34653485993699695
Validation loss: 2.3776523544006745

Epoch: 6| Step: 2
Training loss: 0.13725586697453898
Validation loss: 2.399416421624183

Epoch: 6| Step: 3
Training loss: 0.17348523556993084
Validation loss: 2.3840773511062427

Epoch: 6| Step: 4
Training loss: 0.14125040513166207
Validation loss: 2.4204706423944358

Epoch: 6| Step: 5
Training loss: 0.08917933964839003
Validation loss: 2.382164135156603

Epoch: 6| Step: 6
Training loss: 0.25242905429747564
Validation loss: 2.42245462489717

Epoch: 6| Step: 7
Training loss: 0.13769883631532767
Validation loss: 2.412858425316662

Epoch: 6| Step: 8
Training loss: 0.1796902158780722
Validation loss: 2.416464578271561

Epoch: 6| Step: 9
Training loss: 0.19710613639671748
Validation loss: 2.4095849359415817

Epoch: 6| Step: 10
Training loss: 0.19969121222112476
Validation loss: 2.437349765503058

Epoch: 6| Step: 11
Training loss: 0.21542350400487364
Validation loss: 2.3736570892288804

Epoch: 6| Step: 12
Training loss: 0.4638834739636784
Validation loss: 2.422409025204101

Epoch: 6| Step: 13
Training loss: 0.13266939980939949
Validation loss: 2.3749919604093597

Epoch: 410| Step: 0
Training loss: 0.1645731811671817
Validation loss: 2.3797885835843258

Epoch: 6| Step: 1
Training loss: 0.2713095424493536
Validation loss: 2.3825037801468283

Epoch: 6| Step: 2
Training loss: 0.18547602856951537
Validation loss: 2.3395933502461754

Epoch: 6| Step: 3
Training loss: 0.1879087007198774
Validation loss: 2.3494606009494756

Epoch: 6| Step: 4
Training loss: 0.27351138615313203
Validation loss: 2.3594607575517323

Epoch: 6| Step: 5
Training loss: 0.14482662587342188
Validation loss: 2.337938700499227

Epoch: 6| Step: 6
Training loss: 0.22453358242174662
Validation loss: 2.3531071983825087

Epoch: 6| Step: 7
Training loss: 0.5473480358603925
Validation loss: 2.33363124012134

Epoch: 6| Step: 8
Training loss: 0.17196050056158335
Validation loss: 2.361581158965344

Epoch: 6| Step: 9
Training loss: 0.21386182247034252
Validation loss: 2.3705116372782418

Epoch: 6| Step: 10
Training loss: 0.11103583329798701
Validation loss: 2.3996460383556575

Epoch: 6| Step: 11
Training loss: 0.13804446249053584
Validation loss: 2.3840362370538

Epoch: 6| Step: 12
Training loss: 0.2269567643627208
Validation loss: 2.456889854132042

Epoch: 6| Step: 13
Training loss: 0.10391179783430259
Validation loss: 2.42376492976106

Epoch: 411| Step: 0
Training loss: 0.2891355886074832
Validation loss: 2.436927793455512

Epoch: 6| Step: 1
Training loss: 0.2837698166603125
Validation loss: 2.4220207898218002

Epoch: 6| Step: 2
Training loss: 0.12805882698961524
Validation loss: 2.426215151254695

Epoch: 6| Step: 3
Training loss: 0.10372210548457791
Validation loss: 2.466107673157901

Epoch: 6| Step: 4
Training loss: 0.2974559219949427
Validation loss: 2.4393383421353927

Epoch: 6| Step: 5
Training loss: 0.15053152320833857
Validation loss: 2.4259106290754335

Epoch: 6| Step: 6
Training loss: 0.26873093803581594
Validation loss: 2.4356857028536143

Epoch: 6| Step: 7
Training loss: 0.15084823123739224
Validation loss: 2.458527861988058

Epoch: 6| Step: 8
Training loss: 0.2329034224522433
Validation loss: 2.4374122088461583

Epoch: 6| Step: 9
Training loss: 0.16236678908161126
Validation loss: 2.4233433469688532

Epoch: 6| Step: 10
Training loss: 0.2519418580840643
Validation loss: 2.4329712000555443

Epoch: 6| Step: 11
Training loss: 0.15309402751060386
Validation loss: 2.4253506419537065

Epoch: 6| Step: 12
Training loss: 0.25673888370737785
Validation loss: 2.4028585799219453

Epoch: 6| Step: 13
Training loss: 0.6227911062437359
Validation loss: 2.40413933736639

Epoch: 412| Step: 0
Training loss: 0.43905594573100876
Validation loss: 2.424364894971117

Epoch: 6| Step: 1
Training loss: 0.17978377458247646
Validation loss: 2.434313177772063

Epoch: 6| Step: 2
Training loss: 0.32475650955339297
Validation loss: 2.4638404487233054

Epoch: 6| Step: 3
Training loss: 0.11354482340871981
Validation loss: 2.495959274303075

Epoch: 6| Step: 4
Training loss: 0.17311247837147223
Validation loss: 2.478614163035721

Epoch: 6| Step: 5
Training loss: 0.25820302285150537
Validation loss: 2.4704363914567917

Epoch: 6| Step: 6
Training loss: 0.3050516593287103
Validation loss: 2.4834197556722

Epoch: 6| Step: 7
Training loss: 0.17481105942008113
Validation loss: 2.4415778207523138

Epoch: 6| Step: 8
Training loss: 0.1391356597220074
Validation loss: 2.45281027211967

Epoch: 6| Step: 9
Training loss: 0.12089372080289958
Validation loss: 2.4278026020100647

Epoch: 6| Step: 10
Training loss: 0.21481102780927264
Validation loss: 2.4313421514361044

Epoch: 6| Step: 11
Training loss: 0.12634691609395665
Validation loss: 2.423858852597754

Epoch: 6| Step: 12
Training loss: 0.23862482534315252
Validation loss: 2.4132387427250435

Epoch: 6| Step: 13
Training loss: 0.3488464769275445
Validation loss: 2.411240232535019

Epoch: 413| Step: 0
Training loss: 0.15316998346505845
Validation loss: 2.413290968116152

Epoch: 6| Step: 1
Training loss: 0.18527073640440847
Validation loss: 2.4068912918851204

Epoch: 6| Step: 2
Training loss: 0.14025441321443516
Validation loss: 2.4222012620612796

Epoch: 6| Step: 3
Training loss: 0.3000821125388285
Validation loss: 2.4474410953728034

Epoch: 6| Step: 4
Training loss: 0.2490487628101513
Validation loss: 2.426409331022955

Epoch: 6| Step: 5
Training loss: 0.15002548180146635
Validation loss: 2.4449836976170736

Epoch: 6| Step: 6
Training loss: 0.2065344824524288
Validation loss: 2.419301656784541

Epoch: 6| Step: 7
Training loss: 0.13361402881927867
Validation loss: 2.396664285323872

Epoch: 6| Step: 8
Training loss: 0.19191076971948853
Validation loss: 2.415104468954433

Epoch: 6| Step: 9
Training loss: 0.19412609253187207
Validation loss: 2.373622883628532

Epoch: 6| Step: 10
Training loss: 0.21262595146544913
Validation loss: 2.4067571334934854

Epoch: 6| Step: 11
Training loss: 0.24350964451661575
Validation loss: 2.3874253537355177

Epoch: 6| Step: 12
Training loss: 0.2411193055844512
Validation loss: 2.3572278634031822

Epoch: 6| Step: 13
Training loss: 0.6094672548934592
Validation loss: 2.3774243574236893

Epoch: 414| Step: 0
Training loss: 0.2569713743090447
Validation loss: 2.426650753991143

Epoch: 6| Step: 1
Training loss: 0.15891617336064937
Validation loss: 2.3743757302892887

Epoch: 6| Step: 2
Training loss: 0.10037916188530933
Validation loss: 2.3698153128937904

Epoch: 6| Step: 3
Training loss: 0.21968918376456426
Validation loss: 2.3994066880850817

Epoch: 6| Step: 4
Training loss: 0.17455220235873758
Validation loss: 2.3908565054459374

Epoch: 6| Step: 5
Training loss: 0.21961588297252224
Validation loss: 2.386883462330767

Epoch: 6| Step: 6
Training loss: 0.24427222710369734
Validation loss: 2.4100336234531206

Epoch: 6| Step: 7
Training loss: 0.17942723831111007
Validation loss: 2.4052323052527664

Epoch: 6| Step: 8
Training loss: 0.20496190729015404
Validation loss: 2.3829440371906863

Epoch: 6| Step: 9
Training loss: 0.1511972149845687
Validation loss: 2.402778985306549

Epoch: 6| Step: 10
Training loss: 0.4229699336959459
Validation loss: 2.423427488289249

Epoch: 6| Step: 11
Training loss: 0.3344452561341874
Validation loss: 2.4092168737234707

Epoch: 6| Step: 12
Training loss: 0.1883665762070217
Validation loss: 2.407828794427443

Epoch: 6| Step: 13
Training loss: 0.24753891755711274
Validation loss: 2.422512742942445

Epoch: 415| Step: 0
Training loss: 0.1898585239203274
Validation loss: 2.4278366202898143

Epoch: 6| Step: 1
Training loss: 0.2576319466875446
Validation loss: 2.435260136934133

Epoch: 6| Step: 2
Training loss: 0.11841103461901252
Validation loss: 2.45893121060282

Epoch: 6| Step: 3
Training loss: 0.4516918604265401
Validation loss: 2.4556936340785334

Epoch: 6| Step: 4
Training loss: 0.2664070817369471
Validation loss: 2.423330231162275

Epoch: 6| Step: 5
Training loss: 0.1611272290736299
Validation loss: 2.4402016727599793

Epoch: 6| Step: 6
Training loss: 0.15399107023844744
Validation loss: 2.461723846578046

Epoch: 6| Step: 7
Training loss: 0.18518909291828878
Validation loss: 2.4160376873460248

Epoch: 6| Step: 8
Training loss: 0.3367270130108345
Validation loss: 2.4170125990231854

Epoch: 6| Step: 9
Training loss: 0.1579643378316036
Validation loss: 2.422253225420459

Epoch: 6| Step: 10
Training loss: 0.22159887512933735
Validation loss: 2.381861371033784

Epoch: 6| Step: 11
Training loss: 0.29846128998049526
Validation loss: 2.351561361845487

Epoch: 6| Step: 12
Training loss: 0.1234343875420178
Validation loss: 2.3833765409640373

Epoch: 6| Step: 13
Training loss: 0.14986757254152103
Validation loss: 2.3697748233413405

Epoch: 416| Step: 0
Training loss: 0.1783327259201181
Validation loss: 2.3550422990000075

Epoch: 6| Step: 1
Training loss: 0.18545739877507186
Validation loss: 2.3282674418395786

Epoch: 6| Step: 2
Training loss: 0.22375666424613921
Validation loss: 2.3292048949658644

Epoch: 6| Step: 3
Training loss: 0.2551944333138263
Validation loss: 2.341695261387167

Epoch: 6| Step: 4
Training loss: 0.23985944348661623
Validation loss: 2.3489519850456824

Epoch: 6| Step: 5
Training loss: 0.11684484453599209
Validation loss: 2.335475267757761

Epoch: 6| Step: 6
Training loss: 0.2574905639604661
Validation loss: 2.380316626410204

Epoch: 6| Step: 7
Training loss: 0.28504097581231447
Validation loss: 2.3756717240372693

Epoch: 6| Step: 8
Training loss: 0.49523484978184446
Validation loss: 2.3925048945497713

Epoch: 6| Step: 9
Training loss: 0.1678382233310124
Validation loss: 2.4144932142657582

Epoch: 6| Step: 10
Training loss: 0.19237841683415177
Validation loss: 2.4312786453743955

Epoch: 6| Step: 11
Training loss: 0.15356999009768013
Validation loss: 2.490774643915104

Epoch: 6| Step: 12
Training loss: 0.12734990836388443
Validation loss: 2.4722405053867162

Epoch: 6| Step: 13
Training loss: 0.19916740391573529
Validation loss: 2.487182913622098

Epoch: 417| Step: 0
Training loss: 0.20091827852379715
Validation loss: 2.4699220410295197

Epoch: 6| Step: 1
Training loss: 0.27558540327965253
Validation loss: 2.488449950476771

Epoch: 6| Step: 2
Training loss: 0.25481522054859673
Validation loss: 2.458289702042006

Epoch: 6| Step: 3
Training loss: 0.22077446181329222
Validation loss: 2.40268183717849

Epoch: 6| Step: 4
Training loss: 0.2573534172618694
Validation loss: 2.421960149214888

Epoch: 6| Step: 5
Training loss: 0.4777728173672398
Validation loss: 2.4053342488601506

Epoch: 6| Step: 6
Training loss: 0.2616212293077027
Validation loss: 2.409104258761805

Epoch: 6| Step: 7
Training loss: 0.3325719806013046
Validation loss: 2.3787767672843185

Epoch: 6| Step: 8
Training loss: 0.2640844155421121
Validation loss: 2.3750064549684913

Epoch: 6| Step: 9
Training loss: 0.2117687993171634
Validation loss: 2.3808879313374534

Epoch: 6| Step: 10
Training loss: 0.1893234989274493
Validation loss: 2.391526740289501

Epoch: 6| Step: 11
Training loss: 0.4168355678913836
Validation loss: 2.430778718148416

Epoch: 6| Step: 12
Training loss: 0.24841161629056976
Validation loss: 2.426861600021744

Epoch: 6| Step: 13
Training loss: 0.23142849985857222
Validation loss: 2.4034130844242734

Epoch: 418| Step: 0
Training loss: 0.21862055149972515
Validation loss: 2.4625774637667197

Epoch: 6| Step: 1
Training loss: 0.30795404065217774
Validation loss: 2.4615552448199423

Epoch: 6| Step: 2
Training loss: 0.32640414619406943
Validation loss: 2.4578727456158105

Epoch: 6| Step: 3
Training loss: 0.24174153891848935
Validation loss: 2.416063386881377

Epoch: 6| Step: 4
Training loss: 0.22143205599993074
Validation loss: 2.466034770563324

Epoch: 6| Step: 5
Training loss: 0.43935399950828535
Validation loss: 2.430732045912336

Epoch: 6| Step: 6
Training loss: 0.18849071390263183
Validation loss: 2.4014551231466377

Epoch: 6| Step: 7
Training loss: 0.20365700378091162
Validation loss: 2.4346800521585106

Epoch: 6| Step: 8
Training loss: 0.21897185519490925
Validation loss: 2.4273868511668724

Epoch: 6| Step: 9
Training loss: 0.1272162864360319
Validation loss: 2.4297481028515304

Epoch: 6| Step: 10
Training loss: 0.31113805820331797
Validation loss: 2.4236098697896313

Epoch: 6| Step: 11
Training loss: 0.271799439859199
Validation loss: 2.4412884185904793

Epoch: 6| Step: 12
Training loss: 0.2515719435678555
Validation loss: 2.431820661634999

Epoch: 6| Step: 13
Training loss: 0.2111989978867656
Validation loss: 2.412857946133122

Epoch: 419| Step: 0
Training loss: 0.2393359698878796
Validation loss: 2.3979819858187112

Epoch: 6| Step: 1
Training loss: 0.30934163501269674
Validation loss: 2.3885951214099057

Epoch: 6| Step: 2
Training loss: 0.3248405698223328
Validation loss: 2.3593847204903335

Epoch: 6| Step: 3
Training loss: 0.2127952712110835
Validation loss: 2.422471972197054

Epoch: 6| Step: 4
Training loss: 0.14195553176594727
Validation loss: 2.4239659323550447

Epoch: 6| Step: 5
Training loss: 0.24487842466433615
Validation loss: 2.4215786750301342

Epoch: 6| Step: 6
Training loss: 0.2864712220962604
Validation loss: 2.4648703707656097

Epoch: 6| Step: 7
Training loss: 0.2684446768417464
Validation loss: 2.4204014100873956

Epoch: 6| Step: 8
Training loss: 0.35221188228119915
Validation loss: 2.4554619428037907

Epoch: 6| Step: 9
Training loss: 0.30113622847794497
Validation loss: 2.4493416833862116

Epoch: 6| Step: 10
Training loss: 0.15326265599496655
Validation loss: 2.4446157677484974

Epoch: 6| Step: 11
Training loss: 0.12267210821426684
Validation loss: 2.4893668045355946

Epoch: 6| Step: 12
Training loss: 0.4960011072838637
Validation loss: 2.4640825053387214

Epoch: 6| Step: 13
Training loss: 0.25335500004673156
Validation loss: 2.498389982857918

Epoch: 420| Step: 0
Training loss: 0.2708809547861203
Validation loss: 2.474579128404243

Epoch: 6| Step: 1
Training loss: 0.26675655065839393
Validation loss: 2.5176907480947004

Epoch: 6| Step: 2
Training loss: 0.33133463992797296
Validation loss: 2.4410355003479776

Epoch: 6| Step: 3
Training loss: 0.28672893776321245
Validation loss: 2.4502819572068817

Epoch: 6| Step: 4
Training loss: 0.15970473493222337
Validation loss: 2.4377840127493573

Epoch: 6| Step: 5
Training loss: 0.1839101074546671
Validation loss: 2.437826400855112

Epoch: 6| Step: 6
Training loss: 0.27526801335520495
Validation loss: 2.41969081316454

Epoch: 6| Step: 7
Training loss: 0.234001203323494
Validation loss: 2.3883517161298187

Epoch: 6| Step: 8
Training loss: 0.44578985094289614
Validation loss: 2.435868430538909

Epoch: 6| Step: 9
Training loss: 0.3036098250581642
Validation loss: 2.4139620554990247

Epoch: 6| Step: 10
Training loss: 0.1510415851384524
Validation loss: 2.3830091438671075

Epoch: 6| Step: 11
Training loss: 0.215261729002825
Validation loss: 2.3988269167640883

Epoch: 6| Step: 12
Training loss: 0.25582894297155484
Validation loss: 2.3843068429723693

Epoch: 6| Step: 13
Training loss: 0.1313346870571146
Validation loss: 2.4150701168808375

Epoch: 421| Step: 0
Training loss: 0.34616779628891375
Validation loss: 2.3908548930213116

Epoch: 6| Step: 1
Training loss: 0.20452577593816734
Validation loss: 2.3721341629893824

Epoch: 6| Step: 2
Training loss: 0.25582613255859504
Validation loss: 2.404201105641417

Epoch: 6| Step: 3
Training loss: 0.1529616272605519
Validation loss: 2.3993491984976583

Epoch: 6| Step: 4
Training loss: 0.21889624645621011
Validation loss: 2.4634163836855874

Epoch: 6| Step: 5
Training loss: 0.33206003849661614
Validation loss: 2.4622816168981956

Epoch: 6| Step: 6
Training loss: 0.46086223440387414
Validation loss: 2.459057658631965

Epoch: 6| Step: 7
Training loss: 0.18509198695226609
Validation loss: 2.4634027428683516

Epoch: 6| Step: 8
Training loss: 0.13846361613587
Validation loss: 2.501388383730449

Epoch: 6| Step: 9
Training loss: 0.24740021434050335
Validation loss: 2.457003281784966

Epoch: 6| Step: 10
Training loss: 0.16427773027167078
Validation loss: 2.4835878728455185

Epoch: 6| Step: 11
Training loss: 0.21823745524401986
Validation loss: 2.4742812300333785

Epoch: 6| Step: 12
Training loss: 0.18078262974798606
Validation loss: 2.463078162277562

Epoch: 6| Step: 13
Training loss: 0.3574240637540245
Validation loss: 2.4736417958853134

Epoch: 422| Step: 0
Training loss: 0.2225148270520832
Validation loss: 2.429810972610772

Epoch: 6| Step: 1
Training loss: 0.26452076214607145
Validation loss: 2.398959487144552

Epoch: 6| Step: 2
Training loss: 0.30095627881617726
Validation loss: 2.371500716668614

Epoch: 6| Step: 3
Training loss: 0.2571812473199872
Validation loss: 2.398639307713919

Epoch: 6| Step: 4
Training loss: 0.36826262432220724
Validation loss: 2.3891283836190325

Epoch: 6| Step: 5
Training loss: 0.2750373224377563
Validation loss: 2.3856039688839226

Epoch: 6| Step: 6
Training loss: 0.5132189011700451
Validation loss: 2.377668827442192

Epoch: 6| Step: 7
Training loss: 0.24407048553024013
Validation loss: 2.402207461497225

Epoch: 6| Step: 8
Training loss: 0.22511269939078463
Validation loss: 2.382799335391593

Epoch: 6| Step: 9
Training loss: 0.2995171052978845
Validation loss: 2.4080040553704096

Epoch: 6| Step: 10
Training loss: 0.25807618614817723
Validation loss: 2.3756190946535654

Epoch: 6| Step: 11
Training loss: 0.4517877182089478
Validation loss: 2.368224937469306

Epoch: 6| Step: 12
Training loss: 0.3403504310570715
Validation loss: 2.3860257543415386

Epoch: 6| Step: 13
Training loss: 0.19040040989316268
Validation loss: 2.3792593563080997

Epoch: 423| Step: 0
Training loss: 0.14794276635732276
Validation loss: 2.464910101164492

Epoch: 6| Step: 1
Training loss: 0.4514841097467729
Validation loss: 2.444704189472989

Epoch: 6| Step: 2
Training loss: 0.23704165728157692
Validation loss: 2.4846935758046014

Epoch: 6| Step: 3
Training loss: 0.20951337796426656
Validation loss: 2.4439515849924076

Epoch: 6| Step: 4
Training loss: 0.19926052029595834
Validation loss: 2.4636627988197213

Epoch: 6| Step: 5
Training loss: 0.2480250296397269
Validation loss: 2.464593282308901

Epoch: 6| Step: 6
Training loss: 0.21163323248326174
Validation loss: 2.443579755365346

Epoch: 6| Step: 7
Training loss: 0.3120694293645801
Validation loss: 2.4536507798559204

Epoch: 6| Step: 8
Training loss: 0.29690202790753345
Validation loss: 2.448233889986411

Epoch: 6| Step: 9
Training loss: 0.21651677776062006
Validation loss: 2.3819619589137697

Epoch: 6| Step: 10
Training loss: 0.503213598612889
Validation loss: 2.4108084149660844

Epoch: 6| Step: 11
Training loss: 0.29424351872069404
Validation loss: 2.4010942740871384

Epoch: 6| Step: 12
Training loss: 0.39193616161625855
Validation loss: 2.384974730567098

Epoch: 6| Step: 13
Training loss: 0.20489420136398312
Validation loss: 2.339334845939746

Epoch: 424| Step: 0
Training loss: 0.21545197483126174
Validation loss: 2.355783598922623

Epoch: 6| Step: 1
Training loss: 0.2690811545521161
Validation loss: 2.388056907113403

Epoch: 6| Step: 2
Training loss: 0.2667668148325481
Validation loss: 2.3628739623936097

Epoch: 6| Step: 3
Training loss: 0.3896682466524418
Validation loss: 2.3357876564864197

Epoch: 6| Step: 4
Training loss: 0.2529754302737357
Validation loss: 2.398243896734118

Epoch: 6| Step: 5
Training loss: 0.47815612990819917
Validation loss: 2.401738359065931

Epoch: 6| Step: 6
Training loss: 0.34667084373691764
Validation loss: 2.420122862568035

Epoch: 6| Step: 7
Training loss: 0.3208856339782332
Validation loss: 2.4507688566149217

Epoch: 6| Step: 8
Training loss: 0.21531234270596675
Validation loss: 2.4999350652157664

Epoch: 6| Step: 9
Training loss: 0.19917097640828008
Validation loss: 2.5007605903098793

Epoch: 6| Step: 10
Training loss: 0.19969068987332778
Validation loss: 2.500692439833952

Epoch: 6| Step: 11
Training loss: 0.30258751044773496
Validation loss: 2.4965244735339995

Epoch: 6| Step: 12
Training loss: 0.3416746084329219
Validation loss: 2.4801800515347816

Epoch: 6| Step: 13
Training loss: 0.32070755438585924
Validation loss: 2.4725677112022484

Epoch: 425| Step: 0
Training loss: 0.23814996636038252
Validation loss: 2.4168690528466468

Epoch: 6| Step: 1
Training loss: 0.22157375812847477
Validation loss: 2.4014472927547486

Epoch: 6| Step: 2
Training loss: 0.3044612974068962
Validation loss: 2.342165439071687

Epoch: 6| Step: 3
Training loss: 0.4900813072730061
Validation loss: 2.343210262375706

Epoch: 6| Step: 4
Training loss: 0.30014142189950765
Validation loss: 2.2992551301432305

Epoch: 6| Step: 5
Training loss: 0.3468090084812429
Validation loss: 2.342187612563489

Epoch: 6| Step: 6
Training loss: 0.17937323828573087
Validation loss: 2.3551348478447895

Epoch: 6| Step: 7
Training loss: 0.1688448105368737
Validation loss: 2.3412478472859064

Epoch: 6| Step: 8
Training loss: 0.29344274958991906
Validation loss: 2.3728964178544536

Epoch: 6| Step: 9
Training loss: 0.27526142254912983
Validation loss: 2.363124685000647

Epoch: 6| Step: 10
Training loss: 0.23230470380563328
Validation loss: 2.3948045259588358

Epoch: 6| Step: 11
Training loss: 0.1405409720826178
Validation loss: 2.3640641797252138

Epoch: 6| Step: 12
Training loss: 0.25787446693387506
Validation loss: 2.3952160698627316

Epoch: 6| Step: 13
Training loss: 0.1604450111510781
Validation loss: 2.3995351932633895

Epoch: 426| Step: 0
Training loss: 0.27272597790360137
Validation loss: 2.41593983773628

Epoch: 6| Step: 1
Training loss: 0.342663152184226
Validation loss: 2.4286603531417685

Epoch: 6| Step: 2
Training loss: 0.19926367982333587
Validation loss: 2.427892575817427

Epoch: 6| Step: 3
Training loss: 0.16507064359170334
Validation loss: 2.372661626250691

Epoch: 6| Step: 4
Training loss: 0.2963328681805553
Validation loss: 2.3502937382479523

Epoch: 6| Step: 5
Training loss: 0.5316489068366546
Validation loss: 2.381623302853938

Epoch: 6| Step: 6
Training loss: 0.16721396192248228
Validation loss: 2.314639032596641

Epoch: 6| Step: 7
Training loss: 0.2553645145888952
Validation loss: 2.3464302734525515

Epoch: 6| Step: 8
Training loss: 0.24992983548698158
Validation loss: 2.3558099541377033

Epoch: 6| Step: 9
Training loss: 0.09588731829477219
Validation loss: 2.365083003532346

Epoch: 6| Step: 10
Training loss: 0.16315403961163186
Validation loss: 2.3774046412129097

Epoch: 6| Step: 11
Training loss: 0.2561939032722959
Validation loss: 2.4002381318574577

Epoch: 6| Step: 12
Training loss: 0.2494019716777963
Validation loss: 2.4006614335049474

Epoch: 6| Step: 13
Training loss: 0.1835672582627229
Validation loss: 2.393511456986693

Epoch: 427| Step: 0
Training loss: 0.49535108530313215
Validation loss: 2.393811390745867

Epoch: 6| Step: 1
Training loss: 0.21370028598062946
Validation loss: 2.4104221830371304

Epoch: 6| Step: 2
Training loss: 0.13935809864751797
Validation loss: 2.373029006505197

Epoch: 6| Step: 3
Training loss: 0.17952428536978723
Validation loss: 2.4170438576788698

Epoch: 6| Step: 4
Training loss: 0.2566381062423222
Validation loss: 2.405261104614524

Epoch: 6| Step: 5
Training loss: 0.29078803667924874
Validation loss: 2.401586312307861

Epoch: 6| Step: 6
Training loss: 0.25383980688638974
Validation loss: 2.4169439740850143

Epoch: 6| Step: 7
Training loss: 0.1848560220992921
Validation loss: 2.4080997533312005

Epoch: 6| Step: 8
Training loss: 0.18766876414020703
Validation loss: 2.3762573838535532

Epoch: 6| Step: 9
Training loss: 0.1729190554559159
Validation loss: 2.4128677029712295

Epoch: 6| Step: 10
Training loss: 0.35963161263006654
Validation loss: 2.3902426525235194

Epoch: 6| Step: 11
Training loss: 0.19473120971766444
Validation loss: 2.3825686831161095

Epoch: 6| Step: 12
Training loss: 0.1546678429453854
Validation loss: 2.401759301567759

Epoch: 6| Step: 13
Training loss: 0.11618979846805746
Validation loss: 2.359450181180078

Epoch: 428| Step: 0
Training loss: 0.18625241706867088
Validation loss: 2.3237770212998594

Epoch: 6| Step: 1
Training loss: 0.25120287832893534
Validation loss: 2.3502480834350097

Epoch: 6| Step: 2
Training loss: 0.2633073335399235
Validation loss: 2.3087192627112207

Epoch: 6| Step: 3
Training loss: 0.16963402713475526
Validation loss: 2.3313767272890424

Epoch: 6| Step: 4
Training loss: 0.29033449327828054
Validation loss: 2.3194530872233643

Epoch: 6| Step: 5
Training loss: 0.1670195908398128
Validation loss: 2.340433310811788

Epoch: 6| Step: 6
Training loss: 0.12389056529797682
Validation loss: 2.343169029723115

Epoch: 6| Step: 7
Training loss: 0.4372656398852933
Validation loss: 2.3211573641239767

Epoch: 6| Step: 8
Training loss: 0.17122991839190219
Validation loss: 2.334395458781212

Epoch: 6| Step: 9
Training loss: 0.15902060768347653
Validation loss: 2.331827218909128

Epoch: 6| Step: 10
Training loss: 0.13040729977203247
Validation loss: 2.363181337464804

Epoch: 6| Step: 11
Training loss: 0.3032244990933206
Validation loss: 2.3129871357520853

Epoch: 6| Step: 12
Training loss: 0.15276388166247748
Validation loss: 2.327375020991298

Epoch: 6| Step: 13
Training loss: 0.12392423446928465
Validation loss: 2.33351119377301

Epoch: 429| Step: 0
Training loss: 0.18991976224853177
Validation loss: 2.3623953566104605

Epoch: 6| Step: 1
Training loss: 0.17053737100147406
Validation loss: 2.3480869804641573

Epoch: 6| Step: 2
Training loss: 0.23439794269167905
Validation loss: 2.332118237299202

Epoch: 6| Step: 3
Training loss: 0.3603733748784043
Validation loss: 2.351081482521418

Epoch: 6| Step: 4
Training loss: 0.384252622553228
Validation loss: 2.3739703417763636

Epoch: 6| Step: 5
Training loss: 0.13124010582369827
Validation loss: 2.3741472793514475

Epoch: 6| Step: 6
Training loss: 0.18872637820377947
Validation loss: 2.3755193109109474

Epoch: 6| Step: 7
Training loss: 0.23949044265074124
Validation loss: 2.3669540174789723

Epoch: 6| Step: 8
Training loss: 0.14391631684521228
Validation loss: 2.37594657329989

Epoch: 6| Step: 9
Training loss: 0.11460709370641997
Validation loss: 2.3428315269659232

Epoch: 6| Step: 10
Training loss: 0.18123228052275622
Validation loss: 2.368667101683168

Epoch: 6| Step: 11
Training loss: 0.13181593001394515
Validation loss: 2.3735855415515075

Epoch: 6| Step: 12
Training loss: 0.19780753079722024
Validation loss: 2.380181913125331

Epoch: 6| Step: 13
Training loss: 0.15704140511694498
Validation loss: 2.374182575552779

Epoch: 430| Step: 0
Training loss: 0.1722485211589874
Validation loss: 2.3782847960852056

Epoch: 6| Step: 1
Training loss: 0.14843864189511827
Validation loss: 2.384895354973955

Epoch: 6| Step: 2
Training loss: 0.1991270826785171
Validation loss: 2.4072006434856306

Epoch: 6| Step: 3
Training loss: 0.2060829974790192
Validation loss: 2.3604757056788426

Epoch: 6| Step: 4
Training loss: 0.421946201673784
Validation loss: 2.3829235334127996

Epoch: 6| Step: 5
Training loss: 0.27938103908267076
Validation loss: 2.4081753364888336

Epoch: 6| Step: 6
Training loss: 0.13487221469336544
Validation loss: 2.3885712986821455

Epoch: 6| Step: 7
Training loss: 0.27896095295066126
Validation loss: 2.3644211376340243

Epoch: 6| Step: 8
Training loss: 0.18142275921582546
Validation loss: 2.350067313628099

Epoch: 6| Step: 9
Training loss: 0.2244110392739528
Validation loss: 2.3270791184821444

Epoch: 6| Step: 10
Training loss: 0.2202185484580889
Validation loss: 2.3574360322689016

Epoch: 6| Step: 11
Training loss: 0.3000831925754558
Validation loss: 2.3256275176554

Epoch: 6| Step: 12
Training loss: 0.16604054207901608
Validation loss: 2.3449913877451523

Epoch: 6| Step: 13
Training loss: 0.3255866505524093
Validation loss: 2.326087681847544

Epoch: 431| Step: 0
Training loss: 0.237941053523289
Validation loss: 2.3950714736899954

Epoch: 6| Step: 1
Training loss: 0.3879103748714084
Validation loss: 2.362723781892533

Epoch: 6| Step: 2
Training loss: 0.10959608434497597
Validation loss: 2.4051422021653055

Epoch: 6| Step: 3
Training loss: 0.21771123023288438
Validation loss: 2.413479830350776

Epoch: 6| Step: 4
Training loss: 0.26715017470715174
Validation loss: 2.4616739208073923

Epoch: 6| Step: 5
Training loss: 0.16642413647656717
Validation loss: 2.434481297353904

Epoch: 6| Step: 6
Training loss: 0.1969291536844004
Validation loss: 2.4220106221206232

Epoch: 6| Step: 7
Training loss: 0.18357334632313127
Validation loss: 2.413780338480767

Epoch: 6| Step: 8
Training loss: 0.3103113060704492
Validation loss: 2.4101345220629367

Epoch: 6| Step: 9
Training loss: 0.3115054995355957
Validation loss: 2.414054611739546

Epoch: 6| Step: 10
Training loss: 0.3630531989856744
Validation loss: 2.3980723157107677

Epoch: 6| Step: 11
Training loss: 0.2766464359262425
Validation loss: 2.426910857610095

Epoch: 6| Step: 12
Training loss: 0.18406855283412327
Validation loss: 2.395354972119093

Epoch: 6| Step: 13
Training loss: 0.3181232793907596
Validation loss: 2.409510356168104

Epoch: 432| Step: 0
Training loss: 0.29376291084324124
Validation loss: 2.392471017890756

Epoch: 6| Step: 1
Training loss: 0.31374661231016804
Validation loss: 2.361872506677809

Epoch: 6| Step: 2
Training loss: 0.18712483065488564
Validation loss: 2.385289873198848

Epoch: 6| Step: 3
Training loss: 0.26007983199407636
Validation loss: 2.3726808292075363

Epoch: 6| Step: 4
Training loss: 0.24184692185339565
Validation loss: 2.3374438431913362

Epoch: 6| Step: 5
Training loss: 0.24874757184468113
Validation loss: 2.3426453303944696

Epoch: 6| Step: 6
Training loss: 0.24444523691024228
Validation loss: 2.3450141062754883

Epoch: 6| Step: 7
Training loss: 0.1723760054433129
Validation loss: 2.348545358393316

Epoch: 6| Step: 8
Training loss: 0.1861871213829081
Validation loss: 2.388081197120757

Epoch: 6| Step: 9
Training loss: 0.212473188840627
Validation loss: 2.3916160785952694

Epoch: 6| Step: 10
Training loss: 0.48897385875573207
Validation loss: 2.3443662537406076

Epoch: 6| Step: 11
Training loss: 0.14543171627362236
Validation loss: 2.3826355129916563

Epoch: 6| Step: 12
Training loss: 0.1728594611135884
Validation loss: 2.385199532677513

Epoch: 6| Step: 13
Training loss: 0.24563495314915515
Validation loss: 2.388407279685616

Epoch: 433| Step: 0
Training loss: 0.15759864754813582
Validation loss: 2.355908335376357

Epoch: 6| Step: 1
Training loss: 0.2046036453872264
Validation loss: 2.3608042199241743

Epoch: 6| Step: 2
Training loss: 0.16324877461627796
Validation loss: 2.38029805803225

Epoch: 6| Step: 3
Training loss: 0.21354823955251478
Validation loss: 2.3486362656030755

Epoch: 6| Step: 4
Training loss: 0.32314930759841515
Validation loss: 2.3836822767480292

Epoch: 6| Step: 5
Training loss: 0.4369249993065139
Validation loss: 2.350852861686634

Epoch: 6| Step: 6
Training loss: 0.1764294540815216
Validation loss: 2.397233748652349

Epoch: 6| Step: 7
Training loss: 0.2107238747433076
Validation loss: 2.403693115045224

Epoch: 6| Step: 8
Training loss: 0.2258877160003163
Validation loss: 2.356056808916835

Epoch: 6| Step: 9
Training loss: 0.19921295307177556
Validation loss: 2.3529714943946067

Epoch: 6| Step: 10
Training loss: 0.1567280133172951
Validation loss: 2.373283660363265

Epoch: 6| Step: 11
Training loss: 0.19257487474217327
Validation loss: 2.2959882028684033

Epoch: 6| Step: 12
Training loss: 0.2733362555396098
Validation loss: 2.3369860873119

Epoch: 6| Step: 13
Training loss: 0.31913369450228635
Validation loss: 2.331836987720885

Epoch: 434| Step: 0
Training loss: 0.11029338569082682
Validation loss: 2.349803866150224

Epoch: 6| Step: 1
Training loss: 0.2171531190348672
Validation loss: 2.3205690214145926

Epoch: 6| Step: 2
Training loss: 0.21598039274222466
Validation loss: 2.3841257995917635

Epoch: 6| Step: 3
Training loss: 0.22285592177705188
Validation loss: 2.3458244522752225

Epoch: 6| Step: 4
Training loss: 0.15859873486657067
Validation loss: 2.361251844072105

Epoch: 6| Step: 5
Training loss: 0.1701411279679143
Validation loss: 2.3555319131769634

Epoch: 6| Step: 6
Training loss: 0.26319740839496814
Validation loss: 2.3767150047257135

Epoch: 6| Step: 7
Training loss: 0.5635782080723799
Validation loss: 2.3819569999821293

Epoch: 6| Step: 8
Training loss: 0.1504856342080395
Validation loss: 2.3545054842487447

Epoch: 6| Step: 9
Training loss: 0.24229476460690094
Validation loss: 2.3772867276561542

Epoch: 6| Step: 10
Training loss: 0.25629835835503006
Validation loss: 2.3766261979161354

Epoch: 6| Step: 11
Training loss: 0.11421430607172765
Validation loss: 2.4279591525249966

Epoch: 6| Step: 12
Training loss: 0.16359413367356684
Validation loss: 2.342637311361637

Epoch: 6| Step: 13
Training loss: 0.2181558373522056
Validation loss: 2.356201830002978

Epoch: 435| Step: 0
Training loss: 0.28967403471102665
Validation loss: 2.389991299325088

Epoch: 6| Step: 1
Training loss: 0.14520591421064274
Validation loss: 2.3660876651533305

Epoch: 6| Step: 2
Training loss: 0.2630275199845924
Validation loss: 2.402479708512902

Epoch: 6| Step: 3
Training loss: 0.27586981834364294
Validation loss: 2.365093337383026

Epoch: 6| Step: 4
Training loss: 0.13297752337979563
Validation loss: 2.4088833477156224

Epoch: 6| Step: 5
Training loss: 0.14506254617862058
Validation loss: 2.4184332265354573

Epoch: 6| Step: 6
Training loss: 0.2507548856097634
Validation loss: 2.371625992272518

Epoch: 6| Step: 7
Training loss: 0.1953246112883091
Validation loss: 2.358829873477929

Epoch: 6| Step: 8
Training loss: 0.44980327889225613
Validation loss: 2.375782913130973

Epoch: 6| Step: 9
Training loss: 0.33598006888082155
Validation loss: 2.376872411037948

Epoch: 6| Step: 10
Training loss: 0.16675174982698424
Validation loss: 2.363471836021389

Epoch: 6| Step: 11
Training loss: 0.22602754774401362
Validation loss: 2.3562282382054485

Epoch: 6| Step: 12
Training loss: 0.21952782862430573
Validation loss: 2.354174802785875

Epoch: 6| Step: 13
Training loss: 0.15322310409334572
Validation loss: 2.3739688137232946

Epoch: 436| Step: 0
Training loss: 0.4164456933898873
Validation loss: 2.3949648966256807

Epoch: 6| Step: 1
Training loss: 0.2707578144178603
Validation loss: 2.3873881110381863

Epoch: 6| Step: 2
Training loss: 0.262641603446126
Validation loss: 2.395990222824986

Epoch: 6| Step: 3
Training loss: 0.2766386929315011
Validation loss: 2.39874788679354

Epoch: 6| Step: 4
Training loss: 0.22764678173496602
Validation loss: 2.4053239706539924

Epoch: 6| Step: 5
Training loss: 0.0977246426463821
Validation loss: 2.3938968099467863

Epoch: 6| Step: 6
Training loss: 0.23580460058004102
Validation loss: 2.41044169831206

Epoch: 6| Step: 7
Training loss: 0.29850602087341666
Validation loss: 2.375839018273574

Epoch: 6| Step: 8
Training loss: 0.219276917585348
Validation loss: 2.3394494868886433

Epoch: 6| Step: 9
Training loss: 0.21932986583101746
Validation loss: 2.3459330503613547

Epoch: 6| Step: 10
Training loss: 0.2512962590993772
Validation loss: 2.315128877515897

Epoch: 6| Step: 11
Training loss: 0.22301915358923888
Validation loss: 2.324356296461199

Epoch: 6| Step: 12
Training loss: 0.22684397970099407
Validation loss: 2.3192086083823584

Epoch: 6| Step: 13
Training loss: 0.14968271972573097
Validation loss: 2.3131159777122776

Epoch: 437| Step: 0
Training loss: 0.198274280975735
Validation loss: 2.331770369780334

Epoch: 6| Step: 1
Training loss: 0.32023777904315937
Validation loss: 2.267452736409109

Epoch: 6| Step: 2
Training loss: 0.15920115835098478
Validation loss: 2.351314094529342

Epoch: 6| Step: 3
Training loss: 0.20290927251905533
Validation loss: 2.370628688531213

Epoch: 6| Step: 4
Training loss: 0.11194278205403906
Validation loss: 2.40982660187278

Epoch: 6| Step: 5
Training loss: 0.20896068331752582
Validation loss: 2.4172449594000494

Epoch: 6| Step: 6
Training loss: 0.2079280467508822
Validation loss: 2.445461168683848

Epoch: 6| Step: 7
Training loss: 0.17160025224678244
Validation loss: 2.4392113180171315

Epoch: 6| Step: 8
Training loss: 0.2277385017714695
Validation loss: 2.444517566577577

Epoch: 6| Step: 9
Training loss: 0.18957155989325533
Validation loss: 2.446834884073943

Epoch: 6| Step: 10
Training loss: 0.43397968746369714
Validation loss: 2.409502820074735

Epoch: 6| Step: 11
Training loss: 0.17694153905669388
Validation loss: 2.400945240344776

Epoch: 6| Step: 12
Training loss: 0.2597887989692497
Validation loss: 2.414122990674255

Epoch: 6| Step: 13
Training loss: 0.18085458349550385
Validation loss: 2.389827187912961

Epoch: 438| Step: 0
Training loss: 0.15823639413911414
Validation loss: 2.3931101295476824

Epoch: 6| Step: 1
Training loss: 0.16093230053919044
Validation loss: 2.3582670025998427

Epoch: 6| Step: 2
Training loss: 0.2609871560093423
Validation loss: 2.3473266634473857

Epoch: 6| Step: 3
Training loss: 0.11626004135310622
Validation loss: 2.364909681645496

Epoch: 6| Step: 4
Training loss: 0.23791527393343173
Validation loss: 2.3626996033665284

Epoch: 6| Step: 5
Training loss: 0.321730545183439
Validation loss: 2.3487248902367934

Epoch: 6| Step: 6
Training loss: 0.4768628752830677
Validation loss: 2.3610723944917336

Epoch: 6| Step: 7
Training loss: 0.18571263989830153
Validation loss: 2.344835514828066

Epoch: 6| Step: 8
Training loss: 0.18664953952224628
Validation loss: 2.3577658176051437

Epoch: 6| Step: 9
Training loss: 0.2132138589440315
Validation loss: 2.362061866513352

Epoch: 6| Step: 10
Training loss: 0.20877330138879355
Validation loss: 2.355976130426024

Epoch: 6| Step: 11
Training loss: 0.17117621598687205
Validation loss: 2.3892647824364417

Epoch: 6| Step: 12
Training loss: 0.14846585655403913
Validation loss: 2.371236415696574

Epoch: 6| Step: 13
Training loss: 0.18961620194350035
Validation loss: 2.361090666722436

Epoch: 439| Step: 0
Training loss: 0.18325600094877018
Validation loss: 2.3977650206721757

Epoch: 6| Step: 1
Training loss: 0.17070531559985455
Validation loss: 2.4112866877298904

Epoch: 6| Step: 2
Training loss: 0.32836082476328304
Validation loss: 2.3975012481931546

Epoch: 6| Step: 3
Training loss: 0.14540349818269122
Validation loss: 2.3733324296452287

Epoch: 6| Step: 4
Training loss: 0.14232148627606345
Validation loss: 2.3860244193499214

Epoch: 6| Step: 5
Training loss: 0.22288924290669446
Validation loss: 2.358447537957428

Epoch: 6| Step: 6
Training loss: 0.11500358099130377
Validation loss: 2.3567500179071574

Epoch: 6| Step: 7
Training loss: 0.2756135592821807
Validation loss: 2.3704235616893747

Epoch: 6| Step: 8
Training loss: 0.4217505448048979
Validation loss: 2.3528926511804515

Epoch: 6| Step: 9
Training loss: 0.15913988563616788
Validation loss: 2.358122980959319

Epoch: 6| Step: 10
Training loss: 0.15447392144711808
Validation loss: 2.341283907185907

Epoch: 6| Step: 11
Training loss: 0.12881509852668824
Validation loss: 2.3876321723481717

Epoch: 6| Step: 12
Training loss: 0.10989578190195166
Validation loss: 2.379880955384113

Epoch: 6| Step: 13
Training loss: 0.270815223614123
Validation loss: 2.406381462564162

Epoch: 440| Step: 0
Training loss: 0.2551808423526915
Validation loss: 2.3610098328686173

Epoch: 6| Step: 1
Training loss: 0.17591535433095706
Validation loss: 2.355971763157148

Epoch: 6| Step: 2
Training loss: 0.21239988829848663
Validation loss: 2.396737841143847

Epoch: 6| Step: 3
Training loss: 0.41275655181070137
Validation loss: 2.392409259662413

Epoch: 6| Step: 4
Training loss: 0.17169148770205145
Validation loss: 2.4032367291532286

Epoch: 6| Step: 5
Training loss: 0.23106268951928288
Validation loss: 2.3866143639908914

Epoch: 6| Step: 6
Training loss: 0.13665160846569635
Validation loss: 2.3839580184986886

Epoch: 6| Step: 7
Training loss: 0.26790600200496095
Validation loss: 2.3858276377136964

Epoch: 6| Step: 8
Training loss: 0.21510824048769808
Validation loss: 2.3729606318022642

Epoch: 6| Step: 9
Training loss: 0.12921670894786735
Validation loss: 2.386188772423732

Epoch: 6| Step: 10
Training loss: 0.14871102780218365
Validation loss: 2.3975482240840393

Epoch: 6| Step: 11
Training loss: 0.20377903876167397
Validation loss: 2.3597351725069355

Epoch: 6| Step: 12
Training loss: 0.15669344917448944
Validation loss: 2.3614239210613595

Epoch: 6| Step: 13
Training loss: 0.1852693892118496
Validation loss: 2.3580271247249893

Epoch: 441| Step: 0
Training loss: 0.15771499728263255
Validation loss: 2.3747435389737306

Epoch: 6| Step: 1
Training loss: 0.28584770084969147
Validation loss: 2.3907124064165726

Epoch: 6| Step: 2
Training loss: 0.14614082103403273
Validation loss: 2.386914531812373

Epoch: 6| Step: 3
Training loss: 0.15117611053605204
Validation loss: 2.4046988077268368

Epoch: 6| Step: 4
Training loss: 0.4730961541638177
Validation loss: 2.4117077939593035

Epoch: 6| Step: 5
Training loss: 0.1758804888868532
Validation loss: 2.3854161565357104

Epoch: 6| Step: 6
Training loss: 0.144419007922171
Validation loss: 2.4031854395089027

Epoch: 6| Step: 7
Training loss: 0.2022639327053974
Validation loss: 2.4131551937714883

Epoch: 6| Step: 8
Training loss: 0.18656373712075183
Validation loss: 2.4373516566653937

Epoch: 6| Step: 9
Training loss: 0.14907035064216967
Validation loss: 2.401995440454986

Epoch: 6| Step: 10
Training loss: 0.14814927326777946
Validation loss: 2.443215069387038

Epoch: 6| Step: 11
Training loss: 0.10439159774583995
Validation loss: 2.405635293368146

Epoch: 6| Step: 12
Training loss: 0.21265175743879192
Validation loss: 2.408766572529789

Epoch: 6| Step: 13
Training loss: 0.37832463251659565
Validation loss: 2.397104416383351

Epoch: 442| Step: 0
Training loss: 0.12718275283933364
Validation loss: 2.408622491543917

Epoch: 6| Step: 1
Training loss: 0.12041085483568038
Validation loss: 2.3774802809556

Epoch: 6| Step: 2
Training loss: 0.22310345060806097
Validation loss: 2.3967420154004953

Epoch: 6| Step: 3
Training loss: 0.18942134629977952
Validation loss: 2.350582930606425

Epoch: 6| Step: 4
Training loss: 0.28138957269147624
Validation loss: 2.349750280977729

Epoch: 6| Step: 5
Training loss: 0.4029573557715651
Validation loss: 2.3426830507512415

Epoch: 6| Step: 6
Training loss: 0.23313269390265406
Validation loss: 2.3876614449082476

Epoch: 6| Step: 7
Training loss: 0.2600642474050932
Validation loss: 2.385638362693609

Epoch: 6| Step: 8
Training loss: 0.2011470964597226
Validation loss: 2.3988540531924687

Epoch: 6| Step: 9
Training loss: 0.13216257251464028
Validation loss: 2.3890863295690674

Epoch: 6| Step: 10
Training loss: 0.23293904059422382
Validation loss: 2.4017934859136485

Epoch: 6| Step: 11
Training loss: 0.24404354454116092
Validation loss: 2.4016349156921546

Epoch: 6| Step: 12
Training loss: 0.12279392916165909
Validation loss: 2.392130271745936

Epoch: 6| Step: 13
Training loss: 0.1994317356090676
Validation loss: 2.4348607842804673

Epoch: 443| Step: 0
Training loss: 0.21525810339369483
Validation loss: 2.4255082361864284

Epoch: 6| Step: 1
Training loss: 0.27833949240467665
Validation loss: 2.4137905854580737

Epoch: 6| Step: 2
Training loss: 0.1780784336926532
Validation loss: 2.428191518802197

Epoch: 6| Step: 3
Training loss: 0.11799140011688179
Validation loss: 2.3989045708887415

Epoch: 6| Step: 4
Training loss: 0.39623406688052876
Validation loss: 2.4405758384860454

Epoch: 6| Step: 5
Training loss: 0.10294107468245887
Validation loss: 2.3911611320570905

Epoch: 6| Step: 6
Training loss: 0.14050302248636026
Validation loss: 2.3711829283509225

Epoch: 6| Step: 7
Training loss: 0.1292852263951373
Validation loss: 2.3594577429538144

Epoch: 6| Step: 8
Training loss: 0.23488134683455922
Validation loss: 2.3694700422877735

Epoch: 6| Step: 9
Training loss: 0.27586129731551307
Validation loss: 2.3949799371807683

Epoch: 6| Step: 10
Training loss: 0.10686021839226802
Validation loss: 2.3284828872821115

Epoch: 6| Step: 11
Training loss: 0.2341431185920824
Validation loss: 2.3152473955664035

Epoch: 6| Step: 12
Training loss: 0.13443300414714682
Validation loss: 2.3067950185003867

Epoch: 6| Step: 13
Training loss: 0.25321227382290695
Validation loss: 2.3323346856098097

Epoch: 444| Step: 0
Training loss: 0.181001111676559
Validation loss: 2.2807969089933997

Epoch: 6| Step: 1
Training loss: 0.2848411020479149
Validation loss: 2.315455680503323

Epoch: 6| Step: 2
Training loss: 0.18223619752456796
Validation loss: 2.316584898410916

Epoch: 6| Step: 3
Training loss: 0.18887853499587817
Validation loss: 2.2983570888138476

Epoch: 6| Step: 4
Training loss: 0.16385878676658747
Validation loss: 2.321590566160936

Epoch: 6| Step: 5
Training loss: 0.23832180897459052
Validation loss: 2.3361619915617173

Epoch: 6| Step: 6
Training loss: 0.09592464656029022
Validation loss: 2.3438447097729607

Epoch: 6| Step: 7
Training loss: 0.21711542593975158
Validation loss: 2.358134064458809

Epoch: 6| Step: 8
Training loss: 0.16116984548691615
Validation loss: 2.3820145929106395

Epoch: 6| Step: 9
Training loss: 0.12010325374267339
Validation loss: 2.388091038011139

Epoch: 6| Step: 10
Training loss: 0.16127881458012866
Validation loss: 2.3901674810162383

Epoch: 6| Step: 11
Training loss: 0.0732060311401129
Validation loss: 2.4045127022123554

Epoch: 6| Step: 12
Training loss: 0.11678319168314058
Validation loss: 2.450015524270265

Epoch: 6| Step: 13
Training loss: 0.5873237741234033
Validation loss: 2.401936335264975

Epoch: 445| Step: 0
Training loss: 0.12277171234171352
Validation loss: 2.4501749147864107

Epoch: 6| Step: 1
Training loss: 0.15262048602048484
Validation loss: 2.447502942928215

Epoch: 6| Step: 2
Training loss: 0.2304924774886998
Validation loss: 2.4507064544160877

Epoch: 6| Step: 3
Training loss: 0.27668894447309794
Validation loss: 2.4213564356939146

Epoch: 6| Step: 4
Training loss: 0.1578985095521048
Validation loss: 2.4198963764117263

Epoch: 6| Step: 5
Training loss: 0.18565650512030551
Validation loss: 2.4488437556083182

Epoch: 6| Step: 6
Training loss: 0.39109876512885067
Validation loss: 2.4417000442766374

Epoch: 6| Step: 7
Training loss: 0.1615594187263756
Validation loss: 2.403810053242721

Epoch: 6| Step: 8
Training loss: 0.16286953256656853
Validation loss: 2.4013721410449396

Epoch: 6| Step: 9
Training loss: 0.24215048076360185
Validation loss: 2.405602242100117

Epoch: 6| Step: 10
Training loss: 0.2859684859616321
Validation loss: 2.3981770148891104

Epoch: 6| Step: 11
Training loss: 0.14779940028946478
Validation loss: 2.436287234581978

Epoch: 6| Step: 12
Training loss: 0.15611539645738473
Validation loss: 2.4255208032879274

Epoch: 6| Step: 13
Training loss: 0.0929000191714695
Validation loss: 2.4271113276875176

Epoch: 446| Step: 0
Training loss: 0.2268316708848824
Validation loss: 2.3964393915644298

Epoch: 6| Step: 1
Training loss: 0.21688004350431908
Validation loss: 2.4002264385151717

Epoch: 6| Step: 2
Training loss: 0.20748375079289957
Validation loss: 2.3889665093999035

Epoch: 6| Step: 3
Training loss: 0.14405086948257492
Validation loss: 2.4235022649575595

Epoch: 6| Step: 4
Training loss: 0.1433311850457029
Validation loss: 2.4256180756300787

Epoch: 6| Step: 5
Training loss: 0.286114063885543
Validation loss: 2.406933454497971

Epoch: 6| Step: 6
Training loss: 0.18487150856084533
Validation loss: 2.4079904844550315

Epoch: 6| Step: 7
Training loss: 0.24378601260570357
Validation loss: 2.3924099101070007

Epoch: 6| Step: 8
Training loss: 0.1621906237769978
Validation loss: 2.3561168574828546

Epoch: 6| Step: 9
Training loss: 0.38209006202011764
Validation loss: 2.38500493973418

Epoch: 6| Step: 10
Training loss: 0.2007913509010064
Validation loss: 2.391264129034811

Epoch: 6| Step: 11
Training loss: 0.11583507485575663
Validation loss: 2.346363144957175

Epoch: 6| Step: 12
Training loss: 0.21395547342261723
Validation loss: 2.3551995329955444

Epoch: 6| Step: 13
Training loss: 0.1747093206930505
Validation loss: 2.359796123684155

Epoch: 447| Step: 0
Training loss: 0.3133438637583834
Validation loss: 2.3516156230760386

Epoch: 6| Step: 1
Training loss: 0.24780930383552524
Validation loss: 2.3721009691630712

Epoch: 6| Step: 2
Training loss: 0.37417103616517944
Validation loss: 2.363049813835876

Epoch: 6| Step: 3
Training loss: 0.16709378147000098
Validation loss: 2.443721938152428

Epoch: 6| Step: 4
Training loss: 0.21719682591127376
Validation loss: 2.4189450984168506

Epoch: 6| Step: 5
Training loss: 0.24524531112499118
Validation loss: 2.42363379554684

Epoch: 6| Step: 6
Training loss: 0.15484057376040566
Validation loss: 2.4182657425907794

Epoch: 6| Step: 7
Training loss: 0.16826518647998165
Validation loss: 2.489220458416768

Epoch: 6| Step: 8
Training loss: 0.09453054676109594
Validation loss: 2.4879622190901087

Epoch: 6| Step: 9
Training loss: 0.14869775669091523
Validation loss: 2.4841646123562655

Epoch: 6| Step: 10
Training loss: 0.12674922708317074
Validation loss: 2.5135087727318

Epoch: 6| Step: 11
Training loss: 0.14733557393234337
Validation loss: 2.499544118518473

Epoch: 6| Step: 12
Training loss: 0.23433849527266998
Validation loss: 2.4943874865021156

Epoch: 6| Step: 13
Training loss: 0.22358007517169456
Validation loss: 2.4973941368281953

Epoch: 448| Step: 0
Training loss: 0.18481449343883724
Validation loss: 2.447010222422844

Epoch: 6| Step: 1
Training loss: 0.12401898443683093
Validation loss: 2.3952399982866863

Epoch: 6| Step: 2
Training loss: 0.13989556061393116
Validation loss: 2.4411105142623275

Epoch: 6| Step: 3
Training loss: 0.16168118422949768
Validation loss: 2.3892385811194536

Epoch: 6| Step: 4
Training loss: 0.20939700665757366
Validation loss: 2.3547952545843835

Epoch: 6| Step: 5
Training loss: 0.22971910661449937
Validation loss: 2.385253529805714

Epoch: 6| Step: 6
Training loss: 0.23251544447331035
Validation loss: 2.3829384832162757

Epoch: 6| Step: 7
Training loss: 0.1858265625963289
Validation loss: 2.3867456567463154

Epoch: 6| Step: 8
Training loss: 0.16546418101745072
Validation loss: 2.377893485241172

Epoch: 6| Step: 9
Training loss: 0.2378621088986081
Validation loss: 2.393839139844128

Epoch: 6| Step: 10
Training loss: 0.08483324649771372
Validation loss: 2.372840539707454

Epoch: 6| Step: 11
Training loss: 0.16855915678073075
Validation loss: 2.3769555064166243

Epoch: 6| Step: 12
Training loss: 0.4583364580510292
Validation loss: 2.398693430071928

Epoch: 6| Step: 13
Training loss: 0.17455631597766874
Validation loss: 2.37779688371124

Epoch: 449| Step: 0
Training loss: 0.1612617901254714
Validation loss: 2.410589051139274

Epoch: 6| Step: 1
Training loss: 0.21944685192655333
Validation loss: 2.4144359809059015

Epoch: 6| Step: 2
Training loss: 0.13965947434353812
Validation loss: 2.3973580458151185

Epoch: 6| Step: 3
Training loss: 0.15214987792091036
Validation loss: 2.389901892773627

Epoch: 6| Step: 4
Training loss: 0.11995618776627767
Validation loss: 2.3867047274906863

Epoch: 6| Step: 5
Training loss: 0.1394498920867341
Validation loss: 2.396199625771

Epoch: 6| Step: 6
Training loss: 0.49473493819708747
Validation loss: 2.3963395199702733

Epoch: 6| Step: 7
Training loss: 0.18327043350185943
Validation loss: 2.4287693977152385

Epoch: 6| Step: 8
Training loss: 0.12678496888366614
Validation loss: 2.404768710648866

Epoch: 6| Step: 9
Training loss: 0.15150545634580398
Validation loss: 2.372866140964584

Epoch: 6| Step: 10
Training loss: 0.2194333132923271
Validation loss: 2.384138896659535

Epoch: 6| Step: 11
Training loss: 0.18121553742872826
Validation loss: 2.371028446424643

Epoch: 6| Step: 12
Training loss: 0.11901090157185383
Validation loss: 2.3555867990623702

Epoch: 6| Step: 13
Training loss: 0.15419676104103558
Validation loss: 2.3446348061078606

Epoch: 450| Step: 0
Training loss: 0.18816163628304622
Validation loss: 2.394717789185712

Epoch: 6| Step: 1
Training loss: 0.1911966382798537
Validation loss: 2.355965252772196

Epoch: 6| Step: 2
Training loss: 0.2077473724821088
Validation loss: 2.3865947849293394

Epoch: 6| Step: 3
Training loss: 0.421133449289647
Validation loss: 2.3829417833275706

Epoch: 6| Step: 4
Training loss: 0.10391795497590632
Validation loss: 2.371281422623896

Epoch: 6| Step: 5
Training loss: 0.18785432278482544
Validation loss: 2.3656859258277536

Epoch: 6| Step: 6
Training loss: 0.2492510409945613
Validation loss: 2.3423353617081113

Epoch: 6| Step: 7
Training loss: 0.2968331483151928
Validation loss: 2.3559517085458217

Epoch: 6| Step: 8
Training loss: 0.194545039105701
Validation loss: 2.3621843141312526

Epoch: 6| Step: 9
Training loss: 0.21331862202568114
Validation loss: 2.3584718236637063

Epoch: 6| Step: 10
Training loss: 0.17353293181857576
Validation loss: 2.371092201171992

Epoch: 6| Step: 11
Training loss: 0.20252092109149555
Validation loss: 2.4200404718452715

Epoch: 6| Step: 12
Training loss: 0.21600722077561235
Validation loss: 2.4265294287747845

Epoch: 6| Step: 13
Training loss: 0.16198775313659547
Validation loss: 2.399132069015176

Epoch: 451| Step: 0
Training loss: 0.19521901754523066
Validation loss: 2.376845481506574

Epoch: 6| Step: 1
Training loss: 0.19457975265494853
Validation loss: 2.3861589086159425

Epoch: 6| Step: 2
Training loss: 0.22619553970896264
Validation loss: 2.3764343841624123

Epoch: 6| Step: 3
Training loss: 0.12563106562551238
Validation loss: 2.3790475975196994

Epoch: 6| Step: 4
Training loss: 0.16753487773639883
Validation loss: 2.3629564987432774

Epoch: 6| Step: 5
Training loss: 0.13624549427369234
Validation loss: 2.3533675227394504

Epoch: 6| Step: 6
Training loss: 0.15576876202865547
Validation loss: 2.352759697034741

Epoch: 6| Step: 7
Training loss: 0.1652515217607119
Validation loss: 2.355927149847586

Epoch: 6| Step: 8
Training loss: 0.22195258127405743
Validation loss: 2.3563516401177877

Epoch: 6| Step: 9
Training loss: 0.15761403502534327
Validation loss: 2.3560151895652215

Epoch: 6| Step: 10
Training loss: 0.21479075385071467
Validation loss: 2.38403538592499

Epoch: 6| Step: 11
Training loss: 0.14218893888814413
Validation loss: 2.376103089423816

Epoch: 6| Step: 12
Training loss: 0.4377074090595948
Validation loss: 2.3907936980893254

Epoch: 6| Step: 13
Training loss: 0.14931711155567037
Validation loss: 2.405326021289391

Epoch: 452| Step: 0
Training loss: 0.42783290128917645
Validation loss: 2.3905914505892545

Epoch: 6| Step: 1
Training loss: 0.21447542001701125
Validation loss: 2.3885898531901795

Epoch: 6| Step: 2
Training loss: 0.13533361957293497
Validation loss: 2.3998087166284954

Epoch: 6| Step: 3
Training loss: 0.1695598604521995
Validation loss: 2.370595140543325

Epoch: 6| Step: 4
Training loss: 0.14781562514560062
Validation loss: 2.3506391382671126

Epoch: 6| Step: 5
Training loss: 0.29928292465259243
Validation loss: 2.3923393894181033

Epoch: 6| Step: 6
Training loss: 0.13426553154055035
Validation loss: 2.3641868765986116

Epoch: 6| Step: 7
Training loss: 0.1408924632211124
Validation loss: 2.4076908785246665

Epoch: 6| Step: 8
Training loss: 0.24500907550273487
Validation loss: 2.36645926205899

Epoch: 6| Step: 9
Training loss: 0.1646599676183474
Validation loss: 2.3918245027293947

Epoch: 6| Step: 10
Training loss: 0.19532443963750076
Validation loss: 2.367666126199111

Epoch: 6| Step: 11
Training loss: 0.22319837292081143
Validation loss: 2.437463470345124

Epoch: 6| Step: 12
Training loss: 0.139145706497352
Validation loss: 2.376632629590843

Epoch: 6| Step: 13
Training loss: 0.1346761434064288
Validation loss: 2.384389678725394

Epoch: 453| Step: 0
Training loss: 0.15637136156932535
Validation loss: 2.3783201656225246

Epoch: 6| Step: 1
Training loss: 0.16998734802260618
Validation loss: 2.3906660554306742

Epoch: 6| Step: 2
Training loss: 0.12623380670467962
Validation loss: 2.4118384126831365

Epoch: 6| Step: 3
Training loss: 0.1515332510834343
Validation loss: 2.4590386115406364

Epoch: 6| Step: 4
Training loss: 0.1218580040023675
Validation loss: 2.3933213521364034

Epoch: 6| Step: 5
Training loss: 0.19056011526192684
Validation loss: 2.400371821546369

Epoch: 6| Step: 6
Training loss: 0.3280601664478508
Validation loss: 2.422757626009374

Epoch: 6| Step: 7
Training loss: 0.1636790153384376
Validation loss: 2.3809252154138036

Epoch: 6| Step: 8
Training loss: 0.38897229569882324
Validation loss: 2.376655233890385

Epoch: 6| Step: 9
Training loss: 0.24871339383656565
Validation loss: 2.405945228417937

Epoch: 6| Step: 10
Training loss: 0.1743453987438152
Validation loss: 2.416008343702492

Epoch: 6| Step: 11
Training loss: 0.1635806637533354
Validation loss: 2.462742753444756

Epoch: 6| Step: 12
Training loss: 0.07714383196061092
Validation loss: 2.40950686422434

Epoch: 6| Step: 13
Training loss: 0.18775258336721698
Validation loss: 2.4219453555978423

Epoch: 454| Step: 0
Training loss: 0.25843836215704546
Validation loss: 2.383491450316204

Epoch: 6| Step: 1
Training loss: 0.2007775376863574
Validation loss: 2.394376218746445

Epoch: 6| Step: 2
Training loss: 0.29234652246234033
Validation loss: 2.404595986931686

Epoch: 6| Step: 3
Training loss: 0.19520027751306834
Validation loss: 2.3939932892188627

Epoch: 6| Step: 4
Training loss: 0.3336064392106459
Validation loss: 2.4047914944899347

Epoch: 6| Step: 5
Training loss: 0.19714085249333266
Validation loss: 2.3853589789051504

Epoch: 6| Step: 6
Training loss: 0.1659192647091893
Validation loss: 2.3766039800540955

Epoch: 6| Step: 7
Training loss: 0.12910301911748592
Validation loss: 2.388464502410359

Epoch: 6| Step: 8
Training loss: 0.233159225970987
Validation loss: 2.4138351414605577

Epoch: 6| Step: 9
Training loss: 0.1556015686124791
Validation loss: 2.4093763212661057

Epoch: 6| Step: 10
Training loss: 0.1933533157015749
Validation loss: 2.425690624527154

Epoch: 6| Step: 11
Training loss: 0.40903838273797066
Validation loss: 2.408378074489571

Epoch: 6| Step: 12
Training loss: 0.09813272585491847
Validation loss: 2.3957059488410133

Epoch: 6| Step: 13
Training loss: 0.157212742500197
Validation loss: 2.409209127084289

Epoch: 455| Step: 0
Training loss: 0.379778045878081
Validation loss: 2.4187418380539816

Epoch: 6| Step: 1
Training loss: 0.18065336041068847
Validation loss: 2.4456384037940566

Epoch: 6| Step: 2
Training loss: 0.26928853426268395
Validation loss: 2.412383254814648

Epoch: 6| Step: 3
Training loss: 0.1910088754409272
Validation loss: 2.397288578598638

Epoch: 6| Step: 4
Training loss: 0.15789147280050655
Validation loss: 2.3660714256968345

Epoch: 6| Step: 5
Training loss: 0.1489859537602087
Validation loss: 2.3523333641288846

Epoch: 6| Step: 6
Training loss: 0.21620737295132886
Validation loss: 2.3602187705547384

Epoch: 6| Step: 7
Training loss: 0.162460836633833
Validation loss: 2.3544185782062566

Epoch: 6| Step: 8
Training loss: 0.24994627554126125
Validation loss: 2.372442740458

Epoch: 6| Step: 9
Training loss: 0.22713671462952073
Validation loss: 2.383815403834458

Epoch: 6| Step: 10
Training loss: 0.21732617966079318
Validation loss: 2.3953917693438624

Epoch: 6| Step: 11
Training loss: 0.13295190170985974
Validation loss: 2.41858967041441

Epoch: 6| Step: 12
Training loss: 0.12172104651545798
Validation loss: 2.3769141203348894

Epoch: 6| Step: 13
Training loss: 0.17219585575834795
Validation loss: 2.366483180905747

Epoch: 456| Step: 0
Training loss: 0.18532821419783446
Validation loss: 2.3860894022220376

Epoch: 6| Step: 1
Training loss: 0.13028747934732693
Validation loss: 2.413906199743045

Epoch: 6| Step: 2
Training loss: 0.14584287047422373
Validation loss: 2.39884580286156

Epoch: 6| Step: 3
Training loss: 0.3629433485807699
Validation loss: 2.365096734747842

Epoch: 6| Step: 4
Training loss: 0.22287597188240252
Validation loss: 2.3703838109370947

Epoch: 6| Step: 5
Training loss: 0.2216979872086522
Validation loss: 2.3935331328563816

Epoch: 6| Step: 6
Training loss: 0.18009576855861537
Validation loss: 2.378485718246129

Epoch: 6| Step: 7
Training loss: 0.19893923954108764
Validation loss: 2.3566374298685573

Epoch: 6| Step: 8
Training loss: 0.20766452884747283
Validation loss: 2.356188658160105

Epoch: 6| Step: 9
Training loss: 0.11968568894507607
Validation loss: 2.3745180654617117

Epoch: 6| Step: 10
Training loss: 0.17284494592104263
Validation loss: 2.381884590332159

Epoch: 6| Step: 11
Training loss: 0.23492373761021274
Validation loss: 2.378619393226491

Epoch: 6| Step: 12
Training loss: 0.19349214060973
Validation loss: 2.383440520961717

Epoch: 6| Step: 13
Training loss: 0.11663348449471536
Validation loss: 2.399127080390788

Epoch: 457| Step: 0
Training loss: 0.10226571114392947
Validation loss: 2.416358910831303

Epoch: 6| Step: 1
Training loss: 0.25448451583201664
Validation loss: 2.401428827447311

Epoch: 6| Step: 2
Training loss: 0.12202930524597642
Validation loss: 2.4058818868505423

Epoch: 6| Step: 3
Training loss: 0.22319858989708102
Validation loss: 2.3923953431062746

Epoch: 6| Step: 4
Training loss: 0.22889382292829638
Validation loss: 2.3984079014755966

Epoch: 6| Step: 5
Training loss: 0.15088931297781794
Validation loss: 2.4095042245157776

Epoch: 6| Step: 6
Training loss: 0.17654447168115
Validation loss: 2.360177413052012

Epoch: 6| Step: 7
Training loss: 0.14968676395673308
Validation loss: 2.382600148874225

Epoch: 6| Step: 8
Training loss: 0.1936866995249305
Validation loss: 2.3700840487135917

Epoch: 6| Step: 9
Training loss: 0.2174267511098586
Validation loss: 2.3765628974428092

Epoch: 6| Step: 10
Training loss: 0.16340625166988754
Validation loss: 2.3749119105947063

Epoch: 6| Step: 11
Training loss: 0.1672370298050688
Validation loss: 2.3826430017202873

Epoch: 6| Step: 12
Training loss: 0.18310231523977163
Validation loss: 2.405024707290267

Epoch: 6| Step: 13
Training loss: 0.463238259647932
Validation loss: 2.427268590031203

Epoch: 458| Step: 0
Training loss: 0.13664392058387978
Validation loss: 2.4258146736328974

Epoch: 6| Step: 1
Training loss: 0.20371063795643743
Validation loss: 2.4280721671165795

Epoch: 6| Step: 2
Training loss: 0.24459173868126555
Validation loss: 2.445940804196157

Epoch: 6| Step: 3
Training loss: 0.2062771577005849
Validation loss: 2.378794038663558

Epoch: 6| Step: 4
Training loss: 0.13667160992603758
Validation loss: 2.3893596054326736

Epoch: 6| Step: 5
Training loss: 0.18815375637397144
Validation loss: 2.415321532317068

Epoch: 6| Step: 6
Training loss: 0.10917796541333297
Validation loss: 2.342171396754265

Epoch: 6| Step: 7
Training loss: 0.21274791098688586
Validation loss: 2.371831707419676

Epoch: 6| Step: 8
Training loss: 0.12697945835193725
Validation loss: 2.3739277454437593

Epoch: 6| Step: 9
Training loss: 0.25941845633231236
Validation loss: 2.3580741390147346

Epoch: 6| Step: 10
Training loss: 0.12022634524028863
Validation loss: 2.3467263408491874

Epoch: 6| Step: 11
Training loss: 0.11632508193852883
Validation loss: 2.369572186687719

Epoch: 6| Step: 12
Training loss: 0.38002513582769115
Validation loss: 2.3316372557314216

Epoch: 6| Step: 13
Training loss: 0.06415793706809782
Validation loss: 2.3578274274861406

Epoch: 459| Step: 0
Training loss: 0.16665067943745804
Validation loss: 2.3455365291133687

Epoch: 6| Step: 1
Training loss: 0.2183722913603559
Validation loss: 2.3366973460935627

Epoch: 6| Step: 2
Training loss: 0.1624108693631354
Validation loss: 2.38799695799799

Epoch: 6| Step: 3
Training loss: 0.23271466093900595
Validation loss: 2.343507953573881

Epoch: 6| Step: 4
Training loss: 0.18934884101557298
Validation loss: 2.361505120699668

Epoch: 6| Step: 5
Training loss: 0.3960138545069172
Validation loss: 2.3963811054690205

Epoch: 6| Step: 6
Training loss: 0.113621357379413
Validation loss: 2.4005256181728587

Epoch: 6| Step: 7
Training loss: 0.18483729958263143
Validation loss: 2.376520151787928

Epoch: 6| Step: 8
Training loss: 0.1699109786475228
Validation loss: 2.4301136208860843

Epoch: 6| Step: 9
Training loss: 0.11319758762350877
Validation loss: 2.4166098649163907

Epoch: 6| Step: 10
Training loss: 0.13568925854779051
Validation loss: 2.4170738500590527

Epoch: 6| Step: 11
Training loss: 0.21684252627750777
Validation loss: 2.3713868057330805

Epoch: 6| Step: 12
Training loss: 0.13024855151533385
Validation loss: 2.4048992521400665

Epoch: 6| Step: 13
Training loss: 0.25801178425945154
Validation loss: 2.3754778965698775

Epoch: 460| Step: 0
Training loss: 0.189921321640558
Validation loss: 2.3661573782659255

Epoch: 6| Step: 1
Training loss: 0.3162820360294371
Validation loss: 2.399084395892328

Epoch: 6| Step: 2
Training loss: 0.33260009506669236
Validation loss: 2.3931495654783372

Epoch: 6| Step: 3
Training loss: 0.1283453311655579
Validation loss: 2.4194671506346705

Epoch: 6| Step: 4
Training loss: 0.39775990856951227
Validation loss: 2.4358906067062516

Epoch: 6| Step: 5
Training loss: 0.20524393372335378
Validation loss: 2.426694903785265

Epoch: 6| Step: 6
Training loss: 0.16094072047039074
Validation loss: 2.380052861727663

Epoch: 6| Step: 7
Training loss: 0.15314885897530497
Validation loss: 2.4240064706821594

Epoch: 6| Step: 8
Training loss: 0.17285175646754875
Validation loss: 2.4206946146453165

Epoch: 6| Step: 9
Training loss: 0.188765832555919
Validation loss: 2.427008221593482

Epoch: 6| Step: 10
Training loss: 0.09526696368092306
Validation loss: 2.4156575081400957

Epoch: 6| Step: 11
Training loss: 0.1441953079786629
Validation loss: 2.4187530783382236

Epoch: 6| Step: 12
Training loss: 0.2324946313668891
Validation loss: 2.4007937968693045

Epoch: 6| Step: 13
Training loss: 0.2339685492027484
Validation loss: 2.420904380919675

Epoch: 461| Step: 0
Training loss: 0.19079788997731004
Validation loss: 2.371614135697033

Epoch: 6| Step: 1
Training loss: 0.13645524107605878
Validation loss: 2.3691222931189895

Epoch: 6| Step: 2
Training loss: 0.3004609421277468
Validation loss: 2.358388896652697

Epoch: 6| Step: 3
Training loss: 0.19495045484894344
Validation loss: 2.3626282794236175

Epoch: 6| Step: 4
Training loss: 0.12469575781713112
Validation loss: 2.368318976987127

Epoch: 6| Step: 5
Training loss: 0.14706230597720335
Validation loss: 2.389933669066164

Epoch: 6| Step: 6
Training loss: 0.2028638003966306
Validation loss: 2.364381029264796

Epoch: 6| Step: 7
Training loss: 0.15420309065535173
Validation loss: 2.399816200373489

Epoch: 6| Step: 8
Training loss: 0.13202786779868236
Validation loss: 2.3685200583216064

Epoch: 6| Step: 9
Training loss: 0.3362777783041219
Validation loss: 2.378573276508869

Epoch: 6| Step: 10
Training loss: 0.1792810549436575
Validation loss: 2.389382357027174

Epoch: 6| Step: 11
Training loss: 0.28733979924085623
Validation loss: 2.38090260373804

Epoch: 6| Step: 12
Training loss: 0.1788176962901797
Validation loss: 2.3875679170526123

Epoch: 6| Step: 13
Training loss: 0.12554136407764852
Validation loss: 2.388231890234273

Epoch: 462| Step: 0
Training loss: 0.1673180429230151
Validation loss: 2.4099137671583213

Epoch: 6| Step: 1
Training loss: 0.3505311779727132
Validation loss: 2.399318513884268

Epoch: 6| Step: 2
Training loss: 0.18305103764540767
Validation loss: 2.454325256733508

Epoch: 6| Step: 3
Training loss: 0.14788705634090157
Validation loss: 2.4059757406112547

Epoch: 6| Step: 4
Training loss: 0.20194235723185858
Validation loss: 2.404051609740711

Epoch: 6| Step: 5
Training loss: 0.2627981757389182
Validation loss: 2.414515192840522

Epoch: 6| Step: 6
Training loss: 0.10964916132520534
Validation loss: 2.413102272767791

Epoch: 6| Step: 7
Training loss: 0.1601803749801662
Validation loss: 2.4223075700039662

Epoch: 6| Step: 8
Training loss: 0.14959552441818239
Validation loss: 2.4383593975011997

Epoch: 6| Step: 9
Training loss: 0.11045648431195672
Validation loss: 2.444620664070569

Epoch: 6| Step: 10
Training loss: 0.11886881480887884
Validation loss: 2.4269628775239305

Epoch: 6| Step: 11
Training loss: 0.22174200786844978
Validation loss: 2.4194633308135236

Epoch: 6| Step: 12
Training loss: 0.11383269361702064
Validation loss: 2.4045296666575995

Epoch: 6| Step: 13
Training loss: 0.11947006657443966
Validation loss: 2.4012974823525957

Epoch: 463| Step: 0
Training loss: 0.3565437494508152
Validation loss: 2.396195967856222

Epoch: 6| Step: 1
Training loss: 0.19246474327132318
Validation loss: 2.364630339058022

Epoch: 6| Step: 2
Training loss: 0.10088803009103794
Validation loss: 2.3527935369262214

Epoch: 6| Step: 3
Training loss: 0.1088155034599481
Validation loss: 2.337944149742737

Epoch: 6| Step: 4
Training loss: 0.2283395431160263
Validation loss: 2.3334153526440553

Epoch: 6| Step: 5
Training loss: 0.17872579960961013
Validation loss: 2.3687844096679256

Epoch: 6| Step: 6
Training loss: 0.12129848615614895
Validation loss: 2.3425147188708553

Epoch: 6| Step: 7
Training loss: 0.17919296128991974
Validation loss: 2.3557178170609054

Epoch: 6| Step: 8
Training loss: 0.27165509077628075
Validation loss: 2.3477856801006842

Epoch: 6| Step: 9
Training loss: 0.18965190605346735
Validation loss: 2.3669335149067936

Epoch: 6| Step: 10
Training loss: 0.2356550942309024
Validation loss: 2.371233163081993

Epoch: 6| Step: 11
Training loss: 0.13671565733545207
Validation loss: 2.3764118732347517

Epoch: 6| Step: 12
Training loss: 0.1338912337061507
Validation loss: 2.378633775147919

Epoch: 6| Step: 13
Training loss: 0.1350926701716325
Validation loss: 2.382810672064688

Epoch: 464| Step: 0
Training loss: 0.1905444264147073
Validation loss: 2.395140130198259

Epoch: 6| Step: 1
Training loss: 0.19984211352098083
Validation loss: 2.370023577373684

Epoch: 6| Step: 2
Training loss: 0.27415979898299986
Validation loss: 2.4269197160529443

Epoch: 6| Step: 3
Training loss: 0.23049057840974466
Validation loss: 2.406200162842648

Epoch: 6| Step: 4
Training loss: 0.11452995397138907
Validation loss: 2.4139462395324274

Epoch: 6| Step: 5
Training loss: 0.15388226636886618
Validation loss: 2.4389377326299826

Epoch: 6| Step: 6
Training loss: 0.12880205509459539
Validation loss: 2.46743769338236

Epoch: 6| Step: 7
Training loss: 0.14469890278689893
Validation loss: 2.4499928523083496

Epoch: 6| Step: 8
Training loss: 0.10036569389668479
Validation loss: 2.4193247249739036

Epoch: 6| Step: 9
Training loss: 0.18183218176678428
Validation loss: 2.463873274386204

Epoch: 6| Step: 10
Training loss: 0.3188074387427363
Validation loss: 2.4486226570341847

Epoch: 6| Step: 11
Training loss: 0.12421818334222297
Validation loss: 2.426969686529749

Epoch: 6| Step: 12
Training loss: 0.1272407867308631
Validation loss: 2.4442248157970052

Epoch: 6| Step: 13
Training loss: 0.26218250806418836
Validation loss: 2.4503655271270017

Epoch: 465| Step: 0
Training loss: 0.12395165085477969
Validation loss: 2.442506223243202

Epoch: 6| Step: 1
Training loss: 0.2528975182773132
Validation loss: 2.4045299566561886

Epoch: 6| Step: 2
Training loss: 0.19902943984873753
Validation loss: 2.4115310162229076

Epoch: 6| Step: 3
Training loss: 0.17710710230422105
Validation loss: 2.3958661013409257

Epoch: 6| Step: 4
Training loss: 0.15451273124477852
Validation loss: 2.395925280575298

Epoch: 6| Step: 5
Training loss: 0.17876433528424573
Validation loss: 2.3917184691257

Epoch: 6| Step: 6
Training loss: 0.10016732001461806
Validation loss: 2.4303801027208958

Epoch: 6| Step: 7
Training loss: 0.1538136314899193
Validation loss: 2.3987542580855945

Epoch: 6| Step: 8
Training loss: 0.12412927271969558
Validation loss: 2.426695638006106

Epoch: 6| Step: 9
Training loss: 0.37563974726031607
Validation loss: 2.428787913764003

Epoch: 6| Step: 10
Training loss: 0.12938150304308232
Validation loss: 2.441983657253291

Epoch: 6| Step: 11
Training loss: 0.1493867836777433
Validation loss: 2.449150503054619

Epoch: 6| Step: 12
Training loss: 0.07720958724786148
Validation loss: 2.424961252625014

Epoch: 6| Step: 13
Training loss: 0.13914258745620509
Validation loss: 2.448823536123292

Epoch: 466| Step: 0
Training loss: 0.10672766308963626
Validation loss: 2.4054933777269047

Epoch: 6| Step: 1
Training loss: 0.08241861707567168
Validation loss: 2.4337652947856583

Epoch: 6| Step: 2
Training loss: 0.13243167638373837
Validation loss: 2.453916414836757

Epoch: 6| Step: 3
Training loss: 0.20573980670085235
Validation loss: 2.4423662930942127

Epoch: 6| Step: 4
Training loss: 0.16812284188144014
Validation loss: 2.4279665465979594

Epoch: 6| Step: 5
Training loss: 0.2611451482034731
Validation loss: 2.4274355425826535

Epoch: 6| Step: 6
Training loss: 0.1994628719483907
Validation loss: 2.474371123835938

Epoch: 6| Step: 7
Training loss: 0.37706083033878246
Validation loss: 2.416929799974802

Epoch: 6| Step: 8
Training loss: 0.176174259592568
Validation loss: 2.429696800969342

Epoch: 6| Step: 9
Training loss: 0.23325355374316298
Validation loss: 2.421203737255235

Epoch: 6| Step: 10
Training loss: 0.13910515350745703
Validation loss: 2.384544333602103

Epoch: 6| Step: 11
Training loss: 0.18753379278838087
Validation loss: 2.4204864437964977

Epoch: 6| Step: 12
Training loss: 0.1374618905531161
Validation loss: 2.4645852655660763

Epoch: 6| Step: 13
Training loss: 0.21820250183628365
Validation loss: 2.4031984892429064

Epoch: 467| Step: 0
Training loss: 0.19511614466055327
Validation loss: 2.3776794208910537

Epoch: 6| Step: 1
Training loss: 0.14128309150251686
Validation loss: 2.3842585675153525

Epoch: 6| Step: 2
Training loss: 0.13517610260796128
Validation loss: 2.361856153575168

Epoch: 6| Step: 3
Training loss: 0.3507958211612389
Validation loss: 2.3569062406132173

Epoch: 6| Step: 4
Training loss: 0.19985760373077788
Validation loss: 2.3662498834916987

Epoch: 6| Step: 5
Training loss: 0.26055105397591943
Validation loss: 2.328704453548365

Epoch: 6| Step: 6
Training loss: 0.13035767018221783
Validation loss: 2.3726461530222185

Epoch: 6| Step: 7
Training loss: 0.11332661854773432
Validation loss: 2.3797489607153657

Epoch: 6| Step: 8
Training loss: 0.15848752349415882
Validation loss: 2.4094391735650333

Epoch: 6| Step: 9
Training loss: 0.16677691990215168
Validation loss: 2.364557282806338

Epoch: 6| Step: 10
Training loss: 0.2174749509867696
Validation loss: 2.3824614439893796

Epoch: 6| Step: 11
Training loss: 0.15800384639105194
Validation loss: 2.3887293199829163

Epoch: 6| Step: 12
Training loss: 0.2545832192305722
Validation loss: 2.411637796649181

Epoch: 6| Step: 13
Training loss: 0.1671660226770353
Validation loss: 2.4355160180281725

Epoch: 468| Step: 0
Training loss: 0.2124494653807279
Validation loss: 2.4119375872409345

Epoch: 6| Step: 1
Training loss: 0.1454632389999654
Validation loss: 2.4192045723658553

Epoch: 6| Step: 2
Training loss: 0.20737294124549382
Validation loss: 2.4288894328655686

Epoch: 6| Step: 3
Training loss: 0.15254242486703656
Validation loss: 2.3992009838468498

Epoch: 6| Step: 4
Training loss: 0.10256776408001225
Validation loss: 2.402847671780463

Epoch: 6| Step: 5
Training loss: 0.21874432045511702
Validation loss: 2.402425613295755

Epoch: 6| Step: 6
Training loss: 0.09918659845698423
Validation loss: 2.4123085402407662

Epoch: 6| Step: 7
Training loss: 0.15381065246173062
Validation loss: 2.3951967960506257

Epoch: 6| Step: 8
Training loss: 0.11609445071105198
Validation loss: 2.4253998773783385

Epoch: 6| Step: 9
Training loss: 0.34173549645950496
Validation loss: 2.417762720136124

Epoch: 6| Step: 10
Training loss: 0.11924606488415843
Validation loss: 2.4166130835081137

Epoch: 6| Step: 11
Training loss: 0.17128220112715212
Validation loss: 2.4071650156342903

Epoch: 6| Step: 12
Training loss: 0.18258507594146517
Validation loss: 2.411543601946284

Epoch: 6| Step: 13
Training loss: 0.24990790131006524
Validation loss: 2.414111243525573

Epoch: 469| Step: 0
Training loss: 0.13099631218915467
Validation loss: 2.3798761065705034

Epoch: 6| Step: 1
Training loss: 0.24809886357517275
Validation loss: 2.379058626100757

Epoch: 6| Step: 2
Training loss: 0.12483098479860483
Validation loss: 2.365964136083824

Epoch: 6| Step: 3
Training loss: 0.2514359392757275
Validation loss: 2.360524292126351

Epoch: 6| Step: 4
Training loss: 0.25598097961703586
Validation loss: 2.3765408300108795

Epoch: 6| Step: 5
Training loss: 0.23012925051152072
Validation loss: 2.3512612895578204

Epoch: 6| Step: 6
Training loss: 0.1507116952874793
Validation loss: 2.3501277931273434

Epoch: 6| Step: 7
Training loss: 0.3421078493441868
Validation loss: 2.3603590372114787

Epoch: 6| Step: 8
Training loss: 0.21220236824484387
Validation loss: 2.4066326709110037

Epoch: 6| Step: 9
Training loss: 0.10312296962906736
Validation loss: 2.4026372600021135

Epoch: 6| Step: 10
Training loss: 0.16531867543964768
Validation loss: 2.4403217223198257

Epoch: 6| Step: 11
Training loss: 0.15786420758751285
Validation loss: 2.4545872154473

Epoch: 6| Step: 12
Training loss: 0.2437130884808406
Validation loss: 2.426168542331917

Epoch: 6| Step: 13
Training loss: 0.17923958554998273
Validation loss: 2.478050843935691

Epoch: 470| Step: 0
Training loss: 0.203113207107948
Validation loss: 2.4721515047489304

Epoch: 6| Step: 1
Training loss: 0.10976089368920294
Validation loss: 2.4327055352875084

Epoch: 6| Step: 2
Training loss: 0.19003719081917494
Validation loss: 2.460874478493058

Epoch: 6| Step: 3
Training loss: 0.24826336221853973
Validation loss: 2.4304239537658097

Epoch: 6| Step: 4
Training loss: 0.11044449817205884
Validation loss: 2.4117857157711216

Epoch: 6| Step: 5
Training loss: 0.1872375857353205
Validation loss: 2.39992959032895

Epoch: 6| Step: 6
Training loss: 0.32800574633315666
Validation loss: 2.4222372598533455

Epoch: 6| Step: 7
Training loss: 0.2253345310614452
Validation loss: 2.36892804935477

Epoch: 6| Step: 8
Training loss: 0.12335815867572686
Validation loss: 2.3772021362138993

Epoch: 6| Step: 9
Training loss: 0.15679033549935933
Validation loss: 2.3356924279299713

Epoch: 6| Step: 10
Training loss: 0.22835857341624366
Validation loss: 2.3661190775887313

Epoch: 6| Step: 11
Training loss: 0.25302830544645644
Validation loss: 2.325262219142663

Epoch: 6| Step: 12
Training loss: 0.14132278887795263
Validation loss: 2.3381028016491814

Epoch: 6| Step: 13
Training loss: 0.16815213239754306
Validation loss: 2.3406284078090773

Epoch: 471| Step: 0
Training loss: 0.18081455664086435
Validation loss: 2.3293109325275654

Epoch: 6| Step: 1
Training loss: 0.18939504027949786
Validation loss: 2.3146826142282766

Epoch: 6| Step: 2
Training loss: 0.2890669590374115
Validation loss: 2.3241996148730584

Epoch: 6| Step: 3
Training loss: 0.13767286888805472
Validation loss: 2.3181551469531243

Epoch: 6| Step: 4
Training loss: 0.12391445673309909
Validation loss: 2.3406588716949184

Epoch: 6| Step: 5
Training loss: 0.18469510577527395
Validation loss: 2.3313899755359935

Epoch: 6| Step: 6
Training loss: 0.1676089402967776
Validation loss: 2.321770042955814

Epoch: 6| Step: 7
Training loss: 0.29656716750062545
Validation loss: 2.3466487118424735

Epoch: 6| Step: 8
Training loss: 0.10811024666473522
Validation loss: 2.332344024169738

Epoch: 6| Step: 9
Training loss: 0.2566676440597065
Validation loss: 2.338104830651043

Epoch: 6| Step: 10
Training loss: 0.10818955770190722
Validation loss: 2.3527183517009553

Epoch: 6| Step: 11
Training loss: 0.15755589273014198
Validation loss: 2.366797001124177

Epoch: 6| Step: 12
Training loss: 0.21554140045967626
Validation loss: 2.3535229591197826

Epoch: 6| Step: 13
Training loss: 0.1675065078734363
Validation loss: 2.355154835392272

Epoch: 472| Step: 0
Training loss: 0.17096312252399076
Validation loss: 2.37105312766383

Epoch: 6| Step: 1
Training loss: 0.19972469559499587
Validation loss: 2.3684585653053376

Epoch: 6| Step: 2
Training loss: 0.16597451093612856
Validation loss: 2.4081440739639444

Epoch: 6| Step: 3
Training loss: 0.06485877839551303
Validation loss: 2.3965852578479168

Epoch: 6| Step: 4
Training loss: 0.15460435193168143
Validation loss: 2.4066665559469307

Epoch: 6| Step: 5
Training loss: 0.13347838869707143
Validation loss: 2.411127887513915

Epoch: 6| Step: 6
Training loss: 0.2811900445823399
Validation loss: 2.366836212592601

Epoch: 6| Step: 7
Training loss: 0.13979755789522935
Validation loss: 2.400491388538715

Epoch: 6| Step: 8
Training loss: 0.2521523272201765
Validation loss: 2.3965974513908614

Epoch: 6| Step: 9
Training loss: 0.10329366224875756
Validation loss: 2.3927445441491506

Epoch: 6| Step: 10
Training loss: 0.24522461379871802
Validation loss: 2.4103131976009435

Epoch: 6| Step: 11
Training loss: 0.15735903780252122
Validation loss: 2.3745671348980215

Epoch: 6| Step: 12
Training loss: 0.0950216975264103
Validation loss: 2.361165573409676

Epoch: 6| Step: 13
Training loss: 0.11918723257856968
Validation loss: 2.341658223051945

Epoch: 473| Step: 0
Training loss: 0.09657092671831276
Validation loss: 2.380737802282169

Epoch: 6| Step: 1
Training loss: 0.13197143091183655
Validation loss: 2.3342110219900634

Epoch: 6| Step: 2
Training loss: 0.11810667047130533
Validation loss: 2.3638354371778423

Epoch: 6| Step: 3
Training loss: 0.13337462339732406
Validation loss: 2.3622824336972768

Epoch: 6| Step: 4
Training loss: 0.15209434953292775
Validation loss: 2.3706374279950126

Epoch: 6| Step: 5
Training loss: 0.16422655214092166
Validation loss: 2.342576799896059

Epoch: 6| Step: 6
Training loss: 0.30294916470332695
Validation loss: 2.3493535021116774

Epoch: 6| Step: 7
Training loss: 0.20060262415639496
Validation loss: 2.3660050950059683

Epoch: 6| Step: 8
Training loss: 0.17268314885633496
Validation loss: 2.318409497032084

Epoch: 6| Step: 9
Training loss: 0.2553651127014545
Validation loss: 2.3840797490635652

Epoch: 6| Step: 10
Training loss: 0.18515424848030013
Validation loss: 2.336250477639368

Epoch: 6| Step: 11
Training loss: 0.18786901678873957
Validation loss: 2.3748927472675128

Epoch: 6| Step: 12
Training loss: 0.15963765827822574
Validation loss: 2.3698937359049737

Epoch: 6| Step: 13
Training loss: 0.21428129959384032
Validation loss: 2.4060029498453264

Epoch: 474| Step: 0
Training loss: 0.12281345373734608
Validation loss: 2.4254634274393827

Epoch: 6| Step: 1
Training loss: 0.17608946693478425
Validation loss: 2.423148124848744

Epoch: 6| Step: 2
Training loss: 0.16696046784515034
Validation loss: 2.4092376331039262

Epoch: 6| Step: 3
Training loss: 0.1407770553370404
Validation loss: 2.4063331718544263

Epoch: 6| Step: 4
Training loss: 0.14446334919250403
Validation loss: 2.426268003907857

Epoch: 6| Step: 5
Training loss: 0.19385558335553402
Validation loss: 2.41010650159545

Epoch: 6| Step: 6
Training loss: 0.27966934656655895
Validation loss: 2.3886647539796755

Epoch: 6| Step: 7
Training loss: 0.18693471174670045
Validation loss: 2.397666904895166

Epoch: 6| Step: 8
Training loss: 0.2002374465147176
Validation loss: 2.3937245858569036

Epoch: 6| Step: 9
Training loss: 0.12008834120327842
Validation loss: 2.382197972210566

Epoch: 6| Step: 10
Training loss: 0.23286173575092264
Validation loss: 2.3807239671800597

Epoch: 6| Step: 11
Training loss: 0.19436366396226779
Validation loss: 2.3631057878874038

Epoch: 6| Step: 12
Training loss: 0.18940267186009868
Validation loss: 2.371479529655299

Epoch: 6| Step: 13
Training loss: 0.21585675617994463
Validation loss: 2.4057710482817107

Epoch: 475| Step: 0
Training loss: 0.18374357805902217
Validation loss: 2.374065524045108

Epoch: 6| Step: 1
Training loss: 0.2034177412964881
Validation loss: 2.3816213486021987

Epoch: 6| Step: 2
Training loss: 0.10250595103119603
Validation loss: 2.384592902147575

Epoch: 6| Step: 3
Training loss: 0.31894370438964004
Validation loss: 2.3517276780990506

Epoch: 6| Step: 4
Training loss: 0.08725565316336525
Validation loss: 2.362451934325499

Epoch: 6| Step: 5
Training loss: 0.24663028811379362
Validation loss: 2.3867104303296784

Epoch: 6| Step: 6
Training loss: 0.14243522432910527
Validation loss: 2.3854592801282277

Epoch: 6| Step: 7
Training loss: 0.14518245702714155
Validation loss: 2.3743993952866673

Epoch: 6| Step: 8
Training loss: 0.17990559320825247
Validation loss: 2.388551593985622

Epoch: 6| Step: 9
Training loss: 0.17024118741581862
Validation loss: 2.368909895474388

Epoch: 6| Step: 10
Training loss: 0.0962371523754096
Validation loss: 2.3760457270635578

Epoch: 6| Step: 11
Training loss: 0.11745151343692052
Validation loss: 2.3714817776562236

Epoch: 6| Step: 12
Training loss: 0.16505155572498947
Validation loss: 2.3480577560800127

Epoch: 6| Step: 13
Training loss: 0.0819539631336145
Validation loss: 2.3922261358682584

Epoch: 476| Step: 0
Training loss: 0.0632379153895718
Validation loss: 2.376255933870025

Epoch: 6| Step: 1
Training loss: 0.1470772127353992
Validation loss: 2.359929545035475

Epoch: 6| Step: 2
Training loss: 0.1059363516390852
Validation loss: 2.3869865182284267

Epoch: 6| Step: 3
Training loss: 0.27847909246379837
Validation loss: 2.385956811389241

Epoch: 6| Step: 4
Training loss: 0.13421310275257697
Validation loss: 2.3987291591688216

Epoch: 6| Step: 5
Training loss: 0.13654538470719896
Validation loss: 2.422149126653181

Epoch: 6| Step: 6
Training loss: 0.21978286021941928
Validation loss: 2.423868407561661

Epoch: 6| Step: 7
Training loss: 0.20911742814545026
Validation loss: 2.389622408822782

Epoch: 6| Step: 8
Training loss: 0.1676183805598816
Validation loss: 2.3782270158164796

Epoch: 6| Step: 9
Training loss: 0.09236775087967021
Validation loss: 2.39760864703685

Epoch: 6| Step: 10
Training loss: 0.13402294682518828
Validation loss: 2.364416137034543

Epoch: 6| Step: 11
Training loss: 0.15105641364311634
Validation loss: 2.4244313879971027

Epoch: 6| Step: 12
Training loss: 0.22788865734267003
Validation loss: 2.406312388482416

Epoch: 6| Step: 13
Training loss: 0.10108444143742361
Validation loss: 2.3967637572503433

Epoch: 477| Step: 0
Training loss: 0.13895793074611965
Validation loss: 2.3712703259785126

Epoch: 6| Step: 1
Training loss: 0.15850064476187398
Validation loss: 2.376944822379359

Epoch: 6| Step: 2
Training loss: 0.19253162495818527
Validation loss: 2.3672648902907247

Epoch: 6| Step: 3
Training loss: 0.10625878010262911
Validation loss: 2.357260158451263

Epoch: 6| Step: 4
Training loss: 0.21595167244638727
Validation loss: 2.3590096941509766

Epoch: 6| Step: 5
Training loss: 0.09196518625256302
Validation loss: 2.369844905052873

Epoch: 6| Step: 6
Training loss: 0.25781985474701874
Validation loss: 2.341804647586299

Epoch: 6| Step: 7
Training loss: 0.22974212509446557
Validation loss: 2.3587228185623483

Epoch: 6| Step: 8
Training loss: 0.13454185096274843
Validation loss: 2.3159469594340827

Epoch: 6| Step: 9
Training loss: 0.20080904044701336
Validation loss: 2.315190472623952

Epoch: 6| Step: 10
Training loss: 0.11346674398993427
Validation loss: 2.3461275801992083

Epoch: 6| Step: 11
Training loss: 0.09076950744150546
Validation loss: 2.3528635436895744

Epoch: 6| Step: 12
Training loss: 0.12152112254773721
Validation loss: 2.336435225800881

Epoch: 6| Step: 13
Training loss: 0.09119775746300943
Validation loss: 2.367031641763274

Epoch: 478| Step: 0
Training loss: 0.0949485870734545
Validation loss: 2.3885380821304345

Epoch: 6| Step: 1
Training loss: 0.14537536430313241
Validation loss: 2.3580161385710565

Epoch: 6| Step: 2
Training loss: 0.18476471930961336
Validation loss: 2.3470050191828706

Epoch: 6| Step: 3
Training loss: 0.09386490197957181
Validation loss: 2.3956086166166326

Epoch: 6| Step: 4
Training loss: 0.16449112192686147
Validation loss: 2.4030824792842647

Epoch: 6| Step: 5
Training loss: 0.15778561825824272
Validation loss: 2.4056401272938337

Epoch: 6| Step: 6
Training loss: 0.1320423065160815
Validation loss: 2.373568819835171

Epoch: 6| Step: 7
Training loss: 0.22352462550431515
Validation loss: 2.360983061188479

Epoch: 6| Step: 8
Training loss: 0.13447388570163932
Validation loss: 2.3970361359185013

Epoch: 6| Step: 9
Training loss: 0.20197722883280203
Validation loss: 2.3828028320460652

Epoch: 6| Step: 10
Training loss: 0.11655830910131212
Validation loss: 2.337457494660184

Epoch: 6| Step: 11
Training loss: 0.12966408633099566
Validation loss: 2.3775092633675943

Epoch: 6| Step: 12
Training loss: 0.3068355621005359
Validation loss: 2.3650292157797574

Epoch: 6| Step: 13
Training loss: 0.11622345079642675
Validation loss: 2.3520656913068736

Epoch: 479| Step: 0
Training loss: 0.17281700047363466
Validation loss: 2.348280491255754

Epoch: 6| Step: 1
Training loss: 0.15600782939401317
Validation loss: 2.365291782511405

Epoch: 6| Step: 2
Training loss: 0.15273659745962856
Validation loss: 2.376805235215648

Epoch: 6| Step: 3
Training loss: 0.25633145235710464
Validation loss: 2.353268676323239

Epoch: 6| Step: 4
Training loss: 0.14062641725885622
Validation loss: 2.3632944463139216

Epoch: 6| Step: 5
Training loss: 0.09056680430377673
Validation loss: 2.388420679577748

Epoch: 6| Step: 6
Training loss: 0.11473063506839434
Validation loss: 2.384155154450759

Epoch: 6| Step: 7
Training loss: 0.109281857885645
Validation loss: 2.373936513798962

Epoch: 6| Step: 8
Training loss: 0.17279035486706554
Validation loss: 2.3878288476805185

Epoch: 6| Step: 9
Training loss: 0.12705520047500188
Validation loss: 2.3921299829233744

Epoch: 6| Step: 10
Training loss: 0.2189843251081635
Validation loss: 2.394718748389155

Epoch: 6| Step: 11
Training loss: 0.2912584098534953
Validation loss: 2.4088229063888615

Epoch: 6| Step: 12
Training loss: 0.1551039628573433
Validation loss: 2.4072845423380684

Epoch: 6| Step: 13
Training loss: 0.1355372123132432
Validation loss: 2.421801151998213

Epoch: 480| Step: 0
Training loss: 0.10440956842446186
Validation loss: 2.395716470558509

Epoch: 6| Step: 1
Training loss: 0.12695073345572674
Validation loss: 2.41726343009519

Epoch: 6| Step: 2
Training loss: 0.10343297321809539
Validation loss: 2.379390987028123

Epoch: 6| Step: 3
Training loss: 0.1320428707719533
Validation loss: 2.4206305221088322

Epoch: 6| Step: 4
Training loss: 0.2059626260633315
Validation loss: 2.4203527900619926

Epoch: 6| Step: 5
Training loss: 0.21521521446666228
Validation loss: 2.4313947429171554

Epoch: 6| Step: 6
Training loss: 0.2016500881535862
Validation loss: 2.4127650146022632

Epoch: 6| Step: 7
Training loss: 0.05375374691886011
Validation loss: 2.389521431564799

Epoch: 6| Step: 8
Training loss: 0.1287777433549737
Validation loss: 2.407873276557164

Epoch: 6| Step: 9
Training loss: 0.11339033153049675
Validation loss: 2.372494252759601

Epoch: 6| Step: 10
Training loss: 0.125869609468741
Validation loss: 2.374721603613639

Epoch: 6| Step: 11
Training loss: 0.29909884587718555
Validation loss: 2.3863710037626986

Epoch: 6| Step: 12
Training loss: 0.11479082250313546
Validation loss: 2.3587193405546665

Epoch: 6| Step: 13
Training loss: 0.14110192249873768
Validation loss: 2.345859505264353

Epoch: 481| Step: 0
Training loss: 0.1559306039317379
Validation loss: 2.398037306993989

Epoch: 6| Step: 1
Training loss: 0.08905226958227067
Validation loss: 2.3406483680845223

Epoch: 6| Step: 2
Training loss: 0.15595267139854618
Validation loss: 2.330924294276464

Epoch: 6| Step: 3
Training loss: 0.2979947605792548
Validation loss: 2.318810662589231

Epoch: 6| Step: 4
Training loss: 0.14100663402140368
Validation loss: 2.3361736807475824

Epoch: 6| Step: 5
Training loss: 0.21252965509831193
Validation loss: 2.3387804643712418

Epoch: 6| Step: 6
Training loss: 0.1209370999613018
Validation loss: 2.3208030827584527

Epoch: 6| Step: 7
Training loss: 0.20080861376419218
Validation loss: 2.3343589267648763

Epoch: 6| Step: 8
Training loss: 0.15553381219807172
Validation loss: 2.3339177211422975

Epoch: 6| Step: 9
Training loss: 0.10566060841497567
Validation loss: 2.336843262522163

Epoch: 6| Step: 10
Training loss: 0.13574332641562872
Validation loss: 2.3394668656036175

Epoch: 6| Step: 11
Training loss: 0.13487615061243527
Validation loss: 2.3464842698534314

Epoch: 6| Step: 12
Training loss: 0.18885503333352793
Validation loss: 2.355053635394828

Epoch: 6| Step: 13
Training loss: 0.06576509763298206
Validation loss: 2.3661726918624857

Epoch: 482| Step: 0
Training loss: 0.13821218080324207
Validation loss: 2.3808093412270233

Epoch: 6| Step: 1
Training loss: 0.19164135176609853
Validation loss: 2.377343557016067

Epoch: 6| Step: 2
Training loss: 0.14368348604198286
Validation loss: 2.374705828035995

Epoch: 6| Step: 3
Training loss: 0.15024415847733583
Validation loss: 2.3904209187921546

Epoch: 6| Step: 4
Training loss: 0.10199883156287173
Validation loss: 2.3646935155438564

Epoch: 6| Step: 5
Training loss: 0.08583060031462486
Validation loss: 2.3552965231043337

Epoch: 6| Step: 6
Training loss: 0.22142739580623513
Validation loss: 2.372323754663009

Epoch: 6| Step: 7
Training loss: 0.14161034260856667
Validation loss: 2.367529713132501

Epoch: 6| Step: 8
Training loss: 0.1115027196316198
Validation loss: 2.372221743871247

Epoch: 6| Step: 9
Training loss: 0.20430634004392
Validation loss: 2.3417174092248763

Epoch: 6| Step: 10
Training loss: 0.13694112948226392
Validation loss: 2.378653627747313

Epoch: 6| Step: 11
Training loss: 0.12028202516227215
Validation loss: 2.373526303244557

Epoch: 6| Step: 12
Training loss: 0.2650119635517569
Validation loss: 2.3486556366149203

Epoch: 6| Step: 13
Training loss: 0.23366056271397204
Validation loss: 2.360946391675753

Epoch: 483| Step: 0
Training loss: 0.22827694320271494
Validation loss: 2.3482733247163674

Epoch: 6| Step: 1
Training loss: 0.23575786484719227
Validation loss: 2.374892203211353

Epoch: 6| Step: 2
Training loss: 0.11665615180931384
Validation loss: 2.3765169511725737

Epoch: 6| Step: 3
Training loss: 0.16734469724257053
Validation loss: 2.3715173173001682

Epoch: 6| Step: 4
Training loss: 0.09246762215673263
Validation loss: 2.3639903810191685

Epoch: 6| Step: 5
Training loss: 0.11602982665328578
Validation loss: 2.3847115214150816

Epoch: 6| Step: 6
Training loss: 0.1510640708705932
Validation loss: 2.399066951076461

Epoch: 6| Step: 7
Training loss: 0.10017066711949475
Validation loss: 2.3954027178593003

Epoch: 6| Step: 8
Training loss: 0.1365628238888005
Validation loss: 2.3785608256609487

Epoch: 6| Step: 9
Training loss: 0.13407701287043414
Validation loss: 2.3729382591587167

Epoch: 6| Step: 10
Training loss: 0.1110395824855266
Validation loss: 2.3801378462413307

Epoch: 6| Step: 11
Training loss: 0.16391698878467847
Validation loss: 2.3882807938372976

Epoch: 6| Step: 12
Training loss: 0.14393059177774103
Validation loss: 2.392380994084498

Epoch: 6| Step: 13
Training loss: 0.3419698223162389
Validation loss: 2.394119060469038

Epoch: 484| Step: 0
Training loss: 0.13536238193617778
Validation loss: 2.3565085310938043

Epoch: 6| Step: 1
Training loss: 0.10655052777126742
Validation loss: 2.4249986197143456

Epoch: 6| Step: 2
Training loss: 0.20457400167306228
Validation loss: 2.401961010032886

Epoch: 6| Step: 3
Training loss: 0.12302431020768118
Validation loss: 2.36906832897738

Epoch: 6| Step: 4
Training loss: 0.15516953620803658
Validation loss: 2.36568400229939

Epoch: 6| Step: 5
Training loss: 0.2522220654771288
Validation loss: 2.364567610823146

Epoch: 6| Step: 6
Training loss: 0.11179701457891275
Validation loss: 2.3788042208081626

Epoch: 6| Step: 7
Training loss: 0.19073708983075416
Validation loss: 2.3444142975976776

Epoch: 6| Step: 8
Training loss: 0.1463076479097897
Validation loss: 2.4083604617428396

Epoch: 6| Step: 9
Training loss: 0.1574230506417649
Validation loss: 2.373222867083547

Epoch: 6| Step: 10
Training loss: 0.07470673517405363
Validation loss: 2.3628206606111006

Epoch: 6| Step: 11
Training loss: 0.08196851624911068
Validation loss: 2.356830236438339

Epoch: 6| Step: 12
Training loss: 0.24977387692372047
Validation loss: 2.397826788500918

Epoch: 6| Step: 13
Training loss: 0.09024856938769708
Validation loss: 2.3608899961426975

Epoch: 485| Step: 0
Training loss: 0.1299225667475156
Validation loss: 2.398369109977855

Epoch: 6| Step: 1
Training loss: 0.23413992855259924
Validation loss: 2.3920469774106157

Epoch: 6| Step: 2
Training loss: 0.21227658813155637
Validation loss: 2.388132978621814

Epoch: 6| Step: 3
Training loss: 0.10346114776441326
Validation loss: 2.353284672954446

Epoch: 6| Step: 4
Training loss: 0.24652008940493852
Validation loss: 2.4043390607173047

Epoch: 6| Step: 5
Training loss: 0.08282303720588693
Validation loss: 2.404299229333115

Epoch: 6| Step: 6
Training loss: 0.12727939787607548
Validation loss: 2.3913469784005073

Epoch: 6| Step: 7
Training loss: 0.1397796361349484
Validation loss: 2.3841135019387836

Epoch: 6| Step: 8
Training loss: 0.1188452843434875
Validation loss: 2.362520852436112

Epoch: 6| Step: 9
Training loss: 0.2821083349199753
Validation loss: 2.365884666102551

Epoch: 6| Step: 10
Training loss: 0.13484050218598265
Validation loss: 2.36985945867759

Epoch: 6| Step: 11
Training loss: 0.2258364124956222
Validation loss: 2.3803550858255162

Epoch: 6| Step: 12
Training loss: 0.12486211428610862
Validation loss: 2.3972014253294143

Epoch: 6| Step: 13
Training loss: 0.06307845351762247
Validation loss: 2.3844915791239125

Epoch: 486| Step: 0
Training loss: 0.10133115848450541
Validation loss: 2.4064151657689337

Epoch: 6| Step: 1
Training loss: 0.205829605903415
Validation loss: 2.4156390453296916

Epoch: 6| Step: 2
Training loss: 0.1039838637261321
Validation loss: 2.366446783494959

Epoch: 6| Step: 3
Training loss: 0.27487885830501535
Validation loss: 2.410302329046217

Epoch: 6| Step: 4
Training loss: 0.11308558600705457
Validation loss: 2.410515409618494

Epoch: 6| Step: 5
Training loss: 0.19471108347322463
Validation loss: 2.4096906919056598

Epoch: 6| Step: 6
Training loss: 0.11190454266121103
Validation loss: 2.3995729392033236

Epoch: 6| Step: 7
Training loss: 0.17290451833456622
Validation loss: 2.3951456419643957

Epoch: 6| Step: 8
Training loss: 0.08195993184276375
Validation loss: 2.3718704433057733

Epoch: 6| Step: 9
Training loss: 0.1517894270086214
Validation loss: 2.3931452127531943

Epoch: 6| Step: 10
Training loss: 0.15030914427804332
Validation loss: 2.3979529501633663

Epoch: 6| Step: 11
Training loss: 0.13924510437708107
Validation loss: 2.39930943867279

Epoch: 6| Step: 12
Training loss: 0.09679670669442508
Validation loss: 2.366329956569019

Epoch: 6| Step: 13
Training loss: 0.18577365067245694
Validation loss: 2.3708656543119053

Epoch: 487| Step: 0
Training loss: 0.2715469946786099
Validation loss: 2.35804012648121

Epoch: 6| Step: 1
Training loss: 0.16137712625791464
Validation loss: 2.351506012421502

Epoch: 6| Step: 2
Training loss: 0.13048519185107116
Validation loss: 2.3346749204990314

Epoch: 6| Step: 3
Training loss: 0.13523566470751522
Validation loss: 2.34803240731431

Epoch: 6| Step: 4
Training loss: 0.09042554087843585
Validation loss: 2.367619240118805

Epoch: 6| Step: 5
Training loss: 0.15121948665416607
Validation loss: 2.3165251586477416

Epoch: 6| Step: 6
Training loss: 0.08842922590694544
Validation loss: 2.3378915307595474

Epoch: 6| Step: 7
Training loss: 0.09370748231281449
Validation loss: 2.31647548721817

Epoch: 6| Step: 8
Training loss: 0.18671434429190245
Validation loss: 2.369849247296562

Epoch: 6| Step: 9
Training loss: 0.13398121866228588
Validation loss: 2.3799990358249024

Epoch: 6| Step: 10
Training loss: 0.21041170569196113
Validation loss: 2.3640916392720888

Epoch: 6| Step: 11
Training loss: 0.16667385321759456
Validation loss: 2.373902157255352

Epoch: 6| Step: 12
Training loss: 0.08316377965378223
Validation loss: 2.3618009325244804

Epoch: 6| Step: 13
Training loss: 0.09896865642393823
Validation loss: 2.3710270202743073

Epoch: 488| Step: 0
Training loss: 0.13475061415955214
Validation loss: 2.3592478802032795

Epoch: 6| Step: 1
Training loss: 0.17237307166804508
Validation loss: 2.3864139983771504

Epoch: 6| Step: 2
Training loss: 0.15375786807699493
Validation loss: 2.3936501705927147

Epoch: 6| Step: 3
Training loss: 0.1232552844855372
Validation loss: 2.4044847303139143

Epoch: 6| Step: 4
Training loss: 0.10476866358561332
Validation loss: 2.391120108178097

Epoch: 6| Step: 5
Training loss: 0.13123834592305145
Validation loss: 2.388969573683606

Epoch: 6| Step: 6
Training loss: 0.13102427099789715
Validation loss: 2.3836139645683945

Epoch: 6| Step: 7
Training loss: 0.1975395547967426
Validation loss: 2.37599360822769

Epoch: 6| Step: 8
Training loss: 0.09379876378547174
Validation loss: 2.371665643295983

Epoch: 6| Step: 9
Training loss: 0.10618415345385208
Validation loss: 2.407097832107473

Epoch: 6| Step: 10
Training loss: 0.10239068149161676
Validation loss: 2.4075126707060304

Epoch: 6| Step: 11
Training loss: 0.27540975193128997
Validation loss: 2.417548694053382

Epoch: 6| Step: 12
Training loss: 0.12162262648656078
Validation loss: 2.429060006454702

Epoch: 6| Step: 13
Training loss: 0.26915656874427535
Validation loss: 2.40243547546089

Epoch: 489| Step: 0
Training loss: 0.21387081926998505
Validation loss: 2.4078461885402973

Epoch: 6| Step: 1
Training loss: 0.2586830209803739
Validation loss: 2.3940219517864594

Epoch: 6| Step: 2
Training loss: 0.14959038198045266
Validation loss: 2.383380617613082

Epoch: 6| Step: 3
Training loss: 0.2548118434043286
Validation loss: 2.3538148985449308

Epoch: 6| Step: 4
Training loss: 0.11597228990896741
Validation loss: 2.350296528447639

Epoch: 6| Step: 5
Training loss: 0.12742907000353426
Validation loss: 2.3643204058261507

Epoch: 6| Step: 6
Training loss: 0.0956765741380748
Validation loss: 2.3480155582094553

Epoch: 6| Step: 7
Training loss: 0.11089874164745174
Validation loss: 2.3421200004347096

Epoch: 6| Step: 8
Training loss: 0.09711124451357604
Validation loss: 2.3522549529097203

Epoch: 6| Step: 9
Training loss: 0.0941093333461314
Validation loss: 2.3655927494004194

Epoch: 6| Step: 10
Training loss: 0.21319071591372063
Validation loss: 2.3591074621740127

Epoch: 6| Step: 11
Training loss: 0.08974144646501449
Validation loss: 2.385622847364699

Epoch: 6| Step: 12
Training loss: 0.08276820100077827
Validation loss: 2.3685826109879806

Epoch: 6| Step: 13
Training loss: 0.12814817626029743
Validation loss: 2.3642544369717675

Epoch: 490| Step: 0
Training loss: 0.23264519997635186
Validation loss: 2.380555861250786

Epoch: 6| Step: 1
Training loss: 0.21102273066850252
Validation loss: 2.3702170834755316

Epoch: 6| Step: 2
Training loss: 0.07261636072276055
Validation loss: 2.38409965524218

Epoch: 6| Step: 3
Training loss: 0.14427197888558754
Validation loss: 2.381901541041219

Epoch: 6| Step: 4
Training loss: 0.13565432497375343
Validation loss: 2.4152402536623847

Epoch: 6| Step: 5
Training loss: 0.27189292629380146
Validation loss: 2.38572355872787

Epoch: 6| Step: 6
Training loss: 0.18210761224457336
Validation loss: 2.3963940168107967

Epoch: 6| Step: 7
Training loss: 0.2294362101361443
Validation loss: 2.36407511933807

Epoch: 6| Step: 8
Training loss: 0.21207248022630182
Validation loss: 2.3650438638057962

Epoch: 6| Step: 9
Training loss: 0.08798486901969192
Validation loss: 2.409157744315533

Epoch: 6| Step: 10
Training loss: 0.17171810314900102
Validation loss: 2.371715605138646

Epoch: 6| Step: 11
Training loss: 0.12465911069988622
Validation loss: 2.3580570137627084

Epoch: 6| Step: 12
Training loss: 0.1105074414529838
Validation loss: 2.326757079400838

Epoch: 6| Step: 13
Training loss: 0.11256938920286735
Validation loss: 2.3422070352665263

Epoch: 491| Step: 0
Training loss: 0.20304624241095207
Validation loss: 2.3979645816265927

Epoch: 6| Step: 1
Training loss: 0.15013773822897328
Validation loss: 2.3443136761095476

Epoch: 6| Step: 2
Training loss: 0.20031866599723266
Validation loss: 2.326174661070847

Epoch: 6| Step: 3
Training loss: 0.10840255282726458
Validation loss: 2.3405221693800757

Epoch: 6| Step: 4
Training loss: 0.15444109007777962
Validation loss: 2.3620707907060683

Epoch: 6| Step: 5
Training loss: 0.12560621427167357
Validation loss: 2.3765386153816963

Epoch: 6| Step: 6
Training loss: 0.2022405036953138
Validation loss: 2.423043804783022

Epoch: 6| Step: 7
Training loss: 0.29305974183073097
Validation loss: 2.3935419788040697

Epoch: 6| Step: 8
Training loss: 0.1414895305083929
Validation loss: 2.3819046375543147

Epoch: 6| Step: 9
Training loss: 0.159629379648888
Validation loss: 2.352277008406831

Epoch: 6| Step: 10
Training loss: 0.30053705979322803
Validation loss: 2.3667126521845745

Epoch: 6| Step: 11
Training loss: 0.16574078417455212
Validation loss: 2.3806251022240676

Epoch: 6| Step: 12
Training loss: 0.19050884068993598
Validation loss: 2.4002801277681143

Epoch: 6| Step: 13
Training loss: 0.16657983609172225
Validation loss: 2.3748994232798273

Epoch: 492| Step: 0
Training loss: 0.17470448568332989
Validation loss: 2.4092700109532608

Epoch: 6| Step: 1
Training loss: 0.13290969013297746
Validation loss: 2.4081493946845276

Epoch: 6| Step: 2
Training loss: 0.1254026811216908
Validation loss: 2.400434081390107

Epoch: 6| Step: 3
Training loss: 0.12513426186317092
Validation loss: 2.4265241264341886

Epoch: 6| Step: 4
Training loss: 0.1459513949859448
Validation loss: 2.42174947666747

Epoch: 6| Step: 5
Training loss: 0.27657249831321895
Validation loss: 2.3874998287971194

Epoch: 6| Step: 6
Training loss: 0.21517365009200878
Validation loss: 2.386370522483334

Epoch: 6| Step: 7
Training loss: 0.16117582036199082
Validation loss: 2.391195639988325

Epoch: 6| Step: 8
Training loss: 0.08739285177762816
Validation loss: 2.3679833617734465

Epoch: 6| Step: 9
Training loss: 0.17622485347520644
Validation loss: 2.3880026038050834

Epoch: 6| Step: 10
Training loss: 0.3063115583559829
Validation loss: 2.3666040408202265

Epoch: 6| Step: 11
Training loss: 0.1464764465729543
Validation loss: 2.4037451937466825

Epoch: 6| Step: 12
Training loss: 0.0969301409070862
Validation loss: 2.381689364876685

Epoch: 6| Step: 13
Training loss: 0.2554482221376141
Validation loss: 2.3873480263689153

Epoch: 493| Step: 0
Training loss: 0.11002974297055644
Validation loss: 2.4238236319604973

Epoch: 6| Step: 1
Training loss: 0.08358204472222532
Validation loss: 2.412595171344696

Epoch: 6| Step: 2
Training loss: 0.17597446419230162
Validation loss: 2.3956815734850467

Epoch: 6| Step: 3
Training loss: 0.24000127850380745
Validation loss: 2.3893045103769

Epoch: 6| Step: 4
Training loss: 0.192887056873147
Validation loss: 2.4000023699136883

Epoch: 6| Step: 5
Training loss: 0.10978382204117466
Validation loss: 2.3844303474813233

Epoch: 6| Step: 6
Training loss: 0.1621050661732344
Validation loss: 2.3962777908335298

Epoch: 6| Step: 7
Training loss: 0.29828899343519827
Validation loss: 2.397516462101075

Epoch: 6| Step: 8
Training loss: 0.1447719682929052
Validation loss: 2.4309403412491633

Epoch: 6| Step: 9
Training loss: 0.15233948285900256
Validation loss: 2.3902842647269846

Epoch: 6| Step: 10
Training loss: 0.16031130983606143
Validation loss: 2.3796737733740136

Epoch: 6| Step: 11
Training loss: 0.19885555520296433
Validation loss: 2.4178430143301686

Epoch: 6| Step: 12
Training loss: 0.22179602204602555
Validation loss: 2.392663125358801

Epoch: 6| Step: 13
Training loss: 0.11952142363405777
Validation loss: 2.400449534627945

Epoch: 494| Step: 0
Training loss: 0.140795829115431
Validation loss: 2.433672408959671

Epoch: 6| Step: 1
Training loss: 0.26413847998284334
Validation loss: 2.4220828313500586

Epoch: 6| Step: 2
Training loss: 0.22590707651921915
Validation loss: 2.3606648914018775

Epoch: 6| Step: 3
Training loss: 0.23985261745400424
Validation loss: 2.404739880870361

Epoch: 6| Step: 4
Training loss: 0.14416746158486357
Validation loss: 2.414630079133223

Epoch: 6| Step: 5
Training loss: 0.3632227532655927
Validation loss: 2.337335525770599

Epoch: 6| Step: 6
Training loss: 0.14120128223972347
Validation loss: 2.3627948637093272

Epoch: 6| Step: 7
Training loss: 0.15477464441652325
Validation loss: 2.349251215211874

Epoch: 6| Step: 8
Training loss: 0.31053851374280383
Validation loss: 2.3676070889888643

Epoch: 6| Step: 9
Training loss: 0.19113049787768369
Validation loss: 2.34861749587728

Epoch: 6| Step: 10
Training loss: 0.12331055590193832
Validation loss: 2.374102998951141

Epoch: 6| Step: 11
Training loss: 0.1569129529101356
Validation loss: 2.3942911742730306

Epoch: 6| Step: 12
Training loss: 0.16174554211289852
Validation loss: 2.406058979482849

Epoch: 6| Step: 13
Training loss: 0.2221260702008649
Validation loss: 2.399264926525937

Epoch: 495| Step: 0
Training loss: 0.1760669505755586
Validation loss: 2.4552853353649264

Epoch: 6| Step: 1
Training loss: 0.1409286558417049
Validation loss: 2.473043428858155

Epoch: 6| Step: 2
Training loss: 0.10902282094832362
Validation loss: 2.4820700445073536

Epoch: 6| Step: 3
Training loss: 0.19758853355495046
Validation loss: 2.476413129025489

Epoch: 6| Step: 4
Training loss: 0.30056834426563445
Validation loss: 2.496729257605913

Epoch: 6| Step: 5
Training loss: 0.18471419564255104
Validation loss: 2.476995971917057

Epoch: 6| Step: 6
Training loss: 0.10874187346628984
Validation loss: 2.4573015893491

Epoch: 6| Step: 7
Training loss: 0.1854415293340315
Validation loss: 2.4673951827809946

Epoch: 6| Step: 8
Training loss: 0.1805801918622486
Validation loss: 2.442721106155648

Epoch: 6| Step: 9
Training loss: 0.2881854515830187
Validation loss: 2.4443351110386566

Epoch: 6| Step: 10
Training loss: 0.14475404475874307
Validation loss: 2.406667200407782

Epoch: 6| Step: 11
Training loss: 0.1963378314265058
Validation loss: 2.4252744878561865

Epoch: 6| Step: 12
Training loss: 0.3074416976994216
Validation loss: 2.424482050609216

Epoch: 6| Step: 13
Training loss: 0.07969954016363175
Validation loss: 2.3853934509405756

Epoch: 496| Step: 0
Training loss: 0.1540457637799795
Validation loss: 2.405710958750143

Epoch: 6| Step: 1
Training loss: 0.24141953595337898
Validation loss: 2.418938600666299

Epoch: 6| Step: 2
Training loss: 0.17148620891242133
Validation loss: 2.4144341535527483

Epoch: 6| Step: 3
Training loss: 0.3124836082927859
Validation loss: 2.367098983397908

Epoch: 6| Step: 4
Training loss: 0.16895511356214699
Validation loss: 2.426530898637013

Epoch: 6| Step: 5
Training loss: 0.13232966619448322
Validation loss: 2.4047294769912217

Epoch: 6| Step: 6
Training loss: 0.13103960209080798
Validation loss: 2.439154920055278

Epoch: 6| Step: 7
Training loss: 0.20105345490505627
Validation loss: 2.376495424845759

Epoch: 6| Step: 8
Training loss: 0.17227820222920662
Validation loss: 2.3912731039853585

Epoch: 6| Step: 9
Training loss: 0.15399428163979562
Validation loss: 2.3899954193966533

Epoch: 6| Step: 10
Training loss: 0.22260358254447227
Validation loss: 2.388998783713007

Epoch: 6| Step: 11
Training loss: 0.2076548774507397
Validation loss: 2.3477169392998083

Epoch: 6| Step: 12
Training loss: 0.2125126869958347
Validation loss: 2.361892083361456

Epoch: 6| Step: 13
Training loss: 0.15430304358018393
Validation loss: 2.329317849791055

Epoch: 497| Step: 0
Training loss: 0.1731393433561208
Validation loss: 2.367028455394451

Epoch: 6| Step: 1
Training loss: 0.32608439934287625
Validation loss: 2.3048130374545557

Epoch: 6| Step: 2
Training loss: 0.15742683686797238
Validation loss: 2.2971918527778126

Epoch: 6| Step: 3
Training loss: 0.12789800848646296
Validation loss: 2.3449093254563533

Epoch: 6| Step: 4
Training loss: 0.18330711959423976
Validation loss: 2.329027477649569

Epoch: 6| Step: 5
Training loss: 0.26606759895401366
Validation loss: 2.34845242050894

Epoch: 6| Step: 6
Training loss: 0.10808237495934354
Validation loss: 2.3611466025287453

Epoch: 6| Step: 7
Training loss: 0.1702528886413446
Validation loss: 2.356093256937024

Epoch: 6| Step: 8
Training loss: 0.18478518295812055
Validation loss: 2.371492973306901

Epoch: 6| Step: 9
Training loss: 0.20774229771260144
Validation loss: 2.4436955832196796

Epoch: 6| Step: 10
Training loss: 0.1978521785745321
Validation loss: 2.3826479078469474

Epoch: 6| Step: 11
Training loss: 0.122910317833511
Validation loss: 2.386117254015131

Epoch: 6| Step: 12
Training loss: 0.13132968765500058
Validation loss: 2.3693581219809867

Epoch: 6| Step: 13
Training loss: 0.2174964477533989
Validation loss: 2.3845160844571502

Epoch: 498| Step: 0
Training loss: 0.12208675273814211
Validation loss: 2.372828193830324

Epoch: 6| Step: 1
Training loss: 0.2552177742100644
Validation loss: 2.3651949191110684

Epoch: 6| Step: 2
Training loss: 0.19580565182533205
Validation loss: 2.3614707808756785

Epoch: 6| Step: 3
Training loss: 0.11803661519598319
Validation loss: 2.3712272005743404

Epoch: 6| Step: 4
Training loss: 0.2857556640409072
Validation loss: 2.337505866414004

Epoch: 6| Step: 5
Training loss: 0.1389525688899777
Validation loss: 2.356506366719978

Epoch: 6| Step: 6
Training loss: 0.09605254883341897
Validation loss: 2.3772237920219315

Epoch: 6| Step: 7
Training loss: 0.23068175736531996
Validation loss: 2.3830706562269697

Epoch: 6| Step: 8
Training loss: 0.24542148289194088
Validation loss: 2.376491267345791

Epoch: 6| Step: 9
Training loss: 0.18060866872750203
Validation loss: 2.370493287881289

Epoch: 6| Step: 10
Training loss: 0.17354740020199896
Validation loss: 2.3868553300175988

Epoch: 6| Step: 11
Training loss: 0.10949664929159103
Validation loss: 2.390068955204389

Epoch: 6| Step: 12
Training loss: 0.28408907727171123
Validation loss: 2.380858828000204

Epoch: 6| Step: 13
Training loss: 0.19962700917087414
Validation loss: 2.403633260473512

Epoch: 499| Step: 0
Training loss: 0.15339494213088173
Validation loss: 2.404351389802312

Epoch: 6| Step: 1
Training loss: 0.19042086458552393
Validation loss: 2.4095171187358475

Epoch: 6| Step: 2
Training loss: 0.10864466975909652
Validation loss: 2.41146826947456

Epoch: 6| Step: 3
Training loss: 0.22146041040771278
Validation loss: 2.390193127286994

Epoch: 6| Step: 4
Training loss: 0.2639736708937345
Validation loss: 2.42090905251672

Epoch: 6| Step: 5
Training loss: 0.16445087830012348
Validation loss: 2.4288735267521178

Epoch: 6| Step: 6
Training loss: 0.12598240269571104
Validation loss: 2.421057191421642

Epoch: 6| Step: 7
Training loss: 0.32923928161023763
Validation loss: 2.4569574708199347

Epoch: 6| Step: 8
Training loss: 0.13370367792177235
Validation loss: 2.4132973695315574

Epoch: 6| Step: 9
Training loss: 0.1768073228655918
Validation loss: 2.4044086787538843

Epoch: 6| Step: 10
Training loss: 0.1747697816660536
Validation loss: 2.418781249302949

Epoch: 6| Step: 11
Training loss: 0.17032935076654723
Validation loss: 2.4420634358888114

Epoch: 6| Step: 12
Training loss: 0.13938673880882985
Validation loss: 2.406951384435185

Epoch: 6| Step: 13
Training loss: 0.24368505315684685
Validation loss: 2.3880920846835783

Epoch: 500| Step: 0
Training loss: 0.23465471265977364
Validation loss: 2.398103570560972

Epoch: 6| Step: 1
Training loss: 0.10067763361786215
Validation loss: 2.399676274356717

Epoch: 6| Step: 2
Training loss: 0.13764680860358758
Validation loss: 2.3646211204167593

Epoch: 6| Step: 3
Training loss: 0.2595717631716408
Validation loss: 2.383646681868293

Epoch: 6| Step: 4
Training loss: 0.1310303482103783
Validation loss: 2.392259827922272

Epoch: 6| Step: 5
Training loss: 0.09248269349335633
Validation loss: 2.3643407819676883

Epoch: 6| Step: 6
Training loss: 0.11204385737051548
Validation loss: 2.373055125359361

Epoch: 6| Step: 7
Training loss: 0.20311488529844582
Validation loss: 2.3416340443331283

Epoch: 6| Step: 8
Training loss: 0.16133965596515357
Validation loss: 2.3383513415493384

Epoch: 6| Step: 9
Training loss: 0.26013830884866657
Validation loss: 2.363559761745132

Epoch: 6| Step: 10
Training loss: 0.12663232913840808
Validation loss: 2.39852536883498

Epoch: 6| Step: 11
Training loss: 0.14257157976986892
Validation loss: 2.345687439514047

Epoch: 6| Step: 12
Training loss: 0.08178131595418688
Validation loss: 2.385266710694279

Epoch: 6| Step: 13
Training loss: 0.20618496071650155
Validation loss: 2.4020428148652515

Epoch: 501| Step: 0
Training loss: 0.17586932624850735
Validation loss: 2.4501952068236448

Epoch: 6| Step: 1
Training loss: 0.27202092124265775
Validation loss: 2.403512288777341

Epoch: 6| Step: 2
Training loss: 0.09675213478718646
Validation loss: 2.4110695747863784

Epoch: 6| Step: 3
Training loss: 0.18830854210174414
Validation loss: 2.4358142506323297

Epoch: 6| Step: 4
Training loss: 0.10867613799141256
Validation loss: 2.462832797761383

Epoch: 6| Step: 5
Training loss: 0.1241621308276972
Validation loss: 2.4610923237888565

Epoch: 6| Step: 6
Training loss: 0.2005316258700859
Validation loss: 2.447389363031452

Epoch: 6| Step: 7
Training loss: 0.14606833823422952
Validation loss: 2.428813227176091

Epoch: 6| Step: 8
Training loss: 0.12353764407099223
Validation loss: 2.4511081903160505

Epoch: 6| Step: 9
Training loss: 0.17980567529089192
Validation loss: 2.4109751250162472

Epoch: 6| Step: 10
Training loss: 0.17495222631674898
Validation loss: 2.411027546706468

Epoch: 6| Step: 11
Training loss: 0.11972574090597955
Validation loss: 2.3902669567853523

Epoch: 6| Step: 12
Training loss: 0.0999503750156678
Validation loss: 2.4016987812949706

Epoch: 6| Step: 13
Training loss: 0.10165556898220231
Validation loss: 2.4022390750143985

Epoch: 502| Step: 0
Training loss: 0.08260524124548557
Validation loss: 2.3629198929466493

Epoch: 6| Step: 1
Training loss: 0.14479760808441133
Validation loss: 2.3899342815679394

Epoch: 6| Step: 2
Training loss: 0.1170925152802353
Validation loss: 2.36473729998997

Epoch: 6| Step: 3
Training loss: 0.19815292603827572
Validation loss: 2.385292581620498

Epoch: 6| Step: 4
Training loss: 0.09819842514712243
Validation loss: 2.378082121323072

Epoch: 6| Step: 5
Training loss: 0.16110058086427884
Validation loss: 2.3611846136257646

Epoch: 6| Step: 6
Training loss: 0.14440550360108026
Validation loss: 2.37672642866702

Epoch: 6| Step: 7
Training loss: 0.1480805975117986
Validation loss: 2.3628048131702357

Epoch: 6| Step: 8
Training loss: 0.19343107031025905
Validation loss: 2.3893989326692786

Epoch: 6| Step: 9
Training loss: 0.09022283913826333
Validation loss: 2.3808164265194023

Epoch: 6| Step: 10
Training loss: 0.1073559038286457
Validation loss: 2.3769754636295577

Epoch: 6| Step: 11
Training loss: 0.29266911760953485
Validation loss: 2.4183956596825835

Epoch: 6| Step: 12
Training loss: 0.13764270832772885
Validation loss: 2.423609615922954

Epoch: 6| Step: 13
Training loss: 0.2250953310103728
Validation loss: 2.442391771223662

Epoch: 503| Step: 0
Training loss: 0.10227113870629662
Validation loss: 2.423619715565085

Epoch: 6| Step: 1
Training loss: 0.12251057006888068
Validation loss: 2.4360575461098293

Epoch: 6| Step: 2
Training loss: 0.1925878545535628
Validation loss: 2.4206300084551255

Epoch: 6| Step: 3
Training loss: 0.2797121548574616
Validation loss: 2.438574573811543

Epoch: 6| Step: 4
Training loss: 0.18774281118093386
Validation loss: 2.3944049452536267

Epoch: 6| Step: 5
Training loss: 0.1664593656597027
Validation loss: 2.422021983513046

Epoch: 6| Step: 6
Training loss: 0.1404787932742242
Validation loss: 2.4005526964189836

Epoch: 6| Step: 7
Training loss: 0.24286945528061352
Validation loss: 2.4399487921177614

Epoch: 6| Step: 8
Training loss: 0.15971183174366996
Validation loss: 2.3903953039221886

Epoch: 6| Step: 9
Training loss: 0.13235947536914575
Validation loss: 2.420804122345586

Epoch: 6| Step: 10
Training loss: 0.16243557111234078
Validation loss: 2.420279482694382

Epoch: 6| Step: 11
Training loss: 0.11002635297411456
Validation loss: 2.4259727407333966

Epoch: 6| Step: 12
Training loss: 0.09131661548158916
Validation loss: 2.420853820881267

Epoch: 6| Step: 13
Training loss: 0.12605046906223202
Validation loss: 2.374378502446789

Epoch: 504| Step: 0
Training loss: 0.1174470252985092
Validation loss: 2.3714622644615155

Epoch: 6| Step: 1
Training loss: 0.12125156870422021
Validation loss: 2.398994609571006

Epoch: 6| Step: 2
Training loss: 0.20413713282135812
Validation loss: 2.3891173414309668

Epoch: 6| Step: 3
Training loss: 0.10425528293483777
Validation loss: 2.3585569390573413

Epoch: 6| Step: 4
Training loss: 0.26147298518512535
Validation loss: 2.3484444859843676

Epoch: 6| Step: 5
Training loss: 0.1892076750679245
Validation loss: 2.3865194512545638

Epoch: 6| Step: 6
Training loss: 0.149171451492084
Validation loss: 2.357489269298591

Epoch: 6| Step: 7
Training loss: 0.13449765944615863
Validation loss: 2.3694607797227327

Epoch: 6| Step: 8
Training loss: 0.13632710082098443
Validation loss: 2.3587684321584197

Epoch: 6| Step: 9
Training loss: 0.10019701701567828
Validation loss: 2.3677636131191098

Epoch: 6| Step: 10
Training loss: 0.14704123509723757
Validation loss: 2.3429897483613416

Epoch: 6| Step: 11
Training loss: 0.07721636594374927
Validation loss: 2.368964305565282

Epoch: 6| Step: 12
Training loss: 0.19716517090760777
Validation loss: 2.3602029887375564

Epoch: 6| Step: 13
Training loss: 0.13041916864506828
Validation loss: 2.34442591392634

Epoch: 505| Step: 0
Training loss: 0.09925638558879503
Validation loss: 2.3592175226940815

Epoch: 6| Step: 1
Training loss: 0.1497565439542553
Validation loss: 2.380687561352886

Epoch: 6| Step: 2
Training loss: 0.10714202755297494
Validation loss: 2.41420520796462

Epoch: 6| Step: 3
Training loss: 0.08804923422071946
Validation loss: 2.377906489957656

Epoch: 6| Step: 4
Training loss: 0.28132420461646124
Validation loss: 2.418540947717864

Epoch: 6| Step: 5
Training loss: 0.10813743080913688
Validation loss: 2.399969908961901

Epoch: 6| Step: 6
Training loss: 0.22943629943805807
Validation loss: 2.389981358993012

Epoch: 6| Step: 7
Training loss: 0.11193572262503587
Validation loss: 2.414573922433092

Epoch: 6| Step: 8
Training loss: 0.11785129263862461
Validation loss: 2.3738010264329805

Epoch: 6| Step: 9
Training loss: 0.10797491762622254
Validation loss: 2.4056490086478544

Epoch: 6| Step: 10
Training loss: 0.20129811853416898
Validation loss: 2.381777477014079

Epoch: 6| Step: 11
Training loss: 0.07095894740336993
Validation loss: 2.3798894782845306

Epoch: 6| Step: 12
Training loss: 0.1862977744921177
Validation loss: 2.3536162114458743

Epoch: 6| Step: 13
Training loss: 0.14642207410296307
Validation loss: 2.309715168391189

Epoch: 506| Step: 0
Training loss: 0.20107115844650583
Validation loss: 2.370632369675371

Epoch: 6| Step: 1
Training loss: 0.1509603262161792
Validation loss: 2.3207453493894565

Epoch: 6| Step: 2
Training loss: 0.09760982363533495
Validation loss: 2.312588769549782

Epoch: 6| Step: 3
Training loss: 0.1250675138300615
Validation loss: 2.3330428701521337

Epoch: 6| Step: 4
Training loss: 0.08467298248652222
Validation loss: 2.341727819637947

Epoch: 6| Step: 5
Training loss: 0.1014308718368539
Validation loss: 2.3650900844497413

Epoch: 6| Step: 6
Training loss: 0.26174253384144497
Validation loss: 2.324008996229187

Epoch: 6| Step: 7
Training loss: 0.15693190312023853
Validation loss: 2.3760010919950627

Epoch: 6| Step: 8
Training loss: 0.0817311166428501
Validation loss: 2.396035825100354

Epoch: 6| Step: 9
Training loss: 0.09823597969933692
Validation loss: 2.375886758045596

Epoch: 6| Step: 10
Training loss: 0.12476569060465426
Validation loss: 2.393723636964927

Epoch: 6| Step: 11
Training loss: 0.2851018069825499
Validation loss: 2.4241554196806003

Epoch: 6| Step: 12
Training loss: 0.10317408249801568
Validation loss: 2.4067596880710975

Epoch: 6| Step: 13
Training loss: 0.14192127440461041
Validation loss: 2.378381972255758

Epoch: 507| Step: 0
Training loss: 0.09451769384805458
Validation loss: 2.4254516622844022

Epoch: 6| Step: 1
Training loss: 0.19009653929646114
Validation loss: 2.391527374894596

Epoch: 6| Step: 2
Training loss: 0.1064736914645433
Validation loss: 2.397391838446508

Epoch: 6| Step: 3
Training loss: 0.16569049637803657
Validation loss: 2.372317988332411

Epoch: 6| Step: 4
Training loss: 0.22924370807283417
Validation loss: 2.3602057042234414

Epoch: 6| Step: 5
Training loss: 0.15387890132216211
Validation loss: 2.372221934073

Epoch: 6| Step: 6
Training loss: 0.1238969022200033
Validation loss: 2.384838111108195

Epoch: 6| Step: 7
Training loss: 0.10929141086174428
Validation loss: 2.38384290095837

Epoch: 6| Step: 8
Training loss: 0.12575985507381013
Validation loss: 2.394481960143239

Epoch: 6| Step: 9
Training loss: 0.15340852932995783
Validation loss: 2.3614217031113207

Epoch: 6| Step: 10
Training loss: 0.08650142785848047
Validation loss: 2.3869838364310163

Epoch: 6| Step: 11
Training loss: 0.12643467605914394
Validation loss: 2.393592186087221

Epoch: 6| Step: 12
Training loss: 0.2995428750096067
Validation loss: 2.4209430818879336

Epoch: 6| Step: 13
Training loss: 0.13106234310661025
Validation loss: 2.3732596412707476

Epoch: 508| Step: 0
Training loss: 0.09443978523068353
Validation loss: 2.4025134563155635

Epoch: 6| Step: 1
Training loss: 0.0909227388402872
Validation loss: 2.396568445226263

Epoch: 6| Step: 2
Training loss: 0.18071403843191278
Validation loss: 2.391029351059624

Epoch: 6| Step: 3
Training loss: 0.10840692572824324
Validation loss: 2.4102391498483633

Epoch: 6| Step: 4
Training loss: 0.15716502958052245
Validation loss: 2.3679151721268776

Epoch: 6| Step: 5
Training loss: 0.14916316639888727
Validation loss: 2.3820381357394433

Epoch: 6| Step: 6
Training loss: 0.12000436058416623
Validation loss: 2.3997928207369887

Epoch: 6| Step: 7
Training loss: 0.1491586147087333
Validation loss: 2.3674923875653433

Epoch: 6| Step: 8
Training loss: 0.11776684367761613
Validation loss: 2.401579267476242

Epoch: 6| Step: 9
Training loss: 0.1178920665561824
Validation loss: 2.354638743749609

Epoch: 6| Step: 10
Training loss: 0.31083151530219066
Validation loss: 2.353096614698528

Epoch: 6| Step: 11
Training loss: 0.19983893517665874
Validation loss: 2.3474822955985335

Epoch: 6| Step: 12
Training loss: 0.1624836221107628
Validation loss: 2.385644413300658

Epoch: 6| Step: 13
Training loss: 0.24144184010688308
Validation loss: 2.3611754195326635

Epoch: 509| Step: 0
Training loss: 0.11698004320444111
Validation loss: 2.3956180113720418

Epoch: 6| Step: 1
Training loss: 0.11628304976916083
Validation loss: 2.3811446085840178

Epoch: 6| Step: 2
Training loss: 0.17222250141314296
Validation loss: 2.3940782757411547

Epoch: 6| Step: 3
Training loss: 0.18672229492142325
Validation loss: 2.369205564014298

Epoch: 6| Step: 4
Training loss: 0.11744039982666304
Validation loss: 2.3477816355521663

Epoch: 6| Step: 5
Training loss: 0.11234418754863819
Validation loss: 2.3422451019838495

Epoch: 6| Step: 6
Training loss: 0.30279508412671735
Validation loss: 2.343238211918245

Epoch: 6| Step: 7
Training loss: 0.12716902933804825
Validation loss: 2.374460994110538

Epoch: 6| Step: 8
Training loss: 0.1423748016720262
Validation loss: 2.316793426050727

Epoch: 6| Step: 9
Training loss: 0.12529977228449568
Validation loss: 2.353952422227156

Epoch: 6| Step: 10
Training loss: 0.14134855357864778
Validation loss: 2.3502400169865494

Epoch: 6| Step: 11
Training loss: 0.13799391490021604
Validation loss: 2.354841136407859

Epoch: 6| Step: 12
Training loss: 0.23645400013223197
Validation loss: 2.3505339726136985

Epoch: 6| Step: 13
Training loss: 0.14340268735893033
Validation loss: 2.32577647147504

Epoch: 510| Step: 0
Training loss: 0.1844566439236792
Validation loss: 2.3519029491808188

Epoch: 6| Step: 1
Training loss: 0.1470674861519862
Validation loss: 2.339890520472477

Epoch: 6| Step: 2
Training loss: 0.11201190931841097
Validation loss: 2.3752727411307704

Epoch: 6| Step: 3
Training loss: 0.1378011837571233
Validation loss: 2.3604810947494785

Epoch: 6| Step: 4
Training loss: 0.12315359483076682
Validation loss: 2.3802418431229717

Epoch: 6| Step: 5
Training loss: 0.1080478980125603
Validation loss: 2.3743802262034626

Epoch: 6| Step: 6
Training loss: 0.1625207598886991
Validation loss: 2.3792879366977306

Epoch: 6| Step: 7
Training loss: 0.1486242650264922
Validation loss: 2.3692781577369715

Epoch: 6| Step: 8
Training loss: 0.1164334914955404
Validation loss: 2.383939139738647

Epoch: 6| Step: 9
Training loss: 0.2597453173967057
Validation loss: 2.341235381897963

Epoch: 6| Step: 10
Training loss: 0.15715027374021628
Validation loss: 2.3722584265907884

Epoch: 6| Step: 11
Training loss: 0.156378800234674
Validation loss: 2.3622738516129833

Epoch: 6| Step: 12
Training loss: 0.22669350191021617
Validation loss: 2.374007641084772

Epoch: 6| Step: 13
Training loss: 0.12557033720759692
Validation loss: 2.3706824495381755

Epoch: 511| Step: 0
Training loss: 0.10421976782431863
Validation loss: 2.3442562035168137

Epoch: 6| Step: 1
Training loss: 0.2269179417033476
Validation loss: 2.3845750938315993

Epoch: 6| Step: 2
Training loss: 0.1940947334499254
Validation loss: 2.3638749515469026

Epoch: 6| Step: 3
Training loss: 0.10687418816074082
Validation loss: 2.3900795805746866

Epoch: 6| Step: 4
Training loss: 0.10793326635291389
Validation loss: 2.3646114030214305

Epoch: 6| Step: 5
Training loss: 0.2799289460371058
Validation loss: 2.3642955079205707

Epoch: 6| Step: 6
Training loss: 0.2324870923648339
Validation loss: 2.3533184350324254

Epoch: 6| Step: 7
Training loss: 0.08932784440412052
Validation loss: 2.381663597972569

Epoch: 6| Step: 8
Training loss: 0.12955452725961208
Validation loss: 2.373917718949991

Epoch: 6| Step: 9
Training loss: 0.18087948508129342
Validation loss: 2.3822859132645426

Epoch: 6| Step: 10
Training loss: 0.11579747336674033
Validation loss: 2.365856516525531

Epoch: 6| Step: 11
Training loss: 0.12350475932446
Validation loss: 2.381229010449011

Epoch: 6| Step: 12
Training loss: 0.22737854301351404
Validation loss: 2.3595037188205596

Epoch: 6| Step: 13
Training loss: 0.1253844844942661
Validation loss: 2.3745653227477623

Epoch: 512| Step: 0
Training loss: 0.19047776617877188
Validation loss: 2.3362926367252475

Epoch: 6| Step: 1
Training loss: 0.14338569035788606
Validation loss: 2.350562526272516

Epoch: 6| Step: 2
Training loss: 0.1781764244837559
Validation loss: 2.3393167002149684

Epoch: 6| Step: 3
Training loss: 0.2723453782558737
Validation loss: 2.3578235110666728

Epoch: 6| Step: 4
Training loss: 0.12297427215319094
Validation loss: 2.326988225681783

Epoch: 6| Step: 5
Training loss: 0.1671432737429621
Validation loss: 2.294733762272838

Epoch: 6| Step: 6
Training loss: 0.19741171913004613
Validation loss: 2.3210855257475758

Epoch: 6| Step: 7
Training loss: 0.20889458554556772
Validation loss: 2.3312091339839376

Epoch: 6| Step: 8
Training loss: 0.18106572632948656
Validation loss: 2.331743945699752

Epoch: 6| Step: 9
Training loss: 0.12761611217586355
Validation loss: 2.3692744961294956

Epoch: 6| Step: 10
Training loss: 0.16799991895114555
Validation loss: 2.335982134014629

Epoch: 6| Step: 11
Training loss: 0.25426598520956084
Validation loss: 2.345305671820504

Epoch: 6| Step: 12
Training loss: 0.30506411531251654
Validation loss: 2.350748760987586

Epoch: 6| Step: 13
Training loss: 0.14709206733041033
Validation loss: 2.3848200358775866

Epoch: 513| Step: 0
Training loss: 0.3151100948921546
Validation loss: 2.3564980023946

Epoch: 6| Step: 1
Training loss: 0.1324502478504526
Validation loss: 2.4100719570190723

Epoch: 6| Step: 2
Training loss: 0.15209769895281464
Validation loss: 2.377533423374502

Epoch: 6| Step: 3
Training loss: 0.2170855087142599
Validation loss: 2.372230517991913

Epoch: 6| Step: 4
Training loss: 0.21321770276770333
Validation loss: 2.387215963462755

Epoch: 6| Step: 5
Training loss: 0.1094216392056437
Validation loss: 2.40629668843713

Epoch: 6| Step: 6
Training loss: 0.18540847033340258
Validation loss: 2.4134782593305064

Epoch: 6| Step: 7
Training loss: 0.15236304234345505
Validation loss: 2.384451557039383

Epoch: 6| Step: 8
Training loss: 0.15120817877170376
Validation loss: 2.386544929406017

Epoch: 6| Step: 9
Training loss: 0.14283761488116267
Validation loss: 2.388978553498483

Epoch: 6| Step: 10
Training loss: 0.08391074901112344
Validation loss: 2.372453678716727

Epoch: 6| Step: 11
Training loss: 0.16860203790666142
Validation loss: 2.3835668850700173

Epoch: 6| Step: 12
Training loss: 0.19106288200529903
Validation loss: 2.3588262978134953

Epoch: 6| Step: 13
Training loss: 0.1241106867835559
Validation loss: 2.326744375514608

Epoch: 514| Step: 0
Training loss: 0.1745090755525041
Validation loss: 2.337923600562104

Epoch: 6| Step: 1
Training loss: 0.24785116690144934
Validation loss: 2.322246445628775

Epoch: 6| Step: 2
Training loss: 0.3147249882859793
Validation loss: 2.3169851843563976

Epoch: 6| Step: 3
Training loss: 0.11281944558644161
Validation loss: 2.322915187066176

Epoch: 6| Step: 4
Training loss: 0.17490003958099662
Validation loss: 2.3401390233271475

Epoch: 6| Step: 5
Training loss: 0.10461156033718262
Validation loss: 2.3185797757970654

Epoch: 6| Step: 6
Training loss: 0.23302870958091196
Validation loss: 2.3102436870365732

Epoch: 6| Step: 7
Training loss: 0.1629866509101746
Validation loss: 2.3277304293590033

Epoch: 6| Step: 8
Training loss: 0.14035872575171696
Validation loss: 2.331066397897472

Epoch: 6| Step: 9
Training loss: 0.16948121031138813
Validation loss: 2.3780790209106817

Epoch: 6| Step: 10
Training loss: 0.20956091810858674
Validation loss: 2.3516308623932014

Epoch: 6| Step: 11
Training loss: 0.14932370414388751
Validation loss: 2.3889580478571695

Epoch: 6| Step: 12
Training loss: 0.24011467068024783
Validation loss: 2.3822917980541987

Epoch: 6| Step: 13
Training loss: 0.2699882668577231
Validation loss: 2.3887754944446096

Epoch: 515| Step: 0
Training loss: 0.14141093609880065
Validation loss: 2.412474469978493

Epoch: 6| Step: 1
Training loss: 0.1810810123469825
Validation loss: 2.3988522663356426

Epoch: 6| Step: 2
Training loss: 0.15758258482296175
Validation loss: 2.3775173246379304

Epoch: 6| Step: 3
Training loss: 0.1398039132390162
Validation loss: 2.413120958963175

Epoch: 6| Step: 4
Training loss: 0.09480144058218945
Validation loss: 2.3907381336997937

Epoch: 6| Step: 5
Training loss: 0.12026216705037486
Validation loss: 2.396252670791997

Epoch: 6| Step: 6
Training loss: 0.17577880221887837
Validation loss: 2.368403248152405

Epoch: 6| Step: 7
Training loss: 0.13983376083713142
Validation loss: 2.3929530264089798

Epoch: 6| Step: 8
Training loss: 0.29967872632641585
Validation loss: 2.3788694380919955

Epoch: 6| Step: 9
Training loss: 0.09959608812164043
Validation loss: 2.366415605078419

Epoch: 6| Step: 10
Training loss: 0.15661690073314824
Validation loss: 2.3691235840706866

Epoch: 6| Step: 11
Training loss: 0.15944989795961162
Validation loss: 2.3767971424076424

Epoch: 6| Step: 12
Training loss: 0.22786723362425892
Validation loss: 2.373953613051362

Epoch: 6| Step: 13
Training loss: 0.3723024059910561
Validation loss: 2.335278853237765

Epoch: 516| Step: 0
Training loss: 0.1886135650945485
Validation loss: 2.3543763919867375

Epoch: 6| Step: 1
Training loss: 0.1112587151904305
Validation loss: 2.3459476834826454

Epoch: 6| Step: 2
Training loss: 0.2662915393948618
Validation loss: 2.339218604233995

Epoch: 6| Step: 3
Training loss: 0.15259398791528794
Validation loss: 2.352861752958871

Epoch: 6| Step: 4
Training loss: 0.16903369443983904
Validation loss: 2.3803418053107515

Epoch: 6| Step: 5
Training loss: 0.2715320133703817
Validation loss: 2.384744619263372

Epoch: 6| Step: 6
Training loss: 0.2801515267564905
Validation loss: 2.379636040376259

Epoch: 6| Step: 7
Training loss: 0.22041654970482052
Validation loss: 2.367655292507325

Epoch: 6| Step: 8
Training loss: 0.13248850066290013
Validation loss: 2.3696164522211647

Epoch: 6| Step: 9
Training loss: 0.21169035393858085
Validation loss: 2.3770155900196865

Epoch: 6| Step: 10
Training loss: 0.23846448044472185
Validation loss: 2.3808209129630122

Epoch: 6| Step: 11
Training loss: 0.13513821773742468
Validation loss: 2.351248133650995

Epoch: 6| Step: 12
Training loss: 0.2069446364548736
Validation loss: 2.335485400562718

Epoch: 6| Step: 13
Training loss: 0.24271320384518258
Validation loss: 2.3362805969931144

Epoch: 517| Step: 0
Training loss: 0.24306712842062328
Validation loss: 2.3350716851783773

Epoch: 6| Step: 1
Training loss: 0.19061247049647015
Validation loss: 2.320314134100219

Epoch: 6| Step: 2
Training loss: 0.23648737436389314
Validation loss: 2.3109270670191866

Epoch: 6| Step: 3
Training loss: 0.200681505401215
Validation loss: 2.3183065276867096

Epoch: 6| Step: 4
Training loss: 0.15517231509428886
Validation loss: 2.370622396832693

Epoch: 6| Step: 5
Training loss: 0.17409049282440436
Validation loss: 2.3645971206654113

Epoch: 6| Step: 6
Training loss: 0.08402288740413391
Validation loss: 2.3684797934135946

Epoch: 6| Step: 7
Training loss: 0.1640550861500036
Validation loss: 2.3702655345954535

Epoch: 6| Step: 8
Training loss: 0.25450518465850314
Validation loss: 2.3924675814430993

Epoch: 6| Step: 9
Training loss: 0.35290842968622205
Validation loss: 2.3997382258803643

Epoch: 6| Step: 10
Training loss: 0.16392922664945336
Validation loss: 2.414937446297211

Epoch: 6| Step: 11
Training loss: 0.21055202230131365
Validation loss: 2.389959429403725

Epoch: 6| Step: 12
Training loss: 0.15668125838464927
Validation loss: 2.366378038765849

Epoch: 6| Step: 13
Training loss: 0.1771796235851807
Validation loss: 2.3799264219903704

Epoch: 518| Step: 0
Training loss: 0.18255133640029478
Validation loss: 2.3720721843769867

Epoch: 6| Step: 1
Training loss: 0.44637276096257805
Validation loss: 2.4123989115287463

Epoch: 6| Step: 2
Training loss: 0.1819411324839829
Validation loss: 2.4214329978122806

Epoch: 6| Step: 3
Training loss: 0.14159326200163297
Validation loss: 2.405430459628979

Epoch: 6| Step: 4
Training loss: 0.18445694686374903
Validation loss: 2.4251125838779073

Epoch: 6| Step: 5
Training loss: 0.2608378517020541
Validation loss: 2.3914519414660544

Epoch: 6| Step: 6
Training loss: 0.20349781046270574
Validation loss: 2.3863173598531278

Epoch: 6| Step: 7
Training loss: 0.18233997295295545
Validation loss: 2.37432006889264

Epoch: 6| Step: 8
Training loss: 0.20331912667902502
Validation loss: 2.3802649468208337

Epoch: 6| Step: 9
Training loss: 0.16874446948136954
Validation loss: 2.3767465301832367

Epoch: 6| Step: 10
Training loss: 0.13317761302743697
Validation loss: 2.391898557861845

Epoch: 6| Step: 11
Training loss: 0.209520801266597
Validation loss: 2.3581758486204274

Epoch: 6| Step: 12
Training loss: 0.2651841769238372
Validation loss: 2.430556888101411

Epoch: 6| Step: 13
Training loss: 0.13254599619705285
Validation loss: 2.3895799579330634

Epoch: 519| Step: 0
Training loss: 0.27658215576841444
Validation loss: 2.424289086900512

Epoch: 6| Step: 1
Training loss: 0.23510171758558962
Validation loss: 2.4419849144111194

Epoch: 6| Step: 2
Training loss: 0.15994935511947664
Validation loss: 2.4671546097839476

Epoch: 6| Step: 3
Training loss: 0.17810788574318978
Validation loss: 2.421346500249167

Epoch: 6| Step: 4
Training loss: 0.0937455990870979
Validation loss: 2.3849895256254303

Epoch: 6| Step: 5
Training loss: 0.16533204882509575
Validation loss: 2.3955294751215277

Epoch: 6| Step: 6
Training loss: 0.19544545416753073
Validation loss: 2.369507823570373

Epoch: 6| Step: 7
Training loss: 0.10862761405157874
Validation loss: 2.390408780076341

Epoch: 6| Step: 8
Training loss: 0.16469585125177585
Validation loss: 2.359645109545826

Epoch: 6| Step: 9
Training loss: 0.1498796029501579
Validation loss: 2.382637693978703

Epoch: 6| Step: 10
Training loss: 0.35186273682197494
Validation loss: 2.3804950162247644

Epoch: 6| Step: 11
Training loss: 0.22874397703746477
Validation loss: 2.3989167398187727

Epoch: 6| Step: 12
Training loss: 0.24975402473379954
Validation loss: 2.3647717831804664

Epoch: 6| Step: 13
Training loss: 0.14620178940058898
Validation loss: 2.3586242846192786

Epoch: 520| Step: 0
Training loss: 0.1423178020720131
Validation loss: 2.3690860790942914

Epoch: 6| Step: 1
Training loss: 0.16160792040656655
Validation loss: 2.372226782051165

Epoch: 6| Step: 2
Training loss: 0.16372595624178468
Validation loss: 2.381202071511784

Epoch: 6| Step: 3
Training loss: 0.21043816380329536
Validation loss: 2.3904744330796075

Epoch: 6| Step: 4
Training loss: 0.11840316525783075
Validation loss: 2.385879222062696

Epoch: 6| Step: 5
Training loss: 0.12718727087192377
Validation loss: 2.3847959572152044

Epoch: 6| Step: 6
Training loss: 0.21873961151523488
Validation loss: 2.429343272618052

Epoch: 6| Step: 7
Training loss: 0.17943889586418285
Validation loss: 2.419153383884814

Epoch: 6| Step: 8
Training loss: 0.17282369356653499
Validation loss: 2.4131892597123805

Epoch: 6| Step: 9
Training loss: 0.11443853350380474
Validation loss: 2.431606768531239

Epoch: 6| Step: 10
Training loss: 0.3492789918455036
Validation loss: 2.4463809196483806

Epoch: 6| Step: 11
Training loss: 0.22972162019225847
Validation loss: 2.4167912578043294

Epoch: 6| Step: 12
Training loss: 0.17665054691596063
Validation loss: 2.468690869666988

Epoch: 6| Step: 13
Training loss: 0.10431005076789453
Validation loss: 2.412442588367433

Epoch: 521| Step: 0
Training loss: 0.18491018378396173
Validation loss: 2.3907454029582715

Epoch: 6| Step: 1
Training loss: 0.1642245219238937
Validation loss: 2.380315874113956

Epoch: 6| Step: 2
Training loss: 0.22794412405390171
Validation loss: 2.3495041130610805

Epoch: 6| Step: 3
Training loss: 0.16497228050031074
Validation loss: 2.3393006705341444

Epoch: 6| Step: 4
Training loss: 0.15029853627065753
Validation loss: 2.3527153813119246

Epoch: 6| Step: 5
Training loss: 0.11209039560684987
Validation loss: 2.3643935105992377

Epoch: 6| Step: 6
Training loss: 0.1515570403619964
Validation loss: 2.3524825471519195

Epoch: 6| Step: 7
Training loss: 0.18165196619211343
Validation loss: 2.3306470513580093

Epoch: 6| Step: 8
Training loss: 0.17816125517517128
Validation loss: 2.371036070205407

Epoch: 6| Step: 9
Training loss: 0.2243863781750997
Validation loss: 2.3839191644701865

Epoch: 6| Step: 10
Training loss: 0.2602880430467513
Validation loss: 2.3493545196658143

Epoch: 6| Step: 11
Training loss: 0.1501654512164448
Validation loss: 2.391039031854395

Epoch: 6| Step: 12
Training loss: 0.3096779115849659
Validation loss: 2.367859398920811

Epoch: 6| Step: 13
Training loss: 0.21368509317968953
Validation loss: 2.3667907436498257

Epoch: 522| Step: 0
Training loss: 0.1643885256819322
Validation loss: 2.3757832937735635

Epoch: 6| Step: 1
Training loss: 0.16680951751752635
Validation loss: 2.4165561645104128

Epoch: 6| Step: 2
Training loss: 0.28411583986129785
Validation loss: 2.409090227413051

Epoch: 6| Step: 3
Training loss: 0.22180289151159685
Validation loss: 2.409915272951697

Epoch: 6| Step: 4
Training loss: 0.19100600844439394
Validation loss: 2.4417680868456495

Epoch: 6| Step: 5
Training loss: 0.14209588683606222
Validation loss: 2.3869627363691883

Epoch: 6| Step: 6
Training loss: 0.21446620539951444
Validation loss: 2.424194219444758

Epoch: 6| Step: 7
Training loss: 0.14550980304150152
Validation loss: 2.399275894764868

Epoch: 6| Step: 8
Training loss: 0.16963080985451148
Validation loss: 2.3949118905202504

Epoch: 6| Step: 9
Training loss: 0.21082844387542893
Validation loss: 2.366579190771834

Epoch: 6| Step: 10
Training loss: 0.11299602181998111
Validation loss: 2.3702826797987155

Epoch: 6| Step: 11
Training loss: 0.11516106019008693
Validation loss: 2.3461698426220363

Epoch: 6| Step: 12
Training loss: 0.14276582955939338
Validation loss: 2.337714351591097

Epoch: 6| Step: 13
Training loss: 0.12211915755548249
Validation loss: 2.329442784030238

Epoch: 523| Step: 0
Training loss: 0.15249821583689122
Validation loss: 2.326879413283654

Epoch: 6| Step: 1
Training loss: 0.15396111812533533
Validation loss: 2.315545282243707

Epoch: 6| Step: 2
Training loss: 0.14474636256468765
Validation loss: 2.309339289490626

Epoch: 6| Step: 3
Training loss: 0.2328695585748477
Validation loss: 2.3301416931373833

Epoch: 6| Step: 4
Training loss: 0.14352899438243027
Validation loss: 2.3629090488858644

Epoch: 6| Step: 5
Training loss: 0.27328841368510237
Validation loss: 2.322460817578101

Epoch: 6| Step: 6
Training loss: 0.1642030102893379
Validation loss: 2.3393578177563894

Epoch: 6| Step: 7
Training loss: 0.1746737986430645
Validation loss: 2.3259188444154324

Epoch: 6| Step: 8
Training loss: 0.1558909582582039
Validation loss: 2.3082316860648224

Epoch: 6| Step: 9
Training loss: 0.10437753216018998
Validation loss: 2.3783883986435286

Epoch: 6| Step: 10
Training loss: 0.10060338915195753
Validation loss: 2.360337474309728

Epoch: 6| Step: 11
Training loss: 0.23460206317972043
Validation loss: 2.3254546163491625

Epoch: 6| Step: 12
Training loss: 0.14133803740365752
Validation loss: 2.3300308362883286

Epoch: 6| Step: 13
Training loss: 0.15848665967353404
Validation loss: 2.3803622338587873

Epoch: 524| Step: 0
Training loss: 0.09651386123170837
Validation loss: 2.3556093974487484

Epoch: 6| Step: 1
Training loss: 0.10029205890157383
Validation loss: 2.3171101683938087

Epoch: 6| Step: 2
Training loss: 0.12057170318036811
Validation loss: 2.3573155293724057

Epoch: 6| Step: 3
Training loss: 0.3088944575558115
Validation loss: 2.350697123332517

Epoch: 6| Step: 4
Training loss: 0.11141035322521876
Validation loss: 2.3590175339122372

Epoch: 6| Step: 5
Training loss: 0.11807670201293068
Validation loss: 2.3318315187085297

Epoch: 6| Step: 6
Training loss: 0.09749645510978373
Validation loss: 2.3483850916387174

Epoch: 6| Step: 7
Training loss: 0.16775196524227845
Validation loss: 2.344649734895871

Epoch: 6| Step: 8
Training loss: 0.14216725708366335
Validation loss: 2.3819740378916867

Epoch: 6| Step: 9
Training loss: 0.14158809203169517
Validation loss: 2.3672911767041773

Epoch: 6| Step: 10
Training loss: 0.14388925141329165
Validation loss: 2.377824596521929

Epoch: 6| Step: 11
Training loss: 0.1525034067875597
Validation loss: 2.364637033744398

Epoch: 6| Step: 12
Training loss: 0.1370386672214605
Validation loss: 2.385570686835777

Epoch: 6| Step: 13
Training loss: 0.09896407821777774
Validation loss: 2.3710855528230326

Epoch: 525| Step: 0
Training loss: 0.15095047966017555
Validation loss: 2.348587572942381

Epoch: 6| Step: 1
Training loss: 0.10874310246878882
Validation loss: 2.338330749900184

Epoch: 6| Step: 2
Training loss: 0.08754549344589853
Validation loss: 2.3652209142013643

Epoch: 6| Step: 3
Training loss: 0.09678663253474269
Validation loss: 2.3323251579538717

Epoch: 6| Step: 4
Training loss: 0.14227427151007016
Validation loss: 2.370594003956606

Epoch: 6| Step: 5
Training loss: 0.33158787688666996
Validation loss: 2.361798373008219

Epoch: 6| Step: 6
Training loss: 0.14037186967012413
Validation loss: 2.356434102472846

Epoch: 6| Step: 7
Training loss: 0.253929650622204
Validation loss: 2.38128302198165

Epoch: 6| Step: 8
Training loss: 0.14816177006342718
Validation loss: 2.3726646467626575

Epoch: 6| Step: 9
Training loss: 0.10548659456257509
Validation loss: 2.3427430087709715

Epoch: 6| Step: 10
Training loss: 0.07658388206601767
Validation loss: 2.3841393584965314

Epoch: 6| Step: 11
Training loss: 0.11595605097724672
Validation loss: 2.3700439802008924

Epoch: 6| Step: 12
Training loss: 0.12292069065516997
Validation loss: 2.3790652753368295

Epoch: 6| Step: 13
Training loss: 0.1406499390210746
Validation loss: 2.3915038764382794

Epoch: 526| Step: 0
Training loss: 0.15253457931006573
Validation loss: 2.3950797156147754

Epoch: 6| Step: 1
Training loss: 0.11816562304766752
Validation loss: 2.3723232759370707

Epoch: 6| Step: 2
Training loss: 0.07839617753014556
Validation loss: 2.36922511689558

Epoch: 6| Step: 3
Training loss: 0.17019668368421295
Validation loss: 2.3629184000603947

Epoch: 6| Step: 4
Training loss: 0.16191684251154181
Validation loss: 2.3789686799005265

Epoch: 6| Step: 5
Training loss: 0.2020664233001747
Validation loss: 2.3591058728756225

Epoch: 6| Step: 6
Training loss: 0.12766696072566144
Validation loss: 2.3814939059675964

Epoch: 6| Step: 7
Training loss: 0.18984682920494028
Validation loss: 2.385824904110728

Epoch: 6| Step: 8
Training loss: 0.13996402054632137
Validation loss: 2.3757410841582773

Epoch: 6| Step: 9
Training loss: 0.11701958069728817
Validation loss: 2.335693405885502

Epoch: 6| Step: 10
Training loss: 0.24820005387953836
Validation loss: 2.349270628622483

Epoch: 6| Step: 11
Training loss: 0.14812462232235754
Validation loss: 2.352910780461521

Epoch: 6| Step: 12
Training loss: 0.10775794864005134
Validation loss: 2.3431021420494464

Epoch: 6| Step: 13
Training loss: 0.17566977781092205
Validation loss: 2.3554602453980644

Epoch: 527| Step: 0
Training loss: 0.15924520840802148
Validation loss: 2.3848878663306947

Epoch: 6| Step: 1
Training loss: 0.1306802890663625
Validation loss: 2.374079617158498

Epoch: 6| Step: 2
Training loss: 0.2380225152652561
Validation loss: 2.4003557179149153

Epoch: 6| Step: 3
Training loss: 0.13002118648686262
Validation loss: 2.372051513131572

Epoch: 6| Step: 4
Training loss: 0.12392532793447614
Validation loss: 2.351465730914672

Epoch: 6| Step: 5
Training loss: 0.2948058575942718
Validation loss: 2.3471245332039916

Epoch: 6| Step: 6
Training loss: 0.08098921371980738
Validation loss: 2.3282058744718497

Epoch: 6| Step: 7
Training loss: 0.11292290737471414
Validation loss: 2.327588982826586

Epoch: 6| Step: 8
Training loss: 0.08295419026892745
Validation loss: 2.344704561717602

Epoch: 6| Step: 9
Training loss: 0.09183481122441396
Validation loss: 2.3512834852135414

Epoch: 6| Step: 10
Training loss: 0.09535712346633717
Validation loss: 2.357669758735928

Epoch: 6| Step: 11
Training loss: 0.11237031014530215
Validation loss: 2.332488724202613

Epoch: 6| Step: 12
Training loss: 0.06919672247389155
Validation loss: 2.372863944513746

Epoch: 6| Step: 13
Training loss: 0.201015902673594
Validation loss: 2.309670289832016

Epoch: 528| Step: 0
Training loss: 0.09520148648201686
Validation loss: 2.330585395052921

Epoch: 6| Step: 1
Training loss: 0.15568047679862412
Validation loss: 2.3443096933715633

Epoch: 6| Step: 2
Training loss: 0.07205756625219778
Validation loss: 2.3500381438703593

Epoch: 6| Step: 3
Training loss: 0.1272477179867887
Validation loss: 2.352271304099342

Epoch: 6| Step: 4
Training loss: 0.12298576411772638
Validation loss: 2.3830515375306702

Epoch: 6| Step: 5
Training loss: 0.13075869516148955
Validation loss: 2.3789608304532623

Epoch: 6| Step: 6
Training loss: 0.16147031983110224
Validation loss: 2.3716719084461904

Epoch: 6| Step: 7
Training loss: 0.10399978701175375
Validation loss: 2.3757728696478257

Epoch: 6| Step: 8
Training loss: 0.10727879792724426
Validation loss: 2.339993334873686

Epoch: 6| Step: 9
Training loss: 0.25963874816032534
Validation loss: 2.3742003678787453

Epoch: 6| Step: 10
Training loss: 0.2218035717282735
Validation loss: 2.3491124575807047

Epoch: 6| Step: 11
Training loss: 0.1621954298837102
Validation loss: 2.3350290711990533

Epoch: 6| Step: 12
Training loss: 0.1207435604993592
Validation loss: 2.3321702940127262

Epoch: 6| Step: 13
Training loss: 0.08388807075840923
Validation loss: 2.357594456623664

Epoch: 529| Step: 0
Training loss: 0.1104138713233916
Validation loss: 2.3605545877596867

Epoch: 6| Step: 1
Training loss: 0.17916731589406695
Validation loss: 2.3701523019717725

Epoch: 6| Step: 2
Training loss: 0.13813827499403183
Validation loss: 2.33910410157238

Epoch: 6| Step: 3
Training loss: 0.12393947071792062
Validation loss: 2.3604421285158117

Epoch: 6| Step: 4
Training loss: 0.1636875158770926
Validation loss: 2.3942946252350117

Epoch: 6| Step: 5
Training loss: 0.19197015024649755
Validation loss: 2.3969255278978223

Epoch: 6| Step: 6
Training loss: 0.15834326482878805
Validation loss: 2.3790082047714995

Epoch: 6| Step: 7
Training loss: 0.0809251399203777
Validation loss: 2.3705442390921045

Epoch: 6| Step: 8
Training loss: 0.11036390893786216
Validation loss: 2.3874109936344694

Epoch: 6| Step: 9
Training loss: 0.2160116702333421
Validation loss: 2.371749842029119

Epoch: 6| Step: 10
Training loss: 0.1265089480991594
Validation loss: 2.384387597719651

Epoch: 6| Step: 11
Training loss: 0.16403655573657358
Validation loss: 2.3966217505761156

Epoch: 6| Step: 12
Training loss: 0.11323650890638379
Validation loss: 2.4070680727480935

Epoch: 6| Step: 13
Training loss: 0.35264898472689427
Validation loss: 2.384527256539163

Epoch: 530| Step: 0
Training loss: 0.2663502329442757
Validation loss: 2.360498603170751

Epoch: 6| Step: 1
Training loss: 0.1995678535619059
Validation loss: 2.374154004431818

Epoch: 6| Step: 2
Training loss: 0.13618796037444705
Validation loss: 2.3769643159117333

Epoch: 6| Step: 3
Training loss: 0.11888801654215744
Validation loss: 2.3438676718428573

Epoch: 6| Step: 4
Training loss: 0.11432956415182693
Validation loss: 2.3369683138798076

Epoch: 6| Step: 5
Training loss: 0.06104954359237781
Validation loss: 2.3338083404116396

Epoch: 6| Step: 6
Training loss: 0.09640539156564026
Validation loss: 2.345839309014491

Epoch: 6| Step: 7
Training loss: 0.09104048283070613
Validation loss: 2.3302648378200996

Epoch: 6| Step: 8
Training loss: 0.14655426901049853
Validation loss: 2.34374062211543

Epoch: 6| Step: 9
Training loss: 0.14062009246528187
Validation loss: 2.3425329848295955

Epoch: 6| Step: 10
Training loss: 0.12275701016649616
Validation loss: 2.3538197533941183

Epoch: 6| Step: 11
Training loss: 0.1756098176207447
Validation loss: 2.369818166652008

Epoch: 6| Step: 12
Training loss: 0.1844796962414519
Validation loss: 2.3835557773219946

Epoch: 6| Step: 13
Training loss: 0.2660404630652206
Validation loss: 2.368840830998141

Epoch: 531| Step: 0
Training loss: 0.151827567379901
Validation loss: 2.4037395529194994

Epoch: 6| Step: 1
Training loss: 0.12484193657929446
Validation loss: 2.354316882685028

Epoch: 6| Step: 2
Training loss: 0.10039902885677837
Validation loss: 2.345464419288985

Epoch: 6| Step: 3
Training loss: 0.1334005269100601
Validation loss: 2.3605219386610443

Epoch: 6| Step: 4
Training loss: 0.1565771076388988
Validation loss: 2.344326276039465

Epoch: 6| Step: 5
Training loss: 0.23025064331300313
Validation loss: 2.3392161548092987

Epoch: 6| Step: 6
Training loss: 0.2663165095138691
Validation loss: 2.339935163445113

Epoch: 6| Step: 7
Training loss: 0.2587679872388295
Validation loss: 2.358271654239139

Epoch: 6| Step: 8
Training loss: 0.1799184724500086
Validation loss: 2.35983706255796

Epoch: 6| Step: 9
Training loss: 0.11826792400659104
Validation loss: 2.387755231073814

Epoch: 6| Step: 10
Training loss: 0.12398985160168975
Validation loss: 2.3870538446404144

Epoch: 6| Step: 11
Training loss: 0.1600294949029894
Validation loss: 2.3310635582854564

Epoch: 6| Step: 12
Training loss: 0.13576250816118998
Validation loss: 2.3448547286431327

Epoch: 6| Step: 13
Training loss: 0.09699377423516027
Validation loss: 2.4016065281217864

Epoch: 532| Step: 0
Training loss: 0.12812234480362858
Validation loss: 2.365217288584642

Epoch: 6| Step: 1
Training loss: 0.14430540068946185
Validation loss: 2.3729366758825443

Epoch: 6| Step: 2
Training loss: 0.12495225501177991
Validation loss: 2.3423566125944757

Epoch: 6| Step: 3
Training loss: 0.1514409285553583
Validation loss: 2.3517818035920803

Epoch: 6| Step: 4
Training loss: 0.18230238724020179
Validation loss: 2.3742332105803565

Epoch: 6| Step: 5
Training loss: 0.10792698448460614
Validation loss: 2.380837501909211

Epoch: 6| Step: 6
Training loss: 0.12916794136659188
Validation loss: 2.378475347192065

Epoch: 6| Step: 7
Training loss: 0.17529206554637067
Validation loss: 2.3848913147750967

Epoch: 6| Step: 8
Training loss: 0.24392887851160774
Validation loss: 2.393353462216286

Epoch: 6| Step: 9
Training loss: 0.18256267203088142
Validation loss: 2.3612967465426116

Epoch: 6| Step: 10
Training loss: 0.30827049031648557
Validation loss: 2.3546995481315998

Epoch: 6| Step: 11
Training loss: 0.13553018961951854
Validation loss: 2.3672631830120268

Epoch: 6| Step: 12
Training loss: 0.16839534348751647
Validation loss: 2.3540589633457687

Epoch: 6| Step: 13
Training loss: 0.14943860045753382
Validation loss: 2.354109401225997

Epoch: 533| Step: 0
Training loss: 0.08892719108491158
Validation loss: 2.3285433485644877

Epoch: 6| Step: 1
Training loss: 0.14808427670371893
Validation loss: 2.352174480251919

Epoch: 6| Step: 2
Training loss: 0.18180079217812664
Validation loss: 2.317377691591383

Epoch: 6| Step: 3
Training loss: 0.22657483988075108
Validation loss: 2.3205826136240435

Epoch: 6| Step: 4
Training loss: 0.2096491605782802
Validation loss: 2.3322098700123464

Epoch: 6| Step: 5
Training loss: 0.14301541301720336
Validation loss: 2.335876594649665

Epoch: 6| Step: 6
Training loss: 0.14676093379690025
Validation loss: 2.3119159760308996

Epoch: 6| Step: 7
Training loss: 0.11601545417336369
Validation loss: 2.337346640936625

Epoch: 6| Step: 8
Training loss: 0.11159683307644674
Validation loss: 2.3236441973648176

Epoch: 6| Step: 9
Training loss: 0.2118265525037478
Validation loss: 2.360289582142895

Epoch: 6| Step: 10
Training loss: 0.201171875
Validation loss: 2.337618714593375

Epoch: 6| Step: 11
Training loss: 0.2372051862422699
Validation loss: 2.3246208302944806

Epoch: 6| Step: 12
Training loss: 0.21460537257175266
Validation loss: 2.35595107197506

Epoch: 6| Step: 13
Training loss: 0.3686335880990503
Validation loss: 2.3847539471662884

Epoch: 534| Step: 0
Training loss: 0.19062200762792056
Validation loss: 2.3483368440894368

Epoch: 6| Step: 1
Training loss: 0.19694059808001835
Validation loss: 2.377482303309268

Epoch: 6| Step: 2
Training loss: 0.1376630055288636
Validation loss: 2.3539320438333795

Epoch: 6| Step: 3
Training loss: 0.08391542432042436
Validation loss: 2.3685210454526904

Epoch: 6| Step: 4
Training loss: 0.20568366795021337
Validation loss: 2.3363444171809316

Epoch: 6| Step: 5
Training loss: 0.19299955315241696
Validation loss: 2.3168949871273927

Epoch: 6| Step: 6
Training loss: 0.2565108878555747
Validation loss: 2.370986817402965

Epoch: 6| Step: 7
Training loss: 0.16806197351775407
Validation loss: 2.3022220946340473

Epoch: 6| Step: 8
Training loss: 0.16640810853520227
Validation loss: 2.2612407046712875

Epoch: 6| Step: 9
Training loss: 0.24797760003587543
Validation loss: 2.273103024705832

Epoch: 6| Step: 10
Training loss: 0.13994144831015892
Validation loss: 2.2843764656135925

Epoch: 6| Step: 11
Training loss: 0.10298370955976714
Validation loss: 2.280731859867742

Epoch: 6| Step: 12
Training loss: 0.1148456466284639
Validation loss: 2.277055177121509

Epoch: 6| Step: 13
Training loss: 0.39846092978010517
Validation loss: 2.292357676932067

Epoch: 535| Step: 0
Training loss: 0.12497025374289783
Validation loss: 2.3050645028023435

Epoch: 6| Step: 1
Training loss: 0.1265134239415191
Validation loss: 2.2939443681545657

Epoch: 6| Step: 2
Training loss: 0.14106329854385097
Validation loss: 2.3180274444125155

Epoch: 6| Step: 3
Training loss: 0.2109125440457882
Validation loss: 2.320695656714188

Epoch: 6| Step: 4
Training loss: 0.125812741892412
Validation loss: 2.337213297136915

Epoch: 6| Step: 5
Training loss: 0.16416656508862149
Validation loss: 2.3317535323520993

Epoch: 6| Step: 6
Training loss: 0.1679366325012448
Validation loss: 2.325768493209298

Epoch: 6| Step: 7
Training loss: 0.10736510770901671
Validation loss: 2.3283094955318546

Epoch: 6| Step: 8
Training loss: 0.239628267566409
Validation loss: 2.3327115639746374

Epoch: 6| Step: 9
Training loss: 0.10304862973134142
Validation loss: 2.3757581704224844

Epoch: 6| Step: 10
Training loss: 0.157482590337573
Validation loss: 2.340519881785387

Epoch: 6| Step: 11
Training loss: 0.1698541561104325
Validation loss: 2.323450714856487

Epoch: 6| Step: 12
Training loss: 0.1754770401637816
Validation loss: 2.354545056113374

Epoch: 6| Step: 13
Training loss: 0.11121980098512901
Validation loss: 2.351368473764376

Epoch: 536| Step: 0
Training loss: 0.11723583734513669
Validation loss: 2.3583749663158398

Epoch: 6| Step: 1
Training loss: 0.0763410651610862
Validation loss: 2.369105042668855

Epoch: 6| Step: 2
Training loss: 0.06491303003219825
Validation loss: 2.34115481626726

Epoch: 6| Step: 3
Training loss: 0.09540707672053333
Validation loss: 2.39428254631095

Epoch: 6| Step: 4
Training loss: 0.1426599215675338
Validation loss: 2.352352109109471

Epoch: 6| Step: 5
Training loss: 0.25341566081089434
Validation loss: 2.361585323174044

Epoch: 6| Step: 6
Training loss: 0.19548869768384763
Validation loss: 2.3593396126654187

Epoch: 6| Step: 7
Training loss: 0.09207077961715396
Validation loss: 2.4038431718112063

Epoch: 6| Step: 8
Training loss: 0.14644901484634765
Validation loss: 2.3812762298315

Epoch: 6| Step: 9
Training loss: 0.10133913125974049
Validation loss: 2.367340476614564

Epoch: 6| Step: 10
Training loss: 0.09463516230418666
Validation loss: 2.3602771268976293

Epoch: 6| Step: 11
Training loss: 0.19846110166030748
Validation loss: 2.3365309814609807

Epoch: 6| Step: 12
Training loss: 0.1023679395291545
Validation loss: 2.35995185524418

Epoch: 6| Step: 13
Training loss: 0.07768438783137056
Validation loss: 2.351971946956402

Epoch: 537| Step: 0
Training loss: 0.2778984486548605
Validation loss: 2.3559982876483723

Epoch: 6| Step: 1
Training loss: 0.10128887161048587
Validation loss: 2.351684138723393

Epoch: 6| Step: 2
Training loss: 0.1472946897202779
Validation loss: 2.370290534189927

Epoch: 6| Step: 3
Training loss: 0.10274039892659163
Validation loss: 2.344775482394631

Epoch: 6| Step: 4
Training loss: 0.13650182135383385
Validation loss: 2.3591205601253766

Epoch: 6| Step: 5
Training loss: 0.10122306202680664
Validation loss: 2.398929786057209

Epoch: 6| Step: 6
Training loss: 0.1147094749295611
Validation loss: 2.3782506489590083

Epoch: 6| Step: 7
Training loss: 0.1764924338663545
Validation loss: 2.400279172389207

Epoch: 6| Step: 8
Training loss: 0.2361050490850887
Validation loss: 2.3652185789579865

Epoch: 6| Step: 9
Training loss: 0.1771648840961094
Validation loss: 2.354922487366103

Epoch: 6| Step: 10
Training loss: 0.0962048051670969
Validation loss: 2.3557061655438414

Epoch: 6| Step: 11
Training loss: 0.21247053257603582
Validation loss: 2.389878373775766

Epoch: 6| Step: 12
Training loss: 0.13480054016056348
Validation loss: 2.3728468676603565

Epoch: 6| Step: 13
Training loss: 0.16197971536067093
Validation loss: 2.3353682882972953

Epoch: 538| Step: 0
Training loss: 0.12392211514845183
Validation loss: 2.3369527661295972

Epoch: 6| Step: 1
Training loss: 0.16701270418006883
Validation loss: 2.303965187517175

Epoch: 6| Step: 2
Training loss: 0.17159818986808298
Validation loss: 2.3074302097489454

Epoch: 6| Step: 3
Training loss: 0.26244882981785667
Validation loss: 2.2857081484877027

Epoch: 6| Step: 4
Training loss: 0.23377259243447582
Validation loss: 2.294787950659691

Epoch: 6| Step: 5
Training loss: 0.13083730340687574
Validation loss: 2.2707124241181647

Epoch: 6| Step: 6
Training loss: 0.12764430063694215
Validation loss: 2.2881780506961578

Epoch: 6| Step: 7
Training loss: 0.15347457827175962
Validation loss: 2.307285569291093

Epoch: 6| Step: 8
Training loss: 0.12440742912155314
Validation loss: 2.3229561650663837

Epoch: 6| Step: 9
Training loss: 0.08412049595549784
Validation loss: 2.3433770449747064

Epoch: 6| Step: 10
Training loss: 0.09345144177406882
Validation loss: 2.350215338609095

Epoch: 6| Step: 11
Training loss: 0.10563597843573881
Validation loss: 2.338136608066248

Epoch: 6| Step: 12
Training loss: 0.12749415800323946
Validation loss: 2.353099896740574

Epoch: 6| Step: 13
Training loss: 0.12287277438824844
Validation loss: 2.3658771026568366

Epoch: 539| Step: 0
Training loss: 0.11942367855658147
Validation loss: 2.3593774545742763

Epoch: 6| Step: 1
Training loss: 0.10089244253179476
Validation loss: 2.361509070094802

Epoch: 6| Step: 2
Training loss: 0.10854012448258024
Validation loss: 2.372514524663152

Epoch: 6| Step: 3
Training loss: 0.18365219890260567
Validation loss: 2.392336945623765

Epoch: 6| Step: 4
Training loss: 0.17503075925393513
Validation loss: 2.3793123243070955

Epoch: 6| Step: 5
Training loss: 0.27711433001837205
Validation loss: 2.394204694090001

Epoch: 6| Step: 6
Training loss: 0.12004648624482837
Validation loss: 2.3633848626761416

Epoch: 6| Step: 7
Training loss: 0.11667066089003011
Validation loss: 2.3650853643824763

Epoch: 6| Step: 8
Training loss: 0.10732856946462471
Validation loss: 2.358231798122179

Epoch: 6| Step: 9
Training loss: 0.08335402320031342
Validation loss: 2.3777300035543067

Epoch: 6| Step: 10
Training loss: 0.09941986231945153
Validation loss: 2.304598442791649

Epoch: 6| Step: 11
Training loss: 0.1485164143954212
Validation loss: 2.320114930570428

Epoch: 6| Step: 12
Training loss: 0.14810482189505558
Validation loss: 2.3110672054854446

Epoch: 6| Step: 13
Training loss: 0.2142294771971309
Validation loss: 2.310572582863242

Epoch: 540| Step: 0
Training loss: 0.09343112917458529
Validation loss: 2.3156478108617193

Epoch: 6| Step: 1
Training loss: 0.15950859935555395
Validation loss: 2.284053132713993

Epoch: 6| Step: 2
Training loss: 0.15081758703670514
Validation loss: 2.279703103232738

Epoch: 6| Step: 3
Training loss: 0.26715960106001285
Validation loss: 2.313566232024609

Epoch: 6| Step: 4
Training loss: 0.13958232488433978
Validation loss: 2.300250595105482

Epoch: 6| Step: 5
Training loss: 0.1523227188069762
Validation loss: 2.3055496396949535

Epoch: 6| Step: 6
Training loss: 0.17883979862586594
Validation loss: 2.3003242058639892

Epoch: 6| Step: 7
Training loss: 0.10968088479892867
Validation loss: 2.314971594101002

Epoch: 6| Step: 8
Training loss: 0.1939551874357042
Validation loss: 2.339162938095695

Epoch: 6| Step: 9
Training loss: 0.10390536695119458
Validation loss: 2.3586860709782758

Epoch: 6| Step: 10
Training loss: 0.1201342593831117
Validation loss: 2.3656525017261676

Epoch: 6| Step: 11
Training loss: 0.09243133613387151
Validation loss: 2.36780296124209

Epoch: 6| Step: 12
Training loss: 0.10293930595089953
Validation loss: 2.3602489875604733

Epoch: 6| Step: 13
Training loss: 0.13784707275844812
Validation loss: 2.404253654770929

Epoch: 541| Step: 0
Training loss: 0.11009094385647045
Validation loss: 2.4159392350109803

Epoch: 6| Step: 1
Training loss: 0.26514509268616
Validation loss: 2.396767741603578

Epoch: 6| Step: 2
Training loss: 0.13737453133118704
Validation loss: 2.4360067517559996

Epoch: 6| Step: 3
Training loss: 0.1859010829043949
Validation loss: 2.3788462863549173

Epoch: 6| Step: 4
Training loss: 0.10726145122879116
Validation loss: 2.379334676343284

Epoch: 6| Step: 5
Training loss: 0.20185690972967765
Validation loss: 2.405970329308311

Epoch: 6| Step: 6
Training loss: 0.10692402609607257
Validation loss: 2.39588051883695

Epoch: 6| Step: 7
Training loss: 0.10233049525266429
Validation loss: 2.354462228164717

Epoch: 6| Step: 8
Training loss: 0.14527799391467053
Validation loss: 2.3348628018046105

Epoch: 6| Step: 9
Training loss: 0.1423608221332853
Validation loss: 2.3451554599815365

Epoch: 6| Step: 10
Training loss: 0.12255910288184448
Validation loss: 2.339317254736726

Epoch: 6| Step: 11
Training loss: 0.224313840075019
Validation loss: 2.359293719443191

Epoch: 6| Step: 12
Training loss: 0.20115283764879377
Validation loss: 2.335540083580814

Epoch: 6| Step: 13
Training loss: 0.17309608513234415
Validation loss: 2.338660586969551

Epoch: 542| Step: 0
Training loss: 0.17809510565752343
Validation loss: 2.3010563101613783

Epoch: 6| Step: 1
Training loss: 0.14523261884352956
Validation loss: 2.3493523836200265

Epoch: 6| Step: 2
Training loss: 0.09978270876577067
Validation loss: 2.339379200345702

Epoch: 6| Step: 3
Training loss: 0.16012020984895292
Validation loss: 2.343472899323351

Epoch: 6| Step: 4
Training loss: 0.23328578896012828
Validation loss: 2.3248773642826395

Epoch: 6| Step: 5
Training loss: 0.12230458476751564
Validation loss: 2.351966863208332

Epoch: 6| Step: 6
Training loss: 0.18181854681159904
Validation loss: 2.3246751579298675

Epoch: 6| Step: 7
Training loss: 0.12593329226182848
Validation loss: 2.3415913288987587

Epoch: 6| Step: 8
Training loss: 0.19269211589173174
Validation loss: 2.3194908100571934

Epoch: 6| Step: 9
Training loss: 0.13635757286731665
Validation loss: 2.3475357894810336

Epoch: 6| Step: 10
Training loss: 0.05422436285579476
Validation loss: 2.3164334488829113

Epoch: 6| Step: 11
Training loss: 0.11249134888102265
Validation loss: 2.3805029521524705

Epoch: 6| Step: 12
Training loss: 0.07759370752019253
Validation loss: 2.354899635810706

Epoch: 6| Step: 13
Training loss: 0.0756997521901972
Validation loss: 2.334744510858734

Epoch: 543| Step: 0
Training loss: 0.09148754596508386
Validation loss: 2.308275472523616

Epoch: 6| Step: 1
Training loss: 0.26429584283088753
Validation loss: 2.345095286517648

Epoch: 6| Step: 2
Training loss: 0.07849954587545366
Validation loss: 2.3465697982126787

Epoch: 6| Step: 3
Training loss: 0.15349114977612557
Validation loss: 2.3182674502768

Epoch: 6| Step: 4
Training loss: 0.09423252443904215
Validation loss: 2.3273594923188226

Epoch: 6| Step: 5
Training loss: 0.11759641749007231
Validation loss: 2.3360105667652085

Epoch: 6| Step: 6
Training loss: 0.1276374784766588
Validation loss: 2.348413909677257

Epoch: 6| Step: 7
Training loss: 0.1053402347295037
Validation loss: 2.3650381805353047

Epoch: 6| Step: 8
Training loss: 0.12072966817708335
Validation loss: 2.322523925842394

Epoch: 6| Step: 9
Training loss: 0.15903999189972975
Validation loss: 2.3711548762708436

Epoch: 6| Step: 10
Training loss: 0.18193033146864032
Validation loss: 2.3549112232785427

Epoch: 6| Step: 11
Training loss: 0.09066735482308995
Validation loss: 2.3346199042587035

Epoch: 6| Step: 12
Training loss: 0.12572132543096828
Validation loss: 2.328176365294186

Epoch: 6| Step: 13
Training loss: 0.2066216555651855
Validation loss: 2.3388113239152455

Epoch: 544| Step: 0
Training loss: 0.07441985340564276
Validation loss: 2.3250378731650816

Epoch: 6| Step: 1
Training loss: 0.1818197351729351
Validation loss: 2.3338801875548416

Epoch: 6| Step: 2
Training loss: 0.24890215295028695
Validation loss: 2.3411513077804678

Epoch: 6| Step: 3
Training loss: 0.1171503246469554
Validation loss: 2.351048996829178

Epoch: 6| Step: 4
Training loss: 0.12104576452161223
Validation loss: 2.32571167620915

Epoch: 6| Step: 5
Training loss: 0.11371678451659359
Validation loss: 2.3352128132321717

Epoch: 6| Step: 6
Training loss: 0.1001524612376672
Validation loss: 2.362637065299843

Epoch: 6| Step: 7
Training loss: 0.09620170731744485
Validation loss: 2.339834995223609

Epoch: 6| Step: 8
Training loss: 0.06893497367909157
Validation loss: 2.353873357016189

Epoch: 6| Step: 9
Training loss: 0.08579652776145938
Validation loss: 2.339970387920978

Epoch: 6| Step: 10
Training loss: 0.16195723276776028
Validation loss: 2.336651928118076

Epoch: 6| Step: 11
Training loss: 0.11120155735741341
Validation loss: 2.320797142023073

Epoch: 6| Step: 12
Training loss: 0.08255190186174745
Validation loss: 2.3322916635596123

Epoch: 6| Step: 13
Training loss: 0.22252183336921863
Validation loss: 2.3274823017631983

Epoch: 545| Step: 0
Training loss: 0.0996138721273669
Validation loss: 2.3223464308578934

Epoch: 6| Step: 1
Training loss: 0.1231065446497053
Validation loss: 2.3277158199354555

Epoch: 6| Step: 2
Training loss: 0.14447588762395822
Validation loss: 2.328659906827667

Epoch: 6| Step: 3
Training loss: 0.12468972664831138
Validation loss: 2.3289016751713105

Epoch: 6| Step: 4
Training loss: 0.1970486722620245
Validation loss: 2.32208613406807

Epoch: 6| Step: 5
Training loss: 0.2567157391576496
Validation loss: 2.333229029282792

Epoch: 6| Step: 6
Training loss: 0.07100140002122884
Validation loss: 2.331090470123971

Epoch: 6| Step: 7
Training loss: 0.10809908592175543
Validation loss: 2.362363966283904

Epoch: 6| Step: 8
Training loss: 0.10736094827738671
Validation loss: 2.3853517179508676

Epoch: 6| Step: 9
Training loss: 0.09680063215758172
Validation loss: 2.3668446589877923

Epoch: 6| Step: 10
Training loss: 0.08405251012439581
Validation loss: 2.3596268712092674

Epoch: 6| Step: 11
Training loss: 0.16493083859023408
Validation loss: 2.3814266904201604

Epoch: 6| Step: 12
Training loss: 0.08564480332404215
Validation loss: 2.3698750928933388

Epoch: 6| Step: 13
Training loss: 0.06367398153225552
Validation loss: 2.4087534084826294

Epoch: 546| Step: 0
Training loss: 0.0852778159802909
Validation loss: 2.376448843493985

Epoch: 6| Step: 1
Training loss: 0.09822984564823964
Validation loss: 2.3675396624570832

Epoch: 6| Step: 2
Training loss: 0.23537955374878478
Validation loss: 2.429864031915125

Epoch: 6| Step: 3
Training loss: 0.15625829674627753
Validation loss: 2.3842540160370373

Epoch: 6| Step: 4
Training loss: 0.1034064977261898
Validation loss: 2.3860175595763864

Epoch: 6| Step: 5
Training loss: 0.09224936381562607
Validation loss: 2.364932776860281

Epoch: 6| Step: 6
Training loss: 0.16353769036843016
Validation loss: 2.373073562977723

Epoch: 6| Step: 7
Training loss: 0.1661219873226929
Validation loss: 2.3917269294775383

Epoch: 6| Step: 8
Training loss: 0.09745002907230947
Validation loss: 2.391798745329651

Epoch: 6| Step: 9
Training loss: 0.09546527695464853
Validation loss: 2.370411476847684

Epoch: 6| Step: 10
Training loss: 0.11722071097571116
Validation loss: 2.369034551121212

Epoch: 6| Step: 11
Training loss: 0.08520500161241304
Validation loss: 2.3699573648682533

Epoch: 6| Step: 12
Training loss: 0.08949235946925144
Validation loss: 2.374065271899531

Epoch: 6| Step: 13
Training loss: 0.17815256700186635
Validation loss: 2.3825488453848074

Epoch: 547| Step: 0
Training loss: 0.1056338095941312
Validation loss: 2.3839436229939373

Epoch: 6| Step: 1
Training loss: 0.09647632171442651
Validation loss: 2.3493962439163276

Epoch: 6| Step: 2
Training loss: 0.14455052840044896
Validation loss: 2.3582176439998954

Epoch: 6| Step: 3
Training loss: 0.14968525204931668
Validation loss: 2.349166686981104

Epoch: 6| Step: 4
Training loss: 0.07623569553683437
Validation loss: 2.3608518565099725

Epoch: 6| Step: 5
Training loss: 0.24799594206047296
Validation loss: 2.369971854521885

Epoch: 6| Step: 6
Training loss: 0.08141098934424743
Validation loss: 2.3515237130408

Epoch: 6| Step: 7
Training loss: 0.09417601984477919
Validation loss: 2.3342642362799633

Epoch: 6| Step: 8
Training loss: 0.08281556474664692
Validation loss: 2.3553122697692364

Epoch: 6| Step: 9
Training loss: 0.17748614153019393
Validation loss: 2.34590993693603

Epoch: 6| Step: 10
Training loss: 0.07595990716733114
Validation loss: 2.315405843854199

Epoch: 6| Step: 11
Training loss: 0.19366772466031054
Validation loss: 2.3483026877928594

Epoch: 6| Step: 12
Training loss: 0.050947266414701556
Validation loss: 2.3498619111018595

Epoch: 6| Step: 13
Training loss: 0.10415975329186866
Validation loss: 2.3365247460678757

Epoch: 548| Step: 0
Training loss: 0.09138491699503634
Validation loss: 2.3758633290654947

Epoch: 6| Step: 1
Training loss: 0.14729609338681074
Validation loss: 2.3789714472447874

Epoch: 6| Step: 2
Training loss: 0.10605587721520894
Validation loss: 2.324881060527745

Epoch: 6| Step: 3
Training loss: 0.09397929185770743
Validation loss: 2.341267982952012

Epoch: 6| Step: 4
Training loss: 0.14849782019277255
Validation loss: 2.3683121368322633

Epoch: 6| Step: 5
Training loss: 0.25199960679068995
Validation loss: 2.3294308591186677

Epoch: 6| Step: 6
Training loss: 0.0888778187607237
Validation loss: 2.338375662474164

Epoch: 6| Step: 7
Training loss: 0.11772293317464579
Validation loss: 2.3583258697827647

Epoch: 6| Step: 8
Training loss: 0.12768022952851404
Validation loss: 2.35061909705348

Epoch: 6| Step: 9
Training loss: 0.12135888115753049
Validation loss: 2.3749190005278047

Epoch: 6| Step: 10
Training loss: 0.16825910356983362
Validation loss: 2.3257879273702358

Epoch: 6| Step: 11
Training loss: 0.10375812304823474
Validation loss: 2.3386152805687885

Epoch: 6| Step: 12
Training loss: 0.06364312693096003
Validation loss: 2.377012902365427

Epoch: 6| Step: 13
Training loss: 0.2108491694979496
Validation loss: 2.3390144553370615

Epoch: 549| Step: 0
Training loss: 0.0973450853185776
Validation loss: 2.3742211659156673

Epoch: 6| Step: 1
Training loss: 0.10933562830328962
Validation loss: 2.3593664855738203

Epoch: 6| Step: 2
Training loss: 0.0726931977925298
Validation loss: 2.3527295009780502

Epoch: 6| Step: 3
Training loss: 0.11310928133436199
Validation loss: 2.3644238233375763

Epoch: 6| Step: 4
Training loss: 0.14607560662197985
Validation loss: 2.379784715156236

Epoch: 6| Step: 5
Training loss: 0.09806325498287871
Validation loss: 2.3586399145059174

Epoch: 6| Step: 6
Training loss: 0.26210505884201274
Validation loss: 2.3597748152863898

Epoch: 6| Step: 7
Training loss: 0.07861669900229311
Validation loss: 2.365726961629986

Epoch: 6| Step: 8
Training loss: 0.08220244040237662
Validation loss: 2.387620816692912

Epoch: 6| Step: 9
Training loss: 0.12708755858099083
Validation loss: 2.3876624488208815

Epoch: 6| Step: 10
Training loss: 0.12937364949567323
Validation loss: 2.363861609895274

Epoch: 6| Step: 11
Training loss: 0.10979449343917955
Validation loss: 2.377040601667669

Epoch: 6| Step: 12
Training loss: 0.16365638491180845
Validation loss: 2.3695872034149867

Epoch: 6| Step: 13
Training loss: 0.17342486915474836
Validation loss: 2.404438643754471

Epoch: 550| Step: 0
Training loss: 0.16245930602310885
Validation loss: 2.3709611298959516

Epoch: 6| Step: 1
Training loss: 0.07752156564681786
Validation loss: 2.4031427428186634

Epoch: 6| Step: 2
Training loss: 0.08065385696193242
Validation loss: 2.3464182005168155

Epoch: 6| Step: 3
Training loss: 0.16378505840178953
Validation loss: 2.4039445787257363

Epoch: 6| Step: 4
Training loss: 0.10067695832610654
Validation loss: 2.3943605662417724

Epoch: 6| Step: 5
Training loss: 0.11887190171043927
Validation loss: 2.4049504268845516

Epoch: 6| Step: 6
Training loss: 0.08770753545900331
Validation loss: 2.421705730025975

Epoch: 6| Step: 7
Training loss: 0.1253623033191288
Validation loss: 2.3835961048416556

Epoch: 6| Step: 8
Training loss: 0.13101184559729528
Validation loss: 2.4103118292623327

Epoch: 6| Step: 9
Training loss: 0.2377767146075687
Validation loss: 2.3715860260205224

Epoch: 6| Step: 10
Training loss: 0.134016928874706
Validation loss: 2.3957688938657635

Epoch: 6| Step: 11
Training loss: 0.14114305650670503
Validation loss: 2.4070598708071542

Epoch: 6| Step: 12
Training loss: 0.08979340365828889
Validation loss: 2.417025140293448

Epoch: 6| Step: 13
Training loss: 0.12426505994962074
Validation loss: 2.3981426993508967

Epoch: 551| Step: 0
Training loss: 0.07664997191113687
Validation loss: 2.3724156185456304

Epoch: 6| Step: 1
Training loss: 0.15461536324553263
Validation loss: 2.3944753671009735

Epoch: 6| Step: 2
Training loss: 0.1852157951732006
Validation loss: 2.373449383910544

Epoch: 6| Step: 3
Training loss: 0.10839735494537034
Validation loss: 2.4071611810839375

Epoch: 6| Step: 4
Training loss: 0.13579246907037598
Validation loss: 2.390618753689809

Epoch: 6| Step: 5
Training loss: 0.13078275971355935
Validation loss: 2.358847501750403

Epoch: 6| Step: 6
Training loss: 0.07934836456530293
Validation loss: 2.361610764202035

Epoch: 6| Step: 7
Training loss: 0.16253116038392773
Validation loss: 2.344470418049629

Epoch: 6| Step: 8
Training loss: 0.11452689641351672
Validation loss: 2.365593846125002

Epoch: 6| Step: 9
Training loss: 0.11178783818075091
Validation loss: 2.3429169703741457

Epoch: 6| Step: 10
Training loss: 0.1109843929002896
Validation loss: 2.3074322535008394

Epoch: 6| Step: 11
Training loss: 0.08562922727024269
Validation loss: 2.3488245614616052

Epoch: 6| Step: 12
Training loss: 0.2550495523102957
Validation loss: 2.3294791455266863

Epoch: 6| Step: 13
Training loss: 0.1559815007208336
Validation loss: 2.3434892866271935

Epoch: 552| Step: 0
Training loss: 0.09958803191316468
Validation loss: 2.352142192761316

Epoch: 6| Step: 1
Training loss: 0.12293414598446203
Validation loss: 2.359616885532623

Epoch: 6| Step: 2
Training loss: 0.08458656007395443
Validation loss: 2.3435386896072172

Epoch: 6| Step: 3
Training loss: 0.11083270986848927
Validation loss: 2.341464096531192

Epoch: 6| Step: 4
Training loss: 0.20860271720328052
Validation loss: 2.371356410108933

Epoch: 6| Step: 5
Training loss: 0.10239662995550834
Validation loss: 2.3737464158981942

Epoch: 6| Step: 6
Training loss: 0.11174737056843222
Validation loss: 2.348053776417242

Epoch: 6| Step: 7
Training loss: 0.2503146932746342
Validation loss: 2.329217190300643

Epoch: 6| Step: 8
Training loss: 0.14052599494716234
Validation loss: 2.3456138446374797

Epoch: 6| Step: 9
Training loss: 0.16493471785920444
Validation loss: 2.338535974167078

Epoch: 6| Step: 10
Training loss: 0.1890355552041821
Validation loss: 2.3415037218302155

Epoch: 6| Step: 11
Training loss: 0.13437058419357462
Validation loss: 2.3331891035808425

Epoch: 6| Step: 12
Training loss: 0.13284072856477716
Validation loss: 2.3502553044918226

Epoch: 6| Step: 13
Training loss: 0.08528765800107951
Validation loss: 2.361770036872068

Epoch: 553| Step: 0
Training loss: 0.07678082863607055
Validation loss: 2.3754294330497996

Epoch: 6| Step: 1
Training loss: 0.08909309932346701
Validation loss: 2.409608410478881

Epoch: 6| Step: 2
Training loss: 0.10304543033596529
Validation loss: 2.4031147555074983

Epoch: 6| Step: 3
Training loss: 0.1267866510346076
Validation loss: 2.3852192822628235

Epoch: 6| Step: 4
Training loss: 0.14259525744828283
Validation loss: 2.3848824259910297

Epoch: 6| Step: 5
Training loss: 0.10609924423671499
Validation loss: 2.3842532773483835

Epoch: 6| Step: 6
Training loss: 0.11577218038220227
Validation loss: 2.3852004903346464

Epoch: 6| Step: 7
Training loss: 0.1422553916908276
Validation loss: 2.3753941451227787

Epoch: 6| Step: 8
Training loss: 0.15182889846961203
Validation loss: 2.380480912629928

Epoch: 6| Step: 9
Training loss: 0.14094657026103638
Validation loss: 2.3760489962875853

Epoch: 6| Step: 10
Training loss: 0.10118067014604525
Validation loss: 2.3585060593236813

Epoch: 6| Step: 11
Training loss: 0.2539366483831338
Validation loss: 2.3406636996159804

Epoch: 6| Step: 12
Training loss: 0.1757379955479444
Validation loss: 2.341548180220019

Epoch: 6| Step: 13
Training loss: 0.10635360652086116
Validation loss: 2.3357960614990114

Epoch: 554| Step: 0
Training loss: 0.12930942111500682
Validation loss: 2.3085401921757054

Epoch: 6| Step: 1
Training loss: 0.10623165000206868
Validation loss: 2.3314270576914953

Epoch: 6| Step: 2
Training loss: 0.12654145324807523
Validation loss: 2.3155140378930934

Epoch: 6| Step: 3
Training loss: 0.13758772847387185
Validation loss: 2.3449842024079355

Epoch: 6| Step: 4
Training loss: 0.069274892260849
Validation loss: 2.3307090679124074

Epoch: 6| Step: 5
Training loss: 0.23876731575092092
Validation loss: 2.331910666143922

Epoch: 6| Step: 6
Training loss: 0.07276905145394309
Validation loss: 2.3450302652578907

Epoch: 6| Step: 7
Training loss: 0.12159630871631813
Validation loss: 2.346220632027923

Epoch: 6| Step: 8
Training loss: 0.07849275044641532
Validation loss: 2.3215212584279827

Epoch: 6| Step: 9
Training loss: 0.15032251475354474
Validation loss: 2.3534748168996593

Epoch: 6| Step: 10
Training loss: 0.14211555458084046
Validation loss: 2.3406803103046188

Epoch: 6| Step: 11
Training loss: 0.12059942994848909
Validation loss: 2.353977289041327

Epoch: 6| Step: 12
Training loss: 0.18168690819868635
Validation loss: 2.3347860394241566

Epoch: 6| Step: 13
Training loss: 0.09095662664708865
Validation loss: 2.360043477787138

Epoch: 555| Step: 0
Training loss: 0.09674126176653806
Validation loss: 2.3316546772810276

Epoch: 6| Step: 1
Training loss: 0.1471246586020243
Validation loss: 2.3349148456385134

Epoch: 6| Step: 2
Training loss: 0.11623737290981855
Validation loss: 2.3408273304605323

Epoch: 6| Step: 3
Training loss: 0.10041098518081364
Validation loss: 2.3241974143454205

Epoch: 6| Step: 4
Training loss: 0.1513392145704865
Validation loss: 2.305714284830567

Epoch: 6| Step: 5
Training loss: 0.14355666619838026
Validation loss: 2.3157068968410894

Epoch: 6| Step: 6
Training loss: 0.1140399224654673
Validation loss: 2.3613639542545153

Epoch: 6| Step: 7
Training loss: 0.09286276883299362
Validation loss: 2.339039670571804

Epoch: 6| Step: 8
Training loss: 0.0952871390512399
Validation loss: 2.360176528879552

Epoch: 6| Step: 9
Training loss: 0.06416240061139693
Validation loss: 2.3541433948655586

Epoch: 6| Step: 10
Training loss: 0.2688889798387745
Validation loss: 2.3604755297355795

Epoch: 6| Step: 11
Training loss: 0.07580891969234986
Validation loss: 2.35871296709228

Epoch: 6| Step: 12
Training loss: 0.08916158434757211
Validation loss: 2.350031044326677

Epoch: 6| Step: 13
Training loss: 0.17348020539026798
Validation loss: 2.3708555624246106

Epoch: 556| Step: 0
Training loss: 0.09369337338690024
Validation loss: 2.3574643884187356

Epoch: 6| Step: 1
Training loss: 0.10235480146944326
Validation loss: 2.3447686386127438

Epoch: 6| Step: 2
Training loss: 0.10321426610132098
Validation loss: 2.372984830017451

Epoch: 6| Step: 3
Training loss: 0.10160609373425687
Validation loss: 2.3532404825951887

Epoch: 6| Step: 4
Training loss: 0.10414924674606436
Validation loss: 2.3567730538473284

Epoch: 6| Step: 5
Training loss: 0.06614275856956561
Validation loss: 2.3322411627501625

Epoch: 6| Step: 6
Training loss: 0.10020413201910318
Validation loss: 2.3256849402298645

Epoch: 6| Step: 7
Training loss: 0.08352891377351304
Validation loss: 2.357694277535429

Epoch: 6| Step: 8
Training loss: 0.08305469198929322
Validation loss: 2.366350786674058

Epoch: 6| Step: 9
Training loss: 0.12710116631297644
Validation loss: 2.367229220743089

Epoch: 6| Step: 10
Training loss: 0.10202690465766842
Validation loss: 2.3898376400402257

Epoch: 6| Step: 11
Training loss: 0.2655506170132062
Validation loss: 2.3745891710095495

Epoch: 6| Step: 12
Training loss: 0.2148218230415562
Validation loss: 2.3797575336429166

Epoch: 6| Step: 13
Training loss: 0.09031340948392695
Validation loss: 2.3907071123009787

Epoch: 557| Step: 0
Training loss: 0.15241071256416813
Validation loss: 2.402742874707944

Epoch: 6| Step: 1
Training loss: 0.1600516722173487
Validation loss: 2.3524403131362814

Epoch: 6| Step: 2
Training loss: 0.1505255094272646
Validation loss: 2.3799994136388714

Epoch: 6| Step: 3
Training loss: 0.06948991253942173
Validation loss: 2.3546778767885557

Epoch: 6| Step: 4
Training loss: 0.23022700416719077
Validation loss: 2.368322106413633

Epoch: 6| Step: 5
Training loss: 0.07995085080516699
Validation loss: 2.3512197537781803

Epoch: 6| Step: 6
Training loss: 0.11651246038658648
Validation loss: 2.3580132139949805

Epoch: 6| Step: 7
Training loss: 0.0969519298181632
Validation loss: 2.3406995894425022

Epoch: 6| Step: 8
Training loss: 0.12623642578187327
Validation loss: 2.348805281343111

Epoch: 6| Step: 9
Training loss: 0.1033539859580734
Validation loss: 2.3522743230028125

Epoch: 6| Step: 10
Training loss: 0.10597606347371154
Validation loss: 2.369885451822864

Epoch: 6| Step: 11
Training loss: 0.12153843017470525
Validation loss: 2.3497346410558566

Epoch: 6| Step: 12
Training loss: 0.07702419682995267
Validation loss: 2.3754475166006657

Epoch: 6| Step: 13
Training loss: 0.14087115043383222
Validation loss: 2.3819346262735266

Epoch: 558| Step: 0
Training loss: 0.22845295103658883
Validation loss: 2.3621070189463507

Epoch: 6| Step: 1
Training loss: 0.11657461992487549
Validation loss: 2.403963035373426

Epoch: 6| Step: 2
Training loss: 0.0906279896374559
Validation loss: 2.38219730713984

Epoch: 6| Step: 3
Training loss: 0.08953733644884598
Validation loss: 2.3761929385677187

Epoch: 6| Step: 4
Training loss: 0.07674190997143729
Validation loss: 2.4119404804441675

Epoch: 6| Step: 5
Training loss: 0.07551530771210543
Validation loss: 2.4290136320700855

Epoch: 6| Step: 6
Training loss: 0.10691800286889443
Validation loss: 2.401905727463326

Epoch: 6| Step: 7
Training loss: 0.15256572104573476
Validation loss: 2.4253073830834806

Epoch: 6| Step: 8
Training loss: 0.0789768979149127
Validation loss: 2.3613675999011736

Epoch: 6| Step: 9
Training loss: 0.14874869903027593
Validation loss: 2.4015213895512426

Epoch: 6| Step: 10
Training loss: 0.08517218504121286
Validation loss: 2.3728149889539183

Epoch: 6| Step: 11
Training loss: 0.15876037272785234
Validation loss: 2.3468853729081296

Epoch: 6| Step: 12
Training loss: 0.14980530471376197
Validation loss: 2.373216182574134

Epoch: 6| Step: 13
Training loss: 0.04798070840854136
Validation loss: 2.353476584833252

Epoch: 559| Step: 0
Training loss: 0.14586580005913685
Validation loss: 2.3544139978971637

Epoch: 6| Step: 1
Training loss: 0.09161056726438814
Validation loss: 2.373506980215528

Epoch: 6| Step: 2
Training loss: 0.07444763339965843
Validation loss: 2.34067948064919

Epoch: 6| Step: 3
Training loss: 0.09838681657049976
Validation loss: 2.3341511726546837

Epoch: 6| Step: 4
Training loss: 0.09089010899662718
Validation loss: 2.3434388652182436

Epoch: 6| Step: 5
Training loss: 0.12890002206727455
Validation loss: 2.3608923101495027

Epoch: 6| Step: 6
Training loss: 0.10976667607303098
Validation loss: 2.346857465708529

Epoch: 6| Step: 7
Training loss: 0.09536038548188715
Validation loss: 2.3694842179129267

Epoch: 6| Step: 8
Training loss: 0.23148814742548132
Validation loss: 2.34207562979526

Epoch: 6| Step: 9
Training loss: 0.14429937914011237
Validation loss: 2.3727740217131488

Epoch: 6| Step: 10
Training loss: 0.14397860883404984
Validation loss: 2.3865631134941574

Epoch: 6| Step: 11
Training loss: 0.09628945402797
Validation loss: 2.373438849351528

Epoch: 6| Step: 12
Training loss: 0.08768537184653936
Validation loss: 2.370690835730079

Epoch: 6| Step: 13
Training loss: 0.09906867008067625
Validation loss: 2.4006500796791594

Epoch: 560| Step: 0
Training loss: 0.229733287697921
Validation loss: 2.3692491417229498

Epoch: 6| Step: 1
Training loss: 0.11107352490490963
Validation loss: 2.392109674162307

Epoch: 6| Step: 2
Training loss: 0.08664247051213499
Validation loss: 2.421065466656691

Epoch: 6| Step: 3
Training loss: 0.11792719563861656
Validation loss: 2.3869183618343737

Epoch: 6| Step: 4
Training loss: 0.07630782344479115
Validation loss: 2.419362366674873

Epoch: 6| Step: 5
Training loss: 0.11031508053687143
Validation loss: 2.4243860834996522

Epoch: 6| Step: 6
Training loss: 0.1619637996175408
Validation loss: 2.424739006133224

Epoch: 6| Step: 7
Training loss: 0.07292901158849667
Validation loss: 2.4133228475489843

Epoch: 6| Step: 8
Training loss: 0.14469018136540993
Validation loss: 2.427756382593939

Epoch: 6| Step: 9
Training loss: 0.1493350050465786
Validation loss: 2.4354153109517167

Epoch: 6| Step: 10
Training loss: 0.21248152561382502
Validation loss: 2.4142384520578335

Epoch: 6| Step: 11
Training loss: 0.06664937056994007
Validation loss: 2.383168068078148

Epoch: 6| Step: 12
Training loss: 0.07278120245692435
Validation loss: 2.384965348706909

Epoch: 6| Step: 13
Training loss: 0.09938231000465113
Validation loss: 2.4038127834569036

Epoch: 561| Step: 0
Training loss: 0.06428756184645432
Validation loss: 2.4155473850495692

Epoch: 6| Step: 1
Training loss: 0.140197906693345
Validation loss: 2.3407297955702004

Epoch: 6| Step: 2
Training loss: 0.1898367527272663
Validation loss: 2.370137267192013

Epoch: 6| Step: 3
Training loss: 0.0870765790014921
Validation loss: 2.367765686539632

Epoch: 6| Step: 4
Training loss: 0.09976604706533795
Validation loss: 2.379248016721152

Epoch: 6| Step: 5
Training loss: 0.12268765557707272
Validation loss: 2.3580920110264776

Epoch: 6| Step: 6
Training loss: 0.11547840674881107
Validation loss: 2.371287563379614

Epoch: 6| Step: 7
Training loss: 0.261306680275563
Validation loss: 2.378881628684762

Epoch: 6| Step: 8
Training loss: 0.08989344134892746
Validation loss: 2.389026611782252

Epoch: 6| Step: 9
Training loss: 0.084376429174823
Validation loss: 2.374558989117897

Epoch: 6| Step: 10
Training loss: 0.11943310654073734
Validation loss: 2.3815244284058807

Epoch: 6| Step: 11
Training loss: 0.08273037378471504
Validation loss: 2.3862138415536553

Epoch: 6| Step: 12
Training loss: 0.0829018589806
Validation loss: 2.403378289505574

Epoch: 6| Step: 13
Training loss: 0.08426780060966317
Validation loss: 2.400191986188302

Epoch: 562| Step: 0
Training loss: 0.0651553258956126
Validation loss: 2.3966770956613006

Epoch: 6| Step: 1
Training loss: 0.14201093888334243
Validation loss: 2.3643919633456325

Epoch: 6| Step: 2
Training loss: 0.15793820558457541
Validation loss: 2.3911969619077773

Epoch: 6| Step: 3
Training loss: 0.13788752971125284
Validation loss: 2.400058618679087

Epoch: 6| Step: 4
Training loss: 0.23930416047516223
Validation loss: 2.3998418327309627

Epoch: 6| Step: 5
Training loss: 0.12560287023272707
Validation loss: 2.378053771156905

Epoch: 6| Step: 6
Training loss: 0.15604600106366345
Validation loss: 2.3955070285881033

Epoch: 6| Step: 7
Training loss: 0.13094266688956915
Validation loss: 2.376818385565411

Epoch: 6| Step: 8
Training loss: 0.08867534429006362
Validation loss: 2.3818364153903158

Epoch: 6| Step: 9
Training loss: 0.14805457012137038
Validation loss: 2.370892139770022

Epoch: 6| Step: 10
Training loss: 0.17822950167116317
Validation loss: 2.3842016051327852

Epoch: 6| Step: 11
Training loss: 0.11926874713516891
Validation loss: 2.3926374245335684

Epoch: 6| Step: 12
Training loss: 0.11872230241279914
Validation loss: 2.3884320829512515

Epoch: 6| Step: 13
Training loss: 0.10906100757829282
Validation loss: 2.3681472930297547

Epoch: 563| Step: 0
Training loss: 0.09826339337342321
Validation loss: 2.423005165406249

Epoch: 6| Step: 1
Training loss: 0.1464833259544956
Validation loss: 2.422317121561913

Epoch: 6| Step: 2
Training loss: 0.14123182366530615
Validation loss: 2.3852317187749215

Epoch: 6| Step: 3
Training loss: 0.23661832882615383
Validation loss: 2.4253964949852618

Epoch: 6| Step: 4
Training loss: 0.13142684052860062
Validation loss: 2.3998477049160125

Epoch: 6| Step: 5
Training loss: 0.10586339795115432
Validation loss: 2.3858257137690093

Epoch: 6| Step: 6
Training loss: 0.09533756368222829
Validation loss: 2.4079411773231656

Epoch: 6| Step: 7
Training loss: 0.08670977898323955
Validation loss: 2.3879760805269337

Epoch: 6| Step: 8
Training loss: 0.05557838547138568
Validation loss: 2.359969980809522

Epoch: 6| Step: 9
Training loss: 0.08222811781257247
Validation loss: 2.3296008159470287

Epoch: 6| Step: 10
Training loss: 0.16214403678125533
Validation loss: 2.3470893008617586

Epoch: 6| Step: 11
Training loss: 0.2151582929587627
Validation loss: 2.3371759283578264

Epoch: 6| Step: 12
Training loss: 0.09704135908150699
Validation loss: 2.34280561008638

Epoch: 6| Step: 13
Training loss: 0.21064685295003338
Validation loss: 2.3638066244040004

Epoch: 564| Step: 0
Training loss: 0.21526351149948092
Validation loss: 2.358182910597863

Epoch: 6| Step: 1
Training loss: 0.16285728941373187
Validation loss: 2.3497824485930416

Epoch: 6| Step: 2
Training loss: 0.08617856071523311
Validation loss: 2.349990617536545

Epoch: 6| Step: 3
Training loss: 0.08688263914428683
Validation loss: 2.3771085548865702

Epoch: 6| Step: 4
Training loss: 0.06079879006306153
Validation loss: 2.421786156545455

Epoch: 6| Step: 5
Training loss: 0.08726170482385218
Validation loss: 2.4126767463087373

Epoch: 6| Step: 6
Training loss: 0.13597405479286387
Validation loss: 2.4373740559937627

Epoch: 6| Step: 7
Training loss: 0.17576592166613464
Validation loss: 2.439920477839643

Epoch: 6| Step: 8
Training loss: 0.18101154624087606
Validation loss: 2.438183909144459

Epoch: 6| Step: 9
Training loss: 0.08434435853176789
Validation loss: 2.4210793583196497

Epoch: 6| Step: 10
Training loss: 0.07810222174459824
Validation loss: 2.3985261790158097

Epoch: 6| Step: 11
Training loss: 0.2543786276387601
Validation loss: 2.3773194263524635

Epoch: 6| Step: 12
Training loss: 0.1341381808387641
Validation loss: 2.3927595665185897

Epoch: 6| Step: 13
Training loss: 0.18906650223712515
Validation loss: 2.3709648151193385

Epoch: 565| Step: 0
Training loss: 0.14594422889528963
Validation loss: 2.3828854505808943

Epoch: 6| Step: 1
Training loss: 0.1501300957892449
Validation loss: 2.369609650431874

Epoch: 6| Step: 2
Training loss: 0.20161176936922873
Validation loss: 2.3663620087670396

Epoch: 6| Step: 3
Training loss: 0.18141408349734367
Validation loss: 2.3538858850817563

Epoch: 6| Step: 4
Training loss: 0.2762318741560963
Validation loss: 2.349658007752614

Epoch: 6| Step: 5
Training loss: 0.11760604739128362
Validation loss: 2.380726553730011

Epoch: 6| Step: 6
Training loss: 0.1527881864111143
Validation loss: 2.3611812516189

Epoch: 6| Step: 7
Training loss: 0.0642984151829557
Validation loss: 2.361804275739169

Epoch: 6| Step: 8
Training loss: 0.1621626398754024
Validation loss: 2.3539340613692104

Epoch: 6| Step: 9
Training loss: 0.09394794666618164
Validation loss: 2.3332056565079564

Epoch: 6| Step: 10
Training loss: 0.17084126197241103
Validation loss: 2.3482786184269844

Epoch: 6| Step: 11
Training loss: 0.13776364896572238
Validation loss: 2.306293083033277

Epoch: 6| Step: 12
Training loss: 0.08737063232203157
Validation loss: 2.332283021132013

Epoch: 6| Step: 13
Training loss: 0.09126521421345599
Validation loss: 2.3281954413096826

Epoch: 566| Step: 0
Training loss: 0.1170690533949279
Validation loss: 2.357923943913908

Epoch: 6| Step: 1
Training loss: 0.28041301800497154
Validation loss: 2.345147946103485

Epoch: 6| Step: 2
Training loss: 0.11233987671564355
Validation loss: 2.3585352781576887

Epoch: 6| Step: 3
Training loss: 0.2198062328435478
Validation loss: 2.3402270632537263

Epoch: 6| Step: 4
Training loss: 0.2138934968416567
Validation loss: 2.3358419455517

Epoch: 6| Step: 5
Training loss: 0.18257851624681554
Validation loss: 2.336416439802753

Epoch: 6| Step: 6
Training loss: 0.16891527735805795
Validation loss: 2.343605067649717

Epoch: 6| Step: 7
Training loss: 0.3753935020884316
Validation loss: 2.358056426683555

Epoch: 6| Step: 8
Training loss: 0.12266287983148735
Validation loss: 2.3693522694468365

Epoch: 6| Step: 9
Training loss: 0.17061113458406083
Validation loss: 2.373422520854669

Epoch: 6| Step: 10
Training loss: 0.11448960552863813
Validation loss: 2.342071406816991

Epoch: 6| Step: 11
Training loss: 0.1405292821012187
Validation loss: 2.347093980661265

Epoch: 6| Step: 12
Training loss: 0.1323422915796046
Validation loss: 2.3713821679282927

Epoch: 6| Step: 13
Training loss: 0.21641092915072555
Validation loss: 2.3528708694909475

Epoch: 567| Step: 0
Training loss: 0.1800455485934582
Validation loss: 2.3676704838076983

Epoch: 6| Step: 1
Training loss: 0.10518381695524118
Validation loss: 2.370328949164346

Epoch: 6| Step: 2
Training loss: 0.10840955024324166
Validation loss: 2.3439779639727383

Epoch: 6| Step: 3
Training loss: 0.13800112265669234
Validation loss: 2.3476598776212123

Epoch: 6| Step: 4
Training loss: 0.1629629528005714
Validation loss: 2.321852824246647

Epoch: 6| Step: 5
Training loss: 0.13041736196092915
Validation loss: 2.3042402091683796

Epoch: 6| Step: 6
Training loss: 0.1914904856708724
Validation loss: 2.3231678253086874

Epoch: 6| Step: 7
Training loss: 0.12835054839718849
Validation loss: 2.3153507240670783

Epoch: 6| Step: 8
Training loss: 0.21675307028926732
Validation loss: 2.325000554584318

Epoch: 6| Step: 9
Training loss: 0.24007739388788724
Validation loss: 2.3359316345200467

Epoch: 6| Step: 10
Training loss: 0.12996609964486536
Validation loss: 2.346564202392345

Epoch: 6| Step: 11
Training loss: 0.1623179920311765
Validation loss: 2.3067326140764366

Epoch: 6| Step: 12
Training loss: 0.12868349017102113
Validation loss: 2.3506702336560847

Epoch: 6| Step: 13
Training loss: 0.14885746999478427
Validation loss: 2.3413892115727757

Epoch: 568| Step: 0
Training loss: 0.131530556379897
Validation loss: 2.3591436549628515

Epoch: 6| Step: 1
Training loss: 0.16370674003220728
Validation loss: 2.3462586177834814

Epoch: 6| Step: 2
Training loss: 0.11625602392514389
Validation loss: 2.358178008744157

Epoch: 6| Step: 3
Training loss: 0.11849094528072257
Validation loss: 2.3677886044824943

Epoch: 6| Step: 4
Training loss: 0.1455249136277837
Validation loss: 2.3492069609842985

Epoch: 6| Step: 5
Training loss: 0.13081518537350395
Validation loss: 2.340388377204179

Epoch: 6| Step: 6
Training loss: 0.17116531242838082
Validation loss: 2.3016302633349075

Epoch: 6| Step: 7
Training loss: 0.12101802457840162
Validation loss: 2.3094558057158303

Epoch: 6| Step: 8
Training loss: 0.20873492496274396
Validation loss: 2.295984521521112

Epoch: 6| Step: 9
Training loss: 0.10580622581034592
Validation loss: 2.3108246720307553

Epoch: 6| Step: 10
Training loss: 0.1807245101841864
Validation loss: 2.3370535158644845

Epoch: 6| Step: 11
Training loss: 0.09992255270297892
Validation loss: 2.338582677614275

Epoch: 6| Step: 12
Training loss: 0.27854690697095735
Validation loss: 2.3710744157966395

Epoch: 6| Step: 13
Training loss: 0.24241254717884855
Validation loss: 2.3691507268976566

Epoch: 569| Step: 0
Training loss: 0.12096522032028419
Validation loss: 2.344995195500324

Epoch: 6| Step: 1
Training loss: 0.15600781745457892
Validation loss: 2.3285483172063004

Epoch: 6| Step: 2
Training loss: 0.10952010917055295
Validation loss: 2.3526001663332186

Epoch: 6| Step: 3
Training loss: 0.17844261287372187
Validation loss: 2.3395267712658767

Epoch: 6| Step: 4
Training loss: 0.17871052059270873
Validation loss: 2.353313348746233

Epoch: 6| Step: 5
Training loss: 0.17572367042994225
Validation loss: 2.3401884674554356

Epoch: 6| Step: 6
Training loss: 0.23963456366313327
Validation loss: 2.3487789452171746

Epoch: 6| Step: 7
Training loss: 0.0779785930176926
Validation loss: 2.4008530452426893

Epoch: 6| Step: 8
Training loss: 0.19269368184728042
Validation loss: 2.3875539336222245

Epoch: 6| Step: 9
Training loss: 0.36598548561510397
Validation loss: 2.425048401432749

Epoch: 6| Step: 10
Training loss: 0.2111264901004151
Validation loss: 2.4215868484396244

Epoch: 6| Step: 11
Training loss: 0.16532034294690942
Validation loss: 2.410432947886099

Epoch: 6| Step: 12
Training loss: 0.1432429711596355
Validation loss: 2.3980007337111178

Epoch: 6| Step: 13
Training loss: 0.16743891342267087
Validation loss: 2.4013237538679433

Epoch: 570| Step: 0
Training loss: 0.11165857628556439
Validation loss: 2.413330688273988

Epoch: 6| Step: 1
Training loss: 0.2325615743527935
Validation loss: 2.376952653677677

Epoch: 6| Step: 2
Training loss: 0.15219150173714643
Validation loss: 2.3840394367147253

Epoch: 6| Step: 3
Training loss: 0.40602988001726553
Validation loss: 2.4008746372115466

Epoch: 6| Step: 4
Training loss: 0.2103976210781282
Validation loss: 2.364754475517708

Epoch: 6| Step: 5
Training loss: 0.180200218466331
Validation loss: 2.3362109415575607

Epoch: 6| Step: 6
Training loss: 0.23506693427039901
Validation loss: 2.324632826198801

Epoch: 6| Step: 7
Training loss: 0.1257570261167889
Validation loss: 2.3376622834463316

Epoch: 6| Step: 8
Training loss: 0.13253387508477493
Validation loss: 2.3095570678511543

Epoch: 6| Step: 9
Training loss: 0.1759554741318729
Validation loss: 2.334320739955838

Epoch: 6| Step: 10
Training loss: 0.31134241997460477
Validation loss: 2.3066423632562327

Epoch: 6| Step: 11
Training loss: 0.27879354833837244
Validation loss: 2.335864269614877

Epoch: 6| Step: 12
Training loss: 0.11984937943089814
Validation loss: 2.346738445518703

Epoch: 6| Step: 13
Training loss: 0.1050377800218762
Validation loss: 2.308643805325896

Epoch: 571| Step: 0
Training loss: 0.1343400843302769
Validation loss: 2.325739031368575

Epoch: 6| Step: 1
Training loss: 0.2191191861686499
Validation loss: 2.289829006960625

Epoch: 6| Step: 2
Training loss: 0.2564038750900572
Validation loss: 2.3105006051183676

Epoch: 6| Step: 3
Training loss: 0.22969805634821755
Validation loss: 2.309899582777555

Epoch: 6| Step: 4
Training loss: 0.11829413198974836
Validation loss: 2.297419709673241

Epoch: 6| Step: 5
Training loss: 0.14362924936049137
Validation loss: 2.3112741617500596

Epoch: 6| Step: 6
Training loss: 0.10810128283990028
Validation loss: 2.2775695477208013

Epoch: 6| Step: 7
Training loss: 0.31720571418668697
Validation loss: 2.2933093033643184

Epoch: 6| Step: 8
Training loss: 0.1867476907750745
Validation loss: 2.330565778145606

Epoch: 6| Step: 9
Training loss: 0.2655773400577159
Validation loss: 2.3070728614268985

Epoch: 6| Step: 10
Training loss: 0.1688593276288448
Validation loss: 2.3261867387816304

Epoch: 6| Step: 11
Training loss: 0.19720679057294455
Validation loss: 2.3383367316054744

Epoch: 6| Step: 12
Training loss: 0.17102657418992412
Validation loss: 2.3439328423828503

Epoch: 6| Step: 13
Training loss: 0.1501588831798686
Validation loss: 2.3778736613344362

Epoch: 572| Step: 0
Training loss: 0.19516458632513903
Validation loss: 2.3754925327772862

Epoch: 6| Step: 1
Training loss: 0.20060002427005907
Validation loss: 2.3895483325009512

Epoch: 6| Step: 2
Training loss: 0.24590142621685132
Validation loss: 2.381118356673919

Epoch: 6| Step: 3
Training loss: 0.11557406531131727
Validation loss: 2.3807825332187167

Epoch: 6| Step: 4
Training loss: 0.1388892498276577
Validation loss: 2.3661739389183767

Epoch: 6| Step: 5
Training loss: 0.22557505461628627
Validation loss: 2.4161978784262796

Epoch: 6| Step: 6
Training loss: 0.08669489111329119
Validation loss: 2.41075396695293

Epoch: 6| Step: 7
Training loss: 0.37974328074811053
Validation loss: 2.3833242064970386

Epoch: 6| Step: 8
Training loss: 0.151844895169528
Validation loss: 2.371429256900971

Epoch: 6| Step: 9
Training loss: 0.10675261262554248
Validation loss: 2.362260553010557

Epoch: 6| Step: 10
Training loss: 0.33614643386292264
Validation loss: 2.364282170810785

Epoch: 6| Step: 11
Training loss: 0.3852982102750789
Validation loss: 2.345745737144485

Epoch: 6| Step: 12
Training loss: 0.1995367055996975
Validation loss: 2.3458924453075816

Epoch: 6| Step: 13
Training loss: 0.11369833130381538
Validation loss: 2.3245243237352495

Epoch: 573| Step: 0
Training loss: 0.26540994353190756
Validation loss: 2.295291335981991

Epoch: 6| Step: 1
Training loss: 0.24655850742042257
Validation loss: 2.3281547895200663

Epoch: 6| Step: 2
Training loss: 0.33324457516729844
Validation loss: 2.32210836018859

Epoch: 6| Step: 3
Training loss: 0.23466222171040502
Validation loss: 2.406829433942632

Epoch: 6| Step: 4
Training loss: 0.2010230652862515
Validation loss: 2.394621821936568

Epoch: 6| Step: 5
Training loss: 0.2626724375014817
Validation loss: 2.3916508581236378

Epoch: 6| Step: 6
Training loss: 0.2014904647563588
Validation loss: 2.3818183017734325

Epoch: 6| Step: 7
Training loss: 0.26732920463852805
Validation loss: 2.408104654701859

Epoch: 6| Step: 8
Training loss: 0.29867716946949474
Validation loss: 2.4633531466867327

Epoch: 6| Step: 9
Training loss: 0.22422420814064703
Validation loss: 2.421763996249238

Epoch: 6| Step: 10
Training loss: 0.19122140093999915
Validation loss: 2.4232468820330273

Epoch: 6| Step: 11
Training loss: 0.26963915945285816
Validation loss: 2.389274339477436

Epoch: 6| Step: 12
Training loss: 0.19554130503593065
Validation loss: 2.355808143882242

Epoch: 6| Step: 13
Training loss: 0.16664373841129182
Validation loss: 2.3435568059236456

Epoch: 574| Step: 0
Training loss: 0.19960855233756372
Validation loss: 2.3387641701309834

Epoch: 6| Step: 1
Training loss: 0.3196993402020552
Validation loss: 2.3546779192495584

Epoch: 6| Step: 2
Training loss: 0.21238465509532736
Validation loss: 2.369801042969356

Epoch: 6| Step: 3
Training loss: 0.36052701653607705
Validation loss: 2.3725949914063698

Epoch: 6| Step: 4
Training loss: 0.23927407501381892
Validation loss: 2.3584742433072527

Epoch: 6| Step: 5
Training loss: 0.16918874853298452
Validation loss: 2.3896295377175183

Epoch: 6| Step: 6
Training loss: 0.23570294879303624
Validation loss: 2.398350560042629

Epoch: 6| Step: 7
Training loss: 0.1964929195844065
Validation loss: 2.431573504115299

Epoch: 6| Step: 8
Training loss: 0.2944220039275483
Validation loss: 2.482109888979601

Epoch: 6| Step: 9
Training loss: 0.25667326094054127
Validation loss: 2.4651396159279333

Epoch: 6| Step: 10
Training loss: 0.4050493103196644
Validation loss: 2.4898739988027083

Epoch: 6| Step: 11
Training loss: 0.23518501023488436
Validation loss: 2.4698195502417106

Epoch: 6| Step: 12
Training loss: 0.2809428551219726
Validation loss: 2.4662726685500727

Epoch: 6| Step: 13
Training loss: 0.20760778009269018
Validation loss: 2.482270586563408

Epoch: 575| Step: 0
Training loss: 0.3108173967478539
Validation loss: 2.4418666694548756

Epoch: 6| Step: 1
Training loss: 0.23792623431903784
Validation loss: 2.423089190186825

Epoch: 6| Step: 2
Training loss: 0.2934788142036283
Validation loss: 2.391755157230841

Epoch: 6| Step: 3
Training loss: 0.22286519904043064
Validation loss: 2.346434029707127

Epoch: 6| Step: 4
Training loss: 0.32179520691997066
Validation loss: 2.3517896848890225

Epoch: 6| Step: 5
Training loss: 0.246422185170902
Validation loss: 2.358030317821188

Epoch: 6| Step: 6
Training loss: 0.20732017365802555
Validation loss: 2.373026152286975

Epoch: 6| Step: 7
Training loss: 0.1834525722114871
Validation loss: 2.34532991707684

Epoch: 6| Step: 8
Training loss: 0.25204395165219323
Validation loss: 2.35798727317257

Epoch: 6| Step: 9
Training loss: 0.2790514928434693
Validation loss: 2.329851500146456

Epoch: 6| Step: 10
Training loss: 0.2404450291589392
Validation loss: 2.3601239477209255

Epoch: 6| Step: 11
Training loss: 0.31076307388402435
Validation loss: 2.364331543764358

Epoch: 6| Step: 12
Training loss: 0.24834371061985985
Validation loss: 2.3620972781844123

Epoch: 6| Step: 13
Training loss: 0.15971065382308783
Validation loss: 2.3460118242267645

Epoch: 576| Step: 0
Training loss: 0.21652305769538638
Validation loss: 2.3598631796761476

Epoch: 6| Step: 1
Training loss: 0.2979535537949496
Validation loss: 2.344279975721188

Epoch: 6| Step: 2
Training loss: 0.2071909468494999
Validation loss: 2.342659887203962

Epoch: 6| Step: 3
Training loss: 0.1796681041200735
Validation loss: 2.35529470102544

Epoch: 6| Step: 4
Training loss: 0.1485963648897934
Validation loss: 2.3396128399597336

Epoch: 6| Step: 5
Training loss: 0.19730589238480326
Validation loss: 2.3529155314889705

Epoch: 6| Step: 6
Training loss: 0.2655066338642467
Validation loss: 2.3417664034760657

Epoch: 6| Step: 7
Training loss: 0.23141624976426117
Validation loss: 2.292235201195373

Epoch: 6| Step: 8
Training loss: 0.2271548945131582
Validation loss: 2.2760034031696468

Epoch: 6| Step: 9
Training loss: 0.3377238176095692
Validation loss: 2.2707684738983347

Epoch: 6| Step: 10
Training loss: 0.2313164944029428
Validation loss: 2.272006582329817

Epoch: 6| Step: 11
Training loss: 0.2128767043995791
Validation loss: 2.2780992655559036

Epoch: 6| Step: 12
Training loss: 0.24714312780882822
Validation loss: 2.2614158560593904

Epoch: 6| Step: 13
Training loss: 0.30029496603200756
Validation loss: 2.248989987162108

Epoch: 577| Step: 0
Training loss: 0.2961259728766354
Validation loss: 2.2515122482855223

Epoch: 6| Step: 1
Training loss: 0.2582293233118253
Validation loss: 2.2768705086667445

Epoch: 6| Step: 2
Training loss: 0.18632272836479424
Validation loss: 2.268432151111708

Epoch: 6| Step: 3
Training loss: 0.29547436229231283
Validation loss: 2.2795200618408136

Epoch: 6| Step: 4
Training loss: 0.2902489875411086
Validation loss: 2.280661987723811

Epoch: 6| Step: 5
Training loss: 0.36746965889664635
Validation loss: 2.328689581617374

Epoch: 6| Step: 6
Training loss: 0.2586304952554814
Validation loss: 2.3212310518572012

Epoch: 6| Step: 7
Training loss: 0.2379103494243622
Validation loss: 2.3551770944976322

Epoch: 6| Step: 8
Training loss: 0.2019144998945302
Validation loss: 2.3518698371598425

Epoch: 6| Step: 9
Training loss: 0.21127683225057722
Validation loss: 2.372522120976948

Epoch: 6| Step: 10
Training loss: 0.1671644571503528
Validation loss: 2.3596682921400824

Epoch: 6| Step: 11
Training loss: 0.23105938439903745
Validation loss: 2.3117624252324442

Epoch: 6| Step: 12
Training loss: 0.284967451432929
Validation loss: 2.3029689548785113

Epoch: 6| Step: 13
Training loss: 0.20912041202718004
Validation loss: 2.298423135414096

Epoch: 578| Step: 0
Training loss: 0.366203369062417
Validation loss: 2.313662161857972

Epoch: 6| Step: 1
Training loss: 0.25222611239249715
Validation loss: 2.2640964532771295

Epoch: 6| Step: 2
Training loss: 0.3337068129397012
Validation loss: 2.2978262779653833

Epoch: 6| Step: 3
Training loss: 0.1705907394959732
Validation loss: 2.3054752416995354

Epoch: 6| Step: 4
Training loss: 0.19048664512780392
Validation loss: 2.319263200414866

Epoch: 6| Step: 5
Training loss: 0.11940555352519783
Validation loss: 2.3317615005843764

Epoch: 6| Step: 6
Training loss: 0.20284900805449643
Validation loss: 2.311832361534294

Epoch: 6| Step: 7
Training loss: 0.18516975023651852
Validation loss: 2.3229446047094204

Epoch: 6| Step: 8
Training loss: 0.24789468346563726
Validation loss: 2.3361508400326665

Epoch: 6| Step: 9
Training loss: 0.2052876991087043
Validation loss: 2.345302081549004

Epoch: 6| Step: 10
Training loss: 0.21415386408143772
Validation loss: 2.3168432350651944

Epoch: 6| Step: 11
Training loss: 0.1916571937859991
Validation loss: 2.3781203737836867

Epoch: 6| Step: 12
Training loss: 0.21462061305108804
Validation loss: 2.399709321244081

Epoch: 6| Step: 13
Training loss: 0.22473347594065354
Validation loss: 2.4066436172891432

Epoch: 579| Step: 0
Training loss: 0.37790760695348613
Validation loss: 2.3917102810029798

Epoch: 6| Step: 1
Training loss: 0.34957014961336924
Validation loss: 2.368587609826411

Epoch: 6| Step: 2
Training loss: 0.15771948509354894
Validation loss: 2.365865444283912

Epoch: 6| Step: 3
Training loss: 0.1351083461121882
Validation loss: 2.3520276952446317

Epoch: 6| Step: 4
Training loss: 0.28860109465484646
Validation loss: 2.300626017776557

Epoch: 6| Step: 5
Training loss: 0.22242358248249186
Validation loss: 2.3168466232365508

Epoch: 6| Step: 6
Training loss: 0.2861333462967304
Validation loss: 2.360851036658015

Epoch: 6| Step: 7
Training loss: 0.2375275620981097
Validation loss: 2.369787245706525

Epoch: 6| Step: 8
Training loss: 0.2087891995293049
Validation loss: 2.401752824035158

Epoch: 6| Step: 9
Training loss: 0.22117520371940047
Validation loss: 2.4439510678483796

Epoch: 6| Step: 10
Training loss: 0.17077564732888623
Validation loss: 2.4122065117002767

Epoch: 6| Step: 11
Training loss: 0.20546003838118324
Validation loss: 2.421435384185618

Epoch: 6| Step: 12
Training loss: 0.370891977970066
Validation loss: 2.469449123022845

Epoch: 6| Step: 13
Training loss: 0.33234145315692115
Validation loss: 2.4316396305460914

Epoch: 580| Step: 0
Training loss: 0.25280453741315007
Validation loss: 2.4341962283824654

Epoch: 6| Step: 1
Training loss: 0.18273986938618855
Validation loss: 2.411717506552752

Epoch: 6| Step: 2
Training loss: 0.16681605525817855
Validation loss: 2.377997668137829

Epoch: 6| Step: 3
Training loss: 0.23963604827418447
Validation loss: 2.3566173433912536

Epoch: 6| Step: 4
Training loss: 0.3421766079079258
Validation loss: 2.364158170039393

Epoch: 6| Step: 5
Training loss: 0.23494279748617444
Validation loss: 2.383321846503244

Epoch: 6| Step: 6
Training loss: 0.16382903563137674
Validation loss: 2.3583985385934243

Epoch: 6| Step: 7
Training loss: 0.4097065231131693
Validation loss: 2.33282487869811

Epoch: 6| Step: 8
Training loss: 0.12426307385268678
Validation loss: 2.3344309030214125

Epoch: 6| Step: 9
Training loss: 0.16305505151723104
Validation loss: 2.3470824310586504

Epoch: 6| Step: 10
Training loss: 0.19857662160077547
Validation loss: 2.3229459919552937

Epoch: 6| Step: 11
Training loss: 0.30962971740088946
Validation loss: 2.307507769947393

Epoch: 6| Step: 12
Training loss: 0.24136444180370442
Validation loss: 2.3186829159921745

Epoch: 6| Step: 13
Training loss: 0.23676980730117797
Validation loss: 2.301689169514436

Epoch: 581| Step: 0
Training loss: 0.2567273624807386
Validation loss: 2.2921420308159157

Epoch: 6| Step: 1
Training loss: 0.3229827877254993
Validation loss: 2.306581477939375

Epoch: 6| Step: 2
Training loss: 0.20163918817977053
Validation loss: 2.3117957280219295

Epoch: 6| Step: 3
Training loss: 0.20318299162611464
Validation loss: 2.305698472958851

Epoch: 6| Step: 4
Training loss: 0.17180671744365772
Validation loss: 2.322800119673962

Epoch: 6| Step: 5
Training loss: 0.21616216486776538
Validation loss: 2.357327529097696

Epoch: 6| Step: 6
Training loss: 0.1528596700715983
Validation loss: 2.312441327637528

Epoch: 6| Step: 7
Training loss: 0.19628061684426018
Validation loss: 2.342875632985095

Epoch: 6| Step: 8
Training loss: 0.176307922367074
Validation loss: 2.3801933958219847

Epoch: 6| Step: 9
Training loss: 0.23485793585454046
Validation loss: 2.373112767962869

Epoch: 6| Step: 10
Training loss: 0.21147211637505017
Validation loss: 2.3498660229830963

Epoch: 6| Step: 11
Training loss: 0.23567469562283444
Validation loss: 2.345857113044273

Epoch: 6| Step: 12
Training loss: 0.29563726097311144
Validation loss: 2.314325006055169

Epoch: 6| Step: 13
Training loss: 0.16703542071631736
Validation loss: 2.3366492757740627

Epoch: 582| Step: 0
Training loss: 0.18289449108393263
Validation loss: 2.2955577411203163

Epoch: 6| Step: 1
Training loss: 0.1625267653247199
Validation loss: 2.298258860881693

Epoch: 6| Step: 2
Training loss: 0.18113361889081955
Validation loss: 2.3152834795158617

Epoch: 6| Step: 3
Training loss: 0.1902961164697886
Validation loss: 2.3245994575255255

Epoch: 6| Step: 4
Training loss: 0.23041942844552254
Validation loss: 2.284879537172291

Epoch: 6| Step: 5
Training loss: 0.23303375323571335
Validation loss: 2.2870928000640323

Epoch: 6| Step: 6
Training loss: 0.30808742851243803
Validation loss: 2.2768368290237624

Epoch: 6| Step: 7
Training loss: 0.17290664053961938
Validation loss: 2.289971554945754

Epoch: 6| Step: 8
Training loss: 0.1938888736596264
Validation loss: 2.3234400553886867

Epoch: 6| Step: 9
Training loss: 0.1511617250509704
Validation loss: 2.2867842149637507

Epoch: 6| Step: 10
Training loss: 0.15215184277701282
Validation loss: 2.298958740683365

Epoch: 6| Step: 11
Training loss: 0.26285524002611504
Validation loss: 2.3449848042388504

Epoch: 6| Step: 12
Training loss: 0.17879483072595198
Validation loss: 2.336141044815725

Epoch: 6| Step: 13
Training loss: 0.20819810213539522
Validation loss: 2.3573601115129548

Epoch: 583| Step: 0
Training loss: 0.13175063729222541
Validation loss: 2.3703455542169176

Epoch: 6| Step: 1
Training loss: 0.16598885825299733
Validation loss: 2.3688067766299237

Epoch: 6| Step: 2
Training loss: 0.1823633439062999
Validation loss: 2.3899579019194563

Epoch: 6| Step: 3
Training loss: 0.2722006754527656
Validation loss: 2.4010421464288854

Epoch: 6| Step: 4
Training loss: 0.25501068240117675
Validation loss: 2.4314650655596166

Epoch: 6| Step: 5
Training loss: 0.14287585695765656
Validation loss: 2.426804821039192

Epoch: 6| Step: 6
Training loss: 0.2630660691720427
Validation loss: 2.4304708022670507

Epoch: 6| Step: 7
Training loss: 0.1758567224181343
Validation loss: 2.424105068634244

Epoch: 6| Step: 8
Training loss: 0.2094024504985904
Validation loss: 2.4035962262473687

Epoch: 6| Step: 9
Training loss: 0.12257714909978924
Validation loss: 2.403331563041326

Epoch: 6| Step: 10
Training loss: 0.1860799960667689
Validation loss: 2.3894386599886492

Epoch: 6| Step: 11
Training loss: 0.13376118724596978
Validation loss: 2.352714269866789

Epoch: 6| Step: 12
Training loss: 0.27633081742760734
Validation loss: 2.372232996007798

Epoch: 6| Step: 13
Training loss: 0.1444125654737842
Validation loss: 2.3823518998801525

Epoch: 584| Step: 0
Training loss: 0.2724337547169077
Validation loss: 2.356940752447752

Epoch: 6| Step: 1
Training loss: 0.2615417052449195
Validation loss: 2.3714861996013306

Epoch: 6| Step: 2
Training loss: 0.2661922652594362
Validation loss: 2.3334806640391728

Epoch: 6| Step: 3
Training loss: 0.13761278479466338
Validation loss: 2.3279659461641744

Epoch: 6| Step: 4
Training loss: 0.21660462868311522
Validation loss: 2.322848282351027

Epoch: 6| Step: 5
Training loss: 0.15294256874683032
Validation loss: 2.3682275149377445

Epoch: 6| Step: 6
Training loss: 0.1541486039781631
Validation loss: 2.3117910194617863

Epoch: 6| Step: 7
Training loss: 0.3057227520158725
Validation loss: 2.345142501574057

Epoch: 6| Step: 8
Training loss: 0.3169183472322904
Validation loss: 2.3103303450796635

Epoch: 6| Step: 9
Training loss: 0.31252598654464125
Validation loss: 2.3334147719997893

Epoch: 6| Step: 10
Training loss: 0.3956865636705724
Validation loss: 2.3340177759049547

Epoch: 6| Step: 11
Training loss: 0.1710445651247495
Validation loss: 2.328779900245791

Epoch: 6| Step: 12
Training loss: 0.42364100531415827
Validation loss: 2.3695348803111616

Epoch: 6| Step: 13
Training loss: 0.29022852813458416
Validation loss: 2.396844691268234

Epoch: 585| Step: 0
Training loss: 0.42403740703918086
Validation loss: 2.4440688469354104

Epoch: 6| Step: 1
Training loss: 0.3488884317312988
Validation loss: 2.413371532717221

Epoch: 6| Step: 2
Training loss: 0.19439544916678825
Validation loss: 2.398947395374327

Epoch: 6| Step: 3
Training loss: 0.30071691345174134
Validation loss: 2.3732917856759586

Epoch: 6| Step: 4
Training loss: 0.21996591035657764
Validation loss: 2.3711881319936667

Epoch: 6| Step: 5
Training loss: 0.19198144395636327
Validation loss: 2.4040074546657704

Epoch: 6| Step: 6
Training loss: 0.4241970583601938
Validation loss: 2.3845626581953177

Epoch: 6| Step: 7
Training loss: 0.28656156009366013
Validation loss: 2.3769989970494905

Epoch: 6| Step: 8
Training loss: 0.16663476271049024
Validation loss: 2.3930509272966183

Epoch: 6| Step: 9
Training loss: 0.15233693352145797
Validation loss: 2.359944658968864

Epoch: 6| Step: 10
Training loss: 0.16483487810423364
Validation loss: 2.381784218222581

Epoch: 6| Step: 11
Training loss: 0.16620614956012245
Validation loss: 2.401111227984523

Epoch: 6| Step: 12
Training loss: 0.268490759436581
Validation loss: 2.3599399747787713

Epoch: 6| Step: 13
Training loss: 0.19335795893295096
Validation loss: 2.320131966823969

Epoch: 586| Step: 0
Training loss: 0.16198969640166327
Validation loss: 2.315028697946726

Epoch: 6| Step: 1
Training loss: 0.1457280597878776
Validation loss: 2.3215368416121898

Epoch: 6| Step: 2
Training loss: 0.15890112297541745
Validation loss: 2.311394321543309

Epoch: 6| Step: 3
Training loss: 0.2064168558565191
Validation loss: 2.306924768043395

Epoch: 6| Step: 4
Training loss: 0.2184880766212305
Validation loss: 2.2784324684392265

Epoch: 6| Step: 5
Training loss: 0.22938357278722474
Validation loss: 2.3011510447256205

Epoch: 6| Step: 6
Training loss: 0.22118429884112623
Validation loss: 2.3244941314584433

Epoch: 6| Step: 7
Training loss: 0.2157386435390839
Validation loss: 2.3445009768980354

Epoch: 6| Step: 8
Training loss: 0.2457074660750099
Validation loss: 2.3408388419291963

Epoch: 6| Step: 9
Training loss: 0.2675507106799014
Validation loss: 2.3764578085913715

Epoch: 6| Step: 10
Training loss: 0.423021507030941
Validation loss: 2.336550495072687

Epoch: 6| Step: 11
Training loss: 0.26529388265811105
Validation loss: 2.365486299131033

Epoch: 6| Step: 12
Training loss: 0.21676721455897185
Validation loss: 2.338554777670509

Epoch: 6| Step: 13
Training loss: 0.26519542908170785
Validation loss: 2.32765610922741

Epoch: 587| Step: 0
Training loss: 0.16171605872711392
Validation loss: 2.341453344707631

Epoch: 6| Step: 1
Training loss: 0.22127255262853798
Validation loss: 2.373376674194432

Epoch: 6| Step: 2
Training loss: 0.15697843508010964
Validation loss: 2.3841407488457835

Epoch: 6| Step: 3
Training loss: 0.190907841484566
Validation loss: 2.3686163752658493

Epoch: 6| Step: 4
Training loss: 0.3509075421720496
Validation loss: 2.329055205534118

Epoch: 6| Step: 5
Training loss: 0.3631816030039005
Validation loss: 2.339115361772589

Epoch: 6| Step: 6
Training loss: 0.24498057262847578
Validation loss: 2.3227942933113

Epoch: 6| Step: 7
Training loss: 0.17914059586988462
Validation loss: 2.3252972585159895

Epoch: 6| Step: 8
Training loss: 0.20129660100902697
Validation loss: 2.3413296163514365

Epoch: 6| Step: 9
Training loss: 0.16880916335400292
Validation loss: 2.3403426644434036

Epoch: 6| Step: 10
Training loss: 0.20969995646423994
Validation loss: 2.3594654426932036

Epoch: 6| Step: 11
Training loss: 0.2845445892290774
Validation loss: 2.3849604696520608

Epoch: 6| Step: 12
Training loss: 0.2082824774102849
Validation loss: 2.3780842493506555

Epoch: 6| Step: 13
Training loss: 0.19004780552228628
Validation loss: 2.3980804120886168

Epoch: 588| Step: 0
Training loss: 0.16742224835217565
Validation loss: 2.392951229789108

Epoch: 6| Step: 1
Training loss: 0.22731367089193125
Validation loss: 2.3904314879025614

Epoch: 6| Step: 2
Training loss: 0.13353893120141655
Validation loss: 2.371865525424606

Epoch: 6| Step: 3
Training loss: 0.15842827916823213
Validation loss: 2.363402579547489

Epoch: 6| Step: 4
Training loss: 0.1923240630008876
Validation loss: 2.3920489933434332

Epoch: 6| Step: 5
Training loss: 0.23982133481034312
Validation loss: 2.363746902421189

Epoch: 6| Step: 6
Training loss: 0.2145179271937065
Validation loss: 2.3488018072049

Epoch: 6| Step: 7
Training loss: 0.24021492856101195
Validation loss: 2.3634383502359855

Epoch: 6| Step: 8
Training loss: 0.184022858516954
Validation loss: 2.3514388751031836

Epoch: 6| Step: 9
Training loss: 0.23252254998411617
Validation loss: 2.358800453423633

Epoch: 6| Step: 10
Training loss: 0.2529848252219934
Validation loss: 2.3286159097193178

Epoch: 6| Step: 11
Training loss: 0.2840248551305135
Validation loss: 2.3080436417998316

Epoch: 6| Step: 12
Training loss: 0.24130735130715786
Validation loss: 2.329466109269127

Epoch: 6| Step: 13
Training loss: 0.5680041694353763
Validation loss: 2.314808922006998

Epoch: 589| Step: 0
Training loss: 0.14072396187107122
Validation loss: 2.3426188281674922

Epoch: 6| Step: 1
Training loss: 0.14432918754765509
Validation loss: 2.3582289162106203

Epoch: 6| Step: 2
Training loss: 0.17690727069238854
Validation loss: 2.395769761692449

Epoch: 6| Step: 3
Training loss: 0.2854652820495524
Validation loss: 2.3796402850317118

Epoch: 6| Step: 4
Training loss: 0.33127711428027384
Validation loss: 2.3795925117517758

Epoch: 6| Step: 5
Training loss: 0.21395316638359707
Validation loss: 2.363766191357168

Epoch: 6| Step: 6
Training loss: 0.26365384640693934
Validation loss: 2.3871696390928117

Epoch: 6| Step: 7
Training loss: 0.31593273193202587
Validation loss: 2.374567598056847

Epoch: 6| Step: 8
Training loss: 0.36916270517989314
Validation loss: 2.397376141469701

Epoch: 6| Step: 9
Training loss: 0.16553522051859412
Validation loss: 2.3999902048859627

Epoch: 6| Step: 10
Training loss: 0.30420116589261337
Validation loss: 2.413055875898735

Epoch: 6| Step: 11
Training loss: 0.19388335929720024
Validation loss: 2.4245258972381136

Epoch: 6| Step: 12
Training loss: 0.21530052525477958
Validation loss: 2.393456400198472

Epoch: 6| Step: 13
Training loss: 0.23938858195385992
Validation loss: 2.387068883491262

Epoch: 590| Step: 0
Training loss: 0.15971979705782308
Validation loss: 2.3872184935791037

Epoch: 6| Step: 1
Training loss: 0.17889206467741453
Validation loss: 2.3523133820330595

Epoch: 6| Step: 2
Training loss: 0.1340408045101967
Validation loss: 2.371636737563761

Epoch: 6| Step: 3
Training loss: 0.19134902098549536
Validation loss: 2.341380300525901

Epoch: 6| Step: 4
Training loss: 0.1618178803233458
Validation loss: 2.373719965527508

Epoch: 6| Step: 5
Training loss: 0.12208927388745527
Validation loss: 2.3440287018923693

Epoch: 6| Step: 6
Training loss: 0.17469244822009294
Validation loss: 2.35435239233672

Epoch: 6| Step: 7
Training loss: 0.229478543464402
Validation loss: 2.3854707062557603

Epoch: 6| Step: 8
Training loss: 0.2300610978022393
Validation loss: 2.3831298638296303

Epoch: 6| Step: 9
Training loss: 0.17165442422985822
Validation loss: 2.3632372270411244

Epoch: 6| Step: 10
Training loss: 0.28826041676159875
Validation loss: 2.3764220353802217

Epoch: 6| Step: 11
Training loss: 0.2921035707258771
Validation loss: 2.359119751625382

Epoch: 6| Step: 12
Training loss: 0.16866317519862267
Validation loss: 2.3712639867911185

Epoch: 6| Step: 13
Training loss: 0.07154572673441839
Validation loss: 2.3730195450070934

Epoch: 591| Step: 0
Training loss: 0.18396981256604827
Validation loss: 2.366029150362628

Epoch: 6| Step: 1
Training loss: 0.12697876891318224
Validation loss: 2.3874034006679428

Epoch: 6| Step: 2
Training loss: 0.09532101897956563
Validation loss: 2.380827978300425

Epoch: 6| Step: 3
Training loss: 0.1689403841920553
Validation loss: 2.383463164491446

Epoch: 6| Step: 4
Training loss: 0.15721628499055842
Validation loss: 2.3752663192651307

Epoch: 6| Step: 5
Training loss: 0.09967960425052834
Validation loss: 2.341231880649381

Epoch: 6| Step: 6
Training loss: 0.2816649660551961
Validation loss: 2.34437528848852

Epoch: 6| Step: 7
Training loss: 0.1957555133498678
Validation loss: 2.3529106235646817

Epoch: 6| Step: 8
Training loss: 0.12743725532407224
Validation loss: 2.384879431165282

Epoch: 6| Step: 9
Training loss: 0.15765618334675222
Validation loss: 2.3892827376674877

Epoch: 6| Step: 10
Training loss: 0.14664698158676653
Validation loss: 2.372314615627676

Epoch: 6| Step: 11
Training loss: 0.09620813524422148
Validation loss: 2.3427905562904616

Epoch: 6| Step: 12
Training loss: 0.22860872377385394
Validation loss: 2.3700968577742603

Epoch: 6| Step: 13
Training loss: 0.10610121923314866
Validation loss: 2.3653133389957786

Epoch: 592| Step: 0
Training loss: 0.18561636978535104
Validation loss: 2.3848712835217847

Epoch: 6| Step: 1
Training loss: 0.25469990448494995
Validation loss: 2.3704795433145107

Epoch: 6| Step: 2
Training loss: 0.14741445907837827
Validation loss: 2.3461661580622684

Epoch: 6| Step: 3
Training loss: 0.09395804764999524
Validation loss: 2.371856662404227

Epoch: 6| Step: 4
Training loss: 0.19222570675320486
Validation loss: 2.379870543012631

Epoch: 6| Step: 5
Training loss: 0.18438802527631568
Validation loss: 2.355126064460314

Epoch: 6| Step: 6
Training loss: 0.10632585244199197
Validation loss: 2.3571310582624974

Epoch: 6| Step: 7
Training loss: 0.14871918152668182
Validation loss: 2.33294484882522

Epoch: 6| Step: 8
Training loss: 0.11840325964607126
Validation loss: 2.3436105091875055

Epoch: 6| Step: 9
Training loss: 0.1317027584903101
Validation loss: 2.3355199764665584

Epoch: 6| Step: 10
Training loss: 0.10154135190421622
Validation loss: 2.362876425267763

Epoch: 6| Step: 11
Training loss: 0.13178618163283667
Validation loss: 2.336313165137462

Epoch: 6| Step: 12
Training loss: 0.15122379771568353
Validation loss: 2.316710147492415

Epoch: 6| Step: 13
Training loss: 0.11209131786588859
Validation loss: 2.3195915561954243

Epoch: 593| Step: 0
Training loss: 0.15329624400165975
Validation loss: 2.3409496989322687

Epoch: 6| Step: 1
Training loss: 0.08480625211765035
Validation loss: 2.323619554271464

Epoch: 6| Step: 2
Training loss: 0.12661868573108112
Validation loss: 2.324106675235537

Epoch: 6| Step: 3
Training loss: 0.10565253422264007
Validation loss: 2.357862322692108

Epoch: 6| Step: 4
Training loss: 0.1005384138484919
Validation loss: 2.3353279403033578

Epoch: 6| Step: 5
Training loss: 0.25514542362210035
Validation loss: 2.316130303725638

Epoch: 6| Step: 6
Training loss: 0.13774118268157817
Validation loss: 2.349017134032496

Epoch: 6| Step: 7
Training loss: 0.1295730726576575
Validation loss: 2.3545619423309216

Epoch: 6| Step: 8
Training loss: 0.10851852535329348
Validation loss: 2.3396766903303186

Epoch: 6| Step: 9
Training loss: 0.08968824425332035
Validation loss: 2.3722389646329045

Epoch: 6| Step: 10
Training loss: 0.14290318601240304
Validation loss: 2.36190529394933

Epoch: 6| Step: 11
Training loss: 0.14292381132754883
Validation loss: 2.387641749882295

Epoch: 6| Step: 12
Training loss: 0.1470825063607451
Validation loss: 2.376623940218899

Epoch: 6| Step: 13
Training loss: 0.09560576176817648
Validation loss: 2.3404535454959037

Epoch: 594| Step: 0
Training loss: 0.10392356061507581
Validation loss: 2.3815431745264775

Epoch: 6| Step: 1
Training loss: 0.15672707443340048
Validation loss: 2.3657790086436328

Epoch: 6| Step: 2
Training loss: 0.12074845058669295
Validation loss: 2.352984344314449

Epoch: 6| Step: 3
Training loss: 0.11364927198235178
Validation loss: 2.363247315663099

Epoch: 6| Step: 4
Training loss: 0.13365278473340503
Validation loss: 2.333724786916944

Epoch: 6| Step: 5
Training loss: 0.2315014477348786
Validation loss: 2.34471579720905

Epoch: 6| Step: 6
Training loss: 0.0888048886343587
Validation loss: 2.329358944626311

Epoch: 6| Step: 7
Training loss: 0.10886879846197423
Validation loss: 2.3909894587809535

Epoch: 6| Step: 8
Training loss: 0.14983368832854133
Validation loss: 2.3243903607141543

Epoch: 6| Step: 9
Training loss: 0.1704555931835775
Validation loss: 2.3527817603309114

Epoch: 6| Step: 10
Training loss: 0.12390554637155947
Validation loss: 2.3695827644024177

Epoch: 6| Step: 11
Training loss: 0.15917309355388704
Validation loss: 2.382688145558908

Epoch: 6| Step: 12
Training loss: 0.1482139459981981
Validation loss: 2.3894008993359943

Epoch: 6| Step: 13
Training loss: 0.18932315458224186
Validation loss: 2.376191687059951

Epoch: 595| Step: 0
Training loss: 0.10887418341220936
Validation loss: 2.3380396166303234

Epoch: 6| Step: 1
Training loss: 0.15136034550123825
Validation loss: 2.360013748606517

Epoch: 6| Step: 2
Training loss: 0.09689688127801688
Validation loss: 2.3587121997540716

Epoch: 6| Step: 3
Training loss: 0.12504588715395346
Validation loss: 2.3858090031615515

Epoch: 6| Step: 4
Training loss: 0.09100247644235447
Validation loss: 2.367225748735464

Epoch: 6| Step: 5
Training loss: 0.16279174630313106
Validation loss: 2.3887885086033513

Epoch: 6| Step: 6
Training loss: 0.1704907103938057
Validation loss: 2.371282539961529

Epoch: 6| Step: 7
Training loss: 0.11958706571725011
Validation loss: 2.3510168421815623

Epoch: 6| Step: 8
Training loss: 0.12775438251182056
Validation loss: 2.3502175115035104

Epoch: 6| Step: 9
Training loss: 0.2469442143774111
Validation loss: 2.3676135208012887

Epoch: 6| Step: 10
Training loss: 0.1280234335528463
Validation loss: 2.368998270825496

Epoch: 6| Step: 11
Training loss: 0.08929941889626136
Validation loss: 2.3604898049907965

Epoch: 6| Step: 12
Training loss: 0.1451975118815851
Validation loss: 2.3765962263521314

Epoch: 6| Step: 13
Training loss: 0.09346860636556921
Validation loss: 2.3800479962993473

Epoch: 596| Step: 0
Training loss: 0.1513433499178343
Validation loss: 2.3697920829793317

Epoch: 6| Step: 1
Training loss: 0.1458573782773441
Validation loss: 2.3916558516231663

Epoch: 6| Step: 2
Training loss: 0.1694625697794849
Validation loss: 2.359030899427963

Epoch: 6| Step: 3
Training loss: 0.12694977975986244
Validation loss: 2.372789102990911

Epoch: 6| Step: 4
Training loss: 0.10656193372989894
Validation loss: 2.3472531494554834

Epoch: 6| Step: 5
Training loss: 0.10056730671900115
Validation loss: 2.3647812061278164

Epoch: 6| Step: 6
Training loss: 0.11394127583276387
Validation loss: 2.3652836912259536

Epoch: 6| Step: 7
Training loss: 0.15742699068148724
Validation loss: 2.3457228180490524

Epoch: 6| Step: 8
Training loss: 0.10003033677029573
Validation loss: 2.325823064088542

Epoch: 6| Step: 9
Training loss: 0.13855231194601214
Validation loss: 2.331219550359498

Epoch: 6| Step: 10
Training loss: 0.14107743306190443
Validation loss: 2.333628460755621

Epoch: 6| Step: 11
Training loss: 0.11432169896942193
Validation loss: 2.346312685331183

Epoch: 6| Step: 12
Training loss: 0.23880273786986883
Validation loss: 2.3211529330000014

Epoch: 6| Step: 13
Training loss: 0.06384689799127206
Validation loss: 2.340884103103951

Epoch: 597| Step: 0
Training loss: 0.13823646369719497
Validation loss: 2.357992820140226

Epoch: 6| Step: 1
Training loss: 0.10359808498478108
Validation loss: 2.3420369199707327

Epoch: 6| Step: 2
Training loss: 0.17371240257089712
Validation loss: 2.3297890327188284

Epoch: 6| Step: 3
Training loss: 0.09472794875870821
Validation loss: 2.345965921072751

Epoch: 6| Step: 4
Training loss: 0.09503262028808543
Validation loss: 2.364622173141224

Epoch: 6| Step: 5
Training loss: 0.1654000256821475
Validation loss: 2.3353183359400242

Epoch: 6| Step: 6
Training loss: 0.10235136655318926
Validation loss: 2.3457560682051697

Epoch: 6| Step: 7
Training loss: 0.17471565344714954
Validation loss: 2.3719690862825353

Epoch: 6| Step: 8
Training loss: 0.0925027310928335
Validation loss: 2.3557418702719723

Epoch: 6| Step: 9
Training loss: 0.13636405438572216
Validation loss: 2.388436374229252

Epoch: 6| Step: 10
Training loss: 0.2605932145896029
Validation loss: 2.399640965866462

Epoch: 6| Step: 11
Training loss: 0.0853638413193165
Validation loss: 2.366425923901436

Epoch: 6| Step: 12
Training loss: 0.09792009949584811
Validation loss: 2.3677088979811503

Epoch: 6| Step: 13
Training loss: 0.10815512353309926
Validation loss: 2.3864251857448986

Epoch: 598| Step: 0
Training loss: 0.17928407827017878
Validation loss: 2.3687381609994946

Epoch: 6| Step: 1
Training loss: 0.24316348799672108
Validation loss: 2.3724266417563875

Epoch: 6| Step: 2
Training loss: 0.12548376142028586
Validation loss: 2.3628576466012348

Epoch: 6| Step: 3
Training loss: 0.08706225127703567
Validation loss: 2.3579842072224797

Epoch: 6| Step: 4
Training loss: 0.1245146507965131
Validation loss: 2.3383703499078727

Epoch: 6| Step: 5
Training loss: 0.11132703747134487
Validation loss: 2.3473947576738436

Epoch: 6| Step: 6
Training loss: 0.12261297531646369
Validation loss: 2.344450692610735

Epoch: 6| Step: 7
Training loss: 0.11865384293225259
Validation loss: 2.3875961966608643

Epoch: 6| Step: 8
Training loss: 0.10355923291925301
Validation loss: 2.3544689789840603

Epoch: 6| Step: 9
Training loss: 0.10468528855535912
Validation loss: 2.3620547287629177

Epoch: 6| Step: 10
Training loss: 0.13017114028613427
Validation loss: 2.3640192571620893

Epoch: 6| Step: 11
Training loss: 0.07652265523965376
Validation loss: 2.3386238924699927

Epoch: 6| Step: 12
Training loss: 0.17103337001967733
Validation loss: 2.3295044650749097

Epoch: 6| Step: 13
Training loss: 0.16785501910213324
Validation loss: 2.3692875313830415

Epoch: 599| Step: 0
Training loss: 0.08330029680887119
Validation loss: 2.3433062805395912

Epoch: 6| Step: 1
Training loss: 0.10361409901575788
Validation loss: 2.320165734545216

Epoch: 6| Step: 2
Training loss: 0.07078095849189772
Validation loss: 2.3285732758559923

Epoch: 6| Step: 3
Training loss: 0.1346109442417381
Validation loss: 2.3429004554207893

Epoch: 6| Step: 4
Training loss: 0.05140345882893758
Validation loss: 2.3161556413582036

Epoch: 6| Step: 5
Training loss: 0.10503609536414471
Validation loss: 2.315492232307279

Epoch: 6| Step: 6
Training loss: 0.10979929862272837
Validation loss: 2.312627936817689

Epoch: 6| Step: 7
Training loss: 0.06956307722162369
Validation loss: 2.3365190087893115

Epoch: 6| Step: 8
Training loss: 0.10005309345765413
Validation loss: 2.335313563932261

Epoch: 6| Step: 9
Training loss: 0.13048117344349658
Validation loss: 2.337998699594369

Epoch: 6| Step: 10
Training loss: 0.09130593158288562
Validation loss: 2.3383592023323327

Epoch: 6| Step: 11
Training loss: 0.23280870479332172
Validation loss: 2.309681909969495

Epoch: 6| Step: 12
Training loss: 0.11091431875885129
Validation loss: 2.318788826643937

Epoch: 6| Step: 13
Training loss: 0.07189904489730076
Validation loss: 2.3387703820151797

Epoch: 600| Step: 0
Training loss: 0.24497166907713308
Validation loss: 2.346138759704139

Epoch: 6| Step: 1
Training loss: 0.10312622080427108
Validation loss: 2.336773008942211

Epoch: 6| Step: 2
Training loss: 0.0803902347154847
Validation loss: 2.359729702696255

Epoch: 6| Step: 3
Training loss: 0.1282436362401704
Validation loss: 2.342177424473173

Epoch: 6| Step: 4
Training loss: 0.12680986831429203
Validation loss: 2.351319733560511

Epoch: 6| Step: 5
Training loss: 0.0675276774710819
Validation loss: 2.3458668829912273

Epoch: 6| Step: 6
Training loss: 0.07333634364364222
Validation loss: 2.3301382038249576

Epoch: 6| Step: 7
Training loss: 0.1526507438908309
Validation loss: 2.3669559784251564

Epoch: 6| Step: 8
Training loss: 0.10414063505900993
Validation loss: 2.3549724827391434

Epoch: 6| Step: 9
Training loss: 0.11161348929412691
Validation loss: 2.3629290043061215

Epoch: 6| Step: 10
Training loss: 0.1446443836654697
Validation loss: 2.348721243521911

Epoch: 6| Step: 11
Training loss: 0.10696513438041647
Validation loss: 2.3630488830031506

Epoch: 6| Step: 12
Training loss: 0.09722442520385628
Validation loss: 2.397698636016596

Epoch: 6| Step: 13
Training loss: 0.1943131342405445
Validation loss: 2.404620964375381

Epoch: 601| Step: 0
Training loss: 0.08646215061537255
Validation loss: 2.3812305656029555

Epoch: 6| Step: 1
Training loss: 0.255851803733099
Validation loss: 2.3682784109753063

Epoch: 6| Step: 2
Training loss: 0.08995859435421873
Validation loss: 2.375060554038996

Epoch: 6| Step: 3
Training loss: 0.1486683480971487
Validation loss: 2.3643488816303475

Epoch: 6| Step: 4
Training loss: 0.09629876298769721
Validation loss: 2.3734767559392003

Epoch: 6| Step: 5
Training loss: 0.1279573920150205
Validation loss: 2.4052316129766695

Epoch: 6| Step: 6
Training loss: 0.121815510896833
Validation loss: 2.3838380938105543

Epoch: 6| Step: 7
Training loss: 0.08606237312243825
Validation loss: 2.3857747971721928

Epoch: 6| Step: 8
Training loss: 0.12565309559093765
Validation loss: 2.3701623103230065

Epoch: 6| Step: 9
Training loss: 0.0945762936805379
Validation loss: 2.3345540811613192

Epoch: 6| Step: 10
Training loss: 0.13559666387034236
Validation loss: 2.368260733286123

Epoch: 6| Step: 11
Training loss: 0.09959284327333358
Validation loss: 2.35412206633849

Epoch: 6| Step: 12
Training loss: 0.12828130666287804
Validation loss: 2.3769604590652973

Epoch: 6| Step: 13
Training loss: 0.13237015605993682
Validation loss: 2.380462698234795

Epoch: 602| Step: 0
Training loss: 0.10993074676836154
Validation loss: 2.3608458276052184

Epoch: 6| Step: 1
Training loss: 0.15115754160586511
Validation loss: 2.346505859544098

Epoch: 6| Step: 2
Training loss: 0.22847127076424006
Validation loss: 2.3550674161058844

Epoch: 6| Step: 3
Training loss: 0.1103120243505322
Validation loss: 2.360909426779801

Epoch: 6| Step: 4
Training loss: 0.07208975449574376
Validation loss: 2.3520722201152107

Epoch: 6| Step: 5
Training loss: 0.12169349876752272
Validation loss: 2.3665738545853006

Epoch: 6| Step: 6
Training loss: 0.07364789810764129
Validation loss: 2.3489697201902593

Epoch: 6| Step: 7
Training loss: 0.0844544242190805
Validation loss: 2.3439344616564837

Epoch: 6| Step: 8
Training loss: 0.16846617521817342
Validation loss: 2.3229773029889347

Epoch: 6| Step: 9
Training loss: 0.09038970240399898
Validation loss: 2.355087906593436

Epoch: 6| Step: 10
Training loss: 0.11995027932631044
Validation loss: 2.3680243431479133

Epoch: 6| Step: 11
Training loss: 0.08185124800314801
Validation loss: 2.3547819888666646

Epoch: 6| Step: 12
Training loss: 0.09242979955678517
Validation loss: 2.3462921422464023

Epoch: 6| Step: 13
Training loss: 0.06000809950412891
Validation loss: 2.3254787251690234

Epoch: 603| Step: 0
Training loss: 0.0938030430622698
Validation loss: 2.3509514214693574

Epoch: 6| Step: 1
Training loss: 0.05536142909090744
Validation loss: 2.3832430510571028

Epoch: 6| Step: 2
Training loss: 0.14731736172392607
Validation loss: 2.3410450520154256

Epoch: 6| Step: 3
Training loss: 0.11516078118373102
Validation loss: 2.369439521452668

Epoch: 6| Step: 4
Training loss: 0.06924455288782133
Validation loss: 2.4049009886656543

Epoch: 6| Step: 5
Training loss: 0.04645951732397651
Validation loss: 2.375158417993002

Epoch: 6| Step: 6
Training loss: 0.1317351415103063
Validation loss: 2.3712975939671637

Epoch: 6| Step: 7
Training loss: 0.22663527996883578
Validation loss: 2.367873868390834

Epoch: 6| Step: 8
Training loss: 0.10171645673167827
Validation loss: 2.352809553132

Epoch: 6| Step: 9
Training loss: 0.09701700320211816
Validation loss: 2.38257597891364

Epoch: 6| Step: 10
Training loss: 0.12991067401087592
Validation loss: 2.375772388919203

Epoch: 6| Step: 11
Training loss: 0.08664211848066472
Validation loss: 2.3696094102538137

Epoch: 6| Step: 12
Training loss: 0.1594882852309111
Validation loss: 2.3908139638784136

Epoch: 6| Step: 13
Training loss: 0.08468849247970235
Validation loss: 2.3779134291913655

Epoch: 604| Step: 0
Training loss: 0.07054714944222129
Validation loss: 2.399633004558092

Epoch: 6| Step: 1
Training loss: 0.12446931977276904
Validation loss: 2.368854540431152

Epoch: 6| Step: 2
Training loss: 0.0999242862905578
Validation loss: 2.3666692260018904

Epoch: 6| Step: 3
Training loss: 0.21455073749470602
Validation loss: 2.4035839602173574

Epoch: 6| Step: 4
Training loss: 0.06283813145758275
Validation loss: 2.373508789393451

Epoch: 6| Step: 5
Training loss: 0.06668576849152685
Validation loss: 2.365336772761908

Epoch: 6| Step: 6
Training loss: 0.10731547895394754
Validation loss: 2.3751280312389556

Epoch: 6| Step: 7
Training loss: 0.0788256194290201
Validation loss: 2.3501685259907887

Epoch: 6| Step: 8
Training loss: 0.13173129555948063
Validation loss: 2.36518791492288

Epoch: 6| Step: 9
Training loss: 0.14862113184904216
Validation loss: 2.368168900923273

Epoch: 6| Step: 10
Training loss: 0.15634079917533997
Validation loss: 2.386814339540182

Epoch: 6| Step: 11
Training loss: 0.08073027735633144
Validation loss: 2.3533657155073002

Epoch: 6| Step: 12
Training loss: 0.08731520160626871
Validation loss: 2.3451595779284955

Epoch: 6| Step: 13
Training loss: 0.10543203156230355
Validation loss: 2.3782671388763683

Epoch: 605| Step: 0
Training loss: 0.06779388798030303
Validation loss: 2.360611261178509

Epoch: 6| Step: 1
Training loss: 0.05897676532491679
Validation loss: 2.3646017940036064

Epoch: 6| Step: 2
Training loss: 0.10978374569198286
Validation loss: 2.3803431117177682

Epoch: 6| Step: 3
Training loss: 0.06593275963887164
Validation loss: 2.359323224077709

Epoch: 6| Step: 4
Training loss: 0.11508280678527229
Validation loss: 2.3666035127323304

Epoch: 6| Step: 5
Training loss: 0.13073531718306103
Validation loss: 2.373646765660066

Epoch: 6| Step: 6
Training loss: 0.1532286351668188
Validation loss: 2.3945429989898344

Epoch: 6| Step: 7
Training loss: 0.07143339804430995
Validation loss: 2.3873345353534194

Epoch: 6| Step: 8
Training loss: 0.08241043271283599
Validation loss: 2.386868189777575

Epoch: 6| Step: 9
Training loss: 0.13363001760566884
Validation loss: 2.41512532739828

Epoch: 6| Step: 10
Training loss: 0.0645400458222755
Validation loss: 2.414752442535367

Epoch: 6| Step: 11
Training loss: 0.22932775572182865
Validation loss: 2.4316224638301103

Epoch: 6| Step: 12
Training loss: 0.08972451341786196
Validation loss: 2.4138228087744533

Epoch: 6| Step: 13
Training loss: 0.04617661023426464
Validation loss: 2.4142561366054123

Epoch: 606| Step: 0
Training loss: 0.19486931109306488
Validation loss: 2.4291644327821853

Epoch: 6| Step: 1
Training loss: 0.07953822913771641
Validation loss: 2.4175969346437367

Epoch: 6| Step: 2
Training loss: 0.07016747472489657
Validation loss: 2.4097942038418725

Epoch: 6| Step: 3
Training loss: 0.07803217320302823
Validation loss: 2.3699411140673394

Epoch: 6| Step: 4
Training loss: 0.08389516183998304
Validation loss: 2.4201391725837236

Epoch: 6| Step: 5
Training loss: 0.09282409389246496
Validation loss: 2.3754072342128687

Epoch: 6| Step: 6
Training loss: 0.09014935967942084
Validation loss: 2.394218348499853

Epoch: 6| Step: 7
Training loss: 0.10915941039871621
Validation loss: 2.362337620703104

Epoch: 6| Step: 8
Training loss: 0.07300658160172638
Validation loss: 2.3758042872914658

Epoch: 6| Step: 9
Training loss: 0.17382563899973555
Validation loss: 2.39201698203727

Epoch: 6| Step: 10
Training loss: 0.07329404266836047
Validation loss: 2.3738356717088585

Epoch: 6| Step: 11
Training loss: 0.09785661170404367
Validation loss: 2.3876905689401666

Epoch: 6| Step: 12
Training loss: 0.14205901476767527
Validation loss: 2.3749620707688575

Epoch: 6| Step: 13
Training loss: 0.06456349777104317
Validation loss: 2.3895349442967126

Epoch: 607| Step: 0
Training loss: 0.06876221217800983
Validation loss: 2.360488253006262

Epoch: 6| Step: 1
Training loss: 0.08666322440475743
Validation loss: 2.39478350229745

Epoch: 6| Step: 2
Training loss: 0.20686334423006095
Validation loss: 2.370743965432444

Epoch: 6| Step: 3
Training loss: 0.10940748822127974
Validation loss: 2.3765449518261876

Epoch: 6| Step: 4
Training loss: 0.07840436518145663
Validation loss: 2.376591728157845

Epoch: 6| Step: 5
Training loss: 0.06017291810363105
Validation loss: 2.3946088153923277

Epoch: 6| Step: 6
Training loss: 0.09689726093078943
Validation loss: 2.385868118633023

Epoch: 6| Step: 7
Training loss: 0.17006195257814477
Validation loss: 2.3686556637653493

Epoch: 6| Step: 8
Training loss: 0.08585756821939801
Validation loss: 2.386238157305188

Epoch: 6| Step: 9
Training loss: 0.15605446382203383
Validation loss: 2.366465698345241

Epoch: 6| Step: 10
Training loss: 0.0948328866738942
Validation loss: 2.3534691895679956

Epoch: 6| Step: 11
Training loss: 0.09517208019366617
Validation loss: 2.3574999610365768

Epoch: 6| Step: 12
Training loss: 0.09270886633573323
Validation loss: 2.3301278948373394

Epoch: 6| Step: 13
Training loss: 0.1277620367260293
Validation loss: 2.322277566282323

Epoch: 608| Step: 0
Training loss: 0.09569251235196194
Validation loss: 2.314936989252489

Epoch: 6| Step: 1
Training loss: 0.09037253013245952
Validation loss: 2.3197035319239756

Epoch: 6| Step: 2
Training loss: 0.04659471309221061
Validation loss: 2.299529994917124

Epoch: 6| Step: 3
Training loss: 0.14448181801966606
Validation loss: 2.3186771423057535

Epoch: 6| Step: 4
Training loss: 0.11457005246819305
Validation loss: 2.3247454575804416

Epoch: 6| Step: 5
Training loss: 0.08606347420136905
Validation loss: 2.3222007985628297

Epoch: 6| Step: 6
Training loss: 0.07025487512021697
Validation loss: 2.328155354408403

Epoch: 6| Step: 7
Training loss: 0.07460633516360313
Validation loss: 2.3467294553728

Epoch: 6| Step: 8
Training loss: 0.10621764833519284
Validation loss: 2.3459252843501597

Epoch: 6| Step: 9
Training loss: 0.09159959738114007
Validation loss: 2.3362024809751967

Epoch: 6| Step: 10
Training loss: 0.09685977866200521
Validation loss: 2.3397018902102342

Epoch: 6| Step: 11
Training loss: 0.10028097067942937
Validation loss: 2.360630303693536

Epoch: 6| Step: 12
Training loss: 0.18994135721789515
Validation loss: 2.344488411258012

Epoch: 6| Step: 13
Training loss: 0.175976983344012
Validation loss: 2.333247934337341

Epoch: 609| Step: 0
Training loss: 0.12671248297004928
Validation loss: 2.3407982859553864

Epoch: 6| Step: 1
Training loss: 0.18763203740248718
Validation loss: 2.34646316669753

Epoch: 6| Step: 2
Training loss: 0.0885183067454239
Validation loss: 2.3712566032138045

Epoch: 6| Step: 3
Training loss: 0.08228515318049515
Validation loss: 2.3613106542142654

Epoch: 6| Step: 4
Training loss: 0.1330025099090861
Validation loss: 2.4175144546541047

Epoch: 6| Step: 5
Training loss: 0.08366489357677569
Validation loss: 2.358518756261872

Epoch: 6| Step: 6
Training loss: 0.07598871437898036
Validation loss: 2.355123608720735

Epoch: 6| Step: 7
Training loss: 0.15622976291257168
Validation loss: 2.357739260806735

Epoch: 6| Step: 8
Training loss: 0.08159384881846019
Validation loss: 2.353455149502012

Epoch: 6| Step: 9
Training loss: 0.11131620343273467
Validation loss: 2.3590881155854784

Epoch: 6| Step: 10
Training loss: 0.07319161258417398
Validation loss: 2.354805109924564

Epoch: 6| Step: 11
Training loss: 0.09570429762297045
Validation loss: 2.3735640923268964

Epoch: 6| Step: 12
Training loss: 0.07481537237126698
Validation loss: 2.349756569102536

Epoch: 6| Step: 13
Training loss: 0.15043228984197443
Validation loss: 2.3724014231552024

Epoch: 610| Step: 0
Training loss: 0.18027124744543913
Validation loss: 2.380152677828341

Epoch: 6| Step: 1
Training loss: 0.08938494962050043
Validation loss: 2.3879982178117776

Epoch: 6| Step: 2
Training loss: 0.064040059718416
Validation loss: 2.3900371839284325

Epoch: 6| Step: 3
Training loss: 0.1373613989256415
Validation loss: 2.413569997127753

Epoch: 6| Step: 4
Training loss: 0.10751721746049543
Validation loss: 2.3974100782065983

Epoch: 6| Step: 5
Training loss: 0.09450088241773189
Validation loss: 2.4046726583732463

Epoch: 6| Step: 6
Training loss: 0.16600422539561271
Validation loss: 2.398897245135311

Epoch: 6| Step: 7
Training loss: 0.07366858025967629
Validation loss: 2.393358763331919

Epoch: 6| Step: 8
Training loss: 0.10048311959848077
Validation loss: 2.3689094279627843

Epoch: 6| Step: 9
Training loss: 0.07192714460797546
Validation loss: 2.4009418993118383

Epoch: 6| Step: 10
Training loss: 0.07333433077189858
Validation loss: 2.3868348050612913

Epoch: 6| Step: 11
Training loss: 0.08000572350822494
Validation loss: 2.392585176512335

Epoch: 6| Step: 12
Training loss: 0.0918675110320837
Validation loss: 2.3764760256341164

Epoch: 6| Step: 13
Training loss: 0.13936674611066463
Validation loss: 2.3620862859983536

Epoch: 611| Step: 0
Training loss: 0.09197754024516347
Validation loss: 2.376707917992953

Epoch: 6| Step: 1
Training loss: 0.099803137720546
Validation loss: 2.3629744656459106

Epoch: 6| Step: 2
Training loss: 0.097567078886773
Validation loss: 2.3822314132984617

Epoch: 6| Step: 3
Training loss: 0.19098345128675298
Validation loss: 2.3577367947410006

Epoch: 6| Step: 4
Training loss: 0.09216575366068683
Validation loss: 2.394738753474298

Epoch: 6| Step: 5
Training loss: 0.15003700917375098
Validation loss: 2.3550466658153635

Epoch: 6| Step: 6
Training loss: 0.0964202579015898
Validation loss: 2.345432850459153

Epoch: 6| Step: 7
Training loss: 0.047786556580743086
Validation loss: 2.3749298037834605

Epoch: 6| Step: 8
Training loss: 0.052181078664251875
Validation loss: 2.3649340798551166

Epoch: 6| Step: 9
Training loss: 0.16433749539793197
Validation loss: 2.367478571433776

Epoch: 6| Step: 10
Training loss: 0.09751809838631101
Validation loss: 2.373985526142848

Epoch: 6| Step: 11
Training loss: 0.06878662447857446
Validation loss: 2.406479016898544

Epoch: 6| Step: 12
Training loss: 0.09604348267416069
Validation loss: 2.392829444314409

Epoch: 6| Step: 13
Training loss: 0.12709042387343794
Validation loss: 2.4018427858302007

Epoch: 612| Step: 0
Training loss: 0.10724655930739882
Validation loss: 2.3809996170787375

Epoch: 6| Step: 1
Training loss: 0.0842267520001191
Validation loss: 2.3788062409585766

Epoch: 6| Step: 2
Training loss: 0.0522050852578797
Validation loss: 2.387228167275967

Epoch: 6| Step: 3
Training loss: 0.13259166702317418
Validation loss: 2.35622455305412

Epoch: 6| Step: 4
Training loss: 0.18989207355238996
Validation loss: 2.398608206805064

Epoch: 6| Step: 5
Training loss: 0.07855849993278437
Validation loss: 2.3626181968389717

Epoch: 6| Step: 6
Training loss: 0.1250827113328705
Validation loss: 2.3589279510792447

Epoch: 6| Step: 7
Training loss: 0.1193011328331457
Validation loss: 2.3709713527072114

Epoch: 6| Step: 8
Training loss: 0.07980734412728419
Validation loss: 2.385927121967952

Epoch: 6| Step: 9
Training loss: 0.1019152923705701
Validation loss: 2.3934377023991082

Epoch: 6| Step: 10
Training loss: 0.10245295951286519
Validation loss: 2.369029660899588

Epoch: 6| Step: 11
Training loss: 0.0790205175338323
Validation loss: 2.3771627700415663

Epoch: 6| Step: 12
Training loss: 0.08532427781587672
Validation loss: 2.345540953520056

Epoch: 6| Step: 13
Training loss: 0.09033795414657789
Validation loss: 2.3759497776508334

Epoch: 613| Step: 0
Training loss: 0.08987577012883421
Validation loss: 2.3619402010879074

Epoch: 6| Step: 1
Training loss: 0.07891090398226182
Validation loss: 2.3445342760924586

Epoch: 6| Step: 2
Training loss: 0.08864487098181936
Validation loss: 2.3694416702258048

Epoch: 6| Step: 3
Training loss: 0.06558735908980634
Validation loss: 2.3917882819431835

Epoch: 6| Step: 4
Training loss: 0.05098975913284072
Validation loss: 2.400133957850198

Epoch: 6| Step: 5
Training loss: 0.19859303589098956
Validation loss: 2.386686315420672

Epoch: 6| Step: 6
Training loss: 0.12327825650205694
Validation loss: 2.35743138604934

Epoch: 6| Step: 7
Training loss: 0.14117262097506242
Validation loss: 2.3803460260906077

Epoch: 6| Step: 8
Training loss: 0.11769846938869127
Validation loss: 2.3797001801913265

Epoch: 6| Step: 9
Training loss: 0.07115240585529675
Validation loss: 2.364187163955222

Epoch: 6| Step: 10
Training loss: 0.09693464704037755
Validation loss: 2.36026966713305

Epoch: 6| Step: 11
Training loss: 0.06142053627218529
Validation loss: 2.361597885231506

Epoch: 6| Step: 12
Training loss: 0.08563893646791657
Validation loss: 2.3733978394114814

Epoch: 6| Step: 13
Training loss: 0.10963463620642759
Validation loss: 2.355781428985714

Epoch: 614| Step: 0
Training loss: 0.1329277394118643
Validation loss: 2.3516667658078623

Epoch: 6| Step: 1
Training loss: 0.10637533880206707
Validation loss: 2.348373320227651

Epoch: 6| Step: 2
Training loss: 0.0753626911266967
Validation loss: 2.3664572614307007

Epoch: 6| Step: 3
Training loss: 0.07176509739731478
Validation loss: 2.3510512529156897

Epoch: 6| Step: 4
Training loss: 0.09532480004162329
Validation loss: 2.367820446921459

Epoch: 6| Step: 5
Training loss: 0.13058971975807374
Validation loss: 2.3245429720346813

Epoch: 6| Step: 6
Training loss: 0.08716439510971632
Validation loss: 2.368620465413033

Epoch: 6| Step: 7
Training loss: 0.19582572264458242
Validation loss: 2.364539431472092

Epoch: 6| Step: 8
Training loss: 0.1157296576977375
Validation loss: 2.3449942771792287

Epoch: 6| Step: 9
Training loss: 0.09345056477560232
Validation loss: 2.3417198034843976

Epoch: 6| Step: 10
Training loss: 0.06411040829117037
Validation loss: 2.3599573834721754

Epoch: 6| Step: 11
Training loss: 0.12072947918111175
Validation loss: 2.346102343890913

Epoch: 6| Step: 12
Training loss: 0.06656206307693141
Validation loss: 2.3702057352399097

Epoch: 6| Step: 13
Training loss: 0.08607256635651314
Validation loss: 2.365208217473195

Epoch: 615| Step: 0
Training loss: 0.08567360435638373
Validation loss: 2.3814900682982216

Epoch: 6| Step: 1
Training loss: 0.07512081158822895
Validation loss: 2.3687079413527576

Epoch: 6| Step: 2
Training loss: 0.12245799871809249
Validation loss: 2.372945225885435

Epoch: 6| Step: 3
Training loss: 0.040501408148866186
Validation loss: 2.3813151242912562

Epoch: 6| Step: 4
Training loss: 0.11856667051134102
Validation loss: 2.385032943389201

Epoch: 6| Step: 5
Training loss: 0.20380292152513835
Validation loss: 2.3587153430132526

Epoch: 6| Step: 6
Training loss: 0.08271939716619171
Validation loss: 2.3710391003568163

Epoch: 6| Step: 7
Training loss: 0.09385704843004071
Validation loss: 2.376623393862318

Epoch: 6| Step: 8
Training loss: 0.05746113122976127
Validation loss: 2.377641480491845

Epoch: 6| Step: 9
Training loss: 0.12291406093949712
Validation loss: 2.354203129067739

Epoch: 6| Step: 10
Training loss: 0.07932948313499644
Validation loss: 2.3641242472052966

Epoch: 6| Step: 11
Training loss: 0.07472766952671758
Validation loss: 2.3748068479999835

Epoch: 6| Step: 12
Training loss: 0.09923791343622304
Validation loss: 2.3567364765591603

Epoch: 6| Step: 13
Training loss: 0.048805360255727084
Validation loss: 2.353464203823687

Epoch: 616| Step: 0
Training loss: 0.12157984046034645
Validation loss: 2.3836148766149234

Epoch: 6| Step: 1
Training loss: 0.13060272014242
Validation loss: 2.3711017963209176

Epoch: 6| Step: 2
Training loss: 0.07375846104053417
Validation loss: 2.395109738459122

Epoch: 6| Step: 3
Training loss: 0.09695350519331684
Validation loss: 2.3650299802554153

Epoch: 6| Step: 4
Training loss: 0.04655897881647646
Validation loss: 2.3959938147157542

Epoch: 6| Step: 5
Training loss: 0.11645108741944142
Validation loss: 2.3475129905163987

Epoch: 6| Step: 6
Training loss: 0.1927166670638289
Validation loss: 2.3464917712582753

Epoch: 6| Step: 7
Training loss: 0.11387236699515937
Validation loss: 2.376413843097768

Epoch: 6| Step: 8
Training loss: 0.08078943074637412
Validation loss: 2.3523535770967015

Epoch: 6| Step: 9
Training loss: 0.14318106811818607
Validation loss: 2.3639271645944726

Epoch: 6| Step: 10
Training loss: 0.09849056524146682
Validation loss: 2.3903203549349175

Epoch: 6| Step: 11
Training loss: 0.04577665201734303
Validation loss: 2.3602426540724895

Epoch: 6| Step: 12
Training loss: 0.0883096086055069
Validation loss: 2.3413737906280496

Epoch: 6| Step: 13
Training loss: 0.04813390270163164
Validation loss: 2.3399190169360944

Epoch: 617| Step: 0
Training loss: 0.05522197292115846
Validation loss: 2.3566836908292994

Epoch: 6| Step: 1
Training loss: 0.21929821223281723
Validation loss: 2.3565230468705116

Epoch: 6| Step: 2
Training loss: 0.11764213270877263
Validation loss: 2.3706316721617138

Epoch: 6| Step: 3
Training loss: 0.06098640402185193
Validation loss: 2.3741984717646623

Epoch: 6| Step: 4
Training loss: 0.10526006857889798
Validation loss: 2.3697171422758525

Epoch: 6| Step: 5
Training loss: 0.050166266754276295
Validation loss: 2.3642734414690456

Epoch: 6| Step: 6
Training loss: 0.06872089024385881
Validation loss: 2.344080193890215

Epoch: 6| Step: 7
Training loss: 0.08278830620194441
Validation loss: 2.3660604866459645

Epoch: 6| Step: 8
Training loss: 0.05995053556781582
Validation loss: 2.34913694346897

Epoch: 6| Step: 9
Training loss: 0.04882350899812007
Validation loss: 2.3310282718034276

Epoch: 6| Step: 10
Training loss: 0.0704624576994644
Validation loss: 2.349255025883879

Epoch: 6| Step: 11
Training loss: 0.08002815781085854
Validation loss: 2.3458866314924136

Epoch: 6| Step: 12
Training loss: 0.07380683367372656
Validation loss: 2.3492900484201127

Epoch: 6| Step: 13
Training loss: 0.12881878573199837
Validation loss: 2.351575393595077

Epoch: 618| Step: 0
Training loss: 0.07360686431854986
Validation loss: 2.3347975839728

Epoch: 6| Step: 1
Training loss: 0.09118221839639204
Validation loss: 2.3127805544642044

Epoch: 6| Step: 2
Training loss: 0.08021122640288525
Validation loss: 2.3557723411289295

Epoch: 6| Step: 3
Training loss: 0.19595969736039665
Validation loss: 2.3211061831326267

Epoch: 6| Step: 4
Training loss: 0.08090236437857466
Validation loss: 2.3264202387834105

Epoch: 6| Step: 5
Training loss: 0.059081719925745894
Validation loss: 2.3553394928454328

Epoch: 6| Step: 6
Training loss: 0.14155513396898797
Validation loss: 2.353766856644848

Epoch: 6| Step: 7
Training loss: 0.09957725343572706
Validation loss: 2.3566969371399553

Epoch: 6| Step: 8
Training loss: 0.07283629802093758
Validation loss: 2.3560668880254214

Epoch: 6| Step: 9
Training loss: 0.12602630638549528
Validation loss: 2.3892002351956436

Epoch: 6| Step: 10
Training loss: 0.09398433089156158
Validation loss: 2.3774465298779983

Epoch: 6| Step: 11
Training loss: 0.08107560818482588
Validation loss: 2.3626575655506468

Epoch: 6| Step: 12
Training loss: 0.08102723311616375
Validation loss: 2.384358266150994

Epoch: 6| Step: 13
Training loss: 0.0862159255563405
Validation loss: 2.3847191750914494

Epoch: 619| Step: 0
Training loss: 0.13037623706058837
Validation loss: 2.3637059510056524

Epoch: 6| Step: 1
Training loss: 0.08967010676635843
Validation loss: 2.4115159704619957

Epoch: 6| Step: 2
Training loss: 0.05329973431569311
Validation loss: 2.3703390449160597

Epoch: 6| Step: 3
Training loss: 0.058613644639782414
Validation loss: 2.4069291828842823

Epoch: 6| Step: 4
Training loss: 0.06136197519657847
Validation loss: 2.3992785238223853

Epoch: 6| Step: 5
Training loss: 0.05604256181455511
Validation loss: 2.3620768761775888

Epoch: 6| Step: 6
Training loss: 0.161103679450868
Validation loss: 2.35662916010671

Epoch: 6| Step: 7
Training loss: 0.13332702043112216
Validation loss: 2.358626586718961

Epoch: 6| Step: 8
Training loss: 0.07098380471747165
Validation loss: 2.3396400495702263

Epoch: 6| Step: 9
Training loss: 0.06174755525792974
Validation loss: 2.359975063612148

Epoch: 6| Step: 10
Training loss: 0.11624374247188472
Validation loss: 2.3670361256332786

Epoch: 6| Step: 11
Training loss: 0.19421926667136277
Validation loss: 2.3713492370913007

Epoch: 6| Step: 12
Training loss: 0.09199003431711947
Validation loss: 2.3564755294805257

Epoch: 6| Step: 13
Training loss: 0.06737034101757436
Validation loss: 2.3798742001667126

Epoch: 620| Step: 0
Training loss: 0.18393730930327556
Validation loss: 2.3699813260236273

Epoch: 6| Step: 1
Training loss: 0.08843129012374998
Validation loss: 2.3608040472631493

Epoch: 6| Step: 2
Training loss: 0.050208727179577965
Validation loss: 2.3730917487439673

Epoch: 6| Step: 3
Training loss: 0.14000890798200283
Validation loss: 2.385038681665943

Epoch: 6| Step: 4
Training loss: 0.06640181807146053
Validation loss: 2.353668007257419

Epoch: 6| Step: 5
Training loss: 0.049792517315775414
Validation loss: 2.355941652883991

Epoch: 6| Step: 6
Training loss: 0.05493392515730156
Validation loss: 2.346619069697767

Epoch: 6| Step: 7
Training loss: 0.1639437131915048
Validation loss: 2.357775557233817

Epoch: 6| Step: 8
Training loss: 0.06818043585932963
Validation loss: 2.3399220862878445

Epoch: 6| Step: 9
Training loss: 0.06991646748416565
Validation loss: 2.3674662853068917

Epoch: 6| Step: 10
Training loss: 0.08250703096231832
Validation loss: 2.3395405250904737

Epoch: 6| Step: 11
Training loss: 0.053042842995471864
Validation loss: 2.3337759734885184

Epoch: 6| Step: 12
Training loss: 0.09358540629927099
Validation loss: 2.3742441130561325

Epoch: 6| Step: 13
Training loss: 0.04389209173711563
Validation loss: 2.342766137573746

Epoch: 621| Step: 0
Training loss: 0.11824275777507232
Validation loss: 2.362250442267666

Epoch: 6| Step: 1
Training loss: 0.06052219749353338
Validation loss: 2.339107354475964

Epoch: 6| Step: 2
Training loss: 0.07617462593393028
Validation loss: 2.3582079306571466

Epoch: 6| Step: 3
Training loss: 0.08217208557297774
Validation loss: 2.3548118222014076

Epoch: 6| Step: 4
Training loss: 0.07109235052156601
Validation loss: 2.3830510297621683

Epoch: 6| Step: 5
Training loss: 0.08845438816184123
Validation loss: 2.3369850747937546

Epoch: 6| Step: 6
Training loss: 0.14260662786822662
Validation loss: 2.345901243593323

Epoch: 6| Step: 7
Training loss: 0.0786211916100869
Validation loss: 2.3639784004747826

Epoch: 6| Step: 8
Training loss: 0.1868993655717786
Validation loss: 2.334637972287556

Epoch: 6| Step: 9
Training loss: 0.07027802681899728
Validation loss: 2.351801817456342

Epoch: 6| Step: 10
Training loss: 0.12574113241596194
Validation loss: 2.3209962831349826

Epoch: 6| Step: 11
Training loss: 0.0948982796168755
Validation loss: 2.3214092847926

Epoch: 6| Step: 12
Training loss: 0.08077296452024521
Validation loss: 2.3321121220211145

Epoch: 6| Step: 13
Training loss: 0.0654225274338862
Validation loss: 2.3425222619887225

Epoch: 622| Step: 0
Training loss: 0.11698562399868848
Validation loss: 2.3277913771447363

Epoch: 6| Step: 1
Training loss: 0.09298316439111516
Validation loss: 2.3212065466022724

Epoch: 6| Step: 2
Training loss: 0.1232864114638168
Validation loss: 2.341475393556974

Epoch: 6| Step: 3
Training loss: 0.08059647028086575
Validation loss: 2.3428726525790826

Epoch: 6| Step: 4
Training loss: 0.07352360385158091
Validation loss: 2.3643550428310625

Epoch: 6| Step: 5
Training loss: 0.18597012482053052
Validation loss: 2.3490340141508512

Epoch: 6| Step: 6
Training loss: 0.11460544000851032
Validation loss: 2.3483306935364223

Epoch: 6| Step: 7
Training loss: 0.05412548221539612
Validation loss: 2.3584978602457736

Epoch: 6| Step: 8
Training loss: 0.07203835758467926
Validation loss: 2.3640716210098054

Epoch: 6| Step: 9
Training loss: 0.0731577991069414
Validation loss: 2.3525768116554424

Epoch: 6| Step: 10
Training loss: 0.1486127596748375
Validation loss: 2.3789314837009625

Epoch: 6| Step: 11
Training loss: 0.109660329917852
Validation loss: 2.3651335195743046

Epoch: 6| Step: 12
Training loss: 0.07943144054134854
Validation loss: 2.329302725335631

Epoch: 6| Step: 13
Training loss: 0.15729245884066376
Validation loss: 2.3600560437064524

Epoch: 623| Step: 0
Training loss: 0.1896989937682705
Validation loss: 2.3486422991066958

Epoch: 6| Step: 1
Training loss: 0.05225411914971135
Validation loss: 2.347677681494265

Epoch: 6| Step: 2
Training loss: 0.05842665449901407
Validation loss: 2.363673988061907

Epoch: 6| Step: 3
Training loss: 0.06752849807321973
Validation loss: 2.35240894581106

Epoch: 6| Step: 4
Training loss: 0.07562472607429012
Validation loss: 2.3540989020901155

Epoch: 6| Step: 5
Training loss: 0.12043139602186653
Validation loss: 2.3230306758426273

Epoch: 6| Step: 6
Training loss: 0.12312882585681123
Validation loss: 2.3402413491903387

Epoch: 6| Step: 7
Training loss: 0.14493537798796677
Validation loss: 2.3440170934384876

Epoch: 6| Step: 8
Training loss: 0.07136218031494912
Validation loss: 2.341002919380129

Epoch: 6| Step: 9
Training loss: 0.10461375482320327
Validation loss: 2.3678689167661453

Epoch: 6| Step: 10
Training loss: 0.11333918734144616
Validation loss: 2.3654706397014413

Epoch: 6| Step: 11
Training loss: 0.14204551555892328
Validation loss: 2.3840987788662713

Epoch: 6| Step: 12
Training loss: 0.08093989527961665
Validation loss: 2.364094363846415

Epoch: 6| Step: 13
Training loss: 0.09165437270035821
Validation loss: 2.372528805821025

Epoch: 624| Step: 0
Training loss: 0.08337649764806239
Validation loss: 2.3727661323250864

Epoch: 6| Step: 1
Training loss: 0.07613415273090535
Validation loss: 2.3538433571306423

Epoch: 6| Step: 2
Training loss: 0.13867878560859329
Validation loss: 2.3508230915253536

Epoch: 6| Step: 3
Training loss: 0.08218288598144989
Validation loss: 2.3523032803024595

Epoch: 6| Step: 4
Training loss: 0.11092093522017232
Validation loss: 2.363585250937773

Epoch: 6| Step: 5
Training loss: 0.07722668663192443
Validation loss: 2.3382780179186278

Epoch: 6| Step: 6
Training loss: 0.21071229498190705
Validation loss: 2.3549188262986136

Epoch: 6| Step: 7
Training loss: 0.07615153946002966
Validation loss: 2.33098773320651

Epoch: 6| Step: 8
Training loss: 0.07498739032242938
Validation loss: 2.3318984823060167

Epoch: 6| Step: 9
Training loss: 0.07582544139434248
Validation loss: 2.343550603444746

Epoch: 6| Step: 10
Training loss: 0.06718152152675645
Validation loss: 2.347278977364255

Epoch: 6| Step: 11
Training loss: 0.07024829966741732
Validation loss: 2.3206152220080507

Epoch: 6| Step: 12
Training loss: 0.09050061758302227
Validation loss: 2.330043399577716

Epoch: 6| Step: 13
Training loss: 0.053012055007287506
Validation loss: 2.3418130096561462

Epoch: 625| Step: 0
Training loss: 0.055084046762436036
Validation loss: 2.3561217364228235

Epoch: 6| Step: 1
Training loss: 0.09807655010779084
Validation loss: 2.351530041666695

Epoch: 6| Step: 2
Training loss: 0.1313040281537855
Validation loss: 2.340656813691964

Epoch: 6| Step: 3
Training loss: 0.20179128193830098
Validation loss: 2.3143925703323847

Epoch: 6| Step: 4
Training loss: 0.10662046947670344
Validation loss: 2.3459329689475945

Epoch: 6| Step: 5
Training loss: 0.06663427402581
Validation loss: 2.341957943989784

Epoch: 6| Step: 6
Training loss: 0.11866107563180389
Validation loss: 2.3237308201330418

Epoch: 6| Step: 7
Training loss: 0.05067291073677225
Validation loss: 2.3414516848494107

Epoch: 6| Step: 8
Training loss: 0.08621434031737875
Validation loss: 2.3418551227908257

Epoch: 6| Step: 9
Training loss: 0.07977231878427007
Validation loss: 2.304806710690644

Epoch: 6| Step: 10
Training loss: 0.11921516025583319
Validation loss: 2.341807603351783

Epoch: 6| Step: 11
Training loss: 0.08403147718396017
Validation loss: 2.320837154979199

Epoch: 6| Step: 12
Training loss: 0.08042331762504089
Validation loss: 2.3622952676968727

Epoch: 6| Step: 13
Training loss: 0.05675401723831019
Validation loss: 2.338996708278443

Epoch: 626| Step: 0
Training loss: 0.05680940203605452
Validation loss: 2.331858696533559

Epoch: 6| Step: 1
Training loss: 0.11690482777028927
Validation loss: 2.3689252145448805

Epoch: 6| Step: 2
Training loss: 0.09699159458392446
Validation loss: 2.3483975834833783

Epoch: 6| Step: 3
Training loss: 0.09080500627560371
Validation loss: 2.3659405340781987

Epoch: 6| Step: 4
Training loss: 0.08598500802598891
Validation loss: 2.329433514179016

Epoch: 6| Step: 5
Training loss: 0.08784333652336603
Validation loss: 2.3540307229971056

Epoch: 6| Step: 6
Training loss: 0.09097632472399067
Validation loss: 2.3560716370409667

Epoch: 6| Step: 7
Training loss: 0.0965748468934168
Validation loss: 2.352421153649299

Epoch: 6| Step: 8
Training loss: 0.13814866396205835
Validation loss: 2.3681199906610897

Epoch: 6| Step: 9
Training loss: 0.10347345230854509
Validation loss: 2.3344114123250357

Epoch: 6| Step: 10
Training loss: 0.10584931237792973
Validation loss: 2.3511228141149254

Epoch: 6| Step: 11
Training loss: 0.07579144822154373
Validation loss: 2.368432244221808

Epoch: 6| Step: 12
Training loss: 0.09054239368128551
Validation loss: 2.330286474917866

Epoch: 6| Step: 13
Training loss: 0.24755286787585476
Validation loss: 2.3363463906509825

Epoch: 627| Step: 0
Training loss: 0.0931909402427178
Validation loss: 2.341936231915055

Epoch: 6| Step: 1
Training loss: 0.08583056233714689
Validation loss: 2.3552965568465223

Epoch: 6| Step: 2
Training loss: 0.12832555600489357
Validation loss: 2.3764445958351095

Epoch: 6| Step: 3
Training loss: 0.053311461982203184
Validation loss: 2.353295802118335

Epoch: 6| Step: 4
Training loss: 0.08591355185180492
Validation loss: 2.3712746548007577

Epoch: 6| Step: 5
Training loss: 0.07402736683584939
Validation loss: 2.3779342845043443

Epoch: 6| Step: 6
Training loss: 0.10279357749067244
Validation loss: 2.368174603743964

Epoch: 6| Step: 7
Training loss: 0.13564941611670506
Validation loss: 2.363421474016508

Epoch: 6| Step: 8
Training loss: 0.08265370121200859
Validation loss: 2.3768003070515586

Epoch: 6| Step: 9
Training loss: 0.08187221824492213
Validation loss: 2.388954727082463

Epoch: 6| Step: 10
Training loss: 0.18580409842306625
Validation loss: 2.3711322730545312

Epoch: 6| Step: 11
Training loss: 0.12176155716073131
Validation loss: 2.353509507588088

Epoch: 6| Step: 12
Training loss: 0.1991885386728066
Validation loss: 2.3631789383708144

Epoch: 6| Step: 13
Training loss: 0.05536600044076578
Validation loss: 2.3593994456638825

Epoch: 628| Step: 0
Training loss: 0.08707329009070293
Validation loss: 2.3743644634736953

Epoch: 6| Step: 1
Training loss: 0.13328011321089478
Validation loss: 2.3746306580688508

Epoch: 6| Step: 2
Training loss: 0.09115770694050919
Validation loss: 2.3369213061094904

Epoch: 6| Step: 3
Training loss: 0.09100651367980565
Validation loss: 2.3093854466530783

Epoch: 6| Step: 4
Training loss: 0.11486473443224988
Validation loss: 2.3398290945921203

Epoch: 6| Step: 5
Training loss: 0.07087708669278449
Validation loss: 2.321996834410605

Epoch: 6| Step: 6
Training loss: 0.09971306116624801
Validation loss: 2.2970810497044742

Epoch: 6| Step: 7
Training loss: 0.09574143460404551
Validation loss: 2.337445072671311

Epoch: 6| Step: 8
Training loss: 0.12424463536205972
Validation loss: 2.325671477049625

Epoch: 6| Step: 9
Training loss: 0.09231555781081295
Validation loss: 2.3252447370194798

Epoch: 6| Step: 10
Training loss: 0.18662079671839096
Validation loss: 2.331541518997079

Epoch: 6| Step: 11
Training loss: 0.1098909936497619
Validation loss: 2.3122228408121086

Epoch: 6| Step: 12
Training loss: 0.12478552239830476
Validation loss: 2.3374448971880355

Epoch: 6| Step: 13
Training loss: 0.062275868360611074
Validation loss: 2.3490125404627733

Epoch: 629| Step: 0
Training loss: 0.11451245322814176
Validation loss: 2.351587418795632

Epoch: 6| Step: 1
Training loss: 0.08682169452948213
Validation loss: 2.3468878039511387

Epoch: 6| Step: 2
Training loss: 0.1138968021885872
Validation loss: 2.351669521129324

Epoch: 6| Step: 3
Training loss: 0.07051167160526269
Validation loss: 2.3810165407103145

Epoch: 6| Step: 4
Training loss: 0.053258861686139004
Validation loss: 2.326381232095443

Epoch: 6| Step: 5
Training loss: 0.04296585907747826
Validation loss: 2.3430282383836634

Epoch: 6| Step: 6
Training loss: 0.0947161550801971
Validation loss: 2.3541664661128245

Epoch: 6| Step: 7
Training loss: 0.13179030865025765
Validation loss: 2.348963278801234

Epoch: 6| Step: 8
Training loss: 0.0871519358970226
Validation loss: 2.3403864920353095

Epoch: 6| Step: 9
Training loss: 0.10753557516859832
Validation loss: 2.334239066656873

Epoch: 6| Step: 10
Training loss: 0.17985534085423982
Validation loss: 2.331603588726488

Epoch: 6| Step: 11
Training loss: 0.09095367771132126
Validation loss: 2.3158551658873527

Epoch: 6| Step: 12
Training loss: 0.10199220244613182
Validation loss: 2.3321642036043526

Epoch: 6| Step: 13
Training loss: 0.09468551611631801
Validation loss: 2.3407811438332335

Epoch: 630| Step: 0
Training loss: 0.13419800928953532
Validation loss: 2.3236890035230973

Epoch: 6| Step: 1
Training loss: 0.13048858920036605
Validation loss: 2.341167743090356

Epoch: 6| Step: 2
Training loss: 0.18376518929560162
Validation loss: 2.334718892369198

Epoch: 6| Step: 3
Training loss: 0.06102393237865497
Validation loss: 2.3242022577095134

Epoch: 6| Step: 4
Training loss: 0.07730637451651907
Validation loss: 2.3564545468068445

Epoch: 6| Step: 5
Training loss: 0.08039471220149308
Validation loss: 2.339210626333257

Epoch: 6| Step: 6
Training loss: 0.0657299149686523
Validation loss: 2.351046233692724

Epoch: 6| Step: 7
Training loss: 0.06942559543581105
Validation loss: 2.3594673778103776

Epoch: 6| Step: 8
Training loss: 0.10538700255890912
Validation loss: 2.310473830709111

Epoch: 6| Step: 9
Training loss: 0.059985703920254055
Validation loss: 2.3489743476767244

Epoch: 6| Step: 10
Training loss: 0.1178517628378172
Validation loss: 2.3619957548048474

Epoch: 6| Step: 11
Training loss: 0.08557389564190222
Validation loss: 2.337776278262819

Epoch: 6| Step: 12
Training loss: 0.06001828166605551
Validation loss: 2.3123181389911696

Epoch: 6| Step: 13
Training loss: 0.05718196947683561
Validation loss: 2.337073783102132

Epoch: 631| Step: 0
Training loss: 0.12956047932778395
Validation loss: 2.341041479849172

Epoch: 6| Step: 1
Training loss: 0.06495701093270217
Validation loss: 2.3536196109451666

Epoch: 6| Step: 2
Training loss: 0.06735006172270096
Validation loss: 2.3365749425399778

Epoch: 6| Step: 3
Training loss: 0.06004559368455937
Validation loss: 2.3448524819009506

Epoch: 6| Step: 4
Training loss: 0.0693004779405871
Validation loss: 2.3481033901561466

Epoch: 6| Step: 5
Training loss: 0.08243151490846232
Validation loss: 2.3384526167252955

Epoch: 6| Step: 6
Training loss: 0.059284179645272966
Validation loss: 2.3594410351989312

Epoch: 6| Step: 7
Training loss: 0.06344040060693738
Validation loss: 2.363421574623897

Epoch: 6| Step: 8
Training loss: 0.09566317911857823
Validation loss: 2.3690719649324175

Epoch: 6| Step: 9
Training loss: 0.11763429108150462
Validation loss: 2.365849029925625

Epoch: 6| Step: 10
Training loss: 0.06687674668851926
Validation loss: 2.35845504098688

Epoch: 6| Step: 11
Training loss: 0.1806436991169757
Validation loss: 2.331383957313622

Epoch: 6| Step: 12
Training loss: 0.08034505781624932
Validation loss: 2.397884836856348

Epoch: 6| Step: 13
Training loss: 0.11009770707878223
Validation loss: 2.3494271004200002

Epoch: 632| Step: 0
Training loss: 0.18841987706172278
Validation loss: 2.3306826889968706

Epoch: 6| Step: 1
Training loss: 0.06706437595068698
Validation loss: 2.377753353763348

Epoch: 6| Step: 2
Training loss: 0.04701825939935645
Validation loss: 2.350041398002528

Epoch: 6| Step: 3
Training loss: 0.07781142245546209
Validation loss: 2.343978083734377

Epoch: 6| Step: 4
Training loss: 0.1219443586951146
Validation loss: 2.360441893921454

Epoch: 6| Step: 5
Training loss: 0.08266205865500466
Validation loss: 2.3485560231701537

Epoch: 6| Step: 6
Training loss: 0.10902339329132638
Validation loss: 2.3466830500723463

Epoch: 6| Step: 7
Training loss: 0.05884482710855826
Validation loss: 2.3691092764342825

Epoch: 6| Step: 8
Training loss: 0.1127889186577865
Validation loss: 2.391324700586849

Epoch: 6| Step: 9
Training loss: 0.06373415910848389
Validation loss: 2.3757771444054723

Epoch: 6| Step: 10
Training loss: 0.06254293784787103
Validation loss: 2.3947657863553773

Epoch: 6| Step: 11
Training loss: 0.09084367964196934
Validation loss: 2.378669698585389

Epoch: 6| Step: 12
Training loss: 0.058581541696919266
Validation loss: 2.360794895124842

Epoch: 6| Step: 13
Training loss: 0.07911603406700249
Validation loss: 2.3868722244821092

Epoch: 633| Step: 0
Training loss: 0.06555375747898368
Validation loss: 2.3649784892460537

Epoch: 6| Step: 1
Training loss: 0.036212954696467736
Validation loss: 2.3657466304956993

Epoch: 6| Step: 2
Training loss: 0.09662752960158336
Validation loss: 2.396309097440031

Epoch: 6| Step: 3
Training loss: 0.12384366350125207
Validation loss: 2.370325016087079

Epoch: 6| Step: 4
Training loss: 0.08150401298466597
Validation loss: 2.361032883709246

Epoch: 6| Step: 5
Training loss: 0.13644883896895327
Validation loss: 2.358614543604159

Epoch: 6| Step: 6
Training loss: 0.0831313168126133
Validation loss: 2.3845506342591647

Epoch: 6| Step: 7
Training loss: 0.06290971306375599
Validation loss: 2.3719811739964847

Epoch: 6| Step: 8
Training loss: 0.18196754364040926
Validation loss: 2.3207567273865397

Epoch: 6| Step: 9
Training loss: 0.10635908816766709
Validation loss: 2.353942299214167

Epoch: 6| Step: 10
Training loss: 0.10600303495027726
Validation loss: 2.3577253239132414

Epoch: 6| Step: 11
Training loss: 0.05130085215487032
Validation loss: 2.3537326725425616

Epoch: 6| Step: 12
Training loss: 0.08744657718466778
Validation loss: 2.326137532655653

Epoch: 6| Step: 13
Training loss: 0.06072995938248005
Validation loss: 2.3509164738455977

Epoch: 634| Step: 0
Training loss: 0.055829530025645606
Validation loss: 2.3707773182933543

Epoch: 6| Step: 1
Training loss: 0.1014586706550808
Validation loss: 2.3600746545703526

Epoch: 6| Step: 2
Training loss: 0.03737199239087992
Validation loss: 2.3356818163727002

Epoch: 6| Step: 3
Training loss: 0.08550202781432957
Validation loss: 2.355004861512827

Epoch: 6| Step: 4
Training loss: 0.11620528343615072
Validation loss: 2.338374662891468

Epoch: 6| Step: 5
Training loss: 0.07217173340699502
Validation loss: 2.373937241119046

Epoch: 6| Step: 6
Training loss: 0.0437290273363233
Validation loss: 2.33882364438101

Epoch: 6| Step: 7
Training loss: 0.08250882852432805
Validation loss: 2.30300045792314

Epoch: 6| Step: 8
Training loss: 0.06024642585678192
Validation loss: 2.342571707797118

Epoch: 6| Step: 9
Training loss: 0.17626928820817842
Validation loss: 2.3355678032997145

Epoch: 6| Step: 10
Training loss: 0.0889820990803067
Validation loss: 2.3234541002885942

Epoch: 6| Step: 11
Training loss: 0.04838703722459035
Validation loss: 2.3383158503881134

Epoch: 6| Step: 12
Training loss: 0.060135927266347936
Validation loss: 2.348561878406772

Epoch: 6| Step: 13
Training loss: 0.14506017712578584
Validation loss: 2.355906361426016

Epoch: 635| Step: 0
Training loss: 0.10772451338332756
Validation loss: 2.361890893742818

Epoch: 6| Step: 1
Training loss: 0.09056748813840988
Validation loss: 2.3447849097138387

Epoch: 6| Step: 2
Training loss: 0.12780923487123172
Validation loss: 2.3585098289551327

Epoch: 6| Step: 3
Training loss: 0.04758356425790347
Validation loss: 2.3654086701957855

Epoch: 6| Step: 4
Training loss: 0.054908192186358236
Validation loss: 2.3599675507501985

Epoch: 6| Step: 5
Training loss: 0.07537553295220689
Validation loss: 2.3750707467924115

Epoch: 6| Step: 6
Training loss: 0.1980635679233659
Validation loss: 2.362650617859469

Epoch: 6| Step: 7
Training loss: 0.07953272566147687
Validation loss: 2.350788680723045

Epoch: 6| Step: 8
Training loss: 0.10531683860523952
Validation loss: 2.3401170999216556

Epoch: 6| Step: 9
Training loss: 0.04451143342512944
Validation loss: 2.3415124353316483

Epoch: 6| Step: 10
Training loss: 0.08059145220231748
Validation loss: 2.33939473580519

Epoch: 6| Step: 11
Training loss: 0.0630768367828557
Validation loss: 2.3571649267558903

Epoch: 6| Step: 12
Training loss: 0.06864088540751806
Validation loss: 2.336438803912364

Epoch: 6| Step: 13
Training loss: 0.04527605673312031
Validation loss: 2.343566983641813

Epoch: 636| Step: 0
Training loss: 0.0999257821846985
Validation loss: 2.324598761638981

Epoch: 6| Step: 1
Training loss: 0.06956027234264409
Validation loss: 2.3116238726712695

Epoch: 6| Step: 2
Training loss: 0.07737343307662578
Validation loss: 2.3389971050459235

Epoch: 6| Step: 3
Training loss: 0.04274996277731884
Validation loss: 2.345208684462646

Epoch: 6| Step: 4
Training loss: 0.0902439203209072
Validation loss: 2.3402664559019053

Epoch: 6| Step: 5
Training loss: 0.12067717764017533
Validation loss: 2.3616708430636275

Epoch: 6| Step: 6
Training loss: 0.06037559624847936
Validation loss: 2.3338879315841163

Epoch: 6| Step: 7
Training loss: 0.06538852065584556
Validation loss: 2.3692804375825025

Epoch: 6| Step: 8
Training loss: 0.06777119660314344
Validation loss: 2.378986058726009

Epoch: 6| Step: 9
Training loss: 0.07061606020385845
Validation loss: 2.3257786385427712

Epoch: 6| Step: 10
Training loss: 0.07860382094236858
Validation loss: 2.3226978201303345

Epoch: 6| Step: 11
Training loss: 0.0916191978803279
Validation loss: 2.3482606619025495

Epoch: 6| Step: 12
Training loss: 0.20134625700722436
Validation loss: 2.3290258595694566

Epoch: 6| Step: 13
Training loss: 0.0375186954898675
Validation loss: 2.3424422358487353

Epoch: 637| Step: 0
Training loss: 0.1255410079914509
Validation loss: 2.3536187068814316

Epoch: 6| Step: 1
Training loss: 0.0853893451734369
Validation loss: 2.342802957596395

Epoch: 6| Step: 2
Training loss: 0.0695903971197978
Validation loss: 2.3466276511333444

Epoch: 6| Step: 3
Training loss: 0.05869898287001677
Validation loss: 2.3584349775989937

Epoch: 6| Step: 4
Training loss: 0.09275447250068057
Validation loss: 2.351912369186016

Epoch: 6| Step: 5
Training loss: 0.06655867697701992
Validation loss: 2.3327731937561773

Epoch: 6| Step: 6
Training loss: 0.10839633252273734
Validation loss: 2.363555505565502

Epoch: 6| Step: 7
Training loss: 0.07638550719117473
Validation loss: 2.368110360155222

Epoch: 6| Step: 8
Training loss: 0.049193235531750756
Validation loss: 2.358864262615778

Epoch: 6| Step: 9
Training loss: 0.06530979901528466
Validation loss: 2.3529590578846715

Epoch: 6| Step: 10
Training loss: 0.05575637942136529
Validation loss: 2.3795280722181245

Epoch: 6| Step: 11
Training loss: 0.1807426487916988
Validation loss: 2.3540459276215793

Epoch: 6| Step: 12
Training loss: 0.08543292026394722
Validation loss: 2.3808678760928808

Epoch: 6| Step: 13
Training loss: 0.07674615737524855
Validation loss: 2.3753732130053424

Epoch: 638| Step: 0
Training loss: 0.09421660119543299
Validation loss: 2.3582277410506522

Epoch: 6| Step: 1
Training loss: 0.07977268070096952
Validation loss: 2.3957876778024834

Epoch: 6| Step: 2
Training loss: 0.07021711422746993
Validation loss: 2.3479202742026195

Epoch: 6| Step: 3
Training loss: 0.0578082158782423
Validation loss: 2.364643837911486

Epoch: 6| Step: 4
Training loss: 0.09728023139789188
Validation loss: 2.3453869490903316

Epoch: 6| Step: 5
Training loss: 0.10225429957415792
Validation loss: 2.372857289244489

Epoch: 6| Step: 6
Training loss: 0.10848484375841548
Validation loss: 2.3707977124712687

Epoch: 6| Step: 7
Training loss: 0.05744285192230139
Validation loss: 2.36835466476066

Epoch: 6| Step: 8
Training loss: 0.17579003947853553
Validation loss: 2.357433442458004

Epoch: 6| Step: 9
Training loss: 0.0866505883372706
Validation loss: 2.3307317485693053

Epoch: 6| Step: 10
Training loss: 0.151800213049185
Validation loss: 2.3726973545929453

Epoch: 6| Step: 11
Training loss: 0.04862670840980029
Validation loss: 2.375817791177172

Epoch: 6| Step: 12
Training loss: 0.08891900616329589
Validation loss: 2.3870765312201767

Epoch: 6| Step: 13
Training loss: 0.059827503415562686
Validation loss: 2.388579162161962

Epoch: 639| Step: 0
Training loss: 0.06583644629590009
Validation loss: 2.3742535254038355

Epoch: 6| Step: 1
Training loss: 0.09655647904102647
Validation loss: 2.3630982600269097

Epoch: 6| Step: 2
Training loss: 0.11469093376730935
Validation loss: 2.3611761382974907

Epoch: 6| Step: 3
Training loss: 0.06762322095357116
Validation loss: 2.3884561890893248

Epoch: 6| Step: 4
Training loss: 0.07574459201956318
Validation loss: 2.3694394954856093

Epoch: 6| Step: 5
Training loss: 0.08273495538848379
Validation loss: 2.3809923072989014

Epoch: 6| Step: 6
Training loss: 0.09467689942674924
Validation loss: 2.3599285836413397

Epoch: 6| Step: 7
Training loss: 0.07045743825568304
Validation loss: 2.354630339582544

Epoch: 6| Step: 8
Training loss: 0.17288226054385025
Validation loss: 2.3493080941962794

Epoch: 6| Step: 9
Training loss: 0.12495680897300097
Validation loss: 2.3626744002978124

Epoch: 6| Step: 10
Training loss: 0.0934011954247775
Validation loss: 2.3375089257735437

Epoch: 6| Step: 11
Training loss: 0.05765310275332079
Validation loss: 2.3256441310166207

Epoch: 6| Step: 12
Training loss: 0.07484105498532724
Validation loss: 2.3188927369503025

Epoch: 6| Step: 13
Training loss: 0.04999370796131742
Validation loss: 2.326204680552124

Epoch: 640| Step: 0
Training loss: 0.06038943324695885
Validation loss: 2.33587490778098

Epoch: 6| Step: 1
Training loss: 0.06503070700302807
Validation loss: 2.304097291107134

Epoch: 6| Step: 2
Training loss: 0.060656283341005056
Validation loss: 2.3235603351963507

Epoch: 6| Step: 3
Training loss: 0.0627999929174682
Validation loss: 2.322687506816621

Epoch: 6| Step: 4
Training loss: 0.05890374830989715
Validation loss: 2.3313063018280644

Epoch: 6| Step: 5
Training loss: 0.09613523925080529
Validation loss: 2.3303566864252283

Epoch: 6| Step: 6
Training loss: 0.18387519285735202
Validation loss: 2.3610968231244995

Epoch: 6| Step: 7
Training loss: 0.10539900274890732
Validation loss: 2.344574606160177

Epoch: 6| Step: 8
Training loss: 0.13937461790964756
Validation loss: 2.317554077088495

Epoch: 6| Step: 9
Training loss: 0.041345151040157783
Validation loss: 2.347174057908592

Epoch: 6| Step: 10
Training loss: 0.04929666785122593
Validation loss: 2.345807930469605

Epoch: 6| Step: 11
Training loss: 0.038333446208923296
Validation loss: 2.361637083154255

Epoch: 6| Step: 12
Training loss: 0.10857158012635568
Validation loss: 2.351412072952633

Epoch: 6| Step: 13
Training loss: 0.04632647266143134
Validation loss: 2.3406396102936684

Epoch: 641| Step: 0
Training loss: 0.0577950157970993
Validation loss: 2.3383926887525637

Epoch: 6| Step: 1
Training loss: 0.04742718102482222
Validation loss: 2.3456009608975257

Epoch: 6| Step: 2
Training loss: 0.06277739537882407
Validation loss: 2.3435849815986485

Epoch: 6| Step: 3
Training loss: 0.059044956365627434
Validation loss: 2.351842099747141

Epoch: 6| Step: 4
Training loss: 0.057941393444415026
Validation loss: 2.371019119667029

Epoch: 6| Step: 5
Training loss: 0.056574581545958645
Validation loss: 2.367366619786313

Epoch: 6| Step: 6
Training loss: 0.1777378228660091
Validation loss: 2.375283935642269

Epoch: 6| Step: 7
Training loss: 0.03604097067436798
Validation loss: 2.389510951769008

Epoch: 6| Step: 8
Training loss: 0.07945222599980051
Validation loss: 2.3581703183902656

Epoch: 6| Step: 9
Training loss: 0.05983135801938849
Validation loss: 2.364587765829957

Epoch: 6| Step: 10
Training loss: 0.1088186273517611
Validation loss: 2.367140635305349

Epoch: 6| Step: 11
Training loss: 0.10862445037135368
Validation loss: 2.3518719823646452

Epoch: 6| Step: 12
Training loss: 0.08174198101243302
Validation loss: 2.355161004045066

Epoch: 6| Step: 13
Training loss: 0.13539861519024732
Validation loss: 2.3411913101312987

Epoch: 642| Step: 0
Training loss: 0.08637748058237835
Validation loss: 2.3339652825912145

Epoch: 6| Step: 1
Training loss: 0.07288694379062259
Validation loss: 2.33565271556491

Epoch: 6| Step: 2
Training loss: 0.06268211742837036
Validation loss: 2.3729654037269015

Epoch: 6| Step: 3
Training loss: 0.05380909576804922
Validation loss: 2.3427587971362827

Epoch: 6| Step: 4
Training loss: 0.07527884265475704
Validation loss: 2.3484907314899384

Epoch: 6| Step: 5
Training loss: 0.08501064282555762
Validation loss: 2.347262817479648

Epoch: 6| Step: 6
Training loss: 0.12595103249126666
Validation loss: 2.356881959441693

Epoch: 6| Step: 7
Training loss: 0.10429211652094564
Validation loss: 2.341844127547465

Epoch: 6| Step: 8
Training loss: 0.19638716680095292
Validation loss: 2.344049060842389

Epoch: 6| Step: 9
Training loss: 0.06867166778980192
Validation loss: 2.357803506999247

Epoch: 6| Step: 10
Training loss: 0.056303221720547685
Validation loss: 2.346850407338296

Epoch: 6| Step: 11
Training loss: 0.057161444176662725
Validation loss: 2.3720643013007505

Epoch: 6| Step: 12
Training loss: 0.05630560153469633
Validation loss: 2.3580337707524905

Epoch: 6| Step: 13
Training loss: 0.10041374912449015
Validation loss: 2.389662484306835

Epoch: 643| Step: 0
Training loss: 0.08008968746633519
Validation loss: 2.3924554772214583

Epoch: 6| Step: 1
Training loss: 0.08097586188447999
Validation loss: 2.376674601436591

Epoch: 6| Step: 2
Training loss: 0.05777651772144915
Validation loss: 2.366458721751395

Epoch: 6| Step: 3
Training loss: 0.07678733893569617
Validation loss: 2.3601267931022467

Epoch: 6| Step: 4
Training loss: 0.10785717332331683
Validation loss: 2.350687246952384

Epoch: 6| Step: 5
Training loss: 0.09632811537817593
Validation loss: 2.3672633454553433

Epoch: 6| Step: 6
Training loss: 0.05425937853558689
Validation loss: 2.36605911276001

Epoch: 6| Step: 7
Training loss: 0.0695773709757682
Validation loss: 2.357659907215121

Epoch: 6| Step: 8
Training loss: 0.09010236773688836
Validation loss: 2.346615603247737

Epoch: 6| Step: 9
Training loss: 0.19121841049787616
Validation loss: 2.3476728226795727

Epoch: 6| Step: 10
Training loss: 0.12505415399032097
Validation loss: 2.341991204085279

Epoch: 6| Step: 11
Training loss: 0.11011225992133931
Validation loss: 2.3427208591390176

Epoch: 6| Step: 12
Training loss: 0.05402676752050836
Validation loss: 2.3137436548797323

Epoch: 6| Step: 13
Training loss: 0.09594988637358878
Validation loss: 2.309832696735875

Epoch: 644| Step: 0
Training loss: 0.07583789785120282
Validation loss: 2.3259504290029316

Epoch: 6| Step: 1
Training loss: 0.11919932404634893
Validation loss: 2.339516108065018

Epoch: 6| Step: 2
Training loss: 0.1496481962109928
Validation loss: 2.352847851459715

Epoch: 6| Step: 3
Training loss: 0.05840650083379323
Validation loss: 2.3006412494081103

Epoch: 6| Step: 4
Training loss: 0.060597771356468766
Validation loss: 2.3325675492936555

Epoch: 6| Step: 5
Training loss: 0.058681061383627935
Validation loss: 2.3394474278217983

Epoch: 6| Step: 6
Training loss: 0.09398441016623837
Validation loss: 2.3353096339070434

Epoch: 6| Step: 7
Training loss: 0.06564032398419098
Validation loss: 2.34447058863311

Epoch: 6| Step: 8
Training loss: 0.07872822751484596
Validation loss: 2.372576495502186

Epoch: 6| Step: 9
Training loss: 0.15580920987226524
Validation loss: 2.3373174588515413

Epoch: 6| Step: 10
Training loss: 0.08468855846190498
Validation loss: 2.349597468970943

Epoch: 6| Step: 11
Training loss: 0.12017944319818678
Validation loss: 2.3404499636639513

Epoch: 6| Step: 12
Training loss: 0.11534044265759529
Validation loss: 2.3614050689624464

Epoch: 6| Step: 13
Training loss: 0.24420567980916397
Validation loss: 2.386179608062192

Epoch: 645| Step: 0
Training loss: 0.0444960417346585
Validation loss: 2.3376570062714594

Epoch: 6| Step: 1
Training loss: 0.10538717046495438
Validation loss: 2.34146353649598

Epoch: 6| Step: 2
Training loss: 0.08964782581660874
Validation loss: 2.332088242272744

Epoch: 6| Step: 3
Training loss: 0.06485254259705023
Validation loss: 2.330612727382476

Epoch: 6| Step: 4
Training loss: 0.1064951631198719
Validation loss: 2.3238684153313205

Epoch: 6| Step: 5
Training loss: 0.09336552659521208
Validation loss: 2.3364463842018925

Epoch: 6| Step: 6
Training loss: 0.174250090564146
Validation loss: 2.326792941888042

Epoch: 6| Step: 7
Training loss: 0.14478831370219816
Validation loss: 2.319565875345104

Epoch: 6| Step: 8
Training loss: 0.19437107171139967
Validation loss: 2.3320857347915402

Epoch: 6| Step: 9
Training loss: 0.1292748959809982
Validation loss: 2.3523823307168206

Epoch: 6| Step: 10
Training loss: 0.0639364383321306
Validation loss: 2.3163260813825235

Epoch: 6| Step: 11
Training loss: 0.07569500929356068
Validation loss: 2.339052726358077

Epoch: 6| Step: 12
Training loss: 0.10318805941251599
Validation loss: 2.3268841436447625

Epoch: 6| Step: 13
Training loss: 0.07415168329521604
Validation loss: 2.3185287297482455

Epoch: 646| Step: 0
Training loss: 0.09756959885546924
Validation loss: 2.348510466660143

Epoch: 6| Step: 1
Training loss: 0.08904314960278124
Validation loss: 2.3608089990460184

Epoch: 6| Step: 2
Training loss: 0.16132699074704365
Validation loss: 2.3698344837437357

Epoch: 6| Step: 3
Training loss: 0.05996567042679696
Validation loss: 2.3445949286605674

Epoch: 6| Step: 4
Training loss: 0.10530705773245695
Validation loss: 2.384907859284239

Epoch: 6| Step: 5
Training loss: 0.06213952583254971
Validation loss: 2.3714158885622942

Epoch: 6| Step: 6
Training loss: 0.09516326289650943
Validation loss: 2.394687659724836

Epoch: 6| Step: 7
Training loss: 0.17269970532559478
Validation loss: 2.3820585292913874

Epoch: 6| Step: 8
Training loss: 0.06780482562978797
Validation loss: 2.401779444410355

Epoch: 6| Step: 9
Training loss: 0.11664221580478354
Validation loss: 2.3834231423477377

Epoch: 6| Step: 10
Training loss: 0.09343423415858894
Validation loss: 2.385840478298938

Epoch: 6| Step: 11
Training loss: 0.12339935452735454
Validation loss: 2.4009808158108266

Epoch: 6| Step: 12
Training loss: 0.14677717826869466
Validation loss: 2.3894336768762776

Epoch: 6| Step: 13
Training loss: 0.06580936527620752
Validation loss: 2.3905148390636937

Epoch: 647| Step: 0
Training loss: 0.17704685036387469
Validation loss: 2.3677426655150073

Epoch: 6| Step: 1
Training loss: 0.05566938901814257
Validation loss: 2.373039301972379

Epoch: 6| Step: 2
Training loss: 0.07575646860449761
Validation loss: 2.350490485020196

Epoch: 6| Step: 3
Training loss: 0.05840490825233449
Validation loss: 2.366782734665093

Epoch: 6| Step: 4
Training loss: 0.07729285942887712
Validation loss: 2.3523612461435324

Epoch: 6| Step: 5
Training loss: 0.10605282123251386
Validation loss: 2.3853640033092147

Epoch: 6| Step: 6
Training loss: 0.07857569394207245
Validation loss: 2.373326150515284

Epoch: 6| Step: 7
Training loss: 0.0861141707992378
Validation loss: 2.3386462716449117

Epoch: 6| Step: 8
Training loss: 0.10003947916655365
Validation loss: 2.3621397302473714

Epoch: 6| Step: 9
Training loss: 0.09048215402780108
Validation loss: 2.3460598584253174

Epoch: 6| Step: 10
Training loss: 0.1224001586095711
Validation loss: 2.3156680772424227

Epoch: 6| Step: 11
Training loss: 0.12579675898690512
Validation loss: 2.352950935357481

Epoch: 6| Step: 12
Training loss: 0.12113829916147316
Validation loss: 2.363978082185674

Epoch: 6| Step: 13
Training loss: 0.13413016836726468
Validation loss: 2.3483390143552745

Epoch: 648| Step: 0
Training loss: 0.07993423222352669
Validation loss: 2.325862181542844

Epoch: 6| Step: 1
Training loss: 0.18519535899086276
Validation loss: 2.350392179681834

Epoch: 6| Step: 2
Training loss: 0.06715235484015905
Validation loss: 2.374585178592185

Epoch: 6| Step: 3
Training loss: 0.11319177481152956
Validation loss: 2.343207511877194

Epoch: 6| Step: 4
Training loss: 0.09993705426182925
Validation loss: 2.3491276978580387

Epoch: 6| Step: 5
Training loss: 0.05255854397887982
Validation loss: 2.3531035584590945

Epoch: 6| Step: 6
Training loss: 0.11688174653470777
Validation loss: 2.368368064450378

Epoch: 6| Step: 7
Training loss: 0.08525952127324782
Validation loss: 2.3520601946683746

Epoch: 6| Step: 8
Training loss: 0.06572738222358955
Validation loss: 2.3862079382345307

Epoch: 6| Step: 9
Training loss: 0.06687183064566643
Validation loss: 2.3526935674706877

Epoch: 6| Step: 10
Training loss: 0.11138084485096081
Validation loss: 2.3574346180139227

Epoch: 6| Step: 11
Training loss: 0.09354186298654908
Validation loss: 2.3475314441860333

Epoch: 6| Step: 12
Training loss: 0.07027301739434057
Validation loss: 2.3471228434966775

Epoch: 6| Step: 13
Training loss: 0.07124555906459797
Validation loss: 2.352656697380403

Epoch: 649| Step: 0
Training loss: 0.04441042442737397
Validation loss: 2.3774668690032823

Epoch: 6| Step: 1
Training loss: 0.18806288588811673
Validation loss: 2.356941314787747

Epoch: 6| Step: 2
Training loss: 0.06974911819134744
Validation loss: 2.340065997826466

Epoch: 6| Step: 3
Training loss: 0.07738008007133847
Validation loss: 2.338039170358228

Epoch: 6| Step: 4
Training loss: 0.13011180080920803
Validation loss: 2.363307816659423

Epoch: 6| Step: 5
Training loss: 0.08355555174114443
Validation loss: 2.3492715332682277

Epoch: 6| Step: 6
Training loss: 0.05757360911679047
Validation loss: 2.3613547760590015

Epoch: 6| Step: 7
Training loss: 0.0838687455592704
Validation loss: 2.3641884543486267

Epoch: 6| Step: 8
Training loss: 0.0643696967505251
Validation loss: 2.3803839379219918

Epoch: 6| Step: 9
Training loss: 0.0802185641406603
Validation loss: 2.361765592936176

Epoch: 6| Step: 10
Training loss: 0.10471002653079034
Validation loss: 2.378446325892639

Epoch: 6| Step: 11
Training loss: 0.08627280473705914
Validation loss: 2.3728744675799676

Epoch: 6| Step: 12
Training loss: 0.0623383218988363
Validation loss: 2.3719295711114814

Epoch: 6| Step: 13
Training loss: 0.10226564739568011
Validation loss: 2.348739709528422

Epoch: 650| Step: 0
Training loss: 0.08680934705666171
Validation loss: 2.3741904532153564

Epoch: 6| Step: 1
Training loss: 0.0798870516913681
Validation loss: 2.380623731359136

Epoch: 6| Step: 2
Training loss: 0.07324841790720316
Validation loss: 2.3874398479756

Epoch: 6| Step: 3
Training loss: 0.11573425669411058
Validation loss: 2.393671447326943

Epoch: 6| Step: 4
Training loss: 0.07617676548052771
Validation loss: 2.3798711069364615

Epoch: 6| Step: 5
Training loss: 0.0696647463524641
Validation loss: 2.3829759240151542

Epoch: 6| Step: 6
Training loss: 0.055887203770508126
Validation loss: 2.3502979704494633

Epoch: 6| Step: 7
Training loss: 0.05138413472422465
Validation loss: 2.3636127724493163

Epoch: 6| Step: 8
Training loss: 0.05837896239200469
Validation loss: 2.373605801434696

Epoch: 6| Step: 9
Training loss: 0.0936132715481093
Validation loss: 2.3669923620490803

Epoch: 6| Step: 10
Training loss: 0.05555450382371284
Validation loss: 2.351982648515377

Epoch: 6| Step: 11
Training loss: 0.08419735373526667
Validation loss: 2.3644303451282145

Epoch: 6| Step: 12
Training loss: 0.11535447134115269
Validation loss: 2.3674234468758923

Epoch: 6| Step: 13
Training loss: 0.23155348298178366
Validation loss: 2.371623392013898

Epoch: 651| Step: 0
Training loss: 0.09489098269895951
Validation loss: 2.3553906842419496

Epoch: 6| Step: 1
Training loss: 0.086428450958053
Validation loss: 2.357470593438963

Epoch: 6| Step: 2
Training loss: 0.08044617090751745
Validation loss: 2.370683560129059

Epoch: 6| Step: 3
Training loss: 0.053177262993066014
Validation loss: 2.392505263959691

Epoch: 6| Step: 4
Training loss: 0.10222137830137253
Validation loss: 2.368689036831483

Epoch: 6| Step: 5
Training loss: 0.033086156979478046
Validation loss: 2.3798980787132633

Epoch: 6| Step: 6
Training loss: 0.03968016630376929
Validation loss: 2.3851160143068433

Epoch: 6| Step: 7
Training loss: 0.08353590713192041
Validation loss: 2.37656833309545

Epoch: 6| Step: 8
Training loss: 0.1743496507845046
Validation loss: 2.3887111330668738

Epoch: 6| Step: 9
Training loss: 0.18986448873264059
Validation loss: 2.398765232400099

Epoch: 6| Step: 10
Training loss: 0.08150819219604818
Validation loss: 2.3912613893176387

Epoch: 6| Step: 11
Training loss: 0.07828536264576887
Validation loss: 2.359447206770735

Epoch: 6| Step: 12
Training loss: 0.05527986777209978
Validation loss: 2.35350687042965

Epoch: 6| Step: 13
Training loss: 0.0895438163486559
Validation loss: 2.349986598601275

Epoch: 652| Step: 0
Training loss: 0.08740244764183305
Validation loss: 2.3501888677506027

Epoch: 6| Step: 1
Training loss: 0.05590858625922043
Validation loss: 2.3776702172622444

Epoch: 6| Step: 2
Training loss: 0.13267859552667785
Validation loss: 2.3406902075509546

Epoch: 6| Step: 3
Training loss: 0.15961404642335408
Validation loss: 2.3197216349060996

Epoch: 6| Step: 4
Training loss: 0.08175168764927183
Validation loss: 2.314072140780926

Epoch: 6| Step: 5
Training loss: 0.09659084418716647
Validation loss: 2.3211057291868262

Epoch: 6| Step: 6
Training loss: 0.0640984043538216
Validation loss: 2.3254477195645573

Epoch: 6| Step: 7
Training loss: 0.0969267299419495
Validation loss: 2.344015656322335

Epoch: 6| Step: 8
Training loss: 0.1738312806689536
Validation loss: 2.3275221210398374

Epoch: 6| Step: 9
Training loss: 0.08979087808038505
Validation loss: 2.3358906437929976

Epoch: 6| Step: 10
Training loss: 0.09435849107731623
Validation loss: 2.366906580607275

Epoch: 6| Step: 11
Training loss: 0.08769587025964161
Validation loss: 2.2924449959976494

Epoch: 6| Step: 12
Training loss: 0.0707372544831486
Validation loss: 2.330924065510013

Epoch: 6| Step: 13
Training loss: 0.03660486815536594
Validation loss: 2.3536450743567072

Epoch: 653| Step: 0
Training loss: 0.07929499840042675
Validation loss: 2.3622874496658457

Epoch: 6| Step: 1
Training loss: 0.13989709177774357
Validation loss: 2.3600971567587083

Epoch: 6| Step: 2
Training loss: 0.07285327334095379
Validation loss: 2.353358691363378

Epoch: 6| Step: 3
Training loss: 0.07814340374664014
Validation loss: 2.340923076208054

Epoch: 6| Step: 4
Training loss: 0.07900954710882761
Validation loss: 2.3615000227351053

Epoch: 6| Step: 5
Training loss: 0.20085469954519256
Validation loss: 2.310559103191077

Epoch: 6| Step: 6
Training loss: 0.08087595226067716
Validation loss: 2.355658266554605

Epoch: 6| Step: 7
Training loss: 0.05561625786995834
Validation loss: 2.3612783570224316

Epoch: 6| Step: 8
Training loss: 0.06820008929860653
Validation loss: 2.328500182698538

Epoch: 6| Step: 9
Training loss: 0.05383501459996084
Validation loss: 2.3572364257939378

Epoch: 6| Step: 10
Training loss: 0.07600552171252051
Validation loss: 2.361977992648983

Epoch: 6| Step: 11
Training loss: 0.0770126971463951
Validation loss: 2.3245421768739827

Epoch: 6| Step: 12
Training loss: 0.06347103828454141
Validation loss: 2.340160426165849

Epoch: 6| Step: 13
Training loss: 0.05234213050785206
Validation loss: 2.3346531225744536

Epoch: 654| Step: 0
Training loss: 0.1026066602687902
Validation loss: 2.345123829054158

Epoch: 6| Step: 1
Training loss: 0.04924459233101602
Validation loss: 2.344744793187732

Epoch: 6| Step: 2
Training loss: 0.07088567642565596
Validation loss: 2.355109035334059

Epoch: 6| Step: 3
Training loss: 0.08102351473958265
Validation loss: 2.350333395204328

Epoch: 6| Step: 4
Training loss: 0.17395528150116243
Validation loss: 2.387377612213345

Epoch: 6| Step: 5
Training loss: 0.08509881243599951
Validation loss: 2.324804439428998

Epoch: 6| Step: 6
Training loss: 0.13080822243784315
Validation loss: 2.352518538914531

Epoch: 6| Step: 7
Training loss: 0.08577977683846938
Validation loss: 2.3493313596971572

Epoch: 6| Step: 8
Training loss: 0.059663668163795126
Validation loss: 2.337582059670903

Epoch: 6| Step: 9
Training loss: 0.05873349532412153
Validation loss: 2.360599817893757

Epoch: 6| Step: 10
Training loss: 0.08820864573991587
Validation loss: 2.3390273074027834

Epoch: 6| Step: 11
Training loss: 0.07335179075416239
Validation loss: 2.3290408163106884

Epoch: 6| Step: 12
Training loss: 0.06047918011660486
Validation loss: 2.3222129466198727

Epoch: 6| Step: 13
Training loss: 0.06850404757376193
Validation loss: 2.342028953312257

Epoch: 655| Step: 0
Training loss: 0.1749891075508015
Validation loss: 2.3423724057531516

Epoch: 6| Step: 1
Training loss: 0.07341098408152853
Validation loss: 2.333235178991006

Epoch: 6| Step: 2
Training loss: 0.06912697951046042
Validation loss: 2.339899995411212

Epoch: 6| Step: 3
Training loss: 0.07610031887287931
Validation loss: 2.355901872695959

Epoch: 6| Step: 4
Training loss: 0.06917385175787326
Validation loss: 2.3523280588363282

Epoch: 6| Step: 5
Training loss: 0.06643319985548883
Validation loss: 2.361629191298773

Epoch: 6| Step: 6
Training loss: 0.10930143164133804
Validation loss: 2.32973739927011

Epoch: 6| Step: 7
Training loss: 0.05185285874172359
Validation loss: 2.349617896415206

Epoch: 6| Step: 8
Training loss: 0.0792797048893308
Validation loss: 2.322384774543905

Epoch: 6| Step: 9
Training loss: 0.09206878182583692
Validation loss: 2.354136592474336

Epoch: 6| Step: 10
Training loss: 0.05601407109782727
Validation loss: 2.340180020157753

Epoch: 6| Step: 11
Training loss: 0.07190641812728032
Validation loss: 2.380412707818802

Epoch: 6| Step: 12
Training loss: 0.10174809975132555
Validation loss: 2.369299977943614

Epoch: 6| Step: 13
Training loss: 0.05916831124369606
Validation loss: 2.3551904929647356

Epoch: 656| Step: 0
Training loss: 0.042592360310735884
Validation loss: 2.366247751321686

Epoch: 6| Step: 1
Training loss: 0.06605780921227894
Validation loss: 2.351758580319549

Epoch: 6| Step: 2
Training loss: 0.06368654804599236
Validation loss: 2.3540127798565695

Epoch: 6| Step: 3
Training loss: 0.11745812638841802
Validation loss: 2.3619930028462104

Epoch: 6| Step: 4
Training loss: 0.10716014535253306
Validation loss: 2.3439133792934266

Epoch: 6| Step: 5
Training loss: 0.07101708289497499
Validation loss: 2.3507777992407264

Epoch: 6| Step: 6
Training loss: 0.1045938469684312
Validation loss: 2.365462721077832

Epoch: 6| Step: 7
Training loss: 0.055167870671839356
Validation loss: 2.3519996070839513

Epoch: 6| Step: 8
Training loss: 0.08374026773969247
Validation loss: 2.3310850411511805

Epoch: 6| Step: 9
Training loss: 0.10927808248288949
Validation loss: 2.3449868808549645

Epoch: 6| Step: 10
Training loss: 0.05355088054167218
Validation loss: 2.3417193644822634

Epoch: 6| Step: 11
Training loss: 0.09289202389092882
Validation loss: 2.334624951110058

Epoch: 6| Step: 12
Training loss: 0.06474181027289283
Validation loss: 2.3364053366702855

Epoch: 6| Step: 13
Training loss: 0.22915467136952036
Validation loss: 2.3308059816299407

Epoch: 657| Step: 0
Training loss: 0.09284908824186944
Validation loss: 2.313903852798377

Epoch: 6| Step: 1
Training loss: 0.11481234484378089
Validation loss: 2.3224651573472226

Epoch: 6| Step: 2
Training loss: 0.11275558760509602
Validation loss: 2.359765572244595

Epoch: 6| Step: 3
Training loss: 0.047337296328516944
Validation loss: 2.3202482360799337

Epoch: 6| Step: 4
Training loss: 0.0524297565435024
Validation loss: 2.346477296125671

Epoch: 6| Step: 5
Training loss: 0.07325644354361417
Validation loss: 2.308165314807295

Epoch: 6| Step: 6
Training loss: 0.07528603641840859
Validation loss: 2.3404385072417044

Epoch: 6| Step: 7
Training loss: 0.17756054310792818
Validation loss: 2.347146154141411

Epoch: 6| Step: 8
Training loss: 0.11121356658186132
Validation loss: 2.3579796800463346

Epoch: 6| Step: 9
Training loss: 0.09222931156157119
Validation loss: 2.3553675428100425

Epoch: 6| Step: 10
Training loss: 0.07868130033641274
Validation loss: 2.3638876066336194

Epoch: 6| Step: 11
Training loss: 0.09156612552619156
Validation loss: 2.3513664894612023

Epoch: 6| Step: 12
Training loss: 0.06901836874268524
Validation loss: 2.3537545249495135

Epoch: 6| Step: 13
Training loss: 0.07358714883501674
Validation loss: 2.3728727303048998

Epoch: 658| Step: 0
Training loss: 0.04513009679328913
Validation loss: 2.3557272365028252

Epoch: 6| Step: 1
Training loss: 0.1044743469195619
Validation loss: 2.3401131724859767

Epoch: 6| Step: 2
Training loss: 0.1672148419242351
Validation loss: 2.3713858111463373

Epoch: 6| Step: 3
Training loss: 0.05030071791419512
Validation loss: 2.368609807637125

Epoch: 6| Step: 4
Training loss: 0.060880839770260285
Validation loss: 2.3618881356921917

Epoch: 6| Step: 5
Training loss: 0.09269567041050697
Validation loss: 2.35809876558753

Epoch: 6| Step: 6
Training loss: 0.06789962937109222
Validation loss: 2.3569503067709467

Epoch: 6| Step: 7
Training loss: 0.1220849219162974
Validation loss: 2.336588170090892

Epoch: 6| Step: 8
Training loss: 0.11201409600952092
Validation loss: 2.3382310633404293

Epoch: 6| Step: 9
Training loss: 0.05538443971353655
Validation loss: 2.3587236141558847

Epoch: 6| Step: 10
Training loss: 0.11039496724415951
Validation loss: 2.3454224075777232

Epoch: 6| Step: 11
Training loss: 0.05236933780235115
Validation loss: 2.3585326118358867

Epoch: 6| Step: 12
Training loss: 0.05674613793188163
Validation loss: 2.3295218893687832

Epoch: 6| Step: 13
Training loss: 0.06071972209225405
Validation loss: 2.33374025456015

Epoch: 659| Step: 0
Training loss: 0.0664442108148185
Validation loss: 2.3517716374430755

Epoch: 6| Step: 1
Training loss: 0.11059769045494736
Validation loss: 2.3515626755199475

Epoch: 6| Step: 2
Training loss: 0.07403580491818307
Validation loss: 2.3437671455658564

Epoch: 6| Step: 3
Training loss: 0.1774530699806165
Validation loss: 2.310419619083714

Epoch: 6| Step: 4
Training loss: 0.094066903820744
Validation loss: 2.3511425310081204

Epoch: 6| Step: 5
Training loss: 0.1073645265259609
Validation loss: 2.326210484597089

Epoch: 6| Step: 6
Training loss: 0.07507485178640809
Validation loss: 2.3328696052331304

Epoch: 6| Step: 7
Training loss: 0.07287061534183684
Validation loss: 2.3393510364802954

Epoch: 6| Step: 8
Training loss: 0.05522561987265222
Validation loss: 2.3286170855111243

Epoch: 6| Step: 9
Training loss: 0.10507664821253512
Validation loss: 2.354283602074793

Epoch: 6| Step: 10
Training loss: 0.07078775417578471
Validation loss: 2.336016080317046

Epoch: 6| Step: 11
Training loss: 0.058631938172365006
Validation loss: 2.3493431726846317

Epoch: 6| Step: 12
Training loss: 0.05361459935414537
Validation loss: 2.3439081850985493

Epoch: 6| Step: 13
Training loss: 0.08816404199832378
Validation loss: 2.326916604779197

Epoch: 660| Step: 0
Training loss: 0.05103605332372671
Validation loss: 2.335861076948333

Epoch: 6| Step: 1
Training loss: 0.12244860588541236
Validation loss: 2.352563605349952

Epoch: 6| Step: 2
Training loss: 0.04811092561816617
Validation loss: 2.3550757833350366

Epoch: 6| Step: 3
Training loss: 0.07134062065315994
Validation loss: 2.305373517817324

Epoch: 6| Step: 4
Training loss: 0.07719166063956247
Validation loss: 2.312001204193604

Epoch: 6| Step: 5
Training loss: 0.05798430592680065
Validation loss: 2.318532108822213

Epoch: 6| Step: 6
Training loss: 0.07732886330072312
Validation loss: 2.317745535205032

Epoch: 6| Step: 7
Training loss: 0.18270473115828842
Validation loss: 2.329799166046327

Epoch: 6| Step: 8
Training loss: 0.08964375336155063
Validation loss: 2.3396486127741714

Epoch: 6| Step: 9
Training loss: 0.08860995193290935
Validation loss: 2.3123268166801365

Epoch: 6| Step: 10
Training loss: 0.11077939708542896
Validation loss: 2.3345303757385927

Epoch: 6| Step: 11
Training loss: 0.05725284117893325
Validation loss: 2.3290741895967275

Epoch: 6| Step: 12
Training loss: 0.057773134564140044
Validation loss: 2.3365974740964437

Epoch: 6| Step: 13
Training loss: 0.046843073323581196
Validation loss: 2.334096051808359

Epoch: 661| Step: 0
Training loss: 0.07062669595859498
Validation loss: 2.3217818515262354

Epoch: 6| Step: 1
Training loss: 0.060776375535884865
Validation loss: 2.3259685175331803

Epoch: 6| Step: 2
Training loss: 0.06092081804451976
Validation loss: 2.3332654284632652

Epoch: 6| Step: 3
Training loss: 0.05558397990658041
Validation loss: 2.341901281669171

Epoch: 6| Step: 4
Training loss: 0.052153666016284975
Validation loss: 2.3399868830174815

Epoch: 6| Step: 5
Training loss: 0.1921810118037487
Validation loss: 2.35296807816068

Epoch: 6| Step: 6
Training loss: 0.0676404306085551
Validation loss: 2.331348665784295

Epoch: 6| Step: 7
Training loss: 0.058036861868466495
Validation loss: 2.3438501485668435

Epoch: 6| Step: 8
Training loss: 0.11733152757629194
Validation loss: 2.33304429809417

Epoch: 6| Step: 9
Training loss: 0.0912434044342061
Validation loss: 2.3193183095679846

Epoch: 6| Step: 10
Training loss: 0.07959773018736147
Validation loss: 2.3112271055775633

Epoch: 6| Step: 11
Training loss: 0.04094954969885008
Validation loss: 2.328279146436296

Epoch: 6| Step: 12
Training loss: 0.04539579502789117
Validation loss: 2.3232338772117913

Epoch: 6| Step: 13
Training loss: 0.059769068257245324
Validation loss: 2.337843348470007

Epoch: 662| Step: 0
Training loss: 0.09172248870079197
Validation loss: 2.3238479363952855

Epoch: 6| Step: 1
Training loss: 0.09049717524931937
Validation loss: 2.308478867168659

Epoch: 6| Step: 2
Training loss: 0.17425944361963353
Validation loss: 2.3212106763875915

Epoch: 6| Step: 3
Training loss: 0.10017333542576316
Validation loss: 2.3200651647231676

Epoch: 6| Step: 4
Training loss: 0.03834518815120647
Validation loss: 2.3293775168018707

Epoch: 6| Step: 5
Training loss: 0.07881671929806551
Validation loss: 2.353016297753591

Epoch: 6| Step: 6
Training loss: 0.06793148455181407
Validation loss: 2.3457749608248246

Epoch: 6| Step: 7
Training loss: 0.05204599154480396
Validation loss: 2.344479704989923

Epoch: 6| Step: 8
Training loss: 0.054049685115662306
Validation loss: 2.3773978379823486

Epoch: 6| Step: 9
Training loss: 0.10427044129877518
Validation loss: 2.3420305136979658

Epoch: 6| Step: 10
Training loss: 0.08509664549368487
Validation loss: 2.3482548872481277

Epoch: 6| Step: 11
Training loss: 0.05418581839886926
Validation loss: 2.368688170988457

Epoch: 6| Step: 12
Training loss: 0.08707407355795918
Validation loss: 2.3629823858272148

Epoch: 6| Step: 13
Training loss: 0.046279477080658195
Validation loss: 2.3398062676473415

Epoch: 663| Step: 0
Training loss: 0.16832569365133979
Validation loss: 2.343760164847259

Epoch: 6| Step: 1
Training loss: 0.10411364179315556
Validation loss: 2.35105952921258

Epoch: 6| Step: 2
Training loss: 0.11166306354927527
Validation loss: 2.3504487791035222

Epoch: 6| Step: 3
Training loss: 0.05977108414656231
Validation loss: 2.342376792357955

Epoch: 6| Step: 4
Training loss: 0.0523657498103284
Validation loss: 2.3441986245284046

Epoch: 6| Step: 5
Training loss: 0.04817509271186426
Validation loss: 2.319381328697737

Epoch: 6| Step: 6
Training loss: 0.09776085496379794
Validation loss: 2.326843457377183

Epoch: 6| Step: 7
Training loss: 0.079911990071804
Validation loss: 2.3283309179255873

Epoch: 6| Step: 8
Training loss: 0.1082733394711265
Validation loss: 2.3294870219419117

Epoch: 6| Step: 9
Training loss: 0.037127634625679806
Validation loss: 2.31993252111702

Epoch: 6| Step: 10
Training loss: 0.11357742265690642
Validation loss: 2.31422650375333

Epoch: 6| Step: 11
Training loss: 0.056722298470409015
Validation loss: 2.3348625086430204

Epoch: 6| Step: 12
Training loss: 0.044004950851726794
Validation loss: 2.3277955907870282

Epoch: 6| Step: 13
Training loss: 0.04147093108069664
Validation loss: 2.3076042649270834

Epoch: 664| Step: 0
Training loss: 0.17234042937433602
Validation loss: 2.327781361729127

Epoch: 6| Step: 1
Training loss: 0.07580582377590488
Validation loss: 2.3264928639521996

Epoch: 6| Step: 2
Training loss: 0.10786330815747558
Validation loss: 2.3292936255213617

Epoch: 6| Step: 3
Training loss: 0.08326950056116017
Validation loss: 2.2897236388750732

Epoch: 6| Step: 4
Training loss: 0.06957072144890974
Validation loss: 2.320685912256117

Epoch: 6| Step: 5
Training loss: 0.11150146675481551
Validation loss: 2.3228827025714742

Epoch: 6| Step: 6
Training loss: 0.05256299586946684
Validation loss: 2.331028588267862

Epoch: 6| Step: 7
Training loss: 0.07367500846647221
Validation loss: 2.3124529028089986

Epoch: 6| Step: 8
Training loss: 0.05631925612599417
Validation loss: 2.3339414558544003

Epoch: 6| Step: 9
Training loss: 0.13295503288950708
Validation loss: 2.3207730707323124

Epoch: 6| Step: 10
Training loss: 0.06446317753282259
Validation loss: 2.3437454672055185

Epoch: 6| Step: 11
Training loss: 0.07252835828493039
Validation loss: 2.3435104061703353

Epoch: 6| Step: 12
Training loss: 0.07314502311001304
Validation loss: 2.3344890655514585

Epoch: 6| Step: 13
Training loss: 0.03140962705319384
Validation loss: 2.339055822602946

Epoch: 665| Step: 0
Training loss: 0.06438351976394777
Validation loss: 2.3340878592453134

Epoch: 6| Step: 1
Training loss: 0.17128920430054662
Validation loss: 2.3255164494750065

Epoch: 6| Step: 2
Training loss: 0.08779740688321046
Validation loss: 2.3234063347037814

Epoch: 6| Step: 3
Training loss: 0.07380581788725482
Validation loss: 2.3130447069881064

Epoch: 6| Step: 4
Training loss: 0.05847224512006015
Validation loss: 2.319252578351317

Epoch: 6| Step: 5
Training loss: 0.05416386542428144
Validation loss: 2.347609166855672

Epoch: 6| Step: 6
Training loss: 0.09100479953876145
Validation loss: 2.3620587760051865

Epoch: 6| Step: 7
Training loss: 0.0533123485500425
Validation loss: 2.3635838235502504

Epoch: 6| Step: 8
Training loss: 0.13716571498031224
Validation loss: 2.3452979715039435

Epoch: 6| Step: 9
Training loss: 0.07901044589821449
Validation loss: 2.3630302250456174

Epoch: 6| Step: 10
Training loss: 0.07372026183359734
Validation loss: 2.3576303844834254

Epoch: 6| Step: 11
Training loss: 0.05534152649328238
Validation loss: 2.3621753686616622

Epoch: 6| Step: 12
Training loss: 0.05800010039057758
Validation loss: 2.339158863294393

Epoch: 6| Step: 13
Training loss: 0.0624291625769989
Validation loss: 2.344988526731815

Epoch: 666| Step: 0
Training loss: 0.0744135145732902
Validation loss: 2.3559096324806412

Epoch: 6| Step: 1
Training loss: 0.055014088533788565
Validation loss: 2.3479778438145447

Epoch: 6| Step: 2
Training loss: 0.10727013795170653
Validation loss: 2.3798375368081515

Epoch: 6| Step: 3
Training loss: 0.10658042976416318
Validation loss: 2.3729677448510103

Epoch: 6| Step: 4
Training loss: 0.07622603789384859
Validation loss: 2.3800897167279236

Epoch: 6| Step: 5
Training loss: 0.07197025222593596
Validation loss: 2.374377112319528

Epoch: 6| Step: 6
Training loss: 0.050034690814117225
Validation loss: 2.3552694584481326

Epoch: 6| Step: 7
Training loss: 0.05494095617354737
Validation loss: 2.3685709718848393

Epoch: 6| Step: 8
Training loss: 0.1811240552011441
Validation loss: 2.3928464449849707

Epoch: 6| Step: 9
Training loss: 0.052815044478624146
Validation loss: 2.3515540139764677

Epoch: 6| Step: 10
Training loss: 0.06184071142862511
Validation loss: 2.3690469881894978

Epoch: 6| Step: 11
Training loss: 0.05755678138106
Validation loss: 2.3470930871911033

Epoch: 6| Step: 12
Training loss: 0.06693783980082077
Validation loss: 2.3729039708108424

Epoch: 6| Step: 13
Training loss: 0.03478287740243548
Validation loss: 2.3521927055294167

Epoch: 667| Step: 0
Training loss: 0.05570957765750462
Validation loss: 2.3394913330024183

Epoch: 6| Step: 1
Training loss: 0.06093439940976341
Validation loss: 2.3473507764308637

Epoch: 6| Step: 2
Training loss: 0.058781581066777076
Validation loss: 2.336677572591125

Epoch: 6| Step: 3
Training loss: 0.050007989550567476
Validation loss: 2.3369409086105533

Epoch: 6| Step: 4
Training loss: 0.08043140892161617
Validation loss: 2.370783757725322

Epoch: 6| Step: 5
Training loss: 0.10072546142997675
Validation loss: 2.3433043550510586

Epoch: 6| Step: 6
Training loss: 0.11328508107514441
Validation loss: 2.3487090251848066

Epoch: 6| Step: 7
Training loss: 0.17335210407579413
Validation loss: 2.345798737856187

Epoch: 6| Step: 8
Training loss: 0.09528974863449463
Validation loss: 2.3475456130505776

Epoch: 6| Step: 9
Training loss: 0.053615988991321084
Validation loss: 2.338388733205114

Epoch: 6| Step: 10
Training loss: 0.05389298668039028
Validation loss: 2.3329071512334405

Epoch: 6| Step: 11
Training loss: 0.05989526816633585
Validation loss: 2.3352910858551863

Epoch: 6| Step: 12
Training loss: 0.07936238040254143
Validation loss: 2.3339265426011035

Epoch: 6| Step: 13
Training loss: 0.12748040958039056
Validation loss: 2.358524173173822

Epoch: 668| Step: 0
Training loss: 0.17141821699522397
Validation loss: 2.330566575101152

Epoch: 6| Step: 1
Training loss: 0.08234958529380959
Validation loss: 2.323955578552638

Epoch: 6| Step: 2
Training loss: 0.051254792592667985
Validation loss: 2.341268313635822

Epoch: 6| Step: 3
Training loss: 0.08098169855188031
Validation loss: 2.3478986347344373

Epoch: 6| Step: 4
Training loss: 0.07688054520293475
Validation loss: 2.3513471980220806

Epoch: 6| Step: 5
Training loss: 0.08850039251726735
Validation loss: 2.34838857676417

Epoch: 6| Step: 6
Training loss: 0.07988284304555295
Validation loss: 2.336007508186951

Epoch: 6| Step: 7
Training loss: 0.09543145312012145
Validation loss: 2.3426617650717616

Epoch: 6| Step: 8
Training loss: 0.05945715553466687
Validation loss: 2.3471921991386555

Epoch: 6| Step: 9
Training loss: 0.0726194002420734
Validation loss: 2.337703369771352

Epoch: 6| Step: 10
Training loss: 0.06445872759310596
Validation loss: 2.3466845314379716

Epoch: 6| Step: 11
Training loss: 0.048751551667608334
Validation loss: 2.369647350512375

Epoch: 6| Step: 12
Training loss: 0.1208646630053181
Validation loss: 2.3400716508164723

Epoch: 6| Step: 13
Training loss: 0.052782495936791664
Validation loss: 2.3524587728345367

Epoch: 669| Step: 0
Training loss: 0.07210048609901552
Validation loss: 2.319476732869262

Epoch: 6| Step: 1
Training loss: 0.11614791780220697
Validation loss: 2.3924806896374275

Epoch: 6| Step: 2
Training loss: 0.06386548982049603
Validation loss: 2.3476958210166665

Epoch: 6| Step: 3
Training loss: 0.050926847989642685
Validation loss: 2.331429046869718

Epoch: 6| Step: 4
Training loss: 0.19539774941592483
Validation loss: 2.374003018658865

Epoch: 6| Step: 5
Training loss: 0.07732244075206172
Validation loss: 2.364963120626919

Epoch: 6| Step: 6
Training loss: 0.057912713182555316
Validation loss: 2.382273762152915

Epoch: 6| Step: 7
Training loss: 0.08195577566716788
Validation loss: 2.3749544196512593

Epoch: 6| Step: 8
Training loss: 0.07447718811352622
Validation loss: 2.3775454671637797

Epoch: 6| Step: 9
Training loss: 0.049092661002183784
Validation loss: 2.361534056542355

Epoch: 6| Step: 10
Training loss: 0.052401136586307066
Validation loss: 2.3509486865704585

Epoch: 6| Step: 11
Training loss: 0.07820019381609938
Validation loss: 2.3729554050374846

Epoch: 6| Step: 12
Training loss: 0.05496287411610583
Validation loss: 2.3434473981314974

Epoch: 6| Step: 13
Training loss: 0.056024621749104914
Validation loss: 2.3427879344229696

Epoch: 670| Step: 0
Training loss: 0.09941945951310177
Validation loss: 2.339960448736551

Epoch: 6| Step: 1
Training loss: 0.1877490614703781
Validation loss: 2.355427986077579

Epoch: 6| Step: 2
Training loss: 0.045502481639501116
Validation loss: 2.3617130194761953

Epoch: 6| Step: 3
Training loss: 0.08233122529954191
Validation loss: 2.3418300265430227

Epoch: 6| Step: 4
Training loss: 0.07484724562252454
Validation loss: 2.380031370613026

Epoch: 6| Step: 5
Training loss: 0.049608019937947063
Validation loss: 2.3288563577996846

Epoch: 6| Step: 6
Training loss: 0.05719009203977502
Validation loss: 2.3574232343450983

Epoch: 6| Step: 7
Training loss: 0.06573205798440425
Validation loss: 2.348233437549586

Epoch: 6| Step: 8
Training loss: 0.06624268977301766
Validation loss: 2.341502127152478

Epoch: 6| Step: 9
Training loss: 0.043530031835770235
Validation loss: 2.358034799237978

Epoch: 6| Step: 10
Training loss: 0.07166786343188424
Validation loss: 2.35344895023449

Epoch: 6| Step: 11
Training loss: 0.10192159296640325
Validation loss: 2.3486157886876597

Epoch: 6| Step: 12
Training loss: 0.06381847291103032
Validation loss: 2.379711139494666

Epoch: 6| Step: 13
Training loss: 0.05491022964277788
Validation loss: 2.3976190711226386

Epoch: 671| Step: 0
Training loss: 0.06972498277536257
Validation loss: 2.3468094161558737

Epoch: 6| Step: 1
Training loss: 0.07309559775569764
Validation loss: 2.3522406276789125

Epoch: 6| Step: 2
Training loss: 0.04530561884064042
Validation loss: 2.3417412575607224

Epoch: 6| Step: 3
Training loss: 0.07861370477503071
Validation loss: 2.3783350877714913

Epoch: 6| Step: 4
Training loss: 0.06756453267153083
Validation loss: 2.371523881741465

Epoch: 6| Step: 5
Training loss: 0.19014495690695032
Validation loss: 2.331984856729564

Epoch: 6| Step: 6
Training loss: 0.07663391052759917
Validation loss: 2.358434304740172

Epoch: 6| Step: 7
Training loss: 0.12507437936867893
Validation loss: 2.350653632486344

Epoch: 6| Step: 8
Training loss: 0.07101577803361307
Validation loss: 2.3593661601430624

Epoch: 6| Step: 9
Training loss: 0.07212623155842347
Validation loss: 2.3443080322550665

Epoch: 6| Step: 10
Training loss: 0.11291352142138887
Validation loss: 2.337819052437894

Epoch: 6| Step: 11
Training loss: 0.060170050840034975
Validation loss: 2.3485967912074046

Epoch: 6| Step: 12
Training loss: 0.09431950127821435
Validation loss: 2.330467143305099

Epoch: 6| Step: 13
Training loss: 0.07029388764192325
Validation loss: 2.35566041538332

Epoch: 672| Step: 0
Training loss: 0.06579896640171418
Validation loss: 2.3231465881475137

Epoch: 6| Step: 1
Training loss: 0.11078257488647551
Validation loss: 2.332392777308544

Epoch: 6| Step: 2
Training loss: 0.0769040516440705
Validation loss: 2.367994531200768

Epoch: 6| Step: 3
Training loss: 0.054591464972264164
Validation loss: 2.3522629448770966

Epoch: 6| Step: 4
Training loss: 0.04125232177940986
Validation loss: 2.3631632848058364

Epoch: 6| Step: 5
Training loss: 0.06334194801521671
Validation loss: 2.3557149250000986

Epoch: 6| Step: 6
Training loss: 0.054638544803502304
Validation loss: 2.3419339336602683

Epoch: 6| Step: 7
Training loss: 0.09143338880566086
Validation loss: 2.376480238177269

Epoch: 6| Step: 8
Training loss: 0.048854963556051983
Validation loss: 2.3690382764049756

Epoch: 6| Step: 9
Training loss: 0.10512630180727645
Validation loss: 2.372457701195337

Epoch: 6| Step: 10
Training loss: 0.08060745002968109
Validation loss: 2.3293943653514377

Epoch: 6| Step: 11
Training loss: 0.07938645710071658
Validation loss: 2.3614533165734573

Epoch: 6| Step: 12
Training loss: 0.17021208130022372
Validation loss: 2.3553058680393755

Epoch: 6| Step: 13
Training loss: 0.09662762598427202
Validation loss: 2.3561800838013762

Epoch: 673| Step: 0
Training loss: 0.11131555921344276
Validation loss: 2.3321835465456853

Epoch: 6| Step: 1
Training loss: 0.07424958742874811
Validation loss: 2.3347637001102446

Epoch: 6| Step: 2
Training loss: 0.056722569383016556
Validation loss: 2.3618281133740053

Epoch: 6| Step: 3
Training loss: 0.08781418920483969
Validation loss: 2.3319470204909245

Epoch: 6| Step: 4
Training loss: 0.05848394277271761
Validation loss: 2.360127654482516

Epoch: 6| Step: 5
Training loss: 0.08018692115773979
Validation loss: 2.343736678328306

Epoch: 6| Step: 6
Training loss: 0.0749166266141469
Validation loss: 2.352892045379598

Epoch: 6| Step: 7
Training loss: 0.17014388675279932
Validation loss: 2.340847533264093

Epoch: 6| Step: 8
Training loss: 0.06163582300837997
Validation loss: 2.3190576618396705

Epoch: 6| Step: 9
Training loss: 0.09312919868054352
Validation loss: 2.336901572897965

Epoch: 6| Step: 10
Training loss: 0.15242867670178145
Validation loss: 2.314959620669318

Epoch: 6| Step: 11
Training loss: 0.05190303285984931
Validation loss: 2.3590535949570515

Epoch: 6| Step: 12
Training loss: 0.056610311009125794
Validation loss: 2.3511011152552315

Epoch: 6| Step: 13
Training loss: 0.05590595840545443
Validation loss: 2.337078438530685

Epoch: 674| Step: 0
Training loss: 0.09389108234642651
Validation loss: 2.3743173884446445

Epoch: 6| Step: 1
Training loss: 0.07463253271001943
Validation loss: 2.385568916895479

Epoch: 6| Step: 2
Training loss: 0.10885618406081218
Validation loss: 2.356083494576657

Epoch: 6| Step: 3
Training loss: 0.1640817426568413
Validation loss: 2.3552175345814854

Epoch: 6| Step: 4
Training loss: 0.13009584495200985
Validation loss: 2.3568702495036065

Epoch: 6| Step: 5
Training loss: 0.08204719411213643
Validation loss: 2.3302813864912184

Epoch: 6| Step: 6
Training loss: 0.07062307945420987
Validation loss: 2.3396203743535975

Epoch: 6| Step: 7
Training loss: 0.0682416003518047
Validation loss: 2.3457528780729113

Epoch: 6| Step: 8
Training loss: 0.06141795849983505
Validation loss: 2.3421638858905123

Epoch: 6| Step: 9
Training loss: 0.058923961082140826
Validation loss: 2.352020818611144

Epoch: 6| Step: 10
Training loss: 0.12258485687447637
Validation loss: 2.336685371531492

Epoch: 6| Step: 11
Training loss: 0.13255623328177207
Validation loss: 2.327466523772222

Epoch: 6| Step: 12
Training loss: 0.056812666359795296
Validation loss: 2.3240172011567144

Epoch: 6| Step: 13
Training loss: 0.05225477636687491
Validation loss: 2.328132032004026

Epoch: 675| Step: 0
Training loss: 0.04317057283205222
Validation loss: 2.320856957398126

Epoch: 6| Step: 1
Training loss: 0.07705363956076469
Validation loss: 2.33374160463046

Epoch: 6| Step: 2
Training loss: 0.08440939513475951
Validation loss: 2.307669293108357

Epoch: 6| Step: 3
Training loss: 0.05341151397244329
Validation loss: 2.3322608573495294

Epoch: 6| Step: 4
Training loss: 0.09642042210432719
Validation loss: 2.3268311434394797

Epoch: 6| Step: 5
Training loss: 0.09300793575261075
Validation loss: 2.3311751011875206

Epoch: 6| Step: 6
Training loss: 0.051434134599205095
Validation loss: 2.319652965387205

Epoch: 6| Step: 7
Training loss: 0.04705953039245869
Validation loss: 2.326580050610018

Epoch: 6| Step: 8
Training loss: 0.07646024965440884
Validation loss: 2.338688784362062

Epoch: 6| Step: 9
Training loss: 0.19003932752914218
Validation loss: 2.335062094308077

Epoch: 6| Step: 10
Training loss: 0.0923248891723385
Validation loss: 2.330449699677192

Epoch: 6| Step: 11
Training loss: 0.11978698717873537
Validation loss: 2.355386820912626

Epoch: 6| Step: 12
Training loss: 0.09230608425302429
Validation loss: 2.330640928369831

Epoch: 6| Step: 13
Training loss: 0.0432999106488699
Validation loss: 2.352775518428195

Epoch: 676| Step: 0
Training loss: 0.04647210444051991
Validation loss: 2.347670336757795

Epoch: 6| Step: 1
Training loss: 0.11138615434327358
Validation loss: 2.3357748359852226

Epoch: 6| Step: 2
Training loss: 0.11030551489795218
Validation loss: 2.3516759692775153

Epoch: 6| Step: 3
Training loss: 0.09492581343623782
Validation loss: 2.356969242359201

Epoch: 6| Step: 4
Training loss: 0.06756260974920994
Validation loss: 2.3391272997833514

Epoch: 6| Step: 5
Training loss: 0.07080116600721323
Validation loss: 2.359666076885622

Epoch: 6| Step: 6
Training loss: 0.10049920833629317
Validation loss: 2.3456196012025208

Epoch: 6| Step: 7
Training loss: 0.08476683213653305
Validation loss: 2.3185027131463505

Epoch: 6| Step: 8
Training loss: 0.075220521813101
Validation loss: 2.3379804727738924

Epoch: 6| Step: 9
Training loss: 0.0632073120573966
Validation loss: 2.321641817635332

Epoch: 6| Step: 10
Training loss: 0.06272399148364988
Validation loss: 2.312593504753856

Epoch: 6| Step: 11
Training loss: 0.1310642261700704
Validation loss: 2.318599853461595

Epoch: 6| Step: 12
Training loss: 0.19166615415241992
Validation loss: 2.3320484663335255

Epoch: 6| Step: 13
Training loss: 0.08761271939426382
Validation loss: 2.3107231461999502

Epoch: 677| Step: 0
Training loss: 0.16223053253812597
Validation loss: 2.3313655902582617

Epoch: 6| Step: 1
Training loss: 0.046213846824494316
Validation loss: 2.350682716628975

Epoch: 6| Step: 2
Training loss: 0.05677402342282299
Validation loss: 2.3537724820395503

Epoch: 6| Step: 3
Training loss: 0.05013265335428695
Validation loss: 2.3444636575757247

Epoch: 6| Step: 4
Training loss: 0.09708161086831534
Validation loss: 2.3421830614216153

Epoch: 6| Step: 5
Training loss: 0.06539681662251894
Validation loss: 2.3774088359356345

Epoch: 6| Step: 6
Training loss: 0.20369188360417453
Validation loss: 2.3737054166719833

Epoch: 6| Step: 7
Training loss: 0.10192127771742038
Validation loss: 2.3375915450632037

Epoch: 6| Step: 8
Training loss: 0.12073889004966278
Validation loss: 2.329567252669383

Epoch: 6| Step: 9
Training loss: 0.08416632692294826
Validation loss: 2.287220959852961

Epoch: 6| Step: 10
Training loss: 0.13366962587035094
Validation loss: 2.314552924647018

Epoch: 6| Step: 11
Training loss: 0.10624434371926868
Validation loss: 2.3091787008025375

Epoch: 6| Step: 12
Training loss: 0.14407480179069582
Validation loss: 2.324832972493221

Epoch: 6| Step: 13
Training loss: 0.07418613595640511
Validation loss: 2.3087101467265763

Epoch: 678| Step: 0
Training loss: 0.08920154968583967
Validation loss: 2.3213081122842723

Epoch: 6| Step: 1
Training loss: 0.06526088647008599
Validation loss: 2.335555173132998

Epoch: 6| Step: 2
Training loss: 0.11378556658334163
Validation loss: 2.3460263514055013

Epoch: 6| Step: 3
Training loss: 0.09370464479531597
Validation loss: 2.3574063153364313

Epoch: 6| Step: 4
Training loss: 0.2196096321085453
Validation loss: 2.38334708078253

Epoch: 6| Step: 5
Training loss: 0.08797005402138841
Validation loss: 2.3599281197821083

Epoch: 6| Step: 6
Training loss: 0.11387207665260814
Validation loss: 2.3201133808596164

Epoch: 6| Step: 7
Training loss: 0.12711530743091845
Validation loss: 2.3399356915258336

Epoch: 6| Step: 8
Training loss: 0.18295160568340138
Validation loss: 2.3320607147963512

Epoch: 6| Step: 9
Training loss: 0.191792235153232
Validation loss: 2.3002791702772236

Epoch: 6| Step: 10
Training loss: 0.1463667333599423
Validation loss: 2.3185375699526145

Epoch: 6| Step: 11
Training loss: 0.10536268428729123
Validation loss: 2.3206515771039005

Epoch: 6| Step: 12
Training loss: 0.13546505088111616
Validation loss: 2.3049600541884305

Epoch: 6| Step: 13
Training loss: 0.12542641446842612
Validation loss: 2.334771665206433

Epoch: 679| Step: 0
Training loss: 0.09926769145878422
Validation loss: 2.36808529532431

Epoch: 6| Step: 1
Training loss: 0.17572844559902764
Validation loss: 2.330539018651178

Epoch: 6| Step: 2
Training loss: 0.07711799540061261
Validation loss: 2.3537317829539055

Epoch: 6| Step: 3
Training loss: 0.14849265855606192
Validation loss: 2.386950906033026

Epoch: 6| Step: 4
Training loss: 0.13033359859924118
Validation loss: 2.350784240292605

Epoch: 6| Step: 5
Training loss: 0.10914462811276747
Validation loss: 2.3188652612265073

Epoch: 6| Step: 6
Training loss: 0.14569413333791825
Validation loss: 2.328411495675424

Epoch: 6| Step: 7
Training loss: 0.14348344916670494
Validation loss: 2.3177797933975577

Epoch: 6| Step: 8
Training loss: 0.08867487692267849
Validation loss: 2.355916573935142

Epoch: 6| Step: 9
Training loss: 0.12225312467664637
Validation loss: 2.346767933217703

Epoch: 6| Step: 10
Training loss: 0.12372175831833679
Validation loss: 2.3849619444412276

Epoch: 6| Step: 11
Training loss: 0.11318331217298791
Validation loss: 2.331356959242741

Epoch: 6| Step: 12
Training loss: 0.08012523079740697
Validation loss: 2.3635481255661435

Epoch: 6| Step: 13
Training loss: 0.07539397168019771
Validation loss: 2.348874904368883

Epoch: 680| Step: 0
Training loss: 0.12277254298482333
Validation loss: 2.345817479864501

Epoch: 6| Step: 1
Training loss: 0.08537217617985066
Validation loss: 2.3835553325807757

Epoch: 6| Step: 2
Training loss: 0.09882839564712316
Validation loss: 2.3543649810087666

Epoch: 6| Step: 3
Training loss: 0.07730396805804829
Validation loss: 2.3362801438011105

Epoch: 6| Step: 4
Training loss: 0.052412267933110455
Validation loss: 2.353861793845469

Epoch: 6| Step: 5
Training loss: 0.1812990730544947
Validation loss: 2.335335912257188

Epoch: 6| Step: 6
Training loss: 0.1000609028028744
Validation loss: 2.3660502854153735

Epoch: 6| Step: 7
Training loss: 0.06021485121730346
Validation loss: 2.314474318980901

Epoch: 6| Step: 8
Training loss: 0.07961606839860541
Validation loss: 2.3251225205564587

Epoch: 6| Step: 9
Training loss: 0.1417044693166633
Validation loss: 2.3407820944729916

Epoch: 6| Step: 10
Training loss: 0.08488103792746754
Validation loss: 2.3460287937198574

Epoch: 6| Step: 11
Training loss: 0.10108194920559781
Validation loss: 2.3266890285115585

Epoch: 6| Step: 12
Training loss: 0.10898868849637128
Validation loss: 2.328281518179016

Epoch: 6| Step: 13
Training loss: 0.07459735923396744
Validation loss: 2.3150230430505663

Epoch: 681| Step: 0
Training loss: 0.15301114394004073
Validation loss: 2.2885074448604117

Epoch: 6| Step: 1
Training loss: 0.17705656064295872
Validation loss: 2.2847920776447364

Epoch: 6| Step: 2
Training loss: 0.21990341698547025
Validation loss: 2.299596050751039

Epoch: 6| Step: 3
Training loss: 0.2404353224018866
Validation loss: 2.3210339643199895

Epoch: 6| Step: 4
Training loss: 0.08394860736900668
Validation loss: 2.3479813071615774

Epoch: 6| Step: 5
Training loss: 0.10300868891465043
Validation loss: 2.3303563690444697

Epoch: 6| Step: 6
Training loss: 0.12758051562244838
Validation loss: 2.3598764266077654

Epoch: 6| Step: 7
Training loss: 0.23089630264072303
Validation loss: 2.3486588893879894

Epoch: 6| Step: 8
Training loss: 0.08267183750874879
Validation loss: 2.334215580438279

Epoch: 6| Step: 9
Training loss: 0.10298542779087161
Validation loss: 2.328074102677441

Epoch: 6| Step: 10
Training loss: 0.09061992236415052
Validation loss: 2.3154041913426

Epoch: 6| Step: 11
Training loss: 0.30405453200059274
Validation loss: 2.352411436260976

Epoch: 6| Step: 12
Training loss: 0.15110728808742768
Validation loss: 2.318259748065096

Epoch: 6| Step: 13
Training loss: 0.0981853409750745
Validation loss: 2.339700286086567

Epoch: 682| Step: 0
Training loss: 0.12349198457758298
Validation loss: 2.3956238088348556

Epoch: 6| Step: 1
Training loss: 0.16882671206446612
Validation loss: 2.3755305501259336

Epoch: 6| Step: 2
Training loss: 0.12411478388224909
Validation loss: 2.3821635088189703

Epoch: 6| Step: 3
Training loss: 0.14727284896900547
Validation loss: 2.4073737069233894

Epoch: 6| Step: 4
Training loss: 0.060038605907294915
Validation loss: 2.384946399988566

Epoch: 6| Step: 5
Training loss: 0.17501366766281334
Validation loss: 2.368163289022536

Epoch: 6| Step: 6
Training loss: 0.13638417313281562
Validation loss: 2.3349997821974733

Epoch: 6| Step: 7
Training loss: 0.14138460968463862
Validation loss: 2.3747249685816367

Epoch: 6| Step: 8
Training loss: 0.10644308577842046
Validation loss: 2.343620506729128

Epoch: 6| Step: 9
Training loss: 0.12427184241871886
Validation loss: 2.364940214327812

Epoch: 6| Step: 10
Training loss: 0.21404560259098254
Validation loss: 2.348532437247224

Epoch: 6| Step: 11
Training loss: 0.14091038224173574
Validation loss: 2.36236782037346

Epoch: 6| Step: 12
Training loss: 0.1308997362437261
Validation loss: 2.3748449788776345

Epoch: 6| Step: 13
Training loss: 0.12311103449929237
Validation loss: 2.386015504165424

Epoch: 683| Step: 0
Training loss: 0.08550564401577203
Validation loss: 2.3973047536290295

Epoch: 6| Step: 1
Training loss: 0.06560241617163168
Validation loss: 2.399502456486375

Epoch: 6| Step: 2
Training loss: 0.16208715171614743
Validation loss: 2.3988472188853978

Epoch: 6| Step: 3
Training loss: 0.20335915713860958
Validation loss: 2.3728066826578966

Epoch: 6| Step: 4
Training loss: 0.1252365109980778
Validation loss: 2.3702114039564703

Epoch: 6| Step: 5
Training loss: 0.15181320681747035
Validation loss: 2.359483491592232

Epoch: 6| Step: 6
Training loss: 0.10672687773242256
Validation loss: 2.355090249705006

Epoch: 6| Step: 7
Training loss: 0.21163366374596207
Validation loss: 2.32069740764127

Epoch: 6| Step: 8
Training loss: 0.12220309093403167
Validation loss: 2.3244706030255036

Epoch: 6| Step: 9
Training loss: 0.1527532673149174
Validation loss: 2.327154816991025

Epoch: 6| Step: 10
Training loss: 0.15981153280944915
Validation loss: 2.3328568664999763

Epoch: 6| Step: 11
Training loss: 0.1668281865267646
Validation loss: 2.3478713685130996

Epoch: 6| Step: 12
Training loss: 0.15672620685214347
Validation loss: 2.368292307415839

Epoch: 6| Step: 13
Training loss: 0.19007644168094281
Validation loss: 2.3641518725069313

Epoch: 684| Step: 0
Training loss: 0.11018279344262186
Validation loss: 2.3362877525869266

Epoch: 6| Step: 1
Training loss: 0.0963121179598485
Validation loss: 2.3404996892976615

Epoch: 6| Step: 2
Training loss: 0.11804194484895153
Validation loss: 2.3278473906513097

Epoch: 6| Step: 3
Training loss: 0.21479094463255397
Validation loss: 2.339754671182312

Epoch: 6| Step: 4
Training loss: 0.14992508731241247
Validation loss: 2.3381042604912814

Epoch: 6| Step: 5
Training loss: 0.12014047272928416
Validation loss: 2.2955137159822034

Epoch: 6| Step: 6
Training loss: 0.17224842383559114
Validation loss: 2.268085249169929

Epoch: 6| Step: 7
Training loss: 0.15338916204593625
Validation loss: 2.2704076090372896

Epoch: 6| Step: 8
Training loss: 0.16819379944559093
Validation loss: 2.2663253307151137

Epoch: 6| Step: 9
Training loss: 0.2098827482614254
Validation loss: 2.2604467613863557

Epoch: 6| Step: 10
Training loss: 0.1473330897199586
Validation loss: 2.2662170315558763

Epoch: 6| Step: 11
Training loss: 0.1479806646285281
Validation loss: 2.2611364034693913

Epoch: 6| Step: 12
Training loss: 0.16785305496592753
Validation loss: 2.2937047444199137

Epoch: 6| Step: 13
Training loss: 0.1062329474957939
Validation loss: 2.29894931892049

Epoch: 685| Step: 0
Training loss: 0.1748612807743272
Validation loss: 2.3256017237742057

Epoch: 6| Step: 1
Training loss: 0.10976743968128774
Validation loss: 2.3570095668565174

Epoch: 6| Step: 2
Training loss: 0.13136964918740202
Validation loss: 2.3390636459460556

Epoch: 6| Step: 3
Training loss: 0.09616486430083754
Validation loss: 2.329344708609561

Epoch: 6| Step: 4
Training loss: 0.11570886940254421
Validation loss: 2.323316576000651

Epoch: 6| Step: 5
Training loss: 0.13975592124819777
Validation loss: 2.310023895881956

Epoch: 6| Step: 6
Training loss: 0.1995297230099744
Validation loss: 2.320921529761794

Epoch: 6| Step: 7
Training loss: 0.11299361922728489
Validation loss: 2.294799868469907

Epoch: 6| Step: 8
Training loss: 0.09210379000387346
Validation loss: 2.301992239091939

Epoch: 6| Step: 9
Training loss: 0.12388421677527663
Validation loss: 2.293519097161887

Epoch: 6| Step: 10
Training loss: 0.09382899254581246
Validation loss: 2.330717648530237

Epoch: 6| Step: 11
Training loss: 0.12748933672725926
Validation loss: 2.3311150661321767

Epoch: 6| Step: 12
Training loss: 0.12757848623940599
Validation loss: 2.3122252766999525

Epoch: 6| Step: 13
Training loss: 0.11738737465598192
Validation loss: 2.317918541503283

Epoch: 686| Step: 0
Training loss: 0.16048786095031098
Validation loss: 2.3299406197914045

Epoch: 6| Step: 1
Training loss: 0.11587710877616886
Validation loss: 2.2872296755966297

Epoch: 6| Step: 2
Training loss: 0.16931950468519166
Validation loss: 2.2835438481812

Epoch: 6| Step: 3
Training loss: 0.12114276586146724
Validation loss: 2.3131284971045307

Epoch: 6| Step: 4
Training loss: 0.1170865657369816
Validation loss: 2.284593056257118

Epoch: 6| Step: 5
Training loss: 0.1589663193031124
Validation loss: 2.278477485215607

Epoch: 6| Step: 6
Training loss: 0.20541585633045198
Validation loss: 2.2855613661417085

Epoch: 6| Step: 7
Training loss: 0.1305521019209388
Validation loss: 2.310095493962128

Epoch: 6| Step: 8
Training loss: 0.06695990257166617
Validation loss: 2.3260774067084675

Epoch: 6| Step: 9
Training loss: 0.09891039435877488
Validation loss: 2.321417056067176

Epoch: 6| Step: 10
Training loss: 0.11661778086421061
Validation loss: 2.3298333894963927

Epoch: 6| Step: 11
Training loss: 0.20254891573004358
Validation loss: 2.3057785530078645

Epoch: 6| Step: 12
Training loss: 0.10426392534815172
Validation loss: 2.3030612230733714

Epoch: 6| Step: 13
Training loss: 0.13904588257160777
Validation loss: 2.290639872329839

Epoch: 687| Step: 0
Training loss: 0.21126818344477655
Validation loss: 2.2941903106275756

Epoch: 6| Step: 1
Training loss: 0.07495951217818998
Validation loss: 2.3030206310554853

Epoch: 6| Step: 2
Training loss: 0.13045863095177168
Validation loss: 2.330512533307734

Epoch: 6| Step: 3
Training loss: 0.07053053679906374
Validation loss: 2.316669123747077

Epoch: 6| Step: 4
Training loss: 0.10320167346282978
Validation loss: 2.3439941213484303

Epoch: 6| Step: 5
Training loss: 0.07843212615085438
Validation loss: 2.3497999178107953

Epoch: 6| Step: 6
Training loss: 0.09811801931886849
Validation loss: 2.3353093287260376

Epoch: 6| Step: 7
Training loss: 0.14433431095347596
Validation loss: 2.3341123720463366

Epoch: 6| Step: 8
Training loss: 0.13673862585278512
Validation loss: 2.318458238002079

Epoch: 6| Step: 9
Training loss: 0.11972204980855629
Validation loss: 2.3538338991095986

Epoch: 6| Step: 10
Training loss: 0.09603135110525164
Validation loss: 2.3270016895064916

Epoch: 6| Step: 11
Training loss: 0.13107454345644717
Validation loss: 2.320272099019702

Epoch: 6| Step: 12
Training loss: 0.08461738327059368
Validation loss: 2.3300191685478144

Epoch: 6| Step: 13
Training loss: 0.27264339394851883
Validation loss: 2.338243755800868

Epoch: 688| Step: 0
Training loss: 0.11577507634505323
Validation loss: 2.311941978044741

Epoch: 6| Step: 1
Training loss: 0.1035368375816188
Validation loss: 2.3012536231113345

Epoch: 6| Step: 2
Training loss: 0.15005113008411078
Validation loss: 2.321460305048529

Epoch: 6| Step: 3
Training loss: 0.15191146456006868
Validation loss: 2.3273328375061295

Epoch: 6| Step: 4
Training loss: 0.2806305952300221
Validation loss: 2.328141642889051

Epoch: 6| Step: 5
Training loss: 0.07715517328530004
Validation loss: 2.31538393649238

Epoch: 6| Step: 6
Training loss: 0.19475226160959447
Validation loss: 2.3413545810955982

Epoch: 6| Step: 7
Training loss: 0.17014937682058692
Validation loss: 2.3447339334047594

Epoch: 6| Step: 8
Training loss: 0.1369570970584897
Validation loss: 2.3343398044726427

Epoch: 6| Step: 9
Training loss: 0.18187789391971448
Validation loss: 2.3292088176811014

Epoch: 6| Step: 10
Training loss: 0.15601369154586422
Validation loss: 2.3182070018796983

Epoch: 6| Step: 11
Training loss: 0.09206438147434459
Validation loss: 2.317071503968466

Epoch: 6| Step: 12
Training loss: 0.1330461970439131
Validation loss: 2.3551371675062347

Epoch: 6| Step: 13
Training loss: 0.17307365287794843
Validation loss: 2.3855099009393337

Epoch: 689| Step: 0
Training loss: 0.14600545157867467
Validation loss: 2.3835496256885085

Epoch: 6| Step: 1
Training loss: 0.17748047435849065
Validation loss: 2.3690533809232406

Epoch: 6| Step: 2
Training loss: 0.10560150533427522
Validation loss: 2.378281393036382

Epoch: 6| Step: 3
Training loss: 0.20935049696495012
Validation loss: 2.360474468645374

Epoch: 6| Step: 4
Training loss: 0.17437889410955312
Validation loss: 2.3967264869150537

Epoch: 6| Step: 5
Training loss: 0.12743722609172006
Validation loss: 2.36015144387818

Epoch: 6| Step: 6
Training loss: 0.1241623933574672
Validation loss: 2.368114565928395

Epoch: 6| Step: 7
Training loss: 0.191645443603424
Validation loss: 2.3749128529697985

Epoch: 6| Step: 8
Training loss: 0.18443016503930262
Validation loss: 2.346741120051786

Epoch: 6| Step: 9
Training loss: 0.0955482757992808
Validation loss: 2.3255533662279273

Epoch: 6| Step: 10
Training loss: 0.1819368223926607
Validation loss: 2.2972216187992096

Epoch: 6| Step: 11
Training loss: 0.12307101724326354
Validation loss: 2.3031370837555705

Epoch: 6| Step: 12
Training loss: 0.11664516601742368
Validation loss: 2.306739810206201

Epoch: 6| Step: 13
Training loss: 0.1481427730086314
Validation loss: 2.301645156399437

Epoch: 690| Step: 0
Training loss: 0.14095807367282684
Validation loss: 2.324127374708855

Epoch: 6| Step: 1
Training loss: 0.2870856035213836
Validation loss: 2.328794259982516

Epoch: 6| Step: 2
Training loss: 0.1650722289758822
Validation loss: 2.360193052204973

Epoch: 6| Step: 3
Training loss: 0.17428664479653574
Validation loss: 2.351532130491073

Epoch: 6| Step: 4
Training loss: 0.18814679683310045
Validation loss: 2.3273094771173897

Epoch: 6| Step: 5
Training loss: 0.18512993194957247
Validation loss: 2.3183378494070204

Epoch: 6| Step: 6
Training loss: 0.13441787994781804
Validation loss: 2.308225965092635

Epoch: 6| Step: 7
Training loss: 0.09771732327938826
Validation loss: 2.3241204408939318

Epoch: 6| Step: 8
Training loss: 0.07144629436066438
Validation loss: 2.322756732842888

Epoch: 6| Step: 9
Training loss: 0.20708365946602678
Validation loss: 2.343609192696408

Epoch: 6| Step: 10
Training loss: 0.1589859620279868
Validation loss: 2.2971599335992012

Epoch: 6| Step: 11
Training loss: 0.13549814997488688
Validation loss: 2.3153253405331196

Epoch: 6| Step: 12
Training loss: 0.21613782078855573
Validation loss: 2.3119529092488453

Epoch: 6| Step: 13
Training loss: 0.11857427375552153
Validation loss: 2.3474833434499467

Epoch: 691| Step: 0
Training loss: 0.09792561099191964
Validation loss: 2.3539105500265016

Epoch: 6| Step: 1
Training loss: 0.12567111251971588
Validation loss: 2.3476364295702505

Epoch: 6| Step: 2
Training loss: 0.10892453841221489
Validation loss: 2.330647583743179

Epoch: 6| Step: 3
Training loss: 0.14025280626782272
Validation loss: 2.342557543320978

Epoch: 6| Step: 4
Training loss: 0.18465618376344148
Validation loss: 2.357890570969256

Epoch: 6| Step: 5
Training loss: 0.14853615995590908
Validation loss: 2.3633778658692535

Epoch: 6| Step: 6
Training loss: 0.08445660212554956
Validation loss: 2.4007753393496363

Epoch: 6| Step: 7
Training loss: 0.18860412392137704
Validation loss: 2.387129653316497

Epoch: 6| Step: 8
Training loss: 0.19235141129966332
Validation loss: 2.352956678330314

Epoch: 6| Step: 9
Training loss: 0.13237138730946785
Validation loss: 2.3563609912040886

Epoch: 6| Step: 10
Training loss: 0.21962695089091427
Validation loss: 2.3476595118017474

Epoch: 6| Step: 11
Training loss: 0.16060831653102567
Validation loss: 2.354482649333947

Epoch: 6| Step: 12
Training loss: 0.22881703184152247
Validation loss: 2.341846430816577

Epoch: 6| Step: 13
Training loss: 0.14298738243551062
Validation loss: 2.3524669977282695

Epoch: 692| Step: 0
Training loss: 0.0943978840749288
Validation loss: 2.349863347915516

Epoch: 6| Step: 1
Training loss: 0.09915282300664877
Validation loss: 2.3610825026787863

Epoch: 6| Step: 2
Training loss: 0.1436726610868521
Validation loss: 2.339844429300472

Epoch: 6| Step: 3
Training loss: 0.1321641932675862
Validation loss: 2.3214181195492247

Epoch: 6| Step: 4
Training loss: 0.18331323661617183
Validation loss: 2.322211413212687

Epoch: 6| Step: 5
Training loss: 0.16663300216451538
Validation loss: 2.3125101835896325

Epoch: 6| Step: 6
Training loss: 0.18862448703375068
Validation loss: 2.361773147839312

Epoch: 6| Step: 7
Training loss: 0.1304159908637716
Validation loss: 2.3802782686917148

Epoch: 6| Step: 8
Training loss: 0.13578869002517033
Validation loss: 2.376267607075402

Epoch: 6| Step: 9
Training loss: 0.1930333674115396
Validation loss: 2.3926563901575326

Epoch: 6| Step: 10
Training loss: 0.2558914775947156
Validation loss: 2.405507450038706

Epoch: 6| Step: 11
Training loss: 0.14047342317040382
Validation loss: 2.3824478577804453

Epoch: 6| Step: 12
Training loss: 0.10039340731553931
Validation loss: 2.414697964811509

Epoch: 6| Step: 13
Training loss: 0.1338155400048013
Validation loss: 2.40217902786575

Epoch: 693| Step: 0
Training loss: 0.2143990335532992
Validation loss: 2.4045006186437714

Epoch: 6| Step: 1
Training loss: 0.22992057587350223
Validation loss: 2.3923588202000614

Epoch: 6| Step: 2
Training loss: 0.23513727998733874
Validation loss: 2.4001576711535337

Epoch: 6| Step: 3
Training loss: 0.15607135215841114
Validation loss: 2.4134409815556057

Epoch: 6| Step: 4
Training loss: 0.18596577789952154
Validation loss: 2.405907041679809

Epoch: 6| Step: 5
Training loss: 0.2636020426641372
Validation loss: 2.468452657932448

Epoch: 6| Step: 6
Training loss: 0.16817820596974933
Validation loss: 2.427122005313172

Epoch: 6| Step: 7
Training loss: 0.11138841184599885
Validation loss: 2.395422882046957

Epoch: 6| Step: 8
Training loss: 0.1497795148486737
Validation loss: 2.392993992618539

Epoch: 6| Step: 9
Training loss: 0.17850962488954875
Validation loss: 2.376133166468032

Epoch: 6| Step: 10
Training loss: 0.3541030850091049
Validation loss: 2.3770427069006637

Epoch: 6| Step: 11
Training loss: 0.3564338786760451
Validation loss: 2.3628870568258944

Epoch: 6| Step: 12
Training loss: 0.19585106030509006
Validation loss: 2.3677513018090095

Epoch: 6| Step: 13
Training loss: 0.1856416660912485
Validation loss: 2.3661766252056307

Epoch: 694| Step: 0
Training loss: 0.272063522637529
Validation loss: 2.3711645171160294

Epoch: 6| Step: 1
Training loss: 0.23336448582102579
Validation loss: 2.3519494297057904

Epoch: 6| Step: 2
Training loss: 0.1221089759632212
Validation loss: 2.329157406914034

Epoch: 6| Step: 3
Training loss: 0.12795100871618698
Validation loss: 2.2801050922465826

Epoch: 6| Step: 4
Training loss: 0.1489534946358233
Validation loss: 2.2593857491841636

Epoch: 6| Step: 5
Training loss: 0.18025021966637758
Validation loss: 2.2546856593344087

Epoch: 6| Step: 6
Training loss: 0.1310736197655602
Validation loss: 2.2228245213981097

Epoch: 6| Step: 7
Training loss: 0.26964731067265635
Validation loss: 2.2221232816075056

Epoch: 6| Step: 8
Training loss: 0.2184821089298521
Validation loss: 2.19412300451717

Epoch: 6| Step: 9
Training loss: 0.18672646462691816
Validation loss: 2.209657176680809

Epoch: 6| Step: 10
Training loss: 0.13178587068793246
Validation loss: 2.2636764248713908

Epoch: 6| Step: 11
Training loss: 0.12053920686230911
Validation loss: 2.273904896496667

Epoch: 6| Step: 12
Training loss: 0.21464370604308217
Validation loss: 2.314784137784618

Epoch: 6| Step: 13
Training loss: 0.19459748997914647
Validation loss: 2.3159013376448727

Epoch: 695| Step: 0
Training loss: 0.18681990943730892
Validation loss: 2.300681609568292

Epoch: 6| Step: 1
Training loss: 0.1508893993889232
Validation loss: 2.327424037382781

Epoch: 6| Step: 2
Training loss: 0.11785881164959296
Validation loss: 2.3913917949802306

Epoch: 6| Step: 3
Training loss: 0.16097597523364385
Validation loss: 2.387587323852395

Epoch: 6| Step: 4
Training loss: 0.15230396558224102
Validation loss: 2.3731745271131355

Epoch: 6| Step: 5
Training loss: 0.11848437032305932
Validation loss: 2.364143995010295

Epoch: 6| Step: 6
Training loss: 0.16773880144736272
Validation loss: 2.39285860186886

Epoch: 6| Step: 7
Training loss: 0.20442181882133664
Validation loss: 2.3516672928893887

Epoch: 6| Step: 8
Training loss: 0.1135658274180422
Validation loss: 2.3594658642685573

Epoch: 6| Step: 9
Training loss: 0.1221470172215166
Validation loss: 2.348253866488189

Epoch: 6| Step: 10
Training loss: 0.16247870415748375
Validation loss: 2.3591652994099075

Epoch: 6| Step: 11
Training loss: 0.17893804908905364
Validation loss: 2.3829527137369086

Epoch: 6| Step: 12
Training loss: 0.108847307334353
Validation loss: 2.330358442194608

Epoch: 6| Step: 13
Training loss: 0.17448627519123697
Validation loss: 2.350313967120637

Epoch: 696| Step: 0
Training loss: 0.12452734306888526
Validation loss: 2.35067541931639

Epoch: 6| Step: 1
Training loss: 0.1550750244464852
Validation loss: 2.3605715786878374

Epoch: 6| Step: 2
Training loss: 0.14695938025043867
Validation loss: 2.3417212589784153

Epoch: 6| Step: 3
Training loss: 0.14888580285953718
Validation loss: 2.3285304045036677

Epoch: 6| Step: 4
Training loss: 0.1259069028370194
Validation loss: 2.3355625691403588

Epoch: 6| Step: 5
Training loss: 0.10125582500173376
Validation loss: 2.346837854277794

Epoch: 6| Step: 6
Training loss: 0.09058787226615583
Validation loss: 2.3486873487771427

Epoch: 6| Step: 7
Training loss: 0.12964330546401218
Validation loss: 2.351942201860259

Epoch: 6| Step: 8
Training loss: 0.14478766403794927
Validation loss: 2.3363468498652087

Epoch: 6| Step: 9
Training loss: 0.11853595409668499
Validation loss: 2.342288399810564

Epoch: 6| Step: 10
Training loss: 0.2068244422981852
Validation loss: 2.3373144447599032

Epoch: 6| Step: 11
Training loss: 0.10448661236729953
Validation loss: 2.321117248448239

Epoch: 6| Step: 12
Training loss: 0.15470337136082074
Validation loss: 2.3338628287530305

Epoch: 6| Step: 13
Training loss: 0.25964003947487485
Validation loss: 2.316806619925387

Epoch: 697| Step: 0
Training loss: 0.13419739163581357
Validation loss: 2.34520283533829

Epoch: 6| Step: 1
Training loss: 0.0886116125543717
Validation loss: 2.3316623627323443

Epoch: 6| Step: 2
Training loss: 0.15848680658213582
Validation loss: 2.330979879459209

Epoch: 6| Step: 3
Training loss: 0.16429161921360272
Validation loss: 2.35267532972812

Epoch: 6| Step: 4
Training loss: 0.11942577242876959
Validation loss: 2.371435526999894

Epoch: 6| Step: 5
Training loss: 0.10653308434444361
Validation loss: 2.3276713104645563

Epoch: 6| Step: 6
Training loss: 0.21284824789500892
Validation loss: 2.327822987535794

Epoch: 6| Step: 7
Training loss: 0.17467667778148985
Validation loss: 2.3641784998669793

Epoch: 6| Step: 8
Training loss: 0.14823917893484195
Validation loss: 2.352633335635984

Epoch: 6| Step: 9
Training loss: 0.19752525957254885
Validation loss: 2.3382177875221215

Epoch: 6| Step: 10
Training loss: 0.09812179700671632
Validation loss: 2.3603040906869777

Epoch: 6| Step: 11
Training loss: 0.1128994492774604
Validation loss: 2.348813044926516

Epoch: 6| Step: 12
Training loss: 0.10830329465572397
Validation loss: 2.366731290860746

Epoch: 6| Step: 13
Training loss: 0.14669289053303974
Validation loss: 2.355996905718437

Epoch: 698| Step: 0
Training loss: 0.14659605219685456
Validation loss: 2.3544513516829664

Epoch: 6| Step: 1
Training loss: 0.18367169125838603
Validation loss: 2.3550260301874895

Epoch: 6| Step: 2
Training loss: 0.11625063242278812
Validation loss: 2.3430262508467177

Epoch: 6| Step: 3
Training loss: 0.15610491453993117
Validation loss: 2.3106576175994764

Epoch: 6| Step: 4
Training loss: 0.12092154317510366
Validation loss: 2.3122658182780644

Epoch: 6| Step: 5
Training loss: 0.07809940753416235
Validation loss: 2.3362805909578706

Epoch: 6| Step: 6
Training loss: 0.13179327663083898
Validation loss: 2.3328323745735355

Epoch: 6| Step: 7
Training loss: 0.08449191221262
Validation loss: 2.3208888848114086

Epoch: 6| Step: 8
Training loss: 0.15019463488124585
Validation loss: 2.3048334118966554

Epoch: 6| Step: 9
Training loss: 0.09279211257896089
Validation loss: 2.3120331918038683

Epoch: 6| Step: 10
Training loss: 0.11983166852579619
Validation loss: 2.3104897585824262

Epoch: 6| Step: 11
Training loss: 0.15264867563696205
Validation loss: 2.3369429896319867

Epoch: 6| Step: 12
Training loss: 0.10954173186208227
Validation loss: 2.307057446681098

Epoch: 6| Step: 13
Training loss: 0.16047453654441166
Validation loss: 2.3051291410902004

Epoch: 699| Step: 0
Training loss: 0.1740715379953893
Validation loss: 2.325065893407605

Epoch: 6| Step: 1
Training loss: 0.13374918322447474
Validation loss: 2.3091594443750414

Epoch: 6| Step: 2
Training loss: 0.15312207520864077
Validation loss: 2.3233355837817666

Epoch: 6| Step: 3
Training loss: 0.1963412466950601
Validation loss: 2.3588080259749398

Epoch: 6| Step: 4
Training loss: 0.16554007579708116
Validation loss: 2.3450645572210593

Epoch: 6| Step: 5
Training loss: 0.2021267275739362
Validation loss: 2.3980941470578006

Epoch: 6| Step: 6
Training loss: 0.14170291167586077
Validation loss: 2.3782161811860805

Epoch: 6| Step: 7
Training loss: 0.19426160377961887
Validation loss: 2.386869336873821

Epoch: 6| Step: 8
Training loss: 0.1212825687408504
Validation loss: 2.384603398719226

Epoch: 6| Step: 9
Training loss: 0.15362491236242676
Validation loss: 2.391453639516203

Epoch: 6| Step: 10
Training loss: 0.11802786078774595
Validation loss: 2.3649444690994055

Epoch: 6| Step: 11
Training loss: 0.15410582871327466
Validation loss: 2.3666865694901

Epoch: 6| Step: 12
Training loss: 0.10536822190494344
Validation loss: 2.360758844389634

Epoch: 6| Step: 13
Training loss: 0.09597029664356276
Validation loss: 2.333385527007982

Epoch: 700| Step: 0
Training loss: 0.12868538633280932
Validation loss: 2.338293954840157

Epoch: 6| Step: 1
Training loss: 0.13064385929354025
Validation loss: 2.3365024376415167

Epoch: 6| Step: 2
Training loss: 0.16666803632610516
Validation loss: 2.303413853152447

Epoch: 6| Step: 3
Training loss: 0.12930932748534124
Validation loss: 2.3185369170281036

Epoch: 6| Step: 4
Training loss: 0.16601056483915722
Validation loss: 2.3207530853288834

Epoch: 6| Step: 5
Training loss: 0.08209278432701397
Validation loss: 2.3608533561324854

Epoch: 6| Step: 6
Training loss: 0.13903197692900557
Validation loss: 2.346371407197568

Epoch: 6| Step: 7
Training loss: 0.16690360056351503
Validation loss: 2.371897885976333

Epoch: 6| Step: 8
Training loss: 0.1266286665243451
Validation loss: 2.3680219430061302

Epoch: 6| Step: 9
Training loss: 0.13733475737051382
Validation loss: 2.3712808420621894

Epoch: 6| Step: 10
Training loss: 0.09651507707680837
Validation loss: 2.3826575304322826

Epoch: 6| Step: 11
Training loss: 0.24494335195992753
Validation loss: 2.374632451276343

Epoch: 6| Step: 12
Training loss: 0.1358024751449757
Validation loss: 2.3734763703361903

Epoch: 6| Step: 13
Training loss: 0.1099909570347286
Validation loss: 2.365918685597272

Testing loss: 2.4796992416440364
