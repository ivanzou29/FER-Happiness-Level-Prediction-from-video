Epoch: 1| Step: 0
Training loss: 5.426316261291504
Validation loss: 5.117831558309575

Epoch: 5| Step: 1
Training loss: 4.482959270477295
Validation loss: 5.097496617224909

Epoch: 5| Step: 2
Training loss: 4.245736122131348
Validation loss: 5.077679613585113

Epoch: 5| Step: 3
Training loss: 4.814342975616455
Validation loss: 5.056605539014263

Epoch: 5| Step: 4
Training loss: 5.670565605163574
Validation loss: 5.03241027298794

Epoch: 5| Step: 5
Training loss: 5.865981101989746
Validation loss: 5.006672049081454

Epoch: 5| Step: 6
Training loss: 4.21126127243042
Validation loss: 4.976522696915493

Epoch: 5| Step: 7
Training loss: 5.338763236999512
Validation loss: 4.943273759657337

Epoch: 5| Step: 8
Training loss: 4.00912618637085
Validation loss: 4.905922940982285

Epoch: 5| Step: 9
Training loss: 4.617392539978027
Validation loss: 4.863205145764095

Epoch: 5| Step: 10
Training loss: 3.7506308555603027
Validation loss: 4.817905913117111

Epoch: 2| Step: 0
Training loss: 4.378042697906494
Validation loss: 4.767924980450702

Epoch: 5| Step: 1
Training loss: 5.291083812713623
Validation loss: 4.714532283044631

Epoch: 5| Step: 2
Training loss: 3.5590641498565674
Validation loss: 4.657074630901378

Epoch: 5| Step: 3
Training loss: 4.700586318969727
Validation loss: 4.598370931481802

Epoch: 5| Step: 4
Training loss: 3.910611629486084
Validation loss: 4.538106702989148

Epoch: 5| Step: 5
Training loss: 3.8632569313049316
Validation loss: 4.475223997587799

Epoch: 5| Step: 6
Training loss: 5.124452114105225
Validation loss: 4.41443665822347

Epoch: 5| Step: 7
Training loss: 5.021007537841797
Validation loss: 4.354558108955302

Epoch: 5| Step: 8
Training loss: 4.844529628753662
Validation loss: 4.2981307378379245

Epoch: 5| Step: 9
Training loss: 3.7052865028381348
Validation loss: 4.246698876862885

Epoch: 5| Step: 10
Training loss: 2.4741764068603516
Validation loss: 4.196776187548074

Epoch: 3| Step: 0
Training loss: 3.718729019165039
Validation loss: 4.154748639752788

Epoch: 5| Step: 1
Training loss: 3.9480597972869873
Validation loss: 4.11316135878204

Epoch: 5| Step: 2
Training loss: 4.577044486999512
Validation loss: 4.075344513821346

Epoch: 5| Step: 3
Training loss: 3.217967987060547
Validation loss: 4.033218345334453

Epoch: 5| Step: 4
Training loss: 4.037444114685059
Validation loss: 3.9910525352724138

Epoch: 5| Step: 5
Training loss: 3.7585227489471436
Validation loss: 3.946376203208841

Epoch: 5| Step: 6
Training loss: 3.043236494064331
Validation loss: 3.895425065871208

Epoch: 5| Step: 7
Training loss: 3.4290542602539062
Validation loss: 3.8473672995003323

Epoch: 5| Step: 8
Training loss: 3.758599042892456
Validation loss: 3.80621422490766

Epoch: 5| Step: 9
Training loss: 4.273144721984863
Validation loss: 3.775835385886572

Epoch: 5| Step: 10
Training loss: 3.9865331649780273
Validation loss: 3.7467459196685464

Epoch: 4| Step: 0
Training loss: 3.996661424636841
Validation loss: 3.727930832934636

Epoch: 5| Step: 1
Training loss: 5.148751258850098
Validation loss: 3.7119143137367825

Epoch: 5| Step: 2
Training loss: 4.391838073730469
Validation loss: 3.696153461292226

Epoch: 5| Step: 3
Training loss: 3.4735031127929688
Validation loss: 3.671363615220593

Epoch: 5| Step: 4
Training loss: 3.1461124420166016
Validation loss: 3.649307520158829

Epoch: 5| Step: 5
Training loss: 4.434886455535889
Validation loss: 3.6221029630271335

Epoch: 5| Step: 6
Training loss: 2.6105074882507324
Validation loss: 3.5953711130285777

Epoch: 5| Step: 7
Training loss: 3.0000436305999756
Validation loss: 3.5766586231929

Epoch: 5| Step: 8
Training loss: 2.7679672241210938
Validation loss: 3.5632304068534606

Epoch: 5| Step: 9
Training loss: 2.8287954330444336
Validation loss: 3.5511096241653606

Epoch: 5| Step: 10
Training loss: 3.2449734210968018
Validation loss: 3.5398606536208943

Epoch: 5| Step: 0
Training loss: 2.8752732276916504
Validation loss: 3.525169554577079

Epoch: 5| Step: 1
Training loss: 3.262467861175537
Validation loss: 3.507190660763812

Epoch: 5| Step: 2
Training loss: 3.925677537918091
Validation loss: 3.4898527360731557

Epoch: 5| Step: 3
Training loss: 2.71267032623291
Validation loss: 3.472509648210259

Epoch: 5| Step: 4
Training loss: 3.6558680534362793
Validation loss: 3.456395682468209

Epoch: 5| Step: 5
Training loss: 4.378570556640625
Validation loss: 3.4429572987300094

Epoch: 5| Step: 6
Training loss: 3.3733768463134766
Validation loss: 3.423123085370628

Epoch: 5| Step: 7
Training loss: 3.2666382789611816
Validation loss: 3.4074320946970293

Epoch: 5| Step: 8
Training loss: 3.8533082008361816
Validation loss: 3.393093970514113

Epoch: 5| Step: 9
Training loss: 3.057150363922119
Validation loss: 3.380469763150779

Epoch: 5| Step: 10
Training loss: 2.8983609676361084
Validation loss: 3.37188813506916

Epoch: 6| Step: 0
Training loss: 2.9930644035339355
Validation loss: 3.362732859068019

Epoch: 5| Step: 1
Training loss: 4.045505523681641
Validation loss: 3.339008387698922

Epoch: 5| Step: 2
Training loss: 3.776850461959839
Validation loss: 3.3342044712394796

Epoch: 5| Step: 3
Training loss: 2.7384159564971924
Validation loss: 3.322254406508579

Epoch: 5| Step: 4
Training loss: 2.9344048500061035
Validation loss: 3.3115738232930503

Epoch: 5| Step: 5
Training loss: 3.0401504039764404
Validation loss: 3.3032336465774046

Epoch: 5| Step: 6
Training loss: 2.720797300338745
Validation loss: 3.2865370627372497

Epoch: 5| Step: 7
Training loss: 2.85992431640625
Validation loss: 3.270549892097391

Epoch: 5| Step: 8
Training loss: 3.4607760906219482
Validation loss: 3.256276084530738

Epoch: 5| Step: 9
Training loss: 3.4205527305603027
Validation loss: 3.2472309143312517

Epoch: 5| Step: 10
Training loss: 4.102217674255371
Validation loss: 3.235828125348655

Epoch: 7| Step: 0
Training loss: 2.6788482666015625
Validation loss: 3.247437395075316

Epoch: 5| Step: 1
Training loss: 4.347156047821045
Validation loss: 3.2418446643378145

Epoch: 5| Step: 2
Training loss: 2.518897294998169
Validation loss: 3.207921810047601

Epoch: 5| Step: 3
Training loss: 2.985111713409424
Validation loss: 3.2056226191982145

Epoch: 5| Step: 4
Training loss: 2.9183826446533203
Validation loss: 3.2060466966321393

Epoch: 5| Step: 5
Training loss: 2.931682586669922
Validation loss: 3.197357393080188

Epoch: 5| Step: 6
Training loss: 3.3658878803253174
Validation loss: 3.187971450949228

Epoch: 5| Step: 7
Training loss: 3.0736007690429688
Validation loss: 3.174872044594057

Epoch: 5| Step: 8
Training loss: 3.804426908493042
Validation loss: 3.168413016103929

Epoch: 5| Step: 9
Training loss: 3.021998167037964
Validation loss: 3.158153731335876

Epoch: 5| Step: 10
Training loss: 3.491398334503174
Validation loss: 3.146405996814851

Epoch: 8| Step: 0
Training loss: 2.6953935623168945
Validation loss: 3.1397630912001415

Epoch: 5| Step: 1
Training loss: 3.0288071632385254
Validation loss: 3.134156068166097

Epoch: 5| Step: 2
Training loss: 2.885512113571167
Validation loss: 3.1299930285382014

Epoch: 5| Step: 3
Training loss: 3.331411838531494
Validation loss: 3.124555787732524

Epoch: 5| Step: 4
Training loss: 3.6511642932891846
Validation loss: 3.1133332124320408

Epoch: 5| Step: 5
Training loss: 3.6702167987823486
Validation loss: 3.10267614036478

Epoch: 5| Step: 6
Training loss: 3.2438385486602783
Validation loss: 3.0827378073046283

Epoch: 5| Step: 7
Training loss: 3.6015052795410156
Validation loss: 3.0772875739682104

Epoch: 5| Step: 8
Training loss: 2.1757678985595703
Validation loss: 3.064745221086728

Epoch: 5| Step: 9
Training loss: 2.406602382659912
Validation loss: 3.056736397486861

Epoch: 5| Step: 10
Training loss: 3.8520798683166504
Validation loss: 3.0505727080888647

Epoch: 9| Step: 0
Training loss: 4.0508809089660645
Validation loss: 3.043314626139979

Epoch: 5| Step: 1
Training loss: 3.3760151863098145
Validation loss: 3.0205738877737396

Epoch: 5| Step: 2
Training loss: 3.3757050037384033
Validation loss: 3.0097633228507092

Epoch: 5| Step: 3
Training loss: 3.2882399559020996
Validation loss: 3.0068578771365586

Epoch: 5| Step: 4
Training loss: 3.032520294189453
Validation loss: 3.010993362754904

Epoch: 5| Step: 5
Training loss: 2.8941049575805664
Validation loss: 3.00881169431953

Epoch: 5| Step: 6
Training loss: 2.5885119438171387
Validation loss: 3.0043218597289054

Epoch: 5| Step: 7
Training loss: 2.17417573928833
Validation loss: 2.97794585586876

Epoch: 5| Step: 8
Training loss: 3.408278703689575
Validation loss: 2.9640323115933325

Epoch: 5| Step: 9
Training loss: 2.7985517978668213
Validation loss: 2.956569089684435

Epoch: 5| Step: 10
Training loss: 2.665285587310791
Validation loss: 2.9564705741020942

Epoch: 10| Step: 0
Training loss: 2.3191990852355957
Validation loss: 2.949933603245725

Epoch: 5| Step: 1
Training loss: 2.931363105773926
Validation loss: 2.94377314659857

Epoch: 5| Step: 2
Training loss: 3.6146957874298096
Validation loss: 2.930195405919065

Epoch: 5| Step: 3
Training loss: 3.0167651176452637
Validation loss: 2.922655551664291

Epoch: 5| Step: 4
Training loss: 3.5891928672790527
Validation loss: 2.9207737394558486

Epoch: 5| Step: 5
Training loss: 2.8507678508758545
Validation loss: 2.9134643359850814

Epoch: 5| Step: 6
Training loss: 2.4779610633850098
Validation loss: 2.9063594495096514

Epoch: 5| Step: 7
Training loss: 2.9518935680389404
Validation loss: 2.8941159991807837

Epoch: 5| Step: 8
Training loss: 3.0945076942443848
Validation loss: 2.8859305381774902

Epoch: 5| Step: 9
Training loss: 2.4022395610809326
Validation loss: 2.876476880042784

Epoch: 5| Step: 10
Training loss: 3.930978298187256
Validation loss: 2.8749299177559475

Epoch: 11| Step: 0
Training loss: 2.7532739639282227
Validation loss: 2.8663570727071455

Epoch: 5| Step: 1
Training loss: 3.5045323371887207
Validation loss: 2.859920868309595

Epoch: 5| Step: 2
Training loss: 2.5704421997070312
Validation loss: 2.8544403635045534

Epoch: 5| Step: 3
Training loss: 2.9463155269622803
Validation loss: 2.847470388617567

Epoch: 5| Step: 4
Training loss: 2.6406466960906982
Validation loss: 2.8442812094124417

Epoch: 5| Step: 5
Training loss: 2.4432358741760254
Validation loss: 2.8376141466120237

Epoch: 5| Step: 6
Training loss: 2.6160264015197754
Validation loss: 2.831113802489414

Epoch: 5| Step: 7
Training loss: 3.4115614891052246
Validation loss: 2.8266516705994964

Epoch: 5| Step: 8
Training loss: 2.777935266494751
Validation loss: 2.8201030838874077

Epoch: 5| Step: 9
Training loss: 3.4522881507873535
Validation loss: 2.816790198767057

Epoch: 5| Step: 10
Training loss: 3.412964344024658
Validation loss: 2.8143849885591896

Epoch: 12| Step: 0
Training loss: 2.8650715351104736
Validation loss: 2.827160801938785

Epoch: 5| Step: 1
Training loss: 2.261343240737915
Validation loss: 2.80979734851468

Epoch: 5| Step: 2
Training loss: 3.440336227416992
Validation loss: 2.8375678293166624

Epoch: 5| Step: 3
Training loss: 3.1081347465515137
Validation loss: 2.827012969601539

Epoch: 5| Step: 4
Training loss: 2.715914249420166
Validation loss: 2.8663208817922943

Epoch: 5| Step: 5
Training loss: 2.7508838176727295
Validation loss: 2.8104603957104426

Epoch: 5| Step: 6
Training loss: 3.4970474243164062
Validation loss: 2.8038086686083066

Epoch: 5| Step: 7
Training loss: 3.1310558319091797
Validation loss: 2.8029663665320284

Epoch: 5| Step: 8
Training loss: 3.3454556465148926
Validation loss: 2.817120470026488

Epoch: 5| Step: 9
Training loss: 2.5706729888916016
Validation loss: 2.811433861332555

Epoch: 5| Step: 10
Training loss: 2.6813607215881348
Validation loss: 2.8045587821673323

Epoch: 13| Step: 0
Training loss: 3.8694090843200684
Validation loss: 2.80079250438239

Epoch: 5| Step: 1
Training loss: 2.774153232574463
Validation loss: 2.7982101619884534

Epoch: 5| Step: 2
Training loss: 3.2773022651672363
Validation loss: 2.7989036242167153

Epoch: 5| Step: 3
Training loss: 2.938518762588501
Validation loss: 2.7901715181207143

Epoch: 5| Step: 4
Training loss: 3.346029281616211
Validation loss: 2.7908083162000104

Epoch: 5| Step: 5
Training loss: 2.482880115509033
Validation loss: 2.7904304150612123

Epoch: 5| Step: 6
Training loss: 2.4178593158721924
Validation loss: 2.783579800718574

Epoch: 5| Step: 7
Training loss: 3.471827268600464
Validation loss: 2.7809793180035007

Epoch: 5| Step: 8
Training loss: 1.9284950494766235
Validation loss: 2.7747001340312343

Epoch: 5| Step: 9
Training loss: 2.606671094894409
Validation loss: 2.769540015087333

Epoch: 5| Step: 10
Training loss: 3.061495304107666
Validation loss: 2.767824621610744

Epoch: 14| Step: 0
Training loss: 3.2016563415527344
Validation loss: 2.7642907122130036

Epoch: 5| Step: 1
Training loss: 2.7832741737365723
Validation loss: 2.7561113962563137

Epoch: 5| Step: 2
Training loss: 2.83376407623291
Validation loss: 2.7513395688867055

Epoch: 5| Step: 3
Training loss: 3.127126932144165
Validation loss: 2.7494903764417096

Epoch: 5| Step: 4
Training loss: 3.448681354522705
Validation loss: 2.748216793101321

Epoch: 5| Step: 5
Training loss: 3.056511402130127
Validation loss: 2.7458893381139284

Epoch: 5| Step: 6
Training loss: 3.3743553161621094
Validation loss: 2.7463812187153804

Epoch: 5| Step: 7
Training loss: 2.522109031677246
Validation loss: 2.7433702817527195

Epoch: 5| Step: 8
Training loss: 2.9952244758605957
Validation loss: 2.7407154370379705

Epoch: 5| Step: 9
Training loss: 2.3724255561828613
Validation loss: 2.735624095445038

Epoch: 5| Step: 10
Training loss: 2.0545787811279297
Validation loss: 2.730655936784642

Epoch: 15| Step: 0
Training loss: 3.057338237762451
Validation loss: 2.7255663179582164

Epoch: 5| Step: 1
Training loss: 3.190697431564331
Validation loss: 2.724121527005267

Epoch: 5| Step: 2
Training loss: 2.090547561645508
Validation loss: 2.7211780240458827

Epoch: 5| Step: 3
Training loss: 3.1430892944335938
Validation loss: 2.7264144933351906

Epoch: 5| Step: 4
Training loss: 2.4289307594299316
Validation loss: 2.714663069735291

Epoch: 5| Step: 5
Training loss: 2.5579123497009277
Validation loss: 2.7145031241960424

Epoch: 5| Step: 6
Training loss: 3.210176944732666
Validation loss: 2.7136282126108804

Epoch: 5| Step: 7
Training loss: 2.8769474029541016
Validation loss: 2.7099493831716557

Epoch: 5| Step: 8
Training loss: 3.464362382888794
Validation loss: 2.708554111501222

Epoch: 5| Step: 9
Training loss: 3.182107448577881
Validation loss: 2.7072740498409478

Epoch: 5| Step: 10
Training loss: 2.3684346675872803
Validation loss: 2.7040490642670663

Epoch: 16| Step: 0
Training loss: 2.941894292831421
Validation loss: 2.7029222108984507

Epoch: 5| Step: 1
Training loss: 3.0890727043151855
Validation loss: 2.699529940082181

Epoch: 5| Step: 2
Training loss: 3.5306639671325684
Validation loss: 2.6980044713584324

Epoch: 5| Step: 3
Training loss: 2.7897982597351074
Validation loss: 2.696614642297068

Epoch: 5| Step: 4
Training loss: 2.1620068550109863
Validation loss: 2.6933489256007697

Epoch: 5| Step: 5
Training loss: 3.266737461090088
Validation loss: 2.694476189151887

Epoch: 5| Step: 6
Training loss: 4.035483360290527
Validation loss: 2.6917197063405025

Epoch: 5| Step: 7
Training loss: 1.7508227825164795
Validation loss: 2.694033912433091

Epoch: 5| Step: 8
Training loss: 2.547999620437622
Validation loss: 2.690287841263638

Epoch: 5| Step: 9
Training loss: 3.1487479209899902
Validation loss: 2.684365813450147

Epoch: 5| Step: 10
Training loss: 2.1256513595581055
Validation loss: 2.683795041935418

Epoch: 17| Step: 0
Training loss: 2.796875476837158
Validation loss: 2.6835273875985095

Epoch: 5| Step: 1
Training loss: 2.6284286975860596
Validation loss: 2.679742702873804

Epoch: 5| Step: 2
Training loss: 2.7991747856140137
Validation loss: 2.6844136074025142

Epoch: 5| Step: 3
Training loss: 2.7094154357910156
Validation loss: 2.680403991412091

Epoch: 5| Step: 4
Training loss: 3.6300034523010254
Validation loss: 2.6835916016691472

Epoch: 5| Step: 5
Training loss: 3.2646820545196533
Validation loss: 2.681671832197456

Epoch: 5| Step: 6
Training loss: 2.6537764072418213
Validation loss: 2.6883320244409705

Epoch: 5| Step: 7
Training loss: 2.3261821269989014
Validation loss: 2.6861741363361316

Epoch: 5| Step: 8
Training loss: 1.7925535440444946
Validation loss: 2.6785010830048592

Epoch: 5| Step: 9
Training loss: 3.1269402503967285
Validation loss: 2.6810230260254233

Epoch: 5| Step: 10
Training loss: 3.7978453636169434
Validation loss: 2.702594808352891

Epoch: 18| Step: 0
Training loss: 2.842508554458618
Validation loss: 2.6827675347687094

Epoch: 5| Step: 1
Training loss: 3.9008774757385254
Validation loss: 2.6925155834485124

Epoch: 5| Step: 2
Training loss: 2.926283359527588
Validation loss: 2.6689430026597876

Epoch: 5| Step: 3
Training loss: 2.541323184967041
Validation loss: 2.665885467683115

Epoch: 5| Step: 4
Training loss: 2.6201138496398926
Validation loss: 2.665376132534396

Epoch: 5| Step: 5
Training loss: 2.2796149253845215
Validation loss: 2.686345564421787

Epoch: 5| Step: 6
Training loss: 3.3515212535858154
Validation loss: 2.726994983611568

Epoch: 5| Step: 7
Training loss: 2.4901885986328125
Validation loss: 2.6972660351825017

Epoch: 5| Step: 8
Training loss: 3.129866123199463
Validation loss: 2.6760142182791107

Epoch: 5| Step: 9
Training loss: 2.945279121398926
Validation loss: 2.676728520342099

Epoch: 5| Step: 10
Training loss: 2.193596363067627
Validation loss: 2.6782444189953547

Epoch: 19| Step: 0
Training loss: 3.361952304840088
Validation loss: 2.6757899612508793

Epoch: 5| Step: 1
Training loss: 2.9995784759521484
Validation loss: 2.670882322454965

Epoch: 5| Step: 2
Training loss: 2.9815611839294434
Validation loss: 2.6741583936957904

Epoch: 5| Step: 3
Training loss: 3.156951904296875
Validation loss: 2.6714157289074314

Epoch: 5| Step: 4
Training loss: 2.7876932621002197
Validation loss: 2.6670915695928756

Epoch: 5| Step: 5
Training loss: 2.4217300415039062
Validation loss: 2.6578800652616765

Epoch: 5| Step: 6
Training loss: 3.128873109817505
Validation loss: 2.6599285012932232

Epoch: 5| Step: 7
Training loss: 2.227837085723877
Validation loss: 2.6535339304195937

Epoch: 5| Step: 8
Training loss: 2.460904359817505
Validation loss: 2.652978533057756

Epoch: 5| Step: 9
Training loss: 3.0611507892608643
Validation loss: 2.648546705963791

Epoch: 5| Step: 10
Training loss: 2.5399420261383057
Validation loss: 2.644509284727035

Epoch: 20| Step: 0
Training loss: 2.155177116394043
Validation loss: 2.6407078337925736

Epoch: 5| Step: 1
Training loss: 2.6020359992980957
Validation loss: 2.6432653063087055

Epoch: 5| Step: 2
Training loss: 2.9206020832061768
Validation loss: 2.6456140318224506

Epoch: 5| Step: 3
Training loss: 3.3141846656799316
Validation loss: 2.649443454639886

Epoch: 5| Step: 4
Training loss: 2.981203556060791
Validation loss: 2.640448372851136

Epoch: 5| Step: 5
Training loss: 2.9164111614227295
Validation loss: 2.6371095770148822

Epoch: 5| Step: 6
Training loss: 3.364729642868042
Validation loss: 2.628011388163413

Epoch: 5| Step: 7
Training loss: 2.283510684967041
Validation loss: 2.626710776359804

Epoch: 5| Step: 8
Training loss: 2.6394193172454834
Validation loss: 2.62337988679127

Epoch: 5| Step: 9
Training loss: 3.1441283226013184
Validation loss: 2.623760382334391

Epoch: 5| Step: 10
Training loss: 2.6162612438201904
Validation loss: 2.673688098948489

Epoch: 21| Step: 0
Training loss: 2.9272007942199707
Validation loss: 2.71335970458164

Epoch: 5| Step: 1
Training loss: 2.7397091388702393
Validation loss: 2.7010211970216487

Epoch: 5| Step: 2
Training loss: 2.493516445159912
Validation loss: 2.7070320626740814

Epoch: 5| Step: 3
Training loss: 2.501439094543457
Validation loss: 2.7129979236151582

Epoch: 5| Step: 4
Training loss: 2.8780410289764404
Validation loss: 2.7217923287422425

Epoch: 5| Step: 5
Training loss: 2.759460926055908
Validation loss: 2.7269228427640853

Epoch: 5| Step: 6
Training loss: 3.0822861194610596
Validation loss: 2.7142561135753507

Epoch: 5| Step: 7
Training loss: 3.1480350494384766
Validation loss: 2.7004566756627892

Epoch: 5| Step: 8
Training loss: 2.636709213256836
Validation loss: 2.7044119168353338

Epoch: 5| Step: 9
Training loss: 2.8472113609313965
Validation loss: 2.704419700048303

Epoch: 5| Step: 10
Training loss: 3.5486137866973877
Validation loss: 2.703634503067181

Epoch: 22| Step: 0
Training loss: 3.0106875896453857
Validation loss: 2.6876887993146013

Epoch: 5| Step: 1
Training loss: 2.815027952194214
Validation loss: 2.6856106763244956

Epoch: 5| Step: 2
Training loss: 2.3186607360839844
Validation loss: 2.652108477007958

Epoch: 5| Step: 3
Training loss: 2.880396842956543
Validation loss: 2.7046940301054265

Epoch: 5| Step: 4
Training loss: 3.015991687774658
Validation loss: 2.716762004360076

Epoch: 5| Step: 5
Training loss: 3.4242961406707764
Validation loss: 2.7119128114433697

Epoch: 5| Step: 6
Training loss: 2.514667510986328
Validation loss: 2.64046408027731

Epoch: 5| Step: 7
Training loss: 2.0907554626464844
Validation loss: 2.6131612562364146

Epoch: 5| Step: 8
Training loss: 2.656003713607788
Validation loss: 2.633239633293562

Epoch: 5| Step: 9
Training loss: 3.514575242996216
Validation loss: 2.6818463545973583

Epoch: 5| Step: 10
Training loss: 2.8706140518188477
Validation loss: 2.6381853165165072

Epoch: 23| Step: 0
Training loss: 2.5396132469177246
Validation loss: 2.605253663114322

Epoch: 5| Step: 1
Training loss: 2.7437093257904053
Validation loss: 2.605281355560467

Epoch: 5| Step: 2
Training loss: 2.4941937923431396
Validation loss: 2.623013663035567

Epoch: 5| Step: 3
Training loss: 3.368487596511841
Validation loss: 2.651645844982516

Epoch: 5| Step: 4
Training loss: 2.4539408683776855
Validation loss: 2.6582237930708033

Epoch: 5| Step: 5
Training loss: 2.7464334964752197
Validation loss: 2.6435621118032806

Epoch: 5| Step: 6
Training loss: 2.7691538333892822
Validation loss: 2.629640838151337

Epoch: 5| Step: 7
Training loss: 2.8727867603302
Validation loss: 2.6001913906425558

Epoch: 5| Step: 8
Training loss: 2.652635097503662
Validation loss: 2.5893037191001316

Epoch: 5| Step: 9
Training loss: 2.8495984077453613
Validation loss: 2.6017616743682535

Epoch: 5| Step: 10
Training loss: 3.402534008026123
Validation loss: 2.613780495940998

Epoch: 24| Step: 0
Training loss: 2.848268508911133
Validation loss: 2.61417099993716

Epoch: 5| Step: 1
Training loss: 2.678234100341797
Validation loss: 2.6118948433988836

Epoch: 5| Step: 2
Training loss: 2.91705322265625
Validation loss: 2.586800741892989

Epoch: 5| Step: 3
Training loss: 2.7405200004577637
Validation loss: 2.5770856206135084

Epoch: 5| Step: 4
Training loss: 2.5418012142181396
Validation loss: 2.574728229994415

Epoch: 5| Step: 5
Training loss: 2.6538851261138916
Validation loss: 2.5832867955648773

Epoch: 5| Step: 6
Training loss: 2.522545337677002
Validation loss: 2.6494566830255653

Epoch: 5| Step: 7
Training loss: 3.269213914871216
Validation loss: 2.6666091206253215

Epoch: 5| Step: 8
Training loss: 2.330202579498291
Validation loss: 2.618941953105311

Epoch: 5| Step: 9
Training loss: 2.947474479675293
Validation loss: 2.582934989724108

Epoch: 5| Step: 10
Training loss: 3.299515962600708
Validation loss: 2.5699183069249636

Epoch: 25| Step: 0
Training loss: 2.8990533351898193
Validation loss: 2.5638396086231356

Epoch: 5| Step: 1
Training loss: 2.9668471813201904
Validation loss: 2.5588735944481305

Epoch: 5| Step: 2
Training loss: 2.221220016479492
Validation loss: 2.5600135070021435

Epoch: 5| Step: 3
Training loss: 2.787534713745117
Validation loss: 2.561896675376482

Epoch: 5| Step: 4
Training loss: 2.740391731262207
Validation loss: 2.5669456117896625

Epoch: 5| Step: 5
Training loss: 2.727023124694824
Validation loss: 2.5668066188853276

Epoch: 5| Step: 6
Training loss: 3.011014223098755
Validation loss: 2.556585737453994

Epoch: 5| Step: 7
Training loss: 2.337923049926758
Validation loss: 2.552283243466449

Epoch: 5| Step: 8
Training loss: 2.244879961013794
Validation loss: 2.5523253487002466

Epoch: 5| Step: 9
Training loss: 3.3712143898010254
Validation loss: 2.5617677498889226

Epoch: 5| Step: 10
Training loss: 3.0696818828582764
Validation loss: 2.5616426185895036

Epoch: 26| Step: 0
Training loss: 2.5283782482147217
Validation loss: 2.553372570263442

Epoch: 5| Step: 1
Training loss: 2.9238169193267822
Validation loss: 2.5463764385510514

Epoch: 5| Step: 2
Training loss: 3.0930917263031006
Validation loss: 2.5559155812827488

Epoch: 5| Step: 3
Training loss: 1.7888553142547607
Validation loss: 2.5542801682667067

Epoch: 5| Step: 4
Training loss: 2.8219797611236572
Validation loss: 2.5516442252743627

Epoch: 5| Step: 5
Training loss: 2.490400791168213
Validation loss: 2.5746891114019577

Epoch: 5| Step: 6
Training loss: 3.116853713989258
Validation loss: 2.564928423973822

Epoch: 5| Step: 7
Training loss: 2.681962013244629
Validation loss: 2.5814056345211562

Epoch: 5| Step: 8
Training loss: 2.6352028846740723
Validation loss: 2.576951970336258

Epoch: 5| Step: 9
Training loss: 2.74281907081604
Validation loss: 2.586174331685548

Epoch: 5| Step: 10
Training loss: 3.511564254760742
Validation loss: 2.575875679651896

Epoch: 27| Step: 0
Training loss: 2.379286527633667
Validation loss: 2.5524328754794214

Epoch: 5| Step: 1
Training loss: 2.788416624069214
Validation loss: 2.540312023573024

Epoch: 5| Step: 2
Training loss: 2.2507052421569824
Validation loss: 2.533834462524742

Epoch: 5| Step: 3
Training loss: 2.760836362838745
Validation loss: 2.534168007553265

Epoch: 5| Step: 4
Training loss: 2.6321969032287598
Validation loss: 2.546255906422933

Epoch: 5| Step: 5
Training loss: 2.6066882610321045
Validation loss: 2.539348012657576

Epoch: 5| Step: 6
Training loss: 3.4248573780059814
Validation loss: 2.567154538246893

Epoch: 5| Step: 7
Training loss: 2.8196823596954346
Validation loss: 2.544267092981646

Epoch: 5| Step: 8
Training loss: 2.255749225616455
Validation loss: 2.5283788122156614

Epoch: 5| Step: 9
Training loss: 3.198124408721924
Validation loss: 2.5252228065203597

Epoch: 5| Step: 10
Training loss: 3.0122241973876953
Validation loss: 2.5276247070681666

Epoch: 28| Step: 0
Training loss: 3.018925189971924
Validation loss: 2.538937945519724

Epoch: 5| Step: 1
Training loss: 2.865830421447754
Validation loss: 2.552412433008994

Epoch: 5| Step: 2
Training loss: 2.508720636367798
Validation loss: 2.5696261288017355

Epoch: 5| Step: 3
Training loss: 2.3262524604797363
Validation loss: 2.586225930080619

Epoch: 5| Step: 4
Training loss: 2.8553833961486816
Validation loss: 2.564693017672467

Epoch: 5| Step: 5
Training loss: 2.610138177871704
Validation loss: 2.5337249437967935

Epoch: 5| Step: 6
Training loss: 2.4832606315612793
Validation loss: 2.524781652676162

Epoch: 5| Step: 7
Training loss: 3.4521071910858154
Validation loss: 2.5200839247754825

Epoch: 5| Step: 8
Training loss: 2.8588950634002686
Validation loss: 2.52254904213772

Epoch: 5| Step: 9
Training loss: 2.8138585090637207
Validation loss: 2.528048669138262

Epoch: 5| Step: 10
Training loss: 2.313375473022461
Validation loss: 2.5363935193707867

Epoch: 29| Step: 0
Training loss: 3.4353606700897217
Validation loss: 2.5504436159646637

Epoch: 5| Step: 1
Training loss: 2.7456371784210205
Validation loss: 2.541633739266344

Epoch: 5| Step: 2
Training loss: 2.5604472160339355
Validation loss: 2.5228581838710333

Epoch: 5| Step: 3
Training loss: 2.7519450187683105
Validation loss: 2.5176333740193355

Epoch: 5| Step: 4
Training loss: 2.9440929889678955
Validation loss: 2.509289574879472

Epoch: 5| Step: 5
Training loss: 2.971804141998291
Validation loss: 2.5103190714313137

Epoch: 5| Step: 6
Training loss: 2.6398112773895264
Validation loss: 2.516826868057251

Epoch: 5| Step: 7
Training loss: 2.416374683380127
Validation loss: 2.5387878110331874

Epoch: 5| Step: 8
Training loss: 2.127284526824951
Validation loss: 2.5652001596266225

Epoch: 5| Step: 9
Training loss: 2.414405345916748
Validation loss: 2.563716488499795

Epoch: 5| Step: 10
Training loss: 3.203798532485962
Validation loss: 2.5506756203148955

Epoch: 30| Step: 0
Training loss: 3.606584072113037
Validation loss: 2.517494160641906

Epoch: 5| Step: 1
Training loss: 2.4401841163635254
Validation loss: 2.5061200408525366

Epoch: 5| Step: 2
Training loss: 2.74869966506958
Validation loss: 2.503016448790027

Epoch: 5| Step: 3
Training loss: 2.06844162940979
Validation loss: 2.50444241621161

Epoch: 5| Step: 4
Training loss: 3.172908067703247
Validation loss: 2.5087407968377553

Epoch: 5| Step: 5
Training loss: 2.596132755279541
Validation loss: 2.510966121509511

Epoch: 5| Step: 6
Training loss: 1.810361623764038
Validation loss: 2.5170831526479414

Epoch: 5| Step: 7
Training loss: 3.773193359375
Validation loss: 2.6118850990008284

Epoch: 5| Step: 8
Training loss: 2.9510793685913086
Validation loss: 2.639901849531358

Epoch: 5| Step: 9
Training loss: 2.6280465126037598
Validation loss: 2.579879473614436

Epoch: 5| Step: 10
Training loss: 2.309016704559326
Validation loss: 2.572721186504569

Epoch: 31| Step: 0
Training loss: 2.6239218711853027
Validation loss: 2.577519311699816

Epoch: 5| Step: 1
Training loss: 2.1086232662200928
Validation loss: 2.5831365098235426

Epoch: 5| Step: 2
Training loss: 2.602072238922119
Validation loss: 2.603931301383562

Epoch: 5| Step: 3
Training loss: 2.9845986366271973
Validation loss: 2.62604425543098

Epoch: 5| Step: 4
Training loss: 2.1884970664978027
Validation loss: 2.6244627891048307

Epoch: 5| Step: 5
Training loss: 2.804468870162964
Validation loss: 2.6149917289774907

Epoch: 5| Step: 6
Training loss: 2.9572832584381104
Validation loss: 2.5993398466417865

Epoch: 5| Step: 7
Training loss: 3.304318904876709
Validation loss: 2.5940872776892876

Epoch: 5| Step: 8
Training loss: 2.693993091583252
Validation loss: 2.576924798309162

Epoch: 5| Step: 9
Training loss: 3.2590720653533936
Validation loss: 2.575686470154793

Epoch: 5| Step: 10
Training loss: 2.908533811569214
Validation loss: 2.5723822039942585

Epoch: 32| Step: 0
Training loss: 2.8884758949279785
Validation loss: 2.5711670588421565

Epoch: 5| Step: 1
Training loss: 2.733137845993042
Validation loss: 2.566945752789897

Epoch: 5| Step: 2
Training loss: 3.008327007293701
Validation loss: 2.5602244074626634

Epoch: 5| Step: 3
Training loss: 2.0311503410339355
Validation loss: 2.5599632468274844

Epoch: 5| Step: 4
Training loss: 3.0586907863616943
Validation loss: 2.5928893653295373

Epoch: 5| Step: 5
Training loss: 3.397709608078003
Validation loss: 2.592092870384134

Epoch: 5| Step: 6
Training loss: 1.9551761150360107
Validation loss: 2.554693768101354

Epoch: 5| Step: 7
Training loss: 2.2931289672851562
Validation loss: 2.5563722169527443

Epoch: 5| Step: 8
Training loss: 2.666154384613037
Validation loss: 2.5643020650391937

Epoch: 5| Step: 9
Training loss: 3.205627918243408
Validation loss: 2.580692970624534

Epoch: 5| Step: 10
Training loss: 3.112907648086548
Validation loss: 2.5738556461949504

Epoch: 33| Step: 0
Training loss: 2.7857346534729004
Validation loss: 2.588036649970598

Epoch: 5| Step: 1
Training loss: 2.377223014831543
Validation loss: 2.607964087558049

Epoch: 5| Step: 2
Training loss: 3.0584206581115723
Validation loss: 2.6012805226028606

Epoch: 5| Step: 3
Training loss: 2.8256072998046875
Validation loss: 2.580255590459352

Epoch: 5| Step: 4
Training loss: 2.8312313556671143
Validation loss: 2.5616711698552614

Epoch: 5| Step: 5
Training loss: 2.9137017726898193
Validation loss: 2.552102179937465

Epoch: 5| Step: 6
Training loss: 2.436302661895752
Validation loss: 2.550450492930669

Epoch: 5| Step: 7
Training loss: 2.361074447631836
Validation loss: 2.5530982735336467

Epoch: 5| Step: 8
Training loss: 3.1507368087768555
Validation loss: 2.5595493303832186

Epoch: 5| Step: 9
Training loss: 2.585317611694336
Validation loss: 2.5484254565290225

Epoch: 5| Step: 10
Training loss: 2.9176409244537354
Validation loss: 2.5410115001022175

Epoch: 34| Step: 0
Training loss: 2.687802791595459
Validation loss: 2.546966032315326

Epoch: 5| Step: 1
Training loss: 2.363403797149658
Validation loss: 2.5449704457354803

Epoch: 5| Step: 2
Training loss: 2.755908250808716
Validation loss: 2.541774877937891

Epoch: 5| Step: 3
Training loss: 2.40440034866333
Validation loss: 2.5467575878225346

Epoch: 5| Step: 4
Training loss: 4.010262489318848
Validation loss: 2.549669640038603

Epoch: 5| Step: 5
Training loss: 2.4032604694366455
Validation loss: 2.550281801531392

Epoch: 5| Step: 6
Training loss: 2.80183744430542
Validation loss: 2.551556871783349

Epoch: 5| Step: 7
Training loss: 2.531552791595459
Validation loss: 2.5449705892993557

Epoch: 5| Step: 8
Training loss: 2.814662218093872
Validation loss: 2.532060989769556

Epoch: 5| Step: 9
Training loss: 2.363828659057617
Validation loss: 2.520294543235533

Epoch: 5| Step: 10
Training loss: 2.884838581085205
Validation loss: 2.503683956720496

Epoch: 35| Step: 0
Training loss: 2.7976861000061035
Validation loss: 2.5071804920832315

Epoch: 5| Step: 1
Training loss: 2.5211427211761475
Validation loss: 2.5166228125172276

Epoch: 5| Step: 2
Training loss: 2.67985463142395
Validation loss: 2.5289580411808465

Epoch: 5| Step: 3
Training loss: 2.544232130050659
Validation loss: 2.525047133045812

Epoch: 5| Step: 4
Training loss: 2.6283771991729736
Validation loss: 2.5177862157103834

Epoch: 5| Step: 5
Training loss: 2.7667176723480225
Validation loss: 2.5041337167063067

Epoch: 5| Step: 6
Training loss: 2.65454363822937
Validation loss: 2.4906458547038417

Epoch: 5| Step: 7
Training loss: 2.9657039642333984
Validation loss: 2.492749665373115

Epoch: 5| Step: 8
Training loss: 2.709477424621582
Validation loss: 2.4824207303344563

Epoch: 5| Step: 9
Training loss: 2.9617972373962402
Validation loss: 2.474647432245234

Epoch: 5| Step: 10
Training loss: 2.2891557216644287
Validation loss: 2.4723454572821177

Epoch: 36| Step: 0
Training loss: 3.3341147899627686
Validation loss: 2.4751713968092397

Epoch: 5| Step: 1
Training loss: 1.8828967809677124
Validation loss: 2.4661916058550597

Epoch: 5| Step: 2
Training loss: 2.8871355056762695
Validation loss: 2.462571164613129

Epoch: 5| Step: 3
Training loss: 2.847876787185669
Validation loss: 2.464156085445035

Epoch: 5| Step: 4
Training loss: 2.0546767711639404
Validation loss: 2.4626190021473873

Epoch: 5| Step: 5
Training loss: 2.6421103477478027
Validation loss: 2.4555349644794258

Epoch: 5| Step: 6
Training loss: 2.932206630706787
Validation loss: 2.457312407032136

Epoch: 5| Step: 7
Training loss: 2.5193369388580322
Validation loss: 2.4540042620833202

Epoch: 5| Step: 8
Training loss: 2.704221725463867
Validation loss: 2.4565726505812777

Epoch: 5| Step: 9
Training loss: 2.3360602855682373
Validation loss: 2.4570290093780844

Epoch: 5| Step: 10
Training loss: 3.5077872276306152
Validation loss: 2.4622699522203013

Epoch: 37| Step: 0
Training loss: 2.3605566024780273
Validation loss: 2.466334463447653

Epoch: 5| Step: 1
Training loss: 2.2356038093566895
Validation loss: 2.4707013355788363

Epoch: 5| Step: 2
Training loss: 2.3043529987335205
Validation loss: 2.482543332602388

Epoch: 5| Step: 3
Training loss: 2.7545909881591797
Validation loss: 2.497672116884621

Epoch: 5| Step: 4
Training loss: 3.0096945762634277
Validation loss: 2.5051820252531316

Epoch: 5| Step: 5
Training loss: 2.592665910720825
Validation loss: 2.48291007677714

Epoch: 5| Step: 6
Training loss: 2.6339938640594482
Validation loss: 2.4674013788982103

Epoch: 5| Step: 7
Training loss: 2.472256898880005
Validation loss: 2.4574206259942826

Epoch: 5| Step: 8
Training loss: 3.336960554122925
Validation loss: 2.451689871408606

Epoch: 5| Step: 9
Training loss: 2.271597385406494
Validation loss: 2.4527901116237847

Epoch: 5| Step: 10
Training loss: 3.587404251098633
Validation loss: 2.4570991121312624

Epoch: 38| Step: 0
Training loss: 2.538958787918091
Validation loss: 2.456214492039014

Epoch: 5| Step: 1
Training loss: 2.945884943008423
Validation loss: 2.454921576284593

Epoch: 5| Step: 2
Training loss: 2.974853992462158
Validation loss: 2.45773805597777

Epoch: 5| Step: 3
Training loss: 1.9123058319091797
Validation loss: 2.4595064142698884

Epoch: 5| Step: 4
Training loss: 2.8976845741271973
Validation loss: 2.4671562281988

Epoch: 5| Step: 5
Training loss: 2.871908664703369
Validation loss: 2.4616758746485554

Epoch: 5| Step: 6
Training loss: 2.342618227005005
Validation loss: 2.440447186910978

Epoch: 5| Step: 7
Training loss: 2.264019727706909
Validation loss: 2.4500257481810865

Epoch: 5| Step: 8
Training loss: 2.7927658557891846
Validation loss: 2.491611050021264

Epoch: 5| Step: 9
Training loss: 3.174818992614746
Validation loss: 2.504441717619537

Epoch: 5| Step: 10
Training loss: 2.8863964080810547
Validation loss: 2.5196837071449525

Epoch: 39| Step: 0
Training loss: 2.979031562805176
Validation loss: 2.5256489681941208

Epoch: 5| Step: 1
Training loss: 2.851240634918213
Validation loss: 2.522822046792635

Epoch: 5| Step: 2
Training loss: 2.9789700508117676
Validation loss: 2.51871947832005

Epoch: 5| Step: 3
Training loss: 2.7950809001922607
Validation loss: 2.510118220442085

Epoch: 5| Step: 4
Training loss: 2.9333910942077637
Validation loss: 2.4969049704972135

Epoch: 5| Step: 5
Training loss: 3.0392818450927734
Validation loss: 2.489693308389315

Epoch: 5| Step: 6
Training loss: 2.648888111114502
Validation loss: 2.4848153386064755

Epoch: 5| Step: 7
Training loss: 2.469473361968994
Validation loss: 2.488229408059069

Epoch: 5| Step: 8
Training loss: 2.0611777305603027
Validation loss: 2.489256912662137

Epoch: 5| Step: 9
Training loss: 2.3572020530700684
Validation loss: 2.4920477380034742

Epoch: 5| Step: 10
Training loss: 2.6735503673553467
Validation loss: 2.484758835966869

Epoch: 40| Step: 0
Training loss: 2.1272964477539062
Validation loss: 2.4850741381286294

Epoch: 5| Step: 1
Training loss: 2.291968584060669
Validation loss: 2.4866441334447553

Epoch: 5| Step: 2
Training loss: 2.935089588165283
Validation loss: 2.4916545473119265

Epoch: 5| Step: 3
Training loss: 2.912900447845459
Validation loss: 2.5003427433711227

Epoch: 5| Step: 4
Training loss: 2.625990390777588
Validation loss: 2.505466748309392

Epoch: 5| Step: 5
Training loss: 2.381321430206299
Validation loss: 2.503607052628712

Epoch: 5| Step: 6
Training loss: 2.835608720779419
Validation loss: 2.4976968713985976

Epoch: 5| Step: 7
Training loss: 3.0550689697265625
Validation loss: 2.501579015485702

Epoch: 5| Step: 8
Training loss: 2.6999030113220215
Validation loss: 2.498963172717761

Epoch: 5| Step: 9
Training loss: 3.2642903327941895
Validation loss: 2.495889888014845

Epoch: 5| Step: 10
Training loss: 2.4295105934143066
Validation loss: 2.4903197493604434

Epoch: 41| Step: 0
Training loss: 2.4603285789489746
Validation loss: 2.4793567426743044

Epoch: 5| Step: 1
Training loss: 2.391268491744995
Validation loss: 2.4767363814897436

Epoch: 5| Step: 2
Training loss: 2.345661163330078
Validation loss: 2.4718214747726277

Epoch: 5| Step: 3
Training loss: 2.242663860321045
Validation loss: 2.474867182393228

Epoch: 5| Step: 4
Training loss: 2.4169230461120605
Validation loss: 2.4667794178890925

Epoch: 5| Step: 5
Training loss: 2.6882312297821045
Validation loss: 2.474603917009087

Epoch: 5| Step: 6
Training loss: 3.145319938659668
Validation loss: 2.471432428206167

Epoch: 5| Step: 7
Training loss: 3.0272011756896973
Validation loss: 2.470547579949902

Epoch: 5| Step: 8
Training loss: 2.94484281539917
Validation loss: 2.469320839451205

Epoch: 5| Step: 9
Training loss: 2.9929237365722656
Validation loss: 2.4686128529169227

Epoch: 5| Step: 10
Training loss: 2.882622003555298
Validation loss: 2.4677167246418614

Epoch: 42| Step: 0
Training loss: 2.5122413635253906
Validation loss: 2.4748318092797392

Epoch: 5| Step: 1
Training loss: 2.9679739475250244
Validation loss: 2.4865414583554832

Epoch: 5| Step: 2
Training loss: 2.033608913421631
Validation loss: 2.495156631674818

Epoch: 5| Step: 3
Training loss: 3.007037401199341
Validation loss: 2.5037448021673385

Epoch: 5| Step: 4
Training loss: 2.320502519607544
Validation loss: 2.515038426204394

Epoch: 5| Step: 5
Training loss: 3.2672927379608154
Validation loss: 2.5138484431851293

Epoch: 5| Step: 6
Training loss: 2.862828016281128
Validation loss: 2.5018419809238885

Epoch: 5| Step: 7
Training loss: 2.013148546218872
Validation loss: 2.482943634833059

Epoch: 5| Step: 8
Training loss: 2.6719627380371094
Validation loss: 2.475768332840294

Epoch: 5| Step: 9
Training loss: 2.790355682373047
Validation loss: 2.4645423120067966

Epoch: 5| Step: 10
Training loss: 3.0662331581115723
Validation loss: 2.4623050202605543

Epoch: 43| Step: 0
Training loss: 2.7998945713043213
Validation loss: 2.4614345899192234

Epoch: 5| Step: 1
Training loss: 2.387917995452881
Validation loss: 2.459122957721833

Epoch: 5| Step: 2
Training loss: 2.983179807662964
Validation loss: 2.455381408814461

Epoch: 5| Step: 3
Training loss: 2.1399378776550293
Validation loss: 2.4550670064905638

Epoch: 5| Step: 4
Training loss: 2.6486434936523438
Validation loss: 2.455197993145194

Epoch: 5| Step: 5
Training loss: 2.814239978790283
Validation loss: 2.454459938951718

Epoch: 5| Step: 6
Training loss: 2.845712661743164
Validation loss: 2.4546632971814883

Epoch: 5| Step: 7
Training loss: 2.4711849689483643
Validation loss: 2.4498757034219723

Epoch: 5| Step: 8
Training loss: 3.458291530609131
Validation loss: 2.457465000050042

Epoch: 5| Step: 9
Training loss: 2.073751926422119
Validation loss: 2.4641529975398893

Epoch: 5| Step: 10
Training loss: 2.787069320678711
Validation loss: 2.4801394683058544

Epoch: 44| Step: 0
Training loss: 2.9078238010406494
Validation loss: 2.4989159517390753

Epoch: 5| Step: 1
Training loss: 3.012488842010498
Validation loss: 2.5039320735521216

Epoch: 5| Step: 2
Training loss: 2.1484618186950684
Validation loss: 2.487586218823669

Epoch: 5| Step: 3
Training loss: 2.977088451385498
Validation loss: 2.4708700590236212

Epoch: 5| Step: 4
Training loss: 2.529675245285034
Validation loss: 2.4549564033426265

Epoch: 5| Step: 5
Training loss: 3.7021899223327637
Validation loss: 2.4539635873609975

Epoch: 5| Step: 6
Training loss: 2.2609000205993652
Validation loss: 2.4503855525806384

Epoch: 5| Step: 7
Training loss: 2.6494529247283936
Validation loss: 2.44921624788674

Epoch: 5| Step: 8
Training loss: 2.419861078262329
Validation loss: 2.448488453383087

Epoch: 5| Step: 9
Training loss: 2.795327663421631
Validation loss: 2.4464456599245787

Epoch: 5| Step: 10
Training loss: 1.9865105152130127
Validation loss: 2.449766623076572

Epoch: 45| Step: 0
Training loss: 2.7682695388793945
Validation loss: 2.4489707177685154

Epoch: 5| Step: 1
Training loss: 3.356672763824463
Validation loss: 2.4529217827704644

Epoch: 5| Step: 2
Training loss: 1.9088690280914307
Validation loss: 2.4599839795020317

Epoch: 5| Step: 3
Training loss: 2.1757686138153076
Validation loss: 2.459084395439394

Epoch: 5| Step: 4
Training loss: 3.3988709449768066
Validation loss: 2.460554702307588

Epoch: 5| Step: 5
Training loss: 2.6855673789978027
Validation loss: 2.466458520581645

Epoch: 5| Step: 6
Training loss: 2.791307210922241
Validation loss: 2.47601249653806

Epoch: 5| Step: 7
Training loss: 2.816417694091797
Validation loss: 2.4803234941215924

Epoch: 5| Step: 8
Training loss: 2.5644173622131348
Validation loss: 2.4809441207557597

Epoch: 5| Step: 9
Training loss: 2.3930227756500244
Validation loss: 2.481973273779756

Epoch: 5| Step: 10
Training loss: 2.389321804046631
Validation loss: 2.473939908448086

Epoch: 46| Step: 0
Training loss: 3.578425645828247
Validation loss: 2.45874092143069

Epoch: 5| Step: 1
Training loss: 2.198420286178589
Validation loss: 2.4503142705527683

Epoch: 5| Step: 2
Training loss: 3.0725927352905273
Validation loss: 2.4506906309435443

Epoch: 5| Step: 3
Training loss: 2.6346960067749023
Validation loss: 2.446409494646134

Epoch: 5| Step: 4
Training loss: 2.512333869934082
Validation loss: 2.4469821017275573

Epoch: 5| Step: 5
Training loss: 2.557490587234497
Validation loss: 2.4501462495455177

Epoch: 5| Step: 6
Training loss: 2.5749621391296387
Validation loss: 2.4483253071385045

Epoch: 5| Step: 7
Training loss: 2.163017511367798
Validation loss: 2.440173618255123

Epoch: 5| Step: 8
Training loss: 2.603619337081909
Validation loss: 2.443141157909106

Epoch: 5| Step: 9
Training loss: 2.158798933029175
Validation loss: 2.4423686765855357

Epoch: 5| Step: 10
Training loss: 3.2824325561523438
Validation loss: 2.4386373822407057

Epoch: 47| Step: 0
Training loss: 2.4763071537017822
Validation loss: 2.439699019155195

Epoch: 5| Step: 1
Training loss: 2.8493969440460205
Validation loss: 2.4484385674999607

Epoch: 5| Step: 2
Training loss: 2.644055128097534
Validation loss: 2.4579521097162718

Epoch: 5| Step: 3
Training loss: 2.133274555206299
Validation loss: 2.459032509916572

Epoch: 5| Step: 4
Training loss: 2.616084337234497
Validation loss: 2.467906933958812

Epoch: 5| Step: 5
Training loss: 2.931504726409912
Validation loss: 2.4833063323010682

Epoch: 5| Step: 6
Training loss: 2.938271999359131
Validation loss: 2.4981634975761495

Epoch: 5| Step: 7
Training loss: 2.273122787475586
Validation loss: 2.4861098156180432

Epoch: 5| Step: 8
Training loss: 2.9282546043395996
Validation loss: 2.4791030089060464

Epoch: 5| Step: 9
Training loss: 2.873703718185425
Validation loss: 2.462746348432315

Epoch: 5| Step: 10
Training loss: 2.637645959854126
Validation loss: 2.4516088449826805

Epoch: 48| Step: 0
Training loss: 2.88045597076416
Validation loss: 2.4456095541677167

Epoch: 5| Step: 1
Training loss: 2.8729801177978516
Validation loss: 2.4648102816715034

Epoch: 5| Step: 2
Training loss: 2.6949753761291504
Validation loss: 2.495538698729648

Epoch: 5| Step: 3
Training loss: 3.2199110984802246
Validation loss: 2.459810838904432

Epoch: 5| Step: 4
Training loss: 1.9320852756500244
Validation loss: 2.4530474652526197

Epoch: 5| Step: 5
Training loss: 2.5784871578216553
Validation loss: 2.409045696258545

Epoch: 5| Step: 6
Training loss: 2.398139476776123
Validation loss: 2.3899047656725814

Epoch: 5| Step: 7
Training loss: 2.4829487800598145
Validation loss: 2.385433787940651

Epoch: 5| Step: 8
Training loss: 3.2186484336853027
Validation loss: 2.3866587659364105

Epoch: 5| Step: 9
Training loss: 1.8050758838653564
Validation loss: 2.3976338063516924

Epoch: 5| Step: 10
Training loss: 3.157879590988159
Validation loss: 2.4268039605950795

Epoch: 49| Step: 0
Training loss: 2.3170011043548584
Validation loss: 2.4399333154001543

Epoch: 5| Step: 1
Training loss: 2.4053337574005127
Validation loss: 2.466775425018803

Epoch: 5| Step: 2
Training loss: 2.5174331665039062
Validation loss: 2.456256769036734

Epoch: 5| Step: 3
Training loss: 2.6819190979003906
Validation loss: 2.418984959202428

Epoch: 5| Step: 4
Training loss: 2.7537143230438232
Validation loss: 2.392173851689985

Epoch: 5| Step: 5
Training loss: 2.143709182739258
Validation loss: 2.380636417737571

Epoch: 5| Step: 6
Training loss: 2.3177969455718994
Validation loss: 2.382051497377375

Epoch: 5| Step: 7
Training loss: 2.7441515922546387
Validation loss: 2.3779530627753145

Epoch: 5| Step: 8
Training loss: 3.454601287841797
Validation loss: 2.378250211797735

Epoch: 5| Step: 9
Training loss: 3.169726610183716
Validation loss: 2.3750939112837597

Epoch: 5| Step: 10
Training loss: 2.375927686691284
Validation loss: 2.3704878027721117

Epoch: 50| Step: 0
Training loss: 2.5879786014556885
Validation loss: 2.3718333987779516

Epoch: 5| Step: 1
Training loss: 2.480813503265381
Validation loss: 2.3708413493248726

Epoch: 5| Step: 2
Training loss: 2.4015798568725586
Validation loss: 2.370646160135987

Epoch: 5| Step: 3
Training loss: 2.8394272327423096
Validation loss: 2.375082346700853

Epoch: 5| Step: 4
Training loss: 2.999666213989258
Validation loss: 2.38194021871013

Epoch: 5| Step: 5
Training loss: 3.077953338623047
Validation loss: 2.3837076822916665

Epoch: 5| Step: 6
Training loss: 2.4417526721954346
Validation loss: 2.3884086326886247

Epoch: 5| Step: 7
Training loss: 2.6668753623962402
Validation loss: 2.3929368142158753

Epoch: 5| Step: 8
Training loss: 2.082115411758423
Validation loss: 2.40254912325131

Epoch: 5| Step: 9
Training loss: 2.4008727073669434
Validation loss: 2.4144526630319576

Epoch: 5| Step: 10
Training loss: 2.8724353313446045
Validation loss: 2.4098957802659724

Epoch: 51| Step: 0
Training loss: 3.455397844314575
Validation loss: 2.394631649858208

Epoch: 5| Step: 1
Training loss: 3.0907223224639893
Validation loss: 2.376380382045623

Epoch: 5| Step: 2
Training loss: 2.285209894180298
Validation loss: 2.3686730656572568

Epoch: 5| Step: 3
Training loss: 2.7472901344299316
Validation loss: 2.3612523232736895

Epoch: 5| Step: 4
Training loss: 2.01416277885437
Validation loss: 2.365048295708113

Epoch: 5| Step: 5
Training loss: 2.4781763553619385
Validation loss: 2.3674102778075845

Epoch: 5| Step: 6
Training loss: 2.9019737243652344
Validation loss: 2.3671057531910558

Epoch: 5| Step: 7
Training loss: 2.6587741374969482
Validation loss: 2.371194306240287

Epoch: 5| Step: 8
Training loss: 2.750398635864258
Validation loss: 2.363206551920983

Epoch: 5| Step: 9
Training loss: 1.982064962387085
Validation loss: 2.3614299425514798

Epoch: 5| Step: 10
Training loss: 2.5680816173553467
Validation loss: 2.3570935623620146

Epoch: 52| Step: 0
Training loss: 2.138706684112549
Validation loss: 2.3547358538514827

Epoch: 5| Step: 1
Training loss: 2.5144896507263184
Validation loss: 2.366510877045252

Epoch: 5| Step: 2
Training loss: 2.977480888366699
Validation loss: 2.378516281804731

Epoch: 5| Step: 3
Training loss: 3.218787670135498
Validation loss: 2.390332519367177

Epoch: 5| Step: 4
Training loss: 2.290205478668213
Validation loss: 2.392544533616753

Epoch: 5| Step: 5
Training loss: 2.3248131275177
Validation loss: 2.4007669546270884

Epoch: 5| Step: 6
Training loss: 2.3376669883728027
Validation loss: 2.395876779351183

Epoch: 5| Step: 7
Training loss: 2.9457473754882812
Validation loss: 2.4084827002658638

Epoch: 5| Step: 8
Training loss: 2.7505006790161133
Validation loss: 2.405527071286273

Epoch: 5| Step: 9
Training loss: 2.7413220405578613
Validation loss: 2.4154230933035574

Epoch: 5| Step: 10
Training loss: 2.4441120624542236
Validation loss: 2.407073418299357

Epoch: 53| Step: 0
Training loss: 1.9936730861663818
Validation loss: 2.4219992417161182

Epoch: 5| Step: 1
Training loss: 1.854315996170044
Validation loss: 2.4245954226422053

Epoch: 5| Step: 2
Training loss: 3.9176394939422607
Validation loss: 2.4295919223498275

Epoch: 5| Step: 3
Training loss: 2.8976778984069824
Validation loss: 2.432096609505274

Epoch: 5| Step: 4
Training loss: 2.6998279094696045
Validation loss: 2.4249704037943194

Epoch: 5| Step: 5
Training loss: 2.9156970977783203
Validation loss: 2.421129142084429

Epoch: 5| Step: 6
Training loss: 2.36948823928833
Validation loss: 2.4213363688479186

Epoch: 5| Step: 7
Training loss: 2.452393054962158
Validation loss: 2.4090008761293147

Epoch: 5| Step: 8
Training loss: 3.258221387863159
Validation loss: 2.4089348239283406

Epoch: 5| Step: 9
Training loss: 2.490974187850952
Validation loss: 2.406170520731198

Epoch: 5| Step: 10
Training loss: 2.1228363513946533
Validation loss: 2.402996750288112

Epoch: 54| Step: 0
Training loss: 2.6441102027893066
Validation loss: 2.408520560110769

Epoch: 5| Step: 1
Training loss: 2.427004098892212
Validation loss: 2.407005069076374

Epoch: 5| Step: 2
Training loss: 2.335862636566162
Validation loss: 2.4039968636728104

Epoch: 5| Step: 3
Training loss: 2.565208911895752
Validation loss: 2.4050426688245548

Epoch: 5| Step: 4
Training loss: 2.725550889968872
Validation loss: 2.4096834018666256

Epoch: 5| Step: 5
Training loss: 2.50884747505188
Validation loss: 2.4335933064901702

Epoch: 5| Step: 6
Training loss: 2.5187270641326904
Validation loss: 2.4511265267607985

Epoch: 5| Step: 7
Training loss: 3.528481960296631
Validation loss: 2.475722800018967

Epoch: 5| Step: 8
Training loss: 2.5187981128692627
Validation loss: 2.4550233861451507

Epoch: 5| Step: 9
Training loss: 2.314411163330078
Validation loss: 2.429031829680166

Epoch: 5| Step: 10
Training loss: 3.2074923515319824
Validation loss: 2.417246236596056

Epoch: 55| Step: 0
Training loss: 2.1716628074645996
Validation loss: 2.406261852992478

Epoch: 5| Step: 1
Training loss: 3.0171756744384766
Validation loss: 2.402797959184134

Epoch: 5| Step: 2
Training loss: 2.974947214126587
Validation loss: 2.398051848975561

Epoch: 5| Step: 3
Training loss: 2.8094253540039062
Validation loss: 2.395010473907635

Epoch: 5| Step: 4
Training loss: 2.316558361053467
Validation loss: 2.392652380851007

Epoch: 5| Step: 5
Training loss: 2.5136802196502686
Validation loss: 2.395583785990233

Epoch: 5| Step: 6
Training loss: 2.1298880577087402
Validation loss: 2.3918159213117374

Epoch: 5| Step: 7
Training loss: 2.650475025177002
Validation loss: 2.3966311767537105

Epoch: 5| Step: 8
Training loss: 2.9020445346832275
Validation loss: 2.400397777557373

Epoch: 5| Step: 9
Training loss: 2.879960060119629
Validation loss: 2.396553803515691

Epoch: 5| Step: 10
Training loss: 2.493513584136963
Validation loss: 2.395367645448254

Epoch: 56| Step: 0
Training loss: 2.4472999572753906
Validation loss: 2.3954394812225015

Epoch: 5| Step: 1
Training loss: 2.3437623977661133
Validation loss: 2.397741010112147

Epoch: 5| Step: 2
Training loss: 2.817537784576416
Validation loss: 2.398998324589063

Epoch: 5| Step: 3
Training loss: 2.337334156036377
Validation loss: 2.4027965658454487

Epoch: 5| Step: 4
Training loss: 3.3672358989715576
Validation loss: 2.3976027965545654

Epoch: 5| Step: 5
Training loss: 3.084949016571045
Validation loss: 2.3911179598941597

Epoch: 5| Step: 6
Training loss: 2.1669280529022217
Validation loss: 2.392590597111692

Epoch: 5| Step: 7
Training loss: 2.8339595794677734
Validation loss: 2.389417597042617

Epoch: 5| Step: 8
Training loss: 2.7346980571746826
Validation loss: 2.3898296202382734

Epoch: 5| Step: 9
Training loss: 2.036121368408203
Validation loss: 2.3871152913698586

Epoch: 5| Step: 10
Training loss: 2.6120057106018066
Validation loss: 2.383589113912275

Epoch: 57| Step: 0
Training loss: 2.4118950366973877
Validation loss: 2.3786809290609052

Epoch: 5| Step: 1
Training loss: 2.3327362537384033
Validation loss: 2.365921369162939

Epoch: 5| Step: 2
Training loss: 2.5622353553771973
Validation loss: 2.379674352625365

Epoch: 5| Step: 3
Training loss: 2.130218505859375
Validation loss: 2.38577913981612

Epoch: 5| Step: 4
Training loss: 2.3839902877807617
Validation loss: 2.373099362978371

Epoch: 5| Step: 5
Training loss: 2.605290651321411
Validation loss: 2.377961786844397

Epoch: 5| Step: 6
Training loss: 2.5452208518981934
Validation loss: 2.3878912361719276

Epoch: 5| Step: 7
Training loss: 2.6838583946228027
Validation loss: 2.38129432611568

Epoch: 5| Step: 8
Training loss: 3.3242859840393066
Validation loss: 2.3679684772286365

Epoch: 5| Step: 9
Training loss: 2.9957265853881836
Validation loss: 2.3735275986374065

Epoch: 5| Step: 10
Training loss: 2.5621726512908936
Validation loss: 2.3659081766682286

Epoch: 58| Step: 0
Training loss: 2.549375057220459
Validation loss: 2.37309798758517

Epoch: 5| Step: 1
Training loss: 2.2351696491241455
Validation loss: 2.379256643274779

Epoch: 5| Step: 2
Training loss: 2.2979979515075684
Validation loss: 2.371725687416651

Epoch: 5| Step: 3
Training loss: 3.0083675384521484
Validation loss: 2.374890132616925

Epoch: 5| Step: 4
Training loss: 2.426332950592041
Validation loss: 2.3635018256402787

Epoch: 5| Step: 5
Training loss: 2.6723761558532715
Validation loss: 2.338401443214827

Epoch: 5| Step: 6
Training loss: 3.1723690032958984
Validation loss: 2.3411730643241637

Epoch: 5| Step: 7
Training loss: 3.2347278594970703
Validation loss: 2.350015191621678

Epoch: 5| Step: 8
Training loss: 2.523629665374756
Validation loss: 2.3483028770774923

Epoch: 5| Step: 9
Training loss: 2.429316520690918
Validation loss: 2.335185294510216

Epoch: 5| Step: 10
Training loss: 2.005208969116211
Validation loss: 2.3321359337017102

Epoch: 59| Step: 0
Training loss: 3.1920948028564453
Validation loss: 2.3216395583204044

Epoch: 5| Step: 1
Training loss: 2.7461531162261963
Validation loss: 2.3286836339581396

Epoch: 5| Step: 2
Training loss: 2.7842776775360107
Validation loss: 2.3244759831377255

Epoch: 5| Step: 3
Training loss: 2.438633680343628
Validation loss: 2.3270556490908385

Epoch: 5| Step: 4
Training loss: 2.3092246055603027
Validation loss: 2.332649234802492

Epoch: 5| Step: 5
Training loss: 2.60359263420105
Validation loss: 2.372714691264655

Epoch: 5| Step: 6
Training loss: 2.317253589630127
Validation loss: 2.3784324763923563

Epoch: 5| Step: 7
Training loss: 3.076176881790161
Validation loss: 2.404070254295103

Epoch: 5| Step: 8
Training loss: 2.719542980194092
Validation loss: 2.3758631342200824

Epoch: 5| Step: 9
Training loss: 2.278139591217041
Validation loss: 2.336158298677014

Epoch: 5| Step: 10
Training loss: 2.028322219848633
Validation loss: 2.321603003368583

Epoch: 60| Step: 0
Training loss: 3.229252338409424
Validation loss: 2.3374379988639586

Epoch: 5| Step: 1
Training loss: 2.632408380508423
Validation loss: 2.3514276550662134

Epoch: 5| Step: 2
Training loss: 2.20115065574646
Validation loss: 2.3521872028227775

Epoch: 5| Step: 3
Training loss: 2.7295918464660645
Validation loss: 2.354116678237915

Epoch: 5| Step: 4
Training loss: 2.46722412109375
Validation loss: 2.344015649569932

Epoch: 5| Step: 5
Training loss: 2.449526786804199
Validation loss: 2.319673599735383

Epoch: 5| Step: 6
Training loss: 2.280089855194092
Validation loss: 2.316909843875516

Epoch: 5| Step: 7
Training loss: 2.4943270683288574
Validation loss: 2.317736046288603

Epoch: 5| Step: 8
Training loss: 2.5448367595672607
Validation loss: 2.3360218373678063

Epoch: 5| Step: 9
Training loss: 3.05190110206604
Validation loss: 2.3480281893925

Epoch: 5| Step: 10
Training loss: 2.6044766902923584
Validation loss: 2.3620100252089964

Epoch: 61| Step: 0
Training loss: 3.170142412185669
Validation loss: 2.3951440242029007

Epoch: 5| Step: 1
Training loss: 2.6337268352508545
Validation loss: 2.4200437530394523

Epoch: 5| Step: 2
Training loss: 3.0602197647094727
Validation loss: 2.408993467207878

Epoch: 5| Step: 3
Training loss: 2.143350839614868
Validation loss: 2.389017951103949

Epoch: 5| Step: 4
Training loss: 2.298258066177368
Validation loss: 2.369527321989818

Epoch: 5| Step: 5
Training loss: 3.0130434036254883
Validation loss: 2.350065564596525

Epoch: 5| Step: 6
Training loss: 2.761551856994629
Validation loss: 2.3240838050842285

Epoch: 5| Step: 7
Training loss: 2.3577628135681152
Validation loss: 2.313584827607678

Epoch: 5| Step: 8
Training loss: 2.1489715576171875
Validation loss: 2.3103728320008967

Epoch: 5| Step: 9
Training loss: 2.380645275115967
Validation loss: 2.3127355306379256

Epoch: 5| Step: 10
Training loss: 2.628145217895508
Validation loss: 2.3161351834574053

Epoch: 62| Step: 0
Training loss: 2.430642604827881
Validation loss: 2.306392744023313

Epoch: 5| Step: 1
Training loss: 2.9601025581359863
Validation loss: 2.309106149981099

Epoch: 5| Step: 2
Training loss: 2.078625202178955
Validation loss: 2.3073553039181616

Epoch: 5| Step: 3
Training loss: 3.472630262374878
Validation loss: 2.301200471898561

Epoch: 5| Step: 4
Training loss: 2.6258559226989746
Validation loss: 2.306538594666348

Epoch: 5| Step: 5
Training loss: 2.478532075881958
Validation loss: 2.304710921420846

Epoch: 5| Step: 6
Training loss: 2.3139545917510986
Validation loss: 2.3127361882117485

Epoch: 5| Step: 7
Training loss: 2.7159526348114014
Validation loss: 2.321938345509191

Epoch: 5| Step: 8
Training loss: 1.4953887462615967
Validation loss: 2.347025981513403

Epoch: 5| Step: 9
Training loss: 2.979010581970215
Validation loss: 2.373683016787293

Epoch: 5| Step: 10
Training loss: 2.901045560836792
Validation loss: 2.427874765088481

Epoch: 63| Step: 0
Training loss: 2.2852847576141357
Validation loss: 2.424617382787889

Epoch: 5| Step: 1
Training loss: 3.1315503120422363
Validation loss: 2.383081505375524

Epoch: 5| Step: 2
Training loss: 3.089390277862549
Validation loss: 2.3333288187621744

Epoch: 5| Step: 3
Training loss: 1.8472926616668701
Validation loss: 2.3090595199215795

Epoch: 5| Step: 4
Training loss: 2.0766053199768066
Validation loss: 2.30329224371141

Epoch: 5| Step: 5
Training loss: 2.604236602783203
Validation loss: 2.3044189714616343

Epoch: 5| Step: 6
Training loss: 3.0493953227996826
Validation loss: 2.3072699064849527

Epoch: 5| Step: 7
Training loss: 2.654261827468872
Validation loss: 2.3130690128572526

Epoch: 5| Step: 8
Training loss: 2.4717726707458496
Validation loss: 2.317498776220506

Epoch: 5| Step: 9
Training loss: 2.68320894241333
Validation loss: 2.3106991014172955

Epoch: 5| Step: 10
Training loss: 2.444563388824463
Validation loss: 2.3089602660107356

Epoch: 64| Step: 0
Training loss: 2.1003975868225098
Validation loss: 2.3114337869869765

Epoch: 5| Step: 1
Training loss: 3.0206422805786133
Validation loss: 2.3163547259505077

Epoch: 5| Step: 2
Training loss: 2.4963736534118652
Validation loss: 2.324321867317282

Epoch: 5| Step: 3
Training loss: 2.0849952697753906
Validation loss: 2.311753280701176

Epoch: 5| Step: 4
Training loss: 2.341805934906006
Validation loss: 2.3058549178543912

Epoch: 5| Step: 5
Training loss: 3.3031444549560547
Validation loss: 2.307584693354945

Epoch: 5| Step: 6
Training loss: 2.8325304985046387
Validation loss: 2.300358041640251

Epoch: 5| Step: 7
Training loss: 2.4220874309539795
Validation loss: 2.30930208903487

Epoch: 5| Step: 8
Training loss: 2.356698513031006
Validation loss: 2.3054874738057456

Epoch: 5| Step: 9
Training loss: 2.9186787605285645
Validation loss: 2.339352853836552

Epoch: 5| Step: 10
Training loss: 2.34188175201416
Validation loss: 2.366220869043822

Epoch: 65| Step: 0
Training loss: 2.5577919483184814
Validation loss: 2.3990031596153014

Epoch: 5| Step: 1
Training loss: 2.5327699184417725
Validation loss: 2.425470695700697

Epoch: 5| Step: 2
Training loss: 2.847602605819702
Validation loss: 2.4169429271451888

Epoch: 5| Step: 3
Training loss: 2.9990954399108887
Validation loss: 2.406379630488734

Epoch: 5| Step: 4
Training loss: 2.5273563861846924
Validation loss: 2.377651919600784

Epoch: 5| Step: 5
Training loss: 2.613881826400757
Validation loss: 2.33478670607331

Epoch: 5| Step: 6
Training loss: 3.111436605453491
Validation loss: 2.307246131281699

Epoch: 5| Step: 7
Training loss: 2.247596025466919
Validation loss: 2.299236689844439

Epoch: 5| Step: 8
Training loss: 2.3678879737854004
Validation loss: 2.2944047604837725

Epoch: 5| Step: 9
Training loss: 2.506648540496826
Validation loss: 2.3093497881325344

Epoch: 5| Step: 10
Training loss: 2.024562358856201
Validation loss: 2.3135058597851823

Epoch: 66| Step: 0
Training loss: 2.40421462059021
Validation loss: 2.2989022808690227

Epoch: 5| Step: 1
Training loss: 2.8087620735168457
Validation loss: 2.2864302127592024

Epoch: 5| Step: 2
Training loss: 2.8164212703704834
Validation loss: 2.282897371117787

Epoch: 5| Step: 3
Training loss: 2.659346342086792
Validation loss: 2.2887388916425806

Epoch: 5| Step: 4
Training loss: 2.4229342937469482
Validation loss: 2.318072857395295

Epoch: 5| Step: 5
Training loss: 2.612826347351074
Validation loss: 2.3419764657174387

Epoch: 5| Step: 6
Training loss: 2.37821102142334
Validation loss: 2.392464289101221

Epoch: 5| Step: 7
Training loss: 2.792018413543701
Validation loss: 2.449955701828003

Epoch: 5| Step: 8
Training loss: 2.551330089569092
Validation loss: 2.4570967869092057

Epoch: 5| Step: 9
Training loss: 2.8363559246063232
Validation loss: 2.433490486555202

Epoch: 5| Step: 10
Training loss: 1.9823753833770752
Validation loss: 2.395730910762664

Epoch: 67| Step: 0
Training loss: 2.3363728523254395
Validation loss: 2.3815716569141676

Epoch: 5| Step: 1
Training loss: 2.378045082092285
Validation loss: 2.356451757492558

Epoch: 5| Step: 2
Training loss: 3.1564977169036865
Validation loss: 2.3531900682756977

Epoch: 5| Step: 3
Training loss: 2.495938777923584
Validation loss: 2.3694989553061863

Epoch: 5| Step: 4
Training loss: 2.995887279510498
Validation loss: 2.3890480097904

Epoch: 5| Step: 5
Training loss: 2.651421546936035
Validation loss: 2.3772493100935415

Epoch: 5| Step: 6
Training loss: 2.3372116088867188
Validation loss: 2.383305086884447

Epoch: 5| Step: 7
Training loss: 2.579270839691162
Validation loss: 2.3568904476781047

Epoch: 5| Step: 8
Training loss: 2.381420850753784
Validation loss: 2.415390024903

Epoch: 5| Step: 9
Training loss: 2.8669888973236084
Validation loss: 2.3868030873678063

Epoch: 5| Step: 10
Training loss: 2.388082504272461
Validation loss: 2.347320636113485

Epoch: 68| Step: 0
Training loss: 2.401622772216797
Validation loss: 2.3306220705791185

Epoch: 5| Step: 1
Training loss: 2.3630707263946533
Validation loss: 2.3369524043093444

Epoch: 5| Step: 2
Training loss: 2.8231935501098633
Validation loss: 2.3456555002479145

Epoch: 5| Step: 3
Training loss: 2.0637993812561035
Validation loss: 2.3453612455757717

Epoch: 5| Step: 4
Training loss: 2.4940671920776367
Validation loss: 2.3426556125763924

Epoch: 5| Step: 5
Training loss: 3.406144618988037
Validation loss: 2.352047219071337

Epoch: 5| Step: 6
Training loss: 2.7065491676330566
Validation loss: 2.346349803350305

Epoch: 5| Step: 7
Training loss: 2.3896546363830566
Validation loss: 2.328718641752838

Epoch: 5| Step: 8
Training loss: 2.3782808780670166
Validation loss: 2.323576993839715

Epoch: 5| Step: 9
Training loss: 2.6920695304870605
Validation loss: 2.3285289195276078

Epoch: 5| Step: 10
Training loss: 2.756298542022705
Validation loss: 2.319901934234045

Epoch: 69| Step: 0
Training loss: 2.2684500217437744
Validation loss: 2.326818143167803

Epoch: 5| Step: 1
Training loss: 2.0230727195739746
Validation loss: 2.3237999664839877

Epoch: 5| Step: 2
Training loss: 2.528820037841797
Validation loss: 2.342295128812072

Epoch: 5| Step: 3
Training loss: 2.379472017288208
Validation loss: 2.3300211865414857

Epoch: 5| Step: 4
Training loss: 2.150075912475586
Validation loss: 2.3227217479418685

Epoch: 5| Step: 5
Training loss: 2.7023284435272217
Validation loss: 2.324169756263815

Epoch: 5| Step: 6
Training loss: 3.5856308937072754
Validation loss: 2.326632591985887

Epoch: 5| Step: 7
Training loss: 2.6020138263702393
Validation loss: 2.3283269943729525

Epoch: 5| Step: 8
Training loss: 2.6830530166625977
Validation loss: 2.3265297643599974

Epoch: 5| Step: 9
Training loss: 2.808013439178467
Validation loss: 2.314648194979596

Epoch: 5| Step: 10
Training loss: 2.386329412460327
Validation loss: 2.3086531854444936

Epoch: 70| Step: 0
Training loss: 2.7023818492889404
Validation loss: 2.3221987703795075

Epoch: 5| Step: 1
Training loss: 2.3096394538879395
Validation loss: 2.3364473824859946

Epoch: 5| Step: 2
Training loss: 2.010012626647949
Validation loss: 2.3401345591391287

Epoch: 5| Step: 3
Training loss: 2.9388701915740967
Validation loss: 2.334361445519232

Epoch: 5| Step: 4
Training loss: 2.5914206504821777
Validation loss: 2.3214152038738294

Epoch: 5| Step: 5
Training loss: 2.3072257041931152
Validation loss: 2.298294923638785

Epoch: 5| Step: 6
Training loss: 2.817352056503296
Validation loss: 2.264108006672193

Epoch: 5| Step: 7
Training loss: 2.907181978225708
Validation loss: 2.2644303383365756

Epoch: 5| Step: 8
Training loss: 2.3791332244873047
Validation loss: 2.2626692992384716

Epoch: 5| Step: 9
Training loss: 2.9249796867370605
Validation loss: 2.260581083195184

Epoch: 5| Step: 10
Training loss: 2.094785690307617
Validation loss: 2.2691132125034126

Epoch: 71| Step: 0
Training loss: 2.5675041675567627
Validation loss: 2.274833094689154

Epoch: 5| Step: 1
Training loss: 2.382737874984741
Validation loss: 2.267643646527362

Epoch: 5| Step: 2
Training loss: 2.6946167945861816
Validation loss: 2.263179253506404

Epoch: 5| Step: 3
Training loss: 3.324596405029297
Validation loss: 2.2560748233590076

Epoch: 5| Step: 4
Training loss: 1.9123615026474
Validation loss: 2.2629598750863025

Epoch: 5| Step: 5
Training loss: 2.5922088623046875
Validation loss: 2.2690108706874232

Epoch: 5| Step: 6
Training loss: 2.780871868133545
Validation loss: 2.2925901284781833

Epoch: 5| Step: 7
Training loss: 2.2638256549835205
Validation loss: 2.3151221224056777

Epoch: 5| Step: 8
Training loss: 2.5191593170166016
Validation loss: 2.330328490144463

Epoch: 5| Step: 9
Training loss: 2.9018683433532715
Validation loss: 2.3215741675387145

Epoch: 5| Step: 10
Training loss: 2.189016819000244
Validation loss: 2.310682878699354

Epoch: 72| Step: 0
Training loss: 2.4915452003479004
Validation loss: 2.3063086848105154

Epoch: 5| Step: 1
Training loss: 2.5591847896575928
Validation loss: 2.290693803500104

Epoch: 5| Step: 2
Training loss: 2.3834242820739746
Validation loss: 2.261084402761152

Epoch: 5| Step: 3
Training loss: 2.6132044792175293
Validation loss: 2.2560511199376916

Epoch: 5| Step: 4
Training loss: 3.063368320465088
Validation loss: 2.250335693359375

Epoch: 5| Step: 5
Training loss: 2.4679036140441895
Validation loss: 2.2511268482413342

Epoch: 5| Step: 6
Training loss: 2.389206886291504
Validation loss: 2.257886696887273

Epoch: 5| Step: 7
Training loss: 2.5863468647003174
Validation loss: 2.2604726617054274

Epoch: 5| Step: 8
Training loss: 3.1771340370178223
Validation loss: 2.2579934468833347

Epoch: 5| Step: 9
Training loss: 2.256809711456299
Validation loss: 2.252480101841752

Epoch: 5| Step: 10
Training loss: 2.0896806716918945
Validation loss: 2.254973893524498

Epoch: 73| Step: 0
Training loss: 2.91679048538208
Validation loss: 2.259250674196469

Epoch: 5| Step: 1
Training loss: 2.4456422328948975
Validation loss: 2.2670824040648756

Epoch: 5| Step: 2
Training loss: 2.9045441150665283
Validation loss: 2.2855734338042555

Epoch: 5| Step: 3
Training loss: 2.9273338317871094
Validation loss: 2.323936221420124

Epoch: 5| Step: 4
Training loss: 2.2756900787353516
Validation loss: 2.3420405413514827

Epoch: 5| Step: 5
Training loss: 2.6417555809020996
Validation loss: 2.318928369911768

Epoch: 5| Step: 6
Training loss: 1.9214885234832764
Validation loss: 2.2826292924983527

Epoch: 5| Step: 7
Training loss: 2.013094902038574
Validation loss: 2.2616026555338213

Epoch: 5| Step: 8
Training loss: 2.900263547897339
Validation loss: 2.2505331347065587

Epoch: 5| Step: 9
Training loss: 2.561915159225464
Validation loss: 2.2471995610062794

Epoch: 5| Step: 10
Training loss: 2.503565788269043
Validation loss: 2.2742783510556785

Epoch: 74| Step: 0
Training loss: 2.786712646484375
Validation loss: 2.2836109604886783

Epoch: 5| Step: 1
Training loss: 2.4721217155456543
Validation loss: 2.2695364567541305

Epoch: 5| Step: 2
Training loss: 2.7546958923339844
Validation loss: 2.258161380726804

Epoch: 5| Step: 3
Training loss: 2.9334254264831543
Validation loss: 2.2494153027893393

Epoch: 5| Step: 4
Training loss: 1.966672658920288
Validation loss: 2.248276347755104

Epoch: 5| Step: 5
Training loss: 2.748687982559204
Validation loss: 2.249543930894585

Epoch: 5| Step: 6
Training loss: 2.5359420776367188
Validation loss: 2.2533757789160616

Epoch: 5| Step: 7
Training loss: 2.2786781787872314
Validation loss: 2.2655077493318947

Epoch: 5| Step: 8
Training loss: 2.0954036712646484
Validation loss: 2.288334869569348

Epoch: 5| Step: 9
Training loss: 3.112739086151123
Validation loss: 2.338667651658417

Epoch: 5| Step: 10
Training loss: 2.270907163619995
Validation loss: 2.4113975647957093

Epoch: 75| Step: 0
Training loss: 2.9029173851013184
Validation loss: 2.4336184481138825

Epoch: 5| Step: 1
Training loss: 2.3393938541412354
Validation loss: 2.3891578182097404

Epoch: 5| Step: 2
Training loss: 2.374857187271118
Validation loss: 2.3497940083985687

Epoch: 5| Step: 3
Training loss: 2.399561882019043
Validation loss: 2.309705483016147

Epoch: 5| Step: 4
Training loss: 3.1245341300964355
Validation loss: 2.2917220746317217

Epoch: 5| Step: 5
Training loss: 2.2636497020721436
Validation loss: 2.283538164631013

Epoch: 5| Step: 6
Training loss: 3.335880994796753
Validation loss: 2.2628502743218535

Epoch: 5| Step: 7
Training loss: 2.8161122798919678
Validation loss: 2.2598228916045158

Epoch: 5| Step: 8
Training loss: 2.136284112930298
Validation loss: 2.2501190708529566

Epoch: 5| Step: 9
Training loss: 2.521515369415283
Validation loss: 2.2549017578042965

Epoch: 5| Step: 10
Training loss: 1.5480232238769531
Validation loss: 2.259034623381912

Epoch: 76| Step: 0
Training loss: 2.0843582153320312
Validation loss: 2.2692706072202293

Epoch: 5| Step: 1
Training loss: 2.545531988143921
Validation loss: 2.2647722844154603

Epoch: 5| Step: 2
Training loss: 2.1838817596435547
Validation loss: 2.2737567911865892

Epoch: 5| Step: 3
Training loss: 2.7839207649230957
Validation loss: 2.271365655365811

Epoch: 5| Step: 4
Training loss: 2.618518829345703
Validation loss: 2.2823595436670447

Epoch: 5| Step: 5
Training loss: 3.2835707664489746
Validation loss: 2.2827697210414435

Epoch: 5| Step: 6
Training loss: 2.5650382041931152
Validation loss: 2.2782197485687914

Epoch: 5| Step: 7
Training loss: 2.407788038253784
Validation loss: 2.2740896299321163

Epoch: 5| Step: 8
Training loss: 2.6640822887420654
Validation loss: 2.2683338939502673

Epoch: 5| Step: 9
Training loss: 2.305448532104492
Validation loss: 2.2681131901279574

Epoch: 5| Step: 10
Training loss: 2.4085590839385986
Validation loss: 2.2702827274158435

Epoch: 77| Step: 0
Training loss: 2.55767822265625
Validation loss: 2.268206445119714

Epoch: 5| Step: 1
Training loss: 2.6992926597595215
Validation loss: 2.28952964146932

Epoch: 5| Step: 2
Training loss: 2.413534641265869
Validation loss: 2.2969374605404433

Epoch: 5| Step: 3
Training loss: 2.8214221000671387
Validation loss: 2.2953800078361266

Epoch: 5| Step: 4
Training loss: 2.8699069023132324
Validation loss: 2.291310561600552

Epoch: 5| Step: 5
Training loss: 2.666731595993042
Validation loss: 2.2880470547624814

Epoch: 5| Step: 6
Training loss: 1.7928352355957031
Validation loss: 2.2789008950674408

Epoch: 5| Step: 7
Training loss: 2.8996739387512207
Validation loss: 2.2571892379432597

Epoch: 5| Step: 8
Training loss: 1.9972079992294312
Validation loss: 2.2383052738763953

Epoch: 5| Step: 9
Training loss: 2.889324903488159
Validation loss: 2.240650949939605

Epoch: 5| Step: 10
Training loss: 2.3378865718841553
Validation loss: 2.2355305071799987

Epoch: 78| Step: 0
Training loss: 2.7188689708709717
Validation loss: 2.243382243699925

Epoch: 5| Step: 1
Training loss: 2.662691831588745
Validation loss: 2.247843929516372

Epoch: 5| Step: 2
Training loss: 1.395983338356018
Validation loss: 2.2469756833968626

Epoch: 5| Step: 3
Training loss: 2.0587775707244873
Validation loss: 2.2654844919840493

Epoch: 5| Step: 4
Training loss: 1.7691338062286377
Validation loss: 2.2780165710756854

Epoch: 5| Step: 5
Training loss: 2.5990688800811768
Validation loss: 2.2992466957338396

Epoch: 5| Step: 6
Training loss: 3.1491641998291016
Validation loss: 2.3182684016484085

Epoch: 5| Step: 7
Training loss: 2.686302661895752
Validation loss: 2.314357269194818

Epoch: 5| Step: 8
Training loss: 2.7453958988189697
Validation loss: 2.3317617447145524

Epoch: 5| Step: 9
Training loss: 2.8552849292755127
Validation loss: 2.3156625686153287

Epoch: 5| Step: 10
Training loss: 3.2348999977111816
Validation loss: 2.2950023861341577

Epoch: 79| Step: 0
Training loss: 2.277945041656494
Validation loss: 2.274607766059137

Epoch: 5| Step: 1
Training loss: 2.8231451511383057
Validation loss: 2.2476476110437864

Epoch: 5| Step: 2
Training loss: 2.877580165863037
Validation loss: 2.2364840276779665

Epoch: 5| Step: 3
Training loss: 1.9684196710586548
Validation loss: 2.2310212555752007

Epoch: 5| Step: 4
Training loss: 2.4878313541412354
Validation loss: 2.2239065375379337

Epoch: 5| Step: 5
Training loss: 1.967892050743103
Validation loss: 2.2210364803191154

Epoch: 5| Step: 6
Training loss: 2.545339584350586
Validation loss: 2.2198107345129854

Epoch: 5| Step: 7
Training loss: 2.6651980876922607
Validation loss: 2.2237253958179104

Epoch: 5| Step: 8
Training loss: 2.487414836883545
Validation loss: 2.2301885953513523

Epoch: 5| Step: 9
Training loss: 2.794477939605713
Validation loss: 2.254320001089445

Epoch: 5| Step: 10
Training loss: 2.8484811782836914
Validation loss: 2.241482998735161

Epoch: 80| Step: 0
Training loss: 2.3358936309814453
Validation loss: 2.233598102805435

Epoch: 5| Step: 1
Training loss: 2.524714469909668
Validation loss: 2.235809432562961

Epoch: 5| Step: 2
Training loss: 2.6170620918273926
Validation loss: 2.2489157774115123

Epoch: 5| Step: 3
Training loss: 2.2447595596313477
Validation loss: 2.2808061120330647

Epoch: 5| Step: 4
Training loss: 2.5974602699279785
Validation loss: 2.2824472752950524

Epoch: 5| Step: 5
Training loss: 2.553504228591919
Validation loss: 2.295135176309975

Epoch: 5| Step: 6
Training loss: 2.333792209625244
Validation loss: 2.291358188916278

Epoch: 5| Step: 7
Training loss: 2.807121753692627
Validation loss: 2.2738786666624007

Epoch: 5| Step: 8
Training loss: 3.0910804271698
Validation loss: 2.2682924091175036

Epoch: 5| Step: 9
Training loss: 1.874397873878479
Validation loss: 2.2820108116313977

Epoch: 5| Step: 10
Training loss: 2.667464017868042
Validation loss: 2.2895714390662407

Epoch: 81| Step: 0
Training loss: 2.7478981018066406
Validation loss: 2.2795792856524066

Epoch: 5| Step: 1
Training loss: 2.3979878425598145
Validation loss: 2.2748453617095947

Epoch: 5| Step: 2
Training loss: 2.4102821350097656
Validation loss: 2.253342415696831

Epoch: 5| Step: 3
Training loss: 2.740917921066284
Validation loss: 2.243443424983691

Epoch: 5| Step: 4
Training loss: 2.7249627113342285
Validation loss: 2.21177428255799

Epoch: 5| Step: 5
Training loss: 2.8724050521850586
Validation loss: 2.2024696873080347

Epoch: 5| Step: 6
Training loss: 2.520477056503296
Validation loss: 2.209431397017612

Epoch: 5| Step: 7
Training loss: 2.2885076999664307
Validation loss: 2.225193864555769

Epoch: 5| Step: 8
Training loss: 2.5940799713134766
Validation loss: 2.2628757325551843

Epoch: 5| Step: 9
Training loss: 1.9978843927383423
Validation loss: 2.3233894071271344

Epoch: 5| Step: 10
Training loss: 2.409467935562134
Validation loss: 2.3148621564270346

Epoch: 82| Step: 0
Training loss: 2.353386402130127
Validation loss: 2.3142025470733643

Epoch: 5| Step: 1
Training loss: 2.6344752311706543
Validation loss: 2.281440945081813

Epoch: 5| Step: 2
Training loss: 3.023691415786743
Validation loss: 2.2663453496912473

Epoch: 5| Step: 3
Training loss: 2.2518296241760254
Validation loss: 2.2248771036824873

Epoch: 5| Step: 4
Training loss: 2.393738269805908
Validation loss: 2.2120831320362706

Epoch: 5| Step: 5
Training loss: 2.528125762939453
Validation loss: 2.2142144531332035

Epoch: 5| Step: 6
Training loss: 2.3589253425598145
Validation loss: 2.2143878718858123

Epoch: 5| Step: 7
Training loss: 2.169238567352295
Validation loss: 2.2062333681250132

Epoch: 5| Step: 8
Training loss: 2.557459592819214
Validation loss: 2.2043952147165933

Epoch: 5| Step: 9
Training loss: 3.024529218673706
Validation loss: 2.2046094838009087

Epoch: 5| Step: 10
Training loss: 2.617417335510254
Validation loss: 2.2150677224641204

Epoch: 83| Step: 0
Training loss: 2.7961480617523193
Validation loss: 2.2381228913543043

Epoch: 5| Step: 1
Training loss: 2.4825196266174316
Validation loss: 2.2706219714174987

Epoch: 5| Step: 2
Training loss: 2.1130447387695312
Validation loss: 2.2831616401672363

Epoch: 5| Step: 3
Training loss: 2.421827554702759
Validation loss: 2.2887793792191373

Epoch: 5| Step: 4
Training loss: 2.9908485412597656
Validation loss: 2.292012522297521

Epoch: 5| Step: 5
Training loss: 2.0493690967559814
Validation loss: 2.2951516976920505

Epoch: 5| Step: 6
Training loss: 2.7862205505371094
Validation loss: 2.297934953884412

Epoch: 5| Step: 7
Training loss: 2.259403705596924
Validation loss: 2.30627788266828

Epoch: 5| Step: 8
Training loss: 3.0454602241516113
Validation loss: 2.3021121486540763

Epoch: 5| Step: 9
Training loss: 2.824007511138916
Validation loss: 2.3132340215867564

Epoch: 5| Step: 10
Training loss: 2.1772725582122803
Validation loss: 2.3115859441859747

Epoch: 84| Step: 0
Training loss: 2.3988571166992188
Validation loss: 2.295544796092536

Epoch: 5| Step: 1
Training loss: 2.481252670288086
Validation loss: 2.2785042434610348

Epoch: 5| Step: 2
Training loss: 3.089632749557495
Validation loss: 2.268895451740552

Epoch: 5| Step: 3
Training loss: 2.2097907066345215
Validation loss: 2.2669211664507465

Epoch: 5| Step: 4
Training loss: 2.3200080394744873
Validation loss: 2.2649179338127055

Epoch: 5| Step: 5
Training loss: 3.3291847705841064
Validation loss: 2.265173614666026

Epoch: 5| Step: 6
Training loss: 2.53472638130188
Validation loss: 2.2646278181383686

Epoch: 5| Step: 7
Training loss: 2.2901089191436768
Validation loss: 2.2778720099438905

Epoch: 5| Step: 8
Training loss: 2.7937397956848145
Validation loss: 2.2687558999625583

Epoch: 5| Step: 9
Training loss: 1.7960538864135742
Validation loss: 2.270269404175461

Epoch: 5| Step: 10
Training loss: 2.481724977493286
Validation loss: 2.262337685913168

Epoch: 85| Step: 0
Training loss: 2.627753734588623
Validation loss: 2.257824663192995

Epoch: 5| Step: 1
Training loss: 2.764194965362549
Validation loss: 2.257071336110433

Epoch: 5| Step: 2
Training loss: 2.513471841812134
Validation loss: 2.267265071151077

Epoch: 5| Step: 3
Training loss: 2.115238666534424
Validation loss: 2.275925761909895

Epoch: 5| Step: 4
Training loss: 2.668496608734131
Validation loss: 2.2752003797920803

Epoch: 5| Step: 5
Training loss: 2.986402988433838
Validation loss: 2.2779420857788413

Epoch: 5| Step: 6
Training loss: 2.394348621368408
Validation loss: 2.268118353300197

Epoch: 5| Step: 7
Training loss: 3.00588321685791
Validation loss: 2.256599813379267

Epoch: 5| Step: 8
Training loss: 2.432096481323242
Validation loss: 2.2520606017881826

Epoch: 5| Step: 9
Training loss: 1.9874954223632812
Validation loss: 2.2524034874413603

Epoch: 5| Step: 10
Training loss: 2.127078056335449
Validation loss: 2.2476566914589173

Epoch: 86| Step: 0
Training loss: 2.343252182006836
Validation loss: 2.2517502743710756

Epoch: 5| Step: 1
Training loss: 2.4614434242248535
Validation loss: 2.247475298502112

Epoch: 5| Step: 2
Training loss: 2.3397529125213623
Validation loss: 2.2474075645528813

Epoch: 5| Step: 3
Training loss: 2.647888660430908
Validation loss: 2.2496328097517773

Epoch: 5| Step: 4
Training loss: 2.916412830352783
Validation loss: 2.2472391077267226

Epoch: 5| Step: 5
Training loss: 2.7640175819396973
Validation loss: 2.2497207426255748

Epoch: 5| Step: 6
Training loss: 2.3465280532836914
Validation loss: 2.25443834130482

Epoch: 5| Step: 7
Training loss: 2.2347805500030518
Validation loss: 2.2576036196883007

Epoch: 5| Step: 8
Training loss: 2.5393385887145996
Validation loss: 2.2718280258999077

Epoch: 5| Step: 9
Training loss: 2.941171169281006
Validation loss: 2.2786699289916665

Epoch: 5| Step: 10
Training loss: 2.1274538040161133
Validation loss: 2.2717868999768327

Epoch: 87| Step: 0
Training loss: 2.648621082305908
Validation loss: 2.2573264516809934

Epoch: 5| Step: 1
Training loss: 2.0399324893951416
Validation loss: 2.244885721514302

Epoch: 5| Step: 2
Training loss: 2.769798994064331
Validation loss: 2.2380914970110823

Epoch: 5| Step: 3
Training loss: 1.9688127040863037
Validation loss: 2.2340441775578324

Epoch: 5| Step: 4
Training loss: 2.641554594039917
Validation loss: 2.23300507760817

Epoch: 5| Step: 5
Training loss: 2.290440797805786
Validation loss: 2.234620322463333

Epoch: 5| Step: 6
Training loss: 3.064009189605713
Validation loss: 2.2368204824386106

Epoch: 5| Step: 7
Training loss: 2.8460400104522705
Validation loss: 2.2350979402501094

Epoch: 5| Step: 8
Training loss: 2.432375431060791
Validation loss: 2.24026741263687

Epoch: 5| Step: 9
Training loss: 3.0211052894592285
Validation loss: 2.243099861247565

Epoch: 5| Step: 10
Training loss: 1.6592546701431274
Validation loss: 2.250196464600102

Epoch: 88| Step: 0
Training loss: 2.740553379058838
Validation loss: 2.2525280880671676

Epoch: 5| Step: 1
Training loss: 1.7786821126937866
Validation loss: 2.2646518163783576

Epoch: 5| Step: 2
Training loss: 2.44486665725708
Validation loss: 2.255977176850842

Epoch: 5| Step: 3
Training loss: 1.8821758031845093
Validation loss: 2.242683838772517

Epoch: 5| Step: 4
Training loss: 2.701536178588867
Validation loss: 2.244205562017297

Epoch: 5| Step: 5
Training loss: 2.4770541191101074
Validation loss: 2.231554856864355

Epoch: 5| Step: 6
Training loss: 2.726755142211914
Validation loss: 2.2321323938267206

Epoch: 5| Step: 7
Training loss: 2.6407523155212402
Validation loss: 2.232006267834735

Epoch: 5| Step: 8
Training loss: 2.665386199951172
Validation loss: 2.2282724354856756

Epoch: 5| Step: 9
Training loss: 2.5110490322113037
Validation loss: 2.239452774806689

Epoch: 5| Step: 10
Training loss: 2.91672420501709
Validation loss: 2.242078552963913

Epoch: 89| Step: 0
Training loss: 2.2574944496154785
Validation loss: 2.2328263431467037

Epoch: 5| Step: 1
Training loss: 2.5566623210906982
Validation loss: 2.2299210768873974

Epoch: 5| Step: 2
Training loss: 2.409918785095215
Validation loss: 2.231741105356524

Epoch: 5| Step: 3
Training loss: 2.5233988761901855
Validation loss: 2.2308128290278937

Epoch: 5| Step: 4
Training loss: 3.6605544090270996
Validation loss: 2.2321388131828717

Epoch: 5| Step: 5
Training loss: 2.1109557151794434
Validation loss: 2.2335204591033277

Epoch: 5| Step: 6
Training loss: 2.14758563041687
Validation loss: 2.236290785574144

Epoch: 5| Step: 7
Training loss: 2.426670789718628
Validation loss: 2.2416317873103644

Epoch: 5| Step: 8
Training loss: 2.128614902496338
Validation loss: 2.233674874869726

Epoch: 5| Step: 9
Training loss: 2.7235679626464844
Validation loss: 2.24094678765984

Epoch: 5| Step: 10
Training loss: 2.3305928707122803
Validation loss: 2.2243319685741136

Epoch: 90| Step: 0
Training loss: 2.9158616065979004
Validation loss: 2.220171287495603

Epoch: 5| Step: 1
Training loss: 2.551509380340576
Validation loss: 2.220143066939487

Epoch: 5| Step: 2
Training loss: 1.926702857017517
Validation loss: 2.2208151881412794

Epoch: 5| Step: 3
Training loss: 2.4388556480407715
Validation loss: 2.219712265076176

Epoch: 5| Step: 4
Training loss: 2.442206859588623
Validation loss: 2.236985442458942

Epoch: 5| Step: 5
Training loss: 2.1089107990264893
Validation loss: 2.236677274909071

Epoch: 5| Step: 6
Training loss: 2.869582176208496
Validation loss: 2.236066702873476

Epoch: 5| Step: 7
Training loss: 2.901310443878174
Validation loss: 2.228429235437865

Epoch: 5| Step: 8
Training loss: 2.5346851348876953
Validation loss: 2.2224464185776247

Epoch: 5| Step: 9
Training loss: 2.2651352882385254
Validation loss: 2.229864053828742

Epoch: 5| Step: 10
Training loss: 2.4283058643341064
Validation loss: 2.2202775503999446

Epoch: 91| Step: 0
Training loss: 2.3075737953186035
Validation loss: 2.2206143333065893

Epoch: 5| Step: 1
Training loss: 2.9069745540618896
Validation loss: 2.2248995252834853

Epoch: 5| Step: 2
Training loss: 2.7272019386291504
Validation loss: 2.2273520474792807

Epoch: 5| Step: 3
Training loss: 2.8886024951934814
Validation loss: 2.240152302608695

Epoch: 5| Step: 4
Training loss: 2.1512291431427
Validation loss: 2.235391988549181

Epoch: 5| Step: 5
Training loss: 2.388366222381592
Validation loss: 2.222506377004808

Epoch: 5| Step: 6
Training loss: 1.7022079229354858
Validation loss: 2.2263436881444787

Epoch: 5| Step: 7
Training loss: 2.4706168174743652
Validation loss: 2.2143693329185568

Epoch: 5| Step: 8
Training loss: 2.61702299118042
Validation loss: 2.219045913347634

Epoch: 5| Step: 9
Training loss: 2.5797009468078613
Validation loss: 2.2079524840078046

Epoch: 5| Step: 10
Training loss: 2.5485010147094727
Validation loss: 2.2219551660681285

Epoch: 92| Step: 0
Training loss: 2.699439287185669
Validation loss: 2.2342478895700104

Epoch: 5| Step: 1
Training loss: 2.1907753944396973
Validation loss: 2.23419701668524

Epoch: 5| Step: 2
Training loss: 1.5733801126480103
Validation loss: 2.2415897820585515

Epoch: 5| Step: 3
Training loss: 2.5456695556640625
Validation loss: 2.246092119524556

Epoch: 5| Step: 4
Training loss: 2.752450466156006
Validation loss: 2.232159158234955

Epoch: 5| Step: 5
Training loss: 2.4241223335266113
Validation loss: 2.2287775675455728

Epoch: 5| Step: 6
Training loss: 2.5572121143341064
Validation loss: 2.2262996114710325

Epoch: 5| Step: 7
Training loss: 2.51788592338562
Validation loss: 2.2357054730897308

Epoch: 5| Step: 8
Training loss: 2.642019748687744
Validation loss: 2.2439697839880504

Epoch: 5| Step: 9
Training loss: 2.729212999343872
Validation loss: 2.242768059494675

Epoch: 5| Step: 10
Training loss: 2.7822208404541016
Validation loss: 2.227092191737185

Epoch: 93| Step: 0
Training loss: 2.1495654582977295
Validation loss: 2.219532077030469

Epoch: 5| Step: 1
Training loss: 2.7318453788757324
Validation loss: 2.229618159673547

Epoch: 5| Step: 2
Training loss: 2.288709878921509
Validation loss: 2.2212778265758226

Epoch: 5| Step: 3
Training loss: 3.1016767024993896
Validation loss: 2.2275462201846543

Epoch: 5| Step: 4
Training loss: 2.0226383209228516
Validation loss: 2.228518186076995

Epoch: 5| Step: 5
Training loss: 2.7654685974121094
Validation loss: 2.2214189370473227

Epoch: 5| Step: 6
Training loss: 2.853311777114868
Validation loss: 2.21970187464068

Epoch: 5| Step: 7
Training loss: 2.1556639671325684
Validation loss: 2.2017710695984545

Epoch: 5| Step: 8
Training loss: 1.668452501296997
Validation loss: 2.1968206590221775

Epoch: 5| Step: 9
Training loss: 3.198894739151001
Validation loss: 2.194523315275869

Epoch: 5| Step: 10
Training loss: 2.149526596069336
Validation loss: 2.1945713053467455

Epoch: 94| Step: 0
Training loss: 2.24273681640625
Validation loss: 2.188386183913036

Epoch: 5| Step: 1
Training loss: 3.0353586673736572
Validation loss: 2.1905722413011777

Epoch: 5| Step: 2
Training loss: 2.243112564086914
Validation loss: 2.1847456309103195

Epoch: 5| Step: 3
Training loss: 2.8045763969421387
Validation loss: 2.1781490977092455

Epoch: 5| Step: 4
Training loss: 2.7970058917999268
Validation loss: 2.1746573550726778

Epoch: 5| Step: 5
Training loss: 2.3862879276275635
Validation loss: 2.1766869483455533

Epoch: 5| Step: 6
Training loss: 1.6997461318969727
Validation loss: 2.1699457014760664

Epoch: 5| Step: 7
Training loss: 2.1406986713409424
Validation loss: 2.174467814865933

Epoch: 5| Step: 8
Training loss: 2.279615640640259
Validation loss: 2.183956471822595

Epoch: 5| Step: 9
Training loss: 2.6185734272003174
Validation loss: 2.1908797371772026

Epoch: 5| Step: 10
Training loss: 2.869983434677124
Validation loss: 2.204485306175806

Epoch: 95| Step: 0
Training loss: 2.391366720199585
Validation loss: 2.218030615519452

Epoch: 5| Step: 1
Training loss: 3.1901228427886963
Validation loss: 2.2381282416723107

Epoch: 5| Step: 2
Training loss: 2.463179111480713
Validation loss: 2.22403706530089

Epoch: 5| Step: 3
Training loss: 2.8311660289764404
Validation loss: 2.2095519150457075

Epoch: 5| Step: 4
Training loss: 2.158555030822754
Validation loss: 2.1983344875356203

Epoch: 5| Step: 5
Training loss: 2.303422451019287
Validation loss: 2.183434400507199

Epoch: 5| Step: 6
Training loss: 2.7862439155578613
Validation loss: 2.169922887638051

Epoch: 5| Step: 7
Training loss: 1.9612476825714111
Validation loss: 2.1631917594581522

Epoch: 5| Step: 8
Training loss: 1.8348060846328735
Validation loss: 2.169350706120973

Epoch: 5| Step: 9
Training loss: 2.2842259407043457
Validation loss: 2.178853190073403

Epoch: 5| Step: 10
Training loss: 2.9025354385375977
Validation loss: 2.1829808117240987

Epoch: 96| Step: 0
Training loss: 2.457655668258667
Validation loss: 2.1811614421106156

Epoch: 5| Step: 1
Training loss: 2.7263541221618652
Validation loss: 2.1682397934698288

Epoch: 5| Step: 2
Training loss: 2.0566768646240234
Validation loss: 2.1707886111351753

Epoch: 5| Step: 3
Training loss: 3.2126948833465576
Validation loss: 2.1739374860640495

Epoch: 5| Step: 4
Training loss: 2.714940309524536
Validation loss: 2.16493550936381

Epoch: 5| Step: 5
Training loss: 3.1046957969665527
Validation loss: 2.1526559091383413

Epoch: 5| Step: 6
Training loss: 1.775800108909607
Validation loss: 2.1580532981503393

Epoch: 5| Step: 7
Training loss: 2.3096349239349365
Validation loss: 2.1483107484796995

Epoch: 5| Step: 8
Training loss: 1.893328070640564
Validation loss: 2.1522854323028238

Epoch: 5| Step: 9
Training loss: 2.5217580795288086
Validation loss: 2.1524226050223074

Epoch: 5| Step: 10
Training loss: 1.7827457189559937
Validation loss: 2.160145572436753

Epoch: 97| Step: 0
Training loss: 2.381882905960083
Validation loss: 2.163089975234001

Epoch: 5| Step: 1
Training loss: 2.6480352878570557
Validation loss: 2.1668077207380727

Epoch: 5| Step: 2
Training loss: 2.638434648513794
Validation loss: 2.1603383402670584

Epoch: 5| Step: 3
Training loss: 2.183544635772705
Validation loss: 2.1569562624859553

Epoch: 5| Step: 4
Training loss: 2.6607565879821777
Validation loss: 2.1519395523173834

Epoch: 5| Step: 5
Training loss: 2.268065929412842
Validation loss: 2.1529737851952993

Epoch: 5| Step: 6
Training loss: 2.1322109699249268
Validation loss: 2.151749300700362

Epoch: 5| Step: 7
Training loss: 2.6584579944610596
Validation loss: 2.1495719648176626

Epoch: 5| Step: 8
Training loss: 2.2000744342803955
Validation loss: 2.1450725960475143

Epoch: 5| Step: 9
Training loss: 1.962551474571228
Validation loss: 2.136021552547332

Epoch: 5| Step: 10
Training loss: 2.937821388244629
Validation loss: 2.1371992518824916

Epoch: 98| Step: 0
Training loss: 2.192816734313965
Validation loss: 2.132819269293098

Epoch: 5| Step: 1
Training loss: 1.9342706203460693
Validation loss: 2.1337687738480104

Epoch: 5| Step: 2
Training loss: 2.7918195724487305
Validation loss: 2.1305368126079602

Epoch: 5| Step: 3
Training loss: 2.372647523880005
Validation loss: 2.1468506346466723

Epoch: 5| Step: 4
Training loss: 2.280592441558838
Validation loss: 2.1556294207931845

Epoch: 5| Step: 5
Training loss: 2.1772871017456055
Validation loss: 2.1700174731592976

Epoch: 5| Step: 6
Training loss: 2.6729819774627686
Validation loss: 2.1636480105820524

Epoch: 5| Step: 7
Training loss: 2.226097583770752
Validation loss: 2.1630201596085743

Epoch: 5| Step: 8
Training loss: 3.192261219024658
Validation loss: 2.158363121812062

Epoch: 5| Step: 9
Training loss: 2.2429862022399902
Validation loss: 2.1400668313426356

Epoch: 5| Step: 10
Training loss: 2.6058342456817627
Validation loss: 2.134318777309951

Epoch: 99| Step: 0
Training loss: 2.2415099143981934
Validation loss: 2.1339645693379063

Epoch: 5| Step: 1
Training loss: 2.4282383918762207
Validation loss: 2.134542275500554

Epoch: 5| Step: 2
Training loss: 1.9903866052627563
Validation loss: 2.1313416316945064

Epoch: 5| Step: 3
Training loss: 2.4716570377349854
Validation loss: 2.132532569669908

Epoch: 5| Step: 4
Training loss: 2.6579158306121826
Validation loss: 2.1559321521430888

Epoch: 5| Step: 5
Training loss: 2.4107108116149902
Validation loss: 2.178847602618638

Epoch: 5| Step: 6
Training loss: 2.6735644340515137
Validation loss: 2.2077517496642245

Epoch: 5| Step: 7
Training loss: 2.1039490699768066
Validation loss: 2.232512670178567

Epoch: 5| Step: 8
Training loss: 2.381948232650757
Validation loss: 2.2402771044802923

Epoch: 5| Step: 9
Training loss: 3.0090103149414062
Validation loss: 2.2160416341597036

Epoch: 5| Step: 10
Training loss: 2.5485408306121826
Validation loss: 2.1620523198958366

Epoch: 100| Step: 0
Training loss: 2.110137939453125
Validation loss: 2.1442512004606185

Epoch: 5| Step: 1
Training loss: 2.4497389793395996
Validation loss: 2.1346089275934363

Epoch: 5| Step: 2
Training loss: 2.098544120788574
Validation loss: 2.1427582822820193

Epoch: 5| Step: 3
Training loss: 2.5572712421417236
Validation loss: 2.158388041680859

Epoch: 5| Step: 4
Training loss: 2.2385573387145996
Validation loss: 2.186753132010019

Epoch: 5| Step: 5
Training loss: 2.0930747985839844
Validation loss: 2.1684672512033933

Epoch: 5| Step: 6
Training loss: 1.9466514587402344
Validation loss: 2.1587173246568248

Epoch: 5| Step: 7
Training loss: 3.2638416290283203
Validation loss: 2.150476524906774

Epoch: 5| Step: 8
Training loss: 2.6201181411743164
Validation loss: 2.1551777009041078

Epoch: 5| Step: 9
Training loss: 2.993305206298828
Validation loss: 2.1643828499701714

Epoch: 5| Step: 10
Training loss: 2.176323890686035
Validation loss: 2.1695953133285686

Epoch: 101| Step: 0
Training loss: 2.426837921142578
Validation loss: 2.1722192302826913

Epoch: 5| Step: 1
Training loss: 2.704251527786255
Validation loss: 2.1720780800747614

Epoch: 5| Step: 2
Training loss: 2.2057697772979736
Validation loss: 2.160827777718985

Epoch: 5| Step: 3
Training loss: 2.4237093925476074
Validation loss: 2.1412506334243284

Epoch: 5| Step: 4
Training loss: 2.5191433429718018
Validation loss: 2.1328925778788905

Epoch: 5| Step: 5
Training loss: 1.5008646249771118
Validation loss: 2.1241996224208544

Epoch: 5| Step: 6
Training loss: 2.7567481994628906
Validation loss: 2.12642220399713

Epoch: 5| Step: 7
Training loss: 2.490596294403076
Validation loss: 2.12365061108784

Epoch: 5| Step: 8
Training loss: 2.5194783210754395
Validation loss: 2.12431477731274

Epoch: 5| Step: 9
Training loss: 2.4095587730407715
Validation loss: 2.125281395450715

Epoch: 5| Step: 10
Training loss: 2.598965644836426
Validation loss: 2.1227366873013076

Epoch: 102| Step: 0
Training loss: 2.3006443977355957
Validation loss: 2.123992489230248

Epoch: 5| Step: 1
Training loss: 2.1562867164611816
Validation loss: 2.1329061036468833

Epoch: 5| Step: 2
Training loss: 2.4248206615448
Validation loss: 2.140687104194395

Epoch: 5| Step: 3
Training loss: 2.5306217670440674
Validation loss: 2.1567856316925376

Epoch: 5| Step: 4
Training loss: 2.596177339553833
Validation loss: 2.1751534579902567

Epoch: 5| Step: 5
Training loss: 2.890364170074463
Validation loss: 2.1901244732641403

Epoch: 5| Step: 6
Training loss: 2.262862205505371
Validation loss: 2.171855416349185

Epoch: 5| Step: 7
Training loss: 2.4244205951690674
Validation loss: 2.1488796664822485

Epoch: 5| Step: 8
Training loss: 2.5708413124084473
Validation loss: 2.1263869193292435

Epoch: 5| Step: 9
Training loss: 1.847519874572754
Validation loss: 2.1229507025851997

Epoch: 5| Step: 10
Training loss: 2.7140896320343018
Validation loss: 2.1402614860124487

Epoch: 103| Step: 0
Training loss: 2.690253734588623
Validation loss: 2.1500858017193374

Epoch: 5| Step: 1
Training loss: 2.955785036087036
Validation loss: 2.1410924311607116

Epoch: 5| Step: 2
Training loss: 2.2037370204925537
Validation loss: 2.1391616598252328

Epoch: 5| Step: 3
Training loss: 2.4290575981140137
Validation loss: 2.154583218277142

Epoch: 5| Step: 4
Training loss: 2.5959525108337402
Validation loss: 2.151891767337758

Epoch: 5| Step: 5
Training loss: 1.9751999378204346
Validation loss: 2.1457696806999946

Epoch: 5| Step: 6
Training loss: 2.5715014934539795
Validation loss: 2.1436016457055205

Epoch: 5| Step: 7
Training loss: 1.996151328086853
Validation loss: 2.1253908885422574

Epoch: 5| Step: 8
Training loss: 2.3765673637390137
Validation loss: 2.1259100116709226

Epoch: 5| Step: 9
Training loss: 2.7738351821899414
Validation loss: 2.146719019900086

Epoch: 5| Step: 10
Training loss: 1.968867540359497
Validation loss: 2.173365557065574

Epoch: 104| Step: 0
Training loss: 2.9692771434783936
Validation loss: 2.1640395964345625

Epoch: 5| Step: 1
Training loss: 2.1657400131225586
Validation loss: 2.1456528094507035

Epoch: 5| Step: 2
Training loss: 2.2060885429382324
Validation loss: 2.137156194256198

Epoch: 5| Step: 3
Training loss: 2.7012288570404053
Validation loss: 2.1184602206753147

Epoch: 5| Step: 4
Training loss: 1.8233897686004639
Validation loss: 2.1193534148636686

Epoch: 5| Step: 5
Training loss: 2.75195050239563
Validation loss: 2.1339435359483123

Epoch: 5| Step: 6
Training loss: 2.2373552322387695
Validation loss: 2.1657897490327076

Epoch: 5| Step: 7
Training loss: 2.632117509841919
Validation loss: 2.2114384661438646

Epoch: 5| Step: 8
Training loss: 2.173647403717041
Validation loss: 2.174350880807446

Epoch: 5| Step: 9
Training loss: 2.7246580123901367
Validation loss: 2.132959440190305

Epoch: 5| Step: 10
Training loss: 2.7279605865478516
Validation loss: 2.1211270837373633

Epoch: 105| Step: 0
Training loss: 1.9932807683944702
Validation loss: 2.11694392465776

Epoch: 5| Step: 1
Training loss: 2.120640754699707
Validation loss: 2.1556559685737855

Epoch: 5| Step: 2
Training loss: 2.7444746494293213
Validation loss: 2.232116489000218

Epoch: 5| Step: 3
Training loss: 2.2175402641296387
Validation loss: 2.2303039361071844

Epoch: 5| Step: 4
Training loss: 2.077390193939209
Validation loss: 2.2535896121814685

Epoch: 5| Step: 5
Training loss: 3.0491397380828857
Validation loss: 2.2102973153514247

Epoch: 5| Step: 6
Training loss: 2.228355884552002
Validation loss: 2.1553584362870906

Epoch: 5| Step: 7
Training loss: 2.4865550994873047
Validation loss: 2.1002779801686606

Epoch: 5| Step: 8
Training loss: 2.6314313411712646
Validation loss: 2.071013932586998

Epoch: 5| Step: 9
Training loss: 2.2675719261169434
Validation loss: 2.0568663856034637

Epoch: 5| Step: 10
Training loss: 2.7043240070343018
Validation loss: 2.051614652397812

Epoch: 106| Step: 0
Training loss: 2.4224913120269775
Validation loss: 2.056974632765657

Epoch: 5| Step: 1
Training loss: 2.032984495162964
Validation loss: 2.053049025997039

Epoch: 5| Step: 2
Training loss: 2.6197028160095215
Validation loss: 2.0512578436123428

Epoch: 5| Step: 3
Training loss: 1.9725773334503174
Validation loss: 2.052287740092124

Epoch: 5| Step: 4
Training loss: 1.8373124599456787
Validation loss: 2.047385943833218

Epoch: 5| Step: 5
Training loss: 2.606473922729492
Validation loss: 2.0450559482779553

Epoch: 5| Step: 6
Training loss: 1.8715999126434326
Validation loss: 2.050508315845202

Epoch: 5| Step: 7
Training loss: 2.9935460090637207
Validation loss: 2.066882277047762

Epoch: 5| Step: 8
Training loss: 2.2804901599884033
Validation loss: 2.1004712555998113

Epoch: 5| Step: 9
Training loss: 2.9023900032043457
Validation loss: 2.1398455635193856

Epoch: 5| Step: 10
Training loss: 2.3357646465301514
Validation loss: 2.1574160001611196

Epoch: 107| Step: 0
Training loss: 2.300696849822998
Validation loss: 2.1788013417233705

Epoch: 5| Step: 1
Training loss: 1.8346889019012451
Validation loss: 2.185208064253612

Epoch: 5| Step: 2
Training loss: 2.898700714111328
Validation loss: 2.175069470559397

Epoch: 5| Step: 3
Training loss: 2.2020506858825684
Validation loss: 2.134422752165025

Epoch: 5| Step: 4
Training loss: 2.559926986694336
Validation loss: 2.094498029319189

Epoch: 5| Step: 5
Training loss: 2.513601541519165
Validation loss: 2.059654994677472

Epoch: 5| Step: 6
Training loss: 2.997983455657959
Validation loss: 2.051211567335231

Epoch: 5| Step: 7
Training loss: 2.5455973148345947
Validation loss: 2.0503590850419897

Epoch: 5| Step: 8
Training loss: 2.0274853706359863
Validation loss: 2.059074881256268

Epoch: 5| Step: 9
Training loss: 2.3022141456604004
Validation loss: 2.05848862278846

Epoch: 5| Step: 10
Training loss: 2.1680662631988525
Validation loss: 2.058216018061484

Epoch: 108| Step: 0
Training loss: 2.682216167449951
Validation loss: 2.0705852854636406

Epoch: 5| Step: 1
Training loss: 1.7413628101348877
Validation loss: 2.0769282207694104

Epoch: 5| Step: 2
Training loss: 2.2225382328033447
Validation loss: 2.0777358611424765

Epoch: 5| Step: 3
Training loss: 2.738734722137451
Validation loss: 2.0717713268854285

Epoch: 5| Step: 4
Training loss: 2.0511293411254883
Validation loss: 2.073668336355558

Epoch: 5| Step: 5
Training loss: 2.9453752040863037
Validation loss: 2.077135614169541

Epoch: 5| Step: 6
Training loss: 2.7203476428985596
Validation loss: 2.0975913232372654

Epoch: 5| Step: 7
Training loss: 1.9896643161773682
Validation loss: 2.0959371315535678

Epoch: 5| Step: 8
Training loss: 2.142850637435913
Validation loss: 2.0982333793435046

Epoch: 5| Step: 9
Training loss: 2.176823377609253
Validation loss: 2.096313771381173

Epoch: 5| Step: 10
Training loss: 2.393472671508789
Validation loss: 2.1052463939113

Epoch: 109| Step: 0
Training loss: 2.143200159072876
Validation loss: 2.1136913171378513

Epoch: 5| Step: 1
Training loss: 1.7361561059951782
Validation loss: 2.1199683732883905

Epoch: 5| Step: 2
Training loss: 1.9720180034637451
Validation loss: 2.1118506821252967

Epoch: 5| Step: 3
Training loss: 2.8429763317108154
Validation loss: 2.110896107971027

Epoch: 5| Step: 4
Training loss: 2.372360944747925
Validation loss: 2.106719187510911

Epoch: 5| Step: 5
Training loss: 2.730375289916992
Validation loss: 2.090074166174858

Epoch: 5| Step: 6
Training loss: 2.7241199016571045
Validation loss: 2.0651205355121243

Epoch: 5| Step: 7
Training loss: 2.088347911834717
Validation loss: 2.057152840398973

Epoch: 5| Step: 8
Training loss: 2.126746416091919
Validation loss: 2.0572323901678926

Epoch: 5| Step: 9
Training loss: 2.2766730785369873
Validation loss: 2.048079905971404

Epoch: 5| Step: 10
Training loss: 2.8361165523529053
Validation loss: 2.0489492621473087

Epoch: 110| Step: 0
Training loss: 2.8932271003723145
Validation loss: 2.0455676586397233

Epoch: 5| Step: 1
Training loss: 1.9683561325073242
Validation loss: 2.0389948468054495

Epoch: 5| Step: 2
Training loss: 2.32690167427063
Validation loss: 2.0466847599193616

Epoch: 5| Step: 3
Training loss: 2.5890252590179443
Validation loss: 2.0489727797046786

Epoch: 5| Step: 4
Training loss: 2.0664849281311035
Validation loss: 2.053108078177257

Epoch: 5| Step: 5
Training loss: 2.1023497581481934
Validation loss: 2.0776696256411973

Epoch: 5| Step: 6
Training loss: 2.669591188430786
Validation loss: 2.104800337104387

Epoch: 5| Step: 7
Training loss: 2.2298426628112793
Validation loss: 2.1251327145484185

Epoch: 5| Step: 8
Training loss: 2.3502910137176514
Validation loss: 2.1265351900490383

Epoch: 5| Step: 9
Training loss: 2.4551262855529785
Validation loss: 2.1514079365679013

Epoch: 5| Step: 10
Training loss: 2.1098179817199707
Validation loss: 2.1604500893623597

Epoch: 111| Step: 0
Training loss: 2.3042702674865723
Validation loss: 2.1615599432299213

Epoch: 5| Step: 1
Training loss: 2.398205280303955
Validation loss: 2.150289617558961

Epoch: 5| Step: 2
Training loss: 2.5829434394836426
Validation loss: 2.125504305285792

Epoch: 5| Step: 3
Training loss: 2.2623789310455322
Validation loss: 2.130008643673312

Epoch: 5| Step: 4
Training loss: 2.0385639667510986
Validation loss: 2.1243091603761077

Epoch: 5| Step: 5
Training loss: 2.544832229614258
Validation loss: 2.1518306501450075

Epoch: 5| Step: 6
Training loss: 2.5275254249572754
Validation loss: 2.152041427550777

Epoch: 5| Step: 7
Training loss: 2.049379587173462
Validation loss: 2.149105841113675

Epoch: 5| Step: 8
Training loss: 2.308988094329834
Validation loss: 2.1415233522333126

Epoch: 5| Step: 9
Training loss: 2.330522298812866
Validation loss: 2.1379495769418697

Epoch: 5| Step: 10
Training loss: 2.800412893295288
Validation loss: 2.156555450090798

Epoch: 112| Step: 0
Training loss: 2.370833158493042
Validation loss: 2.1459023157755532

Epoch: 5| Step: 1
Training loss: 2.5613715648651123
Validation loss: 2.1352921224409536

Epoch: 5| Step: 2
Training loss: 2.5687174797058105
Validation loss: 2.1135921773090156

Epoch: 5| Step: 3
Training loss: 2.382397174835205
Validation loss: 2.0820801129905124

Epoch: 5| Step: 4
Training loss: 2.0755646228790283
Validation loss: 2.051617399338753

Epoch: 5| Step: 5
Training loss: 1.4636187553405762
Validation loss: 2.0318660851447814

Epoch: 5| Step: 6
Training loss: 2.0480284690856934
Validation loss: 2.022867766759729

Epoch: 5| Step: 7
Training loss: 2.3440604209899902
Validation loss: 2.019795645949661

Epoch: 5| Step: 8
Training loss: 2.3605093955993652
Validation loss: 2.027454312129687

Epoch: 5| Step: 9
Training loss: 2.800957202911377
Validation loss: 2.038548056797315

Epoch: 5| Step: 10
Training loss: 2.712161064147949
Validation loss: 2.0337254180703113

Epoch: 113| Step: 0
Training loss: 2.154176712036133
Validation loss: 2.037141356416928

Epoch: 5| Step: 1
Training loss: 1.8582576513290405
Validation loss: 2.0327472840586016

Epoch: 5| Step: 2
Training loss: 2.886742115020752
Validation loss: 2.0371341589958436

Epoch: 5| Step: 3
Training loss: 2.402121067047119
Validation loss: 2.032211181938007

Epoch: 5| Step: 4
Training loss: 2.338222026824951
Validation loss: 2.032981954595094

Epoch: 5| Step: 5
Training loss: 2.548037052154541
Validation loss: 2.035969216336486

Epoch: 5| Step: 6
Training loss: 1.7813056707382202
Validation loss: 2.0240325286824215

Epoch: 5| Step: 7
Training loss: 2.5190024375915527
Validation loss: 2.0184923038687757

Epoch: 5| Step: 8
Training loss: 1.8735631704330444
Validation loss: 2.009782818055922

Epoch: 5| Step: 9
Training loss: 2.0564064979553223
Validation loss: 2.009932707714778

Epoch: 5| Step: 10
Training loss: 3.037421941757202
Validation loss: 2.0076380493820354

Epoch: 114| Step: 0
Training loss: 2.0123159885406494
Validation loss: 2.0064044011536466

Epoch: 5| Step: 1
Training loss: 2.1754465103149414
Validation loss: 2.0069269493062007

Epoch: 5| Step: 2
Training loss: 2.052764415740967
Validation loss: 2.0088467572325017

Epoch: 5| Step: 3
Training loss: 2.5064964294433594
Validation loss: 2.0140050765006774

Epoch: 5| Step: 4
Training loss: 1.8443748950958252
Validation loss: 2.0073172661565963

Epoch: 5| Step: 5
Training loss: 2.6975932121276855
Validation loss: 2.007385524370337

Epoch: 5| Step: 6
Training loss: 1.9798481464385986
Validation loss: 2.0123596088860625

Epoch: 5| Step: 7
Training loss: 2.3864362239837646
Validation loss: 2.007002122940556

Epoch: 5| Step: 8
Training loss: 2.759821891784668
Validation loss: 2.003471186084132

Epoch: 5| Step: 9
Training loss: 2.2343077659606934
Validation loss: 2.008323028523435

Epoch: 5| Step: 10
Training loss: 2.6799328327178955
Validation loss: 2.0101847033346854

Epoch: 115| Step: 0
Training loss: 1.9246654510498047
Validation loss: 2.01243935092803

Epoch: 5| Step: 1
Training loss: 1.7620235681533813
Validation loss: 2.018289012293662

Epoch: 5| Step: 2
Training loss: 2.84096360206604
Validation loss: 2.014440290389522

Epoch: 5| Step: 3
Training loss: 2.208829402923584
Validation loss: 2.020279730519941

Epoch: 5| Step: 4
Training loss: 2.1344516277313232
Validation loss: 2.016893331722547

Epoch: 5| Step: 5
Training loss: 2.0131568908691406
Validation loss: 2.009158854843468

Epoch: 5| Step: 6
Training loss: 2.6645941734313965
Validation loss: 2.000785599472702

Epoch: 5| Step: 7
Training loss: 2.591054916381836
Validation loss: 1.99675202626054

Epoch: 5| Step: 8
Training loss: 2.9160845279693604
Validation loss: 2.0026718378067017

Epoch: 5| Step: 9
Training loss: 1.8537213802337646
Validation loss: 2.002208889171641

Epoch: 5| Step: 10
Training loss: 2.288242816925049
Validation loss: 1.9972605961625294

Epoch: 116| Step: 0
Training loss: 1.9074742794036865
Validation loss: 2.006987792189403

Epoch: 5| Step: 1
Training loss: 2.453346014022827
Validation loss: 2.013947962432779

Epoch: 5| Step: 2
Training loss: 2.471959352493286
Validation loss: 2.0233565389469104

Epoch: 5| Step: 3
Training loss: 2.0750436782836914
Validation loss: 2.0151130896742626

Epoch: 5| Step: 4
Training loss: 2.7381975650787354
Validation loss: 2.007832986052318

Epoch: 5| Step: 5
Training loss: 1.9333832263946533
Validation loss: 2.0039845922941804

Epoch: 5| Step: 6
Training loss: 2.2463526725769043
Validation loss: 2.0043286815766366

Epoch: 5| Step: 7
Training loss: 2.0881712436676025
Validation loss: 2.007186702502671

Epoch: 5| Step: 8
Training loss: 1.9685779809951782
Validation loss: 2.0062147391739713

Epoch: 5| Step: 9
Training loss: 2.7273943424224854
Validation loss: 2.008119742075602

Epoch: 5| Step: 10
Training loss: 2.629789113998413
Validation loss: 2.0238219230405745

Epoch: 117| Step: 0
Training loss: 1.6279093027114868
Validation loss: 2.045043278765935

Epoch: 5| Step: 1
Training loss: 2.4871325492858887
Validation loss: 2.0640901570679038

Epoch: 5| Step: 2
Training loss: 2.6709513664245605
Validation loss: 2.0668673605047245

Epoch: 5| Step: 3
Training loss: 2.4436159133911133
Validation loss: 2.0644312994454497

Epoch: 5| Step: 4
Training loss: 2.284294605255127
Validation loss: 2.076591218671491

Epoch: 5| Step: 5
Training loss: 2.1862289905548096
Validation loss: 2.0591929984349076

Epoch: 5| Step: 6
Training loss: 2.0710930824279785
Validation loss: 2.0466124473079557

Epoch: 5| Step: 7
Training loss: 2.2968010902404785
Validation loss: 2.039672423434514

Epoch: 5| Step: 8
Training loss: 2.3929688930511475
Validation loss: 2.036734493829871

Epoch: 5| Step: 9
Training loss: 2.8090481758117676
Validation loss: 2.0594794980941282

Epoch: 5| Step: 10
Training loss: 1.8278454542160034
Validation loss: 2.0465536258553945

Epoch: 118| Step: 0
Training loss: 2.466003656387329
Validation loss: 2.026938294851652

Epoch: 5| Step: 1
Training loss: 1.9931614398956299
Validation loss: 2.0209832345285723

Epoch: 5| Step: 2
Training loss: 3.1085662841796875
Validation loss: 2.0015847093315533

Epoch: 5| Step: 3
Training loss: 1.7115049362182617
Validation loss: 1.9994522551054597

Epoch: 5| Step: 4
Training loss: 1.8206298351287842
Validation loss: 1.9997716373012913

Epoch: 5| Step: 5
Training loss: 1.9089586734771729
Validation loss: 2.015698978977819

Epoch: 5| Step: 6
Training loss: 2.880401611328125
Validation loss: 2.0367219140452724

Epoch: 5| Step: 7
Training loss: 2.010695695877075
Validation loss: 2.0394237708019953

Epoch: 5| Step: 8
Training loss: 2.694502592086792
Validation loss: 2.0348384764886673

Epoch: 5| Step: 9
Training loss: 2.302861452102661
Validation loss: 2.0132855433289722

Epoch: 5| Step: 10
Training loss: 2.5725183486938477
Validation loss: 1.9946338592037078

Epoch: 119| Step: 0
Training loss: 1.9889532327651978
Validation loss: 1.9882669602670977

Epoch: 5| Step: 1
Training loss: 1.845252275466919
Validation loss: 1.9879319590906943

Epoch: 5| Step: 2
Training loss: 2.202226400375366
Validation loss: 1.9870955636424403

Epoch: 5| Step: 3
Training loss: 2.1738884449005127
Validation loss: 1.9856863098759805

Epoch: 5| Step: 4
Training loss: 2.355013370513916
Validation loss: 1.9867686276794763

Epoch: 5| Step: 5
Training loss: 2.399923801422119
Validation loss: 1.9864209467364895

Epoch: 5| Step: 6
Training loss: 2.644202709197998
Validation loss: 1.993651190111714

Epoch: 5| Step: 7
Training loss: 2.4374172687530518
Validation loss: 2.0120944797351794

Epoch: 5| Step: 8
Training loss: 2.0800421237945557
Validation loss: 2.017853968886919

Epoch: 5| Step: 9
Training loss: 2.2991862297058105
Validation loss: 2.030693406699806

Epoch: 5| Step: 10
Training loss: 2.631753921508789
Validation loss: 2.0427849318391536

Epoch: 120| Step: 0
Training loss: 2.95469331741333
Validation loss: 2.0446273665274344

Epoch: 5| Step: 1
Training loss: 2.5318515300750732
Validation loss: 2.0655121444374003

Epoch: 5| Step: 2
Training loss: 1.829248070716858
Validation loss: 2.064266598352822

Epoch: 5| Step: 3
Training loss: 1.5060030221939087
Validation loss: 2.0570039992691367

Epoch: 5| Step: 4
Training loss: 1.475211262702942
Validation loss: 2.106611902995776

Epoch: 5| Step: 5
Training loss: 2.537539482116699
Validation loss: 2.1049701962419736

Epoch: 5| Step: 6
Training loss: 2.017271041870117
Validation loss: 2.118450850568792

Epoch: 5| Step: 7
Training loss: 2.9966111183166504
Validation loss: 2.147854192282564

Epoch: 5| Step: 8
Training loss: 3.168910503387451
Validation loss: 2.1308160763914867

Epoch: 5| Step: 9
Training loss: 2.6001176834106445
Validation loss: 2.1033020557895785

Epoch: 5| Step: 10
Training loss: 1.804646611213684
Validation loss: 2.042195209892847

Epoch: 121| Step: 0
Training loss: 2.078209161758423
Validation loss: 1.9973115536474413

Epoch: 5| Step: 1
Training loss: 2.7444190979003906
Validation loss: 2.0023342242804905

Epoch: 5| Step: 2
Training loss: 2.1980137825012207
Validation loss: 2.002265825066515

Epoch: 5| Step: 3
Training loss: 2.4881300926208496
Validation loss: 2.019776782681865

Epoch: 5| Step: 4
Training loss: 1.5100393295288086
Validation loss: 2.046128603719896

Epoch: 5| Step: 5
Training loss: 2.4803683757781982
Validation loss: 2.048745011770597

Epoch: 5| Step: 6
Training loss: 2.41239595413208
Validation loss: 2.041534129009452

Epoch: 5| Step: 7
Training loss: 2.1138765811920166
Validation loss: 2.033215638129942

Epoch: 5| Step: 8
Training loss: 2.0252721309661865
Validation loss: 2.049490726122292

Epoch: 5| Step: 9
Training loss: 2.0095226764678955
Validation loss: 2.0392342459770942

Epoch: 5| Step: 10
Training loss: 2.978663206100464
Validation loss: 2.0538924381297123

Epoch: 122| Step: 0
Training loss: 1.8801944255828857
Validation loss: 2.048498520287134

Epoch: 5| Step: 1
Training loss: 2.4654011726379395
Validation loss: 2.067284935264177

Epoch: 5| Step: 2
Training loss: 2.2307167053222656
Validation loss: 2.0583347787139235

Epoch: 5| Step: 3
Training loss: 2.6604866981506348
Validation loss: 2.0438052774757467

Epoch: 5| Step: 4
Training loss: 2.4063544273376465
Validation loss: 2.04908311751581

Epoch: 5| Step: 5
Training loss: 2.3473293781280518
Validation loss: 2.0546092320513982

Epoch: 5| Step: 6
Training loss: 2.187926769256592
Validation loss: 2.0711066569051435

Epoch: 5| Step: 7
Training loss: 1.6894235610961914
Validation loss: 2.0733690364386446

Epoch: 5| Step: 8
Training loss: 2.3477611541748047
Validation loss: 2.0824374562950543

Epoch: 5| Step: 9
Training loss: 2.4344382286071777
Validation loss: 2.0671984739201044

Epoch: 5| Step: 10
Training loss: 2.189333438873291
Validation loss: 2.078642314480197

Epoch: 123| Step: 0
Training loss: 1.6922153234481812
Validation loss: 2.08353574814335

Epoch: 5| Step: 1
Training loss: 2.100996971130371
Validation loss: 2.074425179471252

Epoch: 5| Step: 2
Training loss: 2.9675581455230713
Validation loss: 2.0850404795779975

Epoch: 5| Step: 3
Training loss: 1.9617048501968384
Validation loss: 2.0672470203009983

Epoch: 5| Step: 4
Training loss: 2.666503429412842
Validation loss: 2.0734498936642884

Epoch: 5| Step: 5
Training loss: 2.0938191413879395
Validation loss: 2.0605917464020433

Epoch: 5| Step: 6
Training loss: 1.8697700500488281
Validation loss: 2.0549492464270642

Epoch: 5| Step: 7
Training loss: 2.2018561363220215
Validation loss: 2.0293332710061023

Epoch: 5| Step: 8
Training loss: 2.138943672180176
Validation loss: 2.027500872970909

Epoch: 5| Step: 9
Training loss: 2.157374858856201
Validation loss: 2.0191468449049097

Epoch: 5| Step: 10
Training loss: 2.773811101913452
Validation loss: 2.0042837614654214

Epoch: 124| Step: 0
Training loss: 2.6328492164611816
Validation loss: 1.994174039492043

Epoch: 5| Step: 1
Training loss: 1.9781593084335327
Validation loss: 1.9936063174278504

Epoch: 5| Step: 2
Training loss: 2.264540195465088
Validation loss: 1.9998515139343918

Epoch: 5| Step: 3
Training loss: 1.8087663650512695
Validation loss: 2.0099127241360244

Epoch: 5| Step: 4
Training loss: 2.6545419692993164
Validation loss: 2.024751856762876

Epoch: 5| Step: 5
Training loss: 2.3752574920654297
Validation loss: 2.0271336417044363

Epoch: 5| Step: 6
Training loss: 2.4950222969055176
Validation loss: 2.024694319694273

Epoch: 5| Step: 7
Training loss: 2.3546347618103027
Validation loss: 2.0151210036329044

Epoch: 5| Step: 8
Training loss: 2.1684608459472656
Validation loss: 2.0019178518684964

Epoch: 5| Step: 9
Training loss: 2.0067574977874756
Validation loss: 2.0053751981386574

Epoch: 5| Step: 10
Training loss: 1.872981071472168
Validation loss: 1.99595134745362

Epoch: 125| Step: 0
Training loss: 2.3120341300964355
Validation loss: 2.0015387458185994

Epoch: 5| Step: 1
Training loss: 2.3363213539123535
Validation loss: 2.011312283495421

Epoch: 5| Step: 2
Training loss: 2.418001174926758
Validation loss: 1.9876710804559852

Epoch: 5| Step: 3
Training loss: 2.0555436611175537
Validation loss: 1.983069799279654

Epoch: 5| Step: 4
Training loss: 2.3883614540100098
Validation loss: 1.97406143014149

Epoch: 5| Step: 5
Training loss: 2.0940849781036377
Validation loss: 1.9645362156693653

Epoch: 5| Step: 6
Training loss: 2.1822688579559326
Validation loss: 1.9657682282950288

Epoch: 5| Step: 7
Training loss: 1.9741302728652954
Validation loss: 1.9735020347820815

Epoch: 5| Step: 8
Training loss: 2.3776814937591553
Validation loss: 1.9745651765536236

Epoch: 5| Step: 9
Training loss: 2.31072998046875
Validation loss: 1.9739496195188133

Epoch: 5| Step: 10
Training loss: 2.307551622390747
Validation loss: 1.9937512028601863

Epoch: 126| Step: 0
Training loss: 1.594287633895874
Validation loss: 1.9994904456600067

Epoch: 5| Step: 1
Training loss: 1.8328964710235596
Validation loss: 2.0126140233009093

Epoch: 5| Step: 2
Training loss: 1.6344499588012695
Validation loss: 2.025620739947083

Epoch: 5| Step: 3
Training loss: 2.520660877227783
Validation loss: 2.0254698120137697

Epoch: 5| Step: 4
Training loss: 2.6209609508514404
Validation loss: 2.022180067595615

Epoch: 5| Step: 5
Training loss: 2.221684217453003
Validation loss: 2.0084709672517675

Epoch: 5| Step: 6
Training loss: 2.574554681777954
Validation loss: 2.018277839947772

Epoch: 5| Step: 7
Training loss: 2.545822858810425
Validation loss: 2.0473529318327546

Epoch: 5| Step: 8
Training loss: 2.6182427406311035
Validation loss: 2.0458629438954015

Epoch: 5| Step: 9
Training loss: 2.0972468852996826
Validation loss: 2.0418185521197576

Epoch: 5| Step: 10
Training loss: 2.224855899810791
Validation loss: 2.0358938940109743

Epoch: 127| Step: 0
Training loss: 2.253117084503174
Validation loss: 2.042861625712405

Epoch: 5| Step: 1
Training loss: 2.106227159500122
Validation loss: 2.0504988572930776

Epoch: 5| Step: 2
Training loss: 2.018277406692505
Validation loss: 2.0338536590658207

Epoch: 5| Step: 3
Training loss: 1.6248528957366943
Validation loss: 2.0253469341544696

Epoch: 5| Step: 4
Training loss: 2.467674732208252
Validation loss: 2.017892265832552

Epoch: 5| Step: 5
Training loss: 3.0448427200317383
Validation loss: 2.022605878050609

Epoch: 5| Step: 6
Training loss: 1.936322808265686
Validation loss: 2.0301248001795944

Epoch: 5| Step: 7
Training loss: 1.9939134120941162
Validation loss: 2.023545857398741

Epoch: 5| Step: 8
Training loss: 1.994951844215393
Validation loss: 2.029752944105415

Epoch: 5| Step: 9
Training loss: 2.281001567840576
Validation loss: 2.0314111184048396

Epoch: 5| Step: 10
Training loss: 2.5149316787719727
Validation loss: 2.0550281540040047

Epoch: 128| Step: 0
Training loss: 2.3810267448425293
Validation loss: 2.093678464171707

Epoch: 5| Step: 1
Training loss: 2.779175043106079
Validation loss: 2.108519264446792

Epoch: 5| Step: 2
Training loss: 1.9084453582763672
Validation loss: 2.089933472294961

Epoch: 5| Step: 3
Training loss: 1.9693816900253296
Validation loss: 2.0774881198842037

Epoch: 5| Step: 4
Training loss: 1.9003127813339233
Validation loss: 2.0647886555681945

Epoch: 5| Step: 5
Training loss: 2.7958645820617676
Validation loss: 2.064993900637473

Epoch: 5| Step: 6
Training loss: 1.9283549785614014
Validation loss: 2.0561945771658294

Epoch: 5| Step: 7
Training loss: 2.417257308959961
Validation loss: 2.0388428934158815

Epoch: 5| Step: 8
Training loss: 2.3186633586883545
Validation loss: 2.0280069663960445

Epoch: 5| Step: 9
Training loss: 2.33748459815979
Validation loss: 2.0323267957215667

Epoch: 5| Step: 10
Training loss: 2.088495969772339
Validation loss: 2.0071716180411716

Epoch: 129| Step: 0
Training loss: 2.0349955558776855
Validation loss: 1.9868579538919593

Epoch: 5| Step: 1
Training loss: 2.8011879920959473
Validation loss: 1.9883120008694228

Epoch: 5| Step: 2
Training loss: 2.6474759578704834
Validation loss: 2.0212627380124983

Epoch: 5| Step: 3
Training loss: 2.1846346855163574
Validation loss: 2.014989722159601

Epoch: 5| Step: 4
Training loss: 1.692556619644165
Validation loss: 2.015968668845392

Epoch: 5| Step: 5
Training loss: 1.764627456665039
Validation loss: 2.008870845199913

Epoch: 5| Step: 6
Training loss: 1.7967888116836548
Validation loss: 2.0010632314989643

Epoch: 5| Step: 7
Training loss: 2.0141615867614746
Validation loss: 2.0067477918440297

Epoch: 5| Step: 8
Training loss: 2.9784038066864014
Validation loss: 2.019809866464266

Epoch: 5| Step: 9
Training loss: 1.8420997858047485
Validation loss: 2.0491083104123353

Epoch: 5| Step: 10
Training loss: 2.4399361610412598
Validation loss: 2.0524231464632097

Epoch: 130| Step: 0
Training loss: 2.326061725616455
Validation loss: 2.0696258275739607

Epoch: 5| Step: 1
Training loss: 2.2131521701812744
Validation loss: 2.081425101526322

Epoch: 5| Step: 2
Training loss: 2.0054678916931152
Validation loss: 2.0735232381410498

Epoch: 5| Step: 3
Training loss: 2.2581353187561035
Validation loss: 2.065899982247301

Epoch: 5| Step: 4
Training loss: 2.2925314903259277
Validation loss: 2.0508769891595326

Epoch: 5| Step: 5
Training loss: 2.080885887145996
Validation loss: 2.0462779652687813

Epoch: 5| Step: 6
Training loss: 2.1841282844543457
Validation loss: 2.0421509050553843

Epoch: 5| Step: 7
Training loss: 2.2344603538513184
Validation loss: 2.0392351381240355

Epoch: 5| Step: 8
Training loss: 1.8545974493026733
Validation loss: 2.0302117511790287

Epoch: 5| Step: 9
Training loss: 1.9035041332244873
Validation loss: 2.020022156418011

Epoch: 5| Step: 10
Training loss: 2.7780325412750244
Validation loss: 2.0309712694537256

Epoch: 131| Step: 0
Training loss: 2.359494209289551
Validation loss: 2.0512317662597983

Epoch: 5| Step: 1
Training loss: 2.5022103786468506
Validation loss: 2.0680343412583873

Epoch: 5| Step: 2
Training loss: 2.455437183380127
Validation loss: 2.084084718458114

Epoch: 5| Step: 3
Training loss: 1.7546968460083008
Validation loss: 2.086371188522667

Epoch: 5| Step: 4
Training loss: 1.8927276134490967
Validation loss: 2.118097246334117

Epoch: 5| Step: 5
Training loss: 2.317650318145752
Validation loss: 2.1130840521986767

Epoch: 5| Step: 6
Training loss: 1.9863128662109375
Validation loss: 2.0893014425872476

Epoch: 5| Step: 7
Training loss: 1.8606243133544922
Validation loss: 2.099164124458067

Epoch: 5| Step: 8
Training loss: 2.1233317852020264
Validation loss: 2.0936118248970277

Epoch: 5| Step: 9
Training loss: 2.276359796524048
Validation loss: 2.0847844949332615

Epoch: 5| Step: 10
Training loss: 2.38712215423584
Validation loss: 2.060594415151945

Epoch: 132| Step: 0
Training loss: 1.9104903936386108
Validation loss: 2.064633313045707

Epoch: 5| Step: 1
Training loss: 2.287864923477173
Validation loss: 2.059578464877221

Epoch: 5| Step: 2
Training loss: 2.7982566356658936
Validation loss: 2.039889689414732

Epoch: 5| Step: 3
Training loss: 2.32570743560791
Validation loss: 2.0139529705047607

Epoch: 5| Step: 4
Training loss: 2.0831377506256104
Validation loss: 2.0043941825948735

Epoch: 5| Step: 5
Training loss: 1.6267715692520142
Validation loss: 2.001286114415815

Epoch: 5| Step: 6
Training loss: 1.9455360174179077
Validation loss: 2.019178205920804

Epoch: 5| Step: 7
Training loss: 2.003862142562866
Validation loss: 2.031851053237915

Epoch: 5| Step: 8
Training loss: 1.7124265432357788
Validation loss: 2.043252985964539

Epoch: 5| Step: 9
Training loss: 2.683366060256958
Validation loss: 2.0259486988026607

Epoch: 5| Step: 10
Training loss: 2.2285690307617188
Validation loss: 2.04463372179257

Epoch: 133| Step: 0
Training loss: 2.338531017303467
Validation loss: 2.0810433741538756

Epoch: 5| Step: 1
Training loss: 2.298311710357666
Validation loss: 2.05619240191675

Epoch: 5| Step: 2
Training loss: 2.0734260082244873
Validation loss: 2.0553987897852415

Epoch: 5| Step: 3
Training loss: 2.1079585552215576
Validation loss: 2.0365462110888575

Epoch: 5| Step: 4
Training loss: 2.091949224472046
Validation loss: 2.0252790220322145

Epoch: 5| Step: 5
Training loss: 2.117865800857544
Validation loss: 2.0423227125598538

Epoch: 5| Step: 6
Training loss: 2.005690336227417
Validation loss: 2.050370588097521

Epoch: 5| Step: 7
Training loss: 2.325477123260498
Validation loss: 2.052614108208687

Epoch: 5| Step: 8
Training loss: 1.818611741065979
Validation loss: 2.0429453901065293

Epoch: 5| Step: 9
Training loss: 2.4302356243133545
Validation loss: 2.054337388725691

Epoch: 5| Step: 10
Training loss: 2.0652108192443848
Validation loss: 2.062123837009553

Epoch: 134| Step: 0
Training loss: 2.1927599906921387
Validation loss: 2.0759028542426323

Epoch: 5| Step: 1
Training loss: 2.311203718185425
Validation loss: 2.102193272241982

Epoch: 5| Step: 2
Training loss: 1.801245093345642
Validation loss: 2.0918189094912623

Epoch: 5| Step: 3
Training loss: 2.234557628631592
Validation loss: 2.1121444240693124

Epoch: 5| Step: 4
Training loss: 2.400930404663086
Validation loss: 2.1000959334834928

Epoch: 5| Step: 5
Training loss: 1.9790064096450806
Validation loss: 2.1040309398405013

Epoch: 5| Step: 6
Training loss: 2.3378679752349854
Validation loss: 2.101760172074841

Epoch: 5| Step: 7
Training loss: 2.584834575653076
Validation loss: 2.0992260248430314

Epoch: 5| Step: 8
Training loss: 1.6713593006134033
Validation loss: 2.118888687062007

Epoch: 5| Step: 9
Training loss: 1.8948408365249634
Validation loss: 2.109524756349543

Epoch: 5| Step: 10
Training loss: 2.1589131355285645
Validation loss: 2.1109303095007457

Epoch: 135| Step: 0
Training loss: 2.5997986793518066
Validation loss: 2.1237343844547065

Epoch: 5| Step: 1
Training loss: 2.1609508991241455
Validation loss: 2.133797255895471

Epoch: 5| Step: 2
Training loss: 2.3560080528259277
Validation loss: 2.129163790774602

Epoch: 5| Step: 3
Training loss: 2.0047318935394287
Validation loss: 2.121713758796774

Epoch: 5| Step: 4
Training loss: 1.6722246408462524
Validation loss: 2.11563136500697

Epoch: 5| Step: 5
Training loss: 2.9888854026794434
Validation loss: 2.1270177159258115

Epoch: 5| Step: 6
Training loss: 1.4922564029693604
Validation loss: 2.101601731392645

Epoch: 5| Step: 7
Training loss: 1.8025951385498047
Validation loss: 2.084716411047084

Epoch: 5| Step: 8
Training loss: 2.090559482574463
Validation loss: 2.065171380196848

Epoch: 5| Step: 9
Training loss: 2.2667949199676514
Validation loss: 2.0586543749737483

Epoch: 5| Step: 10
Training loss: 2.265385866165161
Validation loss: 2.0315683887850855

Epoch: 136| Step: 0
Training loss: 1.9948527812957764
Validation loss: 2.0242311005951255

Epoch: 5| Step: 1
Training loss: 2.193422794342041
Validation loss: 2.03812131574077

Epoch: 5| Step: 2
Training loss: 2.3854198455810547
Validation loss: 2.0648795327832623

Epoch: 5| Step: 3
Training loss: 1.873431921005249
Validation loss: 2.1397347604074786

Epoch: 5| Step: 4
Training loss: 2.444819927215576
Validation loss: 2.144902511309552

Epoch: 5| Step: 5
Training loss: 2.043287515640259
Validation loss: 2.1569633227522655

Epoch: 5| Step: 6
Training loss: 2.064531087875366
Validation loss: 2.12999229533698

Epoch: 5| Step: 7
Training loss: 2.130159854888916
Validation loss: 2.062076917258642

Epoch: 5| Step: 8
Training loss: 2.090646505355835
Validation loss: 2.063838594703264

Epoch: 5| Step: 9
Training loss: 2.227431297302246
Validation loss: 2.072124710647009

Epoch: 5| Step: 10
Training loss: 2.069098949432373
Validation loss: 2.0866556949512933

Epoch: 137| Step: 0
Training loss: 1.999158263206482
Validation loss: 2.09666811009889

Epoch: 5| Step: 1
Training loss: 2.131931781768799
Validation loss: 2.088335426904822

Epoch: 5| Step: 2
Training loss: 2.105698347091675
Validation loss: 2.0865567922592163

Epoch: 5| Step: 3
Training loss: 2.1029140949249268
Validation loss: 2.0732598535476194

Epoch: 5| Step: 4
Training loss: 2.08374285697937
Validation loss: 2.0528520384142475

Epoch: 5| Step: 5
Training loss: 1.8628755807876587
Validation loss: 2.0607503742300053

Epoch: 5| Step: 6
Training loss: 2.4195475578308105
Validation loss: 2.066618452789963

Epoch: 5| Step: 7
Training loss: 2.231748104095459
Validation loss: 2.089494505236226

Epoch: 5| Step: 8
Training loss: 1.5337255001068115
Validation loss: 2.1340156729503343

Epoch: 5| Step: 9
Training loss: 2.3173704147338867
Validation loss: 2.163865925163351

Epoch: 5| Step: 10
Training loss: 2.7292308807373047
Validation loss: 2.1800044685281734

Epoch: 138| Step: 0
Training loss: 2.1001083850860596
Validation loss: 2.188077803580992

Epoch: 5| Step: 1
Training loss: 1.7647044658660889
Validation loss: 2.1712367073182137

Epoch: 5| Step: 2
Training loss: 1.9381805658340454
Validation loss: 2.147663633028666

Epoch: 5| Step: 3
Training loss: 1.852071762084961
Validation loss: 2.1336602293035036

Epoch: 5| Step: 4
Training loss: 1.9108387231826782
Validation loss: 2.143644684104509

Epoch: 5| Step: 5
Training loss: 2.424320936203003
Validation loss: 2.1273239056269326

Epoch: 5| Step: 6
Training loss: 2.562958240509033
Validation loss: 2.129593550517995

Epoch: 5| Step: 7
Training loss: 1.8171058893203735
Validation loss: 2.1405483727814048

Epoch: 5| Step: 8
Training loss: 2.3586535453796387
Validation loss: 2.139631668726603

Epoch: 5| Step: 9
Training loss: 2.2686827182769775
Validation loss: 2.1021886846070648

Epoch: 5| Step: 10
Training loss: 2.5962307453155518
Validation loss: 2.085488224542269

Epoch: 139| Step: 0
Training loss: 2.305236339569092
Validation loss: 2.073726346415858

Epoch: 5| Step: 1
Training loss: 1.605329155921936
Validation loss: 2.0273383099545716

Epoch: 5| Step: 2
Training loss: 2.4375085830688477
Validation loss: 2.028599021255329

Epoch: 5| Step: 3
Training loss: 2.1298203468322754
Validation loss: 2.066645569698785

Epoch: 5| Step: 4
Training loss: 2.104576587677002
Validation loss: 2.093678858972365

Epoch: 5| Step: 5
Training loss: 2.0793039798736572
Validation loss: 2.105125742573892

Epoch: 5| Step: 6
Training loss: 2.0481832027435303
Validation loss: 2.092012846341697

Epoch: 5| Step: 7
Training loss: 2.0089211463928223
Validation loss: 2.062470169477565

Epoch: 5| Step: 8
Training loss: 2.565917491912842
Validation loss: 2.049559061245252

Epoch: 5| Step: 9
Training loss: 2.268784284591675
Validation loss: 2.023646479011864

Epoch: 5| Step: 10
Training loss: 1.8282901048660278
Validation loss: 2.0358649505082

Epoch: 140| Step: 0
Training loss: 2.0474438667297363
Validation loss: 2.0365478684825282

Epoch: 5| Step: 1
Training loss: 2.3623580932617188
Validation loss: 2.0481114746421896

Epoch: 5| Step: 2
Training loss: 1.9087194204330444
Validation loss: 2.076514362007059

Epoch: 5| Step: 3
Training loss: 2.03647780418396
Validation loss: 2.0980828936382006

Epoch: 5| Step: 4
Training loss: 1.714033842086792
Validation loss: 2.1458292315083165

Epoch: 5| Step: 5
Training loss: 1.857415795326233
Validation loss: 2.2100882632758028

Epoch: 5| Step: 6
Training loss: 2.806791305541992
Validation loss: 2.282136986332555

Epoch: 5| Step: 7
Training loss: 2.183800220489502
Validation loss: 2.291871222116614

Epoch: 5| Step: 8
Training loss: 2.4929680824279785
Validation loss: 2.241288406874544

Epoch: 5| Step: 9
Training loss: 2.391343116760254
Validation loss: 2.1843109746133127

Epoch: 5| Step: 10
Training loss: 2.378598928451538
Validation loss: 2.1157865088473082

Epoch: 141| Step: 0
Training loss: 1.5712894201278687
Validation loss: 2.058988173802694

Epoch: 5| Step: 1
Training loss: 2.54709529876709
Validation loss: 2.046322916143684

Epoch: 5| Step: 2
Training loss: 2.419799327850342
Validation loss: 2.0461345718752955

Epoch: 5| Step: 3
Training loss: 2.528669834136963
Validation loss: 2.0654413687285555

Epoch: 5| Step: 4
Training loss: 2.082252264022827
Validation loss: 2.0999510313874934

Epoch: 5| Step: 5
Training loss: 1.8584086894989014
Validation loss: 2.0922197141954975

Epoch: 5| Step: 6
Training loss: 2.583679437637329
Validation loss: 2.051942015206942

Epoch: 5| Step: 7
Training loss: 1.8253142833709717
Validation loss: 2.0040365995899325

Epoch: 5| Step: 8
Training loss: 2.474411964416504
Validation loss: 1.9718045906354023

Epoch: 5| Step: 9
Training loss: 1.856370210647583
Validation loss: 1.9588022411510508

Epoch: 5| Step: 10
Training loss: 2.2884914875030518
Validation loss: 1.9884681650387344

Epoch: 142| Step: 0
Training loss: 1.8894567489624023
Validation loss: 2.0510437591101534

Epoch: 5| Step: 1
Training loss: 2.1722350120544434
Validation loss: 2.149896179476092

Epoch: 5| Step: 2
Training loss: 2.1079440116882324
Validation loss: 2.1823234481196248

Epoch: 5| Step: 3
Training loss: 3.1441235542297363
Validation loss: 2.1403125460429857

Epoch: 5| Step: 4
Training loss: 2.3060965538024902
Validation loss: 2.1421100734382548

Epoch: 5| Step: 5
Training loss: 2.3956315517425537
Validation loss: 2.136569989624844

Epoch: 5| Step: 6
Training loss: 2.3121228218078613
Validation loss: 2.141483999067737

Epoch: 5| Step: 7
Training loss: 2.1631927490234375
Validation loss: 2.1071386593644337

Epoch: 5| Step: 8
Training loss: 1.470310091972351
Validation loss: 2.080204749620089

Epoch: 5| Step: 9
Training loss: 2.3681650161743164
Validation loss: 2.082536751224149

Epoch: 5| Step: 10
Training loss: 1.8912358283996582
Validation loss: 2.154725429832294

Epoch: 143| Step: 0
Training loss: 2.6380810737609863
Validation loss: 2.1907061863971014

Epoch: 5| Step: 1
Training loss: 2.6966586112976074
Validation loss: 2.1700170155494445

Epoch: 5| Step: 2
Training loss: 3.5046913623809814
Validation loss: 2.1192716039637083

Epoch: 5| Step: 3
Training loss: 2.4647133350372314
Validation loss: 2.0596258512107273

Epoch: 5| Step: 4
Training loss: 1.616843819618225
Validation loss: 2.0297571869306665

Epoch: 5| Step: 5
Training loss: 2.3117263317108154
Validation loss: 2.0311297114177416

Epoch: 5| Step: 6
Training loss: 2.053347587585449
Validation loss: 2.046233046439386

Epoch: 5| Step: 7
Training loss: 1.6252200603485107
Validation loss: 2.0884616451878704

Epoch: 5| Step: 8
Training loss: 1.2004178762435913
Validation loss: 2.1426405701585995

Epoch: 5| Step: 9
Training loss: 1.3651487827301025
Validation loss: 2.1988818325022215

Epoch: 5| Step: 10
Training loss: 2.273635149002075
Validation loss: 2.2086623253360873

Epoch: 144| Step: 0
Training loss: 1.6678783893585205
Validation loss: 2.1119106777252687

Epoch: 5| Step: 1
Training loss: 2.304917097091675
Validation loss: 2.0756720060943277

Epoch: 5| Step: 2
Training loss: 2.6594510078430176
Validation loss: 2.077081570061304

Epoch: 5| Step: 3
Training loss: 2.079349994659424
Validation loss: 2.06249774015078

Epoch: 5| Step: 4
Training loss: 2.471635103225708
Validation loss: 2.084974527359009

Epoch: 5| Step: 5
Training loss: 1.8976714611053467
Validation loss: 2.0757510982533938

Epoch: 5| Step: 6
Training loss: 2.0061631202697754
Validation loss: 2.067834859253258

Epoch: 5| Step: 7
Training loss: 1.3984549045562744
Validation loss: 2.0667146431502474

Epoch: 5| Step: 8
Training loss: 1.9444854259490967
Validation loss: 2.0891048985142864

Epoch: 5| Step: 9
Training loss: 2.482309341430664
Validation loss: 2.0973148089583202

Epoch: 5| Step: 10
Training loss: 1.9596593379974365
Validation loss: 2.1208335161209106

Epoch: 145| Step: 0
Training loss: 1.9201786518096924
Validation loss: 2.1189331598179315

Epoch: 5| Step: 1
Training loss: 1.5905678272247314
Validation loss: 2.101984011229648

Epoch: 5| Step: 2
Training loss: 2.5030148029327393
Validation loss: 2.1011022265239427

Epoch: 5| Step: 3
Training loss: 2.8623147010803223
Validation loss: 2.114489419485933

Epoch: 5| Step: 4
Training loss: 1.772414207458496
Validation loss: 2.1057293799615677

Epoch: 5| Step: 5
Training loss: 2.1354949474334717
Validation loss: 2.1161769026069233

Epoch: 5| Step: 6
Training loss: 2.0165364742279053
Validation loss: 2.1196146524080666

Epoch: 5| Step: 7
Training loss: 2.468144178390503
Validation loss: 2.123909763110581

Epoch: 5| Step: 8
Training loss: 1.6171096563339233
Validation loss: 2.117837075264223

Epoch: 5| Step: 9
Training loss: 1.8191837072372437
Validation loss: 2.140058599492555

Epoch: 5| Step: 10
Training loss: 1.9251813888549805
Validation loss: 2.1393613200033865

Epoch: 146| Step: 0
Training loss: 2.1797776222229004
Validation loss: 2.1394918939118743

Epoch: 5| Step: 1
Training loss: 1.3639119863510132
Validation loss: 2.149520927859891

Epoch: 5| Step: 2
Training loss: 1.861808180809021
Validation loss: 2.126237923099149

Epoch: 5| Step: 3
Training loss: 2.1686744689941406
Validation loss: 2.097960146524573

Epoch: 5| Step: 4
Training loss: 2.286482095718384
Validation loss: 2.066126109451376

Epoch: 5| Step: 5
Training loss: 1.701412558555603
Validation loss: 2.0489086797160487

Epoch: 5| Step: 6
Training loss: 1.8317480087280273
Validation loss: 2.039948067357463

Epoch: 5| Step: 7
Training loss: 2.277543544769287
Validation loss: 2.0326364117283977

Epoch: 5| Step: 8
Training loss: 2.2107510566711426
Validation loss: 2.0119961256621988

Epoch: 5| Step: 9
Training loss: 2.3816559314727783
Validation loss: 2.022395307017911

Epoch: 5| Step: 10
Training loss: 2.4624786376953125
Validation loss: 2.034549343970514

Epoch: 147| Step: 0
Training loss: 1.8823521137237549
Validation loss: 2.0435556903962167

Epoch: 5| Step: 1
Training loss: 2.1640191078186035
Validation loss: 2.05978714266131

Epoch: 5| Step: 2
Training loss: 2.184504985809326
Validation loss: 2.0741113129482476

Epoch: 5| Step: 3
Training loss: 2.3745388984680176
Validation loss: 2.0934660255268054

Epoch: 5| Step: 4
Training loss: 2.1011338233947754
Validation loss: 2.105613684141508

Epoch: 5| Step: 5
Training loss: 1.857021689414978
Validation loss: 2.0887504264872563

Epoch: 5| Step: 6
Training loss: 2.7879183292388916
Validation loss: 2.0818669975444837

Epoch: 5| Step: 7
Training loss: 1.4907572269439697
Validation loss: 2.064228029661281

Epoch: 5| Step: 8
Training loss: 2.162421703338623
Validation loss: 2.0569158061858146

Epoch: 5| Step: 9
Training loss: 1.7830970287322998
Validation loss: 2.0500571163751746

Epoch: 5| Step: 10
Training loss: 1.5651664733886719
Validation loss: 2.0643028520768687

Epoch: 148| Step: 0
Training loss: 2.1843433380126953
Validation loss: 2.055649220302541

Epoch: 5| Step: 1
Training loss: 1.7067298889160156
Validation loss: 2.076930023008777

Epoch: 5| Step: 2
Training loss: 2.127654552459717
Validation loss: 2.10140621918504

Epoch: 5| Step: 3
Training loss: 1.8885152339935303
Validation loss: 2.1057378015210553

Epoch: 5| Step: 4
Training loss: 1.7013130187988281
Validation loss: 2.128243007967549

Epoch: 5| Step: 5
Training loss: 2.459244966506958
Validation loss: 2.12933014797908

Epoch: 5| Step: 6
Training loss: 1.9764724969863892
Validation loss: 2.1013896388392292

Epoch: 5| Step: 7
Training loss: 2.178772449493408
Validation loss: 2.080252593563449

Epoch: 5| Step: 8
Training loss: 1.905543327331543
Validation loss: 2.0679134412478377

Epoch: 5| Step: 9
Training loss: 2.084118604660034
Validation loss: 2.0659698773455877

Epoch: 5| Step: 10
Training loss: 1.8380277156829834
Validation loss: 2.068885813477219

Epoch: 149| Step: 0
Training loss: 2.424306869506836
Validation loss: 2.0545198212387743

Epoch: 5| Step: 1
Training loss: 1.6298573017120361
Validation loss: 2.071748432292733

Epoch: 5| Step: 2
Training loss: 1.9067192077636719
Validation loss: 2.1013273526263494

Epoch: 5| Step: 3
Training loss: 1.9674965143203735
Validation loss: 2.1340708988969044

Epoch: 5| Step: 4
Training loss: 1.6876871585845947
Validation loss: 2.1530736774526615

Epoch: 5| Step: 5
Training loss: 2.174478530883789
Validation loss: 2.164739360091507

Epoch: 5| Step: 6
Training loss: 2.4396114349365234
Validation loss: 2.1674667660908034

Epoch: 5| Step: 7
Training loss: 2.0651941299438477
Validation loss: 2.131788002547397

Epoch: 5| Step: 8
Training loss: 2.2269554138183594
Validation loss: 2.099487348269391

Epoch: 5| Step: 9
Training loss: 2.039358139038086
Validation loss: 2.0632146302089898

Epoch: 5| Step: 10
Training loss: 1.7232699394226074
Validation loss: 2.041533026643979

Epoch: 150| Step: 0
Training loss: 1.9572885036468506
Validation loss: 2.0091480298708846

Epoch: 5| Step: 1
Training loss: 2.146493434906006
Validation loss: 1.9854699347608833

Epoch: 5| Step: 2
Training loss: 2.020688533782959
Validation loss: 1.966737337009881

Epoch: 5| Step: 3
Training loss: 2.6382803916931152
Validation loss: 1.9644403367914178

Epoch: 5| Step: 4
Training loss: 1.924644112586975
Validation loss: 1.9563951441036758

Epoch: 5| Step: 5
Training loss: 2.3956995010375977
Validation loss: 1.9377094776399675

Epoch: 5| Step: 6
Training loss: 2.718198776245117
Validation loss: 1.9241243729027369

Epoch: 5| Step: 7
Training loss: 2.000916004180908
Validation loss: 1.9221659168120353

Epoch: 5| Step: 8
Training loss: 1.1738389730453491
Validation loss: 1.9228682184732089

Epoch: 5| Step: 9
Training loss: 2.04970645904541
Validation loss: 1.9292960910386936

Epoch: 5| Step: 10
Training loss: 2.112013816833496
Validation loss: 1.9285906335358978

Epoch: 151| Step: 0
Training loss: 2.2811896800994873
Validation loss: 1.9270216880306121

Epoch: 5| Step: 1
Training loss: 1.650292992591858
Validation loss: 1.9328400563168269

Epoch: 5| Step: 2
Training loss: 1.68129563331604
Validation loss: 1.9489001227963356

Epoch: 5| Step: 3
Training loss: 1.6365588903427124
Validation loss: 1.9390154730889104

Epoch: 5| Step: 4
Training loss: 1.924863576889038
Validation loss: 1.9437478306472942

Epoch: 5| Step: 5
Training loss: 2.273871660232544
Validation loss: 1.996271094968242

Epoch: 5| Step: 6
Training loss: 3.1628642082214355
Validation loss: 2.0247676449437297

Epoch: 5| Step: 7
Training loss: 2.611661434173584
Validation loss: 2.068155957806495

Epoch: 5| Step: 8
Training loss: 1.724896788597107
Validation loss: 2.090718520584927

Epoch: 5| Step: 9
Training loss: 0.9858590960502625
Validation loss: 2.105545484891502

Epoch: 5| Step: 10
Training loss: 2.2717466354370117
Validation loss: 2.0985730489095054

Epoch: 152| Step: 0
Training loss: 2.104046583175659
Validation loss: 2.095250975701117

Epoch: 5| Step: 1
Training loss: 1.8557960987091064
Validation loss: 2.099798458878712

Epoch: 5| Step: 2
Training loss: 1.9122613668441772
Validation loss: 2.111028109827349

Epoch: 5| Step: 3
Training loss: 2.286991596221924
Validation loss: 2.089705072423463

Epoch: 5| Step: 4
Training loss: 2.0275919437408447
Validation loss: 2.0845805111751763

Epoch: 5| Step: 5
Training loss: 2.502793073654175
Validation loss: 2.085025323334561

Epoch: 5| Step: 6
Training loss: 1.8944753408432007
Validation loss: 2.0825735292127057

Epoch: 5| Step: 7
Training loss: 1.7734565734863281
Validation loss: 2.082298855627737

Epoch: 5| Step: 8
Training loss: 1.9627689123153687
Validation loss: 2.08920407167045

Epoch: 5| Step: 9
Training loss: 1.8710956573486328
Validation loss: 2.087479873370099

Epoch: 5| Step: 10
Training loss: 1.398207187652588
Validation loss: 2.1071731736583095

Epoch: 153| Step: 0
Training loss: 2.2172770500183105
Validation loss: 2.11282229551705

Epoch: 5| Step: 1
Training loss: 1.8737070560455322
Validation loss: 2.143349855176864

Epoch: 5| Step: 2
Training loss: 1.9948208332061768
Validation loss: 2.1314633238700127

Epoch: 5| Step: 3
Training loss: 2.173184871673584
Validation loss: 2.1424656670580626

Epoch: 5| Step: 4
Training loss: 1.990181565284729
Validation loss: 2.099864472625076

Epoch: 5| Step: 5
Training loss: 1.6451966762542725
Validation loss: 2.0657356900553547

Epoch: 5| Step: 6
Training loss: 2.095684766769409
Validation loss: 2.026726679135394

Epoch: 5| Step: 7
Training loss: 2.068308115005493
Validation loss: 1.9848193225040232

Epoch: 5| Step: 8
Training loss: 1.5254429578781128
Validation loss: 2.0023356381283013

Epoch: 5| Step: 9
Training loss: 2.1821470260620117
Validation loss: 2.017381916763962

Epoch: 5| Step: 10
Training loss: 2.1431283950805664
Validation loss: 1.9991895639768211

Epoch: 154| Step: 0
Training loss: 2.1785733699798584
Validation loss: 1.992270218428745

Epoch: 5| Step: 1
Training loss: 1.8720805644989014
Validation loss: 1.99313231437437

Epoch: 5| Step: 2
Training loss: 1.9782378673553467
Validation loss: 1.9993536421047744

Epoch: 5| Step: 3
Training loss: 1.9039595127105713
Validation loss: 2.0034725922410206

Epoch: 5| Step: 4
Training loss: 1.7366113662719727
Validation loss: 2.024465166112428

Epoch: 5| Step: 5
Training loss: 1.7045819759368896
Validation loss: 2.0262167402493056

Epoch: 5| Step: 6
Training loss: 1.9800723791122437
Validation loss: 2.061078817613663

Epoch: 5| Step: 7
Training loss: 2.1468098163604736
Validation loss: 2.107880110381752

Epoch: 5| Step: 8
Training loss: 2.284302234649658
Validation loss: 2.1664512439440657

Epoch: 5| Step: 9
Training loss: 1.5550658702850342
Validation loss: 2.1837973697211153

Epoch: 5| Step: 10
Training loss: 2.5372488498687744
Validation loss: 2.14925838798605

Epoch: 155| Step: 0
Training loss: 1.7775741815567017
Validation loss: 2.132500607480285

Epoch: 5| Step: 1
Training loss: 1.662949800491333
Validation loss: 2.1133101601754465

Epoch: 5| Step: 2
Training loss: 2.1628451347351074
Validation loss: 2.0975879161588606

Epoch: 5| Step: 3
Training loss: 1.8402354717254639
Validation loss: 2.095197921158165

Epoch: 5| Step: 4
Training loss: 1.7242625951766968
Validation loss: 2.0956776680484897

Epoch: 5| Step: 5
Training loss: 1.9702584743499756
Validation loss: 2.1083452342658915

Epoch: 5| Step: 6
Training loss: 2.0816378593444824
Validation loss: 2.1173135567736883

Epoch: 5| Step: 7
Training loss: 2.081594944000244
Validation loss: 2.118925280468438

Epoch: 5| Step: 8
Training loss: 2.3266005516052246
Validation loss: 2.132184649026522

Epoch: 5| Step: 9
Training loss: 1.639405608177185
Validation loss: 2.1376931205872567

Epoch: 5| Step: 10
Training loss: 2.1064274311065674
Validation loss: 2.1214835387404247

Epoch: 156| Step: 0
Training loss: 2.1051270961761475
Validation loss: 2.0921775576888875

Epoch: 5| Step: 1
Training loss: 1.7879562377929688
Validation loss: 2.069840810632193

Epoch: 5| Step: 2
Training loss: 1.9553836584091187
Validation loss: 2.02985869684527

Epoch: 5| Step: 3
Training loss: 1.7054275274276733
Validation loss: 2.021336832354146

Epoch: 5| Step: 4
Training loss: 2.1708590984344482
Validation loss: 2.0112115516457507

Epoch: 5| Step: 5
Training loss: 1.9659782648086548
Validation loss: 2.0049244332057174

Epoch: 5| Step: 6
Training loss: 2.392054319381714
Validation loss: 2.0126250136283135

Epoch: 5| Step: 7
Training loss: 1.4224493503570557
Validation loss: 2.0246037821615896

Epoch: 5| Step: 8
Training loss: 2.08390474319458
Validation loss: 2.029035278545913

Epoch: 5| Step: 9
Training loss: 1.7917674779891968
Validation loss: 2.0501124794765184

Epoch: 5| Step: 10
Training loss: 1.7672537565231323
Validation loss: 2.0691741538304154

Epoch: 157| Step: 0
Training loss: 2.309925079345703
Validation loss: 2.098597498350246

Epoch: 5| Step: 1
Training loss: 1.240696907043457
Validation loss: 2.1103733765181674

Epoch: 5| Step: 2
Training loss: 1.8126798868179321
Validation loss: 2.141368889039563

Epoch: 5| Step: 3
Training loss: 2.201416015625
Validation loss: 2.147136028094958

Epoch: 5| Step: 4
Training loss: 1.9761203527450562
Validation loss: 2.166587321988998

Epoch: 5| Step: 5
Training loss: 1.6484369039535522
Validation loss: 2.155083912675099

Epoch: 5| Step: 6
Training loss: 1.9386574029922485
Validation loss: 2.1579863294478385

Epoch: 5| Step: 7
Training loss: 1.9689342975616455
Validation loss: 2.1399691309980167

Epoch: 5| Step: 8
Training loss: 1.9360198974609375
Validation loss: 2.1257321962746243

Epoch: 5| Step: 9
Training loss: 2.2139556407928467
Validation loss: 2.086017544551562

Epoch: 5| Step: 10
Training loss: 1.893774151802063
Validation loss: 2.0721139677109255

Epoch: 158| Step: 0
Training loss: 1.6698490381240845
Validation loss: 2.07268403678812

Epoch: 5| Step: 1
Training loss: 2.034928798675537
Validation loss: 2.0753055695564515

Epoch: 5| Step: 2
Training loss: 2.0779531002044678
Validation loss: 2.065596486932488

Epoch: 5| Step: 3
Training loss: 1.9637489318847656
Validation loss: 2.0659498604395057

Epoch: 5| Step: 4
Training loss: 1.8072354793548584
Validation loss: 2.0586370806540213

Epoch: 5| Step: 5
Training loss: 2.165151596069336
Validation loss: 2.046826934301725

Epoch: 5| Step: 6
Training loss: 1.6465063095092773
Validation loss: 2.0475804831392024

Epoch: 5| Step: 7
Training loss: 1.5803401470184326
Validation loss: 2.027582731298221

Epoch: 5| Step: 8
Training loss: 2.389843702316284
Validation loss: 2.0159859247105096

Epoch: 5| Step: 9
Training loss: 1.8823124170303345
Validation loss: 2.0152719302843978

Epoch: 5| Step: 10
Training loss: 1.6387600898742676
Validation loss: 2.026971055615333

Epoch: 159| Step: 0
Training loss: 1.7618240118026733
Validation loss: 2.025334723534123

Epoch: 5| Step: 1
Training loss: 1.829323410987854
Validation loss: 2.042647202809652

Epoch: 5| Step: 2
Training loss: 2.327240467071533
Validation loss: 2.100906418215844

Epoch: 5| Step: 3
Training loss: 1.5466012954711914
Validation loss: 2.081339748956824

Epoch: 5| Step: 4
Training loss: 2.186027765274048
Validation loss: 2.0548843965735486

Epoch: 5| Step: 5
Training loss: 2.6746745109558105
Validation loss: 2.0563766520510436

Epoch: 5| Step: 6
Training loss: 1.5716733932495117
Validation loss: 2.042651302071028

Epoch: 5| Step: 7
Training loss: 1.6840317249298096
Validation loss: 2.0477760145741124

Epoch: 5| Step: 8
Training loss: 2.031804084777832
Validation loss: 2.0538357893625894

Epoch: 5| Step: 9
Training loss: 1.771092176437378
Validation loss: 2.035414767521684

Epoch: 5| Step: 10
Training loss: 0.9882691502571106
Validation loss: 2.0497791818393174

Epoch: 160| Step: 0
Training loss: 1.996019721031189
Validation loss: 2.068004440235835

Epoch: 5| Step: 1
Training loss: 1.8076932430267334
Validation loss: 2.0487058713871944

Epoch: 5| Step: 2
Training loss: 1.5979411602020264
Validation loss: 2.037797402310115

Epoch: 5| Step: 3
Training loss: 1.6401445865631104
Validation loss: 2.0340036320429977

Epoch: 5| Step: 4
Training loss: 2.0857017040252686
Validation loss: 2.0307052391831593

Epoch: 5| Step: 5
Training loss: 1.8815685510635376
Validation loss: 2.0435719002959547

Epoch: 5| Step: 6
Training loss: 1.8429603576660156
Validation loss: 2.0433114651710755

Epoch: 5| Step: 7
Training loss: 2.4241058826446533
Validation loss: 2.073432542944467

Epoch: 5| Step: 8
Training loss: 1.9402143955230713
Validation loss: 2.047181696020147

Epoch: 5| Step: 9
Training loss: 1.7157615423202515
Validation loss: 2.0356160338206957

Epoch: 5| Step: 10
Training loss: 1.5805609226226807
Validation loss: 2.031517549227643

Epoch: 161| Step: 0
Training loss: 1.5181936025619507
Validation loss: 2.0383599958112164

Epoch: 5| Step: 1
Training loss: 1.827294111251831
Validation loss: 2.0466361097110215

Epoch: 5| Step: 2
Training loss: 1.9979524612426758
Validation loss: 2.0773139358848653

Epoch: 5| Step: 3
Training loss: 1.9025243520736694
Validation loss: 2.116235352331592

Epoch: 5| Step: 4
Training loss: 2.0157711505889893
Validation loss: 2.1535579889051375

Epoch: 5| Step: 5
Training loss: 1.6243765354156494
Validation loss: 2.1227874807132188

Epoch: 5| Step: 6
Training loss: 2.462581157684326
Validation loss: 2.101110137918944

Epoch: 5| Step: 7
Training loss: 1.6490938663482666
Validation loss: 2.093519846598307

Epoch: 5| Step: 8
Training loss: 1.116617202758789
Validation loss: 2.0473670395471717

Epoch: 5| Step: 9
Training loss: 2.48401141166687
Validation loss: 2.0520965527462702

Epoch: 5| Step: 10
Training loss: 2.105325698852539
Validation loss: 2.0632914907188824

Epoch: 162| Step: 0
Training loss: 1.8658937215805054
Validation loss: 2.0727491506966214

Epoch: 5| Step: 1
Training loss: 2.1459031105041504
Validation loss: 2.0948943245795464

Epoch: 5| Step: 2
Training loss: 2.3571438789367676
Validation loss: 2.13754270410025

Epoch: 5| Step: 3
Training loss: 1.7666171789169312
Validation loss: 2.1673941458425214

Epoch: 5| Step: 4
Training loss: 1.5453715324401855
Validation loss: 2.2431255155994045

Epoch: 5| Step: 5
Training loss: 2.249535083770752
Validation loss: 2.214731982959214

Epoch: 5| Step: 6
Training loss: 1.9828729629516602
Validation loss: 2.1730336348215737

Epoch: 5| Step: 7
Training loss: 1.7307100296020508
Validation loss: 2.1166447977865896

Epoch: 5| Step: 8
Training loss: 1.4615318775177002
Validation loss: 2.064533620752314

Epoch: 5| Step: 9
Training loss: 1.7869163751602173
Validation loss: 2.028781129467872

Epoch: 5| Step: 10
Training loss: 1.8755099773406982
Validation loss: 2.015751484901674

Epoch: 163| Step: 0
Training loss: 1.658177137374878
Validation loss: 2.009026570986676

Epoch: 5| Step: 1
Training loss: 2.161449432373047
Validation loss: 2.0194610357284546

Epoch: 5| Step: 2
Training loss: 2.222273826599121
Validation loss: 2.002692158504199

Epoch: 5| Step: 3
Training loss: 2.395301580429077
Validation loss: 2.01248828570048

Epoch: 5| Step: 4
Training loss: 1.9198353290557861
Validation loss: 1.9830786130761588

Epoch: 5| Step: 5
Training loss: 1.5823850631713867
Validation loss: 1.982889639433994

Epoch: 5| Step: 6
Training loss: 1.888185739517212
Validation loss: 1.9962118364149524

Epoch: 5| Step: 7
Training loss: 1.6038751602172852
Validation loss: 2.018289822404103

Epoch: 5| Step: 8
Training loss: 1.495642066001892
Validation loss: 2.02358922138009

Epoch: 5| Step: 9
Training loss: 2.0709481239318848
Validation loss: 2.0092967056458995

Epoch: 5| Step: 10
Training loss: 1.5901687145233154
Validation loss: 1.9848194827315628

Epoch: 164| Step: 0
Training loss: 1.9943809509277344
Validation loss: 1.9987177079723728

Epoch: 5| Step: 1
Training loss: 2.213561534881592
Validation loss: 2.018383172250563

Epoch: 5| Step: 2
Training loss: 1.5195684432983398
Validation loss: 2.033830997764423

Epoch: 5| Step: 3
Training loss: 1.841468095779419
Validation loss: 2.0656307666532454

Epoch: 5| Step: 4
Training loss: 1.4560288190841675
Validation loss: 2.0858264277058263

Epoch: 5| Step: 5
Training loss: 1.9697872400283813
Validation loss: 2.121222496032715

Epoch: 5| Step: 6
Training loss: 1.6553157567977905
Validation loss: 2.125624748968309

Epoch: 5| Step: 7
Training loss: 1.0260305404663086
Validation loss: 2.1149810065505323

Epoch: 5| Step: 8
Training loss: 2.2927405834198
Validation loss: 2.113698785023023

Epoch: 5| Step: 9
Training loss: 2.3113129138946533
Validation loss: 2.080466902384194

Epoch: 5| Step: 10
Training loss: 1.818893551826477
Validation loss: 2.0447802697458575

Epoch: 165| Step: 0
Training loss: 2.156374454498291
Validation loss: 2.018706721644248

Epoch: 5| Step: 1
Training loss: 2.284261703491211
Validation loss: 2.008429296555058

Epoch: 5| Step: 2
Training loss: 1.7923635244369507
Validation loss: 1.9812399738578386

Epoch: 5| Step: 3
Training loss: 2.0842771530151367
Validation loss: 1.9883368220380557

Epoch: 5| Step: 4
Training loss: 1.2301868200302124
Validation loss: 1.9878855007950977

Epoch: 5| Step: 5
Training loss: 1.500431776046753
Validation loss: 1.9943431449192826

Epoch: 5| Step: 6
Training loss: 1.866093397140503
Validation loss: 2.004471819887879

Epoch: 5| Step: 7
Training loss: 1.8416694402694702
Validation loss: 2.0061129293134137

Epoch: 5| Step: 8
Training loss: 1.56832754611969
Validation loss: 2.0293333094607116

Epoch: 5| Step: 9
Training loss: 1.6219213008880615
Validation loss: 2.0511453779794837

Epoch: 5| Step: 10
Training loss: 2.015681505203247
Validation loss: 2.1024583385836695

Epoch: 166| Step: 0
Training loss: 1.1507097482681274
Validation loss: 2.0991752814221125

Epoch: 5| Step: 1
Training loss: 2.5508177280426025
Validation loss: 2.0777035246613207

Epoch: 5| Step: 2
Training loss: 1.4178093671798706
Validation loss: 2.0282593286165627

Epoch: 5| Step: 3
Training loss: 1.6656644344329834
Validation loss: 2.031209716232874

Epoch: 5| Step: 4
Training loss: 2.028085708618164
Validation loss: 2.0549968801518923

Epoch: 5| Step: 5
Training loss: 1.9293806552886963
Validation loss: 2.0823761468292563

Epoch: 5| Step: 6
Training loss: 1.8888260126113892
Validation loss: 2.091929244738753

Epoch: 5| Step: 7
Training loss: 2.163222551345825
Validation loss: 2.116889469085201

Epoch: 5| Step: 8
Training loss: 2.409334897994995
Validation loss: 2.134016562533635

Epoch: 5| Step: 9
Training loss: 1.9190986156463623
Validation loss: 2.139437826730872

Epoch: 5| Step: 10
Training loss: 1.0720415115356445
Validation loss: 2.131559648821431

Epoch: 167| Step: 0
Training loss: 2.0884132385253906
Validation loss: 2.1417177313117572

Epoch: 5| Step: 1
Training loss: 1.6861178874969482
Validation loss: 2.177698048212195

Epoch: 5| Step: 2
Training loss: 1.8844034671783447
Validation loss: 2.1971263629133984

Epoch: 5| Step: 3
Training loss: 1.8314692974090576
Validation loss: 2.136124687810098

Epoch: 5| Step: 4
Training loss: 1.5791816711425781
Validation loss: 2.09037148439756

Epoch: 5| Step: 5
Training loss: 1.7745949029922485
Validation loss: 2.027912452656736

Epoch: 5| Step: 6
Training loss: 1.9455883502960205
Validation loss: 2.0091810687895744

Epoch: 5| Step: 7
Training loss: 2.0607330799102783
Validation loss: 2.0042240824750674

Epoch: 5| Step: 8
Training loss: 2.029209613800049
Validation loss: 2.0232176755064275

Epoch: 5| Step: 9
Training loss: 1.4053939580917358
Validation loss: 2.0084319217230684

Epoch: 5| Step: 10
Training loss: 1.8312441110610962
Validation loss: 2.0199324469412527

Epoch: 168| Step: 0
Training loss: 1.9836852550506592
Validation loss: 2.0143547250378515

Epoch: 5| Step: 1
Training loss: 1.3974180221557617
Validation loss: 2.0602976647756432

Epoch: 5| Step: 2
Training loss: 1.3068732023239136
Validation loss: 2.077574400491612

Epoch: 5| Step: 3
Training loss: 1.2441681623458862
Validation loss: 2.1021000428866317

Epoch: 5| Step: 4
Training loss: 2.1159374713897705
Validation loss: 2.098612775084793

Epoch: 5| Step: 5
Training loss: 0.8123127222061157
Validation loss: 2.110718773257348

Epoch: 5| Step: 6
Training loss: 2.188295841217041
Validation loss: 2.1303436627952

Epoch: 5| Step: 7
Training loss: 2.2164089679718018
Validation loss: 2.1864981100123417

Epoch: 5| Step: 8
Training loss: 2.3388354778289795
Validation loss: 2.1979941001502414

Epoch: 5| Step: 9
Training loss: 2.4702982902526855
Validation loss: 2.1371397459378807

Epoch: 5| Step: 10
Training loss: 1.6180180311203003
Validation loss: 2.08549694092043

Epoch: 169| Step: 0
Training loss: 1.9120874404907227
Validation loss: 2.0497690016223538

Epoch: 5| Step: 1
Training loss: 1.794769287109375
Validation loss: 2.031810470806655

Epoch: 5| Step: 2
Training loss: 2.019429922103882
Validation loss: 2.013789692232686

Epoch: 5| Step: 3
Training loss: 2.232029676437378
Validation loss: 1.9833393942925237

Epoch: 5| Step: 4
Training loss: 1.2939016819000244
Validation loss: 1.987868643576099

Epoch: 5| Step: 5
Training loss: 1.8422811031341553
Validation loss: 1.9929039119392313

Epoch: 5| Step: 6
Training loss: 1.3338830471038818
Validation loss: 1.980968790669595

Epoch: 5| Step: 7
Training loss: 1.9429540634155273
Validation loss: 2.014285202949278

Epoch: 5| Step: 8
Training loss: 2.0488879680633545
Validation loss: 2.0389936944489837

Epoch: 5| Step: 9
Training loss: 1.7110309600830078
Validation loss: 2.044337172662058

Epoch: 5| Step: 10
Training loss: 1.064263105392456
Validation loss: 2.058126134257163

Epoch: 170| Step: 0
Training loss: 1.2506364583969116
Validation loss: 2.068017672466975

Epoch: 5| Step: 1
Training loss: 1.5016422271728516
Validation loss: 2.04906750494434

Epoch: 5| Step: 2
Training loss: 1.2975246906280518
Validation loss: 2.03370395270727

Epoch: 5| Step: 3
Training loss: 1.9090471267700195
Validation loss: 1.9985611656660676

Epoch: 5| Step: 4
Training loss: 2.0052249431610107
Validation loss: 1.9733982137454453

Epoch: 5| Step: 5
Training loss: 2.2143921852111816
Validation loss: 1.990726117164858

Epoch: 5| Step: 6
Training loss: 1.4922293424606323
Validation loss: 2.013395263302711

Epoch: 5| Step: 7
Training loss: 1.6098432540893555
Validation loss: 2.0135388348692205

Epoch: 5| Step: 8
Training loss: 2.031862497329712
Validation loss: 2.0030814550256215

Epoch: 5| Step: 9
Training loss: 2.194436550140381
Validation loss: 1.9864015143404725

Epoch: 5| Step: 10
Training loss: 1.3851258754730225
Validation loss: 1.9651271117630826

Epoch: 171| Step: 0
Training loss: 2.167397975921631
Validation loss: 1.9649931192398071

Epoch: 5| Step: 1
Training loss: 1.7751392126083374
Validation loss: 1.9610469828369796

Epoch: 5| Step: 2
Training loss: 1.935826301574707
Validation loss: 1.9772720413823281

Epoch: 5| Step: 3
Training loss: 2.411052703857422
Validation loss: 2.0117757653677337

Epoch: 5| Step: 4
Training loss: 1.8796532154083252
Validation loss: 2.0550247533347017

Epoch: 5| Step: 5
Training loss: 1.6668479442596436
Validation loss: 2.0784589885383524

Epoch: 5| Step: 6
Training loss: 1.4858732223510742
Validation loss: 2.1031684952397502

Epoch: 5| Step: 7
Training loss: 1.6452834606170654
Validation loss: 2.1361023226091937

Epoch: 5| Step: 8
Training loss: 1.3186719417572021
Validation loss: 2.131339979428117

Epoch: 5| Step: 9
Training loss: 1.1566615104675293
Validation loss: 2.117822024130052

Epoch: 5| Step: 10
Training loss: 1.4892067909240723
Validation loss: 2.0882927051154514

Epoch: 172| Step: 0
Training loss: 1.555147409439087
Validation loss: 2.0718689836481565

Epoch: 5| Step: 1
Training loss: 1.5670255422592163
Validation loss: 2.032297542018275

Epoch: 5| Step: 2
Training loss: 2.0184268951416016
Validation loss: 2.02118646073085

Epoch: 5| Step: 3
Training loss: 1.8171565532684326
Validation loss: 2.028624524352371

Epoch: 5| Step: 4
Training loss: 1.6342697143554688
Validation loss: 2.0216782298139346

Epoch: 5| Step: 5
Training loss: 1.3155827522277832
Validation loss: 1.9972442926899079

Epoch: 5| Step: 6
Training loss: 1.3456699848175049
Validation loss: 1.9852522521890619

Epoch: 5| Step: 7
Training loss: 1.7060966491699219
Validation loss: 1.9928206423277497

Epoch: 5| Step: 8
Training loss: 1.7095615863800049
Validation loss: 2.0049545149649344

Epoch: 5| Step: 9
Training loss: 1.9358927011489868
Validation loss: 2.0201951406335317

Epoch: 5| Step: 10
Training loss: 2.1371021270751953
Validation loss: 2.0325408199782014

Epoch: 173| Step: 0
Training loss: 1.6435136795043945
Validation loss: 1.986287001640566

Epoch: 5| Step: 1
Training loss: 1.6355044841766357
Validation loss: 1.961107603965267

Epoch: 5| Step: 2
Training loss: 1.6060720682144165
Validation loss: 1.9620409473296134

Epoch: 5| Step: 3
Training loss: 1.726435661315918
Validation loss: 1.984579206794821

Epoch: 5| Step: 4
Training loss: 1.7177711725234985
Validation loss: 1.9957904226036483

Epoch: 5| Step: 5
Training loss: 1.8159507513046265
Validation loss: 2.0294223536727247

Epoch: 5| Step: 6
Training loss: 1.7917124032974243
Validation loss: 2.047358471860168

Epoch: 5| Step: 7
Training loss: 1.5284249782562256
Validation loss: 2.05552250851867

Epoch: 5| Step: 8
Training loss: 1.6234852075576782
Validation loss: 2.0777977487092376

Epoch: 5| Step: 9
Training loss: 1.2829080820083618
Validation loss: 2.1115015860526793

Epoch: 5| Step: 10
Training loss: 1.8381433486938477
Validation loss: 2.1086776038651824

Epoch: 174| Step: 0
Training loss: 1.777071237564087
Validation loss: 2.1516262536407798

Epoch: 5| Step: 1
Training loss: 1.166417121887207
Validation loss: 2.1533752897734284

Epoch: 5| Step: 2
Training loss: 1.599621057510376
Validation loss: 2.0883156381627566

Epoch: 5| Step: 3
Training loss: 1.5191292762756348
Validation loss: 2.0661057464538084

Epoch: 5| Step: 4
Training loss: 2.195180892944336
Validation loss: 2.044955092091714

Epoch: 5| Step: 5
Training loss: 1.6272220611572266
Validation loss: 2.02177006711242

Epoch: 5| Step: 6
Training loss: 1.3063298463821411
Validation loss: 2.0112976386982906

Epoch: 5| Step: 7
Training loss: 1.4978208541870117
Validation loss: 2.0079903987146195

Epoch: 5| Step: 8
Training loss: 2.3630428314208984
Validation loss: 2.0234211926819174

Epoch: 5| Step: 9
Training loss: 1.861342430114746
Validation loss: 2.1008577500620196

Epoch: 5| Step: 10
Training loss: 1.9751492738723755
Validation loss: 2.118826543131182

Epoch: 175| Step: 0
Training loss: 1.361541509628296
Validation loss: 2.1011960839712494

Epoch: 5| Step: 1
Training loss: 1.9628925323486328
Validation loss: 2.1129047947545208

Epoch: 5| Step: 2
Training loss: 1.1570216417312622
Validation loss: 2.085444668287872

Epoch: 5| Step: 3
Training loss: 1.6571820974349976
Validation loss: 2.0333984513436594

Epoch: 5| Step: 4
Training loss: 1.9013687372207642
Validation loss: 2.013701331230902

Epoch: 5| Step: 5
Training loss: 1.846623182296753
Validation loss: 2.0188736736133532

Epoch: 5| Step: 6
Training loss: 1.4492460489273071
Validation loss: 1.9975018193644862

Epoch: 5| Step: 7
Training loss: 2.043322801589966
Validation loss: 1.9732294851733791

Epoch: 5| Step: 8
Training loss: 1.4437973499298096
Validation loss: 1.9539539237176218

Epoch: 5| Step: 9
Training loss: 1.5885089635849
Validation loss: 1.9854067217919134

Epoch: 5| Step: 10
Training loss: 1.653197169303894
Validation loss: 1.9721892636309388

Epoch: 176| Step: 0
Training loss: 1.506941556930542
Validation loss: 1.9873803661715599

Epoch: 5| Step: 1
Training loss: 1.7616989612579346
Validation loss: 2.0121450065284647

Epoch: 5| Step: 2
Training loss: 1.3351091146469116
Validation loss: 2.067032539716331

Epoch: 5| Step: 3
Training loss: 1.8603107929229736
Validation loss: 2.1270408476552656

Epoch: 5| Step: 4
Training loss: 1.849036455154419
Validation loss: 2.1667897855081866

Epoch: 5| Step: 5
Training loss: 2.374077558517456
Validation loss: 2.1599179903666177

Epoch: 5| Step: 6
Training loss: 1.7200111150741577
Validation loss: 2.1381516738604476

Epoch: 5| Step: 7
Training loss: 1.1432433128356934
Validation loss: 2.1213235726920505

Epoch: 5| Step: 8
Training loss: 1.5847039222717285
Validation loss: 2.124483431539228

Epoch: 5| Step: 9
Training loss: 1.1745731830596924
Validation loss: 2.0674013963309665

Epoch: 5| Step: 10
Training loss: 1.7309038639068604
Validation loss: 2.033139415966567

Epoch: 177| Step: 0
Training loss: 1.8645318746566772
Validation loss: 2.0199421554483394

Epoch: 5| Step: 1
Training loss: 1.560502290725708
Validation loss: 1.9840005828488259

Epoch: 5| Step: 2
Training loss: 1.8985744714736938
Validation loss: 1.96665931388896

Epoch: 5| Step: 3
Training loss: 1.4326101541519165
Validation loss: 1.9643244974074825

Epoch: 5| Step: 4
Training loss: 1.5526244640350342
Validation loss: 1.9614985860804075

Epoch: 5| Step: 5
Training loss: 1.46084725856781
Validation loss: 1.9588883179490284

Epoch: 5| Step: 6
Training loss: 1.541208028793335
Validation loss: 1.9813102342749154

Epoch: 5| Step: 7
Training loss: 2.1831960678100586
Validation loss: 2.037578263590413

Epoch: 5| Step: 8
Training loss: 1.8137096166610718
Validation loss: 2.0857103332396476

Epoch: 5| Step: 9
Training loss: 1.3854273557662964
Validation loss: 2.117085354302519

Epoch: 5| Step: 10
Training loss: 1.2414954900741577
Validation loss: 2.1050105325637327

Epoch: 178| Step: 0
Training loss: 0.9988155364990234
Validation loss: 2.106092087684139

Epoch: 5| Step: 1
Training loss: 1.222038745880127
Validation loss: 2.0672120868518786

Epoch: 5| Step: 2
Training loss: 1.4763360023498535
Validation loss: 2.048001999496132

Epoch: 5| Step: 3
Training loss: 2.147571086883545
Validation loss: 2.050980415395511

Epoch: 5| Step: 4
Training loss: 1.7581297159194946
Validation loss: 2.0668969423540178

Epoch: 5| Step: 5
Training loss: 1.7360988855361938
Validation loss: 2.0763948425169914

Epoch: 5| Step: 6
Training loss: 1.6460317373275757
Validation loss: 2.027829216372582

Epoch: 5| Step: 7
Training loss: 1.686187505722046
Validation loss: 2.0540773714742353

Epoch: 5| Step: 8
Training loss: 1.4912140369415283
Validation loss: 2.0489334765300957

Epoch: 5| Step: 9
Training loss: 1.668180227279663
Validation loss: 2.0503822488169514

Epoch: 5| Step: 10
Training loss: 2.126532793045044
Validation loss: 2.027968773277857

Epoch: 179| Step: 0
Training loss: 1.55392324924469
Validation loss: 1.9771824908512894

Epoch: 5| Step: 1
Training loss: 1.8028236627578735
Validation loss: 1.9571370501672067

Epoch: 5| Step: 2
Training loss: 1.7418861389160156
Validation loss: 1.9411824800634896

Epoch: 5| Step: 3
Training loss: 0.8450228571891785
Validation loss: 1.9794429066360637

Epoch: 5| Step: 4
Training loss: 1.2632867097854614
Validation loss: 2.017248776651198

Epoch: 5| Step: 5
Training loss: 1.7355639934539795
Validation loss: 2.0614427264018724

Epoch: 5| Step: 6
Training loss: 1.2859195470809937
Validation loss: 2.0687651941853185

Epoch: 5| Step: 7
Training loss: 1.9843543767929077
Validation loss: 2.0751821994781494

Epoch: 5| Step: 8
Training loss: 1.9927036762237549
Validation loss: 2.105604907517792

Epoch: 5| Step: 9
Training loss: 2.045335292816162
Validation loss: 2.0684603132227415

Epoch: 5| Step: 10
Training loss: 1.2720261812210083
Validation loss: 2.065146097572901

Epoch: 180| Step: 0
Training loss: 1.1796939373016357
Validation loss: 2.098871715607182

Epoch: 5| Step: 1
Training loss: 0.8688608407974243
Validation loss: 2.0561452860473306

Epoch: 5| Step: 2
Training loss: 2.1970365047454834
Validation loss: 2.076108609476397

Epoch: 5| Step: 3
Training loss: 1.9582958221435547
Validation loss: 1.9935691613022999

Epoch: 5| Step: 4
Training loss: 1.7758052349090576
Validation loss: 1.9872894838292112

Epoch: 5| Step: 5
Training loss: 1.6732242107391357
Validation loss: 2.018152912457784

Epoch: 5| Step: 6
Training loss: 2.008347749710083
Validation loss: 2.0508823061502106

Epoch: 5| Step: 7
Training loss: 0.9582138061523438
Validation loss: 2.0702481885110178

Epoch: 5| Step: 8
Training loss: 1.8466688394546509
Validation loss: 2.09545386222101

Epoch: 5| Step: 9
Training loss: 1.408186435699463
Validation loss: 2.1204976522794334

Epoch: 5| Step: 10
Training loss: 1.7041149139404297
Validation loss: 2.124074030947942

Epoch: 181| Step: 0
Training loss: 1.3279708623886108
Validation loss: 2.1716164876055974

Epoch: 5| Step: 1
Training loss: 1.7816766500473022
Validation loss: 2.1891288142050467

Epoch: 5| Step: 2
Training loss: 1.5844001770019531
Validation loss: 2.1870834673604658

Epoch: 5| Step: 3
Training loss: 2.1134982109069824
Validation loss: 2.12670640278888

Epoch: 5| Step: 4
Training loss: 1.558043122291565
Validation loss: 2.031160598160118

Epoch: 5| Step: 5
Training loss: 1.2209253311157227
Validation loss: 1.961813053777141

Epoch: 5| Step: 6
Training loss: 1.8613942861557007
Validation loss: 1.929204156321864

Epoch: 5| Step: 7
Training loss: 1.9353500604629517
Validation loss: 1.9340790933178318

Epoch: 5| Step: 8
Training loss: 1.4567046165466309
Validation loss: 1.9461771211316508

Epoch: 5| Step: 9
Training loss: 1.4223042726516724
Validation loss: 1.9662070376898653

Epoch: 5| Step: 10
Training loss: 1.2121413946151733
Validation loss: 1.998321863912767

Epoch: 182| Step: 0
Training loss: 1.443641185760498
Validation loss: 2.040256534853289

Epoch: 5| Step: 1
Training loss: 1.8748213052749634
Validation loss: 2.070823420760452

Epoch: 5| Step: 2
Training loss: 1.5905768871307373
Validation loss: 2.1380470337406283

Epoch: 5| Step: 3
Training loss: 1.2183945178985596
Validation loss: 2.1677173517083608

Epoch: 5| Step: 4
Training loss: 1.3719892501831055
Validation loss: 2.175367239982851

Epoch: 5| Step: 5
Training loss: 1.813481092453003
Validation loss: 2.124269985383557

Epoch: 5| Step: 6
Training loss: 1.432506799697876
Validation loss: 2.096210636118407

Epoch: 5| Step: 7
Training loss: 1.0584661960601807
Validation loss: 2.041039243821175

Epoch: 5| Step: 8
Training loss: 2.164886951446533
Validation loss: 2.0115430431981243

Epoch: 5| Step: 9
Training loss: 1.9611318111419678
Validation loss: 2.0250893433888755

Epoch: 5| Step: 10
Training loss: 1.259282112121582
Validation loss: 2.0034675418689685

Epoch: 183| Step: 0
Training loss: 1.6038106679916382
Validation loss: 2.0007933467947026

Epoch: 5| Step: 1
Training loss: 1.4771158695220947
Validation loss: 1.995250064839599

Epoch: 5| Step: 2
Training loss: 1.6768039464950562
Validation loss: 2.0032229244068103

Epoch: 5| Step: 3
Training loss: 1.0465881824493408
Validation loss: 1.986979979340748

Epoch: 5| Step: 4
Training loss: 1.6920640468597412
Validation loss: 2.073727819227403

Epoch: 5| Step: 5
Training loss: 1.410512924194336
Validation loss: 2.119010966311219

Epoch: 5| Step: 6
Training loss: 1.7757132053375244
Validation loss: 2.190232173089058

Epoch: 5| Step: 7
Training loss: 1.76947820186615
Validation loss: 2.2106709326467207

Epoch: 5| Step: 8
Training loss: 1.8620927333831787
Validation loss: 2.1422705252965293

Epoch: 5| Step: 9
Training loss: 1.120764136314392
Validation loss: 2.0970530971404044

Epoch: 5| Step: 10
Training loss: 1.7062290906906128
Validation loss: 2.084242320829822

Epoch: 184| Step: 0
Training loss: 1.4422987699508667
Validation loss: 2.0623317969742643

Epoch: 5| Step: 1
Training loss: 1.7116641998291016
Validation loss: 2.0471538805192515

Epoch: 5| Step: 2
Training loss: 1.8581085205078125
Validation loss: 2.0387860651939147

Epoch: 5| Step: 3
Training loss: 1.4753968715667725
Validation loss: 2.0141278543779926

Epoch: 5| Step: 4
Training loss: 0.905329704284668
Validation loss: 2.0182152563525784

Epoch: 5| Step: 5
Training loss: 1.3377690315246582
Validation loss: 2.066491330823591

Epoch: 5| Step: 6
Training loss: 1.8669697046279907
Validation loss: 2.1239670194605345

Epoch: 5| Step: 7
Training loss: 1.4949331283569336
Validation loss: 2.147624002989902

Epoch: 5| Step: 8
Training loss: 1.6487106084823608
Validation loss: 2.104224184507965

Epoch: 5| Step: 9
Training loss: 1.9657690525054932
Validation loss: 2.0467388142821608

Epoch: 5| Step: 10
Training loss: 1.1030313968658447
Validation loss: 2.0086158219204155

Epoch: 185| Step: 0
Training loss: 1.4261575937271118
Validation loss: 1.9730875133186259

Epoch: 5| Step: 1
Training loss: 1.432843565940857
Validation loss: 2.009587113575269

Epoch: 5| Step: 2
Training loss: 1.5012110471725464
Validation loss: 2.0359268855023127

Epoch: 5| Step: 3
Training loss: 1.827959656715393
Validation loss: 2.0798226300106255

Epoch: 5| Step: 4
Training loss: 1.8066952228546143
Validation loss: 2.113904324910974

Epoch: 5| Step: 5
Training loss: 1.6868976354599
Validation loss: 2.119654591365527

Epoch: 5| Step: 6
Training loss: 0.9881811141967773
Validation loss: 2.1275240170058383

Epoch: 5| Step: 7
Training loss: 0.7642976641654968
Validation loss: 2.1181044604188655

Epoch: 5| Step: 8
Training loss: 1.4817854166030884
Validation loss: 2.0722052897176435

Epoch: 5| Step: 9
Training loss: 1.6074867248535156
Validation loss: 2.0455089922874206

Epoch: 5| Step: 10
Training loss: 1.7857447862625122
Validation loss: 2.0096133832008607

Epoch: 186| Step: 0
Training loss: 1.922811508178711
Validation loss: 1.979709791880782

Epoch: 5| Step: 1
Training loss: 1.5906261205673218
Validation loss: 1.989481774709558

Epoch: 5| Step: 2
Training loss: 1.289777159690857
Validation loss: 1.9778706271161315

Epoch: 5| Step: 3
Training loss: 1.9498714208602905
Validation loss: 2.0282380709084133

Epoch: 5| Step: 4
Training loss: 1.49214506149292
Validation loss: 2.057258718757219

Epoch: 5| Step: 5
Training loss: 1.0848857164382935
Validation loss: 2.0916959854864303

Epoch: 5| Step: 6
Training loss: 1.4673893451690674
Validation loss: 2.1665660540262857

Epoch: 5| Step: 7
Training loss: 1.8173410892486572
Validation loss: 2.1889370769582768

Epoch: 5| Step: 8
Training loss: 1.3148047924041748
Validation loss: 2.188228166231545

Epoch: 5| Step: 9
Training loss: 1.2434364557266235
Validation loss: 2.17613971617914

Epoch: 5| Step: 10
Training loss: 1.1413789987564087
Validation loss: 2.1525397223810994

Epoch: 187| Step: 0
Training loss: 1.0817075967788696
Validation loss: 2.150478793728736

Epoch: 5| Step: 1
Training loss: 1.4543445110321045
Validation loss: 2.164875477872869

Epoch: 5| Step: 2
Training loss: 1.6648623943328857
Validation loss: 2.146836091113347

Epoch: 5| Step: 3
Training loss: 1.8800382614135742
Validation loss: 2.12291524487157

Epoch: 5| Step: 4
Training loss: 0.9701091647148132
Validation loss: 2.0962568765045493

Epoch: 5| Step: 5
Training loss: 1.3278189897537231
Validation loss: 2.0927707866955827

Epoch: 5| Step: 6
Training loss: 1.5925813913345337
Validation loss: 2.0750646206640426

Epoch: 5| Step: 7
Training loss: 1.8648746013641357
Validation loss: 2.0389130397509505

Epoch: 5| Step: 8
Training loss: 1.0670942068099976
Validation loss: 2.0162461124440676

Epoch: 5| Step: 9
Training loss: 1.6944961547851562
Validation loss: 2.004068996316643

Epoch: 5| Step: 10
Training loss: 1.673667073249817
Validation loss: 2.000058953480054

Epoch: 188| Step: 0
Training loss: 1.599123239517212
Validation loss: 2.0279606183369956

Epoch: 5| Step: 1
Training loss: 1.3037668466567993
Validation loss: 2.0251829983085714

Epoch: 5| Step: 2
Training loss: 1.7569200992584229
Validation loss: 2.063093344370524

Epoch: 5| Step: 3
Training loss: 1.13466477394104
Validation loss: 2.0970244279471775

Epoch: 5| Step: 4
Training loss: 1.1001930236816406
Validation loss: 2.1305138654606317

Epoch: 5| Step: 5
Training loss: 1.6889503002166748
Validation loss: 2.1373470547378703

Epoch: 5| Step: 6
Training loss: 1.2813411951065063
Validation loss: 2.1874461571375527

Epoch: 5| Step: 7
Training loss: 1.3440932035446167
Validation loss: 2.1929668970005487

Epoch: 5| Step: 8
Training loss: 1.479199767112732
Validation loss: 2.1238037540066625

Epoch: 5| Step: 9
Training loss: 1.1716864109039307
Validation loss: 2.053034013317477

Epoch: 5| Step: 10
Training loss: 2.0203685760498047
Validation loss: 2.0082623958587646

Epoch: 189| Step: 0
Training loss: 1.3622732162475586
Validation loss: 1.9938575247282624

Epoch: 5| Step: 1
Training loss: 1.458160400390625
Validation loss: 1.9901912904554797

Epoch: 5| Step: 2
Training loss: 1.2725982666015625
Validation loss: 1.9937438311115387

Epoch: 5| Step: 3
Training loss: 1.2159650325775146
Validation loss: 2.0116644777277464

Epoch: 5| Step: 4
Training loss: 1.003519058227539
Validation loss: 2.0429482434385564

Epoch: 5| Step: 5
Training loss: 1.8063195943832397
Validation loss: 2.0675970431297057

Epoch: 5| Step: 6
Training loss: 1.9078524112701416
Validation loss: 2.187482287806849

Epoch: 5| Step: 7
Training loss: 1.38271164894104
Validation loss: 2.2384313306500836

Epoch: 5| Step: 8
Training loss: 1.8703949451446533
Validation loss: 2.260876860669864

Epoch: 5| Step: 9
Training loss: 1.4099606275558472
Validation loss: 2.2528601718205277

Epoch: 5| Step: 10
Training loss: 1.6753852367401123
Validation loss: 2.2340865878648657

Epoch: 190| Step: 0
Training loss: 1.3624064922332764
Validation loss: 2.1654398620769544

Epoch: 5| Step: 1
Training loss: 1.2379732131958008
Validation loss: 2.060079551512195

Epoch: 5| Step: 2
Training loss: 1.5847774744033813
Validation loss: 1.9913921394655782

Epoch: 5| Step: 3
Training loss: 1.4255292415618896
Validation loss: 1.9784162890526555

Epoch: 5| Step: 4
Training loss: 1.9840093851089478
Validation loss: 1.969946825376121

Epoch: 5| Step: 5
Training loss: 1.2798165082931519
Validation loss: 1.9718240525132866

Epoch: 5| Step: 6
Training loss: 1.3890445232391357
Validation loss: 1.9650794024108558

Epoch: 5| Step: 7
Training loss: 0.8646453619003296
Validation loss: 1.987895429775279

Epoch: 5| Step: 8
Training loss: 2.018503189086914
Validation loss: 1.996451840605787

Epoch: 5| Step: 9
Training loss: 1.092589020729065
Validation loss: 2.0007202932911534

Epoch: 5| Step: 10
Training loss: 1.4247488975524902
Validation loss: 2.007535937011883

Epoch: 191| Step: 0
Training loss: 1.1554679870605469
Validation loss: 2.005304085311069

Epoch: 5| Step: 1
Training loss: 1.5899931192398071
Validation loss: 2.0253203197192122

Epoch: 5| Step: 2
Training loss: 1.1097185611724854
Validation loss: 2.0058225406113492

Epoch: 5| Step: 3
Training loss: 1.4456621408462524
Validation loss: 2.0412971268418016

Epoch: 5| Step: 4
Training loss: 1.5622062683105469
Validation loss: 2.0526114356133247

Epoch: 5| Step: 5
Training loss: 1.5062181949615479
Validation loss: 2.0804710413820002

Epoch: 5| Step: 6
Training loss: 1.3890936374664307
Validation loss: 2.068188923661427

Epoch: 5| Step: 7
Training loss: 1.245849847793579
Validation loss: 2.0728122239471762

Epoch: 5| Step: 8
Training loss: 1.0225025415420532
Validation loss: 2.0954771272597776

Epoch: 5| Step: 9
Training loss: 1.6216189861297607
Validation loss: 2.1187832458044893

Epoch: 5| Step: 10
Training loss: 1.8334940671920776
Validation loss: 2.167681961931208

Epoch: 192| Step: 0
Training loss: 1.7923692464828491
Validation loss: 2.2036391227476058

Epoch: 5| Step: 1
Training loss: 1.5063908100128174
Validation loss: 2.157413023774342

Epoch: 5| Step: 2
Training loss: 1.8111015558242798
Validation loss: 2.142708445108065

Epoch: 5| Step: 3
Training loss: 1.5370500087738037
Validation loss: 2.1273218841962915

Epoch: 5| Step: 4
Training loss: 1.118764042854309
Validation loss: 2.0997728404178413

Epoch: 5| Step: 5
Training loss: 1.1404147148132324
Validation loss: 2.09068101708607

Epoch: 5| Step: 6
Training loss: 1.0799376964569092
Validation loss: 2.0615946887641825

Epoch: 5| Step: 7
Training loss: 1.2236301898956299
Validation loss: 2.0517531107830744

Epoch: 5| Step: 8
Training loss: 1.243536353111267
Validation loss: 2.0546732205216602

Epoch: 5| Step: 9
Training loss: 1.1644433736801147
Validation loss: 2.0901007485646073

Epoch: 5| Step: 10
Training loss: 1.6969045400619507
Validation loss: 2.0620346428245626

Epoch: 193| Step: 0
Training loss: 1.3953794240951538
Validation loss: 2.067548023757114

Epoch: 5| Step: 1
Training loss: 1.4275686740875244
Validation loss: 2.0711366386823755

Epoch: 5| Step: 2
Training loss: 1.368146538734436
Validation loss: 2.0430378683151735

Epoch: 5| Step: 3
Training loss: 1.5211009979248047
Validation loss: 2.037355083291249

Epoch: 5| Step: 4
Training loss: 1.6652660369873047
Validation loss: 2.0213344148410264

Epoch: 5| Step: 5
Training loss: 1.3541516065597534
Validation loss: 1.9872529173410067

Epoch: 5| Step: 6
Training loss: 1.3609719276428223
Validation loss: 1.9902731167372836

Epoch: 5| Step: 7
Training loss: 1.404869556427002
Validation loss: 2.0054684813304613

Epoch: 5| Step: 8
Training loss: 1.2552490234375
Validation loss: 1.981630822663666

Epoch: 5| Step: 9
Training loss: 1.1297944784164429
Validation loss: 2.0178666448080413

Epoch: 5| Step: 10
Training loss: 1.0645142793655396
Validation loss: 2.0861044711964105

Epoch: 194| Step: 0
Training loss: 1.4533573389053345
Validation loss: 2.1588517940172585

Epoch: 5| Step: 1
Training loss: 1.6562007665634155
Validation loss: 2.177850377175116

Epoch: 5| Step: 2
Training loss: 1.2069445848464966
Validation loss: 2.1874095342492543

Epoch: 5| Step: 3
Training loss: 1.1872694492340088
Validation loss: 2.1635710911084245

Epoch: 5| Step: 4
Training loss: 1.2742012739181519
Validation loss: 2.1479048267487557

Epoch: 5| Step: 5
Training loss: 0.9657710790634155
Validation loss: 2.133916747185492

Epoch: 5| Step: 6
Training loss: 1.8757270574569702
Validation loss: 2.1070195628750708

Epoch: 5| Step: 7
Training loss: 1.0806858539581299
Validation loss: 2.077817315696388

Epoch: 5| Step: 8
Training loss: 1.6548926830291748
Validation loss: 2.007618499058549

Epoch: 5| Step: 9
Training loss: 1.3494173288345337
Validation loss: 2.0043412280339066

Epoch: 5| Step: 10
Training loss: 1.2638578414916992
Validation loss: 1.9877772254328574

Epoch: 195| Step: 0
Training loss: 1.0751678943634033
Validation loss: 1.9897813181723318

Epoch: 5| Step: 1
Training loss: 1.3136632442474365
Validation loss: 1.9996877536978772

Epoch: 5| Step: 2
Training loss: 1.5358717441558838
Validation loss: 2.005209481844338

Epoch: 5| Step: 3
Training loss: 1.4168710708618164
Validation loss: 1.9995655398215018

Epoch: 5| Step: 4
Training loss: 1.3840018510818481
Validation loss: 2.021135114854382

Epoch: 5| Step: 5
Training loss: 1.1778404712677002
Validation loss: 2.0640064413829515

Epoch: 5| Step: 6
Training loss: 1.4856998920440674
Validation loss: 2.0370682093404953

Epoch: 5| Step: 7
Training loss: 1.3676602840423584
Validation loss: 2.0655708928262033

Epoch: 5| Step: 8
Training loss: 1.392770528793335
Validation loss: 2.081229111199738

Epoch: 5| Step: 9
Training loss: 1.396519422531128
Validation loss: 2.069206812048471

Epoch: 5| Step: 10
Training loss: 1.097362756729126
Validation loss: 2.049469772205558

Epoch: 196| Step: 0
Training loss: 1.2142268419265747
Validation loss: 2.0451651055325746

Epoch: 5| Step: 1
Training loss: 1.351348876953125
Validation loss: 2.0118065316190004

Epoch: 5| Step: 2
Training loss: 1.2582180500030518
Validation loss: 2.010253091012278

Epoch: 5| Step: 3
Training loss: 1.4472148418426514
Validation loss: 2.0079379453453967

Epoch: 5| Step: 4
Training loss: 1.1585423946380615
Validation loss: 2.029220529781875

Epoch: 5| Step: 5
Training loss: 1.0802732706069946
Validation loss: 2.0386227510308705

Epoch: 5| Step: 6
Training loss: 1.3888776302337646
Validation loss: 2.0270356273138397

Epoch: 5| Step: 7
Training loss: 1.645219087600708
Validation loss: 2.055026714519788

Epoch: 5| Step: 8
Training loss: 1.933476209640503
Validation loss: 2.06868613278994

Epoch: 5| Step: 9
Training loss: 0.9218646287918091
Validation loss: 2.0386554835945048

Epoch: 5| Step: 10
Training loss: 0.7101267576217651
Validation loss: 2.014628520575903

Epoch: 197| Step: 0
Training loss: 1.1976944208145142
Validation loss: 2.0201750493818715

Epoch: 5| Step: 1
Training loss: 0.8510602712631226
Validation loss: 1.9889062963506228

Epoch: 5| Step: 2
Training loss: 1.1844861507415771
Validation loss: 1.9932525721929406

Epoch: 5| Step: 3
Training loss: 1.4653375148773193
Validation loss: 1.9954709032530427

Epoch: 5| Step: 4
Training loss: 1.4413444995880127
Validation loss: 2.010366145000663

Epoch: 5| Step: 5
Training loss: 1.4920192956924438
Validation loss: 2.028470928950976

Epoch: 5| Step: 6
Training loss: 1.0432263612747192
Validation loss: 2.0593233467430196

Epoch: 5| Step: 7
Training loss: 1.4464372396469116
Validation loss: 2.0269078618736676

Epoch: 5| Step: 8
Training loss: 1.7771437168121338
Validation loss: 2.0160667024632937

Epoch: 5| Step: 9
Training loss: 1.1360952854156494
Validation loss: 1.9937646978644914

Epoch: 5| Step: 10
Training loss: 1.296127200126648
Validation loss: 2.0281193948561147

Epoch: 198| Step: 0
Training loss: 0.9605226516723633
Validation loss: 2.0532670149239163

Epoch: 5| Step: 1
Training loss: 0.9626550674438477
Validation loss: 2.0443098660438292

Epoch: 5| Step: 2
Training loss: 1.1263507604599
Validation loss: 2.081390247550062

Epoch: 5| Step: 3
Training loss: 1.2977975606918335
Validation loss: 2.0990621351426646

Epoch: 5| Step: 4
Training loss: 1.4301435947418213
Validation loss: 2.13841522893598

Epoch: 5| Step: 5
Training loss: 1.6515464782714844
Validation loss: 2.162254330932453

Epoch: 5| Step: 6
Training loss: 1.5170180797576904
Validation loss: 2.167580476371191

Epoch: 5| Step: 7
Training loss: 1.4840552806854248
Validation loss: 2.0795315978347615

Epoch: 5| Step: 8
Training loss: 1.4067281484603882
Validation loss: 2.0255948343584613

Epoch: 5| Step: 9
Training loss: 1.262540340423584
Validation loss: 1.9858888246679818

Epoch: 5| Step: 10
Training loss: 1.0204133987426758
Validation loss: 1.9587874361263808

Epoch: 199| Step: 0
Training loss: 1.483001470565796
Validation loss: 1.9579522789165538

Epoch: 5| Step: 1
Training loss: 1.438057780265808
Validation loss: 1.9582580379260484

Epoch: 5| Step: 2
Training loss: 1.7776439189910889
Validation loss: 1.9764467759798932

Epoch: 5| Step: 3
Training loss: 0.7953896522521973
Validation loss: 1.9785981127010879

Epoch: 5| Step: 4
Training loss: 1.0898393392562866
Validation loss: 2.023972163918198

Epoch: 5| Step: 5
Training loss: 1.3750941753387451
Validation loss: 2.0705158274660826

Epoch: 5| Step: 6
Training loss: 1.6290500164031982
Validation loss: 2.115570955379035

Epoch: 5| Step: 7
Training loss: 1.1994472742080688
Validation loss: 2.109227059989847

Epoch: 5| Step: 8
Training loss: 1.062691330909729
Validation loss: 2.079750568636002

Epoch: 5| Step: 9
Training loss: 1.1574259996414185
Validation loss: 2.088898907425583

Epoch: 5| Step: 10
Training loss: 1.0790278911590576
Validation loss: 2.0853090606709963

Epoch: 200| Step: 0
Training loss: 1.7162907123565674
Validation loss: 2.051068749479068

Epoch: 5| Step: 1
Training loss: 1.3763835430145264
Validation loss: 2.055940910052228

Epoch: 5| Step: 2
Training loss: 0.8419482111930847
Validation loss: 2.038216044825892

Epoch: 5| Step: 3
Training loss: 1.4841783046722412
Validation loss: 2.0081607500712075

Epoch: 5| Step: 4
Training loss: 1.3487228155136108
Validation loss: 2.060918919501766

Epoch: 5| Step: 5
Training loss: 1.4663293361663818
Validation loss: 2.1017356995613343

Epoch: 5| Step: 6
Training loss: 0.9884616136550903
Validation loss: 2.0830024442365094

Epoch: 5| Step: 7
Training loss: 1.1960810422897339
Validation loss: 2.0609836860369612

Epoch: 5| Step: 8
Training loss: 1.1603108644485474
Validation loss: 1.999411799574411

Epoch: 5| Step: 9
Training loss: 1.6019535064697266
Validation loss: 1.9274551842802314

Epoch: 5| Step: 10
Training loss: 1.2409553527832031
Validation loss: 1.8900773166328348

Epoch: 201| Step: 0
Training loss: 1.7284284830093384
Validation loss: 1.9082359549819783

Epoch: 5| Step: 1
Training loss: 1.4907258749008179
Validation loss: 1.9145892538050169

Epoch: 5| Step: 2
Training loss: 1.3688238859176636
Validation loss: 1.9434027312904276

Epoch: 5| Step: 3
Training loss: 1.0118205547332764
Validation loss: 1.942127284183297

Epoch: 5| Step: 4
Training loss: 1.0331103801727295
Validation loss: 1.9680509592897149

Epoch: 5| Step: 5
Training loss: 1.1341817378997803
Validation loss: 2.065575756052489

Epoch: 5| Step: 6
Training loss: 1.0383638143539429
Validation loss: 2.1338867782264628

Epoch: 5| Step: 7
Training loss: 1.5686718225479126
Validation loss: 2.2104012966156006

Epoch: 5| Step: 8
Training loss: 1.4812339544296265
Validation loss: 2.275517289356519

Epoch: 5| Step: 9
Training loss: 1.1807459592819214
Validation loss: 2.223369336897327

Epoch: 5| Step: 10
Training loss: 1.1817489862442017
Validation loss: 2.122095464378275

Epoch: 202| Step: 0
Training loss: 1.150666356086731
Validation loss: 2.038895760813067

Epoch: 5| Step: 1
Training loss: 0.9394046068191528
Validation loss: 1.9853067513435119

Epoch: 5| Step: 2
Training loss: 1.4867862462997437
Validation loss: 1.9779305329886816

Epoch: 5| Step: 3
Training loss: 1.4669244289398193
Validation loss: 1.9090020387403426

Epoch: 5| Step: 4
Training loss: 1.3379647731781006
Validation loss: 1.9178469501515871

Epoch: 5| Step: 5
Training loss: 1.003211259841919
Validation loss: 1.9338454508012342

Epoch: 5| Step: 6
Training loss: 0.9117940068244934
Validation loss: 1.972415977908719

Epoch: 5| Step: 7
Training loss: 1.6496566534042358
Validation loss: 2.0157508875734065

Epoch: 5| Step: 8
Training loss: 1.227150321006775
Validation loss: 2.0609338462993665

Epoch: 5| Step: 9
Training loss: 1.587289571762085
Validation loss: 2.049686139629733

Epoch: 5| Step: 10
Training loss: 1.5366781949996948
Validation loss: 2.031651378959738

Epoch: 203| Step: 0
Training loss: 1.4460251331329346
Validation loss: 1.981062444307471

Epoch: 5| Step: 1
Training loss: 1.236706256866455
Validation loss: 1.9702830955546389

Epoch: 5| Step: 2
Training loss: 1.2559291124343872
Validation loss: 1.9732371222588323

Epoch: 5| Step: 3
Training loss: 1.5667697191238403
Validation loss: 1.977815830579368

Epoch: 5| Step: 4
Training loss: 1.0106492042541504
Validation loss: 1.9459932516979914

Epoch: 5| Step: 5
Training loss: 1.6106160879135132
Validation loss: 1.9745028544497747

Epoch: 5| Step: 6
Training loss: 0.7720990180969238
Validation loss: 1.950216152334726

Epoch: 5| Step: 7
Training loss: 1.1349464654922485
Validation loss: 1.9826379232509161

Epoch: 5| Step: 8
Training loss: 1.086358666419983
Validation loss: 2.047004738161641

Epoch: 5| Step: 9
Training loss: 0.9262367486953735
Validation loss: 2.1109793301551574

Epoch: 5| Step: 10
Training loss: 1.8195470571517944
Validation loss: 2.143710010795183

Epoch: 204| Step: 0
Training loss: 1.2644990682601929
Validation loss: 2.1059086450966458

Epoch: 5| Step: 1
Training loss: 1.724992036819458
Validation loss: 2.0855286685369347

Epoch: 5| Step: 2
Training loss: 1.020667552947998
Validation loss: 2.0596481959025064

Epoch: 5| Step: 3
Training loss: 1.0164146423339844
Validation loss: 2.0464656070996354

Epoch: 5| Step: 4
Training loss: 1.3185087442398071
Validation loss: 2.0482960195951563

Epoch: 5| Step: 5
Training loss: 1.2378437519073486
Validation loss: 2.0514564155250468

Epoch: 5| Step: 6
Training loss: 0.8921340107917786
Validation loss: 2.033464544562883

Epoch: 5| Step: 7
Training loss: 1.421052098274231
Validation loss: 2.0219060759390555

Epoch: 5| Step: 8
Training loss: 1.3404390811920166
Validation loss: 2.011648137082336

Epoch: 5| Step: 9
Training loss: 0.907923698425293
Validation loss: 2.0033513525480866

Epoch: 5| Step: 10
Training loss: 1.2843915224075317
Validation loss: 2.017197999902951

Epoch: 205| Step: 0
Training loss: 1.1354527473449707
Validation loss: 2.0400708900984896

Epoch: 5| Step: 1
Training loss: 1.2061892747879028
Validation loss: 2.0347653230031333

Epoch: 5| Step: 2
Training loss: 1.2639580965042114
Validation loss: 2.0304632315071682

Epoch: 5| Step: 3
Training loss: 1.0662556886672974
Validation loss: 1.9943102790463356

Epoch: 5| Step: 4
Training loss: 1.039208173751831
Validation loss: 1.9925854898268176

Epoch: 5| Step: 5
Training loss: 1.138391137123108
Validation loss: 2.0049938732577908

Epoch: 5| Step: 6
Training loss: 1.4269638061523438
Validation loss: 2.0011763470147246

Epoch: 5| Step: 7
Training loss: 1.3673889636993408
Validation loss: 2.057611567999727

Epoch: 5| Step: 8
Training loss: 1.1797840595245361
Validation loss: 2.058194392470903

Epoch: 5| Step: 9
Training loss: 1.4321479797363281
Validation loss: 2.106385202818019

Epoch: 5| Step: 10
Training loss: 0.9161637425422668
Validation loss: 2.0906762833236368

Epoch: 206| Step: 0
Training loss: 0.4911292493343353
Validation loss: 2.080413008248934

Epoch: 5| Step: 1
Training loss: 1.0045045614242554
Validation loss: 2.091816040777391

Epoch: 5| Step: 2
Training loss: 1.336429238319397
Validation loss: 2.1358794114922963

Epoch: 5| Step: 3
Training loss: 1.2119715213775635
Validation loss: 2.1196568755693335

Epoch: 5| Step: 4
Training loss: 0.9641780853271484
Validation loss: 2.0883247339597313

Epoch: 5| Step: 5
Training loss: 1.4381071329116821
Validation loss: 2.0544644889011177

Epoch: 5| Step: 6
Training loss: 1.0112882852554321
Validation loss: 1.9958470611162082

Epoch: 5| Step: 7
Training loss: 1.411686658859253
Validation loss: 1.985831981064171

Epoch: 5| Step: 8
Training loss: 1.6345112323760986
Validation loss: 1.98336963499746

Epoch: 5| Step: 9
Training loss: 1.4290682077407837
Validation loss: 1.9353979633700462

Epoch: 5| Step: 10
Training loss: 1.3982561826705933
Validation loss: 1.9414082573306175

Epoch: 207| Step: 0
Training loss: 1.441937804222107
Validation loss: 1.9938920441494192

Epoch: 5| Step: 1
Training loss: 1.2576168775558472
Validation loss: 2.0353385056218793

Epoch: 5| Step: 2
Training loss: 0.9908447265625
Validation loss: 2.0543194842594925

Epoch: 5| Step: 3
Training loss: 1.4380277395248413
Validation loss: 2.072926349537347

Epoch: 5| Step: 4
Training loss: 1.1885943412780762
Validation loss: 2.118864991331613

Epoch: 5| Step: 5
Training loss: 1.0835821628570557
Validation loss: 2.119698668038973

Epoch: 5| Step: 6
Training loss: 1.2096997499465942
Validation loss: 2.082556632257277

Epoch: 5| Step: 7
Training loss: 1.0966790914535522
Validation loss: 2.051831422313567

Epoch: 5| Step: 8
Training loss: 1.1713372468948364
Validation loss: 2.0522431455632693

Epoch: 5| Step: 9
Training loss: 0.8684039115905762
Validation loss: 2.0279704088805826

Epoch: 5| Step: 10
Training loss: 1.369764804840088
Validation loss: 2.0276030558411793

Epoch: 208| Step: 0
Training loss: 1.0685408115386963
Validation loss: 2.0018578139684533

Epoch: 5| Step: 1
Training loss: 1.1176865100860596
Validation loss: 1.9812156346536451

Epoch: 5| Step: 2
Training loss: 0.8451442718505859
Validation loss: 1.9972191549116565

Epoch: 5| Step: 3
Training loss: 1.2603275775909424
Validation loss: 1.9783200679286834

Epoch: 5| Step: 4
Training loss: 1.0250346660614014
Validation loss: 1.9673718675490348

Epoch: 5| Step: 5
Training loss: 1.2162106037139893
Validation loss: 1.97351784219024

Epoch: 5| Step: 6
Training loss: 1.6583846807479858
Validation loss: 1.9405783812204997

Epoch: 5| Step: 7
Training loss: 1.211232304573059
Validation loss: 1.957021346656225

Epoch: 5| Step: 8
Training loss: 1.5109668970108032
Validation loss: 1.955010570505614

Epoch: 5| Step: 9
Training loss: 0.8044502139091492
Validation loss: 1.98745689212635

Epoch: 5| Step: 10
Training loss: 1.1450759172439575
Validation loss: 2.0214670511984054

Epoch: 209| Step: 0
Training loss: 1.54414701461792
Validation loss: 2.0446036707970405

Epoch: 5| Step: 1
Training loss: 1.0347020626068115
Validation loss: 2.070545570824736

Epoch: 5| Step: 2
Training loss: 1.019067406654358
Validation loss: 2.0968170114742812

Epoch: 5| Step: 3
Training loss: 0.8421810269355774
Validation loss: 2.093866373903008

Epoch: 5| Step: 4
Training loss: 0.9883373379707336
Validation loss: 2.04444553518808

Epoch: 5| Step: 5
Training loss: 1.070976972579956
Validation loss: 2.0225913242627214

Epoch: 5| Step: 6
Training loss: 1.2524855136871338
Validation loss: 2.0315406681388937

Epoch: 5| Step: 7
Training loss: 1.176719069480896
Validation loss: 1.9810693417826006

Epoch: 5| Step: 8
Training loss: 1.1946055889129639
Validation loss: 1.9966992985817693

Epoch: 5| Step: 9
Training loss: 1.6502681970596313
Validation loss: 1.9677856071020967

Epoch: 5| Step: 10
Training loss: 1.178393006324768
Validation loss: 1.943085111597533

Epoch: 210| Step: 0
Training loss: 1.1797301769256592
Validation loss: 1.944515469253704

Epoch: 5| Step: 1
Training loss: 0.7928498387336731
Validation loss: 1.9499774363733107

Epoch: 5| Step: 2
Training loss: 0.9006536602973938
Validation loss: 1.9394808277007072

Epoch: 5| Step: 3
Training loss: 1.3292670249938965
Validation loss: 1.99805236119096

Epoch: 5| Step: 4
Training loss: 1.2952567338943481
Validation loss: 2.020522895679679

Epoch: 5| Step: 5
Training loss: 1.3065966367721558
Validation loss: 2.0374278445397653

Epoch: 5| Step: 6
Training loss: 0.9238349795341492
Validation loss: 2.038449897561022

Epoch: 5| Step: 7
Training loss: 1.644667387008667
Validation loss: 1.9631311534553446

Epoch: 5| Step: 8
Training loss: 1.4933874607086182
Validation loss: 1.9389142144110896

Epoch: 5| Step: 9
Training loss: 1.031751275062561
Validation loss: 1.9600178708312332

Epoch: 5| Step: 10
Training loss: 1.045036792755127
Validation loss: 1.9563256245787426

Epoch: 211| Step: 0
Training loss: 1.8842796087265015
Validation loss: 1.9438823653805641

Epoch: 5| Step: 1
Training loss: 1.2947324514389038
Validation loss: 1.9523067653820079

Epoch: 5| Step: 2
Training loss: 1.311139702796936
Validation loss: 1.9719965355370634

Epoch: 5| Step: 3
Training loss: 0.9917014837265015
Validation loss: 1.9812267890540503

Epoch: 5| Step: 4
Training loss: 0.9421089887619019
Validation loss: 2.043006673935921

Epoch: 5| Step: 5
Training loss: 0.9911679029464722
Validation loss: 2.005409916241964

Epoch: 5| Step: 6
Training loss: 1.052725076675415
Validation loss: 1.9875476283411826

Epoch: 5| Step: 7
Training loss: 1.084625005722046
Validation loss: 1.9989359045541415

Epoch: 5| Step: 8
Training loss: 1.030855417251587
Validation loss: 1.9798632488455823

Epoch: 5| Step: 9
Training loss: 0.8095771670341492
Validation loss: 1.9873916154266686

Epoch: 5| Step: 10
Training loss: 1.1997414827346802
Validation loss: 2.003244971716276

Epoch: 212| Step: 0
Training loss: 1.2100608348846436
Validation loss: 1.992270282519761

Epoch: 5| Step: 1
Training loss: 1.735762357711792
Validation loss: 1.9931692231085993

Epoch: 5| Step: 2
Training loss: 0.9043025970458984
Validation loss: 2.0004524453993766

Epoch: 5| Step: 3
Training loss: 1.1703535318374634
Validation loss: 1.9991743282605243

Epoch: 5| Step: 4
Training loss: 1.2781604528427124
Validation loss: 2.0122384025204565

Epoch: 5| Step: 5
Training loss: 0.9415173530578613
Validation loss: 2.066021660322784

Epoch: 5| Step: 6
Training loss: 1.4992265701293945
Validation loss: 2.1406709865857194

Epoch: 5| Step: 7
Training loss: 1.1829806566238403
Validation loss: 2.15580238321776

Epoch: 5| Step: 8
Training loss: 0.6240991353988647
Validation loss: 2.2037363667641916

Epoch: 5| Step: 9
Training loss: 0.9591778516769409
Validation loss: 2.2109112201198453

Epoch: 5| Step: 10
Training loss: 1.2017227411270142
Validation loss: 2.146752198537191

Epoch: 213| Step: 0
Training loss: 1.3748447895050049
Validation loss: 2.0990538199742637

Epoch: 5| Step: 1
Training loss: 1.1203901767730713
Validation loss: 2.024495946463718

Epoch: 5| Step: 2
Training loss: 1.1887871026992798
Validation loss: 2.0070230268662974

Epoch: 5| Step: 3
Training loss: 1.32272469997406
Validation loss: 1.9337466570638842

Epoch: 5| Step: 4
Training loss: 1.096616268157959
Validation loss: 1.9500883779218119

Epoch: 5| Step: 5
Training loss: 1.0657720565795898
Validation loss: 1.9527044270628242

Epoch: 5| Step: 6
Training loss: 0.6395989060401917
Validation loss: 2.019583632228195

Epoch: 5| Step: 7
Training loss: 1.2157907485961914
Validation loss: 2.034567727837511

Epoch: 5| Step: 8
Training loss: 1.1299034357070923
Validation loss: 2.0642796024199455

Epoch: 5| Step: 9
Training loss: 1.0943779945373535
Validation loss: 2.0593253310008715

Epoch: 5| Step: 10
Training loss: 1.23717200756073
Validation loss: 2.01679559933242

Epoch: 214| Step: 0
Training loss: 1.2487701177597046
Validation loss: 1.9761402812055362

Epoch: 5| Step: 1
Training loss: 1.3335771560668945
Validation loss: 2.003509226665702

Epoch: 5| Step: 2
Training loss: 1.0063378810882568
Validation loss: 2.0190854239207443

Epoch: 5| Step: 3
Training loss: 1.2277876138687134
Validation loss: 2.028772602799118

Epoch: 5| Step: 4
Training loss: 0.9033339619636536
Validation loss: 2.0531096240525604

Epoch: 5| Step: 5
Training loss: 1.3251802921295166
Validation loss: 2.0597602923711142

Epoch: 5| Step: 6
Training loss: 0.8833417892456055
Validation loss: 2.0570597212801696

Epoch: 5| Step: 7
Training loss: 0.8510361909866333
Validation loss: 2.0616735989047634

Epoch: 5| Step: 8
Training loss: 0.8703309893608093
Validation loss: 2.0944242028779883

Epoch: 5| Step: 9
Training loss: 2.080810785293579
Validation loss: 2.090125363360169

Epoch: 5| Step: 10
Training loss: 1.0539520978927612
Validation loss: 2.0101338586499615

Epoch: 215| Step: 0
Training loss: 1.2232078313827515
Validation loss: 2.0127731625751784

Epoch: 5| Step: 1
Training loss: 0.7033203840255737
Validation loss: 1.9812514448678622

Epoch: 5| Step: 2
Training loss: 1.0279333591461182
Validation loss: 1.9475210097528273

Epoch: 5| Step: 3
Training loss: 1.480669379234314
Validation loss: 1.946235256810342

Epoch: 5| Step: 4
Training loss: 1.0639537572860718
Validation loss: 1.9440153362930461

Epoch: 5| Step: 5
Training loss: 1.2736542224884033
Validation loss: 1.9887504116181405

Epoch: 5| Step: 6
Training loss: 1.1494660377502441
Validation loss: 1.9788397063491165

Epoch: 5| Step: 7
Training loss: 1.6164404153823853
Validation loss: 2.0480124386407996

Epoch: 5| Step: 8
Training loss: 1.464773416519165
Validation loss: 2.144763961915047

Epoch: 5| Step: 9
Training loss: 0.8616288900375366
Validation loss: 2.146083706168718

Epoch: 5| Step: 10
Training loss: 0.7513642907142639
Validation loss: 2.0922088379501016

Epoch: 216| Step: 0
Training loss: 1.0502147674560547
Validation loss: 1.9893241838742328

Epoch: 5| Step: 1
Training loss: 1.13460373878479
Validation loss: 1.9200448912958945

Epoch: 5| Step: 2
Training loss: 0.8992009162902832
Validation loss: 1.8665496008370512

Epoch: 5| Step: 3
Training loss: 1.2732359170913696
Validation loss: 1.9066040669718096

Epoch: 5| Step: 4
Training loss: 1.064332365989685
Validation loss: 1.914789076774351

Epoch: 5| Step: 5
Training loss: 1.2591367959976196
Validation loss: 1.9163984944743495

Epoch: 5| Step: 6
Training loss: 1.5349781513214111
Validation loss: 1.9552309077273133

Epoch: 5| Step: 7
Training loss: 1.5026079416275024
Validation loss: 1.9812354016047653

Epoch: 5| Step: 8
Training loss: 1.211834192276001
Validation loss: 2.028281852763186

Epoch: 5| Step: 9
Training loss: 0.8350609540939331
Validation loss: 2.0562878629212737

Epoch: 5| Step: 10
Training loss: 0.6516202092170715
Validation loss: 2.0433666782994426

Epoch: 217| Step: 0
Training loss: 0.8122442364692688
Validation loss: 2.0485262063241776

Epoch: 5| Step: 1
Training loss: 1.3337045907974243
Validation loss: 2.0151175234907415

Epoch: 5| Step: 2
Training loss: 1.1274007558822632
Validation loss: 2.000106526959327

Epoch: 5| Step: 3
Training loss: 1.0504106283187866
Validation loss: 1.947695630852894

Epoch: 5| Step: 4
Training loss: 0.7340295314788818
Validation loss: 1.9454946069307224

Epoch: 5| Step: 5
Training loss: 1.423075556755066
Validation loss: 1.969476838265696

Epoch: 5| Step: 6
Training loss: 1.211485505104065
Validation loss: 1.9897632009239608

Epoch: 5| Step: 7
Training loss: 1.4004724025726318
Validation loss: 1.9417087852313955

Epoch: 5| Step: 8
Training loss: 1.049045443534851
Validation loss: 1.956587694024527

Epoch: 5| Step: 9
Training loss: 0.9717445373535156
Validation loss: 2.0200346567297496

Epoch: 5| Step: 10
Training loss: 1.034363031387329
Validation loss: 2.0436121263811664

Epoch: 218| Step: 0
Training loss: 1.304740309715271
Validation loss: 2.0250107575488347

Epoch: 5| Step: 1
Training loss: 0.7853600382804871
Validation loss: 2.020745813205678

Epoch: 5| Step: 2
Training loss: 0.8018964529037476
Validation loss: 1.999231239800812

Epoch: 5| Step: 3
Training loss: 0.707817018032074
Validation loss: 2.002431905397805

Epoch: 5| Step: 4
Training loss: 1.1155157089233398
Validation loss: 1.9880352225354923

Epoch: 5| Step: 5
Training loss: 1.596400260925293
Validation loss: 2.015315155829153

Epoch: 5| Step: 6
Training loss: 1.338041067123413
Validation loss: 2.0203885647558395

Epoch: 5| Step: 7
Training loss: 0.7674625515937805
Validation loss: 2.0700833156544673

Epoch: 5| Step: 8
Training loss: 1.3755851984024048
Validation loss: 2.075516859690348

Epoch: 5| Step: 9
Training loss: 1.1888000965118408
Validation loss: 2.104978503719453

Epoch: 5| Step: 10
Training loss: 0.7450941801071167
Validation loss: 2.0610706562637002

Epoch: 219| Step: 0
Training loss: 1.0523183345794678
Validation loss: 2.0470287889562626

Epoch: 5| Step: 1
Training loss: 0.4935484528541565
Validation loss: 2.0477023406695296

Epoch: 5| Step: 2
Training loss: 1.4330637454986572
Validation loss: 2.0432410957992717

Epoch: 5| Step: 3
Training loss: 0.4584847390651703
Validation loss: 2.0066622944288355

Epoch: 5| Step: 4
Training loss: 1.2940552234649658
Validation loss: 2.0116952606426772

Epoch: 5| Step: 5
Training loss: 1.0578958988189697
Validation loss: 1.9773711196837886

Epoch: 5| Step: 6
Training loss: 0.8740399479866028
Validation loss: 1.988134140609413

Epoch: 5| Step: 7
Training loss: 1.1155864000320435
Validation loss: 2.0003223547371487

Epoch: 5| Step: 8
Training loss: 0.9053075909614563
Validation loss: 2.013229513681063

Epoch: 5| Step: 9
Training loss: 1.1674935817718506
Validation loss: 1.9711090441673034

Epoch: 5| Step: 10
Training loss: 1.8471957445144653
Validation loss: 1.9417692845867527

Epoch: 220| Step: 0
Training loss: 0.9410317540168762
Validation loss: 1.9433339359939739

Epoch: 5| Step: 1
Training loss: 1.2915284633636475
Validation loss: 1.929826077594552

Epoch: 5| Step: 2
Training loss: 0.9264078140258789
Validation loss: 1.9480282824526551

Epoch: 5| Step: 3
Training loss: 0.921225905418396
Validation loss: 1.9781037812591882

Epoch: 5| Step: 4
Training loss: 0.9787777066230774
Validation loss: 1.9764616540683213

Epoch: 5| Step: 5
Training loss: 0.7508305907249451
Validation loss: 1.9966489499615085

Epoch: 5| Step: 6
Training loss: 1.1754374504089355
Validation loss: 1.9347140571122527

Epoch: 5| Step: 7
Training loss: 1.0710837841033936
Validation loss: 1.9751319551980624

Epoch: 5| Step: 8
Training loss: 1.1030964851379395
Validation loss: 1.9481038970331992

Epoch: 5| Step: 9
Training loss: 0.8889360427856445
Validation loss: 1.9541718805989912

Epoch: 5| Step: 10
Training loss: 1.2170089483261108
Validation loss: 1.9482051518655592

Epoch: 221| Step: 0
Training loss: 0.9500592350959778
Validation loss: 1.9924531021425802

Epoch: 5| Step: 1
Training loss: 0.7151923179626465
Validation loss: 1.9824485778808594

Epoch: 5| Step: 2
Training loss: 0.8499919176101685
Validation loss: 2.0033181534018567

Epoch: 5| Step: 3
Training loss: 0.799197256565094
Validation loss: 2.0110830837680447

Epoch: 5| Step: 4
Training loss: 1.1181185245513916
Validation loss: 2.013011311972013

Epoch: 5| Step: 5
Training loss: 0.9104509353637695
Validation loss: 1.9729777125902073

Epoch: 5| Step: 6
Training loss: 0.9881950616836548
Validation loss: 2.0276856730061192

Epoch: 5| Step: 7
Training loss: 0.9188827276229858
Validation loss: 2.000580762022285

Epoch: 5| Step: 8
Training loss: 1.4061415195465088
Validation loss: 1.986820408093032

Epoch: 5| Step: 9
Training loss: 1.2823407649993896
Validation loss: 1.9595344963894095

Epoch: 5| Step: 10
Training loss: 1.0589613914489746
Validation loss: 1.967808420940112

Epoch: 222| Step: 0
Training loss: 1.2040181159973145
Validation loss: 1.978927787914071

Epoch: 5| Step: 1
Training loss: 0.9840810894966125
Validation loss: 2.006531177028533

Epoch: 5| Step: 2
Training loss: 0.5498839020729065
Validation loss: 2.027155812068652

Epoch: 5| Step: 3
Training loss: 0.7329738736152649
Validation loss: 2.0762666374124508

Epoch: 5| Step: 4
Training loss: 0.9747111201286316
Validation loss: 2.07361739425249

Epoch: 5| Step: 5
Training loss: 0.8713881373405457
Validation loss: 2.054184135570321

Epoch: 5| Step: 6
Training loss: 1.2243521213531494
Validation loss: 2.053087052478585

Epoch: 5| Step: 7
Training loss: 1.050635576248169
Validation loss: 2.049997370730164

Epoch: 5| Step: 8
Training loss: 1.2530138492584229
Validation loss: 2.0226557972610637

Epoch: 5| Step: 9
Training loss: 0.8625353574752808
Validation loss: 2.0349144448516188

Epoch: 5| Step: 10
Training loss: 1.4783272743225098
Validation loss: 1.9783149239837483

Epoch: 223| Step: 0
Training loss: 0.9724552035331726
Validation loss: 1.970667649340886

Epoch: 5| Step: 1
Training loss: 0.9471279382705688
Validation loss: 2.0253478301468717

Epoch: 5| Step: 2
Training loss: 1.085503339767456
Validation loss: 1.9920695558671029

Epoch: 5| Step: 3
Training loss: 1.4150598049163818
Validation loss: 1.9862424430026804

Epoch: 5| Step: 4
Training loss: 0.9210759997367859
Validation loss: 1.9494616241865261

Epoch: 5| Step: 5
Training loss: 0.9829925298690796
Validation loss: 1.933017720458328

Epoch: 5| Step: 6
Training loss: 0.9151284098625183
Validation loss: 1.9332779812556442

Epoch: 5| Step: 7
Training loss: 1.01369309425354
Validation loss: 1.970049794002246

Epoch: 5| Step: 8
Training loss: 0.7592232823371887
Validation loss: 1.9684412646037277

Epoch: 5| Step: 9
Training loss: 0.9390811920166016
Validation loss: 2.0015323815807218

Epoch: 5| Step: 10
Training loss: 1.104442834854126
Validation loss: 2.00323127418436

Epoch: 224| Step: 0
Training loss: 0.9410387873649597
Validation loss: 2.004356199695218

Epoch: 5| Step: 1
Training loss: 0.5197256803512573
Validation loss: 2.0072287231363277

Epoch: 5| Step: 2
Training loss: 0.8957374691963196
Validation loss: 2.00616616331121

Epoch: 5| Step: 3
Training loss: 1.2689682245254517
Validation loss: 2.0050062723057245

Epoch: 5| Step: 4
Training loss: 0.8646278381347656
Validation loss: 1.9774945884622552

Epoch: 5| Step: 5
Training loss: 0.9332854151725769
Validation loss: 1.96032759194733

Epoch: 5| Step: 6
Training loss: 0.6841307878494263
Validation loss: 1.9900639839069818

Epoch: 5| Step: 7
Training loss: 1.18319571018219
Validation loss: 1.9557368998886437

Epoch: 5| Step: 8
Training loss: 0.8678737878799438
Validation loss: 1.9678322884344286

Epoch: 5| Step: 9
Training loss: 1.0870107412338257
Validation loss: 1.9735332612068421

Epoch: 5| Step: 10
Training loss: 1.3526859283447266
Validation loss: 1.9446246803447764

Epoch: 225| Step: 0
Training loss: 0.7541375756263733
Validation loss: 1.9755466804709485

Epoch: 5| Step: 1
Training loss: 1.3206216096878052
Validation loss: 1.94805863852142

Epoch: 5| Step: 2
Training loss: 1.3522790670394897
Validation loss: 1.9677926135319534

Epoch: 5| Step: 3
Training loss: 0.7474664449691772
Validation loss: 1.924656456516635

Epoch: 5| Step: 4
Training loss: 0.7085085511207581
Validation loss: 1.8722883629542526

Epoch: 5| Step: 5
Training loss: 0.9020937085151672
Validation loss: 1.8650162655820128

Epoch: 5| Step: 6
Training loss: 1.287010908126831
Validation loss: 1.9024077025792931

Epoch: 5| Step: 7
Training loss: 0.5862658023834229
Validation loss: 1.9165945822192776

Epoch: 5| Step: 8
Training loss: 1.198915719985962
Validation loss: 1.969002946730583

Epoch: 5| Step: 9
Training loss: 0.9805862307548523
Validation loss: 1.9949170889392975

Epoch: 5| Step: 10
Training loss: 0.6643648147583008
Validation loss: 2.0375603886060816

Epoch: 226| Step: 0
Training loss: 0.8628581166267395
Validation loss: 2.0817372388737176

Epoch: 5| Step: 1
Training loss: 1.1137334108352661
Validation loss: 2.062284473449953

Epoch: 5| Step: 2
Training loss: 0.9359359741210938
Validation loss: 2.039507955633184

Epoch: 5| Step: 3
Training loss: 1.3422625064849854
Validation loss: 1.9706836426129906

Epoch: 5| Step: 4
Training loss: 1.164665937423706
Validation loss: 1.8970791280910533

Epoch: 5| Step: 5
Training loss: 1.2075587511062622
Validation loss: 1.8766920630649855

Epoch: 5| Step: 6
Training loss: 0.4495323598384857
Validation loss: 1.8728899212293728

Epoch: 5| Step: 7
Training loss: 0.9538125991821289
Validation loss: 1.8809784266256517

Epoch: 5| Step: 8
Training loss: 1.0950132608413696
Validation loss: 1.907171881327065

Epoch: 5| Step: 9
Training loss: 0.7641507983207703
Validation loss: 1.9499518025305964

Epoch: 5| Step: 10
Training loss: 0.7176394462585449
Validation loss: 1.9803990599929646

Epoch: 227| Step: 0
Training loss: 1.0449855327606201
Validation loss: 2.0429395732059272

Epoch: 5| Step: 1
Training loss: 1.1544125080108643
Validation loss: 2.1268469441321587

Epoch: 5| Step: 2
Training loss: 0.8162755966186523
Validation loss: 2.1305883699847805

Epoch: 5| Step: 3
Training loss: 0.7430835962295532
Validation loss: 2.0707697765801543

Epoch: 5| Step: 4
Training loss: 1.1737648248672485
Validation loss: 2.012333695606519

Epoch: 5| Step: 5
Training loss: 0.9917553067207336
Validation loss: 1.9623997467820362

Epoch: 5| Step: 6
Training loss: 0.6694949269294739
Validation loss: 1.921358593048588

Epoch: 5| Step: 7
Training loss: 1.0557018518447876
Validation loss: 1.901144443019744

Epoch: 5| Step: 8
Training loss: 1.354137659072876
Validation loss: 1.9073269751764113

Epoch: 5| Step: 9
Training loss: 0.9498518109321594
Validation loss: 1.8679444712977256

Epoch: 5| Step: 10
Training loss: 0.8999271988868713
Validation loss: 1.9042123004954348

Epoch: 228| Step: 0
Training loss: 0.7619209885597229
Validation loss: 1.9503042954270557

Epoch: 5| Step: 1
Training loss: 1.036705493927002
Validation loss: 1.9515371668723323

Epoch: 5| Step: 2
Training loss: 0.8732097744941711
Validation loss: 1.9427769645567863

Epoch: 5| Step: 3
Training loss: 1.168907880783081
Validation loss: 1.8969708053014611

Epoch: 5| Step: 4
Training loss: 0.7895927429199219
Validation loss: 1.880792951071134

Epoch: 5| Step: 5
Training loss: 0.603675365447998
Validation loss: 1.8775970294911375

Epoch: 5| Step: 6
Training loss: 1.0753806829452515
Validation loss: 1.8897060937778924

Epoch: 5| Step: 7
Training loss: 1.0573248863220215
Validation loss: 1.9320121119099278

Epoch: 5| Step: 8
Training loss: 0.985684871673584
Validation loss: 1.9506469708617016

Epoch: 5| Step: 9
Training loss: 1.2035142183303833
Validation loss: 1.9913999880513837

Epoch: 5| Step: 10
Training loss: 1.2438483238220215
Validation loss: 2.032481528097583

Epoch: 229| Step: 0
Training loss: 1.3435089588165283
Validation loss: 2.050465635074082

Epoch: 5| Step: 1
Training loss: 1.000781536102295
Validation loss: 2.0029035076018302

Epoch: 5| Step: 2
Training loss: 1.1365629434585571
Validation loss: 2.0041109156864945

Epoch: 5| Step: 3
Training loss: 0.8182685971260071
Validation loss: 1.9546186693253056

Epoch: 5| Step: 4
Training loss: 0.8433060646057129
Validation loss: 1.9226101713795816

Epoch: 5| Step: 5
Training loss: 0.8295729756355286
Validation loss: 1.8666096515552972

Epoch: 5| Step: 6
Training loss: 0.514776885509491
Validation loss: 1.87854011981718

Epoch: 5| Step: 7
Training loss: 0.7642512321472168
Validation loss: 1.8855851939929429

Epoch: 5| Step: 8
Training loss: 0.7569406032562256
Validation loss: 1.9171455085918467

Epoch: 5| Step: 9
Training loss: 0.9847456216812134
Validation loss: 1.9504366382475822

Epoch: 5| Step: 10
Training loss: 1.3101035356521606
Validation loss: 1.9916723851234681

Epoch: 230| Step: 0
Training loss: 1.1481822729110718
Validation loss: 1.960149331759381

Epoch: 5| Step: 1
Training loss: 0.6155089139938354
Validation loss: 1.9464773131955055

Epoch: 5| Step: 2
Training loss: 1.1272789239883423
Validation loss: 1.9402497430001535

Epoch: 5| Step: 3
Training loss: 1.0764868259429932
Validation loss: 1.9166172012206046

Epoch: 5| Step: 4
Training loss: 0.7375656366348267
Validation loss: 1.931729378238801

Epoch: 5| Step: 5
Training loss: 0.8318105936050415
Validation loss: 1.9443959433545348

Epoch: 5| Step: 6
Training loss: 0.7054296135902405
Validation loss: 1.9691329092107794

Epoch: 5| Step: 7
Training loss: 1.2250851392745972
Validation loss: 1.9872579754039805

Epoch: 5| Step: 8
Training loss: 0.8272266387939453
Validation loss: 1.9778908388589018

Epoch: 5| Step: 9
Training loss: 0.6988013982772827
Validation loss: 2.023916006088257

Epoch: 5| Step: 10
Training loss: 0.959036111831665
Validation loss: 2.0161260174166773

Epoch: 231| Step: 0
Training loss: 0.8947327733039856
Validation loss: 2.0071222653952976

Epoch: 5| Step: 1
Training loss: 1.1731230020523071
Validation loss: 1.977543592453003

Epoch: 5| Step: 2
Training loss: 0.8618986010551453
Validation loss: 2.0028866734555972

Epoch: 5| Step: 3
Training loss: 0.6658385992050171
Validation loss: 2.0107336928767543

Epoch: 5| Step: 4
Training loss: 0.9001483917236328
Validation loss: 1.9952856263806742

Epoch: 5| Step: 5
Training loss: 1.1265668869018555
Validation loss: 2.001621412974532

Epoch: 5| Step: 6
Training loss: 1.2605599164962769
Validation loss: 2.0310968045265443

Epoch: 5| Step: 7
Training loss: 1.00638747215271
Validation loss: 1.9905648949325725

Epoch: 5| Step: 8
Training loss: 0.7120802402496338
Validation loss: 1.9671097058121876

Epoch: 5| Step: 9
Training loss: 0.8697015047073364
Validation loss: 1.933613443887362

Epoch: 5| Step: 10
Training loss: 0.7563444972038269
Validation loss: 1.8956538579797233

Epoch: 232| Step: 0
Training loss: 0.9565654993057251
Validation loss: 1.910930650208586

Epoch: 5| Step: 1
Training loss: 0.8385298848152161
Validation loss: 1.8918623975528184

Epoch: 5| Step: 2
Training loss: 0.7965947985649109
Validation loss: 1.920395605025753

Epoch: 5| Step: 3
Training loss: 1.1046198606491089
Validation loss: 1.96375334647394

Epoch: 5| Step: 4
Training loss: 1.131203293800354
Validation loss: 2.0098696934279574

Epoch: 5| Step: 5
Training loss: 0.8700167536735535
Validation loss: 2.014980040570741

Epoch: 5| Step: 6
Training loss: 0.7384101748466492
Validation loss: 2.049895748015373

Epoch: 5| Step: 7
Training loss: 0.82342129945755
Validation loss: 2.0438892379883797

Epoch: 5| Step: 8
Training loss: 1.254844307899475
Validation loss: 2.028919299443563

Epoch: 5| Step: 9
Training loss: 0.7792753577232361
Validation loss: 2.013309400568726

Epoch: 5| Step: 10
Training loss: 0.5160613059997559
Validation loss: 1.9750444735250166

Epoch: 233| Step: 0
Training loss: 0.8135193586349487
Validation loss: 1.989932680642733

Epoch: 5| Step: 1
Training loss: 0.8159580230712891
Validation loss: 1.998778889256139

Epoch: 5| Step: 2
Training loss: 0.9844304919242859
Validation loss: 1.9909895876402497

Epoch: 5| Step: 3
Training loss: 0.9185489416122437
Validation loss: 2.0300799544139574

Epoch: 5| Step: 4
Training loss: 0.7909342050552368
Validation loss: 1.9915091119786745

Epoch: 5| Step: 5
Training loss: 0.41776666045188904
Validation loss: 1.9685557093671573

Epoch: 5| Step: 6
Training loss: 1.0673516988754272
Validation loss: 1.945500268731066

Epoch: 5| Step: 7
Training loss: 0.5448238253593445
Validation loss: 1.942820365710925

Epoch: 5| Step: 8
Training loss: 0.6385029554367065
Validation loss: 1.9261810664207704

Epoch: 5| Step: 9
Training loss: 1.2743499279022217
Validation loss: 1.9410275913053943

Epoch: 5| Step: 10
Training loss: 1.591460943222046
Validation loss: 1.923661865213866

Epoch: 234| Step: 0
Training loss: 1.0514938831329346
Validation loss: 1.922810140476432

Epoch: 5| Step: 1
Training loss: 0.936404824256897
Validation loss: 1.9008152818167081

Epoch: 5| Step: 2
Training loss: 1.0255805253982544
Validation loss: 1.915487822665963

Epoch: 5| Step: 3
Training loss: 0.9176956415176392
Validation loss: 1.9439887462123748

Epoch: 5| Step: 4
Training loss: 0.6290391683578491
Validation loss: 1.9678482394064627

Epoch: 5| Step: 5
Training loss: 0.9958284497261047
Validation loss: 1.9936230221102316

Epoch: 5| Step: 6
Training loss: 0.934493362903595
Validation loss: 1.9770260818542973

Epoch: 5| Step: 7
Training loss: 0.9362232089042664
Validation loss: 1.9632016843365085

Epoch: 5| Step: 8
Training loss: 0.6289684176445007
Validation loss: 1.9798159624940606

Epoch: 5| Step: 9
Training loss: 0.7709897756576538
Validation loss: 2.00709944130272

Epoch: 5| Step: 10
Training loss: 0.5403060913085938
Validation loss: 1.9658671297052854

Epoch: 235| Step: 0
Training loss: 0.8862983584403992
Validation loss: 1.9529718763084822

Epoch: 5| Step: 1
Training loss: 0.912232518196106
Validation loss: 1.9602196947220834

Epoch: 5| Step: 2
Training loss: 0.6470351219177246
Validation loss: 1.9812436257639239

Epoch: 5| Step: 3
Training loss: 1.305284857749939
Validation loss: 1.9376220331397107

Epoch: 5| Step: 4
Training loss: 0.6524596214294434
Validation loss: 1.9386650400777017

Epoch: 5| Step: 5
Training loss: 0.8862890005111694
Validation loss: 1.920534090329242

Epoch: 5| Step: 6
Training loss: 0.6668240427970886
Validation loss: 1.909043708155232

Epoch: 5| Step: 7
Training loss: 0.7734166383743286
Validation loss: 1.9182507004789127

Epoch: 5| Step: 8
Training loss: 0.8178461790084839
Validation loss: 1.9477310270391486

Epoch: 5| Step: 9
Training loss: 1.0892871618270874
Validation loss: 1.943847970295978

Epoch: 5| Step: 10
Training loss: 1.0666662454605103
Validation loss: 1.9526942417185793

Epoch: 236| Step: 0
Training loss: 0.8460468053817749
Validation loss: 1.9783272281769784

Epoch: 5| Step: 1
Training loss: 0.7779637575149536
Validation loss: 1.9662124546625281

Epoch: 5| Step: 2
Training loss: 0.944342315196991
Validation loss: 1.9721971711804789

Epoch: 5| Step: 3
Training loss: 0.7532358169555664
Validation loss: 1.9577577549924132

Epoch: 5| Step: 4
Training loss: 0.5437314510345459
Validation loss: 1.8918614605421662

Epoch: 5| Step: 5
Training loss: 0.7429416179656982
Validation loss: 1.922928746028613

Epoch: 5| Step: 6
Training loss: 1.0166364908218384
Validation loss: 1.8801433411977624

Epoch: 5| Step: 7
Training loss: 0.7332391738891602
Validation loss: 1.8802185186775782

Epoch: 5| Step: 8
Training loss: 1.042990803718567
Validation loss: 1.9150516269027547

Epoch: 5| Step: 9
Training loss: 0.8661882281303406
Validation loss: 1.958461397437639

Epoch: 5| Step: 10
Training loss: 0.9351696968078613
Validation loss: 1.976784643306527

Epoch: 237| Step: 0
Training loss: 1.0644352436065674
Validation loss: 2.0130044209059847

Epoch: 5| Step: 1
Training loss: 0.990308940410614
Validation loss: 1.9983621015343616

Epoch: 5| Step: 2
Training loss: 0.9713866114616394
Validation loss: 2.0212199893049014

Epoch: 5| Step: 3
Training loss: 0.6612769365310669
Validation loss: 1.9743055156482163

Epoch: 5| Step: 4
Training loss: 1.08625328540802
Validation loss: 2.003532550668204

Epoch: 5| Step: 5
Training loss: 0.7150989174842834
Validation loss: 1.9477507132355885

Epoch: 5| Step: 6
Training loss: 0.8805219531059265
Validation loss: 1.927711643198485

Epoch: 5| Step: 7
Training loss: 0.4103231430053711
Validation loss: 1.9292122856263192

Epoch: 5| Step: 8
Training loss: 0.7792763710021973
Validation loss: 1.9504310777110438

Epoch: 5| Step: 9
Training loss: 0.8152487874031067
Validation loss: 1.9418092363624162

Epoch: 5| Step: 10
Training loss: 0.7940340638160706
Validation loss: 1.9726284985901208

Epoch: 238| Step: 0
Training loss: 0.6958980560302734
Validation loss: 1.9363459515315231

Epoch: 5| Step: 1
Training loss: 0.9341071248054504
Validation loss: 1.9143782866898404

Epoch: 5| Step: 2
Training loss: 0.9166091680526733
Validation loss: 1.889820234749907

Epoch: 5| Step: 3
Training loss: 0.8287464380264282
Validation loss: 1.8778285006041169

Epoch: 5| Step: 4
Training loss: 0.5700181722640991
Validation loss: 1.874553644528953

Epoch: 5| Step: 5
Training loss: 0.9904934763908386
Validation loss: 1.8838338877565117

Epoch: 5| Step: 6
Training loss: 0.8353539705276489
Validation loss: 1.9212293471059492

Epoch: 5| Step: 7
Training loss: 1.3562109470367432
Validation loss: 1.9469205076976488

Epoch: 5| Step: 8
Training loss: 0.9235089421272278
Validation loss: 1.9547332717526344

Epoch: 5| Step: 9
Training loss: 0.6035119295120239
Validation loss: 2.008918781434336

Epoch: 5| Step: 10
Training loss: 0.8661134243011475
Validation loss: 2.042263050233164

Epoch: 239| Step: 0
Training loss: 1.1359763145446777
Validation loss: 2.074698699417935

Epoch: 5| Step: 1
Training loss: 0.9742103815078735
Validation loss: 2.0735711743754726

Epoch: 5| Step: 2
Training loss: 0.5516632795333862
Validation loss: 2.0438979518029

Epoch: 5| Step: 3
Training loss: 1.0652976036071777
Validation loss: 2.016629990711007

Epoch: 5| Step: 4
Training loss: 0.7238972187042236
Validation loss: 2.002678040535219

Epoch: 5| Step: 5
Training loss: 0.7661420702934265
Validation loss: 1.9396023750305176

Epoch: 5| Step: 6
Training loss: 1.0653984546661377
Validation loss: 1.9463271402543592

Epoch: 5| Step: 7
Training loss: 0.5841380953788757
Validation loss: 1.9094376512753066

Epoch: 5| Step: 8
Training loss: 0.9683862924575806
Validation loss: 1.9189744969849944

Epoch: 5| Step: 9
Training loss: 0.6927414536476135
Validation loss: 1.921328592044051

Epoch: 5| Step: 10
Training loss: 0.958301305770874
Validation loss: 1.9319633373650171

Epoch: 240| Step: 0
Training loss: 0.8668403625488281
Validation loss: 1.9625025590260823

Epoch: 5| Step: 1
Training loss: 0.8656466603279114
Validation loss: 1.9418950683327132

Epoch: 5| Step: 2
Training loss: 0.8375066518783569
Validation loss: 1.936951639831707

Epoch: 5| Step: 3
Training loss: 1.007752537727356
Validation loss: 1.966271710652177

Epoch: 5| Step: 4
Training loss: 0.8345922231674194
Validation loss: 1.956772522259784

Epoch: 5| Step: 5
Training loss: 0.7970762848854065
Validation loss: 2.024770043229544

Epoch: 5| Step: 6
Training loss: 0.5286184549331665
Validation loss: 1.9927571794038177

Epoch: 5| Step: 7
Training loss: 1.0040322542190552
Validation loss: 1.998254358127553

Epoch: 5| Step: 8
Training loss: 0.5251719355583191
Validation loss: 1.957102483318698

Epoch: 5| Step: 9
Training loss: 0.8879218101501465
Validation loss: 1.9327279483118365

Epoch: 5| Step: 10
Training loss: 0.8688617944717407
Validation loss: 1.9194082419077556

Epoch: 241| Step: 0
Training loss: 0.5885338187217712
Validation loss: 1.9128688202109387

Epoch: 5| Step: 1
Training loss: 1.1655361652374268
Validation loss: 1.9083173710812804

Epoch: 5| Step: 2
Training loss: 1.0224000215530396
Validation loss: 1.937196667476367

Epoch: 5| Step: 3
Training loss: 0.6378613710403442
Validation loss: 1.9229301124490716

Epoch: 5| Step: 4
Training loss: 0.4161917567253113
Validation loss: 1.9279364783276793

Epoch: 5| Step: 5
Training loss: 0.9495943188667297
Validation loss: 1.965143298590055

Epoch: 5| Step: 6
Training loss: 1.1868401765823364
Validation loss: 1.961479220339047

Epoch: 5| Step: 7
Training loss: 0.791374683380127
Validation loss: 1.9698696239020235

Epoch: 5| Step: 8
Training loss: 0.7519382834434509
Validation loss: 1.9283522854569137

Epoch: 5| Step: 9
Training loss: 0.6208660006523132
Validation loss: 1.95124444782093

Epoch: 5| Step: 10
Training loss: 0.6724119782447815
Validation loss: 1.9524826875296972

Epoch: 242| Step: 0
Training loss: 0.4320452809333801
Validation loss: 1.9004659011799803

Epoch: 5| Step: 1
Training loss: 0.6367542743682861
Validation loss: 1.9299407633402015

Epoch: 5| Step: 2
Training loss: 0.6531321406364441
Validation loss: 1.9265065834086428

Epoch: 5| Step: 3
Training loss: 0.7893370985984802
Validation loss: 1.900427722161816

Epoch: 5| Step: 4
Training loss: 0.5295271873474121
Validation loss: 1.9015353571984075

Epoch: 5| Step: 5
Training loss: 0.7323229908943176
Validation loss: 1.8723664027388378

Epoch: 5| Step: 6
Training loss: 1.2136001586914062
Validation loss: 1.8649552663167317

Epoch: 5| Step: 7
Training loss: 0.7657204866409302
Validation loss: 1.8836087744723085

Epoch: 5| Step: 8
Training loss: 0.8716226816177368
Validation loss: 1.903603881917974

Epoch: 5| Step: 9
Training loss: 0.7930636405944824
Validation loss: 1.9343061934235275

Epoch: 5| Step: 10
Training loss: 1.0855441093444824
Validation loss: 1.9319085574919177

Epoch: 243| Step: 0
Training loss: 1.1969687938690186
Validation loss: 1.9344422740321006

Epoch: 5| Step: 1
Training loss: 0.6986141800880432
Validation loss: 1.9236740912160566

Epoch: 5| Step: 2
Training loss: 0.5642408728599548
Validation loss: 1.9109272687665877

Epoch: 5| Step: 3
Training loss: 0.8785373568534851
Validation loss: 1.8984416530978294

Epoch: 5| Step: 4
Training loss: 0.719900906085968
Validation loss: 1.895968993504842

Epoch: 5| Step: 5
Training loss: 0.5481208562850952
Validation loss: 1.8765241407578992

Epoch: 5| Step: 6
Training loss: 0.6739681959152222
Validation loss: 1.8968609327911048

Epoch: 5| Step: 7
Training loss: 0.7569063901901245
Validation loss: 1.895589990000571

Epoch: 5| Step: 8
Training loss: 0.8460235595703125
Validation loss: 1.9198661260707404

Epoch: 5| Step: 9
Training loss: 0.7674382925033569
Validation loss: 1.9085991292871454

Epoch: 5| Step: 10
Training loss: 0.7903592586517334
Validation loss: 1.9017992609290666

Epoch: 244| Step: 0
Training loss: 0.839472770690918
Validation loss: 1.9120411770318144

Epoch: 5| Step: 1
Training loss: 1.126383662223816
Validation loss: 1.89697693240258

Epoch: 5| Step: 2
Training loss: 0.5765749216079712
Validation loss: 1.8816699712507186

Epoch: 5| Step: 3
Training loss: 0.8822880983352661
Validation loss: 1.888111129883797

Epoch: 5| Step: 4
Training loss: 0.6703829169273376
Validation loss: 1.8590029913892028

Epoch: 5| Step: 5
Training loss: 0.6984027028083801
Validation loss: 1.8595877283362932

Epoch: 5| Step: 6
Training loss: 0.7683283686637878
Validation loss: 1.8900569485079857

Epoch: 5| Step: 7
Training loss: 0.8349924087524414
Validation loss: 1.9054204674177273

Epoch: 5| Step: 8
Training loss: 0.797649621963501
Validation loss: 1.9210619644452167

Epoch: 5| Step: 9
Training loss: 0.5813426971435547
Validation loss: 1.9562538349500267

Epoch: 5| Step: 10
Training loss: 0.6765314340591431
Validation loss: 1.9522871061037945

Epoch: 245| Step: 0
Training loss: 0.6802667379379272
Validation loss: 1.967953162808572

Epoch: 5| Step: 1
Training loss: 0.5793062448501587
Validation loss: 1.9634123361238869

Epoch: 5| Step: 2
Training loss: 0.5059003233909607
Validation loss: 1.9472454004390265

Epoch: 5| Step: 3
Training loss: 0.8762567639350891
Validation loss: 1.9123068035289805

Epoch: 5| Step: 4
Training loss: 0.8014729619026184
Validation loss: 1.8955031800013717

Epoch: 5| Step: 5
Training loss: 0.8241409063339233
Validation loss: 1.8573792621653566

Epoch: 5| Step: 6
Training loss: 0.8759651184082031
Validation loss: 1.8772666992679719

Epoch: 5| Step: 7
Training loss: 0.8229982256889343
Validation loss: 1.8931739548201203

Epoch: 5| Step: 8
Training loss: 0.7049013376235962
Validation loss: 1.8951520663435741

Epoch: 5| Step: 9
Training loss: 0.5291836261749268
Validation loss: 1.901637884878343

Epoch: 5| Step: 10
Training loss: 1.2493317127227783
Validation loss: 1.9405178498196345

Epoch: 246| Step: 0
Training loss: 1.092289686203003
Validation loss: 1.9119326247963855

Epoch: 5| Step: 1
Training loss: 0.5389515161514282
Validation loss: 1.9084117412567139

Epoch: 5| Step: 2
Training loss: 0.9158034324645996
Validation loss: 1.8842158061201855

Epoch: 5| Step: 3
Training loss: 0.9056156873703003
Validation loss: 1.8944443528370192

Epoch: 5| Step: 4
Training loss: 0.5894386768341064
Validation loss: 1.8735846242597025

Epoch: 5| Step: 5
Training loss: 0.6760267019271851
Validation loss: 1.8801533329871394

Epoch: 5| Step: 6
Training loss: 0.6222836375236511
Validation loss: 1.8891857862472534

Epoch: 5| Step: 7
Training loss: 0.691346287727356
Validation loss: 1.8922822321614912

Epoch: 5| Step: 8
Training loss: 0.5507946014404297
Validation loss: 1.93102813536121

Epoch: 5| Step: 9
Training loss: 0.7571040987968445
Validation loss: 1.9838090891479163

Epoch: 5| Step: 10
Training loss: 1.0329267978668213
Validation loss: 1.9361139907631824

Epoch: 247| Step: 0
Training loss: 0.7874308824539185
Validation loss: 1.9344290430827806

Epoch: 5| Step: 1
Training loss: 1.002142071723938
Validation loss: 1.887747847905723

Epoch: 5| Step: 2
Training loss: 0.7488294243812561
Validation loss: 1.9065822106535717

Epoch: 5| Step: 3
Training loss: 0.6860858798027039
Validation loss: 1.9082917218567224

Epoch: 5| Step: 4
Training loss: 0.6284310221672058
Validation loss: 1.8626186309322235

Epoch: 5| Step: 5
Training loss: 0.5528315305709839
Validation loss: 1.8963554623306438

Epoch: 5| Step: 6
Training loss: 0.4246406555175781
Validation loss: 1.883263849443005

Epoch: 5| Step: 7
Training loss: 0.7944844365119934
Validation loss: 1.8930990439589306

Epoch: 5| Step: 8
Training loss: 0.7013567090034485
Validation loss: 1.879697976573821

Epoch: 5| Step: 9
Training loss: 0.7274607419967651
Validation loss: 1.9002278197196223

Epoch: 5| Step: 10
Training loss: 0.940823495388031
Validation loss: 1.918573309016484

Epoch: 248| Step: 0
Training loss: 0.4722272753715515
Validation loss: 1.9290870287085091

Epoch: 5| Step: 1
Training loss: 0.6795223951339722
Validation loss: 1.925187401874091

Epoch: 5| Step: 2
Training loss: 0.8904749751091003
Validation loss: 1.921662252436402

Epoch: 5| Step: 3
Training loss: 0.777193546295166
Validation loss: 1.8823922872543335

Epoch: 5| Step: 4
Training loss: 0.6676813364028931
Validation loss: 1.8743886011903004

Epoch: 5| Step: 5
Training loss: 0.39323776960372925
Validation loss: 1.8501694843333254

Epoch: 5| Step: 6
Training loss: 0.773468554019928
Validation loss: 1.8645927188217

Epoch: 5| Step: 7
Training loss: 1.1569112539291382
Validation loss: 1.8692647795523367

Epoch: 5| Step: 8
Training loss: 0.8485311269760132
Validation loss: 1.8760076915064166

Epoch: 5| Step: 9
Training loss: 0.469036340713501
Validation loss: 1.875311920719762

Epoch: 5| Step: 10
Training loss: 1.0404462814331055
Validation loss: 1.8855819702148438

Epoch: 249| Step: 0
Training loss: 0.9736595153808594
Validation loss: 1.886074057189367

Epoch: 5| Step: 1
Training loss: 0.6827090978622437
Validation loss: 1.9196652302178003

Epoch: 5| Step: 2
Training loss: 0.8514263033866882
Validation loss: 1.9188454689518097

Epoch: 5| Step: 3
Training loss: 0.688473105430603
Validation loss: 1.9051964372716925

Epoch: 5| Step: 4
Training loss: 0.6530369520187378
Validation loss: 1.877449236890321

Epoch: 5| Step: 5
Training loss: 0.9009544253349304
Validation loss: 1.8546237407192108

Epoch: 5| Step: 6
Training loss: 0.8422011137008667
Validation loss: 1.846004028474131

Epoch: 5| Step: 7
Training loss: 0.5416359901428223
Validation loss: 1.8523561134133288

Epoch: 5| Step: 8
Training loss: 0.33227893710136414
Validation loss: 1.8655979697422316

Epoch: 5| Step: 9
Training loss: 0.7180450558662415
Validation loss: 1.9016919353956818

Epoch: 5| Step: 10
Training loss: 0.6646626591682434
Validation loss: 1.920238483336664

Epoch: 250| Step: 0
Training loss: 0.6137844920158386
Validation loss: 1.940564986198179

Epoch: 5| Step: 1
Training loss: 1.0281332731246948
Validation loss: 1.8855815728505452

Epoch: 5| Step: 2
Training loss: 0.5662500858306885
Validation loss: 1.8891746818378408

Epoch: 5| Step: 3
Training loss: 0.6632088422775269
Validation loss: 1.8862829131464804

Epoch: 5| Step: 4
Training loss: 0.44948363304138184
Validation loss: 1.8753337885743828

Epoch: 5| Step: 5
Training loss: 0.8490279316902161
Validation loss: 1.8892766160349692

Epoch: 5| Step: 6
Training loss: 0.48755699396133423
Validation loss: 1.893669948782972

Epoch: 5| Step: 7
Training loss: 0.8534165620803833
Validation loss: 1.9409196376800537

Epoch: 5| Step: 8
Training loss: 0.8106371760368347
Validation loss: 1.9324488332194667

Epoch: 5| Step: 9
Training loss: 0.7142024040222168
Validation loss: 1.91420058537555

Epoch: 5| Step: 10
Training loss: 1.0269349813461304
Validation loss: 1.941013677145845

Epoch: 251| Step: 0
Training loss: 0.7809856534004211
Validation loss: 1.9075626468145719

Epoch: 5| Step: 1
Training loss: 0.6086682677268982
Validation loss: 1.9041132337303572

Epoch: 5| Step: 2
Training loss: 0.8871762156486511
Validation loss: 1.864602952875117

Epoch: 5| Step: 3
Training loss: 1.0738765001296997
Validation loss: 1.919017921211899

Epoch: 5| Step: 4
Training loss: 0.5133795142173767
Validation loss: 1.9136500538036387

Epoch: 5| Step: 5
Training loss: 1.0140866041183472
Validation loss: 1.9022201684213453

Epoch: 5| Step: 6
Training loss: 0.8339047431945801
Validation loss: 1.8923428494443175

Epoch: 5| Step: 7
Training loss: 0.8008505702018738
Validation loss: 1.8420340194497058

Epoch: 5| Step: 8
Training loss: 0.46171480417251587
Validation loss: 1.8552053013155538

Epoch: 5| Step: 9
Training loss: 0.7629057765007019
Validation loss: 1.8432323445555985

Epoch: 5| Step: 10
Training loss: 0.6722144484519958
Validation loss: 1.8361614840005034

Epoch: 252| Step: 0
Training loss: 0.5225480794906616
Validation loss: 1.8557096360832133

Epoch: 5| Step: 1
Training loss: 0.6306014657020569
Validation loss: 1.8833061559225923

Epoch: 5| Step: 2
Training loss: 0.5642958879470825
Validation loss: 1.9271856930948073

Epoch: 5| Step: 3
Training loss: 0.9579465985298157
Validation loss: 1.955454513590823

Epoch: 5| Step: 4
Training loss: 0.7181047201156616
Validation loss: 1.9626538189508582

Epoch: 5| Step: 5
Training loss: 0.8134620785713196
Validation loss: 1.9299590023615028

Epoch: 5| Step: 6
Training loss: 0.573246955871582
Validation loss: 1.8461706894700245

Epoch: 5| Step: 7
Training loss: 0.6451107263565063
Validation loss: 1.8247407328697942

Epoch: 5| Step: 8
Training loss: 0.7329541444778442
Validation loss: 1.8143592021798576

Epoch: 5| Step: 9
Training loss: 0.7479260563850403
Validation loss: 1.8292562615486883

Epoch: 5| Step: 10
Training loss: 1.2076306343078613
Validation loss: 1.8452466508393646

Epoch: 253| Step: 0
Training loss: 0.8410269021987915
Validation loss: 1.8746011205898818

Epoch: 5| Step: 1
Training loss: 0.6936074495315552
Validation loss: 1.9287936328559794

Epoch: 5| Step: 2
Training loss: 0.4955471158027649
Validation loss: 1.9685661408209032

Epoch: 5| Step: 3
Training loss: 0.7271264791488647
Validation loss: 1.9934383425661313

Epoch: 5| Step: 4
Training loss: 0.7248403429985046
Validation loss: 1.967492195867723

Epoch: 5| Step: 5
Training loss: 0.7906097173690796
Validation loss: 1.9697850699065833

Epoch: 5| Step: 6
Training loss: 0.37876737117767334
Validation loss: 1.9269326297185754

Epoch: 5| Step: 7
Training loss: 0.8682327270507812
Validation loss: 1.9051541820649178

Epoch: 5| Step: 8
Training loss: 0.5280097723007202
Validation loss: 1.8395957844231718

Epoch: 5| Step: 9
Training loss: 0.8911458849906921
Validation loss: 1.8336699278123918

Epoch: 5| Step: 10
Training loss: 0.8589774370193481
Validation loss: 1.84111064352015

Epoch: 254| Step: 0
Training loss: 0.7693878412246704
Validation loss: 1.8247656412022089

Epoch: 5| Step: 1
Training loss: 0.7535020112991333
Validation loss: 1.8713138103485107

Epoch: 5| Step: 2
Training loss: 0.6786614656448364
Validation loss: 1.894096238638765

Epoch: 5| Step: 3
Training loss: 0.7299591898918152
Validation loss: 1.9433327721011253

Epoch: 5| Step: 4
Training loss: 0.8081551790237427
Validation loss: 1.9320323569800264

Epoch: 5| Step: 5
Training loss: 0.6306911706924438
Validation loss: 1.897135091084306

Epoch: 5| Step: 6
Training loss: 0.4815695881843567
Validation loss: 1.9060047416276829

Epoch: 5| Step: 7
Training loss: 0.7896999716758728
Validation loss: 1.89625411136176

Epoch: 5| Step: 8
Training loss: 0.8257878422737122
Validation loss: 1.8586889864296041

Epoch: 5| Step: 9
Training loss: 0.6517347097396851
Validation loss: 1.8578327855756205

Epoch: 5| Step: 10
Training loss: 0.5440401434898376
Validation loss: 1.8632063724661385

Epoch: 255| Step: 0
Training loss: 0.6923138499259949
Validation loss: 1.8444156287818827

Epoch: 5| Step: 1
Training loss: 0.826330840587616
Validation loss: 1.840276127220482

Epoch: 5| Step: 2
Training loss: 0.7281867861747742
Validation loss: 1.82667891440853

Epoch: 5| Step: 3
Training loss: 0.7027119398117065
Validation loss: 1.824814138873931

Epoch: 5| Step: 4
Training loss: 0.6241531372070312
Validation loss: 1.8337237194020262

Epoch: 5| Step: 5
Training loss: 0.7048859000205994
Validation loss: 1.86474565024017

Epoch: 5| Step: 6
Training loss: 0.7123152613639832
Validation loss: 1.8927135775166173

Epoch: 5| Step: 7
Training loss: 0.8171841502189636
Validation loss: 1.8792264948609054

Epoch: 5| Step: 8
Training loss: 0.7659260630607605
Validation loss: 1.8310944905845068

Epoch: 5| Step: 9
Training loss: 0.6312141418457031
Validation loss: 1.8166923830586095

Epoch: 5| Step: 10
Training loss: 0.7073720097541809
Validation loss: 1.7900932834994407

Epoch: 256| Step: 0
Training loss: 0.538801372051239
Validation loss: 1.8261503058095132

Epoch: 5| Step: 1
Training loss: 0.6736100316047668
Validation loss: 1.8278447120420394

Epoch: 5| Step: 2
Training loss: 0.6751407980918884
Validation loss: 1.881496871671369

Epoch: 5| Step: 3
Training loss: 0.8531366586685181
Validation loss: 1.8668674269030172

Epoch: 5| Step: 4
Training loss: 0.8585060238838196
Validation loss: 1.8450267417456514

Epoch: 5| Step: 5
Training loss: 0.7811262011528015
Validation loss: 1.8693512498691518

Epoch: 5| Step: 6
Training loss: 0.4837571084499359
Validation loss: 1.8607527261139245

Epoch: 5| Step: 7
Training loss: 0.8916662335395813
Validation loss: 1.8534495817717684

Epoch: 5| Step: 8
Training loss: 0.814952552318573
Validation loss: 1.8894231498882335

Epoch: 5| Step: 9
Training loss: 0.3602583706378937
Validation loss: 1.8751542234933505

Epoch: 5| Step: 10
Training loss: 0.7641165852546692
Validation loss: 1.8876436756503197

Epoch: 257| Step: 0
Training loss: 0.7248668074607849
Validation loss: 1.8874234602015505

Epoch: 5| Step: 1
Training loss: 0.8067646026611328
Validation loss: 1.879678944105743

Epoch: 5| Step: 2
Training loss: 0.6100900173187256
Validation loss: 1.9076203453925349

Epoch: 5| Step: 3
Training loss: 0.49359649419784546
Validation loss: 1.9446387419136621

Epoch: 5| Step: 4
Training loss: 0.4582686424255371
Validation loss: 1.9480546674420756

Epoch: 5| Step: 5
Training loss: 0.6396140456199646
Validation loss: 1.9349207647385136

Epoch: 5| Step: 6
Training loss: 0.7965006232261658
Validation loss: 1.9527183168677873

Epoch: 5| Step: 7
Training loss: 0.6421419978141785
Validation loss: 1.9444611815996067

Epoch: 5| Step: 8
Training loss: 0.6374433636665344
Validation loss: 1.8941299902495516

Epoch: 5| Step: 9
Training loss: 0.7175542712211609
Validation loss: 1.890112994819559

Epoch: 5| Step: 10
Training loss: 0.9382853507995605
Validation loss: 1.9030176272956274

Epoch: 258| Step: 0
Training loss: 0.47331637144088745
Validation loss: 1.8757768318217287

Epoch: 5| Step: 1
Training loss: 0.5706920027732849
Validation loss: 1.8899508919767154

Epoch: 5| Step: 2
Training loss: 0.5556744933128357
Validation loss: 1.8851580465993574

Epoch: 5| Step: 3
Training loss: 0.6730581521987915
Validation loss: 1.9110489186420236

Epoch: 5| Step: 4
Training loss: 0.5945421457290649
Validation loss: 1.9250702716970955

Epoch: 5| Step: 5
Training loss: 0.8051708340644836
Validation loss: 1.8970607762695642

Epoch: 5| Step: 6
Training loss: 0.5702071785926819
Validation loss: 1.887565593565664

Epoch: 5| Step: 7
Training loss: 0.9092071652412415
Validation loss: 1.8858581871114752

Epoch: 5| Step: 8
Training loss: 0.926619827747345
Validation loss: 1.857936074656825

Epoch: 5| Step: 9
Training loss: 0.6181827783584595
Validation loss: 1.878567522571933

Epoch: 5| Step: 10
Training loss: 0.7351165413856506
Validation loss: 1.8453875562196136

Epoch: 259| Step: 0
Training loss: 1.0717999935150146
Validation loss: 1.8975220136745001

Epoch: 5| Step: 1
Training loss: 0.7500591278076172
Validation loss: 1.8648979817667315

Epoch: 5| Step: 2
Training loss: 0.7515906095504761
Validation loss: 1.8796183370774793

Epoch: 5| Step: 3
Training loss: 0.39295870065689087
Validation loss: 1.8979914649840324

Epoch: 5| Step: 4
Training loss: 0.6482201814651489
Validation loss: 1.9242987966024747

Epoch: 5| Step: 5
Training loss: 0.7081993222236633
Validation loss: 1.9349570806308458

Epoch: 5| Step: 6
Training loss: 0.6118674874305725
Validation loss: 1.8807132256928312

Epoch: 5| Step: 7
Training loss: 0.4924265444278717
Validation loss: 1.8214951022978751

Epoch: 5| Step: 8
Training loss: 0.5956268906593323
Validation loss: 1.856208647451093

Epoch: 5| Step: 9
Training loss: 0.5978583097457886
Validation loss: 1.837786562981144

Epoch: 5| Step: 10
Training loss: 0.5904203057289124
Validation loss: 1.8579086014019546

Epoch: 260| Step: 0
Training loss: 0.6944028735160828
Validation loss: 1.8911080783413303

Epoch: 5| Step: 1
Training loss: 0.7066960334777832
Validation loss: 1.901906713362663

Epoch: 5| Step: 2
Training loss: 0.5824546217918396
Validation loss: 1.881780529534945

Epoch: 5| Step: 3
Training loss: 0.6358790397644043
Validation loss: 1.8854778658959173

Epoch: 5| Step: 4
Training loss: 0.8896604776382446
Validation loss: 1.8330816222775368

Epoch: 5| Step: 5
Training loss: 0.5013788342475891
Validation loss: 1.8104399493945542

Epoch: 5| Step: 6
Training loss: 0.6044771671295166
Validation loss: 1.7995531276990009

Epoch: 5| Step: 7
Training loss: 0.7878373265266418
Validation loss: 1.8226442055035663

Epoch: 5| Step: 8
Training loss: 0.899131178855896
Validation loss: 1.7864801473515008

Epoch: 5| Step: 9
Training loss: 0.6575977802276611
Validation loss: 1.7871310351997294

Epoch: 5| Step: 10
Training loss: 0.483383446931839
Validation loss: 1.8260672143710557

Epoch: 261| Step: 0
Training loss: 0.6840112209320068
Validation loss: 1.86566315415085

Epoch: 5| Step: 1
Training loss: 0.5116259455680847
Validation loss: 1.8994899385718889

Epoch: 5| Step: 2
Training loss: 0.9248547554016113
Validation loss: 1.9066978500735374

Epoch: 5| Step: 3
Training loss: 0.4869515895843506
Validation loss: 1.8808655867012598

Epoch: 5| Step: 4
Training loss: 0.45291218161582947
Validation loss: 1.850776785163469

Epoch: 5| Step: 5
Training loss: 0.5772643685340881
Validation loss: 1.834923162255236

Epoch: 5| Step: 6
Training loss: 0.757848858833313
Validation loss: 1.854109130879884

Epoch: 5| Step: 7
Training loss: 0.7096113562583923
Validation loss: 1.8471420362431517

Epoch: 5| Step: 8
Training loss: 0.494727224111557
Validation loss: 1.8991869277851556

Epoch: 5| Step: 9
Training loss: 0.9564472436904907
Validation loss: 1.9116173533983127

Epoch: 5| Step: 10
Training loss: 0.6450878977775574
Validation loss: 1.9094710068036151

Epoch: 262| Step: 0
Training loss: 0.8515917062759399
Validation loss: 1.9069958681701331

Epoch: 5| Step: 1
Training loss: 0.5901576280593872
Validation loss: 1.9019184945732035

Epoch: 5| Step: 2
Training loss: 0.5420104265213013
Validation loss: 1.8504923300076557

Epoch: 5| Step: 3
Training loss: 0.7148405909538269
Validation loss: 1.8518769433421474

Epoch: 5| Step: 4
Training loss: 0.8447639346122742
Validation loss: 1.8058873171447425

Epoch: 5| Step: 5
Training loss: 0.6662836074829102
Validation loss: 1.7790052788231963

Epoch: 5| Step: 6
Training loss: 0.7066456079483032
Validation loss: 1.7750403419617684

Epoch: 5| Step: 7
Training loss: 0.6932758688926697
Validation loss: 1.7878354762190132

Epoch: 5| Step: 8
Training loss: 0.6081485748291016
Validation loss: 1.7859455539334206

Epoch: 5| Step: 9
Training loss: 0.5487545728683472
Validation loss: 1.8365125963764806

Epoch: 5| Step: 10
Training loss: 0.3807000517845154
Validation loss: 1.81690840823676

Epoch: 263| Step: 0
Training loss: 0.5695910453796387
Validation loss: 1.8483603154459307

Epoch: 5| Step: 1
Training loss: 0.31850266456604004
Validation loss: 1.8322835481295021

Epoch: 5| Step: 2
Training loss: 0.5689820051193237
Validation loss: 1.8351783675532187

Epoch: 5| Step: 3
Training loss: 0.7707738876342773
Validation loss: 1.821241650530087

Epoch: 5| Step: 4
Training loss: 0.7737115621566772
Validation loss: 1.7979383930083244

Epoch: 5| Step: 5
Training loss: 0.7096585035324097
Validation loss: 1.817115306854248

Epoch: 5| Step: 6
Training loss: 0.8499851226806641
Validation loss: 1.8308908785543134

Epoch: 5| Step: 7
Training loss: 0.44508862495422363
Validation loss: 1.820976165033156

Epoch: 5| Step: 8
Training loss: 0.7662073373794556
Validation loss: 1.8332338627948557

Epoch: 5| Step: 9
Training loss: 0.6587054133415222
Validation loss: 1.8468059544922204

Epoch: 5| Step: 10
Training loss: 0.4413827359676361
Validation loss: 1.9234418458836053

Epoch: 264| Step: 0
Training loss: 0.6933678388595581
Validation loss: 1.9235002084444928

Epoch: 5| Step: 1
Training loss: 0.3216291666030884
Validation loss: 1.8911502656116281

Epoch: 5| Step: 2
Training loss: 0.612773060798645
Validation loss: 1.897261328594659

Epoch: 5| Step: 3
Training loss: 0.3259614109992981
Validation loss: 1.8550093430344776

Epoch: 5| Step: 4
Training loss: 0.699876606464386
Validation loss: 1.8498691922874861

Epoch: 5| Step: 5
Training loss: 0.5506768822669983
Validation loss: 1.8134424891523135

Epoch: 5| Step: 6
Training loss: 0.6369466781616211
Validation loss: 1.8001176759760866

Epoch: 5| Step: 7
Training loss: 0.7636281847953796
Validation loss: 1.7724622577749274

Epoch: 5| Step: 8
Training loss: 0.613105833530426
Validation loss: 1.7536227228820964

Epoch: 5| Step: 9
Training loss: 0.8971854448318481
Validation loss: 1.7391737891781716

Epoch: 5| Step: 10
Training loss: 0.5500763058662415
Validation loss: 1.7679219592002131

Epoch: 265| Step: 0
Training loss: 0.4030037820339203
Validation loss: 1.7393189553291566

Epoch: 5| Step: 1
Training loss: 0.6259051561355591
Validation loss: 1.8125206719162643

Epoch: 5| Step: 2
Training loss: 0.8164782524108887
Validation loss: 1.8155213671345865

Epoch: 5| Step: 3
Training loss: 0.6829420328140259
Validation loss: 1.8461199652764104

Epoch: 5| Step: 4
Training loss: 0.6660124659538269
Validation loss: 1.8014404773712158

Epoch: 5| Step: 5
Training loss: 0.6168292760848999
Validation loss: 1.765990097035644

Epoch: 5| Step: 6
Training loss: 0.3262059986591339
Validation loss: 1.8011058838136735

Epoch: 5| Step: 7
Training loss: 0.5942960381507874
Validation loss: 1.806595943307364

Epoch: 5| Step: 8
Training loss: 0.8017061948776245
Validation loss: 1.8348788061449606

Epoch: 5| Step: 9
Training loss: 0.6744250655174255
Validation loss: 1.8293611336779851

Epoch: 5| Step: 10
Training loss: 0.5583267211914062
Validation loss: 1.835448085620839

Epoch: 266| Step: 0
Training loss: 0.4251367151737213
Validation loss: 1.8313591685346378

Epoch: 5| Step: 1
Training loss: 0.6506811380386353
Validation loss: 1.8454241380896619

Epoch: 5| Step: 2
Training loss: 0.5748499631881714
Validation loss: 1.8823988437652588

Epoch: 5| Step: 3
Training loss: 0.8968106508255005
Validation loss: 1.9013085173022362

Epoch: 5| Step: 4
Training loss: 0.7944422960281372
Validation loss: 1.873090265899576

Epoch: 5| Step: 5
Training loss: 0.7127208709716797
Validation loss: 1.8642134333169589

Epoch: 5| Step: 6
Training loss: 0.58570396900177
Validation loss: 1.8228498299916585

Epoch: 5| Step: 7
Training loss: 0.3739597201347351
Validation loss: 1.8152336215460172

Epoch: 5| Step: 8
Training loss: 0.4736320376396179
Validation loss: 1.8137695122790594

Epoch: 5| Step: 9
Training loss: 0.3359428346157074
Validation loss: 1.8171984457200574

Epoch: 5| Step: 10
Training loss: 0.718097984790802
Validation loss: 1.817101050448674

Epoch: 267| Step: 0
Training loss: 0.3679887354373932
Validation loss: 1.822910080673874

Epoch: 5| Step: 1
Training loss: 0.6024099588394165
Validation loss: 1.864383751346219

Epoch: 5| Step: 2
Training loss: 0.5465985536575317
Validation loss: 1.8188989098354051

Epoch: 5| Step: 3
Training loss: 0.7601539492607117
Validation loss: 1.8607843563120852

Epoch: 5| Step: 4
Training loss: 0.7729252576828003
Validation loss: 1.875883758708995

Epoch: 5| Step: 5
Training loss: 0.514678955078125
Validation loss: 1.8428994417190552

Epoch: 5| Step: 6
Training loss: 0.6627271771430969
Validation loss: 1.8319335394008185

Epoch: 5| Step: 7
Training loss: 0.5803003311157227
Validation loss: 1.8140086948230703

Epoch: 5| Step: 8
Training loss: 0.486084520816803
Validation loss: 1.7528115998032272

Epoch: 5| Step: 9
Training loss: 0.6821479201316833
Validation loss: 1.7559657276317637

Epoch: 5| Step: 10
Training loss: 0.5814273357391357
Validation loss: 1.7479758941999046

Epoch: 268| Step: 0
Training loss: 0.41671139001846313
Validation loss: 1.768915271246305

Epoch: 5| Step: 1
Training loss: 0.5468583703041077
Validation loss: 1.7873637086601668

Epoch: 5| Step: 2
Training loss: 0.5890929102897644
Validation loss: 1.779656453799176

Epoch: 5| Step: 3
Training loss: 0.6141501069068909
Validation loss: 1.778068801408173

Epoch: 5| Step: 4
Training loss: 0.6430805325508118
Validation loss: 1.7731396382854832

Epoch: 5| Step: 5
Training loss: 0.49119147658348083
Validation loss: 1.799636172991927

Epoch: 5| Step: 6
Training loss: 0.6490944623947144
Validation loss: 1.7814929087956746

Epoch: 5| Step: 7
Training loss: 0.5349710583686829
Validation loss: 1.797468259770383

Epoch: 5| Step: 8
Training loss: 0.33158499002456665
Validation loss: 1.7864827289376208

Epoch: 5| Step: 9
Training loss: 0.7859843373298645
Validation loss: 1.81562985656082

Epoch: 5| Step: 10
Training loss: 0.6566656231880188
Validation loss: 1.801556711555809

Epoch: 269| Step: 0
Training loss: 0.5268114805221558
Validation loss: 1.7813996153493081

Epoch: 5| Step: 1
Training loss: 0.5192310214042664
Validation loss: 1.795797360840664

Epoch: 5| Step: 2
Training loss: 0.4807822108268738
Validation loss: 1.7849677326858684

Epoch: 5| Step: 3
Training loss: 1.0019869804382324
Validation loss: 1.7665469684908468

Epoch: 5| Step: 4
Training loss: 0.5979536175727844
Validation loss: 1.7731489840374197

Epoch: 5| Step: 5
Training loss: 0.7406343221664429
Validation loss: 1.7839101296599194

Epoch: 5| Step: 6
Training loss: 0.3925377428531647
Validation loss: 1.7518587548245665

Epoch: 5| Step: 7
Training loss: 0.4514501690864563
Validation loss: 1.769654800814967

Epoch: 5| Step: 8
Training loss: 0.36437320709228516
Validation loss: 1.7783373889102732

Epoch: 5| Step: 9
Training loss: 0.5259774923324585
Validation loss: 1.805554997536444

Epoch: 5| Step: 10
Training loss: 0.44899803400039673
Validation loss: 1.8079375605429373

Epoch: 270| Step: 0
Training loss: 0.2390022724866867
Validation loss: 1.802121288032942

Epoch: 5| Step: 1
Training loss: 0.6288172006607056
Validation loss: 1.8757652287842126

Epoch: 5| Step: 2
Training loss: 1.0150970220565796
Validation loss: 1.8535041039989841

Epoch: 5| Step: 3
Training loss: 0.45158880949020386
Validation loss: 1.8617663280938261

Epoch: 5| Step: 4
Training loss: 0.990857720375061
Validation loss: 1.8064937873553204

Epoch: 5| Step: 5
Training loss: 0.4155732989311218
Validation loss: 1.8028978622087868

Epoch: 5| Step: 6
Training loss: 0.5340642929077148
Validation loss: 1.773835051444269

Epoch: 5| Step: 7
Training loss: 0.6387227773666382
Validation loss: 1.761183637444691

Epoch: 5| Step: 8
Training loss: 0.5225033164024353
Validation loss: 1.774844399062536

Epoch: 5| Step: 9
Training loss: 0.439598947763443
Validation loss: 1.7659566287071473

Epoch: 5| Step: 10
Training loss: 0.6920596957206726
Validation loss: 1.8088907452039822

Epoch: 271| Step: 0
Training loss: 0.45139455795288086
Validation loss: 1.8419512612845308

Epoch: 5| Step: 1
Training loss: 0.39923641085624695
Validation loss: 1.831062420721977

Epoch: 5| Step: 2
Training loss: 0.40859946608543396
Validation loss: 1.8725770276079896

Epoch: 5| Step: 3
Training loss: 0.9251490831375122
Validation loss: 1.8356754497815204

Epoch: 5| Step: 4
Training loss: 0.5484967231750488
Validation loss: 1.8218435664330759

Epoch: 5| Step: 5
Training loss: 0.7842193841934204
Validation loss: 1.809143756025581

Epoch: 5| Step: 6
Training loss: 0.6086835861206055
Validation loss: 1.7907661340569938

Epoch: 5| Step: 7
Training loss: 0.9448490142822266
Validation loss: 1.7849270195089362

Epoch: 5| Step: 8
Training loss: 0.40555810928344727
Validation loss: 1.7772291027089602

Epoch: 5| Step: 9
Training loss: 0.3858562111854553
Validation loss: 1.7492821101219422

Epoch: 5| Step: 10
Training loss: 0.44736918807029724
Validation loss: 1.7998440650201613

Epoch: 272| Step: 0
Training loss: 0.7138410210609436
Validation loss: 1.8056056627663233

Epoch: 5| Step: 1
Training loss: 0.6273508071899414
Validation loss: 1.7960403093727686

Epoch: 5| Step: 2
Training loss: 0.4781108498573303
Validation loss: 1.7720149896478141

Epoch: 5| Step: 3
Training loss: 0.864092230796814
Validation loss: 1.746252768783159

Epoch: 5| Step: 4
Training loss: 0.4001380503177643
Validation loss: 1.7540505880950599

Epoch: 5| Step: 5
Training loss: 0.5922755002975464
Validation loss: 1.7266373198519471

Epoch: 5| Step: 6
Training loss: 0.6902294754981995
Validation loss: 1.688662593082715

Epoch: 5| Step: 7
Training loss: 0.5563373565673828
Validation loss: 1.7342161401625602

Epoch: 5| Step: 8
Training loss: 0.5635589957237244
Validation loss: 1.7218736730596071

Epoch: 5| Step: 9
Training loss: 0.5600055456161499
Validation loss: 1.7715388446725824

Epoch: 5| Step: 10
Training loss: 0.49853986501693726
Validation loss: 1.7541508854076426

Epoch: 273| Step: 0
Training loss: 0.47437596321105957
Validation loss: 1.798211811691202

Epoch: 5| Step: 1
Training loss: 0.655980110168457
Validation loss: 1.8009749753500826

Epoch: 5| Step: 2
Training loss: 0.7896605730056763
Validation loss: 1.8747269056176628

Epoch: 5| Step: 3
Training loss: 0.38519105315208435
Validation loss: 1.9170314112017233

Epoch: 5| Step: 4
Training loss: 0.8334833383560181
Validation loss: 1.9406188790516188

Epoch: 5| Step: 5
Training loss: 0.5651528835296631
Validation loss: 1.9085783496979745

Epoch: 5| Step: 6
Training loss: 0.6183550357818604
Validation loss: 1.9082275385497718

Epoch: 5| Step: 7
Training loss: 0.39726415276527405
Validation loss: 1.8095573532965876

Epoch: 5| Step: 8
Training loss: 0.9097793698310852
Validation loss: 1.7998852345251268

Epoch: 5| Step: 9
Training loss: 0.5522670149803162
Validation loss: 1.765035633117922

Epoch: 5| Step: 10
Training loss: 0.3942677974700928
Validation loss: 1.8022082928688294

Epoch: 274| Step: 0
Training loss: 0.3481515049934387
Validation loss: 1.7889033440620667

Epoch: 5| Step: 1
Training loss: 0.6925691366195679
Validation loss: 1.819002389907837

Epoch: 5| Step: 2
Training loss: 0.3388371467590332
Validation loss: 1.837976973543885

Epoch: 5| Step: 3
Training loss: 0.5049247145652771
Validation loss: 1.8156564004959599

Epoch: 5| Step: 4
Training loss: 0.5861340761184692
Validation loss: 1.838743120111445

Epoch: 5| Step: 5
Training loss: 0.8169983625411987
Validation loss: 1.791810558688256

Epoch: 5| Step: 6
Training loss: 0.6567164659500122
Validation loss: 1.8003134919751076

Epoch: 5| Step: 7
Training loss: 0.5394631624221802
Validation loss: 1.805842363706199

Epoch: 5| Step: 8
Training loss: 0.4561861455440521
Validation loss: 1.7585414917238298

Epoch: 5| Step: 9
Training loss: 0.856280505657196
Validation loss: 1.7826078091898272

Epoch: 5| Step: 10
Training loss: 0.4073111414909363
Validation loss: 1.757413350766705

Epoch: 275| Step: 0
Training loss: 0.4661107659339905
Validation loss: 1.7969192151100404

Epoch: 5| Step: 1
Training loss: 0.6528211832046509
Validation loss: 1.8211604920766686

Epoch: 5| Step: 2
Training loss: 0.6885391473770142
Validation loss: 1.8190261369110436

Epoch: 5| Step: 3
Training loss: 0.5014615058898926
Validation loss: 1.8399077000156525

Epoch: 5| Step: 4
Training loss: 0.30287715792655945
Validation loss: 1.7963247119739492

Epoch: 5| Step: 5
Training loss: 0.3887755572795868
Validation loss: 1.7982455889383953

Epoch: 5| Step: 6
Training loss: 0.5871143341064453
Validation loss: 1.8117887781512352

Epoch: 5| Step: 7
Training loss: 0.5630157589912415
Validation loss: 1.809549944375151

Epoch: 5| Step: 8
Training loss: 0.6352804899215698
Validation loss: 1.8173533780600435

Epoch: 5| Step: 9
Training loss: 0.36984723806381226
Validation loss: 1.789155258927294

Epoch: 5| Step: 10
Training loss: 0.6020256280899048
Validation loss: 1.8049672970207788

Epoch: 276| Step: 0
Training loss: 0.6164058446884155
Validation loss: 1.7989343994407243

Epoch: 5| Step: 1
Training loss: 0.7623642086982727
Validation loss: 1.7996311982472737

Epoch: 5| Step: 2
Training loss: 0.49983078241348267
Validation loss: 1.800362317792831

Epoch: 5| Step: 3
Training loss: 0.4743366241455078
Validation loss: 1.7948100464318388

Epoch: 5| Step: 4
Training loss: 0.35277286171913147
Validation loss: 1.7783357635621102

Epoch: 5| Step: 5
Training loss: 0.3416209816932678
Validation loss: 1.7549905443704257

Epoch: 5| Step: 6
Training loss: 0.5066202282905579
Validation loss: 1.7311898380197503

Epoch: 5| Step: 7
Training loss: 0.5861927270889282
Validation loss: 1.7515537764436455

Epoch: 5| Step: 8
Training loss: 0.6543681621551514
Validation loss: 1.7232850764387397

Epoch: 5| Step: 9
Training loss: 0.5604349970817566
Validation loss: 1.730760105194584

Epoch: 5| Step: 10
Training loss: 0.31809690594673157
Validation loss: 1.747959788127612

Epoch: 277| Step: 0
Training loss: 0.6763259172439575
Validation loss: 1.7523278292789255

Epoch: 5| Step: 1
Training loss: 0.5909672975540161
Validation loss: 1.7727516210207375

Epoch: 5| Step: 2
Training loss: 0.3858018219470978
Validation loss: 1.8047599625843826

Epoch: 5| Step: 3
Training loss: 0.2593464255332947
Validation loss: 1.806372655335293

Epoch: 5| Step: 4
Training loss: 0.537619948387146
Validation loss: 1.8188953374021797

Epoch: 5| Step: 5
Training loss: 0.3988276422023773
Validation loss: 1.7973265904252247

Epoch: 5| Step: 6
Training loss: 0.6730985641479492
Validation loss: 1.7923453905249154

Epoch: 5| Step: 7
Training loss: 0.44224387407302856
Validation loss: 1.7922842374411962

Epoch: 5| Step: 8
Training loss: 0.3860960304737091
Validation loss: 1.7845294860101515

Epoch: 5| Step: 9
Training loss: 0.6245704889297485
Validation loss: 1.7594073626302904

Epoch: 5| Step: 10
Training loss: 0.4887656569480896
Validation loss: 1.720400312895416

Epoch: 278| Step: 0
Training loss: 0.3564867675304413
Validation loss: 1.7222407530712824

Epoch: 5| Step: 1
Training loss: 0.2727004587650299
Validation loss: 1.742635324437131

Epoch: 5| Step: 2
Training loss: 0.6439434289932251
Validation loss: 1.7454391833274596

Epoch: 5| Step: 3
Training loss: 0.654403805732727
Validation loss: 1.7615059934636599

Epoch: 5| Step: 4
Training loss: 0.650750994682312
Validation loss: 1.7718646667336906

Epoch: 5| Step: 5
Training loss: 0.3460499942302704
Validation loss: 1.7427443150551087

Epoch: 5| Step: 6
Training loss: 0.6840096712112427
Validation loss: 1.7595363201633576

Epoch: 5| Step: 7
Training loss: 0.42702850699424744
Validation loss: 1.7930824641258485

Epoch: 5| Step: 8
Training loss: 0.5063673853874207
Validation loss: 1.7843181779307704

Epoch: 5| Step: 9
Training loss: 0.27331775426864624
Validation loss: 1.8164907283680414

Epoch: 5| Step: 10
Training loss: 0.6923204660415649
Validation loss: 1.7981600120503416

Epoch: 279| Step: 0
Training loss: 0.28069978952407837
Validation loss: 1.7731868861823954

Epoch: 5| Step: 1
Training loss: 0.3747180998325348
Validation loss: 1.784009506625514

Epoch: 5| Step: 2
Training loss: 0.6238778829574585
Validation loss: 1.7928561549032889

Epoch: 5| Step: 3
Training loss: 0.7088244557380676
Validation loss: 1.7558855138799196

Epoch: 5| Step: 4
Training loss: 0.5028002858161926
Validation loss: 1.7745968398227487

Epoch: 5| Step: 5
Training loss: 0.47985410690307617
Validation loss: 1.7670998983485724

Epoch: 5| Step: 6
Training loss: 0.6341180205345154
Validation loss: 1.7569829610086256

Epoch: 5| Step: 7
Training loss: 0.52330482006073
Validation loss: 1.7587249586659093

Epoch: 5| Step: 8
Training loss: 0.6255184412002563
Validation loss: 1.7596254284663866

Epoch: 5| Step: 9
Training loss: 0.2941562235355377
Validation loss: 1.7790546404418124

Epoch: 5| Step: 10
Training loss: 0.21172335743904114
Validation loss: 1.7756744456547562

Epoch: 280| Step: 0
Training loss: 0.5699197053909302
Validation loss: 1.7980311352719542

Epoch: 5| Step: 1
Training loss: 0.3611593246459961
Validation loss: 1.7966464732282905

Epoch: 5| Step: 2
Training loss: 0.4880271553993225
Validation loss: 1.8413146670146654

Epoch: 5| Step: 3
Training loss: 0.447561651468277
Validation loss: 1.7918254649767311

Epoch: 5| Step: 4
Training loss: 0.5158042907714844
Validation loss: 1.743647188268682

Epoch: 5| Step: 5
Training loss: 0.5334035754203796
Validation loss: 1.7530779377106698

Epoch: 5| Step: 6
Training loss: 0.6133410930633545
Validation loss: 1.743904257333407

Epoch: 5| Step: 7
Training loss: 0.5998417735099792
Validation loss: 1.7200625468325872

Epoch: 5| Step: 8
Training loss: 0.3764309287071228
Validation loss: 1.7138760397511144

Epoch: 5| Step: 9
Training loss: 0.5216716527938843
Validation loss: 1.7111007167446999

Epoch: 5| Step: 10
Training loss: 0.6467486023902893
Validation loss: 1.7660376410330496

Epoch: 281| Step: 0
Training loss: 0.6243810057640076
Validation loss: 1.7379603514107325

Epoch: 5| Step: 1
Training loss: 0.5679172277450562
Validation loss: 1.7681785680914437

Epoch: 5| Step: 2
Training loss: 0.525744616985321
Validation loss: 1.7849068744208223

Epoch: 5| Step: 3
Training loss: 0.26188188791275024
Validation loss: 1.8523043663271013

Epoch: 5| Step: 4
Training loss: 0.5361319184303284
Validation loss: 1.8831394398084251

Epoch: 5| Step: 5
Training loss: 0.6280967593193054
Validation loss: 1.8982442643052788

Epoch: 5| Step: 6
Training loss: 0.35019272565841675
Validation loss: 1.8743323792693436

Epoch: 5| Step: 7
Training loss: 0.6145877242088318
Validation loss: 1.8567440279068486

Epoch: 5| Step: 8
Training loss: 0.6378368735313416
Validation loss: 1.8394844557649346

Epoch: 5| Step: 9
Training loss: 0.31993502378463745
Validation loss: 1.8342669548526886

Epoch: 5| Step: 10
Training loss: 0.42589980363845825
Validation loss: 1.83587477027729

Epoch: 282| Step: 0
Training loss: 0.7110710144042969
Validation loss: 1.7977186492694321

Epoch: 5| Step: 1
Training loss: 0.5398164987564087
Validation loss: 1.7946025607406453

Epoch: 5| Step: 2
Training loss: 0.33228832483291626
Validation loss: 1.8099331253318376

Epoch: 5| Step: 3
Training loss: 0.5682507753372192
Validation loss: 1.7947210342653337

Epoch: 5| Step: 4
Training loss: 0.5859536528587341
Validation loss: 1.8050039737455306

Epoch: 5| Step: 5
Training loss: 0.5810251235961914
Validation loss: 1.8236204296030023

Epoch: 5| Step: 6
Training loss: 0.495889276266098
Validation loss: 1.7963657930333128

Epoch: 5| Step: 7
Training loss: 0.3002418875694275
Validation loss: 1.7453979471678376

Epoch: 5| Step: 8
Training loss: 0.3953542113304138
Validation loss: 1.739021662742861

Epoch: 5| Step: 9
Training loss: 0.7348715662956238
Validation loss: 1.7398784211886826

Epoch: 5| Step: 10
Training loss: 0.489528089761734
Validation loss: 1.7361355468791018

Epoch: 283| Step: 0
Training loss: 0.4771919250488281
Validation loss: 1.7752301308416552

Epoch: 5| Step: 1
Training loss: 0.5563087463378906
Validation loss: 1.7773692992425734

Epoch: 5| Step: 2
Training loss: 0.4965616762638092
Validation loss: 1.794764696910817

Epoch: 5| Step: 3
Training loss: 0.22876277565956116
Validation loss: 1.8302543624754875

Epoch: 5| Step: 4
Training loss: 0.6634764671325684
Validation loss: 1.824006526700912

Epoch: 5| Step: 5
Training loss: 0.5183544158935547
Validation loss: 1.815349978785361

Epoch: 5| Step: 6
Training loss: 0.4205660820007324
Validation loss: 1.8037418075787124

Epoch: 5| Step: 7
Training loss: 0.4024246335029602
Validation loss: 1.7661022511861657

Epoch: 5| Step: 8
Training loss: 0.47415056824684143
Validation loss: 1.761468691210593

Epoch: 5| Step: 9
Training loss: 0.5223852396011353
Validation loss: 1.7508506159628592

Epoch: 5| Step: 10
Training loss: 0.5101650357246399
Validation loss: 1.7682754493528796

Epoch: 284| Step: 0
Training loss: 0.32459133863449097
Validation loss: 1.7623830405614709

Epoch: 5| Step: 1
Training loss: 0.4312496781349182
Validation loss: 1.791477059805265

Epoch: 5| Step: 2
Training loss: 0.4906312823295593
Validation loss: 1.7934370886894964

Epoch: 5| Step: 3
Training loss: 0.6873716711997986
Validation loss: 1.8186272651918474

Epoch: 5| Step: 4
Training loss: 0.36908861994743347
Validation loss: 1.7896855031290362

Epoch: 5| Step: 5
Training loss: 0.41202816367149353
Validation loss: 1.7695641671457598

Epoch: 5| Step: 6
Training loss: 0.45993202924728394
Validation loss: 1.7705226264974123

Epoch: 5| Step: 7
Training loss: 0.47384554147720337
Validation loss: 1.7779552423825828

Epoch: 5| Step: 8
Training loss: 0.6739085912704468
Validation loss: 1.7772794564565022

Epoch: 5| Step: 9
Training loss: 0.5693123936653137
Validation loss: 1.8103816496428622

Epoch: 5| Step: 10
Training loss: 0.33193662762641907
Validation loss: 1.8449848159666984

Epoch: 285| Step: 0
Training loss: 0.4574240744113922
Validation loss: 1.8360105893945182

Epoch: 5| Step: 1
Training loss: 0.3994196653366089
Validation loss: 1.8937502266258321

Epoch: 5| Step: 2
Training loss: 0.5002455711364746
Validation loss: 1.8384263259108349

Epoch: 5| Step: 3
Training loss: 0.40827256441116333
Validation loss: 1.851091250296562

Epoch: 5| Step: 4
Training loss: 0.5256364345550537
Validation loss: 1.8049314521974134

Epoch: 5| Step: 5
Training loss: 0.3651781678199768
Validation loss: 1.7846794884691957

Epoch: 5| Step: 6
Training loss: 0.4966716766357422
Validation loss: 1.7814274423865861

Epoch: 5| Step: 7
Training loss: 0.4494989514350891
Validation loss: 1.8075521287097727

Epoch: 5| Step: 8
Training loss: 0.5150869488716125
Validation loss: 1.7810858193264212

Epoch: 5| Step: 9
Training loss: 0.6008721590042114
Validation loss: 1.771011749903361

Epoch: 5| Step: 10
Training loss: 0.45881593227386475
Validation loss: 1.8209997876997916

Epoch: 286| Step: 0
Training loss: 0.27701836824417114
Validation loss: 1.7813848039155364

Epoch: 5| Step: 1
Training loss: 0.5335923433303833
Validation loss: 1.8044488545387023

Epoch: 5| Step: 2
Training loss: 0.5075436234474182
Validation loss: 1.8186023837776595

Epoch: 5| Step: 3
Training loss: 0.38485684990882874
Validation loss: 1.816827852238891

Epoch: 5| Step: 4
Training loss: 0.2891819477081299
Validation loss: 1.8146482385614866

Epoch: 5| Step: 5
Training loss: 0.559002161026001
Validation loss: 1.7880131044695455

Epoch: 5| Step: 6
Training loss: 0.5829818248748779
Validation loss: 1.8028715823286323

Epoch: 5| Step: 7
Training loss: 0.5435070991516113
Validation loss: 1.7985840882024458

Epoch: 5| Step: 8
Training loss: 0.4313948154449463
Validation loss: 1.7852880608650945

Epoch: 5| Step: 9
Training loss: 0.17601804435253143
Validation loss: 1.7740428140086513

Epoch: 5| Step: 10
Training loss: 0.5694661736488342
Validation loss: 1.7577531004464755

Epoch: 287| Step: 0
Training loss: 0.3017957806587219
Validation loss: 1.7522194039437078

Epoch: 5| Step: 1
Training loss: 0.7767459750175476
Validation loss: 1.775179115674829

Epoch: 5| Step: 2
Training loss: 0.29038652777671814
Validation loss: 1.7631813838917723

Epoch: 5| Step: 3
Training loss: 0.5203911066055298
Validation loss: 1.8056089724263837

Epoch: 5| Step: 4
Training loss: 0.6401189565658569
Validation loss: 1.7980119566763602

Epoch: 5| Step: 5
Training loss: 0.36140209436416626
Validation loss: 1.7994691941045946

Epoch: 5| Step: 6
Training loss: 0.3104941248893738
Validation loss: 1.7385355939147293

Epoch: 5| Step: 7
Training loss: 0.33388441801071167
Validation loss: 1.7089462164909608

Epoch: 5| Step: 8
Training loss: 0.4284555912017822
Validation loss: 1.7195362455101424

Epoch: 5| Step: 9
Training loss: 0.5893401503562927
Validation loss: 1.7374860573840398

Epoch: 5| Step: 10
Training loss: 0.4837417006492615
Validation loss: 1.7452280623938448

Epoch: 288| Step: 0
Training loss: 0.3758329153060913
Validation loss: 1.7852304212508663

Epoch: 5| Step: 1
Training loss: 0.357064425945282
Validation loss: 1.8176412902852541

Epoch: 5| Step: 2
Training loss: 0.519156813621521
Validation loss: 1.8254930114233365

Epoch: 5| Step: 3
Training loss: 0.47077903151512146
Validation loss: 1.8347379725466493

Epoch: 5| Step: 4
Training loss: 0.6883336901664734
Validation loss: 1.8581214284384122

Epoch: 5| Step: 5
Training loss: 0.2196406126022339
Validation loss: 1.8511996628135763

Epoch: 5| Step: 6
Training loss: 0.2926221191883087
Validation loss: 1.840840248651402

Epoch: 5| Step: 7
Training loss: 0.42005443572998047
Validation loss: 1.754022939230806

Epoch: 5| Step: 8
Training loss: 0.5290624499320984
Validation loss: 1.7167794986437726

Epoch: 5| Step: 9
Training loss: 0.49320346117019653
Validation loss: 1.7221420657250188

Epoch: 5| Step: 10
Training loss: 0.5938723087310791
Validation loss: 1.6972419792605984

Epoch: 289| Step: 0
Training loss: 0.3730613589286804
Validation loss: 1.719160088928797

Epoch: 5| Step: 1
Training loss: 0.6723203659057617
Validation loss: 1.6809310002993512

Epoch: 5| Step: 2
Training loss: 0.2782086431980133
Validation loss: 1.7380959705639911

Epoch: 5| Step: 3
Training loss: 0.2657407820224762
Validation loss: 1.7691347893848215

Epoch: 5| Step: 4
Training loss: 0.42238011956214905
Validation loss: 1.768039462386921

Epoch: 5| Step: 5
Training loss: 0.45781296491622925
Validation loss: 1.7974198095260128

Epoch: 5| Step: 6
Training loss: 0.621155858039856
Validation loss: 1.822659364310644

Epoch: 5| Step: 7
Training loss: 0.4378589689731598
Validation loss: 1.8433530112748504

Epoch: 5| Step: 8
Training loss: 0.5123087167739868
Validation loss: 1.81463227733489

Epoch: 5| Step: 9
Training loss: 0.37677496671676636
Validation loss: 1.7963297527323487

Epoch: 5| Step: 10
Training loss: 0.38226354122161865
Validation loss: 1.79864413251159

Epoch: 290| Step: 0
Training loss: 0.38611024618148804
Validation loss: 1.8098644133537047

Epoch: 5| Step: 1
Training loss: 0.4284897446632385
Validation loss: 1.8314032836626934

Epoch: 5| Step: 2
Training loss: 0.3679940402507782
Validation loss: 1.8036722688264744

Epoch: 5| Step: 3
Training loss: 0.5203415751457214
Validation loss: 1.8017098006381784

Epoch: 5| Step: 4
Training loss: 0.5164726972579956
Validation loss: 1.8010349927410003

Epoch: 5| Step: 5
Training loss: 0.7640967965126038
Validation loss: 1.7777265156469038

Epoch: 5| Step: 6
Training loss: 0.39757803082466125
Validation loss: 1.7760054372972058

Epoch: 5| Step: 7
Training loss: 0.2788007855415344
Validation loss: 1.784505618515835

Epoch: 5| Step: 8
Training loss: 0.28895139694213867
Validation loss: 1.8403655893059188

Epoch: 5| Step: 9
Training loss: 0.3937617540359497
Validation loss: 1.8081788580904725

Epoch: 5| Step: 10
Training loss: 0.33431312441825867
Validation loss: 1.7953620213334278

Epoch: 291| Step: 0
Training loss: 0.5813719630241394
Validation loss: 1.785123279017787

Epoch: 5| Step: 1
Training loss: 0.4589540362358093
Validation loss: 1.7829165561224825

Epoch: 5| Step: 2
Training loss: 0.48875680565834045
Validation loss: 1.7402960138936197

Epoch: 5| Step: 3
Training loss: 0.3138936161994934
Validation loss: 1.7335485309682868

Epoch: 5| Step: 4
Training loss: 0.2872522175312042
Validation loss: 1.7267864596459173

Epoch: 5| Step: 5
Training loss: 0.3700295090675354
Validation loss: 1.7737685083061137

Epoch: 5| Step: 6
Training loss: 0.4681290090084076
Validation loss: 1.7949391475287817

Epoch: 5| Step: 7
Training loss: 0.278513103723526
Validation loss: 1.7797457133570025

Epoch: 5| Step: 8
Training loss: 0.7088078260421753
Validation loss: 1.7099251644585722

Epoch: 5| Step: 9
Training loss: 0.31813758611679077
Validation loss: 1.7642872743709113

Epoch: 5| Step: 10
Training loss: 0.4941675066947937
Validation loss: 1.7039595547542776

Epoch: 292| Step: 0
Training loss: 0.5145875811576843
Validation loss: 1.7237573503166117

Epoch: 5| Step: 1
Training loss: 0.5862299799919128
Validation loss: 1.7291082092510757

Epoch: 5| Step: 2
Training loss: 0.4943748414516449
Validation loss: 1.7254181831113753

Epoch: 5| Step: 3
Training loss: 0.33909979462623596
Validation loss: 1.7275532214872298

Epoch: 5| Step: 4
Training loss: 0.37304916977882385
Validation loss: 1.7664194299328713

Epoch: 5| Step: 5
Training loss: 0.4285879135131836
Validation loss: 1.7905406285357732

Epoch: 5| Step: 6
Training loss: 0.2779112458229065
Validation loss: 1.7755845080139816

Epoch: 5| Step: 7
Training loss: 0.40090590715408325
Validation loss: 1.8197962186669792

Epoch: 5| Step: 8
Training loss: 0.23107890784740448
Validation loss: 1.8305429258654196

Epoch: 5| Step: 9
Training loss: 0.5128642320632935
Validation loss: 1.7812294011474938

Epoch: 5| Step: 10
Training loss: 0.38777318596839905
Validation loss: 1.7822859979444934

Epoch: 293| Step: 0
Training loss: 0.5426458716392517
Validation loss: 1.7574106698395104

Epoch: 5| Step: 1
Training loss: 0.4024275839328766
Validation loss: 1.7885771977004183

Epoch: 5| Step: 2
Training loss: 0.3023352026939392
Validation loss: 1.7608366038209649

Epoch: 5| Step: 3
Training loss: 0.2987682819366455
Validation loss: 1.7900454549379246

Epoch: 5| Step: 4
Training loss: 0.37151771783828735
Validation loss: 1.7906244083117413

Epoch: 5| Step: 5
Training loss: 0.32715779542922974
Validation loss: 1.7641321894943074

Epoch: 5| Step: 6
Training loss: 0.441145122051239
Validation loss: 1.7515237075026318

Epoch: 5| Step: 7
Training loss: 0.5206971168518066
Validation loss: 1.7722176864583006

Epoch: 5| Step: 8
Training loss: 0.3393809199333191
Validation loss: 1.730929272149199

Epoch: 5| Step: 9
Training loss: 0.423058420419693
Validation loss: 1.7265283984522666

Epoch: 5| Step: 10
Training loss: 0.491203635931015
Validation loss: 1.7470418714707898

Epoch: 294| Step: 0
Training loss: 0.5825080871582031
Validation loss: 1.738122602944733

Epoch: 5| Step: 1
Training loss: 0.3605079650878906
Validation loss: 1.7435256691389187

Epoch: 5| Step: 2
Training loss: 0.3557775318622589
Validation loss: 1.7322976646884796

Epoch: 5| Step: 3
Training loss: 0.43327197432518005
Validation loss: 1.7358917972092986

Epoch: 5| Step: 4
Training loss: 0.3775670528411865
Validation loss: 1.7274148515475694

Epoch: 5| Step: 5
Training loss: 0.34352007508277893
Validation loss: 1.7515725346021755

Epoch: 5| Step: 6
Training loss: 0.24601244926452637
Validation loss: 1.7802091580565258

Epoch: 5| Step: 7
Training loss: 0.31125667691230774
Validation loss: 1.7510518232981365

Epoch: 5| Step: 8
Training loss: 0.5884344577789307
Validation loss: 1.7820710879500195

Epoch: 5| Step: 9
Training loss: 0.31058526039123535
Validation loss: 1.7805516386544833

Epoch: 5| Step: 10
Training loss: 0.5948217511177063
Validation loss: 1.7791544468172136

Epoch: 295| Step: 0
Training loss: 0.44493618607521057
Validation loss: 1.781051153777748

Epoch: 5| Step: 1
Training loss: 0.48686546087265015
Validation loss: 1.7518325454445296

Epoch: 5| Step: 2
Training loss: 0.3223744332790375
Validation loss: 1.7527549394997217

Epoch: 5| Step: 3
Training loss: 0.34417620301246643
Validation loss: 1.7487447543810772

Epoch: 5| Step: 4
Training loss: 0.23995883762836456
Validation loss: 1.730022963657174

Epoch: 5| Step: 5
Training loss: 0.22079189121723175
Validation loss: 1.7493913353130381

Epoch: 5| Step: 6
Training loss: 0.2719458043575287
Validation loss: 1.7399615062180387

Epoch: 5| Step: 7
Training loss: 0.33217477798461914
Validation loss: 1.7557273910891624

Epoch: 5| Step: 8
Training loss: 0.43742552399635315
Validation loss: 1.758719696793505

Epoch: 5| Step: 9
Training loss: 0.4855111539363861
Validation loss: 1.7402748221992164

Epoch: 5| Step: 10
Training loss: 0.5494771003723145
Validation loss: 1.7629005793602235

Epoch: 296| Step: 0
Training loss: 0.42895373702049255
Validation loss: 1.7565216633581346

Epoch: 5| Step: 1
Training loss: 0.393561452627182
Validation loss: 1.7677333560041202

Epoch: 5| Step: 2
Training loss: 0.523138165473938
Validation loss: 1.75480184888327

Epoch: 5| Step: 3
Training loss: 0.4947025179862976
Validation loss: 1.7792178533410514

Epoch: 5| Step: 4
Training loss: 0.34778663516044617
Validation loss: 1.75383597676472

Epoch: 5| Step: 5
Training loss: 0.21406510472297668
Validation loss: 1.7427069358928229

Epoch: 5| Step: 6
Training loss: 0.35949039459228516
Validation loss: 1.7618001225174114

Epoch: 5| Step: 7
Training loss: 0.34580087661743164
Validation loss: 1.7659093654283913

Epoch: 5| Step: 8
Training loss: 0.44373732805252075
Validation loss: 1.7721775167731828

Epoch: 5| Step: 9
Training loss: 0.45108675956726074
Validation loss: 1.7789425221822595

Epoch: 5| Step: 10
Training loss: 0.18833374977111816
Validation loss: 1.7589504590598486

Epoch: 297| Step: 0
Training loss: 0.4644388258457184
Validation loss: 1.723780434618714

Epoch: 5| Step: 1
Training loss: 0.3834853768348694
Validation loss: 1.7219265032840032

Epoch: 5| Step: 2
Training loss: 0.3137422800064087
Validation loss: 1.712123123548364

Epoch: 5| Step: 3
Training loss: 0.3358069360256195
Validation loss: 1.7165909556932346

Epoch: 5| Step: 4
Training loss: 0.4064571261405945
Validation loss: 1.7545369517418645

Epoch: 5| Step: 5
Training loss: 0.41141510009765625
Validation loss: 1.774464604675129

Epoch: 5| Step: 6
Training loss: 0.4005090594291687
Validation loss: 1.8016071178579842

Epoch: 5| Step: 7
Training loss: 0.47742921113967896
Validation loss: 1.7914634468734905

Epoch: 5| Step: 8
Training loss: 0.4887438714504242
Validation loss: 1.783491002616062

Epoch: 5| Step: 9
Training loss: 0.1908005028963089
Validation loss: 1.759006170816319

Epoch: 5| Step: 10
Training loss: 0.4262387156486511
Validation loss: 1.7161519629980928

Epoch: 298| Step: 0
Training loss: 0.3837907910346985
Validation loss: 1.7133934190196376

Epoch: 5| Step: 1
Training loss: 0.3979746699333191
Validation loss: 1.7141074993277108

Epoch: 5| Step: 2
Training loss: 0.40624532103538513
Validation loss: 1.7121881618294665

Epoch: 5| Step: 3
Training loss: 0.2619370222091675
Validation loss: 1.6859750158043318

Epoch: 5| Step: 4
Training loss: 0.263285756111145
Validation loss: 1.7580051037573046

Epoch: 5| Step: 5
Training loss: 0.48801565170288086
Validation loss: 1.7884652332593036

Epoch: 5| Step: 6
Training loss: 0.3987065255641937
Validation loss: 1.7741169775685957

Epoch: 5| Step: 7
Training loss: 0.5470460057258606
Validation loss: 1.7569729756283503

Epoch: 5| Step: 8
Training loss: 0.2535855174064636
Validation loss: 1.762073088717717

Epoch: 5| Step: 9
Training loss: 0.5151229500770569
Validation loss: 1.7648037518224409

Epoch: 5| Step: 10
Training loss: 0.33323708176612854
Validation loss: 1.758091716356175

Epoch: 299| Step: 0
Training loss: 0.21745285391807556
Validation loss: 1.7181437989716888

Epoch: 5| Step: 1
Training loss: 0.2022349089384079
Validation loss: 1.7172307557957147

Epoch: 5| Step: 2
Training loss: 0.40637820959091187
Validation loss: 1.7127547892191077

Epoch: 5| Step: 3
Training loss: 0.5645588636398315
Validation loss: 1.7225631872812908

Epoch: 5| Step: 4
Training loss: 0.49620532989501953
Validation loss: 1.7574103570753528

Epoch: 5| Step: 5
Training loss: 0.4260713458061218
Validation loss: 1.7799994868616904

Epoch: 5| Step: 6
Training loss: 0.5864266753196716
Validation loss: 1.7533013051556003

Epoch: 5| Step: 7
Training loss: 0.27793392539024353
Validation loss: 1.7436642621153144

Epoch: 5| Step: 8
Training loss: 0.29629865288734436
Validation loss: 1.7563949990016159

Epoch: 5| Step: 9
Training loss: 0.41164785623550415
Validation loss: 1.6979897861839623

Epoch: 5| Step: 10
Training loss: 0.4024333357810974
Validation loss: 1.6852694192240316

Epoch: 300| Step: 0
Training loss: 0.22098508477210999
Validation loss: 1.7011269343796598

Epoch: 5| Step: 1
Training loss: 0.31355738639831543
Validation loss: 1.7027194384605653

Epoch: 5| Step: 2
Training loss: 0.3560224175453186
Validation loss: 1.7272840353750414

Epoch: 5| Step: 3
Training loss: 0.42029279470443726
Validation loss: 1.7172529735872823

Epoch: 5| Step: 4
Training loss: 0.4191296100616455
Validation loss: 1.7436864529886553

Epoch: 5| Step: 5
Training loss: 0.36784592270851135
Validation loss: 1.7554776386548114

Epoch: 5| Step: 6
Training loss: 0.37271419167518616
Validation loss: 1.6881770087826637

Epoch: 5| Step: 7
Training loss: 0.5545670390129089
Validation loss: 1.7033093526799192

Epoch: 5| Step: 8
Training loss: 0.25077518820762634
Validation loss: 1.7154424600703742

Epoch: 5| Step: 9
Training loss: 0.28579166531562805
Validation loss: 1.6884309040602816

Epoch: 5| Step: 10
Training loss: 0.6582993268966675
Validation loss: 1.6883499237798876

Epoch: 301| Step: 0
Training loss: 0.36621442437171936
Validation loss: 1.6805983692087152

Epoch: 5| Step: 1
Training loss: 0.3298119902610779
Validation loss: 1.6948799881883847

Epoch: 5| Step: 2
Training loss: 0.40396204590797424
Validation loss: 1.7242315764068274

Epoch: 5| Step: 3
Training loss: 0.21696433424949646
Validation loss: 1.7113867626395276

Epoch: 5| Step: 4
Training loss: 0.47046589851379395
Validation loss: 1.7435158824407926

Epoch: 5| Step: 5
Training loss: 0.17800241708755493
Validation loss: 1.7592731714248657

Epoch: 5| Step: 6
Training loss: 0.4980587959289551
Validation loss: 1.733720398718311

Epoch: 5| Step: 7
Training loss: 0.44824376702308655
Validation loss: 1.7590707771239742

Epoch: 5| Step: 8
Training loss: 0.3495820164680481
Validation loss: 1.7343298235247213

Epoch: 5| Step: 9
Training loss: 0.16979756951332092
Validation loss: 1.742835726789249

Epoch: 5| Step: 10
Training loss: 0.4886157214641571
Validation loss: 1.7321782291576426

Epoch: 302| Step: 0
Training loss: 0.23398680984973907
Validation loss: 1.719624452693488

Epoch: 5| Step: 1
Training loss: 0.3490615785121918
Validation loss: 1.7452543038193897

Epoch: 5| Step: 2
Training loss: 0.3385639786720276
Validation loss: 1.7651363777857956

Epoch: 5| Step: 3
Training loss: 0.37515348196029663
Validation loss: 1.7627561656377648

Epoch: 5| Step: 4
Training loss: 0.5196078419685364
Validation loss: 1.7544443299693446

Epoch: 5| Step: 5
Training loss: 0.2747116684913635
Validation loss: 1.7820323615945795

Epoch: 5| Step: 6
Training loss: 0.5078796148300171
Validation loss: 1.8165031351068968

Epoch: 5| Step: 7
Training loss: 0.45216912031173706
Validation loss: 1.8394966125488281

Epoch: 5| Step: 8
Training loss: 0.3706868290901184
Validation loss: 1.828277975000361

Epoch: 5| Step: 9
Training loss: 0.41284531354904175
Validation loss: 1.850500475975775

Epoch: 5| Step: 10
Training loss: 0.22745856642723083
Validation loss: 1.7939564925368114

Epoch: 303| Step: 0
Training loss: 0.4045904278755188
Validation loss: 1.785502205612839

Epoch: 5| Step: 1
Training loss: 0.29450723528862
Validation loss: 1.742846304370511

Epoch: 5| Step: 2
Training loss: 0.2829212248325348
Validation loss: 1.7534859834178802

Epoch: 5| Step: 3
Training loss: 0.39965128898620605
Validation loss: 1.7442838838023524

Epoch: 5| Step: 4
Training loss: 0.4313696026802063
Validation loss: 1.746990147457328

Epoch: 5| Step: 5
Training loss: 0.5135582089424133
Validation loss: 1.728380787757135

Epoch: 5| Step: 6
Training loss: 0.38316041231155396
Validation loss: 1.756587836050218

Epoch: 5| Step: 7
Training loss: 0.4732299745082855
Validation loss: 1.751460116396668

Epoch: 5| Step: 8
Training loss: 0.3883139193058014
Validation loss: 1.787400730194584

Epoch: 5| Step: 9
Training loss: 0.39788371324539185
Validation loss: 1.8032301343897337

Epoch: 5| Step: 10
Training loss: 0.34367287158966064
Validation loss: 1.8108933100136377

Epoch: 304| Step: 0
Training loss: 0.38623785972595215
Validation loss: 1.7855993496474398

Epoch: 5| Step: 1
Training loss: 0.3815183639526367
Validation loss: 1.7551848068032214

Epoch: 5| Step: 2
Training loss: 0.4100084900856018
Validation loss: 1.7288600424284577

Epoch: 5| Step: 3
Training loss: 0.3450344204902649
Validation loss: 1.7587610995897682

Epoch: 5| Step: 4
Training loss: 0.20163729786872864
Validation loss: 1.758921879594044

Epoch: 5| Step: 5
Training loss: 0.5586029291152954
Validation loss: 1.7283879172417425

Epoch: 5| Step: 6
Training loss: 0.37757736444473267
Validation loss: 1.7301556294964207

Epoch: 5| Step: 7
Training loss: 0.4371860921382904
Validation loss: 1.767861093244245

Epoch: 5| Step: 8
Training loss: 0.4562563896179199
Validation loss: 1.80097032618779

Epoch: 5| Step: 9
Training loss: 0.3298787474632263
Validation loss: 1.7834334988747873

Epoch: 5| Step: 10
Training loss: 0.4057808220386505
Validation loss: 1.730333024455655

Epoch: 305| Step: 0
Training loss: 0.3450244963169098
Validation loss: 1.6928863320299374

Epoch: 5| Step: 1
Training loss: 0.39485639333724976
Validation loss: 1.6651107970104422

Epoch: 5| Step: 2
Training loss: 0.34666362404823303
Validation loss: 1.6312862391112952

Epoch: 5| Step: 3
Training loss: 0.2784872353076935
Validation loss: 1.6435296740583194

Epoch: 5| Step: 4
Training loss: 0.4311528205871582
Validation loss: 1.6507675968190676

Epoch: 5| Step: 5
Training loss: 0.2784254848957062
Validation loss: 1.6626212737893546

Epoch: 5| Step: 6
Training loss: 0.3878975212574005
Validation loss: 1.665701590558534

Epoch: 5| Step: 7
Training loss: 0.4423292279243469
Validation loss: 1.6754001840468375

Epoch: 5| Step: 8
Training loss: 0.38001570105552673
Validation loss: 1.7233658465006019

Epoch: 5| Step: 9
Training loss: 0.39682909846305847
Validation loss: 1.76199431573191

Epoch: 5| Step: 10
Training loss: 0.595169723033905
Validation loss: 1.7500521098413775

Epoch: 306| Step: 0
Training loss: 0.37285733222961426
Validation loss: 1.7199898278841408

Epoch: 5| Step: 1
Training loss: 0.21754971146583557
Validation loss: 1.6919988778329664

Epoch: 5| Step: 2
Training loss: 0.6456357836723328
Validation loss: 1.7150890250359812

Epoch: 5| Step: 3
Training loss: 0.4312979280948639
Validation loss: 1.7175466783585087

Epoch: 5| Step: 4
Training loss: 0.22631943225860596
Validation loss: 1.6987752811883086

Epoch: 5| Step: 5
Training loss: 0.45323601365089417
Validation loss: 1.6735603655538251

Epoch: 5| Step: 6
Training loss: 0.5964140295982361
Validation loss: 1.699122509648723

Epoch: 5| Step: 7
Training loss: 0.3299572169780731
Validation loss: 1.6985274719935592

Epoch: 5| Step: 8
Training loss: 0.20087239146232605
Validation loss: 1.6895141447744062

Epoch: 5| Step: 9
Training loss: 0.30808335542678833
Validation loss: 1.685585734664753

Epoch: 5| Step: 10
Training loss: 0.4110535681247711
Validation loss: 1.7054446563925794

Epoch: 307| Step: 0
Training loss: 0.3575441837310791
Validation loss: 1.6747571012025237

Epoch: 5| Step: 1
Training loss: 0.4969235062599182
Validation loss: 1.688143418681237

Epoch: 5| Step: 2
Training loss: 0.3751445412635803
Validation loss: 1.6775971689531881

Epoch: 5| Step: 3
Training loss: 0.34111300110816956
Validation loss: 1.6810171155519382

Epoch: 5| Step: 4
Training loss: 0.21570786833763123
Validation loss: 1.6957501288383239

Epoch: 5| Step: 5
Training loss: 0.43786197900772095
Validation loss: 1.7134519648808304

Epoch: 5| Step: 6
Training loss: 0.2649797797203064
Validation loss: 1.6917870172890284

Epoch: 5| Step: 7
Training loss: 0.448805034160614
Validation loss: 1.693844344026299

Epoch: 5| Step: 8
Training loss: 0.39682167768478394
Validation loss: 1.7064171491130706

Epoch: 5| Step: 9
Training loss: 0.4346780776977539
Validation loss: 1.6871588537769933

Epoch: 5| Step: 10
Training loss: 0.29653143882751465
Validation loss: 1.7212514210772771

Epoch: 308| Step: 0
Training loss: 0.4152809679508209
Validation loss: 1.6960826073923418

Epoch: 5| Step: 1
Training loss: 0.3083741068840027
Validation loss: 1.699685106354375

Epoch: 5| Step: 2
Training loss: 0.30021947622299194
Validation loss: 1.7205337542359547

Epoch: 5| Step: 3
Training loss: 0.3782883584499359
Validation loss: 1.7085510889689128

Epoch: 5| Step: 4
Training loss: 0.5147920846939087
Validation loss: 1.7263440624360116

Epoch: 5| Step: 5
Training loss: 0.2734265923500061
Validation loss: 1.7396180258002332

Epoch: 5| Step: 6
Training loss: 0.45713871717453003
Validation loss: 1.7730807219782183

Epoch: 5| Step: 7
Training loss: 0.4659900665283203
Validation loss: 1.7334414682080668

Epoch: 5| Step: 8
Training loss: 0.2798444330692291
Validation loss: 1.7363242974845312

Epoch: 5| Step: 9
Training loss: 0.19562117755413055
Validation loss: 1.7297657253921672

Epoch: 5| Step: 10
Training loss: 0.2287234365940094
Validation loss: 1.6664550919686594

Epoch: 309| Step: 0
Training loss: 0.24567170441150665
Validation loss: 1.6759331110985047

Epoch: 5| Step: 1
Training loss: 0.43066245317459106
Validation loss: 1.6864230325145106

Epoch: 5| Step: 2
Training loss: 0.3344190716743469
Validation loss: 1.704800723701395

Epoch: 5| Step: 3
Training loss: 0.30988192558288574
Validation loss: 1.6856828761357132

Epoch: 5| Step: 4
Training loss: 0.39368683099746704
Validation loss: 1.7218624520045456

Epoch: 5| Step: 5
Training loss: 0.290465772151947
Validation loss: 1.7237571388162591

Epoch: 5| Step: 6
Training loss: 0.4470679759979248
Validation loss: 1.7451883567276822

Epoch: 5| Step: 7
Training loss: 0.5721098184585571
Validation loss: 1.7179039639811362

Epoch: 5| Step: 8
Training loss: 0.3142402768135071
Validation loss: 1.7498332864494734

Epoch: 5| Step: 9
Training loss: 0.21962592005729675
Validation loss: 1.710999572148887

Epoch: 5| Step: 10
Training loss: 0.33287644386291504
Validation loss: 1.7089478110754361

Epoch: 310| Step: 0
Training loss: 0.3140799403190613
Validation loss: 1.7354703500706663

Epoch: 5| Step: 1
Training loss: 0.46057194471359253
Validation loss: 1.7719000539472025

Epoch: 5| Step: 2
Training loss: 0.32592660188674927
Validation loss: 1.7506093043153004

Epoch: 5| Step: 3
Training loss: 0.1452191174030304
Validation loss: 1.702734467803791

Epoch: 5| Step: 4
Training loss: 0.3401487469673157
Validation loss: 1.7115374829179497

Epoch: 5| Step: 5
Training loss: 0.4391675591468811
Validation loss: 1.7087017220835532

Epoch: 5| Step: 6
Training loss: 0.4968632161617279
Validation loss: 1.726376373280761

Epoch: 5| Step: 7
Training loss: 0.3548050820827484
Validation loss: 1.735856856069257

Epoch: 5| Step: 8
Training loss: 0.46154823899269104
Validation loss: 1.7431014686502435

Epoch: 5| Step: 9
Training loss: 0.23768830299377441
Validation loss: 1.7631989858483756

Epoch: 5| Step: 10
Training loss: 0.26601287722587585
Validation loss: 1.7209486307636384

Epoch: 311| Step: 0
Training loss: 0.23097515106201172
Validation loss: 1.7169204796514204

Epoch: 5| Step: 1
Training loss: 0.3650935888290405
Validation loss: 1.7066226595191545

Epoch: 5| Step: 2
Training loss: 0.3419188857078552
Validation loss: 1.6879342422690442

Epoch: 5| Step: 3
Training loss: 0.3919787108898163
Validation loss: 1.6869447269747335

Epoch: 5| Step: 4
Training loss: 0.3046073317527771
Validation loss: 1.6686473508034982

Epoch: 5| Step: 5
Training loss: 0.39120811223983765
Validation loss: 1.7025251760277698

Epoch: 5| Step: 6
Training loss: 0.2912918031215668
Validation loss: 1.723843930869974

Epoch: 5| Step: 7
Training loss: 0.3354654908180237
Validation loss: 1.681573158951216

Epoch: 5| Step: 8
Training loss: 0.31443530321121216
Validation loss: 1.664535294296921

Epoch: 5| Step: 9
Training loss: 0.37011778354644775
Validation loss: 1.654195676567734

Epoch: 5| Step: 10
Training loss: 0.26988744735717773
Validation loss: 1.6617126605843986

Epoch: 312| Step: 0
Training loss: 0.5229129195213318
Validation loss: 1.6593490659549672

Epoch: 5| Step: 1
Training loss: 0.3773038685321808
Validation loss: 1.6541140899863294

Epoch: 5| Step: 2
Training loss: 0.2345086634159088
Validation loss: 1.7179322691373928

Epoch: 5| Step: 3
Training loss: 0.22974297404289246
Validation loss: 1.73894033252552

Epoch: 5| Step: 4
Training loss: 0.3791186511516571
Validation loss: 1.7702208744582308

Epoch: 5| Step: 5
Training loss: 0.39528170228004456
Validation loss: 1.7704341578227218

Epoch: 5| Step: 6
Training loss: 0.2065480500459671
Validation loss: 1.7581688845029442

Epoch: 5| Step: 7
Training loss: 0.16210098564624786
Validation loss: 1.7435999544717933

Epoch: 5| Step: 8
Training loss: 0.3731679916381836
Validation loss: 1.7236318870257306

Epoch: 5| Step: 9
Training loss: 0.4936749339103699
Validation loss: 1.7389158433483494

Epoch: 5| Step: 10
Training loss: 0.6446678042411804
Validation loss: 1.7454968908781647

Epoch: 313| Step: 0
Training loss: 0.33000311255455017
Validation loss: 1.7345824369820215

Epoch: 5| Step: 1
Training loss: 0.34498387575149536
Validation loss: 1.7154710542771123

Epoch: 5| Step: 2
Training loss: 0.3149690330028534
Validation loss: 1.690969431272117

Epoch: 5| Step: 3
Training loss: 0.12084678560495377
Validation loss: 1.7004453725712274

Epoch: 5| Step: 4
Training loss: 0.3615359663963318
Validation loss: 1.711987933804912

Epoch: 5| Step: 5
Training loss: 0.3064609169960022
Validation loss: 1.7223975273870653

Epoch: 5| Step: 6
Training loss: 0.21110832691192627
Validation loss: 1.6998245318730671

Epoch: 5| Step: 7
Training loss: 0.3978455066680908
Validation loss: 1.7043443931046354

Epoch: 5| Step: 8
Training loss: 0.37779420614242554
Validation loss: 1.6958525334635088

Epoch: 5| Step: 9
Training loss: 0.37715333700180054
Validation loss: 1.7175758525889406

Epoch: 5| Step: 10
Training loss: 0.387198805809021
Validation loss: 1.682311269544786

Epoch: 314| Step: 0
Training loss: 0.3739730715751648
Validation loss: 1.690719505792023

Epoch: 5| Step: 1
Training loss: 0.39889559149742126
Validation loss: 1.7165310049569735

Epoch: 5| Step: 2
Training loss: 0.28216204047203064
Validation loss: 1.6997072222412273

Epoch: 5| Step: 3
Training loss: 0.4223751425743103
Validation loss: 1.7033133711866153

Epoch: 5| Step: 4
Training loss: 0.3233529329299927
Validation loss: 1.7084275496903287

Epoch: 5| Step: 5
Training loss: 0.2954460382461548
Validation loss: 1.737161369733913

Epoch: 5| Step: 6
Training loss: 0.3484623432159424
Validation loss: 1.7099518352939236

Epoch: 5| Step: 7
Training loss: 0.2458256036043167
Validation loss: 1.709780018816712

Epoch: 5| Step: 8
Training loss: 0.21076567471027374
Validation loss: 1.68786145089775

Epoch: 5| Step: 9
Training loss: 0.3669815957546234
Validation loss: 1.6762995758364279

Epoch: 5| Step: 10
Training loss: 0.2851320207118988
Validation loss: 1.679652424268825

Epoch: 315| Step: 0
Training loss: 0.5000608563423157
Validation loss: 1.676417427678262

Epoch: 5| Step: 1
Training loss: 0.27831465005874634
Validation loss: 1.674822445838682

Epoch: 5| Step: 2
Training loss: 0.38552409410476685
Validation loss: 1.68082179305374

Epoch: 5| Step: 3
Training loss: 0.16026434302330017
Validation loss: 1.6941071723097114

Epoch: 5| Step: 4
Training loss: 0.16472163796424866
Validation loss: 1.6801997641081452

Epoch: 5| Step: 5
Training loss: 0.1649554818868637
Validation loss: 1.709320690042229

Epoch: 5| Step: 6
Training loss: 0.4112853407859802
Validation loss: 1.7573326095458

Epoch: 5| Step: 7
Training loss: 0.4057379364967346
Validation loss: 1.7854657480793614

Epoch: 5| Step: 8
Training loss: 0.5037976503372192
Validation loss: 1.7719183045048867

Epoch: 5| Step: 9
Training loss: 0.3456137180328369
Validation loss: 1.7728351059780325

Epoch: 5| Step: 10
Training loss: 0.4941309690475464
Validation loss: 1.7416626573890768

Epoch: 316| Step: 0
Training loss: 0.24834755063056946
Validation loss: 1.6856126157186364

Epoch: 5| Step: 1
Training loss: 0.34597939252853394
Validation loss: 1.7008258719598093

Epoch: 5| Step: 2
Training loss: 0.4314621090888977
Validation loss: 1.66519828637441

Epoch: 5| Step: 3
Training loss: 0.35084375739097595
Validation loss: 1.6650462945302327

Epoch: 5| Step: 4
Training loss: 0.41541939973831177
Validation loss: 1.6280147067962154

Epoch: 5| Step: 5
Training loss: 0.36279740929603577
Validation loss: 1.6586725122185164

Epoch: 5| Step: 6
Training loss: 0.42260533571243286
Validation loss: 1.7116853729371102

Epoch: 5| Step: 7
Training loss: 0.19366000592708588
Validation loss: 1.7174253566290743

Epoch: 5| Step: 8
Training loss: 0.2997220456600189
Validation loss: 1.7550946884257819

Epoch: 5| Step: 9
Training loss: 0.30613332986831665
Validation loss: 1.7045739466144192

Epoch: 5| Step: 10
Training loss: 0.3496013581752777
Validation loss: 1.6890848400772258

Epoch: 317| Step: 0
Training loss: 0.18919171392917633
Validation loss: 1.6731380185773295

Epoch: 5| Step: 1
Training loss: 0.18756704032421112
Validation loss: 1.702847582037731

Epoch: 5| Step: 2
Training loss: 0.2948327958583832
Validation loss: 1.7006048015368882

Epoch: 5| Step: 3
Training loss: 0.3293045461177826
Validation loss: 1.7144470061025312

Epoch: 5| Step: 4
Training loss: 0.3915790915489197
Validation loss: 1.7079047246645855

Epoch: 5| Step: 5
Training loss: 0.37740087509155273
Validation loss: 1.7187468262128933

Epoch: 5| Step: 6
Training loss: 0.21378076076507568
Validation loss: 1.7317691708123812

Epoch: 5| Step: 7
Training loss: 0.350198894739151
Validation loss: 1.7159178571034504

Epoch: 5| Step: 8
Training loss: 0.40461140871047974
Validation loss: 1.7338886568623204

Epoch: 5| Step: 9
Training loss: 0.287151038646698
Validation loss: 1.6958821665856145

Epoch: 5| Step: 10
Training loss: 0.33078834414482117
Validation loss: 1.711788063408226

Epoch: 318| Step: 0
Training loss: 0.243709996342659
Validation loss: 1.6812871245927707

Epoch: 5| Step: 1
Training loss: 0.23996134102344513
Validation loss: 1.6772485010085567

Epoch: 5| Step: 2
Training loss: 0.39626145362854004
Validation loss: 1.7028625754899875

Epoch: 5| Step: 3
Training loss: 0.165909081697464
Validation loss: 1.7239874550091323

Epoch: 5| Step: 4
Training loss: 0.5496121644973755
Validation loss: 1.7155833898052093

Epoch: 5| Step: 5
Training loss: 0.35302498936653137
Validation loss: 1.738434112200173

Epoch: 5| Step: 6
Training loss: 0.3923596143722534
Validation loss: 1.7198717901783604

Epoch: 5| Step: 7
Training loss: 0.18279893696308136
Validation loss: 1.7427878187548729

Epoch: 5| Step: 8
Training loss: 0.3016868233680725
Validation loss: 1.7210472232551985

Epoch: 5| Step: 9
Training loss: 0.1966368854045868
Validation loss: 1.6976472998178134

Epoch: 5| Step: 10
Training loss: 0.289893239736557
Validation loss: 1.6930164496103923

Epoch: 319| Step: 0
Training loss: 0.38599830865859985
Validation loss: 1.668149212996165

Epoch: 5| Step: 1
Training loss: 0.16532225906848907
Validation loss: 1.6736522310523576

Epoch: 5| Step: 2
Training loss: 0.2391405999660492
Validation loss: 1.6528148356304373

Epoch: 5| Step: 3
Training loss: 0.3731449246406555
Validation loss: 1.6417141832331175

Epoch: 5| Step: 4
Training loss: 0.338617742061615
Validation loss: 1.6276271266321982

Epoch: 5| Step: 5
Training loss: 0.3256455957889557
Validation loss: 1.6603640241007651

Epoch: 5| Step: 6
Training loss: 0.37756532430648804
Validation loss: 1.659607320703486

Epoch: 5| Step: 7
Training loss: 0.2561611235141754
Validation loss: 1.6368068648922829

Epoch: 5| Step: 8
Training loss: 0.3969191908836365
Validation loss: 1.657532299718549

Epoch: 5| Step: 9
Training loss: 0.30924999713897705
Validation loss: 1.7045464592595254

Epoch: 5| Step: 10
Training loss: 0.1818428784608841
Validation loss: 1.6912524956528858

Epoch: 320| Step: 0
Training loss: 0.26101088523864746
Validation loss: 1.7135689925122004

Epoch: 5| Step: 1
Training loss: 0.5077757835388184
Validation loss: 1.6426874924731512

Epoch: 5| Step: 2
Training loss: 0.30275872349739075
Validation loss: 1.649546302774901

Epoch: 5| Step: 3
Training loss: 0.3749080300331116
Validation loss: 1.66347248067138

Epoch: 5| Step: 4
Training loss: 0.18362876772880554
Validation loss: 1.6669645476084884

Epoch: 5| Step: 5
Training loss: 0.36561495065689087
Validation loss: 1.6173828481346049

Epoch: 5| Step: 6
Training loss: 0.210841566324234
Validation loss: 1.630093547605699

Epoch: 5| Step: 7
Training loss: 0.42958107590675354
Validation loss: 1.632022539774577

Epoch: 5| Step: 8
Training loss: 0.3704112768173218
Validation loss: 1.6623936968465005

Epoch: 5| Step: 9
Training loss: 0.288239985704422
Validation loss: 1.6715033977262435

Epoch: 5| Step: 10
Training loss: 0.15456552803516388
Validation loss: 1.67910583044893

Epoch: 321| Step: 0
Training loss: 0.23794052004814148
Validation loss: 1.6815357003160702

Epoch: 5| Step: 1
Training loss: 0.3166332244873047
Validation loss: 1.698134724811841

Epoch: 5| Step: 2
Training loss: 0.3427460789680481
Validation loss: 1.66095850160045

Epoch: 5| Step: 3
Training loss: 0.34909504652023315
Validation loss: 1.67019816752403

Epoch: 5| Step: 4
Training loss: 0.3213382661342621
Validation loss: 1.663899742146974

Epoch: 5| Step: 5
Training loss: 0.18106047809123993
Validation loss: 1.6470211423853391

Epoch: 5| Step: 6
Training loss: 0.3332098722457886
Validation loss: 1.6610905201204362

Epoch: 5| Step: 7
Training loss: 0.3226367235183716
Validation loss: 1.68960770996668

Epoch: 5| Step: 8
Training loss: 0.3059311807155609
Validation loss: 1.6974771573979368

Epoch: 5| Step: 9
Training loss: 0.3712562918663025
Validation loss: 1.6744997321918447

Epoch: 5| Step: 10
Training loss: 0.391180157661438
Validation loss: 1.6977092796756375

Epoch: 322| Step: 0
Training loss: 0.35082608461380005
Validation loss: 1.7003366639537196

Epoch: 5| Step: 1
Training loss: 0.34910449385643005
Validation loss: 1.6692447047079764

Epoch: 5| Step: 2
Training loss: 0.2610945999622345
Validation loss: 1.6934936841328938

Epoch: 5| Step: 3
Training loss: 0.2539219856262207
Validation loss: 1.7077625913004721

Epoch: 5| Step: 4
Training loss: 0.2622198462486267
Validation loss: 1.6759741242213915

Epoch: 5| Step: 5
Training loss: 0.1680121123790741
Validation loss: 1.6742832814493487

Epoch: 5| Step: 6
Training loss: 0.2783217132091522
Validation loss: 1.7130189954593618

Epoch: 5| Step: 7
Training loss: 0.3643673062324524
Validation loss: 1.6885686984626196

Epoch: 5| Step: 8
Training loss: 0.38005930185317993
Validation loss: 1.7038097394410001

Epoch: 5| Step: 9
Training loss: 0.2755867838859558
Validation loss: 1.670131214203373

Epoch: 5| Step: 10
Training loss: 0.23873281478881836
Validation loss: 1.688419516368579

Epoch: 323| Step: 0
Training loss: 0.42771396040916443
Validation loss: 1.6615535264374108

Epoch: 5| Step: 1
Training loss: 0.2406030148267746
Validation loss: 1.6770906140727382

Epoch: 5| Step: 2
Training loss: 0.3730499744415283
Validation loss: 1.6717254936054189

Epoch: 5| Step: 3
Training loss: 0.20329201221466064
Validation loss: 1.664679241436784

Epoch: 5| Step: 4
Training loss: 0.4567797780036926
Validation loss: 1.6568172388179327

Epoch: 5| Step: 5
Training loss: 0.28504711389541626
Validation loss: 1.6667735538175028

Epoch: 5| Step: 6
Training loss: 0.1440938413143158
Validation loss: 1.660335111361678

Epoch: 5| Step: 7
Training loss: 0.27331531047821045
Validation loss: 1.7077215333138742

Epoch: 5| Step: 8
Training loss: 0.22699639201164246
Validation loss: 1.7043069421604116

Epoch: 5| Step: 9
Training loss: 0.33969539403915405
Validation loss: 1.730038796701739

Epoch: 5| Step: 10
Training loss: 0.34545063972473145
Validation loss: 1.7182603523295412

Epoch: 324| Step: 0
Training loss: 0.41328325867652893
Validation loss: 1.7236620046759163

Epoch: 5| Step: 1
Training loss: 0.3514023423194885
Validation loss: 1.699792222310138

Epoch: 5| Step: 2
Training loss: 0.2248745858669281
Validation loss: 1.7453902729095951

Epoch: 5| Step: 3
Training loss: 0.33647680282592773
Validation loss: 1.7723016021072224

Epoch: 5| Step: 4
Training loss: 0.29491060972213745
Validation loss: 1.7508344893814416

Epoch: 5| Step: 5
Training loss: 0.27757811546325684
Validation loss: 1.7774173008498324

Epoch: 5| Step: 6
Training loss: 0.21367435157299042
Validation loss: 1.7501859690553399

Epoch: 5| Step: 7
Training loss: 0.29721447825431824
Validation loss: 1.7323125382905364

Epoch: 5| Step: 8
Training loss: 0.3736439645290375
Validation loss: 1.7021841733686385

Epoch: 5| Step: 9
Training loss: 0.34422340989112854
Validation loss: 1.6894685786257508

Epoch: 5| Step: 10
Training loss: 0.32294923067092896
Validation loss: 1.6698985227974512

Epoch: 325| Step: 0
Training loss: 0.3950751721858978
Validation loss: 1.645822407096945

Epoch: 5| Step: 1
Training loss: 0.27413424849510193
Validation loss: 1.6129798837887344

Epoch: 5| Step: 2
Training loss: 0.30051931738853455
Validation loss: 1.6173145258298485

Epoch: 5| Step: 3
Training loss: 0.3834732472896576
Validation loss: 1.6061775069082938

Epoch: 5| Step: 4
Training loss: 0.37529897689819336
Validation loss: 1.6380481117515153

Epoch: 5| Step: 5
Training loss: 0.2694801688194275
Validation loss: 1.6251583624911565

Epoch: 5| Step: 6
Training loss: 0.32455891370773315
Validation loss: 1.6241812423993183

Epoch: 5| Step: 7
Training loss: 0.18122704327106476
Validation loss: 1.6220838498043757

Epoch: 5| Step: 8
Training loss: 0.19627556204795837
Validation loss: 1.6294629919913508

Epoch: 5| Step: 9
Training loss: 0.4020232558250427
Validation loss: 1.6442661977583362

Epoch: 5| Step: 10
Training loss: 0.512717604637146
Validation loss: 1.6806466502528037

Epoch: 326| Step: 0
Training loss: 0.24352554976940155
Validation loss: 1.702708359687559

Epoch: 5| Step: 1
Training loss: 0.3836742043495178
Validation loss: 1.7395848561358709

Epoch: 5| Step: 2
Training loss: 0.2832283675670624
Validation loss: 1.770257201246036

Epoch: 5| Step: 3
Training loss: 0.30212125182151794
Validation loss: 1.744354030137421

Epoch: 5| Step: 4
Training loss: 0.3513268828392029
Validation loss: 1.7064909986270371

Epoch: 5| Step: 5
Training loss: 0.3820273280143738
Validation loss: 1.7073661268398326

Epoch: 5| Step: 6
Training loss: 0.3865639269351959
Validation loss: 1.6772997276757353

Epoch: 5| Step: 7
Training loss: 0.2688451409339905
Validation loss: 1.670905045283738

Epoch: 5| Step: 8
Training loss: 0.354470431804657
Validation loss: 1.633252287423739

Epoch: 5| Step: 9
Training loss: 0.27283042669296265
Validation loss: 1.6497799196550924

Epoch: 5| Step: 10
Training loss: 0.36032727360725403
Validation loss: 1.6135831315030333

Epoch: 327| Step: 0
Training loss: 0.38561564683914185
Validation loss: 1.6144840076405516

Epoch: 5| Step: 1
Training loss: 0.1505509614944458
Validation loss: 1.620549084037863

Epoch: 5| Step: 2
Training loss: 0.14161339402198792
Validation loss: 1.6266816059748332

Epoch: 5| Step: 3
Training loss: 0.6485812067985535
Validation loss: 1.646717079224125

Epoch: 5| Step: 4
Training loss: 0.30656927824020386
Validation loss: 1.6855074756888933

Epoch: 5| Step: 5
Training loss: 0.35542505979537964
Validation loss: 1.6665816755704983

Epoch: 5| Step: 6
Training loss: 0.3342549502849579
Validation loss: 1.6886870963599092

Epoch: 5| Step: 7
Training loss: 0.22067269682884216
Validation loss: 1.6609957410443215

Epoch: 5| Step: 8
Training loss: 0.2625386714935303
Validation loss: 1.6684028281960437

Epoch: 5| Step: 9
Training loss: 0.3934147357940674
Validation loss: 1.668030700375957

Epoch: 5| Step: 10
Training loss: 0.4780890941619873
Validation loss: 1.6505519459324498

Epoch: 328| Step: 0
Training loss: 0.5083786845207214
Validation loss: 1.6798155871770715

Epoch: 5| Step: 1
Training loss: 0.3812382221221924
Validation loss: 1.7058461314888411

Epoch: 5| Step: 2
Training loss: 0.24769330024719238
Validation loss: 1.7431428060736707

Epoch: 5| Step: 3
Training loss: 0.3554159998893738
Validation loss: 1.7768552316132413

Epoch: 5| Step: 4
Training loss: 0.33287155628204346
Validation loss: 1.7947367493824293

Epoch: 5| Step: 5
Training loss: 0.32312750816345215
Validation loss: 1.7875026169643606

Epoch: 5| Step: 6
Training loss: 0.13789789378643036
Validation loss: 1.758129963310816

Epoch: 5| Step: 7
Training loss: 0.22589287161827087
Validation loss: 1.7314635220394339

Epoch: 5| Step: 8
Training loss: 0.40928563475608826
Validation loss: 1.7229952966013262

Epoch: 5| Step: 9
Training loss: 0.3178727924823761
Validation loss: 1.7284089903677664

Epoch: 5| Step: 10
Training loss: 0.3426080644130707
Validation loss: 1.679055222900965

Epoch: 329| Step: 0
Training loss: 0.25302135944366455
Validation loss: 1.6927602752562492

Epoch: 5| Step: 1
Training loss: 0.4216429591178894
Validation loss: 1.6825629626550982

Epoch: 5| Step: 2
Training loss: 0.31149330735206604
Validation loss: 1.67094002872385

Epoch: 5| Step: 3
Training loss: 0.3397185206413269
Validation loss: 1.700665525210801

Epoch: 5| Step: 4
Training loss: 0.31533294916152954
Validation loss: 1.711397244084266

Epoch: 5| Step: 5
Training loss: 0.255341112613678
Validation loss: 1.6812258792179886

Epoch: 5| Step: 6
Training loss: 0.44577986001968384
Validation loss: 1.7027630100968063

Epoch: 5| Step: 7
Training loss: 0.3507850766181946
Validation loss: 1.6646504978979788

Epoch: 5| Step: 8
Training loss: 0.3653694987297058
Validation loss: 1.6759834007550312

Epoch: 5| Step: 9
Training loss: 0.27572137117385864
Validation loss: 1.6999013321374052

Epoch: 5| Step: 10
Training loss: 0.2563779354095459
Validation loss: 1.6974205611854472

Epoch: 330| Step: 0
Training loss: 0.24545316398143768
Validation loss: 1.713431950538389

Epoch: 5| Step: 1
Training loss: 0.40976682305336
Validation loss: 1.700385465416857

Epoch: 5| Step: 2
Training loss: 0.2775062620639801
Validation loss: 1.67782990137736

Epoch: 5| Step: 3
Training loss: 0.2565201222896576
Validation loss: 1.6836417618618216

Epoch: 5| Step: 4
Training loss: 0.23154234886169434
Validation loss: 1.6838795113307174

Epoch: 5| Step: 5
Training loss: 0.28196173906326294
Validation loss: 1.6485256994924238

Epoch: 5| Step: 6
Training loss: 0.23784403502941132
Validation loss: 1.6371145556049962

Epoch: 5| Step: 7
Training loss: 0.3577198386192322
Validation loss: 1.668732773873114

Epoch: 5| Step: 8
Training loss: 0.3238510489463806
Validation loss: 1.6044583474436114

Epoch: 5| Step: 9
Training loss: 0.3002796471118927
Validation loss: 1.5875459447983773

Epoch: 5| Step: 10
Training loss: 0.4122256636619568
Validation loss: 1.6010784769570956

Epoch: 331| Step: 0
Training loss: 0.2982475161552429
Validation loss: 1.6058314461861887

Epoch: 5| Step: 1
Training loss: 0.4508330225944519
Validation loss: 1.590228448631943

Epoch: 5| Step: 2
Training loss: 0.1759212613105774
Validation loss: 1.6604005162433912

Epoch: 5| Step: 3
Training loss: 0.28741106390953064
Validation loss: 1.643149891207295

Epoch: 5| Step: 4
Training loss: 0.2962203919887543
Validation loss: 1.7128575322448567

Epoch: 5| Step: 5
Training loss: 0.3475143611431122
Validation loss: 1.7441237639355403

Epoch: 5| Step: 6
Training loss: 0.32305335998535156
Validation loss: 1.7678801846760575

Epoch: 5| Step: 7
Training loss: 0.4648227095603943
Validation loss: 1.7898619713321808

Epoch: 5| Step: 8
Training loss: 0.34197962284088135
Validation loss: 1.749459320499051

Epoch: 5| Step: 9
Training loss: 0.360398530960083
Validation loss: 1.7234382808849376

Epoch: 5| Step: 10
Training loss: 0.349269837141037
Validation loss: 1.6655920718305854

Epoch: 332| Step: 0
Training loss: 0.44668811559677124
Validation loss: 1.6464436490048644

Epoch: 5| Step: 1
Training loss: 0.25440269708633423
Validation loss: 1.648438101173729

Epoch: 5| Step: 2
Training loss: 0.3430115580558777
Validation loss: 1.635630085904111

Epoch: 5| Step: 3
Training loss: 0.4226594865322113
Validation loss: 1.6787799609604703

Epoch: 5| Step: 4
Training loss: 0.2509450614452362
Validation loss: 1.716688604765041

Epoch: 5| Step: 5
Training loss: 0.3847064673900604
Validation loss: 1.7339803429060086

Epoch: 5| Step: 6
Training loss: 0.35451197624206543
Validation loss: 1.7750346070976668

Epoch: 5| Step: 7
Training loss: 0.2972528040409088
Validation loss: 1.7668912410736084

Epoch: 5| Step: 8
Training loss: 0.33328738808631897
Validation loss: 1.7291681587055165

Epoch: 5| Step: 9
Training loss: 0.24494707584381104
Validation loss: 1.7063352856584775

Epoch: 5| Step: 10
Training loss: 0.2344679832458496
Validation loss: 1.6981551378004012

Epoch: 333| Step: 0
Training loss: 0.3310151696205139
Validation loss: 1.6933588955992012

Epoch: 5| Step: 1
Training loss: 0.5378910899162292
Validation loss: 1.712635124242434

Epoch: 5| Step: 2
Training loss: 0.2996077537536621
Validation loss: 1.7465881327147126

Epoch: 5| Step: 3
Training loss: 0.2707149386405945
Validation loss: 1.7384592999694168

Epoch: 5| Step: 4
Training loss: 0.3060341477394104
Validation loss: 1.7701755031462638

Epoch: 5| Step: 5
Training loss: 0.3021380603313446
Validation loss: 1.799842091016872

Epoch: 5| Step: 6
Training loss: 0.16955658793449402
Validation loss: 1.754954755947154

Epoch: 5| Step: 7
Training loss: 0.39591723680496216
Validation loss: 1.7491663264971908

Epoch: 5| Step: 8
Training loss: 0.18669667840003967
Validation loss: 1.7135384441703878

Epoch: 5| Step: 9
Training loss: 0.2184775173664093
Validation loss: 1.6921394204580655

Epoch: 5| Step: 10
Training loss: 0.485848605632782
Validation loss: 1.681036154429118

Epoch: 334| Step: 0
Training loss: 0.4594728946685791
Validation loss: 1.6677814837424987

Epoch: 5| Step: 1
Training loss: 0.24267998337745667
Validation loss: 1.6695417922030213

Epoch: 5| Step: 2
Training loss: 0.4092872738838196
Validation loss: 1.6520767327277892

Epoch: 5| Step: 3
Training loss: 0.31114110350608826
Validation loss: 1.6694477527372298

Epoch: 5| Step: 4
Training loss: 0.33270150423049927
Validation loss: 1.6939207123171898

Epoch: 5| Step: 5
Training loss: 0.32432612776756287
Validation loss: 1.6957719428564912

Epoch: 5| Step: 6
Training loss: 0.30714625120162964
Validation loss: 1.6816496797787246

Epoch: 5| Step: 7
Training loss: 0.1654314547777176
Validation loss: 1.6651007013936197

Epoch: 5| Step: 8
Training loss: 0.2231520414352417
Validation loss: 1.7086024361272012

Epoch: 5| Step: 9
Training loss: 0.20825684070587158
Validation loss: 1.7168071680171515

Epoch: 5| Step: 10
Training loss: 0.20463894307613373
Validation loss: 1.743394403047459

Epoch: 335| Step: 0
Training loss: 0.38143226504325867
Validation loss: 1.7619042832364318

Epoch: 5| Step: 1
Training loss: 0.2161567211151123
Validation loss: 1.7564401549677695

Epoch: 5| Step: 2
Training loss: 0.2927103638648987
Validation loss: 1.7246723008412186

Epoch: 5| Step: 3
Training loss: 0.2838612496852875
Validation loss: 1.696559436859623

Epoch: 5| Step: 4
Training loss: 0.39686793088912964
Validation loss: 1.6759339288998676

Epoch: 5| Step: 5
Training loss: 0.2485940158367157
Validation loss: 1.6191480710942259

Epoch: 5| Step: 6
Training loss: 0.3916749954223633
Validation loss: 1.6532772766646517

Epoch: 5| Step: 7
Training loss: 0.17123255133628845
Validation loss: 1.6703220759668658

Epoch: 5| Step: 8
Training loss: 0.2654873728752136
Validation loss: 1.6111826178848103

Epoch: 5| Step: 9
Training loss: 0.22730867564678192
Validation loss: 1.6350756281165666

Epoch: 5| Step: 10
Training loss: 0.49347394704818726
Validation loss: 1.6639784241235385

Epoch: 336| Step: 0
Training loss: 0.4125553071498871
Validation loss: 1.6815123481135215

Epoch: 5| Step: 1
Training loss: 0.3843333423137665
Validation loss: 1.6968091662212084

Epoch: 5| Step: 2
Training loss: 0.3161460757255554
Validation loss: 1.724629134260198

Epoch: 5| Step: 3
Training loss: 0.20391058921813965
Validation loss: 1.7290731758199713

Epoch: 5| Step: 4
Training loss: 0.42578667402267456
Validation loss: 1.7459981813225696

Epoch: 5| Step: 5
Training loss: 0.42598873376846313
Validation loss: 1.7569926182428997

Epoch: 5| Step: 6
Training loss: 0.346334308385849
Validation loss: 1.7844479750561457

Epoch: 5| Step: 7
Training loss: 0.3038828372955322
Validation loss: 1.7714495223055604

Epoch: 5| Step: 8
Training loss: 0.2521520256996155
Validation loss: 1.7560049641516902

Epoch: 5| Step: 9
Training loss: 0.2027706354856491
Validation loss: 1.723617631901977

Epoch: 5| Step: 10
Training loss: 0.19259494543075562
Validation loss: 1.723589870237535

Epoch: 337| Step: 0
Training loss: 0.25268250703811646
Validation loss: 1.7180105499041978

Epoch: 5| Step: 1
Training loss: 0.2092418670654297
Validation loss: 1.7168522970650786

Epoch: 5| Step: 2
Training loss: 0.14494019746780396
Validation loss: 1.7432827705978065

Epoch: 5| Step: 3
Training loss: 0.42937907576560974
Validation loss: 1.7200636568889822

Epoch: 5| Step: 4
Training loss: 0.3338731825351715
Validation loss: 1.7178324704529138

Epoch: 5| Step: 5
Training loss: 0.29140228033065796
Validation loss: 1.7205112570075578

Epoch: 5| Step: 6
Training loss: 0.2387993037700653
Validation loss: 1.686474674491472

Epoch: 5| Step: 7
Training loss: 0.1525934487581253
Validation loss: 1.7093148308415567

Epoch: 5| Step: 8
Training loss: 0.1756235957145691
Validation loss: 1.6839036044254099

Epoch: 5| Step: 9
Training loss: 0.35076528787612915
Validation loss: 1.6398274347346316

Epoch: 5| Step: 10
Training loss: 0.37444019317626953
Validation loss: 1.6632302755950599

Epoch: 338| Step: 0
Training loss: 0.22175848484039307
Validation loss: 1.6396479862992481

Epoch: 5| Step: 1
Training loss: 0.33378085494041443
Validation loss: 1.6335151528799405

Epoch: 5| Step: 2
Training loss: 0.2785331606864929
Validation loss: 1.6461019772355274

Epoch: 5| Step: 3
Training loss: 0.35526347160339355
Validation loss: 1.645332697899111

Epoch: 5| Step: 4
Training loss: 0.24350802600383759
Validation loss: 1.6234207448138986

Epoch: 5| Step: 5
Training loss: 0.29877156019210815
Validation loss: 1.6277242834850023

Epoch: 5| Step: 6
Training loss: 0.258175790309906
Validation loss: 1.6689792679202171

Epoch: 5| Step: 7
Training loss: 0.19126765429973602
Validation loss: 1.7019895186988256

Epoch: 5| Step: 8
Training loss: 0.2094060629606247
Validation loss: 1.6653226024361067

Epoch: 5| Step: 9
Training loss: 0.5105093717575073
Validation loss: 1.6648558506401636

Epoch: 5| Step: 10
Training loss: 0.2948478162288666
Validation loss: 1.6830075556232083

Epoch: 339| Step: 0
Training loss: 0.24222421646118164
Validation loss: 1.6600854140456005

Epoch: 5| Step: 1
Training loss: 0.20250804722309113
Validation loss: 1.6366184834511048

Epoch: 5| Step: 2
Training loss: 0.278151273727417
Validation loss: 1.6723204748604887

Epoch: 5| Step: 3
Training loss: 0.21328699588775635
Validation loss: 1.6850176165180821

Epoch: 5| Step: 4
Training loss: 0.33395329117774963
Validation loss: 1.727294083564512

Epoch: 5| Step: 5
Training loss: 0.3781990110874176
Validation loss: 1.7372124900100052

Epoch: 5| Step: 6
Training loss: 0.42367514967918396
Validation loss: 1.729285325414391

Epoch: 5| Step: 7
Training loss: 0.30749550461769104
Validation loss: 1.6966552401101718

Epoch: 5| Step: 8
Training loss: 0.3521197438240051
Validation loss: 1.7104476844110796

Epoch: 5| Step: 9
Training loss: 0.17371872067451477
Validation loss: 1.6870977750388525

Epoch: 5| Step: 10
Training loss: 0.21724122762680054
Validation loss: 1.6892504807441466

Epoch: 340| Step: 0
Training loss: 0.13811685144901276
Validation loss: 1.6624956489891134

Epoch: 5| Step: 1
Training loss: 0.3673282265663147
Validation loss: 1.6615241913385288

Epoch: 5| Step: 2
Training loss: 0.34014803171157837
Validation loss: 1.6612720592047578

Epoch: 5| Step: 3
Training loss: 0.29220354557037354
Validation loss: 1.6389267713792863

Epoch: 5| Step: 4
Training loss: 0.21970057487487793
Validation loss: 1.6167596283779349

Epoch: 5| Step: 5
Training loss: 0.3445521295070648
Validation loss: 1.6514710892913163

Epoch: 5| Step: 6
Training loss: 0.4060477316379547
Validation loss: 1.6559083436125068

Epoch: 5| Step: 7
Training loss: 0.23947858810424805
Validation loss: 1.68010885612939

Epoch: 5| Step: 8
Training loss: 0.16242286562919617
Validation loss: 1.6923273186529837

Epoch: 5| Step: 9
Training loss: 0.14618591964244843
Validation loss: 1.7286625985176332

Epoch: 5| Step: 10
Training loss: 0.27438798546791077
Validation loss: 1.7380736976541498

Epoch: 341| Step: 0
Training loss: 0.3231448233127594
Validation loss: 1.802389032097273

Epoch: 5| Step: 1
Training loss: 0.26878514885902405
Validation loss: 1.7581238951734317

Epoch: 5| Step: 2
Training loss: 0.13482828438282013
Validation loss: 1.7139213828630344

Epoch: 5| Step: 3
Training loss: 0.3279438316822052
Validation loss: 1.6938354597296765

Epoch: 5| Step: 4
Training loss: 0.2740573287010193
Validation loss: 1.680426371994839

Epoch: 5| Step: 5
Training loss: 0.3025597929954529
Validation loss: 1.6977317269130419

Epoch: 5| Step: 6
Training loss: 0.3557795584201813
Validation loss: 1.6501670165728497

Epoch: 5| Step: 7
Training loss: 0.25938910245895386
Validation loss: 1.654900526487699

Epoch: 5| Step: 8
Training loss: 0.12032721936702728
Validation loss: 1.6690472697698941

Epoch: 5| Step: 9
Training loss: 0.28787052631378174
Validation loss: 1.6689151435770013

Epoch: 5| Step: 10
Training loss: 0.20523792505264282
Validation loss: 1.6417390941291727

Epoch: 342| Step: 0
Training loss: 0.2463257759809494
Validation loss: 1.6672610416207263

Epoch: 5| Step: 1
Training loss: 0.22472591698169708
Validation loss: 1.6354291926148117

Epoch: 5| Step: 2
Training loss: 0.24257461726665497
Validation loss: 1.6450581601870957

Epoch: 5| Step: 3
Training loss: 0.18972556293010712
Validation loss: 1.650364331019822

Epoch: 5| Step: 4
Training loss: 0.23984184861183167
Validation loss: 1.679345598784826

Epoch: 5| Step: 5
Training loss: 0.14146187901496887
Validation loss: 1.6892609288615565

Epoch: 5| Step: 6
Training loss: 0.21001386642456055
Validation loss: 1.6702683561591691

Epoch: 5| Step: 7
Training loss: 0.45212918519973755
Validation loss: 1.6888142708809144

Epoch: 5| Step: 8
Training loss: 0.20265889167785645
Validation loss: 1.6955077814799484

Epoch: 5| Step: 9
Training loss: 0.30317965149879456
Validation loss: 1.6641479230696155

Epoch: 5| Step: 10
Training loss: 0.3274521827697754
Validation loss: 1.643634525678491

Epoch: 343| Step: 0
Training loss: 0.1393900215625763
Validation loss: 1.6387979407464304

Epoch: 5| Step: 1
Training loss: 0.2756342887878418
Validation loss: 1.6481919673181349

Epoch: 5| Step: 2
Training loss: 0.22981977462768555
Validation loss: 1.662882775388738

Epoch: 5| Step: 3
Training loss: 0.34439945220947266
Validation loss: 1.6061946140822543

Epoch: 5| Step: 4
Training loss: 0.3781498968601227
Validation loss: 1.594906162190181

Epoch: 5| Step: 5
Training loss: 0.21206268668174744
Validation loss: 1.6319672907552412

Epoch: 5| Step: 6
Training loss: 0.17881275713443756
Validation loss: 1.607923210308116

Epoch: 5| Step: 7
Training loss: 0.20189225673675537
Validation loss: 1.6489080652113883

Epoch: 5| Step: 8
Training loss: 0.16226747632026672
Validation loss: 1.6304886892277708

Epoch: 5| Step: 9
Training loss: 0.19561859965324402
Validation loss: 1.6187257664178007

Epoch: 5| Step: 10
Training loss: 0.14028511941432953
Validation loss: 1.65109081550311

Epoch: 344| Step: 0
Training loss: 0.28979748487472534
Validation loss: 1.6558994298340173

Epoch: 5| Step: 1
Training loss: 0.09528811275959015
Validation loss: 1.62346391524038

Epoch: 5| Step: 2
Training loss: 0.3001739978790283
Validation loss: 1.6550042603605537

Epoch: 5| Step: 3
Training loss: 0.3264574408531189
Validation loss: 1.6307535197145195

Epoch: 5| Step: 4
Training loss: 0.1870357096195221
Validation loss: 1.6415979221302976

Epoch: 5| Step: 5
Training loss: 0.16064150631427765
Validation loss: 1.6058388397257815

Epoch: 5| Step: 6
Training loss: 0.19014298915863037
Validation loss: 1.6678310953160769

Epoch: 5| Step: 7
Training loss: 0.28453561663627625
Validation loss: 1.6141184888860232

Epoch: 5| Step: 8
Training loss: 0.17569950222969055
Validation loss: 1.6384512352687057

Epoch: 5| Step: 9
Training loss: 0.2827136218547821
Validation loss: 1.6796052840448195

Epoch: 5| Step: 10
Training loss: 0.3065524101257324
Validation loss: 1.6867255946641326

Epoch: 345| Step: 0
Training loss: 0.4497290551662445
Validation loss: 1.6587581185884372

Epoch: 5| Step: 1
Training loss: 0.17436131834983826
Validation loss: 1.6697879209313342

Epoch: 5| Step: 2
Training loss: 0.2495909184217453
Validation loss: 1.6967776654868998

Epoch: 5| Step: 3
Training loss: 0.20703275501728058
Validation loss: 1.659334954395089

Epoch: 5| Step: 4
Training loss: 0.25888168811798096
Validation loss: 1.656755373042117

Epoch: 5| Step: 5
Training loss: 0.20144692063331604
Validation loss: 1.6556660154814362

Epoch: 5| Step: 6
Training loss: 0.21420125663280487
Validation loss: 1.685488800848684

Epoch: 5| Step: 7
Training loss: 0.1884167194366455
Validation loss: 1.6541232024469683

Epoch: 5| Step: 8
Training loss: 0.16366252303123474
Validation loss: 1.6606289225239907

Epoch: 5| Step: 9
Training loss: 0.1389971673488617
Validation loss: 1.66972771639465

Epoch: 5| Step: 10
Training loss: 0.4085698425769806
Validation loss: 1.680572364279019

Epoch: 346| Step: 0
Training loss: 0.23867936432361603
Validation loss: 1.6660234569221415

Epoch: 5| Step: 1
Training loss: 0.18071630597114563
Validation loss: 1.6784472491151543

Epoch: 5| Step: 2
Training loss: 0.28329703211784363
Validation loss: 1.6683274930523289

Epoch: 5| Step: 3
Training loss: 0.3342316746711731
Validation loss: 1.6434409669650498

Epoch: 5| Step: 4
Training loss: 0.19455203413963318
Validation loss: 1.6313780546188354

Epoch: 5| Step: 5
Training loss: 0.3317447006702423
Validation loss: 1.6550637727142663

Epoch: 5| Step: 6
Training loss: 0.22315995395183563
Validation loss: 1.6662638905227825

Epoch: 5| Step: 7
Training loss: 0.08491909503936768
Validation loss: 1.6453063103460497

Epoch: 5| Step: 8
Training loss: 0.21185079216957092
Validation loss: 1.6814343493471864

Epoch: 5| Step: 9
Training loss: 0.3811778724193573
Validation loss: 1.6828433057313323

Epoch: 5| Step: 10
Training loss: 0.250460684299469
Validation loss: 1.6668912967046101

Epoch: 347| Step: 0
Training loss: 0.23711328208446503
Validation loss: 1.7095908734106249

Epoch: 5| Step: 1
Training loss: 0.21167311072349548
Validation loss: 1.7299655861752008

Epoch: 5| Step: 2
Training loss: 0.2650871276855469
Validation loss: 1.7196351699931647

Epoch: 5| Step: 3
Training loss: 0.4828105568885803
Validation loss: 1.7148509679302093

Epoch: 5| Step: 4
Training loss: 0.3850117325782776
Validation loss: 1.7204995937244867

Epoch: 5| Step: 5
Training loss: 0.15039417147636414
Validation loss: 1.7135561755908433

Epoch: 5| Step: 6
Training loss: 0.16604582965373993
Validation loss: 1.6828498468604138

Epoch: 5| Step: 7
Training loss: 0.11052193492650986
Validation loss: 1.6797142233899844

Epoch: 5| Step: 8
Training loss: 0.230519101023674
Validation loss: 1.6742064478576824

Epoch: 5| Step: 9
Training loss: 0.2131444215774536
Validation loss: 1.6619756144862021

Epoch: 5| Step: 10
Training loss: 0.20540666580200195
Validation loss: 1.6912307752076017

Epoch: 348| Step: 0
Training loss: 0.2857789099216461
Validation loss: 1.726362689848869

Epoch: 5| Step: 1
Training loss: 0.22613172233104706
Validation loss: 1.6483481558420325

Epoch: 5| Step: 2
Training loss: 0.20675954222679138
Validation loss: 1.6698103502232542

Epoch: 5| Step: 3
Training loss: 0.16346168518066406
Validation loss: 1.644814263107956

Epoch: 5| Step: 4
Training loss: 0.26298606395721436
Validation loss: 1.649538238843282

Epoch: 5| Step: 5
Training loss: 0.2825414538383484
Validation loss: 1.6217350203503844

Epoch: 5| Step: 6
Training loss: 0.2127257138490677
Validation loss: 1.6396625490598782

Epoch: 5| Step: 7
Training loss: 0.30967622995376587
Validation loss: 1.624007406414196

Epoch: 5| Step: 8
Training loss: 0.28093260526657104
Validation loss: 1.63333821681238

Epoch: 5| Step: 9
Training loss: 0.34613972902297974
Validation loss: 1.6660835166131296

Epoch: 5| Step: 10
Training loss: 0.1937970519065857
Validation loss: 1.6445691226631083

Epoch: 349| Step: 0
Training loss: 0.3207995891571045
Validation loss: 1.6481652439281504

Epoch: 5| Step: 1
Training loss: 0.14480090141296387
Validation loss: 1.6838002589441114

Epoch: 5| Step: 2
Training loss: 0.28315362334251404
Validation loss: 1.6853381869613484

Epoch: 5| Step: 3
Training loss: 0.2664130926132202
Validation loss: 1.7234156413744854

Epoch: 5| Step: 4
Training loss: 0.31708988547325134
Validation loss: 1.7183579565376363

Epoch: 5| Step: 5
Training loss: 0.2994382381439209
Validation loss: 1.7144817203603766

Epoch: 5| Step: 6
Training loss: 0.22674866020679474
Validation loss: 1.7135683798020886

Epoch: 5| Step: 7
Training loss: 0.23555521667003632
Validation loss: 1.7066664836739982

Epoch: 5| Step: 8
Training loss: 0.20147092640399933
Validation loss: 1.7200500747208953

Epoch: 5| Step: 9
Training loss: 0.20935185253620148
Validation loss: 1.6784520219731074

Epoch: 5| Step: 10
Training loss: 0.268553227186203
Validation loss: 1.7092630286370554

Epoch: 350| Step: 0
Training loss: 0.2743324637413025
Validation loss: 1.6931144127281763

Epoch: 5| Step: 1
Training loss: 0.1900172233581543
Validation loss: 1.6700223415128645

Epoch: 5| Step: 2
Training loss: 0.21889109909534454
Validation loss: 1.6518260022645355

Epoch: 5| Step: 3
Training loss: 0.20265290141105652
Validation loss: 1.7118608182476414

Epoch: 5| Step: 4
Training loss: 0.29670724272727966
Validation loss: 1.6775692303975422

Epoch: 5| Step: 5
Training loss: 0.1662786453962326
Validation loss: 1.6915012572401313

Epoch: 5| Step: 6
Training loss: 0.31027668714523315
Validation loss: 1.6930670738220215

Epoch: 5| Step: 7
Training loss: 0.23481357097625732
Validation loss: 1.6628760125047417

Epoch: 5| Step: 8
Training loss: 0.26337355375289917
Validation loss: 1.6666372911904448

Epoch: 5| Step: 9
Training loss: 0.16057071089744568
Validation loss: 1.6526794279775312

Epoch: 5| Step: 10
Training loss: 0.2713369131088257
Validation loss: 1.6817272837444017

Epoch: 351| Step: 0
Training loss: 0.2706094980239868
Validation loss: 1.6951098954805763

Epoch: 5| Step: 1
Training loss: 0.27329081296920776
Validation loss: 1.6843643976796059

Epoch: 5| Step: 2
Training loss: 0.22661101818084717
Validation loss: 1.6904490173503917

Epoch: 5| Step: 3
Training loss: 0.19914975762367249
Validation loss: 1.71818551581393

Epoch: 5| Step: 4
Training loss: 0.23934057354927063
Validation loss: 1.7030043396898495

Epoch: 5| Step: 5
Training loss: 0.41855478286743164
Validation loss: 1.7158998744462126

Epoch: 5| Step: 6
Training loss: 0.1664927899837494
Validation loss: 1.693258257322414

Epoch: 5| Step: 7
Training loss: 0.19355431199073792
Validation loss: 1.712062817747875

Epoch: 5| Step: 8
Training loss: 0.17918869853019714
Validation loss: 1.6889536726859309

Epoch: 5| Step: 9
Training loss: 0.25717028975486755
Validation loss: 1.673473758082236

Epoch: 5| Step: 10
Training loss: 0.27663472294807434
Validation loss: 1.6463218542837328

Epoch: 352| Step: 0
Training loss: 0.2247765064239502
Validation loss: 1.6617115236097766

Epoch: 5| Step: 1
Training loss: 0.28094667196273804
Validation loss: 1.6810907702292166

Epoch: 5| Step: 2
Training loss: 0.23090168833732605
Validation loss: 1.6581457186770696

Epoch: 5| Step: 3
Training loss: 0.31464266777038574
Validation loss: 1.6660702484910206

Epoch: 5| Step: 4
Training loss: 0.24692270159721375
Validation loss: 1.6643406934635614

Epoch: 5| Step: 5
Training loss: 0.2394782304763794
Validation loss: 1.6965775656443771

Epoch: 5| Step: 6
Training loss: 0.22091355919837952
Validation loss: 1.6656238648199266

Epoch: 5| Step: 7
Training loss: 0.19321461021900177
Validation loss: 1.6831400176530242

Epoch: 5| Step: 8
Training loss: 0.369558721780777
Validation loss: 1.6926540969520487

Epoch: 5| Step: 9
Training loss: 0.2553963363170624
Validation loss: 1.7050679986194899

Epoch: 5| Step: 10
Training loss: 0.31350716948509216
Validation loss: 1.708822783603463

Epoch: 353| Step: 0
Training loss: 0.31037452816963196
Validation loss: 1.7171166058509582

Epoch: 5| Step: 1
Training loss: 0.2610085904598236
Validation loss: 1.6752014089656133

Epoch: 5| Step: 2
Training loss: 0.33593448996543884
Validation loss: 1.6934891984026919

Epoch: 5| Step: 3
Training loss: 0.15407180786132812
Validation loss: 1.7239629555773992

Epoch: 5| Step: 4
Training loss: 0.2776853144168854
Validation loss: 1.705548829929803

Epoch: 5| Step: 5
Training loss: 0.27106332778930664
Validation loss: 1.6790427610438357

Epoch: 5| Step: 6
Training loss: 0.2363189160823822
Validation loss: 1.681314496583836

Epoch: 5| Step: 7
Training loss: 0.22525420784950256
Validation loss: 1.687172584636237

Epoch: 5| Step: 8
Training loss: 0.29267618060112
Validation loss: 1.6747788524114957

Epoch: 5| Step: 9
Training loss: 0.3204478919506073
Validation loss: 1.6404757294603574

Epoch: 5| Step: 10
Training loss: 0.23107284307479858
Validation loss: 1.6692382456153951

Epoch: 354| Step: 0
Training loss: 0.30262935161590576
Validation loss: 1.6815688097348778

Epoch: 5| Step: 1
Training loss: 0.18765534460544586
Validation loss: 1.6689919041049095

Epoch: 5| Step: 2
Training loss: 0.30517956614494324
Validation loss: 1.705447873761577

Epoch: 5| Step: 3
Training loss: 0.20383572578430176
Validation loss: 1.6871247214655722

Epoch: 5| Step: 4
Training loss: 0.21730688214302063
Validation loss: 1.665914931604939

Epoch: 5| Step: 5
Training loss: 0.21352848410606384
Validation loss: 1.6392022294382895

Epoch: 5| Step: 6
Training loss: 0.26478853821754456
Validation loss: 1.692648063423813

Epoch: 5| Step: 7
Training loss: 0.22169438004493713
Validation loss: 1.6672346873949933

Epoch: 5| Step: 8
Training loss: 0.27873972058296204
Validation loss: 1.6790123107612773

Epoch: 5| Step: 9
Training loss: 0.22832265496253967
Validation loss: 1.6695398566543416

Epoch: 5| Step: 10
Training loss: 0.21129097044467926
Validation loss: 1.6919910818017938

Epoch: 355| Step: 0
Training loss: 0.2065066397190094
Validation loss: 1.6375849221342353

Epoch: 5| Step: 1
Training loss: 0.19290021061897278
Validation loss: 1.665393207662849

Epoch: 5| Step: 2
Training loss: 0.3644260764122009
Validation loss: 1.6590793440418858

Epoch: 5| Step: 3
Training loss: 0.28319892287254333
Validation loss: 1.644755768519576

Epoch: 5| Step: 4
Training loss: 0.3366681933403015
Validation loss: 1.62101766819595

Epoch: 5| Step: 5
Training loss: 0.3657950162887573
Validation loss: 1.6445324459383566

Epoch: 5| Step: 6
Training loss: 0.2249186486005783
Validation loss: 1.619796900339024

Epoch: 5| Step: 7
Training loss: 0.24420399963855743
Validation loss: 1.6388605179325226

Epoch: 5| Step: 8
Training loss: 0.1537664383649826
Validation loss: 1.6695560011812436

Epoch: 5| Step: 9
Training loss: 0.17964592576026917
Validation loss: 1.7116667647515573

Epoch: 5| Step: 10
Training loss: 0.2777661979198456
Validation loss: 1.7111918618602138

Epoch: 356| Step: 0
Training loss: 0.2086678296327591
Validation loss: 1.660187062396798

Epoch: 5| Step: 1
Training loss: 0.20287159085273743
Validation loss: 1.640324088834947

Epoch: 5| Step: 2
Training loss: 0.2506420612335205
Validation loss: 1.6521587884554298

Epoch: 5| Step: 3
Training loss: 0.2019219696521759
Validation loss: 1.641714067869289

Epoch: 5| Step: 4
Training loss: 0.2912946343421936
Validation loss: 1.636969765027364

Epoch: 5| Step: 5
Training loss: 0.18571123480796814
Validation loss: 1.639759768721878

Epoch: 5| Step: 6
Training loss: 0.3011902868747711
Validation loss: 1.6593253304881435

Epoch: 5| Step: 7
Training loss: 0.20557141304016113
Validation loss: 1.6156483850171488

Epoch: 5| Step: 8
Training loss: 0.3324826657772064
Validation loss: 1.6477088710313201

Epoch: 5| Step: 9
Training loss: 0.22236080467700958
Validation loss: 1.6622531260213544

Epoch: 5| Step: 10
Training loss: 0.2782409191131592
Validation loss: 1.6950714139528171

Epoch: 357| Step: 0
Training loss: 0.2850988209247589
Validation loss: 1.6683425236773748

Epoch: 5| Step: 1
Training loss: 0.36450543999671936
Validation loss: 1.6195144691774923

Epoch: 5| Step: 2
Training loss: 0.22348952293395996
Validation loss: 1.6524429090561406

Epoch: 5| Step: 3
Training loss: 0.16638830304145813
Validation loss: 1.656645736386699

Epoch: 5| Step: 4
Training loss: 0.24867752194404602
Validation loss: 1.628132261255736

Epoch: 5| Step: 5
Training loss: 0.19125397503376007
Validation loss: 1.6586718982265842

Epoch: 5| Step: 6
Training loss: 0.174941286444664
Validation loss: 1.6864689588546753

Epoch: 5| Step: 7
Training loss: 0.19150307774543762
Validation loss: 1.7112146526254632

Epoch: 5| Step: 8
Training loss: 0.28380995988845825
Validation loss: 1.6952648316660235

Epoch: 5| Step: 9
Training loss: 0.22902588546276093
Validation loss: 1.7067298350795623

Epoch: 5| Step: 10
Training loss: 0.29713666439056396
Validation loss: 1.689062515894572

Epoch: 358| Step: 0
Training loss: 0.2462308406829834
Validation loss: 1.6809374158100416

Epoch: 5| Step: 1
Training loss: 0.29369646310806274
Validation loss: 1.6973946562377356

Epoch: 5| Step: 2
Training loss: 0.17124734818935394
Validation loss: 1.7134467799176452

Epoch: 5| Step: 3
Training loss: 0.33870476484298706
Validation loss: 1.7119616898157264

Epoch: 5| Step: 4
Training loss: 0.24023552238941193
Validation loss: 1.6674668917091944

Epoch: 5| Step: 5
Training loss: 0.2184697836637497
Validation loss: 1.6656996575734948

Epoch: 5| Step: 6
Training loss: 0.22808487713336945
Validation loss: 1.6565680068026307

Epoch: 5| Step: 7
Training loss: 0.16173426806926727
Validation loss: 1.6047409503690657

Epoch: 5| Step: 8
Training loss: 0.19660282135009766
Validation loss: 1.580267939516293

Epoch: 5| Step: 9
Training loss: 0.2972210943698883
Validation loss: 1.6213295139292234

Epoch: 5| Step: 10
Training loss: 0.1553061157464981
Validation loss: 1.6178387775216052

Epoch: 359| Step: 0
Training loss: 0.16593977808952332
Validation loss: 1.6051163904128536

Epoch: 5| Step: 1
Training loss: 0.30416691303253174
Validation loss: 1.6327854651276783

Epoch: 5| Step: 2
Training loss: 0.17265096306800842
Validation loss: 1.620798385271462

Epoch: 5| Step: 3
Training loss: 0.27789077162742615
Validation loss: 1.6790364121878019

Epoch: 5| Step: 4
Training loss: 0.22961218655109406
Validation loss: 1.6532395616654427

Epoch: 5| Step: 5
Training loss: 0.1560605764389038
Validation loss: 1.6790218712181173

Epoch: 5| Step: 6
Training loss: 0.15140719711780548
Validation loss: 1.6952942635423394

Epoch: 5| Step: 7
Training loss: 0.24806323647499084
Validation loss: 1.7217476201313797

Epoch: 5| Step: 8
Training loss: 0.2204412966966629
Validation loss: 1.6940361620277486

Epoch: 5| Step: 9
Training loss: 0.19435694813728333
Validation loss: 1.7048925020361458

Epoch: 5| Step: 10
Training loss: 0.3987606465816498
Validation loss: 1.6700213557930403

Epoch: 360| Step: 0
Training loss: 0.16448238492012024
Validation loss: 1.7034385153042373

Epoch: 5| Step: 1
Training loss: 0.30643099546432495
Validation loss: 1.7095611967066282

Epoch: 5| Step: 2
Training loss: 0.28768715262413025
Validation loss: 1.695460783537998

Epoch: 5| Step: 3
Training loss: 0.22809000313282013
Validation loss: 1.6884274175090175

Epoch: 5| Step: 4
Training loss: 0.2612190842628479
Validation loss: 1.696349338818622

Epoch: 5| Step: 5
Training loss: 0.2635924518108368
Validation loss: 1.6486329429893083

Epoch: 5| Step: 6
Training loss: 0.29500070214271545
Validation loss: 1.649448331966195

Epoch: 5| Step: 7
Training loss: 0.15410861372947693
Validation loss: 1.6315835880976852

Epoch: 5| Step: 8
Training loss: 0.21445207297801971
Validation loss: 1.607989186881691

Epoch: 5| Step: 9
Training loss: 0.173694908618927
Validation loss: 1.6161860932586014

Epoch: 5| Step: 10
Training loss: 0.2039327621459961
Validation loss: 1.6204531167143135

Epoch: 361| Step: 0
Training loss: 0.20854492485523224
Validation loss: 1.6250968299886233

Epoch: 5| Step: 1
Training loss: 0.24227598309516907
Validation loss: 1.6369778020407564

Epoch: 5| Step: 2
Training loss: 0.14116282761096954
Validation loss: 1.6169455115513136

Epoch: 5| Step: 3
Training loss: 0.23279504477977753
Validation loss: 1.63691359437922

Epoch: 5| Step: 4
Training loss: 0.32447758316993713
Validation loss: 1.6670031675728418

Epoch: 5| Step: 5
Training loss: 0.13391907513141632
Validation loss: 1.673449823933263

Epoch: 5| Step: 6
Training loss: 0.2225465327501297
Validation loss: 1.6984925962263537

Epoch: 5| Step: 7
Training loss: 0.12336082756519318
Validation loss: 1.7087514541482414

Epoch: 5| Step: 8
Training loss: 0.25322410464286804
Validation loss: 1.6903443016031736

Epoch: 5| Step: 9
Training loss: 0.23633208870887756
Validation loss: 1.7201202479741906

Epoch: 5| Step: 10
Training loss: 0.29945290088653564
Validation loss: 1.7040379431939894

Epoch: 362| Step: 0
Training loss: 0.1980394721031189
Validation loss: 1.6897426343733264

Epoch: 5| Step: 1
Training loss: 0.21014757454395294
Validation loss: 1.6502041662892988

Epoch: 5| Step: 2
Training loss: 0.2144506722688675
Validation loss: 1.6755135213175127

Epoch: 5| Step: 3
Training loss: 0.2342829704284668
Validation loss: 1.6762939653088968

Epoch: 5| Step: 4
Training loss: 0.12729938328266144
Validation loss: 1.6718870593655495

Epoch: 5| Step: 5
Training loss: 0.17851392924785614
Validation loss: 1.6261945161768185

Epoch: 5| Step: 6
Training loss: 0.17503945529460907
Validation loss: 1.6379563167531004

Epoch: 5| Step: 7
Training loss: 0.32389235496520996
Validation loss: 1.6585097960246507

Epoch: 5| Step: 8
Training loss: 0.1565476655960083
Validation loss: 1.6568852291312268

Epoch: 5| Step: 9
Training loss: 0.2422753870487213
Validation loss: 1.652047359815208

Epoch: 5| Step: 10
Training loss: 0.21434208750724792
Validation loss: 1.657729019400894

Epoch: 363| Step: 0
Training loss: 0.2439669370651245
Validation loss: 1.650210572827247

Epoch: 5| Step: 1
Training loss: 0.2972368597984314
Validation loss: 1.6444571210492043

Epoch: 5| Step: 2
Training loss: 0.14528682827949524
Validation loss: 1.6478107334465109

Epoch: 5| Step: 3
Training loss: 0.2871144413948059
Validation loss: 1.6704061338978429

Epoch: 5| Step: 4
Training loss: 0.2888515889644623
Validation loss: 1.7056235036542338

Epoch: 5| Step: 5
Training loss: 0.2083677053451538
Validation loss: 1.6966759274082799

Epoch: 5| Step: 6
Training loss: 0.2209143340587616
Validation loss: 1.7023068115275393

Epoch: 5| Step: 7
Training loss: 0.1542966067790985
Validation loss: 1.6846142238186252

Epoch: 5| Step: 8
Training loss: 0.15284965932369232
Validation loss: 1.6997473150171258

Epoch: 5| Step: 9
Training loss: 0.2392444610595703
Validation loss: 1.7028189679627777

Epoch: 5| Step: 10
Training loss: 0.24442307651042938
Validation loss: 1.6999936514003302

Epoch: 364| Step: 0
Training loss: 0.21884147822856903
Validation loss: 1.7001521792463077

Epoch: 5| Step: 1
Training loss: 0.13022299110889435
Validation loss: 1.6884812231986754

Epoch: 5| Step: 2
Training loss: 0.3076130449771881
Validation loss: 1.6974591965316443

Epoch: 5| Step: 3
Training loss: 0.20440860092639923
Validation loss: 1.6851820279193181

Epoch: 5| Step: 4
Training loss: 0.17646697163581848
Validation loss: 1.6282764980869908

Epoch: 5| Step: 5
Training loss: 0.22156386077404022
Validation loss: 1.6114293926505632

Epoch: 5| Step: 6
Training loss: 0.18551521003246307
Validation loss: 1.606384454234954

Epoch: 5| Step: 7
Training loss: 0.17591522634029388
Validation loss: 1.6002073480236916

Epoch: 5| Step: 8
Training loss: 0.20752155780792236
Validation loss: 1.5616232015753304

Epoch: 5| Step: 9
Training loss: 0.2936447858810425
Validation loss: 1.5618924030693628

Epoch: 5| Step: 10
Training loss: 0.26161694526672363
Validation loss: 1.5632578147354947

Epoch: 365| Step: 0
Training loss: 0.2623635232448578
Validation loss: 1.5429096080923592

Epoch: 5| Step: 1
Training loss: 0.215336412191391
Validation loss: 1.5351740326932681

Epoch: 5| Step: 2
Training loss: 0.17560935020446777
Validation loss: 1.579535153604323

Epoch: 5| Step: 3
Training loss: 0.14743082225322723
Validation loss: 1.5875329189403082

Epoch: 5| Step: 4
Training loss: 0.13839168846607208
Validation loss: 1.622699805485305

Epoch: 5| Step: 5
Training loss: 0.1938256323337555
Validation loss: 1.6347447505561254

Epoch: 5| Step: 6
Training loss: 0.38121381402015686
Validation loss: 1.6117310126622517

Epoch: 5| Step: 7
Training loss: 0.12905625998973846
Validation loss: 1.6279018578990814

Epoch: 5| Step: 8
Training loss: 0.11200086772441864
Validation loss: 1.615983493866459

Epoch: 5| Step: 9
Training loss: 0.1873970329761505
Validation loss: 1.6117985517747941

Epoch: 5| Step: 10
Training loss: 0.35171547532081604
Validation loss: 1.6711775666923934

Epoch: 366| Step: 0
Training loss: 0.26390451192855835
Validation loss: 1.6449109097962737

Epoch: 5| Step: 1
Training loss: 0.23650667071342468
Validation loss: 1.6249753467498287

Epoch: 5| Step: 2
Training loss: 0.2566351890563965
Validation loss: 1.662378505993915

Epoch: 5| Step: 3
Training loss: 0.20307791233062744
Validation loss: 1.6846341497154647

Epoch: 5| Step: 4
Training loss: 0.20669862627983093
Validation loss: 1.6816966354206044

Epoch: 5| Step: 5
Training loss: 0.22579006850719452
Validation loss: 1.6443441478154992

Epoch: 5| Step: 6
Training loss: 0.17257177829742432
Validation loss: 1.6829692586775749

Epoch: 5| Step: 7
Training loss: 0.2075825184583664
Validation loss: 1.6611688342145694

Epoch: 5| Step: 8
Training loss: 0.16540175676345825
Validation loss: 1.6661266665304861

Epoch: 5| Step: 9
Training loss: 0.12326322495937347
Validation loss: 1.6520025922406105

Epoch: 5| Step: 10
Training loss: 0.42935848236083984
Validation loss: 1.665863747237831

Epoch: 367| Step: 0
Training loss: 0.23814158141613007
Validation loss: 1.621090942813504

Epoch: 5| Step: 1
Training loss: 0.18129658699035645
Validation loss: 1.6187124303592149

Epoch: 5| Step: 2
Training loss: 0.14753741025924683
Validation loss: 1.6096322491604795

Epoch: 5| Step: 3
Training loss: 0.1823885142803192
Validation loss: 1.603937178529719

Epoch: 5| Step: 4
Training loss: 0.16449229419231415
Validation loss: 1.625608935151049

Epoch: 5| Step: 5
Training loss: 0.3223477303981781
Validation loss: 1.6047132117773897

Epoch: 5| Step: 6
Training loss: 0.24355439841747284
Validation loss: 1.6245711029216807

Epoch: 5| Step: 7
Training loss: 0.1135687381029129
Validation loss: 1.617171255491113

Epoch: 5| Step: 8
Training loss: 0.21140392124652863
Validation loss: 1.6316142364214825

Epoch: 5| Step: 9
Training loss: 0.28234291076660156
Validation loss: 1.6462984854175198

Epoch: 5| Step: 10
Training loss: 0.25528818368911743
Validation loss: 1.6305224844204482

Epoch: 368| Step: 0
Training loss: 0.3116852045059204
Validation loss: 1.6784602211367698

Epoch: 5| Step: 1
Training loss: 0.21891717612743378
Validation loss: 1.684161311836653

Epoch: 5| Step: 2
Training loss: 0.22784090042114258
Validation loss: 1.6260021758335892

Epoch: 5| Step: 3
Training loss: 0.1852060854434967
Validation loss: 1.6273511955814977

Epoch: 5| Step: 4
Training loss: 0.12846419215202332
Validation loss: 1.604928155099192

Epoch: 5| Step: 5
Training loss: 0.13680535554885864
Validation loss: 1.5859238332317722

Epoch: 5| Step: 6
Training loss: 0.208607479929924
Validation loss: 1.5853534808722876

Epoch: 5| Step: 7
Training loss: 0.22418951988220215
Validation loss: 1.6134101883057625

Epoch: 5| Step: 8
Training loss: 0.3158889710903168
Validation loss: 1.56559798794408

Epoch: 5| Step: 9
Training loss: 0.16537299752235413
Validation loss: 1.5884662328227874

Epoch: 5| Step: 10
Training loss: 0.22164779901504517
Validation loss: 1.5914399752052881

Epoch: 369| Step: 0
Training loss: 0.18002943694591522
Validation loss: 1.6152019064913514

Epoch: 5| Step: 1
Training loss: 0.13169685006141663
Validation loss: 1.6276977869772142

Epoch: 5| Step: 2
Training loss: 0.12981575727462769
Validation loss: 1.6509101365202217

Epoch: 5| Step: 3
Training loss: 0.24901099503040314
Validation loss: 1.6408482905357116

Epoch: 5| Step: 4
Training loss: 0.25146156549453735
Validation loss: 1.6310837627739034

Epoch: 5| Step: 5
Training loss: 0.2521243989467621
Validation loss: 1.5927999711805774

Epoch: 5| Step: 6
Training loss: 0.27733027935028076
Validation loss: 1.6160108838030087

Epoch: 5| Step: 7
Training loss: 0.18565328419208527
Validation loss: 1.589962887507613

Epoch: 5| Step: 8
Training loss: 0.14741531014442444
Validation loss: 1.5670007415997085

Epoch: 5| Step: 9
Training loss: 0.21665950119495392
Validation loss: 1.6267215192958873

Epoch: 5| Step: 10
Training loss: 0.36269834637641907
Validation loss: 1.6060361939091836

Epoch: 370| Step: 0
Training loss: 0.17471669614315033
Validation loss: 1.590204523455712

Epoch: 5| Step: 1
Training loss: 0.21120920777320862
Validation loss: 1.628170265946337

Epoch: 5| Step: 2
Training loss: 0.22035253047943115
Validation loss: 1.6682887372150217

Epoch: 5| Step: 3
Training loss: 0.23747971653938293
Validation loss: 1.6784746864790558

Epoch: 5| Step: 4
Training loss: 0.2043900489807129
Validation loss: 1.6816180111259542

Epoch: 5| Step: 5
Training loss: 0.23933498561382294
Validation loss: 1.6618013074321132

Epoch: 5| Step: 6
Training loss: 0.14201217889785767
Validation loss: 1.675066872309613

Epoch: 5| Step: 7
Training loss: 0.27108967304229736
Validation loss: 1.647472894319924

Epoch: 5| Step: 8
Training loss: 0.20069646835327148
Validation loss: 1.6451695196090206

Epoch: 5| Step: 9
Training loss: 0.12928366661071777
Validation loss: 1.6769734095501643

Epoch: 5| Step: 10
Training loss: 0.15659001469612122
Validation loss: 1.66904563865354

Epoch: 371| Step: 0
Training loss: 0.11396698653697968
Validation loss: 1.683714420564713

Epoch: 5| Step: 1
Training loss: 0.14660011231899261
Validation loss: 1.7109109445284771

Epoch: 5| Step: 2
Training loss: 0.12859371304512024
Validation loss: 1.6901249219012517

Epoch: 5| Step: 3
Training loss: 0.1893680840730667
Validation loss: 1.7227764475730158

Epoch: 5| Step: 4
Training loss: 0.16532272100448608
Validation loss: 1.701300718451059

Epoch: 5| Step: 5
Training loss: 0.19139687716960907
Validation loss: 1.710643038954786

Epoch: 5| Step: 6
Training loss: 0.2687951922416687
Validation loss: 1.6632087128136748

Epoch: 5| Step: 7
Training loss: 0.2197260856628418
Validation loss: 1.6413235715640488

Epoch: 5| Step: 8
Training loss: 0.23175811767578125
Validation loss: 1.6254922164383756

Epoch: 5| Step: 9
Training loss: 0.23343467712402344
Validation loss: 1.628147796277077

Epoch: 5| Step: 10
Training loss: 0.3364887237548828
Validation loss: 1.605341843379441

Epoch: 372| Step: 0
Training loss: 0.26826179027557373
Validation loss: 1.6242392780960246

Epoch: 5| Step: 1
Training loss: 0.17637979984283447
Validation loss: 1.5951155885573356

Epoch: 5| Step: 2
Training loss: 0.1859176754951477
Validation loss: 1.6357281079856298

Epoch: 5| Step: 3
Training loss: 0.10271531343460083
Validation loss: 1.6270413744834162

Epoch: 5| Step: 4
Training loss: 0.2980850040912628
Validation loss: 1.683392261946073

Epoch: 5| Step: 5
Training loss: 0.19932368397712708
Validation loss: 1.6887714106549498

Epoch: 5| Step: 6
Training loss: 0.40921539068222046
Validation loss: 1.6872151513253488

Epoch: 5| Step: 7
Training loss: 0.22771823406219482
Validation loss: 1.6629268712894891

Epoch: 5| Step: 8
Training loss: 0.18540897965431213
Validation loss: 1.6404464270478936

Epoch: 5| Step: 9
Training loss: 0.17702922224998474
Validation loss: 1.6316041984865743

Epoch: 5| Step: 10
Training loss: 0.18257834017276764
Validation loss: 1.6164696383219894

Epoch: 373| Step: 0
Training loss: 0.17682020366191864
Validation loss: 1.6108954478335638

Epoch: 5| Step: 1
Training loss: 0.18982498347759247
Validation loss: 1.6512862072196057

Epoch: 5| Step: 2
Training loss: 0.23644128441810608
Validation loss: 1.6307887415732107

Epoch: 5| Step: 3
Training loss: 0.2167244851589203
Validation loss: 1.6656456557653283

Epoch: 5| Step: 4
Training loss: 0.25785401463508606
Validation loss: 1.6499038870616625

Epoch: 5| Step: 5
Training loss: 0.2854655981063843
Validation loss: 1.6096266649102653

Epoch: 5| Step: 6
Training loss: 0.19492249190807343
Validation loss: 1.6408747831980388

Epoch: 5| Step: 7
Training loss: 0.2638801634311676
Validation loss: 1.6670510615071943

Epoch: 5| Step: 8
Training loss: 0.15338456630706787
Validation loss: 1.6791158542838147

Epoch: 5| Step: 9
Training loss: 0.18785163760185242
Validation loss: 1.6579882470510339

Epoch: 5| Step: 10
Training loss: 0.1791844666004181
Validation loss: 1.6813500388976066

Epoch: 374| Step: 0
Training loss: 0.16832880675792694
Validation loss: 1.646723626762308

Epoch: 5| Step: 1
Training loss: 0.21979236602783203
Validation loss: 1.6523879561372983

Epoch: 5| Step: 2
Training loss: 0.23979084193706512
Validation loss: 1.6536923070107736

Epoch: 5| Step: 3
Training loss: 0.20217370986938477
Validation loss: 1.6649400111167663

Epoch: 5| Step: 4
Training loss: 0.15318217873573303
Validation loss: 1.6589147467767038

Epoch: 5| Step: 5
Training loss: 0.1420750916004181
Validation loss: 1.6821286139949676

Epoch: 5| Step: 6
Training loss: 0.22203321754932404
Validation loss: 1.6399660482201526

Epoch: 5| Step: 7
Training loss: 0.1410943567752838
Validation loss: 1.654658268856746

Epoch: 5| Step: 8
Training loss: 0.14710867404937744
Validation loss: 1.669140205588392

Epoch: 5| Step: 9
Training loss: 0.1877644956111908
Validation loss: 1.6686969675043577

Epoch: 5| Step: 10
Training loss: 0.19693523645401
Validation loss: 1.6626139328043947

Epoch: 375| Step: 0
Training loss: 0.1760455071926117
Validation loss: 1.6423158453356834

Epoch: 5| Step: 1
Training loss: 0.1921103298664093
Validation loss: 1.6524040743868837

Epoch: 5| Step: 2
Training loss: 0.23091760277748108
Validation loss: 1.629089306759578

Epoch: 5| Step: 3
Training loss: 0.08689933270215988
Validation loss: 1.6195277642178278

Epoch: 5| Step: 4
Training loss: 0.18792185187339783
Validation loss: 1.6280564236384567

Epoch: 5| Step: 5
Training loss: 0.16727124154567719
Validation loss: 1.6376305869830552

Epoch: 5| Step: 6
Training loss: 0.20613963901996613
Validation loss: 1.6776307026545207

Epoch: 5| Step: 7
Training loss: 0.20044764876365662
Validation loss: 1.668655877472252

Epoch: 5| Step: 8
Training loss: 0.23975512385368347
Validation loss: 1.6349672886633104

Epoch: 5| Step: 9
Training loss: 0.24810278415679932
Validation loss: 1.6183001738722607

Epoch: 5| Step: 10
Training loss: 0.19099672138690948
Validation loss: 1.648146960043138

Epoch: 376| Step: 0
Training loss: 0.23867420852184296
Validation loss: 1.6383781138286795

Epoch: 5| Step: 1
Training loss: 0.14141766726970673
Validation loss: 1.6429406519859069

Epoch: 5| Step: 2
Training loss: 0.1369544416666031
Validation loss: 1.6434304624475458

Epoch: 5| Step: 3
Training loss: 0.1501581221818924
Validation loss: 1.676435596199446

Epoch: 5| Step: 4
Training loss: 0.13130053877830505
Validation loss: 1.6251739750626266

Epoch: 5| Step: 5
Training loss: 0.17962069809436798
Validation loss: 1.6145203818557083

Epoch: 5| Step: 6
Training loss: 0.1768968254327774
Validation loss: 1.601600920000384

Epoch: 5| Step: 7
Training loss: 0.11314606666564941
Validation loss: 1.599957558416551

Epoch: 5| Step: 8
Training loss: 0.17810805141925812
Validation loss: 1.625567352899941

Epoch: 5| Step: 9
Training loss: 0.3778243064880371
Validation loss: 1.610501984114288

Epoch: 5| Step: 10
Training loss: 0.1070176288485527
Validation loss: 1.6286830158643826

Epoch: 377| Step: 0
Training loss: 0.06431063264608383
Validation loss: 1.5839608305244035

Epoch: 5| Step: 1
Training loss: 0.09895627945661545
Validation loss: 1.5840832405192877

Epoch: 5| Step: 2
Training loss: 0.1165585070848465
Validation loss: 1.603185123012912

Epoch: 5| Step: 3
Training loss: 0.132656529545784
Validation loss: 1.598374920506631

Epoch: 5| Step: 4
Training loss: 0.16666552424430847
Validation loss: 1.618451015923613

Epoch: 5| Step: 5
Training loss: 0.19021524488925934
Validation loss: 1.6134473713495399

Epoch: 5| Step: 6
Training loss: 0.21343350410461426
Validation loss: 1.6326764283641693

Epoch: 5| Step: 7
Training loss: 0.21690583229064941
Validation loss: 1.6231976606512581

Epoch: 5| Step: 8
Training loss: 0.23951753973960876
Validation loss: 1.6284708143562399

Epoch: 5| Step: 9
Training loss: 0.2442052811384201
Validation loss: 1.6222790005386516

Epoch: 5| Step: 10
Training loss: 0.2862517535686493
Validation loss: 1.6250993769655946

Epoch: 378| Step: 0
Training loss: 0.16029882431030273
Validation loss: 1.575423712371498

Epoch: 5| Step: 1
Training loss: 0.2007247507572174
Validation loss: 1.5986623366673787

Epoch: 5| Step: 2
Training loss: 0.206944078207016
Validation loss: 1.5971876754555652

Epoch: 5| Step: 3
Training loss: 0.14628279209136963
Validation loss: 1.5802092500912246

Epoch: 5| Step: 4
Training loss: 0.1840008944272995
Validation loss: 1.5995492345543318

Epoch: 5| Step: 5
Training loss: 0.19085094332695007
Validation loss: 1.5581412251277635

Epoch: 5| Step: 6
Training loss: 0.21183106303215027
Validation loss: 1.5694982582522976

Epoch: 5| Step: 7
Training loss: 0.14406171441078186
Validation loss: 1.5529937205776092

Epoch: 5| Step: 8
Training loss: 0.23913756012916565
Validation loss: 1.5582278954085482

Epoch: 5| Step: 9
Training loss: 0.1184193342924118
Validation loss: 1.5473933604455763

Epoch: 5| Step: 10
Training loss: 0.24906200170516968
Validation loss: 1.5746442271817116

Epoch: 379| Step: 0
Training loss: 0.14531776309013367
Validation loss: 1.5592962131705335

Epoch: 5| Step: 1
Training loss: 0.214814230799675
Validation loss: 1.5897950075005973

Epoch: 5| Step: 2
Training loss: 0.2121911346912384
Validation loss: 1.6072640431824552

Epoch: 5| Step: 3
Training loss: 0.22518830001354218
Validation loss: 1.6209878203689412

Epoch: 5| Step: 4
Training loss: 0.1204928383231163
Validation loss: 1.613887603564929

Epoch: 5| Step: 5
Training loss: 0.26701146364212036
Validation loss: 1.5961029093752626

Epoch: 5| Step: 6
Training loss: 0.1794278621673584
Validation loss: 1.6211094471716112

Epoch: 5| Step: 7
Training loss: 0.14573921263217926
Validation loss: 1.6027025330451228

Epoch: 5| Step: 8
Training loss: 0.1820460855960846
Validation loss: 1.5897096151946692

Epoch: 5| Step: 9
Training loss: 0.13246984779834747
Validation loss: 1.6163068894417054

Epoch: 5| Step: 10
Training loss: 0.25672033429145813
Validation loss: 1.6361405388001473

Epoch: 380| Step: 0
Training loss: 0.20051737129688263
Validation loss: 1.6391024358810917

Epoch: 5| Step: 1
Training loss: 0.29719704389572144
Validation loss: 1.6447401918390745

Epoch: 5| Step: 2
Training loss: 0.1082497388124466
Validation loss: 1.6398702424059632

Epoch: 5| Step: 3
Training loss: 0.21561022102832794
Validation loss: 1.647697110329905

Epoch: 5| Step: 4
Training loss: 0.1701832264661789
Validation loss: 1.6195734213757258

Epoch: 5| Step: 5
Training loss: 0.22931413352489471
Validation loss: 1.6162685296868766

Epoch: 5| Step: 6
Training loss: 0.12944704294204712
Validation loss: 1.613712715846236

Epoch: 5| Step: 7
Training loss: 0.13117238879203796
Validation loss: 1.6224609882600847

Epoch: 5| Step: 8
Training loss: 0.13070926070213318
Validation loss: 1.6187735962611374

Epoch: 5| Step: 9
Training loss: 0.1961197555065155
Validation loss: 1.640660314149754

Epoch: 5| Step: 10
Training loss: 0.22504980862140656
Validation loss: 1.6477121601822555

Epoch: 381| Step: 0
Training loss: 0.16983681917190552
Validation loss: 1.6726448984556301

Epoch: 5| Step: 1
Training loss: 0.12456993758678436
Validation loss: 1.6252704576779438

Epoch: 5| Step: 2
Training loss: 0.27220362424850464
Validation loss: 1.6413120403084704

Epoch: 5| Step: 3
Training loss: 0.13226793706417084
Validation loss: 1.6218069676429994

Epoch: 5| Step: 4
Training loss: 0.11811158806085587
Validation loss: 1.5963891603613412

Epoch: 5| Step: 5
Training loss: 0.22401699423789978
Validation loss: 1.5941153495542464

Epoch: 5| Step: 6
Training loss: 0.24508889019489288
Validation loss: 1.592747764561766

Epoch: 5| Step: 7
Training loss: 0.19968834519386292
Validation loss: 1.6065871971909718

Epoch: 5| Step: 8
Training loss: 0.10944590717554092
Validation loss: 1.5578541242948143

Epoch: 5| Step: 9
Training loss: 0.19334164261817932
Validation loss: 1.5951033176914338

Epoch: 5| Step: 10
Training loss: 0.18215790390968323
Validation loss: 1.543458455352373

Epoch: 382| Step: 0
Training loss: 0.21422544121742249
Validation loss: 1.5600849018302014

Epoch: 5| Step: 1
Training loss: 0.20383301377296448
Validation loss: 1.5911676960606729

Epoch: 5| Step: 2
Training loss: 0.15990538895130157
Validation loss: 1.6097425953034432

Epoch: 5| Step: 3
Training loss: 0.23594796657562256
Validation loss: 1.6014413884890977

Epoch: 5| Step: 4
Training loss: 0.17059463262557983
Validation loss: 1.592688484858441

Epoch: 5| Step: 5
Training loss: 0.18704484403133392
Validation loss: 1.583632871668826

Epoch: 5| Step: 6
Training loss: 0.15764638781547546
Validation loss: 1.6050891658311248

Epoch: 5| Step: 7
Training loss: 0.18848450481891632
Validation loss: 1.6017582954898957

Epoch: 5| Step: 8
Training loss: 0.13122759759426117
Validation loss: 1.6066898222892516

Epoch: 5| Step: 9
Training loss: 0.27131789922714233
Validation loss: 1.5912423890124086

Epoch: 5| Step: 10
Training loss: 0.2058839499950409
Validation loss: 1.6171350017670663

Epoch: 383| Step: 0
Training loss: 0.1755714863538742
Validation loss: 1.5873950976197437

Epoch: 5| Step: 1
Training loss: 0.20363983511924744
Validation loss: 1.6029109672833515

Epoch: 5| Step: 2
Training loss: 0.19371387362480164
Validation loss: 1.6083680801494147

Epoch: 5| Step: 3
Training loss: 0.104885533452034
Validation loss: 1.6349323244505032

Epoch: 5| Step: 4
Training loss: 0.2353663146495819
Validation loss: 1.5991807445403068

Epoch: 5| Step: 5
Training loss: 0.2418375015258789
Validation loss: 1.6245277248403078

Epoch: 5| Step: 6
Training loss: 0.1785101592540741
Validation loss: 1.6214704795550274

Epoch: 5| Step: 7
Training loss: 0.21300359070301056
Validation loss: 1.633505380281838

Epoch: 5| Step: 8
Training loss: 0.18810692429542542
Validation loss: 1.6776566338795487

Epoch: 5| Step: 9
Training loss: 0.13524429500102997
Validation loss: 1.6544864664795578

Epoch: 5| Step: 10
Training loss: 0.1715913563966751
Validation loss: 1.6171265468802503

Epoch: 384| Step: 0
Training loss: 0.13383722305297852
Validation loss: 1.6120961981434976

Epoch: 5| Step: 1
Training loss: 0.2116161286830902
Validation loss: 1.6113489468892415

Epoch: 5| Step: 2
Training loss: 0.22891616821289062
Validation loss: 1.5918475966299734

Epoch: 5| Step: 3
Training loss: 0.30106058716773987
Validation loss: 1.6206700455757879

Epoch: 5| Step: 4
Training loss: 0.2005237340927124
Validation loss: 1.6354121610682497

Epoch: 5| Step: 5
Training loss: 0.2270565927028656
Validation loss: 1.633985689891282

Epoch: 5| Step: 6
Training loss: 0.11193607747554779
Validation loss: 1.6492772307447208

Epoch: 5| Step: 7
Training loss: 0.1609431654214859
Validation loss: 1.636135188482141

Epoch: 5| Step: 8
Training loss: 0.26101821660995483
Validation loss: 1.6494051410305886

Epoch: 5| Step: 9
Training loss: 0.15943780541419983
Validation loss: 1.6275020555783344

Epoch: 5| Step: 10
Training loss: 0.1032140702009201
Validation loss: 1.6339605521130305

Epoch: 385| Step: 0
Training loss: 0.2222953736782074
Validation loss: 1.592577254259458

Epoch: 5| Step: 1
Training loss: 0.10710456222295761
Validation loss: 1.59904694813554

Epoch: 5| Step: 2
Training loss: 0.253539115190506
Validation loss: 1.5999447068860453

Epoch: 5| Step: 3
Training loss: 0.12147214263677597
Validation loss: 1.6424415880633938

Epoch: 5| Step: 4
Training loss: 0.31033986806869507
Validation loss: 1.5992742610234085

Epoch: 5| Step: 5
Training loss: 0.15082727372646332
Validation loss: 1.626820315596878

Epoch: 5| Step: 6
Training loss: 0.15092046558856964
Validation loss: 1.64434435290675

Epoch: 5| Step: 7
Training loss: 0.13714981079101562
Validation loss: 1.6530903488077142

Epoch: 5| Step: 8
Training loss: 0.22275197505950928
Validation loss: 1.6863378337634507

Epoch: 5| Step: 9
Training loss: 0.24613109230995178
Validation loss: 1.6654284397761028

Epoch: 5| Step: 10
Training loss: 0.18948206305503845
Validation loss: 1.6733977051191433

Epoch: 386| Step: 0
Training loss: 0.13596367835998535
Validation loss: 1.6801405017093947

Epoch: 5| Step: 1
Training loss: 0.08674164116382599
Validation loss: 1.6824406475149176

Epoch: 5| Step: 2
Training loss: 0.1817021369934082
Validation loss: 1.6142462402261712

Epoch: 5| Step: 3
Training loss: 0.29309219121932983
Validation loss: 1.6427294861885808

Epoch: 5| Step: 4
Training loss: 0.1259317398071289
Validation loss: 1.622475326702159

Epoch: 5| Step: 5
Training loss: 0.2501554787158966
Validation loss: 1.608610555689822

Epoch: 5| Step: 6
Training loss: 0.11703195422887802
Validation loss: 1.609480986031153

Epoch: 5| Step: 7
Training loss: 0.10366421937942505
Validation loss: 1.626870515525982

Epoch: 5| Step: 8
Training loss: 0.2016998827457428
Validation loss: 1.6018189960910427

Epoch: 5| Step: 9
Training loss: 0.3126925528049469
Validation loss: 1.613022973460536

Epoch: 5| Step: 10
Training loss: 0.31162428855895996
Validation loss: 1.5957270001852384

Epoch: 387| Step: 0
Training loss: 0.2527630925178528
Validation loss: 1.597148295371763

Epoch: 5| Step: 1
Training loss: 0.23763485252857208
Validation loss: 1.6616182019633632

Epoch: 5| Step: 2
Training loss: 0.119318887591362
Validation loss: 1.6216486205336869

Epoch: 5| Step: 3
Training loss: 0.18055924773216248
Validation loss: 1.6745916361449866

Epoch: 5| Step: 4
Training loss: 0.17835891246795654
Validation loss: 1.685308926848955

Epoch: 5| Step: 5
Training loss: 0.13525328040122986
Validation loss: 1.6689945369638421

Epoch: 5| Step: 6
Training loss: 0.19409498572349548
Validation loss: 1.6879782721560488

Epoch: 5| Step: 7
Training loss: 0.23194709420204163
Validation loss: 1.7135884466991629

Epoch: 5| Step: 8
Training loss: 0.19137431681156158
Validation loss: 1.7143738449260753

Epoch: 5| Step: 9
Training loss: 0.21846231818199158
Validation loss: 1.7065227172708

Epoch: 5| Step: 10
Training loss: 0.22610419988632202
Validation loss: 1.6951536093988726

Epoch: 388| Step: 0
Training loss: 0.1201312318444252
Validation loss: 1.695444824875042

Epoch: 5| Step: 1
Training loss: 0.11902575194835663
Validation loss: 1.6821023520602976

Epoch: 5| Step: 2
Training loss: 0.2728494703769684
Validation loss: 1.688234826569916

Epoch: 5| Step: 3
Training loss: 0.1410466730594635
Validation loss: 1.649593908299682

Epoch: 5| Step: 4
Training loss: 0.25665944814682007
Validation loss: 1.6615776054320797

Epoch: 5| Step: 5
Training loss: 0.21066150069236755
Validation loss: 1.63167832743737

Epoch: 5| Step: 6
Training loss: 0.2673361003398895
Validation loss: 1.6360561155503797

Epoch: 5| Step: 7
Training loss: 0.1521526575088501
Validation loss: 1.6017067522130988

Epoch: 5| Step: 8
Training loss: 0.13568967580795288
Validation loss: 1.5766829188152025

Epoch: 5| Step: 9
Training loss: 0.11594337224960327
Validation loss: 1.5735913156181254

Epoch: 5| Step: 10
Training loss: 0.14190874993801117
Validation loss: 1.5499380993586716

Epoch: 389| Step: 0
Training loss: 0.1436745822429657
Validation loss: 1.5533127348910096

Epoch: 5| Step: 1
Training loss: 0.21206791698932648
Validation loss: 1.580028393576222

Epoch: 5| Step: 2
Training loss: 0.252462774515152
Validation loss: 1.6128111757257932

Epoch: 5| Step: 3
Training loss: 0.21569299697875977
Validation loss: 1.6194482580307992

Epoch: 5| Step: 4
Training loss: 0.15041598677635193
Validation loss: 1.646861184027887

Epoch: 5| Step: 5
Training loss: 0.1335349828004837
Validation loss: 1.6618601852847683

Epoch: 5| Step: 6
Training loss: 0.24453707039356232
Validation loss: 1.663670083527924

Epoch: 5| Step: 7
Training loss: 0.2880675196647644
Validation loss: 1.6827890924228135

Epoch: 5| Step: 8
Training loss: 0.22569337487220764
Validation loss: 1.6769553756201139

Epoch: 5| Step: 9
Training loss: 0.16194646060466766
Validation loss: 1.6296101936730005

Epoch: 5| Step: 10
Training loss: 0.218763068318367
Validation loss: 1.661502577925241

Epoch: 390| Step: 0
Training loss: 0.14754906296730042
Validation loss: 1.6624774830315703

Epoch: 5| Step: 1
Training loss: 0.18454760313034058
Validation loss: 1.6563547144653976

Epoch: 5| Step: 2
Training loss: 0.17407414317131042
Validation loss: 1.6110398025922879

Epoch: 5| Step: 3
Training loss: 0.11767158657312393
Validation loss: 1.629509509250682

Epoch: 5| Step: 4
Training loss: 0.2076679766178131
Validation loss: 1.6257888386326451

Epoch: 5| Step: 5
Training loss: 0.1663336455821991
Validation loss: 1.5991735817283712

Epoch: 5| Step: 6
Training loss: 0.1790851354598999
Validation loss: 1.5932428080548522

Epoch: 5| Step: 7
Training loss: 0.1252482831478119
Validation loss: 1.6085255248572237

Epoch: 5| Step: 8
Training loss: 0.25018510222435
Validation loss: 1.6129788275687926

Epoch: 5| Step: 9
Training loss: 0.13057979941368103
Validation loss: 1.6007671856111096

Epoch: 5| Step: 10
Training loss: 0.3440607190132141
Validation loss: 1.6224054341675134

Epoch: 391| Step: 0
Training loss: 0.26275187730789185
Validation loss: 1.6613359899931057

Epoch: 5| Step: 1
Training loss: 0.14228367805480957
Validation loss: 1.641813442271243

Epoch: 5| Step: 2
Training loss: 0.16968531906604767
Validation loss: 1.6456708151807067

Epoch: 5| Step: 3
Training loss: 0.25387436151504517
Validation loss: 1.6378381918835383

Epoch: 5| Step: 4
Training loss: 0.12374719232320786
Validation loss: 1.6632362642595846

Epoch: 5| Step: 5
Training loss: 0.24197717010974884
Validation loss: 1.6379068307979132

Epoch: 5| Step: 6
Training loss: 0.13545337319374084
Validation loss: 1.639316289655624

Epoch: 5| Step: 7
Training loss: 0.13525524735450745
Validation loss: 1.6158522514886753

Epoch: 5| Step: 8
Training loss: 0.194422647356987
Validation loss: 1.616211587382901

Epoch: 5| Step: 9
Training loss: 0.1820099651813507
Validation loss: 1.6164067740081458

Epoch: 5| Step: 10
Training loss: 0.13746537268161774
Validation loss: 1.583985029369272

Epoch: 392| Step: 0
Training loss: 0.14335106313228607
Validation loss: 1.6010851052499586

Epoch: 5| Step: 1
Training loss: 0.2220514565706253
Validation loss: 1.600902429191015

Epoch: 5| Step: 2
Training loss: 0.21017496287822723
Validation loss: 1.5860842325354134

Epoch: 5| Step: 3
Training loss: 0.1527465283870697
Validation loss: 1.5856244435874365

Epoch: 5| Step: 4
Training loss: 0.21042582392692566
Validation loss: 1.5875636249460199

Epoch: 5| Step: 5
Training loss: 0.12406393140554428
Validation loss: 1.58632077452957

Epoch: 5| Step: 6
Training loss: 0.17792733013629913
Validation loss: 1.6015543399318573

Epoch: 5| Step: 7
Training loss: 0.15242686867713928
Validation loss: 1.6372303578161425

Epoch: 5| Step: 8
Training loss: 0.2262563407421112
Validation loss: 1.6196250197707966

Epoch: 5| Step: 9
Training loss: 0.1771882027387619
Validation loss: 1.5925975268886936

Epoch: 5| Step: 10
Training loss: 0.11775075644254684
Validation loss: 1.5920871739746423

Epoch: 393| Step: 0
Training loss: 0.1499367207288742
Validation loss: 1.5777248413332048

Epoch: 5| Step: 1
Training loss: 0.24589738249778748
Validation loss: 1.5681079196673569

Epoch: 5| Step: 2
Training loss: 0.171556293964386
Validation loss: 1.5949138082483763

Epoch: 5| Step: 3
Training loss: 0.1311994343996048
Validation loss: 1.6040689240219772

Epoch: 5| Step: 4
Training loss: 0.14567793905735016
Validation loss: 1.6288222958964687

Epoch: 5| Step: 5
Training loss: 0.12378676235675812
Validation loss: 1.6623346459481023

Epoch: 5| Step: 6
Training loss: 0.1801668405532837
Validation loss: 1.6377265504611436

Epoch: 5| Step: 7
Training loss: 0.2503935992717743
Validation loss: 1.6682751537651144

Epoch: 5| Step: 8
Training loss: 0.22684979438781738
Validation loss: 1.6885976714472617

Epoch: 5| Step: 9
Training loss: 0.18306128680706024
Validation loss: 1.6639128910597933

Epoch: 5| Step: 10
Training loss: 0.15879204869270325
Validation loss: 1.6822301969733289

Epoch: 394| Step: 0
Training loss: 0.19801315665245056
Validation loss: 1.6718519554343274

Epoch: 5| Step: 1
Training loss: 0.18450579047203064
Validation loss: 1.6215796560369513

Epoch: 5| Step: 2
Training loss: 0.23241575062274933
Validation loss: 1.5907043551885953

Epoch: 5| Step: 3
Training loss: 0.13137544691562653
Validation loss: 1.589749409306434

Epoch: 5| Step: 4
Training loss: 0.18307313323020935
Validation loss: 1.5864135244841218

Epoch: 5| Step: 5
Training loss: 0.3348280191421509
Validation loss: 1.552851451340542

Epoch: 5| Step: 6
Training loss: 0.23576512932777405
Validation loss: 1.576343504331445

Epoch: 5| Step: 7
Training loss: 0.2545478940010071
Validation loss: 1.5937708141983196

Epoch: 5| Step: 8
Training loss: 0.2051556408405304
Validation loss: 1.5678976146123742

Epoch: 5| Step: 9
Training loss: 0.3098754584789276
Validation loss: 1.584611294090107

Epoch: 5| Step: 10
Training loss: 0.16483174264431
Validation loss: 1.6089908153780046

Epoch: 395| Step: 0
Training loss: 0.21654829382896423
Validation loss: 1.6143017225368048

Epoch: 5| Step: 1
Training loss: 0.20125643908977509
Validation loss: 1.6272140087619904

Epoch: 5| Step: 2
Training loss: 0.2616554796695709
Validation loss: 1.6360036326992897

Epoch: 5| Step: 3
Training loss: 0.2309219092130661
Validation loss: 1.6219598862432665

Epoch: 5| Step: 4
Training loss: 0.21278217434883118
Validation loss: 1.6020446772216468

Epoch: 5| Step: 5
Training loss: 0.24054083228111267
Validation loss: 1.621910842516089

Epoch: 5| Step: 6
Training loss: 0.19368094205856323
Validation loss: 1.617627029777855

Epoch: 5| Step: 7
Training loss: 0.2128477841615677
Validation loss: 1.6255790905285907

Epoch: 5| Step: 8
Training loss: 0.136546328663826
Validation loss: 1.6026701401638728

Epoch: 5| Step: 9
Training loss: 0.20451664924621582
Validation loss: 1.5945042999841834

Epoch: 5| Step: 10
Training loss: 0.17450761795043945
Validation loss: 1.589342382005466

Epoch: 396| Step: 0
Training loss: 0.1896621286869049
Validation loss: 1.6140500473719772

Epoch: 5| Step: 1
Training loss: 0.2457810342311859
Validation loss: 1.6012495435694212

Epoch: 5| Step: 2
Training loss: 0.17673546075820923
Validation loss: 1.625439432359511

Epoch: 5| Step: 3
Training loss: 0.13799293339252472
Validation loss: 1.650086287529238

Epoch: 5| Step: 4
Training loss: 0.1167745366692543
Validation loss: 1.6332788749407696

Epoch: 5| Step: 5
Training loss: 0.11579000949859619
Validation loss: 1.6015841435360652

Epoch: 5| Step: 6
Training loss: 0.09734226763248444
Validation loss: 1.6108395303449323

Epoch: 5| Step: 7
Training loss: 0.15191565454006195
Validation loss: 1.601575683521968

Epoch: 5| Step: 8
Training loss: 0.29538264870643616
Validation loss: 1.5655678074846986

Epoch: 5| Step: 9
Training loss: 0.1906079351902008
Validation loss: 1.6012582791748868

Epoch: 5| Step: 10
Training loss: 0.24469740688800812
Validation loss: 1.5929887358860304

Epoch: 397| Step: 0
Training loss: 0.14692580699920654
Validation loss: 1.602764291148032

Epoch: 5| Step: 1
Training loss: 0.26034948229789734
Validation loss: 1.6289555167639127

Epoch: 5| Step: 2
Training loss: 0.14644965529441833
Validation loss: 1.6433136258074033

Epoch: 5| Step: 3
Training loss: 0.1028449758887291
Validation loss: 1.6224776724333405

Epoch: 5| Step: 4
Training loss: 0.2568361163139343
Validation loss: 1.6350823602368754

Epoch: 5| Step: 5
Training loss: 0.1598382294178009
Validation loss: 1.6540124185623661

Epoch: 5| Step: 6
Training loss: 0.17681989073753357
Validation loss: 1.6530305608626334

Epoch: 5| Step: 7
Training loss: 0.117091104388237
Validation loss: 1.6707898096371723

Epoch: 5| Step: 8
Training loss: 0.13796810805797577
Validation loss: 1.658210071184302

Epoch: 5| Step: 9
Training loss: 0.2037648856639862
Validation loss: 1.6354623815064788

Epoch: 5| Step: 10
Training loss: 0.21462632715702057
Validation loss: 1.655144686340004

Epoch: 398| Step: 0
Training loss: 0.14004918932914734
Validation loss: 1.6163931726127543

Epoch: 5| Step: 1
Training loss: 0.20631244778633118
Validation loss: 1.5921883865069317

Epoch: 5| Step: 2
Training loss: 0.2261079102754593
Validation loss: 1.5910765778633855

Epoch: 5| Step: 3
Training loss: 0.17587092518806458
Validation loss: 1.573878929179202

Epoch: 5| Step: 4
Training loss: 0.3135831952095032
Validation loss: 1.5426683477176133

Epoch: 5| Step: 5
Training loss: 0.21830300986766815
Validation loss: 1.553356311654532

Epoch: 5| Step: 6
Training loss: 0.20186667144298553
Validation loss: 1.575565570144243

Epoch: 5| Step: 7
Training loss: 0.18483343720436096
Validation loss: 1.5881559259148055

Epoch: 5| Step: 8
Training loss: 0.09259937703609467
Validation loss: 1.5734727203205068

Epoch: 5| Step: 9
Training loss: 0.17147274315357208
Validation loss: 1.5688082543752526

Epoch: 5| Step: 10
Training loss: 0.10978259146213531
Validation loss: 1.5701943879486413

Epoch: 399| Step: 0
Training loss: 0.16420453786849976
Validation loss: 1.6360759773562032

Epoch: 5| Step: 1
Training loss: 0.12535427510738373
Validation loss: 1.6495382683251494

Epoch: 5| Step: 2
Training loss: 0.14826937019824982
Validation loss: 1.6523526150693175

Epoch: 5| Step: 3
Training loss: 0.2455555498600006
Validation loss: 1.637303025491776

Epoch: 5| Step: 4
Training loss: 0.17475625872612
Validation loss: 1.6486651141156432

Epoch: 5| Step: 5
Training loss: 0.14114682376384735
Validation loss: 1.6194857551205544

Epoch: 5| Step: 6
Training loss: 0.17720192670822144
Validation loss: 1.6160880019587855

Epoch: 5| Step: 7
Training loss: 0.28320378065109253
Validation loss: 1.6171784144575878

Epoch: 5| Step: 8
Training loss: 0.16857099533081055
Validation loss: 1.6057069878424368

Epoch: 5| Step: 9
Training loss: 0.1703600287437439
Validation loss: 1.6134913166364033

Epoch: 5| Step: 10
Training loss: 0.2120383232831955
Validation loss: 1.5930812281946982

Epoch: 400| Step: 0
Training loss: 0.20123234391212463
Validation loss: 1.5688910574041388

Epoch: 5| Step: 1
Training loss: 0.22312669456005096
Validation loss: 1.5850682899516115

Epoch: 5| Step: 2
Training loss: 0.20758569240570068
Validation loss: 1.5990390687860467

Epoch: 5| Step: 3
Training loss: 0.20340010523796082
Validation loss: 1.5723756474833335

Epoch: 5| Step: 4
Training loss: 0.2093265801668167
Validation loss: 1.5480050117738786

Epoch: 5| Step: 5
Training loss: 0.12402264028787613
Validation loss: 1.5490316755028182

Epoch: 5| Step: 6
Training loss: 0.1809217780828476
Validation loss: 1.5545670050446705

Epoch: 5| Step: 7
Training loss: 0.21497610211372375
Validation loss: 1.5554832591805408

Epoch: 5| Step: 8
Training loss: 0.16435065865516663
Validation loss: 1.5662555361306796

Epoch: 5| Step: 9
Training loss: 0.1582898199558258
Validation loss: 1.6097431541771017

Epoch: 5| Step: 10
Training loss: 0.14871762692928314
Validation loss: 1.6279101448674356

Epoch: 401| Step: 0
Training loss: 0.23527464270591736
Validation loss: 1.6080002554001347

Epoch: 5| Step: 1
Training loss: 0.1708240509033203
Validation loss: 1.5750516704333726

Epoch: 5| Step: 2
Training loss: 0.23802590370178223
Validation loss: 1.5902314686006116

Epoch: 5| Step: 3
Training loss: 0.1554296761751175
Validation loss: 1.606230282014416

Epoch: 5| Step: 4
Training loss: 0.2452699840068817
Validation loss: 1.5907070021475516

Epoch: 5| Step: 5
Training loss: 0.1972217559814453
Validation loss: 1.5742187743545861

Epoch: 5| Step: 6
Training loss: 0.1495644450187683
Validation loss: 1.6048115145775579

Epoch: 5| Step: 7
Training loss: 0.12748143076896667
Validation loss: 1.6258714519521242

Epoch: 5| Step: 8
Training loss: 0.1143631711602211
Validation loss: 1.6059118829747683

Epoch: 5| Step: 9
Training loss: 0.1122199073433876
Validation loss: 1.6108186027055145

Epoch: 5| Step: 10
Training loss: 0.10865159332752228
Validation loss: 1.6300689661374657

Epoch: 402| Step: 0
Training loss: 0.08808670938014984
Validation loss: 1.6271255067599717

Epoch: 5| Step: 1
Training loss: 0.12857277691364288
Validation loss: 1.6375124480134697

Epoch: 5| Step: 2
Training loss: 0.15268215537071228
Validation loss: 1.623495351883673

Epoch: 5| Step: 3
Training loss: 0.16883485019207
Validation loss: 1.6321262300655406

Epoch: 5| Step: 4
Training loss: 0.1843435913324356
Validation loss: 1.6055182564643122

Epoch: 5| Step: 5
Training loss: 0.1948673576116562
Validation loss: 1.5883400837580364

Epoch: 5| Step: 6
Training loss: 0.21972060203552246
Validation loss: 1.5840861771696357

Epoch: 5| Step: 7
Training loss: 0.1835421621799469
Validation loss: 1.573641369419713

Epoch: 5| Step: 8
Training loss: 0.17604975402355194
Validation loss: 1.5628240159762803

Epoch: 5| Step: 9
Training loss: 0.17061398923397064
Validation loss: 1.5538496214856383

Epoch: 5| Step: 10
Training loss: 0.17359405755996704
Validation loss: 1.5526001132944578

Epoch: 403| Step: 0
Training loss: 0.17228451371192932
Validation loss: 1.566399174351846

Epoch: 5| Step: 1
Training loss: 0.138588547706604
Validation loss: 1.5489861439633112

Epoch: 5| Step: 2
Training loss: 0.14193663001060486
Validation loss: 1.5611129114704747

Epoch: 5| Step: 3
Training loss: 0.17241279780864716
Validation loss: 1.557254029858497

Epoch: 5| Step: 4
Training loss: 0.12441210448741913
Validation loss: 1.5664571574939194

Epoch: 5| Step: 5
Training loss: 0.1496926099061966
Validation loss: 1.5850774036940707

Epoch: 5| Step: 6
Training loss: 0.23624654114246368
Validation loss: 1.5898709027997908

Epoch: 5| Step: 7
Training loss: 0.18475891649723053
Validation loss: 1.6156508127848308

Epoch: 5| Step: 8
Training loss: 0.21108540892601013
Validation loss: 1.5977288035936252

Epoch: 5| Step: 9
Training loss: 0.18855103850364685
Validation loss: 1.5746747178416098

Epoch: 5| Step: 10
Training loss: 0.17711292207241058
Validation loss: 1.5349696413163216

Epoch: 404| Step: 0
Training loss: 0.12606099247932434
Validation loss: 1.5655224316863603

Epoch: 5| Step: 1
Training loss: 0.13041812181472778
Validation loss: 1.5302324935954104

Epoch: 5| Step: 2
Training loss: 0.15491238236427307
Validation loss: 1.551965259736584

Epoch: 5| Step: 3
Training loss: 0.20596449077129364
Validation loss: 1.5561677127756097

Epoch: 5| Step: 4
Training loss: 0.10997577011585236
Validation loss: 1.5771478401717318

Epoch: 5| Step: 5
Training loss: 0.14011390507221222
Validation loss: 1.6029275642928256

Epoch: 5| Step: 6
Training loss: 0.22943317890167236
Validation loss: 1.5703373929505706

Epoch: 5| Step: 7
Training loss: 0.13652333617210388
Validation loss: 1.5934890752197595

Epoch: 5| Step: 8
Training loss: 0.2467438280582428
Validation loss: 1.5851720571517944

Epoch: 5| Step: 9
Training loss: 0.2201237976551056
Validation loss: 1.5972397840151222

Epoch: 5| Step: 10
Training loss: 0.14276939630508423
Validation loss: 1.5862298293780255

Epoch: 405| Step: 0
Training loss: 0.13048821687698364
Validation loss: 1.5879872627155756

Epoch: 5| Step: 1
Training loss: 0.13528457283973694
Validation loss: 1.5748405994907502

Epoch: 5| Step: 2
Training loss: 0.13949725031852722
Validation loss: 1.5792211473629039

Epoch: 5| Step: 3
Training loss: 0.2462897002696991
Validation loss: 1.6072222468673543

Epoch: 5| Step: 4
Training loss: 0.12929680943489075
Validation loss: 1.6565361208813165

Epoch: 5| Step: 5
Training loss: 0.11830971390008926
Validation loss: 1.6314561251671083

Epoch: 5| Step: 6
Training loss: 0.2518957257270813
Validation loss: 1.655837966549781

Epoch: 5| Step: 7
Training loss: 0.24972446262836456
Validation loss: 1.6539867155013546

Epoch: 5| Step: 8
Training loss: 0.24133534729480743
Validation loss: 1.677572883585448

Epoch: 5| Step: 9
Training loss: 0.23311488330364227
Validation loss: 1.6736103885917253

Epoch: 5| Step: 10
Training loss: 0.14037375152111053
Validation loss: 1.654745654393268

Epoch: 406| Step: 0
Training loss: 0.10518090426921844
Validation loss: 1.6399696437261437

Epoch: 5| Step: 1
Training loss: 0.13967661559581757
Validation loss: 1.6293633676344348

Epoch: 5| Step: 2
Training loss: 0.0938790962100029
Validation loss: 1.6144810825265863

Epoch: 5| Step: 3
Training loss: 0.15106375515460968
Validation loss: 1.6456151726425334

Epoch: 5| Step: 4
Training loss: 0.1736069619655609
Validation loss: 1.6577684264029227

Epoch: 5| Step: 5
Training loss: 0.3197804391384125
Validation loss: 1.6348980037114953

Epoch: 5| Step: 6
Training loss: 0.17898482084274292
Validation loss: 1.6470818493955879

Epoch: 5| Step: 7
Training loss: 0.16401877999305725
Validation loss: 1.6204766599080895

Epoch: 5| Step: 8
Training loss: 0.1797235757112503
Validation loss: 1.6367939518344017

Epoch: 5| Step: 9
Training loss: 0.24588704109191895
Validation loss: 1.5927183051263132

Epoch: 5| Step: 10
Training loss: 0.2555328905582428
Validation loss: 1.6148997968243015

Epoch: 407| Step: 0
Training loss: 0.22863081097602844
Validation loss: 1.6150958230418544

Epoch: 5| Step: 1
Training loss: 0.2997157871723175
Validation loss: 1.6258436633694557

Epoch: 5| Step: 2
Training loss: 0.17195861041545868
Validation loss: 1.6740325855952438

Epoch: 5| Step: 3
Training loss: 0.0904078334569931
Validation loss: 1.6529206768158944

Epoch: 5| Step: 4
Training loss: 0.1429363340139389
Validation loss: 1.6683551483256842

Epoch: 5| Step: 5
Training loss: 0.2046935111284256
Validation loss: 1.6336322702387327

Epoch: 5| Step: 6
Training loss: 0.26394519209861755
Validation loss: 1.6588394821331065

Epoch: 5| Step: 7
Training loss: 0.21155567467212677
Validation loss: 1.6266710553117978

Epoch: 5| Step: 8
Training loss: 0.13190536201000214
Validation loss: 1.6501151169500043

Epoch: 5| Step: 9
Training loss: 0.16417045891284943
Validation loss: 1.6482231719519502

Epoch: 5| Step: 10
Training loss: 0.1180286556482315
Validation loss: 1.6767893337434339

Epoch: 408| Step: 0
Training loss: 0.18827198445796967
Validation loss: 1.6510469170026882

Epoch: 5| Step: 1
Training loss: 0.16246400773525238
Validation loss: 1.6722486121680147

Epoch: 5| Step: 2
Training loss: 0.13402530550956726
Validation loss: 1.6467658153144262

Epoch: 5| Step: 3
Training loss: 0.14390672743320465
Validation loss: 1.6179859048576766

Epoch: 5| Step: 4
Training loss: 0.1706666648387909
Validation loss: 1.6058184754463933

Epoch: 5| Step: 5
Training loss: 0.24634523689746857
Validation loss: 1.5881991277458847

Epoch: 5| Step: 6
Training loss: 0.13663189113140106
Validation loss: 1.6057397550152195

Epoch: 5| Step: 7
Training loss: 0.17812786996364594
Validation loss: 1.610720895951794

Epoch: 5| Step: 8
Training loss: 0.13821952044963837
Validation loss: 1.5920674339417489

Epoch: 5| Step: 9
Training loss: 0.1944587528705597
Validation loss: 1.6240812757963776

Epoch: 5| Step: 10
Training loss: 0.25014162063598633
Validation loss: 1.6153549789100565

Epoch: 409| Step: 0
Training loss: 0.17636804282665253
Validation loss: 1.611393041508172

Epoch: 5| Step: 1
Training loss: 0.1515616923570633
Validation loss: 1.5915015153987433

Epoch: 5| Step: 2
Training loss: 0.10609172284603119
Validation loss: 1.5993580843812676

Epoch: 5| Step: 3
Training loss: 0.15984545648097992
Validation loss: 1.6303559451974847

Epoch: 5| Step: 4
Training loss: 0.19168329238891602
Validation loss: 1.6068564191941292

Epoch: 5| Step: 5
Training loss: 0.1701069325208664
Validation loss: 1.6118523023461784

Epoch: 5| Step: 6
Training loss: 0.1685483455657959
Validation loss: 1.659414565691384

Epoch: 5| Step: 7
Training loss: 0.16364379227161407
Validation loss: 1.6395260864688503

Epoch: 5| Step: 8
Training loss: 0.15879490971565247
Validation loss: 1.6806362751991517

Epoch: 5| Step: 9
Training loss: 0.3387933075428009
Validation loss: 1.7048433890906713

Epoch: 5| Step: 10
Training loss: 0.16608107089996338
Validation loss: 1.7008236287742533

Epoch: 410| Step: 0
Training loss: 0.1298546940088272
Validation loss: 1.6357862218733756

Epoch: 5| Step: 1
Training loss: 0.2055942565202713
Validation loss: 1.629811680445107

Epoch: 5| Step: 2
Training loss: 0.27215689420700073
Validation loss: 1.642880965304631

Epoch: 5| Step: 3
Training loss: 0.14421895146369934
Validation loss: 1.6236468463815668

Epoch: 5| Step: 4
Training loss: 0.1812758445739746
Validation loss: 1.6329555857566096

Epoch: 5| Step: 5
Training loss: 0.16194912791252136
Validation loss: 1.6201174528368059

Epoch: 5| Step: 6
Training loss: 0.17809000611305237
Validation loss: 1.6201670746649466

Epoch: 5| Step: 7
Training loss: 0.13424640893936157
Validation loss: 1.6395006846356135

Epoch: 5| Step: 8
Training loss: 0.1975245475769043
Validation loss: 1.6678558998210455

Epoch: 5| Step: 9
Training loss: 0.17359472811222076
Validation loss: 1.6587557510663105

Epoch: 5| Step: 10
Training loss: 0.18227951228618622
Validation loss: 1.6529161827538603

Epoch: 411| Step: 0
Training loss: 0.14754346013069153
Validation loss: 1.6355446589890348

Epoch: 5| Step: 1
Training loss: 0.10962486267089844
Validation loss: 1.5996051212792755

Epoch: 5| Step: 2
Training loss: 0.2006031572818756
Validation loss: 1.5913105190441172

Epoch: 5| Step: 3
Training loss: 0.29409223794937134
Validation loss: 1.5612533707772531

Epoch: 5| Step: 4
Training loss: 0.2643982768058777
Validation loss: 1.5738147292085873

Epoch: 5| Step: 5
Training loss: 0.1125786304473877
Validation loss: 1.5838914801997523

Epoch: 5| Step: 6
Training loss: 0.21011796593666077
Validation loss: 1.5842502399157452

Epoch: 5| Step: 7
Training loss: 0.15269765257835388
Validation loss: 1.6080670587478145

Epoch: 5| Step: 8
Training loss: 0.17655208706855774
Validation loss: 1.6269527154584085

Epoch: 5| Step: 9
Training loss: 0.135763019323349
Validation loss: 1.6495401038918445

Epoch: 5| Step: 10
Training loss: 0.22067052125930786
Validation loss: 1.6704642939311203

Epoch: 412| Step: 0
Training loss: 0.32745009660720825
Validation loss: 1.6823742261496923

Epoch: 5| Step: 1
Training loss: 0.20560777187347412
Validation loss: 1.6750593826334963

Epoch: 5| Step: 2
Training loss: 0.2310878038406372
Validation loss: 1.672520508048355

Epoch: 5| Step: 3
Training loss: 0.16741807758808136
Validation loss: 1.6159790946591286

Epoch: 5| Step: 4
Training loss: 0.1083637923002243
Validation loss: 1.6119753904240106

Epoch: 5| Step: 5
Training loss: 0.20081689953804016
Validation loss: 1.5484852457559237

Epoch: 5| Step: 6
Training loss: 0.2201758325099945
Validation loss: 1.5570973952611287

Epoch: 5| Step: 7
Training loss: 0.17280372977256775
Validation loss: 1.5369338937985

Epoch: 5| Step: 8
Training loss: 0.15680310130119324
Validation loss: 1.5308272979592765

Epoch: 5| Step: 9
Training loss: 0.15305905044078827
Validation loss: 1.566525831017443

Epoch: 5| Step: 10
Training loss: 0.14729392528533936
Validation loss: 1.5803625019647742

Epoch: 413| Step: 0
Training loss: 0.2140647917985916
Validation loss: 1.6206541304947228

Epoch: 5| Step: 1
Training loss: 0.20811529457569122
Validation loss: 1.6369217416291595

Epoch: 5| Step: 2
Training loss: 0.1404286026954651
Validation loss: 1.655731201171875

Epoch: 5| Step: 3
Training loss: 0.10637589544057846
Validation loss: 1.652857320283049

Epoch: 5| Step: 4
Training loss: 0.20608365535736084
Validation loss: 1.6134067017544982

Epoch: 5| Step: 5
Training loss: 0.1173495203256607
Validation loss: 1.6554545151290072

Epoch: 5| Step: 6
Training loss: 0.15024909377098083
Validation loss: 1.6349218545421478

Epoch: 5| Step: 7
Training loss: 0.11028687655925751
Validation loss: 1.6418357279992872

Epoch: 5| Step: 8
Training loss: 0.19181938469409943
Validation loss: 1.6040927633162467

Epoch: 5| Step: 9
Training loss: 0.2560136020183563
Validation loss: 1.6192114199361494

Epoch: 5| Step: 10
Training loss: 0.1821502298116684
Validation loss: 1.588935008613012

Epoch: 414| Step: 0
Training loss: 0.10337455570697784
Validation loss: 1.6249757338595647

Epoch: 5| Step: 1
Training loss: 0.2099568396806717
Validation loss: 1.656405101540268

Epoch: 5| Step: 2
Training loss: 0.14191754162311554
Validation loss: 1.6487844067235147

Epoch: 5| Step: 3
Training loss: 0.12610846757888794
Validation loss: 1.639745771244008

Epoch: 5| Step: 4
Training loss: 0.1551872193813324
Validation loss: 1.6237608873715965

Epoch: 5| Step: 5
Training loss: 0.2633729875087738
Validation loss: 1.632742658738167

Epoch: 5| Step: 6
Training loss: 0.22637319564819336
Validation loss: 1.6486421720955962

Epoch: 5| Step: 7
Training loss: 0.23664529621601105
Validation loss: 1.6384900910879976

Epoch: 5| Step: 8
Training loss: 0.1333194077014923
Validation loss: 1.6311428341814267

Epoch: 5| Step: 9
Training loss: 0.13880260288715363
Validation loss: 1.5984206443191857

Epoch: 5| Step: 10
Training loss: 0.17823126912117004
Validation loss: 1.6367903332556448

Epoch: 415| Step: 0
Training loss: 0.22952871024608612
Validation loss: 1.6236434200758576

Epoch: 5| Step: 1
Training loss: 0.30654820799827576
Validation loss: 1.6180127846297396

Epoch: 5| Step: 2
Training loss: 0.14886146783828735
Validation loss: 1.6307390127130734

Epoch: 5| Step: 3
Training loss: 0.0810929387807846
Validation loss: 1.6722332585242488

Epoch: 5| Step: 4
Training loss: 0.12103525549173355
Validation loss: 1.6689287859906432

Epoch: 5| Step: 5
Training loss: 0.13532549142837524
Validation loss: 1.7106701930363972

Epoch: 5| Step: 6
Training loss: 0.28431716561317444
Validation loss: 1.707125682984629

Epoch: 5| Step: 7
Training loss: 0.22212722897529602
Validation loss: 1.697151860883159

Epoch: 5| Step: 8
Training loss: 0.218232199549675
Validation loss: 1.66175336991587

Epoch: 5| Step: 9
Training loss: 0.2068411409854889
Validation loss: 1.6620168045002928

Epoch: 5| Step: 10
Training loss: 0.1513756662607193
Validation loss: 1.6195585221372626

Epoch: 416| Step: 0
Training loss: 0.2765795588493347
Validation loss: 1.6309201230284989

Epoch: 5| Step: 1
Training loss: 0.14413851499557495
Validation loss: 1.6029488393055495

Epoch: 5| Step: 2
Training loss: 0.21511630713939667
Validation loss: 1.610571038338446

Epoch: 5| Step: 3
Training loss: 0.14649227261543274
Validation loss: 1.61047351232139

Epoch: 5| Step: 4
Training loss: 0.16469718515872955
Validation loss: 1.5765956563334311

Epoch: 5| Step: 5
Training loss: 0.1655159890651703
Validation loss: 1.6167024386826383

Epoch: 5| Step: 6
Training loss: 0.1934141218662262
Validation loss: 1.6354940834865774

Epoch: 5| Step: 7
Training loss: 0.25846797227859497
Validation loss: 1.6483331418806506

Epoch: 5| Step: 8
Training loss: 0.16063079237937927
Validation loss: 1.638582435987329

Epoch: 5| Step: 9
Training loss: 0.15284733474254608
Validation loss: 1.609185129083613

Epoch: 5| Step: 10
Training loss: 0.17953276634216309
Validation loss: 1.6133175639696018

Epoch: 417| Step: 0
Training loss: 0.14254072308540344
Validation loss: 1.6198071164469565

Epoch: 5| Step: 1
Training loss: 0.1527118682861328
Validation loss: 1.6301780426374046

Epoch: 5| Step: 2
Training loss: 0.13270319998264313
Validation loss: 1.630099541397505

Epoch: 5| Step: 3
Training loss: 0.1735110580921173
Validation loss: 1.6348462591889084

Epoch: 5| Step: 4
Training loss: 0.19326485693454742
Validation loss: 1.6702131443126227

Epoch: 5| Step: 5
Training loss: 0.17779037356376648
Validation loss: 1.6573965716105636

Epoch: 5| Step: 6
Training loss: 0.2172248363494873
Validation loss: 1.6794190355526504

Epoch: 5| Step: 7
Training loss: 0.19886590540409088
Validation loss: 1.6843226596873293

Epoch: 5| Step: 8
Training loss: 0.16339799761772156
Validation loss: 1.6828664528426303

Epoch: 5| Step: 9
Training loss: 0.14970475435256958
Validation loss: 1.6876770770677956

Epoch: 5| Step: 10
Training loss: 0.26290279626846313
Validation loss: 1.6895626232188234

Epoch: 418| Step: 0
Training loss: 0.13039548695087433
Validation loss: 1.6577766351802374

Epoch: 5| Step: 1
Training loss: 0.24462851881980896
Validation loss: 1.6519505234174832

Epoch: 5| Step: 2
Training loss: 0.15048591792583466
Validation loss: 1.651649103369764

Epoch: 5| Step: 3
Training loss: 0.18799348175525665
Validation loss: 1.6300897886676173

Epoch: 5| Step: 4
Training loss: 0.16517452895641327
Validation loss: 1.6325574408295334

Epoch: 5| Step: 5
Training loss: 0.15959015488624573
Validation loss: 1.6381632512615574

Epoch: 5| Step: 6
Training loss: 0.19226934015750885
Validation loss: 1.5948774378786805

Epoch: 5| Step: 7
Training loss: 0.13086220622062683
Validation loss: 1.6254496882038731

Epoch: 5| Step: 8
Training loss: 0.19430343806743622
Validation loss: 1.6661656338681456

Epoch: 5| Step: 9
Training loss: 0.15264129638671875
Validation loss: 1.6421939608871297

Epoch: 5| Step: 10
Training loss: 0.12340705841779709
Validation loss: 1.6817515639848606

Epoch: 419| Step: 0
Training loss: 0.17162969708442688
Validation loss: 1.6878822670188

Epoch: 5| Step: 1
Training loss: 0.2264150083065033
Validation loss: 1.6887880525281351

Epoch: 5| Step: 2
Training loss: 0.22854435443878174
Validation loss: 1.67009017544408

Epoch: 5| Step: 3
Training loss: 0.16853007674217224
Validation loss: 1.5963454772067327

Epoch: 5| Step: 4
Training loss: 0.10959669202566147
Validation loss: 1.5833458874815254

Epoch: 5| Step: 5
Training loss: 0.15485632419586182
Validation loss: 1.5610392298749698

Epoch: 5| Step: 6
Training loss: 0.18025925755500793
Validation loss: 1.529159310043499

Epoch: 5| Step: 7
Training loss: 0.2801138758659363
Validation loss: 1.5755621630658385

Epoch: 5| Step: 8
Training loss: 0.21307644248008728
Validation loss: 1.54600082161606

Epoch: 5| Step: 9
Training loss: 0.1606525331735611
Validation loss: 1.5437333776104836

Epoch: 5| Step: 10
Training loss: 0.18716086447238922
Validation loss: 1.556960718606108

Epoch: 420| Step: 0
Training loss: 0.0955672487616539
Validation loss: 1.5846051451980427

Epoch: 5| Step: 1
Training loss: 0.14891426265239716
Validation loss: 1.6276455233173985

Epoch: 5| Step: 2
Training loss: 0.21629753708839417
Validation loss: 1.6602596082995016

Epoch: 5| Step: 3
Training loss: 0.15049412846565247
Validation loss: 1.6702008465284943

Epoch: 5| Step: 4
Training loss: 0.24272513389587402
Validation loss: 1.642116383839679

Epoch: 5| Step: 5
Training loss: 0.17384083569049835
Validation loss: 1.6531136599920129

Epoch: 5| Step: 6
Training loss: 0.13522054255008698
Validation loss: 1.6277624093076235

Epoch: 5| Step: 7
Training loss: 0.1282452791929245
Validation loss: 1.6555137301004061

Epoch: 5| Step: 8
Training loss: 0.1569172590970993
Validation loss: 1.6100631836921937

Epoch: 5| Step: 9
Training loss: 0.28781312704086304
Validation loss: 1.618047873179118

Epoch: 5| Step: 10
Training loss: 0.18345242738723755
Validation loss: 1.5761511389927199

Epoch: 421| Step: 0
Training loss: 0.1508428007364273
Validation loss: 1.6001578082320511

Epoch: 5| Step: 1
Training loss: 0.1711902916431427
Validation loss: 1.6279846006824124

Epoch: 5| Step: 2
Training loss: 0.22797565162181854
Validation loss: 1.6198981615804857

Epoch: 5| Step: 3
Training loss: 0.18996480107307434
Validation loss: 1.6596954381594093

Epoch: 5| Step: 4
Training loss: 0.14562168717384338
Validation loss: 1.63671487762082

Epoch: 5| Step: 5
Training loss: 0.14821606874465942
Validation loss: 1.6217870481552616

Epoch: 5| Step: 6
Training loss: 0.17075350880622864
Validation loss: 1.6155162319060294

Epoch: 5| Step: 7
Training loss: 0.12573929131031036
Validation loss: 1.5847138384337067

Epoch: 5| Step: 8
Training loss: 0.16898322105407715
Validation loss: 1.6232925820094284

Epoch: 5| Step: 9
Training loss: 0.1556549221277237
Validation loss: 1.559187827571746

Epoch: 5| Step: 10
Training loss: 0.10427851974964142
Validation loss: 1.620623202734096

Epoch: 422| Step: 0
Training loss: 0.18900218605995178
Validation loss: 1.5638828995407268

Epoch: 5| Step: 1
Training loss: 0.11571445316076279
Validation loss: 1.5876593012963571

Epoch: 5| Step: 2
Training loss: 0.11875484138727188
Validation loss: 1.6002493186663556

Epoch: 5| Step: 3
Training loss: 0.17022229731082916
Validation loss: 1.6046315059866956

Epoch: 5| Step: 4
Training loss: 0.17678287625312805
Validation loss: 1.6077139839049308

Epoch: 5| Step: 5
Training loss: 0.13495174050331116
Validation loss: 1.6182929687602545

Epoch: 5| Step: 6
Training loss: 0.08403034508228302
Validation loss: 1.6266219750527413

Epoch: 5| Step: 7
Training loss: 0.21210706233978271
Validation loss: 1.6570553510419783

Epoch: 5| Step: 8
Training loss: 0.15302488207817078
Validation loss: 1.6619587918763519

Epoch: 5| Step: 9
Training loss: 0.16374945640563965
Validation loss: 1.7110860065747333

Epoch: 5| Step: 10
Training loss: 0.23995433747768402
Validation loss: 1.6669575322058894

Epoch: 423| Step: 0
Training loss: 0.26180392503738403
Validation loss: 1.656249092471215

Epoch: 5| Step: 1
Training loss: 0.08738730102777481
Validation loss: 1.6080956023226503

Epoch: 5| Step: 2
Training loss: 0.08987154811620712
Validation loss: 1.5869725955429899

Epoch: 5| Step: 3
Training loss: 0.1240740418434143
Validation loss: 1.5868874365283596

Epoch: 5| Step: 4
Training loss: 0.19005773961544037
Validation loss: 1.6145103234116749

Epoch: 5| Step: 5
Training loss: 0.24849867820739746
Validation loss: 1.6135891496494252

Epoch: 5| Step: 6
Training loss: 0.26345163583755493
Validation loss: 1.616952710254218

Epoch: 5| Step: 7
Training loss: 0.19437873363494873
Validation loss: 1.6087385531394713

Epoch: 5| Step: 8
Training loss: 0.1404205858707428
Validation loss: 1.6010463776126984

Epoch: 5| Step: 9
Training loss: 0.14805474877357483
Validation loss: 1.6504473506763417

Epoch: 5| Step: 10
Training loss: 0.14297586679458618
Validation loss: 1.6293396257585095

Epoch: 424| Step: 0
Training loss: 0.15756633877754211
Validation loss: 1.606344510150212

Epoch: 5| Step: 1
Training loss: 0.18909071385860443
Validation loss: 1.6014369892817673

Epoch: 5| Step: 2
Training loss: 0.09651891142129898
Validation loss: 1.580981299441348

Epoch: 5| Step: 3
Training loss: 0.13317948579788208
Validation loss: 1.5815508839904622

Epoch: 5| Step: 4
Training loss: 0.1625441610813141
Validation loss: 1.596205194791158

Epoch: 5| Step: 5
Training loss: 0.1613219678401947
Validation loss: 1.5859280555478987

Epoch: 5| Step: 6
Training loss: 0.12851551175117493
Validation loss: 1.5809717485981603

Epoch: 5| Step: 7
Training loss: 0.2418670654296875
Validation loss: 1.5615104193328528

Epoch: 5| Step: 8
Training loss: 0.19367201626300812
Validation loss: 1.587656904292363

Epoch: 5| Step: 9
Training loss: 0.1637243926525116
Validation loss: 1.569917308386936

Epoch: 5| Step: 10
Training loss: 0.19469302892684937
Validation loss: 1.6221502083604054

Epoch: 425| Step: 0
Training loss: 0.1453268826007843
Validation loss: 1.597522493331663

Epoch: 5| Step: 1
Training loss: 0.1526520550251007
Validation loss: 1.6097951512182913

Epoch: 5| Step: 2
Training loss: 0.19472576677799225
Validation loss: 1.5945051511128743

Epoch: 5| Step: 3
Training loss: 0.2162032127380371
Validation loss: 1.6195998217469902

Epoch: 5| Step: 4
Training loss: 0.13888120651245117
Validation loss: 1.5902132257338493

Epoch: 5| Step: 5
Training loss: 0.16537901759147644
Validation loss: 1.5742176373799641

Epoch: 5| Step: 6
Training loss: 0.11909786611795425
Validation loss: 1.5512261711141115

Epoch: 5| Step: 7
Training loss: 0.13977406919002533
Validation loss: 1.5584881882513724

Epoch: 5| Step: 8
Training loss: 0.1410333812236786
Validation loss: 1.5341986084497103

Epoch: 5| Step: 9
Training loss: 0.14581824839115143
Validation loss: 1.550268991019136

Epoch: 5| Step: 10
Training loss: 0.1134563535451889
Validation loss: 1.5681413412094116

Epoch: 426| Step: 0
Training loss: 0.19369319081306458
Validation loss: 1.5721629204288605

Epoch: 5| Step: 1
Training loss: 0.1606149971485138
Validation loss: 1.5791928678430536

Epoch: 5| Step: 2
Training loss: 0.14176589250564575
Validation loss: 1.610423013728152

Epoch: 5| Step: 3
Training loss: 0.14625419676303864
Validation loss: 1.6541122518559939

Epoch: 5| Step: 4
Training loss: 0.14522583782672882
Validation loss: 1.6467383894869076

Epoch: 5| Step: 5
Training loss: 0.12151318788528442
Validation loss: 1.6614101061256983

Epoch: 5| Step: 6
Training loss: 0.16192874312400818
Validation loss: 1.6305943073764924

Epoch: 5| Step: 7
Training loss: 0.21775774657726288
Validation loss: 1.6581481810539

Epoch: 5| Step: 8
Training loss: 0.16947627067565918
Validation loss: 1.639872956019576

Epoch: 5| Step: 9
Training loss: 0.19324824213981628
Validation loss: 1.6373591692216936

Epoch: 5| Step: 10
Training loss: 0.1991942971944809
Validation loss: 1.6248140937538558

Epoch: 427| Step: 0
Training loss: 0.2319185435771942
Validation loss: 1.6193293025416713

Epoch: 5| Step: 1
Training loss: 0.14833766222000122
Validation loss: 1.6198546578807216

Epoch: 5| Step: 2
Training loss: 0.1507485955953598
Validation loss: 1.598505231641954

Epoch: 5| Step: 3
Training loss: 0.1617404967546463
Validation loss: 1.6006889343261719

Epoch: 5| Step: 4
Training loss: 0.15507876873016357
Validation loss: 1.6054249194360548

Epoch: 5| Step: 5
Training loss: 0.12083673477172852
Validation loss: 1.5863743841007192

Epoch: 5| Step: 6
Training loss: 0.2558380961418152
Validation loss: 1.6043573887117448

Epoch: 5| Step: 7
Training loss: 0.17659468948841095
Validation loss: 1.6504410607840425

Epoch: 5| Step: 8
Training loss: 0.13793693482875824
Validation loss: 1.6691198682272306

Epoch: 5| Step: 9
Training loss: 0.0966847687959671
Validation loss: 1.6313733644382928

Epoch: 5| Step: 10
Training loss: 0.2115277796983719
Validation loss: 1.677048299902229

Epoch: 428| Step: 0
Training loss: 0.21323511004447937
Validation loss: 1.6228634593307332

Epoch: 5| Step: 1
Training loss: 0.16753435134887695
Validation loss: 1.647390506600821

Epoch: 5| Step: 2
Training loss: 0.07803738862276077
Validation loss: 1.6266931635077282

Epoch: 5| Step: 3
Training loss: 0.14187094569206238
Validation loss: 1.6042942641883768

Epoch: 5| Step: 4
Training loss: 0.1789495199918747
Validation loss: 1.582525481459915

Epoch: 5| Step: 5
Training loss: 0.15818829834461212
Validation loss: 1.583217074794154

Epoch: 5| Step: 6
Training loss: 0.21435189247131348
Validation loss: 1.5949043541826227

Epoch: 5| Step: 7
Training loss: 0.10655830055475235
Validation loss: 1.5977979065269552

Epoch: 5| Step: 8
Training loss: 0.10945620387792587
Validation loss: 1.571533456925423

Epoch: 5| Step: 9
Training loss: 0.2183058261871338
Validation loss: 1.6338827674106886

Epoch: 5| Step: 10
Training loss: 0.27025189995765686
Validation loss: 1.6300365514652704

Epoch: 429| Step: 0
Training loss: 0.14243954420089722
Validation loss: 1.6239767574494886

Epoch: 5| Step: 1
Training loss: 0.16949151456356049
Validation loss: 1.6205297362419866

Epoch: 5| Step: 2
Training loss: 0.10528799146413803
Validation loss: 1.5883170020195745

Epoch: 5| Step: 3
Training loss: 0.09621705859899521
Validation loss: 1.6193979273560226

Epoch: 5| Step: 4
Training loss: 0.1971229761838913
Validation loss: 1.6428708043149722

Epoch: 5| Step: 5
Training loss: 0.20252740383148193
Validation loss: 1.6400553282871042

Epoch: 5| Step: 6
Training loss: 0.09205424785614014
Validation loss: 1.6498908048034997

Epoch: 5| Step: 7
Training loss: 0.260677307844162
Validation loss: 1.6518796618266771

Epoch: 5| Step: 8
Training loss: 0.1308242529630661
Validation loss: 1.6405776675029466

Epoch: 5| Step: 9
Training loss: 0.1556999534368515
Validation loss: 1.6161117797256799

Epoch: 5| Step: 10
Training loss: 0.18372948467731476
Validation loss: 1.6334844282878342

Epoch: 430| Step: 0
Training loss: 0.09133873879909515
Validation loss: 1.610301007506668

Epoch: 5| Step: 1
Training loss: 0.22570767998695374
Validation loss: 1.5978026069620603

Epoch: 5| Step: 2
Training loss: 0.1388678103685379
Validation loss: 1.5903584534122097

Epoch: 5| Step: 3
Training loss: 0.1446041762828827
Validation loss: 1.573269760736855

Epoch: 5| Step: 4
Training loss: 0.16938933730125427
Validation loss: 1.5657152437394666

Epoch: 5| Step: 5
Training loss: 0.13939622044563293
Validation loss: 1.5768151936992523

Epoch: 5| Step: 6
Training loss: 0.15691068768501282
Validation loss: 1.5793394619418728

Epoch: 5| Step: 7
Training loss: 0.1951078325510025
Validation loss: 1.58970037967928

Epoch: 5| Step: 8
Training loss: 0.2161015272140503
Validation loss: 1.5932301090609642

Epoch: 5| Step: 9
Training loss: 0.15584826469421387
Validation loss: 1.580431777943847

Epoch: 5| Step: 10
Training loss: 0.10392417758703232
Validation loss: 1.5805368346552695

Epoch: 431| Step: 0
Training loss: 0.18749193847179413
Validation loss: 1.5773222677169307

Epoch: 5| Step: 1
Training loss: 0.1408899426460266
Validation loss: 1.5997994394712551

Epoch: 5| Step: 2
Training loss: 0.2437000721693039
Validation loss: 1.6117078642691336

Epoch: 5| Step: 3
Training loss: 0.13998980820178986
Validation loss: 1.601264589576311

Epoch: 5| Step: 4
Training loss: 0.21637769043445587
Validation loss: 1.6246711771975282

Epoch: 5| Step: 5
Training loss: 0.11034748703241348
Validation loss: 1.606826388707725

Epoch: 5| Step: 6
Training loss: 0.11985800415277481
Validation loss: 1.628042628688197

Epoch: 5| Step: 7
Training loss: 0.11311115324497223
Validation loss: 1.6352053111599338

Epoch: 5| Step: 8
Training loss: 0.09186212718486786
Validation loss: 1.5868810415267944

Epoch: 5| Step: 9
Training loss: 0.12378661334514618
Validation loss: 1.600875667346421

Epoch: 5| Step: 10
Training loss: 0.11481717228889465
Validation loss: 1.6182492304873723

Epoch: 432| Step: 0
Training loss: 0.13555499911308289
Validation loss: 1.593408267985108

Epoch: 5| Step: 1
Training loss: 0.0712951272726059
Validation loss: 1.602225157522386

Epoch: 5| Step: 2
Training loss: 0.12093937397003174
Validation loss: 1.595091292935033

Epoch: 5| Step: 3
Training loss: 0.1204710453748703
Validation loss: 1.5897010526349467

Epoch: 5| Step: 4
Training loss: 0.1118481308221817
Validation loss: 1.6010571070896682

Epoch: 5| Step: 5
Training loss: 0.1112309917807579
Validation loss: 1.5986305590598815

Epoch: 5| Step: 6
Training loss: 0.23719961941242218
Validation loss: 1.6058613407996394

Epoch: 5| Step: 7
Training loss: 0.17549104988574982
Validation loss: 1.568202245619989

Epoch: 5| Step: 8
Training loss: 0.24271273612976074
Validation loss: 1.5602883908056444

Epoch: 5| Step: 9
Training loss: 0.11532354354858398
Validation loss: 1.5686081404327064

Epoch: 5| Step: 10
Training loss: 0.13686993718147278
Validation loss: 1.5625547427003101

Epoch: 433| Step: 0
Training loss: 0.09376201778650284
Validation loss: 1.5996859355639386

Epoch: 5| Step: 1
Training loss: 0.20784220099449158
Validation loss: 1.5885557282355525

Epoch: 5| Step: 2
Training loss: 0.11676573753356934
Validation loss: 1.58449968471322

Epoch: 5| Step: 3
Training loss: 0.08829827606678009
Validation loss: 1.5916218347446893

Epoch: 5| Step: 4
Training loss: 0.21924766898155212
Validation loss: 1.605414508491434

Epoch: 5| Step: 5
Training loss: 0.14881673455238342
Validation loss: 1.6292953773211407

Epoch: 5| Step: 6
Training loss: 0.14465834200382233
Validation loss: 1.6530629973257742

Epoch: 5| Step: 7
Training loss: 0.08748941868543625
Validation loss: 1.6562667521097327

Epoch: 5| Step: 8
Training loss: 0.11350840330123901
Validation loss: 1.6807849150831982

Epoch: 5| Step: 9
Training loss: 0.15172496438026428
Validation loss: 1.6683049458329395

Epoch: 5| Step: 10
Training loss: 0.10953158140182495
Validation loss: 1.6770485306298861

Epoch: 434| Step: 0
Training loss: 0.12564793229103088
Validation loss: 1.6616439357880624

Epoch: 5| Step: 1
Training loss: 0.16766460239887238
Validation loss: 1.6351176795139108

Epoch: 5| Step: 2
Training loss: 0.10418921709060669
Validation loss: 1.6466611200763333

Epoch: 5| Step: 3
Training loss: 0.22216355800628662
Validation loss: 1.6269461365156277

Epoch: 5| Step: 4
Training loss: 0.11305125057697296
Validation loss: 1.605558403076664

Epoch: 5| Step: 5
Training loss: 0.07308612763881683
Validation loss: 1.6047489322641844

Epoch: 5| Step: 6
Training loss: 0.15200945734977722
Validation loss: 1.6089333706004645

Epoch: 5| Step: 7
Training loss: 0.1084742322564125
Validation loss: 1.566514665080655

Epoch: 5| Step: 8
Training loss: 0.27663084864616394
Validation loss: 1.5383804741726126

Epoch: 5| Step: 9
Training loss: 0.11825890839099884
Validation loss: 1.5783634672882736

Epoch: 5| Step: 10
Training loss: 0.1550474613904953
Validation loss: 1.562857408677378

Epoch: 435| Step: 0
Training loss: 0.11403300613164902
Validation loss: 1.5612402692917855

Epoch: 5| Step: 1
Training loss: 0.12990811467170715
Validation loss: 1.6128577583579606

Epoch: 5| Step: 2
Training loss: 0.12365885078907013
Validation loss: 1.6001696009789743

Epoch: 5| Step: 3
Training loss: 0.09402947127819061
Validation loss: 1.631106775294068

Epoch: 5| Step: 4
Training loss: 0.1538427472114563
Validation loss: 1.618737707855881

Epoch: 5| Step: 5
Training loss: 0.23752529919147491
Validation loss: 1.6305832696217362

Epoch: 5| Step: 6
Training loss: 0.1171470433473587
Validation loss: 1.6401402309376707

Epoch: 5| Step: 7
Training loss: 0.21627292037010193
Validation loss: 1.6332182268942557

Epoch: 5| Step: 8
Training loss: 0.24480080604553223
Validation loss: 1.6487954765237787

Epoch: 5| Step: 9
Training loss: 0.1737796813249588
Validation loss: 1.6633118698673863

Epoch: 5| Step: 10
Training loss: 0.19182872772216797
Validation loss: 1.6988317671642508

Epoch: 436| Step: 0
Training loss: 0.19793501496315002
Validation loss: 1.684753333368609

Epoch: 5| Step: 1
Training loss: 0.13575556874275208
Validation loss: 1.7158899794342697

Epoch: 5| Step: 2
Training loss: 0.2075406312942505
Validation loss: 1.670491740267764

Epoch: 5| Step: 3
Training loss: 0.13474400341510773
Validation loss: 1.6602784305490472

Epoch: 5| Step: 4
Training loss: 0.16138404607772827
Validation loss: 1.6144402450130833

Epoch: 5| Step: 5
Training loss: 0.15108366310596466
Validation loss: 1.6020716883802926

Epoch: 5| Step: 6
Training loss: 0.10554975271224976
Validation loss: 1.5880592587173625

Epoch: 5| Step: 7
Training loss: 0.19652879238128662
Validation loss: 1.6178095635547434

Epoch: 5| Step: 8
Training loss: 0.24023766815662384
Validation loss: 1.587226890748547

Epoch: 5| Step: 9
Training loss: 0.1829337775707245
Validation loss: 1.6106233699347383

Epoch: 5| Step: 10
Training loss: 0.19327767193317413
Validation loss: 1.6244235820667718

Epoch: 437| Step: 0
Training loss: 0.1204022616147995
Validation loss: 1.6162856573699622

Epoch: 5| Step: 1
Training loss: 0.13827037811279297
Validation loss: 1.596438177170292

Epoch: 5| Step: 2
Training loss: 0.14686259627342224
Validation loss: 1.621935543193612

Epoch: 5| Step: 3
Training loss: 0.15884679555892944
Validation loss: 1.6060228450323946

Epoch: 5| Step: 4
Training loss: 0.14728374779224396
Validation loss: 1.59018527243727

Epoch: 5| Step: 5
Training loss: 0.17757418751716614
Validation loss: 1.6213528110134987

Epoch: 5| Step: 6
Training loss: 0.18668577075004578
Validation loss: 1.6329871172546058

Epoch: 5| Step: 7
Training loss: 0.21116289496421814
Validation loss: 1.6471202937505578

Epoch: 5| Step: 8
Training loss: 0.1554698944091797
Validation loss: 1.6478324385099514

Epoch: 5| Step: 9
Training loss: 0.13640448451042175
Validation loss: 1.632979836515201

Epoch: 5| Step: 10
Training loss: 0.21205489337444305
Validation loss: 1.655199941768441

Epoch: 438| Step: 0
Training loss: 0.13730762898921967
Validation loss: 1.6429493850277317

Epoch: 5| Step: 1
Training loss: 0.1100640743970871
Validation loss: 1.6791764151665471

Epoch: 5| Step: 2
Training loss: 0.12528011202812195
Validation loss: 1.675629715765676

Epoch: 5| Step: 3
Training loss: 0.17477253079414368
Validation loss: 1.6730089725986603

Epoch: 5| Step: 4
Training loss: 0.12873810529708862
Validation loss: 1.6866035807517268

Epoch: 5| Step: 5
Training loss: 0.13293230533599854
Validation loss: 1.6439962412721367

Epoch: 5| Step: 6
Training loss: 0.12277527153491974
Validation loss: 1.6252515944101478

Epoch: 5| Step: 7
Training loss: 0.11393807828426361
Validation loss: 1.612367291604319

Epoch: 5| Step: 8
Training loss: 0.2309722602367401
Validation loss: 1.608594016362262

Epoch: 5| Step: 9
Training loss: 0.2103801667690277
Validation loss: 1.5995726623842794

Epoch: 5| Step: 10
Training loss: 0.21051469445228577
Validation loss: 1.6141434036275393

Epoch: 439| Step: 0
Training loss: 0.14509296417236328
Validation loss: 1.618747357399233

Epoch: 5| Step: 1
Training loss: 0.10984742641448975
Validation loss: 1.6211573475150651

Epoch: 5| Step: 2
Training loss: 0.13573558628559113
Validation loss: 1.6354981571115472

Epoch: 5| Step: 3
Training loss: 0.1250123530626297
Validation loss: 1.602072641413699

Epoch: 5| Step: 4
Training loss: 0.07992951571941376
Validation loss: 1.6377877637904177

Epoch: 5| Step: 5
Training loss: 0.15935251116752625
Validation loss: 1.6188638120569208

Epoch: 5| Step: 6
Training loss: 0.1146223321557045
Validation loss: 1.62544451221343

Epoch: 5| Step: 7
Training loss: 0.07939229905605316
Validation loss: 1.6543409798734932

Epoch: 5| Step: 8
Training loss: 0.1306958794593811
Validation loss: 1.6251201450183828

Epoch: 5| Step: 9
Training loss: 0.21600480377674103
Validation loss: 1.6139534852838004

Epoch: 5| Step: 10
Training loss: 0.13049350678920746
Validation loss: 1.609332021846566

Epoch: 440| Step: 0
Training loss: 0.17981624603271484
Validation loss: 1.5890787365616008

Epoch: 5| Step: 1
Training loss: 0.15985599160194397
Validation loss: 1.584865379077132

Epoch: 5| Step: 2
Training loss: 0.09383091330528259
Validation loss: 1.5779458989379227

Epoch: 5| Step: 3
Training loss: 0.07169803231954575
Validation loss: 1.5901824300007155

Epoch: 5| Step: 4
Training loss: 0.17222881317138672
Validation loss: 1.5802267495022024

Epoch: 5| Step: 5
Training loss: 0.11582903563976288
Validation loss: 1.6016897732211697

Epoch: 5| Step: 6
Training loss: 0.20544235408306122
Validation loss: 1.594133432193469

Epoch: 5| Step: 7
Training loss: 0.14730370044708252
Validation loss: 1.5899539557836389

Epoch: 5| Step: 8
Training loss: 0.1145268902182579
Validation loss: 1.6014793829251361

Epoch: 5| Step: 9
Training loss: 0.1993185579776764
Validation loss: 1.6123244031783073

Epoch: 5| Step: 10
Training loss: 0.08551423996686935
Validation loss: 1.6100287360529746

Epoch: 441| Step: 0
Training loss: 0.08790852874517441
Validation loss: 1.6189724476106706

Epoch: 5| Step: 1
Training loss: 0.11475946754217148
Validation loss: 1.5985557315170125

Epoch: 5| Step: 2
Training loss: 0.10517419874668121
Validation loss: 1.5947920571091354

Epoch: 5| Step: 3
Training loss: 0.11272784322500229
Validation loss: 1.6191054287777151

Epoch: 5| Step: 4
Training loss: 0.1569853127002716
Validation loss: 1.6113729541019728

Epoch: 5| Step: 5
Training loss: 0.2016887217760086
Validation loss: 1.6148107141576789

Epoch: 5| Step: 6
Training loss: 0.16861872375011444
Validation loss: 1.6211084934972948

Epoch: 5| Step: 7
Training loss: 0.11036409437656403
Validation loss: 1.62404171113045

Epoch: 5| Step: 8
Training loss: 0.16042454540729523
Validation loss: 1.6352261227946128

Epoch: 5| Step: 9
Training loss: 0.1700768917798996
Validation loss: 1.626656832233552

Epoch: 5| Step: 10
Training loss: 0.15468795597553253
Validation loss: 1.6368728690249945

Epoch: 442| Step: 0
Training loss: 0.1221662163734436
Validation loss: 1.6325308610034246

Epoch: 5| Step: 1
Training loss: 0.18010684847831726
Validation loss: 1.6352595911231091

Epoch: 5| Step: 2
Training loss: 0.12671519815921783
Validation loss: 1.5890471576362528

Epoch: 5| Step: 3
Training loss: 0.10723477602005005
Validation loss: 1.580073425846715

Epoch: 5| Step: 4
Training loss: 0.10894918441772461
Validation loss: 1.5872617395975257

Epoch: 5| Step: 5
Training loss: 0.1524105817079544
Validation loss: 1.5868355612601004

Epoch: 5| Step: 6
Training loss: 0.13775213062763214
Validation loss: 1.5926775675947948

Epoch: 5| Step: 7
Training loss: 0.1426423192024231
Validation loss: 1.5542860390037618

Epoch: 5| Step: 8
Training loss: 0.1048758253455162
Validation loss: 1.57510979073022

Epoch: 5| Step: 9
Training loss: 0.09086541831493378
Validation loss: 1.5618596781966507

Epoch: 5| Step: 10
Training loss: 0.18493284285068512
Validation loss: 1.5721434931601248

Epoch: 443| Step: 0
Training loss: 0.14043688774108887
Validation loss: 1.5933158179765106

Epoch: 5| Step: 1
Training loss: 0.16112592816352844
Validation loss: 1.5517470605911747

Epoch: 5| Step: 2
Training loss: 0.09323281049728394
Validation loss: 1.5906730800546625

Epoch: 5| Step: 3
Training loss: 0.10486352443695068
Validation loss: 1.6038326435191657

Epoch: 5| Step: 4
Training loss: 0.09253309667110443
Validation loss: 1.6293722865402058

Epoch: 5| Step: 5
Training loss: 0.15926866233348846
Validation loss: 1.6021967959660355

Epoch: 5| Step: 6
Training loss: 0.1464920938014984
Validation loss: 1.6109133740907073

Epoch: 5| Step: 7
Training loss: 0.11154236644506454
Validation loss: 1.6041197366611932

Epoch: 5| Step: 8
Training loss: 0.1574583500623703
Validation loss: 1.6502370654895742

Epoch: 5| Step: 9
Training loss: 0.08474759757518768
Validation loss: 1.6142424601380543

Epoch: 5| Step: 10
Training loss: 0.19450369477272034
Validation loss: 1.630028493942753

Epoch: 444| Step: 0
Training loss: 0.08525659888982773
Validation loss: 1.6536378757928007

Epoch: 5| Step: 1
Training loss: 0.13669726252555847
Validation loss: 1.6125764218709802

Epoch: 5| Step: 2
Training loss: 0.09068122506141663
Validation loss: 1.6228233870639597

Epoch: 5| Step: 3
Training loss: 0.14712539315223694
Validation loss: 1.5857285004790111

Epoch: 5| Step: 4
Training loss: 0.15759381651878357
Validation loss: 1.600896817381664

Epoch: 5| Step: 5
Training loss: 0.19191813468933105
Validation loss: 1.5725879489734609

Epoch: 5| Step: 6
Training loss: 0.12818218767642975
Validation loss: 1.5847043093814646

Epoch: 5| Step: 7
Training loss: 0.15791676938533783
Validation loss: 1.5360284941170805

Epoch: 5| Step: 8
Training loss: 0.08751261979341507
Validation loss: 1.5739488012047225

Epoch: 5| Step: 9
Training loss: 0.1130855530500412
Validation loss: 1.5778114539320751

Epoch: 5| Step: 10
Training loss: 0.08657284826040268
Validation loss: 1.5964142725031862

Epoch: 445| Step: 0
Training loss: 0.16625913977622986
Validation loss: 1.625065824036957

Epoch: 5| Step: 1
Training loss: 0.10922567546367645
Validation loss: 1.5995521083954842

Epoch: 5| Step: 2
Training loss: 0.13833720982074738
Validation loss: 1.6022327176986202

Epoch: 5| Step: 3
Training loss: 0.1624819040298462
Validation loss: 1.622954773646529

Epoch: 5| Step: 4
Training loss: 0.10055960714817047
Validation loss: 1.601417654304094

Epoch: 5| Step: 5
Training loss: 0.1979808211326599
Validation loss: 1.6359534173883417

Epoch: 5| Step: 6
Training loss: 0.1939203441143036
Validation loss: 1.6515588657830351

Epoch: 5| Step: 7
Training loss: 0.20856747031211853
Validation loss: 1.6270949494454168

Epoch: 5| Step: 8
Training loss: 0.11333820968866348
Validation loss: 1.6329262666804816

Epoch: 5| Step: 9
Training loss: 0.12309781461954117
Validation loss: 1.6231097867411952

Epoch: 5| Step: 10
Training loss: 0.16640116274356842
Validation loss: 1.6408464293326102

Epoch: 446| Step: 0
Training loss: 0.07501965761184692
Validation loss: 1.625726569083429

Epoch: 5| Step: 1
Training loss: 0.11229591071605682
Validation loss: 1.6424712455400856

Epoch: 5| Step: 2
Training loss: 0.10478593409061432
Validation loss: 1.6231506281001593

Epoch: 5| Step: 3
Training loss: 0.19734075665473938
Validation loss: 1.6045824058594242

Epoch: 5| Step: 4
Training loss: 0.1793757677078247
Validation loss: 1.6313650787517588

Epoch: 5| Step: 5
Training loss: 0.11116655170917511
Validation loss: 1.624802750925864

Epoch: 5| Step: 6
Training loss: 0.15593135356903076
Validation loss: 1.635987542008841

Epoch: 5| Step: 7
Training loss: 0.15985916554927826
Validation loss: 1.6083769490641933

Epoch: 5| Step: 8
Training loss: 0.12192269414663315
Validation loss: 1.63524075477354

Epoch: 5| Step: 9
Training loss: 0.14239351451396942
Validation loss: 1.643303584027034

Epoch: 5| Step: 10
Training loss: 0.09485672414302826
Validation loss: 1.646278779993775

Epoch: 447| Step: 0
Training loss: 0.13640236854553223
Validation loss: 1.6208405392144316

Epoch: 5| Step: 1
Training loss: 0.13842453062534332
Validation loss: 1.6564668775886617

Epoch: 5| Step: 2
Training loss: 0.13905155658721924
Validation loss: 1.6438258796609857

Epoch: 5| Step: 3
Training loss: 0.07933235913515091
Validation loss: 1.627957445318981

Epoch: 5| Step: 4
Training loss: 0.15947680175304413
Validation loss: 1.6516891858911003

Epoch: 5| Step: 5
Training loss: 0.21073079109191895
Validation loss: 1.6298037754592074

Epoch: 5| Step: 6
Training loss: 0.15917816758155823
Validation loss: 1.622131554029321

Epoch: 5| Step: 7
Training loss: 0.12678304314613342
Validation loss: 1.6310187744837936

Epoch: 5| Step: 8
Training loss: 0.11704633384943008
Validation loss: 1.601599811225809

Epoch: 5| Step: 9
Training loss: 0.1099339947104454
Validation loss: 1.5937167265081917

Epoch: 5| Step: 10
Training loss: 0.11091713607311249
Validation loss: 1.623403331284882

Epoch: 448| Step: 0
Training loss: 0.16411449015140533
Validation loss: 1.6287774603853944

Epoch: 5| Step: 1
Training loss: 0.11498047411441803
Validation loss: 1.5932484801097582

Epoch: 5| Step: 2
Training loss: 0.14308691024780273
Validation loss: 1.5790874124855123

Epoch: 5| Step: 3
Training loss: 0.12142831087112427
Validation loss: 1.5846625604937155

Epoch: 5| Step: 4
Training loss: 0.07039536535739899
Validation loss: 1.5907968859518729

Epoch: 5| Step: 5
Training loss: 0.11772949993610382
Validation loss: 1.5725809809982136

Epoch: 5| Step: 6
Training loss: 0.1253385841846466
Validation loss: 1.5879856207037484

Epoch: 5| Step: 7
Training loss: 0.09120652824640274
Validation loss: 1.5917376446467575

Epoch: 5| Step: 8
Training loss: 0.11547920852899551
Validation loss: 1.5827416066200501

Epoch: 5| Step: 9
Training loss: 0.12229311466217041
Validation loss: 1.6439016788236556

Epoch: 5| Step: 10
Training loss: 0.1519150733947754
Validation loss: 1.5986908225603

Epoch: 449| Step: 0
Training loss: 0.08352500945329666
Validation loss: 1.6086449533380487

Epoch: 5| Step: 1
Training loss: 0.0819411501288414
Validation loss: 1.634106348278702

Epoch: 5| Step: 2
Training loss: 0.08942006528377533
Validation loss: 1.6260780416509157

Epoch: 5| Step: 3
Training loss: 0.1442323923110962
Validation loss: 1.6466750380813435

Epoch: 5| Step: 4
Training loss: 0.1549421101808548
Validation loss: 1.6342674455335062

Epoch: 5| Step: 5
Training loss: 0.10964541137218475
Validation loss: 1.5899553388677619

Epoch: 5| Step: 6
Training loss: 0.16560375690460205
Validation loss: 1.5862008781843289

Epoch: 5| Step: 7
Training loss: 0.16390876471996307
Validation loss: 1.5810467914868427

Epoch: 5| Step: 8
Training loss: 0.15275564789772034
Validation loss: 1.5632381772482267

Epoch: 5| Step: 9
Training loss: 0.1316612958908081
Validation loss: 1.568158302255856

Epoch: 5| Step: 10
Training loss: 0.09009389579296112
Validation loss: 1.5659660690574235

Epoch: 450| Step: 0
Training loss: 0.10557772219181061
Validation loss: 1.5730702979590303

Epoch: 5| Step: 1
Training loss: 0.20368662476539612
Validation loss: 1.6073702484048822

Epoch: 5| Step: 2
Training loss: 0.13454292714595795
Validation loss: 1.6328401911643244

Epoch: 5| Step: 3
Training loss: 0.11575653403997421
Validation loss: 1.5751801742020475

Epoch: 5| Step: 4
Training loss: 0.18831586837768555
Validation loss: 1.6133830214059481

Epoch: 5| Step: 5
Training loss: 0.07661671936511993
Validation loss: 1.5804264699259112

Epoch: 5| Step: 6
Training loss: 0.1305394470691681
Validation loss: 1.5514335657960625

Epoch: 5| Step: 7
Training loss: 0.15305766463279724
Validation loss: 1.561422646686595

Epoch: 5| Step: 8
Training loss: 0.27183473110198975
Validation loss: 1.555642666355256

Epoch: 5| Step: 9
Training loss: 0.14796975255012512
Validation loss: 1.5561499775096934

Epoch: 5| Step: 10
Training loss: 0.15709006786346436
Validation loss: 1.5353820247034873

Epoch: 451| Step: 0
Training loss: 0.09381650388240814
Validation loss: 1.557246869610202

Epoch: 5| Step: 1
Training loss: 0.14790739119052887
Validation loss: 1.5848996716160928

Epoch: 5| Step: 2
Training loss: 0.1385454684495926
Validation loss: 1.6243930785886702

Epoch: 5| Step: 3
Training loss: 0.2036917507648468
Validation loss: 1.6435683170954387

Epoch: 5| Step: 4
Training loss: 0.1864224374294281
Validation loss: 1.6479344047525877

Epoch: 5| Step: 5
Training loss: 0.09197463095188141
Validation loss: 1.5963105065848238

Epoch: 5| Step: 6
Training loss: 0.1353445202112198
Validation loss: 1.5838014810316023

Epoch: 5| Step: 7
Training loss: 0.11894536018371582
Validation loss: 1.551251357601535

Epoch: 5| Step: 8
Training loss: 0.19502118229866028
Validation loss: 1.5877727321399155

Epoch: 5| Step: 9
Training loss: 0.19737498462200165
Validation loss: 1.56176713461517

Epoch: 5| Step: 10
Training loss: 0.14177055656909943
Validation loss: 1.5409574559939805

Epoch: 452| Step: 0
Training loss: 0.1294868439435959
Validation loss: 1.574871870779222

Epoch: 5| Step: 1
Training loss: 0.1473880261182785
Validation loss: 1.6112484060307986

Epoch: 5| Step: 2
Training loss: 0.1481122523546219
Validation loss: 1.6344144869876165

Epoch: 5| Step: 3
Training loss: 0.12380405515432358
Validation loss: 1.6424100770745227

Epoch: 5| Step: 4
Training loss: 0.13924358785152435
Validation loss: 1.6523325238176572

Epoch: 5| Step: 5
Training loss: 0.0969410091638565
Validation loss: 1.6784836925486082

Epoch: 5| Step: 6
Training loss: 0.12487900257110596
Validation loss: 1.6409327394218856

Epoch: 5| Step: 7
Training loss: 0.2547870874404907
Validation loss: 1.6441215853537283

Epoch: 5| Step: 8
Training loss: 0.14127853512763977
Validation loss: 1.618304798679967

Epoch: 5| Step: 9
Training loss: 0.14371611177921295
Validation loss: 1.6062266775356826

Epoch: 5| Step: 10
Training loss: 0.25574353337287903
Validation loss: 1.6121696169658373

Epoch: 453| Step: 0
Training loss: 0.17504474520683289
Validation loss: 1.5803358836840558

Epoch: 5| Step: 1
Training loss: 0.18362124264240265
Validation loss: 1.5878490235215874

Epoch: 5| Step: 2
Training loss: 0.11042241752147675
Validation loss: 1.5804377775038443

Epoch: 5| Step: 3
Training loss: 0.12486918270587921
Validation loss: 1.6034749643777007

Epoch: 5| Step: 4
Training loss: 0.10515890270471573
Validation loss: 1.6191170689880208

Epoch: 5| Step: 5
Training loss: 0.2261679470539093
Validation loss: 1.6210809241059005

Epoch: 5| Step: 6
Training loss: 0.16172702610492706
Validation loss: 1.6437030210289905

Epoch: 5| Step: 7
Training loss: 0.11016514152288437
Validation loss: 1.5845952008360176

Epoch: 5| Step: 8
Training loss: 0.11253919452428818
Validation loss: 1.602665441010588

Epoch: 5| Step: 9
Training loss: 0.1633017659187317
Validation loss: 1.5873598321791618

Epoch: 5| Step: 10
Training loss: 0.09660488367080688
Validation loss: 1.5749234794288554

Epoch: 454| Step: 0
Training loss: 0.1743740737438202
Validation loss: 1.5851943749253468

Epoch: 5| Step: 1
Training loss: 0.12984009087085724
Validation loss: 1.6119804971961564

Epoch: 5| Step: 2
Training loss: 0.13532307744026184
Validation loss: 1.6016569675937775

Epoch: 5| Step: 3
Training loss: 0.12525412440299988
Validation loss: 1.647910366776169

Epoch: 5| Step: 4
Training loss: 0.22569546103477478
Validation loss: 1.6185859480211813

Epoch: 5| Step: 5
Training loss: 0.15358111262321472
Validation loss: 1.632942500934806

Epoch: 5| Step: 6
Training loss: 0.09243637323379517
Validation loss: 1.6454871258428019

Epoch: 5| Step: 7
Training loss: 0.10579035431146622
Validation loss: 1.6504525946032615

Epoch: 5| Step: 8
Training loss: 0.16033963859081268
Validation loss: 1.6623247977226012

Epoch: 5| Step: 9
Training loss: 0.10731562227010727
Validation loss: 1.6614072886846398

Epoch: 5| Step: 10
Training loss: 0.10223597288131714
Validation loss: 1.6646316179665186

Epoch: 455| Step: 0
Training loss: 0.17068947851657867
Validation loss: 1.7049788454527497

Epoch: 5| Step: 1
Training loss: 0.28559550642967224
Validation loss: 1.6757164821829846

Epoch: 5| Step: 2
Training loss: 0.16775932908058167
Validation loss: 1.6677173568356423

Epoch: 5| Step: 3
Training loss: 0.08513333648443222
Validation loss: 1.6304933768446728

Epoch: 5| Step: 4
Training loss: 0.1067906841635704
Validation loss: 1.6036348406986525

Epoch: 5| Step: 5
Training loss: 0.10149240493774414
Validation loss: 1.5971040059161443

Epoch: 5| Step: 6
Training loss: 0.12079286575317383
Validation loss: 1.5916506641654558

Epoch: 5| Step: 7
Training loss: 0.15430514514446259
Validation loss: 1.5793523083450973

Epoch: 5| Step: 8
Training loss: 0.13336046040058136
Validation loss: 1.5574278831481934

Epoch: 5| Step: 9
Training loss: 0.13790267705917358
Validation loss: 1.557970566134299

Epoch: 5| Step: 10
Training loss: 0.11175438016653061
Validation loss: 1.5578505518615886

Epoch: 456| Step: 0
Training loss: 0.13869601488113403
Validation loss: 1.606799840927124

Epoch: 5| Step: 1
Training loss: 0.20042510330677032
Validation loss: 1.6239754217927174

Epoch: 5| Step: 2
Training loss: 0.07944830507040024
Validation loss: 1.6428821291974796

Epoch: 5| Step: 3
Training loss: 0.17047350108623505
Validation loss: 1.643673655807331

Epoch: 5| Step: 4
Training loss: 0.10678718239068985
Validation loss: 1.612299451904912

Epoch: 5| Step: 5
Training loss: 0.20547182857990265
Validation loss: 1.6392426657420334

Epoch: 5| Step: 6
Training loss: 0.13335053622722626
Validation loss: 1.6106105619861233

Epoch: 5| Step: 7
Training loss: 0.09312815964221954
Validation loss: 1.619419793928823

Epoch: 5| Step: 8
Training loss: 0.12828513979911804
Validation loss: 1.627565021155983

Epoch: 5| Step: 9
Training loss: 0.16418960690498352
Validation loss: 1.628007250447427

Epoch: 5| Step: 10
Training loss: 0.2401818335056305
Validation loss: 1.6516421674400248

Epoch: 457| Step: 0
Training loss: 0.17728766798973083
Validation loss: 1.6524265722561908

Epoch: 5| Step: 1
Training loss: 0.12308521568775177
Validation loss: 1.6358057427149948

Epoch: 5| Step: 2
Training loss: 0.16189928352832794
Validation loss: 1.6350403652396253

Epoch: 5| Step: 3
Training loss: 0.1349991112947464
Validation loss: 1.6229578448880104

Epoch: 5| Step: 4
Training loss: 0.12225233018398285
Validation loss: 1.6347114706552157

Epoch: 5| Step: 5
Training loss: 0.1124228835105896
Validation loss: 1.6225794156392415

Epoch: 5| Step: 6
Training loss: 0.10498599708080292
Validation loss: 1.5935302190883185

Epoch: 5| Step: 7
Training loss: 0.17664054036140442
Validation loss: 1.5901449226563977

Epoch: 5| Step: 8
Training loss: 0.10828389972448349
Validation loss: 1.566036347419985

Epoch: 5| Step: 9
Training loss: 0.09298993647098541
Validation loss: 1.5595689986341743

Epoch: 5| Step: 10
Training loss: 0.1217680275440216
Validation loss: 1.5331317840083953

Epoch: 458| Step: 0
Training loss: 0.14452706277370453
Validation loss: 1.5076938457386468

Epoch: 5| Step: 1
Training loss: 0.11444725841283798
Validation loss: 1.5272671984088035

Epoch: 5| Step: 2
Training loss: 0.1437877118587494
Validation loss: 1.532806190111304

Epoch: 5| Step: 3
Training loss: 0.17521247267723083
Validation loss: 1.5537507085389988

Epoch: 5| Step: 4
Training loss: 0.09883543848991394
Validation loss: 1.5718252581934775

Epoch: 5| Step: 5
Training loss: 0.07413075864315033
Validation loss: 1.581199170440756

Epoch: 5| Step: 6
Training loss: 0.13622143864631653
Validation loss: 1.6023851902254167

Epoch: 5| Step: 7
Training loss: 0.10450653731822968
Validation loss: 1.644231492473233

Epoch: 5| Step: 8
Training loss: 0.09092537313699722
Validation loss: 1.6239239695251628

Epoch: 5| Step: 9
Training loss: 0.1205691546201706
Validation loss: 1.5946167201124213

Epoch: 5| Step: 10
Training loss: 0.07411039620637894
Validation loss: 1.5635985578260114

Epoch: 459| Step: 0
Training loss: 0.1405465006828308
Validation loss: 1.5819575491771902

Epoch: 5| Step: 1
Training loss: 0.11860071122646332
Validation loss: 1.6010877009361022

Epoch: 5| Step: 2
Training loss: 0.10309325158596039
Validation loss: 1.5741801659266155

Epoch: 5| Step: 3
Training loss: 0.10501071065664291
Validation loss: 1.5966550970590243

Epoch: 5| Step: 4
Training loss: 0.17789936065673828
Validation loss: 1.564532035140581

Epoch: 5| Step: 5
Training loss: 0.14682504534721375
Validation loss: 1.6075354391528713

Epoch: 5| Step: 6
Training loss: 0.16059143841266632
Validation loss: 1.5928948451113958

Epoch: 5| Step: 7
Training loss: 0.117997907102108
Validation loss: 1.6288151766664238

Epoch: 5| Step: 8
Training loss: 0.14264273643493652
Validation loss: 1.6499215877184303

Epoch: 5| Step: 9
Training loss: 0.11847188323736191
Validation loss: 1.610652159619075

Epoch: 5| Step: 10
Training loss: 0.14838573336601257
Validation loss: 1.6251930588035173

Epoch: 460| Step: 0
Training loss: 0.12984296679496765
Validation loss: 1.6256426649708902

Epoch: 5| Step: 1
Training loss: 0.0884968563914299
Validation loss: 1.6198537272791709

Epoch: 5| Step: 2
Training loss: 0.16403301060199738
Validation loss: 1.6303217769950948

Epoch: 5| Step: 3
Training loss: 0.17501983046531677
Validation loss: 1.610589595251186

Epoch: 5| Step: 4
Training loss: 0.10650531202554703
Validation loss: 1.5830121847891039

Epoch: 5| Step: 5
Training loss: 0.07600286602973938
Validation loss: 1.6008479556729716

Epoch: 5| Step: 6
Training loss: 0.07134269177913666
Validation loss: 1.5891999467726676

Epoch: 5| Step: 7
Training loss: 0.1433211714029312
Validation loss: 1.5814758936564128

Epoch: 5| Step: 8
Training loss: 0.0782666951417923
Validation loss: 1.5626447264866163

Epoch: 5| Step: 9
Training loss: 0.08504865318536758
Validation loss: 1.5954118697874007

Epoch: 5| Step: 10
Training loss: 0.1514567732810974
Validation loss: 1.5833848355918803

Epoch: 461| Step: 0
Training loss: 0.09097043424844742
Validation loss: 1.5718358268019974

Epoch: 5| Step: 1
Training loss: 0.10342121124267578
Validation loss: 1.5952714950807634

Epoch: 5| Step: 2
Training loss: 0.13958582282066345
Validation loss: 1.5607939253571212

Epoch: 5| Step: 3
Training loss: 0.13496285676956177
Validation loss: 1.583738532117618

Epoch: 5| Step: 4
Training loss: 0.15973567962646484
Validation loss: 1.578183720188756

Epoch: 5| Step: 5
Training loss: 0.15094196796417236
Validation loss: 1.5750415158528153

Epoch: 5| Step: 6
Training loss: 0.16058571636676788
Validation loss: 1.5773192695392075

Epoch: 5| Step: 7
Training loss: 0.07335031032562256
Validation loss: 1.5991933627795147

Epoch: 5| Step: 8
Training loss: 0.1619275063276291
Validation loss: 1.593099868425759

Epoch: 5| Step: 9
Training loss: 0.06110147759318352
Validation loss: 1.571899583262782

Epoch: 5| Step: 10
Training loss: 0.11039870232343674
Validation loss: 1.571301426938785

Epoch: 462| Step: 0
Training loss: 0.11538722366094589
Validation loss: 1.5810534543888544

Epoch: 5| Step: 1
Training loss: 0.1185767874121666
Validation loss: 1.58066725730896

Epoch: 5| Step: 2
Training loss: 0.1235945001244545
Validation loss: 1.58943760202777

Epoch: 5| Step: 3
Training loss: 0.10712265968322754
Validation loss: 1.5700974336234472

Epoch: 5| Step: 4
Training loss: 0.12878549098968506
Validation loss: 1.597975924450864

Epoch: 5| Step: 5
Training loss: 0.1300421506166458
Validation loss: 1.6294784161352343

Epoch: 5| Step: 6
Training loss: 0.10482944548130035
Validation loss: 1.6379516727180892

Epoch: 5| Step: 7
Training loss: 0.11713436990976334
Validation loss: 1.6381969067358202

Epoch: 5| Step: 8
Training loss: 0.12373600155115128
Validation loss: 1.618834622444645

Epoch: 5| Step: 9
Training loss: 0.13796670734882355
Validation loss: 1.5887215393845753

Epoch: 5| Step: 10
Training loss: 0.13035599887371063
Validation loss: 1.5851952414358816

Epoch: 463| Step: 0
Training loss: 0.12104365974664688
Validation loss: 1.5516826645020516

Epoch: 5| Step: 1
Training loss: 0.17546914517879486
Validation loss: 1.5632551870038431

Epoch: 5| Step: 2
Training loss: 0.14082325994968414
Validation loss: 1.5669704855129283

Epoch: 5| Step: 3
Training loss: 0.17634457349777222
Validation loss: 1.5683804039032228

Epoch: 5| Step: 4
Training loss: 0.12392310798168182
Validation loss: 1.5777038073027005

Epoch: 5| Step: 5
Training loss: 0.10678787529468536
Validation loss: 1.591515291121698

Epoch: 5| Step: 6
Training loss: 0.08116631209850311
Validation loss: 1.5715006551434916

Epoch: 5| Step: 7
Training loss: 0.15857449173927307
Validation loss: 1.6052035811126872

Epoch: 5| Step: 8
Training loss: 0.12792852520942688
Validation loss: 1.597488118756202

Epoch: 5| Step: 9
Training loss: 0.10310838371515274
Validation loss: 1.6114350544509066

Epoch: 5| Step: 10
Training loss: 0.1715172380208969
Validation loss: 1.615785357772663

Epoch: 464| Step: 0
Training loss: 0.11418769508600235
Validation loss: 1.5995331707821097

Epoch: 5| Step: 1
Training loss: 0.0997205600142479
Validation loss: 1.569710680233535

Epoch: 5| Step: 2
Training loss: 0.09637021273374557
Validation loss: 1.555065110806496

Epoch: 5| Step: 3
Training loss: 0.0827508419752121
Validation loss: 1.5570844501577399

Epoch: 5| Step: 4
Training loss: 0.1741456836462021
Validation loss: 1.52343407113065

Epoch: 5| Step: 5
Training loss: 0.14557507634162903
Validation loss: 1.5433708416518344

Epoch: 5| Step: 6
Training loss: 0.10869872570037842
Validation loss: 1.537423191532012

Epoch: 5| Step: 7
Training loss: 0.06281470507383347
Validation loss: 1.5592766679743284

Epoch: 5| Step: 8
Training loss: 0.1834036409854889
Validation loss: 1.5843994771280596

Epoch: 5| Step: 9
Training loss: 0.13866640627384186
Validation loss: 1.5636636531481178

Epoch: 5| Step: 10
Training loss: 0.264345645904541
Validation loss: 1.5508004773047663

Epoch: 465| Step: 0
Training loss: 0.1129336804151535
Validation loss: 1.5439896660466348

Epoch: 5| Step: 1
Training loss: 0.11218006908893585
Validation loss: 1.5476205759151007

Epoch: 5| Step: 2
Training loss: 0.14125584065914154
Validation loss: 1.5822960234457446

Epoch: 5| Step: 3
Training loss: 0.058655958622694016
Validation loss: 1.5760434301950599

Epoch: 5| Step: 4
Training loss: 0.11918864399194717
Validation loss: 1.5753818827290689

Epoch: 5| Step: 5
Training loss: 0.1509513556957245
Validation loss: 1.5719048130896784

Epoch: 5| Step: 6
Training loss: 0.12741932272911072
Validation loss: 1.6094838393631803

Epoch: 5| Step: 7
Training loss: 0.07944761216640472
Validation loss: 1.5808568436612365

Epoch: 5| Step: 8
Training loss: 0.13415101170539856
Validation loss: 1.629172222588652

Epoch: 5| Step: 9
Training loss: 0.11090365797281265
Validation loss: 1.6502001221461962

Epoch: 5| Step: 10
Training loss: 0.16750675439834595
Validation loss: 1.6515991200682938

Epoch: 466| Step: 0
Training loss: 0.058936577290296555
Validation loss: 1.6421048128476707

Epoch: 5| Step: 1
Training loss: 0.07825838774442673
Validation loss: 1.6141581086702244

Epoch: 5| Step: 2
Training loss: 0.12537068128585815
Validation loss: 1.6095623277848767

Epoch: 5| Step: 3
Training loss: 0.19969716668128967
Validation loss: 1.6143591134778914

Epoch: 5| Step: 4
Training loss: 0.11619792133569717
Validation loss: 1.5796476346190258

Epoch: 5| Step: 5
Training loss: 0.13556931912899017
Validation loss: 1.60439444229167

Epoch: 5| Step: 6
Training loss: 0.09864784777164459
Validation loss: 1.5848116708058182

Epoch: 5| Step: 7
Training loss: 0.12786582112312317
Validation loss: 1.5879570040651547

Epoch: 5| Step: 8
Training loss: 0.11251099407672882
Validation loss: 1.6045603611135995

Epoch: 5| Step: 9
Training loss: 0.10048066079616547
Validation loss: 1.5914570657155847

Epoch: 5| Step: 10
Training loss: 0.08656835556030273
Validation loss: 1.6139769195228495

Epoch: 467| Step: 0
Training loss: 0.15050062537193298
Validation loss: 1.5782291927645284

Epoch: 5| Step: 1
Training loss: 0.12173764407634735
Validation loss: 1.6258068981991018

Epoch: 5| Step: 2
Training loss: 0.14275121688842773
Validation loss: 1.6079457408638411

Epoch: 5| Step: 3
Training loss: 0.10286968946456909
Validation loss: 1.5670206931329542

Epoch: 5| Step: 4
Training loss: 0.11178363859653473
Validation loss: 1.556608699983166

Epoch: 5| Step: 5
Training loss: 0.12742173671722412
Validation loss: 1.5695799217429212

Epoch: 5| Step: 6
Training loss: 0.1538754105567932
Validation loss: 1.5427959977939565

Epoch: 5| Step: 7
Training loss: 0.13978146016597748
Validation loss: 1.5563128955902592

Epoch: 5| Step: 8
Training loss: 0.08521605283021927
Validation loss: 1.5965947451130036

Epoch: 5| Step: 9
Training loss: 0.08875511586666107
Validation loss: 1.5899213180747083

Epoch: 5| Step: 10
Training loss: 0.1443706452846527
Validation loss: 1.6092508672386088

Epoch: 468| Step: 0
Training loss: 0.18891465663909912
Validation loss: 1.6092094836696502

Epoch: 5| Step: 1
Training loss: 0.07290562242269516
Validation loss: 1.6163743195995208

Epoch: 5| Step: 2
Training loss: 0.06684307754039764
Validation loss: 1.6117440359566801

Epoch: 5| Step: 3
Training loss: 0.12137265503406525
Validation loss: 1.5906467207016484

Epoch: 5| Step: 4
Training loss: 0.18060007691383362
Validation loss: 1.6104852191863521

Epoch: 5| Step: 5
Training loss: 0.06817637383937836
Validation loss: 1.579731354149439

Epoch: 5| Step: 6
Training loss: 0.09711231291294098
Validation loss: 1.573063072337899

Epoch: 5| Step: 7
Training loss: 0.12030327320098877
Validation loss: 1.5312068622599366

Epoch: 5| Step: 8
Training loss: 0.10059010982513428
Validation loss: 1.532661158551452

Epoch: 5| Step: 9
Training loss: 0.1310858428478241
Validation loss: 1.5430204406861336

Epoch: 5| Step: 10
Training loss: 0.15031985938549042
Validation loss: 1.5285194381590812

Epoch: 469| Step: 0
Training loss: 0.13521285355091095
Validation loss: 1.541065498064923

Epoch: 5| Step: 1
Training loss: 0.14353564381599426
Validation loss: 1.5233077413292342

Epoch: 5| Step: 2
Training loss: 0.1343204826116562
Validation loss: 1.5951478148019442

Epoch: 5| Step: 3
Training loss: 0.14917154610157013
Validation loss: 1.596715861110277

Epoch: 5| Step: 4
Training loss: 0.0654679462313652
Validation loss: 1.5700093123220629

Epoch: 5| Step: 5
Training loss: 0.13537010550498962
Validation loss: 1.6116913544234408

Epoch: 5| Step: 6
Training loss: 0.09679843485355377
Validation loss: 1.5632860314461492

Epoch: 5| Step: 7
Training loss: 0.0908280611038208
Validation loss: 1.531360230138225

Epoch: 5| Step: 8
Training loss: 0.10337867587804794
Validation loss: 1.5370362356144895

Epoch: 5| Step: 9
Training loss: 0.1466892808675766
Validation loss: 1.5351786030236112

Epoch: 5| Step: 10
Training loss: 0.15212425589561462
Validation loss: 1.5844303497704126

Epoch: 470| Step: 0
Training loss: 0.17654380202293396
Validation loss: 1.5762972036997478

Epoch: 5| Step: 1
Training loss: 0.14190144836902618
Validation loss: 1.5729270365930372

Epoch: 5| Step: 2
Training loss: 0.1479916274547577
Validation loss: 1.556826747873778

Epoch: 5| Step: 3
Training loss: 0.10063240677118301
Validation loss: 1.5919081600763465

Epoch: 5| Step: 4
Training loss: 0.17792895436286926
Validation loss: 1.597622981635473

Epoch: 5| Step: 5
Training loss: 0.09975051879882812
Validation loss: 1.6071012071383897

Epoch: 5| Step: 6
Training loss: 0.16821026802062988
Validation loss: 1.6084967774729575

Epoch: 5| Step: 7
Training loss: 0.08596234023571014
Validation loss: 1.5970183841643795

Epoch: 5| Step: 8
Training loss: 0.15266256034374237
Validation loss: 1.577728675257775

Epoch: 5| Step: 9
Training loss: 0.06118739768862724
Validation loss: 1.570887093902916

Epoch: 5| Step: 10
Training loss: 0.12817107141017914
Validation loss: 1.5665711267020113

Epoch: 471| Step: 0
Training loss: 0.0997917577624321
Validation loss: 1.5749227513549149

Epoch: 5| Step: 1
Training loss: 0.172448068857193
Validation loss: 1.5921752196486278

Epoch: 5| Step: 2
Training loss: 0.20260000228881836
Validation loss: 1.5580738949519333

Epoch: 5| Step: 3
Training loss: 0.15684828162193298
Validation loss: 1.6049849294847058

Epoch: 5| Step: 4
Training loss: 0.12735508382320404
Validation loss: 1.5907044026159471

Epoch: 5| Step: 5
Training loss: 0.09317396581172943
Validation loss: 1.6417624181316746

Epoch: 5| Step: 6
Training loss: 0.1045401319861412
Validation loss: 1.6455341180165608

Epoch: 5| Step: 7
Training loss: 0.11307527124881744
Validation loss: 1.6450354027491745

Epoch: 5| Step: 8
Training loss: 0.13448184728622437
Validation loss: 1.6275633970896404

Epoch: 5| Step: 9
Training loss: 0.13611455261707306
Validation loss: 1.6057217505670363

Epoch: 5| Step: 10
Training loss: 0.13793541491031647
Validation loss: 1.5917544211110761

Epoch: 472| Step: 0
Training loss: 0.12338200956583023
Validation loss: 1.5684754758752801

Epoch: 5| Step: 1
Training loss: 0.0752158984541893
Validation loss: 1.5725794479411135

Epoch: 5| Step: 2
Training loss: 0.13674601912498474
Validation loss: 1.572064274100847

Epoch: 5| Step: 3
Training loss: 0.15554270148277283
Validation loss: 1.5418751047503563

Epoch: 5| Step: 4
Training loss: 0.15811507403850555
Validation loss: 1.5316262168269004

Epoch: 5| Step: 5
Training loss: 0.11067010462284088
Validation loss: 1.5416511028043685

Epoch: 5| Step: 6
Training loss: 0.12146606296300888
Validation loss: 1.568725086027576

Epoch: 5| Step: 7
Training loss: 0.11486321687698364
Validation loss: 1.5561021015208254

Epoch: 5| Step: 8
Training loss: 0.18332140147686005
Validation loss: 1.5667380735438357

Epoch: 5| Step: 9
Training loss: 0.13987183570861816
Validation loss: 1.5736056809784265

Epoch: 5| Step: 10
Training loss: 0.06888486444950104
Validation loss: 1.5863496206140006

Epoch: 473| Step: 0
Training loss: 0.07745923846960068
Validation loss: 1.5940382339621102

Epoch: 5| Step: 1
Training loss: 0.07208672165870667
Validation loss: 1.605655316383608

Epoch: 5| Step: 2
Training loss: 0.11795046180486679
Validation loss: 1.5873426339959587

Epoch: 5| Step: 3
Training loss: 0.13447216153144836
Validation loss: 1.606187746088992

Epoch: 5| Step: 4
Training loss: 0.07570002973079681
Validation loss: 1.6043459702563543

Epoch: 5| Step: 5
Training loss: 0.078748919069767
Validation loss: 1.5720363637452484

Epoch: 5| Step: 6
Training loss: 0.1374395489692688
Validation loss: 1.584179610975327

Epoch: 5| Step: 7
Training loss: 0.09412665665149689
Validation loss: 1.5693761738397742

Epoch: 5| Step: 8
Training loss: 0.19114288687705994
Validation loss: 1.5814001291028914

Epoch: 5| Step: 9
Training loss: 0.07814003527164459
Validation loss: 1.5631275343638595

Epoch: 5| Step: 10
Training loss: 0.12335432320833206
Validation loss: 1.5512855847676594

Epoch: 474| Step: 0
Training loss: 0.0805145874619484
Validation loss: 1.5659158524646555

Epoch: 5| Step: 1
Training loss: 0.10160501301288605
Validation loss: 1.5780070520216418

Epoch: 5| Step: 2
Training loss: 0.13945096731185913
Validation loss: 1.6180925817899807

Epoch: 5| Step: 3
Training loss: 0.08266135305166245
Validation loss: 1.639167724117156

Epoch: 5| Step: 4
Training loss: 0.11252441257238388
Validation loss: 1.5906120859166628

Epoch: 5| Step: 5
Training loss: 0.15966956317424774
Validation loss: 1.599204009579074

Epoch: 5| Step: 6
Training loss: 0.12944760918617249
Validation loss: 1.6308995728851647

Epoch: 5| Step: 7
Training loss: 0.08596596121788025
Validation loss: 1.6028095291506859

Epoch: 5| Step: 8
Training loss: 0.11628703773021698
Validation loss: 1.6255390669709893

Epoch: 5| Step: 9
Training loss: 0.09526564180850983
Validation loss: 1.5974731214584843

Epoch: 5| Step: 10
Training loss: 0.12415162473917007
Validation loss: 1.5960434393216205

Epoch: 475| Step: 0
Training loss: 0.0790923684835434
Validation loss: 1.5296047554221204

Epoch: 5| Step: 1
Training loss: 0.14545124769210815
Validation loss: 1.5713821329096311

Epoch: 5| Step: 2
Training loss: 0.1149045005440712
Validation loss: 1.5552800111873175

Epoch: 5| Step: 3
Training loss: 0.060888148844242096
Validation loss: 1.5801745486515824

Epoch: 5| Step: 4
Training loss: 0.105415478348732
Validation loss: 1.619255506864158

Epoch: 5| Step: 5
Training loss: 0.20132486522197723
Validation loss: 1.600958780575824

Epoch: 5| Step: 6
Training loss: 0.1541893035173416
Validation loss: 1.6333850904177594

Epoch: 5| Step: 7
Training loss: 0.12343160808086395
Validation loss: 1.630666841742813

Epoch: 5| Step: 8
Training loss: 0.1242140531539917
Validation loss: 1.6280004696179462

Epoch: 5| Step: 9
Training loss: 0.10514221340417862
Validation loss: 1.6273838704632175

Epoch: 5| Step: 10
Training loss: 0.07856235653162003
Validation loss: 1.615939300547364

Epoch: 476| Step: 0
Training loss: 0.09849689155817032
Validation loss: 1.597028737427086

Epoch: 5| Step: 1
Training loss: 0.08325935900211334
Validation loss: 1.5814810773377777

Epoch: 5| Step: 2
Training loss: 0.1070159524679184
Validation loss: 1.5759388746753815

Epoch: 5| Step: 3
Training loss: 0.126132994890213
Validation loss: 1.5751153038394066

Epoch: 5| Step: 4
Training loss: 0.12196958065032959
Validation loss: 1.5848887453797043

Epoch: 5| Step: 5
Training loss: 0.1278305947780609
Validation loss: 1.5557245874917636

Epoch: 5| Step: 6
Training loss: 0.13840389251708984
Validation loss: 1.544434283369331

Epoch: 5| Step: 7
Training loss: 0.131007581949234
Validation loss: 1.536975416444963

Epoch: 5| Step: 8
Training loss: 0.11869631707668304
Validation loss: 1.5367365126968713

Epoch: 5| Step: 9
Training loss: 0.12772758305072784
Validation loss: 1.5570816186166578

Epoch: 5| Step: 10
Training loss: 0.11301132291555405
Validation loss: 1.5634709917088991

Epoch: 477| Step: 0
Training loss: 0.10533330589532852
Validation loss: 1.5236612340455413

Epoch: 5| Step: 1
Training loss: 0.09557410329580307
Validation loss: 1.5557521953377673

Epoch: 5| Step: 2
Training loss: 0.11651593446731567
Validation loss: 1.5591877865534958

Epoch: 5| Step: 3
Training loss: 0.10248596966266632
Validation loss: 1.5667637663502847

Epoch: 5| Step: 4
Training loss: 0.12377135455608368
Validation loss: 1.5774018456858974

Epoch: 5| Step: 5
Training loss: 0.17843112349510193
Validation loss: 1.580060532016139

Epoch: 5| Step: 6
Training loss: 0.10155092179775238
Validation loss: 1.5590464812453075

Epoch: 5| Step: 7
Training loss: 0.11208689212799072
Validation loss: 1.5705716404863583

Epoch: 5| Step: 8
Training loss: 0.08661118149757385
Validation loss: 1.5846566423293083

Epoch: 5| Step: 9
Training loss: 0.11003484576940536
Validation loss: 1.5364329276546356

Epoch: 5| Step: 10
Training loss: 0.1092359870672226
Validation loss: 1.5669189447997718

Epoch: 478| Step: 0
Training loss: 0.10912871360778809
Validation loss: 1.544352533996746

Epoch: 5| Step: 1
Training loss: 0.10088636726140976
Validation loss: 1.5685520889938518

Epoch: 5| Step: 2
Training loss: 0.09834842383861542
Validation loss: 1.560572672915715

Epoch: 5| Step: 3
Training loss: 0.16954973340034485
Validation loss: 1.5955630630575202

Epoch: 5| Step: 4
Training loss: 0.08192390948534012
Validation loss: 1.6044302012330742

Epoch: 5| Step: 5
Training loss: 0.07761497795581818
Validation loss: 1.5879246752749208

Epoch: 5| Step: 6
Training loss: 0.06662626564502716
Validation loss: 1.6108331616206835

Epoch: 5| Step: 7
Training loss: 0.13168957829475403
Validation loss: 1.5955663919448853

Epoch: 5| Step: 8
Training loss: 0.14555248618125916
Validation loss: 1.6228827789265623

Epoch: 5| Step: 9
Training loss: 0.1826014220714569
Validation loss: 1.6067207833772064

Epoch: 5| Step: 10
Training loss: 0.0863332599401474
Validation loss: 1.591581292049859

Epoch: 479| Step: 0
Training loss: 0.11878335475921631
Validation loss: 1.5928092464323966

Epoch: 5| Step: 1
Training loss: 0.12720029056072235
Validation loss: 1.5986903226503761

Epoch: 5| Step: 2
Training loss: 0.08197617530822754
Validation loss: 1.5991146051755516

Epoch: 5| Step: 3
Training loss: 0.11508512496948242
Validation loss: 1.6001923404714113

Epoch: 5| Step: 4
Training loss: 0.11493857204914093
Validation loss: 1.6318472149551555

Epoch: 5| Step: 5
Training loss: 0.13483652472496033
Validation loss: 1.6090280086763444

Epoch: 5| Step: 6
Training loss: 0.08485352993011475
Validation loss: 1.5516371637262323

Epoch: 5| Step: 7
Training loss: 0.1059105396270752
Validation loss: 1.5705468398268505

Epoch: 5| Step: 8
Training loss: 0.12412464618682861
Validation loss: 1.562862947422971

Epoch: 5| Step: 9
Training loss: 0.11730565875768661
Validation loss: 1.5961491318159207

Epoch: 5| Step: 10
Training loss: 0.17447076737880707
Validation loss: 1.587075242432215

Epoch: 480| Step: 0
Training loss: 0.12598808109760284
Validation loss: 1.583584071487509

Epoch: 5| Step: 1
Training loss: 0.10407443344593048
Validation loss: 1.5660510575899513

Epoch: 5| Step: 2
Training loss: 0.11841420829296112
Validation loss: 1.583349230468914

Epoch: 5| Step: 3
Training loss: 0.10297610610723495
Validation loss: 1.5923691975173129

Epoch: 5| Step: 4
Training loss: 0.09036610275506973
Validation loss: 1.6055968628134778

Epoch: 5| Step: 5
Training loss: 0.11841783672571182
Validation loss: 1.5805904839628486

Epoch: 5| Step: 6
Training loss: 0.1005702018737793
Validation loss: 1.5685915011231617

Epoch: 5| Step: 7
Training loss: 0.13251939415931702
Validation loss: 1.5530332826798963

Epoch: 5| Step: 8
Training loss: 0.15063217282295227
Validation loss: 1.56563385071293

Epoch: 5| Step: 9
Training loss: 0.11668147891759872
Validation loss: 1.5743061778365925

Epoch: 5| Step: 10
Training loss: 0.09071335196495056
Validation loss: 1.5716365716790641

Epoch: 481| Step: 0
Training loss: 0.11428241431713104
Validation loss: 1.5868706651913222

Epoch: 5| Step: 1
Training loss: 0.1385497748851776
Validation loss: 1.5849122052551599

Epoch: 5| Step: 2
Training loss: 0.11475519835948944
Validation loss: 1.61327370648743

Epoch: 5| Step: 3
Training loss: 0.18330064415931702
Validation loss: 1.5864067667274064

Epoch: 5| Step: 4
Training loss: 0.1465049684047699
Validation loss: 1.6234973592142905

Epoch: 5| Step: 5
Training loss: 0.09995334595441818
Validation loss: 1.5745400369808238

Epoch: 5| Step: 6
Training loss: 0.10773752629756927
Validation loss: 1.5803146105940624

Epoch: 5| Step: 7
Training loss: 0.0950503721833229
Validation loss: 1.5541116947768836

Epoch: 5| Step: 8
Training loss: 0.08833911269903183
Validation loss: 1.5947071095948577

Epoch: 5| Step: 9
Training loss: 0.1304393857717514
Validation loss: 1.5537779459389307

Epoch: 5| Step: 10
Training loss: 0.14343449473381042
Validation loss: 1.5847991038394231

Epoch: 482| Step: 0
Training loss: 0.24033062160015106
Validation loss: 1.5858743344583819

Epoch: 5| Step: 1
Training loss: 0.10320208221673965
Validation loss: 1.6181295417970227

Epoch: 5| Step: 2
Training loss: 0.13258448243141174
Validation loss: 1.627043870187575

Epoch: 5| Step: 3
Training loss: 0.1851634383201599
Validation loss: 1.6222640340046217

Epoch: 5| Step: 4
Training loss: 0.18406549096107483
Validation loss: 1.5945566354259368

Epoch: 5| Step: 5
Training loss: 0.07231275737285614
Validation loss: 1.6160932894675963

Epoch: 5| Step: 6
Training loss: 0.10719909518957138
Validation loss: 1.5753976170734694

Epoch: 5| Step: 7
Training loss: 0.09000241756439209
Validation loss: 1.5818011119801512

Epoch: 5| Step: 8
Training loss: 0.14731088280677795
Validation loss: 1.5766362144101052

Epoch: 5| Step: 9
Training loss: 0.14403223991394043
Validation loss: 1.5788376638966222

Epoch: 5| Step: 10
Training loss: 0.14534133672714233
Validation loss: 1.5963531668468187

Epoch: 483| Step: 0
Training loss: 0.14166538417339325
Validation loss: 1.5935622569053405

Epoch: 5| Step: 1
Training loss: 0.09328185021877289
Validation loss: 1.5931233154830111

Epoch: 5| Step: 2
Training loss: 0.08868030458688736
Validation loss: 1.6045578679730814

Epoch: 5| Step: 3
Training loss: 0.13331007957458496
Validation loss: 1.6085765746331984

Epoch: 5| Step: 4
Training loss: 0.1116427555680275
Validation loss: 1.5915007642520371

Epoch: 5| Step: 5
Training loss: 0.12278032302856445
Validation loss: 1.5829271321655602

Epoch: 5| Step: 6
Training loss: 0.07772339880466461
Validation loss: 1.5740243017032582

Epoch: 5| Step: 7
Training loss: 0.07467227429151535
Validation loss: 1.5777214188729562

Epoch: 5| Step: 8
Training loss: 0.04564804583787918
Validation loss: 1.5510971687173332

Epoch: 5| Step: 9
Training loss: 0.17605289816856384
Validation loss: 1.537231385066945

Epoch: 5| Step: 10
Training loss: 0.14387524127960205
Validation loss: 1.5542669091173398

Epoch: 484| Step: 0
Training loss: 0.11294838041067123
Validation loss: 1.5436359310662875

Epoch: 5| Step: 1
Training loss: 0.08059805631637573
Validation loss: 1.5222294003732744

Epoch: 5| Step: 2
Training loss: 0.0970989540219307
Validation loss: 1.5482599555805165

Epoch: 5| Step: 3
Training loss: 0.17204883694648743
Validation loss: 1.5940533658509612

Epoch: 5| Step: 4
Training loss: 0.11826638132333755
Validation loss: 1.571249577306932

Epoch: 5| Step: 5
Training loss: 0.08642955869436264
Validation loss: 1.5706514709739274

Epoch: 5| Step: 6
Training loss: 0.14133962988853455
Validation loss: 1.628036077304553

Epoch: 5| Step: 7
Training loss: 0.08901385962963104
Validation loss: 1.591995377694407

Epoch: 5| Step: 8
Training loss: 0.08306101709604263
Validation loss: 1.581004620880209

Epoch: 5| Step: 9
Training loss: 0.127525195479393
Validation loss: 1.5883077075404506

Epoch: 5| Step: 10
Training loss: 0.14710858464241028
Validation loss: 1.5829439035025976

Epoch: 485| Step: 0
Training loss: 0.10329794883728027
Validation loss: 1.560954224678778

Epoch: 5| Step: 1
Training loss: 0.07450256496667862
Validation loss: 1.5579987700267504

Epoch: 5| Step: 2
Training loss: 0.1270173341035843
Validation loss: 1.547868981156298

Epoch: 5| Step: 3
Training loss: 0.13967826962471008
Validation loss: 1.5680756979091193

Epoch: 5| Step: 4
Training loss: 0.15682974457740784
Validation loss: 1.559739790936952

Epoch: 5| Step: 5
Training loss: 0.15421795845031738
Validation loss: 1.5883105377997122

Epoch: 5| Step: 6
Training loss: 0.0899798572063446
Validation loss: 1.5909079890097342

Epoch: 5| Step: 7
Training loss: 0.10132124274969101
Validation loss: 1.5872003839861961

Epoch: 5| Step: 8
Training loss: 0.20091161131858826
Validation loss: 1.5771987169019637

Epoch: 5| Step: 9
Training loss: 0.07116863876581192
Validation loss: 1.5516726355398855

Epoch: 5| Step: 10
Training loss: 0.13445742428302765
Validation loss: 1.5260657405340543

Epoch: 486| Step: 0
Training loss: 0.09089929610490799
Validation loss: 1.529767867057554

Epoch: 5| Step: 1
Training loss: 0.0834800973534584
Validation loss: 1.532446885621676

Epoch: 5| Step: 2
Training loss: 0.1354195773601532
Validation loss: 1.5327927040797409

Epoch: 5| Step: 3
Training loss: 0.07925210148096085
Validation loss: 1.5720338154864568

Epoch: 5| Step: 4
Training loss: 0.0719531923532486
Validation loss: 1.5529622083069177

Epoch: 5| Step: 5
Training loss: 0.12196054309606552
Validation loss: 1.5971992003020419

Epoch: 5| Step: 6
Training loss: 0.09678705036640167
Validation loss: 1.5779580980218866

Epoch: 5| Step: 7
Training loss: 0.13313588500022888
Validation loss: 1.5817247359983382

Epoch: 5| Step: 8
Training loss: 0.15477757155895233
Validation loss: 1.618660952455254

Epoch: 5| Step: 9
Training loss: 0.10631301254034042
Validation loss: 1.6164714226158716

Epoch: 5| Step: 10
Training loss: 0.19143730401992798
Validation loss: 1.5652926839807981

Epoch: 487| Step: 0
Training loss: 0.0854635089635849
Validation loss: 1.5866339104149931

Epoch: 5| Step: 1
Training loss: 0.11696086823940277
Validation loss: 1.5757065831973989

Epoch: 5| Step: 2
Training loss: 0.0889039933681488
Validation loss: 1.6103748865025018

Epoch: 5| Step: 3
Training loss: 0.10231268405914307
Validation loss: 1.5929073723413611

Epoch: 5| Step: 4
Training loss: 0.09104137867689133
Validation loss: 1.5869052743399015

Epoch: 5| Step: 5
Training loss: 0.09912078082561493
Validation loss: 1.5754692618564894

Epoch: 5| Step: 6
Training loss: 0.05483435466885567
Validation loss: 1.5597298286294425

Epoch: 5| Step: 7
Training loss: 0.14002089202404022
Validation loss: 1.5651147057933192

Epoch: 5| Step: 8
Training loss: 0.09922854602336884
Validation loss: 1.5667646008153115

Epoch: 5| Step: 9
Training loss: 0.10131329298019409
Validation loss: 1.5461637127783991

Epoch: 5| Step: 10
Training loss: 0.07179731875658035
Validation loss: 1.5559948772512457

Epoch: 488| Step: 0
Training loss: 0.12166931480169296
Validation loss: 1.5595241246684906

Epoch: 5| Step: 1
Training loss: 0.11784094572067261
Validation loss: 1.5772099866661975

Epoch: 5| Step: 2
Training loss: 0.11357569694519043
Validation loss: 1.5894909661303285

Epoch: 5| Step: 3
Training loss: 0.10369859635829926
Validation loss: 1.5802057891763666

Epoch: 5| Step: 4
Training loss: 0.06997033208608627
Validation loss: 1.575464984422089

Epoch: 5| Step: 5
Training loss: 0.0645236149430275
Validation loss: 1.5313415104343044

Epoch: 5| Step: 6
Training loss: 0.09389466047286987
Validation loss: 1.5225039130897933

Epoch: 5| Step: 7
Training loss: 0.10231177508831024
Validation loss: 1.5324661872720207

Epoch: 5| Step: 8
Training loss: 0.08140580356121063
Validation loss: 1.5283999545599825

Epoch: 5| Step: 9
Training loss: 0.1137019619345665
Validation loss: 1.5520618525884484

Epoch: 5| Step: 10
Training loss: 0.06657425314188004
Validation loss: 1.550853060137841

Epoch: 489| Step: 0
Training loss: 0.07477997243404388
Validation loss: 1.5522748795888757

Epoch: 5| Step: 1
Training loss: 0.05909997224807739
Validation loss: 1.5773915417732731

Epoch: 5| Step: 2
Training loss: 0.08479475229978561
Validation loss: 1.5858931669624903

Epoch: 5| Step: 3
Training loss: 0.09423629939556122
Validation loss: 1.5688354353750906

Epoch: 5| Step: 4
Training loss: 0.1282534897327423
Validation loss: 1.5501187039959816

Epoch: 5| Step: 5
Training loss: 0.13434985280036926
Validation loss: 1.5843472685865176

Epoch: 5| Step: 6
Training loss: 0.07567574828863144
Validation loss: 1.5597641788503176

Epoch: 5| Step: 7
Training loss: 0.1312526911497116
Validation loss: 1.5297836860020955

Epoch: 5| Step: 8
Training loss: 0.13553602993488312
Validation loss: 1.550599935234234

Epoch: 5| Step: 9
Training loss: 0.10972575098276138
Validation loss: 1.5477877727118872

Epoch: 5| Step: 10
Training loss: 0.14466045796871185
Validation loss: 1.536762575949392

Epoch: 490| Step: 0
Training loss: 0.10321341454982758
Validation loss: 1.549095953664472

Epoch: 5| Step: 1
Training loss: 0.12211332470178604
Validation loss: 1.5327391073267946

Epoch: 5| Step: 2
Training loss: 0.12770110368728638
Validation loss: 1.5391770729454615

Epoch: 5| Step: 3
Training loss: 0.12049311399459839
Validation loss: 1.5837208250517487

Epoch: 5| Step: 4
Training loss: 0.13321714103221893
Validation loss: 1.5590408463631906

Epoch: 5| Step: 5
Training loss: 0.1039622575044632
Validation loss: 1.5504196087519329

Epoch: 5| Step: 6
Training loss: 0.13033954799175262
Validation loss: 1.5727805501671248

Epoch: 5| Step: 7
Training loss: 0.15078246593475342
Validation loss: 1.574562056090242

Epoch: 5| Step: 8
Training loss: 0.13332396745681763
Validation loss: 1.593454421207469

Epoch: 5| Step: 9
Training loss: 0.13091662526130676
Validation loss: 1.566672307188793

Epoch: 5| Step: 10
Training loss: 0.0770774558186531
Validation loss: 1.5640739984409784

Epoch: 491| Step: 0
Training loss: 0.10946855694055557
Validation loss: 1.537009940352491

Epoch: 5| Step: 1
Training loss: 0.08499099314212799
Validation loss: 1.559747193449287

Epoch: 5| Step: 2
Training loss: 0.09517724066972733
Validation loss: 1.5458612211288945

Epoch: 5| Step: 3
Training loss: 0.12374436855316162
Validation loss: 1.5510726795401624

Epoch: 5| Step: 4
Training loss: 0.08255837857723236
Validation loss: 1.548078444696242

Epoch: 5| Step: 5
Training loss: 0.08143343031406403
Validation loss: 1.5599839046437254

Epoch: 5| Step: 6
Training loss: 0.06709369271993637
Validation loss: 1.5725716134553314

Epoch: 5| Step: 7
Training loss: 0.10826440900564194
Validation loss: 1.5830565908903718

Epoch: 5| Step: 8
Training loss: 0.142293319106102
Validation loss: 1.6076441657158635

Epoch: 5| Step: 9
Training loss: 0.13123108446598053
Validation loss: 1.5645449494802823

Epoch: 5| Step: 10
Training loss: 0.11371786892414093
Validation loss: 1.5817453976600402

Epoch: 492| Step: 0
Training loss: 0.10701849311590195
Validation loss: 1.5789129618675477

Epoch: 5| Step: 1
Training loss: 0.12107066065073013
Validation loss: 1.5580004005021946

Epoch: 5| Step: 2
Training loss: 0.15868453681468964
Validation loss: 1.523913852630123

Epoch: 5| Step: 3
Training loss: 0.10913487523794174
Validation loss: 1.5480274513203611

Epoch: 5| Step: 4
Training loss: 0.09424644708633423
Validation loss: 1.540091614569387

Epoch: 5| Step: 5
Training loss: 0.06783665716648102
Validation loss: 1.6126918241541872

Epoch: 5| Step: 6
Training loss: 0.07100918143987656
Validation loss: 1.590105938655074

Epoch: 5| Step: 7
Training loss: 0.08652899414300919
Validation loss: 1.6248891392061788

Epoch: 5| Step: 8
Training loss: 0.1305166780948639
Validation loss: 1.615651071712535

Epoch: 5| Step: 9
Training loss: 0.12585215270519257
Validation loss: 1.6696509148484917

Epoch: 5| Step: 10
Training loss: 0.2160860002040863
Validation loss: 1.6381560666586763

Epoch: 493| Step: 0
Training loss: 0.14214828610420227
Validation loss: 1.6195943560651553

Epoch: 5| Step: 1
Training loss: 0.051045555621385574
Validation loss: 1.6297614907705655

Epoch: 5| Step: 2
Training loss: 0.06540535390377045
Validation loss: 1.6120818071467902

Epoch: 5| Step: 3
Training loss: 0.10675909370183945
Validation loss: 1.580601534535808

Epoch: 5| Step: 4
Training loss: 0.13777990639209747
Validation loss: 1.5697116979988672

Epoch: 5| Step: 5
Training loss: 0.13130943477153778
Validation loss: 1.5731649244985273

Epoch: 5| Step: 6
Training loss: 0.151930034160614
Validation loss: 1.563697584213749

Epoch: 5| Step: 7
Training loss: 0.16374088823795319
Validation loss: 1.5412844470752183

Epoch: 5| Step: 8
Training loss: 0.17444324493408203
Validation loss: 1.5406588405691168

Epoch: 5| Step: 9
Training loss: 0.1595790535211563
Validation loss: 1.549020573016136

Epoch: 5| Step: 10
Training loss: 0.14249923825263977
Validation loss: 1.5440141283055788

Epoch: 494| Step: 0
Training loss: 0.11142809689044952
Validation loss: 1.5789994014206754

Epoch: 5| Step: 1
Training loss: 0.11780185997486115
Validation loss: 1.5729984692347947

Epoch: 5| Step: 2
Training loss: 0.12638932466506958
Validation loss: 1.5878077066072853

Epoch: 5| Step: 3
Training loss: 0.14244256913661957
Validation loss: 1.6031368188960577

Epoch: 5| Step: 4
Training loss: 0.13451933860778809
Validation loss: 1.6287298920334026

Epoch: 5| Step: 5
Training loss: 0.08490420877933502
Validation loss: 1.5894040920401131

Epoch: 5| Step: 6
Training loss: 0.16265055537223816
Validation loss: 1.6205443105389994

Epoch: 5| Step: 7
Training loss: 0.11816619336605072
Validation loss: 1.6091946196812454

Epoch: 5| Step: 8
Training loss: 0.1167980208992958
Validation loss: 1.600351232354359

Epoch: 5| Step: 9
Training loss: 0.15148739516735077
Validation loss: 1.6013348967798295

Epoch: 5| Step: 10
Training loss: 0.06814659386873245
Validation loss: 1.601343084407109

Epoch: 495| Step: 0
Training loss: 0.1156441941857338
Validation loss: 1.597662837274613

Epoch: 5| Step: 1
Training loss: 0.1223013624548912
Validation loss: 1.6025204145780174

Epoch: 5| Step: 2
Training loss: 0.134805366396904
Validation loss: 1.6004769135546941

Epoch: 5| Step: 3
Training loss: 0.10307512432336807
Validation loss: 1.5970499515533447

Epoch: 5| Step: 4
Training loss: 0.0953497439622879
Validation loss: 1.5871998956126552

Epoch: 5| Step: 5
Training loss: 0.08358713239431381
Validation loss: 1.605877476353799

Epoch: 5| Step: 6
Training loss: 0.14763201773166656
Validation loss: 1.5927903652191162

Epoch: 5| Step: 7
Training loss: 0.07469803094863892
Validation loss: 1.5638475443727227

Epoch: 5| Step: 8
Training loss: 0.04800485819578171
Validation loss: 1.5811544163252718

Epoch: 5| Step: 9
Training loss: 0.07485517114400864
Validation loss: 1.5699457032706148

Epoch: 5| Step: 10
Training loss: 0.10103097558021545
Validation loss: 1.5568955995703255

Epoch: 496| Step: 0
Training loss: 0.14088726043701172
Validation loss: 1.5471297053880588

Epoch: 5| Step: 1
Training loss: 0.08040713518857956
Validation loss: 1.5651482266764487

Epoch: 5| Step: 2
Training loss: 0.12588778138160706
Validation loss: 1.5474298756609681

Epoch: 5| Step: 3
Training loss: 0.15515409409999847
Validation loss: 1.5702919460112048

Epoch: 5| Step: 4
Training loss: 0.1026548370718956
Validation loss: 1.5653020694691648

Epoch: 5| Step: 5
Training loss: 0.09575039148330688
Validation loss: 1.5685056563346618

Epoch: 5| Step: 6
Training loss: 0.10448607057332993
Validation loss: 1.5606165214251446

Epoch: 5| Step: 7
Training loss: 0.1431044638156891
Validation loss: 1.5905432188382713

Epoch: 5| Step: 8
Training loss: 0.07972315698862076
Validation loss: 1.566658381492861

Epoch: 5| Step: 9
Training loss: 0.06965252012014389
Validation loss: 1.5661564001473047

Epoch: 5| Step: 10
Training loss: 0.09619159251451492
Validation loss: 1.6011162522018596

Epoch: 497| Step: 0
Training loss: 0.08525256812572479
Validation loss: 1.5883884814477736

Epoch: 5| Step: 1
Training loss: 0.16115833818912506
Validation loss: 1.5755315711421352

Epoch: 5| Step: 2
Training loss: 0.10055069625377655
Validation loss: 1.6003081696007841

Epoch: 5| Step: 3
Training loss: 0.14592640101909637
Validation loss: 1.5961267717422978

Epoch: 5| Step: 4
Training loss: 0.13010145723819733
Validation loss: 1.6015227661337903

Epoch: 5| Step: 5
Training loss: 0.06780214607715607
Validation loss: 1.5638803801228922

Epoch: 5| Step: 6
Training loss: 0.07554401457309723
Validation loss: 1.5773635333584202

Epoch: 5| Step: 7
Training loss: 0.10011832416057587
Validation loss: 1.5761555189727454

Epoch: 5| Step: 8
Training loss: 0.09229433536529541
Validation loss: 1.561001617421386

Epoch: 5| Step: 9
Training loss: 0.12725326418876648
Validation loss: 1.5676668420914681

Epoch: 5| Step: 10
Training loss: 0.13818609714508057
Validation loss: 1.558194214297879

Epoch: 498| Step: 0
Training loss: 0.11926895380020142
Validation loss: 1.5623618172061058

Epoch: 5| Step: 1
Training loss: 0.08667164295911789
Validation loss: 1.5596469589458999

Epoch: 5| Step: 2
Training loss: 0.1139851063489914
Validation loss: 1.5858134479932888

Epoch: 5| Step: 3
Training loss: 0.1209544911980629
Validation loss: 1.5982556214896582

Epoch: 5| Step: 4
Training loss: 0.1633681058883667
Validation loss: 1.5752188441573933

Epoch: 5| Step: 5
Training loss: 0.10459359735250473
Validation loss: 1.5948458589533323

Epoch: 5| Step: 6
Training loss: 0.11191444098949432
Validation loss: 1.577058583177546

Epoch: 5| Step: 7
Training loss: 0.08342669159173965
Validation loss: 1.5533275834975704

Epoch: 5| Step: 8
Training loss: 0.08359812200069427
Validation loss: 1.5370364407057404

Epoch: 5| Step: 9
Training loss: 0.08715382218360901
Validation loss: 1.54444323560243

Epoch: 5| Step: 10
Training loss: 0.0988859310746193
Validation loss: 1.5476893391660465

Epoch: 499| Step: 0
Training loss: 0.08699585497379303
Validation loss: 1.5501861136446717

Epoch: 5| Step: 1
Training loss: 0.11384348571300507
Validation loss: 1.55096310441212

Epoch: 5| Step: 2
Training loss: 0.07552812248468399
Validation loss: 1.5805012051777174

Epoch: 5| Step: 3
Training loss: 0.12678846716880798
Validation loss: 1.5897510538819015

Epoch: 5| Step: 4
Training loss: 0.13233713805675507
Validation loss: 1.611444915494611

Epoch: 5| Step: 5
Training loss: 0.10065879672765732
Validation loss: 1.5733073219176261

Epoch: 5| Step: 6
Training loss: 0.181026428937912
Validation loss: 1.5949741794217018

Epoch: 5| Step: 7
Training loss: 0.1479320228099823
Validation loss: 1.6113347725201679

Epoch: 5| Step: 8
Training loss: 0.08892840892076492
Validation loss: 1.6191651673727139

Epoch: 5| Step: 9
Training loss: 0.08515645563602448
Validation loss: 1.634762938304614

Epoch: 5| Step: 10
Training loss: 0.12923626601696014
Validation loss: 1.6155110918065554

Epoch: 500| Step: 0
Training loss: 0.09800626337528229
Validation loss: 1.6286006012270529

Epoch: 5| Step: 1
Training loss: 0.1062643975019455
Validation loss: 1.6158296690192273

Epoch: 5| Step: 2
Training loss: 0.08758138120174408
Validation loss: 1.6034626717208533

Epoch: 5| Step: 3
Training loss: 0.06638848781585693
Validation loss: 1.5946424231734326

Epoch: 5| Step: 4
Training loss: 0.1746523082256317
Validation loss: 1.5878247029037886

Epoch: 5| Step: 5
Training loss: 0.14233143627643585
Validation loss: 1.6157006281678394

Epoch: 5| Step: 6
Training loss: 0.1160518154501915
Validation loss: 1.6198427613063524

Epoch: 5| Step: 7
Training loss: 0.11601988226175308
Validation loss: 1.634230254798807

Epoch: 5| Step: 8
Training loss: 0.13948509097099304
Validation loss: 1.6475582584258048

Epoch: 5| Step: 9
Training loss: 0.06764181703329086
Validation loss: 1.6094368042484406

Epoch: 5| Step: 10
Training loss: 0.12357015907764435
Validation loss: 1.6372456095551933

Epoch: 501| Step: 0
Training loss: 0.1148776262998581
Validation loss: 1.6105048669281827

Epoch: 5| Step: 1
Training loss: 0.11670991033315659
Validation loss: 1.593817832649395

Epoch: 5| Step: 2
Training loss: 0.1549631804227829
Validation loss: 1.6041945283130934

Epoch: 5| Step: 3
Training loss: 0.08015045523643494
Validation loss: 1.6156474838974655

Epoch: 5| Step: 4
Training loss: 0.1656850129365921
Validation loss: 1.5980891181576637

Epoch: 5| Step: 5
Training loss: 0.08093734830617905
Validation loss: 1.5768141977248653

Epoch: 5| Step: 6
Training loss: 0.1309269368648529
Validation loss: 1.6030356819911669

Epoch: 5| Step: 7
Training loss: 0.06747971475124359
Validation loss: 1.5790456395636323

Epoch: 5| Step: 8
Training loss: 0.04293842986226082
Validation loss: 1.5888041001494213

Epoch: 5| Step: 9
Training loss: 0.11510346829891205
Validation loss: 1.5669389802922484

Epoch: 5| Step: 10
Training loss: 0.077784463763237
Validation loss: 1.5577936146848945

Epoch: 502| Step: 0
Training loss: 0.05931055545806885
Validation loss: 1.557750972368384

Epoch: 5| Step: 1
Training loss: 0.08760769665241241
Validation loss: 1.5573286933283652

Epoch: 5| Step: 2
Training loss: 0.10717413574457169
Validation loss: 1.580369649394866

Epoch: 5| Step: 3
Training loss: 0.09152398258447647
Validation loss: 1.5704336525291525

Epoch: 5| Step: 4
Training loss: 0.1908733993768692
Validation loss: 1.5966614087422688

Epoch: 5| Step: 5
Training loss: 0.10983052104711533
Validation loss: 1.5468758113922612

Epoch: 5| Step: 6
Training loss: 0.1483825296163559
Validation loss: 1.5304411675340386

Epoch: 5| Step: 7
Training loss: 0.10433187335729599
Validation loss: 1.5522269869363436

Epoch: 5| Step: 8
Training loss: 0.11609828472137451
Validation loss: 1.5692485365816342

Epoch: 5| Step: 9
Training loss: 0.06606651097536087
Validation loss: 1.5810750146065988

Epoch: 5| Step: 10
Training loss: 0.08496218919754028
Validation loss: 1.5926931647844211

Epoch: 503| Step: 0
Training loss: 0.11229207366704941
Validation loss: 1.5976861279497865

Epoch: 5| Step: 1
Training loss: 0.10606386512517929
Validation loss: 1.5791327504701511

Epoch: 5| Step: 2
Training loss: 0.08311817795038223
Validation loss: 1.5874383129099363

Epoch: 5| Step: 3
Training loss: 0.0936812087893486
Validation loss: 1.584653672351632

Epoch: 5| Step: 4
Training loss: 0.11246281862258911
Validation loss: 1.5782535845233547

Epoch: 5| Step: 5
Training loss: 0.07585890591144562
Validation loss: 1.5779743797035628

Epoch: 5| Step: 6
Training loss: 0.08094699680805206
Validation loss: 1.5888883913716962

Epoch: 5| Step: 7
Training loss: 0.07084687054157257
Validation loss: 1.5930309398199922

Epoch: 5| Step: 8
Training loss: 0.08092927187681198
Validation loss: 1.5977300020956224

Epoch: 5| Step: 9
Training loss: 0.1322495937347412
Validation loss: 1.6157509357698503

Epoch: 5| Step: 10
Training loss: 0.10447713732719421
Validation loss: 1.6234246966659382

Epoch: 504| Step: 0
Training loss: 0.05662103742361069
Validation loss: 1.6068695193977767

Epoch: 5| Step: 1
Training loss: 0.07738813012838364
Validation loss: 1.6215725444978284

Epoch: 5| Step: 2
Training loss: 0.09059502184391022
Validation loss: 1.6056897486409833

Epoch: 5| Step: 3
Training loss: 0.0877419039607048
Validation loss: 1.5747493236295638

Epoch: 5| Step: 4
Training loss: 0.08546510338783264
Validation loss: 1.6148391808232954

Epoch: 5| Step: 5
Training loss: 0.07901836186647415
Validation loss: 1.6239213251298474

Epoch: 5| Step: 6
Training loss: 0.08133338391780853
Validation loss: 1.5990554927497782

Epoch: 5| Step: 7
Training loss: 0.13274100422859192
Validation loss: 1.5993846308800481

Epoch: 5| Step: 8
Training loss: 0.15384435653686523
Validation loss: 1.590841172843851

Epoch: 5| Step: 9
Training loss: 0.15930739045143127
Validation loss: 1.6251711217305993

Epoch: 5| Step: 10
Training loss: 0.10040086507797241
Validation loss: 1.5624946343001498

Epoch: 505| Step: 0
Training loss: 0.0804794579744339
Validation loss: 1.572511847301196

Epoch: 5| Step: 1
Training loss: 0.06994792073965073
Validation loss: 1.5482448070280013

Epoch: 5| Step: 2
Training loss: 0.09389139711856842
Validation loss: 1.5415617163463304

Epoch: 5| Step: 3
Training loss: 0.15928706526756287
Validation loss: 1.5494513627021544

Epoch: 5| Step: 4
Training loss: 0.1132182627916336
Validation loss: 1.5445286304719987

Epoch: 5| Step: 5
Training loss: 0.12402397394180298
Validation loss: 1.5293199772475867

Epoch: 5| Step: 6
Training loss: 0.11697013676166534
Validation loss: 1.5141344019161758

Epoch: 5| Step: 7
Training loss: 0.10045071691274643
Validation loss: 1.5502004431140037

Epoch: 5| Step: 8
Training loss: 0.10394050925970078
Validation loss: 1.554993938374263

Epoch: 5| Step: 9
Training loss: 0.10848722606897354
Validation loss: 1.549613683454452

Epoch: 5| Step: 10
Training loss: 0.07033953070640564
Validation loss: 1.5353109785305556

Epoch: 506| Step: 0
Training loss: 0.08929894864559174
Validation loss: 1.5449302196502686

Epoch: 5| Step: 1
Training loss: 0.09668247401714325
Validation loss: 1.5525135968321113

Epoch: 5| Step: 2
Training loss: 0.11041991412639618
Validation loss: 1.5892488212995632

Epoch: 5| Step: 3
Training loss: 0.08133299648761749
Validation loss: 1.5578912784976344

Epoch: 5| Step: 4
Training loss: 0.14858302474021912
Validation loss: 1.581126255373801

Epoch: 5| Step: 5
Training loss: 0.10681392252445221
Validation loss: 1.5565435078836256

Epoch: 5| Step: 6
Training loss: 0.14344611763954163
Validation loss: 1.5780359993698776

Epoch: 5| Step: 7
Training loss: 0.08971703052520752
Validation loss: 1.5808306573539652

Epoch: 5| Step: 8
Training loss: 0.08603110909461975
Validation loss: 1.5930490929593322

Epoch: 5| Step: 9
Training loss: 0.09843205660581589
Validation loss: 1.5830343641260618

Epoch: 5| Step: 10
Training loss: 0.11793918907642365
Validation loss: 1.6034796237945557

Epoch: 507| Step: 0
Training loss: 0.08721818029880524
Validation loss: 1.6234025903927383

Epoch: 5| Step: 1
Training loss: 0.10906871408224106
Validation loss: 1.603083888689677

Epoch: 5| Step: 2
Training loss: 0.1147644966840744
Validation loss: 1.6102080819427327

Epoch: 5| Step: 3
Training loss: 0.10824596881866455
Validation loss: 1.5927036013654483

Epoch: 5| Step: 4
Training loss: 0.09270981699228287
Validation loss: 1.588454254211918

Epoch: 5| Step: 5
Training loss: 0.0821555107831955
Validation loss: 1.5944872863831059

Epoch: 5| Step: 6
Training loss: 0.08203808218240738
Validation loss: 1.6052479756775724

Epoch: 5| Step: 7
Training loss: 0.0957566499710083
Validation loss: 1.5966926825943815

Epoch: 5| Step: 8
Training loss: 0.0634443536400795
Validation loss: 1.596445664282768

Epoch: 5| Step: 9
Training loss: 0.10151944309473038
Validation loss: 1.5733383983694098

Epoch: 5| Step: 10
Training loss: 0.12922343611717224
Validation loss: 1.5790181275336974

Epoch: 508| Step: 0
Training loss: 0.1657865345478058
Validation loss: 1.556237555319263

Epoch: 5| Step: 1
Training loss: 0.07607536017894745
Validation loss: 1.5794131960920108

Epoch: 5| Step: 2
Training loss: 0.11766742169857025
Validation loss: 1.5978141228357952

Epoch: 5| Step: 3
Training loss: 0.06414881348609924
Validation loss: 1.5533583125760477

Epoch: 5| Step: 4
Training loss: 0.0751325860619545
Validation loss: 1.5647658673665856

Epoch: 5| Step: 5
Training loss: 0.058388032019138336
Validation loss: 1.590408170095054

Epoch: 5| Step: 6
Training loss: 0.16019770503044128
Validation loss: 1.6034767884080128

Epoch: 5| Step: 7
Training loss: 0.12232835590839386
Validation loss: 1.6089658173181678

Epoch: 5| Step: 8
Training loss: 0.05913378670811653
Validation loss: 1.5808402312699186

Epoch: 5| Step: 9
Training loss: 0.056683044880628586
Validation loss: 1.5825132810941307

Epoch: 5| Step: 10
Training loss: 0.1224462017416954
Validation loss: 1.593858426617038

Epoch: 509| Step: 0
Training loss: 0.05446557328104973
Validation loss: 1.593152226940278

Epoch: 5| Step: 1
Training loss: 0.054512858390808105
Validation loss: 1.5864254697676627

Epoch: 5| Step: 2
Training loss: 0.07851274311542511
Validation loss: 1.5772907849281066

Epoch: 5| Step: 3
Training loss: 0.09730225801467896
Validation loss: 1.5987851042901315

Epoch: 5| Step: 4
Training loss: 0.07211507856845856
Validation loss: 1.5806438589608798

Epoch: 5| Step: 5
Training loss: 0.09816344082355499
Validation loss: 1.6018475832477692

Epoch: 5| Step: 6
Training loss: 0.10121717303991318
Validation loss: 1.5914487377289803

Epoch: 5| Step: 7
Training loss: 0.07978428900241852
Validation loss: 1.5847729021503079

Epoch: 5| Step: 8
Training loss: 0.1448417603969574
Validation loss: 1.5827810719449034

Epoch: 5| Step: 9
Training loss: 0.10092905908823013
Validation loss: 1.6438701934711908

Epoch: 5| Step: 10
Training loss: 0.1891280561685562
Validation loss: 1.6098865924342987

Epoch: 510| Step: 0
Training loss: 0.08344630151987076
Validation loss: 1.6094830305345598

Epoch: 5| Step: 1
Training loss: 0.1439986526966095
Validation loss: 1.5985077760552848

Epoch: 5| Step: 2
Training loss: 0.12554927170276642
Validation loss: 1.6241454014214136

Epoch: 5| Step: 3
Training loss: 0.1257413774728775
Validation loss: 1.5824817925371149

Epoch: 5| Step: 4
Training loss: 0.22646097838878632
Validation loss: 1.5655175562827819

Epoch: 5| Step: 5
Training loss: 0.09909477084875107
Validation loss: 1.5750981210380472

Epoch: 5| Step: 6
Training loss: 0.06400041282176971
Validation loss: 1.5486817283015097

Epoch: 5| Step: 7
Training loss: 0.1072673425078392
Validation loss: 1.5918042980214602

Epoch: 5| Step: 8
Training loss: 0.08695469796657562
Validation loss: 1.5938938734351948

Epoch: 5| Step: 9
Training loss: 0.08192890882492065
Validation loss: 1.5739664223886305

Epoch: 5| Step: 10
Training loss: 0.15472576022148132
Validation loss: 1.600026543422412

Epoch: 511| Step: 0
Training loss: 0.11140183359384537
Validation loss: 1.5891102443459213

Epoch: 5| Step: 1
Training loss: 0.09311405569314957
Validation loss: 1.5705367275463638

Epoch: 5| Step: 2
Training loss: 0.10580619424581528
Validation loss: 1.5720905296264156

Epoch: 5| Step: 3
Training loss: 0.140338733792305
Validation loss: 1.558106945407006

Epoch: 5| Step: 4
Training loss: 0.10402896255254745
Validation loss: 1.5417023179351643

Epoch: 5| Step: 5
Training loss: 0.11963971704244614
Validation loss: 1.588675896326701

Epoch: 5| Step: 6
Training loss: 0.17167100310325623
Validation loss: 1.5866087072639055

Epoch: 5| Step: 7
Training loss: 0.0971851721405983
Validation loss: 1.594901604037131

Epoch: 5| Step: 8
Training loss: 0.12345749139785767
Validation loss: 1.588558094475859

Epoch: 5| Step: 9
Training loss: 0.11756274849176407
Validation loss: 1.583424586121754

Epoch: 5| Step: 10
Training loss: 0.07440987974405289
Validation loss: 1.6135956984694286

Epoch: 512| Step: 0
Training loss: 0.05914973467588425
Validation loss: 1.6005823484031103

Epoch: 5| Step: 1
Training loss: 0.045010268688201904
Validation loss: 1.6038604705564437

Epoch: 5| Step: 2
Training loss: 0.10319150984287262
Validation loss: 1.5936285116339242

Epoch: 5| Step: 3
Training loss: 0.07816808670759201
Validation loss: 1.6088984730423137

Epoch: 5| Step: 4
Training loss: 0.07470449805259705
Validation loss: 1.5939867957945792

Epoch: 5| Step: 5
Training loss: 0.07934395968914032
Validation loss: 1.5814980563297067

Epoch: 5| Step: 6
Training loss: 0.1377715766429901
Validation loss: 1.572970426210793

Epoch: 5| Step: 7
Training loss: 0.13065758347511292
Validation loss: 1.5725320962167555

Epoch: 5| Step: 8
Training loss: 0.12093149125576019
Validation loss: 1.5745759061587754

Epoch: 5| Step: 9
Training loss: 0.08652646839618683
Validation loss: 1.5695984312283096

Epoch: 5| Step: 10
Training loss: 0.0706532821059227
Validation loss: 1.5705103694751699

Epoch: 513| Step: 0
Training loss: 0.05658585950732231
Validation loss: 1.596757726002765

Epoch: 5| Step: 1
Training loss: 0.07369108498096466
Validation loss: 1.5790362601639123

Epoch: 5| Step: 2
Training loss: 0.07511276006698608
Validation loss: 1.6023955986063967

Epoch: 5| Step: 3
Training loss: 0.053040165454149246
Validation loss: 1.605406779114918

Epoch: 5| Step: 4
Training loss: 0.09392503648996353
Validation loss: 1.6089601798724102

Epoch: 5| Step: 5
Training loss: 0.11145128309726715
Validation loss: 1.593234662727643

Epoch: 5| Step: 6
Training loss: 0.151560440659523
Validation loss: 1.626064419746399

Epoch: 5| Step: 7
Training loss: 0.12519490718841553
Validation loss: 1.5901809353982248

Epoch: 5| Step: 8
Training loss: 0.07792499661445618
Validation loss: 1.5721250913476432

Epoch: 5| Step: 9
Training loss: 0.09446760267019272
Validation loss: 1.6039316654205322

Epoch: 5| Step: 10
Training loss: 0.18857024610042572
Validation loss: 1.5502248310273694

Epoch: 514| Step: 0
Training loss: 0.1537443846464157
Validation loss: 1.540627416744027

Epoch: 5| Step: 1
Training loss: 0.0887964740395546
Validation loss: 1.5856056687652424

Epoch: 5| Step: 2
Training loss: 0.0927228182554245
Validation loss: 1.5761459809477611

Epoch: 5| Step: 3
Training loss: 0.09765300899744034
Validation loss: 1.569625558391694

Epoch: 5| Step: 4
Training loss: 0.10360614955425262
Validation loss: 1.5862006910385624

Epoch: 5| Step: 5
Training loss: 0.06567379087209702
Validation loss: 1.5829103723649056

Epoch: 5| Step: 6
Training loss: 0.08802657574415207
Validation loss: 1.5880038533159482

Epoch: 5| Step: 7
Training loss: 0.09756070375442505
Validation loss: 1.6080992990924465

Epoch: 5| Step: 8
Training loss: 0.0732785314321518
Validation loss: 1.5796087159905383

Epoch: 5| Step: 9
Training loss: 0.07628484815359116
Validation loss: 1.5756970400451331

Epoch: 5| Step: 10
Training loss: 0.07488277554512024
Validation loss: 1.5899901838712795

Epoch: 515| Step: 0
Training loss: 0.10347577184438705
Validation loss: 1.570632948670336

Epoch: 5| Step: 1
Training loss: 0.11737821251153946
Validation loss: 1.5808718653135403

Epoch: 5| Step: 2
Training loss: 0.11340701580047607
Validation loss: 1.5961751860956992

Epoch: 5| Step: 3
Training loss: 0.09075949341058731
Validation loss: 1.5817513177471776

Epoch: 5| Step: 4
Training loss: 0.08857055008411407
Validation loss: 1.572643764557377

Epoch: 5| Step: 5
Training loss: 0.11745365709066391
Validation loss: 1.5730269198776574

Epoch: 5| Step: 6
Training loss: 0.0922180563211441
Validation loss: 1.563808189284417

Epoch: 5| Step: 7
Training loss: 0.07547245174646378
Validation loss: 1.569062340644098

Epoch: 5| Step: 8
Training loss: 0.14311712980270386
Validation loss: 1.5744846431157922

Epoch: 5| Step: 9
Training loss: 0.10360655933618546
Validation loss: 1.5888654352516256

Epoch: 5| Step: 10
Training loss: 0.09023324400186539
Validation loss: 1.576492489025157

Epoch: 516| Step: 0
Training loss: 0.07248742878437042
Validation loss: 1.5758096992328603

Epoch: 5| Step: 1
Training loss: 0.13732579350471497
Validation loss: 1.576599269784907

Epoch: 5| Step: 2
Training loss: 0.12450842559337616
Validation loss: 1.6144124038757817

Epoch: 5| Step: 3
Training loss: 0.07748586684465408
Validation loss: 1.6175193632802656

Epoch: 5| Step: 4
Training loss: 0.07537733018398285
Validation loss: 1.5897126697724866

Epoch: 5| Step: 5
Training loss: 0.12336667627096176
Validation loss: 1.5711393317868632

Epoch: 5| Step: 6
Training loss: 0.10623832046985626
Validation loss: 1.5600974508511123

Epoch: 5| Step: 7
Training loss: 0.07799355685710907
Validation loss: 1.5922611221190421

Epoch: 5| Step: 8
Training loss: 0.12226154655218124
Validation loss: 1.5418023473473006

Epoch: 5| Step: 9
Training loss: 0.11299987137317657
Validation loss: 1.5932645374728787

Epoch: 5| Step: 10
Training loss: 0.1263931542634964
Validation loss: 1.549132150988425

Epoch: 517| Step: 0
Training loss: 0.0640382319688797
Validation loss: 1.5275644192131617

Epoch: 5| Step: 1
Training loss: 0.0687524825334549
Validation loss: 1.5589326479101693

Epoch: 5| Step: 2
Training loss: 0.13407698273658752
Validation loss: 1.5563517360277073

Epoch: 5| Step: 3
Training loss: 0.11115732043981552
Validation loss: 1.5616179461120276

Epoch: 5| Step: 4
Training loss: 0.11829651892185211
Validation loss: 1.5671847148608136

Epoch: 5| Step: 5
Training loss: 0.0834047943353653
Validation loss: 1.5573401271655996

Epoch: 5| Step: 6
Training loss: 0.1350732147693634
Validation loss: 1.571695778959541

Epoch: 5| Step: 7
Training loss: 0.06889577209949493
Validation loss: 1.5724518299102783

Epoch: 5| Step: 8
Training loss: 0.0734388455748558
Validation loss: 1.57287258742958

Epoch: 5| Step: 9
Training loss: 0.08715978264808655
Validation loss: 1.577210190475628

Epoch: 5| Step: 10
Training loss: 0.06384819000959396
Validation loss: 1.5931350364479968

Epoch: 518| Step: 0
Training loss: 0.07249467074871063
Validation loss: 1.5898139399866904

Epoch: 5| Step: 1
Training loss: 0.09255277365446091
Validation loss: 1.605545873283058

Epoch: 5| Step: 2
Training loss: 0.0951189249753952
Validation loss: 1.5914646412736626

Epoch: 5| Step: 3
Training loss: 0.09416482597589493
Validation loss: 1.5661881803184428

Epoch: 5| Step: 4
Training loss: 0.07597442716360092
Validation loss: 1.581999037855415

Epoch: 5| Step: 5
Training loss: 0.0771494060754776
Validation loss: 1.59907526739182

Epoch: 5| Step: 6
Training loss: 0.10799503326416016
Validation loss: 1.5893529589458177

Epoch: 5| Step: 7
Training loss: 0.13273222744464874
Validation loss: 1.569042731356877

Epoch: 5| Step: 8
Training loss: 0.11135800927877426
Validation loss: 1.5701258720890168

Epoch: 5| Step: 9
Training loss: 0.05139990895986557
Validation loss: 1.5912386191788541

Epoch: 5| Step: 10
Training loss: 0.08664040267467499
Validation loss: 1.5521359456482755

Epoch: 519| Step: 0
Training loss: 0.08515568822622299
Validation loss: 1.6127561407704507

Epoch: 5| Step: 1
Training loss: 0.08219237625598907
Validation loss: 1.5611817426578973

Epoch: 5| Step: 2
Training loss: 0.059151552617549896
Validation loss: 1.592926981628582

Epoch: 5| Step: 3
Training loss: 0.10007257759571075
Validation loss: 1.5573411116036036

Epoch: 5| Step: 4
Training loss: 0.09630312025547028
Validation loss: 1.5456037841817385

Epoch: 5| Step: 5
Training loss: 0.10541228950023651
Validation loss: 1.5608632256907802

Epoch: 5| Step: 6
Training loss: 0.10600229352712631
Validation loss: 1.517677221246945

Epoch: 5| Step: 7
Training loss: 0.12378767877817154
Validation loss: 1.5328582666253532

Epoch: 5| Step: 8
Training loss: 0.10875485092401505
Validation loss: 1.5184867112867293

Epoch: 5| Step: 9
Training loss: 0.10060741007328033
Validation loss: 1.5302538294945993

Epoch: 5| Step: 10
Training loss: 0.13677555322647095
Validation loss: 1.541935331077986

Epoch: 520| Step: 0
Training loss: 0.08271349966526031
Validation loss: 1.5404370997541694

Epoch: 5| Step: 1
Training loss: 0.10321696102619171
Validation loss: 1.550741385388118

Epoch: 5| Step: 2
Training loss: 0.04351462423801422
Validation loss: 1.5719617746209587

Epoch: 5| Step: 3
Training loss: 0.07327977567911148
Validation loss: 1.598422086367043

Epoch: 5| Step: 4
Training loss: 0.10461340099573135
Validation loss: 1.5748273403413835

Epoch: 5| Step: 5
Training loss: 0.11157349497079849
Validation loss: 1.5989634567691433

Epoch: 5| Step: 6
Training loss: 0.07559418678283691
Validation loss: 1.5902401529332644

Epoch: 5| Step: 7
Training loss: 0.13309583067893982
Validation loss: 1.5650139316435783

Epoch: 5| Step: 8
Training loss: 0.056927360594272614
Validation loss: 1.5854981496769895

Epoch: 5| Step: 9
Training loss: 0.13987474143505096
Validation loss: 1.5868684258512271

Epoch: 5| Step: 10
Training loss: 0.08056135475635529
Validation loss: 1.5868675503679501

Epoch: 521| Step: 0
Training loss: 0.07480834424495697
Validation loss: 1.573214260480737

Epoch: 5| Step: 1
Training loss: 0.120614193379879
Validation loss: 1.5624921116777646

Epoch: 5| Step: 2
Training loss: 0.1570834517478943
Validation loss: 1.5891728862639396

Epoch: 5| Step: 3
Training loss: 0.07862160354852676
Validation loss: 1.5949162065341909

Epoch: 5| Step: 4
Training loss: 0.07975243031978607
Validation loss: 1.6134383140071746

Epoch: 5| Step: 5
Training loss: 0.08009505271911621
Validation loss: 1.573054540541864

Epoch: 5| Step: 6
Training loss: 0.11096455901861191
Validation loss: 1.5748960766741025

Epoch: 5| Step: 7
Training loss: 0.06817473471164703
Validation loss: 1.5485257346143004

Epoch: 5| Step: 8
Training loss: 0.052736662328243256
Validation loss: 1.5950525896523589

Epoch: 5| Step: 9
Training loss: 0.11135894060134888
Validation loss: 1.550838489045379

Epoch: 5| Step: 10
Training loss: 0.07819269597530365
Validation loss: 1.536754410753968

Epoch: 522| Step: 0
Training loss: 0.07935049384832382
Validation loss: 1.5758052615709202

Epoch: 5| Step: 1
Training loss: 0.07209281623363495
Validation loss: 1.5625017983939058

Epoch: 5| Step: 2
Training loss: 0.0826205387711525
Validation loss: 1.5538738828192475

Epoch: 5| Step: 3
Training loss: 0.09100040048360825
Validation loss: 1.5640738420588995

Epoch: 5| Step: 4
Training loss: 0.09724044799804688
Validation loss: 1.5868029581603182

Epoch: 5| Step: 5
Training loss: 0.08989928662776947
Validation loss: 1.5757833578253304

Epoch: 5| Step: 6
Training loss: 0.11164059489965439
Validation loss: 1.5604998360397995

Epoch: 5| Step: 7
Training loss: 0.08617547154426575
Validation loss: 1.5568505153861096

Epoch: 5| Step: 8
Training loss: 0.0526227168738842
Validation loss: 1.5326760545853646

Epoch: 5| Step: 9
Training loss: 0.07171449810266495
Validation loss: 1.5115010866554834

Epoch: 5| Step: 10
Training loss: 0.09695883095264435
Validation loss: 1.4991624201497724

Epoch: 523| Step: 0
Training loss: 0.06322933733463287
Validation loss: 1.538073903770857

Epoch: 5| Step: 1
Training loss: 0.1047421246767044
Validation loss: 1.5491793219761183

Epoch: 5| Step: 2
Training loss: 0.05251403525471687
Validation loss: 1.540921866252858

Epoch: 5| Step: 3
Training loss: 0.10072139650583267
Validation loss: 1.5484617140985304

Epoch: 5| Step: 4
Training loss: 0.10481248050928116
Validation loss: 1.5800147902580999

Epoch: 5| Step: 5
Training loss: 0.07062302529811859
Validation loss: 1.5655684125038885

Epoch: 5| Step: 6
Training loss: 0.09180168062448502
Validation loss: 1.5613043256985244

Epoch: 5| Step: 7
Training loss: 0.058510251343250275
Validation loss: 1.5514385789953253

Epoch: 5| Step: 8
Training loss: 0.07569539546966553
Validation loss: 1.551719589899945

Epoch: 5| Step: 9
Training loss: 0.08201475441455841
Validation loss: 1.5616340201388124

Epoch: 5| Step: 10
Training loss: 0.12587271630764008
Validation loss: 1.573390576147264

Epoch: 524| Step: 0
Training loss: 0.09785718470811844
Validation loss: 1.5120297772910005

Epoch: 5| Step: 1
Training loss: 0.08897854387760162
Validation loss: 1.5313674852412233

Epoch: 5| Step: 2
Training loss: 0.13157585263252258
Validation loss: 1.5163647051780456

Epoch: 5| Step: 3
Training loss: 0.10400595515966415
Validation loss: 1.5479734700213197

Epoch: 5| Step: 4
Training loss: 0.16759271919727325
Validation loss: 1.5534697912072624

Epoch: 5| Step: 5
Training loss: 0.12940683960914612
Validation loss: 1.5805008667771534

Epoch: 5| Step: 6
Training loss: 0.08321307599544525
Validation loss: 1.579551386576827

Epoch: 5| Step: 7
Training loss: 0.050540268421173096
Validation loss: 1.6374351773210751

Epoch: 5| Step: 8
Training loss: 0.07203489542007446
Validation loss: 1.6072942274872974

Epoch: 5| Step: 9
Training loss: 0.06968390196561813
Validation loss: 1.6016965578961115

Epoch: 5| Step: 10
Training loss: 0.11705392599105835
Validation loss: 1.5998776869107318

Epoch: 525| Step: 0
Training loss: 0.095024973154068
Validation loss: 1.6162914999069706

Epoch: 5| Step: 1
Training loss: 0.11975221335887909
Validation loss: 1.590362492428031

Epoch: 5| Step: 2
Training loss: 0.08371736109256744
Validation loss: 1.6253064717015913

Epoch: 5| Step: 3
Training loss: 0.1080157533288002
Validation loss: 1.6130014542610414

Epoch: 5| Step: 4
Training loss: 0.10351073741912842
Validation loss: 1.6215390659147693

Epoch: 5| Step: 5
Training loss: 0.07961950451135635
Validation loss: 1.602930853443761

Epoch: 5| Step: 6
Training loss: 0.06090952828526497
Validation loss: 1.6281623737786406

Epoch: 5| Step: 7
Training loss: 0.06798197329044342
Validation loss: 1.5678026086540633

Epoch: 5| Step: 8
Training loss: 0.08849543333053589
Validation loss: 1.5711340929872246

Epoch: 5| Step: 9
Training loss: 0.0749536007642746
Validation loss: 1.573023183371431

Epoch: 5| Step: 10
Training loss: 0.05762096121907234
Validation loss: 1.562673891744306

Epoch: 526| Step: 0
Training loss: 0.0669441968202591
Validation loss: 1.5744153145820863

Epoch: 5| Step: 1
Training loss: 0.08168903738260269
Validation loss: 1.5639202678075401

Epoch: 5| Step: 2
Training loss: 0.14259283244609833
Validation loss: 1.5486454950865878

Epoch: 5| Step: 3
Training loss: 0.0774330347776413
Validation loss: 1.5332019559798702

Epoch: 5| Step: 4
Training loss: 0.05811415985226631
Validation loss: 1.5511270620489632

Epoch: 5| Step: 5
Training loss: 0.09187744557857513
Validation loss: 1.5539394027443343

Epoch: 5| Step: 6
Training loss: 0.1124221682548523
Validation loss: 1.5642871831053047

Epoch: 5| Step: 7
Training loss: 0.0759514793753624
Validation loss: 1.5806733382645475

Epoch: 5| Step: 8
Training loss: 0.0936364009976387
Validation loss: 1.5755024558754378

Epoch: 5| Step: 9
Training loss: 0.1112038865685463
Validation loss: 1.5560416598473825

Epoch: 5| Step: 10
Training loss: 0.1346789300441742
Validation loss: 1.5883368253707886

Epoch: 527| Step: 0
Training loss: 0.06346140056848526
Validation loss: 1.5644934023580244

Epoch: 5| Step: 1
Training loss: 0.10096939653158188
Validation loss: 1.5530454958638837

Epoch: 5| Step: 2
Training loss: 0.08149584382772446
Validation loss: 1.530275644794587

Epoch: 5| Step: 3
Training loss: 0.06600870937108994
Validation loss: 1.5659586409086823

Epoch: 5| Step: 4
Training loss: 0.06926757097244263
Validation loss: 1.5281662300068846

Epoch: 5| Step: 5
Training loss: 0.12280642986297607
Validation loss: 1.5246477652621526

Epoch: 5| Step: 6
Training loss: 0.12347906827926636
Validation loss: 1.5394338471915132

Epoch: 5| Step: 7
Training loss: 0.06995104253292084
Validation loss: 1.5195778723685973

Epoch: 5| Step: 8
Training loss: 0.07823099195957184
Validation loss: 1.5396745692017257

Epoch: 5| Step: 9
Training loss: 0.09543873369693756
Validation loss: 1.5541286904324767

Epoch: 5| Step: 10
Training loss: 0.15951694548130035
Validation loss: 1.566575232372489

Epoch: 528| Step: 0
Training loss: 0.09974197298288345
Validation loss: 1.5642162548598422

Epoch: 5| Step: 1
Training loss: 0.07109446823596954
Validation loss: 1.5702793303356375

Epoch: 5| Step: 2
Training loss: 0.10967622697353363
Validation loss: 1.573090918602482

Epoch: 5| Step: 3
Training loss: 0.09565744549036026
Validation loss: 1.550141885716428

Epoch: 5| Step: 4
Training loss: 0.1187141090631485
Validation loss: 1.5578035314877827

Epoch: 5| Step: 5
Training loss: 0.07418296486139297
Validation loss: 1.565396785736084

Epoch: 5| Step: 6
Training loss: 0.08012170344591141
Validation loss: 1.5623652614572996

Epoch: 5| Step: 7
Training loss: 0.1282740831375122
Validation loss: 1.5445394362172773

Epoch: 5| Step: 8
Training loss: 0.08507396280765533
Validation loss: 1.5614942017421927

Epoch: 5| Step: 9
Training loss: 0.07104115933179855
Validation loss: 1.57496771120256

Epoch: 5| Step: 10
Training loss: 0.11919096112251282
Validation loss: 1.5713419311790056

Epoch: 529| Step: 0
Training loss: 0.09141602367162704
Validation loss: 1.562101702536306

Epoch: 5| Step: 1
Training loss: 0.11830904334783554
Validation loss: 1.5488381155075566

Epoch: 5| Step: 2
Training loss: 0.07348640263080597
Validation loss: 1.5580384282655613

Epoch: 5| Step: 3
Training loss: 0.09223167598247528
Validation loss: 1.577280172737696

Epoch: 5| Step: 4
Training loss: 0.08048246800899506
Validation loss: 1.5648408538551741

Epoch: 5| Step: 5
Training loss: 0.09663142263889313
Validation loss: 1.5874367388345862

Epoch: 5| Step: 6
Training loss: 0.09710759669542313
Validation loss: 1.5776503746227553

Epoch: 5| Step: 7
Training loss: 0.06636007130146027
Validation loss: 1.5952899225296513

Epoch: 5| Step: 8
Training loss: 0.10811556875705719
Validation loss: 1.5961416536761868

Epoch: 5| Step: 9
Training loss: 0.09417189657688141
Validation loss: 1.5951712541682745

Epoch: 5| Step: 10
Training loss: 0.07749861478805542
Validation loss: 1.5689927275462816

Epoch: 530| Step: 0
Training loss: 0.08732627332210541
Validation loss: 1.6122871727071784

Epoch: 5| Step: 1
Training loss: 0.13357806205749512
Validation loss: 1.5839807833394697

Epoch: 5| Step: 2
Training loss: 0.07154156267642975
Validation loss: 1.604196527952789

Epoch: 5| Step: 3
Training loss: 0.08591697365045547
Validation loss: 1.5665346601957917

Epoch: 5| Step: 4
Training loss: 0.06556820124387741
Validation loss: 1.584628257700192

Epoch: 5| Step: 5
Training loss: 0.07792775332927704
Validation loss: 1.5923183124552491

Epoch: 5| Step: 6
Training loss: 0.08595461398363113
Validation loss: 1.5941351165053665

Epoch: 5| Step: 7
Training loss: 0.07245993614196777
Validation loss: 1.6174240599396408

Epoch: 5| Step: 8
Training loss: 0.07276275008916855
Validation loss: 1.6156748033338977

Epoch: 5| Step: 9
Training loss: 0.07920543104410172
Validation loss: 1.6235432105679666

Epoch: 5| Step: 10
Training loss: 0.14314542710781097
Validation loss: 1.600644282115403

Epoch: 531| Step: 0
Training loss: 0.1302465796470642
Validation loss: 1.6127482293754496

Epoch: 5| Step: 1
Training loss: 0.05207647755742073
Validation loss: 1.6016184758114558

Epoch: 5| Step: 2
Training loss: 0.11091990768909454
Validation loss: 1.62215127611673

Epoch: 5| Step: 3
Training loss: 0.11361999809741974
Validation loss: 1.652097757144641

Epoch: 5| Step: 4
Training loss: 0.09410638362169266
Validation loss: 1.635616986982284

Epoch: 5| Step: 5
Training loss: 0.04718396067619324
Validation loss: 1.6313784507013136

Epoch: 5| Step: 6
Training loss: 0.13230273127555847
Validation loss: 1.6132397100489626

Epoch: 5| Step: 7
Training loss: 0.07628212869167328
Validation loss: 1.612991956613397

Epoch: 5| Step: 8
Training loss: 0.07448752969503403
Validation loss: 1.5980649507173927

Epoch: 5| Step: 9
Training loss: 0.09916869550943375
Validation loss: 1.6281424158362932

Epoch: 5| Step: 10
Training loss: 0.06564546376466751
Validation loss: 1.5921778460984588

Epoch: 532| Step: 0
Training loss: 0.09078211337327957
Validation loss: 1.6058894511192077

Epoch: 5| Step: 1
Training loss: 0.08697645366191864
Validation loss: 1.600896131607794

Epoch: 5| Step: 2
Training loss: 0.062170885503292084
Validation loss: 1.5980301236593595

Epoch: 5| Step: 3
Training loss: 0.09473705291748047
Validation loss: 1.5850220393109065

Epoch: 5| Step: 4
Training loss: 0.1025838851928711
Validation loss: 1.5528669408572617

Epoch: 5| Step: 5
Training loss: 0.11304537951946259
Validation loss: 1.5528790329092292

Epoch: 5| Step: 6
Training loss: 0.10699055343866348
Validation loss: 1.5875048252844042

Epoch: 5| Step: 7
Training loss: 0.09035937488079071
Validation loss: 1.5640566169574697

Epoch: 5| Step: 8
Training loss: 0.08709698170423508
Validation loss: 1.5559356366434405

Epoch: 5| Step: 9
Training loss: 0.14813010394573212
Validation loss: 1.5100740873685448

Epoch: 5| Step: 10
Training loss: 0.06805259734392166
Validation loss: 1.5738512751876668

Epoch: 533| Step: 0
Training loss: 0.12238230556249619
Validation loss: 1.59340932420505

Epoch: 5| Step: 1
Training loss: 0.060962386429309845
Validation loss: 1.5799539102021085

Epoch: 5| Step: 2
Training loss: 0.0892559364438057
Validation loss: 1.600037173558307

Epoch: 5| Step: 3
Training loss: 0.10256098210811615
Validation loss: 1.578937477962945

Epoch: 5| Step: 4
Training loss: 0.1213379055261612
Validation loss: 1.6068216575089322

Epoch: 5| Step: 5
Training loss: 0.09775596857070923
Validation loss: 1.6041840635320193

Epoch: 5| Step: 6
Training loss: 0.10269279778003693
Validation loss: 1.5533603275975874

Epoch: 5| Step: 7
Training loss: 0.10328660905361176
Validation loss: 1.5993123541596115

Epoch: 5| Step: 8
Training loss: 0.0706249326467514
Validation loss: 1.5671916764269593

Epoch: 5| Step: 9
Training loss: 0.1598246991634369
Validation loss: 1.553570084674384

Epoch: 5| Step: 10
Training loss: 0.08898502588272095
Validation loss: 1.5664529095413864

Epoch: 534| Step: 0
Training loss: 0.15237955749034882
Validation loss: 1.575034777323405

Epoch: 5| Step: 1
Training loss: 0.0840798020362854
Validation loss: 1.5554892196450183

Epoch: 5| Step: 2
Training loss: 0.07686793804168701
Validation loss: 1.5547540341654131

Epoch: 5| Step: 3
Training loss: 0.06510599702596664
Validation loss: 1.5785459369741461

Epoch: 5| Step: 4
Training loss: 0.06213383749127388
Validation loss: 1.5494266120336389

Epoch: 5| Step: 5
Training loss: 0.04893060773611069
Validation loss: 1.5744815065014748

Epoch: 5| Step: 6
Training loss: 0.11256861686706543
Validation loss: 1.5791250877482916

Epoch: 5| Step: 7
Training loss: 0.054006993770599365
Validation loss: 1.597484859087134

Epoch: 5| Step: 8
Training loss: 0.08118584007024765
Validation loss: 1.5642702476952666

Epoch: 5| Step: 9
Training loss: 0.07287748903036118
Validation loss: 1.5648140727832753

Epoch: 5| Step: 10
Training loss: 0.0818026214838028
Validation loss: 1.561826249604584

Epoch: 535| Step: 0
Training loss: 0.11288414150476456
Validation loss: 1.5667912049960064

Epoch: 5| Step: 1
Training loss: 0.06706695258617401
Validation loss: 1.5557935865976478

Epoch: 5| Step: 2
Training loss: 0.0739670842885971
Validation loss: 1.5459855384724115

Epoch: 5| Step: 3
Training loss: 0.0762484222650528
Validation loss: 1.5541565290061377

Epoch: 5| Step: 4
Training loss: 0.06333806365728378
Validation loss: 1.5875874309129612

Epoch: 5| Step: 5
Training loss: 0.13723133504390717
Validation loss: 1.5779305824669458

Epoch: 5| Step: 6
Training loss: 0.1061515063047409
Validation loss: 1.6102822224299114

Epoch: 5| Step: 7
Training loss: 0.09161534905433655
Validation loss: 1.61375904275525

Epoch: 5| Step: 8
Training loss: 0.10546599328517914
Validation loss: 1.616977619868453

Epoch: 5| Step: 9
Training loss: 0.12854282557964325
Validation loss: 1.6330489304757887

Epoch: 5| Step: 10
Training loss: 0.06371883302927017
Validation loss: 1.6096728988873061

Epoch: 536| Step: 0
Training loss: 0.1114407405257225
Validation loss: 1.626969842500584

Epoch: 5| Step: 1
Training loss: 0.08846571296453476
Validation loss: 1.6465011976098503

Epoch: 5| Step: 2
Training loss: 0.11461365222930908
Validation loss: 1.6070102401958999

Epoch: 5| Step: 3
Training loss: 0.09792432934045792
Validation loss: 1.5599333060685026

Epoch: 5| Step: 4
Training loss: 0.07206235826015472
Validation loss: 1.5685841627018426

Epoch: 5| Step: 5
Training loss: 0.16056673228740692
Validation loss: 1.5328238138588526

Epoch: 5| Step: 6
Training loss: 0.13247227668762207
Validation loss: 1.5323301361453148

Epoch: 5| Step: 7
Training loss: 0.18616174161434174
Validation loss: 1.5128841130964217

Epoch: 5| Step: 8
Training loss: 0.09204649925231934
Validation loss: 1.5153310337374288

Epoch: 5| Step: 9
Training loss: 0.08022892475128174
Validation loss: 1.534540186646164

Epoch: 5| Step: 10
Training loss: 0.09677277505397797
Validation loss: 1.5450525617086759

Epoch: 537| Step: 0
Training loss: 0.10219025611877441
Validation loss: 1.580965832997394

Epoch: 5| Step: 1
Training loss: 0.09858836978673935
Validation loss: 1.6068659802918792

Epoch: 5| Step: 2
Training loss: 0.08472426235675812
Validation loss: 1.5852583044318742

Epoch: 5| Step: 3
Training loss: 0.10307589918375015
Validation loss: 1.5863345220524778

Epoch: 5| Step: 4
Training loss: 0.0720088928937912
Validation loss: 1.582834723175213

Epoch: 5| Step: 5
Training loss: 0.09498896449804306
Validation loss: 1.5781036532053383

Epoch: 5| Step: 6
Training loss: 0.16298405826091766
Validation loss: 1.5925123704377042

Epoch: 5| Step: 7
Training loss: 0.1072010025382042
Validation loss: 1.570916170715004

Epoch: 5| Step: 8
Training loss: 0.08838619291782379
Validation loss: 1.5439120524673051

Epoch: 5| Step: 9
Training loss: 0.09073075652122498
Validation loss: 1.5568853296259397

Epoch: 5| Step: 10
Training loss: 0.08466294407844543
Validation loss: 1.5206340333466888

Epoch: 538| Step: 0
Training loss: 0.12729229032993317
Validation loss: 1.5444955095168083

Epoch: 5| Step: 1
Training loss: 0.03369157016277313
Validation loss: 1.5558606091366018

Epoch: 5| Step: 2
Training loss: 0.09963123500347137
Validation loss: 1.532525816271382

Epoch: 5| Step: 3
Training loss: 0.10137492418289185
Validation loss: 1.5538981473574074

Epoch: 5| Step: 4
Training loss: 0.08753713220357895
Validation loss: 1.5634515093218895

Epoch: 5| Step: 5
Training loss: 0.06123778223991394
Validation loss: 1.541151713299495

Epoch: 5| Step: 6
Training loss: 0.08484246581792831
Validation loss: 1.5948645940390966

Epoch: 5| Step: 7
Training loss: 0.059705864638090134
Validation loss: 1.6095829650919924

Epoch: 5| Step: 8
Training loss: 0.14048556983470917
Validation loss: 1.5696196812455372

Epoch: 5| Step: 9
Training loss: 0.057500988245010376
Validation loss: 1.5820256330633675

Epoch: 5| Step: 10
Training loss: 0.07993821054697037
Validation loss: 1.574974145940555

Epoch: 539| Step: 0
Training loss: 0.05499463528394699
Validation loss: 1.5750910787172214

Epoch: 5| Step: 1
Training loss: 0.08168463408946991
Validation loss: 1.5506198624128937

Epoch: 5| Step: 2
Training loss: 0.12024452537298203
Validation loss: 1.5771305317519813

Epoch: 5| Step: 3
Training loss: 0.11785547435283661
Validation loss: 1.547714610253611

Epoch: 5| Step: 4
Training loss: 0.06714743375778198
Validation loss: 1.557127664166112

Epoch: 5| Step: 5
Training loss: 0.11586389690637589
Validation loss: 1.573476819581883

Epoch: 5| Step: 6
Training loss: 0.10943450033664703
Validation loss: 1.5583130377595142

Epoch: 5| Step: 7
Training loss: 0.06836799532175064
Validation loss: 1.5371210908377042

Epoch: 5| Step: 8
Training loss: 0.09304579347372055
Validation loss: 1.5317779894798034

Epoch: 5| Step: 9
Training loss: 0.09059039503335953
Validation loss: 1.5328354515055174

Epoch: 5| Step: 10
Training loss: 0.07487272471189499
Validation loss: 1.565182670470207

Epoch: 540| Step: 0
Training loss: 0.047121115028858185
Validation loss: 1.536148295607618

Epoch: 5| Step: 1
Training loss: 0.06891830265522003
Validation loss: 1.5397157079430037

Epoch: 5| Step: 2
Training loss: 0.06457407772541046
Validation loss: 1.5485557997098534

Epoch: 5| Step: 3
Training loss: 0.1098489984869957
Validation loss: 1.546629048162891

Epoch: 5| Step: 4
Training loss: 0.0852624699473381
Validation loss: 1.548190644992295

Epoch: 5| Step: 5
Training loss: 0.09533438831567764
Validation loss: 1.5495982958424477

Epoch: 5| Step: 6
Training loss: 0.08713585138320923
Validation loss: 1.5533699143317439

Epoch: 5| Step: 7
Training loss: 0.10211030393838882
Validation loss: 1.5544174794227845

Epoch: 5| Step: 8
Training loss: 0.08559980988502502
Validation loss: 1.5603058491983721

Epoch: 5| Step: 9
Training loss: 0.07162238657474518
Validation loss: 1.5305444437970397

Epoch: 5| Step: 10
Training loss: 0.07764028012752533
Validation loss: 1.562823256497742

Epoch: 541| Step: 0
Training loss: 0.0487242229282856
Validation loss: 1.5845324352223387

Epoch: 5| Step: 1
Training loss: 0.09405975788831711
Validation loss: 1.5747406989015558

Epoch: 5| Step: 2
Training loss: 0.07004392147064209
Validation loss: 1.5571608812578264

Epoch: 5| Step: 3
Training loss: 0.1201772689819336
Validation loss: 1.5465697409004293

Epoch: 5| Step: 4
Training loss: 0.10285862535238266
Validation loss: 1.562335366843849

Epoch: 5| Step: 5
Training loss: 0.12918353080749512
Validation loss: 1.5280886632139965

Epoch: 5| Step: 6
Training loss: 0.1039501428604126
Validation loss: 1.5158197911836768

Epoch: 5| Step: 7
Training loss: 0.0831853523850441
Validation loss: 1.5367156126165902

Epoch: 5| Step: 8
Training loss: 0.08353842794895172
Validation loss: 1.5375704573046776

Epoch: 5| Step: 9
Training loss: 0.06683016568422318
Validation loss: 1.5423168443864392

Epoch: 5| Step: 10
Training loss: 0.05820970609784126
Validation loss: 1.5639856784574446

Epoch: 542| Step: 0
Training loss: 0.08509471267461777
Validation loss: 1.5412866492425241

Epoch: 5| Step: 1
Training loss: 0.07191172242164612
Validation loss: 1.565449450605659

Epoch: 5| Step: 2
Training loss: 0.14528925716876984
Validation loss: 1.5884109979034753

Epoch: 5| Step: 3
Training loss: 0.07136472314596176
Validation loss: 1.5782806565684657

Epoch: 5| Step: 4
Training loss: 0.10319308191537857
Validation loss: 1.574507591544941

Epoch: 5| Step: 5
Training loss: 0.07325384020805359
Validation loss: 1.6011553079851213

Epoch: 5| Step: 6
Training loss: 0.09224607795476913
Validation loss: 1.5843738894308768

Epoch: 5| Step: 7
Training loss: 0.08103316277265549
Validation loss: 1.5770158959973244

Epoch: 5| Step: 8
Training loss: 0.06432698667049408
Validation loss: 1.5854016529616488

Epoch: 5| Step: 9
Training loss: 0.09917750209569931
Validation loss: 1.589326350919662

Epoch: 5| Step: 10
Training loss: 0.08463003486394882
Validation loss: 1.5968030114327707

Epoch: 543| Step: 0
Training loss: 0.06426388025283813
Validation loss: 1.6052167979619836

Epoch: 5| Step: 1
Training loss: 0.05421258136630058
Validation loss: 1.5761301773850636

Epoch: 5| Step: 2
Training loss: 0.11710610240697861
Validation loss: 1.5965387359742196

Epoch: 5| Step: 3
Training loss: 0.05326259136199951
Validation loss: 1.5650096324182325

Epoch: 5| Step: 4
Training loss: 0.05744980648159981
Validation loss: 1.5902810635105256

Epoch: 5| Step: 5
Training loss: 0.06303370743989944
Validation loss: 1.5994999177994267

Epoch: 5| Step: 6
Training loss: 0.12988874316215515
Validation loss: 1.586052115245532

Epoch: 5| Step: 7
Training loss: 0.06716559827327728
Validation loss: 1.5769288232249599

Epoch: 5| Step: 8
Training loss: 0.08677639067173004
Validation loss: 1.5781743334185692

Epoch: 5| Step: 9
Training loss: 0.11888018995523453
Validation loss: 1.5481568933815084

Epoch: 5| Step: 10
Training loss: 0.056635066866874695
Validation loss: 1.545092982630576

Epoch: 544| Step: 0
Training loss: 0.08875904232263565
Validation loss: 1.5820872053023307

Epoch: 5| Step: 1
Training loss: 0.06330610066652298
Validation loss: 1.587979269284074

Epoch: 5| Step: 2
Training loss: 0.09326781332492828
Validation loss: 1.5656372013912405

Epoch: 5| Step: 3
Training loss: 0.08370561897754669
Validation loss: 1.5845944464847606

Epoch: 5| Step: 4
Training loss: 0.11804632842540741
Validation loss: 1.587590176572082

Epoch: 5| Step: 5
Training loss: 0.10077349841594696
Validation loss: 1.622832211115027

Epoch: 5| Step: 6
Training loss: 0.09363038837909698
Validation loss: 1.6130766868591309

Epoch: 5| Step: 7
Training loss: 0.06937900930643082
Validation loss: 1.601017657146659

Epoch: 5| Step: 8
Training loss: 0.10619910061359406
Validation loss: 1.594307509801721

Epoch: 5| Step: 9
Training loss: 0.06625546514987946
Validation loss: 1.5662736354335662

Epoch: 5| Step: 10
Training loss: 0.0884561762213707
Validation loss: 1.5796666568325413

Epoch: 545| Step: 0
Training loss: 0.11830152571201324
Validation loss: 1.5580585618172922

Epoch: 5| Step: 1
Training loss: 0.10899815708398819
Validation loss: 1.5504668617761264

Epoch: 5| Step: 2
Training loss: 0.08567489683628082
Validation loss: 1.559943611262947

Epoch: 5| Step: 3
Training loss: 0.060503553599119186
Validation loss: 1.5834686474133564

Epoch: 5| Step: 4
Training loss: 0.08331295102834702
Validation loss: 1.5809898812283751

Epoch: 5| Step: 5
Training loss: 0.16270090639591217
Validation loss: 1.5582934528268793

Epoch: 5| Step: 6
Training loss: 0.0886387750506401
Validation loss: 1.614636613476661

Epoch: 5| Step: 7
Training loss: 0.09734603762626648
Validation loss: 1.5800399652091406

Epoch: 5| Step: 8
Training loss: 0.10344837605953217
Validation loss: 1.5743149403602845

Epoch: 5| Step: 9
Training loss: 0.08367641270160675
Validation loss: 1.5784462946717457

Epoch: 5| Step: 10
Training loss: 0.0897734984755516
Validation loss: 1.5172119999444613

Epoch: 546| Step: 0
Training loss: 0.03185850381851196
Validation loss: 1.5711401354882024

Epoch: 5| Step: 1
Training loss: 0.06005377694964409
Validation loss: 1.547691846406588

Epoch: 5| Step: 2
Training loss: 0.05504195764660835
Validation loss: 1.548996945863129

Epoch: 5| Step: 3
Training loss: 0.10181429237127304
Validation loss: 1.5549500065465127

Epoch: 5| Step: 4
Training loss: 0.08271145075559616
Validation loss: 1.5700436997157272

Epoch: 5| Step: 5
Training loss: 0.09154792875051498
Validation loss: 1.5700993307175175

Epoch: 5| Step: 6
Training loss: 0.0892794281244278
Validation loss: 1.5627702596367046

Epoch: 5| Step: 7
Training loss: 0.07853905111551285
Validation loss: 1.5785373833871656

Epoch: 5| Step: 8
Training loss: 0.06567023694515228
Validation loss: 1.5690055380585373

Epoch: 5| Step: 9
Training loss: 0.07327914237976074
Validation loss: 1.5708846148624216

Epoch: 5| Step: 10
Training loss: 0.12548768520355225
Validation loss: 1.6071195897235666

Epoch: 547| Step: 0
Training loss: 0.08987301588058472
Validation loss: 1.6028726152194444

Epoch: 5| Step: 1
Training loss: 0.0565529391169548
Validation loss: 1.5932381524834582

Epoch: 5| Step: 2
Training loss: 0.10775518417358398
Validation loss: 1.5884466517356135

Epoch: 5| Step: 3
Training loss: 0.07843978703022003
Validation loss: 1.5806350951553674

Epoch: 5| Step: 4
Training loss: 0.09231998771429062
Validation loss: 1.5864229702180432

Epoch: 5| Step: 5
Training loss: 0.10318348556756973
Validation loss: 1.5723152904100315

Epoch: 5| Step: 6
Training loss: 0.10820452868938446
Validation loss: 1.5904509252117527

Epoch: 5| Step: 7
Training loss: 0.15642376244068146
Validation loss: 1.60163317700868

Epoch: 5| Step: 8
Training loss: 0.09814740717411041
Validation loss: 1.5805705516569075

Epoch: 5| Step: 9
Training loss: 0.09529663622379303
Validation loss: 1.5747174524491834

Epoch: 5| Step: 10
Training loss: 0.0774044394493103
Validation loss: 1.575006990663467

Epoch: 548| Step: 0
Training loss: 0.06705297529697418
Validation loss: 1.5738526210990003

Epoch: 5| Step: 1
Training loss: 0.060480616986751556
Validation loss: 1.5737843090488064

Epoch: 5| Step: 2
Training loss: 0.09243126213550568
Validation loss: 1.5667005636358773

Epoch: 5| Step: 3
Training loss: 0.16201287508010864
Validation loss: 1.6022340379735476

Epoch: 5| Step: 4
Training loss: 0.07666216045618057
Validation loss: 1.5522528656067387

Epoch: 5| Step: 5
Training loss: 0.11857287585735321
Validation loss: 1.5690758638484503

Epoch: 5| Step: 6
Training loss: 0.07662007212638855
Validation loss: 1.5775333309686312

Epoch: 5| Step: 7
Training loss: 0.18610690534114838
Validation loss: 1.5707588426528438

Epoch: 5| Step: 8
Training loss: 0.17607331275939941
Validation loss: 1.5879607110895135

Epoch: 5| Step: 9
Training loss: 0.17610932886600494
Validation loss: 1.6054608411686395

Epoch: 5| Step: 10
Training loss: 0.09025464206933975
Validation loss: 1.6139320891390565

Epoch: 549| Step: 0
Training loss: 0.08876533061265945
Validation loss: 1.6190882139308478

Epoch: 5| Step: 1
Training loss: 0.12839409708976746
Validation loss: 1.6055974024598316

Epoch: 5| Step: 2
Training loss: 0.09584146738052368
Validation loss: 1.638286534176078

Epoch: 5| Step: 3
Training loss: 0.1597099006175995
Validation loss: 1.662819831602035

Epoch: 5| Step: 4
Training loss: 0.0937628448009491
Validation loss: 1.6097624173728369

Epoch: 5| Step: 5
Training loss: 0.10605408996343613
Validation loss: 1.585482835128743

Epoch: 5| Step: 6
Training loss: 0.0667964369058609
Validation loss: 1.5661873843080254

Epoch: 5| Step: 7
Training loss: 0.10333941131830215
Validation loss: 1.5761523150628614

Epoch: 5| Step: 8
Training loss: 0.11267751455307007
Validation loss: 1.5622405159857966

Epoch: 5| Step: 9
Training loss: 0.05242022126913071
Validation loss: 1.551526229868653

Epoch: 5| Step: 10
Training loss: 0.1133178249001503
Validation loss: 1.5485865140473971

Epoch: 550| Step: 0
Training loss: 0.09151698648929596
Validation loss: 1.5766155283938172

Epoch: 5| Step: 1
Training loss: 0.10030747950077057
Validation loss: 1.5643434088717225

Epoch: 5| Step: 2
Training loss: 0.1385166347026825
Validation loss: 1.574104993574081

Epoch: 5| Step: 3
Training loss: 0.15374340116977692
Validation loss: 1.5694001989979898

Epoch: 5| Step: 4
Training loss: 0.12680771946907043
Validation loss: 1.5957889954249065

Epoch: 5| Step: 5
Training loss: 0.06527536362409592
Validation loss: 1.5837614036375476

Epoch: 5| Step: 6
Training loss: 0.08783723413944244
Validation loss: 1.6074228004742694

Epoch: 5| Step: 7
Training loss: 0.14831210672855377
Validation loss: 1.5979783663185694

Epoch: 5| Step: 8
Training loss: 0.08124757558107376
Validation loss: 1.5786513372134137

Epoch: 5| Step: 9
Training loss: 0.06937400251626968
Validation loss: 1.6096295669514646

Epoch: 5| Step: 10
Training loss: 0.08593159168958664
Validation loss: 1.60096001496879

Epoch: 551| Step: 0
Training loss: 0.0792502760887146
Validation loss: 1.5874177230301725

Epoch: 5| Step: 1
Training loss: 0.0716044157743454
Validation loss: 1.591512119898232

Epoch: 5| Step: 2
Training loss: 0.08918063342571259
Validation loss: 1.5854157183759956

Epoch: 5| Step: 3
Training loss: 0.05827595666050911
Validation loss: 1.5747814498921877

Epoch: 5| Step: 4
Training loss: 0.11300303041934967
Validation loss: 1.5793505195648438

Epoch: 5| Step: 5
Training loss: 0.11940983682870865
Validation loss: 1.6024784785445019

Epoch: 5| Step: 6
Training loss: 0.08233393728733063
Validation loss: 1.5726487149474442

Epoch: 5| Step: 7
Training loss: 0.06020176410675049
Validation loss: 1.59332428696335

Epoch: 5| Step: 8
Training loss: 0.07817378640174866
Validation loss: 1.5418213746880973

Epoch: 5| Step: 9
Training loss: 0.053222380578517914
Validation loss: 1.5788521830753615

Epoch: 5| Step: 10
Training loss: 0.1188458800315857
Validation loss: 1.5931593051520727

Epoch: 552| Step: 0
Training loss: 0.1109718307852745
Validation loss: 1.5852426937831345

Epoch: 5| Step: 1
Training loss: 0.09175623953342438
Validation loss: 1.581410918184506

Epoch: 5| Step: 2
Training loss: 0.1492392122745514
Validation loss: 1.5767765352802892

Epoch: 5| Step: 3
Training loss: 0.08007705211639404
Validation loss: 1.5962136804416616

Epoch: 5| Step: 4
Training loss: 0.06250841915607452
Validation loss: 1.620375717839887

Epoch: 5| Step: 5
Training loss: 0.09486817568540573
Validation loss: 1.6236823797225952

Epoch: 5| Step: 6
Training loss: 0.10316121578216553
Validation loss: 1.6407383770071051

Epoch: 5| Step: 7
Training loss: 0.05087796971201897
Validation loss: 1.6569104092095488

Epoch: 5| Step: 8
Training loss: 0.05447588115930557
Validation loss: 1.6549063594110551

Epoch: 5| Step: 9
Training loss: 0.06955771148204803
Validation loss: 1.6068738686141146

Epoch: 5| Step: 10
Training loss: 0.08578956872224808
Validation loss: 1.6311972602721183

Epoch: 553| Step: 0
Training loss: 0.06516222655773163
Validation loss: 1.5995131333669026

Epoch: 5| Step: 1
Training loss: 0.0658314973115921
Validation loss: 1.6231819096431936

Epoch: 5| Step: 2
Training loss: 0.11404915899038315
Validation loss: 1.5823946678510277

Epoch: 5| Step: 3
Training loss: 0.09906017035245895
Validation loss: 1.6049194912756644

Epoch: 5| Step: 4
Training loss: 0.05270998552441597
Validation loss: 1.5849773576182704

Epoch: 5| Step: 5
Training loss: 0.1053043007850647
Validation loss: 1.5943770549630607

Epoch: 5| Step: 6
Training loss: 0.09134544432163239
Validation loss: 1.6095320947708622

Epoch: 5| Step: 7
Training loss: 0.05680154636502266
Validation loss: 1.5700461902926046

Epoch: 5| Step: 8
Training loss: 0.07429073750972748
Validation loss: 1.5680357435698151

Epoch: 5| Step: 9
Training loss: 0.09977037459611893
Validation loss: 1.6184348854967343

Epoch: 5| Step: 10
Training loss: 0.09200584143400192
Validation loss: 1.6211908735254759

Epoch: 554| Step: 0
Training loss: 0.08411511778831482
Validation loss: 1.6237715405802573

Epoch: 5| Step: 1
Training loss: 0.14257624745368958
Validation loss: 1.5791407836380826

Epoch: 5| Step: 2
Training loss: 0.14383570849895477
Validation loss: 1.5488150247963526

Epoch: 5| Step: 3
Training loss: 0.04665733501315117
Validation loss: 1.5481443405151367

Epoch: 5| Step: 4
Training loss: 0.09338229894638062
Validation loss: 1.5453923568930676

Epoch: 5| Step: 5
Training loss: 0.140919491648674
Validation loss: 1.5091348655762211

Epoch: 5| Step: 6
Training loss: 0.1098335012793541
Validation loss: 1.5316051193462905

Epoch: 5| Step: 7
Training loss: 0.11022771894931793
Validation loss: 1.5675210811758553

Epoch: 5| Step: 8
Training loss: 0.07874244451522827
Validation loss: 1.5582226284088627

Epoch: 5| Step: 9
Training loss: 0.11666162312030792
Validation loss: 1.5953124364217122

Epoch: 5| Step: 10
Training loss: 0.11128070205450058
Validation loss: 1.5960868340666576

Epoch: 555| Step: 0
Training loss: 0.18197157979011536
Validation loss: 1.6091423342304845

Epoch: 5| Step: 1
Training loss: 0.09091299772262573
Validation loss: 1.5986344557936474

Epoch: 5| Step: 2
Training loss: 0.09134649485349655
Validation loss: 1.6067413489023845

Epoch: 5| Step: 3
Training loss: 0.06295289844274521
Validation loss: 1.6336949666341145

Epoch: 5| Step: 4
Training loss: 0.05565708130598068
Validation loss: 1.5799871727984438

Epoch: 5| Step: 5
Training loss: 0.0758737325668335
Validation loss: 1.5956744045339606

Epoch: 5| Step: 6
Training loss: 0.1063142791390419
Validation loss: 1.5395776507675007

Epoch: 5| Step: 7
Training loss: 0.1276969164609909
Validation loss: 1.567159188691006

Epoch: 5| Step: 8
Training loss: 0.17083868384361267
Validation loss: 1.5533816558058544

Epoch: 5| Step: 9
Training loss: 0.0654481053352356
Validation loss: 1.54082735635901

Epoch: 5| Step: 10
Training loss: 0.07354623079299927
Validation loss: 1.5731217181810768

Epoch: 556| Step: 0
Training loss: 0.06942425668239594
Validation loss: 1.5636664667437155

Epoch: 5| Step: 1
Training loss: 0.14522945880889893
Validation loss: 1.5744383976023684

Epoch: 5| Step: 2
Training loss: 0.08600031584501266
Validation loss: 1.5630668247899702

Epoch: 5| Step: 3
Training loss: 0.07825557887554169
Validation loss: 1.5578941388796734

Epoch: 5| Step: 4
Training loss: 0.046563465148210526
Validation loss: 1.5577298293831527

Epoch: 5| Step: 5
Training loss: 0.07323716580867767
Validation loss: 1.5429348304707518

Epoch: 5| Step: 6
Training loss: 0.07820048928260803
Validation loss: 1.5478698252349772

Epoch: 5| Step: 7
Training loss: 0.07007097452878952
Validation loss: 1.5309213592160134

Epoch: 5| Step: 8
Training loss: 0.09665483236312866
Validation loss: 1.5609597993153397

Epoch: 5| Step: 9
Training loss: 0.13022124767303467
Validation loss: 1.5463981987327657

Epoch: 5| Step: 10
Training loss: 0.09997975081205368
Validation loss: 1.5531449471750567

Epoch: 557| Step: 0
Training loss: 0.04735469073057175
Validation loss: 1.5543913956611388

Epoch: 5| Step: 1
Training loss: 0.0788988322019577
Validation loss: 1.568695226023274

Epoch: 5| Step: 2
Training loss: 0.13064593076705933
Validation loss: 1.5359466588625343

Epoch: 5| Step: 3
Training loss: 0.1010802835226059
Validation loss: 1.5618341943269134

Epoch: 5| Step: 4
Training loss: 0.06399007886648178
Validation loss: 1.5566327520596084

Epoch: 5| Step: 5
Training loss: 0.11159749329090118
Validation loss: 1.5548761339597805

Epoch: 5| Step: 6
Training loss: 0.05809953063726425
Validation loss: 1.548698902130127

Epoch: 5| Step: 7
Training loss: 0.042460691183805466
Validation loss: 1.5485896025934527

Epoch: 5| Step: 8
Training loss: 0.07348670065402985
Validation loss: 1.5515470556033555

Epoch: 5| Step: 9
Training loss: 0.06670265644788742
Validation loss: 1.5235825411735042

Epoch: 5| Step: 10
Training loss: 0.09732979536056519
Validation loss: 1.523873467599192

Epoch: 558| Step: 0
Training loss: 0.05815434455871582
Validation loss: 1.5370404566487958

Epoch: 5| Step: 1
Training loss: 0.1458621323108673
Validation loss: 1.532800861584243

Epoch: 5| Step: 2
Training loss: 0.06393809616565704
Validation loss: 1.5241064666419901

Epoch: 5| Step: 3
Training loss: 0.06663664430379868
Validation loss: 1.5247686819363666

Epoch: 5| Step: 4
Training loss: 0.07894275337457657
Validation loss: 1.543705900510152

Epoch: 5| Step: 5
Training loss: 0.04996776580810547
Validation loss: 1.5712625121557584

Epoch: 5| Step: 6
Training loss: 0.06316206604242325
Validation loss: 1.5664779755377

Epoch: 5| Step: 7
Training loss: 0.06202344223856926
Validation loss: 1.5765854229209244

Epoch: 5| Step: 8
Training loss: 0.11470296233892441
Validation loss: 1.5992676070941392

Epoch: 5| Step: 9
Training loss: 0.11111346632242203
Validation loss: 1.6000528899572228

Epoch: 5| Step: 10
Training loss: 0.08506862819194794
Validation loss: 1.555081844329834

Epoch: 559| Step: 0
Training loss: 0.142243891954422
Validation loss: 1.5309491593350646

Epoch: 5| Step: 1
Training loss: 0.10038445889949799
Validation loss: 1.5651411958920058

Epoch: 5| Step: 2
Training loss: 0.09138500690460205
Validation loss: 1.5548833941900602

Epoch: 5| Step: 3
Training loss: 0.08065998554229736
Validation loss: 1.5637467497138566

Epoch: 5| Step: 4
Training loss: 0.12199661880731583
Validation loss: 1.5410061395296486

Epoch: 5| Step: 5
Training loss: 0.12454112619161606
Validation loss: 1.5597055599253664

Epoch: 5| Step: 6
Training loss: 0.07533986866474152
Validation loss: 1.5717187658432992

Epoch: 5| Step: 7
Training loss: 0.03200734779238701
Validation loss: 1.558354482855848

Epoch: 5| Step: 8
Training loss: 0.054644159972667694
Validation loss: 1.594438104219334

Epoch: 5| Step: 9
Training loss: 0.07536346465349197
Validation loss: 1.5985513746097524

Epoch: 5| Step: 10
Training loss: 0.0689503625035286
Validation loss: 1.5751037854020313

Epoch: 560| Step: 0
Training loss: 0.07136161625385284
Validation loss: 1.5675086295732887

Epoch: 5| Step: 1
Training loss: 0.09207197278738022
Validation loss: 1.5393359507283857

Epoch: 5| Step: 2
Training loss: 0.10569634288549423
Validation loss: 1.5710574862777547

Epoch: 5| Step: 3
Training loss: 0.10833760350942612
Validation loss: 1.5230606179083548

Epoch: 5| Step: 4
Training loss: 0.1133892759680748
Validation loss: 1.538189274008556

Epoch: 5| Step: 5
Training loss: 0.11487472057342529
Validation loss: 1.5178507604906637

Epoch: 5| Step: 6
Training loss: 0.09826189279556274
Validation loss: 1.5148253107583651

Epoch: 5| Step: 7
Training loss: 0.06745252013206482
Validation loss: 1.5381511090904154

Epoch: 5| Step: 8
Training loss: 0.09067536145448685
Validation loss: 1.5757982243773758

Epoch: 5| Step: 9
Training loss: 0.1270516812801361
Validation loss: 1.5817060675672305

Epoch: 5| Step: 10
Training loss: 0.08806028962135315
Validation loss: 1.574691818606469

Epoch: 561| Step: 0
Training loss: 0.06834482401609421
Validation loss: 1.5724221403880785

Epoch: 5| Step: 1
Training loss: 0.09547370672225952
Validation loss: 1.5627141614114084

Epoch: 5| Step: 2
Training loss: 0.08894617855548859
Validation loss: 1.5421827326538742

Epoch: 5| Step: 3
Training loss: 0.07003749161958694
Validation loss: 1.5683483218634

Epoch: 5| Step: 4
Training loss: 0.06039559841156006
Validation loss: 1.5723227300951559

Epoch: 5| Step: 5
Training loss: 0.14134670794010162
Validation loss: 1.554624137058053

Epoch: 5| Step: 6
Training loss: 0.12999668717384338
Validation loss: 1.5578435249226068

Epoch: 5| Step: 7
Training loss: 0.07479642331600189
Validation loss: 1.593407195101502

Epoch: 5| Step: 8
Training loss: 0.10690991580486298
Validation loss: 1.5619479456255514

Epoch: 5| Step: 9
Training loss: 0.1296515166759491
Validation loss: 1.5666710862549402

Epoch: 5| Step: 10
Training loss: 0.0767892450094223
Validation loss: 1.5655793297675349

Epoch: 562| Step: 0
Training loss: 0.08667539805173874
Validation loss: 1.5555043194883613

Epoch: 5| Step: 1
Training loss: 0.09254071861505508
Validation loss: 1.5687582749192432

Epoch: 5| Step: 2
Training loss: 0.11145881563425064
Validation loss: 1.5724477011670348

Epoch: 5| Step: 3
Training loss: 0.09210309386253357
Validation loss: 1.5603317701688377

Epoch: 5| Step: 4
Training loss: 0.06269166618585587
Validation loss: 1.5859146887256252

Epoch: 5| Step: 5
Training loss: 0.1167997345328331
Validation loss: 1.5499272628497052

Epoch: 5| Step: 6
Training loss: 0.07458584010601044
Validation loss: 1.5538431367566508

Epoch: 5| Step: 7
Training loss: 0.07199864089488983
Validation loss: 1.5348705476330173

Epoch: 5| Step: 8
Training loss: 0.06829766184091568
Validation loss: 1.5684177696063955

Epoch: 5| Step: 9
Training loss: 0.06826524436473846
Validation loss: 1.5564118405824066

Epoch: 5| Step: 10
Training loss: 0.08718091994524002
Validation loss: 1.5449256781608827

Epoch: 563| Step: 0
Training loss: 0.12604227662086487
Validation loss: 1.5341421558010964

Epoch: 5| Step: 1
Training loss: 0.07264601439237595
Validation loss: 1.5394564354291527

Epoch: 5| Step: 2
Training loss: 0.07084425538778305
Validation loss: 1.5330893160194479

Epoch: 5| Step: 3
Training loss: 0.06092916801571846
Validation loss: 1.5465707458475584

Epoch: 5| Step: 4
Training loss: 0.11471779644489288
Validation loss: 1.5068864207113943

Epoch: 5| Step: 5
Training loss: 0.03678148239850998
Validation loss: 1.5103898650856429

Epoch: 5| Step: 6
Training loss: 0.05424833297729492
Validation loss: 1.52615527824689

Epoch: 5| Step: 7
Training loss: 0.06990866363048553
Validation loss: 1.526140179685367

Epoch: 5| Step: 8
Training loss: 0.05992475897073746
Validation loss: 1.4919806667553481

Epoch: 5| Step: 9
Training loss: 0.0783245712518692
Validation loss: 1.4869447677366194

Epoch: 5| Step: 10
Training loss: 0.0965527668595314
Validation loss: 1.5179145810424641

Epoch: 564| Step: 0
Training loss: 0.09598229825496674
Validation loss: 1.485702181375155

Epoch: 5| Step: 1
Training loss: 0.08932211250066757
Validation loss: 1.4815594573174753

Epoch: 5| Step: 2
Training loss: 0.057151444256305695
Validation loss: 1.4903534125256281

Epoch: 5| Step: 3
Training loss: 0.09141238033771515
Validation loss: 1.4989709443943475

Epoch: 5| Step: 4
Training loss: 0.10318003594875336
Validation loss: 1.524422848096458

Epoch: 5| Step: 5
Training loss: 0.0584254264831543
Validation loss: 1.557697981916448

Epoch: 5| Step: 6
Training loss: 0.051510464400053024
Validation loss: 1.542920539456029

Epoch: 5| Step: 7
Training loss: 0.062434375286102295
Validation loss: 1.5415689458129227

Epoch: 5| Step: 8
Training loss: 0.08979655802249908
Validation loss: 1.5834396500741281

Epoch: 5| Step: 9
Training loss: 0.07121912389993668
Validation loss: 1.5737540875711749

Epoch: 5| Step: 10
Training loss: 0.06495524942874908
Validation loss: 1.54101836809548

Epoch: 565| Step: 0
Training loss: 0.044296640902757645
Validation loss: 1.5712203453945857

Epoch: 5| Step: 1
Training loss: 0.06710262596607208
Validation loss: 1.5629644304193475

Epoch: 5| Step: 2
Training loss: 0.09838709980249405
Validation loss: 1.5681071691615607

Epoch: 5| Step: 3
Training loss: 0.06851019710302353
Validation loss: 1.5428836948128157

Epoch: 5| Step: 4
Training loss: 0.06708110868930817
Validation loss: 1.559659037538754

Epoch: 5| Step: 5
Training loss: 0.08150515705347061
Validation loss: 1.5727903586561962

Epoch: 5| Step: 6
Training loss: 0.09443971514701843
Validation loss: 1.5663357421916018

Epoch: 5| Step: 7
Training loss: 0.064862459897995
Validation loss: 1.5817475447090723

Epoch: 5| Step: 8
Training loss: 0.0781765803694725
Validation loss: 1.5896781849604782

Epoch: 5| Step: 9
Training loss: 0.11320970207452774
Validation loss: 1.584831299320344

Epoch: 5| Step: 10
Training loss: 0.05788005143404007
Validation loss: 1.6122799458042267

Epoch: 566| Step: 0
Training loss: 0.06562851369380951
Validation loss: 1.554887645988054

Epoch: 5| Step: 1
Training loss: 0.07856372743844986
Validation loss: 1.5843483337792017

Epoch: 5| Step: 2
Training loss: 0.061964161694049835
Validation loss: 1.5820648144650202

Epoch: 5| Step: 3
Training loss: 0.14594146609306335
Validation loss: 1.5736118529432563

Epoch: 5| Step: 4
Training loss: 0.07247661054134369
Validation loss: 1.5615055073973954

Epoch: 5| Step: 5
Training loss: 0.08726391196250916
Validation loss: 1.5600026884386617

Epoch: 5| Step: 6
Training loss: 0.10051707923412323
Validation loss: 1.5572989730424778

Epoch: 5| Step: 7
Training loss: 0.07101842761039734
Validation loss: 1.572505440763248

Epoch: 5| Step: 8
Training loss: 0.0804806798696518
Validation loss: 1.5586996142582228

Epoch: 5| Step: 9
Training loss: 0.09761985391378403
Validation loss: 1.57765914804192

Epoch: 5| Step: 10
Training loss: 0.04495741426944733
Validation loss: 1.5567909004867717

Epoch: 567| Step: 0
Training loss: 0.10026079416275024
Validation loss: 1.5771855538891209

Epoch: 5| Step: 1
Training loss: 0.0585172176361084
Validation loss: 1.5664513816115677

Epoch: 5| Step: 2
Training loss: 0.11155770719051361
Validation loss: 1.5385526457140524

Epoch: 5| Step: 3
Training loss: 0.09006194025278091
Validation loss: 1.533932347451487

Epoch: 5| Step: 4
Training loss: 0.07668809592723846
Validation loss: 1.530450265894654

Epoch: 5| Step: 5
Training loss: 0.09838235378265381
Validation loss: 1.5208685962102746

Epoch: 5| Step: 6
Training loss: 0.07733002305030823
Validation loss: 1.5036288974105672

Epoch: 5| Step: 7
Training loss: 0.09928607940673828
Validation loss: 1.5009475664425922

Epoch: 5| Step: 8
Training loss: 0.06986378133296967
Validation loss: 1.5064454668311662

Epoch: 5| Step: 9
Training loss: 0.10319669544696808
Validation loss: 1.537532414159467

Epoch: 5| Step: 10
Training loss: 0.05645641312003136
Validation loss: 1.5128387763936033

Epoch: 568| Step: 0
Training loss: 0.09823785722255707
Validation loss: 1.5289619443237141

Epoch: 5| Step: 1
Training loss: 0.09358696639537811
Validation loss: 1.5176363709152385

Epoch: 5| Step: 2
Training loss: 0.10017062723636627
Validation loss: 1.5284493809105248

Epoch: 5| Step: 3
Training loss: 0.047447558492422104
Validation loss: 1.5570610646278626

Epoch: 5| Step: 4
Training loss: 0.08951514214277267
Validation loss: 1.5543206891705912

Epoch: 5| Step: 5
Training loss: 0.05891790986061096
Validation loss: 1.5562450001316686

Epoch: 5| Step: 6
Training loss: 0.05775439739227295
Validation loss: 1.5524836970913796

Epoch: 5| Step: 7
Training loss: 0.06806468218564987
Validation loss: 1.5531498360377487

Epoch: 5| Step: 8
Training loss: 0.06193394213914871
Validation loss: 1.5378471587293892

Epoch: 5| Step: 9
Training loss: 0.10912103950977325
Validation loss: 1.5544741538263136

Epoch: 5| Step: 10
Training loss: 0.09617087244987488
Validation loss: 1.587002795229676

Epoch: 569| Step: 0
Training loss: 0.08034772425889969
Validation loss: 1.5629537028651084

Epoch: 5| Step: 1
Training loss: 0.11194665729999542
Validation loss: 1.5540993309790088

Epoch: 5| Step: 2
Training loss: 0.045419223606586456
Validation loss: 1.5326044059568835

Epoch: 5| Step: 3
Training loss: 0.07837089151144028
Validation loss: 1.542762376928842

Epoch: 5| Step: 4
Training loss: 0.08371725678443909
Validation loss: 1.5155491572554394

Epoch: 5| Step: 5
Training loss: 0.0822882428765297
Validation loss: 1.507429826644159

Epoch: 5| Step: 6
Training loss: 0.11444967985153198
Validation loss: 1.5043112488203152

Epoch: 5| Step: 7
Training loss: 0.04961056634783745
Validation loss: 1.5143788694053568

Epoch: 5| Step: 8
Training loss: 0.11423105001449585
Validation loss: 1.490851313837113

Epoch: 5| Step: 9
Training loss: 0.12444963306188583
Validation loss: 1.523089688311341

Epoch: 5| Step: 10
Training loss: 0.06356003880500793
Validation loss: 1.5399381396591023

Epoch: 570| Step: 0
Training loss: 0.06935439258813858
Validation loss: 1.5857097198886256

Epoch: 5| Step: 1
Training loss: 0.09289111196994781
Validation loss: 1.575404090266074

Epoch: 5| Step: 2
Training loss: 0.07399721443653107
Validation loss: 1.5768308665162774

Epoch: 5| Step: 3
Training loss: 0.08636493980884552
Validation loss: 1.5639376101955291

Epoch: 5| Step: 4
Training loss: 0.08129532635211945
Validation loss: 1.5426820003858177

Epoch: 5| Step: 5
Training loss: 0.08455141633749008
Validation loss: 1.5239371503553083

Epoch: 5| Step: 6
Training loss: 0.06339181959629059
Validation loss: 1.5478096546665314

Epoch: 5| Step: 7
Training loss: 0.0644318237900734
Validation loss: 1.5595372492267239

Epoch: 5| Step: 8
Training loss: 0.185474693775177
Validation loss: 1.5731133953217538

Epoch: 5| Step: 9
Training loss: 0.08334001153707504
Validation loss: 1.5968365630795878

Epoch: 5| Step: 10
Training loss: 0.12948401272296906
Validation loss: 1.5973969685134066

Epoch: 571| Step: 0
Training loss: 0.08887176215648651
Validation loss: 1.5762658273020098

Epoch: 5| Step: 1
Training loss: 0.09513449668884277
Validation loss: 1.5595302761241954

Epoch: 5| Step: 2
Training loss: 0.09759362787008286
Validation loss: 1.5947369593445972

Epoch: 5| Step: 3
Training loss: 0.08323464542627335
Validation loss: 1.5685811593968382

Epoch: 5| Step: 4
Training loss: 0.06571817398071289
Validation loss: 1.570352751721618

Epoch: 5| Step: 5
Training loss: 0.12181107699871063
Validation loss: 1.625013723168322

Epoch: 5| Step: 6
Training loss: 0.09371572732925415
Validation loss: 1.643655687250117

Epoch: 5| Step: 7
Training loss: 0.16373053193092346
Validation loss: 1.6221747552194903

Epoch: 5| Step: 8
Training loss: 0.06877362728118896
Validation loss: 1.609822903909991

Epoch: 5| Step: 9
Training loss: 0.11761398613452911
Validation loss: 1.5815287174717072

Epoch: 5| Step: 10
Training loss: 0.0836610347032547
Validation loss: 1.5719353665587723

Epoch: 572| Step: 0
Training loss: 0.1710166037082672
Validation loss: 1.5492646155818817

Epoch: 5| Step: 1
Training loss: 0.13616101443767548
Validation loss: 1.5562276763300742

Epoch: 5| Step: 2
Training loss: 0.08238983154296875
Validation loss: 1.5200685557498728

Epoch: 5| Step: 3
Training loss: 0.07834239304065704
Validation loss: 1.5157186087741648

Epoch: 5| Step: 4
Training loss: 0.11179348081350327
Validation loss: 1.522849429038263

Epoch: 5| Step: 5
Training loss: 0.10302112251520157
Validation loss: 1.5555076124847576

Epoch: 5| Step: 6
Training loss: 0.13110533356666565
Validation loss: 1.530209074738205

Epoch: 5| Step: 7
Training loss: 0.11555476486682892
Validation loss: 1.55928966435053

Epoch: 5| Step: 8
Training loss: 0.11524512618780136
Validation loss: 1.526420340743116

Epoch: 5| Step: 9
Training loss: 0.11148130893707275
Validation loss: 1.5785333841077742

Epoch: 5| Step: 10
Training loss: 0.08916230499744415
Validation loss: 1.5572709345048474

Epoch: 573| Step: 0
Training loss: 0.07541677355766296
Validation loss: 1.5640183584664458

Epoch: 5| Step: 1
Training loss: 0.060955971479415894
Validation loss: 1.5720942251143917

Epoch: 5| Step: 2
Training loss: 0.06660729646682739
Validation loss: 1.6030046798849618

Epoch: 5| Step: 3
Training loss: 0.09306061267852783
Validation loss: 1.5868619539404427

Epoch: 5| Step: 4
Training loss: 0.08941866457462311
Validation loss: 1.590449579300419

Epoch: 5| Step: 5
Training loss: 0.1378680169582367
Validation loss: 1.592288508210131

Epoch: 5| Step: 6
Training loss: 0.1456509381532669
Validation loss: 1.6012315519394413

Epoch: 5| Step: 7
Training loss: 0.06258530914783478
Validation loss: 1.5786167049920687

Epoch: 5| Step: 8
Training loss: 0.06940919905900955
Validation loss: 1.5867646765965286

Epoch: 5| Step: 9
Training loss: 0.04264640063047409
Validation loss: 1.5507963511251635

Epoch: 5| Step: 10
Training loss: 0.0841754749417305
Validation loss: 1.5545195200109994

Epoch: 574| Step: 0
Training loss: 0.06593728065490723
Validation loss: 1.5432869131847093

Epoch: 5| Step: 1
Training loss: 0.10788055509328842
Validation loss: 1.559906336569017

Epoch: 5| Step: 2
Training loss: 0.1239355057477951
Validation loss: 1.5297792009128037

Epoch: 5| Step: 3
Training loss: 0.10336470603942871
Validation loss: 1.5311938857519498

Epoch: 5| Step: 4
Training loss: 0.10488708317279816
Validation loss: 1.5136202202048352

Epoch: 5| Step: 5
Training loss: 0.10756096988916397
Validation loss: 1.5049068966219503

Epoch: 5| Step: 6
Training loss: 0.05998659133911133
Validation loss: 1.5026975395858928

Epoch: 5| Step: 7
Training loss: 0.08124390989542007
Validation loss: 1.5165285730874667

Epoch: 5| Step: 8
Training loss: 0.11688365787267685
Validation loss: 1.5254714130073466

Epoch: 5| Step: 9
Training loss: 0.07586880773305893
Validation loss: 1.5444795995630243

Epoch: 5| Step: 10
Training loss: 0.06420174986124039
Validation loss: 1.5424601442070418

Epoch: 575| Step: 0
Training loss: 0.08474971354007721
Validation loss: 1.5599109139493716

Epoch: 5| Step: 1
Training loss: 0.05700358748435974
Validation loss: 1.5684150624018844

Epoch: 5| Step: 2
Training loss: 0.07419343292713165
Validation loss: 1.6087298111249042

Epoch: 5| Step: 3
Training loss: 0.06936518847942352
Validation loss: 1.5928208469062723

Epoch: 5| Step: 4
Training loss: 0.10262807458639145
Validation loss: 1.5853241643598002

Epoch: 5| Step: 5
Training loss: 0.13621929287910461
Validation loss: 1.5788131465194046

Epoch: 5| Step: 6
Training loss: 0.06868134438991547
Validation loss: 1.5766178010612406

Epoch: 5| Step: 7
Training loss: 0.05290944501757622
Validation loss: 1.5537171389466973

Epoch: 5| Step: 8
Training loss: 0.12317106872797012
Validation loss: 1.5512083884208434

Epoch: 5| Step: 9
Training loss: 0.11738879978656769
Validation loss: 1.5399166178959671

Epoch: 5| Step: 10
Training loss: 0.06740614771842957
Validation loss: 1.5340462269321564

Epoch: 576| Step: 0
Training loss: 0.10001041740179062
Validation loss: 1.5451909861256998

Epoch: 5| Step: 1
Training loss: 0.09203266352415085
Validation loss: 1.5290282951888217

Epoch: 5| Step: 2
Training loss: 0.07146430015563965
Validation loss: 1.5425226355111727

Epoch: 5| Step: 3
Training loss: 0.10163731873035431
Validation loss: 1.5415893523923812

Epoch: 5| Step: 4
Training loss: 0.06610716879367828
Validation loss: 1.5484749706842567

Epoch: 5| Step: 5
Training loss: 0.11752259731292725
Validation loss: 1.5678663074329335

Epoch: 5| Step: 6
Training loss: 0.08961725234985352
Validation loss: 1.5421043839505924

Epoch: 5| Step: 7
Training loss: 0.05626257508993149
Validation loss: 1.5713305742509904

Epoch: 5| Step: 8
Training loss: 0.07734061777591705
Validation loss: 1.5474099843732771

Epoch: 5| Step: 9
Training loss: 0.09726358205080032
Validation loss: 1.575504332460383

Epoch: 5| Step: 10
Training loss: 0.04500773549079895
Validation loss: 1.5774315454626595

Epoch: 577| Step: 0
Training loss: 0.07008367776870728
Validation loss: 1.5670155222697923

Epoch: 5| Step: 1
Training loss: 0.0555461160838604
Validation loss: 1.5540567508307837

Epoch: 5| Step: 2
Training loss: 0.10920045524835587
Validation loss: 1.5886964387791132

Epoch: 5| Step: 3
Training loss: 0.06499164551496506
Validation loss: 1.579881198944584

Epoch: 5| Step: 4
Training loss: 0.09321374446153641
Validation loss: 1.5903189131008681

Epoch: 5| Step: 5
Training loss: 0.12572941184043884
Validation loss: 1.602880403559695

Epoch: 5| Step: 6
Training loss: 0.1484696865081787
Validation loss: 1.5861667176728607

Epoch: 5| Step: 7
Training loss: 0.07037229835987091
Validation loss: 1.5655197866501347

Epoch: 5| Step: 8
Training loss: 0.06866580247879028
Validation loss: 1.5672616266435193

Epoch: 5| Step: 9
Training loss: 0.06661031395196915
Validation loss: 1.576810598373413

Epoch: 5| Step: 10
Training loss: 0.07602420449256897
Validation loss: 1.5881400031428183

Epoch: 578| Step: 0
Training loss: 0.07230503857135773
Validation loss: 1.5445999368544547

Epoch: 5| Step: 1
Training loss: 0.049355439841747284
Validation loss: 1.5550716397582844

Epoch: 5| Step: 2
Training loss: 0.10795734822750092
Validation loss: 1.5583409981061054

Epoch: 5| Step: 3
Training loss: 0.05860245227813721
Validation loss: 1.5524301452021445

Epoch: 5| Step: 4
Training loss: 0.1047433465719223
Validation loss: 1.5521339742086266

Epoch: 5| Step: 5
Training loss: 0.081209197640419
Validation loss: 1.5825797127139183

Epoch: 5| Step: 6
Training loss: 0.0706997737288475
Validation loss: 1.5447661338313934

Epoch: 5| Step: 7
Training loss: 0.07087402045726776
Validation loss: 1.5605545466946018

Epoch: 5| Step: 8
Training loss: 0.10450643301010132
Validation loss: 1.5629881184588197

Epoch: 5| Step: 9
Training loss: 0.05862485617399216
Validation loss: 1.554822673079788

Epoch: 5| Step: 10
Training loss: 0.06288392841815948
Validation loss: 1.5499032280778373

Epoch: 579| Step: 0
Training loss: 0.09929125010967255
Validation loss: 1.5622934352967046

Epoch: 5| Step: 1
Training loss: 0.05582321807742119
Validation loss: 1.5250685471360401

Epoch: 5| Step: 2
Training loss: 0.05728994682431221
Validation loss: 1.5458450291746406

Epoch: 5| Step: 3
Training loss: 0.06942902505397797
Validation loss: 1.534571538689316

Epoch: 5| Step: 4
Training loss: 0.0946902334690094
Validation loss: 1.567448910846505

Epoch: 5| Step: 5
Training loss: 0.07974343001842499
Validation loss: 1.535795493792462

Epoch: 5| Step: 6
Training loss: 0.09902408719062805
Validation loss: 1.5359662335406068

Epoch: 5| Step: 7
Training loss: 0.09871919453144073
Validation loss: 1.5680153203266922

Epoch: 5| Step: 8
Training loss: 0.0810328871011734
Validation loss: 1.551258348649548

Epoch: 5| Step: 9
Training loss: 0.06569854170084
Validation loss: 1.524798338131238

Epoch: 5| Step: 10
Training loss: 0.056382227689027786
Validation loss: 1.5444808416469122

Epoch: 580| Step: 0
Training loss: 0.05645568296313286
Validation loss: 1.524415792957429

Epoch: 5| Step: 1
Training loss: 0.07475639879703522
Validation loss: 1.560646149419969

Epoch: 5| Step: 2
Training loss: 0.06946466118097305
Validation loss: 1.5744399050230622

Epoch: 5| Step: 3
Training loss: 0.12200786173343658
Validation loss: 1.549641401537003

Epoch: 5| Step: 4
Training loss: 0.10261289030313492
Validation loss: 1.5774367496531496

Epoch: 5| Step: 5
Training loss: 0.04805166274309158
Validation loss: 1.58737862366502

Epoch: 5| Step: 6
Training loss: 0.07190880924463272
Validation loss: 1.5855052368615263

Epoch: 5| Step: 7
Training loss: 0.053729988634586334
Validation loss: 1.5618181741365822

Epoch: 5| Step: 8
Training loss: 0.07691248506307602
Validation loss: 1.5916175906376173

Epoch: 5| Step: 9
Training loss: 0.09307582676410675
Validation loss: 1.5848051117312523

Epoch: 5| Step: 10
Training loss: 0.11358392983675003
Validation loss: 1.5633373991135628

Epoch: 581| Step: 0
Training loss: 0.09689895808696747
Validation loss: 1.5914254944811586

Epoch: 5| Step: 1
Training loss: 0.09258876740932465
Validation loss: 1.5753972838001866

Epoch: 5| Step: 2
Training loss: 0.13388888537883759
Validation loss: 1.6048376188483289

Epoch: 5| Step: 3
Training loss: 0.07702170312404633
Validation loss: 1.5853774675758936

Epoch: 5| Step: 4
Training loss: 0.08848907053470612
Validation loss: 1.5998969731792327

Epoch: 5| Step: 5
Training loss: 0.06379444897174835
Validation loss: 1.5997456376270582

Epoch: 5| Step: 6
Training loss: 0.076551154255867
Validation loss: 1.5810364395059564

Epoch: 5| Step: 7
Training loss: 0.07737443596124649
Validation loss: 1.6001586401334373

Epoch: 5| Step: 8
Training loss: 0.05690409988164902
Validation loss: 1.587037492823857

Epoch: 5| Step: 9
Training loss: 0.052295438945293427
Validation loss: 1.604574639310119

Epoch: 5| Step: 10
Training loss: 0.09766805917024612
Validation loss: 1.5941632306703957

Epoch: 582| Step: 0
Training loss: 0.08345718681812286
Validation loss: 1.539029021416941

Epoch: 5| Step: 1
Training loss: 0.12937617301940918
Validation loss: 1.5519856868251678

Epoch: 5| Step: 2
Training loss: 0.0942712351679802
Validation loss: 1.6039490571586035

Epoch: 5| Step: 3
Training loss: 0.0991072803735733
Validation loss: 1.6039526244645477

Epoch: 5| Step: 4
Training loss: 0.05740181729197502
Validation loss: 1.5934987247631114

Epoch: 5| Step: 5
Training loss: 0.09412052482366562
Validation loss: 1.574004186737922

Epoch: 5| Step: 6
Training loss: 0.056652747094631195
Validation loss: 1.610110189325066

Epoch: 5| Step: 7
Training loss: 0.15320134162902832
Validation loss: 1.6004755548251572

Epoch: 5| Step: 8
Training loss: 0.07467353343963623
Validation loss: 1.5875377398665234

Epoch: 5| Step: 9
Training loss: 0.045041777193546295
Validation loss: 1.5719335848285305

Epoch: 5| Step: 10
Training loss: 0.13342203199863434
Validation loss: 1.5644738071708268

Epoch: 583| Step: 0
Training loss: 0.1037382259964943
Validation loss: 1.57910672567224

Epoch: 5| Step: 1
Training loss: 0.06738521158695221
Validation loss: 1.553123144693272

Epoch: 5| Step: 2
Training loss: 0.16995170712471008
Validation loss: 1.5556502162769277

Epoch: 5| Step: 3
Training loss: 0.06972894817590714
Validation loss: 1.5533056393746407

Epoch: 5| Step: 4
Training loss: 0.1254742443561554
Validation loss: 1.5479339361190796

Epoch: 5| Step: 5
Training loss: 0.08055485785007477
Validation loss: 1.544522548234591

Epoch: 5| Step: 6
Training loss: 0.09677880257368088
Validation loss: 1.5765171973936019

Epoch: 5| Step: 7
Training loss: 0.09543398022651672
Validation loss: 1.5951376653486682

Epoch: 5| Step: 8
Training loss: 0.05397281050682068
Validation loss: 1.6153794693690475

Epoch: 5| Step: 9
Training loss: 0.05638892576098442
Validation loss: 1.6214543722009147

Epoch: 5| Step: 10
Training loss: 0.08025646209716797
Validation loss: 1.6128771125629384

Epoch: 584| Step: 0
Training loss: 0.04250673949718475
Validation loss: 1.6139182711160311

Epoch: 5| Step: 1
Training loss: 0.09538091719150543
Validation loss: 1.582610907093171

Epoch: 5| Step: 2
Training loss: 0.07385141402482986
Validation loss: 1.596595061722622

Epoch: 5| Step: 3
Training loss: 0.07145797461271286
Validation loss: 1.5736541401955388

Epoch: 5| Step: 4
Training loss: 0.07427903264760971
Validation loss: 1.5789058926284953

Epoch: 5| Step: 5
Training loss: 0.09261943399906158
Validation loss: 1.541708416836236

Epoch: 5| Step: 6
Training loss: 0.0924680307507515
Validation loss: 1.5684270474218553

Epoch: 5| Step: 7
Training loss: 0.11747559159994125
Validation loss: 1.5815146507755402

Epoch: 5| Step: 8
Training loss: 0.062267791479825974
Validation loss: 1.5837608434820687

Epoch: 5| Step: 9
Training loss: 0.05175570398569107
Validation loss: 1.5947500146845335

Epoch: 5| Step: 10
Training loss: 0.10232963413000107
Validation loss: 1.616211457919049

Epoch: 585| Step: 0
Training loss: 0.10379967838525772
Validation loss: 1.6117654538923694

Epoch: 5| Step: 1
Training loss: 0.07391656935214996
Validation loss: 1.6108570867969143

Epoch: 5| Step: 2
Training loss: 0.10986675322055817
Validation loss: 1.5671952885966147

Epoch: 5| Step: 3
Training loss: 0.07497289031744003
Validation loss: 1.544618454030765

Epoch: 5| Step: 4
Training loss: 0.08240772783756256
Validation loss: 1.5248747807677074

Epoch: 5| Step: 5
Training loss: 0.09554214775562286
Validation loss: 1.501155134170286

Epoch: 5| Step: 6
Training loss: 0.09374810010194778
Validation loss: 1.5225558979536897

Epoch: 5| Step: 7
Training loss: 0.0670982301235199
Validation loss: 1.4869046775243615

Epoch: 5| Step: 8
Training loss: 0.08616657555103302
Validation loss: 1.4936310501508816

Epoch: 5| Step: 9
Training loss: 0.062209587544202805
Validation loss: 1.4908475452853787

Epoch: 5| Step: 10
Training loss: 0.08289278298616409
Validation loss: 1.5261180311120965

Epoch: 586| Step: 0
Training loss: 0.06754248589277267
Validation loss: 1.5214240909904562

Epoch: 5| Step: 1
Training loss: 0.1225445494055748
Validation loss: 1.5687350226986794

Epoch: 5| Step: 2
Training loss: 0.06547896564006805
Validation loss: 1.5453827393952237

Epoch: 5| Step: 3
Training loss: 0.1065259724855423
Validation loss: 1.5628030518049836

Epoch: 5| Step: 4
Training loss: 0.08314742892980576
Validation loss: 1.5336494061254686

Epoch: 5| Step: 5
Training loss: 0.07546819001436234
Validation loss: 1.556860367457072

Epoch: 5| Step: 6
Training loss: 0.05697626993060112
Validation loss: 1.5542784711366058

Epoch: 5| Step: 7
Training loss: 0.09700515121221542
Validation loss: 1.566447672023568

Epoch: 5| Step: 8
Training loss: 0.05709825083613396
Validation loss: 1.5848058398051927

Epoch: 5| Step: 9
Training loss: 0.10898479074239731
Validation loss: 1.592815415833586

Epoch: 5| Step: 10
Training loss: 0.08561629801988602
Validation loss: 1.57752509655491

Epoch: 587| Step: 0
Training loss: 0.0930803120136261
Validation loss: 1.5802546893396685

Epoch: 5| Step: 1
Training loss: 0.08602069318294525
Validation loss: 1.60516397799215

Epoch: 5| Step: 2
Training loss: 0.1027659922838211
Validation loss: 1.5964067751361477

Epoch: 5| Step: 3
Training loss: 0.08352359384298325
Validation loss: 1.600763120958882

Epoch: 5| Step: 4
Training loss: 0.06523201614618301
Validation loss: 1.6422427802957513

Epoch: 5| Step: 5
Training loss: 0.07525050640106201
Validation loss: 1.6144772229656097

Epoch: 5| Step: 6
Training loss: 0.1345495581626892
Validation loss: 1.6284269863559353

Epoch: 5| Step: 7
Training loss: 0.09563237428665161
Validation loss: 1.618880210384246

Epoch: 5| Step: 8
Training loss: 0.09885434806346893
Validation loss: 1.624304517622917

Epoch: 5| Step: 9
Training loss: 0.07630722224712372
Validation loss: 1.6215716344054028

Epoch: 5| Step: 10
Training loss: 0.10834667831659317
Validation loss: 1.5978322766160453

Epoch: 588| Step: 0
Training loss: 0.09973089396953583
Validation loss: 1.602843165397644

Epoch: 5| Step: 1
Training loss: 0.17192819714546204
Validation loss: 1.5921449866346133

Epoch: 5| Step: 2
Training loss: 0.07320878654718399
Validation loss: 1.5811338168318554

Epoch: 5| Step: 3
Training loss: 0.09166990220546722
Validation loss: 1.5647902296435448

Epoch: 5| Step: 4
Training loss: 0.07138951867818832
Validation loss: 1.5477836465322843

Epoch: 5| Step: 5
Training loss: 0.051530320197343826
Validation loss: 1.5721506175174509

Epoch: 5| Step: 6
Training loss: 0.06100548431277275
Validation loss: 1.5580719811941988

Epoch: 5| Step: 7
Training loss: 0.07289912551641464
Validation loss: 1.5853340600126533

Epoch: 5| Step: 8
Training loss: 0.05543793365359306
Validation loss: 1.6013737891310005

Epoch: 5| Step: 9
Training loss: 0.08534333854913712
Validation loss: 1.5951350952989312

Epoch: 5| Step: 10
Training loss: 0.07942888885736465
Validation loss: 1.6065436460638558

Epoch: 589| Step: 0
Training loss: 0.09523624181747437
Validation loss: 1.5638493966030818

Epoch: 5| Step: 1
Training loss: 0.08509328216314316
Validation loss: 1.5410668298762331

Epoch: 5| Step: 2
Training loss: 0.08519246429204941
Validation loss: 1.5500788727114279

Epoch: 5| Step: 3
Training loss: 0.12107785046100616
Validation loss: 1.5531879266103108

Epoch: 5| Step: 4
Training loss: 0.08066225051879883
Validation loss: 1.5588079114114084

Epoch: 5| Step: 5
Training loss: 0.08684210479259491
Validation loss: 1.5447090312998781

Epoch: 5| Step: 6
Training loss: 0.07955002039670944
Validation loss: 1.5609695206406295

Epoch: 5| Step: 7
Training loss: 0.08726444840431213
Validation loss: 1.5717419680728708

Epoch: 5| Step: 8
Training loss: 0.08438773453235626
Validation loss: 1.572431045193826

Epoch: 5| Step: 9
Training loss: 0.05862657353281975
Validation loss: 1.587062167864974

Epoch: 5| Step: 10
Training loss: 0.11081239581108093
Validation loss: 1.5797283662262784

Epoch: 590| Step: 0
Training loss: 0.09808552265167236
Validation loss: 1.5731876357909171

Epoch: 5| Step: 1
Training loss: 0.08472289144992828
Validation loss: 1.572272116138089

Epoch: 5| Step: 2
Training loss: 0.0452427864074707
Validation loss: 1.5555744273688203

Epoch: 5| Step: 3
Training loss: 0.08303048461675644
Validation loss: 1.5526972804018246

Epoch: 5| Step: 4
Training loss: 0.059970878064632416
Validation loss: 1.5493659370688981

Epoch: 5| Step: 5
Training loss: 0.05825136974453926
Validation loss: 1.5314625206814017

Epoch: 5| Step: 6
Training loss: 0.07102815806865692
Validation loss: 1.5486927570835236

Epoch: 5| Step: 7
Training loss: 0.09683720767498016
Validation loss: 1.5418194558030816

Epoch: 5| Step: 8
Training loss: 0.07789455354213715
Validation loss: 1.5384148500298942

Epoch: 5| Step: 9
Training loss: 0.13821978867053986
Validation loss: 1.5269443783708798

Epoch: 5| Step: 10
Training loss: 0.05685238167643547
Validation loss: 1.514270040296739

Epoch: 591| Step: 0
Training loss: 0.07524969428777695
Validation loss: 1.5068104164574736

Epoch: 5| Step: 1
Training loss: 0.16527989506721497
Validation loss: 1.5360507529268983

Epoch: 5| Step: 2
Training loss: 0.09821493923664093
Validation loss: 1.5333566293921521

Epoch: 5| Step: 3
Training loss: 0.07256399095058441
Validation loss: 1.5534301778321624

Epoch: 5| Step: 4
Training loss: 0.10592015832662582
Validation loss: 1.5992112877548381

Epoch: 5| Step: 5
Training loss: 0.053070057183504105
Validation loss: 1.6058297849470569

Epoch: 5| Step: 6
Training loss: 0.08385654538869858
Validation loss: 1.5742340292981876

Epoch: 5| Step: 7
Training loss: 0.0827043205499649
Validation loss: 1.588827121642328

Epoch: 5| Step: 8
Training loss: 0.04200947284698486
Validation loss: 1.5811597724114694

Epoch: 5| Step: 9
Training loss: 0.07573257386684418
Validation loss: 1.5448074046001639

Epoch: 5| Step: 10
Training loss: 0.09645473957061768
Validation loss: 1.5140184779320993

Epoch: 592| Step: 0
Training loss: 0.09582613408565521
Validation loss: 1.5007174015045166

Epoch: 5| Step: 1
Training loss: 0.12619802355766296
Validation loss: 1.5270991338196622

Epoch: 5| Step: 2
Training loss: 0.10095225274562836
Validation loss: 1.5268107588573168

Epoch: 5| Step: 3
Training loss: 0.06012282520532608
Validation loss: 1.559931044937462

Epoch: 5| Step: 4
Training loss: 0.056131958961486816
Validation loss: 1.566019772201456

Epoch: 5| Step: 5
Training loss: 0.10407457500696182
Validation loss: 1.5758250451857043

Epoch: 5| Step: 6
Training loss: 0.12362352758646011
Validation loss: 1.569314323445802

Epoch: 5| Step: 7
Training loss: 0.08448972553014755
Validation loss: 1.570472268648045

Epoch: 5| Step: 8
Training loss: 0.07845552265644073
Validation loss: 1.5434987134830926

Epoch: 5| Step: 9
Training loss: 0.14319655299186707
Validation loss: 1.5533868433326803

Epoch: 5| Step: 10
Training loss: 0.07262361794710159
Validation loss: 1.5432286480421662

Epoch: 593| Step: 0
Training loss: 0.08724474906921387
Validation loss: 1.54952286904858

Epoch: 5| Step: 1
Training loss: 0.06093932315707207
Validation loss: 1.5513646730812647

Epoch: 5| Step: 2
Training loss: 0.11787164211273193
Validation loss: 1.5709151170587028

Epoch: 5| Step: 3
Training loss: 0.10763098299503326
Validation loss: 1.5178163448969524

Epoch: 5| Step: 4
Training loss: 0.06855838000774384
Validation loss: 1.5364630094138525

Epoch: 5| Step: 5
Training loss: 0.08710013329982758
Validation loss: 1.5659777259313932

Epoch: 5| Step: 6
Training loss: 0.09357663244009018
Validation loss: 1.5649914658197792

Epoch: 5| Step: 7
Training loss: 0.11299576610326767
Validation loss: 1.5701604799557758

Epoch: 5| Step: 8
Training loss: 0.07014624774456024
Validation loss: 1.5789619427855297

Epoch: 5| Step: 9
Training loss: 0.06422131508588791
Validation loss: 1.542433286225924

Epoch: 5| Step: 10
Training loss: 0.05296672508120537
Validation loss: 1.5289617392324633

Epoch: 594| Step: 0
Training loss: 0.13511009514331818
Validation loss: 1.5475387111786874

Epoch: 5| Step: 1
Training loss: 0.09435822069644928
Validation loss: 1.5511848016451764

Epoch: 5| Step: 2
Training loss: 0.07341869175434113
Validation loss: 1.5416433670187508

Epoch: 5| Step: 3
Training loss: 0.10586823523044586
Validation loss: 1.5305324344224827

Epoch: 5| Step: 4
Training loss: 0.09390901774168015
Validation loss: 1.5407642613175094

Epoch: 5| Step: 5
Training loss: 0.074063241481781
Validation loss: 1.5246017081763155

Epoch: 5| Step: 6
Training loss: 0.07130005955696106
Validation loss: 1.5415197123763382

Epoch: 5| Step: 7
Training loss: 0.08637912571430206
Validation loss: 1.52409605826101

Epoch: 5| Step: 8
Training loss: 0.0755658820271492
Validation loss: 1.554338083472303

Epoch: 5| Step: 9
Training loss: 0.09630484879016876
Validation loss: 1.5577358443249938

Epoch: 5| Step: 10
Training loss: 0.06496845185756683
Validation loss: 1.5757283446609334

Epoch: 595| Step: 0
Training loss: 0.09979140013456345
Validation loss: 1.556527909412179

Epoch: 5| Step: 1
Training loss: 0.06191325932741165
Validation loss: 1.569220358325589

Epoch: 5| Step: 2
Training loss: 0.09930254518985748
Validation loss: 1.5504384784288303

Epoch: 5| Step: 3
Training loss: 0.1001729741692543
Validation loss: 1.5574734185331611

Epoch: 5| Step: 4
Training loss: 0.06819061934947968
Validation loss: 1.5303351609937605

Epoch: 5| Step: 5
Training loss: 0.06743824481964111
Validation loss: 1.5143869230824132

Epoch: 5| Step: 6
Training loss: 0.09904073178768158
Validation loss: 1.505086495030311

Epoch: 5| Step: 7
Training loss: 0.08000107854604721
Validation loss: 1.4985954569232078

Epoch: 5| Step: 8
Training loss: 0.08148181438446045
Validation loss: 1.4976567901590818

Epoch: 5| Step: 9
Training loss: 0.0717005506157875
Validation loss: 1.4977802589375486

Epoch: 5| Step: 10
Training loss: 0.07605412602424622
Validation loss: 1.5205942212894399

Epoch: 596| Step: 0
Training loss: 0.06941251456737518
Validation loss: 1.530808215500206

Epoch: 5| Step: 1
Training loss: 0.08269090950489044
Validation loss: 1.5214960844286027

Epoch: 5| Step: 2
Training loss: 0.05366712808609009
Validation loss: 1.5828283832919212

Epoch: 5| Step: 3
Training loss: 0.13733407855033875
Validation loss: 1.59002677471407

Epoch: 5| Step: 4
Training loss: 0.06856522709131241
Validation loss: 1.6087938252315725

Epoch: 5| Step: 5
Training loss: 0.07725877314805984
Validation loss: 1.6182051076683948

Epoch: 5| Step: 6
Training loss: 0.07479308545589447
Validation loss: 1.6188434234229467

Epoch: 5| Step: 7
Training loss: 0.09494803100824356
Validation loss: 1.6031725842465636

Epoch: 5| Step: 8
Training loss: 0.06719575822353363
Validation loss: 1.580014201902574

Epoch: 5| Step: 9
Training loss: 0.12871167063713074
Validation loss: 1.5681652215219313

Epoch: 5| Step: 10
Training loss: 0.048057932406663895
Validation loss: 1.5781898088352655

Epoch: 597| Step: 0
Training loss: 0.07243438065052032
Validation loss: 1.545471122187953

Epoch: 5| Step: 1
Training loss: 0.1351557970046997
Validation loss: 1.5747725732864872

Epoch: 5| Step: 2
Training loss: 0.09265230596065521
Validation loss: 1.591474688181313

Epoch: 5| Step: 3
Training loss: 0.12251409143209457
Validation loss: 1.5906087724111413

Epoch: 5| Step: 4
Training loss: 0.060143280774354935
Validation loss: 1.5862735009962512

Epoch: 5| Step: 5
Training loss: 0.05936630442738533
Validation loss: 1.6034987754719232

Epoch: 5| Step: 6
Training loss: 0.052257977426052094
Validation loss: 1.605315323798887

Epoch: 5| Step: 7
Training loss: 0.10323403775691986
Validation loss: 1.592980597608833

Epoch: 5| Step: 8
Training loss: 0.07274727523326874
Validation loss: 1.5803938911807152

Epoch: 5| Step: 9
Training loss: 0.0818885937333107
Validation loss: 1.6007649949801865

Epoch: 5| Step: 10
Training loss: 0.1107078418135643
Validation loss: 1.5995340578017696

Epoch: 598| Step: 0
Training loss: 0.10020444542169571
Validation loss: 1.6084944894236903

Epoch: 5| Step: 1
Training loss: 0.050323642790317535
Validation loss: 1.5839993876795615

Epoch: 5| Step: 2
Training loss: 0.08256982266902924
Validation loss: 1.5655744409048429

Epoch: 5| Step: 3
Training loss: 0.10258343070745468
Validation loss: 1.568876894571448

Epoch: 5| Step: 4
Training loss: 0.08151265978813171
Validation loss: 1.5425369560077626

Epoch: 5| Step: 5
Training loss: 0.07906033098697662
Validation loss: 1.5679502615364649

Epoch: 5| Step: 6
Training loss: 0.05334124714136124
Validation loss: 1.5462356536619124

Epoch: 5| Step: 7
Training loss: 0.09687251597642899
Validation loss: 1.556651963982531

Epoch: 5| Step: 8
Training loss: 0.0792490690946579
Validation loss: 1.5658912684327813

Epoch: 5| Step: 9
Training loss: 0.08596138656139374
Validation loss: 1.5549977928079584

Epoch: 5| Step: 10
Training loss: 0.0522027462720871
Validation loss: 1.5740161172805294

Epoch: 599| Step: 0
Training loss: 0.09817686676979065
Validation loss: 1.5880600008913266

Epoch: 5| Step: 1
Training loss: 0.06473489105701447
Validation loss: 1.5743495200269966

Epoch: 5| Step: 2
Training loss: 0.05947086960077286
Validation loss: 1.5709617907001125

Epoch: 5| Step: 3
Training loss: 0.08557593077421188
Validation loss: 1.5835115345575477

Epoch: 5| Step: 4
Training loss: 0.06118589639663696
Validation loss: 1.5797274702338762

Epoch: 5| Step: 5
Training loss: 0.10614931583404541
Validation loss: 1.5850579264343425

Epoch: 5| Step: 6
Training loss: 0.11781029403209686
Validation loss: 1.603637755558055

Epoch: 5| Step: 7
Training loss: 0.11052729934453964
Validation loss: 1.5872957911542667

Epoch: 5| Step: 8
Training loss: 0.07737486064434052
Validation loss: 1.5693280639186982

Epoch: 5| Step: 9
Training loss: 0.10721435397863388
Validation loss: 1.5946182140740015

Epoch: 5| Step: 10
Training loss: 0.06390248239040375
Validation loss: 1.5999119153586767

Epoch: 600| Step: 0
Training loss: 0.0990157350897789
Validation loss: 1.5653122791679956

Epoch: 5| Step: 1
Training loss: 0.09393159300088882
Validation loss: 1.562278684108488

Epoch: 5| Step: 2
Training loss: 0.07312171906232834
Validation loss: 1.5710308679970362

Epoch: 5| Step: 3
Training loss: 0.06769868731498718
Validation loss: 1.5979000727335613

Epoch: 5| Step: 4
Training loss: 0.1251581907272339
Validation loss: 1.5533442176798338

Epoch: 5| Step: 5
Training loss: 0.08792641013860703
Validation loss: 1.542305177257907

Epoch: 5| Step: 6
Training loss: 0.08789081871509552
Validation loss: 1.5401110469654042

Epoch: 5| Step: 7
Training loss: 0.11258824169635773
Validation loss: 1.5611455184157177

Epoch: 5| Step: 8
Training loss: 0.07243306189775467
Validation loss: 1.5624923827827617

Epoch: 5| Step: 9
Training loss: 0.06126808375120163
Validation loss: 1.5583866591094642

Epoch: 5| Step: 10
Training loss: 0.06915569305419922
Validation loss: 1.5870700164507794

Epoch: 601| Step: 0
Training loss: 0.07532549649477005
Validation loss: 1.566128412882487

Epoch: 5| Step: 1
Training loss: 0.06125606968998909
Validation loss: 1.5582038946049188

Epoch: 5| Step: 2
Training loss: 0.060926735401153564
Validation loss: 1.5732025792521815

Epoch: 5| Step: 3
Training loss: 0.08279715478420258
Validation loss: 1.5464957221861808

Epoch: 5| Step: 4
Training loss: 0.06263326108455658
Validation loss: 1.5461901118678432

Epoch: 5| Step: 5
Training loss: 0.0890648290514946
Validation loss: 1.5952281900631484

Epoch: 5| Step: 6
Training loss: 0.05571603775024414
Validation loss: 1.5480823247663436

Epoch: 5| Step: 7
Training loss: 0.12954100966453552
Validation loss: 1.553831410664384

Epoch: 5| Step: 8
Training loss: 0.0907764583826065
Validation loss: 1.5750864596777066

Epoch: 5| Step: 9
Training loss: 0.08487436175346375
Validation loss: 1.5901756414803125

Epoch: 5| Step: 10
Training loss: 0.05304841697216034
Validation loss: 1.5787226666686356

Epoch: 602| Step: 0
Training loss: 0.08345283567905426
Validation loss: 1.5665934188391573

Epoch: 5| Step: 1
Training loss: 0.09237198531627655
Validation loss: 1.5844145000621837

Epoch: 5| Step: 2
Training loss: 0.10194985568523407
Validation loss: 1.593872574067885

Epoch: 5| Step: 3
Training loss: 0.06487870216369629
Validation loss: 1.563075097658301

Epoch: 5| Step: 4
Training loss: 0.04310610517859459
Validation loss: 1.583302390190863

Epoch: 5| Step: 5
Training loss: 0.057148050516843796
Validation loss: 1.5863135764675755

Epoch: 5| Step: 6
Training loss: 0.07667313516139984
Validation loss: 1.6304814828339445

Epoch: 5| Step: 7
Training loss: 0.09724485129117966
Validation loss: 1.6099991977855723

Epoch: 5| Step: 8
Training loss: 0.1085490733385086
Validation loss: 1.615413893935501

Epoch: 5| Step: 9
Training loss: 0.10972201824188232
Validation loss: 1.6317315268260177

Epoch: 5| Step: 10
Training loss: 0.06903637200593948
Validation loss: 1.6154617276242984

Epoch: 603| Step: 0
Training loss: 0.06233227998018265
Validation loss: 1.611590112409284

Epoch: 5| Step: 1
Training loss: 0.1125938668847084
Validation loss: 1.5948200456557735

Epoch: 5| Step: 2
Training loss: 0.0634428933262825
Validation loss: 1.5557952029730684

Epoch: 5| Step: 3
Training loss: 0.09611141681671143
Validation loss: 1.5708145204410757

Epoch: 5| Step: 4
Training loss: 0.09852121770381927
Validation loss: 1.574768904716738

Epoch: 5| Step: 5
Training loss: 0.07119886577129364
Validation loss: 1.555343859939165

Epoch: 5| Step: 6
Training loss: 0.11271146684885025
Validation loss: 1.5723499431405017

Epoch: 5| Step: 7
Training loss: 0.042658206075429916
Validation loss: 1.5804543264450566

Epoch: 5| Step: 8
Training loss: 0.1031247153878212
Validation loss: 1.5857635172464515

Epoch: 5| Step: 9
Training loss: 0.05812215059995651
Validation loss: 1.5489480469816475

Epoch: 5| Step: 10
Training loss: 0.06214798241853714
Validation loss: 1.5529626248985209

Epoch: 604| Step: 0
Training loss: 0.08735020458698273
Validation loss: 1.526237060946803

Epoch: 5| Step: 1
Training loss: 0.07346826791763306
Validation loss: 1.5609086636574037

Epoch: 5| Step: 2
Training loss: 0.05008891224861145
Validation loss: 1.545296480578761

Epoch: 5| Step: 3
Training loss: 0.07813675701618195
Validation loss: 1.5427143714761222

Epoch: 5| Step: 4
Training loss: 0.07039378583431244
Validation loss: 1.5598353711507653

Epoch: 5| Step: 5
Training loss: 0.08813127875328064
Validation loss: 1.5527707851061257

Epoch: 5| Step: 6
Training loss: 0.07908748835325241
Validation loss: 1.5434185933041316

Epoch: 5| Step: 7
Training loss: 0.0869891420006752
Validation loss: 1.5383948010783042

Epoch: 5| Step: 8
Training loss: 0.11620090901851654
Validation loss: 1.5507268251911286

Epoch: 5| Step: 9
Training loss: 0.0519685372710228
Validation loss: 1.5753506857861754

Epoch: 5| Step: 10
Training loss: 0.08998177945613861
Validation loss: 1.5480204577087073

Epoch: 605| Step: 0
Training loss: 0.06875865906476974
Validation loss: 1.5543602429410464

Epoch: 5| Step: 1
Training loss: 0.05540568381547928
Validation loss: 1.5849741581947572

Epoch: 5| Step: 2
Training loss: 0.07731839269399643
Validation loss: 1.5365569072384988

Epoch: 5| Step: 3
Training loss: 0.08557230979204178
Validation loss: 1.5486864659094042

Epoch: 5| Step: 4
Training loss: 0.05764668062329292
Validation loss: 1.5344359592724872

Epoch: 5| Step: 5
Training loss: 0.1099051684141159
Validation loss: 1.5422800189705306

Epoch: 5| Step: 6
Training loss: 0.043840326368808746
Validation loss: 1.5421102021330146

Epoch: 5| Step: 7
Training loss: 0.05939982086420059
Validation loss: 1.5503723711095831

Epoch: 5| Step: 8
Training loss: 0.08429442346096039
Validation loss: 1.577220307883396

Epoch: 5| Step: 9
Training loss: 0.0802842229604721
Validation loss: 1.5577851956890476

Epoch: 5| Step: 10
Training loss: 0.0839185118675232
Validation loss: 1.568928974930958

Epoch: 606| Step: 0
Training loss: 0.05584989860653877
Validation loss: 1.5649631420771282

Epoch: 5| Step: 1
Training loss: 0.07210125029087067
Validation loss: 1.5658402173749861

Epoch: 5| Step: 2
Training loss: 0.08958286046981812
Validation loss: 1.59039907686172

Epoch: 5| Step: 3
Training loss: 0.0660911351442337
Validation loss: 1.57017429413334

Epoch: 5| Step: 4
Training loss: 0.12525787949562073
Validation loss: 1.5887243760529386

Epoch: 5| Step: 5
Training loss: 0.07255958765745163
Validation loss: 1.5517281447687457

Epoch: 5| Step: 6
Training loss: 0.11792244762182236
Validation loss: 1.582207973285388

Epoch: 5| Step: 7
Training loss: 0.07184281945228577
Validation loss: 1.5891600731880433

Epoch: 5| Step: 8
Training loss: 0.038844238966703415
Validation loss: 1.6130348533712409

Epoch: 5| Step: 9
Training loss: 0.043526362627744675
Validation loss: 1.583718353702176

Epoch: 5| Step: 10
Training loss: 0.05330196022987366
Validation loss: 1.5732776772591375

Epoch: 607| Step: 0
Training loss: 0.06507609784603119
Validation loss: 1.5972879855863509

Epoch: 5| Step: 1
Training loss: 0.09631097316741943
Validation loss: 1.5799281930410733

Epoch: 5| Step: 2
Training loss: 0.05202918499708176
Validation loss: 1.5746415174135597

Epoch: 5| Step: 3
Training loss: 0.07231434434652328
Validation loss: 1.5921715946607693

Epoch: 5| Step: 4
Training loss: 0.06876050680875778
Validation loss: 1.5791238495098647

Epoch: 5| Step: 5
Training loss: 0.06689207255840302
Validation loss: 1.5807672956938386

Epoch: 5| Step: 6
Training loss: 0.06653345376253128
Validation loss: 1.5725542191536195

Epoch: 5| Step: 7
Training loss: 0.03744760900735855
Validation loss: 1.5715438217245123

Epoch: 5| Step: 8
Training loss: 0.12699471414089203
Validation loss: 1.582487771587987

Epoch: 5| Step: 9
Training loss: 0.07157222926616669
Validation loss: 1.5567253956230738

Epoch: 5| Step: 10
Training loss: 0.06100569665431976
Validation loss: 1.5600005785624187

Epoch: 608| Step: 0
Training loss: 0.08107097446918488
Validation loss: 1.5609480181047994

Epoch: 5| Step: 1
Training loss: 0.06716489046812057
Validation loss: 1.558573556202714

Epoch: 5| Step: 2
Training loss: 0.05531218647956848
Validation loss: 1.5561297542305403

Epoch: 5| Step: 3
Training loss: 0.07005243003368378
Validation loss: 1.53883284138095

Epoch: 5| Step: 4
Training loss: 0.11475733667612076
Validation loss: 1.548806909591921

Epoch: 5| Step: 5
Training loss: 0.07907097041606903
Validation loss: 1.5622296564040645

Epoch: 5| Step: 6
Training loss: 0.07128247618675232
Validation loss: 1.5735260825003348

Epoch: 5| Step: 7
Training loss: 0.09368796646595001
Validation loss: 1.5592912025349115

Epoch: 5| Step: 8
Training loss: 0.049058396369218826
Validation loss: 1.5550185634243874

Epoch: 5| Step: 9
Training loss: 0.060020674020051956
Validation loss: 1.5862748622894287

Epoch: 5| Step: 10
Training loss: 0.08271603286266327
Validation loss: 1.5948635890919676

Epoch: 609| Step: 0
Training loss: 0.08557969331741333
Validation loss: 1.596294682513001

Epoch: 5| Step: 1
Training loss: 0.07324231415987015
Validation loss: 1.5861029150665447

Epoch: 5| Step: 2
Training loss: 0.08953628689050674
Validation loss: 1.5951945621480224

Epoch: 5| Step: 3
Training loss: 0.09443236887454987
Validation loss: 1.5604920489813692

Epoch: 5| Step: 4
Training loss: 0.06491721421480179
Validation loss: 1.5618531703948975

Epoch: 5| Step: 5
Training loss: 0.04916638880968094
Validation loss: 1.5603280810899631

Epoch: 5| Step: 6
Training loss: 0.07360057532787323
Validation loss: 1.5789766901282853

Epoch: 5| Step: 7
Training loss: 0.12566418945789337
Validation loss: 1.5665734326967629

Epoch: 5| Step: 8
Training loss: 0.052426017820835114
Validation loss: 1.5834407537214217

Epoch: 5| Step: 9
Training loss: 0.05808704346418381
Validation loss: 1.5727688586840065

Epoch: 5| Step: 10
Training loss: 0.07364765554666519
Validation loss: 1.585500705626703

Epoch: 610| Step: 0
Training loss: 0.04880838841199875
Validation loss: 1.594662521475105

Epoch: 5| Step: 1
Training loss: 0.062452949583530426
Validation loss: 1.560274556759865

Epoch: 5| Step: 2
Training loss: 0.08450448513031006
Validation loss: 1.5822843095307708

Epoch: 5| Step: 3
Training loss: 0.08321978896856308
Validation loss: 1.570624122055628

Epoch: 5| Step: 4
Training loss: 0.06492510437965393
Validation loss: 1.5694027805841098

Epoch: 5| Step: 5
Training loss: 0.07122891396284103
Validation loss: 1.5725831421472694

Epoch: 5| Step: 6
Training loss: 0.08925206959247589
Validation loss: 1.5707148980068903

Epoch: 5| Step: 7
Training loss: 0.08331580460071564
Validation loss: 1.574465222256158

Epoch: 5| Step: 8
Training loss: 0.07635484635829926
Validation loss: 1.576826617281924

Epoch: 5| Step: 9
Training loss: 0.1030845046043396
Validation loss: 1.5768054557102982

Epoch: 5| Step: 10
Training loss: 0.07117700576782227
Validation loss: 1.5659352117969143

Epoch: 611| Step: 0
Training loss: 0.06385423243045807
Validation loss: 1.5557339934892551

Epoch: 5| Step: 1
Training loss: 0.057467538863420486
Validation loss: 1.5665817978561565

Epoch: 5| Step: 2
Training loss: 0.08627752214670181
Validation loss: 1.5377959461622341

Epoch: 5| Step: 3
Training loss: 0.06560740619897842
Validation loss: 1.5716490155907088

Epoch: 5| Step: 4
Training loss: 0.06882838159799576
Validation loss: 1.5724908946662821

Epoch: 5| Step: 5
Training loss: 0.03517358750104904
Validation loss: 1.580759831013218

Epoch: 5| Step: 6
Training loss: 0.07570572197437286
Validation loss: 1.5440265106898483

Epoch: 5| Step: 7
Training loss: 0.07435683906078339
Validation loss: 1.551994546767204

Epoch: 5| Step: 8
Training loss: 0.0699523538351059
Validation loss: 1.5376241219941007

Epoch: 5| Step: 9
Training loss: 0.09700902551412582
Validation loss: 1.5542552669843037

Epoch: 5| Step: 10
Training loss: 0.09283775091171265
Validation loss: 1.5336390144081526

Epoch: 612| Step: 0
Training loss: 0.11577310413122177
Validation loss: 1.532409966632884

Epoch: 5| Step: 1
Training loss: 0.09625954180955887
Validation loss: 1.527095047376489

Epoch: 5| Step: 2
Training loss: 0.06595306843519211
Validation loss: 1.5221617055195633

Epoch: 5| Step: 3
Training loss: 0.10421371459960938
Validation loss: 1.5111792625919465

Epoch: 5| Step: 4
Training loss: 0.07695811241865158
Validation loss: 1.5408972527391167

Epoch: 5| Step: 5
Training loss: 0.0695216953754425
Validation loss: 1.5280426445827688

Epoch: 5| Step: 6
Training loss: 0.08249654620885849
Validation loss: 1.5221911373958792

Epoch: 5| Step: 7
Training loss: 0.05016857385635376
Validation loss: 1.5094405220400902

Epoch: 5| Step: 8
Training loss: 0.06404326856136322
Validation loss: 1.5230287877462243

Epoch: 5| Step: 9
Training loss: 0.04015788808465004
Validation loss: 1.5421718141084075

Epoch: 5| Step: 10
Training loss: 0.061973247677087784
Validation loss: 1.5422729529360288

Epoch: 613| Step: 0
Training loss: 0.06735841929912567
Validation loss: 1.5547344838419268

Epoch: 5| Step: 1
Training loss: 0.06257854402065277
Validation loss: 1.5655097012878747

Epoch: 5| Step: 2
Training loss: 0.0658043846487999
Validation loss: 1.5743116832548572

Epoch: 5| Step: 3
Training loss: 0.12379304319620132
Validation loss: 1.5477965903538529

Epoch: 5| Step: 4
Training loss: 0.0935228019952774
Validation loss: 1.562955742241234

Epoch: 5| Step: 5
Training loss: 0.08251623809337616
Validation loss: 1.5444899938439811

Epoch: 5| Step: 6
Training loss: 0.08026865869760513
Validation loss: 1.5497737110302012

Epoch: 5| Step: 7
Training loss: 0.035653360188007355
Validation loss: 1.5495370857177242

Epoch: 5| Step: 8
Training loss: 0.05457180738449097
Validation loss: 1.522970259830516

Epoch: 5| Step: 9
Training loss: 0.0472990982234478
Validation loss: 1.5470819768085275

Epoch: 5| Step: 10
Training loss: 0.12227436900138855
Validation loss: 1.5158029910056823

Epoch: 614| Step: 0
Training loss: 0.06862837076187134
Validation loss: 1.5554720560709636

Epoch: 5| Step: 1
Training loss: 0.17959998548030853
Validation loss: 1.57973567516573

Epoch: 5| Step: 2
Training loss: 0.05798829719424248
Validation loss: 1.577872395515442

Epoch: 5| Step: 3
Training loss: 0.09381546080112457
Validation loss: 1.583150953374883

Epoch: 5| Step: 4
Training loss: 0.08162045478820801
Validation loss: 1.549024329390577

Epoch: 5| Step: 5
Training loss: 0.04463016241788864
Validation loss: 1.5472983160326559

Epoch: 5| Step: 6
Training loss: 0.06693700700998306
Validation loss: 1.5631783675122004

Epoch: 5| Step: 7
Training loss: 0.09103307127952576
Validation loss: 1.5342658091616888

Epoch: 5| Step: 8
Training loss: 0.07344220578670502
Validation loss: 1.5037593303188201

Epoch: 5| Step: 9
Training loss: 0.056850600987672806
Validation loss: 1.5163396045725832

Epoch: 5| Step: 10
Training loss: 0.06742292642593384
Validation loss: 1.528881428062275

Epoch: 615| Step: 0
Training loss: 0.0560605525970459
Validation loss: 1.5321374888061194

Epoch: 5| Step: 1
Training loss: 0.08297306299209595
Validation loss: 1.5173073737852034

Epoch: 5| Step: 2
Training loss: 0.06605386734008789
Validation loss: 1.5644954609614548

Epoch: 5| Step: 3
Training loss: 0.09957712143659592
Validation loss: 1.5496975324487174

Epoch: 5| Step: 4
Training loss: 0.11921308189630508
Validation loss: 1.5527416172847952

Epoch: 5| Step: 5
Training loss: 0.12599687278270721
Validation loss: 1.5613345664034608

Epoch: 5| Step: 6
Training loss: 0.06578205525875092
Validation loss: 1.5316943045585387

Epoch: 5| Step: 7
Training loss: 0.0695204958319664
Validation loss: 1.576340853527028

Epoch: 5| Step: 8
Training loss: 0.09495201706886292
Validation loss: 1.5876267379330051

Epoch: 5| Step: 9
Training loss: 0.04556873440742493
Validation loss: 1.5637287811566425

Epoch: 5| Step: 10
Training loss: 0.06805014610290527
Validation loss: 1.5531845067137031

Epoch: 616| Step: 0
Training loss: 0.09026060253381729
Validation loss: 1.5552978131078905

Epoch: 5| Step: 1
Training loss: 0.04526805132627487
Validation loss: 1.5689054535281273

Epoch: 5| Step: 2
Training loss: 0.08587536215782166
Validation loss: 1.5568093317811207

Epoch: 5| Step: 3
Training loss: 0.06543119996786118
Validation loss: 1.5528469342057423

Epoch: 5| Step: 4
Training loss: 0.08642590045928955
Validation loss: 1.5809190683467413

Epoch: 5| Step: 5
Training loss: 0.10753905773162842
Validation loss: 1.5549611404377928

Epoch: 5| Step: 6
Training loss: 0.10011197626590729
Validation loss: 1.5482033644953082

Epoch: 5| Step: 7
Training loss: 0.06209395453333855
Validation loss: 1.5368354397435342

Epoch: 5| Step: 8
Training loss: 0.06312777101993561
Validation loss: 1.5442793459020636

Epoch: 5| Step: 9
Training loss: 0.08617015182971954
Validation loss: 1.5403449343096824

Epoch: 5| Step: 10
Training loss: 0.056144118309020996
Validation loss: 1.5532426885379258

Epoch: 617| Step: 0
Training loss: 0.0540715754032135
Validation loss: 1.536958626521531

Epoch: 5| Step: 1
Training loss: 0.13014598190784454
Validation loss: 1.563361212771426

Epoch: 5| Step: 2
Training loss: 0.0769951269030571
Validation loss: 1.5440457059491066

Epoch: 5| Step: 3
Training loss: 0.028650909662246704
Validation loss: 1.5349503242841331

Epoch: 5| Step: 4
Training loss: 0.0590856596827507
Validation loss: 1.533953038595056

Epoch: 5| Step: 5
Training loss: 0.044085439294576645
Validation loss: 1.5424087970487532

Epoch: 5| Step: 6
Training loss: 0.06785950809717178
Validation loss: 1.5485739938674434

Epoch: 5| Step: 7
Training loss: 0.0692019835114479
Validation loss: 1.5770519138664327

Epoch: 5| Step: 8
Training loss: 0.06367689371109009
Validation loss: 1.5593647764575096

Epoch: 5| Step: 9
Training loss: 0.07353778183460236
Validation loss: 1.5562448065768006

Epoch: 5| Step: 10
Training loss: 0.07985790818929672
Validation loss: 1.559836538889075

Epoch: 618| Step: 0
Training loss: 0.06120102480053902
Validation loss: 1.5625208334256244

Epoch: 5| Step: 1
Training loss: 0.08096571266651154
Validation loss: 1.575549267953442

Epoch: 5| Step: 2
Training loss: 0.07310903072357178
Validation loss: 1.5692578067061722

Epoch: 5| Step: 3
Training loss: 0.07330120354890823
Validation loss: 1.5485492008988575

Epoch: 5| Step: 4
Training loss: 0.07551376521587372
Validation loss: 1.5735477170636576

Epoch: 5| Step: 5
Training loss: 0.15338292717933655
Validation loss: 1.5619510495534508

Epoch: 5| Step: 6
Training loss: 0.10664526373147964
Validation loss: 1.5436509937368414

Epoch: 5| Step: 7
Training loss: 0.06329437345266342
Validation loss: 1.526272166159845

Epoch: 5| Step: 8
Training loss: 0.041234247386455536
Validation loss: 1.5243909307705459

Epoch: 5| Step: 9
Training loss: 0.051398444920778275
Validation loss: 1.5216381793381066

Epoch: 5| Step: 10
Training loss: 0.0648338720202446
Validation loss: 1.5458210360619329

Epoch: 619| Step: 0
Training loss: 0.04672668129205704
Validation loss: 1.5405197784464846

Epoch: 5| Step: 1
Training loss: 0.03649799898266792
Validation loss: 1.5498060744295838

Epoch: 5| Step: 2
Training loss: 0.06926790624856949
Validation loss: 1.554654566190576

Epoch: 5| Step: 3
Training loss: 0.14722809195518494
Validation loss: 1.569515771763299

Epoch: 5| Step: 4
Training loss: 0.058846164494752884
Validation loss: 1.52926250555182

Epoch: 5| Step: 5
Training loss: 0.09318944066762924
Validation loss: 1.5683230546212965

Epoch: 5| Step: 6
Training loss: 0.07235501706600189
Validation loss: 1.5526753587107505

Epoch: 5| Step: 7
Training loss: 0.0828005000948906
Validation loss: 1.5273062836739324

Epoch: 5| Step: 8
Training loss: 0.101119264960289
Validation loss: 1.4981944669959366

Epoch: 5| Step: 9
Training loss: 0.08152703940868378
Validation loss: 1.5134517191558756

Epoch: 5| Step: 10
Training loss: 0.06544484198093414
Validation loss: 1.5009128816666142

Epoch: 620| Step: 0
Training loss: 0.08517788350582123
Validation loss: 1.517567292977405

Epoch: 5| Step: 1
Training loss: 0.10142078250646591
Validation loss: 1.5341552636956657

Epoch: 5| Step: 2
Training loss: 0.1156216636300087
Validation loss: 1.5489782735865603

Epoch: 5| Step: 3
Training loss: 0.06512393802404404
Validation loss: 1.5452606883100284

Epoch: 5| Step: 4
Training loss: 0.052587248384952545
Validation loss: 1.5550986887306295

Epoch: 5| Step: 5
Training loss: 0.0565125048160553
Validation loss: 1.5358012760839155

Epoch: 5| Step: 6
Training loss: 0.07279971241950989
Validation loss: 1.5341442426045735

Epoch: 5| Step: 7
Training loss: 0.05013635754585266
Validation loss: 1.5481672376714728

Epoch: 5| Step: 8
Training loss: 0.11495226621627808
Validation loss: 1.5160190264383953

Epoch: 5| Step: 9
Training loss: 0.05525795370340347
Validation loss: 1.5388117490276214

Epoch: 5| Step: 10
Training loss: 0.04126826301217079
Validation loss: 1.5197645015614007

Epoch: 621| Step: 0
Training loss: 0.07029151171445847
Validation loss: 1.5168781434336016

Epoch: 5| Step: 1
Training loss: 0.06366530805826187
Validation loss: 1.509599893964747

Epoch: 5| Step: 2
Training loss: 0.044461943209171295
Validation loss: 1.5477909811081425

Epoch: 5| Step: 3
Training loss: 0.09130740165710449
Validation loss: 1.5329793153270599

Epoch: 5| Step: 4
Training loss: 0.06505072116851807
Validation loss: 1.562253584143936

Epoch: 5| Step: 5
Training loss: 0.06052043288946152
Validation loss: 1.5543893376986186

Epoch: 5| Step: 6
Training loss: 0.05395998805761337
Validation loss: 1.537401489032212

Epoch: 5| Step: 7
Training loss: 0.047568973153829575
Validation loss: 1.5469925659959034

Epoch: 5| Step: 8
Training loss: 0.08702345192432404
Validation loss: 1.5550597021656651

Epoch: 5| Step: 9
Training loss: 0.053226619958877563
Validation loss: 1.5316846011787333

Epoch: 5| Step: 10
Training loss: 0.06583163142204285
Validation loss: 1.5386200239581447

Epoch: 622| Step: 0
Training loss: 0.07622470706701279
Validation loss: 1.5072266209510066

Epoch: 5| Step: 1
Training loss: 0.1204637885093689
Validation loss: 1.5271647848108763

Epoch: 5| Step: 2
Training loss: 0.07096956670284271
Validation loss: 1.5268364978092972

Epoch: 5| Step: 3
Training loss: 0.059313200414180756
Validation loss: 1.5142794950034029

Epoch: 5| Step: 4
Training loss: 0.06279834359884262
Validation loss: 1.5143497092749483

Epoch: 5| Step: 5
Training loss: 0.07511985301971436
Validation loss: 1.5308129415717175

Epoch: 5| Step: 6
Training loss: 0.08959276229143143
Validation loss: 1.5509922094242548

Epoch: 5| Step: 7
Training loss: 0.04915899038314819
Validation loss: 1.5733805548760198

Epoch: 5| Step: 8
Training loss: 0.06819372624158859
Validation loss: 1.5886397771937872

Epoch: 5| Step: 9
Training loss: 0.11587698757648468
Validation loss: 1.5516964671432332

Epoch: 5| Step: 10
Training loss: 0.0696122869849205
Validation loss: 1.5800414521207091

Epoch: 623| Step: 0
Training loss: 0.07286620140075684
Validation loss: 1.5736744890930832

Epoch: 5| Step: 1
Training loss: 0.06488647311925888
Validation loss: 1.5294694580057615

Epoch: 5| Step: 2
Training loss: 0.0685172975063324
Validation loss: 1.528619440652991

Epoch: 5| Step: 3
Training loss: 0.08124944567680359
Validation loss: 1.5502271421494023

Epoch: 5| Step: 4
Training loss: 0.10016441345214844
Validation loss: 1.518874809306155

Epoch: 5| Step: 5
Training loss: 0.10135960578918457
Validation loss: 1.5192419021360335

Epoch: 5| Step: 6
Training loss: 0.06920655816793442
Validation loss: 1.5543614331112112

Epoch: 5| Step: 7
Training loss: 0.07387930154800415
Validation loss: 1.5412379016158402

Epoch: 5| Step: 8
Training loss: 0.08899688720703125
Validation loss: 1.5344471316183768

Epoch: 5| Step: 9
Training loss: 0.03216509893536568
Validation loss: 1.5372100876223656

Epoch: 5| Step: 10
Training loss: 0.058628592640161514
Validation loss: 1.5505477356654342

Epoch: 624| Step: 0
Training loss: 0.05103624612092972
Validation loss: 1.5385828172006915

Epoch: 5| Step: 1
Training loss: 0.09482912719249725
Validation loss: 1.5426728174250612

Epoch: 5| Step: 2
Training loss: 0.07942335307598114
Validation loss: 1.5489629263518958

Epoch: 5| Step: 3
Training loss: 0.09256357699632645
Validation loss: 1.5569877445056874

Epoch: 5| Step: 4
Training loss: 0.09286954998970032
Validation loss: 1.5418203748682493

Epoch: 5| Step: 5
Training loss: 0.0859985426068306
Validation loss: 1.534573479365277

Epoch: 5| Step: 6
Training loss: 0.052547257393598557
Validation loss: 1.5175085952205043

Epoch: 5| Step: 7
Training loss: 0.045061785727739334
Validation loss: 1.5221969632692234

Epoch: 5| Step: 8
Training loss: 0.05679015442728996
Validation loss: 1.508558734770744

Epoch: 5| Step: 9
Training loss: 0.06559927761554718
Validation loss: 1.519075632095337

Epoch: 5| Step: 10
Training loss: 0.07415224611759186
Validation loss: 1.5299010122975996

Epoch: 625| Step: 0
Training loss: 0.05619123578071594
Validation loss: 1.5513943843944098

Epoch: 5| Step: 1
Training loss: 0.0828588455915451
Validation loss: 1.5193555496072257

Epoch: 5| Step: 2
Training loss: 0.06534892320632935
Validation loss: 1.5290905967835458

Epoch: 5| Step: 3
Training loss: 0.12033329904079437
Validation loss: 1.5224625615663425

Epoch: 5| Step: 4
Training loss: 0.07967022806406021
Validation loss: 1.5340153068624518

Epoch: 5| Step: 5
Training loss: 0.051081061363220215
Validation loss: 1.519886351400806

Epoch: 5| Step: 6
Training loss: 0.06681923568248749
Validation loss: 1.5349472645790345

Epoch: 5| Step: 7
Training loss: 0.0669204443693161
Validation loss: 1.5323556033513879

Epoch: 5| Step: 8
Training loss: 0.06354416906833649
Validation loss: 1.5330932550532843

Epoch: 5| Step: 9
Training loss: 0.08252568542957306
Validation loss: 1.5417737268632459

Epoch: 5| Step: 10
Training loss: 0.054488830268383026
Validation loss: 1.5144823866505777

Epoch: 626| Step: 0
Training loss: 0.1099475771188736
Validation loss: 1.5212606319817163

Epoch: 5| Step: 1
Training loss: 0.04316118359565735
Validation loss: 1.5055068949217438

Epoch: 5| Step: 2
Training loss: 0.04989958554506302
Validation loss: 1.526722091500477

Epoch: 5| Step: 3
Training loss: 0.06833507120609283
Validation loss: 1.5057401554558867

Epoch: 5| Step: 4
Training loss: 0.07407515496015549
Validation loss: 1.5255155819718555

Epoch: 5| Step: 5
Training loss: 0.046875931322574615
Validation loss: 1.5385996987742763

Epoch: 5| Step: 6
Training loss: 0.07819117605686188
Validation loss: 1.5274213642202399

Epoch: 5| Step: 7
Training loss: 0.06640113890171051
Validation loss: 1.5295318198460404

Epoch: 5| Step: 8
Training loss: 0.07841440290212631
Validation loss: 1.4970385669380106

Epoch: 5| Step: 9
Training loss: 0.10404577106237411
Validation loss: 1.5457027522466515

Epoch: 5| Step: 10
Training loss: 0.048269372433423996
Validation loss: 1.5375258371394167

Epoch: 627| Step: 0
Training loss: 0.06871252506971359
Validation loss: 1.5152868045273649

Epoch: 5| Step: 1
Training loss: 0.06505922973155975
Validation loss: 1.5349979605726016

Epoch: 5| Step: 2
Training loss: 0.07893751561641693
Validation loss: 1.5051470571948635

Epoch: 5| Step: 3
Training loss: 0.04870337247848511
Validation loss: 1.5050455722757565

Epoch: 5| Step: 4
Training loss: 0.10204379260540009
Validation loss: 1.5041332437146095

Epoch: 5| Step: 5
Training loss: 0.09967942535877228
Validation loss: 1.4989754999837568

Epoch: 5| Step: 6
Training loss: 0.11841456592082977
Validation loss: 1.5385152037425707

Epoch: 5| Step: 7
Training loss: 0.06400101631879807
Validation loss: 1.5417481084023752

Epoch: 5| Step: 8
Training loss: 0.08087112009525299
Validation loss: 1.5215426183515979

Epoch: 5| Step: 9
Training loss: 0.0657794252038002
Validation loss: 1.511034401514197

Epoch: 5| Step: 10
Training loss: 0.05522279441356659
Validation loss: 1.5536169992980136

Epoch: 628| Step: 0
Training loss: 0.08085270971059799
Validation loss: 1.5506517092386882

Epoch: 5| Step: 1
Training loss: 0.07141607999801636
Validation loss: 1.5511804985743698

Epoch: 5| Step: 2
Training loss: 0.05533513426780701
Validation loss: 1.5582123071916643

Epoch: 5| Step: 3
Training loss: 0.06599821150302887
Validation loss: 1.552241466378653

Epoch: 5| Step: 4
Training loss: 0.04932563751935959
Validation loss: 1.5265410894988685

Epoch: 5| Step: 5
Training loss: 0.09191878139972687
Validation loss: 1.5271569157159457

Epoch: 5| Step: 6
Training loss: 0.1460385024547577
Validation loss: 1.5452363016784831

Epoch: 5| Step: 7
Training loss: 0.05125110596418381
Validation loss: 1.5677146578347811

Epoch: 5| Step: 8
Training loss: 0.06753058731555939
Validation loss: 1.5322367760442919

Epoch: 5| Step: 9
Training loss: 0.0631079226732254
Validation loss: 1.538880262323605

Epoch: 5| Step: 10
Training loss: 0.055488765239715576
Validation loss: 1.547686937034771

Epoch: 629| Step: 0
Training loss: 0.052793342620134354
Validation loss: 1.5574269833103302

Epoch: 5| Step: 1
Training loss: 0.050761133432388306
Validation loss: 1.5523089619093045

Epoch: 5| Step: 2
Training loss: 0.050077278167009354
Validation loss: 1.5523040012646747

Epoch: 5| Step: 3
Training loss: 0.10692435503005981
Validation loss: 1.5482905744224467

Epoch: 5| Step: 4
Training loss: 0.07682802528142929
Validation loss: 1.530855223696719

Epoch: 5| Step: 5
Training loss: 0.08143648505210876
Validation loss: 1.540507129443589

Epoch: 5| Step: 6
Training loss: 0.04220873862504959
Validation loss: 1.531098731102482

Epoch: 5| Step: 7
Training loss: 0.062487415969371796
Validation loss: 1.5364993926017516

Epoch: 5| Step: 8
Training loss: 0.06287572532892227
Validation loss: 1.5411668208337599

Epoch: 5| Step: 9
Training loss: 0.08416076749563217
Validation loss: 1.5319241874961442

Epoch: 5| Step: 10
Training loss: 0.05684283375740051
Validation loss: 1.5394547921355053

Epoch: 630| Step: 0
Training loss: 0.10148044675588608
Validation loss: 1.5441806277921122

Epoch: 5| Step: 1
Training loss: 0.09383735805749893
Validation loss: 1.533190555469964

Epoch: 5| Step: 2
Training loss: 0.07774220407009125
Validation loss: 1.526069043785013

Epoch: 5| Step: 3
Training loss: 0.09522483497858047
Validation loss: 1.5251204211224791

Epoch: 5| Step: 4
Training loss: 0.06447821110486984
Validation loss: 1.5179255162515948

Epoch: 5| Step: 5
Training loss: 0.05684946849942207
Validation loss: 1.538810763307797

Epoch: 5| Step: 6
Training loss: 0.05798681452870369
Validation loss: 1.52574973593476

Epoch: 5| Step: 7
Training loss: 0.054749298840761185
Validation loss: 1.5351282870897682

Epoch: 5| Step: 8
Training loss: 0.07313959300518036
Validation loss: 1.51295345060287

Epoch: 5| Step: 9
Training loss: 0.0346393808722496
Validation loss: 1.5383808215459187

Epoch: 5| Step: 10
Training loss: 0.045084141194820404
Validation loss: 1.4907560668965822

Epoch: 631| Step: 0
Training loss: 0.10890601575374603
Validation loss: 1.50237799075342

Epoch: 5| Step: 1
Training loss: 0.11665041744709015
Validation loss: 1.5174857147278324

Epoch: 5| Step: 2
Training loss: 0.06023913621902466
Validation loss: 1.514367441977224

Epoch: 5| Step: 3
Training loss: 0.05365882068872452
Validation loss: 1.5263648007505684

Epoch: 5| Step: 4
Training loss: 0.08538996428251266
Validation loss: 1.5402223384508522

Epoch: 5| Step: 5
Training loss: 0.0873812884092331
Validation loss: 1.5426394362603464

Epoch: 5| Step: 6
Training loss: 0.0695660412311554
Validation loss: 1.5001626431301076

Epoch: 5| Step: 7
Training loss: 0.04866456612944603
Validation loss: 1.5206266500616585

Epoch: 5| Step: 8
Training loss: 0.08784909546375275
Validation loss: 1.5383545269248307

Epoch: 5| Step: 9
Training loss: 0.07078585028648376
Validation loss: 1.5203694246148551

Epoch: 5| Step: 10
Training loss: 0.05689374729990959
Validation loss: 1.542789424619367

Epoch: 632| Step: 0
Training loss: 0.06056472659111023
Validation loss: 1.5427748746769403

Epoch: 5| Step: 1
Training loss: 0.03900015726685524
Validation loss: 1.544790872963526

Epoch: 5| Step: 2
Training loss: 0.08429732173681259
Validation loss: 1.5540314605159145

Epoch: 5| Step: 3
Training loss: 0.0872160792350769
Validation loss: 1.5591101620786934

Epoch: 5| Step: 4
Training loss: 0.07130464166402817
Validation loss: 1.5336963489491453

Epoch: 5| Step: 5
Training loss: 0.05310448259115219
Validation loss: 1.520317417319103

Epoch: 5| Step: 6
Training loss: 0.08314317464828491
Validation loss: 1.5295149869816278

Epoch: 5| Step: 7
Training loss: 0.0677676573395729
Validation loss: 1.5232191790816605

Epoch: 5| Step: 8
Training loss: 0.07717816531658173
Validation loss: 1.5219713898115261

Epoch: 5| Step: 9
Training loss: 0.04098677635192871
Validation loss: 1.5426432983849638

Epoch: 5| Step: 10
Training loss: 0.05599287524819374
Validation loss: 1.5356184615883777

Epoch: 633| Step: 0
Training loss: 0.06745775789022446
Validation loss: 1.5790379188394035

Epoch: 5| Step: 1
Training loss: 0.10662929713726044
Validation loss: 1.5691592962511125

Epoch: 5| Step: 2
Training loss: 0.06682322919368744
Validation loss: 1.5740546757175076

Epoch: 5| Step: 3
Training loss: 0.053249508142471313
Validation loss: 1.5438243509620748

Epoch: 5| Step: 4
Training loss: 0.04572412744164467
Validation loss: 1.5559855173992854

Epoch: 5| Step: 5
Training loss: 0.05374103784561157
Validation loss: 1.5458136925133326

Epoch: 5| Step: 6
Training loss: 0.1284739226102829
Validation loss: 1.5657633684014762

Epoch: 5| Step: 7
Training loss: 0.0635516494512558
Validation loss: 1.5402524138009677

Epoch: 5| Step: 8
Training loss: 0.05139810964465141
Validation loss: 1.527811167060688

Epoch: 5| Step: 9
Training loss: 0.0637425109744072
Validation loss: 1.5151413115121986

Epoch: 5| Step: 10
Training loss: 0.05596141144633293
Validation loss: 1.5155272163370603

Epoch: 634| Step: 0
Training loss: 0.0779234915971756
Validation loss: 1.5299671349986907

Epoch: 5| Step: 1
Training loss: 0.0811435803771019
Validation loss: 1.552731910059529

Epoch: 5| Step: 2
Training loss: 0.04765145853161812
Validation loss: 1.5552955109585997

Epoch: 5| Step: 3
Training loss: 0.12249473482370377
Validation loss: 1.567965151802186

Epoch: 5| Step: 4
Training loss: 0.0671607181429863
Validation loss: 1.5407765719198412

Epoch: 5| Step: 5
Training loss: 0.04356493055820465
Validation loss: 1.5220879694466949

Epoch: 5| Step: 6
Training loss: 0.09596303105354309
Validation loss: 1.534596936677092

Epoch: 5| Step: 7
Training loss: 0.0496695414185524
Validation loss: 1.5445118488803986

Epoch: 5| Step: 8
Training loss: 0.07273756712675095
Validation loss: 1.5517148894648398

Epoch: 5| Step: 9
Training loss: 0.07415982335805893
Validation loss: 1.5467693139148015

Epoch: 5| Step: 10
Training loss: 0.12746399641036987
Validation loss: 1.5427933046894688

Epoch: 635| Step: 0
Training loss: 0.06740716844797134
Validation loss: 1.5617682164715183

Epoch: 5| Step: 1
Training loss: 0.04757685586810112
Validation loss: 1.5362929349304528

Epoch: 5| Step: 2
Training loss: 0.0540592186152935
Validation loss: 1.5439730049461446

Epoch: 5| Step: 3
Training loss: 0.071721151471138
Validation loss: 1.5631286610839188

Epoch: 5| Step: 4
Training loss: 0.05202822759747505
Validation loss: 1.5800710724246116

Epoch: 5| Step: 5
Training loss: 0.0570799820125103
Validation loss: 1.5561720504555652

Epoch: 5| Step: 6
Training loss: 0.0869523137807846
Validation loss: 1.600805724820783

Epoch: 5| Step: 7
Training loss: 0.07375449687242508
Validation loss: 1.6006875730329944

Epoch: 5| Step: 8
Training loss: 0.09248343855142593
Validation loss: 1.589221567235967

Epoch: 5| Step: 9
Training loss: 0.07792922109365463
Validation loss: 1.564731054408576

Epoch: 5| Step: 10
Training loss: 0.056970804929733276
Validation loss: 1.5725671411842428

Epoch: 636| Step: 0
Training loss: 0.07753660529851913
Validation loss: 1.569038030921772

Epoch: 5| Step: 1
Training loss: 0.05583714321255684
Validation loss: 1.5508223041411369

Epoch: 5| Step: 2
Training loss: 0.08494936674833298
Validation loss: 1.5404926359012563

Epoch: 5| Step: 3
Training loss: 0.06066852807998657
Validation loss: 1.5544801245453537

Epoch: 5| Step: 4
Training loss: 0.09216853231191635
Validation loss: 1.52975433616228

Epoch: 5| Step: 5
Training loss: 0.06164415925741196
Validation loss: 1.5162535021381993

Epoch: 5| Step: 6
Training loss: 0.07377971708774567
Validation loss: 1.5058810146906043

Epoch: 5| Step: 7
Training loss: 0.10862831771373749
Validation loss: 1.5315252504041117

Epoch: 5| Step: 8
Training loss: 0.064673513174057
Validation loss: 1.5356078468343264

Epoch: 5| Step: 9
Training loss: 0.057244740426540375
Validation loss: 1.5274222999490716

Epoch: 5| Step: 10
Training loss: 0.07644112408161163
Validation loss: 1.4956414135553504

Epoch: 637| Step: 0
Training loss: 0.08562351763248444
Validation loss: 1.509160977537914

Epoch: 5| Step: 1
Training loss: 0.06333451718091965
Validation loss: 1.50938710986927

Epoch: 5| Step: 2
Training loss: 0.050599802285432816
Validation loss: 1.5229686690915016

Epoch: 5| Step: 3
Training loss: 0.06637958437204361
Validation loss: 1.5150446930239279

Epoch: 5| Step: 4
Training loss: 0.044599805027246475
Validation loss: 1.510737290946386

Epoch: 5| Step: 5
Training loss: 0.06368792057037354
Validation loss: 1.52604930375212

Epoch: 5| Step: 6
Training loss: 0.051581479609012604
Validation loss: 1.5435654629943192

Epoch: 5| Step: 7
Training loss: 0.11174186319112778
Validation loss: 1.543110119399204

Epoch: 5| Step: 8
Training loss: 0.07700468599796295
Validation loss: 1.5424449584817375

Epoch: 5| Step: 9
Training loss: 0.06170504540205002
Validation loss: 1.5438159563208138

Epoch: 5| Step: 10
Training loss: 0.0649753212928772
Validation loss: 1.5387014906893495

Epoch: 638| Step: 0
Training loss: 0.06747721880674362
Validation loss: 1.5086315729284798

Epoch: 5| Step: 1
Training loss: 0.1137305349111557
Validation loss: 1.5342988890986289

Epoch: 5| Step: 2
Training loss: 0.07898160815238953
Validation loss: 1.520244115142412

Epoch: 5| Step: 3
Training loss: 0.0618298277258873
Validation loss: 1.5066525884853896

Epoch: 5| Step: 4
Training loss: 0.07869945466518402
Validation loss: 1.5254481402776574

Epoch: 5| Step: 5
Training loss: 0.06398800760507584
Validation loss: 1.5089306562177596

Epoch: 5| Step: 6
Training loss: 0.060814905911684036
Validation loss: 1.530784394151421

Epoch: 5| Step: 7
Training loss: 0.08332821726799011
Validation loss: 1.547732812102123

Epoch: 5| Step: 8
Training loss: 0.03907114267349243
Validation loss: 1.5378522180741834

Epoch: 5| Step: 9
Training loss: 0.07495858520269394
Validation loss: 1.547012444465391

Epoch: 5| Step: 10
Training loss: 0.09259647876024246
Validation loss: 1.5592076727139053

Epoch: 639| Step: 0
Training loss: 0.06830794364213943
Validation loss: 1.5522150044800134

Epoch: 5| Step: 1
Training loss: 0.08344633877277374
Validation loss: 1.5201344566960489

Epoch: 5| Step: 2
Training loss: 0.07853670418262482
Validation loss: 1.5457212002046647

Epoch: 5| Step: 3
Training loss: 0.08676247298717499
Validation loss: 1.5780954796780822

Epoch: 5| Step: 4
Training loss: 0.04963887855410576
Validation loss: 1.5671344880134828

Epoch: 5| Step: 5
Training loss: 0.08002020418643951
Validation loss: 1.5615383527612174

Epoch: 5| Step: 6
Training loss: 0.05454146862030029
Validation loss: 1.5803305384933308

Epoch: 5| Step: 7
Training loss: 0.08244453370571136
Validation loss: 1.58412467920652

Epoch: 5| Step: 8
Training loss: 0.11316609382629395
Validation loss: 1.5746247512038036

Epoch: 5| Step: 9
Training loss: 0.07308366894721985
Validation loss: 1.6031180786830124

Epoch: 5| Step: 10
Training loss: 0.07959466427564621
Validation loss: 1.5785833558728617

Epoch: 640| Step: 0
Training loss: 0.06861631572246552
Validation loss: 1.5847563820500528

Epoch: 5| Step: 1
Training loss: 0.06669200956821442
Validation loss: 1.56772542384363

Epoch: 5| Step: 2
Training loss: 0.07086605578660965
Validation loss: 1.5589359780793548

Epoch: 5| Step: 3
Training loss: 0.04617500305175781
Validation loss: 1.5612091300308064

Epoch: 5| Step: 4
Training loss: 0.05520712584257126
Validation loss: 1.5493849041641399

Epoch: 5| Step: 5
Training loss: 0.08229988813400269
Validation loss: 1.5537249535642645

Epoch: 5| Step: 6
Training loss: 0.06653407961130142
Validation loss: 1.566126472206526

Epoch: 5| Step: 7
Training loss: 0.06181689351797104
Validation loss: 1.5597390115901988

Epoch: 5| Step: 8
Training loss: 0.0979158878326416
Validation loss: 1.568434484543339

Epoch: 5| Step: 9
Training loss: 0.04850754886865616
Validation loss: 1.5574790687971218

Epoch: 5| Step: 10
Training loss: 0.045210715383291245
Validation loss: 1.5456833788143691

Epoch: 641| Step: 0
Training loss: 0.06191002205014229
Validation loss: 1.5225943083404212

Epoch: 5| Step: 1
Training loss: 0.05032546445727348
Validation loss: 1.5331164354919105

Epoch: 5| Step: 2
Training loss: 0.052299391478300095
Validation loss: 1.4866253483679988

Epoch: 5| Step: 3
Training loss: 0.13402077555656433
Validation loss: 1.5083246141351678

Epoch: 5| Step: 4
Training loss: 0.07476873695850372
Validation loss: 1.5011406329370314

Epoch: 5| Step: 5
Training loss: 0.08109991252422333
Validation loss: 1.485497155497151

Epoch: 5| Step: 6
Training loss: 0.07050241529941559
Validation loss: 1.4784019416378391

Epoch: 5| Step: 7
Training loss: 0.062365271151065826
Validation loss: 1.5114552679882254

Epoch: 5| Step: 8
Training loss: 0.06833530962467194
Validation loss: 1.5060157013195816

Epoch: 5| Step: 9
Training loss: 0.046079885214567184
Validation loss: 1.5283510005602272

Epoch: 5| Step: 10
Training loss: 0.05404193326830864
Validation loss: 1.5436285477812572

Epoch: 642| Step: 0
Training loss: 0.04721011966466904
Validation loss: 1.5417041676018828

Epoch: 5| Step: 1
Training loss: 0.08004104346036911
Validation loss: 1.5644852153716549

Epoch: 5| Step: 2
Training loss: 0.07532064616680145
Validation loss: 1.5422900607508998

Epoch: 5| Step: 3
Training loss: 0.0349431075155735
Validation loss: 1.5191029566590504

Epoch: 5| Step: 4
Training loss: 0.06165292114019394
Validation loss: 1.5470955538493332

Epoch: 5| Step: 5
Training loss: 0.07890275120735168
Validation loss: 1.5427163018975207

Epoch: 5| Step: 6
Training loss: 0.08896015584468842
Validation loss: 1.5283412112984607

Epoch: 5| Step: 7
Training loss: 0.049311794340610504
Validation loss: 1.5333198091035247

Epoch: 5| Step: 8
Training loss: 0.03351880609989166
Validation loss: 1.562055733896071

Epoch: 5| Step: 9
Training loss: 0.04239615425467491
Validation loss: 1.5778062907598351

Epoch: 5| Step: 10
Training loss: 0.050970714539289474
Validation loss: 1.5898775246835524

Epoch: 643| Step: 0
Training loss: 0.06830737739801407
Validation loss: 1.5679968505777337

Epoch: 5| Step: 1
Training loss: 0.09526717662811279
Validation loss: 1.6068429126534411

Epoch: 5| Step: 2
Training loss: 0.07798083871603012
Validation loss: 1.6079875205152778

Epoch: 5| Step: 3
Training loss: 0.15254639089107513
Validation loss: 1.5896920914291053

Epoch: 5| Step: 4
Training loss: 0.06980735063552856
Validation loss: 1.562115664123207

Epoch: 5| Step: 5
Training loss: 0.042903102934360504
Validation loss: 1.5349473120063863

Epoch: 5| Step: 6
Training loss: 0.09183023124933243
Validation loss: 1.5026930275783743

Epoch: 5| Step: 7
Training loss: 0.08226573467254639
Validation loss: 1.5051980236525178

Epoch: 5| Step: 8
Training loss: 0.13789227604866028
Validation loss: 1.4856758835495159

Epoch: 5| Step: 9
Training loss: 0.09629860520362854
Validation loss: 1.4956578035508432

Epoch: 5| Step: 10
Training loss: 0.07523690909147263
Validation loss: 1.5123991927792948

Epoch: 644| Step: 0
Training loss: 0.07985682785511017
Validation loss: 1.5513667380937965

Epoch: 5| Step: 1
Training loss: 0.08931471407413483
Validation loss: 1.5567527208276974

Epoch: 5| Step: 2
Training loss: 0.19170713424682617
Validation loss: 1.5977543028452064

Epoch: 5| Step: 3
Training loss: 0.14565283060073853
Validation loss: 1.5932705761283956

Epoch: 5| Step: 4
Training loss: 0.07076733559370041
Validation loss: 1.5825585178149644

Epoch: 5| Step: 5
Training loss: 0.0701136365532875
Validation loss: 1.553546114634442

Epoch: 5| Step: 6
Training loss: 0.06234114617109299
Validation loss: 1.5576645558880222

Epoch: 5| Step: 7
Training loss: 0.09054235368967056
Validation loss: 1.5416654553464664

Epoch: 5| Step: 8
Training loss: 0.08237452805042267
Validation loss: 1.551348634945449

Epoch: 5| Step: 9
Training loss: 0.1220831498503685
Validation loss: 1.4988226095835369

Epoch: 5| Step: 10
Training loss: 0.13331946730613708
Validation loss: 1.5454665730076451

Epoch: 645| Step: 0
Training loss: 0.08055157214403152
Validation loss: 1.5253844312442246

Epoch: 5| Step: 1
Training loss: 0.08727410435676575
Validation loss: 1.520586823904386

Epoch: 5| Step: 2
Training loss: 0.06528625637292862
Validation loss: 1.5237671124037875

Epoch: 5| Step: 3
Training loss: 0.09167024493217468
Validation loss: 1.5385215513167843

Epoch: 5| Step: 4
Training loss: 0.11311224848031998
Validation loss: 1.575220165714141

Epoch: 5| Step: 5
Training loss: 0.10381264984607697
Validation loss: 1.563433466419097

Epoch: 5| Step: 6
Training loss: 0.06524394452571869
Validation loss: 1.5729843301157798

Epoch: 5| Step: 7
Training loss: 0.08185015618801117
Validation loss: 1.5285994340014715

Epoch: 5| Step: 8
Training loss: 0.06219380348920822
Validation loss: 1.5198400020599365

Epoch: 5| Step: 9
Training loss: 0.08455227315425873
Validation loss: 1.5340028706417288

Epoch: 5| Step: 10
Training loss: 0.10124760866165161
Validation loss: 1.5048339225912606

Epoch: 646| Step: 0
Training loss: 0.04674512892961502
Validation loss: 1.5247013934196965

Epoch: 5| Step: 1
Training loss: 0.04843636229634285
Validation loss: 1.563614660693753

Epoch: 5| Step: 2
Training loss: 0.06966762244701385
Validation loss: 1.5607172186656664

Epoch: 5| Step: 3
Training loss: 0.09780173003673553
Validation loss: 1.559541501024718

Epoch: 5| Step: 4
Training loss: 0.060332041233778
Validation loss: 1.5373449710107618

Epoch: 5| Step: 5
Training loss: 0.08675442636013031
Validation loss: 1.596769586686165

Epoch: 5| Step: 6
Training loss: 0.09731486439704895
Validation loss: 1.5906672375176543

Epoch: 5| Step: 7
Training loss: 0.11479894816875458
Validation loss: 1.5910392204920452

Epoch: 5| Step: 8
Training loss: 0.06652653962373734
Validation loss: 1.6117807831815494

Epoch: 5| Step: 9
Training loss: 0.06451302766799927
Validation loss: 1.5687572981721611

Epoch: 5| Step: 10
Training loss: 0.06403133273124695
Validation loss: 1.568389775932476

Epoch: 647| Step: 0
Training loss: 0.07322083413600922
Validation loss: 1.5059506662430302

Epoch: 5| Step: 1
Training loss: 0.06319089978933334
Validation loss: 1.5364737331226308

Epoch: 5| Step: 2
Training loss: 0.04356824979186058
Validation loss: 1.5070571335413123

Epoch: 5| Step: 3
Training loss: 0.07539652287960052
Validation loss: 1.5492979275282992

Epoch: 5| Step: 4
Training loss: 0.0805806815624237
Validation loss: 1.556985144974083

Epoch: 5| Step: 5
Training loss: 0.06444589793682098
Validation loss: 1.5439290449183474

Epoch: 5| Step: 6
Training loss: 0.09172657877206802
Validation loss: 1.556964611494413

Epoch: 5| Step: 7
Training loss: 0.054096519947052
Validation loss: 1.5549873728905954

Epoch: 5| Step: 8
Training loss: 0.13981331884860992
Validation loss: 1.5527114445163357

Epoch: 5| Step: 9
Training loss: 0.04637889191508293
Validation loss: 1.5517619553432669

Epoch: 5| Step: 10
Training loss: 0.0970519408583641
Validation loss: 1.5866231661970898

Epoch: 648| Step: 0
Training loss: 0.0867806226015091
Validation loss: 1.5828110043720534

Epoch: 5| Step: 1
Training loss: 0.13951079547405243
Validation loss: 1.586042390074781

Epoch: 5| Step: 2
Training loss: 0.08283062279224396
Validation loss: 1.5643052695899882

Epoch: 5| Step: 3
Training loss: 0.0781254917383194
Validation loss: 1.5436496632073515

Epoch: 5| Step: 4
Training loss: 0.07124806940555573
Validation loss: 1.5361226656103646

Epoch: 5| Step: 5
Training loss: 0.03834942728281021
Validation loss: 1.515129114991875

Epoch: 5| Step: 6
Training loss: 0.07363179326057434
Validation loss: 1.5140158848095966

Epoch: 5| Step: 7
Training loss: 0.08937215805053711
Validation loss: 1.4936818576628161

Epoch: 5| Step: 8
Training loss: 0.05276643484830856
Validation loss: 1.4866594755521385

Epoch: 5| Step: 9
Training loss: 0.06747592240571976
Validation loss: 1.498712912682564

Epoch: 5| Step: 10
Training loss: 0.07723473012447357
Validation loss: 1.5250689188639324

Epoch: 649| Step: 0
Training loss: 0.09216558933258057
Validation loss: 1.5036029431127733

Epoch: 5| Step: 1
Training loss: 0.04302182421088219
Validation loss: 1.517708441262604

Epoch: 5| Step: 2
Training loss: 0.10199026763439178
Validation loss: 1.5044581505560106

Epoch: 5| Step: 3
Training loss: 0.06519974768161774
Validation loss: 1.5043152000314446

Epoch: 5| Step: 4
Training loss: 0.08332127332687378
Validation loss: 1.515686095401805

Epoch: 5| Step: 5
Training loss: 0.07193958014249802
Validation loss: 1.5081405357647968

Epoch: 5| Step: 6
Training loss: 0.05423542112112045
Validation loss: 1.5224372340786843

Epoch: 5| Step: 7
Training loss: 0.07920388877391815
Validation loss: 1.5097737594317364

Epoch: 5| Step: 8
Training loss: 0.1104227751493454
Validation loss: 1.545322081094147

Epoch: 5| Step: 9
Training loss: 0.0966741293668747
Validation loss: 1.5731411762135004

Epoch: 5| Step: 10
Training loss: 0.06316540390253067
Validation loss: 1.5371453313417331

Epoch: 650| Step: 0
Training loss: 0.09148527681827545
Validation loss: 1.536628221952787

Epoch: 5| Step: 1
Training loss: 0.07186321914196014
Validation loss: 1.563946432964776

Epoch: 5| Step: 2
Training loss: 0.047582536935806274
Validation loss: 1.533904024349746

Epoch: 5| Step: 3
Training loss: 0.07767390459775925
Validation loss: 1.5470396062379241

Epoch: 5| Step: 4
Training loss: 0.08014895021915436
Validation loss: 1.498722586580502

Epoch: 5| Step: 5
Training loss: 0.05339521914720535
Validation loss: 1.5064948335770638

Epoch: 5| Step: 6
Training loss: 0.07516364753246307
Validation loss: 1.4902194469205794

Epoch: 5| Step: 7
Training loss: 0.09216362237930298
Validation loss: 1.508485145466302

Epoch: 5| Step: 8
Training loss: 0.09517984837293625
Validation loss: 1.5305122175524313

Epoch: 5| Step: 9
Training loss: 0.05782243609428406
Validation loss: 1.491145005790136

Epoch: 5| Step: 10
Training loss: 0.06005407124757767
Validation loss: 1.514693602438896

Epoch: 651| Step: 0
Training loss: 0.05792055279016495
Validation loss: 1.512351788500304

Epoch: 5| Step: 1
Training loss: 0.036716118454933167
Validation loss: 1.5050850119642032

Epoch: 5| Step: 2
Training loss: 0.09768164157867432
Validation loss: 1.5391831833829162

Epoch: 5| Step: 3
Training loss: 0.11721370369195938
Validation loss: 1.5135566957535282

Epoch: 5| Step: 4
Training loss: 0.09749589115381241
Validation loss: 1.5171664632776731

Epoch: 5| Step: 5
Training loss: 0.06845392286777496
Validation loss: 1.512514368821216

Epoch: 5| Step: 6
Training loss: 0.08958477526903152
Validation loss: 1.569120616041204

Epoch: 5| Step: 7
Training loss: 0.11755798012018204
Validation loss: 1.537556045798845

Epoch: 5| Step: 8
Training loss: 0.04826752096414566
Validation loss: 1.559869271452709

Epoch: 5| Step: 9
Training loss: 0.06158226728439331
Validation loss: 1.5569550696239676

Epoch: 5| Step: 10
Training loss: 0.08168471604585648
Validation loss: 1.5193103795410485

Epoch: 652| Step: 0
Training loss: 0.06410486996173859
Validation loss: 1.522409871060361

Epoch: 5| Step: 1
Training loss: 0.059343982487916946
Validation loss: 1.5658598740895588

Epoch: 5| Step: 2
Training loss: 0.07456366717815399
Validation loss: 1.540514067936969

Epoch: 5| Step: 3
Training loss: 0.06154536083340645
Validation loss: 1.5352387966648224

Epoch: 5| Step: 4
Training loss: 0.07213103026151657
Validation loss: 1.5245510109009281

Epoch: 5| Step: 5
Training loss: 0.04229167848825455
Validation loss: 1.5119090541716544

Epoch: 5| Step: 6
Training loss: 0.06750211119651794
Validation loss: 1.532507473422635

Epoch: 5| Step: 7
Training loss: 0.0385889932513237
Validation loss: 1.5278824708795036

Epoch: 5| Step: 8
Training loss: 0.06120024994015694
Validation loss: 1.5122317203911402

Epoch: 5| Step: 9
Training loss: 0.11520536243915558
Validation loss: 1.513182400375284

Epoch: 5| Step: 10
Training loss: 0.10621713101863861
Validation loss: 1.5150981398038967

Epoch: 653| Step: 0
Training loss: 0.05529708415269852
Validation loss: 1.5086890292424027

Epoch: 5| Step: 1
Training loss: 0.0885157361626625
Validation loss: 1.5212544920623943

Epoch: 5| Step: 2
Training loss: 0.05846775695681572
Validation loss: 1.5146496616384035

Epoch: 5| Step: 3
Training loss: 0.045195210725069046
Validation loss: 1.5164552375834475

Epoch: 5| Step: 4
Training loss: 0.10552042722702026
Validation loss: 1.5289404443515244

Epoch: 5| Step: 5
Training loss: 0.07397831976413727
Validation loss: 1.5388088213500155

Epoch: 5| Step: 6
Training loss: 0.09908972680568695
Validation loss: 1.5522853475745007

Epoch: 5| Step: 7
Training loss: 0.08044255524873734
Validation loss: 1.548937201499939

Epoch: 5| Step: 8
Training loss: 0.0641246885061264
Validation loss: 1.5140575183335172

Epoch: 5| Step: 9
Training loss: 0.05297447368502617
Validation loss: 1.5183716691950315

Epoch: 5| Step: 10
Training loss: 0.08287889510393143
Validation loss: 1.5314732520811019

Epoch: 654| Step: 0
Training loss: 0.07496222853660583
Validation loss: 1.5215208735517276

Epoch: 5| Step: 1
Training loss: 0.04986278712749481
Validation loss: 1.534573499874402

Epoch: 5| Step: 2
Training loss: 0.10751412063837051
Validation loss: 1.5686644956629763

Epoch: 5| Step: 3
Training loss: 0.09259357303380966
Validation loss: 1.538208060367133

Epoch: 5| Step: 4
Training loss: 0.0663774311542511
Validation loss: 1.592283010482788

Epoch: 5| Step: 5
Training loss: 0.06692244112491608
Validation loss: 1.5478518239913448

Epoch: 5| Step: 6
Training loss: 0.06216323375701904
Validation loss: 1.5096364687847834

Epoch: 5| Step: 7
Training loss: 0.04056312516331673
Validation loss: 1.524721816021909

Epoch: 5| Step: 8
Training loss: 0.11064541339874268
Validation loss: 1.4690741339037496

Epoch: 5| Step: 9
Training loss: 0.06203071400523186
Validation loss: 1.5141051610310872

Epoch: 5| Step: 10
Training loss: 0.09060376137495041
Validation loss: 1.5071122543786162

Epoch: 655| Step: 0
Training loss: 0.059154242277145386
Validation loss: 1.5102667577805058

Epoch: 5| Step: 1
Training loss: 0.07181937992572784
Validation loss: 1.5239773514450237

Epoch: 5| Step: 2
Training loss: 0.05116074159741402
Validation loss: 1.5334188835595244

Epoch: 5| Step: 3
Training loss: 0.07001683861017227
Validation loss: 1.5387089816472863

Epoch: 5| Step: 4
Training loss: 0.09136120229959488
Validation loss: 1.5828429281070668

Epoch: 5| Step: 5
Training loss: 0.04868939518928528
Validation loss: 1.5510221540286977

Epoch: 5| Step: 6
Training loss: 0.05377022549510002
Validation loss: 1.5680226549025504

Epoch: 5| Step: 7
Training loss: 0.042876966297626495
Validation loss: 1.606947293845556

Epoch: 5| Step: 8
Training loss: 0.07201709598302841
Validation loss: 1.5605213052483016

Epoch: 5| Step: 9
Training loss: 0.07869716733694077
Validation loss: 1.5842685161098358

Epoch: 5| Step: 10
Training loss: 0.10644053667783737
Validation loss: 1.5888891220092773

Epoch: 656| Step: 0
Training loss: 0.08587293326854706
Validation loss: 1.56690687517966

Epoch: 5| Step: 1
Training loss: 0.06535112857818604
Validation loss: 1.5623807599467616

Epoch: 5| Step: 2
Training loss: 0.10492642223834991
Validation loss: 1.551758304719002

Epoch: 5| Step: 3
Training loss: 0.07646988332271576
Validation loss: 1.5709088797210364

Epoch: 5| Step: 4
Training loss: 0.0661366656422615
Validation loss: 1.5722813593444003

Epoch: 5| Step: 5
Training loss: 0.06104432791471481
Validation loss: 1.556448616007323

Epoch: 5| Step: 6
Training loss: 0.09179575741291046
Validation loss: 1.5257764964975336

Epoch: 5| Step: 7
Training loss: 0.0735768973827362
Validation loss: 1.5384689095199748

Epoch: 5| Step: 8
Training loss: 0.05230575054883957
Validation loss: 1.510626353243346

Epoch: 5| Step: 9
Training loss: 0.071321040391922
Validation loss: 1.4962944869072206

Epoch: 5| Step: 10
Training loss: 0.08022736012935638
Validation loss: 1.5375787288911882

Epoch: 657| Step: 0
Training loss: 0.07429340481758118
Validation loss: 1.5090474826033398

Epoch: 5| Step: 1
Training loss: 0.11572710424661636
Validation loss: 1.5300204228329402

Epoch: 5| Step: 2
Training loss: 0.06673307716846466
Validation loss: 1.5315815979434597

Epoch: 5| Step: 3
Training loss: 0.052326686680316925
Validation loss: 1.5045281020543908

Epoch: 5| Step: 4
Training loss: 0.06427682191133499
Validation loss: 1.5473914120786934

Epoch: 5| Step: 5
Training loss: 0.07831208407878876
Validation loss: 1.5224908526225756

Epoch: 5| Step: 6
Training loss: 0.08002631366252899
Validation loss: 1.533459222444924

Epoch: 5| Step: 7
Training loss: 0.06618525087833405
Validation loss: 1.5254850605482697

Epoch: 5| Step: 8
Training loss: 0.04474267736077309
Validation loss: 1.5250938759055188

Epoch: 5| Step: 9
Training loss: 0.06473828107118607
Validation loss: 1.5031385960117463

Epoch: 5| Step: 10
Training loss: 0.10569717735052109
Validation loss: 1.5020564038266417

Epoch: 658| Step: 0
Training loss: 0.0489681214094162
Validation loss: 1.5143031240791403

Epoch: 5| Step: 1
Training loss: 0.07780437171459198
Validation loss: 1.5135193306912658

Epoch: 5| Step: 2
Training loss: 0.07011713087558746
Validation loss: 1.535156443554868

Epoch: 5| Step: 3
Training loss: 0.060954444110393524
Validation loss: 1.547786106345474

Epoch: 5| Step: 4
Training loss: 0.05840475484728813
Validation loss: 1.5171805799648326

Epoch: 5| Step: 5
Training loss: 0.05738679692149162
Validation loss: 1.529477673192178

Epoch: 5| Step: 6
Training loss: 0.06674842536449432
Validation loss: 1.5087515487465808

Epoch: 5| Step: 7
Training loss: 0.05424848943948746
Validation loss: 1.5384048672132595

Epoch: 5| Step: 8
Training loss: 0.07884730398654938
Validation loss: 1.4953153505120227

Epoch: 5| Step: 9
Training loss: 0.041667621582746506
Validation loss: 1.5433560866181568

Epoch: 5| Step: 10
Training loss: 0.04995747283101082
Validation loss: 1.522462583357288

Epoch: 659| Step: 0
Training loss: 0.07431311160326004
Validation loss: 1.5631356386728184

Epoch: 5| Step: 1
Training loss: 0.05071554332971573
Validation loss: 1.5474417107079619

Epoch: 5| Step: 2
Training loss: 0.05704377964138985
Validation loss: 1.5557305171925535

Epoch: 5| Step: 3
Training loss: 0.07839668542146683
Validation loss: 1.5449179327616127

Epoch: 5| Step: 4
Training loss: 0.06077369302511215
Validation loss: 1.5219496706480622

Epoch: 5| Step: 5
Training loss: 0.04204937443137169
Validation loss: 1.5321095130776847

Epoch: 5| Step: 6
Training loss: 0.08344398438930511
Validation loss: 1.545111511343269

Epoch: 5| Step: 7
Training loss: 0.07814387232065201
Validation loss: 1.5295839271237772

Epoch: 5| Step: 8
Training loss: 0.09382973611354828
Validation loss: 1.560995453147478

Epoch: 5| Step: 9
Training loss: 0.1330571472644806
Validation loss: 1.5729800296086136

Epoch: 5| Step: 10
Training loss: 0.056796953082084656
Validation loss: 1.577826503784426

Epoch: 660| Step: 0
Training loss: 0.06667158007621765
Validation loss: 1.5486387411753337

Epoch: 5| Step: 1
Training loss: 0.06416793167591095
Validation loss: 1.5168969003103112

Epoch: 5| Step: 2
Training loss: 0.0687573105096817
Validation loss: 1.5176993698202155

Epoch: 5| Step: 3
Training loss: 0.06110408902168274
Validation loss: 1.4907259736009824

Epoch: 5| Step: 4
Training loss: 0.121246337890625
Validation loss: 1.538502521412347

Epoch: 5| Step: 5
Training loss: 0.06361689418554306
Validation loss: 1.5223655598137968

Epoch: 5| Step: 6
Training loss: 0.047755416482686996
Validation loss: 1.4954249833219795

Epoch: 5| Step: 7
Training loss: 0.06837020069360733
Validation loss: 1.5272651180144279

Epoch: 5| Step: 8
Training loss: 0.054772961884737015
Validation loss: 1.506604117090984

Epoch: 5| Step: 9
Training loss: 0.07248082011938095
Validation loss: 1.5278120399803243

Epoch: 5| Step: 10
Training loss: 0.05846426263451576
Validation loss: 1.5190883964620612

Epoch: 661| Step: 0
Training loss: 0.07963874936103821
Validation loss: 1.5091280264239157

Epoch: 5| Step: 1
Training loss: 0.04158886522054672
Validation loss: 1.533607695692329

Epoch: 5| Step: 2
Training loss: 0.0917443186044693
Validation loss: 1.5225747387896302

Epoch: 5| Step: 3
Training loss: 0.05361996963620186
Validation loss: 1.541105877968573

Epoch: 5| Step: 4
Training loss: 0.03709287568926811
Validation loss: 1.5262393951416016

Epoch: 5| Step: 5
Training loss: 0.05257129669189453
Validation loss: 1.5200231357287335

Epoch: 5| Step: 6
Training loss: 0.05267106369137764
Validation loss: 1.5593568112260552

Epoch: 5| Step: 7
Training loss: 0.06948746740818024
Validation loss: 1.5431306951789445

Epoch: 5| Step: 8
Training loss: 0.08427254110574722
Validation loss: 1.5160780747731526

Epoch: 5| Step: 9
Training loss: 0.06045528128743172
Validation loss: 1.5153725762521066

Epoch: 5| Step: 10
Training loss: 0.09467879682779312
Validation loss: 1.5328816572825115

Epoch: 662| Step: 0
Training loss: 0.05687477067112923
Validation loss: 1.5312098738967732

Epoch: 5| Step: 1
Training loss: 0.06475840508937836
Validation loss: 1.5024801249145179

Epoch: 5| Step: 2
Training loss: 0.06689506024122238
Validation loss: 1.5156605794865599

Epoch: 5| Step: 3
Training loss: 0.09991239011287689
Validation loss: 1.5275189633010535

Epoch: 5| Step: 4
Training loss: 0.05999133735895157
Validation loss: 1.5380651066380162

Epoch: 5| Step: 5
Training loss: 0.06256081163883209
Validation loss: 1.5359127931697394

Epoch: 5| Step: 6
Training loss: 0.06953588873147964
Validation loss: 1.5361484289169312

Epoch: 5| Step: 7
Training loss: 0.07529958337545395
Validation loss: 1.5177409520713232

Epoch: 5| Step: 8
Training loss: 0.060406070202589035
Validation loss: 1.519040092345207

Epoch: 5| Step: 9
Training loss: 0.10016210377216339
Validation loss: 1.5027759600711126

Epoch: 5| Step: 10
Training loss: 0.04797171428799629
Validation loss: 1.5279061614826162

Epoch: 663| Step: 0
Training loss: 0.0894615650177002
Validation loss: 1.5049986506021151

Epoch: 5| Step: 1
Training loss: 0.04792025685310364
Validation loss: 1.5380395227862942

Epoch: 5| Step: 2
Training loss: 0.05060127377510071
Validation loss: 1.5376608076915945

Epoch: 5| Step: 3
Training loss: 0.07828006893396378
Validation loss: 1.5459851943036562

Epoch: 5| Step: 4
Training loss: 0.08045719563961029
Validation loss: 1.5188062729374054

Epoch: 5| Step: 5
Training loss: 0.03916800022125244
Validation loss: 1.5324169538354362

Epoch: 5| Step: 6
Training loss: 0.055703479796648026
Validation loss: 1.5126842542361187

Epoch: 5| Step: 7
Training loss: 0.05408811569213867
Validation loss: 1.501334478778224

Epoch: 5| Step: 8
Training loss: 0.07363016903400421
Validation loss: 1.540750616340227

Epoch: 5| Step: 9
Training loss: 0.060899458825588226
Validation loss: 1.5385035942959528

Epoch: 5| Step: 10
Training loss: 0.059273965656757355
Validation loss: 1.5247557932330715

Epoch: 664| Step: 0
Training loss: 0.10245390981435776
Validation loss: 1.5487060175147107

Epoch: 5| Step: 1
Training loss: 0.08309795707464218
Validation loss: 1.5398673716411795

Epoch: 5| Step: 2
Training loss: 0.05765647813677788
Validation loss: 1.5651841432817521

Epoch: 5| Step: 3
Training loss: 0.05073503404855728
Validation loss: 1.5753957456158054

Epoch: 5| Step: 4
Training loss: 0.04577014967799187
Validation loss: 1.5681539145849084

Epoch: 5| Step: 5
Training loss: 0.06803542375564575
Validation loss: 1.5389155905733827

Epoch: 5| Step: 6
Training loss: 0.055368851870298386
Validation loss: 1.5503038302544625

Epoch: 5| Step: 7
Training loss: 0.0649775043129921
Validation loss: 1.5608373483022053

Epoch: 5| Step: 8
Training loss: 0.04999855160713196
Validation loss: 1.541677608284899

Epoch: 5| Step: 9
Training loss: 0.08822053670883179
Validation loss: 1.5655136287853282

Epoch: 5| Step: 10
Training loss: 0.0444922000169754
Validation loss: 1.5356077788978495

Epoch: 665| Step: 0
Training loss: 0.07809693366289139
Validation loss: 1.5528784746764808

Epoch: 5| Step: 1
Training loss: 0.0783643126487732
Validation loss: 1.5871124831579064

Epoch: 5| Step: 2
Training loss: 0.09192387014627457
Validation loss: 1.5427039541223997

Epoch: 5| Step: 3
Training loss: 0.051685214042663574
Validation loss: 1.528578959485536

Epoch: 5| Step: 4
Training loss: 0.03733634948730469
Validation loss: 1.536950889454093

Epoch: 5| Step: 5
Training loss: 0.05416969582438469
Validation loss: 1.52959196541899

Epoch: 5| Step: 6
Training loss: 0.08954284340143204
Validation loss: 1.5279672786753664

Epoch: 5| Step: 7
Training loss: 0.07627908885478973
Validation loss: 1.5214988518786687

Epoch: 5| Step: 8
Training loss: 0.11180522292852402
Validation loss: 1.5136254948954428

Epoch: 5| Step: 9
Training loss: 0.04263675957918167
Validation loss: 1.5147468069548249

Epoch: 5| Step: 10
Training loss: 0.06400244683027267
Validation loss: 1.5036858486872848

Epoch: 666| Step: 0
Training loss: 0.05874396115541458
Validation loss: 1.5098046166922456

Epoch: 5| Step: 1
Training loss: 0.05290927737951279
Validation loss: 1.5047241321174047

Epoch: 5| Step: 2
Training loss: 0.0639728307723999
Validation loss: 1.5076704384178243

Epoch: 5| Step: 3
Training loss: 0.05437576025724411
Validation loss: 1.5142934886358117

Epoch: 5| Step: 4
Training loss: 0.07773397117853165
Validation loss: 1.5176218626319722

Epoch: 5| Step: 5
Training loss: 0.07935453951358795
Validation loss: 1.528447784403319

Epoch: 5| Step: 6
Training loss: 0.05715203285217285
Validation loss: 1.5372425933038034

Epoch: 5| Step: 7
Training loss: 0.05429207533597946
Validation loss: 1.5545100960680234

Epoch: 5| Step: 8
Training loss: 0.047483474016189575
Validation loss: 1.556247809881805

Epoch: 5| Step: 9
Training loss: 0.08202745020389557
Validation loss: 1.5359579863086823

Epoch: 5| Step: 10
Training loss: 0.07916086912155151
Validation loss: 1.5477910041809082

Epoch: 667| Step: 0
Training loss: 0.03898372873663902
Validation loss: 1.5524943637591537

Epoch: 5| Step: 1
Training loss: 0.049504272639751434
Validation loss: 1.5284277739063385

Epoch: 5| Step: 2
Training loss: 0.07611318677663803
Validation loss: 1.5352958620235484

Epoch: 5| Step: 3
Training loss: 0.06427064538002014
Validation loss: 1.5585784437835857

Epoch: 5| Step: 4
Training loss: 0.03613577410578728
Validation loss: 1.55921854383202

Epoch: 5| Step: 5
Training loss: 0.08067019283771515
Validation loss: 1.5355249476689163

Epoch: 5| Step: 6
Training loss: 0.09021757543087006
Validation loss: 1.5307974866641465

Epoch: 5| Step: 7
Training loss: 0.04354773089289665
Validation loss: 1.549256053342614

Epoch: 5| Step: 8
Training loss: 0.08730610460042953
Validation loss: 1.5785778478909565

Epoch: 5| Step: 9
Training loss: 0.08847207576036453
Validation loss: 1.559828951794614

Epoch: 5| Step: 10
Training loss: 0.05041930824518204
Validation loss: 1.5838030948433826

Epoch: 668| Step: 0
Training loss: 0.06649184972047806
Validation loss: 1.6008480159185265

Epoch: 5| Step: 1
Training loss: 0.07019037753343582
Validation loss: 1.5769197043552194

Epoch: 5| Step: 2
Training loss: 0.08450374752283096
Validation loss: 1.5460634411022227

Epoch: 5| Step: 3
Training loss: 0.08316214382648468
Validation loss: 1.5097863212708504

Epoch: 5| Step: 4
Training loss: 0.059765540063381195
Validation loss: 1.493239305993562

Epoch: 5| Step: 5
Training loss: 0.04660194367170334
Validation loss: 1.5117999622898717

Epoch: 5| Step: 6
Training loss: 0.07853247225284576
Validation loss: 1.5031048072281705

Epoch: 5| Step: 7
Training loss: 0.07810574769973755
Validation loss: 1.496147398025759

Epoch: 5| Step: 8
Training loss: 0.05617687851190567
Validation loss: 1.4809459281224076

Epoch: 5| Step: 9
Training loss: 0.037006065249443054
Validation loss: 1.4944574294551727

Epoch: 5| Step: 10
Training loss: 0.054762572050094604
Validation loss: 1.5256168765406455

Epoch: 669| Step: 0
Training loss: 0.11701898276805878
Validation loss: 1.5013706312384656

Epoch: 5| Step: 1
Training loss: 0.049488864839076996
Validation loss: 1.5137078659508818

Epoch: 5| Step: 2
Training loss: 0.0468759648501873
Validation loss: 1.5189900667436662

Epoch: 5| Step: 3
Training loss: 0.08613363653421402
Validation loss: 1.5465776920318604

Epoch: 5| Step: 4
Training loss: 0.06004469469189644
Validation loss: 1.545635324652477

Epoch: 5| Step: 5
Training loss: 0.053917694836854935
Validation loss: 1.5438954548169208

Epoch: 5| Step: 6
Training loss: 0.05760832875967026
Validation loss: 1.541132898740871

Epoch: 5| Step: 7
Training loss: 0.05682815983891487
Validation loss: 1.5642939126619728

Epoch: 5| Step: 8
Training loss: 0.03695669025182724
Validation loss: 1.5901698809798046

Epoch: 5| Step: 9
Training loss: 0.04948219656944275
Validation loss: 1.5765170307569607

Epoch: 5| Step: 10
Training loss: 0.08899229764938354
Validation loss: 1.5672660258508497

Epoch: 670| Step: 0
Training loss: 0.07876431941986084
Validation loss: 1.5661817968532603

Epoch: 5| Step: 1
Training loss: 0.03895573318004608
Validation loss: 1.569017630751415

Epoch: 5| Step: 2
Training loss: 0.06975077092647552
Validation loss: 1.5687254757009528

Epoch: 5| Step: 3
Training loss: 0.05517056584358215
Validation loss: 1.568369464207721

Epoch: 5| Step: 4
Training loss: 0.07872899621725082
Validation loss: 1.5412435698252853

Epoch: 5| Step: 5
Training loss: 0.07506195455789566
Validation loss: 1.5758800775774064

Epoch: 5| Step: 6
Training loss: 0.052768319845199585
Validation loss: 1.5584913505020963

Epoch: 5| Step: 7
Training loss: 0.0421392098069191
Validation loss: 1.5530096984678698

Epoch: 5| Step: 8
Training loss: 0.048519931733608246
Validation loss: 1.5443823568282589

Epoch: 5| Step: 9
Training loss: 0.09436732530593872
Validation loss: 1.5759204254355481

Epoch: 5| Step: 10
Training loss: 0.08472498506307602
Validation loss: 1.5817335119811438

Epoch: 671| Step: 0
Training loss: 0.04654867947101593
Validation loss: 1.5716283116289365

Epoch: 5| Step: 1
Training loss: 0.09419022500514984
Validation loss: 1.5507948052498601

Epoch: 5| Step: 2
Training loss: 0.057192038744688034
Validation loss: 1.5655444258002824

Epoch: 5| Step: 3
Training loss: 0.07386107742786407
Validation loss: 1.5623930244035618

Epoch: 5| Step: 4
Training loss: 0.07511952519416809
Validation loss: 1.539251506969493

Epoch: 5| Step: 5
Training loss: 0.050905656069517136
Validation loss: 1.5402417644377677

Epoch: 5| Step: 6
Training loss: 0.0597965233027935
Validation loss: 1.5559921911967698

Epoch: 5| Step: 7
Training loss: 0.05506206303834915
Validation loss: 1.546568150161415

Epoch: 5| Step: 8
Training loss: 0.0640408918261528
Validation loss: 1.542197838906319

Epoch: 5| Step: 9
Training loss: 0.04457123577594757
Validation loss: 1.539659592413133

Epoch: 5| Step: 10
Training loss: 0.05614618957042694
Validation loss: 1.5157476868680728

Epoch: 672| Step: 0
Training loss: 0.05078263208270073
Validation loss: 1.5146239662683139

Epoch: 5| Step: 1
Training loss: 0.07656390219926834
Validation loss: 1.5106611854286605

Epoch: 5| Step: 2
Training loss: 0.057725656777620316
Validation loss: 1.5164432961453673

Epoch: 5| Step: 3
Training loss: 0.047645289450883865
Validation loss: 1.518007932170745

Epoch: 5| Step: 4
Training loss: 0.05411379784345627
Validation loss: 1.517210405359986

Epoch: 5| Step: 5
Training loss: 0.09262580424547195
Validation loss: 1.5157052522064538

Epoch: 5| Step: 6
Training loss: 0.07528888434171677
Validation loss: 1.5418385715894802

Epoch: 5| Step: 7
Training loss: 0.03528781980276108
Validation loss: 1.5355631048961351

Epoch: 5| Step: 8
Training loss: 0.10405077040195465
Validation loss: 1.520456164113937

Epoch: 5| Step: 9
Training loss: 0.04789099469780922
Validation loss: 1.539498677817724

Epoch: 5| Step: 10
Training loss: 0.06521648168563843
Validation loss: 1.528561725411364

Epoch: 673| Step: 0
Training loss: 0.060132693499326706
Validation loss: 1.519735683677017

Epoch: 5| Step: 1
Training loss: 0.0795365422964096
Validation loss: 1.5140210569545787

Epoch: 5| Step: 2
Training loss: 0.0636117234826088
Validation loss: 1.4941205491301834

Epoch: 5| Step: 3
Training loss: 0.06682935357093811
Validation loss: 1.5150376539076529

Epoch: 5| Step: 4
Training loss: 0.10915561765432358
Validation loss: 1.5239762567704724

Epoch: 5| Step: 5
Training loss: 0.05833104997873306
Validation loss: 1.5279156879712177

Epoch: 5| Step: 6
Training loss: 0.0974566787481308
Validation loss: 1.5265337908139793

Epoch: 5| Step: 7
Training loss: 0.09060465544462204
Validation loss: 1.5286662270945888

Epoch: 5| Step: 8
Training loss: 0.06650228798389435
Validation loss: 1.5381963246612138

Epoch: 5| Step: 9
Training loss: 0.05556157976388931
Validation loss: 1.5754803278112923

Epoch: 5| Step: 10
Training loss: 0.08162401616573334
Validation loss: 1.5663623425268358

Epoch: 674| Step: 0
Training loss: 0.08214505761861801
Validation loss: 1.5774029865059802

Epoch: 5| Step: 1
Training loss: 0.07831598818302155
Validation loss: 1.5834348060751473

Epoch: 5| Step: 2
Training loss: 0.04288512468338013
Validation loss: 1.5174753947924542

Epoch: 5| Step: 3
Training loss: 0.06124461814761162
Validation loss: 1.5448714353704964

Epoch: 5| Step: 4
Training loss: 0.07345389574766159
Validation loss: 1.514794768825654

Epoch: 5| Step: 5
Training loss: 0.08585186302661896
Validation loss: 1.5395136225608088

Epoch: 5| Step: 6
Training loss: 0.05719465762376785
Validation loss: 1.5504796658792803

Epoch: 5| Step: 7
Training loss: 0.06616614013910294
Validation loss: 1.5501679220507223

Epoch: 5| Step: 8
Training loss: 0.10780708491802216
Validation loss: 1.5560422764029553

Epoch: 5| Step: 9
Training loss: 0.060231588780879974
Validation loss: 1.5739558589073919

Epoch: 5| Step: 10
Training loss: 0.0671340674161911
Validation loss: 1.5725380823176394

Epoch: 675| Step: 0
Training loss: 0.047922633588314056
Validation loss: 1.5500152290508311

Epoch: 5| Step: 1
Training loss: 0.04888661950826645
Validation loss: 1.5361959511233914

Epoch: 5| Step: 2
Training loss: 0.07047859579324722
Validation loss: 1.5579438811989241

Epoch: 5| Step: 3
Training loss: 0.07334935665130615
Validation loss: 1.5516283371115243

Epoch: 5| Step: 4
Training loss: 0.04161330312490463
Validation loss: 1.5806513114642071

Epoch: 5| Step: 5
Training loss: 0.0533439926803112
Validation loss: 1.5604666061298822

Epoch: 5| Step: 6
Training loss: 0.07721179723739624
Validation loss: 1.548525482095698

Epoch: 5| Step: 7
Training loss: 0.11143942922353745
Validation loss: 1.547728746168075

Epoch: 5| Step: 8
Training loss: 0.08946478366851807
Validation loss: 1.5604258711620043

Epoch: 5| Step: 9
Training loss: 0.041874803602695465
Validation loss: 1.5547529215453773

Epoch: 5| Step: 10
Training loss: 0.057456664741039276
Validation loss: 1.561950356729569

Epoch: 676| Step: 0
Training loss: 0.048201464116573334
Validation loss: 1.547788716131641

Epoch: 5| Step: 1
Training loss: 0.07324695587158203
Validation loss: 1.5520663017867713

Epoch: 5| Step: 2
Training loss: 0.0899650827050209
Validation loss: 1.5360691855030675

Epoch: 5| Step: 3
Training loss: 0.06282634288072586
Validation loss: 1.5524324204332085

Epoch: 5| Step: 4
Training loss: 0.06745181977748871
Validation loss: 1.533683996046743

Epoch: 5| Step: 5
Training loss: 0.059034205973148346
Validation loss: 1.5699358845269809

Epoch: 5| Step: 6
Training loss: 0.09652192890644073
Validation loss: 1.524984768000982

Epoch: 5| Step: 7
Training loss: 0.12261025607585907
Validation loss: 1.5229186268262966

Epoch: 5| Step: 8
Training loss: 0.07897943258285522
Validation loss: 1.5054545748618342

Epoch: 5| Step: 9
Training loss: 0.0719555988907814
Validation loss: 1.5343245229413431

Epoch: 5| Step: 10
Training loss: 0.07808835804462433
Validation loss: 1.520051892085742

Epoch: 677| Step: 0
Training loss: 0.07230788469314575
Validation loss: 1.5406670006372596

Epoch: 5| Step: 1
Training loss: 0.05306587368249893
Validation loss: 1.5352363073697655

Epoch: 5| Step: 2
Training loss: 0.03962274268269539
Validation loss: 1.5358620805125083

Epoch: 5| Step: 3
Training loss: 0.09779469668865204
Validation loss: 1.5404033455797421

Epoch: 5| Step: 4
Training loss: 0.09484489262104034
Validation loss: 1.4958261315540602

Epoch: 5| Step: 5
Training loss: 0.061612945050001144
Validation loss: 1.4899242565196047

Epoch: 5| Step: 6
Training loss: 0.0671294629573822
Validation loss: 1.5122355978976014

Epoch: 5| Step: 7
Training loss: 0.057853687554597855
Validation loss: 1.49549739719719

Epoch: 5| Step: 8
Training loss: 0.08163364231586456
Validation loss: 1.4992568133979716

Epoch: 5| Step: 9
Training loss: 0.07265987247228622
Validation loss: 1.4995025306619623

Epoch: 5| Step: 10
Training loss: 0.0517587810754776
Validation loss: 1.488161220345446

Epoch: 678| Step: 0
Training loss: 0.06787826865911484
Validation loss: 1.483552966066586

Epoch: 5| Step: 1
Training loss: 0.056220509111881256
Validation loss: 1.5016018062509515

Epoch: 5| Step: 2
Training loss: 0.09071044623851776
Validation loss: 1.5046626124330746

Epoch: 5| Step: 3
Training loss: 0.041233789175748825
Validation loss: 1.497111323059246

Epoch: 5| Step: 4
Training loss: 0.08734049648046494
Validation loss: 1.53214927001666

Epoch: 5| Step: 5
Training loss: 0.05091310665011406
Validation loss: 1.5325335789752264

Epoch: 5| Step: 6
Training loss: 0.08360639214515686
Validation loss: 1.5551518817101755

Epoch: 5| Step: 7
Training loss: 0.05779870226979256
Validation loss: 1.5332319146843367

Epoch: 5| Step: 8
Training loss: 0.08346427977085114
Validation loss: 1.559850133875365

Epoch: 5| Step: 9
Training loss: 0.04252665489912033
Validation loss: 1.5375031373834098

Epoch: 5| Step: 10
Training loss: 0.058889240026474
Validation loss: 1.5356995982508506

Epoch: 679| Step: 0
Training loss: 0.0559452585875988
Validation loss: 1.5363733499280867

Epoch: 5| Step: 1
Training loss: 0.0597647950053215
Validation loss: 1.5639167652335217

Epoch: 5| Step: 2
Training loss: 0.08382689207792282
Validation loss: 1.5404160368827082

Epoch: 5| Step: 3
Training loss: 0.07206714153289795
Validation loss: 1.5502068188882643

Epoch: 5| Step: 4
Training loss: 0.039603687822818756
Validation loss: 1.5523945593064832

Epoch: 5| Step: 5
Training loss: 0.04641377925872803
Validation loss: 1.5476581486322547

Epoch: 5| Step: 6
Training loss: 0.04513246938586235
Validation loss: 1.5446995971023396

Epoch: 5| Step: 7
Training loss: 0.06300555169582367
Validation loss: 1.5217383369322746

Epoch: 5| Step: 8
Training loss: 0.0893036276102066
Validation loss: 1.5186791163618847

Epoch: 5| Step: 9
Training loss: 0.1017431989312172
Validation loss: 1.5124028177671536

Epoch: 5| Step: 10
Training loss: 0.05632055550813675
Validation loss: 1.5128758312553487

Epoch: 680| Step: 0
Training loss: 0.0336875319480896
Validation loss: 1.5231605729749125

Epoch: 5| Step: 1
Training loss: 0.07133647799491882
Validation loss: 1.538628444876722

Epoch: 5| Step: 2
Training loss: 0.02909933403134346
Validation loss: 1.5436805563588296

Epoch: 5| Step: 3
Training loss: 0.05160912871360779
Validation loss: 1.5340132174953338

Epoch: 5| Step: 4
Training loss: 0.0665929988026619
Validation loss: 1.5356182552153064

Epoch: 5| Step: 5
Training loss: 0.06240464374423027
Validation loss: 1.5615975036416003

Epoch: 5| Step: 6
Training loss: 0.05819545313715935
Validation loss: 1.5636369028399069

Epoch: 5| Step: 7
Training loss: 0.04815181344747543
Validation loss: 1.5277621874245264

Epoch: 5| Step: 8
Training loss: 0.05549674108624458
Validation loss: 1.5282648968440231

Epoch: 5| Step: 9
Training loss: 0.07811484485864639
Validation loss: 1.5369242340005853

Epoch: 5| Step: 10
Training loss: 0.13864333927631378
Validation loss: 1.5150652944400747

Epoch: 681| Step: 0
Training loss: 0.07595039904117584
Validation loss: 1.4771353813909716

Epoch: 5| Step: 1
Training loss: 0.040894586592912674
Validation loss: 1.5083734719983992

Epoch: 5| Step: 2
Training loss: 0.06536296755075455
Validation loss: 1.5067465677056262

Epoch: 5| Step: 3
Training loss: 0.039888329803943634
Validation loss: 1.5146534609538254

Epoch: 5| Step: 4
Training loss: 0.07036010921001434
Validation loss: 1.5124175343462216

Epoch: 5| Step: 5
Training loss: 0.0572240836918354
Validation loss: 1.5205000433870541

Epoch: 5| Step: 6
Training loss: 0.05350800231099129
Validation loss: 1.5180558799415507

Epoch: 5| Step: 7
Training loss: 0.04046628624200821
Validation loss: 1.5188452492478073

Epoch: 5| Step: 8
Training loss: 0.09732908010482788
Validation loss: 1.5372165941422986

Epoch: 5| Step: 9
Training loss: 0.08705656230449677
Validation loss: 1.5154527810312086

Epoch: 5| Step: 10
Training loss: 0.07112274318933487
Validation loss: 1.521146100054505

Epoch: 682| Step: 0
Training loss: 0.04062320291996002
Validation loss: 1.4991560187391055

Epoch: 5| Step: 1
Training loss: 0.03098488785326481
Validation loss: 1.5303146980142082

Epoch: 5| Step: 2
Training loss: 0.0764121413230896
Validation loss: 1.5204150740818312

Epoch: 5| Step: 3
Training loss: 0.05715646222233772
Validation loss: 1.530051577475763

Epoch: 5| Step: 4
Training loss: 0.09008656442165375
Validation loss: 1.5096935149162047

Epoch: 5| Step: 5
Training loss: 0.11600003391504288
Validation loss: 1.5093420590123823

Epoch: 5| Step: 6
Training loss: 0.09864966571331024
Validation loss: 1.5131727521137526

Epoch: 5| Step: 7
Training loss: 0.04468202963471413
Validation loss: 1.523701065330095

Epoch: 5| Step: 8
Training loss: 0.06807515770196915
Validation loss: 1.5116679527426278

Epoch: 5| Step: 9
Training loss: 0.06548238545656204
Validation loss: 1.5176976547446301

Epoch: 5| Step: 10
Training loss: 0.09762528538703918
Validation loss: 1.4936608012004564

Epoch: 683| Step: 0
Training loss: 0.07620620727539062
Validation loss: 1.5054429577242943

Epoch: 5| Step: 1
Training loss: 0.06308045238256454
Validation loss: 1.4735637557122014

Epoch: 5| Step: 2
Training loss: 0.036799389868974686
Validation loss: 1.469173869779033

Epoch: 5| Step: 3
Training loss: 0.060237884521484375
Validation loss: 1.4820019288729596

Epoch: 5| Step: 4
Training loss: 0.03771231696009636
Validation loss: 1.5093627104195215

Epoch: 5| Step: 5
Training loss: 0.05272086709737778
Validation loss: 1.4864786248053274

Epoch: 5| Step: 6
Training loss: 0.09031037241220474
Validation loss: 1.506584103389453

Epoch: 5| Step: 7
Training loss: 0.07322940975427628
Validation loss: 1.521500115753502

Epoch: 5| Step: 8
Training loss: 0.1577548086643219
Validation loss: 1.5122728841279143

Epoch: 5| Step: 9
Training loss: 0.052091728895902634
Validation loss: 1.5029407585820844

Epoch: 5| Step: 10
Training loss: 0.08381503075361252
Validation loss: 1.494408074245658

Epoch: 684| Step: 0
Training loss: 0.09636027365922928
Validation loss: 1.4977875281405706

Epoch: 5| Step: 1
Training loss: 0.047056712210178375
Validation loss: 1.506424009159047

Epoch: 5| Step: 2
Training loss: 0.06874968856573105
Validation loss: 1.4987624268377981

Epoch: 5| Step: 3
Training loss: 0.09088784456253052
Validation loss: 1.509147733770391

Epoch: 5| Step: 4
Training loss: 0.057226985692977905
Validation loss: 1.5458137553225282

Epoch: 5| Step: 5
Training loss: 0.048061687499284744
Validation loss: 1.5254461714016494

Epoch: 5| Step: 6
Training loss: 0.053028225898742676
Validation loss: 1.534911778665358

Epoch: 5| Step: 7
Training loss: 0.0645919069647789
Validation loss: 1.5519501175931705

Epoch: 5| Step: 8
Training loss: 0.07399974018335342
Validation loss: 1.541405298376596

Epoch: 5| Step: 9
Training loss: 0.08813928067684174
Validation loss: 1.5887474635595917

Epoch: 5| Step: 10
Training loss: 0.04235991835594177
Validation loss: 1.543586290010842

Epoch: 685| Step: 0
Training loss: 0.07762502133846283
Validation loss: 1.5258440753465057

Epoch: 5| Step: 1
Training loss: 0.07521109282970428
Validation loss: 1.520866403015711

Epoch: 5| Step: 2
Training loss: 0.06472539901733398
Validation loss: 1.5215655488352622

Epoch: 5| Step: 3
Training loss: 0.09689943492412567
Validation loss: 1.5085500965836227

Epoch: 5| Step: 4
Training loss: 0.1392635554075241
Validation loss: 1.5116100471506837

Epoch: 5| Step: 5
Training loss: 0.05526912212371826
Validation loss: 1.519369174075383

Epoch: 5| Step: 6
Training loss: 0.06719405949115753
Validation loss: 1.561198926741077

Epoch: 5| Step: 7
Training loss: 0.11606212705373764
Validation loss: 1.5853295672324397

Epoch: 5| Step: 8
Training loss: 0.14294108748435974
Validation loss: 1.6045043148020262

Epoch: 5| Step: 9
Training loss: 0.09556617587804794
Validation loss: 1.5772908144099738

Epoch: 5| Step: 10
Training loss: 0.07623998820781708
Validation loss: 1.5607356384236326

Epoch: 686| Step: 0
Training loss: 0.08071677386760712
Validation loss: 1.5316527940893685

Epoch: 5| Step: 1
Training loss: 0.05713809281587601
Validation loss: 1.5099001264059415

Epoch: 5| Step: 2
Training loss: 0.11057470738887787
Validation loss: 1.511767941136514

Epoch: 5| Step: 3
Training loss: 0.06098570302128792
Validation loss: 1.5061855348207618

Epoch: 5| Step: 4
Training loss: 0.10582728683948517
Validation loss: 1.5059797238278132

Epoch: 5| Step: 5
Training loss: 0.07609282433986664
Validation loss: 1.530829252735261

Epoch: 5| Step: 6
Training loss: 0.07167308032512665
Validation loss: 1.5306454845654067

Epoch: 5| Step: 7
Training loss: 0.06887240707874298
Validation loss: 1.5398801283169818

Epoch: 5| Step: 8
Training loss: 0.14115828275680542
Validation loss: 1.5474122442224973

Epoch: 5| Step: 9
Training loss: 0.07500795274972916
Validation loss: 1.5588463365390737

Epoch: 5| Step: 10
Training loss: 0.12193471938371658
Validation loss: 1.5437133773680656

Epoch: 687| Step: 0
Training loss: 0.09428761899471283
Validation loss: 1.5420742945004535

Epoch: 5| Step: 1
Training loss: 0.03945727273821831
Validation loss: 1.5146255057345155

Epoch: 5| Step: 2
Training loss: 0.08201402425765991
Validation loss: 1.4862505159070414

Epoch: 5| Step: 3
Training loss: 0.09199840575456619
Validation loss: 1.495101369837279

Epoch: 5| Step: 4
Training loss: 0.05583159998059273
Validation loss: 1.5038094379568612

Epoch: 5| Step: 5
Training loss: 0.07490284740924835
Validation loss: 1.5156875502678655

Epoch: 5| Step: 6
Training loss: 0.06748686730861664
Validation loss: 1.4999679198829077

Epoch: 5| Step: 7
Training loss: 0.07208825647830963
Validation loss: 1.533328349872302

Epoch: 5| Step: 8
Training loss: 0.10380051285028458
Validation loss: 1.5770542237066454

Epoch: 5| Step: 9
Training loss: 0.09404867887496948
Validation loss: 1.5765254907710577

Epoch: 5| Step: 10
Training loss: 0.11911061406135559
Validation loss: 1.543474921616175

Epoch: 688| Step: 0
Training loss: 0.0866076797246933
Validation loss: 1.543710195890037

Epoch: 5| Step: 1
Training loss: 0.08557422459125519
Validation loss: 1.52474336213963

Epoch: 5| Step: 2
Training loss: 0.08348990976810455
Validation loss: 1.503053141537533

Epoch: 5| Step: 3
Training loss: 0.07760465145111084
Validation loss: 1.4890687260576474

Epoch: 5| Step: 4
Training loss: 0.07557456195354462
Validation loss: 1.5093624405963446

Epoch: 5| Step: 5
Training loss: 0.11081403493881226
Validation loss: 1.525278038876031

Epoch: 5| Step: 6
Training loss: 0.06303270906209946
Validation loss: 1.5287257759801802

Epoch: 5| Step: 7
Training loss: 0.053640592843294144
Validation loss: 1.5579973689971431

Epoch: 5| Step: 8
Training loss: 0.05346200615167618
Validation loss: 1.5339289608822073

Epoch: 5| Step: 9
Training loss: 0.085789754986763
Validation loss: 1.5480837591232792

Epoch: 5| Step: 10
Training loss: 0.09146219491958618
Validation loss: 1.5446293123306767

Epoch: 689| Step: 0
Training loss: 0.05933213233947754
Validation loss: 1.5174087567995953

Epoch: 5| Step: 1
Training loss: 0.07412105053663254
Validation loss: 1.5063059317168368

Epoch: 5| Step: 2
Training loss: 0.0417102687060833
Validation loss: 1.5081211084960608

Epoch: 5| Step: 3
Training loss: 0.0561198815703392
Validation loss: 1.4994518064683484

Epoch: 5| Step: 4
Training loss: 0.05448951572179794
Validation loss: 1.4829579066204768

Epoch: 5| Step: 5
Training loss: 0.08731530606746674
Validation loss: 1.4808004158799366

Epoch: 5| Step: 6
Training loss: 0.06628252565860748
Validation loss: 1.496889696326307

Epoch: 5| Step: 7
Training loss: 0.04062741994857788
Validation loss: 1.4873513585777693

Epoch: 5| Step: 8
Training loss: 0.07675214111804962
Validation loss: 1.538547267195999

Epoch: 5| Step: 9
Training loss: 0.06864253431558609
Validation loss: 1.5620302859173025

Epoch: 5| Step: 10
Training loss: 0.05664905905723572
Validation loss: 1.5680595136457873

Epoch: 690| Step: 0
Training loss: 0.060426343232393265
Validation loss: 1.5644083407617384

Epoch: 5| Step: 1
Training loss: 0.0447748526930809
Validation loss: 1.5827223908516668

Epoch: 5| Step: 2
Training loss: 0.028407514095306396
Validation loss: 1.5869888759428454

Epoch: 5| Step: 3
Training loss: 0.07109303772449493
Validation loss: 1.5873368247862785

Epoch: 5| Step: 4
Training loss: 0.05517396330833435
Validation loss: 1.5535997729147635

Epoch: 5| Step: 5
Training loss: 0.05316441133618355
Validation loss: 1.5677399981406428

Epoch: 5| Step: 6
Training loss: 0.11715606600046158
Validation loss: 1.5850984486200477

Epoch: 5| Step: 7
Training loss: 0.08798902481794357
Validation loss: 1.5590842032945285

Epoch: 5| Step: 8
Training loss: 0.055028609931468964
Validation loss: 1.5663897439997683

Epoch: 5| Step: 9
Training loss: 0.05211513116955757
Validation loss: 1.5737334682095436

Epoch: 5| Step: 10
Training loss: 0.07728630304336548
Validation loss: 1.5703249580116683

Epoch: 691| Step: 0
Training loss: 0.06390686333179474
Validation loss: 1.5761448785822878

Epoch: 5| Step: 1
Training loss: 0.06391346454620361
Validation loss: 1.5825831223559637

Epoch: 5| Step: 2
Training loss: 0.07488887012004852
Validation loss: 1.5736292882632184

Epoch: 5| Step: 3
Training loss: 0.06846960633993149
Validation loss: 1.568251854629927

Epoch: 5| Step: 4
Training loss: 0.07122046500444412
Validation loss: 1.5917854911537581

Epoch: 5| Step: 5
Training loss: 0.08236176520586014
Validation loss: 1.5828993948557044

Epoch: 5| Step: 6
Training loss: 0.03729705885052681
Validation loss: 1.598149440621817

Epoch: 5| Step: 7
Training loss: 0.08640623092651367
Validation loss: 1.6105964260716592

Epoch: 5| Step: 8
Training loss: 0.06337571144104004
Validation loss: 1.592948511082639

Epoch: 5| Step: 9
Training loss: 0.05680810287594795
Validation loss: 1.5512339068997292

Epoch: 5| Step: 10
Training loss: 0.0881912112236023
Validation loss: 1.57415795646688

Epoch: 692| Step: 0
Training loss: 0.0665600597858429
Validation loss: 1.5669943824891122

Epoch: 5| Step: 1
Training loss: 0.0762496069073677
Validation loss: 1.5881757249114334

Epoch: 5| Step: 2
Training loss: 0.04903347045183182
Validation loss: 1.5680332106928672

Epoch: 5| Step: 3
Training loss: 0.12187854945659637
Validation loss: 1.5711829200867684

Epoch: 5| Step: 4
Training loss: 0.060837846249341965
Validation loss: 1.604674332885332

Epoch: 5| Step: 5
Training loss: 0.053286194801330566
Validation loss: 1.6105034223166845

Epoch: 5| Step: 6
Training loss: 0.06560883671045303
Validation loss: 1.584829213798687

Epoch: 5| Step: 7
Training loss: 0.06730905920267105
Validation loss: 1.6132692867709744

Epoch: 5| Step: 8
Training loss: 0.052857257425785065
Validation loss: 1.6165214635992562

Epoch: 5| Step: 9
Training loss: 0.06417369842529297
Validation loss: 1.5989492811182493

Epoch: 5| Step: 10
Training loss: 0.0741533562541008
Validation loss: 1.5833101849402151

Epoch: 693| Step: 0
Training loss: 0.09710278362035751
Validation loss: 1.588020734889533

Epoch: 5| Step: 1
Training loss: 0.04941565915942192
Validation loss: 1.5775186400259695

Epoch: 5| Step: 2
Training loss: 0.0519319549202919
Validation loss: 1.5616882347291516

Epoch: 5| Step: 3
Training loss: 0.05847126245498657
Validation loss: 1.562006300495517

Epoch: 5| Step: 4
Training loss: 0.06733815371990204
Validation loss: 1.5439479556134952

Epoch: 5| Step: 5
Training loss: 0.08186475187540054
Validation loss: 1.5578472306651454

Epoch: 5| Step: 6
Training loss: 0.031739454716444016
Validation loss: 1.5560396999441168

Epoch: 5| Step: 7
Training loss: 0.1027316004037857
Validation loss: 1.545179723411478

Epoch: 5| Step: 8
Training loss: 0.07684306800365448
Validation loss: 1.5722611924653411

Epoch: 5| Step: 9
Training loss: 0.07226421684026718
Validation loss: 1.582155232788414

Epoch: 5| Step: 10
Training loss: 0.05555346980690956
Validation loss: 1.5672244077087731

Epoch: 694| Step: 0
Training loss: 0.07689420878887177
Validation loss: 1.565128235406773

Epoch: 5| Step: 1
Training loss: 0.08110643178224564
Validation loss: 1.5912597499867922

Epoch: 5| Step: 2
Training loss: 0.06857426464557648
Validation loss: 1.5988680162737448

Epoch: 5| Step: 3
Training loss: 0.03625789284706116
Validation loss: 1.5633751346218971

Epoch: 5| Step: 4
Training loss: 0.05372852087020874
Validation loss: 1.5346308523608791

Epoch: 5| Step: 5
Training loss: 0.037339482456445694
Validation loss: 1.562334931024941

Epoch: 5| Step: 6
Training loss: 0.07851920276880264
Validation loss: 1.5646007176368468

Epoch: 5| Step: 7
Training loss: 0.06299232691526413
Validation loss: 1.551645985213659

Epoch: 5| Step: 8
Training loss: 0.0614347942173481
Validation loss: 1.5716507447663175

Epoch: 5| Step: 9
Training loss: 0.10527510941028595
Validation loss: 1.5528582116608978

Epoch: 5| Step: 10
Training loss: 0.059259261935949326
Validation loss: 1.5454784798365768

Epoch: 695| Step: 0
Training loss: 0.08099772781133652
Validation loss: 1.5691746127220891

Epoch: 5| Step: 1
Training loss: 0.06272253394126892
Validation loss: 1.568802531047534

Epoch: 5| Step: 2
Training loss: 0.04759257286787033
Validation loss: 1.592880871988112

Epoch: 5| Step: 3
Training loss: 0.04890839383006096
Validation loss: 1.5794230571357153

Epoch: 5| Step: 4
Training loss: 0.08467883616685867
Validation loss: 1.6024457972536805

Epoch: 5| Step: 5
Training loss: 0.051560401916503906
Validation loss: 1.598653676689312

Epoch: 5| Step: 6
Training loss: 0.13448576629161835
Validation loss: 1.5807429026531916

Epoch: 5| Step: 7
Training loss: 0.08490126579999924
Validation loss: 1.5650032874076598

Epoch: 5| Step: 8
Training loss: 0.04497746378183365
Validation loss: 1.5079800980065459

Epoch: 5| Step: 9
Training loss: 0.04620792716741562
Validation loss: 1.4808565890917214

Epoch: 5| Step: 10
Training loss: 0.09613138437271118
Validation loss: 1.4865155796850882

Epoch: 696| Step: 0
Training loss: 0.10459865629673004
Validation loss: 1.4796043839505924

Epoch: 5| Step: 1
Training loss: 0.10032825171947479
Validation loss: 1.4920065543984855

Epoch: 5| Step: 2
Training loss: 0.08506645262241364
Validation loss: 1.4804328680038452

Epoch: 5| Step: 3
Training loss: 0.05044995993375778
Validation loss: 1.4888623170955206

Epoch: 5| Step: 4
Training loss: 0.12893451750278473
Validation loss: 1.5364411492501535

Epoch: 5| Step: 5
Training loss: 0.0557248592376709
Validation loss: 1.5367612954108947

Epoch: 5| Step: 6
Training loss: 0.08710390329360962
Validation loss: 1.512536737867581

Epoch: 5| Step: 7
Training loss: 0.05124485492706299
Validation loss: 1.52170273821841

Epoch: 5| Step: 8
Training loss: 0.06043960526585579
Validation loss: 1.5196026018870774

Epoch: 5| Step: 9
Training loss: 0.07334954291582108
Validation loss: 1.55438539033295

Epoch: 5| Step: 10
Training loss: 0.05663425475358963
Validation loss: 1.5578818334046232

Epoch: 697| Step: 0
Training loss: 0.08076886832714081
Validation loss: 1.5690085721272293

Epoch: 5| Step: 1
Training loss: 0.07386944442987442
Validation loss: 1.5720590160739036

Epoch: 5| Step: 2
Training loss: 0.042740266770124435
Validation loss: 1.5515509805371683

Epoch: 5| Step: 3
Training loss: 0.12642081081867218
Validation loss: 1.56863598990184

Epoch: 5| Step: 4
Training loss: 0.043917424976825714
Validation loss: 1.5800229067443519

Epoch: 5| Step: 5
Training loss: 0.1029265969991684
Validation loss: 1.5483786867510887

Epoch: 5| Step: 6
Training loss: 0.0630357638001442
Validation loss: 1.5439797486028364

Epoch: 5| Step: 7
Training loss: 0.05515943095088005
Validation loss: 1.53971855742957

Epoch: 5| Step: 8
Training loss: 0.046241410076618195
Validation loss: 1.5544849672625143

Epoch: 5| Step: 9
Training loss: 0.049321286380290985
Validation loss: 1.5372497932885283

Epoch: 5| Step: 10
Training loss: 0.07229050248861313
Validation loss: 1.5292290154323782

Epoch: 698| Step: 0
Training loss: 0.07518713921308517
Validation loss: 1.559536112252102

Epoch: 5| Step: 1
Training loss: 0.06157687306404114
Validation loss: 1.5544032947991484

Epoch: 5| Step: 2
Training loss: 0.043594978749752045
Validation loss: 1.5654103166313582

Epoch: 5| Step: 3
Training loss: 0.07663621008396149
Validation loss: 1.5531502923657816

Epoch: 5| Step: 4
Training loss: 0.05657011270523071
Validation loss: 1.5458699849344069

Epoch: 5| Step: 5
Training loss: 0.03505333885550499
Validation loss: 1.565232346134801

Epoch: 5| Step: 6
Training loss: 0.08425365388393402
Validation loss: 1.5925115744272869

Epoch: 5| Step: 7
Training loss: 0.0314730703830719
Validation loss: 1.5729582232813681

Epoch: 5| Step: 8
Training loss: 0.07814346253871918
Validation loss: 1.555915330686877

Epoch: 5| Step: 9
Training loss: 0.06335153430700302
Validation loss: 1.5175087323752783

Epoch: 5| Step: 10
Training loss: 0.03390083461999893
Validation loss: 1.5213913148449314

Epoch: 699| Step: 0
Training loss: 0.07136938720941544
Validation loss: 1.5220082306092786

Epoch: 5| Step: 1
Training loss: 0.06153186038136482
Validation loss: 1.531576338634696

Epoch: 5| Step: 2
Training loss: 0.029775669798254967
Validation loss: 1.4964448867305633

Epoch: 5| Step: 3
Training loss: 0.06406817585229874
Validation loss: 1.5025886899681502

Epoch: 5| Step: 4
Training loss: 0.05177774280309677
Validation loss: 1.523010039842257

Epoch: 5| Step: 5
Training loss: 0.0680890828371048
Validation loss: 1.5060646277602001

Epoch: 5| Step: 6
Training loss: 0.07337691634893417
Validation loss: 1.4998143578088412

Epoch: 5| Step: 7
Training loss: 0.03595651686191559
Validation loss: 1.521363317325551

Epoch: 5| Step: 8
Training loss: 0.04910733178257942
Validation loss: 1.5250449616421935

Epoch: 5| Step: 9
Training loss: 0.07374489307403564
Validation loss: 1.5121121163009315

Epoch: 5| Step: 10
Training loss: 0.09369458258152008
Validation loss: 1.5139351576887152

Epoch: 700| Step: 0
Training loss: 0.04989020898938179
Validation loss: 1.5465354893797187

Epoch: 5| Step: 1
Training loss: 0.034788377583026886
Validation loss: 1.5006028945728014

Epoch: 5| Step: 2
Training loss: 0.04895789921283722
Validation loss: 1.5163387175529235

Epoch: 5| Step: 3
Training loss: 0.04474583640694618
Validation loss: 1.5140521987791984

Epoch: 5| Step: 4
Training loss: 0.047367386519908905
Validation loss: 1.5324298938115437

Epoch: 5| Step: 5
Training loss: 0.06905482709407806
Validation loss: 1.533356434555464

Epoch: 5| Step: 6
Training loss: 0.0486789271235466
Validation loss: 1.526965533533404

Epoch: 5| Step: 7
Training loss: 0.10361041873693466
Validation loss: 1.5319503661124938

Epoch: 5| Step: 8
Training loss: 0.05509420484304428
Validation loss: 1.5199744137384559

Epoch: 5| Step: 9
Training loss: 0.04696076363325119
Validation loss: 1.529974869502488

Epoch: 5| Step: 10
Training loss: 0.07974418252706528
Validation loss: 1.5498841481824075

Epoch: 701| Step: 0
Training loss: 0.07537169009447098
Validation loss: 1.5585588562873103

Epoch: 5| Step: 1
Training loss: 0.06705604493618011
Validation loss: 1.5374717789311563

Epoch: 5| Step: 2
Training loss: 0.0556444451212883
Validation loss: 1.5252896611408522

Epoch: 5| Step: 3
Training loss: 0.027104169130325317
Validation loss: 1.5016251199988908

Epoch: 5| Step: 4
Training loss: 0.036704517900943756
Validation loss: 1.5200620082116896

Epoch: 5| Step: 5
Training loss: 0.034692466259002686
Validation loss: 1.5063983214798795

Epoch: 5| Step: 6
Training loss: 0.09141550213098526
Validation loss: 1.4959012590428835

Epoch: 5| Step: 7
Training loss: 0.04443969577550888
Validation loss: 1.5063833139275993

Epoch: 5| Step: 8
Training loss: 0.056247808039188385
Validation loss: 1.5252212965360252

Epoch: 5| Step: 9
Training loss: 0.06636254489421844
Validation loss: 1.492055941653508

Epoch: 5| Step: 10
Training loss: 0.10120923072099686
Validation loss: 1.5142648912245227

Epoch: 702| Step: 0
Training loss: 0.1046457514166832
Validation loss: 1.4870898787693312

Epoch: 5| Step: 1
Training loss: 0.04212689399719238
Validation loss: 1.5022591852372693

Epoch: 5| Step: 2
Training loss: 0.062179405242204666
Validation loss: 1.5106908044507426

Epoch: 5| Step: 3
Training loss: 0.05199737101793289
Validation loss: 1.5144913901564896

Epoch: 5| Step: 4
Training loss: 0.035224027931690216
Validation loss: 1.5436966996039114

Epoch: 5| Step: 5
Training loss: 0.024818871170282364
Validation loss: 1.5432285647238455

Epoch: 5| Step: 6
Training loss: 0.055861640721559525
Validation loss: 1.553470173189717

Epoch: 5| Step: 7
Training loss: 0.04643029719591141
Validation loss: 1.5672103256307623

Epoch: 5| Step: 8
Training loss: 0.05901271849870682
Validation loss: 1.5768437731650569

Epoch: 5| Step: 9
Training loss: 0.06272603571414948
Validation loss: 1.5869977397303427

Epoch: 5| Step: 10
Training loss: 0.07446317374706268
Validation loss: 1.5493547326775008

Epoch: 703| Step: 0
Training loss: 0.048594050109386444
Validation loss: 1.5385757300161547

Epoch: 5| Step: 1
Training loss: 0.04644595831632614
Validation loss: 1.5524199521669777

Epoch: 5| Step: 2
Training loss: 0.040088631212711334
Validation loss: 1.5376128009570542

Epoch: 5| Step: 3
Training loss: 0.08470605313777924
Validation loss: 1.529037267931046

Epoch: 5| Step: 4
Training loss: 0.08666462451219559
Validation loss: 1.5180096882645802

Epoch: 5| Step: 5
Training loss: 0.05719597265124321
Validation loss: 1.5451797605842672

Epoch: 5| Step: 6
Training loss: 0.059884212911129
Validation loss: 1.5338297274804884

Epoch: 5| Step: 7
Training loss: 0.03913556784391403
Validation loss: 1.537214651543607

Epoch: 5| Step: 8
Training loss: 0.04775795340538025
Validation loss: 1.5081367441402969

Epoch: 5| Step: 9
Training loss: 0.053440116345882416
Validation loss: 1.5314144229376188

Epoch: 5| Step: 10
Training loss: 0.04510807245969772
Validation loss: 1.531042580963463

Epoch: 704| Step: 0
Training loss: 0.055004991590976715
Validation loss: 1.5392227762488908

Epoch: 5| Step: 1
Training loss: 0.041476357728242874
Validation loss: 1.5364470584418184

Epoch: 5| Step: 2
Training loss: 0.06169964745640755
Validation loss: 1.5295722542270538

Epoch: 5| Step: 3
Training loss: 0.07952775806188583
Validation loss: 1.5545031960292528

Epoch: 5| Step: 4
Training loss: 0.03142882511019707
Validation loss: 1.5596146980921428

Epoch: 5| Step: 5
Training loss: 0.04711814597249031
Validation loss: 1.550122787875514

Epoch: 5| Step: 6
Training loss: 0.045677877962589264
Validation loss: 1.5624731766280306

Epoch: 5| Step: 7
Training loss: 0.05834130570292473
Validation loss: 1.5648862905399774

Epoch: 5| Step: 8
Training loss: 0.053457874804735184
Validation loss: 1.5609411770297634

Epoch: 5| Step: 9
Training loss: 0.0873318612575531
Validation loss: 1.5775562332522484

Epoch: 5| Step: 10
Training loss: 0.09375936537981033
Validation loss: 1.5396136814548123

Epoch: 705| Step: 0
Training loss: 0.09829244762659073
Validation loss: 1.5577954733243553

Epoch: 5| Step: 1
Training loss: 0.04307938367128372
Validation loss: 1.5593569791445168

Epoch: 5| Step: 2
Training loss: 0.05590264871716499
Validation loss: 1.5651135419004707

Epoch: 5| Step: 3
Training loss: 0.0785830095410347
Validation loss: 1.553161859512329

Epoch: 5| Step: 4
Training loss: 0.038221050053834915
Validation loss: 1.5649806068789573

Epoch: 5| Step: 5
Training loss: 0.10022146999835968
Validation loss: 1.5611399835155857

Epoch: 5| Step: 6
Training loss: 0.038214921951293945
Validation loss: 1.5602231076968613

Epoch: 5| Step: 7
Training loss: 0.06232939288020134
Validation loss: 1.553863888145775

Epoch: 5| Step: 8
Training loss: 0.07873956859111786
Validation loss: 1.5473342595561859

Epoch: 5| Step: 9
Training loss: 0.053745366632938385
Validation loss: 1.551163734928254

Epoch: 5| Step: 10
Training loss: 0.05158467963337898
Validation loss: 1.5480814287739415

Epoch: 706| Step: 0
Training loss: 0.06523208320140839
Validation loss: 1.5470634404049124

Epoch: 5| Step: 1
Training loss: 0.07374583929777145
Validation loss: 1.5561690830415296

Epoch: 5| Step: 2
Training loss: 0.0556081160902977
Validation loss: 1.546498910073311

Epoch: 5| Step: 3
Training loss: 0.06689880788326263
Validation loss: 1.5552954930131153

Epoch: 5| Step: 4
Training loss: 0.11774082481861115
Validation loss: 1.5458659869368359

Epoch: 5| Step: 5
Training loss: 0.03569021075963974
Validation loss: 1.5416649003182687

Epoch: 5| Step: 6
Training loss: 0.07443220913410187
Validation loss: 1.5267612831566924

Epoch: 5| Step: 7
Training loss: 0.05141349881887436
Validation loss: 1.534160308299526

Epoch: 5| Step: 8
Training loss: 0.059969156980514526
Validation loss: 1.5513892532676778

Epoch: 5| Step: 9
Training loss: 0.04634159058332443
Validation loss: 1.5212017336199362

Epoch: 5| Step: 10
Training loss: 0.09446340799331665
Validation loss: 1.5441973170926493

Epoch: 707| Step: 0
Training loss: 0.04499143362045288
Validation loss: 1.5172433750603789

Epoch: 5| Step: 1
Training loss: 0.06370305269956589
Validation loss: 1.534330633378798

Epoch: 5| Step: 2
Training loss: 0.0416717454791069
Validation loss: 1.536386016876467

Epoch: 5| Step: 3
Training loss: 0.04616294428706169
Validation loss: 1.525021235148112

Epoch: 5| Step: 4
Training loss: 0.09595973044633865
Validation loss: 1.5213025141787786

Epoch: 5| Step: 5
Training loss: 0.046409644186496735
Validation loss: 1.5364907082690988

Epoch: 5| Step: 6
Training loss: 0.056874655187129974
Validation loss: 1.512990709914956

Epoch: 5| Step: 7
Training loss: 0.03812100738286972
Validation loss: 1.5426363509188417

Epoch: 5| Step: 8
Training loss: 0.07759246975183487
Validation loss: 1.5606528956403014

Epoch: 5| Step: 9
Training loss: 0.07038215547800064
Validation loss: 1.5506651798884075

Epoch: 5| Step: 10
Training loss: 0.10111190378665924
Validation loss: 1.5374310106359503

Epoch: 708| Step: 0
Training loss: 0.09912852197885513
Validation loss: 1.5270577092324533

Epoch: 5| Step: 1
Training loss: 0.06753446161746979
Validation loss: 1.5405556565971785

Epoch: 5| Step: 2
Training loss: 0.04467402771115303
Validation loss: 1.5356630586808728

Epoch: 5| Step: 3
Training loss: 0.07360696792602539
Validation loss: 1.526667288554612

Epoch: 5| Step: 4
Training loss: 0.08398013561964035
Validation loss: 1.5289314152092062

Epoch: 5| Step: 5
Training loss: 0.051564037799835205
Validation loss: 1.5061071688129055

Epoch: 5| Step: 6
Training loss: 0.0738844946026802
Validation loss: 1.537227665224383

Epoch: 5| Step: 7
Training loss: 0.0950305238366127
Validation loss: 1.533799015065675

Epoch: 5| Step: 8
Training loss: 0.06074308231472969
Validation loss: 1.5080946363428587

Epoch: 5| Step: 9
Training loss: 0.04308111593127251
Validation loss: 1.5081093029309345

Epoch: 5| Step: 10
Training loss: 0.06373157352209091
Validation loss: 1.4879497481930641

Epoch: 709| Step: 0
Training loss: 0.040017325431108475
Validation loss: 1.503962221965995

Epoch: 5| Step: 1
Training loss: 0.0749211385846138
Validation loss: 1.5067196456334924

Epoch: 5| Step: 2
Training loss: 0.04588695988059044
Validation loss: 1.527696701788133

Epoch: 5| Step: 3
Training loss: 0.06657425314188004
Validation loss: 1.505109308868326

Epoch: 5| Step: 4
Training loss: 0.05613765865564346
Validation loss: 1.5179034458693637

Epoch: 5| Step: 5
Training loss: 0.09275612980127335
Validation loss: 1.503728441012803

Epoch: 5| Step: 6
Training loss: 0.08220826089382172
Validation loss: 1.497352418079171

Epoch: 5| Step: 7
Training loss: 0.032857734709978104
Validation loss: 1.503358684560304

Epoch: 5| Step: 8
Training loss: 0.06691651791334152
Validation loss: 1.5056113748140232

Epoch: 5| Step: 9
Training loss: 0.05928893759846687
Validation loss: 1.4852071244229552

Epoch: 5| Step: 10
Training loss: 0.053853701800107956
Validation loss: 1.4827677114035493

Epoch: 710| Step: 0
Training loss: 0.044118963181972504
Validation loss: 1.5035916169484456

Epoch: 5| Step: 1
Training loss: 0.07713576406240463
Validation loss: 1.5226096760842107

Epoch: 5| Step: 2
Training loss: 0.05595808103680611
Validation loss: 1.5118304119315198

Epoch: 5| Step: 3
Training loss: 0.08534489572048187
Validation loss: 1.5162422836467784

Epoch: 5| Step: 4
Training loss: 0.08453039079904556
Validation loss: 1.5013676548516879

Epoch: 5| Step: 5
Training loss: 0.07374374568462372
Validation loss: 1.4975903482847317

Epoch: 5| Step: 6
Training loss: 0.05867509916424751
Validation loss: 1.4657551191186393

Epoch: 5| Step: 7
Training loss: 0.07896033674478531
Validation loss: 1.4903761750908309

Epoch: 5| Step: 8
Training loss: 0.07464978843927383
Validation loss: 1.5018415989414338

Epoch: 5| Step: 9
Training loss: 0.046023253351449966
Validation loss: 1.5120811680311799

Epoch: 5| Step: 10
Training loss: 0.0688004344701767
Validation loss: 1.4949496664026731

Epoch: 711| Step: 0
Training loss: 0.0809444710612297
Validation loss: 1.532306186614498

Epoch: 5| Step: 1
Training loss: 0.035933949053287506
Validation loss: 1.5266421533400012

Epoch: 5| Step: 2
Training loss: 0.07879351079463959
Validation loss: 1.545173490560183

Epoch: 5| Step: 3
Training loss: 0.05559535697102547
Validation loss: 1.5534347449579546

Epoch: 5| Step: 4
Training loss: 0.08730721473693848
Validation loss: 1.552375885748094

Epoch: 5| Step: 5
Training loss: 0.04861588031053543
Validation loss: 1.5580280788483158

Epoch: 5| Step: 6
Training loss: 0.05685596540570259
Validation loss: 1.5561133277031682

Epoch: 5| Step: 7
Training loss: 0.06822328269481659
Validation loss: 1.5859266596455728

Epoch: 5| Step: 8
Training loss: 0.04568095877766609
Validation loss: 1.5455806357886201

Epoch: 5| Step: 9
Training loss: 0.06621768325567245
Validation loss: 1.5661525187953826

Epoch: 5| Step: 10
Training loss: 0.04263979196548462
Validation loss: 1.552802102540129

Epoch: 712| Step: 0
Training loss: 0.07340437173843384
Validation loss: 1.5371227008040234

Epoch: 5| Step: 1
Training loss: 0.09799116104841232
Validation loss: 1.5579800285318846

Epoch: 5| Step: 2
Training loss: 0.035695772618055344
Validation loss: 1.565607504178119

Epoch: 5| Step: 3
Training loss: 0.02864552102982998
Validation loss: 1.5505700265207598

Epoch: 5| Step: 4
Training loss: 0.04703465476632118
Validation loss: 1.5353240620705388

Epoch: 5| Step: 5
Training loss: 0.06264220178127289
Validation loss: 1.5335651757896587

Epoch: 5| Step: 6
Training loss: 0.04183581843972206
Validation loss: 1.5235539617076996

Epoch: 5| Step: 7
Training loss: 0.0925040990114212
Validation loss: 1.5252817087276007

Epoch: 5| Step: 8
Training loss: 0.04548787325620651
Validation loss: 1.519880622945806

Epoch: 5| Step: 9
Training loss: 0.05028798058629036
Validation loss: 1.5322667770488287

Epoch: 5| Step: 10
Training loss: 0.04577977955341339
Validation loss: 1.5172977601328204

Epoch: 713| Step: 0
Training loss: 0.06589754670858383
Validation loss: 1.5327302025210472

Epoch: 5| Step: 1
Training loss: 0.05190454050898552
Validation loss: 1.5445733237010177

Epoch: 5| Step: 2
Training loss: 0.04424931854009628
Validation loss: 1.5405230176064275

Epoch: 5| Step: 3
Training loss: 0.054199330508708954
Validation loss: 1.5387576010919386

Epoch: 5| Step: 4
Training loss: 0.07372395694255829
Validation loss: 1.537570131722317

Epoch: 5| Step: 5
Training loss: 0.0556778609752655
Validation loss: 1.5348374356505692

Epoch: 5| Step: 6
Training loss: 0.06787753850221634
Validation loss: 1.5486996314858879

Epoch: 5| Step: 7
Training loss: 0.0543985553085804
Validation loss: 1.5250729386524489

Epoch: 5| Step: 8
Training loss: 0.04902256280183792
Validation loss: 1.5208077167951932

Epoch: 5| Step: 9
Training loss: 0.07312992960214615
Validation loss: 1.5252038624978834

Epoch: 5| Step: 10
Training loss: 0.07537555694580078
Validation loss: 1.5278761694508214

Epoch: 714| Step: 0
Training loss: 0.053768228739500046
Validation loss: 1.5366667098896478

Epoch: 5| Step: 1
Training loss: 0.04318343847990036
Validation loss: 1.5285492289450862

Epoch: 5| Step: 2
Training loss: 0.0857425108551979
Validation loss: 1.5612463476837322

Epoch: 5| Step: 3
Training loss: 0.06637436896562576
Validation loss: 1.524607619931621

Epoch: 5| Step: 4
Training loss: 0.03707007318735123
Validation loss: 1.5169896092466129

Epoch: 5| Step: 5
Training loss: 0.04352159425616264
Validation loss: 1.5463909923389394

Epoch: 5| Step: 6
Training loss: 0.06986359506845474
Validation loss: 1.5382534150154359

Epoch: 5| Step: 7
Training loss: 0.06255456060171127
Validation loss: 1.5284782878814205

Epoch: 5| Step: 8
Training loss: 0.06514672189950943
Validation loss: 1.539489753784672

Epoch: 5| Step: 9
Training loss: 0.07918150722980499
Validation loss: 1.5127929282444779

Epoch: 5| Step: 10
Training loss: 0.04582527279853821
Validation loss: 1.5053780181433565

Epoch: 715| Step: 0
Training loss: 0.06829117983579636
Validation loss: 1.5153435635310348

Epoch: 5| Step: 1
Training loss: 0.07396484166383743
Validation loss: 1.521846999404251

Epoch: 5| Step: 2
Training loss: 0.05037027597427368
Validation loss: 1.5208667811527048

Epoch: 5| Step: 3
Training loss: 0.08191809803247452
Validation loss: 1.5500009944362025

Epoch: 5| Step: 4
Training loss: 0.0468914732336998
Validation loss: 1.5391107695077055

Epoch: 5| Step: 5
Training loss: 0.07753060758113861
Validation loss: 1.5349055272276684

Epoch: 5| Step: 6
Training loss: 0.03362756967544556
Validation loss: 1.5400651475434661

Epoch: 5| Step: 7
Training loss: 0.04710375517606735
Validation loss: 1.5295453327958302

Epoch: 5| Step: 8
Training loss: 0.03113497421145439
Validation loss: 1.5311213680492934

Epoch: 5| Step: 9
Training loss: 0.05879594013094902
Validation loss: 1.5489363042257165

Epoch: 5| Step: 10
Training loss: 0.05283263698220253
Validation loss: 1.5335063088324763

Epoch: 716| Step: 0
Training loss: 0.08598698675632477
Validation loss: 1.5373321822894517

Epoch: 5| Step: 1
Training loss: 0.08698099851608276
Validation loss: 1.5103989288371096

Epoch: 5| Step: 2
Training loss: 0.07481074333190918
Validation loss: 1.5297421255419332

Epoch: 5| Step: 3
Training loss: 0.04585427790880203
Validation loss: 1.518531418615772

Epoch: 5| Step: 4
Training loss: 0.035609327256679535
Validation loss: 1.540565408686156

Epoch: 5| Step: 5
Training loss: 0.056973814964294434
Validation loss: 1.5398926286287205

Epoch: 5| Step: 6
Training loss: 0.0446077361702919
Validation loss: 1.511298535972513

Epoch: 5| Step: 7
Training loss: 0.04939340427517891
Validation loss: 1.5226506610070505

Epoch: 5| Step: 8
Training loss: 0.05730156973004341
Validation loss: 1.5285931620546567

Epoch: 5| Step: 9
Training loss: 0.0487859882414341
Validation loss: 1.51449042366397

Epoch: 5| Step: 10
Training loss: 0.05242207273840904
Validation loss: 1.4948136755215224

Epoch: 717| Step: 0
Training loss: 0.10032317787408829
Validation loss: 1.50215515013664

Epoch: 5| Step: 1
Training loss: 0.05232159420847893
Validation loss: 1.4966156931333645

Epoch: 5| Step: 2
Training loss: 0.04285946860909462
Validation loss: 1.4945495417041164

Epoch: 5| Step: 3
Training loss: 0.0440838560461998
Validation loss: 1.5014464944921515

Epoch: 5| Step: 4
Training loss: 0.047538209706544876
Validation loss: 1.5298413957959862

Epoch: 5| Step: 5
Training loss: 0.06022627279162407
Validation loss: 1.546035382055467

Epoch: 5| Step: 6
Training loss: 0.034456364810466766
Validation loss: 1.5256879932136946

Epoch: 5| Step: 7
Training loss: 0.046802278608083725
Validation loss: 1.5275816596964353

Epoch: 5| Step: 8
Training loss: 0.09520167112350464
Validation loss: 1.5561417559141755

Epoch: 5| Step: 9
Training loss: 0.06761588901281357
Validation loss: 1.5035022458722513

Epoch: 5| Step: 10
Training loss: 0.06900579482316971
Validation loss: 1.534172204232985

Epoch: 718| Step: 0
Training loss: 0.0757969543337822
Validation loss: 1.5084506747543172

Epoch: 5| Step: 1
Training loss: 0.02942097745835781
Validation loss: 1.5102704853139899

Epoch: 5| Step: 2
Training loss: 0.04274676367640495
Validation loss: 1.5124015321013748

Epoch: 5| Step: 3
Training loss: 0.04498064145445824
Validation loss: 1.520759274882655

Epoch: 5| Step: 4
Training loss: 0.13517144322395325
Validation loss: 1.522927850805303

Epoch: 5| Step: 5
Training loss: 0.04752376675605774
Validation loss: 1.4993641197040517

Epoch: 5| Step: 6
Training loss: 0.07054801285266876
Validation loss: 1.5087449037900535

Epoch: 5| Step: 7
Training loss: 0.049428340047597885
Validation loss: 1.521484689045978

Epoch: 5| Step: 8
Training loss: 0.04804883152246475
Validation loss: 1.5053924552855953

Epoch: 5| Step: 9
Training loss: 0.08382949978113174
Validation loss: 1.5424067768999326

Epoch: 5| Step: 10
Training loss: 0.043104156851768494
Validation loss: 1.5471299694430443

Epoch: 719| Step: 0
Training loss: 0.06768666952848434
Validation loss: 1.5483842440830764

Epoch: 5| Step: 1
Training loss: 0.0401560440659523
Validation loss: 1.5419797038519254

Epoch: 5| Step: 2
Training loss: 0.0494823083281517
Validation loss: 1.5223390799696728

Epoch: 5| Step: 3
Training loss: 0.05243026092648506
Validation loss: 1.5563997325076853

Epoch: 5| Step: 4
Training loss: 0.07258179783821106
Validation loss: 1.5358108820453766

Epoch: 5| Step: 5
Training loss: 0.1091098040342331
Validation loss: 1.5637656680999263

Epoch: 5| Step: 6
Training loss: 0.06697000563144684
Validation loss: 1.531483547020984

Epoch: 5| Step: 7
Training loss: 0.03849024325609207
Validation loss: 1.5272155820682485

Epoch: 5| Step: 8
Training loss: 0.07188574969768524
Validation loss: 1.538190871156672

Epoch: 5| Step: 9
Training loss: 0.077305369079113
Validation loss: 1.5220917713257573

Epoch: 5| Step: 10
Training loss: 0.03159388154745102
Validation loss: 1.5120745705020042

Epoch: 720| Step: 0
Training loss: 0.07852043211460114
Validation loss: 1.5324451974643174

Epoch: 5| Step: 1
Training loss: 0.02559388056397438
Validation loss: 1.5345487286967616

Epoch: 5| Step: 2
Training loss: 0.042575985193252563
Validation loss: 1.5168110375763268

Epoch: 5| Step: 3
Training loss: 0.058405615389347076
Validation loss: 1.5339827024808494

Epoch: 5| Step: 4
Training loss: 0.05930628627538681
Validation loss: 1.5356882541410384

Epoch: 5| Step: 5
Training loss: 0.05200387164950371
Validation loss: 1.5550076698744169

Epoch: 5| Step: 6
Training loss: 0.04329397529363632
Validation loss: 1.5332261852679714

Epoch: 5| Step: 7
Training loss: 0.042893461883068085
Validation loss: 1.5240195592244465

Epoch: 5| Step: 8
Training loss: 0.0604524239897728
Validation loss: 1.5131692783806914

Epoch: 5| Step: 9
Training loss: 0.08340499550104141
Validation loss: 1.4914204766673427

Epoch: 5| Step: 10
Training loss: 0.06902702897787094
Validation loss: 1.523438424192449

Epoch: 721| Step: 0
Training loss: 0.06297260522842407
Validation loss: 1.5278020571636897

Epoch: 5| Step: 1
Training loss: 0.10898707807064056
Validation loss: 1.560323739564547

Epoch: 5| Step: 2
Training loss: 0.050451409071683884
Validation loss: 1.5552633000958351

Epoch: 5| Step: 3
Training loss: 0.0701175108551979
Validation loss: 1.5736998338853159

Epoch: 5| Step: 4
Training loss: 0.0431138351559639
Validation loss: 1.5897342915176063

Epoch: 5| Step: 5
Training loss: 0.06265771389007568
Validation loss: 1.5548663587980374

Epoch: 5| Step: 6
Training loss: 0.07060650736093521
Validation loss: 1.554283865036503

Epoch: 5| Step: 7
Training loss: 0.04405400902032852
Validation loss: 1.543150298057064

Epoch: 5| Step: 8
Training loss: 0.06007914990186691
Validation loss: 1.5208763941641776

Epoch: 5| Step: 9
Training loss: 0.05304359272122383
Validation loss: 1.5031309512353712

Epoch: 5| Step: 10
Training loss: 0.10270599275827408
Validation loss: 1.5418277901987876

Epoch: 722| Step: 0
Training loss: 0.08149654418230057
Validation loss: 1.517839809899689

Epoch: 5| Step: 1
Training loss: 0.04048744961619377
Validation loss: 1.5186841193065848

Epoch: 5| Step: 2
Training loss: 0.037683237344026566
Validation loss: 1.5297792521856164

Epoch: 5| Step: 3
Training loss: 0.05688941478729248
Validation loss: 1.5084960063298543

Epoch: 5| Step: 4
Training loss: 0.057678572833538055
Validation loss: 1.5378546650691698

Epoch: 5| Step: 5
Training loss: 0.038990627974271774
Validation loss: 1.5196953383825158

Epoch: 5| Step: 6
Training loss: 0.06420023739337921
Validation loss: 1.5165883610325475

Epoch: 5| Step: 7
Training loss: 0.09549006074666977
Validation loss: 1.5088257494793142

Epoch: 5| Step: 8
Training loss: 0.060935042798519135
Validation loss: 1.5313259747720533

Epoch: 5| Step: 9
Training loss: 0.0559149906039238
Validation loss: 1.5004040118186706

Epoch: 5| Step: 10
Training loss: 0.09421801567077637
Validation loss: 1.5089834313238821

Epoch: 723| Step: 0
Training loss: 0.07217572629451752
Validation loss: 1.522211782393917

Epoch: 5| Step: 1
Training loss: 0.05457473546266556
Validation loss: 1.5061848407150598

Epoch: 5| Step: 2
Training loss: 0.04316093027591705
Validation loss: 1.512982968361147

Epoch: 5| Step: 3
Training loss: 0.04036106914281845
Validation loss: 1.5169534772954962

Epoch: 5| Step: 4
Training loss: 0.039276547729969025
Validation loss: 1.5289805986547982

Epoch: 5| Step: 5
Training loss: 0.04825936257839203
Validation loss: 1.5145422925231278

Epoch: 5| Step: 6
Training loss: 0.07981214672327042
Validation loss: 1.5346413081692112

Epoch: 5| Step: 7
Training loss: 0.0454307496547699
Validation loss: 1.5292086639711935

Epoch: 5| Step: 8
Training loss: 0.10831230878829956
Validation loss: 1.5453745575361355

Epoch: 5| Step: 9
Training loss: 0.04723288118839264
Validation loss: 1.5383936884582683

Epoch: 5| Step: 10
Training loss: 0.07767149060964584
Validation loss: 1.5315718304726385

Epoch: 724| Step: 0
Training loss: 0.06416527181863785
Validation loss: 1.5476558823739328

Epoch: 5| Step: 1
Training loss: 0.03707922250032425
Validation loss: 1.5231603384017944

Epoch: 5| Step: 2
Training loss: 0.0559258833527565
Validation loss: 1.500559849764711

Epoch: 5| Step: 3
Training loss: 0.0379718542098999
Validation loss: 1.5156194394634617

Epoch: 5| Step: 4
Training loss: 0.10204468667507172
Validation loss: 1.516591852711093

Epoch: 5| Step: 5
Training loss: 0.06709989160299301
Validation loss: 1.4904048519749795

Epoch: 5| Step: 6
Training loss: 0.057645879685878754
Validation loss: 1.483896069629218

Epoch: 5| Step: 7
Training loss: 0.0578395240008831
Validation loss: 1.5069628287387151

Epoch: 5| Step: 8
Training loss: 0.06225323677062988
Validation loss: 1.5118071392018309

Epoch: 5| Step: 9
Training loss: 0.03930710256099701
Validation loss: 1.4960723038642638

Epoch: 5| Step: 10
Training loss: 0.041741710156202316
Validation loss: 1.4938725489442066

Epoch: 725| Step: 0
Training loss: 0.04622665047645569
Validation loss: 1.5062606514141124

Epoch: 5| Step: 1
Training loss: 0.054727960377931595
Validation loss: 1.4954508671196558

Epoch: 5| Step: 2
Training loss: 0.03751543164253235
Validation loss: 1.5064303567332606

Epoch: 5| Step: 3
Training loss: 0.08292054384946823
Validation loss: 1.5264836601031724

Epoch: 5| Step: 4
Training loss: 0.0641247034072876
Validation loss: 1.5396322960494666

Epoch: 5| Step: 5
Training loss: 0.04215595871210098
Validation loss: 1.5377355256388265

Epoch: 5| Step: 6
Training loss: 0.07434762269258499
Validation loss: 1.5239042684596071

Epoch: 5| Step: 7
Training loss: 0.033202748745679855
Validation loss: 1.5366552209341398

Epoch: 5| Step: 8
Training loss: 0.06573507934808731
Validation loss: 1.5675565683713524

Epoch: 5| Step: 9
Training loss: 0.0673305094242096
Validation loss: 1.5481473258746568

Epoch: 5| Step: 10
Training loss: 0.02976110391318798
Validation loss: 1.533519660272906

Epoch: 726| Step: 0
Training loss: 0.06539961695671082
Validation loss: 1.5245629702844927

Epoch: 5| Step: 1
Training loss: 0.09075511991977692
Validation loss: 1.5086753778560187

Epoch: 5| Step: 2
Training loss: 0.05502277612686157
Validation loss: 1.5149734673961517

Epoch: 5| Step: 3
Training loss: 0.03101893700659275
Validation loss: 1.5313329465927616

Epoch: 5| Step: 4
Training loss: 0.038866735994815826
Validation loss: 1.5146517689510057

Epoch: 5| Step: 5
Training loss: 0.09792251884937286
Validation loss: 1.514041575052405

Epoch: 5| Step: 6
Training loss: 0.050639666616916656
Validation loss: 1.5407405681507562

Epoch: 5| Step: 7
Training loss: 0.04554042965173721
Validation loss: 1.5283377401290401

Epoch: 5| Step: 8
Training loss: 0.025598546490073204
Validation loss: 1.5487947335807226

Epoch: 5| Step: 9
Training loss: 0.05277581140398979
Validation loss: 1.5198931719667168

Epoch: 5| Step: 10
Training loss: 0.05967188626527786
Validation loss: 1.5498981296375234

Epoch: 727| Step: 0
Training loss: 0.05820899084210396
Validation loss: 1.5336954209112352

Epoch: 5| Step: 1
Training loss: 0.07531635463237762
Validation loss: 1.5379992851646997

Epoch: 5| Step: 2
Training loss: 0.08884866535663605
Validation loss: 1.5310219308381439

Epoch: 5| Step: 3
Training loss: 0.06982073932886124
Validation loss: 1.5502219841044436

Epoch: 5| Step: 4
Training loss: 0.06482584774494171
Validation loss: 1.5543038325925027

Epoch: 5| Step: 5
Training loss: 0.04535181075334549
Validation loss: 1.5948458717715355

Epoch: 5| Step: 6
Training loss: 0.046139564365148544
Validation loss: 1.6094143339382705

Epoch: 5| Step: 7
Training loss: 0.058312129229307175
Validation loss: 1.5557200421569168

Epoch: 5| Step: 8
Training loss: 0.045408524572849274
Validation loss: 1.5572591071487756

Epoch: 5| Step: 9
Training loss: 0.057051997631788254
Validation loss: 1.5391170619636454

Epoch: 5| Step: 10
Training loss: 0.06314244866371155
Validation loss: 1.5464727840115946

Epoch: 728| Step: 0
Training loss: 0.08361907303333282
Validation loss: 1.5401866833368938

Epoch: 5| Step: 1
Training loss: 0.11965713649988174
Validation loss: 1.5423136885448168

Epoch: 5| Step: 2
Training loss: 0.047378819435834885
Validation loss: 1.5360277301521712

Epoch: 5| Step: 3
Training loss: 0.045603446662425995
Validation loss: 1.5227561484100998

Epoch: 5| Step: 4
Training loss: 0.047354500740766525
Validation loss: 1.5343646900628203

Epoch: 5| Step: 5
Training loss: 0.054419636726379395
Validation loss: 1.5151585622500348

Epoch: 5| Step: 6
Training loss: 0.03838919475674629
Validation loss: 1.53563182456519

Epoch: 5| Step: 7
Training loss: 0.06519613415002823
Validation loss: 1.5189034272265691

Epoch: 5| Step: 8
Training loss: 0.04916311427950859
Validation loss: 1.5328047583180089

Epoch: 5| Step: 9
Training loss: 0.06502015888690948
Validation loss: 1.534381023017309

Epoch: 5| Step: 10
Training loss: 0.04041988402605057
Validation loss: 1.5520369096468853

Epoch: 729| Step: 0
Training loss: 0.05784984678030014
Validation loss: 1.5157301925843762

Epoch: 5| Step: 1
Training loss: 0.07785693556070328
Validation loss: 1.519234352214362

Epoch: 5| Step: 2
Training loss: 0.045820508152246475
Validation loss: 1.499819085162173

Epoch: 5| Step: 3
Training loss: 0.041579388082027435
Validation loss: 1.5121974688704296

Epoch: 5| Step: 4
Training loss: 0.07590726017951965
Validation loss: 1.5289734243064799

Epoch: 5| Step: 5
Training loss: 0.04077683761715889
Validation loss: 1.511467731127175

Epoch: 5| Step: 6
Training loss: 0.03156353160738945
Validation loss: 1.5183924282750776

Epoch: 5| Step: 7
Training loss: 0.06162169575691223
Validation loss: 1.489527290867221

Epoch: 5| Step: 8
Training loss: 0.0400591678917408
Validation loss: 1.5054979580704884

Epoch: 5| Step: 9
Training loss: 0.04129355773329735
Validation loss: 1.5093705731053506

Epoch: 5| Step: 10
Training loss: 0.06777939200401306
Validation loss: 1.5188896284308484

Epoch: 730| Step: 0
Training loss: 0.056776564568281174
Validation loss: 1.5294396569651942

Epoch: 5| Step: 1
Training loss: 0.05707366392016411
Validation loss: 1.5189907973812473

Epoch: 5| Step: 2
Training loss: 0.09540858119726181
Validation loss: 1.522362134789908

Epoch: 5| Step: 3
Training loss: 0.07176315784454346
Validation loss: 1.502769753497134

Epoch: 5| Step: 4
Training loss: 0.059278737753629684
Validation loss: 1.4911880582891486

Epoch: 5| Step: 5
Training loss: 0.04574234411120415
Validation loss: 1.4936658631088913

Epoch: 5| Step: 6
Training loss: 0.04962291195988655
Validation loss: 1.4981882264537196

Epoch: 5| Step: 7
Training loss: 0.05200185254216194
Validation loss: 1.4866701261971587

Epoch: 5| Step: 8
Training loss: 0.09850253164768219
Validation loss: 1.5028984790207238

Epoch: 5| Step: 9
Training loss: 0.05267916992306709
Validation loss: 1.5215526062955138

Epoch: 5| Step: 10
Training loss: 0.05310622975230217
Validation loss: 1.5351033486345762

Epoch: 731| Step: 0
Training loss: 0.035990845412015915
Validation loss: 1.5364307357418923

Epoch: 5| Step: 1
Training loss: 0.07688874006271362
Validation loss: 1.5356673245788903

Epoch: 5| Step: 2
Training loss: 0.08859451860189438
Validation loss: 1.5375027131008845

Epoch: 5| Step: 3
Training loss: 0.0791398212313652
Validation loss: 1.5454274031423754

Epoch: 5| Step: 4
Training loss: 0.03774315118789673
Validation loss: 1.546476931982143

Epoch: 5| Step: 5
Training loss: 0.05312054231762886
Validation loss: 1.5054592727332987

Epoch: 5| Step: 6
Training loss: 0.054166603833436966
Validation loss: 1.5277637704726188

Epoch: 5| Step: 7
Training loss: 0.03743927553296089
Validation loss: 1.5043532168993385

Epoch: 5| Step: 8
Training loss: 0.06567460298538208
Validation loss: 1.4843973869918494

Epoch: 5| Step: 9
Training loss: 0.038341112434864044
Validation loss: 1.5194701558800154

Epoch: 5| Step: 10
Training loss: 0.06166242063045502
Validation loss: 1.48677949495213

Epoch: 732| Step: 0
Training loss: 0.06104432791471481
Validation loss: 1.520477871741018

Epoch: 5| Step: 1
Training loss: 0.06656692922115326
Validation loss: 1.5143981543920373

Epoch: 5| Step: 2
Training loss: 0.07282210886478424
Validation loss: 1.5483323540738834

Epoch: 5| Step: 3
Training loss: 0.04459361359477043
Validation loss: 1.562016285234882

Epoch: 5| Step: 4
Training loss: 0.05526740476489067
Validation loss: 1.5797266203870055

Epoch: 5| Step: 5
Training loss: 0.09871909767389297
Validation loss: 1.5693928477584675

Epoch: 5| Step: 6
Training loss: 0.08866000175476074
Validation loss: 1.5756710011471984

Epoch: 5| Step: 7
Training loss: 0.06189886853098869
Validation loss: 1.528711562515587

Epoch: 5| Step: 8
Training loss: 0.05970432236790657
Validation loss: 1.5320574929637294

Epoch: 5| Step: 9
Training loss: 0.09081979095935822
Validation loss: 1.5154144610128095

Epoch: 5| Step: 10
Training loss: 0.03999343514442444
Validation loss: 1.5215650245707522

Epoch: 733| Step: 0
Training loss: 0.0677374005317688
Validation loss: 1.4888674956496044

Epoch: 5| Step: 1
Training loss: 0.07479972392320633
Validation loss: 1.5237337543118386

Epoch: 5| Step: 2
Training loss: 0.046524688601493835
Validation loss: 1.5374466526892878

Epoch: 5| Step: 3
Training loss: 0.095047727227211
Validation loss: 1.5535036569000573

Epoch: 5| Step: 4
Training loss: 0.09792059659957886
Validation loss: 1.573678002562574

Epoch: 5| Step: 5
Training loss: 0.028592705726623535
Validation loss: 1.5452430825079642

Epoch: 5| Step: 6
Training loss: 0.06634566932916641
Validation loss: 1.5598866330680026

Epoch: 5| Step: 7
Training loss: 0.05241215229034424
Validation loss: 1.526281605484665

Epoch: 5| Step: 8
Training loss: 0.04795917868614197
Validation loss: 1.5393877657510902

Epoch: 5| Step: 9
Training loss: 0.05771173909306526
Validation loss: 1.5237434692280267

Epoch: 5| Step: 10
Training loss: 0.06184869632124901
Validation loss: 1.5216268031827864

Epoch: 734| Step: 0
Training loss: 0.06719554960727692
Validation loss: 1.5038405182541057

Epoch: 5| Step: 1
Training loss: 0.05903876572847366
Validation loss: 1.508930435744665

Epoch: 5| Step: 2
Training loss: 0.07189243286848068
Validation loss: 1.516473549668507

Epoch: 5| Step: 3
Training loss: 0.0748501792550087
Validation loss: 1.5213899074062225

Epoch: 5| Step: 4
Training loss: 0.040693558752536774
Validation loss: 1.534934195139075

Epoch: 5| Step: 5
Training loss: 0.05083112046122551
Validation loss: 1.5306014027646793

Epoch: 5| Step: 6
Training loss: 0.07814265787601471
Validation loss: 1.5467721326376802

Epoch: 5| Step: 7
Training loss: 0.12553644180297852
Validation loss: 1.5561736065854308

Epoch: 5| Step: 8
Training loss: 0.05788346379995346
Validation loss: 1.5310671585862354

Epoch: 5| Step: 9
Training loss: 0.0413442924618721
Validation loss: 1.523694869010679

Epoch: 5| Step: 10
Training loss: 0.03805820271372795
Validation loss: 1.4974590578386862

Epoch: 735| Step: 0
Training loss: 0.07918436825275421
Validation loss: 1.4817641550494778

Epoch: 5| Step: 1
Training loss: 0.06343812495470047
Validation loss: 1.4979500796205254

Epoch: 5| Step: 2
Training loss: 0.10796073824167252
Validation loss: 1.5074106839395338

Epoch: 5| Step: 3
Training loss: 0.04335269331932068
Validation loss: 1.5039084111490557

Epoch: 5| Step: 4
Training loss: 0.039813082665205
Validation loss: 1.5154585620408416

Epoch: 5| Step: 5
Training loss: 0.05942130088806152
Validation loss: 1.5406894658201484

Epoch: 5| Step: 6
Training loss: 0.08429418504238129
Validation loss: 1.5728391344829271

Epoch: 5| Step: 7
Training loss: 0.0446452870965004
Validation loss: 1.5912779800353511

Epoch: 5| Step: 8
Training loss: 0.05860546976327896
Validation loss: 1.5700464966476604

Epoch: 5| Step: 9
Training loss: 0.05712585523724556
Validation loss: 1.5325490415737193

Epoch: 5| Step: 10
Training loss: 0.09284518659114838
Validation loss: 1.5387091636657715

Epoch: 736| Step: 0
Training loss: 0.09642232209444046
Validation loss: 1.5348165086520615

Epoch: 5| Step: 1
Training loss: 0.03613075241446495
Validation loss: 1.5327384523166123

Epoch: 5| Step: 2
Training loss: 0.08752433210611343
Validation loss: 1.5448255923486525

Epoch: 5| Step: 3
Training loss: 0.0460795983672142
Validation loss: 1.5252884152115032

Epoch: 5| Step: 4
Training loss: 0.07936982065439224
Validation loss: 1.5316824246478338

Epoch: 5| Step: 5
Training loss: 0.04855694621801376
Validation loss: 1.5338416740458498

Epoch: 5| Step: 6
Training loss: 0.07254109531641006
Validation loss: 1.551932745082404

Epoch: 5| Step: 7
Training loss: 0.06967726349830627
Validation loss: 1.534045006639214

Epoch: 5| Step: 8
Training loss: 0.05901307612657547
Validation loss: 1.5439253532758324

Epoch: 5| Step: 9
Training loss: 0.06020756810903549
Validation loss: 1.5361202660427298

Epoch: 5| Step: 10
Training loss: 0.061397600919008255
Validation loss: 1.5759882132212322

Epoch: 737| Step: 0
Training loss: 0.09666291624307632
Validation loss: 1.5208481998853787

Epoch: 5| Step: 1
Training loss: 0.08081184327602386
Validation loss: 1.5244153725203646

Epoch: 5| Step: 2
Training loss: 0.06356391310691833
Validation loss: 1.5197674612845145

Epoch: 5| Step: 3
Training loss: 0.03402138873934746
Validation loss: 1.5034384599295996

Epoch: 5| Step: 4
Training loss: 0.027675127610564232
Validation loss: 1.5027463256671865

Epoch: 5| Step: 5
Training loss: 0.039063237607479095
Validation loss: 1.5317027030452606

Epoch: 5| Step: 6
Training loss: 0.05926644057035446
Validation loss: 1.515267574658958

Epoch: 5| Step: 7
Training loss: 0.05084938928484917
Validation loss: 1.5369838206998763

Epoch: 5| Step: 8
Training loss: 0.032930243760347366
Validation loss: 1.5532095227190243

Epoch: 5| Step: 9
Training loss: 0.050589174032211304
Validation loss: 1.553575103000928

Epoch: 5| Step: 10
Training loss: 0.06399668753147125
Validation loss: 1.5455909390603342

Epoch: 738| Step: 0
Training loss: 0.0915212482213974
Validation loss: 1.5401697466450353

Epoch: 5| Step: 1
Training loss: 0.054249148815870285
Validation loss: 1.560241239045256

Epoch: 5| Step: 2
Training loss: 0.05242755264043808
Validation loss: 1.562465621579078

Epoch: 5| Step: 3
Training loss: 0.06797433644533157
Validation loss: 1.553625404193837

Epoch: 5| Step: 4
Training loss: 0.03269122913479805
Validation loss: 1.5524083606658443

Epoch: 5| Step: 5
Training loss: 0.053129613399505615
Validation loss: 1.5281345626359344

Epoch: 5| Step: 6
Training loss: 0.07200227677822113
Validation loss: 1.5429292981342604

Epoch: 5| Step: 7
Training loss: 0.04227721691131592
Validation loss: 1.5189636971360894

Epoch: 5| Step: 8
Training loss: 0.0687510222196579
Validation loss: 1.514725064718595

Epoch: 5| Step: 9
Training loss: 0.05024882033467293
Validation loss: 1.54088205804107

Epoch: 5| Step: 10
Training loss: 0.07953226566314697
Validation loss: 1.5431303926693496

Epoch: 739| Step: 0
Training loss: 0.04818175360560417
Validation loss: 1.5475789834094305

Epoch: 5| Step: 1
Training loss: 0.045022401958703995
Validation loss: 1.5569630874100553

Epoch: 5| Step: 2
Training loss: 0.05635876581072807
Validation loss: 1.5395603205568047

Epoch: 5| Step: 3
Training loss: 0.07460768520832062
Validation loss: 1.5376172155462287

Epoch: 5| Step: 4
Training loss: 0.048298709094524384
Validation loss: 1.5169236506185224

Epoch: 5| Step: 5
Training loss: 0.04252522066235542
Validation loss: 1.5189385567941973

Epoch: 5| Step: 6
Training loss: 0.09234199672937393
Validation loss: 1.5160454037368938

Epoch: 5| Step: 7
Training loss: 0.04403318837285042
Validation loss: 1.5161567221405685

Epoch: 5| Step: 8
Training loss: 0.06510461866855621
Validation loss: 1.512642204120595

Epoch: 5| Step: 9
Training loss: 0.048833124339580536
Validation loss: 1.508438806379995

Epoch: 5| Step: 10
Training loss: 0.05709194019436836
Validation loss: 1.496907627710732

Epoch: 740| Step: 0
Training loss: 0.06402461230754852
Validation loss: 1.5033488209529589

Epoch: 5| Step: 1
Training loss: 0.06904385983943939
Validation loss: 1.5187046220225673

Epoch: 5| Step: 2
Training loss: 0.031006041914224625
Validation loss: 1.5472314569257921

Epoch: 5| Step: 3
Training loss: 0.08813785761594772
Validation loss: 1.5294323185438752

Epoch: 5| Step: 4
Training loss: 0.04457911103963852
Validation loss: 1.5318878209719093

Epoch: 5| Step: 5
Training loss: 0.09649626165628433
Validation loss: 1.511143276768346

Epoch: 5| Step: 6
Training loss: 0.04250962287187576
Validation loss: 1.493166233262708

Epoch: 5| Step: 7
Training loss: 0.04673365503549576
Validation loss: 1.5133471719680294

Epoch: 5| Step: 8
Training loss: 0.0330653078854084
Validation loss: 1.5092946957516413

Epoch: 5| Step: 9
Training loss: 0.05036662891507149
Validation loss: 1.5066843045655118

Epoch: 5| Step: 10
Training loss: 0.06763706356287003
Validation loss: 1.5028908214261454

Epoch: 741| Step: 0
Training loss: 0.06277976930141449
Validation loss: 1.545075398619457

Epoch: 5| Step: 1
Training loss: 0.07122437655925751
Validation loss: 1.5148200245313748

Epoch: 5| Step: 2
Training loss: 0.046978387981653214
Validation loss: 1.5010324896022837

Epoch: 5| Step: 3
Training loss: 0.02948184683918953
Validation loss: 1.531538341635017

Epoch: 5| Step: 4
Training loss: 0.07753350585699081
Validation loss: 1.5027815282985728

Epoch: 5| Step: 5
Training loss: 0.11766064167022705
Validation loss: 1.520741121743315

Epoch: 5| Step: 6
Training loss: 0.080393947660923
Validation loss: 1.4905675880370601

Epoch: 5| Step: 7
Training loss: 0.07071919739246368
Validation loss: 1.5067680349913977

Epoch: 5| Step: 8
Training loss: 0.0599941723048687
Validation loss: 1.496968646203318

Epoch: 5| Step: 9
Training loss: 0.055632948875427246
Validation loss: 1.5113646522645028

Epoch: 5| Step: 10
Training loss: 0.043103788048028946
Validation loss: 1.5086329906217513

Epoch: 742| Step: 0
Training loss: 0.0652971938252449
Validation loss: 1.5234277068927724

Epoch: 5| Step: 1
Training loss: 0.07482045143842697
Validation loss: 1.5393031540737356

Epoch: 5| Step: 2
Training loss: 0.03903215005993843
Validation loss: 1.5297067479420734

Epoch: 5| Step: 3
Training loss: 0.09512679278850555
Validation loss: 1.5639253047204786

Epoch: 5| Step: 4
Training loss: 0.08092565834522247
Validation loss: 1.5497124720645208

Epoch: 5| Step: 5
Training loss: 0.060659341514110565
Validation loss: 1.5494778989463724

Epoch: 5| Step: 6
Training loss: 0.07005202770233154
Validation loss: 1.541095713133453

Epoch: 5| Step: 7
Training loss: 0.08656758069992065
Validation loss: 1.5392875261204217

Epoch: 5| Step: 8
Training loss: 0.053964078426361084
Validation loss: 1.5299371942397086

Epoch: 5| Step: 9
Training loss: 0.03196403756737709
Validation loss: 1.5544153721101823

Epoch: 5| Step: 10
Training loss: 0.06938213109970093
Validation loss: 1.5420917208476732

Epoch: 743| Step: 0
Training loss: 0.10961626470088959
Validation loss: 1.547286892449984

Epoch: 5| Step: 1
Training loss: 0.04286579415202141
Validation loss: 1.5629627268801454

Epoch: 5| Step: 2
Training loss: 0.0780772939324379
Validation loss: 1.5786129710494832

Epoch: 5| Step: 3
Training loss: 0.033718276768922806
Validation loss: 1.5711072952516618

Epoch: 5| Step: 4
Training loss: 0.03315838426351547
Validation loss: 1.5695783733039774

Epoch: 5| Step: 5
Training loss: 0.043264467269182205
Validation loss: 1.567204120338604

Epoch: 5| Step: 6
Training loss: 0.043608762323856354
Validation loss: 1.5716628733501639

Epoch: 5| Step: 7
Training loss: 0.03891875222325325
Validation loss: 1.566916456786535

Epoch: 5| Step: 8
Training loss: 0.06364215910434723
Validation loss: 1.5803309999486452

Epoch: 5| Step: 9
Training loss: 0.10748831927776337
Validation loss: 1.5335670735246392

Epoch: 5| Step: 10
Training loss: 0.05355481430888176
Validation loss: 1.5345769902711273

Epoch: 744| Step: 0
Training loss: 0.045552678406238556
Validation loss: 1.5363066702760675

Epoch: 5| Step: 1
Training loss: 0.052927542477846146
Validation loss: 1.5605697003743981

Epoch: 5| Step: 2
Training loss: 0.05421771854162216
Validation loss: 1.543360751162293

Epoch: 5| Step: 3
Training loss: 0.06887068599462509
Validation loss: 1.5440660651012132

Epoch: 5| Step: 4
Training loss: 0.048341818153858185
Validation loss: 1.5528481942351147

Epoch: 5| Step: 5
Training loss: 0.06230950355529785
Validation loss: 1.5730682771692994

Epoch: 5| Step: 6
Training loss: 0.06419996917247772
Validation loss: 1.5435610548142464

Epoch: 5| Step: 7
Training loss: 0.06006098538637161
Validation loss: 1.550223212088308

Epoch: 5| Step: 8
Training loss: 0.05201956629753113
Validation loss: 1.5547096280641453

Epoch: 5| Step: 9
Training loss: 0.04082740098237991
Validation loss: 1.5271784567063855

Epoch: 5| Step: 10
Training loss: 0.1001400277018547
Validation loss: 1.5394486176070346

Epoch: 745| Step: 0
Training loss: 0.04701981693506241
Validation loss: 1.5425612849573935

Epoch: 5| Step: 1
Training loss: 0.06836915761232376
Validation loss: 1.5500388542811077

Epoch: 5| Step: 2
Training loss: 0.06291641294956207
Validation loss: 1.5524772187714935

Epoch: 5| Step: 3
Training loss: 0.034783948212862015
Validation loss: 1.5359684510897564

Epoch: 5| Step: 4
Training loss: 0.03918086364865303
Validation loss: 1.541919075032716

Epoch: 5| Step: 5
Training loss: 0.09803087264299393
Validation loss: 1.5818259395578855

Epoch: 5| Step: 6
Training loss: 0.0671982541680336
Validation loss: 1.5979909717395742

Epoch: 5| Step: 7
Training loss: 0.08781911432743073
Validation loss: 1.5729554545494817

Epoch: 5| Step: 8
Training loss: 0.04142565280199051
Validation loss: 1.5313083869154736

Epoch: 5| Step: 9
Training loss: 0.07292824983596802
Validation loss: 1.5288149079968851

Epoch: 5| Step: 10
Training loss: 0.07708155363798141
Validation loss: 1.4887270594155917

Epoch: 746| Step: 0
Training loss: 0.07834161818027496
Validation loss: 1.4895655685855496

Epoch: 5| Step: 1
Training loss: 0.06535105407238007
Validation loss: 1.4946124399861982

Epoch: 5| Step: 2
Training loss: 0.041321031749248505
Validation loss: 1.5018679762399325

Epoch: 5| Step: 3
Training loss: 0.07895520329475403
Validation loss: 1.4780513830082391

Epoch: 5| Step: 4
Training loss: 0.057253528386354446
Validation loss: 1.47902750584387

Epoch: 5| Step: 5
Training loss: 0.10491015017032623
Validation loss: 1.5046741808614423

Epoch: 5| Step: 6
Training loss: 0.06477668881416321
Validation loss: 1.5200209425341698

Epoch: 5| Step: 7
Training loss: 0.05721987038850784
Validation loss: 1.5313070897133119

Epoch: 5| Step: 8
Training loss: 0.04809374734759331
Validation loss: 1.5279995215836393

Epoch: 5| Step: 9
Training loss: 0.053132615983486176
Validation loss: 1.5350870278573805

Epoch: 5| Step: 10
Training loss: 0.0672152191400528
Validation loss: 1.5132452851982527

Epoch: 747| Step: 0
Training loss: 0.030697548761963844
Validation loss: 1.528844831451293

Epoch: 5| Step: 1
Training loss: 0.048102181404829025
Validation loss: 1.497678920786868

Epoch: 5| Step: 2
Training loss: 0.050464559346437454
Validation loss: 1.4975079810747536

Epoch: 5| Step: 3
Training loss: 0.06511495262384415
Validation loss: 1.5236628901573919

Epoch: 5| Step: 4
Training loss: 0.052340734750032425
Validation loss: 1.528613123842465

Epoch: 5| Step: 5
Training loss: 0.03789014369249344
Validation loss: 1.5132228180926333

Epoch: 5| Step: 6
Training loss: 0.07642021030187607
Validation loss: 1.510458820609636

Epoch: 5| Step: 7
Training loss: 0.05774087458848953
Validation loss: 1.5438864000381962

Epoch: 5| Step: 8
Training loss: 0.04776104912161827
Validation loss: 1.5335010565737242

Epoch: 5| Step: 9
Training loss: 0.08433181047439575
Validation loss: 1.539995910019003

Epoch: 5| Step: 10
Training loss: 0.047301314771175385
Validation loss: 1.5356818399121683

Epoch: 748| Step: 0
Training loss: 0.05418112128973007
Validation loss: 1.5339801067947059

Epoch: 5| Step: 1
Training loss: 0.09913831204175949
Validation loss: 1.5179134274041781

Epoch: 5| Step: 2
Training loss: 0.037057023495435715
Validation loss: 1.522532804037935

Epoch: 5| Step: 3
Training loss: 0.04075479507446289
Validation loss: 1.4990100142776326

Epoch: 5| Step: 4
Training loss: 0.03273262456059456
Validation loss: 1.510015328725179

Epoch: 5| Step: 5
Training loss: 0.02051454782485962
Validation loss: 1.5203295984575826

Epoch: 5| Step: 6
Training loss: 0.04071595147252083
Validation loss: 1.5005167709883822

Epoch: 5| Step: 7
Training loss: 0.05579408258199692
Validation loss: 1.5118026066851873

Epoch: 5| Step: 8
Training loss: 0.040334414690732956
Validation loss: 1.524001827803991

Epoch: 5| Step: 9
Training loss: 0.05917816609144211
Validation loss: 1.506923912673868

Epoch: 5| Step: 10
Training loss: 0.0539526492357254
Validation loss: 1.5035377446041311

Epoch: 749| Step: 0
Training loss: 0.034369342029094696
Validation loss: 1.512705082534462

Epoch: 5| Step: 1
Training loss: 0.047723520547151566
Validation loss: 1.5149006997385333

Epoch: 5| Step: 2
Training loss: 0.05306439474225044
Validation loss: 1.4909923358630108

Epoch: 5| Step: 3
Training loss: 0.05701514333486557
Validation loss: 1.4954870772618118

Epoch: 5| Step: 4
Training loss: 0.06256431341171265
Validation loss: 1.503955929510055

Epoch: 5| Step: 5
Training loss: 0.02526579238474369
Validation loss: 1.4880132636716288

Epoch: 5| Step: 6
Training loss: 0.05736998841166496
Validation loss: 1.4723407927379812

Epoch: 5| Step: 7
Training loss: 0.069347083568573
Validation loss: 1.4876703434093024

Epoch: 5| Step: 8
Training loss: 0.09403549134731293
Validation loss: 1.4744780883994153

Epoch: 5| Step: 9
Training loss: 0.07541289180517197
Validation loss: 1.4658246751754516

Epoch: 5| Step: 10
Training loss: 0.057196784764528275
Validation loss: 1.4854813307844184

Epoch: 750| Step: 0
Training loss: 0.026562821120023727
Validation loss: 1.5094500241741058

Epoch: 5| Step: 1
Training loss: 0.03339611738920212
Validation loss: 1.481524432859113

Epoch: 5| Step: 2
Training loss: 0.028584888204932213
Validation loss: 1.4799028212024319

Epoch: 5| Step: 3
Training loss: 0.06608500331640244
Validation loss: 1.5241729142845317

Epoch: 5| Step: 4
Training loss: 0.053795672953128815
Validation loss: 1.5136875170533375

Epoch: 5| Step: 5
Training loss: 0.03419218957424164
Validation loss: 1.5244993599512244

Epoch: 5| Step: 6
Training loss: 0.06547825038433075
Validation loss: 1.5131271603286907

Epoch: 5| Step: 7
Training loss: 0.052385441958904266
Validation loss: 1.5555725386065822

Epoch: 5| Step: 8
Training loss: 0.06751099228858948
Validation loss: 1.510034869435013

Epoch: 5| Step: 9
Training loss: 0.0693407878279686
Validation loss: 1.5142466714305263

Epoch: 5| Step: 10
Training loss: 0.09421166032552719
Validation loss: 1.5100366864153134

Testing loss: 2.05169235335456
