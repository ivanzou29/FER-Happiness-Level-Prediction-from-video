Epoch: 1| Step: 0
Training loss: 5.132289261762849
Validation loss: 5.834725193089714

Epoch: 5| Step: 1
Training loss: 5.840887827340315
Validation loss: 5.813533476287224

Epoch: 5| Step: 2
Training loss: 6.523405337682692
Validation loss: 5.796794751384138

Epoch: 5| Step: 3
Training loss: 5.419508183817769
Validation loss: 5.781621179746048

Epoch: 5| Step: 4
Training loss: 6.273817837065844
Validation loss: 5.763982613214143

Epoch: 5| Step: 5
Training loss: 5.46975890526168
Validation loss: 5.745119960369298

Epoch: 5| Step: 6
Training loss: 5.746800735101648
Validation loss: 5.723477540731318

Epoch: 5| Step: 7
Training loss: 4.644234329370506
Validation loss: 5.6994187162810865

Epoch: 5| Step: 8
Training loss: 5.8418971097427175
Validation loss: 5.6734940510137015

Epoch: 5| Step: 9
Training loss: 5.523487225730906
Validation loss: 5.644136505397864

Epoch: 5| Step: 10
Training loss: 6.8853548617529965
Validation loss: 5.612343201099479

Epoch: 2| Step: 0
Training loss: 4.4033189047250465
Validation loss: 5.577279385465875

Epoch: 5| Step: 1
Training loss: 6.610930852631969
Validation loss: 5.540230010219181

Epoch: 5| Step: 2
Training loss: 5.329868244024164
Validation loss: 5.501053514383617

Epoch: 5| Step: 3
Training loss: 5.701663982379946
Validation loss: 5.458761985396684

Epoch: 5| Step: 4
Training loss: 5.270804645123519
Validation loss: 5.4131857365356835

Epoch: 5| Step: 5
Training loss: 6.271344473486284
Validation loss: 5.365531124500892

Epoch: 5| Step: 6
Training loss: 5.889445624435597
Validation loss: 5.3154333192303636

Epoch: 5| Step: 7
Training loss: 5.408375757616263
Validation loss: 5.262284042841288

Epoch: 5| Step: 8
Training loss: 4.822886566441686
Validation loss: 5.206971768827986

Epoch: 5| Step: 9
Training loss: 4.449108574552244
Validation loss: 5.149147835801616

Epoch: 5| Step: 10
Training loss: 4.79539760241872
Validation loss: 5.092144629915697

Epoch: 3| Step: 0
Training loss: 4.822619610969682
Validation loss: 5.03385143353058

Epoch: 5| Step: 1
Training loss: 6.303734160128603
Validation loss: 4.978364246592295

Epoch: 5| Step: 2
Training loss: 5.410780931895945
Validation loss: 4.923027834611058

Epoch: 5| Step: 3
Training loss: 4.48827912518988
Validation loss: 4.865072282138808

Epoch: 5| Step: 4
Training loss: 4.482226132708648
Validation loss: 4.8074318160297835

Epoch: 5| Step: 5
Training loss: 4.836227186459281
Validation loss: 4.748984849586751

Epoch: 5| Step: 6
Training loss: 3.789784911199676
Validation loss: 4.692904446184836

Epoch: 5| Step: 7
Training loss: 5.46405822038142
Validation loss: 4.63418354013465

Epoch: 5| Step: 8
Training loss: 4.530992382224167
Validation loss: 4.571913666246549

Epoch: 5| Step: 9
Training loss: 3.9389264383993745
Validation loss: 4.503162940531731

Epoch: 5| Step: 10
Training loss: 4.62974140343135
Validation loss: 4.418248208981027

Epoch: 4| Step: 0
Training loss: 5.518678851765239
Validation loss: 4.358737357452584

Epoch: 5| Step: 1
Training loss: 3.186521043230023
Validation loss: 4.3354092816565615

Epoch: 5| Step: 2
Training loss: 4.143760329013569
Validation loss: 4.294387658884585

Epoch: 5| Step: 3
Training loss: 4.595744835193742
Validation loss: 4.237057630146703

Epoch: 5| Step: 4
Training loss: 4.801631991786324
Validation loss: 4.1887628166091835

Epoch: 5| Step: 5
Training loss: 3.2196196334989047
Validation loss: 4.150381646298005

Epoch: 5| Step: 6
Training loss: 4.161562170739221
Validation loss: 4.137229109185577

Epoch: 5| Step: 7
Training loss: 4.147839519269315
Validation loss: 4.116543787872287

Epoch: 5| Step: 8
Training loss: 4.732735428634393
Validation loss: 4.077060337796071

Epoch: 5| Step: 9
Training loss: 3.7123558144875304
Validation loss: 4.0539038154076295

Epoch: 5| Step: 10
Training loss: 4.772681443295759
Validation loss: 4.038106635325429

Epoch: 5| Step: 0
Training loss: 4.935218380441385
Validation loss: 4.018046842655374

Epoch: 5| Step: 1
Training loss: 2.9391315879996167
Validation loss: 3.9912652479834283

Epoch: 5| Step: 2
Training loss: 3.5907844581090034
Validation loss: 3.9697640405519508

Epoch: 5| Step: 3
Training loss: 3.9000514785107874
Validation loss: 3.9381843202718687

Epoch: 5| Step: 4
Training loss: 3.394103906770689
Validation loss: 3.9191497209493393

Epoch: 5| Step: 5
Training loss: 3.756325409651155
Validation loss: 3.9092059876208483

Epoch: 5| Step: 6
Training loss: 4.426540111050201
Validation loss: 3.901284735982682

Epoch: 5| Step: 7
Training loss: 3.946618194561645
Validation loss: 3.8797608740736322

Epoch: 5| Step: 8
Training loss: 3.8830912622361184
Validation loss: 3.8639486300408823

Epoch: 5| Step: 9
Training loss: 4.402491055099871
Validation loss: 3.850064046961197

Epoch: 5| Step: 10
Training loss: 5.25990831795628
Validation loss: 3.8407709566213777

Epoch: 6| Step: 0
Training loss: 3.634629974211746
Validation loss: 3.8349137470237054

Epoch: 5| Step: 1
Training loss: 3.3181173810010947
Validation loss: 3.826517665962517

Epoch: 5| Step: 2
Training loss: 4.837150951478833
Validation loss: 3.8166549638016254

Epoch: 5| Step: 3
Training loss: 3.9015824164270643
Validation loss: 3.8034902606213716

Epoch: 5| Step: 4
Training loss: 3.6026519650155318
Validation loss: 3.79130281913331

Epoch: 5| Step: 5
Training loss: 3.929478543074564
Validation loss: 3.780812204838549

Epoch: 5| Step: 6
Training loss: 4.129693799802469
Validation loss: 3.7733003012252264

Epoch: 5| Step: 7
Training loss: 3.2690855244266133
Validation loss: 3.7650178877647393

Epoch: 5| Step: 8
Training loss: 4.317834622967724
Validation loss: 3.7573034667310385

Epoch: 5| Step: 9
Training loss: 4.573890159525724
Validation loss: 3.745342571414306

Epoch: 5| Step: 10
Training loss: 3.693461626030381
Validation loss: 3.7354181910719904

Epoch: 7| Step: 0
Training loss: 4.198537599188765
Validation loss: 3.731958905944226

Epoch: 5| Step: 1
Training loss: 4.318585511096242
Validation loss: 3.722900826087135

Epoch: 5| Step: 2
Training loss: 3.656287168656228
Validation loss: 3.712006665337851

Epoch: 5| Step: 3
Training loss: 4.488457605733488
Validation loss: 3.703629208388685

Epoch: 5| Step: 4
Training loss: 3.597714832669748
Validation loss: 3.697864160622802

Epoch: 5| Step: 5
Training loss: 3.9007695930378596
Validation loss: 3.6933076847886235

Epoch: 5| Step: 6
Training loss: 4.121432987370384
Validation loss: 3.68764512666551

Epoch: 5| Step: 7
Training loss: 3.3893714380570903
Validation loss: 3.680876493685527

Epoch: 5| Step: 8
Training loss: 2.9684380618395156
Validation loss: 3.6695820767459404

Epoch: 5| Step: 9
Training loss: 4.5744387006122595
Validation loss: 3.662674415974237

Epoch: 5| Step: 10
Training loss: 2.9500066854110223
Validation loss: 3.6543960491623624

Epoch: 8| Step: 0
Training loss: 2.9166758582560712
Validation loss: 3.646452969868769

Epoch: 5| Step: 1
Training loss: 3.562966700986877
Validation loss: 3.6430586904786195

Epoch: 5| Step: 2
Training loss: 3.879809317671643
Validation loss: 3.6374256381985837

Epoch: 5| Step: 3
Training loss: 3.0774746125426815
Validation loss: 3.631419250939162

Epoch: 5| Step: 4
Training loss: 3.867331885522726
Validation loss: 3.624869139519012

Epoch: 5| Step: 5
Training loss: 4.342239666186508
Validation loss: 3.6180036792478267

Epoch: 5| Step: 6
Training loss: 4.299934768181968
Validation loss: 3.6129897793204018

Epoch: 5| Step: 7
Training loss: 3.74387686232682
Validation loss: 3.6041232752613817

Epoch: 5| Step: 8
Training loss: 3.908299633170932
Validation loss: 3.6008189682665512

Epoch: 5| Step: 9
Training loss: 4.2192590477027
Validation loss: 3.5917233980940964

Epoch: 5| Step: 10
Training loss: 3.8637221097356065
Validation loss: 3.6044885360181813

Epoch: 9| Step: 0
Training loss: 3.6730786237893254
Validation loss: 3.6022816188938287

Epoch: 5| Step: 1
Training loss: 3.55342337799017
Validation loss: 3.5829916493277127

Epoch: 5| Step: 2
Training loss: 4.254925510278936
Validation loss: 3.5720800843871188

Epoch: 5| Step: 3
Training loss: 3.629853912230257
Validation loss: 3.5629351295657488

Epoch: 5| Step: 4
Training loss: 4.2470401105861635
Validation loss: 3.5762318175065686

Epoch: 5| Step: 5
Training loss: 3.5817764507762013
Validation loss: 3.5524774975695537

Epoch: 5| Step: 6
Training loss: 3.5741501765109045
Validation loss: 3.550272534550924

Epoch: 5| Step: 7
Training loss: 3.544388357321281
Validation loss: 3.546191309131867

Epoch: 5| Step: 8
Training loss: 3.41987976710585
Validation loss: 3.5435557983381574

Epoch: 5| Step: 9
Training loss: 3.4703011008895124
Validation loss: 3.5445322207970653

Epoch: 5| Step: 10
Training loss: 4.427915726739328
Validation loss: 3.540412678421096

Epoch: 10| Step: 0
Training loss: 4.07393831803937
Validation loss: 3.529687014128897

Epoch: 5| Step: 1
Training loss: 3.689740421706876
Validation loss: 3.522405548712347

Epoch: 5| Step: 2
Training loss: 3.4576063809196063
Validation loss: 3.5109151792540296

Epoch: 5| Step: 3
Training loss: 3.1830932972735733
Validation loss: 3.501239535144783

Epoch: 5| Step: 4
Training loss: 4.0129951147814475
Validation loss: 3.492669132261587

Epoch: 5| Step: 5
Training loss: 2.740867275199142
Validation loss: 3.4861373472766037

Epoch: 5| Step: 6
Training loss: 3.5602909400010576
Validation loss: 3.48087560074533

Epoch: 5| Step: 7
Training loss: 3.825903796959148
Validation loss: 3.4733436245892073

Epoch: 5| Step: 8
Training loss: 4.221143707482458
Validation loss: 3.470980595792352

Epoch: 5| Step: 9
Training loss: 3.8289442781631493
Validation loss: 3.4652570235770543

Epoch: 5| Step: 10
Training loss: 3.934750156832311
Validation loss: 3.4580604251817633

Epoch: 11| Step: 0
Training loss: 3.4742152144334946
Validation loss: 3.447625159078363

Epoch: 5| Step: 1
Training loss: 3.281848235318118
Validation loss: 3.4432769172323425

Epoch: 5| Step: 2
Training loss: 2.88863886052804
Validation loss: 3.4385284227838606

Epoch: 5| Step: 3
Training loss: 3.4670447204539965
Validation loss: 3.4333386139112756

Epoch: 5| Step: 4
Training loss: 3.235471972508446
Validation loss: 3.429101279483641

Epoch: 5| Step: 5
Training loss: 4.458551252987084
Validation loss: 3.425480979881896

Epoch: 5| Step: 6
Training loss: 3.45818265716897
Validation loss: 3.420343072337363

Epoch: 5| Step: 7
Training loss: 4.208424003807743
Validation loss: 3.412907944214311

Epoch: 5| Step: 8
Training loss: 4.037357878176594
Validation loss: 3.4089813781499574

Epoch: 5| Step: 9
Training loss: 3.240925517995716
Validation loss: 3.408465870871937

Epoch: 5| Step: 10
Training loss: 4.10958084345135
Validation loss: 3.3990477273749393

Epoch: 12| Step: 0
Training loss: 3.6726682414865524
Validation loss: 3.3995854097830023

Epoch: 5| Step: 1
Training loss: 3.512127845027412
Validation loss: 3.410744006942535

Epoch: 5| Step: 2
Training loss: 3.21486940987823
Validation loss: 3.4082047256751333

Epoch: 5| Step: 3
Training loss: 3.944807024008277
Validation loss: 3.4193058750480168

Epoch: 5| Step: 4
Training loss: 4.090196770968866
Validation loss: 3.4009955058091617

Epoch: 5| Step: 5
Training loss: 3.6168165243249324
Validation loss: 3.3897484283797565

Epoch: 5| Step: 6
Training loss: 3.470133599999179
Validation loss: 3.3853619127917827

Epoch: 5| Step: 7
Training loss: 4.029915522217673
Validation loss: 3.3848779569987553

Epoch: 5| Step: 8
Training loss: 3.4059103700197983
Validation loss: 3.379993630546621

Epoch: 5| Step: 9
Training loss: 3.2879796363589797
Validation loss: 3.3798316983250247

Epoch: 5| Step: 10
Training loss: 3.471354288767502
Validation loss: 3.376861493398546

Epoch: 13| Step: 0
Training loss: 3.6791398274590104
Validation loss: 3.3691649651655062

Epoch: 5| Step: 1
Training loss: 3.733345943384218
Validation loss: 3.363542434928623

Epoch: 5| Step: 2
Training loss: 3.9060329529543694
Validation loss: 3.3583936757059725

Epoch: 5| Step: 3
Training loss: 3.496530448022753
Validation loss: 3.3529394550926086

Epoch: 5| Step: 4
Training loss: 3.359056750459512
Validation loss: 3.346066730090194

Epoch: 5| Step: 5
Training loss: 3.4011465215170658
Validation loss: 3.3431901820605106

Epoch: 5| Step: 6
Training loss: 2.907202779809088
Validation loss: 3.34147592934675

Epoch: 5| Step: 7
Training loss: 4.011305329918068
Validation loss: 3.338228864370533

Epoch: 5| Step: 8
Training loss: 3.412406886580573
Validation loss: 3.332880591338126

Epoch: 5| Step: 9
Training loss: 3.0553090275427426
Validation loss: 3.3298091522024658

Epoch: 5| Step: 10
Training loss: 4.357817997318602
Validation loss: 3.3256403423707748

Epoch: 14| Step: 0
Training loss: 3.711007143672152
Validation loss: 3.322925368696333

Epoch: 5| Step: 1
Training loss: 3.9809185518903383
Validation loss: 3.319538357345944

Epoch: 5| Step: 2
Training loss: 3.825808450868179
Validation loss: 3.3122289093528687

Epoch: 5| Step: 3
Training loss: 3.413356681858116
Validation loss: 3.3067094632284286

Epoch: 5| Step: 4
Training loss: 3.3656755845599453
Validation loss: 3.3020591146203944

Epoch: 5| Step: 5
Training loss: 2.9120841584882404
Validation loss: 3.2962246920114535

Epoch: 5| Step: 6
Training loss: 3.2594549123562966
Validation loss: 3.300543910745473

Epoch: 5| Step: 7
Training loss: 2.8643751773921573
Validation loss: 3.2981214190415438

Epoch: 5| Step: 8
Training loss: 4.013728900142347
Validation loss: 3.29897658120535

Epoch: 5| Step: 9
Training loss: 3.742136530837656
Validation loss: 3.2852411236132517

Epoch: 5| Step: 10
Training loss: 3.7667224598581206
Validation loss: 3.2932937970212217

Epoch: 15| Step: 0
Training loss: 3.690293886220284
Validation loss: 3.296690719874917

Epoch: 5| Step: 1
Training loss: 3.1176061516426756
Validation loss: 3.300037902012769

Epoch: 5| Step: 2
Training loss: 3.693198117306896
Validation loss: 3.288635258894123

Epoch: 5| Step: 3
Training loss: 4.1194235359519285
Validation loss: 3.2759257946471694

Epoch: 5| Step: 4
Training loss: 3.6212404420968154
Validation loss: 3.264905558772739

Epoch: 5| Step: 5
Training loss: 3.2828182287588343
Validation loss: 3.261344692412415

Epoch: 5| Step: 6
Training loss: 3.9966175560138457
Validation loss: 3.2858376804335836

Epoch: 5| Step: 7
Training loss: 3.577186294759409
Validation loss: 3.254249320573797

Epoch: 5| Step: 8
Training loss: 2.8254084739084355
Validation loss: 3.2540777575072646

Epoch: 5| Step: 9
Training loss: 3.511230842209426
Validation loss: 3.255097125641568

Epoch: 5| Step: 10
Training loss: 2.9972182728628733
Validation loss: 3.260042857063229

Epoch: 16| Step: 0
Training loss: 3.704852381351049
Validation loss: 3.2607815970167757

Epoch: 5| Step: 1
Training loss: 3.131313964434078
Validation loss: 3.2549359077242905

Epoch: 5| Step: 2
Training loss: 3.752849640539774
Validation loss: 3.2467740742388678

Epoch: 5| Step: 3
Training loss: 3.712362236780672
Validation loss: 3.241055253942176

Epoch: 5| Step: 4
Training loss: 2.948645367999615
Validation loss: 3.2298919598887106

Epoch: 5| Step: 5
Training loss: 3.602876965338695
Validation loss: 3.2197433421925994

Epoch: 5| Step: 6
Training loss: 3.381318429758619
Validation loss: 3.2104625090597647

Epoch: 5| Step: 7
Training loss: 3.2741584803232207
Validation loss: 3.2028145988607104

Epoch: 5| Step: 8
Training loss: 3.598107523992498
Validation loss: 3.2036014549683185

Epoch: 5| Step: 9
Training loss: 3.371518493981789
Validation loss: 3.20384824737677

Epoch: 5| Step: 10
Training loss: 3.757262001241287
Validation loss: 3.201100792861725

Epoch: 17| Step: 0
Training loss: 3.686029690652409
Validation loss: 3.1936528344267194

Epoch: 5| Step: 1
Training loss: 3.008116550683354
Validation loss: 3.184121281315686

Epoch: 5| Step: 2
Training loss: 3.3331744791961686
Validation loss: 3.178525563779571

Epoch: 5| Step: 3
Training loss: 3.4127630558559203
Validation loss: 3.1754938085409976

Epoch: 5| Step: 4
Training loss: 2.9057538008866457
Validation loss: 3.172780437344748

Epoch: 5| Step: 5
Training loss: 3.091800730661288
Validation loss: 3.1781185750432233

Epoch: 5| Step: 6
Training loss: 3.2497806475048394
Validation loss: 3.182439589405277

Epoch: 5| Step: 7
Training loss: 4.001356610084802
Validation loss: 3.1759993461838

Epoch: 5| Step: 8
Training loss: 3.51321179111556
Validation loss: 3.1657300955480805

Epoch: 5| Step: 9
Training loss: 3.8240663772791543
Validation loss: 3.1901815846106514

Epoch: 5| Step: 10
Training loss: 3.6866852458281056
Validation loss: 3.174260401767917

Epoch: 18| Step: 0
Training loss: 3.3192447157129115
Validation loss: 3.1613413454975134

Epoch: 5| Step: 1
Training loss: 2.8004112690928116
Validation loss: 3.1612842251909496

Epoch: 5| Step: 2
Training loss: 2.729701467826581
Validation loss: 3.159743148432113

Epoch: 5| Step: 3
Training loss: 4.159448984406689
Validation loss: 3.156812928126314

Epoch: 5| Step: 4
Training loss: 3.438662800489276
Validation loss: 3.1511689603364723

Epoch: 5| Step: 5
Training loss: 3.0257245858991126
Validation loss: 3.1472335292983034

Epoch: 5| Step: 6
Training loss: 3.118535030195766
Validation loss: 3.14456805186824

Epoch: 5| Step: 7
Training loss: 4.055490168098061
Validation loss: 3.143720655064373

Epoch: 5| Step: 8
Training loss: 3.4968194133850634
Validation loss: 3.1424234222765035

Epoch: 5| Step: 9
Training loss: 3.9268165855306925
Validation loss: 3.1382921697519364

Epoch: 5| Step: 10
Training loss: 3.1154774346793292
Validation loss: 3.132444966375907

Epoch: 19| Step: 0
Training loss: 2.8387751398690897
Validation loss: 3.128150218426668

Epoch: 5| Step: 1
Training loss: 3.82196396157258
Validation loss: 3.1236436078261587

Epoch: 5| Step: 2
Training loss: 3.299205950369589
Validation loss: 3.122793392346321

Epoch: 5| Step: 3
Training loss: 3.3802182864065635
Validation loss: 3.118905664435316

Epoch: 5| Step: 4
Training loss: 2.7231978940805437
Validation loss: 3.1152355402781216

Epoch: 5| Step: 5
Training loss: 3.9166077277977207
Validation loss: 3.1107404899996745

Epoch: 5| Step: 6
Training loss: 3.027281375365489
Validation loss: 3.108377657943259

Epoch: 5| Step: 7
Training loss: 3.4656541085289194
Validation loss: 3.1105972058844586

Epoch: 5| Step: 8
Training loss: 3.3487155444632037
Validation loss: 3.1028179052807383

Epoch: 5| Step: 9
Training loss: 3.6003099361093014
Validation loss: 3.100168364627228

Epoch: 5| Step: 10
Training loss: 3.6411822633371855
Validation loss: 3.095745899208618

Epoch: 20| Step: 0
Training loss: 3.531677490284998
Validation loss: 3.0940672147408845

Epoch: 5| Step: 1
Training loss: 3.5832991191797885
Validation loss: 3.093031474036997

Epoch: 5| Step: 2
Training loss: 3.816708727497958
Validation loss: 3.0912248555199713

Epoch: 5| Step: 3
Training loss: 2.831305806871007
Validation loss: 3.099096170063966

Epoch: 5| Step: 4
Training loss: 3.1426495910825856
Validation loss: 3.0976687882140204

Epoch: 5| Step: 5
Training loss: 2.976438664941656
Validation loss: 3.0892901317889034

Epoch: 5| Step: 6
Training loss: 3.8935375418954066
Validation loss: 3.094992219094549

Epoch: 5| Step: 7
Training loss: 3.0737004891434117
Validation loss: 3.1175505317010734

Epoch: 5| Step: 8
Training loss: 3.3770720161438192
Validation loss: 3.107433355757559

Epoch: 5| Step: 9
Training loss: 3.3156211112356435
Validation loss: 3.0781793318365964

Epoch: 5| Step: 10
Training loss: 3.2698682750336867
Validation loss: 3.077961145844111

Epoch: 21| Step: 0
Training loss: 3.4167171257448863
Validation loss: 3.0906834390982816

Epoch: 5| Step: 1
Training loss: 3.723317522876563
Validation loss: 3.1013160004840565

Epoch: 5| Step: 2
Training loss: 3.5284455902977174
Validation loss: 3.097318909128567

Epoch: 5| Step: 3
Training loss: 3.575066071013146
Validation loss: 3.087199419440868

Epoch: 5| Step: 4
Training loss: 2.518392048051778
Validation loss: 3.0782773392607052

Epoch: 5| Step: 5
Training loss: 2.798906664601533
Validation loss: 3.0756787172433726

Epoch: 5| Step: 6
Training loss: 3.4363689989540784
Validation loss: 3.0711016974170753

Epoch: 5| Step: 7
Training loss: 3.7066035290241808
Validation loss: 3.079499837923043

Epoch: 5| Step: 8
Training loss: 3.650352743165533
Validation loss: 3.0767457115398695

Epoch: 5| Step: 9
Training loss: 2.977957171007252
Validation loss: 3.0763113507646875

Epoch: 5| Step: 10
Training loss: 3.516740681259577
Validation loss: 3.069492656780943

Epoch: 22| Step: 0
Training loss: 3.734955810326319
Validation loss: 3.0656671326535414

Epoch: 5| Step: 1
Training loss: 3.1253703088699614
Validation loss: 3.0605643540122704

Epoch: 5| Step: 2
Training loss: 3.683316201102573
Validation loss: 3.0608493105721344

Epoch: 5| Step: 3
Training loss: 3.5296609729784927
Validation loss: 3.059124641641215

Epoch: 5| Step: 4
Training loss: 3.2858808990552104
Validation loss: 3.0519528650703878

Epoch: 5| Step: 5
Training loss: 3.0802652886321416
Validation loss: 3.048037720844064

Epoch: 5| Step: 6
Training loss: 3.426219255378338
Validation loss: 3.0464282275951824

Epoch: 5| Step: 7
Training loss: 3.2395764971269476
Validation loss: 3.039219801867431

Epoch: 5| Step: 8
Training loss: 3.3052689421817654
Validation loss: 3.0368405349236807

Epoch: 5| Step: 9
Training loss: 3.359190186140856
Validation loss: 3.0358146818743723

Epoch: 5| Step: 10
Training loss: 2.745004277738424
Validation loss: 3.0331369440122025

Epoch: 23| Step: 0
Training loss: 2.854449255845901
Validation loss: 3.0340166928869614

Epoch: 5| Step: 1
Training loss: 3.6547264119882317
Validation loss: 3.0360494629048618

Epoch: 5| Step: 2
Training loss: 3.1990804304652825
Validation loss: 3.025799428742452

Epoch: 5| Step: 3
Training loss: 3.808522885959329
Validation loss: 3.0259975710910605

Epoch: 5| Step: 4
Training loss: 3.297086302146377
Validation loss: 3.033262695275223

Epoch: 5| Step: 5
Training loss: 3.150831046303282
Validation loss: 3.0414220571387047

Epoch: 5| Step: 6
Training loss: 2.938443458499971
Validation loss: 3.0396984310293464

Epoch: 5| Step: 7
Training loss: 3.4051500696842
Validation loss: 3.0313567521335583

Epoch: 5| Step: 8
Training loss: 3.0157350510197705
Validation loss: 3.020650377910743

Epoch: 5| Step: 9
Training loss: 3.4693748667364246
Validation loss: 3.0182758649638792

Epoch: 5| Step: 10
Training loss: 3.584170768526721
Validation loss: 3.010120322048244

Epoch: 24| Step: 0
Training loss: 3.4008928921665937
Validation loss: 3.0105266367157477

Epoch: 5| Step: 1
Training loss: 3.371746614431991
Validation loss: 3.0134527837503806

Epoch: 5| Step: 2
Training loss: 3.369843110640617
Validation loss: 3.0167211943626016

Epoch: 5| Step: 3
Training loss: 2.8773162467609485
Validation loss: 2.9990521210204673

Epoch: 5| Step: 4
Training loss: 2.8980079188584202
Validation loss: 2.9980567539954595

Epoch: 5| Step: 5
Training loss: 3.485023061930509
Validation loss: 2.996229348667382

Epoch: 5| Step: 6
Training loss: 3.486238674010012
Validation loss: 2.9934721428720836

Epoch: 5| Step: 7
Training loss: 3.4345771153881306
Validation loss: 2.9937986075505942

Epoch: 5| Step: 8
Training loss: 3.352888507449031
Validation loss: 2.9871446809838624

Epoch: 5| Step: 9
Training loss: 3.4448687555257966
Validation loss: 2.9799668895073728

Epoch: 5| Step: 10
Training loss: 2.965178258468146
Validation loss: 2.9991793227808206

Epoch: 25| Step: 0
Training loss: 3.2661039010390978
Validation loss: 3.018662576495055

Epoch: 5| Step: 1
Training loss: 3.367068826305619
Validation loss: 2.9961245656175173

Epoch: 5| Step: 2
Training loss: 3.4719896738804144
Validation loss: 2.9819814898931414

Epoch: 5| Step: 3
Training loss: 3.706857080257094
Validation loss: 3.006272993873282

Epoch: 5| Step: 4
Training loss: 3.237519288465858
Validation loss: 3.05668296958929

Epoch: 5| Step: 5
Training loss: 3.510149544684643
Validation loss: 2.9971586413872084

Epoch: 5| Step: 6
Training loss: 3.2783351485365815
Validation loss: 2.997676458867942

Epoch: 5| Step: 7
Training loss: 3.0335909269458763
Validation loss: 2.992621570547012

Epoch: 5| Step: 8
Training loss: 3.5332993493755045
Validation loss: 2.9804692351227517

Epoch: 5| Step: 9
Training loss: 2.6787910407727797
Validation loss: 2.974753784176012

Epoch: 5| Step: 10
Training loss: 2.990251916077715
Validation loss: 2.972991048731158

Epoch: 26| Step: 0
Training loss: 3.1078732952080563
Validation loss: 2.9767177460449683

Epoch: 5| Step: 1
Training loss: 2.9774553056336375
Validation loss: 2.9889935430532883

Epoch: 5| Step: 2
Training loss: 2.9495391873726104
Validation loss: 3.0051670057047994

Epoch: 5| Step: 3
Training loss: 2.8836635584250248
Validation loss: 3.004328952531834

Epoch: 5| Step: 4
Training loss: 3.309778354980019
Validation loss: 2.9986933397175135

Epoch: 5| Step: 5
Training loss: 3.6458699833072306
Validation loss: 2.9754060180189894

Epoch: 5| Step: 6
Training loss: 3.422658752147924
Validation loss: 2.9651947909647776

Epoch: 5| Step: 7
Training loss: 3.478123689361627
Validation loss: 2.9608709315019137

Epoch: 5| Step: 8
Training loss: 3.504514915649004
Validation loss: 2.9582825124402956

Epoch: 5| Step: 9
Training loss: 3.391885690076524
Validation loss: 2.9588865031325424

Epoch: 5| Step: 10
Training loss: 3.228154637070511
Validation loss: 2.9584796975611374

Epoch: 27| Step: 0
Training loss: 3.445028211148691
Validation loss: 2.954876263853325

Epoch: 5| Step: 1
Training loss: 3.246412644863555
Validation loss: 2.9526777187534887

Epoch: 5| Step: 2
Training loss: 2.7354264335913125
Validation loss: 2.9523016415602266

Epoch: 5| Step: 3
Training loss: 3.4228817926179325
Validation loss: 2.9485951997250632

Epoch: 5| Step: 4
Training loss: 3.559976587540009
Validation loss: 2.946501323659596

Epoch: 5| Step: 5
Training loss: 2.947411879240611
Validation loss: 2.943428471676895

Epoch: 5| Step: 6
Training loss: 3.436914012553631
Validation loss: 2.9421012726324847

Epoch: 5| Step: 7
Training loss: 2.83459760470996
Validation loss: 2.9410989672723797

Epoch: 5| Step: 8
Training loss: 3.531036775616249
Validation loss: 2.947605421146402

Epoch: 5| Step: 9
Training loss: 2.8748636628041884
Validation loss: 2.9404507375928532

Epoch: 5| Step: 10
Training loss: 3.644026055846873
Validation loss: 2.937237153765984

Epoch: 28| Step: 0
Training loss: 3.018693538793288
Validation loss: 2.9323348394049944

Epoch: 5| Step: 1
Training loss: 3.2230200729762926
Validation loss: 2.928176035398911

Epoch: 5| Step: 2
Training loss: 3.079200053431926
Validation loss: 2.9392256179149108

Epoch: 5| Step: 3
Training loss: 3.245282049867302
Validation loss: 2.9568099716149248

Epoch: 5| Step: 4
Training loss: 3.2585053290381647
Validation loss: 2.926510675388832

Epoch: 5| Step: 5
Training loss: 3.74665301685856
Validation loss: 2.9207043353788054

Epoch: 5| Step: 6
Training loss: 3.181677043558833
Validation loss: 2.9194856527516198

Epoch: 5| Step: 7
Training loss: 3.3134011536327774
Validation loss: 2.9211824789801284

Epoch: 5| Step: 8
Training loss: 3.2080363511858443
Validation loss: 2.9237911426898413

Epoch: 5| Step: 9
Training loss: 3.390012342942535
Validation loss: 2.919962007309412

Epoch: 5| Step: 10
Training loss: 2.7695085231348897
Validation loss: 2.9239869249392507

Epoch: 29| Step: 0
Training loss: 2.880349200059296
Validation loss: 2.91923937798392

Epoch: 5| Step: 1
Training loss: 2.8331722512923854
Validation loss: 2.918844909733977

Epoch: 5| Step: 2
Training loss: 3.37684693839702
Validation loss: 2.9154332191200125

Epoch: 5| Step: 3
Training loss: 3.0716189645453245
Validation loss: 2.9136977600481715

Epoch: 5| Step: 4
Training loss: 3.641114034265126
Validation loss: 2.9130274210988785

Epoch: 5| Step: 5
Training loss: 3.5730170559287857
Validation loss: 2.910647957926777

Epoch: 5| Step: 6
Training loss: 3.277254123848982
Validation loss: 2.9113106315999073

Epoch: 5| Step: 7
Training loss: 2.8770540612066986
Validation loss: 2.9094976934938317

Epoch: 5| Step: 8
Training loss: 3.3648014686820704
Validation loss: 2.9082609997701945

Epoch: 5| Step: 9
Training loss: 2.9471274533756477
Validation loss: 2.9099614022739866

Epoch: 5| Step: 10
Training loss: 3.5340149443935953
Validation loss: 2.9063691586613314

Epoch: 30| Step: 0
Training loss: 3.3179693593455113
Validation loss: 2.904408166221128

Epoch: 5| Step: 1
Training loss: 2.6805254012691924
Validation loss: 2.907232565901197

Epoch: 5| Step: 2
Training loss: 3.312010387008154
Validation loss: 2.9069075637172994

Epoch: 5| Step: 3
Training loss: 3.200352208304915
Validation loss: 2.90256128983839

Epoch: 5| Step: 4
Training loss: 3.5348176741353834
Validation loss: 2.9048725321240747

Epoch: 5| Step: 5
Training loss: 3.167896199365764
Validation loss: 2.9032091791435652

Epoch: 5| Step: 6
Training loss: 3.431158284835916
Validation loss: 2.901637849048011

Epoch: 5| Step: 7
Training loss: 3.392430541101216
Validation loss: 2.899545685737068

Epoch: 5| Step: 8
Training loss: 2.9875698065482963
Validation loss: 2.8978532191668527

Epoch: 5| Step: 9
Training loss: 2.7729420393985023
Validation loss: 2.8979735758720455

Epoch: 5| Step: 10
Training loss: 3.462268995160346
Validation loss: 2.8967846119242466

Epoch: 31| Step: 0
Training loss: 3.6549020222318216
Validation loss: 2.8937069591857143

Epoch: 5| Step: 1
Training loss: 2.97178863817078
Validation loss: 2.899661617034964

Epoch: 5| Step: 2
Training loss: 2.8901629104368403
Validation loss: 2.899315502521469

Epoch: 5| Step: 3
Training loss: 3.5421697521059565
Validation loss: 2.906080471479174

Epoch: 5| Step: 4
Training loss: 3.133414422331913
Validation loss: 2.9009261310517913

Epoch: 5| Step: 5
Training loss: 2.752488570852224
Validation loss: 2.8947023325636927

Epoch: 5| Step: 6
Training loss: 3.0870980313833725
Validation loss: 2.891641652553828

Epoch: 5| Step: 7
Training loss: 3.1847481910418347
Validation loss: 2.888281057958693

Epoch: 5| Step: 8
Training loss: 3.047042450827286
Validation loss: 2.890411650221023

Epoch: 5| Step: 9
Training loss: 3.590728418306743
Validation loss: 2.8916472193169303

Epoch: 5| Step: 10
Training loss: 3.216385055890975
Validation loss: 2.8883491885064845

Epoch: 32| Step: 0
Training loss: 3.1375393868819943
Validation loss: 2.887869896431393

Epoch: 5| Step: 1
Training loss: 2.5551257209677907
Validation loss: 2.8953569601302545

Epoch: 5| Step: 2
Training loss: 2.7558708812492343
Validation loss: 2.9009643910835003

Epoch: 5| Step: 3
Training loss: 3.0549275725874225
Validation loss: 2.90149008976721

Epoch: 5| Step: 4
Training loss: 3.3612543571219784
Validation loss: 2.8974428505933707

Epoch: 5| Step: 5
Training loss: 3.8298282493149074
Validation loss: 2.892319196688458

Epoch: 5| Step: 6
Training loss: 2.996143246158545
Validation loss: 2.881127127024768

Epoch: 5| Step: 7
Training loss: 3.5638948353451596
Validation loss: 2.880368877998762

Epoch: 5| Step: 8
Training loss: 3.386592312644885
Validation loss: 2.8781936335009686

Epoch: 5| Step: 9
Training loss: 2.741737176593321
Validation loss: 2.8830298649651565

Epoch: 5| Step: 10
Training loss: 3.6210377842138834
Validation loss: 2.9231610878894725

Epoch: 33| Step: 0
Training loss: 3.879141040776089
Validation loss: 2.9326451349596736

Epoch: 5| Step: 1
Training loss: 2.733955569114839
Validation loss: 2.9244047353103464

Epoch: 5| Step: 2
Training loss: 3.2790223325368477
Validation loss: 2.922986879191698

Epoch: 5| Step: 3
Training loss: 2.9257468614989235
Validation loss: 2.8727998826518117

Epoch: 5| Step: 4
Training loss: 3.1345261907196784
Validation loss: 2.8721641618388114

Epoch: 5| Step: 5
Training loss: 3.5899765770448235
Validation loss: 2.876438221633572

Epoch: 5| Step: 6
Training loss: 3.2672144475963054
Validation loss: 2.882490754899912

Epoch: 5| Step: 7
Training loss: 2.1513690714713154
Validation loss: 2.8904212336625865

Epoch: 5| Step: 8
Training loss: 3.174453213684458
Validation loss: 2.9290496915075557

Epoch: 5| Step: 9
Training loss: 3.874122027947333
Validation loss: 2.950272976825678

Epoch: 5| Step: 10
Training loss: 2.9167258846992477
Validation loss: 2.9023403952241362

Epoch: 34| Step: 0
Training loss: 2.6574249361764397
Validation loss: 2.8667288600569165

Epoch: 5| Step: 1
Training loss: 2.7019915547270696
Validation loss: 2.866093115570254

Epoch: 5| Step: 2
Training loss: 3.4066842178619217
Validation loss: 2.8702066972769815

Epoch: 5| Step: 3
Training loss: 3.3673353406131943
Validation loss: 2.8774073822142667

Epoch: 5| Step: 4
Training loss: 3.11701035534017
Validation loss: 2.87624083212803

Epoch: 5| Step: 5
Training loss: 3.0506616781445155
Validation loss: 2.8900378268593925

Epoch: 5| Step: 6
Training loss: 3.1767516583190467
Validation loss: 2.886250083942276

Epoch: 5| Step: 7
Training loss: 3.582971746845946
Validation loss: 2.875083863264433

Epoch: 5| Step: 8
Training loss: 3.428067530773633
Validation loss: 2.8673667273865457

Epoch: 5| Step: 9
Training loss: 2.8072318009956865
Validation loss: 2.8603725646632494

Epoch: 5| Step: 10
Training loss: 3.604947632132806
Validation loss: 2.859665631136575

Epoch: 35| Step: 0
Training loss: 3.242997769138864
Validation loss: 2.852468076929954

Epoch: 5| Step: 1
Training loss: 3.0534101776659046
Validation loss: 2.8580726864412167

Epoch: 5| Step: 2
Training loss: 2.953667807773372
Validation loss: 2.8752732612966434

Epoch: 5| Step: 3
Training loss: 3.309446258786343
Validation loss: 2.8762426343692344

Epoch: 5| Step: 4
Training loss: 3.179011842516608
Validation loss: 2.8664948512349944

Epoch: 5| Step: 5
Training loss: 3.356671616197995
Validation loss: 2.852938369250063

Epoch: 5| Step: 6
Training loss: 3.1936941362187103
Validation loss: 2.8486011375164555

Epoch: 5| Step: 7
Training loss: 2.9924485214764385
Validation loss: 2.8444070689114405

Epoch: 5| Step: 8
Training loss: 3.5729718143815163
Validation loss: 2.8478922892752316

Epoch: 5| Step: 9
Training loss: 3.11243261547759
Validation loss: 2.8515849648766647

Epoch: 5| Step: 10
Training loss: 2.7158930006453845
Validation loss: 2.8522860132996275

Epoch: 36| Step: 0
Training loss: 3.234133209183891
Validation loss: 2.8516145120154133

Epoch: 5| Step: 1
Training loss: 3.74904124401541
Validation loss: 2.853804880136029

Epoch: 5| Step: 2
Training loss: 2.671036795148123
Validation loss: 2.851163394389142

Epoch: 5| Step: 3
Training loss: 2.8217553334088152
Validation loss: 2.849723455069159

Epoch: 5| Step: 4
Training loss: 3.4850058219784414
Validation loss: 2.8600521790896014

Epoch: 5| Step: 5
Training loss: 2.7597867906842732
Validation loss: 2.889663842466487

Epoch: 5| Step: 6
Training loss: 3.2969386379373544
Validation loss: 2.884148480097564

Epoch: 5| Step: 7
Training loss: 2.8891573092479
Validation loss: 2.865314068409334

Epoch: 5| Step: 8
Training loss: 3.1375407546842617
Validation loss: 2.8299785344464827

Epoch: 5| Step: 9
Training loss: 2.8088603735417284
Validation loss: 2.829918287793295

Epoch: 5| Step: 10
Training loss: 3.777340467859872
Validation loss: 2.8315145734250957

Epoch: 37| Step: 0
Training loss: 3.251071166532409
Validation loss: 2.8334698722581035

Epoch: 5| Step: 1
Training loss: 3.692485736258921
Validation loss: 2.834757970293481

Epoch: 5| Step: 2
Training loss: 3.00139887302693
Validation loss: 2.840094585100186

Epoch: 5| Step: 3
Training loss: 3.2004311747934597
Validation loss: 2.8433750315108446

Epoch: 5| Step: 4
Training loss: 3.2375222341591425
Validation loss: 2.8303691504022073

Epoch: 5| Step: 5
Training loss: 3.0199929657911015
Validation loss: 2.8273229482053197

Epoch: 5| Step: 6
Training loss: 3.4694064782085072
Validation loss: 2.825465128412693

Epoch: 5| Step: 7
Training loss: 2.898198120432052
Validation loss: 2.8234510209266994

Epoch: 5| Step: 8
Training loss: 3.0911470502654423
Validation loss: 2.820393764504602

Epoch: 5| Step: 9
Training loss: 3.255687725116855
Validation loss: 2.8234881180736195

Epoch: 5| Step: 10
Training loss: 2.3122810053875322
Validation loss: 2.8252848789453266

Epoch: 38| Step: 0
Training loss: 3.1736135744789706
Validation loss: 2.8237084591067263

Epoch: 5| Step: 1
Training loss: 2.803765020377019
Validation loss: 2.8387889425080046

Epoch: 5| Step: 2
Training loss: 3.245838729076936
Validation loss: 2.8655424067872164

Epoch: 5| Step: 3
Training loss: 3.83949105863726
Validation loss: 2.898167388759656

Epoch: 5| Step: 4
Training loss: 2.7617825469724213
Validation loss: 2.827652265268638

Epoch: 5| Step: 5
Training loss: 3.396159774598305
Validation loss: 2.8574595224963746

Epoch: 5| Step: 6
Training loss: 3.6033817090631595
Validation loss: 2.9166466089663543

Epoch: 5| Step: 7
Training loss: 2.708361718444752
Validation loss: 2.8512149641152336

Epoch: 5| Step: 8
Training loss: 2.9521925326987177
Validation loss: 2.8428626359007647

Epoch: 5| Step: 9
Training loss: 2.771577539148323
Validation loss: 2.8482949242483038

Epoch: 5| Step: 10
Training loss: 3.3844314471862367
Validation loss: 2.8424238709639704

Epoch: 39| Step: 0
Training loss: 3.2426247175550436
Validation loss: 2.8397874202688684

Epoch: 5| Step: 1
Training loss: 2.9555841127448508
Validation loss: 2.8421664259130184

Epoch: 5| Step: 2
Training loss: 3.1139255369148895
Validation loss: 2.83842264772413

Epoch: 5| Step: 3
Training loss: 3.074522592344607
Validation loss: 2.84154391662519

Epoch: 5| Step: 4
Training loss: 3.850102579310819
Validation loss: 2.8899241636891344

Epoch: 5| Step: 5
Training loss: 3.1560306283989985
Validation loss: 2.8484480745977665

Epoch: 5| Step: 6
Training loss: 2.667286194917854
Validation loss: 2.849400111377624

Epoch: 5| Step: 7
Training loss: 3.123908042863316
Validation loss: 2.8494251673583104

Epoch: 5| Step: 8
Training loss: 3.673248553558316
Validation loss: 2.8254451706230856

Epoch: 5| Step: 9
Training loss: 2.670536352856158
Validation loss: 2.8233274229033607

Epoch: 5| Step: 10
Training loss: 2.7362514487829506
Validation loss: 2.8171188219721945

Epoch: 40| Step: 0
Training loss: 3.2781883851824496
Validation loss: 2.818206989246409

Epoch: 5| Step: 1
Training loss: 3.1764682528751074
Validation loss: 2.8208085140564405

Epoch: 5| Step: 2
Training loss: 3.2479919685865806
Validation loss: 2.8213737099498553

Epoch: 5| Step: 3
Training loss: 3.1696620794745742
Validation loss: 2.8190556480092486

Epoch: 5| Step: 4
Training loss: 2.773748074187495
Validation loss: 2.8166910827106615

Epoch: 5| Step: 5
Training loss: 2.870784156352282
Validation loss: 2.8168729596490203

Epoch: 5| Step: 6
Training loss: 3.2273715208027376
Validation loss: 2.813878152652538

Epoch: 5| Step: 7
Training loss: 3.1029553877008165
Validation loss: 2.8154111327914237

Epoch: 5| Step: 8
Training loss: 3.70118656205859
Validation loss: 2.8141319617296263

Epoch: 5| Step: 9
Training loss: 3.010302179572893
Validation loss: 2.8093059528526703

Epoch: 5| Step: 10
Training loss: 2.7308782398705613
Validation loss: 2.8094452779931323

Epoch: 41| Step: 0
Training loss: 3.706460344029105
Validation loss: 2.8120521471407556

Epoch: 5| Step: 1
Training loss: 3.3369856534517455
Validation loss: 2.819311855322469

Epoch: 5| Step: 2
Training loss: 3.086033918588661
Validation loss: 2.8125540633571378

Epoch: 5| Step: 3
Training loss: 2.7841998968926305
Validation loss: 2.812316325216361

Epoch: 5| Step: 4
Training loss: 3.012165041460961
Validation loss: 2.817691029492537

Epoch: 5| Step: 5
Training loss: 2.838346944773709
Validation loss: 2.822249610521336

Epoch: 5| Step: 6
Training loss: 3.141887050626041
Validation loss: 2.84008609285937

Epoch: 5| Step: 7
Training loss: 3.0349512215077117
Validation loss: 2.836851180670268

Epoch: 5| Step: 8
Training loss: 3.131592929358399
Validation loss: 2.83581468937782

Epoch: 5| Step: 9
Training loss: 3.319484041865425
Validation loss: 2.8276767786842023

Epoch: 5| Step: 10
Training loss: 2.6952385491440256
Validation loss: 2.828298761566918

Epoch: 42| Step: 0
Training loss: 2.9013206763248554
Validation loss: 2.8141276946582865

Epoch: 5| Step: 1
Training loss: 3.0262026894427168
Validation loss: 2.8070586167133986

Epoch: 5| Step: 2
Training loss: 2.7659431748638523
Validation loss: 2.803237873586545

Epoch: 5| Step: 3
Training loss: 3.063916404310826
Validation loss: 2.8023483965874383

Epoch: 5| Step: 4
Training loss: 2.965022588068075
Validation loss: 2.8001851690829214

Epoch: 5| Step: 5
Training loss: 3.6686173943074833
Validation loss: 2.8045170389682053

Epoch: 5| Step: 6
Training loss: 3.2729401495123676
Validation loss: 2.802004300267133

Epoch: 5| Step: 7
Training loss: 3.5771816292737326
Validation loss: 2.795560706613102

Epoch: 5| Step: 8
Training loss: 3.5795280004739114
Validation loss: 2.7956452059751538

Epoch: 5| Step: 9
Training loss: 2.7256242509511552
Validation loss: 2.7910307890241275

Epoch: 5| Step: 10
Training loss: 2.2394075073301685
Validation loss: 2.7885344529859113

Epoch: 43| Step: 0
Training loss: 2.9743634608831053
Validation loss: 2.788293379662077

Epoch: 5| Step: 1
Training loss: 3.2757257370870136
Validation loss: 2.7888222095651347

Epoch: 5| Step: 2
Training loss: 3.116901738350634
Validation loss: 2.789972066158342

Epoch: 5| Step: 3
Training loss: 3.160466616258256
Validation loss: 2.788226407575179

Epoch: 5| Step: 4
Training loss: 3.2115593746563924
Validation loss: 2.789055183345667

Epoch: 5| Step: 5
Training loss: 2.9350640768565697
Validation loss: 2.7900637079131596

Epoch: 5| Step: 6
Training loss: 2.9573066613405152
Validation loss: 2.7852719851042402

Epoch: 5| Step: 7
Training loss: 2.991502329811899
Validation loss: 2.785490456545714

Epoch: 5| Step: 8
Training loss: 3.463313060281387
Validation loss: 2.782955843452628

Epoch: 5| Step: 9
Training loss: 2.785514562384893
Validation loss: 2.7843070554181435

Epoch: 5| Step: 10
Training loss: 3.2397551823181674
Validation loss: 2.7841447221787687

Epoch: 44| Step: 0
Training loss: 2.8634389545054386
Validation loss: 2.7840953419958834

Epoch: 5| Step: 1
Training loss: 2.7017621259476337
Validation loss: 2.795352815114368

Epoch: 5| Step: 2
Training loss: 3.499389322683869
Validation loss: 2.795829655968375

Epoch: 5| Step: 3
Training loss: 3.1752534359684415
Validation loss: 2.810560819916256

Epoch: 5| Step: 4
Training loss: 3.0709339706790355
Validation loss: 2.8201929568778765

Epoch: 5| Step: 5
Training loss: 3.3435382241182974
Validation loss: 2.831833194968505

Epoch: 5| Step: 6
Training loss: 2.6021495076650956
Validation loss: 2.8373040461977843

Epoch: 5| Step: 7
Training loss: 3.4776258578311245
Validation loss: 2.8271024391042037

Epoch: 5| Step: 8
Training loss: 3.08842271615419
Validation loss: 2.7935770746991966

Epoch: 5| Step: 9
Training loss: 3.235223778556727
Validation loss: 2.781329885812396

Epoch: 5| Step: 10
Training loss: 3.0095081652435303
Validation loss: 2.7806843588818855

Epoch: 45| Step: 0
Training loss: 3.1519766100969315
Validation loss: 2.776712982681146

Epoch: 5| Step: 1
Training loss: 2.806292486400175
Validation loss: 2.778418613844988

Epoch: 5| Step: 2
Training loss: 3.304080700006548
Validation loss: 2.778749805694162

Epoch: 5| Step: 3
Training loss: 3.2042847557447884
Validation loss: 2.7762814005225516

Epoch: 5| Step: 4
Training loss: 2.995730859297553
Validation loss: 2.780907524456783

Epoch: 5| Step: 5
Training loss: 3.478274765971661
Validation loss: 2.776877662340366

Epoch: 5| Step: 6
Training loss: 3.306416232972501
Validation loss: 2.778731731218032

Epoch: 5| Step: 7
Training loss: 3.347896963432236
Validation loss: 2.773522641026051

Epoch: 5| Step: 8
Training loss: 2.7870274232980434
Validation loss: 2.775434705673096

Epoch: 5| Step: 9
Training loss: 2.3093288432504173
Validation loss: 2.7754275747789374

Epoch: 5| Step: 10
Training loss: 3.183742477593823
Validation loss: 2.790917426557544

Epoch: 46| Step: 0
Training loss: 2.6761207977708095
Validation loss: 2.806672683105595

Epoch: 5| Step: 1
Training loss: 3.723303051184783
Validation loss: 2.830643845609192

Epoch: 5| Step: 2
Training loss: 2.826203594543836
Validation loss: 2.84690619041274

Epoch: 5| Step: 3
Training loss: 2.7175495522902304
Validation loss: 2.8352316017373327

Epoch: 5| Step: 4
Training loss: 3.4690668459687135
Validation loss: 2.8073805444261

Epoch: 5| Step: 5
Training loss: 2.9952478918232592
Validation loss: 2.7923469143223456

Epoch: 5| Step: 6
Training loss: 3.0418960972484053
Validation loss: 2.781947104905036

Epoch: 5| Step: 7
Training loss: 3.129472812215735
Validation loss: 2.773854147572116

Epoch: 5| Step: 8
Training loss: 3.4170110265360205
Validation loss: 2.7731072203329568

Epoch: 5| Step: 9
Training loss: 3.0618219987494975
Validation loss: 2.7710581214969516

Epoch: 5| Step: 10
Training loss: 2.6256847396770335
Validation loss: 2.7685057209701793

Epoch: 47| Step: 0
Training loss: 3.2401210588044402
Validation loss: 2.7657145842613904

Epoch: 5| Step: 1
Training loss: 2.9938534712779297
Validation loss: 2.765786727682516

Epoch: 5| Step: 2
Training loss: 3.1988893369593616
Validation loss: 2.764564924182452

Epoch: 5| Step: 3
Training loss: 3.1686806214090377
Validation loss: 2.7625263222323033

Epoch: 5| Step: 4
Training loss: 3.3477401455812585
Validation loss: 2.7585316706576775

Epoch: 5| Step: 5
Training loss: 3.439359682060457
Validation loss: 2.7619626821291505

Epoch: 5| Step: 6
Training loss: 3.1832066961800436
Validation loss: 2.75881054604794

Epoch: 5| Step: 7
Training loss: 2.4653252132908547
Validation loss: 2.752899191055093

Epoch: 5| Step: 8
Training loss: 3.0646804521023943
Validation loss: 2.758015181737015

Epoch: 5| Step: 9
Training loss: 2.927024831673687
Validation loss: 2.7548775435473267

Epoch: 5| Step: 10
Training loss: 2.7477733093611363
Validation loss: 2.7545243704608415

Epoch: 48| Step: 0
Training loss: 2.9096862823119967
Validation loss: 2.7512485023000934

Epoch: 5| Step: 1
Training loss: 2.5898687899430533
Validation loss: 2.7589991199825756

Epoch: 5| Step: 2
Training loss: 3.2320543892787987
Validation loss: 2.7631354723638

Epoch: 5| Step: 3
Training loss: 3.1955149989796032
Validation loss: 2.7688707674649637

Epoch: 5| Step: 4
Training loss: 4.06032280902351
Validation loss: 2.776304241850482

Epoch: 5| Step: 5
Training loss: 2.6190612462337413
Validation loss: 2.760628610199473

Epoch: 5| Step: 6
Training loss: 2.774674002941844
Validation loss: 2.7583867775136546

Epoch: 5| Step: 7
Training loss: 2.9792497174262147
Validation loss: 2.7575649124888986

Epoch: 5| Step: 8
Training loss: 2.6892970974166888
Validation loss: 2.7562138512812937

Epoch: 5| Step: 9
Training loss: 3.7788731694819124
Validation loss: 2.750570390973623

Epoch: 5| Step: 10
Training loss: 2.3963023072266214
Validation loss: 2.7426350976208296

Epoch: 49| Step: 0
Training loss: 3.377191185489019
Validation loss: 2.740316633863378

Epoch: 5| Step: 1
Training loss: 2.717261597564653
Validation loss: 2.7419387316096433

Epoch: 5| Step: 2
Training loss: 2.908167872782061
Validation loss: 2.7412722181684535

Epoch: 5| Step: 3
Training loss: 3.2393333281350656
Validation loss: 2.7409298860908224

Epoch: 5| Step: 4
Training loss: 3.1001251503077745
Validation loss: 2.7362027736354273

Epoch: 5| Step: 5
Training loss: 3.0616910216294313
Validation loss: 2.737331868109258

Epoch: 5| Step: 6
Training loss: 3.6351425082096402
Validation loss: 2.733477638768778

Epoch: 5| Step: 7
Training loss: 2.736674361069054
Validation loss: 2.73793511226606

Epoch: 5| Step: 8
Training loss: 2.869463856292809
Validation loss: 2.7331384931771883

Epoch: 5| Step: 9
Training loss: 3.2199814301897147
Validation loss: 2.731300777080536

Epoch: 5| Step: 10
Training loss: 2.5778775183064164
Validation loss: 2.7320662645022664

Epoch: 50| Step: 0
Training loss: 3.3494388281108876
Validation loss: 2.731794070601102

Epoch: 5| Step: 1
Training loss: 3.4710928763028526
Validation loss: 2.7301537661268878

Epoch: 5| Step: 2
Training loss: 3.2125676604392925
Validation loss: 2.7313822439171593

Epoch: 5| Step: 3
Training loss: 2.8677653632063
Validation loss: 2.7323729636853344

Epoch: 5| Step: 4
Training loss: 3.0258353727125984
Validation loss: 2.730719411055757

Epoch: 5| Step: 5
Training loss: 2.980165718642386
Validation loss: 2.7292825435814465

Epoch: 5| Step: 6
Training loss: 2.83391623017442
Validation loss: 2.7329535408289587

Epoch: 5| Step: 7
Training loss: 2.8332700348309543
Validation loss: 2.7319558426034423

Epoch: 5| Step: 8
Training loss: 3.124867245715364
Validation loss: 2.7473173900782575

Epoch: 5| Step: 9
Training loss: 3.0716753160338004
Validation loss: 2.7767135311002287

Epoch: 5| Step: 10
Training loss: 2.7884046275556704
Validation loss: 2.7317605556811357

Epoch: 51| Step: 0
Training loss: 2.4898638281298426
Validation loss: 2.727568716492305

Epoch: 5| Step: 1
Training loss: 3.2367055853544433
Validation loss: 2.725681297811007

Epoch: 5| Step: 2
Training loss: 3.2236745254420285
Validation loss: 2.727325805552767

Epoch: 5| Step: 3
Training loss: 2.7763036397933116
Validation loss: 2.7279553017419116

Epoch: 5| Step: 4
Training loss: 2.5718301391397143
Validation loss: 2.728734767931188

Epoch: 5| Step: 5
Training loss: 3.6873466330493994
Validation loss: 2.7333807037244497

Epoch: 5| Step: 6
Training loss: 3.339897431951621
Validation loss: 2.7318771292981086

Epoch: 5| Step: 7
Training loss: 2.9164298006788365
Validation loss: 2.7265580018574056

Epoch: 5| Step: 8
Training loss: 3.360619035190186
Validation loss: 2.726145546871426

Epoch: 5| Step: 9
Training loss: 3.1504056094168598
Validation loss: 2.724611740472944

Epoch: 5| Step: 10
Training loss: 2.611523503232274
Validation loss: 2.725575452797707

Epoch: 52| Step: 0
Training loss: 3.7808548902155317
Validation loss: 2.7220483945474383

Epoch: 5| Step: 1
Training loss: 3.508917076011584
Validation loss: 2.7233751102774173

Epoch: 5| Step: 2
Training loss: 3.0262624076831557
Validation loss: 2.7237547948970775

Epoch: 5| Step: 3
Training loss: 2.6142938359898977
Validation loss: 2.722283895113579

Epoch: 5| Step: 4
Training loss: 2.866388942513417
Validation loss: 2.7216154525448855

Epoch: 5| Step: 5
Training loss: 2.759214568955561
Validation loss: 2.740109765563992

Epoch: 5| Step: 6
Training loss: 2.928332043211263
Validation loss: 2.7746734873816

Epoch: 5| Step: 7
Training loss: 2.6006963164239747
Validation loss: 2.8006337460900577

Epoch: 5| Step: 8
Training loss: 3.069597699773074
Validation loss: 2.7979745221179435

Epoch: 5| Step: 9
Training loss: 3.2809667555855127
Validation loss: 2.734084307194799

Epoch: 5| Step: 10
Training loss: 2.982249196867491
Validation loss: 2.720586468362315

Epoch: 53| Step: 0
Training loss: 2.9233442070416955
Validation loss: 2.7154932776787954

Epoch: 5| Step: 1
Training loss: 2.97928877004519
Validation loss: 2.7187482065117803

Epoch: 5| Step: 2
Training loss: 2.633594521313342
Validation loss: 2.7198926593961823

Epoch: 5| Step: 3
Training loss: 2.9759144315313213
Validation loss: 2.7204705342180504

Epoch: 5| Step: 4
Training loss: 2.9992916542487316
Validation loss: 2.7244840255191094

Epoch: 5| Step: 5
Training loss: 3.5204326394106635
Validation loss: 2.72443067799943

Epoch: 5| Step: 6
Training loss: 3.1920261037901665
Validation loss: 2.7181099437746825

Epoch: 5| Step: 7
Training loss: 3.0078784489523303
Validation loss: 2.7196770345076353

Epoch: 5| Step: 8
Training loss: 3.224515917028465
Validation loss: 2.7151111300254147

Epoch: 5| Step: 9
Training loss: 3.1477783118862184
Validation loss: 2.7156040055228456

Epoch: 5| Step: 10
Training loss: 2.883499022410733
Validation loss: 2.713589242696

Epoch: 54| Step: 0
Training loss: 2.7881779483504063
Validation loss: 2.7121200088946362

Epoch: 5| Step: 1
Training loss: 3.073376085669446
Validation loss: 2.7118305455160883

Epoch: 5| Step: 2
Training loss: 3.073600736005736
Validation loss: 2.7184909211024273

Epoch: 5| Step: 3
Training loss: 2.865107226004623
Validation loss: 2.717751700305044

Epoch: 5| Step: 4
Training loss: 3.363707689283555
Validation loss: 2.715696255610617

Epoch: 5| Step: 5
Training loss: 3.3715769044697623
Validation loss: 2.728453208426765

Epoch: 5| Step: 6
Training loss: 3.63368316389463
Validation loss: 2.760224645664838

Epoch: 5| Step: 7
Training loss: 2.802609834994345
Validation loss: 2.7578712997900694

Epoch: 5| Step: 8
Training loss: 2.862296191293685
Validation loss: 2.784319700920178

Epoch: 5| Step: 9
Training loss: 2.6905351400046067
Validation loss: 2.794596834249768

Epoch: 5| Step: 10
Training loss: 2.7425493398312257
Validation loss: 2.73717943705387

Epoch: 55| Step: 0
Training loss: 3.4768800054716773
Validation loss: 2.715828542922583

Epoch: 5| Step: 1
Training loss: 3.384539368249318
Validation loss: 2.706505112170148

Epoch: 5| Step: 2
Training loss: 3.2397754935200505
Validation loss: 2.7045944661081385

Epoch: 5| Step: 3
Training loss: 2.522214043763168
Validation loss: 2.7022429874338023

Epoch: 5| Step: 4
Training loss: 2.7718142635051954
Validation loss: 2.7032284910947535

Epoch: 5| Step: 5
Training loss: 3.036589020435317
Validation loss: 2.7044233715050012

Epoch: 5| Step: 6
Training loss: 3.0327725077158574
Validation loss: 2.699214802747384

Epoch: 5| Step: 7
Training loss: 3.361683748574105
Validation loss: 2.704061425288829

Epoch: 5| Step: 8
Training loss: 2.93603901345009
Validation loss: 2.695474615418785

Epoch: 5| Step: 9
Training loss: 2.771189807725096
Validation loss: 2.6934738062888073

Epoch: 5| Step: 10
Training loss: 2.6941816085965877
Validation loss: 2.690213164839617

Epoch: 56| Step: 0
Training loss: 2.730394179563357
Validation loss: 2.6891687396405257

Epoch: 5| Step: 1
Training loss: 2.885605696856716
Validation loss: 2.684191893978194

Epoch: 5| Step: 2
Training loss: 2.6378930761663977
Validation loss: 2.6843118847868643

Epoch: 5| Step: 3
Training loss: 2.9927412272707046
Validation loss: 2.686850114119437

Epoch: 5| Step: 4
Training loss: 3.3118040685334167
Validation loss: 2.68358277452076

Epoch: 5| Step: 5
Training loss: 2.547221996797778
Validation loss: 2.688190052054183

Epoch: 5| Step: 6
Training loss: 3.3691460031659974
Validation loss: 2.6829287262991643

Epoch: 5| Step: 7
Training loss: 3.0710181282027627
Validation loss: 2.6859754486429788

Epoch: 5| Step: 8
Training loss: 2.8149923513522
Validation loss: 2.6773792759400776

Epoch: 5| Step: 9
Training loss: 3.3334296848358926
Validation loss: 2.678090598667667

Epoch: 5| Step: 10
Training loss: 3.4063019354824355
Validation loss: 2.681122959013954

Epoch: 57| Step: 0
Training loss: 3.0392612892387416
Validation loss: 2.677404425049753

Epoch: 5| Step: 1
Training loss: 3.4330762661986016
Validation loss: 2.676587478594605

Epoch: 5| Step: 2
Training loss: 3.17819156183178
Validation loss: 2.6817397151356754

Epoch: 5| Step: 3
Training loss: 3.1437756880512686
Validation loss: 2.677872502952883

Epoch: 5| Step: 4
Training loss: 2.981337354487856
Validation loss: 2.680971465915423

Epoch: 5| Step: 5
Training loss: 2.9490092019926792
Validation loss: 2.680507980480755

Epoch: 5| Step: 6
Training loss: 3.1964873227065413
Validation loss: 2.677986425221321

Epoch: 5| Step: 7
Training loss: 3.0208678846466057
Validation loss: 2.6778446269145437

Epoch: 5| Step: 8
Training loss: 2.616575983828941
Validation loss: 2.673022116247957

Epoch: 5| Step: 9
Training loss: 2.950598226117506
Validation loss: 2.675612597760206

Epoch: 5| Step: 10
Training loss: 2.3280067157779585
Validation loss: 2.6776768676933025

Epoch: 58| Step: 0
Training loss: 3.4836843858226327
Validation loss: 2.6814700381453758

Epoch: 5| Step: 1
Training loss: 2.736338319289763
Validation loss: 2.6871075697813738

Epoch: 5| Step: 2
Training loss: 3.2448532727283133
Validation loss: 2.6782255341217898

Epoch: 5| Step: 3
Training loss: 2.9715853352380863
Validation loss: 2.6677797984749643

Epoch: 5| Step: 4
Training loss: 3.02592409379332
Validation loss: 2.6685812384359164

Epoch: 5| Step: 5
Training loss: 2.9783142221866217
Validation loss: 2.669695144571718

Epoch: 5| Step: 6
Training loss: 3.060845064147133
Validation loss: 2.6702426946566873

Epoch: 5| Step: 7
Training loss: 2.852213411636657
Validation loss: 2.67049931687219

Epoch: 5| Step: 8
Training loss: 2.9901083951458483
Validation loss: 2.6724431464644036

Epoch: 5| Step: 9
Training loss: 2.916767082302312
Validation loss: 2.6689910205773053

Epoch: 5| Step: 10
Training loss: 2.7982874878548594
Validation loss: 2.6702464447178

Epoch: 59| Step: 0
Training loss: 2.835787850627167
Validation loss: 2.6675744767482024

Epoch: 5| Step: 1
Training loss: 2.9947142129363673
Validation loss: 2.6660375205421776

Epoch: 5| Step: 2
Training loss: 2.956305834382053
Validation loss: 2.668537480268463

Epoch: 5| Step: 3
Training loss: 2.5665053721523488
Validation loss: 2.678969415551894

Epoch: 5| Step: 4
Training loss: 2.835791886219481
Validation loss: 2.690197852783495

Epoch: 5| Step: 5
Training loss: 3.2147657308462825
Validation loss: 2.666378247586526

Epoch: 5| Step: 6
Training loss: 3.5235302018448755
Validation loss: 2.6599717590531586

Epoch: 5| Step: 7
Training loss: 2.955336938228369
Validation loss: 2.661289315116296

Epoch: 5| Step: 8
Training loss: 3.1437131966774365
Validation loss: 2.658156818638964

Epoch: 5| Step: 9
Training loss: 3.3498142190917393
Validation loss: 2.6597510836345397

Epoch: 5| Step: 10
Training loss: 2.4011632484441185
Validation loss: 2.6580403301833604

Epoch: 60| Step: 0
Training loss: 3.1373715986141213
Validation loss: 2.6555423486430128

Epoch: 5| Step: 1
Training loss: 3.166488207423016
Validation loss: 2.656385071111303

Epoch: 5| Step: 2
Training loss: 3.446161905019895
Validation loss: 2.660075809164268

Epoch: 5| Step: 3
Training loss: 3.2447596630561244
Validation loss: 2.655600914497891

Epoch: 5| Step: 4
Training loss: 2.2949368350576225
Validation loss: 2.6548141488199466

Epoch: 5| Step: 5
Training loss: 2.95079327925012
Validation loss: 2.6558909849776815

Epoch: 5| Step: 6
Training loss: 3.144775684404948
Validation loss: 2.6594456076760653

Epoch: 5| Step: 7
Training loss: 2.837020625150063
Validation loss: 2.658922179117577

Epoch: 5| Step: 8
Training loss: 3.0586543948030718
Validation loss: 2.65574942787703

Epoch: 5| Step: 9
Training loss: 2.766168400887826
Validation loss: 2.653780873086857

Epoch: 5| Step: 10
Training loss: 2.8309682811171526
Validation loss: 2.650658219996205

Epoch: 61| Step: 0
Training loss: 2.5699451497084067
Validation loss: 2.6518173148414657

Epoch: 5| Step: 1
Training loss: 2.753034564642702
Validation loss: 2.660435898092081

Epoch: 5| Step: 2
Training loss: 3.382113977073874
Validation loss: 2.6662027025250388

Epoch: 5| Step: 3
Training loss: 3.389367217474037
Validation loss: 2.659107218185596

Epoch: 5| Step: 4
Training loss: 2.980084915743426
Validation loss: 2.659077705045956

Epoch: 5| Step: 5
Training loss: 2.4929230659815462
Validation loss: 2.6510194909313216

Epoch: 5| Step: 6
Training loss: 2.636792081590216
Validation loss: 2.6531809072955954

Epoch: 5| Step: 7
Training loss: 3.2514659803107526
Validation loss: 2.6484768201173217

Epoch: 5| Step: 8
Training loss: 3.005409449960864
Validation loss: 2.648727891355057

Epoch: 5| Step: 9
Training loss: 3.159277040375959
Validation loss: 2.6502233914918927

Epoch: 5| Step: 10
Training loss: 3.1335769443636705
Validation loss: 2.6502786651199335

Epoch: 62| Step: 0
Training loss: 2.8370169274595267
Validation loss: 2.651956290976252

Epoch: 5| Step: 1
Training loss: 2.438123280970269
Validation loss: 2.6470858440431586

Epoch: 5| Step: 2
Training loss: 2.655356582288255
Validation loss: 2.6502068568683512

Epoch: 5| Step: 3
Training loss: 3.3433215856171414
Validation loss: 2.662317059483075

Epoch: 5| Step: 4
Training loss: 3.5234572585539397
Validation loss: 2.6507101120987873

Epoch: 5| Step: 5
Training loss: 2.9763614456478837
Validation loss: 2.660371738268746

Epoch: 5| Step: 6
Training loss: 2.9787413464675434
Validation loss: 2.662957743041951

Epoch: 5| Step: 7
Training loss: 3.484344619139553
Validation loss: 2.6638276083183503

Epoch: 5| Step: 8
Training loss: 3.179122087225245
Validation loss: 2.6677023734341874

Epoch: 5| Step: 9
Training loss: 2.6940507229714727
Validation loss: 2.6649390397016894

Epoch: 5| Step: 10
Training loss: 2.3949648291886327
Validation loss: 2.6436001596349663

Epoch: 63| Step: 0
Training loss: 2.923070326500372
Validation loss: 2.640079256221654

Epoch: 5| Step: 1
Training loss: 3.2944700319076654
Validation loss: 2.63935740172071

Epoch: 5| Step: 2
Training loss: 2.8155777092115373
Validation loss: 2.6425910364100895

Epoch: 5| Step: 3
Training loss: 2.90418867616418
Validation loss: 2.636130854894547

Epoch: 5| Step: 4
Training loss: 3.162862818716925
Validation loss: 2.6345833466050044

Epoch: 5| Step: 5
Training loss: 2.6239733732023933
Validation loss: 2.638084934078072

Epoch: 5| Step: 6
Training loss: 2.9036266012652514
Validation loss: 2.639545530461985

Epoch: 5| Step: 7
Training loss: 3.0924787895936996
Validation loss: 2.63988398313177

Epoch: 5| Step: 8
Training loss: 3.0585945295038117
Validation loss: 2.6378415616969058

Epoch: 5| Step: 9
Training loss: 3.2454576293643127
Validation loss: 2.6459194327922937

Epoch: 5| Step: 10
Training loss: 2.57559653474018
Validation loss: 2.6520952859278326

Epoch: 64| Step: 0
Training loss: 3.272764150334671
Validation loss: 2.6487952750055213

Epoch: 5| Step: 1
Training loss: 2.3488725757944673
Validation loss: 2.667452173200333

Epoch: 5| Step: 2
Training loss: 3.1842901486218795
Validation loss: 2.6790433504271665

Epoch: 5| Step: 3
Training loss: 2.7641123282522004
Validation loss: 2.6591416757981596

Epoch: 5| Step: 4
Training loss: 3.167712105963402
Validation loss: 2.6453417753457207

Epoch: 5| Step: 5
Training loss: 2.5345101730855935
Validation loss: 2.636873706197544

Epoch: 5| Step: 6
Training loss: 2.845892298372865
Validation loss: 2.6348423998291834

Epoch: 5| Step: 7
Training loss: 3.1661142737465093
Validation loss: 2.6351891965476066

Epoch: 5| Step: 8
Training loss: 3.131845072776667
Validation loss: 2.63448722474877

Epoch: 5| Step: 9
Training loss: 3.0826854712507803
Validation loss: 2.6354243158296486

Epoch: 5| Step: 10
Training loss: 3.212596010190952
Validation loss: 2.632345744455331

Epoch: 65| Step: 0
Training loss: 3.3551012399694193
Validation loss: 2.632049412959738

Epoch: 5| Step: 1
Training loss: 2.294813411665609
Validation loss: 2.630746730078665

Epoch: 5| Step: 2
Training loss: 3.5213465269574136
Validation loss: 2.630008853612195

Epoch: 5| Step: 3
Training loss: 2.579517427749752
Validation loss: 2.628346537655184

Epoch: 5| Step: 4
Training loss: 3.006460544882399
Validation loss: 2.6279991359825083

Epoch: 5| Step: 5
Training loss: 3.1007689414497297
Validation loss: 2.630329673077593

Epoch: 5| Step: 6
Training loss: 2.674412286671889
Validation loss: 2.6324352530777326

Epoch: 5| Step: 7
Training loss: 2.932403200963336
Validation loss: 2.639772259390783

Epoch: 5| Step: 8
Training loss: 2.632693415362528
Validation loss: 2.65409537556544

Epoch: 5| Step: 9
Training loss: 3.217371080449304
Validation loss: 2.672489588993756

Epoch: 5| Step: 10
Training loss: 3.2808302837961945
Validation loss: 2.66339060321371

Epoch: 66| Step: 0
Training loss: 2.9782468180444504
Validation loss: 2.6232954273450084

Epoch: 5| Step: 1
Training loss: 3.354544071423719
Validation loss: 2.6305757002658647

Epoch: 5| Step: 2
Training loss: 3.5685934857521575
Validation loss: 2.643612804221245

Epoch: 5| Step: 3
Training loss: 3.02059195420106
Validation loss: 2.6408040237880317

Epoch: 5| Step: 4
Training loss: 2.56617779927016
Validation loss: 2.656824972137275

Epoch: 5| Step: 5
Training loss: 2.740677724959621
Validation loss: 2.668717773831593

Epoch: 5| Step: 6
Training loss: 3.03036973894271
Validation loss: 2.6553286204877526

Epoch: 5| Step: 7
Training loss: 3.0137223482386277
Validation loss: 2.6496151758293

Epoch: 5| Step: 8
Training loss: 2.6567286340657184
Validation loss: 2.6435035607191106

Epoch: 5| Step: 9
Training loss: 2.941141184987851
Validation loss: 2.638514195042078

Epoch: 5| Step: 10
Training loss: 3.141263982192957
Validation loss: 2.637579530427537

Epoch: 67| Step: 0
Training loss: 2.9187350613785603
Validation loss: 2.6377187153656467

Epoch: 5| Step: 1
Training loss: 2.839112577274883
Validation loss: 2.634498851417685

Epoch: 5| Step: 2
Training loss: 3.188384288720322
Validation loss: 2.633387410369412

Epoch: 5| Step: 3
Training loss: 2.5480165322155197
Validation loss: 2.6327817057033145

Epoch: 5| Step: 4
Training loss: 3.1721031971292017
Validation loss: 2.632516360303784

Epoch: 5| Step: 5
Training loss: 2.794150447948185
Validation loss: 2.6293625664055114

Epoch: 5| Step: 6
Training loss: 3.516000820841167
Validation loss: 2.6243530302386304

Epoch: 5| Step: 7
Training loss: 3.0653218872909704
Validation loss: 2.623372774347418

Epoch: 5| Step: 8
Training loss: 2.7952610239286297
Validation loss: 2.622189595074703

Epoch: 5| Step: 9
Training loss: 2.936219605945853
Validation loss: 2.6261220029332892

Epoch: 5| Step: 10
Training loss: 2.891662411498824
Validation loss: 2.6285658025652707

Epoch: 68| Step: 0
Training loss: 2.299440365583123
Validation loss: 2.6387415916238295

Epoch: 5| Step: 1
Training loss: 2.693550307800215
Validation loss: 2.6723146574006598

Epoch: 5| Step: 2
Training loss: 3.3400943059799006
Validation loss: 2.735109357768765

Epoch: 5| Step: 3
Training loss: 3.60765781260963
Validation loss: 2.734583918827636

Epoch: 5| Step: 4
Training loss: 3.3023043938577774
Validation loss: 2.682071838705514

Epoch: 5| Step: 5
Training loss: 2.392283145081333
Validation loss: 2.6209310999502655

Epoch: 5| Step: 6
Training loss: 3.205539593435559
Validation loss: 2.6220450745901376

Epoch: 5| Step: 7
Training loss: 2.5065337631657574
Validation loss: 2.6201774688047403

Epoch: 5| Step: 8
Training loss: 2.9392743534715478
Validation loss: 2.6293360227459055

Epoch: 5| Step: 9
Training loss: 3.238240019716415
Validation loss: 2.6303574444978026

Epoch: 5| Step: 10
Training loss: 3.0401772462471053
Validation loss: 2.6414626510665564

Epoch: 69| Step: 0
Training loss: 3.0742744334120777
Validation loss: 2.6412360012420617

Epoch: 5| Step: 1
Training loss: 2.3474358631346592
Validation loss: 2.639425948290983

Epoch: 5| Step: 2
Training loss: 3.1365498536506693
Validation loss: 2.638238495290476

Epoch: 5| Step: 3
Training loss: 3.364998019304302
Validation loss: 2.642232924874074

Epoch: 5| Step: 4
Training loss: 3.172415250423274
Validation loss: 2.640627662058823

Epoch: 5| Step: 5
Training loss: 2.857247316630738
Validation loss: 2.6357269558401875

Epoch: 5| Step: 6
Training loss: 2.424170605903363
Validation loss: 2.6292295031838213

Epoch: 5| Step: 7
Training loss: 3.107550310876937
Validation loss: 2.630518632631189

Epoch: 5| Step: 8
Training loss: 3.102324192866381
Validation loss: 2.62847460651756

Epoch: 5| Step: 9
Training loss: 3.0407534408493415
Validation loss: 2.629718274728467

Epoch: 5| Step: 10
Training loss: 3.060489383783174
Validation loss: 2.623696673131451

Epoch: 70| Step: 0
Training loss: 3.2208667202329866
Validation loss: 2.6198998785673617

Epoch: 5| Step: 1
Training loss: 2.992700119529541
Validation loss: 2.617559027959362

Epoch: 5| Step: 2
Training loss: 3.1372747819167794
Validation loss: 2.6220577204627586

Epoch: 5| Step: 3
Training loss: 2.1773757981486628
Validation loss: 2.622885589336006

Epoch: 5| Step: 4
Training loss: 2.7110569292744646
Validation loss: 2.628253072497853

Epoch: 5| Step: 5
Training loss: 3.676642516660071
Validation loss: 2.6338959612212283

Epoch: 5| Step: 6
Training loss: 3.4009749136775995
Validation loss: 2.660289021979359

Epoch: 5| Step: 7
Training loss: 2.6095869697774075
Validation loss: 2.6871678747382903

Epoch: 5| Step: 8
Training loss: 3.005468629421056
Validation loss: 2.6714672071751684

Epoch: 5| Step: 9
Training loss: 2.6089388545669094
Validation loss: 2.657579451951601

Epoch: 5| Step: 10
Training loss: 2.811505544538626
Validation loss: 2.6680013385905315

Epoch: 71| Step: 0
Training loss: 3.396870569754399
Validation loss: 2.634375592297627

Epoch: 5| Step: 1
Training loss: 2.9208401566088797
Validation loss: 2.615404741678393

Epoch: 5| Step: 2
Training loss: 3.4327808238023496
Validation loss: 2.6091964510274392

Epoch: 5| Step: 3
Training loss: 2.6516435061181998
Validation loss: 2.610860448807319

Epoch: 5| Step: 4
Training loss: 3.091966982202553
Validation loss: 2.6086837759850345

Epoch: 5| Step: 5
Training loss: 3.0077624031948176
Validation loss: 2.61047429432161

Epoch: 5| Step: 6
Training loss: 2.4664258035990914
Validation loss: 2.607936066200243

Epoch: 5| Step: 7
Training loss: 3.0571945322301537
Validation loss: 2.608870481767552

Epoch: 5| Step: 8
Training loss: 3.0507496772333926
Validation loss: 2.608436005339549

Epoch: 5| Step: 9
Training loss: 2.5149619608859632
Validation loss: 2.6051935316630033

Epoch: 5| Step: 10
Training loss: 2.799442498018692
Validation loss: 2.6052639414555014

Epoch: 72| Step: 0
Training loss: 2.8019228940125562
Validation loss: 2.6060197408748795

Epoch: 5| Step: 1
Training loss: 2.9438518271683214
Validation loss: 2.607292772530256

Epoch: 5| Step: 2
Training loss: 2.881178312588984
Validation loss: 2.6046119739079474

Epoch: 5| Step: 3
Training loss: 2.74671653316501
Validation loss: 2.601159923381691

Epoch: 5| Step: 4
Training loss: 2.245424705043139
Validation loss: 2.610398214058753

Epoch: 5| Step: 5
Training loss: 3.454064703074113
Validation loss: 2.6087760746371225

Epoch: 5| Step: 6
Training loss: 2.8376859629186435
Validation loss: 2.619798157817101

Epoch: 5| Step: 7
Training loss: 3.0698378489661815
Validation loss: 2.631984723336381

Epoch: 5| Step: 8
Training loss: 3.0654460205342993
Validation loss: 2.6231021808232766

Epoch: 5| Step: 9
Training loss: 3.418485173040231
Validation loss: 2.6217010304612667

Epoch: 5| Step: 10
Training loss: 2.8791758852276064
Validation loss: 2.608955672350117

Epoch: 73| Step: 0
Training loss: 2.423512354468857
Validation loss: 2.6084785427165076

Epoch: 5| Step: 1
Training loss: 2.638437211270369
Validation loss: 2.6068867990587257

Epoch: 5| Step: 2
Training loss: 3.164837325557383
Validation loss: 2.6005353421437674

Epoch: 5| Step: 3
Training loss: 2.7212160699049397
Validation loss: 2.5970365219435694

Epoch: 5| Step: 4
Training loss: 3.4443499200081225
Validation loss: 2.59423780542899

Epoch: 5| Step: 5
Training loss: 2.936485927127819
Validation loss: 2.5934134239137916

Epoch: 5| Step: 6
Training loss: 2.5634359185766047
Validation loss: 2.5955724312067616

Epoch: 5| Step: 7
Training loss: 2.9219125347480497
Validation loss: 2.5964220923295445

Epoch: 5| Step: 8
Training loss: 3.1279228274686717
Validation loss: 2.5922571000786303

Epoch: 5| Step: 9
Training loss: 3.5408976598869626
Validation loss: 2.5959543921822466

Epoch: 5| Step: 10
Training loss: 2.6682980335608204
Validation loss: 2.596564734386985

Epoch: 74| Step: 0
Training loss: 3.3541875487125754
Validation loss: 2.5957754612966077

Epoch: 5| Step: 1
Training loss: 3.1576480601822388
Validation loss: 2.59917928522697

Epoch: 5| Step: 2
Training loss: 2.6761670356587577
Validation loss: 2.60217271594462

Epoch: 5| Step: 3
Training loss: 2.6258892188081973
Validation loss: 2.6037410192979804

Epoch: 5| Step: 4
Training loss: 2.7960028966962356
Validation loss: 2.6204570342110327

Epoch: 5| Step: 5
Training loss: 2.314581475541828
Validation loss: 2.5931378455261545

Epoch: 5| Step: 6
Training loss: 2.8700085308200705
Validation loss: 2.5916403196533664

Epoch: 5| Step: 7
Training loss: 2.906464271439996
Validation loss: 2.5890475404598448

Epoch: 5| Step: 8
Training loss: 2.948220191309963
Validation loss: 2.5912837828997515

Epoch: 5| Step: 9
Training loss: 3.6248313601499267
Validation loss: 2.593327378753516

Epoch: 5| Step: 10
Training loss: 2.965685095544957
Validation loss: 2.5926888117764357

Epoch: 75| Step: 0
Training loss: 3.1652425943602402
Validation loss: 2.5890599573722333

Epoch: 5| Step: 1
Training loss: 3.176381034565218
Validation loss: 2.58865346762249

Epoch: 5| Step: 2
Training loss: 2.66925268151539
Validation loss: 2.5910894361296712

Epoch: 5| Step: 3
Training loss: 3.199217557615773
Validation loss: 2.5963584997042823

Epoch: 5| Step: 4
Training loss: 2.997116133264104
Validation loss: 2.610738087662685

Epoch: 5| Step: 5
Training loss: 2.891698194729501
Validation loss: 2.6115572084748613

Epoch: 5| Step: 6
Training loss: 2.633629827668146
Validation loss: 2.6314308648200355

Epoch: 5| Step: 7
Training loss: 2.8965013314469115
Validation loss: 2.6375507396317173

Epoch: 5| Step: 8
Training loss: 3.098553560038734
Validation loss: 2.6015099557068004

Epoch: 5| Step: 9
Training loss: 2.6700500144988926
Validation loss: 2.588915717499256

Epoch: 5| Step: 10
Training loss: 3.0065025746917993
Validation loss: 2.585042218246984

Epoch: 76| Step: 0
Training loss: 3.198398880942045
Validation loss: 2.587505550575733

Epoch: 5| Step: 1
Training loss: 2.627576744054955
Validation loss: 2.585359939185944

Epoch: 5| Step: 2
Training loss: 3.379503706662374
Validation loss: 2.585971690406282

Epoch: 5| Step: 3
Training loss: 2.420280965620555
Validation loss: 2.583925431071212

Epoch: 5| Step: 4
Training loss: 3.2344065494196474
Validation loss: 2.5878402519934536

Epoch: 5| Step: 5
Training loss: 2.9113740766659006
Validation loss: 2.584350861554707

Epoch: 5| Step: 6
Training loss: 2.7595022930364523
Validation loss: 2.5849579870355917

Epoch: 5| Step: 7
Training loss: 3.37854679378652
Validation loss: 2.5844965772574398

Epoch: 5| Step: 8
Training loss: 2.7293601125246063
Validation loss: 2.5823267630659905

Epoch: 5| Step: 9
Training loss: 2.7457679783207256
Validation loss: 2.5914899277985577

Epoch: 5| Step: 10
Training loss: 2.759048487525827
Validation loss: 2.589413194575883

Epoch: 77| Step: 0
Training loss: 2.855205894301239
Validation loss: 2.5876553259425976

Epoch: 5| Step: 1
Training loss: 3.3211018420659033
Validation loss: 2.5960578421458798

Epoch: 5| Step: 2
Training loss: 3.104513537251612
Validation loss: 2.598053029632209

Epoch: 5| Step: 3
Training loss: 2.557213051099693
Validation loss: 2.599375994780054

Epoch: 5| Step: 4
Training loss: 2.769095016579595
Validation loss: 2.6059539535498044

Epoch: 5| Step: 5
Training loss: 3.673166770158813
Validation loss: 2.595785507351234

Epoch: 5| Step: 6
Training loss: 2.9854422852791695
Validation loss: 2.5869940728953194

Epoch: 5| Step: 7
Training loss: 2.5348242496760216
Validation loss: 2.5782225659038884

Epoch: 5| Step: 8
Training loss: 2.6485394933635584
Validation loss: 2.5762751948837956

Epoch: 5| Step: 9
Training loss: 2.7658510277406134
Validation loss: 2.5810771766392926

Epoch: 5| Step: 10
Training loss: 2.8533104124960875
Validation loss: 2.580489045338078

Epoch: 78| Step: 0
Training loss: 3.0632795003561535
Validation loss: 2.581490363064607

Epoch: 5| Step: 1
Training loss: 2.8547295528126915
Validation loss: 2.5761531385166614

Epoch: 5| Step: 2
Training loss: 3.051620934430358
Validation loss: 2.578788606786349

Epoch: 5| Step: 3
Training loss: 2.9872593547353086
Validation loss: 2.5786419929021474

Epoch: 5| Step: 4
Training loss: 3.062213027899082
Validation loss: 2.583670193928256

Epoch: 5| Step: 5
Training loss: 2.861403782596169
Validation loss: 2.597809608577775

Epoch: 5| Step: 6
Training loss: 2.668059809682079
Validation loss: 2.6411900288072188

Epoch: 5| Step: 7
Training loss: 3.165100982163906
Validation loss: 2.653958293658037

Epoch: 5| Step: 8
Training loss: 2.9245434983544167
Validation loss: 2.6539188644548575

Epoch: 5| Step: 9
Training loss: 2.9791599264713327
Validation loss: 2.638669176963252

Epoch: 5| Step: 10
Training loss: 2.5812456144799025
Validation loss: 2.601501771587066

Epoch: 79| Step: 0
Training loss: 2.750456338646513
Validation loss: 2.5833572736564308

Epoch: 5| Step: 1
Training loss: 3.0030240076650725
Validation loss: 2.5750888819875426

Epoch: 5| Step: 2
Training loss: 2.6093723502688175
Validation loss: 2.574919311616427

Epoch: 5| Step: 3
Training loss: 2.6697642594467563
Validation loss: 2.572138542400782

Epoch: 5| Step: 4
Training loss: 3.168752401678315
Validation loss: 2.57333745691916

Epoch: 5| Step: 5
Training loss: 3.01241372645767
Validation loss: 2.579786879855022

Epoch: 5| Step: 6
Training loss: 3.484003021501705
Validation loss: 2.574245536334075

Epoch: 5| Step: 7
Training loss: 3.2144744030503976
Validation loss: 2.5744194709259602

Epoch: 5| Step: 8
Training loss: 2.969889853647413
Validation loss: 2.572500729246186

Epoch: 5| Step: 9
Training loss: 2.6646547973530073
Validation loss: 2.5801287439429426

Epoch: 5| Step: 10
Training loss: 2.639652321347263
Validation loss: 2.601560001950412

Epoch: 80| Step: 0
Training loss: 2.933247999192715
Validation loss: 2.6313160610014887

Epoch: 5| Step: 1
Training loss: 2.9270570873744544
Validation loss: 2.651190868972096

Epoch: 5| Step: 2
Training loss: 3.285271351143916
Validation loss: 2.6790001468781584

Epoch: 5| Step: 3
Training loss: 2.7087789511266687
Validation loss: 2.6960163145711245

Epoch: 5| Step: 4
Training loss: 2.7920630633820473
Validation loss: 2.7744424744157654

Epoch: 5| Step: 5
Training loss: 3.2683829748834228
Validation loss: 2.80674077693504

Epoch: 5| Step: 6
Training loss: 3.2366873174048516
Validation loss: 2.722028617498148

Epoch: 5| Step: 7
Training loss: 2.486723455627764
Validation loss: 2.6418839300835804

Epoch: 5| Step: 8
Training loss: 2.738070448571686
Validation loss: 2.610869083745459

Epoch: 5| Step: 9
Training loss: 3.237280089225928
Validation loss: 2.5929697936207394

Epoch: 5| Step: 10
Training loss: 2.997509558426202
Validation loss: 2.5824284260386996

Epoch: 81| Step: 0
Training loss: 3.488850272694539
Validation loss: 2.5816996096150713

Epoch: 5| Step: 1
Training loss: 2.857722070430176
Validation loss: 2.5838090532685625

Epoch: 5| Step: 2
Training loss: 2.918587206725912
Validation loss: 2.5794052291477456

Epoch: 5| Step: 3
Training loss: 2.916214789853711
Validation loss: 2.579570386227479

Epoch: 5| Step: 4
Training loss: 2.9288602347637336
Validation loss: 2.5785298307746003

Epoch: 5| Step: 5
Training loss: 3.0318244311146243
Validation loss: 2.576906274019964

Epoch: 5| Step: 6
Training loss: 3.0860183125791285
Validation loss: 2.5785824734940137

Epoch: 5| Step: 7
Training loss: 2.860119665350048
Validation loss: 2.575584168382605

Epoch: 5| Step: 8
Training loss: 2.747764111946053
Validation loss: 2.583019420778284

Epoch: 5| Step: 9
Training loss: 2.9189587079401567
Validation loss: 2.5905146152709424

Epoch: 5| Step: 10
Training loss: 2.6269573906505794
Validation loss: 2.5896698950857737

Epoch: 82| Step: 0
Training loss: 2.9638765187250145
Validation loss: 2.583160704905987

Epoch: 5| Step: 1
Training loss: 2.9821022526935623
Validation loss: 2.5814182441885576

Epoch: 5| Step: 2
Training loss: 2.2798691842547574
Validation loss: 2.5884758385533173

Epoch: 5| Step: 3
Training loss: 2.536857234181189
Validation loss: 2.5922281500677022

Epoch: 5| Step: 4
Training loss: 2.7345160747647785
Validation loss: 2.601413410032223

Epoch: 5| Step: 5
Training loss: 2.777034007209358
Validation loss: 2.602050364986696

Epoch: 5| Step: 6
Training loss: 2.853875546795389
Validation loss: 2.6067099108902703

Epoch: 5| Step: 7
Training loss: 3.275169915603497
Validation loss: 2.604322576634333

Epoch: 5| Step: 8
Training loss: 3.1123857346973964
Validation loss: 2.6172951453473505

Epoch: 5| Step: 9
Training loss: 3.282187191773318
Validation loss: 2.6207114100155806

Epoch: 5| Step: 10
Training loss: 3.4031081802611065
Validation loss: 2.6182201461022836

Epoch: 83| Step: 0
Training loss: 3.4100980808326375
Validation loss: 2.629801090812649

Epoch: 5| Step: 1
Training loss: 2.738570041637665
Validation loss: 2.6159300735425077

Epoch: 5| Step: 2
Training loss: 2.667382283352807
Validation loss: 2.621408626053715

Epoch: 5| Step: 3
Training loss: 3.012121032684369
Validation loss: 2.6125109292408313

Epoch: 5| Step: 4
Training loss: 3.017949448735361
Validation loss: 2.5965367318624137

Epoch: 5| Step: 5
Training loss: 2.9264893025186933
Validation loss: 2.594121962403578

Epoch: 5| Step: 6
Training loss: 2.968433082128302
Validation loss: 2.5966921952748887

Epoch: 5| Step: 7
Training loss: 3.0705418780113685
Validation loss: 2.599258230625267

Epoch: 5| Step: 8
Training loss: 3.061165343640947
Validation loss: 2.610997682422027

Epoch: 5| Step: 9
Training loss: 2.40579714786742
Validation loss: 2.6044407378329386

Epoch: 5| Step: 10
Training loss: 2.8762804579997563
Validation loss: 2.5954343918593956

Epoch: 84| Step: 0
Training loss: 2.839691619786099
Validation loss: 2.596110505675231

Epoch: 5| Step: 1
Training loss: 3.148535942261405
Validation loss: 2.5824736919055167

Epoch: 5| Step: 2
Training loss: 3.151536802793258
Validation loss: 2.587431812938497

Epoch: 5| Step: 3
Training loss: 2.6789088772337837
Validation loss: 2.5634303591266328

Epoch: 5| Step: 4
Training loss: 3.3246671237530907
Validation loss: 2.5590709840823895

Epoch: 5| Step: 5
Training loss: 2.6031216368361565
Validation loss: 2.5590919814238506

Epoch: 5| Step: 6
Training loss: 2.6769951732878408
Validation loss: 2.557951235605131

Epoch: 5| Step: 7
Training loss: 2.650464567812959
Validation loss: 2.5546348706596005

Epoch: 5| Step: 8
Training loss: 3.1155802854583476
Validation loss: 2.5554935061534216

Epoch: 5| Step: 9
Training loss: 2.816438587442214
Validation loss: 2.5576555503490876

Epoch: 5| Step: 10
Training loss: 3.0021492888392523
Validation loss: 2.557645047808303

Epoch: 85| Step: 0
Training loss: 2.644975498136455
Validation loss: 2.562452617480316

Epoch: 5| Step: 1
Training loss: 3.200209616709716
Validation loss: 2.5724652316821084

Epoch: 5| Step: 2
Training loss: 3.0856720242810423
Validation loss: 2.5760896555753656

Epoch: 5| Step: 3
Training loss: 2.7652183276822386
Validation loss: 2.5561412066949165

Epoch: 5| Step: 4
Training loss: 2.6492117591164948
Validation loss: 2.5549088595085947

Epoch: 5| Step: 5
Training loss: 2.604620342155459
Validation loss: 2.556710163932653

Epoch: 5| Step: 6
Training loss: 3.3491741642832844
Validation loss: 2.555518914774911

Epoch: 5| Step: 7
Training loss: 2.7080341369471945
Validation loss: 2.561363670577165

Epoch: 5| Step: 8
Training loss: 3.1483885806237533
Validation loss: 2.5582366681659883

Epoch: 5| Step: 9
Training loss: 2.947986795155158
Validation loss: 2.55367045839351

Epoch: 5| Step: 10
Training loss: 2.9360953685956406
Validation loss: 2.552425309541212

Epoch: 86| Step: 0
Training loss: 2.2865841308838526
Validation loss: 2.5546773244431793

Epoch: 5| Step: 1
Training loss: 2.7823972586062737
Validation loss: 2.5635511001868228

Epoch: 5| Step: 2
Training loss: 3.258071120720562
Validation loss: 2.595099405408049

Epoch: 5| Step: 3
Training loss: 3.005178273985598
Validation loss: 2.6437626581823044

Epoch: 5| Step: 4
Training loss: 2.7549485851551103
Validation loss: 2.7154150945251136

Epoch: 5| Step: 5
Training loss: 2.307211318385897
Validation loss: 2.830893621299518

Epoch: 5| Step: 6
Training loss: 3.2874685307726237
Validation loss: 2.807936581514408

Epoch: 5| Step: 7
Training loss: 2.8292520711496336
Validation loss: 2.620385743198864

Epoch: 5| Step: 8
Training loss: 3.484364462524355
Validation loss: 2.561328024669496

Epoch: 5| Step: 9
Training loss: 3.0283177931503547
Validation loss: 2.5577791008133137

Epoch: 5| Step: 10
Training loss: 3.2179819320256833
Validation loss: 2.5596313461773748

Epoch: 87| Step: 0
Training loss: 3.389880261177322
Validation loss: 2.5783844758509296

Epoch: 5| Step: 1
Training loss: 3.2192262463870485
Validation loss: 2.5688149978745383

Epoch: 5| Step: 2
Training loss: 2.091168876574827
Validation loss: 2.5643511372941035

Epoch: 5| Step: 3
Training loss: 2.6149284975914484
Validation loss: 2.567381112980246

Epoch: 5| Step: 4
Training loss: 3.386656517504205
Validation loss: 2.566093688132799

Epoch: 5| Step: 5
Training loss: 2.3881004816637135
Validation loss: 2.56483479962478

Epoch: 5| Step: 6
Training loss: 2.677872290422883
Validation loss: 2.5673096412647065

Epoch: 5| Step: 7
Training loss: 3.3369196355034676
Validation loss: 2.561585388914407

Epoch: 5| Step: 8
Training loss: 3.2922865046608525
Validation loss: 2.5591150828084306

Epoch: 5| Step: 9
Training loss: 2.84238895920709
Validation loss: 2.55658657785477

Epoch: 5| Step: 10
Training loss: 2.9379369532479362
Validation loss: 2.5678701488091447

Epoch: 88| Step: 0
Training loss: 2.7854107369982977
Validation loss: 2.581824041563174

Epoch: 5| Step: 1
Training loss: 2.6897731305285544
Validation loss: 2.603253829610958

Epoch: 5| Step: 2
Training loss: 3.0738498800896488
Validation loss: 2.6430333283441105

Epoch: 5| Step: 3
Training loss: 3.0728510100683577
Validation loss: 2.701850895752226

Epoch: 5| Step: 4
Training loss: 3.0905446102845984
Validation loss: 2.680802243192215

Epoch: 5| Step: 5
Training loss: 2.529039430219646
Validation loss: 2.647910851711758

Epoch: 5| Step: 6
Training loss: 2.8156938855617706
Validation loss: 2.632548558064551

Epoch: 5| Step: 7
Training loss: 2.1638008262443007
Validation loss: 2.609219188875737

Epoch: 5| Step: 8
Training loss: 3.287848241659074
Validation loss: 2.577716730182523

Epoch: 5| Step: 9
Training loss: 3.381396695549178
Validation loss: 2.5667810382885343

Epoch: 5| Step: 10
Training loss: 3.2164680762252216
Validation loss: 2.5535823672875786

Epoch: 89| Step: 0
Training loss: 2.507507971221333
Validation loss: 2.5558901529937947

Epoch: 5| Step: 1
Training loss: 2.9797682432647905
Validation loss: 2.5643433184491387

Epoch: 5| Step: 2
Training loss: 3.558365413571786
Validation loss: 2.5654354724564064

Epoch: 5| Step: 3
Training loss: 2.733566862302792
Validation loss: 2.5674278583502805

Epoch: 5| Step: 4
Training loss: 3.005231904588064
Validation loss: 2.559535706321784

Epoch: 5| Step: 5
Training loss: 2.796209842289505
Validation loss: 2.5621575647707906

Epoch: 5| Step: 6
Training loss: 2.9176237624982817
Validation loss: 2.552828037749833

Epoch: 5| Step: 7
Training loss: 2.8277936709727007
Validation loss: 2.547773847688355

Epoch: 5| Step: 8
Training loss: 3.372841179898172
Validation loss: 2.553181581503696

Epoch: 5| Step: 9
Training loss: 2.8426053604555324
Validation loss: 2.547918737339538

Epoch: 5| Step: 10
Training loss: 2.4766694536189147
Validation loss: 2.554505032264848

Epoch: 90| Step: 0
Training loss: 3.0306471392294307
Validation loss: 2.5579260024819432

Epoch: 5| Step: 1
Training loss: 2.9963738460989706
Validation loss: 2.5649709226037207

Epoch: 5| Step: 2
Training loss: 3.312458253993285
Validation loss: 2.5609682638932583

Epoch: 5| Step: 3
Training loss: 2.713861916376673
Validation loss: 2.5464110166656573

Epoch: 5| Step: 4
Training loss: 2.834168778459554
Validation loss: 2.54739400866379

Epoch: 5| Step: 5
Training loss: 3.412506377385367
Validation loss: 2.5488366864530954

Epoch: 5| Step: 6
Training loss: 2.793338351036548
Validation loss: 2.5559838916738866

Epoch: 5| Step: 7
Training loss: 2.4165835749931674
Validation loss: 2.56143373184658

Epoch: 5| Step: 8
Training loss: 3.0506952837800005
Validation loss: 2.586523990008306

Epoch: 5| Step: 9
Training loss: 2.750769334164363
Validation loss: 2.6500865126945397

Epoch: 5| Step: 10
Training loss: 2.6113964177447957
Validation loss: 2.6383965677600245

Epoch: 91| Step: 0
Training loss: 3.108370824865574
Validation loss: 2.6239275423757427

Epoch: 5| Step: 1
Training loss: 2.7442548734835888
Validation loss: 2.5716719844835096

Epoch: 5| Step: 2
Training loss: 2.9898442986305676
Validation loss: 2.548750199568766

Epoch: 5| Step: 3
Training loss: 3.462686548819569
Validation loss: 2.5381086104061708

Epoch: 5| Step: 4
Training loss: 3.1108980522164624
Validation loss: 2.5416953597793452

Epoch: 5| Step: 5
Training loss: 3.1741557823656192
Validation loss: 2.5359232978498176

Epoch: 5| Step: 6
Training loss: 3.252926462584712
Validation loss: 2.5382423619870687

Epoch: 5| Step: 7
Training loss: 2.6632836061815808
Validation loss: 2.5396693890323014

Epoch: 5| Step: 8
Training loss: 2.001940501103491
Validation loss: 2.5485609483524407

Epoch: 5| Step: 9
Training loss: 2.1013325278228985
Validation loss: 2.558252896322394

Epoch: 5| Step: 10
Training loss: 3.0756478968424785
Validation loss: 2.5636384297493873

Epoch: 92| Step: 0
Training loss: 2.960726687694437
Validation loss: 2.5670883274496332

Epoch: 5| Step: 1
Training loss: 3.171423518178049
Validation loss: 2.5812866145969062

Epoch: 5| Step: 2
Training loss: 2.7877330015504262
Validation loss: 2.5729946257350425

Epoch: 5| Step: 3
Training loss: 2.5921719817926663
Validation loss: 2.5692803144669267

Epoch: 5| Step: 4
Training loss: 2.354292492049906
Validation loss: 2.567687664378529

Epoch: 5| Step: 5
Training loss: 3.19354960490353
Validation loss: 2.553176359694618

Epoch: 5| Step: 6
Training loss: 3.26849574892708
Validation loss: 2.535787356487043

Epoch: 5| Step: 7
Training loss: 3.232918084081146
Validation loss: 2.5343239593899405

Epoch: 5| Step: 8
Training loss: 2.8198397337911913
Validation loss: 2.534249143739104

Epoch: 5| Step: 9
Training loss: 2.8764318135012634
Validation loss: 2.5300176875159144

Epoch: 5| Step: 10
Training loss: 2.462533294142835
Validation loss: 2.525490875801053

Epoch: 93| Step: 0
Training loss: 2.964340468802129
Validation loss: 2.5308636393648665

Epoch: 5| Step: 1
Training loss: 3.3856974010954772
Validation loss: 2.5287053108707953

Epoch: 5| Step: 2
Training loss: 3.0983831988571797
Validation loss: 2.526143803935081

Epoch: 5| Step: 3
Training loss: 2.200784617006044
Validation loss: 2.5323435888340837

Epoch: 5| Step: 4
Training loss: 2.7051206950339437
Validation loss: 2.5500403605931945

Epoch: 5| Step: 5
Training loss: 2.9015395846101377
Validation loss: 2.561357676246134

Epoch: 5| Step: 6
Training loss: 2.763569040710479
Validation loss: 2.583235084486082

Epoch: 5| Step: 7
Training loss: 2.631424082164506
Validation loss: 2.5707344770774796

Epoch: 5| Step: 8
Training loss: 3.2874216802862564
Validation loss: 2.557948536613931

Epoch: 5| Step: 9
Training loss: 2.9263470539356957
Validation loss: 2.5448497533799905

Epoch: 5| Step: 10
Training loss: 2.830749979559718
Validation loss: 2.5364339601214447

Epoch: 94| Step: 0
Training loss: 3.2578091335507935
Validation loss: 2.523652243625837

Epoch: 5| Step: 1
Training loss: 2.8082387219649716
Validation loss: 2.520710833251185

Epoch: 5| Step: 2
Training loss: 3.1240634277684274
Validation loss: 2.5229943268317228

Epoch: 5| Step: 3
Training loss: 3.2089374188210895
Validation loss: 2.5243326403570214

Epoch: 5| Step: 4
Training loss: 2.7129872073509222
Validation loss: 2.526684453685008

Epoch: 5| Step: 5
Training loss: 2.9768316192317315
Validation loss: 2.5307009076206763

Epoch: 5| Step: 6
Training loss: 2.646001635227289
Validation loss: 2.5343352019300744

Epoch: 5| Step: 7
Training loss: 2.494079828081446
Validation loss: 2.5349244277620238

Epoch: 5| Step: 8
Training loss: 2.8131672385603697
Validation loss: 2.536251368866578

Epoch: 5| Step: 9
Training loss: 2.9521980243623274
Validation loss: 2.5334524470188162

Epoch: 5| Step: 10
Training loss: 3.0671667237241285
Validation loss: 2.529355776394706

Epoch: 95| Step: 0
Training loss: 3.237274050100124
Validation loss: 2.5297748394858894

Epoch: 5| Step: 1
Training loss: 2.8606562844470815
Validation loss: 2.5279692395867284

Epoch: 5| Step: 2
Training loss: 2.6159841931183414
Validation loss: 2.516722796093377

Epoch: 5| Step: 3
Training loss: 3.019137219853899
Validation loss: 2.5160888629425116

Epoch: 5| Step: 4
Training loss: 3.3825917513316264
Validation loss: 2.511050053556976

Epoch: 5| Step: 5
Training loss: 2.467342313387152
Validation loss: 2.5167351909039954

Epoch: 5| Step: 6
Training loss: 3.380466837273046
Validation loss: 2.534942244268846

Epoch: 5| Step: 7
Training loss: 2.195033154074296
Validation loss: 2.5851123091613792

Epoch: 5| Step: 8
Training loss: 3.2002017196018406
Validation loss: 2.6537233992806604

Epoch: 5| Step: 9
Training loss: 2.8201422388985327
Validation loss: 2.642747831908959

Epoch: 5| Step: 10
Training loss: 2.69973312754445
Validation loss: 2.566021203465968

Epoch: 96| Step: 0
Training loss: 2.482039499434227
Validation loss: 2.52309163479461

Epoch: 5| Step: 1
Training loss: 2.816886786788951
Validation loss: 2.512200988509059

Epoch: 5| Step: 2
Training loss: 2.852687833119842
Validation loss: 2.515586766623953

Epoch: 5| Step: 3
Training loss: 2.88187300096888
Validation loss: 2.5188077576752845

Epoch: 5| Step: 4
Training loss: 3.0746444930837287
Validation loss: 2.5229554643761682

Epoch: 5| Step: 5
Training loss: 3.1811457109125976
Validation loss: 2.5201038785568213

Epoch: 5| Step: 6
Training loss: 2.520977320906885
Validation loss: 2.5174386644327944

Epoch: 5| Step: 7
Training loss: 2.5618523500348154
Validation loss: 2.5176735294146773

Epoch: 5| Step: 8
Training loss: 3.5180189332002563
Validation loss: 2.514632732319615

Epoch: 5| Step: 9
Training loss: 2.954588189516249
Validation loss: 2.5118136451730915

Epoch: 5| Step: 10
Training loss: 2.8772401789498354
Validation loss: 2.510259960826846

Epoch: 97| Step: 0
Training loss: 2.8851413159328665
Validation loss: 2.5124406970731195

Epoch: 5| Step: 1
Training loss: 1.8722800553719008
Validation loss: 2.512718097181778

Epoch: 5| Step: 2
Training loss: 3.235793829896263
Validation loss: 2.524354609107109

Epoch: 5| Step: 3
Training loss: 3.1778691221623294
Validation loss: 2.533943180692224

Epoch: 5| Step: 4
Training loss: 3.2379412317250265
Validation loss: 2.5278049523726955

Epoch: 5| Step: 5
Training loss: 3.1258845793929315
Validation loss: 2.5351830344598567

Epoch: 5| Step: 6
Training loss: 2.2856235124240505
Validation loss: 2.529744702193907

Epoch: 5| Step: 7
Training loss: 2.5766168055412617
Validation loss: 2.5309671507019327

Epoch: 5| Step: 8
Training loss: 2.922500298649338
Validation loss: 2.520094904133922

Epoch: 5| Step: 9
Training loss: 2.400147663977974
Validation loss: 2.525507079884216

Epoch: 5| Step: 10
Training loss: 3.638067042667823
Validation loss: 2.5347474229606584

Epoch: 98| Step: 0
Training loss: 2.177265421235559
Validation loss: 2.561375717248429

Epoch: 5| Step: 1
Training loss: 3.045446285873248
Validation loss: 2.5791046677707037

Epoch: 5| Step: 2
Training loss: 2.7308331902598706
Validation loss: 2.587849032098172

Epoch: 5| Step: 3
Training loss: 3.2036629573980613
Validation loss: 2.5795308813951543

Epoch: 5| Step: 4
Training loss: 3.0001846892409247
Validation loss: 2.550579855883678

Epoch: 5| Step: 5
Training loss: 3.2621581735251097
Validation loss: 2.533228370610978

Epoch: 5| Step: 6
Training loss: 2.6687435963037927
Validation loss: 2.526069705064545

Epoch: 5| Step: 7
Training loss: 3.2213869126592427
Validation loss: 2.518165902580639

Epoch: 5| Step: 8
Training loss: 2.6496001535733495
Validation loss: 2.5268980001720656

Epoch: 5| Step: 9
Training loss: 2.6605460039651803
Validation loss: 2.5307671417952973

Epoch: 5| Step: 10
Training loss: 2.860710124173853
Validation loss: 2.525947723485511

Epoch: 99| Step: 0
Training loss: 2.7998955468721998
Validation loss: 2.5236009297032047

Epoch: 5| Step: 1
Training loss: 3.2560849080180105
Validation loss: 2.5268496142380945

Epoch: 5| Step: 2
Training loss: 2.68367406289029
Validation loss: 2.5223965128387116

Epoch: 5| Step: 3
Training loss: 2.7437513625156784
Validation loss: 2.5214591561801067

Epoch: 5| Step: 4
Training loss: 3.1961977602106364
Validation loss: 2.51896647744906

Epoch: 5| Step: 5
Training loss: 3.0338617458439843
Validation loss: 2.5213463033448504

Epoch: 5| Step: 6
Training loss: 3.1221291134105367
Validation loss: 2.5244263454128992

Epoch: 5| Step: 7
Training loss: 2.188236766446129
Validation loss: 2.5287285758018343

Epoch: 5| Step: 8
Training loss: 2.585434141466307
Validation loss: 2.532692242506327

Epoch: 5| Step: 9
Training loss: 3.156721476475475
Validation loss: 2.5458875601983393

Epoch: 5| Step: 10
Training loss: 2.64922624844002
Validation loss: 2.5449645764345314

Epoch: 100| Step: 0
Training loss: 2.912975446016784
Validation loss: 2.545989095312926

Epoch: 5| Step: 1
Training loss: 2.486526517302065
Validation loss: 2.548607171828577

Epoch: 5| Step: 2
Training loss: 2.649863070423109
Validation loss: 2.56107861254719

Epoch: 5| Step: 3
Training loss: 2.951611004618157
Validation loss: 2.5611352275012824

Epoch: 5| Step: 4
Training loss: 3.1881509751931447
Validation loss: 2.5941691756104333

Epoch: 5| Step: 5
Training loss: 2.846989557534493
Validation loss: 2.5589461104557363

Epoch: 5| Step: 6
Training loss: 2.8200620080339536
Validation loss: 2.542222270088321

Epoch: 5| Step: 7
Training loss: 2.838203470690577
Validation loss: 2.5322548054246403

Epoch: 5| Step: 8
Training loss: 3.235517217216257
Validation loss: 2.5180274305772627

Epoch: 5| Step: 9
Training loss: 2.488298592739062
Validation loss: 2.5106783208733345

Epoch: 5| Step: 10
Training loss: 3.0347428795183946
Validation loss: 2.5094320287568372

Epoch: 101| Step: 0
Training loss: 2.5045475607156513
Validation loss: 2.5078468814916186

Epoch: 5| Step: 1
Training loss: 2.2251392835247876
Validation loss: 2.5118342037054067

Epoch: 5| Step: 2
Training loss: 2.7844272424525593
Validation loss: 2.512757011863076

Epoch: 5| Step: 3
Training loss: 2.644668102245103
Validation loss: 2.522686664408357

Epoch: 5| Step: 4
Training loss: 2.8116838754588214
Validation loss: 2.5126066265766385

Epoch: 5| Step: 5
Training loss: 2.946828113235497
Validation loss: 2.520080865639081

Epoch: 5| Step: 6
Training loss: 3.1676972034128776
Validation loss: 2.5177404423166423

Epoch: 5| Step: 7
Training loss: 3.3718559314093146
Validation loss: 2.530688670357214

Epoch: 5| Step: 8
Training loss: 2.880885361376441
Validation loss: 2.5393603855820497

Epoch: 5| Step: 9
Training loss: 3.3070463955661036
Validation loss: 2.557584101548807

Epoch: 5| Step: 10
Training loss: 2.7040604753221067
Validation loss: 2.554896138147998

Epoch: 102| Step: 0
Training loss: 2.345403164528629
Validation loss: 2.533044976967111

Epoch: 5| Step: 1
Training loss: 2.896857229299677
Validation loss: 2.5117935641327547

Epoch: 5| Step: 2
Training loss: 3.3921882084688058
Validation loss: 2.515600277847943

Epoch: 5| Step: 3
Training loss: 3.1874266971312393
Validation loss: 2.5140712686005924

Epoch: 5| Step: 4
Training loss: 2.725179326867578
Validation loss: 2.507957233766614

Epoch: 5| Step: 5
Training loss: 3.2982997617961516
Validation loss: 2.5176997728354262

Epoch: 5| Step: 6
Training loss: 2.91445175721009
Validation loss: 2.523893374513494

Epoch: 5| Step: 7
Training loss: 2.072298529648633
Validation loss: 2.5089247327054793

Epoch: 5| Step: 8
Training loss: 2.360854840551515
Validation loss: 2.505192932595959

Epoch: 5| Step: 9
Training loss: 2.6627035394515044
Validation loss: 2.5009249186284266

Epoch: 5| Step: 10
Training loss: 3.3830116689076513
Validation loss: 2.5026371695367993

Epoch: 103| Step: 0
Training loss: 2.5852733116356794
Validation loss: 2.501923610641927

Epoch: 5| Step: 1
Training loss: 2.052856325543206
Validation loss: 2.497750618819433

Epoch: 5| Step: 2
Training loss: 2.7152361908633424
Validation loss: 2.5021629574996345

Epoch: 5| Step: 3
Training loss: 3.4313925847235267
Validation loss: 2.506807613750888

Epoch: 5| Step: 4
Training loss: 2.7571108522541183
Validation loss: 2.5248591781256966

Epoch: 5| Step: 5
Training loss: 3.22642550050593
Validation loss: 2.5273608551230144

Epoch: 5| Step: 6
Training loss: 2.5667112218614396
Validation loss: 2.5465636046320594

Epoch: 5| Step: 7
Training loss: 2.8339705779083513
Validation loss: 2.5562621476312275

Epoch: 5| Step: 8
Training loss: 2.7611458924795853
Validation loss: 2.564547843231374

Epoch: 5| Step: 9
Training loss: 3.662833782518581
Validation loss: 2.594692487457154

Epoch: 5| Step: 10
Training loss: 2.54083143383275
Validation loss: 2.5609797953879

Epoch: 104| Step: 0
Training loss: 2.518259031847827
Validation loss: 2.540090376396135

Epoch: 5| Step: 1
Training loss: 3.080708615171879
Validation loss: 2.5330376874604448

Epoch: 5| Step: 2
Training loss: 2.9159642781606205
Validation loss: 2.520189394394235

Epoch: 5| Step: 3
Training loss: 2.809963863045412
Validation loss: 2.525593946533636

Epoch: 5| Step: 4
Training loss: 2.6435951818853156
Validation loss: 2.5188014096533906

Epoch: 5| Step: 5
Training loss: 2.9164660975203947
Validation loss: 2.5147825315846246

Epoch: 5| Step: 6
Training loss: 2.5675493130503
Validation loss: 2.5300462778273594

Epoch: 5| Step: 7
Training loss: 3.1530258783161065
Validation loss: 2.5276975599452993

Epoch: 5| Step: 8
Training loss: 3.2760611059989797
Validation loss: 2.536344911545513

Epoch: 5| Step: 9
Training loss: 2.872613828842255
Validation loss: 2.552599055752428

Epoch: 5| Step: 10
Training loss: 2.393451391175548
Validation loss: 2.557325386787599

Epoch: 105| Step: 0
Training loss: 2.688867088190962
Validation loss: 2.56117716113945

Epoch: 5| Step: 1
Training loss: 2.77160257164055
Validation loss: 2.58150133266368

Epoch: 5| Step: 2
Training loss: 2.7261989755591207
Validation loss: 2.551703352492003

Epoch: 5| Step: 3
Training loss: 2.3906515282050376
Validation loss: 2.539364320849966

Epoch: 5| Step: 4
Training loss: 2.835160246126455
Validation loss: 2.537894011169512

Epoch: 5| Step: 5
Training loss: 2.9998540842810235
Validation loss: 2.532894718814262

Epoch: 5| Step: 6
Training loss: 3.132352038859796
Validation loss: 2.5375630641091727

Epoch: 5| Step: 7
Training loss: 3.2130296856778906
Validation loss: 2.5343881992035673

Epoch: 5| Step: 8
Training loss: 2.7277141423344307
Validation loss: 2.533564849653573

Epoch: 5| Step: 9
Training loss: 2.921151464299715
Validation loss: 2.534719821735691

Epoch: 5| Step: 10
Training loss: 3.024294394175541
Validation loss: 2.525106458431019

Epoch: 106| Step: 0
Training loss: 2.9934460256669975
Validation loss: 2.509614275925566

Epoch: 5| Step: 1
Training loss: 2.6694673096833874
Validation loss: 2.5050146364740673

Epoch: 5| Step: 2
Training loss: 2.6080969690187303
Validation loss: 2.500661006828321

Epoch: 5| Step: 3
Training loss: 2.8588498159579205
Validation loss: 2.5052203904526658

Epoch: 5| Step: 4
Training loss: 3.301580894263714
Validation loss: 2.5283161177031404

Epoch: 5| Step: 5
Training loss: 2.8639566371767757
Validation loss: 2.570360128604314

Epoch: 5| Step: 6
Training loss: 2.879667722289483
Validation loss: 2.680222448956172

Epoch: 5| Step: 7
Training loss: 2.694312222394726
Validation loss: 2.8261703247535035

Epoch: 5| Step: 8
Training loss: 3.1856305493206736
Validation loss: 2.7661306675463915

Epoch: 5| Step: 9
Training loss: 2.8917799833083415
Validation loss: 2.6054434083467304

Epoch: 5| Step: 10
Training loss: 2.7055911242187753
Validation loss: 2.5170407350601214

Epoch: 107| Step: 0
Training loss: 2.9314037941480704
Validation loss: 2.495508722936125

Epoch: 5| Step: 1
Training loss: 3.2310861276654466
Validation loss: 2.511926001117671

Epoch: 5| Step: 2
Training loss: 2.6252780040485733
Validation loss: 2.5073927968117293

Epoch: 5| Step: 3
Training loss: 2.889793812613444
Validation loss: 2.5185763615837273

Epoch: 5| Step: 4
Training loss: 2.499996948240325
Validation loss: 2.5186631619106974

Epoch: 5| Step: 5
Training loss: 2.925991157773908
Validation loss: 2.5274608005691426

Epoch: 5| Step: 6
Training loss: 3.0146387889078667
Validation loss: 2.532859591286771

Epoch: 5| Step: 7
Training loss: 2.7610938243294973
Validation loss: 2.5362321524918316

Epoch: 5| Step: 8
Training loss: 2.9754298500659657
Validation loss: 2.5269973440647306

Epoch: 5| Step: 9
Training loss: 2.83414438270513
Validation loss: 2.528052727913162

Epoch: 5| Step: 10
Training loss: 3.2161395403636983
Validation loss: 2.521083773752032

Epoch: 108| Step: 0
Training loss: 2.3526813468802987
Validation loss: 2.5077973101675988

Epoch: 5| Step: 1
Training loss: 2.660601025563627
Validation loss: 2.5071899205555606

Epoch: 5| Step: 2
Training loss: 3.228486971950136
Validation loss: 2.5069520813643997

Epoch: 5| Step: 3
Training loss: 3.581988651600576
Validation loss: 2.5084756679649596

Epoch: 5| Step: 4
Training loss: 2.6784738177724785
Validation loss: 2.51847973320649

Epoch: 5| Step: 5
Training loss: 2.245163275339807
Validation loss: 2.5345069686720727

Epoch: 5| Step: 6
Training loss: 3.035692400813356
Validation loss: 2.541293938101796

Epoch: 5| Step: 7
Training loss: 2.917982803576432
Validation loss: 2.5635022920175743

Epoch: 5| Step: 8
Training loss: 2.485806706390677
Validation loss: 2.5842039908344194

Epoch: 5| Step: 9
Training loss: 3.219989130700763
Validation loss: 2.6209349968618243

Epoch: 5| Step: 10
Training loss: 2.8523555123246758
Validation loss: 2.6052145941835723

Epoch: 109| Step: 0
Training loss: 2.905281643895973
Validation loss: 2.597983771367814

Epoch: 5| Step: 1
Training loss: 3.088875832366183
Validation loss: 2.570754487628254

Epoch: 5| Step: 2
Training loss: 2.8594508760317887
Validation loss: 2.576183945967918

Epoch: 5| Step: 3
Training loss: 2.7902800309399076
Validation loss: 2.5914759743395357

Epoch: 5| Step: 4
Training loss: 2.6853963025970584
Validation loss: 2.597712911561044

Epoch: 5| Step: 5
Training loss: 3.132317939210872
Validation loss: 2.6036708794635057

Epoch: 5| Step: 6
Training loss: 2.7771599516967598
Validation loss: 2.5725022280657384

Epoch: 5| Step: 7
Training loss: 2.9392289288463043
Validation loss: 2.5367459198178897

Epoch: 5| Step: 8
Training loss: 2.5282753313821726
Validation loss: 2.516851086763582

Epoch: 5| Step: 9
Training loss: 2.9205266932133123
Validation loss: 2.513014223137987

Epoch: 5| Step: 10
Training loss: 2.95568397700289
Validation loss: 2.504906240351819

Epoch: 110| Step: 0
Training loss: 2.4948396830759463
Validation loss: 2.5030243412999855

Epoch: 5| Step: 1
Training loss: 2.8345163530896444
Validation loss: 2.506326271753934

Epoch: 5| Step: 2
Training loss: 3.444999421096111
Validation loss: 2.5060585944163916

Epoch: 5| Step: 3
Training loss: 3.2070101366730404
Validation loss: 2.502826018359416

Epoch: 5| Step: 4
Training loss: 2.599407322896581
Validation loss: 2.503262193182193

Epoch: 5| Step: 5
Training loss: 2.7237504596543505
Validation loss: 2.5029215139241394

Epoch: 5| Step: 6
Training loss: 2.473801671472035
Validation loss: 2.5061219987599803

Epoch: 5| Step: 7
Training loss: 3.3295226408496124
Validation loss: 2.500233732597853

Epoch: 5| Step: 8
Training loss: 2.780755502695533
Validation loss: 2.5029152024303807

Epoch: 5| Step: 9
Training loss: 2.8364422141485806
Validation loss: 2.514315415689916

Epoch: 5| Step: 10
Training loss: 2.7537175107087837
Validation loss: 2.5269138381158758

Epoch: 111| Step: 0
Training loss: 2.906622585901472
Validation loss: 2.532480800751745

Epoch: 5| Step: 1
Training loss: 2.757257508365467
Validation loss: 2.560725443274323

Epoch: 5| Step: 2
Training loss: 2.4830754557961474
Validation loss: 2.5870352920785558

Epoch: 5| Step: 3
Training loss: 2.73284782269062
Validation loss: 2.609961091851152

Epoch: 5| Step: 4
Training loss: 3.2128956710636665
Validation loss: 2.6482049717307428

Epoch: 5| Step: 5
Training loss: 2.8890813881569724
Validation loss: 2.645353672175827

Epoch: 5| Step: 6
Training loss: 3.803887943169711
Validation loss: 2.614826144216563

Epoch: 5| Step: 7
Training loss: 2.5848694407919215
Validation loss: 2.568156241847256

Epoch: 5| Step: 8
Training loss: 2.7190577015003075
Validation loss: 2.5229307083770576

Epoch: 5| Step: 9
Training loss: 2.3451844975296963
Validation loss: 2.5146319891119586

Epoch: 5| Step: 10
Training loss: 2.734414410988303
Validation loss: 2.5144536363714205

Epoch: 112| Step: 0
Training loss: 2.7168231142862553
Validation loss: 2.523829228171662

Epoch: 5| Step: 1
Training loss: 3.2475026145495782
Validation loss: 2.513617015121128

Epoch: 5| Step: 2
Training loss: 3.0391669954118967
Validation loss: 2.5024530578710187

Epoch: 5| Step: 3
Training loss: 2.7653677438172526
Validation loss: 2.5004801842775604

Epoch: 5| Step: 4
Training loss: 2.9068409308711227
Validation loss: 2.501415915120557

Epoch: 5| Step: 5
Training loss: 3.1336760056246304
Validation loss: 2.496374764784751

Epoch: 5| Step: 6
Training loss: 2.359548297100807
Validation loss: 2.502658917450036

Epoch: 5| Step: 7
Training loss: 2.973747784877111
Validation loss: 2.5235524978221244

Epoch: 5| Step: 8
Training loss: 3.015142688822531
Validation loss: 2.552942833349951

Epoch: 5| Step: 9
Training loss: 2.6290646826969555
Validation loss: 2.5961136172634256

Epoch: 5| Step: 10
Training loss: 2.5750659711960706
Validation loss: 2.6467240216464103

Epoch: 113| Step: 0
Training loss: 3.158914630978968
Validation loss: 2.721145214111973

Epoch: 5| Step: 1
Training loss: 2.744825002237431
Validation loss: 2.661090734095887

Epoch: 5| Step: 2
Training loss: 3.316835409373449
Validation loss: 2.700937285266533

Epoch: 5| Step: 3
Training loss: 3.080318076318409
Validation loss: 2.615994799538068

Epoch: 5| Step: 4
Training loss: 2.755105394677091
Validation loss: 2.52422125203331

Epoch: 5| Step: 5
Training loss: 2.7833052338725524
Validation loss: 2.497254026949588

Epoch: 5| Step: 6
Training loss: 2.521887051956516
Validation loss: 2.4921603614578576

Epoch: 5| Step: 7
Training loss: 2.726430545444817
Validation loss: 2.5034631717176508

Epoch: 5| Step: 8
Training loss: 3.067211652787927
Validation loss: 2.522832590412411

Epoch: 5| Step: 9
Training loss: 3.076782243513347
Validation loss: 2.523759743180445

Epoch: 5| Step: 10
Training loss: 2.676989206126315
Validation loss: 2.515615347189789

Epoch: 114| Step: 0
Training loss: 2.888500030543991
Validation loss: 2.5101883946619092

Epoch: 5| Step: 1
Training loss: 2.9971027689469367
Validation loss: 2.5024390761241775

Epoch: 5| Step: 2
Training loss: 3.017907420341768
Validation loss: 2.5035185961198914

Epoch: 5| Step: 3
Training loss: 2.5547893165574043
Validation loss: 2.5044384360195924

Epoch: 5| Step: 4
Training loss: 3.1008690508048318
Validation loss: 2.4943860979931203

Epoch: 5| Step: 5
Training loss: 2.871051232678383
Validation loss: 2.4961764732604617

Epoch: 5| Step: 6
Training loss: 2.776992968848795
Validation loss: 2.4852874353682184

Epoch: 5| Step: 7
Training loss: 2.8894089898996795
Validation loss: 2.483719022806134

Epoch: 5| Step: 8
Training loss: 2.6822119741113233
Validation loss: 2.4930899438462886

Epoch: 5| Step: 9
Training loss: 2.7710152377505
Validation loss: 2.5151566665841374

Epoch: 5| Step: 10
Training loss: 2.9410276941930102
Validation loss: 2.525831770012712

Epoch: 115| Step: 0
Training loss: 3.0604624295345912
Validation loss: 2.6231874271863784

Epoch: 5| Step: 1
Training loss: 2.9354521735493835
Validation loss: 2.6154546533931997

Epoch: 5| Step: 2
Training loss: 2.7035318410249567
Validation loss: 2.555643222573448

Epoch: 5| Step: 3
Training loss: 2.7811445580543652
Validation loss: 2.5603285592443195

Epoch: 5| Step: 4
Training loss: 2.7386838260597175
Validation loss: 2.558883103303105

Epoch: 5| Step: 5
Training loss: 2.9796624649188357
Validation loss: 2.555691914006556

Epoch: 5| Step: 6
Training loss: 3.2067485875261683
Validation loss: 2.551861582387365

Epoch: 5| Step: 7
Training loss: 2.8112706358590263
Validation loss: 2.5267874919634585

Epoch: 5| Step: 8
Training loss: 2.2715935324158836
Validation loss: 2.498421082220839

Epoch: 5| Step: 9
Training loss: 2.620557568167243
Validation loss: 2.4950939954969757

Epoch: 5| Step: 10
Training loss: 3.0892973946083573
Validation loss: 2.4857033720035697

Epoch: 116| Step: 0
Training loss: 2.9868451027133194
Validation loss: 2.48286212682665

Epoch: 5| Step: 1
Training loss: 2.863051422179651
Validation loss: 2.4799889164115263

Epoch: 5| Step: 2
Training loss: 2.6642527582240745
Validation loss: 2.498089348379523

Epoch: 5| Step: 3
Training loss: 2.569853303930624
Validation loss: 2.499995425435465

Epoch: 5| Step: 4
Training loss: 2.65517610271213
Validation loss: 2.51497553560826

Epoch: 5| Step: 5
Training loss: 3.4337940005776875
Validation loss: 2.5272702158238176

Epoch: 5| Step: 6
Training loss: 2.7180907228386966
Validation loss: 2.5512491262021952

Epoch: 5| Step: 7
Training loss: 2.6944240709126643
Validation loss: 2.51974086196385

Epoch: 5| Step: 8
Training loss: 2.6769067332479666
Validation loss: 2.5057642123872483

Epoch: 5| Step: 9
Training loss: 2.9761068641180195
Validation loss: 2.4926507384098135

Epoch: 5| Step: 10
Training loss: 2.8436356406220913
Validation loss: 2.4983599851710943

Epoch: 117| Step: 0
Training loss: 2.2822376360316503
Validation loss: 2.4979796583005114

Epoch: 5| Step: 1
Training loss: 2.529902346690295
Validation loss: 2.5166803356626057

Epoch: 5| Step: 2
Training loss: 2.521626676035181
Validation loss: 2.5325567229255035

Epoch: 5| Step: 3
Training loss: 3.005085449527178
Validation loss: 2.518920957817057

Epoch: 5| Step: 4
Training loss: 2.865644075918821
Validation loss: 2.5287464379896787

Epoch: 5| Step: 5
Training loss: 2.9774801286599617
Validation loss: 2.5252679598781893

Epoch: 5| Step: 6
Training loss: 2.54927287112978
Validation loss: 2.5320671116794347

Epoch: 5| Step: 7
Training loss: 2.9626335983090435
Validation loss: 2.5437859734161923

Epoch: 5| Step: 8
Training loss: 3.263843981566941
Validation loss: 2.558240163531581

Epoch: 5| Step: 9
Training loss: 2.8080451440143825
Validation loss: 2.559652471628523

Epoch: 5| Step: 10
Training loss: 3.046316398864331
Validation loss: 2.5449934979640254

Epoch: 118| Step: 0
Training loss: 3.0476167216178554
Validation loss: 2.5165008383803595

Epoch: 5| Step: 1
Training loss: 2.9262030059417308
Validation loss: 2.5122741239337922

Epoch: 5| Step: 2
Training loss: 2.6173934627737854
Validation loss: 2.4976058273380697

Epoch: 5| Step: 3
Training loss: 2.662409563274814
Validation loss: 2.498170529873158

Epoch: 5| Step: 4
Training loss: 2.853686568448754
Validation loss: 2.4949772318096826

Epoch: 5| Step: 5
Training loss: 2.808472865531334
Validation loss: 2.497540929873768

Epoch: 5| Step: 6
Training loss: 3.2727332620854916
Validation loss: 2.4907076292921535

Epoch: 5| Step: 7
Training loss: 2.6949715661298796
Validation loss: 2.4835232403018628

Epoch: 5| Step: 8
Training loss: 2.7700741428133924
Validation loss: 2.4870480633155103

Epoch: 5| Step: 9
Training loss: 2.4149903918404902
Validation loss: 2.4839898505684936

Epoch: 5| Step: 10
Training loss: 2.7359497767183334
Validation loss: 2.4820482096677066

Epoch: 119| Step: 0
Training loss: 3.186943155155789
Validation loss: 2.4869639251831233

Epoch: 5| Step: 1
Training loss: 2.923514655770496
Validation loss: 2.4900942581202377

Epoch: 5| Step: 2
Training loss: 2.9710104919371596
Validation loss: 2.49190356347

Epoch: 5| Step: 3
Training loss: 2.239111621474926
Validation loss: 2.524266738037582

Epoch: 5| Step: 4
Training loss: 2.2538470123281367
Validation loss: 2.574000021189639

Epoch: 5| Step: 5
Training loss: 2.6706683016140538
Validation loss: 2.6161413681528747

Epoch: 5| Step: 6
Training loss: 2.587496008386159
Validation loss: 2.6230689210409426

Epoch: 5| Step: 7
Training loss: 2.4475676159193376
Validation loss: 2.558396307704054

Epoch: 5| Step: 8
Training loss: 3.1128814708619634
Validation loss: 2.5233366708089564

Epoch: 5| Step: 9
Training loss: 3.298020584162502
Validation loss: 2.4908217123010266

Epoch: 5| Step: 10
Training loss: 3.020664096344838
Validation loss: 2.4949271222067715

Epoch: 120| Step: 0
Training loss: 2.8547285506079647
Validation loss: 2.486003397526206

Epoch: 5| Step: 1
Training loss: 2.9480810939551247
Validation loss: 2.4908106850539005

Epoch: 5| Step: 2
Training loss: 2.5883605300086936
Validation loss: 2.4891053987565157

Epoch: 5| Step: 3
Training loss: 2.7584003113819486
Validation loss: 2.4916191768479634

Epoch: 5| Step: 4
Training loss: 2.4739200200912124
Validation loss: 2.502278301935276

Epoch: 5| Step: 5
Training loss: 2.9678778722575885
Validation loss: 2.5091656482575524

Epoch: 5| Step: 6
Training loss: 3.046654952490704
Validation loss: 2.5074159384489114

Epoch: 5| Step: 7
Training loss: 2.368007001879367
Validation loss: 2.5063559531582698

Epoch: 5| Step: 8
Training loss: 3.4292653721215043
Validation loss: 2.5240111752155694

Epoch: 5| Step: 9
Training loss: 2.8457555720222705
Validation loss: 2.519660022901475

Epoch: 5| Step: 10
Training loss: 2.2863624454166325
Validation loss: 2.524268379243663

Epoch: 121| Step: 0
Training loss: 2.405534117585768
Validation loss: 2.5208184867170154

Epoch: 5| Step: 1
Training loss: 2.71893941285232
Validation loss: 2.513910892628754

Epoch: 5| Step: 2
Training loss: 2.614424884346673
Validation loss: 2.5186190088933693

Epoch: 5| Step: 3
Training loss: 2.9085693948542155
Validation loss: 2.507604328212694

Epoch: 5| Step: 4
Training loss: 2.634677848739421
Validation loss: 2.4895404999574633

Epoch: 5| Step: 5
Training loss: 2.757336626789972
Validation loss: 2.4860679238272656

Epoch: 5| Step: 6
Training loss: 3.0263421352121362
Validation loss: 2.477145725852921

Epoch: 5| Step: 7
Training loss: 2.575720943523628
Validation loss: 2.482513244036424

Epoch: 5| Step: 8
Training loss: 3.3392843212943673
Validation loss: 2.5003700074827644

Epoch: 5| Step: 9
Training loss: 2.7521515145953632
Validation loss: 2.5216944640762535

Epoch: 5| Step: 10
Training loss: 2.9599567490072642
Validation loss: 2.507156038251948

Epoch: 122| Step: 0
Training loss: 2.582973106453985
Validation loss: 2.514646202792879

Epoch: 5| Step: 1
Training loss: 2.9409706228813097
Validation loss: 2.5024390853442884

Epoch: 5| Step: 2
Training loss: 2.980490988152211
Validation loss: 2.4927200785739183

Epoch: 5| Step: 3
Training loss: 2.7772698372449964
Validation loss: 2.469166311560173

Epoch: 5| Step: 4
Training loss: 2.604671876857062
Validation loss: 2.48032145509772

Epoch: 5| Step: 5
Training loss: 2.59387473300537
Validation loss: 2.480291106581119

Epoch: 5| Step: 6
Training loss: 3.1840733079186783
Validation loss: 2.4840753392246557

Epoch: 5| Step: 7
Training loss: 2.946267860950813
Validation loss: 2.4778271064659227

Epoch: 5| Step: 8
Training loss: 2.3439735814581466
Validation loss: 2.471747070734065

Epoch: 5| Step: 9
Training loss: 2.9115091955192693
Validation loss: 2.476992782107459

Epoch: 5| Step: 10
Training loss: 2.6699126772941884
Validation loss: 2.4958474290953627

Epoch: 123| Step: 0
Training loss: 2.7522911584330196
Validation loss: 2.512313029165164

Epoch: 5| Step: 1
Training loss: 2.4417471441691805
Validation loss: 2.5181548627281964

Epoch: 5| Step: 2
Training loss: 2.2333380153474076
Validation loss: 2.522817697300518

Epoch: 5| Step: 3
Training loss: 3.1359733180351235
Validation loss: 2.5097913719437632

Epoch: 5| Step: 4
Training loss: 2.489821791035845
Validation loss: 2.5052313880421555

Epoch: 5| Step: 5
Training loss: 2.6368657728107436
Validation loss: 2.531418171264798

Epoch: 5| Step: 6
Training loss: 3.166051319634148
Validation loss: 2.5230027066798204

Epoch: 5| Step: 7
Training loss: 2.8998084103667083
Validation loss: 2.5512836207013394

Epoch: 5| Step: 8
Training loss: 3.3287172462149774
Validation loss: 2.5976069388102885

Epoch: 5| Step: 9
Training loss: 2.5444584715159024
Validation loss: 2.58168254476765

Epoch: 5| Step: 10
Training loss: 2.8193222378542284
Validation loss: 2.547120951670724

Epoch: 124| Step: 0
Training loss: 2.8178501528284228
Validation loss: 2.5216928811764303

Epoch: 5| Step: 1
Training loss: 2.9326968593489933
Validation loss: 2.504494445843625

Epoch: 5| Step: 2
Training loss: 2.032480776650149
Validation loss: 2.4994040937753885

Epoch: 5| Step: 3
Training loss: 2.765889559231085
Validation loss: 2.490318652276558

Epoch: 5| Step: 4
Training loss: 2.801128541491274
Validation loss: 2.4913838262391383

Epoch: 5| Step: 5
Training loss: 2.88026874242048
Validation loss: 2.4929293431278214

Epoch: 5| Step: 6
Training loss: 3.1432704127443882
Validation loss: 2.4864291754174257

Epoch: 5| Step: 7
Training loss: 3.072243585525684
Validation loss: 2.487510332620043

Epoch: 5| Step: 8
Training loss: 2.658558011102029
Validation loss: 2.4819494340551587

Epoch: 5| Step: 9
Training loss: 2.1655606479083627
Validation loss: 2.4911747210321997

Epoch: 5| Step: 10
Training loss: 3.0950274671774736
Validation loss: 2.5154992843294495

Epoch: 125| Step: 0
Training loss: 2.9083457691469627
Validation loss: 2.5273783749985377

Epoch: 5| Step: 1
Training loss: 2.2392531277207866
Validation loss: 2.526081633856859

Epoch: 5| Step: 2
Training loss: 2.8744537829779198
Validation loss: 2.5282296863040785

Epoch: 5| Step: 3
Training loss: 2.801391535072504
Validation loss: 2.5321427885912193

Epoch: 5| Step: 4
Training loss: 2.7415853420668292
Validation loss: 2.5178066997535113

Epoch: 5| Step: 5
Training loss: 2.7733783554433042
Validation loss: 2.497036741539573

Epoch: 5| Step: 6
Training loss: 2.750102821508612
Validation loss: 2.4947503428779214

Epoch: 5| Step: 7
Training loss: 3.091826332130283
Validation loss: 2.5079546772363783

Epoch: 5| Step: 8
Training loss: 3.079576179276903
Validation loss: 2.5199492204263456

Epoch: 5| Step: 9
Training loss: 2.5952359274925554
Validation loss: 2.4777744575934535

Epoch: 5| Step: 10
Training loss: 2.5940627863159684
Validation loss: 2.492684310845944

Epoch: 126| Step: 0
Training loss: 2.6005747526632366
Validation loss: 2.490674812476606

Epoch: 5| Step: 1
Training loss: 2.7515053530319857
Validation loss: 2.4865231324847805

Epoch: 5| Step: 2
Training loss: 2.892548452118229
Validation loss: 2.4848234989838507

Epoch: 5| Step: 3
Training loss: 2.63052921163367
Validation loss: 2.49927561683965

Epoch: 5| Step: 4
Training loss: 2.6599449040149348
Validation loss: 2.518261430304215

Epoch: 5| Step: 5
Training loss: 2.6497971187159264
Validation loss: 2.5316261772589326

Epoch: 5| Step: 6
Training loss: 2.7336967280970463
Validation loss: 2.5160958230325217

Epoch: 5| Step: 7
Training loss: 2.7484558278351563
Validation loss: 2.4926183277189264

Epoch: 5| Step: 8
Training loss: 3.0448277564731563
Validation loss: 2.469704657976068

Epoch: 5| Step: 9
Training loss: 2.7572385714878025
Validation loss: 2.466633830673692

Epoch: 5| Step: 10
Training loss: 3.087654505273073
Validation loss: 2.465640103985985

Epoch: 127| Step: 0
Training loss: 2.7962505133555475
Validation loss: 2.4648519167135787

Epoch: 5| Step: 1
Training loss: 3.272065305230679
Validation loss: 2.4667791846713745

Epoch: 5| Step: 2
Training loss: 2.8506088543421915
Validation loss: 2.469576298460463

Epoch: 5| Step: 3
Training loss: 2.737276902535804
Validation loss: 2.4726064169246698

Epoch: 5| Step: 4
Training loss: 2.4243137017702687
Validation loss: 2.4838863477069606

Epoch: 5| Step: 5
Training loss: 2.579527594764611
Validation loss: 2.5104968790413076

Epoch: 5| Step: 6
Training loss: 2.6670354548394375
Validation loss: 2.5363259465503107

Epoch: 5| Step: 7
Training loss: 2.6381678237457824
Validation loss: 2.5296817825105724

Epoch: 5| Step: 8
Training loss: 2.6044427547333626
Validation loss: 2.5264215574221103

Epoch: 5| Step: 9
Training loss: 3.021446656852892
Validation loss: 2.5215076902883418

Epoch: 5| Step: 10
Training loss: 2.992747759844243
Validation loss: 2.5192695458229624

Epoch: 128| Step: 0
Training loss: 3.173835186290222
Validation loss: 2.5329765195510165

Epoch: 5| Step: 1
Training loss: 2.377539431528765
Validation loss: 2.524938131780825

Epoch: 5| Step: 2
Training loss: 2.7997873157378756
Validation loss: 2.5134086600792016

Epoch: 5| Step: 3
Training loss: 3.034705640416317
Validation loss: 2.4961518029229763

Epoch: 5| Step: 4
Training loss: 2.8418118086484765
Validation loss: 2.499842684420958

Epoch: 5| Step: 5
Training loss: 2.155601182708161
Validation loss: 2.4866734250674107

Epoch: 5| Step: 6
Training loss: 2.237589730962239
Validation loss: 2.491926947712909

Epoch: 5| Step: 7
Training loss: 2.13467013327853
Validation loss: 2.487220032378889

Epoch: 5| Step: 8
Training loss: 3.296315511805437
Validation loss: 2.5094494551822675

Epoch: 5| Step: 9
Training loss: 2.8776634152672167
Validation loss: 2.5401999425575936

Epoch: 5| Step: 10
Training loss: 3.124457350345954
Validation loss: 2.5969443973713986

Epoch: 129| Step: 0
Training loss: 3.136375474970291
Validation loss: 2.6847866676654064

Epoch: 5| Step: 1
Training loss: 2.746997668203858
Validation loss: 2.623298240873883

Epoch: 5| Step: 2
Training loss: 2.4286014791440635
Validation loss: 2.5376342512424075

Epoch: 5| Step: 3
Training loss: 3.0133690178145147
Validation loss: 2.479940090246412

Epoch: 5| Step: 4
Training loss: 2.4106884929750576
Validation loss: 2.467240752429748

Epoch: 5| Step: 5
Training loss: 2.7850663650796457
Validation loss: 2.4688400588581656

Epoch: 5| Step: 6
Training loss: 2.946767108839413
Validation loss: 2.4776232971942704

Epoch: 5| Step: 7
Training loss: 2.9263931673494707
Validation loss: 2.479701220228136

Epoch: 5| Step: 8
Training loss: 2.393996410784664
Validation loss: 2.4847079447547307

Epoch: 5| Step: 9
Training loss: 2.952346456929743
Validation loss: 2.4783798572734232

Epoch: 5| Step: 10
Training loss: 3.5235233000397277
Validation loss: 2.4764346149924075

Epoch: 130| Step: 0
Training loss: 2.47851658694081
Validation loss: 2.4767327553402168

Epoch: 5| Step: 1
Training loss: 3.038360436158727
Validation loss: 2.4784118190491724

Epoch: 5| Step: 2
Training loss: 2.2875338192300227
Validation loss: 2.523853652344313

Epoch: 5| Step: 3
Training loss: 3.084962483182582
Validation loss: 2.62658546644976

Epoch: 5| Step: 4
Training loss: 2.2813140651120305
Validation loss: 2.7074927686069143

Epoch: 5| Step: 5
Training loss: 3.6737520655171605
Validation loss: 2.777101535382212

Epoch: 5| Step: 6
Training loss: 2.860954640460584
Validation loss: 2.7466408516513683

Epoch: 5| Step: 7
Training loss: 3.0517776561854846
Validation loss: 2.709416980259451

Epoch: 5| Step: 8
Training loss: 2.8762191177958294
Validation loss: 2.653073972960698

Epoch: 5| Step: 9
Training loss: 3.0838217133717833
Validation loss: 2.577385187136265

Epoch: 5| Step: 10
Training loss: 2.861390950942094
Validation loss: 2.5384073583144793

Epoch: 131| Step: 0
Training loss: 3.1978212688187515
Validation loss: 2.525303601109818

Epoch: 5| Step: 1
Training loss: 2.9573398766658805
Validation loss: 2.538341435606071

Epoch: 5| Step: 2
Training loss: 3.0557141542214925
Validation loss: 2.525844428672827

Epoch: 5| Step: 3
Training loss: 2.589261871378447
Validation loss: 2.4946339577278986

Epoch: 5| Step: 4
Training loss: 2.430397641335122
Validation loss: 2.4828988971705592

Epoch: 5| Step: 5
Training loss: 3.144491368390339
Validation loss: 2.4857051789354876

Epoch: 5| Step: 6
Training loss: 2.7288092070939483
Validation loss: 2.493327437609303

Epoch: 5| Step: 7
Training loss: 2.8774778220401642
Validation loss: 2.5230367064060544

Epoch: 5| Step: 8
Training loss: 2.704371346915775
Validation loss: 2.572890494565025

Epoch: 5| Step: 9
Training loss: 3.160533000805739
Validation loss: 2.5424280066939184

Epoch: 5| Step: 10
Training loss: 2.4803858945930553
Validation loss: 2.5203899935079073

Epoch: 132| Step: 0
Training loss: 2.618746074227461
Validation loss: 2.5041343671184295

Epoch: 5| Step: 1
Training loss: 2.5641970713633877
Validation loss: 2.5287790273626567

Epoch: 5| Step: 2
Training loss: 3.1672365445450334
Validation loss: 2.539627079569784

Epoch: 5| Step: 3
Training loss: 1.9144527738080872
Validation loss: 2.5358605719077842

Epoch: 5| Step: 4
Training loss: 3.1785241700604074
Validation loss: 2.541129460106626

Epoch: 5| Step: 5
Training loss: 2.717180873518372
Validation loss: 2.528003226264005

Epoch: 5| Step: 6
Training loss: 3.163748718526725
Validation loss: 2.5198013052824932

Epoch: 5| Step: 7
Training loss: 3.1612053675157443
Validation loss: 2.5001683598915414

Epoch: 5| Step: 8
Training loss: 2.479812943879699
Validation loss: 2.4950120285539605

Epoch: 5| Step: 9
Training loss: 2.7476107882376892
Validation loss: 2.4932266081684946

Epoch: 5| Step: 10
Training loss: 2.4289766602664966
Validation loss: 2.4831258252147865

Epoch: 133| Step: 0
Training loss: 2.5917276978333965
Validation loss: 2.5021543869584635

Epoch: 5| Step: 1
Training loss: 2.6577348037298205
Validation loss: 2.5046120125493507

Epoch: 5| Step: 2
Training loss: 2.346424865222052
Validation loss: 2.547272943576263

Epoch: 5| Step: 3
Training loss: 2.714697173847761
Validation loss: 2.597152407710299

Epoch: 5| Step: 4
Training loss: 2.6430459746722073
Validation loss: 2.582229854590828

Epoch: 5| Step: 5
Training loss: 2.860179516953728
Validation loss: 2.5770288906043004

Epoch: 5| Step: 6
Training loss: 3.1756788474226694
Validation loss: 2.488732668405906

Epoch: 5| Step: 7
Training loss: 3.1218399855413326
Validation loss: 2.468480164088468

Epoch: 5| Step: 8
Training loss: 2.72951341323925
Validation loss: 2.451850761343598

Epoch: 5| Step: 9
Training loss: 2.8178522680800926
Validation loss: 2.4491614540959423

Epoch: 5| Step: 10
Training loss: 2.9126298670814226
Validation loss: 2.4439912348230024

Epoch: 134| Step: 0
Training loss: 1.8204457639448426
Validation loss: 2.4482370837575904

Epoch: 5| Step: 1
Training loss: 2.8911465560938754
Validation loss: 2.4467669881710976

Epoch: 5| Step: 2
Training loss: 2.9940001572358543
Validation loss: 2.448000818262279

Epoch: 5| Step: 3
Training loss: 2.465024237213758
Validation loss: 2.4453885091745566

Epoch: 5| Step: 4
Training loss: 3.3935902369990507
Validation loss: 2.476484851364553

Epoch: 5| Step: 5
Training loss: 2.8639777820833543
Validation loss: 2.49001100127466

Epoch: 5| Step: 6
Training loss: 2.7429975307674606
Validation loss: 2.539405759921037

Epoch: 5| Step: 7
Training loss: 2.765440164197702
Validation loss: 2.5503814212545164

Epoch: 5| Step: 8
Training loss: 2.841581419023129
Validation loss: 2.57861778842242

Epoch: 5| Step: 9
Training loss: 2.7361704136273506
Validation loss: 2.5486166091526874

Epoch: 5| Step: 10
Training loss: 2.8574247119026417
Validation loss: 2.5420551998279124

Epoch: 135| Step: 0
Training loss: 2.8736964048454525
Validation loss: 2.524608087964648

Epoch: 5| Step: 1
Training loss: 2.5801052002565457
Validation loss: 2.4960512827189807

Epoch: 5| Step: 2
Training loss: 2.7206135644021705
Validation loss: 2.474583365602036

Epoch: 5| Step: 3
Training loss: 2.473070251614658
Validation loss: 2.4789641447444963

Epoch: 5| Step: 4
Training loss: 2.438085339029757
Validation loss: 2.488202170193348

Epoch: 5| Step: 5
Training loss: 2.9300671954473034
Validation loss: 2.4957195574539917

Epoch: 5| Step: 6
Training loss: 2.288599481721963
Validation loss: 2.4960656966971895

Epoch: 5| Step: 7
Training loss: 2.82878551883961
Validation loss: 2.5114380536380274

Epoch: 5| Step: 8
Training loss: 2.5766143997174944
Validation loss: 2.500130731999677

Epoch: 5| Step: 9
Training loss: 2.9522093306964154
Validation loss: 2.5127804530204263

Epoch: 5| Step: 10
Training loss: 3.4015846150090705
Validation loss: 2.500565927295659

Epoch: 136| Step: 0
Training loss: 2.0758398585431994
Validation loss: 2.487842979372481

Epoch: 5| Step: 1
Training loss: 2.9353441484390532
Validation loss: 2.496253488827116

Epoch: 5| Step: 2
Training loss: 2.6970624025372367
Validation loss: 2.519194910968196

Epoch: 5| Step: 3
Training loss: 2.4390044826765105
Validation loss: 2.5179331839758654

Epoch: 5| Step: 4
Training loss: 2.885129250948341
Validation loss: 2.501337024061847

Epoch: 5| Step: 5
Training loss: 3.0836390953702097
Validation loss: 2.486365060612722

Epoch: 5| Step: 6
Training loss: 2.781745352191184
Validation loss: 2.4783399197317633

Epoch: 5| Step: 7
Training loss: 3.1731402499764343
Validation loss: 2.4833882712760573

Epoch: 5| Step: 8
Training loss: 2.5368289454815067
Validation loss: 2.480267673617446

Epoch: 5| Step: 9
Training loss: 2.61895473654058
Validation loss: 2.48545009718216

Epoch: 5| Step: 10
Training loss: 2.614916827044336
Validation loss: 2.4883917343573105

Epoch: 137| Step: 0
Training loss: 2.487979026178595
Validation loss: 2.4846054406770763

Epoch: 5| Step: 1
Training loss: 2.596184656443995
Validation loss: 2.4805007386028293

Epoch: 5| Step: 2
Training loss: 2.7550672315920064
Validation loss: 2.488498172354076

Epoch: 5| Step: 3
Training loss: 2.6912982625571646
Validation loss: 2.507561680663671

Epoch: 5| Step: 4
Training loss: 2.823720716617584
Validation loss: 2.520188546014881

Epoch: 5| Step: 5
Training loss: 2.9618883040629047
Validation loss: 2.516753960247062

Epoch: 5| Step: 6
Training loss: 3.1695996471506893
Validation loss: 2.516627795706932

Epoch: 5| Step: 7
Training loss: 2.6261091159832435
Validation loss: 2.5386277733293032

Epoch: 5| Step: 8
Training loss: 2.596079136786945
Validation loss: 2.5517746384352815

Epoch: 5| Step: 9
Training loss: 2.5200209977016903
Validation loss: 2.5667035640221365

Epoch: 5| Step: 10
Training loss: 2.6495470631586406
Validation loss: 2.5618467921518504

Epoch: 138| Step: 0
Training loss: 2.6894806061935657
Validation loss: 2.5180159831245597

Epoch: 5| Step: 1
Training loss: 2.4214049836885483
Validation loss: 2.4906418212754073

Epoch: 5| Step: 2
Training loss: 2.825891951464192
Validation loss: 2.502634482597966

Epoch: 5| Step: 3
Training loss: 2.847312289004872
Validation loss: 2.4908896429365686

Epoch: 5| Step: 4
Training loss: 3.106574863201637
Validation loss: 2.513011074966407

Epoch: 5| Step: 5
Training loss: 2.1507235485003586
Validation loss: 2.52714773780001

Epoch: 5| Step: 6
Training loss: 2.7722910916020216
Validation loss: 2.5433869581047754

Epoch: 5| Step: 7
Training loss: 2.9128669147465187
Validation loss: 2.5608530461997545

Epoch: 5| Step: 8
Training loss: 2.251159792908537
Validation loss: 2.508206981226158

Epoch: 5| Step: 9
Training loss: 3.061736654008796
Validation loss: 2.514780233792048

Epoch: 5| Step: 10
Training loss: 3.0158925308386504
Validation loss: 2.497510890168115

Epoch: 139| Step: 0
Training loss: 3.2102540117103113
Validation loss: 2.4907581819666404

Epoch: 5| Step: 1
Training loss: 2.5677937047873334
Validation loss: 2.4973797500213766

Epoch: 5| Step: 2
Training loss: 2.180750215214862
Validation loss: 2.486779400538379

Epoch: 5| Step: 3
Training loss: 2.7855321943414855
Validation loss: 2.4925590673017206

Epoch: 5| Step: 4
Training loss: 3.216475340402516
Validation loss: 2.491778378423071

Epoch: 5| Step: 5
Training loss: 2.4797381428941683
Validation loss: 2.4878552439630868

Epoch: 5| Step: 6
Training loss: 2.9661801107076613
Validation loss: 2.4945400872552246

Epoch: 5| Step: 7
Training loss: 2.683597037189808
Validation loss: 2.5238077576609004

Epoch: 5| Step: 8
Training loss: 2.6987457965148445
Validation loss: 2.520092503353391

Epoch: 5| Step: 9
Training loss: 2.923489863845741
Validation loss: 2.5417239886886716

Epoch: 5| Step: 10
Training loss: 2.3685259670310232
Validation loss: 2.5458224817072286

Epoch: 140| Step: 0
Training loss: 2.914622398770893
Validation loss: 2.5377849217643917

Epoch: 5| Step: 1
Training loss: 3.0114289971876373
Validation loss: 2.543080947246001

Epoch: 5| Step: 2
Training loss: 2.6693454837439967
Validation loss: 2.543977189196453

Epoch: 5| Step: 3
Training loss: 2.800264489079785
Validation loss: 2.5454075874817708

Epoch: 5| Step: 4
Training loss: 2.6972340686231076
Validation loss: 2.557448336211817

Epoch: 5| Step: 5
Training loss: 2.9052023691412723
Validation loss: 2.5591446713698818

Epoch: 5| Step: 6
Training loss: 2.579838131550827
Validation loss: 2.567841056640551

Epoch: 5| Step: 7
Training loss: 2.526277154911498
Validation loss: 2.5716616159450005

Epoch: 5| Step: 8
Training loss: 2.565141014699381
Validation loss: 2.5574159257216134

Epoch: 5| Step: 9
Training loss: 2.714927529339041
Validation loss: 2.5359255279601527

Epoch: 5| Step: 10
Training loss: 2.8161010576830763
Validation loss: 2.4841367360033675

Epoch: 141| Step: 0
Training loss: 2.8488216239492017
Validation loss: 2.477264859547616

Epoch: 5| Step: 1
Training loss: 2.499041755135094
Validation loss: 2.4554700394474422

Epoch: 5| Step: 2
Training loss: 3.0038060840033283
Validation loss: 2.4542221166975295

Epoch: 5| Step: 3
Training loss: 2.449762749375694
Validation loss: 2.4479681169753458

Epoch: 5| Step: 4
Training loss: 2.8068218132896927
Validation loss: 2.458776517130182

Epoch: 5| Step: 5
Training loss: 2.669032855086419
Validation loss: 2.4649207169770553

Epoch: 5| Step: 6
Training loss: 2.9585442445459615
Validation loss: 2.479687427588701

Epoch: 5| Step: 7
Training loss: 2.6152899852307288
Validation loss: 2.4949597536221475

Epoch: 5| Step: 8
Training loss: 2.7664167919459017
Validation loss: 2.513711326151788

Epoch: 5| Step: 9
Training loss: 2.5963719914831076
Validation loss: 2.5524609396670503

Epoch: 5| Step: 10
Training loss: 2.934904209633862
Validation loss: 2.5663559537653904

Epoch: 142| Step: 0
Training loss: 2.503026275021352
Validation loss: 2.5596342151625886

Epoch: 5| Step: 1
Training loss: 2.638866132225383
Validation loss: 2.518687041756457

Epoch: 5| Step: 2
Training loss: 2.6797518263678133
Validation loss: 2.495286038141485

Epoch: 5| Step: 3
Training loss: 2.7363952149274477
Validation loss: 2.477044538899987

Epoch: 5| Step: 4
Training loss: 2.7145432998933448
Validation loss: 2.4717476276983605

Epoch: 5| Step: 5
Training loss: 2.5384874837167453
Validation loss: 2.4686348242974767

Epoch: 5| Step: 6
Training loss: 2.91490378009999
Validation loss: 2.4666259307319036

Epoch: 5| Step: 7
Training loss: 2.7329939488086783
Validation loss: 2.4671412031732647

Epoch: 5| Step: 8
Training loss: 2.5272613936482613
Validation loss: 2.4837987557441767

Epoch: 5| Step: 9
Training loss: 2.669850257074849
Validation loss: 2.5150375938977763

Epoch: 5| Step: 10
Training loss: 3.4373788985681775
Validation loss: 2.539686030079918

Epoch: 143| Step: 0
Training loss: 2.1916546196358677
Validation loss: 2.565105324338847

Epoch: 5| Step: 1
Training loss: 2.983091068198722
Validation loss: 2.567582099851953

Epoch: 5| Step: 2
Training loss: 2.541039832525448
Validation loss: 2.502290509092106

Epoch: 5| Step: 3
Training loss: 2.5926037749044264
Validation loss: 2.474882716659426

Epoch: 5| Step: 4
Training loss: 3.0389263053913647
Validation loss: 2.4752408907805585

Epoch: 5| Step: 5
Training loss: 3.0383273218555447
Validation loss: 2.493603805684227

Epoch: 5| Step: 6
Training loss: 3.0459806254441366
Validation loss: 2.5111698329152516

Epoch: 5| Step: 7
Training loss: 2.8149742263508437
Validation loss: 2.537251174570097

Epoch: 5| Step: 8
Training loss: 2.55113220137268
Validation loss: 2.5402611847955656

Epoch: 5| Step: 9
Training loss: 2.849561517011591
Validation loss: 2.5450553833524587

Epoch: 5| Step: 10
Training loss: 3.1854274219824523
Validation loss: 2.561737984707533

Epoch: 144| Step: 0
Training loss: 2.6252848152777872
Validation loss: 2.5650137020483035

Epoch: 5| Step: 1
Training loss: 3.076621525916522
Validation loss: 2.587179552561958

Epoch: 5| Step: 2
Training loss: 2.93615464589559
Validation loss: 2.6365652694605637

Epoch: 5| Step: 3
Training loss: 2.788963508452029
Validation loss: 2.627557099896656

Epoch: 5| Step: 4
Training loss: 3.118035910888352
Validation loss: 2.5928007855749815

Epoch: 5| Step: 5
Training loss: 2.3781309070087713
Validation loss: 2.5497657953041193

Epoch: 5| Step: 6
Training loss: 2.8677638667325653
Validation loss: 2.530441335284368

Epoch: 5| Step: 7
Training loss: 2.126040708724508
Validation loss: 2.5175828447991946

Epoch: 5| Step: 8
Training loss: 1.9415343336379782
Validation loss: 2.51429152185395

Epoch: 5| Step: 9
Training loss: 2.428314606125916
Validation loss: 2.4932294934142387

Epoch: 5| Step: 10
Training loss: 3.2495689106185144
Validation loss: 2.4887052073644678

Epoch: 145| Step: 0
Training loss: 2.2544678727138963
Validation loss: 2.4908917126706456

Epoch: 5| Step: 1
Training loss: 2.9045508555200485
Validation loss: 2.4796257810688136

Epoch: 5| Step: 2
Training loss: 2.7699265298843274
Validation loss: 2.4769857400862607

Epoch: 5| Step: 3
Training loss: 2.207537729668822
Validation loss: 2.4993071754845255

Epoch: 5| Step: 4
Training loss: 3.2258648799403877
Validation loss: 2.5000884071223357

Epoch: 5| Step: 5
Training loss: 2.831692631965247
Validation loss: 2.516057363480183

Epoch: 5| Step: 6
Training loss: 2.4994609251560296
Validation loss: 2.526252632393645

Epoch: 5| Step: 7
Training loss: 2.954203090972244
Validation loss: 2.527858679835528

Epoch: 5| Step: 8
Training loss: 2.8088603735417284
Validation loss: 2.5573959641757837

Epoch: 5| Step: 9
Training loss: 2.6739335189121682
Validation loss: 2.5301391592782134

Epoch: 5| Step: 10
Training loss: 2.374525223508661
Validation loss: 2.5261365457638965

Epoch: 146| Step: 0
Training loss: 2.691905646644587
Validation loss: 2.5008490300009774

Epoch: 5| Step: 1
Training loss: 2.2441121523705077
Validation loss: 2.4854228938412484

Epoch: 5| Step: 2
Training loss: 2.635041151069252
Validation loss: 2.4871247214448804

Epoch: 5| Step: 3
Training loss: 2.9822878904293204
Validation loss: 2.4866617855934767

Epoch: 5| Step: 4
Training loss: 3.0858523586454862
Validation loss: 2.4960232987809947

Epoch: 5| Step: 5
Training loss: 2.2086114408407265
Validation loss: 2.5003710245846276

Epoch: 5| Step: 6
Training loss: 2.4035393445750812
Validation loss: 2.5108623195025066

Epoch: 5| Step: 7
Training loss: 2.78036905116919
Validation loss: 2.514097943230088

Epoch: 5| Step: 8
Training loss: 3.059446408429114
Validation loss: 2.5152970293031047

Epoch: 5| Step: 9
Training loss: 2.8932285440457437
Validation loss: 2.5233396476065906

Epoch: 5| Step: 10
Training loss: 2.455467029441063
Validation loss: 2.553994404776338

Epoch: 147| Step: 0
Training loss: 2.9057692263414396
Validation loss: 2.580964649520227

Epoch: 5| Step: 1
Training loss: 3.1943642997823716
Validation loss: 2.617792311925756

Epoch: 5| Step: 2
Training loss: 2.3930204270698945
Validation loss: 2.6470623719407893

Epoch: 5| Step: 3
Training loss: 2.911907636791572
Validation loss: 2.664988336345001

Epoch: 5| Step: 4
Training loss: 2.5480360883256084
Validation loss: 2.7045496924574954

Epoch: 5| Step: 5
Training loss: 2.794151727864186
Validation loss: 2.6840175034912455

Epoch: 5| Step: 6
Training loss: 2.6922366960827153
Validation loss: 2.5992925456445213

Epoch: 5| Step: 7
Training loss: 2.720331104966488
Validation loss: 2.518714112297101

Epoch: 5| Step: 8
Training loss: 2.6922917784755014
Validation loss: 2.498034427485484

Epoch: 5| Step: 9
Training loss: 2.25849962173604
Validation loss: 2.4781304266516573

Epoch: 5| Step: 10
Training loss: 2.647829059038954
Validation loss: 2.476968262249611

Epoch: 148| Step: 0
Training loss: 2.688104871946366
Validation loss: 2.4847053178735625

Epoch: 5| Step: 1
Training loss: 2.4326340450038146
Validation loss: 2.5178404142957738

Epoch: 5| Step: 2
Training loss: 2.925466686089742
Validation loss: 2.5640569189523243

Epoch: 5| Step: 3
Training loss: 3.0439681834639662
Validation loss: 2.5538153417610046

Epoch: 5| Step: 4
Training loss: 2.5698538605815884
Validation loss: 2.5130295569011127

Epoch: 5| Step: 5
Training loss: 2.6439414782431845
Validation loss: 2.4698822417861086

Epoch: 5| Step: 6
Training loss: 2.84319358664129
Validation loss: 2.468183606951144

Epoch: 5| Step: 7
Training loss: 2.6914806604826187
Validation loss: 2.475554207455294

Epoch: 5| Step: 8
Training loss: 2.5794459802332375
Validation loss: 2.5176027564501076

Epoch: 5| Step: 9
Training loss: 2.684451925221322
Validation loss: 2.5429618937051806

Epoch: 5| Step: 10
Training loss: 2.5422186851347184
Validation loss: 2.575593668107523

Epoch: 149| Step: 0
Training loss: 2.667958473196944
Validation loss: 2.5956788267736317

Epoch: 5| Step: 1
Training loss: 2.8053684098760745
Validation loss: 2.6152812943108805

Epoch: 5| Step: 2
Training loss: 2.9321140666906955
Validation loss: 2.5916148046967824

Epoch: 5| Step: 3
Training loss: 2.6056574305627316
Validation loss: 2.552065307339227

Epoch: 5| Step: 4
Training loss: 2.4905776800736326
Validation loss: 2.536661603887336

Epoch: 5| Step: 5
Training loss: 3.0013802849876097
Validation loss: 2.5127172768878467

Epoch: 5| Step: 6
Training loss: 2.3332786099510865
Validation loss: 2.5102357485594906

Epoch: 5| Step: 7
Training loss: 2.658567427449676
Validation loss: 2.496318481379486

Epoch: 5| Step: 8
Training loss: 2.9616970406604284
Validation loss: 2.4962425256280647

Epoch: 5| Step: 9
Training loss: 2.167351932242053
Validation loss: 2.4964032623575445

Epoch: 5| Step: 10
Training loss: 2.676496290466942
Validation loss: 2.4969156917849977

Epoch: 150| Step: 0
Training loss: 1.9077199677593075
Validation loss: 2.5249087561373598

Epoch: 5| Step: 1
Training loss: 2.8373426418952454
Validation loss: 2.546070320287839

Epoch: 5| Step: 2
Training loss: 2.4610314729701663
Validation loss: 2.585110116524785

Epoch: 5| Step: 3
Training loss: 1.8484225790883937
Validation loss: 2.6456670058834497

Epoch: 5| Step: 4
Training loss: 3.0798057963093965
Validation loss: 2.7146943662758436

Epoch: 5| Step: 5
Training loss: 3.4238295177015137
Validation loss: 2.6754935103664645

Epoch: 5| Step: 6
Training loss: 2.6540617063200678
Validation loss: 2.597591156860631

Epoch: 5| Step: 7
Training loss: 3.1206821365978086
Validation loss: 2.5808609551464303

Epoch: 5| Step: 8
Training loss: 2.6456309163518332
Validation loss: 2.580126663323645

Epoch: 5| Step: 9
Training loss: 2.378492598125367
Validation loss: 2.59260651296924

Epoch: 5| Step: 10
Training loss: 3.1744440508124065
Validation loss: 2.590646284633877

Epoch: 151| Step: 0
Training loss: 2.4960551609644264
Validation loss: 2.557720782811113

Epoch: 5| Step: 1
Training loss: 2.4904413593513253
Validation loss: 2.535039425309301

Epoch: 5| Step: 2
Training loss: 2.7418781334237603
Validation loss: 2.5272604685200992

Epoch: 5| Step: 3
Training loss: 2.71626492632694
Validation loss: 2.5231027465243105

Epoch: 5| Step: 4
Training loss: 2.311416887826035
Validation loss: 2.5391708686615853

Epoch: 5| Step: 5
Training loss: 2.676651015546685
Validation loss: 2.5287893375446977

Epoch: 5| Step: 6
Training loss: 2.745421065396793
Validation loss: 2.5783709048635743

Epoch: 5| Step: 7
Training loss: 2.939386614176934
Validation loss: 2.589016271162836

Epoch: 5| Step: 8
Training loss: 2.735582357609822
Validation loss: 2.5663750774389387

Epoch: 5| Step: 9
Training loss: 2.709849554298835
Validation loss: 2.6034726234869527

Epoch: 5| Step: 10
Training loss: 2.738730748786628
Validation loss: 2.558330823910379

Epoch: 152| Step: 0
Training loss: 2.851922668286044
Validation loss: 2.5548759773007097

Epoch: 5| Step: 1
Training loss: 2.552364961823827
Validation loss: 2.5278761982890883

Epoch: 5| Step: 2
Training loss: 2.8987105824437673
Validation loss: 2.487684425603317

Epoch: 5| Step: 3
Training loss: 2.8275031148959138
Validation loss: 2.5078400722906338

Epoch: 5| Step: 4
Training loss: 1.7553250493787298
Validation loss: 2.521276107814707

Epoch: 5| Step: 5
Training loss: 2.8805541416689144
Validation loss: 2.5227892044269438

Epoch: 5| Step: 6
Training loss: 2.9634133005526886
Validation loss: 2.5137374258347727

Epoch: 5| Step: 7
Training loss: 2.464823340378308
Validation loss: 2.5113801713462762

Epoch: 5| Step: 8
Training loss: 2.769160451668733
Validation loss: 2.4877487630011226

Epoch: 5| Step: 9
Training loss: 2.772715729832962
Validation loss: 2.473967855766549

Epoch: 5| Step: 10
Training loss: 2.0988717136226693
Validation loss: 2.478214833656976

Epoch: 153| Step: 0
Training loss: 2.431288115293342
Validation loss: 2.4656278383261103

Epoch: 5| Step: 1
Training loss: 3.1006094671843414
Validation loss: 2.465868768986516

Epoch: 5| Step: 2
Training loss: 2.5835349916894277
Validation loss: 2.4824253914007652

Epoch: 5| Step: 3
Training loss: 2.28002614675554
Validation loss: 2.473662515170145

Epoch: 5| Step: 4
Training loss: 3.3100406946175776
Validation loss: 2.4870903709704475

Epoch: 5| Step: 5
Training loss: 2.8287781019243554
Validation loss: 2.537295720729851

Epoch: 5| Step: 6
Training loss: 2.3597111746674297
Validation loss: 2.544776186093548

Epoch: 5| Step: 7
Training loss: 3.0076387429519307
Validation loss: 2.552241761993102

Epoch: 5| Step: 8
Training loss: 2.280450759299218
Validation loss: 2.553928392541697

Epoch: 5| Step: 9
Training loss: 2.5380507111168855
Validation loss: 2.5559356491355207

Epoch: 5| Step: 10
Training loss: 2.1807941649081113
Validation loss: 2.546847840237368

Epoch: 154| Step: 0
Training loss: 3.1019302265478337
Validation loss: 2.532717470941069

Epoch: 5| Step: 1
Training loss: 1.8456874301788058
Validation loss: 2.528126979583582

Epoch: 5| Step: 2
Training loss: 2.786560646151484
Validation loss: 2.5050787488099227

Epoch: 5| Step: 3
Training loss: 3.136919559117437
Validation loss: 2.4959987758590616

Epoch: 5| Step: 4
Training loss: 2.2473457363257534
Validation loss: 2.4954852089141455

Epoch: 5| Step: 5
Training loss: 2.416205877462671
Validation loss: 2.475161164407081

Epoch: 5| Step: 6
Training loss: 2.4931514394510055
Validation loss: 2.480137594989469

Epoch: 5| Step: 7
Training loss: 2.3086009791950053
Validation loss: 2.480858570254223

Epoch: 5| Step: 8
Training loss: 2.7806406961016465
Validation loss: 2.4944703547315417

Epoch: 5| Step: 9
Training loss: 2.6128174693855706
Validation loss: 2.5011269480213736

Epoch: 5| Step: 10
Training loss: 2.9335729443336778
Validation loss: 2.5087043465198726

Epoch: 155| Step: 0
Training loss: 2.3293275735467636
Validation loss: 2.525910458309084

Epoch: 5| Step: 1
Training loss: 2.2385600983180547
Validation loss: 2.5275746883003403

Epoch: 5| Step: 2
Training loss: 2.7779234805571167
Validation loss: 2.553356403776843

Epoch: 5| Step: 3
Training loss: 2.915077830301254
Validation loss: 2.5664143522466225

Epoch: 5| Step: 4
Training loss: 2.9220876361360686
Validation loss: 2.565014960374045

Epoch: 5| Step: 5
Training loss: 2.374366474984799
Validation loss: 2.585695642112619

Epoch: 5| Step: 6
Training loss: 2.8282841590228673
Validation loss: 2.629625036247584

Epoch: 5| Step: 7
Training loss: 2.8704070846597767
Validation loss: 2.6318195766617962

Epoch: 5| Step: 8
Training loss: 1.5884950057717577
Validation loss: 2.6132381394021684

Epoch: 5| Step: 9
Training loss: 2.869819285588135
Validation loss: 2.60148349149155

Epoch: 5| Step: 10
Training loss: 2.7947516026269206
Validation loss: 2.5635241901057513

Epoch: 156| Step: 0
Training loss: 2.070850806159355
Validation loss: 2.5356735919410536

Epoch: 5| Step: 1
Training loss: 2.552287990123291
Validation loss: 2.5244176341477225

Epoch: 5| Step: 2
Training loss: 2.3541045279164927
Validation loss: 2.5010048005789134

Epoch: 5| Step: 3
Training loss: 2.648637702149181
Validation loss: 2.4944653291294885

Epoch: 5| Step: 4
Training loss: 2.8964175359997184
Validation loss: 2.496159413256662

Epoch: 5| Step: 5
Training loss: 2.5289413850386455
Validation loss: 2.483751413379089

Epoch: 5| Step: 6
Training loss: 2.719697633654495
Validation loss: 2.4816019518788854

Epoch: 5| Step: 7
Training loss: 2.4693708966915535
Validation loss: 2.4946359143956656

Epoch: 5| Step: 8
Training loss: 2.8526727892524764
Validation loss: 2.530473610041248

Epoch: 5| Step: 9
Training loss: 2.6696444118183567
Validation loss: 2.559262779780896

Epoch: 5| Step: 10
Training loss: 2.889890175286896
Validation loss: 2.5818407614179626

Epoch: 157| Step: 0
Training loss: 2.341788424746274
Validation loss: 2.5917562251316486

Epoch: 5| Step: 1
Training loss: 3.019627736118127
Validation loss: 2.5954238900788593

Epoch: 5| Step: 2
Training loss: 2.122467102227175
Validation loss: 2.565363639741022

Epoch: 5| Step: 3
Training loss: 2.880906050998994
Validation loss: 2.5442314608824654

Epoch: 5| Step: 4
Training loss: 2.47682588061234
Validation loss: 2.5429084218347353

Epoch: 5| Step: 5
Training loss: 2.9133324411712374
Validation loss: 2.510052499631029

Epoch: 5| Step: 6
Training loss: 2.6013264133681337
Validation loss: 2.5093183576421785

Epoch: 5| Step: 7
Training loss: 2.6950785217452946
Validation loss: 2.507994691082336

Epoch: 5| Step: 8
Training loss: 2.4572495695558723
Validation loss: 2.505408050992767

Epoch: 5| Step: 9
Training loss: 2.444408895734987
Validation loss: 2.5269358564567743

Epoch: 5| Step: 10
Training loss: 2.444988582717044
Validation loss: 2.5320136942394402

Epoch: 158| Step: 0
Training loss: 2.241808071663536
Validation loss: 2.502545764875023

Epoch: 5| Step: 1
Training loss: 2.768069205532519
Validation loss: 2.5476652190667433

Epoch: 5| Step: 2
Training loss: 2.6641982594910694
Validation loss: 2.5358713880910426

Epoch: 5| Step: 3
Training loss: 2.907513415632843
Validation loss: 2.5422841099943327

Epoch: 5| Step: 4
Training loss: 2.666745532379599
Validation loss: 2.5783008176156432

Epoch: 5| Step: 5
Training loss: 2.5069791651112214
Validation loss: 2.609165744497636

Epoch: 5| Step: 6
Training loss: 3.0524114924915726
Validation loss: 2.6488185420548027

Epoch: 5| Step: 7
Training loss: 2.250036981066803
Validation loss: 2.6778498827733546

Epoch: 5| Step: 8
Training loss: 2.326985227405983
Validation loss: 2.650611578715644

Epoch: 5| Step: 9
Training loss: 2.6466916611914137
Validation loss: 2.6377457889147093

Epoch: 5| Step: 10
Training loss: 2.9279877881905465
Validation loss: 2.5975951001364455

Epoch: 159| Step: 0
Training loss: 2.818428234335082
Validation loss: 2.547711025099419

Epoch: 5| Step: 1
Training loss: 2.60080183209531
Validation loss: 2.5304301483889926

Epoch: 5| Step: 2
Training loss: 2.8472942022720433
Validation loss: 2.526396161598333

Epoch: 5| Step: 3
Training loss: 2.399489976414076
Validation loss: 2.5207548652164715

Epoch: 5| Step: 4
Training loss: 2.9375904150501033
Validation loss: 2.5199894924550263

Epoch: 5| Step: 5
Training loss: 2.5530797349706247
Validation loss: 2.516766862179302

Epoch: 5| Step: 6
Training loss: 2.3585848464115444
Validation loss: 2.5185953788023023

Epoch: 5| Step: 7
Training loss: 2.244623117395869
Validation loss: 2.539447798479659

Epoch: 5| Step: 8
Training loss: 2.116261973203529
Validation loss: 2.5617213703230397

Epoch: 5| Step: 9
Training loss: 2.7948220673020345
Validation loss: 2.5765847277063254

Epoch: 5| Step: 10
Training loss: 2.6075742984182138
Validation loss: 2.6288709367672802

Epoch: 160| Step: 0
Training loss: 2.560948902637729
Validation loss: 2.6813954512063836

Epoch: 5| Step: 1
Training loss: 2.346524948244351
Validation loss: 2.7022081117390564

Epoch: 5| Step: 2
Training loss: 2.695000937325451
Validation loss: 2.7882556680653865

Epoch: 5| Step: 3
Training loss: 2.5255479048205474
Validation loss: 2.7448505579681113

Epoch: 5| Step: 4
Training loss: 2.856065846856832
Validation loss: 2.658574366500289

Epoch: 5| Step: 5
Training loss: 2.5849295781059665
Validation loss: 2.5833039382971714

Epoch: 5| Step: 6
Training loss: 2.83527461099467
Validation loss: 2.523735339431013

Epoch: 5| Step: 7
Training loss: 2.4477047659421305
Validation loss: 2.508223124235966

Epoch: 5| Step: 8
Training loss: 2.5453758274019513
Validation loss: 2.496326429076642

Epoch: 5| Step: 9
Training loss: 2.5395197529979363
Validation loss: 2.490716993682571

Epoch: 5| Step: 10
Training loss: 2.5184028405174708
Validation loss: 2.4928674594831444

Epoch: 161| Step: 0
Training loss: 2.9448968811634195
Validation loss: 2.4794144693151887

Epoch: 5| Step: 1
Training loss: 2.7065948971345573
Validation loss: 2.484421731988263

Epoch: 5| Step: 2
Training loss: 2.1155733944615385
Validation loss: 2.4642299583882528

Epoch: 5| Step: 3
Training loss: 2.951600503752573
Validation loss: 2.459930368015395

Epoch: 5| Step: 4
Training loss: 2.7645054507023294
Validation loss: 2.4795681021850515

Epoch: 5| Step: 5
Training loss: 2.336309294950817
Validation loss: 2.5047876823831463

Epoch: 5| Step: 6
Training loss: 2.6286234597275024
Validation loss: 2.5199087208839983

Epoch: 5| Step: 7
Training loss: 2.42992044295072
Validation loss: 2.561355649440433

Epoch: 5| Step: 8
Training loss: 2.561612882808573
Validation loss: 2.591946358873627

Epoch: 5| Step: 9
Training loss: 1.7536873117935752
Validation loss: 2.6070567249401604

Epoch: 5| Step: 10
Training loss: 2.5455778598330894
Validation loss: 2.5965970116561143

Epoch: 162| Step: 0
Training loss: 3.0508537723454356
Validation loss: 2.5531755920611747

Epoch: 5| Step: 1
Training loss: 1.7875805843301844
Validation loss: 2.547626716346562

Epoch: 5| Step: 2
Training loss: 2.2513793320178106
Validation loss: 2.528255813053428

Epoch: 5| Step: 3
Training loss: 2.812333335176855
Validation loss: 2.509795825486547

Epoch: 5| Step: 4
Training loss: 2.8411727796769157
Validation loss: 2.508843972770329

Epoch: 5| Step: 5
Training loss: 2.5631306500245863
Validation loss: 2.5228397879731164

Epoch: 5| Step: 6
Training loss: 2.4593436756586993
Validation loss: 2.5447454225365354

Epoch: 5| Step: 7
Training loss: 2.5037115202835443
Validation loss: 2.5477210755297506

Epoch: 5| Step: 8
Training loss: 2.3198480109052775
Validation loss: 2.5470967828166278

Epoch: 5| Step: 9
Training loss: 2.67187526769804
Validation loss: 2.5362025599401283

Epoch: 5| Step: 10
Training loss: 2.5669079526797445
Validation loss: 2.521153921760952

Epoch: 163| Step: 0
Training loss: 2.2645848484496307
Validation loss: 2.5494144456663004

Epoch: 5| Step: 1
Training loss: 2.075713744984347
Validation loss: 2.5997322155625904

Epoch: 5| Step: 2
Training loss: 2.878810513481945
Validation loss: 2.628923130205192

Epoch: 5| Step: 3
Training loss: 2.6817809177272545
Validation loss: 2.668481246573721

Epoch: 5| Step: 4
Training loss: 2.763993725047738
Validation loss: 2.661116985339081

Epoch: 5| Step: 5
Training loss: 2.8293167890927293
Validation loss: 2.6074020809614247

Epoch: 5| Step: 6
Training loss: 2.0511451035108994
Validation loss: 2.5482727620027226

Epoch: 5| Step: 7
Training loss: 2.9435699731808174
Validation loss: 2.5117704873234716

Epoch: 5| Step: 8
Training loss: 1.7896504997583746
Validation loss: 2.49072585575187

Epoch: 5| Step: 9
Training loss: 2.614697812273077
Validation loss: 2.493665872555454

Epoch: 5| Step: 10
Training loss: 2.7807563600831817
Validation loss: 2.496740198131819

Epoch: 164| Step: 0
Training loss: 2.427504365172621
Validation loss: 2.5024388702083593

Epoch: 5| Step: 1
Training loss: 2.1570842069089005
Validation loss: 2.521436607063613

Epoch: 5| Step: 2
Training loss: 2.663161855468122
Validation loss: 2.5258111356111543

Epoch: 5| Step: 3
Training loss: 2.7742225932699194
Validation loss: 2.515725005092021

Epoch: 5| Step: 4
Training loss: 2.023088933312692
Validation loss: 2.5441994090193036

Epoch: 5| Step: 5
Training loss: 2.62362489559263
Validation loss: 2.5724808598390343

Epoch: 5| Step: 6
Training loss: 2.188530488479685
Validation loss: 2.605986440147237

Epoch: 5| Step: 7
Training loss: 2.4587683427492033
Validation loss: 2.6339871214000534

Epoch: 5| Step: 8
Training loss: 2.654524837582479
Validation loss: 2.6808836543089405

Epoch: 5| Step: 9
Training loss: 2.5178408134263317
Validation loss: 2.64812427628346

Epoch: 5| Step: 10
Training loss: 2.8361475002417347
Validation loss: 2.6264686753504867

Epoch: 165| Step: 0
Training loss: 2.7170308257127918
Validation loss: 2.6075393717265496

Epoch: 5| Step: 1
Training loss: 2.481689729329332
Validation loss: 2.6306137992421568

Epoch: 5| Step: 2
Training loss: 2.5992236005200646
Validation loss: 2.5990238956171274

Epoch: 5| Step: 3
Training loss: 2.1890804575933007
Validation loss: 2.5429260836049896

Epoch: 5| Step: 4
Training loss: 2.4189670948315287
Validation loss: 2.507639681729548

Epoch: 5| Step: 5
Training loss: 2.587614777456496
Validation loss: 2.4660666823467046

Epoch: 5| Step: 6
Training loss: 1.9792478511288374
Validation loss: 2.452598159364538

Epoch: 5| Step: 7
Training loss: 2.5250328854978226
Validation loss: 2.4377747478937346

Epoch: 5| Step: 8
Training loss: 2.316884909671144
Validation loss: 2.4332378904639596

Epoch: 5| Step: 9
Training loss: 2.9582847447949665
Validation loss: 2.4248599369832955

Epoch: 5| Step: 10
Training loss: 2.6393512610764227
Validation loss: 2.434306790549172

Epoch: 166| Step: 0
Training loss: 2.486288521354607
Validation loss: 2.4343871988286283

Epoch: 5| Step: 1
Training loss: 2.252987679411839
Validation loss: 2.4363180975699334

Epoch: 5| Step: 2
Training loss: 2.8056994979325522
Validation loss: 2.4452143205196446

Epoch: 5| Step: 3
Training loss: 2.5615542457580673
Validation loss: 2.4722878747853185

Epoch: 5| Step: 4
Training loss: 2.2598645873560734
Validation loss: 2.486479338740352

Epoch: 5| Step: 5
Training loss: 2.083872369332215
Validation loss: 2.4877523233976504

Epoch: 5| Step: 6
Training loss: 2.49528745902628
Validation loss: 2.500706246816455

Epoch: 5| Step: 7
Training loss: 2.557327073441933
Validation loss: 2.5405933444500484

Epoch: 5| Step: 8
Training loss: 2.6504664568359013
Validation loss: 2.593769356588286

Epoch: 5| Step: 9
Training loss: 2.0317748345403546
Validation loss: 2.5715702641340177

Epoch: 5| Step: 10
Training loss: 2.9897969310275467
Validation loss: 2.5554426981846134

Epoch: 167| Step: 0
Training loss: 2.5275509968941545
Validation loss: 2.5622583911162953

Epoch: 5| Step: 1
Training loss: 2.2304625502732356
Validation loss: 2.5506008628200076

Epoch: 5| Step: 2
Training loss: 2.5201106861571376
Validation loss: 2.55477677823648

Epoch: 5| Step: 3
Training loss: 2.1304380732902697
Validation loss: 2.527805703877445

Epoch: 5| Step: 4
Training loss: 2.6584676124676236
Validation loss: 2.5178962013413564

Epoch: 5| Step: 5
Training loss: 2.4935154740041017
Validation loss: 2.4905846599895485

Epoch: 5| Step: 6
Training loss: 2.379243172274524
Validation loss: 2.502356108093373

Epoch: 5| Step: 7
Training loss: 2.425417665517296
Validation loss: 2.500657060887402

Epoch: 5| Step: 8
Training loss: 2.123379482125101
Validation loss: 2.5024191995351233

Epoch: 5| Step: 9
Training loss: 2.8822351720135524
Validation loss: 2.508383527613348

Epoch: 5| Step: 10
Training loss: 2.6386934698817948
Validation loss: 2.5045461563438627

Epoch: 168| Step: 0
Training loss: 2.605754419133636
Validation loss: 2.530839466188823

Epoch: 5| Step: 1
Training loss: 2.5974991141382935
Validation loss: 2.558708976249505

Epoch: 5| Step: 2
Training loss: 2.5264785441248736
Validation loss: 2.611858082238733

Epoch: 5| Step: 3
Training loss: 2.448541526312981
Validation loss: 2.6579567277712286

Epoch: 5| Step: 4
Training loss: 2.5012373723097854
Validation loss: 2.6450847205843173

Epoch: 5| Step: 5
Training loss: 2.5396879863586
Validation loss: 2.641482829451001

Epoch: 5| Step: 6
Training loss: 2.397759357222936
Validation loss: 2.6654346889530136

Epoch: 5| Step: 7
Training loss: 2.694724552324937
Validation loss: 2.6185644703689626

Epoch: 5| Step: 8
Training loss: 1.9517123797780518
Validation loss: 2.5846608416574863

Epoch: 5| Step: 9
Training loss: 2.4021910083874656
Validation loss: 2.559521379341234

Epoch: 5| Step: 10
Training loss: 2.0933986767615345
Validation loss: 2.522605074720758

Epoch: 169| Step: 0
Training loss: 2.1051834847407123
Validation loss: 2.487964443761213

Epoch: 5| Step: 1
Training loss: 2.053780126925328
Validation loss: 2.4740591225335264

Epoch: 5| Step: 2
Training loss: 2.172554952543219
Validation loss: 2.45157868894273

Epoch: 5| Step: 3
Training loss: 2.3363153158479952
Validation loss: 2.463146578072121

Epoch: 5| Step: 4
Training loss: 2.516825703360038
Validation loss: 2.4705711969278292

Epoch: 5| Step: 5
Training loss: 2.355259824378625
Validation loss: 2.447835136387635

Epoch: 5| Step: 6
Training loss: 2.01476653987629
Validation loss: 2.4785852706183507

Epoch: 5| Step: 7
Training loss: 2.4415326139172864
Validation loss: 2.48926266941654

Epoch: 5| Step: 8
Training loss: 2.9883803407284106
Validation loss: 2.497627272641112

Epoch: 5| Step: 9
Training loss: 2.610222775828363
Validation loss: 2.4934373822120746

Epoch: 5| Step: 10
Training loss: 2.834397415358495
Validation loss: 2.5088484044925634

Epoch: 170| Step: 0
Training loss: 2.319144112133137
Validation loss: 2.555965338193661

Epoch: 5| Step: 1
Training loss: 2.547482751520256
Validation loss: 2.596398134567226

Epoch: 5| Step: 2
Training loss: 2.537152508023218
Validation loss: 2.5667362292869647

Epoch: 5| Step: 3
Training loss: 2.6927861412115566
Validation loss: 2.5345897945824403

Epoch: 5| Step: 4
Training loss: 2.504933924460257
Validation loss: 2.500201357659287

Epoch: 5| Step: 5
Training loss: 2.538511339668341
Validation loss: 2.482323524261339

Epoch: 5| Step: 6
Training loss: 2.8561236130278935
Validation loss: 2.4786028291061677

Epoch: 5| Step: 7
Training loss: 1.9313303637527286
Validation loss: 2.4909756219059402

Epoch: 5| Step: 8
Training loss: 1.865180305376325
Validation loss: 2.460840656479963

Epoch: 5| Step: 9
Training loss: 2.3148979950547592
Validation loss: 2.470354545543512

Epoch: 5| Step: 10
Training loss: 2.3180512478209825
Validation loss: 2.4671526926285363

Epoch: 171| Step: 0
Training loss: 2.5670445779125526
Validation loss: 2.4783423857842144

Epoch: 5| Step: 1
Training loss: 2.4652256012411216
Validation loss: 2.4539892522549436

Epoch: 5| Step: 2
Training loss: 2.0718870689075097
Validation loss: 2.4510041267764704

Epoch: 5| Step: 3
Training loss: 2.3586905794083397
Validation loss: 2.447414408631012

Epoch: 5| Step: 4
Training loss: 2.8533673988816246
Validation loss: 2.462914947758925

Epoch: 5| Step: 5
Training loss: 1.8077094468242327
Validation loss: 2.4768733206768707

Epoch: 5| Step: 6
Training loss: 2.374719803996138
Validation loss: 2.498960444984104

Epoch: 5| Step: 7
Training loss: 2.4588196375827067
Validation loss: 2.5044090338665357

Epoch: 5| Step: 8
Training loss: 2.2195272024695805
Validation loss: 2.5302057820340376

Epoch: 5| Step: 9
Training loss: 2.018569569747388
Validation loss: 2.527384208505869

Epoch: 5| Step: 10
Training loss: 2.9322591252438253
Validation loss: 2.5405574061102056

Epoch: 172| Step: 0
Training loss: 2.2459749671376645
Validation loss: 2.530718222031761

Epoch: 5| Step: 1
Training loss: 2.4473785349988257
Validation loss: 2.5335004852435703

Epoch: 5| Step: 2
Training loss: 2.734418073042444
Validation loss: 2.496178738880996

Epoch: 5| Step: 3
Training loss: 2.222503388684396
Validation loss: 2.4918813754991054

Epoch: 5| Step: 4
Training loss: 1.8776384227941572
Validation loss: 2.4781046414570644

Epoch: 5| Step: 5
Training loss: 2.543379743093454
Validation loss: 2.4676045171685157

Epoch: 5| Step: 6
Training loss: 2.4172369075921245
Validation loss: 2.4491954520464536

Epoch: 5| Step: 7
Training loss: 2.0745504512761643
Validation loss: 2.4418720857241323

Epoch: 5| Step: 8
Training loss: 2.7175716608981446
Validation loss: 2.4569352719412145

Epoch: 5| Step: 9
Training loss: 2.1637227036083786
Validation loss: 2.4583873760219683

Epoch: 5| Step: 10
Training loss: 2.4615762517394097
Validation loss: 2.458150947260959

Epoch: 173| Step: 0
Training loss: 2.3254026330951505
Validation loss: 2.4885492994216083

Epoch: 5| Step: 1
Training loss: 2.0648830402863636
Validation loss: 2.507577501695707

Epoch: 5| Step: 2
Training loss: 2.556341633168617
Validation loss: 2.4938101392668925

Epoch: 5| Step: 3
Training loss: 2.8029378464905466
Validation loss: 2.506815467855499

Epoch: 5| Step: 4
Training loss: 2.328926716445524
Validation loss: 2.4912376654980313

Epoch: 5| Step: 5
Training loss: 2.12626442035896
Validation loss: 2.469515205113668

Epoch: 5| Step: 6
Training loss: 2.6163969297747087
Validation loss: 2.4647290012768384

Epoch: 5| Step: 7
Training loss: 2.1854446564498105
Validation loss: 2.44198153714307

Epoch: 5| Step: 8
Training loss: 2.194283784009732
Validation loss: 2.446210770458101

Epoch: 5| Step: 9
Training loss: 2.5136586909922807
Validation loss: 2.4364593646711654

Epoch: 5| Step: 10
Training loss: 1.6223229585285412
Validation loss: 2.459471402819253

Epoch: 174| Step: 0
Training loss: 2.1417153359114103
Validation loss: 2.5137423027632457

Epoch: 5| Step: 1
Training loss: 2.1215990564082423
Validation loss: 2.544345449348368

Epoch: 5| Step: 2
Training loss: 2.581184282921055
Validation loss: 2.546004423809024

Epoch: 5| Step: 3
Training loss: 2.6343621014950114
Validation loss: 2.536464184702099

Epoch: 5| Step: 4
Training loss: 2.2598295606637047
Validation loss: 2.5142858557778647

Epoch: 5| Step: 5
Training loss: 2.656600659729855
Validation loss: 2.478385526823315

Epoch: 5| Step: 6
Training loss: 1.747629331024175
Validation loss: 2.4496847190516884

Epoch: 5| Step: 7
Training loss: 2.288129284293846
Validation loss: 2.4422933389214063

Epoch: 5| Step: 8
Training loss: 2.4964438895779404
Validation loss: 2.441269328947836

Epoch: 5| Step: 9
Training loss: 2.3658481749628604
Validation loss: 2.461916541881946

Epoch: 5| Step: 10
Training loss: 2.31854746054782
Validation loss: 2.464828728563976

Epoch: 175| Step: 0
Training loss: 2.3257791874741547
Validation loss: 2.452878612682706

Epoch: 5| Step: 1
Training loss: 1.6310692931891553
Validation loss: 2.4367165149028187

Epoch: 5| Step: 2
Training loss: 2.2868761681582126
Validation loss: 2.4200439517678314

Epoch: 5| Step: 3
Training loss: 2.0309548970580997
Validation loss: 2.4302659103470385

Epoch: 5| Step: 4
Training loss: 2.1238877246514347
Validation loss: 2.4381524930441696

Epoch: 5| Step: 5
Training loss: 2.158424607731751
Validation loss: 2.4705369358994984

Epoch: 5| Step: 6
Training loss: 2.7537515366836116
Validation loss: 2.501442497182923

Epoch: 5| Step: 7
Training loss: 2.776221197357609
Validation loss: 2.526369619863623

Epoch: 5| Step: 8
Training loss: 2.1121396632110243
Validation loss: 2.5655536999576993

Epoch: 5| Step: 9
Training loss: 2.809738244324092
Validation loss: 2.602102363393554

Epoch: 5| Step: 10
Training loss: 2.0133580907768933
Validation loss: 2.6146189467370924

Epoch: 176| Step: 0
Training loss: 2.0143751660807627
Validation loss: 2.6229071314146255

Epoch: 5| Step: 1
Training loss: 2.2976385391522967
Validation loss: 2.639015582514981

Epoch: 5| Step: 2
Training loss: 1.9446451658765391
Validation loss: 2.6369630368187336

Epoch: 5| Step: 3
Training loss: 1.8173643149162755
Validation loss: 2.6113247694165946

Epoch: 5| Step: 4
Training loss: 2.6728130277867077
Validation loss: 2.6447934106347852

Epoch: 5| Step: 5
Training loss: 2.5395810580745413
Validation loss: 2.571619144475632

Epoch: 5| Step: 6
Training loss: 2.442522303499905
Validation loss: 2.53327667923721

Epoch: 5| Step: 7
Training loss: 2.4176531017152056
Validation loss: 2.4883740131364176

Epoch: 5| Step: 8
Training loss: 1.8945942976381045
Validation loss: 2.425239938930791

Epoch: 5| Step: 9
Training loss: 2.3451328521380717
Validation loss: 2.404710709597098

Epoch: 5| Step: 10
Training loss: 2.6445844411078845
Validation loss: 2.383327648598658

Epoch: 177| Step: 0
Training loss: 2.1134854427835337
Validation loss: 2.38446550651889

Epoch: 5| Step: 1
Training loss: 1.833907608196831
Validation loss: 2.3767828027643327

Epoch: 5| Step: 2
Training loss: 2.588861385585021
Validation loss: 2.389380994405354

Epoch: 5| Step: 3
Training loss: 2.243591719546164
Validation loss: 2.3991059995047137

Epoch: 5| Step: 4
Training loss: 2.2490736855953175
Validation loss: 2.4070927582809354

Epoch: 5| Step: 5
Training loss: 2.4168761809281807
Validation loss: 2.4399309144863293

Epoch: 5| Step: 6
Training loss: 2.434082178175146
Validation loss: 2.4281807487472333

Epoch: 5| Step: 7
Training loss: 2.1030388506948077
Validation loss: 2.4361218873314923

Epoch: 5| Step: 8
Training loss: 2.2297125768821844
Validation loss: 2.4152563440280885

Epoch: 5| Step: 9
Training loss: 2.3760668717423967
Validation loss: 2.4401836498981786

Epoch: 5| Step: 10
Training loss: 2.260905117812711
Validation loss: 2.4349842240839394

Epoch: 178| Step: 0
Training loss: 1.6285410226885124
Validation loss: 2.4575481763447247

Epoch: 5| Step: 1
Training loss: 2.381735436327819
Validation loss: 2.4870785788302263

Epoch: 5| Step: 2
Training loss: 2.448583687883386
Validation loss: 2.4993565110650002

Epoch: 5| Step: 3
Training loss: 2.306189303129228
Validation loss: 2.5101479306629275

Epoch: 5| Step: 4
Training loss: 2.355468142684934
Validation loss: 2.4955943881639655

Epoch: 5| Step: 5
Training loss: 2.3404911018239924
Validation loss: 2.473035498596164

Epoch: 5| Step: 6
Training loss: 2.2866314682693596
Validation loss: 2.4173908068095193

Epoch: 5| Step: 7
Training loss: 2.765033637147455
Validation loss: 2.4230404402615613

Epoch: 5| Step: 8
Training loss: 2.1392933957057307
Validation loss: 2.4269164752144983

Epoch: 5| Step: 9
Training loss: 2.2860339443593536
Validation loss: 2.480013620901198

Epoch: 5| Step: 10
Training loss: 1.736177624593931
Validation loss: 2.540052971007777

Epoch: 179| Step: 0
Training loss: 2.1315209806565365
Validation loss: 2.532590700677531

Epoch: 5| Step: 1
Training loss: 2.2739307615665076
Validation loss: 2.5004867274740357

Epoch: 5| Step: 2
Training loss: 2.298622556454943
Validation loss: 2.473612308536646

Epoch: 5| Step: 3
Training loss: 2.190644973467922
Validation loss: 2.4409893681795567

Epoch: 5| Step: 4
Training loss: 2.380797487851838
Validation loss: 2.4259411591003364

Epoch: 5| Step: 5
Training loss: 1.9761140940464974
Validation loss: 2.4240419546465244

Epoch: 5| Step: 6
Training loss: 1.6714319372900117
Validation loss: 2.430660527116484

Epoch: 5| Step: 7
Training loss: 2.6910603914207196
Validation loss: 2.4384660218546808

Epoch: 5| Step: 8
Training loss: 2.403259995814625
Validation loss: 2.4432627601919847

Epoch: 5| Step: 9
Training loss: 2.4059699750185826
Validation loss: 2.464315766340013

Epoch: 5| Step: 10
Training loss: 1.88810940940302
Validation loss: 2.4716667763278357

Epoch: 180| Step: 0
Training loss: 2.5115807289182515
Validation loss: 2.477460995375138

Epoch: 5| Step: 1
Training loss: 1.9054683896448
Validation loss: 2.498467480174609

Epoch: 5| Step: 2
Training loss: 2.2113443276668043
Validation loss: 2.4939793292152417

Epoch: 5| Step: 3
Training loss: 2.2388786330933446
Validation loss: 2.4846888043641235

Epoch: 5| Step: 4
Training loss: 2.374160919539553
Validation loss: 2.4690854441907426

Epoch: 5| Step: 5
Training loss: 1.8079011385988508
Validation loss: 2.437484322564019

Epoch: 5| Step: 6
Training loss: 2.205086234173254
Validation loss: 2.4566323736351907

Epoch: 5| Step: 7
Training loss: 2.1565146905729016
Validation loss: 2.4642901018757937

Epoch: 5| Step: 8
Training loss: 1.9026000929178908
Validation loss: 2.4811904576895794

Epoch: 5| Step: 9
Training loss: 2.378915570621365
Validation loss: 2.47119969774185

Epoch: 5| Step: 10
Training loss: 2.154378991451168
Validation loss: 2.4703051973811845

Epoch: 181| Step: 0
Training loss: 2.1385873716895687
Validation loss: 2.463874070362519

Epoch: 5| Step: 1
Training loss: 2.370949553829478
Validation loss: 2.457683388326012

Epoch: 5| Step: 2
Training loss: 1.9849735468680048
Validation loss: 2.4921269820447427

Epoch: 5| Step: 3
Training loss: 2.0827119154799303
Validation loss: 2.51024858493025

Epoch: 5| Step: 4
Training loss: 2.5501108968219572
Validation loss: 2.4992738930603497

Epoch: 5| Step: 5
Training loss: 2.4498221157658087
Validation loss: 2.4693855712601893

Epoch: 5| Step: 6
Training loss: 1.6497737295886798
Validation loss: 2.4538703503559107

Epoch: 5| Step: 7
Training loss: 2.1419765911158852
Validation loss: 2.42709738934914

Epoch: 5| Step: 8
Training loss: 2.3699034164964883
Validation loss: 2.4257967145575905

Epoch: 5| Step: 9
Training loss: 1.920848417188401
Validation loss: 2.405821515039683

Epoch: 5| Step: 10
Training loss: 1.8532732050333287
Validation loss: 2.4059249121364297

Epoch: 182| Step: 0
Training loss: 2.1273635734449825
Validation loss: 2.4219169758610226

Epoch: 5| Step: 1
Training loss: 2.4021459482528873
Validation loss: 2.43216246558447

Epoch: 5| Step: 2
Training loss: 2.4454355422194025
Validation loss: 2.4554842166009543

Epoch: 5| Step: 3
Training loss: 2.3528103480010643
Validation loss: 2.4897736843754856

Epoch: 5| Step: 4
Training loss: 2.1907888484524056
Validation loss: 2.513964567252275

Epoch: 5| Step: 5
Training loss: 1.7669550519363402
Validation loss: 2.5359862234104287

Epoch: 5| Step: 6
Training loss: 2.0450061682349263
Validation loss: 2.5608911153117653

Epoch: 5| Step: 7
Training loss: 1.962963197799418
Validation loss: 2.5588338534335144

Epoch: 5| Step: 8
Training loss: 2.090096887961923
Validation loss: 2.5324448095430494

Epoch: 5| Step: 9
Training loss: 2.0041220624986997
Validation loss: 2.4939292499315107

Epoch: 5| Step: 10
Training loss: 2.1634658376536895
Validation loss: 2.4835867828075395

Epoch: 183| Step: 0
Training loss: 2.2964790677695306
Validation loss: 2.461560146502593

Epoch: 5| Step: 1
Training loss: 2.3237659173495193
Validation loss: 2.4541724096745976

Epoch: 5| Step: 2
Training loss: 2.3129480288777677
Validation loss: 2.4408875861403403

Epoch: 5| Step: 3
Training loss: 2.391248135603374
Validation loss: 2.4643255566332964

Epoch: 5| Step: 4
Training loss: 2.2182068495752243
Validation loss: 2.45961434505181

Epoch: 5| Step: 5
Training loss: 2.2551176362744982
Validation loss: 2.5046831853369578

Epoch: 5| Step: 6
Training loss: 2.03322188692112
Validation loss: 2.543413950209957

Epoch: 5| Step: 7
Training loss: 1.4486550111215433
Validation loss: 2.5860998012724443

Epoch: 5| Step: 8
Training loss: 1.8925908484882552
Validation loss: 2.595909155969137

Epoch: 5| Step: 9
Training loss: 1.8503999561270228
Validation loss: 2.535935293009941

Epoch: 5| Step: 10
Training loss: 2.350642230156592
Validation loss: 2.5161167877547213

Epoch: 184| Step: 0
Training loss: 2.126403233087807
Validation loss: 2.486558335184124

Epoch: 5| Step: 1
Training loss: 2.110293040243047
Validation loss: 2.4931235216792036

Epoch: 5| Step: 2
Training loss: 2.709451141519487
Validation loss: 2.449160682646823

Epoch: 5| Step: 3
Training loss: 1.9507550929481035
Validation loss: 2.434622072933954

Epoch: 5| Step: 4
Training loss: 2.232393680104105
Validation loss: 2.415889312280421

Epoch: 5| Step: 5
Training loss: 2.040061851947565
Validation loss: 2.407538927642015

Epoch: 5| Step: 6
Training loss: 1.7012386549796297
Validation loss: 2.4308118753204933

Epoch: 5| Step: 7
Training loss: 1.9239178476856944
Validation loss: 2.453233195920052

Epoch: 5| Step: 8
Training loss: 1.7833669029475019
Validation loss: 2.445053194297249

Epoch: 5| Step: 9
Training loss: 2.1158964718260873
Validation loss: 2.47046014181984

Epoch: 5| Step: 10
Training loss: 2.4257997275614707
Validation loss: 2.5066703736184666

Epoch: 185| Step: 0
Training loss: 1.6234177442271993
Validation loss: 2.490856239804902

Epoch: 5| Step: 1
Training loss: 2.2258815861932986
Validation loss: 2.4850907943368536

Epoch: 5| Step: 2
Training loss: 2.469263723497683
Validation loss: 2.4891402075503803

Epoch: 5| Step: 3
Training loss: 2.143615304702419
Validation loss: 2.5239676916661566

Epoch: 5| Step: 4
Training loss: 2.6530469543696062
Validation loss: 2.554089664440797

Epoch: 5| Step: 5
Training loss: 2.071305637751925
Validation loss: 2.5690786242256363

Epoch: 5| Step: 6
Training loss: 2.124465201904706
Validation loss: 2.5481099568897307

Epoch: 5| Step: 7
Training loss: 1.7059075259852554
Validation loss: 2.5084670934422055

Epoch: 5| Step: 8
Training loss: 1.8812597686412567
Validation loss: 2.492488724968404

Epoch: 5| Step: 9
Training loss: 1.7907413784375013
Validation loss: 2.4854003406343246

Epoch: 5| Step: 10
Training loss: 2.0751644069389816
Validation loss: 2.4987486517299584

Epoch: 186| Step: 0
Training loss: 2.0684700306802286
Validation loss: 2.5233570999010477

Epoch: 5| Step: 1
Training loss: 1.997799437593707
Validation loss: 2.5390777824705504

Epoch: 5| Step: 2
Training loss: 1.853859486655231
Validation loss: 2.5087125533714674

Epoch: 5| Step: 3
Training loss: 1.9966543944379176
Validation loss: 2.476848926946469

Epoch: 5| Step: 4
Training loss: 2.2052054896371627
Validation loss: 2.4842395813927385

Epoch: 5| Step: 5
Training loss: 2.487834417205627
Validation loss: 2.47267898061569

Epoch: 5| Step: 6
Training loss: 2.276181796464562
Validation loss: 2.496911065367116

Epoch: 5| Step: 7
Training loss: 1.9421417869288735
Validation loss: 2.4803671880252867

Epoch: 5| Step: 8
Training loss: 1.5398089152846888
Validation loss: 2.489221300872356

Epoch: 5| Step: 9
Training loss: 1.9654028155925345
Validation loss: 2.500863070867415

Epoch: 5| Step: 10
Training loss: 2.18287824396564
Validation loss: 2.5161469655013122

Epoch: 187| Step: 0
Training loss: 1.9806825420848064
Validation loss: 2.5923590025736782

Epoch: 5| Step: 1
Training loss: 2.054969681193618
Validation loss: 2.632633270680288

Epoch: 5| Step: 2
Training loss: 2.3611894918658693
Validation loss: 2.6654588908577583

Epoch: 5| Step: 3
Training loss: 1.5802092432946955
Validation loss: 2.6093011042075545

Epoch: 5| Step: 4
Training loss: 1.9860480156978453
Validation loss: 2.560717607351887

Epoch: 5| Step: 5
Training loss: 2.1749263707117943
Validation loss: 2.510550281507521

Epoch: 5| Step: 6
Training loss: 1.9776711351537166
Validation loss: 2.478868280579691

Epoch: 5| Step: 7
Training loss: 1.9717328318083889
Validation loss: 2.4488486351017813

Epoch: 5| Step: 8
Training loss: 2.1566399484283374
Validation loss: 2.4295314789766347

Epoch: 5| Step: 9
Training loss: 2.156389646569193
Validation loss: 2.4409412622130615

Epoch: 5| Step: 10
Training loss: 2.0304278543895875
Validation loss: 2.433915663638452

Epoch: 188| Step: 0
Training loss: 1.8918765630800654
Validation loss: 2.40182885241952

Epoch: 5| Step: 1
Training loss: 2.02049459653121
Validation loss: 2.4305636638343993

Epoch: 5| Step: 2
Training loss: 1.74840957032942
Validation loss: 2.4124469830528206

Epoch: 5| Step: 3
Training loss: 1.6811407854988603
Validation loss: 2.435975973225673

Epoch: 5| Step: 4
Training loss: 1.7890207877148137
Validation loss: 2.4295906324820704

Epoch: 5| Step: 5
Training loss: 1.3761835639710567
Validation loss: 2.4285752187495766

Epoch: 5| Step: 6
Training loss: 2.2794193604286646
Validation loss: 2.472776741446509

Epoch: 5| Step: 7
Training loss: 1.902011160788698
Validation loss: 2.479703366501087

Epoch: 5| Step: 8
Training loss: 2.6267478210318194
Validation loss: 2.4769885304015817

Epoch: 5| Step: 9
Training loss: 2.3186022688288017
Validation loss: 2.48628274660806

Epoch: 5| Step: 10
Training loss: 2.266686657742624
Validation loss: 2.4471401961607144

Epoch: 189| Step: 0
Training loss: 1.6861043032627974
Validation loss: 2.4447601123238423

Epoch: 5| Step: 1
Training loss: 1.6956048528793948
Validation loss: 2.4634386370741277

Epoch: 5| Step: 2
Training loss: 1.6797781276650088
Validation loss: 2.434175787175041

Epoch: 5| Step: 3
Training loss: 2.0673504062395796
Validation loss: 2.4399199756018195

Epoch: 5| Step: 4
Training loss: 2.3703057929631233
Validation loss: 2.4383735716302515

Epoch: 5| Step: 5
Training loss: 2.114320961095046
Validation loss: 2.451458317433297

Epoch: 5| Step: 6
Training loss: 1.836086056157291
Validation loss: 2.466886548943035

Epoch: 5| Step: 7
Training loss: 2.0227077744258204
Validation loss: 2.5096250652785144

Epoch: 5| Step: 8
Training loss: 2.31363670661162
Validation loss: 2.5262350955776416

Epoch: 5| Step: 9
Training loss: 2.3372444910761208
Validation loss: 2.52259875251498

Epoch: 5| Step: 10
Training loss: 1.698829623862224
Validation loss: 2.5257402049657145

Epoch: 190| Step: 0
Training loss: 1.5513143319831126
Validation loss: 2.5294359016986663

Epoch: 5| Step: 1
Training loss: 2.050250349807849
Validation loss: 2.493245351923806

Epoch: 5| Step: 2
Training loss: 2.043866924709241
Validation loss: 2.4715969388691956

Epoch: 5| Step: 3
Training loss: 2.6156938076653744
Validation loss: 2.455551868862778

Epoch: 5| Step: 4
Training loss: 1.4171513494993029
Validation loss: 2.422822378624557

Epoch: 5| Step: 5
Training loss: 2.1586102822243998
Validation loss: 2.3950856840350663

Epoch: 5| Step: 6
Training loss: 1.3920002255850643
Validation loss: 2.3949452514910923

Epoch: 5| Step: 7
Training loss: 1.8698423656790975
Validation loss: 2.401594175338188

Epoch: 5| Step: 8
Training loss: 1.8804141396048322
Validation loss: 2.401162281138424

Epoch: 5| Step: 9
Training loss: 2.1993897068391606
Validation loss: 2.4439282682965167

Epoch: 5| Step: 10
Training loss: 2.2596045117655135
Validation loss: 2.4516156827503934

Epoch: 191| Step: 0
Training loss: 1.9025935140277235
Validation loss: 2.477474200237304

Epoch: 5| Step: 1
Training loss: 1.7376707226425205
Validation loss: 2.473306011905568

Epoch: 5| Step: 2
Training loss: 1.8033888466776007
Validation loss: 2.5103790640530588

Epoch: 5| Step: 3
Training loss: 1.776782808760152
Validation loss: 2.495661699924099

Epoch: 5| Step: 4
Training loss: 1.9190563839515389
Validation loss: 2.50952356772933

Epoch: 5| Step: 5
Training loss: 1.6995915146531264
Validation loss: 2.5002975620054175

Epoch: 5| Step: 6
Training loss: 2.0635994957169244
Validation loss: 2.489762057335714

Epoch: 5| Step: 7
Training loss: 2.043139594613195
Validation loss: 2.483496702314885

Epoch: 5| Step: 8
Training loss: 2.0326278708235748
Validation loss: 2.451653035713243

Epoch: 5| Step: 9
Training loss: 2.32974995478853
Validation loss: 2.4193336058953063

Epoch: 5| Step: 10
Training loss: 2.1410958544936474
Validation loss: 2.4061132231546285

Epoch: 192| Step: 0
Training loss: 2.187512860941546
Validation loss: 2.409222813506038

Epoch: 5| Step: 1
Training loss: 2.109058497667154
Validation loss: 2.457472624636236

Epoch: 5| Step: 2
Training loss: 1.9840651142525525
Validation loss: 2.4654365756084733

Epoch: 5| Step: 3
Training loss: 1.9400416285187652
Validation loss: 2.4576782958447723

Epoch: 5| Step: 4
Training loss: 1.532954143547511
Validation loss: 2.4198672872042932

Epoch: 5| Step: 5
Training loss: 2.0765586055033083
Validation loss: 2.3904100203870575

Epoch: 5| Step: 6
Training loss: 2.1568341776882027
Validation loss: 2.3927511183893335

Epoch: 5| Step: 7
Training loss: 1.4983362666869737
Validation loss: 2.376592487565823

Epoch: 5| Step: 8
Training loss: 2.0231176882126474
Validation loss: 2.4050423316742617

Epoch: 5| Step: 9
Training loss: 1.63931229163482
Validation loss: 2.3993255252857026

Epoch: 5| Step: 10
Training loss: 2.1765974558195587
Validation loss: 2.3976211208631737

Epoch: 193| Step: 0
Training loss: 1.5438376768596676
Validation loss: 2.420738632138535

Epoch: 5| Step: 1
Training loss: 1.700466916532754
Validation loss: 2.4525334005598656

Epoch: 5| Step: 2
Training loss: 1.8582811744566117
Validation loss: 2.5152816777670286

Epoch: 5| Step: 3
Training loss: 1.9202847608358413
Validation loss: 2.5632308700024224

Epoch: 5| Step: 4
Training loss: 1.9967726655865077
Validation loss: 2.5857311146964803

Epoch: 5| Step: 5
Training loss: 1.626546417362029
Validation loss: 2.6081994360800067

Epoch: 5| Step: 6
Training loss: 2.2754101142539813
Validation loss: 2.585091918858489

Epoch: 5| Step: 7
Training loss: 1.9765773365534447
Validation loss: 2.544902382599561

Epoch: 5| Step: 8
Training loss: 1.8890213904313207
Validation loss: 2.4818307690104553

Epoch: 5| Step: 9
Training loss: 2.013185784678501
Validation loss: 2.414280894117278

Epoch: 5| Step: 10
Training loss: 2.410027746302012
Validation loss: 2.371442275986122

Epoch: 194| Step: 0
Training loss: 1.7042097784183763
Validation loss: 2.360094934846202

Epoch: 5| Step: 1
Training loss: 2.440365793918994
Validation loss: 2.3563238074968207

Epoch: 5| Step: 2
Training loss: 2.3845021745156316
Validation loss: 2.3346487005939394

Epoch: 5| Step: 3
Training loss: 1.7046432027821845
Validation loss: 2.3702389988717107

Epoch: 5| Step: 4
Training loss: 2.5406333407069233
Validation loss: 2.3695023425087145

Epoch: 5| Step: 5
Training loss: 1.8300362402032244
Validation loss: 2.382600347931334

Epoch: 5| Step: 6
Training loss: 1.607493365379394
Validation loss: 2.396630897471839

Epoch: 5| Step: 7
Training loss: 1.3565272175370995
Validation loss: 2.409774058842807

Epoch: 5| Step: 8
Training loss: 1.8503549879595198
Validation loss: 2.4174279727732535

Epoch: 5| Step: 9
Training loss: 1.6278311934764478
Validation loss: 2.44837644749727

Epoch: 5| Step: 10
Training loss: 1.4255003770060393
Validation loss: 2.472468333913805

Epoch: 195| Step: 0
Training loss: 1.7609525989606116
Validation loss: 2.464781981851787

Epoch: 5| Step: 1
Training loss: 1.667406903231729
Validation loss: 2.458216565506432

Epoch: 5| Step: 2
Training loss: 2.321711673870839
Validation loss: 2.4494275790741207

Epoch: 5| Step: 3
Training loss: 2.3100185999596246
Validation loss: 2.4206572912591913

Epoch: 5| Step: 4
Training loss: 1.6981257288499152
Validation loss: 2.381766003030777

Epoch: 5| Step: 5
Training loss: 1.5672136542285766
Validation loss: 2.353983437909539

Epoch: 5| Step: 6
Training loss: 1.8077354289435552
Validation loss: 2.356157947329678

Epoch: 5| Step: 7
Training loss: 1.789648901108679
Validation loss: 2.34259232673505

Epoch: 5| Step: 8
Training loss: 2.1180974264818055
Validation loss: 2.3357032150531745

Epoch: 5| Step: 9
Training loss: 1.7589633819255812
Validation loss: 2.332424540768441

Epoch: 5| Step: 10
Training loss: 1.807882609940782
Validation loss: 2.3329851682556586

Epoch: 196| Step: 0
Training loss: 1.6644969963947307
Validation loss: 2.373298226386974

Epoch: 5| Step: 1
Training loss: 2.032062192077773
Validation loss: 2.374821636235814

Epoch: 5| Step: 2
Training loss: 1.4426202391388971
Validation loss: 2.392900357139438

Epoch: 5| Step: 3
Training loss: 1.429468857352914
Validation loss: 2.396723006295663

Epoch: 5| Step: 4
Training loss: 1.4145667088711071
Validation loss: 2.440422536821797

Epoch: 5| Step: 5
Training loss: 1.670701087163753
Validation loss: 2.4857872789874684

Epoch: 5| Step: 6
Training loss: 1.6347842927548242
Validation loss: 2.475417754307758

Epoch: 5| Step: 7
Training loss: 2.4228612060846975
Validation loss: 2.4994088022502137

Epoch: 5| Step: 8
Training loss: 2.013726693414542
Validation loss: 2.494341073294393

Epoch: 5| Step: 9
Training loss: 2.1317453474367802
Validation loss: 2.439118007377181

Epoch: 5| Step: 10
Training loss: 2.2506094213199197
Validation loss: 2.414883111020324

Epoch: 197| Step: 0
Training loss: 2.143689600146468
Validation loss: 2.3992948553285216

Epoch: 5| Step: 1
Training loss: 2.2624394614197647
Validation loss: 2.3794257911768466

Epoch: 5| Step: 2
Training loss: 2.04075172579953
Validation loss: 2.3717991924794437

Epoch: 5| Step: 3
Training loss: 1.801196598635314
Validation loss: 2.381772859442079

Epoch: 5| Step: 4
Training loss: 1.8882205901308295
Validation loss: 2.3688879667000045

Epoch: 5| Step: 5
Training loss: 1.4852742733682276
Validation loss: 2.3823080345530725

Epoch: 5| Step: 6
Training loss: 1.451119300023396
Validation loss: 2.381467568020523

Epoch: 5| Step: 7
Training loss: 1.7312617497785647
Validation loss: 2.359707534066627

Epoch: 5| Step: 8
Training loss: 1.791280113334453
Validation loss: 2.3952607514373563

Epoch: 5| Step: 9
Training loss: 1.5379617695416012
Validation loss: 2.376094792464398

Epoch: 5| Step: 10
Training loss: 1.9176131344161997
Validation loss: 2.3782878908396636

Epoch: 198| Step: 0
Training loss: 1.4522459591287091
Validation loss: 2.3827256957323697

Epoch: 5| Step: 1
Training loss: 2.121444532638036
Validation loss: 2.373626155109519

Epoch: 5| Step: 2
Training loss: 1.4033097789053168
Validation loss: 2.389403304825761

Epoch: 5| Step: 3
Training loss: 2.1297696383919007
Validation loss: 2.410216948268307

Epoch: 5| Step: 4
Training loss: 1.8477710260787954
Validation loss: 2.4280831572656143

Epoch: 5| Step: 5
Training loss: 1.4239629150555042
Validation loss: 2.437056467170832

Epoch: 5| Step: 6
Training loss: 1.7923500472889222
Validation loss: 2.457553788593145

Epoch: 5| Step: 7
Training loss: 2.215312282515429
Validation loss: 2.4685064055168553

Epoch: 5| Step: 8
Training loss: 1.5385297443786288
Validation loss: 2.423437447995946

Epoch: 5| Step: 9
Training loss: 1.5699901344815466
Validation loss: 2.4135209803079087

Epoch: 5| Step: 10
Training loss: 2.1419630115282398
Validation loss: 2.368341904189155

Epoch: 199| Step: 0
Training loss: 1.6779351608334518
Validation loss: 2.4013497336456764

Epoch: 5| Step: 1
Training loss: 1.90720793621697
Validation loss: 2.37350586554522

Epoch: 5| Step: 2
Training loss: 1.5531051480964517
Validation loss: 2.3616972829231906

Epoch: 5| Step: 3
Training loss: 2.2992504059365126
Validation loss: 2.33822596451852

Epoch: 5| Step: 4
Training loss: 1.259027214398509
Validation loss: 2.3631767041682754

Epoch: 5| Step: 5
Training loss: 1.5311650622418864
Validation loss: 2.3389900180232734

Epoch: 5| Step: 6
Training loss: 2.0477665713914277
Validation loss: 2.3470804851842213

Epoch: 5| Step: 7
Training loss: 1.7818049185521094
Validation loss: 2.347376002047762

Epoch: 5| Step: 8
Training loss: 1.8634163669563024
Validation loss: 2.339165864868312

Epoch: 5| Step: 9
Training loss: 1.8210671624624322
Validation loss: 2.3541562029966925

Epoch: 5| Step: 10
Training loss: 1.741871347522773
Validation loss: 2.361280357967248

Epoch: 200| Step: 0
Training loss: 1.4883510142718215
Validation loss: 2.3856417316064515

Epoch: 5| Step: 1
Training loss: 2.0345381898368338
Validation loss: 2.3971869056257504

Epoch: 5| Step: 2
Training loss: 1.9555484842343551
Validation loss: 2.4440859160038357

Epoch: 5| Step: 3
Training loss: 1.2472341933144382
Validation loss: 2.466378624088875

Epoch: 5| Step: 4
Training loss: 1.5011481023886937
Validation loss: 2.4811651020936583

Epoch: 5| Step: 5
Training loss: 1.9674864453208725
Validation loss: 2.454273346730139

Epoch: 5| Step: 6
Training loss: 1.7224565939562466
Validation loss: 2.4795192858270667

Epoch: 5| Step: 7
Training loss: 1.993796084358686
Validation loss: 2.449341698562857

Epoch: 5| Step: 8
Training loss: 1.923402938718198
Validation loss: 2.4359445702205376

Epoch: 5| Step: 9
Training loss: 1.83574672275912
Validation loss: 2.427802113104693

Epoch: 5| Step: 10
Training loss: 1.566184011471221
Validation loss: 2.4246657874998516

Epoch: 201| Step: 0
Training loss: 1.7105903447480246
Validation loss: 2.4339120508206222

Epoch: 5| Step: 1
Training loss: 1.7618813450250115
Validation loss: 2.4478242129266996

Epoch: 5| Step: 2
Training loss: 2.0378839002413844
Validation loss: 2.497411223299159

Epoch: 5| Step: 3
Training loss: 1.5239816329680294
Validation loss: 2.488638540829303

Epoch: 5| Step: 4
Training loss: 2.0869337124718323
Validation loss: 2.4834814958900955

Epoch: 5| Step: 5
Training loss: 1.9138205239066803
Validation loss: 2.4466038266174004

Epoch: 5| Step: 6
Training loss: 1.8044363400293473
Validation loss: 2.4297812223880793

Epoch: 5| Step: 7
Training loss: 1.6349186067999213
Validation loss: 2.423432378758948

Epoch: 5| Step: 8
Training loss: 1.5604321338547393
Validation loss: 2.3944293791091247

Epoch: 5| Step: 9
Training loss: 1.7687983395067044
Validation loss: 2.4041223419085

Epoch: 5| Step: 10
Training loss: 1.3836417001937589
Validation loss: 2.4176720644876806

Epoch: 202| Step: 0
Training loss: 1.5925289038845234
Validation loss: 2.4095225662278428

Epoch: 5| Step: 1
Training loss: 1.8145368903691708
Validation loss: 2.4041681604840504

Epoch: 5| Step: 2
Training loss: 1.3460452858673941
Validation loss: 2.4219917324804325

Epoch: 5| Step: 3
Training loss: 1.5907683062497509
Validation loss: 2.4387228727180394

Epoch: 5| Step: 4
Training loss: 2.0583350002678467
Validation loss: 2.457215470206359

Epoch: 5| Step: 5
Training loss: 1.4262455432497914
Validation loss: 2.4684066616789133

Epoch: 5| Step: 6
Training loss: 1.2526692501086816
Validation loss: 2.4216222995759837

Epoch: 5| Step: 7
Training loss: 1.9216341937790677
Validation loss: 2.3787210913971255

Epoch: 5| Step: 8
Training loss: 1.758479284342905
Validation loss: 2.3735336911022915

Epoch: 5| Step: 9
Training loss: 2.272955879504875
Validation loss: 2.3996711442416165

Epoch: 5| Step: 10
Training loss: 1.7590209875801126
Validation loss: 2.4012769916949357

Epoch: 203| Step: 0
Training loss: 2.2141761379113554
Validation loss: 2.4061210229126253

Epoch: 5| Step: 1
Training loss: 1.5349145752438142
Validation loss: 2.4067628577887206

Epoch: 5| Step: 2
Training loss: 1.7671384823153877
Validation loss: 2.4130151238553017

Epoch: 5| Step: 3
Training loss: 1.4898709195184603
Validation loss: 2.4158852979158008

Epoch: 5| Step: 4
Training loss: 1.3769252909559344
Validation loss: 2.4328570207644824

Epoch: 5| Step: 5
Training loss: 1.8419513657825173
Validation loss: 2.43703047250782

Epoch: 5| Step: 6
Training loss: 1.3675545771864306
Validation loss: 2.4710768272774355

Epoch: 5| Step: 7
Training loss: 1.9202630951549993
Validation loss: 2.4635605492113513

Epoch: 5| Step: 8
Training loss: 1.2499930858420838
Validation loss: 2.449759228996712

Epoch: 5| Step: 9
Training loss: 1.8517081287914081
Validation loss: 2.465781258008085

Epoch: 5| Step: 10
Training loss: 1.8291207886361076
Validation loss: 2.454990571892819

Epoch: 204| Step: 0
Training loss: 1.541170796558194
Validation loss: 2.4454133823708406

Epoch: 5| Step: 1
Training loss: 1.678810706954708
Validation loss: 2.4320963146313845

Epoch: 5| Step: 2
Training loss: 1.3505579572469961
Validation loss: 2.410377251783743

Epoch: 5| Step: 3
Training loss: 1.9654247721713232
Validation loss: 2.378899557751939

Epoch: 5| Step: 4
Training loss: 1.9894144542447803
Validation loss: 2.3866210550153713

Epoch: 5| Step: 5
Training loss: 1.7287720915623377
Validation loss: 2.384032583058353

Epoch: 5| Step: 6
Training loss: 1.9130318494300071
Validation loss: 2.4106316850675094

Epoch: 5| Step: 7
Training loss: 1.8254417877570082
Validation loss: 2.3962316373689734

Epoch: 5| Step: 8
Training loss: 1.711118784318924
Validation loss: 2.394917077929906

Epoch: 5| Step: 9
Training loss: 0.9540506776888753
Validation loss: 2.3609697211114047

Epoch: 5| Step: 10
Training loss: 1.6457131820795166
Validation loss: 2.3923186993329804

Epoch: 205| Step: 0
Training loss: 1.0497288308349604
Validation loss: 2.377839427443712

Epoch: 5| Step: 1
Training loss: 2.0667111725270644
Validation loss: 2.4204177023384963

Epoch: 5| Step: 2
Training loss: 1.822745861952347
Validation loss: 2.423335409576402

Epoch: 5| Step: 3
Training loss: 1.5271169196473442
Validation loss: 2.3877140794248812

Epoch: 5| Step: 4
Training loss: 2.010009276335458
Validation loss: 2.408100439992113

Epoch: 5| Step: 5
Training loss: 1.9830123548137244
Validation loss: 2.4035305546207346

Epoch: 5| Step: 6
Training loss: 1.1232778295129797
Validation loss: 2.395434576363253

Epoch: 5| Step: 7
Training loss: 2.011178960879192
Validation loss: 2.38211535458471

Epoch: 5| Step: 8
Training loss: 1.4927288890771158
Validation loss: 2.375527773916893

Epoch: 5| Step: 9
Training loss: 1.2820513940468763
Validation loss: 2.4025894478258225

Epoch: 5| Step: 10
Training loss: 1.5649315796542107
Validation loss: 2.383109067431682

Epoch: 206| Step: 0
Training loss: 1.7098167615725075
Validation loss: 2.40487389488602

Epoch: 5| Step: 1
Training loss: 1.777113142877828
Validation loss: 2.407655173277108

Epoch: 5| Step: 2
Training loss: 1.3773187679420442
Validation loss: 2.4468128065738592

Epoch: 5| Step: 3
Training loss: 1.5553564424843234
Validation loss: 2.465300630421846

Epoch: 5| Step: 4
Training loss: 1.8758115919297356
Validation loss: 2.5375794386197987

Epoch: 5| Step: 5
Training loss: 1.6999237351981742
Validation loss: 2.5504694208804697

Epoch: 5| Step: 6
Training loss: 1.7555835749137891
Validation loss: 2.527148246034574

Epoch: 5| Step: 7
Training loss: 1.5613217298096604
Validation loss: 2.4904116035658155

Epoch: 5| Step: 8
Training loss: 1.4854117537422133
Validation loss: 2.4597151609322867

Epoch: 5| Step: 9
Training loss: 1.7518553435426958
Validation loss: 2.395939904224009

Epoch: 5| Step: 10
Training loss: 1.7703780617488476
Validation loss: 2.366506556505823

Epoch: 207| Step: 0
Training loss: 2.20457378394275
Validation loss: 2.35705112296884

Epoch: 5| Step: 1
Training loss: 1.598464723953696
Validation loss: 2.3142208358192042

Epoch: 5| Step: 2
Training loss: 2.1383427614919457
Validation loss: 2.3036583890272255

Epoch: 5| Step: 3
Training loss: 1.7588965570027375
Validation loss: 2.2998379800744777

Epoch: 5| Step: 4
Training loss: 1.4050166337464216
Validation loss: 2.3500374958797083

Epoch: 5| Step: 5
Training loss: 1.3610602707785697
Validation loss: 2.360054184024133

Epoch: 5| Step: 6
Training loss: 1.5465372660920191
Validation loss: 2.4051508199498945

Epoch: 5| Step: 7
Training loss: 1.2775377132126962
Validation loss: 2.353819537744272

Epoch: 5| Step: 8
Training loss: 1.337910672893818
Validation loss: 2.3601385764963725

Epoch: 5| Step: 9
Training loss: 1.6065120230971928
Validation loss: 2.3554902671370326

Epoch: 5| Step: 10
Training loss: 1.8758179469969571
Validation loss: 2.387197253834946

Epoch: 208| Step: 0
Training loss: 1.6290839301887183
Validation loss: 2.4155040970775876

Epoch: 5| Step: 1
Training loss: 1.8092346374146238
Validation loss: 2.423955111267438

Epoch: 5| Step: 2
Training loss: 1.6418383516622126
Validation loss: 2.4353480193522237

Epoch: 5| Step: 3
Training loss: 1.8058456073808007
Validation loss: 2.4532300807585585

Epoch: 5| Step: 4
Training loss: 1.9143695195811128
Validation loss: 2.467965334287578

Epoch: 5| Step: 5
Training loss: 1.2019747896073714
Validation loss: 2.453589758064599

Epoch: 5| Step: 6
Training loss: 1.099960352443224
Validation loss: 2.446845853336988

Epoch: 5| Step: 7
Training loss: 1.5730054548184733
Validation loss: 2.4454177676004467

Epoch: 5| Step: 8
Training loss: 1.9804581560983914
Validation loss: 2.411933010403164

Epoch: 5| Step: 9
Training loss: 1.6020413310973565
Validation loss: 2.3725342010107937

Epoch: 5| Step: 10
Training loss: 1.5354158216014315
Validation loss: 2.3749722455944533

Epoch: 209| Step: 0
Training loss: 1.735598158609926
Validation loss: 2.3476444345302188

Epoch: 5| Step: 1
Training loss: 1.476818647822995
Validation loss: 2.3554768083377713

Epoch: 5| Step: 2
Training loss: 1.688776875359002
Validation loss: 2.335584927156733

Epoch: 5| Step: 3
Training loss: 1.6226466083561575
Validation loss: 2.353963760603465

Epoch: 5| Step: 4
Training loss: 1.503462371715592
Validation loss: 2.387199996605536

Epoch: 5| Step: 5
Training loss: 1.2223701507943403
Validation loss: 2.3862053879768133

Epoch: 5| Step: 6
Training loss: 1.3695680220564037
Validation loss: 2.3976972701018826

Epoch: 5| Step: 7
Training loss: 1.4800047134633658
Validation loss: 2.4077290960649083

Epoch: 5| Step: 8
Training loss: 1.9739556291573421
Validation loss: 2.4112063628655602

Epoch: 5| Step: 9
Training loss: 1.6454516664429044
Validation loss: 2.415867327105815

Epoch: 5| Step: 10
Training loss: 2.1491465005548522
Validation loss: 2.3925560884881873

Epoch: 210| Step: 0
Training loss: 1.3716270083599844
Validation loss: 2.409286203971024

Epoch: 5| Step: 1
Training loss: 1.7329293489401028
Validation loss: 2.4363482909378065

Epoch: 5| Step: 2
Training loss: 1.556865221235575
Validation loss: 2.4575597356847796

Epoch: 5| Step: 3
Training loss: 1.5036417939154192
Validation loss: 2.4312226538961967

Epoch: 5| Step: 4
Training loss: 1.4705842921260253
Validation loss: 2.431296547613017

Epoch: 5| Step: 5
Training loss: 1.837043980694424
Validation loss: 2.418567257703711

Epoch: 5| Step: 6
Training loss: 1.898763997451389
Validation loss: 2.4195161487099166

Epoch: 5| Step: 7
Training loss: 1.5110416127956157
Validation loss: 2.4069869531413124

Epoch: 5| Step: 8
Training loss: 1.7263450658256765
Validation loss: 2.4004162586995856

Epoch: 5| Step: 9
Training loss: 1.5320331361439021
Validation loss: 2.4169997055452206

Epoch: 5| Step: 10
Training loss: 1.3481801659372756
Validation loss: 2.4379895593957563

Epoch: 211| Step: 0
Training loss: 1.432298953875875
Validation loss: 2.421811059378313

Epoch: 5| Step: 1
Training loss: 1.816239281640453
Validation loss: 2.4557755593918063

Epoch: 5| Step: 2
Training loss: 1.2912876690875132
Validation loss: 2.4302507780361036

Epoch: 5| Step: 3
Training loss: 1.6916090775382226
Validation loss: 2.459366936893314

Epoch: 5| Step: 4
Training loss: 1.5888913462841412
Validation loss: 2.4378342221858817

Epoch: 5| Step: 5
Training loss: 1.2777784815155155
Validation loss: 2.4349405425523254

Epoch: 5| Step: 6
Training loss: 1.425802904774552
Validation loss: 2.4174870483633133

Epoch: 5| Step: 7
Training loss: 1.4731125668505571
Validation loss: 2.3864935828860085

Epoch: 5| Step: 8
Training loss: 1.9540300637375656
Validation loss: 2.3900782950425423

Epoch: 5| Step: 9
Training loss: 1.853520577266336
Validation loss: 2.391228887166319

Epoch: 5| Step: 10
Training loss: 1.4153496379700765
Validation loss: 2.4108848069599906

Epoch: 212| Step: 0
Training loss: 1.5176904506672733
Validation loss: 2.4164111865499853

Epoch: 5| Step: 1
Training loss: 1.7712657923993842
Validation loss: 2.401528647519636

Epoch: 5| Step: 2
Training loss: 1.5557325674947222
Validation loss: 2.4665352214566294

Epoch: 5| Step: 3
Training loss: 1.5195408210354906
Validation loss: 2.467078818144414

Epoch: 5| Step: 4
Training loss: 1.722766275849639
Validation loss: 2.4312173119676377

Epoch: 5| Step: 5
Training loss: 1.381543196547836
Validation loss: 2.411763592206443

Epoch: 5| Step: 6
Training loss: 1.457262772479768
Validation loss: 2.36821693333482

Epoch: 5| Step: 7
Training loss: 1.7220961163951893
Validation loss: 2.3749954847499066

Epoch: 5| Step: 8
Training loss: 1.3980071188727707
Validation loss: 2.3835515595370604

Epoch: 5| Step: 9
Training loss: 1.857268221784389
Validation loss: 2.3637044390933153

Epoch: 5| Step: 10
Training loss: 1.738584341992413
Validation loss: 2.3946090059570713

Epoch: 213| Step: 0
Training loss: 1.542459524603574
Validation loss: 2.4320944415184096

Epoch: 5| Step: 1
Training loss: 1.416322535435889
Validation loss: 2.487242397986803

Epoch: 5| Step: 2
Training loss: 1.7658687187035045
Validation loss: 2.5315750320531296

Epoch: 5| Step: 3
Training loss: 1.5395212796739277
Validation loss: 2.5588042016654793

Epoch: 5| Step: 4
Training loss: 1.2881139791240221
Validation loss: 2.5375870681681314

Epoch: 5| Step: 5
Training loss: 1.5654379879546394
Validation loss: 2.47364036982171

Epoch: 5| Step: 6
Training loss: 1.315721010886487
Validation loss: 2.447091118434252

Epoch: 5| Step: 7
Training loss: 1.8766894041121551
Validation loss: 2.387723525642035

Epoch: 5| Step: 8
Training loss: 1.5833409292473875
Validation loss: 2.3627821561144677

Epoch: 5| Step: 9
Training loss: 1.124279109137731
Validation loss: 2.3622834603329914

Epoch: 5| Step: 10
Training loss: 2.1499132671161005
Validation loss: 2.3572599529041156

Epoch: 214| Step: 0
Training loss: 1.4503134322949442
Validation loss: 2.3349247744601227

Epoch: 5| Step: 1
Training loss: 1.627622835179395
Validation loss: 2.3470112480324916

Epoch: 5| Step: 2
Training loss: 1.5714834222262057
Validation loss: 2.348637619663446

Epoch: 5| Step: 3
Training loss: 1.2950425127776417
Validation loss: 2.3801921474947347

Epoch: 5| Step: 4
Training loss: 1.5573162302314782
Validation loss: 2.3895942813974993

Epoch: 5| Step: 5
Training loss: 1.1625670485490853
Validation loss: 2.4098304656924077

Epoch: 5| Step: 6
Training loss: 1.4475990971720807
Validation loss: 2.392650208884705

Epoch: 5| Step: 7
Training loss: 1.2564091406083155
Validation loss: 2.3956922456592595

Epoch: 5| Step: 8
Training loss: 1.7387580132042686
Validation loss: 2.379257418970866

Epoch: 5| Step: 9
Training loss: 1.8244763341546475
Validation loss: 2.3993454599065527

Epoch: 5| Step: 10
Training loss: 1.9954175904992
Validation loss: 2.3923396975042546

Epoch: 215| Step: 0
Training loss: 1.403778956888244
Validation loss: 2.3975196566031434

Epoch: 5| Step: 1
Training loss: 1.5589450067506794
Validation loss: 2.4045467519927484

Epoch: 5| Step: 2
Training loss: 1.7038101078214098
Validation loss: 2.423389380793502

Epoch: 5| Step: 3
Training loss: 1.118179947519535
Validation loss: 2.398767563306615

Epoch: 5| Step: 4
Training loss: 1.2255665325437144
Validation loss: 2.3954726753370004

Epoch: 5| Step: 5
Training loss: 2.2187646140033683
Validation loss: 2.417776862324971

Epoch: 5| Step: 6
Training loss: 1.552594793991605
Validation loss: 2.425049379296576

Epoch: 5| Step: 7
Training loss: 1.4873026035667443
Validation loss: 2.4265130906613064

Epoch: 5| Step: 8
Training loss: 1.068780679987418
Validation loss: 2.4232163751922893

Epoch: 5| Step: 9
Training loss: 1.558726828493915
Validation loss: 2.4534514689169136

Epoch: 5| Step: 10
Training loss: 1.6800572188033862
Validation loss: 2.4267486655945443

Epoch: 216| Step: 0
Training loss: 1.850421602305125
Validation loss: 2.46769976236375

Epoch: 5| Step: 1
Training loss: 1.5162003988155015
Validation loss: 2.4569249471769936

Epoch: 5| Step: 2
Training loss: 1.155658312782115
Validation loss: 2.4753566839589145

Epoch: 5| Step: 3
Training loss: 1.8456061766659577
Validation loss: 2.4797434009745367

Epoch: 5| Step: 4
Training loss: 1.0094991365516903
Validation loss: 2.452615511920835

Epoch: 5| Step: 5
Training loss: 2.094854945803532
Validation loss: 2.4208250015734145

Epoch: 5| Step: 6
Training loss: 1.2192057222136932
Validation loss: 2.3922519068842196

Epoch: 5| Step: 7
Training loss: 1.0417644963419626
Validation loss: 2.396596997837958

Epoch: 5| Step: 8
Training loss: 1.588792833160532
Validation loss: 2.389421710712128

Epoch: 5| Step: 9
Training loss: 1.5944511516812474
Validation loss: 2.390036923277798

Epoch: 5| Step: 10
Training loss: 1.473587106206982
Validation loss: 2.387446061529942

Epoch: 217| Step: 0
Training loss: 1.1823128293645901
Validation loss: 2.4060253112452505

Epoch: 5| Step: 1
Training loss: 1.433160201787018
Validation loss: 2.4492757002016403

Epoch: 5| Step: 2
Training loss: 1.4806502339188203
Validation loss: 2.4366233486095115

Epoch: 5| Step: 3
Training loss: 1.5091393517827854
Validation loss: 2.431632041001739

Epoch: 5| Step: 4
Training loss: 1.430670561791978
Validation loss: 2.455020964799287

Epoch: 5| Step: 5
Training loss: 1.5837204945020478
Validation loss: 2.4071831185060844

Epoch: 5| Step: 6
Training loss: 1.3827631882318114
Validation loss: 2.4027590295586276

Epoch: 5| Step: 7
Training loss: 1.1145865835457351
Validation loss: 2.3804663749411668

Epoch: 5| Step: 8
Training loss: 1.7341940158200944
Validation loss: 2.3771879408276826

Epoch: 5| Step: 9
Training loss: 1.7773377135457245
Validation loss: 2.3758597909057864

Epoch: 5| Step: 10
Training loss: 1.8560978836770121
Validation loss: 2.3891847247561553

Epoch: 218| Step: 0
Training loss: 1.4946518765079888
Validation loss: 2.4043852973922477

Epoch: 5| Step: 1
Training loss: 2.0276012808342094
Validation loss: 2.3952845194071277

Epoch: 5| Step: 2
Training loss: 1.542593376758531
Validation loss: 2.4156601305120793

Epoch: 5| Step: 3
Training loss: 1.4498876791234467
Validation loss: 2.3838390036204817

Epoch: 5| Step: 4
Training loss: 0.8608399822302072
Validation loss: 2.4000515549430856

Epoch: 5| Step: 5
Training loss: 1.7019028784702614
Validation loss: 2.3691427372529565

Epoch: 5| Step: 6
Training loss: 1.1225685759669264
Validation loss: 2.3832941341496743

Epoch: 5| Step: 7
Training loss: 1.7920112795943104
Validation loss: 2.376530721231268

Epoch: 5| Step: 8
Training loss: 1.2725347583872555
Validation loss: 2.376611144762889

Epoch: 5| Step: 9
Training loss: 1.5108443696000662
Validation loss: 2.384791493837175

Epoch: 5| Step: 10
Training loss: 1.2900841565737022
Validation loss: 2.3832144245121514

Epoch: 219| Step: 0
Training loss: 1.4431341302648137
Validation loss: 2.358355818082939

Epoch: 5| Step: 1
Training loss: 1.2741437486459053
Validation loss: 2.3506449795899935

Epoch: 5| Step: 2
Training loss: 1.3954543790204348
Validation loss: 2.37077302424764

Epoch: 5| Step: 3
Training loss: 1.7114528768138617
Validation loss: 2.370202231899237

Epoch: 5| Step: 4
Training loss: 1.6627226974363303
Validation loss: 2.3560391418100473

Epoch: 5| Step: 5
Training loss: 1.5024360108673842
Validation loss: 2.366695884074772

Epoch: 5| Step: 6
Training loss: 1.3381356787578416
Validation loss: 2.3639749030878505

Epoch: 5| Step: 7
Training loss: 1.2903966761760863
Validation loss: 2.3910029771549643

Epoch: 5| Step: 8
Training loss: 1.5916220726969523
Validation loss: 2.4164335805349535

Epoch: 5| Step: 9
Training loss: 1.4954059503865216
Validation loss: 2.4228855926281967

Epoch: 5| Step: 10
Training loss: 1.3585693778363073
Validation loss: 2.4011203449656824

Epoch: 220| Step: 0
Training loss: 1.444753342798382
Validation loss: 2.404680532633664

Epoch: 5| Step: 1
Training loss: 1.4949904076003762
Validation loss: 2.395620425600993

Epoch: 5| Step: 2
Training loss: 1.5922304276808565
Validation loss: 2.37068519086916

Epoch: 5| Step: 3
Training loss: 1.384507600448648
Validation loss: 2.3794486065107097

Epoch: 5| Step: 4
Training loss: 1.5156840676664465
Validation loss: 2.3382590811711506

Epoch: 5| Step: 5
Training loss: 1.6130285919597378
Validation loss: 2.364042356738041

Epoch: 5| Step: 6
Training loss: 1.51419046685943
Validation loss: 2.367310118378697

Epoch: 5| Step: 7
Training loss: 1.4043020532165047
Validation loss: 2.3803222468149485

Epoch: 5| Step: 8
Training loss: 1.0010911233985706
Validation loss: 2.381916217422843

Epoch: 5| Step: 9
Training loss: 1.0894780246081726
Validation loss: 2.400104509491413

Epoch: 5| Step: 10
Training loss: 1.862356216205871
Validation loss: 2.4165689266865464

Epoch: 221| Step: 0
Training loss: 1.8020068319616669
Validation loss: 2.398179149672339

Epoch: 5| Step: 1
Training loss: 1.366189647015131
Validation loss: 2.407729720011024

Epoch: 5| Step: 2
Training loss: 1.3228422229076124
Validation loss: 2.402997565303362

Epoch: 5| Step: 3
Training loss: 1.1394605571620833
Validation loss: 2.4360199108639957

Epoch: 5| Step: 4
Training loss: 1.7436275261421672
Validation loss: 2.396326492794194

Epoch: 5| Step: 5
Training loss: 1.2023900251797137
Validation loss: 2.3913618348064953

Epoch: 5| Step: 6
Training loss: 1.3542757528334193
Validation loss: 2.354442772630631

Epoch: 5| Step: 7
Training loss: 1.4959448199932783
Validation loss: 2.377778397543012

Epoch: 5| Step: 8
Training loss: 0.9824946776578367
Validation loss: 2.384798022277213

Epoch: 5| Step: 9
Training loss: 1.590029169090989
Validation loss: 2.3739868409072287

Epoch: 5| Step: 10
Training loss: 1.8019993565862018
Validation loss: 2.359928721604138

Epoch: 222| Step: 0
Training loss: 1.5250369552136944
Validation loss: 2.3658177558584805

Epoch: 5| Step: 1
Training loss: 1.4131637583448973
Validation loss: 2.3745497410054903

Epoch: 5| Step: 2
Training loss: 1.6747742230283214
Validation loss: 2.36047611947128

Epoch: 5| Step: 3
Training loss: 1.4640296403093989
Validation loss: 2.3552429311913254

Epoch: 5| Step: 4
Training loss: 1.5015239127100386
Validation loss: 2.3291352744764975

Epoch: 5| Step: 5
Training loss: 1.0513091055530248
Validation loss: 2.349817502544218

Epoch: 5| Step: 6
Training loss: 1.5122313899343847
Validation loss: 2.3638248473014642

Epoch: 5| Step: 7
Training loss: 1.4120377011925827
Validation loss: 2.3696102822515206

Epoch: 5| Step: 8
Training loss: 1.6728166441827783
Validation loss: 2.3955531055841295

Epoch: 5| Step: 9
Training loss: 1.4023316364243303
Validation loss: 2.4004279794190087

Epoch: 5| Step: 10
Training loss: 1.0658143465400474
Validation loss: 2.4258426067137155

Epoch: 223| Step: 0
Training loss: 1.23115573657768
Validation loss: 2.4233663893797006

Epoch: 5| Step: 1
Training loss: 1.4370595008302167
Validation loss: 2.4100154334910067

Epoch: 5| Step: 2
Training loss: 1.2483231741606844
Validation loss: 2.443808877411553

Epoch: 5| Step: 3
Training loss: 1.3921938843586075
Validation loss: 2.4043120459068303

Epoch: 5| Step: 4
Training loss: 0.9384063472143707
Validation loss: 2.4256718317132293

Epoch: 5| Step: 5
Training loss: 1.204519825706881
Validation loss: 2.410259963178593

Epoch: 5| Step: 6
Training loss: 1.777798571398776
Validation loss: 2.42751527868658

Epoch: 5| Step: 7
Training loss: 1.7469166431683885
Validation loss: 2.432183076022909

Epoch: 5| Step: 8
Training loss: 1.6342758848869348
Validation loss: 2.4280489307432895

Epoch: 5| Step: 9
Training loss: 1.44514901551102
Validation loss: 2.3994877754871355

Epoch: 5| Step: 10
Training loss: 1.4483187366506551
Validation loss: 2.388230088989333

Epoch: 224| Step: 0
Training loss: 1.064383408249478
Validation loss: 2.3590919060209834

Epoch: 5| Step: 1
Training loss: 1.176745402796988
Validation loss: 2.3629477639616954

Epoch: 5| Step: 2
Training loss: 1.5604613928842492
Validation loss: 2.3538892046866686

Epoch: 5| Step: 3
Training loss: 0.9464648135718624
Validation loss: 2.35527196083981

Epoch: 5| Step: 4
Training loss: 1.5222029158411303
Validation loss: 2.3739634779486445

Epoch: 5| Step: 5
Training loss: 1.4752073174595102
Validation loss: 2.3891444218220896

Epoch: 5| Step: 6
Training loss: 1.3566189593675622
Validation loss: 2.404780880820288

Epoch: 5| Step: 7
Training loss: 1.491950370760863
Validation loss: 2.4343361711091487

Epoch: 5| Step: 8
Training loss: 1.7200211419425193
Validation loss: 2.4760681157833626

Epoch: 5| Step: 9
Training loss: 1.6093521116536484
Validation loss: 2.461441006760762

Epoch: 5| Step: 10
Training loss: 1.5207923813971695
Validation loss: 2.3976973583116625

Epoch: 225| Step: 0
Training loss: 1.854161944722653
Validation loss: 2.4140405873937794

Epoch: 5| Step: 1
Training loss: 1.03458097775381
Validation loss: 2.381795841730478

Epoch: 5| Step: 2
Training loss: 1.302610788960219
Validation loss: 2.405462582850889

Epoch: 5| Step: 3
Training loss: 1.1944343981702334
Validation loss: 2.385679167591457

Epoch: 5| Step: 4
Training loss: 1.0241812413241425
Validation loss: 2.4065142261258856

Epoch: 5| Step: 5
Training loss: 1.4675880056114106
Validation loss: 2.4057159651583855

Epoch: 5| Step: 6
Training loss: 1.0176908170714773
Validation loss: 2.447749028239949

Epoch: 5| Step: 7
Training loss: 1.756693097892314
Validation loss: 2.441504027149899

Epoch: 5| Step: 8
Training loss: 1.011653647666339
Validation loss: 2.469075275102367

Epoch: 5| Step: 9
Training loss: 1.8176824864806078
Validation loss: 2.463959110366406

Epoch: 5| Step: 10
Training loss: 1.6020048693560296
Validation loss: 2.4383541164171763

Epoch: 226| Step: 0
Training loss: 1.5832644330476238
Validation loss: 2.4113695444626404

Epoch: 5| Step: 1
Training loss: 1.6472455818416916
Validation loss: 2.4297500579612725

Epoch: 5| Step: 2
Training loss: 0.9551197503191137
Validation loss: 2.366435510345619

Epoch: 5| Step: 3
Training loss: 1.5560074766611942
Validation loss: 2.347622076703141

Epoch: 5| Step: 4
Training loss: 1.1060489708956323
Validation loss: 2.357268863193371

Epoch: 5| Step: 5
Training loss: 1.346052193733588
Validation loss: 2.3262276475797243

Epoch: 5| Step: 6
Training loss: 1.454922046867229
Validation loss: 2.3663398489146106

Epoch: 5| Step: 7
Training loss: 0.858786433417378
Validation loss: 2.390112912996549

Epoch: 5| Step: 8
Training loss: 1.7220507052684317
Validation loss: 2.432630297496811

Epoch: 5| Step: 9
Training loss: 1.479428290570485
Validation loss: 2.455955621159946

Epoch: 5| Step: 10
Training loss: 1.7031293396500762
Validation loss: 2.4310285079569964

Epoch: 227| Step: 0
Training loss: 1.0343302760294673
Validation loss: 2.4186933441873943

Epoch: 5| Step: 1
Training loss: 1.3870595593800938
Validation loss: 2.356582053349303

Epoch: 5| Step: 2
Training loss: 1.6545270198991662
Validation loss: 2.374030313572851

Epoch: 5| Step: 3
Training loss: 1.5140186724701843
Validation loss: 2.341134256394085

Epoch: 5| Step: 4
Training loss: 1.3063548506859246
Validation loss: 2.3391258267835284

Epoch: 5| Step: 5
Training loss: 1.2984293619536638
Validation loss: 2.3292089156388327

Epoch: 5| Step: 6
Training loss: 1.042807462987032
Validation loss: 2.3551640127133386

Epoch: 5| Step: 7
Training loss: 1.1236975866194234
Validation loss: 2.35422804441452

Epoch: 5| Step: 8
Training loss: 1.673725423254947
Validation loss: 2.3818679763891404

Epoch: 5| Step: 9
Training loss: 1.367387811427956
Validation loss: 2.401488468480541

Epoch: 5| Step: 10
Training loss: 1.5719277344611502
Validation loss: 2.410188074101772

Epoch: 228| Step: 0
Training loss: 1.2379105551581753
Validation loss: 2.439247153062823

Epoch: 5| Step: 1
Training loss: 1.416637373602703
Validation loss: 2.422697523410148

Epoch: 5| Step: 2
Training loss: 1.485904427690826
Validation loss: 2.40830649329628

Epoch: 5| Step: 3
Training loss: 1.4419617448301
Validation loss: 2.3987847484621856

Epoch: 5| Step: 4
Training loss: 1.026345525888654
Validation loss: 2.3842167625109476

Epoch: 5| Step: 5
Training loss: 1.1417429944903688
Validation loss: 2.3458258292692467

Epoch: 5| Step: 6
Training loss: 1.6720476863485634
Validation loss: 2.3628196201039002

Epoch: 5| Step: 7
Training loss: 1.6144355542223365
Validation loss: 2.362033799992395

Epoch: 5| Step: 8
Training loss: 1.0017757147165354
Validation loss: 2.364472925527633

Epoch: 5| Step: 9
Training loss: 1.359109786897952
Validation loss: 2.3911401465871025

Epoch: 5| Step: 10
Training loss: 1.228583693324301
Validation loss: 2.3831675275247632

Epoch: 229| Step: 0
Training loss: 1.1805304742779208
Validation loss: 2.4152593903482034

Epoch: 5| Step: 1
Training loss: 0.9656543492668562
Validation loss: 2.432574860908236

Epoch: 5| Step: 2
Training loss: 1.3203088884473535
Validation loss: 2.444915910211713

Epoch: 5| Step: 3
Training loss: 1.0871632197016108
Validation loss: 2.476410331850483

Epoch: 5| Step: 4
Training loss: 1.4370921841853284
Validation loss: 2.4427372642346783

Epoch: 5| Step: 5
Training loss: 0.757967470978346
Validation loss: 2.369560885131222

Epoch: 5| Step: 6
Training loss: 1.7154493370524746
Validation loss: 2.351965808089431

Epoch: 5| Step: 7
Training loss: 1.8497804202112278
Validation loss: 2.326832706304508

Epoch: 5| Step: 8
Training loss: 1.2270446121418985
Validation loss: 2.3338493913282643

Epoch: 5| Step: 9
Training loss: 1.4317946617869926
Validation loss: 2.34110747315302

Epoch: 5| Step: 10
Training loss: 1.3449880086796784
Validation loss: 2.347419858317582

Epoch: 230| Step: 0
Training loss: 1.3388337980485094
Validation loss: 2.356975473155813

Epoch: 5| Step: 1
Training loss: 1.0396913045544693
Validation loss: 2.357624646642891

Epoch: 5| Step: 2
Training loss: 1.3932842160576546
Validation loss: 2.384051284186745

Epoch: 5| Step: 3
Training loss: 1.3732584414539515
Validation loss: 2.3762882896536572

Epoch: 5| Step: 4
Training loss: 0.9490262374004443
Validation loss: 2.371470028463153

Epoch: 5| Step: 5
Training loss: 1.3834620959704456
Validation loss: 2.3860413820148207

Epoch: 5| Step: 6
Training loss: 1.4415225263801046
Validation loss: 2.3659091544884525

Epoch: 5| Step: 7
Training loss: 1.3703878384174661
Validation loss: 2.331356103177095

Epoch: 5| Step: 8
Training loss: 1.3426784856343001
Validation loss: 2.313611683232024

Epoch: 5| Step: 9
Training loss: 1.1896965391648844
Validation loss: 2.339300832727404

Epoch: 5| Step: 10
Training loss: 1.6631079429832683
Validation loss: 2.343600494100998

Epoch: 231| Step: 0
Training loss: 1.7364692759345466
Validation loss: 2.35063563303017

Epoch: 5| Step: 1
Training loss: 1.2065898001585118
Validation loss: 2.339346935705543

Epoch: 5| Step: 2
Training loss: 1.3238858505004631
Validation loss: 2.3718263911569086

Epoch: 5| Step: 3
Training loss: 1.3545421764387644
Validation loss: 2.3785003876810498

Epoch: 5| Step: 4
Training loss: 1.339786228023961
Validation loss: 2.391991333886182

Epoch: 5| Step: 5
Training loss: 1.3551780542875655
Validation loss: 2.4325199710860104

Epoch: 5| Step: 6
Training loss: 1.6180887705495832
Validation loss: 2.435160917353911

Epoch: 5| Step: 7
Training loss: 1.2964175233216306
Validation loss: 2.3886078676952347

Epoch: 5| Step: 8
Training loss: 1.0947942381059457
Validation loss: 2.3690119601391353

Epoch: 5| Step: 9
Training loss: 0.8125694318595549
Validation loss: 2.3547757566208314

Epoch: 5| Step: 10
Training loss: 1.0645728367675578
Validation loss: 2.3362778290091053

Epoch: 232| Step: 0
Training loss: 1.3693350791248335
Validation loss: 2.33806272288215

Epoch: 5| Step: 1
Training loss: 1.7464569192023842
Validation loss: 2.3373225547196115

Epoch: 5| Step: 2
Training loss: 0.9659003831093503
Validation loss: 2.3304613548116566

Epoch: 5| Step: 3
Training loss: 1.5402144560177726
Validation loss: 2.336692427693204

Epoch: 5| Step: 4
Training loss: 0.6963922496378621
Validation loss: 2.3255566645428374

Epoch: 5| Step: 5
Training loss: 1.3928744093205516
Validation loss: 2.36887036660953

Epoch: 5| Step: 6
Training loss: 0.9466807024434613
Validation loss: 2.3545296625367285

Epoch: 5| Step: 7
Training loss: 1.2684865085995531
Validation loss: 2.386599843253876

Epoch: 5| Step: 8
Training loss: 1.6522820643821474
Validation loss: 2.390412526745788

Epoch: 5| Step: 9
Training loss: 1.2167754194348859
Validation loss: 2.3722908984942452

Epoch: 5| Step: 10
Training loss: 0.9958930617473716
Validation loss: 2.3434787317070085

Epoch: 233| Step: 0
Training loss: 1.5160845816778394
Validation loss: 2.3186480646879186

Epoch: 5| Step: 1
Training loss: 0.7908383017632793
Validation loss: 2.3316262980652813

Epoch: 5| Step: 2
Training loss: 1.190573980084326
Validation loss: 2.3212298314601

Epoch: 5| Step: 3
Training loss: 1.1685190594824104
Validation loss: 2.3200376951491934

Epoch: 5| Step: 4
Training loss: 0.969246767713162
Validation loss: 2.3583314246504727

Epoch: 5| Step: 5
Training loss: 1.545883091882339
Validation loss: 2.3841047339148767

Epoch: 5| Step: 6
Training loss: 1.1988402524193633
Validation loss: 2.387990899932293

Epoch: 5| Step: 7
Training loss: 1.5277525215758594
Validation loss: 2.39747171616968

Epoch: 5| Step: 8
Training loss: 1.5146745670900574
Validation loss: 2.40903345896939

Epoch: 5| Step: 9
Training loss: 1.2599425672127125
Validation loss: 2.3947996530333344

Epoch: 5| Step: 10
Training loss: 1.3195214243512303
Validation loss: 2.3898351936876523

Epoch: 234| Step: 0
Training loss: 0.4892539140313744
Validation loss: 2.38713792695727

Epoch: 5| Step: 1
Training loss: 1.391886706669142
Validation loss: 2.3734768925744256

Epoch: 5| Step: 2
Training loss: 1.1586864678703233
Validation loss: 2.3628337271291486

Epoch: 5| Step: 3
Training loss: 1.5092865848906265
Validation loss: 2.366586314334617

Epoch: 5| Step: 4
Training loss: 1.4285311165299008
Validation loss: 2.383699910514406

Epoch: 5| Step: 5
Training loss: 1.0924840958264743
Validation loss: 2.383932511086689

Epoch: 5| Step: 6
Training loss: 1.5377459631705475
Validation loss: 2.3919687276815274

Epoch: 5| Step: 7
Training loss: 1.484916106529108
Validation loss: 2.3725573192546303

Epoch: 5| Step: 8
Training loss: 1.4676548547615267
Validation loss: 2.356823132336412

Epoch: 5| Step: 9
Training loss: 1.2092781757560431
Validation loss: 2.344020398583557

Epoch: 5| Step: 10
Training loss: 0.9154187110029569
Validation loss: 2.310573755632055

Epoch: 235| Step: 0
Training loss: 0.955846496919308
Validation loss: 2.3701707675794057

Epoch: 5| Step: 1
Training loss: 1.1743861441415928
Validation loss: 2.335105082332748

Epoch: 5| Step: 2
Training loss: 1.5181896102053263
Validation loss: 2.35185840148476

Epoch: 5| Step: 3
Training loss: 1.11412728269744
Validation loss: 2.3187380947705942

Epoch: 5| Step: 4
Training loss: 0.9160328031771472
Validation loss: 2.324742795787467

Epoch: 5| Step: 5
Training loss: 0.8742441250388517
Validation loss: 2.3422097048494677

Epoch: 5| Step: 6
Training loss: 1.3870056285427663
Validation loss: 2.319277857555722

Epoch: 5| Step: 7
Training loss: 1.4600517321265845
Validation loss: 2.3318083111315517

Epoch: 5| Step: 8
Training loss: 1.7698425288653765
Validation loss: 2.3281170936500324

Epoch: 5| Step: 9
Training loss: 1.1776750084637093
Validation loss: 2.337017126868476

Epoch: 5| Step: 10
Training loss: 1.3232057460820439
Validation loss: 2.3493515313835918

Epoch: 236| Step: 0
Training loss: 1.279203082424718
Validation loss: 2.373709026083846

Epoch: 5| Step: 1
Training loss: 1.0131998304421892
Validation loss: 2.369285684356789

Epoch: 5| Step: 2
Training loss: 1.6777589594113362
Validation loss: 2.3840698109664253

Epoch: 5| Step: 3
Training loss: 1.1484225006162017
Validation loss: 2.355033711214617

Epoch: 5| Step: 4
Training loss: 1.258277475409896
Validation loss: 2.336912031915755

Epoch: 5| Step: 5
Training loss: 1.1977475862456834
Validation loss: 2.3518400319091586

Epoch: 5| Step: 6
Training loss: 0.8466726476603237
Validation loss: 2.326299506241527

Epoch: 5| Step: 7
Training loss: 1.19496678358065
Validation loss: 2.325393059397766

Epoch: 5| Step: 8
Training loss: 1.5088742327801548
Validation loss: 2.3304116327988953

Epoch: 5| Step: 9
Training loss: 1.2657005852628531
Validation loss: 2.3323108334214435

Epoch: 5| Step: 10
Training loss: 1.0535480136440023
Validation loss: 2.3249596098603416

Epoch: 237| Step: 0
Training loss: 1.6495276728746024
Validation loss: 2.340682050663367

Epoch: 5| Step: 1
Training loss: 1.2502013044388025
Validation loss: 2.3349230934915246

Epoch: 5| Step: 2
Training loss: 0.8932830230818068
Validation loss: 2.330725922235396

Epoch: 5| Step: 3
Training loss: 0.8910185964786496
Validation loss: 2.318090475410979

Epoch: 5| Step: 4
Training loss: 1.650720543022721
Validation loss: 2.288414621229163

Epoch: 5| Step: 5
Training loss: 1.248286789831555
Validation loss: 2.2897051688433203

Epoch: 5| Step: 6
Training loss: 1.098557614613973
Validation loss: 2.286334587734697

Epoch: 5| Step: 7
Training loss: 1.1433966419127286
Validation loss: 2.313699932570615

Epoch: 5| Step: 8
Training loss: 1.2521895305939812
Validation loss: 2.3342937925996474

Epoch: 5| Step: 9
Training loss: 0.9547795178009971
Validation loss: 2.3378408032981253

Epoch: 5| Step: 10
Training loss: 1.2513865886605466
Validation loss: 2.354924278162728

Epoch: 238| Step: 0
Training loss: 1.3258001736407037
Validation loss: 2.383705048115018

Epoch: 5| Step: 1
Training loss: 1.1949628929537934
Validation loss: 2.3445729668267314

Epoch: 5| Step: 2
Training loss: 1.351576612101181
Validation loss: 2.3717975468324455

Epoch: 5| Step: 3
Training loss: 1.2052938061175154
Validation loss: 2.3606165842364026

Epoch: 5| Step: 4
Training loss: 1.5943010163048947
Validation loss: 2.330147534684673

Epoch: 5| Step: 5
Training loss: 1.283958595882853
Validation loss: 2.3181170064664096

Epoch: 5| Step: 6
Training loss: 0.8104942212754803
Validation loss: 2.3075991056540657

Epoch: 5| Step: 7
Training loss: 1.2701239038835663
Validation loss: 2.315754547797572

Epoch: 5| Step: 8
Training loss: 0.9619388480309308
Validation loss: 2.2777841885377534

Epoch: 5| Step: 9
Training loss: 1.0251705260431805
Validation loss: 2.30590075800309

Epoch: 5| Step: 10
Training loss: 1.2750871890306665
Validation loss: 2.300119657110222

Epoch: 239| Step: 0
Training loss: 1.0163931069488263
Validation loss: 2.3079979043300134

Epoch: 5| Step: 1
Training loss: 0.9696850724578674
Validation loss: 2.333822385528355

Epoch: 5| Step: 2
Training loss: 1.2068787512382633
Validation loss: 2.3043356605852767

Epoch: 5| Step: 3
Training loss: 1.1296732056110408
Validation loss: 2.2892287777471436

Epoch: 5| Step: 4
Training loss: 1.3453466998105135
Validation loss: 2.286012070646608

Epoch: 5| Step: 5
Training loss: 1.3018358325972517
Validation loss: 2.280843685352247

Epoch: 5| Step: 6
Training loss: 1.47492866343608
Validation loss: 2.2686478152035336

Epoch: 5| Step: 7
Training loss: 1.3964549241595128
Validation loss: 2.2959660909686908

Epoch: 5| Step: 8
Training loss: 1.0425719460010907
Validation loss: 2.284409855662706

Epoch: 5| Step: 9
Training loss: 1.2156635719593245
Validation loss: 2.3105731575977013

Epoch: 5| Step: 10
Training loss: 1.1243177570489638
Validation loss: 2.362118537413342

Epoch: 240| Step: 0
Training loss: 1.1076895038888162
Validation loss: 2.3744100853790098

Epoch: 5| Step: 1
Training loss: 1.1030708969724288
Validation loss: 2.3700701633194186

Epoch: 5| Step: 2
Training loss: 1.432806063671902
Validation loss: 2.3689048145273603

Epoch: 5| Step: 3
Training loss: 1.3590410194971236
Validation loss: 2.3559433482361096

Epoch: 5| Step: 4
Training loss: 1.1959156683690222
Validation loss: 2.326277558204476

Epoch: 5| Step: 5
Training loss: 1.4748515555474995
Validation loss: 2.329952192749534

Epoch: 5| Step: 6
Training loss: 1.2682495689970368
Validation loss: 2.3424880329470392

Epoch: 5| Step: 7
Training loss: 0.786893829290095
Validation loss: 2.325599731816355

Epoch: 5| Step: 8
Training loss: 1.537263312380936
Validation loss: 2.334707034485314

Epoch: 5| Step: 9
Training loss: 0.7759020293567037
Validation loss: 2.3195994341338357

Epoch: 5| Step: 10
Training loss: 0.7900061677136672
Validation loss: 2.3306584882626624

Epoch: 241| Step: 0
Training loss: 1.3110968037182047
Validation loss: 2.354971450194732

Epoch: 5| Step: 1
Training loss: 1.2744609721820332
Validation loss: 2.3619224976687985

Epoch: 5| Step: 2
Training loss: 1.1313862207497134
Validation loss: 2.3374808024368874

Epoch: 5| Step: 3
Training loss: 1.076240440441391
Validation loss: 2.3620253863204135

Epoch: 5| Step: 4
Training loss: 0.8535291029086377
Validation loss: 2.35693205628317

Epoch: 5| Step: 5
Training loss: 1.2206457994352142
Validation loss: 2.342426658765156

Epoch: 5| Step: 6
Training loss: 1.224520398669043
Validation loss: 2.3240418157654927

Epoch: 5| Step: 7
Training loss: 0.7337174413888617
Validation loss: 2.318274830663547

Epoch: 5| Step: 8
Training loss: 1.3684263447657272
Validation loss: 2.3206608190663998

Epoch: 5| Step: 9
Training loss: 1.3626875582049691
Validation loss: 2.323080151933436

Epoch: 5| Step: 10
Training loss: 1.4045366233784857
Validation loss: 2.300629086620231

Epoch: 242| Step: 0
Training loss: 1.0377785917610645
Validation loss: 2.3195711351017168

Epoch: 5| Step: 1
Training loss: 1.5551376841144113
Validation loss: 2.338512200577949

Epoch: 5| Step: 2
Training loss: 1.198711026843993
Validation loss: 2.383754710434188

Epoch: 5| Step: 3
Training loss: 1.2776336807509934
Validation loss: 2.3833398615653536

Epoch: 5| Step: 4
Training loss: 0.9611356267362686
Validation loss: 2.384758417064655

Epoch: 5| Step: 5
Training loss: 1.4488023020771847
Validation loss: 2.4226841808308652

Epoch: 5| Step: 6
Training loss: 0.808216615161437
Validation loss: 2.385705295706142

Epoch: 5| Step: 7
Training loss: 1.09866362804005
Validation loss: 2.3792080271135867

Epoch: 5| Step: 8
Training loss: 0.8765458348503898
Validation loss: 2.331094153768014

Epoch: 5| Step: 9
Training loss: 1.0718059840101306
Validation loss: 2.3324167440680874

Epoch: 5| Step: 10
Training loss: 1.4679370821896476
Validation loss: 2.314044766798061

Epoch: 243| Step: 0
Training loss: 0.7472760484430095
Validation loss: 2.2886420206768783

Epoch: 5| Step: 1
Training loss: 1.1660101553374904
Validation loss: 2.306083417469241

Epoch: 5| Step: 2
Training loss: 1.3123542159724035
Validation loss: 2.3346649455937127

Epoch: 5| Step: 3
Training loss: 1.576867310591799
Validation loss: 2.379283292744491

Epoch: 5| Step: 4
Training loss: 1.187290373921576
Validation loss: 2.379540501305764

Epoch: 5| Step: 5
Training loss: 0.9183153188142019
Validation loss: 2.3576074477172773

Epoch: 5| Step: 6
Training loss: 0.8859072765866629
Validation loss: 2.321673412926998

Epoch: 5| Step: 7
Training loss: 1.0290778431934509
Validation loss: 2.323117850080485

Epoch: 5| Step: 8
Training loss: 1.5572581292903385
Validation loss: 2.3125699516875593

Epoch: 5| Step: 9
Training loss: 1.350345482594466
Validation loss: 2.327599136195513

Epoch: 5| Step: 10
Training loss: 1.0405870883210266
Validation loss: 2.3011873519421306

Epoch: 244| Step: 0
Training loss: 0.8883460149581484
Validation loss: 2.330194021194931

Epoch: 5| Step: 1
Training loss: 1.2493214672960882
Validation loss: 2.3393204295356407

Epoch: 5| Step: 2
Training loss: 1.368696502615526
Validation loss: 2.3547329284687315

Epoch: 5| Step: 3
Training loss: 0.8583374001736883
Validation loss: 2.3649194623149152

Epoch: 5| Step: 4
Training loss: 1.1694707494260481
Validation loss: 2.3914607661680725

Epoch: 5| Step: 5
Training loss: 1.4841251363767864
Validation loss: 2.400417141400071

Epoch: 5| Step: 6
Training loss: 1.1861382758022438
Validation loss: 2.4119400839841205

Epoch: 5| Step: 7
Training loss: 0.8993302263748685
Validation loss: 2.3957856307735765

Epoch: 5| Step: 8
Training loss: 1.0113960252159848
Validation loss: 2.35770880340932

Epoch: 5| Step: 9
Training loss: 0.9664272025449763
Validation loss: 2.3419460187661647

Epoch: 5| Step: 10
Training loss: 1.5786314047927326
Validation loss: 2.3201220835359355

Epoch: 245| Step: 0
Training loss: 1.4924356144447035
Validation loss: 2.319062993222269

Epoch: 5| Step: 1
Training loss: 1.029575722724289
Validation loss: 2.30435584845113

Epoch: 5| Step: 2
Training loss: 0.6593236243314526
Validation loss: 2.3104648498033953

Epoch: 5| Step: 3
Training loss: 1.070725577062315
Validation loss: 2.304922936623643

Epoch: 5| Step: 4
Training loss: 1.055152338518654
Validation loss: 2.327324106716333

Epoch: 5| Step: 5
Training loss: 1.4384498774998542
Validation loss: 2.376854362056826

Epoch: 5| Step: 6
Training loss: 0.8368212582779965
Validation loss: 2.3807999440293592

Epoch: 5| Step: 7
Training loss: 1.2382758107351703
Validation loss: 2.3952722175027428

Epoch: 5| Step: 8
Training loss: 1.2910256897596046
Validation loss: 2.3572618158784

Epoch: 5| Step: 9
Training loss: 1.0325763149552991
Validation loss: 2.3700783926724545

Epoch: 5| Step: 10
Training loss: 1.4496323645620859
Validation loss: 2.3563831219604947

Epoch: 246| Step: 0
Training loss: 1.152255607725416
Validation loss: 2.3282462522958

Epoch: 5| Step: 1
Training loss: 1.433148140735017
Validation loss: 2.322287641864011

Epoch: 5| Step: 2
Training loss: 1.3216284790310773
Validation loss: 2.3138176872971012

Epoch: 5| Step: 3
Training loss: 1.0862419195719655
Validation loss: 2.3142647875624442

Epoch: 5| Step: 4
Training loss: 0.8743867087244882
Validation loss: 2.336558002036944

Epoch: 5| Step: 5
Training loss: 1.2752293810483433
Validation loss: 2.3601756533964218

Epoch: 5| Step: 6
Training loss: 0.8758497880018487
Validation loss: 2.383830186192622

Epoch: 5| Step: 7
Training loss: 1.0285163250611817
Validation loss: 2.4330424191207234

Epoch: 5| Step: 8
Training loss: 1.217054850998027
Validation loss: 2.4049920239172486

Epoch: 5| Step: 9
Training loss: 1.2940773720198746
Validation loss: 2.4058674669527678

Epoch: 5| Step: 10
Training loss: 0.9162773295303985
Validation loss: 2.364949562891048

Epoch: 247| Step: 0
Training loss: 0.9846643900482299
Validation loss: 2.34959033536268

Epoch: 5| Step: 1
Training loss: 1.1523990941092768
Validation loss: 2.321828660662788

Epoch: 5| Step: 2
Training loss: 0.7791275184574732
Validation loss: 2.3076159921206045

Epoch: 5| Step: 3
Training loss: 1.0206109537815484
Validation loss: 2.293101198646535

Epoch: 5| Step: 4
Training loss: 1.04050735175172
Validation loss: 2.3000421019058424

Epoch: 5| Step: 5
Training loss: 1.4790008434063697
Validation loss: 2.3276695989260783

Epoch: 5| Step: 6
Training loss: 1.0676558442898691
Validation loss: 2.3396091406905724

Epoch: 5| Step: 7
Training loss: 1.3898060133615773
Validation loss: 2.3718903849391895

Epoch: 5| Step: 8
Training loss: 1.4422299892328725
Validation loss: 2.348817661807052

Epoch: 5| Step: 9
Training loss: 0.8985942206317675
Validation loss: 2.3401488434387776

Epoch: 5| Step: 10
Training loss: 0.9778737839402678
Validation loss: 2.3436286419038552

Epoch: 248| Step: 0
Training loss: 0.9539981032378656
Validation loss: 2.3340113975981285

Epoch: 5| Step: 1
Training loss: 1.2754631547619373
Validation loss: 2.3424522192240715

Epoch: 5| Step: 2
Training loss: 1.1915191096647544
Validation loss: 2.362048209638471

Epoch: 5| Step: 3
Training loss: 0.5758769686884482
Validation loss: 2.3672432386784226

Epoch: 5| Step: 4
Training loss: 1.3930511313321994
Validation loss: 2.3664563053968206

Epoch: 5| Step: 5
Training loss: 1.2472506327792834
Validation loss: 2.3509827526279876

Epoch: 5| Step: 6
Training loss: 0.8989037009059994
Validation loss: 2.3324125244854046

Epoch: 5| Step: 7
Training loss: 1.0469466227612823
Validation loss: 2.3136166484824354

Epoch: 5| Step: 8
Training loss: 1.1628884661125567
Validation loss: 2.2885553193666106

Epoch: 5| Step: 9
Training loss: 1.0563853972743389
Validation loss: 2.2998103625377295

Epoch: 5| Step: 10
Training loss: 1.2883692408875544
Validation loss: 2.2854058595548907

Epoch: 249| Step: 0
Training loss: 1.09966460880304
Validation loss: 2.2908194138235003

Epoch: 5| Step: 1
Training loss: 0.9483368784084554
Validation loss: 2.304930111709515

Epoch: 5| Step: 2
Training loss: 0.832645887703036
Validation loss: 2.3201949168945677

Epoch: 5| Step: 3
Training loss: 1.1750747738035827
Validation loss: 2.311343502096741

Epoch: 5| Step: 4
Training loss: 1.1115803893169682
Validation loss: 2.333040035692844

Epoch: 5| Step: 5
Training loss: 1.4364431891727654
Validation loss: 2.338981632160353

Epoch: 5| Step: 6
Training loss: 1.3183065672294116
Validation loss: 2.3533668255554216

Epoch: 5| Step: 7
Training loss: 1.340610740603571
Validation loss: 2.332086388869536

Epoch: 5| Step: 8
Training loss: 0.8154012161126984
Validation loss: 2.3405182705550347

Epoch: 5| Step: 9
Training loss: 0.9109000903344054
Validation loss: 2.3039853719529795

Epoch: 5| Step: 10
Training loss: 0.9175462115548977
Validation loss: 2.2907336773630393

Epoch: 250| Step: 0
Training loss: 1.0883956640912114
Validation loss: 2.334132783990353

Epoch: 5| Step: 1
Training loss: 1.2703646697232711
Validation loss: 2.327051999409602

Epoch: 5| Step: 2
Training loss: 1.142166298227229
Validation loss: 2.3361786474267627

Epoch: 5| Step: 3
Training loss: 1.113584296490261
Validation loss: 2.321449862552347

Epoch: 5| Step: 4
Training loss: 1.2271333568762899
Validation loss: 2.3456856165285247

Epoch: 5| Step: 5
Training loss: 0.9910609239834071
Validation loss: 2.3575362709347103

Epoch: 5| Step: 6
Training loss: 0.5889403391076069
Validation loss: 2.3609319530447497

Epoch: 5| Step: 7
Training loss: 1.2638976000158422
Validation loss: 2.3324757382884216

Epoch: 5| Step: 8
Training loss: 0.9253909096932769
Validation loss: 2.3297701788244347

Epoch: 5| Step: 9
Training loss: 1.1119516564330492
Validation loss: 2.3132740417038575

Epoch: 5| Step: 10
Training loss: 1.1484237981484922
Validation loss: 2.300883506712786

Epoch: 251| Step: 0
Training loss: 1.1477325247911379
Validation loss: 2.3113926456447533

Epoch: 5| Step: 1
Training loss: 0.966342518708742
Validation loss: 2.303248518768063

Epoch: 5| Step: 2
Training loss: 1.19121487440618
Validation loss: 2.313338329810638

Epoch: 5| Step: 3
Training loss: 1.4147884971071227
Validation loss: 2.283268908764036

Epoch: 5| Step: 4
Training loss: 0.4531342406810491
Validation loss: 2.2833610096984605

Epoch: 5| Step: 5
Training loss: 1.0722635126701074
Validation loss: 2.2712098410018724

Epoch: 5| Step: 6
Training loss: 0.8926776521648736
Validation loss: 2.2929243799827597

Epoch: 5| Step: 7
Training loss: 1.4177130686699317
Validation loss: 2.333929768669793

Epoch: 5| Step: 8
Training loss: 0.8947526416254605
Validation loss: 2.3286612433297598

Epoch: 5| Step: 9
Training loss: 1.1835885630075338
Validation loss: 2.3512896792872713

Epoch: 5| Step: 10
Training loss: 0.8952973262972338
Validation loss: 2.3531107565901377

Epoch: 252| Step: 0
Training loss: 1.1181253618097973
Validation loss: 2.3458169148578967

Epoch: 5| Step: 1
Training loss: 1.199898393620909
Validation loss: 2.316945125900895

Epoch: 5| Step: 2
Training loss: 1.1508957898435417
Validation loss: 2.3306049694455298

Epoch: 5| Step: 3
Training loss: 1.0643513202105133
Validation loss: 2.308332884176046

Epoch: 5| Step: 4
Training loss: 0.9191434445968161
Validation loss: 2.3175453017162755

Epoch: 5| Step: 5
Training loss: 0.8858449722762296
Validation loss: 2.3339739852428942

Epoch: 5| Step: 6
Training loss: 1.0941138615955928
Validation loss: 2.3720455478174958

Epoch: 5| Step: 7
Training loss: 0.7879024325059567
Validation loss: 2.37322579236067

Epoch: 5| Step: 8
Training loss: 1.190678959222015
Validation loss: 2.3769764041080044

Epoch: 5| Step: 9
Training loss: 0.7816216919763557
Validation loss: 2.3727327393514734

Epoch: 5| Step: 10
Training loss: 1.5725097466729252
Validation loss: 2.3404481738412826

Epoch: 253| Step: 0
Training loss: 0.9882974133281752
Validation loss: 2.3380485003878184

Epoch: 5| Step: 1
Training loss: 1.2797826878284808
Validation loss: 2.3103675644070814

Epoch: 5| Step: 2
Training loss: 1.2828043371723772
Validation loss: 2.284855122266663

Epoch: 5| Step: 3
Training loss: 1.0698883998462692
Validation loss: 2.266982323523391

Epoch: 5| Step: 4
Training loss: 0.9706036461067378
Validation loss: 2.279159429701067

Epoch: 5| Step: 5
Training loss: 1.3028728634544933
Validation loss: 2.3168327374564477

Epoch: 5| Step: 6
Training loss: 0.5949955474462523
Validation loss: 2.3569637479108514

Epoch: 5| Step: 7
Training loss: 1.306763875534045
Validation loss: 2.4200088599359875

Epoch: 5| Step: 8
Training loss: 1.2745191976508883
Validation loss: 2.4221026755184485

Epoch: 5| Step: 9
Training loss: 0.5373498274361587
Validation loss: 2.402560223766418

Epoch: 5| Step: 10
Training loss: 1.181147196499481
Validation loss: 2.365420125981942

Epoch: 254| Step: 0
Training loss: 0.8924573152950892
Validation loss: 2.3243740444570005

Epoch: 5| Step: 1
Training loss: 1.11753343681475
Validation loss: 2.3007101342583343

Epoch: 5| Step: 2
Training loss: 1.2981961426504396
Validation loss: 2.252682326653328

Epoch: 5| Step: 3
Training loss: 1.0584544410397236
Validation loss: 2.2601858731662907

Epoch: 5| Step: 4
Training loss: 1.1596755242352557
Validation loss: 2.257257988929121

Epoch: 5| Step: 5
Training loss: 1.1601886680517826
Validation loss: 2.285049671302705

Epoch: 5| Step: 6
Training loss: 0.797855932814396
Validation loss: 2.3203742414507698

Epoch: 5| Step: 7
Training loss: 0.9908670665163023
Validation loss: 2.317525584938774

Epoch: 5| Step: 8
Training loss: 1.0256135244151756
Validation loss: 2.331967860345402

Epoch: 5| Step: 9
Training loss: 1.13947771455834
Validation loss: 2.3538470329404038

Epoch: 5| Step: 10
Training loss: 1.0803354794831004
Validation loss: 2.294991697821445

Epoch: 255| Step: 0
Training loss: 1.0532401998205663
Validation loss: 2.270074461477828

Epoch: 5| Step: 1
Training loss: 1.1817970865874468
Validation loss: 2.288614947978481

Epoch: 5| Step: 2
Training loss: 1.1097086552435282
Validation loss: 2.2550677240721786

Epoch: 5| Step: 3
Training loss: 0.8323453211926182
Validation loss: 2.2811155404609234

Epoch: 5| Step: 4
Training loss: 1.0615341621144938
Validation loss: 2.260268456632125

Epoch: 5| Step: 5
Training loss: 0.9343382289119487
Validation loss: 2.271621238514219

Epoch: 5| Step: 6
Training loss: 1.2847440574554585
Validation loss: 2.3081130432386288

Epoch: 5| Step: 7
Training loss: 1.0707616490120742
Validation loss: 2.3067709572419712

Epoch: 5| Step: 8
Training loss: 0.75027885815987
Validation loss: 2.306654517676255

Epoch: 5| Step: 9
Training loss: 1.202691433552859
Validation loss: 2.344203948219116

Epoch: 5| Step: 10
Training loss: 0.7568835434246389
Validation loss: 2.322987356774488

Epoch: 256| Step: 0
Training loss: 1.1032122439716772
Validation loss: 2.3140220893201335

Epoch: 5| Step: 1
Training loss: 0.9443628569654766
Validation loss: 2.3297649971128274

Epoch: 5| Step: 2
Training loss: 0.64952297588086
Validation loss: 2.3104153765258304

Epoch: 5| Step: 3
Training loss: 0.601983158617392
Validation loss: 2.2778234703162386

Epoch: 5| Step: 4
Training loss: 0.881328922822894
Validation loss: 2.2309367118169754

Epoch: 5| Step: 5
Training loss: 1.2276540382212877
Validation loss: 2.263508729312005

Epoch: 5| Step: 6
Training loss: 1.221655243919508
Validation loss: 2.251064554589645

Epoch: 5| Step: 7
Training loss: 1.321427410633358
Validation loss: 2.2437215397122343

Epoch: 5| Step: 8
Training loss: 1.0510878558764125
Validation loss: 2.2674769147136065

Epoch: 5| Step: 9
Training loss: 1.0056200650166964
Validation loss: 2.2772279222102667

Epoch: 5| Step: 10
Training loss: 1.0350976891417492
Validation loss: 2.306027788031144

Epoch: 257| Step: 0
Training loss: 1.3196955938179105
Validation loss: 2.3237276979521897

Epoch: 5| Step: 1
Training loss: 0.834213332612145
Validation loss: 2.3462709133472623

Epoch: 5| Step: 2
Training loss: 1.0171388347838577
Validation loss: 2.341419688552986

Epoch: 5| Step: 3
Training loss: 1.2120542237707328
Validation loss: 2.3175019011327254

Epoch: 5| Step: 4
Training loss: 0.6106423135604621
Validation loss: 2.3301411732890243

Epoch: 5| Step: 5
Training loss: 0.5693120411590326
Validation loss: 2.3491043239357308

Epoch: 5| Step: 6
Training loss: 1.0879408107393156
Validation loss: 2.3377554836075682

Epoch: 5| Step: 7
Training loss: 0.8810350872980905
Validation loss: 2.280146575397058

Epoch: 5| Step: 8
Training loss: 1.0342604882047597
Validation loss: 2.296040932468083

Epoch: 5| Step: 9
Training loss: 1.1951873813543912
Validation loss: 2.3160338556995037

Epoch: 5| Step: 10
Training loss: 1.1942874277888722
Validation loss: 2.2930435861918803

Epoch: 258| Step: 0
Training loss: 1.1896377194738619
Validation loss: 2.280000833202844

Epoch: 5| Step: 1
Training loss: 1.4334004035309365
Validation loss: 2.3002368866539573

Epoch: 5| Step: 2
Training loss: 0.7561596808606563
Validation loss: 2.290843310816981

Epoch: 5| Step: 3
Training loss: 0.7777852094007609
Validation loss: 2.2898764855036227

Epoch: 5| Step: 4
Training loss: 1.246957987459242
Validation loss: 2.3378015605859406

Epoch: 5| Step: 5
Training loss: 1.0750687998557198
Validation loss: 2.3455660231786886

Epoch: 5| Step: 6
Training loss: 0.8220445421801397
Validation loss: 2.343854605141785

Epoch: 5| Step: 7
Training loss: 0.8825335779367041
Validation loss: 2.2837578494813346

Epoch: 5| Step: 8
Training loss: 0.863429993118087
Validation loss: 2.309180111028399

Epoch: 5| Step: 9
Training loss: 0.5944896157082062
Validation loss: 2.2967952412785815

Epoch: 5| Step: 10
Training loss: 1.1445611943308467
Validation loss: 2.2816539041047514

Epoch: 259| Step: 0
Training loss: 1.20229310839354
Validation loss: 2.287561569851165

Epoch: 5| Step: 1
Training loss: 0.8471199835563599
Validation loss: 2.260374730504051

Epoch: 5| Step: 2
Training loss: 1.0665015991957236
Validation loss: 2.258505649150647

Epoch: 5| Step: 3
Training loss: 1.1099816933402442
Validation loss: 2.2963756738160543

Epoch: 5| Step: 4
Training loss: 1.235134470564846
Validation loss: 2.291524619420027

Epoch: 5| Step: 5
Training loss: 0.9223144906075453
Validation loss: 2.306375242702575

Epoch: 5| Step: 6
Training loss: 0.7702999632397479
Validation loss: 2.323299037857776

Epoch: 5| Step: 7
Training loss: 1.16839561189391
Validation loss: 2.2982188451101155

Epoch: 5| Step: 8
Training loss: 0.7297149277296548
Validation loss: 2.308665437961091

Epoch: 5| Step: 9
Training loss: 0.8552018885925287
Validation loss: 2.2846603142881134

Epoch: 5| Step: 10
Training loss: 0.9519825326214667
Validation loss: 2.2862856838965406

Epoch: 260| Step: 0
Training loss: 1.1054296587714834
Validation loss: 2.3139188809723112

Epoch: 5| Step: 1
Training loss: 0.9783780121119062
Validation loss: 2.2927048953714886

Epoch: 5| Step: 2
Training loss: 0.944852953727689
Validation loss: 2.314149085097824

Epoch: 5| Step: 3
Training loss: 1.0791181882380152
Validation loss: 2.289791567988794

Epoch: 5| Step: 4
Training loss: 0.8996308072808948
Validation loss: 2.271905632516101

Epoch: 5| Step: 5
Training loss: 0.9654290281274617
Validation loss: 2.2688979189206475

Epoch: 5| Step: 6
Training loss: 0.9539882002986471
Validation loss: 2.257716275663499

Epoch: 5| Step: 7
Training loss: 0.9284410856801079
Validation loss: 2.2922367166297013

Epoch: 5| Step: 8
Training loss: 0.7304622629458987
Validation loss: 2.2873471185727983

Epoch: 5| Step: 9
Training loss: 1.19716834315599
Validation loss: 2.325692133935522

Epoch: 5| Step: 10
Training loss: 1.0495293970448043
Validation loss: 2.3250468330637153

Epoch: 261| Step: 0
Training loss: 1.1000984689681585
Validation loss: 2.335081230996176

Epoch: 5| Step: 1
Training loss: 1.0082589277027794
Validation loss: 2.3497483585876418

Epoch: 5| Step: 2
Training loss: 1.0961873825441186
Validation loss: 2.341487150376673

Epoch: 5| Step: 3
Training loss: 1.0478243153238984
Validation loss: 2.2935508764315853

Epoch: 5| Step: 4
Training loss: 1.0725315229856192
Validation loss: 2.299622707666605

Epoch: 5| Step: 5
Training loss: 1.015801399757546
Validation loss: 2.3021629058786055

Epoch: 5| Step: 6
Training loss: 1.0716565457267087
Validation loss: 2.2928090882746224

Epoch: 5| Step: 7
Training loss: 0.7069235450946314
Validation loss: 2.3256413233658058

Epoch: 5| Step: 8
Training loss: 1.098619249048219
Validation loss: 2.2827151902159977

Epoch: 5| Step: 9
Training loss: 0.6914057974086508
Validation loss: 2.240911603746727

Epoch: 5| Step: 10
Training loss: 0.858570103410814
Validation loss: 2.274450050349353

Epoch: 262| Step: 0
Training loss: 0.6396169407202433
Validation loss: 2.287297695589351

Epoch: 5| Step: 1
Training loss: 0.8612171542765628
Validation loss: 2.3066869367444105

Epoch: 5| Step: 2
Training loss: 0.8100401983765002
Validation loss: 2.2938500065279976

Epoch: 5| Step: 3
Training loss: 0.9098901646216769
Validation loss: 2.3191923009914217

Epoch: 5| Step: 4
Training loss: 1.0498216636527122
Validation loss: 2.2752430846477254

Epoch: 5| Step: 5
Training loss: 1.1469650690535027
Validation loss: 2.280923891716407

Epoch: 5| Step: 6
Training loss: 0.9372847309917226
Validation loss: 2.2803728246446693

Epoch: 5| Step: 7
Training loss: 1.0379681668444294
Validation loss: 2.2862200861762894

Epoch: 5| Step: 8
Training loss: 1.1110606751650944
Validation loss: 2.303945618237405

Epoch: 5| Step: 9
Training loss: 1.1445704638953402
Validation loss: 2.317414921633435

Epoch: 5| Step: 10
Training loss: 0.7470435044209665
Validation loss: 2.3291021018426314

Epoch: 263| Step: 0
Training loss: 0.9184672199436532
Validation loss: 2.311944869973111

Epoch: 5| Step: 1
Training loss: 0.7480322933518831
Validation loss: 2.307859622306692

Epoch: 5| Step: 2
Training loss: 0.9329459524619574
Validation loss: 2.329827720467576

Epoch: 5| Step: 3
Training loss: 1.0429310881140463
Validation loss: 2.3103489559279557

Epoch: 5| Step: 4
Training loss: 0.9832827245221432
Validation loss: 2.3218504083964393

Epoch: 5| Step: 5
Training loss: 1.0395787039572792
Validation loss: 2.3174692290301193

Epoch: 5| Step: 6
Training loss: 0.8921297311869845
Validation loss: 2.2950224424244268

Epoch: 5| Step: 7
Training loss: 1.1377266417024892
Validation loss: 2.282622369140453

Epoch: 5| Step: 8
Training loss: 1.1412338826440067
Validation loss: 2.282339928300682

Epoch: 5| Step: 9
Training loss: 0.7942149700260213
Validation loss: 2.2670454857226887

Epoch: 5| Step: 10
Training loss: 0.771530768049801
Validation loss: 2.2678629785377717

Epoch: 264| Step: 0
Training loss: 0.857112959215436
Validation loss: 2.2727206721447715

Epoch: 5| Step: 1
Training loss: 0.9246880881774001
Validation loss: 2.276422186695665

Epoch: 5| Step: 2
Training loss: 0.7078510821271211
Validation loss: 2.300015454866793

Epoch: 5| Step: 3
Training loss: 1.1133291133831096
Validation loss: 2.3156520189235654

Epoch: 5| Step: 4
Training loss: 0.8275464754220512
Validation loss: 2.3094173816875636

Epoch: 5| Step: 5
Training loss: 1.0700530691444805
Validation loss: 2.3332222697491853

Epoch: 5| Step: 6
Training loss: 1.2135172283456965
Validation loss: 2.3309305740717527

Epoch: 5| Step: 7
Training loss: 1.0567224157129627
Validation loss: 2.3209833036116807

Epoch: 5| Step: 8
Training loss: 1.165778105552205
Validation loss: 2.346979348283405

Epoch: 5| Step: 9
Training loss: 0.6537899273920614
Validation loss: 2.300437684455472

Epoch: 5| Step: 10
Training loss: 0.5964705479985961
Validation loss: 2.306535877084292

Epoch: 265| Step: 0
Training loss: 0.9789310570912597
Validation loss: 2.3030042850127748

Epoch: 5| Step: 1
Training loss: 0.5485334861204296
Validation loss: 2.3305530504700998

Epoch: 5| Step: 2
Training loss: 0.8679371248624744
Validation loss: 2.3292565732375774

Epoch: 5| Step: 3
Training loss: 0.9057267750377056
Validation loss: 2.2988198212462567

Epoch: 5| Step: 4
Training loss: 0.9697306499414265
Validation loss: 2.3270814049680157

Epoch: 5| Step: 5
Training loss: 1.0592030253398828
Validation loss: 2.306557418899204

Epoch: 5| Step: 6
Training loss: 0.922617629338711
Validation loss: 2.3191052925870794

Epoch: 5| Step: 7
Training loss: 0.9924513098162333
Validation loss: 2.3135977270649524

Epoch: 5| Step: 8
Training loss: 0.5986134960051329
Validation loss: 2.2965771368474766

Epoch: 5| Step: 9
Training loss: 1.3934581057489375
Validation loss: 2.286307845408687

Epoch: 5| Step: 10
Training loss: 0.7166777883450337
Validation loss: 2.2955738808163715

Epoch: 266| Step: 0
Training loss: 0.6008872416125984
Validation loss: 2.302660916996052

Epoch: 5| Step: 1
Training loss: 0.5935548662472224
Validation loss: 2.2956968613057396

Epoch: 5| Step: 2
Training loss: 1.0057573285235282
Validation loss: 2.302775854062274

Epoch: 5| Step: 3
Training loss: 1.397801643600622
Validation loss: 2.314740358155591

Epoch: 5| Step: 4
Training loss: 0.6262939648224315
Validation loss: 2.2991182150841603

Epoch: 5| Step: 5
Training loss: 1.0063336189545913
Validation loss: 2.2725310397987615

Epoch: 5| Step: 6
Training loss: 1.0301046079457936
Validation loss: 2.2575750528763536

Epoch: 5| Step: 7
Training loss: 0.6050780481642594
Validation loss: 2.2552920639529295

Epoch: 5| Step: 8
Training loss: 0.9835810411282122
Validation loss: 2.273593476764934

Epoch: 5| Step: 9
Training loss: 1.041804088428814
Validation loss: 2.2624944527394355

Epoch: 5| Step: 10
Training loss: 0.9277603306402031
Validation loss: 2.277192950381027

Epoch: 267| Step: 0
Training loss: 1.1045650926942776
Validation loss: 2.275909632504895

Epoch: 5| Step: 1
Training loss: 0.5280840728069945
Validation loss: 2.2979552939012953

Epoch: 5| Step: 2
Training loss: 0.9779061191370898
Validation loss: 2.34907499870875

Epoch: 5| Step: 3
Training loss: 1.1029904356409521
Validation loss: 2.3588188019425305

Epoch: 5| Step: 4
Training loss: 0.8176678487551708
Validation loss: 2.3379841565274697

Epoch: 5| Step: 5
Training loss: 0.7612888786021701
Validation loss: 2.3160444488023266

Epoch: 5| Step: 6
Training loss: 0.947265971075565
Validation loss: 2.2891880460012306

Epoch: 5| Step: 7
Training loss: 1.2473094116515238
Validation loss: 2.2609319321242745

Epoch: 5| Step: 8
Training loss: 1.1297843184605276
Validation loss: 2.2834154954820667

Epoch: 5| Step: 9
Training loss: 0.5293036316162385
Validation loss: 2.2730288391805855

Epoch: 5| Step: 10
Training loss: 0.5054783509181355
Validation loss: 2.291034459887606

Epoch: 268| Step: 0
Training loss: 0.6735573487167559
Validation loss: 2.279724885666513

Epoch: 5| Step: 1
Training loss: 1.013615248316726
Validation loss: 2.3081771768743047

Epoch: 5| Step: 2
Training loss: 1.055049297301905
Validation loss: 2.297179346414031

Epoch: 5| Step: 3
Training loss: 1.0207744049398646
Validation loss: 2.3035599303050276

Epoch: 5| Step: 4
Training loss: 0.9703878585374287
Validation loss: 2.307501385022797

Epoch: 5| Step: 5
Training loss: 0.6149112640112847
Validation loss: 2.3184909215995466

Epoch: 5| Step: 6
Training loss: 0.9521651515960882
Validation loss: 2.2876236584333935

Epoch: 5| Step: 7
Training loss: 1.0095544000169718
Validation loss: 2.2932397836967797

Epoch: 5| Step: 8
Training loss: 1.0377084614548715
Validation loss: 2.2998289804869647

Epoch: 5| Step: 9
Training loss: 0.7271149288697825
Validation loss: 2.278133443622096

Epoch: 5| Step: 10
Training loss: 0.8926934766627426
Validation loss: 2.2880127907243875

Epoch: 269| Step: 0
Training loss: 0.5620352096354503
Validation loss: 2.29617858200106

Epoch: 5| Step: 1
Training loss: 0.9905667320949078
Validation loss: 2.276860324996003

Epoch: 5| Step: 2
Training loss: 0.691277055469564
Validation loss: 2.3215087721487753

Epoch: 5| Step: 3
Training loss: 0.478979049799854
Validation loss: 2.305464071840887

Epoch: 5| Step: 4
Training loss: 0.8978374965545944
Validation loss: 2.278049542905217

Epoch: 5| Step: 5
Training loss: 1.0620169944193676
Validation loss: 2.2770305713634347

Epoch: 5| Step: 6
Training loss: 1.2038396719136721
Validation loss: 2.275922018636276

Epoch: 5| Step: 7
Training loss: 0.8273541803756138
Validation loss: 2.28770946326157

Epoch: 5| Step: 8
Training loss: 1.1450259861225307
Validation loss: 2.2890185067339766

Epoch: 5| Step: 9
Training loss: 1.0938402411154455
Validation loss: 2.270363833277012

Epoch: 5| Step: 10
Training loss: 0.33062674846439233
Validation loss: 2.26171248858024

Epoch: 270| Step: 0
Training loss: 0.8700718380876533
Validation loss: 2.2753703097142877

Epoch: 5| Step: 1
Training loss: 0.8261545598806094
Validation loss: 2.2587622874435382

Epoch: 5| Step: 2
Training loss: 1.0097482705607932
Validation loss: 2.298655761872303

Epoch: 5| Step: 3
Training loss: 0.9495262935045174
Validation loss: 2.3010192126284768

Epoch: 5| Step: 4
Training loss: 0.8441037743259769
Validation loss: 2.286525123150098

Epoch: 5| Step: 5
Training loss: 1.1024250954854058
Validation loss: 2.277946559414606

Epoch: 5| Step: 6
Training loss: 0.6318688597791136
Validation loss: 2.2857993626884685

Epoch: 5| Step: 7
Training loss: 0.9637257821074428
Validation loss: 2.2824850993841586

Epoch: 5| Step: 8
Training loss: 0.7965419297613403
Validation loss: 2.2894178769323674

Epoch: 5| Step: 9
Training loss: 0.7111487860641842
Validation loss: 2.2764848783639056

Epoch: 5| Step: 10
Training loss: 0.9040531299578867
Validation loss: 2.2990492596770555

Epoch: 271| Step: 0
Training loss: 0.970158598852916
Validation loss: 2.2895722656496065

Epoch: 5| Step: 1
Training loss: 0.542090824533825
Validation loss: 2.2993582374116435

Epoch: 5| Step: 2
Training loss: 0.8733354130081963
Validation loss: 2.2994798805606314

Epoch: 5| Step: 3
Training loss: 1.0120082720806707
Validation loss: 2.300910758729146

Epoch: 5| Step: 4
Training loss: 0.6319351236356993
Validation loss: 2.299447192091236

Epoch: 5| Step: 5
Training loss: 0.8967778342643525
Validation loss: 2.2548054272676126

Epoch: 5| Step: 6
Training loss: 0.8080723505062211
Validation loss: 2.264797341552692

Epoch: 5| Step: 7
Training loss: 1.213962541979557
Validation loss: 2.282374119805395

Epoch: 5| Step: 8
Training loss: 0.6839762897983058
Validation loss: 2.2993762603050696

Epoch: 5| Step: 9
Training loss: 0.5295165897432524
Validation loss: 2.2744168037643857

Epoch: 5| Step: 10
Training loss: 1.148784040210287
Validation loss: 2.3183822057769405

Epoch: 272| Step: 0
Training loss: 0.7465672613146179
Validation loss: 2.273051605891599

Epoch: 5| Step: 1
Training loss: 0.7652553522370833
Validation loss: 2.336438803912364

Epoch: 5| Step: 2
Training loss: 1.1569505579678647
Validation loss: 2.3259544751410046

Epoch: 5| Step: 3
Training loss: 0.841668811801657
Validation loss: 2.310793161660716

Epoch: 5| Step: 4
Training loss: 0.7305221946054878
Validation loss: 2.3195796441889147

Epoch: 5| Step: 5
Training loss: 1.0528402469881653
Validation loss: 2.333489454740644

Epoch: 5| Step: 6
Training loss: 0.8733335702716224
Validation loss: 2.3219555303357735

Epoch: 5| Step: 7
Training loss: 0.8781992463459837
Validation loss: 2.310615805158553

Epoch: 5| Step: 8
Training loss: 0.5577845013427694
Validation loss: 2.314425951582406

Epoch: 5| Step: 9
Training loss: 0.8990945155198254
Validation loss: 2.3216586969265305

Epoch: 5| Step: 10
Training loss: 0.87640166413564
Validation loss: 2.273707789408718

Epoch: 273| Step: 0
Training loss: 1.14682256594338
Validation loss: 2.297918478765225

Epoch: 5| Step: 1
Training loss: 1.136201354056641
Validation loss: 2.2800963807509342

Epoch: 5| Step: 2
Training loss: 0.6228766373198086
Validation loss: 2.252895650522924

Epoch: 5| Step: 3
Training loss: 0.7752793854449573
Validation loss: 2.287469634682704

Epoch: 5| Step: 4
Training loss: 0.6735380349934968
Validation loss: 2.276242874347983

Epoch: 5| Step: 5
Training loss: 0.626200405334724
Validation loss: 2.2866236393150867

Epoch: 5| Step: 6
Training loss: 0.949486777058351
Validation loss: 2.3208886760430767

Epoch: 5| Step: 7
Training loss: 0.6429655072673914
Validation loss: 2.2940914729293675

Epoch: 5| Step: 8
Training loss: 0.7499935229339662
Validation loss: 2.3130874375448536

Epoch: 5| Step: 9
Training loss: 0.7391079910826968
Validation loss: 2.2614137882916934

Epoch: 5| Step: 10
Training loss: 1.1622648760195795
Validation loss: 2.2652458442254315

Epoch: 274| Step: 0
Training loss: 0.917409653542031
Validation loss: 2.286330210780924

Epoch: 5| Step: 1
Training loss: 0.7958104371643534
Validation loss: 2.260191354475813

Epoch: 5| Step: 2
Training loss: 0.8248427139972324
Validation loss: 2.2698020429688914

Epoch: 5| Step: 3
Training loss: 0.9528149272403598
Validation loss: 2.2578986043230893

Epoch: 5| Step: 4
Training loss: 0.7466903617908138
Validation loss: 2.2644175269755324

Epoch: 5| Step: 5
Training loss: 0.9492662206011878
Validation loss: 2.3071481835143253

Epoch: 5| Step: 6
Training loss: 0.5395075854103175
Validation loss: 2.2868013980691586

Epoch: 5| Step: 7
Training loss: 0.6675387554490556
Validation loss: 2.2615048272290066

Epoch: 5| Step: 8
Training loss: 0.9777817096293994
Validation loss: 2.2603223484308077

Epoch: 5| Step: 9
Training loss: 0.8903860139606073
Validation loss: 2.2656241807663866

Epoch: 5| Step: 10
Training loss: 1.03871602183015
Validation loss: 2.2762063404423816

Epoch: 275| Step: 0
Training loss: 0.8700403935274061
Validation loss: 2.2682894486595675

Epoch: 5| Step: 1
Training loss: 0.9427130086090886
Validation loss: 2.239297321330722

Epoch: 5| Step: 2
Training loss: 0.59641328599121
Validation loss: 2.2218384681422445

Epoch: 5| Step: 3
Training loss: 0.9925236770726761
Validation loss: 2.245292789414017

Epoch: 5| Step: 4
Training loss: 0.6349603911684678
Validation loss: 2.2688224083276474

Epoch: 5| Step: 5
Training loss: 0.7767738668668925
Validation loss: 2.2726227287306764

Epoch: 5| Step: 6
Training loss: 1.2316399707060484
Validation loss: 2.252201305818973

Epoch: 5| Step: 7
Training loss: 0.9146502308865613
Validation loss: 2.297615211589697

Epoch: 5| Step: 8
Training loss: 0.929029472269561
Validation loss: 2.265344231067863

Epoch: 5| Step: 9
Training loss: 0.5843825497879044
Validation loss: 2.314238537474218

Epoch: 5| Step: 10
Training loss: 0.31232499944634523
Validation loss: 2.3035897581599745

Epoch: 276| Step: 0
Training loss: 0.947419804875687
Validation loss: 2.299974187962031

Epoch: 5| Step: 1
Training loss: 0.6504328258673057
Validation loss: 2.2968188104487597

Epoch: 5| Step: 2
Training loss: 0.5711263310731475
Validation loss: 2.2893201842626

Epoch: 5| Step: 3
Training loss: 0.9473981626935316
Validation loss: 2.259742152654179

Epoch: 5| Step: 4
Training loss: 0.6750627788737021
Validation loss: 2.2511728151497703

Epoch: 5| Step: 5
Training loss: 0.9075424908970714
Validation loss: 2.2338301360514983

Epoch: 5| Step: 6
Training loss: 0.7442680109681062
Validation loss: 2.2536216833873195

Epoch: 5| Step: 7
Training loss: 1.1823197864207722
Validation loss: 2.2485081182821003

Epoch: 5| Step: 8
Training loss: 0.7634694643390857
Validation loss: 2.2355978181373226

Epoch: 5| Step: 9
Training loss: 0.9686241683454262
Validation loss: 2.224863378347545

Epoch: 5| Step: 10
Training loss: 0.48978038298886034
Validation loss: 2.250039484846612

Epoch: 277| Step: 0
Training loss: 0.9086577887366111
Validation loss: 2.2478917692036333

Epoch: 5| Step: 1
Training loss: 0.29789762297143274
Validation loss: 2.25598700455808

Epoch: 5| Step: 2
Training loss: 0.6749849202979452
Validation loss: 2.2508063463774275

Epoch: 5| Step: 3
Training loss: 0.5157400349695818
Validation loss: 2.269515416476607

Epoch: 5| Step: 4
Training loss: 0.5457134718245141
Validation loss: 2.2822418158321756

Epoch: 5| Step: 5
Training loss: 0.5728319770177982
Validation loss: 2.264157042646874

Epoch: 5| Step: 6
Training loss: 1.1491266375774531
Validation loss: 2.273697275302943

Epoch: 5| Step: 7
Training loss: 0.822939960938734
Validation loss: 2.274837630944938

Epoch: 5| Step: 8
Training loss: 1.024533274853503
Validation loss: 2.2772805418989592

Epoch: 5| Step: 9
Training loss: 1.2037838209556584
Validation loss: 2.295361130253141

Epoch: 5| Step: 10
Training loss: 0.8772761847957518
Validation loss: 2.2627337289074756

Epoch: 278| Step: 0
Training loss: 0.8335352096809666
Validation loss: 2.2644482304398252

Epoch: 5| Step: 1
Training loss: 1.1182064398185592
Validation loss: 2.274674971651408

Epoch: 5| Step: 2
Training loss: 0.924418770693281
Validation loss: 2.2767673175836385

Epoch: 5| Step: 3
Training loss: 1.041309193626445
Validation loss: 2.255274094007886

Epoch: 5| Step: 4
Training loss: 0.6049436445628635
Validation loss: 2.266358030869781

Epoch: 5| Step: 5
Training loss: 0.7487554555703744
Validation loss: 2.265580955589274

Epoch: 5| Step: 6
Training loss: 0.7685138153492294
Validation loss: 2.3089468469612444

Epoch: 5| Step: 7
Training loss: 0.49342078146174156
Validation loss: 2.2777503738368887

Epoch: 5| Step: 8
Training loss: 0.9650622595334709
Validation loss: 2.289212969595284

Epoch: 5| Step: 9
Training loss: 0.670438028243792
Validation loss: 2.280383349005497

Epoch: 5| Step: 10
Training loss: 0.6107508459596712
Validation loss: 2.2861336535404297

Epoch: 279| Step: 0
Training loss: 1.0020788757055883
Validation loss: 2.2727791956827583

Epoch: 5| Step: 1
Training loss: 0.6411645989314863
Validation loss: 2.2926392800428514

Epoch: 5| Step: 2
Training loss: 0.8192238259253732
Validation loss: 2.276681274898451

Epoch: 5| Step: 3
Training loss: 0.9109379436302086
Validation loss: 2.2569473618287907

Epoch: 5| Step: 4
Training loss: 0.36883322213078296
Validation loss: 2.260693025804171

Epoch: 5| Step: 5
Training loss: 0.7664900972033953
Validation loss: 2.274184783264691

Epoch: 5| Step: 6
Training loss: 0.9575172280337866
Validation loss: 2.2864066512489924

Epoch: 5| Step: 7
Training loss: 0.827450387510453
Validation loss: 2.285404337347583

Epoch: 5| Step: 8
Training loss: 0.7499064546103059
Validation loss: 2.3197847723781875

Epoch: 5| Step: 9
Training loss: 1.1907344237179185
Validation loss: 2.3037342356091814

Epoch: 5| Step: 10
Training loss: 0.38045209969622856
Validation loss: 2.349543002919541

Epoch: 280| Step: 0
Training loss: 0.6475290115956208
Validation loss: 2.3629680412774374

Epoch: 5| Step: 1
Training loss: 1.000567454030158
Validation loss: 2.3831321992714276

Epoch: 5| Step: 2
Training loss: 0.7720349628704313
Validation loss: 2.332365582074958

Epoch: 5| Step: 3
Training loss: 0.8694106464770498
Validation loss: 2.310315018647241

Epoch: 5| Step: 4
Training loss: 0.9174763434268118
Validation loss: 2.3084133703686556

Epoch: 5| Step: 5
Training loss: 0.8151440879787558
Validation loss: 2.2742867771769832

Epoch: 5| Step: 6
Training loss: 0.652720496750956
Validation loss: 2.274485906882249

Epoch: 5| Step: 7
Training loss: 0.7889102751186634
Validation loss: 2.2745828571320623

Epoch: 5| Step: 8
Training loss: 0.8086074238233744
Validation loss: 2.281609410118604

Epoch: 5| Step: 9
Training loss: 0.7784730768515706
Validation loss: 2.2649569818311073

Epoch: 5| Step: 10
Training loss: 0.8619954125908486
Validation loss: 2.3052355154206734

Epoch: 281| Step: 0
Training loss: 0.9078309968255668
Validation loss: 2.2895694350390032

Epoch: 5| Step: 1
Training loss: 0.5950122516636931
Validation loss: 2.2801227681152736

Epoch: 5| Step: 2
Training loss: 1.0642639552019804
Validation loss: 2.28981879079474

Epoch: 5| Step: 3
Training loss: 0.6071385400482372
Validation loss: 2.2531077617555706

Epoch: 5| Step: 4
Training loss: 0.875840668785187
Validation loss: 2.2832648706318373

Epoch: 5| Step: 5
Training loss: 0.8765381508775575
Validation loss: 2.293862065559612

Epoch: 5| Step: 6
Training loss: 0.7352622333794293
Validation loss: 2.2774639822227827

Epoch: 5| Step: 7
Training loss: 0.812751914365609
Validation loss: 2.2805436417828346

Epoch: 5| Step: 8
Training loss: 0.7328398058913953
Validation loss: 2.2709924791317846

Epoch: 5| Step: 9
Training loss: 0.5636492221692566
Validation loss: 2.2414167069101003

Epoch: 5| Step: 10
Training loss: 0.9383859263147692
Validation loss: 2.2060030057151776

Epoch: 282| Step: 0
Training loss: 1.277504493795057
Validation loss: 2.2163513843273592

Epoch: 5| Step: 1
Training loss: 0.8120704028680795
Validation loss: 2.229666008701876

Epoch: 5| Step: 2
Training loss: 0.5747720297565065
Validation loss: 2.247468287410884

Epoch: 5| Step: 3
Training loss: 0.61282834866585
Validation loss: 2.270344251302499

Epoch: 5| Step: 4
Training loss: 0.714896861953881
Validation loss: 2.2702162205992185

Epoch: 5| Step: 5
Training loss: 0.21330767212855037
Validation loss: 2.248966466187007

Epoch: 5| Step: 6
Training loss: 0.5625664618752799
Validation loss: 2.301560243699959

Epoch: 5| Step: 7
Training loss: 0.9233644059584214
Validation loss: 2.282287036044124

Epoch: 5| Step: 8
Training loss: 0.8554455131266382
Validation loss: 2.2852253357490357

Epoch: 5| Step: 9
Training loss: 0.6981739357622778
Validation loss: 2.2741363494906546

Epoch: 5| Step: 10
Training loss: 1.1168483406048761
Validation loss: 2.267228318688369

Epoch: 283| Step: 0
Training loss: 0.8804004767957797
Validation loss: 2.2845230659895046

Epoch: 5| Step: 1
Training loss: 0.7578964186933467
Validation loss: 2.3113690132383904

Epoch: 5| Step: 2
Training loss: 0.6479249330179337
Validation loss: 2.2868580254510555

Epoch: 5| Step: 3
Training loss: 1.2561760913876099
Validation loss: 2.291665788875945

Epoch: 5| Step: 4
Training loss: 0.5526695078606887
Validation loss: 2.3256620890987665

Epoch: 5| Step: 5
Training loss: 0.9964091082252734
Validation loss: 2.3172873962433034

Epoch: 5| Step: 6
Training loss: 0.7418565112463839
Validation loss: 2.2632683377974723

Epoch: 5| Step: 7
Training loss: 0.5866641815450804
Validation loss: 2.3158578547772195

Epoch: 5| Step: 8
Training loss: 0.7395818244667959
Validation loss: 2.3223172109655463

Epoch: 5| Step: 9
Training loss: 0.8308417543911062
Validation loss: 2.325794748192033

Epoch: 5| Step: 10
Training loss: 0.32104436489970695
Validation loss: 2.310730448058769

Epoch: 284| Step: 0
Training loss: 0.7409657511318815
Validation loss: 2.3081790289284223

Epoch: 5| Step: 1
Training loss: 0.3737021478109929
Validation loss: 2.299603748027758

Epoch: 5| Step: 2
Training loss: 1.0090514854475034
Validation loss: 2.2831947868762854

Epoch: 5| Step: 3
Training loss: 1.1667432703118772
Validation loss: 2.274466734325114

Epoch: 5| Step: 4
Training loss: 0.5971592600726272
Validation loss: 2.276790336290986

Epoch: 5| Step: 5
Training loss: 0.783794911997508
Validation loss: 2.2347123292781976

Epoch: 5| Step: 6
Training loss: 0.6074121603234908
Validation loss: 2.283640207322409

Epoch: 5| Step: 7
Training loss: 0.746074097059959
Validation loss: 2.2666001894043815

Epoch: 5| Step: 8
Training loss: 0.8570206383297679
Validation loss: 2.282922735797652

Epoch: 5| Step: 9
Training loss: 0.9162927139338921
Validation loss: 2.274046854247863

Epoch: 5| Step: 10
Training loss: 0.4361876662079516
Validation loss: 2.2641626002534907

Epoch: 285| Step: 0
Training loss: 0.8252579343611385
Validation loss: 2.2335179615185976

Epoch: 5| Step: 1
Training loss: 0.45950862082985844
Validation loss: 2.2226562355823374

Epoch: 5| Step: 2
Training loss: 0.5930297398017035
Validation loss: 2.262450194412587

Epoch: 5| Step: 3
Training loss: 0.567161530039385
Validation loss: 2.2739820759479983

Epoch: 5| Step: 4
Training loss: 1.0029787164903985
Validation loss: 2.2498141078657152

Epoch: 5| Step: 5
Training loss: 0.9020779040542508
Validation loss: 2.2882658194228216

Epoch: 5| Step: 6
Training loss: 0.7424301553878806
Validation loss: 2.2950472630038847

Epoch: 5| Step: 7
Training loss: 0.9334779930973771
Validation loss: 2.2937256886337036

Epoch: 5| Step: 8
Training loss: 0.891841559474873
Validation loss: 2.2999791592460297

Epoch: 5| Step: 9
Training loss: 0.7283049987181448
Validation loss: 2.288239779722365

Epoch: 5| Step: 10
Training loss: 0.6879773433511625
Validation loss: 2.3014652530698756

Epoch: 286| Step: 0
Training loss: 1.020144924639066
Validation loss: 2.297485452372241

Epoch: 5| Step: 1
Training loss: 0.8771452151748768
Validation loss: 2.299625360353654

Epoch: 5| Step: 2
Training loss: 0.8567924535433254
Validation loss: 2.272474728897313

Epoch: 5| Step: 3
Training loss: 0.6421474416448809
Validation loss: 2.3092630108676793

Epoch: 5| Step: 4
Training loss: 0.3979395204076078
Validation loss: 2.2772640856769333

Epoch: 5| Step: 5
Training loss: 0.769324763910057
Validation loss: 2.2895474887304497

Epoch: 5| Step: 6
Training loss: 0.980791198475817
Validation loss: 2.3088793037571267

Epoch: 5| Step: 7
Training loss: 0.7110302204410817
Validation loss: 2.3101759819995173

Epoch: 5| Step: 8
Training loss: 0.7471060949993723
Validation loss: 2.2839378853919876

Epoch: 5| Step: 9
Training loss: 0.5972548489443639
Validation loss: 2.27757986329225

Epoch: 5| Step: 10
Training loss: 0.648463719768573
Validation loss: 2.2647378872862847

Epoch: 287| Step: 0
Training loss: 0.7568274712858124
Validation loss: 2.234953041610184

Epoch: 5| Step: 1
Training loss: 0.5730409285139955
Validation loss: 2.2559663804470027

Epoch: 5| Step: 2
Training loss: 0.7372090460784744
Validation loss: 2.264902868664013

Epoch: 5| Step: 3
Training loss: 0.8200886375507155
Validation loss: 2.2473488881924175

Epoch: 5| Step: 4
Training loss: 0.8288995251755811
Validation loss: 2.2444099787186413

Epoch: 5| Step: 5
Training loss: 1.0100754164875476
Validation loss: 2.236063044699843

Epoch: 5| Step: 6
Training loss: 0.6343428862011596
Validation loss: 2.2476803753196632

Epoch: 5| Step: 7
Training loss: 0.8296137688988592
Validation loss: 2.245073037654866

Epoch: 5| Step: 8
Training loss: 0.7896866171393764
Validation loss: 2.2498699313570802

Epoch: 5| Step: 9
Training loss: 0.756392889474161
Validation loss: 2.287228735623879

Epoch: 5| Step: 10
Training loss: 0.534609355065238
Validation loss: 2.277812837336225

Epoch: 288| Step: 0
Training loss: 0.7102053718658081
Validation loss: 2.2612421490452186

Epoch: 5| Step: 1
Training loss: 0.9906277749777835
Validation loss: 2.290855425962526

Epoch: 5| Step: 2
Training loss: 0.7487598338301302
Validation loss: 2.278046490346547

Epoch: 5| Step: 3
Training loss: 0.5065872081870493
Validation loss: 2.2859373754704957

Epoch: 5| Step: 4
Training loss: 0.7120913688990497
Validation loss: 2.2801451806633968

Epoch: 5| Step: 5
Training loss: 0.8608735630227796
Validation loss: 2.2630281790339133

Epoch: 5| Step: 6
Training loss: 0.5801773243350492
Validation loss: 2.27537343797139

Epoch: 5| Step: 7
Training loss: 0.8045395650339497
Validation loss: 2.264344553065196

Epoch: 5| Step: 8
Training loss: 0.5941919890202378
Validation loss: 2.2867825541008866

Epoch: 5| Step: 9
Training loss: 0.9087294171401613
Validation loss: 2.2522385034354917

Epoch: 5| Step: 10
Training loss: 0.8784072476676903
Validation loss: 2.2379288839421183

Epoch: 289| Step: 0
Training loss: 0.8459683678487244
Validation loss: 2.234612315550602

Epoch: 5| Step: 1
Training loss: 1.0323588449821735
Validation loss: 2.2319039879069686

Epoch: 5| Step: 2
Training loss: 0.747837246438757
Validation loss: 2.242714781202474

Epoch: 5| Step: 3
Training loss: 0.6236159497091978
Validation loss: 2.2497179134834995

Epoch: 5| Step: 4
Training loss: 0.49666248971294236
Validation loss: 2.255120074730968

Epoch: 5| Step: 5
Training loss: 0.9198576951367073
Validation loss: 2.26067706198362

Epoch: 5| Step: 6
Training loss: 0.5590132092090677
Validation loss: 2.253186792503675

Epoch: 5| Step: 7
Training loss: 0.7987298508611514
Validation loss: 2.2534167668038494

Epoch: 5| Step: 8
Training loss: 0.5766433597092074
Validation loss: 2.2790934525184223

Epoch: 5| Step: 9
Training loss: 0.634313804042527
Validation loss: 2.2607739727881495

Epoch: 5| Step: 10
Training loss: 0.9260612418498377
Validation loss: 2.2598232537367355

Epoch: 290| Step: 0
Training loss: 0.8234121344059763
Validation loss: 2.2768494702078597

Epoch: 5| Step: 1
Training loss: 1.028584938017365
Validation loss: 2.292043177493822

Epoch: 5| Step: 2
Training loss: 0.9009875389702339
Validation loss: 2.2887044176667954

Epoch: 5| Step: 3
Training loss: 0.6838753910262297
Validation loss: 2.2928478482105183

Epoch: 5| Step: 4
Training loss: 0.7356989674421839
Validation loss: 2.286100595933067

Epoch: 5| Step: 5
Training loss: 0.7195703137590717
Validation loss: 2.3054436851803564

Epoch: 5| Step: 6
Training loss: 0.5627154096770224
Validation loss: 2.2804711985142037

Epoch: 5| Step: 7
Training loss: 0.8676836810935746
Validation loss: 2.2392754032318165

Epoch: 5| Step: 8
Training loss: 0.45557168873691617
Validation loss: 2.269843019248306

Epoch: 5| Step: 9
Training loss: 0.6974578079670452
Validation loss: 2.2554360542138427

Epoch: 5| Step: 10
Training loss: 0.5830364380011848
Validation loss: 2.2656942807454543

Epoch: 291| Step: 0
Training loss: 0.7485898987621848
Validation loss: 2.2866077806394767

Epoch: 5| Step: 1
Training loss: 0.7584639040355335
Validation loss: 2.263148710747057

Epoch: 5| Step: 2
Training loss: 0.8542831775629443
Validation loss: 2.291184002191434

Epoch: 5| Step: 3
Training loss: 0.9632276212269323
Validation loss: 2.253397332502726

Epoch: 5| Step: 4
Training loss: 0.6519252554009024
Validation loss: 2.272513749355282

Epoch: 5| Step: 5
Training loss: 0.8315625012041885
Validation loss: 2.240916056255886

Epoch: 5| Step: 6
Training loss: 0.813512171667725
Validation loss: 2.2528354275450404

Epoch: 5| Step: 7
Training loss: 0.5767254255472233
Validation loss: 2.256789225837973

Epoch: 5| Step: 8
Training loss: 0.6911693533541702
Validation loss: 2.2749302050695417

Epoch: 5| Step: 9
Training loss: 0.6438222974160063
Validation loss: 2.2865614697621433

Epoch: 5| Step: 10
Training loss: 0.4870386563307944
Validation loss: 2.316027715662552

Epoch: 292| Step: 0
Training loss: 0.7906567925254228
Validation loss: 2.2974100422418693

Epoch: 5| Step: 1
Training loss: 0.6859500058365785
Validation loss: 2.3622553676856852

Epoch: 5| Step: 2
Training loss: 1.0121828877743502
Validation loss: 2.3607302916168593

Epoch: 5| Step: 3
Training loss: 0.9196458795315287
Validation loss: 2.3171285809572364

Epoch: 5| Step: 4
Training loss: 0.8421997026964295
Validation loss: 2.27939752671308

Epoch: 5| Step: 5
Training loss: 0.5897735654999039
Validation loss: 2.2599845354274546

Epoch: 5| Step: 6
Training loss: 0.574467663435071
Validation loss: 2.2632036032754934

Epoch: 5| Step: 7
Training loss: 0.7266175444066422
Validation loss: 2.2454986528666607

Epoch: 5| Step: 8
Training loss: 0.6709481211204952
Validation loss: 2.2385795761110647

Epoch: 5| Step: 9
Training loss: 0.6570312980806059
Validation loss: 2.253856194951703

Epoch: 5| Step: 10
Training loss: 0.682673636136701
Validation loss: 2.2767507698233986

Epoch: 293| Step: 0
Training loss: 0.7889568900259748
Validation loss: 2.288465516737825

Epoch: 5| Step: 1
Training loss: 0.7151738639664369
Validation loss: 2.3060591659117695

Epoch: 5| Step: 2
Training loss: 0.4307760149361272
Validation loss: 2.3192058001257165

Epoch: 5| Step: 3
Training loss: 0.7021726092129278
Validation loss: 2.3193541643843796

Epoch: 5| Step: 4
Training loss: 0.5470977601993671
Validation loss: 2.273766363081288

Epoch: 5| Step: 5
Training loss: 0.8723694223230267
Validation loss: 2.243922229639293

Epoch: 5| Step: 6
Training loss: 0.5883767788797122
Validation loss: 2.2730906401310014

Epoch: 5| Step: 7
Training loss: 0.6877100580265668
Validation loss: 2.2491110306860325

Epoch: 5| Step: 8
Training loss: 1.0081756292449155
Validation loss: 2.2204587689062794

Epoch: 5| Step: 9
Training loss: 0.9665886548780472
Validation loss: 2.226307606351102

Epoch: 5| Step: 10
Training loss: 0.810357974917292
Validation loss: 2.2735299693243447

Epoch: 294| Step: 0
Training loss: 0.4895279037940791
Validation loss: 2.279212414221896

Epoch: 5| Step: 1
Training loss: 0.5792107310330433
Validation loss: 2.304429437098294

Epoch: 5| Step: 2
Training loss: 0.7954655318306554
Validation loss: 2.286492517444553

Epoch: 5| Step: 3
Training loss: 0.579874561696957
Validation loss: 2.2782453606387345

Epoch: 5| Step: 4
Training loss: 0.4956278377802882
Validation loss: 2.294280643425167

Epoch: 5| Step: 5
Training loss: 0.9335374056999719
Validation loss: 2.2315331525116857

Epoch: 5| Step: 6
Training loss: 0.49275122254895926
Validation loss: 2.2366277483685026

Epoch: 5| Step: 7
Training loss: 0.9366707631244431
Validation loss: 2.188053695053448

Epoch: 5| Step: 8
Training loss: 0.9906111683165691
Validation loss: 2.255956645037422

Epoch: 5| Step: 9
Training loss: 0.8752565688949371
Validation loss: 2.2257504922446745

Epoch: 5| Step: 10
Training loss: 0.6546062136786702
Validation loss: 2.222616597469662

Epoch: 295| Step: 0
Training loss: 0.7239533202365963
Validation loss: 2.234721454872772

Epoch: 5| Step: 1
Training loss: 0.9619652748998103
Validation loss: 2.22997603636755

Epoch: 5| Step: 2
Training loss: 0.7261923800934097
Validation loss: 2.2088964057484364

Epoch: 5| Step: 3
Training loss: 0.5966449733694056
Validation loss: 2.23685836556545

Epoch: 5| Step: 4
Training loss: 0.9346379780763037
Validation loss: 2.24482938829337

Epoch: 5| Step: 5
Training loss: 0.7297122730567062
Validation loss: 2.241847763114484

Epoch: 5| Step: 6
Training loss: 0.6543968921340415
Validation loss: 2.2240312607612562

Epoch: 5| Step: 7
Training loss: 0.8373067106129519
Validation loss: 2.2378984887940363

Epoch: 5| Step: 8
Training loss: 0.4920590248154778
Validation loss: 2.2340631328291756

Epoch: 5| Step: 9
Training loss: 0.5540499179399035
Validation loss: 2.2244264475467346

Epoch: 5| Step: 10
Training loss: 0.6513473759373507
Validation loss: 2.2201744843838767

Epoch: 296| Step: 0
Training loss: 0.7876289110787374
Validation loss: 2.214158146310325

Epoch: 5| Step: 1
Training loss: 0.396322057411735
Validation loss: 2.2290992464027437

Epoch: 5| Step: 2
Training loss: 1.013367594361434
Validation loss: 2.2158848508933713

Epoch: 5| Step: 3
Training loss: 0.4396680687716187
Validation loss: 2.222080015516967

Epoch: 5| Step: 4
Training loss: 0.7742762015974457
Validation loss: 2.2206128870567237

Epoch: 5| Step: 5
Training loss: 0.7513259055307249
Validation loss: 2.2554522201557687

Epoch: 5| Step: 6
Training loss: 0.6177225328928719
Validation loss: 2.2420139029017108

Epoch: 5| Step: 7
Training loss: 0.6647598419852471
Validation loss: 2.2660467992100495

Epoch: 5| Step: 8
Training loss: 0.733478526531141
Validation loss: 2.268724391540404

Epoch: 5| Step: 9
Training loss: 0.8111623242909088
Validation loss: 2.257231316100255

Epoch: 5| Step: 10
Training loss: 0.768988209545989
Validation loss: 2.2488564686787704

Epoch: 297| Step: 0
Training loss: 0.9362334915355851
Validation loss: 2.2711131937695326

Epoch: 5| Step: 1
Training loss: 0.9463000852968366
Validation loss: 2.2654154062829943

Epoch: 5| Step: 2
Training loss: 0.6744471042823434
Validation loss: 2.265359628628845

Epoch: 5| Step: 3
Training loss: 0.7491914443846799
Validation loss: 2.2585953115703448

Epoch: 5| Step: 4
Training loss: 0.7669083874187962
Validation loss: 2.2733600928744933

Epoch: 5| Step: 5
Training loss: 0.530083806816353
Validation loss: 2.2556828022438964

Epoch: 5| Step: 6
Training loss: 0.5640652389671209
Validation loss: 2.236204754749608

Epoch: 5| Step: 7
Training loss: 0.4234629169451136
Validation loss: 2.2247073891006686

Epoch: 5| Step: 8
Training loss: 0.913567727013363
Validation loss: 2.223057961290737

Epoch: 5| Step: 9
Training loss: 0.41227359121381607
Validation loss: 2.257809892146146

Epoch: 5| Step: 10
Training loss: 0.7521607743932733
Validation loss: 2.2457662775080816

Epoch: 298| Step: 0
Training loss: 0.48446977364978766
Validation loss: 2.316556352287837

Epoch: 5| Step: 1
Training loss: 0.5269918327169176
Validation loss: 2.334522360402697

Epoch: 5| Step: 2
Training loss: 0.7639213603275599
Validation loss: 2.2912086517609778

Epoch: 5| Step: 3
Training loss: 0.8232283585406184
Validation loss: 2.300829494199002

Epoch: 5| Step: 4
Training loss: 0.8823610012069654
Validation loss: 2.263788154045735

Epoch: 5| Step: 5
Training loss: 1.0382853878906095
Validation loss: 2.2646611342666536

Epoch: 5| Step: 6
Training loss: 0.61721965850876
Validation loss: 2.246556712300443

Epoch: 5| Step: 7
Training loss: 0.7283133872928712
Validation loss: 2.241541322856637

Epoch: 5| Step: 8
Training loss: 0.5328966874092498
Validation loss: 2.2081811968204703

Epoch: 5| Step: 9
Training loss: 0.6626893375755851
Validation loss: 2.2433064953428077

Epoch: 5| Step: 10
Training loss: 0.6300845510648192
Validation loss: 2.244171698411965

Epoch: 299| Step: 0
Training loss: 0.6427245973191307
Validation loss: 2.2642704632699977

Epoch: 5| Step: 1
Training loss: 0.7300615450638348
Validation loss: 2.2792000257255363

Epoch: 5| Step: 2
Training loss: 0.6314527950675374
Validation loss: 2.2696754703860114

Epoch: 5| Step: 3
Training loss: 0.7897367335114238
Validation loss: 2.2573616056482266

Epoch: 5| Step: 4
Training loss: 0.7700186797762018
Validation loss: 2.2571338136380876

Epoch: 5| Step: 5
Training loss: 0.3945434492887871
Validation loss: 2.267147492113655

Epoch: 5| Step: 6
Training loss: 0.839460241004459
Validation loss: 2.266527981952051

Epoch: 5| Step: 7
Training loss: 0.7285492099251095
Validation loss: 2.268166133314227

Epoch: 5| Step: 8
Training loss: 0.632282364686251
Validation loss: 2.256035738484549

Epoch: 5| Step: 9
Training loss: 0.7811147191223748
Validation loss: 2.243202904821599

Epoch: 5| Step: 10
Training loss: 0.6327571844720227
Validation loss: 2.224392992090429

Epoch: 300| Step: 0
Training loss: 0.5141964978364775
Validation loss: 2.22322730524059

Epoch: 5| Step: 1
Training loss: 0.8502331778509028
Validation loss: 2.2438270474496664

Epoch: 5| Step: 2
Training loss: 0.7030494861319029
Validation loss: 2.2601495918363663

Epoch: 5| Step: 3
Training loss: 0.5716475706785058
Validation loss: 2.2693040508949465

Epoch: 5| Step: 4
Training loss: 0.3092680457222849
Validation loss: 2.2806977128724624

Epoch: 5| Step: 5
Training loss: 0.8468056203427703
Validation loss: 2.312236040255568

Epoch: 5| Step: 6
Training loss: 0.37453986787012195
Validation loss: 2.2925256843768382

Epoch: 5| Step: 7
Training loss: 0.7529825273667529
Validation loss: 2.2952971037132595

Epoch: 5| Step: 8
Training loss: 0.7601004600634925
Validation loss: 2.2880565826000883

Epoch: 5| Step: 9
Training loss: 0.5565964262965839
Validation loss: 2.269584480192173

Epoch: 5| Step: 10
Training loss: 1.0749208132831956
Validation loss: 2.280978866177389

Testing loss: 2.463313914142027
