Epoch: 1| Step: 0
Training loss: 5.452651038791138
Validation loss: 5.832524620051906

Epoch: 6| Step: 1
Training loss: 5.883696916420566
Validation loss: 5.81390061243256

Epoch: 6| Step: 2
Training loss: 5.590323821431706
Validation loss: 5.7963208967831

Epoch: 6| Step: 3
Training loss: 6.235248399327677
Validation loss: 5.776548402468439

Epoch: 6| Step: 4
Training loss: 6.575690972169739
Validation loss: 5.753530633762291

Epoch: 6| Step: 5
Training loss: 4.927173874435122
Validation loss: 5.728049523702572

Epoch: 6| Step: 6
Training loss: 5.545256902524015
Validation loss: 5.698203781185068

Epoch: 6| Step: 7
Training loss: 3.455403952494491
Validation loss: 5.664095645817458

Epoch: 6| Step: 8
Training loss: 6.604851944886213
Validation loss: 5.627607456325572

Epoch: 6| Step: 9
Training loss: 6.014790425062363
Validation loss: 5.58606473842498

Epoch: 6| Step: 10
Training loss: 4.7524664649000945
Validation loss: 5.540412826986454

Epoch: 6| Step: 11
Training loss: 5.769864144403493
Validation loss: 5.4903153633106

Epoch: 6| Step: 12
Training loss: 6.683103167723767
Validation loss: 5.434718779407992

Epoch: 6| Step: 13
Training loss: 4.961757321839229
Validation loss: 5.373631514199546

Epoch: 2| Step: 0
Training loss: 5.44191501317506
Validation loss: 5.306507366822713

Epoch: 6| Step: 1
Training loss: 4.4858532107415545
Validation loss: 5.234986432527426

Epoch: 6| Step: 2
Training loss: 6.35325684417655
Validation loss: 5.161545309502806

Epoch: 6| Step: 3
Training loss: 4.845039048485333
Validation loss: 5.085430913116786

Epoch: 6| Step: 4
Training loss: 5.372403959513768
Validation loss: 5.011951686813818

Epoch: 6| Step: 5
Training loss: 5.028746935952296
Validation loss: 4.9420532088388

Epoch: 6| Step: 6
Training loss: 4.81036706201952
Validation loss: 4.875627988928358

Epoch: 6| Step: 7
Training loss: 4.832630018605657
Validation loss: 4.814940985360556

Epoch: 6| Step: 8
Training loss: 5.134567262714726
Validation loss: 4.759570932009016

Epoch: 6| Step: 9
Training loss: 5.106939546118591
Validation loss: 4.7103627381677775

Epoch: 6| Step: 10
Training loss: 4.841725572412659
Validation loss: 4.667189216509775

Epoch: 6| Step: 11
Training loss: 3.9658322159157113
Validation loss: 4.629854467686284

Epoch: 6| Step: 12
Training loss: 4.2698756687189805
Validation loss: 4.599530311617158

Epoch: 6| Step: 13
Training loss: 4.403305260113716
Validation loss: 4.573022552698761

Epoch: 3| Step: 0
Training loss: 4.812988256481751
Validation loss: 4.548877704223206

Epoch: 6| Step: 1
Training loss: 3.66640698351427
Validation loss: 4.527260421100309

Epoch: 6| Step: 2
Training loss: 5.069454361486388
Validation loss: 4.504600625132009

Epoch: 6| Step: 3
Training loss: 4.172461764901558
Validation loss: 4.486501202176996

Epoch: 6| Step: 4
Training loss: 4.740193332640616
Validation loss: 4.468086196242324

Epoch: 6| Step: 5
Training loss: 5.306984585259655
Validation loss: 4.454136251879498

Epoch: 6| Step: 6
Training loss: 3.9684148932327554
Validation loss: 4.438273150926479

Epoch: 6| Step: 7
Training loss: 4.38720569982068
Validation loss: 4.422705166241169

Epoch: 6| Step: 8
Training loss: 4.74536629584464
Validation loss: 4.402179456140193

Epoch: 6| Step: 9
Training loss: 4.149482437399996
Validation loss: 4.379969185236461

Epoch: 6| Step: 10
Training loss: 3.595534967720598
Validation loss: 4.359519595901943

Epoch: 6| Step: 11
Training loss: 5.090714937074815
Validation loss: 4.343404387131318

Epoch: 6| Step: 12
Training loss: 5.261329778101307
Validation loss: 4.32333604024035

Epoch: 6| Step: 13
Training loss: 3.902967370716158
Validation loss: 4.303590811900055

Epoch: 4| Step: 0
Training loss: 4.985025680307494
Validation loss: 4.2807491312799515

Epoch: 6| Step: 1
Training loss: 3.9438883713328736
Validation loss: 4.256006083099917

Epoch: 6| Step: 2
Training loss: 4.828502850114057
Validation loss: 4.235988003825697

Epoch: 6| Step: 3
Training loss: 4.480015779194972
Validation loss: 4.211053071557472

Epoch: 6| Step: 4
Training loss: 4.4409879489143345
Validation loss: 4.193696224203532

Epoch: 6| Step: 5
Training loss: 3.494762589191084
Validation loss: 4.179866157265564

Epoch: 6| Step: 6
Training loss: 4.555108759196147
Validation loss: 4.164708649995404

Epoch: 6| Step: 7
Training loss: 3.7653966810725956
Validation loss: 4.146943627842339

Epoch: 6| Step: 8
Training loss: 4.368634415872528
Validation loss: 4.123483955363993

Epoch: 6| Step: 9
Training loss: 4.495304837185531
Validation loss: 4.110788731701068

Epoch: 6| Step: 10
Training loss: 3.2799249789334572
Validation loss: 4.094684926485062

Epoch: 6| Step: 11
Training loss: 4.792225326921135
Validation loss: 4.073448234375389

Epoch: 6| Step: 12
Training loss: 4.480580282777015
Validation loss: 4.062841532622949

Epoch: 6| Step: 13
Training loss: 3.5232791569014306
Validation loss: 4.057869950136724

Epoch: 5| Step: 0
Training loss: 4.257166486255761
Validation loss: 4.035664758492041

Epoch: 6| Step: 1
Training loss: 4.500163605153098
Validation loss: 4.0141355410332915

Epoch: 6| Step: 2
Training loss: 5.056407134793733
Validation loss: 3.9997608756812704

Epoch: 6| Step: 3
Training loss: 3.5314360713041384
Validation loss: 3.984069214100902

Epoch: 6| Step: 4
Training loss: 4.920252166116471
Validation loss: 3.976513758738053

Epoch: 6| Step: 5
Training loss: 2.7829966686035568
Validation loss: 3.95288663689683

Epoch: 6| Step: 6
Training loss: 4.246000764419983
Validation loss: 3.956016511890597

Epoch: 6| Step: 7
Training loss: 3.9887032729244822
Validation loss: 3.9506581534507417

Epoch: 6| Step: 8
Training loss: 3.6362343700147766
Validation loss: 3.9234736394374115

Epoch: 6| Step: 9
Training loss: 4.478378486779518
Validation loss: 3.9051049622810705

Epoch: 6| Step: 10
Training loss: 3.5693480944132916
Validation loss: 3.89506413054892

Epoch: 6| Step: 11
Training loss: 4.551468773507715
Validation loss: 3.8779065825150334

Epoch: 6| Step: 12
Training loss: 3.6950985481634517
Validation loss: 3.8731775751838486

Epoch: 6| Step: 13
Training loss: 3.2573899102509642
Validation loss: 3.8741905115804585

Epoch: 6| Step: 0
Training loss: 4.432478306475727
Validation loss: 3.861642218822771

Epoch: 6| Step: 1
Training loss: 3.9764690875340363
Validation loss: 3.842297103097818

Epoch: 6| Step: 2
Training loss: 4.809514296152219
Validation loss: 3.829895566385432

Epoch: 6| Step: 3
Training loss: 2.827180652072507
Validation loss: 3.809066907815853

Epoch: 6| Step: 4
Training loss: 4.186720134936326
Validation loss: 3.797208161606126

Epoch: 6| Step: 5
Training loss: 4.170180987631651
Validation loss: 3.7847291918060675

Epoch: 6| Step: 6
Training loss: 2.985517512816821
Validation loss: 3.762969667643428

Epoch: 6| Step: 7
Training loss: 3.3688659025222787
Validation loss: 3.7490218442093606

Epoch: 6| Step: 8
Training loss: 4.893920373204155
Validation loss: 3.739226468040835

Epoch: 6| Step: 9
Training loss: 4.324020257131322
Validation loss: 3.719812536620293

Epoch: 6| Step: 10
Training loss: 2.68551811064141
Validation loss: 3.7060061987040376

Epoch: 6| Step: 11
Training loss: 3.320394214297797
Validation loss: 3.700444977023757

Epoch: 6| Step: 12
Training loss: 4.32240374482773
Validation loss: 3.692330821170995

Epoch: 6| Step: 13
Training loss: 4.24208858367642
Validation loss: 3.6877366551954363

Epoch: 7| Step: 0
Training loss: 4.1918681122220045
Validation loss: 3.6611447010116356

Epoch: 6| Step: 1
Training loss: 3.972406340083716
Validation loss: 3.6628267778490993

Epoch: 6| Step: 2
Training loss: 3.9655003497265815
Validation loss: 3.663231150993655

Epoch: 6| Step: 3
Training loss: 4.145005007603914
Validation loss: 3.6631192044073844

Epoch: 6| Step: 4
Training loss: 3.957236824080706
Validation loss: 3.655576141975529

Epoch: 6| Step: 5
Training loss: 2.8926457120944216
Validation loss: 3.6440723372370933

Epoch: 6| Step: 6
Training loss: 3.5452924382334405
Validation loss: 3.6342442921595466

Epoch: 6| Step: 7
Training loss: 4.686513161096516
Validation loss: 3.622721250377113

Epoch: 6| Step: 8
Training loss: 4.16678586153567
Validation loss: 3.6062801953909127

Epoch: 6| Step: 9
Training loss: 2.5737306077031126
Validation loss: 3.5974541876235957

Epoch: 6| Step: 10
Training loss: 2.8146828551713092
Validation loss: 3.5888749979913728

Epoch: 6| Step: 11
Training loss: 4.33121949992925
Validation loss: 3.5738788290904497

Epoch: 6| Step: 12
Training loss: 3.4617414724697158
Validation loss: 3.562248913405045

Epoch: 6| Step: 13
Training loss: 4.300394953842403
Validation loss: 3.5544321225598843

Epoch: 8| Step: 0
Training loss: 2.9306970916686756
Validation loss: 3.5447634111101265

Epoch: 6| Step: 1
Training loss: 4.005583204461159
Validation loss: 3.5368574426713315

Epoch: 6| Step: 2
Training loss: 3.2695728148959673
Validation loss: 3.529969786543413

Epoch: 6| Step: 3
Training loss: 4.08334589326964
Validation loss: 3.520508048437422

Epoch: 6| Step: 4
Training loss: 3.53256822135474
Validation loss: 3.5082738049417292

Epoch: 6| Step: 5
Training loss: 2.816848952886268
Validation loss: 3.502515878909193

Epoch: 6| Step: 6
Training loss: 4.308543283645968
Validation loss: 3.4967312835846616

Epoch: 6| Step: 7
Training loss: 2.9261769331487453
Validation loss: 3.4889342986288323

Epoch: 6| Step: 8
Training loss: 4.870852931722606
Validation loss: 3.481424833920169

Epoch: 6| Step: 9
Training loss: 3.164512470415473
Validation loss: 3.471787216556369

Epoch: 6| Step: 10
Training loss: 3.805125373850088
Validation loss: 3.4670693434216533

Epoch: 6| Step: 11
Training loss: 3.9903427609713704
Validation loss: 3.4633530671426613

Epoch: 6| Step: 12
Training loss: 3.709480208308506
Validation loss: 3.455540887831209

Epoch: 6| Step: 13
Training loss: 3.9728142060842027
Validation loss: 3.4451886966976053

Epoch: 9| Step: 0
Training loss: 4.047996571776857
Validation loss: 3.4411946686611032

Epoch: 6| Step: 1
Training loss: 3.9559354780622744
Validation loss: 3.428511907949111

Epoch: 6| Step: 2
Training loss: 2.6024240894221746
Validation loss: 3.4219099466215015

Epoch: 6| Step: 3
Training loss: 3.176223405038345
Validation loss: 3.41626078948352

Epoch: 6| Step: 4
Training loss: 2.7842249015313274
Validation loss: 3.4140849114723353

Epoch: 6| Step: 5
Training loss: 3.771103289022921
Validation loss: 3.407126998783383

Epoch: 6| Step: 6
Training loss: 4.095483078182201
Validation loss: 3.399626876195679

Epoch: 6| Step: 7
Training loss: 3.9035194313735446
Validation loss: 3.392997899213291

Epoch: 6| Step: 8
Training loss: 4.267291850738578
Validation loss: 3.3844337802252005

Epoch: 6| Step: 9
Training loss: 3.3909374743507223
Validation loss: 3.377580835582493

Epoch: 6| Step: 10
Training loss: 4.418872906002097
Validation loss: 3.3744066218871036

Epoch: 6| Step: 11
Training loss: 2.2846993274823477
Validation loss: 3.3632582057633007

Epoch: 6| Step: 12
Training loss: 4.095701960762233
Validation loss: 3.3599247567736366

Epoch: 6| Step: 13
Training loss: 2.6740043141823135
Validation loss: 3.3566854246763485

Epoch: 10| Step: 0
Training loss: 3.5681126868923725
Validation loss: 3.3594354485283744

Epoch: 6| Step: 1
Training loss: 3.883014758117122
Validation loss: 3.34989877234718

Epoch: 6| Step: 2
Training loss: 3.5942929065120355
Validation loss: 3.3393604691942276

Epoch: 6| Step: 3
Training loss: 3.2917657829202387
Validation loss: 3.333928644693336

Epoch: 6| Step: 4
Training loss: 3.6191162503816945
Validation loss: 3.3299266085570967

Epoch: 6| Step: 5
Training loss: 2.6847088536232646
Validation loss: 3.3309588717224665

Epoch: 6| Step: 6
Training loss: 3.640996823949353
Validation loss: 3.337952717556755

Epoch: 6| Step: 7
Training loss: 4.549599581695049
Validation loss: 3.3160913169236808

Epoch: 6| Step: 8
Training loss: 3.6331036194678012
Validation loss: 3.3147212927762943

Epoch: 6| Step: 9
Training loss: 3.400749314708342
Validation loss: 3.3213734512010973

Epoch: 6| Step: 10
Training loss: 3.9860595732283888
Validation loss: 3.332490385795711

Epoch: 6| Step: 11
Training loss: 3.202218127386667
Validation loss: 3.3289752686542293

Epoch: 6| Step: 12
Training loss: 3.6771882270065994
Validation loss: 3.3052765362919776

Epoch: 6| Step: 13
Training loss: 1.9757018496064147
Validation loss: 3.293558894366802

Epoch: 11| Step: 0
Training loss: 3.642834430912286
Validation loss: 3.298401621866215

Epoch: 6| Step: 1
Training loss: 3.8111248350375178
Validation loss: 3.296154010837275

Epoch: 6| Step: 2
Training loss: 2.9570718860731637
Validation loss: 3.296506004832726

Epoch: 6| Step: 3
Training loss: 3.8642067258753503
Validation loss: 3.2850645738583997

Epoch: 6| Step: 4
Training loss: 3.527749951737632
Validation loss: 3.2695114294509806

Epoch: 6| Step: 5
Training loss: 3.784367308856888
Validation loss: 3.2680189955993177

Epoch: 6| Step: 6
Training loss: 3.4966321818272843
Validation loss: 3.264180869682718

Epoch: 6| Step: 7
Training loss: 3.9915938262558366
Validation loss: 3.26228298813451

Epoch: 6| Step: 8
Training loss: 3.4676245160838706
Validation loss: 3.2575413283743253

Epoch: 6| Step: 9
Training loss: 3.2326276546564876
Validation loss: 3.2538603415384446

Epoch: 6| Step: 10
Training loss: 3.3704761279711852
Validation loss: 3.2487880712608512

Epoch: 6| Step: 11
Training loss: 3.3005012709475463
Validation loss: 3.24308621399083

Epoch: 6| Step: 12
Training loss: 3.4646334578940086
Validation loss: 3.240414629940548

Epoch: 6| Step: 13
Training loss: 2.874229659660934
Validation loss: 3.2440541529311115

Epoch: 12| Step: 0
Training loss: 3.600916343202406
Validation loss: 3.2353297512660015

Epoch: 6| Step: 1
Training loss: 4.0919910175452365
Validation loss: 3.226712078669693

Epoch: 6| Step: 2
Training loss: 3.5037018409056757
Validation loss: 3.224816837691464

Epoch: 6| Step: 3
Training loss: 3.9297537523148964
Validation loss: 3.2209486747149114

Epoch: 6| Step: 4
Training loss: 3.918754399980086
Validation loss: 3.2185681000271615

Epoch: 6| Step: 5
Training loss: 1.6345131518469929
Validation loss: 3.2138572324263093

Epoch: 6| Step: 6
Training loss: 3.397380375050866
Validation loss: 3.211435260499365

Epoch: 6| Step: 7
Training loss: 3.606157859008581
Validation loss: 3.208675133522734

Epoch: 6| Step: 8
Training loss: 3.605738273292087
Validation loss: 3.2052634443459276

Epoch: 6| Step: 9
Training loss: 3.1673735448679703
Validation loss: 3.2006896021952627

Epoch: 6| Step: 10
Training loss: 3.6397372624658932
Validation loss: 3.194114836288104

Epoch: 6| Step: 11
Training loss: 3.0494786801922826
Validation loss: 3.1911413396312374

Epoch: 6| Step: 12
Training loss: 3.4851333408761453
Validation loss: 3.1886599652114906

Epoch: 6| Step: 13
Training loss: 3.094732879795935
Validation loss: 3.183674404447032

Epoch: 13| Step: 0
Training loss: 4.0417075138715255
Validation loss: 3.1817658409551495

Epoch: 6| Step: 1
Training loss: 3.7280099165133764
Validation loss: 3.184018634884659

Epoch: 6| Step: 2
Training loss: 2.6658220940516246
Validation loss: 3.1716488217498062

Epoch: 6| Step: 3
Training loss: 2.845335466018826
Validation loss: 3.1705521454284105

Epoch: 6| Step: 4
Training loss: 3.441995490178152
Validation loss: 3.1720983229723445

Epoch: 6| Step: 5
Training loss: 3.4622513664573997
Validation loss: 3.1680705100417814

Epoch: 6| Step: 6
Training loss: 3.7231272092322456
Validation loss: 3.1621267247348093

Epoch: 6| Step: 7
Training loss: 3.5606953918987734
Validation loss: 3.1619155930719822

Epoch: 6| Step: 8
Training loss: 2.9809507527703127
Validation loss: 3.1596256521863

Epoch: 6| Step: 9
Training loss: 3.845189019010502
Validation loss: 3.1619563672964976

Epoch: 6| Step: 10
Training loss: 3.0440773664510323
Validation loss: 3.1544467384617567

Epoch: 6| Step: 11
Training loss: 4.0194826113887885
Validation loss: 3.148474351475967

Epoch: 6| Step: 12
Training loss: 2.995641243992264
Validation loss: 3.148040439471733

Epoch: 6| Step: 13
Training loss: 3.119700248453007
Validation loss: 3.146875556121069

Epoch: 14| Step: 0
Training loss: 3.7830716623793625
Validation loss: 3.146202384121718

Epoch: 6| Step: 1
Training loss: 3.132636238904519
Validation loss: 3.1485386797102475

Epoch: 6| Step: 2
Training loss: 3.561558113734741
Validation loss: 3.1445809786046612

Epoch: 6| Step: 3
Training loss: 3.2425985420447296
Validation loss: 3.144030877624453

Epoch: 6| Step: 4
Training loss: 2.8901020298671103
Validation loss: 3.1343520920537484

Epoch: 6| Step: 5
Training loss: 3.2554524973533887
Validation loss: 3.138059714989607

Epoch: 6| Step: 6
Training loss: 3.3769802359380217
Validation loss: 3.1325528971156698

Epoch: 6| Step: 7
Training loss: 3.6193855478630055
Validation loss: 3.1263152055924133

Epoch: 6| Step: 8
Training loss: 3.5754935237381504
Validation loss: 3.128414577376908

Epoch: 6| Step: 9
Training loss: 3.311662100136201
Validation loss: 3.127867943397959

Epoch: 6| Step: 10
Training loss: 3.2508599537418976
Validation loss: 3.1255862221460866

Epoch: 6| Step: 11
Training loss: 3.7009358433973643
Validation loss: 3.123640234660067

Epoch: 6| Step: 12
Training loss: 3.901095476106204
Validation loss: 3.119270979867587

Epoch: 6| Step: 13
Training loss: 2.2858126227478657
Validation loss: 3.116154127721179

Epoch: 15| Step: 0
Training loss: 3.2828734241989173
Validation loss: 3.1108728269095915

Epoch: 6| Step: 1
Training loss: 2.97211947714108
Validation loss: 3.1083517449527114

Epoch: 6| Step: 2
Training loss: 3.243647602795064
Validation loss: 3.106298774987806

Epoch: 6| Step: 3
Training loss: 3.1089744118134113
Validation loss: 3.101727465435789

Epoch: 6| Step: 4
Training loss: 3.1293407048075057
Validation loss: 3.1067205014353423

Epoch: 6| Step: 5
Training loss: 3.008166641590705
Validation loss: 3.162652742957242

Epoch: 6| Step: 6
Training loss: 3.9798213293715463
Validation loss: 3.124366011758919

Epoch: 6| Step: 7
Training loss: 3.0716020433731326
Validation loss: 3.092384372578609

Epoch: 6| Step: 8
Training loss: 3.547869169074466
Validation loss: 3.0932821676430753

Epoch: 6| Step: 9
Training loss: 3.6698643150505372
Validation loss: 3.1159493393456974

Epoch: 6| Step: 10
Training loss: 3.6451244137309153
Validation loss: 3.1048368391381076

Epoch: 6| Step: 11
Training loss: 3.8788413419795864
Validation loss: 3.1136489395560583

Epoch: 6| Step: 12
Training loss: 3.7083317331603523
Validation loss: 3.107926377807514

Epoch: 6| Step: 13
Training loss: 2.3792072976334584
Validation loss: 3.1001459661594897

Epoch: 16| Step: 0
Training loss: 3.8531271830086196
Validation loss: 3.098529021894224

Epoch: 6| Step: 1
Training loss: 3.6301792897066445
Validation loss: 3.0915459747102823

Epoch: 6| Step: 2
Training loss: 3.1506218916974724
Validation loss: 3.085240548849738

Epoch: 6| Step: 3
Training loss: 2.848888240605183
Validation loss: 3.0838504818747206

Epoch: 6| Step: 4
Training loss: 2.9266735799211028
Validation loss: 3.079875837259714

Epoch: 6| Step: 5
Training loss: 4.179172263073557
Validation loss: 3.0801709433497835

Epoch: 6| Step: 6
Training loss: 3.6619635387628473
Validation loss: 3.0737879854553185

Epoch: 6| Step: 7
Training loss: 3.6039578298288357
Validation loss: 3.068867694758216

Epoch: 6| Step: 8
Training loss: 3.2080271355962946
Validation loss: 3.066599707911285

Epoch: 6| Step: 9
Training loss: 2.4736143067063394
Validation loss: 3.063722998707945

Epoch: 6| Step: 10
Training loss: 2.760756695995658
Validation loss: 3.0602397300083273

Epoch: 6| Step: 11
Training loss: 3.995986593978129
Validation loss: 3.0563494875509534

Epoch: 6| Step: 12
Training loss: 3.2132715805208725
Validation loss: 3.054882154034413

Epoch: 6| Step: 13
Training loss: 2.670946372541743
Validation loss: 3.056991921067189

Epoch: 17| Step: 0
Training loss: 2.5667555294094346
Validation loss: 3.061773838979983

Epoch: 6| Step: 1
Training loss: 2.379898240294167
Validation loss: 3.061819313551231

Epoch: 6| Step: 2
Training loss: 3.9289183574921567
Validation loss: 3.0599479153856066

Epoch: 6| Step: 3
Training loss: 3.10107756314032
Validation loss: 3.0442935732890946

Epoch: 6| Step: 4
Training loss: 3.0418406049211506
Validation loss: 3.043440446696429

Epoch: 6| Step: 5
Training loss: 4.088129043005568
Validation loss: 3.0429057587954467

Epoch: 6| Step: 6
Training loss: 3.253365168285431
Validation loss: 3.042536476453103

Epoch: 6| Step: 7
Training loss: 3.4830070513145444
Validation loss: 3.0416211338205983

Epoch: 6| Step: 8
Training loss: 2.811899587333375
Validation loss: 3.0421927791179524

Epoch: 6| Step: 9
Training loss: 3.0973646837285385
Validation loss: 3.0398543211236695

Epoch: 6| Step: 10
Training loss: 3.782536185445112
Validation loss: 3.071993000971839

Epoch: 6| Step: 11
Training loss: 3.9162244479468713
Validation loss: 3.0401274314713898

Epoch: 6| Step: 12
Training loss: 3.807988733996227
Validation loss: 3.0385873310625855

Epoch: 6| Step: 13
Training loss: 2.418212385336425
Validation loss: 3.0783933317789964

Epoch: 18| Step: 0
Training loss: 3.4609306111493234
Validation loss: 3.041130373194511

Epoch: 6| Step: 1
Training loss: 3.143181514721169
Validation loss: 3.02875420196419

Epoch: 6| Step: 2
Training loss: 3.563571166572728
Validation loss: 3.028231762366684

Epoch: 6| Step: 3
Training loss: 3.1646025773635857
Validation loss: 3.0305085420814786

Epoch: 6| Step: 4
Training loss: 3.2137795004275205
Validation loss: 3.0351346319854104

Epoch: 6| Step: 5
Training loss: 2.487973276479291
Validation loss: 3.036618106401045

Epoch: 6| Step: 6
Training loss: 3.2093901606928763
Validation loss: 3.0382222862237565

Epoch: 6| Step: 7
Training loss: 3.7088164682735263
Validation loss: 3.0419117779203275

Epoch: 6| Step: 8
Training loss: 3.2683739294487397
Validation loss: 3.038113698672548

Epoch: 6| Step: 9
Training loss: 3.2661006891318967
Validation loss: 3.033970716254232

Epoch: 6| Step: 10
Training loss: 3.075401689298019
Validation loss: 3.0296394095933654

Epoch: 6| Step: 11
Training loss: 3.6404431997593134
Validation loss: 3.0270656828211195

Epoch: 6| Step: 12
Training loss: 3.666033314421893
Validation loss: 3.024934665561178

Epoch: 6| Step: 13
Training loss: 3.5948044266645156
Validation loss: 3.0226201821882963

Epoch: 19| Step: 0
Training loss: 3.1328657721273334
Validation loss: 3.02443045259077

Epoch: 6| Step: 1
Training loss: 3.3684504501415176
Validation loss: 3.020501689648004

Epoch: 6| Step: 2
Training loss: 3.2627951302169707
Validation loss: 3.018664485639314

Epoch: 6| Step: 3
Training loss: 3.540499565953041
Validation loss: 3.015096159100019

Epoch: 6| Step: 4
Training loss: 3.335959512606677
Validation loss: 3.0120372246051934

Epoch: 6| Step: 5
Training loss: 2.9470386253391254
Validation loss: 3.008429981822469

Epoch: 6| Step: 6
Training loss: 3.060539863933817
Validation loss: 3.0056347654890407

Epoch: 6| Step: 7
Training loss: 3.759653508880298
Validation loss: 3.0036466168323086

Epoch: 6| Step: 8
Training loss: 3.095609472163824
Validation loss: 3.0008567574525897

Epoch: 6| Step: 9
Training loss: 3.5837742881630446
Validation loss: 2.9991018068450495

Epoch: 6| Step: 10
Training loss: 3.0579797510907514
Validation loss: 2.996912005299099

Epoch: 6| Step: 11
Training loss: 3.082623442988093
Validation loss: 2.9953678373320964

Epoch: 6| Step: 12
Training loss: 3.6312869570717776
Validation loss: 2.993420626774809

Epoch: 6| Step: 13
Training loss: 3.2241439806969168
Validation loss: 2.994035551363233

Epoch: 20| Step: 0
Training loss: 3.3941089644016214
Validation loss: 2.9920712123933524

Epoch: 6| Step: 1
Training loss: 3.3133607142012336
Validation loss: 2.9909070719386226

Epoch: 6| Step: 2
Training loss: 2.636079837956138
Validation loss: 2.9883687260093796

Epoch: 6| Step: 3
Training loss: 3.145336962480164
Validation loss: 2.989086000993492

Epoch: 6| Step: 4
Training loss: 3.941316117767432
Validation loss: 2.9894303619316127

Epoch: 6| Step: 5
Training loss: 3.166122255877078
Validation loss: 2.989238668694715

Epoch: 6| Step: 6
Training loss: 3.6242584259236286
Validation loss: 2.9875236746104448

Epoch: 6| Step: 7
Training loss: 3.3322227217297335
Validation loss: 2.994024731778413

Epoch: 6| Step: 8
Training loss: 3.102179862203502
Validation loss: 2.9879444751568878

Epoch: 6| Step: 9
Training loss: 3.321147643131884
Validation loss: 2.9861127452904697

Epoch: 6| Step: 10
Training loss: 2.867256184516641
Validation loss: 2.9813490146574053

Epoch: 6| Step: 11
Training loss: 3.0929866581162546
Validation loss: 2.9774380852371185

Epoch: 6| Step: 12
Training loss: 3.6637363573365014
Validation loss: 2.9762210242583187

Epoch: 6| Step: 13
Training loss: 2.9779307507212636
Validation loss: 2.980972098085294

Epoch: 21| Step: 0
Training loss: 3.240718058148482
Validation loss: 2.990724093341629

Epoch: 6| Step: 1
Training loss: 3.752327895820986
Validation loss: 2.99030870696863

Epoch: 6| Step: 2
Training loss: 3.8817160457114444
Validation loss: 2.973821104796592

Epoch: 6| Step: 3
Training loss: 2.9814859356878727
Validation loss: 2.9725943664531798

Epoch: 6| Step: 4
Training loss: 3.593783569179153
Validation loss: 2.9770790241692815

Epoch: 6| Step: 5
Training loss: 3.166090477841623
Validation loss: 2.980272476962586

Epoch: 6| Step: 6
Training loss: 2.462172425455484
Validation loss: 2.9868592999942334

Epoch: 6| Step: 7
Training loss: 3.2763405538690202
Validation loss: 2.989358241284949

Epoch: 6| Step: 8
Training loss: 3.7598176234228924
Validation loss: 2.991896580571792

Epoch: 6| Step: 9
Training loss: 3.335109491795678
Validation loss: 2.9789320456580457

Epoch: 6| Step: 10
Training loss: 2.6861435771752236
Validation loss: 2.975050589411478

Epoch: 6| Step: 11
Training loss: 3.3938265684703848
Validation loss: 2.9730245337739656

Epoch: 6| Step: 12
Training loss: 2.951392094230158
Validation loss: 2.9738440736891043

Epoch: 6| Step: 13
Training loss: 2.8351013800577007
Validation loss: 2.9726317687413997

Epoch: 22| Step: 0
Training loss: 2.3003437034212144
Validation loss: 2.9727652010999317

Epoch: 6| Step: 1
Training loss: 3.1278554459168597
Validation loss: 2.975616619154487

Epoch: 6| Step: 2
Training loss: 4.289363107065874
Validation loss: 2.979389601120337

Epoch: 6| Step: 3
Training loss: 2.9952970835687482
Validation loss: 2.9755514430921046

Epoch: 6| Step: 4
Training loss: 2.999812120276536
Validation loss: 2.967074658000255

Epoch: 6| Step: 5
Training loss: 3.2622961572566287
Validation loss: 2.964528688022812

Epoch: 6| Step: 6
Training loss: 3.5303748742774737
Validation loss: 2.9610029137541956

Epoch: 6| Step: 7
Training loss: 3.4258721403724595
Validation loss: 2.9611953959409925

Epoch: 6| Step: 8
Training loss: 3.6432032808043626
Validation loss: 2.95961714611078

Epoch: 6| Step: 9
Training loss: 2.240382089043569
Validation loss: 2.959720588457104

Epoch: 6| Step: 10
Training loss: 3.6632295161894035
Validation loss: 2.957126466293127

Epoch: 6| Step: 11
Training loss: 3.566153677178729
Validation loss: 2.957428130043028

Epoch: 6| Step: 12
Training loss: 2.919212066213144
Validation loss: 2.956372867276876

Epoch: 6| Step: 13
Training loss: 2.9458420173772413
Validation loss: 2.9545116399534823

Epoch: 23| Step: 0
Training loss: 2.9505646116819677
Validation loss: 2.95827611607622

Epoch: 6| Step: 1
Training loss: 3.018148364657779
Validation loss: 2.961639491647948

Epoch: 6| Step: 2
Training loss: 2.5983285593213687
Validation loss: 2.9652921805600716

Epoch: 6| Step: 3
Training loss: 2.888385792068934
Validation loss: 2.957328021275202

Epoch: 6| Step: 4
Training loss: 4.003369104594538
Validation loss: 2.952507523534937

Epoch: 6| Step: 5
Training loss: 3.3267739289242244
Validation loss: 2.9545078706462733

Epoch: 6| Step: 6
Training loss: 2.9902595703339254
Validation loss: 2.950280295116163

Epoch: 6| Step: 7
Training loss: 2.6780324557148862
Validation loss: 2.947386274138939

Epoch: 6| Step: 8
Training loss: 3.092024967650444
Validation loss: 2.9454556630523205

Epoch: 6| Step: 9
Training loss: 3.688158655341141
Validation loss: 2.9451896681253675

Epoch: 6| Step: 10
Training loss: 3.497475940111691
Validation loss: 2.9451125121589348

Epoch: 6| Step: 11
Training loss: 2.9573959871448183
Validation loss: 2.944761580991823

Epoch: 6| Step: 12
Training loss: 4.111685331869469
Validation loss: 2.9569284921335512

Epoch: 6| Step: 13
Training loss: 3.2665944097922437
Validation loss: 2.9554546798848174

Epoch: 24| Step: 0
Training loss: 2.887071559546352
Validation loss: 2.944987288487873

Epoch: 6| Step: 1
Training loss: 2.8206234071077483
Validation loss: 2.9441806157514048

Epoch: 6| Step: 2
Training loss: 3.882600283436025
Validation loss: 2.944916290584378

Epoch: 6| Step: 3
Training loss: 2.902419981334003
Validation loss: 2.9451798015569786

Epoch: 6| Step: 4
Training loss: 3.3890554425389
Validation loss: 2.9442877141183215

Epoch: 6| Step: 5
Training loss: 3.36726878481862
Validation loss: 2.9426035239571826

Epoch: 6| Step: 6
Training loss: 3.226301501342284
Validation loss: 2.943328585293776

Epoch: 6| Step: 7
Training loss: 2.538067244093578
Validation loss: 2.94271246216216

Epoch: 6| Step: 8
Training loss: 3.606827799029306
Validation loss: 2.9410742956820326

Epoch: 6| Step: 9
Training loss: 3.342749615338356
Validation loss: 2.9401426557026737

Epoch: 6| Step: 10
Training loss: 3.1304391446866404
Validation loss: 2.942592187684412

Epoch: 6| Step: 11
Training loss: 3.1033833345290613
Validation loss: 2.9417064643023925

Epoch: 6| Step: 12
Training loss: 3.6709970276814574
Validation loss: 2.94002666563981

Epoch: 6| Step: 13
Training loss: 3.221568382909815
Validation loss: 2.9397897865706315

Epoch: 25| Step: 0
Training loss: 3.072627856804519
Validation loss: 2.93777770137265

Epoch: 6| Step: 1
Training loss: 3.1629626210910926
Validation loss: 2.940779341531109

Epoch: 6| Step: 2
Training loss: 2.7771626988884557
Validation loss: 2.939363833045467

Epoch: 6| Step: 3
Training loss: 3.473072692136708
Validation loss: 2.937074985272299

Epoch: 6| Step: 4
Training loss: 2.711315381539936
Validation loss: 2.9354705061575053

Epoch: 6| Step: 5
Training loss: 3.032003721934427
Validation loss: 2.937551245311127

Epoch: 6| Step: 6
Training loss: 3.735653071981731
Validation loss: 2.9358397054839878

Epoch: 6| Step: 7
Training loss: 3.4312682104409182
Validation loss: 2.9381186785707603

Epoch: 6| Step: 8
Training loss: 3.798379733337994
Validation loss: 2.930448265919484

Epoch: 6| Step: 9
Training loss: 3.1602325996068967
Validation loss: 2.9269206437172266

Epoch: 6| Step: 10
Training loss: 2.47734370380499
Validation loss: 2.9268195694295533

Epoch: 6| Step: 11
Training loss: 3.5276000477899943
Validation loss: 2.9268693550508806

Epoch: 6| Step: 12
Training loss: 3.2750381525743895
Validation loss: 2.9299245220820644

Epoch: 6| Step: 13
Training loss: 3.370361814460871
Validation loss: 2.932836868157188

Epoch: 26| Step: 0
Training loss: 2.474891267179791
Validation loss: 2.9301932877130548

Epoch: 6| Step: 1
Training loss: 3.3239417493010586
Validation loss: 2.9352856547940176

Epoch: 6| Step: 2
Training loss: 3.444573493987457
Validation loss: 2.9389860565487633

Epoch: 6| Step: 3
Training loss: 2.949138230999353
Validation loss: 2.940194293534664

Epoch: 6| Step: 4
Training loss: 2.522970150402453
Validation loss: 2.937877116784916

Epoch: 6| Step: 5
Training loss: 3.6974601069755684
Validation loss: 2.939029879943228

Epoch: 6| Step: 6
Training loss: 3.5685512614321167
Validation loss: 2.9301546096593967

Epoch: 6| Step: 7
Training loss: 3.39551146372395
Validation loss: 2.928832616192726

Epoch: 6| Step: 8
Training loss: 3.288116246472649
Validation loss: 2.9245682199862415

Epoch: 6| Step: 9
Training loss: 3.447800894615455
Validation loss: 2.919742464277143

Epoch: 6| Step: 10
Training loss: 3.378046709224452
Validation loss: 2.9194069893796946

Epoch: 6| Step: 11
Training loss: 3.046600798959827
Validation loss: 2.918160409084723

Epoch: 6| Step: 12
Training loss: 3.2064154866661188
Validation loss: 2.9167137640272283

Epoch: 6| Step: 13
Training loss: 2.961217861943142
Validation loss: 2.921063338333975

Epoch: 27| Step: 0
Training loss: 2.6492567567565466
Validation loss: 2.932094931876325

Epoch: 6| Step: 1
Training loss: 2.7772685495489045
Validation loss: 2.9373523340787826

Epoch: 6| Step: 2
Training loss: 2.910626141804116
Validation loss: 2.9448177117561434

Epoch: 6| Step: 3
Training loss: 3.1921387372281305
Validation loss: 2.939164167886371

Epoch: 6| Step: 4
Training loss: 3.5633555940861115
Validation loss: 2.944309862457038

Epoch: 6| Step: 5
Training loss: 3.1313655870008414
Validation loss: 2.9298646794821646

Epoch: 6| Step: 6
Training loss: 3.275515386199102
Validation loss: 2.9178932306353556

Epoch: 6| Step: 7
Training loss: 2.429679846061598
Validation loss: 2.9130872126819027

Epoch: 6| Step: 8
Training loss: 3.4919316072178885
Validation loss: 2.913345756823408

Epoch: 6| Step: 9
Training loss: 4.18260840914471
Validation loss: 2.9224246244444605

Epoch: 6| Step: 10
Training loss: 3.043041771929529
Validation loss: 2.9198238685461217

Epoch: 6| Step: 11
Training loss: 3.638283299795093
Validation loss: 2.9206584270735103

Epoch: 6| Step: 12
Training loss: 3.5112163112133747
Validation loss: 2.9146774704505356

Epoch: 6| Step: 13
Training loss: 2.513391960819513
Validation loss: 2.911960940942875

Epoch: 28| Step: 0
Training loss: 3.2391045677592607
Validation loss: 2.9082799361548046

Epoch: 6| Step: 1
Training loss: 3.2421695570851394
Validation loss: 2.9062489890984327

Epoch: 6| Step: 2
Training loss: 3.3843939698762853
Validation loss: 2.9099685003844264

Epoch: 6| Step: 3
Training loss: 3.5016293139298527
Validation loss: 2.9007674296912525

Epoch: 6| Step: 4
Training loss: 3.1178072741088934
Validation loss: 2.9010323642722886

Epoch: 6| Step: 5
Training loss: 2.444127779977634
Validation loss: 2.9011954481848323

Epoch: 6| Step: 6
Training loss: 2.9527702320281977
Validation loss: 2.900753022271685

Epoch: 6| Step: 7
Training loss: 3.018490709498719
Validation loss: 2.8970474727934437

Epoch: 6| Step: 8
Training loss: 3.7752851618498555
Validation loss: 2.897403618552838

Epoch: 6| Step: 9
Training loss: 3.5557956184036223
Validation loss: 2.8988631439849692

Epoch: 6| Step: 10
Training loss: 3.1461556545293266
Validation loss: 2.8990501484039752

Epoch: 6| Step: 11
Training loss: 3.1580608951623637
Validation loss: 2.8965757331233744

Epoch: 6| Step: 12
Training loss: 3.2920592512543774
Validation loss: 2.897736590918114

Epoch: 6| Step: 13
Training loss: 2.4029247542786982
Validation loss: 2.901101056950203

Epoch: 29| Step: 0
Training loss: 3.3667241107333057
Validation loss: 2.9165647134379915

Epoch: 6| Step: 1
Training loss: 3.178935793938346
Validation loss: 2.9351357087395846

Epoch: 6| Step: 2
Training loss: 3.955651964543849
Validation loss: 2.9420862642235823

Epoch: 6| Step: 3
Training loss: 3.133929807284666
Validation loss: 2.9314608636888884

Epoch: 6| Step: 4
Training loss: 2.696233973342738
Validation loss: 2.8933315263238493

Epoch: 6| Step: 5
Training loss: 3.560275269913633
Validation loss: 2.8915716136196776

Epoch: 6| Step: 6
Training loss: 3.332352080557207
Validation loss: 2.891015287356766

Epoch: 6| Step: 7
Training loss: 3.4550749507563854
Validation loss: 2.892069036016427

Epoch: 6| Step: 8
Training loss: 2.352133545340997
Validation loss: 2.908782836193423

Epoch: 6| Step: 9
Training loss: 2.86354802698618
Validation loss: 2.9235977973297405

Epoch: 6| Step: 10
Training loss: 3.226993264176201
Validation loss: 2.925081752752629

Epoch: 6| Step: 11
Training loss: 2.6100395407184487
Validation loss: 2.918768859691328

Epoch: 6| Step: 12
Training loss: 3.139910564485286
Validation loss: 2.899197204371665

Epoch: 6| Step: 13
Training loss: 3.9044661454208187
Validation loss: 2.897276523974865

Epoch: 30| Step: 0
Training loss: 3.329405918683137
Validation loss: 2.894364309653856

Epoch: 6| Step: 1
Training loss: 3.53156677445667
Validation loss: 2.8914666633086425

Epoch: 6| Step: 2
Training loss: 3.4639534994620735
Validation loss: 2.8888863693549203

Epoch: 6| Step: 3
Training loss: 2.9686706532365115
Validation loss: 2.8870167569050382

Epoch: 6| Step: 4
Training loss: 3.7162700686665118
Validation loss: 2.8882256684736105

Epoch: 6| Step: 5
Training loss: 3.3042850474781673
Validation loss: 2.8852638306919247

Epoch: 6| Step: 6
Training loss: 2.823107742280469
Validation loss: 2.882148191034559

Epoch: 6| Step: 7
Training loss: 2.7739377712318984
Validation loss: 2.8869605404049192

Epoch: 6| Step: 8
Training loss: 2.8921313510681106
Validation loss: 2.89166611555628

Epoch: 6| Step: 9
Training loss: 3.8638319465785993
Validation loss: 2.93505192185892

Epoch: 6| Step: 10
Training loss: 3.2829216468238425
Validation loss: 2.8842730004646966

Epoch: 6| Step: 11
Training loss: 3.2429823303305905
Validation loss: 2.8785439433307065

Epoch: 6| Step: 12
Training loss: 2.5343894798156796
Validation loss: 2.8798097964741527

Epoch: 6| Step: 13
Training loss: 1.9455832174283167
Validation loss: 2.878586006215608

Epoch: 31| Step: 0
Training loss: 3.2993793828739655
Validation loss: 2.8798367840083423

Epoch: 6| Step: 1
Training loss: 3.3977687133785692
Validation loss: 2.8830214405061656

Epoch: 6| Step: 2
Training loss: 2.802010366253189
Validation loss: 2.8802211597783574

Epoch: 6| Step: 3
Training loss: 3.25736136480328
Validation loss: 2.874954824284418

Epoch: 6| Step: 4
Training loss: 2.883133040804993
Validation loss: 2.875043601177608

Epoch: 6| Step: 5
Training loss: 3.4384767011768647
Validation loss: 2.8705320537531307

Epoch: 6| Step: 6
Training loss: 3.059066716404701
Validation loss: 2.872068635284042

Epoch: 6| Step: 7
Training loss: 2.9739764336047987
Validation loss: 2.876078517048262

Epoch: 6| Step: 8
Training loss: 3.557016536113319
Validation loss: 2.884330539464918

Epoch: 6| Step: 9
Training loss: 3.2616213846807596
Validation loss: 2.878953641550747

Epoch: 6| Step: 10
Training loss: 3.142831966373618
Validation loss: 2.8701407004770845

Epoch: 6| Step: 11
Training loss: 3.1377405993852903
Validation loss: 2.870155269601263

Epoch: 6| Step: 12
Training loss: 2.912008998888385
Validation loss: 2.8684654815562305

Epoch: 6| Step: 13
Training loss: 3.614962525866005
Validation loss: 2.8687893885454123

Epoch: 32| Step: 0
Training loss: 2.5057490050226248
Validation loss: 2.8702143831687863

Epoch: 6| Step: 1
Training loss: 3.101847676347629
Validation loss: 2.867018733210517

Epoch: 6| Step: 2
Training loss: 3.6889966093623237
Validation loss: 2.869425612238225

Epoch: 6| Step: 3
Training loss: 2.6150090047123284
Validation loss: 2.8729018981787675

Epoch: 6| Step: 4
Training loss: 2.624152818846989
Validation loss: 2.8789811945435475

Epoch: 6| Step: 5
Training loss: 3.083046014819141
Validation loss: 2.8787212765717936

Epoch: 6| Step: 6
Training loss: 3.6554811109353014
Validation loss: 2.894003740669861

Epoch: 6| Step: 7
Training loss: 2.8461746107997543
Validation loss: 2.9050016956360754

Epoch: 6| Step: 8
Training loss: 3.56796367687502
Validation loss: 2.8896902420444586

Epoch: 6| Step: 9
Training loss: 2.7927483318290753
Validation loss: 2.8756934627494077

Epoch: 6| Step: 10
Training loss: 3.1613821474015413
Validation loss: 2.861564722596472

Epoch: 6| Step: 11
Training loss: 3.3801844301637427
Validation loss: 2.860757532190483

Epoch: 6| Step: 12
Training loss: 3.8397600508267185
Validation loss: 2.8592759358476347

Epoch: 6| Step: 13
Training loss: 3.213525476317012
Validation loss: 2.8574889936389396

Epoch: 33| Step: 0
Training loss: 2.457637354290469
Validation loss: 2.8566412061409903

Epoch: 6| Step: 1
Training loss: 3.2279438451730122
Validation loss: 2.854268448495914

Epoch: 6| Step: 2
Training loss: 3.6806994300088376
Validation loss: 2.8515008600292844

Epoch: 6| Step: 3
Training loss: 3.0272114386408955
Validation loss: 2.8522931102321167

Epoch: 6| Step: 4
Training loss: 3.3453382481274994
Validation loss: 2.852960106218304

Epoch: 6| Step: 5
Training loss: 3.1210891666307083
Validation loss: 2.8500808442412904

Epoch: 6| Step: 6
Training loss: 3.132957093666754
Validation loss: 2.8494977087087707

Epoch: 6| Step: 7
Training loss: 2.0785588550140512
Validation loss: 2.8492032079120553

Epoch: 6| Step: 8
Training loss: 2.5882707194336603
Validation loss: 2.84865966702321

Epoch: 6| Step: 9
Training loss: 3.4248492409598446
Validation loss: 2.850676288973009

Epoch: 6| Step: 10
Training loss: 2.7928176518896723
Validation loss: 2.849491442419591

Epoch: 6| Step: 11
Training loss: 3.624336971288033
Validation loss: 2.8492233025070135

Epoch: 6| Step: 12
Training loss: 3.791333334107855
Validation loss: 2.8498446650865863

Epoch: 6| Step: 13
Training loss: 3.6914000495979673
Validation loss: 2.8439599335719183

Epoch: 34| Step: 0
Training loss: 3.321538146946546
Validation loss: 2.842263542840746

Epoch: 6| Step: 1
Training loss: 3.573192678454158
Validation loss: 2.840831221049325

Epoch: 6| Step: 2
Training loss: 2.212815420652266
Validation loss: 2.837674838103185

Epoch: 6| Step: 3
Training loss: 3.6057111631755165
Validation loss: 2.8330266075909054

Epoch: 6| Step: 4
Training loss: 2.7630601617073696
Validation loss: 2.8317539118611528

Epoch: 6| Step: 5
Training loss: 3.5966376603317713
Validation loss: 2.82548747233194

Epoch: 6| Step: 6
Training loss: 3.527587206308004
Validation loss: 2.824003100372382

Epoch: 6| Step: 7
Training loss: 1.969360983364983
Validation loss: 2.8222051891701847

Epoch: 6| Step: 8
Training loss: 2.7138396018411783
Validation loss: 2.818183752519435

Epoch: 6| Step: 9
Training loss: 3.6550914526481657
Validation loss: 2.822217417783327

Epoch: 6| Step: 10
Training loss: 3.0707892516106696
Validation loss: 2.815551265757066

Epoch: 6| Step: 11
Training loss: 3.7105558500292815
Validation loss: 2.8206861290126968

Epoch: 6| Step: 12
Training loss: 2.1052154218757906
Validation loss: 2.8170251099686427

Epoch: 6| Step: 13
Training loss: 3.509625822158262
Validation loss: 2.8258095005713075

Epoch: 35| Step: 0
Training loss: 3.450766193615274
Validation loss: 2.82471291733795

Epoch: 6| Step: 1
Training loss: 3.3562361846582656
Validation loss: 2.8285754351645314

Epoch: 6| Step: 2
Training loss: 2.4605546926037203
Validation loss: 2.822113863499582

Epoch: 6| Step: 3
Training loss: 2.978487128449747
Validation loss: 2.8150665595480606

Epoch: 6| Step: 4
Training loss: 2.899126736931656
Validation loss: 2.807561966205424

Epoch: 6| Step: 5
Training loss: 2.759137319003385
Validation loss: 2.8056231413786783

Epoch: 6| Step: 6
Training loss: 3.234469647335732
Validation loss: 2.808245097650106

Epoch: 6| Step: 7
Training loss: 3.4667429573271993
Validation loss: 2.8068768144166385

Epoch: 6| Step: 8
Training loss: 3.2225736850218816
Validation loss: 2.8100961400159563

Epoch: 6| Step: 9
Training loss: 2.8867914296500157
Validation loss: 2.810805049966622

Epoch: 6| Step: 10
Training loss: 2.6483117357849397
Validation loss: 2.8177244967521196

Epoch: 6| Step: 11
Training loss: 3.4740010973325237
Validation loss: 2.818859213240858

Epoch: 6| Step: 12
Training loss: 3.77535702867553
Validation loss: 2.8206173502482983

Epoch: 6| Step: 13
Training loss: 2.772922263843171
Validation loss: 2.8096323559317598

Epoch: 36| Step: 0
Training loss: 3.2540425321288167
Validation loss: 2.8084730042805353

Epoch: 6| Step: 1
Training loss: 2.6968232716785487
Validation loss: 2.8062703568908978

Epoch: 6| Step: 2
Training loss: 3.5305179073375004
Validation loss: 2.806025109976119

Epoch: 6| Step: 3
Training loss: 2.6226066396030663
Validation loss: 2.8119397606932357

Epoch: 6| Step: 4
Training loss: 3.4374730889394054
Validation loss: 2.8060604092896786

Epoch: 6| Step: 5
Training loss: 3.255245523876092
Validation loss: 2.806933131480005

Epoch: 6| Step: 6
Training loss: 3.092058740588384
Validation loss: 2.8034689388677094

Epoch: 6| Step: 7
Training loss: 2.299478521523362
Validation loss: 2.7985626022162795

Epoch: 6| Step: 8
Training loss: 2.330904332119438
Validation loss: 2.798502196818245

Epoch: 6| Step: 9
Training loss: 4.004599787495351
Validation loss: 2.795792341288637

Epoch: 6| Step: 10
Training loss: 3.182054842780202
Validation loss: 2.7976769893368796

Epoch: 6| Step: 11
Training loss: 3.585371384158315
Validation loss: 2.800261992511637

Epoch: 6| Step: 12
Training loss: 3.0240966709165944
Validation loss: 2.801395122384285

Epoch: 6| Step: 13
Training loss: 2.654449750414957
Validation loss: 2.812548875099196

Epoch: 37| Step: 0
Training loss: 3.024790064565206
Validation loss: 2.8044222851637097

Epoch: 6| Step: 1
Training loss: 3.0918030440557533
Validation loss: 2.8154214618704936

Epoch: 6| Step: 2
Training loss: 3.129912825275369
Validation loss: 2.820363783027111

Epoch: 6| Step: 3
Training loss: 2.841258204423544
Validation loss: 2.8098735527701604

Epoch: 6| Step: 4
Training loss: 3.043563059993778
Validation loss: 2.808727856737374

Epoch: 6| Step: 5
Training loss: 2.3720191519737615
Validation loss: 2.809804575026269

Epoch: 6| Step: 6
Training loss: 2.946876495134413
Validation loss: 2.8143013238907124

Epoch: 6| Step: 7
Training loss: 2.880149210667393
Validation loss: 2.803416853883255

Epoch: 6| Step: 8
Training loss: 3.3581936910544905
Validation loss: 2.800157963198094

Epoch: 6| Step: 9
Training loss: 3.5082765539895027
Validation loss: 2.7984634410395812

Epoch: 6| Step: 10
Training loss: 4.022778029236732
Validation loss: 2.791093248246477

Epoch: 6| Step: 11
Training loss: 2.5188414109825215
Validation loss: 2.7848660700558

Epoch: 6| Step: 12
Training loss: 3.2050657766082202
Validation loss: 2.7880090553374504

Epoch: 6| Step: 13
Training loss: 3.3697454733338112
Validation loss: 2.7896880737448635

Epoch: 38| Step: 0
Training loss: 2.863574003941544
Validation loss: 2.7895937426001125

Epoch: 6| Step: 1
Training loss: 3.986866011489086
Validation loss: 2.7919636594266812

Epoch: 6| Step: 2
Training loss: 2.52600109159517
Validation loss: 2.7911698635960893

Epoch: 6| Step: 3
Training loss: 3.9695897452975766
Validation loss: 2.790923268628406

Epoch: 6| Step: 4
Training loss: 2.8144067023192596
Validation loss: 2.787196408906505

Epoch: 6| Step: 5
Training loss: 2.664446224197558
Validation loss: 2.7857169504343346

Epoch: 6| Step: 6
Training loss: 2.914831310645445
Validation loss: 2.78410493596537

Epoch: 6| Step: 7
Training loss: 3.6704311697570122
Validation loss: 2.782213961849301

Epoch: 6| Step: 8
Training loss: 3.2621113980542464
Validation loss: 2.7848179528082766

Epoch: 6| Step: 9
Training loss: 2.7879697224301516
Validation loss: 2.7907264888254733

Epoch: 6| Step: 10
Training loss: 3.0867381155863978
Validation loss: 2.8002365863481415

Epoch: 6| Step: 11
Training loss: 2.1437984805839387
Validation loss: 2.810012147278919

Epoch: 6| Step: 12
Training loss: 3.1723298747303135
Validation loss: 2.8165310155371763

Epoch: 6| Step: 13
Training loss: 3.151857700243691
Validation loss: 2.812496492481665

Epoch: 39| Step: 0
Training loss: 3.4099081851534887
Validation loss: 2.8106178293491015

Epoch: 6| Step: 1
Training loss: 3.240675240313906
Validation loss: 2.8022467117325043

Epoch: 6| Step: 2
Training loss: 2.911432874610338
Validation loss: 2.7808854833330416

Epoch: 6| Step: 3
Training loss: 3.639008519258352
Validation loss: 2.775337324894758

Epoch: 6| Step: 4
Training loss: 2.8920335791552327
Validation loss: 2.7736286758931823

Epoch: 6| Step: 5
Training loss: 2.7600264267416454
Validation loss: 2.774601617530831

Epoch: 6| Step: 6
Training loss: 2.9214852629026598
Validation loss: 2.7723892719837004

Epoch: 6| Step: 7
Training loss: 3.1529020172003315
Validation loss: 2.775193331346389

Epoch: 6| Step: 8
Training loss: 2.7133303588675926
Validation loss: 2.7728833909215904

Epoch: 6| Step: 9
Training loss: 2.7283603457459598
Validation loss: 2.772775296261675

Epoch: 6| Step: 10
Training loss: 2.955424710136456
Validation loss: 2.7747040392424123

Epoch: 6| Step: 11
Training loss: 3.4170704734798107
Validation loss: 2.773961600398838

Epoch: 6| Step: 12
Training loss: 3.274581381564261
Validation loss: 2.781153134406726

Epoch: 6| Step: 13
Training loss: 3.3607061543242502
Validation loss: 2.772092026455257

Epoch: 40| Step: 0
Training loss: 3.5966867140764243
Validation loss: 2.773807241360503

Epoch: 6| Step: 1
Training loss: 3.2819849553574105
Validation loss: 2.7676266392358277

Epoch: 6| Step: 2
Training loss: 2.756821148920882
Validation loss: 2.7683704029062013

Epoch: 6| Step: 3
Training loss: 2.748305752509597
Validation loss: 2.7664289150191155

Epoch: 6| Step: 4
Training loss: 3.158202370081465
Validation loss: 2.766299762914263

Epoch: 6| Step: 5
Training loss: 3.5647293610855852
Validation loss: 2.767720830789422

Epoch: 6| Step: 6
Training loss: 1.9382097728485619
Validation loss: 2.7657189482730127

Epoch: 6| Step: 7
Training loss: 3.5627617990770712
Validation loss: 2.7657408887283825

Epoch: 6| Step: 8
Training loss: 2.7339630688598646
Validation loss: 2.7707157398417954

Epoch: 6| Step: 9
Training loss: 3.302317389407151
Validation loss: 2.7665817610824304

Epoch: 6| Step: 10
Training loss: 3.337093965784393
Validation loss: 2.7727405246010632

Epoch: 6| Step: 11
Training loss: 2.7542330500633527
Validation loss: 2.7730608635712857

Epoch: 6| Step: 12
Training loss: 3.1300024048427324
Validation loss: 2.7774169786685645

Epoch: 6| Step: 13
Training loss: 2.957012705574695
Validation loss: 2.788241609754815

Epoch: 41| Step: 0
Training loss: 2.0449193100061516
Validation loss: 2.812180684875888

Epoch: 6| Step: 1
Training loss: 2.5400630916058717
Validation loss: 2.8376435828660873

Epoch: 6| Step: 2
Training loss: 3.6297996579206164
Validation loss: 2.869537598353942

Epoch: 6| Step: 3
Training loss: 2.640312221444461
Validation loss: 2.7981810846044692

Epoch: 6| Step: 4
Training loss: 2.632431500767245
Validation loss: 2.774044525856737

Epoch: 6| Step: 5
Training loss: 3.6031621661424036
Validation loss: 2.77367407485783

Epoch: 6| Step: 6
Training loss: 3.3450001313761186
Validation loss: 2.8096812307306203

Epoch: 6| Step: 7
Training loss: 3.639601534947324
Validation loss: 2.8166086528294008

Epoch: 6| Step: 8
Training loss: 3.524224237882975
Validation loss: 2.7624684047789962

Epoch: 6| Step: 9
Training loss: 2.9710681096670055
Validation loss: 2.757881596642685

Epoch: 6| Step: 10
Training loss: 3.028268665413344
Validation loss: 2.758523166165281

Epoch: 6| Step: 11
Training loss: 3.141779597214863
Validation loss: 2.759562361140958

Epoch: 6| Step: 12
Training loss: 3.012228520613997
Validation loss: 2.7590477688083785

Epoch: 6| Step: 13
Training loss: 3.189456414094293
Validation loss: 2.7600324075771936

Epoch: 42| Step: 0
Training loss: 3.6032900028875927
Validation loss: 2.7774184942842632

Epoch: 6| Step: 1
Training loss: 3.481718273617327
Validation loss: 2.7836655361834617

Epoch: 6| Step: 2
Training loss: 2.7746558723490264
Validation loss: 2.7598552842712456

Epoch: 6| Step: 3
Training loss: 2.5564848850220474
Validation loss: 2.7634730990349494

Epoch: 6| Step: 4
Training loss: 2.9529444725120144
Validation loss: 2.7701846425946246

Epoch: 6| Step: 5
Training loss: 3.0231310469791866
Validation loss: 2.774161170877611

Epoch: 6| Step: 6
Training loss: 3.382503222275783
Validation loss: 2.76055013636164

Epoch: 6| Step: 7
Training loss: 3.6953087578849315
Validation loss: 2.7573626560182403

Epoch: 6| Step: 8
Training loss: 2.7130403745116785
Validation loss: 2.751925745982386

Epoch: 6| Step: 9
Training loss: 3.3794691377696005
Validation loss: 2.75039091063288

Epoch: 6| Step: 10
Training loss: 2.486550584117091
Validation loss: 2.7505054419565687

Epoch: 6| Step: 11
Training loss: 2.6612032315797505
Validation loss: 2.749037644145165

Epoch: 6| Step: 12
Training loss: 2.910724108292424
Validation loss: 2.747424834754967

Epoch: 6| Step: 13
Training loss: 3.5198460987432236
Validation loss: 2.7595017374807425

Epoch: 43| Step: 0
Training loss: 2.9227582443130165
Validation loss: 2.76579916032391

Epoch: 6| Step: 1
Training loss: 3.4437249433710155
Validation loss: 2.7696807379908006

Epoch: 6| Step: 2
Training loss: 3.2205220501800325
Validation loss: 2.775092766063099

Epoch: 6| Step: 3
Training loss: 2.851453303506413
Validation loss: 2.790459998535457

Epoch: 6| Step: 4
Training loss: 2.9284782660682294
Validation loss: 2.808368750579798

Epoch: 6| Step: 5
Training loss: 2.464260606657586
Validation loss: 2.8372479389211853

Epoch: 6| Step: 6
Training loss: 3.2710520353315506
Validation loss: 2.836788355284252

Epoch: 6| Step: 7
Training loss: 3.137869161947713
Validation loss: 2.8224524485720317

Epoch: 6| Step: 8
Training loss: 3.134879403114307
Validation loss: 2.777455784446552

Epoch: 6| Step: 9
Training loss: 3.6266060264042954
Validation loss: 2.7434028265130586

Epoch: 6| Step: 10
Training loss: 2.6326511231722924
Validation loss: 2.7459199237410936

Epoch: 6| Step: 11
Training loss: 2.977274491668962
Validation loss: 2.74428426931289

Epoch: 6| Step: 12
Training loss: 2.848247953250953
Validation loss: 2.749483511219321

Epoch: 6| Step: 13
Training loss: 3.6003300674442973
Validation loss: 2.757111108886811

Epoch: 44| Step: 0
Training loss: 3.4536858702983166
Validation loss: 2.763024485617564

Epoch: 6| Step: 1
Training loss: 2.4080834277772643
Validation loss: 2.7522072543094436

Epoch: 6| Step: 2
Training loss: 3.0154184853793966
Validation loss: 2.746121015389865

Epoch: 6| Step: 3
Training loss: 2.9347144372366114
Validation loss: 2.743761509603421

Epoch: 6| Step: 4
Training loss: 3.288701778393266
Validation loss: 2.746629843427185

Epoch: 6| Step: 5
Training loss: 2.7022857245120946
Validation loss: 2.746240305522406

Epoch: 6| Step: 6
Training loss: 3.7089572481646886
Validation loss: 2.750329575874457

Epoch: 6| Step: 7
Training loss: 2.3603307543947314
Validation loss: 2.745835201723329

Epoch: 6| Step: 8
Training loss: 3.074720019488309
Validation loss: 2.752320985384778

Epoch: 6| Step: 9
Training loss: 2.671065626194395
Validation loss: 2.7510892196931254

Epoch: 6| Step: 10
Training loss: 3.7411286004708835
Validation loss: 2.7510950559503264

Epoch: 6| Step: 11
Training loss: 3.5867364529434744
Validation loss: 2.759148104505842

Epoch: 6| Step: 12
Training loss: 2.543855152253078
Validation loss: 2.747451081989128

Epoch: 6| Step: 13
Training loss: 3.04521658341685
Validation loss: 2.754682805777178

Epoch: 45| Step: 0
Training loss: 3.0109993833745845
Validation loss: 2.748799427402862

Epoch: 6| Step: 1
Training loss: 2.56215386262642
Validation loss: 2.74292547117314

Epoch: 6| Step: 2
Training loss: 2.7602250134615773
Validation loss: 2.744857912131442

Epoch: 6| Step: 3
Training loss: 2.780968469665282
Validation loss: 2.733814496371755

Epoch: 6| Step: 4
Training loss: 3.8273913867771197
Validation loss: 2.7424364645685446

Epoch: 6| Step: 5
Training loss: 2.8256482823658726
Validation loss: 2.737535192458483

Epoch: 6| Step: 6
Training loss: 2.9099091495345557
Validation loss: 2.731277542499143

Epoch: 6| Step: 7
Training loss: 2.9602663593044776
Validation loss: 2.724979562523766

Epoch: 6| Step: 8
Training loss: 3.8224078401941024
Validation loss: 2.7201019987674164

Epoch: 6| Step: 9
Training loss: 2.9921357073173365
Validation loss: 2.7207509410822857

Epoch: 6| Step: 10
Training loss: 2.896774596415635
Validation loss: 2.720107413307312

Epoch: 6| Step: 11
Training loss: 3.584783630226113
Validation loss: 2.716379852701302

Epoch: 6| Step: 12
Training loss: 2.354690043467646
Validation loss: 2.7171065007357726

Epoch: 6| Step: 13
Training loss: 3.235715431687156
Validation loss: 2.717001232208729

Epoch: 46| Step: 0
Training loss: 2.605444500537219
Validation loss: 2.711652630620274

Epoch: 6| Step: 1
Training loss: 3.2784264904983114
Validation loss: 2.712874850321451

Epoch: 6| Step: 2
Training loss: 3.123375584884163
Validation loss: 2.716505266595736

Epoch: 6| Step: 3
Training loss: 2.7714812780770224
Validation loss: 2.721556502447561

Epoch: 6| Step: 4
Training loss: 2.962590302326408
Validation loss: 2.7282895260908253

Epoch: 6| Step: 5
Training loss: 3.8446031569523846
Validation loss: 2.731902913128919

Epoch: 6| Step: 6
Training loss: 3.0437700149536044
Validation loss: 2.7253360713782597

Epoch: 6| Step: 7
Training loss: 3.2907009076151095
Validation loss: 2.733330954186249

Epoch: 6| Step: 8
Training loss: 2.7199643810127867
Validation loss: 2.7337892060149325

Epoch: 6| Step: 9
Training loss: 2.742754929133816
Validation loss: 2.726271967181399

Epoch: 6| Step: 10
Training loss: 3.3794816954899116
Validation loss: 2.7251041751820813

Epoch: 6| Step: 11
Training loss: 2.5458607906810897
Validation loss: 2.7170919082372715

Epoch: 6| Step: 12
Training loss: 2.9779824702129307
Validation loss: 2.7137423044680746

Epoch: 6| Step: 13
Training loss: 3.1343504823921924
Validation loss: 2.7117260213501733

Epoch: 47| Step: 0
Training loss: 3.155438913807322
Validation loss: 2.717930178998233

Epoch: 6| Step: 1
Training loss: 2.946404292679538
Validation loss: 2.7080439038228703

Epoch: 6| Step: 2
Training loss: 2.7837514879199583
Validation loss: 2.709524483071096

Epoch: 6| Step: 3
Training loss: 3.4576102423866164
Validation loss: 2.705302999675562

Epoch: 6| Step: 4
Training loss: 3.22858415497443
Validation loss: 2.70032685442367

Epoch: 6| Step: 5
Training loss: 2.598186972188482
Validation loss: 2.7005170876564657

Epoch: 6| Step: 6
Training loss: 3.7913288063740915
Validation loss: 2.699528689135767

Epoch: 6| Step: 7
Training loss: 3.1069197425851276
Validation loss: 2.6992634287740636

Epoch: 6| Step: 8
Training loss: 2.8961052160908203
Validation loss: 2.6967303987970213

Epoch: 6| Step: 9
Training loss: 3.4483919459567605
Validation loss: 2.6955369063794867

Epoch: 6| Step: 10
Training loss: 2.771156253975541
Validation loss: 2.698077129407102

Epoch: 6| Step: 11
Training loss: 2.8178839966645977
Validation loss: 2.6965563001075097

Epoch: 6| Step: 12
Training loss: 2.4208753922486226
Validation loss: 2.6954479695321445

Epoch: 6| Step: 13
Training loss: 2.6042933522245373
Validation loss: 2.6998416189154493

Epoch: 48| Step: 0
Training loss: 3.141926813527409
Validation loss: 2.6917506831515516

Epoch: 6| Step: 1
Training loss: 3.3907486150331345
Validation loss: 2.6985824421673215

Epoch: 6| Step: 2
Training loss: 3.250640805966427
Validation loss: 2.695510088012399

Epoch: 6| Step: 3
Training loss: 2.634299200920097
Validation loss: 2.6934280244578246

Epoch: 6| Step: 4
Training loss: 3.0053783525120505
Validation loss: 2.692428844432323

Epoch: 6| Step: 5
Training loss: 2.669792925630576
Validation loss: 2.693604393496458

Epoch: 6| Step: 6
Training loss: 2.874049651596386
Validation loss: 2.6918271907769094

Epoch: 6| Step: 7
Training loss: 2.7108360953150306
Validation loss: 2.693252692836322

Epoch: 6| Step: 8
Training loss: 3.480549855255901
Validation loss: 2.6947189735713555

Epoch: 6| Step: 9
Training loss: 2.9243558255843127
Validation loss: 2.690207319433406

Epoch: 6| Step: 10
Training loss: 3.6722498925558518
Validation loss: 2.686796305610761

Epoch: 6| Step: 11
Training loss: 2.5991337983879568
Validation loss: 2.692901955362453

Epoch: 6| Step: 12
Training loss: 2.8927017587310693
Validation loss: 2.698156664384598

Epoch: 6| Step: 13
Training loss: 3.025819456222204
Validation loss: 2.6967302514466187

Epoch: 49| Step: 0
Training loss: 2.9780298656147095
Validation loss: 2.6956563275218395

Epoch: 6| Step: 1
Training loss: 2.925827535306451
Validation loss: 2.69585705892024

Epoch: 6| Step: 2
Training loss: 2.683528982655252
Validation loss: 2.693776786249798

Epoch: 6| Step: 3
Training loss: 3.0489394798690737
Validation loss: 2.6912742311015627

Epoch: 6| Step: 4
Training loss: 3.430715211421292
Validation loss: 2.6903410563659933

Epoch: 6| Step: 5
Training loss: 2.798669165005719
Validation loss: 2.6923508675293513

Epoch: 6| Step: 6
Training loss: 3.590635459360106
Validation loss: 2.6988652466493783

Epoch: 6| Step: 7
Training loss: 3.2418706899996352
Validation loss: 2.707446114081673

Epoch: 6| Step: 8
Training loss: 2.752115996111844
Validation loss: 2.692802043091934

Epoch: 6| Step: 9
Training loss: 2.585717229307045
Validation loss: 2.705472992527436

Epoch: 6| Step: 10
Training loss: 2.735354874652136
Validation loss: 2.7468856598339015

Epoch: 6| Step: 11
Training loss: 2.612384636627053
Validation loss: 2.8038622586707707

Epoch: 6| Step: 12
Training loss: 3.557926923665047
Validation loss: 2.855372085799194

Epoch: 6| Step: 13
Training loss: 3.9335036812010196
Validation loss: 2.7614387367584214

Epoch: 50| Step: 0
Training loss: 3.0854307893425115
Validation loss: 2.7046684511997205

Epoch: 6| Step: 1
Training loss: 3.1262880341154458
Validation loss: 2.6929946803967666

Epoch: 6| Step: 2
Training loss: 2.8492075772140923
Validation loss: 2.71797262602498

Epoch: 6| Step: 3
Training loss: 2.6835625659180247
Validation loss: 2.712747038779262

Epoch: 6| Step: 4
Training loss: 2.9217362804428557
Validation loss: 2.7137799840444825

Epoch: 6| Step: 5
Training loss: 2.8971849393005216
Validation loss: 2.70907752427726

Epoch: 6| Step: 6
Training loss: 3.081349654066022
Validation loss: 2.707420812244212

Epoch: 6| Step: 7
Training loss: 3.3591549823481754
Validation loss: 2.7050327035257893

Epoch: 6| Step: 8
Training loss: 2.961969442381217
Validation loss: 2.6934964894224693

Epoch: 6| Step: 9
Training loss: 3.5018052486381435
Validation loss: 2.6930377593908035

Epoch: 6| Step: 10
Training loss: 2.695849378991071
Validation loss: 2.688440088341788

Epoch: 6| Step: 11
Training loss: 2.898199930248664
Validation loss: 2.6902636173906824

Epoch: 6| Step: 12
Training loss: 3.4091950730102556
Validation loss: 2.7068634518637116

Epoch: 6| Step: 13
Training loss: 2.8419294293612793
Validation loss: 2.7219124499793064

Epoch: 51| Step: 0
Training loss: 3.3968207361121148
Validation loss: 2.7362098737099236

Epoch: 6| Step: 1
Training loss: 2.7324066925172374
Validation loss: 2.7134283909480006

Epoch: 6| Step: 2
Training loss: 3.2688515525199535
Validation loss: 2.695002745665903

Epoch: 6| Step: 3
Training loss: 3.1312553360031257
Validation loss: 2.6877624114604135

Epoch: 6| Step: 4
Training loss: 2.9938995005444573
Validation loss: 2.682616969612002

Epoch: 6| Step: 5
Training loss: 2.861976982210741
Validation loss: 2.6826566268474363

Epoch: 6| Step: 6
Training loss: 3.3287100837311145
Validation loss: 2.682899763782824

Epoch: 6| Step: 7
Training loss: 2.5227771757221698
Validation loss: 2.684729602663531

Epoch: 6| Step: 8
Training loss: 3.075915477905997
Validation loss: 2.6814666087634658

Epoch: 6| Step: 9
Training loss: 3.037986584531434
Validation loss: 2.681270486137794

Epoch: 6| Step: 10
Training loss: 2.808280407400254
Validation loss: 2.6773370930804177

Epoch: 6| Step: 11
Training loss: 2.8955771426670265
Validation loss: 2.6820823854607303

Epoch: 6| Step: 12
Training loss: 3.2301045850232137
Validation loss: 2.67882881002261

Epoch: 6| Step: 13
Training loss: 2.860046474639384
Validation loss: 2.6817429625358304

Epoch: 52| Step: 0
Training loss: 3.185098079686351
Validation loss: 2.6859600141192383

Epoch: 6| Step: 1
Training loss: 3.3399187046139573
Validation loss: 2.691153658121177

Epoch: 6| Step: 2
Training loss: 2.9838508824784102
Validation loss: 2.690465981274931

Epoch: 6| Step: 3
Training loss: 3.435619741667925
Validation loss: 2.678731686104468

Epoch: 6| Step: 4
Training loss: 2.8319726556438454
Validation loss: 2.6765347893921922

Epoch: 6| Step: 5
Training loss: 2.843658110423018
Validation loss: 2.6732632582310427

Epoch: 6| Step: 6
Training loss: 2.8239715594623727
Validation loss: 2.6717239746902726

Epoch: 6| Step: 7
Training loss: 2.972264347986074
Validation loss: 2.6677450103864553

Epoch: 6| Step: 8
Training loss: 3.160770917605245
Validation loss: 2.671400048006121

Epoch: 6| Step: 9
Training loss: 2.6746554714334967
Validation loss: 2.6759076948404683

Epoch: 6| Step: 10
Training loss: 2.406556345277036
Validation loss: 2.6857818115329852

Epoch: 6| Step: 11
Training loss: 3.1114950189172057
Validation loss: 2.7100007716485317

Epoch: 6| Step: 12
Training loss: 3.309224938870871
Validation loss: 2.7128097500980703

Epoch: 6| Step: 13
Training loss: 3.0785520615567528
Validation loss: 2.740888111671551

Epoch: 53| Step: 0
Training loss: 3.5368417673391646
Validation loss: 2.7534949708946215

Epoch: 6| Step: 1
Training loss: 2.9774633130840957
Validation loss: 2.7047315948424173

Epoch: 6| Step: 2
Training loss: 3.1491331936289737
Validation loss: 2.684510407579419

Epoch: 6| Step: 3
Training loss: 3.184591125401553
Validation loss: 2.6743411168418434

Epoch: 6| Step: 4
Training loss: 3.202948737528338
Validation loss: 2.669107455164089

Epoch: 6| Step: 5
Training loss: 2.741298520571581
Validation loss: 2.6687058322586203

Epoch: 6| Step: 6
Training loss: 2.984404079435388
Validation loss: 2.673298195075146

Epoch: 6| Step: 7
Training loss: 3.1464396686089184
Validation loss: 2.676729007327465

Epoch: 6| Step: 8
Training loss: 2.876025141514591
Validation loss: 2.6759954608838457

Epoch: 6| Step: 9
Training loss: 3.056153552946018
Validation loss: 2.6735955746668107

Epoch: 6| Step: 10
Training loss: 3.2747479640279606
Validation loss: 2.6720559049880235

Epoch: 6| Step: 11
Training loss: 2.5224516746950525
Validation loss: 2.6701584916289325

Epoch: 6| Step: 12
Training loss: 2.6655503757849273
Validation loss: 2.665340252005821

Epoch: 6| Step: 13
Training loss: 2.6396400375317235
Validation loss: 2.6663445459541575

Epoch: 54| Step: 0
Training loss: 3.2459500828428673
Validation loss: 2.6657457277196075

Epoch: 6| Step: 1
Training loss: 3.324762069105413
Validation loss: 2.6675989350550418

Epoch: 6| Step: 2
Training loss: 2.4383807425106476
Validation loss: 2.674969692286624

Epoch: 6| Step: 3
Training loss: 2.6984436423845297
Validation loss: 2.7051994372641834

Epoch: 6| Step: 4
Training loss: 3.0991958313448653
Validation loss: 2.7392142081590825

Epoch: 6| Step: 5
Training loss: 3.1382306589384363
Validation loss: 2.782944885835221

Epoch: 6| Step: 6
Training loss: 3.9848950813295074
Validation loss: 2.7121654326659574

Epoch: 6| Step: 7
Training loss: 3.2446470927467175
Validation loss: 2.659995148082462

Epoch: 6| Step: 8
Training loss: 3.057034500631178
Validation loss: 2.6622366858632316

Epoch: 6| Step: 9
Training loss: 2.831796023366892
Validation loss: 2.6650609978095625

Epoch: 6| Step: 10
Training loss: 2.7922175324142517
Validation loss: 2.674738241841728

Epoch: 6| Step: 11
Training loss: 3.0301810670642
Validation loss: 2.70083641919895

Epoch: 6| Step: 12
Training loss: 2.6562514361209355
Validation loss: 2.7165639573166493

Epoch: 6| Step: 13
Training loss: 2.547528610143708
Validation loss: 2.7364941182764513

Epoch: 55| Step: 0
Training loss: 2.7083652396645728
Validation loss: 2.730661703359011

Epoch: 6| Step: 1
Training loss: 2.5572170601480826
Validation loss: 2.7291273680820183

Epoch: 6| Step: 2
Training loss: 3.3765402211059317
Validation loss: 2.7434864448416385

Epoch: 6| Step: 3
Training loss: 3.1358591234327795
Validation loss: 2.757966475191557

Epoch: 6| Step: 4
Training loss: 2.466184611084439
Validation loss: 2.7387304033771884

Epoch: 6| Step: 5
Training loss: 2.6034880605899695
Validation loss: 2.739737935645784

Epoch: 6| Step: 6
Training loss: 3.3059235554076594
Validation loss: 2.7363090704486446

Epoch: 6| Step: 7
Training loss: 3.3654861577403485
Validation loss: 2.72409087568233

Epoch: 6| Step: 8
Training loss: 2.502842622181077
Validation loss: 2.7090217762883584

Epoch: 6| Step: 9
Training loss: 2.963746361571371
Validation loss: 2.694478009673879

Epoch: 6| Step: 10
Training loss: 3.128381044501249
Validation loss: 2.685155523667775

Epoch: 6| Step: 11
Training loss: 3.555332133770472
Validation loss: 2.6671026229845864

Epoch: 6| Step: 12
Training loss: 3.9196741988582815
Validation loss: 2.66736068526169

Epoch: 6| Step: 13
Training loss: 2.208459550621418
Validation loss: 2.666896526238517

Epoch: 56| Step: 0
Training loss: 3.178670734672802
Validation loss: 2.6644790069295143

Epoch: 6| Step: 1
Training loss: 2.5482497922062124
Validation loss: 2.665747262107308

Epoch: 6| Step: 2
Training loss: 2.8626140321898164
Validation loss: 2.660669891051865

Epoch: 6| Step: 3
Training loss: 2.981720547758753
Validation loss: 2.6646950778782648

Epoch: 6| Step: 4
Training loss: 3.190233591788887
Validation loss: 2.665671428831053

Epoch: 6| Step: 5
Training loss: 3.2779505535071443
Validation loss: 2.666884691384257

Epoch: 6| Step: 6
Training loss: 2.3905050210203873
Validation loss: 2.669495428777483

Epoch: 6| Step: 7
Training loss: 2.909853762068805
Validation loss: 2.670538025127192

Epoch: 6| Step: 8
Training loss: 2.709784270705365
Validation loss: 2.6751757430150693

Epoch: 6| Step: 9
Training loss: 2.988141464255063
Validation loss: 2.6935875702935066

Epoch: 6| Step: 10
Training loss: 2.84663647051243
Validation loss: 2.699015814224733

Epoch: 6| Step: 11
Training loss: 3.3422503094079152
Validation loss: 2.7088118049264582

Epoch: 6| Step: 12
Training loss: 3.4664480458306826
Validation loss: 2.735803394293308

Epoch: 6| Step: 13
Training loss: 3.4108593752236795
Validation loss: 2.7305824645398027

Epoch: 57| Step: 0
Training loss: 2.912949582219831
Validation loss: 2.721871769172768

Epoch: 6| Step: 1
Training loss: 2.8197594097666
Validation loss: 2.698018323020703

Epoch: 6| Step: 2
Training loss: 3.573826369129733
Validation loss: 2.6767594310817575

Epoch: 6| Step: 3
Training loss: 3.0386344392458753
Validation loss: 2.683444478107551

Epoch: 6| Step: 4
Training loss: 3.044778738517517
Validation loss: 2.7011256940466377

Epoch: 6| Step: 5
Training loss: 2.97935278962461
Validation loss: 2.7195539670728928

Epoch: 6| Step: 6
Training loss: 2.652262937862466
Validation loss: 2.7224946542493007

Epoch: 6| Step: 7
Training loss: 3.0883257545450937
Validation loss: 2.722960035045874

Epoch: 6| Step: 8
Training loss: 2.883883145635527
Validation loss: 2.6844420161653697

Epoch: 6| Step: 9
Training loss: 2.596715679399867
Validation loss: 2.6717552806373446

Epoch: 6| Step: 10
Training loss: 3.354639876888916
Validation loss: 2.658524710810611

Epoch: 6| Step: 11
Training loss: 2.8980966043633978
Validation loss: 2.654238125832755

Epoch: 6| Step: 12
Training loss: 2.7183435070409567
Validation loss: 2.661643677997216

Epoch: 6| Step: 13
Training loss: 3.518218037860398
Validation loss: 2.6639185295095684

Epoch: 58| Step: 0
Training loss: 2.8463535337921493
Validation loss: 2.6888579848469067

Epoch: 6| Step: 1
Training loss: 3.4636616545044876
Validation loss: 2.685253631541529

Epoch: 6| Step: 2
Training loss: 2.934451855190282
Validation loss: 2.675934413630834

Epoch: 6| Step: 3
Training loss: 3.1691995997744367
Validation loss: 2.650003361211291

Epoch: 6| Step: 4
Training loss: 2.638840653720406
Validation loss: 2.650469636156165

Epoch: 6| Step: 5
Training loss: 3.076661357385994
Validation loss: 2.652172041442628

Epoch: 6| Step: 6
Training loss: 2.6185586099174865
Validation loss: 2.65599472006326

Epoch: 6| Step: 7
Training loss: 3.0887432236328882
Validation loss: 2.6582667426104565

Epoch: 6| Step: 8
Training loss: 3.003534460188536
Validation loss: 2.65657106856267

Epoch: 6| Step: 9
Training loss: 3.3307083920608145
Validation loss: 2.653720700123853

Epoch: 6| Step: 10
Training loss: 2.841320635030444
Validation loss: 2.6528170943740235

Epoch: 6| Step: 11
Training loss: 2.803685001158988
Validation loss: 2.6541191612094495

Epoch: 6| Step: 12
Training loss: 3.19715048758021
Validation loss: 2.6603903229649712

Epoch: 6| Step: 13
Training loss: 2.9772804175442364
Validation loss: 2.66062922872636

Epoch: 59| Step: 0
Training loss: 2.373343040289298
Validation loss: 2.660278234635871

Epoch: 6| Step: 1
Training loss: 2.842812184391128
Validation loss: 2.6715820589439536

Epoch: 6| Step: 2
Training loss: 2.636620911089872
Validation loss: 2.669691626122993

Epoch: 6| Step: 3
Training loss: 2.9937626848370193
Validation loss: 2.6780807828611124

Epoch: 6| Step: 4
Training loss: 2.737573115796372
Validation loss: 2.681902375700832

Epoch: 6| Step: 5
Training loss: 2.935942703737821
Validation loss: 2.6699746188477174

Epoch: 6| Step: 6
Training loss: 3.6771279279185825
Validation loss: 2.675736757822768

Epoch: 6| Step: 7
Training loss: 2.9239011868794003
Validation loss: 2.667491387946525

Epoch: 6| Step: 8
Training loss: 3.2084743584358337
Validation loss: 2.6785462119951284

Epoch: 6| Step: 9
Training loss: 2.8264978269618948
Validation loss: 2.672076184304181

Epoch: 6| Step: 10
Training loss: 2.7581423813414623
Validation loss: 2.6632203481010657

Epoch: 6| Step: 11
Training loss: 3.1781247959493237
Validation loss: 2.6564782910142695

Epoch: 6| Step: 12
Training loss: 3.1407116930179484
Validation loss: 2.657970038052701

Epoch: 6| Step: 13
Training loss: 3.6061217604236515
Validation loss: 2.6549993795676086

Epoch: 60| Step: 0
Training loss: 3.706023293262944
Validation loss: 2.652434661799067

Epoch: 6| Step: 1
Training loss: 2.061797744954891
Validation loss: 2.6508531017237984

Epoch: 6| Step: 2
Training loss: 3.047952627689953
Validation loss: 2.6483873309379304

Epoch: 6| Step: 3
Training loss: 2.632025264236107
Validation loss: 2.6484237623595006

Epoch: 6| Step: 4
Training loss: 2.5251762139802465
Validation loss: 2.6488082422489634

Epoch: 6| Step: 5
Training loss: 2.756173487009993
Validation loss: 2.652768102106123

Epoch: 6| Step: 6
Training loss: 3.1932342411453694
Validation loss: 2.65036781669932

Epoch: 6| Step: 7
Training loss: 2.679043706402837
Validation loss: 2.6468101915723277

Epoch: 6| Step: 8
Training loss: 3.1216230838772656
Validation loss: 2.646168366306509

Epoch: 6| Step: 9
Training loss: 2.833788180773434
Validation loss: 2.6473333518413957

Epoch: 6| Step: 10
Training loss: 3.671656046081596
Validation loss: 2.6479891429800366

Epoch: 6| Step: 11
Training loss: 3.4361455850012006
Validation loss: 2.648818162660297

Epoch: 6| Step: 12
Training loss: 2.958684300481718
Validation loss: 2.6481359021324002

Epoch: 6| Step: 13
Training loss: 2.92873894149249
Validation loss: 2.6525040157246313

Epoch: 61| Step: 0
Training loss: 2.644514841679617
Validation loss: 2.662586080548179

Epoch: 6| Step: 1
Training loss: 3.2309082913076965
Validation loss: 2.6625199731553955

Epoch: 6| Step: 2
Training loss: 2.7533850210416775
Validation loss: 2.654781623351873

Epoch: 6| Step: 3
Training loss: 3.105275427600941
Validation loss: 2.6771191322905223

Epoch: 6| Step: 4
Training loss: 3.646075053603366
Validation loss: 2.6602830549282275

Epoch: 6| Step: 5
Training loss: 2.7515845502048943
Validation loss: 2.6514921947636627

Epoch: 6| Step: 6
Training loss: 2.1522698640689883
Validation loss: 2.647291425236211

Epoch: 6| Step: 7
Training loss: 3.0956008461022027
Validation loss: 2.647649537144857

Epoch: 6| Step: 8
Training loss: 2.49527408233478
Validation loss: 2.6495850712433193

Epoch: 6| Step: 9
Training loss: 3.1499024572861747
Validation loss: 2.6500235567924584

Epoch: 6| Step: 10
Training loss: 3.232492239840251
Validation loss: 2.6473783126546024

Epoch: 6| Step: 11
Training loss: 2.776935273726295
Validation loss: 2.647374130747251

Epoch: 6| Step: 12
Training loss: 2.9131787471073
Validation loss: 2.6469904493184426

Epoch: 6| Step: 13
Training loss: 3.8355038896982787
Validation loss: 2.6557733145440374

Epoch: 62| Step: 0
Training loss: 2.456281150251496
Validation loss: 2.660423072803824

Epoch: 6| Step: 1
Training loss: 3.424850494017523
Validation loss: 2.6909986894311335

Epoch: 6| Step: 2
Training loss: 2.9300808655187325
Validation loss: 2.67754296784867

Epoch: 6| Step: 3
Training loss: 3.0678266017807703
Validation loss: 2.670414945773299

Epoch: 6| Step: 4
Training loss: 2.60950227529818
Validation loss: 2.6586052689700486

Epoch: 6| Step: 5
Training loss: 2.825561457516261
Validation loss: 2.672134359480522

Epoch: 6| Step: 6
Training loss: 3.144130591225914
Validation loss: 2.6798895365644966

Epoch: 6| Step: 7
Training loss: 3.1278502626604427
Validation loss: 2.68842829063364

Epoch: 6| Step: 8
Training loss: 2.929501621707507
Validation loss: 2.6911801636258166

Epoch: 6| Step: 9
Training loss: 3.016178851088803
Validation loss: 2.679475613585696

Epoch: 6| Step: 10
Training loss: 2.522360557127265
Validation loss: 2.6883372361791134

Epoch: 6| Step: 11
Training loss: 2.989957212314204
Validation loss: 2.680523724708531

Epoch: 6| Step: 12
Training loss: 3.5341110117412198
Validation loss: 2.6891822491163935

Epoch: 6| Step: 13
Training loss: 3.0234490130695684
Validation loss: 2.6638230812326786

Epoch: 63| Step: 0
Training loss: 3.450080876162614
Validation loss: 2.649178696492407

Epoch: 6| Step: 1
Training loss: 2.844421978040557
Validation loss: 2.6444862402971188

Epoch: 6| Step: 2
Training loss: 2.898475996311905
Validation loss: 2.6416798971283546

Epoch: 6| Step: 3
Training loss: 3.5767163831437934
Validation loss: 2.641366159358236

Epoch: 6| Step: 4
Training loss: 2.6993097270644046
Validation loss: 2.6385154843852616

Epoch: 6| Step: 5
Training loss: 3.268266695371973
Validation loss: 2.6438681975644513

Epoch: 6| Step: 6
Training loss: 2.8145024270816217
Validation loss: 2.641152204211349

Epoch: 6| Step: 7
Training loss: 2.864990390408629
Validation loss: 2.638405423510455

Epoch: 6| Step: 8
Training loss: 3.0005578476094383
Validation loss: 2.6411479721636435

Epoch: 6| Step: 9
Training loss: 2.7017912468337157
Validation loss: 2.6427773498918326

Epoch: 6| Step: 10
Training loss: 3.0078058416119484
Validation loss: 2.6380363912303513

Epoch: 6| Step: 11
Training loss: 2.310815145827029
Validation loss: 2.643599313039983

Epoch: 6| Step: 12
Training loss: 3.161183344755593
Validation loss: 2.6376427619639307

Epoch: 6| Step: 13
Training loss: 2.7527505817047215
Validation loss: 2.6437908315199996

Epoch: 64| Step: 0
Training loss: 2.982946883022491
Validation loss: 2.658822747706641

Epoch: 6| Step: 1
Training loss: 3.03274326314218
Validation loss: 2.6591902479235365

Epoch: 6| Step: 2
Training loss: 2.301660237046675
Validation loss: 2.67103980409539

Epoch: 6| Step: 3
Training loss: 3.1520030843264597
Validation loss: 2.7027674223964557

Epoch: 6| Step: 4
Training loss: 3.272656623000695
Validation loss: 2.761370696511585

Epoch: 6| Step: 5
Training loss: 2.8448308211241438
Validation loss: 2.782776696885232

Epoch: 6| Step: 6
Training loss: 2.2592025754357374
Validation loss: 2.7448673695901467

Epoch: 6| Step: 7
Training loss: 2.6473368380288096
Validation loss: 2.723522678404119

Epoch: 6| Step: 8
Training loss: 3.6883255632482137
Validation loss: 2.7156163044568946

Epoch: 6| Step: 9
Training loss: 3.52094446191212
Validation loss: 2.6994391829294027

Epoch: 6| Step: 10
Training loss: 2.941569330119786
Validation loss: 2.681342140360662

Epoch: 6| Step: 11
Training loss: 2.7816101869670327
Validation loss: 2.663033699321014

Epoch: 6| Step: 12
Training loss: 3.028348812496897
Validation loss: 2.6495976040579765

Epoch: 6| Step: 13
Training loss: 3.3495969900007916
Validation loss: 2.6492206948377044

Epoch: 65| Step: 0
Training loss: 3.33028445681348
Validation loss: 2.6558585098604706

Epoch: 6| Step: 1
Training loss: 3.3300967397756853
Validation loss: 2.6605860142674027

Epoch: 6| Step: 2
Training loss: 2.071649889562205
Validation loss: 2.648544728973043

Epoch: 6| Step: 3
Training loss: 2.9688980868698955
Validation loss: 2.640262867998045

Epoch: 6| Step: 4
Training loss: 3.093401031849517
Validation loss: 2.6335735017855804

Epoch: 6| Step: 5
Training loss: 2.79544064700893
Validation loss: 2.6301592175407706

Epoch: 6| Step: 6
Training loss: 2.960156662377907
Validation loss: 2.64028080677998

Epoch: 6| Step: 7
Training loss: 2.82106063092297
Validation loss: 2.6542738723244095

Epoch: 6| Step: 8
Training loss: 2.915522396330692
Validation loss: 2.6942664966771286

Epoch: 6| Step: 9
Training loss: 2.9302213055354818
Validation loss: 2.7092743146850022

Epoch: 6| Step: 10
Training loss: 2.8797652517120667
Validation loss: 2.744707570960534

Epoch: 6| Step: 11
Training loss: 2.911912876921836
Validation loss: 2.789023786775753

Epoch: 6| Step: 12
Training loss: 3.2453850478620745
Validation loss: 2.746827941780389

Epoch: 6| Step: 13
Training loss: 3.5423471732007576
Validation loss: 2.696886154127213

Epoch: 66| Step: 0
Training loss: 3.181093547099096
Validation loss: 2.6426315649641

Epoch: 6| Step: 1
Training loss: 2.612944212021979
Validation loss: 2.6272055876700793

Epoch: 6| Step: 2
Training loss: 3.2227694404837766
Validation loss: 2.6223431407679305

Epoch: 6| Step: 3
Training loss: 2.774922319991773
Validation loss: 2.622479857567193

Epoch: 6| Step: 4
Training loss: 2.8132789380869943
Validation loss: 2.621494700053748

Epoch: 6| Step: 5
Training loss: 3.007118204415102
Validation loss: 2.627001886311324

Epoch: 6| Step: 6
Training loss: 3.39738065575958
Validation loss: 2.621428353449055

Epoch: 6| Step: 7
Training loss: 3.3568733304249885
Validation loss: 2.6408709601859117

Epoch: 6| Step: 8
Training loss: 2.7194307724588778
Validation loss: 2.6626912830286935

Epoch: 6| Step: 9
Training loss: 3.2518839144286686
Validation loss: 2.6786143672839584

Epoch: 6| Step: 10
Training loss: 2.969760602299981
Validation loss: 2.70940775861349

Epoch: 6| Step: 11
Training loss: 2.715710749880068
Validation loss: 2.7087062377035505

Epoch: 6| Step: 12
Training loss: 2.968278867581343
Validation loss: 2.714926836240442

Epoch: 6| Step: 13
Training loss: 2.24954770098542
Validation loss: 2.698147873626777

Epoch: 67| Step: 0
Training loss: 3.5393944725647457
Validation loss: 2.685698017420244

Epoch: 6| Step: 1
Training loss: 2.653981395664852
Validation loss: 2.678172669425777

Epoch: 6| Step: 2
Training loss: 2.9783993957854995
Validation loss: 2.67311965860484

Epoch: 6| Step: 3
Training loss: 3.742146215031921
Validation loss: 2.668768095768914

Epoch: 6| Step: 4
Training loss: 2.2904727484466942
Validation loss: 2.665302197351409

Epoch: 6| Step: 5
Training loss: 3.1664543247973485
Validation loss: 2.6637734598658405

Epoch: 6| Step: 6
Training loss: 2.002279055975782
Validation loss: 2.649101730377277

Epoch: 6| Step: 7
Training loss: 2.3871061070051063
Validation loss: 2.634927890998357

Epoch: 6| Step: 8
Training loss: 2.198654400523901
Validation loss: 2.630381372673456

Epoch: 6| Step: 9
Training loss: 3.64606602970667
Validation loss: 2.6424039772962886

Epoch: 6| Step: 10
Training loss: 3.057549660155401
Validation loss: 2.639180158448797

Epoch: 6| Step: 11
Training loss: 3.53845748614076
Validation loss: 2.6326002364829786

Epoch: 6| Step: 12
Training loss: 2.487092648991092
Validation loss: 2.631184904927074

Epoch: 6| Step: 13
Training loss: 3.3710474959257986
Validation loss: 2.6343774490657443

Epoch: 68| Step: 0
Training loss: 3.0490401962197975
Validation loss: 2.641592589359648

Epoch: 6| Step: 1
Training loss: 2.3044582446886888
Validation loss: 2.655286753508245

Epoch: 6| Step: 2
Training loss: 2.8602617066694522
Validation loss: 2.6629242763451346

Epoch: 6| Step: 3
Training loss: 3.109498448053915
Validation loss: 2.6637339690279203

Epoch: 6| Step: 4
Training loss: 2.9747300802926886
Validation loss: 2.649861351727107

Epoch: 6| Step: 5
Training loss: 2.5069017509377947
Validation loss: 2.6378539603068223

Epoch: 6| Step: 6
Training loss: 3.2994981788783995
Validation loss: 2.635854017868452

Epoch: 6| Step: 7
Training loss: 3.0797799400882715
Validation loss: 2.6295575240255484

Epoch: 6| Step: 8
Training loss: 3.438461585365706
Validation loss: 2.625886116143129

Epoch: 6| Step: 9
Training loss: 2.5748541225851986
Validation loss: 2.6211284109869064

Epoch: 6| Step: 10
Training loss: 3.359276490652327
Validation loss: 2.6237478878598193

Epoch: 6| Step: 11
Training loss: 3.120239293629852
Validation loss: 2.622971394958258

Epoch: 6| Step: 12
Training loss: 2.8293063399417133
Validation loss: 2.6237564373927666

Epoch: 6| Step: 13
Training loss: 2.2097125754581057
Validation loss: 2.619005035771495

Epoch: 69| Step: 0
Training loss: 2.7908490440250695
Validation loss: 2.6253650702457865

Epoch: 6| Step: 1
Training loss: 2.911352129496504
Validation loss: 2.631594232685902

Epoch: 6| Step: 2
Training loss: 2.8208112196475765
Validation loss: 2.6225405049065875

Epoch: 6| Step: 3
Training loss: 2.8918223607549116
Validation loss: 2.6242464158738237

Epoch: 6| Step: 4
Training loss: 3.588794907860581
Validation loss: 2.6339825099348473

Epoch: 6| Step: 5
Training loss: 2.6403028302913536
Validation loss: 2.6293540370513098

Epoch: 6| Step: 6
Training loss: 3.2263835275442814
Validation loss: 2.6268335854011884

Epoch: 6| Step: 7
Training loss: 3.118269424259313
Validation loss: 2.626148754794043

Epoch: 6| Step: 8
Training loss: 3.3378589108535803
Validation loss: 2.621265138329693

Epoch: 6| Step: 9
Training loss: 2.8699987282567414
Validation loss: 2.620918550368897

Epoch: 6| Step: 10
Training loss: 2.749167663151596
Validation loss: 2.6210140939152446

Epoch: 6| Step: 11
Training loss: 1.7327451866566284
Validation loss: 2.6350130807093044

Epoch: 6| Step: 12
Training loss: 3.2657172815161095
Validation loss: 2.626060228756912

Epoch: 6| Step: 13
Training loss: 3.1216754777019884
Validation loss: 2.618529915446113

Epoch: 70| Step: 0
Training loss: 2.666511819237824
Validation loss: 2.609356051955809

Epoch: 6| Step: 1
Training loss: 3.2266550120098554
Validation loss: 2.6095559534732615

Epoch: 6| Step: 2
Training loss: 2.9760900407829007
Validation loss: 2.607514711873214

Epoch: 6| Step: 3
Training loss: 3.2637870033179777
Validation loss: 2.606741743896725

Epoch: 6| Step: 4
Training loss: 3.3035450937996256
Validation loss: 2.6096632986521895

Epoch: 6| Step: 5
Training loss: 2.956252767872069
Validation loss: 2.606060818990464

Epoch: 6| Step: 6
Training loss: 2.632951047970376
Validation loss: 2.6035307575824245

Epoch: 6| Step: 7
Training loss: 2.3945165138973565
Validation loss: 2.6059026862131636

Epoch: 6| Step: 8
Training loss: 2.8313512788219892
Validation loss: 2.6419108954484942

Epoch: 6| Step: 9
Training loss: 2.982252554593162
Validation loss: 2.709223693823198

Epoch: 6| Step: 10
Training loss: 2.460360795521792
Validation loss: 2.7377596307392453

Epoch: 6| Step: 11
Training loss: 3.3946995314839894
Validation loss: 2.6871859020418363

Epoch: 6| Step: 12
Training loss: 3.043738682782637
Validation loss: 2.6523445522419435

Epoch: 6| Step: 13
Training loss: 2.9830244113947595
Validation loss: 2.6334882139119533

Epoch: 71| Step: 0
Training loss: 3.241480297494182
Validation loss: 2.625181551239861

Epoch: 6| Step: 1
Training loss: 3.5211982462705183
Validation loss: 2.623582224655369

Epoch: 6| Step: 2
Training loss: 2.5369667206935804
Validation loss: 2.613695202089411

Epoch: 6| Step: 3
Training loss: 2.6184219409786755
Validation loss: 2.611151717372125

Epoch: 6| Step: 4
Training loss: 3.2157492862923935
Validation loss: 2.60730102696539

Epoch: 6| Step: 5
Training loss: 2.6337394554097284
Validation loss: 2.6121648628934944

Epoch: 6| Step: 6
Training loss: 2.858272319027569
Validation loss: 2.600332108924701

Epoch: 6| Step: 7
Training loss: 2.683022606275641
Validation loss: 2.5982460188255945

Epoch: 6| Step: 8
Training loss: 3.083374194999952
Validation loss: 2.5962588613788453

Epoch: 6| Step: 9
Training loss: 3.2315922804861015
Validation loss: 2.597963307425941

Epoch: 6| Step: 10
Training loss: 3.262543314796052
Validation loss: 2.592756244817246

Epoch: 6| Step: 11
Training loss: 2.5528087181934667
Validation loss: 2.595511715738068

Epoch: 6| Step: 12
Training loss: 2.7575225245367694
Validation loss: 2.5943937228065064

Epoch: 6| Step: 13
Training loss: 2.3776046123413694
Validation loss: 2.5916802986967458

Epoch: 72| Step: 0
Training loss: 3.6153285479529456
Validation loss: 2.5908094565713964

Epoch: 6| Step: 1
Training loss: 2.980053234008892
Validation loss: 2.5900983866980014

Epoch: 6| Step: 2
Training loss: 2.9674551298224823
Validation loss: 2.5875200099328888

Epoch: 6| Step: 3
Training loss: 2.9997657048605673
Validation loss: 2.587771788345368

Epoch: 6| Step: 4
Training loss: 2.60840355613032
Validation loss: 2.5870307188081307

Epoch: 6| Step: 5
Training loss: 3.1022126023356833
Validation loss: 2.5904019151993576

Epoch: 6| Step: 6
Training loss: 3.0694630153855615
Validation loss: 2.601282025490176

Epoch: 6| Step: 7
Training loss: 3.1082985706447928
Validation loss: 2.6195808987534974

Epoch: 6| Step: 8
Training loss: 2.9760982121289787
Validation loss: 2.610037739321008

Epoch: 6| Step: 9
Training loss: 3.2822208966311557
Validation loss: 2.606043185705192

Epoch: 6| Step: 10
Training loss: 2.6282686137582845
Validation loss: 2.600813299839231

Epoch: 6| Step: 11
Training loss: 2.442954977525537
Validation loss: 2.5973871208087944

Epoch: 6| Step: 12
Training loss: 2.597284321940712
Validation loss: 2.5915380495911693

Epoch: 6| Step: 13
Training loss: 2.1770586684683924
Validation loss: 2.5845538536578907

Epoch: 73| Step: 0
Training loss: 3.420675546505106
Validation loss: 2.604914812150796

Epoch: 6| Step: 1
Training loss: 3.718706146751016
Validation loss: 2.6263905849499647

Epoch: 6| Step: 2
Training loss: 3.277114150833439
Validation loss: 2.6305427942113258

Epoch: 6| Step: 3
Training loss: 3.195946665465645
Validation loss: 2.6246937965293404

Epoch: 6| Step: 4
Training loss: 2.575396764612828
Validation loss: 2.623563671390142

Epoch: 6| Step: 5
Training loss: 2.7412559035377235
Validation loss: 2.597373620484772

Epoch: 6| Step: 6
Training loss: 2.911167209835362
Validation loss: 2.583785624478148

Epoch: 6| Step: 7
Training loss: 2.7727596690393086
Validation loss: 2.584808133725878

Epoch: 6| Step: 8
Training loss: 2.8150657818224336
Validation loss: 2.594654886617976

Epoch: 6| Step: 9
Training loss: 3.1174389730566374
Validation loss: 2.6012191341390762

Epoch: 6| Step: 10
Training loss: 2.9189872955641722
Validation loss: 2.606427423133333

Epoch: 6| Step: 11
Training loss: 1.9556846020967742
Validation loss: 2.6039329794762947

Epoch: 6| Step: 12
Training loss: 2.932082354504005
Validation loss: 2.6050484845628294

Epoch: 6| Step: 13
Training loss: 2.6798213113456253
Validation loss: 2.5994459378681554

Epoch: 74| Step: 0
Training loss: 2.9005691627498744
Validation loss: 2.596058405028178

Epoch: 6| Step: 1
Training loss: 3.4937407519059454
Validation loss: 2.594630129997533

Epoch: 6| Step: 2
Training loss: 2.901480257494672
Validation loss: 2.589515559446974

Epoch: 6| Step: 3
Training loss: 2.6729343388945237
Validation loss: 2.5915126567886673

Epoch: 6| Step: 4
Training loss: 3.180995662692248
Validation loss: 2.5901362912285415

Epoch: 6| Step: 5
Training loss: 2.6623590566375452
Validation loss: 2.5853360365787097

Epoch: 6| Step: 6
Training loss: 2.6040674012656573
Validation loss: 2.5890108646721

Epoch: 6| Step: 7
Training loss: 3.029819741001743
Validation loss: 2.5968021661246317

Epoch: 6| Step: 8
Training loss: 3.088653373735217
Validation loss: 2.6149216515434555

Epoch: 6| Step: 9
Training loss: 2.567510219356773
Validation loss: 2.624386517960328

Epoch: 6| Step: 10
Training loss: 2.9673285042523414
Validation loss: 2.6537720869996506

Epoch: 6| Step: 11
Training loss: 3.163948565657009
Validation loss: 2.644446402782231

Epoch: 6| Step: 12
Training loss: 2.5254202691246395
Validation loss: 2.630573393493228

Epoch: 6| Step: 13
Training loss: 3.396653963563754
Validation loss: 2.6031713635444302

Epoch: 75| Step: 0
Training loss: 3.2289022686091773
Validation loss: 2.594427636755033

Epoch: 6| Step: 1
Training loss: 2.450781218869541
Validation loss: 2.5945995969022233

Epoch: 6| Step: 2
Training loss: 3.2522136778596695
Validation loss: 2.5935218800663216

Epoch: 6| Step: 3
Training loss: 3.0794166914245023
Validation loss: 2.58879435217427

Epoch: 6| Step: 4
Training loss: 2.7756203241615967
Validation loss: 2.587265343409357

Epoch: 6| Step: 5
Training loss: 2.6543184325835387
Validation loss: 2.604512564708684

Epoch: 6| Step: 6
Training loss: 2.938478022962
Validation loss: 2.6158744906397065

Epoch: 6| Step: 7
Training loss: 2.9529862951573627
Validation loss: 2.6268097400703323

Epoch: 6| Step: 8
Training loss: 2.739714286971738
Validation loss: 2.6105581264702016

Epoch: 6| Step: 9
Training loss: 3.1266298240112285
Validation loss: 2.5853060402540473

Epoch: 6| Step: 10
Training loss: 2.7484070759401935
Validation loss: 2.590364781560298

Epoch: 6| Step: 11
Training loss: 2.8537640995407516
Validation loss: 2.5773458795761526

Epoch: 6| Step: 12
Training loss: 3.232697572504406
Validation loss: 2.576072138577931

Epoch: 6| Step: 13
Training loss: 2.689617919305522
Validation loss: 2.5764339067806463

Epoch: 76| Step: 0
Training loss: 3.2303869751401724
Validation loss: 2.5862943485296372

Epoch: 6| Step: 1
Training loss: 2.8721767329293413
Validation loss: 2.589296442637335

Epoch: 6| Step: 2
Training loss: 3.310406581190305
Validation loss: 2.587948592022984

Epoch: 6| Step: 3
Training loss: 2.814972786509284
Validation loss: 2.591702687720399

Epoch: 6| Step: 4
Training loss: 2.889945615368919
Validation loss: 2.5865042075128355

Epoch: 6| Step: 5
Training loss: 3.439709733426926
Validation loss: 2.588499057515072

Epoch: 6| Step: 6
Training loss: 2.875718400180844
Validation loss: 2.5835324702550153

Epoch: 6| Step: 7
Training loss: 3.8062432650802482
Validation loss: 2.582843625602143

Epoch: 6| Step: 8
Training loss: 2.4023100067498104
Validation loss: 2.589067769896636

Epoch: 6| Step: 9
Training loss: 2.7976896495471233
Validation loss: 2.58375915632722

Epoch: 6| Step: 10
Training loss: 2.44444693459278
Validation loss: 2.598125859977617

Epoch: 6| Step: 11
Training loss: 2.354387379880336
Validation loss: 2.6082728667256534

Epoch: 6| Step: 12
Training loss: 2.978125935061009
Validation loss: 2.629978577236373

Epoch: 6| Step: 13
Training loss: 2.4955133231894036
Validation loss: 2.65091142738036

Epoch: 77| Step: 0
Training loss: 2.346874951236892
Validation loss: 2.663597770084427

Epoch: 6| Step: 1
Training loss: 3.3772122232423993
Validation loss: 2.654714137673295

Epoch: 6| Step: 2
Training loss: 2.5146206574618444
Validation loss: 2.6509598887141217

Epoch: 6| Step: 3
Training loss: 3.251364934841083
Validation loss: 2.629878016421875

Epoch: 6| Step: 4
Training loss: 2.9493898051594196
Validation loss: 2.6158657291392045

Epoch: 6| Step: 5
Training loss: 2.8321676287205975
Validation loss: 2.590976566139591

Epoch: 6| Step: 6
Training loss: 3.4809961743507745
Validation loss: 2.5790774259502407

Epoch: 6| Step: 7
Training loss: 2.759337870606167
Validation loss: 2.5814034835042747

Epoch: 6| Step: 8
Training loss: 3.2164677797278403
Validation loss: 2.5820895332349987

Epoch: 6| Step: 9
Training loss: 2.62632627134039
Validation loss: 2.583136417718416

Epoch: 6| Step: 10
Training loss: 2.653227219336708
Validation loss: 2.5904871302420363

Epoch: 6| Step: 11
Training loss: 2.505333551673142
Validation loss: 2.593862153331912

Epoch: 6| Step: 12
Training loss: 3.403002669672741
Validation loss: 2.5878884664175543

Epoch: 6| Step: 13
Training loss: 2.696608610467391
Validation loss: 2.582414705553364

Epoch: 78| Step: 0
Training loss: 3.28275693168254
Validation loss: 2.577160909753457

Epoch: 6| Step: 1
Training loss: 2.9245299654472388
Validation loss: 2.577515794578263

Epoch: 6| Step: 2
Training loss: 2.4363034563771353
Validation loss: 2.589352569331247

Epoch: 6| Step: 3
Training loss: 3.2032784774111063
Validation loss: 2.5877761938730317

Epoch: 6| Step: 4
Training loss: 2.9738547356638936
Validation loss: 2.587280290622782

Epoch: 6| Step: 5
Training loss: 3.012496353083892
Validation loss: 2.6090670846008313

Epoch: 6| Step: 6
Training loss: 3.126240140890982
Validation loss: 2.6102256417520446

Epoch: 6| Step: 7
Training loss: 2.9667899638353505
Validation loss: 2.602932981751856

Epoch: 6| Step: 8
Training loss: 3.106927416368309
Validation loss: 2.6068524217406823

Epoch: 6| Step: 9
Training loss: 2.620150764582887
Validation loss: 2.6093414728915083

Epoch: 6| Step: 10
Training loss: 2.649176840421139
Validation loss: 2.6072008107509395

Epoch: 6| Step: 11
Training loss: 3.077516757104466
Validation loss: 2.6128710539440076

Epoch: 6| Step: 12
Training loss: 2.9904963642067006
Validation loss: 2.609489854958802

Epoch: 6| Step: 13
Training loss: 2.4810598074712975
Validation loss: 2.609459786047428

Epoch: 79| Step: 0
Training loss: 2.712405903673969
Validation loss: 2.6119968357804777

Epoch: 6| Step: 1
Training loss: 2.5717880512432547
Validation loss: 2.6162893807341376

Epoch: 6| Step: 2
Training loss: 3.170102380489186
Validation loss: 2.615460525700634

Epoch: 6| Step: 3
Training loss: 2.8825536265351723
Validation loss: 2.622770144628684

Epoch: 6| Step: 4
Training loss: 2.828687411706096
Validation loss: 2.629800483485994

Epoch: 6| Step: 5
Training loss: 2.7881068026802445
Validation loss: 2.6287670378086805

Epoch: 6| Step: 6
Training loss: 2.652237138585921
Validation loss: 2.637184156075417

Epoch: 6| Step: 7
Training loss: 3.1875007479797683
Validation loss: 2.645034022699877

Epoch: 6| Step: 8
Training loss: 2.940981323836614
Validation loss: 2.650986088208571

Epoch: 6| Step: 9
Training loss: 3.0913104061976404
Validation loss: 2.653894191201137

Epoch: 6| Step: 10
Training loss: 3.3880222720300237
Validation loss: 2.6680160448844235

Epoch: 6| Step: 11
Training loss: 2.9626527513485685
Validation loss: 2.665723553771297

Epoch: 6| Step: 12
Training loss: 2.9705085765931196
Validation loss: 2.6739239898533875

Epoch: 6| Step: 13
Training loss: 3.2432838884160873
Validation loss: 2.6579789771231632

Epoch: 80| Step: 0
Training loss: 2.9303202441710083
Validation loss: 2.6501299331891928

Epoch: 6| Step: 1
Training loss: 3.3182136633878105
Validation loss: 2.692004139901702

Epoch: 6| Step: 2
Training loss: 2.8094852820488003
Validation loss: 2.731764521598807

Epoch: 6| Step: 3
Training loss: 2.8235846054184917
Validation loss: 2.7245545093770795

Epoch: 6| Step: 4
Training loss: 3.194383257588592
Validation loss: 2.692882462155305

Epoch: 6| Step: 5
Training loss: 3.5856255289642225
Validation loss: 2.671713453253483

Epoch: 6| Step: 6
Training loss: 2.8615949174361806
Validation loss: 2.6185371280100935

Epoch: 6| Step: 7
Training loss: 2.417260382058414
Validation loss: 2.6255386989313005

Epoch: 6| Step: 8
Training loss: 2.4425551983971205
Validation loss: 2.6338162776718055

Epoch: 6| Step: 9
Training loss: 3.6840167647155297
Validation loss: 2.649971793456675

Epoch: 6| Step: 10
Training loss: 3.248516184196535
Validation loss: 2.649412257877808

Epoch: 6| Step: 11
Training loss: 2.5826823326952564
Validation loss: 2.6414444077953845

Epoch: 6| Step: 12
Training loss: 2.8554847810767505
Validation loss: 2.633229371136186

Epoch: 6| Step: 13
Training loss: 2.5941511096808525
Validation loss: 2.6185823061895306

Epoch: 81| Step: 0
Training loss: 2.7052583599985494
Validation loss: 2.6188110125560513

Epoch: 6| Step: 1
Training loss: 3.4239932954490833
Validation loss: 2.617522440210421

Epoch: 6| Step: 2
Training loss: 2.7390083512188994
Validation loss: 2.6158561600574775

Epoch: 6| Step: 3
Training loss: 2.8822326904115925
Validation loss: 2.61552631797101

Epoch: 6| Step: 4
Training loss: 2.715235927440302
Validation loss: 2.618997399669434

Epoch: 6| Step: 5
Training loss: 2.5411177078841245
Validation loss: 2.6216223814684527

Epoch: 6| Step: 6
Training loss: 2.4048154443682717
Validation loss: 2.6231850953479396

Epoch: 6| Step: 7
Training loss: 3.516412943384682
Validation loss: 2.6254762050588005

Epoch: 6| Step: 8
Training loss: 3.0684289954705064
Validation loss: 2.642732485415388

Epoch: 6| Step: 9
Training loss: 3.4046671978370138
Validation loss: 2.6476284016545435

Epoch: 6| Step: 10
Training loss: 3.2861187372005394
Validation loss: 2.657731752710594

Epoch: 6| Step: 11
Training loss: 2.946569847253938
Validation loss: 2.6422312327481996

Epoch: 6| Step: 12
Training loss: 2.9298115208124482
Validation loss: 2.637006046347203

Epoch: 6| Step: 13
Training loss: 2.5813163656427145
Validation loss: 2.623308381866257

Epoch: 82| Step: 0
Training loss: 2.69415736116485
Validation loss: 2.6117217988603385

Epoch: 6| Step: 1
Training loss: 2.419883155051157
Validation loss: 2.602785095604262

Epoch: 6| Step: 2
Training loss: 3.5840266835888315
Validation loss: 2.5982902049963954

Epoch: 6| Step: 3
Training loss: 3.290783791908531
Validation loss: 2.5951656279275306

Epoch: 6| Step: 4
Training loss: 2.536909581541004
Validation loss: 2.595539805374912

Epoch: 6| Step: 5
Training loss: 2.57642229669189
Validation loss: 2.5964973706352166

Epoch: 6| Step: 6
Training loss: 2.237963375933906
Validation loss: 2.5990578398949125

Epoch: 6| Step: 7
Training loss: 2.9936147129653503
Validation loss: 2.599877577992467

Epoch: 6| Step: 8
Training loss: 3.6412130380280776
Validation loss: 2.613620106221219

Epoch: 6| Step: 9
Training loss: 2.695392994438884
Validation loss: 2.6197144696717576

Epoch: 6| Step: 10
Training loss: 3.4720017596297486
Validation loss: 2.6399999709982325

Epoch: 6| Step: 11
Training loss: 3.046946676340417
Validation loss: 2.635076772715517

Epoch: 6| Step: 12
Training loss: 2.579467423938924
Validation loss: 2.618998703515125

Epoch: 6| Step: 13
Training loss: 3.1043785244802855
Validation loss: 2.5988368730725853

Epoch: 83| Step: 0
Training loss: 2.776255291036745
Validation loss: 2.569988251350368

Epoch: 6| Step: 1
Training loss: 3.0944123763183073
Validation loss: 2.573961145985248

Epoch: 6| Step: 2
Training loss: 2.435024765327361
Validation loss: 2.574748842423921

Epoch: 6| Step: 3
Training loss: 2.7282749689749837
Validation loss: 2.5919563258071343

Epoch: 6| Step: 4
Training loss: 3.0649398115760746
Validation loss: 2.621022759957344

Epoch: 6| Step: 5
Training loss: 2.8040913662901445
Validation loss: 2.6000452908924645

Epoch: 6| Step: 6
Training loss: 2.8297471931686924
Validation loss: 2.583864822916545

Epoch: 6| Step: 7
Training loss: 3.1313470090659905
Validation loss: 2.563274945668472

Epoch: 6| Step: 8
Training loss: 2.504696630507668
Validation loss: 2.5534569069827677

Epoch: 6| Step: 9
Training loss: 2.8603120529556216
Validation loss: 2.5634262867893747

Epoch: 6| Step: 10
Training loss: 2.5920306102511135
Validation loss: 2.5598505160695733

Epoch: 6| Step: 11
Training loss: 3.2132150410871283
Validation loss: 2.559326895467664

Epoch: 6| Step: 12
Training loss: 3.147295799266967
Validation loss: 2.558993637045633

Epoch: 6| Step: 13
Training loss: 3.9372629972307913
Validation loss: 2.562348027878909

Epoch: 84| Step: 0
Training loss: 2.8246760967542293
Validation loss: 2.560880667084687

Epoch: 6| Step: 1
Training loss: 3.269443159842277
Validation loss: 2.5564972515101254

Epoch: 6| Step: 2
Training loss: 2.671702061460522
Validation loss: 2.5531850235441045

Epoch: 6| Step: 3
Training loss: 3.074674424714455
Validation loss: 2.5567548804279414

Epoch: 6| Step: 4
Training loss: 2.384126294765462
Validation loss: 2.5495194009371

Epoch: 6| Step: 5
Training loss: 3.678145747746084
Validation loss: 2.5581442176199998

Epoch: 6| Step: 6
Training loss: 3.1058957364181574
Validation loss: 2.5628897497838

Epoch: 6| Step: 7
Training loss: 2.190206542704827
Validation loss: 2.5747666417380355

Epoch: 6| Step: 8
Training loss: 2.5954327008306373
Validation loss: 2.627646296502953

Epoch: 6| Step: 9
Training loss: 2.557764376104299
Validation loss: 2.7038524814583633

Epoch: 6| Step: 10
Training loss: 3.095146403509093
Validation loss: 2.7773635217646406

Epoch: 6| Step: 11
Training loss: 2.6065576385500275
Validation loss: 2.8288301757985734

Epoch: 6| Step: 12
Training loss: 3.350450593621379
Validation loss: 2.7923753668694675

Epoch: 6| Step: 13
Training loss: 3.4808826136249444
Validation loss: 2.631358649392095

Epoch: 85| Step: 0
Training loss: 2.8891109316012176
Validation loss: 2.5596962613766774

Epoch: 6| Step: 1
Training loss: 3.1786222805896793
Validation loss: 2.5487928952029857

Epoch: 6| Step: 2
Training loss: 2.7473316251414204
Validation loss: 2.5519431056627595

Epoch: 6| Step: 3
Training loss: 3.072423311274361
Validation loss: 2.5608012753837253

Epoch: 6| Step: 4
Training loss: 2.7358827630127793
Validation loss: 2.5751831313730564

Epoch: 6| Step: 5
Training loss: 2.589335902437035
Validation loss: 2.586933540598528

Epoch: 6| Step: 6
Training loss: 2.4563466681563084
Validation loss: 2.569474925461172

Epoch: 6| Step: 7
Training loss: 2.417998527873485
Validation loss: 2.559034055992651

Epoch: 6| Step: 8
Training loss: 3.326773355591369
Validation loss: 2.5542679223521234

Epoch: 6| Step: 9
Training loss: 2.9935645378499776
Validation loss: 2.5448118331532092

Epoch: 6| Step: 10
Training loss: 2.753125495347705
Validation loss: 2.5467070078649106

Epoch: 6| Step: 11
Training loss: 3.7940484974304813
Validation loss: 2.5441355146839295

Epoch: 6| Step: 12
Training loss: 2.913496929030259
Validation loss: 2.5377585794524733

Epoch: 6| Step: 13
Training loss: 2.902481096388498
Validation loss: 2.5416317857849955

Epoch: 86| Step: 0
Training loss: 3.005085449527178
Validation loss: 2.54090973429117

Epoch: 6| Step: 1
Training loss: 2.865174296138617
Validation loss: 2.550609135887016

Epoch: 6| Step: 2
Training loss: 2.7028785549123326
Validation loss: 2.5694490936186978

Epoch: 6| Step: 3
Training loss: 3.081628035747989
Validation loss: 2.629056277191473

Epoch: 6| Step: 4
Training loss: 2.751615916507524
Validation loss: 2.6795692787292498

Epoch: 6| Step: 5
Training loss: 3.0419972035472287
Validation loss: 2.652334644053651

Epoch: 6| Step: 6
Training loss: 2.745719178701379
Validation loss: 2.6545882024376284

Epoch: 6| Step: 7
Training loss: 2.9777401974743842
Validation loss: 2.6538487486150344

Epoch: 6| Step: 8
Training loss: 3.1598158229802333
Validation loss: 2.594144342213103

Epoch: 6| Step: 9
Training loss: 3.4277745779782665
Validation loss: 2.541059078120476

Epoch: 6| Step: 10
Training loss: 3.1156310973877774
Validation loss: 2.531701885578083

Epoch: 6| Step: 11
Training loss: 2.7739963881751697
Validation loss: 2.535108221914279

Epoch: 6| Step: 12
Training loss: 2.5720027479332086
Validation loss: 2.5358392709988724

Epoch: 6| Step: 13
Training loss: 2.5247421435139374
Validation loss: 2.5384307312620424

Epoch: 87| Step: 0
Training loss: 3.39196441493172
Validation loss: 2.5438525295101173

Epoch: 6| Step: 1
Training loss: 3.5813549405845295
Validation loss: 2.5458570306007124

Epoch: 6| Step: 2
Training loss: 3.025840888308548
Validation loss: 2.5387304944985916

Epoch: 6| Step: 3
Training loss: 2.0842541249241138
Validation loss: 2.5425882934624897

Epoch: 6| Step: 4
Training loss: 2.3667245544374507
Validation loss: 2.5405388872984274

Epoch: 6| Step: 5
Training loss: 3.1671456091904666
Validation loss: 2.535333687350296

Epoch: 6| Step: 6
Training loss: 2.625577045775504
Validation loss: 2.5456356453240634

Epoch: 6| Step: 7
Training loss: 3.3140863902423767
Validation loss: 2.5582846368316594

Epoch: 6| Step: 8
Training loss: 2.678352668548405
Validation loss: 2.554913003620115

Epoch: 6| Step: 9
Training loss: 2.8638324285105905
Validation loss: 2.627990039331763

Epoch: 6| Step: 10
Training loss: 3.155399170061423
Validation loss: 2.7088132567156427

Epoch: 6| Step: 11
Training loss: 2.206982421334854
Validation loss: 2.7225874655862237

Epoch: 6| Step: 12
Training loss: 3.1935443789586544
Validation loss: 2.7284944112298644

Epoch: 6| Step: 13
Training loss: 2.2735202420308624
Validation loss: 2.6759668161172967

Epoch: 88| Step: 0
Training loss: 2.751687312504075
Validation loss: 2.706323616015368

Epoch: 6| Step: 1
Training loss: 3.4944883272710463
Validation loss: 2.683423901604421

Epoch: 6| Step: 2
Training loss: 2.755510963784994
Validation loss: 2.6022976875480004

Epoch: 6| Step: 3
Training loss: 2.586753048175429
Validation loss: 2.576570904464067

Epoch: 6| Step: 4
Training loss: 2.505890772467467
Validation loss: 2.5614865627815946

Epoch: 6| Step: 5
Training loss: 3.3539415998748536
Validation loss: 2.544523021692968

Epoch: 6| Step: 6
Training loss: 2.9390692881658387
Validation loss: 2.552711964563389

Epoch: 6| Step: 7
Training loss: 2.788250631355071
Validation loss: 2.559074954155913

Epoch: 6| Step: 8
Training loss: 3.3133667585604525
Validation loss: 2.5605117093214367

Epoch: 6| Step: 9
Training loss: 3.301751746888838
Validation loss: 2.561620988206855

Epoch: 6| Step: 10
Training loss: 3.031237100790048
Validation loss: 2.558801153913935

Epoch: 6| Step: 11
Training loss: 2.8801876203034786
Validation loss: 2.5427422576768066

Epoch: 6| Step: 12
Training loss: 2.771278938276577
Validation loss: 2.54341748106537

Epoch: 6| Step: 13
Training loss: 2.2915781408608757
Validation loss: 2.556733910017152

Epoch: 89| Step: 0
Training loss: 2.9854972287204946
Validation loss: 2.5551734410217604

Epoch: 6| Step: 1
Training loss: 3.189864534473371
Validation loss: 2.560357924013736

Epoch: 6| Step: 2
Training loss: 2.4739468115822714
Validation loss: 2.5702440931159747

Epoch: 6| Step: 3
Training loss: 3.3330717619945522
Validation loss: 2.588362561420013

Epoch: 6| Step: 4
Training loss: 3.2827779936032293
Validation loss: 2.622878510906581

Epoch: 6| Step: 5
Training loss: 3.0475882453440426
Validation loss: 2.657385368359475

Epoch: 6| Step: 6
Training loss: 2.7097752962878805
Validation loss: 2.6655511124989935

Epoch: 6| Step: 7
Training loss: 3.3218482202148447
Validation loss: 2.6776969646584314

Epoch: 6| Step: 8
Training loss: 2.633272396863409
Validation loss: 2.6369310980956557

Epoch: 6| Step: 9
Training loss: 2.6521945287782804
Validation loss: 2.6097505056230523

Epoch: 6| Step: 10
Training loss: 2.6160523643152396
Validation loss: 2.571279630621941

Epoch: 6| Step: 11
Training loss: 2.1819752271803656
Validation loss: 2.549220653950057

Epoch: 6| Step: 12
Training loss: 3.4524658402528465
Validation loss: 2.540444936961759

Epoch: 6| Step: 13
Training loss: 2.7662594169942514
Validation loss: 2.5315091947250616

Epoch: 90| Step: 0
Training loss: 2.3809739320778744
Validation loss: 2.5320105656408565

Epoch: 6| Step: 1
Training loss: 2.9574314587374433
Validation loss: 2.5286757397274275

Epoch: 6| Step: 2
Training loss: 2.923542057126943
Validation loss: 2.5329165100656086

Epoch: 6| Step: 3
Training loss: 3.0921154906305586
Validation loss: 2.550310871398129

Epoch: 6| Step: 4
Training loss: 2.7176412316535004
Validation loss: 2.5611088756125353

Epoch: 6| Step: 5
Training loss: 3.1524806412443533
Validation loss: 2.5366308237813957

Epoch: 6| Step: 6
Training loss: 2.591707827454828
Validation loss: 2.531077411601008

Epoch: 6| Step: 7
Training loss: 3.049554673499893
Validation loss: 2.523108009744232

Epoch: 6| Step: 8
Training loss: 2.9145168737687746
Validation loss: 2.5155868277700995

Epoch: 6| Step: 9
Training loss: 3.169247596089233
Validation loss: 2.5135020778040857

Epoch: 6| Step: 10
Training loss: 3.4453404570329713
Validation loss: 2.518217649971259

Epoch: 6| Step: 11
Training loss: 2.3866236491384547
Validation loss: 2.523459732555601

Epoch: 6| Step: 12
Training loss: 2.9185215274499803
Validation loss: 2.5409381046845048

Epoch: 6| Step: 13
Training loss: 2.705276074379626
Validation loss: 2.555309840894763

Epoch: 91| Step: 0
Training loss: 3.104067619501545
Validation loss: 2.552939876007567

Epoch: 6| Step: 1
Training loss: 2.946435203379644
Validation loss: 2.5415257664167155

Epoch: 6| Step: 2
Training loss: 2.6473225184847085
Validation loss: 2.5225545210217706

Epoch: 6| Step: 3
Training loss: 3.336896200246676
Validation loss: 2.531872335436866

Epoch: 6| Step: 4
Training loss: 2.657291701758093
Validation loss: 2.5272978294298687

Epoch: 6| Step: 5
Training loss: 2.7844458231711555
Validation loss: 2.515495057961065

Epoch: 6| Step: 6
Training loss: 3.2262530236154285
Validation loss: 2.5221673142214414

Epoch: 6| Step: 7
Training loss: 2.983650479073314
Validation loss: 2.5196658727520855

Epoch: 6| Step: 8
Training loss: 2.4183535662522613
Validation loss: 2.524407749902415

Epoch: 6| Step: 9
Training loss: 2.9230739153333007
Validation loss: 2.5159376069027997

Epoch: 6| Step: 10
Training loss: 3.0308532455191597
Validation loss: 2.5166140068046685

Epoch: 6| Step: 11
Training loss: 2.375768637506085
Validation loss: 2.5162921230616973

Epoch: 6| Step: 12
Training loss: 3.105900495734578
Validation loss: 2.516690744305083

Epoch: 6| Step: 13
Training loss: 2.283737603014542
Validation loss: 2.5205616466858984

Epoch: 92| Step: 0
Training loss: 2.1568192546033123
Validation loss: 2.524556181135026

Epoch: 6| Step: 1
Training loss: 2.8225018148357277
Validation loss: 2.5320535982134165

Epoch: 6| Step: 2
Training loss: 3.298849807044643
Validation loss: 2.534021750650024

Epoch: 6| Step: 3
Training loss: 2.7225500274909846
Validation loss: 2.5313675140525205

Epoch: 6| Step: 4
Training loss: 2.403176264222287
Validation loss: 2.539364930624131

Epoch: 6| Step: 5
Training loss: 2.7535476342855927
Validation loss: 2.5470191124123303

Epoch: 6| Step: 6
Training loss: 3.129895457511508
Validation loss: 2.5397874769905675

Epoch: 6| Step: 7
Training loss: 3.255903897041124
Validation loss: 2.514824112704293

Epoch: 6| Step: 8
Training loss: 2.7451580075784827
Validation loss: 2.5204975864276555

Epoch: 6| Step: 9
Training loss: 2.753433251850097
Validation loss: 2.5127576260535713

Epoch: 6| Step: 10
Training loss: 2.9542532889754667
Validation loss: 2.5126811785883274

Epoch: 6| Step: 11
Training loss: 3.2461984849322847
Validation loss: 2.5108072461009487

Epoch: 6| Step: 12
Training loss: 2.993750420492696
Validation loss: 2.512656133628051

Epoch: 6| Step: 13
Training loss: 2.747365556643501
Validation loss: 2.5075325881066766

Epoch: 93| Step: 0
Training loss: 3.0827261524510834
Validation loss: 2.515763409602443

Epoch: 6| Step: 1
Training loss: 2.8563321291678774
Validation loss: 2.5141049914277454

Epoch: 6| Step: 2
Training loss: 2.9347196366438695
Validation loss: 2.5185921510866742

Epoch: 6| Step: 3
Training loss: 2.063812185236679
Validation loss: 2.5270701983695267

Epoch: 6| Step: 4
Training loss: 2.36358983570934
Validation loss: 2.5394915111190786

Epoch: 6| Step: 5
Training loss: 2.1230110509353923
Validation loss: 2.549984408151378

Epoch: 6| Step: 6
Training loss: 2.4205036834014244
Validation loss: 2.550554115617533

Epoch: 6| Step: 7
Training loss: 3.231515551046108
Validation loss: 2.5665611831788855

Epoch: 6| Step: 8
Training loss: 3.3324136100955415
Validation loss: 2.5741658786131416

Epoch: 6| Step: 9
Training loss: 3.241937760995265
Validation loss: 2.5495011754815162

Epoch: 6| Step: 10
Training loss: 3.1702300819148492
Validation loss: 2.5408036898390005

Epoch: 6| Step: 11
Training loss: 2.9981380088449177
Validation loss: 2.524663094878793

Epoch: 6| Step: 12
Training loss: 3.126052984216972
Validation loss: 2.5260361226846344

Epoch: 6| Step: 13
Training loss: 2.9429601690958656
Validation loss: 2.526384958820322

Epoch: 94| Step: 0
Training loss: 2.330091733804821
Validation loss: 2.5317193774382454

Epoch: 6| Step: 1
Training loss: 2.4917016587197782
Validation loss: 2.5470352308666575

Epoch: 6| Step: 2
Training loss: 2.3220695239558338
Validation loss: 2.546703487610138

Epoch: 6| Step: 3
Training loss: 2.7824125110619145
Validation loss: 2.5779547303554597

Epoch: 6| Step: 4
Training loss: 2.669415060969484
Validation loss: 2.5947239106541056

Epoch: 6| Step: 5
Training loss: 3.1865577052919147
Validation loss: 2.6150879104423055

Epoch: 6| Step: 6
Training loss: 2.9322970149170438
Validation loss: 2.5890844078215633

Epoch: 6| Step: 7
Training loss: 2.8677470729182093
Validation loss: 2.554897444603945

Epoch: 6| Step: 8
Training loss: 3.2438131278479094
Validation loss: 2.5386686069081033

Epoch: 6| Step: 9
Training loss: 2.7542100238320963
Validation loss: 2.5438542533151614

Epoch: 6| Step: 10
Training loss: 3.4687241561889173
Validation loss: 2.5452468240643573

Epoch: 6| Step: 11
Training loss: 3.1900806825772507
Validation loss: 2.544817748592661

Epoch: 6| Step: 12
Training loss: 2.8923047932767934
Validation loss: 2.54496030934534

Epoch: 6| Step: 13
Training loss: 2.462294915658656
Validation loss: 2.5398671399697

Epoch: 95| Step: 0
Training loss: 3.3938486271080426
Validation loss: 2.5356254947926797

Epoch: 6| Step: 1
Training loss: 3.3661447844438994
Validation loss: 2.5220439454535954

Epoch: 6| Step: 2
Training loss: 2.957151221559014
Validation loss: 2.5240118476095312

Epoch: 6| Step: 3
Training loss: 2.8377886318668684
Validation loss: 2.5278607101731145

Epoch: 6| Step: 4
Training loss: 2.4012075326908477
Validation loss: 2.55048994022055

Epoch: 6| Step: 5
Training loss: 2.468702581408972
Validation loss: 2.562532281159551

Epoch: 6| Step: 6
Training loss: 2.1626102794245217
Validation loss: 2.528268097582028

Epoch: 6| Step: 7
Training loss: 2.607162634145597
Validation loss: 2.5128491836491507

Epoch: 6| Step: 8
Training loss: 3.122810512279839
Validation loss: 2.507278389083575

Epoch: 6| Step: 9
Training loss: 2.5602845640275236
Validation loss: 2.520884705964742

Epoch: 6| Step: 10
Training loss: 2.6038227515420003
Validation loss: 2.5347106664370487

Epoch: 6| Step: 11
Training loss: 3.6947454618295374
Validation loss: 2.547457449926789

Epoch: 6| Step: 12
Training loss: 2.663541144315161
Validation loss: 2.5203868179314584

Epoch: 6| Step: 13
Training loss: 2.7717386549797203
Validation loss: 2.511848718991375

Epoch: 96| Step: 0
Training loss: 2.838218591252005
Validation loss: 2.51220391829374

Epoch: 6| Step: 1
Training loss: 2.968051547155518
Validation loss: 2.5096707780326617

Epoch: 6| Step: 2
Training loss: 2.3532534378076897
Validation loss: 2.5145231399517853

Epoch: 6| Step: 3
Training loss: 3.0243812684894644
Validation loss: 2.5133834448887473

Epoch: 6| Step: 4
Training loss: 2.8103139222755598
Validation loss: 2.504949855221084

Epoch: 6| Step: 5
Training loss: 3.0887781130948193
Validation loss: 2.5053480667611816

Epoch: 6| Step: 6
Training loss: 2.9203488857396676
Validation loss: 2.5105926771265192

Epoch: 6| Step: 7
Training loss: 2.8809580226754377
Validation loss: 2.5123588904610834

Epoch: 6| Step: 8
Training loss: 3.1303696847334415
Validation loss: 2.509661683559342

Epoch: 6| Step: 9
Training loss: 2.7932630690642166
Validation loss: 2.5115620229882762

Epoch: 6| Step: 10
Training loss: 2.74123894351342
Validation loss: 2.5129725375989533

Epoch: 6| Step: 11
Training loss: 2.842547655066786
Validation loss: 2.517376956081253

Epoch: 6| Step: 12
Training loss: 2.7492745049371323
Validation loss: 2.5116673035289483

Epoch: 6| Step: 13
Training loss: 3.269756277491761
Validation loss: 2.5156884720115253

Epoch: 97| Step: 0
Training loss: 2.868136963344486
Validation loss: 2.5091576502958026

Epoch: 6| Step: 1
Training loss: 2.4464461651150535
Validation loss: 2.515420054282919

Epoch: 6| Step: 2
Training loss: 2.6499178639764542
Validation loss: 2.5136624196859354

Epoch: 6| Step: 3
Training loss: 2.8999637996124195
Validation loss: 2.516299245599718

Epoch: 6| Step: 4
Training loss: 2.5164280906755057
Validation loss: 2.5410289798261503

Epoch: 6| Step: 5
Training loss: 3.046007551297842
Validation loss: 2.5737969537200738

Epoch: 6| Step: 6
Training loss: 2.9086782504135296
Validation loss: 2.647687014753113

Epoch: 6| Step: 7
Training loss: 3.3059691340487745
Validation loss: 2.703133386678001

Epoch: 6| Step: 8
Training loss: 3.076156683990269
Validation loss: 2.6622650334747098

Epoch: 6| Step: 9
Training loss: 3.255673225266817
Validation loss: 2.6018471338405322

Epoch: 6| Step: 10
Training loss: 2.5402362634005646
Validation loss: 2.5103832377616104

Epoch: 6| Step: 11
Training loss: 2.9132820291024535
Validation loss: 2.510064841586937

Epoch: 6| Step: 12
Training loss: 2.5387137305534635
Validation loss: 2.513060749512042

Epoch: 6| Step: 13
Training loss: 3.196407662069823
Validation loss: 2.517880087767453

Epoch: 98| Step: 0
Training loss: 2.290183876517984
Validation loss: 2.5167384821193397

Epoch: 6| Step: 1
Training loss: 2.9775747745583043
Validation loss: 2.518731621069819

Epoch: 6| Step: 2
Training loss: 3.1079331318499728
Validation loss: 2.519380787767562

Epoch: 6| Step: 3
Training loss: 2.94838887848258
Validation loss: 2.520424879830348

Epoch: 6| Step: 4
Training loss: 3.252563639200743
Validation loss: 2.5216029226451613

Epoch: 6| Step: 5
Training loss: 2.816731808452752
Validation loss: 2.5245037329907007

Epoch: 6| Step: 6
Training loss: 3.119366412509233
Validation loss: 2.526033402786633

Epoch: 6| Step: 7
Training loss: 2.82833625468109
Validation loss: 2.5278800484991053

Epoch: 6| Step: 8
Training loss: 3.1157654695210244
Validation loss: 2.5242362475657023

Epoch: 6| Step: 9
Training loss: 2.2800678691466705
Validation loss: 2.5216159665007134

Epoch: 6| Step: 10
Training loss: 3.0819371817076653
Validation loss: 2.521472575950409

Epoch: 6| Step: 11
Training loss: 3.0392648977630126
Validation loss: 2.5229744241998975

Epoch: 6| Step: 12
Training loss: 2.691934342749888
Validation loss: 2.5204291304808106

Epoch: 6| Step: 13
Training loss: 3.1802420167777044
Validation loss: 2.5135425714410484

Epoch: 99| Step: 0
Training loss: 2.309464395364655
Validation loss: 2.516406725113799

Epoch: 6| Step: 1
Training loss: 2.5493252441159533
Validation loss: 2.5188403453607235

Epoch: 6| Step: 2
Training loss: 3.169600700236228
Validation loss: 2.5185738911567954

Epoch: 6| Step: 3
Training loss: 3.4017350257784496
Validation loss: 2.5174144651996277

Epoch: 6| Step: 4
Training loss: 2.8533077386201318
Validation loss: 2.5230551992359267

Epoch: 6| Step: 5
Training loss: 2.233036840979702
Validation loss: 2.5418966953460504

Epoch: 6| Step: 6
Training loss: 2.626914824593006
Validation loss: 2.55574412485777

Epoch: 6| Step: 7
Training loss: 2.916559126551676
Validation loss: 2.5646779718795085

Epoch: 6| Step: 8
Training loss: 3.3328219657294964
Validation loss: 2.5764888679203075

Epoch: 6| Step: 9
Training loss: 3.4130243254900363
Validation loss: 2.558902400040824

Epoch: 6| Step: 10
Training loss: 3.1549500158252837
Validation loss: 2.5396350623316812

Epoch: 6| Step: 11
Training loss: 2.7278642143061105
Validation loss: 2.5354826862210635

Epoch: 6| Step: 12
Training loss: 2.5643817226350616
Validation loss: 2.511851909444477

Epoch: 6| Step: 13
Training loss: 2.5955780205814065
Validation loss: 2.505554868724113

Epoch: 100| Step: 0
Training loss: 2.8827453440052224
Validation loss: 2.4958278050805607

Epoch: 6| Step: 1
Training loss: 2.6512010048058032
Validation loss: 2.4975258500174875

Epoch: 6| Step: 2
Training loss: 3.009835491817647
Validation loss: 2.499521233235135

Epoch: 6| Step: 3
Training loss: 2.784616383237453
Validation loss: 2.488949804284198

Epoch: 6| Step: 4
Training loss: 3.2450556191025965
Validation loss: 2.5023903186784624

Epoch: 6| Step: 5
Training loss: 3.0665340712809876
Validation loss: 2.513129873373883

Epoch: 6| Step: 6
Training loss: 2.7779488849921976
Validation loss: 2.5180349910853606

Epoch: 6| Step: 7
Training loss: 2.832295583030366
Validation loss: 2.522142055473366

Epoch: 6| Step: 8
Training loss: 3.1047079821881938
Validation loss: 2.5313280377903955

Epoch: 6| Step: 9
Training loss: 2.9679688078379995
Validation loss: 2.5138198081452656

Epoch: 6| Step: 10
Training loss: 2.5697775054982666
Validation loss: 2.494588965250154

Epoch: 6| Step: 11
Training loss: 3.0613098946160324
Validation loss: 2.5028731376899382

Epoch: 6| Step: 12
Training loss: 2.28065378419207
Validation loss: 2.4939923520490854

Epoch: 6| Step: 13
Training loss: 2.5245322105753902
Validation loss: 2.490095847722665

Epoch: 101| Step: 0
Training loss: 2.81700392477773
Validation loss: 2.4942492001612773

Epoch: 6| Step: 1
Training loss: 3.324983788931199
Validation loss: 2.4889316173492886

Epoch: 6| Step: 2
Training loss: 3.108724708224168
Validation loss: 2.4931880621578406

Epoch: 6| Step: 3
Training loss: 2.5939130616924406
Validation loss: 2.499892140184435

Epoch: 6| Step: 4
Training loss: 2.094852669572339
Validation loss: 2.509508235018237

Epoch: 6| Step: 5
Training loss: 3.1450149448446028
Validation loss: 2.538288762259835

Epoch: 6| Step: 6
Training loss: 1.8028350173779166
Validation loss: 2.542322828750314

Epoch: 6| Step: 7
Training loss: 2.9619707302731113
Validation loss: 2.5340891636157767

Epoch: 6| Step: 8
Training loss: 3.1909802454830376
Validation loss: 2.548538624945898

Epoch: 6| Step: 9
Training loss: 2.669011416351154
Validation loss: 2.53793038622588

Epoch: 6| Step: 10
Training loss: 2.2675017903414454
Validation loss: 2.5426090674722617

Epoch: 6| Step: 11
Training loss: 3.076172030009917
Validation loss: 2.5335294162152975

Epoch: 6| Step: 12
Training loss: 2.997494605077831
Validation loss: 2.513749916953442

Epoch: 6| Step: 13
Training loss: 3.4202884148681596
Validation loss: 2.512940615487814

Epoch: 102| Step: 0
Training loss: 2.2975413076113917
Validation loss: 2.518135588683151

Epoch: 6| Step: 1
Training loss: 2.8826828180519946
Validation loss: 2.4947839384395794

Epoch: 6| Step: 2
Training loss: 2.938817317293858
Validation loss: 2.506643709948928

Epoch: 6| Step: 3
Training loss: 3.0910034318285984
Validation loss: 2.5159644227391205

Epoch: 6| Step: 4
Training loss: 3.0313234615272853
Validation loss: 2.506007235323165

Epoch: 6| Step: 5
Training loss: 3.346762895175856
Validation loss: 2.5053076279362263

Epoch: 6| Step: 6
Training loss: 2.562719754356234
Validation loss: 2.5095910054154342

Epoch: 6| Step: 7
Training loss: 2.3029774674221417
Validation loss: 2.510105918700702

Epoch: 6| Step: 8
Training loss: 2.909231154084864
Validation loss: 2.513946372627603

Epoch: 6| Step: 9
Training loss: 2.696187549021676
Validation loss: 2.523048813128405

Epoch: 6| Step: 10
Training loss: 2.9957929358236783
Validation loss: 2.5316518922559776

Epoch: 6| Step: 11
Training loss: 2.6537293984704613
Validation loss: 2.5269281074998124

Epoch: 6| Step: 12
Training loss: 2.839010628041109
Validation loss: 2.5470002611194937

Epoch: 6| Step: 13
Training loss: 2.8098382009983767
Validation loss: 2.556577140870802

Epoch: 103| Step: 0
Training loss: 2.8714586090978584
Validation loss: 2.5601570529311823

Epoch: 6| Step: 1
Training loss: 3.3939773230528476
Validation loss: 2.6195957300816177

Epoch: 6| Step: 2
Training loss: 2.555792799824024
Validation loss: 2.6769271721406964

Epoch: 6| Step: 3
Training loss: 2.6024727360216167
Validation loss: 2.810514515376481

Epoch: 6| Step: 4
Training loss: 3.588324390287428
Validation loss: 2.926910760234449

Epoch: 6| Step: 5
Training loss: 2.9839884722387273
Validation loss: 2.7306478508142313

Epoch: 6| Step: 6
Training loss: 3.0435005477420973
Validation loss: 2.5448195306765444

Epoch: 6| Step: 7
Training loss: 2.6312222078355214
Validation loss: 2.4904626028252794

Epoch: 6| Step: 8
Training loss: 2.3520124138095775
Validation loss: 2.501811358837061

Epoch: 6| Step: 9
Training loss: 2.6899718516412157
Validation loss: 2.517128442844872

Epoch: 6| Step: 10
Training loss: 3.356090838815867
Validation loss: 2.540806545273661

Epoch: 6| Step: 11
Training loss: 3.2017018203619134
Validation loss: 2.564998385206132

Epoch: 6| Step: 12
Training loss: 2.433228295380227
Validation loss: 2.5470036450822766

Epoch: 6| Step: 13
Training loss: 3.4038295720578073
Validation loss: 2.5457290415643405

Epoch: 104| Step: 0
Training loss: 3.043152868457045
Validation loss: 2.5235920469543895

Epoch: 6| Step: 1
Training loss: 3.114396377787136
Validation loss: 2.5150763299872185

Epoch: 6| Step: 2
Training loss: 2.6454434645759446
Validation loss: 2.5123992203828114

Epoch: 6| Step: 3
Training loss: 2.843583322188659
Validation loss: 2.5067266444746927

Epoch: 6| Step: 4
Training loss: 2.947281965712239
Validation loss: 2.504828710938663

Epoch: 6| Step: 5
Training loss: 2.738907202383652
Validation loss: 2.498016554022834

Epoch: 6| Step: 6
Training loss: 2.9733456026630973
Validation loss: 2.4959764794701296

Epoch: 6| Step: 7
Training loss: 2.6875507438659634
Validation loss: 2.503742891441555

Epoch: 6| Step: 8
Training loss: 3.32971282476768
Validation loss: 2.512331155005299

Epoch: 6| Step: 9
Training loss: 2.54289365033476
Validation loss: 2.5203135486836055

Epoch: 6| Step: 10
Training loss: 3.128072220302736
Validation loss: 2.5586747782349066

Epoch: 6| Step: 11
Training loss: 2.7042251729489433
Validation loss: 2.5912525890659084

Epoch: 6| Step: 12
Training loss: 2.359176526342675
Validation loss: 2.57853784422132

Epoch: 6| Step: 13
Training loss: 3.510005953313664
Validation loss: 2.573027421861595

Epoch: 105| Step: 0
Training loss: 2.1083631561140224
Validation loss: 2.5717442121917653

Epoch: 6| Step: 1
Training loss: 2.4487976004164116
Validation loss: 2.5789138656003594

Epoch: 6| Step: 2
Training loss: 2.3548842380200132
Validation loss: 2.561023385760395

Epoch: 6| Step: 3
Training loss: 2.777921163249111
Validation loss: 2.5658884702843654

Epoch: 6| Step: 4
Training loss: 2.7466031683214447
Validation loss: 2.564450161937365

Epoch: 6| Step: 5
Training loss: 2.622679002178501
Validation loss: 2.5312719856866095

Epoch: 6| Step: 6
Training loss: 2.970180769020495
Validation loss: 2.5244153654360497

Epoch: 6| Step: 7
Training loss: 3.0225854111586363
Validation loss: 2.5220710816112915

Epoch: 6| Step: 8
Training loss: 3.240337974911011
Validation loss: 2.512837143070088

Epoch: 6| Step: 9
Training loss: 3.1135789831755765
Validation loss: 2.498367988967603

Epoch: 6| Step: 10
Training loss: 4.011445835714486
Validation loss: 2.494355428294239

Epoch: 6| Step: 11
Training loss: 2.2736839344394433
Validation loss: 2.5019274961793188

Epoch: 6| Step: 12
Training loss: 2.840778852771973
Validation loss: 2.488232892039615

Epoch: 6| Step: 13
Training loss: 2.63034376544823
Validation loss: 2.4932394796702395

Epoch: 106| Step: 0
Training loss: 3.2202167317209214
Validation loss: 2.4967802038025284

Epoch: 6| Step: 1
Training loss: 2.538323491462101
Validation loss: 2.4977584654802345

Epoch: 6| Step: 2
Training loss: 3.206273313441298
Validation loss: 2.4942958175554275

Epoch: 6| Step: 3
Training loss: 3.0185153530375555
Validation loss: 2.4926079913423056

Epoch: 6| Step: 4
Training loss: 3.5822426370628517
Validation loss: 2.484163818753477

Epoch: 6| Step: 5
Training loss: 2.7268922273037917
Validation loss: 2.4894324516233937

Epoch: 6| Step: 6
Training loss: 2.6585895781550155
Validation loss: 2.492363165073522

Epoch: 6| Step: 7
Training loss: 2.560617825640292
Validation loss: 2.4994350502578

Epoch: 6| Step: 8
Training loss: 2.779133280525436
Validation loss: 2.50445119155159

Epoch: 6| Step: 9
Training loss: 2.310132748145958
Validation loss: 2.5122710381025253

Epoch: 6| Step: 10
Training loss: 2.9549391890979906
Validation loss: 2.5370424838672516

Epoch: 6| Step: 11
Training loss: 3.0508850314454095
Validation loss: 2.5775309375752924

Epoch: 6| Step: 12
Training loss: 2.44613204726263
Validation loss: 2.609622685422151

Epoch: 6| Step: 13
Training loss: 2.5854723186379536
Validation loss: 2.66336006187973

Epoch: 107| Step: 0
Training loss: 2.968381356891976
Validation loss: 2.6702717493319876

Epoch: 6| Step: 1
Training loss: 2.915066707103004
Validation loss: 2.696693298563457

Epoch: 6| Step: 2
Training loss: 2.8995476008108017
Validation loss: 2.75234035661617

Epoch: 6| Step: 3
Training loss: 3.242763385413635
Validation loss: 2.6668430534088596

Epoch: 6| Step: 4
Training loss: 3.7504480730028797
Validation loss: 2.538829938841243

Epoch: 6| Step: 5
Training loss: 2.1391288930928516
Validation loss: 2.508107154732234

Epoch: 6| Step: 6
Training loss: 2.5177394912889803
Validation loss: 2.4908999905605533

Epoch: 6| Step: 7
Training loss: 3.213111308672855
Validation loss: 2.4875174716107704

Epoch: 6| Step: 8
Training loss: 2.4746257537564715
Validation loss: 2.49649167054114

Epoch: 6| Step: 9
Training loss: 2.7032636485621775
Validation loss: 2.495942869146462

Epoch: 6| Step: 10
Training loss: 2.9433153094743907
Validation loss: 2.4952631672301533

Epoch: 6| Step: 11
Training loss: 2.981978967501627
Validation loss: 2.498503170243038

Epoch: 6| Step: 12
Training loss: 2.1326309518084297
Validation loss: 2.501494249250851

Epoch: 6| Step: 13
Training loss: 3.1804522220385456
Validation loss: 2.503611058360327

Epoch: 108| Step: 0
Training loss: 2.4402975998417604
Validation loss: 2.508732988121128

Epoch: 6| Step: 1
Training loss: 2.911121510429671
Validation loss: 2.496473891804328

Epoch: 6| Step: 2
Training loss: 2.776838339787486
Validation loss: 2.505242245389837

Epoch: 6| Step: 3
Training loss: 3.352267673529767
Validation loss: 2.5172060649697947

Epoch: 6| Step: 4
Training loss: 3.121905053101951
Validation loss: 2.5296137291494203

Epoch: 6| Step: 5
Training loss: 2.6101945515174227
Validation loss: 2.565480295683254

Epoch: 6| Step: 6
Training loss: 2.7146285815699476
Validation loss: 2.601430721900079

Epoch: 6| Step: 7
Training loss: 2.7477750447190203
Validation loss: 2.6537183912509623

Epoch: 6| Step: 8
Training loss: 2.6506978069902942
Validation loss: 2.6665031270157997

Epoch: 6| Step: 9
Training loss: 2.7327355401798865
Validation loss: 2.680527904153294

Epoch: 6| Step: 10
Training loss: 2.696430715164877
Validation loss: 2.6545773552296046

Epoch: 6| Step: 11
Training loss: 3.053905962702244
Validation loss: 2.6857948674674743

Epoch: 6| Step: 12
Training loss: 2.843419317784144
Validation loss: 2.6894242518097746

Epoch: 6| Step: 13
Training loss: 3.4143665448942455
Validation loss: 2.6725771363484525

Epoch: 109| Step: 0
Training loss: 2.7198854903351886
Validation loss: 2.592137021633939

Epoch: 6| Step: 1
Training loss: 3.2408847627476907
Validation loss: 2.5416999752848386

Epoch: 6| Step: 2
Training loss: 3.017885299899519
Validation loss: 2.4996662317017964

Epoch: 6| Step: 3
Training loss: 2.1845457564207145
Validation loss: 2.488043273012501

Epoch: 6| Step: 4
Training loss: 2.1399717796104922
Validation loss: 2.4854122469789446

Epoch: 6| Step: 5
Training loss: 2.82779147884478
Validation loss: 2.489012210715584

Epoch: 6| Step: 6
Training loss: 3.050885344034792
Validation loss: 2.4836386106937782

Epoch: 6| Step: 7
Training loss: 2.8790592893091698
Validation loss: 2.478295354513728

Epoch: 6| Step: 8
Training loss: 2.7706095287218897
Validation loss: 2.473221824006774

Epoch: 6| Step: 9
Training loss: 2.628195770072857
Validation loss: 2.475524474667346

Epoch: 6| Step: 10
Training loss: 2.815073997107695
Validation loss: 2.483663308298428

Epoch: 6| Step: 11
Training loss: 3.792140442030078
Validation loss: 2.490768499259059

Epoch: 6| Step: 12
Training loss: 2.4051919567882774
Validation loss: 2.511571677086526

Epoch: 6| Step: 13
Training loss: 2.5699978435819015
Validation loss: 2.530922793993946

Epoch: 110| Step: 0
Training loss: 2.453994596846896
Validation loss: 2.5765281388051

Epoch: 6| Step: 1
Training loss: 2.7149438633744185
Validation loss: 2.6055393924315737

Epoch: 6| Step: 2
Training loss: 3.257556054430055
Validation loss: 2.588079901607457

Epoch: 6| Step: 3
Training loss: 2.342184942955367
Validation loss: 2.5533451988027838

Epoch: 6| Step: 4
Training loss: 3.200232711913368
Validation loss: 2.5370294536436355

Epoch: 6| Step: 5
Training loss: 3.3284536566560208
Validation loss: 2.5047569404631016

Epoch: 6| Step: 6
Training loss: 2.605932649094879
Validation loss: 2.4856024787618116

Epoch: 6| Step: 7
Training loss: 2.7502514117365324
Validation loss: 2.4837846302826834

Epoch: 6| Step: 8
Training loss: 2.64576050265139
Validation loss: 2.4767846386694283

Epoch: 6| Step: 9
Training loss: 2.5043861060280634
Validation loss: 2.474360394192463

Epoch: 6| Step: 10
Training loss: 3.093368198455894
Validation loss: 2.4738742602084165

Epoch: 6| Step: 11
Training loss: 2.71640825817351
Validation loss: 2.4759719603651846

Epoch: 6| Step: 12
Training loss: 2.6295440942984514
Validation loss: 2.4767859552756324

Epoch: 6| Step: 13
Training loss: 3.2773207617079643
Validation loss: 2.475230392765322

Epoch: 111| Step: 0
Training loss: 2.2330689781458224
Validation loss: 2.478475503460932

Epoch: 6| Step: 1
Training loss: 2.9867754963506354
Validation loss: 2.4813282371628858

Epoch: 6| Step: 2
Training loss: 2.886478068186654
Validation loss: 2.4777625124777916

Epoch: 6| Step: 3
Training loss: 3.313536283953765
Validation loss: 2.4803809024679357

Epoch: 6| Step: 4
Training loss: 2.6067995621771427
Validation loss: 2.479378942879109

Epoch: 6| Step: 5
Training loss: 2.4849965979324478
Validation loss: 2.4896952440507127

Epoch: 6| Step: 6
Training loss: 2.8252476338915953
Validation loss: 2.491729345495995

Epoch: 6| Step: 7
Training loss: 3.0594040149407764
Validation loss: 2.4935649159494973

Epoch: 6| Step: 8
Training loss: 2.8371915540383665
Validation loss: 2.5020074045244782

Epoch: 6| Step: 9
Training loss: 2.0540508255655086
Validation loss: 2.5095691873285073

Epoch: 6| Step: 10
Training loss: 3.0392667804696267
Validation loss: 2.5256764577449946

Epoch: 6| Step: 11
Training loss: 3.0625023355280474
Validation loss: 2.5482518797378804

Epoch: 6| Step: 12
Training loss: 2.4571049956639617
Validation loss: 2.5442347689253317

Epoch: 6| Step: 13
Training loss: 3.0894037408435286
Validation loss: 2.539369068806192

Epoch: 112| Step: 0
Training loss: 2.6218628074899013
Validation loss: 2.546591977473417

Epoch: 6| Step: 1
Training loss: 2.4394757992841347
Validation loss: 2.5254813104402403

Epoch: 6| Step: 2
Training loss: 2.9410515276232014
Validation loss: 2.5115278714965195

Epoch: 6| Step: 3
Training loss: 2.618354286759145
Validation loss: 2.5024593213568336

Epoch: 6| Step: 4
Training loss: 3.4182205543407633
Validation loss: 2.494258709539067

Epoch: 6| Step: 5
Training loss: 2.826939708535033
Validation loss: 2.494349015986553

Epoch: 6| Step: 6
Training loss: 2.0755509805504104
Validation loss: 2.5070115271717723

Epoch: 6| Step: 7
Training loss: 3.171511173522694
Validation loss: 2.4959488449416396

Epoch: 6| Step: 8
Training loss: 2.8990678538776424
Validation loss: 2.5121748284724355

Epoch: 6| Step: 9
Training loss: 2.880887182069188
Validation loss: 2.507848805360999

Epoch: 6| Step: 10
Training loss: 3.136740184439919
Validation loss: 2.524806137708433

Epoch: 6| Step: 11
Training loss: 2.3370611747860566
Validation loss: 2.5393024492118137

Epoch: 6| Step: 12
Training loss: 2.8794127061518346
Validation loss: 2.534890780648495

Epoch: 6| Step: 13
Training loss: 2.1239634959214424
Validation loss: 2.5348577540602846

Epoch: 113| Step: 0
Training loss: 2.4815796294448
Validation loss: 2.5228907332714114

Epoch: 6| Step: 1
Training loss: 2.4939071796951584
Validation loss: 2.52899787197527

Epoch: 6| Step: 2
Training loss: 2.389773846863768
Validation loss: 2.5280512007124356

Epoch: 6| Step: 3
Training loss: 3.390740036660997
Validation loss: 2.5414213848595497

Epoch: 6| Step: 4
Training loss: 3.110614472061562
Validation loss: 2.529986091428651

Epoch: 6| Step: 5
Training loss: 2.7415640358619995
Validation loss: 2.512693949412004

Epoch: 6| Step: 6
Training loss: 2.5323149713102673
Validation loss: 2.5034822402507966

Epoch: 6| Step: 7
Training loss: 3.409387386030291
Validation loss: 2.5024554089850493

Epoch: 6| Step: 8
Training loss: 3.1985800155546777
Validation loss: 2.4928465563349125

Epoch: 6| Step: 9
Training loss: 2.356966722191173
Validation loss: 2.5034391169568204

Epoch: 6| Step: 10
Training loss: 2.4448173435999045
Validation loss: 2.4930243087460107

Epoch: 6| Step: 11
Training loss: 2.114983456594278
Validation loss: 2.492369284197586

Epoch: 6| Step: 12
Training loss: 2.833497229678925
Validation loss: 2.4960421889492763

Epoch: 6| Step: 13
Training loss: 3.1614617856219995
Validation loss: 2.5081439300948962

Epoch: 114| Step: 0
Training loss: 2.892499161491833
Validation loss: 2.5135046919286532

Epoch: 6| Step: 1
Training loss: 2.570295061324771
Validation loss: 2.502994538449855

Epoch: 6| Step: 2
Training loss: 2.135502387086342
Validation loss: 2.501248392536692

Epoch: 6| Step: 3
Training loss: 2.658096300118629
Validation loss: 2.5030204687316764

Epoch: 6| Step: 4
Training loss: 3.3514860984790524
Validation loss: 2.487691411060745

Epoch: 6| Step: 5
Training loss: 2.5213405529700887
Validation loss: 2.4905527535544594

Epoch: 6| Step: 6
Training loss: 2.903794266309555
Validation loss: 2.5097183265856087

Epoch: 6| Step: 7
Training loss: 2.0712260983549315
Validation loss: 2.516711228872632

Epoch: 6| Step: 8
Training loss: 2.7865431062631605
Validation loss: 2.5350021471451063

Epoch: 6| Step: 9
Training loss: 3.1538484709339327
Validation loss: 2.5180333427621395

Epoch: 6| Step: 10
Training loss: 2.7630297019209746
Validation loss: 2.525442346168023

Epoch: 6| Step: 11
Training loss: 2.6677154822938323
Validation loss: 2.5241904776515613

Epoch: 6| Step: 12
Training loss: 3.165836693933572
Validation loss: 2.507733232576084

Epoch: 6| Step: 13
Training loss: 2.4567146036585825
Validation loss: 2.517550344703788

Epoch: 115| Step: 0
Training loss: 2.4373191375145113
Validation loss: 2.506993988698629

Epoch: 6| Step: 1
Training loss: 2.8047267730428467
Validation loss: 2.4991936213781387

Epoch: 6| Step: 2
Training loss: 2.520179653273101
Validation loss: 2.50363732374966

Epoch: 6| Step: 3
Training loss: 2.8077938123791197
Validation loss: 2.5043470356805857

Epoch: 6| Step: 4
Training loss: 3.158271368890074
Validation loss: 2.49572937658313

Epoch: 6| Step: 5
Training loss: 2.8668663406324457
Validation loss: 2.4924716921796266

Epoch: 6| Step: 6
Training loss: 3.1520375761319306
Validation loss: 2.4910345952966444

Epoch: 6| Step: 7
Training loss: 2.2139371870136677
Validation loss: 2.4854324947510196

Epoch: 6| Step: 8
Training loss: 2.9003712252086893
Validation loss: 2.4912794286428777

Epoch: 6| Step: 9
Training loss: 2.465245137125435
Validation loss: 2.496826037754503

Epoch: 6| Step: 10
Training loss: 2.092873347074139
Validation loss: 2.51737429709559

Epoch: 6| Step: 11
Training loss: 3.3709059007627125
Validation loss: 2.53734774785178

Epoch: 6| Step: 12
Training loss: 2.6252504865026354
Validation loss: 2.5201490248514946

Epoch: 6| Step: 13
Training loss: 3.026803914821992
Validation loss: 2.526547186230006

Epoch: 116| Step: 0
Training loss: 3.1709591901132645
Validation loss: 2.497387836002131

Epoch: 6| Step: 1
Training loss: 2.7651568517637397
Validation loss: 2.489898162993406

Epoch: 6| Step: 2
Training loss: 2.788862376152487
Validation loss: 2.477232037475835

Epoch: 6| Step: 3
Training loss: 2.381561851606492
Validation loss: 2.475235970100389

Epoch: 6| Step: 4
Training loss: 2.311981452332911
Validation loss: 2.476766962749339

Epoch: 6| Step: 5
Training loss: 3.069593350196617
Validation loss: 2.4768269022072795

Epoch: 6| Step: 6
Training loss: 2.8204741286355977
Validation loss: 2.477621576458167

Epoch: 6| Step: 7
Training loss: 2.840558115693177
Validation loss: 2.4818190324512432

Epoch: 6| Step: 8
Training loss: 2.2113807692171927
Validation loss: 2.481426594289292

Epoch: 6| Step: 9
Training loss: 3.1580409643549503
Validation loss: 2.5026702914806376

Epoch: 6| Step: 10
Training loss: 3.147273527667874
Validation loss: 2.535797444066081

Epoch: 6| Step: 11
Training loss: 2.4745715107538753
Validation loss: 2.5247566891761193

Epoch: 6| Step: 12
Training loss: 1.860662062957838
Validation loss: 2.5468106553931946

Epoch: 6| Step: 13
Training loss: 3.4427624735227784
Validation loss: 2.537056014210867

Epoch: 117| Step: 0
Training loss: 2.783803132281983
Validation loss: 2.5479190150425772

Epoch: 6| Step: 1
Training loss: 2.8444068904556676
Validation loss: 2.6041288239385416

Epoch: 6| Step: 2
Training loss: 3.045213451702633
Validation loss: 2.618739352697884

Epoch: 6| Step: 3
Training loss: 3.208900120860221
Validation loss: 2.679811345466234

Epoch: 6| Step: 4
Training loss: 2.060355487631345
Validation loss: 2.6702592165838133

Epoch: 6| Step: 5
Training loss: 2.6209361999734093
Validation loss: 2.678665541710947

Epoch: 6| Step: 6
Training loss: 2.9281392393305388
Validation loss: 2.653908918674752

Epoch: 6| Step: 7
Training loss: 2.8961916548606674
Validation loss: 2.5946048109314157

Epoch: 6| Step: 8
Training loss: 2.19829012574062
Validation loss: 2.5168711885670483

Epoch: 6| Step: 9
Training loss: 3.1190363628277247
Validation loss: 2.4776608809595824

Epoch: 6| Step: 10
Training loss: 2.8062913819386286
Validation loss: 2.478322779358125

Epoch: 6| Step: 11
Training loss: 2.3801856398109282
Validation loss: 2.4824346434869438

Epoch: 6| Step: 12
Training loss: 2.803051484673876
Validation loss: 2.4910383804962204

Epoch: 6| Step: 13
Training loss: 3.1054409577667537
Validation loss: 2.5039710101325086

Epoch: 118| Step: 0
Training loss: 2.4913200375463567
Validation loss: 2.510208431351187

Epoch: 6| Step: 1
Training loss: 3.2208397757073866
Validation loss: 2.5092478608813793

Epoch: 6| Step: 2
Training loss: 3.2076862888248048
Validation loss: 2.5041781817529385

Epoch: 6| Step: 3
Training loss: 2.488273393028706
Validation loss: 2.49946642483231

Epoch: 6| Step: 4
Training loss: 3.4000188546499412
Validation loss: 2.48561324651349

Epoch: 6| Step: 5
Training loss: 2.845573092430633
Validation loss: 2.4849539858811434

Epoch: 6| Step: 6
Training loss: 2.7747783159941584
Validation loss: 2.478421000264319

Epoch: 6| Step: 7
Training loss: 2.5371637845096817
Validation loss: 2.4725827421294744

Epoch: 6| Step: 8
Training loss: 3.0991964467782056
Validation loss: 2.463621406242003

Epoch: 6| Step: 9
Training loss: 2.213193248180168
Validation loss: 2.4638031119655666

Epoch: 6| Step: 10
Training loss: 2.8600623133346637
Validation loss: 2.4716221955482047

Epoch: 6| Step: 11
Training loss: 2.3811060063437
Validation loss: 2.463078456831859

Epoch: 6| Step: 12
Training loss: 3.2808061572024787
Validation loss: 2.4744095122874823

Epoch: 6| Step: 13
Training loss: 2.860375234623793
Validation loss: 2.454005331961628

Epoch: 119| Step: 0
Training loss: 2.3423964597440765
Validation loss: 2.499141226700023

Epoch: 6| Step: 1
Training loss: 2.930921777759719
Validation loss: 2.5370043964214264

Epoch: 6| Step: 2
Training loss: 2.4350874283152173
Validation loss: 2.5622232959537317

Epoch: 6| Step: 3
Training loss: 2.6026188535786745
Validation loss: 2.6285714183375664

Epoch: 6| Step: 4
Training loss: 2.921308656363971
Validation loss: 2.6841444094264553

Epoch: 6| Step: 5
Training loss: 3.2002732398678795
Validation loss: 2.636431560425068

Epoch: 6| Step: 6
Training loss: 2.921147383396199
Validation loss: 2.5334199167517824

Epoch: 6| Step: 7
Training loss: 2.3217192729823823
Validation loss: 2.509391679242118

Epoch: 6| Step: 8
Training loss: 2.6225121834383756
Validation loss: 2.505588514841259

Epoch: 6| Step: 9
Training loss: 2.568629122300868
Validation loss: 2.490983043763761

Epoch: 6| Step: 10
Training loss: 3.05783504269204
Validation loss: 2.491468839961138

Epoch: 6| Step: 11
Training loss: 3.1704975012152907
Validation loss: 2.4892649186723887

Epoch: 6| Step: 12
Training loss: 3.114394081175163
Validation loss: 2.4908647823215064

Epoch: 6| Step: 13
Training loss: 3.061029353572124
Validation loss: 2.525473203760975

Epoch: 120| Step: 0
Training loss: 2.7428121262926375
Validation loss: 2.5628173195459327

Epoch: 6| Step: 1
Training loss: 2.974324664230849
Validation loss: 2.5876190336507365

Epoch: 6| Step: 2
Training loss: 3.4174649461289315
Validation loss: 2.5897419306790184

Epoch: 6| Step: 3
Training loss: 2.0681189090181396
Validation loss: 2.58580585855111

Epoch: 6| Step: 4
Training loss: 2.705424218468109
Validation loss: 2.558810088765022

Epoch: 6| Step: 5
Training loss: 2.6334943030045688
Validation loss: 2.5477494727117924

Epoch: 6| Step: 6
Training loss: 2.805227668620968
Validation loss: 2.5064929609432673

Epoch: 6| Step: 7
Training loss: 3.1691674012123023
Validation loss: 2.485987116417769

Epoch: 6| Step: 8
Training loss: 2.9972053862829413
Validation loss: 2.494892144456048

Epoch: 6| Step: 9
Training loss: 2.8544018131113496
Validation loss: 2.4866502450373655

Epoch: 6| Step: 10
Training loss: 2.4584181711676703
Validation loss: 2.4976437888785523

Epoch: 6| Step: 11
Training loss: 3.0446296439105858
Validation loss: 2.5229944701032774

Epoch: 6| Step: 12
Training loss: 2.353778188154781
Validation loss: 2.5409807176933565

Epoch: 6| Step: 13
Training loss: 2.370169093220259
Validation loss: 2.5674598828410216

Epoch: 121| Step: 0
Training loss: 2.283641450052942
Validation loss: 2.5943052169826677

Epoch: 6| Step: 1
Training loss: 2.730292624276465
Validation loss: 2.643587911619276

Epoch: 6| Step: 2
Training loss: 2.842144691182642
Validation loss: 2.664423001248088

Epoch: 6| Step: 3
Training loss: 3.0786104545610535
Validation loss: 2.661932371544102

Epoch: 6| Step: 4
Training loss: 2.703758562403369
Validation loss: 2.668851354229178

Epoch: 6| Step: 5
Training loss: 2.5557427049838894
Validation loss: 2.6804105443969304

Epoch: 6| Step: 6
Training loss: 2.716989495300271
Validation loss: 2.7016917107465312

Epoch: 6| Step: 7
Training loss: 2.6690082005260116
Validation loss: 2.641406048667231

Epoch: 6| Step: 8
Training loss: 2.6003655323424115
Validation loss: 2.5835836714626224

Epoch: 6| Step: 9
Training loss: 2.9924192015177793
Validation loss: 2.582588918834146

Epoch: 6| Step: 10
Training loss: 3.1714956874201654
Validation loss: 2.5403729364938754

Epoch: 6| Step: 11
Training loss: 2.4301888785719243
Validation loss: 2.5271804933594093

Epoch: 6| Step: 12
Training loss: 3.0010062755301736
Validation loss: 2.5200848401687086

Epoch: 6| Step: 13
Training loss: 3.0620422021111606
Validation loss: 2.5091430438348676

Epoch: 122| Step: 0
Training loss: 2.842833151103351
Validation loss: 2.5160922915355903

Epoch: 6| Step: 1
Training loss: 3.195773289666417
Validation loss: 2.517867048994422

Epoch: 6| Step: 2
Training loss: 2.840445138673766
Validation loss: 2.498592743574308

Epoch: 6| Step: 3
Training loss: 2.710007829690018
Validation loss: 2.497322144478167

Epoch: 6| Step: 4
Training loss: 2.9405955784427467
Validation loss: 2.4827037960461382

Epoch: 6| Step: 5
Training loss: 3.0407121981029204
Validation loss: 2.4801004922071614

Epoch: 6| Step: 6
Training loss: 2.9084238105698503
Validation loss: 2.4630267916775654

Epoch: 6| Step: 7
Training loss: 2.625828748396544
Validation loss: 2.499138972997449

Epoch: 6| Step: 8
Training loss: 2.751105173156252
Validation loss: 2.546381634023528

Epoch: 6| Step: 9
Training loss: 2.7202328551419725
Validation loss: 2.5760772696912078

Epoch: 6| Step: 10
Training loss: 1.9526917854513335
Validation loss: 2.5948450618739125

Epoch: 6| Step: 11
Training loss: 2.5979455313548665
Validation loss: 2.6128481182823236

Epoch: 6| Step: 12
Training loss: 2.8950580318346693
Validation loss: 2.5924502280265216

Epoch: 6| Step: 13
Training loss: 2.952733896989477
Validation loss: 2.613312857773465

Epoch: 123| Step: 0
Training loss: 2.6945317561192534
Validation loss: 2.58017124226186

Epoch: 6| Step: 1
Training loss: 2.816159558966796
Validation loss: 2.560555961949881

Epoch: 6| Step: 2
Training loss: 2.7010467125173316
Validation loss: 2.5563554700265234

Epoch: 6| Step: 3
Training loss: 2.8404669622223317
Validation loss: 2.541227930881465

Epoch: 6| Step: 4
Training loss: 1.7993352218741454
Validation loss: 2.5357717412844307

Epoch: 6| Step: 5
Training loss: 2.477021280147235
Validation loss: 2.540012210149326

Epoch: 6| Step: 6
Training loss: 2.7974849440755
Validation loss: 2.5477621371833936

Epoch: 6| Step: 7
Training loss: 3.078216551372888
Validation loss: 2.5204356076486834

Epoch: 6| Step: 8
Training loss: 2.8958302413228676
Validation loss: 2.5610512210266196

Epoch: 6| Step: 9
Training loss: 2.3124319530476103
Validation loss: 2.5504340257867804

Epoch: 6| Step: 10
Training loss: 3.012229787017405
Validation loss: 2.5392523743317357

Epoch: 6| Step: 11
Training loss: 2.7348758783716085
Validation loss: 2.526369789327334

Epoch: 6| Step: 12
Training loss: 2.708505380496631
Validation loss: 2.498046100175076

Epoch: 6| Step: 13
Training loss: 3.4107981424002043
Validation loss: 2.4894550342086217

Epoch: 124| Step: 0
Training loss: 2.3371415623305847
Validation loss: 2.480926431656565

Epoch: 6| Step: 1
Training loss: 2.6829303660020543
Validation loss: 2.4841367040112234

Epoch: 6| Step: 2
Training loss: 2.4602175673750484
Validation loss: 2.4709619115083132

Epoch: 6| Step: 3
Training loss: 2.4684041420797516
Validation loss: 2.4779925376572947

Epoch: 6| Step: 4
Training loss: 2.6807578037457525
Validation loss: 2.477638894479518

Epoch: 6| Step: 5
Training loss: 3.329331443506004
Validation loss: 2.4788500972436407

Epoch: 6| Step: 6
Training loss: 3.108370671461364
Validation loss: 2.481950921451057

Epoch: 6| Step: 7
Training loss: 2.0304300854220787
Validation loss: 2.4864364530954397

Epoch: 6| Step: 8
Training loss: 3.044988586203946
Validation loss: 2.5034497260667155

Epoch: 6| Step: 9
Training loss: 2.791770496620082
Validation loss: 2.5344642933469146

Epoch: 6| Step: 10
Training loss: 2.491719743127183
Validation loss: 2.568139037593167

Epoch: 6| Step: 11
Training loss: 2.8668279188476204
Validation loss: 2.58595321725346

Epoch: 6| Step: 12
Training loss: 2.502297299585462
Validation loss: 2.6353537799129003

Epoch: 6| Step: 13
Training loss: 3.324830049459383
Validation loss: 2.63942773934397

Epoch: 125| Step: 0
Training loss: 2.4612068150007334
Validation loss: 2.6095445614808197

Epoch: 6| Step: 1
Training loss: 2.689948984392688
Validation loss: 2.5671252460341356

Epoch: 6| Step: 2
Training loss: 2.3847791216794056
Validation loss: 2.5153269411891097

Epoch: 6| Step: 3
Training loss: 3.3923030515552863
Validation loss: 2.469207060916317

Epoch: 6| Step: 4
Training loss: 2.3470166647424677
Validation loss: 2.4658363701585775

Epoch: 6| Step: 5
Training loss: 2.8456240337327454
Validation loss: 2.4599780797144324

Epoch: 6| Step: 6
Training loss: 3.2153996187491147
Validation loss: 2.4532968223064366

Epoch: 6| Step: 7
Training loss: 2.6319941032598697
Validation loss: 2.4596036948713134

Epoch: 6| Step: 8
Training loss: 2.4292117324583464
Validation loss: 2.4558261818290017

Epoch: 6| Step: 9
Training loss: 2.79301382175171
Validation loss: 2.466546023596631

Epoch: 6| Step: 10
Training loss: 2.905283449299976
Validation loss: 2.485290914705734

Epoch: 6| Step: 11
Training loss: 2.4341170481589796
Validation loss: 2.507082764773011

Epoch: 6| Step: 12
Training loss: 2.6567023397018614
Validation loss: 2.5434450413249947

Epoch: 6| Step: 13
Training loss: 2.966960809534312
Validation loss: 2.5624749327243133

Epoch: 126| Step: 0
Training loss: 2.5584366378885237
Validation loss: 2.5568607275406046

Epoch: 6| Step: 1
Training loss: 3.4014688236232673
Validation loss: 2.542566530152142

Epoch: 6| Step: 2
Training loss: 2.5934239377895496
Validation loss: 2.503473567726662

Epoch: 6| Step: 3
Training loss: 2.7265474597767483
Validation loss: 2.4965996895883715

Epoch: 6| Step: 4
Training loss: 2.7555839893025995
Validation loss: 2.4942933199968707

Epoch: 6| Step: 5
Training loss: 2.5272241295831797
Validation loss: 2.488379543497837

Epoch: 6| Step: 6
Training loss: 3.2672807064471336
Validation loss: 2.4819906314932405

Epoch: 6| Step: 7
Training loss: 2.3726657639891466
Validation loss: 2.4912016078968047

Epoch: 6| Step: 8
Training loss: 1.6425035167174526
Validation loss: 2.489816030147254

Epoch: 6| Step: 9
Training loss: 2.494835287096367
Validation loss: 2.500220504388466

Epoch: 6| Step: 10
Training loss: 3.1613815440740325
Validation loss: 2.4979284235437027

Epoch: 6| Step: 11
Training loss: 2.846731446517017
Validation loss: 2.5122226286283875

Epoch: 6| Step: 12
Training loss: 2.5281334988860253
Validation loss: 2.532805981546401

Epoch: 6| Step: 13
Training loss: 2.3894765251876002
Validation loss: 2.562803913205418

Epoch: 127| Step: 0
Training loss: 2.554325743093675
Validation loss: 2.5777171986104985

Epoch: 6| Step: 1
Training loss: 2.3739348582945112
Validation loss: 2.592196036964271

Epoch: 6| Step: 2
Training loss: 2.7670804089718057
Validation loss: 2.617884012302403

Epoch: 6| Step: 3
Training loss: 2.8329667433898393
Validation loss: 2.6261878590343564

Epoch: 6| Step: 4
Training loss: 2.6309755521977407
Validation loss: 2.6297375956601403

Epoch: 6| Step: 5
Training loss: 2.946228856175539
Validation loss: 2.659130098067009

Epoch: 6| Step: 6
Training loss: 3.0784250490755625
Validation loss: 2.688986057140383

Epoch: 6| Step: 7
Training loss: 2.664984311456647
Validation loss: 2.643443307042776

Epoch: 6| Step: 8
Training loss: 2.721792250907183
Validation loss: 2.596336340411309

Epoch: 6| Step: 9
Training loss: 2.4906228633857093
Validation loss: 2.561846579503046

Epoch: 6| Step: 10
Training loss: 2.328918526612959
Validation loss: 2.5244961745919685

Epoch: 6| Step: 11
Training loss: 2.1586671632424896
Validation loss: 2.500910229231747

Epoch: 6| Step: 12
Training loss: 3.247816379280163
Validation loss: 2.4875926085805258

Epoch: 6| Step: 13
Training loss: 2.7710632477407904
Validation loss: 2.483992900836692

Epoch: 128| Step: 0
Training loss: 2.6867158322375295
Validation loss: 2.4788182445409226

Epoch: 6| Step: 1
Training loss: 2.831828185068963
Validation loss: 2.4756257444613494

Epoch: 6| Step: 2
Training loss: 3.206936982380533
Validation loss: 2.4780160117919494

Epoch: 6| Step: 3
Training loss: 2.3812316653529515
Validation loss: 2.480539214089618

Epoch: 6| Step: 4
Training loss: 2.75578185796366
Validation loss: 2.482451580942572

Epoch: 6| Step: 5
Training loss: 3.0597696394634077
Validation loss: 2.4756859186551083

Epoch: 6| Step: 6
Training loss: 2.3578551999542756
Validation loss: 2.4785594663661175

Epoch: 6| Step: 7
Training loss: 3.437078970353999
Validation loss: 2.4865774147894215

Epoch: 6| Step: 8
Training loss: 2.517076725005217
Validation loss: 2.513951940551613

Epoch: 6| Step: 9
Training loss: 2.814117644604749
Validation loss: 2.5680610737103455

Epoch: 6| Step: 10
Training loss: 1.7033314710981389
Validation loss: 2.6012117010839195

Epoch: 6| Step: 11
Training loss: 2.509045829418246
Validation loss: 2.6447537236310117

Epoch: 6| Step: 12
Training loss: 3.1213614070932905
Validation loss: 2.678984952552211

Epoch: 6| Step: 13
Training loss: 2.262220047127595
Validation loss: 2.632940715302844

Epoch: 129| Step: 0
Training loss: 2.4361028334987953
Validation loss: 2.562047483725303

Epoch: 6| Step: 1
Training loss: 2.3659503587044077
Validation loss: 2.507522933793413

Epoch: 6| Step: 2
Training loss: 2.473590017642054
Validation loss: 2.479843618723401

Epoch: 6| Step: 3
Training loss: 2.342963531783431
Validation loss: 2.4758438356912054

Epoch: 6| Step: 4
Training loss: 3.19078911518958
Validation loss: 2.47457711443776

Epoch: 6| Step: 5
Training loss: 2.906145319540324
Validation loss: 2.4814336505692096

Epoch: 6| Step: 6
Training loss: 2.3981652120798373
Validation loss: 2.4664314512554792

Epoch: 6| Step: 7
Training loss: 2.5761057951509017
Validation loss: 2.46318783708278

Epoch: 6| Step: 8
Training loss: 3.2186504459725622
Validation loss: 2.4689009332008487

Epoch: 6| Step: 9
Training loss: 2.1962232770689
Validation loss: 2.473734564945562

Epoch: 6| Step: 10
Training loss: 2.950476856807413
Validation loss: 2.460129952286833

Epoch: 6| Step: 11
Training loss: 3.068743511123168
Validation loss: 2.487691180737279

Epoch: 6| Step: 12
Training loss: 2.568402633012611
Validation loss: 2.4982739632624686

Epoch: 6| Step: 13
Training loss: 2.942432725991346
Validation loss: 2.5063066796660203

Epoch: 130| Step: 0
Training loss: 2.0916284089053536
Validation loss: 2.515700689507168

Epoch: 6| Step: 1
Training loss: 3.17683511400147
Validation loss: 2.505460734138569

Epoch: 6| Step: 2
Training loss: 3.1940960422281512
Validation loss: 2.503374761910935

Epoch: 6| Step: 3
Training loss: 2.85353835120998
Validation loss: 2.5124812312846743

Epoch: 6| Step: 4
Training loss: 2.3722401695952313
Validation loss: 2.5226048663859864

Epoch: 6| Step: 5
Training loss: 3.168007131924934
Validation loss: 2.516360709891328

Epoch: 6| Step: 6
Training loss: 2.4885060255250955
Validation loss: 2.5239996703442973

Epoch: 6| Step: 7
Training loss: 2.6361197236213734
Validation loss: 2.5444362818883812

Epoch: 6| Step: 8
Training loss: 2.496677861649082
Validation loss: 2.5220478670814876

Epoch: 6| Step: 9
Training loss: 1.9152168374267162
Validation loss: 2.526586154264353

Epoch: 6| Step: 10
Training loss: 2.917399686708497
Validation loss: 2.5306576909739915

Epoch: 6| Step: 11
Training loss: 2.9515622156646897
Validation loss: 2.5294554068672976

Epoch: 6| Step: 12
Training loss: 2.501487289527566
Validation loss: 2.5196154452608788

Epoch: 6| Step: 13
Training loss: 1.2943897563658666
Validation loss: 2.509220633043636

Epoch: 131| Step: 0
Training loss: 2.474555806074684
Validation loss: 2.509133063657934

Epoch: 6| Step: 1
Training loss: 2.5207997049237667
Validation loss: 2.518278027030453

Epoch: 6| Step: 2
Training loss: 2.660668412029803
Validation loss: 2.53497299026715

Epoch: 6| Step: 3
Training loss: 2.210063424559615
Validation loss: 2.552006661872939

Epoch: 6| Step: 4
Training loss: 2.7977024324893516
Validation loss: 2.5470490946285653

Epoch: 6| Step: 5
Training loss: 2.5236746378393033
Validation loss: 2.5587933461630583

Epoch: 6| Step: 6
Training loss: 2.4464957692421376
Validation loss: 2.5802786991174287

Epoch: 6| Step: 7
Training loss: 2.925390403320695
Validation loss: 2.600265181927217

Epoch: 6| Step: 8
Training loss: 2.7651114983867724
Validation loss: 2.579723474409204

Epoch: 6| Step: 9
Training loss: 2.7344135390699273
Validation loss: 2.5476734417937674

Epoch: 6| Step: 10
Training loss: 2.1236738667080384
Validation loss: 2.516434820606496

Epoch: 6| Step: 11
Training loss: 2.908711693170923
Validation loss: 2.4976057893598176

Epoch: 6| Step: 12
Training loss: 2.916774438955913
Validation loss: 2.470502006117141

Epoch: 6| Step: 13
Training loss: 2.7013805250895344
Validation loss: 2.466321621845965

Epoch: 132| Step: 0
Training loss: 2.0893705884114944
Validation loss: 2.457885315165783

Epoch: 6| Step: 1
Training loss: 2.5856964828793627
Validation loss: 2.460435266090938

Epoch: 6| Step: 2
Training loss: 2.517633998301154
Validation loss: 2.4662073566493143

Epoch: 6| Step: 3
Training loss: 2.725250890538674
Validation loss: 2.458899280760414

Epoch: 6| Step: 4
Training loss: 2.4402620365583427
Validation loss: 2.4545088152206755

Epoch: 6| Step: 5
Training loss: 2.643220968499961
Validation loss: 2.456910128273328

Epoch: 6| Step: 6
Training loss: 2.9356287413734274
Validation loss: 2.4624735408377756

Epoch: 6| Step: 7
Training loss: 3.117640412203936
Validation loss: 2.4703959954946533

Epoch: 6| Step: 8
Training loss: 2.4848712929258987
Validation loss: 2.5053388020823375

Epoch: 6| Step: 9
Training loss: 2.886789777860109
Validation loss: 2.541108731001788

Epoch: 6| Step: 10
Training loss: 2.6162850261590855
Validation loss: 2.619092281135473

Epoch: 6| Step: 11
Training loss: 2.1007064720909407
Validation loss: 2.6611361592258476

Epoch: 6| Step: 12
Training loss: 2.8717407328005398
Validation loss: 2.6625458875105865

Epoch: 6| Step: 13
Training loss: 3.0526423718041844
Validation loss: 2.612512249080586

Epoch: 133| Step: 0
Training loss: 2.7343225092618026
Validation loss: 2.5925411308700355

Epoch: 6| Step: 1
Training loss: 2.74514367719454
Validation loss: 2.5778232958511547

Epoch: 6| Step: 2
Training loss: 2.585789978798186
Validation loss: 2.5889026562377206

Epoch: 6| Step: 3
Training loss: 3.1142994592895765
Validation loss: 2.589895345124152

Epoch: 6| Step: 4
Training loss: 2.6622173821977206
Validation loss: 2.574333452149079

Epoch: 6| Step: 5
Training loss: 2.8807502958692686
Validation loss: 2.5237302146542837

Epoch: 6| Step: 6
Training loss: 3.0003111995777245
Validation loss: 2.494076524439611

Epoch: 6| Step: 7
Training loss: 2.4808199416125785
Validation loss: 2.4675106158261264

Epoch: 6| Step: 8
Training loss: 2.548020649303801
Validation loss: 2.460919096149176

Epoch: 6| Step: 9
Training loss: 1.8283472170631534
Validation loss: 2.453284854146877

Epoch: 6| Step: 10
Training loss: 2.2197125992879125
Validation loss: 2.460596971314255

Epoch: 6| Step: 11
Training loss: 2.8897433199296656
Validation loss: 2.4651807563066037

Epoch: 6| Step: 12
Training loss: 2.4707244510257973
Validation loss: 2.475294353738832

Epoch: 6| Step: 13
Training loss: 1.983607166150259
Validation loss: 2.499416860639928

Epoch: 134| Step: 0
Training loss: 2.5381909561887035
Validation loss: 2.529585780031653

Epoch: 6| Step: 1
Training loss: 2.6591510862226557
Validation loss: 2.5688242272297184

Epoch: 6| Step: 2
Training loss: 2.5423714541307314
Validation loss: 2.6045591230104197

Epoch: 6| Step: 3
Training loss: 2.055293468858777
Validation loss: 2.636246569309898

Epoch: 6| Step: 4
Training loss: 2.963594638415849
Validation loss: 2.673328117973836

Epoch: 6| Step: 5
Training loss: 2.6645824115225656
Validation loss: 2.6549942252436187

Epoch: 6| Step: 6
Training loss: 1.691217495647508
Validation loss: 2.6061830136414232

Epoch: 6| Step: 7
Training loss: 3.1007460281013235
Validation loss: 2.5516054326701245

Epoch: 6| Step: 8
Training loss: 2.8131531698684866
Validation loss: 2.5423055908516017

Epoch: 6| Step: 9
Training loss: 2.5949373400111195
Validation loss: 2.5117868779016903

Epoch: 6| Step: 10
Training loss: 2.6489701087160906
Validation loss: 2.507858867316927

Epoch: 6| Step: 11
Training loss: 2.335596984744261
Validation loss: 2.495750201144583

Epoch: 6| Step: 12
Training loss: 2.755470902756017
Validation loss: 2.5039633273004136

Epoch: 6| Step: 13
Training loss: 2.979974028198943
Validation loss: 2.4892399594397188

Epoch: 135| Step: 0
Training loss: 2.4413594722081147
Validation loss: 2.5069070031757437

Epoch: 6| Step: 1
Training loss: 2.8191052333517854
Validation loss: 2.497598700760236

Epoch: 6| Step: 2
Training loss: 2.3223379009989085
Validation loss: 2.5021336935654843

Epoch: 6| Step: 3
Training loss: 2.5782013852912415
Validation loss: 2.51222421137242

Epoch: 6| Step: 4
Training loss: 2.860175349055325
Validation loss: 2.506553010848989

Epoch: 6| Step: 5
Training loss: 2.7251540429208228
Validation loss: 2.508007938596378

Epoch: 6| Step: 6
Training loss: 2.5245035948823147
Validation loss: 2.5308422275178812

Epoch: 6| Step: 7
Training loss: 2.1613446186593914
Validation loss: 2.5211739140106335

Epoch: 6| Step: 8
Training loss: 2.94912626614097
Validation loss: 2.5279449809284653

Epoch: 6| Step: 9
Training loss: 2.3427980651451485
Validation loss: 2.5441357716389246

Epoch: 6| Step: 10
Training loss: 2.8389488184858025
Validation loss: 2.558629832780075

Epoch: 6| Step: 11
Training loss: 2.2667786916463317
Validation loss: 2.584054328927037

Epoch: 6| Step: 12
Training loss: 2.207127175736153
Validation loss: 2.6277155193031123

Epoch: 6| Step: 13
Training loss: 2.653645573779172
Validation loss: 2.6416857945979038

Epoch: 136| Step: 0
Training loss: 2.757876127984121
Validation loss: 2.66012320293854

Epoch: 6| Step: 1
Training loss: 2.2956265540446177
Validation loss: 2.648899355717287

Epoch: 6| Step: 2
Training loss: 2.3604363081794695
Validation loss: 2.596520491207631

Epoch: 6| Step: 3
Training loss: 3.283041474074856
Validation loss: 2.5686054617318477

Epoch: 6| Step: 4
Training loss: 2.7087402233727187
Validation loss: 2.5372144219849426

Epoch: 6| Step: 5
Training loss: 2.8454469082386655
Validation loss: 2.5426263118837857

Epoch: 6| Step: 6
Training loss: 2.8203600934945023
Validation loss: 2.572606155718294

Epoch: 6| Step: 7
Training loss: 2.09223393452106
Validation loss: 2.591989650515504

Epoch: 6| Step: 8
Training loss: 2.21191039769288
Validation loss: 2.596505118325733

Epoch: 6| Step: 9
Training loss: 2.5276014618171656
Validation loss: 2.630013837581025

Epoch: 6| Step: 10
Training loss: 2.5599694201013903
Validation loss: 2.6033454128375517

Epoch: 6| Step: 11
Training loss: 2.447173948770453
Validation loss: 2.5961913524333147

Epoch: 6| Step: 12
Training loss: 2.774258086544151
Validation loss: 2.588632082185913

Epoch: 6| Step: 13
Training loss: 2.5403834266817533
Validation loss: 2.590873009268105

Epoch: 137| Step: 0
Training loss: 2.624262751635976
Validation loss: 2.5828761249592054

Epoch: 6| Step: 1
Training loss: 3.1208013175541085
Validation loss: 2.5759779615276672

Epoch: 6| Step: 2
Training loss: 1.8486028911669907
Validation loss: 2.5638815434311537

Epoch: 6| Step: 3
Training loss: 2.7655387908085465
Validation loss: 2.5569168523562076

Epoch: 6| Step: 4
Training loss: 2.8403140259792257
Validation loss: 2.5725077499725266

Epoch: 6| Step: 5
Training loss: 2.8884795603980655
Validation loss: 2.574880416439777

Epoch: 6| Step: 6
Training loss: 2.244261948349626
Validation loss: 2.5833809623601405

Epoch: 6| Step: 7
Training loss: 2.333976305065808
Validation loss: 2.586732047420981

Epoch: 6| Step: 8
Training loss: 2.8398662498034057
Validation loss: 2.595684072215216

Epoch: 6| Step: 9
Training loss: 2.9740184414874795
Validation loss: 2.57588170395284

Epoch: 6| Step: 10
Training loss: 2.7141672732389917
Validation loss: 2.5701422913170546

Epoch: 6| Step: 11
Training loss: 2.7154643934230185
Validation loss: 2.5703719525855107

Epoch: 6| Step: 12
Training loss: 1.9854654034626662
Validation loss: 2.55515483048732

Epoch: 6| Step: 13
Training loss: 0.8061072038273491
Validation loss: 2.542707552531245

Epoch: 138| Step: 0
Training loss: 2.5340630241691753
Validation loss: 2.524190233900629

Epoch: 6| Step: 1
Training loss: 2.534644782104142
Validation loss: 2.515906006196847

Epoch: 6| Step: 2
Training loss: 2.589431937086862
Validation loss: 2.5221375800237342

Epoch: 6| Step: 3
Training loss: 2.327071802924086
Validation loss: 2.5212071686583757

Epoch: 6| Step: 4
Training loss: 2.7761957771127896
Validation loss: 2.5472835573182584

Epoch: 6| Step: 5
Training loss: 2.7733223044958653
Validation loss: 2.5750293401871907

Epoch: 6| Step: 6
Training loss: 3.0327593005239555
Validation loss: 2.5688182383320646

Epoch: 6| Step: 7
Training loss: 2.0140996084649347
Validation loss: 2.586694800146777

Epoch: 6| Step: 8
Training loss: 2.307908939317185
Validation loss: 2.5635795600228133

Epoch: 6| Step: 9
Training loss: 3.090128001799421
Validation loss: 2.5374911606931354

Epoch: 6| Step: 10
Training loss: 2.097286141988487
Validation loss: 2.5356501966120315

Epoch: 6| Step: 11
Training loss: 2.727275591184095
Validation loss: 2.5219235135409157

Epoch: 6| Step: 12
Training loss: 2.089592977433723
Validation loss: 2.5047444556723013

Epoch: 6| Step: 13
Training loss: 2.291786838039424
Validation loss: 2.49174289040098

Epoch: 139| Step: 0
Training loss: 2.4207092432816117
Validation loss: 2.473397128964574

Epoch: 6| Step: 1
Training loss: 2.839292113236091
Validation loss: 2.4695937102702623

Epoch: 6| Step: 2
Training loss: 2.6415938005315724
Validation loss: 2.4674693563691514

Epoch: 6| Step: 3
Training loss: 2.5072235651808836
Validation loss: 2.466555559748455

Epoch: 6| Step: 4
Training loss: 2.3814209924214893
Validation loss: 2.480160376943265

Epoch: 6| Step: 5
Training loss: 2.4391198277991166
Validation loss: 2.483144947712943

Epoch: 6| Step: 6
Training loss: 2.221957936730873
Validation loss: 2.4855622508952475

Epoch: 6| Step: 7
Training loss: 2.215262452500713
Validation loss: 2.4889685256569094

Epoch: 6| Step: 8
Training loss: 2.8115581206885127
Validation loss: 2.501893634829673

Epoch: 6| Step: 9
Training loss: 2.4664480365914483
Validation loss: 2.5161724051669982

Epoch: 6| Step: 10
Training loss: 3.0020627241907496
Validation loss: 2.5598897437641814

Epoch: 6| Step: 11
Training loss: 2.400885013481784
Validation loss: 2.546325679715997

Epoch: 6| Step: 12
Training loss: 2.4029299137214903
Validation loss: 2.539509067436942

Epoch: 6| Step: 13
Training loss: 2.1289066979644025
Validation loss: 2.5149648691058957

Epoch: 140| Step: 0
Training loss: 2.6927424907669932
Validation loss: 2.5128793072888103

Epoch: 6| Step: 1
Training loss: 2.239634372809734
Validation loss: 2.5074372323698686

Epoch: 6| Step: 2
Training loss: 2.6391014805428137
Validation loss: 2.5131009840113143

Epoch: 6| Step: 3
Training loss: 2.73479183834499
Validation loss: 2.496666981432703

Epoch: 6| Step: 4
Training loss: 1.7283877567905548
Validation loss: 2.5085359248779495

Epoch: 6| Step: 5
Training loss: 3.0084229481488687
Validation loss: 2.528221950438767

Epoch: 6| Step: 6
Training loss: 2.0061459285564993
Validation loss: 2.542974204980365

Epoch: 6| Step: 7
Training loss: 2.400670506275217
Validation loss: 2.555943853781341

Epoch: 6| Step: 8
Training loss: 2.96723626344294
Validation loss: 2.560350914027948

Epoch: 6| Step: 9
Training loss: 2.5581501583499775
Validation loss: 2.552691629796655

Epoch: 6| Step: 10
Training loss: 2.346692590443876
Validation loss: 2.526030969084371

Epoch: 6| Step: 11
Training loss: 2.509899851256257
Validation loss: 2.5337599242828537

Epoch: 6| Step: 12
Training loss: 2.4306036396417148
Validation loss: 2.5356205912021728

Epoch: 6| Step: 13
Training loss: 2.3940684134157975
Validation loss: 2.5158208659842405

Epoch: 141| Step: 0
Training loss: 2.3940942063626505
Validation loss: 2.5091865789294867

Epoch: 6| Step: 1
Training loss: 2.9828113234184426
Validation loss: 2.5025463897669287

Epoch: 6| Step: 2
Training loss: 2.3888560213987153
Validation loss: 2.513392782933233

Epoch: 6| Step: 3
Training loss: 1.9839897682941312
Validation loss: 2.5257356496161476

Epoch: 6| Step: 4
Training loss: 2.543546033925232
Validation loss: 2.5421772162828598

Epoch: 6| Step: 5
Training loss: 2.1759513089959284
Validation loss: 2.5362629030690362

Epoch: 6| Step: 6
Training loss: 2.681763759378238
Validation loss: 2.5540982343541123

Epoch: 6| Step: 7
Training loss: 2.398122959449264
Validation loss: 2.5309156113167086

Epoch: 6| Step: 8
Training loss: 2.435172706134744
Validation loss: 2.516771476544505

Epoch: 6| Step: 9
Training loss: 2.4401594472599033
Validation loss: 2.4741801062221165

Epoch: 6| Step: 10
Training loss: 1.913914951164852
Validation loss: 2.4711254618343887

Epoch: 6| Step: 11
Training loss: 3.030206402336197
Validation loss: 2.4625145852137083

Epoch: 6| Step: 12
Training loss: 2.174551761961071
Validation loss: 2.4636154342402166

Epoch: 6| Step: 13
Training loss: 3.130247669110338
Validation loss: 2.4462317440883012

Epoch: 142| Step: 0
Training loss: 2.386596876363613
Validation loss: 2.4615382619997033

Epoch: 6| Step: 1
Training loss: 2.4470664854382838
Validation loss: 2.49518432411275

Epoch: 6| Step: 2
Training loss: 2.909105108508222
Validation loss: 2.5107447646764522

Epoch: 6| Step: 3
Training loss: 2.0988700097166544
Validation loss: 2.524111774330496

Epoch: 6| Step: 4
Training loss: 2.4055295584049396
Validation loss: 2.53719162286844

Epoch: 6| Step: 5
Training loss: 2.728150350795911
Validation loss: 2.556841329165484

Epoch: 6| Step: 6
Training loss: 2.3570104206746616
Validation loss: 2.5880306110222926

Epoch: 6| Step: 7
Training loss: 2.720722929587377
Validation loss: 2.5705031716870597

Epoch: 6| Step: 8
Training loss: 3.2371324956562395
Validation loss: 2.5460959004780848

Epoch: 6| Step: 9
Training loss: 2.2433277380969407
Validation loss: 2.509419925809437

Epoch: 6| Step: 10
Training loss: 2.4120963277734178
Validation loss: 2.482691788941045

Epoch: 6| Step: 11
Training loss: 2.8972259210173013
Validation loss: 2.4616538613816195

Epoch: 6| Step: 12
Training loss: 1.655302676502452
Validation loss: 2.4669334646545895

Epoch: 6| Step: 13
Training loss: 1.7320720056979049
Validation loss: 2.4650665027057834

Epoch: 143| Step: 0
Training loss: 3.1755256878452487
Validation loss: 2.469886220286166

Epoch: 6| Step: 1
Training loss: 2.683465102220259
Validation loss: 2.475095069404258

Epoch: 6| Step: 2
Training loss: 2.595446755498217
Validation loss: 2.4967199126851463

Epoch: 6| Step: 3
Training loss: 1.9937753370821598
Validation loss: 2.494779810565901

Epoch: 6| Step: 4
Training loss: 1.7406975229382977
Validation loss: 2.497701556359531

Epoch: 6| Step: 5
Training loss: 2.6947377352238573
Validation loss: 2.495955523271264

Epoch: 6| Step: 6
Training loss: 2.760682511873824
Validation loss: 2.488237424865597

Epoch: 6| Step: 7
Training loss: 2.5129365949726594
Validation loss: 2.489757827435654

Epoch: 6| Step: 8
Training loss: 2.12502266366878
Validation loss: 2.5020730416863404

Epoch: 6| Step: 9
Training loss: 2.0151129966838823
Validation loss: 2.514538497138346

Epoch: 6| Step: 10
Training loss: 1.6464795964399073
Validation loss: 2.5231134558444084

Epoch: 6| Step: 11
Training loss: 2.964348029107058
Validation loss: 2.515870363792505

Epoch: 6| Step: 12
Training loss: 2.3202561907887573
Validation loss: 2.5173523331148346

Epoch: 6| Step: 13
Training loss: 2.4802375745805247
Validation loss: 2.49930665645977

Epoch: 144| Step: 0
Training loss: 2.019374819218053
Validation loss: 2.5080530532165044

Epoch: 6| Step: 1
Training loss: 1.693503121827331
Validation loss: 2.4941920218475695

Epoch: 6| Step: 2
Training loss: 2.0872461450148014
Validation loss: 2.494377892310561

Epoch: 6| Step: 3
Training loss: 2.56443341517083
Validation loss: 2.4916029334641383

Epoch: 6| Step: 4
Training loss: 2.5103433263256707
Validation loss: 2.4835255190138215

Epoch: 6| Step: 5
Training loss: 1.9993594455143762
Validation loss: 2.493439016464245

Epoch: 6| Step: 6
Training loss: 2.6559084504389525
Validation loss: 2.4763735076061786

Epoch: 6| Step: 7
Training loss: 2.25585292798727
Validation loss: 2.470630750236893

Epoch: 6| Step: 8
Training loss: 2.9787053282313916
Validation loss: 2.4646142243272053

Epoch: 6| Step: 9
Training loss: 1.899976632325882
Validation loss: 2.460143222037799

Epoch: 6| Step: 10
Training loss: 2.5205914299864998
Validation loss: 2.4534966933320392

Epoch: 6| Step: 11
Training loss: 2.6299036636404187
Validation loss: 2.459495241346966

Epoch: 6| Step: 12
Training loss: 2.7219599048147622
Validation loss: 2.4790375688760853

Epoch: 6| Step: 13
Training loss: 3.0222787139636758
Validation loss: 2.4935362934081464

Epoch: 145| Step: 0
Training loss: 2.5423232517678573
Validation loss: 2.4985854228123396

Epoch: 6| Step: 1
Training loss: 2.944967963104342
Validation loss: 2.511825041538603

Epoch: 6| Step: 2
Training loss: 2.0183458520116218
Validation loss: 2.5208012375347297

Epoch: 6| Step: 3
Training loss: 2.0946711321701605
Validation loss: 2.5097536794356565

Epoch: 6| Step: 4
Training loss: 2.33685437838405
Validation loss: 2.4982489062463507

Epoch: 6| Step: 5
Training loss: 2.086512797027769
Validation loss: 2.501881713672916

Epoch: 6| Step: 6
Training loss: 2.5819448205561026
Validation loss: 2.4914252864701645

Epoch: 6| Step: 7
Training loss: 1.8589378291789873
Validation loss: 2.4781915703706705

Epoch: 6| Step: 8
Training loss: 2.2204394288798373
Validation loss: 2.498286123284966

Epoch: 6| Step: 9
Training loss: 2.7912011588743937
Validation loss: 2.502617893785523

Epoch: 6| Step: 10
Training loss: 2.3914607961840098
Validation loss: 2.487918625851402

Epoch: 6| Step: 11
Training loss: 1.9501266047141819
Validation loss: 2.482110117238856

Epoch: 6| Step: 12
Training loss: 2.88133900933131
Validation loss: 2.4869936830474617

Epoch: 6| Step: 13
Training loss: 2.2372588640413174
Validation loss: 2.4980937417115374

Epoch: 146| Step: 0
Training loss: 1.6875802480195896
Validation loss: 2.5045797893987762

Epoch: 6| Step: 1
Training loss: 2.149676932968695
Validation loss: 2.5179428930619214

Epoch: 6| Step: 2
Training loss: 1.6697019197932617
Validation loss: 2.55316765866396

Epoch: 6| Step: 3
Training loss: 2.5065812270165586
Validation loss: 2.5626809841364837

Epoch: 6| Step: 4
Training loss: 2.682219974090567
Validation loss: 2.589894901665653

Epoch: 6| Step: 5
Training loss: 1.4707832871839064
Validation loss: 2.590209732152347

Epoch: 6| Step: 6
Training loss: 2.502590744400682
Validation loss: 2.610912149017488

Epoch: 6| Step: 7
Training loss: 3.066000047737216
Validation loss: 2.6079600408462777

Epoch: 6| Step: 8
Training loss: 2.700321220787366
Validation loss: 2.5906127091020505

Epoch: 6| Step: 9
Training loss: 2.6393532483855178
Validation loss: 2.55086432637032

Epoch: 6| Step: 10
Training loss: 2.8012226773061086
Validation loss: 2.5098748367633505

Epoch: 6| Step: 11
Training loss: 2.4456639631420285
Validation loss: 2.491676704347285

Epoch: 6| Step: 12
Training loss: 2.0617459392597817
Validation loss: 2.500574724728814

Epoch: 6| Step: 13
Training loss: 2.559240454559546
Validation loss: 2.495514668438285

Epoch: 147| Step: 0
Training loss: 2.5660619403145284
Validation loss: 2.536335453829395

Epoch: 6| Step: 1
Training loss: 2.298610524628543
Validation loss: 2.5843313620065462

Epoch: 6| Step: 2
Training loss: 2.1368684873121864
Validation loss: 2.5849393648166434

Epoch: 6| Step: 3
Training loss: 2.311394195102295
Validation loss: 2.564925340851117

Epoch: 6| Step: 4
Training loss: 2.5340428897928247
Validation loss: 2.539663455039811

Epoch: 6| Step: 5
Training loss: 2.210518409719646
Validation loss: 2.4930515252902263

Epoch: 6| Step: 6
Training loss: 2.919500028317218
Validation loss: 2.4605402758547243

Epoch: 6| Step: 7
Training loss: 2.661090703508583
Validation loss: 2.4414741443012424

Epoch: 6| Step: 8
Training loss: 2.170236092658118
Validation loss: 2.4222119983751353

Epoch: 6| Step: 9
Training loss: 2.0752451740333315
Validation loss: 2.4330555795098263

Epoch: 6| Step: 10
Training loss: 2.556704130615259
Validation loss: 2.4450121304606003

Epoch: 6| Step: 11
Training loss: 2.511145067923106
Validation loss: 2.4464578848449214

Epoch: 6| Step: 12
Training loss: 2.3581028217937945
Validation loss: 2.458201294473377

Epoch: 6| Step: 13
Training loss: 3.2148051856359503
Validation loss: 2.497141375823793

Epoch: 148| Step: 0
Training loss: 1.8753244755049017
Validation loss: 2.482305320793869

Epoch: 6| Step: 1
Training loss: 2.70281742529057
Validation loss: 2.4792484267552655

Epoch: 6| Step: 2
Training loss: 2.526207410480743
Validation loss: 2.4831668575662507

Epoch: 6| Step: 3
Training loss: 2.3914261017965837
Validation loss: 2.495411091398509

Epoch: 6| Step: 4
Training loss: 2.3204734052873772
Validation loss: 2.5247519401408636

Epoch: 6| Step: 5
Training loss: 2.72353030477254
Validation loss: 2.541764293942757

Epoch: 6| Step: 6
Training loss: 1.7648771609605098
Validation loss: 2.585856671717175

Epoch: 6| Step: 7
Training loss: 3.416083464431441
Validation loss: 2.584095064237294

Epoch: 6| Step: 8
Training loss: 2.168141621063822
Validation loss: 2.522007967435042

Epoch: 6| Step: 9
Training loss: 2.3808121085853706
Validation loss: 2.4474792431757693

Epoch: 6| Step: 10
Training loss: 1.858533909440854
Validation loss: 2.4196727402995952

Epoch: 6| Step: 11
Training loss: 2.113367667696453
Validation loss: 2.4141012336609515

Epoch: 6| Step: 12
Training loss: 1.741397695747131
Validation loss: 2.3995265243271096

Epoch: 6| Step: 13
Training loss: 2.932964963613306
Validation loss: 2.4083853596953935

Epoch: 149| Step: 0
Training loss: 3.145421100073812
Validation loss: 2.3997563527283443

Epoch: 6| Step: 1
Training loss: 1.796185834000049
Validation loss: 2.4039057166053874

Epoch: 6| Step: 2
Training loss: 2.3979669662312855
Validation loss: 2.4188731654058424

Epoch: 6| Step: 3
Training loss: 2.763210557373633
Validation loss: 2.4757146792264266

Epoch: 6| Step: 4
Training loss: 2.406512159458291
Validation loss: 2.5425425287390038

Epoch: 6| Step: 5
Training loss: 2.4224538788080965
Validation loss: 2.5966861916689337

Epoch: 6| Step: 6
Training loss: 2.342549130831387
Validation loss: 2.624758258554286

Epoch: 6| Step: 7
Training loss: 2.065193267349656
Validation loss: 2.6396095132457402

Epoch: 6| Step: 8
Training loss: 2.1208401523123226
Validation loss: 2.6089762701791392

Epoch: 6| Step: 9
Training loss: 2.369786815149281
Validation loss: 2.550289290094337

Epoch: 6| Step: 10
Training loss: 2.6467816513156524
Validation loss: 2.4712484979373643

Epoch: 6| Step: 11
Training loss: 2.4447621466587197
Validation loss: 2.4347754902712673

Epoch: 6| Step: 12
Training loss: 2.257462101446076
Validation loss: 2.423992038036659

Epoch: 6| Step: 13
Training loss: 2.535206751621654
Validation loss: 2.41159203707371

Epoch: 150| Step: 0
Training loss: 2.3105113783727282
Validation loss: 2.4245396277828135

Epoch: 6| Step: 1
Training loss: 2.5047206179213544
Validation loss: 2.4230857149021965

Epoch: 6| Step: 2
Training loss: 2.3528321346092462
Validation loss: 2.433377213517209

Epoch: 6| Step: 3
Training loss: 2.3261749498169224
Validation loss: 2.4567405340494646

Epoch: 6| Step: 4
Training loss: 2.4818288363349654
Validation loss: 2.4585386596856944

Epoch: 6| Step: 5
Training loss: 2.029065174904145
Validation loss: 2.4714695344371345

Epoch: 6| Step: 6
Training loss: 1.9616878335416312
Validation loss: 2.4842474593775057

Epoch: 6| Step: 7
Training loss: 2.6176209048208223
Validation loss: 2.4988688155525796

Epoch: 6| Step: 8
Training loss: 2.2876538834638738
Validation loss: 2.5162577112708733

Epoch: 6| Step: 9
Training loss: 2.4496622125191743
Validation loss: 2.522546911049469

Epoch: 6| Step: 10
Training loss: 2.225957848615071
Validation loss: 2.5207773960232562

Epoch: 6| Step: 11
Training loss: 2.851148099704783
Validation loss: 2.509374826568907

Epoch: 6| Step: 12
Training loss: 1.6911740044480705
Validation loss: 2.5008858403373773

Epoch: 6| Step: 13
Training loss: 2.2721709298725976
Validation loss: 2.4735993079574814

Epoch: 151| Step: 0
Training loss: 2.6330280159149035
Validation loss: 2.467776315106312

Epoch: 6| Step: 1
Training loss: 2.233713759100027
Validation loss: 2.46870682973151

Epoch: 6| Step: 2
Training loss: 2.9105612658599402
Validation loss: 2.4570214212511434

Epoch: 6| Step: 3
Training loss: 2.446740071947834
Validation loss: 2.4622331033523146

Epoch: 6| Step: 4
Training loss: 2.0273323426265653
Validation loss: 2.460369885716868

Epoch: 6| Step: 5
Training loss: 1.554974170114575
Validation loss: 2.445958529945387

Epoch: 6| Step: 6
Training loss: 1.8931191126875768
Validation loss: 2.4387326191090386

Epoch: 6| Step: 7
Training loss: 2.134084692406849
Validation loss: 2.4467714967064604

Epoch: 6| Step: 8
Training loss: 2.297178702484833
Validation loss: 2.4329090031062433

Epoch: 6| Step: 9
Training loss: 1.9842272726023573
Validation loss: 2.433623576866597

Epoch: 6| Step: 10
Training loss: 2.1179706771881217
Validation loss: 2.4148739801788803

Epoch: 6| Step: 11
Training loss: 2.392179295521426
Validation loss: 2.4109822386236717

Epoch: 6| Step: 12
Training loss: 2.409862234522937
Validation loss: 2.4515374405601924

Epoch: 6| Step: 13
Training loss: 2.0927124868997002
Validation loss: 2.4620359730754013

Epoch: 152| Step: 0
Training loss: 2.1133254746412296
Validation loss: 2.4586825893524384

Epoch: 6| Step: 1
Training loss: 2.2250785299437195
Validation loss: 2.4646969879220775

Epoch: 6| Step: 2
Training loss: 2.7614015561635226
Validation loss: 2.4723455223502815

Epoch: 6| Step: 3
Training loss: 2.555931045294607
Validation loss: 2.4681427191706575

Epoch: 6| Step: 4
Training loss: 2.6519320228805814
Validation loss: 2.4575764919892324

Epoch: 6| Step: 5
Training loss: 1.835576383098199
Validation loss: 2.4797679120007214

Epoch: 6| Step: 6
Training loss: 1.831554749424756
Validation loss: 2.489094362875786

Epoch: 6| Step: 7
Training loss: 1.9436373564533274
Validation loss: 2.509797193212894

Epoch: 6| Step: 8
Training loss: 2.203978352954436
Validation loss: 2.514136789647902

Epoch: 6| Step: 9
Training loss: 2.387453456245232
Validation loss: 2.515388155079089

Epoch: 6| Step: 10
Training loss: 2.2907150604737487
Validation loss: 2.535645829931859

Epoch: 6| Step: 11
Training loss: 2.0694529926484773
Validation loss: 2.5228867377583173

Epoch: 6| Step: 12
Training loss: 2.0522142036133086
Validation loss: 2.4888780353141513

Epoch: 6| Step: 13
Training loss: 1.8514031450289192
Validation loss: 2.4657335847807675

Epoch: 153| Step: 0
Training loss: 2.1954328293590626
Validation loss: 2.45097594648811

Epoch: 6| Step: 1
Training loss: 1.967433549856718
Validation loss: 2.4430541145731977

Epoch: 6| Step: 2
Training loss: 2.42292359324608
Validation loss: 2.447699281932134

Epoch: 6| Step: 3
Training loss: 1.9836278394885145
Validation loss: 2.459127129744589

Epoch: 6| Step: 4
Training loss: 2.138641106371135
Validation loss: 2.4631462876891668

Epoch: 6| Step: 5
Training loss: 2.1842166783228647
Validation loss: 2.4564713534775944

Epoch: 6| Step: 6
Training loss: 2.4969271848952066
Validation loss: 2.4822248938683726

Epoch: 6| Step: 7
Training loss: 2.737984765037578
Validation loss: 2.507860617395966

Epoch: 6| Step: 8
Training loss: 1.6662773472343955
Validation loss: 2.5217741008526495

Epoch: 6| Step: 9
Training loss: 1.9468155534954166
Validation loss: 2.5407630616001606

Epoch: 6| Step: 10
Training loss: 2.295708600190744
Validation loss: 2.55148020974342

Epoch: 6| Step: 11
Training loss: 2.257756532813581
Validation loss: 2.5412047662594106

Epoch: 6| Step: 12
Training loss: 2.279611390943527
Validation loss: 2.517855757358349

Epoch: 6| Step: 13
Training loss: 2.0456182684060633
Validation loss: 2.476898616704998

Epoch: 154| Step: 0
Training loss: 2.037230388378907
Validation loss: 2.4328838429527426

Epoch: 6| Step: 1
Training loss: 1.8530753992657096
Validation loss: 2.4143630651500785

Epoch: 6| Step: 2
Training loss: 2.0823988026442954
Validation loss: 2.391234137242745

Epoch: 6| Step: 3
Training loss: 2.065136005273231
Validation loss: 2.385217196069455

Epoch: 6| Step: 4
Training loss: 1.8173728421945747
Validation loss: 2.385546136453765

Epoch: 6| Step: 5
Training loss: 2.5916923726106167
Validation loss: 2.4008934062952934

Epoch: 6| Step: 6
Training loss: 2.1673338914203817
Validation loss: 2.402747093480697

Epoch: 6| Step: 7
Training loss: 2.393031286804254
Validation loss: 2.44322214159001

Epoch: 6| Step: 8
Training loss: 2.2165915507541656
Validation loss: 2.471789270017876

Epoch: 6| Step: 9
Training loss: 2.1175687664805425
Validation loss: 2.514424101534505

Epoch: 6| Step: 10
Training loss: 2.2278047007738446
Validation loss: 2.5005436357470994

Epoch: 6| Step: 11
Training loss: 2.862660172824515
Validation loss: 2.4965854039699322

Epoch: 6| Step: 12
Training loss: 1.9870995867941608
Validation loss: 2.5083744131424255

Epoch: 6| Step: 13
Training loss: 2.6372792192229597
Validation loss: 2.501951515265312

Epoch: 155| Step: 0
Training loss: 1.9841147424834915
Validation loss: 2.4832823761411564

Epoch: 6| Step: 1
Training loss: 2.0323171306704815
Validation loss: 2.4859660177452083

Epoch: 6| Step: 2
Training loss: 2.2099512279531512
Validation loss: 2.4733599079665125

Epoch: 6| Step: 3
Training loss: 2.4899350693291376
Validation loss: 2.43792681642233

Epoch: 6| Step: 4
Training loss: 2.310371140724331
Validation loss: 2.459176800209635

Epoch: 6| Step: 5
Training loss: 2.3430557239921592
Validation loss: 2.4608486114559183

Epoch: 6| Step: 6
Training loss: 2.3283442451623673
Validation loss: 2.475580832138407

Epoch: 6| Step: 7
Training loss: 2.2732106518387285
Validation loss: 2.4740907505177727

Epoch: 6| Step: 8
Training loss: 2.0479435352051754
Validation loss: 2.437505706788843

Epoch: 6| Step: 9
Training loss: 1.8719584272895502
Validation loss: 2.403980007430021

Epoch: 6| Step: 10
Training loss: 1.6120034392156901
Validation loss: 2.3887299295738327

Epoch: 6| Step: 11
Training loss: 2.5564730409349323
Validation loss: 2.3796170384476873

Epoch: 6| Step: 12
Training loss: 1.92852630890438
Validation loss: 2.3928021281365326

Epoch: 6| Step: 13
Training loss: 2.391806416521318
Validation loss: 2.420850562391442

Epoch: 156| Step: 0
Training loss: 2.5245425045902694
Validation loss: 2.4607654538088157

Epoch: 6| Step: 1
Training loss: 1.891935036509723
Validation loss: 2.5185626087971436

Epoch: 6| Step: 2
Training loss: 1.7971623066632265
Validation loss: 2.586350993359535

Epoch: 6| Step: 3
Training loss: 2.2123707146236953
Validation loss: 2.5787414649036084

Epoch: 6| Step: 4
Training loss: 2.2889067821461704
Validation loss: 2.536726088696281

Epoch: 6| Step: 5
Training loss: 2.5385046712949975
Validation loss: 2.50281629570031

Epoch: 6| Step: 6
Training loss: 1.9441743761550998
Validation loss: 2.4831632007754116

Epoch: 6| Step: 7
Training loss: 2.4137888139066495
Validation loss: 2.4713409948026617

Epoch: 6| Step: 8
Training loss: 2.1604326012764674
Validation loss: 2.4621629233469626

Epoch: 6| Step: 9
Training loss: 2.362197905102596
Validation loss: 2.43493021296473

Epoch: 6| Step: 10
Training loss: 1.6078759035411765
Validation loss: 2.4154080652059458

Epoch: 6| Step: 11
Training loss: 2.433134130484781
Validation loss: 2.4133101531901673

Epoch: 6| Step: 12
Training loss: 1.9702169614494505
Validation loss: 2.406480917406737

Epoch: 6| Step: 13
Training loss: 2.288332982388567
Validation loss: 2.4132690761244513

Epoch: 157| Step: 0
Training loss: 2.526801073161494
Validation loss: 2.389348377084196

Epoch: 6| Step: 1
Training loss: 2.2679566060108045
Validation loss: 2.4060361724825423

Epoch: 6| Step: 2
Training loss: 2.2548810150152536
Validation loss: 2.4012657945170313

Epoch: 6| Step: 3
Training loss: 2.1341365295609935
Validation loss: 2.4246518403896733

Epoch: 6| Step: 4
Training loss: 1.7579302260924836
Validation loss: 2.4391038733101835

Epoch: 6| Step: 5
Training loss: 2.5180354919962182
Validation loss: 2.4614596884384663

Epoch: 6| Step: 6
Training loss: 2.3948329218999636
Validation loss: 2.4711043291222508

Epoch: 6| Step: 7
Training loss: 1.9813820202280548
Validation loss: 2.4761157898596697

Epoch: 6| Step: 8
Training loss: 1.8578275123291228
Validation loss: 2.5110597484192687

Epoch: 6| Step: 9
Training loss: 1.3809986610792826
Validation loss: 2.498318046910474

Epoch: 6| Step: 10
Training loss: 2.3475406764267213
Validation loss: 2.4831246926445436

Epoch: 6| Step: 11
Training loss: 1.9743211424540992
Validation loss: 2.468883126074117

Epoch: 6| Step: 12
Training loss: 2.1692989083465797
Validation loss: 2.4476105065017673

Epoch: 6| Step: 13
Training loss: 1.7820907750069832
Validation loss: 2.4262078170920436

Epoch: 158| Step: 0
Training loss: 2.2503570697165247
Validation loss: 2.4199285936410058

Epoch: 6| Step: 1
Training loss: 2.2197481516011823
Validation loss: 2.414823352800046

Epoch: 6| Step: 2
Training loss: 2.1754814229008526
Validation loss: 2.422742148401977

Epoch: 6| Step: 3
Training loss: 2.2257324813261308
Validation loss: 2.410206758426591

Epoch: 6| Step: 4
Training loss: 1.873135720732401
Validation loss: 2.409250880961971

Epoch: 6| Step: 5
Training loss: 2.0585050328517243
Validation loss: 2.410532765201767

Epoch: 6| Step: 6
Training loss: 1.6462628089910463
Validation loss: 2.398825640194473

Epoch: 6| Step: 7
Training loss: 2.0037328931395924
Validation loss: 2.3979195431026987

Epoch: 6| Step: 8
Training loss: 2.2848095231413392
Validation loss: 2.40144112556923

Epoch: 6| Step: 9
Training loss: 2.0212903505542927
Validation loss: 2.4045795107176655

Epoch: 6| Step: 10
Training loss: 1.626514609270363
Validation loss: 2.427039055752902

Epoch: 6| Step: 11
Training loss: 1.8514766753703131
Validation loss: 2.450534655529266

Epoch: 6| Step: 12
Training loss: 2.5233605907518397
Validation loss: 2.4795602124348983

Epoch: 6| Step: 13
Training loss: 2.2800026187547067
Validation loss: 2.536845276223631

Epoch: 159| Step: 0
Training loss: 1.8430521662755277
Validation loss: 2.593441283218943

Epoch: 6| Step: 1
Training loss: 1.665212744103221
Validation loss: 2.615646241035729

Epoch: 6| Step: 2
Training loss: 1.8017739561438015
Validation loss: 2.6453002852650727

Epoch: 6| Step: 3
Training loss: 1.7765036137869166
Validation loss: 2.6215318758327943

Epoch: 6| Step: 4
Training loss: 2.017316596334698
Validation loss: 2.602635190141533

Epoch: 6| Step: 5
Training loss: 2.0494892228367356
Validation loss: 2.584098213111549

Epoch: 6| Step: 6
Training loss: 2.197205294310634
Validation loss: 2.550639995567225

Epoch: 6| Step: 7
Training loss: 2.2801987825707455
Validation loss: 2.5332453034277154

Epoch: 6| Step: 8
Training loss: 2.388034389267401
Validation loss: 2.4913799221999096

Epoch: 6| Step: 9
Training loss: 2.165643328084082
Validation loss: 2.461881146151105

Epoch: 6| Step: 10
Training loss: 2.602214009954038
Validation loss: 2.4426144345443572

Epoch: 6| Step: 11
Training loss: 2.522085294026885
Validation loss: 2.415717469645966

Epoch: 6| Step: 12
Training loss: 1.6588832148030266
Validation loss: 2.3802358805640096

Epoch: 6| Step: 13
Training loss: 1.8702338359100088
Validation loss: 2.3691865768976164

Epoch: 160| Step: 0
Training loss: 1.7717603239326802
Validation loss: 2.3635274866096236

Epoch: 6| Step: 1
Training loss: 2.1062871867442987
Validation loss: 2.377328763978876

Epoch: 6| Step: 2
Training loss: 1.415823666945778
Validation loss: 2.417447133499429

Epoch: 6| Step: 3
Training loss: 2.0149311379528925
Validation loss: 2.448200092302035

Epoch: 6| Step: 4
Training loss: 2.3601865067573975
Validation loss: 2.4520809548033875

Epoch: 6| Step: 5
Training loss: 1.7452067398635362
Validation loss: 2.4396787938872957

Epoch: 6| Step: 6
Training loss: 2.2523150719739817
Validation loss: 2.4522024582834767

Epoch: 6| Step: 7
Training loss: 2.3158226886333955
Validation loss: 2.453614369453732

Epoch: 6| Step: 8
Training loss: 1.7022421412192008
Validation loss: 2.4549104943636064

Epoch: 6| Step: 9
Training loss: 2.6005512826854527
Validation loss: 2.479805547000774

Epoch: 6| Step: 10
Training loss: 1.652015310701445
Validation loss: 2.4877523079400787

Epoch: 6| Step: 11
Training loss: 2.19075761467101
Validation loss: 2.489678101536449

Epoch: 6| Step: 12
Training loss: 1.8895283821075992
Validation loss: 2.4688765863436877

Epoch: 6| Step: 13
Training loss: 2.794855336930718
Validation loss: 2.461949252620477

Epoch: 161| Step: 0
Training loss: 1.9348988453844602
Validation loss: 2.440351464853648

Epoch: 6| Step: 1
Training loss: 1.7767196733369843
Validation loss: 2.4274119743019926

Epoch: 6| Step: 2
Training loss: 2.451166136229587
Validation loss: 2.4238810000877344

Epoch: 6| Step: 3
Training loss: 2.4859374309470255
Validation loss: 2.4230801973915885

Epoch: 6| Step: 4
Training loss: 2.3366740924900418
Validation loss: 2.415924822615807

Epoch: 6| Step: 5
Training loss: 2.0000879745208096
Validation loss: 2.42622543341543

Epoch: 6| Step: 6
Training loss: 1.7845228143988139
Validation loss: 2.4143800554155717

Epoch: 6| Step: 7
Training loss: 2.6403917740072895
Validation loss: 2.4205457878956786

Epoch: 6| Step: 8
Training loss: 1.6607958470369795
Validation loss: 2.4513959714793856

Epoch: 6| Step: 9
Training loss: 1.624789444413638
Validation loss: 2.4480297276332075

Epoch: 6| Step: 10
Training loss: 2.154657411538129
Validation loss: 2.4615633542275894

Epoch: 6| Step: 11
Training loss: 1.682143434148984
Validation loss: 2.4352018725418283

Epoch: 6| Step: 12
Training loss: 1.641930269807471
Validation loss: 2.446822332670511

Epoch: 6| Step: 13
Training loss: 1.314854326845944
Validation loss: 2.4370675325174855

Epoch: 162| Step: 0
Training loss: 2.1890427734880276
Validation loss: 2.4421386775174185

Epoch: 6| Step: 1
Training loss: 2.4809729356561907
Validation loss: 2.4492703358922476

Epoch: 6| Step: 2
Training loss: 2.4187535998098313
Validation loss: 2.4470378616965425

Epoch: 6| Step: 3
Training loss: 2.0518781943504063
Validation loss: 2.4574844759052676

Epoch: 6| Step: 4
Training loss: 1.7896574272238883
Validation loss: 2.4309130167192055

Epoch: 6| Step: 5
Training loss: 1.8753086471835878
Validation loss: 2.4378346449313812

Epoch: 6| Step: 6
Training loss: 2.1846352483573726
Validation loss: 2.450087463746396

Epoch: 6| Step: 7
Training loss: 1.9938851696341215
Validation loss: 2.467418337980259

Epoch: 6| Step: 8
Training loss: 2.1641764146039093
Validation loss: 2.456040812169209

Epoch: 6| Step: 9
Training loss: 1.6672673414537988
Validation loss: 2.4656730845239676

Epoch: 6| Step: 10
Training loss: 1.2938052695442572
Validation loss: 2.4708492999918517

Epoch: 6| Step: 11
Training loss: 1.899562612181943
Validation loss: 2.488193733931472

Epoch: 6| Step: 12
Training loss: 1.7373277427854685
Validation loss: 2.5181994168491117

Epoch: 6| Step: 13
Training loss: 1.6222268430362425
Validation loss: 2.539340764677304

Epoch: 163| Step: 0
Training loss: 1.933946488698351
Validation loss: 2.568621271565283

Epoch: 6| Step: 1
Training loss: 1.9809783941917172
Validation loss: 2.5688869346705436

Epoch: 6| Step: 2
Training loss: 2.0424483094042145
Validation loss: 2.5546777117974653

Epoch: 6| Step: 3
Training loss: 1.919678650329053
Validation loss: 2.493065844526298

Epoch: 6| Step: 4
Training loss: 1.9559368187543125
Validation loss: 2.459062352096182

Epoch: 6| Step: 5
Training loss: 1.9437052510007644
Validation loss: 2.4432716548317526

Epoch: 6| Step: 6
Training loss: 1.6838034656308203
Validation loss: 2.4363293640941386

Epoch: 6| Step: 7
Training loss: 2.5155518325685255
Validation loss: 2.4370071116836125

Epoch: 6| Step: 8
Training loss: 2.282307732329821
Validation loss: 2.4389418824877187

Epoch: 6| Step: 9
Training loss: 1.8113820146742452
Validation loss: 2.449323017611735

Epoch: 6| Step: 10
Training loss: 1.4537249731400805
Validation loss: 2.478985053263038

Epoch: 6| Step: 11
Training loss: 2.1122961092636725
Validation loss: 2.504318170914418

Epoch: 6| Step: 12
Training loss: 2.3091589014846745
Validation loss: 2.496620201917669

Epoch: 6| Step: 13
Training loss: 1.8996088629221242
Validation loss: 2.496598138013155

Epoch: 164| Step: 0
Training loss: 2.1795321720249055
Validation loss: 2.455425321210137

Epoch: 6| Step: 1
Training loss: 2.1525391422483198
Validation loss: 2.4188038799558003

Epoch: 6| Step: 2
Training loss: 1.9562376929922818
Validation loss: 2.408720635213745

Epoch: 6| Step: 3
Training loss: 1.9755201644621432
Validation loss: 2.402031981464285

Epoch: 6| Step: 4
Training loss: 1.950027756615699
Validation loss: 2.423097233392479

Epoch: 6| Step: 5
Training loss: 1.8906268285316894
Validation loss: 2.431373685584122

Epoch: 6| Step: 6
Training loss: 1.7072662959871896
Validation loss: 2.44385373477832

Epoch: 6| Step: 7
Training loss: 2.2540187972875008
Validation loss: 2.4588311633158475

Epoch: 6| Step: 8
Training loss: 1.6262018454339842
Validation loss: 2.4589761752458976

Epoch: 6| Step: 9
Training loss: 2.394818585877673
Validation loss: 2.468620849363095

Epoch: 6| Step: 10
Training loss: 1.8107148949478857
Validation loss: 2.479192511476471

Epoch: 6| Step: 11
Training loss: 2.0821238885420694
Validation loss: 2.4827390477368367

Epoch: 6| Step: 12
Training loss: 1.7869115167537746
Validation loss: 2.4797719862930756

Epoch: 6| Step: 13
Training loss: 1.4918447370460186
Validation loss: 2.448980118139021

Epoch: 165| Step: 0
Training loss: 2.161712031048975
Validation loss: 2.4358118983431165

Epoch: 6| Step: 1
Training loss: 1.8187011659758252
Validation loss: 2.4302894045367083

Epoch: 6| Step: 2
Training loss: 1.4113315745886175
Validation loss: 2.4316093072819562

Epoch: 6| Step: 3
Training loss: 1.5487782493151683
Validation loss: 2.4143787780439774

Epoch: 6| Step: 4
Training loss: 2.2863794427584216
Validation loss: 2.4069569655455645

Epoch: 6| Step: 5
Training loss: 1.879741522693658
Validation loss: 2.423298099357766

Epoch: 6| Step: 6
Training loss: 1.836354179984603
Validation loss: 2.4343833202771856

Epoch: 6| Step: 7
Training loss: 1.9929632135222368
Validation loss: 2.432832795819288

Epoch: 6| Step: 8
Training loss: 1.4662608705135556
Validation loss: 2.4503613715064927

Epoch: 6| Step: 9
Training loss: 2.047205075738957
Validation loss: 2.447135308022646

Epoch: 6| Step: 10
Training loss: 1.8399564866435563
Validation loss: 2.4563925844420953

Epoch: 6| Step: 11
Training loss: 2.020162044861748
Validation loss: 2.4503759653199406

Epoch: 6| Step: 12
Training loss: 2.534900623006367
Validation loss: 2.4676742234773665

Epoch: 6| Step: 13
Training loss: 1.8607424027599067
Validation loss: 2.460873305471001

Epoch: 166| Step: 0
Training loss: 1.975713856770623
Validation loss: 2.438612006684205

Epoch: 6| Step: 1
Training loss: 2.1613212327487026
Validation loss: 2.435944275542477

Epoch: 6| Step: 2
Training loss: 1.6295440669227361
Validation loss: 2.409739737700039

Epoch: 6| Step: 3
Training loss: 1.8338741314043296
Validation loss: 2.415943541097937

Epoch: 6| Step: 4
Training loss: 1.646931543411034
Validation loss: 2.4058476806771134

Epoch: 6| Step: 5
Training loss: 2.2418581624351916
Validation loss: 2.4254113003190936

Epoch: 6| Step: 6
Training loss: 1.986819226255218
Validation loss: 2.441270616402093

Epoch: 6| Step: 7
Training loss: 2.1216518728614973
Validation loss: 2.4275159355657654

Epoch: 6| Step: 8
Training loss: 1.6260893178340403
Validation loss: 2.436975603092463

Epoch: 6| Step: 9
Training loss: 1.748910496663207
Validation loss: 2.441558616297215

Epoch: 6| Step: 10
Training loss: 2.0192573405882497
Validation loss: 2.4472105702287745

Epoch: 6| Step: 11
Training loss: 1.9993740532775335
Validation loss: 2.4766500440792805

Epoch: 6| Step: 12
Training loss: 1.8957179177613197
Validation loss: 2.4877264627460374

Epoch: 6| Step: 13
Training loss: 1.975516724894407
Validation loss: 2.469956396735274

Epoch: 167| Step: 0
Training loss: 2.5300354103957607
Validation loss: 2.459649312715942

Epoch: 6| Step: 1
Training loss: 2.158224335303015
Validation loss: 2.4439718710082166

Epoch: 6| Step: 2
Training loss: 1.4241458240112583
Validation loss: 2.432606052378087

Epoch: 6| Step: 3
Training loss: 1.413392218961521
Validation loss: 2.396641575045864

Epoch: 6| Step: 4
Training loss: 2.2366281099971
Validation loss: 2.3946458467618568

Epoch: 6| Step: 5
Training loss: 2.3902383130061837
Validation loss: 2.381800309645868

Epoch: 6| Step: 6
Training loss: 1.9198361258309982
Validation loss: 2.393262294900772

Epoch: 6| Step: 7
Training loss: 1.764681673818853
Validation loss: 2.392549348699563

Epoch: 6| Step: 8
Training loss: 1.7899425624177892
Validation loss: 2.3992911519132116

Epoch: 6| Step: 9
Training loss: 1.343819328116532
Validation loss: 2.425450602138715

Epoch: 6| Step: 10
Training loss: 2.6289016247463493
Validation loss: 2.429368054718748

Epoch: 6| Step: 11
Training loss: 1.0147841273788498
Validation loss: 2.4635648875696683

Epoch: 6| Step: 12
Training loss: 1.4727603460701904
Validation loss: 2.4809730989208525

Epoch: 6| Step: 13
Training loss: 1.898829855228492
Validation loss: 2.499738277558726

Epoch: 168| Step: 0
Training loss: 1.302213230011597
Validation loss: 2.5177312130565803

Epoch: 6| Step: 1
Training loss: 1.679503319866764
Validation loss: 2.5444570932024506

Epoch: 6| Step: 2
Training loss: 1.3851387156212032
Validation loss: 2.5396416540471103

Epoch: 6| Step: 3
Training loss: 1.4730982433376723
Validation loss: 2.4999942748711774

Epoch: 6| Step: 4
Training loss: 1.5750375894571929
Validation loss: 2.462627514359546

Epoch: 6| Step: 5
Training loss: 1.9837914757818589
Validation loss: 2.4302541051483106

Epoch: 6| Step: 6
Training loss: 2.0070121149477695
Validation loss: 2.406117787622318

Epoch: 6| Step: 7
Training loss: 2.313608677039752
Validation loss: 2.388132993650696

Epoch: 6| Step: 8
Training loss: 1.7769830694084379
Validation loss: 2.389795970713681

Epoch: 6| Step: 9
Training loss: 2.482063033417054
Validation loss: 2.4070939101171804

Epoch: 6| Step: 10
Training loss: 1.7563975424915932
Validation loss: 2.4116565760443276

Epoch: 6| Step: 11
Training loss: 2.0704336454826753
Validation loss: 2.417089937234022

Epoch: 6| Step: 12
Training loss: 2.3987565713686085
Validation loss: 2.439978231347742

Epoch: 6| Step: 13
Training loss: 1.9381711474217127
Validation loss: 2.4239879799798674

Epoch: 169| Step: 0
Training loss: 1.815013589519142
Validation loss: 2.4402002681266843

Epoch: 6| Step: 1
Training loss: 1.4916762829404904
Validation loss: 2.4679180761749473

Epoch: 6| Step: 2
Training loss: 2.0983485494864373
Validation loss: 2.476017147219268

Epoch: 6| Step: 3
Training loss: 1.9104647709050122
Validation loss: 2.4809686101720625

Epoch: 6| Step: 4
Training loss: 1.742181478584045
Validation loss: 2.4837589512667577

Epoch: 6| Step: 5
Training loss: 1.8892490645069746
Validation loss: 2.4783446480541667

Epoch: 6| Step: 6
Training loss: 2.101098445439718
Validation loss: 2.4812350339348543

Epoch: 6| Step: 7
Training loss: 1.6687546604962937
Validation loss: 2.4576679867194553

Epoch: 6| Step: 8
Training loss: 1.9859429120005796
Validation loss: 2.450729018307346

Epoch: 6| Step: 9
Training loss: 1.7586066592542138
Validation loss: 2.4391741833745706

Epoch: 6| Step: 10
Training loss: 2.0978460527927836
Validation loss: 2.434000612290398

Epoch: 6| Step: 11
Training loss: 1.724384919677607
Validation loss: 2.4211264033882673

Epoch: 6| Step: 12
Training loss: 1.9640086164343746
Validation loss: 2.409379302666957

Epoch: 6| Step: 13
Training loss: 1.7929998656920145
Validation loss: 2.424832096721116

Epoch: 170| Step: 0
Training loss: 2.2853327756337243
Validation loss: 2.4259922571961483

Epoch: 6| Step: 1
Training loss: 1.7118370443581268
Validation loss: 2.432529308650637

Epoch: 6| Step: 2
Training loss: 1.1818520096792566
Validation loss: 2.426169741643239

Epoch: 6| Step: 3
Training loss: 1.9124152744449994
Validation loss: 2.4552981468243837

Epoch: 6| Step: 4
Training loss: 2.2980785719783037
Validation loss: 2.4833431989324213

Epoch: 6| Step: 5
Training loss: 1.7447848267682124
Validation loss: 2.465098443663417

Epoch: 6| Step: 6
Training loss: 1.644289483717894
Validation loss: 2.4392496060878175

Epoch: 6| Step: 7
Training loss: 2.432182380350335
Validation loss: 2.4185911400670363

Epoch: 6| Step: 8
Training loss: 1.9342846185279023
Validation loss: 2.406129978672146

Epoch: 6| Step: 9
Training loss: 1.5061399047630757
Validation loss: 2.3699912415290654

Epoch: 6| Step: 10
Training loss: 1.9286791062444504
Validation loss: 2.3799839584941944

Epoch: 6| Step: 11
Training loss: 1.7792028743564592
Validation loss: 2.3692074175954128

Epoch: 6| Step: 12
Training loss: 1.4573251872630468
Validation loss: 2.371404973083826

Epoch: 6| Step: 13
Training loss: 1.4597955003988123
Validation loss: 2.3838182897649163

Epoch: 171| Step: 0
Training loss: 1.8103484175635511
Validation loss: 2.3883556082506097

Epoch: 6| Step: 1
Training loss: 1.7064822643217903
Validation loss: 2.4007455005495286

Epoch: 6| Step: 2
Training loss: 2.133318606961603
Validation loss: 2.4376217086271867

Epoch: 6| Step: 3
Training loss: 2.3728579850235123
Validation loss: 2.430781748179451

Epoch: 6| Step: 4
Training loss: 2.004045210216038
Validation loss: 2.453969700936381

Epoch: 6| Step: 5
Training loss: 1.2911028810870928
Validation loss: 2.4400795685503214

Epoch: 6| Step: 6
Training loss: 1.7205780018444117
Validation loss: 2.444197272674963

Epoch: 6| Step: 7
Training loss: 1.7382136985426009
Validation loss: 2.486428145395115

Epoch: 6| Step: 8
Training loss: 1.296327452373497
Validation loss: 2.499073116182163

Epoch: 6| Step: 9
Training loss: 1.6961451300838406
Validation loss: 2.4809925356053864

Epoch: 6| Step: 10
Training loss: 2.147776221029015
Validation loss: 2.503095271434423

Epoch: 6| Step: 11
Training loss: 1.8264148244559426
Validation loss: 2.4925304373239987

Epoch: 6| Step: 12
Training loss: 1.8607189546593972
Validation loss: 2.5077676488896983

Epoch: 6| Step: 13
Training loss: 1.824995573900682
Validation loss: 2.472182096292645

Epoch: 172| Step: 0
Training loss: 1.864478664195303
Validation loss: 2.455110244984003

Epoch: 6| Step: 1
Training loss: 1.239267816645987
Validation loss: 2.445720591508293

Epoch: 6| Step: 2
Training loss: 1.797577430426207
Validation loss: 2.4239986089648755

Epoch: 6| Step: 3
Training loss: 1.5879199786599196
Validation loss: 2.390039286294651

Epoch: 6| Step: 4
Training loss: 2.3378010846601103
Validation loss: 2.390749408064688

Epoch: 6| Step: 5
Training loss: 1.5686974262075635
Validation loss: 2.3645972448036177

Epoch: 6| Step: 6
Training loss: 1.6778494780983142
Validation loss: 2.3861815107713342

Epoch: 6| Step: 7
Training loss: 1.8658344042651278
Validation loss: 2.402060336791324

Epoch: 6| Step: 8
Training loss: 1.8163995558092372
Validation loss: 2.4390005978032345

Epoch: 6| Step: 9
Training loss: 2.251432386738101
Validation loss: 2.4876040685029035

Epoch: 6| Step: 10
Training loss: 2.3083829573749606
Validation loss: 2.520905720352732

Epoch: 6| Step: 11
Training loss: 1.7197458330035449
Validation loss: 2.5437005655339338

Epoch: 6| Step: 12
Training loss: 1.680307814918075
Validation loss: 2.5438288833824734

Epoch: 6| Step: 13
Training loss: 1.9387554285205861
Validation loss: 2.516961609556089

Epoch: 173| Step: 0
Training loss: 1.4156930700782577
Validation loss: 2.477093321232964

Epoch: 6| Step: 1
Training loss: 1.599382507855174
Validation loss: 2.437945140940326

Epoch: 6| Step: 2
Training loss: 1.6582586236479617
Validation loss: 2.4200442849291046

Epoch: 6| Step: 3
Training loss: 1.5164444271511626
Validation loss: 2.379492239042328

Epoch: 6| Step: 4
Training loss: 1.8357989319798744
Validation loss: 2.3794381276024215

Epoch: 6| Step: 5
Training loss: 1.7244037233389005
Validation loss: 2.3915263243658

Epoch: 6| Step: 6
Training loss: 2.500247180163206
Validation loss: 2.404077159083892

Epoch: 6| Step: 7
Training loss: 1.7254911525149084
Validation loss: 2.4046578303651223

Epoch: 6| Step: 8
Training loss: 1.6345484508429464
Validation loss: 2.3863412050818495

Epoch: 6| Step: 9
Training loss: 1.3133754535317375
Validation loss: 2.3791345747769976

Epoch: 6| Step: 10
Training loss: 1.738929884687667
Validation loss: 2.371632401835685

Epoch: 6| Step: 11
Training loss: 2.4674564304389452
Validation loss: 2.3862545667789496

Epoch: 6| Step: 12
Training loss: 2.048758535594278
Validation loss: 2.387424995083032

Epoch: 6| Step: 13
Training loss: 2.030342721055095
Validation loss: 2.4050243363389803

Epoch: 174| Step: 0
Training loss: 0.9316342911415
Validation loss: 2.3927287288275463

Epoch: 6| Step: 1
Training loss: 1.4546466366839634
Validation loss: 2.3931124798886563

Epoch: 6| Step: 2
Training loss: 2.1246384705818233
Validation loss: 2.4135069496747135

Epoch: 6| Step: 3
Training loss: 1.720674235245382
Validation loss: 2.4022977514937978

Epoch: 6| Step: 4
Training loss: 1.9952002389942873
Validation loss: 2.4199049135796074

Epoch: 6| Step: 5
Training loss: 1.6281550662729647
Validation loss: 2.422122975706387

Epoch: 6| Step: 6
Training loss: 1.8463544392731273
Validation loss: 2.4372911019284267

Epoch: 6| Step: 7
Training loss: 1.7009316416017004
Validation loss: 2.4568307253078028

Epoch: 6| Step: 8
Training loss: 2.2402950368448833
Validation loss: 2.470913967838072

Epoch: 6| Step: 9
Training loss: 2.2302595531480094
Validation loss: 2.4959497457263

Epoch: 6| Step: 10
Training loss: 1.4369287599758478
Validation loss: 2.4741714159526746

Epoch: 6| Step: 11
Training loss: 1.9963313071473705
Validation loss: 2.4525014161686856

Epoch: 6| Step: 12
Training loss: 1.579420105954635
Validation loss: 2.4534151537799853

Epoch: 6| Step: 13
Training loss: 1.4816940993925853
Validation loss: 2.4020613016008387

Epoch: 175| Step: 0
Training loss: 1.6104908750477478
Validation loss: 2.378415466458584

Epoch: 6| Step: 1
Training loss: 2.18792894789906
Validation loss: 2.3597525984640684

Epoch: 6| Step: 2
Training loss: 1.85406794624551
Validation loss: 2.3510952478055573

Epoch: 6| Step: 3
Training loss: 1.8700529958997834
Validation loss: 2.3453126233444164

Epoch: 6| Step: 4
Training loss: 1.7946392579845785
Validation loss: 2.356222460773431

Epoch: 6| Step: 5
Training loss: 2.0908854232549263
Validation loss: 2.3429570224549168

Epoch: 6| Step: 6
Training loss: 1.6941380102107948
Validation loss: 2.3519037999477073

Epoch: 6| Step: 7
Training loss: 1.7662399706383658
Validation loss: 2.3728742147676303

Epoch: 6| Step: 8
Training loss: 1.1433805859275918
Validation loss: 2.376872766968432

Epoch: 6| Step: 9
Training loss: 1.8902353563047993
Validation loss: 2.3885785031611673

Epoch: 6| Step: 10
Training loss: 1.715194909500283
Validation loss: 2.3935341434103594

Epoch: 6| Step: 11
Training loss: 1.3202915528571326
Validation loss: 2.4440361549258665

Epoch: 6| Step: 12
Training loss: 1.9156130991032434
Validation loss: 2.4509896711093013

Epoch: 6| Step: 13
Training loss: 1.7297048841807214
Validation loss: 2.4457365872145496

Epoch: 176| Step: 0
Training loss: 1.616593919998434
Validation loss: 2.465047286764714

Epoch: 6| Step: 1
Training loss: 1.0789357329807507
Validation loss: 2.4526726706928756

Epoch: 6| Step: 2
Training loss: 1.9222143230324928
Validation loss: 2.4819267418609434

Epoch: 6| Step: 3
Training loss: 2.542139718064467
Validation loss: 2.4839158049458483

Epoch: 6| Step: 4
Training loss: 1.9960353417258676
Validation loss: 2.4591684697443283

Epoch: 6| Step: 5
Training loss: 1.8338860921149216
Validation loss: 2.4553201067842347

Epoch: 6| Step: 6
Training loss: 1.2058751764179716
Validation loss: 2.3992426506423254

Epoch: 6| Step: 7
Training loss: 1.4133086328927176
Validation loss: 2.39575263088534

Epoch: 6| Step: 8
Training loss: 1.4853316587259473
Validation loss: 2.388623065265504

Epoch: 6| Step: 9
Training loss: 1.8299923350481113
Validation loss: 2.379811086270665

Epoch: 6| Step: 10
Training loss: 1.3258883323427086
Validation loss: 2.3739717175632324

Epoch: 6| Step: 11
Training loss: 1.6211800058236434
Validation loss: 2.3680162181655695

Epoch: 6| Step: 12
Training loss: 1.8895515357906203
Validation loss: 2.3462719109317223

Epoch: 6| Step: 13
Training loss: 2.3822973476175933
Validation loss: 2.3299293911723127

Epoch: 177| Step: 0
Training loss: 1.9507327879239615
Validation loss: 2.3325334231119483

Epoch: 6| Step: 1
Training loss: 1.7350086051441693
Validation loss: 2.339802003320596

Epoch: 6| Step: 2
Training loss: 1.545082826585527
Validation loss: 2.336892729758612

Epoch: 6| Step: 3
Training loss: 2.0140324888516328
Validation loss: 2.3672707176627847

Epoch: 6| Step: 4
Training loss: 2.0201674737529256
Validation loss: 2.383976322865298

Epoch: 6| Step: 5
Training loss: 2.2624034207632486
Validation loss: 2.378509790461013

Epoch: 6| Step: 6
Training loss: 1.760754374177876
Validation loss: 2.390906427611623

Epoch: 6| Step: 7
Training loss: 1.388409510640964
Validation loss: 2.3922073646890305

Epoch: 6| Step: 8
Training loss: 1.5286795392021963
Validation loss: 2.408562455588631

Epoch: 6| Step: 9
Training loss: 1.6683947267138515
Validation loss: 2.4048093902930914

Epoch: 6| Step: 10
Training loss: 1.9485106625009478
Validation loss: 2.4514289282227484

Epoch: 6| Step: 11
Training loss: 1.0235420930720354
Validation loss: 2.4855028067724967

Epoch: 6| Step: 12
Training loss: 1.5541781257159224
Validation loss: 2.507290452267141

Epoch: 6| Step: 13
Training loss: 1.697961802750537
Validation loss: 2.5443386481502754

Epoch: 178| Step: 0
Training loss: 2.1685204156288838
Validation loss: 2.546665519485812

Epoch: 6| Step: 1
Training loss: 1.3917432425136023
Validation loss: 2.5213750428207833

Epoch: 6| Step: 2
Training loss: 1.3179639435179056
Validation loss: 2.494135179363624

Epoch: 6| Step: 3
Training loss: 1.6354429238837698
Validation loss: 2.4653076621457015

Epoch: 6| Step: 4
Training loss: 1.8393595517981294
Validation loss: 2.4667653405652836

Epoch: 6| Step: 5
Training loss: 1.4940289224993766
Validation loss: 2.4504373088140152

Epoch: 6| Step: 6
Training loss: 1.7072802608621815
Validation loss: 2.4286101129111373

Epoch: 6| Step: 7
Training loss: 1.751602052621451
Validation loss: 2.4029158436516593

Epoch: 6| Step: 8
Training loss: 1.6107004873743833
Validation loss: 2.4059770032646157

Epoch: 6| Step: 9
Training loss: 1.716402010593379
Validation loss: 2.3656168165360807

Epoch: 6| Step: 10
Training loss: 1.82868544636057
Validation loss: 2.355162100184784

Epoch: 6| Step: 11
Training loss: 1.813400702463891
Validation loss: 2.3442657215041995

Epoch: 6| Step: 12
Training loss: 1.591444779286862
Validation loss: 2.3551683787587616

Epoch: 6| Step: 13
Training loss: 2.243739425081713
Validation loss: 2.341132116133269

Epoch: 179| Step: 0
Training loss: 1.4014231175549443
Validation loss: 2.3339265338137127

Epoch: 6| Step: 1
Training loss: 1.8241689540429875
Validation loss: 2.357840140038873

Epoch: 6| Step: 2
Training loss: 1.004223250276184
Validation loss: 2.344390046699496

Epoch: 6| Step: 3
Training loss: 2.099579850809861
Validation loss: 2.3399019872470603

Epoch: 6| Step: 4
Training loss: 1.9966392294325872
Validation loss: 2.3615036801132674

Epoch: 6| Step: 5
Training loss: 1.5480037385762335
Validation loss: 2.337305564793385

Epoch: 6| Step: 6
Training loss: 1.4023137846484035
Validation loss: 2.356428832523174

Epoch: 6| Step: 7
Training loss: 1.9489342246780885
Validation loss: 2.3771774045027727

Epoch: 6| Step: 8
Training loss: 1.4215852211582762
Validation loss: 2.363965648272167

Epoch: 6| Step: 9
Training loss: 1.839717010214707
Validation loss: 2.336552196814287

Epoch: 6| Step: 10
Training loss: 1.9588935808190604
Validation loss: 2.3380080528120946

Epoch: 6| Step: 11
Training loss: 1.7901419502320455
Validation loss: 2.327169661275185

Epoch: 6| Step: 12
Training loss: 1.7431618741232762
Validation loss: 2.3609114741867314

Epoch: 6| Step: 13
Training loss: 1.6715084636723854
Validation loss: 2.3487950248165945

Epoch: 180| Step: 0
Training loss: 2.1024614985112495
Validation loss: 2.3813096795572917

Epoch: 6| Step: 1
Training loss: 1.0895333343665359
Validation loss: 2.415838731647662

Epoch: 6| Step: 2
Training loss: 1.556098489395035
Validation loss: 2.4133710068958814

Epoch: 6| Step: 3
Training loss: 1.664472789061853
Validation loss: 2.4528810667076097

Epoch: 6| Step: 4
Training loss: 2.112092253028436
Validation loss: 2.5024798624889013

Epoch: 6| Step: 5
Training loss: 1.9202869335983705
Validation loss: 2.4302906397897672

Epoch: 6| Step: 6
Training loss: 1.5370222016060733
Validation loss: 2.379201265675468

Epoch: 6| Step: 7
Training loss: 2.2027730457735593
Validation loss: 2.3613749210331427

Epoch: 6| Step: 8
Training loss: 1.9476294756294947
Validation loss: 2.3567576530675844

Epoch: 6| Step: 9
Training loss: 1.6478211032375896
Validation loss: 2.3357747909854796

Epoch: 6| Step: 10
Training loss: 1.4092062500203566
Validation loss: 2.33843424900448

Epoch: 6| Step: 11
Training loss: 1.3785318185055662
Validation loss: 2.3007180066494857

Epoch: 6| Step: 12
Training loss: 1.3652924401155757
Validation loss: 2.311960272092027

Epoch: 6| Step: 13
Training loss: 1.2550418738108364
Validation loss: 2.3287885983317462

Epoch: 181| Step: 0
Training loss: 2.203032038465647
Validation loss: 2.355419199976815

Epoch: 6| Step: 1
Training loss: 1.8523823013702347
Validation loss: 2.391639754155472

Epoch: 6| Step: 2
Training loss: 2.325674111048403
Validation loss: 2.404674790588199

Epoch: 6| Step: 3
Training loss: 1.9779646653316167
Validation loss: 2.466809326329596

Epoch: 6| Step: 4
Training loss: 1.4700248542293433
Validation loss: 2.4936818537125203

Epoch: 6| Step: 5
Training loss: 1.6854680154504764
Validation loss: 2.5033273683485127

Epoch: 6| Step: 6
Training loss: 1.845061401544667
Validation loss: 2.4907982621026816

Epoch: 6| Step: 7
Training loss: 1.2399467555274173
Validation loss: 2.468145890295962

Epoch: 6| Step: 8
Training loss: 1.001053493613811
Validation loss: 2.436282920256572

Epoch: 6| Step: 9
Training loss: 1.5884315160698292
Validation loss: 2.40593399382796

Epoch: 6| Step: 10
Training loss: 1.5444793646148036
Validation loss: 2.376474894017539

Epoch: 6| Step: 11
Training loss: 1.5229414694767176
Validation loss: 2.3829969249022476

Epoch: 6| Step: 12
Training loss: 1.4079765740743309
Validation loss: 2.3669007209281814

Epoch: 6| Step: 13
Training loss: 1.3931868026804897
Validation loss: 2.3478360485596736

Epoch: 182| Step: 0
Training loss: 1.3099771958470197
Validation loss: 2.360842218073462

Epoch: 6| Step: 1
Training loss: 1.3958270039580971
Validation loss: 2.363450821091687

Epoch: 6| Step: 2
Training loss: 1.8161768614606626
Validation loss: 2.3774606234373574

Epoch: 6| Step: 3
Training loss: 2.074338517978782
Validation loss: 2.4262884472842567

Epoch: 6| Step: 4
Training loss: 1.637674712550263
Validation loss: 2.4738916479858584

Epoch: 6| Step: 5
Training loss: 1.8200107045959235
Validation loss: 2.5170379972936323

Epoch: 6| Step: 6
Training loss: 1.6423166908384605
Validation loss: 2.4823874563509047

Epoch: 6| Step: 7
Training loss: 1.5145116433130228
Validation loss: 2.4877582560065368

Epoch: 6| Step: 8
Training loss: 2.0038711515033576
Validation loss: 2.4536854678678286

Epoch: 6| Step: 9
Training loss: 1.6952798725978984
Validation loss: 2.443148196184019

Epoch: 6| Step: 10
Training loss: 1.3654378976685562
Validation loss: 2.436910984590082

Epoch: 6| Step: 11
Training loss: 1.561217811930697
Validation loss: 2.435926009642827

Epoch: 6| Step: 12
Training loss: 1.731784707685454
Validation loss: 2.4438494715752968

Epoch: 6| Step: 13
Training loss: 1.0689541627282997
Validation loss: 2.4168338915797

Epoch: 183| Step: 0
Training loss: 1.1496094413651017
Validation loss: 2.407926023957992

Epoch: 6| Step: 1
Training loss: 1.6641294080867421
Validation loss: 2.4205044713978796

Epoch: 6| Step: 2
Training loss: 2.000554723104139
Validation loss: 2.405836840433506

Epoch: 6| Step: 3
Training loss: 1.6144869457720112
Validation loss: 2.3857281708024463

Epoch: 6| Step: 4
Training loss: 1.873830366898707
Validation loss: 2.4049442478956347

Epoch: 6| Step: 5
Training loss: 1.8957152137708901
Validation loss: 2.404325347561462

Epoch: 6| Step: 6
Training loss: 1.9561075859515966
Validation loss: 2.4280297570704095

Epoch: 6| Step: 7
Training loss: 1.8172076682548446
Validation loss: 2.4100224323877084

Epoch: 6| Step: 8
Training loss: 1.7490733281724409
Validation loss: 2.413687328816254

Epoch: 6| Step: 9
Training loss: 1.2543925830652203
Validation loss: 2.427808845840421

Epoch: 6| Step: 10
Training loss: 1.5891779974840383
Validation loss: 2.433732855699808

Epoch: 6| Step: 11
Training loss: 1.3424779504425077
Validation loss: 2.4449958820385094

Epoch: 6| Step: 12
Training loss: 1.2978336513824746
Validation loss: 2.419919496668652

Epoch: 6| Step: 13
Training loss: 1.3341822107486936
Validation loss: 2.409071077371308

Epoch: 184| Step: 0
Training loss: 1.581112667950343
Validation loss: 2.401357729830539

Epoch: 6| Step: 1
Training loss: 1.933921400881377
Validation loss: 2.381775616531892

Epoch: 6| Step: 2
Training loss: 1.504485576069872
Validation loss: 2.3753952945221832

Epoch: 6| Step: 3
Training loss: 1.6889098600429633
Validation loss: 2.37320128495156

Epoch: 6| Step: 4
Training loss: 1.5638245118560574
Validation loss: 2.380007787467506

Epoch: 6| Step: 5
Training loss: 1.0328591248207395
Validation loss: 2.3554338846374625

Epoch: 6| Step: 6
Training loss: 1.4187982828268066
Validation loss: 2.3661461015708243

Epoch: 6| Step: 7
Training loss: 1.7632973781350079
Validation loss: 2.36868882145306

Epoch: 6| Step: 8
Training loss: 1.6274025102940803
Validation loss: 2.419044477593219

Epoch: 6| Step: 9
Training loss: 1.2066496705777916
Validation loss: 2.4104166551517765

Epoch: 6| Step: 10
Training loss: 1.827771796642181
Validation loss: 2.434220894727113

Epoch: 6| Step: 11
Training loss: 2.089657441863311
Validation loss: 2.465804119578804

Epoch: 6| Step: 12
Training loss: 1.7747729142758841
Validation loss: 2.4327594419433707

Epoch: 6| Step: 13
Training loss: 1.169861500603981
Validation loss: 2.446617540662247

Epoch: 185| Step: 0
Training loss: 1.7751162477493359
Validation loss: 2.4069905824085454

Epoch: 6| Step: 1
Training loss: 1.5334514441127296
Validation loss: 2.3974288268286696

Epoch: 6| Step: 2
Training loss: 1.7055206947961106
Validation loss: 2.3621333996583407

Epoch: 6| Step: 3
Training loss: 1.5005272097740643
Validation loss: 2.3464622418493346

Epoch: 6| Step: 4
Training loss: 1.8277018130606562
Validation loss: 2.3377513794856584

Epoch: 6| Step: 5
Training loss: 1.5706716098389184
Validation loss: 2.331493830034985

Epoch: 6| Step: 6
Training loss: 1.9363082173647554
Validation loss: 2.3348022680961926

Epoch: 6| Step: 7
Training loss: 1.8406630714507581
Validation loss: 2.3410114869071683

Epoch: 6| Step: 8
Training loss: 1.2207282712253715
Validation loss: 2.3380240392715153

Epoch: 6| Step: 9
Training loss: 1.286270725094396
Validation loss: 2.3560139588947533

Epoch: 6| Step: 10
Training loss: 1.431158424346303
Validation loss: 2.374461535566319

Epoch: 6| Step: 11
Training loss: 1.3498188745003974
Validation loss: 2.4021295736973105

Epoch: 6| Step: 12
Training loss: 1.646081334353762
Validation loss: 2.4216381199293564

Epoch: 6| Step: 13
Training loss: 1.6875014128502477
Validation loss: 2.461803552005101

Epoch: 186| Step: 0
Training loss: 1.5879584904393436
Validation loss: 2.425054421896212

Epoch: 6| Step: 1
Training loss: 2.0708488489359045
Validation loss: 2.415959656491288

Epoch: 6| Step: 2
Training loss: 1.9339057439461458
Validation loss: 2.385973581131432

Epoch: 6| Step: 3
Training loss: 1.6003573465646637
Validation loss: 2.3959655047568282

Epoch: 6| Step: 4
Training loss: 1.6831770733109541
Validation loss: 2.3887176121581764

Epoch: 6| Step: 5
Training loss: 1.4913590613084107
Validation loss: 2.3469474109615227

Epoch: 6| Step: 6
Training loss: 1.146015753819165
Validation loss: 2.341603535655937

Epoch: 6| Step: 7
Training loss: 1.7230568763790302
Validation loss: 2.3484974186954544

Epoch: 6| Step: 8
Training loss: 1.2994064076248484
Validation loss: 2.328426361124943

Epoch: 6| Step: 9
Training loss: 1.8413829803614972
Validation loss: 2.368951935428832

Epoch: 6| Step: 10
Training loss: 1.3363144549105777
Validation loss: 2.3498715640289722

Epoch: 6| Step: 11
Training loss: 1.0623246216486109
Validation loss: 2.399530178233082

Epoch: 6| Step: 12
Training loss: 1.6618680857284651
Validation loss: 2.3776057703763755

Epoch: 6| Step: 13
Training loss: 1.5407844631160406
Validation loss: 2.3639602020770787

Epoch: 187| Step: 0
Training loss: 0.8243395459213133
Validation loss: 2.3766587428203767

Epoch: 6| Step: 1
Training loss: 1.8088663443666109
Validation loss: 2.3624128182893007

Epoch: 6| Step: 2
Training loss: 1.4410842494492195
Validation loss: 2.3606821530297637

Epoch: 6| Step: 3
Training loss: 1.6516572143766666
Validation loss: 2.3566509228332317

Epoch: 6| Step: 4
Training loss: 1.77436474997693
Validation loss: 2.37639583162793

Epoch: 6| Step: 5
Training loss: 1.7932875937734956
Validation loss: 2.3720438056122393

Epoch: 6| Step: 6
Training loss: 1.0827755347873957
Validation loss: 2.3795501728180595

Epoch: 6| Step: 7
Training loss: 1.4094451210188421
Validation loss: 2.376215368496028

Epoch: 6| Step: 8
Training loss: 1.6100838590782034
Validation loss: 2.3927315874002915

Epoch: 6| Step: 9
Training loss: 1.6499500295990635
Validation loss: 2.401613010852569

Epoch: 6| Step: 10
Training loss: 1.8354795493511842
Validation loss: 2.3988639877501665

Epoch: 6| Step: 11
Training loss: 1.6171193868694915
Validation loss: 2.4084465549800727

Epoch: 6| Step: 12
Training loss: 1.4140116224040602
Validation loss: 2.438077802409787

Epoch: 6| Step: 13
Training loss: 1.617041097454902
Validation loss: 2.41430335139794

Epoch: 188| Step: 0
Training loss: 1.53615733501167
Validation loss: 2.4157368922659046

Epoch: 6| Step: 1
Training loss: 1.2963549478951788
Validation loss: 2.402338353459536

Epoch: 6| Step: 2
Training loss: 1.3251334213163408
Validation loss: 2.3965470123589654

Epoch: 6| Step: 3
Training loss: 1.7828225672953322
Validation loss: 2.3674470839098634

Epoch: 6| Step: 4
Training loss: 1.7107911069068478
Validation loss: 2.3818047872399704

Epoch: 6| Step: 5
Training loss: 1.122894170579413
Validation loss: 2.3771659525322844

Epoch: 6| Step: 6
Training loss: 1.7625751317020246
Validation loss: 2.3658625066552763

Epoch: 6| Step: 7
Training loss: 1.4248500343516315
Validation loss: 2.362826129505073

Epoch: 6| Step: 8
Training loss: 1.7022667218340943
Validation loss: 2.3676151590699104

Epoch: 6| Step: 9
Training loss: 1.5266054520279624
Validation loss: 2.3475474198490383

Epoch: 6| Step: 10
Training loss: 1.630867196252765
Validation loss: 2.3335589425788714

Epoch: 6| Step: 11
Training loss: 1.2609606375574534
Validation loss: 2.312269564618395

Epoch: 6| Step: 12
Training loss: 1.6965345206195865
Validation loss: 2.3440454150557684

Epoch: 6| Step: 13
Training loss: 1.70242463156513
Validation loss: 2.33373769557608

Epoch: 189| Step: 0
Training loss: 1.8779483502631544
Validation loss: 2.343327580056907

Epoch: 6| Step: 1
Training loss: 1.4214704168503947
Validation loss: 2.3531832841308016

Epoch: 6| Step: 2
Training loss: 1.9853731783747024
Validation loss: 2.4115926387593998

Epoch: 6| Step: 3
Training loss: 1.4673837841228232
Validation loss: 2.395407493237164

Epoch: 6| Step: 4
Training loss: 1.2733588633216502
Validation loss: 2.4383261516092025

Epoch: 6| Step: 5
Training loss: 1.1296182782715152
Validation loss: 2.4393583291609824

Epoch: 6| Step: 6
Training loss: 1.0932599195880406
Validation loss: 2.4193652276872286

Epoch: 6| Step: 7
Training loss: 1.3393673953625016
Validation loss: 2.384087671445779

Epoch: 6| Step: 8
Training loss: 1.5343326756997155
Validation loss: 2.3919311704177626

Epoch: 6| Step: 9
Training loss: 1.603827609936813
Validation loss: 2.385794434541091

Epoch: 6| Step: 10
Training loss: 1.8502546753728293
Validation loss: 2.369375916452485

Epoch: 6| Step: 11
Training loss: 1.7731883004163773
Validation loss: 2.352137338264335

Epoch: 6| Step: 12
Training loss: 1.3443931105212736
Validation loss: 2.3461468194920645

Epoch: 6| Step: 13
Training loss: 1.209579838795771
Validation loss: 2.3236202592776323

Epoch: 190| Step: 0
Training loss: 1.590586196036381
Validation loss: 2.323897259397294

Epoch: 6| Step: 1
Training loss: 1.4886366852780484
Validation loss: 2.2884553947473383

Epoch: 6| Step: 2
Training loss: 1.7181792265160094
Validation loss: 2.303667237330274

Epoch: 6| Step: 3
Training loss: 1.5744886143340258
Validation loss: 2.317270523279007

Epoch: 6| Step: 4
Training loss: 1.5776132943750014
Validation loss: 2.31313530427397

Epoch: 6| Step: 5
Training loss: 0.9985984875431293
Validation loss: 2.286919416814118

Epoch: 6| Step: 6
Training loss: 1.4516093235245187
Validation loss: 2.295364775184852

Epoch: 6| Step: 7
Training loss: 1.2942758274813522
Validation loss: 2.2972634451408696

Epoch: 6| Step: 8
Training loss: 1.9514952917567543
Validation loss: 2.3281939294607747

Epoch: 6| Step: 9
Training loss: 1.4799215065271425
Validation loss: 2.3605627188761966

Epoch: 6| Step: 10
Training loss: 1.6975668408320208
Validation loss: 2.3755828906369283

Epoch: 6| Step: 11
Training loss: 1.6694115288328693
Validation loss: 2.4109659527913005

Epoch: 6| Step: 12
Training loss: 1.3165801524860639
Validation loss: 2.4137624242213915

Epoch: 6| Step: 13
Training loss: 0.7212238859741447
Validation loss: 2.4240211549501347

Epoch: 191| Step: 0
Training loss: 1.7320692527087937
Validation loss: 2.4522911417043747

Epoch: 6| Step: 1
Training loss: 1.579311944256073
Validation loss: 2.4309030602211164

Epoch: 6| Step: 2
Training loss: 0.9422213243071859
Validation loss: 2.4174169532720073

Epoch: 6| Step: 3
Training loss: 1.8495481454770903
Validation loss: 2.438598344861369

Epoch: 6| Step: 4
Training loss: 1.439422731324518
Validation loss: 2.3703735001506976

Epoch: 6| Step: 5
Training loss: 1.3569657032651752
Validation loss: 2.3483197111457517

Epoch: 6| Step: 6
Training loss: 1.2768656451255567
Validation loss: 2.3446633039538645

Epoch: 6| Step: 7
Training loss: 1.6155603303639057
Validation loss: 2.3323205831703118

Epoch: 6| Step: 8
Training loss: 1.4800722904850443
Validation loss: 2.3331589476145624

Epoch: 6| Step: 9
Training loss: 1.3104806533660387
Validation loss: 2.297892272883407

Epoch: 6| Step: 10
Training loss: 1.2547754620303688
Validation loss: 2.3107790386982803

Epoch: 6| Step: 11
Training loss: 1.7724449976685122
Validation loss: 2.342686550378144

Epoch: 6| Step: 12
Training loss: 1.6538805296947225
Validation loss: 2.364507673328005

Epoch: 6| Step: 13
Training loss: 1.5394405152492396
Validation loss: 2.397166245081197

Epoch: 192| Step: 0
Training loss: 1.0543362633102313
Validation loss: 2.3746492810186575

Epoch: 6| Step: 1
Training loss: 1.5104178417683558
Validation loss: 2.421150359510727

Epoch: 6| Step: 2
Training loss: 1.6068301032792618
Validation loss: 2.4238740004874146

Epoch: 6| Step: 3
Training loss: 1.5502106123548085
Validation loss: 2.4149142305710107

Epoch: 6| Step: 4
Training loss: 1.568189105794707
Validation loss: 2.415263647759878

Epoch: 6| Step: 5
Training loss: 1.7289055853151611
Validation loss: 2.374830409386876

Epoch: 6| Step: 6
Training loss: 1.565879371674115
Validation loss: 2.3562647216542394

Epoch: 6| Step: 7
Training loss: 1.6528094562019973
Validation loss: 2.322663607434501

Epoch: 6| Step: 8
Training loss: 1.0050401629303618
Validation loss: 2.348252153575594

Epoch: 6| Step: 9
Training loss: 1.767330190225284
Validation loss: 2.3494844885326347

Epoch: 6| Step: 10
Training loss: 1.7409786940250924
Validation loss: 2.3710530271099532

Epoch: 6| Step: 11
Training loss: 1.3358942660647493
Validation loss: 2.352387452799958

Epoch: 6| Step: 12
Training loss: 1.2497337057658118
Validation loss: 2.3538902099335584

Epoch: 6| Step: 13
Training loss: 1.081518113515893
Validation loss: 2.3697242888606493

Epoch: 193| Step: 0
Training loss: 1.3615796856937072
Validation loss: 2.3750987396699

Epoch: 6| Step: 1
Training loss: 1.1778149426992364
Validation loss: 2.3596142073954254

Epoch: 6| Step: 2
Training loss: 1.5020453495438084
Validation loss: 2.369910607952886

Epoch: 6| Step: 3
Training loss: 2.211379152001359
Validation loss: 2.3841831653988397

Epoch: 6| Step: 4
Training loss: 1.577841629421277
Validation loss: 2.369293418701986

Epoch: 6| Step: 5
Training loss: 1.4223382216242082
Validation loss: 2.3507914725163626

Epoch: 6| Step: 6
Training loss: 1.2048841224449336
Validation loss: 2.3650071586129906

Epoch: 6| Step: 7
Training loss: 1.3133786303233221
Validation loss: 2.3264141889712766

Epoch: 6| Step: 8
Training loss: 1.4765371492016082
Validation loss: 2.357806402478366

Epoch: 6| Step: 9
Training loss: 1.053743745506975
Validation loss: 2.3300688323708165

Epoch: 6| Step: 10
Training loss: 1.8212310699966232
Validation loss: 2.3173338530972356

Epoch: 6| Step: 11
Training loss: 1.1687231784945653
Validation loss: 2.3504933633315694

Epoch: 6| Step: 12
Training loss: 1.6433558669618413
Validation loss: 2.3554061652502565

Epoch: 6| Step: 13
Training loss: 0.9644338377966539
Validation loss: 2.3722123385916865

Epoch: 194| Step: 0
Training loss: 1.3331541994083147
Validation loss: 2.3808979941600725

Epoch: 6| Step: 1
Training loss: 1.5665587543630728
Validation loss: 2.3918383100648857

Epoch: 6| Step: 2
Training loss: 1.3405277296938187
Validation loss: 2.401459473353322

Epoch: 6| Step: 3
Training loss: 1.510240961137133
Validation loss: 2.428432706531719

Epoch: 6| Step: 4
Training loss: 1.1769081874387914
Validation loss: 2.4413200400605564

Epoch: 6| Step: 5
Training loss: 1.741502293521971
Validation loss: 2.4537663653019814

Epoch: 6| Step: 6
Training loss: 1.5617157302987548
Validation loss: 2.4453354753541086

Epoch: 6| Step: 7
Training loss: 1.279202010736084
Validation loss: 2.467022711212682

Epoch: 6| Step: 8
Training loss: 1.39830319063316
Validation loss: 2.4014789995459345

Epoch: 6| Step: 9
Training loss: 1.6208126697677732
Validation loss: 2.413477534897556

Epoch: 6| Step: 10
Training loss: 1.2597926883599793
Validation loss: 2.378588653517886

Epoch: 6| Step: 11
Training loss: 1.4214468510500515
Validation loss: 2.384016927162192

Epoch: 6| Step: 12
Training loss: 1.2142051662048008
Validation loss: 2.3755270325147464

Epoch: 6| Step: 13
Training loss: 1.6582743670972109
Validation loss: 2.332752149543182

Epoch: 195| Step: 0
Training loss: 1.8603721957927295
Validation loss: 2.3336401494492187

Epoch: 6| Step: 1
Training loss: 1.5215756507692262
Validation loss: 2.3210047107842118

Epoch: 6| Step: 2
Training loss: 1.1727945915824753
Validation loss: 2.33180629918899

Epoch: 6| Step: 3
Training loss: 1.3715021552202102
Validation loss: 2.324177982878985

Epoch: 6| Step: 4
Training loss: 1.730208745501257
Validation loss: 2.337787252063805

Epoch: 6| Step: 5
Training loss: 1.5294468441992213
Validation loss: 2.372656866140769

Epoch: 6| Step: 6
Training loss: 1.7834836106249128
Validation loss: 2.401751350483447

Epoch: 6| Step: 7
Training loss: 1.4188356718168582
Validation loss: 2.424406627339423

Epoch: 6| Step: 8
Training loss: 0.9863209941341858
Validation loss: 2.4258768638365127

Epoch: 6| Step: 9
Training loss: 1.6738509863201405
Validation loss: 2.464175131782477

Epoch: 6| Step: 10
Training loss: 1.4037121655060851
Validation loss: 2.4033120284325853

Epoch: 6| Step: 11
Training loss: 1.1741475767086815
Validation loss: 2.411605487795889

Epoch: 6| Step: 12
Training loss: 1.0076647509717467
Validation loss: 2.3632068329087006

Epoch: 6| Step: 13
Training loss: 0.9785809219106711
Validation loss: 2.339263127971498

Epoch: 196| Step: 0
Training loss: 0.9651178750500319
Validation loss: 2.337294728029644

Epoch: 6| Step: 1
Training loss: 1.6477614910435208
Validation loss: 2.3521020682009746

Epoch: 6| Step: 2
Training loss: 1.68558061020068
Validation loss: 2.3580485402394236

Epoch: 6| Step: 3
Training loss: 1.4308392830785903
Validation loss: 2.364129807967906

Epoch: 6| Step: 4
Training loss: 1.36277827299717
Validation loss: 2.4072454764150955

Epoch: 6| Step: 5
Training loss: 1.732753373591472
Validation loss: 2.4298038653297196

Epoch: 6| Step: 6
Training loss: 1.3280993739629074
Validation loss: 2.428544759840914

Epoch: 6| Step: 7
Training loss: 1.393815057031602
Validation loss: 2.4586246037055046

Epoch: 6| Step: 8
Training loss: 1.3603722433146228
Validation loss: 2.4217520262809953

Epoch: 6| Step: 9
Training loss: 1.5951212051880956
Validation loss: 2.3899967451979167

Epoch: 6| Step: 10
Training loss: 1.0950521619557079
Validation loss: 2.3906295951119754

Epoch: 6| Step: 11
Training loss: 1.4424218215781215
Validation loss: 2.3644671064395504

Epoch: 6| Step: 12
Training loss: 1.6054729823592708
Validation loss: 2.3274615682416564

Epoch: 6| Step: 13
Training loss: 1.691875084439104
Validation loss: 2.3106392377930725

Epoch: 197| Step: 0
Training loss: 1.388166719348174
Validation loss: 2.2896788051382604

Epoch: 6| Step: 1
Training loss: 1.6438607414276403
Validation loss: 2.2875948853932924

Epoch: 6| Step: 2
Training loss: 1.3325834052802092
Validation loss: 2.294852261191084

Epoch: 6| Step: 3
Training loss: 1.0770442908839715
Validation loss: 2.30449889287108

Epoch: 6| Step: 4
Training loss: 1.5233410927027462
Validation loss: 2.328432879696194

Epoch: 6| Step: 5
Training loss: 1.9642547877465648
Validation loss: 2.3166503489886012

Epoch: 6| Step: 6
Training loss: 1.2629797335619861
Validation loss: 2.331340191954992

Epoch: 6| Step: 7
Training loss: 1.3165693323558865
Validation loss: 2.3086165812975517

Epoch: 6| Step: 8
Training loss: 1.5360403063373276
Validation loss: 2.315025282198411

Epoch: 6| Step: 9
Training loss: 1.178340420645443
Validation loss: 2.3218998522230256

Epoch: 6| Step: 10
Training loss: 1.6418390051269045
Validation loss: 2.3001191154299265

Epoch: 6| Step: 11
Training loss: 1.5805168532981768
Validation loss: 2.3286212745398425

Epoch: 6| Step: 12
Training loss: 0.7844264496119244
Validation loss: 2.384795780916231

Epoch: 6| Step: 13
Training loss: 1.1427280947084368
Validation loss: 2.3693113802904087

Epoch: 198| Step: 0
Training loss: 1.3841555264273653
Validation loss: 2.4128703368751356

Epoch: 6| Step: 1
Training loss: 1.4969394773481604
Validation loss: 2.4306999339063453

Epoch: 6| Step: 2
Training loss: 1.5696431721513873
Validation loss: 2.4316143626352287

Epoch: 6| Step: 3
Training loss: 1.1841766634220932
Validation loss: 2.443600962451721

Epoch: 6| Step: 4
Training loss: 1.16369633388009
Validation loss: 2.4323083138709203

Epoch: 6| Step: 5
Training loss: 1.739521467132869
Validation loss: 2.395454259758206

Epoch: 6| Step: 6
Training loss: 0.6544822088771238
Validation loss: 2.3867151957089137

Epoch: 6| Step: 7
Training loss: 1.8780763819744264
Validation loss: 2.329841416562321

Epoch: 6| Step: 8
Training loss: 0.5960162731131629
Validation loss: 2.336133795494734

Epoch: 6| Step: 9
Training loss: 1.3924600730390566
Validation loss: 2.281459745327371

Epoch: 6| Step: 10
Training loss: 1.4048661946831018
Validation loss: 2.282507219175454

Epoch: 6| Step: 11
Training loss: 1.1201846061711307
Validation loss: 2.271493472780291

Epoch: 6| Step: 12
Training loss: 1.6857977157780049
Validation loss: 2.2796463031801446

Epoch: 6| Step: 13
Training loss: 1.9084974079589192
Validation loss: 2.2959990481256445

Epoch: 199| Step: 0
Training loss: 1.2550497099921547
Validation loss: 2.29047558913358

Epoch: 6| Step: 1
Training loss: 1.4088813746205482
Validation loss: 2.310938085115974

Epoch: 6| Step: 2
Training loss: 1.6153193939233088
Validation loss: 2.354779578493518

Epoch: 6| Step: 3
Training loss: 1.3733290576328148
Validation loss: 2.3858823005193144

Epoch: 6| Step: 4
Training loss: 1.082887826916904
Validation loss: 2.385399686483614

Epoch: 6| Step: 5
Training loss: 1.5648144936838182
Validation loss: 2.391758964495252

Epoch: 6| Step: 6
Training loss: 1.032022533625397
Validation loss: 2.4002720890090834

Epoch: 6| Step: 7
Training loss: 0.9864899757463719
Validation loss: 2.387465506366056

Epoch: 6| Step: 8
Training loss: 1.5244616074023798
Validation loss: 2.4121278573873717

Epoch: 6| Step: 9
Training loss: 1.612415885209967
Validation loss: 2.423920372198499

Epoch: 6| Step: 10
Training loss: 1.7386151282452387
Validation loss: 2.4053358097452935

Epoch: 6| Step: 11
Training loss: 1.3821111937367474
Validation loss: 2.3778335041424863

Epoch: 6| Step: 12
Training loss: 1.2102236704949803
Validation loss: 2.350067322900576

Epoch: 6| Step: 13
Training loss: 1.3480408492902898
Validation loss: 2.3547285844790387

Epoch: 200| Step: 0
Training loss: 1.0125793567217622
Validation loss: 2.3099704577819105

Epoch: 6| Step: 1
Training loss: 1.793169396835751
Validation loss: 2.291765530449634

Epoch: 6| Step: 2
Training loss: 1.342182043062248
Validation loss: 2.3025749300454863

Epoch: 6| Step: 3
Training loss: 1.3673253453109868
Validation loss: 2.2678445910302276

Epoch: 6| Step: 4
Training loss: 1.3825953253774197
Validation loss: 2.267539069354045

Epoch: 6| Step: 5
Training loss: 1.4208284655773795
Validation loss: 2.234377181710898

Epoch: 6| Step: 6
Training loss: 1.587578136293351
Validation loss: 2.2477408573125195

Epoch: 6| Step: 7
Training loss: 0.7743998233982152
Validation loss: 2.2724117706285156

Epoch: 6| Step: 8
Training loss: 1.4814367828425343
Validation loss: 2.2621442586625764

Epoch: 6| Step: 9
Training loss: 1.4682289173152623
Validation loss: 2.3006552451705744

Epoch: 6| Step: 10
Training loss: 1.7872860680453284
Validation loss: 2.3244669938077824

Epoch: 6| Step: 11
Training loss: 1.0446635559788757
Validation loss: 2.336424089840197

Epoch: 6| Step: 12
Training loss: 1.2849668693724468
Validation loss: 2.3685312111471113

Epoch: 6| Step: 13
Training loss: 1.0316632916503656
Validation loss: 2.3679773661824126

Epoch: 201| Step: 0
Training loss: 1.2723774622765838
Validation loss: 2.402543041074235

Epoch: 6| Step: 1
Training loss: 1.2012315192572394
Validation loss: 2.390936261607293

Epoch: 6| Step: 2
Training loss: 0.6548815947082465
Validation loss: 2.402760992758759

Epoch: 6| Step: 3
Training loss: 1.0501635696526102
Validation loss: 2.3740645111432293

Epoch: 6| Step: 4
Training loss: 1.3424586811491261
Validation loss: 2.3638074529917037

Epoch: 6| Step: 5
Training loss: 1.383623779591339
Validation loss: 2.360256189968019

Epoch: 6| Step: 6
Training loss: 1.331100899670096
Validation loss: 2.3200494733096213

Epoch: 6| Step: 7
Training loss: 1.6765311459527406
Validation loss: 2.2993764944400894

Epoch: 6| Step: 8
Training loss: 1.4020787575785474
Validation loss: 2.3047002442655686

Epoch: 6| Step: 9
Training loss: 1.439795941093649
Validation loss: 2.286946434758103

Epoch: 6| Step: 10
Training loss: 1.372842830511336
Validation loss: 2.2701525243850265

Epoch: 6| Step: 11
Training loss: 1.6046380262910733
Validation loss: 2.281434683657423

Epoch: 6| Step: 12
Training loss: 1.6994973842132721
Validation loss: 2.2870393967246003

Epoch: 6| Step: 13
Training loss: 0.9011398144373517
Validation loss: 2.315986445159425

Epoch: 202| Step: 0
Training loss: 1.0401273161646065
Validation loss: 2.3032376197147078

Epoch: 6| Step: 1
Training loss: 1.0870004295727285
Validation loss: 2.321619206635348

Epoch: 6| Step: 2
Training loss: 1.2856595059865412
Validation loss: 2.343725685348997

Epoch: 6| Step: 3
Training loss: 1.5494618989212017
Validation loss: 2.367947730114557

Epoch: 6| Step: 4
Training loss: 1.421194899001712
Validation loss: 2.3739158636471314

Epoch: 6| Step: 5
Training loss: 1.4156734500366501
Validation loss: 2.3703278751801933

Epoch: 6| Step: 6
Training loss: 1.9787016740634265
Validation loss: 2.3307927883583015

Epoch: 6| Step: 7
Training loss: 1.3179743904033778
Validation loss: 2.3165844734586103

Epoch: 6| Step: 8
Training loss: 0.8655144989324233
Validation loss: 2.280601413759641

Epoch: 6| Step: 9
Training loss: 1.3320927312092072
Validation loss: 2.306222120582785

Epoch: 6| Step: 10
Training loss: 1.5002777319329779
Validation loss: 2.31620076061838

Epoch: 6| Step: 11
Training loss: 1.3592380147731462
Validation loss: 2.313023573058956

Epoch: 6| Step: 12
Training loss: 1.0979300052380285
Validation loss: 2.3395786423164457

Epoch: 6| Step: 13
Training loss: 1.1463665617371341
Validation loss: 2.3178820550586385

Epoch: 203| Step: 0
Training loss: 1.5113408210163939
Validation loss: 2.362435959616832

Epoch: 6| Step: 1
Training loss: 1.0219221471706783
Validation loss: 2.3288865969987733

Epoch: 6| Step: 2
Training loss: 1.717156451762894
Validation loss: 2.348728119992418

Epoch: 6| Step: 3
Training loss: 1.5719105953486308
Validation loss: 2.3354946200488227

Epoch: 6| Step: 4
Training loss: 1.343176253500459
Validation loss: 2.3350601312804584

Epoch: 6| Step: 5
Training loss: 1.3364901821576485
Validation loss: 2.316822267463465

Epoch: 6| Step: 6
Training loss: 1.1918891303390537
Validation loss: 2.2874078725446276

Epoch: 6| Step: 7
Training loss: 1.5342771230894994
Validation loss: 2.3158693398109773

Epoch: 6| Step: 8
Training loss: 1.3105234522083713
Validation loss: 2.316592566352021

Epoch: 6| Step: 9
Training loss: 1.7133415437692125
Validation loss: 2.315112926192005

Epoch: 6| Step: 10
Training loss: 1.1511962349563012
Validation loss: 2.2975759228508412

Epoch: 6| Step: 11
Training loss: 1.0603389079444967
Validation loss: 2.3035762020142436

Epoch: 6| Step: 12
Training loss: 1.048733442355408
Validation loss: 2.2700649006340345

Epoch: 6| Step: 13
Training loss: 1.188831987732561
Validation loss: 2.27668297184437

Epoch: 204| Step: 0
Training loss: 1.0443003865132525
Validation loss: 2.3066370095562103

Epoch: 6| Step: 1
Training loss: 1.4410777144008824
Validation loss: 2.3512982567604217

Epoch: 6| Step: 2
Training loss: 1.403807065216559
Validation loss: 2.3722628324991195

Epoch: 6| Step: 3
Training loss: 1.4406324340893295
Validation loss: 2.376374044212328

Epoch: 6| Step: 4
Training loss: 1.7365620887787439
Validation loss: 2.3580544077824617

Epoch: 6| Step: 5
Training loss: 1.4465704315159291
Validation loss: 2.379047504846859

Epoch: 6| Step: 6
Training loss: 1.1044095629911184
Validation loss: 2.358841919840647

Epoch: 6| Step: 7
Training loss: 0.9088510478639331
Validation loss: 2.3641333560919713

Epoch: 6| Step: 8
Training loss: 1.3060005570391509
Validation loss: 2.359456533093376

Epoch: 6| Step: 9
Training loss: 1.4454160086193257
Validation loss: 2.3341885514175438

Epoch: 6| Step: 10
Training loss: 1.5970994496728705
Validation loss: 2.3091615132413534

Epoch: 6| Step: 11
Training loss: 1.067756719965991
Validation loss: 2.276633817328573

Epoch: 6| Step: 12
Training loss: 1.1401104746377266
Validation loss: 2.241296164046566

Epoch: 6| Step: 13
Training loss: 1.3162467248627725
Validation loss: 2.259044047485598

Epoch: 205| Step: 0
Training loss: 1.093060194202508
Validation loss: 2.2245131590135796

Epoch: 6| Step: 1
Training loss: 1.0967278406266705
Validation loss: 2.2217171434276133

Epoch: 6| Step: 2
Training loss: 1.4749276127267446
Validation loss: 2.2465888911384604

Epoch: 6| Step: 3
Training loss: 1.183504208240191
Validation loss: 2.23108126046303

Epoch: 6| Step: 4
Training loss: 1.7359107838659902
Validation loss: 2.2946245012770854

Epoch: 6| Step: 5
Training loss: 1.106630395693214
Validation loss: 2.3441369943823926

Epoch: 6| Step: 6
Training loss: 1.2203137074170263
Validation loss: 2.3563740772227657

Epoch: 6| Step: 7
Training loss: 1.3111649944436508
Validation loss: 2.4172301676822294

Epoch: 6| Step: 8
Training loss: 1.7391785095401404
Validation loss: 2.419831881338327

Epoch: 6| Step: 9
Training loss: 1.3261290418311762
Validation loss: 2.449803422781085

Epoch: 6| Step: 10
Training loss: 1.0347025902839284
Validation loss: 2.464287069352535

Epoch: 6| Step: 11
Training loss: 1.063301233108051
Validation loss: 2.438895839483766

Epoch: 6| Step: 12
Training loss: 1.337095550635038
Validation loss: 2.415777640843787

Epoch: 6| Step: 13
Training loss: 1.3470177948703075
Validation loss: 2.3569625965930685

Epoch: 206| Step: 0
Training loss: 1.2567639452538275
Validation loss: 2.3251306901310724

Epoch: 6| Step: 1
Training loss: 1.2992525941589073
Validation loss: 2.2828315680891986

Epoch: 6| Step: 2
Training loss: 1.0406124056950377
Validation loss: 2.2566181777705916

Epoch: 6| Step: 3
Training loss: 1.3221160037699498
Validation loss: 2.2248583290999724

Epoch: 6| Step: 4
Training loss: 1.298733861270383
Validation loss: 2.2472352738966053

Epoch: 6| Step: 5
Training loss: 1.2492173605810362
Validation loss: 2.239511773086304

Epoch: 6| Step: 6
Training loss: 1.4166244986747056
Validation loss: 2.210042721628631

Epoch: 6| Step: 7
Training loss: 1.6017787880344523
Validation loss: 2.2594979146115204

Epoch: 6| Step: 8
Training loss: 1.1186401419804588
Validation loss: 2.2844704756526406

Epoch: 6| Step: 9
Training loss: 1.3519771579302609
Validation loss: 2.2991161310475556

Epoch: 6| Step: 10
Training loss: 1.333115838113699
Validation loss: 2.322643663684846

Epoch: 6| Step: 11
Training loss: 0.9972158058713341
Validation loss: 2.355988151663124

Epoch: 6| Step: 12
Training loss: 1.2307979082929699
Validation loss: 2.379028000366339

Epoch: 6| Step: 13
Training loss: 1.5034010794206007
Validation loss: 2.3518501748714136

Epoch: 207| Step: 0
Training loss: 1.0985286951532092
Validation loss: 2.3766481922839193

Epoch: 6| Step: 1
Training loss: 0.895536832016852
Validation loss: 2.366705183457834

Epoch: 6| Step: 2
Training loss: 1.521173604584442
Validation loss: 2.334282917692305

Epoch: 6| Step: 3
Training loss: 1.535341518569663
Validation loss: 2.3518278842780966

Epoch: 6| Step: 4
Training loss: 1.5801997379613208
Validation loss: 2.3182190613844758

Epoch: 6| Step: 5
Training loss: 1.4263842835930298
Validation loss: 2.3544899488654103

Epoch: 6| Step: 6
Training loss: 1.5020602700221628
Validation loss: 2.3305401296715917

Epoch: 6| Step: 7
Training loss: 1.455311842204169
Validation loss: 2.357931059105201

Epoch: 6| Step: 8
Training loss: 1.0410220376795922
Validation loss: 2.3265163063693035

Epoch: 6| Step: 9
Training loss: 0.8279410103871581
Validation loss: 2.3346747393171814

Epoch: 6| Step: 10
Training loss: 1.1408013507956738
Validation loss: 2.3331448548270917

Epoch: 6| Step: 11
Training loss: 0.9886547182087361
Validation loss: 2.31729870935241

Epoch: 6| Step: 12
Training loss: 1.2486287224790769
Validation loss: 2.287981335104733

Epoch: 6| Step: 13
Training loss: 1.335774506558469
Validation loss: 2.3059725519185745

Epoch: 208| Step: 0
Training loss: 1.4411373559582734
Validation loss: 2.2447118456360875

Epoch: 6| Step: 1
Training loss: 1.2646474006088897
Validation loss: 2.2336344600027007

Epoch: 6| Step: 2
Training loss: 1.2755737640542941
Validation loss: 2.206796236744957

Epoch: 6| Step: 3
Training loss: 1.0657087007914625
Validation loss: 2.212223257864673

Epoch: 6| Step: 4
Training loss: 1.6433143009272695
Validation loss: 2.2235590713800626

Epoch: 6| Step: 5
Training loss: 0.6579645556495342
Validation loss: 2.2673069216908686

Epoch: 6| Step: 6
Training loss: 0.865185118364626
Validation loss: 2.3151500298760026

Epoch: 6| Step: 7
Training loss: 1.348815772969163
Validation loss: 2.386111864826512

Epoch: 6| Step: 8
Training loss: 1.1454913698335039
Validation loss: 2.4179086036417137

Epoch: 6| Step: 9
Training loss: 1.6640702368328066
Validation loss: 2.402444397206703

Epoch: 6| Step: 10
Training loss: 1.1587051924485374
Validation loss: 2.4018265661113807

Epoch: 6| Step: 11
Training loss: 1.5320492429712544
Validation loss: 2.388884784238354

Epoch: 6| Step: 12
Training loss: 1.3707912361305672
Validation loss: 2.385216666191096

Epoch: 6| Step: 13
Training loss: 1.2200701972433705
Validation loss: 2.3351774703337034

Epoch: 209| Step: 0
Training loss: 1.2353900164623977
Validation loss: 2.342925467985167

Epoch: 6| Step: 1
Training loss: 1.0474582015554308
Validation loss: 2.306665756234416

Epoch: 6| Step: 2
Training loss: 1.6425062020938082
Validation loss: 2.2743651001661767

Epoch: 6| Step: 3
Training loss: 0.8063972974375253
Validation loss: 2.2527961595553263

Epoch: 6| Step: 4
Training loss: 1.5269105106554375
Validation loss: 2.2210086082044977

Epoch: 6| Step: 5
Training loss: 0.9862349966670306
Validation loss: 2.2201119609914977

Epoch: 6| Step: 6
Training loss: 1.2729061867157132
Validation loss: 2.231755645520694

Epoch: 6| Step: 7
Training loss: 0.947970004554825
Validation loss: 2.2231713876001424

Epoch: 6| Step: 8
Training loss: 1.3626331439277484
Validation loss: 2.2921271766658915

Epoch: 6| Step: 9
Training loss: 1.228999201902374
Validation loss: 2.2717007333909294

Epoch: 6| Step: 10
Training loss: 1.3217905563184524
Validation loss: 2.276497139179921

Epoch: 6| Step: 11
Training loss: 1.2202074677304326
Validation loss: 2.2808828762245943

Epoch: 6| Step: 12
Training loss: 1.5312447061252559
Validation loss: 2.270753858142101

Epoch: 6| Step: 13
Training loss: 1.0213188197691674
Validation loss: 2.3022967280350914

Epoch: 210| Step: 0
Training loss: 1.2433924558830667
Validation loss: 2.268061844839382

Epoch: 6| Step: 1
Training loss: 1.0422928009138863
Validation loss: 2.2974112641333457

Epoch: 6| Step: 2
Training loss: 0.8766071682188902
Validation loss: 2.3121574256753172

Epoch: 6| Step: 3
Training loss: 1.3204180432632764
Validation loss: 2.2660485267461974

Epoch: 6| Step: 4
Training loss: 1.3470800080018908
Validation loss: 2.2750031059358427

Epoch: 6| Step: 5
Training loss: 1.465729549884057
Validation loss: 2.294389278318396

Epoch: 6| Step: 6
Training loss: 1.0572422310432545
Validation loss: 2.287034573302099

Epoch: 6| Step: 7
Training loss: 1.2946400515521237
Validation loss: 2.2996767763937638

Epoch: 6| Step: 8
Training loss: 1.1559488058865082
Validation loss: 2.273901355838614

Epoch: 6| Step: 9
Training loss: 1.0991844860557671
Validation loss: 2.2930960123327497

Epoch: 6| Step: 10
Training loss: 1.05097069149366
Validation loss: 2.259164947792835

Epoch: 6| Step: 11
Training loss: 1.1080846132168394
Validation loss: 2.2779122997639814

Epoch: 6| Step: 12
Training loss: 1.5421959595607644
Validation loss: 2.253883352458551

Epoch: 6| Step: 13
Training loss: 1.4303910655704848
Validation loss: 2.259796493769964

Epoch: 211| Step: 0
Training loss: 1.4037160295569513
Validation loss: 2.259183923396503

Epoch: 6| Step: 1
Training loss: 1.2953911070675819
Validation loss: 2.241208594865187

Epoch: 6| Step: 2
Training loss: 1.3936462158427658
Validation loss: 2.2508942685272446

Epoch: 6| Step: 3
Training loss: 1.020213983753945
Validation loss: 2.2584213546940703

Epoch: 6| Step: 4
Training loss: 1.4625143425393061
Validation loss: 2.244406967788681

Epoch: 6| Step: 5
Training loss: 1.1830004725386771
Validation loss: 2.242886489524004

Epoch: 6| Step: 6
Training loss: 1.2806696624191278
Validation loss: 2.254060149201401

Epoch: 6| Step: 7
Training loss: 1.003868428864868
Validation loss: 2.2569206512518005

Epoch: 6| Step: 8
Training loss: 1.3272670892106397
Validation loss: 2.264374656340628

Epoch: 6| Step: 9
Training loss: 1.0268293478088188
Validation loss: 2.277119986211142

Epoch: 6| Step: 10
Training loss: 0.9493299505458347
Validation loss: 2.314593648082219

Epoch: 6| Step: 11
Training loss: 1.1736437863849263
Validation loss: 2.287563426268516

Epoch: 6| Step: 12
Training loss: 1.2428797586306397
Validation loss: 2.325503712904943

Epoch: 6| Step: 13
Training loss: 1.1900520007207902
Validation loss: 2.3194596730134043

Epoch: 212| Step: 0
Training loss: 1.3185965769683552
Validation loss: 2.3099549186502437

Epoch: 6| Step: 1
Training loss: 1.3057422143775987
Validation loss: 2.3252714267933965

Epoch: 6| Step: 2
Training loss: 0.5194535735150319
Validation loss: 2.3244305693460783

Epoch: 6| Step: 3
Training loss: 1.4933186981783975
Validation loss: 2.306744814142662

Epoch: 6| Step: 4
Training loss: 1.661008799934387
Validation loss: 2.298377135110743

Epoch: 6| Step: 5
Training loss: 1.0920336744614778
Validation loss: 2.2948762658831483

Epoch: 6| Step: 6
Training loss: 1.4900901394659052
Validation loss: 2.3303502744454283

Epoch: 6| Step: 7
Training loss: 0.9046774407389196
Validation loss: 2.288261120142871

Epoch: 6| Step: 8
Training loss: 1.1268705076613672
Validation loss: 2.2801780300405077

Epoch: 6| Step: 9
Training loss: 1.1033708595586276
Validation loss: 2.2701711724117097

Epoch: 6| Step: 10
Training loss: 1.270737060694135
Validation loss: 2.2595488680726534

Epoch: 6| Step: 11
Training loss: 1.1089483165891758
Validation loss: 2.260580931796097

Epoch: 6| Step: 12
Training loss: 1.1907041388215063
Validation loss: 2.2586392515760694

Epoch: 6| Step: 13
Training loss: 0.8527791841959944
Validation loss: 2.2474145271210983

Epoch: 213| Step: 0
Training loss: 1.0629262630119674
Validation loss: 2.226891336731578

Epoch: 6| Step: 1
Training loss: 0.9301401526969243
Validation loss: 2.2475205641369027

Epoch: 6| Step: 2
Training loss: 0.5816820876674205
Validation loss: 2.218550020663269

Epoch: 6| Step: 3
Training loss: 1.3457781545155445
Validation loss: 2.2356154755094555

Epoch: 6| Step: 4
Training loss: 1.2712817521382513
Validation loss: 2.260720454633152

Epoch: 6| Step: 5
Training loss: 1.3143028411430504
Validation loss: 2.283757138904784

Epoch: 6| Step: 6
Training loss: 1.2936544300107733
Validation loss: 2.309723065586561

Epoch: 6| Step: 7
Training loss: 1.2098412258235667
Validation loss: 2.3429342549815098

Epoch: 6| Step: 8
Training loss: 1.2874560894931706
Validation loss: 2.307495583914078

Epoch: 6| Step: 9
Training loss: 1.3888365142271903
Validation loss: 2.3465077173997506

Epoch: 6| Step: 10
Training loss: 1.656946719476176
Validation loss: 2.315802009580065

Epoch: 6| Step: 11
Training loss: 0.8084010387525344
Validation loss: 2.342180951672112

Epoch: 6| Step: 12
Training loss: 1.2116157355135861
Validation loss: 2.3229303144836413

Epoch: 6| Step: 13
Training loss: 1.2997570874607374
Validation loss: 2.3030810302868523

Epoch: 214| Step: 0
Training loss: 1.305375334743569
Validation loss: 2.2610993862473796

Epoch: 6| Step: 1
Training loss: 1.2484581020598478
Validation loss: 2.2512500895268275

Epoch: 6| Step: 2
Training loss: 0.9171715704137342
Validation loss: 2.2239943933662674

Epoch: 6| Step: 3
Training loss: 1.1831302049847796
Validation loss: 2.230782030997

Epoch: 6| Step: 4
Training loss: 0.7942124183728111
Validation loss: 2.241051107683312

Epoch: 6| Step: 5
Training loss: 1.148507459935966
Validation loss: 2.2660005200967626

Epoch: 6| Step: 6
Training loss: 1.211602452967123
Validation loss: 2.2900592275077543

Epoch: 6| Step: 7
Training loss: 1.465740448201154
Validation loss: 2.3150785416072956

Epoch: 6| Step: 8
Training loss: 1.3681550879936297
Validation loss: 2.320052970612842

Epoch: 6| Step: 9
Training loss: 0.9388046088253059
Validation loss: 2.317848155076579

Epoch: 6| Step: 10
Training loss: 0.9881405334409881
Validation loss: 2.2655851406598226

Epoch: 6| Step: 11
Training loss: 1.7197061826677866
Validation loss: 2.2503390700467922

Epoch: 6| Step: 12
Training loss: 1.4235411722428104
Validation loss: 2.254516383627634

Epoch: 6| Step: 13
Training loss: 0.35164081972663874
Validation loss: 2.2920639730323864

Epoch: 215| Step: 0
Training loss: 1.300959486105511
Validation loss: 2.2528028588431943

Epoch: 6| Step: 1
Training loss: 1.450307760791889
Validation loss: 2.2630162553332513

Epoch: 6| Step: 2
Training loss: 1.4578545829038638
Validation loss: 2.265878669249223

Epoch: 6| Step: 3
Training loss: 1.0806774939014856
Validation loss: 2.2904391272283346

Epoch: 6| Step: 4
Training loss: 0.9214381783270809
Validation loss: 2.3165128623484357

Epoch: 6| Step: 5
Training loss: 1.2272132556486597
Validation loss: 2.2997539827405626

Epoch: 6| Step: 6
Training loss: 0.9672392170379708
Validation loss: 2.3252485186774225

Epoch: 6| Step: 7
Training loss: 1.171169984459854
Validation loss: 2.3173382373158558

Epoch: 6| Step: 8
Training loss: 1.1865903482291174
Validation loss: 2.24231209826255

Epoch: 6| Step: 9
Training loss: 0.8756099686567936
Validation loss: 2.290356574989858

Epoch: 6| Step: 10
Training loss: 0.8644957134169234
Validation loss: 2.263987020451072

Epoch: 6| Step: 11
Training loss: 1.4008099767374318
Validation loss: 2.2470468889427013

Epoch: 6| Step: 12
Training loss: 1.1988631724694048
Validation loss: 2.2568389608145742

Epoch: 6| Step: 13
Training loss: 1.371411974024532
Validation loss: 2.255846016150936

Epoch: 216| Step: 0
Training loss: 1.0369982183913815
Validation loss: 2.246487685260931

Epoch: 6| Step: 1
Training loss: 0.9921154386528989
Validation loss: 2.2500421469966945

Epoch: 6| Step: 2
Training loss: 1.2915292892413481
Validation loss: 2.220948821188725

Epoch: 6| Step: 3
Training loss: 1.2750482961445895
Validation loss: 2.247012985903024

Epoch: 6| Step: 4
Training loss: 1.4266176879502903
Validation loss: 2.2578349307683587

Epoch: 6| Step: 5
Training loss: 0.8107563161848023
Validation loss: 2.2365641661603575

Epoch: 6| Step: 6
Training loss: 1.2084216162340804
Validation loss: 2.2634107355625317

Epoch: 6| Step: 7
Training loss: 1.1610899998349287
Validation loss: 2.2798961780810645

Epoch: 6| Step: 8
Training loss: 1.0111092753154964
Validation loss: 2.2994208603661948

Epoch: 6| Step: 9
Training loss: 1.5089750403684066
Validation loss: 2.2933673115698343

Epoch: 6| Step: 10
Training loss: 1.021101403882645
Validation loss: 2.3029564348032654

Epoch: 6| Step: 11
Training loss: 1.0802153626044337
Validation loss: 2.30764993576641

Epoch: 6| Step: 12
Training loss: 1.3112938652301762
Validation loss: 2.2942636350614447

Epoch: 6| Step: 13
Training loss: 1.0231814464548235
Validation loss: 2.302069393396571

Epoch: 217| Step: 0
Training loss: 1.3384515853236878
Validation loss: 2.2779663970602826

Epoch: 6| Step: 1
Training loss: 1.4207106633336402
Validation loss: 2.2528549435052057

Epoch: 6| Step: 2
Training loss: 0.9543107895650619
Validation loss: 2.231106466620296

Epoch: 6| Step: 3
Training loss: 1.1951335199533366
Validation loss: 2.2514577903434874

Epoch: 6| Step: 4
Training loss: 0.7491688891736064
Validation loss: 2.252147173020574

Epoch: 6| Step: 5
Training loss: 1.2771894729259272
Validation loss: 2.272468774633959

Epoch: 6| Step: 6
Training loss: 1.4076841035437861
Validation loss: 2.243208141346417

Epoch: 6| Step: 7
Training loss: 1.407637018069606
Validation loss: 2.2732422413611664

Epoch: 6| Step: 8
Training loss: 1.1604049878357414
Validation loss: 2.258361159307112

Epoch: 6| Step: 9
Training loss: 1.0264491838827219
Validation loss: 2.270701705340489

Epoch: 6| Step: 10
Training loss: 1.1567666214143875
Validation loss: 2.2414481583475783

Epoch: 6| Step: 11
Training loss: 0.7576577726676494
Validation loss: 2.2475701842674707

Epoch: 6| Step: 12
Training loss: 1.3772907681804345
Validation loss: 2.251728316407236

Epoch: 6| Step: 13
Training loss: 0.40310162395153964
Validation loss: 2.274437162508589

Epoch: 218| Step: 0
Training loss: 1.4184644268847648
Validation loss: 2.2597209683407753

Epoch: 6| Step: 1
Training loss: 1.056077112348169
Validation loss: 2.2928118841373624

Epoch: 6| Step: 2
Training loss: 1.117458390692284
Validation loss: 2.297695127061491

Epoch: 6| Step: 3
Training loss: 0.8680035300029224
Validation loss: 2.2861202607758617

Epoch: 6| Step: 4
Training loss: 1.277144343592302
Validation loss: 2.2756111385677875

Epoch: 6| Step: 5
Training loss: 0.9640959030621428
Validation loss: 2.253778367249771

Epoch: 6| Step: 6
Training loss: 1.6691077316831888
Validation loss: 2.2352770662386785

Epoch: 6| Step: 7
Training loss: 1.2400519289402787
Validation loss: 2.2393334842938724

Epoch: 6| Step: 8
Training loss: 0.8193367377221584
Validation loss: 2.2409612752638615

Epoch: 6| Step: 9
Training loss: 1.037334123243
Validation loss: 2.2609997120201903

Epoch: 6| Step: 10
Training loss: 1.14374033189033
Validation loss: 2.215089212178104

Epoch: 6| Step: 11
Training loss: 0.9780033925666552
Validation loss: 2.2425896520232085

Epoch: 6| Step: 12
Training loss: 1.0484547438816596
Validation loss: 2.267814581293885

Epoch: 6| Step: 13
Training loss: 1.2773119721265742
Validation loss: 2.2459303239217467

Epoch: 219| Step: 0
Training loss: 0.9404480358960151
Validation loss: 2.2858840662607984

Epoch: 6| Step: 1
Training loss: 1.45125590885875
Validation loss: 2.3024231479821062

Epoch: 6| Step: 2
Training loss: 0.931502805868398
Validation loss: 2.312794680722928

Epoch: 6| Step: 3
Training loss: 1.4470178389434953
Validation loss: 2.330247128639818

Epoch: 6| Step: 4
Training loss: 1.0034166619136866
Validation loss: 2.2850487748892503

Epoch: 6| Step: 5
Training loss: 1.1593129082270341
Validation loss: 2.297930995609508

Epoch: 6| Step: 6
Training loss: 1.2904462381106698
Validation loss: 2.28643627456503

Epoch: 6| Step: 7
Training loss: 1.131366991347915
Validation loss: 2.2821326914360514

Epoch: 6| Step: 8
Training loss: 0.9457678210611076
Validation loss: 2.2569769594823113

Epoch: 6| Step: 9
Training loss: 1.1007351846037974
Validation loss: 2.2433160959475122

Epoch: 6| Step: 10
Training loss: 0.9077381543495224
Validation loss: 2.256989505171802

Epoch: 6| Step: 11
Training loss: 1.258824385686754
Validation loss: 2.2205568190131166

Epoch: 6| Step: 12
Training loss: 1.041924285821354
Validation loss: 2.221422915075328

Epoch: 6| Step: 13
Training loss: 1.1982620349536723
Validation loss: 2.2363674035881234

Epoch: 220| Step: 0
Training loss: 1.219659759182556
Validation loss: 2.2414920261809765

Epoch: 6| Step: 1
Training loss: 0.8917306094252452
Validation loss: 2.262085477549143

Epoch: 6| Step: 2
Training loss: 1.2339794152798051
Validation loss: 2.2662097638778724

Epoch: 6| Step: 3
Training loss: 1.0114208357224967
Validation loss: 2.242715008678774

Epoch: 6| Step: 4
Training loss: 0.479480347030726
Validation loss: 2.2610627856655303

Epoch: 6| Step: 5
Training loss: 0.8310495593835062
Validation loss: 2.244229598496576

Epoch: 6| Step: 6
Training loss: 0.9498201827476338
Validation loss: 2.2838258348066973

Epoch: 6| Step: 7
Training loss: 1.1638628385193384
Validation loss: 2.303135917217944

Epoch: 6| Step: 8
Training loss: 1.3022196380479651
Validation loss: 2.2758899357588147

Epoch: 6| Step: 9
Training loss: 1.2498152119425459
Validation loss: 2.2998746273777098

Epoch: 6| Step: 10
Training loss: 1.3789458012514493
Validation loss: 2.280331678385193

Epoch: 6| Step: 11
Training loss: 1.31731005694666
Validation loss: 2.3026520514659476

Epoch: 6| Step: 12
Training loss: 1.4372759105332795
Validation loss: 2.2568971396622097

Epoch: 6| Step: 13
Training loss: 0.6413856967694965
Validation loss: 2.2621363659270513

Epoch: 221| Step: 0
Training loss: 1.350152796469493
Validation loss: 2.237309716679157

Epoch: 6| Step: 1
Training loss: 0.9569247439540012
Validation loss: 2.2251496088532914

Epoch: 6| Step: 2
Training loss: 1.155614368891157
Validation loss: 2.235303368529118

Epoch: 6| Step: 3
Training loss: 1.0056935590343747
Validation loss: 2.237559058809568

Epoch: 6| Step: 4
Training loss: 1.3678719687307563
Validation loss: 2.2648384440348086

Epoch: 6| Step: 5
Training loss: 1.1229299467831397
Validation loss: 2.251478811012425

Epoch: 6| Step: 6
Training loss: 0.9589346816478924
Validation loss: 2.257346618596144

Epoch: 6| Step: 7
Training loss: 1.0941198541099009
Validation loss: 2.286106495627947

Epoch: 6| Step: 8
Training loss: 1.282953386085847
Validation loss: 2.304651418118077

Epoch: 6| Step: 9
Training loss: 0.9965089717926225
Validation loss: 2.307881579986822

Epoch: 6| Step: 10
Training loss: 0.8667195062546348
Validation loss: 2.275282868878438

Epoch: 6| Step: 11
Training loss: 0.9532221134927957
Validation loss: 2.249578601703095

Epoch: 6| Step: 12
Training loss: 1.2526163852701095
Validation loss: 2.3061208020544965

Epoch: 6| Step: 13
Training loss: 1.2223130984670842
Validation loss: 2.279941204749855

Epoch: 222| Step: 0
Training loss: 1.2470814010617044
Validation loss: 2.2671288602070536

Epoch: 6| Step: 1
Training loss: 1.165257192881264
Validation loss: 2.2925445398466398

Epoch: 6| Step: 2
Training loss: 1.1402840300644268
Validation loss: 2.225630675488419

Epoch: 6| Step: 3
Training loss: 1.494202616284469
Validation loss: 2.251674597485524

Epoch: 6| Step: 4
Training loss: 1.3709062844821012
Validation loss: 2.267134021114644

Epoch: 6| Step: 5
Training loss: 0.9124339994312047
Validation loss: 2.2514151574421613

Epoch: 6| Step: 6
Training loss: 0.757465873176138
Validation loss: 2.255883394591204

Epoch: 6| Step: 7
Training loss: 0.49664723316145076
Validation loss: 2.2658927049281123

Epoch: 6| Step: 8
Training loss: 1.399947816012434
Validation loss: 2.2273980930772526

Epoch: 6| Step: 9
Training loss: 1.4397588480250116
Validation loss: 2.2660080101898257

Epoch: 6| Step: 10
Training loss: 0.7671018098107906
Validation loss: 2.2619830734443105

Epoch: 6| Step: 11
Training loss: 0.9010786956646126
Validation loss: 2.272637699082943

Epoch: 6| Step: 12
Training loss: 0.6845410350247355
Validation loss: 2.2505939239836876

Epoch: 6| Step: 13
Training loss: 1.1714648228279636
Validation loss: 2.256414892157974

Epoch: 223| Step: 0
Training loss: 1.145355760868416
Validation loss: 2.294090744879872

Epoch: 6| Step: 1
Training loss: 1.3880889570494015
Validation loss: 2.297775503887376

Epoch: 6| Step: 2
Training loss: 0.723568685678661
Validation loss: 2.281620153496554

Epoch: 6| Step: 3
Training loss: 0.8395780631026956
Validation loss: 2.2823425331182934

Epoch: 6| Step: 4
Training loss: 1.1564143296047
Validation loss: 2.3141413990898734

Epoch: 6| Step: 5
Training loss: 1.3752514002462948
Validation loss: 2.305545701188174

Epoch: 6| Step: 6
Training loss: 0.8098289527549533
Validation loss: 2.2952649219554626

Epoch: 6| Step: 7
Training loss: 1.0492013164330214
Validation loss: 2.2712054089390157

Epoch: 6| Step: 8
Training loss: 1.3860569623963899
Validation loss: 2.3126860934218816

Epoch: 6| Step: 9
Training loss: 1.0876731997718585
Validation loss: 2.2922637661251235

Epoch: 6| Step: 10
Training loss: 0.7365162252489293
Validation loss: 2.2679324678622566

Epoch: 6| Step: 11
Training loss: 1.3461164883261154
Validation loss: 2.2908296613378405

Epoch: 6| Step: 12
Training loss: 1.0262187992050515
Validation loss: 2.2680457648188805

Epoch: 6| Step: 13
Training loss: 0.8142201481501335
Validation loss: 2.2757981379549648

Epoch: 224| Step: 0
Training loss: 0.972630634506764
Validation loss: 2.274467218994922

Epoch: 6| Step: 1
Training loss: 1.3556610762499075
Validation loss: 2.268250883347959

Epoch: 6| Step: 2
Training loss: 1.1567077761516908
Validation loss: 2.29186263230044

Epoch: 6| Step: 3
Training loss: 1.066827544110568
Validation loss: 2.3038296406665895

Epoch: 6| Step: 4
Training loss: 0.6279724723513863
Validation loss: 2.3089357760602

Epoch: 6| Step: 5
Training loss: 1.0088264037437884
Validation loss: 2.315511061296033

Epoch: 6| Step: 6
Training loss: 1.0034286609831788
Validation loss: 2.3467871645298435

Epoch: 6| Step: 7
Training loss: 1.1893465341999325
Validation loss: 2.3231767471758515

Epoch: 6| Step: 8
Training loss: 1.3248818236858309
Validation loss: 2.3282791568966337

Epoch: 6| Step: 9
Training loss: 0.9416200703651767
Validation loss: 2.3067934898475007

Epoch: 6| Step: 10
Training loss: 1.2212417268814473
Validation loss: 2.3117191217952673

Epoch: 6| Step: 11
Training loss: 1.2376405038928795
Validation loss: 2.305388437852987

Epoch: 6| Step: 12
Training loss: 0.787981860770178
Validation loss: 2.2367679481378993

Epoch: 6| Step: 13
Training loss: 1.039948164858543
Validation loss: 2.2228817659818576

Epoch: 225| Step: 0
Training loss: 1.089487543995115
Validation loss: 2.1925329283826644

Epoch: 6| Step: 1
Training loss: 1.4361517844885336
Validation loss: 2.227678114955172

Epoch: 6| Step: 2
Training loss: 1.1063340106681212
Validation loss: 2.187420307119977

Epoch: 6| Step: 3
Training loss: 1.4985083474762677
Validation loss: 2.202209243933537

Epoch: 6| Step: 4
Training loss: 1.189536105864703
Validation loss: 2.2469365219234216

Epoch: 6| Step: 5
Training loss: 0.9215137291049572
Validation loss: 2.247614561087653

Epoch: 6| Step: 6
Training loss: 1.1995681601586439
Validation loss: 2.2649377387991465

Epoch: 6| Step: 7
Training loss: 0.9190632889324954
Validation loss: 2.309201733921189

Epoch: 6| Step: 8
Training loss: 1.132845174383976
Validation loss: 2.316390075610524

Epoch: 6| Step: 9
Training loss: 1.1173208730620434
Validation loss: 2.3324208009714607

Epoch: 6| Step: 10
Training loss: 0.5170468752895808
Validation loss: 2.3246951118208106

Epoch: 6| Step: 11
Training loss: 1.0059507458120789
Validation loss: 2.3353866117976305

Epoch: 6| Step: 12
Training loss: 0.8353654561951032
Validation loss: 2.3109085603921926

Epoch: 6| Step: 13
Training loss: 0.7448994929727383
Validation loss: 2.3135202247599773

Epoch: 226| Step: 0
Training loss: 0.9465685294945688
Validation loss: 2.3092694053535157

Epoch: 6| Step: 1
Training loss: 0.8186720658112879
Validation loss: 2.2947093371415095

Epoch: 6| Step: 2
Training loss: 0.8003228340837204
Validation loss: 2.2945688029579565

Epoch: 6| Step: 3
Training loss: 0.9193466234528235
Validation loss: 2.264771600830432

Epoch: 6| Step: 4
Training loss: 1.6604063316926592
Validation loss: 2.269791228405728

Epoch: 6| Step: 5
Training loss: 0.8655436288204793
Validation loss: 2.278255548808462

Epoch: 6| Step: 6
Training loss: 1.0586133441308145
Validation loss: 2.278522479725066

Epoch: 6| Step: 7
Training loss: 0.9479062774983165
Validation loss: 2.280839279315541

Epoch: 6| Step: 8
Training loss: 1.121252812921064
Validation loss: 2.227874662244964

Epoch: 6| Step: 9
Training loss: 0.7577612161489019
Validation loss: 2.236826914347084

Epoch: 6| Step: 10
Training loss: 1.0682185496908225
Validation loss: 2.2205165732333962

Epoch: 6| Step: 11
Training loss: 1.160706463462546
Validation loss: 2.2302017346615326

Epoch: 6| Step: 12
Training loss: 1.5064705524978617
Validation loss: 2.2248622093705492

Epoch: 6| Step: 13
Training loss: 1.0617128148870913
Validation loss: 2.2396370055475

Epoch: 227| Step: 0
Training loss: 1.4388845658861285
Validation loss: 2.2588864350670477

Epoch: 6| Step: 1
Training loss: 1.0195482040691024
Validation loss: 2.2198300330547154

Epoch: 6| Step: 2
Training loss: 0.9447092700990005
Validation loss: 2.2417771095796675

Epoch: 6| Step: 3
Training loss: 1.128226633328217
Validation loss: 2.2277743245733284

Epoch: 6| Step: 4
Training loss: 0.9183888224979906
Validation loss: 2.27378454034426

Epoch: 6| Step: 5
Training loss: 1.2060434194185154
Validation loss: 2.2557383003659583

Epoch: 6| Step: 6
Training loss: 0.7379290431912724
Validation loss: 2.2594969445229003

Epoch: 6| Step: 7
Training loss: 1.4094018159670856
Validation loss: 2.2632753968736137

Epoch: 6| Step: 8
Training loss: 0.6233333299844235
Validation loss: 2.275275344530276

Epoch: 6| Step: 9
Training loss: 1.0489461537588154
Validation loss: 2.3042172621895105

Epoch: 6| Step: 10
Training loss: 0.8482815945242187
Validation loss: 2.3114628127363375

Epoch: 6| Step: 11
Training loss: 1.1037147004821604
Validation loss: 2.3031591743937754

Epoch: 6| Step: 12
Training loss: 1.0938821440297672
Validation loss: 2.3234600778137264

Epoch: 6| Step: 13
Training loss: 0.8430550150177375
Validation loss: 2.3031836668601366

Epoch: 228| Step: 0
Training loss: 0.8792661481019259
Validation loss: 2.294984452566735

Epoch: 6| Step: 1
Training loss: 1.1821798812293995
Validation loss: 2.293202892298828

Epoch: 6| Step: 2
Training loss: 1.0246708550807089
Validation loss: 2.3165790066173066

Epoch: 6| Step: 3
Training loss: 0.6712041211210867
Validation loss: 2.2667283519673203

Epoch: 6| Step: 4
Training loss: 1.0235247392818587
Validation loss: 2.2733371242935387

Epoch: 6| Step: 5
Training loss: 1.4098312552912124
Validation loss: 2.261314805305412

Epoch: 6| Step: 6
Training loss: 0.9756752561324271
Validation loss: 2.2758073671852674

Epoch: 6| Step: 7
Training loss: 1.2854174316667766
Validation loss: 2.235088581806386

Epoch: 6| Step: 8
Training loss: 1.2282211363149784
Validation loss: 2.219077628437514

Epoch: 6| Step: 9
Training loss: 1.1364614188865967
Validation loss: 2.232794242285993

Epoch: 6| Step: 10
Training loss: 1.152636474671403
Validation loss: 2.2585412378114937

Epoch: 6| Step: 11
Training loss: 0.9399724147685494
Validation loss: 2.2206370607523307

Epoch: 6| Step: 12
Training loss: 0.9532461871039136
Validation loss: 2.2472728366256645

Epoch: 6| Step: 13
Training loss: 0.5008304672931454
Validation loss: 2.2497607808118274

Epoch: 229| Step: 0
Training loss: 0.8731378085508308
Validation loss: 2.284977913358855

Epoch: 6| Step: 1
Training loss: 1.0460402163766667
Validation loss: 2.2826462014532485

Epoch: 6| Step: 2
Training loss: 1.065275214279342
Validation loss: 2.3008749685948926

Epoch: 6| Step: 3
Training loss: 0.9016040891578302
Validation loss: 2.3220485516563705

Epoch: 6| Step: 4
Training loss: 0.9422853093281077
Validation loss: 2.312928951248679

Epoch: 6| Step: 5
Training loss: 0.8943556567432199
Validation loss: 2.334863794381408

Epoch: 6| Step: 6
Training loss: 1.4007283206605328
Validation loss: 2.3639088454237047

Epoch: 6| Step: 7
Training loss: 1.1581204209543399
Validation loss: 2.3201224680617645

Epoch: 6| Step: 8
Training loss: 1.1290490083286941
Validation loss: 2.3553594917174436

Epoch: 6| Step: 9
Training loss: 0.9639248507024115
Validation loss: 2.361357662298093

Epoch: 6| Step: 10
Training loss: 1.2103782100554161
Validation loss: 2.304336233537727

Epoch: 6| Step: 11
Training loss: 0.8570474141490889
Validation loss: 2.339824215644475

Epoch: 6| Step: 12
Training loss: 0.9629446327894577
Validation loss: 2.3194619686683047

Epoch: 6| Step: 13
Training loss: 1.1976921976944206
Validation loss: 2.3156224125939042

Epoch: 230| Step: 0
Training loss: 1.1252693277736119
Validation loss: 2.305505091477347

Epoch: 6| Step: 1
Training loss: 0.8982324780932485
Validation loss: 2.2927016071019777

Epoch: 6| Step: 2
Training loss: 1.0714280378249519
Validation loss: 2.255713670060586

Epoch: 6| Step: 3
Training loss: 1.0247532198562905
Validation loss: 2.2310615049173856

Epoch: 6| Step: 4
Training loss: 1.2098157547740782
Validation loss: 2.244783982250749

Epoch: 6| Step: 5
Training loss: 0.7653306667777648
Validation loss: 2.2282564004657885

Epoch: 6| Step: 6
Training loss: 1.3113582276953537
Validation loss: 2.269899827434523

Epoch: 6| Step: 7
Training loss: 1.1743444744729021
Validation loss: 2.276518614733915

Epoch: 6| Step: 8
Training loss: 1.2452624187665857
Validation loss: 2.271441096559962

Epoch: 6| Step: 9
Training loss: 0.6550721088058097
Validation loss: 2.3163861190130595

Epoch: 6| Step: 10
Training loss: 1.390545060506846
Validation loss: 2.319774195250192

Epoch: 6| Step: 11
Training loss: 0.9311650499858196
Validation loss: 2.3302332286487757

Epoch: 6| Step: 12
Training loss: 0.7373390038190621
Validation loss: 2.35227956847461

Epoch: 6| Step: 13
Training loss: 0.41559941779546555
Validation loss: 2.3391213425674193

Epoch: 231| Step: 0
Training loss: 1.6112300218715288
Validation loss: 2.326115974340142

Epoch: 6| Step: 1
Training loss: 1.2099020191592278
Validation loss: 2.2939595726275868

Epoch: 6| Step: 2
Training loss: 0.8172600037483828
Validation loss: 2.2909931408739665

Epoch: 6| Step: 3
Training loss: 1.2222641873861742
Validation loss: 2.2910285303612086

Epoch: 6| Step: 4
Training loss: 1.1442471304539343
Validation loss: 2.2635074811910134

Epoch: 6| Step: 5
Training loss: 0.8779458457130261
Validation loss: 2.247607001144323

Epoch: 6| Step: 6
Training loss: 1.0530217898361316
Validation loss: 2.228454499850981

Epoch: 6| Step: 7
Training loss: 0.7140181730105423
Validation loss: 2.23161234505712

Epoch: 6| Step: 8
Training loss: 0.8136868977727961
Validation loss: 2.2359780583861903

Epoch: 6| Step: 9
Training loss: 0.8594352701033509
Validation loss: 2.260516822319591

Epoch: 6| Step: 10
Training loss: 0.8750040871660961
Validation loss: 2.304853997491663

Epoch: 6| Step: 11
Training loss: 1.175726398189761
Validation loss: 2.351697642120749

Epoch: 6| Step: 12
Training loss: 0.9559139970357434
Validation loss: 2.3731235870030702

Epoch: 6| Step: 13
Training loss: 1.1290816860432373
Validation loss: 2.3662057965855374

Epoch: 232| Step: 0
Training loss: 0.9588269883420043
Validation loss: 2.3241601820946585

Epoch: 6| Step: 1
Training loss: 0.7173071767648208
Validation loss: 2.3235767316412743

Epoch: 6| Step: 2
Training loss: 0.9568437665131203
Validation loss: 2.2767217861810702

Epoch: 6| Step: 3
Training loss: 1.1133651434090652
Validation loss: 2.2573856677419277

Epoch: 6| Step: 4
Training loss: 1.331771243496522
Validation loss: 2.260358475575519

Epoch: 6| Step: 5
Training loss: 1.2878631098280853
Validation loss: 2.248626138000997

Epoch: 6| Step: 6
Training loss: 1.1351353474718677
Validation loss: 2.2560672923620557

Epoch: 6| Step: 7
Training loss: 1.0300094772569501
Validation loss: 2.263757391800047

Epoch: 6| Step: 8
Training loss: 1.3059933916862339
Validation loss: 2.307083035636085

Epoch: 6| Step: 9
Training loss: 1.1500996090416575
Validation loss: 2.333369736746384

Epoch: 6| Step: 10
Training loss: 1.1056518942158813
Validation loss: 2.3355971054844678

Epoch: 6| Step: 11
Training loss: 1.0208830659131283
Validation loss: 2.339632179941728

Epoch: 6| Step: 12
Training loss: 0.6893623011258975
Validation loss: 2.3545582523940523

Epoch: 6| Step: 13
Training loss: 1.1377072575150824
Validation loss: 2.3921449791448275

Epoch: 233| Step: 0
Training loss: 1.2463684257630054
Validation loss: 2.3584938916774774

Epoch: 6| Step: 1
Training loss: 1.1294149552810355
Validation loss: 2.28852583326114

Epoch: 6| Step: 2
Training loss: 1.0473706794246287
Validation loss: 2.2968591663427884

Epoch: 6| Step: 3
Training loss: 1.1759321046290323
Validation loss: 2.2743518635404545

Epoch: 6| Step: 4
Training loss: 1.2595446015684195
Validation loss: 2.2656744182488424

Epoch: 6| Step: 5
Training loss: 1.286141803220521
Validation loss: 2.2701879338511253

Epoch: 6| Step: 6
Training loss: 0.9837519475294755
Validation loss: 2.2547132212922083

Epoch: 6| Step: 7
Training loss: 1.062814890256783
Validation loss: 2.2465311676874027

Epoch: 6| Step: 8
Training loss: 0.8174426787225704
Validation loss: 2.256547149405995

Epoch: 6| Step: 9
Training loss: 0.8563796119326328
Validation loss: 2.2805337651047544

Epoch: 6| Step: 10
Training loss: 1.0036049476033295
Validation loss: 2.275933040614477

Epoch: 6| Step: 11
Training loss: 1.0988888048110466
Validation loss: 2.338734869808909

Epoch: 6| Step: 12
Training loss: 1.0014663316854195
Validation loss: 2.341359626569451

Epoch: 6| Step: 13
Training loss: 1.5032405023749016
Validation loss: 2.3315300308965545

Epoch: 234| Step: 0
Training loss: 0.9932501201423133
Validation loss: 2.3164687186384376

Epoch: 6| Step: 1
Training loss: 0.6108057392214209
Validation loss: 2.30248665681185

Epoch: 6| Step: 2
Training loss: 0.7514301810099713
Validation loss: 2.280663044356338

Epoch: 6| Step: 3
Training loss: 1.1758818219030478
Validation loss: 2.241916142280879

Epoch: 6| Step: 4
Training loss: 1.2546347525068307
Validation loss: 2.2298071273482005

Epoch: 6| Step: 5
Training loss: 1.0713429189687185
Validation loss: 2.2356471318309907

Epoch: 6| Step: 6
Training loss: 1.0820017235648764
Validation loss: 2.2414055735318916

Epoch: 6| Step: 7
Training loss: 0.8063950799923435
Validation loss: 2.2753496190555054

Epoch: 6| Step: 8
Training loss: 1.329843105441056
Validation loss: 2.2664975996169545

Epoch: 6| Step: 9
Training loss: 0.9912045934314375
Validation loss: 2.312155520815217

Epoch: 6| Step: 10
Training loss: 0.9824830902624596
Validation loss: 2.308625506096987

Epoch: 6| Step: 11
Training loss: 1.4222705835739486
Validation loss: 2.308484394281924

Epoch: 6| Step: 12
Training loss: 1.1090150168479682
Validation loss: 2.348650864417553

Epoch: 6| Step: 13
Training loss: 1.0810531437009077
Validation loss: 2.333227826698149

Epoch: 235| Step: 0
Training loss: 1.0287618965953562
Validation loss: 2.367508815435333

Epoch: 6| Step: 1
Training loss: 1.0103250573437155
Validation loss: 2.349630202768102

Epoch: 6| Step: 2
Training loss: 1.1299977025709176
Validation loss: 2.3267395727003493

Epoch: 6| Step: 3
Training loss: 0.6485460948782702
Validation loss: 2.3273577651296966

Epoch: 6| Step: 4
Training loss: 0.9858766032182077
Validation loss: 2.2747002137371775

Epoch: 6| Step: 5
Training loss: 1.126507861205201
Validation loss: 2.2836552154655148

Epoch: 6| Step: 6
Training loss: 0.6740999862016722
Validation loss: 2.2684573835552273

Epoch: 6| Step: 7
Training loss: 0.8671070095888892
Validation loss: 2.230020747212169

Epoch: 6| Step: 8
Training loss: 1.0181000701680958
Validation loss: 2.2106317372270023

Epoch: 6| Step: 9
Training loss: 0.8377418652773896
Validation loss: 2.221614423133765

Epoch: 6| Step: 10
Training loss: 1.619172430703896
Validation loss: 2.2198842760210984

Epoch: 6| Step: 11
Training loss: 0.7747437207194321
Validation loss: 2.249153331120143

Epoch: 6| Step: 12
Training loss: 1.305462726827957
Validation loss: 2.284177886133468

Epoch: 6| Step: 13
Training loss: 1.3844729868911398
Validation loss: 2.306360157315763

Epoch: 236| Step: 0
Training loss: 1.0737776526908227
Validation loss: 2.3463409016639525

Epoch: 6| Step: 1
Training loss: 1.1839510438179928
Validation loss: 2.3150196544250794

Epoch: 6| Step: 2
Training loss: 0.9812926216344908
Validation loss: 2.304847149179857

Epoch: 6| Step: 3
Training loss: 0.3950346388597916
Validation loss: 2.3281067410259793

Epoch: 6| Step: 4
Training loss: 1.1337106235652108
Validation loss: 2.3138321662040564

Epoch: 6| Step: 5
Training loss: 0.9724703998032536
Validation loss: 2.322644121745105

Epoch: 6| Step: 6
Training loss: 0.948272453162963
Validation loss: 2.2889951492823037

Epoch: 6| Step: 7
Training loss: 0.9794861935007121
Validation loss: 2.2870184865596506

Epoch: 6| Step: 8
Training loss: 1.2665858918502215
Validation loss: 2.255372870952238

Epoch: 6| Step: 9
Training loss: 0.926020080406357
Validation loss: 2.2707464982953582

Epoch: 6| Step: 10
Training loss: 1.0795382207418223
Validation loss: 2.262351895882216

Epoch: 6| Step: 11
Training loss: 1.1908531030535916
Validation loss: 2.250587138383618

Epoch: 6| Step: 12
Training loss: 0.7803841943157966
Validation loss: 2.2150622954506933

Epoch: 6| Step: 13
Training loss: 1.2647316688043113
Validation loss: 2.1966341521853017

Epoch: 237| Step: 0
Training loss: 0.8692284700384043
Validation loss: 2.2048159134885057

Epoch: 6| Step: 1
Training loss: 0.9989389810819064
Validation loss: 2.1979948789133865

Epoch: 6| Step: 2
Training loss: 1.105300189535597
Validation loss: 2.208501417790932

Epoch: 6| Step: 3
Training loss: 1.0257292270179366
Validation loss: 2.2151474100776696

Epoch: 6| Step: 4
Training loss: 0.9955202733173627
Validation loss: 2.253318137912347

Epoch: 6| Step: 5
Training loss: 0.9359853588980616
Validation loss: 2.2755783601452975

Epoch: 6| Step: 6
Training loss: 0.866155336610398
Validation loss: 2.2879506028934666

Epoch: 6| Step: 7
Training loss: 0.9381295951105529
Validation loss: 2.3173621368588675

Epoch: 6| Step: 8
Training loss: 0.9140095817702238
Validation loss: 2.325133543604179

Epoch: 6| Step: 9
Training loss: 1.2348157844142578
Validation loss: 2.34008285596638

Epoch: 6| Step: 10
Training loss: 0.9609519523216108
Validation loss: 2.343801149746726

Epoch: 6| Step: 11
Training loss: 1.2695836452529234
Validation loss: 2.3366601489939627

Epoch: 6| Step: 12
Training loss: 1.227135008332138
Validation loss: 2.314464046836204

Epoch: 6| Step: 13
Training loss: 0.43758887001416147
Validation loss: 2.2732719956260827

Epoch: 238| Step: 0
Training loss: 1.3358939537402093
Validation loss: 2.2813046676821465

Epoch: 6| Step: 1
Training loss: 0.7271482915926819
Validation loss: 2.2299974365712596

Epoch: 6| Step: 2
Training loss: 1.1378303153034925
Validation loss: 2.2556069606338034

Epoch: 6| Step: 3
Training loss: 1.3489143580433074
Validation loss: 2.231052508561226

Epoch: 6| Step: 4
Training loss: 0.6727118270899861
Validation loss: 2.2409883785464184

Epoch: 6| Step: 5
Training loss: 0.5458671001249666
Validation loss: 2.2641295541817197

Epoch: 6| Step: 6
Training loss: 1.1696834671558403
Validation loss: 2.290965594637369

Epoch: 6| Step: 7
Training loss: 1.0085892160847092
Validation loss: 2.2830749712669456

Epoch: 6| Step: 8
Training loss: 0.9271450057929532
Validation loss: 2.2822484466583144

Epoch: 6| Step: 9
Training loss: 0.8117652284975394
Validation loss: 2.2866864394872697

Epoch: 6| Step: 10
Training loss: 0.7096621213782038
Validation loss: 2.2951076891573647

Epoch: 6| Step: 11
Training loss: 0.9705181905092163
Validation loss: 2.297211282620588

Epoch: 6| Step: 12
Training loss: 1.1731905864089494
Validation loss: 2.327951566726607

Epoch: 6| Step: 13
Training loss: 0.9323540600973294
Validation loss: 2.320760694207166

Epoch: 239| Step: 0
Training loss: 0.5915834904577499
Validation loss: 2.3174453258900356

Epoch: 6| Step: 1
Training loss: 1.2783493143613753
Validation loss: 2.3235297618781985

Epoch: 6| Step: 2
Training loss: 0.8701417108198924
Validation loss: 2.3139600044396555

Epoch: 6| Step: 3
Training loss: 1.292234460053498
Validation loss: 2.2649539789735833

Epoch: 6| Step: 4
Training loss: 0.9371788746486812
Validation loss: 2.2930393740935915

Epoch: 6| Step: 5
Training loss: 0.893020453503969
Validation loss: 2.2712192119108323

Epoch: 6| Step: 6
Training loss: 0.9622558296425441
Validation loss: 2.281812283047459

Epoch: 6| Step: 7
Training loss: 0.7390675066723914
Validation loss: 2.2248071791842774

Epoch: 6| Step: 8
Training loss: 1.0746778582123504
Validation loss: 2.2553072607412887

Epoch: 6| Step: 9
Training loss: 1.1248585294146547
Validation loss: 2.2594928020696154

Epoch: 6| Step: 10
Training loss: 0.2781959523554087
Validation loss: 2.26128813498005

Epoch: 6| Step: 11
Training loss: 1.364193018451158
Validation loss: 2.2414944674512967

Epoch: 6| Step: 12
Training loss: 0.8425029793638531
Validation loss: 2.2848182873548963

Epoch: 6| Step: 13
Training loss: 0.745231889568023
Validation loss: 2.2673906992516963

Epoch: 240| Step: 0
Training loss: 0.9293270213627925
Validation loss: 2.2332024572971183

Epoch: 6| Step: 1
Training loss: 0.9653105436720804
Validation loss: 2.275253416400668

Epoch: 6| Step: 2
Training loss: 0.9691801961794687
Validation loss: 2.2915504030807514

Epoch: 6| Step: 3
Training loss: 1.0475313776456052
Validation loss: 2.2477475813620074

Epoch: 6| Step: 4
Training loss: 0.9502496968434209
Validation loss: 2.294510753620953

Epoch: 6| Step: 5
Training loss: 1.1185326114618865
Validation loss: 2.304650613869552

Epoch: 6| Step: 6
Training loss: 1.047264083753033
Validation loss: 2.2971938029676076

Epoch: 6| Step: 7
Training loss: 0.43273114841110183
Validation loss: 2.2913360577232416

Epoch: 6| Step: 8
Training loss: 0.5612666596146949
Validation loss: 2.295540354971479

Epoch: 6| Step: 9
Training loss: 1.0929309503046334
Validation loss: 2.272405206992932

Epoch: 6| Step: 10
Training loss: 1.3175001268911573
Validation loss: 2.2548823122513846

Epoch: 6| Step: 11
Training loss: 0.8436118825259209
Validation loss: 2.2452505224354113

Epoch: 6| Step: 12
Training loss: 0.8951013405928866
Validation loss: 2.238015594606495

Epoch: 6| Step: 13
Training loss: 1.0120092144384543
Validation loss: 2.278484318835053

Epoch: 241| Step: 0
Training loss: 0.5603173613457065
Validation loss: 2.24012771099183

Epoch: 6| Step: 1
Training loss: 0.6296844406621556
Validation loss: 2.2656457958745095

Epoch: 6| Step: 2
Training loss: 1.2293473234876942
Validation loss: 2.2338763701128985

Epoch: 6| Step: 3
Training loss: 0.8805536048164246
Validation loss: 2.264006884163336

Epoch: 6| Step: 4
Training loss: 0.6815257153210882
Validation loss: 2.2802298019557976

Epoch: 6| Step: 5
Training loss: 0.7722884225447045
Validation loss: 2.266136560335232

Epoch: 6| Step: 6
Training loss: 1.0290940607897603
Validation loss: 2.2844623699627844

Epoch: 6| Step: 7
Training loss: 1.1274678395288058
Validation loss: 2.30486669578957

Epoch: 6| Step: 8
Training loss: 0.8142727805427444
Validation loss: 2.2712174541628776

Epoch: 6| Step: 9
Training loss: 0.9564735811935156
Validation loss: 2.299972129223112

Epoch: 6| Step: 10
Training loss: 1.196523215285862
Validation loss: 2.2838123128883243

Epoch: 6| Step: 11
Training loss: 0.9507602999658644
Validation loss: 2.291631216929113

Epoch: 6| Step: 12
Training loss: 1.2091452348274565
Validation loss: 2.26883511450426

Epoch: 6| Step: 13
Training loss: 1.2403495675005067
Validation loss: 2.2910334550359392

Epoch: 242| Step: 0
Training loss: 0.749612350418205
Validation loss: 2.273932415468864

Epoch: 6| Step: 1
Training loss: 0.6504700758235779
Validation loss: 2.224126550980603

Epoch: 6| Step: 2
Training loss: 1.4223578335428202
Validation loss: 2.223744343026891

Epoch: 6| Step: 3
Training loss: 0.675450591408673
Validation loss: 2.1858626529784737

Epoch: 6| Step: 4
Training loss: 0.8142542241695228
Validation loss: 2.1982808107176752

Epoch: 6| Step: 5
Training loss: 1.1899485190659904
Validation loss: 2.1960500296375915

Epoch: 6| Step: 6
Training loss: 1.1350368366061434
Validation loss: 2.213943087946786

Epoch: 6| Step: 7
Training loss: 0.4959237415638321
Validation loss: 2.236292392624184

Epoch: 6| Step: 8
Training loss: 1.0762240471629374
Validation loss: 2.233940999679293

Epoch: 6| Step: 9
Training loss: 0.8227921202526625
Validation loss: 2.2563657653486513

Epoch: 6| Step: 10
Training loss: 0.40834158050551667
Validation loss: 2.311048103455836

Epoch: 6| Step: 11
Training loss: 1.1187659363703788
Validation loss: 2.314444610357123

Epoch: 6| Step: 12
Training loss: 1.2571609420683116
Validation loss: 2.341212743865432

Epoch: 6| Step: 13
Training loss: 0.7429178358857915
Validation loss: 2.3284611051578623

Epoch: 243| Step: 0
Training loss: 0.491809275791208
Validation loss: 2.325336561212593

Epoch: 6| Step: 1
Training loss: 1.0097833923311452
Validation loss: 2.2785759341627503

Epoch: 6| Step: 2
Training loss: 1.0009896626429353
Validation loss: 2.2942857343166456

Epoch: 6| Step: 3
Training loss: 1.1369262715627626
Validation loss: 2.286557540032605

Epoch: 6| Step: 4
Training loss: 1.1401049329750177
Validation loss: 2.2971272455972174

Epoch: 6| Step: 5
Training loss: 0.9360289158063366
Validation loss: 2.261115259429751

Epoch: 6| Step: 6
Training loss: 0.9080887917364514
Validation loss: 2.287541230411408

Epoch: 6| Step: 7
Training loss: 0.8676853984413562
Validation loss: 2.2492390180932182

Epoch: 6| Step: 8
Training loss: 0.9283298869956496
Validation loss: 2.2400814417274453

Epoch: 6| Step: 9
Training loss: 0.9993257037345082
Validation loss: 2.2605688528614416

Epoch: 6| Step: 10
Training loss: 0.776139596652839
Validation loss: 2.239997092562281

Epoch: 6| Step: 11
Training loss: 0.90155225777717
Validation loss: 2.2616904635244506

Epoch: 6| Step: 12
Training loss: 0.7361829700623691
Validation loss: 2.2734473364652144

Epoch: 6| Step: 13
Training loss: 1.3509273028689288
Validation loss: 2.2826909464537817

Epoch: 244| Step: 0
Training loss: 0.4266185402301487
Validation loss: 2.264449442380345

Epoch: 6| Step: 1
Training loss: 0.9257151262192889
Validation loss: 2.276558080227172

Epoch: 6| Step: 2
Training loss: 1.0122500758718669
Validation loss: 2.2634472120977445

Epoch: 6| Step: 3
Training loss: 0.8608574305580863
Validation loss: 2.2549622335187034

Epoch: 6| Step: 4
Training loss: 1.1831237061055682
Validation loss: 2.2549186663935514

Epoch: 6| Step: 5
Training loss: 1.139976526152549
Validation loss: 2.2611264533577193

Epoch: 6| Step: 6
Training loss: 1.0200031109369745
Validation loss: 2.226021357177294

Epoch: 6| Step: 7
Training loss: 0.7454859070011881
Validation loss: 2.2509041066967774

Epoch: 6| Step: 8
Training loss: 0.6338901057172696
Validation loss: 2.247022120584112

Epoch: 6| Step: 9
Training loss: 0.6088695875509551
Validation loss: 2.252357714020288

Epoch: 6| Step: 10
Training loss: 1.1294451948347808
Validation loss: 2.2368222393760293

Epoch: 6| Step: 11
Training loss: 0.9749001354034702
Validation loss: 2.261140037244701

Epoch: 6| Step: 12
Training loss: 1.0948324024716993
Validation loss: 2.257658933803465

Epoch: 6| Step: 13
Training loss: 1.0884614333862728
Validation loss: 2.268647560946715

Epoch: 245| Step: 0
Training loss: 0.9790059153852514
Validation loss: 2.2811975308738037

Epoch: 6| Step: 1
Training loss: 0.7863155934395979
Validation loss: 2.261870633992837

Epoch: 6| Step: 2
Training loss: 0.9747617369300081
Validation loss: 2.3021455462276252

Epoch: 6| Step: 3
Training loss: 0.9182018227634107
Validation loss: 2.2747778147448066

Epoch: 6| Step: 4
Training loss: 0.8065776661832965
Validation loss: 2.284903041882524

Epoch: 6| Step: 5
Training loss: 1.1295528474073533
Validation loss: 2.2700622760816356

Epoch: 6| Step: 6
Training loss: 0.8552820707461697
Validation loss: 2.2624004519103864

Epoch: 6| Step: 7
Training loss: 0.9696664781962562
Validation loss: 2.2565789756066255

Epoch: 6| Step: 8
Training loss: 0.8640853106228104
Validation loss: 2.2967334173788867

Epoch: 6| Step: 9
Training loss: 0.8747091491135255
Validation loss: 2.2482248761824164

Epoch: 6| Step: 10
Training loss: 1.1835220365547665
Validation loss: 2.265107693452495

Epoch: 6| Step: 11
Training loss: 0.5944373519074255
Validation loss: 2.2669983986475994

Epoch: 6| Step: 12
Training loss: 0.9382402041030846
Validation loss: 2.275785170445781

Epoch: 6| Step: 13
Training loss: 0.8273747842675744
Validation loss: 2.235858007729086

Epoch: 246| Step: 0
Training loss: 0.7255007872284733
Validation loss: 2.2603895256538067

Epoch: 6| Step: 1
Training loss: 0.41840053252606574
Validation loss: 2.2668813099909273

Epoch: 6| Step: 2
Training loss: 0.7893122664869681
Validation loss: 2.2667876533717592

Epoch: 6| Step: 3
Training loss: 0.7665119094421099
Validation loss: 2.275778947727391

Epoch: 6| Step: 4
Training loss: 0.9481640517378169
Validation loss: 2.2949099477694945

Epoch: 6| Step: 5
Training loss: 1.0261132591301723
Validation loss: 2.276746594580189

Epoch: 6| Step: 6
Training loss: 1.0979621433826356
Validation loss: 2.2722583054313117

Epoch: 6| Step: 7
Training loss: 0.9029699687484171
Validation loss: 2.271169752895941

Epoch: 6| Step: 8
Training loss: 0.8902620948134883
Validation loss: 2.262623041331565

Epoch: 6| Step: 9
Training loss: 1.2488749209249237
Validation loss: 2.2675196820375727

Epoch: 6| Step: 10
Training loss: 0.9396070960875111
Validation loss: 2.2557561921730267

Epoch: 6| Step: 11
Training loss: 0.8711213248639661
Validation loss: 2.2469042587834047

Epoch: 6| Step: 12
Training loss: 0.8567438942675256
Validation loss: 2.272221387036005

Epoch: 6| Step: 13
Training loss: 1.0080709200009625
Validation loss: 2.236359883575617

Epoch: 247| Step: 0
Training loss: 1.0944972074498311
Validation loss: 2.2454860452603382

Epoch: 6| Step: 1
Training loss: 0.5253826835627742
Validation loss: 2.2770854895187416

Epoch: 6| Step: 2
Training loss: 1.1014694282767101
Validation loss: 2.241033383319532

Epoch: 6| Step: 3
Training loss: 0.756422557532882
Validation loss: 2.230084945920065

Epoch: 6| Step: 4
Training loss: 0.6327622476098543
Validation loss: 2.24338224312287

Epoch: 6| Step: 5
Training loss: 1.1694162642244175
Validation loss: 2.2437442478857212

Epoch: 6| Step: 6
Training loss: 0.7171007390618656
Validation loss: 2.2705179913544384

Epoch: 6| Step: 7
Training loss: 1.0694317500419284
Validation loss: 2.292861786443293

Epoch: 6| Step: 8
Training loss: 0.7149407576313263
Validation loss: 2.2790247489560427

Epoch: 6| Step: 9
Training loss: 1.142750679745302
Validation loss: 2.310172842054264

Epoch: 6| Step: 10
Training loss: 0.5360748315250954
Validation loss: 2.2804933035525625

Epoch: 6| Step: 11
Training loss: 0.9028664928438459
Validation loss: 2.2850780169713136

Epoch: 6| Step: 12
Training loss: 1.094245580387581
Validation loss: 2.271015432198384

Epoch: 6| Step: 13
Training loss: 0.6564624306314731
Validation loss: 2.2686925735647807

Epoch: 248| Step: 0
Training loss: 0.6759675491292009
Validation loss: 2.2860281655926276

Epoch: 6| Step: 1
Training loss: 0.8381610780669831
Validation loss: 2.28536200230335

Epoch: 6| Step: 2
Training loss: 0.9954856362659741
Validation loss: 2.3144234725958515

Epoch: 6| Step: 3
Training loss: 0.7168004090432507
Validation loss: 2.3342796943081967

Epoch: 6| Step: 4
Training loss: 0.9738169412777891
Validation loss: 2.314927589331025

Epoch: 6| Step: 5
Training loss: 1.2743955413524843
Validation loss: 2.28376429405256

Epoch: 6| Step: 6
Training loss: 0.8973784465880361
Validation loss: 2.2835793598487806

Epoch: 6| Step: 7
Training loss: 0.4680298359379557
Validation loss: 2.3202599562695827

Epoch: 6| Step: 8
Training loss: 0.32881346637501885
Validation loss: 2.2777844519041768

Epoch: 6| Step: 9
Training loss: 0.9511489395415631
Validation loss: 2.2643862360716156

Epoch: 6| Step: 10
Training loss: 0.7612211509462202
Validation loss: 2.253403529995266

Epoch: 6| Step: 11
Training loss: 1.326162526430599
Validation loss: 2.288260014362636

Epoch: 6| Step: 12
Training loss: 0.6907472864692066
Validation loss: 2.2666643807350204

Epoch: 6| Step: 13
Training loss: 1.2177991336659673
Validation loss: 2.294943707357258

Epoch: 249| Step: 0
Training loss: 0.6165774746993853
Validation loss: 2.227355936556407

Epoch: 6| Step: 1
Training loss: 0.7203488189742658
Validation loss: 2.2547912117173396

Epoch: 6| Step: 2
Training loss: 0.9752620736054154
Validation loss: 2.2447783131403654

Epoch: 6| Step: 3
Training loss: 0.741385337607013
Validation loss: 2.2689056587613226

Epoch: 6| Step: 4
Training loss: 0.6845699206907536
Validation loss: 2.28280140863821

Epoch: 6| Step: 5
Training loss: 0.82090817576624
Validation loss: 2.2774269568498764

Epoch: 6| Step: 6
Training loss: 0.6722618807788695
Validation loss: 2.2771656920319328

Epoch: 6| Step: 7
Training loss: 1.1959007660642036
Validation loss: 2.2748173941161505

Epoch: 6| Step: 8
Training loss: 1.18393211438192
Validation loss: 2.2539376056394063

Epoch: 6| Step: 9
Training loss: 0.6725872168301421
Validation loss: 2.2648558824952363

Epoch: 6| Step: 10
Training loss: 1.1202337176129928
Validation loss: 2.256598919297038

Epoch: 6| Step: 11
Training loss: 0.6945671415548905
Validation loss: 2.2583251273526006

Epoch: 6| Step: 12
Training loss: 1.2736818980091866
Validation loss: 2.2596996284015853

Epoch: 6| Step: 13
Training loss: 0.36187043603842206
Validation loss: 2.2298267551804765

Epoch: 250| Step: 0
Training loss: 0.8412404710816637
Validation loss: 2.209933531411262

Epoch: 6| Step: 1
Training loss: 0.7611619919764995
Validation loss: 2.2306539695209993

Epoch: 6| Step: 2
Training loss: 1.0164113448511576
Validation loss: 2.2509697860257374

Epoch: 6| Step: 3
Training loss: 0.8844133564210058
Validation loss: 2.2215054537481635

Epoch: 6| Step: 4
Training loss: 0.7633400120366646
Validation loss: 2.2319853275104378

Epoch: 6| Step: 5
Training loss: 0.8038616572135661
Validation loss: 2.2429151948816854

Epoch: 6| Step: 6
Training loss: 1.0935401170171763
Validation loss: 2.236033260216814

Epoch: 6| Step: 7
Training loss: 0.8855485967443528
Validation loss: 2.2209323795710176

Epoch: 6| Step: 8
Training loss: 1.0409655245808016
Validation loss: 2.203166442588364

Epoch: 6| Step: 9
Training loss: 0.8199552575558395
Validation loss: 2.19989629801251

Epoch: 6| Step: 10
Training loss: 0.9533511034325264
Validation loss: 2.217472255023749

Epoch: 6| Step: 11
Training loss: 0.8865999654787532
Validation loss: 2.229627952732259

Epoch: 6| Step: 12
Training loss: 0.8802774541376841
Validation loss: 2.2194826983680387

Epoch: 6| Step: 13
Training loss: 0.5045645206712898
Validation loss: 2.21445796717707

Epoch: 251| Step: 0
Training loss: 1.3050988742305865
Validation loss: 2.218915637065936

Epoch: 6| Step: 1
Training loss: 0.8838668536098215
Validation loss: 2.2708441263758776

Epoch: 6| Step: 2
Training loss: 0.8926070728240595
Validation loss: 2.2637858596885754

Epoch: 6| Step: 3
Training loss: 0.854077431429259
Validation loss: 2.2764281579279833

Epoch: 6| Step: 4
Training loss: 0.20244444031932898
Validation loss: 2.2839272483264126

Epoch: 6| Step: 5
Training loss: 0.7016062121802441
Validation loss: 2.3021159919809424

Epoch: 6| Step: 6
Training loss: 1.0236816697378812
Validation loss: 2.3012325140224057

Epoch: 6| Step: 7
Training loss: 0.9577592221948478
Validation loss: 2.298490655736017

Epoch: 6| Step: 8
Training loss: 1.1091719965492626
Validation loss: 2.312887960747773

Epoch: 6| Step: 9
Training loss: 0.7665519163736161
Validation loss: 2.2976349017328572

Epoch: 6| Step: 10
Training loss: 0.6515419423910499
Validation loss: 2.2880504618831794

Epoch: 6| Step: 11
Training loss: 1.1098132275338743
Validation loss: 2.2502707360657443

Epoch: 6| Step: 12
Training loss: 0.421400898753395
Validation loss: 2.2449337162716807

Epoch: 6| Step: 13
Training loss: 0.9897170662446012
Validation loss: 2.2287576904213884

Epoch: 252| Step: 0
Training loss: 0.8631329991704042
Validation loss: 2.2030595955747274

Epoch: 6| Step: 1
Training loss: 0.722767259474167
Validation loss: 2.233942351535835

Epoch: 6| Step: 2
Training loss: 0.6131815252194764
Validation loss: 2.2001586035361567

Epoch: 6| Step: 3
Training loss: 0.7437824578776068
Validation loss: 2.208794253357993

Epoch: 6| Step: 4
Training loss: 0.8133227510884282
Validation loss: 2.2123398365216254

Epoch: 6| Step: 5
Training loss: 0.9017228141009597
Validation loss: 2.233094116519771

Epoch: 6| Step: 6
Training loss: 1.1221862148786392
Validation loss: 2.2193026139728484

Epoch: 6| Step: 7
Training loss: 0.9596551231455424
Validation loss: 2.2504740093811737

Epoch: 6| Step: 8
Training loss: 0.9866638216630625
Validation loss: 2.2690951365149017

Epoch: 6| Step: 9
Training loss: 1.0096028121053644
Validation loss: 2.2937846765442216

Epoch: 6| Step: 10
Training loss: 0.561386728645412
Validation loss: 2.2932469159652573

Epoch: 6| Step: 11
Training loss: 0.8902588476455358
Validation loss: 2.3111437784128532

Epoch: 6| Step: 12
Training loss: 0.8136310041531046
Validation loss: 2.3072383717701848

Epoch: 6| Step: 13
Training loss: 1.2568830764336503
Validation loss: 2.3004848047524318

Epoch: 253| Step: 0
Training loss: 0.5713025213759177
Validation loss: 2.3022311472252897

Epoch: 6| Step: 1
Training loss: 0.7902108325176175
Validation loss: 2.276085431310885

Epoch: 6| Step: 2
Training loss: 0.5790142488834622
Validation loss: 2.270201609474642

Epoch: 6| Step: 3
Training loss: 0.7919830058326441
Validation loss: 2.2530190552312934

Epoch: 6| Step: 4
Training loss: 0.6434741744066196
Validation loss: 2.264358330494935

Epoch: 6| Step: 5
Training loss: 0.8686094911414701
Validation loss: 2.2407922452899833

Epoch: 6| Step: 6
Training loss: 1.3343369561161362
Validation loss: 2.20798591238298

Epoch: 6| Step: 7
Training loss: 0.7805540799986384
Validation loss: 2.244594966688383

Epoch: 6| Step: 8
Training loss: 0.8436794251489951
Validation loss: 2.2089898567142208

Epoch: 6| Step: 9
Training loss: 0.9520857100731853
Validation loss: 2.2286025782552286

Epoch: 6| Step: 10
Training loss: 1.3248607688302887
Validation loss: 2.2342864154603888

Epoch: 6| Step: 11
Training loss: 0.9403732140242819
Validation loss: 2.243715286911841

Epoch: 6| Step: 12
Training loss: 0.6011437283694291
Validation loss: 2.2390202582575647

Epoch: 6| Step: 13
Training loss: 0.3700869706433316
Validation loss: 2.2501145046589994

Epoch: 254| Step: 0
Training loss: 0.6563442480438382
Validation loss: 2.257352851809106

Epoch: 6| Step: 1
Training loss: 0.3986046010584933
Validation loss: 2.2632977327238226

Epoch: 6| Step: 2
Training loss: 0.9487842460151045
Validation loss: 2.2470597673088406

Epoch: 6| Step: 3
Training loss: 1.342320058402866
Validation loss: 2.2544758343701403

Epoch: 6| Step: 4
Training loss: 1.164706570423374
Validation loss: 2.2672748424155333

Epoch: 6| Step: 5
Training loss: 0.6300762973482191
Validation loss: 2.2643699363492087

Epoch: 6| Step: 6
Training loss: 0.6903283936521677
Validation loss: 2.232296438743548

Epoch: 6| Step: 7
Training loss: 0.2668039580671374
Validation loss: 2.2382646639621235

Epoch: 6| Step: 8
Training loss: 0.5738034206029812
Validation loss: 2.2403163499214767

Epoch: 6| Step: 9
Training loss: 1.1157283724381744
Validation loss: 2.2191899377780135

Epoch: 6| Step: 10
Training loss: 0.791711609384525
Validation loss: 2.22201461580643

Epoch: 6| Step: 11
Training loss: 1.0095521564736638
Validation loss: 2.2491886369146994

Epoch: 6| Step: 12
Training loss: 0.8742006260797427
Validation loss: 2.2662807408143433

Epoch: 6| Step: 13
Training loss: 0.6935970275210228
Validation loss: 2.268859793323025

Epoch: 255| Step: 0
Training loss: 0.914540548924172
Validation loss: 2.224932893637723

Epoch: 6| Step: 1
Training loss: 0.5080739741963679
Validation loss: 2.2708791000196284

Epoch: 6| Step: 2
Training loss: 1.0954789801095302
Validation loss: 2.2583864214045315

Epoch: 6| Step: 3
Training loss: 0.5162494230844447
Validation loss: 2.254933501889441

Epoch: 6| Step: 4
Training loss: 0.9573995076325065
Validation loss: 2.2875460998347688

Epoch: 6| Step: 5
Training loss: 0.7391092007421116
Validation loss: 2.239481203956198

Epoch: 6| Step: 6
Training loss: 1.0322866142654854
Validation loss: 2.2596612313192628

Epoch: 6| Step: 7
Training loss: 0.6716317024627796
Validation loss: 2.239168202377214

Epoch: 6| Step: 8
Training loss: 0.8990362079847894
Validation loss: 2.221102195490161

Epoch: 6| Step: 9
Training loss: 0.33566791229899257
Validation loss: 2.2080514715963186

Epoch: 6| Step: 10
Training loss: 0.7861189373047646
Validation loss: 2.2138697582408913

Epoch: 6| Step: 11
Training loss: 0.8140073878400558
Validation loss: 2.1841758656388945

Epoch: 6| Step: 12
Training loss: 1.0931243196793932
Validation loss: 2.180257188159773

Epoch: 6| Step: 13
Training loss: 1.2424365579691818
Validation loss: 2.1857417413433735

Epoch: 256| Step: 0
Training loss: 0.7918670969435475
Validation loss: 2.2206601106167976

Epoch: 6| Step: 1
Training loss: 0.8389703866986205
Validation loss: 2.2105789488093612

Epoch: 6| Step: 2
Training loss: 0.9628586212472695
Validation loss: 2.2487574157608985

Epoch: 6| Step: 3
Training loss: 0.548257768964712
Validation loss: 2.2482950656891676

Epoch: 6| Step: 4
Training loss: 0.6712940054948191
Validation loss: 2.240717209691925

Epoch: 6| Step: 5
Training loss: 1.0925928261469886
Validation loss: 2.272633353280268

Epoch: 6| Step: 6
Training loss: 0.9689342262081363
Validation loss: 2.3049820791131137

Epoch: 6| Step: 7
Training loss: 0.7982387840398182
Validation loss: 2.303839853123001

Epoch: 6| Step: 8
Training loss: 0.6471303150326423
Validation loss: 2.276855749113197

Epoch: 6| Step: 9
Training loss: 1.0100035396362825
Validation loss: 2.277991658662664

Epoch: 6| Step: 10
Training loss: 0.4209631496167641
Validation loss: 2.2715178360524186

Epoch: 6| Step: 11
Training loss: 0.9706008826586052
Validation loss: 2.290200592514586

Epoch: 6| Step: 12
Training loss: 0.9201985325866056
Validation loss: 2.2499390187083685

Epoch: 6| Step: 13
Training loss: 0.9940595012908575
Validation loss: 2.245769681018429

Epoch: 257| Step: 0
Training loss: 0.5761382012306309
Validation loss: 2.248135017108302

Epoch: 6| Step: 1
Training loss: 0.8605380078177938
Validation loss: 2.2608318077121474

Epoch: 6| Step: 2
Training loss: 0.5415837579023007
Validation loss: 2.2602237792831277

Epoch: 6| Step: 3
Training loss: 0.9462648748843747
Validation loss: 2.239683970779878

Epoch: 6| Step: 4
Training loss: 0.8992275578973089
Validation loss: 2.251574951796924

Epoch: 6| Step: 5
Training loss: 1.130447286258396
Validation loss: 2.263441594828899

Epoch: 6| Step: 6
Training loss: 0.9291129380388395
Validation loss: 2.250017076060626

Epoch: 6| Step: 7
Training loss: 0.7506216969286356
Validation loss: 2.282167870087877

Epoch: 6| Step: 8
Training loss: 0.6901406380474754
Validation loss: 2.3203951432587857

Epoch: 6| Step: 9
Training loss: 0.8919379946001825
Validation loss: 2.294900759615311

Epoch: 6| Step: 10
Training loss: 0.7778713410352901
Validation loss: 2.298561706307793

Epoch: 6| Step: 11
Training loss: 0.9152203912517402
Validation loss: 2.2740245033499797

Epoch: 6| Step: 12
Training loss: 0.8600228382005692
Validation loss: 2.2857467523671886

Epoch: 6| Step: 13
Training loss: 0.7565425574893802
Validation loss: 2.276212199331879

Epoch: 258| Step: 0
Training loss: 0.6283726294225989
Validation loss: 2.2845978152616073

Epoch: 6| Step: 1
Training loss: 0.8564405452025776
Validation loss: 2.236337725757597

Epoch: 6| Step: 2
Training loss: 0.8344109402463266
Validation loss: 2.2070777103384556

Epoch: 6| Step: 3
Training loss: 0.5532485942365918
Validation loss: 2.22813357623802

Epoch: 6| Step: 4
Training loss: 1.0114380436023467
Validation loss: 2.2130264947057183

Epoch: 6| Step: 5
Training loss: 0.6960030030975008
Validation loss: 2.2330084242354724

Epoch: 6| Step: 6
Training loss: 0.8575702095761122
Validation loss: 2.2259626132021295

Epoch: 6| Step: 7
Training loss: 0.8739718800261345
Validation loss: 2.2193607562536046

Epoch: 6| Step: 8
Training loss: 0.8056600674616858
Validation loss: 2.2619560794867124

Epoch: 6| Step: 9
Training loss: 0.9165253024482035
Validation loss: 2.2647013658834356

Epoch: 6| Step: 10
Training loss: 1.0151957264934262
Validation loss: 2.2655940635416245

Epoch: 6| Step: 11
Training loss: 0.6832451067545843
Validation loss: 2.266232486535892

Epoch: 6| Step: 12
Training loss: 0.8976510627935349
Validation loss: 2.2644264057763843

Epoch: 6| Step: 13
Training loss: 1.0672517994489978
Validation loss: 2.271665797788614

Epoch: 259| Step: 0
Training loss: 0.9251821325747251
Validation loss: 2.2520387031680458

Epoch: 6| Step: 1
Training loss: 0.8413303436638279
Validation loss: 2.288317842479112

Epoch: 6| Step: 2
Training loss: 1.0219464688288091
Validation loss: 2.306647902549965

Epoch: 6| Step: 3
Training loss: 0.7349669323184292
Validation loss: 2.2769371954121786

Epoch: 6| Step: 4
Training loss: 0.631052371522319
Validation loss: 2.278099097879949

Epoch: 6| Step: 5
Training loss: 0.8437908657208877
Validation loss: 2.263009965783826

Epoch: 6| Step: 6
Training loss: 1.0514975449791444
Validation loss: 2.2718619964891436

Epoch: 6| Step: 7
Training loss: 1.1187423876284965
Validation loss: 2.2671291123726185

Epoch: 6| Step: 8
Training loss: 0.5806207912115958
Validation loss: 2.2744830298818504

Epoch: 6| Step: 9
Training loss: 0.6068707630783509
Validation loss: 2.27268409459125

Epoch: 6| Step: 10
Training loss: 0.9061166402099874
Validation loss: 2.2671519349362868

Epoch: 6| Step: 11
Training loss: 0.6119236589513928
Validation loss: 2.2606657626346065

Epoch: 6| Step: 12
Training loss: 0.7371623527115438
Validation loss: 2.212886722578887

Epoch: 6| Step: 13
Training loss: 0.6721601324748318
Validation loss: 2.246404930697938

Epoch: 260| Step: 0
Training loss: 0.9193064580972066
Validation loss: 2.2468259726269357

Epoch: 6| Step: 1
Training loss: 0.5678029171140794
Validation loss: 2.2628089623123397

Epoch: 6| Step: 2
Training loss: 0.8854917531806079
Validation loss: 2.2638959318540866

Epoch: 6| Step: 3
Training loss: 0.9946621349479065
Validation loss: 2.289378701150651

Epoch: 6| Step: 4
Training loss: 0.8930301314756514
Validation loss: 2.311780329797006

Epoch: 6| Step: 5
Training loss: 0.42440961685345113
Validation loss: 2.29424923295593

Epoch: 6| Step: 6
Training loss: 0.8553969470682488
Validation loss: 2.271692620506531

Epoch: 6| Step: 7
Training loss: 0.9219214864098716
Validation loss: 2.288530856299039

Epoch: 6| Step: 8
Training loss: 0.9288231814934171
Validation loss: 2.302983615814577

Epoch: 6| Step: 9
Training loss: 0.7135432770054227
Validation loss: 2.2720944572828397

Epoch: 6| Step: 10
Training loss: 1.003132325142708
Validation loss: 2.2791518731580207

Epoch: 6| Step: 11
Training loss: 0.8448077741624656
Validation loss: 2.246322904064029

Epoch: 6| Step: 12
Training loss: 0.6648063308459711
Validation loss: 2.292180274692349

Epoch: 6| Step: 13
Training loss: 0.46621094325320905
Validation loss: 2.2631791986424394

Epoch: 261| Step: 0
Training loss: 0.6139091630275759
Validation loss: 2.253765986821545

Epoch: 6| Step: 1
Training loss: 0.948557336768441
Validation loss: 2.2552111926730056

Epoch: 6| Step: 2
Training loss: 0.6390595732157871
Validation loss: 2.2419845022097102

Epoch: 6| Step: 3
Training loss: 0.7972521170070385
Validation loss: 2.2371434590197032

Epoch: 6| Step: 4
Training loss: 0.7937946246962083
Validation loss: 2.2252360450202384

Epoch: 6| Step: 5
Training loss: 0.7098190816547431
Validation loss: 2.2130887966168

Epoch: 6| Step: 6
Training loss: 0.8250104889058423
Validation loss: 2.2567913705447826

Epoch: 6| Step: 7
Training loss: 0.8844101551738398
Validation loss: 2.251624446144643

Epoch: 6| Step: 8
Training loss: 0.8499883047870063
Validation loss: 2.271948318166139

Epoch: 6| Step: 9
Training loss: 0.9273302021017168
Validation loss: 2.270837265249075

Epoch: 6| Step: 10
Training loss: 1.2197268557032774
Validation loss: 2.247637228218544

Epoch: 6| Step: 11
Training loss: 0.6988368776390591
Validation loss: 2.2407215493200905

Epoch: 6| Step: 12
Training loss: 0.6829198512836501
Validation loss: 2.259258094610794

Epoch: 6| Step: 13
Training loss: 0.29809562814322615
Validation loss: 2.278117547506286

Epoch: 262| Step: 0
Training loss: 0.8015560960420886
Validation loss: 2.273203219874871

Epoch: 6| Step: 1
Training loss: 0.8965559455044297
Validation loss: 2.288243358133098

Epoch: 6| Step: 2
Training loss: 0.7588784497804228
Validation loss: 2.2649289429326105

Epoch: 6| Step: 3
Training loss: 0.9272475079389558
Validation loss: 2.284079817820039

Epoch: 6| Step: 4
Training loss: 0.6975750917600944
Validation loss: 2.2499198899312836

Epoch: 6| Step: 5
Training loss: 0.5775716040341319
Validation loss: 2.252494561149189

Epoch: 6| Step: 6
Training loss: 0.4925731933976107
Validation loss: 2.2601088061917354

Epoch: 6| Step: 7
Training loss: 0.9801156369416296
Validation loss: 2.266121045873906

Epoch: 6| Step: 8
Training loss: 0.8544877929574497
Validation loss: 2.281139913912537

Epoch: 6| Step: 9
Training loss: 0.68266972897617
Validation loss: 2.2465453795888197

Epoch: 6| Step: 10
Training loss: 0.9915329583904223
Validation loss: 2.2430317510444033

Epoch: 6| Step: 11
Training loss: 0.7379481053417786
Validation loss: 2.210414350189736

Epoch: 6| Step: 12
Training loss: 0.8664338557228551
Validation loss: 2.2130294371209587

Epoch: 6| Step: 13
Training loss: 0.9197746855628834
Validation loss: 2.2244607570619945

Epoch: 263| Step: 0
Training loss: 0.5961940805936
Validation loss: 2.2298408982188054

Epoch: 6| Step: 1
Training loss: 0.6611707668031467
Validation loss: 2.237354169822891

Epoch: 6| Step: 2
Training loss: 0.7725590427760475
Validation loss: 2.23254426235222

Epoch: 6| Step: 3
Training loss: 0.8702021941544635
Validation loss: 2.2469617550162955

Epoch: 6| Step: 4
Training loss: 0.6468834005722579
Validation loss: 2.2635007410992474

Epoch: 6| Step: 5
Training loss: 0.831712509495917
Validation loss: 2.268724872916987

Epoch: 6| Step: 6
Training loss: 0.9405322944860163
Validation loss: 2.2719462289536416

Epoch: 6| Step: 7
Training loss: 0.9821747910893788
Validation loss: 2.289614837476617

Epoch: 6| Step: 8
Training loss: 1.0050520833122472
Validation loss: 2.2914061330175697

Epoch: 6| Step: 9
Training loss: 0.9711254897266753
Validation loss: 2.317299251442111

Epoch: 6| Step: 10
Training loss: 0.8070704167214885
Validation loss: 2.305684860274747

Epoch: 6| Step: 11
Training loss: 0.5289082807448379
Validation loss: 2.290681459599307

Epoch: 6| Step: 12
Training loss: 0.7952960958831328
Validation loss: 2.270779227358899

Epoch: 6| Step: 13
Training loss: 0.5551567778945848
Validation loss: 2.263549154695354

Epoch: 264| Step: 0
Training loss: 0.8628322762913966
Validation loss: 2.260287521647866

Epoch: 6| Step: 1
Training loss: 0.6587980847118355
Validation loss: 2.279782265695856

Epoch: 6| Step: 2
Training loss: 0.9604927522444431
Validation loss: 2.247250006108685

Epoch: 6| Step: 3
Training loss: 0.7011917663983017
Validation loss: 2.249412294653681

Epoch: 6| Step: 4
Training loss: 0.40472866349769815
Validation loss: 2.2321532465023495

Epoch: 6| Step: 5
Training loss: 1.0865814714637914
Validation loss: 2.2316502075089524

Epoch: 6| Step: 6
Training loss: 1.040685433130776
Validation loss: 2.2508767947934287

Epoch: 6| Step: 7
Training loss: 0.5782325747643817
Validation loss: 2.2558493152428376

Epoch: 6| Step: 8
Training loss: 0.798424093951349
Validation loss: 2.288742016115903

Epoch: 6| Step: 9
Training loss: 0.914635959290049
Validation loss: 2.325303352026475

Epoch: 6| Step: 10
Training loss: 0.6928370052713241
Validation loss: 2.315517677119636

Epoch: 6| Step: 11
Training loss: 0.71789483321855
Validation loss: 2.3100295091912395

Epoch: 6| Step: 12
Training loss: 0.8477755695515353
Validation loss: 2.2771850884142664

Epoch: 6| Step: 13
Training loss: 0.5281219674198279
Validation loss: 2.3046315632200858

Epoch: 265| Step: 0
Training loss: 1.1287728729127295
Validation loss: 2.2345142133252542

Epoch: 6| Step: 1
Training loss: 0.8953619352476878
Validation loss: 2.220382458470717

Epoch: 6| Step: 2
Training loss: 0.6911355905892581
Validation loss: 2.2146490576868847

Epoch: 6| Step: 3
Training loss: 0.4218672115878568
Validation loss: 2.208655042156328

Epoch: 6| Step: 4
Training loss: 0.6220111429528815
Validation loss: 2.2012722160914584

Epoch: 6| Step: 5
Training loss: 0.5721111675037983
Validation loss: 2.228960287204677

Epoch: 6| Step: 6
Training loss: 0.8456889937631982
Validation loss: 2.2219212244448623

Epoch: 6| Step: 7
Training loss: 1.064197138532015
Validation loss: 2.248935951476015

Epoch: 6| Step: 8
Training loss: 0.8696780140037659
Validation loss: 2.2878800368576178

Epoch: 6| Step: 9
Training loss: 0.6251274455784873
Validation loss: 2.3172010005908104

Epoch: 6| Step: 10
Training loss: 0.6285317295019338
Validation loss: 2.31862995055959

Epoch: 6| Step: 11
Training loss: 0.7546823884463121
Validation loss: 2.3249578356792595

Epoch: 6| Step: 12
Training loss: 0.890709421272599
Validation loss: 2.2666593290327235

Epoch: 6| Step: 13
Training loss: 0.909453255606102
Validation loss: 2.268516124437323

Epoch: 266| Step: 0
Training loss: 0.9522503451073567
Validation loss: 2.2404388621356057

Epoch: 6| Step: 1
Training loss: 0.7069940926077056
Validation loss: 2.245590806234053

Epoch: 6| Step: 2
Training loss: 0.703273206561845
Validation loss: 2.253516122867222

Epoch: 6| Step: 3
Training loss: 0.7344045430186257
Validation loss: 2.2443070314063496

Epoch: 6| Step: 4
Training loss: 0.5448680017017075
Validation loss: 2.22143715489441

Epoch: 6| Step: 5
Training loss: 0.42309440000655857
Validation loss: 2.223145092838693

Epoch: 6| Step: 6
Training loss: 0.5105447478713399
Validation loss: 2.2320437487326372

Epoch: 6| Step: 7
Training loss: 0.7896274017543841
Validation loss: 2.2171268780015816

Epoch: 6| Step: 8
Training loss: 0.6984714585141192
Validation loss: 2.2346977404096653

Epoch: 6| Step: 9
Training loss: 1.1876222647918595
Validation loss: 2.2603779730829126

Epoch: 6| Step: 10
Training loss: 0.8790630963564524
Validation loss: 2.263141500049684

Epoch: 6| Step: 11
Training loss: 0.7634084105600237
Validation loss: 2.2523687670839165

Epoch: 6| Step: 12
Training loss: 0.8360254473189862
Validation loss: 2.2535400519672177

Epoch: 6| Step: 13
Training loss: 0.9714136727577009
Validation loss: 2.247396196461266

Epoch: 267| Step: 0
Training loss: 0.8130976972753543
Validation loss: 2.253807368398269

Epoch: 6| Step: 1
Training loss: 0.8793165139471306
Validation loss: 2.2580235027801754

Epoch: 6| Step: 2
Training loss: 0.5437602305272001
Validation loss: 2.2508381395694546

Epoch: 6| Step: 3
Training loss: 0.4871474568547777
Validation loss: 2.247255817143515

Epoch: 6| Step: 4
Training loss: 0.6845020254688933
Validation loss: 2.2887724117531865

Epoch: 6| Step: 5
Training loss: 0.917585901817732
Validation loss: 2.251191234061784

Epoch: 6| Step: 6
Training loss: 0.9114951571337455
Validation loss: 2.249161011246202

Epoch: 6| Step: 7
Training loss: 0.6867328177997706
Validation loss: 2.2228265950767416

Epoch: 6| Step: 8
Training loss: 1.0763105521186953
Validation loss: 2.219213491323676

Epoch: 6| Step: 9
Training loss: 0.44966123598343305
Validation loss: 2.2390652957197488

Epoch: 6| Step: 10
Training loss: 0.7496059495172759
Validation loss: 2.246027317428986

Epoch: 6| Step: 11
Training loss: 0.8218075162501611
Validation loss: 2.2515941072177292

Epoch: 6| Step: 12
Training loss: 0.7838034671512085
Validation loss: 2.231427600874944

Epoch: 6| Step: 13
Training loss: 0.6034804398733551
Validation loss: 2.2549788183871797

Epoch: 268| Step: 0
Training loss: 0.8712695162542521
Validation loss: 2.224621087966382

Epoch: 6| Step: 1
Training loss: 0.4194616590353954
Validation loss: 2.256492269911538

Epoch: 6| Step: 2
Training loss: 0.7662121603803091
Validation loss: 2.240283857268413

Epoch: 6| Step: 3
Training loss: 0.7477840031424063
Validation loss: 2.259039850297097

Epoch: 6| Step: 4
Training loss: 0.5051442987294916
Validation loss: 2.277071044907932

Epoch: 6| Step: 5
Training loss: 0.8428787395513707
Validation loss: 2.2903343004247176

Epoch: 6| Step: 6
Training loss: 0.9758506316539317
Validation loss: 2.2720952843383513

Epoch: 6| Step: 7
Training loss: 0.8946160022282583
Validation loss: 2.2211964805687407

Epoch: 6| Step: 8
Training loss: 0.7033421287129804
Validation loss: 2.245557257955244

Epoch: 6| Step: 9
Training loss: 0.62866784546837
Validation loss: 2.2528688583384575

Epoch: 6| Step: 10
Training loss: 1.008849327746701
Validation loss: 2.2415414412291144

Epoch: 6| Step: 11
Training loss: 0.94066917087601
Validation loss: 2.2283344649385186

Epoch: 6| Step: 12
Training loss: 0.5939238193465384
Validation loss: 2.2170369102007053

Epoch: 6| Step: 13
Training loss: 0.17240059748536934
Validation loss: 2.200573995644255

Epoch: 269| Step: 0
Training loss: 0.7426533090576138
Validation loss: 2.227256898338426

Epoch: 6| Step: 1
Training loss: 0.721734980425261
Validation loss: 2.224330990666127

Epoch: 6| Step: 2
Training loss: 0.7161413204166518
Validation loss: 2.2448206324069817

Epoch: 6| Step: 3
Training loss: 0.8592735230614215
Validation loss: 2.2534877846232173

Epoch: 6| Step: 4
Training loss: 0.7755772824790349
Validation loss: 2.24324497038756

Epoch: 6| Step: 5
Training loss: 0.795002251387953
Validation loss: 2.2521270794907573

Epoch: 6| Step: 6
Training loss: 0.7657785067132624
Validation loss: 2.277244707979685

Epoch: 6| Step: 7
Training loss: 0.8287986318781324
Validation loss: 2.2584913672167164

Epoch: 6| Step: 8
Training loss: 0.9803906899796526
Validation loss: 2.2953834761008904

Epoch: 6| Step: 9
Training loss: 0.6694650232239556
Validation loss: 2.281027384780094

Epoch: 6| Step: 10
Training loss: 0.7484753927621162
Validation loss: 2.2739125291017075

Epoch: 6| Step: 11
Training loss: 0.5797749250350008
Validation loss: 2.272032716118219

Epoch: 6| Step: 12
Training loss: 0.7583053402048243
Validation loss: 2.257616684859418

Epoch: 6| Step: 13
Training loss: 0.3772541879708395
Validation loss: 2.2626795251807628

Epoch: 270| Step: 0
Training loss: 0.8098848511829309
Validation loss: 2.2612650916790096

Epoch: 6| Step: 1
Training loss: 0.7751787794699578
Validation loss: 2.2235116698595654

Epoch: 6| Step: 2
Training loss: 0.8083229164225754
Validation loss: 2.262685749934256

Epoch: 6| Step: 3
Training loss: 0.7612645286589277
Validation loss: 2.268987967226336

Epoch: 6| Step: 4
Training loss: 0.9780357844216557
Validation loss: 2.269689205855255

Epoch: 6| Step: 5
Training loss: 0.8735621764267121
Validation loss: 2.256050798448078

Epoch: 6| Step: 6
Training loss: 0.8549509789540508
Validation loss: 2.253418649643962

Epoch: 6| Step: 7
Training loss: 0.6848319039526763
Validation loss: 2.2469795273135604

Epoch: 6| Step: 8
Training loss: 0.7247359584252111
Validation loss: 2.253074288424402

Epoch: 6| Step: 9
Training loss: 0.317534002826187
Validation loss: 2.2438675669247874

Epoch: 6| Step: 10
Training loss: 0.882111059722224
Validation loss: 2.2422047721898126

Epoch: 6| Step: 11
Training loss: 0.6366919295390089
Validation loss: 2.2267499820666568

Epoch: 6| Step: 12
Training loss: 0.3830153258820522
Validation loss: 2.2245899108728384

Epoch: 6| Step: 13
Training loss: 0.6764293495581746
Validation loss: 2.2620774514443074

Epoch: 271| Step: 0
Training loss: 0.4807261266092189
Validation loss: 2.246447107484443

Epoch: 6| Step: 1
Training loss: 0.8221612714573293
Validation loss: 2.252898462918551

Epoch: 6| Step: 2
Training loss: 0.5182313072377633
Validation loss: 2.2437043483254735

Epoch: 6| Step: 3
Training loss: 0.6517268936281315
Validation loss: 2.225788422161223

Epoch: 6| Step: 4
Training loss: 0.5713265691981447
Validation loss: 2.2619013357602995

Epoch: 6| Step: 5
Training loss: 0.8565181061834553
Validation loss: 2.2499026684235184

Epoch: 6| Step: 6
Training loss: 0.7543370098418307
Validation loss: 2.258947389312044

Epoch: 6| Step: 7
Training loss: 0.4535464924403863
Validation loss: 2.2519670488207617

Epoch: 6| Step: 8
Training loss: 0.8190124382313502
Validation loss: 2.263756150610988

Epoch: 6| Step: 9
Training loss: 0.7654002891398438
Validation loss: 2.25160614349618

Epoch: 6| Step: 10
Training loss: 0.5170943104206133
Validation loss: 2.213949229717613

Epoch: 6| Step: 11
Training loss: 1.1552670398834903
Validation loss: 2.239898039581439

Epoch: 6| Step: 12
Training loss: 0.8857694745723619
Validation loss: 2.230636204491791

Epoch: 6| Step: 13
Training loss: 0.7595208173238192
Validation loss: 2.206433827842247

Epoch: 272| Step: 0
Training loss: 0.6397899674948171
Validation loss: 2.2131145082995336

Epoch: 6| Step: 1
Training loss: 0.5324230986124198
Validation loss: 2.231203612196987

Epoch: 6| Step: 2
Training loss: 0.7183181875347745
Validation loss: 2.222777560363066

Epoch: 6| Step: 3
Training loss: 0.48890589622906583
Validation loss: 2.218847283913081

Epoch: 6| Step: 4
Training loss: 0.4721539721145233
Validation loss: 2.2468667369581454

Epoch: 6| Step: 5
Training loss: 0.696512494078535
Validation loss: 2.2548960507150033

Epoch: 6| Step: 6
Training loss: 0.6437689232128236
Validation loss: 2.2392520481136295

Epoch: 6| Step: 7
Training loss: 1.0223189203394571
Validation loss: 2.2305504350204983

Epoch: 6| Step: 8
Training loss: 0.8826553745032459
Validation loss: 2.253073021437927

Epoch: 6| Step: 9
Training loss: 0.7002066766941941
Validation loss: 2.2719324213715955

Epoch: 6| Step: 10
Training loss: 0.3680464660473833
Validation loss: 2.268959128475156

Epoch: 6| Step: 11
Training loss: 0.8491527865145521
Validation loss: 2.2624664167496213

Epoch: 6| Step: 12
Training loss: 1.0010957674828103
Validation loss: 2.2784078111690835

Epoch: 6| Step: 13
Training loss: 1.0774687276138928
Validation loss: 2.2847790080215433

Epoch: 273| Step: 0
Training loss: 0.41193592344528446
Validation loss: 2.267935517643448

Epoch: 6| Step: 1
Training loss: 0.7839390823821513
Validation loss: 2.260193139797555

Epoch: 6| Step: 2
Training loss: 0.9889934823059607
Validation loss: 2.238506720761101

Epoch: 6| Step: 3
Training loss: 1.046981976864963
Validation loss: 2.2223152311235386

Epoch: 6| Step: 4
Training loss: 0.6384790345217325
Validation loss: 2.23087800189356

Epoch: 6| Step: 5
Training loss: 0.5408070847480326
Validation loss: 2.2410136371447518

Epoch: 6| Step: 6
Training loss: 0.9526516098352428
Validation loss: 2.2347333365309208

Epoch: 6| Step: 7
Training loss: 0.3364234115893618
Validation loss: 2.2306788225106

Epoch: 6| Step: 8
Training loss: 0.44417611066763435
Validation loss: 2.238169188485055

Epoch: 6| Step: 9
Training loss: 0.8027776998815385
Validation loss: 2.2442298972146673

Epoch: 6| Step: 10
Training loss: 0.7848297503083036
Validation loss: 2.2667950814888482

Epoch: 6| Step: 11
Training loss: 0.7164749961158478
Validation loss: 2.2762890775573363

Epoch: 6| Step: 12
Training loss: 0.8430841078855702
Validation loss: 2.28234073198664

Epoch: 6| Step: 13
Training loss: 0.22597193206289656
Validation loss: 2.307109582154558

Epoch: 274| Step: 0
Training loss: 0.49217048494507276
Validation loss: 2.269901526626639

Epoch: 6| Step: 1
Training loss: 0.918087241459107
Validation loss: 2.2993063933501685

Epoch: 6| Step: 2
Training loss: 0.6903975720739716
Validation loss: 2.297690646227324

Epoch: 6| Step: 3
Training loss: 0.7953172679825651
Validation loss: 2.302913126640082

Epoch: 6| Step: 4
Training loss: 0.5066857381836868
Validation loss: 2.30171909512287

Epoch: 6| Step: 5
Training loss: 0.35859410819906323
Validation loss: 2.2938954203544113

Epoch: 6| Step: 6
Training loss: 0.9404734505267984
Validation loss: 2.288563299660506

Epoch: 6| Step: 7
Training loss: 0.9719135558891824
Validation loss: 2.26808647442621

Epoch: 6| Step: 8
Training loss: 0.8992616936498945
Validation loss: 2.2956008496691562

Epoch: 6| Step: 9
Training loss: 0.6341422438545049
Validation loss: 2.272935187733523

Epoch: 6| Step: 10
Training loss: 0.6826689213480199
Validation loss: 2.2748291596051478

Epoch: 6| Step: 11
Training loss: 0.3621382832433136
Validation loss: 2.263984443205993

Epoch: 6| Step: 12
Training loss: 0.7812712857207698
Validation loss: 2.2382006735302866

Epoch: 6| Step: 13
Training loss: 0.7455461899451337
Validation loss: 2.2677502359922386

Epoch: 275| Step: 0
Training loss: 0.6829463836212226
Validation loss: 2.244556492817583

Epoch: 6| Step: 1
Training loss: 0.17396128301251676
Validation loss: 2.2307797934808504

Epoch: 6| Step: 2
Training loss: 0.6829925727398511
Validation loss: 2.2450633163849893

Epoch: 6| Step: 3
Training loss: 0.5938267909133995
Validation loss: 2.2481968170418325

Epoch: 6| Step: 4
Training loss: 1.0219859538372815
Validation loss: 2.2270367626590537

Epoch: 6| Step: 5
Training loss: 0.9649692098617138
Validation loss: 2.2522451599899633

Epoch: 6| Step: 6
Training loss: 0.5284662803062995
Validation loss: 2.2227968408324212

Epoch: 6| Step: 7
Training loss: 0.9714193484175044
Validation loss: 2.2311370249624933

Epoch: 6| Step: 8
Training loss: 0.7819234615587531
Validation loss: 2.237378695159182

Epoch: 6| Step: 9
Training loss: 0.5009894415852596
Validation loss: 2.24177307618642

Epoch: 6| Step: 10
Training loss: 0.9626618397876565
Validation loss: 2.2224875208987425

Epoch: 6| Step: 11
Training loss: 0.5615471080269101
Validation loss: 2.2545152999583684

Epoch: 6| Step: 12
Training loss: 0.32740190849691714
Validation loss: 2.2333713012247993

Epoch: 6| Step: 13
Training loss: 0.6809877258236547
Validation loss: 2.2735553126383716

Epoch: 276| Step: 0
Training loss: 0.6011999449642966
Validation loss: 2.238996566711828

Epoch: 6| Step: 1
Training loss: 1.133928630429793
Validation loss: 2.2673041299944443

Epoch: 6| Step: 2
Training loss: 0.6731073477439643
Validation loss: 2.2476318959371437

Epoch: 6| Step: 3
Training loss: 0.8247107172014655
Validation loss: 2.2111231115310326

Epoch: 6| Step: 4
Training loss: 0.4695993675545295
Validation loss: 2.240128475462375

Epoch: 6| Step: 5
Training loss: 0.581197974224984
Validation loss: 2.239718346462218

Epoch: 6| Step: 6
Training loss: 0.6260022234008841
Validation loss: 2.214922884727389

Epoch: 6| Step: 7
Training loss: 0.5583033306923708
Validation loss: 2.233588840728418

Epoch: 6| Step: 8
Training loss: 0.6352590667726113
Validation loss: 2.2282401655007336

Epoch: 6| Step: 9
Training loss: 0.9541180549687669
Validation loss: 2.226863684268533

Epoch: 6| Step: 10
Training loss: 0.8402947213082129
Validation loss: 2.2356524216014972

Epoch: 6| Step: 11
Training loss: 0.6794367141206765
Validation loss: 2.2145066874463195

Epoch: 6| Step: 12
Training loss: 0.5428350819231698
Validation loss: 2.2360388414339005

Epoch: 6| Step: 13
Training loss: 0.37583835588230174
Validation loss: 2.215549739385161

Epoch: 277| Step: 0
Training loss: 0.727891874853758
Validation loss: 2.2026280866964854

Epoch: 6| Step: 1
Training loss: 0.4392783262382512
Validation loss: 2.2383836704421207

Epoch: 6| Step: 2
Training loss: 0.8936461021481333
Validation loss: 2.241934572063115

Epoch: 6| Step: 3
Training loss: 0.45463661748114464
Validation loss: 2.2698499822057188

Epoch: 6| Step: 4
Training loss: 0.7900498510880719
Validation loss: 2.2920199481760015

Epoch: 6| Step: 5
Training loss: 0.5946869735194255
Validation loss: 2.2564654232923873

Epoch: 6| Step: 6
Training loss: 0.6846537627592374
Validation loss: 2.3076817026294294

Epoch: 6| Step: 7
Training loss: 0.6413667617890302
Validation loss: 2.2973641064620702

Epoch: 6| Step: 8
Training loss: 0.7693513379149872
Validation loss: 2.27777399544594

Epoch: 6| Step: 9
Training loss: 0.7449499820073486
Validation loss: 2.274169844796797

Epoch: 6| Step: 10
Training loss: 0.5619002960078024
Validation loss: 2.2838787492347272

Epoch: 6| Step: 11
Training loss: 0.5079229674862514
Validation loss: 2.2887757787537857

Epoch: 6| Step: 12
Training loss: 0.8871846592485795
Validation loss: 2.2539314107527892

Epoch: 6| Step: 13
Training loss: 1.1699461257790214
Validation loss: 2.251341068031322

Epoch: 278| Step: 0
Training loss: 0.5698058346852981
Validation loss: 2.2559493016902943

Epoch: 6| Step: 1
Training loss: 0.4241511788129361
Validation loss: 2.2380049242744806

Epoch: 6| Step: 2
Training loss: 0.5857689169915593
Validation loss: 2.2267985568715556

Epoch: 6| Step: 3
Training loss: 0.6980489823662318
Validation loss: 2.2338259913331533

Epoch: 6| Step: 4
Training loss: 0.5963055675532634
Validation loss: 2.247986350206902

Epoch: 6| Step: 5
Training loss: 0.6957827917082346
Validation loss: 2.278891749927908

Epoch: 6| Step: 6
Training loss: 0.9383724285866448
Validation loss: 2.272817948099608

Epoch: 6| Step: 7
Training loss: 0.6442065952957651
Validation loss: 2.2622001212623495

Epoch: 6| Step: 8
Training loss: 0.9102465539755441
Validation loss: 2.282224603452086

Epoch: 6| Step: 9
Training loss: 0.9140218742015204
Validation loss: 2.327357883130461

Epoch: 6| Step: 10
Training loss: 0.608828005678725
Validation loss: 2.334693782001732

Epoch: 6| Step: 11
Training loss: 0.8403110357451246
Validation loss: 2.3039864768621388

Epoch: 6| Step: 12
Training loss: 0.5930768513807911
Validation loss: 2.281092750837352

Epoch: 6| Step: 13
Training loss: 0.873257912340857
Validation loss: 2.3023297852574944

Epoch: 279| Step: 0
Training loss: 0.9114358118090402
Validation loss: 2.2825207886976058

Epoch: 6| Step: 1
Training loss: 0.5479896357819678
Validation loss: 2.264465791343621

Epoch: 6| Step: 2
Training loss: 0.7941994723588914
Validation loss: 2.25747101612032

Epoch: 6| Step: 3
Training loss: 0.6010267919179604
Validation loss: 2.2556635062343537

Epoch: 6| Step: 4
Training loss: 0.6504720459340713
Validation loss: 2.255730754010829

Epoch: 6| Step: 5
Training loss: 0.5668932432542835
Validation loss: 2.255366862445784

Epoch: 6| Step: 6
Training loss: 0.7703684014702087
Validation loss: 2.258925592079555

Epoch: 6| Step: 7
Training loss: 0.838895395357557
Validation loss: 2.2565426925205503

Epoch: 6| Step: 8
Training loss: 0.7326912346490665
Validation loss: 2.2782601702660576

Epoch: 6| Step: 9
Training loss: 0.7751253764965642
Validation loss: 2.2808550578331626

Epoch: 6| Step: 10
Training loss: 0.5261086021617739
Validation loss: 2.243818933184026

Epoch: 6| Step: 11
Training loss: 0.4541959274851861
Validation loss: 2.2805742090772743

Epoch: 6| Step: 12
Training loss: 0.8813212805523553
Validation loss: 2.2865311764741265

Epoch: 6| Step: 13
Training loss: 0.521074283813898
Validation loss: 2.2716315760187253

Epoch: 280| Step: 0
Training loss: 0.781086446808449
Validation loss: 2.242354752180007

Epoch: 6| Step: 1
Training loss: 0.6219290867963744
Validation loss: 2.2520622387285596

Epoch: 6| Step: 2
Training loss: 0.4982364966749036
Validation loss: 2.274130617993364

Epoch: 6| Step: 3
Training loss: 0.7098228183811562
Validation loss: 2.2719785559590577

Epoch: 6| Step: 4
Training loss: 0.6879343914642068
Validation loss: 2.257645693478713

Epoch: 6| Step: 5
Training loss: 0.5092685073276125
Validation loss: 2.267305812475325

Epoch: 6| Step: 6
Training loss: 0.5529822073638495
Validation loss: 2.2663059330156052

Epoch: 6| Step: 7
Training loss: 0.8833982836638643
Validation loss: 2.28172660728394

Epoch: 6| Step: 8
Training loss: 0.8391014189547108
Validation loss: 2.2343095362084644

Epoch: 6| Step: 9
Training loss: 0.8459591378924302
Validation loss: 2.275348676569209

Epoch: 6| Step: 10
Training loss: 0.6075045415920461
Validation loss: 2.269760791487044

Epoch: 6| Step: 11
Training loss: 0.9508938236090945
Validation loss: 2.29177861280525

Epoch: 6| Step: 12
Training loss: 0.4832632781373873
Validation loss: 2.2955137684720266

Epoch: 6| Step: 13
Training loss: 0.3264089739089168
Validation loss: 2.271103079667204

Epoch: 281| Step: 0
Training loss: 0.6877128965019754
Validation loss: 2.2945083821654904

Epoch: 6| Step: 1
Training loss: 0.8445418139281338
Validation loss: 2.3199614312459986

Epoch: 6| Step: 2
Training loss: 0.3580059428147995
Validation loss: 2.262140791392748

Epoch: 6| Step: 3
Training loss: 0.7048949534701634
Validation loss: 2.2183502168705447

Epoch: 6| Step: 4
Training loss: 0.7382102811096899
Validation loss: 2.239328961093353

Epoch: 6| Step: 5
Training loss: 0.8326611350888494
Validation loss: 2.2299174557800843

Epoch: 6| Step: 6
Training loss: 0.7147645333177838
Validation loss: 2.2294305578682048

Epoch: 6| Step: 7
Training loss: 0.7621741474103424
Validation loss: 2.2153750651874993

Epoch: 6| Step: 8
Training loss: 0.6821086337136083
Validation loss: 2.231714958980683

Epoch: 6| Step: 9
Training loss: 0.3679515923713516
Validation loss: 2.239300233805753

Epoch: 6| Step: 10
Training loss: 0.6505117675866262
Validation loss: 2.2354045537954867

Epoch: 6| Step: 11
Training loss: 0.6900791643519885
Validation loss: 2.2490028224843406

Epoch: 6| Step: 12
Training loss: 0.7360966973922888
Validation loss: 2.242123876504134

Epoch: 6| Step: 13
Training loss: 0.7946863973822166
Validation loss: 2.2537845233139047

Epoch: 282| Step: 0
Training loss: 0.6025835512328181
Validation loss: 2.2505908210863454

Epoch: 6| Step: 1
Training loss: 0.8787085755895789
Validation loss: 2.27904795071487

Epoch: 6| Step: 2
Training loss: 0.493788371224829
Validation loss: 2.2745906001699265

Epoch: 6| Step: 3
Training loss: 0.9056770881537148
Validation loss: 2.255479543715717

Epoch: 6| Step: 4
Training loss: 0.7759112476788805
Validation loss: 2.249203392235993

Epoch: 6| Step: 5
Training loss: 0.6835836791250354
Validation loss: 2.2519020867612523

Epoch: 6| Step: 6
Training loss: 0.5168751963623117
Validation loss: 2.265101218436282

Epoch: 6| Step: 7
Training loss: 0.8732713585684311
Validation loss: 2.270492960210557

Epoch: 6| Step: 8
Training loss: 0.6595240166942342
Validation loss: 2.242757202275652

Epoch: 6| Step: 9
Training loss: 0.5034411449998952
Validation loss: 2.2003366254283376

Epoch: 6| Step: 10
Training loss: 0.5984839896926454
Validation loss: 2.224273321197752

Epoch: 6| Step: 11
Training loss: 0.6798765862192684
Validation loss: 2.2297369178032507

Epoch: 6| Step: 12
Training loss: 0.6382886570999124
Validation loss: 2.2344265493063817

Epoch: 6| Step: 13
Training loss: 0.5154688049482887
Validation loss: 2.26663583646156

Epoch: 283| Step: 0
Training loss: 0.6146010757299084
Validation loss: 2.2498699780750093

Epoch: 6| Step: 1
Training loss: 0.7992433993508766
Validation loss: 2.2966556339679682

Epoch: 6| Step: 2
Training loss: 0.32054221824630935
Validation loss: 2.297638099817049

Epoch: 6| Step: 3
Training loss: 0.3308784668513459
Validation loss: 2.294861118871255

Epoch: 6| Step: 4
Training loss: 0.5628337399860901
Validation loss: 2.29075023994419

Epoch: 6| Step: 5
Training loss: 0.9719651612780736
Validation loss: 2.297280091768354

Epoch: 6| Step: 6
Training loss: 0.6910238986816551
Validation loss: 2.3152020816649164

Epoch: 6| Step: 7
Training loss: 0.8371404744404494
Validation loss: 2.270945555740203

Epoch: 6| Step: 8
Training loss: 0.9354697177742418
Validation loss: 2.2749140834440063

Epoch: 6| Step: 9
Training loss: 0.5276856903276472
Validation loss: 2.2170820840482843

Epoch: 6| Step: 10
Training loss: 0.5585273756593869
Validation loss: 2.2328849073067625

Epoch: 6| Step: 11
Training loss: 0.5401936977074631
Validation loss: 2.230150350943742

Epoch: 6| Step: 12
Training loss: 0.899295463570846
Validation loss: 2.219920400692591

Epoch: 6| Step: 13
Training loss: 0.5483914739092057
Validation loss: 2.2068290249726954

Epoch: 284| Step: 0
Training loss: 0.648065805187437
Validation loss: 2.195887189432986

Epoch: 6| Step: 1
Training loss: 1.0943212924503614
Validation loss: 2.219068095103621

Epoch: 6| Step: 2
Training loss: 0.48800074340224314
Validation loss: 2.2575150972475035

Epoch: 6| Step: 3
Training loss: 0.6292971231565454
Validation loss: 2.2394072966896763

Epoch: 6| Step: 4
Training loss: 0.912670412219851
Validation loss: 2.273682287121508

Epoch: 6| Step: 5
Training loss: 0.8387260984491642
Validation loss: 2.275669166444185

Epoch: 6| Step: 6
Training loss: 0.3893845125631459
Validation loss: 2.3312366176310086

Epoch: 6| Step: 7
Training loss: 0.7993883253214215
Validation loss: 2.340226587821164

Epoch: 6| Step: 8
Training loss: 0.7184723856961195
Validation loss: 2.3114769692300903

Epoch: 6| Step: 9
Training loss: 0.708338840313616
Validation loss: 2.319860066852352

Epoch: 6| Step: 10
Training loss: 0.48549220236911184
Validation loss: 2.262279582296324

Epoch: 6| Step: 11
Training loss: 0.36741136260489454
Validation loss: 2.2502243540853346

Epoch: 6| Step: 12
Training loss: 0.654749289717258
Validation loss: 2.2075343363117828

Epoch: 6| Step: 13
Training loss: 0.25853647825233494
Validation loss: 2.2102077399735856

Epoch: 285| Step: 0
Training loss: 0.762041424606507
Validation loss: 2.193227781876077

Epoch: 6| Step: 1
Training loss: 0.38391503360871004
Validation loss: 2.192388404276133

Epoch: 6| Step: 2
Training loss: 0.6652774243585032
Validation loss: 2.191732946319934

Epoch: 6| Step: 3
Training loss: 0.8526083796790696
Validation loss: 2.221890064273413

Epoch: 6| Step: 4
Training loss: 0.7656517802634599
Validation loss: 2.2113738870571744

Epoch: 6| Step: 5
Training loss: 0.812913202708216
Validation loss: 2.242997721024424

Epoch: 6| Step: 6
Training loss: 0.6387373397826649
Validation loss: 2.2512036855891195

Epoch: 6| Step: 7
Training loss: 0.7417823488762729
Validation loss: 2.2865191976266135

Epoch: 6| Step: 8
Training loss: 0.5348866194167015
Validation loss: 2.2850747303480183

Epoch: 6| Step: 9
Training loss: 0.6827144089693178
Validation loss: 2.2557431691154175

Epoch: 6| Step: 10
Training loss: 0.6207862668683232
Validation loss: 2.2086768903707794

Epoch: 6| Step: 11
Training loss: 0.712106393545232
Validation loss: 2.2225755990155633

Epoch: 6| Step: 12
Training loss: 0.7768756473013774
Validation loss: 2.221113806913279

Epoch: 6| Step: 13
Training loss: 0.63863713347877
Validation loss: 2.189154584872157

Epoch: 286| Step: 0
Training loss: 0.8430350771628096
Validation loss: 2.211042787137956

Epoch: 6| Step: 1
Training loss: 0.6866221024656801
Validation loss: 2.1937079651696316

Epoch: 6| Step: 2
Training loss: 0.4589841802069068
Validation loss: 2.1730591048602887

Epoch: 6| Step: 3
Training loss: 0.8929103842256316
Validation loss: 2.199978921832167

Epoch: 6| Step: 4
Training loss: 0.4399224720732198
Validation loss: 2.1909765427961454

Epoch: 6| Step: 5
Training loss: 0.4656319227280051
Validation loss: 2.2301649615128136

Epoch: 6| Step: 6
Training loss: 0.5925972439442099
Validation loss: 2.239742311375892

Epoch: 6| Step: 7
Training loss: 0.523062585960816
Validation loss: 2.251533635650927

Epoch: 6| Step: 8
Training loss: 0.5401162890769377
Validation loss: 2.2619498198572927

Epoch: 6| Step: 9
Training loss: 0.7678155507580984
Validation loss: 2.2924623821377272

Epoch: 6| Step: 10
Training loss: 0.8896308503574302
Validation loss: 2.3285793445547207

Epoch: 6| Step: 11
Training loss: 0.6325832469723872
Validation loss: 2.3359169814562346

Epoch: 6| Step: 12
Training loss: 0.8990687930483873
Validation loss: 2.3185803308555797

Epoch: 6| Step: 13
Training loss: 0.5814921551467988
Validation loss: 2.2888305371819855

Epoch: 287| Step: 0
Training loss: 0.4242411591738824
Validation loss: 2.2771137409649085

Epoch: 6| Step: 1
Training loss: 0.8527577961856363
Validation loss: 2.26798596278062

Epoch: 6| Step: 2
Training loss: 0.4134913950454891
Validation loss: 2.24841397511518

Epoch: 6| Step: 3
Training loss: 0.7587136485207447
Validation loss: 2.2502162230133194

Epoch: 6| Step: 4
Training loss: 0.8081646208996512
Validation loss: 2.1910834177099114

Epoch: 6| Step: 5
Training loss: 0.5667484170717431
Validation loss: 2.186740995536186

Epoch: 6| Step: 6
Training loss: 0.697136789595333
Validation loss: 2.21422988375025

Epoch: 6| Step: 7
Training loss: 0.754435378268149
Validation loss: 2.19845264102883

Epoch: 6| Step: 8
Training loss: 0.6858337106583934
Validation loss: 2.2358534975631565

Epoch: 6| Step: 9
Training loss: 0.38216660954796194
Validation loss: 2.2354668100244024

Epoch: 6| Step: 10
Training loss: 0.7002125715312666
Validation loss: 2.263465357270275

Epoch: 6| Step: 11
Training loss: 0.4202058054000524
Validation loss: 2.3025173776060406

Epoch: 6| Step: 12
Training loss: 0.8987260438063402
Validation loss: 2.2717034474597124

Epoch: 6| Step: 13
Training loss: 0.9404364691595757
Validation loss: 2.258331580362486

Epoch: 288| Step: 0
Training loss: 0.8230592789188272
Validation loss: 2.2600852126357966

Epoch: 6| Step: 1
Training loss: 0.6822674773686994
Validation loss: 2.220016856147564

Epoch: 6| Step: 2
Training loss: 0.5670436823920247
Validation loss: 2.200010412737833

Epoch: 6| Step: 3
Training loss: 0.7215686759172278
Validation loss: 2.1840442503362554

Epoch: 6| Step: 4
Training loss: 0.9230285474819863
Validation loss: 2.188018677566922

Epoch: 6| Step: 5
Training loss: 0.8200614181638178
Validation loss: 2.204491121849455

Epoch: 6| Step: 6
Training loss: 0.5309605651479671
Validation loss: 2.2194628889623886

Epoch: 6| Step: 7
Training loss: 0.7514461244825725
Validation loss: 2.2468921522492473

Epoch: 6| Step: 8
Training loss: 0.8913071680125485
Validation loss: 2.2602464934983613

Epoch: 6| Step: 9
Training loss: 0.5884046366910208
Validation loss: 2.2761687720105517

Epoch: 6| Step: 10
Training loss: 0.4720538059516359
Validation loss: 2.2583295409885866

Epoch: 6| Step: 11
Training loss: 0.7845003795343263
Validation loss: 2.3098813867251895

Epoch: 6| Step: 12
Training loss: 0.3438397203746864
Validation loss: 2.321277108953882

Epoch: 6| Step: 13
Training loss: 0.61814911690192
Validation loss: 2.2983940012147537

Epoch: 289| Step: 0
Training loss: 0.5503098655347353
Validation loss: 2.304659499520937

Epoch: 6| Step: 1
Training loss: 0.9850016219227407
Validation loss: 2.274220487290616

Epoch: 6| Step: 2
Training loss: 0.4257974709037023
Validation loss: 2.252998630531631

Epoch: 6| Step: 3
Training loss: 0.505609958976659
Validation loss: 2.261902361487732

Epoch: 6| Step: 4
Training loss: 0.8016758085775139
Validation loss: 2.226072899543662

Epoch: 6| Step: 5
Training loss: 0.8699962733177959
Validation loss: 2.195761243423681

Epoch: 6| Step: 6
Training loss: 0.7536850441673526
Validation loss: 2.203743887195489

Epoch: 6| Step: 7
Training loss: 0.6894139178747803
Validation loss: 2.2232633698274182

Epoch: 6| Step: 8
Training loss: 0.5584503736757197
Validation loss: 2.19722493218554

Epoch: 6| Step: 9
Training loss: 0.6413723842587584
Validation loss: 2.219977740948792

Epoch: 6| Step: 10
Training loss: 0.3527818303592993
Validation loss: 2.213859598585997

Epoch: 6| Step: 11
Training loss: 0.5823392884964043
Validation loss: 2.206432374894223

Epoch: 6| Step: 12
Training loss: 0.7145866390259319
Validation loss: 2.255873823321608

Epoch: 6| Step: 13
Training loss: 0.6450486158560886
Validation loss: 2.274982479550413

Epoch: 290| Step: 0
Training loss: 0.5582935353466656
Validation loss: 2.2469554570380996

Epoch: 6| Step: 1
Training loss: 0.872190324101511
Validation loss: 2.2695361575000397

Epoch: 6| Step: 2
Training loss: 0.7123787492344503
Validation loss: 2.2527373695194663

Epoch: 6| Step: 3
Training loss: 0.7092724259615844
Validation loss: 2.247277346118726

Epoch: 6| Step: 4
Training loss: 0.5430281901585352
Validation loss: 2.2595163337355992

Epoch: 6| Step: 5
Training loss: 0.8812361628210361
Validation loss: 2.2497153700316743

Epoch: 6| Step: 6
Training loss: 0.3116597561954102
Validation loss: 2.251510178254226

Epoch: 6| Step: 7
Training loss: 0.42280026800896914
Validation loss: 2.2479154337162717

Epoch: 6| Step: 8
Training loss: 0.5795833134142692
Validation loss: 2.2543613965759515

Epoch: 6| Step: 9
Training loss: 0.5091742231034103
Validation loss: 2.249755889429826

Epoch: 6| Step: 10
Training loss: 0.6777553939857972
Validation loss: 2.253273065624745

Epoch: 6| Step: 11
Training loss: 0.5455902813050044
Validation loss: 2.2555766197949647

Epoch: 6| Step: 12
Training loss: 0.6743480942867852
Validation loss: 2.235408518401268

Epoch: 6| Step: 13
Training loss: 1.141772959742889
Validation loss: 2.2268221772999928

Epoch: 291| Step: 0
Training loss: 0.7963208160169758
Validation loss: 2.2440924924053283

Epoch: 6| Step: 1
Training loss: 0.45083592445254134
Validation loss: 2.2580268486458612

Epoch: 6| Step: 2
Training loss: 0.7852592210953897
Validation loss: 2.2754014839308647

Epoch: 6| Step: 3
Training loss: 0.49996250727273167
Validation loss: 2.263244043170739

Epoch: 6| Step: 4
Training loss: 0.6004921444483087
Validation loss: 2.279307737815866

Epoch: 6| Step: 5
Training loss: 0.5822741366518861
Validation loss: 2.319637047384247

Epoch: 6| Step: 6
Training loss: 0.823423535338959
Validation loss: 2.277307153828228

Epoch: 6| Step: 7
Training loss: 0.6436541282225088
Validation loss: 2.325798066005359

Epoch: 6| Step: 8
Training loss: 0.652463753449866
Validation loss: 2.3108145301045884

Epoch: 6| Step: 9
Training loss: 0.4948386738850758
Validation loss: 2.3578262276620445

Epoch: 6| Step: 10
Training loss: 0.8816577144076965
Validation loss: 2.341226038288447

Epoch: 6| Step: 11
Training loss: 0.5656205614453245
Validation loss: 2.2983461074469944

Epoch: 6| Step: 12
Training loss: 0.6261360096312873
Validation loss: 2.2875655292350987

Epoch: 6| Step: 13
Training loss: 0.6683716033227128
Validation loss: 2.2664649037381976

Epoch: 292| Step: 0
Training loss: 0.9306335123978118
Validation loss: 2.256704441264008

Epoch: 6| Step: 1
Training loss: 0.7305726166180612
Validation loss: 2.2718311799443653

Epoch: 6| Step: 2
Training loss: 0.5987903580572872
Validation loss: 2.210788637294674

Epoch: 6| Step: 3
Training loss: 0.4506185862895591
Validation loss: 2.2370241810692515

Epoch: 6| Step: 4
Training loss: 0.7043853484157696
Validation loss: 2.2258870085866036

Epoch: 6| Step: 5
Training loss: 0.5852202794245538
Validation loss: 2.238413213489039

Epoch: 6| Step: 6
Training loss: 0.31353930264381236
Validation loss: 2.23741967973735

Epoch: 6| Step: 7
Training loss: 0.8212910220092186
Validation loss: 2.2216680005674534

Epoch: 6| Step: 8
Training loss: 0.21818617979276944
Validation loss: 2.2598959130745495

Epoch: 6| Step: 9
Training loss: 0.48642117020038
Validation loss: 2.2482572084577517

Epoch: 6| Step: 10
Training loss: 0.822969475190506
Validation loss: 2.2959934038640095

Epoch: 6| Step: 11
Training loss: 0.6072932165354019
Validation loss: 2.2915955167969955

Epoch: 6| Step: 12
Training loss: 0.7762500218684736
Validation loss: 2.2984305772912537

Epoch: 6| Step: 13
Training loss: 0.2210177651575109
Validation loss: 2.303737773260008

Epoch: 293| Step: 0
Training loss: 0.35335162874342757
Validation loss: 2.30143533223673

Epoch: 6| Step: 1
Training loss: 0.5772167752725588
Validation loss: 2.2799239429546305

Epoch: 6| Step: 2
Training loss: 0.5243434751944024
Validation loss: 2.296246789068589

Epoch: 6| Step: 3
Training loss: 0.9384902175084564
Validation loss: 2.2609311809242145

Epoch: 6| Step: 4
Training loss: 0.5371294329972776
Validation loss: 2.239142884892891

Epoch: 6| Step: 5
Training loss: 0.5312267186168428
Validation loss: 2.2223603729490775

Epoch: 6| Step: 6
Training loss: 0.7427579594779162
Validation loss: 2.245812131143262

Epoch: 6| Step: 7
Training loss: 0.6625237307706833
Validation loss: 2.2405668220250217

Epoch: 6| Step: 8
Training loss: 0.7699223797553124
Validation loss: 2.2521471593608595

Epoch: 6| Step: 9
Training loss: 0.30988721541702136
Validation loss: 2.261660648708858

Epoch: 6| Step: 10
Training loss: 0.33960887860634176
Validation loss: 2.2646876290287974

Epoch: 6| Step: 11
Training loss: 0.7651437297760312
Validation loss: 2.26781315834525

Epoch: 6| Step: 12
Training loss: 0.8810626216286792
Validation loss: 2.2751335586465142

Epoch: 6| Step: 13
Training loss: 0.4576815681578415
Validation loss: 2.295441344217957

Epoch: 294| Step: 0
Training loss: 0.5775295748300605
Validation loss: 2.27015284171303

Epoch: 6| Step: 1
Training loss: 0.5578731877842213
Validation loss: 2.296087775658271

Epoch: 6| Step: 2
Training loss: 0.5495421356953877
Validation loss: 2.3057072689582503

Epoch: 6| Step: 3
Training loss: 0.646672754414733
Validation loss: 2.3098301320757177

Epoch: 6| Step: 4
Training loss: 0.6222429979021563
Validation loss: 2.3354824071582243

Epoch: 6| Step: 5
Training loss: 0.42939642670876527
Validation loss: 2.35065779424113

Epoch: 6| Step: 6
Training loss: 0.737382371864646
Validation loss: 2.332783211367876

Epoch: 6| Step: 7
Training loss: 0.9890302450937972
Validation loss: 2.316410212096729

Epoch: 6| Step: 8
Training loss: 0.4119342956348886
Validation loss: 2.3179040483054796

Epoch: 6| Step: 9
Training loss: 0.79534372294654
Validation loss: 2.3008269359380846

Epoch: 6| Step: 10
Training loss: 0.7567675750375236
Validation loss: 2.2824922821062157

Epoch: 6| Step: 11
Training loss: 0.4045561175845515
Validation loss: 2.2701623395116206

Epoch: 6| Step: 12
Training loss: 0.3954618074010432
Validation loss: 2.2814791670051955

Epoch: 6| Step: 13
Training loss: 0.3589787164186099
Validation loss: 2.283126996104157

Epoch: 295| Step: 0
Training loss: 0.5474902642921655
Validation loss: 2.243448516904266

Epoch: 6| Step: 1
Training loss: 0.43417254470804845
Validation loss: 2.2447026421650706

Epoch: 6| Step: 2
Training loss: 0.3990602488443064
Validation loss: 2.243688884991312

Epoch: 6| Step: 3
Training loss: 0.6863644498571069
Validation loss: 2.2278448039624155

Epoch: 6| Step: 4
Training loss: 0.6727517196480197
Validation loss: 2.212468036865444

Epoch: 6| Step: 5
Training loss: 0.6062586891888729
Validation loss: 2.2233309051773578

Epoch: 6| Step: 6
Training loss: 0.6528593526984959
Validation loss: 2.2295997851704485

Epoch: 6| Step: 7
Training loss: 0.8563707377937835
Validation loss: 2.246477975533328

Epoch: 6| Step: 8
Training loss: 0.4881852169967559
Validation loss: 2.2744015996807954

Epoch: 6| Step: 9
Training loss: 0.6112704021270796
Validation loss: 2.2611385106062687

Epoch: 6| Step: 10
Training loss: 0.735627222762724
Validation loss: 2.3022787363553423

Epoch: 6| Step: 11
Training loss: 0.655222406119959
Validation loss: 2.2859498631531467

Epoch: 6| Step: 12
Training loss: 0.511006099283804
Validation loss: 2.2962856355557406

Epoch: 6| Step: 13
Training loss: 0.4799058144024601
Validation loss: 2.3075627793350377

Epoch: 296| Step: 0
Training loss: 1.0018064157257296
Validation loss: 2.3058299458027065

Epoch: 6| Step: 1
Training loss: 0.7903605444782428
Validation loss: 2.33391592850707

Epoch: 6| Step: 2
Training loss: 0.5894640527803094
Validation loss: 2.265389173806351

Epoch: 6| Step: 3
Training loss: 0.5481275111698752
Validation loss: 2.2942408422316536

Epoch: 6| Step: 4
Training loss: 0.47406569686646594
Validation loss: 2.2577484799648584

Epoch: 6| Step: 5
Training loss: 0.2205829461950237
Validation loss: 2.2866431967954433

Epoch: 6| Step: 6
Training loss: 0.5752964934650818
Validation loss: 2.2517687659976993

Epoch: 6| Step: 7
Training loss: 0.6801363898685283
Validation loss: 2.23191345090749

Epoch: 6| Step: 8
Training loss: 0.3176738871468976
Validation loss: 2.250319831886179

Epoch: 6| Step: 9
Training loss: 0.4668964614939968
Validation loss: 2.211605299170365

Epoch: 6| Step: 10
Training loss: 0.6961655687815592
Validation loss: 2.2150157453600086

Epoch: 6| Step: 11
Training loss: 0.4154682050100986
Validation loss: 2.220062907313466

Epoch: 6| Step: 12
Training loss: 0.7894493891926313
Validation loss: 2.2272657313290165

Epoch: 6| Step: 13
Training loss: 0.47285402116920194
Validation loss: 2.232932686771382

Epoch: 297| Step: 0
Training loss: 0.3314505042241028
Validation loss: 2.252026209015167

Epoch: 6| Step: 1
Training loss: 0.6542452663735788
Validation loss: 2.2361260960128058

Epoch: 6| Step: 2
Training loss: 0.269839966929147
Validation loss: 2.2374618838215596

Epoch: 6| Step: 3
Training loss: 0.7606026321921291
Validation loss: 2.2284777081403457

Epoch: 6| Step: 4
Training loss: 0.4626372404357672
Validation loss: 2.261282220417249

Epoch: 6| Step: 5
Training loss: 0.7477610069237677
Validation loss: 2.2599784702691554

Epoch: 6| Step: 6
Training loss: 0.5155933254801337
Validation loss: 2.270064394696459

Epoch: 6| Step: 7
Training loss: 0.4174800225863387
Validation loss: 2.2508489928033186

Epoch: 6| Step: 8
Training loss: 0.6062851109120009
Validation loss: 2.2080454701617396

Epoch: 6| Step: 9
Training loss: 0.5285463255137008
Validation loss: 2.217779132870401

Epoch: 6| Step: 10
Training loss: 0.5573617380125325
Validation loss: 2.2161701414537505

Epoch: 6| Step: 11
Training loss: 0.6193473783583375
Validation loss: 2.2309607928959787

Epoch: 6| Step: 12
Training loss: 0.8282274506732288
Validation loss: 2.2167852369173464

Epoch: 6| Step: 13
Training loss: 0.9000112599092355
Validation loss: 2.2383023302747453

Epoch: 298| Step: 0
Training loss: 0.584360237751101
Validation loss: 2.268071683142401

Epoch: 6| Step: 1
Training loss: 0.5531407402514523
Validation loss: 2.2648622274761965

Epoch: 6| Step: 2
Training loss: 0.5926391097430619
Validation loss: 2.278411955238388

Epoch: 6| Step: 3
Training loss: 0.27582715654708273
Validation loss: 2.2415420879887695

Epoch: 6| Step: 4
Training loss: 0.6633701754607156
Validation loss: 2.2608733559127163

Epoch: 6| Step: 5
Training loss: 0.7564656982511602
Validation loss: 2.252998133136062

Epoch: 6| Step: 6
Training loss: 0.6590280542103981
Validation loss: 2.259297419643094

Epoch: 6| Step: 7
Training loss: 0.7037189306376401
Validation loss: 2.2808142119518924

Epoch: 6| Step: 8
Training loss: 0.5561673210076559
Validation loss: 2.2646371302312907

Epoch: 6| Step: 9
Training loss: 0.5536784275206003
Validation loss: 2.2753868708939797

Epoch: 6| Step: 10
Training loss: 0.6066517255937908
Validation loss: 2.2650938707814117

Epoch: 6| Step: 11
Training loss: 0.4467022275054027
Validation loss: 2.283626038238085

Epoch: 6| Step: 12
Training loss: 0.5829154089922514
Validation loss: 2.265817383832524

Epoch: 6| Step: 13
Training loss: 0.7391508118205995
Validation loss: 2.262168880715273

Epoch: 299| Step: 0
Training loss: 0.7547590739111283
Validation loss: 2.270382890584784

Epoch: 6| Step: 1
Training loss: 0.7975839191636956
Validation loss: 2.2413203133999664

Epoch: 6| Step: 2
Training loss: 0.563150374278002
Validation loss: 2.2314286790977618

Epoch: 6| Step: 3
Training loss: 0.1859154303459885
Validation loss: 2.2266606267331115

Epoch: 6| Step: 4
Training loss: 0.6520010681991953
Validation loss: 2.2281444549228953

Epoch: 6| Step: 5
Training loss: 0.531599042332736
Validation loss: 2.264783789789384

Epoch: 6| Step: 6
Training loss: 0.358924022993456
Validation loss: 2.208222088262956

Epoch: 6| Step: 7
Training loss: 0.6693477784292972
Validation loss: 2.209735673147474

Epoch: 6| Step: 8
Training loss: 0.6624956607676499
Validation loss: 2.220968068764826

Epoch: 6| Step: 9
Training loss: 0.548020498303087
Validation loss: 2.2102606167088275

Epoch: 6| Step: 10
Training loss: 0.6945643954526216
Validation loss: 2.2008112540586624

Epoch: 6| Step: 11
Training loss: 0.4120137071979693
Validation loss: 2.208207287231769

Epoch: 6| Step: 12
Training loss: 0.6157253667664367
Validation loss: 2.2242164752105342

Epoch: 6| Step: 13
Training loss: 0.7997590402472002
Validation loss: 2.2580261010207217

Epoch: 300| Step: 0
Training loss: 0.5219238372611446
Validation loss: 2.2511663330781104

Epoch: 6| Step: 1
Training loss: 0.4369564085328378
Validation loss: 2.2183618964356917

Epoch: 6| Step: 2
Training loss: 0.5670586873215071
Validation loss: 2.2586287830993705

Epoch: 6| Step: 3
Training loss: 0.4580317574364386
Validation loss: 2.2236307845366112

Epoch: 6| Step: 4
Training loss: 0.38422103527455226
Validation loss: 2.261851979020006

Epoch: 6| Step: 5
Training loss: 0.6608302270576555
Validation loss: 2.25636202390046

Epoch: 6| Step: 6
Training loss: 0.6860951244711438
Validation loss: 2.2863703845891994

Epoch: 6| Step: 7
Training loss: 0.5990940327272827
Validation loss: 2.2887669574481255

Epoch: 6| Step: 8
Training loss: 0.6425289146804282
Validation loss: 2.2782064619812097

Epoch: 6| Step: 9
Training loss: 0.590076526915948
Validation loss: 2.300971700508117

Epoch: 6| Step: 10
Training loss: 0.6431296859807755
Validation loss: 2.300149371311248

Epoch: 6| Step: 11
Training loss: 0.8227578545087942
Validation loss: 2.29260537358105

Epoch: 6| Step: 12
Training loss: 0.7021098119645857
Validation loss: 2.2621188759032513

Epoch: 6| Step: 13
Training loss: 0.3133014534502563
Validation loss: 2.2452556833928363

Epoch: 301| Step: 0
Training loss: 0.4992225085670693
Validation loss: 2.2781871333729784

Epoch: 6| Step: 1
Training loss: 0.4755830392612136
Validation loss: 2.255001477431412

Epoch: 6| Step: 2
Training loss: 0.21434120009079485
Validation loss: 2.2571350016790372

Epoch: 6| Step: 3
Training loss: 0.45578416401660965
Validation loss: 2.2556412050333625

Epoch: 6| Step: 4
Training loss: 0.7794057822553576
Validation loss: 2.287545489056112

Epoch: 6| Step: 5
Training loss: 0.6191017307134685
Validation loss: 2.2739268111363793

Epoch: 6| Step: 6
Training loss: 0.5753664756208086
Validation loss: 2.247211644431424

Epoch: 6| Step: 7
Training loss: 0.7425355597050236
Validation loss: 2.2601097351829607

Epoch: 6| Step: 8
Training loss: 0.5712817851850195
Validation loss: 2.235794752781221

Epoch: 6| Step: 9
Training loss: 0.5281713984496065
Validation loss: 2.273304776291507

Epoch: 6| Step: 10
Training loss: 0.6403719239333238
Validation loss: 2.251076772214433

Epoch: 6| Step: 11
Training loss: 0.59522598418903
Validation loss: 2.228645108053098

Epoch: 6| Step: 12
Training loss: 0.694520048688366
Validation loss: 2.240016992760147

Epoch: 6| Step: 13
Training loss: 0.497455380322225
Validation loss: 2.280782057950749

Epoch: 302| Step: 0
Training loss: 0.5498798650971648
Validation loss: 2.2757971967808954

Epoch: 6| Step: 1
Training loss: 0.7426378189005326
Validation loss: 2.277362907341896

Epoch: 6| Step: 2
Training loss: 0.6586827644476895
Validation loss: 2.3109425957312597

Epoch: 6| Step: 3
Training loss: 0.7358980820257731
Validation loss: 2.294688550494184

Epoch: 6| Step: 4
Training loss: 0.5911019402787863
Validation loss: 2.280416524341953

Epoch: 6| Step: 5
Training loss: 0.34151632511639435
Validation loss: 2.2520459169715497

Epoch: 6| Step: 6
Training loss: 0.5378847386433544
Validation loss: 2.3075059867920498

Epoch: 6| Step: 7
Training loss: 0.32637292981303895
Validation loss: 2.2792607342256757

Epoch: 6| Step: 8
Training loss: 0.7127418676398769
Validation loss: 2.282328807526939

Epoch: 6| Step: 9
Training loss: 0.33342452838266845
Validation loss: 2.2612014766417174

Epoch: 6| Step: 10
Training loss: 0.5737277156682616
Validation loss: 2.2618759910777793

Epoch: 6| Step: 11
Training loss: 0.7639457426203081
Validation loss: 2.2779862592919558

Epoch: 6| Step: 12
Training loss: 0.5465922033178897
Validation loss: 2.24359891651721

Epoch: 6| Step: 13
Training loss: 0.3033042589054942
Validation loss: 2.2868634523597016

Epoch: 303| Step: 0
Training loss: 0.25012296394423084
Validation loss: 2.285502321906659

Epoch: 6| Step: 1
Training loss: 0.5266157140359055
Validation loss: 2.251824567786536

Epoch: 6| Step: 2
Training loss: 0.3365113436075014
Validation loss: 2.291307861638714

Epoch: 6| Step: 3
Training loss: 0.5556779266397742
Validation loss: 2.2425154093576953

Epoch: 6| Step: 4
Training loss: 0.5145929006183935
Validation loss: 2.292555465693753

Epoch: 6| Step: 5
Training loss: 0.21485133591177333
Validation loss: 2.2784882067936336

Epoch: 6| Step: 6
Training loss: 0.715310949854673
Validation loss: 2.30213333348049

Epoch: 6| Step: 7
Training loss: 0.5564247381946444
Validation loss: 2.2982321189870416

Epoch: 6| Step: 8
Training loss: 0.6011549076613238
Validation loss: 2.2605509118216265

Epoch: 6| Step: 9
Training loss: 0.4475541163068024
Validation loss: 2.2817033066432324

Epoch: 6| Step: 10
Training loss: 1.0180624835993075
Validation loss: 2.277069079735756

Epoch: 6| Step: 11
Training loss: 0.6945977770221418
Validation loss: 2.2797310616289668

Epoch: 6| Step: 12
Training loss: 0.4964361886232036
Validation loss: 2.2818228462711057

Epoch: 6| Step: 13
Training loss: 0.6115600828377387
Validation loss: 2.28955874183841

Epoch: 304| Step: 0
Training loss: 0.7973925835667589
Validation loss: 2.3162284599819274

Epoch: 6| Step: 1
Training loss: 0.5459740983806833
Validation loss: 2.2527206697104005

Epoch: 6| Step: 2
Training loss: 0.6473822452370279
Validation loss: 2.297867360869667

Epoch: 6| Step: 3
Training loss: 0.5129740220867091
Validation loss: 2.2780248786768538

Epoch: 6| Step: 4
Training loss: 0.6081285934498895
Validation loss: 2.295330392420472

Epoch: 6| Step: 5
Training loss: 0.414368318587302
Validation loss: 2.2868176068517827

Epoch: 6| Step: 6
Training loss: 0.654725711408419
Validation loss: 2.266759577176436

Epoch: 6| Step: 7
Training loss: 0.5463173338987491
Validation loss: 2.2944479553126405

Epoch: 6| Step: 8
Training loss: 0.4056028383252096
Validation loss: 2.273119825710008

Epoch: 6| Step: 9
Training loss: 0.6212440884575613
Validation loss: 2.2779482362858765

Epoch: 6| Step: 10
Training loss: 0.25491847230941633
Validation loss: 2.25080316489792

Epoch: 6| Step: 11
Training loss: 0.828431342701746
Validation loss: 2.2680244613854468

Epoch: 6| Step: 12
Training loss: 0.48029739922020487
Validation loss: 2.243157402997734

Epoch: 6| Step: 13
Training loss: 0.3972748641868639
Validation loss: 2.260749010658568

Epoch: 305| Step: 0
Training loss: 0.8895809679796515
Validation loss: 2.2578541616678094

Epoch: 6| Step: 1
Training loss: 0.478968363307464
Validation loss: 2.2358299559201686

Epoch: 6| Step: 2
Training loss: 0.5283330609093253
Validation loss: 2.226454596071795

Epoch: 6| Step: 3
Training loss: 0.3246836833160449
Validation loss: 2.239226516340288

Epoch: 6| Step: 4
Training loss: 0.5373567878315011
Validation loss: 2.270740251608131

Epoch: 6| Step: 5
Training loss: 0.5669644203443335
Validation loss: 2.24592671576237

Epoch: 6| Step: 6
Training loss: 0.31512995553952894
Validation loss: 2.254854372053086

Epoch: 6| Step: 7
Training loss: 0.8835069406298305
Validation loss: 2.240138711102746

Epoch: 6| Step: 8
Training loss: 0.5219384548876047
Validation loss: 2.285312323248971

Epoch: 6| Step: 9
Training loss: 0.7058724238039795
Validation loss: 2.2678400071300238

Epoch: 6| Step: 10
Training loss: 0.5338190454855082
Validation loss: 2.2538378512788166

Epoch: 6| Step: 11
Training loss: 0.36920308790594586
Validation loss: 2.257237262288744

Epoch: 6| Step: 12
Training loss: 0.5390231353097656
Validation loss: 2.2447375085993397

Epoch: 6| Step: 13
Training loss: 0.30408049297905376
Validation loss: 2.27496700625794

Epoch: 306| Step: 0
Training loss: 0.3660363353296851
Validation loss: 2.2480198682222996

Epoch: 6| Step: 1
Training loss: 0.614392118826687
Validation loss: 2.2991299638191154

Epoch: 6| Step: 2
Training loss: 0.49041721840111424
Validation loss: 2.2636304642379996

Epoch: 6| Step: 3
Training loss: 0.7359193836096202
Validation loss: 2.266771689849577

Epoch: 6| Step: 4
Training loss: 0.7434852096687296
Validation loss: 2.272369660594487

Epoch: 6| Step: 5
Training loss: 0.5281274411748863
Validation loss: 2.2826614424349994

Epoch: 6| Step: 6
Training loss: 0.7329714328226414
Validation loss: 2.2841920147573926

Epoch: 6| Step: 7
Training loss: 0.645447513228193
Validation loss: 2.2726187263923783

Epoch: 6| Step: 8
Training loss: 0.6979318209089396
Validation loss: 2.276689750607088

Epoch: 6| Step: 9
Training loss: 0.38073677632893566
Validation loss: 2.2808420477013325

Epoch: 6| Step: 10
Training loss: 0.5489010202455691
Validation loss: 2.2881290927038993

Epoch: 6| Step: 11
Training loss: 0.42083474228248546
Validation loss: 2.285137755392149

Epoch: 6| Step: 12
Training loss: 0.3124354534246206
Validation loss: 2.2952375414728077

Epoch: 6| Step: 13
Training loss: 0.4553935059151822
Validation loss: 2.300217039346204

Epoch: 307| Step: 0
Training loss: 0.6177137762755162
Validation loss: 2.28206930311524

Epoch: 6| Step: 1
Training loss: 0.2007443134308862
Validation loss: 2.315357726773196

Epoch: 6| Step: 2
Training loss: 0.7227567448203995
Validation loss: 2.2613323888420225

Epoch: 6| Step: 3
Training loss: 0.4636629960223118
Validation loss: 2.2639665699985874

Epoch: 6| Step: 4
Training loss: 0.6099541186447175
Validation loss: 2.2427078860305087

Epoch: 6| Step: 5
Training loss: 0.5806708855457455
Validation loss: 2.250659223944335

Epoch: 6| Step: 6
Training loss: 0.6120788060231418
Validation loss: 2.251673134450283

Epoch: 6| Step: 7
Training loss: 0.5524184061879401
Validation loss: 2.2617887788997204

Epoch: 6| Step: 8
Training loss: 0.5170166136675032
Validation loss: 2.24550940518204

Epoch: 6| Step: 9
Training loss: 0.7098108523901328
Validation loss: 2.2461241766325353

Epoch: 6| Step: 10
Training loss: 0.39330018477994455
Validation loss: 2.2715340393402585

Epoch: 6| Step: 11
Training loss: 0.654712783944337
Validation loss: 2.2937947576943634

Epoch: 6| Step: 12
Training loss: 0.4354476815757132
Validation loss: 2.2964727068822155

Epoch: 6| Step: 13
Training loss: 0.7353035757915076
Validation loss: 2.288664001991547

Epoch: 308| Step: 0
Training loss: 0.46469562638853334
Validation loss: 2.2891624468342124

Epoch: 6| Step: 1
Training loss: 0.3455123482725048
Validation loss: 2.304680830283827

Epoch: 6| Step: 2
Training loss: 0.605517649983175
Validation loss: 2.2708299372831

Epoch: 6| Step: 3
Training loss: 0.4418802838636823
Validation loss: 2.2924309523465394

Epoch: 6| Step: 4
Training loss: 0.8348682017442948
Validation loss: 2.259958503086988

Epoch: 6| Step: 5
Training loss: 0.7178583834460505
Validation loss: 2.2883450671326697

Epoch: 6| Step: 6
Training loss: 0.19520209052757503
Validation loss: 2.274544771596643

Epoch: 6| Step: 7
Training loss: 0.2546355703572801
Validation loss: 2.2592486820326467

Epoch: 6| Step: 8
Training loss: 0.5508588100501326
Validation loss: 2.209410964230551

Epoch: 6| Step: 9
Training loss: 0.5047639157104363
Validation loss: 2.2195226285101506

Epoch: 6| Step: 10
Training loss: 0.7169312395353404
Validation loss: 2.215508384950125

Epoch: 6| Step: 11
Training loss: 0.38451931422998725
Validation loss: 2.201951336187344

Epoch: 6| Step: 12
Training loss: 0.6985056560126256
Validation loss: 2.212275543516461

Epoch: 6| Step: 13
Training loss: 0.5904082066915373
Validation loss: 2.2373451151231576

Epoch: 309| Step: 0
Training loss: 0.5508136604458743
Validation loss: 2.2357488562355186

Epoch: 6| Step: 1
Training loss: 0.5598435458822515
Validation loss: 2.230132201977674

Epoch: 6| Step: 2
Training loss: 0.3970615526725748
Validation loss: 2.262514773728347

Epoch: 6| Step: 3
Training loss: 0.2826379859299625
Validation loss: 2.2534473357415

Epoch: 6| Step: 4
Training loss: 0.4206375056727453
Validation loss: 2.276430724463498

Epoch: 6| Step: 5
Training loss: 0.47482950890271713
Validation loss: 2.2781213137110696

Epoch: 6| Step: 6
Training loss: 0.5405468338482419
Validation loss: 2.305470219439772

Epoch: 6| Step: 7
Training loss: 0.49081362360363345
Validation loss: 2.307626073948788

Epoch: 6| Step: 8
Training loss: 0.6095093799022643
Validation loss: 2.3349222376353946

Epoch: 6| Step: 9
Training loss: 0.4630528419281374
Validation loss: 2.331974669687496

Epoch: 6| Step: 10
Training loss: 0.3703927697532174
Validation loss: 2.3035070968163147

Epoch: 6| Step: 11
Training loss: 0.9277789617164149
Validation loss: 2.3274790331630797

Epoch: 6| Step: 12
Training loss: 0.7733487550318628
Validation loss: 2.302396003500998

Epoch: 6| Step: 13
Training loss: 0.37828138286047785
Validation loss: 2.2865040322528585

Epoch: 310| Step: 0
Training loss: 0.3684991783627236
Validation loss: 2.2738615863331466

Epoch: 6| Step: 1
Training loss: 0.5144366239248989
Validation loss: 2.2665464949450826

Epoch: 6| Step: 2
Training loss: 0.6107889546054542
Validation loss: 2.2667282131386433

Epoch: 6| Step: 3
Training loss: 0.4158326583900147
Validation loss: 2.2613269856885867

Epoch: 6| Step: 4
Training loss: 0.3765648537083428
Validation loss: 2.2633644773056263

Epoch: 6| Step: 5
Training loss: 0.6970620592803917
Validation loss: 2.2574483932203435

Epoch: 6| Step: 6
Training loss: 0.5215413494632825
Validation loss: 2.2399718885957753

Epoch: 6| Step: 7
Training loss: 0.3072140913637167
Validation loss: 2.235107943037458

Epoch: 6| Step: 8
Training loss: 0.7116060571821224
Validation loss: 2.2458755651135505

Epoch: 6| Step: 9
Training loss: 0.5283588388325487
Validation loss: 2.251770190261802

Epoch: 6| Step: 10
Training loss: 0.5572429677297909
Validation loss: 2.261496180115846

Epoch: 6| Step: 11
Training loss: 0.6090791424219011
Validation loss: 2.2804018186551085

Epoch: 6| Step: 12
Training loss: 0.46033854282047754
Validation loss: 2.2635759829881565

Epoch: 6| Step: 13
Training loss: 0.753615090868632
Validation loss: 2.299655331212702

Epoch: 311| Step: 0
Training loss: 0.6995502517229142
Validation loss: 2.2869308313858046

Epoch: 6| Step: 1
Training loss: 0.6717178693270007
Validation loss: 2.315167550022919

Epoch: 6| Step: 2
Training loss: 0.6103587890197193
Validation loss: 2.2867729706239377

Epoch: 6| Step: 3
Training loss: 0.49525645327034395
Validation loss: 2.279894746649412

Epoch: 6| Step: 4
Training loss: 0.4726253373307036
Validation loss: 2.275176410220238

Epoch: 6| Step: 5
Training loss: 0.5212083007178587
Validation loss: 2.27884007586131

Epoch: 6| Step: 6
Training loss: 0.5744288053828893
Validation loss: 2.2598284489124096

Epoch: 6| Step: 7
Training loss: 0.4506369387861208
Validation loss: 2.240083449075739

Epoch: 6| Step: 8
Training loss: 0.40795061980643527
Validation loss: 2.253566236660699

Epoch: 6| Step: 9
Training loss: 0.6153953704902841
Validation loss: 2.2508592298070926

Epoch: 6| Step: 10
Training loss: 0.7255676185071823
Validation loss: 2.2616348371468704

Epoch: 6| Step: 11
Training loss: 0.42422719704664186
Validation loss: 2.285019085342306

Epoch: 6| Step: 12
Training loss: 0.4632371016207995
Validation loss: 2.2983784457211045

Epoch: 6| Step: 13
Training loss: 0.563089565089433
Validation loss: 2.3133083783058757

Epoch: 312| Step: 0
Training loss: 0.44882251015546604
Validation loss: 2.3026962284767767

Epoch: 6| Step: 1
Training loss: 0.35451480173327
Validation loss: 2.332434318069733

Epoch: 6| Step: 2
Training loss: 0.6305216543697615
Validation loss: 2.319611701913947

Epoch: 6| Step: 3
Training loss: 0.35275051929116635
Validation loss: 2.280482071474639

Epoch: 6| Step: 4
Training loss: 0.5132246209757467
Validation loss: 2.286509686484628

Epoch: 6| Step: 5
Training loss: 0.49998149241526657
Validation loss: 2.302449770496421

Epoch: 6| Step: 6
Training loss: 0.6764943324187859
Validation loss: 2.265546366932753

Epoch: 6| Step: 7
Training loss: 0.4968105004390703
Validation loss: 2.2980848804518574

Epoch: 6| Step: 8
Training loss: 0.6092362612731571
Validation loss: 2.261829490613521

Epoch: 6| Step: 9
Training loss: 0.4812944651782601
Validation loss: 2.242072496740989

Epoch: 6| Step: 10
Training loss: 0.7585812631477046
Validation loss: 2.2508018003883707

Epoch: 6| Step: 11
Training loss: 0.48502524629736765
Validation loss: 2.2432538261355206

Epoch: 6| Step: 12
Training loss: 0.6278411423115079
Validation loss: 2.272344863076018

Epoch: 6| Step: 13
Training loss: 0.17227133657108454
Validation loss: 2.2409926638826256

Epoch: 313| Step: 0
Training loss: 0.38885024305411814
Validation loss: 2.2425528099335303

Epoch: 6| Step: 1
Training loss: 0.5694837950727785
Validation loss: 2.226426201250128

Epoch: 6| Step: 2
Training loss: 0.31928413740922607
Validation loss: 2.2388297718903973

Epoch: 6| Step: 3
Training loss: 0.4490628179178725
Validation loss: 2.232462111136422

Epoch: 6| Step: 4
Training loss: 0.3046397391812802
Validation loss: 2.2482978154241584

Epoch: 6| Step: 5
Training loss: 0.6911435678919728
Validation loss: 2.271902100590606

Epoch: 6| Step: 6
Training loss: 0.5697533989236238
Validation loss: 2.2478162532225276

Epoch: 6| Step: 7
Training loss: 0.7341597221239472
Validation loss: 2.2487893653165685

Epoch: 6| Step: 8
Training loss: 0.4371376921589485
Validation loss: 2.2775671051595334

Epoch: 6| Step: 9
Training loss: 0.5141476070832486
Validation loss: 2.292675240114439

Epoch: 6| Step: 10
Training loss: 0.5202986706794622
Validation loss: 2.3094418122236493

Epoch: 6| Step: 11
Training loss: 0.6384064475717471
Validation loss: 2.314501944856449

Epoch: 6| Step: 12
Training loss: 0.5811293866522652
Validation loss: 2.3061188877614542

Epoch: 6| Step: 13
Training loss: 0.6505590684668129
Validation loss: 2.280252364105325

Epoch: 314| Step: 0
Training loss: 0.7272046440670756
Validation loss: 2.2830724287632544

Epoch: 6| Step: 1
Training loss: 0.7547828045488941
Validation loss: 2.27565449992522

Epoch: 6| Step: 2
Training loss: 0.523776755776193
Validation loss: 2.2884572958096707

Epoch: 6| Step: 3
Training loss: 0.6161573480436777
Validation loss: 2.240015344717349

Epoch: 6| Step: 4
Training loss: 0.6886744438032599
Validation loss: 2.2618481253701357

Epoch: 6| Step: 5
Training loss: 0.5444242331209032
Validation loss: 2.249147675302617

Epoch: 6| Step: 6
Training loss: 0.35736871542913673
Validation loss: 2.2281835590705277

Epoch: 6| Step: 7
Training loss: 0.4415791434561799
Validation loss: 2.2526748098923326

Epoch: 6| Step: 8
Training loss: 0.3544729138223687
Validation loss: 2.2725802729024447

Epoch: 6| Step: 9
Training loss: 0.4128328454362935
Validation loss: 2.2515920819513564

Epoch: 6| Step: 10
Training loss: 0.4020644764933904
Validation loss: 2.232967955696872

Epoch: 6| Step: 11
Training loss: 0.3059285393825871
Validation loss: 2.2453463167778467

Epoch: 6| Step: 12
Training loss: 0.5895533067675376
Validation loss: 2.257812063418167

Epoch: 6| Step: 13
Training loss: 0.44612781441362737
Validation loss: 2.230232999982423

Epoch: 315| Step: 0
Training loss: 0.5798360659913293
Validation loss: 2.2253111798324396

Epoch: 6| Step: 1
Training loss: 0.5796394616141638
Validation loss: 2.2466065619731594

Epoch: 6| Step: 2
Training loss: 0.3686685116487754
Validation loss: 2.2426607715030307

Epoch: 6| Step: 3
Training loss: 0.5460999582617199
Validation loss: 2.235620298351349

Epoch: 6| Step: 4
Training loss: 0.5041591098576366
Validation loss: 2.275068562256654

Epoch: 6| Step: 5
Training loss: 0.49440434169865155
Validation loss: 2.2914302325475133

Epoch: 6| Step: 6
Training loss: 0.32928034060996053
Validation loss: 2.266594535838412

Epoch: 6| Step: 7
Training loss: 0.5049008157792644
Validation loss: 2.2873324720144277

Epoch: 6| Step: 8
Training loss: 0.7258806207832401
Validation loss: 2.2388493481034892

Epoch: 6| Step: 9
Training loss: 0.5470410503608966
Validation loss: 2.23109980818469

Epoch: 6| Step: 10
Training loss: 0.4828251531479926
Validation loss: 2.2334302262562313

Epoch: 6| Step: 11
Training loss: 0.6548957020224643
Validation loss: 2.239301664282963

Epoch: 6| Step: 12
Training loss: 0.6784694324289849
Validation loss: 2.264129443783899

Epoch: 6| Step: 13
Training loss: 0.43116860450849337
Validation loss: 2.2188498327085906

Epoch: 316| Step: 0
Training loss: 0.6068201549823958
Validation loss: 2.262087444971794

Epoch: 6| Step: 1
Training loss: 0.2772468209467075
Validation loss: 2.252577546376313

Epoch: 6| Step: 2
Training loss: 0.5686385789659935
Validation loss: 2.2749256422080877

Epoch: 6| Step: 3
Training loss: 0.3356998623304792
Validation loss: 2.3092138360138414

Epoch: 6| Step: 4
Training loss: 0.5992691615657297
Validation loss: 2.307702053410766

Epoch: 6| Step: 5
Training loss: 0.7741185282210783
Validation loss: 2.263222871246576

Epoch: 6| Step: 6
Training loss: 0.4162920897342346
Validation loss: 2.296650035690988

Epoch: 6| Step: 7
Training loss: 0.4251783810049386
Validation loss: 2.283278697822557

Epoch: 6| Step: 8
Training loss: 0.5954277027229434
Validation loss: 2.282663363484429

Epoch: 6| Step: 9
Training loss: 0.3303759433301317
Validation loss: 2.2428161824772825

Epoch: 6| Step: 10
Training loss: 0.48289174969561777
Validation loss: 2.2624867952122703

Epoch: 6| Step: 11
Training loss: 0.677761110333622
Validation loss: 2.2069468445881446

Epoch: 6| Step: 12
Training loss: 0.490704117609826
Validation loss: 2.2629401412083654

Epoch: 6| Step: 13
Training loss: 0.6400719325425945
Validation loss: 2.285867470103364

Epoch: 317| Step: 0
Training loss: 0.37490817773706037
Validation loss: 2.27848580009686

Epoch: 6| Step: 1
Training loss: 0.7441282096087409
Validation loss: 2.3025096171411183

Epoch: 6| Step: 2
Training loss: 0.38923242297633837
Validation loss: 2.2809737472722778

Epoch: 6| Step: 3
Training loss: 0.30946580584940975
Validation loss: 2.278851306470106

Epoch: 6| Step: 4
Training loss: 0.6565283684480953
Validation loss: 2.2822035750337077

Epoch: 6| Step: 5
Training loss: 0.43809259675772994
Validation loss: 2.325132743132556

Epoch: 6| Step: 6
Training loss: 0.4271023753813557
Validation loss: 2.316300025652384

Epoch: 6| Step: 7
Training loss: 0.6944931002631858
Validation loss: 2.3332684598714506

Epoch: 6| Step: 8
Training loss: 0.5918897801359441
Validation loss: 2.3479282268768014

Epoch: 6| Step: 9
Training loss: 0.5651187601856664
Validation loss: 2.3123195281775004

Epoch: 6| Step: 10
Training loss: 0.7442809846122151
Validation loss: 2.30733185642408

Epoch: 6| Step: 11
Training loss: 0.3830609196751517
Validation loss: 2.2751434604577625

Epoch: 6| Step: 12
Training loss: 0.4275686909885792
Validation loss: 2.2733681637223615

Epoch: 6| Step: 13
Training loss: 0.2621078729941799
Validation loss: 2.252947972568739

Epoch: 318| Step: 0
Training loss: 0.6423241713501779
Validation loss: 2.264393133161307

Epoch: 6| Step: 1
Training loss: 0.26534239377034713
Validation loss: 2.283293879004702

Epoch: 6| Step: 2
Training loss: 0.543138244300612
Validation loss: 2.245428932248129

Epoch: 6| Step: 3
Training loss: 0.4128994892940841
Validation loss: 2.285976863117851

Epoch: 6| Step: 4
Training loss: 0.3129897809401839
Validation loss: 2.2583370116835453

Epoch: 6| Step: 5
Training loss: 0.5656058081642965
Validation loss: 2.27467024711149

Epoch: 6| Step: 6
Training loss: 0.44614207645674875
Validation loss: 2.2812855720977487

Epoch: 6| Step: 7
Training loss: 0.5853152213209021
Validation loss: 2.2941823543770017

Epoch: 6| Step: 8
Training loss: 0.7962781503513067
Validation loss: 2.3085609695919285

Epoch: 6| Step: 9
Training loss: 0.7312145811453054
Validation loss: 2.3005608189244926

Epoch: 6| Step: 10
Training loss: 0.5726222987083168
Validation loss: 2.29963424925767

Epoch: 6| Step: 11
Training loss: 0.38771278092164807
Validation loss: 2.295531741140196

Epoch: 6| Step: 12
Training loss: 0.629748378868182
Validation loss: 2.2953234000952287

Epoch: 6| Step: 13
Training loss: 0.2216795194515986
Validation loss: 2.2947245477178586

Epoch: 319| Step: 0
Training loss: 0.5180460991506299
Validation loss: 2.338712692630084

Epoch: 6| Step: 1
Training loss: 0.5446719344996003
Validation loss: 2.315361340779104

Epoch: 6| Step: 2
Training loss: 0.26328504938842306
Validation loss: 2.3065588512896644

Epoch: 6| Step: 3
Training loss: 0.618789043543307
Validation loss: 2.319539879218015

Epoch: 6| Step: 4
Training loss: 0.4748018918255216
Validation loss: 2.284070678697372

Epoch: 6| Step: 5
Training loss: 0.5161297668307119
Validation loss: 2.253638346374492

Epoch: 6| Step: 6
Training loss: 0.49861966275284725
Validation loss: 2.277296030429725

Epoch: 6| Step: 7
Training loss: 0.5213705217182384
Validation loss: 2.299219754663977

Epoch: 6| Step: 8
Training loss: 0.4887323355836318
Validation loss: 2.2711311902132274

Epoch: 6| Step: 9
Training loss: 0.4127401613706815
Validation loss: 2.2495917812457336

Epoch: 6| Step: 10
Training loss: 0.49271812294824374
Validation loss: 2.2434245961522987

Epoch: 6| Step: 11
Training loss: 0.5676083403786435
Validation loss: 2.2566511381553864

Epoch: 6| Step: 12
Training loss: 0.6754680635482756
Validation loss: 2.277456315930771

Epoch: 6| Step: 13
Training loss: 0.5804442717575214
Validation loss: 2.2879711443032837

Epoch: 320| Step: 0
Training loss: 0.206703187020757
Validation loss: 2.2755570759706623

Epoch: 6| Step: 1
Training loss: 0.26350162802560645
Validation loss: 2.269183650684545

Epoch: 6| Step: 2
Training loss: 0.5391969098576339
Validation loss: 2.2902554500813674

Epoch: 6| Step: 3
Training loss: 0.3061941261314266
Validation loss: 2.3093834018544728

Epoch: 6| Step: 4
Training loss: 0.6163010810898276
Validation loss: 2.2613043412790157

Epoch: 6| Step: 5
Training loss: 0.6660829437331399
Validation loss: 2.2964670392252353

Epoch: 6| Step: 6
Training loss: 0.6108476011666443
Validation loss: 2.3010331320026522

Epoch: 6| Step: 7
Training loss: 0.23758916718181067
Validation loss: 2.31111322941353

Epoch: 6| Step: 8
Training loss: 0.5067723405220329
Validation loss: 2.297728089263982

Epoch: 6| Step: 9
Training loss: 0.5696948639293831
Validation loss: 2.3050764342105645

Epoch: 6| Step: 10
Training loss: 0.4560452936091285
Validation loss: 2.2936298906799286

Epoch: 6| Step: 11
Training loss: 0.36009949756244036
Validation loss: 2.26424870383594

Epoch: 6| Step: 12
Training loss: 0.5782693218824349
Validation loss: 2.2748908305081668

Epoch: 6| Step: 13
Training loss: 0.9812714835566803
Validation loss: 2.2537437987946234

Epoch: 321| Step: 0
Training loss: 0.4758246290854942
Validation loss: 2.2247123925969383

Epoch: 6| Step: 1
Training loss: 0.5483682681127637
Validation loss: 2.2270284772826705

Epoch: 6| Step: 2
Training loss: 0.23926021029769468
Validation loss: 2.2392504704895106

Epoch: 6| Step: 3
Training loss: 0.43204432807429083
Validation loss: 2.223751348588812

Epoch: 6| Step: 4
Training loss: 0.6615435678028226
Validation loss: 2.251878881383698

Epoch: 6| Step: 5
Training loss: 0.5018369785219947
Validation loss: 2.2546720996666987

Epoch: 6| Step: 6
Training loss: 0.4369491276591435
Validation loss: 2.29095189944711

Epoch: 6| Step: 7
Training loss: 0.6915025159123923
Validation loss: 2.278446395842052

Epoch: 6| Step: 8
Training loss: 0.5740012970321569
Validation loss: 2.2756284201223362

Epoch: 6| Step: 9
Training loss: 0.2479383877179866
Validation loss: 2.2816263535425096

Epoch: 6| Step: 10
Training loss: 0.16820633519746372
Validation loss: 2.310343678504925

Epoch: 6| Step: 11
Training loss: 0.6403299443040902
Validation loss: 2.283875073624532

Epoch: 6| Step: 12
Training loss: 0.42523865730726734
Validation loss: 2.280986966263509

Epoch: 6| Step: 13
Training loss: 0.747307553986959
Validation loss: 2.3021067496238072

Epoch: 322| Step: 0
Training loss: 0.23076795294336044
Validation loss: 2.2518122810717864

Epoch: 6| Step: 1
Training loss: 0.30976027908618897
Validation loss: 2.2826384711407885

Epoch: 6| Step: 2
Training loss: 0.39273510351771757
Validation loss: 2.276952102494804

Epoch: 6| Step: 3
Training loss: 0.33747986539191455
Validation loss: 2.2663235061076956

Epoch: 6| Step: 4
Training loss: 0.6175045937201254
Validation loss: 2.254556964278703

Epoch: 6| Step: 5
Training loss: 0.5530135457309634
Validation loss: 2.247319183128066

Epoch: 6| Step: 6
Training loss: 0.6223278859822428
Validation loss: 2.243174240288717

Epoch: 6| Step: 7
Training loss: 0.49678298050127356
Validation loss: 2.277868386582455

Epoch: 6| Step: 8
Training loss: 0.46402858134942326
Validation loss: 2.251482776348722

Epoch: 6| Step: 9
Training loss: 0.3469748087074604
Validation loss: 2.2686890767524965

Epoch: 6| Step: 10
Training loss: 0.5379294498479921
Validation loss: 2.3045424727020816

Epoch: 6| Step: 11
Training loss: 0.5023333819848543
Validation loss: 2.2870386994979937

Epoch: 6| Step: 12
Training loss: 0.8053161239690512
Validation loss: 2.2993825897467133

Epoch: 6| Step: 13
Training loss: 0.2743395503959245
Validation loss: 2.32081051307482

Epoch: 323| Step: 0
Training loss: 0.5292985641621455
Validation loss: 2.2801622530216954

Epoch: 6| Step: 1
Training loss: 0.7279466140371721
Validation loss: 2.331653358987191

Epoch: 6| Step: 2
Training loss: 0.49264775811791295
Validation loss: 2.3058557573973486

Epoch: 6| Step: 3
Training loss: 0.647977780917788
Validation loss: 2.2976506315779375

Epoch: 6| Step: 4
Training loss: 0.5103194929252326
Validation loss: 2.3004533469378328

Epoch: 6| Step: 5
Training loss: 0.3618099196620913
Validation loss: 2.2649035964747664

Epoch: 6| Step: 6
Training loss: 0.5337422199262938
Validation loss: 2.30071593687622

Epoch: 6| Step: 7
Training loss: 0.24296423733068456
Validation loss: 2.274714450817205

Epoch: 6| Step: 8
Training loss: 0.4492074384509102
Validation loss: 2.245423760842584

Epoch: 6| Step: 9
Training loss: 0.3788363992074969
Validation loss: 2.2636415698485672

Epoch: 6| Step: 10
Training loss: 0.25606285623400404
Validation loss: 2.253577636448916

Epoch: 6| Step: 11
Training loss: 0.5312783850772176
Validation loss: 2.2612010594211154

Epoch: 6| Step: 12
Training loss: 0.4848939515216286
Validation loss: 2.271831267398991

Epoch: 6| Step: 13
Training loss: 0.5468052683378333
Validation loss: 2.304476550309633

Epoch: 324| Step: 0
Training loss: 0.38112457041279874
Validation loss: 2.3077644060698836

Epoch: 6| Step: 1
Training loss: 0.3805326576529543
Validation loss: 2.2778052206142876

Epoch: 6| Step: 2
Training loss: 0.7136154879138022
Validation loss: 2.3290273807849413

Epoch: 6| Step: 3
Training loss: 0.562827756548902
Validation loss: 2.348748005976928

Epoch: 6| Step: 4
Training loss: 0.37488935745693375
Validation loss: 2.3519896437966694

Epoch: 6| Step: 5
Training loss: 0.5269407074343931
Validation loss: 2.332072415195265

Epoch: 6| Step: 6
Training loss: 0.3825488837177352
Validation loss: 2.3459392886140225

Epoch: 6| Step: 7
Training loss: 0.5249838974163522
Validation loss: 2.314468480520425

Epoch: 6| Step: 8
Training loss: 0.2280307009856202
Validation loss: 2.3291324270066873

Epoch: 6| Step: 9
Training loss: 0.5684758751882806
Validation loss: 2.2469043743061765

Epoch: 6| Step: 10
Training loss: 0.5910030366170879
Validation loss: 2.264070413581408

Epoch: 6| Step: 11
Training loss: 0.3987045141364002
Validation loss: 2.2762223543667366

Epoch: 6| Step: 12
Training loss: 0.44405074136884953
Validation loss: 2.255189234283662

Epoch: 6| Step: 13
Training loss: 0.6228743646179425
Validation loss: 2.254343026309488

Epoch: 325| Step: 0
Training loss: 0.3797246608680629
Validation loss: 2.248630749668344

Epoch: 6| Step: 1
Training loss: 0.8503755118657155
Validation loss: 2.2366896479023097

Epoch: 6| Step: 2
Training loss: 0.43208486903747534
Validation loss: 2.2309804645866205

Epoch: 6| Step: 3
Training loss: 0.5153373436060306
Validation loss: 2.233292165599336

Epoch: 6| Step: 4
Training loss: 0.4101425168599324
Validation loss: 2.220328205737184

Epoch: 6| Step: 5
Training loss: 0.4983493709083353
Validation loss: 2.2389889209923894

Epoch: 6| Step: 6
Training loss: 0.38989361002671447
Validation loss: 2.267625347007288

Epoch: 6| Step: 7
Training loss: 0.6578715137097214
Validation loss: 2.309492261550668

Epoch: 6| Step: 8
Training loss: 0.38426877391522196
Validation loss: 2.338538587646591

Epoch: 6| Step: 9
Training loss: 0.4663748329610124
Validation loss: 2.312248517845816

Epoch: 6| Step: 10
Training loss: 0.4959862359755933
Validation loss: 2.3312281367962475

Epoch: 6| Step: 11
Training loss: 0.34188991915074385
Validation loss: 2.355981257209592

Epoch: 6| Step: 12
Training loss: 0.4257919240191044
Validation loss: 2.384898659902054

Epoch: 6| Step: 13
Training loss: 0.4390660255263434
Validation loss: 2.3798244699303504

Epoch: 326| Step: 0
Training loss: 0.423679272929829
Validation loss: 2.347742142965082

Epoch: 6| Step: 1
Training loss: 0.273998420862186
Validation loss: 2.337811743620932

Epoch: 6| Step: 2
Training loss: 0.5635178152549759
Validation loss: 2.3380055157691912

Epoch: 6| Step: 3
Training loss: 0.30428365695828413
Validation loss: 2.315080524900013

Epoch: 6| Step: 4
Training loss: 0.32231962734091985
Validation loss: 2.3268814900824832

Epoch: 6| Step: 5
Training loss: 0.6925335546482466
Validation loss: 2.352769055859466

Epoch: 6| Step: 6
Training loss: 0.7242343477052978
Validation loss: 2.2977350714821116

Epoch: 6| Step: 7
Training loss: 0.623825662759736
Validation loss: 2.269177118383166

Epoch: 6| Step: 8
Training loss: 0.5463232799584123
Validation loss: 2.231599823850398

Epoch: 6| Step: 9
Training loss: 0.3995778463833528
Validation loss: 2.2537479017646946

Epoch: 6| Step: 10
Training loss: 0.3419468577880219
Validation loss: 2.243464628100606

Epoch: 6| Step: 11
Training loss: 0.681850390143135
Validation loss: 2.2662161933051546

Epoch: 6| Step: 12
Training loss: 0.47833371499951294
Validation loss: 2.2381620807217772

Epoch: 6| Step: 13
Training loss: 0.6971742158698846
Validation loss: 2.279576506849844

Epoch: 327| Step: 0
Training loss: 0.41250388981690184
Validation loss: 2.29323537464699

Epoch: 6| Step: 1
Training loss: 0.455105121777732
Validation loss: 2.3089746422279327

Epoch: 6| Step: 2
Training loss: 0.4055109637856117
Validation loss: 2.280439329716907

Epoch: 6| Step: 3
Training loss: 0.6452608314131224
Validation loss: 2.3179436842878305

Epoch: 6| Step: 4
Training loss: 0.3231706568929188
Validation loss: 2.2719637663180694

Epoch: 6| Step: 5
Training loss: 0.43448248843735093
Validation loss: 2.2410908514341403

Epoch: 6| Step: 6
Training loss: 0.47717250805420613
Validation loss: 2.2635020198041347

Epoch: 6| Step: 7
Training loss: 0.5805927652418106
Validation loss: 2.2526476090795864

Epoch: 6| Step: 8
Training loss: 0.5194567576760568
Validation loss: 2.2074674790302966

Epoch: 6| Step: 9
Training loss: 0.5838875068267491
Validation loss: 2.2398684019500075

Epoch: 6| Step: 10
Training loss: 0.45347422263772136
Validation loss: 2.2135089122416636

Epoch: 6| Step: 11
Training loss: 0.4728779863792138
Validation loss: 2.258822118037772

Epoch: 6| Step: 12
Training loss: 0.7577170479033583
Validation loss: 2.2681722961042317

Epoch: 6| Step: 13
Training loss: 0.36608986442610714
Validation loss: 2.2851999033784898

Epoch: 328| Step: 0
Training loss: 0.47434385745286495
Validation loss: 2.295903946884698

Epoch: 6| Step: 1
Training loss: 0.35094229775577507
Validation loss: 2.3180181792321584

Epoch: 6| Step: 2
Training loss: 0.5072100660530104
Validation loss: 2.3141341295961944

Epoch: 6| Step: 3
Training loss: 0.7670916309008065
Validation loss: 2.3034603065657397

Epoch: 6| Step: 4
Training loss: 0.5208671431693835
Validation loss: 2.31985265559353

Epoch: 6| Step: 5
Training loss: 0.5678700178928303
Validation loss: 2.282648561085761

Epoch: 6| Step: 6
Training loss: 0.5725029983608572
Validation loss: 2.3156131851195787

Epoch: 6| Step: 7
Training loss: 0.2135869807724338
Validation loss: 2.2694407877766225

Epoch: 6| Step: 8
Training loss: 0.32908003196129365
Validation loss: 2.2876692664625606

Epoch: 6| Step: 9
Training loss: 0.4708417949366285
Validation loss: 2.2729962502208303

Epoch: 6| Step: 10
Training loss: 0.5151284745989452
Validation loss: 2.255030990918592

Epoch: 6| Step: 11
Training loss: 0.4423573467680683
Validation loss: 2.2675938375144744

Epoch: 6| Step: 12
Training loss: 0.4122412773317613
Validation loss: 2.24715326274136

Epoch: 6| Step: 13
Training loss: 0.475055422184768
Validation loss: 2.2213582992635486

Epoch: 329| Step: 0
Training loss: 0.38039277667433813
Validation loss: 2.266252620160143

Epoch: 6| Step: 1
Training loss: 0.5706122407604387
Validation loss: 2.2843171719073023

Epoch: 6| Step: 2
Training loss: 0.7202810069582792
Validation loss: 2.321159307984268

Epoch: 6| Step: 3
Training loss: 0.33846211476866717
Validation loss: 2.353005600350933

Epoch: 6| Step: 4
Training loss: 0.6161640953481174
Validation loss: 2.3168680492668328

Epoch: 6| Step: 5
Training loss: 0.4055750999556844
Validation loss: 2.3483089350343667

Epoch: 6| Step: 6
Training loss: 0.5990631150076848
Validation loss: 2.330794646089855

Epoch: 6| Step: 7
Training loss: 0.3933491134441544
Validation loss: 2.337361180292479

Epoch: 6| Step: 8
Training loss: 0.518984542816792
Validation loss: 2.2733510358312015

Epoch: 6| Step: 9
Training loss: 0.38323142037641006
Validation loss: 2.2854036682266585

Epoch: 6| Step: 10
Training loss: 0.4990508786773055
Validation loss: 2.270656184970829

Epoch: 6| Step: 11
Training loss: 0.18532299790391235
Validation loss: 2.2422976977518734

Epoch: 6| Step: 12
Training loss: 0.4672355346481597
Validation loss: 2.287898213479951

Epoch: 6| Step: 13
Training loss: 0.6258186224399178
Validation loss: 2.2837306666837125

Epoch: 330| Step: 0
Training loss: 0.5859285989721054
Validation loss: 2.280433523282784

Epoch: 6| Step: 1
Training loss: 0.4320859553656974
Validation loss: 2.3141874743202244

Epoch: 6| Step: 2
Training loss: 0.6295955505633148
Validation loss: 2.322382477362637

Epoch: 6| Step: 3
Training loss: 0.3466439886920797
Validation loss: 2.2875001621005326

Epoch: 6| Step: 4
Training loss: 0.5610884598790943
Validation loss: 2.2794382247794696

Epoch: 6| Step: 5
Training loss: 0.4385940632209162
Validation loss: 2.305431059004539

Epoch: 6| Step: 6
Training loss: 0.4827500281301813
Validation loss: 2.289383200492742

Epoch: 6| Step: 7
Training loss: 0.4194389582725007
Validation loss: 2.3140895621820787

Epoch: 6| Step: 8
Training loss: 0.6067496993241352
Validation loss: 2.3096625783750486

Epoch: 6| Step: 9
Training loss: 0.5572516049635353
Validation loss: 2.294640549779623

Epoch: 6| Step: 10
Training loss: 0.2616654242093258
Validation loss: 2.2572860305514144

Epoch: 6| Step: 11
Training loss: 0.4870908034638054
Validation loss: 2.250055759062615

Epoch: 6| Step: 12
Training loss: 0.4502484172356897
Validation loss: 2.2690903529050312

Epoch: 6| Step: 13
Training loss: 0.45855397274495535
Validation loss: 2.2154090005101605

Epoch: 331| Step: 0
Training loss: 0.47172059697196783
Validation loss: 2.216887062142374

Epoch: 6| Step: 1
Training loss: 0.5031891681196684
Validation loss: 2.212083819168609

Epoch: 6| Step: 2
Training loss: 0.5101074592661157
Validation loss: 2.1782562653205937

Epoch: 6| Step: 3
Training loss: 0.5161546241275968
Validation loss: 2.2060247796726884

Epoch: 6| Step: 4
Training loss: 0.44508864816362265
Validation loss: 2.220162638261137

Epoch: 6| Step: 5
Training loss: 0.3970359573475525
Validation loss: 2.234709663206009

Epoch: 6| Step: 6
Training loss: 0.5557366777917666
Validation loss: 2.2722093530574576

Epoch: 6| Step: 7
Training loss: 0.4449350028575468
Validation loss: 2.3171413054776773

Epoch: 6| Step: 8
Training loss: 0.40686617485706617
Validation loss: 2.296936124750492

Epoch: 6| Step: 9
Training loss: 0.5360882572080578
Validation loss: 2.3085603888040525

Epoch: 6| Step: 10
Training loss: 0.39777953854133563
Validation loss: 2.351318935461794

Epoch: 6| Step: 11
Training loss: 0.5920426012784823
Validation loss: 2.329972538262274

Epoch: 6| Step: 12
Training loss: 0.2994669773551308
Validation loss: 2.333837356018209

Epoch: 6| Step: 13
Training loss: 0.4072081563984265
Validation loss: 2.3032677277788296

Epoch: 332| Step: 0
Training loss: 0.719205007411447
Validation loss: 2.3222328361109636

Epoch: 6| Step: 1
Training loss: 0.4582141988705556
Validation loss: 2.29124972744725

Epoch: 6| Step: 2
Training loss: 0.3935806228005366
Validation loss: 2.328416636358218

Epoch: 6| Step: 3
Training loss: 0.4171285651937409
Validation loss: 2.270161033503149

Epoch: 6| Step: 4
Training loss: 0.5448489123210078
Validation loss: 2.287866508646173

Epoch: 6| Step: 5
Training loss: 0.30317064659303494
Validation loss: 2.300002361401616

Epoch: 6| Step: 6
Training loss: 0.3976873554287626
Validation loss: 2.2728941064719956

Epoch: 6| Step: 7
Training loss: 0.47226942011946677
Validation loss: 2.2874957475914655

Epoch: 6| Step: 8
Training loss: 0.44790004728963867
Validation loss: 2.3007521094477177

Epoch: 6| Step: 9
Training loss: 0.5019449908714414
Validation loss: 2.3014950980471545

Epoch: 6| Step: 10
Training loss: 0.5201557392955506
Validation loss: 2.3225595479409233

Epoch: 6| Step: 11
Training loss: 0.2793553697913533
Validation loss: 2.281489677273182

Epoch: 6| Step: 12
Training loss: 0.44892093903952945
Validation loss: 2.287205275689936

Epoch: 6| Step: 13
Training loss: 0.6136983922793418
Validation loss: 2.291616800237393

Epoch: 333| Step: 0
Training loss: 0.46022055521471295
Validation loss: 2.2875227825434084

Epoch: 6| Step: 1
Training loss: 0.3051214917530939
Validation loss: 2.2708778621586068

Epoch: 6| Step: 2
Training loss: 0.3872100329673609
Validation loss: 2.28298427228665

Epoch: 6| Step: 3
Training loss: 0.6389605135321282
Validation loss: 2.258868532303619

Epoch: 6| Step: 4
Training loss: 0.2697981190492882
Validation loss: 2.2971644299766023

Epoch: 6| Step: 5
Training loss: 0.41324899039171126
Validation loss: 2.24523145076792

Epoch: 6| Step: 6
Training loss: 0.36540436486198596
Validation loss: 2.270765171644319

Epoch: 6| Step: 7
Training loss: 0.4145683401677843
Validation loss: 2.2866009965234473

Epoch: 6| Step: 8
Training loss: 0.45538341121879317
Validation loss: 2.271844154788673

Epoch: 6| Step: 9
Training loss: 0.47365615629892516
Validation loss: 2.256248961749449

Epoch: 6| Step: 10
Training loss: 0.6424570172400695
Validation loss: 2.287339151968507

Epoch: 6| Step: 11
Training loss: 0.7708595159740634
Validation loss: 2.2836966947478317

Epoch: 6| Step: 12
Training loss: 0.5327500874498243
Validation loss: 2.259801830246653

Epoch: 6| Step: 13
Training loss: 0.5652931061597467
Validation loss: 2.319645273301935

Epoch: 334| Step: 0
Training loss: 0.6456781529041821
Validation loss: 2.302002621736736

Epoch: 6| Step: 1
Training loss: 0.4942720562591806
Validation loss: 2.3309168784650716

Epoch: 6| Step: 2
Training loss: 0.4699501726694659
Validation loss: 2.3455268031495184

Epoch: 6| Step: 3
Training loss: 0.5641154827056394
Validation loss: 2.3382023796500473

Epoch: 6| Step: 4
Training loss: 0.6402970614417541
Validation loss: 2.3130096557380213

Epoch: 6| Step: 5
Training loss: 0.41651081110786264
Validation loss: 2.2913451169605894

Epoch: 6| Step: 6
Training loss: 0.437477060125296
Validation loss: 2.2816030229449162

Epoch: 6| Step: 7
Training loss: 0.4087360681265203
Validation loss: 2.2949962721726074

Epoch: 6| Step: 8
Training loss: 0.6258917169305939
Validation loss: 2.2543456134397655

Epoch: 6| Step: 9
Training loss: 0.35600629970516506
Validation loss: 2.2488396169320217

Epoch: 6| Step: 10
Training loss: 0.3934158004400253
Validation loss: 2.245225141085213

Epoch: 6| Step: 11
Training loss: 0.428739455541064
Validation loss: 2.219875531454845

Epoch: 6| Step: 12
Training loss: 0.4201593126984769
Validation loss: 2.2286573577082818

Epoch: 6| Step: 13
Training loss: 0.336771970999287
Validation loss: 2.1868707563412686

Epoch: 335| Step: 0
Training loss: 0.45394136618000247
Validation loss: 2.2121106840605247

Epoch: 6| Step: 1
Training loss: 0.5348049040720028
Validation loss: 2.2127855161520507

Epoch: 6| Step: 2
Training loss: 0.5143873214636456
Validation loss: 2.250704055273731

Epoch: 6| Step: 3
Training loss: 0.3947908661497886
Validation loss: 2.257928895723066

Epoch: 6| Step: 4
Training loss: 0.5401822222886908
Validation loss: 2.2511684751702656

Epoch: 6| Step: 5
Training loss: 0.5501479708420497
Validation loss: 2.246410694989166

Epoch: 6| Step: 6
Training loss: 0.4078453174993826
Validation loss: 2.288633160210061

Epoch: 6| Step: 7
Training loss: 0.40256694047501657
Validation loss: 2.2541775165818607

Epoch: 6| Step: 8
Training loss: 0.5640966220161505
Validation loss: 2.276497723080281

Epoch: 6| Step: 9
Training loss: 0.4482049365553103
Validation loss: 2.273845859629681

Epoch: 6| Step: 10
Training loss: 0.6547941680902499
Validation loss: 2.2812254068979385

Epoch: 6| Step: 11
Training loss: 0.603737034352404
Validation loss: 2.2957916897243265

Epoch: 6| Step: 12
Training loss: 0.36187068310733883
Validation loss: 2.2694013868817318

Epoch: 6| Step: 13
Training loss: 0.29231452373760836
Validation loss: 2.316932784251761

Epoch: 336| Step: 0
Training loss: 0.6099822124639372
Validation loss: 2.2797584079419213

Epoch: 6| Step: 1
Training loss: 0.3786972295238711
Validation loss: 2.2814630905332605

Epoch: 6| Step: 2
Training loss: 0.5580254177778454
Validation loss: 2.2506601750609923

Epoch: 6| Step: 3
Training loss: 0.4067990920458988
Validation loss: 2.2229712074765957

Epoch: 6| Step: 4
Training loss: 0.46785491679711366
Validation loss: 2.232374445771753

Epoch: 6| Step: 5
Training loss: 0.5823282341800258
Validation loss: 2.2701190861215355

Epoch: 6| Step: 6
Training loss: 0.39229919241346345
Validation loss: 2.235980220761569

Epoch: 6| Step: 7
Training loss: 0.45348238827323717
Validation loss: 2.2725275866842343

Epoch: 6| Step: 8
Training loss: 0.4755354586215284
Validation loss: 2.2487266496842104

Epoch: 6| Step: 9
Training loss: 0.5417846282256934
Validation loss: 2.2568203772769895

Epoch: 6| Step: 10
Training loss: 0.5456459403198195
Validation loss: 2.248123466564181

Epoch: 6| Step: 11
Training loss: 0.22342177182307302
Validation loss: 2.298189405600966

Epoch: 6| Step: 12
Training loss: 0.505781071910055
Validation loss: 2.3193844512027906

Epoch: 6| Step: 13
Training loss: 0.715722799489812
Validation loss: 2.3060672179240425

Epoch: 337| Step: 0
Training loss: 0.39338392618608164
Validation loss: 2.309626684658795

Epoch: 6| Step: 1
Training loss: 0.6013680180850214
Validation loss: 2.3111081739256267

Epoch: 6| Step: 2
Training loss: 0.4953398796239825
Validation loss: 2.2861315060832523

Epoch: 6| Step: 3
Training loss: 0.35536571728192173
Validation loss: 2.2871344565941967

Epoch: 6| Step: 4
Training loss: 0.6380955139880069
Validation loss: 2.264275336317454

Epoch: 6| Step: 5
Training loss: 0.4872727622542634
Validation loss: 2.2981509909301456

Epoch: 6| Step: 6
Training loss: 0.554229627942905
Validation loss: 2.299580769275512

Epoch: 6| Step: 7
Training loss: 0.4495622731185292
Validation loss: 2.2935618606379777

Epoch: 6| Step: 8
Training loss: 0.6052295335305432
Validation loss: 2.2936124765047428

Epoch: 6| Step: 9
Training loss: 0.4943168536978551
Validation loss: 2.299733076706539

Epoch: 6| Step: 10
Training loss: 0.4531215799136824
Validation loss: 2.2690335069400827

Epoch: 6| Step: 11
Training loss: 0.4585667922302739
Validation loss: 2.284794713889083

Epoch: 6| Step: 12
Training loss: 0.43686046859957434
Validation loss: 2.286773512943191

Epoch: 6| Step: 13
Training loss: 0.5495476130179897
Validation loss: 2.255456233633398

Epoch: 338| Step: 0
Training loss: 0.3264662162621825
Validation loss: 2.2340557594027737

Epoch: 6| Step: 1
Training loss: 0.688739764177311
Validation loss: 2.2497609363558917

Epoch: 6| Step: 2
Training loss: 0.6674875232516292
Validation loss: 2.2534802955769213

Epoch: 6| Step: 3
Training loss: 0.5287903899690217
Validation loss: 2.26787221971314

Epoch: 6| Step: 4
Training loss: 0.5535488530578943
Validation loss: 2.2639698827353083

Epoch: 6| Step: 5
Training loss: 0.3353416792446861
Validation loss: 2.2438953822954377

Epoch: 6| Step: 6
Training loss: 0.44428286392660404
Validation loss: 2.2527165881988345

Epoch: 6| Step: 7
Training loss: 0.48732129147055453
Validation loss: 2.277615698129192

Epoch: 6| Step: 8
Training loss: 0.3855707101304877
Validation loss: 2.283081075285447

Epoch: 6| Step: 9
Training loss: 0.4517974809711475
Validation loss: 2.2976981931252536

Epoch: 6| Step: 10
Training loss: 0.3022361470251235
Validation loss: 2.35748810790672

Epoch: 6| Step: 11
Training loss: 0.650901273212896
Validation loss: 2.3290354051251407

Epoch: 6| Step: 12
Training loss: 0.6678793105540178
Validation loss: 2.361338849297239

Epoch: 6| Step: 13
Training loss: 0.6406505858731626
Validation loss: 2.3411099490702845

Epoch: 339| Step: 0
Training loss: 0.5327642681855137
Validation loss: 2.3005269790680956

Epoch: 6| Step: 1
Training loss: 0.6348640717679137
Validation loss: 2.225955031549615

Epoch: 6| Step: 2
Training loss: 0.6176221258810338
Validation loss: 2.2492882390113174

Epoch: 6| Step: 3
Training loss: 0.383080213707622
Validation loss: 2.2328142164394493

Epoch: 6| Step: 4
Training loss: 0.605633374875705
Validation loss: 2.2106486187245444

Epoch: 6| Step: 5
Training loss: 0.5978119591223447
Validation loss: 2.2440932572388275

Epoch: 6| Step: 6
Training loss: 0.3015103853486748
Validation loss: 2.2658156085995502

Epoch: 6| Step: 7
Training loss: 0.6783338638212987
Validation loss: 2.3133815575030527

Epoch: 6| Step: 8
Training loss: 0.537086625050869
Validation loss: 2.3095757981511214

Epoch: 6| Step: 9
Training loss: 0.4812877931246053
Validation loss: 2.3562522258211094

Epoch: 6| Step: 10
Training loss: 0.5359846789444229
Validation loss: 2.397675108494709

Epoch: 6| Step: 11
Training loss: 0.6712257663962689
Validation loss: 2.380650052258652

Epoch: 6| Step: 12
Training loss: 0.3828127335528226
Validation loss: 2.3898711340613747

Epoch: 6| Step: 13
Training loss: 0.5601734153426534
Validation loss: 2.414507586365112

Epoch: 340| Step: 0
Training loss: 0.5240842894071639
Validation loss: 2.3962914505479693

Epoch: 6| Step: 1
Training loss: 0.6010649964704272
Validation loss: 2.3955741037636944

Epoch: 6| Step: 2
Training loss: 0.7949809959227494
Validation loss: 2.3095821484808763

Epoch: 6| Step: 3
Training loss: 0.5240673432100772
Validation loss: 2.3158927425357767

Epoch: 6| Step: 4
Training loss: 0.39774160761823796
Validation loss: 2.2895348325569764

Epoch: 6| Step: 5
Training loss: 0.4448624059572463
Validation loss: 2.243659788474177

Epoch: 6| Step: 6
Training loss: 0.518867987118287
Validation loss: 2.233543090822001

Epoch: 6| Step: 7
Training loss: 0.5848814539332131
Validation loss: 2.212688957494164

Epoch: 6| Step: 8
Training loss: 0.49438179674552235
Validation loss: 2.207371669705172

Epoch: 6| Step: 9
Training loss: 0.3837933333841165
Validation loss: 2.2347207748783076

Epoch: 6| Step: 10
Training loss: 0.720371986961385
Validation loss: 2.2375994334306375

Epoch: 6| Step: 11
Training loss: 0.4840447007238204
Validation loss: 2.2624278162009355

Epoch: 6| Step: 12
Training loss: 0.6364844891740147
Validation loss: 2.2800359649156796

Epoch: 6| Step: 13
Training loss: 0.3944543631389344
Validation loss: 2.2602958478678987

Epoch: 341| Step: 0
Training loss: 0.5836731965146162
Validation loss: 2.281865280681218

Epoch: 6| Step: 1
Training loss: 0.5428187760081961
Validation loss: 2.3114308491196986

Epoch: 6| Step: 2
Training loss: 0.48303117768831977
Validation loss: 2.310281144118967

Epoch: 6| Step: 3
Training loss: 0.7000722949978607
Validation loss: 2.328621150685619

Epoch: 6| Step: 4
Training loss: 0.6208782901957061
Validation loss: 2.302029300341969

Epoch: 6| Step: 5
Training loss: 0.47098679917964553
Validation loss: 2.304321295563883

Epoch: 6| Step: 6
Training loss: 0.2955365627747507
Validation loss: 2.2783426325075404

Epoch: 6| Step: 7
Training loss: 0.448929735174187
Validation loss: 2.2509817934686174

Epoch: 6| Step: 8
Training loss: 0.44662646471536604
Validation loss: 2.259544444338003

Epoch: 6| Step: 9
Training loss: 0.5784055183921679
Validation loss: 2.2637178059140948

Epoch: 6| Step: 10
Training loss: 0.678306316271976
Validation loss: 2.2826450513982506

Epoch: 6| Step: 11
Training loss: 0.6070634821087851
Validation loss: 2.2731466634127817

Epoch: 6| Step: 12
Training loss: 0.4705046714212312
Validation loss: 2.281988571927322

Epoch: 6| Step: 13
Training loss: 0.5761845215524826
Validation loss: 2.2808805361208577

Epoch: 342| Step: 0
Training loss: 0.6700309909229196
Validation loss: 2.269241658774618

Epoch: 6| Step: 1
Training loss: 0.500623790725219
Validation loss: 2.3249768631218677

Epoch: 6| Step: 2
Training loss: 0.44723520633588393
Validation loss: 2.3504529682158672

Epoch: 6| Step: 3
Training loss: 0.5657221115375717
Validation loss: 2.3250599608075544

Epoch: 6| Step: 4
Training loss: 0.29289944146807323
Validation loss: 2.347988228927012

Epoch: 6| Step: 5
Training loss: 0.6157128789308464
Validation loss: 2.3304062258964566

Epoch: 6| Step: 6
Training loss: 0.5179008197687338
Validation loss: 2.3395792964911832

Epoch: 6| Step: 7
Training loss: 0.22306187808056188
Validation loss: 2.2841964221833

Epoch: 6| Step: 8
Training loss: 0.4714205012002276
Validation loss: 2.315148520027785

Epoch: 6| Step: 9
Training loss: 0.47505948422055244
Validation loss: 2.3317294944573703

Epoch: 6| Step: 10
Training loss: 0.5150080660308716
Validation loss: 2.331547511523223

Epoch: 6| Step: 11
Training loss: 0.4535750094756213
Validation loss: 2.3099734467901256

Epoch: 6| Step: 12
Training loss: 0.7316624888153829
Validation loss: 2.298118112602242

Epoch: 6| Step: 13
Training loss: 0.5069171054064129
Validation loss: 2.2786746702464376

Epoch: 343| Step: 0
Training loss: 0.4380978178334349
Validation loss: 2.273679917056237

Epoch: 6| Step: 1
Training loss: 0.5040508033355526
Validation loss: 2.248711468846675

Epoch: 6| Step: 2
Training loss: 0.5347918641234052
Validation loss: 2.2692125634052718

Epoch: 6| Step: 3
Training loss: 0.659261017479836
Validation loss: 2.243728888230067

Epoch: 6| Step: 4
Training loss: 0.3139277624655018
Validation loss: 2.267208056908186

Epoch: 6| Step: 5
Training loss: 0.5692316028401503
Validation loss: 2.2748962442690357

Epoch: 6| Step: 6
Training loss: 0.3529532158191336
Validation loss: 2.3287240954927286

Epoch: 6| Step: 7
Training loss: 0.40133659450393094
Validation loss: 2.323338150912699

Epoch: 6| Step: 8
Training loss: 0.7863839642728239
Validation loss: 2.3516299324913494

Epoch: 6| Step: 9
Training loss: 0.49809151243749183
Validation loss: 2.34513329487391

Epoch: 6| Step: 10
Training loss: 0.5057720565549598
Validation loss: 2.2842490715783805

Epoch: 6| Step: 11
Training loss: 0.42459924048828857
Validation loss: 2.27119460613758

Epoch: 6| Step: 12
Training loss: 0.4330734361502842
Validation loss: 2.276316610503043

Epoch: 6| Step: 13
Training loss: 0.5162314691981659
Validation loss: 2.265507722109883

Epoch: 344| Step: 0
Training loss: 0.34234544601264066
Validation loss: 2.248003218328579

Epoch: 6| Step: 1
Training loss: 0.35593999290765527
Validation loss: 2.2607710074653267

Epoch: 6| Step: 2
Training loss: 0.5406656613797219
Validation loss: 2.207194703634362

Epoch: 6| Step: 3
Training loss: 0.44484080044003355
Validation loss: 2.2042459332889575

Epoch: 6| Step: 4
Training loss: 0.5224124493781899
Validation loss: 2.222444090312583

Epoch: 6| Step: 5
Training loss: 0.5088673712566897
Validation loss: 2.2309508909109454

Epoch: 6| Step: 6
Training loss: 0.49832540465376624
Validation loss: 2.2743168751032226

Epoch: 6| Step: 7
Training loss: 0.4443059554831437
Validation loss: 2.2464618962188547

Epoch: 6| Step: 8
Training loss: 0.6709434127724755
Validation loss: 2.2723510320199116

Epoch: 6| Step: 9
Training loss: 0.47905977411359335
Validation loss: 2.2931952724743194

Epoch: 6| Step: 10
Training loss: 0.27046294132829063
Validation loss: 2.309191804962199

Epoch: 6| Step: 11
Training loss: 0.32841129528732593
Validation loss: 2.3048957809847987

Epoch: 6| Step: 12
Training loss: 0.6392706068176428
Validation loss: 2.3298858603689023

Epoch: 6| Step: 13
Training loss: 0.297810786223309
Validation loss: 2.3211184004264602

Epoch: 345| Step: 0
Training loss: 0.542977806399995
Validation loss: 2.269750541185647

Epoch: 6| Step: 1
Training loss: 0.1951321723079233
Validation loss: 2.280099979812477

Epoch: 6| Step: 2
Training loss: 0.4303052449774846
Validation loss: 2.299633591523427

Epoch: 6| Step: 3
Training loss: 0.4237652745208692
Validation loss: 2.300732074372683

Epoch: 6| Step: 4
Training loss: 0.38839217046542296
Validation loss: 2.284551028240078

Epoch: 6| Step: 5
Training loss: 0.3602802857409162
Validation loss: 2.3043364059796985

Epoch: 6| Step: 6
Training loss: 0.4672392500727115
Validation loss: 2.2679160681531196

Epoch: 6| Step: 7
Training loss: 0.44698776542958446
Validation loss: 2.287071631453185

Epoch: 6| Step: 8
Training loss: 0.5307768790598771
Validation loss: 2.279140244716401

Epoch: 6| Step: 9
Training loss: 0.366844707128685
Validation loss: 2.251506727059203

Epoch: 6| Step: 10
Training loss: 0.3915070303118839
Validation loss: 2.2717109994377824

Epoch: 6| Step: 11
Training loss: 0.300441004542811
Validation loss: 2.290020398542888

Epoch: 6| Step: 12
Training loss: 0.44178423268976935
Validation loss: 2.30944584399211

Epoch: 6| Step: 13
Training loss: 0.6716830844466024
Validation loss: 2.3120223679814726

Epoch: 346| Step: 0
Training loss: 0.6144478508491935
Validation loss: 2.314350688012706

Epoch: 6| Step: 1
Training loss: 0.4208266336392448
Validation loss: 2.302905458792828

Epoch: 6| Step: 2
Training loss: 0.403202325960198
Validation loss: 2.334617513698891

Epoch: 6| Step: 3
Training loss: 0.253824837176961
Validation loss: 2.3504073167685218

Epoch: 6| Step: 4
Training loss: 0.3957260848197549
Validation loss: 2.3457270699729267

Epoch: 6| Step: 5
Training loss: 0.3907599406817537
Validation loss: 2.3550339833593936

Epoch: 6| Step: 6
Training loss: 0.38846920230849274
Validation loss: 2.2993164502908305

Epoch: 6| Step: 7
Training loss: 0.3454037140215016
Validation loss: 2.257250112612407

Epoch: 6| Step: 8
Training loss: 0.5290953474218394
Validation loss: 2.298811562070623

Epoch: 6| Step: 9
Training loss: 0.525483927897463
Validation loss: 2.2360529107856943

Epoch: 6| Step: 10
Training loss: 0.38750343475050086
Validation loss: 2.237278369778084

Epoch: 6| Step: 11
Training loss: 0.37822695925919514
Validation loss: 2.229830585415907

Epoch: 6| Step: 12
Training loss: 0.6134153571774533
Validation loss: 2.2333300035902144

Epoch: 6| Step: 13
Training loss: 0.3607872290960456
Validation loss: 2.2333262344557308

Epoch: 347| Step: 0
Training loss: 0.39649666452387894
Validation loss: 2.224928570456095

Epoch: 6| Step: 1
Training loss: 0.32649959159054415
Validation loss: 2.269192477508818

Epoch: 6| Step: 2
Training loss: 0.6470823259789985
Validation loss: 2.2532584865673377

Epoch: 6| Step: 3
Training loss: 0.4804337651611397
Validation loss: 2.2748808357521817

Epoch: 6| Step: 4
Training loss: 0.30042281406204435
Validation loss: 2.2497700576005255

Epoch: 6| Step: 5
Training loss: 0.5235105150454711
Validation loss: 2.2695623790378243

Epoch: 6| Step: 6
Training loss: 0.2183128826073571
Validation loss: 2.27694842639928

Epoch: 6| Step: 7
Training loss: 0.17236090380188002
Validation loss: 2.276275542402658

Epoch: 6| Step: 8
Training loss: 0.3717101749619279
Validation loss: 2.258770422935743

Epoch: 6| Step: 9
Training loss: 0.5307662388136217
Validation loss: 2.2693842053288895

Epoch: 6| Step: 10
Training loss: 0.4381776738303582
Validation loss: 2.2715638430661103

Epoch: 6| Step: 11
Training loss: 0.34570168101553345
Validation loss: 2.2320487874684507

Epoch: 6| Step: 12
Training loss: 0.41040233314322216
Validation loss: 2.2451859146939994

Epoch: 6| Step: 13
Training loss: 0.4894071491930562
Validation loss: 2.261749333113901

Epoch: 348| Step: 0
Training loss: 0.5251399012764391
Validation loss: 2.2530606780963987

Epoch: 6| Step: 1
Training loss: 0.39909228581906764
Validation loss: 2.2263317208038673

Epoch: 6| Step: 2
Training loss: 0.6625335145066575
Validation loss: 2.267166608966885

Epoch: 6| Step: 3
Training loss: 0.37507505460506213
Validation loss: 2.260806656284598

Epoch: 6| Step: 4
Training loss: 0.46088276554287383
Validation loss: 2.27926932294162

Epoch: 6| Step: 5
Training loss: 0.34006703375114944
Validation loss: 2.2710615684812243

Epoch: 6| Step: 6
Training loss: 0.24219428329812667
Validation loss: 2.294888044713185

Epoch: 6| Step: 7
Training loss: 0.3758224171316978
Validation loss: 2.2752461336436585

Epoch: 6| Step: 8
Training loss: 0.2872932260640188
Validation loss: 2.286745008076573

Epoch: 6| Step: 9
Training loss: 0.5566783691459165
Validation loss: 2.265304655936238

Epoch: 6| Step: 10
Training loss: 0.22561712998906244
Validation loss: 2.2716158767616403

Epoch: 6| Step: 11
Training loss: 0.3153313640021539
Validation loss: 2.27873220947439

Epoch: 6| Step: 12
Training loss: 0.4083748232756747
Validation loss: 2.229068179672382

Epoch: 6| Step: 13
Training loss: 0.47564375758935423
Validation loss: 2.2851507954777346

Epoch: 349| Step: 0
Training loss: 0.4541964524094025
Validation loss: 2.252491207065806

Epoch: 6| Step: 1
Training loss: 0.5372943628970009
Validation loss: 2.2567733006445776

Epoch: 6| Step: 2
Training loss: 0.28021092000048653
Validation loss: 2.2058033322274193

Epoch: 6| Step: 3
Training loss: 0.5719569027727345
Validation loss: 2.2057366775942895

Epoch: 6| Step: 4
Training loss: 0.4009044234858421
Validation loss: 2.2121300401166546

Epoch: 6| Step: 5
Training loss: 0.4618939482037464
Validation loss: 2.233842168487367

Epoch: 6| Step: 6
Training loss: 0.19963803766727686
Validation loss: 2.2484135452599032

Epoch: 6| Step: 7
Training loss: 0.40388473291101207
Validation loss: 2.2701526294081784

Epoch: 6| Step: 8
Training loss: 0.37594063327082905
Validation loss: 2.272356808338441

Epoch: 6| Step: 9
Training loss: 0.17990904087700152
Validation loss: 2.2679321041603155

Epoch: 6| Step: 10
Training loss: 0.5526401452933868
Validation loss: 2.2877413142687497

Epoch: 6| Step: 11
Training loss: 0.39079040839968865
Validation loss: 2.2820393838272786

Epoch: 6| Step: 12
Training loss: 0.1866587203185031
Validation loss: 2.2749558116917497

Epoch: 6| Step: 13
Training loss: 0.27616917016675546
Validation loss: 2.255565239273466

Epoch: 350| Step: 0
Training loss: 0.472336653171216
Validation loss: 2.269686231848859

Epoch: 6| Step: 1
Training loss: 0.3445020165875769
Validation loss: 2.2827162279290767

Epoch: 6| Step: 2
Training loss: 0.235004549109277
Validation loss: 2.266587662978845

Epoch: 6| Step: 3
Training loss: 0.21261903955794278
Validation loss: 2.2803596088386864

Epoch: 6| Step: 4
Training loss: 0.6399334454576113
Validation loss: 2.2689459235853384

Epoch: 6| Step: 5
Training loss: 0.4297423241059053
Validation loss: 2.241990841595007

Epoch: 6| Step: 6
Training loss: 0.47542975209064653
Validation loss: 2.23105399488575

Epoch: 6| Step: 7
Training loss: 0.2965609495566612
Validation loss: 2.2443828089558986

Epoch: 6| Step: 8
Training loss: 0.4301980020454065
Validation loss: 2.2652135869374797

Epoch: 6| Step: 9
Training loss: 0.3848321924863161
Validation loss: 2.279163939093875

Epoch: 6| Step: 10
Training loss: 0.4010242565719118
Validation loss: 2.2541005745758858

Epoch: 6| Step: 11
Training loss: 0.37777892267218866
Validation loss: 2.2660692208751305

Epoch: 6| Step: 12
Training loss: 0.35587520208242485
Validation loss: 2.225656198511675

Epoch: 6| Step: 13
Training loss: 0.16124594213865384
Validation loss: 2.224565671515815

Epoch: 351| Step: 0
Training loss: 0.21630042170464972
Validation loss: 2.2404184770822715

Epoch: 6| Step: 1
Training loss: 0.32713909989880746
Validation loss: 2.198598388458588

Epoch: 6| Step: 2
Training loss: 0.36802381277655355
Validation loss: 2.259605800617132

Epoch: 6| Step: 3
Training loss: 0.42819598298640715
Validation loss: 2.2537655073686427

Epoch: 6| Step: 4
Training loss: 0.4011295849760071
Validation loss: 2.2610459370215987

Epoch: 6| Step: 5
Training loss: 0.4908168417659507
Validation loss: 2.2633744844057513

Epoch: 6| Step: 6
Training loss: 0.6124119033517498
Validation loss: 2.2677745982169135

Epoch: 6| Step: 7
Training loss: 0.34450065407739344
Validation loss: 2.269377769626475

Epoch: 6| Step: 8
Training loss: 0.33885218122604044
Validation loss: 2.2858824254918497

Epoch: 6| Step: 9
Training loss: 0.20493341517412925
Validation loss: 2.308176685954763

Epoch: 6| Step: 10
Training loss: 0.516996207688182
Validation loss: 2.316720474413124

Epoch: 6| Step: 11
Training loss: 0.4152330730486005
Validation loss: 2.3021404036745414

Epoch: 6| Step: 12
Training loss: 0.28309543798440095
Validation loss: 2.263079157229377

Epoch: 6| Step: 13
Training loss: 0.28223854752274435
Validation loss: 2.30218753923142

Epoch: 352| Step: 0
Training loss: 0.3310840559904397
Validation loss: 2.30520345683838

Epoch: 6| Step: 1
Training loss: 0.34944586952910633
Validation loss: 2.262980892816821

Epoch: 6| Step: 2
Training loss: 0.44105644206129757
Validation loss: 2.2653433608071754

Epoch: 6| Step: 3
Training loss: 0.32493905403820705
Validation loss: 2.229253375836067

Epoch: 6| Step: 4
Training loss: 0.30502711222479834
Validation loss: 2.254538615220762

Epoch: 6| Step: 5
Training loss: 0.4421253760543574
Validation loss: 2.2186880997084177

Epoch: 6| Step: 6
Training loss: 0.354881094307485
Validation loss: 2.2036150705284228

Epoch: 6| Step: 7
Training loss: 0.44968318979558325
Validation loss: 2.2198268213269436

Epoch: 6| Step: 8
Training loss: 0.3393064285082229
Validation loss: 2.197062445103123

Epoch: 6| Step: 9
Training loss: 0.49938473993955507
Validation loss: 2.2140672065396

Epoch: 6| Step: 10
Training loss: 0.3096225586133858
Validation loss: 2.2350541016536924

Epoch: 6| Step: 11
Training loss: 0.18416992032153082
Validation loss: 2.210133954588032

Epoch: 6| Step: 12
Training loss: 0.4209842107693432
Validation loss: 2.2118265882018893

Epoch: 6| Step: 13
Training loss: 0.6068301246936809
Validation loss: 2.2236118883021994

Epoch: 353| Step: 0
Training loss: 0.44408988427939916
Validation loss: 2.2239679146764137

Epoch: 6| Step: 1
Training loss: 0.29978803656746006
Validation loss: 2.2659049342436446

Epoch: 6| Step: 2
Training loss: 0.25993050813455093
Validation loss: 2.2710779127405387

Epoch: 6| Step: 3
Training loss: 0.3637401184889706
Validation loss: 2.2858618423210393

Epoch: 6| Step: 4
Training loss: 0.5220048571539675
Validation loss: 2.2944769256522917

Epoch: 6| Step: 5
Training loss: 0.5130152403499174
Validation loss: 2.339677340642608

Epoch: 6| Step: 6
Training loss: 0.1845470191748943
Validation loss: 2.3279121666676326

Epoch: 6| Step: 7
Training loss: 0.4918185622423012
Validation loss: 2.2860023263756815

Epoch: 6| Step: 8
Training loss: 0.37613161531147504
Validation loss: 2.295036327237105

Epoch: 6| Step: 9
Training loss: 0.5060667106469264
Validation loss: 2.2986825172403496

Epoch: 6| Step: 10
Training loss: 0.3402527507457773
Validation loss: 2.2727934594598955

Epoch: 6| Step: 11
Training loss: 0.2565546707603565
Validation loss: 2.2306584798563716

Epoch: 6| Step: 12
Training loss: 0.31179695916993133
Validation loss: 2.2357390365164367

Epoch: 6| Step: 13
Training loss: 0.2515766080608376
Validation loss: 2.247733954177435

Epoch: 354| Step: 0
Training loss: 0.515779154304377
Validation loss: 2.2124546860029533

Epoch: 6| Step: 1
Training loss: 0.44891763629540704
Validation loss: 2.2273842907516386

Epoch: 6| Step: 2
Training loss: 0.4005524843141996
Validation loss: 2.246498329566499

Epoch: 6| Step: 3
Training loss: 0.4149076725046939
Validation loss: 2.2330015530510003

Epoch: 6| Step: 4
Training loss: 0.44663215320900623
Validation loss: 2.219830127754996

Epoch: 6| Step: 5
Training loss: 0.40857404074169684
Validation loss: 2.238667395069696

Epoch: 6| Step: 6
Training loss: 0.44377397485897974
Validation loss: 2.253653432596452

Epoch: 6| Step: 7
Training loss: 0.237848154044511
Validation loss: 2.227830309360981

Epoch: 6| Step: 8
Training loss: 0.30537227560850955
Validation loss: 2.2491587646581674

Epoch: 6| Step: 9
Training loss: 0.4056977773659564
Validation loss: 2.257061905329836

Epoch: 6| Step: 10
Training loss: 0.1629514196549699
Validation loss: 2.278840570850743

Epoch: 6| Step: 11
Training loss: 0.3292228859966154
Validation loss: 2.2930225474244166

Epoch: 6| Step: 12
Training loss: 0.4716740167565191
Validation loss: 2.298002967117219

Epoch: 6| Step: 13
Training loss: 0.19628971726037892
Validation loss: 2.2829564946610446

Epoch: 355| Step: 0
Training loss: 0.1965346626559256
Validation loss: 2.2683935769246366

Epoch: 6| Step: 1
Training loss: 0.42292813143043567
Validation loss: 2.3079319151279107

Epoch: 6| Step: 2
Training loss: 0.4513347216245062
Validation loss: 2.2586460254707315

Epoch: 6| Step: 3
Training loss: 0.3751272144703519
Validation loss: 2.3037548424323657

Epoch: 6| Step: 4
Training loss: 0.30026893829710766
Validation loss: 2.2974399563575716

Epoch: 6| Step: 5
Training loss: 0.36577154629826103
Validation loss: 2.270855872938097

Epoch: 6| Step: 6
Training loss: 0.22128266226796342
Validation loss: 2.2719899835340116

Epoch: 6| Step: 7
Training loss: 0.3063723368456985
Validation loss: 2.2526269071646148

Epoch: 6| Step: 8
Training loss: 0.6243087283562911
Validation loss: 2.246631804477506

Epoch: 6| Step: 9
Training loss: 0.4313354621737143
Validation loss: 2.2385181674645667

Epoch: 6| Step: 10
Training loss: 0.5001138021182765
Validation loss: 2.2383959893502516

Epoch: 6| Step: 11
Training loss: 0.15930655168942293
Validation loss: 2.242616388109197

Epoch: 6| Step: 12
Training loss: 0.3732316523192446
Validation loss: 2.2540630744469574

Epoch: 6| Step: 13
Training loss: 0.4697389343282049
Validation loss: 2.269217459732177

Epoch: 356| Step: 0
Training loss: 0.42744498718727914
Validation loss: 2.2911264037683563

Epoch: 6| Step: 1
Training loss: 0.33570412358452184
Validation loss: 2.3319855877895237

Epoch: 6| Step: 2
Training loss: 0.4468534311011086
Validation loss: 2.3289650222437177

Epoch: 6| Step: 3
Training loss: 0.49410894541155836
Validation loss: 2.3462038185360092

Epoch: 6| Step: 4
Training loss: 0.503657227722268
Validation loss: 2.3275103961144095

Epoch: 6| Step: 5
Training loss: 0.22711875472302745
Validation loss: 2.3248182610544483

Epoch: 6| Step: 6
Training loss: 0.2917287014089852
Validation loss: 2.312969216699247

Epoch: 6| Step: 7
Training loss: 0.3098674034520115
Validation loss: 2.2760613827494285

Epoch: 6| Step: 8
Training loss: 0.23975528458577688
Validation loss: 2.2917711705816664

Epoch: 6| Step: 9
Training loss: 0.34904259285984757
Validation loss: 2.275583769454024

Epoch: 6| Step: 10
Training loss: 0.4061695899612946
Validation loss: 2.242558397788478

Epoch: 6| Step: 11
Training loss: 0.417605411505166
Validation loss: 2.2435415246445607

Epoch: 6| Step: 12
Training loss: 0.38531940324080144
Validation loss: 2.2111883261413094

Epoch: 6| Step: 13
Training loss: 0.3510247674528696
Validation loss: 2.2146765535909383

Epoch: 357| Step: 0
Training loss: 0.2406316898704066
Validation loss: 2.2318992492126846

Epoch: 6| Step: 1
Training loss: 0.25024341117938653
Validation loss: 2.21299232678069

Epoch: 6| Step: 2
Training loss: 0.47162041775489144
Validation loss: 2.2493009757528752

Epoch: 6| Step: 3
Training loss: 0.4229654594831706
Validation loss: 2.221632503209954

Epoch: 6| Step: 4
Training loss: 0.38710153304239675
Validation loss: 2.2460553080803365

Epoch: 6| Step: 5
Training loss: 0.35938723170155107
Validation loss: 2.226582086200271

Epoch: 6| Step: 6
Training loss: 0.3491567206711184
Validation loss: 2.2347694569114642

Epoch: 6| Step: 7
Training loss: 0.49489597593013845
Validation loss: 2.2530675074498747

Epoch: 6| Step: 8
Training loss: 0.3450085186597677
Validation loss: 2.2770447133738356

Epoch: 6| Step: 9
Training loss: 0.43098489657002154
Validation loss: 2.291596919664277

Epoch: 6| Step: 10
Training loss: 0.35624250102934424
Validation loss: 2.2902000943834566

Epoch: 6| Step: 11
Training loss: 0.4424514548833988
Validation loss: 2.307029919458146

Epoch: 6| Step: 12
Training loss: 0.47491354280979375
Validation loss: 2.316301110852499

Epoch: 6| Step: 13
Training loss: 0.14646772289994403
Validation loss: 2.315334344660853

Epoch: 358| Step: 0
Training loss: 0.3451959154262546
Validation loss: 2.320620353447969

Epoch: 6| Step: 1
Training loss: 0.30134878244522745
Validation loss: 2.306096328554229

Epoch: 6| Step: 2
Training loss: 0.31784601303043564
Validation loss: 2.3009658807086852

Epoch: 6| Step: 3
Training loss: 0.4627938471196362
Validation loss: 2.279588233156056

Epoch: 6| Step: 4
Training loss: 0.4439619901170264
Validation loss: 2.2761173830320685

Epoch: 6| Step: 5
Training loss: 0.1850718088388651
Validation loss: 2.2689343665602237

Epoch: 6| Step: 6
Training loss: 0.33880371686623234
Validation loss: 2.2411245146164998

Epoch: 6| Step: 7
Training loss: 0.342670925276652
Validation loss: 2.25602806585299

Epoch: 6| Step: 8
Training loss: 0.3213261869832589
Validation loss: 2.254137959213233

Epoch: 6| Step: 9
Training loss: 0.5638717772743307
Validation loss: 2.2365048640439795

Epoch: 6| Step: 10
Training loss: 0.2593832141081126
Validation loss: 2.2636622621987113

Epoch: 6| Step: 11
Training loss: 0.23552884749323094
Validation loss: 2.252277901801635

Epoch: 6| Step: 12
Training loss: 0.26208899769830174
Validation loss: 2.315306743665344

Epoch: 6| Step: 13
Training loss: 0.673212184519667
Validation loss: 2.3086596558788166

Epoch: 359| Step: 0
Training loss: 0.3543286747735348
Validation loss: 2.259880696661601

Epoch: 6| Step: 1
Training loss: 0.41932452985422997
Validation loss: 2.27435277206036

Epoch: 6| Step: 2
Training loss: 0.3012766783127757
Validation loss: 2.2592026389819972

Epoch: 6| Step: 3
Training loss: 0.5254289691078698
Validation loss: 2.2454960155845867

Epoch: 6| Step: 4
Training loss: 0.2699527761434244
Validation loss: 2.253822508087105

Epoch: 6| Step: 5
Training loss: 0.40298081858069457
Validation loss: 2.2856585919229158

Epoch: 6| Step: 6
Training loss: 0.1807483476488082
Validation loss: 2.2540747515071633

Epoch: 6| Step: 7
Training loss: 0.41501170348704564
Validation loss: 2.2430510751432773

Epoch: 6| Step: 8
Training loss: 0.4040460591758842
Validation loss: 2.2336811549069457

Epoch: 6| Step: 9
Training loss: 0.2642442636336408
Validation loss: 2.2544478214739123

Epoch: 6| Step: 10
Training loss: 0.4001811526294249
Validation loss: 2.2632057520985023

Epoch: 6| Step: 11
Training loss: 0.28876526474340664
Validation loss: 2.254934151629405

Epoch: 6| Step: 12
Training loss: 0.46255967425372513
Validation loss: 2.300615068412065

Epoch: 6| Step: 13
Training loss: 0.1472781292390255
Validation loss: 2.2865607118462163

Epoch: 360| Step: 0
Training loss: 0.3991441257552511
Validation loss: 2.2904384405505063

Epoch: 6| Step: 1
Training loss: 0.6124834593660918
Validation loss: 2.3207344949491793

Epoch: 6| Step: 2
Training loss: 0.23179806413592993
Validation loss: 2.3012795796114514

Epoch: 6| Step: 3
Training loss: 0.39851801189701663
Validation loss: 2.280406852842505

Epoch: 6| Step: 4
Training loss: 0.4013509816705796
Validation loss: 2.338042981212161

Epoch: 6| Step: 5
Training loss: 0.31903533319234334
Validation loss: 2.308573985642869

Epoch: 6| Step: 6
Training loss: 0.14984488861717432
Validation loss: 2.278100441115919

Epoch: 6| Step: 7
Training loss: 0.4516688495521067
Validation loss: 2.2606856515603577

Epoch: 6| Step: 8
Training loss: 0.43532707244733754
Validation loss: 2.2986003932197607

Epoch: 6| Step: 9
Training loss: 0.3438823076863203
Validation loss: 2.331043785108865

Epoch: 6| Step: 10
Training loss: 0.4153958929652287
Validation loss: 2.277288722121324

Epoch: 6| Step: 11
Training loss: 0.3777780154560937
Validation loss: 2.312222696122286

Epoch: 6| Step: 12
Training loss: 0.14810013077403006
Validation loss: 2.272117735240394

Epoch: 6| Step: 13
Training loss: 0.14079103998910444
Validation loss: 2.282386482929782

Epoch: 361| Step: 0
Training loss: 0.39644507979174654
Validation loss: 2.2835469366135173

Epoch: 6| Step: 1
Training loss: 0.2938999128292223
Validation loss: 2.2847926386674104

Epoch: 6| Step: 2
Training loss: 0.24897426044853374
Validation loss: 2.286963358538997

Epoch: 6| Step: 3
Training loss: 0.37347866453950346
Validation loss: 2.2530755053451816

Epoch: 6| Step: 4
Training loss: 0.21778787470975103
Validation loss: 2.262362597561713

Epoch: 6| Step: 5
Training loss: 0.4892468479778133
Validation loss: 2.269244521520085

Epoch: 6| Step: 6
Training loss: 0.2584548231267079
Validation loss: 2.243159134447368

Epoch: 6| Step: 7
Training loss: 0.4459170537697534
Validation loss: 2.239039444086769

Epoch: 6| Step: 8
Training loss: 0.37036215292349034
Validation loss: 2.277702023480079

Epoch: 6| Step: 9
Training loss: 0.42878256788093655
Validation loss: 2.2655371049543622

Epoch: 6| Step: 10
Training loss: 0.31742764669809465
Validation loss: 2.284290729744476

Epoch: 6| Step: 11
Training loss: 0.4231557654855601
Validation loss: 2.287689798071661

Epoch: 6| Step: 12
Training loss: 0.42825679142783946
Validation loss: 2.2748810757891182

Epoch: 6| Step: 13
Training loss: 0.27602443401360527
Validation loss: 2.3103227573320977

Epoch: 362| Step: 0
Training loss: 0.2978865305901568
Validation loss: 2.284974710457772

Epoch: 6| Step: 1
Training loss: 0.22246045990876734
Validation loss: 2.3100932811090713

Epoch: 6| Step: 2
Training loss: 0.4026103571538818
Validation loss: 2.266667063510662

Epoch: 6| Step: 3
Training loss: 0.47556196775092024
Validation loss: 2.2742740349515014

Epoch: 6| Step: 4
Training loss: 0.2595024353098661
Validation loss: 2.2861497055787634

Epoch: 6| Step: 5
Training loss: 0.5024403682360664
Validation loss: 2.2822996942180303

Epoch: 6| Step: 6
Training loss: 0.30866091033609
Validation loss: 2.291787221726358

Epoch: 6| Step: 7
Training loss: 0.3580432139706207
Validation loss: 2.277625542438116

Epoch: 6| Step: 8
Training loss: 0.3633596684305618
Validation loss: 2.264343632604457

Epoch: 6| Step: 9
Training loss: 0.23894865342056312
Validation loss: 2.2625050007763674

Epoch: 6| Step: 10
Training loss: 0.24114834981199887
Validation loss: 2.25604042932227

Epoch: 6| Step: 11
Training loss: 0.23886471588777433
Validation loss: 2.255925331666161

Epoch: 6| Step: 12
Training loss: 0.5478213160796103
Validation loss: 2.2570236445419742

Epoch: 6| Step: 13
Training loss: 0.2121016906695179
Validation loss: 2.2482591341032037

Epoch: 363| Step: 0
Training loss: 0.16601780160711238
Validation loss: 2.2518458776163723

Epoch: 6| Step: 1
Training loss: 0.23201771064071106
Validation loss: 2.2425869198671737

Epoch: 6| Step: 2
Training loss: 0.33907008624050067
Validation loss: 2.2529299890472374

Epoch: 6| Step: 3
Training loss: 0.4022363686086336
Validation loss: 2.259344106113586

Epoch: 6| Step: 4
Training loss: 0.30204944036798487
Validation loss: 2.2503452400763813

Epoch: 6| Step: 5
Training loss: 0.4535186307480572
Validation loss: 2.246756834050646

Epoch: 6| Step: 6
Training loss: 0.266279172373728
Validation loss: 2.2494324033164195

Epoch: 6| Step: 7
Training loss: 0.30063434828183583
Validation loss: 2.2893599724602036

Epoch: 6| Step: 8
Training loss: 0.2971322175081341
Validation loss: 2.2844110617825444

Epoch: 6| Step: 9
Training loss: 0.3819763627828
Validation loss: 2.309242297496671

Epoch: 6| Step: 10
Training loss: 0.45443298387021325
Validation loss: 2.322372085376315

Epoch: 6| Step: 11
Training loss: 0.40981956468746594
Validation loss: 2.317088215187114

Epoch: 6| Step: 12
Training loss: 0.4958366418642634
Validation loss: 2.316993965169356

Epoch: 6| Step: 13
Training loss: 0.4848634195471621
Validation loss: 2.3246948785816133

Epoch: 364| Step: 0
Training loss: 0.4277281738946543
Validation loss: 2.3228546675818764

Epoch: 6| Step: 1
Training loss: 0.4006247231516722
Validation loss: 2.3148031829578195

Epoch: 6| Step: 2
Training loss: 0.36217638401881674
Validation loss: 2.297616693349414

Epoch: 6| Step: 3
Training loss: 0.14484897049607806
Validation loss: 2.307455141287428

Epoch: 6| Step: 4
Training loss: 0.207120282444614
Validation loss: 2.2881937203487652

Epoch: 6| Step: 5
Training loss: 0.31686387112127573
Validation loss: 2.2520982593280316

Epoch: 6| Step: 6
Training loss: 0.44862565403144206
Validation loss: 2.256801033059824

Epoch: 6| Step: 7
Training loss: 0.4002007755411193
Validation loss: 2.286612459212478

Epoch: 6| Step: 8
Training loss: 0.2643034118195786
Validation loss: 2.2604284621236648

Epoch: 6| Step: 9
Training loss: 0.455968125682835
Validation loss: 2.2930098645923924

Epoch: 6| Step: 10
Training loss: 0.32519665279627724
Validation loss: 2.237336608888454

Epoch: 6| Step: 11
Training loss: 0.17988306267106907
Validation loss: 2.259705332118516

Epoch: 6| Step: 12
Training loss: 0.15571861507770496
Validation loss: 2.269748264432714

Epoch: 6| Step: 13
Training loss: 0.6022859904381227
Validation loss: 2.2847288225769335

Epoch: 365| Step: 0
Training loss: 0.14769095991773912
Validation loss: 2.280659824997836

Epoch: 6| Step: 1
Training loss: 0.466123518240945
Validation loss: 2.251785152665315

Epoch: 6| Step: 2
Training loss: 0.46199936512597956
Validation loss: 2.2846016080946816

Epoch: 6| Step: 3
Training loss: 0.22887589510519185
Validation loss: 2.280781147776797

Epoch: 6| Step: 4
Training loss: 0.0719414832413079
Validation loss: 2.2999614983207817

Epoch: 6| Step: 5
Training loss: 0.3816422071004382
Validation loss: 2.303887697224702

Epoch: 6| Step: 6
Training loss: 0.20626184256106556
Validation loss: 2.3179504507725475

Epoch: 6| Step: 7
Training loss: 0.541301169938973
Validation loss: 2.31848785428375

Epoch: 6| Step: 8
Training loss: 0.27856306231165723
Validation loss: 2.322908408556205

Epoch: 6| Step: 9
Training loss: 0.2635950612395664
Validation loss: 2.304540235049401

Epoch: 6| Step: 10
Training loss: 0.2310688643245843
Validation loss: 2.301635594708884

Epoch: 6| Step: 11
Training loss: 0.4993348465723826
Validation loss: 2.3412804470714077

Epoch: 6| Step: 12
Training loss: 0.4076590676902984
Validation loss: 2.2891126497912424

Epoch: 6| Step: 13
Training loss: 0.17818691992757274
Validation loss: 2.2779778806902176

Epoch: 366| Step: 0
Training loss: 0.45748046252218866
Validation loss: 2.265730220400847

Epoch: 6| Step: 1
Training loss: 0.2067133694335596
Validation loss: 2.2782900103430883

Epoch: 6| Step: 2
Training loss: 0.2985327014566359
Validation loss: 2.2566229980435586

Epoch: 6| Step: 3
Training loss: 0.22118701888358422
Validation loss: 2.2423250838527577

Epoch: 6| Step: 4
Training loss: 0.35584492743064416
Validation loss: 2.247219420746663

Epoch: 6| Step: 5
Training loss: 0.5312488219304206
Validation loss: 2.2811153494057494

Epoch: 6| Step: 6
Training loss: 0.4714309004678621
Validation loss: 2.2650634760008352

Epoch: 6| Step: 7
Training loss: 0.266628333902954
Validation loss: 2.2583259793167003

Epoch: 6| Step: 8
Training loss: 0.4758243472369259
Validation loss: 2.22359779067288

Epoch: 6| Step: 9
Training loss: 0.2349145718280734
Validation loss: 2.25415756227235

Epoch: 6| Step: 10
Training loss: 0.23868914384068596
Validation loss: 2.282721231181945

Epoch: 6| Step: 11
Training loss: 0.13870592102330104
Validation loss: 2.2888439868916968

Epoch: 6| Step: 12
Training loss: 0.3042852730063444
Validation loss: 2.289490550515393

Epoch: 6| Step: 13
Training loss: 0.45889079986530484
Validation loss: 2.294579225896305

Epoch: 367| Step: 0
Training loss: 0.2811378016790425
Validation loss: 2.2820199635470884

Epoch: 6| Step: 1
Training loss: 0.3521938906092352
Validation loss: 2.302729948503799

Epoch: 6| Step: 2
Training loss: 0.45526898356140616
Validation loss: 2.253355987197338

Epoch: 6| Step: 3
Training loss: 0.4430047520130767
Validation loss: 2.2493319542276553

Epoch: 6| Step: 4
Training loss: 0.42254312027171886
Validation loss: 2.2642620299520066

Epoch: 6| Step: 5
Training loss: 0.5488026297406869
Validation loss: 2.2588640300617264

Epoch: 6| Step: 6
Training loss: 0.14704295786742622
Validation loss: 2.2632719163281925

Epoch: 6| Step: 7
Training loss: 0.33980007548699037
Validation loss: 2.2508029564628758

Epoch: 6| Step: 8
Training loss: 0.3291518741716272
Validation loss: 2.2543800487138985

Epoch: 6| Step: 9
Training loss: 0.28887380420878045
Validation loss: 2.2826940775938955

Epoch: 6| Step: 10
Training loss: 0.28573101071383733
Validation loss: 2.3034333354085654

Epoch: 6| Step: 11
Training loss: 0.2607465165025336
Validation loss: 2.342423696119746

Epoch: 6| Step: 12
Training loss: 0.3663656289494255
Validation loss: 2.2710880184888254

Epoch: 6| Step: 13
Training loss: 0.26767339193898404
Validation loss: 2.303365687012524

Epoch: 368| Step: 0
Training loss: 0.24735897525815054
Validation loss: 2.3103398680115843

Epoch: 6| Step: 1
Training loss: 0.24633840479574995
Validation loss: 2.276069725182619

Epoch: 6| Step: 2
Training loss: 0.3999418767781095
Validation loss: 2.2791879267989934

Epoch: 6| Step: 3
Training loss: 0.25905696030090297
Validation loss: 2.2980344947314304

Epoch: 6| Step: 4
Training loss: 0.4159182224062424
Validation loss: 2.2930673001328934

Epoch: 6| Step: 5
Training loss: 0.23979507381035914
Validation loss: 2.2846628850411284

Epoch: 6| Step: 6
Training loss: 0.23726897893299273
Validation loss: 2.2813953174129904

Epoch: 6| Step: 7
Training loss: 0.4057515828212813
Validation loss: 2.2701622598976368

Epoch: 6| Step: 8
Training loss: 0.4467752425347618
Validation loss: 2.2847950117917963

Epoch: 6| Step: 9
Training loss: 0.407916703193333
Validation loss: 2.2783082015876994

Epoch: 6| Step: 10
Training loss: 0.44793213403595356
Validation loss: 2.308421651829062

Epoch: 6| Step: 11
Training loss: 0.3837680956522305
Validation loss: 2.300056393339064

Epoch: 6| Step: 12
Training loss: 0.1225358858386866
Validation loss: 2.2836171027393575

Epoch: 6| Step: 13
Training loss: 0.36972201949611666
Validation loss: 2.324926728298002

Epoch: 369| Step: 0
Training loss: 0.21517035195006423
Validation loss: 2.2999848282800945

Epoch: 6| Step: 1
Training loss: 0.13874786605139058
Validation loss: 2.2789032989227147

Epoch: 6| Step: 2
Training loss: 0.5247691282627057
Validation loss: 2.2789573696014114

Epoch: 6| Step: 3
Training loss: 0.34249021778964306
Validation loss: 2.2898937041811287

Epoch: 6| Step: 4
Training loss: 0.27668341078751313
Validation loss: 2.307643695101169

Epoch: 6| Step: 5
Training loss: 0.390627613058887
Validation loss: 2.304246143080855

Epoch: 6| Step: 6
Training loss: 0.2769664965631198
Validation loss: 2.3086725947530686

Epoch: 6| Step: 7
Training loss: 0.3233490620286715
Validation loss: 2.345077099549698

Epoch: 6| Step: 8
Training loss: 0.4258909871487894
Validation loss: 2.3121937690631924

Epoch: 6| Step: 9
Training loss: 0.24248368087896335
Validation loss: 2.2590642741139186

Epoch: 6| Step: 10
Training loss: 0.286357322859112
Validation loss: 2.30104886117851

Epoch: 6| Step: 11
Training loss: 0.35150762765538834
Validation loss: 2.273623387674031

Epoch: 6| Step: 12
Training loss: 0.4263043471338204
Validation loss: 2.2709518058137945

Epoch: 6| Step: 13
Training loss: 0.2571400774344753
Validation loss: 2.244301269708069

Epoch: 370| Step: 0
Training loss: 0.3611233723934859
Validation loss: 2.269015663900833

Epoch: 6| Step: 1
Training loss: 0.348755480986427
Validation loss: 2.2492100799989214

Epoch: 6| Step: 2
Training loss: 0.4114976654890361
Validation loss: 2.2549704281961347

Epoch: 6| Step: 3
Training loss: 0.4606835263673068
Validation loss: 2.271726429454794

Epoch: 6| Step: 4
Training loss: 0.3705552862516839
Validation loss: 2.25937481781769

Epoch: 6| Step: 5
Training loss: 0.42202839005485276
Validation loss: 2.276775368471401

Epoch: 6| Step: 6
Training loss: 0.26465506738895545
Validation loss: 2.2966827849014773

Epoch: 6| Step: 7
Training loss: 0.21373070320228785
Validation loss: 2.2983554655937786

Epoch: 6| Step: 8
Training loss: 0.452429072580211
Validation loss: 2.2953250296478918

Epoch: 6| Step: 9
Training loss: 0.320950361475137
Validation loss: 2.2888944674006186

Epoch: 6| Step: 10
Training loss: 0.12942229638819178
Validation loss: 2.34334187881785

Epoch: 6| Step: 11
Training loss: 0.3451937786403627
Validation loss: 2.335604578467883

Epoch: 6| Step: 12
Training loss: 0.2091613893314939
Validation loss: 2.358032426980078

Epoch: 6| Step: 13
Training loss: 0.2277434581168787
Validation loss: 2.336650659820756

Epoch: 371| Step: 0
Training loss: 0.304590013998705
Validation loss: 2.313956684609295

Epoch: 6| Step: 1
Training loss: 0.47672312796703914
Validation loss: 2.3404689670271983

Epoch: 6| Step: 2
Training loss: 0.23114629333854883
Validation loss: 2.3295665615682544

Epoch: 6| Step: 3
Training loss: 0.4917525534318685
Validation loss: 2.3215461866136664

Epoch: 6| Step: 4
Training loss: 0.23836351756769347
Validation loss: 2.3383144974770174

Epoch: 6| Step: 5
Training loss: 0.4105785557276846
Validation loss: 2.301350622614641

Epoch: 6| Step: 6
Training loss: 0.368702866079656
Validation loss: 2.2765327832915463

Epoch: 6| Step: 7
Training loss: 0.2598043140482681
Validation loss: 2.300668070830363

Epoch: 6| Step: 8
Training loss: 0.3518277545128556
Validation loss: 2.314734647732228

Epoch: 6| Step: 9
Training loss: 0.2712849495166079
Validation loss: 2.2874536406590633

Epoch: 6| Step: 10
Training loss: 0.1907141101990959
Validation loss: 2.2734351905726733

Epoch: 6| Step: 11
Training loss: 0.43494137127722954
Validation loss: 2.2847031280015258

Epoch: 6| Step: 12
Training loss: 0.17864455360717915
Validation loss: 2.2703565006777096

Epoch: 6| Step: 13
Training loss: 0.23858847901443272
Validation loss: 2.2299419260991034

Epoch: 372| Step: 0
Training loss: 0.412421483456801
Validation loss: 2.2730193257271525

Epoch: 6| Step: 1
Training loss: 0.2104554142228094
Validation loss: 2.2782869175976357

Epoch: 6| Step: 2
Training loss: 0.161819250096786
Validation loss: 2.307081973324511

Epoch: 6| Step: 3
Training loss: 0.3777907360046228
Validation loss: 2.3082517493389174

Epoch: 6| Step: 4
Training loss: 0.4163903353228197
Validation loss: 2.35082926173005

Epoch: 6| Step: 5
Training loss: 0.43005327781809194
Validation loss: 2.3038861438314795

Epoch: 6| Step: 6
Training loss: 0.15984339511716344
Validation loss: 2.3605750040093874

Epoch: 6| Step: 7
Training loss: 0.32425271281487683
Validation loss: 2.358162588874442

Epoch: 6| Step: 8
Training loss: 0.3764761639784314
Validation loss: 2.3478011888704984

Epoch: 6| Step: 9
Training loss: 0.21064434166458929
Validation loss: 2.33741702259928

Epoch: 6| Step: 10
Training loss: 0.35462409053439803
Validation loss: 2.343800344712634

Epoch: 6| Step: 11
Training loss: 0.2899871676993093
Validation loss: 2.343069209279591

Epoch: 6| Step: 12
Training loss: 0.2054793565427518
Validation loss: 2.3474088858630497

Epoch: 6| Step: 13
Training loss: 0.5640909161371028
Validation loss: 2.338392929396102

Epoch: 373| Step: 0
Training loss: 0.3652388220531614
Validation loss: 2.335095446312316

Epoch: 6| Step: 1
Training loss: 0.34254728502498627
Validation loss: 2.3489722642175552

Epoch: 6| Step: 2
Training loss: 0.33325133830143033
Validation loss: 2.330558485632199

Epoch: 6| Step: 3
Training loss: 0.2076537651791672
Validation loss: 2.3154774426999127

Epoch: 6| Step: 4
Training loss: 0.38905549406921225
Validation loss: 2.3206063985561967

Epoch: 6| Step: 5
Training loss: 0.20749612115199007
Validation loss: 2.3173403956803407

Epoch: 6| Step: 6
Training loss: 0.30550126685615003
Validation loss: 2.3060257858355016

Epoch: 6| Step: 7
Training loss: 0.2348179287652244
Validation loss: 2.272085521002177

Epoch: 6| Step: 8
Training loss: 0.19429625292878983
Validation loss: 2.24044509833435

Epoch: 6| Step: 9
Training loss: 0.35755263474605503
Validation loss: 2.279612632496584

Epoch: 6| Step: 10
Training loss: 0.26539228567390466
Validation loss: 2.274441688872213

Epoch: 6| Step: 11
Training loss: 0.395603686356702
Validation loss: 2.2896833901035696

Epoch: 6| Step: 12
Training loss: 0.1370022015246783
Validation loss: 2.253082860903305

Epoch: 6| Step: 13
Training loss: 0.7423887682612857
Validation loss: 2.2693443188174682

Epoch: 374| Step: 0
Training loss: 0.4347013811627884
Validation loss: 2.2865435745824847

Epoch: 6| Step: 1
Training loss: 0.35749953630057185
Validation loss: 2.2678813941565372

Epoch: 6| Step: 2
Training loss: 0.2144459856995507
Validation loss: 2.2770830115370693

Epoch: 6| Step: 3
Training loss: 0.4105338039186632
Validation loss: 2.2811232422188157

Epoch: 6| Step: 4
Training loss: 0.312329698888714
Validation loss: 2.2761071515018108

Epoch: 6| Step: 5
Training loss: 0.433445466950898
Validation loss: 2.3023444900709986

Epoch: 6| Step: 6
Training loss: 0.1934639233859138
Validation loss: 2.2839983186762844

Epoch: 6| Step: 7
Training loss: 0.3500438526474149
Validation loss: 2.3292634081157835

Epoch: 6| Step: 8
Training loss: 0.12835243496559706
Validation loss: 2.3102109178333494

Epoch: 6| Step: 9
Training loss: 0.42989509076232346
Validation loss: 2.307045287716528

Epoch: 6| Step: 10
Training loss: 0.1096142850620335
Validation loss: 2.312618239289201

Epoch: 6| Step: 11
Training loss: 0.33888987704343165
Validation loss: 2.299684322347686

Epoch: 6| Step: 12
Training loss: 0.33938139672336515
Validation loss: 2.316406336325085

Epoch: 6| Step: 13
Training loss: 0.22028302408089262
Validation loss: 2.280003011171144

Epoch: 375| Step: 0
Training loss: 0.2946401349268083
Validation loss: 2.2776445505234104

Epoch: 6| Step: 1
Training loss: 0.6394477354648649
Validation loss: 2.289240446211993

Epoch: 6| Step: 2
Training loss: 0.33459266681447714
Validation loss: 2.2877086933992072

Epoch: 6| Step: 3
Training loss: 0.19605734893822582
Validation loss: 2.310509908211207

Epoch: 6| Step: 4
Training loss: 0.4332898079886404
Validation loss: 2.280837018408453

Epoch: 6| Step: 5
Training loss: 0.3676212265251614
Validation loss: 2.320901941631617

Epoch: 6| Step: 6
Training loss: 0.13210822350233098
Validation loss: 2.275797959407909

Epoch: 6| Step: 7
Training loss: 0.42177921550005965
Validation loss: 2.3014508024613254

Epoch: 6| Step: 8
Training loss: 0.2259030116075109
Validation loss: 2.2702578409682026

Epoch: 6| Step: 9
Training loss: 0.256600304488851
Validation loss: 2.3124773993880177

Epoch: 6| Step: 10
Training loss: 0.2036055510812252
Validation loss: 2.3086802151297583

Epoch: 6| Step: 11
Training loss: 0.24018256086124634
Validation loss: 2.3028785821632196

Epoch: 6| Step: 12
Training loss: 0.2609447021404143
Validation loss: 2.3331068239564683

Epoch: 6| Step: 13
Training loss: 0.20528533095323206
Validation loss: 2.3203729736473355

Epoch: 376| Step: 0
Training loss: 0.2325881075038204
Validation loss: 2.2766640497560533

Epoch: 6| Step: 1
Training loss: 0.16388092892743616
Validation loss: 2.3534843444447473

Epoch: 6| Step: 2
Training loss: 0.38415878386419394
Validation loss: 2.380039821883443

Epoch: 6| Step: 3
Training loss: 0.2723243124717579
Validation loss: 2.359438706186961

Epoch: 6| Step: 4
Training loss: 0.19750946384402163
Validation loss: 2.383596906652738

Epoch: 6| Step: 5
Training loss: 0.42012505162609615
Validation loss: 2.38969074449193

Epoch: 6| Step: 6
Training loss: 0.34355610017122795
Validation loss: 2.3889944505210665

Epoch: 6| Step: 7
Training loss: 0.28065284276528707
Validation loss: 2.333182831787273

Epoch: 6| Step: 8
Training loss: 0.1444221032906519
Validation loss: 2.329264852132574

Epoch: 6| Step: 9
Training loss: 0.5003023723408802
Validation loss: 2.332957159064128

Epoch: 6| Step: 10
Training loss: 0.5185582507454671
Validation loss: 2.290072045343545

Epoch: 6| Step: 11
Training loss: 0.2822843578255804
Validation loss: 2.294251784025026

Epoch: 6| Step: 12
Training loss: 0.24973405908806745
Validation loss: 2.3199132335001384

Epoch: 6| Step: 13
Training loss: 0.1550330154093129
Validation loss: 2.312786776280409

Epoch: 377| Step: 0
Training loss: 0.4256579194243066
Validation loss: 2.311813711617096

Epoch: 6| Step: 1
Training loss: 0.18481745648179926
Validation loss: 2.2772539763777306

Epoch: 6| Step: 2
Training loss: 0.4438761921219111
Validation loss: 2.2775998268209814

Epoch: 6| Step: 3
Training loss: 0.2428877305980752
Validation loss: 2.2934958091584483

Epoch: 6| Step: 4
Training loss: 0.40921227955809764
Validation loss: 2.2986230828737924

Epoch: 6| Step: 5
Training loss: 0.35495223781822255
Validation loss: 2.2968992090110896

Epoch: 6| Step: 6
Training loss: 0.2351664531433286
Validation loss: 2.3475817329210695

Epoch: 6| Step: 7
Training loss: 0.24016066715295772
Validation loss: 2.3229104320682126

Epoch: 6| Step: 8
Training loss: 0.3437791616901559
Validation loss: 2.3474014004943795

Epoch: 6| Step: 9
Training loss: 0.2447837598348861
Validation loss: 2.341999035958061

Epoch: 6| Step: 10
Training loss: 0.31218434126958033
Validation loss: 2.315814599691642

Epoch: 6| Step: 11
Training loss: 0.19337424789410676
Validation loss: 2.325726675758669

Epoch: 6| Step: 12
Training loss: 0.3844206953411642
Validation loss: 2.296167967588032

Epoch: 6| Step: 13
Training loss: 0.3430046757888168
Validation loss: 2.270890589572975

Epoch: 378| Step: 0
Training loss: 0.31518672880842
Validation loss: 2.304830943170105

Epoch: 6| Step: 1
Training loss: 0.16691190898103278
Validation loss: 2.292540211371801

Epoch: 6| Step: 2
Training loss: 0.34609186546553156
Validation loss: 2.281902620511817

Epoch: 6| Step: 3
Training loss: 0.5229526950638715
Validation loss: 2.2735083248697285

Epoch: 6| Step: 4
Training loss: 0.17234098598238573
Validation loss: 2.276232174855608

Epoch: 6| Step: 5
Training loss: 0.3167489868168934
Validation loss: 2.254759155623854

Epoch: 6| Step: 6
Training loss: 0.39957171175938555
Validation loss: 2.249320275625559

Epoch: 6| Step: 7
Training loss: 0.17961291133390958
Validation loss: 2.31051306933471

Epoch: 6| Step: 8
Training loss: 0.3335251802463844
Validation loss: 2.294920800356503

Epoch: 6| Step: 9
Training loss: 0.19884603828121886
Validation loss: 2.3127346989518998

Epoch: 6| Step: 10
Training loss: 0.3317386347578185
Validation loss: 2.342597543546

Epoch: 6| Step: 11
Training loss: 0.21740338827061664
Validation loss: 2.3192375583476594

Epoch: 6| Step: 12
Training loss: 0.390638847105644
Validation loss: 2.374194422541021

Epoch: 6| Step: 13
Training loss: 0.27138823583946886
Validation loss: 2.3236436633750563

Epoch: 379| Step: 0
Training loss: 0.24108219958392707
Validation loss: 2.331469116518809

Epoch: 6| Step: 1
Training loss: 0.2771782045192728
Validation loss: 2.34902916741822

Epoch: 6| Step: 2
Training loss: 0.3668188313990569
Validation loss: 2.331064296232986

Epoch: 6| Step: 3
Training loss: 0.3334724563108109
Validation loss: 2.3271910478940603

Epoch: 6| Step: 4
Training loss: 0.2840105057858532
Validation loss: 2.345499276545962

Epoch: 6| Step: 5
Training loss: 0.2902895427040473
Validation loss: 2.313072265428099

Epoch: 6| Step: 6
Training loss: 0.37118408709754086
Validation loss: 2.2977278281835063

Epoch: 6| Step: 7
Training loss: 0.3453894878887311
Validation loss: 2.3193405727130747

Epoch: 6| Step: 8
Training loss: 0.399308841341662
Validation loss: 2.309183345857347

Epoch: 6| Step: 9
Training loss: 0.38978042852749
Validation loss: 2.3203075965875666

Epoch: 6| Step: 10
Training loss: 0.4054617754385976
Validation loss: 2.3224567653534467

Epoch: 6| Step: 11
Training loss: 0.24493472082348017
Validation loss: 2.2836886946412362

Epoch: 6| Step: 12
Training loss: 0.13663681845054848
Validation loss: 2.2888619088878857

Epoch: 6| Step: 13
Training loss: 0.1405526610917431
Validation loss: 2.2847069778862226

Epoch: 380| Step: 0
Training loss: 0.19346412557103965
Validation loss: 2.2979233769599685

Epoch: 6| Step: 1
Training loss: 0.20424226537916823
Validation loss: 2.29664940472935

Epoch: 6| Step: 2
Training loss: 0.12277945341420625
Validation loss: 2.3019676671286144

Epoch: 6| Step: 3
Training loss: 0.3833146402562672
Validation loss: 2.3203163029549194

Epoch: 6| Step: 4
Training loss: 0.3707293277078086
Validation loss: 2.318872193619193

Epoch: 6| Step: 5
Training loss: 0.2427137026718157
Validation loss: 2.354599031918101

Epoch: 6| Step: 6
Training loss: 0.33895644186031804
Validation loss: 2.3332613164435116

Epoch: 6| Step: 7
Training loss: 0.16582025363952527
Validation loss: 2.3160200502789903

Epoch: 6| Step: 8
Training loss: 0.4419124199212825
Validation loss: 2.3239823680724414

Epoch: 6| Step: 9
Training loss: 0.2505303955368082
Validation loss: 2.3497993346691928

Epoch: 6| Step: 10
Training loss: 0.4334200605694636
Validation loss: 2.3415266017504717

Epoch: 6| Step: 11
Training loss: 0.2867985294785834
Validation loss: 2.3133461786210625

Epoch: 6| Step: 12
Training loss: 0.3325026363612469
Validation loss: 2.3203632935723926

Epoch: 6| Step: 13
Training loss: 0.3649980320942751
Validation loss: 2.32959076429186

Epoch: 381| Step: 0
Training loss: 0.4159336277919774
Validation loss: 2.3107780879191533

Epoch: 6| Step: 1
Training loss: 0.28161972963063736
Validation loss: 2.288164576905058

Epoch: 6| Step: 2
Training loss: 0.18273342737390064
Validation loss: 2.28164505357908

Epoch: 6| Step: 3
Training loss: 0.2764541704764692
Validation loss: 2.2655641433751823

Epoch: 6| Step: 4
Training loss: 0.3377506539495873
Validation loss: 2.2690086486697063

Epoch: 6| Step: 5
Training loss: 0.32246391669317553
Validation loss: 2.283658211693808

Epoch: 6| Step: 6
Training loss: 0.35940348470831546
Validation loss: 2.2799612853442923

Epoch: 6| Step: 7
Training loss: 0.13843273308557277
Validation loss: 2.2671551508604972

Epoch: 6| Step: 8
Training loss: 0.11228397841871754
Validation loss: 2.275768562598832

Epoch: 6| Step: 9
Training loss: 0.28897730113021736
Validation loss: 2.2877868191004946

Epoch: 6| Step: 10
Training loss: 0.256701982035302
Validation loss: 2.2579801082583066

Epoch: 6| Step: 11
Training loss: 0.5033179108781105
Validation loss: 2.2659806732951413

Epoch: 6| Step: 12
Training loss: 0.20742813790559222
Validation loss: 2.2811080679439892

Epoch: 6| Step: 13
Training loss: 0.28124365534513673
Validation loss: 2.2869694633889996

Epoch: 382| Step: 0
Training loss: 0.3912335424039196
Validation loss: 2.2794370146224994

Epoch: 6| Step: 1
Training loss: 0.23744688757754098
Validation loss: 2.2591193288680147

Epoch: 6| Step: 2
Training loss: 0.13177560909447458
Validation loss: 2.3132108589630818

Epoch: 6| Step: 3
Training loss: 0.25586615982960464
Validation loss: 2.2920950119171675

Epoch: 6| Step: 4
Training loss: 0.23235473143812976
Validation loss: 2.2935755329785086

Epoch: 6| Step: 5
Training loss: 0.34161193203768425
Validation loss: 2.3112066143391603

Epoch: 6| Step: 6
Training loss: 0.2703948904173331
Validation loss: 2.2929637020244398

Epoch: 6| Step: 7
Training loss: 0.20879125138965124
Validation loss: 2.3275435539847664

Epoch: 6| Step: 8
Training loss: 0.437485217798366
Validation loss: 2.2915846109848568

Epoch: 6| Step: 9
Training loss: 0.45339678144444195
Validation loss: 2.3009224587578263

Epoch: 6| Step: 10
Training loss: 0.25996411419768234
Validation loss: 2.316179004664471

Epoch: 6| Step: 11
Training loss: 0.17265614815963573
Validation loss: 2.3074161084226166

Epoch: 6| Step: 12
Training loss: 0.3376741763417739
Validation loss: 2.28370415879451

Epoch: 6| Step: 13
Training loss: 0.3698322135115545
Validation loss: 2.3337568282943812

Epoch: 383| Step: 0
Training loss: 0.3334704678297907
Validation loss: 2.3202612733025134

Epoch: 6| Step: 1
Training loss: 0.4323050102411232
Validation loss: 2.30841055619793

Epoch: 6| Step: 2
Training loss: 0.15785459108191977
Validation loss: 2.317670297581346

Epoch: 6| Step: 3
Training loss: 0.2538385300926707
Validation loss: 2.315757671871753

Epoch: 6| Step: 4
Training loss: 0.4099371551986805
Validation loss: 2.290092145132852

Epoch: 6| Step: 5
Training loss: 0.25233725902606147
Validation loss: 2.303816778081481

Epoch: 6| Step: 6
Training loss: 0.20449644884043436
Validation loss: 2.3071482421286973

Epoch: 6| Step: 7
Training loss: 0.2709724622165741
Validation loss: 2.2759482133474345

Epoch: 6| Step: 8
Training loss: 0.15475745208897004
Validation loss: 2.28968455565739

Epoch: 6| Step: 9
Training loss: 0.3475298919788408
Validation loss: 2.264488825282702

Epoch: 6| Step: 10
Training loss: 0.32139276147039836
Validation loss: 2.294294635527764

Epoch: 6| Step: 11
Training loss: 0.42644274361495255
Validation loss: 2.25539094525247

Epoch: 6| Step: 12
Training loss: 0.3178171443130997
Validation loss: 2.2560548949498527

Epoch: 6| Step: 13
Training loss: 0.12804903040218693
Validation loss: 2.2598287183419825

Epoch: 384| Step: 0
Training loss: 0.2808903275200862
Validation loss: 2.2732238454883067

Epoch: 6| Step: 1
Training loss: 0.35847439078049037
Validation loss: 2.2737424230366727

Epoch: 6| Step: 2
Training loss: 0.09823934994613456
Validation loss: 2.2996132869518533

Epoch: 6| Step: 3
Training loss: 0.18571408417187749
Validation loss: 2.308515141314809

Epoch: 6| Step: 4
Training loss: 0.2040117148169037
Validation loss: 2.280398133505972

Epoch: 6| Step: 5
Training loss: 0.19315338722407097
Validation loss: 2.3323833488134667

Epoch: 6| Step: 6
Training loss: 0.4496593139382862
Validation loss: 2.3122754774403536

Epoch: 6| Step: 7
Training loss: 0.22700212839258901
Validation loss: 2.3392472502572152

Epoch: 6| Step: 8
Training loss: 0.4112994837049791
Validation loss: 2.35987940971004

Epoch: 6| Step: 9
Training loss: 0.23033685466147855
Validation loss: 2.342310289759355

Epoch: 6| Step: 10
Training loss: 0.4327587128692644
Validation loss: 2.3164105806377844

Epoch: 6| Step: 11
Training loss: 0.4185820741011123
Validation loss: 2.31896888896696

Epoch: 6| Step: 12
Training loss: 0.18107322548585722
Validation loss: 2.3129943900084484

Epoch: 6| Step: 13
Training loss: 0.22500889945973795
Validation loss: 2.291259898631644

Epoch: 385| Step: 0
Training loss: 0.2062606144110048
Validation loss: 2.3104266567083225

Epoch: 6| Step: 1
Training loss: 0.1365473899512943
Validation loss: 2.300075909885358

Epoch: 6| Step: 2
Training loss: 0.2239275909364011
Validation loss: 2.315782533683952

Epoch: 6| Step: 3
Training loss: 0.22812923140063457
Validation loss: 2.3262958585353166

Epoch: 6| Step: 4
Training loss: 0.2335303344892384
Validation loss: 2.281442806846438

Epoch: 6| Step: 5
Training loss: 0.31212333390169716
Validation loss: 2.2878229204356413

Epoch: 6| Step: 6
Training loss: 0.32006649712225216
Validation loss: 2.275792154649632

Epoch: 6| Step: 7
Training loss: 0.2338124358333366
Validation loss: 2.294821923181918

Epoch: 6| Step: 8
Training loss: 0.33421318960892327
Validation loss: 2.2917158503768666

Epoch: 6| Step: 9
Training loss: 0.4065962013215886
Validation loss: 2.302813323514951

Epoch: 6| Step: 10
Training loss: 0.4269321530732832
Validation loss: 2.296114115461122

Epoch: 6| Step: 11
Training loss: 0.367663501063288
Validation loss: 2.2955207306221586

Epoch: 6| Step: 12
Training loss: 0.36373987268986063
Validation loss: 2.2469935287316756

Epoch: 6| Step: 13
Training loss: 0.33938396526318365
Validation loss: 2.2759976507488675

Epoch: 386| Step: 0
Training loss: 0.385080199248628
Validation loss: 2.310389307120987

Epoch: 6| Step: 1
Training loss: 0.3057530672694615
Validation loss: 2.304396073464768

Epoch: 6| Step: 2
Training loss: 0.18601128532669833
Validation loss: 2.3330869711259963

Epoch: 6| Step: 3
Training loss: 0.26753858288033966
Validation loss: 2.3259267703619644

Epoch: 6| Step: 4
Training loss: 0.13376007322900024
Validation loss: 2.3118285218903734

Epoch: 6| Step: 5
Training loss: 0.11203876192188103
Validation loss: 2.319983943480359

Epoch: 6| Step: 6
Training loss: 0.3954584349903869
Validation loss: 2.355792195944894

Epoch: 6| Step: 7
Training loss: 0.35956357072086936
Validation loss: 2.3086343820017863

Epoch: 6| Step: 8
Training loss: 0.21783831190305009
Validation loss: 2.326886505241032

Epoch: 6| Step: 9
Training loss: 0.38374035164573655
Validation loss: 2.306273991483082

Epoch: 6| Step: 10
Training loss: 0.31912238303522394
Validation loss: 2.313390804683423

Epoch: 6| Step: 11
Training loss: 0.29717770001752614
Validation loss: 2.2792851623790407

Epoch: 6| Step: 12
Training loss: 0.3378169580318942
Validation loss: 2.3017292016663244

Epoch: 6| Step: 13
Training loss: 0.29462133340330293
Validation loss: 2.2707881936174785

Epoch: 387| Step: 0
Training loss: 0.3056700343319515
Validation loss: 2.236588689270275

Epoch: 6| Step: 1
Training loss: 0.37590846646418374
Validation loss: 2.2469263178202517

Epoch: 6| Step: 2
Training loss: 0.2535639289249648
Validation loss: 2.2537144629666113

Epoch: 6| Step: 3
Training loss: 0.34316895969394257
Validation loss: 2.2167378183412625

Epoch: 6| Step: 4
Training loss: 0.18034086443969397
Validation loss: 2.241118064109063

Epoch: 6| Step: 5
Training loss: 0.43509066856305206
Validation loss: 2.2562855375912023

Epoch: 6| Step: 6
Training loss: 0.4337066640834891
Validation loss: 2.2948173518346495

Epoch: 6| Step: 7
Training loss: 0.14204402722378523
Validation loss: 2.30968753909426

Epoch: 6| Step: 8
Training loss: 0.3220186153859592
Validation loss: 2.2998275659204928

Epoch: 6| Step: 9
Training loss: 0.2885523108413791
Validation loss: 2.3381487199261084

Epoch: 6| Step: 10
Training loss: 0.34860309506230736
Validation loss: 2.3482965628053876

Epoch: 6| Step: 11
Training loss: 0.24244590018171702
Validation loss: 2.3238061119639655

Epoch: 6| Step: 12
Training loss: 0.1864812913183435
Validation loss: 2.3468600098407957

Epoch: 6| Step: 13
Training loss: 0.34521834008848706
Validation loss: 2.3272032624360484

Epoch: 388| Step: 0
Training loss: 0.43606838941212417
Validation loss: 2.3571761436395646

Epoch: 6| Step: 1
Training loss: 0.14832614812856665
Validation loss: 2.3211903774984592

Epoch: 6| Step: 2
Training loss: 0.29517193481467324
Validation loss: 2.300094578070425

Epoch: 6| Step: 3
Training loss: 0.3054180312917667
Validation loss: 2.2912242357914034

Epoch: 6| Step: 4
Training loss: 0.2624686301878665
Validation loss: 2.28197485824985

Epoch: 6| Step: 5
Training loss: 0.33484587625530693
Validation loss: 2.2568328886225877

Epoch: 6| Step: 6
Training loss: 0.23879088947902077
Validation loss: 2.2593962300388095

Epoch: 6| Step: 7
Training loss: 0.19910246129064157
Validation loss: 2.2920888435441045

Epoch: 6| Step: 8
Training loss: 0.30553877337684776
Validation loss: 2.2922976818336966

Epoch: 6| Step: 9
Training loss: 0.42260460106113756
Validation loss: 2.2802096523329687

Epoch: 6| Step: 10
Training loss: 0.29975043187973305
Validation loss: 2.311695232668957

Epoch: 6| Step: 11
Training loss: 0.2157866680451187
Validation loss: 2.2894671231359767

Epoch: 6| Step: 12
Training loss: 0.2991784354957077
Validation loss: 2.281102390208335

Epoch: 6| Step: 13
Training loss: 0.05046820435066628
Validation loss: 2.236904599497683

Epoch: 389| Step: 0
Training loss: 0.3289972247438573
Validation loss: 2.2725152700441758

Epoch: 6| Step: 1
Training loss: 0.32335951136687324
Validation loss: 2.296583361258833

Epoch: 6| Step: 2
Training loss: 0.2109383653693639
Validation loss: 2.2964381961380367

Epoch: 6| Step: 3
Training loss: 0.12724585163506216
Validation loss: 2.31343558779676

Epoch: 6| Step: 4
Training loss: 0.38543652363049313
Validation loss: 2.3184422056433838

Epoch: 6| Step: 5
Training loss: 0.36358603131175354
Validation loss: 2.30247923583839

Epoch: 6| Step: 6
Training loss: 0.2142306683575601
Validation loss: 2.317024508552014

Epoch: 6| Step: 7
Training loss: 0.34438429096448286
Validation loss: 2.2939695926610746

Epoch: 6| Step: 8
Training loss: 0.23467300860469423
Validation loss: 2.3341170147097827

Epoch: 6| Step: 9
Training loss: 0.2751256601463485
Validation loss: 2.2934415780852437

Epoch: 6| Step: 10
Training loss: 0.19690768182546023
Validation loss: 2.3254577968447627

Epoch: 6| Step: 11
Training loss: 0.41109692922107355
Validation loss: 2.325922964456091

Epoch: 6| Step: 12
Training loss: 0.28813542086525623
Validation loss: 2.272700219345261

Epoch: 6| Step: 13
Training loss: 0.16141697651320172
Validation loss: 2.278171736423793

Epoch: 390| Step: 0
Training loss: 0.13453725455836876
Validation loss: 2.320011530822045

Epoch: 6| Step: 1
Training loss: 0.22548580011363256
Validation loss: 2.2831850339501454

Epoch: 6| Step: 2
Training loss: 0.31303443508883166
Validation loss: 2.322818767468036

Epoch: 6| Step: 3
Training loss: 0.2784126396298053
Validation loss: 2.2785504689220737

Epoch: 6| Step: 4
Training loss: 0.34158474470194256
Validation loss: 2.280137921963193

Epoch: 6| Step: 5
Training loss: 0.24138787764477787
Validation loss: 2.2881982018541596

Epoch: 6| Step: 6
Training loss: 0.21699087381179855
Validation loss: 2.2478934559499124

Epoch: 6| Step: 7
Training loss: 0.296820786193995
Validation loss: 2.2475306663057655

Epoch: 6| Step: 8
Training loss: 0.3221488162959316
Validation loss: 2.2720242444753422

Epoch: 6| Step: 9
Training loss: 0.21662509401696878
Validation loss: 2.2516017098493397

Epoch: 6| Step: 10
Training loss: 0.2518554024846026
Validation loss: 2.26307072683529

Epoch: 6| Step: 11
Training loss: 0.26488105994993366
Validation loss: 2.246868277287002

Epoch: 6| Step: 12
Training loss: 0.5078169015546924
Validation loss: 2.2486913315059134

Epoch: 6| Step: 13
Training loss: 0.2699551220966983
Validation loss: 2.2547175766203615

Epoch: 391| Step: 0
Training loss: 0.24478007688208356
Validation loss: 2.2830336272285714

Epoch: 6| Step: 1
Training loss: 0.36914016077728956
Validation loss: 2.2653039808783104

Epoch: 6| Step: 2
Training loss: 0.34566616140912343
Validation loss: 2.3024714991836546

Epoch: 6| Step: 3
Training loss: 0.3066067889552157
Validation loss: 2.2855368177487967

Epoch: 6| Step: 4
Training loss: 0.3518776117197414
Validation loss: 2.295701290195775

Epoch: 6| Step: 5
Training loss: 0.31017434670336536
Validation loss: 2.2904224722948343

Epoch: 6| Step: 6
Training loss: 0.26777215869690024
Validation loss: 2.264408750599055

Epoch: 6| Step: 7
Training loss: 0.2824923705657422
Validation loss: 2.2589464504800167

Epoch: 6| Step: 8
Training loss: 0.2641595780512604
Validation loss: 2.3011592595759396

Epoch: 6| Step: 9
Training loss: 0.4039592162180488
Validation loss: 2.263906579806524

Epoch: 6| Step: 10
Training loss: 0.24476328982917422
Validation loss: 2.2327716391799637

Epoch: 6| Step: 11
Training loss: 0.16583843873502216
Validation loss: 2.2544963964980123

Epoch: 6| Step: 12
Training loss: 0.2758045197522485
Validation loss: 2.244773656441985

Epoch: 6| Step: 13
Training loss: 0.2817122581271347
Validation loss: 2.2678980309360264

Epoch: 392| Step: 0
Training loss: 0.24202807624464825
Validation loss: 2.2832748140914525

Epoch: 6| Step: 1
Training loss: 0.3033091963716415
Validation loss: 2.2967638456654584

Epoch: 6| Step: 2
Training loss: 0.17757652944912872
Validation loss: 2.2784209027117623

Epoch: 6| Step: 3
Training loss: 0.24002662452648232
Validation loss: 2.274103802612204

Epoch: 6| Step: 4
Training loss: 0.19434432390223044
Validation loss: 2.3088855204026295

Epoch: 6| Step: 5
Training loss: 0.2860411799959922
Validation loss: 2.3240671283656793

Epoch: 6| Step: 6
Training loss: 0.48315725764157247
Validation loss: 2.3185391024724202

Epoch: 6| Step: 7
Training loss: 0.1715541847399178
Validation loss: 2.314225253629699

Epoch: 6| Step: 8
Training loss: 0.33753202957474393
Validation loss: 2.3320922612725044

Epoch: 6| Step: 9
Training loss: 0.3204562864665188
Validation loss: 2.2853291724734754

Epoch: 6| Step: 10
Training loss: 0.24486466428608486
Validation loss: 2.31636255138641

Epoch: 6| Step: 11
Training loss: 0.39324869229510945
Validation loss: 2.3175151103324985

Epoch: 6| Step: 12
Training loss: 0.11838177258171903
Validation loss: 2.317324655946515

Epoch: 6| Step: 13
Training loss: 0.3146479340826894
Validation loss: 2.3134353102044116

Epoch: 393| Step: 0
Training loss: 0.4313734617280463
Validation loss: 2.3179990570657263

Epoch: 6| Step: 1
Training loss: 0.15790365862763095
Validation loss: 2.3145790858840933

Epoch: 6| Step: 2
Training loss: 0.3475753711532184
Validation loss: 2.3149012484724047

Epoch: 6| Step: 3
Training loss: 0.2011825040212947
Validation loss: 2.3144913602008668

Epoch: 6| Step: 4
Training loss: 0.2792160077165832
Validation loss: 2.2673022575545763

Epoch: 6| Step: 5
Training loss: 0.3217695984899542
Validation loss: 2.2947320094099313

Epoch: 6| Step: 6
Training loss: 0.1797969111837608
Validation loss: 2.281455427566129

Epoch: 6| Step: 7
Training loss: 0.26052218524674114
Validation loss: 2.25799050253765

Epoch: 6| Step: 8
Training loss: 0.30855234085583444
Validation loss: 2.2449820586480027

Epoch: 6| Step: 9
Training loss: 0.32751588824730976
Validation loss: 2.277795839659101

Epoch: 6| Step: 10
Training loss: 0.18037489353673783
Validation loss: 2.2720532905105006

Epoch: 6| Step: 11
Training loss: 0.3541112697510061
Validation loss: 2.2495553341802337

Epoch: 6| Step: 12
Training loss: 0.2565643992800928
Validation loss: 2.283481428620521

Epoch: 6| Step: 13
Training loss: 0.25139639209792597
Validation loss: 2.2781337052601556

Epoch: 394| Step: 0
Training loss: 0.38094900005903787
Validation loss: 2.312670505471484

Epoch: 6| Step: 1
Training loss: 0.29263168017972385
Validation loss: 2.287526198452916

Epoch: 6| Step: 2
Training loss: 0.3374523451504177
Validation loss: 2.3432813415115312

Epoch: 6| Step: 3
Training loss: 0.21237648115882088
Validation loss: 2.3329696456074283

Epoch: 6| Step: 4
Training loss: 0.20940495888750765
Validation loss: 2.369474119600949

Epoch: 6| Step: 5
Training loss: 0.23483669582592104
Validation loss: 2.3425187987786096

Epoch: 6| Step: 6
Training loss: 0.32345935637114775
Validation loss: 2.3074713399768836

Epoch: 6| Step: 7
Training loss: 0.18388326624436568
Validation loss: 2.3676592901134232

Epoch: 6| Step: 8
Training loss: 0.2119458609776415
Validation loss: 2.3319665741096776

Epoch: 6| Step: 9
Training loss: 0.19375803338593475
Validation loss: 2.344762413645771

Epoch: 6| Step: 10
Training loss: 0.4036064333811283
Validation loss: 2.3109910909455134

Epoch: 6| Step: 11
Training loss: 0.3476348613203098
Validation loss: 2.2829115847353383

Epoch: 6| Step: 12
Training loss: 0.20087095549950165
Validation loss: 2.2811162158970277

Epoch: 6| Step: 13
Training loss: 0.4203749053743989
Validation loss: 2.277880367030035

Epoch: 395| Step: 0
Training loss: 0.28454235046871723
Validation loss: 2.2969042572664966

Epoch: 6| Step: 1
Training loss: 0.2025594724930901
Validation loss: 2.286568073486442

Epoch: 6| Step: 2
Training loss: 0.22080626651744742
Validation loss: 2.260848094956296

Epoch: 6| Step: 3
Training loss: 0.26794582357840874
Validation loss: 2.3013885644737844

Epoch: 6| Step: 4
Training loss: 0.19366180004398906
Validation loss: 2.3195130715465897

Epoch: 6| Step: 5
Training loss: 0.3400846263457731
Validation loss: 2.3186574395755244

Epoch: 6| Step: 6
Training loss: 0.3867016605492968
Validation loss: 2.3201434196507837

Epoch: 6| Step: 7
Training loss: 0.14547425721639856
Validation loss: 2.3141644603605545

Epoch: 6| Step: 8
Training loss: 0.2253687915772025
Validation loss: 2.3470638329551208

Epoch: 6| Step: 9
Training loss: 0.4887929447751251
Validation loss: 2.3058636177799166

Epoch: 6| Step: 10
Training loss: 0.26499703452862217
Validation loss: 2.313312376184277

Epoch: 6| Step: 11
Training loss: 0.27465352372315893
Validation loss: 2.3176455998177516

Epoch: 6| Step: 12
Training loss: 0.3137101108529209
Validation loss: 2.3141777716950807

Epoch: 6| Step: 13
Training loss: 0.2497792088546788
Validation loss: 2.29064889347057

Epoch: 396| Step: 0
Training loss: 0.4294802772914094
Validation loss: 2.273531377137035

Epoch: 6| Step: 1
Training loss: 0.20862984220029154
Validation loss: 2.2990060161848054

Epoch: 6| Step: 2
Training loss: 0.33705742038921915
Validation loss: 2.2853414924087074

Epoch: 6| Step: 3
Training loss: 0.30045424681766586
Validation loss: 2.281546251651533

Epoch: 6| Step: 4
Training loss: 0.16323928704461174
Validation loss: 2.3060327062433776

Epoch: 6| Step: 5
Training loss: 0.16658430871022767
Validation loss: 2.2834076336082685

Epoch: 6| Step: 6
Training loss: 0.20625752594250502
Validation loss: 2.336772537195242

Epoch: 6| Step: 7
Training loss: 0.20348532518869317
Validation loss: 2.3299648417355687

Epoch: 6| Step: 8
Training loss: 0.23042508697702646
Validation loss: 2.343557090340274

Epoch: 6| Step: 9
Training loss: 0.31624575653546344
Validation loss: 2.3055266468153017

Epoch: 6| Step: 10
Training loss: 0.242761040491496
Validation loss: 2.345474212732002

Epoch: 6| Step: 11
Training loss: 0.3597432198935995
Validation loss: 2.3378426033413433

Epoch: 6| Step: 12
Training loss: 0.25611730489346185
Validation loss: 2.3152649149765314

Epoch: 6| Step: 13
Training loss: 0.3950221718227179
Validation loss: 2.3185577364390206

Epoch: 397| Step: 0
Training loss: 0.2574086638839111
Validation loss: 2.3060705830187285

Epoch: 6| Step: 1
Training loss: 0.30901596303326184
Validation loss: 2.271616587750397

Epoch: 6| Step: 2
Training loss: 0.3272848271983328
Validation loss: 2.264202824877021

Epoch: 6| Step: 3
Training loss: 0.1517823156559342
Validation loss: 2.267846079806673

Epoch: 6| Step: 4
Training loss: 0.20891458469047575
Validation loss: 2.243752805166679

Epoch: 6| Step: 5
Training loss: 0.36934783206307065
Validation loss: 2.291060721831764

Epoch: 6| Step: 6
Training loss: 0.40362264094840283
Validation loss: 2.2961033310393533

Epoch: 6| Step: 7
Training loss: 0.3716057507918416
Validation loss: 2.3238272559452264

Epoch: 6| Step: 8
Training loss: 0.35045264215141436
Validation loss: 2.341480293151423

Epoch: 6| Step: 9
Training loss: 0.16421041178926551
Validation loss: 2.350816771901599

Epoch: 6| Step: 10
Training loss: 0.3819000502516161
Validation loss: 2.3507242460843805

Epoch: 6| Step: 11
Training loss: 0.12728663433270956
Validation loss: 2.351105410336874

Epoch: 6| Step: 12
Training loss: 0.2436085281269268
Validation loss: 2.3387971695491534

Epoch: 6| Step: 13
Training loss: 0.1985695771092929
Validation loss: 2.324900678536979

Epoch: 398| Step: 0
Training loss: 0.30571286966579375
Validation loss: 2.351726797835481

Epoch: 6| Step: 1
Training loss: 0.34177176247032215
Validation loss: 2.3036349065278143

Epoch: 6| Step: 2
Training loss: 0.2603054317691675
Validation loss: 2.289676059193102

Epoch: 6| Step: 3
Training loss: 0.40791516893415164
Validation loss: 2.28928410877855

Epoch: 6| Step: 4
Training loss: 0.23615778940023904
Validation loss: 2.280635605474249

Epoch: 6| Step: 5
Training loss: 0.13068218476164897
Validation loss: 2.2774471243385084

Epoch: 6| Step: 6
Training loss: 0.20616931348498094
Validation loss: 2.2629007981942464

Epoch: 6| Step: 7
Training loss: 0.33271776919678525
Validation loss: 2.289704957791571

Epoch: 6| Step: 8
Training loss: 0.24930753770557992
Validation loss: 2.2968948315407527

Epoch: 6| Step: 9
Training loss: 0.3328840523576529
Validation loss: 2.27871694502493

Epoch: 6| Step: 10
Training loss: 0.28559932514045494
Validation loss: 2.3347758388005757

Epoch: 6| Step: 11
Training loss: 0.23578203175884707
Validation loss: 2.2996583790558973

Epoch: 6| Step: 12
Training loss: 0.16293919980238353
Validation loss: 2.2959650544986983

Epoch: 6| Step: 13
Training loss: 0.21420425260251064
Validation loss: 2.305546586296438

Epoch: 399| Step: 0
Training loss: 0.1580914821646837
Validation loss: 2.275819457048599

Epoch: 6| Step: 1
Training loss: 0.3260930931293066
Validation loss: 2.271728337745527

Epoch: 6| Step: 2
Training loss: 0.2542864666990029
Validation loss: 2.32691854052314

Epoch: 6| Step: 3
Training loss: 0.40227130126504446
Validation loss: 2.2907115888855905

Epoch: 6| Step: 4
Training loss: 0.19485628251408496
Validation loss: 2.290893407076873

Epoch: 6| Step: 5
Training loss: 0.15857845101063175
Validation loss: 2.2881545555394145

Epoch: 6| Step: 6
Training loss: 0.24013518790198846
Validation loss: 2.3391621270814777

Epoch: 6| Step: 7
Training loss: 0.44968502889647444
Validation loss: 2.3196436122060335

Epoch: 6| Step: 8
Training loss: 0.28509331361385365
Validation loss: 2.306870261310829

Epoch: 6| Step: 9
Training loss: 0.2856607546641554
Validation loss: 2.317728302221953

Epoch: 6| Step: 10
Training loss: 0.36523735330764695
Validation loss: 2.2721876260701612

Epoch: 6| Step: 11
Training loss: 0.16166341290956154
Validation loss: 2.2943589073704627

Epoch: 6| Step: 12
Training loss: 0.2127446715475466
Validation loss: 2.299886535549434

Epoch: 6| Step: 13
Training loss: 0.15322627688738039
Validation loss: 2.2963473989449823

Epoch: 400| Step: 0
Training loss: 0.32699197472267033
Validation loss: 2.265961029400637

Epoch: 6| Step: 1
Training loss: 0.27844343975423436
Validation loss: 2.298618376328105

Epoch: 6| Step: 2
Training loss: 0.1375846418042793
Validation loss: 2.3033392370276053

Epoch: 6| Step: 3
Training loss: 0.3940449351813542
Validation loss: 2.3287349259032406

Epoch: 6| Step: 4
Training loss: 0.2868939064793494
Validation loss: 2.2845531839158655

Epoch: 6| Step: 5
Training loss: 0.20887730431441348
Validation loss: 2.297295442670877

Epoch: 6| Step: 6
Training loss: 0.2882769840203963
Validation loss: 2.2639414290507585

Epoch: 6| Step: 7
Training loss: 0.23148382647085972
Validation loss: 2.2398302595075648

Epoch: 6| Step: 8
Training loss: 0.3314333974824255
Validation loss: 2.26666823411371

Epoch: 6| Step: 9
Training loss: 0.25422050395752066
Validation loss: 2.270182975249172

Epoch: 6| Step: 10
Training loss: 0.1946122203972642
Validation loss: 2.2682940632972954

Epoch: 6| Step: 11
Training loss: 0.19679034926076977
Validation loss: 2.302108321687398

Epoch: 6| Step: 12
Training loss: 0.26802998001724637
Validation loss: 2.26410119988157

Epoch: 6| Step: 13
Training loss: 0.3836465041794903
Validation loss: 2.2781144373653492

Epoch: 401| Step: 0
Training loss: 0.21433847138395018
Validation loss: 2.2387941630344503

Epoch: 6| Step: 1
Training loss: 0.1913123581707244
Validation loss: 2.2740595966189643

Epoch: 6| Step: 2
Training loss: 0.22419375237072517
Validation loss: 2.2740503084374395

Epoch: 6| Step: 3
Training loss: 0.250689880862898
Validation loss: 2.293373692248724

Epoch: 6| Step: 4
Training loss: 0.399563936128009
Validation loss: 2.309040395676672

Epoch: 6| Step: 5
Training loss: 0.26495861162112166
Validation loss: 2.330899165027469

Epoch: 6| Step: 6
Training loss: 0.25034473909271465
Validation loss: 2.2853248603402303

Epoch: 6| Step: 7
Training loss: 0.16478878998827692
Validation loss: 2.250537317077149

Epoch: 6| Step: 8
Training loss: 0.26461470835930717
Validation loss: 2.2735204517660246

Epoch: 6| Step: 9
Training loss: 0.37172079816128095
Validation loss: 2.303201620861319

Epoch: 6| Step: 10
Training loss: 0.2148091548462766
Validation loss: 2.270726547334498

Epoch: 6| Step: 11
Training loss: 0.20312248741943423
Validation loss: 2.2850513586682535

Epoch: 6| Step: 12
Training loss: 0.42593094180481544
Validation loss: 2.2789135896141564

Epoch: 6| Step: 13
Training loss: 0.15461791115665136
Validation loss: 2.256560506376513

Epoch: 402| Step: 0
Training loss: 0.21283007994481318
Validation loss: 2.287189416563738

Epoch: 6| Step: 1
Training loss: 0.19966511181497681
Validation loss: 2.2876163831189382

Epoch: 6| Step: 2
Training loss: 0.226744414335385
Validation loss: 2.2638485573141836

Epoch: 6| Step: 3
Training loss: 0.2625441701375455
Validation loss: 2.264210750603834

Epoch: 6| Step: 4
Training loss: 0.26952154722578947
Validation loss: 2.2865389564127026

Epoch: 6| Step: 5
Training loss: 0.13837734698034254
Validation loss: 2.2684317939881744

Epoch: 6| Step: 6
Training loss: 0.36647969874169783
Validation loss: 2.2607215112306625

Epoch: 6| Step: 7
Training loss: 0.39282778492446974
Validation loss: 2.294153722821136

Epoch: 6| Step: 8
Training loss: 0.18167403129281579
Validation loss: 2.2969067992480783

Epoch: 6| Step: 9
Training loss: 0.22186139091877743
Validation loss: 2.278207205797107

Epoch: 6| Step: 10
Training loss: 0.12694243606171735
Validation loss: 2.2564526122412762

Epoch: 6| Step: 11
Training loss: 0.3601058080604728
Validation loss: 2.293488713014112

Epoch: 6| Step: 12
Training loss: 0.30099073769015294
Validation loss: 2.2978289862789034

Epoch: 6| Step: 13
Training loss: 0.25068683451276735
Validation loss: 2.276289887321486

Epoch: 403| Step: 0
Training loss: 0.18205026355379636
Validation loss: 2.2761475209513553

Epoch: 6| Step: 1
Training loss: 0.2889432403337501
Validation loss: 2.2688222749943368

Epoch: 6| Step: 2
Training loss: 0.3034320421641436
Validation loss: 2.277998869338964

Epoch: 6| Step: 3
Training loss: 0.20130210660972972
Validation loss: 2.2622497401148793

Epoch: 6| Step: 4
Training loss: 0.17399211177744633
Validation loss: 2.2584038302238905

Epoch: 6| Step: 5
Training loss: 0.20706064987162065
Validation loss: 2.303839551006308

Epoch: 6| Step: 6
Training loss: 0.2699638157457761
Validation loss: 2.2623231595145965

Epoch: 6| Step: 7
Training loss: 0.2502325436765965
Validation loss: 2.2929893638490775

Epoch: 6| Step: 8
Training loss: 0.22000220916733418
Validation loss: 2.283790231555962

Epoch: 6| Step: 9
Training loss: 0.2544348715869186
Validation loss: 2.306886428545676

Epoch: 6| Step: 10
Training loss: 0.27535508650225166
Validation loss: 2.298742349324808

Epoch: 6| Step: 11
Training loss: 0.4045336854462819
Validation loss: 2.2932273748382532

Epoch: 6| Step: 12
Training loss: 0.27546248614394314
Validation loss: 2.2960192590464374

Epoch: 6| Step: 13
Training loss: 0.4414325132405633
Validation loss: 2.3226453215314287

Epoch: 404| Step: 0
Training loss: 0.2757085223384411
Validation loss: 2.2924954833199136

Epoch: 6| Step: 1
Training loss: 0.2711744941270621
Validation loss: 2.2740266881695175

Epoch: 6| Step: 2
Training loss: 0.19902391817373644
Validation loss: 2.293911855892273

Epoch: 6| Step: 3
Training loss: 0.11243573711045922
Validation loss: 2.2507184412955947

Epoch: 6| Step: 4
Training loss: 0.21863472830522743
Validation loss: 2.2733047537372

Epoch: 6| Step: 5
Training loss: 0.1796943414463766
Validation loss: 2.3002474808979647

Epoch: 6| Step: 6
Training loss: 0.23660311187796101
Validation loss: 2.268379376176295

Epoch: 6| Step: 7
Training loss: 0.32551560079819586
Validation loss: 2.309157086298165

Epoch: 6| Step: 8
Training loss: 0.12696401842771138
Validation loss: 2.2749193371276197

Epoch: 6| Step: 9
Training loss: 0.3620963718750335
Validation loss: 2.2808812644531136

Epoch: 6| Step: 10
Training loss: 0.24155679995830437
Validation loss: 2.309711319122996

Epoch: 6| Step: 11
Training loss: 0.4698927936132883
Validation loss: 2.293323486959941

Epoch: 6| Step: 12
Training loss: 0.20961593849407437
Validation loss: 2.275355458180374

Epoch: 6| Step: 13
Training loss: 0.14986565230945
Validation loss: 2.3061401260978935

Epoch: 405| Step: 0
Training loss: 0.2413548260456002
Validation loss: 2.2738133959716103

Epoch: 6| Step: 1
Training loss: 0.44863337648362084
Validation loss: 2.3307398440364566

Epoch: 6| Step: 2
Training loss: 0.3573403604244106
Validation loss: 2.3353992917249884

Epoch: 6| Step: 3
Training loss: 0.331081276785132
Validation loss: 2.290080529703862

Epoch: 6| Step: 4
Training loss: 0.15163928156615808
Validation loss: 2.2996451274858756

Epoch: 6| Step: 5
Training loss: 0.26781563068193637
Validation loss: 2.2701303553569514

Epoch: 6| Step: 6
Training loss: 0.22761406706017537
Validation loss: 2.297226683085687

Epoch: 6| Step: 7
Training loss: 0.1837659494945151
Validation loss: 2.3472129828229615

Epoch: 6| Step: 8
Training loss: 0.294238619039793
Validation loss: 2.330732178641705

Epoch: 6| Step: 9
Training loss: 0.36342433449670536
Validation loss: 2.3352787346766797

Epoch: 6| Step: 10
Training loss: 0.1279414440897228
Validation loss: 2.319907294906311

Epoch: 6| Step: 11
Training loss: 0.25043436403360314
Validation loss: 2.3244520627812357

Epoch: 6| Step: 12
Training loss: 0.1332072254567775
Validation loss: 2.3561678660615137

Epoch: 6| Step: 13
Training loss: 0.12439345558936463
Validation loss: 2.3139475997830243

Epoch: 406| Step: 0
Training loss: 0.2140537650003774
Validation loss: 2.343363673593805

Epoch: 6| Step: 1
Training loss: 0.2888188882082872
Validation loss: 2.336502049502418

Epoch: 6| Step: 2
Training loss: 0.2910690002649368
Validation loss: 2.3372750673466323

Epoch: 6| Step: 3
Training loss: 0.34879835456691893
Validation loss: 2.3232735326111666

Epoch: 6| Step: 4
Training loss: 0.21970404615535347
Validation loss: 2.321743951704031

Epoch: 6| Step: 5
Training loss: 0.15781833217721597
Validation loss: 2.332344466035701

Epoch: 6| Step: 6
Training loss: 0.3377550106552228
Validation loss: 2.286209851640868

Epoch: 6| Step: 7
Training loss: 0.18274513902800685
Validation loss: 2.279090892918448

Epoch: 6| Step: 8
Training loss: 0.230073622447388
Validation loss: 2.287647930606725

Epoch: 6| Step: 9
Training loss: 0.2793576367847588
Validation loss: 2.270534129515652

Epoch: 6| Step: 10
Training loss: 0.28782761193446077
Validation loss: 2.310621431453416

Epoch: 6| Step: 11
Training loss: 0.30953582186454104
Validation loss: 2.3000975272486186

Epoch: 6| Step: 12
Training loss: 0.25646571755850484
Validation loss: 2.2815439908832014

Epoch: 6| Step: 13
Training loss: 0.27622687076819297
Validation loss: 2.3077782830940934

Epoch: 407| Step: 0
Training loss: 0.2527531630122874
Validation loss: 2.2908358756266547

Epoch: 6| Step: 1
Training loss: 0.25384390138844415
Validation loss: 2.3007847075085808

Epoch: 6| Step: 2
Training loss: 0.1765285607016788
Validation loss: 2.2791775448306266

Epoch: 6| Step: 3
Training loss: 0.2199035270991793
Validation loss: 2.2923740152961756

Epoch: 6| Step: 4
Training loss: 0.340283711969874
Validation loss: 2.271995690811835

Epoch: 6| Step: 5
Training loss: 0.2411684392641717
Validation loss: 2.268422474852303

Epoch: 6| Step: 6
Training loss: 0.1420765375677718
Validation loss: 2.2761450518037365

Epoch: 6| Step: 7
Training loss: 0.3329720128300951
Validation loss: 2.2564890328260767

Epoch: 6| Step: 8
Training loss: 0.259491252125127
Validation loss: 2.231695788297469

Epoch: 6| Step: 9
Training loss: 0.31524187289447725
Validation loss: 2.2325896314022495

Epoch: 6| Step: 10
Training loss: 0.1770250502676664
Validation loss: 2.291900039118575

Epoch: 6| Step: 11
Training loss: 0.40656814588867884
Validation loss: 2.2763093531090077

Epoch: 6| Step: 12
Training loss: 0.3046023543302869
Validation loss: 2.291362534941593

Epoch: 6| Step: 13
Training loss: 0.2672950193671101
Validation loss: 2.3094017561328455

Epoch: 408| Step: 0
Training loss: 0.16181191188945548
Validation loss: 2.3330437305436305

Epoch: 6| Step: 1
Training loss: 0.15924860626625872
Validation loss: 2.3631871599901566

Epoch: 6| Step: 2
Training loss: 0.1876740343336316
Validation loss: 2.356014662912332

Epoch: 6| Step: 3
Training loss: 0.34155428315493874
Validation loss: 2.362789859939258

Epoch: 6| Step: 4
Training loss: 0.3418928828958341
Validation loss: 2.3317908470274533

Epoch: 6| Step: 5
Training loss: 0.37824224514395965
Validation loss: 2.3220494652514834

Epoch: 6| Step: 6
Training loss: 0.3671642255508571
Validation loss: 2.3201326463709875

Epoch: 6| Step: 7
Training loss: 0.2694050175388944
Validation loss: 2.2803903966969807

Epoch: 6| Step: 8
Training loss: 0.18366891255782536
Validation loss: 2.289109779414781

Epoch: 6| Step: 9
Training loss: 0.2911257183562376
Validation loss: 2.2666014344085372

Epoch: 6| Step: 10
Training loss: 0.2345523639961948
Validation loss: 2.2720031969661445

Epoch: 6| Step: 11
Training loss: 0.27598094572243176
Validation loss: 2.2645745857576154

Epoch: 6| Step: 12
Training loss: 0.29026260495394846
Validation loss: 2.2386535771239924

Epoch: 6| Step: 13
Training loss: 0.3192460869890608
Validation loss: 2.2462427878277875

Epoch: 409| Step: 0
Training loss: 0.2141192618523696
Validation loss: 2.223762800056977

Epoch: 6| Step: 1
Training loss: 0.3185291071853111
Validation loss: 2.2138687380508317

Epoch: 6| Step: 2
Training loss: 0.32930896234557877
Validation loss: 2.2284002860294625

Epoch: 6| Step: 3
Training loss: 0.3704708292052874
Validation loss: 2.209799164155566

Epoch: 6| Step: 4
Training loss: 0.23337802239040836
Validation loss: 2.2562183001009384

Epoch: 6| Step: 5
Training loss: 0.2931812787067808
Validation loss: 2.254446009996559

Epoch: 6| Step: 6
Training loss: 0.2983932821859923
Validation loss: 2.235370861816987

Epoch: 6| Step: 7
Training loss: 0.27084346287686717
Validation loss: 2.2823688237500654

Epoch: 6| Step: 8
Training loss: 0.2824726813534743
Validation loss: 2.235615077021786

Epoch: 6| Step: 9
Training loss: 0.21436883280810964
Validation loss: 2.288111084297723

Epoch: 6| Step: 10
Training loss: 0.38095146435247007
Validation loss: 2.305422574424631

Epoch: 6| Step: 11
Training loss: 0.23906913635915997
Validation loss: 2.2781725151355063

Epoch: 6| Step: 12
Training loss: 0.26597761143043225
Validation loss: 2.2949875345395805

Epoch: 6| Step: 13
Training loss: 0.24365858173220928
Validation loss: 2.3294678772652793

Epoch: 410| Step: 0
Training loss: 0.26107024511054505
Validation loss: 2.31582557460865

Epoch: 6| Step: 1
Training loss: 0.17269852970684127
Validation loss: 2.331015670380204

Epoch: 6| Step: 2
Training loss: 0.339163944345151
Validation loss: 2.3550327597962335

Epoch: 6| Step: 3
Training loss: 0.4405832974334254
Validation loss: 2.2936909415207545

Epoch: 6| Step: 4
Training loss: 0.404467560494121
Validation loss: 2.3353198519588534

Epoch: 6| Step: 5
Training loss: 0.24579209049760828
Validation loss: 2.3201534111324893

Epoch: 6| Step: 6
Training loss: 0.2676286301667317
Validation loss: 2.286754109044627

Epoch: 6| Step: 7
Training loss: 0.24624837074854236
Validation loss: 2.259185569938499

Epoch: 6| Step: 8
Training loss: 0.19098525556729443
Validation loss: 2.2766410016202774

Epoch: 6| Step: 9
Training loss: 0.2090032337271655
Validation loss: 2.2253414252041717

Epoch: 6| Step: 10
Training loss: 0.2875150293070712
Validation loss: 2.2597178110408374

Epoch: 6| Step: 11
Training loss: 0.3432604598433307
Validation loss: 2.272551489326497

Epoch: 6| Step: 12
Training loss: 0.2657687695694151
Validation loss: 2.291360885788481

Epoch: 6| Step: 13
Training loss: 0.23272106404061335
Validation loss: 2.298633515310613

Epoch: 411| Step: 0
Training loss: 0.19449907672584493
Validation loss: 2.337904528260751

Epoch: 6| Step: 1
Training loss: 0.20191258110201096
Validation loss: 2.319532820060377

Epoch: 6| Step: 2
Training loss: 0.39186907071703536
Validation loss: 2.3307507409748127

Epoch: 6| Step: 3
Training loss: 0.3242035942671752
Validation loss: 2.2893049388984688

Epoch: 6| Step: 4
Training loss: 0.3385723931478174
Validation loss: 2.3163379116187737

Epoch: 6| Step: 5
Training loss: 0.1864653392004805
Validation loss: 2.248465432160285

Epoch: 6| Step: 6
Training loss: 0.46538627444454755
Validation loss: 2.261951540322075

Epoch: 6| Step: 7
Training loss: 0.285169379049649
Validation loss: 2.25582800004656

Epoch: 6| Step: 8
Training loss: 0.31769647211331997
Validation loss: 2.2648502472135914

Epoch: 6| Step: 9
Training loss: 0.2783243279418397
Validation loss: 2.267065691284082

Epoch: 6| Step: 10
Training loss: 0.17092950810957808
Validation loss: 2.2517397158228327

Epoch: 6| Step: 11
Training loss: 0.424907347453067
Validation loss: 2.264146024910081

Epoch: 6| Step: 12
Training loss: 0.29976355553201733
Validation loss: 2.2563322761556956

Epoch: 6| Step: 13
Training loss: 0.30904427971278875
Validation loss: 2.284069662925263

Epoch: 412| Step: 0
Training loss: 0.3722976830879926
Validation loss: 2.321141447049906

Epoch: 6| Step: 1
Training loss: 0.32571378965387837
Validation loss: 2.337576244927631

Epoch: 6| Step: 2
Training loss: 0.2746427947066801
Validation loss: 2.3226107703070284

Epoch: 6| Step: 3
Training loss: 0.43188911293476945
Validation loss: 2.320965991944912

Epoch: 6| Step: 4
Training loss: 0.1929069582272495
Validation loss: 2.309121376237929

Epoch: 6| Step: 5
Training loss: 0.3007834545896911
Validation loss: 2.30552825803675

Epoch: 6| Step: 6
Training loss: 0.3950780158017298
Validation loss: 2.319404471610532

Epoch: 6| Step: 7
Training loss: 0.4545927283239576
Validation loss: 2.2636854707926353

Epoch: 6| Step: 8
Training loss: 0.3407571728651795
Validation loss: 2.242515687154955

Epoch: 6| Step: 9
Training loss: 0.23942286189696868
Validation loss: 2.2472196443445616

Epoch: 6| Step: 10
Training loss: 0.20108308962447408
Validation loss: 2.231673235524213

Epoch: 6| Step: 11
Training loss: 0.372813326442215
Validation loss: 2.2884502701610145

Epoch: 6| Step: 12
Training loss: 0.20279379582082585
Validation loss: 2.3145527623809654

Epoch: 6| Step: 13
Training loss: 0.2986986715123761
Validation loss: 2.3254178159899617

Epoch: 413| Step: 0
Training loss: 0.2777046219867977
Validation loss: 2.3921742436364193

Epoch: 6| Step: 1
Training loss: 0.3786402289576174
Validation loss: 2.347269705321873

Epoch: 6| Step: 2
Training loss: 0.3830460594957491
Validation loss: 2.376421086052124

Epoch: 6| Step: 3
Training loss: 0.37107019851637524
Validation loss: 2.3460198112357453

Epoch: 6| Step: 4
Training loss: 0.2373299133958716
Validation loss: 2.3430473723752323

Epoch: 6| Step: 5
Training loss: 0.16462128710633012
Validation loss: 2.330956751938882

Epoch: 6| Step: 6
Training loss: 0.3871369268349498
Validation loss: 2.3184575032295287

Epoch: 6| Step: 7
Training loss: 0.19420738377230184
Validation loss: 2.309880921694586

Epoch: 6| Step: 8
Training loss: 0.195080963224114
Validation loss: 2.2850871733812794

Epoch: 6| Step: 9
Training loss: 0.1802149784281529
Validation loss: 2.279632644011877

Epoch: 6| Step: 10
Training loss: 0.3788955333020064
Validation loss: 2.290932772930894

Epoch: 6| Step: 11
Training loss: 0.25313867308339316
Validation loss: 2.2823566646794053

Epoch: 6| Step: 12
Training loss: 0.28055590176062634
Validation loss: 2.2341172261597655

Epoch: 6| Step: 13
Training loss: 0.30217680498939437
Validation loss: 2.284053687183721

Epoch: 414| Step: 0
Training loss: 0.2580251539179437
Validation loss: 2.2876928019029577

Epoch: 6| Step: 1
Training loss: 0.2566893416664443
Validation loss: 2.284049784567003

Epoch: 6| Step: 2
Training loss: 0.15473024856502793
Validation loss: 2.305257351300408

Epoch: 6| Step: 3
Training loss: 0.35940566139448293
Validation loss: 2.3021412845240987

Epoch: 6| Step: 4
Training loss: 0.3609462885591704
Validation loss: 2.314292812511053

Epoch: 6| Step: 5
Training loss: 0.3304269628956988
Validation loss: 2.3286279758691935

Epoch: 6| Step: 6
Training loss: 0.32633183605740634
Validation loss: 2.297251156779071

Epoch: 6| Step: 7
Training loss: 0.3077567253315347
Validation loss: 2.302593202763831

Epoch: 6| Step: 8
Training loss: 0.26389581565940196
Validation loss: 2.2775205659877114

Epoch: 6| Step: 9
Training loss: 0.1822862533492178
Validation loss: 2.2665814336719303

Epoch: 6| Step: 10
Training loss: 0.3058583674895353
Validation loss: 2.2517302581544647

Epoch: 6| Step: 11
Training loss: 0.2291690418091426
Validation loss: 2.260985407856165

Epoch: 6| Step: 12
Training loss: 0.40487294458784423
Validation loss: 2.258177799138799

Epoch: 6| Step: 13
Training loss: 0.3044230218012155
Validation loss: 2.2897697240140418

Epoch: 415| Step: 0
Training loss: 0.4802962823238245
Validation loss: 2.2833918800270268

Epoch: 6| Step: 1
Training loss: 0.3137153832841752
Validation loss: 2.3008368904094683

Epoch: 6| Step: 2
Training loss: 0.1831184484331878
Validation loss: 2.333792450851478

Epoch: 6| Step: 3
Training loss: 0.3196719323932983
Validation loss: 2.361996660003714

Epoch: 6| Step: 4
Training loss: 0.2146306802001314
Validation loss: 2.397536976344023

Epoch: 6| Step: 5
Training loss: 0.18590281627842095
Validation loss: 2.4057181880940823

Epoch: 6| Step: 6
Training loss: 0.3430210099778279
Validation loss: 2.333579382983392

Epoch: 6| Step: 7
Training loss: 0.18772272947769456
Validation loss: 2.3523283498212546

Epoch: 6| Step: 8
Training loss: 0.2812099693208548
Validation loss: 2.358113716222666

Epoch: 6| Step: 9
Training loss: 0.3091614728081766
Validation loss: 2.3428343528617983

Epoch: 6| Step: 10
Training loss: 0.21014523069570681
Validation loss: 2.3427586515966667

Epoch: 6| Step: 11
Training loss: 0.2086300921838624
Validation loss: 2.342642118516715

Epoch: 6| Step: 12
Training loss: 0.29332579155098804
Validation loss: 2.343248709936965

Epoch: 6| Step: 13
Training loss: 0.1900880242814408
Validation loss: 2.3555705481587608

Epoch: 416| Step: 0
Training loss: 0.30950267546241494
Validation loss: 2.289140226164544

Epoch: 6| Step: 1
Training loss: 0.21412039273255223
Validation loss: 2.2960327961660916

Epoch: 6| Step: 2
Training loss: 0.3407011506938173
Validation loss: 2.3137534831444158

Epoch: 6| Step: 3
Training loss: 0.266731928995334
Validation loss: 2.2979955506296466

Epoch: 6| Step: 4
Training loss: 0.10608788070960991
Validation loss: 2.2747368124044494

Epoch: 6| Step: 5
Training loss: 0.4141525674424661
Validation loss: 2.2749767527203275

Epoch: 6| Step: 6
Training loss: 0.16355908451952827
Validation loss: 2.233503747069821

Epoch: 6| Step: 7
Training loss: 0.2795352851913329
Validation loss: 2.255117565223862

Epoch: 6| Step: 8
Training loss: 0.16827469508369158
Validation loss: 2.24790488564693

Epoch: 6| Step: 9
Training loss: 0.23260751090754117
Validation loss: 2.2134724622955564

Epoch: 6| Step: 10
Training loss: 0.26147007871490574
Validation loss: 2.224375019738549

Epoch: 6| Step: 11
Training loss: 0.34636185811998726
Validation loss: 2.238385796134344

Epoch: 6| Step: 12
Training loss: 0.2379354797945867
Validation loss: 2.227883213164514

Epoch: 6| Step: 13
Training loss: 0.41376563892600005
Validation loss: 2.256871123110239

Epoch: 417| Step: 0
Training loss: 0.22829279672610228
Validation loss: 2.2351242657554646

Epoch: 6| Step: 1
Training loss: 0.14206940546551222
Validation loss: 2.2568139091544737

Epoch: 6| Step: 2
Training loss: 0.1978811914038027
Validation loss: 2.2889379646448704

Epoch: 6| Step: 3
Training loss: 0.3188139472656365
Validation loss: 2.264697337093912

Epoch: 6| Step: 4
Training loss: 0.2626461848157801
Validation loss: 2.2770879438550407

Epoch: 6| Step: 5
Training loss: 0.34686897375697273
Validation loss: 2.31561048764226

Epoch: 6| Step: 6
Training loss: 0.23152438555362942
Validation loss: 2.3164878169166565

Epoch: 6| Step: 7
Training loss: 0.2473784172888026
Validation loss: 2.3252873106356273

Epoch: 6| Step: 8
Training loss: 0.2410238134764473
Validation loss: 2.3228521115050538

Epoch: 6| Step: 9
Training loss: 0.27950471200877897
Validation loss: 2.3518819818491203

Epoch: 6| Step: 10
Training loss: 0.3579131538713146
Validation loss: 2.316355083836846

Epoch: 6| Step: 11
Training loss: 0.25107180795658335
Validation loss: 2.3044580355443216

Epoch: 6| Step: 12
Training loss: 0.2886808427545618
Validation loss: 2.3093644268807316

Epoch: 6| Step: 13
Training loss: 0.3442313984933601
Validation loss: 2.3106734116233345

Epoch: 418| Step: 0
Training loss: 0.21935277723037236
Validation loss: 2.2675000028599714

Epoch: 6| Step: 1
Training loss: 0.3565051302948661
Validation loss: 2.2822478782704487

Epoch: 6| Step: 2
Training loss: 0.14950179970975291
Validation loss: 2.29597493346514

Epoch: 6| Step: 3
Training loss: 0.14222531235084426
Validation loss: 2.25742695343836

Epoch: 6| Step: 4
Training loss: 0.4028866447650088
Validation loss: 2.2473196143334215

Epoch: 6| Step: 5
Training loss: 0.18495295989768878
Validation loss: 2.2615441718565776

Epoch: 6| Step: 6
Training loss: 0.17646225303010574
Validation loss: 2.2994598918174733

Epoch: 6| Step: 7
Training loss: 0.30085025342626615
Validation loss: 2.286510379948339

Epoch: 6| Step: 8
Training loss: 0.22517052916887684
Validation loss: 2.304376689183211

Epoch: 6| Step: 9
Training loss: 0.33110695260383066
Validation loss: 2.344291097876179

Epoch: 6| Step: 10
Training loss: 0.36075928734782037
Validation loss: 2.3777738972724443

Epoch: 6| Step: 11
Training loss: 0.24593515432564866
Validation loss: 2.3807838673808304

Epoch: 6| Step: 12
Training loss: 0.2136337800735545
Validation loss: 2.4083932021245773

Epoch: 6| Step: 13
Training loss: 0.24786277757646713
Validation loss: 2.397342166824521

Epoch: 419| Step: 0
Training loss: 0.3049246769668108
Validation loss: 2.3803473938844646

Epoch: 6| Step: 1
Training loss: 0.21559264831825484
Validation loss: 2.3975995359488547

Epoch: 6| Step: 2
Training loss: 0.3084128006241271
Validation loss: 2.409008183542878

Epoch: 6| Step: 3
Training loss: 0.2800264100621892
Validation loss: 2.385352612137076

Epoch: 6| Step: 4
Training loss: 0.15521063824250017
Validation loss: 2.3692204261664984

Epoch: 6| Step: 5
Training loss: 0.25598116880592037
Validation loss: 2.329554983392898

Epoch: 6| Step: 6
Training loss: 0.4373728022273497
Validation loss: 2.284252819536948

Epoch: 6| Step: 7
Training loss: 0.18625394716176563
Validation loss: 2.2591971331458645

Epoch: 6| Step: 8
Training loss: 0.2660902520810555
Validation loss: 2.233368398451448

Epoch: 6| Step: 9
Training loss: 0.1746601967381869
Validation loss: 2.1952742490536843

Epoch: 6| Step: 10
Training loss: 0.22506505105295052
Validation loss: 2.1834313662846365

Epoch: 6| Step: 11
Training loss: 0.34660154724636966
Validation loss: 2.206268621637614

Epoch: 6| Step: 12
Training loss: 0.21337516135414697
Validation loss: 2.223102338466675

Epoch: 6| Step: 13
Training loss: 0.21318684539202346
Validation loss: 2.212927999731942

Epoch: 420| Step: 0
Training loss: 0.33008961403619363
Validation loss: 2.201511499709991

Epoch: 6| Step: 1
Training loss: 0.22447067622319924
Validation loss: 2.24296322872814

Epoch: 6| Step: 2
Training loss: 0.3290596094756225
Validation loss: 2.2698046141731156

Epoch: 6| Step: 3
Training loss: 0.1764851886144546
Validation loss: 2.275785555704036

Epoch: 6| Step: 4
Training loss: 0.20887839223594312
Validation loss: 2.3199756850601037

Epoch: 6| Step: 5
Training loss: 0.27065263582835136
Validation loss: 2.3556167473600027

Epoch: 6| Step: 6
Training loss: 0.15563663255350066
Validation loss: 2.326098462814563

Epoch: 6| Step: 7
Training loss: 0.43076421909475754
Validation loss: 2.3315859336955325

Epoch: 6| Step: 8
Training loss: 0.19884200094551785
Validation loss: 2.3393506342934582

Epoch: 6| Step: 9
Training loss: 0.2041986590413797
Validation loss: 2.320881322746504

Epoch: 6| Step: 10
Training loss: 0.2286793945217833
Validation loss: 2.2756649982288844

Epoch: 6| Step: 11
Training loss: 0.18358275197953366
Validation loss: 2.2927974558612894

Epoch: 6| Step: 12
Training loss: 0.28083003000916346
Validation loss: 2.289679522834291

Epoch: 6| Step: 13
Training loss: 0.28567796821190594
Validation loss: 2.248540185963671

Epoch: 421| Step: 0
Training loss: 0.24303122419475132
Validation loss: 2.246091274351064

Epoch: 6| Step: 1
Training loss: 0.2551646811592631
Validation loss: 2.2457139359720215

Epoch: 6| Step: 2
Training loss: 0.13476754615630615
Validation loss: 2.2371587859652795

Epoch: 6| Step: 3
Training loss: 0.14903312941566196
Validation loss: 2.2753791035253035

Epoch: 6| Step: 4
Training loss: 0.18664095706518946
Validation loss: 2.278497939881514

Epoch: 6| Step: 5
Training loss: 0.3963450858955274
Validation loss: 2.2643398782982325

Epoch: 6| Step: 6
Training loss: 0.28566786189860444
Validation loss: 2.251599392542391

Epoch: 6| Step: 7
Training loss: 0.30951157021580644
Validation loss: 2.2944355932120595

Epoch: 6| Step: 8
Training loss: 0.24384143043792478
Validation loss: 2.2703393709559485

Epoch: 6| Step: 9
Training loss: 0.13233965963102393
Validation loss: 2.2990290698177187

Epoch: 6| Step: 10
Training loss: 0.1631274027848406
Validation loss: 2.317085227888602

Epoch: 6| Step: 11
Training loss: 0.3001530887490904
Validation loss: 2.312434001802295

Epoch: 6| Step: 12
Training loss: 0.3052461832856079
Validation loss: 2.2855832923990844

Epoch: 6| Step: 13
Training loss: 0.2582757429307756
Validation loss: 2.319097129699116

Epoch: 422| Step: 0
Training loss: 0.3822285226684896
Validation loss: 2.3273544605550915

Epoch: 6| Step: 1
Training loss: 0.20241748026203632
Validation loss: 2.328918896476986

Epoch: 6| Step: 2
Training loss: 0.36462757886616076
Validation loss: 2.334067382654501

Epoch: 6| Step: 3
Training loss: 0.14499161833758242
Validation loss: 2.3121651692813616

Epoch: 6| Step: 4
Training loss: 0.2848979224012774
Validation loss: 2.310427521638397

Epoch: 6| Step: 5
Training loss: 0.16269486187967494
Validation loss: 2.27852976944955

Epoch: 6| Step: 6
Training loss: 0.2351058611317898
Validation loss: 2.276491233726012

Epoch: 6| Step: 7
Training loss: 0.24706910626867112
Validation loss: 2.266067790891105

Epoch: 6| Step: 8
Training loss: 0.2851702020445685
Validation loss: 2.2781788269667262

Epoch: 6| Step: 9
Training loss: 0.2580609136279981
Validation loss: 2.2754286817311287

Epoch: 6| Step: 10
Training loss: 0.2533360607984393
Validation loss: 2.252038204564393

Epoch: 6| Step: 11
Training loss: 0.15023413480083844
Validation loss: 2.2758499008029083

Epoch: 6| Step: 12
Training loss: 0.2541678181736819
Validation loss: 2.2799417304221206

Epoch: 6| Step: 13
Training loss: 0.211225771840749
Validation loss: 2.263254026449818

Epoch: 423| Step: 0
Training loss: 0.15217735911780034
Validation loss: 2.2635299693489728

Epoch: 6| Step: 1
Training loss: 0.4563178665165329
Validation loss: 2.2334137746499514

Epoch: 6| Step: 2
Training loss: 0.3139697559500422
Validation loss: 2.2652171315551852

Epoch: 6| Step: 3
Training loss: 0.27370103670344814
Validation loss: 2.263146096298445

Epoch: 6| Step: 4
Training loss: 0.40213505415580403
Validation loss: 2.2741796659761384

Epoch: 6| Step: 5
Training loss: 0.25662509981572457
Validation loss: 2.2879750682434215

Epoch: 6| Step: 6
Training loss: 0.18914883549677405
Validation loss: 2.3097047066468734

Epoch: 6| Step: 7
Training loss: 0.20216365885901566
Validation loss: 2.3057942859467464

Epoch: 6| Step: 8
Training loss: 0.20872810730089592
Validation loss: 2.349294339174156

Epoch: 6| Step: 9
Training loss: 0.18333965330356822
Validation loss: 2.322883378554665

Epoch: 6| Step: 10
Training loss: 0.3375874079439001
Validation loss: 2.3546492573541244

Epoch: 6| Step: 11
Training loss: 0.23627759850481486
Validation loss: 2.325207700702097

Epoch: 6| Step: 12
Training loss: 0.1992104846511314
Validation loss: 2.2952320249037874

Epoch: 6| Step: 13
Training loss: 0.3520035414409217
Validation loss: 2.3069342272440823

Epoch: 424| Step: 0
Training loss: 0.2806271968832025
Validation loss: 2.34409216348638

Epoch: 6| Step: 1
Training loss: 0.18168414015102502
Validation loss: 2.3231730857384076

Epoch: 6| Step: 2
Training loss: 0.4443291632167324
Validation loss: 2.2923275625710557

Epoch: 6| Step: 3
Training loss: 0.33925359280805467
Validation loss: 2.3043452205285875

Epoch: 6| Step: 4
Training loss: 0.1985793042575256
Validation loss: 2.273561303521758

Epoch: 6| Step: 5
Training loss: 0.3118845959756186
Validation loss: 2.2846473202150794

Epoch: 6| Step: 6
Training loss: 0.24533260044432442
Validation loss: 2.29703602977312

Epoch: 6| Step: 7
Training loss: 0.23293844886895632
Validation loss: 2.2648056189325465

Epoch: 6| Step: 8
Training loss: 0.252736699183536
Validation loss: 2.2576411604097193

Epoch: 6| Step: 9
Training loss: 0.28007435124407354
Validation loss: 2.268186253730314

Epoch: 6| Step: 10
Training loss: 0.17967637691071064
Validation loss: 2.265201090899198

Epoch: 6| Step: 11
Training loss: 0.18632642717207706
Validation loss: 2.2813617624417937

Epoch: 6| Step: 12
Training loss: 0.3902789299534224
Validation loss: 2.259580975345008

Epoch: 6| Step: 13
Training loss: 0.3667775970690498
Validation loss: 2.312840388732167

Epoch: 425| Step: 0
Training loss: 0.2118872172847678
Validation loss: 2.2930689379968103

Epoch: 6| Step: 1
Training loss: 0.23156070649331503
Validation loss: 2.3106296242839437

Epoch: 6| Step: 2
Training loss: 0.2979936479709161
Validation loss: 2.3202449318762453

Epoch: 6| Step: 3
Training loss: 0.28508095204359485
Validation loss: 2.3299956089851404

Epoch: 6| Step: 4
Training loss: 0.19300054720630552
Validation loss: 2.3384477620391895

Epoch: 6| Step: 5
Training loss: 0.28966019671512133
Validation loss: 2.3597852305041362

Epoch: 6| Step: 6
Training loss: 0.3018009685778891
Validation loss: 2.358593390832816

Epoch: 6| Step: 7
Training loss: 0.30938208359979985
Validation loss: 2.352233518434671

Epoch: 6| Step: 8
Training loss: 0.29110964593981703
Validation loss: 2.340308470344355

Epoch: 6| Step: 9
Training loss: 0.248153633512205
Validation loss: 2.352938445351003

Epoch: 6| Step: 10
Training loss: 0.43068122397070924
Validation loss: 2.352426994906391

Epoch: 6| Step: 11
Training loss: 0.2783927689316829
Validation loss: 2.3546489367151944

Epoch: 6| Step: 12
Training loss: 0.27036501975120125
Validation loss: 2.373215158507357

Epoch: 6| Step: 13
Training loss: 0.2932718362247523
Validation loss: 2.3354138882109607

Epoch: 426| Step: 0
Training loss: 0.22096419295913902
Validation loss: 2.3375335556928656

Epoch: 6| Step: 1
Training loss: 0.2753450477707191
Validation loss: 2.3309571352272838

Epoch: 6| Step: 2
Training loss: 0.355646319630218
Validation loss: 2.335152315494292

Epoch: 6| Step: 3
Training loss: 0.35178020941871924
Validation loss: 2.3165125225973617

Epoch: 6| Step: 4
Training loss: 0.21381748614815657
Validation loss: 2.308565750814288

Epoch: 6| Step: 5
Training loss: 0.4249623674673179
Validation loss: 2.275334805131298

Epoch: 6| Step: 6
Training loss: 0.16601402057545606
Validation loss: 2.2854287396556283

Epoch: 6| Step: 7
Training loss: 0.3226954050760075
Validation loss: 2.2455809664774122

Epoch: 6| Step: 8
Training loss: 0.3162093904114565
Validation loss: 2.2702056530573755

Epoch: 6| Step: 9
Training loss: 0.33651764256407946
Validation loss: 2.3082618447721885

Epoch: 6| Step: 10
Training loss: 0.25459229146573087
Validation loss: 2.31323045403714

Epoch: 6| Step: 11
Training loss: 0.3221167943203164
Validation loss: 2.2988489745830756

Epoch: 6| Step: 12
Training loss: 0.2834647975760052
Validation loss: 2.3262131372716994

Epoch: 6| Step: 13
Training loss: 0.324437733888404
Validation loss: 2.316408454055483

Epoch: 427| Step: 0
Training loss: 0.34311905306820073
Validation loss: 2.3488290719026694

Epoch: 6| Step: 1
Training loss: 0.3337237026805496
Validation loss: 2.3085998243020844

Epoch: 6| Step: 2
Training loss: 0.36728666873733046
Validation loss: 2.299780175768785

Epoch: 6| Step: 3
Training loss: 0.19695212692679698
Validation loss: 2.2833367643726508

Epoch: 6| Step: 4
Training loss: 0.3007954928506226
Validation loss: 2.2831176476825212

Epoch: 6| Step: 5
Training loss: 0.17574961695554728
Validation loss: 2.2714497740966175

Epoch: 6| Step: 6
Training loss: 0.19915863139777218
Validation loss: 2.2214750511333117

Epoch: 6| Step: 7
Training loss: 0.22221493905685832
Validation loss: 2.219800147118832

Epoch: 6| Step: 8
Training loss: 0.21877327863264287
Validation loss: 2.226193385750309

Epoch: 6| Step: 9
Training loss: 0.2812476555408673
Validation loss: 2.2418042624640244

Epoch: 6| Step: 10
Training loss: 0.24253157815614884
Validation loss: 2.291008207153915

Epoch: 6| Step: 11
Training loss: 0.39689192473000245
Validation loss: 2.2610193803105605

Epoch: 6| Step: 12
Training loss: 0.18714664860465405
Validation loss: 2.282577080321802

Epoch: 6| Step: 13
Training loss: 0.33642282470821366
Validation loss: 2.291421789545661

Epoch: 428| Step: 0
Training loss: 0.27923926179383785
Validation loss: 2.2905485033682433

Epoch: 6| Step: 1
Training loss: 0.2332367436698951
Validation loss: 2.271543354739478

Epoch: 6| Step: 2
Training loss: 0.2999652842462435
Validation loss: 2.316102246220343

Epoch: 6| Step: 3
Training loss: 0.3175183520307206
Validation loss: 2.3371342733332634

Epoch: 6| Step: 4
Training loss: 0.20129825733162923
Validation loss: 2.31633429249594

Epoch: 6| Step: 5
Training loss: 0.1711118401147883
Validation loss: 2.31732733925925

Epoch: 6| Step: 6
Training loss: 0.3375985310802209
Validation loss: 2.3059409455055366

Epoch: 6| Step: 7
Training loss: 0.16170928600280154
Validation loss: 2.361146981459265

Epoch: 6| Step: 8
Training loss: 0.23692457737117667
Validation loss: 2.3007348678501343

Epoch: 6| Step: 9
Training loss: 0.16619290815529453
Validation loss: 2.3001699124493724

Epoch: 6| Step: 10
Training loss: 0.17230394330812063
Validation loss: 2.3155736016911055

Epoch: 6| Step: 11
Training loss: 0.23385254325529775
Validation loss: 2.271606735457804

Epoch: 6| Step: 12
Training loss: 0.23841910205020772
Validation loss: 2.298308050944074

Epoch: 6| Step: 13
Training loss: 0.3900615252051866
Validation loss: 2.287233444450552

Epoch: 429| Step: 0
Training loss: 0.22251924683338312
Validation loss: 2.2686847804515953

Epoch: 6| Step: 1
Training loss: 0.16451446970206918
Validation loss: 2.260292816133792

Epoch: 6| Step: 2
Training loss: 0.2873489003552208
Validation loss: 2.3090141072900328

Epoch: 6| Step: 3
Training loss: 0.36022516944124633
Validation loss: 2.271868012149494

Epoch: 6| Step: 4
Training loss: 0.3278302276443535
Validation loss: 2.292022937663962

Epoch: 6| Step: 5
Training loss: 0.08468774467781306
Validation loss: 2.2946559222505623

Epoch: 6| Step: 6
Training loss: 0.24769617053769
Validation loss: 2.293105985830698

Epoch: 6| Step: 7
Training loss: 0.1748367045826463
Validation loss: 2.2836436952735086

Epoch: 6| Step: 8
Training loss: 0.2827345292743685
Validation loss: 2.3358242391434345

Epoch: 6| Step: 9
Training loss: 0.16516731853982788
Validation loss: 2.3518177052474707

Epoch: 6| Step: 10
Training loss: 0.18971115905864402
Validation loss: 2.329741554372917

Epoch: 6| Step: 11
Training loss: 0.24772425569229423
Validation loss: 2.3728923631677623

Epoch: 6| Step: 12
Training loss: 0.24120324620637185
Validation loss: 2.3550563023897135

Epoch: 6| Step: 13
Training loss: 0.3693925109172283
Validation loss: 2.3508771222517506

Epoch: 430| Step: 0
Training loss: 0.32458815155240084
Validation loss: 2.3527318633278673

Epoch: 6| Step: 1
Training loss: 0.26261309219791823
Validation loss: 2.368160723933463

Epoch: 6| Step: 2
Training loss: 0.22242491399459574
Validation loss: 2.355742892140312

Epoch: 6| Step: 3
Training loss: 0.17037661859103123
Validation loss: 2.3324727706973745

Epoch: 6| Step: 4
Training loss: 0.14788703744832252
Validation loss: 2.2921428495193754

Epoch: 6| Step: 5
Training loss: 0.33244273549486447
Validation loss: 2.3066799777332863

Epoch: 6| Step: 6
Training loss: 0.237880306928394
Validation loss: 2.2747795232535313

Epoch: 6| Step: 7
Training loss: 0.17142271006304885
Validation loss: 2.2496328088442947

Epoch: 6| Step: 8
Training loss: 0.4435094839735634
Validation loss: 2.2780695653379515

Epoch: 6| Step: 9
Training loss: 0.2254974389808354
Validation loss: 2.276805225193465

Epoch: 6| Step: 10
Training loss: 0.1319103949062099
Validation loss: 2.2801836133869133

Epoch: 6| Step: 11
Training loss: 0.13071090189433
Validation loss: 2.2839101300280698

Epoch: 6| Step: 12
Training loss: 0.15319020527583552
Validation loss: 2.2771198173372524

Epoch: 6| Step: 13
Training loss: 0.2266206091320245
Validation loss: 2.3020570009509473

Epoch: 431| Step: 0
Training loss: 0.15293786768757997
Validation loss: 2.344650817908581

Epoch: 6| Step: 1
Training loss: 0.16816789997077536
Validation loss: 2.3017831061945104

Epoch: 6| Step: 2
Training loss: 0.22071671233086576
Validation loss: 2.303441287251379

Epoch: 6| Step: 3
Training loss: 0.25321321539707403
Validation loss: 2.274441858226738

Epoch: 6| Step: 4
Training loss: 0.25737447808811653
Validation loss: 2.3054028129052035

Epoch: 6| Step: 5
Training loss: 0.33772834011795083
Validation loss: 2.2784292065477176

Epoch: 6| Step: 6
Training loss: 0.21517730309311012
Validation loss: 2.316214988875148

Epoch: 6| Step: 7
Training loss: 0.2929129356623271
Validation loss: 2.2959883993854113

Epoch: 6| Step: 8
Training loss: 0.2703767038733434
Validation loss: 2.271128362580981

Epoch: 6| Step: 9
Training loss: 0.20825295487193124
Validation loss: 2.241382113650789

Epoch: 6| Step: 10
Training loss: 0.23300544820706764
Validation loss: 2.2118715146657584

Epoch: 6| Step: 11
Training loss: 0.22496455761129105
Validation loss: 2.2217017849581966

Epoch: 6| Step: 12
Training loss: 0.2209158859309883
Validation loss: 2.22923417018393

Epoch: 6| Step: 13
Training loss: 0.2722666604940462
Validation loss: 2.222850033392737

Epoch: 432| Step: 0
Training loss: 0.3131316477056588
Validation loss: 2.2042663539657505

Epoch: 6| Step: 1
Training loss: 0.23860012667965144
Validation loss: 2.2067487359623557

Epoch: 6| Step: 2
Training loss: 0.18977824560595405
Validation loss: 2.209026260800682

Epoch: 6| Step: 3
Training loss: 0.21806194883404278
Validation loss: 2.2130421415909836

Epoch: 6| Step: 4
Training loss: 0.3977612384932342
Validation loss: 2.221534253047707

Epoch: 6| Step: 5
Training loss: 0.22271042716793849
Validation loss: 2.2493593877483464

Epoch: 6| Step: 6
Training loss: 0.10414198543292433
Validation loss: 2.2593196949667336

Epoch: 6| Step: 7
Training loss: 0.22872711241719487
Validation loss: 2.263319381943196

Epoch: 6| Step: 8
Training loss: 0.16139100514231525
Validation loss: 2.309167503339937

Epoch: 6| Step: 9
Training loss: 0.21858133898411927
Validation loss: 2.2952261899923023

Epoch: 6| Step: 10
Training loss: 0.26164344159601016
Validation loss: 2.2956271392214704

Epoch: 6| Step: 11
Training loss: 0.32260295667945915
Validation loss: 2.290246646788038

Epoch: 6| Step: 12
Training loss: 0.281096761071372
Validation loss: 2.3056082706113954

Epoch: 6| Step: 13
Training loss: 0.18624594653602267
Validation loss: 2.303775209262878

Epoch: 433| Step: 0
Training loss: 0.2208862220361502
Validation loss: 2.2798687176003636

Epoch: 6| Step: 1
Training loss: 0.12044479694789338
Validation loss: 2.2512623106997434

Epoch: 6| Step: 2
Training loss: 0.33617379505585204
Validation loss: 2.2767562861321773

Epoch: 6| Step: 3
Training loss: 0.19143585054046283
Validation loss: 2.2738397375843666

Epoch: 6| Step: 4
Training loss: 0.2217080186393448
Validation loss: 2.275667900772049

Epoch: 6| Step: 5
Training loss: 0.14020931211198884
Validation loss: 2.2411262158932757

Epoch: 6| Step: 6
Training loss: 0.15983336162276843
Validation loss: 2.2805171064040963

Epoch: 6| Step: 7
Training loss: 0.2533065609813395
Validation loss: 2.26793976110534

Epoch: 6| Step: 8
Training loss: 0.234124868751872
Validation loss: 2.232651978754415

Epoch: 6| Step: 9
Training loss: 0.22452308821792855
Validation loss: 2.24550602582323

Epoch: 6| Step: 10
Training loss: 0.33199806047499253
Validation loss: 2.252346995535761

Epoch: 6| Step: 11
Training loss: 0.2977005872971159
Validation loss: 2.2640669860616494

Epoch: 6| Step: 12
Training loss: 0.3174232222434354
Validation loss: 2.262210892787821

Epoch: 6| Step: 13
Training loss: 0.1926919902280806
Validation loss: 2.2724428083129737

Epoch: 434| Step: 0
Training loss: 0.0971836288331261
Validation loss: 2.2800801764709573

Epoch: 6| Step: 1
Training loss: 0.16525640791683516
Validation loss: 2.3049776651360374

Epoch: 6| Step: 2
Training loss: 0.1976886688756261
Validation loss: 2.3273039660715185

Epoch: 6| Step: 3
Training loss: 0.3379202151709968
Validation loss: 2.2933964537340215

Epoch: 6| Step: 4
Training loss: 0.2666491790838962
Validation loss: 2.320608453350786

Epoch: 6| Step: 5
Training loss: 0.34172624130654283
Validation loss: 2.3493563719951354

Epoch: 6| Step: 6
Training loss: 0.21207553670887888
Validation loss: 2.3475718423422576

Epoch: 6| Step: 7
Training loss: 0.19734006364811985
Validation loss: 2.3391654248388862

Epoch: 6| Step: 8
Training loss: 0.2138739981067674
Validation loss: 2.3397517511725177

Epoch: 6| Step: 9
Training loss: 0.32137476001375925
Validation loss: 2.296464909803521

Epoch: 6| Step: 10
Training loss: 0.24945537281785815
Validation loss: 2.301421262964109

Epoch: 6| Step: 11
Training loss: 0.18645408099846966
Validation loss: 2.2801060277072236

Epoch: 6| Step: 12
Training loss: 0.22073819717313548
Validation loss: 2.275444776614291

Epoch: 6| Step: 13
Training loss: 0.25482922571683536
Validation loss: 2.3030337159878327

Epoch: 435| Step: 0
Training loss: 0.25156125192747253
Validation loss: 2.3026693193450187

Epoch: 6| Step: 1
Training loss: 0.33624949494221135
Validation loss: 2.2862975406237993

Epoch: 6| Step: 2
Training loss: 0.16978910893774118
Validation loss: 2.3071053023963954

Epoch: 6| Step: 3
Training loss: 0.3277476843403675
Validation loss: 2.292641897200088

Epoch: 6| Step: 4
Training loss: 0.15807624721213048
Validation loss: 2.250729349210421

Epoch: 6| Step: 5
Training loss: 0.1980960664470783
Validation loss: 2.260045724071915

Epoch: 6| Step: 6
Training loss: 0.16666644935792424
Validation loss: 2.2654311298368714

Epoch: 6| Step: 7
Training loss: 0.2858721095499047
Validation loss: 2.2244309030884235

Epoch: 6| Step: 8
Training loss: 0.34695766211508494
Validation loss: 2.2430132691296167

Epoch: 6| Step: 9
Training loss: 0.28838767074871574
Validation loss: 2.250109137231958

Epoch: 6| Step: 10
Training loss: 0.11734909598468996
Validation loss: 2.221475766629503

Epoch: 6| Step: 11
Training loss: 0.14212072502222395
Validation loss: 2.2588136059283674

Epoch: 6| Step: 12
Training loss: 0.18623197461916163
Validation loss: 2.243977692453648

Epoch: 6| Step: 13
Training loss: 0.1250406065192762
Validation loss: 2.2521988809920317

Epoch: 436| Step: 0
Training loss: 0.19111578174138466
Validation loss: 2.2432746756897965

Epoch: 6| Step: 1
Training loss: 0.1649447628784129
Validation loss: 2.2698047231654557

Epoch: 6| Step: 2
Training loss: 0.41434861140855694
Validation loss: 2.2747653108110857

Epoch: 6| Step: 3
Training loss: 0.25874433310840694
Validation loss: 2.2748461123957426

Epoch: 6| Step: 4
Training loss: 0.38634137322801626
Validation loss: 2.2650698718978735

Epoch: 6| Step: 5
Training loss: 0.21236366709085844
Validation loss: 2.246063376600749

Epoch: 6| Step: 6
Training loss: 0.14338814553258575
Validation loss: 2.2758671078886974

Epoch: 6| Step: 7
Training loss: 0.2933238103162451
Validation loss: 2.3019118469032844

Epoch: 6| Step: 8
Training loss: 0.09748060643364659
Validation loss: 2.331370934456212

Epoch: 6| Step: 9
Training loss: 0.2337965901118203
Validation loss: 2.2916282602114175

Epoch: 6| Step: 10
Training loss: 0.1484705863016882
Validation loss: 2.342217860795067

Epoch: 6| Step: 11
Training loss: 0.13918499641239482
Validation loss: 2.299861713133769

Epoch: 6| Step: 12
Training loss: 0.14470256498356324
Validation loss: 2.3285317223636217

Epoch: 6| Step: 13
Training loss: 0.2558996736662298
Validation loss: 2.336816447653251

Epoch: 437| Step: 0
Training loss: 0.24766512653315637
Validation loss: 2.356839668838239

Epoch: 6| Step: 1
Training loss: 0.3430344546907615
Validation loss: 2.3246095660536414

Epoch: 6| Step: 2
Training loss: 0.24974815528300998
Validation loss: 2.3400561346408533

Epoch: 6| Step: 3
Training loss: 0.19571478422539482
Validation loss: 2.300708606576761

Epoch: 6| Step: 4
Training loss: 0.33908918073600935
Validation loss: 2.326738643868643

Epoch: 6| Step: 5
Training loss: 0.21533825923710323
Validation loss: 2.301713796799297

Epoch: 6| Step: 6
Training loss: 0.19281536214549702
Validation loss: 2.291991874314191

Epoch: 6| Step: 7
Training loss: 0.2396379370592432
Validation loss: 2.270267904633348

Epoch: 6| Step: 8
Training loss: 0.11900055578045926
Validation loss: 2.275135540420721

Epoch: 6| Step: 9
Training loss: 0.21605334064765258
Validation loss: 2.283784285466021

Epoch: 6| Step: 10
Training loss: 0.2357311274629148
Validation loss: 2.257085749701786

Epoch: 6| Step: 11
Training loss: 0.1804291305979368
Validation loss: 2.261351043566496

Epoch: 6| Step: 12
Training loss: 0.30368255286339324
Validation loss: 2.2413744754969773

Epoch: 6| Step: 13
Training loss: 0.15254592928895594
Validation loss: 2.257475464359258

Epoch: 438| Step: 0
Training loss: 0.23878137290001872
Validation loss: 2.2330805939305294

Epoch: 6| Step: 1
Training loss: 0.29979502013086917
Validation loss: 2.2556469309462868

Epoch: 6| Step: 2
Training loss: 0.09039673421090968
Validation loss: 2.2570533218394697

Epoch: 6| Step: 3
Training loss: 0.22543365325638753
Validation loss: 2.2350968459068703

Epoch: 6| Step: 4
Training loss: 0.12493575948788092
Validation loss: 2.25847008575304

Epoch: 6| Step: 5
Training loss: 0.1308659865004435
Validation loss: 2.2732291436773497

Epoch: 6| Step: 6
Training loss: 0.19186246764232293
Validation loss: 2.259322861900574

Epoch: 6| Step: 7
Training loss: 0.15709911535824095
Validation loss: 2.273150874026906

Epoch: 6| Step: 8
Training loss: 0.2724386226581039
Validation loss: 2.2708798501867866

Epoch: 6| Step: 9
Training loss: 0.29955521184745393
Validation loss: 2.2820760773928552

Epoch: 6| Step: 10
Training loss: 0.20336122714945726
Validation loss: 2.29894757735653

Epoch: 6| Step: 11
Training loss: 0.20400337887518225
Validation loss: 2.273334516205536

Epoch: 6| Step: 12
Training loss: 0.2995373282415309
Validation loss: 2.2800609317712537

Epoch: 6| Step: 13
Training loss: 0.14801883633300236
Validation loss: 2.277354220253662

Epoch: 439| Step: 0
Training loss: 0.1536377760557929
Validation loss: 2.2578355734284457

Epoch: 6| Step: 1
Training loss: 0.24574421476887118
Validation loss: 2.2436451755159093

Epoch: 6| Step: 2
Training loss: 0.21038399590645265
Validation loss: 2.2401855605332663

Epoch: 6| Step: 3
Training loss: 0.15323532689101219
Validation loss: 2.2821036455548622

Epoch: 6| Step: 4
Training loss: 0.1120563996655015
Validation loss: 2.2502065584264277

Epoch: 6| Step: 5
Training loss: 0.35840706464066363
Validation loss: 2.321891873886216

Epoch: 6| Step: 6
Training loss: 0.18308007636433918
Validation loss: 2.2585839257572684

Epoch: 6| Step: 7
Training loss: 0.13526499871444644
Validation loss: 2.261469042045143

Epoch: 6| Step: 8
Training loss: 0.23891927941808253
Validation loss: 2.273406095872476

Epoch: 6| Step: 9
Training loss: 0.14897822722946666
Validation loss: 2.2653734960765552

Epoch: 6| Step: 10
Training loss: 0.2129419859779487
Validation loss: 2.3099912911414164

Epoch: 6| Step: 11
Training loss: 0.2940986714833439
Validation loss: 2.2847639332044856

Epoch: 6| Step: 12
Training loss: 0.2745501089376172
Validation loss: 2.311220095902259

Epoch: 6| Step: 13
Training loss: 0.3381139976100494
Validation loss: 2.3027467103620243

Epoch: 440| Step: 0
Training loss: 0.24696397566256248
Validation loss: 2.2826172749793927

Epoch: 6| Step: 1
Training loss: 0.1589519767648511
Validation loss: 2.3220901979797324

Epoch: 6| Step: 2
Training loss: 0.30288220149604905
Validation loss: 2.330489639309006

Epoch: 6| Step: 3
Training loss: 0.12901631626961735
Validation loss: 2.308945624790115

Epoch: 6| Step: 4
Training loss: 0.1806206934656397
Validation loss: 2.3013153399201576

Epoch: 6| Step: 5
Training loss: 0.3056400277435316
Validation loss: 2.30209966707669

Epoch: 6| Step: 6
Training loss: 0.19050839093769512
Validation loss: 2.324795709068424

Epoch: 6| Step: 7
Training loss: 0.333667515588005
Validation loss: 2.3141415203956166

Epoch: 6| Step: 8
Training loss: 0.13594077698276474
Validation loss: 2.3241985096459037

Epoch: 6| Step: 9
Training loss: 0.1739843234664642
Validation loss: 2.2945296816023553

Epoch: 6| Step: 10
Training loss: 0.2167181782897141
Validation loss: 2.2885509942686926

Epoch: 6| Step: 11
Training loss: 0.21268006507440096
Validation loss: 2.3043317734050848

Epoch: 6| Step: 12
Training loss: 0.16565733562467083
Validation loss: 2.2899020072767127

Epoch: 6| Step: 13
Training loss: 0.24004179516098945
Validation loss: 2.277738938582816

Epoch: 441| Step: 0
Training loss: 0.19373342189312856
Validation loss: 2.273870305931023

Epoch: 6| Step: 1
Training loss: 0.12717404583761813
Validation loss: 2.305852112927994

Epoch: 6| Step: 2
Training loss: 0.20389572057905697
Validation loss: 2.2974862490863592

Epoch: 6| Step: 3
Training loss: 0.2515338988068105
Validation loss: 2.2927526095518425

Epoch: 6| Step: 4
Training loss: 0.2895347114722513
Validation loss: 2.31204631762336

Epoch: 6| Step: 5
Training loss: 0.21355000146246436
Validation loss: 2.3328097769800316

Epoch: 6| Step: 6
Training loss: 0.1763755342234139
Validation loss: 2.290129424709458

Epoch: 6| Step: 7
Training loss: 0.2303864121852293
Validation loss: 2.325786121855235

Epoch: 6| Step: 8
Training loss: 0.31371646388414376
Validation loss: 2.3065973154340274

Epoch: 6| Step: 9
Training loss: 0.3121095244367908
Validation loss: 2.2838594192416606

Epoch: 6| Step: 10
Training loss: 0.19109264295480355
Validation loss: 2.315743785097267

Epoch: 6| Step: 11
Training loss: 0.20586694055658034
Validation loss: 2.2770376587046797

Epoch: 6| Step: 12
Training loss: 0.10033772685388992
Validation loss: 2.2968804210994818

Epoch: 6| Step: 13
Training loss: 0.11289905744296215
Validation loss: 2.3362870689603707

Epoch: 442| Step: 0
Training loss: 0.16842038405583326
Validation loss: 2.326986757667383

Epoch: 6| Step: 1
Training loss: 0.1543307327593983
Validation loss: 2.3189527838580712

Epoch: 6| Step: 2
Training loss: 0.15564237106036227
Validation loss: 2.3353581862700943

Epoch: 6| Step: 3
Training loss: 0.28245528565635675
Validation loss: 2.311635237895932

Epoch: 6| Step: 4
Training loss: 0.23868848833367437
Validation loss: 2.3371273188736943

Epoch: 6| Step: 5
Training loss: 0.14459908671905194
Validation loss: 2.300547894603012

Epoch: 6| Step: 6
Training loss: 0.2778960088938117
Validation loss: 2.3000451982791157

Epoch: 6| Step: 7
Training loss: 0.21488909676299017
Validation loss: 2.3229275841173362

Epoch: 6| Step: 8
Training loss: 0.13563525152356276
Validation loss: 2.270641876154646

Epoch: 6| Step: 9
Training loss: 0.1583393711164438
Validation loss: 2.273715365736085

Epoch: 6| Step: 10
Training loss: 0.1647229129150869
Validation loss: 2.2766970450737265

Epoch: 6| Step: 11
Training loss: 0.2731778274225381
Validation loss: 2.2927027015150774

Epoch: 6| Step: 12
Training loss: 0.2684030139207041
Validation loss: 2.2982960197021094

Epoch: 6| Step: 13
Training loss: 0.08698136691872058
Validation loss: 2.2865640190374297

Epoch: 443| Step: 0
Training loss: 0.1591172066444711
Validation loss: 2.2846906890481753

Epoch: 6| Step: 1
Training loss: 0.2888278137362193
Validation loss: 2.292929146292877

Epoch: 6| Step: 2
Training loss: 0.3184625423344075
Validation loss: 2.2826599986987457

Epoch: 6| Step: 3
Training loss: 0.1304922219823191
Validation loss: 2.3182862440082967

Epoch: 6| Step: 4
Training loss: 0.10588095170595963
Validation loss: 2.301159121710411

Epoch: 6| Step: 5
Training loss: 0.17496989344580754
Validation loss: 2.329116624421554

Epoch: 6| Step: 6
Training loss: 0.10802199320628736
Validation loss: 2.3252164085675577

Epoch: 6| Step: 7
Training loss: 0.26954129794644915
Validation loss: 2.317126159628309

Epoch: 6| Step: 8
Training loss: 0.15615921959640364
Validation loss: 2.302148938212826

Epoch: 6| Step: 9
Training loss: 0.2758578402147836
Validation loss: 2.317848107516713

Epoch: 6| Step: 10
Training loss: 0.14085723324171984
Validation loss: 2.351450051161375

Epoch: 6| Step: 11
Training loss: 0.20332302014749404
Validation loss: 2.3252156026117667

Epoch: 6| Step: 12
Training loss: 0.17377644209889698
Validation loss: 2.3307647088240158

Epoch: 6| Step: 13
Training loss: 0.18502492271226378
Validation loss: 2.3058996528994147

Epoch: 444| Step: 0
Training loss: 0.15499517711127145
Validation loss: 2.2904735990861624

Epoch: 6| Step: 1
Training loss: 0.1553678405536226
Validation loss: 2.2873349489795416

Epoch: 6| Step: 2
Training loss: 0.14185565644369585
Validation loss: 2.276801951962799

Epoch: 6| Step: 3
Training loss: 0.2752101117196235
Validation loss: 2.2563919871249896

Epoch: 6| Step: 4
Training loss: 0.12277202335942652
Validation loss: 2.2331344254959675

Epoch: 6| Step: 5
Training loss: 0.21370245629259185
Validation loss: 2.2521451650416324

Epoch: 6| Step: 6
Training loss: 0.2778973494245118
Validation loss: 2.2264669631354765

Epoch: 6| Step: 7
Training loss: 0.1605712816384273
Validation loss: 2.260331757105037

Epoch: 6| Step: 8
Training loss: 0.39598817264710845
Validation loss: 2.2399380123791337

Epoch: 6| Step: 9
Training loss: 0.15937597657820748
Validation loss: 2.2626581564937007

Epoch: 6| Step: 10
Training loss: 0.22033173193081507
Validation loss: 2.260499188776014

Epoch: 6| Step: 11
Training loss: 0.3334168637440455
Validation loss: 2.270725044076151

Epoch: 6| Step: 12
Training loss: 0.15899270431856682
Validation loss: 2.2966198311033814

Epoch: 6| Step: 13
Training loss: 0.08885074819743269
Validation loss: 2.287885519609509

Epoch: 445| Step: 0
Training loss: 0.19456501020533298
Validation loss: 2.2931049131311454

Epoch: 6| Step: 1
Training loss: 0.31542282569436986
Validation loss: 2.271040843082366

Epoch: 6| Step: 2
Training loss: 0.30038582211388914
Validation loss: 2.3160033850387873

Epoch: 6| Step: 3
Training loss: 0.3114073725487305
Validation loss: 2.3047530971206793

Epoch: 6| Step: 4
Training loss: 0.15167070537559052
Validation loss: 2.3493347713983606

Epoch: 6| Step: 5
Training loss: 0.09545136443259962
Validation loss: 2.307273034305924

Epoch: 6| Step: 6
Training loss: 0.1353555221859156
Validation loss: 2.2848484081218783

Epoch: 6| Step: 7
Training loss: 0.16908920643006659
Validation loss: 2.3156952626540717

Epoch: 6| Step: 8
Training loss: 0.16821440763855247
Validation loss: 2.3405364259270294

Epoch: 6| Step: 9
Training loss: 0.18892976893697824
Validation loss: 2.3042803171572155

Epoch: 6| Step: 10
Training loss: 0.20967321864583888
Validation loss: 2.2894572446423087

Epoch: 6| Step: 11
Training loss: 0.25312847441184355
Validation loss: 2.291128115051691

Epoch: 6| Step: 12
Training loss: 0.2300603448445076
Validation loss: 2.27603641257005

Epoch: 6| Step: 13
Training loss: 0.09741852913642594
Validation loss: 2.282064751157856

Epoch: 446| Step: 0
Training loss: 0.345266465100381
Validation loss: 2.233559199436562

Epoch: 6| Step: 1
Training loss: 0.21860725990958849
Validation loss: 2.2317010627359157

Epoch: 6| Step: 2
Training loss: 0.11284193404555391
Validation loss: 2.2160873820862137

Epoch: 6| Step: 3
Training loss: 0.24156368578561802
Validation loss: 2.2255402661345585

Epoch: 6| Step: 4
Training loss: 0.32711206490171657
Validation loss: 2.219993973978517

Epoch: 6| Step: 5
Training loss: 0.10427590295053826
Validation loss: 2.242506199158689

Epoch: 6| Step: 6
Training loss: 0.13249326655084956
Validation loss: 2.2349355889193037

Epoch: 6| Step: 7
Training loss: 0.2185775553967011
Validation loss: 2.263175935722659

Epoch: 6| Step: 8
Training loss: 0.18624258617072179
Validation loss: 2.2340821586929125

Epoch: 6| Step: 9
Training loss: 0.13677832803967144
Validation loss: 2.268846921184759

Epoch: 6| Step: 10
Training loss: 0.16556370878660362
Validation loss: 2.2725893967534634

Epoch: 6| Step: 11
Training loss: 0.21132955497779682
Validation loss: 2.2927798117363003

Epoch: 6| Step: 12
Training loss: 0.21219249312153943
Validation loss: 2.2958040400561486

Epoch: 6| Step: 13
Training loss: 0.26900790725133356
Validation loss: 2.2820854831607473

Epoch: 447| Step: 0
Training loss: 0.2930604791089534
Validation loss: 2.2616643196147765

Epoch: 6| Step: 1
Training loss: 0.24668463658965648
Validation loss: 2.2843621731587618

Epoch: 6| Step: 2
Training loss: 0.2611865710871587
Validation loss: 2.2567780694673982

Epoch: 6| Step: 3
Training loss: 0.13540802448156763
Validation loss: 2.2558074267590333

Epoch: 6| Step: 4
Training loss: 0.1684923494329102
Validation loss: 2.280073600617164

Epoch: 6| Step: 5
Training loss: 0.2548664716254431
Validation loss: 2.2759293076786298

Epoch: 6| Step: 6
Training loss: 0.17896796332336787
Validation loss: 2.306205692183001

Epoch: 6| Step: 7
Training loss: 0.2742667430602148
Validation loss: 2.296979592482307

Epoch: 6| Step: 8
Training loss: 0.10204859096969215
Validation loss: 2.3075198075986614

Epoch: 6| Step: 9
Training loss: 0.2470902446200513
Validation loss: 2.3317555349948944

Epoch: 6| Step: 10
Training loss: 0.21502087834085498
Validation loss: 2.3283742906225444

Epoch: 6| Step: 11
Training loss: 0.16628792254052943
Validation loss: 2.2948122498339227

Epoch: 6| Step: 12
Training loss: 0.2506567108041627
Validation loss: 2.307514213737147

Epoch: 6| Step: 13
Training loss: 0.14737661110544975
Validation loss: 2.279490320528151

Epoch: 448| Step: 0
Training loss: 0.30645949487100815
Validation loss: 2.2564358782926806

Epoch: 6| Step: 1
Training loss: 0.12152496591978335
Validation loss: 2.2752195308474317

Epoch: 6| Step: 2
Training loss: 0.2820641601466309
Validation loss: 2.2871815446843753

Epoch: 6| Step: 3
Training loss: 0.23540518375399846
Validation loss: 2.257044126098871

Epoch: 6| Step: 4
Training loss: 0.23724358168302348
Validation loss: 2.266159913279571

Epoch: 6| Step: 5
Training loss: 0.23289248161510026
Validation loss: 2.2374407712803936

Epoch: 6| Step: 6
Training loss: 0.09274422034920636
Validation loss: 2.2735304902771603

Epoch: 6| Step: 7
Training loss: 0.1153908975813635
Validation loss: 2.230004304366407

Epoch: 6| Step: 8
Training loss: 0.19018222673723126
Validation loss: 2.2566031818048757

Epoch: 6| Step: 9
Training loss: 0.2077626139774128
Validation loss: 2.2759952752099823

Epoch: 6| Step: 10
Training loss: 0.10889208143226103
Validation loss: 2.2818869683260017

Epoch: 6| Step: 11
Training loss: 0.1930479277208093
Validation loss: 2.287878396959828

Epoch: 6| Step: 12
Training loss: 0.24018814448444617
Validation loss: 2.28087578846786

Epoch: 6| Step: 13
Training loss: 0.34868785947161324
Validation loss: 2.3050470448876537

Epoch: 449| Step: 0
Training loss: 0.3696840313178762
Validation loss: 2.2922018770445245

Epoch: 6| Step: 1
Training loss: 0.18070147358972208
Validation loss: 2.29811201282629

Epoch: 6| Step: 2
Training loss: 0.23552004533242485
Validation loss: 2.289762812114044

Epoch: 6| Step: 3
Training loss: 0.13640947783803323
Validation loss: 2.25964029187402

Epoch: 6| Step: 4
Training loss: 0.24146351736843472
Validation loss: 2.2596854504475217

Epoch: 6| Step: 5
Training loss: 0.12918038551734892
Validation loss: 2.2596218085240904

Epoch: 6| Step: 6
Training loss: 0.14087676981294056
Validation loss: 2.244435480082568

Epoch: 6| Step: 7
Training loss: 0.1534303707498208
Validation loss: 2.274007012317069

Epoch: 6| Step: 8
Training loss: 0.2055790550707846
Validation loss: 2.2612703702714714

Epoch: 6| Step: 9
Training loss: 0.17751495734848827
Validation loss: 2.2084998379340552

Epoch: 6| Step: 10
Training loss: 0.20657582844541875
Validation loss: 2.2237938060239917

Epoch: 6| Step: 11
Training loss: 0.3051248981017771
Validation loss: 2.230742410425283

Epoch: 6| Step: 12
Training loss: 0.12432669561795813
Validation loss: 2.212736012726812

Epoch: 6| Step: 13
Training loss: 0.15727050830519274
Validation loss: 2.1969736110748697

Epoch: 450| Step: 0
Training loss: 0.1624391487701331
Validation loss: 2.2289758124622603

Epoch: 6| Step: 1
Training loss: 0.28829693583584526
Validation loss: 2.1983638328571007

Epoch: 6| Step: 2
Training loss: 0.20336261019806032
Validation loss: 2.227020064673069

Epoch: 6| Step: 3
Training loss: 0.15436448656027593
Validation loss: 2.222864031101965

Epoch: 6| Step: 4
Training loss: 0.10871987753955284
Validation loss: 2.2405620736194813

Epoch: 6| Step: 5
Training loss: 0.24913349337581825
Validation loss: 2.2125314320850062

Epoch: 6| Step: 6
Training loss: 0.25027861567023113
Validation loss: 2.231843369651391

Epoch: 6| Step: 7
Training loss: 0.19419300631465783
Validation loss: 2.235415851527232

Epoch: 6| Step: 8
Training loss: 0.26487443571764185
Validation loss: 2.253249841371567

Epoch: 6| Step: 9
Training loss: 0.17910230755001005
Validation loss: 2.2858294660415077

Epoch: 6| Step: 10
Training loss: 0.1526416043154372
Validation loss: 2.2706815547143724

Epoch: 6| Step: 11
Training loss: 0.2366091184777811
Validation loss: 2.301323477179769

Epoch: 6| Step: 12
Training loss: 0.15367843933901776
Validation loss: 2.2818036095279646

Epoch: 6| Step: 13
Training loss: 0.16040542455290274
Validation loss: 2.2845031595941423

Epoch: 451| Step: 0
Training loss: 0.27840544084711183
Validation loss: 2.3079265755272447

Epoch: 6| Step: 1
Training loss: 0.10396173902881872
Validation loss: 2.2793796725774254

Epoch: 6| Step: 2
Training loss: 0.2039421134044628
Validation loss: 2.27885251018829

Epoch: 6| Step: 3
Training loss: 0.16211004142164648
Validation loss: 2.280166360734913

Epoch: 6| Step: 4
Training loss: 0.3014979678863632
Validation loss: 2.2992668597813815

Epoch: 6| Step: 5
Training loss: 0.14666325773017222
Validation loss: 2.2932777655657235

Epoch: 6| Step: 6
Training loss: 0.21000643392481982
Validation loss: 2.2749229950906416

Epoch: 6| Step: 7
Training loss: 0.1467228664637283
Validation loss: 2.2418660951152884

Epoch: 6| Step: 8
Training loss: 0.09607564670333674
Validation loss: 2.2301498796334687

Epoch: 6| Step: 9
Training loss: 0.22960275462010904
Validation loss: 2.2324586503036867

Epoch: 6| Step: 10
Training loss: 0.27091934904481585
Validation loss: 2.2222553491900543

Epoch: 6| Step: 11
Training loss: 0.22520667557778187
Validation loss: 2.2277297216972634

Epoch: 6| Step: 12
Training loss: 0.140140387191341
Validation loss: 2.2287943286313268

Epoch: 6| Step: 13
Training loss: 0.16544943357257139
Validation loss: 2.22484072578006

Epoch: 452| Step: 0
Training loss: 0.31742803398164143
Validation loss: 2.2543517816012493

Epoch: 6| Step: 1
Training loss: 0.1457579466132196
Validation loss: 2.2621866412010903

Epoch: 6| Step: 2
Training loss: 0.2240639241757215
Validation loss: 2.253468290070707

Epoch: 6| Step: 3
Training loss: 0.3144658956836959
Validation loss: 2.2561252487922703

Epoch: 6| Step: 4
Training loss: 0.28031719012467193
Validation loss: 2.279710634333149

Epoch: 6| Step: 5
Training loss: 0.16805144979899422
Validation loss: 2.2394199808752817

Epoch: 6| Step: 6
Training loss: 0.13030527003332049
Validation loss: 2.258685548153144

Epoch: 6| Step: 7
Training loss: 0.11039835013959172
Validation loss: 2.2869272985637394

Epoch: 6| Step: 8
Training loss: 0.11801082748026523
Validation loss: 2.2438809193968337

Epoch: 6| Step: 9
Training loss: 0.21446666570554163
Validation loss: 2.305747261090237

Epoch: 6| Step: 10
Training loss: 0.16416557797766446
Validation loss: 2.2668500135138916

Epoch: 6| Step: 11
Training loss: 0.17875424886868932
Validation loss: 2.2939914709603997

Epoch: 6| Step: 12
Training loss: 0.2706172460101527
Validation loss: 2.271892015953947

Epoch: 6| Step: 13
Training loss: 0.13886309589522883
Validation loss: 2.295577333883576

Epoch: 453| Step: 0
Training loss: 0.2217799224770784
Validation loss: 2.2503611800006618

Epoch: 6| Step: 1
Training loss: 0.1968797932904157
Validation loss: 2.2625885261444694

Epoch: 6| Step: 2
Training loss: 0.16047703785652026
Validation loss: 2.2417534786178397

Epoch: 6| Step: 3
Training loss: 0.24588265523643993
Validation loss: 2.253967021592679

Epoch: 6| Step: 4
Training loss: 0.23790623906450084
Validation loss: 2.282307650331339

Epoch: 6| Step: 5
Training loss: 0.1927400747568952
Validation loss: 2.2946906541927894

Epoch: 6| Step: 6
Training loss: 0.16755037544818024
Validation loss: 2.2859490848478425

Epoch: 6| Step: 7
Training loss: 0.34724582062108716
Validation loss: 2.2888125746174657

Epoch: 6| Step: 8
Training loss: 0.11061339415808408
Validation loss: 2.2876265766214146

Epoch: 6| Step: 9
Training loss: 0.13905583537129643
Validation loss: 2.2938734316138576

Epoch: 6| Step: 10
Training loss: 0.1525638652960772
Validation loss: 2.2957984187650746

Epoch: 6| Step: 11
Training loss: 0.18400193553792837
Validation loss: 2.3061228197309833

Epoch: 6| Step: 12
Training loss: 0.2771660410026589
Validation loss: 2.264109182578907

Epoch: 6| Step: 13
Training loss: 0.20024640431551277
Validation loss: 2.252028991760606

Epoch: 454| Step: 0
Training loss: 0.20460996324032957
Validation loss: 2.243728852238785

Epoch: 6| Step: 1
Training loss: 0.18763908552303343
Validation loss: 2.265971712337953

Epoch: 6| Step: 2
Training loss: 0.2225906375783626
Validation loss: 2.25215349290633

Epoch: 6| Step: 3
Training loss: 0.2834713159259358
Validation loss: 2.2195235711681542

Epoch: 6| Step: 4
Training loss: 0.24103804040476418
Validation loss: 2.247276826495082

Epoch: 6| Step: 5
Training loss: 0.10285475136652067
Validation loss: 2.2438581891849343

Epoch: 6| Step: 6
Training loss: 0.1815115870233255
Validation loss: 2.2514998656442122

Epoch: 6| Step: 7
Training loss: 0.2519135850738293
Validation loss: 2.284373058461185

Epoch: 6| Step: 8
Training loss: 0.23328613228872466
Validation loss: 2.3023008118456523

Epoch: 6| Step: 9
Training loss: 0.25586819815528533
Validation loss: 2.290161659602124

Epoch: 6| Step: 10
Training loss: 0.16523027347316965
Validation loss: 2.3304697449323033

Epoch: 6| Step: 11
Training loss: 0.16961239990847385
Validation loss: 2.3083439346460377

Epoch: 6| Step: 12
Training loss: 0.1729645063729135
Validation loss: 2.330351433960625

Epoch: 6| Step: 13
Training loss: 0.16909822258456464
Validation loss: 2.2860574304716934

Epoch: 455| Step: 0
Training loss: 0.24296216741151416
Validation loss: 2.318122835737651

Epoch: 6| Step: 1
Training loss: 0.13037695139323383
Validation loss: 2.2944046653223125

Epoch: 6| Step: 2
Training loss: 0.24198125702169523
Validation loss: 2.297924009524159

Epoch: 6| Step: 3
Training loss: 0.17816453796069018
Validation loss: 2.2894900611877227

Epoch: 6| Step: 4
Training loss: 0.30949424988515556
Validation loss: 2.251236015509107

Epoch: 6| Step: 5
Training loss: 0.3024678318204047
Validation loss: 2.2323729057777415

Epoch: 6| Step: 6
Training loss: 0.24023811988702956
Validation loss: 2.2137520389854726

Epoch: 6| Step: 7
Training loss: 0.13809953700843616
Validation loss: 2.2457248818934645

Epoch: 6| Step: 8
Training loss: 0.15149972097210637
Validation loss: 2.2300760712154837

Epoch: 6| Step: 9
Training loss: 0.1870870811862964
Validation loss: 2.233540400972196

Epoch: 6| Step: 10
Training loss: 0.26554914401129565
Validation loss: 2.243222612011188

Epoch: 6| Step: 11
Training loss: 0.17797658995121649
Validation loss: 2.256407870983402

Epoch: 6| Step: 12
Training loss: 0.21749338181062
Validation loss: 2.306531632384397

Epoch: 6| Step: 13
Training loss: 0.06909520710323556
Validation loss: 2.2671249612489186

Epoch: 456| Step: 0
Training loss: 0.25736158125061814
Validation loss: 2.2913885332807875

Epoch: 6| Step: 1
Training loss: 0.16823169730461068
Validation loss: 2.3347984546978076

Epoch: 6| Step: 2
Training loss: 0.2667055870254054
Validation loss: 2.3334613363820385

Epoch: 6| Step: 3
Training loss: 0.1470147006200093
Validation loss: 2.3342416064206146

Epoch: 6| Step: 4
Training loss: 0.1875
Validation loss: 2.3372534754764116

Epoch: 6| Step: 5
Training loss: 0.11260889978177538
Validation loss: 2.334506224225839

Epoch: 6| Step: 6
Training loss: 0.22795768833841945
Validation loss: 2.3193112055221405

Epoch: 6| Step: 7
Training loss: 0.17120521259070845
Validation loss: 2.3071189711483187

Epoch: 6| Step: 8
Training loss: 0.28531532553603395
Validation loss: 2.314524013419677

Epoch: 6| Step: 9
Training loss: 0.16933826546130284
Validation loss: 2.2648807042809707

Epoch: 6| Step: 10
Training loss: 0.19000764687107713
Validation loss: 2.2412595603459002

Epoch: 6| Step: 11
Training loss: 0.26597964229697085
Validation loss: 2.2449392719351593

Epoch: 6| Step: 12
Training loss: 0.19239551482891107
Validation loss: 2.211184150286513

Epoch: 6| Step: 13
Training loss: 0.3296304183286069
Validation loss: 2.2379131235252827

Epoch: 457| Step: 0
Training loss: 0.15698421945922048
Validation loss: 2.219292572756974

Epoch: 6| Step: 1
Training loss: 0.23445204422169982
Validation loss: 2.2144605129208146

Epoch: 6| Step: 2
Training loss: 0.29363655273686134
Validation loss: 2.280746849493639

Epoch: 6| Step: 3
Training loss: 0.17336133367008727
Validation loss: 2.3024334696709947

Epoch: 6| Step: 4
Training loss: 0.22223817323932132
Validation loss: 2.2830014183013403

Epoch: 6| Step: 5
Training loss: 0.16728435856884508
Validation loss: 2.3040417094051535

Epoch: 6| Step: 6
Training loss: 0.3796501133412052
Validation loss: 2.305390641877796

Epoch: 6| Step: 7
Training loss: 0.24730164926868248
Validation loss: 2.355308502639311

Epoch: 6| Step: 8
Training loss: 0.18787927811397034
Validation loss: 2.360872344029284

Epoch: 6| Step: 9
Training loss: 0.11061430347313943
Validation loss: 2.3179113781432057

Epoch: 6| Step: 10
Training loss: 0.25476224832130706
Validation loss: 2.348377985460082

Epoch: 6| Step: 11
Training loss: 0.24679882226304367
Validation loss: 2.357495032207937

Epoch: 6| Step: 12
Training loss: 0.12760892359631673
Validation loss: 2.314788484747206

Epoch: 6| Step: 13
Training loss: 0.15619376481891747
Validation loss: 2.3288878728267535

Epoch: 458| Step: 0
Training loss: 0.26083068203162585
Validation loss: 2.2914349275658266

Epoch: 6| Step: 1
Training loss: 0.2514353021842829
Validation loss: 2.2755741942984944

Epoch: 6| Step: 2
Training loss: 0.20671438764725358
Validation loss: 2.2803167231303467

Epoch: 6| Step: 3
Training loss: 0.1933525642968037
Validation loss: 2.2532795547198896

Epoch: 6| Step: 4
Training loss: 0.23200144528173103
Validation loss: 2.2956288671116023

Epoch: 6| Step: 5
Training loss: 0.23887578086336145
Validation loss: 2.276989866010562

Epoch: 6| Step: 6
Training loss: 0.19270359927024497
Validation loss: 2.234014163435226

Epoch: 6| Step: 7
Training loss: 0.1663714242589622
Validation loss: 2.3068417016602827

Epoch: 6| Step: 8
Training loss: 0.17916521586525685
Validation loss: 2.2747577033255775

Epoch: 6| Step: 9
Training loss: 0.28224533177038597
Validation loss: 2.3301254875666393

Epoch: 6| Step: 10
Training loss: 0.1995530222497822
Validation loss: 2.3062370340168616

Epoch: 6| Step: 11
Training loss: 0.2968312532417015
Validation loss: 2.313042660991031

Epoch: 6| Step: 12
Training loss: 0.16540987916284267
Validation loss: 2.3020935650439758

Epoch: 6| Step: 13
Training loss: 0.14482836212589856
Validation loss: 2.3053962311618372

Epoch: 459| Step: 0
Training loss: 0.1659168061501386
Validation loss: 2.3105195824116187

Epoch: 6| Step: 1
Training loss: 0.19562377920165933
Validation loss: 2.3407793235979657

Epoch: 6| Step: 2
Training loss: 0.20914314157356254
Validation loss: 2.329080132885272

Epoch: 6| Step: 3
Training loss: 0.17451237367273364
Validation loss: 2.3181491684666695

Epoch: 6| Step: 4
Training loss: 0.18028147628896937
Validation loss: 2.3081071259318344

Epoch: 6| Step: 5
Training loss: 0.2468793002490458
Validation loss: 2.287710831531593

Epoch: 6| Step: 6
Training loss: 0.2351560532451833
Validation loss: 2.30027950406728

Epoch: 6| Step: 7
Training loss: 0.3351169256335364
Validation loss: 2.327696540642517

Epoch: 6| Step: 8
Training loss: 0.1975659454380756
Validation loss: 2.288141055280487

Epoch: 6| Step: 9
Training loss: 0.2149333246939776
Validation loss: 2.266736636150299

Epoch: 6| Step: 10
Training loss: 0.21489943736301365
Validation loss: 2.2803236704078955

Epoch: 6| Step: 11
Training loss: 0.26986887421133454
Validation loss: 2.300251881243815

Epoch: 6| Step: 12
Training loss: 0.21771154678899562
Validation loss: 2.2906831668782983

Epoch: 6| Step: 13
Training loss: 0.28348745345386045
Validation loss: 2.2690450154423636

Epoch: 460| Step: 0
Training loss: 0.19937463346286194
Validation loss: 2.2417682537160717

Epoch: 6| Step: 1
Training loss: 0.23443608282754658
Validation loss: 2.2859550886701543

Epoch: 6| Step: 2
Training loss: 0.17035945914269127
Validation loss: 2.272610516387757

Epoch: 6| Step: 3
Training loss: 0.13794438851228477
Validation loss: 2.313925935652143

Epoch: 6| Step: 4
Training loss: 0.19177801657144045
Validation loss: 2.3261270802975824

Epoch: 6| Step: 5
Training loss: 0.24638359470027354
Validation loss: 2.30496309279276

Epoch: 6| Step: 6
Training loss: 0.16030646467095214
Validation loss: 2.32541029511153

Epoch: 6| Step: 7
Training loss: 0.3332845259736591
Validation loss: 2.2997568565529263

Epoch: 6| Step: 8
Training loss: 0.19080676379173514
Validation loss: 2.3182755306600513

Epoch: 6| Step: 9
Training loss: 0.20769700483544196
Validation loss: 2.2881324236777005

Epoch: 6| Step: 10
Training loss: 0.15430347814796297
Validation loss: 2.275550917971453

Epoch: 6| Step: 11
Training loss: 0.19824990130670983
Validation loss: 2.2452160807334844

Epoch: 6| Step: 12
Training loss: 0.16660310357690264
Validation loss: 2.2978705287864454

Epoch: 6| Step: 13
Training loss: 0.4176689035002342
Validation loss: 2.252041172279026

Epoch: 461| Step: 0
Training loss: 0.12052700641061286
Validation loss: 2.2485192022407516

Epoch: 6| Step: 1
Training loss: 0.28374904762645997
Validation loss: 2.2756302688128063

Epoch: 6| Step: 2
Training loss: 0.17398570986485326
Validation loss: 2.272752271297527

Epoch: 6| Step: 3
Training loss: 0.18660563510206127
Validation loss: 2.3004491110740455

Epoch: 6| Step: 4
Training loss: 0.22500651535561475
Validation loss: 2.2796478376666416

Epoch: 6| Step: 5
Training loss: 0.272373062237188
Validation loss: 2.3098781858921256

Epoch: 6| Step: 6
Training loss: 0.1628905399239956
Validation loss: 2.2605962900722774

Epoch: 6| Step: 7
Training loss: 0.20554422363055938
Validation loss: 2.293033609068488

Epoch: 6| Step: 8
Training loss: 0.17089993612449786
Validation loss: 2.293964466982448

Epoch: 6| Step: 9
Training loss: 0.11404021646399645
Validation loss: 2.270087846139764

Epoch: 6| Step: 10
Training loss: 0.16278692919644175
Validation loss: 2.313036392204325

Epoch: 6| Step: 11
Training loss: 0.21802218305246224
Validation loss: 2.256087650787777

Epoch: 6| Step: 12
Training loss: 0.27954360094499087
Validation loss: 2.244263555006668

Epoch: 6| Step: 13
Training loss: 0.19640863866271518
Validation loss: 2.3028435584707037

Epoch: 462| Step: 0
Training loss: 0.13077635052890982
Validation loss: 2.2729008029177247

Epoch: 6| Step: 1
Training loss: 0.2007015433718741
Validation loss: 2.2705182454018025

Epoch: 6| Step: 2
Training loss: 0.20254421650610954
Validation loss: 2.29000779200162

Epoch: 6| Step: 3
Training loss: 0.17301238385773934
Validation loss: 2.276330994580633

Epoch: 6| Step: 4
Training loss: 0.21929805085315757
Validation loss: 2.2991428637750877

Epoch: 6| Step: 5
Training loss: 0.15289860332765182
Validation loss: 2.3059474664933854

Epoch: 6| Step: 6
Training loss: 0.16992732291422108
Validation loss: 2.2907056920979025

Epoch: 6| Step: 7
Training loss: 0.1412615409710503
Validation loss: 2.306707673617294

Epoch: 6| Step: 8
Training loss: 0.2869549939567008
Validation loss: 2.2954572730927207

Epoch: 6| Step: 9
Training loss: 0.1477400115767027
Validation loss: 2.274455735674121

Epoch: 6| Step: 10
Training loss: 0.1656771069558335
Validation loss: 2.2698513979479746

Epoch: 6| Step: 11
Training loss: 0.23684607251160159
Validation loss: 2.26035135521765

Epoch: 6| Step: 12
Training loss: 0.09802000486876461
Validation loss: 2.2746470367649905

Epoch: 6| Step: 13
Training loss: 0.3360036296960645
Validation loss: 2.2730508919681784

Epoch: 463| Step: 0
Training loss: 0.14667164593836485
Validation loss: 2.311700215343489

Epoch: 6| Step: 1
Training loss: 0.25554012444774743
Validation loss: 2.305424035598285

Epoch: 6| Step: 2
Training loss: 0.2271323600976837
Validation loss: 2.252750899295463

Epoch: 6| Step: 3
Training loss: 0.2919019093862045
Validation loss: 2.2755758253195393

Epoch: 6| Step: 4
Training loss: 0.15567832316669275
Validation loss: 2.214753771927729

Epoch: 6| Step: 5
Training loss: 0.14438547051018705
Validation loss: 2.2172721217119875

Epoch: 6| Step: 6
Training loss: 0.12665308195077307
Validation loss: 2.2015465858395666

Epoch: 6| Step: 7
Training loss: 0.29731166247509916
Validation loss: 2.1795457930703224

Epoch: 6| Step: 8
Training loss: 0.2351132527833531
Validation loss: 2.194877257599336

Epoch: 6| Step: 9
Training loss: 0.17194486411883456
Validation loss: 2.1940567768776273

Epoch: 6| Step: 10
Training loss: 0.19760125944512275
Validation loss: 2.1986089282153176

Epoch: 6| Step: 11
Training loss: 0.27069881044943084
Validation loss: 2.215289770675872

Epoch: 6| Step: 12
Training loss: 0.2413589548490207
Validation loss: 2.2363886784377605

Epoch: 6| Step: 13
Training loss: 0.3656132410880994
Validation loss: 2.249470608596594

Epoch: 464| Step: 0
Training loss: 0.273778498420347
Validation loss: 2.2738986731424298

Epoch: 6| Step: 1
Training loss: 0.14553624073847737
Validation loss: 2.272716077775129

Epoch: 6| Step: 2
Training loss: 0.17060350308871705
Validation loss: 2.258903502398743

Epoch: 6| Step: 3
Training loss: 0.3272515774878999
Validation loss: 2.28731229977966

Epoch: 6| Step: 4
Training loss: 0.12204679644094607
Validation loss: 2.2976916272473544

Epoch: 6| Step: 5
Training loss: 0.2889031022283579
Validation loss: 2.330859757600498

Epoch: 6| Step: 6
Training loss: 0.28183014956933217
Validation loss: 2.327787273626903

Epoch: 6| Step: 7
Training loss: 0.14528069276224861
Validation loss: 2.329059266641753

Epoch: 6| Step: 8
Training loss: 0.1278781204542075
Validation loss: 2.2963166039801237

Epoch: 6| Step: 9
Training loss: 0.25031644939493014
Validation loss: 2.337562531639518

Epoch: 6| Step: 10
Training loss: 0.19387118679566362
Validation loss: 2.330622932752313

Epoch: 6| Step: 11
Training loss: 0.16848891689005613
Validation loss: 2.3062855197970107

Epoch: 6| Step: 12
Training loss: 0.27889022033104666
Validation loss: 2.2871177291167597

Epoch: 6| Step: 13
Training loss: 0.33945446079987796
Validation loss: 2.299722482043632

Epoch: 465| Step: 0
Training loss: 0.15667375680317014
Validation loss: 2.2981201551534456

Epoch: 6| Step: 1
Training loss: 0.23607373535884407
Validation loss: 2.2758159976589045

Epoch: 6| Step: 2
Training loss: 0.18813525312941212
Validation loss: 2.264622798100753

Epoch: 6| Step: 3
Training loss: 0.32381072279459533
Validation loss: 2.2511212330809314

Epoch: 6| Step: 4
Training loss: 0.32436740868198716
Validation loss: 2.278415400559886

Epoch: 6| Step: 5
Training loss: 0.28776982955151825
Validation loss: 2.265320202017635

Epoch: 6| Step: 6
Training loss: 0.14544207733026523
Validation loss: 2.307043341409496

Epoch: 6| Step: 7
Training loss: 0.34856931391296225
Validation loss: 2.2849942680271376

Epoch: 6| Step: 8
Training loss: 0.18771409686008142
Validation loss: 2.3161901167626158

Epoch: 6| Step: 9
Training loss: 0.2223732304012142
Validation loss: 2.285030903764651

Epoch: 6| Step: 10
Training loss: 0.22340531417473522
Validation loss: 2.296317058360688

Epoch: 6| Step: 11
Training loss: 0.31972223650616227
Validation loss: 2.279390384850659

Epoch: 6| Step: 12
Training loss: 0.24723871997698316
Validation loss: 2.252024803696108

Epoch: 6| Step: 13
Training loss: 0.12434832005228796
Validation loss: 2.233131894152247

Epoch: 466| Step: 0
Training loss: 0.2131987537929791
Validation loss: 2.193716599601315

Epoch: 6| Step: 1
Training loss: 0.2090870792041457
Validation loss: 2.187195063137596

Epoch: 6| Step: 2
Training loss: 0.3008619918451888
Validation loss: 2.165493151184649

Epoch: 6| Step: 3
Training loss: 0.22547387977099337
Validation loss: 2.185583088646356

Epoch: 6| Step: 4
Training loss: 0.3848204985086735
Validation loss: 2.177747431345797

Epoch: 6| Step: 5
Training loss: 0.16634825873548564
Validation loss: 2.210125858135609

Epoch: 6| Step: 6
Training loss: 0.2455215310669605
Validation loss: 2.2473202280594196

Epoch: 6| Step: 7
Training loss: 0.17135717675329615
Validation loss: 2.259015095975228

Epoch: 6| Step: 8
Training loss: 0.4082608706866027
Validation loss: 2.2504668440794635

Epoch: 6| Step: 9
Training loss: 0.19306933681056426
Validation loss: 2.2236118173977837

Epoch: 6| Step: 10
Training loss: 0.17767249067517038
Validation loss: 2.2995902007143156

Epoch: 6| Step: 11
Training loss: 0.16902922602545645
Validation loss: 2.2663320409140115

Epoch: 6| Step: 12
Training loss: 0.22070096445292037
Validation loss: 2.2568226446369395

Epoch: 6| Step: 13
Training loss: 0.3276558996916332
Validation loss: 2.316191488684378

Epoch: 467| Step: 0
Training loss: 0.2593703740638112
Validation loss: 2.2952518129786257

Epoch: 6| Step: 1
Training loss: 0.22163254492858958
Validation loss: 2.2476798301263226

Epoch: 6| Step: 2
Training loss: 0.2517552744853644
Validation loss: 2.2578645610686676

Epoch: 6| Step: 3
Training loss: 0.22623709626046132
Validation loss: 2.2565179380710187

Epoch: 6| Step: 4
Training loss: 0.16018854955291428
Validation loss: 2.217225276058615

Epoch: 6| Step: 5
Training loss: 0.2305157985186268
Validation loss: 2.204517654808541

Epoch: 6| Step: 6
Training loss: 0.26243973108239477
Validation loss: 2.181293995378849

Epoch: 6| Step: 7
Training loss: 0.3061465395144512
Validation loss: 2.18809480329983

Epoch: 6| Step: 8
Training loss: 0.30279237745289184
Validation loss: 2.163671409991177

Epoch: 6| Step: 9
Training loss: 0.3091713533706032
Validation loss: 2.186542339888381

Epoch: 6| Step: 10
Training loss: 0.2881287623757665
Validation loss: 2.222309730222798

Epoch: 6| Step: 11
Training loss: 0.1971446506717794
Validation loss: 2.226567716939615

Epoch: 6| Step: 12
Training loss: 0.37774783941846446
Validation loss: 2.258744647580078

Epoch: 6| Step: 13
Training loss: 0.15789489389242342
Validation loss: 2.26434630680793

Epoch: 468| Step: 0
Training loss: 0.27267119795695693
Validation loss: 2.297082530413706

Epoch: 6| Step: 1
Training loss: 0.24272748522991497
Validation loss: 2.278134328690077

Epoch: 6| Step: 2
Training loss: 0.13015859766625426
Validation loss: 2.306674947538253

Epoch: 6| Step: 3
Training loss: 0.20247226154233797
Validation loss: 2.3226220321001465

Epoch: 6| Step: 4
Training loss: 0.2165802999367576
Validation loss: 2.327726718364853

Epoch: 6| Step: 5
Training loss: 0.24070388380288257
Validation loss: 2.3303920589825133

Epoch: 6| Step: 6
Training loss: 0.2511426769270786
Validation loss: 2.3459274634038096

Epoch: 6| Step: 7
Training loss: 0.19760597252979967
Validation loss: 2.3340174507841738

Epoch: 6| Step: 8
Training loss: 0.2614204072738357
Validation loss: 2.277882370330292

Epoch: 6| Step: 9
Training loss: 0.1746665579333525
Validation loss: 2.2772518109780173

Epoch: 6| Step: 10
Training loss: 0.2971159810232834
Validation loss: 2.2995205607229545

Epoch: 6| Step: 11
Training loss: 0.14881348675605366
Validation loss: 2.293606028867252

Epoch: 6| Step: 12
Training loss: 0.19383631752348676
Validation loss: 2.2835986534816684

Epoch: 6| Step: 13
Training loss: 0.39163911786827177
Validation loss: 2.2580156995254654

Epoch: 469| Step: 0
Training loss: 0.1253314466850698
Validation loss: 2.252581915222998

Epoch: 6| Step: 1
Training loss: 0.3037271035359796
Validation loss: 2.258484632303446

Epoch: 6| Step: 2
Training loss: 0.225581610832172
Validation loss: 2.281966995344763

Epoch: 6| Step: 3
Training loss: 0.2365935702813861
Validation loss: 2.287620691843229

Epoch: 6| Step: 4
Training loss: 0.2064045832506756
Validation loss: 2.2513339703962743

Epoch: 6| Step: 5
Training loss: 0.17262750317252365
Validation loss: 2.252943292360845

Epoch: 6| Step: 6
Training loss: 0.18516726561666058
Validation loss: 2.2542941164794086

Epoch: 6| Step: 7
Training loss: 0.17028418095531023
Validation loss: 2.245298409270579

Epoch: 6| Step: 8
Training loss: 0.2473772878555511
Validation loss: 2.2558173605562133

Epoch: 6| Step: 9
Training loss: 0.20737407298740276
Validation loss: 2.2421761314844497

Epoch: 6| Step: 10
Training loss: 0.36210598084999934
Validation loss: 2.207794159087883

Epoch: 6| Step: 11
Training loss: 0.2875640668181707
Validation loss: 2.2094404293944585

Epoch: 6| Step: 12
Training loss: 0.25225844107494055
Validation loss: 2.215713368742707

Epoch: 6| Step: 13
Training loss: 0.20830066643348244
Validation loss: 2.242334258210367

Epoch: 470| Step: 0
Training loss: 0.178680990659615
Validation loss: 2.226413051538497

Epoch: 6| Step: 1
Training loss: 0.18580723615261033
Validation loss: 2.235308964184357

Epoch: 6| Step: 2
Training loss: 0.2878457183182505
Validation loss: 2.2302420694758287

Epoch: 6| Step: 3
Training loss: 0.2937622260532179
Validation loss: 2.2510444331741613

Epoch: 6| Step: 4
Training loss: 0.2106957197885913
Validation loss: 2.2802577769418093

Epoch: 6| Step: 5
Training loss: 0.27241827517976197
Validation loss: 2.315598587816136

Epoch: 6| Step: 6
Training loss: 0.30995460027839844
Validation loss: 2.3309940488495298

Epoch: 6| Step: 7
Training loss: 0.18021383116352777
Validation loss: 2.329866172101556

Epoch: 6| Step: 8
Training loss: 0.278355539334551
Validation loss: 2.349583116626612

Epoch: 6| Step: 9
Training loss: 0.15288156553706606
Validation loss: 2.3133449158315464

Epoch: 6| Step: 10
Training loss: 0.3197727773515623
Validation loss: 2.337963423481897

Epoch: 6| Step: 11
Training loss: 0.11883126022722239
Validation loss: 2.3099300637574656

Epoch: 6| Step: 12
Training loss: 0.2415028246197078
Validation loss: 2.2924620365857034

Epoch: 6| Step: 13
Training loss: 0.21477216915291586
Validation loss: 2.3143104321970758

Epoch: 471| Step: 0
Training loss: 0.21533643410954148
Validation loss: 2.271428864320234

Epoch: 6| Step: 1
Training loss: 0.22462424353438737
Validation loss: 2.2708801233852984

Epoch: 6| Step: 2
Training loss: 0.19091326617525067
Validation loss: 2.276192078342108

Epoch: 6| Step: 3
Training loss: 0.16192051790665007
Validation loss: 2.2668254756699273

Epoch: 6| Step: 4
Training loss: 0.1776069351905283
Validation loss: 2.2683570154894466

Epoch: 6| Step: 5
Training loss: 0.2925570074183957
Validation loss: 2.2684206584300504

Epoch: 6| Step: 6
Training loss: 0.18568545737695072
Validation loss: 2.283375657592564

Epoch: 6| Step: 7
Training loss: 0.2482926585275315
Validation loss: 2.244987894538044

Epoch: 6| Step: 8
Training loss: 0.1916693028151245
Validation loss: 2.26864100676112

Epoch: 6| Step: 9
Training loss: 0.2644342491817431
Validation loss: 2.286619054941477

Epoch: 6| Step: 10
Training loss: 0.29244814074749176
Validation loss: 2.285804096750475

Epoch: 6| Step: 11
Training loss: 0.20474312077541484
Validation loss: 2.285097364703463

Epoch: 6| Step: 12
Training loss: 0.16229751883236115
Validation loss: 2.2927324100885875

Epoch: 6| Step: 13
Training loss: 0.22384049213322774
Validation loss: 2.2712753377894153

Epoch: 472| Step: 0
Training loss: 0.22518876025683393
Validation loss: 2.235553309427531

Epoch: 6| Step: 1
Training loss: 0.18872073273454953
Validation loss: 2.2186231494572275

Epoch: 6| Step: 2
Training loss: 0.19690090871812396
Validation loss: 2.241908968209616

Epoch: 6| Step: 3
Training loss: 0.2272001206042161
Validation loss: 2.2225087535707964

Epoch: 6| Step: 4
Training loss: 0.14471399507513907
Validation loss: 2.2237971324922556

Epoch: 6| Step: 5
Training loss: 0.17622526569331542
Validation loss: 2.185528537455907

Epoch: 6| Step: 6
Training loss: 0.20752961975707274
Validation loss: 2.172848334425837

Epoch: 6| Step: 7
Training loss: 0.30260917781985514
Validation loss: 2.2851297928651335

Epoch: 6| Step: 8
Training loss: 0.19030426002854395
Validation loss: 2.25408395083161

Epoch: 6| Step: 9
Training loss: 0.3391599462383838
Validation loss: 2.2401541194069896

Epoch: 6| Step: 10
Training loss: 0.3282160519108837
Validation loss: 2.252880448277487

Epoch: 6| Step: 11
Training loss: 0.18049701494102421
Validation loss: 2.267869919313984

Epoch: 6| Step: 12
Training loss: 0.15093259257479627
Validation loss: 2.263051781556673

Epoch: 6| Step: 13
Training loss: 0.18816396257501997
Validation loss: 2.2747394896041646

Epoch: 473| Step: 0
Training loss: 0.18818786727099146
Validation loss: 2.270500642674973

Epoch: 6| Step: 1
Training loss: 0.27680310758313315
Validation loss: 2.271446010655806

Epoch: 6| Step: 2
Training loss: 0.332602581570356
Validation loss: 2.2954660189891514

Epoch: 6| Step: 3
Training loss: 0.30485962627448043
Validation loss: 2.284872564617142

Epoch: 6| Step: 4
Training loss: 0.21057755170714243
Validation loss: 2.28332765988851

Epoch: 6| Step: 5
Training loss: 0.28253716401588724
Validation loss: 2.271338163898218

Epoch: 6| Step: 6
Training loss: 0.14312165010688185
Validation loss: 2.284440595107222

Epoch: 6| Step: 7
Training loss: 0.22056548291094757
Validation loss: 2.293588968835124

Epoch: 6| Step: 8
Training loss: 0.18171477086310045
Validation loss: 2.276827589328817

Epoch: 6| Step: 9
Training loss: 0.1445694048238985
Validation loss: 2.2778723132950436

Epoch: 6| Step: 10
Training loss: 0.17821879970610713
Validation loss: 2.2783720489892905

Epoch: 6| Step: 11
Training loss: 0.16489849085623268
Validation loss: 2.268009833032515

Epoch: 6| Step: 12
Training loss: 0.23841789892481102
Validation loss: 2.280915213694719

Epoch: 6| Step: 13
Training loss: 0.22547465630591929
Validation loss: 2.2345767765854117

Epoch: 474| Step: 0
Training loss: 0.14134933105927128
Validation loss: 2.2431189187560476

Epoch: 6| Step: 1
Training loss: 0.24241648892693043
Validation loss: 2.2333806053409027

Epoch: 6| Step: 2
Training loss: 0.2776994707410891
Validation loss: 2.2305214544524974

Epoch: 6| Step: 3
Training loss: 0.21863718188978418
Validation loss: 2.2081111489324172

Epoch: 6| Step: 4
Training loss: 0.34145770001696973
Validation loss: 2.2115819891695994

Epoch: 6| Step: 5
Training loss: 0.24794652365699318
Validation loss: 2.212223890598093

Epoch: 6| Step: 6
Training loss: 0.11402837017324333
Validation loss: 2.205447621899422

Epoch: 6| Step: 7
Training loss: 0.15230238181651265
Validation loss: 2.191984964053999

Epoch: 6| Step: 8
Training loss: 0.21338790595238522
Validation loss: 2.180539617991195

Epoch: 6| Step: 9
Training loss: 0.1794266569707388
Validation loss: 2.2122105104495384

Epoch: 6| Step: 10
Training loss: 0.2858900270503214
Validation loss: 2.215511930406633

Epoch: 6| Step: 11
Training loss: 0.21813228789016728
Validation loss: 2.203014877500649

Epoch: 6| Step: 12
Training loss: 0.22407355043197108
Validation loss: 2.1893247350639293

Epoch: 6| Step: 13
Training loss: 0.20417686606414207
Validation loss: 2.2254989297372196

Epoch: 475| Step: 0
Training loss: 0.21880293103563658
Validation loss: 2.2028432814458743

Epoch: 6| Step: 1
Training loss: 0.21231490341355644
Validation loss: 2.2236612000463505

Epoch: 6| Step: 2
Training loss: 0.16977574653138364
Validation loss: 2.2261862036197595

Epoch: 6| Step: 3
Training loss: 0.25155892695383236
Validation loss: 2.2308693383430374

Epoch: 6| Step: 4
Training loss: 0.3015731073401555
Validation loss: 2.241670012350529

Epoch: 6| Step: 5
Training loss: 0.2496313043671233
Validation loss: 2.2654371048605775

Epoch: 6| Step: 6
Training loss: 0.25449359158577256
Validation loss: 2.293382600353241

Epoch: 6| Step: 7
Training loss: 0.20930586356653869
Validation loss: 2.282298085132022

Epoch: 6| Step: 8
Training loss: 0.1696696437306423
Validation loss: 2.3043673685609436

Epoch: 6| Step: 9
Training loss: 0.21775395259160396
Validation loss: 2.32363644788154

Epoch: 6| Step: 10
Training loss: 0.13128867118933762
Validation loss: 2.345981057214147

Epoch: 6| Step: 11
Training loss: 0.15884114756676546
Validation loss: 2.356855500370101

Epoch: 6| Step: 12
Training loss: 0.27809894525450707
Validation loss: 2.3508745682902643

Epoch: 6| Step: 13
Training loss: 0.19766190826097302
Validation loss: 2.3639824910553515

Epoch: 476| Step: 0
Training loss: 0.27105217430707734
Validation loss: 2.359862948283291

Epoch: 6| Step: 1
Training loss: 0.20983233394516107
Validation loss: 2.3058186264556655

Epoch: 6| Step: 2
Training loss: 0.20170263992855259
Validation loss: 2.332134044278882

Epoch: 6| Step: 3
Training loss: 0.11599054193835713
Validation loss: 2.3160815408839697

Epoch: 6| Step: 4
Training loss: 0.2214080053191238
Validation loss: 2.2694649352991263

Epoch: 6| Step: 5
Training loss: 0.1589965410287405
Validation loss: 2.2497857893673516

Epoch: 6| Step: 6
Training loss: 0.28154585430295376
Validation loss: 2.2643256354273045

Epoch: 6| Step: 7
Training loss: 0.23859394380752696
Validation loss: 2.2529932368347825

Epoch: 6| Step: 8
Training loss: 0.1939997232720279
Validation loss: 2.2611582581872223

Epoch: 6| Step: 9
Training loss: 0.22652863380930596
Validation loss: 2.2554012082442063

Epoch: 6| Step: 10
Training loss: 0.19736599021385084
Validation loss: 2.305459719528899

Epoch: 6| Step: 11
Training loss: 0.2842871472612011
Validation loss: 2.2781822343805547

Epoch: 6| Step: 12
Training loss: 0.1664688375464557
Validation loss: 2.2498811476204477

Epoch: 6| Step: 13
Training loss: 0.17115720504095894
Validation loss: 2.2856593495771724

Epoch: 477| Step: 0
Training loss: 0.21146751855215723
Validation loss: 2.274428242195419

Epoch: 6| Step: 1
Training loss: 0.18729702572869414
Validation loss: 2.2867792637615123

Epoch: 6| Step: 2
Training loss: 0.272474623579071
Validation loss: 2.2813002451174436

Epoch: 6| Step: 3
Training loss: 0.2233618214631036
Validation loss: 2.2838230930494605

Epoch: 6| Step: 4
Training loss: 0.1724838829112988
Validation loss: 2.293772755694653

Epoch: 6| Step: 5
Training loss: 0.33057397921070736
Validation loss: 2.274106885827832

Epoch: 6| Step: 6
Training loss: 0.17053769866748925
Validation loss: 2.3030846101269744

Epoch: 6| Step: 7
Training loss: 0.22785937802863365
Validation loss: 2.2881855810722413

Epoch: 6| Step: 8
Training loss: 0.2587809723363243
Validation loss: 2.281466199761209

Epoch: 6| Step: 9
Training loss: 0.21519254634545262
Validation loss: 2.2615889058711027

Epoch: 6| Step: 10
Training loss: 0.2587935537272425
Validation loss: 2.2809575514731137

Epoch: 6| Step: 11
Training loss: 0.19325770007210905
Validation loss: 2.294671263895112

Epoch: 6| Step: 12
Training loss: 0.17450610825838336
Validation loss: 2.2648223875379685

Epoch: 6| Step: 13
Training loss: 0.336935800044619
Validation loss: 2.272118195800135

Epoch: 478| Step: 0
Training loss: 0.2379601769960088
Validation loss: 2.2259804103475695

Epoch: 6| Step: 1
Training loss: 0.15996731686010685
Validation loss: 2.24744240695874

Epoch: 6| Step: 2
Training loss: 0.1577854706967887
Validation loss: 2.253500192176437

Epoch: 6| Step: 3
Training loss: 0.2507333281889733
Validation loss: 2.2222188863891597

Epoch: 6| Step: 4
Training loss: 0.224121692133086
Validation loss: 2.2193163527777005

Epoch: 6| Step: 5
Training loss: 0.2001944193005989
Validation loss: 2.179036055185296

Epoch: 6| Step: 6
Training loss: 0.13596850677359765
Validation loss: 2.1993111814822077

Epoch: 6| Step: 7
Training loss: 0.18549599200800276
Validation loss: 2.2489274133472184

Epoch: 6| Step: 8
Training loss: 0.2783670754214717
Validation loss: 2.232788268318568

Epoch: 6| Step: 9
Training loss: 0.23597577523509217
Validation loss: 2.2419162429092507

Epoch: 6| Step: 10
Training loss: 0.39747640218805924
Validation loss: 2.261527786468988

Epoch: 6| Step: 11
Training loss: 0.15064351382580282
Validation loss: 2.2217524571194183

Epoch: 6| Step: 12
Training loss: 0.2378608324785202
Validation loss: 2.232489826313474

Epoch: 6| Step: 13
Training loss: 0.3025494656827436
Validation loss: 2.242531346062139

Epoch: 479| Step: 0
Training loss: 0.28641654779096737
Validation loss: 2.2332626374592035

Epoch: 6| Step: 1
Training loss: 0.26825347654430914
Validation loss: 2.285263731274374

Epoch: 6| Step: 2
Training loss: 0.21930309603476045
Validation loss: 2.264492619531671

Epoch: 6| Step: 3
Training loss: 0.27259146732335354
Validation loss: 2.2762225475220097

Epoch: 6| Step: 4
Training loss: 0.25924065971562354
Validation loss: 2.280151696159157

Epoch: 6| Step: 5
Training loss: 0.22838455092738333
Validation loss: 2.284789152470284

Epoch: 6| Step: 6
Training loss: 0.1972161788156283
Validation loss: 2.2868820109222896

Epoch: 6| Step: 7
Training loss: 0.21046654791412753
Validation loss: 2.2902345703988183

Epoch: 6| Step: 8
Training loss: 0.1914137819326328
Validation loss: 2.2952226526258395

Epoch: 6| Step: 9
Training loss: 0.2897529346672917
Validation loss: 2.267143132536013

Epoch: 6| Step: 10
Training loss: 0.242394827730109
Validation loss: 2.307239077892879

Epoch: 6| Step: 11
Training loss: 0.11973833023163374
Validation loss: 2.3364532688193087

Epoch: 6| Step: 12
Training loss: 0.18435490870519522
Validation loss: 2.3717196553515967

Epoch: 6| Step: 13
Training loss: 0.1595264472574746
Validation loss: 2.351056099296238

Epoch: 480| Step: 0
Training loss: 0.24949533964918919
Validation loss: 2.3938868622718315

Epoch: 6| Step: 1
Training loss: 0.2969466047767959
Validation loss: 2.394851650019632

Epoch: 6| Step: 2
Training loss: 0.3294636124372526
Validation loss: 2.3754447559433536

Epoch: 6| Step: 3
Training loss: 0.2308292721068035
Validation loss: 2.333605756619275

Epoch: 6| Step: 4
Training loss: 0.1636646646991773
Validation loss: 2.305839641583659

Epoch: 6| Step: 5
Training loss: 0.1828009247171888
Validation loss: 2.28484902859765

Epoch: 6| Step: 6
Training loss: 0.16320695784009212
Validation loss: 2.2874135576046117

Epoch: 6| Step: 7
Training loss: 0.346971673639282
Validation loss: 2.2316679868669937

Epoch: 6| Step: 8
Training loss: 0.20970280770483243
Validation loss: 2.2466097622331263

Epoch: 6| Step: 9
Training loss: 0.25489014947496463
Validation loss: 2.2313331914572925

Epoch: 6| Step: 10
Training loss: 0.22170038168686756
Validation loss: 2.243675947285553

Epoch: 6| Step: 11
Training loss: 0.30446046537967764
Validation loss: 2.234976952091611

Epoch: 6| Step: 12
Training loss: 0.15105556281610308
Validation loss: 2.2720252667610414

Epoch: 6| Step: 13
Training loss: 0.23731062924830948
Validation loss: 2.291151835391094

Epoch: 481| Step: 0
Training loss: 0.3034376159534174
Validation loss: 2.307108828766575

Epoch: 6| Step: 1
Training loss: 0.1790290044909068
Validation loss: 2.3269189812159015

Epoch: 6| Step: 2
Training loss: 0.20921358569368853
Validation loss: 2.38705025540699

Epoch: 6| Step: 3
Training loss: 0.21152120643629657
Validation loss: 2.384614076394935

Epoch: 6| Step: 4
Training loss: 0.1703381755268746
Validation loss: 2.3822864615508528

Epoch: 6| Step: 5
Training loss: 0.24114471175068217
Validation loss: 2.375063338349961

Epoch: 6| Step: 6
Training loss: 0.23348042313063017
Validation loss: 2.3659460212241927

Epoch: 6| Step: 7
Training loss: 0.26641979239042846
Validation loss: 2.419779719248091

Epoch: 6| Step: 8
Training loss: 0.2204966211984577
Validation loss: 2.3618057052876416

Epoch: 6| Step: 9
Training loss: 0.23105848152870026
Validation loss: 2.317681285280466

Epoch: 6| Step: 10
Training loss: 0.2443966095728621
Validation loss: 2.3197331389377136

Epoch: 6| Step: 11
Training loss: 0.2407914502497744
Validation loss: 2.2761974456461944

Epoch: 6| Step: 12
Training loss: 0.3010178787024311
Validation loss: 2.2408215723880884

Epoch: 6| Step: 13
Training loss: 0.3691574980901088
Validation loss: 2.2374863667295317

Epoch: 482| Step: 0
Training loss: 0.18494696760744278
Validation loss: 2.222120059638394

Epoch: 6| Step: 1
Training loss: 0.18105929676431415
Validation loss: 2.224458497052766

Epoch: 6| Step: 2
Training loss: 0.2909456591378851
Validation loss: 2.2439671298730306

Epoch: 6| Step: 3
Training loss: 0.2858109470327744
Validation loss: 2.235254217567906

Epoch: 6| Step: 4
Training loss: 0.1427912295275619
Validation loss: 2.2258317693522076

Epoch: 6| Step: 5
Training loss: 0.21979434345447385
Validation loss: 2.238745015997189

Epoch: 6| Step: 6
Training loss: 0.27960200414884123
Validation loss: 2.250420046921545

Epoch: 6| Step: 7
Training loss: 0.26104448774893263
Validation loss: 2.2281078043007794

Epoch: 6| Step: 8
Training loss: 0.1410266782069052
Validation loss: 2.23949262278396

Epoch: 6| Step: 9
Training loss: 0.18079783667698554
Validation loss: 2.2579626672199318

Epoch: 6| Step: 10
Training loss: 0.2745356171748576
Validation loss: 2.2279513224661502

Epoch: 6| Step: 11
Training loss: 0.16222715120968825
Validation loss: 2.255758535610789

Epoch: 6| Step: 12
Training loss: 0.3373878354432608
Validation loss: 2.2830518820180696

Epoch: 6| Step: 13
Training loss: 0.2683544591595035
Validation loss: 2.3207970138850653

Epoch: 483| Step: 0
Training loss: 0.17332459503584854
Validation loss: 2.318372315029625

Epoch: 6| Step: 1
Training loss: 0.27158829874860646
Validation loss: 2.346525777471801

Epoch: 6| Step: 2
Training loss: 0.18308519378309213
Validation loss: 2.331411151901877

Epoch: 6| Step: 3
Training loss: 0.2848900898430599
Validation loss: 2.3414331263281043

Epoch: 6| Step: 4
Training loss: 0.19289791065607764
Validation loss: 2.3181956323799144

Epoch: 6| Step: 5
Training loss: 0.20606739673922775
Validation loss: 2.3094833248375544

Epoch: 6| Step: 6
Training loss: 0.1829644944781709
Validation loss: 2.2765384645411038

Epoch: 6| Step: 7
Training loss: 0.2069939813717932
Validation loss: 2.30307343090009

Epoch: 6| Step: 8
Training loss: 0.24878239653119139
Validation loss: 2.279380292854791

Epoch: 6| Step: 9
Training loss: 0.21885103208635354
Validation loss: 2.2915698421603734

Epoch: 6| Step: 10
Training loss: 0.17607001851298462
Validation loss: 2.2711602564883173

Epoch: 6| Step: 11
Training loss: 0.25046252142383546
Validation loss: 2.2479407265281357

Epoch: 6| Step: 12
Training loss: 0.1867565276423485
Validation loss: 2.263832025818103

Epoch: 6| Step: 13
Training loss: 0.1906652021227484
Validation loss: 2.261044794688066

Epoch: 484| Step: 0
Training loss: 0.1438963321494704
Validation loss: 2.1910559568554873

Epoch: 6| Step: 1
Training loss: 0.17027525494544793
Validation loss: 2.1878663419908397

Epoch: 6| Step: 2
Training loss: 0.2143445892006107
Validation loss: 2.2328877896835655

Epoch: 6| Step: 3
Training loss: 0.2724863129424427
Validation loss: 2.2244315144857785

Epoch: 6| Step: 4
Training loss: 0.2587663604567401
Validation loss: 2.2413348648811167

Epoch: 6| Step: 5
Training loss: 0.2533171642522541
Validation loss: 2.237574963789898

Epoch: 6| Step: 6
Training loss: 0.26487027263338275
Validation loss: 2.25376106147608

Epoch: 6| Step: 7
Training loss: 0.1653508959134276
Validation loss: 2.262005435088892

Epoch: 6| Step: 8
Training loss: 0.22204580616333036
Validation loss: 2.2800669786452046

Epoch: 6| Step: 9
Training loss: 0.28324036188974816
Validation loss: 2.3116524253631474

Epoch: 6| Step: 10
Training loss: 0.17047621749969588
Validation loss: 2.2646564952458634

Epoch: 6| Step: 11
Training loss: 0.24739210560985078
Validation loss: 2.3051582557819406

Epoch: 6| Step: 12
Training loss: 0.19463687388509449
Validation loss: 2.235282830840447

Epoch: 6| Step: 13
Training loss: 0.24336726725411284
Validation loss: 2.2570989887679644

Epoch: 485| Step: 0
Training loss: 0.1629012140999091
Validation loss: 2.2466804349527374

Epoch: 6| Step: 1
Training loss: 0.1773394504311602
Validation loss: 2.2530264781077656

Epoch: 6| Step: 2
Training loss: 0.11904960031790773
Validation loss: 2.2583939339122874

Epoch: 6| Step: 3
Training loss: 0.28287102531037717
Validation loss: 2.2392383835392504

Epoch: 6| Step: 4
Training loss: 0.2613776247046908
Validation loss: 2.241462086234659

Epoch: 6| Step: 5
Training loss: 0.18353607408083578
Validation loss: 2.235177682797477

Epoch: 6| Step: 6
Training loss: 0.21465931692138593
Validation loss: 2.2534118981474545

Epoch: 6| Step: 7
Training loss: 0.19987185329073973
Validation loss: 2.2168692151235243

Epoch: 6| Step: 8
Training loss: 0.15251740315286627
Validation loss: 2.19933038208673

Epoch: 6| Step: 9
Training loss: 0.12579734385342278
Validation loss: 2.2232122382057846

Epoch: 6| Step: 10
Training loss: 0.17279820238192214
Validation loss: 2.1823639421718988

Epoch: 6| Step: 11
Training loss: 0.23377101481162382
Validation loss: 2.2150834942671334

Epoch: 6| Step: 12
Training loss: 0.2405965679884138
Validation loss: 2.204498212144201

Epoch: 6| Step: 13
Training loss: 0.11677631720337185
Validation loss: 2.1865887251220224

Epoch: 486| Step: 0
Training loss: 0.24563281473924342
Validation loss: 2.215613226932542

Epoch: 6| Step: 1
Training loss: 0.18089605334380315
Validation loss: 2.198839469693288

Epoch: 6| Step: 2
Training loss: 0.20876734150450033
Validation loss: 2.2074544306525676

Epoch: 6| Step: 3
Training loss: 0.16499040665156076
Validation loss: 2.213962166287755

Epoch: 6| Step: 4
Training loss: 0.0999750270059353
Validation loss: 2.264014616945478

Epoch: 6| Step: 5
Training loss: 0.19893614040213373
Validation loss: 2.2755280883902635

Epoch: 6| Step: 6
Training loss: 0.1838637659270356
Validation loss: 2.279073368777076

Epoch: 6| Step: 7
Training loss: 0.2513218741785378
Validation loss: 2.2827131131038234

Epoch: 6| Step: 8
Training loss: 0.2671235113874486
Validation loss: 2.2752765692948427

Epoch: 6| Step: 9
Training loss: 0.2713443889186445
Validation loss: 2.2677198615538967

Epoch: 6| Step: 10
Training loss: 0.21548359698734013
Validation loss: 2.2785525802070725

Epoch: 6| Step: 11
Training loss: 0.12216147642624081
Validation loss: 2.260872025828772

Epoch: 6| Step: 12
Training loss: 0.1806420390134212
Validation loss: 2.254997969051824

Epoch: 6| Step: 13
Training loss: 0.17810982045528642
Validation loss: 2.2764510730799143

Epoch: 487| Step: 0
Training loss: 0.19583334140743752
Validation loss: 2.2631549545999783

Epoch: 6| Step: 1
Training loss: 0.25011593395504667
Validation loss: 2.252233428482447

Epoch: 6| Step: 2
Training loss: 0.22312733523431727
Validation loss: 2.272990241494007

Epoch: 6| Step: 3
Training loss: 0.21066499698204597
Validation loss: 2.286289048952771

Epoch: 6| Step: 4
Training loss: 0.17177953019303974
Validation loss: 2.280244889883986

Epoch: 6| Step: 5
Training loss: 0.12167132978071007
Validation loss: 2.3270325835172803

Epoch: 6| Step: 6
Training loss: 0.1453375300005551
Validation loss: 2.3011638598236055

Epoch: 6| Step: 7
Training loss: 0.1440560027868826
Validation loss: 2.308301385048559

Epoch: 6| Step: 8
Training loss: 0.16167153553804023
Validation loss: 2.307344056655051

Epoch: 6| Step: 9
Training loss: 0.20415952306693225
Validation loss: 2.3123962259330355

Epoch: 6| Step: 10
Training loss: 0.35680553054083536
Validation loss: 2.3109274564030837

Epoch: 6| Step: 11
Training loss: 0.13953326884877806
Validation loss: 2.2480940573953334

Epoch: 6| Step: 12
Training loss: 0.22223495479621558
Validation loss: 2.276387363251393

Epoch: 6| Step: 13
Training loss: 0.21898430809648725
Validation loss: 2.2412010925264045

Epoch: 488| Step: 0
Training loss: 0.24986072475461674
Validation loss: 2.2477627290759883

Epoch: 6| Step: 1
Training loss: 0.18958467655090308
Validation loss: 2.215090292567073

Epoch: 6| Step: 2
Training loss: 0.190356215951059
Validation loss: 2.2562244165564405

Epoch: 6| Step: 3
Training loss: 0.21926341093341806
Validation loss: 2.219453964854007

Epoch: 6| Step: 4
Training loss: 0.170340515597283
Validation loss: 2.209942845459397

Epoch: 6| Step: 5
Training loss: 0.1775043277313634
Validation loss: 2.2342894021643613

Epoch: 6| Step: 6
Training loss: 0.13127374519403348
Validation loss: 2.2595530064521268

Epoch: 6| Step: 7
Training loss: 0.12412715689964256
Validation loss: 2.2363704734883996

Epoch: 6| Step: 8
Training loss: 0.23689810533238917
Validation loss: 2.2802564803693635

Epoch: 6| Step: 9
Training loss: 0.17225444156217434
Validation loss: 2.2563712542339363

Epoch: 6| Step: 10
Training loss: 0.15150714064796156
Validation loss: 2.2378365811696987

Epoch: 6| Step: 11
Training loss: 0.15485538730523452
Validation loss: 2.2543211043835703

Epoch: 6| Step: 12
Training loss: 0.19535096743378055
Validation loss: 2.253165297379495

Epoch: 6| Step: 13
Training loss: 0.11691083037563689
Validation loss: 2.256213938011546

Epoch: 489| Step: 0
Training loss: 0.14291538561055916
Validation loss: 2.2597430228030086

Epoch: 6| Step: 1
Training loss: 0.19707643293360402
Validation loss: 2.23979843339143

Epoch: 6| Step: 2
Training loss: 0.17004454777618394
Validation loss: 2.2677503778671615

Epoch: 6| Step: 3
Training loss: 0.16302380548962955
Validation loss: 2.2638765490095984

Epoch: 6| Step: 4
Training loss: 0.12177883061630859
Validation loss: 2.2755038018537097

Epoch: 6| Step: 5
Training loss: 0.14751102531574584
Validation loss: 2.2664375995015607

Epoch: 6| Step: 6
Training loss: 0.08903437387831217
Validation loss: 2.2487261623166193

Epoch: 6| Step: 7
Training loss: 0.25156345841124506
Validation loss: 2.25663275443539

Epoch: 6| Step: 8
Training loss: 0.14124324450120296
Validation loss: 2.2504365308415966

Epoch: 6| Step: 9
Training loss: 0.2610971556281031
Validation loss: 2.2678964534569235

Epoch: 6| Step: 10
Training loss: 0.13525723201918213
Validation loss: 2.261119766259435

Epoch: 6| Step: 11
Training loss: 0.21633277224050132
Validation loss: 2.275559731363276

Epoch: 6| Step: 12
Training loss: 0.17963511283814163
Validation loss: 2.2303468326702345

Epoch: 6| Step: 13
Training loss: 0.11859684890472776
Validation loss: 2.260280095963014

Epoch: 490| Step: 0
Training loss: 0.12108425903043032
Validation loss: 2.282546869493622

Epoch: 6| Step: 1
Training loss: 0.16643377264521172
Validation loss: 2.270214519948766

Epoch: 6| Step: 2
Training loss: 0.20182088215120367
Validation loss: 2.2828060354921598

Epoch: 6| Step: 3
Training loss: 0.149095744718322
Validation loss: 2.2911425157964906

Epoch: 6| Step: 4
Training loss: 0.14364893408073476
Validation loss: 2.2777873089777096

Epoch: 6| Step: 5
Training loss: 0.17326777934694965
Validation loss: 2.2613771655905452

Epoch: 6| Step: 6
Training loss: 0.130730900398349
Validation loss: 2.2541557477185017

Epoch: 6| Step: 7
Training loss: 0.2449904946507423
Validation loss: 2.2977238679014547

Epoch: 6| Step: 8
Training loss: 0.26252854736956743
Validation loss: 2.268625593050024

Epoch: 6| Step: 9
Training loss: 0.2547562822244896
Validation loss: 2.2799495688277744

Epoch: 6| Step: 10
Training loss: 0.17749954262190978
Validation loss: 2.2916791447572895

Epoch: 6| Step: 11
Training loss: 0.0677922085428435
Validation loss: 2.318154888173231

Epoch: 6| Step: 12
Training loss: 0.1365021420243506
Validation loss: 2.287900490379836

Epoch: 6| Step: 13
Training loss: 0.1248522123254596
Validation loss: 2.2949459415204574

Epoch: 491| Step: 0
Training loss: 0.19349669387368532
Validation loss: 2.275415925620218

Epoch: 6| Step: 1
Training loss: 0.21813379075991723
Validation loss: 2.2549411134420976

Epoch: 6| Step: 2
Training loss: 0.20215907967238606
Validation loss: 2.2667210661363995

Epoch: 6| Step: 3
Training loss: 0.11740024646642994
Validation loss: 2.2759353328638414

Epoch: 6| Step: 4
Training loss: 0.12592793790424373
Validation loss: 2.2639450815375644

Epoch: 6| Step: 5
Training loss: 0.14889761236222263
Validation loss: 2.269370203670728

Epoch: 6| Step: 6
Training loss: 0.2040020184317711
Validation loss: 2.2520495721737417

Epoch: 6| Step: 7
Training loss: 0.31545838500061807
Validation loss: 2.266307158102659

Epoch: 6| Step: 8
Training loss: 0.08298142518640385
Validation loss: 2.271653556037758

Epoch: 6| Step: 9
Training loss: 0.2342409942910054
Validation loss: 2.237110877308844

Epoch: 6| Step: 10
Training loss: 0.15081395599952407
Validation loss: 2.261928991135858

Epoch: 6| Step: 11
Training loss: 0.15224706809739608
Validation loss: 2.2591866615804292

Epoch: 6| Step: 12
Training loss: 0.11981227212062372
Validation loss: 2.2514134801664043

Epoch: 6| Step: 13
Training loss: 0.11262233840774855
Validation loss: 2.293392218250304

Epoch: 492| Step: 0
Training loss: 0.15240416795928727
Validation loss: 2.262893291585455

Epoch: 6| Step: 1
Training loss: 0.157077090371615
Validation loss: 2.2803963032954626

Epoch: 6| Step: 2
Training loss: 0.20465312698271756
Validation loss: 2.258960160680016

Epoch: 6| Step: 3
Training loss: 0.1605309023650068
Validation loss: 2.2734842386174994

Epoch: 6| Step: 4
Training loss: 0.21386660397245325
Validation loss: 2.251534498155212

Epoch: 6| Step: 5
Training loss: 0.22241045116890948
Validation loss: 2.256562276393551

Epoch: 6| Step: 6
Training loss: 0.15586547026989156
Validation loss: 2.2750604112373556

Epoch: 6| Step: 7
Training loss: 0.24603522831042934
Validation loss: 2.282455686491212

Epoch: 6| Step: 8
Training loss: 0.1849136892391755
Validation loss: 2.249056673044131

Epoch: 6| Step: 9
Training loss: 0.13825907179142613
Validation loss: 2.2776191193296453

Epoch: 6| Step: 10
Training loss: 0.18815153885261993
Validation loss: 2.267837276002834

Epoch: 6| Step: 11
Training loss: 0.19556658430214247
Validation loss: 2.3075251014789457

Epoch: 6| Step: 12
Training loss: 0.15811099207126858
Validation loss: 2.295964871937008

Epoch: 6| Step: 13
Training loss: 0.19779879213659587
Validation loss: 2.2765477994395953

Epoch: 493| Step: 0
Training loss: 0.27866659205941824
Validation loss: 2.2820080991990257

Epoch: 6| Step: 1
Training loss: 0.1581728164462446
Validation loss: 2.3077222901457484

Epoch: 6| Step: 2
Training loss: 0.13026752000949232
Validation loss: 2.2768995951278646

Epoch: 6| Step: 3
Training loss: 0.15628726038123833
Validation loss: 2.2677411316733527

Epoch: 6| Step: 4
Training loss: 0.2320138571542947
Validation loss: 2.248440167627016

Epoch: 6| Step: 5
Training loss: 0.17293497002105185
Validation loss: 2.2827942386805957

Epoch: 6| Step: 6
Training loss: 0.1348525886246873
Validation loss: 2.251618297837648

Epoch: 6| Step: 7
Training loss: 0.2234089826511984
Validation loss: 2.26507044912358

Epoch: 6| Step: 8
Training loss: 0.11934860243450485
Validation loss: 2.266246755884408

Epoch: 6| Step: 9
Training loss: 0.2661640503777072
Validation loss: 2.2566131666298013

Epoch: 6| Step: 10
Training loss: 0.23020749721260186
Validation loss: 2.289561604933768

Epoch: 6| Step: 11
Training loss: 0.2131812185940645
Validation loss: 2.2753629326890183

Epoch: 6| Step: 12
Training loss: 0.09011546800921644
Validation loss: 2.3154182888617907

Epoch: 6| Step: 13
Training loss: 0.09964937454135969
Validation loss: 2.284606386718749

Epoch: 494| Step: 0
Training loss: 0.20081983707581694
Validation loss: 2.3241376970758867

Epoch: 6| Step: 1
Training loss: 0.12721837284151233
Validation loss: 2.2753756536063143

Epoch: 6| Step: 2
Training loss: 0.1378067863992669
Validation loss: 2.294399979174325

Epoch: 6| Step: 3
Training loss: 0.1607556813672516
Validation loss: 2.262577912779345

Epoch: 6| Step: 4
Training loss: 0.1502282269033662
Validation loss: 2.2787749691890564

Epoch: 6| Step: 5
Training loss: 0.17455109790757486
Validation loss: 2.2704813845257807

Epoch: 6| Step: 6
Training loss: 0.2222305545056064
Validation loss: 2.2608103807387474

Epoch: 6| Step: 7
Training loss: 0.27331330339866305
Validation loss: 2.2241643829543603

Epoch: 6| Step: 8
Training loss: 0.17814654462588536
Validation loss: 2.202306931408231

Epoch: 6| Step: 9
Training loss: 0.138055964863096
Validation loss: 2.198418870183985

Epoch: 6| Step: 10
Training loss: 0.20225895979336084
Validation loss: 2.2054794671316973

Epoch: 6| Step: 11
Training loss: 0.19574265794577594
Validation loss: 2.2022324668845465

Epoch: 6| Step: 12
Training loss: 0.23473156985094962
Validation loss: 2.2356224682397876

Epoch: 6| Step: 13
Training loss: 0.20357017152202148
Validation loss: 2.2480177577695653

Epoch: 495| Step: 0
Training loss: 0.1533617522492191
Validation loss: 2.243286989452499

Epoch: 6| Step: 1
Training loss: 0.15860658579592873
Validation loss: 2.235763944778351

Epoch: 6| Step: 2
Training loss: 0.2671964387346551
Validation loss: 2.248887916385148

Epoch: 6| Step: 3
Training loss: 0.25191405828839436
Validation loss: 2.2808589928916803

Epoch: 6| Step: 4
Training loss: 0.19304506206085711
Validation loss: 2.302901981090623

Epoch: 6| Step: 5
Training loss: 0.1073271376999925
Validation loss: 2.2926186281018115

Epoch: 6| Step: 6
Training loss: 0.23687922637510692
Validation loss: 2.2749033224827437

Epoch: 6| Step: 7
Training loss: 0.18809939977016737
Validation loss: 2.259959350465023

Epoch: 6| Step: 8
Training loss: 0.18939026055050337
Validation loss: 2.269741472280355

Epoch: 6| Step: 9
Training loss: 0.21197966689598302
Validation loss: 2.2398958206140325

Epoch: 6| Step: 10
Training loss: 0.24496503872450073
Validation loss: 2.2265269171752338

Epoch: 6| Step: 11
Training loss: 0.14666914413086435
Validation loss: 2.2381069438542616

Epoch: 6| Step: 12
Training loss: 0.2650664431344552
Validation loss: 2.240729936803278

Epoch: 6| Step: 13
Training loss: 0.1817211874866438
Validation loss: 2.2207500231197566

Epoch: 496| Step: 0
Training loss: 0.23428291260118037
Validation loss: 2.255842529540817

Epoch: 6| Step: 1
Training loss: 0.17122339144614093
Validation loss: 2.2329111189453434

Epoch: 6| Step: 2
Training loss: 0.2633189629957463
Validation loss: 2.2134676071218355

Epoch: 6| Step: 3
Training loss: 0.17348212192202353
Validation loss: 2.23158308016632

Epoch: 6| Step: 4
Training loss: 0.21015156808055285
Validation loss: 2.24672329918937

Epoch: 6| Step: 5
Training loss: 0.12054653503904039
Validation loss: 2.2690941682696932

Epoch: 6| Step: 6
Training loss: 0.1782941805357052
Validation loss: 2.2941597470767827

Epoch: 6| Step: 7
Training loss: 0.1546529692823898
Validation loss: 2.270554876475958

Epoch: 6| Step: 8
Training loss: 0.13662803910375035
Validation loss: 2.2939554879370903

Epoch: 6| Step: 9
Training loss: 0.20470092234392068
Validation loss: 2.2698503351531127

Epoch: 6| Step: 10
Training loss: 0.14051228880678474
Validation loss: 2.298234027857856

Epoch: 6| Step: 11
Training loss: 0.18216627213227993
Validation loss: 2.288114900437937

Epoch: 6| Step: 12
Training loss: 0.1931867696068889
Validation loss: 2.329043687007762

Epoch: 6| Step: 13
Training loss: 0.09342447030558085
Validation loss: 2.3031715024717405

Epoch: 497| Step: 0
Training loss: 0.13845226198372365
Validation loss: 2.3070173025193177

Epoch: 6| Step: 1
Training loss: 0.16168913316657588
Validation loss: 2.290802992189698

Epoch: 6| Step: 2
Training loss: 0.14065295842185493
Validation loss: 2.2653492370407586

Epoch: 6| Step: 3
Training loss: 0.27041143635412035
Validation loss: 2.264152982742008

Epoch: 6| Step: 4
Training loss: 0.2694696964245969
Validation loss: 2.240069834206384

Epoch: 6| Step: 5
Training loss: 0.1601503417623293
Validation loss: 2.237291405496933

Epoch: 6| Step: 6
Training loss: 0.23129038715804653
Validation loss: 2.2530024030252496

Epoch: 6| Step: 7
Training loss: 0.14926162123843525
Validation loss: 2.244780049049981

Epoch: 6| Step: 8
Training loss: 0.154619591670793
Validation loss: 2.2778714860861613

Epoch: 6| Step: 9
Training loss: 0.12186205073790417
Validation loss: 2.272239158079784

Epoch: 6| Step: 10
Training loss: 0.1780033068142146
Validation loss: 2.289317735201474

Epoch: 6| Step: 11
Training loss: 0.12326313118933083
Validation loss: 2.331406310318517

Epoch: 6| Step: 12
Training loss: 0.20439583039360704
Validation loss: 2.3170335359503524

Epoch: 6| Step: 13
Training loss: 0.14150042374921507
Validation loss: 2.276918652621614

Epoch: 498| Step: 0
Training loss: 0.1068993953557931
Validation loss: 2.282112436167981

Epoch: 6| Step: 1
Training loss: 0.12255564530310155
Validation loss: 2.231240973163215

Epoch: 6| Step: 2
Training loss: 0.20030631732772308
Validation loss: 2.2560024387108184

Epoch: 6| Step: 3
Training loss: 0.19008025362992062
Validation loss: 2.2565978400360467

Epoch: 6| Step: 4
Training loss: 0.37394179606022115
Validation loss: 2.2210497020972517

Epoch: 6| Step: 5
Training loss: 0.15765074853589328
Validation loss: 2.2453485100926236

Epoch: 6| Step: 6
Training loss: 0.08309602257894354
Validation loss: 2.2598062341917764

Epoch: 6| Step: 7
Training loss: 0.14995750381580888
Validation loss: 2.262818464311503

Epoch: 6| Step: 8
Training loss: 0.2564578300959724
Validation loss: 2.2703732949063413

Epoch: 6| Step: 9
Training loss: 0.15970082776091596
Validation loss: 2.271996427069941

Epoch: 6| Step: 10
Training loss: 0.18732295021866166
Validation loss: 2.256670617424735

Epoch: 6| Step: 11
Training loss: 0.09690014432101875
Validation loss: 2.2882616590284854

Epoch: 6| Step: 12
Training loss: 0.14650197241304874
Validation loss: 2.284013659511008

Epoch: 6| Step: 13
Training loss: 0.17809790856987742
Validation loss: 2.2894896233681394

Epoch: 499| Step: 0
Training loss: 0.23322014802434235
Validation loss: 2.264732084743392

Epoch: 6| Step: 1
Training loss: 0.17381926310377338
Validation loss: 2.2406726985570646

Epoch: 6| Step: 2
Training loss: 0.13621185886606393
Validation loss: 2.279571443837954

Epoch: 6| Step: 3
Training loss: 0.10689044761280542
Validation loss: 2.2644102874863243

Epoch: 6| Step: 4
Training loss: 0.12085254550025806
Validation loss: 2.266880894946613

Epoch: 6| Step: 5
Training loss: 0.2500098792746714
Validation loss: 2.2544426326620135

Epoch: 6| Step: 6
Training loss: 0.15060990930678755
Validation loss: 2.231715006653028

Epoch: 6| Step: 7
Training loss: 0.17057868472143137
Validation loss: 2.2749701071790924

Epoch: 6| Step: 8
Training loss: 0.152566978547475
Validation loss: 2.2666896696148005

Epoch: 6| Step: 9
Training loss: 0.13041799037564233
Validation loss: 2.290952582054438

Epoch: 6| Step: 10
Training loss: 0.18183545974029483
Validation loss: 2.26184595258877

Epoch: 6| Step: 11
Training loss: 0.20800923629058546
Validation loss: 2.2885100790652944

Epoch: 6| Step: 12
Training loss: 0.17513666649200044
Validation loss: 2.3248199019121376

Epoch: 6| Step: 13
Training loss: 0.11403110215712477
Validation loss: 2.2971709317964155

Epoch: 500| Step: 0
Training loss: 0.14553173559778287
Validation loss: 2.3480774839712573

Epoch: 6| Step: 1
Training loss: 0.17451076197775525
Validation loss: 2.3834136296084245

Epoch: 6| Step: 2
Training loss: 0.2184275310926608
Validation loss: 2.3022924281950936

Epoch: 6| Step: 3
Training loss: 0.11685829812063867
Validation loss: 2.3450548735747963

Epoch: 6| Step: 4
Training loss: 0.17232135770762388
Validation loss: 2.324328325018251

Epoch: 6| Step: 5
Training loss: 0.08714800328856548
Validation loss: 2.3027476588907363

Epoch: 6| Step: 6
Training loss: 0.1128393465945583
Validation loss: 2.2868826671393196

Epoch: 6| Step: 7
Training loss: 0.20915607279917212
Validation loss: 2.296063736737633

Epoch: 6| Step: 8
Training loss: 0.11717671503665945
Validation loss: 2.3085609962437585

Epoch: 6| Step: 9
Training loss: 0.20675650846472607
Validation loss: 2.269776590544169

Epoch: 6| Step: 10
Training loss: 0.18716422453722545
Validation loss: 2.279148919372996

Epoch: 6| Step: 11
Training loss: 0.0907412923554415
Validation loss: 2.3098083125100666

Epoch: 6| Step: 12
Training loss: 0.13192105547821995
Validation loss: 2.2991787533487216

Epoch: 6| Step: 13
Training loss: 0.2756455911786126
Validation loss: 2.3085909982359527

Epoch: 501| Step: 0
Training loss: 0.1422794492751297
Validation loss: 2.2544971015144175

Epoch: 6| Step: 1
Training loss: 0.1177011517919272
Validation loss: 2.283902749718227

Epoch: 6| Step: 2
Training loss: 0.15642451435004273
Validation loss: 2.2623324414499733

Epoch: 6| Step: 3
Training loss: 0.15441576686799577
Validation loss: 2.224815445754038

Epoch: 6| Step: 4
Training loss: 0.11921951152463305
Validation loss: 2.2589045249478192

Epoch: 6| Step: 5
Training loss: 0.13285282869080497
Validation loss: 2.2592314819908488

Epoch: 6| Step: 6
Training loss: 0.0737086573290043
Validation loss: 2.2583150422528138

Epoch: 6| Step: 7
Training loss: 0.21762164346723742
Validation loss: 2.294466160909632

Epoch: 6| Step: 8
Training loss: 0.1682729959721659
Validation loss: 2.2794651466695437

Epoch: 6| Step: 9
Training loss: 0.1623865309108982
Validation loss: 2.323488455814837

Epoch: 6| Step: 10
Training loss: 0.2020651788684411
Validation loss: 2.3131751987385005

Epoch: 6| Step: 11
Training loss: 0.11552011494661114
Validation loss: 2.2860909888512477

Epoch: 6| Step: 12
Training loss: 0.2250971680344192
Validation loss: 2.298299750330833

Epoch: 6| Step: 13
Training loss: 0.12447975346760788
Validation loss: 2.2689234145340134

Epoch: 502| Step: 0
Training loss: 0.20877860090347697
Validation loss: 2.280796296688368

Epoch: 6| Step: 1
Training loss: 0.10374851839030254
Validation loss: 2.2912815370734414

Epoch: 6| Step: 2
Training loss: 0.11041310796835886
Validation loss: 2.2635269164633973

Epoch: 6| Step: 3
Training loss: 0.0854544937685408
Validation loss: 2.2879335875306426

Epoch: 6| Step: 4
Training loss: 0.1452727755731251
Validation loss: 2.267222749798137

Epoch: 6| Step: 5
Training loss: 0.25171457870882175
Validation loss: 2.2601930218347897

Epoch: 6| Step: 6
Training loss: 0.19772074857051095
Validation loss: 2.2632492503168615

Epoch: 6| Step: 7
Training loss: 0.22118263143014089
Validation loss: 2.2837168658035716

Epoch: 6| Step: 8
Training loss: 0.08642968745482912
Validation loss: 2.3095995132857436

Epoch: 6| Step: 9
Training loss: 0.14481121732829455
Validation loss: 2.2331165137379587

Epoch: 6| Step: 10
Training loss: 0.13242725288251034
Validation loss: 2.2948722788963503

Epoch: 6| Step: 11
Training loss: 0.2088567040749869
Validation loss: 2.2724506723027615

Epoch: 6| Step: 12
Training loss: 0.14885596217742553
Validation loss: 2.2945504127079426

Epoch: 6| Step: 13
Training loss: 0.07172642737894115
Validation loss: 2.305971089772295

Epoch: 503| Step: 0
Training loss: 0.21284149197904237
Validation loss: 2.2951824254494064

Epoch: 6| Step: 1
Training loss: 0.12810675182883527
Validation loss: 2.2969330833401185

Epoch: 6| Step: 2
Training loss: 0.08698262499979023
Validation loss: 2.3083394375553747

Epoch: 6| Step: 3
Training loss: 0.09197601633825911
Validation loss: 2.295064476398432

Epoch: 6| Step: 4
Training loss: 0.1305052677604074
Validation loss: 2.3060046453894216

Epoch: 6| Step: 5
Training loss: 0.1923589546397951
Validation loss: 2.333145374830294

Epoch: 6| Step: 6
Training loss: 0.08265830959988248
Validation loss: 2.3093431804532485

Epoch: 6| Step: 7
Training loss: 0.23281492129609288
Validation loss: 2.3027329922775026

Epoch: 6| Step: 8
Training loss: 0.21748990473941304
Validation loss: 2.2954774697976834

Epoch: 6| Step: 9
Training loss: 0.08020831202015449
Validation loss: 2.2759314354753415

Epoch: 6| Step: 10
Training loss: 0.1276900398237065
Validation loss: 2.3114111165085496

Epoch: 6| Step: 11
Training loss: 0.17872743582525705
Validation loss: 2.3012727446138195

Epoch: 6| Step: 12
Training loss: 0.15423673350985162
Validation loss: 2.291094217556644

Epoch: 6| Step: 13
Training loss: 0.07860654008288172
Validation loss: 2.2568523825103104

Epoch: 504| Step: 0
Training loss: 0.11601204240449965
Validation loss: 2.2926316885367473

Epoch: 6| Step: 1
Training loss: 0.13025865456636054
Validation loss: 2.283586096809637

Epoch: 6| Step: 2
Training loss: 0.14496659105686993
Validation loss: 2.2813583569675404

Epoch: 6| Step: 3
Training loss: 0.10467792652253777
Validation loss: 2.2793613335481515

Epoch: 6| Step: 4
Training loss: 0.11272428328615566
Validation loss: 2.2654576105015396

Epoch: 6| Step: 5
Training loss: 0.10379472928841972
Validation loss: 2.294760622578846

Epoch: 6| Step: 6
Training loss: 0.3063699049648558
Validation loss: 2.319472606351979

Epoch: 6| Step: 7
Training loss: 0.10891652233929741
Validation loss: 2.293001610484

Epoch: 6| Step: 8
Training loss: 0.23433371816106574
Validation loss: 2.275953146998274

Epoch: 6| Step: 9
Training loss: 0.10313706182974637
Validation loss: 2.3093309713565326

Epoch: 6| Step: 10
Training loss: 0.132653934123804
Validation loss: 2.2984315186780737

Epoch: 6| Step: 11
Training loss: 0.13664423410525053
Validation loss: 2.2844871408740994

Epoch: 6| Step: 12
Training loss: 0.14080121338061374
Validation loss: 2.27723690135425

Epoch: 6| Step: 13
Training loss: 0.11035036407090017
Validation loss: 2.290583296471746

Epoch: 505| Step: 0
Training loss: 0.11356212882903456
Validation loss: 2.303647037865512

Epoch: 6| Step: 1
Training loss: 0.1769611706283561
Validation loss: 2.257908798010984

Epoch: 6| Step: 2
Training loss: 0.12911194227219858
Validation loss: 2.299727399248574

Epoch: 6| Step: 3
Training loss: 0.1094355373084025
Validation loss: 2.3040761340793114

Epoch: 6| Step: 4
Training loss: 0.20936429615558738
Validation loss: 2.2812872094302734

Epoch: 6| Step: 5
Training loss: 0.11198379863725354
Validation loss: 2.3134037547740665

Epoch: 6| Step: 6
Training loss: 0.26064018511730747
Validation loss: 2.3018110726111223

Epoch: 6| Step: 7
Training loss: 0.09080072417311784
Validation loss: 2.290702724113236

Epoch: 6| Step: 8
Training loss: 0.12759575686346858
Validation loss: 2.291735137035901

Epoch: 6| Step: 9
Training loss: 0.11911606926429738
Validation loss: 2.30499084044816

Epoch: 6| Step: 10
Training loss: 0.1318017844714271
Validation loss: 2.3137894255791487

Epoch: 6| Step: 11
Training loss: 0.11594527998626214
Validation loss: 2.2818249977832226

Epoch: 6| Step: 12
Training loss: 0.14544290336543444
Validation loss: 2.2800654337592605

Epoch: 6| Step: 13
Training loss: 0.203780610924011
Validation loss: 2.2921570101349893

Epoch: 506| Step: 0
Training loss: 0.22490157318977072
Validation loss: 2.21962926399538

Epoch: 6| Step: 1
Training loss: 0.14421944879463822
Validation loss: 2.2828185801712038

Epoch: 6| Step: 2
Training loss: 0.23017456384530274
Validation loss: 2.253811955814348

Epoch: 6| Step: 3
Training loss: 0.13599407372596772
Validation loss: 2.284097049891308

Epoch: 6| Step: 4
Training loss: 0.15698234475046402
Validation loss: 2.2369782628324457

Epoch: 6| Step: 5
Training loss: 0.14268992234478495
Validation loss: 2.25292368072752

Epoch: 6| Step: 6
Training loss: 0.1131266204509802
Validation loss: 2.2565924255462737

Epoch: 6| Step: 7
Training loss: 0.11769341301105317
Validation loss: 2.268047219553388

Epoch: 6| Step: 8
Training loss: 0.09222184890987649
Validation loss: 2.2551136221942594

Epoch: 6| Step: 9
Training loss: 0.1442731343842128
Validation loss: 2.2645652252770474

Epoch: 6| Step: 10
Training loss: 0.1460919527973462
Validation loss: 2.268923740508114

Epoch: 6| Step: 11
Training loss: 0.20982982178832238
Validation loss: 2.258742592973075

Epoch: 6| Step: 12
Training loss: 0.1693618028679471
Validation loss: 2.2988417102600733

Epoch: 6| Step: 13
Training loss: 0.089304779350361
Validation loss: 2.2900052843428305

Epoch: 507| Step: 0
Training loss: 0.1591369243822661
Validation loss: 2.264770792041784

Epoch: 6| Step: 1
Training loss: 0.08295011197896576
Validation loss: 2.2722256653674178

Epoch: 6| Step: 2
Training loss: 0.15528786790118362
Validation loss: 2.2994421416143767

Epoch: 6| Step: 3
Training loss: 0.10158136082629514
Validation loss: 2.271827542957403

Epoch: 6| Step: 4
Training loss: 0.27336844525984483
Validation loss: 2.2693361003557566

Epoch: 6| Step: 5
Training loss: 0.09546139414055482
Validation loss: 2.2574825926523965

Epoch: 6| Step: 6
Training loss: 0.14613951460931293
Validation loss: 2.2709488362830967

Epoch: 6| Step: 7
Training loss: 0.13772424434507188
Validation loss: 2.259741613207116

Epoch: 6| Step: 8
Training loss: 0.10933629696546028
Validation loss: 2.249202189177424

Epoch: 6| Step: 9
Training loss: 0.24747269172722997
Validation loss: 2.2644364987541348

Epoch: 6| Step: 10
Training loss: 0.14375724255934108
Validation loss: 2.2761032639813115

Epoch: 6| Step: 11
Training loss: 0.12240750091484251
Validation loss: 2.2976297591260386

Epoch: 6| Step: 12
Training loss: 0.1976676658680971
Validation loss: 2.319747599710203

Epoch: 6| Step: 13
Training loss: 0.2022445929161686
Validation loss: 2.3316542979555215

Epoch: 508| Step: 0
Training loss: 0.2678714175053725
Validation loss: 2.3333230031205257

Epoch: 6| Step: 1
Training loss: 0.14729790169424936
Validation loss: 2.321269008647815

Epoch: 6| Step: 2
Training loss: 0.12144296038323169
Validation loss: 2.330734144214552

Epoch: 6| Step: 3
Training loss: 0.12348652059435222
Validation loss: 2.3239982717561727

Epoch: 6| Step: 4
Training loss: 0.08923669122760104
Validation loss: 2.3022704628635857

Epoch: 6| Step: 5
Training loss: 0.11892435503082688
Validation loss: 2.3066778371788086

Epoch: 6| Step: 6
Training loss: 0.14194587413973397
Validation loss: 2.3184679567155153

Epoch: 6| Step: 7
Training loss: 0.20537564630400923
Validation loss: 2.2925112481490517

Epoch: 6| Step: 8
Training loss: 0.1930135659443294
Validation loss: 2.3082255025051555

Epoch: 6| Step: 9
Training loss: 0.21492094907072368
Validation loss: 2.3052984335545985

Epoch: 6| Step: 10
Training loss: 0.1274745941795672
Validation loss: 2.287229714826368

Epoch: 6| Step: 11
Training loss: 0.14161704406293296
Validation loss: 2.3189068027586783

Epoch: 6| Step: 12
Training loss: 0.21585028427316053
Validation loss: 2.284130844711232

Epoch: 6| Step: 13
Training loss: 0.09078262941950614
Validation loss: 2.294485170542863

Epoch: 509| Step: 0
Training loss: 0.17006319023379188
Validation loss: 2.2892746001650233

Epoch: 6| Step: 1
Training loss: 0.13322440254331938
Validation loss: 2.311877864571765

Epoch: 6| Step: 2
Training loss: 0.14556236012715376
Validation loss: 2.2895144037128383

Epoch: 6| Step: 3
Training loss: 0.15459599051963824
Validation loss: 2.305616725042307

Epoch: 6| Step: 4
Training loss: 0.16546262753176172
Validation loss: 2.287014074483695

Epoch: 6| Step: 5
Training loss: 0.23542130889085222
Validation loss: 2.293099635710354

Epoch: 6| Step: 6
Training loss: 0.21811788201673268
Validation loss: 2.2858538660542007

Epoch: 6| Step: 7
Training loss: 0.14167349731115553
Validation loss: 2.267902532764838

Epoch: 6| Step: 8
Training loss: 0.1619657776707235
Validation loss: 2.2978948271597943

Epoch: 6| Step: 9
Training loss: 0.09190961326857994
Validation loss: 2.2508693460349996

Epoch: 6| Step: 10
Training loss: 0.09949271532569465
Validation loss: 2.2709479963923185

Epoch: 6| Step: 11
Training loss: 0.13854180535570054
Validation loss: 2.2522137449323982

Epoch: 6| Step: 12
Training loss: 0.1584530257719478
Validation loss: 2.2510649896329786

Epoch: 6| Step: 13
Training loss: 0.28446176955307867
Validation loss: 2.2619636249068993

Epoch: 510| Step: 0
Training loss: 0.11589704323069135
Validation loss: 2.2624168621391787

Epoch: 6| Step: 1
Training loss: 0.12664241916578686
Validation loss: 2.2822710236736903

Epoch: 6| Step: 2
Training loss: 0.08734626142852644
Validation loss: 2.2656768826833713

Epoch: 6| Step: 3
Training loss: 0.15914979314636332
Validation loss: 2.2783509220009357

Epoch: 6| Step: 4
Training loss: 0.2441777925809895
Validation loss: 2.274557024273589

Epoch: 6| Step: 5
Training loss: 0.1525172321753505
Validation loss: 2.305886945280864

Epoch: 6| Step: 6
Training loss: 0.15810498384209318
Validation loss: 2.2845689334167085

Epoch: 6| Step: 7
Training loss: 0.1565762451747284
Validation loss: 2.2869204324414647

Epoch: 6| Step: 8
Training loss: 0.22337968318344145
Validation loss: 2.265257030190762

Epoch: 6| Step: 9
Training loss: 0.13517063896673248
Validation loss: 2.2500261706308025

Epoch: 6| Step: 10
Training loss: 0.16362149139092966
Validation loss: 2.2553485594771185

Epoch: 6| Step: 11
Training loss: 0.110058750467265
Validation loss: 2.2836856602849083

Epoch: 6| Step: 12
Training loss: 0.22540669937596705
Validation loss: 2.2736008657330844

Epoch: 6| Step: 13
Training loss: 0.10980527830151557
Validation loss: 2.2728843646140016

Epoch: 511| Step: 0
Training loss: 0.12742750596281677
Validation loss: 2.261187359690465

Epoch: 6| Step: 1
Training loss: 0.07891101020202497
Validation loss: 2.2495597695810283

Epoch: 6| Step: 2
Training loss: 0.14741591214572186
Validation loss: 2.2621501075080532

Epoch: 6| Step: 3
Training loss: 0.21509489639078705
Validation loss: 2.2745466290575713

Epoch: 6| Step: 4
Training loss: 0.22780958147625804
Validation loss: 2.282507040591626

Epoch: 6| Step: 5
Training loss: 0.15506370342853185
Validation loss: 2.2629719517012545

Epoch: 6| Step: 6
Training loss: 0.1025497294735909
Validation loss: 2.2788470405777415

Epoch: 6| Step: 7
Training loss: 0.15222470204795138
Validation loss: 2.284679166783751

Epoch: 6| Step: 8
Training loss: 0.07830886959378044
Validation loss: 2.3140330888026677

Epoch: 6| Step: 9
Training loss: 0.21082167624456047
Validation loss: 2.2950143538958745

Epoch: 6| Step: 10
Training loss: 0.12558872937648383
Validation loss: 2.3086096730771115

Epoch: 6| Step: 11
Training loss: 0.11825383929488037
Validation loss: 2.2932242681414508

Epoch: 6| Step: 12
Training loss: 0.13833558582957708
Validation loss: 2.2872653550457898

Epoch: 6| Step: 13
Training loss: 0.12142951238629761
Validation loss: 2.323922526136464

Epoch: 512| Step: 0
Training loss: 0.13811917370379462
Validation loss: 2.2752007323646244

Epoch: 6| Step: 1
Training loss: 0.10771891101203175
Validation loss: 2.297654136475459

Epoch: 6| Step: 2
Training loss: 0.161056835873579
Validation loss: 2.3265680264547313

Epoch: 6| Step: 3
Training loss: 0.1501421361774319
Validation loss: 2.3038865099249626

Epoch: 6| Step: 4
Training loss: 0.24613248429415008
Validation loss: 2.322371476581538

Epoch: 6| Step: 5
Training loss: 0.1765005125255816
Validation loss: 2.2790309830598963

Epoch: 6| Step: 6
Training loss: 0.1632609884111352
Validation loss: 2.2575910291923718

Epoch: 6| Step: 7
Training loss: 0.20953566486108247
Validation loss: 2.26645932618546

Epoch: 6| Step: 8
Training loss: 0.1365814814153509
Validation loss: 2.207099405743298

Epoch: 6| Step: 9
Training loss: 0.14911146626249658
Validation loss: 2.228604768780506

Epoch: 6| Step: 10
Training loss: 0.200397157097851
Validation loss: 2.2454398002100593

Epoch: 6| Step: 11
Training loss: 0.2895860570097982
Validation loss: 2.2480301427702716

Epoch: 6| Step: 12
Training loss: 0.10370877976696308
Validation loss: 2.247519531845877

Epoch: 6| Step: 13
Training loss: 0.10212059918088229
Validation loss: 2.2823289861247127

Epoch: 513| Step: 0
Training loss: 0.1179402533274488
Validation loss: 2.2829446087906797

Epoch: 6| Step: 1
Training loss: 0.13719272199524252
Validation loss: 2.2929938410128465

Epoch: 6| Step: 2
Training loss: 0.16760748448198742
Validation loss: 2.3394517366280474

Epoch: 6| Step: 3
Training loss: 0.26840334702766283
Validation loss: 2.333328125840923

Epoch: 6| Step: 4
Training loss: 0.1180610720215907
Validation loss: 2.3598323439337765

Epoch: 6| Step: 5
Training loss: 0.2069390559499457
Validation loss: 2.3544741368147633

Epoch: 6| Step: 6
Training loss: 0.19839143068093368
Validation loss: 2.3483008488245

Epoch: 6| Step: 7
Training loss: 0.11779997828644082
Validation loss: 2.310076014623285

Epoch: 6| Step: 8
Training loss: 0.19513211503457673
Validation loss: 2.307081611071707

Epoch: 6| Step: 9
Training loss: 0.1527727030202659
Validation loss: 2.3092735340060577

Epoch: 6| Step: 10
Training loss: 0.1498298221077888
Validation loss: 2.301727239169293

Epoch: 6| Step: 11
Training loss: 0.13484279523933615
Validation loss: 2.24782204582857

Epoch: 6| Step: 12
Training loss: 0.22308512424861138
Validation loss: 2.301683722985119

Epoch: 6| Step: 13
Training loss: 0.16031454567412717
Validation loss: 2.298767908165482

Epoch: 514| Step: 0
Training loss: 0.23942185052997175
Validation loss: 2.284450410566943

Epoch: 6| Step: 1
Training loss: 0.24993846553244922
Validation loss: 2.294126463732632

Epoch: 6| Step: 2
Training loss: 0.12093525943602733
Validation loss: 2.2973702813153953

Epoch: 6| Step: 3
Training loss: 0.23067767969517905
Validation loss: 2.313718293603439

Epoch: 6| Step: 4
Training loss: 0.16458811463782805
Validation loss: 2.2657567320798435

Epoch: 6| Step: 5
Training loss: 0.1425945651361097
Validation loss: 2.274258346044673

Epoch: 6| Step: 6
Training loss: 0.15424358075261418
Validation loss: 2.2807416114817647

Epoch: 6| Step: 7
Training loss: 0.1321131581960945
Validation loss: 2.311709493647047

Epoch: 6| Step: 8
Training loss: 0.12939130671100116
Validation loss: 2.3118340251931917

Epoch: 6| Step: 9
Training loss: 0.10921262711647131
Validation loss: 2.341921370119482

Epoch: 6| Step: 10
Training loss: 0.08550850038003426
Validation loss: 2.3448349419316528

Epoch: 6| Step: 11
Training loss: 0.13261100968141853
Validation loss: 2.348033620331644

Epoch: 6| Step: 12
Training loss: 0.2088923831152079
Validation loss: 2.35115669991852

Epoch: 6| Step: 13
Training loss: 0.07533714616306962
Validation loss: 2.364952579702675

Epoch: 515| Step: 0
Training loss: 0.08633083041513125
Validation loss: 2.345293329111937

Epoch: 6| Step: 1
Training loss: 0.1147324168393891
Validation loss: 2.3381159202307567

Epoch: 6| Step: 2
Training loss: 0.2972394813941597
Validation loss: 2.3358248499196237

Epoch: 6| Step: 3
Training loss: 0.23708501310429447
Validation loss: 2.3208786628732367

Epoch: 6| Step: 4
Training loss: 0.14314748790392484
Validation loss: 2.2809018138921964

Epoch: 6| Step: 5
Training loss: 0.08562846865032514
Validation loss: 2.280753451507134

Epoch: 6| Step: 6
Training loss: 0.15784580002131116
Validation loss: 2.2659371155039074

Epoch: 6| Step: 7
Training loss: 0.14829762041834837
Validation loss: 2.24925314050943

Epoch: 6| Step: 8
Training loss: 0.09366895232043551
Validation loss: 2.231031318992869

Epoch: 6| Step: 9
Training loss: 0.14767335913702148
Validation loss: 2.2737047518800972

Epoch: 6| Step: 10
Training loss: 0.14348339724028422
Validation loss: 2.252900436088221

Epoch: 6| Step: 11
Training loss: 0.09793776942510007
Validation loss: 2.255908393513738

Epoch: 6| Step: 12
Training loss: 0.131274298564455
Validation loss: 2.277803659562997

Epoch: 6| Step: 13
Training loss: 0.11523086332369156
Validation loss: 2.271649722400994

Epoch: 516| Step: 0
Training loss: 0.12805008500772982
Validation loss: 2.2777752693738798

Epoch: 6| Step: 1
Training loss: 0.15492761836945632
Validation loss: 2.2710022127368985

Epoch: 6| Step: 2
Training loss: 0.15602032948040462
Validation loss: 2.3146867653444714

Epoch: 6| Step: 3
Training loss: 0.11036259250036423
Validation loss: 2.291380175435269

Epoch: 6| Step: 4
Training loss: 0.21465444894830055
Validation loss: 2.2831515967944305

Epoch: 6| Step: 5
Training loss: 0.1690956890771918
Validation loss: 2.2730666952253076

Epoch: 6| Step: 6
Training loss: 0.21569510750686735
Validation loss: 2.2725939834827336

Epoch: 6| Step: 7
Training loss: 0.14219556722706725
Validation loss: 2.252658358283697

Epoch: 6| Step: 8
Training loss: 0.22091204114827542
Validation loss: 2.292354826834856

Epoch: 6| Step: 9
Training loss: 0.1273799031664411
Validation loss: 2.279307772120597

Epoch: 6| Step: 10
Training loss: 0.11934448998205091
Validation loss: 2.2770904663020453

Epoch: 6| Step: 11
Training loss: 0.09039817141400686
Validation loss: 2.2869760311850094

Epoch: 6| Step: 12
Training loss: 0.12486821171301664
Validation loss: 2.301181260301858

Epoch: 6| Step: 13
Training loss: 0.0744781603556232
Validation loss: 2.314097104897411

Epoch: 517| Step: 0
Training loss: 0.20718575056842056
Validation loss: 2.2955705438887954

Epoch: 6| Step: 1
Training loss: 0.1743991452423911
Validation loss: 2.3269255387143297

Epoch: 6| Step: 2
Training loss: 0.15176884673665766
Validation loss: 2.2602762328278736

Epoch: 6| Step: 3
Training loss: 0.13348263084542955
Validation loss: 2.2947325490103188

Epoch: 6| Step: 4
Training loss: 0.22369477192478307
Validation loss: 2.32141787479931

Epoch: 6| Step: 5
Training loss: 0.1348348868033109
Validation loss: 2.3033863397046406

Epoch: 6| Step: 6
Training loss: 0.14533740824854563
Validation loss: 2.3197914959187544

Epoch: 6| Step: 7
Training loss: 0.12067977454110175
Validation loss: 2.2995260271476607

Epoch: 6| Step: 8
Training loss: 0.21286943312694698
Validation loss: 2.2851809735639566

Epoch: 6| Step: 9
Training loss: 0.15020490300745137
Validation loss: 2.2970701180397954

Epoch: 6| Step: 10
Training loss: 0.12356995103875684
Validation loss: 2.2918628929304736

Epoch: 6| Step: 11
Training loss: 0.06524837337993081
Validation loss: 2.2950015547269884

Epoch: 6| Step: 12
Training loss: 0.11352284746500405
Validation loss: 2.2648324747893014

Epoch: 6| Step: 13
Training loss: 0.17230646207315495
Validation loss: 2.272691536712854

Epoch: 518| Step: 0
Training loss: 0.2595330251027859
Validation loss: 2.272708100492542

Epoch: 6| Step: 1
Training loss: 0.16493861962285694
Validation loss: 2.284589026637219

Epoch: 6| Step: 2
Training loss: 0.1699963220205457
Validation loss: 2.2847490299641646

Epoch: 6| Step: 3
Training loss: 0.08695846398560741
Validation loss: 2.2668509465280198

Epoch: 6| Step: 4
Training loss: 0.17687267975919738
Validation loss: 2.2718439448987566

Epoch: 6| Step: 5
Training loss: 0.12478914581980986
Validation loss: 2.3034009181277297

Epoch: 6| Step: 6
Training loss: 0.1256896455459292
Validation loss: 2.284651773891441

Epoch: 6| Step: 7
Training loss: 0.2304631571980128
Validation loss: 2.275388655559799

Epoch: 6| Step: 8
Training loss: 0.1492697885616056
Validation loss: 2.3041629779065693

Epoch: 6| Step: 9
Training loss: 0.11555815323782859
Validation loss: 2.2858188226375997

Epoch: 6| Step: 10
Training loss: 0.11093616081826428
Validation loss: 2.303912807302503

Epoch: 6| Step: 11
Training loss: 0.15816440814944518
Validation loss: 2.2983655411958552

Epoch: 6| Step: 12
Training loss: 0.15185497811290313
Validation loss: 2.309229530560591

Epoch: 6| Step: 13
Training loss: 0.18931593302702332
Validation loss: 2.2757581729168836

Epoch: 519| Step: 0
Training loss: 0.11543223399211182
Validation loss: 2.2598389294155212

Epoch: 6| Step: 1
Training loss: 0.15527598061068454
Validation loss: 2.2877593670474576

Epoch: 6| Step: 2
Training loss: 0.12197354868431805
Validation loss: 2.267067177179574

Epoch: 6| Step: 3
Training loss: 0.08821179202082026
Validation loss: 2.2497117257798274

Epoch: 6| Step: 4
Training loss: 0.10629509466761532
Validation loss: 2.288994828126532

Epoch: 6| Step: 5
Training loss: 0.1446323492244376
Validation loss: 2.252425127645556

Epoch: 6| Step: 6
Training loss: 0.21135786344385749
Validation loss: 2.261268703990313

Epoch: 6| Step: 7
Training loss: 0.1076905012941263
Validation loss: 2.2739363828002874

Epoch: 6| Step: 8
Training loss: 0.11524678018037941
Validation loss: 2.275426437417912

Epoch: 6| Step: 9
Training loss: 0.06950635182969467
Validation loss: 2.3004498716578965

Epoch: 6| Step: 10
Training loss: 0.11579128435542377
Validation loss: 2.3165190453666042

Epoch: 6| Step: 11
Training loss: 0.22408204579991256
Validation loss: 2.2883331605177326

Epoch: 6| Step: 12
Training loss: 0.19592258536537602
Validation loss: 2.24813185950173

Epoch: 6| Step: 13
Training loss: 0.12315648358973101
Validation loss: 2.3011870299812984

Epoch: 520| Step: 0
Training loss: 0.2072560331653664
Validation loss: 2.3019498605324387

Epoch: 6| Step: 1
Training loss: 0.1967311738706402
Validation loss: 2.314474090803819

Epoch: 6| Step: 2
Training loss: 0.12710880124666582
Validation loss: 2.295476765082647

Epoch: 6| Step: 3
Training loss: 0.15839670253231528
Validation loss: 2.2895522486339095

Epoch: 6| Step: 4
Training loss: 0.17059743258541715
Validation loss: 2.3275764029850157

Epoch: 6| Step: 5
Training loss: 0.10177053639236179
Validation loss: 2.3069551969268574

Epoch: 6| Step: 6
Training loss: 0.1170096000743187
Validation loss: 2.2963093673713932

Epoch: 6| Step: 7
Training loss: 0.1197127534952275
Validation loss: 2.2977634447534556

Epoch: 6| Step: 8
Training loss: 0.14219400841625462
Validation loss: 2.2696780807019703

Epoch: 6| Step: 9
Training loss: 0.17543143857406054
Validation loss: 2.2902609685632056

Epoch: 6| Step: 10
Training loss: 0.11564942952422316
Validation loss: 2.2804588646336823

Epoch: 6| Step: 11
Training loss: 0.1762720778854571
Validation loss: 2.2855021783294642

Epoch: 6| Step: 12
Training loss: 0.13687296072211536
Validation loss: 2.2994843501041164

Epoch: 6| Step: 13
Training loss: 0.1561559036164014
Validation loss: 2.2702325811076833

Epoch: 521| Step: 0
Training loss: 0.0818116507078141
Validation loss: 2.289510787538178

Epoch: 6| Step: 1
Training loss: 0.1537145902594691
Validation loss: 2.249796715762908

Epoch: 6| Step: 2
Training loss: 0.2127782805206614
Validation loss: 2.229162439195291

Epoch: 6| Step: 3
Training loss: 0.14860777123903116
Validation loss: 2.2166562887475134

Epoch: 6| Step: 4
Training loss: 0.22640554976898017
Validation loss: 2.2001582067830707

Epoch: 6| Step: 5
Training loss: 0.1468883158349397
Validation loss: 2.2655381527988996

Epoch: 6| Step: 6
Training loss: 0.20446969558040087
Validation loss: 2.2448291244866754

Epoch: 6| Step: 7
Training loss: 0.14724031579971517
Validation loss: 2.2507909634423804

Epoch: 6| Step: 8
Training loss: 0.22097465387538004
Validation loss: 2.2312876193469573

Epoch: 6| Step: 9
Training loss: 0.15701107398464373
Validation loss: 2.252936810831499

Epoch: 6| Step: 10
Training loss: 0.18182950812588417
Validation loss: 2.2561622104194963

Epoch: 6| Step: 11
Training loss: 0.13797525937027838
Validation loss: 2.258314051222455

Epoch: 6| Step: 12
Training loss: 0.1528276010181979
Validation loss: 2.250054797436153

Epoch: 6| Step: 13
Training loss: 0.136830774460856
Validation loss: 2.2523440674923316

Epoch: 522| Step: 0
Training loss: 0.1460338339618829
Validation loss: 2.2863757997607177

Epoch: 6| Step: 1
Training loss: 0.20439758006891734
Validation loss: 2.2924289740613326

Epoch: 6| Step: 2
Training loss: 0.23696941663086632
Validation loss: 2.295178215042368

Epoch: 6| Step: 3
Training loss: 0.1269250838782676
Validation loss: 2.2950034950489426

Epoch: 6| Step: 4
Training loss: 0.15163168409620387
Validation loss: 2.327659673299745

Epoch: 6| Step: 5
Training loss: 0.24700675116609996
Validation loss: 2.2911193962350915

Epoch: 6| Step: 6
Training loss: 0.14663523852617596
Validation loss: 2.2654738531731216

Epoch: 6| Step: 7
Training loss: 0.1557114798146091
Validation loss: 2.273951767277195

Epoch: 6| Step: 8
Training loss: 0.11442044087633425
Validation loss: 2.2885550953265152

Epoch: 6| Step: 9
Training loss: 0.14618820767926533
Validation loss: 2.2638737604436954

Epoch: 6| Step: 10
Training loss: 0.1352571700490755
Validation loss: 2.3013916097430878

Epoch: 6| Step: 11
Training loss: 0.14828433743067376
Validation loss: 2.2887284789979976

Epoch: 6| Step: 12
Training loss: 0.1553649812427489
Validation loss: 2.2805087359765515

Epoch: 6| Step: 13
Training loss: 0.09727638273228192
Validation loss: 2.30326174404112

Epoch: 523| Step: 0
Training loss: 0.148165535239381
Validation loss: 2.286404634113705

Epoch: 6| Step: 1
Training loss: 0.17535252741435367
Validation loss: 2.3005088180916204

Epoch: 6| Step: 2
Training loss: 0.23217743754242576
Validation loss: 2.304602404052877

Epoch: 6| Step: 3
Training loss: 0.2682163395947235
Validation loss: 2.3044821196658334

Epoch: 6| Step: 4
Training loss: 0.19468760660330853
Validation loss: 2.340150653209427

Epoch: 6| Step: 5
Training loss: 0.13000274799725345
Validation loss: 2.3064138380124444

Epoch: 6| Step: 6
Training loss: 0.1800972992459424
Validation loss: 2.318788409834698

Epoch: 6| Step: 7
Training loss: 0.2147525246885882
Validation loss: 2.363306866402486

Epoch: 6| Step: 8
Training loss: 0.17704371518712347
Validation loss: 2.3310386361975155

Epoch: 6| Step: 9
Training loss: 0.14068551218593484
Validation loss: 2.3344026887909877

Epoch: 6| Step: 10
Training loss: 0.11219572088277356
Validation loss: 2.3536321523428914

Epoch: 6| Step: 11
Training loss: 0.1800281985037033
Validation loss: 2.3261553634942387

Epoch: 6| Step: 12
Training loss: 0.20530329558818333
Validation loss: 2.361792469177052

Epoch: 6| Step: 13
Training loss: 0.11506665276203375
Validation loss: 2.348573295202932

Epoch: 524| Step: 0
Training loss: 0.20880404383810322
Validation loss: 2.3607052255313716

Epoch: 6| Step: 1
Training loss: 0.18575913184503173
Validation loss: 2.355253005075011

Epoch: 6| Step: 2
Training loss: 0.10827775199546467
Validation loss: 2.3535354193371294

Epoch: 6| Step: 3
Training loss: 0.23881441408282306
Validation loss: 2.370419875894895

Epoch: 6| Step: 4
Training loss: 0.19540174352713335
Validation loss: 2.364965649617901

Epoch: 6| Step: 5
Training loss: 0.13315519829876138
Validation loss: 2.3240722565962795

Epoch: 6| Step: 6
Training loss: 0.08022857117578418
Validation loss: 2.3151801657310918

Epoch: 6| Step: 7
Training loss: 0.14803182857618596
Validation loss: 2.3281899521813187

Epoch: 6| Step: 8
Training loss: 0.10503566089539967
Validation loss: 2.3404698728842828

Epoch: 6| Step: 9
Training loss: 0.12565760191821282
Validation loss: 2.3093779712513407

Epoch: 6| Step: 10
Training loss: 0.10455629574723788
Validation loss: 2.3090018587037573

Epoch: 6| Step: 11
Training loss: 0.19016810326161762
Validation loss: 2.253720893915115

Epoch: 6| Step: 12
Training loss: 0.12334755082866922
Validation loss: 2.2817947185745058

Epoch: 6| Step: 13
Training loss: 0.12982072278281795
Validation loss: 2.2778986152858596

Epoch: 525| Step: 0
Training loss: 0.0919995910354263
Validation loss: 2.2716468192378505

Epoch: 6| Step: 1
Training loss: 0.16536514527433138
Validation loss: 2.265881418011207

Epoch: 6| Step: 2
Training loss: 0.23301796647208103
Validation loss: 2.227011675270676

Epoch: 6| Step: 3
Training loss: 0.09063946756440323
Validation loss: 2.2683070142963095

Epoch: 6| Step: 4
Training loss: 0.12481220115287736
Validation loss: 2.2663612716751036

Epoch: 6| Step: 5
Training loss: 0.15466141191764357
Validation loss: 2.285003662063358

Epoch: 6| Step: 6
Training loss: 0.13724781936987324
Validation loss: 2.2640785073537564

Epoch: 6| Step: 7
Training loss: 0.10092381329940792
Validation loss: 2.260071857212799

Epoch: 6| Step: 8
Training loss: 0.10538228782468334
Validation loss: 2.281003313581568

Epoch: 6| Step: 9
Training loss: 0.21881604900494722
Validation loss: 2.312277832822133

Epoch: 6| Step: 10
Training loss: 0.14883228556506967
Validation loss: 2.2808873293836704

Epoch: 6| Step: 11
Training loss: 0.1849711269323256
Validation loss: 2.2870323762482734

Epoch: 6| Step: 12
Training loss: 0.12402957615716463
Validation loss: 2.2966227333954152

Epoch: 6| Step: 13
Training loss: 0.11525423880889342
Validation loss: 2.3206568310856617

Epoch: 526| Step: 0
Training loss: 0.10220803916196533
Validation loss: 2.298869378186071

Epoch: 6| Step: 1
Training loss: 0.14738336000358504
Validation loss: 2.3195752393393207

Epoch: 6| Step: 2
Training loss: 0.1490506633521441
Validation loss: 2.3152970457306785

Epoch: 6| Step: 3
Training loss: 0.08842160579143608
Validation loss: 2.3608502374378197

Epoch: 6| Step: 4
Training loss: 0.15857893259141825
Validation loss: 2.2916985447102993

Epoch: 6| Step: 5
Training loss: 0.17486695294172086
Validation loss: 2.3062318861361977

Epoch: 6| Step: 6
Training loss: 0.14778731397697578
Validation loss: 2.298169058708723

Epoch: 6| Step: 7
Training loss: 0.16186534944878309
Validation loss: 2.269599168428466

Epoch: 6| Step: 8
Training loss: 0.13462011802520532
Validation loss: 2.2837346282191455

Epoch: 6| Step: 9
Training loss: 0.15814139492245882
Validation loss: 2.2877040641340343

Epoch: 6| Step: 10
Training loss: 0.10508405321266896
Validation loss: 2.258625522118674

Epoch: 6| Step: 11
Training loss: 0.2629348626971339
Validation loss: 2.2562421732725215

Epoch: 6| Step: 12
Training loss: 0.10499422737272837
Validation loss: 2.2550504895828847

Epoch: 6| Step: 13
Training loss: 0.11288339532319823
Validation loss: 2.223764464755969

Epoch: 527| Step: 0
Training loss: 0.15726473445611766
Validation loss: 2.200711741172416

Epoch: 6| Step: 1
Training loss: 0.20202130544723426
Validation loss: 2.2300796343216507

Epoch: 6| Step: 2
Training loss: 0.15934649895157602
Validation loss: 2.2427229463297915

Epoch: 6| Step: 3
Training loss: 0.17548436418936975
Validation loss: 2.2394994980921727

Epoch: 6| Step: 4
Training loss: 0.16129745395049866
Validation loss: 2.248419649881252

Epoch: 6| Step: 5
Training loss: 0.1342266056262103
Validation loss: 2.2122440591707333

Epoch: 6| Step: 6
Training loss: 0.2408311997649669
Validation loss: 2.2040257046561433

Epoch: 6| Step: 7
Training loss: 0.15052023170333356
Validation loss: 2.204278875754896

Epoch: 6| Step: 8
Training loss: 0.1313120428537639
Validation loss: 2.2050498595023322

Epoch: 6| Step: 9
Training loss: 0.16806990327804325
Validation loss: 2.2315507234306735

Epoch: 6| Step: 10
Training loss: 0.11346744986629477
Validation loss: 2.2762037173399086

Epoch: 6| Step: 11
Training loss: 0.17621787204513578
Validation loss: 2.3046860339099413

Epoch: 6| Step: 12
Training loss: 0.1044970671681955
Validation loss: 2.2898994368076777

Epoch: 6| Step: 13
Training loss: 0.05751517527072034
Validation loss: 2.2922308103445697

Epoch: 528| Step: 0
Training loss: 0.1881425299033617
Validation loss: 2.28208481475178

Epoch: 6| Step: 1
Training loss: 0.22727552386481456
Validation loss: 2.300359410007102

Epoch: 6| Step: 2
Training loss: 0.10993876513170128
Validation loss: 2.317977401491798

Epoch: 6| Step: 3
Training loss: 0.11354104621160642
Validation loss: 2.3141797059089226

Epoch: 6| Step: 4
Training loss: 0.21777407043091354
Validation loss: 2.2745837216035354

Epoch: 6| Step: 5
Training loss: 0.22390547209855452
Validation loss: 2.31669423250784

Epoch: 6| Step: 6
Training loss: 0.12445543550452683
Validation loss: 2.3079363916298705

Epoch: 6| Step: 7
Training loss: 0.08297011136340794
Validation loss: 2.284916717789824

Epoch: 6| Step: 8
Training loss: 0.1582195779698509
Validation loss: 2.255230376035382

Epoch: 6| Step: 9
Training loss: 0.1091316701018325
Validation loss: 2.2822019349886595

Epoch: 6| Step: 10
Training loss: 0.16714580898442433
Validation loss: 2.2812405174598833

Epoch: 6| Step: 11
Training loss: 0.08877914385058049
Validation loss: 2.2627268550843818

Epoch: 6| Step: 12
Training loss: 0.13449322079924403
Validation loss: 2.27365046862007

Epoch: 6| Step: 13
Training loss: 0.14131274530287402
Validation loss: 2.2886104224822126

Epoch: 529| Step: 0
Training loss: 0.13857921674665877
Validation loss: 2.244745344307361

Epoch: 6| Step: 1
Training loss: 0.15650754207651893
Validation loss: 2.21910352142188

Epoch: 6| Step: 2
Training loss: 0.1533075193668379
Validation loss: 2.2683320740829505

Epoch: 6| Step: 3
Training loss: 0.10854918934425156
Validation loss: 2.249661488944314

Epoch: 6| Step: 4
Training loss: 0.1914990161386171
Validation loss: 2.266609337327211

Epoch: 6| Step: 5
Training loss: 0.12621533882355937
Validation loss: 2.228364278119646

Epoch: 6| Step: 6
Training loss: 0.1337743876407376
Validation loss: 2.2517560346760455

Epoch: 6| Step: 7
Training loss: 0.2106140977771609
Validation loss: 2.24948454151548

Epoch: 6| Step: 8
Training loss: 0.10775771528615903
Validation loss: 2.2708637889916954

Epoch: 6| Step: 9
Training loss: 0.19841260115539724
Validation loss: 2.255180227036363

Epoch: 6| Step: 10
Training loss: 0.10314552706104288
Validation loss: 2.2585914285275934

Epoch: 6| Step: 11
Training loss: 0.10032073957852748
Validation loss: 2.266762045520541

Epoch: 6| Step: 12
Training loss: 0.0964901443640708
Validation loss: 2.272175807413467

Epoch: 6| Step: 13
Training loss: 0.1812047548384416
Validation loss: 2.2761092346423966

Epoch: 530| Step: 0
Training loss: 0.11866138172656471
Validation loss: 2.2757152596371224

Epoch: 6| Step: 1
Training loss: 0.11122929218262767
Validation loss: 2.263481945526438

Epoch: 6| Step: 2
Training loss: 0.1475095858126128
Validation loss: 2.271219531347303

Epoch: 6| Step: 3
Training loss: 0.11451852430472223
Validation loss: 2.269947717313313

Epoch: 6| Step: 4
Training loss: 0.18619440426659187
Validation loss: 2.286559478550531

Epoch: 6| Step: 5
Training loss: 0.10444871051450255
Validation loss: 2.2742205616898574

Epoch: 6| Step: 6
Training loss: 0.09452027540894956
Validation loss: 2.260967318183328

Epoch: 6| Step: 7
Training loss: 0.11203455571627187
Validation loss: 2.2686849160530107

Epoch: 6| Step: 8
Training loss: 0.21582297931939473
Validation loss: 2.2400050684564645

Epoch: 6| Step: 9
Training loss: 0.09235240363223736
Validation loss: 2.2552620906618617

Epoch: 6| Step: 10
Training loss: 0.09734515228914688
Validation loss: 2.2511540441942555

Epoch: 6| Step: 11
Training loss: 0.09922819505626043
Validation loss: 2.257649903478901

Epoch: 6| Step: 12
Training loss: 0.23933580645418634
Validation loss: 2.2522399638269484

Epoch: 6| Step: 13
Training loss: 0.09750872436181422
Validation loss: 2.27346890538518

Epoch: 531| Step: 0
Training loss: 0.10149451878327741
Validation loss: 2.2754783309615836

Epoch: 6| Step: 1
Training loss: 0.09115369172506459
Validation loss: 2.277465582904827

Epoch: 6| Step: 2
Training loss: 0.20211426819318004
Validation loss: 2.296408669470524

Epoch: 6| Step: 3
Training loss: 0.12304653061712603
Validation loss: 2.265653676384423

Epoch: 6| Step: 4
Training loss: 0.21591159564429394
Validation loss: 2.258321878420599

Epoch: 6| Step: 5
Training loss: 0.11080333343665064
Validation loss: 2.284751875523356

Epoch: 6| Step: 6
Training loss: 0.12374715368894125
Validation loss: 2.3097426052018886

Epoch: 6| Step: 7
Training loss: 0.21968361328832517
Validation loss: 2.323231223342411

Epoch: 6| Step: 8
Training loss: 0.08816279021237938
Validation loss: 2.287817681816173

Epoch: 6| Step: 9
Training loss: 0.09371365895837537
Validation loss: 2.292667570454025

Epoch: 6| Step: 10
Training loss: 0.05449621559965063
Validation loss: 2.2894891351600144

Epoch: 6| Step: 11
Training loss: 0.13122202313931638
Validation loss: 2.2611181914211023

Epoch: 6| Step: 12
Training loss: 0.13576794112446197
Validation loss: 2.255233484485215

Epoch: 6| Step: 13
Training loss: 0.06902155996121113
Validation loss: 2.302741431102358

Epoch: 532| Step: 0
Training loss: 0.137035812847852
Validation loss: 2.286074929111422

Epoch: 6| Step: 1
Training loss: 0.14187096585827516
Validation loss: 2.281393869504343

Epoch: 6| Step: 2
Training loss: 0.1453213553140267
Validation loss: 2.326431110774201

Epoch: 6| Step: 3
Training loss: 0.14462314081645536
Validation loss: 2.2933568814467473

Epoch: 6| Step: 4
Training loss: 0.13679650684091468
Validation loss: 2.3141517136557255

Epoch: 6| Step: 5
Training loss: 0.09029066324230228
Validation loss: 2.337675783396826

Epoch: 6| Step: 6
Training loss: 0.11883495156331379
Validation loss: 2.345023275180664

Epoch: 6| Step: 7
Training loss: 0.19962669192930618
Validation loss: 2.2945800526682496

Epoch: 6| Step: 8
Training loss: 0.15322576024915155
Validation loss: 2.2960195616338672

Epoch: 6| Step: 9
Training loss: 0.18008542573573214
Validation loss: 2.293839887621598

Epoch: 6| Step: 10
Training loss: 0.1291264473943841
Validation loss: 2.2724325681351374

Epoch: 6| Step: 11
Training loss: 0.12687086227791922
Validation loss: 2.2478039562881587

Epoch: 6| Step: 12
Training loss: 0.10034536090842
Validation loss: 2.2601820580762766

Epoch: 6| Step: 13
Training loss: 0.24859471534910813
Validation loss: 2.2753614967154543

Epoch: 533| Step: 0
Training loss: 0.10007178739898824
Validation loss: 2.2538419284849653

Epoch: 6| Step: 1
Training loss: 0.1233783601377695
Validation loss: 2.2666387488704656

Epoch: 6| Step: 2
Training loss: 0.15770440908582176
Validation loss: 2.2602274899526336

Epoch: 6| Step: 3
Training loss: 0.13145124328519747
Validation loss: 2.2472656400126936

Epoch: 6| Step: 4
Training loss: 0.1187429592278912
Validation loss: 2.2025990291389057

Epoch: 6| Step: 5
Training loss: 0.21759468063567464
Validation loss: 2.2537513381527883

Epoch: 6| Step: 6
Training loss: 0.07342266417353426
Validation loss: 2.285506717832181

Epoch: 6| Step: 7
Training loss: 0.18469568061783861
Validation loss: 2.2343047767995685

Epoch: 6| Step: 8
Training loss: 0.2229825523344207
Validation loss: 2.2495329786926197

Epoch: 6| Step: 9
Training loss: 0.16297723379573353
Validation loss: 2.281442539407559

Epoch: 6| Step: 10
Training loss: 0.15492517774623113
Validation loss: 2.262776468192964

Epoch: 6| Step: 11
Training loss: 0.1489629980392818
Validation loss: 2.278071748528722

Epoch: 6| Step: 12
Training loss: 0.12833476544046607
Validation loss: 2.281754932720379

Epoch: 6| Step: 13
Training loss: 0.0902948148201623
Validation loss: 2.2750519401636815

Epoch: 534| Step: 0
Training loss: 0.12343830714987979
Validation loss: 2.300861922360867

Epoch: 6| Step: 1
Training loss: 0.16600571771118935
Validation loss: 2.2827380927933496

Epoch: 6| Step: 2
Training loss: 0.1390756116000745
Validation loss: 2.2998143587992663

Epoch: 6| Step: 3
Training loss: 0.10194915292390534
Validation loss: 2.301201185074868

Epoch: 6| Step: 4
Training loss: 0.1215570569719812
Validation loss: 2.317601337200712

Epoch: 6| Step: 5
Training loss: 0.22315013219035407
Validation loss: 2.299153674080929

Epoch: 6| Step: 6
Training loss: 0.16810630555253203
Validation loss: 2.306379234258409

Epoch: 6| Step: 7
Training loss: 0.09044575105699017
Validation loss: 2.3027605516617107

Epoch: 6| Step: 8
Training loss: 0.17332888286483006
Validation loss: 2.305648956337598

Epoch: 6| Step: 9
Training loss: 0.19034547166260218
Validation loss: 2.3229734470029966

Epoch: 6| Step: 10
Training loss: 0.10588578056730132
Validation loss: 2.3029035952616335

Epoch: 6| Step: 11
Training loss: 0.22293131552155743
Validation loss: 2.276439411697384

Epoch: 6| Step: 12
Training loss: 0.25132555020252284
Validation loss: 2.2690029174956297

Epoch: 6| Step: 13
Training loss: 0.20188474733482392
Validation loss: 2.283472025795882

Epoch: 535| Step: 0
Training loss: 0.29603448893771406
Validation loss: 2.2953010240645426

Epoch: 6| Step: 1
Training loss: 0.22084992514365692
Validation loss: 2.3246632080102274

Epoch: 6| Step: 2
Training loss: 0.21929520545544104
Validation loss: 2.307354460216195

Epoch: 6| Step: 3
Training loss: 0.22081654933959965
Validation loss: 2.3231802375642814

Epoch: 6| Step: 4
Training loss: 0.21801477582098094
Validation loss: 2.3250492373230345

Epoch: 6| Step: 5
Training loss: 0.26063516827971395
Validation loss: 2.309883544843314

Epoch: 6| Step: 6
Training loss: 0.2145858690812611
Validation loss: 2.2966932334073573

Epoch: 6| Step: 7
Training loss: 0.14642603030163875
Validation loss: 2.3194240627159233

Epoch: 6| Step: 8
Training loss: 0.16673780887389836
Validation loss: 2.3110838564028398

Epoch: 6| Step: 9
Training loss: 0.23557064733537433
Validation loss: 2.292664385843358

Epoch: 6| Step: 10
Training loss: 0.13178416754487426
Validation loss: 2.2805770935691205

Epoch: 6| Step: 11
Training loss: 0.20899401847479646
Validation loss: 2.2776642264681786

Epoch: 6| Step: 12
Training loss: 0.09023388350546938
Validation loss: 2.3000360072323773

Epoch: 6| Step: 13
Training loss: 0.1756610777476013
Validation loss: 2.319816500157504

Epoch: 536| Step: 0
Training loss: 0.22752908349155077
Validation loss: 2.259862729171689

Epoch: 6| Step: 1
Training loss: 0.1724656857174949
Validation loss: 2.2788192614583336

Epoch: 6| Step: 2
Training loss: 0.1670082095753047
Validation loss: 2.258778933221688

Epoch: 6| Step: 3
Training loss: 0.12046801885365668
Validation loss: 2.272327658087316

Epoch: 6| Step: 4
Training loss: 0.2497650472940369
Validation loss: 2.284078844703037

Epoch: 6| Step: 5
Training loss: 0.1432630079922591
Validation loss: 2.298946721767798

Epoch: 6| Step: 6
Training loss: 0.25257717886363173
Validation loss: 2.269163119401402

Epoch: 6| Step: 7
Training loss: 0.20289856871285283
Validation loss: 2.3053642890758406

Epoch: 6| Step: 8
Training loss: 0.17623748910748188
Validation loss: 2.2739755935069885

Epoch: 6| Step: 9
Training loss: 0.1502166212068755
Validation loss: 2.257960960178798

Epoch: 6| Step: 10
Training loss: 0.17912270058262764
Validation loss: 2.303121355483847

Epoch: 6| Step: 11
Training loss: 0.18636203193449694
Validation loss: 2.3040223983608588

Epoch: 6| Step: 12
Training loss: 0.12133293218478675
Validation loss: 2.3405223364176657

Epoch: 6| Step: 13
Training loss: 0.10412390596180232
Validation loss: 2.303656797920453

Epoch: 537| Step: 0
Training loss: 0.2415098585235177
Validation loss: 2.3095029196243813

Epoch: 6| Step: 1
Training loss: 0.14488875789585015
Validation loss: 2.3155474954222703

Epoch: 6| Step: 2
Training loss: 0.16959251624003546
Validation loss: 2.318953004961367

Epoch: 6| Step: 3
Training loss: 0.1798581681160082
Validation loss: 2.333035027169038

Epoch: 6| Step: 4
Training loss: 0.1021681936061385
Validation loss: 2.320900842013916

Epoch: 6| Step: 5
Training loss: 0.24007027922005686
Validation loss: 2.2997496798185177

Epoch: 6| Step: 6
Training loss: 0.10048589546033207
Validation loss: 2.3000711639580427

Epoch: 6| Step: 7
Training loss: 0.12540279252148137
Validation loss: 2.2913275343769524

Epoch: 6| Step: 8
Training loss: 0.14560364121454927
Validation loss: 2.270487620634071

Epoch: 6| Step: 9
Training loss: 0.16407426156164534
Validation loss: 2.2800876928335736

Epoch: 6| Step: 10
Training loss: 0.2313684343867634
Validation loss: 2.269180638733322

Epoch: 6| Step: 11
Training loss: 0.08211852721358201
Validation loss: 2.262892933587794

Epoch: 6| Step: 12
Training loss: 0.155778040972441
Validation loss: 2.258451979906022

Epoch: 6| Step: 13
Training loss: 0.11891909625152913
Validation loss: 2.2588064126034393

Epoch: 538| Step: 0
Training loss: 0.1579005798191492
Validation loss: 2.2779640865973625

Epoch: 6| Step: 1
Training loss: 0.08644838091528009
Validation loss: 2.295451845840146

Epoch: 6| Step: 2
Training loss: 0.1335454239914292
Validation loss: 2.267448720422599

Epoch: 6| Step: 3
Training loss: 0.13713629178532077
Validation loss: 2.254584884568277

Epoch: 6| Step: 4
Training loss: 0.12345882364380198
Validation loss: 2.287107778825554

Epoch: 6| Step: 5
Training loss: 0.11169727926076257
Validation loss: 2.2998073617141808

Epoch: 6| Step: 6
Training loss: 0.0701365122822607
Validation loss: 2.2857557642193886

Epoch: 6| Step: 7
Training loss: 0.14485800381825079
Validation loss: 2.3019255364705162

Epoch: 6| Step: 8
Training loss: 0.11608095673606361
Validation loss: 2.2726541177380937

Epoch: 6| Step: 9
Training loss: 0.1857876370056372
Validation loss: 2.3109255250139356

Epoch: 6| Step: 10
Training loss: 0.2214578955832312
Validation loss: 2.336543781081044

Epoch: 6| Step: 11
Training loss: 0.10903006470977067
Validation loss: 2.316809928064529

Epoch: 6| Step: 12
Training loss: 0.21570492589987
Validation loss: 2.274439895573278

Epoch: 6| Step: 13
Training loss: 0.07646837664806512
Validation loss: 2.273753738581097

Epoch: 539| Step: 0
Training loss: 0.10203438951180789
Validation loss: 2.278003220098469

Epoch: 6| Step: 1
Training loss: 0.13509919169414988
Validation loss: 2.247133748030891

Epoch: 6| Step: 2
Training loss: 0.1820849859139399
Validation loss: 2.2761756818283208

Epoch: 6| Step: 3
Training loss: 0.2132690461129112
Validation loss: 2.2322384444717156

Epoch: 6| Step: 4
Training loss: 0.10350503957355195
Validation loss: 2.3156748051591878

Epoch: 6| Step: 5
Training loss: 0.162208808140493
Validation loss: 2.2784580632675198

Epoch: 6| Step: 6
Training loss: 0.11071925808921598
Validation loss: 2.2682503216245786

Epoch: 6| Step: 7
Training loss: 0.12709842583145192
Validation loss: 2.2803729915913267

Epoch: 6| Step: 8
Training loss: 0.19369730655860942
Validation loss: 2.303818623625941

Epoch: 6| Step: 9
Training loss: 0.1500472508455269
Validation loss: 2.286592111330298

Epoch: 6| Step: 10
Training loss: 0.13568659542832975
Validation loss: 2.324521359227478

Epoch: 6| Step: 11
Training loss: 0.14443854632343217
Validation loss: 2.3213012440427776

Epoch: 6| Step: 12
Training loss: 0.19352938181552762
Validation loss: 2.323973866280522

Epoch: 6| Step: 13
Training loss: 0.12914684990282116
Validation loss: 2.3035737130210974

Epoch: 540| Step: 0
Training loss: 0.15828937957763545
Validation loss: 2.2998418483758583

Epoch: 6| Step: 1
Training loss: 0.09969146935862401
Validation loss: 2.3129601146938374

Epoch: 6| Step: 2
Training loss: 0.12346613693634209
Validation loss: 2.289963691510638

Epoch: 6| Step: 3
Training loss: 0.144772650192596
Validation loss: 2.3037905469317246

Epoch: 6| Step: 4
Training loss: 0.14315176881098082
Validation loss: 2.301593528145045

Epoch: 6| Step: 5
Training loss: 0.12641070470045274
Validation loss: 2.2978145722127254

Epoch: 6| Step: 6
Training loss: 0.10713669027947809
Validation loss: 2.261530812579982

Epoch: 6| Step: 7
Training loss: 0.1604687270820995
Validation loss: 2.2488521424686696

Epoch: 6| Step: 8
Training loss: 0.22572659157582586
Validation loss: 2.26017923829697

Epoch: 6| Step: 9
Training loss: 0.1406009772762755
Validation loss: 2.261014320247764

Epoch: 6| Step: 10
Training loss: 0.14640579659179048
Validation loss: 2.298548122738785

Epoch: 6| Step: 11
Training loss: 0.19514773094452204
Validation loss: 2.282665135722691

Epoch: 6| Step: 12
Training loss: 0.22618910834190448
Validation loss: 2.272920237951085

Epoch: 6| Step: 13
Training loss: 0.27466606976581576
Validation loss: 2.293234567512718

Epoch: 541| Step: 0
Training loss: 0.18011275018551137
Validation loss: 2.302432759847593

Epoch: 6| Step: 1
Training loss: 0.07921919788237747
Validation loss: 2.285200474678107

Epoch: 6| Step: 2
Training loss: 0.10380810228807415
Validation loss: 2.267731752044415

Epoch: 6| Step: 3
Training loss: 0.1306955536212985
Validation loss: 2.261967065814155

Epoch: 6| Step: 4
Training loss: 0.25707342677192857
Validation loss: 2.265751624608813

Epoch: 6| Step: 5
Training loss: 0.1652068690138483
Validation loss: 2.245552522956522

Epoch: 6| Step: 6
Training loss: 0.13193105868848337
Validation loss: 2.217426636209658

Epoch: 6| Step: 7
Training loss: 0.13597741089216203
Validation loss: 2.227980269151853

Epoch: 6| Step: 8
Training loss: 0.2427505285942852
Validation loss: 2.208742277606126

Epoch: 6| Step: 9
Training loss: 0.17676820250265443
Validation loss: 2.252314596196009

Epoch: 6| Step: 10
Training loss: 0.18190176455536827
Validation loss: 2.2406708931052663

Epoch: 6| Step: 11
Training loss: 0.1949023326793881
Validation loss: 2.252476283212124

Epoch: 6| Step: 12
Training loss: 0.13013907656994783
Validation loss: 2.2606481041701283

Epoch: 6| Step: 13
Training loss: 0.21887485313029348
Validation loss: 2.2554447114894014

Epoch: 542| Step: 0
Training loss: 0.1544688268619248
Validation loss: 2.271712911126994

Epoch: 6| Step: 1
Training loss: 0.2090723351729653
Validation loss: 2.289122922864865

Epoch: 6| Step: 2
Training loss: 0.13363408767997229
Validation loss: 2.239043890586606

Epoch: 6| Step: 3
Training loss: 0.12933155902673912
Validation loss: 2.2279566138238853

Epoch: 6| Step: 4
Training loss: 0.2448130464686512
Validation loss: 2.241274708157786

Epoch: 6| Step: 5
Training loss: 0.15251414233435617
Validation loss: 2.2640046172041863

Epoch: 6| Step: 6
Training loss: 0.17453061360693112
Validation loss: 2.2667313182619235

Epoch: 6| Step: 7
Training loss: 0.12038873975491911
Validation loss: 2.227865134910062

Epoch: 6| Step: 8
Training loss: 0.1633635972643567
Validation loss: 2.208763975231572

Epoch: 6| Step: 9
Training loss: 0.10681452283735085
Validation loss: 2.2288606790374503

Epoch: 6| Step: 10
Training loss: 0.13194053880100484
Validation loss: 2.2460027187424716

Epoch: 6| Step: 11
Training loss: 0.12603626758529424
Validation loss: 2.252475167831481

Epoch: 6| Step: 12
Training loss: 0.3075486727511165
Validation loss: 2.2535750347859325

Epoch: 6| Step: 13
Training loss: 0.20538653843043841
Validation loss: 2.2660802093219488

Epoch: 543| Step: 0
Training loss: 0.1778688760260844
Validation loss: 2.263820359734814

Epoch: 6| Step: 1
Training loss: 0.20232724376500993
Validation loss: 2.2414676402092626

Epoch: 6| Step: 2
Training loss: 0.3243908482834644
Validation loss: 2.2561483891888066

Epoch: 6| Step: 3
Training loss: 0.17852964742666733
Validation loss: 2.2664740442892675

Epoch: 6| Step: 4
Training loss: 0.14164045391714175
Validation loss: 2.299235906564085

Epoch: 6| Step: 5
Training loss: 0.1895770129959794
Validation loss: 2.305870136206976

Epoch: 6| Step: 6
Training loss: 0.1556266091064392
Validation loss: 2.2869631136048105

Epoch: 6| Step: 7
Training loss: 0.20073814300423673
Validation loss: 2.2852225362136793

Epoch: 6| Step: 8
Training loss: 0.10026083880083796
Validation loss: 2.305304714486548

Epoch: 6| Step: 9
Training loss: 0.12371004488532342
Validation loss: 2.2387942054031074

Epoch: 6| Step: 10
Training loss: 0.1277016142733974
Validation loss: 2.2528469550684798

Epoch: 6| Step: 11
Training loss: 0.18305060009619642
Validation loss: 2.2682838699422017

Epoch: 6| Step: 12
Training loss: 0.1180409073409968
Validation loss: 2.235772828438189

Epoch: 6| Step: 13
Training loss: 0.10258978996715552
Validation loss: 2.2314012804729297

Epoch: 544| Step: 0
Training loss: 0.13106234310661025
Validation loss: 2.2513148193097816

Epoch: 6| Step: 1
Training loss: 0.12419443282342382
Validation loss: 2.1940696823447245

Epoch: 6| Step: 2
Training loss: 0.18169954841368177
Validation loss: 2.223155219284799

Epoch: 6| Step: 3
Training loss: 0.15170026864024574
Validation loss: 2.2442038908857507

Epoch: 6| Step: 4
Training loss: 0.10315804530040174
Validation loss: 2.2472328171876033

Epoch: 6| Step: 5
Training loss: 0.15243090679562227
Validation loss: 2.253724093741681

Epoch: 6| Step: 6
Training loss: 0.17864171756492692
Validation loss: 2.249036835733994

Epoch: 6| Step: 7
Training loss: 0.13200172314232606
Validation loss: 2.2661850545033255

Epoch: 6| Step: 8
Training loss: 0.2138758966771586
Validation loss: 2.2953591405323466

Epoch: 6| Step: 9
Training loss: 0.18926943889923736
Validation loss: 2.2576247904134426

Epoch: 6| Step: 10
Training loss: 0.12238035882023661
Validation loss: 2.259664238373988

Epoch: 6| Step: 11
Training loss: 0.26840277796969153
Validation loss: 2.2721625811636676

Epoch: 6| Step: 12
Training loss: 0.21409441577750504
Validation loss: 2.304234512776039

Epoch: 6| Step: 13
Training loss: 0.10847431826167363
Validation loss: 2.2543698578334856

Epoch: 545| Step: 0
Training loss: 0.1528980003063377
Validation loss: 2.2685222201660946

Epoch: 6| Step: 1
Training loss: 0.16384151880599318
Validation loss: 2.242896519410216

Epoch: 6| Step: 2
Training loss: 0.14128926796828337
Validation loss: 2.263023591891579

Epoch: 6| Step: 3
Training loss: 0.09714639606332616
Validation loss: 2.280467214447071

Epoch: 6| Step: 4
Training loss: 0.16603829846102922
Validation loss: 2.2799324875680345

Epoch: 6| Step: 5
Training loss: 0.1366645978222466
Validation loss: 2.2999897661021556

Epoch: 6| Step: 6
Training loss: 0.11365249655412234
Validation loss: 2.273717799468747

Epoch: 6| Step: 7
Training loss: 0.20318410086978728
Validation loss: 2.2968548284195562

Epoch: 6| Step: 8
Training loss: 0.07954269311399398
Validation loss: 2.3128232278283014

Epoch: 6| Step: 9
Training loss: 0.11661189495166462
Validation loss: 2.269190177600758

Epoch: 6| Step: 10
Training loss: 0.1457547646000564
Validation loss: 2.2786199327160013

Epoch: 6| Step: 11
Training loss: 0.2259153215515911
Validation loss: 2.2937964688031434

Epoch: 6| Step: 12
Training loss: 0.1706509078184554
Validation loss: 2.2983086923259632

Epoch: 6| Step: 13
Training loss: 0.10886320792604331
Validation loss: 2.3095410391936464

Epoch: 546| Step: 0
Training loss: 0.10026019785803496
Validation loss: 2.294122851475414

Epoch: 6| Step: 1
Training loss: 0.09796994371310552
Validation loss: 2.3054264291855464

Epoch: 6| Step: 2
Training loss: 0.2325744208443582
Validation loss: 2.2670927357865733

Epoch: 6| Step: 3
Training loss: 0.11459011677328627
Validation loss: 2.2376791081409637

Epoch: 6| Step: 4
Training loss: 0.15045343053677582
Validation loss: 2.248584821828009

Epoch: 6| Step: 5
Training loss: 0.22214021614199683
Validation loss: 2.2590565950297274

Epoch: 6| Step: 6
Training loss: 0.15008669027006968
Validation loss: 2.2113909680833475

Epoch: 6| Step: 7
Training loss: 0.19073952142749415
Validation loss: 2.2271297864124016

Epoch: 6| Step: 8
Training loss: 0.17633278998177498
Validation loss: 2.2214063231878436

Epoch: 6| Step: 9
Training loss: 0.16029361323592756
Validation loss: 2.2423572033722246

Epoch: 6| Step: 10
Training loss: 0.1689349761182327
Validation loss: 2.22511071637932

Epoch: 6| Step: 11
Training loss: 0.09437992638083638
Validation loss: 2.23971074727499

Epoch: 6| Step: 12
Training loss: 0.14323371244210514
Validation loss: 2.2660894532422744

Epoch: 6| Step: 13
Training loss: 0.14094875076157473
Validation loss: 2.256143392344524

Epoch: 547| Step: 0
Training loss: 0.1905172880130338
Validation loss: 2.301988293385085

Epoch: 6| Step: 1
Training loss: 0.16318006711444394
Validation loss: 2.2859296630166988

Epoch: 6| Step: 2
Training loss: 0.1416920865851584
Validation loss: 2.2947754607996607

Epoch: 6| Step: 3
Training loss: 0.15404170702657807
Validation loss: 2.337994191834457

Epoch: 6| Step: 4
Training loss: 0.1515513868288592
Validation loss: 2.3228792393271607

Epoch: 6| Step: 5
Training loss: 0.14181903713209523
Validation loss: 2.3117367954755355

Epoch: 6| Step: 6
Training loss: 0.16365490531806004
Validation loss: 2.348015442475165

Epoch: 6| Step: 7
Training loss: 0.10725620672966302
Validation loss: 2.328769882751632

Epoch: 6| Step: 8
Training loss: 0.18230161072084305
Validation loss: 2.2851475577604994

Epoch: 6| Step: 9
Training loss: 0.15814751954734
Validation loss: 2.2906612760069804

Epoch: 6| Step: 10
Training loss: 0.19648323134588105
Validation loss: 2.3034847585467317

Epoch: 6| Step: 11
Training loss: 0.08938885674730583
Validation loss: 2.2971243662630414

Epoch: 6| Step: 12
Training loss: 0.12292011104286424
Validation loss: 2.2573366086231634

Epoch: 6| Step: 13
Training loss: 0.14665328777474657
Validation loss: 2.2971072631668514

Epoch: 548| Step: 0
Training loss: 0.20950398955495442
Validation loss: 2.2716952138339748

Epoch: 6| Step: 1
Training loss: 0.2059144179935269
Validation loss: 2.2896287203722694

Epoch: 6| Step: 2
Training loss: 0.13222702792605553
Validation loss: 2.2899759092665537

Epoch: 6| Step: 3
Training loss: 0.19367533214048693
Validation loss: 2.277180058362441

Epoch: 6| Step: 4
Training loss: 0.13872568671389435
Validation loss: 2.2990572520513983

Epoch: 6| Step: 5
Training loss: 0.16378843031255627
Validation loss: 2.316996090661039

Epoch: 6| Step: 6
Training loss: 0.14010030825051425
Validation loss: 2.2743869303419504

Epoch: 6| Step: 7
Training loss: 0.12993414301937212
Validation loss: 2.284706855578706

Epoch: 6| Step: 8
Training loss: 0.11699723852140805
Validation loss: 2.2817636277720657

Epoch: 6| Step: 9
Training loss: 0.12842363265278522
Validation loss: 2.2822348395712067

Epoch: 6| Step: 10
Training loss: 0.1093913815355996
Validation loss: 2.250104043804158

Epoch: 6| Step: 11
Training loss: 0.14407231953186214
Validation loss: 2.2282582435887788

Epoch: 6| Step: 12
Training loss: 0.09383427289312538
Validation loss: 2.2500907601631286

Epoch: 6| Step: 13
Training loss: 0.08163083932718669
Validation loss: 2.2518993448426468

Epoch: 549| Step: 0
Training loss: 0.14487231453355934
Validation loss: 2.243418116833395

Epoch: 6| Step: 1
Training loss: 0.1479602343798715
Validation loss: 2.262161600598354

Epoch: 6| Step: 2
Training loss: 0.09102687111329845
Validation loss: 2.296371406986492

Epoch: 6| Step: 3
Training loss: 0.116632474383285
Validation loss: 2.312181950331752

Epoch: 6| Step: 4
Training loss: 0.13350015618729474
Validation loss: 2.2944122033355248

Epoch: 6| Step: 5
Training loss: 0.14050652891266868
Validation loss: 2.3193836133770684

Epoch: 6| Step: 6
Training loss: 0.20808672415540064
Validation loss: 2.3114708071066747

Epoch: 6| Step: 7
Training loss: 0.12066015941744972
Validation loss: 2.2707218245992142

Epoch: 6| Step: 8
Training loss: 0.1708710948324137
Validation loss: 2.2601705736353273

Epoch: 6| Step: 9
Training loss: 0.2083849554875947
Validation loss: 2.2784038060533978

Epoch: 6| Step: 10
Training loss: 0.14575960148818953
Validation loss: 2.2570076585304113

Epoch: 6| Step: 11
Training loss: 0.13224214211305002
Validation loss: 2.255997270520055

Epoch: 6| Step: 12
Training loss: 0.11129137737722632
Validation loss: 2.2375008892938193

Epoch: 6| Step: 13
Training loss: 0.15003695330816968
Validation loss: 2.2087400363339644

Epoch: 550| Step: 0
Training loss: 0.1255624677996027
Validation loss: 2.223064174748362

Epoch: 6| Step: 1
Training loss: 0.08563850418597448
Validation loss: 2.222496568073721

Epoch: 6| Step: 2
Training loss: 0.09748218281881631
Validation loss: 2.226622742185328

Epoch: 6| Step: 3
Training loss: 0.09995502451453901
Validation loss: 2.270198516155808

Epoch: 6| Step: 4
Training loss: 0.1258075674732143
Validation loss: 2.2386112958747972

Epoch: 6| Step: 5
Training loss: 0.09930026017848348
Validation loss: 2.2626369235687047

Epoch: 6| Step: 6
Training loss: 0.19321504658693267
Validation loss: 2.2822028516167223

Epoch: 6| Step: 7
Training loss: 0.2421568651205066
Validation loss: 2.2763625779660885

Epoch: 6| Step: 8
Training loss: 0.25326559965623174
Validation loss: 2.2575529159132848

Epoch: 6| Step: 9
Training loss: 0.0967917803977701
Validation loss: 2.2839031945018338

Epoch: 6| Step: 10
Training loss: 0.1471587488922625
Validation loss: 2.289049934101567

Epoch: 6| Step: 11
Training loss: 0.1141038207431734
Validation loss: 2.2545142356195274

Epoch: 6| Step: 12
Training loss: 0.17947461122084668
Validation loss: 2.28634438104731

Epoch: 6| Step: 13
Training loss: 0.09866659133670376
Validation loss: 2.259461104845838

Testing loss: 2.414363792078079
