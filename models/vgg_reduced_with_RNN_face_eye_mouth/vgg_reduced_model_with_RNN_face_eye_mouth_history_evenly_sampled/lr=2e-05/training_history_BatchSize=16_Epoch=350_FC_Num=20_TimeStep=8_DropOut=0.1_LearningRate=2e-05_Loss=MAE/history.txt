Epoch: 1| Step: 0
Training loss: 5.908993244171143
Validation loss: 5.145619864104896

Epoch: 6| Step: 1
Training loss: 4.503292560577393
Validation loss: 5.130253156026204

Epoch: 6| Step: 2
Training loss: 6.181098461151123
Validation loss: 5.115030678369665

Epoch: 6| Step: 3
Training loss: 6.377457618713379
Validation loss: 5.099304999074628

Epoch: 6| Step: 4
Training loss: 4.864588737487793
Validation loss: 5.0812145253663425

Epoch: 6| Step: 5
Training loss: 4.920105457305908
Validation loss: 5.060390328848234

Epoch: 6| Step: 6
Training loss: 4.490055084228516
Validation loss: 5.03681981179022

Epoch: 6| Step: 7
Training loss: 4.043363571166992
Validation loss: 5.0093667840444915

Epoch: 6| Step: 8
Training loss: 3.3603107929229736
Validation loss: 4.976807517390097

Epoch: 6| Step: 9
Training loss: 4.639232635498047
Validation loss: 4.940073864434355

Epoch: 6| Step: 10
Training loss: 4.346530914306641
Validation loss: 4.89724592239626

Epoch: 6| Step: 11
Training loss: 5.2223358154296875
Validation loss: 4.848996685397241

Epoch: 6| Step: 12
Training loss: 3.77671480178833
Validation loss: 4.795930888063165

Epoch: 6| Step: 13
Training loss: 4.4105072021484375
Validation loss: 4.7364792157244935

Epoch: 2| Step: 0
Training loss: 4.601362705230713
Validation loss: 4.6720496070000435

Epoch: 6| Step: 1
Training loss: 4.624260425567627
Validation loss: 4.602960494256789

Epoch: 6| Step: 2
Training loss: 3.5880260467529297
Validation loss: 4.533109582880492

Epoch: 6| Step: 3
Training loss: 3.8390421867370605
Validation loss: 4.45863437908952

Epoch: 6| Step: 4
Training loss: 5.464428424835205
Validation loss: 4.381454257554905

Epoch: 6| Step: 5
Training loss: 4.948760032653809
Validation loss: 4.306152123276905

Epoch: 6| Step: 6
Training loss: 4.163558006286621
Validation loss: 4.23258460978026

Epoch: 6| Step: 7
Training loss: 3.845895290374756
Validation loss: 4.157072641516245

Epoch: 6| Step: 8
Training loss: 5.217735290527344
Validation loss: 4.086536720234861

Epoch: 6| Step: 9
Training loss: 3.243938446044922
Validation loss: 4.014178660608107

Epoch: 6| Step: 10
Training loss: 3.8164830207824707
Validation loss: 3.9437098195475917

Epoch: 6| Step: 11
Training loss: 3.172055721282959
Validation loss: 3.872863938731532

Epoch: 6| Step: 12
Training loss: 2.6273999214172363
Validation loss: 3.810123053930139

Epoch: 6| Step: 13
Training loss: 3.3126230239868164
Validation loss: 3.7625497284755913

Epoch: 3| Step: 0
Training loss: 4.1374711990356445
Validation loss: 3.714825486624113

Epoch: 6| Step: 1
Training loss: 2.92553448677063
Validation loss: 3.6668404738108316

Epoch: 6| Step: 2
Training loss: 2.531489133834839
Validation loss: 3.6261563506177676

Epoch: 6| Step: 3
Training loss: 3.5958504676818848
Validation loss: 3.5802643914376535

Epoch: 6| Step: 4
Training loss: 3.8640410900115967
Validation loss: 3.5439046993050525

Epoch: 6| Step: 5
Training loss: 3.12786865234375
Validation loss: 3.51570047614395

Epoch: 6| Step: 6
Training loss: 2.5227134227752686
Validation loss: 3.4961608994391655

Epoch: 6| Step: 7
Training loss: 2.397397518157959
Validation loss: 3.484639080621863

Epoch: 6| Step: 8
Training loss: 3.460453510284424
Validation loss: 3.466152775672174

Epoch: 6| Step: 9
Training loss: 4.340639114379883
Validation loss: 3.4512976369550152

Epoch: 6| Step: 10
Training loss: 4.532330513000488
Validation loss: 3.417339845370221

Epoch: 6| Step: 11
Training loss: 3.872394323348999
Validation loss: 3.3960829806584183

Epoch: 6| Step: 12
Training loss: 3.119638442993164
Validation loss: 3.3795483958336616

Epoch: 6| Step: 13
Training loss: 4.016084671020508
Validation loss: 3.3678576100257134

Epoch: 4| Step: 0
Training loss: 3.836207866668701
Validation loss: 3.3643385799982215

Epoch: 6| Step: 1
Training loss: 3.5116801261901855
Validation loss: 3.352606160666353

Epoch: 6| Step: 2
Training loss: 3.1276183128356934
Validation loss: 3.3260295032173075

Epoch: 6| Step: 3
Training loss: 3.4521918296813965
Validation loss: 3.299231511290355

Epoch: 6| Step: 4
Training loss: 3.780701160430908
Validation loss: 3.2859475433185534

Epoch: 6| Step: 5
Training loss: 2.864118814468384
Validation loss: 3.2759102595749723

Epoch: 6| Step: 6
Training loss: 1.7574748992919922
Validation loss: 3.2812178263100247

Epoch: 6| Step: 7
Training loss: 2.860600471496582
Validation loss: 3.2876076698303223

Epoch: 6| Step: 8
Training loss: 3.9428493976593018
Validation loss: 3.2750271827943864

Epoch: 6| Step: 9
Training loss: 4.0305609703063965
Validation loss: 3.2612653445172053

Epoch: 6| Step: 10
Training loss: 3.493321418762207
Validation loss: 3.224620980601157

Epoch: 6| Step: 11
Training loss: 3.0070343017578125
Validation loss: 3.197570505962577

Epoch: 6| Step: 12
Training loss: 2.5960798263549805
Validation loss: 3.1813382333324802

Epoch: 6| Step: 13
Training loss: 3.443704605102539
Validation loss: 3.171325093956404

Epoch: 5| Step: 0
Training loss: 3.5081164836883545
Validation loss: 3.165843497040451

Epoch: 6| Step: 1
Training loss: 1.9225924015045166
Validation loss: 3.155529022216797

Epoch: 6| Step: 2
Training loss: 2.2133665084838867
Validation loss: 3.1488085459637385

Epoch: 6| Step: 3
Training loss: 3.0165061950683594
Validation loss: 3.153697347128263

Epoch: 6| Step: 4
Training loss: 3.951103448867798
Validation loss: 3.1404712635983705

Epoch: 6| Step: 5
Training loss: 3.765285015106201
Validation loss: 3.128411252011535

Epoch: 6| Step: 6
Training loss: 3.368021011352539
Validation loss: 3.10949549623715

Epoch: 6| Step: 7
Training loss: 3.4329795837402344
Validation loss: 3.116253270897814

Epoch: 6| Step: 8
Training loss: 2.935161590576172
Validation loss: 3.1248394212415143

Epoch: 6| Step: 9
Training loss: 2.5358426570892334
Validation loss: 3.0988464022195465

Epoch: 6| Step: 10
Training loss: 3.499344825744629
Validation loss: 3.063216875958186

Epoch: 6| Step: 11
Training loss: 4.065495014190674
Validation loss: 3.064973697867445

Epoch: 6| Step: 12
Training loss: 2.7107272148132324
Validation loss: 3.0656826598669893

Epoch: 6| Step: 13
Training loss: 2.8514981269836426
Validation loss: 3.0519360598697456

Epoch: 6| Step: 0
Training loss: 3.9694759845733643
Validation loss: 3.052308838854554

Epoch: 6| Step: 1
Training loss: 2.441089153289795
Validation loss: 3.025859437963014

Epoch: 6| Step: 2
Training loss: 2.6418089866638184
Validation loss: 3.019585878618302

Epoch: 6| Step: 3
Training loss: 3.118807792663574
Validation loss: 3.0242858343226935

Epoch: 6| Step: 4
Training loss: 2.6315627098083496
Validation loss: 3.0256271900669223

Epoch: 6| Step: 5
Training loss: 2.8280951976776123
Validation loss: 3.018953300291492

Epoch: 6| Step: 6
Training loss: 3.4544639587402344
Validation loss: 3.011116450832736

Epoch: 6| Step: 7
Training loss: 2.976564407348633
Validation loss: 2.99163406895053

Epoch: 6| Step: 8
Training loss: 3.6996121406555176
Validation loss: 2.972145608676377

Epoch: 6| Step: 9
Training loss: 2.811781406402588
Validation loss: 2.9607358465912523

Epoch: 6| Step: 10
Training loss: 3.124633312225342
Validation loss: 2.954411132361299

Epoch: 6| Step: 11
Training loss: 3.417428970336914
Validation loss: 2.948173079439389

Epoch: 6| Step: 12
Training loss: 2.3526611328125
Validation loss: 2.948347453148134

Epoch: 6| Step: 13
Training loss: 3.719668388366699
Validation loss: 2.941910723204254

Epoch: 7| Step: 0
Training loss: 2.9435198307037354
Validation loss: 2.931431321687596

Epoch: 6| Step: 1
Training loss: 3.6126770973205566
Validation loss: 2.920344880832139

Epoch: 6| Step: 2
Training loss: 3.066932201385498
Validation loss: 2.9092826971443753

Epoch: 6| Step: 3
Training loss: 3.5232737064361572
Validation loss: 2.902224909874701

Epoch: 6| Step: 4
Training loss: 3.1936838626861572
Validation loss: 2.8976386336870092

Epoch: 6| Step: 5
Training loss: 2.300349473953247
Validation loss: 2.8884977448371147

Epoch: 6| Step: 6
Training loss: 2.8066000938415527
Validation loss: 2.8799821945928756

Epoch: 6| Step: 7
Training loss: 2.7139973640441895
Validation loss: 2.875569038493659

Epoch: 6| Step: 8
Training loss: 2.261385917663574
Validation loss: 2.8701943043739564

Epoch: 6| Step: 9
Training loss: 3.3301148414611816
Validation loss: 2.8679271077597015

Epoch: 6| Step: 10
Training loss: 2.913445234298706
Validation loss: 2.8598356067493396

Epoch: 6| Step: 11
Training loss: 3.026214122772217
Validation loss: 2.8536639111016386

Epoch: 6| Step: 12
Training loss: 3.4445879459381104
Validation loss: 2.8484865439835416

Epoch: 6| Step: 13
Training loss: 2.556067705154419
Validation loss: 2.8398508077026694

Epoch: 8| Step: 0
Training loss: 3.2283759117126465
Validation loss: 2.831322298255018

Epoch: 6| Step: 1
Training loss: 3.4116125106811523
Validation loss: 2.826898136446553

Epoch: 6| Step: 2
Training loss: 3.2913882732391357
Validation loss: 2.8185588928960983

Epoch: 6| Step: 3
Training loss: 2.912490129470825
Validation loss: 2.810098981344572

Epoch: 6| Step: 4
Training loss: 3.278657913208008
Validation loss: 2.8028749035250757

Epoch: 6| Step: 5
Training loss: 3.089076042175293
Validation loss: 2.797272994954099

Epoch: 6| Step: 6
Training loss: 3.1215476989746094
Validation loss: 2.802552006577933

Epoch: 6| Step: 7
Training loss: 2.326808452606201
Validation loss: 2.8041779507872877

Epoch: 6| Step: 8
Training loss: 2.2335615158081055
Validation loss: 2.7903542210978847

Epoch: 6| Step: 9
Training loss: 3.21622371673584
Validation loss: 2.8055275973453315

Epoch: 6| Step: 10
Training loss: 2.420078754425049
Validation loss: 2.781133177459881

Epoch: 6| Step: 11
Training loss: 2.533687114715576
Validation loss: 2.7803925980803785

Epoch: 6| Step: 12
Training loss: 3.5222771167755127
Validation loss: 2.781025681444394

Epoch: 6| Step: 13
Training loss: 2.104926347732544
Validation loss: 2.7790847093828264

Epoch: 9| Step: 0
Training loss: 3.679990291595459
Validation loss: 2.7728255641075874

Epoch: 6| Step: 1
Training loss: 3.3878772258758545
Validation loss: 2.764353747008949

Epoch: 6| Step: 2
Training loss: 3.514951229095459
Validation loss: 2.751750662762632

Epoch: 6| Step: 3
Training loss: 2.779536247253418
Validation loss: 2.7489782661520024

Epoch: 6| Step: 4
Training loss: 2.5326406955718994
Validation loss: 2.7458724898676716

Epoch: 6| Step: 5
Training loss: 2.67081356048584
Validation loss: 2.745417397509339

Epoch: 6| Step: 6
Training loss: 3.1322879791259766
Validation loss: 2.7400267124176025

Epoch: 6| Step: 7
Training loss: 2.2914347648620605
Validation loss: 2.7342275701543337

Epoch: 6| Step: 8
Training loss: 3.3190526962280273
Validation loss: 2.7284127461012972

Epoch: 6| Step: 9
Training loss: 1.9458162784576416
Validation loss: 2.726400872712494

Epoch: 6| Step: 10
Training loss: 3.146287441253662
Validation loss: 2.724043362884111

Epoch: 6| Step: 11
Training loss: 2.6067755222320557
Validation loss: 2.7204682980814288

Epoch: 6| Step: 12
Training loss: 2.52384614944458
Validation loss: 2.717464787985689

Epoch: 6| Step: 13
Training loss: 3.106085777282715
Validation loss: 2.720127018549109

Epoch: 10| Step: 0
Training loss: 3.262730598449707
Validation loss: 2.7271437157866774

Epoch: 6| Step: 1
Training loss: 2.923426628112793
Validation loss: 2.7101935443057807

Epoch: 6| Step: 2
Training loss: 2.515934705734253
Validation loss: 2.721423654146092

Epoch: 6| Step: 3
Training loss: 3.1014342308044434
Validation loss: 2.7148111892002884

Epoch: 6| Step: 4
Training loss: 2.6904923915863037
Validation loss: 2.7074604393333517

Epoch: 6| Step: 5
Training loss: 2.812465190887451
Validation loss: 2.7016906046098277

Epoch: 6| Step: 6
Training loss: 2.9012606143951416
Validation loss: 2.6963462034861245

Epoch: 6| Step: 7
Training loss: 2.8728790283203125
Validation loss: 2.6892672251629572

Epoch: 6| Step: 8
Training loss: 2.1572957038879395
Validation loss: 2.688361757545061

Epoch: 6| Step: 9
Training loss: 3.0535426139831543
Validation loss: 2.6875509113393803

Epoch: 6| Step: 10
Training loss: 3.11798357963562
Validation loss: 2.700808625067434

Epoch: 6| Step: 11
Training loss: 2.8706722259521484
Validation loss: 2.7225147447278424

Epoch: 6| Step: 12
Training loss: 2.3622500896453857
Validation loss: 2.686205240987962

Epoch: 6| Step: 13
Training loss: 4.042323589324951
Validation loss: 2.6823169851815827

Epoch: 11| Step: 0
Training loss: 3.443380832672119
Validation loss: 2.682548056366623

Epoch: 6| Step: 1
Training loss: 2.5560646057128906
Validation loss: 2.6840176172153924

Epoch: 6| Step: 2
Training loss: 2.9458932876586914
Validation loss: 2.6870818804669123

Epoch: 6| Step: 3
Training loss: 2.9522953033447266
Validation loss: 2.674122118180798

Epoch: 6| Step: 4
Training loss: 3.061387062072754
Validation loss: 2.672705873366325

Epoch: 6| Step: 5
Training loss: 3.121636390686035
Validation loss: 2.68081263572939

Epoch: 6| Step: 6
Training loss: 3.0090184211730957
Validation loss: 2.6827479690633793

Epoch: 6| Step: 7
Training loss: 3.0376298427581787
Validation loss: 2.6866223581375612

Epoch: 6| Step: 8
Training loss: 2.6363325119018555
Validation loss: 2.658538587631718

Epoch: 6| Step: 9
Training loss: 1.8492058515548706
Validation loss: 2.6537907943930676

Epoch: 6| Step: 10
Training loss: 3.4498939514160156
Validation loss: 2.6541535674884753

Epoch: 6| Step: 11
Training loss: 1.4613896608352661
Validation loss: 2.6722902149282475

Epoch: 6| Step: 12
Training loss: 3.7369155883789062
Validation loss: 2.7073174804769535

Epoch: 6| Step: 13
Training loss: 2.680901050567627
Validation loss: 2.6521246663985716

Epoch: 12| Step: 0
Training loss: 2.3518412113189697
Validation loss: 2.646627567147696

Epoch: 6| Step: 1
Training loss: 2.775317907333374
Validation loss: 2.6517404971584195

Epoch: 6| Step: 2
Training loss: 3.3738226890563965
Validation loss: 2.675333079471383

Epoch: 6| Step: 3
Training loss: 2.9749763011932373
Validation loss: 2.659982942765759

Epoch: 6| Step: 4
Training loss: 3.2250008583068848
Validation loss: 2.6460365890174784

Epoch: 6| Step: 5
Training loss: 3.024351119995117
Validation loss: 2.643522806065057

Epoch: 6| Step: 6
Training loss: 2.7782115936279297
Validation loss: 2.64486284922528

Epoch: 6| Step: 7
Training loss: 3.125300884246826
Validation loss: 2.649321756055278

Epoch: 6| Step: 8
Training loss: 2.8957326412200928
Validation loss: 2.6470633963102936

Epoch: 6| Step: 9
Training loss: 2.2669754028320312
Validation loss: 2.6481021322229856

Epoch: 6| Step: 10
Training loss: 3.2793192863464355
Validation loss: 2.6443908958024878

Epoch: 6| Step: 11
Training loss: 2.597379446029663
Validation loss: 2.6378817878743654

Epoch: 6| Step: 12
Training loss: 2.5557379722595215
Validation loss: 2.637511045702042

Epoch: 6| Step: 13
Training loss: 2.033310890197754
Validation loss: 2.6346386581338863

Epoch: 13| Step: 0
Training loss: 2.3261685371398926
Validation loss: 2.639078532495806

Epoch: 6| Step: 1
Training loss: 2.982262134552002
Validation loss: 2.6389111934169645

Epoch: 6| Step: 2
Training loss: 2.956721544265747
Validation loss: 2.633045640043033

Epoch: 6| Step: 3
Training loss: 2.1676979064941406
Validation loss: 2.624418556049306

Epoch: 6| Step: 4
Training loss: 2.315983772277832
Validation loss: 2.62251603475181

Epoch: 6| Step: 5
Training loss: 3.0104286670684814
Validation loss: 2.6183799543688373

Epoch: 6| Step: 6
Training loss: 2.1921236515045166
Validation loss: 2.6147580044243925

Epoch: 6| Step: 7
Training loss: 3.00913143157959
Validation loss: 2.6100605123786518

Epoch: 6| Step: 8
Training loss: 2.9874634742736816
Validation loss: 2.6116609957910355

Epoch: 6| Step: 9
Training loss: 2.9749932289123535
Validation loss: 2.6201218276895504

Epoch: 6| Step: 10
Training loss: 2.9102439880371094
Validation loss: 2.6020907804530156

Epoch: 6| Step: 11
Training loss: 2.9703190326690674
Validation loss: 2.60043671823317

Epoch: 6| Step: 12
Training loss: 3.12760329246521
Validation loss: 2.5898891879666235

Epoch: 6| Step: 13
Training loss: 3.651024341583252
Validation loss: 2.5864662944629626

Epoch: 14| Step: 0
Training loss: 3.129913806915283
Validation loss: 2.5969020781978482

Epoch: 6| Step: 1
Training loss: 3.2177982330322266
Validation loss: 2.591208134928057

Epoch: 6| Step: 2
Training loss: 2.916599988937378
Validation loss: 2.5788524740485737

Epoch: 6| Step: 3
Training loss: 2.784223794937134
Validation loss: 2.577501684106806

Epoch: 6| Step: 4
Training loss: 2.8998138904571533
Validation loss: 2.5780292736586703

Epoch: 6| Step: 5
Training loss: 3.0666985511779785
Validation loss: 2.584545691808065

Epoch: 6| Step: 6
Training loss: 2.751518726348877
Validation loss: 2.6097508220262426

Epoch: 6| Step: 7
Training loss: 2.4700698852539062
Validation loss: 2.5938095200446343

Epoch: 6| Step: 8
Training loss: 3.245157241821289
Validation loss: 2.575270568170855

Epoch: 6| Step: 9
Training loss: 2.7068421840667725
Validation loss: 2.5692132493501068

Epoch: 6| Step: 10
Training loss: 2.112989664077759
Validation loss: 2.568693332774665

Epoch: 6| Step: 11
Training loss: 2.267296075820923
Validation loss: 2.559673673363142

Epoch: 6| Step: 12
Training loss: 2.5442042350769043
Validation loss: 2.5608248146631385

Epoch: 6| Step: 13
Training loss: 2.693016767501831
Validation loss: 2.589942686019405

Epoch: 15| Step: 0
Training loss: 2.344647169113159
Validation loss: 2.5982221364974976

Epoch: 6| Step: 1
Training loss: 2.8606739044189453
Validation loss: 2.601665134071022

Epoch: 6| Step: 2
Training loss: 2.971426010131836
Validation loss: 2.557812585625597

Epoch: 6| Step: 3
Training loss: 2.5040900707244873
Validation loss: 2.5410276561655025

Epoch: 6| Step: 4
Training loss: 1.9539645910263062
Validation loss: 2.549263649089362

Epoch: 6| Step: 5
Training loss: 2.469789981842041
Validation loss: 2.553432805563814

Epoch: 6| Step: 6
Training loss: 2.455284357070923
Validation loss: 2.5408924395038235

Epoch: 6| Step: 7
Training loss: 3.450415849685669
Validation loss: 2.5376239899666078

Epoch: 6| Step: 8
Training loss: 3.0676827430725098
Validation loss: 2.5302379310771985

Epoch: 6| Step: 9
Training loss: 3.0358290672302246
Validation loss: 2.53934230086624

Epoch: 6| Step: 10
Training loss: 3.397528648376465
Validation loss: 2.5676467982671594

Epoch: 6| Step: 11
Training loss: 2.652373790740967
Validation loss: 2.5495855116075083

Epoch: 6| Step: 12
Training loss: 2.268418312072754
Validation loss: 2.5177770583860335

Epoch: 6| Step: 13
Training loss: 3.4513275623321533
Validation loss: 2.51952604580951

Epoch: 16| Step: 0
Training loss: 2.9540200233459473
Validation loss: 2.527541196474465

Epoch: 6| Step: 1
Training loss: 2.091607093811035
Validation loss: 2.5513531930984987

Epoch: 6| Step: 2
Training loss: 1.705082893371582
Validation loss: 2.617212700587447

Epoch: 6| Step: 3
Training loss: 2.726513385772705
Validation loss: 2.7024484193453224

Epoch: 6| Step: 4
Training loss: 2.794273853302002
Validation loss: 2.6452765951874437

Epoch: 6| Step: 5
Training loss: 3.0116617679595947
Validation loss: 2.5294475632329143

Epoch: 6| Step: 6
Training loss: 3.6238555908203125
Validation loss: 2.4999789448194605

Epoch: 6| Step: 7
Training loss: 2.740746021270752
Validation loss: 2.5732789244703067

Epoch: 6| Step: 8
Training loss: 3.1516385078430176
Validation loss: 2.7591440088005474

Epoch: 6| Step: 9
Training loss: 3.30739426612854
Validation loss: 2.91485886163609

Epoch: 6| Step: 10
Training loss: 3.7632551193237305
Validation loss: 2.8651240615434546

Epoch: 6| Step: 11
Training loss: 2.4582443237304688
Validation loss: 2.738347294510052

Epoch: 6| Step: 12
Training loss: 1.9537372589111328
Validation loss: 2.574102242787679

Epoch: 6| Step: 13
Training loss: 3.8980624675750732
Validation loss: 2.4991386834011284

Epoch: 17| Step: 0
Training loss: 3.040883779525757
Validation loss: 2.55424391582448

Epoch: 6| Step: 1
Training loss: 2.8285579681396484
Validation loss: 2.699234034425469

Epoch: 6| Step: 2
Training loss: 2.6896798610687256
Validation loss: 2.8005095989473405

Epoch: 6| Step: 3
Training loss: 2.934525966644287
Validation loss: 2.6958878347950597

Epoch: 6| Step: 4
Training loss: 2.42928147315979
Validation loss: 2.548276557717272

Epoch: 6| Step: 5
Training loss: 2.5452921390533447
Validation loss: 2.5224388799359723

Epoch: 6| Step: 6
Training loss: 2.1834640502929688
Validation loss: 2.5149066755848546

Epoch: 6| Step: 7
Training loss: 2.7514963150024414
Validation loss: 2.54882727899859

Epoch: 6| Step: 8
Training loss: 3.1226556301116943
Validation loss: 2.6094566314451155

Epoch: 6| Step: 9
Training loss: 2.797558069229126
Validation loss: 2.6438580533509612

Epoch: 6| Step: 10
Training loss: 3.162916660308838
Validation loss: 2.6790885053655153

Epoch: 6| Step: 11
Training loss: 3.6562583446502686
Validation loss: 2.6720030230860554

Epoch: 6| Step: 12
Training loss: 2.243304491043091
Validation loss: 2.6103438433780464

Epoch: 6| Step: 13
Training loss: 3.730876922607422
Validation loss: 2.5582237525652816

Epoch: 18| Step: 0
Training loss: 2.8244590759277344
Validation loss: 2.533038354689075

Epoch: 6| Step: 1
Training loss: 3.209073305130005
Validation loss: 2.508333183103992

Epoch: 6| Step: 2
Training loss: 3.0568509101867676
Validation loss: 2.5125115071573565

Epoch: 6| Step: 3
Training loss: 3.1545157432556152
Validation loss: 2.5202315956033687

Epoch: 6| Step: 4
Training loss: 2.6766576766967773
Validation loss: 2.5266353725105204

Epoch: 6| Step: 5
Training loss: 3.440307378768921
Validation loss: 2.529469126014299

Epoch: 6| Step: 6
Training loss: 2.608509063720703
Validation loss: 2.5226747092380317

Epoch: 6| Step: 7
Training loss: 2.791372299194336
Validation loss: 2.5224353113482074

Epoch: 6| Step: 8
Training loss: 2.180291175842285
Validation loss: 2.5261116284196095

Epoch: 6| Step: 9
Training loss: 2.278265953063965
Validation loss: 2.524917774302985

Epoch: 6| Step: 10
Training loss: 2.2527339458465576
Validation loss: 2.523435003014021

Epoch: 6| Step: 11
Training loss: 2.286733627319336
Validation loss: 2.518213777131932

Epoch: 6| Step: 12
Training loss: 3.135420322418213
Validation loss: 2.5125415914802143

Epoch: 6| Step: 13
Training loss: 2.609243154525757
Validation loss: 2.5143882510482625

Epoch: 19| Step: 0
Training loss: 2.682110071182251
Validation loss: 2.50870019133373

Epoch: 6| Step: 1
Training loss: 2.9241228103637695
Validation loss: 2.5004993574593657

Epoch: 6| Step: 2
Training loss: 3.0946831703186035
Validation loss: 2.4901024269801315

Epoch: 6| Step: 3
Training loss: 3.020508289337158
Validation loss: 2.4841673604903685

Epoch: 6| Step: 4
Training loss: 2.4963345527648926
Validation loss: 2.477946389106012

Epoch: 6| Step: 5
Training loss: 3.0670220851898193
Validation loss: 2.471945580615792

Epoch: 6| Step: 6
Training loss: 2.5294947624206543
Validation loss: 2.469377433100054

Epoch: 6| Step: 7
Training loss: 2.1747851371765137
Validation loss: 2.46579602713226

Epoch: 6| Step: 8
Training loss: 3.564546585083008
Validation loss: 2.4782304763793945

Epoch: 6| Step: 9
Training loss: 2.341329574584961
Validation loss: 2.4637326168757614

Epoch: 6| Step: 10
Training loss: 2.258596897125244
Validation loss: 2.4738628146468953

Epoch: 6| Step: 11
Training loss: 2.4268171787261963
Validation loss: 2.5098998879873626

Epoch: 6| Step: 12
Training loss: 2.8546700477600098
Validation loss: 2.5170353612592145

Epoch: 6| Step: 13
Training loss: 2.802666187286377
Validation loss: 2.4870996218855663

Epoch: 20| Step: 0
Training loss: 2.4801857471466064
Validation loss: 2.4517141285762993

Epoch: 6| Step: 1
Training loss: 2.678926944732666
Validation loss: 2.4518549570473294

Epoch: 6| Step: 2
Training loss: 3.3958544731140137
Validation loss: 2.4542587726346907

Epoch: 6| Step: 3
Training loss: 2.417790412902832
Validation loss: 2.4532625239382506

Epoch: 6| Step: 4
Training loss: 2.2833163738250732
Validation loss: 2.463378890868156

Epoch: 6| Step: 5
Training loss: 2.5236735343933105
Validation loss: 2.4555548173125072

Epoch: 6| Step: 6
Training loss: 2.937262535095215
Validation loss: 2.454088221314133

Epoch: 6| Step: 7
Training loss: 1.956384539604187
Validation loss: 2.4515862413631972

Epoch: 6| Step: 8
Training loss: 2.26129150390625
Validation loss: 2.4479842378247167

Epoch: 6| Step: 9
Training loss: 3.1615052223205566
Validation loss: 2.4468877007884364

Epoch: 6| Step: 10
Training loss: 2.69564151763916
Validation loss: 2.4489558819801576

Epoch: 6| Step: 11
Training loss: 3.431367874145508
Validation loss: 2.4522599122857534

Epoch: 6| Step: 12
Training loss: 3.309765338897705
Validation loss: 2.4628892380704164

Epoch: 6| Step: 13
Training loss: 2.3031153678894043
Validation loss: 2.460349570038498

Epoch: 21| Step: 0
Training loss: 2.4274284839630127
Validation loss: 2.452294118942753

Epoch: 6| Step: 1
Training loss: 2.8969459533691406
Validation loss: 2.469254393731394

Epoch: 6| Step: 2
Training loss: 3.1255745887756348
Validation loss: 2.4705112441893546

Epoch: 6| Step: 3
Training loss: 2.525322437286377
Validation loss: 2.469988638354886

Epoch: 6| Step: 4
Training loss: 2.218060255050659
Validation loss: 2.461219000559981

Epoch: 6| Step: 5
Training loss: 2.9787347316741943
Validation loss: 2.4490640701786166

Epoch: 6| Step: 6
Training loss: 3.3263633251190186
Validation loss: 2.447763399411273

Epoch: 6| Step: 7
Training loss: 2.44484281539917
Validation loss: 2.4516972316208707

Epoch: 6| Step: 8
Training loss: 2.3198771476745605
Validation loss: 2.4544317671047744

Epoch: 6| Step: 9
Training loss: 3.1526870727539062
Validation loss: 2.462767093412338

Epoch: 6| Step: 10
Training loss: 2.47342848777771
Validation loss: 2.4669175788920414

Epoch: 6| Step: 11
Training loss: 2.9984540939331055
Validation loss: 2.467194411062425

Epoch: 6| Step: 12
Training loss: 2.3161888122558594
Validation loss: 2.4521607788660194

Epoch: 6| Step: 13
Training loss: 2.7632339000701904
Validation loss: 2.446721394856771

Epoch: 22| Step: 0
Training loss: 2.673184871673584
Validation loss: 2.449126987047093

Epoch: 6| Step: 1
Training loss: 3.0948586463928223
Validation loss: 2.449418460169146

Epoch: 6| Step: 2
Training loss: 2.923156261444092
Validation loss: 2.4513435697042816

Epoch: 6| Step: 3
Training loss: 2.3293135166168213
Validation loss: 2.460638589756463

Epoch: 6| Step: 4
Training loss: 2.7890546321868896
Validation loss: 2.4643988199131464

Epoch: 6| Step: 5
Training loss: 3.112051486968994
Validation loss: 2.47397603014464

Epoch: 6| Step: 6
Training loss: 2.7671384811401367
Validation loss: 2.4764551513938495

Epoch: 6| Step: 7
Training loss: 2.680032253265381
Validation loss: 2.4744925909144904

Epoch: 6| Step: 8
Training loss: 2.105538845062256
Validation loss: 2.444622665323237

Epoch: 6| Step: 9
Training loss: 2.610572338104248
Validation loss: 2.4331927350772324

Epoch: 6| Step: 10
Training loss: 2.897364616394043
Validation loss: 2.4315330879662627

Epoch: 6| Step: 11
Training loss: 2.6087379455566406
Validation loss: 2.431487165471559

Epoch: 6| Step: 12
Training loss: 2.846179485321045
Validation loss: 2.429414908091227

Epoch: 6| Step: 13
Training loss: 1.6880894899368286
Validation loss: 2.4244540250429543

Epoch: 23| Step: 0
Training loss: 2.7833733558654785
Validation loss: 2.4197622370976273

Epoch: 6| Step: 1
Training loss: 2.352841854095459
Validation loss: 2.4181414650332544

Epoch: 6| Step: 2
Training loss: 3.3938448429107666
Validation loss: 2.4162132060655983

Epoch: 6| Step: 3
Training loss: 1.6725692749023438
Validation loss: 2.4215726903689805

Epoch: 6| Step: 4
Training loss: 3.192882776260376
Validation loss: 2.422304122678695

Epoch: 6| Step: 5
Training loss: 2.592181921005249
Validation loss: 2.427958993501561

Epoch: 6| Step: 6
Training loss: 2.7446389198303223
Validation loss: 2.434535800769765

Epoch: 6| Step: 7
Training loss: 2.224973440170288
Validation loss: 2.4371852938846876

Epoch: 6| Step: 8
Training loss: 2.4453654289245605
Validation loss: 2.428468135095412

Epoch: 6| Step: 9
Training loss: 3.1071977615356445
Validation loss: 2.4190821775826077

Epoch: 6| Step: 10
Training loss: 2.8923521041870117
Validation loss: 2.4165091360768964

Epoch: 6| Step: 11
Training loss: 3.051054000854492
Validation loss: 2.424859687846194

Epoch: 6| Step: 12
Training loss: 2.0994441509246826
Validation loss: 2.445472435284686

Epoch: 6| Step: 13
Training loss: 3.190670967102051
Validation loss: 2.4916058765944613

Epoch: 24| Step: 0
Training loss: 2.85744309425354
Validation loss: 2.5557216803232827

Epoch: 6| Step: 1
Training loss: 2.1437926292419434
Validation loss: 2.5982918534227597

Epoch: 6| Step: 2
Training loss: 1.8424913883209229
Validation loss: 2.571074785724763

Epoch: 6| Step: 3
Training loss: 3.063058376312256
Validation loss: 2.51651499348302

Epoch: 6| Step: 4
Training loss: 3.2862911224365234
Validation loss: 2.524922642656552

Epoch: 6| Step: 5
Training loss: 3.0058181285858154
Validation loss: 2.527507374363561

Epoch: 6| Step: 6
Training loss: 2.9969005584716797
Validation loss: 2.5253177612058577

Epoch: 6| Step: 7
Training loss: 3.0693507194519043
Validation loss: 2.514021611982776

Epoch: 6| Step: 8
Training loss: 2.985572099685669
Validation loss: 2.482106316474176

Epoch: 6| Step: 9
Training loss: 2.224714756011963
Validation loss: 2.464787680615661

Epoch: 6| Step: 10
Training loss: 2.864779233932495
Validation loss: 2.459648455342939

Epoch: 6| Step: 11
Training loss: 2.7337934970855713
Validation loss: 2.4879085415153095

Epoch: 6| Step: 12
Training loss: 1.9781622886657715
Validation loss: 2.4426234588828137

Epoch: 6| Step: 13
Training loss: 2.4837210178375244
Validation loss: 2.4191126079969507

Epoch: 25| Step: 0
Training loss: 2.466440200805664
Validation loss: 2.4176857727830128

Epoch: 6| Step: 1
Training loss: 2.856658458709717
Validation loss: 2.417254373591433

Epoch: 6| Step: 2
Training loss: 2.6349215507507324
Validation loss: 2.41012038723115

Epoch: 6| Step: 3
Training loss: 2.908331871032715
Validation loss: 2.4075705389822684

Epoch: 6| Step: 4
Training loss: 2.7518558502197266
Validation loss: 2.404242161781557

Epoch: 6| Step: 5
Training loss: 3.6947312355041504
Validation loss: 2.4027535825647335

Epoch: 6| Step: 6
Training loss: 2.0113794803619385
Validation loss: 2.404169403096681

Epoch: 6| Step: 7
Training loss: 2.68477725982666
Validation loss: 2.398108479797199

Epoch: 6| Step: 8
Training loss: 2.677842140197754
Validation loss: 2.399177433342062

Epoch: 6| Step: 9
Training loss: 2.6381773948669434
Validation loss: 2.400083435479031

Epoch: 6| Step: 10
Training loss: 2.82833194732666
Validation loss: 2.3973635768377655

Epoch: 6| Step: 11
Training loss: 2.0428473949432373
Validation loss: 2.3939233813234555

Epoch: 6| Step: 12
Training loss: 2.5540659427642822
Validation loss: 2.3946812460499425

Epoch: 6| Step: 13
Training loss: 2.1378819942474365
Validation loss: 2.3933304561081754

Epoch: 26| Step: 0
Training loss: 2.8314571380615234
Validation loss: 2.399502954175395

Epoch: 6| Step: 1
Training loss: 2.070361852645874
Validation loss: 2.4114796294960925

Epoch: 6| Step: 2
Training loss: 2.1522912979125977
Validation loss: 2.4509270345011065

Epoch: 6| Step: 3
Training loss: 2.1137399673461914
Validation loss: 2.508837963945122

Epoch: 6| Step: 4
Training loss: 3.0156538486480713
Validation loss: 2.5178051302509923

Epoch: 6| Step: 5
Training loss: 2.6789870262145996
Validation loss: 2.492797082470309

Epoch: 6| Step: 6
Training loss: 3.0928826332092285
Validation loss: 2.4771349148083757

Epoch: 6| Step: 7
Training loss: 2.9333581924438477
Validation loss: 2.4562857125395086

Epoch: 6| Step: 8
Training loss: 3.080125093460083
Validation loss: 2.437185484875915

Epoch: 6| Step: 9
Training loss: 2.9098572731018066
Validation loss: 2.419629978877242

Epoch: 6| Step: 10
Training loss: 2.1860015392303467
Validation loss: 2.4128660002062396

Epoch: 6| Step: 11
Training loss: 2.5844855308532715
Validation loss: 2.416272706882928

Epoch: 6| Step: 12
Training loss: 3.407712459564209
Validation loss: 2.423401786435035

Epoch: 6| Step: 13
Training loss: 2.166242837905884
Validation loss: 2.415088338236655

Epoch: 27| Step: 0
Training loss: 2.047513484954834
Validation loss: 2.3927915967920774

Epoch: 6| Step: 1
Training loss: 2.179753541946411
Validation loss: 2.3764560120080107

Epoch: 6| Step: 2
Training loss: 2.728635787963867
Validation loss: 2.376331724146361

Epoch: 6| Step: 3
Training loss: 2.343700885772705
Validation loss: 2.387479705195273

Epoch: 6| Step: 4
Training loss: 2.340240716934204
Validation loss: 2.413666926404481

Epoch: 6| Step: 5
Training loss: 2.6648683547973633
Validation loss: 2.439679632904709

Epoch: 6| Step: 6
Training loss: 3.2344870567321777
Validation loss: 2.442783107039749

Epoch: 6| Step: 7
Training loss: 2.6266679763793945
Validation loss: 2.4226006025909097

Epoch: 6| Step: 8
Training loss: 2.784153461456299
Validation loss: 2.403127234469178

Epoch: 6| Step: 9
Training loss: 2.8161561489105225
Validation loss: 2.3838618134939544

Epoch: 6| Step: 10
Training loss: 2.5365383625030518
Validation loss: 2.3619242791206605

Epoch: 6| Step: 11
Training loss: 2.4632725715637207
Validation loss: 2.354654524915962

Epoch: 6| Step: 12
Training loss: 3.2601661682128906
Validation loss: 2.3613163476349204

Epoch: 6| Step: 13
Training loss: 3.2547190189361572
Validation loss: 2.3572144533998225

Epoch: 28| Step: 0
Training loss: 2.81634783744812
Validation loss: 2.3652787029102282

Epoch: 6| Step: 1
Training loss: 1.881077527999878
Validation loss: 2.371162296623312

Epoch: 6| Step: 2
Training loss: 2.4781298637390137
Validation loss: 2.3776864620947067

Epoch: 6| Step: 3
Training loss: 2.937358856201172
Validation loss: 2.366322978850334

Epoch: 6| Step: 4
Training loss: 2.9608585834503174
Validation loss: 2.3685497032698763

Epoch: 6| Step: 5
Training loss: 2.8448657989501953
Validation loss: 2.3719425047597578

Epoch: 6| Step: 6
Training loss: 2.7687766551971436
Validation loss: 2.3667883616621777

Epoch: 6| Step: 7
Training loss: 2.578713893890381
Validation loss: 2.362242423078065

Epoch: 6| Step: 8
Training loss: 2.7939133644104004
Validation loss: 2.3564763120425645

Epoch: 6| Step: 9
Training loss: 2.800908327102661
Validation loss: 2.354629388419531

Epoch: 6| Step: 10
Training loss: 2.577272891998291
Validation loss: 2.353150285700316

Epoch: 6| Step: 11
Training loss: 2.269684314727783
Validation loss: 2.361372273455384

Epoch: 6| Step: 12
Training loss: 2.62312912940979
Validation loss: 2.3601342913925007

Epoch: 6| Step: 13
Training loss: 2.4195234775543213
Validation loss: 2.3597198968292563

Epoch: 29| Step: 0
Training loss: 2.7571539878845215
Validation loss: 2.3601260877424672

Epoch: 6| Step: 1
Training loss: 3.035946846008301
Validation loss: 2.3644656289008354

Epoch: 6| Step: 2
Training loss: 2.17020845413208
Validation loss: 2.3692869217165056

Epoch: 6| Step: 3
Training loss: 2.836820125579834
Validation loss: 2.372710943222046

Epoch: 6| Step: 4
Training loss: 1.4308581352233887
Validation loss: 2.3843323953690065

Epoch: 6| Step: 5
Training loss: 2.271414279937744
Validation loss: 2.3852368170215237

Epoch: 6| Step: 6
Training loss: 3.2789599895477295
Validation loss: 2.376612840160247

Epoch: 6| Step: 7
Training loss: 2.8343863487243652
Validation loss: 2.358934716511798

Epoch: 6| Step: 8
Training loss: 3.482191562652588
Validation loss: 2.3500349316545712

Epoch: 6| Step: 9
Training loss: 2.012564182281494
Validation loss: 2.3413705236168316

Epoch: 6| Step: 10
Training loss: 2.088113307952881
Validation loss: 2.345147358473911

Epoch: 6| Step: 11
Training loss: 2.831582546234131
Validation loss: 2.3409132060184272

Epoch: 6| Step: 12
Training loss: 2.6568570137023926
Validation loss: 2.3387543642392723

Epoch: 6| Step: 13
Training loss: 3.2807199954986572
Validation loss: 2.3404610490286224

Epoch: 30| Step: 0
Training loss: 2.3567681312561035
Validation loss: 2.340249599949006

Epoch: 6| Step: 1
Training loss: 3.1007938385009766
Validation loss: 2.3409515350095687

Epoch: 6| Step: 2
Training loss: 3.0872859954833984
Validation loss: 2.3426194242251817

Epoch: 6| Step: 3
Training loss: 2.4480366706848145
Validation loss: 2.343599875768026

Epoch: 6| Step: 4
Training loss: 3.0257387161254883
Validation loss: 2.3521695419024398

Epoch: 6| Step: 5
Training loss: 3.361978054046631
Validation loss: 2.3744586770252516

Epoch: 6| Step: 6
Training loss: 2.4138355255126953
Validation loss: 2.383108183901797

Epoch: 6| Step: 7
Training loss: 2.1080119609832764
Validation loss: 2.3971598737983295

Epoch: 6| Step: 8
Training loss: 2.961878776550293
Validation loss: 2.410988582077847

Epoch: 6| Step: 9
Training loss: 2.044375419616699
Validation loss: 2.392660238409555

Epoch: 6| Step: 10
Training loss: 2.3662891387939453
Validation loss: 2.3855730205453853

Epoch: 6| Step: 11
Training loss: 2.667039155960083
Validation loss: 2.3716938931454896

Epoch: 6| Step: 12
Training loss: 2.444911003112793
Validation loss: 2.351215552258235

Epoch: 6| Step: 13
Training loss: 1.7216399908065796
Validation loss: 2.3336545575049614

Epoch: 31| Step: 0
Training loss: 3.444140911102295
Validation loss: 2.322431533567367

Epoch: 6| Step: 1
Training loss: 2.327700614929199
Validation loss: 2.328025607652562

Epoch: 6| Step: 2
Training loss: 1.6296231746673584
Validation loss: 2.3349762937074066

Epoch: 6| Step: 3
Training loss: 2.5861077308654785
Validation loss: 2.3448840674533638

Epoch: 6| Step: 4
Training loss: 2.8963284492492676
Validation loss: 2.342835241748441

Epoch: 6| Step: 5
Training loss: 2.912031650543213
Validation loss: 2.336708875112636

Epoch: 6| Step: 6
Training loss: 2.1033411026000977
Validation loss: 2.329086105028788

Epoch: 6| Step: 7
Training loss: 2.857010841369629
Validation loss: 2.331089053102719

Epoch: 6| Step: 8
Training loss: 2.3791613578796387
Validation loss: 2.3533865892758934

Epoch: 6| Step: 9
Training loss: 2.696186065673828
Validation loss: 2.3565905478692826

Epoch: 6| Step: 10
Training loss: 2.820983409881592
Validation loss: 2.3467934823805288

Epoch: 6| Step: 11
Training loss: 2.876014232635498
Validation loss: 2.3522983597170923

Epoch: 6| Step: 12
Training loss: 2.914216995239258
Validation loss: 2.3564408517652944

Epoch: 6| Step: 13
Training loss: 2.206880807876587
Validation loss: 2.351782137347806

Epoch: 32| Step: 0
Training loss: 2.6527061462402344
Validation loss: 2.358465160093

Epoch: 6| Step: 1
Training loss: 2.3669378757476807
Validation loss: 2.3550622924681632

Epoch: 6| Step: 2
Training loss: 2.576106071472168
Validation loss: 2.3496851715990292

Epoch: 6| Step: 3
Training loss: 2.9606986045837402
Validation loss: 2.3438818275287585

Epoch: 6| Step: 4
Training loss: 2.550830841064453
Validation loss: 2.345511859463107

Epoch: 6| Step: 5
Training loss: 2.4042551517486572
Validation loss: 2.3478770512406544

Epoch: 6| Step: 6
Training loss: 2.569932460784912
Validation loss: 2.345413987354566

Epoch: 6| Step: 7
Training loss: 2.9653496742248535
Validation loss: 2.3471373640080935

Epoch: 6| Step: 8
Training loss: 2.5257887840270996
Validation loss: 2.3460077547257945

Epoch: 6| Step: 9
Training loss: 2.241758346557617
Validation loss: 2.359969154480965

Epoch: 6| Step: 10
Training loss: 2.1344916820526123
Validation loss: 2.379417816797892

Epoch: 6| Step: 11
Training loss: 2.795961380004883
Validation loss: 2.385052514332597

Epoch: 6| Step: 12
Training loss: 3.1183550357818604
Validation loss: 2.4008837771672074

Epoch: 6| Step: 13
Training loss: 2.8326399326324463
Validation loss: 2.4008857639887

Epoch: 33| Step: 0
Training loss: 2.731816291809082
Validation loss: 2.3705790683787358

Epoch: 6| Step: 1
Training loss: 3.3016161918640137
Validation loss: 2.3436383483230427

Epoch: 6| Step: 2
Training loss: 2.3438405990600586
Validation loss: 2.3279654197795416

Epoch: 6| Step: 3
Training loss: 2.473275661468506
Validation loss: 2.323343558978009

Epoch: 6| Step: 4
Training loss: 2.516977071762085
Validation loss: 2.3235096752002673

Epoch: 6| Step: 5
Training loss: 3.2463741302490234
Validation loss: 2.3462648007177536

Epoch: 6| Step: 6
Training loss: 2.448575735092163
Validation loss: 2.3690595678103867

Epoch: 6| Step: 7
Training loss: 2.947549343109131
Validation loss: 2.417096012382097

Epoch: 6| Step: 8
Training loss: 2.4414939880371094
Validation loss: 2.4039390317855345

Epoch: 6| Step: 9
Training loss: 3.0646159648895264
Validation loss: 2.376436802648729

Epoch: 6| Step: 10
Training loss: 2.209399938583374
Validation loss: 2.3759021041213826

Epoch: 6| Step: 11
Training loss: 2.2335243225097656
Validation loss: 2.375682084791122

Epoch: 6| Step: 12
Training loss: 2.2598018646240234
Validation loss: 2.3961285980798865

Epoch: 6| Step: 13
Training loss: 2.342939615249634
Validation loss: 2.4161487702400453

Epoch: 34| Step: 0
Training loss: 2.8964195251464844
Validation loss: 2.399650526303117

Epoch: 6| Step: 1
Training loss: 2.916158676147461
Validation loss: 2.354298622377457

Epoch: 6| Step: 2
Training loss: 2.0569705963134766
Validation loss: 2.322988228131366

Epoch: 6| Step: 3
Training loss: 2.928067684173584
Validation loss: 2.308838936590379

Epoch: 6| Step: 4
Training loss: 2.284074306488037
Validation loss: 2.312222057773221

Epoch: 6| Step: 5
Training loss: 1.6315768957138062
Validation loss: 2.3288638835312216

Epoch: 6| Step: 6
Training loss: 2.4920613765716553
Validation loss: 2.3289657126190844

Epoch: 6| Step: 7
Training loss: 3.55163311958313
Validation loss: 2.3593866773830947

Epoch: 6| Step: 8
Training loss: 2.8436717987060547
Validation loss: 2.371933324362642

Epoch: 6| Step: 9
Training loss: 2.414185047149658
Validation loss: 2.4153071154830275

Epoch: 6| Step: 10
Training loss: 2.6300835609436035
Validation loss: 2.4296563620208413

Epoch: 6| Step: 11
Training loss: 2.2117035388946533
Validation loss: 2.4066260271174933

Epoch: 6| Step: 12
Training loss: 2.7521755695343018
Validation loss: 2.3718816541856333

Epoch: 6| Step: 13
Training loss: 3.4995977878570557
Validation loss: 2.3491254006662676

Epoch: 35| Step: 0
Training loss: 1.5000265836715698
Validation loss: 2.31088008675524

Epoch: 6| Step: 1
Training loss: 2.5094997882843018
Validation loss: 2.2995398300950245

Epoch: 6| Step: 2
Training loss: 3.0981063842773438
Validation loss: 2.306451374484647

Epoch: 6| Step: 3
Training loss: 2.53452730178833
Validation loss: 2.319791083694786

Epoch: 6| Step: 4
Training loss: 2.161266565322876
Validation loss: 2.3429592399186987

Epoch: 6| Step: 5
Training loss: 2.9513847827911377
Validation loss: 2.3654044853743685

Epoch: 6| Step: 6
Training loss: 3.214771270751953
Validation loss: 2.434678254588958

Epoch: 6| Step: 7
Training loss: 2.682060956954956
Validation loss: 2.4724175494204284

Epoch: 6| Step: 8
Training loss: 2.397024393081665
Validation loss: 2.423554907562912

Epoch: 6| Step: 9
Training loss: 2.841043472290039
Validation loss: 2.3852734386280017

Epoch: 6| Step: 10
Training loss: 2.549814224243164
Validation loss: 2.3228088425051783

Epoch: 6| Step: 11
Training loss: 2.5452871322631836
Validation loss: 2.331250285589567

Epoch: 6| Step: 12
Training loss: 3.173837661743164
Validation loss: 2.3825775871994677

Epoch: 6| Step: 13
Training loss: 3.2862634658813477
Validation loss: 2.446966081537226

Epoch: 36| Step: 0
Training loss: 2.886162281036377
Validation loss: 2.4240888677617556

Epoch: 6| Step: 1
Training loss: 3.0322976112365723
Validation loss: 2.374249986422959

Epoch: 6| Step: 2
Training loss: 1.8978701829910278
Validation loss: 2.3208212955023653

Epoch: 6| Step: 3
Training loss: 2.384681463241577
Validation loss: 2.2883826417307698

Epoch: 6| Step: 4
Training loss: 2.6245670318603516
Validation loss: 2.2808798026013117

Epoch: 6| Step: 5
Training loss: 3.2969484329223633
Validation loss: 2.285017375023134

Epoch: 6| Step: 6
Training loss: 1.839796781539917
Validation loss: 2.2958073026390484

Epoch: 6| Step: 7
Training loss: 2.2381184101104736
Validation loss: 2.301733381004744

Epoch: 6| Step: 8
Training loss: 3.8605642318725586
Validation loss: 2.305603563144643

Epoch: 6| Step: 9
Training loss: 2.475562334060669
Validation loss: 2.306673639564104

Epoch: 6| Step: 10
Training loss: 2.4134676456451416
Validation loss: 2.308677593866984

Epoch: 6| Step: 11
Training loss: 2.935177803039551
Validation loss: 2.3106393378268004

Epoch: 6| Step: 12
Training loss: 2.3365752696990967
Validation loss: 2.3085414184037076

Epoch: 6| Step: 13
Training loss: 2.3019070625305176
Validation loss: 2.3058195780682307

Epoch: 37| Step: 0
Training loss: 2.6392698287963867
Validation loss: 2.2972079118092856

Epoch: 6| Step: 1
Training loss: 1.6694587469100952
Validation loss: 2.2917922978760092

Epoch: 6| Step: 2
Training loss: 3.2910587787628174
Validation loss: 2.2849083946597193

Epoch: 6| Step: 3
Training loss: 2.608241558074951
Validation loss: 2.319622201304282

Epoch: 6| Step: 4
Training loss: 2.8201990127563477
Validation loss: 2.3312348294001755

Epoch: 6| Step: 5
Training loss: 2.397469997406006
Validation loss: 2.3343220115989767

Epoch: 6| Step: 6
Training loss: 2.9496846199035645
Validation loss: 2.349033442876672

Epoch: 6| Step: 7
Training loss: 2.861767292022705
Validation loss: 2.323732383789555

Epoch: 6| Step: 8
Training loss: 2.1926162242889404
Validation loss: 2.3274409514601513

Epoch: 6| Step: 9
Training loss: 2.7003469467163086
Validation loss: 2.308663673298333

Epoch: 6| Step: 10
Training loss: 2.501433849334717
Validation loss: 2.279064523276462

Epoch: 6| Step: 11
Training loss: 2.799752712249756
Validation loss: 2.2767670487844818

Epoch: 6| Step: 12
Training loss: 2.2687735557556152
Validation loss: 2.2756840311070925

Epoch: 6| Step: 13
Training loss: 2.5784082412719727
Validation loss: 2.2720430038308583

Epoch: 38| Step: 0
Training loss: 2.6305959224700928
Validation loss: 2.276075206777101

Epoch: 6| Step: 1
Training loss: 2.942690372467041
Validation loss: 2.273346990667364

Epoch: 6| Step: 2
Training loss: 2.71466064453125
Validation loss: 2.275405999152891

Epoch: 6| Step: 3
Training loss: 2.4817681312561035
Validation loss: 2.2750070941063667

Epoch: 6| Step: 4
Training loss: 2.9416890144348145
Validation loss: 2.275751463828548

Epoch: 6| Step: 5
Training loss: 1.9738655090332031
Validation loss: 2.2717369448754097

Epoch: 6| Step: 6
Training loss: 2.4579362869262695
Validation loss: 2.2731803258260093

Epoch: 6| Step: 7
Training loss: 2.1438493728637695
Validation loss: 2.2742982423433693

Epoch: 6| Step: 8
Training loss: 2.5084495544433594
Validation loss: 2.271478742681524

Epoch: 6| Step: 9
Training loss: 2.368699073791504
Validation loss: 2.2727288840919413

Epoch: 6| Step: 10
Training loss: 2.788889169692993
Validation loss: 2.269664356785436

Epoch: 6| Step: 11
Training loss: 2.4097824096679688
Validation loss: 2.2648232624094975

Epoch: 6| Step: 12
Training loss: 2.9960227012634277
Validation loss: 2.2728151172719975

Epoch: 6| Step: 13
Training loss: 2.698847532272339
Validation loss: 2.271493483615178

Epoch: 39| Step: 0
Training loss: 2.2139813899993896
Validation loss: 2.2701924244562783

Epoch: 6| Step: 1
Training loss: 2.4204933643341064
Validation loss: 2.2677393523595666

Epoch: 6| Step: 2
Training loss: 2.8424201011657715
Validation loss: 2.267159741411927

Epoch: 6| Step: 3
Training loss: 2.9219272136688232
Validation loss: 2.268412777172622

Epoch: 6| Step: 4
Training loss: 2.9970953464508057
Validation loss: 2.2660322163694646

Epoch: 6| Step: 5
Training loss: 2.5277209281921387
Validation loss: 2.265289386113485

Epoch: 6| Step: 6
Training loss: 2.651719570159912
Validation loss: 2.2622650669467066

Epoch: 6| Step: 7
Training loss: 1.9027634859085083
Validation loss: 2.2601623868429535

Epoch: 6| Step: 8
Training loss: 2.0182225704193115
Validation loss: 2.2615969514334076

Epoch: 6| Step: 9
Training loss: 2.6821975708007812
Validation loss: 2.2617087800015687

Epoch: 6| Step: 10
Training loss: 3.0438170433044434
Validation loss: 2.2680076655521186

Epoch: 6| Step: 11
Training loss: 2.418264150619507
Validation loss: 2.2676323895813315

Epoch: 6| Step: 12
Training loss: 2.5986971855163574
Validation loss: 2.2869124104899745

Epoch: 6| Step: 13
Training loss: 2.5798330307006836
Validation loss: 2.3077328820382395

Epoch: 40| Step: 0
Training loss: 2.562865734100342
Validation loss: 2.3372666079510926

Epoch: 6| Step: 1
Training loss: 2.375152587890625
Validation loss: 2.3365248326332337

Epoch: 6| Step: 2
Training loss: 2.4615836143493652
Validation loss: 2.3314928867483653

Epoch: 6| Step: 3
Training loss: 2.1594555377960205
Validation loss: 2.330379045137795

Epoch: 6| Step: 4
Training loss: 2.706784248352051
Validation loss: 2.3158546211898967

Epoch: 6| Step: 5
Training loss: 2.2826175689697266
Validation loss: 2.29925202297908

Epoch: 6| Step: 6
Training loss: 2.013233184814453
Validation loss: 2.294847954985916

Epoch: 6| Step: 7
Training loss: 3.454352378845215
Validation loss: 2.288589818503267

Epoch: 6| Step: 8
Training loss: 2.76715350151062
Validation loss: 2.273524861181936

Epoch: 6| Step: 9
Training loss: 2.42143177986145
Validation loss: 2.2751718336536038

Epoch: 6| Step: 10
Training loss: 2.4427151679992676
Validation loss: 2.266265876831547

Epoch: 6| Step: 11
Training loss: 2.715364933013916
Validation loss: 2.2674790428530787

Epoch: 6| Step: 12
Training loss: 2.8619284629821777
Validation loss: 2.2606938680013022

Epoch: 6| Step: 13
Training loss: 2.852130651473999
Validation loss: 2.258238069472774

Epoch: 41| Step: 0
Training loss: 2.0031986236572266
Validation loss: 2.2624651667892293

Epoch: 6| Step: 1
Training loss: 3.2672476768493652
Validation loss: 2.2540329451202066

Epoch: 6| Step: 2
Training loss: 2.836430549621582
Validation loss: 2.2549739806882796

Epoch: 6| Step: 3
Training loss: 2.175537586212158
Validation loss: 2.254612292012861

Epoch: 6| Step: 4
Training loss: 3.049375057220459
Validation loss: 2.2574029404629945

Epoch: 6| Step: 5
Training loss: 2.202280044555664
Validation loss: 2.258560431900845

Epoch: 6| Step: 6
Training loss: 1.8732390403747559
Validation loss: 2.252262807661487

Epoch: 6| Step: 7
Training loss: 2.0125370025634766
Validation loss: 2.2518386276819373

Epoch: 6| Step: 8
Training loss: 3.1460843086242676
Validation loss: 2.2537963364713933

Epoch: 6| Step: 9
Training loss: 2.845355987548828
Validation loss: 2.2592064231954594

Epoch: 6| Step: 10
Training loss: 2.4801087379455566
Validation loss: 2.2625709720837173

Epoch: 6| Step: 11
Training loss: 2.8817431926727295
Validation loss: 2.2701990450582197

Epoch: 6| Step: 12
Training loss: 2.372873544692993
Validation loss: 2.2673159619813323

Epoch: 6| Step: 13
Training loss: 3.006535530090332
Validation loss: 2.2747702188389276

Epoch: 42| Step: 0
Training loss: 2.7052650451660156
Validation loss: 2.2787676498454106

Epoch: 6| Step: 1
Training loss: 2.347494125366211
Validation loss: 2.2809445435001003

Epoch: 6| Step: 2
Training loss: 2.8039932250976562
Validation loss: 2.3039470846934984

Epoch: 6| Step: 3
Training loss: 2.330808639526367
Validation loss: 2.3141657947212138

Epoch: 6| Step: 4
Training loss: 2.2319278717041016
Validation loss: 2.309121875352757

Epoch: 6| Step: 5
Training loss: 2.9428181648254395
Validation loss: 2.303519202816871

Epoch: 6| Step: 6
Training loss: 2.075082778930664
Validation loss: 2.3060170758155083

Epoch: 6| Step: 7
Training loss: 2.6665921211242676
Validation loss: 2.309248883237121

Epoch: 6| Step: 8
Training loss: 2.319650173187256
Validation loss: 2.301731260873938

Epoch: 6| Step: 9
Training loss: 1.8369472026824951
Validation loss: 2.2933450975725727

Epoch: 6| Step: 10
Training loss: 3.1090798377990723
Validation loss: 2.2704772885127733

Epoch: 6| Step: 11
Training loss: 2.946983814239502
Validation loss: 2.2698144861446914

Epoch: 6| Step: 12
Training loss: 3.1908955574035645
Validation loss: 2.26131086708397

Epoch: 6| Step: 13
Training loss: 2.1375668048858643
Validation loss: 2.2552626158601496

Epoch: 43| Step: 0
Training loss: 2.515151023864746
Validation loss: 2.2562741297547535

Epoch: 6| Step: 1
Training loss: 2.759843349456787
Validation loss: 2.250017689120385

Epoch: 6| Step: 2
Training loss: 2.3602142333984375
Validation loss: 2.2582448221022084

Epoch: 6| Step: 3
Training loss: 3.177905321121216
Validation loss: 2.2623803359206005

Epoch: 6| Step: 4
Training loss: 2.9298481941223145
Validation loss: 2.264993554802351

Epoch: 6| Step: 5
Training loss: 2.3667633533477783
Validation loss: 2.2691315194611907

Epoch: 6| Step: 6
Training loss: 1.8533270359039307
Validation loss: 2.271760276568833

Epoch: 6| Step: 7
Training loss: 2.7546024322509766
Validation loss: 2.2797491934991654

Epoch: 6| Step: 8
Training loss: 3.055133819580078
Validation loss: 2.2870330246545936

Epoch: 6| Step: 9
Training loss: 2.833348035812378
Validation loss: 2.278344746558897

Epoch: 6| Step: 10
Training loss: 2.7681479454040527
Validation loss: 2.2627217590167956

Epoch: 6| Step: 11
Training loss: 2.527585029602051
Validation loss: 2.2503442789918635

Epoch: 6| Step: 12
Training loss: 2.0087623596191406
Validation loss: 2.2464013971308225

Epoch: 6| Step: 13
Training loss: 1.2168112993240356
Validation loss: 2.2559049924214682

Epoch: 44| Step: 0
Training loss: 3.126471519470215
Validation loss: 2.262709717596731

Epoch: 6| Step: 1
Training loss: 2.361748218536377
Validation loss: 2.254286332796979

Epoch: 6| Step: 2
Training loss: 2.7333297729492188
Validation loss: 2.254661063994131

Epoch: 6| Step: 3
Training loss: 1.8967564105987549
Validation loss: 2.2488198946881037

Epoch: 6| Step: 4
Training loss: 3.0391225814819336
Validation loss: 2.2515258891608125

Epoch: 6| Step: 5
Training loss: 2.736692428588867
Validation loss: 2.2556062449691114

Epoch: 6| Step: 6
Training loss: 2.1006059646606445
Validation loss: 2.259140399194533

Epoch: 6| Step: 7
Training loss: 2.8248112201690674
Validation loss: 2.2496276901614283

Epoch: 6| Step: 8
Training loss: 2.4403481483459473
Validation loss: 2.2491277238374114

Epoch: 6| Step: 9
Training loss: 2.6048717498779297
Validation loss: 2.229490195551226

Epoch: 6| Step: 10
Training loss: 2.2416434288024902
Validation loss: 2.221446362874841

Epoch: 6| Step: 11
Training loss: 2.424344301223755
Validation loss: 2.2191904719157884

Epoch: 6| Step: 12
Training loss: 2.4846181869506836
Validation loss: 2.2293065388997397

Epoch: 6| Step: 13
Training loss: 2.5680856704711914
Validation loss: 2.2350957009100143

Epoch: 45| Step: 0
Training loss: 2.4149115085601807
Validation loss: 2.237278779347738

Epoch: 6| Step: 1
Training loss: 2.5463056564331055
Validation loss: 2.2439534112971318

Epoch: 6| Step: 2
Training loss: 2.5874593257904053
Validation loss: 2.2569770479714997

Epoch: 6| Step: 3
Training loss: 2.5090267658233643
Validation loss: 2.277061420102273

Epoch: 6| Step: 4
Training loss: 2.105771541595459
Validation loss: 2.2987056778323267

Epoch: 6| Step: 5
Training loss: 2.3776636123657227
Validation loss: 2.3050877073759675

Epoch: 6| Step: 6
Training loss: 2.0070738792419434
Validation loss: 2.305877923965454

Epoch: 6| Step: 7
Training loss: 2.474004030227661
Validation loss: 2.3051901940376527

Epoch: 6| Step: 8
Training loss: 2.7827658653259277
Validation loss: 2.2823119137876775

Epoch: 6| Step: 9
Training loss: 2.9399349689483643
Validation loss: 2.2705252080835323

Epoch: 6| Step: 10
Training loss: 2.13960599899292
Validation loss: 2.2527090810960337

Epoch: 6| Step: 11
Training loss: 2.926025152206421
Validation loss: 2.248241570688063

Epoch: 6| Step: 12
Training loss: 2.8574323654174805
Validation loss: 2.245330141436669

Epoch: 6| Step: 13
Training loss: 3.2744977474212646
Validation loss: 2.2414208227588284

Epoch: 46| Step: 0
Training loss: 2.8725013732910156
Validation loss: 2.240403941882554

Epoch: 6| Step: 1
Training loss: 2.35530948638916
Validation loss: 2.2309004645193777

Epoch: 6| Step: 2
Training loss: 1.7410368919372559
Validation loss: 2.2246740261713662

Epoch: 6| Step: 3
Training loss: 2.5264158248901367
Validation loss: 2.2296105046426096

Epoch: 6| Step: 4
Training loss: 2.5993902683258057
Validation loss: 2.2280757055487683

Epoch: 6| Step: 5
Training loss: 2.0010504722595215
Validation loss: 2.224274586605769

Epoch: 6| Step: 6
Training loss: 3.0005762577056885
Validation loss: 2.2127364745704075

Epoch: 6| Step: 7
Training loss: 2.824183702468872
Validation loss: 2.2062999202359106

Epoch: 6| Step: 8
Training loss: 2.524982452392578
Validation loss: 2.212466662929904

Epoch: 6| Step: 9
Training loss: 2.3905248641967773
Validation loss: 2.2196700701149563

Epoch: 6| Step: 10
Training loss: 3.0214791297912598
Validation loss: 2.223676577691109

Epoch: 6| Step: 11
Training loss: 2.798407554626465
Validation loss: 2.2195522349367858

Epoch: 6| Step: 12
Training loss: 2.5333545207977295
Validation loss: 2.222693876553607

Epoch: 6| Step: 13
Training loss: 2.0932202339172363
Validation loss: 2.229311978945168

Epoch: 47| Step: 0
Training loss: 2.9367401599884033
Validation loss: 2.2297810200721986

Epoch: 6| Step: 1
Training loss: 2.6293320655822754
Validation loss: 2.2377227506329938

Epoch: 6| Step: 2
Training loss: 2.4687769412994385
Validation loss: 2.226249958879204

Epoch: 6| Step: 3
Training loss: 2.1313869953155518
Validation loss: 2.2173289355411323

Epoch: 6| Step: 4
Training loss: 2.5773119926452637
Validation loss: 2.211981891303934

Epoch: 6| Step: 5
Training loss: 1.6716878414154053
Validation loss: 2.196244743562514

Epoch: 6| Step: 6
Training loss: 2.487578868865967
Validation loss: 2.191990262718611

Epoch: 6| Step: 7
Training loss: 2.0442190170288086
Validation loss: 2.193504418096235

Epoch: 6| Step: 8
Training loss: 2.615694046020508
Validation loss: 2.1897993728678715

Epoch: 6| Step: 9
Training loss: 2.6540064811706543
Validation loss: 2.204347825819446

Epoch: 6| Step: 10
Training loss: 2.237988233566284
Validation loss: 2.2007380993135515

Epoch: 6| Step: 11
Training loss: 2.401517391204834
Validation loss: 2.2082253989352973

Epoch: 6| Step: 12
Training loss: 3.4915714263916016
Validation loss: 2.2156370262945853

Epoch: 6| Step: 13
Training loss: 3.3120832443237305
Validation loss: 2.2209347537768784

Epoch: 48| Step: 0
Training loss: 2.586428165435791
Validation loss: 2.249378977283355

Epoch: 6| Step: 1
Training loss: 2.5031182765960693
Validation loss: 2.2868213217745543

Epoch: 6| Step: 2
Training loss: 2.2283387184143066
Validation loss: 2.324906623491677

Epoch: 6| Step: 3
Training loss: 2.1032323837280273
Validation loss: 2.304934800312083

Epoch: 6| Step: 4
Training loss: 2.698470115661621
Validation loss: 2.30518941725454

Epoch: 6| Step: 5
Training loss: 1.9321144819259644
Validation loss: 2.256345448955413

Epoch: 6| Step: 6
Training loss: 2.587587833404541
Validation loss: 2.222615267640801

Epoch: 6| Step: 7
Training loss: 2.344599723815918
Validation loss: 2.194088153941657

Epoch: 6| Step: 8
Training loss: 2.62850284576416
Validation loss: 2.1824183951142015

Epoch: 6| Step: 9
Training loss: 2.486186981201172
Validation loss: 2.179100318621564

Epoch: 6| Step: 10
Training loss: 3.193849563598633
Validation loss: 2.1928841657536005

Epoch: 6| Step: 11
Training loss: 2.629544734954834
Validation loss: 2.196401519160117

Epoch: 6| Step: 12
Training loss: 2.87613844871521
Validation loss: 2.1928279194780576

Epoch: 6| Step: 13
Training loss: 2.7720224857330322
Validation loss: 2.180865865881725

Epoch: 49| Step: 0
Training loss: 2.5703248977661133
Validation loss: 2.1853370820322344

Epoch: 6| Step: 1
Training loss: 1.5413237810134888
Validation loss: 2.1846625933083157

Epoch: 6| Step: 2
Training loss: 2.5059635639190674
Validation loss: 2.2010106886586835

Epoch: 6| Step: 3
Training loss: 3.264697790145874
Validation loss: 2.238823608685565

Epoch: 6| Step: 4
Training loss: 2.5136470794677734
Validation loss: 2.312252841969972

Epoch: 6| Step: 5
Training loss: 2.269765853881836
Validation loss: 2.3450151361444944

Epoch: 6| Step: 6
Training loss: 3.1328046321868896
Validation loss: 2.320933831635342

Epoch: 6| Step: 7
Training loss: 2.7877721786499023
Validation loss: 2.278242159915227

Epoch: 6| Step: 8
Training loss: 3.2052202224731445
Validation loss: 2.247336044106432

Epoch: 6| Step: 9
Training loss: 2.9103057384490967
Validation loss: 2.2149393148319696

Epoch: 6| Step: 10
Training loss: 2.4050395488739014
Validation loss: 2.2017699287783716

Epoch: 6| Step: 11
Training loss: 1.5676213502883911
Validation loss: 2.1940941682425876

Epoch: 6| Step: 12
Training loss: 2.55674409866333
Validation loss: 2.1933890247857697

Epoch: 6| Step: 13
Training loss: 2.3096156120300293
Validation loss: 2.1857782538219164

Epoch: 50| Step: 0
Training loss: 2.814436435699463
Validation loss: 2.1888857554363947

Epoch: 6| Step: 1
Training loss: 2.71755313873291
Validation loss: 2.1971961400842153

Epoch: 6| Step: 2
Training loss: 2.311938524246216
Validation loss: 2.196704376128412

Epoch: 6| Step: 3
Training loss: 2.014017105102539
Validation loss: 2.2052751664192445

Epoch: 6| Step: 4
Training loss: 2.3623995780944824
Validation loss: 2.2331292834333194

Epoch: 6| Step: 5
Training loss: 2.694589614868164
Validation loss: 2.267175579583773

Epoch: 6| Step: 6
Training loss: 2.4640841484069824
Validation loss: 2.316964626312256

Epoch: 6| Step: 7
Training loss: 2.477423667907715
Validation loss: 2.350933018551078

Epoch: 6| Step: 8
Training loss: 2.4561450481414795
Validation loss: 2.3346119567912114

Epoch: 6| Step: 9
Training loss: 2.0377297401428223
Validation loss: 2.325851830103064

Epoch: 6| Step: 10
Training loss: 3.1394834518432617
Validation loss: 2.3008943911521667

Epoch: 6| Step: 11
Training loss: 2.490985155105591
Validation loss: 2.2477894393346642

Epoch: 6| Step: 12
Training loss: 2.6544013023376465
Validation loss: 2.2123649402331282

Epoch: 6| Step: 13
Training loss: 3.11584734916687
Validation loss: 2.2037623697711575

Epoch: 51| Step: 0
Training loss: 2.5277087688446045
Validation loss: 2.2038436243610997

Epoch: 6| Step: 1
Training loss: 2.56720232963562
Validation loss: 2.2084302774039646

Epoch: 6| Step: 2
Training loss: 2.7605907917022705
Validation loss: 2.1998267865950063

Epoch: 6| Step: 3
Training loss: 3.0399386882781982
Validation loss: 2.198304686495053

Epoch: 6| Step: 4
Training loss: 2.0269274711608887
Validation loss: 2.1873244675256873

Epoch: 6| Step: 5
Training loss: 2.6496381759643555
Validation loss: 2.1855215513578026

Epoch: 6| Step: 6
Training loss: 2.4821763038635254
Validation loss: 2.172611641627486

Epoch: 6| Step: 7
Training loss: 2.2842750549316406
Validation loss: 2.1647314307510213

Epoch: 6| Step: 8
Training loss: 2.7708165645599365
Validation loss: 2.162412720341836

Epoch: 6| Step: 9
Training loss: 2.2124364376068115
Validation loss: 2.1613001643970446

Epoch: 6| Step: 10
Training loss: 2.9661881923675537
Validation loss: 2.162448740774585

Epoch: 6| Step: 11
Training loss: 2.953857898712158
Validation loss: 2.162357763577533

Epoch: 6| Step: 12
Training loss: 1.8572263717651367
Validation loss: 2.172240913555186

Epoch: 6| Step: 13
Training loss: 2.0528013706207275
Validation loss: 2.1902605448999712

Epoch: 52| Step: 0
Training loss: 1.991431474685669
Validation loss: 2.2083361507743917

Epoch: 6| Step: 1
Training loss: 3.0474140644073486
Validation loss: 2.2101254155558925

Epoch: 6| Step: 2
Training loss: 2.57228946685791
Validation loss: 2.2288450566671227

Epoch: 6| Step: 3
Training loss: 2.509688377380371
Validation loss: 2.207867337811378

Epoch: 6| Step: 4
Training loss: 2.1664652824401855
Validation loss: 2.194738572643649

Epoch: 6| Step: 5
Training loss: 2.877129554748535
Validation loss: 2.1842172145843506

Epoch: 6| Step: 6
Training loss: 2.336225986480713
Validation loss: 2.175132074663716

Epoch: 6| Step: 7
Training loss: 2.2073111534118652
Validation loss: 2.163892692135226

Epoch: 6| Step: 8
Training loss: 2.2709391117095947
Validation loss: 2.1591113575043215

Epoch: 6| Step: 9
Training loss: 2.2571935653686523
Validation loss: 2.1580434024974866

Epoch: 6| Step: 10
Training loss: 3.4103469848632812
Validation loss: 2.154503116043665

Epoch: 6| Step: 11
Training loss: 2.4722046852111816
Validation loss: 2.1573800861194568

Epoch: 6| Step: 12
Training loss: 2.67907977104187
Validation loss: 2.1535215044534333

Epoch: 6| Step: 13
Training loss: 2.492436408996582
Validation loss: 2.151845847406695

Epoch: 53| Step: 0
Training loss: 2.4471096992492676
Validation loss: 2.1571177410823044

Epoch: 6| Step: 1
Training loss: 2.4851841926574707
Validation loss: 2.1640929791235153

Epoch: 6| Step: 2
Training loss: 2.3158459663391113
Validation loss: 2.164709584687346

Epoch: 6| Step: 3
Training loss: 2.1610264778137207
Validation loss: 2.16734807209302

Epoch: 6| Step: 4
Training loss: 2.5235841274261475
Validation loss: 2.167602913354033

Epoch: 6| Step: 5
Training loss: 1.9299870729446411
Validation loss: 2.1601277435979536

Epoch: 6| Step: 6
Training loss: 2.2553281784057617
Validation loss: 2.189690710395895

Epoch: 6| Step: 7
Training loss: 2.5595779418945312
Validation loss: 2.1958863043016

Epoch: 6| Step: 8
Training loss: 2.4115896224975586
Validation loss: 2.2133104865268995

Epoch: 6| Step: 9
Training loss: 2.436190605163574
Validation loss: 2.1665335291175434

Epoch: 6| Step: 10
Training loss: 2.865403175354004
Validation loss: 2.166344242711221

Epoch: 6| Step: 11
Training loss: 2.77361798286438
Validation loss: 2.15094167699096

Epoch: 6| Step: 12
Training loss: 2.6539316177368164
Validation loss: 2.152670609053745

Epoch: 6| Step: 13
Training loss: 3.426377296447754
Validation loss: 2.1413257070766982

Epoch: 54| Step: 0
Training loss: 2.2270278930664062
Validation loss: 2.148182920230332

Epoch: 6| Step: 1
Training loss: 1.893942952156067
Validation loss: 2.1527795227625037

Epoch: 6| Step: 2
Training loss: 2.5141077041625977
Validation loss: 2.1487519523148895

Epoch: 6| Step: 3
Training loss: 2.2363789081573486
Validation loss: 2.1532959322775564

Epoch: 6| Step: 4
Training loss: 2.2014410495758057
Validation loss: 2.1403095517107236

Epoch: 6| Step: 5
Training loss: 2.621588706970215
Validation loss: 2.1282671010622414

Epoch: 6| Step: 6
Training loss: 2.810276746749878
Validation loss: 2.129314561044016

Epoch: 6| Step: 7
Training loss: 3.010768413543701
Validation loss: 2.1468959187948577

Epoch: 6| Step: 8
Training loss: 2.4605274200439453
Validation loss: 2.1472295227871148

Epoch: 6| Step: 9
Training loss: 2.666414260864258
Validation loss: 2.1589594464148245

Epoch: 6| Step: 10
Training loss: 2.804255247116089
Validation loss: 2.166750728443105

Epoch: 6| Step: 11
Training loss: 2.24969482421875
Validation loss: 2.1831193957277524

Epoch: 6| Step: 12
Training loss: 2.3366472721099854
Validation loss: 2.2028371775022118

Epoch: 6| Step: 13
Training loss: 2.6339480876922607
Validation loss: 2.2357122693010556

Epoch: 55| Step: 0
Training loss: 2.2882282733917236
Validation loss: 2.3030874780429307

Epoch: 6| Step: 1
Training loss: 3.1256091594696045
Validation loss: 2.3691733985818844

Epoch: 6| Step: 2
Training loss: 2.510678291320801
Validation loss: 2.4073522731822026

Epoch: 6| Step: 3
Training loss: 2.911344051361084
Validation loss: 2.381821278602846

Epoch: 6| Step: 4
Training loss: 3.3589682579040527
Validation loss: 2.283610833588467

Epoch: 6| Step: 5
Training loss: 2.4186506271362305
Validation loss: 2.1919525913012925

Epoch: 6| Step: 6
Training loss: 3.2782974243164062
Validation loss: 2.16566224252024

Epoch: 6| Step: 7
Training loss: 2.2556750774383545
Validation loss: 2.142085680397608

Epoch: 6| Step: 8
Training loss: 2.1316134929656982
Validation loss: 2.1297962627103253

Epoch: 6| Step: 9
Training loss: 1.8007402420043945
Validation loss: 2.1350835010569584

Epoch: 6| Step: 10
Training loss: 2.3278565406799316
Validation loss: 2.166099174048311

Epoch: 6| Step: 11
Training loss: 2.070435047149658
Validation loss: 2.1768349345012377

Epoch: 6| Step: 12
Training loss: 2.796562671661377
Validation loss: 2.2131247033355055

Epoch: 6| Step: 13
Training loss: 2.513993978500366
Validation loss: 2.182875020529634

Epoch: 56| Step: 0
Training loss: 2.8142709732055664
Validation loss: 2.1845387207564486

Epoch: 6| Step: 1
Training loss: 3.4294393062591553
Validation loss: 2.1664840534169185

Epoch: 6| Step: 2
Training loss: 2.260551929473877
Validation loss: 2.129115968622187

Epoch: 6| Step: 3
Training loss: 2.9760568141937256
Validation loss: 2.129099302394416

Epoch: 6| Step: 4
Training loss: 3.1882498264312744
Validation loss: 2.13354500134786

Epoch: 6| Step: 5
Training loss: 2.114546537399292
Validation loss: 2.134826192291834

Epoch: 6| Step: 6
Training loss: 2.2239179611206055
Validation loss: 2.142573220755464

Epoch: 6| Step: 7
Training loss: 3.033331871032715
Validation loss: 2.170275777898809

Epoch: 6| Step: 8
Training loss: 2.4685866832733154
Validation loss: 2.176046666278634

Epoch: 6| Step: 9
Training loss: 2.0002646446228027
Validation loss: 2.215316585315171

Epoch: 6| Step: 10
Training loss: 2.050940990447998
Validation loss: 2.2221833659756567

Epoch: 6| Step: 11
Training loss: 2.475212574005127
Validation loss: 2.237722732687509

Epoch: 6| Step: 12
Training loss: 1.6228128671646118
Validation loss: 2.2125426210382932

Epoch: 6| Step: 13
Training loss: 1.822804570198059
Validation loss: 2.201897482718191

Epoch: 57| Step: 0
Training loss: 3.132946491241455
Validation loss: 2.2166598253352667

Epoch: 6| Step: 1
Training loss: 2.5886707305908203
Validation loss: 2.1806722866591586

Epoch: 6| Step: 2
Training loss: 2.595170497894287
Validation loss: 2.164175498870111

Epoch: 6| Step: 3
Training loss: 2.414358377456665
Validation loss: 2.131788540911931

Epoch: 6| Step: 4
Training loss: 2.5293807983398438
Validation loss: 2.127069486084805

Epoch: 6| Step: 5
Training loss: 2.911715507507324
Validation loss: 2.1310284599181144

Epoch: 6| Step: 6
Training loss: 2.7633743286132812
Validation loss: 2.1314847059147333

Epoch: 6| Step: 7
Training loss: 2.3786206245422363
Validation loss: 2.1260801143543695

Epoch: 6| Step: 8
Training loss: 2.1370773315429688
Validation loss: 2.115414363081737

Epoch: 6| Step: 9
Training loss: 1.9008845090866089
Validation loss: 2.1199235185500114

Epoch: 6| Step: 10
Training loss: 2.4336657524108887
Validation loss: 2.1210797345766457

Epoch: 6| Step: 11
Training loss: 2.6628551483154297
Validation loss: 2.125121696020967

Epoch: 6| Step: 12
Training loss: 1.965685486793518
Validation loss: 2.137522707703293

Epoch: 6| Step: 13
Training loss: 2.2419052124023438
Validation loss: 2.168750068192841

Epoch: 58| Step: 0
Training loss: 2.792476177215576
Validation loss: 2.1968024084644933

Epoch: 6| Step: 1
Training loss: 2.7774410247802734
Validation loss: 2.2272398830741964

Epoch: 6| Step: 2
Training loss: 2.1944239139556885
Validation loss: 2.2546966998807845

Epoch: 6| Step: 3
Training loss: 2.681471824645996
Validation loss: 2.297991109150712

Epoch: 6| Step: 4
Training loss: 2.548074722290039
Validation loss: 2.26173799268661

Epoch: 6| Step: 5
Training loss: 2.7375376224517822
Validation loss: 2.232655986662834

Epoch: 6| Step: 6
Training loss: 2.4123754501342773
Validation loss: 2.1687911172066965

Epoch: 6| Step: 7
Training loss: 2.8392395973205566
Validation loss: 2.147918839608469

Epoch: 6| Step: 8
Training loss: 2.2430520057678223
Validation loss: 2.147147878523796

Epoch: 6| Step: 9
Training loss: 2.5926513671875
Validation loss: 2.1332903382598714

Epoch: 6| Step: 10
Training loss: 1.7518924474716187
Validation loss: 2.1262142786415676

Epoch: 6| Step: 11
Training loss: 2.012730360031128
Validation loss: 2.1153086718692573

Epoch: 6| Step: 12
Training loss: 2.5837297439575195
Validation loss: 2.105914336378856

Epoch: 6| Step: 13
Training loss: 2.4857091903686523
Validation loss: 2.112044225456894

Epoch: 59| Step: 0
Training loss: 2.3009698390960693
Validation loss: 2.1177995589471634

Epoch: 6| Step: 1
Training loss: 2.2720327377319336
Validation loss: 2.1167212942595124

Epoch: 6| Step: 2
Training loss: 2.5632107257843018
Validation loss: 2.1288656086050053

Epoch: 6| Step: 3
Training loss: 2.5167770385742188
Validation loss: 2.1232503947391304

Epoch: 6| Step: 4
Training loss: 2.832613229751587
Validation loss: 2.1171346415755568

Epoch: 6| Step: 5
Training loss: 2.2351112365722656
Validation loss: 2.1189842147211873

Epoch: 6| Step: 6
Training loss: 2.095078706741333
Validation loss: 2.1131824229353215

Epoch: 6| Step: 7
Training loss: 2.4490342140197754
Validation loss: 2.1202742002343618

Epoch: 6| Step: 8
Training loss: 2.632418155670166
Validation loss: 2.124852970082273

Epoch: 6| Step: 9
Training loss: 1.9551198482513428
Validation loss: 2.1332478523254395

Epoch: 6| Step: 10
Training loss: 2.4612412452697754
Validation loss: 2.152839324807608

Epoch: 6| Step: 11
Training loss: 2.6918153762817383
Validation loss: 2.1494581494280087

Epoch: 6| Step: 12
Training loss: 2.337728977203369
Validation loss: 2.1355413570198962

Epoch: 6| Step: 13
Training loss: 3.541626453399658
Validation loss: 2.1336836353425057

Epoch: 60| Step: 0
Training loss: 2.2769527435302734
Validation loss: 2.116353274673544

Epoch: 6| Step: 1
Training loss: 2.9029345512390137
Validation loss: 2.1042704812942015

Epoch: 6| Step: 2
Training loss: 3.020432949066162
Validation loss: 2.100221573665578

Epoch: 6| Step: 3
Training loss: 2.5933914184570312
Validation loss: 2.0976394376447125

Epoch: 6| Step: 4
Training loss: 2.9557108879089355
Validation loss: 2.0996678952247865

Epoch: 6| Step: 5
Training loss: 2.105274200439453
Validation loss: 2.1025888253283758

Epoch: 6| Step: 6
Training loss: 1.9708397388458252
Validation loss: 2.1008510410144763

Epoch: 6| Step: 7
Training loss: 2.5500266551971436
Validation loss: 2.104660472562236

Epoch: 6| Step: 8
Training loss: 2.5162606239318848
Validation loss: 2.1076637955122095

Epoch: 6| Step: 9
Training loss: 2.188704013824463
Validation loss: 2.1144372622172036

Epoch: 6| Step: 10
Training loss: 2.402158737182617
Validation loss: 2.1247881791924916

Epoch: 6| Step: 11
Training loss: 2.046705722808838
Validation loss: 2.1317379167003017

Epoch: 6| Step: 12
Training loss: 3.1526103019714355
Validation loss: 2.1422652659877652

Epoch: 6| Step: 13
Training loss: 1.4597904682159424
Validation loss: 2.1497831421513713

Epoch: 61| Step: 0
Training loss: 2.473557233810425
Validation loss: 2.1357494144029516

Epoch: 6| Step: 1
Training loss: 1.9857103824615479
Validation loss: 2.157475492005707

Epoch: 6| Step: 2
Training loss: 2.611618995666504
Validation loss: 2.177508787442279

Epoch: 6| Step: 3
Training loss: 2.7563118934631348
Validation loss: 2.1689152538135485

Epoch: 6| Step: 4
Training loss: 2.6756391525268555
Validation loss: 2.1772779085302867

Epoch: 6| Step: 5
Training loss: 2.6020822525024414
Validation loss: 2.1825559600707023

Epoch: 6| Step: 6
Training loss: 1.6669589281082153
Validation loss: 2.1671460649018646

Epoch: 6| Step: 7
Training loss: 1.9912781715393066
Validation loss: 2.1588766395404773

Epoch: 6| Step: 8
Training loss: 3.1065351963043213
Validation loss: 2.1474790957666214

Epoch: 6| Step: 9
Training loss: 1.9098331928253174
Validation loss: 2.1522126736179477

Epoch: 6| Step: 10
Training loss: 2.764580249786377
Validation loss: 2.136891461187793

Epoch: 6| Step: 11
Training loss: 1.9183207750320435
Validation loss: 2.1398980463704755

Epoch: 6| Step: 12
Training loss: 3.119256019592285
Validation loss: 2.1331803465402253

Epoch: 6| Step: 13
Training loss: 3.048349618911743
Validation loss: 2.1444639954515683

Epoch: 62| Step: 0
Training loss: 1.8492798805236816
Validation loss: 2.1528507919721704

Epoch: 6| Step: 1
Training loss: 1.5972874164581299
Validation loss: 2.1563470004707255

Epoch: 6| Step: 2
Training loss: 1.9590572118759155
Validation loss: 2.146604907128119

Epoch: 6| Step: 3
Training loss: 2.194516658782959
Validation loss: 2.1548982922748854

Epoch: 6| Step: 4
Training loss: 2.8280856609344482
Validation loss: 2.167950901933896

Epoch: 6| Step: 5
Training loss: 3.2344517707824707
Validation loss: 2.1524720935411352

Epoch: 6| Step: 6
Training loss: 2.5663857460021973
Validation loss: 2.130371726969237

Epoch: 6| Step: 7
Training loss: 2.9591546058654785
Validation loss: 2.122752079399683

Epoch: 6| Step: 8
Training loss: 2.364992141723633
Validation loss: 2.1044621454772128

Epoch: 6| Step: 9
Training loss: 2.507059097290039
Validation loss: 2.1087556423679477

Epoch: 6| Step: 10
Training loss: 2.6044063568115234
Validation loss: 2.0999152942370345

Epoch: 6| Step: 11
Training loss: 2.6570401191711426
Validation loss: 2.0978035080817437

Epoch: 6| Step: 12
Training loss: 2.8020219802856445
Validation loss: 2.099605667975641

Epoch: 6| Step: 13
Training loss: 1.7718898057937622
Validation loss: 2.0968025627956597

Epoch: 63| Step: 0
Training loss: 2.5399885177612305
Validation loss: 2.0970802460947344

Epoch: 6| Step: 1
Training loss: 2.8345720767974854
Validation loss: 2.096182084852649

Epoch: 6| Step: 2
Training loss: 2.793659210205078
Validation loss: 2.0950600588193504

Epoch: 6| Step: 3
Training loss: 2.4065890312194824
Validation loss: 2.087259469493743

Epoch: 6| Step: 4
Training loss: 2.1389408111572266
Validation loss: 2.0831585622602895

Epoch: 6| Step: 5
Training loss: 2.6038925647735596
Validation loss: 2.086041755573724

Epoch: 6| Step: 6
Training loss: 2.3566510677337646
Validation loss: 2.0820857529999106

Epoch: 6| Step: 7
Training loss: 2.488961696624756
Validation loss: 2.0804729307851484

Epoch: 6| Step: 8
Training loss: 2.7538206577301025
Validation loss: 2.090065808706386

Epoch: 6| Step: 9
Training loss: 2.2438902854919434
Validation loss: 2.0938269758737214

Epoch: 6| Step: 10
Training loss: 2.386164665222168
Validation loss: 2.109141367737965

Epoch: 6| Step: 11
Training loss: 1.8095486164093018
Validation loss: 2.1100597612319456

Epoch: 6| Step: 12
Training loss: 1.9848902225494385
Validation loss: 2.105187959568475

Epoch: 6| Step: 13
Training loss: 2.8267126083374023
Validation loss: 2.103201945622762

Epoch: 64| Step: 0
Training loss: 2.275599718093872
Validation loss: 2.1197235699622863

Epoch: 6| Step: 1
Training loss: 2.09838604927063
Validation loss: 2.1592020706463884

Epoch: 6| Step: 2
Training loss: 2.7224907875061035
Validation loss: 2.1873727383152133

Epoch: 6| Step: 3
Training loss: 2.814298152923584
Validation loss: 2.204828913493823

Epoch: 6| Step: 4
Training loss: 2.4655299186706543
Validation loss: 2.1813533870122765

Epoch: 6| Step: 5
Training loss: 2.2742199897766113
Validation loss: 2.149696675680017

Epoch: 6| Step: 6
Training loss: 2.58658504486084
Validation loss: 2.1089130114483576

Epoch: 6| Step: 7
Training loss: 2.110888719558716
Validation loss: 2.1088428138404764

Epoch: 6| Step: 8
Training loss: 2.307051181793213
Validation loss: 2.1124258682291996

Epoch: 6| Step: 9
Training loss: 2.091350555419922
Validation loss: 2.109932476474393

Epoch: 6| Step: 10
Training loss: 2.4970059394836426
Validation loss: 2.110637467394593

Epoch: 6| Step: 11
Training loss: 2.8546173572540283
Validation loss: 2.1141738532691874

Epoch: 6| Step: 12
Training loss: 2.1805167198181152
Validation loss: 2.11748089585253

Epoch: 6| Step: 13
Training loss: 2.9826481342315674
Validation loss: 2.1140439330890612

Epoch: 65| Step: 0
Training loss: 2.5292680263519287
Validation loss: 2.1309272550767466

Epoch: 6| Step: 1
Training loss: 2.815347909927368
Validation loss: 2.1417612478297245

Epoch: 6| Step: 2
Training loss: 2.4756691455841064
Validation loss: 2.142522668325773

Epoch: 6| Step: 3
Training loss: 2.4894986152648926
Validation loss: 2.1365694281875447

Epoch: 6| Step: 4
Training loss: 2.6988422870635986
Validation loss: 2.1356071220931185

Epoch: 6| Step: 5
Training loss: 2.5682950019836426
Validation loss: 2.132410136602258

Epoch: 6| Step: 6
Training loss: 2.0673208236694336
Validation loss: 2.1332929211278118

Epoch: 6| Step: 7
Training loss: 2.3912549018859863
Validation loss: 2.1309659070866083

Epoch: 6| Step: 8
Training loss: 2.4049477577209473
Validation loss: 2.1316689175944172

Epoch: 6| Step: 9
Training loss: 2.9543163776397705
Validation loss: 2.1446530088301627

Epoch: 6| Step: 10
Training loss: 2.307927131652832
Validation loss: 2.1337625980377197

Epoch: 6| Step: 11
Training loss: 2.2359776496887207
Validation loss: 2.1465735768759124

Epoch: 6| Step: 12
Training loss: 2.552119731903076
Validation loss: 2.1806823233122468

Epoch: 6| Step: 13
Training loss: 1.4785306453704834
Validation loss: 2.2579539027265323

Epoch: 66| Step: 0
Training loss: 2.134439468383789
Validation loss: 2.2974859719635337

Epoch: 6| Step: 1
Training loss: 2.7761120796203613
Validation loss: 2.3802184750956874

Epoch: 6| Step: 2
Training loss: 2.964475631713867
Validation loss: 2.400419158320273

Epoch: 6| Step: 3
Training loss: 2.7736120223999023
Validation loss: 2.3405517916525564

Epoch: 6| Step: 4
Training loss: 2.34187912940979
Validation loss: 2.2294104637638217

Epoch: 6| Step: 5
Training loss: 2.1838431358337402
Validation loss: 2.1261358363654024

Epoch: 6| Step: 6
Training loss: 2.484121322631836
Validation loss: 2.094712588094896

Epoch: 6| Step: 7
Training loss: 1.5921976566314697
Validation loss: 2.0694884907814766

Epoch: 6| Step: 8
Training loss: 2.5544066429138184
Validation loss: 2.0706698304863385

Epoch: 6| Step: 9
Training loss: 2.172311305999756
Validation loss: 2.067555901824787

Epoch: 6| Step: 10
Training loss: 2.3622922897338867
Validation loss: 2.0626888480237735

Epoch: 6| Step: 11
Training loss: 3.229905128479004
Validation loss: 2.0716471748967327

Epoch: 6| Step: 12
Training loss: 2.3919248580932617
Validation loss: 2.0785412916573147

Epoch: 6| Step: 13
Training loss: 2.5904617309570312
Validation loss: 2.077586850812358

Epoch: 67| Step: 0
Training loss: 1.5052005052566528
Validation loss: 2.0720262142919723

Epoch: 6| Step: 1
Training loss: 1.9808963537216187
Validation loss: 2.073583766978274

Epoch: 6| Step: 2
Training loss: 2.9898324012756348
Validation loss: 2.1063629555445846

Epoch: 6| Step: 3
Training loss: 3.0989317893981934
Validation loss: 2.1589399819732993

Epoch: 6| Step: 4
Training loss: 3.0229270458221436
Validation loss: 2.2419206147552817

Epoch: 6| Step: 5
Training loss: 3.1035518646240234
Validation loss: 2.2676095013977378

Epoch: 6| Step: 6
Training loss: 3.30290150642395
Validation loss: 2.243368996086941

Epoch: 6| Step: 7
Training loss: 1.4205808639526367
Validation loss: 2.1949403452616867

Epoch: 6| Step: 8
Training loss: 1.9679230451583862
Validation loss: 2.1596604752284225

Epoch: 6| Step: 9
Training loss: 2.6027352809906006
Validation loss: 2.1162365764699955

Epoch: 6| Step: 10
Training loss: 2.3068203926086426
Validation loss: 2.1005963484446206

Epoch: 6| Step: 11
Training loss: 1.9632467031478882
Validation loss: 2.085224299020665

Epoch: 6| Step: 12
Training loss: 2.0374855995178223
Validation loss: 2.077101110130228

Epoch: 6| Step: 13
Training loss: 3.7067630290985107
Validation loss: 2.0680269900188653

Epoch: 68| Step: 0
Training loss: 2.371181011199951
Validation loss: 2.0679890750556864

Epoch: 6| Step: 1
Training loss: 2.4375925064086914
Validation loss: 2.071900183154691

Epoch: 6| Step: 2
Training loss: 2.564824104309082
Validation loss: 2.0700416359850156

Epoch: 6| Step: 3
Training loss: 2.3175299167633057
Validation loss: 2.0674898688511183

Epoch: 6| Step: 4
Training loss: 3.1868369579315186
Validation loss: 2.069153265286517

Epoch: 6| Step: 5
Training loss: 2.3800535202026367
Validation loss: 2.066431386496431

Epoch: 6| Step: 6
Training loss: 2.8711209297180176
Validation loss: 2.0703482243322555

Epoch: 6| Step: 7
Training loss: 2.4578375816345215
Validation loss: 2.0670578864312943

Epoch: 6| Step: 8
Training loss: 2.3176519870758057
Validation loss: 2.0770949035562496

Epoch: 6| Step: 9
Training loss: 2.8932011127471924
Validation loss: 2.0997663287706274

Epoch: 6| Step: 10
Training loss: 1.8335024118423462
Validation loss: 2.1067116850165912

Epoch: 6| Step: 11
Training loss: 1.9057161808013916
Validation loss: 2.1235432470998457

Epoch: 6| Step: 12
Training loss: 2.4703116416931152
Validation loss: 2.149298316688948

Epoch: 6| Step: 13
Training loss: 1.298769235610962
Validation loss: 2.1990670004198627

Epoch: 69| Step: 0
Training loss: 2.818267345428467
Validation loss: 2.2133414617148777

Epoch: 6| Step: 1
Training loss: 2.677828311920166
Validation loss: 2.2567802449708343

Epoch: 6| Step: 2
Training loss: 1.9808988571166992
Validation loss: 2.237208133102745

Epoch: 6| Step: 3
Training loss: 2.866067886352539
Validation loss: 2.183253757415279

Epoch: 6| Step: 4
Training loss: 2.8173828125
Validation loss: 2.148027471316758

Epoch: 6| Step: 5
Training loss: 2.486905574798584
Validation loss: 2.117986963641259

Epoch: 6| Step: 6
Training loss: 3.4031167030334473
Validation loss: 2.083229602024119

Epoch: 6| Step: 7
Training loss: 2.4719271659851074
Validation loss: 2.06710894133455

Epoch: 6| Step: 8
Training loss: 1.6664977073669434
Validation loss: 2.0629945108967442

Epoch: 6| Step: 9
Training loss: 2.0583012104034424
Validation loss: 2.061777175113719

Epoch: 6| Step: 10
Training loss: 1.9671740531921387
Validation loss: 2.0644109120932956

Epoch: 6| Step: 11
Training loss: 2.351620674133301
Validation loss: 2.0541154825559227

Epoch: 6| Step: 12
Training loss: 1.9991443157196045
Validation loss: 2.063198539518541

Epoch: 6| Step: 13
Training loss: 2.0216033458709717
Validation loss: 2.0607889647124917

Epoch: 70| Step: 0
Training loss: 2.3180694580078125
Validation loss: 2.0723898269796885

Epoch: 6| Step: 1
Training loss: 2.68784761428833
Validation loss: 2.0815971564221125

Epoch: 6| Step: 2
Training loss: 3.1853244304656982
Validation loss: 2.0920497063667542

Epoch: 6| Step: 3
Training loss: 2.227720022201538
Validation loss: 2.0964350879833265

Epoch: 6| Step: 4
Training loss: 2.7878963947296143
Validation loss: 2.1050814069727415

Epoch: 6| Step: 5
Training loss: 2.1719672679901123
Validation loss: 2.118483470332238

Epoch: 6| Step: 6
Training loss: 1.9597026109695435
Validation loss: 2.121186979355351

Epoch: 6| Step: 7
Training loss: 3.248802900314331
Validation loss: 2.1397773937512468

Epoch: 6| Step: 8
Training loss: 2.2040624618530273
Validation loss: 2.164167760520853

Epoch: 6| Step: 9
Training loss: 2.2940850257873535
Validation loss: 2.1592799232852076

Epoch: 6| Step: 10
Training loss: 2.085970640182495
Validation loss: 2.13432244331606

Epoch: 6| Step: 11
Training loss: 2.3168246746063232
Validation loss: 2.1213075396835164

Epoch: 6| Step: 12
Training loss: 1.9090815782546997
Validation loss: 2.1064790833380913

Epoch: 6| Step: 13
Training loss: 2.415410280227661
Validation loss: 2.074802147444858

Epoch: 71| Step: 0
Training loss: 2.5429587364196777
Validation loss: 2.0820638620725243

Epoch: 6| Step: 1
Training loss: 2.1972503662109375
Validation loss: 2.064957650758887

Epoch: 6| Step: 2
Training loss: 2.266517162322998
Validation loss: 2.0689207789718465

Epoch: 6| Step: 3
Training loss: 2.5033411979675293
Validation loss: 2.067383381628221

Epoch: 6| Step: 4
Training loss: 1.797299861907959
Validation loss: 2.065438880715319

Epoch: 6| Step: 5
Training loss: 2.7388248443603516
Validation loss: 2.063115002006613

Epoch: 6| Step: 6
Training loss: 2.301422119140625
Validation loss: 2.057581386258525

Epoch: 6| Step: 7
Training loss: 2.364966630935669
Validation loss: 2.055689263087447

Epoch: 6| Step: 8
Training loss: 2.976016044616699
Validation loss: 2.06905544957807

Epoch: 6| Step: 9
Training loss: 2.4681782722473145
Validation loss: 2.0659877228480514

Epoch: 6| Step: 10
Training loss: 1.966801643371582
Validation loss: 2.0741559587499148

Epoch: 6| Step: 11
Training loss: 2.408428192138672
Validation loss: 2.071718212096922

Epoch: 6| Step: 12
Training loss: 2.437607526779175
Validation loss: 2.0807029534411687

Epoch: 6| Step: 13
Training loss: 2.629274606704712
Validation loss: 2.078764973148223

Epoch: 72| Step: 0
Training loss: 2.1219539642333984
Validation loss: 2.0947411034696843

Epoch: 6| Step: 1
Training loss: 1.4863920211791992
Validation loss: 2.102860604563067

Epoch: 6| Step: 2
Training loss: 1.9733641147613525
Validation loss: 2.1054316682200276

Epoch: 6| Step: 3
Training loss: 2.207368850708008
Validation loss: 2.1258843662918254

Epoch: 6| Step: 4
Training loss: 2.531693935394287
Validation loss: 2.141112853122014

Epoch: 6| Step: 5
Training loss: 2.075998067855835
Validation loss: 2.1090586390546573

Epoch: 6| Step: 6
Training loss: 2.586573600769043
Validation loss: 2.086321920476934

Epoch: 6| Step: 7
Training loss: 3.1479148864746094
Validation loss: 2.052302390016535

Epoch: 6| Step: 8
Training loss: 2.90493106842041
Validation loss: 2.0420436871949064

Epoch: 6| Step: 9
Training loss: 1.7080857753753662
Validation loss: 2.0409129768289547

Epoch: 6| Step: 10
Training loss: 2.7101335525512695
Validation loss: 2.038114604129586

Epoch: 6| Step: 11
Training loss: 2.254363536834717
Validation loss: 2.0436608035077333

Epoch: 6| Step: 12
Training loss: 3.3813977241516113
Validation loss: 2.054624704904454

Epoch: 6| Step: 13
Training loss: 3.1089301109313965
Validation loss: 2.0684249298546904

Epoch: 73| Step: 0
Training loss: 2.2259159088134766
Validation loss: 2.078520139058431

Epoch: 6| Step: 1
Training loss: 2.3171050548553467
Validation loss: 2.070822902905044

Epoch: 6| Step: 2
Training loss: 2.497407913208008
Validation loss: 2.0644995525319088

Epoch: 6| Step: 3
Training loss: 2.361774206161499
Validation loss: 2.048943127355268

Epoch: 6| Step: 4
Training loss: 2.6276257038116455
Validation loss: 2.0429208355565227

Epoch: 6| Step: 5
Training loss: 2.5869686603546143
Validation loss: 2.0305200725473385

Epoch: 6| Step: 6
Training loss: 2.2290287017822266
Validation loss: 2.036812561814503

Epoch: 6| Step: 7
Training loss: 2.8182332515716553
Validation loss: 2.0414401408164733

Epoch: 6| Step: 8
Training loss: 2.487055778503418
Validation loss: 2.0525392575930526

Epoch: 6| Step: 9
Training loss: 2.5037007331848145
Validation loss: 2.0718752491858696

Epoch: 6| Step: 10
Training loss: 2.051614761352539
Validation loss: 2.12287042474234

Epoch: 6| Step: 11
Training loss: 2.22562837600708
Validation loss: 2.1298347698744906

Epoch: 6| Step: 12
Training loss: 2.2499189376831055
Validation loss: 2.1178136910161665

Epoch: 6| Step: 13
Training loss: 3.029292106628418
Validation loss: 2.081273963374476

Epoch: 74| Step: 0
Training loss: 2.2684946060180664
Validation loss: 2.05439095599677

Epoch: 6| Step: 1
Training loss: 2.588715076446533
Validation loss: 2.0307452217225106

Epoch: 6| Step: 2
Training loss: 2.2418301105499268
Validation loss: 2.0256284923963648

Epoch: 6| Step: 3
Training loss: 2.156581163406372
Validation loss: 2.0286066788499073

Epoch: 6| Step: 4
Training loss: 2.3489575386047363
Validation loss: 2.031341596316266

Epoch: 6| Step: 5
Training loss: 1.6446810960769653
Validation loss: 2.02766764292153

Epoch: 6| Step: 6
Training loss: 2.657357692718506
Validation loss: 2.032233281802106

Epoch: 6| Step: 7
Training loss: 1.8066545724868774
Validation loss: 2.025557485959863

Epoch: 6| Step: 8
Training loss: 2.350308895111084
Validation loss: 2.0254111213068806

Epoch: 6| Step: 9
Training loss: 2.949582815170288
Validation loss: 2.0183911579911427

Epoch: 6| Step: 10
Training loss: 3.2595391273498535
Validation loss: 2.02761209523806

Epoch: 6| Step: 11
Training loss: 2.497286081314087
Validation loss: 2.0312644115058323

Epoch: 6| Step: 12
Training loss: 2.5171847343444824
Validation loss: 2.035484516492454

Epoch: 6| Step: 13
Training loss: 2.2506208419799805
Validation loss: 2.0318673733742005

Epoch: 75| Step: 0
Training loss: 1.9195914268493652
Validation loss: 2.024068529887866

Epoch: 6| Step: 1
Training loss: 2.4297635555267334
Validation loss: 2.0324662013720443

Epoch: 6| Step: 2
Training loss: 2.7420642375946045
Validation loss: 2.0471929247661302

Epoch: 6| Step: 3
Training loss: 3.261381149291992
Validation loss: 2.036278877207028

Epoch: 6| Step: 4
Training loss: 2.4786386489868164
Validation loss: 2.0486342753133466

Epoch: 6| Step: 5
Training loss: 1.4455511569976807
Validation loss: 2.055030495889725

Epoch: 6| Step: 6
Training loss: 3.1727561950683594
Validation loss: 2.070471417519354

Epoch: 6| Step: 7
Training loss: 2.1176910400390625
Validation loss: 2.0875336739324752

Epoch: 6| Step: 8
Training loss: 1.7474470138549805
Validation loss: 2.0799691241274596

Epoch: 6| Step: 9
Training loss: 2.186843156814575
Validation loss: 2.063868545716809

Epoch: 6| Step: 10
Training loss: 2.2389063835144043
Validation loss: 2.0709021424734466

Epoch: 6| Step: 11
Training loss: 2.722508430480957
Validation loss: 2.0473756226160194

Epoch: 6| Step: 12
Training loss: 2.61704158782959
Validation loss: 2.0285728823754097

Epoch: 6| Step: 13
Training loss: 1.7198772430419922
Validation loss: 2.016126384017288

Epoch: 76| Step: 0
Training loss: 1.8671256303787231
Validation loss: 2.006921932261477

Epoch: 6| Step: 1
Training loss: 2.512965679168701
Validation loss: 1.9983353640443535

Epoch: 6| Step: 2
Training loss: 2.961972951889038
Validation loss: 2.0001936317771993

Epoch: 6| Step: 3
Training loss: 2.257361888885498
Validation loss: 1.9958881152573453

Epoch: 6| Step: 4
Training loss: 2.68941593170166
Validation loss: 2.002497144924697

Epoch: 6| Step: 5
Training loss: 2.5091936588287354
Validation loss: 1.9971634803279754

Epoch: 6| Step: 6
Training loss: 2.2670693397521973
Validation loss: 2.0002819953426236

Epoch: 6| Step: 7
Training loss: 1.8239818811416626
Validation loss: 2.006293107104558

Epoch: 6| Step: 8
Training loss: 2.1328177452087402
Validation loss: 2.0051691685953448

Epoch: 6| Step: 9
Training loss: 1.9694328308105469
Validation loss: 2.0585983055894093

Epoch: 6| Step: 10
Training loss: 1.954494833946228
Validation loss: 2.0818121869076966

Epoch: 6| Step: 11
Training loss: 2.8607940673828125
Validation loss: 2.0779667515908518

Epoch: 6| Step: 12
Training loss: 2.4321987628936768
Validation loss: 2.0768008693572013

Epoch: 6| Step: 13
Training loss: 3.55092716217041
Validation loss: 2.018368832526668

Epoch: 77| Step: 0
Training loss: 2.4337077140808105
Validation loss: 2.0042668363099456

Epoch: 6| Step: 1
Training loss: 1.7935054302215576
Validation loss: 1.9916162003753006

Epoch: 6| Step: 2
Training loss: 2.1165802478790283
Validation loss: 1.9994632685056297

Epoch: 6| Step: 3
Training loss: 2.709012269973755
Validation loss: 1.9971095951654578

Epoch: 6| Step: 4
Training loss: 3.1588947772979736
Validation loss: 2.0001139230625604

Epoch: 6| Step: 5
Training loss: 2.427550792694092
Validation loss: 1.9982443201926448

Epoch: 6| Step: 6
Training loss: 1.8458707332611084
Validation loss: 1.9985121898753668

Epoch: 6| Step: 7
Training loss: 1.654747486114502
Validation loss: 2.002033172115203

Epoch: 6| Step: 8
Training loss: 3.248612403869629
Validation loss: 1.9967881697480396

Epoch: 6| Step: 9
Training loss: 2.476252555847168
Validation loss: 2.0034488298559703

Epoch: 6| Step: 10
Training loss: 2.086984634399414
Validation loss: 2.01322264312416

Epoch: 6| Step: 11
Training loss: 2.190027952194214
Validation loss: 2.034718930080373

Epoch: 6| Step: 12
Training loss: 2.529430627822876
Validation loss: 2.0483130344780545

Epoch: 6| Step: 13
Training loss: 2.536529541015625
Validation loss: 2.0517562871338217

Epoch: 78| Step: 0
Training loss: 3.019132137298584
Validation loss: 2.0453247203621814

Epoch: 6| Step: 1
Training loss: 2.525294542312622
Validation loss: 2.041384939224489

Epoch: 6| Step: 2
Training loss: 2.880476951599121
Validation loss: 2.0531623658313545

Epoch: 6| Step: 3
Training loss: 2.364198684692383
Validation loss: 2.09384141173414

Epoch: 6| Step: 4
Training loss: 2.085814952850342
Validation loss: 2.098217128425516

Epoch: 6| Step: 5
Training loss: 1.9630687236785889
Validation loss: 2.0734873381994103

Epoch: 6| Step: 6
Training loss: 2.1741199493408203
Validation loss: 2.075714588165283

Epoch: 6| Step: 7
Training loss: 1.4779300689697266
Validation loss: 2.070994620682091

Epoch: 6| Step: 8
Training loss: 2.739664316177368
Validation loss: 2.034768714699694

Epoch: 6| Step: 9
Training loss: 2.8710718154907227
Validation loss: 2.0186722586231847

Epoch: 6| Step: 10
Training loss: 2.971020221710205
Validation loss: 2.011384492279381

Epoch: 6| Step: 11
Training loss: 1.692033052444458
Validation loss: 2.007780462182978

Epoch: 6| Step: 12
Training loss: 1.9377226829528809
Validation loss: 2.000968917723625

Epoch: 6| Step: 13
Training loss: 1.9722627401351929
Validation loss: 1.9971390103781095

Epoch: 79| Step: 0
Training loss: 2.2356677055358887
Validation loss: 2.00254423515771

Epoch: 6| Step: 1
Training loss: 1.296355128288269
Validation loss: 1.9989881374502694

Epoch: 6| Step: 2
Training loss: 2.231045961380005
Validation loss: 1.994621633201517

Epoch: 6| Step: 3
Training loss: 3.0100202560424805
Validation loss: 1.9959432143037037

Epoch: 6| Step: 4
Training loss: 2.593813419342041
Validation loss: 2.0099872158419703

Epoch: 6| Step: 5
Training loss: 2.4223155975341797
Validation loss: 2.0089136964531353

Epoch: 6| Step: 6
Training loss: 2.7891125679016113
Validation loss: 2.0243402258042367

Epoch: 6| Step: 7
Training loss: 2.6482021808624268
Validation loss: 2.0432176333601757

Epoch: 6| Step: 8
Training loss: 2.888718605041504
Validation loss: 2.063989413681851

Epoch: 6| Step: 9
Training loss: 2.168545722961426
Validation loss: 2.09550045382592

Epoch: 6| Step: 10
Training loss: 2.136009693145752
Validation loss: 2.1122869240340365

Epoch: 6| Step: 11
Training loss: 1.796565055847168
Validation loss: 2.074326503661371

Epoch: 6| Step: 12
Training loss: 2.4078609943389893
Validation loss: 2.028579508104632

Epoch: 6| Step: 13
Training loss: 2.340902328491211
Validation loss: 2.0136944350375923

Epoch: 80| Step: 0
Training loss: 3.0231590270996094
Validation loss: 1.9945212435978714

Epoch: 6| Step: 1
Training loss: 2.45153546333313
Validation loss: 1.9872144088950208

Epoch: 6| Step: 2
Training loss: 3.0273213386535645
Validation loss: 1.9845620022025159

Epoch: 6| Step: 3
Training loss: 2.34335994720459
Validation loss: 1.987741301136632

Epoch: 6| Step: 4
Training loss: 1.953966498374939
Validation loss: 2.001174662702827

Epoch: 6| Step: 5
Training loss: 2.1918575763702393
Validation loss: 2.00026693267207

Epoch: 6| Step: 6
Training loss: 2.6423726081848145
Validation loss: 2.002108996914279

Epoch: 6| Step: 7
Training loss: 2.2733731269836426
Validation loss: 1.9911021135186637

Epoch: 6| Step: 8
Training loss: 2.566162109375
Validation loss: 1.9927068282199163

Epoch: 6| Step: 9
Training loss: 1.6956391334533691
Validation loss: 2.004455994534236

Epoch: 6| Step: 10
Training loss: 1.6721417903900146
Validation loss: 2.0259635756092687

Epoch: 6| Step: 11
Training loss: 2.421873092651367
Validation loss: 2.0207604131390973

Epoch: 6| Step: 12
Training loss: 2.762503147125244
Validation loss: 2.0310521228339082

Epoch: 6| Step: 13
Training loss: 1.1040738821029663
Validation loss: 2.0426296572531424

Epoch: 81| Step: 0
Training loss: 2.0764455795288086
Validation loss: 2.0562162501837618

Epoch: 6| Step: 1
Training loss: 2.738607406616211
Validation loss: 2.0708474356641053

Epoch: 6| Step: 2
Training loss: 1.698251485824585
Validation loss: 2.0601677074227283

Epoch: 6| Step: 3
Training loss: 2.6718883514404297
Validation loss: 2.0494548530988794

Epoch: 6| Step: 4
Training loss: 2.1371097564697266
Validation loss: 2.0240144639886837

Epoch: 6| Step: 5
Training loss: 1.9351959228515625
Validation loss: 2.007990194905189

Epoch: 6| Step: 6
Training loss: 2.3410072326660156
Validation loss: 2.0088169600373957

Epoch: 6| Step: 7
Training loss: 3.0428452491760254
Validation loss: 1.9942646103520547

Epoch: 6| Step: 8
Training loss: 2.3891429901123047
Validation loss: 1.994659262318765

Epoch: 6| Step: 9
Training loss: 2.4823215007781982
Validation loss: 1.9905152026043142

Epoch: 6| Step: 10
Training loss: 2.164388418197632
Validation loss: 1.9821125345845376

Epoch: 6| Step: 11
Training loss: 1.4917620420455933
Validation loss: 1.9868950510537753

Epoch: 6| Step: 12
Training loss: 3.073404550552368
Validation loss: 1.9756548763603292

Epoch: 6| Step: 13
Training loss: 2.5579299926757812
Validation loss: 1.980710829457929

Epoch: 82| Step: 0
Training loss: 1.9402225017547607
Validation loss: 1.981240149467222

Epoch: 6| Step: 1
Training loss: 2.06457257270813
Validation loss: 1.9896459964013868

Epoch: 6| Step: 2
Training loss: 2.638740301132202
Validation loss: 1.9908434703785887

Epoch: 6| Step: 3
Training loss: 2.5934267044067383
Validation loss: 1.9798246750267603

Epoch: 6| Step: 4
Training loss: 2.496969699859619
Validation loss: 1.9855859535996632

Epoch: 6| Step: 5
Training loss: 1.6359385251998901
Validation loss: 1.984916808784649

Epoch: 6| Step: 6
Training loss: 2.2949976921081543
Validation loss: 1.9854050515800394

Epoch: 6| Step: 7
Training loss: 2.9689011573791504
Validation loss: 1.9906837504397157

Epoch: 6| Step: 8
Training loss: 2.6397500038146973
Validation loss: 2.004002873615552

Epoch: 6| Step: 9
Training loss: 2.4191665649414062
Validation loss: 2.0097455337483394

Epoch: 6| Step: 10
Training loss: 2.9553403854370117
Validation loss: 1.9981625003199424

Epoch: 6| Step: 11
Training loss: 2.0164079666137695
Validation loss: 2.006324924448485

Epoch: 6| Step: 12
Training loss: 1.6363191604614258
Validation loss: 2.0004280510769097

Epoch: 6| Step: 13
Training loss: 2.1828064918518066
Validation loss: 1.9965532466929445

Epoch: 83| Step: 0
Training loss: 2.1163816452026367
Validation loss: 1.9776990875121085

Epoch: 6| Step: 1
Training loss: 2.8361082077026367
Validation loss: 1.9842652184988863

Epoch: 6| Step: 2
Training loss: 2.1676297187805176
Validation loss: 1.9873830272305397

Epoch: 6| Step: 3
Training loss: 2.707456350326538
Validation loss: 1.9934467410528531

Epoch: 6| Step: 4
Training loss: 1.277998685836792
Validation loss: 1.99533429966178

Epoch: 6| Step: 5
Training loss: 2.2546725273132324
Validation loss: 1.9868721628701815

Epoch: 6| Step: 6
Training loss: 2.4714267253875732
Validation loss: 1.9880277392684773

Epoch: 6| Step: 7
Training loss: 2.6275367736816406
Validation loss: 1.9919651733931674

Epoch: 6| Step: 8
Training loss: 1.6872462034225464
Validation loss: 1.9790240180107854

Epoch: 6| Step: 9
Training loss: 2.763162612915039
Validation loss: 1.9849059761211436

Epoch: 6| Step: 10
Training loss: 2.4231972694396973
Validation loss: 1.9878577775852655

Epoch: 6| Step: 11
Training loss: 1.958540439605713
Validation loss: 2.017440862553094

Epoch: 6| Step: 12
Training loss: 2.3148136138916016
Validation loss: 2.04609428938999

Epoch: 6| Step: 13
Training loss: 2.8865349292755127
Validation loss: 2.093843333182796

Epoch: 84| Step: 0
Training loss: 1.9415754079818726
Validation loss: 2.175571408323062

Epoch: 6| Step: 1
Training loss: 1.6783016920089722
Validation loss: 2.2114403042742

Epoch: 6| Step: 2
Training loss: 2.100554943084717
Validation loss: 2.237944669620965

Epoch: 6| Step: 3
Training loss: 2.686142921447754
Validation loss: 2.1435628142408145

Epoch: 6| Step: 4
Training loss: 1.8362466096878052
Validation loss: 2.071533218506844

Epoch: 6| Step: 5
Training loss: 3.077477216720581
Validation loss: 2.0384377330862065

Epoch: 6| Step: 6
Training loss: 3.1745994091033936
Validation loss: 2.0242802173860612

Epoch: 6| Step: 7
Training loss: 1.8733078241348267
Validation loss: 2.0194985738364597

Epoch: 6| Step: 8
Training loss: 2.6090400218963623
Validation loss: 2.0052681725512267

Epoch: 6| Step: 9
Training loss: 2.2300026416778564
Validation loss: 2.012596082943742

Epoch: 6| Step: 10
Training loss: 2.311819076538086
Validation loss: 2.0120026757640224

Epoch: 6| Step: 11
Training loss: 2.9449069499969482
Validation loss: 2.0071659805954143

Epoch: 6| Step: 12
Training loss: 2.2223429679870605
Validation loss: 2.021384431469825

Epoch: 6| Step: 13
Training loss: 2.3709874153137207
Validation loss: 2.026801287486989

Epoch: 85| Step: 0
Training loss: 2.2218241691589355
Validation loss: 2.0581845468090427

Epoch: 6| Step: 1
Training loss: 2.005939483642578
Validation loss: 2.0853881887210313

Epoch: 6| Step: 2
Training loss: 1.9384125471115112
Validation loss: 2.079994317023985

Epoch: 6| Step: 3
Training loss: 2.4100852012634277
Validation loss: 2.0575995368342244

Epoch: 6| Step: 4
Training loss: 2.5853257179260254
Validation loss: 2.0400108265620407

Epoch: 6| Step: 5
Training loss: 3.0005462169647217
Validation loss: 2.015716004115279

Epoch: 6| Step: 6
Training loss: 2.435436248779297
Validation loss: 2.0038462941364577

Epoch: 6| Step: 7
Training loss: 1.9862029552459717
Validation loss: 2.0172238196096113

Epoch: 6| Step: 8
Training loss: 2.0406229496002197
Validation loss: 2.0242823657169136

Epoch: 6| Step: 9
Training loss: 3.290616035461426
Validation loss: 2.025374061317854

Epoch: 6| Step: 10
Training loss: 1.7406870126724243
Validation loss: 2.053103866115693

Epoch: 6| Step: 11
Training loss: 1.8451942205429077
Validation loss: 2.0598495314198155

Epoch: 6| Step: 12
Training loss: 2.1548619270324707
Validation loss: 2.0657462496911325

Epoch: 6| Step: 13
Training loss: 3.3793187141418457
Validation loss: 2.0781701354570288

Epoch: 86| Step: 0
Training loss: 2.5037803649902344
Validation loss: 2.087813692708169

Epoch: 6| Step: 1
Training loss: 3.071659564971924
Validation loss: 2.0861354207479827

Epoch: 6| Step: 2
Training loss: 2.4487364292144775
Validation loss: 2.0684513097168296

Epoch: 6| Step: 3
Training loss: 2.6381568908691406
Validation loss: 2.0605308535278484

Epoch: 6| Step: 4
Training loss: 2.639346122741699
Validation loss: 2.043591389092066

Epoch: 6| Step: 5
Training loss: 2.013061761856079
Validation loss: 2.033000102607153

Epoch: 6| Step: 6
Training loss: 1.8506587743759155
Validation loss: 2.030035102239219

Epoch: 6| Step: 7
Training loss: 2.4007408618927
Validation loss: 2.054465388738981

Epoch: 6| Step: 8
Training loss: 1.8457956314086914
Validation loss: 2.0658190391396962

Epoch: 6| Step: 9
Training loss: 2.0269577503204346
Validation loss: 2.1295985996082263

Epoch: 6| Step: 10
Training loss: 2.1025657653808594
Validation loss: 2.1809424995094218

Epoch: 6| Step: 11
Training loss: 2.930868625640869
Validation loss: 2.2155363418722667

Epoch: 6| Step: 12
Training loss: 2.4543867111206055
Validation loss: 2.214426927669074

Epoch: 6| Step: 13
Training loss: 1.3126213550567627
Validation loss: 2.1398002793712

Epoch: 87| Step: 0
Training loss: 2.1078109741210938
Validation loss: 2.0313074204229538

Epoch: 6| Step: 1
Training loss: 2.096991777420044
Validation loss: 1.9964685286245039

Epoch: 6| Step: 2
Training loss: 2.6466829776763916
Validation loss: 1.955357938684443

Epoch: 6| Step: 3
Training loss: 1.766660451889038
Validation loss: 1.9627154129807667

Epoch: 6| Step: 4
Training loss: 2.5348894596099854
Validation loss: 1.9771806591300554

Epoch: 6| Step: 5
Training loss: 2.903095245361328
Validation loss: 1.9960157281608992

Epoch: 6| Step: 6
Training loss: 2.3712639808654785
Validation loss: 2.009778017638832

Epoch: 6| Step: 7
Training loss: 2.4041600227355957
Validation loss: 2.027043870700303

Epoch: 6| Step: 8
Training loss: 2.5376155376434326
Validation loss: 2.036634878445697

Epoch: 6| Step: 9
Training loss: 2.749579906463623
Validation loss: 2.027272875590991

Epoch: 6| Step: 10
Training loss: 2.7877845764160156
Validation loss: 2.010071227627416

Epoch: 6| Step: 11
Training loss: 1.996944546699524
Validation loss: 1.9934921956831408

Epoch: 6| Step: 12
Training loss: 2.1943917274475098
Validation loss: 1.9678386103722356

Epoch: 6| Step: 13
Training loss: 2.155674934387207
Validation loss: 1.9664675599785262

Epoch: 88| Step: 0
Training loss: 2.220324754714966
Validation loss: 1.9944759620133268

Epoch: 6| Step: 1
Training loss: 2.11265230178833
Validation loss: 2.0515717972991285

Epoch: 6| Step: 2
Training loss: 2.0158121585845947
Validation loss: 2.0862585004939826

Epoch: 6| Step: 3
Training loss: 2.155418872833252
Validation loss: 2.1375064888308124

Epoch: 6| Step: 4
Training loss: 2.45357084274292
Validation loss: 2.1126544898556125

Epoch: 6| Step: 5
Training loss: 2.5921201705932617
Validation loss: 2.0667718200273413

Epoch: 6| Step: 6
Training loss: 2.739771842956543
Validation loss: 2.014334713259051

Epoch: 6| Step: 7
Training loss: 1.2999519109725952
Validation loss: 1.9677461757454822

Epoch: 6| Step: 8
Training loss: 2.1493167877197266
Validation loss: 1.950113409308977

Epoch: 6| Step: 9
Training loss: 2.6488399505615234
Validation loss: 1.95351868291055

Epoch: 6| Step: 10
Training loss: 2.754237651824951
Validation loss: 1.9628036406732374

Epoch: 6| Step: 11
Training loss: 2.0475668907165527
Validation loss: 1.9668333850881106

Epoch: 6| Step: 12
Training loss: 2.764735698699951
Validation loss: 1.9994453589121501

Epoch: 6| Step: 13
Training loss: 2.507456064224243
Validation loss: 2.024679486469556

Epoch: 89| Step: 0
Training loss: 2.3338804244995117
Validation loss: 2.0597930287802093

Epoch: 6| Step: 1
Training loss: 1.8485610485076904
Validation loss: 2.1123211601729035

Epoch: 6| Step: 2
Training loss: 3.4594831466674805
Validation loss: 2.2123173962357225

Epoch: 6| Step: 3
Training loss: 2.1103873252868652
Validation loss: 2.232436833843108

Epoch: 6| Step: 4
Training loss: 2.3587074279785156
Validation loss: 2.2147165857335573

Epoch: 6| Step: 5
Training loss: 2.635395050048828
Validation loss: 2.1373328675505934

Epoch: 6| Step: 6
Training loss: 2.2224783897399902
Validation loss: 2.063826599428731

Epoch: 6| Step: 7
Training loss: 1.910706639289856
Validation loss: 2.0097143316781647

Epoch: 6| Step: 8
Training loss: 2.209057569503784
Validation loss: 1.9978814445516115

Epoch: 6| Step: 9
Training loss: 2.7637600898742676
Validation loss: 2.0364798640692108

Epoch: 6| Step: 10
Training loss: 2.2795186042785645
Validation loss: 2.094604828024423

Epoch: 6| Step: 11
Training loss: 2.8630495071411133
Validation loss: 2.1281600690657094

Epoch: 6| Step: 12
Training loss: 1.9074560403823853
Validation loss: 2.1194109493686306

Epoch: 6| Step: 13
Training loss: 2.491300344467163
Validation loss: 2.120443791471502

Epoch: 90| Step: 0
Training loss: 2.4617066383361816
Validation loss: 2.079528856021102

Epoch: 6| Step: 1
Training loss: 2.7599809169769287
Validation loss: 2.0330473735768306

Epoch: 6| Step: 2
Training loss: 1.6497703790664673
Validation loss: 1.9893323324059928

Epoch: 6| Step: 3
Training loss: 2.5243546962738037
Validation loss: 1.970068597024487

Epoch: 6| Step: 4
Training loss: 2.263678550720215
Validation loss: 1.9557505294840822

Epoch: 6| Step: 5
Training loss: 2.258767604827881
Validation loss: 1.951154101279474

Epoch: 6| Step: 6
Training loss: 2.9609427452087402
Validation loss: 1.9629066169902842

Epoch: 6| Step: 7
Training loss: 2.708894729614258
Validation loss: 2.0015130530121508

Epoch: 6| Step: 8
Training loss: 2.186176300048828
Validation loss: 2.011582712973318

Epoch: 6| Step: 9
Training loss: 2.0095067024230957
Validation loss: 2.0254695210405576

Epoch: 6| Step: 10
Training loss: 2.1033453941345215
Validation loss: 2.0397524218405447

Epoch: 6| Step: 11
Training loss: 1.8043665885925293
Validation loss: 2.032292845428631

Epoch: 6| Step: 12
Training loss: 2.380800724029541
Validation loss: 2.0238680249901226

Epoch: 6| Step: 13
Training loss: 2.160987377166748
Validation loss: 2.0085254458970923

Epoch: 91| Step: 0
Training loss: 2.2052524089813232
Validation loss: 1.9861641737722582

Epoch: 6| Step: 1
Training loss: 2.4007203578948975
Validation loss: 1.9596860485692178

Epoch: 6| Step: 2
Training loss: 2.126828670501709
Validation loss: 1.9466898108041415

Epoch: 6| Step: 3
Training loss: 2.72005033493042
Validation loss: 1.9890919693054692

Epoch: 6| Step: 4
Training loss: 2.0695929527282715
Validation loss: 2.0434119714203702

Epoch: 6| Step: 5
Training loss: 2.946537971496582
Validation loss: 2.0837349609662126

Epoch: 6| Step: 6
Training loss: 2.3057312965393066
Validation loss: 2.1163595696931243

Epoch: 6| Step: 7
Training loss: 1.7754135131835938
Validation loss: 2.1266836197145524

Epoch: 6| Step: 8
Training loss: 2.71447491645813
Validation loss: 2.159078526240523

Epoch: 6| Step: 9
Training loss: 1.9763009548187256
Validation loss: 2.1022383859080653

Epoch: 6| Step: 10
Training loss: 2.339601516723633
Validation loss: 2.086256806568433

Epoch: 6| Step: 11
Training loss: 2.759256362915039
Validation loss: 2.050171975166567

Epoch: 6| Step: 12
Training loss: 2.03511905670166
Validation loss: 1.996521537021924

Epoch: 6| Step: 13
Training loss: 2.448340892791748
Validation loss: 1.9627427260080974

Epoch: 92| Step: 0
Training loss: 2.163290500640869
Validation loss: 1.9860842458663448

Epoch: 6| Step: 1
Training loss: 2.3980774879455566
Validation loss: 2.050216387676936

Epoch: 6| Step: 2
Training loss: 2.758021354675293
Validation loss: 2.0738472246354624

Epoch: 6| Step: 3
Training loss: 1.9550344944000244
Validation loss: 2.0574292380322694

Epoch: 6| Step: 4
Training loss: 2.217928886413574
Validation loss: 2.032377282778422

Epoch: 6| Step: 5
Training loss: 1.915787935256958
Validation loss: 2.019583520068917

Epoch: 6| Step: 6
Training loss: 1.7369223833084106
Validation loss: 1.9945697579332577

Epoch: 6| Step: 7
Training loss: 2.447960376739502
Validation loss: 1.967985762062893

Epoch: 6| Step: 8
Training loss: 3.4386353492736816
Validation loss: 1.9631983375036588

Epoch: 6| Step: 9
Training loss: 1.8142799139022827
Validation loss: 1.9728220124398508

Epoch: 6| Step: 10
Training loss: 1.9713914394378662
Validation loss: 1.9776994028399069

Epoch: 6| Step: 11
Training loss: 2.552621364593506
Validation loss: 1.973785396545164

Epoch: 6| Step: 12
Training loss: 2.5587708950042725
Validation loss: 1.9737977007383942

Epoch: 6| Step: 13
Training loss: 2.4148941040039062
Validation loss: 1.9877270421674174

Epoch: 93| Step: 0
Training loss: 1.8798043727874756
Validation loss: 1.9966924908340618

Epoch: 6| Step: 1
Training loss: 2.790651321411133
Validation loss: 1.9966001818256993

Epoch: 6| Step: 2
Training loss: 2.4646782875061035
Validation loss: 1.998501153402431

Epoch: 6| Step: 3
Training loss: 2.568795680999756
Validation loss: 1.9988391937748078

Epoch: 6| Step: 4
Training loss: 2.1383118629455566
Validation loss: 2.0013882280677877

Epoch: 6| Step: 5
Training loss: 2.4307875633239746
Validation loss: 1.9844619484357937

Epoch: 6| Step: 6
Training loss: 2.614454746246338
Validation loss: 1.9875511661652596

Epoch: 6| Step: 7
Training loss: 1.9154374599456787
Validation loss: 1.9919745076087214

Epoch: 6| Step: 8
Training loss: 1.7753490209579468
Validation loss: 1.994268202012585

Epoch: 6| Step: 9
Training loss: 2.070767879486084
Validation loss: 2.007614916370761

Epoch: 6| Step: 10
Training loss: 2.695075511932373
Validation loss: 1.9936579222320228

Epoch: 6| Step: 11
Training loss: 1.897618293762207
Validation loss: 2.019119772859799

Epoch: 6| Step: 12
Training loss: 2.1263537406921387
Validation loss: 2.0154573097023913

Epoch: 6| Step: 13
Training loss: 2.179652214050293
Validation loss: 2.022378343407826

Epoch: 94| Step: 0
Training loss: 2.305068254470825
Validation loss: 2.0272100035862257

Epoch: 6| Step: 1
Training loss: 2.9516189098358154
Validation loss: 2.018671679240401

Epoch: 6| Step: 2
Training loss: 2.275606632232666
Validation loss: 2.0096322887687275

Epoch: 6| Step: 3
Training loss: 2.307100772857666
Validation loss: 2.0222858023899857

Epoch: 6| Step: 4
Training loss: 1.8693177700042725
Validation loss: 2.008599832493772

Epoch: 6| Step: 5
Training loss: 2.4086008071899414
Validation loss: 2.04088560740153

Epoch: 6| Step: 6
Training loss: 2.01076078414917
Validation loss: 2.061347570470584

Epoch: 6| Step: 7
Training loss: 1.917100429534912
Validation loss: 2.15051370282327

Epoch: 6| Step: 8
Training loss: 2.549919605255127
Validation loss: 2.184028826734071

Epoch: 6| Step: 9
Training loss: 2.596184015274048
Validation loss: 2.1950990487170476

Epoch: 6| Step: 10
Training loss: 1.5954022407531738
Validation loss: 2.1643945119714223

Epoch: 6| Step: 11
Training loss: 2.452796220779419
Validation loss: 2.107628583908081

Epoch: 6| Step: 12
Training loss: 2.776200771331787
Validation loss: 2.074302657958

Epoch: 6| Step: 13
Training loss: 2.3617208003997803
Validation loss: 2.0589225984388784

Epoch: 95| Step: 0
Training loss: 2.2291810512542725
Validation loss: 2.0388888979470856

Epoch: 6| Step: 1
Training loss: 2.7496702671051025
Validation loss: 2.0436806678771973

Epoch: 6| Step: 2
Training loss: 1.8443057537078857
Validation loss: 2.0286965139450563

Epoch: 6| Step: 3
Training loss: 2.955313205718994
Validation loss: 2.0329211142755326

Epoch: 6| Step: 4
Training loss: 2.7340168952941895
Validation loss: 2.0490731680265037

Epoch: 6| Step: 5
Training loss: 2.2071492671966553
Validation loss: 2.0662025456787436

Epoch: 6| Step: 6
Training loss: 2.43884015083313
Validation loss: 2.024602902832852

Epoch: 6| Step: 7
Training loss: 2.4116101264953613
Validation loss: 2.008623779460948

Epoch: 6| Step: 8
Training loss: 1.5376418828964233
Validation loss: 1.9866727757197555

Epoch: 6| Step: 9
Training loss: 2.0759530067443848
Validation loss: 1.9567621241333664

Epoch: 6| Step: 10
Training loss: 2.1418073177337646
Validation loss: 1.9294260548007103

Epoch: 6| Step: 11
Training loss: 2.2238211631774902
Validation loss: 1.9094274120946084

Epoch: 6| Step: 12
Training loss: 2.4421298503875732
Validation loss: 1.9178921407268894

Epoch: 6| Step: 13
Training loss: 1.9197158813476562
Validation loss: 1.9273078608256515

Epoch: 96| Step: 0
Training loss: 1.4677730798721313
Validation loss: 1.946539359707986

Epoch: 6| Step: 1
Training loss: 1.9406495094299316
Validation loss: 1.959569343956568

Epoch: 6| Step: 2
Training loss: 2.1777379512786865
Validation loss: 1.9568395204441522

Epoch: 6| Step: 3
Training loss: 2.4827921390533447
Validation loss: 1.9590708196804087

Epoch: 6| Step: 4
Training loss: 2.252824306488037
Validation loss: 1.9610880164689914

Epoch: 6| Step: 5
Training loss: 2.5328311920166016
Validation loss: 1.9348502646210373

Epoch: 6| Step: 6
Training loss: 2.5329718589782715
Validation loss: 1.9388116098219348

Epoch: 6| Step: 7
Training loss: 2.418666362762451
Validation loss: 1.937013441516507

Epoch: 6| Step: 8
Training loss: 2.4954280853271484
Validation loss: 1.9440748409558368

Epoch: 6| Step: 9
Training loss: 2.0151801109313965
Validation loss: 1.9547630189567484

Epoch: 6| Step: 10
Training loss: 2.144667863845825
Validation loss: 1.9565997713355607

Epoch: 6| Step: 11
Training loss: 2.730602264404297
Validation loss: 1.9681853414863668

Epoch: 6| Step: 12
Training loss: 2.689931869506836
Validation loss: 1.972257109098537

Epoch: 6| Step: 13
Training loss: 2.1116011142730713
Validation loss: 1.9899922263237737

Epoch: 97| Step: 0
Training loss: 1.7776238918304443
Validation loss: 1.9972209904783516

Epoch: 6| Step: 1
Training loss: 1.918843388557434
Validation loss: 1.9825256870638939

Epoch: 6| Step: 2
Training loss: 2.251926898956299
Validation loss: 1.976850219952163

Epoch: 6| Step: 3
Training loss: 2.6138429641723633
Validation loss: 1.9625502363328011

Epoch: 6| Step: 4
Training loss: 2.2043755054473877
Validation loss: 1.956895753901492

Epoch: 6| Step: 5
Training loss: 1.9929951429367065
Validation loss: 1.952473735296598

Epoch: 6| Step: 6
Training loss: 2.3069841861724854
Validation loss: 1.9659408792372672

Epoch: 6| Step: 7
Training loss: 2.364952802658081
Validation loss: 1.952847732010708

Epoch: 6| Step: 8
Training loss: 1.8743131160736084
Validation loss: 1.952039272554459

Epoch: 6| Step: 9
Training loss: 2.5590057373046875
Validation loss: 1.9429436563163676

Epoch: 6| Step: 10
Training loss: 2.9000885486602783
Validation loss: 1.9439744410976287

Epoch: 6| Step: 11
Training loss: 2.0426881313323975
Validation loss: 1.9523051938702982

Epoch: 6| Step: 12
Training loss: 2.1451849937438965
Validation loss: 1.9422568300718903

Epoch: 6| Step: 13
Training loss: 2.3322246074676514
Validation loss: 1.9407207094213015

Epoch: 98| Step: 0
Training loss: 2.872532844543457
Validation loss: 1.9474617396631548

Epoch: 6| Step: 1
Training loss: 2.263965368270874
Validation loss: 1.948827967848829

Epoch: 6| Step: 2
Training loss: 1.7019113302230835
Validation loss: 1.9509447159305695

Epoch: 6| Step: 3
Training loss: 2.02195405960083
Validation loss: 1.9552288721966486

Epoch: 6| Step: 4
Training loss: 2.2622907161712646
Validation loss: 1.9622768381590485

Epoch: 6| Step: 5
Training loss: 2.446152925491333
Validation loss: 1.972927426779142

Epoch: 6| Step: 6
Training loss: 1.7580491304397583
Validation loss: 1.9781752017236525

Epoch: 6| Step: 7
Training loss: 2.6673967838287354
Validation loss: 2.002668244864351

Epoch: 6| Step: 8
Training loss: 1.6743512153625488
Validation loss: 1.9886618609069495

Epoch: 6| Step: 9
Training loss: 2.1703124046325684
Validation loss: 1.9714783225008237

Epoch: 6| Step: 10
Training loss: 2.199563980102539
Validation loss: 1.961594230385237

Epoch: 6| Step: 11
Training loss: 2.44245982170105
Validation loss: 1.9409918708185996

Epoch: 6| Step: 12
Training loss: 2.062033176422119
Validation loss: 1.9500933103663947

Epoch: 6| Step: 13
Training loss: 2.208325147628784
Validation loss: 1.9694095926900064

Epoch: 99| Step: 0
Training loss: 2.023499011993408
Validation loss: 1.979190429051717

Epoch: 6| Step: 1
Training loss: 2.1108062267303467
Validation loss: 2.0116875799753333

Epoch: 6| Step: 2
Training loss: 2.49143385887146
Validation loss: 2.0231719734848186

Epoch: 6| Step: 3
Training loss: 2.163076877593994
Validation loss: 2.0330659317713913

Epoch: 6| Step: 4
Training loss: 3.132169485092163
Validation loss: 2.054856277281238

Epoch: 6| Step: 5
Training loss: 2.1483209133148193
Validation loss: 2.036174005077731

Epoch: 6| Step: 6
Training loss: 2.3223652839660645
Validation loss: 2.042150023163006

Epoch: 6| Step: 7
Training loss: 2.843933343887329
Validation loss: 2.051714990728645

Epoch: 6| Step: 8
Training loss: 1.9019761085510254
Validation loss: 2.0614450952058196

Epoch: 6| Step: 9
Training loss: 2.132528781890869
Validation loss: 2.0727730169091174

Epoch: 6| Step: 10
Training loss: 2.0932540893554688
Validation loss: 2.05777052141005

Epoch: 6| Step: 11
Training loss: 2.4958834648132324
Validation loss: 2.0496056015773485

Epoch: 6| Step: 12
Training loss: 1.5837733745574951
Validation loss: 2.02683122568233

Epoch: 6| Step: 13
Training loss: 1.7474124431610107
Validation loss: 2.018084572207543

Epoch: 100| Step: 0
Training loss: 2.20044207572937
Validation loss: 2.0043086210886636

Epoch: 6| Step: 1
Training loss: 1.6569013595581055
Validation loss: 2.0209946837476505

Epoch: 6| Step: 2
Training loss: 2.4832706451416016
Validation loss: 2.02911070341705

Epoch: 6| Step: 3
Training loss: 2.2567806243896484
Validation loss: 2.008006884205726

Epoch: 6| Step: 4
Training loss: 2.207122802734375
Validation loss: 1.998701375017884

Epoch: 6| Step: 5
Training loss: 2.291989803314209
Validation loss: 1.9874102941123388

Epoch: 6| Step: 6
Training loss: 1.2661893367767334
Validation loss: 1.9565841510731687

Epoch: 6| Step: 7
Training loss: 2.1888041496276855
Validation loss: 1.949151587742631

Epoch: 6| Step: 8
Training loss: 2.737837076187134
Validation loss: 1.9382987227491153

Epoch: 6| Step: 9
Training loss: 2.4457170963287354
Validation loss: 1.94688291447137

Epoch: 6| Step: 10
Training loss: 2.351198196411133
Validation loss: 1.9459870399967316

Epoch: 6| Step: 11
Training loss: 1.6323423385620117
Validation loss: 1.9631779655333488

Epoch: 6| Step: 12
Training loss: 2.7624142169952393
Validation loss: 1.975022638997724

Epoch: 6| Step: 13
Training loss: 2.588797092437744
Validation loss: 1.9907497334223923

Epoch: 101| Step: 0
Training loss: 2.9165778160095215
Validation loss: 1.97372954891574

Epoch: 6| Step: 1
Training loss: 2.060805082321167
Validation loss: 1.963919965169763

Epoch: 6| Step: 2
Training loss: 2.0029616355895996
Validation loss: 1.956697969026463

Epoch: 6| Step: 3
Training loss: 2.308206796646118
Validation loss: 1.951060712978404

Epoch: 6| Step: 4
Training loss: 1.584811806678772
Validation loss: 1.950864593187968

Epoch: 6| Step: 5
Training loss: 2.420464515686035
Validation loss: 1.9667831966953893

Epoch: 6| Step: 6
Training loss: 1.7627613544464111
Validation loss: 1.9799506356639247

Epoch: 6| Step: 7
Training loss: 2.710261344909668
Validation loss: 2.009041832339379

Epoch: 6| Step: 8
Training loss: 2.5454583168029785
Validation loss: 2.0043413113522273

Epoch: 6| Step: 9
Training loss: 1.999206781387329
Validation loss: 1.961068340527114

Epoch: 6| Step: 10
Training loss: 1.7634919881820679
Validation loss: 1.943161795216222

Epoch: 6| Step: 11
Training loss: 2.180386781692505
Validation loss: 1.9497085027797247

Epoch: 6| Step: 12
Training loss: 2.5134589672088623
Validation loss: 1.9530316937354304

Epoch: 6| Step: 13
Training loss: 1.7461591958999634
Validation loss: 1.9854783422203475

Epoch: 102| Step: 0
Training loss: 1.96000337600708
Validation loss: 2.007612748812604

Epoch: 6| Step: 1
Training loss: 1.9088026285171509
Validation loss: 1.9832239304819415

Epoch: 6| Step: 2
Training loss: 2.4988489151000977
Validation loss: 1.9790517232751335

Epoch: 6| Step: 3
Training loss: 1.7221158742904663
Validation loss: 1.9677275329507806

Epoch: 6| Step: 4
Training loss: 2.7049498558044434
Validation loss: 1.9612370896083053

Epoch: 6| Step: 5
Training loss: 1.711667776107788
Validation loss: 1.956898118859978

Epoch: 6| Step: 6
Training loss: 2.3930680751800537
Validation loss: 1.9401736477369904

Epoch: 6| Step: 7
Training loss: 1.8699045181274414
Validation loss: 1.936763677545773

Epoch: 6| Step: 8
Training loss: 1.5257160663604736
Validation loss: 1.9350478597866592

Epoch: 6| Step: 9
Training loss: 2.16105318069458
Validation loss: 1.9518103048365603

Epoch: 6| Step: 10
Training loss: 2.979518413543701
Validation loss: 1.954347123381912

Epoch: 6| Step: 11
Training loss: 2.4826643466949463
Validation loss: 1.9628902212266

Epoch: 6| Step: 12
Training loss: 2.2033157348632812
Validation loss: 1.9602273523166616

Epoch: 6| Step: 13
Training loss: 2.3614652156829834
Validation loss: 1.9678174782824773

Epoch: 103| Step: 0
Training loss: 1.9806902408599854
Validation loss: 1.9655493203029837

Epoch: 6| Step: 1
Training loss: 2.3476412296295166
Validation loss: 1.9666445460370792

Epoch: 6| Step: 2
Training loss: 2.340203285217285
Validation loss: 1.9774263405030774

Epoch: 6| Step: 3
Training loss: 2.390240430831909
Validation loss: 1.9783880044055242

Epoch: 6| Step: 4
Training loss: 2.6120309829711914
Validation loss: 1.9584180808836413

Epoch: 6| Step: 5
Training loss: 1.7756420373916626
Validation loss: 1.9540181493246427

Epoch: 6| Step: 6
Training loss: 1.330108880996704
Validation loss: 1.9698212339032082

Epoch: 6| Step: 7
Training loss: 2.817751884460449
Validation loss: 1.950227052934708

Epoch: 6| Step: 8
Training loss: 1.8751397132873535
Validation loss: 1.9559884763533069

Epoch: 6| Step: 9
Training loss: 2.714594841003418
Validation loss: 1.9468021123639998

Epoch: 6| Step: 10
Training loss: 2.066226005554199
Validation loss: 1.9416275819142659

Epoch: 6| Step: 11
Training loss: 2.3600234985351562
Validation loss: 1.9444007232624998

Epoch: 6| Step: 12
Training loss: 1.8118265867233276
Validation loss: 1.9585242720060452

Epoch: 6| Step: 13
Training loss: 1.694240927696228
Validation loss: 1.9829307294660998

Epoch: 104| Step: 0
Training loss: 2.444610595703125
Validation loss: 2.007462416925738

Epoch: 6| Step: 1
Training loss: 1.957519292831421
Validation loss: 2.06562513818023

Epoch: 6| Step: 2
Training loss: 2.2742180824279785
Validation loss: 2.0557422073938514

Epoch: 6| Step: 3
Training loss: 2.692085027694702
Validation loss: 2.0312901914760633

Epoch: 6| Step: 4
Training loss: 2.714461088180542
Validation loss: 2.0359909508817937

Epoch: 6| Step: 5
Training loss: 1.8300518989562988
Validation loss: 2.0119475459539764

Epoch: 6| Step: 6
Training loss: 2.636086940765381
Validation loss: 2.0264400487305014

Epoch: 6| Step: 7
Training loss: 2.0893657207489014
Validation loss: 2.0075583252855527

Epoch: 6| Step: 8
Training loss: 1.775282621383667
Validation loss: 1.972970688214866

Epoch: 6| Step: 9
Training loss: 1.8017675876617432
Validation loss: 1.9492693511388635

Epoch: 6| Step: 10
Training loss: 1.6947815418243408
Validation loss: 1.9641046139501757

Epoch: 6| Step: 11
Training loss: 1.795019268989563
Validation loss: 1.9831286784141295

Epoch: 6| Step: 12
Training loss: 2.219277858734131
Validation loss: 1.999949929534748

Epoch: 6| Step: 13
Training loss: 2.366157293319702
Validation loss: 2.048848996880234

Epoch: 105| Step: 0
Training loss: 2.4567036628723145
Validation loss: 2.093586128245118

Epoch: 6| Step: 1
Training loss: 2.737335681915283
Validation loss: 2.0969163064033753

Epoch: 6| Step: 2
Training loss: 2.5177221298217773
Validation loss: 2.0671164669016355

Epoch: 6| Step: 3
Training loss: 1.5307749509811401
Validation loss: 2.021097530600845

Epoch: 6| Step: 4
Training loss: 2.577287197113037
Validation loss: 1.9755364335993284

Epoch: 6| Step: 5
Training loss: 1.7748157978057861
Validation loss: 1.9411499372092627

Epoch: 6| Step: 6
Training loss: 2.211225748062134
Validation loss: 1.9231841974360968

Epoch: 6| Step: 7
Training loss: 2.59255051612854
Validation loss: 1.9464044391468007

Epoch: 6| Step: 8
Training loss: 2.955453395843506
Validation loss: 1.9760057208358601

Epoch: 6| Step: 9
Training loss: 1.7289228439331055
Validation loss: 1.992181380589803

Epoch: 6| Step: 10
Training loss: 2.3973474502563477
Validation loss: 1.9990998570637037

Epoch: 6| Step: 11
Training loss: 1.8973102569580078
Validation loss: 1.9795427642842776

Epoch: 6| Step: 12
Training loss: 1.6283807754516602
Validation loss: 1.939050418074413

Epoch: 6| Step: 13
Training loss: 2.467878580093384
Validation loss: 1.9302849115863923

Epoch: 106| Step: 0
Training loss: 2.059718608856201
Validation loss: 1.941737167296871

Epoch: 6| Step: 1
Training loss: 2.5162487030029297
Validation loss: 1.9360377673179872

Epoch: 6| Step: 2
Training loss: 2.3656790256500244
Validation loss: 1.9644193508291756

Epoch: 6| Step: 3
Training loss: 1.9377700090408325
Validation loss: 1.954617505432457

Epoch: 6| Step: 4
Training loss: 2.2292327880859375
Validation loss: 1.959412964441443

Epoch: 6| Step: 5
Training loss: 2.6560261249542236
Validation loss: 1.9602127946833128

Epoch: 6| Step: 6
Training loss: 1.9600309133529663
Validation loss: 1.991043206184141

Epoch: 6| Step: 7
Training loss: 2.2082407474517822
Validation loss: 2.0566077616906937

Epoch: 6| Step: 8
Training loss: 1.5040886402130127
Validation loss: 2.0769513755716305

Epoch: 6| Step: 9
Training loss: 2.5814342498779297
Validation loss: 2.1604349126097975

Epoch: 6| Step: 10
Training loss: 2.3850488662719727
Validation loss: 2.1500961293456373

Epoch: 6| Step: 11
Training loss: 2.04168701171875
Validation loss: 2.0393416189378306

Epoch: 6| Step: 12
Training loss: 1.878498911857605
Validation loss: 1.9702127595101633

Epoch: 6| Step: 13
Training loss: 1.7482719421386719
Validation loss: 1.9601617115800098

Epoch: 107| Step: 0
Training loss: 1.8676726818084717
Validation loss: 1.959691483487365

Epoch: 6| Step: 1
Training loss: 2.810922622680664
Validation loss: 1.9659092887755363

Epoch: 6| Step: 2
Training loss: 1.8240509033203125
Validation loss: 1.9849767351663241

Epoch: 6| Step: 3
Training loss: 2.532196283340454
Validation loss: 1.9802045668325117

Epoch: 6| Step: 4
Training loss: 2.869110584259033
Validation loss: 1.9680536805942495

Epoch: 6| Step: 5
Training loss: 1.9917833805084229
Validation loss: 1.9386175640167729

Epoch: 6| Step: 6
Training loss: 2.3729336261749268
Validation loss: 1.9254178218944098

Epoch: 6| Step: 7
Training loss: 2.103771924972534
Validation loss: 1.9095080924290482

Epoch: 6| Step: 8
Training loss: 2.082618474960327
Validation loss: 1.9129071799657678

Epoch: 6| Step: 9
Training loss: 2.4662070274353027
Validation loss: 1.9105415997966644

Epoch: 6| Step: 10
Training loss: 2.2147512435913086
Validation loss: 1.9224892265053206

Epoch: 6| Step: 11
Training loss: 1.676692008972168
Validation loss: 1.9347070237641693

Epoch: 6| Step: 12
Training loss: 1.6689447164535522
Validation loss: 1.9554508527119954

Epoch: 6| Step: 13
Training loss: 2.2572431564331055
Validation loss: 1.9732751205403318

Epoch: 108| Step: 0
Training loss: 2.722733974456787
Validation loss: 1.9634217369940974

Epoch: 6| Step: 1
Training loss: 1.8625209331512451
Validation loss: 1.9575729190662343

Epoch: 6| Step: 2
Training loss: 1.504197597503662
Validation loss: 1.990223269308767

Epoch: 6| Step: 3
Training loss: 2.2848706245422363
Validation loss: 2.0092507088056175

Epoch: 6| Step: 4
Training loss: 1.5604066848754883
Validation loss: 2.0330236727191555

Epoch: 6| Step: 5
Training loss: 1.4194039106369019
Validation loss: 2.037837933468562

Epoch: 6| Step: 6
Training loss: 2.5239622592926025
Validation loss: 2.0206452018471173

Epoch: 6| Step: 7
Training loss: 2.7481062412261963
Validation loss: 2.009635010073262

Epoch: 6| Step: 8
Training loss: 1.3535343408584595
Validation loss: 2.0190268819050123

Epoch: 6| Step: 9
Training loss: 2.0020430088043213
Validation loss: 2.0205331284512758

Epoch: 6| Step: 10
Training loss: 2.5003154277801514
Validation loss: 2.0439654524608324

Epoch: 6| Step: 11
Training loss: 2.6475071907043457
Validation loss: 2.028168275792112

Epoch: 6| Step: 12
Training loss: 1.8017783164978027
Validation loss: 2.0274354744982976

Epoch: 6| Step: 13
Training loss: 3.7199795246124268
Validation loss: 1.9834640385002218

Epoch: 109| Step: 0
Training loss: 2.191694974899292
Validation loss: 1.9944972761215702

Epoch: 6| Step: 1
Training loss: 2.053234577178955
Validation loss: 1.982346139928346

Epoch: 6| Step: 2
Training loss: 1.9860185384750366
Validation loss: 1.9856272666685042

Epoch: 6| Step: 3
Training loss: 2.216444730758667
Validation loss: 1.9769398909743114

Epoch: 6| Step: 4
Training loss: 1.4937763214111328
Validation loss: 1.9812622301040157

Epoch: 6| Step: 5
Training loss: 2.9776177406311035
Validation loss: 1.9928611375952279

Epoch: 6| Step: 6
Training loss: 2.122713088989258
Validation loss: 1.9934952489791378

Epoch: 6| Step: 7
Training loss: 1.969895362854004
Validation loss: 1.983076375017884

Epoch: 6| Step: 8
Training loss: 1.9534430503845215
Validation loss: 1.9983746902917021

Epoch: 6| Step: 9
Training loss: 1.6894580125808716
Validation loss: 2.0143459035504248

Epoch: 6| Step: 10
Training loss: 1.967444658279419
Validation loss: 2.004478757099439

Epoch: 6| Step: 11
Training loss: 1.514235019683838
Validation loss: 1.9744866535227785

Epoch: 6| Step: 12
Training loss: 3.0088753700256348
Validation loss: 1.977889342974591

Epoch: 6| Step: 13
Training loss: 3.39397931098938
Validation loss: 1.9713008160232215

Epoch: 110| Step: 0
Training loss: 1.8186049461364746
Validation loss: 1.9705764555162

Epoch: 6| Step: 1
Training loss: 2.769629955291748
Validation loss: 1.94835231765624

Epoch: 6| Step: 2
Training loss: 2.020106077194214
Validation loss: 1.9650243533554899

Epoch: 6| Step: 3
Training loss: 2.7364501953125
Validation loss: 1.975174037359094

Epoch: 6| Step: 4
Training loss: 2.119971513748169
Validation loss: 1.9813428822384085

Epoch: 6| Step: 5
Training loss: 2.052090883255005
Validation loss: 1.9857479423604987

Epoch: 6| Step: 6
Training loss: 1.675238013267517
Validation loss: 1.9708751709230485

Epoch: 6| Step: 7
Training loss: 2.2628190517425537
Validation loss: 1.950460721087712

Epoch: 6| Step: 8
Training loss: 2.1704790592193604
Validation loss: 1.943496657956031

Epoch: 6| Step: 9
Training loss: 2.122880220413208
Validation loss: 1.9168255418859503

Epoch: 6| Step: 10
Training loss: 2.186680555343628
Validation loss: 1.9305378595987956

Epoch: 6| Step: 11
Training loss: 1.4556419849395752
Validation loss: 1.9670088496259464

Epoch: 6| Step: 12
Training loss: 2.112959861755371
Validation loss: 2.0182737381227556

Epoch: 6| Step: 13
Training loss: 2.626203775405884
Validation loss: 2.1046188595474407

Epoch: 111| Step: 0
Training loss: 1.6400713920593262
Validation loss: 2.136061688905121

Epoch: 6| Step: 1
Training loss: 3.048006057739258
Validation loss: 2.1458657069872786

Epoch: 6| Step: 2
Training loss: 2.1308658123016357
Validation loss: 2.1369708276564077

Epoch: 6| Step: 3
Training loss: 2.2890443801879883
Validation loss: 2.06543908580657

Epoch: 6| Step: 4
Training loss: 1.8868485689163208
Validation loss: 2.0210545575746925

Epoch: 6| Step: 5
Training loss: 1.7945444583892822
Validation loss: 1.9681106946801628

Epoch: 6| Step: 6
Training loss: 2.228097438812256
Validation loss: 1.938300814679874

Epoch: 6| Step: 7
Training loss: 2.2189700603485107
Validation loss: 1.9456539730871878

Epoch: 6| Step: 8
Training loss: 1.8114041090011597
Validation loss: 1.9389961624658236

Epoch: 6| Step: 9
Training loss: 2.1826281547546387
Validation loss: 1.9393886276470718

Epoch: 6| Step: 10
Training loss: 2.016512393951416
Validation loss: 1.9458724760240125

Epoch: 6| Step: 11
Training loss: 2.064828395843506
Validation loss: 1.9302117901463662

Epoch: 6| Step: 12
Training loss: 1.950285792350769
Validation loss: 1.9218010376858454

Epoch: 6| Step: 13
Training loss: 3.090121269226074
Validation loss: 1.934521198272705

Epoch: 112| Step: 0
Training loss: 1.8425917625427246
Validation loss: 1.9155802521654355

Epoch: 6| Step: 1
Training loss: 1.630064845085144
Validation loss: 1.9222189213639946

Epoch: 6| Step: 2
Training loss: 1.8070077896118164
Validation loss: 1.9458489828212286

Epoch: 6| Step: 3
Training loss: 1.9204645156860352
Validation loss: 1.9532766419072305

Epoch: 6| Step: 4
Training loss: 2.695340871810913
Validation loss: 1.9782449224943757

Epoch: 6| Step: 5
Training loss: 2.4924421310424805
Validation loss: 1.969143606001331

Epoch: 6| Step: 6
Training loss: 2.882411241531372
Validation loss: 1.9518275671107794

Epoch: 6| Step: 7
Training loss: 2.3119258880615234
Validation loss: 1.9416795212735412

Epoch: 6| Step: 8
Training loss: 1.8119577169418335
Validation loss: 1.9477781813631776

Epoch: 6| Step: 9
Training loss: 2.0971927642822266
Validation loss: 1.9113449229989001

Epoch: 6| Step: 10
Training loss: 2.3510005474090576
Validation loss: 1.9211219254360403

Epoch: 6| Step: 11
Training loss: 2.320385456085205
Validation loss: 1.927753830468783

Epoch: 6| Step: 12
Training loss: 1.6796362400054932
Validation loss: 1.934747588249945

Epoch: 6| Step: 13
Training loss: 1.3203343152999878
Validation loss: 1.9449625899714809

Epoch: 113| Step: 0
Training loss: 2.096039295196533
Validation loss: 1.9499924259801065

Epoch: 6| Step: 1
Training loss: 1.7982265949249268
Validation loss: 1.9663252548504901

Epoch: 6| Step: 2
Training loss: 1.9117977619171143
Validation loss: 1.9961778143400788

Epoch: 6| Step: 3
Training loss: 2.443859100341797
Validation loss: 2.0022217637749127

Epoch: 6| Step: 4
Training loss: 2.2672533988952637
Validation loss: 2.0035535186849613

Epoch: 6| Step: 5
Training loss: 1.8809843063354492
Validation loss: 2.0145293948470906

Epoch: 6| Step: 6
Training loss: 2.031869888305664
Validation loss: 1.9800260746350853

Epoch: 6| Step: 7
Training loss: 1.664548635482788
Validation loss: 1.9722464123079855

Epoch: 6| Step: 8
Training loss: 2.477550983428955
Validation loss: 1.9693713777808732

Epoch: 6| Step: 9
Training loss: 2.5322067737579346
Validation loss: 1.9605486316065635

Epoch: 6| Step: 10
Training loss: 1.484600305557251
Validation loss: 1.9562103568866689

Epoch: 6| Step: 11
Training loss: 2.5865511894226074
Validation loss: 1.9407957882009528

Epoch: 6| Step: 12
Training loss: 2.201272964477539
Validation loss: 1.927017440078079

Epoch: 6| Step: 13
Training loss: 2.1785197257995605
Validation loss: 1.9290649390989734

Epoch: 114| Step: 0
Training loss: 2.5852599143981934
Validation loss: 1.9327632791252547

Epoch: 6| Step: 1
Training loss: 2.0014114379882812
Validation loss: 1.9240845736636911

Epoch: 6| Step: 2
Training loss: 1.8510583639144897
Validation loss: 1.9253950234382384

Epoch: 6| Step: 3
Training loss: 2.222200393676758
Validation loss: 1.9601283970699515

Epoch: 6| Step: 4
Training loss: 2.0753066539764404
Validation loss: 1.9357950149043914

Epoch: 6| Step: 5
Training loss: 1.787384033203125
Validation loss: 1.923724869246124

Epoch: 6| Step: 6
Training loss: 2.0423312187194824
Validation loss: 1.9202104242899085

Epoch: 6| Step: 7
Training loss: 2.327547550201416
Validation loss: 1.921288497986332

Epoch: 6| Step: 8
Training loss: 2.1944029331207275
Validation loss: 1.9203695020368021

Epoch: 6| Step: 9
Training loss: 1.960649013519287
Validation loss: 1.9240167140960693

Epoch: 6| Step: 10
Training loss: 1.9529329538345337
Validation loss: 1.9254676039500902

Epoch: 6| Step: 11
Training loss: 2.237879991531372
Validation loss: 1.9805076981103549

Epoch: 6| Step: 12
Training loss: 1.9044115543365479
Validation loss: 1.9940857964177285

Epoch: 6| Step: 13
Training loss: 1.9205502271652222
Validation loss: 2.003579972892679

Epoch: 115| Step: 0
Training loss: 2.068091869354248
Validation loss: 1.9919868617929437

Epoch: 6| Step: 1
Training loss: 2.0451152324676514
Validation loss: 1.9766826770638908

Epoch: 6| Step: 2
Training loss: 2.4737133979797363
Validation loss: 1.9499177035465036

Epoch: 6| Step: 3
Training loss: 2.4879181385040283
Validation loss: 1.983915453316063

Epoch: 6| Step: 4
Training loss: 1.7671773433685303
Validation loss: 2.0056215742582917

Epoch: 6| Step: 5
Training loss: 2.1535489559173584
Validation loss: 2.0172460053556707

Epoch: 6| Step: 6
Training loss: 1.591944932937622
Validation loss: 2.0262354753350698

Epoch: 6| Step: 7
Training loss: 1.9633264541625977
Validation loss: 2.033739956476355

Epoch: 6| Step: 8
Training loss: 1.8311342000961304
Validation loss: 2.0578014645525204

Epoch: 6| Step: 9
Training loss: 1.738957166671753
Validation loss: 2.0722136600043184

Epoch: 6| Step: 10
Training loss: 2.238480806350708
Validation loss: 2.088836375103202

Epoch: 6| Step: 11
Training loss: 1.9491232633590698
Validation loss: 2.0844249879160235

Epoch: 6| Step: 12
Training loss: 2.3221359252929688
Validation loss: 2.040299993689342

Epoch: 6| Step: 13
Training loss: 2.4075708389282227
Validation loss: 2.0236052992523357

Epoch: 116| Step: 0
Training loss: 2.143026828765869
Validation loss: 1.995083635853183

Epoch: 6| Step: 1
Training loss: 1.9943652153015137
Validation loss: 1.9822836665696995

Epoch: 6| Step: 2
Training loss: 2.3305463790893555
Validation loss: 1.9917135007919804

Epoch: 6| Step: 3
Training loss: 2.434821128845215
Validation loss: 1.9790019066103044

Epoch: 6| Step: 4
Training loss: 2.102114677429199
Validation loss: 1.9476530295546337

Epoch: 6| Step: 5
Training loss: 2.08418869972229
Validation loss: 1.9479996670958817

Epoch: 6| Step: 6
Training loss: 1.6750197410583496
Validation loss: 1.9463914568706224

Epoch: 6| Step: 7
Training loss: 2.0723516941070557
Validation loss: 1.9391014063230125

Epoch: 6| Step: 8
Training loss: 2.217207431793213
Validation loss: 1.9195011495262064

Epoch: 6| Step: 9
Training loss: 1.990776538848877
Validation loss: 1.921754821654289

Epoch: 6| Step: 10
Training loss: 2.0740256309509277
Validation loss: 1.9155153292481617

Epoch: 6| Step: 11
Training loss: 2.5082316398620605
Validation loss: 1.9159098338055354

Epoch: 6| Step: 12
Training loss: 1.4605869054794312
Validation loss: 1.9033195998079033

Epoch: 6| Step: 13
Training loss: 1.4302374124526978
Validation loss: 1.9221827394218856

Epoch: 117| Step: 0
Training loss: 2.2621262073516846
Validation loss: 1.9186985543979111

Epoch: 6| Step: 1
Training loss: 2.097681760787964
Validation loss: 1.9428301716363559

Epoch: 6| Step: 2
Training loss: 1.7177749872207642
Validation loss: 1.939846832265136

Epoch: 6| Step: 3
Training loss: 2.2153191566467285
Validation loss: 1.9405264290430213

Epoch: 6| Step: 4
Training loss: 1.687401533126831
Validation loss: 1.9147785889205111

Epoch: 6| Step: 5
Training loss: 2.067917823791504
Validation loss: 1.9597708115013697

Epoch: 6| Step: 6
Training loss: 2.138152599334717
Validation loss: 1.964595804932297

Epoch: 6| Step: 7
Training loss: 2.20419979095459
Validation loss: 1.9534097730472524

Epoch: 6| Step: 8
Training loss: 2.1008167266845703
Validation loss: 1.966207427363242

Epoch: 6| Step: 9
Training loss: 1.937395691871643
Validation loss: 1.9787884848092192

Epoch: 6| Step: 10
Training loss: 2.0150704383850098
Validation loss: 2.047502061372162

Epoch: 6| Step: 11
Training loss: 2.2585859298706055
Validation loss: 2.1256850842506654

Epoch: 6| Step: 12
Training loss: 1.6923587322235107
Validation loss: 2.161884264279437

Epoch: 6| Step: 13
Training loss: 2.415842056274414
Validation loss: 2.1715724070866904

Epoch: 118| Step: 0
Training loss: 1.6180763244628906
Validation loss: 2.033504621956938

Epoch: 6| Step: 1
Training loss: 2.0241217613220215
Validation loss: 1.9358921358662267

Epoch: 6| Step: 2
Training loss: 1.6154910326004028
Validation loss: 1.9230312762721893

Epoch: 6| Step: 3
Training loss: 1.584106683731079
Validation loss: 1.9753421468119468

Epoch: 6| Step: 4
Training loss: 2.886944532394409
Validation loss: 2.0416176601122786

Epoch: 6| Step: 5
Training loss: 2.794102668762207
Validation loss: 2.0742643699851087

Epoch: 6| Step: 6
Training loss: 2.0604913234710693
Validation loss: 2.0953761095641763

Epoch: 6| Step: 7
Training loss: 2.570894718170166
Validation loss: 2.069735819293607

Epoch: 6| Step: 8
Training loss: 2.3964414596557617
Validation loss: 1.9922915594552153

Epoch: 6| Step: 9
Training loss: 2.4425253868103027
Validation loss: 1.897411968118401

Epoch: 6| Step: 10
Training loss: 2.389772891998291
Validation loss: 1.8612053291772002

Epoch: 6| Step: 11
Training loss: 1.884212851524353
Validation loss: 1.8802665741212907

Epoch: 6| Step: 12
Training loss: 2.1371798515319824
Validation loss: 1.8795009402818577

Epoch: 6| Step: 13
Training loss: 2.513732433319092
Validation loss: 1.8881576638067923

Epoch: 119| Step: 0
Training loss: 2.176740884780884
Validation loss: 1.8854699160463066

Epoch: 6| Step: 1
Training loss: 2.318247079849243
Validation loss: 1.8921394719872424

Epoch: 6| Step: 2
Training loss: 1.7410738468170166
Validation loss: 1.926949733047075

Epoch: 6| Step: 3
Training loss: 2.098158597946167
Validation loss: 1.9200057701397968

Epoch: 6| Step: 4
Training loss: 2.4016075134277344
Validation loss: 1.945859065619848

Epoch: 6| Step: 5
Training loss: 2.402235984802246
Validation loss: 1.975668768728933

Epoch: 6| Step: 6
Training loss: 2.2558887004852295
Validation loss: 2.022929831217694

Epoch: 6| Step: 7
Training loss: 1.928626537322998
Validation loss: 2.024897736887778

Epoch: 6| Step: 8
Training loss: 2.677055835723877
Validation loss: 2.0188178657203593

Epoch: 6| Step: 9
Training loss: 1.8212262392044067
Validation loss: 2.0187352575281614

Epoch: 6| Step: 10
Training loss: 1.9231096506118774
Validation loss: 2.042475429914331

Epoch: 6| Step: 11
Training loss: 1.853625774383545
Validation loss: 2.0696341888878935

Epoch: 6| Step: 12
Training loss: 1.5374478101730347
Validation loss: 2.0836783814173874

Epoch: 6| Step: 13
Training loss: 2.053584098815918
Validation loss: 2.06021406573634

Epoch: 120| Step: 0
Training loss: 1.986295461654663
Validation loss: 2.0315849575945126

Epoch: 6| Step: 1
Training loss: 1.4142076969146729
Validation loss: 2.027221231050389

Epoch: 6| Step: 2
Training loss: 2.2311835289001465
Validation loss: 2.003650939592751

Epoch: 6| Step: 3
Training loss: 2.0931243896484375
Validation loss: 1.9795451997428812

Epoch: 6| Step: 4
Training loss: 2.44331431388855
Validation loss: 1.9510060638509772

Epoch: 6| Step: 5
Training loss: 1.4869062900543213
Validation loss: 1.9558521586079751

Epoch: 6| Step: 6
Training loss: 2.804229259490967
Validation loss: 1.9695128112710931

Epoch: 6| Step: 7
Training loss: 2.2325692176818848
Validation loss: 1.9527174900936823

Epoch: 6| Step: 8
Training loss: 1.847279667854309
Validation loss: 1.922666270245788

Epoch: 6| Step: 9
Training loss: 2.196319341659546
Validation loss: 1.9387213978716122

Epoch: 6| Step: 10
Training loss: 2.165224552154541
Validation loss: 1.9223721834921068

Epoch: 6| Step: 11
Training loss: 1.1050069332122803
Validation loss: 1.9208863845435522

Epoch: 6| Step: 12
Training loss: 2.169541358947754
Validation loss: 1.9180821180343628

Epoch: 6| Step: 13
Training loss: 1.8089817762374878
Validation loss: 1.9264560437971545

Epoch: 121| Step: 0
Training loss: 1.4470851421356201
Validation loss: 1.9204727218997093

Epoch: 6| Step: 1
Training loss: 1.734184980392456
Validation loss: 1.934796889623006

Epoch: 6| Step: 2
Training loss: 1.8947795629501343
Validation loss: 1.975449485163535

Epoch: 6| Step: 3
Training loss: 1.5033860206604004
Validation loss: 1.9690896388023131

Epoch: 6| Step: 4
Training loss: 2.1564712524414062
Validation loss: 1.984906704195084

Epoch: 6| Step: 5
Training loss: 1.814385175704956
Validation loss: 1.9895678002347228

Epoch: 6| Step: 6
Training loss: 2.4048938751220703
Validation loss: 2.0000736200681297

Epoch: 6| Step: 7
Training loss: 2.463107109069824
Validation loss: 2.0088260686525734

Epoch: 6| Step: 8
Training loss: 1.9555456638336182
Validation loss: 1.9932071521718016

Epoch: 6| Step: 9
Training loss: 2.477187395095825
Validation loss: 1.974949570112331

Epoch: 6| Step: 10
Training loss: 1.8975015878677368
Validation loss: 1.976896152701429

Epoch: 6| Step: 11
Training loss: 1.9602230787277222
Validation loss: 1.9652599198843843

Epoch: 6| Step: 12
Training loss: 2.4100489616394043
Validation loss: 1.955894995761174

Epoch: 6| Step: 13
Training loss: 1.8328232765197754
Validation loss: 1.934508963297772

Epoch: 122| Step: 0
Training loss: 2.0895516872406006
Validation loss: 1.9375359332689674

Epoch: 6| Step: 1
Training loss: 1.986267328262329
Validation loss: 2.03083368783356

Epoch: 6| Step: 2
Training loss: 1.9705209732055664
Validation loss: 2.2471531052743234

Epoch: 6| Step: 3
Training loss: 2.2239842414855957
Validation loss: 2.3823430922723587

Epoch: 6| Step: 4
Training loss: 2.2574169635772705
Validation loss: 2.3010301077237694

Epoch: 6| Step: 5
Training loss: 1.7910395860671997
Validation loss: 2.1588274599403463

Epoch: 6| Step: 6
Training loss: 2.595364809036255
Validation loss: 1.9804686961635467

Epoch: 6| Step: 7
Training loss: 2.7322025299072266
Validation loss: 1.9035855262510237

Epoch: 6| Step: 8
Training loss: 2.2844908237457275
Validation loss: 1.8597836699537051

Epoch: 6| Step: 9
Training loss: 2.41978120803833
Validation loss: 1.8673443204613143

Epoch: 6| Step: 10
Training loss: 1.9723390340805054
Validation loss: 1.9123336063918246

Epoch: 6| Step: 11
Training loss: 1.5214130878448486
Validation loss: 1.9443013078422957

Epoch: 6| Step: 12
Training loss: 1.841967225074768
Validation loss: 1.9425182470711329

Epoch: 6| Step: 13
Training loss: 1.7660737037658691
Validation loss: 1.927360761550165

Epoch: 123| Step: 0
Training loss: 1.875100016593933
Validation loss: 1.9076200736466276

Epoch: 6| Step: 1
Training loss: 1.667653203010559
Validation loss: 1.8915907259910338

Epoch: 6| Step: 2
Training loss: 1.830951452255249
Validation loss: 1.8660034428360641

Epoch: 6| Step: 3
Training loss: 2.2859647274017334
Validation loss: 1.8573987663433116

Epoch: 6| Step: 4
Training loss: 1.532173991203308
Validation loss: 1.8322391702282814

Epoch: 6| Step: 5
Training loss: 2.1616621017456055
Validation loss: 1.838737500611172

Epoch: 6| Step: 6
Training loss: 2.5754776000976562
Validation loss: 1.8623848756154378

Epoch: 6| Step: 7
Training loss: 2.339017391204834
Validation loss: 1.8723644338628298

Epoch: 6| Step: 8
Training loss: 2.1647114753723145
Validation loss: 1.8898512624925183

Epoch: 6| Step: 9
Training loss: 2.2839159965515137
Validation loss: 1.9195273307061964

Epoch: 6| Step: 10
Training loss: 2.2645325660705566
Validation loss: 1.928496999125327

Epoch: 6| Step: 11
Training loss: 2.318132162094116
Validation loss: 1.9411866921250538

Epoch: 6| Step: 12
Training loss: 1.8579246997833252
Validation loss: 1.9350769750533565

Epoch: 6| Step: 13
Training loss: 2.949305534362793
Validation loss: 1.9533585758619412

Epoch: 124| Step: 0
Training loss: 2.0799355506896973
Validation loss: 1.9322180606985604

Epoch: 6| Step: 1
Training loss: 1.5156311988830566
Validation loss: 1.9260424080715384

Epoch: 6| Step: 2
Training loss: 1.6725943088531494
Validation loss: 1.9485489578657254

Epoch: 6| Step: 3
Training loss: 1.7286220788955688
Validation loss: 1.927978705334407

Epoch: 6| Step: 4
Training loss: 1.9006123542785645
Validation loss: 1.9474876132062686

Epoch: 6| Step: 5
Training loss: 1.9636962413787842
Validation loss: 1.9750494316060057

Epoch: 6| Step: 6
Training loss: 2.054445743560791
Validation loss: 1.9933781726385957

Epoch: 6| Step: 7
Training loss: 2.2309961318969727
Validation loss: 2.03303442206434

Epoch: 6| Step: 8
Training loss: 1.8919435739517212
Validation loss: 2.0458197747507403

Epoch: 6| Step: 9
Training loss: 2.7357516288757324
Validation loss: 2.035738855279902

Epoch: 6| Step: 10
Training loss: 2.575617790222168
Validation loss: 2.0534739801960606

Epoch: 6| Step: 11
Training loss: 1.3968772888183594
Validation loss: 2.0548055633421867

Epoch: 6| Step: 12
Training loss: 2.2751617431640625
Validation loss: 2.0538386785855858

Epoch: 6| Step: 13
Training loss: 1.879265308380127
Validation loss: 2.0465682462979387

Epoch: 125| Step: 0
Training loss: 1.9499239921569824
Validation loss: 2.046960469215147

Epoch: 6| Step: 1
Training loss: 2.0485215187072754
Validation loss: 2.033328094790059

Epoch: 6| Step: 2
Training loss: 2.428579330444336
Validation loss: 2.0441600866215204

Epoch: 6| Step: 3
Training loss: 2.1445019245147705
Validation loss: 2.0751253430561354

Epoch: 6| Step: 4
Training loss: 2.4427108764648438
Validation loss: 2.0678692274196173

Epoch: 6| Step: 5
Training loss: 1.4438823461532593
Validation loss: 2.0172506404179398

Epoch: 6| Step: 6
Training loss: 1.6399818658828735
Validation loss: 1.9363640790344567

Epoch: 6| Step: 7
Training loss: 1.7930595874786377
Validation loss: 1.8847263102890344

Epoch: 6| Step: 8
Training loss: 2.4209847450256348
Validation loss: 1.8700705920496294

Epoch: 6| Step: 9
Training loss: 1.9969420433044434
Validation loss: 1.8761743742932555

Epoch: 6| Step: 10
Training loss: 2.343327522277832
Validation loss: 1.8780965574326054

Epoch: 6| Step: 11
Training loss: 1.6090116500854492
Validation loss: 1.8691993759524437

Epoch: 6| Step: 12
Training loss: 1.7350939512252808
Validation loss: 1.8733673787886096

Epoch: 6| Step: 13
Training loss: 2.749413251876831
Validation loss: 1.8570802263034287

Epoch: 126| Step: 0
Training loss: 1.795973300933838
Validation loss: 1.8662563652120612

Epoch: 6| Step: 1
Training loss: 1.812620997428894
Validation loss: 1.8739086145995765

Epoch: 6| Step: 2
Training loss: 1.8215174674987793
Validation loss: 1.9043235586535545

Epoch: 6| Step: 3
Training loss: 2.2068238258361816
Validation loss: 1.9376585163095945

Epoch: 6| Step: 4
Training loss: 2.2080299854278564
Validation loss: 1.9555058120399393

Epoch: 6| Step: 5
Training loss: 2.2577576637268066
Validation loss: 1.951517415303056

Epoch: 6| Step: 6
Training loss: 1.5927531719207764
Validation loss: 1.9504685171188847

Epoch: 6| Step: 7
Training loss: 1.453026294708252
Validation loss: 1.9388364899543025

Epoch: 6| Step: 8
Training loss: 2.203244686126709
Validation loss: 1.9354801716343049

Epoch: 6| Step: 9
Training loss: 2.0908939838409424
Validation loss: 1.927357994100099

Epoch: 6| Step: 10
Training loss: 2.2999727725982666
Validation loss: 1.9203652630570114

Epoch: 6| Step: 11
Training loss: 1.8009448051452637
Validation loss: 1.919149932040963

Epoch: 6| Step: 12
Training loss: 1.4567781686782837
Validation loss: 1.9485063988675353

Epoch: 6| Step: 13
Training loss: 2.78729248046875
Validation loss: 1.9484397160109652

Epoch: 127| Step: 0
Training loss: 2.095897674560547
Validation loss: 1.9610351670172907

Epoch: 6| Step: 1
Training loss: 1.8668569326400757
Validation loss: 1.983739519631991

Epoch: 6| Step: 2
Training loss: 2.171164035797119
Validation loss: 2.0086501772685716

Epoch: 6| Step: 3
Training loss: 1.4707740545272827
Validation loss: 2.0266351340919413

Epoch: 6| Step: 4
Training loss: 2.2722220420837402
Validation loss: 2.033636854540917

Epoch: 6| Step: 5
Training loss: 1.5864040851593018
Validation loss: 2.0428680425049155

Epoch: 6| Step: 6
Training loss: 2.6443939208984375
Validation loss: 2.040417153348205

Epoch: 6| Step: 7
Training loss: 1.6633715629577637
Validation loss: 2.0449313284248434

Epoch: 6| Step: 8
Training loss: 1.8904205560684204
Validation loss: 2.0367737559862036

Epoch: 6| Step: 9
Training loss: 2.2683990001678467
Validation loss: 2.029488722483317

Epoch: 6| Step: 10
Training loss: 1.6307766437530518
Validation loss: 2.013596273237659

Epoch: 6| Step: 11
Training loss: 1.5405422449111938
Validation loss: 1.9909651663995558

Epoch: 6| Step: 12
Training loss: 2.2669448852539062
Validation loss: 1.9603430366003385

Epoch: 6| Step: 13
Training loss: 2.3419554233551025
Validation loss: 1.9573229666679137

Epoch: 128| Step: 0
Training loss: 1.977349877357483
Validation loss: 1.9244475621049122

Epoch: 6| Step: 1
Training loss: 1.3471763134002686
Validation loss: 1.9265198002579391

Epoch: 6| Step: 2
Training loss: 1.9360883235931396
Validation loss: 1.9126412855681552

Epoch: 6| Step: 3
Training loss: 1.8600335121154785
Validation loss: 1.9075073324224001

Epoch: 6| Step: 4
Training loss: 2.192983388900757
Validation loss: 1.9115175329228884

Epoch: 6| Step: 5
Training loss: 1.6722421646118164
Validation loss: 1.912761462632046

Epoch: 6| Step: 6
Training loss: 2.412909984588623
Validation loss: 1.927250200702298

Epoch: 6| Step: 7
Training loss: 2.19313383102417
Validation loss: 1.9158907077645744

Epoch: 6| Step: 8
Training loss: 2.4220478534698486
Validation loss: 1.918142666098892

Epoch: 6| Step: 9
Training loss: 1.9021886587142944
Validation loss: 1.9233959182616203

Epoch: 6| Step: 10
Training loss: 1.3641694784164429
Validation loss: 1.9239114292206303

Epoch: 6| Step: 11
Training loss: 2.355029582977295
Validation loss: 1.9372536315712878

Epoch: 6| Step: 12
Training loss: 1.6215696334838867
Validation loss: 1.9542119926021946

Epoch: 6| Step: 13
Training loss: 1.476439356803894
Validation loss: 1.9751858224150955

Epoch: 129| Step: 0
Training loss: 2.3539772033691406
Validation loss: 1.9786464885998798

Epoch: 6| Step: 1
Training loss: 1.7848066091537476
Validation loss: 2.0013042111550607

Epoch: 6| Step: 2
Training loss: 1.285048007965088
Validation loss: 2.0317694551201275

Epoch: 6| Step: 3
Training loss: 1.9650765657424927
Validation loss: 2.0373171388462024

Epoch: 6| Step: 4
Training loss: 2.5932509899139404
Validation loss: 2.0641352873976513

Epoch: 6| Step: 5
Training loss: 2.136953592300415
Validation loss: 2.0901061822009344

Epoch: 6| Step: 6
Training loss: 1.315352201461792
Validation loss: 2.0732154769282185

Epoch: 6| Step: 7
Training loss: 0.9835336804389954
Validation loss: 2.046859889902094

Epoch: 6| Step: 8
Training loss: 1.7474974393844604
Validation loss: 2.0335391106144076

Epoch: 6| Step: 9
Training loss: 2.309811592102051
Validation loss: 1.9881094014772804

Epoch: 6| Step: 10
Training loss: 1.8482006788253784
Validation loss: 1.952559894131076

Epoch: 6| Step: 11
Training loss: 2.5410614013671875
Validation loss: 1.9385381052570958

Epoch: 6| Step: 12
Training loss: 1.293541431427002
Validation loss: 1.9085818157401135

Epoch: 6| Step: 13
Training loss: 2.446341037750244
Validation loss: 1.8882792457457511

Epoch: 130| Step: 0
Training loss: 0.9785120487213135
Validation loss: 1.8814563238492577

Epoch: 6| Step: 1
Training loss: 1.6327458620071411
Validation loss: 1.8933660035492272

Epoch: 6| Step: 2
Training loss: 2.3051841259002686
Validation loss: 1.916280391395733

Epoch: 6| Step: 3
Training loss: 2.1465559005737305
Validation loss: 1.919507634255194

Epoch: 6| Step: 4
Training loss: 1.4617202281951904
Validation loss: 1.9418851406343522

Epoch: 6| Step: 5
Training loss: 2.6466033458709717
Validation loss: 1.9466182262666765

Epoch: 6| Step: 6
Training loss: 1.760814905166626
Validation loss: 1.9639547076276553

Epoch: 6| Step: 7
Training loss: 1.9402889013290405
Validation loss: 1.9248968657626901

Epoch: 6| Step: 8
Training loss: 1.0743882656097412
Validation loss: 1.9413584406657884

Epoch: 6| Step: 9
Training loss: 2.2108616828918457
Validation loss: 1.9396355869949504

Epoch: 6| Step: 10
Training loss: 2.4178552627563477
Validation loss: 1.9289695293672624

Epoch: 6| Step: 11
Training loss: 2.0342912673950195
Validation loss: 1.9376058014490272

Epoch: 6| Step: 12
Training loss: 1.8915882110595703
Validation loss: 1.928220623282976

Epoch: 6| Step: 13
Training loss: 3.023085594177246
Validation loss: 1.9529794813484274

Epoch: 131| Step: 0
Training loss: 2.043421745300293
Validation loss: 1.9690843320661975

Epoch: 6| Step: 1
Training loss: 1.830304741859436
Validation loss: 1.990557450120167

Epoch: 6| Step: 2
Training loss: 1.2565672397613525
Validation loss: 1.9959404481354581

Epoch: 6| Step: 3
Training loss: 1.6703617572784424
Validation loss: 2.050122348211145

Epoch: 6| Step: 4
Training loss: 2.253732681274414
Validation loss: 2.1156139040506012

Epoch: 6| Step: 5
Training loss: 2.146193027496338
Validation loss: 2.1537515835095475

Epoch: 6| Step: 6
Training loss: 2.824267864227295
Validation loss: 2.1841907834493988

Epoch: 6| Step: 7
Training loss: 2.3326077461242676
Validation loss: 2.200586352297055

Epoch: 6| Step: 8
Training loss: 2.651806116104126
Validation loss: 2.117122583491828

Epoch: 6| Step: 9
Training loss: 2.12998366355896
Validation loss: 2.0413744667524933

Epoch: 6| Step: 10
Training loss: 1.1826802492141724
Validation loss: 2.0144185763533398

Epoch: 6| Step: 11
Training loss: 1.9066942930221558
Validation loss: 2.0275285513170305

Epoch: 6| Step: 12
Training loss: 1.693572759628296
Validation loss: 2.043158964444232

Epoch: 6| Step: 13
Training loss: 2.1558570861816406
Validation loss: 2.075528114072738

Epoch: 132| Step: 0
Training loss: 1.5412827730178833
Validation loss: 2.0643401453571935

Epoch: 6| Step: 1
Training loss: 1.521549940109253
Validation loss: 2.0200594163710073

Epoch: 6| Step: 2
Training loss: 2.072774648666382
Validation loss: 2.011389519578667

Epoch: 6| Step: 3
Training loss: 2.0836355686187744
Validation loss: 1.9999186223553074

Epoch: 6| Step: 4
Training loss: 2.0292625427246094
Validation loss: 2.025964621574648

Epoch: 6| Step: 5
Training loss: 2.4707350730895996
Validation loss: 2.0918023355545534

Epoch: 6| Step: 6
Training loss: 1.8613262176513672
Validation loss: 2.196165907767511

Epoch: 6| Step: 7
Training loss: 2.405956983566284
Validation loss: 2.2828308689978813

Epoch: 6| Step: 8
Training loss: 2.1529273986816406
Validation loss: 2.190492114713115

Epoch: 6| Step: 9
Training loss: 2.195140838623047
Validation loss: 2.070114533106486

Epoch: 6| Step: 10
Training loss: 2.196317195892334
Validation loss: 1.9545647969809912

Epoch: 6| Step: 11
Training loss: 1.2824794054031372
Validation loss: 1.9088617537611274

Epoch: 6| Step: 12
Training loss: 2.336549997329712
Validation loss: 1.8793627613334245

Epoch: 6| Step: 13
Training loss: 2.0585381984710693
Validation loss: 1.892485692936887

Epoch: 133| Step: 0
Training loss: 1.7395638227462769
Validation loss: 1.8782009924611738

Epoch: 6| Step: 1
Training loss: 1.9231903553009033
Validation loss: 1.8831530886311685

Epoch: 6| Step: 2
Training loss: 1.1061633825302124
Validation loss: 1.8667524027568039

Epoch: 6| Step: 3
Training loss: 2.132603645324707
Validation loss: 1.8607594633615145

Epoch: 6| Step: 4
Training loss: 2.238327980041504
Validation loss: 1.8677077331850607

Epoch: 6| Step: 5
Training loss: 1.7467714548110962
Validation loss: 1.8771635909234323

Epoch: 6| Step: 6
Training loss: 1.7636816501617432
Validation loss: 1.8821959354544198

Epoch: 6| Step: 7
Training loss: 1.9583039283752441
Validation loss: 1.8957167043480823

Epoch: 6| Step: 8
Training loss: 2.282357692718506
Validation loss: 1.9219828972252466

Epoch: 6| Step: 9
Training loss: 2.2439966201782227
Validation loss: 1.9574608264430877

Epoch: 6| Step: 10
Training loss: 1.902834415435791
Validation loss: 1.9504208116121189

Epoch: 6| Step: 11
Training loss: 1.5968165397644043
Validation loss: 1.9752239001694547

Epoch: 6| Step: 12
Training loss: 1.5814659595489502
Validation loss: 1.981985604891213

Epoch: 6| Step: 13
Training loss: 2.7701449394226074
Validation loss: 2.01085308290297

Epoch: 134| Step: 0
Training loss: 1.6755986213684082
Validation loss: 2.0054328518529094

Epoch: 6| Step: 1
Training loss: 1.8778470754623413
Validation loss: 2.0374651596110356

Epoch: 6| Step: 2
Training loss: 1.9679627418518066
Validation loss: 2.030143003309927

Epoch: 6| Step: 3
Training loss: 1.9404104948043823
Validation loss: 2.0407307096706924

Epoch: 6| Step: 4
Training loss: 1.0952935218811035
Validation loss: 2.0536193591292187

Epoch: 6| Step: 5
Training loss: 1.284803032875061
Validation loss: 2.0595550178199686

Epoch: 6| Step: 6
Training loss: 2.547966718673706
Validation loss: 2.0629121052321566

Epoch: 6| Step: 7
Training loss: 1.5804673433303833
Validation loss: 2.035715885059808

Epoch: 6| Step: 8
Training loss: 1.5793431997299194
Validation loss: 2.040706019247732

Epoch: 6| Step: 9
Training loss: 2.6100759506225586
Validation loss: 2.0288350351395144

Epoch: 6| Step: 10
Training loss: 1.699873447418213
Validation loss: 2.028193458434074

Epoch: 6| Step: 11
Training loss: 2.53669810295105
Validation loss: 2.0310090485439507

Epoch: 6| Step: 12
Training loss: 1.9370887279510498
Validation loss: 2.0083670231603805

Epoch: 6| Step: 13
Training loss: 1.7879496812820435
Validation loss: 1.9923626697191628

Epoch: 135| Step: 0
Training loss: 2.020204544067383
Validation loss: 1.9701121750698294

Epoch: 6| Step: 1
Training loss: 2.095496892929077
Validation loss: 1.97237519807713

Epoch: 6| Step: 2
Training loss: 1.4298899173736572
Validation loss: 1.9858481243092527

Epoch: 6| Step: 3
Training loss: 2.081848621368408
Validation loss: 1.9618203306710849

Epoch: 6| Step: 4
Training loss: 2.0566933155059814
Validation loss: 1.9641621625551613

Epoch: 6| Step: 5
Training loss: 1.9230085611343384
Validation loss: 1.956440943543629

Epoch: 6| Step: 6
Training loss: 1.7404142618179321
Validation loss: 1.9538273298612205

Epoch: 6| Step: 7
Training loss: 2.4682888984680176
Validation loss: 1.93882369226025

Epoch: 6| Step: 8
Training loss: 2.2533087730407715
Validation loss: 1.949819682746805

Epoch: 6| Step: 9
Training loss: 1.3893775939941406
Validation loss: 1.9388454652601672

Epoch: 6| Step: 10
Training loss: 1.616853952407837
Validation loss: 1.9539073282672512

Epoch: 6| Step: 11
Training loss: 1.2781193256378174
Validation loss: 1.9490774062372023

Epoch: 6| Step: 12
Training loss: 1.8124780654907227
Validation loss: 1.9514968369596748

Epoch: 6| Step: 13
Training loss: 1.0806761980056763
Validation loss: 1.9585162311471918

Epoch: 136| Step: 0
Training loss: 1.5885365009307861
Validation loss: 1.9692510148530364

Epoch: 6| Step: 1
Training loss: 2.365598678588867
Validation loss: 1.9617906834489556

Epoch: 6| Step: 2
Training loss: 1.1473729610443115
Validation loss: 1.9709238916315057

Epoch: 6| Step: 3
Training loss: 2.846902847290039
Validation loss: 1.9491945594869635

Epoch: 6| Step: 4
Training loss: 1.798095464706421
Validation loss: 1.952350631836922

Epoch: 6| Step: 5
Training loss: 2.0491223335266113
Validation loss: 1.9656900846829979

Epoch: 6| Step: 6
Training loss: 1.2700612545013428
Validation loss: 1.9850013743164718

Epoch: 6| Step: 7
Training loss: 1.5127224922180176
Validation loss: 1.9846570876336866

Epoch: 6| Step: 8
Training loss: 1.9100298881530762
Validation loss: 2.0109593047890613

Epoch: 6| Step: 9
Training loss: 1.783786416053772
Validation loss: 2.003261955835486

Epoch: 6| Step: 10
Training loss: 1.6091612577438354
Validation loss: 1.989306915190912

Epoch: 6| Step: 11
Training loss: 1.2209970951080322
Validation loss: 1.9481104778987106

Epoch: 6| Step: 12
Training loss: 2.4089813232421875
Validation loss: 1.9526990100901613

Epoch: 6| Step: 13
Training loss: 2.122154712677002
Validation loss: 1.954519038559288

Epoch: 137| Step: 0
Training loss: 1.6257555484771729
Validation loss: 1.9731297903163458

Epoch: 6| Step: 1
Training loss: 1.4286631345748901
Validation loss: 1.9911238429366902

Epoch: 6| Step: 2
Training loss: 1.4704952239990234
Validation loss: 2.0094693976063884

Epoch: 6| Step: 3
Training loss: 1.781830072402954
Validation loss: 2.0366126773177937

Epoch: 6| Step: 4
Training loss: 2.451284408569336
Validation loss: 2.065668644443635

Epoch: 6| Step: 5
Training loss: 1.7198947668075562
Validation loss: 2.085857632339642

Epoch: 6| Step: 6
Training loss: 1.714519739151001
Validation loss: 2.077479884188662

Epoch: 6| Step: 7
Training loss: 2.2629871368408203
Validation loss: 2.081521511077881

Epoch: 6| Step: 8
Training loss: 1.8436334133148193
Validation loss: 2.0738636473173737

Epoch: 6| Step: 9
Training loss: 2.3745293617248535
Validation loss: 2.0573478078329437

Epoch: 6| Step: 10
Training loss: 1.5787622928619385
Validation loss: 2.0169593364961687

Epoch: 6| Step: 11
Training loss: 1.9855608940124512
Validation loss: 1.9929388466701712

Epoch: 6| Step: 12
Training loss: 1.658684253692627
Validation loss: 1.9851136028125722

Epoch: 6| Step: 13
Training loss: 1.9052653312683105
Validation loss: 1.954896096260317

Epoch: 138| Step: 0
Training loss: 2.3294548988342285
Validation loss: 1.9407982159686346

Epoch: 6| Step: 1
Training loss: 1.4729745388031006
Validation loss: 1.917515431680987

Epoch: 6| Step: 2
Training loss: 2.051009178161621
Validation loss: 1.9010044438864595

Epoch: 6| Step: 3
Training loss: 1.8225922584533691
Validation loss: 1.8996063727204517

Epoch: 6| Step: 4
Training loss: 2.283902168273926
Validation loss: 1.9018558404778922

Epoch: 6| Step: 5
Training loss: 1.5857365131378174
Validation loss: 1.917064336038405

Epoch: 6| Step: 6
Training loss: 1.516645073890686
Validation loss: 1.9365960231391333

Epoch: 6| Step: 7
Training loss: 1.558591604232788
Validation loss: 1.948486033306327

Epoch: 6| Step: 8
Training loss: 2.215358257293701
Validation loss: 1.931489295856927

Epoch: 6| Step: 9
Training loss: 2.320587635040283
Validation loss: 1.9135628413128596

Epoch: 6| Step: 10
Training loss: 2.085160732269287
Validation loss: 1.9086576418210102

Epoch: 6| Step: 11
Training loss: 1.5721156597137451
Validation loss: 1.923060469729926

Epoch: 6| Step: 12
Training loss: 1.1844598054885864
Validation loss: 1.9274039281311857

Epoch: 6| Step: 13
Training loss: 1.9961351156234741
Validation loss: 1.9553658423885223

Epoch: 139| Step: 0
Training loss: 1.5442259311676025
Validation loss: 1.9889670123336136

Epoch: 6| Step: 1
Training loss: 1.2987678050994873
Validation loss: 2.012781875107878

Epoch: 6| Step: 2
Training loss: 1.3136080503463745
Validation loss: 2.0442938650808027

Epoch: 6| Step: 3
Training loss: 1.9016144275665283
Validation loss: 2.059261450203516

Epoch: 6| Step: 4
Training loss: 2.063717842102051
Validation loss: 2.073355115869994

Epoch: 6| Step: 5
Training loss: 2.261362075805664
Validation loss: 2.0375062291340162

Epoch: 6| Step: 6
Training loss: 1.183509111404419
Validation loss: 2.0348915105224936

Epoch: 6| Step: 7
Training loss: 1.9584190845489502
Validation loss: 2.0250964369825137

Epoch: 6| Step: 8
Training loss: 1.9717750549316406
Validation loss: 1.992695354646252

Epoch: 6| Step: 9
Training loss: 2.0868101119995117
Validation loss: 1.976366178963774

Epoch: 6| Step: 10
Training loss: 2.604094982147217
Validation loss: 1.967924725624823

Epoch: 6| Step: 11
Training loss: 1.8152189254760742
Validation loss: 1.9429359679581018

Epoch: 6| Step: 12
Training loss: 1.6953903436660767
Validation loss: 1.9469031082686556

Epoch: 6| Step: 13
Training loss: 1.9893145561218262
Validation loss: 1.9314626737307476

Epoch: 140| Step: 0
Training loss: 1.276698112487793
Validation loss: 1.968141128939967

Epoch: 6| Step: 1
Training loss: 1.6573379039764404
Validation loss: 1.989149119264336

Epoch: 6| Step: 2
Training loss: 1.7622922658920288
Validation loss: 2.0294824928365727

Epoch: 6| Step: 3
Training loss: 2.8221511840820312
Validation loss: 2.0870922291150658

Epoch: 6| Step: 4
Training loss: 1.3671671152114868
Validation loss: 2.095282023952853

Epoch: 6| Step: 5
Training loss: 1.6599280834197998
Validation loss: 2.1271844346036195

Epoch: 6| Step: 6
Training loss: 2.0240817070007324
Validation loss: 2.0945458899262133

Epoch: 6| Step: 7
Training loss: 2.0489578247070312
Validation loss: 2.0893959460719937

Epoch: 6| Step: 8
Training loss: 1.7504503726959229
Validation loss: 2.0578672885894775

Epoch: 6| Step: 9
Training loss: 1.780715823173523
Validation loss: 2.0338055395310923

Epoch: 6| Step: 10
Training loss: 2.399794101715088
Validation loss: 2.0028268893559775

Epoch: 6| Step: 11
Training loss: 1.6572942733764648
Validation loss: 2.005028619561144

Epoch: 6| Step: 12
Training loss: 1.7903804779052734
Validation loss: 1.9709376827363045

Epoch: 6| Step: 13
Training loss: 1.0092270374298096
Validation loss: 1.9764261758455666

Epoch: 141| Step: 0
Training loss: 2.594334363937378
Validation loss: 2.000298259078815

Epoch: 6| Step: 1
Training loss: 1.5531373023986816
Validation loss: 1.9840540398833573

Epoch: 6| Step: 2
Training loss: 1.7516274452209473
Validation loss: 1.9756385228967155

Epoch: 6| Step: 3
Training loss: 1.864255666732788
Validation loss: 1.9715420969070927

Epoch: 6| Step: 4
Training loss: 1.296160101890564
Validation loss: 1.9418899423332625

Epoch: 6| Step: 5
Training loss: 1.9569514989852905
Validation loss: 1.9294433850114063

Epoch: 6| Step: 6
Training loss: 1.6718504428863525
Validation loss: 1.939427073283862

Epoch: 6| Step: 7
Training loss: 1.2037405967712402
Validation loss: 1.9541455597005866

Epoch: 6| Step: 8
Training loss: 1.5356483459472656
Validation loss: 2.017591894313853

Epoch: 6| Step: 9
Training loss: 1.8794958591461182
Validation loss: 2.119126941568108

Epoch: 6| Step: 10
Training loss: 1.940181851387024
Validation loss: 2.1201044692788074

Epoch: 6| Step: 11
Training loss: 2.532825469970703
Validation loss: 2.1097476431118545

Epoch: 6| Step: 12
Training loss: 2.4415993690490723
Validation loss: 2.025109055221722

Epoch: 6| Step: 13
Training loss: 1.2762330770492554
Validation loss: 1.9522179608703942

Epoch: 142| Step: 0
Training loss: 1.7386651039123535
Validation loss: 1.925772520803636

Epoch: 6| Step: 1
Training loss: 1.6708824634552002
Validation loss: 1.911866021412675

Epoch: 6| Step: 2
Training loss: 1.5725290775299072
Validation loss: 1.9286997574631886

Epoch: 6| Step: 3
Training loss: 1.8505616188049316
Validation loss: 1.9475852635598951

Epoch: 6| Step: 4
Training loss: 1.6561784744262695
Validation loss: 1.9390321700803694

Epoch: 6| Step: 5
Training loss: 2.362912654876709
Validation loss: 1.949321032852255

Epoch: 6| Step: 6
Training loss: 1.7756139039993286
Validation loss: 1.9409498245485368

Epoch: 6| Step: 7
Training loss: 2.077982187271118
Validation loss: 1.9191703988659767

Epoch: 6| Step: 8
Training loss: 1.9204115867614746
Validation loss: 1.902129929552796

Epoch: 6| Step: 9
Training loss: 1.1897563934326172
Validation loss: 1.937663826891171

Epoch: 6| Step: 10
Training loss: 1.7893462181091309
Validation loss: 2.00274819712485

Epoch: 6| Step: 11
Training loss: 1.3482438325881958
Validation loss: 2.0387086765740507

Epoch: 6| Step: 12
Training loss: 2.2957472801208496
Validation loss: 2.0419700299539874

Epoch: 6| Step: 13
Training loss: 2.0514414310455322
Validation loss: 2.0492479185904227

Epoch: 143| Step: 0
Training loss: 1.6737680435180664
Validation loss: 2.0594548717621834

Epoch: 6| Step: 1
Training loss: 1.4196372032165527
Validation loss: 2.018832507953849

Epoch: 6| Step: 2
Training loss: 2.1253838539123535
Validation loss: 1.9949988652301092

Epoch: 6| Step: 3
Training loss: 2.1098408699035645
Validation loss: 1.9635188400104482

Epoch: 6| Step: 4
Training loss: 1.7472776174545288
Validation loss: 1.966610316307314

Epoch: 6| Step: 5
Training loss: 1.4834600687026978
Validation loss: 1.973100862195415

Epoch: 6| Step: 6
Training loss: 1.7162647247314453
Validation loss: 1.9889053554945095

Epoch: 6| Step: 7
Training loss: 1.8058784008026123
Validation loss: 2.0024010609554987

Epoch: 6| Step: 8
Training loss: 1.863044023513794
Validation loss: 2.023025135840139

Epoch: 6| Step: 9
Training loss: 1.9241371154785156
Validation loss: 2.030777031375516

Epoch: 6| Step: 10
Training loss: 1.6417546272277832
Validation loss: 2.0244798403914257

Epoch: 6| Step: 11
Training loss: 1.1533052921295166
Validation loss: 1.9871367049473587

Epoch: 6| Step: 12
Training loss: 1.819617509841919
Validation loss: 1.9563327579088108

Epoch: 6| Step: 13
Training loss: 2.598424196243286
Validation loss: 1.9343858534289944

Epoch: 144| Step: 0
Training loss: 1.4251575469970703
Validation loss: 1.9337624067901282

Epoch: 6| Step: 1
Training loss: 2.0375754833221436
Validation loss: 1.9122424279489825

Epoch: 6| Step: 2
Training loss: 1.3389499187469482
Validation loss: 1.913900198475007

Epoch: 6| Step: 3
Training loss: 1.718611240386963
Validation loss: 1.9098861576408468

Epoch: 6| Step: 4
Training loss: 1.9845755100250244
Validation loss: 1.9326857225869292

Epoch: 6| Step: 5
Training loss: 1.8605570793151855
Validation loss: 1.9598196424463743

Epoch: 6| Step: 6
Training loss: 1.8089592456817627
Validation loss: 1.9815032084782918

Epoch: 6| Step: 7
Training loss: 1.9056406021118164
Validation loss: 2.001641204280238

Epoch: 6| Step: 8
Training loss: 1.2602214813232422
Validation loss: 2.0077349947344874

Epoch: 6| Step: 9
Training loss: 2.1709156036376953
Validation loss: 2.0258851487149476

Epoch: 6| Step: 10
Training loss: 0.8861729502677917
Validation loss: 2.0347941152511106

Epoch: 6| Step: 11
Training loss: 1.5747802257537842
Validation loss: 2.010292891533144

Epoch: 6| Step: 12
Training loss: 2.3888516426086426
Validation loss: 1.9918707929631716

Epoch: 6| Step: 13
Training loss: 1.9233328104019165
Validation loss: 1.9843299888795423

Epoch: 145| Step: 0
Training loss: 1.7186987400054932
Validation loss: 1.9834062463493758

Epoch: 6| Step: 1
Training loss: 1.612547516822815
Validation loss: 1.9761989911397297

Epoch: 6| Step: 2
Training loss: 1.2696490287780762
Validation loss: 1.9873949737959011

Epoch: 6| Step: 3
Training loss: 1.7091161012649536
Validation loss: 1.9683297705906693

Epoch: 6| Step: 4
Training loss: 1.8287732601165771
Validation loss: 1.984751170681369

Epoch: 6| Step: 5
Training loss: 1.2389702796936035
Validation loss: 2.0030455589294434

Epoch: 6| Step: 6
Training loss: 1.857249140739441
Validation loss: 2.0214724412528415

Epoch: 6| Step: 7
Training loss: 2.487410306930542
Validation loss: 2.0203447059918473

Epoch: 6| Step: 8
Training loss: 1.5751615762710571
Validation loss: 1.9924823314912858

Epoch: 6| Step: 9
Training loss: 1.8374278545379639
Validation loss: 1.977170826286398

Epoch: 6| Step: 10
Training loss: 2.1957273483276367
Validation loss: 1.947583713839131

Epoch: 6| Step: 11
Training loss: 2.0720808506011963
Validation loss: 1.947047846291655

Epoch: 6| Step: 12
Training loss: 1.7281917333602905
Validation loss: 1.9497020757326515

Epoch: 6| Step: 13
Training loss: 0.9519490003585815
Validation loss: 1.9609230769577848

Epoch: 146| Step: 0
Training loss: 2.636106014251709
Validation loss: 1.9484067399014708

Epoch: 6| Step: 1
Training loss: 1.490121841430664
Validation loss: 1.9673466502979238

Epoch: 6| Step: 2
Training loss: 1.9776962995529175
Validation loss: 1.9738034458570584

Epoch: 6| Step: 3
Training loss: 1.940613031387329
Validation loss: 1.981967213333294

Epoch: 6| Step: 4
Training loss: 2.2439420223236084
Validation loss: 2.0268501440684

Epoch: 6| Step: 5
Training loss: 1.2512900829315186
Validation loss: 2.0448475730034614

Epoch: 6| Step: 6
Training loss: 1.2974376678466797
Validation loss: 2.0418269493246592

Epoch: 6| Step: 7
Training loss: 1.6127660274505615
Validation loss: 2.010106175176559

Epoch: 6| Step: 8
Training loss: 1.9953808784484863
Validation loss: 1.9955867490460795

Epoch: 6| Step: 9
Training loss: 1.07991361618042
Validation loss: 1.9900164053004274

Epoch: 6| Step: 10
Training loss: 1.6585774421691895
Validation loss: 1.9773603024021271

Epoch: 6| Step: 11
Training loss: 1.9704188108444214
Validation loss: 1.9723304830571657

Epoch: 6| Step: 12
Training loss: 1.1419286727905273
Validation loss: 1.9631801395006077

Epoch: 6| Step: 13
Training loss: 1.3734694719314575
Validation loss: 1.963572386772402

Epoch: 147| Step: 0
Training loss: 1.144562005996704
Validation loss: 1.9592860103935323

Epoch: 6| Step: 1
Training loss: 2.2148051261901855
Validation loss: 1.9512897858055689

Epoch: 6| Step: 2
Training loss: 1.7799025774002075
Validation loss: 1.952991718887001

Epoch: 6| Step: 3
Training loss: 1.8247966766357422
Validation loss: 1.9767833217497794

Epoch: 6| Step: 4
Training loss: 1.9234576225280762
Validation loss: 1.9932011128753744

Epoch: 6| Step: 5
Training loss: 1.5041882991790771
Validation loss: 2.0460783653361823

Epoch: 6| Step: 6
Training loss: 2.051664113998413
Validation loss: 2.041539804909819

Epoch: 6| Step: 7
Training loss: 1.7010880708694458
Validation loss: 2.0330040044682

Epoch: 6| Step: 8
Training loss: 1.8170475959777832
Validation loss: 1.9891649343634163

Epoch: 6| Step: 9
Training loss: 1.5865349769592285
Validation loss: 1.9560070665933753

Epoch: 6| Step: 10
Training loss: 1.3206942081451416
Validation loss: 1.9294587617279382

Epoch: 6| Step: 11
Training loss: 2.0232324600219727
Validation loss: 1.921667875782136

Epoch: 6| Step: 12
Training loss: 1.9406615495681763
Validation loss: 1.95030854850687

Epoch: 6| Step: 13
Training loss: 1.4195319414138794
Validation loss: 1.9500784450961697

Epoch: 148| Step: 0
Training loss: 2.221534490585327
Validation loss: 1.9523933382444485

Epoch: 6| Step: 1
Training loss: 2.4521138668060303
Validation loss: 1.9532245974386893

Epoch: 6| Step: 2
Training loss: 1.2312921285629272
Validation loss: 1.960204016777777

Epoch: 6| Step: 3
Training loss: 1.071427583694458
Validation loss: 1.982174237569173

Epoch: 6| Step: 4
Training loss: 1.2122727632522583
Validation loss: 2.034431449828609

Epoch: 6| Step: 5
Training loss: 1.406772255897522
Validation loss: 2.088298523297874

Epoch: 6| Step: 6
Training loss: 1.660402536392212
Validation loss: 2.113892468073035

Epoch: 6| Step: 7
Training loss: 1.9795646667480469
Validation loss: 2.117062553282707

Epoch: 6| Step: 8
Training loss: 1.3456532955169678
Validation loss: 2.1382003522688344

Epoch: 6| Step: 9
Training loss: 1.940300464630127
Validation loss: 2.1133427030296734

Epoch: 6| Step: 10
Training loss: 2.0274791717529297
Validation loss: 2.0552940855744066

Epoch: 6| Step: 11
Training loss: 1.5870615243911743
Validation loss: 2.0292380112473682

Epoch: 6| Step: 12
Training loss: 2.128218650817871
Validation loss: 2.010650352765155

Epoch: 6| Step: 13
Training loss: 1.6689807176589966
Validation loss: 2.010845286871797

Epoch: 149| Step: 0
Training loss: 2.5030951499938965
Validation loss: 2.002172586738422

Epoch: 6| Step: 1
Training loss: 1.813713550567627
Validation loss: 2.0052428912091

Epoch: 6| Step: 2
Training loss: 2.101593494415283
Validation loss: 2.0051802178864837

Epoch: 6| Step: 3
Training loss: 1.1419621706008911
Validation loss: 1.9720387394710253

Epoch: 6| Step: 4
Training loss: 1.4391098022460938
Validation loss: 1.957578291175186

Epoch: 6| Step: 5
Training loss: 1.363973617553711
Validation loss: 1.946208957702883

Epoch: 6| Step: 6
Training loss: 2.411188840866089
Validation loss: 1.9700080938236688

Epoch: 6| Step: 7
Training loss: 1.4153718948364258
Validation loss: 1.991289911731597

Epoch: 6| Step: 8
Training loss: 1.8088829517364502
Validation loss: 2.0553529903452885

Epoch: 6| Step: 9
Training loss: 1.7860232591629028
Validation loss: 2.1202094195991434

Epoch: 6| Step: 10
Training loss: 1.61015784740448
Validation loss: 2.1340762287057857

Epoch: 6| Step: 11
Training loss: 1.5315190553665161
Validation loss: 2.0917799947082356

Epoch: 6| Step: 12
Training loss: 1.807207465171814
Validation loss: 2.0612027696383897

Epoch: 6| Step: 13
Training loss: 1.5345011949539185
Validation loss: 2.0233074529196626

Epoch: 150| Step: 0
Training loss: 1.9850032329559326
Validation loss: 2.0044068367250505

Epoch: 6| Step: 1
Training loss: 1.7969563007354736
Validation loss: 1.9931241568698679

Epoch: 6| Step: 2
Training loss: 1.3644810914993286
Validation loss: 1.9929329502967097

Epoch: 6| Step: 3
Training loss: 1.7576861381530762
Validation loss: 1.9702523087942472

Epoch: 6| Step: 4
Training loss: 2.5090911388397217
Validation loss: 1.9737495568490797

Epoch: 6| Step: 5
Training loss: 1.1294715404510498
Validation loss: 1.9630703605631346

Epoch: 6| Step: 6
Training loss: 1.5257474184036255
Validation loss: 1.9698188086991668

Epoch: 6| Step: 7
Training loss: 2.004453659057617
Validation loss: 1.9579105043923983

Epoch: 6| Step: 8
Training loss: 1.7634191513061523
Validation loss: 1.95261247440051

Epoch: 6| Step: 9
Training loss: 1.5208344459533691
Validation loss: 1.967105180986466

Epoch: 6| Step: 10
Training loss: 1.6382856369018555
Validation loss: 2.00306724861104

Epoch: 6| Step: 11
Training loss: 1.3436180353164673
Validation loss: 2.0236640450774983

Epoch: 6| Step: 12
Training loss: 1.579403042793274
Validation loss: 2.071061485557146

Epoch: 6| Step: 13
Training loss: 1.4664547443389893
Validation loss: 2.0402796909373295

Epoch: 151| Step: 0
Training loss: 2.525294065475464
Validation loss: 2.0162969481560493

Epoch: 6| Step: 1
Training loss: 1.6216614246368408
Validation loss: 1.9971257819924304

Epoch: 6| Step: 2
Training loss: 1.0831717252731323
Validation loss: 1.9441802040223153

Epoch: 6| Step: 3
Training loss: 1.9213289022445679
Validation loss: 1.9624503274117746

Epoch: 6| Step: 4
Training loss: 1.1579948663711548
Validation loss: 1.9445806049531507

Epoch: 6| Step: 5
Training loss: 1.287584662437439
Validation loss: 1.9566724877203665

Epoch: 6| Step: 6
Training loss: 1.677374005317688
Validation loss: 1.9719840916254188

Epoch: 6| Step: 7
Training loss: 1.9785799980163574
Validation loss: 1.9819372418106243

Epoch: 6| Step: 8
Training loss: 1.3833463191986084
Validation loss: 1.9898237054065993

Epoch: 6| Step: 9
Training loss: 1.76951265335083
Validation loss: 2.0023646764857794

Epoch: 6| Step: 10
Training loss: 1.3121874332427979
Validation loss: 2.014705947009466

Epoch: 6| Step: 11
Training loss: 1.910311222076416
Validation loss: 2.007100216804012

Epoch: 6| Step: 12
Training loss: 2.2077317237854004
Validation loss: 1.9956822215869863

Epoch: 6| Step: 13
Training loss: 1.0744787454605103
Validation loss: 1.9855525852531515

Epoch: 152| Step: 0
Training loss: 2.403097152709961
Validation loss: 1.9965821466138285

Epoch: 6| Step: 1
Training loss: 1.3505281209945679
Validation loss: 2.0120087592832503

Epoch: 6| Step: 2
Training loss: 1.3575336933135986
Validation loss: 2.039659616767719

Epoch: 6| Step: 3
Training loss: 1.4029957056045532
Validation loss: 2.0338039116192888

Epoch: 6| Step: 4
Training loss: 1.5660345554351807
Validation loss: 1.9995134081891788

Epoch: 6| Step: 5
Training loss: 1.6986843347549438
Validation loss: 1.9781816505616712

Epoch: 6| Step: 6
Training loss: 1.3543819189071655
Validation loss: 1.9528581788462978

Epoch: 6| Step: 7
Training loss: 1.7021267414093018
Validation loss: 1.9379583071636897

Epoch: 6| Step: 8
Training loss: 1.6483676433563232
Validation loss: 1.929237634904923

Epoch: 6| Step: 9
Training loss: 1.5253252983093262
Validation loss: 1.9306402514057774

Epoch: 6| Step: 10
Training loss: 1.470842719078064
Validation loss: 1.955849282203182

Epoch: 6| Step: 11
Training loss: 1.6114332675933838
Validation loss: 1.9633323236178326

Epoch: 6| Step: 12
Training loss: 1.6327898502349854
Validation loss: 1.9628866385388117

Epoch: 6| Step: 13
Training loss: 2.089491844177246
Validation loss: 1.9741835209631151

Epoch: 153| Step: 0
Training loss: 1.9147571325302124
Validation loss: 1.9515064095938077

Epoch: 6| Step: 1
Training loss: 1.717160940170288
Validation loss: 1.965796241196253

Epoch: 6| Step: 2
Training loss: 1.5606660842895508
Validation loss: 1.9399815387623285

Epoch: 6| Step: 3
Training loss: 1.1624119281768799
Validation loss: 1.9254011236211306

Epoch: 6| Step: 4
Training loss: 1.8164242506027222
Validation loss: 1.9353914824865197

Epoch: 6| Step: 5
Training loss: 1.479641079902649
Validation loss: 1.9444569656925816

Epoch: 6| Step: 6
Training loss: 1.4363327026367188
Validation loss: 1.9365417265122937

Epoch: 6| Step: 7
Training loss: 1.5203588008880615
Validation loss: 1.937367731525052

Epoch: 6| Step: 8
Training loss: 1.3716576099395752
Validation loss: 1.938966264006912

Epoch: 6| Step: 9
Training loss: 2.2434661388397217
Validation loss: 1.9379723046415596

Epoch: 6| Step: 10
Training loss: 1.2914570569992065
Validation loss: 1.9609664896483063

Epoch: 6| Step: 11
Training loss: 1.3383092880249023
Validation loss: 1.929563714611915

Epoch: 6| Step: 12
Training loss: 1.7449342012405396
Validation loss: 1.9184470356151622

Epoch: 6| Step: 13
Training loss: 1.7252039909362793
Validation loss: 1.9160361187432402

Epoch: 154| Step: 0
Training loss: 2.0647776126861572
Validation loss: 1.9250945416829919

Epoch: 6| Step: 1
Training loss: 1.7565141916275024
Validation loss: 1.9239785978871007

Epoch: 6| Step: 2
Training loss: 1.4257190227508545
Validation loss: 1.9342412038515973

Epoch: 6| Step: 3
Training loss: 1.2539055347442627
Validation loss: 1.9384232656930083

Epoch: 6| Step: 4
Training loss: 1.608220100402832
Validation loss: 1.9656587236671037

Epoch: 6| Step: 5
Training loss: 1.2346651554107666
Validation loss: 1.9778484182973062

Epoch: 6| Step: 6
Training loss: 2.1264305114746094
Validation loss: 1.9958680163147628

Epoch: 6| Step: 7
Training loss: 1.9684712886810303
Validation loss: 2.0346925027908815

Epoch: 6| Step: 8
Training loss: 1.703506350517273
Validation loss: 1.9985670915213964

Epoch: 6| Step: 9
Training loss: 0.9373026490211487
Validation loss: 1.9884788836202314

Epoch: 6| Step: 10
Training loss: 1.1524264812469482
Validation loss: 1.9896604322618054

Epoch: 6| Step: 11
Training loss: 1.8119454383850098
Validation loss: 1.982883922515377

Epoch: 6| Step: 12
Training loss: 1.7876224517822266
Validation loss: 1.9731509429152294

Epoch: 6| Step: 13
Training loss: 1.614376425743103
Validation loss: 1.9668499256974907

Epoch: 155| Step: 0
Training loss: 1.273953914642334
Validation loss: 1.97874064471132

Epoch: 6| Step: 1
Training loss: 1.4157180786132812
Validation loss: 1.9960703055063884

Epoch: 6| Step: 2
Training loss: 1.1204158067703247
Validation loss: 1.9840302236618534

Epoch: 6| Step: 3
Training loss: 2.018717050552368
Validation loss: 2.0084630007384927

Epoch: 6| Step: 4
Training loss: 1.371027946472168
Validation loss: 2.0273003296185563

Epoch: 6| Step: 5
Training loss: 1.6523511409759521
Validation loss: 2.0081646980777865

Epoch: 6| Step: 6
Training loss: 1.1702284812927246
Validation loss: 1.9677783699445828

Epoch: 6| Step: 7
Training loss: 1.7651101350784302
Validation loss: 1.9437690909190843

Epoch: 6| Step: 8
Training loss: 1.9483001232147217
Validation loss: 1.9358399888520599

Epoch: 6| Step: 9
Training loss: 1.5804719924926758
Validation loss: 1.9169563824130642

Epoch: 6| Step: 10
Training loss: 2.0722150802612305
Validation loss: 1.9174013791545745

Epoch: 6| Step: 11
Training loss: 1.316338062286377
Validation loss: 1.8971727560925227

Epoch: 6| Step: 12
Training loss: 1.6842398643493652
Validation loss: 1.8894291923892113

Epoch: 6| Step: 13
Training loss: 1.7444453239440918
Validation loss: 1.9074798091765373

Epoch: 156| Step: 0
Training loss: 1.2628583908081055
Validation loss: 1.8991431420849216

Epoch: 6| Step: 1
Training loss: 1.8582121133804321
Validation loss: 1.9321663815488097

Epoch: 6| Step: 2
Training loss: 1.305645227432251
Validation loss: 1.926226592832996

Epoch: 6| Step: 3
Training loss: 1.6043105125427246
Validation loss: 1.9697929761743034

Epoch: 6| Step: 4
Training loss: 2.1724400520324707
Validation loss: 2.0331871407006377

Epoch: 6| Step: 5
Training loss: 1.30763578414917
Validation loss: 2.100732962290446

Epoch: 6| Step: 6
Training loss: 1.1499823331832886
Validation loss: 2.1640852856379684

Epoch: 6| Step: 7
Training loss: 2.148668050765991
Validation loss: 2.181329893809493

Epoch: 6| Step: 8
Training loss: 1.670087456703186
Validation loss: 2.1005215593563613

Epoch: 6| Step: 9
Training loss: 1.42637300491333
Validation loss: 2.04294394036775

Epoch: 6| Step: 10
Training loss: 2.078428268432617
Validation loss: 2.0395644390454857

Epoch: 6| Step: 11
Training loss: 1.9860949516296387
Validation loss: 2.0226023402265323

Epoch: 6| Step: 12
Training loss: 1.3864715099334717
Validation loss: 2.0246357110238846

Epoch: 6| Step: 13
Training loss: 1.63853120803833
Validation loss: 2.0083941657056092

Epoch: 157| Step: 0
Training loss: 1.403588056564331
Validation loss: 1.9889501205054663

Epoch: 6| Step: 1
Training loss: 1.064753532409668
Validation loss: 1.9489754233309018

Epoch: 6| Step: 2
Training loss: 2.4032177925109863
Validation loss: 1.9311097744972474

Epoch: 6| Step: 3
Training loss: 1.796301007270813
Validation loss: 1.9579452058320403

Epoch: 6| Step: 4
Training loss: 1.5063974857330322
Validation loss: 1.9874790970997145

Epoch: 6| Step: 5
Training loss: 1.5195523500442505
Validation loss: 2.0086619725791355

Epoch: 6| Step: 6
Training loss: 1.7818100452423096
Validation loss: 2.048783653525896

Epoch: 6| Step: 7
Training loss: 1.587865948677063
Validation loss: 2.012108915595598

Epoch: 6| Step: 8
Training loss: 1.8245775699615479
Validation loss: 1.9671997549713298

Epoch: 6| Step: 9
Training loss: 0.7939099073410034
Validation loss: 1.947415631304505

Epoch: 6| Step: 10
Training loss: 1.7763590812683105
Validation loss: 1.9090751947895173

Epoch: 6| Step: 11
Training loss: 1.5029733180999756
Validation loss: 1.8973803763748498

Epoch: 6| Step: 12
Training loss: 1.9417513608932495
Validation loss: 1.9104652225330312

Epoch: 6| Step: 13
Training loss: 1.5210363864898682
Validation loss: 1.915886507239393

Epoch: 158| Step: 0
Training loss: 1.4017250537872314
Validation loss: 1.9429746263770646

Epoch: 6| Step: 1
Training loss: 1.4531843662261963
Validation loss: 1.9579139781254593

Epoch: 6| Step: 2
Training loss: 2.0081217288970947
Validation loss: 1.9717687214574506

Epoch: 6| Step: 3
Training loss: 1.3366143703460693
Validation loss: 1.9830160230718634

Epoch: 6| Step: 4
Training loss: 2.161318778991699
Validation loss: 2.0172281611350273

Epoch: 6| Step: 5
Training loss: 1.1192076206207275
Validation loss: 2.013883001060896

Epoch: 6| Step: 6
Training loss: 1.6152420043945312
Validation loss: 2.011732207831516

Epoch: 6| Step: 7
Training loss: 1.7162076234817505
Validation loss: 2.003359211388455

Epoch: 6| Step: 8
Training loss: 0.9448943138122559
Validation loss: 1.9866819445804884

Epoch: 6| Step: 9
Training loss: 0.7549145221710205
Validation loss: 1.9765336064882175

Epoch: 6| Step: 10
Training loss: 1.6986808776855469
Validation loss: 1.9798317019657423

Epoch: 6| Step: 11
Training loss: 1.861395239830017
Validation loss: 1.9811294399281985

Epoch: 6| Step: 12
Training loss: 1.9256476163864136
Validation loss: 1.9740909645634312

Epoch: 6| Step: 13
Training loss: 1.0621888637542725
Validation loss: 1.957405310805126

Epoch: 159| Step: 0
Training loss: 1.0305676460266113
Validation loss: 1.9948214254071635

Epoch: 6| Step: 1
Training loss: 1.4515624046325684
Validation loss: 2.0047900702363703

Epoch: 6| Step: 2
Training loss: 1.2321436405181885
Validation loss: 2.0240954750327655

Epoch: 6| Step: 3
Training loss: 1.8497066497802734
Validation loss: 2.00682407809842

Epoch: 6| Step: 4
Training loss: 1.80076265335083
Validation loss: 1.9930888299019105

Epoch: 6| Step: 5
Training loss: 1.6530778408050537
Validation loss: 1.9886971622385003

Epoch: 6| Step: 6
Training loss: 0.983371376991272
Validation loss: 1.9623613972817697

Epoch: 6| Step: 7
Training loss: 1.3527743816375732
Validation loss: 1.9610910364376601

Epoch: 6| Step: 8
Training loss: 2.055361747741699
Validation loss: 1.968435977094917

Epoch: 6| Step: 9
Training loss: 1.6510570049285889
Validation loss: 1.951593199083882

Epoch: 6| Step: 10
Training loss: 1.5244431495666504
Validation loss: 1.9430895966868247

Epoch: 6| Step: 11
Training loss: 1.5290005207061768
Validation loss: 1.952426197708294

Epoch: 6| Step: 12
Training loss: 1.94850754737854
Validation loss: 1.9608547020983953

Epoch: 6| Step: 13
Training loss: 0.9541398286819458
Validation loss: 1.9625747383281749

Epoch: 160| Step: 0
Training loss: 2.2237067222595215
Validation loss: 1.9804283342053812

Epoch: 6| Step: 1
Training loss: 2.1242306232452393
Validation loss: 1.9846816678200998

Epoch: 6| Step: 2
Training loss: 1.8018747568130493
Validation loss: 2.0030690213685394

Epoch: 6| Step: 3
Training loss: 1.9002565145492554
Validation loss: 2.004551794580234

Epoch: 6| Step: 4
Training loss: 1.531719446182251
Validation loss: 1.9316527612747685

Epoch: 6| Step: 5
Training loss: 1.6569504737854004
Validation loss: 1.8991812788030153

Epoch: 6| Step: 6
Training loss: 1.5074315071105957
Validation loss: 1.898849625741282

Epoch: 6| Step: 7
Training loss: 1.1491985321044922
Validation loss: 1.8876189929182812

Epoch: 6| Step: 8
Training loss: 1.0625524520874023
Validation loss: 1.8902537361268075

Epoch: 6| Step: 9
Training loss: 1.283231258392334
Validation loss: 1.89036484431195

Epoch: 6| Step: 10
Training loss: 1.295586109161377
Validation loss: 1.8995149238135225

Epoch: 6| Step: 11
Training loss: 1.5824929475784302
Validation loss: 1.8975322823370657

Epoch: 6| Step: 12
Training loss: 1.297165870666504
Validation loss: 1.920844829210671

Epoch: 6| Step: 13
Training loss: 1.8068097829818726
Validation loss: 2.002097145203621

Epoch: 161| Step: 0
Training loss: 1.6747100353240967
Validation loss: 2.041597645769837

Epoch: 6| Step: 1
Training loss: 1.714281678199768
Validation loss: 2.0796641931738904

Epoch: 6| Step: 2
Training loss: 1.637642741203308
Validation loss: 2.06492220329982

Epoch: 6| Step: 3
Training loss: 1.7174978256225586
Validation loss: 2.0346343671121905

Epoch: 6| Step: 4
Training loss: 1.0519218444824219
Validation loss: 2.011177175788469

Epoch: 6| Step: 5
Training loss: 1.5148863792419434
Validation loss: 1.9879639353803409

Epoch: 6| Step: 6
Training loss: 1.442737340927124
Validation loss: 1.9754676152301092

Epoch: 6| Step: 7
Training loss: 2.0918076038360596
Validation loss: 1.9545707471909062

Epoch: 6| Step: 8
Training loss: 1.2887122631072998
Validation loss: 1.9476350776610836

Epoch: 6| Step: 9
Training loss: 1.2742911577224731
Validation loss: 1.939656089710933

Epoch: 6| Step: 10
Training loss: 0.7646245956420898
Validation loss: 1.9317681545852332

Epoch: 6| Step: 11
Training loss: 1.9951120615005493
Validation loss: 1.9255595155941543

Epoch: 6| Step: 12
Training loss: 1.4599578380584717
Validation loss: 1.957644457458168

Epoch: 6| Step: 13
Training loss: 1.708052158355713
Validation loss: 1.9864437785199893

Epoch: 162| Step: 0
Training loss: 1.5919510126113892
Validation loss: 1.9927030942773307

Epoch: 6| Step: 1
Training loss: 1.4574992656707764
Validation loss: 1.9917323563688545

Epoch: 6| Step: 2
Training loss: 1.6776847839355469
Validation loss: 1.9866502208094443

Epoch: 6| Step: 3
Training loss: 1.5396252870559692
Validation loss: 1.9583091171838904

Epoch: 6| Step: 4
Training loss: 1.6654019355773926
Validation loss: 1.9336797614251413

Epoch: 6| Step: 5
Training loss: 0.8382014036178589
Validation loss: 1.9070902575728714

Epoch: 6| Step: 6
Training loss: 1.9946635961532593
Validation loss: 1.921123025237873

Epoch: 6| Step: 7
Training loss: 1.4619312286376953
Validation loss: 1.9190988950831915

Epoch: 6| Step: 8
Training loss: 1.4054975509643555
Validation loss: 1.9106505147872432

Epoch: 6| Step: 9
Training loss: 1.4950194358825684
Validation loss: 1.9292937145438245

Epoch: 6| Step: 10
Training loss: 1.306706190109253
Validation loss: 1.9083297329564248

Epoch: 6| Step: 11
Training loss: 1.5581859350204468
Validation loss: 1.942711845521004

Epoch: 6| Step: 12
Training loss: 1.5424593687057495
Validation loss: 1.9514840046564739

Epoch: 6| Step: 13
Training loss: 1.6008902788162231
Validation loss: 2.008840589113133

Epoch: 163| Step: 0
Training loss: 1.9393017292022705
Validation loss: 2.023519718518821

Epoch: 6| Step: 1
Training loss: 1.6821579933166504
Validation loss: 2.026042707504765

Epoch: 6| Step: 2
Training loss: 1.7044739723205566
Validation loss: 1.9958434566374748

Epoch: 6| Step: 3
Training loss: 1.8695012331008911
Validation loss: 2.016682586362285

Epoch: 6| Step: 4
Training loss: 1.0955144166946411
Validation loss: 2.0130020905566472

Epoch: 6| Step: 5
Training loss: 1.1220529079437256
Validation loss: 1.9882667910668157

Epoch: 6| Step: 6
Training loss: 1.3612060546875
Validation loss: 2.009175594134997

Epoch: 6| Step: 7
Training loss: 2.0198135375976562
Validation loss: 1.9816994077415877

Epoch: 6| Step: 8
Training loss: 1.0988695621490479
Validation loss: 1.9809858158070555

Epoch: 6| Step: 9
Training loss: 1.1280378103256226
Validation loss: 1.9888394314755675

Epoch: 6| Step: 10
Training loss: 1.494125485420227
Validation loss: 1.9835929434786561

Epoch: 6| Step: 11
Training loss: 1.3020617961883545
Validation loss: 1.992357741120041

Epoch: 6| Step: 12
Training loss: 1.5931720733642578
Validation loss: 2.0088444935378207

Epoch: 6| Step: 13
Training loss: 0.8962647914886475
Validation loss: 1.9737131108519852

Epoch: 164| Step: 0
Training loss: 1.2878296375274658
Validation loss: 1.955743876836633

Epoch: 6| Step: 1
Training loss: 1.6956396102905273
Validation loss: 1.9435362405674432

Epoch: 6| Step: 2
Training loss: 1.6351407766342163
Validation loss: 1.9628185046616422

Epoch: 6| Step: 3
Training loss: 1.593672752380371
Validation loss: 1.9569850390957249

Epoch: 6| Step: 4
Training loss: 2.2662672996520996
Validation loss: 1.9593702926430652

Epoch: 6| Step: 5
Training loss: 1.8127329349517822
Validation loss: 1.928131159915719

Epoch: 6| Step: 6
Training loss: 1.4462449550628662
Validation loss: 1.9329044408695673

Epoch: 6| Step: 7
Training loss: 1.1430168151855469
Validation loss: 1.9576094124906807

Epoch: 6| Step: 8
Training loss: 1.3563355207443237
Validation loss: 1.9412885788948304

Epoch: 6| Step: 9
Training loss: 0.7875939607620239
Validation loss: 1.9329890281923356

Epoch: 6| Step: 10
Training loss: 1.667683482170105
Validation loss: 1.9502735291757891

Epoch: 6| Step: 11
Training loss: 1.5349466800689697
Validation loss: 1.9564993637864307

Epoch: 6| Step: 12
Training loss: 1.393794059753418
Validation loss: 1.9450340911906252

Epoch: 6| Step: 13
Training loss: 0.875912606716156
Validation loss: 1.9512768740295081

Epoch: 165| Step: 0
Training loss: 1.2314164638519287
Validation loss: 1.9505413398947766

Epoch: 6| Step: 1
Training loss: 1.0911893844604492
Validation loss: 1.9786338472879061

Epoch: 6| Step: 2
Training loss: 2.2565741539001465
Validation loss: 1.970840060582725

Epoch: 6| Step: 3
Training loss: 1.394975185394287
Validation loss: 1.9751481035704255

Epoch: 6| Step: 4
Training loss: 1.2845687866210938
Validation loss: 1.9758031393892022

Epoch: 6| Step: 5
Training loss: 1.4708058834075928
Validation loss: 1.9524681965510051

Epoch: 6| Step: 6
Training loss: 1.4430537223815918
Validation loss: 1.964723579345211

Epoch: 6| Step: 7
Training loss: 1.7057647705078125
Validation loss: 1.957233525091602

Epoch: 6| Step: 8
Training loss: 1.5998504161834717
Validation loss: 1.9619484511754846

Epoch: 6| Step: 9
Training loss: 0.9296970367431641
Validation loss: 1.9591609790760984

Epoch: 6| Step: 10
Training loss: 1.0203232765197754
Validation loss: 1.9960985440079884

Epoch: 6| Step: 11
Training loss: 1.5626474618911743
Validation loss: 2.0207405961969847

Epoch: 6| Step: 12
Training loss: 1.7647889852523804
Validation loss: 1.9952053485378143

Epoch: 6| Step: 13
Training loss: 1.9436819553375244
Validation loss: 1.9507391760426183

Epoch: 166| Step: 0
Training loss: 1.113420009613037
Validation loss: 1.931308486128366

Epoch: 6| Step: 1
Training loss: 1.3832130432128906
Validation loss: 1.933961022284723

Epoch: 6| Step: 2
Training loss: 1.145269751548767
Validation loss: 1.9206769697127803

Epoch: 6| Step: 3
Training loss: 0.9094173908233643
Validation loss: 1.9149940757341282

Epoch: 6| Step: 4
Training loss: 1.222959280014038
Validation loss: 1.9018747370730165

Epoch: 6| Step: 5
Training loss: 0.7917547225952148
Validation loss: 1.930157289710096

Epoch: 6| Step: 6
Training loss: 2.0284128189086914
Validation loss: 1.9440951552442325

Epoch: 6| Step: 7
Training loss: 1.1840370893478394
Validation loss: 1.958742864670292

Epoch: 6| Step: 8
Training loss: 1.4758644104003906
Validation loss: 1.9719327444671302

Epoch: 6| Step: 9
Training loss: 2.36255145072937
Validation loss: 1.9790461935022825

Epoch: 6| Step: 10
Training loss: 1.3507230281829834
Validation loss: 1.942128501912599

Epoch: 6| Step: 11
Training loss: 2.2679407596588135
Validation loss: 1.9533156105267104

Epoch: 6| Step: 12
Training loss: 1.6844139099121094
Validation loss: 1.948955056487873

Epoch: 6| Step: 13
Training loss: 1.2009549140930176
Validation loss: 1.9485643576550227

Epoch: 167| Step: 0
Training loss: 1.0312705039978027
Validation loss: 1.94550932094615

Epoch: 6| Step: 1
Training loss: 0.8365856409072876
Validation loss: 1.9534399253065868

Epoch: 6| Step: 2
Training loss: 1.538555383682251
Validation loss: 1.9600100671091387

Epoch: 6| Step: 3
Training loss: 1.4841722249984741
Validation loss: 1.9913154186740998

Epoch: 6| Step: 4
Training loss: 1.5278781652450562
Validation loss: 1.9965581637556835

Epoch: 6| Step: 5
Training loss: 2.2192115783691406
Validation loss: 1.9840201895724061

Epoch: 6| Step: 6
Training loss: 1.3237793445587158
Validation loss: 2.0000001602275397

Epoch: 6| Step: 7
Training loss: 1.4813895225524902
Validation loss: 1.9707101660390054

Epoch: 6| Step: 8
Training loss: 1.5753748416900635
Validation loss: 1.9619315106381652

Epoch: 6| Step: 9
Training loss: 1.470597505569458
Validation loss: 1.9558935062859648

Epoch: 6| Step: 10
Training loss: 1.1623371839523315
Validation loss: 1.9492777573165072

Epoch: 6| Step: 11
Training loss: 1.8487638235092163
Validation loss: 1.9427967763716174

Epoch: 6| Step: 12
Training loss: 1.1136574745178223
Validation loss: 1.9185343532152073

Epoch: 6| Step: 13
Training loss: 1.3698452711105347
Validation loss: 1.9013141073206419

Epoch: 168| Step: 0
Training loss: 1.68056321144104
Validation loss: 1.907340597080928

Epoch: 6| Step: 1
Training loss: 1.3625643253326416
Validation loss: 1.9138227214095413

Epoch: 6| Step: 2
Training loss: 1.9797486066818237
Validation loss: 1.8994267717484505

Epoch: 6| Step: 3
Training loss: 0.7533009052276611
Validation loss: 1.90427137959388

Epoch: 6| Step: 4
Training loss: 1.2859960794448853
Validation loss: 1.9081048529635194

Epoch: 6| Step: 5
Training loss: 0.7686457633972168
Validation loss: 1.9191586753373504

Epoch: 6| Step: 6
Training loss: 1.8729798793792725
Validation loss: 1.946788336641045

Epoch: 6| Step: 7
Training loss: 1.128861904144287
Validation loss: 1.9516262687662596

Epoch: 6| Step: 8
Training loss: 1.454925537109375
Validation loss: 1.9779497026115336

Epoch: 6| Step: 9
Training loss: 0.8699606657028198
Validation loss: 1.997740658380652

Epoch: 6| Step: 10
Training loss: 1.5920002460479736
Validation loss: 1.9923878305701799

Epoch: 6| Step: 11
Training loss: 1.558640956878662
Validation loss: 2.001255376364595

Epoch: 6| Step: 12
Training loss: 2.1062636375427246
Validation loss: 1.9769789634212371

Epoch: 6| Step: 13
Training loss: 1.5696051120758057
Validation loss: 1.9683726154347903

Epoch: 169| Step: 0
Training loss: 2.0949926376342773
Validation loss: 1.9648644513981317

Epoch: 6| Step: 1
Training loss: 1.5174449682235718
Validation loss: 1.9448969171893211

Epoch: 6| Step: 2
Training loss: 1.611112356185913
Validation loss: 1.9244610109636862

Epoch: 6| Step: 3
Training loss: 1.4184560775756836
Validation loss: 1.9444433463517057

Epoch: 6| Step: 4
Training loss: 0.9372392296791077
Validation loss: 1.9746999868782618

Epoch: 6| Step: 5
Training loss: 1.621350884437561
Validation loss: 2.026140066885179

Epoch: 6| Step: 6
Training loss: 1.5271072387695312
Validation loss: 2.040997361624113

Epoch: 6| Step: 7
Training loss: 1.8233546018600464
Validation loss: 2.0602960842911915

Epoch: 6| Step: 8
Training loss: 1.5605319738388062
Validation loss: 2.0437036509154947

Epoch: 6| Step: 9
Training loss: 0.6052064299583435
Validation loss: 1.9079553709235242

Epoch: 6| Step: 10
Training loss: 1.5928550958633423
Validation loss: 1.8612492276776222

Epoch: 6| Step: 11
Training loss: 1.5138041973114014
Validation loss: 1.8573640161944973

Epoch: 6| Step: 12
Training loss: 1.1993954181671143
Validation loss: 1.8938525363963137

Epoch: 6| Step: 13
Training loss: 2.0058109760284424
Validation loss: 1.916040261586507

Epoch: 170| Step: 0
Training loss: 1.6702842712402344
Validation loss: 1.9180098272139026

Epoch: 6| Step: 1
Training loss: 1.5019590854644775
Validation loss: 1.922284504418732

Epoch: 6| Step: 2
Training loss: 1.7818458080291748
Validation loss: 1.898225135700677

Epoch: 6| Step: 3
Training loss: 1.3916065692901611
Validation loss: 1.8555434519244778

Epoch: 6| Step: 4
Training loss: 1.698099970817566
Validation loss: 1.8676066283256776

Epoch: 6| Step: 5
Training loss: 1.6870918273925781
Validation loss: 1.946532513505669

Epoch: 6| Step: 6
Training loss: 1.6007143259048462
Validation loss: 2.085998181373842

Epoch: 6| Step: 7
Training loss: 2.0367369651794434
Validation loss: 2.2169935728913996

Epoch: 6| Step: 8
Training loss: 1.3324421644210815
Validation loss: 2.2009344690589496

Epoch: 6| Step: 9
Training loss: 2.001373767852783
Validation loss: 2.1392357490395986

Epoch: 6| Step: 10
Training loss: 1.8363761901855469
Validation loss: 2.0468664425675587

Epoch: 6| Step: 11
Training loss: 1.097404956817627
Validation loss: 1.9584394283192132

Epoch: 6| Step: 12
Training loss: 1.249424934387207
Validation loss: 1.9404924877228276

Epoch: 6| Step: 13
Training loss: 1.2588448524475098
Validation loss: 1.9360891208853772

Epoch: 171| Step: 0
Training loss: 1.1776683330535889
Validation loss: 1.9138212492389064

Epoch: 6| Step: 1
Training loss: 1.1932191848754883
Validation loss: 1.9136851884985482

Epoch: 6| Step: 2
Training loss: 1.852717399597168
Validation loss: 1.9066411910518524

Epoch: 6| Step: 3
Training loss: 2.0381698608398438
Validation loss: 1.9116865165771977

Epoch: 6| Step: 4
Training loss: 1.741659164428711
Validation loss: 1.887396336883627

Epoch: 6| Step: 5
Training loss: 1.903846025466919
Validation loss: 1.8799298604329426

Epoch: 6| Step: 6
Training loss: 1.4036355018615723
Validation loss: 1.8830300351624847

Epoch: 6| Step: 7
Training loss: 0.9701659679412842
Validation loss: 1.9095071464456537

Epoch: 6| Step: 8
Training loss: 1.1722023487091064
Validation loss: 1.8990389429112917

Epoch: 6| Step: 9
Training loss: 1.6786918640136719
Validation loss: 1.93349237467653

Epoch: 6| Step: 10
Training loss: 1.0958285331726074
Validation loss: 1.9240476469839773

Epoch: 6| Step: 11
Training loss: 1.289559245109558
Validation loss: 1.9328859288205382

Epoch: 6| Step: 12
Training loss: 1.4441375732421875
Validation loss: 1.9361274703856437

Epoch: 6| Step: 13
Training loss: 0.9493598937988281
Validation loss: 1.9409539584190614

Epoch: 172| Step: 0
Training loss: 1.9010740518569946
Validation loss: 1.9366194855782293

Epoch: 6| Step: 1
Training loss: 1.699714183807373
Validation loss: 1.9484963904144943

Epoch: 6| Step: 2
Training loss: 1.2888925075531006
Validation loss: 1.9325336871608612

Epoch: 6| Step: 3
Training loss: 0.9145689010620117
Validation loss: 1.9525682221176803

Epoch: 6| Step: 4
Training loss: 1.1220717430114746
Validation loss: 1.9432433266793527

Epoch: 6| Step: 5
Training loss: 1.281714677810669
Validation loss: 1.922694262637887

Epoch: 6| Step: 6
Training loss: 1.0578713417053223
Validation loss: 1.9310894435451877

Epoch: 6| Step: 7
Training loss: 1.7897558212280273
Validation loss: 1.94221931247301

Epoch: 6| Step: 8
Training loss: 0.8069144487380981
Validation loss: 1.9233887964679348

Epoch: 6| Step: 9
Training loss: 1.155113697052002
Validation loss: 1.8955824695607668

Epoch: 6| Step: 10
Training loss: 1.5244030952453613
Validation loss: 1.8756482626802178

Epoch: 6| Step: 11
Training loss: 1.6874701976776123
Validation loss: 1.8415152475398073

Epoch: 6| Step: 12
Training loss: 1.0502500534057617
Validation loss: 1.8609320284217916

Epoch: 6| Step: 13
Training loss: 1.6563485860824585
Validation loss: 1.8603295331360192

Epoch: 173| Step: 0
Training loss: 1.1686525344848633
Validation loss: 1.849129617855113

Epoch: 6| Step: 1
Training loss: 1.473660945892334
Validation loss: 1.8419378880531556

Epoch: 6| Step: 2
Training loss: 1.6325230598449707
Validation loss: 1.8593921648558749

Epoch: 6| Step: 3
Training loss: 1.321584939956665
Validation loss: 1.8635373807722522

Epoch: 6| Step: 4
Training loss: 1.452897310256958
Validation loss: 1.8947364630237702

Epoch: 6| Step: 5
Training loss: 1.1852331161499023
Validation loss: 1.90750749393176

Epoch: 6| Step: 6
Training loss: 1.246289610862732
Validation loss: 1.9054922493555213

Epoch: 6| Step: 7
Training loss: 1.3426178693771362
Validation loss: 1.9354460957229778

Epoch: 6| Step: 8
Training loss: 1.1879922151565552
Validation loss: 1.9381688512781614

Epoch: 6| Step: 9
Training loss: 1.0837006568908691
Validation loss: 1.9131015654533141

Epoch: 6| Step: 10
Training loss: 1.1311607360839844
Validation loss: 1.9099137193413191

Epoch: 6| Step: 11
Training loss: 1.549204707145691
Validation loss: 1.9059614878828808

Epoch: 6| Step: 12
Training loss: 1.2531795501708984
Validation loss: 1.8704142596132012

Epoch: 6| Step: 13
Training loss: 1.6267530918121338
Validation loss: 1.8822356654751686

Epoch: 174| Step: 0
Training loss: 1.6022992134094238
Validation loss: 1.860889204086796

Epoch: 6| Step: 1
Training loss: 1.3816964626312256
Validation loss: 1.843654449268054

Epoch: 6| Step: 2
Training loss: 0.934807300567627
Validation loss: 1.8687655284840574

Epoch: 6| Step: 3
Training loss: 1.2587652206420898
Validation loss: 1.8956969886697748

Epoch: 6| Step: 4
Training loss: 1.5383175611495972
Validation loss: 1.9127940080499137

Epoch: 6| Step: 5
Training loss: 0.7535030841827393
Validation loss: 1.9214485140256985

Epoch: 6| Step: 6
Training loss: 1.2527990341186523
Validation loss: 1.907898599101651

Epoch: 6| Step: 7
Training loss: 1.172384262084961
Validation loss: 1.893560331354859

Epoch: 6| Step: 8
Training loss: 1.2471153736114502
Validation loss: 1.9024142962630077

Epoch: 6| Step: 9
Training loss: 1.800994634628296
Validation loss: 1.891816851913288

Epoch: 6| Step: 10
Training loss: 1.2773276567459106
Validation loss: 1.8963436644564393

Epoch: 6| Step: 11
Training loss: 0.9632090330123901
Validation loss: 1.9097748277007893

Epoch: 6| Step: 12
Training loss: 1.7837294340133667
Validation loss: 1.9025600135967295

Epoch: 6| Step: 13
Training loss: 0.6961837410926819
Validation loss: 1.9001384986344205

Epoch: 175| Step: 0
Training loss: 1.4762099981307983
Validation loss: 1.8743289491181732

Epoch: 6| Step: 1
Training loss: 1.6494134664535522
Validation loss: 1.8798089155586817

Epoch: 6| Step: 2
Training loss: 1.5269393920898438
Validation loss: 1.9025816763600996

Epoch: 6| Step: 3
Training loss: 1.3691282272338867
Validation loss: 1.9088725325881795

Epoch: 6| Step: 4
Training loss: 1.0843887329101562
Validation loss: 1.9082134385262766

Epoch: 6| Step: 5
Training loss: 1.9116017818450928
Validation loss: 1.930704011712023

Epoch: 6| Step: 6
Training loss: 1.315856695175171
Validation loss: 1.9356075615011237

Epoch: 6| Step: 7
Training loss: 0.9477531313896179
Validation loss: 1.943286689378882

Epoch: 6| Step: 8
Training loss: 0.7172441482543945
Validation loss: 1.924998462841075

Epoch: 6| Step: 9
Training loss: 1.5540850162506104
Validation loss: 1.9141562061925088

Epoch: 6| Step: 10
Training loss: 0.9160175919532776
Validation loss: 1.8943867862865489

Epoch: 6| Step: 11
Training loss: 0.6167171001434326
Validation loss: 1.8685743911291963

Epoch: 6| Step: 12
Training loss: 1.734337329864502
Validation loss: 1.8651378782846595

Epoch: 6| Step: 13
Training loss: 1.154563546180725
Validation loss: 1.8606867303130448

Epoch: 176| Step: 0
Training loss: 1.340640902519226
Validation loss: 1.867554259556596

Epoch: 6| Step: 1
Training loss: 1.6251893043518066
Validation loss: 1.8767886597623107

Epoch: 6| Step: 2
Training loss: 0.7933197021484375
Validation loss: 1.9028989256069224

Epoch: 6| Step: 3
Training loss: 1.5121970176696777
Validation loss: 1.8932024413539517

Epoch: 6| Step: 4
Training loss: 1.3357925415039062
Validation loss: 1.941806012584317

Epoch: 6| Step: 5
Training loss: 1.34852933883667
Validation loss: 1.90916234062564

Epoch: 6| Step: 6
Training loss: 1.2011406421661377
Validation loss: 1.9047440867270193

Epoch: 6| Step: 7
Training loss: 1.0068563222885132
Validation loss: 1.8739679680075696

Epoch: 6| Step: 8
Training loss: 1.3093235492706299
Validation loss: 1.891343903797929

Epoch: 6| Step: 9
Training loss: 1.4764755964279175
Validation loss: 1.8749529853943856

Epoch: 6| Step: 10
Training loss: 1.565035104751587
Validation loss: 1.8858892276722898

Epoch: 6| Step: 11
Training loss: 1.2113101482391357
Validation loss: 1.917740684683605

Epoch: 6| Step: 12
Training loss: 1.341654896736145
Validation loss: 1.922896877411873

Epoch: 6| Step: 13
Training loss: 0.9499686360359192
Validation loss: 1.9405020590751403

Epoch: 177| Step: 0
Training loss: 1.6979100704193115
Validation loss: 1.9443553698960172

Epoch: 6| Step: 1
Training loss: 0.7526148557662964
Validation loss: 1.9309618755053448

Epoch: 6| Step: 2
Training loss: 0.9865016341209412
Validation loss: 1.9214782458479687

Epoch: 6| Step: 3
Training loss: 1.0716757774353027
Validation loss: 1.876708371664888

Epoch: 6| Step: 4
Training loss: 1.172892451286316
Validation loss: 1.837053176536355

Epoch: 6| Step: 5
Training loss: 1.4495354890823364
Validation loss: 1.8424307082289009

Epoch: 6| Step: 6
Training loss: 1.7630672454833984
Validation loss: 1.8349621462565597

Epoch: 6| Step: 7
Training loss: 0.8924808502197266
Validation loss: 1.8265435772557412

Epoch: 6| Step: 8
Training loss: 1.573437213897705
Validation loss: 1.8662476821612286

Epoch: 6| Step: 9
Training loss: 1.3571128845214844
Validation loss: 1.9380971052313363

Epoch: 6| Step: 10
Training loss: 1.3373627662658691
Validation loss: 2.020199143117474

Epoch: 6| Step: 11
Training loss: 1.9544306993484497
Validation loss: 2.1143048142874115

Epoch: 6| Step: 12
Training loss: 1.74241304397583
Validation loss: 2.1968568448097474

Epoch: 6| Step: 13
Training loss: 1.517934799194336
Validation loss: 2.1678801480159966

Epoch: 178| Step: 0
Training loss: 2.270028591156006
Validation loss: 2.1412034406456897

Epoch: 6| Step: 1
Training loss: 1.115891456604004
Validation loss: 2.024969744425948

Epoch: 6| Step: 2
Training loss: 1.4226632118225098
Validation loss: 1.9657416061688495

Epoch: 6| Step: 3
Training loss: 1.1158320903778076
Validation loss: 1.896218947184983

Epoch: 6| Step: 4
Training loss: 1.306770920753479
Validation loss: 1.841010973017703

Epoch: 6| Step: 5
Training loss: 1.0336058139801025
Validation loss: 1.8453440307289042

Epoch: 6| Step: 6
Training loss: 1.3140976428985596
Validation loss: 1.831398525545674

Epoch: 6| Step: 7
Training loss: 1.7320218086242676
Validation loss: 1.8207017465304303

Epoch: 6| Step: 8
Training loss: 1.3815107345581055
Validation loss: 1.803031627849866

Epoch: 6| Step: 9
Training loss: 0.9950900077819824
Validation loss: 1.7999590135389758

Epoch: 6| Step: 10
Training loss: 1.3694130182266235
Validation loss: 1.864714071314822

Epoch: 6| Step: 11
Training loss: 1.4646656513214111
Validation loss: 1.9481434386263612

Epoch: 6| Step: 12
Training loss: 1.2585349082946777
Validation loss: 1.944520649089608

Epoch: 6| Step: 13
Training loss: 2.3842127323150635
Validation loss: 1.9692759642037012

Epoch: 179| Step: 0
Training loss: 1.0392135381698608
Validation loss: 1.9499501464187459

Epoch: 6| Step: 1
Training loss: 1.179748296737671
Validation loss: 1.8800732858719365

Epoch: 6| Step: 2
Training loss: 1.5756711959838867
Validation loss: 1.8218834528359034

Epoch: 6| Step: 3
Training loss: 1.9049054384231567
Validation loss: 1.8060567225179365

Epoch: 6| Step: 4
Training loss: 1.0820038318634033
Validation loss: 1.8284435554217267

Epoch: 6| Step: 5
Training loss: 1.1376988887786865
Validation loss: 1.82719208604546

Epoch: 6| Step: 6
Training loss: 0.7159260511398315
Validation loss: 1.8394926978695778

Epoch: 6| Step: 7
Training loss: 0.7881971001625061
Validation loss: 1.8365486539820188

Epoch: 6| Step: 8
Training loss: 1.4521031379699707
Validation loss: 1.841297790568362

Epoch: 6| Step: 9
Training loss: 1.1982214450836182
Validation loss: 1.8597682163279543

Epoch: 6| Step: 10
Training loss: 1.756084680557251
Validation loss: 1.8763718271768222

Epoch: 6| Step: 11
Training loss: 1.470510721206665
Validation loss: 1.8977042141781058

Epoch: 6| Step: 12
Training loss: 1.1032514572143555
Validation loss: 1.8852866798318841

Epoch: 6| Step: 13
Training loss: 1.6398557424545288
Validation loss: 1.8755360905842116

Epoch: 180| Step: 0
Training loss: 1.0572657585144043
Validation loss: 1.8609458323447936

Epoch: 6| Step: 1
Training loss: 1.1766972541809082
Validation loss: 1.8589977423350017

Epoch: 6| Step: 2
Training loss: 0.8476805090904236
Validation loss: 1.8329953044973395

Epoch: 6| Step: 3
Training loss: 1.2430236339569092
Validation loss: 1.8238275384390226

Epoch: 6| Step: 4
Training loss: 1.2512853145599365
Validation loss: 1.8305353772255681

Epoch: 6| Step: 5
Training loss: 0.7335033416748047
Validation loss: 1.8440521429943781

Epoch: 6| Step: 6
Training loss: 1.6360626220703125
Validation loss: 1.8611130009415329

Epoch: 6| Step: 7
Training loss: 1.066550612449646
Validation loss: 1.864729860777496

Epoch: 6| Step: 8
Training loss: 1.7379647493362427
Validation loss: 1.862747005237046

Epoch: 6| Step: 9
Training loss: 1.8866920471191406
Validation loss: 1.8703910945564188

Epoch: 6| Step: 10
Training loss: 0.9312376379966736
Validation loss: 1.8485667167171356

Epoch: 6| Step: 11
Training loss: 0.9594330787658691
Validation loss: 1.8330922267770255

Epoch: 6| Step: 12
Training loss: 1.6121573448181152
Validation loss: 1.8178637258468135

Epoch: 6| Step: 13
Training loss: 1.3161771297454834
Validation loss: 1.81954010071293

Epoch: 181| Step: 0
Training loss: 1.4784754514694214
Validation loss: 1.8220936136861001

Epoch: 6| Step: 1
Training loss: 1.140293002128601
Validation loss: 1.8107759311635008

Epoch: 6| Step: 2
Training loss: 1.193140983581543
Validation loss: 1.8018927612612325

Epoch: 6| Step: 3
Training loss: 1.0902228355407715
Validation loss: 1.8142808034855833

Epoch: 6| Step: 4
Training loss: 1.6892653703689575
Validation loss: 1.8362486490639307

Epoch: 6| Step: 5
Training loss: 1.0594182014465332
Validation loss: 1.8782574463916082

Epoch: 6| Step: 6
Training loss: 1.2562685012817383
Validation loss: 1.8888734027903566

Epoch: 6| Step: 7
Training loss: 1.6435683965682983
Validation loss: 1.894686596367949

Epoch: 6| Step: 8
Training loss: 0.7330160737037659
Validation loss: 1.893135546356119

Epoch: 6| Step: 9
Training loss: 0.7620604038238525
Validation loss: 1.8930544930119668

Epoch: 6| Step: 10
Training loss: 1.4261384010314941
Validation loss: 1.8524414403464204

Epoch: 6| Step: 11
Training loss: 1.0081579685211182
Validation loss: 1.839881814936156

Epoch: 6| Step: 12
Training loss: 1.5000667572021484
Validation loss: 1.8322359567047448

Epoch: 6| Step: 13
Training loss: 0.6650916337966919
Validation loss: 1.8445602924593034

Epoch: 182| Step: 0
Training loss: 0.9635021686553955
Validation loss: 1.8237978642986667

Epoch: 6| Step: 1
Training loss: 1.294872522354126
Validation loss: 1.8437590509332635

Epoch: 6| Step: 2
Training loss: 1.1880297660827637
Validation loss: 1.8451325355037567

Epoch: 6| Step: 3
Training loss: 1.3177039623260498
Validation loss: 1.8344095265993507

Epoch: 6| Step: 4
Training loss: 1.2050362825393677
Validation loss: 1.8396734704253495

Epoch: 6| Step: 5
Training loss: 1.4567079544067383
Validation loss: 1.8185284855545207

Epoch: 6| Step: 6
Training loss: 0.9294013381004333
Validation loss: 1.8095187884505077

Epoch: 6| Step: 7
Training loss: 1.2228899002075195
Validation loss: 1.821863152647531

Epoch: 6| Step: 8
Training loss: 1.2074381113052368
Validation loss: 1.8171111409382155

Epoch: 6| Step: 9
Training loss: 0.9226065278053284
Validation loss: 1.8216029623503327

Epoch: 6| Step: 10
Training loss: 1.3605647087097168
Validation loss: 1.8219916948708155

Epoch: 6| Step: 11
Training loss: 1.695597767829895
Validation loss: 1.8346869112342916

Epoch: 6| Step: 12
Training loss: 0.905052125453949
Validation loss: 1.8371708149551063

Epoch: 6| Step: 13
Training loss: 1.0525661706924438
Validation loss: 1.8313705651990828

Epoch: 183| Step: 0
Training loss: 1.1988770961761475
Validation loss: 1.8355829574728524

Epoch: 6| Step: 1
Training loss: 1.4644266366958618
Validation loss: 1.8348171723786222

Epoch: 6| Step: 2
Training loss: 1.3256983757019043
Validation loss: 1.8284859849560646

Epoch: 6| Step: 3
Training loss: 1.0717625617980957
Validation loss: 1.8476043183316466

Epoch: 6| Step: 4
Training loss: 0.7082729339599609
Validation loss: 1.842252395486319

Epoch: 6| Step: 5
Training loss: 1.164245367050171
Validation loss: 1.836241388833651

Epoch: 6| Step: 6
Training loss: 0.6814513206481934
Validation loss: 1.826815197544713

Epoch: 6| Step: 7
Training loss: 1.088211178779602
Validation loss: 1.8202916165833831

Epoch: 6| Step: 8
Training loss: 1.4461618661880493
Validation loss: 1.816153331469464

Epoch: 6| Step: 9
Training loss: 1.0432875156402588
Validation loss: 1.8418084562465709

Epoch: 6| Step: 10
Training loss: 1.7136461734771729
Validation loss: 1.829692458593717

Epoch: 6| Step: 11
Training loss: 1.01743483543396
Validation loss: 1.846055753769413

Epoch: 6| Step: 12
Training loss: 1.0651004314422607
Validation loss: 1.8478606285587433

Epoch: 6| Step: 13
Training loss: 0.977763295173645
Validation loss: 1.8503673230448077

Epoch: 184| Step: 0
Training loss: 1.3231620788574219
Validation loss: 1.85094032877235

Epoch: 6| Step: 1
Training loss: 1.045906901359558
Validation loss: 1.8556099399443595

Epoch: 6| Step: 2
Training loss: 0.9002354145050049
Validation loss: 1.8698891234654251

Epoch: 6| Step: 3
Training loss: 1.488088607788086
Validation loss: 1.8546041045137631

Epoch: 6| Step: 4
Training loss: 1.069840669631958
Validation loss: 1.8333750873483636

Epoch: 6| Step: 5
Training loss: 1.525303840637207
Validation loss: 1.8258291482925415

Epoch: 6| Step: 6
Training loss: 1.853658676147461
Validation loss: 1.815338203983922

Epoch: 6| Step: 7
Training loss: 0.620728611946106
Validation loss: 1.8216325672723914

Epoch: 6| Step: 8
Training loss: 0.862520694732666
Validation loss: 1.8057590146218576

Epoch: 6| Step: 9
Training loss: 0.8655787110328674
Validation loss: 1.867983046398368

Epoch: 6| Step: 10
Training loss: 1.4552470445632935
Validation loss: 1.9060328301563059

Epoch: 6| Step: 11
Training loss: 1.4190970659255981
Validation loss: 1.8987349771684217

Epoch: 6| Step: 12
Training loss: 0.9225906729698181
Validation loss: 1.8708864386363695

Epoch: 6| Step: 13
Training loss: 1.1616698503494263
Validation loss: 1.825244116526778

Epoch: 185| Step: 0
Training loss: 0.9528614282608032
Validation loss: 1.7945830463081278

Epoch: 6| Step: 1
Training loss: 0.7859331369400024
Validation loss: 1.7917577079547349

Epoch: 6| Step: 2
Training loss: 1.376106858253479
Validation loss: 1.7904049837461082

Epoch: 6| Step: 3
Training loss: 0.5626661777496338
Validation loss: 1.7841408021988407

Epoch: 6| Step: 4
Training loss: 1.1350501775741577
Validation loss: 1.7952106844994329

Epoch: 6| Step: 5
Training loss: 1.3521102666854858
Validation loss: 1.80391320490068

Epoch: 6| Step: 6
Training loss: 1.1478601694107056
Validation loss: 1.7881837737175725

Epoch: 6| Step: 7
Training loss: 1.3102266788482666
Validation loss: 1.790736606044154

Epoch: 6| Step: 8
Training loss: 1.1062569618225098
Validation loss: 1.8345478298843547

Epoch: 6| Step: 9
Training loss: 0.8652364015579224
Validation loss: 1.802225928152761

Epoch: 6| Step: 10
Training loss: 1.098658561706543
Validation loss: 1.8155949243935205

Epoch: 6| Step: 11
Training loss: 1.647073745727539
Validation loss: 1.824704106136035

Epoch: 6| Step: 12
Training loss: 1.0469653606414795
Validation loss: 1.839628965623917

Epoch: 6| Step: 13
Training loss: 1.431485652923584
Validation loss: 1.8404014700202531

Epoch: 186| Step: 0
Training loss: 0.9399653077125549
Validation loss: 1.853873473341747

Epoch: 6| Step: 1
Training loss: 0.9430751800537109
Validation loss: 1.8454607404688352

Epoch: 6| Step: 2
Training loss: 1.1174676418304443
Validation loss: 1.8516981576078682

Epoch: 6| Step: 3
Training loss: 1.397390604019165
Validation loss: 1.8589253746053225

Epoch: 6| Step: 4
Training loss: 1.282658576965332
Validation loss: 1.8417664048492268

Epoch: 6| Step: 5
Training loss: 0.7029706239700317
Validation loss: 1.8203811869826367

Epoch: 6| Step: 6
Training loss: 1.2142815589904785
Validation loss: 1.8386275050460652

Epoch: 6| Step: 7
Training loss: 1.0396714210510254
Validation loss: 1.8227677717003772

Epoch: 6| Step: 8
Training loss: 1.3193275928497314
Validation loss: 1.8073284446552236

Epoch: 6| Step: 9
Training loss: 1.6442546844482422
Validation loss: 1.8165741825616488

Epoch: 6| Step: 10
Training loss: 1.1311061382293701
Validation loss: 1.7809933141995502

Epoch: 6| Step: 11
Training loss: 0.9258458018302917
Validation loss: 1.7944031633356565

Epoch: 6| Step: 12
Training loss: 0.586267352104187
Validation loss: 1.7833034620490125

Epoch: 6| Step: 13
Training loss: 1.2733439207077026
Validation loss: 1.7975149667391213

Epoch: 187| Step: 0
Training loss: 1.3920080661773682
Validation loss: 1.8064653476079304

Epoch: 6| Step: 1
Training loss: 1.0822570323944092
Validation loss: 1.8034272988637288

Epoch: 6| Step: 2
Training loss: 1.2033193111419678
Validation loss: 1.8225819603089364

Epoch: 6| Step: 3
Training loss: 1.0633951425552368
Validation loss: 1.8632111895468928

Epoch: 6| Step: 4
Training loss: 0.7939460277557373
Validation loss: 1.8577134929677492

Epoch: 6| Step: 5
Training loss: 1.5187962055206299
Validation loss: 1.8462465693873744

Epoch: 6| Step: 6
Training loss: 0.9479514956474304
Validation loss: 1.8256402528414162

Epoch: 6| Step: 7
Training loss: 1.477031946182251
Validation loss: 1.8160594304402669

Epoch: 6| Step: 8
Training loss: 1.4694100618362427
Validation loss: 1.7944534504285423

Epoch: 6| Step: 9
Training loss: 0.9809790253639221
Validation loss: 1.820756362330529

Epoch: 6| Step: 10
Training loss: 1.3797760009765625
Validation loss: 1.8133843509099816

Epoch: 6| Step: 11
Training loss: 1.065180778503418
Validation loss: 1.7916270199642386

Epoch: 6| Step: 12
Training loss: 0.7734935283660889
Validation loss: 1.8070567192569855

Epoch: 6| Step: 13
Training loss: 0.7468911409378052
Validation loss: 1.8038899411437332

Epoch: 188| Step: 0
Training loss: 0.9990079998970032
Validation loss: 1.8085436064709899

Epoch: 6| Step: 1
Training loss: 1.184058427810669
Validation loss: 1.8327425910580544

Epoch: 6| Step: 2
Training loss: 1.1432145833969116
Validation loss: 1.8158069374740764

Epoch: 6| Step: 3
Training loss: 1.2864925861358643
Validation loss: 1.8037446493743567

Epoch: 6| Step: 4
Training loss: 1.4167242050170898
Validation loss: 1.7888166507085164

Epoch: 6| Step: 5
Training loss: 0.8591561317443848
Validation loss: 1.7850174160413845

Epoch: 6| Step: 6
Training loss: 0.9364428520202637
Validation loss: 1.7931552587016937

Epoch: 6| Step: 7
Training loss: 1.0824564695358276
Validation loss: 1.7951708942331293

Epoch: 6| Step: 8
Training loss: 1.0391123294830322
Validation loss: 1.7820453848890079

Epoch: 6| Step: 9
Training loss: 0.7071977853775024
Validation loss: 1.783673309510754

Epoch: 6| Step: 10
Training loss: 1.969672679901123
Validation loss: 1.7897482905336606

Epoch: 6| Step: 11
Training loss: 0.9268025159835815
Validation loss: 1.80644856473451

Epoch: 6| Step: 12
Training loss: 0.35267531871795654
Validation loss: 1.8061917776702552

Epoch: 6| Step: 13
Training loss: 1.3044520616531372
Validation loss: 1.8081030589278027

Epoch: 189| Step: 0
Training loss: 0.9261140823364258
Validation loss: 1.8077534462815972

Epoch: 6| Step: 1
Training loss: 1.2052171230316162
Validation loss: 1.8186923675639655

Epoch: 6| Step: 2
Training loss: 1.4775370359420776
Validation loss: 1.791893333517095

Epoch: 6| Step: 3
Training loss: 0.6914235353469849
Validation loss: 1.7976435653624996

Epoch: 6| Step: 4
Training loss: 1.2950259447097778
Validation loss: 1.8073217753441102

Epoch: 6| Step: 5
Training loss: 1.1137721538543701
Validation loss: 1.8069894416357881

Epoch: 6| Step: 6
Training loss: 0.6385959386825562
Validation loss: 1.7921339901544715

Epoch: 6| Step: 7
Training loss: 1.0187125205993652
Validation loss: 1.8118331868161437

Epoch: 6| Step: 8
Training loss: 1.632968783378601
Validation loss: 1.803112268447876

Epoch: 6| Step: 9
Training loss: 1.1648145914077759
Validation loss: 1.8138538406741234

Epoch: 6| Step: 10
Training loss: 0.6866523623466492
Validation loss: 1.8221175439896122

Epoch: 6| Step: 11
Training loss: 1.1556246280670166
Validation loss: 1.8099980251763457

Epoch: 6| Step: 12
Training loss: 1.208312749862671
Validation loss: 1.8138013655139553

Epoch: 6| Step: 13
Training loss: 0.6611426472663879
Validation loss: 1.806065164586549

Epoch: 190| Step: 0
Training loss: 1.134101390838623
Validation loss: 1.7948538129047682

Epoch: 6| Step: 1
Training loss: 0.8212658166885376
Validation loss: 1.8058494572998376

Epoch: 6| Step: 2
Training loss: 1.3501108884811401
Validation loss: 1.8148424369032665

Epoch: 6| Step: 3
Training loss: 0.6254245638847351
Validation loss: 1.805725512966033

Epoch: 6| Step: 4
Training loss: 1.2040801048278809
Validation loss: 1.7864522818596131

Epoch: 6| Step: 5
Training loss: 1.1863998174667358
Validation loss: 1.775619282517382

Epoch: 6| Step: 6
Training loss: 1.1721100807189941
Validation loss: 1.7561916446173063

Epoch: 6| Step: 7
Training loss: 1.3018128871917725
Validation loss: 1.7493904521388393

Epoch: 6| Step: 8
Training loss: 1.5148191452026367
Validation loss: 1.7884185185996435

Epoch: 6| Step: 9
Training loss: 0.9753154516220093
Validation loss: 1.7569653718702254

Epoch: 6| Step: 10
Training loss: 1.223315954208374
Validation loss: 1.7692714993671705

Epoch: 6| Step: 11
Training loss: 0.9052847623825073
Validation loss: 1.7731272841012606

Epoch: 6| Step: 12
Training loss: 0.8820552825927734
Validation loss: 1.7639514630840671

Epoch: 6| Step: 13
Training loss: 0.3613450229167938
Validation loss: 1.7768707749664143

Epoch: 191| Step: 0
Training loss: 1.3993821144104004
Validation loss: 1.7851657931522658

Epoch: 6| Step: 1
Training loss: 1.1775444746017456
Validation loss: 1.7811850194008119

Epoch: 6| Step: 2
Training loss: 0.8114789724349976
Validation loss: 1.800372059627246

Epoch: 6| Step: 3
Training loss: 1.6477892398834229
Validation loss: 1.8069515587181173

Epoch: 6| Step: 4
Training loss: 0.713019847869873
Validation loss: 1.7751219618705012

Epoch: 6| Step: 5
Training loss: 1.1068904399871826
Validation loss: 1.7942329747702486

Epoch: 6| Step: 6
Training loss: 0.7575783133506775
Validation loss: 1.7747014543061614

Epoch: 6| Step: 7
Training loss: 0.820014238357544
Validation loss: 1.772741517712993

Epoch: 6| Step: 8
Training loss: 1.0343669652938843
Validation loss: 1.785629064806046

Epoch: 6| Step: 9
Training loss: 1.02931809425354
Validation loss: 1.7861670268479215

Epoch: 6| Step: 10
Training loss: 1.3947362899780273
Validation loss: 1.7939049300327097

Epoch: 6| Step: 11
Training loss: 0.795169472694397
Validation loss: 1.7986429263186712

Epoch: 6| Step: 12
Training loss: 1.1783710718154907
Validation loss: 1.8050267183652489

Epoch: 6| Step: 13
Training loss: 0.9956735968589783
Validation loss: 1.7979358767950406

Epoch: 192| Step: 0
Training loss: 0.8758866786956787
Validation loss: 1.7871925420658563

Epoch: 6| Step: 1
Training loss: 1.1153440475463867
Validation loss: 1.7836910960494832

Epoch: 6| Step: 2
Training loss: 1.263014793395996
Validation loss: 1.7757682902838594

Epoch: 6| Step: 3
Training loss: 1.0777969360351562
Validation loss: 1.784024480850466

Epoch: 6| Step: 4
Training loss: 0.6365118622779846
Validation loss: 1.7700734369216427

Epoch: 6| Step: 5
Training loss: 0.7840676307678223
Validation loss: 1.7646431538366503

Epoch: 6| Step: 6
Training loss: 1.1224604845046997
Validation loss: 1.7697772390098983

Epoch: 6| Step: 7
Training loss: 1.2094676494598389
Validation loss: 1.7799416485653128

Epoch: 6| Step: 8
Training loss: 1.1906795501708984
Validation loss: 1.7986626830152286

Epoch: 6| Step: 9
Training loss: 1.013411045074463
Validation loss: 1.7976128055203346

Epoch: 6| Step: 10
Training loss: 0.9080336093902588
Validation loss: 1.8118807577317761

Epoch: 6| Step: 11
Training loss: 1.1418440341949463
Validation loss: 1.8306770324707031

Epoch: 6| Step: 12
Training loss: 0.8603857755661011
Validation loss: 1.8136594000683035

Epoch: 6| Step: 13
Training loss: 1.4875839948654175
Validation loss: 1.769359193822389

Epoch: 193| Step: 0
Training loss: 1.0460379123687744
Validation loss: 1.7529267252132457

Epoch: 6| Step: 1
Training loss: 0.871473491191864
Validation loss: 1.7783914868549635

Epoch: 6| Step: 2
Training loss: 1.177355408668518
Validation loss: 1.7875948516271447

Epoch: 6| Step: 3
Training loss: 1.2175546884536743
Validation loss: 1.795817591810739

Epoch: 6| Step: 4
Training loss: 0.6374325156211853
Validation loss: 1.7845584961675829

Epoch: 6| Step: 5
Training loss: 0.7138928771018982
Validation loss: 1.795649923304076

Epoch: 6| Step: 6
Training loss: 0.5758388638496399
Validation loss: 1.779336146769985

Epoch: 6| Step: 7
Training loss: 0.8942368626594543
Validation loss: 1.7716353272878995

Epoch: 6| Step: 8
Training loss: 1.4781255722045898
Validation loss: 1.7712340072918964

Epoch: 6| Step: 9
Training loss: 1.3960189819335938
Validation loss: 1.7824232014276649

Epoch: 6| Step: 10
Training loss: 1.1241745948791504
Validation loss: 1.768450261444174

Epoch: 6| Step: 11
Training loss: 0.8822944164276123
Validation loss: 1.768164469349769

Epoch: 6| Step: 12
Training loss: 1.3116662502288818
Validation loss: 1.7778383826696744

Epoch: 6| Step: 13
Training loss: 0.8467784523963928
Validation loss: 1.7607113238303893

Epoch: 194| Step: 0
Training loss: 0.7749193906784058
Validation loss: 1.7604720823226436

Epoch: 6| Step: 1
Training loss: 1.3301703929901123
Validation loss: 1.7805771725152129

Epoch: 6| Step: 2
Training loss: 0.9980963468551636
Validation loss: 1.76990633626138

Epoch: 6| Step: 3
Training loss: 0.946099579334259
Validation loss: 1.7829177251426123

Epoch: 6| Step: 4
Training loss: 1.0565032958984375
Validation loss: 1.7813432370462725

Epoch: 6| Step: 5
Training loss: 1.3099393844604492
Validation loss: 1.786498433800154

Epoch: 6| Step: 6
Training loss: 1.491147518157959
Validation loss: 1.7690225378159554

Epoch: 6| Step: 7
Training loss: 0.5355918407440186
Validation loss: 1.7868100648285241

Epoch: 6| Step: 8
Training loss: 1.4955861568450928
Validation loss: 1.8318152966037873

Epoch: 6| Step: 9
Training loss: 0.7393398284912109
Validation loss: 1.8438258068535918

Epoch: 6| Step: 10
Training loss: 0.9200584888458252
Validation loss: 1.8390977087841238

Epoch: 6| Step: 11
Training loss: 1.1984366178512573
Validation loss: 1.8460898078897947

Epoch: 6| Step: 12
Training loss: 0.6916927099227905
Validation loss: 1.8246936413549608

Epoch: 6| Step: 13
Training loss: 1.1672329902648926
Validation loss: 1.8084082706000215

Epoch: 195| Step: 0
Training loss: 0.9035444259643555
Validation loss: 1.7951257933852494

Epoch: 6| Step: 1
Training loss: 0.90647292137146
Validation loss: 1.7990985096141856

Epoch: 6| Step: 2
Training loss: 0.8629753589630127
Validation loss: 1.7895450950950704

Epoch: 6| Step: 3
Training loss: 0.9724304676055908
Validation loss: 1.7819893052501063

Epoch: 6| Step: 4
Training loss: 0.9664019346237183
Validation loss: 1.7590684801019647

Epoch: 6| Step: 5
Training loss: 0.9455564022064209
Validation loss: 1.782425271567478

Epoch: 6| Step: 6
Training loss: 1.8629162311553955
Validation loss: 1.7636539833520049

Epoch: 6| Step: 7
Training loss: 1.0730540752410889
Validation loss: 1.7605248907560944

Epoch: 6| Step: 8
Training loss: 0.9405205249786377
Validation loss: 1.768978407306056

Epoch: 6| Step: 9
Training loss: 0.6858415007591248
Validation loss: 1.7553947010347921

Epoch: 6| Step: 10
Training loss: 0.6550747156143188
Validation loss: 1.782836628216569

Epoch: 6| Step: 11
Training loss: 1.3379812240600586
Validation loss: 1.759372539417718

Epoch: 6| Step: 12
Training loss: 0.9948070645332336
Validation loss: 1.7767518874137633

Epoch: 6| Step: 13
Training loss: 0.9290012717247009
Validation loss: 1.765719404784582

Epoch: 196| Step: 0
Training loss: 0.8658133745193481
Validation loss: 1.766045311445831

Epoch: 6| Step: 1
Training loss: 1.3316527605056763
Validation loss: 1.7812831401824951

Epoch: 6| Step: 2
Training loss: 0.9787917137145996
Validation loss: 1.7558542105459398

Epoch: 6| Step: 3
Training loss: 1.2896678447723389
Validation loss: 1.7660569407606637

Epoch: 6| Step: 4
Training loss: 1.0753984451293945
Validation loss: 1.7604962779629616

Epoch: 6| Step: 5
Training loss: 0.8747527599334717
Validation loss: 1.7737665343028244

Epoch: 6| Step: 6
Training loss: 0.9923361539840698
Validation loss: 1.7547110511410622

Epoch: 6| Step: 7
Training loss: 1.3872584104537964
Validation loss: 1.766284328635021

Epoch: 6| Step: 8
Training loss: 0.8425306677818298
Validation loss: 1.7491930607826478

Epoch: 6| Step: 9
Training loss: 0.9821637272834778
Validation loss: 1.7604902175164991

Epoch: 6| Step: 10
Training loss: 0.5560120344161987
Validation loss: 1.762217188394198

Epoch: 6| Step: 11
Training loss: 1.4045668840408325
Validation loss: 1.8075113347781602

Epoch: 6| Step: 12
Training loss: 0.821501612663269
Validation loss: 1.819644530614217

Epoch: 6| Step: 13
Training loss: 0.7132404446601868
Validation loss: 1.8375613791968233

Epoch: 197| Step: 0
Training loss: 1.1434684991836548
Validation loss: 1.787302952940746

Epoch: 6| Step: 1
Training loss: 0.7900776863098145
Validation loss: 1.77694498467189

Epoch: 6| Step: 2
Training loss: 0.9750040769577026
Validation loss: 1.7766057150338286

Epoch: 6| Step: 3
Training loss: 1.2785016298294067
Validation loss: 1.7850653176666589

Epoch: 6| Step: 4
Training loss: 0.8898753523826599
Validation loss: 1.777547933722055

Epoch: 6| Step: 5
Training loss: 1.0849380493164062
Validation loss: 1.7806477418509863

Epoch: 6| Step: 6
Training loss: 1.0737944841384888
Validation loss: 1.7883222026209677

Epoch: 6| Step: 7
Training loss: 0.7462486028671265
Validation loss: 1.781760977160546

Epoch: 6| Step: 8
Training loss: 1.3850507736206055
Validation loss: 1.81867996082511

Epoch: 6| Step: 9
Training loss: 1.0548025369644165
Validation loss: 1.801134773479995

Epoch: 6| Step: 10
Training loss: 0.6904627084732056
Validation loss: 1.7986132457692137

Epoch: 6| Step: 11
Training loss: 0.8870660066604614
Validation loss: 1.8009170511717438

Epoch: 6| Step: 12
Training loss: 1.032212257385254
Validation loss: 1.7892937096216346

Epoch: 6| Step: 13
Training loss: 0.9813699722290039
Validation loss: 1.7714694059023293

Epoch: 198| Step: 0
Training loss: 1.1342365741729736
Validation loss: 1.7755372921625774

Epoch: 6| Step: 1
Training loss: 0.9986088275909424
Validation loss: 1.757408365126579

Epoch: 6| Step: 2
Training loss: 0.5282581448554993
Validation loss: 1.766587003584831

Epoch: 6| Step: 3
Training loss: 0.565760612487793
Validation loss: 1.7543762922286987

Epoch: 6| Step: 4
Training loss: 0.7498793601989746
Validation loss: 1.7902022792446999

Epoch: 6| Step: 5
Training loss: 1.3182579278945923
Validation loss: 1.8177557427396056

Epoch: 6| Step: 6
Training loss: 1.0325766801834106
Validation loss: 1.823418491630144

Epoch: 6| Step: 7
Training loss: 1.193744421005249
Validation loss: 1.8276523774670017

Epoch: 6| Step: 8
Training loss: 1.1713032722473145
Validation loss: 1.7838215174213532

Epoch: 6| Step: 9
Training loss: 0.8451089262962341
Validation loss: 1.7848025034832697

Epoch: 6| Step: 10
Training loss: 1.3785508871078491
Validation loss: 1.7566269956609255

Epoch: 6| Step: 11
Training loss: 1.061370849609375
Validation loss: 1.77487902743842

Epoch: 6| Step: 12
Training loss: 0.9719783663749695
Validation loss: 1.7464083022968744

Epoch: 6| Step: 13
Training loss: 1.1459280252456665
Validation loss: 1.763940344574631

Epoch: 199| Step: 0
Training loss: 0.900067925453186
Validation loss: 1.7524471846959924

Epoch: 6| Step: 1
Training loss: 0.6935585737228394
Validation loss: 1.7668401169520553

Epoch: 6| Step: 2
Training loss: 1.1273748874664307
Validation loss: 1.7678080989468483

Epoch: 6| Step: 3
Training loss: 0.6748993396759033
Validation loss: 1.7634298250239382

Epoch: 6| Step: 4
Training loss: 0.83420330286026
Validation loss: 1.8036564114273235

Epoch: 6| Step: 5
Training loss: 1.026997447013855
Validation loss: 1.7742681593023322

Epoch: 6| Step: 6
Training loss: 1.5067938566207886
Validation loss: 1.789842677372758

Epoch: 6| Step: 7
Training loss: 1.0255939960479736
Validation loss: 1.7646373215542044

Epoch: 6| Step: 8
Training loss: 0.9871810078620911
Validation loss: 1.7363906957769906

Epoch: 6| Step: 9
Training loss: 0.8721553087234497
Validation loss: 1.731489836528737

Epoch: 6| Step: 10
Training loss: 0.9436932802200317
Validation loss: 1.728308036763181

Epoch: 6| Step: 11
Training loss: 0.806530237197876
Validation loss: 1.7138649109871156

Epoch: 6| Step: 12
Training loss: 1.1663415431976318
Validation loss: 1.7359454195986512

Epoch: 6| Step: 13
Training loss: 1.2622156143188477
Validation loss: 1.7306818218641384

Epoch: 200| Step: 0
Training loss: 0.9914613962173462
Validation loss: 1.759114550006005

Epoch: 6| Step: 1
Training loss: 1.3542711734771729
Validation loss: 1.7656565032979494

Epoch: 6| Step: 2
Training loss: 0.7410134077072144
Validation loss: 1.7525636854992117

Epoch: 6| Step: 3
Training loss: 1.0566872358322144
Validation loss: 1.7688820797909972

Epoch: 6| Step: 4
Training loss: 0.5071223974227905
Validation loss: 1.7707986652210195

Epoch: 6| Step: 5
Training loss: 1.6392017602920532
Validation loss: 1.783785645679761

Epoch: 6| Step: 6
Training loss: 0.754225492477417
Validation loss: 1.7866455457543815

Epoch: 6| Step: 7
Training loss: 0.7937490344047546
Validation loss: 1.7864413389595606

Epoch: 6| Step: 8
Training loss: 0.4842391014099121
Validation loss: 1.7839316552685154

Epoch: 6| Step: 9
Training loss: 0.6596860289573669
Validation loss: 1.7455314474721109

Epoch: 6| Step: 10
Training loss: 0.7962501049041748
Validation loss: 1.7349279772850774

Epoch: 6| Step: 11
Training loss: 1.2395094633102417
Validation loss: 1.7341933455518497

Epoch: 6| Step: 12
Training loss: 1.1085015535354614
Validation loss: 1.7444997064528927

Epoch: 6| Step: 13
Training loss: 1.466646671295166
Validation loss: 1.7431047667739212

Epoch: 201| Step: 0
Training loss: 1.0058165788650513
Validation loss: 1.7318250953510244

Epoch: 6| Step: 1
Training loss: 1.25315260887146
Validation loss: 1.766787535400801

Epoch: 6| Step: 2
Training loss: 1.1649545431137085
Validation loss: 1.7576489948457288

Epoch: 6| Step: 3
Training loss: 0.805329442024231
Validation loss: 1.781964494336036

Epoch: 6| Step: 4
Training loss: 0.8052270412445068
Validation loss: 1.770458775181924

Epoch: 6| Step: 5
Training loss: 1.1145765781402588
Validation loss: 1.7654457528104064

Epoch: 6| Step: 6
Training loss: 0.945256769657135
Validation loss: 1.7492441733678181

Epoch: 6| Step: 7
Training loss: 1.161881685256958
Validation loss: 1.726448142400352

Epoch: 6| Step: 8
Training loss: 0.8530782461166382
Validation loss: 1.7306302426963724

Epoch: 6| Step: 9
Training loss: 0.5664111971855164
Validation loss: 1.7270171629485263

Epoch: 6| Step: 10
Training loss: 1.0830267667770386
Validation loss: 1.7502485154777445

Epoch: 6| Step: 11
Training loss: 0.8936957120895386
Validation loss: 1.7872331616699055

Epoch: 6| Step: 12
Training loss: 1.031064510345459
Validation loss: 1.775328113186744

Epoch: 6| Step: 13
Training loss: 0.7184419631958008
Validation loss: 1.7610563488416775

Epoch: 202| Step: 0
Training loss: 1.286891222000122
Validation loss: 1.7948167362520773

Epoch: 6| Step: 1
Training loss: 0.6501189470291138
Validation loss: 1.7955091230330928

Epoch: 6| Step: 2
Training loss: 0.9540283679962158
Validation loss: 1.8116824101376277

Epoch: 6| Step: 3
Training loss: 0.9678183197975159
Validation loss: 1.7998510445317915

Epoch: 6| Step: 4
Training loss: 0.7036576271057129
Validation loss: 1.7902519215819657

Epoch: 6| Step: 5
Training loss: 0.7825556397438049
Validation loss: 1.766258744783299

Epoch: 6| Step: 6
Training loss: 1.395969271659851
Validation loss: 1.7654846945116598

Epoch: 6| Step: 7
Training loss: 0.8415817022323608
Validation loss: 1.7802143699379378

Epoch: 6| Step: 8
Training loss: 1.0394392013549805
Validation loss: 1.7690954310919649

Epoch: 6| Step: 9
Training loss: 1.0255920886993408
Validation loss: 1.767785826037007

Epoch: 6| Step: 10
Training loss: 0.6721110939979553
Validation loss: 1.7688070445932367

Epoch: 6| Step: 11
Training loss: 1.233708143234253
Validation loss: 1.7567534126261228

Epoch: 6| Step: 12
Training loss: 0.7868613004684448
Validation loss: 1.7600849520775579

Epoch: 6| Step: 13
Training loss: 0.8456944227218628
Validation loss: 1.7644278362233152

Epoch: 203| Step: 0
Training loss: 0.8785250186920166
Validation loss: 1.794221180741505

Epoch: 6| Step: 1
Training loss: 0.6119507551193237
Validation loss: 1.8092213548639768

Epoch: 6| Step: 2
Training loss: 1.1294848918914795
Validation loss: 1.7916683343149

Epoch: 6| Step: 3
Training loss: 0.8205235004425049
Validation loss: 1.765970068593179

Epoch: 6| Step: 4
Training loss: 1.2169394493103027
Validation loss: 1.7689403372426187

Epoch: 6| Step: 5
Training loss: 0.8373178243637085
Validation loss: 1.7677386332583684

Epoch: 6| Step: 6
Training loss: 0.7380028963088989
Validation loss: 1.7608846746465212

Epoch: 6| Step: 7
Training loss: 1.341723084449768
Validation loss: 1.7534190864973171

Epoch: 6| Step: 8
Training loss: 0.8674737215042114
Validation loss: 1.7667988602833082

Epoch: 6| Step: 9
Training loss: 1.014983892440796
Validation loss: 1.7510993557591592

Epoch: 6| Step: 10
Training loss: 0.7445359230041504
Validation loss: 1.7518626797583796

Epoch: 6| Step: 11
Training loss: 0.7012974619865417
Validation loss: 1.752490197458575

Epoch: 6| Step: 12
Training loss: 0.9004926681518555
Validation loss: 1.7519816801112185

Epoch: 6| Step: 13
Training loss: 1.0337072610855103
Validation loss: 1.741815584962086

Epoch: 204| Step: 0
Training loss: 0.7387548685073853
Validation loss: 1.7580524349725375

Epoch: 6| Step: 1
Training loss: 0.7951992750167847
Validation loss: 1.774116018766998

Epoch: 6| Step: 2
Training loss: 1.2849558591842651
Validation loss: 1.7545694253777946

Epoch: 6| Step: 3
Training loss: 0.4929811358451843
Validation loss: 1.7465353191539805

Epoch: 6| Step: 4
Training loss: 0.5244373679161072
Validation loss: 1.7724515853389617

Epoch: 6| Step: 5
Training loss: 0.5825244188308716
Validation loss: 1.7528014426590295

Epoch: 6| Step: 6
Training loss: 0.9301206469535828
Validation loss: 1.760282761307173

Epoch: 6| Step: 7
Training loss: 1.0149881839752197
Validation loss: 1.7433352034579042

Epoch: 6| Step: 8
Training loss: 1.5258337259292603
Validation loss: 1.7332549184881232

Epoch: 6| Step: 9
Training loss: 0.9103435277938843
Validation loss: 1.7569505386455084

Epoch: 6| Step: 10
Training loss: 1.2819929122924805
Validation loss: 1.756285253391471

Epoch: 6| Step: 11
Training loss: 0.9906535148620605
Validation loss: 1.786185751679123

Epoch: 6| Step: 12
Training loss: 1.227872610092163
Validation loss: 1.7747905510728077

Epoch: 6| Step: 13
Training loss: 0.30986112356185913
Validation loss: 1.764960399238012

Epoch: 205| Step: 0
Training loss: 0.36670050024986267
Validation loss: 1.7779170492643952

Epoch: 6| Step: 1
Training loss: 0.9518395066261292
Validation loss: 1.7788238448481406

Epoch: 6| Step: 2
Training loss: 0.5874984860420227
Validation loss: 1.7734932822565879

Epoch: 6| Step: 3
Training loss: 0.6400592923164368
Validation loss: 1.7779706396082395

Epoch: 6| Step: 4
Training loss: 1.0473339557647705
Validation loss: 1.755601462497506

Epoch: 6| Step: 5
Training loss: 0.8608102798461914
Validation loss: 1.7525444774217502

Epoch: 6| Step: 6
Training loss: 1.393775463104248
Validation loss: 1.7471659542411886

Epoch: 6| Step: 7
Training loss: 1.2083477973937988
Validation loss: 1.7410907847906953

Epoch: 6| Step: 8
Training loss: 0.8950529098510742
Validation loss: 1.7483737571265108

Epoch: 6| Step: 9
Training loss: 0.9166982173919678
Validation loss: 1.7230744740014434

Epoch: 6| Step: 10
Training loss: 0.9564904570579529
Validation loss: 1.7315570744135047

Epoch: 6| Step: 11
Training loss: 0.8408421277999878
Validation loss: 1.7513644400463309

Epoch: 6| Step: 12
Training loss: 0.8322813510894775
Validation loss: 1.7557192156391759

Epoch: 6| Step: 13
Training loss: 1.1823805570602417
Validation loss: 1.7510388128219112

Epoch: 206| Step: 0
Training loss: 1.2004332542419434
Validation loss: 1.757228527017819

Epoch: 6| Step: 1
Training loss: 0.6684618592262268
Validation loss: 1.7301638857010873

Epoch: 6| Step: 2
Training loss: 0.9239083528518677
Validation loss: 1.6857973952447214

Epoch: 6| Step: 3
Training loss: 1.1325743198394775
Validation loss: 1.7246919780649164

Epoch: 6| Step: 4
Training loss: 0.9233439564704895
Validation loss: 1.7201628543997323

Epoch: 6| Step: 5
Training loss: 0.8257120251655579
Validation loss: 1.7318807622437835

Epoch: 6| Step: 6
Training loss: 1.2694768905639648
Validation loss: 1.7235214761508408

Epoch: 6| Step: 7
Training loss: 0.9902812242507935
Validation loss: 1.7167229408858924

Epoch: 6| Step: 8
Training loss: 0.7463700771331787
Validation loss: 1.7357166351810578

Epoch: 6| Step: 9
Training loss: 0.7488851547241211
Validation loss: 1.7708175079796904

Epoch: 6| Step: 10
Training loss: 1.1799235343933105
Validation loss: 1.8096608064507926

Epoch: 6| Step: 11
Training loss: 0.6474735736846924
Validation loss: 1.8263522309641684

Epoch: 6| Step: 12
Training loss: 1.1341524124145508
Validation loss: 1.8012875254436205

Epoch: 6| Step: 13
Training loss: 0.6482377052307129
Validation loss: 1.7577901091626895

Epoch: 207| Step: 0
Training loss: 0.46987384557724
Validation loss: 1.741132890024493

Epoch: 6| Step: 1
Training loss: 0.8539860248565674
Validation loss: 1.7165782515720656

Epoch: 6| Step: 2
Training loss: 1.1757426261901855
Validation loss: 1.7221697248438352

Epoch: 6| Step: 3
Training loss: 1.4117026329040527
Validation loss: 1.7204346297889628

Epoch: 6| Step: 4
Training loss: 1.0411791801452637
Validation loss: 1.7435813962772329

Epoch: 6| Step: 5
Training loss: 0.8546928763389587
Validation loss: 1.7534919746460453

Epoch: 6| Step: 6
Training loss: 0.51484614610672
Validation loss: 1.7664327160004647

Epoch: 6| Step: 7
Training loss: 1.2092794179916382
Validation loss: 1.7637737079333233

Epoch: 6| Step: 8
Training loss: 1.0910699367523193
Validation loss: 1.7685074267848846

Epoch: 6| Step: 9
Training loss: 0.9096765518188477
Validation loss: 1.7522627871523622

Epoch: 6| Step: 10
Training loss: 0.5665156841278076
Validation loss: 1.7352721473222137

Epoch: 6| Step: 11
Training loss: 1.2678797245025635
Validation loss: 1.7221604701011413

Epoch: 6| Step: 12
Training loss: 0.40159258246421814
Validation loss: 1.7076551606578212

Epoch: 6| Step: 13
Training loss: 0.6212753653526306
Validation loss: 1.6958097988559353

Epoch: 208| Step: 0
Training loss: 0.9211519956588745
Validation loss: 1.7374549963141

Epoch: 6| Step: 1
Training loss: 1.1154334545135498
Validation loss: 1.728623156906456

Epoch: 6| Step: 2
Training loss: 0.9831302165985107
Validation loss: 1.7363149235325475

Epoch: 6| Step: 3
Training loss: 0.5329542756080627
Validation loss: 1.744658125344143

Epoch: 6| Step: 4
Training loss: 0.8679413795471191
Validation loss: 1.7234758971839823

Epoch: 6| Step: 5
Training loss: 0.4386555552482605
Validation loss: 1.715409694179412

Epoch: 6| Step: 6
Training loss: 0.7332318425178528
Validation loss: 1.7108508720192859

Epoch: 6| Step: 7
Training loss: 1.0898613929748535
Validation loss: 1.7054317894802298

Epoch: 6| Step: 8
Training loss: 0.6864241361618042
Validation loss: 1.6926946934833322

Epoch: 6| Step: 9
Training loss: 1.1930646896362305
Validation loss: 1.714700803961805

Epoch: 6| Step: 10
Training loss: 0.8068315982818604
Validation loss: 1.741813850659196

Epoch: 6| Step: 11
Training loss: 1.0843727588653564
Validation loss: 1.7395354060716526

Epoch: 6| Step: 12
Training loss: 1.0335577726364136
Validation loss: 1.7258259378453737

Epoch: 6| Step: 13
Training loss: 1.3056929111480713
Validation loss: 1.715279133089127

Epoch: 209| Step: 0
Training loss: 0.7431818246841431
Validation loss: 1.7081149765240249

Epoch: 6| Step: 1
Training loss: 0.5241382122039795
Validation loss: 1.7015490455012168

Epoch: 6| Step: 2
Training loss: 0.9182612895965576
Validation loss: 1.6901095118573917

Epoch: 6| Step: 3
Training loss: 0.6991082429885864
Validation loss: 1.686562911156685

Epoch: 6| Step: 4
Training loss: 0.8702623844146729
Validation loss: 1.71470017843349

Epoch: 6| Step: 5
Training loss: 1.055761456489563
Validation loss: 1.6933729443498837

Epoch: 6| Step: 6
Training loss: 1.3404784202575684
Validation loss: 1.69380630729019

Epoch: 6| Step: 7
Training loss: 0.6015165448188782
Validation loss: 1.7067457206787602

Epoch: 6| Step: 8
Training loss: 1.0149339437484741
Validation loss: 1.7004356871369064

Epoch: 6| Step: 9
Training loss: 1.1920545101165771
Validation loss: 1.7089995479071012

Epoch: 6| Step: 10
Training loss: 1.004941701889038
Validation loss: 1.7439909083868868

Epoch: 6| Step: 11
Training loss: 0.555924654006958
Validation loss: 1.7497108444090812

Epoch: 6| Step: 12
Training loss: 0.7368495464324951
Validation loss: 1.7296009525176017

Epoch: 6| Step: 13
Training loss: 0.9737324118614197
Validation loss: 1.7395190038988668

Epoch: 210| Step: 0
Training loss: 0.6671314239501953
Validation loss: 1.7385961855611494

Epoch: 6| Step: 1
Training loss: 0.7217262983322144
Validation loss: 1.7725060511660833

Epoch: 6| Step: 2
Training loss: 0.8155851364135742
Validation loss: 1.7385736883327525

Epoch: 6| Step: 3
Training loss: 0.8173887133598328
Validation loss: 1.7697800192781674

Epoch: 6| Step: 4
Training loss: 0.9731540679931641
Validation loss: 1.761758214683943

Epoch: 6| Step: 5
Training loss: 0.46900901198387146
Validation loss: 1.7583619638155865

Epoch: 6| Step: 6
Training loss: 1.0494399070739746
Validation loss: 1.7683781500785583

Epoch: 6| Step: 7
Training loss: 0.5740143060684204
Validation loss: 1.7518698630794403

Epoch: 6| Step: 8
Training loss: 0.9286941885948181
Validation loss: 1.7204799241917108

Epoch: 6| Step: 9
Training loss: 1.3868848085403442
Validation loss: 1.7308514951377787

Epoch: 6| Step: 10
Training loss: 1.1352142095565796
Validation loss: 1.726034104183156

Epoch: 6| Step: 11
Training loss: 0.7785218954086304
Validation loss: 1.7343016978233092

Epoch: 6| Step: 12
Training loss: 0.9201482534408569
Validation loss: 1.7287660414172756

Epoch: 6| Step: 13
Training loss: 0.9283380508422852
Validation loss: 1.750600100845419

Epoch: 211| Step: 0
Training loss: 0.7453401684761047
Validation loss: 1.785398273057835

Epoch: 6| Step: 1
Training loss: 0.862893283367157
Validation loss: 1.8188707161975164

Epoch: 6| Step: 2
Training loss: 0.8032827377319336
Validation loss: 1.8094444877357894

Epoch: 6| Step: 3
Training loss: 0.6857498288154602
Validation loss: 1.7950372311376757

Epoch: 6| Step: 4
Training loss: 1.2839710712432861
Validation loss: 1.7582566392037176

Epoch: 6| Step: 5
Training loss: 0.8888289928436279
Validation loss: 1.7272197341406217

Epoch: 6| Step: 6
Training loss: 0.808915376663208
Validation loss: 1.6967277578128281

Epoch: 6| Step: 7
Training loss: 0.8004682064056396
Validation loss: 1.725163972505959

Epoch: 6| Step: 8
Training loss: 0.8930812478065491
Validation loss: 1.7286457746259627

Epoch: 6| Step: 9
Training loss: 1.092128872871399
Validation loss: 1.6960372950441094

Epoch: 6| Step: 10
Training loss: 0.9875064492225647
Validation loss: 1.721274665606919

Epoch: 6| Step: 11
Training loss: 0.9378742575645447
Validation loss: 1.7300343449397753

Epoch: 6| Step: 12
Training loss: 0.7501828074455261
Validation loss: 1.6993689101229432

Epoch: 6| Step: 13
Training loss: 1.0308587551116943
Validation loss: 1.7166249931499522

Epoch: 212| Step: 0
Training loss: 0.7035065293312073
Validation loss: 1.7415119512106783

Epoch: 6| Step: 1
Training loss: 0.6544203758239746
Validation loss: 1.7271673294805712

Epoch: 6| Step: 2
Training loss: 0.7806099057197571
Validation loss: 1.735507813833093

Epoch: 6| Step: 3
Training loss: 0.4653276801109314
Validation loss: 1.720604879881746

Epoch: 6| Step: 4
Training loss: 0.6676456928253174
Validation loss: 1.7171161328592608

Epoch: 6| Step: 5
Training loss: 0.7035130262374878
Validation loss: 1.723173205570508

Epoch: 6| Step: 6
Training loss: 1.2221232652664185
Validation loss: 1.7323869133508334

Epoch: 6| Step: 7
Training loss: 0.6436363458633423
Validation loss: 1.7318653124634937

Epoch: 6| Step: 8
Training loss: 0.973543107509613
Validation loss: 1.73785993360704

Epoch: 6| Step: 9
Training loss: 0.9548554420471191
Validation loss: 1.7249099823736376

Epoch: 6| Step: 10
Training loss: 1.0520013570785522
Validation loss: 1.732921464468843

Epoch: 6| Step: 11
Training loss: 1.0906648635864258
Validation loss: 1.714631111391129

Epoch: 6| Step: 12
Training loss: 0.9880015850067139
Validation loss: 1.7199873821709746

Epoch: 6| Step: 13
Training loss: 0.680808424949646
Validation loss: 1.7355696706361667

Epoch: 213| Step: 0
Training loss: 1.1003423929214478
Validation loss: 1.7224477055252239

Epoch: 6| Step: 1
Training loss: 1.024155616760254
Validation loss: 1.7150363845209922

Epoch: 6| Step: 2
Training loss: 0.3838403522968292
Validation loss: 1.7221106662545154

Epoch: 6| Step: 3
Training loss: 0.7314659357070923
Validation loss: 1.7092295359539729

Epoch: 6| Step: 4
Training loss: 0.7797759771347046
Validation loss: 1.7259611506615915

Epoch: 6| Step: 5
Training loss: 0.779466986656189
Validation loss: 1.7340764268752067

Epoch: 6| Step: 6
Training loss: 1.0203502178192139
Validation loss: 1.7366819343259257

Epoch: 6| Step: 7
Training loss: 1.1365156173706055
Validation loss: 1.7289016503159718

Epoch: 6| Step: 8
Training loss: 0.7562300562858582
Validation loss: 1.7089520731279928

Epoch: 6| Step: 9
Training loss: 0.5350464582443237
Validation loss: 1.7159288993445776

Epoch: 6| Step: 10
Training loss: 0.9634777903556824
Validation loss: 1.7052155387017034

Epoch: 6| Step: 11
Training loss: 1.200438141822815
Validation loss: 1.720044219365684

Epoch: 6| Step: 12
Training loss: 0.6005164384841919
Validation loss: 1.7143460986434773

Epoch: 6| Step: 13
Training loss: 0.3623918294906616
Validation loss: 1.719874438419137

Epoch: 214| Step: 0
Training loss: 0.6352004408836365
Validation loss: 1.714678059342087

Epoch: 6| Step: 1
Training loss: 1.0413951873779297
Validation loss: 1.7248549102455057

Epoch: 6| Step: 2
Training loss: 0.3600323796272278
Validation loss: 1.7314378138511413

Epoch: 6| Step: 3
Training loss: 0.5843956470489502
Validation loss: 1.7136721828932404

Epoch: 6| Step: 4
Training loss: 0.8678826689720154
Validation loss: 1.7160641736881708

Epoch: 6| Step: 5
Training loss: 0.9716438055038452
Validation loss: 1.7184734934119767

Epoch: 6| Step: 6
Training loss: 1.1455655097961426
Validation loss: 1.7255925260564333

Epoch: 6| Step: 7
Training loss: 0.8792091608047485
Validation loss: 1.7481349873286423

Epoch: 6| Step: 8
Training loss: 0.840694785118103
Validation loss: 1.7546041370719991

Epoch: 6| Step: 9
Training loss: 0.9489227533340454
Validation loss: 1.7712192791764454

Epoch: 6| Step: 10
Training loss: 1.1779706478118896
Validation loss: 1.7430332335092689

Epoch: 6| Step: 11
Training loss: 0.8119010329246521
Validation loss: 1.7252583221722675

Epoch: 6| Step: 12
Training loss: 0.7593084573745728
Validation loss: 1.7121227325931672

Epoch: 6| Step: 13
Training loss: 0.7275832295417786
Validation loss: 1.705925182629657

Epoch: 215| Step: 0
Training loss: 0.4190782606601715
Validation loss: 1.7159718915980349

Epoch: 6| Step: 1
Training loss: 1.2968695163726807
Validation loss: 1.721532074354028

Epoch: 6| Step: 2
Training loss: 0.6623094081878662
Validation loss: 1.7393081470202374

Epoch: 6| Step: 3
Training loss: 1.3567121028900146
Validation loss: 1.7528494276026243

Epoch: 6| Step: 4
Training loss: 1.0354313850402832
Validation loss: 1.7456123399478134

Epoch: 6| Step: 5
Training loss: 0.4867372214794159
Validation loss: 1.7576337706658147

Epoch: 6| Step: 6
Training loss: 1.0332791805267334
Validation loss: 1.705034222654117

Epoch: 6| Step: 7
Training loss: 0.6079613566398621
Validation loss: 1.696216433278976

Epoch: 6| Step: 8
Training loss: 0.7651972770690918
Validation loss: 1.7189555693698186

Epoch: 6| Step: 9
Training loss: 0.5965383052825928
Validation loss: 1.7037964136369768

Epoch: 6| Step: 10
Training loss: 0.8735842704772949
Validation loss: 1.7223228754535798

Epoch: 6| Step: 11
Training loss: 0.9957982897758484
Validation loss: 1.7171360972107097

Epoch: 6| Step: 12
Training loss: 1.1286396980285645
Validation loss: 1.7303652942821544

Epoch: 6| Step: 13
Training loss: 0.5897915363311768
Validation loss: 1.7445808802881548

Epoch: 216| Step: 0
Training loss: 0.7842244505882263
Validation loss: 1.7733632390217116

Epoch: 6| Step: 1
Training loss: 1.2690746784210205
Validation loss: 1.7920834813066708

Epoch: 6| Step: 2
Training loss: 1.021304965019226
Validation loss: 1.7896448924977293

Epoch: 6| Step: 3
Training loss: 0.5401366353034973
Validation loss: 1.762708281957975

Epoch: 6| Step: 4
Training loss: 0.5613471269607544
Validation loss: 1.7536757710159465

Epoch: 6| Step: 5
Training loss: 0.6832608580589294
Validation loss: 1.7457218772621566

Epoch: 6| Step: 6
Training loss: 0.8046637773513794
Validation loss: 1.7289807258113739

Epoch: 6| Step: 7
Training loss: 0.9814203977584839
Validation loss: 1.707871587045731

Epoch: 6| Step: 8
Training loss: 0.5755860805511475
Validation loss: 1.7224116338196622

Epoch: 6| Step: 9
Training loss: 1.2486445903778076
Validation loss: 1.7214485855512722

Epoch: 6| Step: 10
Training loss: 0.5768221020698547
Validation loss: 1.725040933137299

Epoch: 6| Step: 11
Training loss: 0.4536699950695038
Validation loss: 1.7168571820823095

Epoch: 6| Step: 12
Training loss: 1.1880970001220703
Validation loss: 1.7199968150866929

Epoch: 6| Step: 13
Training loss: 0.9942675828933716
Validation loss: 1.7255518410795478

Epoch: 217| Step: 0
Training loss: 1.2636661529541016
Validation loss: 1.717709388784183

Epoch: 6| Step: 1
Training loss: 0.563357949256897
Validation loss: 1.714895712432041

Epoch: 6| Step: 2
Training loss: 0.4824525713920593
Validation loss: 1.7102793980670232

Epoch: 6| Step: 3
Training loss: 1.0734950304031372
Validation loss: 1.7160300580404138

Epoch: 6| Step: 4
Training loss: 0.4665018320083618
Validation loss: 1.7083518133368543

Epoch: 6| Step: 5
Training loss: 0.9613564610481262
Validation loss: 1.7013074544168287

Epoch: 6| Step: 6
Training loss: 0.7942280769348145
Validation loss: 1.711596809407716

Epoch: 6| Step: 7
Training loss: 1.122493863105774
Validation loss: 1.7056780938179261

Epoch: 6| Step: 8
Training loss: 0.9811362028121948
Validation loss: 1.7004259017206007

Epoch: 6| Step: 9
Training loss: 0.5472855567932129
Validation loss: 1.715642681685827

Epoch: 6| Step: 10
Training loss: 0.9685508012771606
Validation loss: 1.7354267771526048

Epoch: 6| Step: 11
Training loss: 0.703034520149231
Validation loss: 1.7623633274468042

Epoch: 6| Step: 12
Training loss: 0.31185051798820496
Validation loss: 1.7466458761563866

Epoch: 6| Step: 13
Training loss: 0.8581255674362183
Validation loss: 1.7234641121279808

Epoch: 218| Step: 0
Training loss: 0.9828983545303345
Validation loss: 1.7351409491672312

Epoch: 6| Step: 1
Training loss: 0.8927576541900635
Validation loss: 1.750290145156204

Epoch: 6| Step: 2
Training loss: 1.2166846990585327
Validation loss: 1.7787395754168112

Epoch: 6| Step: 3
Training loss: 1.1118593215942383
Validation loss: 1.7732982097133514

Epoch: 6| Step: 4
Training loss: 0.5728614330291748
Validation loss: 1.7449848498067548

Epoch: 6| Step: 5
Training loss: 0.5638278126716614
Validation loss: 1.7510429710470221

Epoch: 6| Step: 6
Training loss: 0.5969560146331787
Validation loss: 1.7550634543100994

Epoch: 6| Step: 7
Training loss: 0.7945181131362915
Validation loss: 1.798121452331543

Epoch: 6| Step: 8
Training loss: 0.7428048253059387
Validation loss: 1.8102584218466153

Epoch: 6| Step: 9
Training loss: 1.7081842422485352
Validation loss: 1.7882489722262147

Epoch: 6| Step: 10
Training loss: 1.0032601356506348
Validation loss: 1.7508839227819954

Epoch: 6| Step: 11
Training loss: 0.6734408140182495
Validation loss: 1.7487781534912765

Epoch: 6| Step: 12
Training loss: 0.6820983290672302
Validation loss: 1.7378577737398044

Epoch: 6| Step: 13
Training loss: 1.3418360948562622
Validation loss: 1.8025328472096434

Epoch: 219| Step: 0
Training loss: 0.8710470199584961
Validation loss: 1.7930647750054636

Epoch: 6| Step: 1
Training loss: 0.6704427599906921
Validation loss: 1.7552367487261373

Epoch: 6| Step: 2
Training loss: 0.6420013904571533
Validation loss: 1.7186233048797936

Epoch: 6| Step: 3
Training loss: 0.7128898501396179
Validation loss: 1.7237350709976689

Epoch: 6| Step: 4
Training loss: 1.2376601696014404
Validation loss: 1.7475842301563551

Epoch: 6| Step: 5
Training loss: 1.067233920097351
Validation loss: 1.7943260644071846

Epoch: 6| Step: 6
Training loss: 0.9342950582504272
Validation loss: 1.8417944562050603

Epoch: 6| Step: 7
Training loss: 1.1247637271881104
Validation loss: 1.8248639978388304

Epoch: 6| Step: 8
Training loss: 0.9297947883605957
Validation loss: 1.7688567151305497

Epoch: 6| Step: 9
Training loss: 0.9220423102378845
Validation loss: 1.7264732404421734

Epoch: 6| Step: 10
Training loss: 1.0594334602355957
Validation loss: 1.7592803585913874

Epoch: 6| Step: 11
Training loss: 0.9506101608276367
Validation loss: 1.7851364433124501

Epoch: 6| Step: 12
Training loss: 1.1669330596923828
Validation loss: 1.7686631935898975

Epoch: 6| Step: 13
Training loss: 0.2802574634552002
Validation loss: 1.7718782745381838

Epoch: 220| Step: 0
Training loss: 0.3786451518535614
Validation loss: 1.7433469346774522

Epoch: 6| Step: 1
Training loss: 1.0781290531158447
Validation loss: 1.724054217338562

Epoch: 6| Step: 2
Training loss: 0.9092260599136353
Validation loss: 1.7382877795926985

Epoch: 6| Step: 3
Training loss: 0.8663235902786255
Validation loss: 1.7437110818842405

Epoch: 6| Step: 4
Training loss: 1.1398812532424927
Validation loss: 1.7501139666444512

Epoch: 6| Step: 5
Training loss: 0.9488393068313599
Validation loss: 1.7333674405210762

Epoch: 6| Step: 6
Training loss: 0.4151308834552765
Validation loss: 1.7445253736229354

Epoch: 6| Step: 7
Training loss: 0.6618204116821289
Validation loss: 1.7160710147632066

Epoch: 6| Step: 8
Training loss: 0.36733710765838623
Validation loss: 1.720677727012224

Epoch: 6| Step: 9
Training loss: 0.9430260062217712
Validation loss: 1.7053854286029775

Epoch: 6| Step: 10
Training loss: 0.8877114057540894
Validation loss: 1.676511182579943

Epoch: 6| Step: 11
Training loss: 0.8824946284294128
Validation loss: 1.7084337665188698

Epoch: 6| Step: 12
Training loss: 0.8735424280166626
Validation loss: 1.6940826895416423

Epoch: 6| Step: 13
Training loss: 0.6116201877593994
Validation loss: 1.720460295677185

Epoch: 221| Step: 0
Training loss: 0.8332344889640808
Validation loss: 1.7034108459308583

Epoch: 6| Step: 1
Training loss: 0.3995249569416046
Validation loss: 1.716575950063685

Epoch: 6| Step: 2
Training loss: 0.6460750699043274
Validation loss: 1.7156207151310419

Epoch: 6| Step: 3
Training loss: 0.7049000263214111
Validation loss: 1.710797223993527

Epoch: 6| Step: 4
Training loss: 0.6306931376457214
Validation loss: 1.7087429056885421

Epoch: 6| Step: 5
Training loss: 0.6508122682571411
Validation loss: 1.7118494433741416

Epoch: 6| Step: 6
Training loss: 1.2762045860290527
Validation loss: 1.7081387030181063

Epoch: 6| Step: 7
Training loss: 0.7696353197097778
Validation loss: 1.720073987078923

Epoch: 6| Step: 8
Training loss: 1.0142260789871216
Validation loss: 1.716923725861375

Epoch: 6| Step: 9
Training loss: 0.9808462858200073
Validation loss: 1.7050549509704753

Epoch: 6| Step: 10
Training loss: 0.8316540718078613
Validation loss: 1.7009398591133855

Epoch: 6| Step: 11
Training loss: 0.5847539305686951
Validation loss: 1.693746232217358

Epoch: 6| Step: 12
Training loss: 0.8813010454177856
Validation loss: 1.713496478655005

Epoch: 6| Step: 13
Training loss: 0.5545728802680969
Validation loss: 1.7308292658098283

Epoch: 222| Step: 0
Training loss: 0.7619221806526184
Validation loss: 1.675900710526333

Epoch: 6| Step: 1
Training loss: 0.4993218183517456
Validation loss: 1.6990790040262285

Epoch: 6| Step: 2
Training loss: 0.7916498780250549
Validation loss: 1.6936821200514351

Epoch: 6| Step: 3
Training loss: 0.7151017189025879
Validation loss: 1.7101509968439739

Epoch: 6| Step: 4
Training loss: 0.8297362327575684
Validation loss: 1.6851725411671463

Epoch: 6| Step: 5
Training loss: 0.9009587168693542
Validation loss: 1.699128456013177

Epoch: 6| Step: 6
Training loss: 0.7234385013580322
Validation loss: 1.6909892046323387

Epoch: 6| Step: 7
Training loss: 1.1793205738067627
Validation loss: 1.6854479312896729

Epoch: 6| Step: 8
Training loss: 0.545278787612915
Validation loss: 1.7033941579121414

Epoch: 6| Step: 9
Training loss: 0.6607670783996582
Validation loss: 1.705404241879781

Epoch: 6| Step: 10
Training loss: 0.711833119392395
Validation loss: 1.6884392230741438

Epoch: 6| Step: 11
Training loss: 0.7903503179550171
Validation loss: 1.6762145603856733

Epoch: 6| Step: 12
Training loss: 0.44557246565818787
Validation loss: 1.677472545254615

Epoch: 6| Step: 13
Training loss: 0.7142108678817749
Validation loss: 1.7071890343901932

Epoch: 223| Step: 0
Training loss: 0.9376102685928345
Validation loss: 1.7174652314955188

Epoch: 6| Step: 1
Training loss: 0.5535680055618286
Validation loss: 1.7029307734581731

Epoch: 6| Step: 2
Training loss: 0.8062278032302856
Validation loss: 1.7235608716164865

Epoch: 6| Step: 3
Training loss: 0.7570958137512207
Validation loss: 1.7300909962705386

Epoch: 6| Step: 4
Training loss: 0.7974914312362671
Validation loss: 1.727627843938848

Epoch: 6| Step: 5
Training loss: 0.6608049273490906
Validation loss: 1.7074344440173077

Epoch: 6| Step: 6
Training loss: 0.39182305335998535
Validation loss: 1.6951816364001202

Epoch: 6| Step: 7
Training loss: 0.7543051242828369
Validation loss: 1.6951533709802935

Epoch: 6| Step: 8
Training loss: 0.7032826542854309
Validation loss: 1.6876063000771306

Epoch: 6| Step: 9
Training loss: 1.009812355041504
Validation loss: 1.7085699624912714

Epoch: 6| Step: 10
Training loss: 0.8224594593048096
Validation loss: 1.7080382672689294

Epoch: 6| Step: 11
Training loss: 0.6765353679656982
Validation loss: 1.725030501683553

Epoch: 6| Step: 12
Training loss: 0.7086882591247559
Validation loss: 1.714229832413376

Epoch: 6| Step: 13
Training loss: 0.7882259488105774
Validation loss: 1.710416288786037

Epoch: 224| Step: 0
Training loss: 0.6901798248291016
Validation loss: 1.7264328714339965

Epoch: 6| Step: 1
Training loss: 0.6514853835105896
Validation loss: 1.7085435044380926

Epoch: 6| Step: 2
Training loss: 0.5449651479721069
Validation loss: 1.6792739193926576

Epoch: 6| Step: 3
Training loss: 0.5721426010131836
Validation loss: 1.6783831529719855

Epoch: 6| Step: 4
Training loss: 1.1895310878753662
Validation loss: 1.6755344662615048

Epoch: 6| Step: 5
Training loss: 0.6197645664215088
Validation loss: 1.6947381983521164

Epoch: 6| Step: 6
Training loss: 0.69488924741745
Validation loss: 1.6795113625064972

Epoch: 6| Step: 7
Training loss: 0.7243757247924805
Validation loss: 1.659299986336821

Epoch: 6| Step: 8
Training loss: 1.2464295625686646
Validation loss: 1.6592177870453044

Epoch: 6| Step: 9
Training loss: 0.8001198172569275
Validation loss: 1.6669988657838555

Epoch: 6| Step: 10
Training loss: 0.3404156565666199
Validation loss: 1.6567222559323875

Epoch: 6| Step: 11
Training loss: 0.4650134742259979
Validation loss: 1.6624583659633514

Epoch: 6| Step: 12
Training loss: 0.8625661730766296
Validation loss: 1.664574033470564

Epoch: 6| Step: 13
Training loss: 0.3607974648475647
Validation loss: 1.6625779521080755

Epoch: 225| Step: 0
Training loss: 0.9566687345504761
Validation loss: 1.6982631439803748

Epoch: 6| Step: 1
Training loss: 0.45324981212615967
Validation loss: 1.696599213025903

Epoch: 6| Step: 2
Training loss: 1.0606670379638672
Validation loss: 1.7096334144633303

Epoch: 6| Step: 3
Training loss: 0.8877414464950562
Validation loss: 1.7097431113643031

Epoch: 6| Step: 4
Training loss: 0.7157387733459473
Validation loss: 1.702395757039388

Epoch: 6| Step: 5
Training loss: 0.40998247265815735
Validation loss: 1.707157427264798

Epoch: 6| Step: 6
Training loss: 0.6790142059326172
Validation loss: 1.6994265253825853

Epoch: 6| Step: 7
Training loss: 0.7894442081451416
Validation loss: 1.6823810479974235

Epoch: 6| Step: 8
Training loss: 0.44488590955734253
Validation loss: 1.6886339725986603

Epoch: 6| Step: 9
Training loss: 0.5758296847343445
Validation loss: 1.6945196864425496

Epoch: 6| Step: 10
Training loss: 0.7587441802024841
Validation loss: 1.7172003817814652

Epoch: 6| Step: 11
Training loss: 0.663796067237854
Validation loss: 1.7107830791063205

Epoch: 6| Step: 12
Training loss: 0.7257184386253357
Validation loss: 1.7336442957642257

Epoch: 6| Step: 13
Training loss: 1.0638353824615479
Validation loss: 1.7167315995821388

Epoch: 226| Step: 0
Training loss: 0.777949869632721
Validation loss: 1.7290104948064333

Epoch: 6| Step: 1
Training loss: 0.9761089086532593
Validation loss: 1.754082913039833

Epoch: 6| Step: 2
Training loss: 1.0209460258483887
Validation loss: 1.7507316412464264

Epoch: 6| Step: 3
Training loss: 0.7860345244407654
Validation loss: 1.7535862076667048

Epoch: 6| Step: 4
Training loss: 0.7998016476631165
Validation loss: 1.7620165053234305

Epoch: 6| Step: 5
Training loss: 1.0635645389556885
Validation loss: 1.7521595083257204

Epoch: 6| Step: 6
Training loss: 0.5244913697242737
Validation loss: 1.7373703449003157

Epoch: 6| Step: 7
Training loss: 0.33159005641937256
Validation loss: 1.742874865890831

Epoch: 6| Step: 8
Training loss: 0.39935460686683655
Validation loss: 1.7444503781616048

Epoch: 6| Step: 9
Training loss: 0.8742154836654663
Validation loss: 1.7620427903308664

Epoch: 6| Step: 10
Training loss: 0.7344241142272949
Validation loss: 1.7594252132600354

Epoch: 6| Step: 11
Training loss: 0.5990104079246521
Validation loss: 1.7485077304224814

Epoch: 6| Step: 12
Training loss: 0.7876802682876587
Validation loss: 1.7470504519759968

Epoch: 6| Step: 13
Training loss: 0.4974279999732971
Validation loss: 1.7439398893745996

Epoch: 227| Step: 0
Training loss: 0.8779152035713196
Validation loss: 1.762633490306075

Epoch: 6| Step: 1
Training loss: 0.6792469024658203
Validation loss: 1.7556305611005394

Epoch: 6| Step: 2
Training loss: 0.4754054546356201
Validation loss: 1.7624866283068092

Epoch: 6| Step: 3
Training loss: 1.1334271430969238
Validation loss: 1.7376969104172082

Epoch: 6| Step: 4
Training loss: 0.7872381210327148
Validation loss: 1.726022530627507

Epoch: 6| Step: 5
Training loss: 1.0267622470855713
Validation loss: 1.7095368011023409

Epoch: 6| Step: 6
Training loss: 0.5575637221336365
Validation loss: 1.7278090036043556

Epoch: 6| Step: 7
Training loss: 0.5812165141105652
Validation loss: 1.7184555940730597

Epoch: 6| Step: 8
Training loss: 0.5844839811325073
Validation loss: 1.7575484527054654

Epoch: 6| Step: 9
Training loss: 1.0753930807113647
Validation loss: 1.7587018025818693

Epoch: 6| Step: 10
Training loss: 0.7142214775085449
Validation loss: 1.7349800653355096

Epoch: 6| Step: 11
Training loss: 0.5859184265136719
Validation loss: 1.7059640615217146

Epoch: 6| Step: 12
Training loss: 0.5278326272964478
Validation loss: 1.703508924412471

Epoch: 6| Step: 13
Training loss: 0.6799966096878052
Validation loss: 1.6739193213883268

Epoch: 228| Step: 0
Training loss: 0.6701779365539551
Validation loss: 1.7206101058631815

Epoch: 6| Step: 1
Training loss: 0.6173653602600098
Validation loss: 1.712299907079307

Epoch: 6| Step: 2
Training loss: 0.861380934715271
Validation loss: 1.7097545708379438

Epoch: 6| Step: 3
Training loss: 0.7262202501296997
Validation loss: 1.6901274599054807

Epoch: 6| Step: 4
Training loss: 0.5281004905700684
Validation loss: 1.6969106799812728

Epoch: 6| Step: 5
Training loss: 0.4233430325984955
Validation loss: 1.6887542791264032

Epoch: 6| Step: 6
Training loss: 0.6978216171264648
Validation loss: 1.6858392928236274

Epoch: 6| Step: 7
Training loss: 0.6552067995071411
Validation loss: 1.7035655975341797

Epoch: 6| Step: 8
Training loss: 0.541637122631073
Validation loss: 1.7160172218917518

Epoch: 6| Step: 9
Training loss: 0.9422707557678223
Validation loss: 1.703006907175946

Epoch: 6| Step: 10
Training loss: 0.5808002948760986
Validation loss: 1.7078392300554501

Epoch: 6| Step: 11
Training loss: 1.1078945398330688
Validation loss: 1.6907233884257655

Epoch: 6| Step: 12
Training loss: 0.8679097294807434
Validation loss: 1.6958481201561548

Epoch: 6| Step: 13
Training loss: 0.4910488724708557
Validation loss: 1.699279441628405

Epoch: 229| Step: 0
Training loss: 0.8268656730651855
Validation loss: 1.6778692583883963

Epoch: 6| Step: 1
Training loss: 0.4503185749053955
Validation loss: 1.6813667833164174

Epoch: 6| Step: 2
Training loss: 0.8585370779037476
Validation loss: 1.692864344966027

Epoch: 6| Step: 3
Training loss: 0.4461449384689331
Validation loss: 1.7063551884825512

Epoch: 6| Step: 4
Training loss: 0.5533983111381531
Validation loss: 1.70009151581795

Epoch: 6| Step: 5
Training loss: 0.8446903228759766
Validation loss: 1.7200808883995138

Epoch: 6| Step: 6
Training loss: 0.9534612894058228
Validation loss: 1.7114098097688408

Epoch: 6| Step: 7
Training loss: 0.48927173018455505
Validation loss: 1.7525067444770568

Epoch: 6| Step: 8
Training loss: 0.9088715314865112
Validation loss: 1.709279550019131

Epoch: 6| Step: 9
Training loss: 0.6509184837341309
Validation loss: 1.6848403946045907

Epoch: 6| Step: 10
Training loss: 0.5377632975578308
Validation loss: 1.7083108604595225

Epoch: 6| Step: 11
Training loss: 0.5051454305648804
Validation loss: 1.69985629153508

Epoch: 6| Step: 12
Training loss: 0.8741910457611084
Validation loss: 1.699439468563244

Epoch: 6| Step: 13
Training loss: 0.7059357166290283
Validation loss: 1.6819495513874998

Epoch: 230| Step: 0
Training loss: 1.1643539667129517
Validation loss: 1.7008233403646817

Epoch: 6| Step: 1
Training loss: 0.39605802297592163
Validation loss: 1.6874164714608142

Epoch: 6| Step: 2
Training loss: 1.2481874227523804
Validation loss: 1.6933030723243632

Epoch: 6| Step: 3
Training loss: 0.6482839584350586
Validation loss: 1.6886117278888662

Epoch: 6| Step: 4
Training loss: 0.5899721384048462
Validation loss: 1.714969801646407

Epoch: 6| Step: 5
Training loss: 0.5264508724212646
Validation loss: 1.7199834598008024

Epoch: 6| Step: 6
Training loss: 0.47300201654434204
Validation loss: 1.7314316162499048

Epoch: 6| Step: 7
Training loss: 0.7996256947517395
Validation loss: 1.7109477571261826

Epoch: 6| Step: 8
Training loss: 0.7469867467880249
Validation loss: 1.723321085335106

Epoch: 6| Step: 9
Training loss: 0.5354549884796143
Validation loss: 1.7029579800944175

Epoch: 6| Step: 10
Training loss: 0.670733630657196
Validation loss: 1.6861299109715286

Epoch: 6| Step: 11
Training loss: 0.791618824005127
Validation loss: 1.7086345534170828

Epoch: 6| Step: 12
Training loss: 0.669334352016449
Validation loss: 1.7103757896730978

Epoch: 6| Step: 13
Training loss: 0.7634295225143433
Validation loss: 1.7229455671002787

Epoch: 231| Step: 0
Training loss: 0.3543178141117096
Validation loss: 1.7092566477355136

Epoch: 6| Step: 1
Training loss: 0.36850258708000183
Validation loss: 1.7464591008360668

Epoch: 6| Step: 2
Training loss: 0.7869572043418884
Validation loss: 1.7547975868307135

Epoch: 6| Step: 3
Training loss: 0.49293553829193115
Validation loss: 1.7491801515702279

Epoch: 6| Step: 4
Training loss: 0.4983740448951721
Validation loss: 1.7539445354092507

Epoch: 6| Step: 5
Training loss: 0.7760393619537354
Validation loss: 1.746462837342293

Epoch: 6| Step: 6
Training loss: 0.7846183180809021
Validation loss: 1.7610615363685034

Epoch: 6| Step: 7
Training loss: 0.7679466009140015
Validation loss: 1.751168962447874

Epoch: 6| Step: 8
Training loss: 0.527539849281311
Validation loss: 1.7145483724532589

Epoch: 6| Step: 9
Training loss: 0.6733975410461426
Validation loss: 1.722152571524343

Epoch: 6| Step: 10
Training loss: 1.0643134117126465
Validation loss: 1.7071099614584317

Epoch: 6| Step: 11
Training loss: 0.6929072141647339
Validation loss: 1.706056756357993

Epoch: 6| Step: 12
Training loss: 0.8257776498794556
Validation loss: 1.698878683069701

Epoch: 6| Step: 13
Training loss: 0.7246701717376709
Validation loss: 1.681363118592129

Epoch: 232| Step: 0
Training loss: 0.6788730025291443
Validation loss: 1.6616893019727481

Epoch: 6| Step: 1
Training loss: 0.9805475473403931
Validation loss: 1.6762567502196117

Epoch: 6| Step: 2
Training loss: 0.6061149835586548
Validation loss: 1.6622614040169665

Epoch: 6| Step: 3
Training loss: 0.6559295654296875
Validation loss: 1.6588357545996224

Epoch: 6| Step: 4
Training loss: 0.5650938749313354
Validation loss: 1.6689431923691944

Epoch: 6| Step: 5
Training loss: 0.5989969372749329
Validation loss: 1.6567713419596355

Epoch: 6| Step: 6
Training loss: 0.6094352006912231
Validation loss: 1.6765263208778955

Epoch: 6| Step: 7
Training loss: 0.42853713035583496
Validation loss: 1.697640004978385

Epoch: 6| Step: 8
Training loss: 0.8813517093658447
Validation loss: 1.6994272694792798

Epoch: 6| Step: 9
Training loss: 0.5344728231430054
Validation loss: 1.712829638552922

Epoch: 6| Step: 10
Training loss: 0.44178587198257446
Validation loss: 1.718424709894324

Epoch: 6| Step: 11
Training loss: 0.8075078725814819
Validation loss: 1.7087275725539013

Epoch: 6| Step: 12
Training loss: 0.5792280435562134
Validation loss: 1.6711132090578797

Epoch: 6| Step: 13
Training loss: 1.1404281854629517
Validation loss: 1.6869131890676354

Epoch: 233| Step: 0
Training loss: 0.29238641262054443
Validation loss: 1.7011428571516467

Epoch: 6| Step: 1
Training loss: 0.5803250670433044
Validation loss: 1.703992623154835

Epoch: 6| Step: 2
Training loss: 0.7729241251945496
Validation loss: 1.6844524119489936

Epoch: 6| Step: 3
Training loss: 0.47695380449295044
Validation loss: 1.6943865591479885

Epoch: 6| Step: 4
Training loss: 0.6326829791069031
Validation loss: 1.673571837845669

Epoch: 6| Step: 5
Training loss: 0.8903837203979492
Validation loss: 1.6673611299965971

Epoch: 6| Step: 6
Training loss: 0.43235838413238525
Validation loss: 1.6789492983971872

Epoch: 6| Step: 7
Training loss: 0.8890515565872192
Validation loss: 1.663965008592093

Epoch: 6| Step: 8
Training loss: 0.6298331022262573
Validation loss: 1.681270348128452

Epoch: 6| Step: 9
Training loss: 0.5162715911865234
Validation loss: 1.6477206791600874

Epoch: 6| Step: 10
Training loss: 0.3678542375564575
Validation loss: 1.674071931069897

Epoch: 6| Step: 11
Training loss: 0.6701669692993164
Validation loss: 1.6584489486550773

Epoch: 6| Step: 12
Training loss: 1.1225955486297607
Validation loss: 1.654873772334027

Epoch: 6| Step: 13
Training loss: 0.8103763461112976
Validation loss: 1.6536989288945352

Epoch: 234| Step: 0
Training loss: 0.7966263890266418
Validation loss: 1.6700121818050262

Epoch: 6| Step: 1
Training loss: 0.540421724319458
Validation loss: 1.6724741074346727

Epoch: 6| Step: 2
Training loss: 0.44250059127807617
Validation loss: 1.6870813728660665

Epoch: 6| Step: 3
Training loss: 0.7495110630989075
Validation loss: 1.6867792824263215

Epoch: 6| Step: 4
Training loss: 0.818181037902832
Validation loss: 1.689302190657585

Epoch: 6| Step: 5
Training loss: 0.46306100487709045
Validation loss: 1.6835637592500257

Epoch: 6| Step: 6
Training loss: 0.4460976719856262
Validation loss: 1.689536718912022

Epoch: 6| Step: 7
Training loss: 0.5624921917915344
Validation loss: 1.695443691745881

Epoch: 6| Step: 8
Training loss: 0.5489739179611206
Validation loss: 1.6769409051505468

Epoch: 6| Step: 9
Training loss: 0.7760481238365173
Validation loss: 1.6745864101635513

Epoch: 6| Step: 10
Training loss: 0.825381875038147
Validation loss: 1.6840921871123775

Epoch: 6| Step: 11
Training loss: 0.5211023092269897
Validation loss: 1.6769593197812316

Epoch: 6| Step: 12
Training loss: 0.5246275067329407
Validation loss: 1.6869405418313959

Epoch: 6| Step: 13
Training loss: 0.8112667798995972
Validation loss: 1.6725641912029636

Epoch: 235| Step: 0
Training loss: 0.6686486601829529
Validation loss: 1.7076450342773108

Epoch: 6| Step: 1
Training loss: 0.45796501636505127
Validation loss: 1.6706241561520485

Epoch: 6| Step: 2
Training loss: 0.9348486065864563
Validation loss: 1.691208831725582

Epoch: 6| Step: 3
Training loss: 0.6784342527389526
Validation loss: 1.6845208444902975

Epoch: 6| Step: 4
Training loss: 0.6264949440956116
Validation loss: 1.6849728899617349

Epoch: 6| Step: 5
Training loss: 0.4313679039478302
Validation loss: 1.7233005416008733

Epoch: 6| Step: 6
Training loss: 0.6490974426269531
Validation loss: 1.6942002260556785

Epoch: 6| Step: 7
Training loss: 0.9291104674339294
Validation loss: 1.6688262570288874

Epoch: 6| Step: 8
Training loss: 0.6176997423171997
Validation loss: 1.6672049363454182

Epoch: 6| Step: 9
Training loss: 0.4462023377418518
Validation loss: 1.640558822180635

Epoch: 6| Step: 10
Training loss: 0.39678189158439636
Validation loss: 1.6486555607088151

Epoch: 6| Step: 11
Training loss: 0.854557454586029
Validation loss: 1.654985943148213

Epoch: 6| Step: 12
Training loss: 0.5735679864883423
Validation loss: 1.6684620688038487

Epoch: 6| Step: 13
Training loss: 0.42451906204223633
Validation loss: 1.6915877166614737

Epoch: 236| Step: 0
Training loss: 0.41687819361686707
Validation loss: 1.723548735341718

Epoch: 6| Step: 1
Training loss: 0.41507643461227417
Validation loss: 1.72614166813512

Epoch: 6| Step: 2
Training loss: 0.8247808218002319
Validation loss: 1.7245411667772519

Epoch: 6| Step: 3
Training loss: 0.6626168489456177
Validation loss: 1.6639744581714753

Epoch: 6| Step: 4
Training loss: 0.517702043056488
Validation loss: 1.6699688126963954

Epoch: 6| Step: 5
Training loss: 0.6261798143386841
Validation loss: 1.6859585931224208

Epoch: 6| Step: 6
Training loss: 0.4288662075996399
Validation loss: 1.6849292439799155

Epoch: 6| Step: 7
Training loss: 1.2315747737884521
Validation loss: 1.7043196437179402

Epoch: 6| Step: 8
Training loss: 0.38103365898132324
Validation loss: 1.6962254624212942

Epoch: 6| Step: 9
Training loss: 0.7503835558891296
Validation loss: 1.658963821267569

Epoch: 6| Step: 10
Training loss: 0.8314756155014038
Validation loss: 1.6610810670160479

Epoch: 6| Step: 11
Training loss: 0.6429508924484253
Validation loss: 1.6931644767843268

Epoch: 6| Step: 12
Training loss: 0.7592905759811401
Validation loss: 1.7175558664465462

Epoch: 6| Step: 13
Training loss: 0.5442681908607483
Validation loss: 1.700118286635286

Epoch: 237| Step: 0
Training loss: 0.45073598623275757
Validation loss: 1.661331872786245

Epoch: 6| Step: 1
Training loss: 0.9270792603492737
Validation loss: 1.6745271593011835

Epoch: 6| Step: 2
Training loss: 0.6256068348884583
Validation loss: 1.6716488022958078

Epoch: 6| Step: 3
Training loss: 0.439594030380249
Validation loss: 1.6753183372559086

Epoch: 6| Step: 4
Training loss: 0.9851012825965881
Validation loss: 1.68311438381031

Epoch: 6| Step: 5
Training loss: 0.715095043182373
Validation loss: 1.6818705117830666

Epoch: 6| Step: 6
Training loss: 0.8135672211647034
Validation loss: 1.6916209433668403

Epoch: 6| Step: 7
Training loss: 0.4412083923816681
Validation loss: 1.6698604758067797

Epoch: 6| Step: 8
Training loss: 0.7810264825820923
Validation loss: 1.6809693177541096

Epoch: 6| Step: 9
Training loss: 0.4524061679840088
Validation loss: 1.6862609719717374

Epoch: 6| Step: 10
Training loss: 0.3391009569168091
Validation loss: 1.7015078606144074

Epoch: 6| Step: 11
Training loss: 0.476864755153656
Validation loss: 1.7115446495753464

Epoch: 6| Step: 12
Training loss: 0.4153703451156616
Validation loss: 1.6848399908311906

Epoch: 6| Step: 13
Training loss: 0.6657818555831909
Validation loss: 1.6581132899048507

Epoch: 238| Step: 0
Training loss: 0.5841040015220642
Validation loss: 1.6453812942709973

Epoch: 6| Step: 1
Training loss: 0.4658883213996887
Validation loss: 1.680878318766112

Epoch: 6| Step: 2
Training loss: 0.7763117551803589
Validation loss: 1.6433115851494573

Epoch: 6| Step: 3
Training loss: 0.33476194739341736
Validation loss: 1.654327828397033

Epoch: 6| Step: 4
Training loss: 0.4118761122226715
Validation loss: 1.6530604490669825

Epoch: 6| Step: 5
Training loss: 0.4594144821166992
Validation loss: 1.6913314275844122

Epoch: 6| Step: 6
Training loss: 0.8361293077468872
Validation loss: 1.6876021200610745

Epoch: 6| Step: 7
Training loss: 0.459011435508728
Validation loss: 1.6594480109471146

Epoch: 6| Step: 8
Training loss: 0.3232065439224243
Validation loss: 1.6881554254921534

Epoch: 6| Step: 9
Training loss: 0.5002066493034363
Validation loss: 1.6808413331226637

Epoch: 6| Step: 10
Training loss: 0.434050589799881
Validation loss: 1.6975427981345885

Epoch: 6| Step: 11
Training loss: 0.6281472444534302
Validation loss: 1.697030931390742

Epoch: 6| Step: 12
Training loss: 1.0839102268218994
Validation loss: 1.6946753430110153

Epoch: 6| Step: 13
Training loss: 0.7026563286781311
Validation loss: 1.6844912446955198

Epoch: 239| Step: 0
Training loss: 0.44483351707458496
Validation loss: 1.6814594166253203

Epoch: 6| Step: 1
Training loss: 0.4232776165008545
Validation loss: 1.6664036820011754

Epoch: 6| Step: 2
Training loss: 0.404654860496521
Validation loss: 1.6633854681445706

Epoch: 6| Step: 3
Training loss: 0.7791407704353333
Validation loss: 1.6663676769502702

Epoch: 6| Step: 4
Training loss: 0.5594184398651123
Validation loss: 1.655959706152639

Epoch: 6| Step: 5
Training loss: 0.5680755972862244
Validation loss: 1.6481361991615706

Epoch: 6| Step: 6
Training loss: 0.5076231360435486
Validation loss: 1.6790994674928728

Epoch: 6| Step: 7
Training loss: 0.5226951241493225
Validation loss: 1.6998286836890764

Epoch: 6| Step: 8
Training loss: 0.6856904029846191
Validation loss: 1.7062711151697303

Epoch: 6| Step: 9
Training loss: 0.9748486876487732
Validation loss: 1.7162190060461722

Epoch: 6| Step: 10
Training loss: 0.9759556651115417
Validation loss: 1.7038126741686175

Epoch: 6| Step: 11
Training loss: 0.6815806031227112
Validation loss: 1.7051773481471564

Epoch: 6| Step: 12
Training loss: 0.41045641899108887
Validation loss: 1.707815506125009

Epoch: 6| Step: 13
Training loss: 0.3738156855106354
Validation loss: 1.6918994137035903

Epoch: 240| Step: 0
Training loss: 0.5878956317901611
Validation loss: 1.696938600591434

Epoch: 6| Step: 1
Training loss: 0.6212505102157593
Validation loss: 1.7100839268776677

Epoch: 6| Step: 2
Training loss: 0.6363996863365173
Validation loss: 1.7085109436383812

Epoch: 6| Step: 3
Training loss: 0.7064098119735718
Validation loss: 1.699899220979342

Epoch: 6| Step: 4
Training loss: 0.3316762447357178
Validation loss: 1.6636430448101414

Epoch: 6| Step: 5
Training loss: 0.9512190818786621
Validation loss: 1.691204878591722

Epoch: 6| Step: 6
Training loss: 0.193728506565094
Validation loss: 1.6813444475973807

Epoch: 6| Step: 7
Training loss: 1.0797216892242432
Validation loss: 1.6468712616992254

Epoch: 6| Step: 8
Training loss: 0.6581409573554993
Validation loss: 1.6519691457030594

Epoch: 6| Step: 9
Training loss: 0.40893590450286865
Validation loss: 1.6602981064909248

Epoch: 6| Step: 10
Training loss: 0.49872708320617676
Validation loss: 1.6764851603456723

Epoch: 6| Step: 11
Training loss: 0.8963526487350464
Validation loss: 1.6607123485175512

Epoch: 6| Step: 12
Training loss: 0.20926743745803833
Validation loss: 1.6990048936618272

Epoch: 6| Step: 13
Training loss: 0.9641938805580139
Validation loss: 1.6817488272984822

Epoch: 241| Step: 0
Training loss: 0.6178637742996216
Validation loss: 1.6939476664348314

Epoch: 6| Step: 1
Training loss: 0.5481286644935608
Validation loss: 1.7203455740405666

Epoch: 6| Step: 2
Training loss: 0.7733663320541382
Validation loss: 1.7237109368847263

Epoch: 6| Step: 3
Training loss: 0.8911172151565552
Validation loss: 1.7000368564359603

Epoch: 6| Step: 4
Training loss: 0.7601416707038879
Validation loss: 1.6905002158175233

Epoch: 6| Step: 5
Training loss: 0.5426158905029297
Validation loss: 1.6840213421852357

Epoch: 6| Step: 6
Training loss: 0.47860944271087646
Validation loss: 1.6827364762624104

Epoch: 6| Step: 7
Training loss: 0.5357326865196228
Validation loss: 1.6953700678322905

Epoch: 6| Step: 8
Training loss: 0.903235912322998
Validation loss: 1.6773944785518031

Epoch: 6| Step: 9
Training loss: 0.6233140826225281
Validation loss: 1.6687247971052765

Epoch: 6| Step: 10
Training loss: 0.3203365206718445
Validation loss: 1.6533658299394833

Epoch: 6| Step: 11
Training loss: 0.27341535687446594
Validation loss: 1.6541675008753294

Epoch: 6| Step: 12
Training loss: 0.4731384217739105
Validation loss: 1.6804143510838991

Epoch: 6| Step: 13
Training loss: 0.2583191692829132
Validation loss: 1.700188322092897

Epoch: 242| Step: 0
Training loss: 0.4508068263530731
Validation loss: 1.7176792172975437

Epoch: 6| Step: 1
Training loss: 0.5646154880523682
Validation loss: 1.6737148774567472

Epoch: 6| Step: 2
Training loss: 0.8786892890930176
Validation loss: 1.6687585205160163

Epoch: 6| Step: 3
Training loss: 0.7340890765190125
Validation loss: 1.6414842169771913

Epoch: 6| Step: 4
Training loss: 0.7053391933441162
Validation loss: 1.63983779568826

Epoch: 6| Step: 5
Training loss: 0.5536866188049316
Validation loss: 1.6300071362526185

Epoch: 6| Step: 6
Training loss: 0.34707286953926086
Validation loss: 1.6243189175923665

Epoch: 6| Step: 7
Training loss: 0.43522918224334717
Validation loss: 1.6327160917302614

Epoch: 6| Step: 8
Training loss: 0.3549947738647461
Validation loss: 1.661669651667277

Epoch: 6| Step: 9
Training loss: 0.3464391827583313
Validation loss: 1.6660394002032537

Epoch: 6| Step: 10
Training loss: 0.7228288650512695
Validation loss: 1.688224938607985

Epoch: 6| Step: 11
Training loss: 0.8919411301612854
Validation loss: 1.67793490681597

Epoch: 6| Step: 12
Training loss: 0.5143218040466309
Validation loss: 1.685859308447889

Epoch: 6| Step: 13
Training loss: 0.46675682067871094
Validation loss: 1.6396056580287155

Epoch: 243| Step: 0
Training loss: 0.8822630643844604
Validation loss: 1.631517335932742

Epoch: 6| Step: 1
Training loss: 0.3600403368473053
Validation loss: 1.6830115587480607

Epoch: 6| Step: 2
Training loss: 0.4316490888595581
Validation loss: 1.6951232969119985

Epoch: 6| Step: 3
Training loss: 0.5770662426948547
Validation loss: 1.665760145392469

Epoch: 6| Step: 4
Training loss: 0.5214172601699829
Validation loss: 1.6445942809504848

Epoch: 6| Step: 5
Training loss: 0.3375067114830017
Validation loss: 1.683599313100179

Epoch: 6| Step: 6
Training loss: 0.5849287509918213
Validation loss: 1.6722931682422597

Epoch: 6| Step: 7
Training loss: 0.5604676008224487
Validation loss: 1.6923640222959622

Epoch: 6| Step: 8
Training loss: 0.2645021677017212
Validation loss: 1.6994125996866534

Epoch: 6| Step: 9
Training loss: 0.8405459523200989
Validation loss: 1.7023429883423673

Epoch: 6| Step: 10
Training loss: 0.8134633302688599
Validation loss: 1.7114651792792863

Epoch: 6| Step: 11
Training loss: 0.9525309801101685
Validation loss: 1.669620680552657

Epoch: 6| Step: 12
Training loss: 0.5064677596092224
Validation loss: 1.6601170532165035

Epoch: 6| Step: 13
Training loss: 0.4069845378398895
Validation loss: 1.6424237169245237

Epoch: 244| Step: 0
Training loss: 0.6596322059631348
Validation loss: 1.6532909357419578

Epoch: 6| Step: 1
Training loss: 0.4850674569606781
Validation loss: 1.6740088565375215

Epoch: 6| Step: 2
Training loss: 0.6914559602737427
Validation loss: 1.6681793300054406

Epoch: 6| Step: 3
Training loss: 0.6119447946548462
Validation loss: 1.6457069304681593

Epoch: 6| Step: 4
Training loss: 0.7780836224555969
Validation loss: 1.6386119268273796

Epoch: 6| Step: 5
Training loss: 0.32214903831481934
Validation loss: 1.6713767654152327

Epoch: 6| Step: 6
Training loss: 0.40857911109924316
Validation loss: 1.6709107352841286

Epoch: 6| Step: 7
Training loss: 0.6227420568466187
Validation loss: 1.6387068443400885

Epoch: 6| Step: 8
Training loss: 0.26061031222343445
Validation loss: 1.6396884751576248

Epoch: 6| Step: 9
Training loss: 0.6136324405670166
Validation loss: 1.638530308200467

Epoch: 6| Step: 10
Training loss: 0.4066286087036133
Validation loss: 1.6502047854085122

Epoch: 6| Step: 11
Training loss: 0.6047744750976562
Validation loss: 1.6456459863211519

Epoch: 6| Step: 12
Training loss: 0.8085092902183533
Validation loss: 1.649928318556919

Epoch: 6| Step: 13
Training loss: 0.38985657691955566
Validation loss: 1.6496558817484046

Epoch: 245| Step: 0
Training loss: 0.5757846236228943
Validation loss: 1.6508432126814319

Epoch: 6| Step: 1
Training loss: 0.5961202383041382
Validation loss: 1.6704419787212084

Epoch: 6| Step: 2
Training loss: 0.5957798957824707
Validation loss: 1.646424570391255

Epoch: 6| Step: 3
Training loss: 0.6076455116271973
Validation loss: 1.632872878223337

Epoch: 6| Step: 4
Training loss: 0.4289519190788269
Validation loss: 1.6114747114078973

Epoch: 6| Step: 5
Training loss: 0.9616973996162415
Validation loss: 1.6112226863061228

Epoch: 6| Step: 6
Training loss: 0.7461835741996765
Validation loss: 1.6065553670288415

Epoch: 6| Step: 7
Training loss: 0.22931690514087677
Validation loss: 1.5944818745377243

Epoch: 6| Step: 8
Training loss: 0.7387905120849609
Validation loss: 1.6216167660169705

Epoch: 6| Step: 9
Training loss: 0.3583284318447113
Validation loss: 1.6359614364562496

Epoch: 6| Step: 10
Training loss: 0.45483720302581787
Validation loss: 1.640354666658627

Epoch: 6| Step: 11
Training loss: 0.35217297077178955
Validation loss: 1.657632707267679

Epoch: 6| Step: 12
Training loss: 0.42683500051498413
Validation loss: 1.6479384078774402

Epoch: 6| Step: 13
Training loss: 0.40454763174057007
Validation loss: 1.6497668989243046

Epoch: 246| Step: 0
Training loss: 0.6665416955947876
Validation loss: 1.6461536320306922

Epoch: 6| Step: 1
Training loss: 0.3842059373855591
Validation loss: 1.6674200680948073

Epoch: 6| Step: 2
Training loss: 0.38477182388305664
Validation loss: 1.660918612633982

Epoch: 6| Step: 3
Training loss: 0.41784965991973877
Validation loss: 1.648273346244648

Epoch: 6| Step: 4
Training loss: 0.5815532207489014
Validation loss: 1.6594182137520082

Epoch: 6| Step: 5
Training loss: 0.4610925316810608
Validation loss: 1.6752729172347693

Epoch: 6| Step: 6
Training loss: 0.3689359426498413
Validation loss: 1.6987465837950348

Epoch: 6| Step: 7
Training loss: 0.7302825450897217
Validation loss: 1.6716721903893255

Epoch: 6| Step: 8
Training loss: 0.3621557354927063
Validation loss: 1.6858814865030267

Epoch: 6| Step: 9
Training loss: 0.31067702174186707
Validation loss: 1.7038370716956355

Epoch: 6| Step: 10
Training loss: 0.4197697639465332
Validation loss: 1.6974284020803307

Epoch: 6| Step: 11
Training loss: 0.8150614500045776
Validation loss: 1.6927387932295441

Epoch: 6| Step: 12
Training loss: 0.8905540108680725
Validation loss: 1.6811634314957487

Epoch: 6| Step: 13
Training loss: 0.5570639967918396
Validation loss: 1.6954799031698575

Epoch: 247| Step: 0
Training loss: 0.5311752557754517
Validation loss: 1.6839786319322483

Epoch: 6| Step: 1
Training loss: 0.7198286652565002
Validation loss: 1.6317727411946943

Epoch: 6| Step: 2
Training loss: 0.42944854497909546
Validation loss: 1.6589108000519455

Epoch: 6| Step: 3
Training loss: 0.6463778614997864
Validation loss: 1.6653494270898963

Epoch: 6| Step: 4
Training loss: 0.5472844839096069
Validation loss: 1.6471351346661967

Epoch: 6| Step: 5
Training loss: 0.6708052754402161
Validation loss: 1.6276279495608421

Epoch: 6| Step: 6
Training loss: 0.5177688002586365
Validation loss: 1.6548646932007165

Epoch: 6| Step: 7
Training loss: 0.5047948360443115
Validation loss: 1.6662920803152106

Epoch: 6| Step: 8
Training loss: 0.40942034125328064
Validation loss: 1.6691934767589773

Epoch: 6| Step: 9
Training loss: 0.543411135673523
Validation loss: 1.6689354719654206

Epoch: 6| Step: 10
Training loss: 0.4953117072582245
Validation loss: 1.6839559808854134

Epoch: 6| Step: 11
Training loss: 0.542868971824646
Validation loss: 1.6918420996717227

Epoch: 6| Step: 12
Training loss: 0.7029361724853516
Validation loss: 1.6859760720242736

Epoch: 6| Step: 13
Training loss: 0.4262382388114929
Validation loss: 1.6857473004248835

Epoch: 248| Step: 0
Training loss: 0.5160109400749207
Validation loss: 1.6667322984305761

Epoch: 6| Step: 1
Training loss: 0.621772825717926
Validation loss: 1.6589290172823015

Epoch: 6| Step: 2
Training loss: 0.5160188674926758
Validation loss: 1.6825072778168546

Epoch: 6| Step: 3
Training loss: 0.6328985095024109
Validation loss: 1.683897892634074

Epoch: 6| Step: 4
Training loss: 0.32836002111434937
Validation loss: 1.6738382975260417

Epoch: 6| Step: 5
Training loss: 0.5710916519165039
Validation loss: 1.678050838490968

Epoch: 6| Step: 6
Training loss: 0.7108691930770874
Validation loss: 1.6775893947129608

Epoch: 6| Step: 7
Training loss: 0.4827353358268738
Validation loss: 1.6509869355027393

Epoch: 6| Step: 8
Training loss: 0.49055635929107666
Validation loss: 1.6830263599272697

Epoch: 6| Step: 9
Training loss: 0.5614166259765625
Validation loss: 1.6779371717924714

Epoch: 6| Step: 10
Training loss: 0.42142441868782043
Validation loss: 1.7053063505439348

Epoch: 6| Step: 11
Training loss: 0.5245894193649292
Validation loss: 1.6931543273310508

Epoch: 6| Step: 12
Training loss: 0.45972248911857605
Validation loss: 1.6734860071571924

Epoch: 6| Step: 13
Training loss: 0.363982617855072
Validation loss: 1.6550136471307406

Epoch: 249| Step: 0
Training loss: 0.40423041582107544
Validation loss: 1.655881119030778

Epoch: 6| Step: 1
Training loss: 0.5307193994522095
Validation loss: 1.6564908399376819

Epoch: 6| Step: 2
Training loss: 0.610999345779419
Validation loss: 1.659143526067016

Epoch: 6| Step: 3
Training loss: 0.361480712890625
Validation loss: 1.6634499398610925

Epoch: 6| Step: 4
Training loss: 0.4094429612159729
Validation loss: 1.651309028748543

Epoch: 6| Step: 5
Training loss: 0.41709691286087036
Validation loss: 1.6938280495264197

Epoch: 6| Step: 6
Training loss: 0.703401505947113
Validation loss: 1.6909309574352798

Epoch: 6| Step: 7
Training loss: 0.6088435053825378
Validation loss: 1.6978114676731888

Epoch: 6| Step: 8
Training loss: 0.3987521529197693
Validation loss: 1.6932922383790374

Epoch: 6| Step: 9
Training loss: 0.6181604266166687
Validation loss: 1.6902836048474876

Epoch: 6| Step: 10
Training loss: 0.6170818209648132
Validation loss: 1.679653839398456

Epoch: 6| Step: 11
Training loss: 0.3874015808105469
Validation loss: 1.6639475630175682

Epoch: 6| Step: 12
Training loss: 0.7891853451728821
Validation loss: 1.6388379412312661

Epoch: 6| Step: 13
Training loss: 0.4782665967941284
Validation loss: 1.6457327527384604

Epoch: 250| Step: 0
Training loss: 0.42738524079322815
Validation loss: 1.6720148299330024

Epoch: 6| Step: 1
Training loss: 0.8342074751853943
Validation loss: 1.648547739110967

Epoch: 6| Step: 2
Training loss: 0.41610729694366455
Validation loss: 1.6485505475792834

Epoch: 6| Step: 3
Training loss: 0.5983461737632751
Validation loss: 1.674515357581518

Epoch: 6| Step: 4
Training loss: 0.46121537685394287
Validation loss: 1.6861001419764694

Epoch: 6| Step: 5
Training loss: 0.6778387427330017
Validation loss: 1.7136217330091743

Epoch: 6| Step: 6
Training loss: 0.6354939341545105
Validation loss: 1.7126528434855963

Epoch: 6| Step: 7
Training loss: 0.19834083318710327
Validation loss: 1.6660583788348782

Epoch: 6| Step: 8
Training loss: 0.4018874168395996
Validation loss: 1.6361363164840206

Epoch: 6| Step: 9
Training loss: 0.5496742129325867
Validation loss: 1.6586150635955155

Epoch: 6| Step: 10
Training loss: 0.5751477479934692
Validation loss: 1.6620321530167774

Epoch: 6| Step: 11
Training loss: 0.2641107738018036
Validation loss: 1.6719254909023162

Epoch: 6| Step: 12
Training loss: 0.650148868560791
Validation loss: 1.6791295800157773

Epoch: 6| Step: 13
Training loss: 0.7587764263153076
Validation loss: 1.6753429969151814

Epoch: 251| Step: 0
Training loss: 0.5361955165863037
Validation loss: 1.6611843852586643

Epoch: 6| Step: 1
Training loss: 0.6639697551727295
Validation loss: 1.65843766479082

Epoch: 6| Step: 2
Training loss: 0.4802597761154175
Validation loss: 1.6751073188679193

Epoch: 6| Step: 3
Training loss: 0.5527781844139099
Validation loss: 1.7070382589934974

Epoch: 6| Step: 4
Training loss: 0.7490364909172058
Validation loss: 1.6877252645390008

Epoch: 6| Step: 5
Training loss: 0.5696322321891785
Validation loss: 1.6708458521032845

Epoch: 6| Step: 6
Training loss: 0.5367692708969116
Validation loss: 1.67022063655238

Epoch: 6| Step: 7
Training loss: 0.23121443390846252
Validation loss: 1.6528231777170652

Epoch: 6| Step: 8
Training loss: 0.44025492668151855
Validation loss: 1.634171821737802

Epoch: 6| Step: 9
Training loss: 0.6215802431106567
Validation loss: 1.6367532130210631

Epoch: 6| Step: 10
Training loss: 0.6731243133544922
Validation loss: 1.6485404320942458

Epoch: 6| Step: 11
Training loss: 0.4332268536090851
Validation loss: 1.6352157797864688

Epoch: 6| Step: 12
Training loss: 0.5419957637786865
Validation loss: 1.65082565687036

Epoch: 6| Step: 13
Training loss: 0.38639330863952637
Validation loss: 1.657430560358109

Epoch: 252| Step: 0
Training loss: 0.5312317609786987
Validation loss: 1.6928648474395915

Epoch: 6| Step: 1
Training loss: 0.5053377151489258
Validation loss: 1.6922823876462958

Epoch: 6| Step: 2
Training loss: 0.4588865041732788
Validation loss: 1.7069978585807226

Epoch: 6| Step: 3
Training loss: 0.2846623957157135
Validation loss: 1.6874065463260939

Epoch: 6| Step: 4
Training loss: 0.5185721516609192
Validation loss: 1.6688840440524522

Epoch: 6| Step: 5
Training loss: 0.37299469113349915
Validation loss: 1.6915005958208473

Epoch: 6| Step: 6
Training loss: 0.8543566465377808
Validation loss: 1.6840052732857325

Epoch: 6| Step: 7
Training loss: 0.5559831857681274
Validation loss: 1.6741980942346717

Epoch: 6| Step: 8
Training loss: 0.40715280175209045
Validation loss: 1.6732146804050734

Epoch: 6| Step: 9
Training loss: 0.7761660218238831
Validation loss: 1.6851815382639568

Epoch: 6| Step: 10
Training loss: 0.5873422622680664
Validation loss: 1.6707237971726285

Epoch: 6| Step: 11
Training loss: 0.5607291460037231
Validation loss: 1.669964253261525

Epoch: 6| Step: 12
Training loss: 0.45246344804763794
Validation loss: 1.6670048211210517

Epoch: 6| Step: 13
Training loss: 0.2384611964225769
Validation loss: 1.6470587766298683

Epoch: 253| Step: 0
Training loss: 0.12023438513278961
Validation loss: 1.655281811632136

Epoch: 6| Step: 1
Training loss: 0.4817989468574524
Validation loss: 1.6678797352698542

Epoch: 6| Step: 2
Training loss: 0.4438478350639343
Validation loss: 1.6605901871958086

Epoch: 6| Step: 3
Training loss: 0.7008605003356934
Validation loss: 1.62011714776357

Epoch: 6| Step: 4
Training loss: 0.5436686277389526
Validation loss: 1.6386614755917621

Epoch: 6| Step: 5
Training loss: 0.5287782549858093
Validation loss: 1.6197764899141045

Epoch: 6| Step: 6
Training loss: 0.5094614028930664
Validation loss: 1.6166593567017586

Epoch: 6| Step: 7
Training loss: 0.6784691214561462
Validation loss: 1.6163849035898845

Epoch: 6| Step: 8
Training loss: 0.5885677933692932
Validation loss: 1.644723621747827

Epoch: 6| Step: 9
Training loss: 0.3733856678009033
Validation loss: 1.6430615186691284

Epoch: 6| Step: 10
Training loss: 0.3098638951778412
Validation loss: 1.621714662480098

Epoch: 6| Step: 11
Training loss: 0.2655951678752899
Validation loss: 1.654639414561692

Epoch: 6| Step: 12
Training loss: 0.48630663752555847
Validation loss: 1.655544432260657

Epoch: 6| Step: 13
Training loss: 0.38927915692329407
Validation loss: 1.6543919194129206

Epoch: 254| Step: 0
Training loss: 0.46750321984291077
Validation loss: 1.6510871161696732

Epoch: 6| Step: 1
Training loss: 0.48385512828826904
Validation loss: 1.6283451395650064

Epoch: 6| Step: 2
Training loss: 0.5639826059341431
Validation loss: 1.6343786998461651

Epoch: 6| Step: 3
Training loss: 0.42850691080093384
Validation loss: 1.6391381935406757

Epoch: 6| Step: 4
Training loss: 0.4263851046562195
Validation loss: 1.6011032122437672

Epoch: 6| Step: 5
Training loss: 0.6251680850982666
Validation loss: 1.6232673339946295

Epoch: 6| Step: 6
Training loss: 0.5042088031768799
Validation loss: 1.6164323476053053

Epoch: 6| Step: 7
Training loss: 0.2646004259586334
Validation loss: 1.6179783651905675

Epoch: 6| Step: 8
Training loss: 0.43642550706863403
Validation loss: 1.6226740383332776

Epoch: 6| Step: 9
Training loss: 0.34960055351257324
Validation loss: 1.6239716314500379

Epoch: 6| Step: 10
Training loss: 0.4628652334213257
Validation loss: 1.623225873516452

Epoch: 6| Step: 11
Training loss: 0.2783712148666382
Validation loss: 1.6387026540694698

Epoch: 6| Step: 12
Training loss: 0.6187467575073242
Validation loss: 1.6307602390166251

Epoch: 6| Step: 13
Training loss: 0.7629492282867432
Validation loss: 1.6584270397822063

Epoch: 255| Step: 0
Training loss: 0.572234570980072
Validation loss: 1.6627597949838127

Epoch: 6| Step: 1
Training loss: 0.5784559845924377
Validation loss: 1.6554039498811126

Epoch: 6| Step: 2
Training loss: 0.2976849675178528
Validation loss: 1.6486361898401731

Epoch: 6| Step: 3
Training loss: 0.5818432569503784
Validation loss: 1.6235685733056837

Epoch: 6| Step: 4
Training loss: 0.44445765018463135
Validation loss: 1.6450377920622468

Epoch: 6| Step: 5
Training loss: 0.6971954703330994
Validation loss: 1.6731246222731888

Epoch: 6| Step: 6
Training loss: 0.4221923351287842
Validation loss: 1.6444010170557166

Epoch: 6| Step: 7
Training loss: 0.7196052074432373
Validation loss: 1.6238443518197665

Epoch: 6| Step: 8
Training loss: 0.3561384975910187
Validation loss: 1.622071071337628

Epoch: 6| Step: 9
Training loss: 0.4148339033126831
Validation loss: 1.6374880293364167

Epoch: 6| Step: 10
Training loss: 0.5267493724822998
Validation loss: 1.6492052667884416

Epoch: 6| Step: 11
Training loss: 0.6444113254547119
Validation loss: 1.6560547838928878

Epoch: 6| Step: 12
Training loss: 0.36899080872535706
Validation loss: 1.6727599931019608

Epoch: 6| Step: 13
Training loss: 0.5098984837532043
Validation loss: 1.6562673071379304

Epoch: 256| Step: 0
Training loss: 0.3942776322364807
Validation loss: 1.6725880727973035

Epoch: 6| Step: 1
Training loss: 0.4321384131908417
Validation loss: 1.6430417491543678

Epoch: 6| Step: 2
Training loss: 0.6945980787277222
Validation loss: 1.6764162919854606

Epoch: 6| Step: 3
Training loss: 0.37239912152290344
Validation loss: 1.6718006005851171

Epoch: 6| Step: 4
Training loss: 0.5258930325508118
Validation loss: 1.6628044266854562

Epoch: 6| Step: 5
Training loss: 0.3412395119667053
Validation loss: 1.6651007001117994

Epoch: 6| Step: 6
Training loss: 0.5698538422584534
Validation loss: 1.6594164486854308

Epoch: 6| Step: 7
Training loss: 0.5922803282737732
Validation loss: 1.6610633852661296

Epoch: 6| Step: 8
Training loss: 0.5110625624656677
Validation loss: 1.6594644285017444

Epoch: 6| Step: 9
Training loss: 0.5052918791770935
Validation loss: 1.653217871983846

Epoch: 6| Step: 10
Training loss: 0.47148028016090393
Validation loss: 1.6536223106486823

Epoch: 6| Step: 11
Training loss: 0.40949392318725586
Validation loss: 1.6442206636551888

Epoch: 6| Step: 12
Training loss: 0.4291103482246399
Validation loss: 1.6565760374069214

Epoch: 6| Step: 13
Training loss: 0.3155897855758667
Validation loss: 1.6286276732721636

Epoch: 257| Step: 0
Training loss: 0.30125755071640015
Validation loss: 1.653829861712712

Epoch: 6| Step: 1
Training loss: 0.5133951306343079
Validation loss: 1.6133100858298681

Epoch: 6| Step: 2
Training loss: 0.49680718779563904
Validation loss: 1.6450133990215998

Epoch: 6| Step: 3
Training loss: 0.5152245759963989
Validation loss: 1.6491735058446084

Epoch: 6| Step: 4
Training loss: 0.706397533416748
Validation loss: 1.6427795194810437

Epoch: 6| Step: 5
Training loss: 0.40972161293029785
Validation loss: 1.6388841649537444

Epoch: 6| Step: 6
Training loss: 0.6445778012275696
Validation loss: 1.6468472160318846

Epoch: 6| Step: 7
Training loss: 0.4011951684951782
Validation loss: 1.6151218145124373

Epoch: 6| Step: 8
Training loss: 0.38971012830734253
Validation loss: 1.61171737024861

Epoch: 6| Step: 9
Training loss: 0.843431830406189
Validation loss: 1.6078331393580283

Epoch: 6| Step: 10
Training loss: 0.5336273908615112
Validation loss: 1.6296112460474814

Epoch: 6| Step: 11
Training loss: 0.4085213840007782
Validation loss: 1.6568061972177157

Epoch: 6| Step: 12
Training loss: 0.4504833519458771
Validation loss: 1.639185465792174

Epoch: 6| Step: 13
Training loss: 0.38279470801353455
Validation loss: 1.6599629207323956

Epoch: 258| Step: 0
Training loss: 0.546535849571228
Validation loss: 1.6589998070911696

Epoch: 6| Step: 1
Training loss: 0.302130788564682
Validation loss: 1.6693691425426032

Epoch: 6| Step: 2
Training loss: 0.4121822416782379
Validation loss: 1.6762743303852696

Epoch: 6| Step: 3
Training loss: 0.4629230797290802
Validation loss: 1.6545195553892402

Epoch: 6| Step: 4
Training loss: 0.4538828730583191
Validation loss: 1.6679963988642539

Epoch: 6| Step: 5
Training loss: 0.5952348709106445
Validation loss: 1.6715168427395564

Epoch: 6| Step: 6
Training loss: 0.39745840430259705
Validation loss: 1.6726074346932032

Epoch: 6| Step: 7
Training loss: 0.41460299491882324
Validation loss: 1.6742171613118981

Epoch: 6| Step: 8
Training loss: 0.4664187431335449
Validation loss: 1.6752476769108926

Epoch: 6| Step: 9
Training loss: 0.46771517395973206
Validation loss: 1.6832215542434363

Epoch: 6| Step: 10
Training loss: 0.33567672967910767
Validation loss: 1.6651657448020032

Epoch: 6| Step: 11
Training loss: 0.5250746011734009
Validation loss: 1.6762579846125778

Epoch: 6| Step: 12
Training loss: 0.8119664788246155
Validation loss: 1.6790596618447253

Epoch: 6| Step: 13
Training loss: 0.31011152267456055
Validation loss: 1.6551529310082878

Epoch: 259| Step: 0
Training loss: 0.35712864995002747
Validation loss: 1.6417614913755847

Epoch: 6| Step: 1
Training loss: 0.4445415139198303
Validation loss: 1.633380381009912

Epoch: 6| Step: 2
Training loss: 0.3924449682235718
Validation loss: 1.651913804392661

Epoch: 6| Step: 3
Training loss: 0.40717077255249023
Validation loss: 1.6609231675824812

Epoch: 6| Step: 4
Training loss: 0.5424152612686157
Validation loss: 1.649480724847445

Epoch: 6| Step: 5
Training loss: 0.5341018438339233
Validation loss: 1.641915016276862

Epoch: 6| Step: 6
Training loss: 0.49595192074775696
Validation loss: 1.6488823890686035

Epoch: 6| Step: 7
Training loss: 0.5415617227554321
Validation loss: 1.639139183105961

Epoch: 6| Step: 8
Training loss: 0.2410055249929428
Validation loss: 1.6676590910521887

Epoch: 6| Step: 9
Training loss: 0.7144812345504761
Validation loss: 1.6647230066278929

Epoch: 6| Step: 10
Training loss: 0.3591201901435852
Validation loss: 1.674348541485366

Epoch: 6| Step: 11
Training loss: 0.7009585499763489
Validation loss: 1.62968736310159

Epoch: 6| Step: 12
Training loss: 0.48057979345321655
Validation loss: 1.6261362388569822

Epoch: 6| Step: 13
Training loss: 0.5467520952224731
Validation loss: 1.6224194925318483

Epoch: 260| Step: 0
Training loss: 0.44871756434440613
Validation loss: 1.6270131885364492

Epoch: 6| Step: 1
Training loss: 0.7073932886123657
Validation loss: 1.6360788114609257

Epoch: 6| Step: 2
Training loss: 0.30737194418907166
Validation loss: 1.6406927595856369

Epoch: 6| Step: 3
Training loss: 0.5147780179977417
Validation loss: 1.6347424727614208

Epoch: 6| Step: 4
Training loss: 0.5096346139907837
Validation loss: 1.6506145692640735

Epoch: 6| Step: 5
Training loss: 0.3083968162536621
Validation loss: 1.63716749734776

Epoch: 6| Step: 6
Training loss: 0.7519502639770508
Validation loss: 1.647246765834029

Epoch: 6| Step: 7
Training loss: 0.38442230224609375
Validation loss: 1.6428555160440423

Epoch: 6| Step: 8
Training loss: 0.3175356388092041
Validation loss: 1.642190997318555

Epoch: 6| Step: 9
Training loss: 0.4642038345336914
Validation loss: 1.6599794036598616

Epoch: 6| Step: 10
Training loss: 0.4653007388114929
Validation loss: 1.6363617425323815

Epoch: 6| Step: 11
Training loss: 0.33898216485977173
Validation loss: 1.644397392067858

Epoch: 6| Step: 12
Training loss: 0.4428896903991699
Validation loss: 1.6126783227407804

Epoch: 6| Step: 13
Training loss: 0.7103743553161621
Validation loss: 1.6212979580766411

Epoch: 261| Step: 0
Training loss: 0.6015021204948425
Validation loss: 1.6281008015396774

Epoch: 6| Step: 1
Training loss: 0.47048822045326233
Validation loss: 1.6194535980942428

Epoch: 6| Step: 2
Training loss: 0.39639925956726074
Validation loss: 1.628680795751592

Epoch: 6| Step: 3
Training loss: 0.5867615938186646
Validation loss: 1.621822044413577

Epoch: 6| Step: 4
Training loss: 0.40863025188446045
Validation loss: 1.638702336178031

Epoch: 6| Step: 5
Training loss: 0.3509662449359894
Validation loss: 1.6031297586297477

Epoch: 6| Step: 6
Training loss: 0.4419783353805542
Validation loss: 1.626514519414594

Epoch: 6| Step: 7
Training loss: 0.42052745819091797
Validation loss: 1.6422198318666028

Epoch: 6| Step: 8
Training loss: 0.5331218242645264
Validation loss: 1.6540931450423373

Epoch: 6| Step: 9
Training loss: 0.4302797317504883
Validation loss: 1.6477790148027482

Epoch: 6| Step: 10
Training loss: 0.29393404722213745
Validation loss: 1.6442280905221098

Epoch: 6| Step: 11
Training loss: 0.2901563048362732
Validation loss: 1.6412457701980427

Epoch: 6| Step: 12
Training loss: 0.38561540842056274
Validation loss: 1.6690896505950599

Epoch: 6| Step: 13
Training loss: 0.3339283764362335
Validation loss: 1.6493205588351014

Epoch: 262| Step: 0
Training loss: 0.4686443507671356
Validation loss: 1.6654212814505382

Epoch: 6| Step: 1
Training loss: 0.3982987701892853
Validation loss: 1.6609775033048404

Epoch: 6| Step: 2
Training loss: 0.6903984546661377
Validation loss: 1.6499062917565788

Epoch: 6| Step: 3
Training loss: 0.25644662976264954
Validation loss: 1.659218527937448

Epoch: 6| Step: 4
Training loss: 0.3635925054550171
Validation loss: 1.656709123683232

Epoch: 6| Step: 5
Training loss: 0.47418901324272156
Validation loss: 1.6565605145628735

Epoch: 6| Step: 6
Training loss: 0.35286301374435425
Validation loss: 1.689909344078392

Epoch: 6| Step: 7
Training loss: 0.4902094602584839
Validation loss: 1.676540405519547

Epoch: 6| Step: 8
Training loss: 0.3595164716243744
Validation loss: 1.6553238662340308

Epoch: 6| Step: 9
Training loss: 0.3309558629989624
Validation loss: 1.6560959892888223

Epoch: 6| Step: 10
Training loss: 0.6997509002685547
Validation loss: 1.6726163471898725

Epoch: 6| Step: 11
Training loss: 0.43983256816864014
Validation loss: 1.6611977187536096

Epoch: 6| Step: 12
Training loss: 0.3689050078392029
Validation loss: 1.6367170887608682

Epoch: 6| Step: 13
Training loss: 0.18017451465129852
Validation loss: 1.651827375094096

Epoch: 263| Step: 0
Training loss: 0.3321727514266968
Validation loss: 1.6550777394284484

Epoch: 6| Step: 1
Training loss: 0.3664281964302063
Validation loss: 1.652778492178968

Epoch: 6| Step: 2
Training loss: 0.47932422161102295
Validation loss: 1.6561501590154504

Epoch: 6| Step: 3
Training loss: 0.4779849648475647
Validation loss: 1.6521753982831073

Epoch: 6| Step: 4
Training loss: 0.5555816292762756
Validation loss: 1.644474821705972

Epoch: 6| Step: 5
Training loss: 0.6124548316001892
Validation loss: 1.6191033932470507

Epoch: 6| Step: 6
Training loss: 0.16941192746162415
Validation loss: 1.6203224492329422

Epoch: 6| Step: 7
Training loss: 0.2942143678665161
Validation loss: 1.64289153006769

Epoch: 6| Step: 8
Training loss: 0.30796486139297485
Validation loss: 1.625909783506906

Epoch: 6| Step: 9
Training loss: 0.49893757700920105
Validation loss: 1.6492672158825783

Epoch: 6| Step: 10
Training loss: 0.4187830686569214
Validation loss: 1.6347210509802705

Epoch: 6| Step: 11
Training loss: 0.5750339031219482
Validation loss: 1.6450950022666686

Epoch: 6| Step: 12
Training loss: 0.3897564709186554
Validation loss: 1.632448357920493

Epoch: 6| Step: 13
Training loss: 0.5132097005844116
Validation loss: 1.6581624964232087

Epoch: 264| Step: 0
Training loss: 0.7329584360122681
Validation loss: 1.6420058999010312

Epoch: 6| Step: 1
Training loss: 0.43424278497695923
Validation loss: 1.6493588057897424

Epoch: 6| Step: 2
Training loss: 0.4115108251571655
Validation loss: 1.6486322367063133

Epoch: 6| Step: 3
Training loss: 0.2277003526687622
Validation loss: 1.6346195333747453

Epoch: 6| Step: 4
Training loss: 0.40044087171554565
Validation loss: 1.6661684923274542

Epoch: 6| Step: 5
Training loss: 0.2602991461753845
Validation loss: 1.653299141955632

Epoch: 6| Step: 6
Training loss: 0.2696453332901001
Validation loss: 1.6400977924305906

Epoch: 6| Step: 7
Training loss: 0.3512970805168152
Validation loss: 1.6224079170534689

Epoch: 6| Step: 8
Training loss: 0.6061110496520996
Validation loss: 1.6340513408824962

Epoch: 6| Step: 9
Training loss: 0.14885185658931732
Validation loss: 1.6477884079820366

Epoch: 6| Step: 10
Training loss: 0.480013906955719
Validation loss: 1.639176107222034

Epoch: 6| Step: 11
Training loss: 0.292476087808609
Validation loss: 1.6316255279766616

Epoch: 6| Step: 12
Training loss: 0.5719282627105713
Validation loss: 1.6273217713961037

Epoch: 6| Step: 13
Training loss: 0.44726699590682983
Validation loss: 1.6217045809632988

Epoch: 265| Step: 0
Training loss: 0.78882896900177
Validation loss: 1.654659273803875

Epoch: 6| Step: 1
Training loss: 0.5676494836807251
Validation loss: 1.6675900720780896

Epoch: 6| Step: 2
Training loss: 0.3195638656616211
Validation loss: 1.6436749017366798

Epoch: 6| Step: 3
Training loss: 0.18069717288017273
Validation loss: 1.6489814404518373

Epoch: 6| Step: 4
Training loss: 0.4109036922454834
Validation loss: 1.639734342534055

Epoch: 6| Step: 5
Training loss: 0.32228606939315796
Validation loss: 1.6421320746021886

Epoch: 6| Step: 6
Training loss: 0.1722767949104309
Validation loss: 1.6481872630375687

Epoch: 6| Step: 7
Training loss: 0.32851287722587585
Validation loss: 1.6602002997552194

Epoch: 6| Step: 8
Training loss: 0.3460416793823242
Validation loss: 1.6548422933906637

Epoch: 6| Step: 9
Training loss: 0.4911070764064789
Validation loss: 1.6470129489898682

Epoch: 6| Step: 10
Training loss: 0.528577983379364
Validation loss: 1.6465972367153372

Epoch: 6| Step: 11
Training loss: 0.6608932018280029
Validation loss: 1.6447155270525204

Epoch: 6| Step: 12
Training loss: 0.18314096331596375
Validation loss: 1.6305409080238753

Epoch: 6| Step: 13
Training loss: 0.6038804054260254
Validation loss: 1.6057014837059924

Epoch: 266| Step: 0
Training loss: 0.25779488682746887
Validation loss: 1.6156631362053655

Epoch: 6| Step: 1
Training loss: 0.32552212476730347
Validation loss: 1.602855909255243

Epoch: 6| Step: 2
Training loss: 0.5512510538101196
Validation loss: 1.6262162257266302

Epoch: 6| Step: 3
Training loss: 0.5813050270080566
Validation loss: 1.6158703155415033

Epoch: 6| Step: 4
Training loss: 0.3794217109680176
Validation loss: 1.626527000499028

Epoch: 6| Step: 5
Training loss: 0.5609970092773438
Validation loss: 1.6109904922464842

Epoch: 6| Step: 6
Training loss: 0.20649781823158264
Validation loss: 1.6049683247843096

Epoch: 6| Step: 7
Training loss: 0.6307257413864136
Validation loss: 1.6092115474003617

Epoch: 6| Step: 8
Training loss: 0.3398389220237732
Validation loss: 1.6047504537849016

Epoch: 6| Step: 9
Training loss: 0.2846619486808777
Validation loss: 1.589369079759044

Epoch: 6| Step: 10
Training loss: 0.3657992482185364
Validation loss: 1.6011031853255404

Epoch: 6| Step: 11
Training loss: 0.4067167639732361
Validation loss: 1.6178889530961231

Epoch: 6| Step: 12
Training loss: 0.3290058374404907
Validation loss: 1.6097511437631422

Epoch: 6| Step: 13
Training loss: 0.17094489932060242
Validation loss: 1.5981948862793625

Epoch: 267| Step: 0
Training loss: 0.31104934215545654
Validation loss: 1.6183467782953733

Epoch: 6| Step: 1
Training loss: 0.20990464091300964
Validation loss: 1.6233177569604689

Epoch: 6| Step: 2
Training loss: 0.42939311265945435
Validation loss: 1.6198011547006586

Epoch: 6| Step: 3
Training loss: 0.3602771759033203
Validation loss: 1.6549754617034749

Epoch: 6| Step: 4
Training loss: 0.24306337535381317
Validation loss: 1.6253718112104683

Epoch: 6| Step: 5
Training loss: 0.6037219762802124
Validation loss: 1.6611648323715373

Epoch: 6| Step: 6
Training loss: 0.3601418137550354
Validation loss: 1.6554336791397424

Epoch: 6| Step: 7
Training loss: 0.2921239137649536
Validation loss: 1.655728828522467

Epoch: 6| Step: 8
Training loss: 0.23343560099601746
Validation loss: 1.6586773228901688

Epoch: 6| Step: 9
Training loss: 0.37381699681282043
Validation loss: 1.6432163817908174

Epoch: 6| Step: 10
Training loss: 0.5731008052825928
Validation loss: 1.597089308564381

Epoch: 6| Step: 11
Training loss: 0.5013982057571411
Validation loss: 1.6254958991081483

Epoch: 6| Step: 12
Training loss: 0.4380326569080353
Validation loss: 1.6179717650977514

Epoch: 6| Step: 13
Training loss: 0.815893292427063
Validation loss: 1.5870313875136837

Epoch: 268| Step: 0
Training loss: 0.32818886637687683
Validation loss: 1.5883974195808492

Epoch: 6| Step: 1
Training loss: 0.3652398884296417
Validation loss: 1.610149965491346

Epoch: 6| Step: 2
Training loss: 0.36608612537384033
Validation loss: 1.6215855754831785

Epoch: 6| Step: 3
Training loss: 0.3655475676059723
Validation loss: 1.607660944743823

Epoch: 6| Step: 4
Training loss: 0.4832870364189148
Validation loss: 1.6049572511385846

Epoch: 6| Step: 5
Training loss: 0.5477815866470337
Validation loss: 1.5924860162119712

Epoch: 6| Step: 6
Training loss: 0.45886197686195374
Validation loss: 1.586933260322899

Epoch: 6| Step: 7
Training loss: 0.25401797890663147
Validation loss: 1.5794145253396803

Epoch: 6| Step: 8
Training loss: 0.5330908894538879
Validation loss: 1.5997617398538897

Epoch: 6| Step: 9
Training loss: 0.438968300819397
Validation loss: 1.612255137453797

Epoch: 6| Step: 10
Training loss: 0.18486465513706207
Validation loss: 1.622698631337894

Epoch: 6| Step: 11
Training loss: 0.2899623513221741
Validation loss: 1.617332677687368

Epoch: 6| Step: 12
Training loss: 0.41738590598106384
Validation loss: 1.6383903231672061

Epoch: 6| Step: 13
Training loss: 0.49282631278038025
Validation loss: 1.6319182252371183

Epoch: 269| Step: 0
Training loss: 0.34398192167282104
Validation loss: 1.63720711200468

Epoch: 6| Step: 1
Training loss: 0.3800120949745178
Validation loss: 1.6241399306122974

Epoch: 6| Step: 2
Training loss: 0.31347015500068665
Validation loss: 1.643685035808112

Epoch: 6| Step: 3
Training loss: 0.2970980405807495
Validation loss: 1.6169594154563

Epoch: 6| Step: 4
Training loss: 0.45707637071609497
Validation loss: 1.616738284787824

Epoch: 6| Step: 5
Training loss: 0.21391119062900543
Validation loss: 1.6248822289128457

Epoch: 6| Step: 6
Training loss: 0.256981760263443
Validation loss: 1.6262681766222882

Epoch: 6| Step: 7
Training loss: 0.3495607376098633
Validation loss: 1.6636642615000408

Epoch: 6| Step: 8
Training loss: 0.5808131694793701
Validation loss: 1.6832162167436333

Epoch: 6| Step: 9
Training loss: 0.7369552850723267
Validation loss: 1.6508875995553949

Epoch: 6| Step: 10
Training loss: 0.3868181109428406
Validation loss: 1.6838478234506422

Epoch: 6| Step: 11
Training loss: 0.5590832829475403
Validation loss: 1.6403839947074972

Epoch: 6| Step: 12
Training loss: 0.3531060218811035
Validation loss: 1.6332874157095467

Epoch: 6| Step: 13
Training loss: 0.327168732881546
Validation loss: 1.6429939987838909

Epoch: 270| Step: 0
Training loss: 0.5266122817993164
Validation loss: 1.6272416140443535

Epoch: 6| Step: 1
Training loss: 0.3432943522930145
Validation loss: 1.6233270668214368

Epoch: 6| Step: 2
Training loss: 0.41518306732177734
Validation loss: 1.6120488130918114

Epoch: 6| Step: 3
Training loss: 0.3567352890968323
Validation loss: 1.6406462166898994

Epoch: 6| Step: 4
Training loss: 0.3383942246437073
Validation loss: 1.6592778621181365

Epoch: 6| Step: 5
Training loss: 0.4366742968559265
Validation loss: 1.6794272327935824

Epoch: 6| Step: 6
Training loss: 0.29337480664253235
Validation loss: 1.6537181356901764

Epoch: 6| Step: 7
Training loss: 0.5294430255889893
Validation loss: 1.62251696278972

Epoch: 6| Step: 8
Training loss: 0.8178921937942505
Validation loss: 1.6169761342387046

Epoch: 6| Step: 9
Training loss: 0.4217352867126465
Validation loss: 1.6625442966338126

Epoch: 6| Step: 10
Training loss: 0.3126510977745056
Validation loss: 1.6102591406914495

Epoch: 6| Step: 11
Training loss: 0.35724830627441406
Validation loss: 1.6179460043548255

Epoch: 6| Step: 12
Training loss: 0.2935169041156769
Validation loss: 1.610345063670989

Epoch: 6| Step: 13
Training loss: 0.4984568953514099
Validation loss: 1.6149488434355745

Epoch: 271| Step: 0
Training loss: 0.21947741508483887
Validation loss: 1.6378753608272922

Epoch: 6| Step: 1
Training loss: 0.380764365196228
Validation loss: 1.6158575011837868

Epoch: 6| Step: 2
Training loss: 0.3489769697189331
Validation loss: 1.6385124319343156

Epoch: 6| Step: 3
Training loss: 0.5931525230407715
Validation loss: 1.6309086686821395

Epoch: 6| Step: 4
Training loss: 0.45992448925971985
Validation loss: 1.6306417603646555

Epoch: 6| Step: 5
Training loss: 0.4927404522895813
Validation loss: 1.6404770907535349

Epoch: 6| Step: 6
Training loss: 0.4432578682899475
Validation loss: 1.6226271711369997

Epoch: 6| Step: 7
Training loss: 0.47708404064178467
Validation loss: 1.636438444096555

Epoch: 6| Step: 8
Training loss: 0.47810792922973633
Validation loss: 1.6284304600889965

Epoch: 6| Step: 9
Training loss: 0.42246049642562866
Validation loss: 1.655247481920386

Epoch: 6| Step: 10
Training loss: 0.3415222764015198
Validation loss: 1.6404672156098068

Epoch: 6| Step: 11
Training loss: 0.2346520721912384
Validation loss: 1.6620850768140567

Epoch: 6| Step: 12
Training loss: 0.21383105218410492
Validation loss: 1.6769011046296807

Epoch: 6| Step: 13
Training loss: 0.847801923751831
Validation loss: 1.6271872379446541

Epoch: 272| Step: 0
Training loss: 0.44406455755233765
Validation loss: 1.652074190878099

Epoch: 6| Step: 1
Training loss: 0.5917266607284546
Validation loss: 1.6621832642503964

Epoch: 6| Step: 2
Training loss: 0.3618927299976349
Validation loss: 1.6278400805688673

Epoch: 6| Step: 3
Training loss: 0.2678525149822235
Validation loss: 1.5910386770002303

Epoch: 6| Step: 4
Training loss: 0.3199267089366913
Validation loss: 1.6329269165633826

Epoch: 6| Step: 5
Training loss: 0.44231271743774414
Validation loss: 1.610326636222101

Epoch: 6| Step: 6
Training loss: 0.3634430766105652
Validation loss: 1.608374116241291

Epoch: 6| Step: 7
Training loss: 0.483180433511734
Validation loss: 1.639240244383453

Epoch: 6| Step: 8
Training loss: 0.46477779746055603
Validation loss: 1.6219718007631199

Epoch: 6| Step: 9
Training loss: 0.452040433883667
Validation loss: 1.580292792730434

Epoch: 6| Step: 10
Training loss: 0.347711980342865
Validation loss: 1.5979767358431252

Epoch: 6| Step: 11
Training loss: 0.39030468463897705
Validation loss: 1.5767380934889599

Epoch: 6| Step: 12
Training loss: 0.3126325309276581
Validation loss: 1.5891971947044454

Epoch: 6| Step: 13
Training loss: 0.6633152961730957
Validation loss: 1.5903659546247093

Epoch: 273| Step: 0
Training loss: 0.31044912338256836
Validation loss: 1.6032889613541224

Epoch: 6| Step: 1
Training loss: 0.4029290974140167
Validation loss: 1.6027092702927128

Epoch: 6| Step: 2
Training loss: 0.4172321557998657
Validation loss: 1.6154431168751051

Epoch: 6| Step: 3
Training loss: 0.32786130905151367
Validation loss: 1.6283877139450402

Epoch: 6| Step: 4
Training loss: 0.3872748911380768
Validation loss: 1.6166990162223898

Epoch: 6| Step: 5
Training loss: 0.30566927790641785
Validation loss: 1.6318563081884896

Epoch: 6| Step: 6
Training loss: 0.34551355242729187
Validation loss: 1.6275489086745887

Epoch: 6| Step: 7
Training loss: 0.46582290530204773
Validation loss: 1.6164835858088669

Epoch: 6| Step: 8
Training loss: 0.3726554811000824
Validation loss: 1.5963647955207414

Epoch: 6| Step: 9
Training loss: 0.3544202446937561
Validation loss: 1.6198896246571695

Epoch: 6| Step: 10
Training loss: 0.35864850878715515
Validation loss: 1.6071750117886452

Epoch: 6| Step: 11
Training loss: 0.6362689733505249
Validation loss: 1.6117582423712618

Epoch: 6| Step: 12
Training loss: 0.2404784858226776
Validation loss: 1.6410046521053518

Epoch: 6| Step: 13
Training loss: 0.44155552983283997
Validation loss: 1.6322334472851088

Epoch: 274| Step: 0
Training loss: 0.538163959980011
Validation loss: 1.648531465120213

Epoch: 6| Step: 1
Training loss: 0.3169061541557312
Validation loss: 1.6543779539805588

Epoch: 6| Step: 2
Training loss: 0.3036220073699951
Validation loss: 1.6419441546163251

Epoch: 6| Step: 3
Training loss: 0.16142144799232483
Validation loss: 1.6384404692598569

Epoch: 6| Step: 4
Training loss: 0.24764685332775116
Validation loss: 1.6206363349832513

Epoch: 6| Step: 5
Training loss: 0.46740609407424927
Validation loss: 1.6409522730817077

Epoch: 6| Step: 6
Training loss: 0.5622683763504028
Validation loss: 1.631176842156277

Epoch: 6| Step: 7
Training loss: 0.5577722191810608
Validation loss: 1.6314670180761686

Epoch: 6| Step: 8
Training loss: 0.6241832971572876
Validation loss: 1.6004610843555902

Epoch: 6| Step: 9
Training loss: 0.3289050757884979
Validation loss: 1.5990155153377081

Epoch: 6| Step: 10
Training loss: 0.4822474718093872
Validation loss: 1.6253177517203874

Epoch: 6| Step: 11
Training loss: 0.6757442951202393
Validation loss: 1.620889445786835

Epoch: 6| Step: 12
Training loss: 0.5359946489334106
Validation loss: 1.629418892245139

Epoch: 6| Step: 13
Training loss: 0.3347686529159546
Validation loss: 1.6305082664694837

Epoch: 275| Step: 0
Training loss: 0.45910829305648804
Validation loss: 1.5754519451049067

Epoch: 6| Step: 1
Training loss: 0.28646254539489746
Validation loss: 1.582395343370335

Epoch: 6| Step: 2
Training loss: 0.5110206604003906
Validation loss: 1.577104462090359

Epoch: 6| Step: 3
Training loss: 0.3243536651134491
Validation loss: 1.5997834577355334

Epoch: 6| Step: 4
Training loss: 0.7075382471084595
Validation loss: 1.5900936254891016

Epoch: 6| Step: 5
Training loss: 0.6501414775848389
Validation loss: 1.6128987689172067

Epoch: 6| Step: 6
Training loss: 0.5266872644424438
Validation loss: 1.6115341955615627

Epoch: 6| Step: 7
Training loss: 0.30788373947143555
Validation loss: 1.61308317799722

Epoch: 6| Step: 8
Training loss: 0.26751700043678284
Validation loss: 1.6345436906301847

Epoch: 6| Step: 9
Training loss: 0.34121039509773254
Validation loss: 1.644695807528752

Epoch: 6| Step: 10
Training loss: 0.2797810733318329
Validation loss: 1.637020545621072

Epoch: 6| Step: 11
Training loss: 0.3141975402832031
Validation loss: 1.63001508866587

Epoch: 6| Step: 12
Training loss: 0.34370899200439453
Validation loss: 1.6569751334446732

Epoch: 6| Step: 13
Training loss: 0.29657599329948425
Validation loss: 1.634754765418268

Epoch: 276| Step: 0
Training loss: 0.3609122931957245
Validation loss: 1.6246463816653016

Epoch: 6| Step: 1
Training loss: 0.3665332794189453
Validation loss: 1.6405574852420437

Epoch: 6| Step: 2
Training loss: 0.23158784210681915
Validation loss: 1.636708305728051

Epoch: 6| Step: 3
Training loss: 0.08815659582614899
Validation loss: 1.6312639495377899

Epoch: 6| Step: 4
Training loss: 0.40705037117004395
Validation loss: 1.6406844072444464

Epoch: 6| Step: 5
Training loss: 0.48843446373939514
Validation loss: 1.6482212646033174

Epoch: 6| Step: 6
Training loss: 0.3364608585834503
Validation loss: 1.6613276825156262

Epoch: 6| Step: 7
Training loss: 0.6762461066246033
Validation loss: 1.6473575574095531

Epoch: 6| Step: 8
Training loss: 0.45135819911956787
Validation loss: 1.618984442885204

Epoch: 6| Step: 9
Training loss: 0.5145706534385681
Validation loss: 1.6363567306149391

Epoch: 6| Step: 10
Training loss: 0.5308148860931396
Validation loss: 1.6073713635885587

Epoch: 6| Step: 11
Training loss: 0.21462537348270416
Validation loss: 1.6393907807206596

Epoch: 6| Step: 12
Training loss: 0.4039720892906189
Validation loss: 1.6038700935020243

Epoch: 6| Step: 13
Training loss: 0.2462143898010254
Validation loss: 1.631804737993466

Epoch: 277| Step: 0
Training loss: 0.23412412405014038
Validation loss: 1.6417318441534554

Epoch: 6| Step: 1
Training loss: 0.175731360912323
Validation loss: 1.625856170090296

Epoch: 6| Step: 2
Training loss: 0.35627973079681396
Validation loss: 1.6250624861768497

Epoch: 6| Step: 3
Training loss: 0.3731105327606201
Validation loss: 1.6855233587244505

Epoch: 6| Step: 4
Training loss: 0.3135865032672882
Validation loss: 1.657785984777635

Epoch: 6| Step: 5
Training loss: 0.5587298274040222
Validation loss: 1.636852572041173

Epoch: 6| Step: 6
Training loss: 0.3401803970336914
Validation loss: 1.6310022390016945

Epoch: 6| Step: 7
Training loss: 0.35277998447418213
Validation loss: 1.6341540454536356

Epoch: 6| Step: 8
Training loss: 0.615672767162323
Validation loss: 1.6437506239901307

Epoch: 6| Step: 9
Training loss: 0.2558757960796356
Validation loss: 1.650820768007668

Epoch: 6| Step: 10
Training loss: 0.31027132272720337
Validation loss: 1.6498838778465026

Epoch: 6| Step: 11
Training loss: 0.4322066903114319
Validation loss: 1.6388295952991774

Epoch: 6| Step: 12
Training loss: 0.3379705548286438
Validation loss: 1.6186409368309924

Epoch: 6| Step: 13
Training loss: 0.7675418853759766
Validation loss: 1.6157099059832993

Epoch: 278| Step: 0
Training loss: 0.4958939552307129
Validation loss: 1.6201381997395587

Epoch: 6| Step: 1
Training loss: 0.21074718236923218
Validation loss: 1.6381765245109476

Epoch: 6| Step: 2
Training loss: 0.4199528694152832
Validation loss: 1.6348698805737238

Epoch: 6| Step: 3
Training loss: 0.30696678161621094
Validation loss: 1.640874014105848

Epoch: 6| Step: 4
Training loss: 0.1757698506116867
Validation loss: 1.6202838895141438

Epoch: 6| Step: 5
Training loss: 0.42417556047439575
Validation loss: 1.6197968503480316

Epoch: 6| Step: 6
Training loss: 0.2430245280265808
Validation loss: 1.6368925802169307

Epoch: 6| Step: 7
Training loss: 0.5388344526290894
Validation loss: 1.6116869539342902

Epoch: 6| Step: 8
Training loss: 0.260415256023407
Validation loss: 1.6226555878116238

Epoch: 6| Step: 9
Training loss: 0.5743076801300049
Validation loss: 1.6163165056577293

Epoch: 6| Step: 10
Training loss: 0.5174373984336853
Validation loss: 1.6223312481757133

Epoch: 6| Step: 11
Training loss: 0.44394510984420776
Validation loss: 1.632212185090588

Epoch: 6| Step: 12
Training loss: 0.21627362072467804
Validation loss: 1.6333520438081475

Epoch: 6| Step: 13
Training loss: 0.22900551557540894
Validation loss: 1.6278915354000625

Epoch: 279| Step: 0
Training loss: 0.2680729031562805
Validation loss: 1.6262433426354521

Epoch: 6| Step: 1
Training loss: 0.37308579683303833
Validation loss: 1.6559304268129411

Epoch: 6| Step: 2
Training loss: 0.48196208477020264
Validation loss: 1.6402016506400159

Epoch: 6| Step: 3
Training loss: 0.22114229202270508
Validation loss: 1.6284599740018126

Epoch: 6| Step: 4
Training loss: 0.4551279544830322
Validation loss: 1.6591644979292346

Epoch: 6| Step: 5
Training loss: 0.29404520988464355
Validation loss: 1.6466649719463882

Epoch: 6| Step: 6
Training loss: 0.4562457799911499
Validation loss: 1.65287571953189

Epoch: 6| Step: 7
Training loss: 0.4922759532928467
Validation loss: 1.6640007021606609

Epoch: 6| Step: 8
Training loss: 0.3068259060382843
Validation loss: 1.6308149791532947

Epoch: 6| Step: 9
Training loss: 0.30909720063209534
Validation loss: 1.6521761161024853

Epoch: 6| Step: 10
Training loss: 0.43256875872612
Validation loss: 1.6271068780652937

Epoch: 6| Step: 11
Training loss: 0.43192872405052185
Validation loss: 1.6279100833400604

Epoch: 6| Step: 12
Training loss: 0.7794070243835449
Validation loss: 1.6325815262333039

Epoch: 6| Step: 13
Training loss: 0.3819316625595093
Validation loss: 1.6262881537919402

Epoch: 280| Step: 0
Training loss: 0.29242557287216187
Validation loss: 1.6257415086992326

Epoch: 6| Step: 1
Training loss: 0.26305800676345825
Validation loss: 1.6357167843849427

Epoch: 6| Step: 2
Training loss: 0.613111674785614
Validation loss: 1.6405201855526175

Epoch: 6| Step: 3
Training loss: 0.31570881605148315
Validation loss: 1.6414661766380392

Epoch: 6| Step: 4
Training loss: 0.5542187094688416
Validation loss: 1.636089091659874

Epoch: 6| Step: 5
Training loss: 0.38413363695144653
Validation loss: 1.649730779791391

Epoch: 6| Step: 6
Training loss: 0.40456774830818176
Validation loss: 1.6321496104681363

Epoch: 6| Step: 7
Training loss: 0.5071026086807251
Validation loss: 1.6241707058363064

Epoch: 6| Step: 8
Training loss: 0.3233031630516052
Validation loss: 1.6504503962814168

Epoch: 6| Step: 9
Training loss: 0.17004412412643433
Validation loss: 1.615519456965949

Epoch: 6| Step: 10
Training loss: 0.5472602248191833
Validation loss: 1.6510188464195497

Epoch: 6| Step: 11
Training loss: 0.21757392585277557
Validation loss: 1.6582076011165496

Epoch: 6| Step: 12
Training loss: 0.27100005745887756
Validation loss: 1.6347127909301429

Epoch: 6| Step: 13
Training loss: 0.29338327050209045
Validation loss: 1.6361952135639806

Epoch: 281| Step: 0
Training loss: 0.4778635501861572
Validation loss: 1.628640313302317

Epoch: 6| Step: 1
Training loss: 0.2616109251976013
Validation loss: 1.6350641968429729

Epoch: 6| Step: 2
Training loss: 0.3601190149784088
Validation loss: 1.604621850034242

Epoch: 6| Step: 3
Training loss: 0.19938737154006958
Validation loss: 1.619628519140264

Epoch: 6| Step: 4
Training loss: 0.36739930510520935
Validation loss: 1.626852850760183

Epoch: 6| Step: 5
Training loss: 0.41709664463996887
Validation loss: 1.5857246524544173

Epoch: 6| Step: 6
Training loss: 0.2796216607093811
Validation loss: 1.6093033488078783

Epoch: 6| Step: 7
Training loss: 0.3641061782836914
Validation loss: 1.6326152483622234

Epoch: 6| Step: 8
Training loss: 0.2904413044452667
Validation loss: 1.6376746213564308

Epoch: 6| Step: 9
Training loss: 0.34022438526153564
Validation loss: 1.6263530010818152

Epoch: 6| Step: 10
Training loss: 0.4221595227718353
Validation loss: 1.6267891699267971

Epoch: 6| Step: 11
Training loss: 0.4921928942203522
Validation loss: 1.610593213829943

Epoch: 6| Step: 12
Training loss: 0.39542195200920105
Validation loss: 1.64581214099802

Epoch: 6| Step: 13
Training loss: 0.22290430963039398
Validation loss: 1.6413078731106174

Epoch: 282| Step: 0
Training loss: 0.31948724389076233
Validation loss: 1.6565666275639688

Epoch: 6| Step: 1
Training loss: 0.35673612356185913
Validation loss: 1.6540963970204836

Epoch: 6| Step: 2
Training loss: 0.17960532009601593
Validation loss: 1.6309671466068556

Epoch: 6| Step: 3
Training loss: 0.17215515673160553
Validation loss: 1.6209875537503151

Epoch: 6| Step: 4
Training loss: 0.4070495367050171
Validation loss: 1.608851130290698

Epoch: 6| Step: 5
Training loss: 0.2708744406700134
Validation loss: 1.6142144959460023

Epoch: 6| Step: 6
Training loss: 0.41263705492019653
Validation loss: 1.6326686746330672

Epoch: 6| Step: 7
Training loss: 0.24909448623657227
Validation loss: 1.6080443551463466

Epoch: 6| Step: 8
Training loss: 0.3719401955604553
Validation loss: 1.6061795808935677

Epoch: 6| Step: 9
Training loss: 0.691429615020752
Validation loss: 1.6064629234293455

Epoch: 6| Step: 10
Training loss: 0.222653329372406
Validation loss: 1.6236224405227169

Epoch: 6| Step: 11
Training loss: 0.5736922025680542
Validation loss: 1.6085747083028157

Epoch: 6| Step: 12
Training loss: 0.22711120545864105
Validation loss: 1.6154193314172889

Epoch: 6| Step: 13
Training loss: 0.7446798086166382
Validation loss: 1.631462271495532

Epoch: 283| Step: 0
Training loss: 0.3681206703186035
Validation loss: 1.6146088402758363

Epoch: 6| Step: 1
Training loss: 0.3314632773399353
Validation loss: 1.6184867992196033

Epoch: 6| Step: 2
Training loss: 0.20198704302310944
Validation loss: 1.5846782781744515

Epoch: 6| Step: 3
Training loss: 0.17727376520633698
Validation loss: 1.5978898963620585

Epoch: 6| Step: 4
Training loss: 0.9632762670516968
Validation loss: 1.5729314293912662

Epoch: 6| Step: 5
Training loss: 0.17744135856628418
Validation loss: 1.5846244083937777

Epoch: 6| Step: 6
Training loss: 0.3763211965560913
Validation loss: 1.571154894367341

Epoch: 6| Step: 7
Training loss: 0.202408567070961
Validation loss: 1.5853118537574686

Epoch: 6| Step: 8
Training loss: 0.43060365319252014
Validation loss: 1.5949922876973306

Epoch: 6| Step: 9
Training loss: 0.29236841201782227
Validation loss: 1.6030403196170766

Epoch: 6| Step: 10
Training loss: 0.38024207949638367
Validation loss: 1.6097096063757454

Epoch: 6| Step: 11
Training loss: 0.469127893447876
Validation loss: 1.630100909099784

Epoch: 6| Step: 12
Training loss: 0.31923097372055054
Validation loss: 1.6492088264034641

Epoch: 6| Step: 13
Training loss: 0.4469400644302368
Validation loss: 1.6543324737138645

Epoch: 284| Step: 0
Training loss: 0.3404483199119568
Validation loss: 1.6520588526161768

Epoch: 6| Step: 1
Training loss: 0.19638201594352722
Validation loss: 1.663037856419881

Epoch: 6| Step: 2
Training loss: 0.5465037822723389
Validation loss: 1.650192145378359

Epoch: 6| Step: 3
Training loss: 0.7792874574661255
Validation loss: 1.6042568068350516

Epoch: 6| Step: 4
Training loss: 0.37869828939437866
Validation loss: 1.6209023396174114

Epoch: 6| Step: 5
Training loss: 0.24180079996585846
Validation loss: 1.5903569357369536

Epoch: 6| Step: 6
Training loss: 0.29124462604522705
Validation loss: 1.602619396742954

Epoch: 6| Step: 7
Training loss: 0.16597265005111694
Validation loss: 1.575490254227833

Epoch: 6| Step: 8
Training loss: 0.3154553174972534
Validation loss: 1.6198429035884079

Epoch: 6| Step: 9
Training loss: 0.3505886197090149
Validation loss: 1.5981254757091563

Epoch: 6| Step: 10
Training loss: 0.40315955877304077
Validation loss: 1.5982221711066462

Epoch: 6| Step: 11
Training loss: 0.3308921456336975
Validation loss: 1.5988776158261042

Epoch: 6| Step: 12
Training loss: 0.3036893606185913
Validation loss: 1.5999618409782328

Epoch: 6| Step: 13
Training loss: 0.192282572388649
Validation loss: 1.5893581823636127

Epoch: 285| Step: 0
Training loss: 0.4484793543815613
Validation loss: 1.5926465167794177

Epoch: 6| Step: 1
Training loss: 0.28885990381240845
Validation loss: 1.5954385303681897

Epoch: 6| Step: 2
Training loss: 0.3654372990131378
Validation loss: 1.6162150175340715

Epoch: 6| Step: 3
Training loss: 0.6706196069717407
Validation loss: 1.587691145558511

Epoch: 6| Step: 4
Training loss: 0.41469112038612366
Validation loss: 1.5991855603392406

Epoch: 6| Step: 5
Training loss: 0.2541429400444031
Validation loss: 1.6433613704096885

Epoch: 6| Step: 6
Training loss: 0.38894084095954895
Validation loss: 1.6138007076837684

Epoch: 6| Step: 7
Training loss: 0.3054618239402771
Validation loss: 1.6015859637209164

Epoch: 6| Step: 8
Training loss: 0.31281226873397827
Validation loss: 1.613712477427657

Epoch: 6| Step: 9
Training loss: 0.4385090172290802
Validation loss: 1.6247063554743284

Epoch: 6| Step: 10
Training loss: 0.22885474562644958
Validation loss: 1.6035538822092035

Epoch: 6| Step: 11
Training loss: 0.5125792026519775
Validation loss: 1.61621460863339

Epoch: 6| Step: 12
Training loss: 0.23231428861618042
Validation loss: 1.6453379943806639

Epoch: 6| Step: 13
Training loss: 0.49322837591171265
Validation loss: 1.6178675672059417

Epoch: 286| Step: 0
Training loss: 0.3407258689403534
Validation loss: 1.615550209117192

Epoch: 6| Step: 1
Training loss: 0.3690425753593445
Validation loss: 1.6008551761668215

Epoch: 6| Step: 2
Training loss: 0.382720410823822
Validation loss: 1.6143355343931465

Epoch: 6| Step: 3
Training loss: 0.397814005613327
Validation loss: 1.587583036832912

Epoch: 6| Step: 4
Training loss: 0.3887629806995392
Validation loss: 1.5917390296536107

Epoch: 6| Step: 5
Training loss: 0.2322525978088379
Validation loss: 1.5795234172574935

Epoch: 6| Step: 6
Training loss: 0.4622448980808258
Validation loss: 1.5978033927179152

Epoch: 6| Step: 7
Training loss: 0.36175334453582764
Validation loss: 1.5962664940023934

Epoch: 6| Step: 8
Training loss: 0.28768834471702576
Validation loss: 1.6196276910843388

Epoch: 6| Step: 9
Training loss: 0.22343437373638153
Validation loss: 1.6115846915911602

Epoch: 6| Step: 10
Training loss: 0.5595048069953918
Validation loss: 1.600299448095342

Epoch: 6| Step: 11
Training loss: 0.4226929545402527
Validation loss: 1.5908955361253472

Epoch: 6| Step: 12
Training loss: 0.41991421580314636
Validation loss: 1.6081613186867005

Epoch: 6| Step: 13
Training loss: 0.28048259019851685
Validation loss: 1.6109922752585462

Epoch: 287| Step: 0
Training loss: 0.19221827387809753
Validation loss: 1.609933610244464

Epoch: 6| Step: 1
Training loss: 0.2621017396450043
Validation loss: 1.6266993937953826

Epoch: 6| Step: 2
Training loss: 0.4167035222053528
Validation loss: 1.6043771595083258

Epoch: 6| Step: 3
Training loss: 0.49582573771476746
Validation loss: 1.5969713746860463

Epoch: 6| Step: 4
Training loss: 0.32609647512435913
Validation loss: 1.6259704584716468

Epoch: 6| Step: 5
Training loss: 0.38259613513946533
Validation loss: 1.6022004696630663

Epoch: 6| Step: 6
Training loss: 0.31245410442352295
Validation loss: 1.6467897379270164

Epoch: 6| Step: 7
Training loss: 0.23269231617450714
Validation loss: 1.646225175549907

Epoch: 6| Step: 8
Training loss: 0.2503494620323181
Validation loss: 1.6460088952895133

Epoch: 6| Step: 9
Training loss: 0.5259751081466675
Validation loss: 1.6198483795248053

Epoch: 6| Step: 10
Training loss: 0.43509525060653687
Validation loss: 1.6355529151937014

Epoch: 6| Step: 11
Training loss: 0.3833377957344055
Validation loss: 1.6249007935165076

Epoch: 6| Step: 12
Training loss: 0.4398399293422699
Validation loss: 1.5885850780753679

Epoch: 6| Step: 13
Training loss: 0.5664008259773254
Validation loss: 1.5900728612817743

Epoch: 288| Step: 0
Training loss: 0.4480776786804199
Validation loss: 1.5899824301401775

Epoch: 6| Step: 1
Training loss: 0.27940428256988525
Validation loss: 1.6200730300718738

Epoch: 6| Step: 2
Training loss: 0.4204344153404236
Validation loss: 1.656819126939261

Epoch: 6| Step: 3
Training loss: 0.546817421913147
Validation loss: 1.6732853868956208

Epoch: 6| Step: 4
Training loss: 0.5555275082588196
Validation loss: 1.6620590738070908

Epoch: 6| Step: 5
Training loss: 0.2816198468208313
Validation loss: 1.6197367765570199

Epoch: 6| Step: 6
Training loss: 0.3367975950241089
Validation loss: 1.605333666647634

Epoch: 6| Step: 7
Training loss: 0.4890785217285156
Validation loss: 1.5982731676870776

Epoch: 6| Step: 8
Training loss: 0.237913578748703
Validation loss: 1.585771790114782

Epoch: 6| Step: 9
Training loss: 0.37578725814819336
Validation loss: 1.598864786086544

Epoch: 6| Step: 10
Training loss: 0.4871870279312134
Validation loss: 1.6053035771974953

Epoch: 6| Step: 11
Training loss: 0.46337148547172546
Validation loss: 1.5877043457441433

Epoch: 6| Step: 12
Training loss: 0.26849180459976196
Validation loss: 1.5901848494365651

Epoch: 6| Step: 13
Training loss: 0.4097549617290497
Validation loss: 1.5858273518982755

Epoch: 289| Step: 0
Training loss: 0.444077730178833
Validation loss: 1.5934739087217598

Epoch: 6| Step: 1
Training loss: 0.30758213996887207
Validation loss: 1.6143733891107703

Epoch: 6| Step: 2
Training loss: 0.4471546411514282
Validation loss: 1.6395219807983727

Epoch: 6| Step: 3
Training loss: 0.22399821877479553
Validation loss: 1.6624151660550026

Epoch: 6| Step: 4
Training loss: 0.4968339204788208
Validation loss: 1.6396399005766837

Epoch: 6| Step: 5
Training loss: 0.17280706763267517
Validation loss: 1.6472201116623417

Epoch: 6| Step: 6
Training loss: 0.39185088872909546
Validation loss: 1.6533875901211974

Epoch: 6| Step: 7
Training loss: 0.6957986950874329
Validation loss: 1.6530589736917967

Epoch: 6| Step: 8
Training loss: 0.2411428987979889
Validation loss: 1.6538933220730032

Epoch: 6| Step: 9
Training loss: 0.2896616458892822
Validation loss: 1.6398095020683863

Epoch: 6| Step: 10
Training loss: 0.25359082221984863
Validation loss: 1.6382766116049983

Epoch: 6| Step: 11
Training loss: 0.3598814010620117
Validation loss: 1.6206380782588836

Epoch: 6| Step: 12
Training loss: 0.2676258981227875
Validation loss: 1.5940649394066102

Epoch: 6| Step: 13
Training loss: 0.21938367187976837
Validation loss: 1.6038701111270535

Epoch: 290| Step: 0
Training loss: 0.40714937448501587
Validation loss: 1.6225114535259944

Epoch: 6| Step: 1
Training loss: 0.31553375720977783
Validation loss: 1.6307855498406194

Epoch: 6| Step: 2
Training loss: 0.6969916820526123
Validation loss: 1.6428654629697081

Epoch: 6| Step: 3
Training loss: 0.1858285814523697
Validation loss: 1.636146551819258

Epoch: 6| Step: 4
Training loss: 0.33822837471961975
Validation loss: 1.6373591243579824

Epoch: 6| Step: 5
Training loss: 0.2096945345401764
Validation loss: 1.6551865031642299

Epoch: 6| Step: 6
Training loss: 0.3363334834575653
Validation loss: 1.6599749941979685

Epoch: 6| Step: 7
Training loss: 0.4793854057788849
Validation loss: 1.6176531417395479

Epoch: 6| Step: 8
Training loss: 0.26742154359817505
Validation loss: 1.6555246960732244

Epoch: 6| Step: 9
Training loss: 0.3151124119758606
Validation loss: 1.6648257317081574

Epoch: 6| Step: 10
Training loss: 0.25267744064331055
Validation loss: 1.6450627426947317

Epoch: 6| Step: 11
Training loss: 0.2858988344669342
Validation loss: 1.6327393926599973

Epoch: 6| Step: 12
Training loss: 0.30793771147727966
Validation loss: 1.6277200803961804

Epoch: 6| Step: 13
Training loss: 0.44153866171836853
Validation loss: 1.6349228735893004

Epoch: 291| Step: 0
Training loss: 0.39561906456947327
Validation loss: 1.6385636073286816

Epoch: 6| Step: 1
Training loss: 0.30458036065101624
Validation loss: 1.6263863502010223

Epoch: 6| Step: 2
Training loss: 0.27697861194610596
Validation loss: 1.6299272493649555

Epoch: 6| Step: 3
Training loss: 0.20776674151420593
Validation loss: 1.5945344919799476

Epoch: 6| Step: 4
Training loss: 0.3336528539657593
Validation loss: 1.606096803501088

Epoch: 6| Step: 5
Training loss: 0.22012051939964294
Validation loss: 1.5872441901955554

Epoch: 6| Step: 6
Training loss: 0.3581511378288269
Validation loss: 1.5749474956143288

Epoch: 6| Step: 7
Training loss: 0.6025334596633911
Validation loss: 1.5830745966203752

Epoch: 6| Step: 8
Training loss: 0.31408190727233887
Validation loss: 1.5636258817488147

Epoch: 6| Step: 9
Training loss: 0.35852718353271484
Validation loss: 1.5739940584346812

Epoch: 6| Step: 10
Training loss: 0.2851526141166687
Validation loss: 1.5910480124976045

Epoch: 6| Step: 11
Training loss: 0.25629281997680664
Validation loss: 1.5754888596073273

Epoch: 6| Step: 12
Training loss: 0.3328850269317627
Validation loss: 1.5741492086841213

Epoch: 6| Step: 13
Training loss: 0.1053822785615921
Validation loss: 1.584510580185921

Epoch: 292| Step: 0
Training loss: 0.2775634229183197
Validation loss: 1.5908489022203671

Epoch: 6| Step: 1
Training loss: 0.43287789821624756
Validation loss: 1.6157667726598761

Epoch: 6| Step: 2
Training loss: 0.35537344217300415
Validation loss: 1.5977688502239924

Epoch: 6| Step: 3
Training loss: 0.2176559567451477
Validation loss: 1.6091834204171294

Epoch: 6| Step: 4
Training loss: 0.21792003512382507
Validation loss: 1.6194371215758785

Epoch: 6| Step: 5
Training loss: 0.37324443459510803
Validation loss: 1.6126399232495217

Epoch: 6| Step: 6
Training loss: 0.19079887866973877
Validation loss: 1.6158698540861889

Epoch: 6| Step: 7
Training loss: 0.34033283591270447
Validation loss: 1.6127464463633876

Epoch: 6| Step: 8
Training loss: 0.14441141486167908
Validation loss: 1.604548123575026

Epoch: 6| Step: 9
Training loss: 0.2872651517391205
Validation loss: 1.613796208494453

Epoch: 6| Step: 10
Training loss: 0.22468407452106476
Validation loss: 1.6161432791781682

Epoch: 6| Step: 11
Training loss: 0.29044950008392334
Validation loss: 1.571768379980518

Epoch: 6| Step: 12
Training loss: 0.5397202968597412
Validation loss: 1.5748328303778043

Epoch: 6| Step: 13
Training loss: 0.3929569721221924
Validation loss: 1.5958795239848476

Epoch: 293| Step: 0
Training loss: 0.28259798884391785
Validation loss: 1.5713182905668854

Epoch: 6| Step: 1
Training loss: 0.28912287950515747
Validation loss: 1.572725784394049

Epoch: 6| Step: 2
Training loss: 0.4790745675563812
Validation loss: 1.5777871788188975

Epoch: 6| Step: 3
Training loss: 0.3433988094329834
Validation loss: 1.531697146354183

Epoch: 6| Step: 4
Training loss: 0.26738810539245605
Validation loss: 1.582757278155255

Epoch: 6| Step: 5
Training loss: 0.2712026536464691
Validation loss: 1.5547901122800765

Epoch: 6| Step: 6
Training loss: 0.194342702627182
Validation loss: 1.572966387194972

Epoch: 6| Step: 7
Training loss: 0.2007935643196106
Validation loss: 1.563111662864685

Epoch: 6| Step: 8
Training loss: 0.21228545904159546
Validation loss: 1.5714815214116087

Epoch: 6| Step: 9
Training loss: 0.36710840463638306
Validation loss: 1.5977020225217264

Epoch: 6| Step: 10
Training loss: 0.22592568397521973
Validation loss: 1.5992054349632674

Epoch: 6| Step: 11
Training loss: 0.3839747905731201
Validation loss: 1.5890605526585733

Epoch: 6| Step: 12
Training loss: 0.4453563690185547
Validation loss: 1.6202059791934105

Epoch: 6| Step: 13
Training loss: 0.33079200983047485
Validation loss: 1.6168430338623703

Epoch: 294| Step: 0
Training loss: 0.6958917379379272
Validation loss: 1.5979090736758323

Epoch: 6| Step: 1
Training loss: 0.30357804894447327
Validation loss: 1.5928867119614796

Epoch: 6| Step: 2
Training loss: 0.2522304952144623
Validation loss: 1.5981745437909198

Epoch: 6| Step: 3
Training loss: 0.3680296540260315
Validation loss: 1.5881883713506884

Epoch: 6| Step: 4
Training loss: 0.26179826259613037
Validation loss: 1.5922449032465618

Epoch: 6| Step: 5
Training loss: 0.18388311564922333
Validation loss: 1.5605784846890358

Epoch: 6| Step: 6
Training loss: 0.18840846419334412
Validation loss: 1.5998958887592438

Epoch: 6| Step: 7
Training loss: 0.210967555642128
Validation loss: 1.6022172768910725

Epoch: 6| Step: 8
Training loss: 0.2833860218524933
Validation loss: 1.620377226542401

Epoch: 6| Step: 9
Training loss: 0.25132620334625244
Validation loss: 1.6297497928783458

Epoch: 6| Step: 10
Training loss: 0.49848201870918274
Validation loss: 1.603827726456427

Epoch: 6| Step: 11
Training loss: 0.3626517355442047
Validation loss: 1.6001823615002375

Epoch: 6| Step: 12
Training loss: 0.10311292111873627
Validation loss: 1.5935246200971707

Epoch: 6| Step: 13
Training loss: 0.24512317776679993
Validation loss: 1.6308557679576259

Epoch: 295| Step: 0
Training loss: 0.19851455092430115
Validation loss: 1.6153202749067737

Epoch: 6| Step: 1
Training loss: 0.17405472695827484
Validation loss: 1.5984613254506101

Epoch: 6| Step: 2
Training loss: 0.23742257058620453
Validation loss: 1.5966341162240634

Epoch: 6| Step: 3
Training loss: 0.21412841975688934
Validation loss: 1.5992527546421174

Epoch: 6| Step: 4
Training loss: 0.379965215921402
Validation loss: 1.6042841083259993

Epoch: 6| Step: 5
Training loss: 0.23877745866775513
Validation loss: 1.590743880118093

Epoch: 6| Step: 6
Training loss: 0.35476261377334595
Validation loss: 1.5941995318217943

Epoch: 6| Step: 7
Training loss: 0.2368982434272766
Validation loss: 1.5963228248780774

Epoch: 6| Step: 8
Training loss: 0.30634722113609314
Validation loss: 1.6091944120263542

Epoch: 6| Step: 9
Training loss: 0.29771941900253296
Validation loss: 1.5979587211403796

Epoch: 6| Step: 10
Training loss: 0.6219892501831055
Validation loss: 1.5867853139036445

Epoch: 6| Step: 11
Training loss: 0.32524389028549194
Validation loss: 1.5942121910792526

Epoch: 6| Step: 12
Training loss: 0.2951052188873291
Validation loss: 1.606654711948928

Epoch: 6| Step: 13
Training loss: 0.17630182206630707
Validation loss: 1.6182165222783242

Epoch: 296| Step: 0
Training loss: 0.46175235509872437
Validation loss: 1.595799340996691

Epoch: 6| Step: 1
Training loss: 0.28134649991989136
Validation loss: 1.5781688536367109

Epoch: 6| Step: 2
Training loss: 0.1317249983549118
Validation loss: 1.5658110162263275

Epoch: 6| Step: 3
Training loss: 0.3388739228248596
Validation loss: 1.579744727380814

Epoch: 6| Step: 4
Training loss: 0.2383815348148346
Validation loss: 1.587158105706656

Epoch: 6| Step: 5
Training loss: 0.30493080615997314
Validation loss: 1.5860801255831154

Epoch: 6| Step: 6
Training loss: 0.31185182929039
Validation loss: 1.6094820935239074

Epoch: 6| Step: 7
Training loss: 0.16895174980163574
Validation loss: 1.5892267163081835

Epoch: 6| Step: 8
Training loss: 0.3240370452404022
Validation loss: 1.6004307731505363

Epoch: 6| Step: 9
Training loss: 0.3207678496837616
Validation loss: 1.5859422517079178

Epoch: 6| Step: 10
Training loss: 0.37328940629959106
Validation loss: 1.5764374027970016

Epoch: 6| Step: 11
Training loss: 0.386857807636261
Validation loss: 1.5822472585144864

Epoch: 6| Step: 12
Training loss: 0.2467828243970871
Validation loss: 1.6032212549640286

Epoch: 6| Step: 13
Training loss: 0.8451960682868958
Validation loss: 1.5918146307750414

Epoch: 297| Step: 0
Training loss: 0.23357447981834412
Validation loss: 1.6283540802617227

Epoch: 6| Step: 1
Training loss: 0.33083105087280273
Validation loss: 1.632293096152685

Epoch: 6| Step: 2
Training loss: 0.26744696497917175
Validation loss: 1.6070273845426497

Epoch: 6| Step: 3
Training loss: 0.392402321100235
Validation loss: 1.6153011225884961

Epoch: 6| Step: 4
Training loss: 0.40438297390937805
Validation loss: 1.6229619082584177

Epoch: 6| Step: 5
Training loss: 0.38626739382743835
Validation loss: 1.660459554323586

Epoch: 6| Step: 6
Training loss: 0.3626449704170227
Validation loss: 1.6363704255832139

Epoch: 6| Step: 7
Training loss: 0.3319647014141083
Validation loss: 1.6395700413693663

Epoch: 6| Step: 8
Training loss: 0.19910743832588196
Validation loss: 1.6319887612455635

Epoch: 6| Step: 9
Training loss: 0.3654526472091675
Validation loss: 1.6361595199954124

Epoch: 6| Step: 10
Training loss: 0.3829711377620697
Validation loss: 1.6416107493062173

Epoch: 6| Step: 11
Training loss: 0.5773540735244751
Validation loss: 1.6453788459941905

Epoch: 6| Step: 12
Training loss: 0.27851375937461853
Validation loss: 1.6439102612515932

Epoch: 6| Step: 13
Training loss: 0.1442021280527115
Validation loss: 1.6467700594214982

Epoch: 298| Step: 0
Training loss: 0.16694393754005432
Validation loss: 1.6131011760363014

Epoch: 6| Step: 1
Training loss: 0.3518684208393097
Validation loss: 1.640988511423911

Epoch: 6| Step: 2
Training loss: 0.3943527936935425
Validation loss: 1.6244713055190219

Epoch: 6| Step: 3
Training loss: 0.22743135690689087
Validation loss: 1.608265789606238

Epoch: 6| Step: 4
Training loss: 0.22488081455230713
Validation loss: 1.612992989119663

Epoch: 6| Step: 5
Training loss: 0.19131971895694733
Validation loss: 1.6311603335924045

Epoch: 6| Step: 6
Training loss: 0.27717891335487366
Validation loss: 1.6200311876112414

Epoch: 6| Step: 7
Training loss: 0.3252341151237488
Validation loss: 1.6305836054586595

Epoch: 6| Step: 8
Training loss: 0.2576856315135956
Validation loss: 1.576249800702577

Epoch: 6| Step: 9
Training loss: 0.3289977014064789
Validation loss: 1.5860877883049749

Epoch: 6| Step: 10
Training loss: 0.2476072907447815
Validation loss: 1.5628788317403486

Epoch: 6| Step: 11
Training loss: 0.37075990438461304
Validation loss: 1.5424461492928125

Epoch: 6| Step: 12
Training loss: 0.5657552480697632
Validation loss: 1.5596391257419382

Epoch: 6| Step: 13
Training loss: 0.29757216572761536
Validation loss: 1.5403395955280592

Epoch: 299| Step: 0
Training loss: 0.24737130105495453
Validation loss: 1.5584952844086515

Epoch: 6| Step: 1
Training loss: 0.30247801542282104
Validation loss: 1.5528496106465657

Epoch: 6| Step: 2
Training loss: 0.35402530431747437
Validation loss: 1.5561101846797492

Epoch: 6| Step: 3
Training loss: 0.30615943670272827
Validation loss: 1.5556879710125666

Epoch: 6| Step: 4
Training loss: 0.3081667125225067
Validation loss: 1.5690879873050156

Epoch: 6| Step: 5
Training loss: 0.2912967801094055
Validation loss: 1.5883429178627588

Epoch: 6| Step: 6
Training loss: 0.3842431902885437
Validation loss: 1.5912752048943632

Epoch: 6| Step: 7
Training loss: 0.1960512101650238
Validation loss: 1.6092891821297266

Epoch: 6| Step: 8
Training loss: 0.1298452764749527
Validation loss: 1.6040612843728834

Epoch: 6| Step: 9
Training loss: 0.2149665653705597
Validation loss: 1.5678938358060774

Epoch: 6| Step: 10
Training loss: 0.2046477347612381
Validation loss: 1.6057492161309848

Epoch: 6| Step: 11
Training loss: 0.6404300928115845
Validation loss: 1.579235433250345

Epoch: 6| Step: 12
Training loss: 0.23893997073173523
Validation loss: 1.5686520145785423

Epoch: 6| Step: 13
Training loss: 0.4331821799278259
Validation loss: 1.5532166419490692

Epoch: 300| Step: 0
Training loss: 0.22834916412830353
Validation loss: 1.566238404602133

Epoch: 6| Step: 1
Training loss: 0.33916157484054565
Validation loss: 1.561407958307574

Epoch: 6| Step: 2
Training loss: 0.22730593383312225
Validation loss: 1.5742190204640871

Epoch: 6| Step: 3
Training loss: 0.16733470559120178
Validation loss: 1.5799649312932005

Epoch: 6| Step: 4
Training loss: 0.2635667026042938
Validation loss: 1.602458494965748

Epoch: 6| Step: 5
Training loss: 0.29354920983314514
Validation loss: 1.6079632953930927

Epoch: 6| Step: 6
Training loss: 0.2926962673664093
Validation loss: 1.5895072760120514

Epoch: 6| Step: 7
Training loss: 0.3215528428554535
Validation loss: 1.578241298275609

Epoch: 6| Step: 8
Training loss: 0.5498380064964294
Validation loss: 1.5698927211505112

Epoch: 6| Step: 9
Training loss: 0.28588736057281494
Validation loss: 1.5553484501377228

Epoch: 6| Step: 10
Training loss: 0.4977058172225952
Validation loss: 1.558850852392053

Epoch: 6| Step: 11
Training loss: 0.2731233239173889
Validation loss: 1.584828907443631

Epoch: 6| Step: 12
Training loss: 0.25494351983070374
Validation loss: 1.579839667966289

Epoch: 6| Step: 13
Training loss: 0.23966234922409058
Validation loss: 1.5995754836707987

Epoch: 301| Step: 0
Training loss: 0.2790907919406891
Validation loss: 1.6046871062247985

Epoch: 6| Step: 1
Training loss: 0.11027700453996658
Validation loss: 1.5928379438256706

Epoch: 6| Step: 2
Training loss: 0.44364994764328003
Validation loss: 1.5686088992703346

Epoch: 6| Step: 3
Training loss: 0.20913082361221313
Validation loss: 1.5721102504320041

Epoch: 6| Step: 4
Training loss: 0.36477869749069214
Validation loss: 1.580802627789077

Epoch: 6| Step: 5
Training loss: 0.230116069316864
Validation loss: 1.5608056655494116

Epoch: 6| Step: 6
Training loss: 0.5901858806610107
Validation loss: 1.5724450311353129

Epoch: 6| Step: 7
Training loss: 0.26687324047088623
Validation loss: 1.5345849708844257

Epoch: 6| Step: 8
Training loss: 0.21284660696983337
Validation loss: 1.5516233918487385

Epoch: 6| Step: 9
Training loss: 0.25369858741760254
Validation loss: 1.5487411740005657

Epoch: 6| Step: 10
Training loss: 0.17575018107891083
Validation loss: 1.555476979542804

Epoch: 6| Step: 11
Training loss: 0.23069053888320923
Validation loss: 1.5666826296878118

Epoch: 6| Step: 12
Training loss: 0.3436511158943176
Validation loss: 1.5631970615797146

Epoch: 6| Step: 13
Training loss: 0.22357861697673798
Validation loss: 1.5883736020775252

Epoch: 302| Step: 0
Training loss: 0.4169287383556366
Validation loss: 1.5817945227828076

Epoch: 6| Step: 1
Training loss: 0.31992149353027344
Validation loss: 1.5922010406371085

Epoch: 6| Step: 2
Training loss: 0.2881367802619934
Validation loss: 1.6067978092419204

Epoch: 6| Step: 3
Training loss: 0.10935899615287781
Validation loss: 1.6000011544073782

Epoch: 6| Step: 4
Training loss: 0.18249954283237457
Validation loss: 1.585241763822494

Epoch: 6| Step: 5
Training loss: 0.19941368699073792
Validation loss: 1.5677927770922262

Epoch: 6| Step: 6
Training loss: 0.34989991784095764
Validation loss: 1.5820309333903815

Epoch: 6| Step: 7
Training loss: 0.2820579409599304
Validation loss: 1.583860090342901

Epoch: 6| Step: 8
Training loss: 0.5367652177810669
Validation loss: 1.5879694954041512

Epoch: 6| Step: 9
Training loss: 0.2148227095603943
Validation loss: 1.5709662988621702

Epoch: 6| Step: 10
Training loss: 0.16021989285945892
Validation loss: 1.5405194297913583

Epoch: 6| Step: 11
Training loss: 0.21718835830688477
Validation loss: 1.5569979580499793

Epoch: 6| Step: 12
Training loss: 0.4208710789680481
Validation loss: 1.539971468269184

Epoch: 6| Step: 13
Training loss: 0.07177458703517914
Validation loss: 1.5461763374267086

Epoch: 303| Step: 0
Training loss: 0.18993434309959412
Validation loss: 1.5831592044522684

Epoch: 6| Step: 1
Training loss: 0.12022624909877777
Validation loss: 1.554256764791345

Epoch: 6| Step: 2
Training loss: 0.32453274726867676
Validation loss: 1.5834815284257293

Epoch: 6| Step: 3
Training loss: 0.556705117225647
Validation loss: 1.5986221118639874

Epoch: 6| Step: 4
Training loss: 0.2200155258178711
Validation loss: 1.5716918681257515

Epoch: 6| Step: 5
Training loss: 0.21695026755332947
Validation loss: 1.5621814112509451

Epoch: 6| Step: 6
Training loss: 0.4454456865787506
Validation loss: 1.5803738794019144

Epoch: 6| Step: 7
Training loss: 0.23547299206256866
Validation loss: 1.6040248922122422

Epoch: 6| Step: 8
Training loss: 0.41859787702560425
Validation loss: 1.5876663936081754

Epoch: 6| Step: 9
Training loss: 0.17949075996875763
Validation loss: 1.6030219088318527

Epoch: 6| Step: 10
Training loss: 0.16532261669635773
Validation loss: 1.6382237089577543

Epoch: 6| Step: 11
Training loss: 0.23329071700572968
Validation loss: 1.6360290255597842

Epoch: 6| Step: 12
Training loss: 0.3383232355117798
Validation loss: 1.6543059323423652

Epoch: 6| Step: 13
Training loss: 0.0654204785823822
Validation loss: 1.631074386258279

Epoch: 304| Step: 0
Training loss: 0.2518462538719177
Validation loss: 1.6322767490981727

Epoch: 6| Step: 1
Training loss: 0.2518640160560608
Validation loss: 1.6302401981046122

Epoch: 6| Step: 2
Training loss: 0.24247974157333374
Validation loss: 1.5844825621574157

Epoch: 6| Step: 3
Training loss: 0.20239834487438202
Validation loss: 1.5977395606297318

Epoch: 6| Step: 4
Training loss: 0.25952327251434326
Validation loss: 1.596152171011894

Epoch: 6| Step: 5
Training loss: 0.29357433319091797
Validation loss: 1.609388723809232

Epoch: 6| Step: 6
Training loss: 0.32700228691101074
Validation loss: 1.5929710365110827

Epoch: 6| Step: 7
Training loss: 0.5222573280334473
Validation loss: 1.5813161814084618

Epoch: 6| Step: 8
Training loss: 0.21475592255592346
Validation loss: 1.573143602699362

Epoch: 6| Step: 9
Training loss: 0.35218545794487
Validation loss: 1.5740331988180838

Epoch: 6| Step: 10
Training loss: 0.18732722103595734
Validation loss: 1.5718636820393224

Epoch: 6| Step: 11
Training loss: 0.4011964499950409
Validation loss: 1.5794837667096047

Epoch: 6| Step: 12
Training loss: 0.3003203868865967
Validation loss: 1.5843937332912157

Epoch: 6| Step: 13
Training loss: 0.15278036892414093
Validation loss: 1.5698782372218307

Epoch: 305| Step: 0
Training loss: 0.2711898684501648
Validation loss: 1.5685907551037368

Epoch: 6| Step: 1
Training loss: 0.2551463842391968
Validation loss: 1.5744271419381584

Epoch: 6| Step: 2
Training loss: 0.17010372877120972
Validation loss: 1.5461568191487303

Epoch: 6| Step: 3
Training loss: 0.23602932691574097
Validation loss: 1.5746204083965671

Epoch: 6| Step: 4
Training loss: 0.24186822772026062
Validation loss: 1.5602777004241943

Epoch: 6| Step: 5
Training loss: 0.43822771310806274
Validation loss: 1.6029716025116623

Epoch: 6| Step: 6
Training loss: 0.24018648266792297
Validation loss: 1.6018675533674096

Epoch: 6| Step: 7
Training loss: 0.42742908000946045
Validation loss: 1.568317973485557

Epoch: 6| Step: 8
Training loss: 0.35394996404647827
Validation loss: 1.582908349652444

Epoch: 6| Step: 9
Training loss: 0.18064285814762115
Validation loss: 1.5704094748343191

Epoch: 6| Step: 10
Training loss: 0.27187371253967285
Validation loss: 1.5693644477475075

Epoch: 6| Step: 11
Training loss: 0.180257186293602
Validation loss: 1.5709525116028324

Epoch: 6| Step: 12
Training loss: 0.4276544153690338
Validation loss: 1.5642847002193492

Epoch: 6| Step: 13
Training loss: 0.08558647334575653
Validation loss: 1.5607932280468684

Epoch: 306| Step: 0
Training loss: 0.3638482391834259
Validation loss: 1.5594252450491792

Epoch: 6| Step: 1
Training loss: 0.24649178981781006
Validation loss: 1.5777535310355566

Epoch: 6| Step: 2
Training loss: 0.22764575481414795
Validation loss: 1.5892943297663042

Epoch: 6| Step: 3
Training loss: 0.33903712034225464
Validation loss: 1.5805596446478238

Epoch: 6| Step: 4
Training loss: 0.3321691155433655
Validation loss: 1.561381406681512

Epoch: 6| Step: 5
Training loss: 0.22647057473659515
Validation loss: 1.572496800012486

Epoch: 6| Step: 6
Training loss: 0.358017235994339
Validation loss: 1.545505242962991

Epoch: 6| Step: 7
Training loss: 0.14585556089878082
Validation loss: 1.5435704569662771

Epoch: 6| Step: 8
Training loss: 0.45525452494621277
Validation loss: 1.5546505258929344

Epoch: 6| Step: 9
Training loss: 0.2014506459236145
Validation loss: 1.5519267897452078

Epoch: 6| Step: 10
Training loss: 0.18871822953224182
Validation loss: 1.5473923080710954

Epoch: 6| Step: 11
Training loss: 0.1908431202173233
Validation loss: 1.5549398365841116

Epoch: 6| Step: 12
Training loss: 0.24318340420722961
Validation loss: 1.5301155826096893

Epoch: 6| Step: 13
Training loss: 0.19674240052700043
Validation loss: 1.5636019104270524

Epoch: 307| Step: 0
Training loss: 0.27288559079170227
Validation loss: 1.5537832244749992

Epoch: 6| Step: 1
Training loss: 0.20379549264907837
Validation loss: 1.5792986680102605

Epoch: 6| Step: 2
Training loss: 0.24086962640285492
Validation loss: 1.5560251858926588

Epoch: 6| Step: 3
Training loss: 0.14940118789672852
Validation loss: 1.5653911694403617

Epoch: 6| Step: 4
Training loss: 0.30986422300338745
Validation loss: 1.561680434852518

Epoch: 6| Step: 5
Training loss: 0.19865313172340393
Validation loss: 1.5527195238297986

Epoch: 6| Step: 6
Training loss: 0.2638893127441406
Validation loss: 1.5394069687012704

Epoch: 6| Step: 7
Training loss: 0.27319011092185974
Validation loss: 1.5252557326388616

Epoch: 6| Step: 8
Training loss: 0.4397367835044861
Validation loss: 1.558616111355443

Epoch: 6| Step: 9
Training loss: 0.5433052182197571
Validation loss: 1.5600448180270452

Epoch: 6| Step: 10
Training loss: 0.19082729518413544
Validation loss: 1.5592171056296236

Epoch: 6| Step: 11
Training loss: 0.26622822880744934
Validation loss: 1.560790660560772

Epoch: 6| Step: 12
Training loss: 0.25956448912620544
Validation loss: 1.5643160676443448

Epoch: 6| Step: 13
Training loss: 0.2178463637828827
Validation loss: 1.5864502345362017

Epoch: 308| Step: 0
Training loss: 0.3735625743865967
Validation loss: 1.5760729582078996

Epoch: 6| Step: 1
Training loss: 0.25836682319641113
Validation loss: 1.5973439710114592

Epoch: 6| Step: 2
Training loss: 0.22372755408287048
Validation loss: 1.5780624535775953

Epoch: 6| Step: 3
Training loss: 0.17202594876289368
Validation loss: 1.5885576125114196

Epoch: 6| Step: 4
Training loss: 0.23451310396194458
Validation loss: 1.5712399149453768

Epoch: 6| Step: 5
Training loss: 0.4698558449745178
Validation loss: 1.5859161089825373

Epoch: 6| Step: 6
Training loss: 0.19747573137283325
Validation loss: 1.5699905208362046

Epoch: 6| Step: 7
Training loss: 0.41344091296195984
Validation loss: 1.5841987632936048

Epoch: 6| Step: 8
Training loss: 0.17810463905334473
Validation loss: 1.5925656403264692

Epoch: 6| Step: 9
Training loss: 0.2380053997039795
Validation loss: 1.5920016778412687

Epoch: 6| Step: 10
Training loss: 0.35335975885391235
Validation loss: 1.568971372419788

Epoch: 6| Step: 11
Training loss: 0.371549129486084
Validation loss: 1.5694134901928645

Epoch: 6| Step: 12
Training loss: 0.2707241177558899
Validation loss: 1.5707247282869072

Epoch: 6| Step: 13
Training loss: 0.2474992573261261
Validation loss: 1.5689864594449279

Epoch: 309| Step: 0
Training loss: 0.1887340098619461
Validation loss: 1.567195579569827

Epoch: 6| Step: 1
Training loss: 0.23156273365020752
Validation loss: 1.5642094176302674

Epoch: 6| Step: 2
Training loss: 0.3078697919845581
Validation loss: 1.5670482112515358

Epoch: 6| Step: 3
Training loss: 0.37010324001312256
Validation loss: 1.575554904117379

Epoch: 6| Step: 4
Training loss: 0.30958929657936096
Validation loss: 1.5689175436573644

Epoch: 6| Step: 5
Training loss: 0.14031702280044556
Validation loss: 1.5886396054298646

Epoch: 6| Step: 6
Training loss: 0.24295467138290405
Validation loss: 1.624481306281141

Epoch: 6| Step: 7
Training loss: 0.31061869859695435
Validation loss: 1.5890225774498397

Epoch: 6| Step: 8
Training loss: 0.47850552201271057
Validation loss: 1.6076694944853425

Epoch: 6| Step: 9
Training loss: 0.28122901916503906
Validation loss: 1.5941599902286325

Epoch: 6| Step: 10
Training loss: 0.23426440358161926
Validation loss: 1.5785723488817933

Epoch: 6| Step: 11
Training loss: 0.09036421775817871
Validation loss: 1.5721691090573546

Epoch: 6| Step: 12
Training loss: 0.30069029331207275
Validation loss: 1.579299726793843

Epoch: 6| Step: 13
Training loss: 0.31258100271224976
Validation loss: 1.5799480176741076

Epoch: 310| Step: 0
Training loss: 0.2626984119415283
Validation loss: 1.5817963846268193

Epoch: 6| Step: 1
Training loss: 0.6247010231018066
Validation loss: 1.5807583280788955

Epoch: 6| Step: 2
Training loss: 0.34532761573791504
Validation loss: 1.593902067471576

Epoch: 6| Step: 3
Training loss: 0.2884520888328552
Validation loss: 1.5650417394535516

Epoch: 6| Step: 4
Training loss: 0.10809601843357086
Validation loss: 1.567182538329914

Epoch: 6| Step: 5
Training loss: 0.25560086965560913
Validation loss: 1.5723392598090633

Epoch: 6| Step: 6
Training loss: 0.1504916250705719
Validation loss: 1.5752758595251268

Epoch: 6| Step: 7
Training loss: 0.26501256227493286
Validation loss: 1.5653958743618381

Epoch: 6| Step: 8
Training loss: 0.20438897609710693
Validation loss: 1.5830454813536776

Epoch: 6| Step: 9
Training loss: 0.1268133521080017
Validation loss: 1.5855664899272304

Epoch: 6| Step: 10
Training loss: 0.405367910861969
Validation loss: 1.5655904213587444

Epoch: 6| Step: 11
Training loss: 0.22808846831321716
Validation loss: 1.5651011108070292

Epoch: 6| Step: 12
Training loss: 0.25651121139526367
Validation loss: 1.5635196239717546

Epoch: 6| Step: 13
Training loss: 0.4917255938053131
Validation loss: 1.5587979401311567

Epoch: 311| Step: 0
Training loss: 0.14768630266189575
Validation loss: 1.5465862571552236

Epoch: 6| Step: 1
Training loss: 0.16799697279930115
Validation loss: 1.5473433784259263

Epoch: 6| Step: 2
Training loss: 0.23049359023571014
Validation loss: 1.546074116101829

Epoch: 6| Step: 3
Training loss: 0.3386251926422119
Validation loss: 1.5593346459891206

Epoch: 6| Step: 4
Training loss: 0.23266816139221191
Validation loss: 1.5454461548918037

Epoch: 6| Step: 5
Training loss: 0.18329833447933197
Validation loss: 1.5762322961643178

Epoch: 6| Step: 6
Training loss: 0.22238267958164215
Validation loss: 1.5459447406953382

Epoch: 6| Step: 7
Training loss: 0.19526070356369019
Validation loss: 1.5559092260176135

Epoch: 6| Step: 8
Training loss: 0.5070486664772034
Validation loss: 1.5257423898225189

Epoch: 6| Step: 9
Training loss: 0.3979493975639343
Validation loss: 1.5182357577867405

Epoch: 6| Step: 10
Training loss: 0.20880641043186188
Validation loss: 1.5632489035206456

Epoch: 6| Step: 11
Training loss: 0.3283488154411316
Validation loss: 1.5661625080211188

Epoch: 6| Step: 12
Training loss: 0.27450430393218994
Validation loss: 1.6018069046799854

Epoch: 6| Step: 13
Training loss: 0.2874811291694641
Validation loss: 1.5658732306572698

Epoch: 312| Step: 0
Training loss: 0.18709245324134827
Validation loss: 1.5727422160487021

Epoch: 6| Step: 1
Training loss: 0.1197676956653595
Validation loss: 1.6008197133259108

Epoch: 6| Step: 2
Training loss: 0.27769601345062256
Validation loss: 1.5794065075535928

Epoch: 6| Step: 3
Training loss: 0.28178671002388
Validation loss: 1.5636652977235856

Epoch: 6| Step: 4
Training loss: 0.34281620383262634
Validation loss: 1.5713675970672278

Epoch: 6| Step: 5
Training loss: 0.3747639060020447
Validation loss: 1.5733270106777069

Epoch: 6| Step: 6
Training loss: 0.2827630341053009
Validation loss: 1.5924400667990408

Epoch: 6| Step: 7
Training loss: 0.16493187844753265
Validation loss: 1.5890980625665316

Epoch: 6| Step: 8
Training loss: 0.17731598019599915
Validation loss: 1.5690385398044382

Epoch: 6| Step: 9
Training loss: 0.20222266018390656
Validation loss: 1.6010990315868008

Epoch: 6| Step: 10
Training loss: 0.41864675283432007
Validation loss: 1.5533714153433358

Epoch: 6| Step: 11
Training loss: 0.13303418457508087
Validation loss: 1.561190943564138

Epoch: 6| Step: 12
Training loss: 0.2649351954460144
Validation loss: 1.5535756644382273

Epoch: 6| Step: 13
Training loss: 0.20634153485298157
Validation loss: 1.5702708741670013

Epoch: 313| Step: 0
Training loss: 0.17656098306179047
Validation loss: 1.5630947710365377

Epoch: 6| Step: 1
Training loss: 0.23333564400672913
Validation loss: 1.535787606752047

Epoch: 6| Step: 2
Training loss: 0.15637223422527313
Validation loss: 1.5577737746700164

Epoch: 6| Step: 3
Training loss: 0.19610902667045593
Validation loss: 1.567083438237508

Epoch: 6| Step: 4
Training loss: 0.23251408338546753
Validation loss: 1.5572787715542702

Epoch: 6| Step: 5
Training loss: 0.3317320942878723
Validation loss: 1.552015410956516

Epoch: 6| Step: 6
Training loss: 0.26251110434532166
Validation loss: 1.5759098145269579

Epoch: 6| Step: 7
Training loss: 0.4355478882789612
Validation loss: 1.554862287095798

Epoch: 6| Step: 8
Training loss: 0.19740533828735352
Validation loss: 1.5483322810101252

Epoch: 6| Step: 9
Training loss: 0.25912797451019287
Validation loss: 1.5491670357283724

Epoch: 6| Step: 10
Training loss: 0.31106001138687134
Validation loss: 1.5800208648045857

Epoch: 6| Step: 11
Training loss: 0.1781681925058365
Validation loss: 1.5545122623443604

Epoch: 6| Step: 12
Training loss: 0.16532868146896362
Validation loss: 1.5573590545244114

Epoch: 6| Step: 13
Training loss: 0.5893948078155518
Validation loss: 1.5384945561808925

Epoch: 314| Step: 0
Training loss: 0.4413597881793976
Validation loss: 1.540847578356343

Epoch: 6| Step: 1
Training loss: 0.20191988348960876
Validation loss: 1.5746471728048017

Epoch: 6| Step: 2
Training loss: 0.2586894631385803
Validation loss: 1.5674206992631317

Epoch: 6| Step: 3
Training loss: 0.2380800098180771
Validation loss: 1.5703260155134304

Epoch: 6| Step: 4
Training loss: 0.31382089853286743
Validation loss: 1.58050754890647

Epoch: 6| Step: 5
Training loss: 0.2585744857788086
Validation loss: 1.6071764000000492

Epoch: 6| Step: 6
Training loss: 0.2306888997554779
Validation loss: 1.6250335170376686

Epoch: 6| Step: 7
Training loss: 0.26183658838272095
Validation loss: 1.6136086910001692

Epoch: 6| Step: 8
Training loss: 0.3871086835861206
Validation loss: 1.623190959294637

Epoch: 6| Step: 9
Training loss: 0.2264699786901474
Validation loss: 1.6097174280433244

Epoch: 6| Step: 10
Training loss: 0.4609912037849426
Validation loss: 1.5799821615219116

Epoch: 6| Step: 11
Training loss: 0.2787167429924011
Validation loss: 1.5846128873927618

Epoch: 6| Step: 12
Training loss: 0.5306062698364258
Validation loss: 1.5617205225011355

Epoch: 6| Step: 13
Training loss: 0.2840222716331482
Validation loss: 1.5730946038358955

Epoch: 315| Step: 0
Training loss: 0.1569501757621765
Validation loss: 1.5517081445263279

Epoch: 6| Step: 1
Training loss: 0.18787270784378052
Validation loss: 1.5401275042564637

Epoch: 6| Step: 2
Training loss: 0.3059777617454529
Validation loss: 1.5853612628034366

Epoch: 6| Step: 3
Training loss: 0.14400985836982727
Validation loss: 1.6028838388381466

Epoch: 6| Step: 4
Training loss: 0.24490731954574585
Validation loss: 1.5781110005993997

Epoch: 6| Step: 5
Training loss: 0.2929934859275818
Validation loss: 1.557580671002788

Epoch: 6| Step: 6
Training loss: 0.29289984703063965
Validation loss: 1.5346424464256532

Epoch: 6| Step: 7
Training loss: 0.38568800687789917
Validation loss: 1.5487032898010746

Epoch: 6| Step: 8
Training loss: 0.5623403787612915
Validation loss: 1.5622342760844896

Epoch: 6| Step: 9
Training loss: 0.3936443030834198
Validation loss: 1.5702745773458993

Epoch: 6| Step: 10
Training loss: 0.4066053032875061
Validation loss: 1.5579492122896257

Epoch: 6| Step: 11
Training loss: 0.2163659632205963
Validation loss: 1.5691686919940415

Epoch: 6| Step: 12
Training loss: 0.2738896608352661
Validation loss: 1.5588853359222412

Epoch: 6| Step: 13
Training loss: 0.21059328317642212
Validation loss: 1.564619783432253

Epoch: 316| Step: 0
Training loss: 0.23260167241096497
Validation loss: 1.5780646775358467

Epoch: 6| Step: 1
Training loss: 0.3023598790168762
Validation loss: 1.579634230623963

Epoch: 6| Step: 2
Training loss: 0.15539005398750305
Validation loss: 1.5757097057116929

Epoch: 6| Step: 3
Training loss: 0.18694952130317688
Validation loss: 1.5642403594909176

Epoch: 6| Step: 4
Training loss: 0.4609021246433258
Validation loss: 1.549497877397845

Epoch: 6| Step: 5
Training loss: 0.5506422519683838
Validation loss: 1.5492414043795677

Epoch: 6| Step: 6
Training loss: 0.256207674741745
Validation loss: 1.5744394640768729

Epoch: 6| Step: 7
Training loss: 0.20114009082317352
Validation loss: 1.5849808544240973

Epoch: 6| Step: 8
Training loss: 0.20338167250156403
Validation loss: 1.5692821189921389

Epoch: 6| Step: 9
Training loss: 0.2218697965145111
Validation loss: 1.5999200831177414

Epoch: 6| Step: 10
Training loss: 0.282021164894104
Validation loss: 1.5560923994228404

Epoch: 6| Step: 11
Training loss: 0.23520296812057495
Validation loss: 1.5656845979793097

Epoch: 6| Step: 12
Training loss: 0.1787802278995514
Validation loss: 1.5578464718275173

Epoch: 6| Step: 13
Training loss: 0.23021334409713745
Validation loss: 1.5472165038508754

Epoch: 317| Step: 0
Training loss: 0.23771947622299194
Validation loss: 1.5491466368398359

Epoch: 6| Step: 1
Training loss: 0.38075196743011475
Validation loss: 1.5796404730889104

Epoch: 6| Step: 2
Training loss: 0.20851334929466248
Validation loss: 1.5788760928697483

Epoch: 6| Step: 3
Training loss: 0.3629077672958374
Validation loss: 1.5704488100544098

Epoch: 6| Step: 4
Training loss: 0.4522538483142853
Validation loss: 1.557906727637014

Epoch: 6| Step: 5
Training loss: 0.2281292974948883
Validation loss: 1.5672619983714113

Epoch: 6| Step: 6
Training loss: 0.2125946283340454
Validation loss: 1.5788778528090446

Epoch: 6| Step: 7
Training loss: 0.3177422285079956
Validation loss: 1.5864185287106423

Epoch: 6| Step: 8
Training loss: 0.19137772917747498
Validation loss: 1.5890310938640306

Epoch: 6| Step: 9
Training loss: 0.23513296246528625
Validation loss: 1.578976156250123

Epoch: 6| Step: 10
Training loss: 0.32853078842163086
Validation loss: 1.560066120598906

Epoch: 6| Step: 11
Training loss: 0.25487029552459717
Validation loss: 1.5440146320609636

Epoch: 6| Step: 12
Training loss: 0.28890135884284973
Validation loss: 1.5808241187885244

Epoch: 6| Step: 13
Training loss: 0.1626824289560318
Validation loss: 1.5530660613890617

Epoch: 318| Step: 0
Training loss: 0.3187640309333801
Validation loss: 1.567466523057671

Epoch: 6| Step: 1
Training loss: 0.29579734802246094
Validation loss: 1.5841444884577105

Epoch: 6| Step: 2
Training loss: 0.15873250365257263
Validation loss: 1.558580365232242

Epoch: 6| Step: 3
Training loss: 0.26125240325927734
Validation loss: 1.5745817922776746

Epoch: 6| Step: 4
Training loss: 0.3953757882118225
Validation loss: 1.557538249159372

Epoch: 6| Step: 5
Training loss: 0.34161901473999023
Validation loss: 1.5709988737619052

Epoch: 6| Step: 6
Training loss: 0.2564014494419098
Validation loss: 1.597204771093143

Epoch: 6| Step: 7
Training loss: 0.4614189863204956
Validation loss: 1.6131224273353495

Epoch: 6| Step: 8
Training loss: 0.27836504578590393
Validation loss: 1.606376547967234

Epoch: 6| Step: 9
Training loss: 0.1678818166255951
Validation loss: 1.6298791016301801

Epoch: 6| Step: 10
Training loss: 0.2787931561470032
Validation loss: 1.6120574871699016

Epoch: 6| Step: 11
Training loss: 0.7525996565818787
Validation loss: 1.5967655733067503

Epoch: 6| Step: 12
Training loss: 0.1520994007587433
Validation loss: 1.5947370772720666

Epoch: 6| Step: 13
Training loss: 0.1636696457862854
Validation loss: 1.5809357063744658

Epoch: 319| Step: 0
Training loss: 0.1799554079771042
Validation loss: 1.5942610617606872

Epoch: 6| Step: 1
Training loss: 0.3402610421180725
Validation loss: 1.6290039734173847

Epoch: 6| Step: 2
Training loss: 0.595564603805542
Validation loss: 1.6196113773571548

Epoch: 6| Step: 3
Training loss: 0.29088833928108215
Validation loss: 1.6191934616334978

Epoch: 6| Step: 4
Training loss: 0.219289630651474
Validation loss: 1.6327230827782744

Epoch: 6| Step: 5
Training loss: 0.2737600803375244
Validation loss: 1.597249090030629

Epoch: 6| Step: 6
Training loss: 0.2424793690443039
Validation loss: 1.613462205856077

Epoch: 6| Step: 7
Training loss: 0.2520906925201416
Validation loss: 1.629953049844311

Epoch: 6| Step: 8
Training loss: 0.3700355887413025
Validation loss: 1.6076491507150794

Epoch: 6| Step: 9
Training loss: 0.18837538361549377
Validation loss: 1.6003224388245614

Epoch: 6| Step: 10
Training loss: 0.20684166252613068
Validation loss: 1.5924702677675473

Epoch: 6| Step: 11
Training loss: 0.23480463027954102
Validation loss: 1.5914513295696628

Epoch: 6| Step: 12
Training loss: 0.24678745865821838
Validation loss: 1.5870933250714374

Epoch: 6| Step: 13
Training loss: 0.32728806138038635
Validation loss: 1.6009772580157045

Epoch: 320| Step: 0
Training loss: 0.3486725986003876
Validation loss: 1.6040153734145626

Epoch: 6| Step: 1
Training loss: 0.3171343207359314
Validation loss: 1.6005673216235252

Epoch: 6| Step: 2
Training loss: 0.23636594414710999
Validation loss: 1.603065752214001

Epoch: 6| Step: 3
Training loss: 0.2573827803134918
Validation loss: 1.5772514394534531

Epoch: 6| Step: 4
Training loss: 0.3618848919868469
Validation loss: 1.5501031311609412

Epoch: 6| Step: 5
Training loss: 0.14944815635681152
Validation loss: 1.5407100838999594

Epoch: 6| Step: 6
Training loss: 0.21902361512184143
Validation loss: 1.5406373675151537

Epoch: 6| Step: 7
Training loss: 0.154517263174057
Validation loss: 1.5293868152044152

Epoch: 6| Step: 8
Training loss: 0.49727797508239746
Validation loss: 1.56499090374157

Epoch: 6| Step: 9
Training loss: 0.18429523706436157
Validation loss: 1.5446999816484348

Epoch: 6| Step: 10
Training loss: 0.40881893038749695
Validation loss: 1.5171966591188986

Epoch: 6| Step: 11
Training loss: 0.25774356722831726
Validation loss: 1.5403873100075671

Epoch: 6| Step: 12
Training loss: 0.19367599487304688
Validation loss: 1.5414238578529769

Epoch: 6| Step: 13
Training loss: 0.16062918305397034
Validation loss: 1.5562061584124

Epoch: 321| Step: 0
Training loss: 0.21436002850532532
Validation loss: 1.5407625039418538

Epoch: 6| Step: 1
Training loss: 0.23927146196365356
Validation loss: 1.5272451709675532

Epoch: 6| Step: 2
Training loss: 0.3587408661842346
Validation loss: 1.5420210925481652

Epoch: 6| Step: 3
Training loss: 0.6006671190261841
Validation loss: 1.5655011887191443

Epoch: 6| Step: 4
Training loss: 0.514457106590271
Validation loss: 1.5377809950100478

Epoch: 6| Step: 5
Training loss: 0.23178282380104065
Validation loss: 1.5641906786990423

Epoch: 6| Step: 6
Training loss: 0.27827900648117065
Validation loss: 1.5342353261927122

Epoch: 6| Step: 7
Training loss: 0.190995991230011
Validation loss: 1.5608668814423263

Epoch: 6| Step: 8
Training loss: 0.2602147161960602
Validation loss: 1.5600426812325754

Epoch: 6| Step: 9
Training loss: 0.181799054145813
Validation loss: 1.535245753103687

Epoch: 6| Step: 10
Training loss: 0.15773841738700867
Validation loss: 1.5483616628954489

Epoch: 6| Step: 11
Training loss: 0.2706896662712097
Validation loss: 1.5406217946801135

Epoch: 6| Step: 12
Training loss: 0.21070119738578796
Validation loss: 1.5364566272304905

Epoch: 6| Step: 13
Training loss: 0.1989946812391281
Validation loss: 1.5530965892217492

Epoch: 322| Step: 0
Training loss: 0.1335357129573822
Validation loss: 1.547111375357515

Epoch: 6| Step: 1
Training loss: 0.11857600510120392
Validation loss: 1.5138757997943508

Epoch: 6| Step: 2
Training loss: 0.17932164669036865
Validation loss: 1.5561037742963402

Epoch: 6| Step: 3
Training loss: 0.19024139642715454
Validation loss: 1.5464306313504455

Epoch: 6| Step: 4
Training loss: 0.20387043058872223
Validation loss: 1.548375996210242

Epoch: 6| Step: 5
Training loss: 0.24559393525123596
Validation loss: 1.5317926714497228

Epoch: 6| Step: 6
Training loss: 0.5662013292312622
Validation loss: 1.5221527391864407

Epoch: 6| Step: 7
Training loss: 0.23958925902843475
Validation loss: 1.5347058708949755

Epoch: 6| Step: 8
Training loss: 0.38923656940460205
Validation loss: 1.5413074608772033

Epoch: 6| Step: 9
Training loss: 0.23805668950080872
Validation loss: 1.5263335768894484

Epoch: 6| Step: 10
Training loss: 0.2543242573738098
Validation loss: 1.5417565043254564

Epoch: 6| Step: 11
Training loss: 0.3475278615951538
Validation loss: 1.5645581099294847

Epoch: 6| Step: 12
Training loss: 0.22901329398155212
Validation loss: 1.556729470529864

Epoch: 6| Step: 13
Training loss: 0.536047101020813
Validation loss: 1.5595026080326369

Epoch: 323| Step: 0
Training loss: 0.13063514232635498
Validation loss: 1.5539701190046085

Epoch: 6| Step: 1
Training loss: 0.22244587540626526
Validation loss: 1.559743885071047

Epoch: 6| Step: 2
Training loss: 0.2272021621465683
Validation loss: 1.5648514865547098

Epoch: 6| Step: 3
Training loss: 0.4266950488090515
Validation loss: 1.5777214688639487

Epoch: 6| Step: 4
Training loss: 0.1677958220243454
Validation loss: 1.5798146442700458

Epoch: 6| Step: 5
Training loss: 0.12710469961166382
Validation loss: 1.5662086586798392

Epoch: 6| Step: 6
Training loss: 0.2097846418619156
Validation loss: 1.5767794142487228

Epoch: 6| Step: 7
Training loss: 0.4521027207374573
Validation loss: 1.6042253701917586

Epoch: 6| Step: 8
Training loss: 0.2076607346534729
Validation loss: 1.5874996736485472

Epoch: 6| Step: 9
Training loss: 0.17540273070335388
Validation loss: 1.5627791971288703

Epoch: 6| Step: 10
Training loss: 0.2431347668170929
Validation loss: 1.566238627638868

Epoch: 6| Step: 11
Training loss: 0.38532814383506775
Validation loss: 1.5889288411345532

Epoch: 6| Step: 12
Training loss: 0.2248533070087433
Validation loss: 1.5964971409049085

Epoch: 6| Step: 13
Training loss: 0.1767382025718689
Validation loss: 1.5741350330332273

Epoch: 324| Step: 0
Training loss: 0.27196094393730164
Validation loss: 1.5642915707762524

Epoch: 6| Step: 1
Training loss: 0.19860175251960754
Validation loss: 1.5957288242155505

Epoch: 6| Step: 2
Training loss: 0.17758435010910034
Validation loss: 1.5765884563487063

Epoch: 6| Step: 3
Training loss: 0.3442101776599884
Validation loss: 1.6072630318262244

Epoch: 6| Step: 4
Training loss: 0.14412151277065277
Validation loss: 1.5821287420488173

Epoch: 6| Step: 5
Training loss: 0.21502429246902466
Validation loss: 1.577194966295714

Epoch: 6| Step: 6
Training loss: 0.17937986552715302
Validation loss: 1.5554226982978083

Epoch: 6| Step: 7
Training loss: 0.3641236126422882
Validation loss: 1.5406770321630663

Epoch: 6| Step: 8
Training loss: 0.2844521403312683
Validation loss: 1.5620164089305426

Epoch: 6| Step: 9
Training loss: 0.1971648931503296
Validation loss: 1.5728780877205633

Epoch: 6| Step: 10
Training loss: 0.2769886255264282
Validation loss: 1.5478634501016268

Epoch: 6| Step: 11
Training loss: 0.21049925684928894
Validation loss: 1.5461737507133073

Epoch: 6| Step: 12
Training loss: 0.5273863077163696
Validation loss: 1.5590699782935522

Epoch: 6| Step: 13
Training loss: 0.0849631056189537
Validation loss: 1.556184732785789

Epoch: 325| Step: 0
Training loss: 0.27834510803222656
Validation loss: 1.5766360112415847

Epoch: 6| Step: 1
Training loss: 0.31368011236190796
Validation loss: 1.5765346814227361

Epoch: 6| Step: 2
Training loss: 0.23110374808311462
Validation loss: 1.5811402566971318

Epoch: 6| Step: 3
Training loss: 0.2820054590702057
Validation loss: 1.583068306728076

Epoch: 6| Step: 4
Training loss: 0.3335198163986206
Validation loss: 1.5975934792590398

Epoch: 6| Step: 5
Training loss: 0.11555150151252747
Validation loss: 1.600914273210751

Epoch: 6| Step: 6
Training loss: 0.2496875822544098
Validation loss: 1.6049547426162227

Epoch: 6| Step: 7
Training loss: 0.301038920879364
Validation loss: 1.576544697566699

Epoch: 6| Step: 8
Training loss: 0.25064340233802795
Validation loss: 1.6049198014761812

Epoch: 6| Step: 9
Training loss: 0.2922520041465759
Validation loss: 1.582333876240638

Epoch: 6| Step: 10
Training loss: 0.5894850492477417
Validation loss: 1.5812952518463135

Epoch: 6| Step: 11
Training loss: 0.33155927062034607
Validation loss: 1.5727477804307015

Epoch: 6| Step: 12
Training loss: 0.25460803508758545
Validation loss: 1.572623557941888

Epoch: 6| Step: 13
Training loss: 0.11800449341535568
Validation loss: 1.5797011493354716

Epoch: 326| Step: 0
Training loss: 0.38364148139953613
Validation loss: 1.5593625730083835

Epoch: 6| Step: 1
Training loss: 0.21793004870414734
Validation loss: 1.5565329469660276

Epoch: 6| Step: 2
Training loss: 0.29818546772003174
Validation loss: 1.548889490865892

Epoch: 6| Step: 3
Training loss: 0.23692011833190918
Validation loss: 1.5300745553867792

Epoch: 6| Step: 4
Training loss: 0.19853588938713074
Validation loss: 1.5388052232803837

Epoch: 6| Step: 5
Training loss: 0.12879982590675354
Validation loss: 1.5064110102192048

Epoch: 6| Step: 6
Training loss: 0.2550095319747925
Validation loss: 1.5171900564624416

Epoch: 6| Step: 7
Training loss: 0.2218940109014511
Validation loss: 1.506811834150745

Epoch: 6| Step: 8
Training loss: 0.3040429353713989
Validation loss: 1.4919125174963346

Epoch: 6| Step: 9
Training loss: 0.18705609440803528
Validation loss: 1.5467209533978534

Epoch: 6| Step: 10
Training loss: 0.26235464215278625
Validation loss: 1.5600330970620597

Epoch: 6| Step: 11
Training loss: 0.2938765287399292
Validation loss: 1.5485832319464734

Epoch: 6| Step: 12
Training loss: 0.3869450092315674
Validation loss: 1.5700024558651833

Epoch: 6| Step: 13
Training loss: 0.35242822766304016
Validation loss: 1.5456045481466478

Epoch: 327| Step: 0
Training loss: 0.11105772107839584
Validation loss: 1.5528457049400575

Epoch: 6| Step: 1
Training loss: 0.24013282358646393
Validation loss: 1.569128441554244

Epoch: 6| Step: 2
Training loss: 0.17419838905334473
Validation loss: 1.5760581583105109

Epoch: 6| Step: 3
Training loss: 0.16668462753295898
Validation loss: 1.569371332404434

Epoch: 6| Step: 4
Training loss: 0.16460314393043518
Validation loss: 1.5577183436321955

Epoch: 6| Step: 5
Training loss: 0.2019072026014328
Validation loss: 1.5802064300865255

Epoch: 6| Step: 6
Training loss: 0.12258706986904144
Validation loss: 1.558306304357385

Epoch: 6| Step: 7
Training loss: 0.22299371659755707
Validation loss: 1.5371920344650105

Epoch: 6| Step: 8
Training loss: 0.16514050960540771
Validation loss: 1.5662780987319125

Epoch: 6| Step: 9
Training loss: 0.49391433596611023
Validation loss: 1.5583754572817075

Epoch: 6| Step: 10
Training loss: 0.35894712805747986
Validation loss: 1.5685059460260535

Epoch: 6| Step: 11
Training loss: 0.4287252426147461
Validation loss: 1.5555243812581545

Epoch: 6| Step: 12
Training loss: 0.1708574891090393
Validation loss: 1.5578269061221872

Epoch: 6| Step: 13
Training loss: 0.3289526700973511
Validation loss: 1.5658797833227343

Epoch: 328| Step: 0
Training loss: 0.24365171790122986
Validation loss: 1.5871527553886495

Epoch: 6| Step: 1
Training loss: 0.25270190834999084
Validation loss: 1.6174391187647337

Epoch: 6| Step: 2
Training loss: 0.31476399302482605
Validation loss: 1.612352660907212

Epoch: 6| Step: 3
Training loss: 0.27720946073532104
Validation loss: 1.5913929388087282

Epoch: 6| Step: 4
Training loss: 0.2686903476715088
Validation loss: 1.5659494438479025

Epoch: 6| Step: 5
Training loss: 0.19644609093666077
Validation loss: 1.5555093032057568

Epoch: 6| Step: 6
Training loss: 0.15785881876945496
Validation loss: 1.5454816023508708

Epoch: 6| Step: 7
Training loss: 0.16883671283721924
Validation loss: 1.557278589535785

Epoch: 6| Step: 8
Training loss: 0.12278169393539429
Validation loss: 1.5701826144290227

Epoch: 6| Step: 9
Training loss: 0.1482040137052536
Validation loss: 1.6229330250011977

Epoch: 6| Step: 10
Training loss: 0.3066498637199402
Validation loss: 1.6078233142052927

Epoch: 6| Step: 11
Training loss: 0.30079883337020874
Validation loss: 1.6154712528310797

Epoch: 6| Step: 12
Training loss: 0.38259029388427734
Validation loss: 1.6123006959115305

Epoch: 6| Step: 13
Training loss: 0.565407931804657
Validation loss: 1.600947763330193

Epoch: 329| Step: 0
Training loss: 0.20092999935150146
Validation loss: 1.5759527567894227

Epoch: 6| Step: 1
Training loss: 0.3341105580329895
Validation loss: 1.5611990190321399

Epoch: 6| Step: 2
Training loss: 0.2685960829257965
Validation loss: 1.5786340236663818

Epoch: 6| Step: 3
Training loss: 0.4221166968345642
Validation loss: 1.5791633308574717

Epoch: 6| Step: 4
Training loss: 0.23230305314064026
Validation loss: 1.5672681575180383

Epoch: 6| Step: 5
Training loss: 0.2793024182319641
Validation loss: 1.5639987261064592

Epoch: 6| Step: 6
Training loss: 0.3769206404685974
Validation loss: 1.5318912588140017

Epoch: 6| Step: 7
Training loss: 0.29162028431892395
Validation loss: 1.5438924604846584

Epoch: 6| Step: 8
Training loss: 0.2578813135623932
Validation loss: 1.5462537952648696

Epoch: 6| Step: 9
Training loss: 0.13055428862571716
Validation loss: 1.5380215042380876

Epoch: 6| Step: 10
Training loss: 0.30915194749832153
Validation loss: 1.567678363092484

Epoch: 6| Step: 11
Training loss: 0.0774080902338028
Validation loss: 1.5380770532033776

Epoch: 6| Step: 12
Training loss: 0.18688273429870605
Validation loss: 1.5562591962916876

Epoch: 6| Step: 13
Training loss: 0.26324889063835144
Validation loss: 1.5434038151976883

Epoch: 330| Step: 0
Training loss: 0.1888110637664795
Validation loss: 1.5434378629089684

Epoch: 6| Step: 1
Training loss: 0.16041813790798187
Validation loss: 1.5518946211825135

Epoch: 6| Step: 2
Training loss: 0.14394724369049072
Validation loss: 1.5522811182083622

Epoch: 6| Step: 3
Training loss: 0.14386790990829468
Validation loss: 1.5651180846716768

Epoch: 6| Step: 4
Training loss: 0.2886827290058136
Validation loss: 1.59596219114078

Epoch: 6| Step: 5
Training loss: 0.32170939445495605
Validation loss: 1.6049472862674343

Epoch: 6| Step: 6
Training loss: 0.35418498516082764
Validation loss: 1.5631136842953262

Epoch: 6| Step: 7
Training loss: 0.22160187363624573
Validation loss: 1.5705402487067766

Epoch: 6| Step: 8
Training loss: 0.3163996934890747
Validation loss: 1.5678382778680453

Epoch: 6| Step: 9
Training loss: 0.23043346405029297
Validation loss: 1.5736999428400429

Epoch: 6| Step: 10
Training loss: 0.16479888558387756
Validation loss: 1.5572501638884186

Epoch: 6| Step: 11
Training loss: 0.2835324704647064
Validation loss: 1.582254643081337

Epoch: 6| Step: 12
Training loss: 0.3549763858318329
Validation loss: 1.5717586535279469

Epoch: 6| Step: 13
Training loss: 0.18270021677017212
Validation loss: 1.5497775411093107

Epoch: 331| Step: 0
Training loss: 0.1751631796360016
Validation loss: 1.5444814261569773

Epoch: 6| Step: 1
Training loss: 0.2590094208717346
Validation loss: 1.5293381855052004

Epoch: 6| Step: 2
Training loss: 0.25837862491607666
Validation loss: 1.5608917628565142

Epoch: 6| Step: 3
Training loss: 0.20567935705184937
Validation loss: 1.5482507674924788

Epoch: 6| Step: 4
Training loss: 0.20104071497917175
Validation loss: 1.5522230620025306

Epoch: 6| Step: 5
Training loss: 0.34371575713157654
Validation loss: 1.557119647661845

Epoch: 6| Step: 6
Training loss: 0.5628049373626709
Validation loss: 1.5499381429405623

Epoch: 6| Step: 7
Training loss: 0.21198542416095734
Validation loss: 1.546659488831797

Epoch: 6| Step: 8
Training loss: 0.2388954758644104
Validation loss: 1.5529139939174856

Epoch: 6| Step: 9
Training loss: 0.20304472744464874
Validation loss: 1.5563097384668165

Epoch: 6| Step: 10
Training loss: 0.3237449526786804
Validation loss: 1.538676982284874

Epoch: 6| Step: 11
Training loss: 0.17990067601203918
Validation loss: 1.5290765775147306

Epoch: 6| Step: 12
Training loss: 0.36035412549972534
Validation loss: 1.5341371079926849

Epoch: 6| Step: 13
Training loss: 0.11660594493150711
Validation loss: 1.5456205862824635

Epoch: 332| Step: 0
Training loss: 0.2503809332847595
Validation loss: 1.5491011283730949

Epoch: 6| Step: 1
Training loss: 0.18682077527046204
Validation loss: 1.5796125550423898

Epoch: 6| Step: 2
Training loss: 0.1667427122592926
Validation loss: 1.5607493039100402

Epoch: 6| Step: 3
Training loss: 0.2099766731262207
Validation loss: 1.57021895018957

Epoch: 6| Step: 4
Training loss: 0.17319034039974213
Validation loss: 1.5576253680772678

Epoch: 6| Step: 5
Training loss: 0.30493876338005066
Validation loss: 1.5539048897322787

Epoch: 6| Step: 6
Training loss: 0.18696627020835876
Validation loss: 1.5526647529294413

Epoch: 6| Step: 7
Training loss: 0.21112224459648132
Validation loss: 1.5529185914865105

Epoch: 6| Step: 8
Training loss: 0.47240763902664185
Validation loss: 1.5328559529396795

Epoch: 6| Step: 9
Training loss: 0.4186929166316986
Validation loss: 1.540458171598373

Epoch: 6| Step: 10
Training loss: 0.2281014323234558
Validation loss: 1.5386785640511462

Epoch: 6| Step: 11
Training loss: 0.15095621347427368
Validation loss: 1.5166957032295965

Epoch: 6| Step: 12
Training loss: 0.35848939418792725
Validation loss: 1.521319334224988

Epoch: 6| Step: 13
Training loss: 0.23365068435668945
Validation loss: 1.5170123154117214

Epoch: 333| Step: 0
Training loss: 0.11539965867996216
Validation loss: 1.5061270286959987

Epoch: 6| Step: 1
Training loss: 0.15377742052078247
Validation loss: 1.5182131669854606

Epoch: 6| Step: 2
Training loss: 0.18292975425720215
Validation loss: 1.5152882042751517

Epoch: 6| Step: 3
Training loss: 0.27485573291778564
Validation loss: 1.5282212918804539

Epoch: 6| Step: 4
Training loss: 0.17161774635314941
Validation loss: 1.5469299343324476

Epoch: 6| Step: 5
Training loss: 0.20534811913967133
Validation loss: 1.5302909599837435

Epoch: 6| Step: 6
Training loss: 0.33614373207092285
Validation loss: 1.5479932113360333

Epoch: 6| Step: 7
Training loss: 0.19199946522712708
Validation loss: 1.5274099470466695

Epoch: 6| Step: 8
Training loss: 0.25086265802383423
Validation loss: 1.529828312576458

Epoch: 6| Step: 9
Training loss: 0.17839182913303375
Validation loss: 1.5320505839522167

Epoch: 6| Step: 10
Training loss: 0.12166399508714676
Validation loss: 1.5381265173676193

Epoch: 6| Step: 11
Training loss: 0.21902328729629517
Validation loss: 1.540856081952331

Epoch: 6| Step: 12
Training loss: 0.47623777389526367
Validation loss: 1.527061794393806

Epoch: 6| Step: 13
Training loss: 0.16105307638645172
Validation loss: 1.5408163865407307

Epoch: 334| Step: 0
Training loss: 0.3100917637348175
Validation loss: 1.5387726573533909

Epoch: 6| Step: 1
Training loss: 0.22273597121238708
Validation loss: 1.5117665106250393

Epoch: 6| Step: 2
Training loss: 0.211643785238266
Validation loss: 1.5448784251366892

Epoch: 6| Step: 3
Training loss: 0.20969384908676147
Validation loss: 1.5502815028672576

Epoch: 6| Step: 4
Training loss: 0.3589216470718384
Validation loss: 1.540094267937445

Epoch: 6| Step: 5
Training loss: 0.1880611628293991
Validation loss: 1.5614302414719776

Epoch: 6| Step: 6
Training loss: 0.3004370331764221
Validation loss: 1.5404370074631066

Epoch: 6| Step: 7
Training loss: 0.2348114550113678
Validation loss: 1.5652079095122635

Epoch: 6| Step: 8
Training loss: 0.42083919048309326
Validation loss: 1.5656083347976848

Epoch: 6| Step: 9
Training loss: 0.1857866793870926
Validation loss: 1.5286153247279506

Epoch: 6| Step: 10
Training loss: 0.17614178359508514
Validation loss: 1.5357080095557756

Epoch: 6| Step: 11
Training loss: 0.21059909462928772
Validation loss: 1.536266114122124

Epoch: 6| Step: 12
Training loss: 0.3099396824836731
Validation loss: 1.5584904109278033

Epoch: 6| Step: 13
Training loss: 0.19167311489582062
Validation loss: 1.5682160674884755

Epoch: 335| Step: 0
Training loss: 0.26183760166168213
Validation loss: 1.562360090594138

Epoch: 6| Step: 1
Training loss: 0.26797759532928467
Validation loss: 1.585751912927115

Epoch: 6| Step: 2
Training loss: 0.4318147301673889
Validation loss: 1.5947101475090109

Epoch: 6| Step: 3
Training loss: 0.30139270424842834
Validation loss: 1.5624935396255986

Epoch: 6| Step: 4
Training loss: 0.15160781145095825
Validation loss: 1.5635664539952432

Epoch: 6| Step: 5
Training loss: 0.24589022994041443
Validation loss: 1.5341072851611721

Epoch: 6| Step: 6
Training loss: 0.20612698793411255
Validation loss: 1.5586228806485412

Epoch: 6| Step: 7
Training loss: 0.22725290060043335
Validation loss: 1.5618075606643513

Epoch: 6| Step: 8
Training loss: 0.24286919832229614
Validation loss: 1.5711256893732215

Epoch: 6| Step: 9
Training loss: 0.18707719445228577
Validation loss: 1.5416809346086235

Epoch: 6| Step: 10
Training loss: 0.24705752730369568
Validation loss: 1.5336546936342794

Epoch: 6| Step: 11
Training loss: 0.3076270818710327
Validation loss: 1.5414375476939703

Epoch: 6| Step: 12
Training loss: 0.11459879577159882
Validation loss: 1.549689228816699

Epoch: 6| Step: 13
Training loss: 0.132454052567482
Validation loss: 1.5368170507492558

Epoch: 336| Step: 0
Training loss: 0.3725625276565552
Validation loss: 1.545523073083611

Epoch: 6| Step: 1
Training loss: 0.29470890760421753
Validation loss: 1.5627948173912622

Epoch: 6| Step: 2
Training loss: 0.28698012232780457
Validation loss: 1.5381326226777927

Epoch: 6| Step: 3
Training loss: 0.19147253036499023
Validation loss: 1.53486664577197

Epoch: 6| Step: 4
Training loss: 0.11715062707662582
Validation loss: 1.5445668774266397

Epoch: 6| Step: 5
Training loss: 0.22192108631134033
Validation loss: 1.5663649074492916

Epoch: 6| Step: 6
Training loss: 0.3250470757484436
Validation loss: 1.5714431744749828

Epoch: 6| Step: 7
Training loss: 0.15046116709709167
Validation loss: 1.5529753751652215

Epoch: 6| Step: 8
Training loss: 0.1592133343219757
Validation loss: 1.5419926528007752

Epoch: 6| Step: 9
Training loss: 0.17979633808135986
Validation loss: 1.541151604344768

Epoch: 6| Step: 10
Training loss: 0.13954195380210876
Validation loss: 1.542760173479716

Epoch: 6| Step: 11
Training loss: 0.31308239698410034
Validation loss: 1.5600725822551276

Epoch: 6| Step: 12
Training loss: 0.2751466631889343
Validation loss: 1.523577586297066

Epoch: 6| Step: 13
Training loss: 0.09616293013095856
Validation loss: 1.5456411992349932

Epoch: 337| Step: 0
Training loss: 0.15268106758594513
Validation loss: 1.5135269459857736

Epoch: 6| Step: 1
Training loss: 0.19596534967422485
Validation loss: 1.532313741663451

Epoch: 6| Step: 2
Training loss: 0.2816199064254761
Validation loss: 1.540228747552441

Epoch: 6| Step: 3
Training loss: 0.3341856896877289
Validation loss: 1.5465729877512941

Epoch: 6| Step: 4
Training loss: 0.13202819228172302
Validation loss: 1.5194272059266285

Epoch: 6| Step: 5
Training loss: 0.17279687523841858
Validation loss: 1.5600665551359936

Epoch: 6| Step: 6
Training loss: 0.14786694943904877
Validation loss: 1.5338465206084713

Epoch: 6| Step: 7
Training loss: 0.2552259862422943
Validation loss: 1.5303818500170143

Epoch: 6| Step: 8
Training loss: 0.40210458636283875
Validation loss: 1.530525811256901

Epoch: 6| Step: 9
Training loss: 0.21650174260139465
Validation loss: 1.575149348987046

Epoch: 6| Step: 10
Training loss: 0.22682560980319977
Validation loss: 1.5095812877019246

Epoch: 6| Step: 11
Training loss: 0.20343062281608582
Validation loss: 1.5247882284143919

Epoch: 6| Step: 12
Training loss: 0.209168940782547
Validation loss: 1.5182690812695412

Epoch: 6| Step: 13
Training loss: 0.39682966470718384
Validation loss: 1.5404003538111204

Epoch: 338| Step: 0
Training loss: 0.39460262656211853
Validation loss: 1.546459178770742

Epoch: 6| Step: 1
Training loss: 0.10651268810033798
Validation loss: 1.5472622353543517

Epoch: 6| Step: 2
Training loss: 0.1674746572971344
Validation loss: 1.520172695959768

Epoch: 6| Step: 3
Training loss: 0.18140804767608643
Validation loss: 1.54661770789854

Epoch: 6| Step: 4
Training loss: 0.2686687707901001
Validation loss: 1.5576786738570019

Epoch: 6| Step: 5
Training loss: 0.23859494924545288
Validation loss: 1.5252953344775784

Epoch: 6| Step: 6
Training loss: 0.41503995656967163
Validation loss: 1.5448822949522285

Epoch: 6| Step: 7
Training loss: 0.12435208261013031
Validation loss: 1.537821819705348

Epoch: 6| Step: 8
Training loss: 0.10275451838970184
Validation loss: 1.5217153256939304

Epoch: 6| Step: 9
Training loss: 0.19162990152835846
Validation loss: 1.5570301086671892

Epoch: 6| Step: 10
Training loss: 0.26106879115104675
Validation loss: 1.5530856796490249

Epoch: 6| Step: 11
Training loss: 0.11289440840482712
Validation loss: 1.5314667968339817

Epoch: 6| Step: 12
Training loss: 0.15780341625213623
Validation loss: 1.5532729817974953

Epoch: 6| Step: 13
Training loss: 0.08128266781568527
Validation loss: 1.5569997231165569

Epoch: 339| Step: 0
Training loss: 0.18387946486473083
Validation loss: 1.5731931597955766

Epoch: 6| Step: 1
Training loss: 0.16027674078941345
Validation loss: 1.5610193764009783

Epoch: 6| Step: 2
Training loss: 0.1247434988617897
Validation loss: 1.5576466245035971

Epoch: 6| Step: 3
Training loss: 0.24216106534004211
Validation loss: 1.5567004654997139

Epoch: 6| Step: 4
Training loss: 0.16889525949954987
Validation loss: 1.5307435489469958

Epoch: 6| Step: 5
Training loss: 0.22466759383678436
Validation loss: 1.5555917575795164

Epoch: 6| Step: 6
Training loss: 0.2035672664642334
Validation loss: 1.5735309252174952

Epoch: 6| Step: 7
Training loss: 0.2260664850473404
Validation loss: 1.5573894734023719

Epoch: 6| Step: 8
Training loss: 0.39812368154525757
Validation loss: 1.551627573146615

Epoch: 6| Step: 9
Training loss: 0.2107519805431366
Validation loss: 1.5274875753669328

Epoch: 6| Step: 10
Training loss: 0.14110612869262695
Validation loss: 1.5511513140893751

Epoch: 6| Step: 11
Training loss: 0.26231691241264343
Validation loss: 1.5773560475277644

Epoch: 6| Step: 12
Training loss: 0.3493380546569824
Validation loss: 1.532100348703323

Epoch: 6| Step: 13
Training loss: 0.06181247532367706
Validation loss: 1.542192784688806

Epoch: 340| Step: 0
Training loss: 0.2164056897163391
Validation loss: 1.5443672749304003

Epoch: 6| Step: 1
Training loss: 0.2307911515235901
Validation loss: 1.5300665734916605

Epoch: 6| Step: 2
Training loss: 0.1660979688167572
Validation loss: 1.559770934043392

Epoch: 6| Step: 3
Training loss: 0.079274982213974
Validation loss: 1.5718619631182762

Epoch: 6| Step: 4
Training loss: 0.14132168889045715
Validation loss: 1.5483021223416893

Epoch: 6| Step: 5
Training loss: 0.3132765293121338
Validation loss: 1.5626410694532498

Epoch: 6| Step: 6
Training loss: 0.17213180661201477
Validation loss: 1.5502155698755735

Epoch: 6| Step: 7
Training loss: 0.4205639660358429
Validation loss: 1.5260890530001732

Epoch: 6| Step: 8
Training loss: 0.1800488829612732
Validation loss: 1.525062486689578

Epoch: 6| Step: 9
Training loss: 0.12085358053445816
Validation loss: 1.5237070398945962

Epoch: 6| Step: 10
Training loss: 0.3326885998249054
Validation loss: 1.501313014697003

Epoch: 6| Step: 11
Training loss: 0.13683941960334778
Validation loss: 1.5038614003889021

Epoch: 6| Step: 12
Training loss: 0.11855684220790863
Validation loss: 1.503337162797169

Epoch: 6| Step: 13
Training loss: 0.11275727301836014
Validation loss: 1.4950179464073592

Epoch: 341| Step: 0
Training loss: 0.5689917802810669
Validation loss: 1.4904924028663225

Epoch: 6| Step: 1
Training loss: 0.15088912844657898
Validation loss: 1.5245307991581578

Epoch: 6| Step: 2
Training loss: 0.08092106878757477
Validation loss: 1.4906334377104236

Epoch: 6| Step: 3
Training loss: 0.22930455207824707
Validation loss: 1.5090189031375352

Epoch: 6| Step: 4
Training loss: 0.15934248268604279
Validation loss: 1.519210107864872

Epoch: 6| Step: 5
Training loss: 0.1970408856868744
Validation loss: 1.5218734318210232

Epoch: 6| Step: 6
Training loss: 0.2621828019618988
Validation loss: 1.5323717619783135

Epoch: 6| Step: 7
Training loss: 0.1578419804573059
Validation loss: 1.52703724368926

Epoch: 6| Step: 8
Training loss: 0.11648425459861755
Validation loss: 1.5632767215851815

Epoch: 6| Step: 9
Training loss: 0.11760196089744568
Validation loss: 1.537865528496363

Epoch: 6| Step: 10
Training loss: 0.16133129596710205
Validation loss: 1.5200607545914189

Epoch: 6| Step: 11
Training loss: 0.1212528645992279
Validation loss: 1.5298297392424716

Epoch: 6| Step: 12
Training loss: 0.3414555788040161
Validation loss: 1.509411709282988

Epoch: 6| Step: 13
Training loss: 0.13019078969955444
Validation loss: 1.505148869688793

Epoch: 342| Step: 0
Training loss: 0.30893751978874207
Validation loss: 1.4876345806224371

Epoch: 6| Step: 1
Training loss: 0.17937099933624268
Validation loss: 1.4942387803908317

Epoch: 6| Step: 2
Training loss: 0.09585721045732498
Validation loss: 1.4865609535606958

Epoch: 6| Step: 3
Training loss: 0.19726429879665375
Validation loss: 1.4920210043589275

Epoch: 6| Step: 4
Training loss: 0.1704118549823761
Validation loss: 1.5314579445828673

Epoch: 6| Step: 5
Training loss: 0.215412899851799
Validation loss: 1.5034726742775208

Epoch: 6| Step: 6
Training loss: 0.2057935893535614
Validation loss: 1.512503259925432

Epoch: 6| Step: 7
Training loss: 0.48549938201904297
Validation loss: 1.5072931140981696

Epoch: 6| Step: 8
Training loss: 0.3486372232437134
Validation loss: 1.522293536893783

Epoch: 6| Step: 9
Training loss: 0.17544639110565186
Validation loss: 1.5327946396284207

Epoch: 6| Step: 10
Training loss: 0.2062162458896637
Validation loss: 1.5368773924407138

Epoch: 6| Step: 11
Training loss: 0.485046923160553
Validation loss: 1.5566746855294833

Epoch: 6| Step: 12
Training loss: 0.23215484619140625
Validation loss: 1.557626260224209

Epoch: 6| Step: 13
Training loss: 0.25675737857818604
Validation loss: 1.5739597402593142

Epoch: 343| Step: 0
Training loss: 0.17564445734024048
Validation loss: 1.5500066408547022

Epoch: 6| Step: 1
Training loss: 0.2407989650964737
Validation loss: 1.5661191683943554

Epoch: 6| Step: 2
Training loss: 0.19731223583221436
Validation loss: 1.5814693627818939

Epoch: 6| Step: 3
Training loss: 0.3235529363155365
Validation loss: 1.5667953311756093

Epoch: 6| Step: 4
Training loss: 0.24133145809173584
Validation loss: 1.5583471502027204

Epoch: 6| Step: 5
Training loss: 0.15453606843948364
Validation loss: 1.5759006033661545

Epoch: 6| Step: 6
Training loss: 0.135973259806633
Validation loss: 1.5499927523315593

Epoch: 6| Step: 7
Training loss: 0.27774301171302795
Validation loss: 1.539413757221673

Epoch: 6| Step: 8
Training loss: 0.26704514026641846
Validation loss: 1.5326412441909953

Epoch: 6| Step: 9
Training loss: 0.13561423122882843
Validation loss: 1.5240141396881433

Epoch: 6| Step: 10
Training loss: 0.1624264121055603
Validation loss: 1.5520662735867243

Epoch: 6| Step: 11
Training loss: 0.25405973196029663
Validation loss: 1.5331310956708846

Epoch: 6| Step: 12
Training loss: 0.569328248500824
Validation loss: 1.544502035264046

Epoch: 6| Step: 13
Training loss: 0.13714994490146637
Validation loss: 1.51718016593687

Epoch: 344| Step: 0
Training loss: 0.17131680250167847
Validation loss: 1.4926959519745202

Epoch: 6| Step: 1
Training loss: 0.11327195167541504
Validation loss: 1.5009809693982523

Epoch: 6| Step: 2
Training loss: 0.1436651200056076
Validation loss: 1.5117879208698068

Epoch: 6| Step: 3
Training loss: 0.11785407364368439
Validation loss: 1.506766193015601

Epoch: 6| Step: 4
Training loss: 0.23377513885498047
Validation loss: 1.4947803597296438

Epoch: 6| Step: 5
Training loss: 0.2151462435722351
Validation loss: 1.5126613763070875

Epoch: 6| Step: 6
Training loss: 0.21849656105041504
Validation loss: 1.5026929519509757

Epoch: 6| Step: 7
Training loss: 0.20497770607471466
Validation loss: 1.5085072453304003

Epoch: 6| Step: 8
Training loss: 0.16486646234989166
Validation loss: 1.4967568561594973

Epoch: 6| Step: 9
Training loss: 0.10840656608343124
Validation loss: 1.5226074200804516

Epoch: 6| Step: 10
Training loss: 0.6109961867332458
Validation loss: 1.536710185389365

Epoch: 6| Step: 11
Training loss: 0.12200096249580383
Validation loss: 1.543408820706029

Epoch: 6| Step: 12
Training loss: 0.38690540194511414
Validation loss: 1.5238584318468649

Epoch: 6| Step: 13
Training loss: 0.18459346890449524
Validation loss: 1.5596005134685065

Epoch: 345| Step: 0
Training loss: 0.19660824537277222
Validation loss: 1.5196655738738276

Epoch: 6| Step: 1
Training loss: 0.12904998660087585
Validation loss: 1.533311966926821

Epoch: 6| Step: 2
Training loss: 0.11138880252838135
Validation loss: 1.5004374045197681

Epoch: 6| Step: 3
Training loss: 0.1804218292236328
Validation loss: 1.5209215148802726

Epoch: 6| Step: 4
Training loss: 0.10859077423810959
Validation loss: 1.508117102807568

Epoch: 6| Step: 5
Training loss: 0.2542157769203186
Validation loss: 1.5234965790984452

Epoch: 6| Step: 6
Training loss: 0.15348099172115326
Validation loss: 1.5235491516769573

Epoch: 6| Step: 7
Training loss: 0.21990275382995605
Validation loss: 1.5493833852070633

Epoch: 6| Step: 8
Training loss: 0.1254441887140274
Validation loss: 1.5357944273179578

Epoch: 6| Step: 9
Training loss: 0.19315138459205627
Validation loss: 1.5375502019800165

Epoch: 6| Step: 10
Training loss: 0.27883338928222656
Validation loss: 1.5326177138154224

Epoch: 6| Step: 11
Training loss: 0.3766508102416992
Validation loss: 1.5587885168290907

Epoch: 6| Step: 12
Training loss: 0.49538326263427734
Validation loss: 1.5588787204475814

Epoch: 6| Step: 13
Training loss: 0.18300165235996246
Validation loss: 1.558005250910277

Epoch: 346| Step: 0
Training loss: 0.11474113911390305
Validation loss: 1.5809342386902019

Epoch: 6| Step: 1
Training loss: 0.17500901222229004
Validation loss: 1.5688636764403312

Epoch: 6| Step: 2
Training loss: 0.3823617100715637
Validation loss: 1.559540452495698

Epoch: 6| Step: 3
Training loss: 0.17572829127311707
Validation loss: 1.5594378645702074

Epoch: 6| Step: 4
Training loss: 0.5328476428985596
Validation loss: 1.5483413742434593

Epoch: 6| Step: 5
Training loss: 0.41912561655044556
Validation loss: 1.5310774426306448

Epoch: 6| Step: 6
Training loss: 0.14766186475753784
Validation loss: 1.5129589444847518

Epoch: 6| Step: 7
Training loss: 0.10332091152667999
Validation loss: 1.5312590983606154

Epoch: 6| Step: 8
Training loss: 0.16002844274044037
Validation loss: 1.5160590211550395

Epoch: 6| Step: 9
Training loss: 0.1669183373451233
Validation loss: 1.5265135547166229

Epoch: 6| Step: 10
Training loss: 0.18251186609268188
Validation loss: 1.5296865932403072

Epoch: 6| Step: 11
Training loss: 0.13768139481544495
Validation loss: 1.5472005285242552

Epoch: 6| Step: 12
Training loss: 0.30866938829421997
Validation loss: 1.512773989349283

Epoch: 6| Step: 13
Training loss: 0.19331683218479156
Validation loss: 1.523626653097009

Epoch: 347| Step: 0
Training loss: 0.1224474236369133
Validation loss: 1.5432048561752483

Epoch: 6| Step: 1
Training loss: 0.122750423848629
Validation loss: 1.526005257201451

Epoch: 6| Step: 2
Training loss: 0.10550644993782043
Validation loss: 1.5221387775995399

Epoch: 6| Step: 3
Training loss: 0.16353179514408112
Validation loss: 1.5296703128404514

Epoch: 6| Step: 4
Training loss: 0.2609782814979553
Validation loss: 1.5279521160228278

Epoch: 6| Step: 5
Training loss: 0.300586462020874
Validation loss: 1.552879387332547

Epoch: 6| Step: 6
Training loss: 0.10122324526309967
Validation loss: 1.5509122366546302

Epoch: 6| Step: 7
Training loss: 0.3636683523654938
Validation loss: 1.576328896707104

Epoch: 6| Step: 8
Training loss: 0.3740406930446625
Validation loss: 1.567621010606007

Epoch: 6| Step: 9
Training loss: 0.2578469514846802
Validation loss: 1.6081431373473136

Epoch: 6| Step: 10
Training loss: 0.27120697498321533
Validation loss: 1.5561082824583976

Epoch: 6| Step: 11
Training loss: 0.20537790656089783
Validation loss: 1.5687777675608152

Epoch: 6| Step: 12
Training loss: 0.3575986623764038
Validation loss: 1.566991288174865

Epoch: 6| Step: 13
Training loss: 0.19205160439014435
Validation loss: 1.5469467037467546

Epoch: 348| Step: 0
Training loss: 0.21321527659893036
Validation loss: 1.5361373219438779

Epoch: 6| Step: 1
Training loss: 0.18554896116256714
Validation loss: 1.5273862705435803

Epoch: 6| Step: 2
Training loss: 0.1683061569929123
Validation loss: 1.5364608264738513

Epoch: 6| Step: 3
Training loss: 0.2002982199192047
Validation loss: 1.5244124397154777

Epoch: 6| Step: 4
Training loss: 0.1745658814907074
Validation loss: 1.5381353888460385

Epoch: 6| Step: 5
Training loss: 0.28649014234542847
Validation loss: 1.5185082779135755

Epoch: 6| Step: 6
Training loss: 0.5224454998970032
Validation loss: 1.529819817312302

Epoch: 6| Step: 7
Training loss: 0.22156670689582825
Validation loss: 1.5520854932005688

Epoch: 6| Step: 8
Training loss: 0.21352386474609375
Validation loss: 1.5332398722248692

Epoch: 6| Step: 9
Training loss: 0.24195128679275513
Validation loss: 1.527157719417285

Epoch: 6| Step: 10
Training loss: 0.28552746772766113
Validation loss: 1.5289985954120595

Epoch: 6| Step: 11
Training loss: 0.11496151983737946
Validation loss: 1.507212108181369

Epoch: 6| Step: 12
Training loss: 0.14224788546562195
Validation loss: 1.517470129074589

Epoch: 6| Step: 13
Training loss: 0.17122849822044373
Validation loss: 1.5070428386811288

Epoch: 349| Step: 0
Training loss: 0.17852088809013367
Validation loss: 1.4869485285974318

Epoch: 6| Step: 1
Training loss: 0.19445139169692993
Validation loss: 1.5051899315208517

Epoch: 6| Step: 2
Training loss: 0.1361529529094696
Validation loss: 1.5021886389742616

Epoch: 6| Step: 3
Training loss: 0.15937426686286926
Validation loss: 1.4914770831343949

Epoch: 6| Step: 4
Training loss: 0.11020056158304214
Validation loss: 1.4416441885373925

Epoch: 6| Step: 5
Training loss: 0.20797330141067505
Validation loss: 1.4776119673123924

Epoch: 6| Step: 6
Training loss: 0.4731491804122925
Validation loss: 1.5160455165370819

Epoch: 6| Step: 7
Training loss: 0.13822880387306213
Validation loss: 1.5189787239156745

Epoch: 6| Step: 8
Training loss: 0.295343816280365
Validation loss: 1.5340503249117123

Epoch: 6| Step: 9
Training loss: 0.16855904459953308
Validation loss: 1.5107111802665136

Epoch: 6| Step: 10
Training loss: 0.36001813411712646
Validation loss: 1.5444887376600696

Epoch: 6| Step: 11
Training loss: 0.15619385242462158
Validation loss: 1.549744274026604

Epoch: 6| Step: 12
Training loss: 0.2257143259048462
Validation loss: 1.5200317290521437

Epoch: 6| Step: 13
Training loss: 0.2275955080986023
Validation loss: 1.5092295433885308

Epoch: 350| Step: 0
Training loss: 0.1285700500011444
Validation loss: 1.557374406886357

Epoch: 6| Step: 1
Training loss: 0.15589672327041626
Validation loss: 1.5583636850439093

Epoch: 6| Step: 2
Training loss: 0.20618759095668793
Validation loss: 1.544514097193236

Epoch: 6| Step: 3
Training loss: 0.1737978458404541
Validation loss: 1.5397090629864765

Epoch: 6| Step: 4
Training loss: 0.17449086904525757
Validation loss: 1.5348462712380193

Epoch: 6| Step: 5
Training loss: 0.22506868839263916
Validation loss: 1.5308859655933995

Epoch: 6| Step: 6
Training loss: 0.17006592452526093
Validation loss: 1.5446091480152582

Epoch: 6| Step: 7
Training loss: 0.15312042832374573
Validation loss: 1.5180012679869128

Epoch: 6| Step: 8
Training loss: 0.39867067337036133
Validation loss: 1.5329123735427856

Epoch: 6| Step: 9
Training loss: 0.21635200083255768
Validation loss: 1.5142258815867926

Epoch: 6| Step: 10
Training loss: 0.22555556893348694
Validation loss: 1.529178902667056

Epoch: 6| Step: 11
Training loss: 0.11129341274499893
Validation loss: 1.5333674466738136

Epoch: 6| Step: 12
Training loss: 0.3600727915763855
Validation loss: 1.5338617306883617

Epoch: 6| Step: 13
Training loss: 0.11350444704294205
Validation loss: 1.518898994051

Testing loss: 2.1698744773864744
