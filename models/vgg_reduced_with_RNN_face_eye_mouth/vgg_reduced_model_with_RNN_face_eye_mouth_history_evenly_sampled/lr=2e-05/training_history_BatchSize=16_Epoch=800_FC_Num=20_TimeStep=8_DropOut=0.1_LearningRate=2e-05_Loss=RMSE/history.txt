Epoch: 1| Step: 0
Training loss: 6.046685425302722
Validation loss: 5.767079821160552

Epoch: 6| Step: 1
Training loss: 6.538928615060828
Validation loss: 5.749778522151294

Epoch: 6| Step: 2
Training loss: 6.0183841075179805
Validation loss: 5.73202943338488

Epoch: 6| Step: 3
Training loss: 4.638707442297854
Validation loss: 5.711829955070333

Epoch: 6| Step: 4
Training loss: 6.7321314780893315
Validation loss: 5.688481030466599

Epoch: 6| Step: 5
Training loss: 5.545107621712761
Validation loss: 5.662632779788914

Epoch: 6| Step: 6
Training loss: 5.159461483614673
Validation loss: 5.632986402862963

Epoch: 6| Step: 7
Training loss: 5.497593613365736
Validation loss: 5.5990668829783266

Epoch: 6| Step: 8
Training loss: 4.980491727888171
Validation loss: 5.559877524754392

Epoch: 6| Step: 9
Training loss: 5.518027671122397
Validation loss: 5.514808839580446

Epoch: 6| Step: 10
Training loss: 5.956155160987482
Validation loss: 5.465641763450671

Epoch: 6| Step: 11
Training loss: 4.625406608234989
Validation loss: 5.40978316000963

Epoch: 6| Step: 12
Training loss: 6.341435052332336
Validation loss: 5.3466239933715505

Epoch: 6| Step: 13
Training loss: 4.082863813122342
Validation loss: 5.277859215718857

Epoch: 2| Step: 0
Training loss: 5.029542431808709
Validation loss: 5.204236103946584

Epoch: 6| Step: 1
Training loss: 4.3608448462926885
Validation loss: 5.122921373818141

Epoch: 6| Step: 2
Training loss: 4.842323536175986
Validation loss: 5.03601267030638

Epoch: 6| Step: 3
Training loss: 4.816784029436079
Validation loss: 4.943209457067311

Epoch: 6| Step: 4
Training loss: 5.111487089140613
Validation loss: 4.849280707206503

Epoch: 6| Step: 5
Training loss: 4.074135652391426
Validation loss: 4.751392542495694

Epoch: 6| Step: 6
Training loss: 5.147849343123502
Validation loss: 4.652837162845925

Epoch: 6| Step: 7
Training loss: 4.974966706591055
Validation loss: 4.551136742451131

Epoch: 6| Step: 8
Training loss: 4.478496247027963
Validation loss: 4.455165605189268

Epoch: 6| Step: 9
Training loss: 5.33081237499432
Validation loss: 4.365550772038773

Epoch: 6| Step: 10
Training loss: 4.679173105336779
Validation loss: 4.275897495828582

Epoch: 6| Step: 11
Training loss: 3.2163889104539294
Validation loss: 4.196596289382966

Epoch: 6| Step: 12
Training loss: 5.5602570201280095
Validation loss: 4.122142164731057

Epoch: 6| Step: 13
Training loss: 2.818456572761973
Validation loss: 4.0597731785457745

Epoch: 3| Step: 0
Training loss: 4.091902687325184
Validation loss: 4.0073872181287475

Epoch: 6| Step: 1
Training loss: 4.209877008014298
Validation loss: 3.9566236204888567

Epoch: 6| Step: 2
Training loss: 3.273242006860115
Validation loss: 3.9139091604612464

Epoch: 6| Step: 3
Training loss: 3.113350325408026
Validation loss: 3.874152655551031

Epoch: 6| Step: 4
Training loss: 4.884286886776204
Validation loss: 3.8452884474228997

Epoch: 6| Step: 5
Training loss: 3.2289611915106287
Validation loss: 3.815089834387157

Epoch: 6| Step: 6
Training loss: 4.390995973818451
Validation loss: 3.791989306101516

Epoch: 6| Step: 7
Training loss: 3.444149314036122
Validation loss: 3.765821798039001

Epoch: 6| Step: 8
Training loss: 3.8318341405728114
Validation loss: 3.7431057604409244

Epoch: 6| Step: 9
Training loss: 3.5995876499954824
Validation loss: 3.7180853898075528

Epoch: 6| Step: 10
Training loss: 4.508783457361959
Validation loss: 3.69785673285581

Epoch: 6| Step: 11
Training loss: 4.408154664388038
Validation loss: 3.673704766549301

Epoch: 6| Step: 12
Training loss: 3.6148302211965877
Validation loss: 3.6545450550914946

Epoch: 6| Step: 13
Training loss: 4.6840245905360165
Validation loss: 3.6335026927250813

Epoch: 4| Step: 0
Training loss: 3.782958598350759
Validation loss: 3.614030318679097

Epoch: 6| Step: 1
Training loss: 4.194903760494924
Validation loss: 3.5980102867948847

Epoch: 6| Step: 2
Training loss: 3.0121924278930536
Validation loss: 3.5784177315155583

Epoch: 6| Step: 3
Training loss: 4.602470580363902
Validation loss: 3.5562456024948395

Epoch: 6| Step: 4
Training loss: 4.234077471313091
Validation loss: 3.5377557929089467

Epoch: 6| Step: 5
Training loss: 3.3383467325242258
Validation loss: 3.516648176601758

Epoch: 6| Step: 6
Training loss: 3.0066373833233304
Validation loss: 3.498631589267924

Epoch: 6| Step: 7
Training loss: 3.6754431736299513
Validation loss: 3.483249007994878

Epoch: 6| Step: 8
Training loss: 3.7954186680260436
Validation loss: 3.470202025947357

Epoch: 6| Step: 9
Training loss: 3.9421409020559626
Validation loss: 3.4492181494518865

Epoch: 6| Step: 10
Training loss: 3.72240979558663
Validation loss: 3.4310124964405344

Epoch: 6| Step: 11
Training loss: 4.051592694989079
Validation loss: 3.4236478896682643

Epoch: 6| Step: 12
Training loss: 3.2298714801741544
Validation loss: 3.4022587127831625

Epoch: 6| Step: 13
Training loss: 2.3953910640565486
Validation loss: 3.390381293689331

Epoch: 5| Step: 0
Training loss: 4.085313796804277
Validation loss: 3.380218476012703

Epoch: 6| Step: 1
Training loss: 4.2481227543510505
Validation loss: 3.3660069358867846

Epoch: 6| Step: 2
Training loss: 3.764087030529565
Validation loss: 3.35254478540726

Epoch: 6| Step: 3
Training loss: 4.026134468512561
Validation loss: 3.3309808110204595

Epoch: 6| Step: 4
Training loss: 3.5647586555699586
Validation loss: 3.3154786289308387

Epoch: 6| Step: 5
Training loss: 3.822830213076785
Validation loss: 3.2990294190419216

Epoch: 6| Step: 6
Training loss: 3.211141835043358
Validation loss: 3.2887265860521455

Epoch: 6| Step: 7
Training loss: 2.726432906516827
Validation loss: 3.2724779967389144

Epoch: 6| Step: 8
Training loss: 2.370685875390367
Validation loss: 3.258687916833494

Epoch: 6| Step: 9
Training loss: 3.5840439794089987
Validation loss: 3.246007982321916

Epoch: 6| Step: 10
Training loss: 3.6611558654498944
Validation loss: 3.2374456357602206

Epoch: 6| Step: 11
Training loss: 3.556288809137152
Validation loss: 3.2238690888436357

Epoch: 6| Step: 12
Training loss: 3.0647588690391294
Validation loss: 3.214035543227358

Epoch: 6| Step: 13
Training loss: 3.2612011892892294
Validation loss: 3.2042925235802517

Epoch: 6| Step: 0
Training loss: 3.7433629111267606
Validation loss: 3.197152638145815

Epoch: 6| Step: 1
Training loss: 3.206330867587793
Validation loss: 3.189357759081466

Epoch: 6| Step: 2
Training loss: 2.4892049419404896
Validation loss: 3.181468368060478

Epoch: 6| Step: 3
Training loss: 3.463133242435006
Validation loss: 3.176146348552755

Epoch: 6| Step: 4
Training loss: 3.830936069290662
Validation loss: 3.168144754371714

Epoch: 6| Step: 5
Training loss: 3.6704097340299247
Validation loss: 3.159610272539512

Epoch: 6| Step: 6
Training loss: 4.093487214251706
Validation loss: 3.147376497671287

Epoch: 6| Step: 7
Training loss: 3.146243104498987
Validation loss: 3.1411175362800496

Epoch: 6| Step: 8
Training loss: 3.3215322610166114
Validation loss: 3.1333790971699353

Epoch: 6| Step: 9
Training loss: 3.6258308510818233
Validation loss: 3.125101123937431

Epoch: 6| Step: 10
Training loss: 3.844161593102173
Validation loss: 3.115864688960039

Epoch: 6| Step: 11
Training loss: 3.0645636009205153
Validation loss: 3.1111304368118615

Epoch: 6| Step: 12
Training loss: 3.2828493126208214
Validation loss: 3.103839751066251

Epoch: 6| Step: 13
Training loss: 1.878724975723847
Validation loss: 3.0979605608817025

Epoch: 7| Step: 0
Training loss: 3.4785071259897578
Validation loss: 3.0937594830734443

Epoch: 6| Step: 1
Training loss: 3.059441109275197
Validation loss: 3.0876054556552432

Epoch: 6| Step: 2
Training loss: 3.9397893638268586
Validation loss: 3.0795502595249316

Epoch: 6| Step: 3
Training loss: 3.5186511769485627
Validation loss: 3.072270581606931

Epoch: 6| Step: 4
Training loss: 3.1573864996317194
Validation loss: 3.0668826709512125

Epoch: 6| Step: 5
Training loss: 2.8374876719471662
Validation loss: 3.05607097084681

Epoch: 6| Step: 6
Training loss: 2.5630743732117387
Validation loss: 3.0556117415894617

Epoch: 6| Step: 7
Training loss: 3.47461321757095
Validation loss: 3.090879356236208

Epoch: 6| Step: 8
Training loss: 3.932689089197116
Validation loss: 3.048574945538341

Epoch: 6| Step: 9
Training loss: 3.5242701052097436
Validation loss: 3.0517474798212176

Epoch: 6| Step: 10
Training loss: 4.030307866682661
Validation loss: 3.05011060047859

Epoch: 6| Step: 11
Training loss: 3.132888907169082
Validation loss: 3.0381860787100208

Epoch: 6| Step: 12
Training loss: 3.0423478361020724
Validation loss: 3.0338320385603326

Epoch: 6| Step: 13
Training loss: 2.300640315611375
Validation loss: 3.02952761018727

Epoch: 8| Step: 0
Training loss: 2.827907069118617
Validation loss: 3.025605943820455

Epoch: 6| Step: 1
Training loss: 3.6413824906031356
Validation loss: 3.026443208835587

Epoch: 6| Step: 2
Training loss: 3.121124916732685
Validation loss: 3.025689223549443

Epoch: 6| Step: 3
Training loss: 3.389350053715475
Validation loss: 3.022736023928839

Epoch: 6| Step: 4
Training loss: 3.623291402209757
Validation loss: 3.0150727749310082

Epoch: 6| Step: 5
Training loss: 3.3626037695092434
Validation loss: 3.007667773903607

Epoch: 6| Step: 6
Training loss: 4.154819557871519
Validation loss: 3.0045032772827605

Epoch: 6| Step: 7
Training loss: 2.6185388520909267
Validation loss: 2.9991039182072337

Epoch: 6| Step: 8
Training loss: 3.8663716390019864
Validation loss: 2.9939043985086133

Epoch: 6| Step: 9
Training loss: 3.651214000572757
Validation loss: 2.992284564526911

Epoch: 6| Step: 10
Training loss: 2.918294579469913
Validation loss: 2.9871938413929464

Epoch: 6| Step: 11
Training loss: 3.5284381575427965
Validation loss: 2.9836286279268087

Epoch: 6| Step: 12
Training loss: 2.0610850711535966
Validation loss: 2.9798727901811692

Epoch: 6| Step: 13
Training loss: 2.529534971599797
Validation loss: 2.9792227165743177

Epoch: 9| Step: 0
Training loss: 4.338678047201201
Validation loss: 2.9784392152772883

Epoch: 6| Step: 1
Training loss: 3.3670110457136917
Validation loss: 2.971133369409283

Epoch: 6| Step: 2
Training loss: 3.231101328161449
Validation loss: 2.960129083785962

Epoch: 6| Step: 3
Training loss: 2.604578601045835
Validation loss: 2.955948592210459

Epoch: 6| Step: 4
Training loss: 3.328100499882312
Validation loss: 2.9495279472900884

Epoch: 6| Step: 5
Training loss: 2.9458441216587357
Validation loss: 2.946021770508492

Epoch: 6| Step: 6
Training loss: 2.9146731148544047
Validation loss: 2.9419629055160885

Epoch: 6| Step: 7
Training loss: 2.571614037364789
Validation loss: 2.9386086135975233

Epoch: 6| Step: 8
Training loss: 3.197658134886752
Validation loss: 2.9326387762148065

Epoch: 6| Step: 9
Training loss: 3.537526182475434
Validation loss: 2.9288497608673247

Epoch: 6| Step: 10
Training loss: 3.436472375029134
Validation loss: 2.9256957888431665

Epoch: 6| Step: 11
Training loss: 3.058959159605881
Validation loss: 2.9194819269123964

Epoch: 6| Step: 12
Training loss: 3.5802065196220916
Validation loss: 2.917854434345303

Epoch: 6| Step: 13
Training loss: 2.953080757253737
Validation loss: 2.909864301697215

Epoch: 10| Step: 0
Training loss: 3.0927890094236177
Validation loss: 2.9121535676338732

Epoch: 6| Step: 1
Training loss: 2.8868208313522166
Validation loss: 2.912501724033514

Epoch: 6| Step: 2
Training loss: 2.970972774990765
Validation loss: 2.900807151801305

Epoch: 6| Step: 3
Training loss: 3.5790907710018076
Validation loss: 2.922230802663494

Epoch: 6| Step: 4
Training loss: 2.9953446825792946
Validation loss: 2.8867221033926422

Epoch: 6| Step: 5
Training loss: 3.6783309995513918
Validation loss: 2.8854528395018444

Epoch: 6| Step: 6
Training loss: 3.3817444275898727
Validation loss: 2.8824647438633857

Epoch: 6| Step: 7
Training loss: 2.6340329202667205
Validation loss: 2.8845009543327116

Epoch: 6| Step: 8
Training loss: 3.791480985573427
Validation loss: 2.8761372717759475

Epoch: 6| Step: 9
Training loss: 3.1173205813344773
Validation loss: 2.873798119140876

Epoch: 6| Step: 10
Training loss: 3.0062127949718302
Validation loss: 2.8702920206869016

Epoch: 6| Step: 11
Training loss: 3.0153425805861427
Validation loss: 2.8668107332352295

Epoch: 6| Step: 12
Training loss: 3.1027863439678662
Validation loss: 2.8637056057931662

Epoch: 6| Step: 13
Training loss: 3.7511100397691006
Validation loss: 2.8611797480904575

Epoch: 11| Step: 0
Training loss: 2.832517805725319
Validation loss: 2.861908841039109

Epoch: 6| Step: 1
Training loss: 2.9026161363812237
Validation loss: 2.862082640367623

Epoch: 6| Step: 2
Training loss: 3.4021520199278603
Validation loss: 2.866195592524548

Epoch: 6| Step: 3
Training loss: 3.2692465527183687
Validation loss: 2.8573323361681666

Epoch: 6| Step: 4
Training loss: 3.700931333913436
Validation loss: 2.8613604923321376

Epoch: 6| Step: 5
Training loss: 3.391853637290642
Validation loss: 2.8467640302420247

Epoch: 6| Step: 6
Training loss: 2.892876155730241
Validation loss: 2.8444663859084254

Epoch: 6| Step: 7
Training loss: 3.0868471760489293
Validation loss: 2.8484832504933078

Epoch: 6| Step: 8
Training loss: 2.8389048119496776
Validation loss: 2.8490478827897547

Epoch: 6| Step: 9
Training loss: 3.6630349090853915
Validation loss: 2.844241497698669

Epoch: 6| Step: 10
Training loss: 3.3928575329314272
Validation loss: 2.8386461635899694

Epoch: 6| Step: 11
Training loss: 3.8404175493597275
Validation loss: 2.829079789017192

Epoch: 6| Step: 12
Training loss: 2.471587566345569
Validation loss: 2.8329265406210387

Epoch: 6| Step: 13
Training loss: 1.843844847744935
Validation loss: 2.8381693145452154

Epoch: 12| Step: 0
Training loss: 3.2911396489983504
Validation loss: 2.8674963179334365

Epoch: 6| Step: 1
Training loss: 3.121599712587282
Validation loss: 2.868055271937019

Epoch: 6| Step: 2
Training loss: 2.668296514571207
Validation loss: 2.8485912270872933

Epoch: 6| Step: 3
Training loss: 2.907444534100706
Validation loss: 2.8196671602337045

Epoch: 6| Step: 4
Training loss: 3.5951910695537617
Validation loss: 2.815371355899276

Epoch: 6| Step: 5
Training loss: 2.870248932360366
Validation loss: 2.8102215205012966

Epoch: 6| Step: 6
Training loss: 3.8426033108386
Validation loss: 2.8124104110686905

Epoch: 6| Step: 7
Training loss: 2.5866945201645697
Validation loss: 2.80541685635971

Epoch: 6| Step: 8
Training loss: 2.633340573200301
Validation loss: 2.7948565642394705

Epoch: 6| Step: 9
Training loss: 3.1809172630547016
Validation loss: 2.793462502294842

Epoch: 6| Step: 10
Training loss: 3.328366839438089
Validation loss: 2.7882552359273993

Epoch: 6| Step: 11
Training loss: 3.2504584649305657
Validation loss: 2.795321715806594

Epoch: 6| Step: 12
Training loss: 3.390327827333875
Validation loss: 2.7953064934359855

Epoch: 6| Step: 13
Training loss: 3.298239330733944
Validation loss: 2.79392053157484

Epoch: 13| Step: 0
Training loss: 3.6967811811188147
Validation loss: 2.7969545119457013

Epoch: 6| Step: 1
Training loss: 3.0826842337914067
Validation loss: 2.7966085565874175

Epoch: 6| Step: 2
Training loss: 2.4742946891345015
Validation loss: 2.7989094362454825

Epoch: 6| Step: 3
Training loss: 3.300531321436623
Validation loss: 2.7954029896467802

Epoch: 6| Step: 4
Training loss: 3.470870048875238
Validation loss: 2.8124508123073113

Epoch: 6| Step: 5
Training loss: 2.807666015200415
Validation loss: 2.7842795544295207

Epoch: 6| Step: 6
Training loss: 2.7012202437146273
Validation loss: 2.823620688472262

Epoch: 6| Step: 7
Training loss: 2.7226791928171616
Validation loss: 2.833616746219228

Epoch: 6| Step: 8
Training loss: 3.1668364997964247
Validation loss: 2.8404077602676825

Epoch: 6| Step: 9
Training loss: 3.3108311893953233
Validation loss: 2.8253314395626163

Epoch: 6| Step: 10
Training loss: 3.0955099629208096
Validation loss: 2.8171271832436537

Epoch: 6| Step: 11
Training loss: 3.5972758370572553
Validation loss: 2.8178850265297988

Epoch: 6| Step: 12
Training loss: 3.2126469203735026
Validation loss: 2.8079838607206127

Epoch: 6| Step: 13
Training loss: 3.3484221998782795
Validation loss: 2.7900522948958257

Epoch: 14| Step: 0
Training loss: 2.810659611755845
Validation loss: 2.7932239156893646

Epoch: 6| Step: 1
Training loss: 3.337747480382219
Validation loss: 2.907189414856683

Epoch: 6| Step: 2
Training loss: 2.9920600087068983
Validation loss: 2.8148561022517864

Epoch: 6| Step: 3
Training loss: 2.800941877667063
Validation loss: 2.775969585044745

Epoch: 6| Step: 4
Training loss: 2.7283642780814903
Validation loss: 2.7510238505300406

Epoch: 6| Step: 5
Training loss: 3.214013030580646
Validation loss: 2.7489246454768734

Epoch: 6| Step: 6
Training loss: 2.976859170542039
Validation loss: 2.7621919813904117

Epoch: 6| Step: 7
Training loss: 3.132559216693876
Validation loss: 2.7781027509106915

Epoch: 6| Step: 8
Training loss: 3.4667358049198502
Validation loss: 2.764309952782559

Epoch: 6| Step: 9
Training loss: 3.1014444247046002
Validation loss: 2.749026656709473

Epoch: 6| Step: 10
Training loss: 3.336824178671276
Validation loss: 2.7461845501849664

Epoch: 6| Step: 11
Training loss: 2.774195092115667
Validation loss: 2.753032289706985

Epoch: 6| Step: 12
Training loss: 3.6431704287625983
Validation loss: 2.7609689325309854

Epoch: 6| Step: 13
Training loss: 3.258907435996242
Validation loss: 2.7744193728928614

Epoch: 15| Step: 0
Training loss: 2.1940858067691473
Validation loss: 2.7914895304678526

Epoch: 6| Step: 1
Training loss: 3.615644813951489
Validation loss: 2.80036266185929

Epoch: 6| Step: 2
Training loss: 3.4792401578226335
Validation loss: 2.7679472690329807

Epoch: 6| Step: 3
Training loss: 3.017784807849025
Validation loss: 2.760221838891139

Epoch: 6| Step: 4
Training loss: 2.879345802074632
Validation loss: 2.7540946598688856

Epoch: 6| Step: 5
Training loss: 3.925231955896718
Validation loss: 2.7512162782608702

Epoch: 6| Step: 6
Training loss: 3.079239696691405
Validation loss: 2.7533104511468096

Epoch: 6| Step: 7
Training loss: 3.061105838993407
Validation loss: 2.7635506879087224

Epoch: 6| Step: 8
Training loss: 3.244660613146903
Validation loss: 2.756046417920002

Epoch: 6| Step: 9
Training loss: 2.809258182120945
Validation loss: 2.740248305382154

Epoch: 6| Step: 10
Training loss: 2.4721681134116342
Validation loss: 2.7356877357970655

Epoch: 6| Step: 11
Training loss: 2.8086591986191625
Validation loss: 2.7399764854820963

Epoch: 6| Step: 12
Training loss: 3.12635026370599
Validation loss: 2.7957200716790993

Epoch: 6| Step: 13
Training loss: 3.8119029844013337
Validation loss: 2.842611395716409

Epoch: 16| Step: 0
Training loss: 2.107192994876708
Validation loss: 2.78569707690878

Epoch: 6| Step: 1
Training loss: 2.6461661622574586
Validation loss: 2.7439604466107066

Epoch: 6| Step: 2
Training loss: 3.3210797309803946
Validation loss: 2.7240190359026317

Epoch: 6| Step: 3
Training loss: 3.1850762221289908
Validation loss: 2.730625074467886

Epoch: 6| Step: 4
Training loss: 3.1099362274205955
Validation loss: 2.7357679868556035

Epoch: 6| Step: 5
Training loss: 3.329718696236866
Validation loss: 2.7348523132657467

Epoch: 6| Step: 6
Training loss: 2.3092267351472544
Validation loss: 2.7356850875226124

Epoch: 6| Step: 7
Training loss: 2.991432034811502
Validation loss: 2.731287530371008

Epoch: 6| Step: 8
Training loss: 3.3478989574357256
Validation loss: 2.7345452443462035

Epoch: 6| Step: 9
Training loss: 3.8254871232755026
Validation loss: 2.7334168548814066

Epoch: 6| Step: 10
Training loss: 3.173435973369432
Validation loss: 2.7322200242118355

Epoch: 6| Step: 11
Training loss: 3.1809806724711884
Validation loss: 2.72865074639924

Epoch: 6| Step: 12
Training loss: 2.894189235234231
Validation loss: 2.726078045765483

Epoch: 6| Step: 13
Training loss: 3.685877297472932
Validation loss: 2.726875949797113

Epoch: 17| Step: 0
Training loss: 3.252378033895539
Validation loss: 2.7308418589036165

Epoch: 6| Step: 1
Training loss: 2.0730234498806044
Validation loss: 2.735899997996063

Epoch: 6| Step: 2
Training loss: 2.6361908108617578
Validation loss: 2.738171488814109

Epoch: 6| Step: 3
Training loss: 2.951738627536823
Validation loss: 2.7261471173226566

Epoch: 6| Step: 4
Training loss: 2.7282523353809256
Validation loss: 2.7244149475554242

Epoch: 6| Step: 5
Training loss: 3.0255750251461433
Validation loss: 2.726274111170855

Epoch: 6| Step: 6
Training loss: 3.838877497164037
Validation loss: 2.730859618553697

Epoch: 6| Step: 7
Training loss: 3.1671690960553103
Validation loss: 2.724532207140575

Epoch: 6| Step: 8
Training loss: 2.987105633232095
Validation loss: 2.7272869031276064

Epoch: 6| Step: 9
Training loss: 3.0501541098761127
Validation loss: 2.7342001741601445

Epoch: 6| Step: 10
Training loss: 3.377688996782323
Validation loss: 2.7397708130738527

Epoch: 6| Step: 11
Training loss: 3.1169363126199277
Validation loss: 2.7501785084277466

Epoch: 6| Step: 12
Training loss: 3.332139437172425
Validation loss: 2.7553396897137694

Epoch: 6| Step: 13
Training loss: 3.4118321027153637
Validation loss: 2.7678840689202153

Epoch: 18| Step: 0
Training loss: 2.7330544034789153
Validation loss: 2.772317007240252

Epoch: 6| Step: 1
Training loss: 2.424114447073105
Validation loss: 2.769524663930675

Epoch: 6| Step: 2
Training loss: 3.391144321593448
Validation loss: 2.773790983152683

Epoch: 6| Step: 3
Training loss: 3.6918260446650764
Validation loss: 2.7748880787452994

Epoch: 6| Step: 4
Training loss: 2.7155071518308116
Validation loss: 2.7699826810129595

Epoch: 6| Step: 5
Training loss: 3.212746957274197
Validation loss: 2.7663413204038187

Epoch: 6| Step: 6
Training loss: 2.231322223765983
Validation loss: 2.7624512789465876

Epoch: 6| Step: 7
Training loss: 3.436206366136037
Validation loss: 2.759395071499308

Epoch: 6| Step: 8
Training loss: 3.4337937228457225
Validation loss: 2.7613538581740054

Epoch: 6| Step: 9
Training loss: 3.8749987694522994
Validation loss: 2.7678212897255086

Epoch: 6| Step: 10
Training loss: 3.326556485351171
Validation loss: 2.760923704425361

Epoch: 6| Step: 11
Training loss: 3.030918535809785
Validation loss: 2.7478737409285077

Epoch: 6| Step: 12
Training loss: 2.753973604284933
Validation loss: 2.73041028774632

Epoch: 6| Step: 13
Training loss: 2.1146477249438855
Validation loss: 2.7237925900904307

Epoch: 19| Step: 0
Training loss: 3.2098529404083065
Validation loss: 2.736838845841248

Epoch: 6| Step: 1
Training loss: 3.33407619463852
Validation loss: 2.7403623110639974

Epoch: 6| Step: 2
Training loss: 2.873871291472736
Validation loss: 2.7278122345374283

Epoch: 6| Step: 3
Training loss: 2.9310439568109197
Validation loss: 2.7146590206518373

Epoch: 6| Step: 4
Training loss: 3.174453964738371
Validation loss: 2.7016394067626535

Epoch: 6| Step: 5
Training loss: 2.876577690784764
Validation loss: 2.693485999734225

Epoch: 6| Step: 6
Training loss: 2.9966626677806456
Validation loss: 2.6945026833167764

Epoch: 6| Step: 7
Training loss: 2.8431325388850572
Validation loss: 2.700141181277858

Epoch: 6| Step: 8
Training loss: 2.80964710924869
Validation loss: 2.7087051010232392

Epoch: 6| Step: 9
Training loss: 2.958558911243585
Validation loss: 2.7207380641977084

Epoch: 6| Step: 10
Training loss: 2.755082029585706
Validation loss: 2.7516602848764284

Epoch: 6| Step: 11
Training loss: 3.248218194660653
Validation loss: 2.7473473456790587

Epoch: 6| Step: 12
Training loss: 3.0664665847965518
Validation loss: 2.7186450412298346

Epoch: 6| Step: 13
Training loss: 4.184562905660014
Validation loss: 2.7161092043788586

Epoch: 20| Step: 0
Training loss: 2.561237303226216
Validation loss: 2.710809139862999

Epoch: 6| Step: 1
Training loss: 3.160456809331895
Validation loss: 2.7170224998596533

Epoch: 6| Step: 2
Training loss: 3.0752629175444377
Validation loss: 2.712924237904129

Epoch: 6| Step: 3
Training loss: 3.028450371078491
Validation loss: 2.711391084655626

Epoch: 6| Step: 4
Training loss: 3.3152553686684323
Validation loss: 2.7044909552424046

Epoch: 6| Step: 5
Training loss: 3.0436157008940867
Validation loss: 2.6947740775269526

Epoch: 6| Step: 6
Training loss: 3.334259397295686
Validation loss: 2.6922623577276688

Epoch: 6| Step: 7
Training loss: 2.1782940748316175
Validation loss: 2.6988661053550023

Epoch: 6| Step: 8
Training loss: 3.0113295564636955
Validation loss: 2.696065859784774

Epoch: 6| Step: 9
Training loss: 3.670184976141426
Validation loss: 2.697395038306229

Epoch: 6| Step: 10
Training loss: 3.1664020695483446
Validation loss: 2.7022332935139284

Epoch: 6| Step: 11
Training loss: 2.935651644057303
Validation loss: 2.703755329119186

Epoch: 6| Step: 12
Training loss: 3.0086627501581917
Validation loss: 2.6955055047630987

Epoch: 6| Step: 13
Training loss: 2.739846297916373
Validation loss: 2.7016218051815777

Epoch: 21| Step: 0
Training loss: 3.427905756043251
Validation loss: 2.6889710498554824

Epoch: 6| Step: 1
Training loss: 2.849845306481393
Validation loss: 2.6881655188348006

Epoch: 6| Step: 2
Training loss: 2.6623269074101636
Validation loss: 2.6905802450104357

Epoch: 6| Step: 3
Training loss: 3.7936431568064073
Validation loss: 2.6914431697439065

Epoch: 6| Step: 4
Training loss: 3.087623927297244
Validation loss: 2.6915299491508327

Epoch: 6| Step: 5
Training loss: 2.7191046121780187
Validation loss: 2.690044105112708

Epoch: 6| Step: 6
Training loss: 2.828192525658167
Validation loss: 2.6886818269732964

Epoch: 6| Step: 7
Training loss: 2.847065093710916
Validation loss: 2.682321365308317

Epoch: 6| Step: 8
Training loss: 2.6025639802981617
Validation loss: 2.687272512695701

Epoch: 6| Step: 9
Training loss: 3.19732289388234
Validation loss: 2.6817327165304503

Epoch: 6| Step: 10
Training loss: 3.2980318616041675
Validation loss: 2.6918548001127314

Epoch: 6| Step: 11
Training loss: 3.0036047894591937
Validation loss: 2.7033903594051525

Epoch: 6| Step: 12
Training loss: 2.5799467181832556
Validation loss: 2.73687667766409

Epoch: 6| Step: 13
Training loss: 3.585538023262306
Validation loss: 2.7567861155828046

Epoch: 22| Step: 0
Training loss: 3.182702137415283
Validation loss: 2.803453490970294

Epoch: 6| Step: 1
Training loss: 3.4304222067288537
Validation loss: 2.8010308550099645

Epoch: 6| Step: 2
Training loss: 2.9586333718176383
Validation loss: 2.7572664611946927

Epoch: 6| Step: 3
Training loss: 2.946457860231356
Validation loss: 2.7061281353125874

Epoch: 6| Step: 4
Training loss: 3.0693809901641016
Validation loss: 2.686249833538812

Epoch: 6| Step: 5
Training loss: 3.062041112034512
Validation loss: 2.705088794344109

Epoch: 6| Step: 6
Training loss: 2.424531328983432
Validation loss: 2.731456041222416

Epoch: 6| Step: 7
Training loss: 3.6220510918875304
Validation loss: 2.75620646788954

Epoch: 6| Step: 8
Training loss: 2.7858439876418464
Validation loss: 2.752052544222881

Epoch: 6| Step: 9
Training loss: 3.0366143022440735
Validation loss: 2.7539532214885996

Epoch: 6| Step: 10
Training loss: 2.981338634013114
Validation loss: 2.7081217762850995

Epoch: 6| Step: 11
Training loss: 2.817666627548231
Validation loss: 2.6942677355521036

Epoch: 6| Step: 12
Training loss: 3.792812481694985
Validation loss: 2.6809031075784433

Epoch: 6| Step: 13
Training loss: 2.793836082822008
Validation loss: 2.6777917949082877

Epoch: 23| Step: 0
Training loss: 3.1617738334847556
Validation loss: 2.675114534264686

Epoch: 6| Step: 1
Training loss: 3.227973389365782
Validation loss: 2.6752270617992133

Epoch: 6| Step: 2
Training loss: 2.8608294680671422
Validation loss: 2.7052555975946406

Epoch: 6| Step: 3
Training loss: 3.3427373475721236
Validation loss: 2.742994671785379

Epoch: 6| Step: 4
Training loss: 2.6483121859180483
Validation loss: 2.8250550217805452

Epoch: 6| Step: 5
Training loss: 3.3068055924590367
Validation loss: 2.789912352309737

Epoch: 6| Step: 6
Training loss: 2.7979727354323267
Validation loss: 2.7703853198413695

Epoch: 6| Step: 7
Training loss: 3.616934781896364
Validation loss: 2.694558680316277

Epoch: 6| Step: 8
Training loss: 3.0792156939976016
Validation loss: 2.6708120042444117

Epoch: 6| Step: 9
Training loss: 2.925112312964586
Validation loss: 2.665808180576457

Epoch: 6| Step: 10
Training loss: 2.2696185464533527
Validation loss: 2.6663264556206103

Epoch: 6| Step: 11
Training loss: 2.425938501344312
Validation loss: 2.676781490625383

Epoch: 6| Step: 12
Training loss: 3.5089672201587234
Validation loss: 2.682831566380734

Epoch: 6| Step: 13
Training loss: 3.067536086388616
Validation loss: 2.683370301451789

Epoch: 24| Step: 0
Training loss: 3.1358211083283276
Validation loss: 2.6809308619275067

Epoch: 6| Step: 1
Training loss: 3.2443618285606775
Validation loss: 2.6742054082769613

Epoch: 6| Step: 2
Training loss: 2.5001228302345
Validation loss: 2.6734558257118817

Epoch: 6| Step: 3
Training loss: 2.9641688286064984
Validation loss: 2.672008128010825

Epoch: 6| Step: 4
Training loss: 3.2316003959934103
Validation loss: 2.6711405639598254

Epoch: 6| Step: 5
Training loss: 2.9213618679605955
Validation loss: 2.66782683148769

Epoch: 6| Step: 6
Training loss: 2.336938955937201
Validation loss: 2.664230002201351

Epoch: 6| Step: 7
Training loss: 2.802397491730992
Validation loss: 2.6654569605227465

Epoch: 6| Step: 8
Training loss: 3.5519762367965777
Validation loss: 2.6739539632738323

Epoch: 6| Step: 9
Training loss: 3.268330744447774
Validation loss: 2.6662219321448015

Epoch: 6| Step: 10
Training loss: 2.7798855467089854
Validation loss: 2.666218181230809

Epoch: 6| Step: 11
Training loss: 3.518909056407344
Validation loss: 2.6742566450249012

Epoch: 6| Step: 12
Training loss: 3.111260690574931
Validation loss: 2.6808130655729348

Epoch: 6| Step: 13
Training loss: 2.4733646577289283
Validation loss: 2.692454191938257

Epoch: 25| Step: 0
Training loss: 3.175408560830912
Validation loss: 2.725940922503089

Epoch: 6| Step: 1
Training loss: 2.5545921191220655
Validation loss: 2.7313137937661804

Epoch: 6| Step: 2
Training loss: 3.850857745645412
Validation loss: 2.7325303041091793

Epoch: 6| Step: 3
Training loss: 2.8093791176635303
Validation loss: 2.697803731716297

Epoch: 6| Step: 4
Training loss: 2.429309484384987
Validation loss: 2.6759199788683676

Epoch: 6| Step: 5
Training loss: 2.5053044311956882
Validation loss: 2.6579931900675566

Epoch: 6| Step: 6
Training loss: 2.9612511944235007
Validation loss: 2.6572109561631962

Epoch: 6| Step: 7
Training loss: 2.625567965143428
Validation loss: 2.6583173781119402

Epoch: 6| Step: 8
Training loss: 2.869023787454708
Validation loss: 2.658391221952372

Epoch: 6| Step: 9
Training loss: 3.373592083045258
Validation loss: 2.6571487643479275

Epoch: 6| Step: 10
Training loss: 3.1446583218695974
Validation loss: 2.6543789522456014

Epoch: 6| Step: 11
Training loss: 2.928590126509573
Validation loss: 2.657248515027077

Epoch: 6| Step: 12
Training loss: 3.495358795828014
Validation loss: 2.6597031289971658

Epoch: 6| Step: 13
Training loss: 3.0555354743837104
Validation loss: 2.6579721242886025

Epoch: 26| Step: 0
Training loss: 2.85392918027975
Validation loss: 2.654411528040527

Epoch: 6| Step: 1
Training loss: 2.9840145192956395
Validation loss: 2.6525892633712673

Epoch: 6| Step: 2
Training loss: 2.9274431507509937
Validation loss: 2.654162503175784

Epoch: 6| Step: 3
Training loss: 3.0466380491797778
Validation loss: 2.6538067124191764

Epoch: 6| Step: 4
Training loss: 2.713005750065808
Validation loss: 2.6446614659848495

Epoch: 6| Step: 5
Training loss: 3.8355697797430723
Validation loss: 2.6526577937118403

Epoch: 6| Step: 6
Training loss: 2.4182027232126297
Validation loss: 2.677762265589428

Epoch: 6| Step: 7
Training loss: 2.8717530200776658
Validation loss: 2.6831692273278276

Epoch: 6| Step: 8
Training loss: 2.8387034145549026
Validation loss: 2.6900612830745216

Epoch: 6| Step: 9
Training loss: 2.5675846918655565
Validation loss: 2.6654095567500384

Epoch: 6| Step: 10
Training loss: 2.9994142278358358
Validation loss: 2.673140985750763

Epoch: 6| Step: 11
Training loss: 3.1689307166940446
Validation loss: 2.6671339456889

Epoch: 6| Step: 12
Training loss: 3.554472327793921
Validation loss: 2.6653138194490054

Epoch: 6| Step: 13
Training loss: 2.9594971064640263
Validation loss: 2.6519631748232197

Epoch: 27| Step: 0
Training loss: 3.162252779860869
Validation loss: 2.6407920171494577

Epoch: 6| Step: 1
Training loss: 2.8453399908255452
Validation loss: 2.6524606002654596

Epoch: 6| Step: 2
Training loss: 2.9343985559657546
Validation loss: 2.6569161030510298

Epoch: 6| Step: 3
Training loss: 2.6290624155534017
Validation loss: 2.6696368802303376

Epoch: 6| Step: 4
Training loss: 3.1688446452134644
Validation loss: 2.6763343550159995

Epoch: 6| Step: 5
Training loss: 3.1107895283783127
Validation loss: 2.6715313668214327

Epoch: 6| Step: 6
Training loss: 3.5639670847990113
Validation loss: 2.6698070603186626

Epoch: 6| Step: 7
Training loss: 3.0104702391472027
Validation loss: 2.662139770342956

Epoch: 6| Step: 8
Training loss: 3.179983214328057
Validation loss: 2.659924536064871

Epoch: 6| Step: 9
Training loss: 2.8483651407815898
Validation loss: 2.6543114582608194

Epoch: 6| Step: 10
Training loss: 3.0408114620170354
Validation loss: 2.6541217788246634

Epoch: 6| Step: 11
Training loss: 2.7152368055170033
Validation loss: 2.6527906597677755

Epoch: 6| Step: 12
Training loss: 3.1629739278079994
Validation loss: 2.6535915701821984

Epoch: 6| Step: 13
Training loss: 2.810893468845926
Validation loss: 2.6495615603242477

Epoch: 28| Step: 0
Training loss: 2.825298604121981
Validation loss: 2.647812171558093

Epoch: 6| Step: 1
Training loss: 3.2631578388764613
Validation loss: 2.648749390217474

Epoch: 6| Step: 2
Training loss: 3.2005007530846803
Validation loss: 2.649736975256656

Epoch: 6| Step: 3
Training loss: 2.869684031568639
Validation loss: 2.6553037083435025

Epoch: 6| Step: 4
Training loss: 2.593872067440122
Validation loss: 2.6568352167414306

Epoch: 6| Step: 5
Training loss: 3.249437283437947
Validation loss: 2.6627247045144844

Epoch: 6| Step: 6
Training loss: 3.0473253748668876
Validation loss: 2.6858633466084707

Epoch: 6| Step: 7
Training loss: 2.868091908353563
Validation loss: 2.7434042366350746

Epoch: 6| Step: 8
Training loss: 3.499489202010458
Validation loss: 2.9331507150748926

Epoch: 6| Step: 9
Training loss: 3.0918576396626722
Validation loss: 2.810639219559875

Epoch: 6| Step: 10
Training loss: 3.355912948534221
Validation loss: 2.6605705524184824

Epoch: 6| Step: 11
Training loss: 2.8745304221751167
Validation loss: 2.6431617733478476

Epoch: 6| Step: 12
Training loss: 2.811836333915185
Validation loss: 2.6457364693848047

Epoch: 6| Step: 13
Training loss: 2.2695502643149803
Validation loss: 2.649398801066489

Epoch: 29| Step: 0
Training loss: 2.7270432187814793
Validation loss: 2.661439694767842

Epoch: 6| Step: 1
Training loss: 3.4015187293527718
Validation loss: 2.7089044689689636

Epoch: 6| Step: 2
Training loss: 2.8811334615378996
Validation loss: 2.7581954188700695

Epoch: 6| Step: 3
Training loss: 2.6309541658289812
Validation loss: 2.8151480465179595

Epoch: 6| Step: 4
Training loss: 2.96540563835297
Validation loss: 2.8457353385300004

Epoch: 6| Step: 5
Training loss: 3.444423292635163
Validation loss: 2.8426149310097166

Epoch: 6| Step: 6
Training loss: 3.3637604233641576
Validation loss: 2.791050462911444

Epoch: 6| Step: 7
Training loss: 3.735361136629887
Validation loss: 2.714385461801753

Epoch: 6| Step: 8
Training loss: 3.110594543835261
Validation loss: 2.677305526836622

Epoch: 6| Step: 9
Training loss: 3.173988878140497
Validation loss: 2.6484116547463525

Epoch: 6| Step: 10
Training loss: 2.2667537639751174
Validation loss: 2.6454300350611666

Epoch: 6| Step: 11
Training loss: 2.701109382750541
Validation loss: 2.6481089512667864

Epoch: 6| Step: 12
Training loss: 3.37283764550845
Validation loss: 2.658305124611566

Epoch: 6| Step: 13
Training loss: 2.9275175883402484
Validation loss: 2.678671376892565

Epoch: 30| Step: 0
Training loss: 3.492817320556263
Validation loss: 2.6832577776782554

Epoch: 6| Step: 1
Training loss: 2.7314007086823384
Validation loss: 2.708436887921125

Epoch: 6| Step: 2
Training loss: 3.1616236199917513
Validation loss: 2.7414470848987356

Epoch: 6| Step: 3
Training loss: 2.904811051702632
Validation loss: 2.703764686669175

Epoch: 6| Step: 4
Training loss: 3.2465787633109775
Validation loss: 2.6987924494566684

Epoch: 6| Step: 5
Training loss: 3.4786148699696864
Validation loss: 2.654849843136044

Epoch: 6| Step: 6
Training loss: 3.1825771838445536
Validation loss: 2.631515865735644

Epoch: 6| Step: 7
Training loss: 2.0725106715536143
Validation loss: 2.6232720766002413

Epoch: 6| Step: 8
Training loss: 2.8462694346853774
Validation loss: 2.6232253823054195

Epoch: 6| Step: 9
Training loss: 2.768981965209818
Validation loss: 2.624860888778223

Epoch: 6| Step: 10
Training loss: 3.1578061639343753
Validation loss: 2.6235043004505743

Epoch: 6| Step: 11
Training loss: 2.9999721843701534
Validation loss: 2.6208236352446437

Epoch: 6| Step: 12
Training loss: 2.676732338384348
Validation loss: 2.6250246987301553

Epoch: 6| Step: 13
Training loss: 2.900932615868401
Validation loss: 2.6307208835105325

Epoch: 31| Step: 0
Training loss: 2.886203497920528
Validation loss: 2.620572760820953

Epoch: 6| Step: 1
Training loss: 3.392540878240772
Validation loss: 2.6165488950290627

Epoch: 6| Step: 2
Training loss: 3.1678122071372066
Validation loss: 2.615298168353313

Epoch: 6| Step: 3
Training loss: 3.358274483618666
Validation loss: 2.615411259073225

Epoch: 6| Step: 4
Training loss: 2.853421710359918
Validation loss: 2.617465500323003

Epoch: 6| Step: 5
Training loss: 3.2262308536805353
Validation loss: 2.612229686109286

Epoch: 6| Step: 6
Training loss: 3.496280328471089
Validation loss: 2.6148694158914774

Epoch: 6| Step: 7
Training loss: 3.273080155344214
Validation loss: 2.617437292406552

Epoch: 6| Step: 8
Training loss: 2.64974196275359
Validation loss: 2.6134770099615263

Epoch: 6| Step: 9
Training loss: 2.2886787587635427
Validation loss: 2.621690222219585

Epoch: 6| Step: 10
Training loss: 2.4557116047031324
Validation loss: 2.623701802954695

Epoch: 6| Step: 11
Training loss: 2.837334407058073
Validation loss: 2.623864336943757

Epoch: 6| Step: 12
Training loss: 2.32754765462798
Validation loss: 2.635822247586234

Epoch: 6| Step: 13
Training loss: 3.168098193062941
Validation loss: 2.665438090871349

Epoch: 32| Step: 0
Training loss: 3.2249583396882215
Validation loss: 2.6524213421042173

Epoch: 6| Step: 1
Training loss: 2.5191909441933267
Validation loss: 2.6382418448222476

Epoch: 6| Step: 2
Training loss: 3.226768505549061
Validation loss: 2.647674226956274

Epoch: 6| Step: 3
Training loss: 2.5081142350970356
Validation loss: 2.626570818068264

Epoch: 6| Step: 4
Training loss: 3.180922659649996
Validation loss: 2.615542365141111

Epoch: 6| Step: 5
Training loss: 3.0631781625172025
Validation loss: 2.6118674048797543

Epoch: 6| Step: 6
Training loss: 3.396689621008921
Validation loss: 2.610309550634802

Epoch: 6| Step: 7
Training loss: 3.220859317913245
Validation loss: 2.608978217737613

Epoch: 6| Step: 8
Training loss: 2.590987239310062
Validation loss: 2.6096490307508873

Epoch: 6| Step: 9
Training loss: 2.873025298929011
Validation loss: 2.6131408095477617

Epoch: 6| Step: 10
Training loss: 2.882318387162172
Validation loss: 2.6093231465217332

Epoch: 6| Step: 11
Training loss: 2.823702056599343
Validation loss: 2.6101522758650484

Epoch: 6| Step: 12
Training loss: 3.316287628316945
Validation loss: 2.6106840115418604

Epoch: 6| Step: 13
Training loss: 2.326632744706705
Validation loss: 2.6059124354763683

Epoch: 33| Step: 0
Training loss: 2.997841058183678
Validation loss: 2.6119532721218457

Epoch: 6| Step: 1
Training loss: 2.7074694698510973
Validation loss: 2.6071350886278917

Epoch: 6| Step: 2
Training loss: 2.861819197141298
Validation loss: 2.612561097401891

Epoch: 6| Step: 3
Training loss: 3.0378111001027084
Validation loss: 2.6142589166981907

Epoch: 6| Step: 4
Training loss: 3.3324691287969594
Validation loss: 2.6116683762465684

Epoch: 6| Step: 5
Training loss: 2.6599838044096584
Validation loss: 2.6098779178098725

Epoch: 6| Step: 6
Training loss: 2.7934615120654285
Validation loss: 2.6063538696746495

Epoch: 6| Step: 7
Training loss: 3.154963769477987
Validation loss: 2.6073167167112667

Epoch: 6| Step: 8
Training loss: 1.9632666384255317
Validation loss: 2.606879452969691

Epoch: 6| Step: 9
Training loss: 3.2335080076666785
Validation loss: 2.603683854825477

Epoch: 6| Step: 10
Training loss: 3.39963161492352
Validation loss: 2.6043500131032458

Epoch: 6| Step: 11
Training loss: 3.316013847653473
Validation loss: 2.599251150482498

Epoch: 6| Step: 12
Training loss: 2.763892282923708
Validation loss: 2.5998804375708633

Epoch: 6| Step: 13
Training loss: 2.986833288903672
Validation loss: 2.601198271858818

Epoch: 34| Step: 0
Training loss: 2.5661751978433998
Validation loss: 2.5963996788345356

Epoch: 6| Step: 1
Training loss: 3.143479601415699
Validation loss: 2.5974685752886657

Epoch: 6| Step: 2
Training loss: 3.6850513151366604
Validation loss: 2.598982566703912

Epoch: 6| Step: 3
Training loss: 3.309641342323868
Validation loss: 2.6011271330635033

Epoch: 6| Step: 4
Training loss: 2.4417644268510736
Validation loss: 2.602672115222365

Epoch: 6| Step: 5
Training loss: 3.4520690131864047
Validation loss: 2.6054922967060676

Epoch: 6| Step: 6
Training loss: 2.8676346682227614
Validation loss: 2.5965817024153264

Epoch: 6| Step: 7
Training loss: 3.295384074447183
Validation loss: 2.59736505320079

Epoch: 6| Step: 8
Training loss: 2.682243884997402
Validation loss: 2.59123051868223

Epoch: 6| Step: 9
Training loss: 2.5642996260527107
Validation loss: 2.5903451560671074

Epoch: 6| Step: 10
Training loss: 2.6205104400537436
Validation loss: 2.5900658077185135

Epoch: 6| Step: 11
Training loss: 2.5189495982556394
Validation loss: 2.5947479732898624

Epoch: 6| Step: 12
Training loss: 2.7780585676903176
Validation loss: 2.5949212701403543

Epoch: 6| Step: 13
Training loss: 3.3306222062860655
Validation loss: 2.5924555373560234

Epoch: 35| Step: 0
Training loss: 3.0569864583213096
Validation loss: 2.5951785648105252

Epoch: 6| Step: 1
Training loss: 3.168708310426724
Validation loss: 2.5989467442955076

Epoch: 6| Step: 2
Training loss: 2.430833650453181
Validation loss: 2.6121772788558486

Epoch: 6| Step: 3
Training loss: 3.0072206385520013
Validation loss: 2.6321447910934084

Epoch: 6| Step: 4
Training loss: 3.0816331420142227
Validation loss: 2.6406560338859184

Epoch: 6| Step: 5
Training loss: 3.2741193038558243
Validation loss: 2.6126319356579883

Epoch: 6| Step: 6
Training loss: 3.061555054910502
Validation loss: 2.5928303036514566

Epoch: 6| Step: 7
Training loss: 3.029022656935003
Validation loss: 2.588869865150181

Epoch: 6| Step: 8
Training loss: 2.933871198961735
Validation loss: 2.5934220279762488

Epoch: 6| Step: 9
Training loss: 2.3933172088689094
Validation loss: 2.597578209293718

Epoch: 6| Step: 10
Training loss: 3.3480576193350817
Validation loss: 2.60472507880427

Epoch: 6| Step: 11
Training loss: 2.8674382819906326
Validation loss: 2.6138783868982176

Epoch: 6| Step: 12
Training loss: 3.0260777342721092
Validation loss: 2.6149634976459777

Epoch: 6| Step: 13
Training loss: 2.590352786571537
Validation loss: 2.603533691922557

Epoch: 36| Step: 0
Training loss: 2.4116066103691685
Validation loss: 2.5995263574203697

Epoch: 6| Step: 1
Training loss: 3.2994250519170416
Validation loss: 2.605571309596006

Epoch: 6| Step: 2
Training loss: 3.28735060551823
Validation loss: 2.611200334899001

Epoch: 6| Step: 3
Training loss: 2.853497911799061
Validation loss: 2.6201964736147985

Epoch: 6| Step: 4
Training loss: 3.047054344180885
Validation loss: 2.6198766590166027

Epoch: 6| Step: 5
Training loss: 3.1597571197557524
Validation loss: 2.612070496313968

Epoch: 6| Step: 6
Training loss: 2.7425852430061366
Validation loss: 2.605271784110054

Epoch: 6| Step: 7
Training loss: 2.577105511318325
Validation loss: 2.600493877547352

Epoch: 6| Step: 8
Training loss: 3.091915010278603
Validation loss: 2.6027321652561075

Epoch: 6| Step: 9
Training loss: 3.2295733944280562
Validation loss: 2.601773965244016

Epoch: 6| Step: 10
Training loss: 3.1232157381841574
Validation loss: 2.602548112172264

Epoch: 6| Step: 11
Training loss: 2.9397652191045855
Validation loss: 2.5984606999568505

Epoch: 6| Step: 12
Training loss: 2.412785559638344
Validation loss: 2.59484374885553

Epoch: 6| Step: 13
Training loss: 3.4436023992072147
Validation loss: 2.5920371191626104

Epoch: 37| Step: 0
Training loss: 2.935881473154879
Validation loss: 2.590003362621703

Epoch: 6| Step: 1
Training loss: 2.612520800055972
Validation loss: 2.5858471759878254

Epoch: 6| Step: 2
Training loss: 2.109852037530067
Validation loss: 2.5849124849933283

Epoch: 6| Step: 3
Training loss: 3.009237531491168
Validation loss: 2.58633976480462

Epoch: 6| Step: 4
Training loss: 3.471026249378842
Validation loss: 2.579740064280011

Epoch: 6| Step: 5
Training loss: 3.2670695199193176
Validation loss: 2.581992548339344

Epoch: 6| Step: 6
Training loss: 2.8808769199677604
Validation loss: 2.5824856023809306

Epoch: 6| Step: 7
Training loss: 2.225460810573166
Validation loss: 2.582583814555614

Epoch: 6| Step: 8
Training loss: 3.0083143732066953
Validation loss: 2.5874690372183293

Epoch: 6| Step: 9
Training loss: 3.1828826671838035
Validation loss: 2.6033295150083258

Epoch: 6| Step: 10
Training loss: 3.360083500869063
Validation loss: 2.6236507954548385

Epoch: 6| Step: 11
Training loss: 3.2989029997238344
Validation loss: 2.6285536463960257

Epoch: 6| Step: 12
Training loss: 2.50500416601143
Validation loss: 2.6117175397368007

Epoch: 6| Step: 13
Training loss: 3.4296724844844992
Validation loss: 2.6022270753347585

Epoch: 38| Step: 0
Training loss: 2.642693155495966
Validation loss: 2.6050126835694556

Epoch: 6| Step: 1
Training loss: 1.9880773893218084
Validation loss: 2.608331658503911

Epoch: 6| Step: 2
Training loss: 3.400729544290555
Validation loss: 2.605684506656045

Epoch: 6| Step: 3
Training loss: 3.198491313054875
Validation loss: 2.5838800070858783

Epoch: 6| Step: 4
Training loss: 3.171219180103582
Validation loss: 2.575315961877861

Epoch: 6| Step: 5
Training loss: 2.905952192245379
Validation loss: 2.5767946680989526

Epoch: 6| Step: 6
Training loss: 3.547951287134093
Validation loss: 2.575925567136295

Epoch: 6| Step: 7
Training loss: 2.9707503155152217
Validation loss: 2.5791281738727387

Epoch: 6| Step: 8
Training loss: 2.8316131493636143
Validation loss: 2.5819703372420584

Epoch: 6| Step: 9
Training loss: 2.3966021644850555
Validation loss: 2.585889121309633

Epoch: 6| Step: 10
Training loss: 2.9486167444874183
Validation loss: 2.582299775632722

Epoch: 6| Step: 11
Training loss: 3.1686851359392993
Validation loss: 2.5859382455158837

Epoch: 6| Step: 12
Training loss: 3.028443285706571
Validation loss: 2.5826623986796506

Epoch: 6| Step: 13
Training loss: 2.8210107673350286
Validation loss: 2.578977287968655

Epoch: 39| Step: 0
Training loss: 2.8779871805103023
Validation loss: 2.576040477910065

Epoch: 6| Step: 1
Training loss: 3.208003204667543
Validation loss: 2.577521987055321

Epoch: 6| Step: 2
Training loss: 2.978308458471639
Validation loss: 2.573036205684524

Epoch: 6| Step: 3
Training loss: 2.692346416970407
Validation loss: 2.5713006628649473

Epoch: 6| Step: 4
Training loss: 2.285487380856477
Validation loss: 2.569390381969785

Epoch: 6| Step: 5
Training loss: 3.140844384876813
Validation loss: 2.5725710940954425

Epoch: 6| Step: 6
Training loss: 2.6899732697587537
Validation loss: 2.569059650402653

Epoch: 6| Step: 7
Training loss: 3.056423152706987
Validation loss: 2.571552412289624

Epoch: 6| Step: 8
Training loss: 3.264015202524273
Validation loss: 2.5756468834375252

Epoch: 6| Step: 9
Training loss: 2.9150271212590426
Validation loss: 2.570808421399982

Epoch: 6| Step: 10
Training loss: 2.9517176266763454
Validation loss: 2.5786099780398875

Epoch: 6| Step: 11
Training loss: 3.4083929757742326
Validation loss: 2.5734337568615424

Epoch: 6| Step: 12
Training loss: 2.5100485081943673
Validation loss: 2.5822399652574184

Epoch: 6| Step: 13
Training loss: 3.1475548654732854
Validation loss: 2.5845639939174045

Epoch: 40| Step: 0
Training loss: 3.4890163283617914
Validation loss: 2.582210243716267

Epoch: 6| Step: 1
Training loss: 3.0727976285647713
Validation loss: 2.5656619518913897

Epoch: 6| Step: 2
Training loss: 3.0868249317348218
Validation loss: 2.5630233944445777

Epoch: 6| Step: 3
Training loss: 2.747954474809177
Validation loss: 2.5661841979295996

Epoch: 6| Step: 4
Training loss: 2.573957369186816
Validation loss: 2.566010433444267

Epoch: 6| Step: 5
Training loss: 3.1082545423024244
Validation loss: 2.565131078495322

Epoch: 6| Step: 6
Training loss: 3.143506905653868
Validation loss: 2.5642494879505566

Epoch: 6| Step: 7
Training loss: 3.2840511899203975
Validation loss: 2.5634007425263294

Epoch: 6| Step: 8
Training loss: 2.341245813890453
Validation loss: 2.562477081700565

Epoch: 6| Step: 9
Training loss: 3.3482302303842815
Validation loss: 2.5651237767300055

Epoch: 6| Step: 10
Training loss: 2.1194313236673152
Validation loss: 2.5790491918047818

Epoch: 6| Step: 11
Training loss: 3.046814746749986
Validation loss: 2.597369808639098

Epoch: 6| Step: 12
Training loss: 2.6859012550274093
Validation loss: 2.60319041076999

Epoch: 6| Step: 13
Training loss: 2.55254990860496
Validation loss: 2.6025510781568384

Epoch: 41| Step: 0
Training loss: 2.827323083309251
Validation loss: 2.582837795267724

Epoch: 6| Step: 1
Training loss: 3.144871815311589
Validation loss: 2.569084053702892

Epoch: 6| Step: 2
Training loss: 3.1328041285833446
Validation loss: 2.565194878609489

Epoch: 6| Step: 3
Training loss: 2.8529196657997287
Validation loss: 2.562285635661035

Epoch: 6| Step: 4
Training loss: 3.1520300121718123
Validation loss: 2.5581006087521527

Epoch: 6| Step: 5
Training loss: 2.8731049636165413
Validation loss: 2.5641875714077424

Epoch: 6| Step: 6
Training loss: 3.148528672784278
Validation loss: 2.5658518861008366

Epoch: 6| Step: 7
Training loss: 3.098393663951365
Validation loss: 2.561530568379162

Epoch: 6| Step: 8
Training loss: 2.570079572610934
Validation loss: 2.56430757599683

Epoch: 6| Step: 9
Training loss: 2.17651716350761
Validation loss: 2.5586654281063455

Epoch: 6| Step: 10
Training loss: 3.0207346582191246
Validation loss: 2.5714587067662737

Epoch: 6| Step: 11
Training loss: 3.3080352347825723
Validation loss: 2.575580842873387

Epoch: 6| Step: 12
Training loss: 3.1102022383700407
Validation loss: 2.584676300855385

Epoch: 6| Step: 13
Training loss: 2.0794757096049854
Validation loss: 2.6064320400731247

Epoch: 42| Step: 0
Training loss: 2.5769460120861174
Validation loss: 2.6001449039150204

Epoch: 6| Step: 1
Training loss: 2.691619554546299
Validation loss: 2.6009868849862934

Epoch: 6| Step: 2
Training loss: 2.308504519214631
Validation loss: 2.6017257499771986

Epoch: 6| Step: 3
Training loss: 3.0770080398786783
Validation loss: 2.616498192914835

Epoch: 6| Step: 4
Training loss: 3.2881156663992397
Validation loss: 2.606051092416202

Epoch: 6| Step: 5
Training loss: 2.6127806955333353
Validation loss: 2.586574002106675

Epoch: 6| Step: 6
Training loss: 3.201639268139979
Validation loss: 2.58314188414194

Epoch: 6| Step: 7
Training loss: 2.862158749158282
Validation loss: 2.5753452334024396

Epoch: 6| Step: 8
Training loss: 2.808977336978172
Validation loss: 2.576976197246468

Epoch: 6| Step: 9
Training loss: 2.8438623427114034
Validation loss: 2.5875900525546607

Epoch: 6| Step: 10
Training loss: 3.2483968448709555
Validation loss: 2.581782317663175

Epoch: 6| Step: 11
Training loss: 3.3596452471240825
Validation loss: 2.572426769787609

Epoch: 6| Step: 12
Training loss: 3.162775375982059
Validation loss: 2.5565492468638285

Epoch: 6| Step: 13
Training loss: 2.4093908643385786
Validation loss: 2.554216113414271

Epoch: 43| Step: 0
Training loss: 2.4468229948439104
Validation loss: 2.553614967986902

Epoch: 6| Step: 1
Training loss: 2.814041986554839
Validation loss: 2.558887421312709

Epoch: 6| Step: 2
Training loss: 2.5562047156913996
Validation loss: 2.5545013511444323

Epoch: 6| Step: 3
Training loss: 3.0042968813487354
Validation loss: 2.5595539023929548

Epoch: 6| Step: 4
Training loss: 3.0711269705835673
Validation loss: 2.560483405620496

Epoch: 6| Step: 5
Training loss: 2.9994625563817645
Validation loss: 2.5598524138746104

Epoch: 6| Step: 6
Training loss: 3.351285909697225
Validation loss: 2.5577275434135016

Epoch: 6| Step: 7
Training loss: 2.6989493339110764
Validation loss: 2.5574659216278777

Epoch: 6| Step: 8
Training loss: 3.3199961073978996
Validation loss: 2.5546036056386505

Epoch: 6| Step: 9
Training loss: 2.9610784089471704
Validation loss: 2.5555536425587664

Epoch: 6| Step: 10
Training loss: 2.5443567100772713
Validation loss: 2.5547728305843256

Epoch: 6| Step: 11
Training loss: 3.3250451680033906
Validation loss: 2.552663040535895

Epoch: 6| Step: 12
Training loss: 2.4627875261864154
Validation loss: 2.555294207043403

Epoch: 6| Step: 13
Training loss: 3.381697332156365
Validation loss: 2.5679040426667523

Epoch: 44| Step: 0
Training loss: 2.520296770059745
Validation loss: 2.5940442848025342

Epoch: 6| Step: 1
Training loss: 3.3575549495969517
Validation loss: 2.611742585914193

Epoch: 6| Step: 2
Training loss: 2.9495068542018
Validation loss: 2.615725738137604

Epoch: 6| Step: 3
Training loss: 3.448644156026043
Validation loss: 2.620184677811933

Epoch: 6| Step: 4
Training loss: 3.1019823381128973
Validation loss: 2.5902117165852836

Epoch: 6| Step: 5
Training loss: 2.654223757558505
Validation loss: 2.5513275520787415

Epoch: 6| Step: 6
Training loss: 2.450978500215885
Validation loss: 2.5478316437460404

Epoch: 6| Step: 7
Training loss: 3.0513332517175358
Validation loss: 2.5502993363954163

Epoch: 6| Step: 8
Training loss: 2.929921540130937
Validation loss: 2.553421552297099

Epoch: 6| Step: 9
Training loss: 3.3956745009146725
Validation loss: 2.5519899479696377

Epoch: 6| Step: 10
Training loss: 2.3059814958450313
Validation loss: 2.5526559330917293

Epoch: 6| Step: 11
Training loss: 3.0126419730387552
Validation loss: 2.5519873411212637

Epoch: 6| Step: 12
Training loss: 3.053023331354019
Validation loss: 2.5604567276266295

Epoch: 6| Step: 13
Training loss: 2.56012252678311
Validation loss: 2.5498457789408597

Epoch: 45| Step: 0
Training loss: 2.8772622205922356
Validation loss: 2.550801483412245

Epoch: 6| Step: 1
Training loss: 2.985298373391482
Validation loss: 2.5503949712998852

Epoch: 6| Step: 2
Training loss: 2.921504522489527
Validation loss: 2.551868541351986

Epoch: 6| Step: 3
Training loss: 2.737984329646919
Validation loss: 2.554358457752428

Epoch: 6| Step: 4
Training loss: 2.289360677938316
Validation loss: 2.5632371810033883

Epoch: 6| Step: 5
Training loss: 2.7122854789602555
Validation loss: 2.5799798015424824

Epoch: 6| Step: 6
Training loss: 3.100718039754751
Validation loss: 2.6084617768948104

Epoch: 6| Step: 7
Training loss: 3.1891552984033225
Validation loss: 2.5889132537879456

Epoch: 6| Step: 8
Training loss: 2.6922865536666865
Validation loss: 2.5796265536037146

Epoch: 6| Step: 9
Training loss: 2.990064380679846
Validation loss: 2.574986635542414

Epoch: 6| Step: 10
Training loss: 2.6810692430580336
Validation loss: 2.561161039597116

Epoch: 6| Step: 11
Training loss: 3.2323836678727615
Validation loss: 2.550915362709992

Epoch: 6| Step: 12
Training loss: 3.1226309379446966
Validation loss: 2.5479951377376406

Epoch: 6| Step: 13
Training loss: 3.3575464284360987
Validation loss: 2.538211944456754

Epoch: 46| Step: 0
Training loss: 2.9256937296551824
Validation loss: 2.541509832919227

Epoch: 6| Step: 1
Training loss: 2.6770910022986936
Validation loss: 2.540397814163838

Epoch: 6| Step: 2
Training loss: 3.2503054548652437
Validation loss: 2.5420943642871103

Epoch: 6| Step: 3
Training loss: 2.323063821507887
Validation loss: 2.541547805438364

Epoch: 6| Step: 4
Training loss: 2.7455043458641946
Validation loss: 2.536516254147212

Epoch: 6| Step: 5
Training loss: 3.241637401563119
Validation loss: 2.548843239284573

Epoch: 6| Step: 6
Training loss: 2.807232820157135
Validation loss: 2.539874324584969

Epoch: 6| Step: 7
Training loss: 2.5138531243840285
Validation loss: 2.5434001361824294

Epoch: 6| Step: 8
Training loss: 2.9802058792681936
Validation loss: 2.543982078694859

Epoch: 6| Step: 9
Training loss: 3.602405904458307
Validation loss: 2.544578232315824

Epoch: 6| Step: 10
Training loss: 2.822898292247098
Validation loss: 2.5454797980385417

Epoch: 6| Step: 11
Training loss: 2.378730554466128
Validation loss: 2.5545447033268127

Epoch: 6| Step: 12
Training loss: 3.136047367438877
Validation loss: 2.5559157673038566

Epoch: 6| Step: 13
Training loss: 3.257669642401365
Validation loss: 2.5701145535129157

Epoch: 47| Step: 0
Training loss: 3.2801535091298746
Validation loss: 2.5662371413541387

Epoch: 6| Step: 1
Training loss: 3.120047497754582
Validation loss: 2.5604124973133375

Epoch: 6| Step: 2
Training loss: 3.2716371232996995
Validation loss: 2.5463761198952546

Epoch: 6| Step: 3
Training loss: 2.4170132969406457
Validation loss: 2.5347284591612307

Epoch: 6| Step: 4
Training loss: 3.0082184752907435
Validation loss: 2.535782462308412

Epoch: 6| Step: 5
Training loss: 2.5302843677398035
Validation loss: 2.5332124476689346

Epoch: 6| Step: 6
Training loss: 2.7594287664028956
Validation loss: 2.5362654209569278

Epoch: 6| Step: 7
Training loss: 2.7987688355112335
Validation loss: 2.5352137805715977

Epoch: 6| Step: 8
Training loss: 3.237932543046614
Validation loss: 2.539740683174751

Epoch: 6| Step: 9
Training loss: 2.8056489364476525
Validation loss: 2.5379423511922607

Epoch: 6| Step: 10
Training loss: 2.8482377409663227
Validation loss: 2.5424331784822294

Epoch: 6| Step: 11
Training loss: 2.7121888716204476
Validation loss: 2.548216508169083

Epoch: 6| Step: 12
Training loss: 3.039829500587025
Validation loss: 2.5471338205634795

Epoch: 6| Step: 13
Training loss: 2.714559899729374
Validation loss: 2.553750167147256

Epoch: 48| Step: 0
Training loss: 2.6962230968592173
Validation loss: 2.5607234359909956

Epoch: 6| Step: 1
Training loss: 2.859117506763314
Validation loss: 2.55278765912802

Epoch: 6| Step: 2
Training loss: 2.63967047599938
Validation loss: 2.56028518984671

Epoch: 6| Step: 3
Training loss: 3.277961899997386
Validation loss: 2.5527674645563074

Epoch: 6| Step: 4
Training loss: 3.3602188824703596
Validation loss: 2.5494685583782055

Epoch: 6| Step: 5
Training loss: 2.8445989997253185
Validation loss: 2.554321590000201

Epoch: 6| Step: 6
Training loss: 2.980010511136559
Validation loss: 2.5433242720965055

Epoch: 6| Step: 7
Training loss: 2.841792344551801
Validation loss: 2.5434135863390526

Epoch: 6| Step: 8
Training loss: 2.8534126863705214
Validation loss: 2.5437648245369484

Epoch: 6| Step: 9
Training loss: 2.6618400543849687
Validation loss: 2.547558428372561

Epoch: 6| Step: 10
Training loss: 2.796985219136947
Validation loss: 2.5386526145794113

Epoch: 6| Step: 11
Training loss: 2.766263726394735
Validation loss: 2.537035967248079

Epoch: 6| Step: 12
Training loss: 3.2829277472259206
Validation loss: 2.540243780011314

Epoch: 6| Step: 13
Training loss: 2.3557138900604486
Validation loss: 2.5424292388893197

Epoch: 49| Step: 0
Training loss: 3.0262828912409003
Validation loss: 2.538577664943405

Epoch: 6| Step: 1
Training loss: 2.4744441361872713
Validation loss: 2.5355524606444275

Epoch: 6| Step: 2
Training loss: 2.924807459045014
Validation loss: 2.5446765661082233

Epoch: 6| Step: 3
Training loss: 2.8336702221316106
Validation loss: 2.5476616166154105

Epoch: 6| Step: 4
Training loss: 3.179162584321354
Validation loss: 2.5531741572035376

Epoch: 6| Step: 5
Training loss: 3.438177839551683
Validation loss: 2.538836859812474

Epoch: 6| Step: 6
Training loss: 3.2241226836400934
Validation loss: 2.540874251431559

Epoch: 6| Step: 7
Training loss: 2.0817543403889007
Validation loss: 2.533296495870342

Epoch: 6| Step: 8
Training loss: 3.1320282294510253
Validation loss: 2.5335699044497906

Epoch: 6| Step: 9
Training loss: 2.8710063895085
Validation loss: 2.5330394646749723

Epoch: 6| Step: 10
Training loss: 2.959005163138611
Validation loss: 2.5351334404637784

Epoch: 6| Step: 11
Training loss: 2.664775495681168
Validation loss: 2.5319089873607186

Epoch: 6| Step: 12
Training loss: 2.9509545479108024
Validation loss: 2.533146926148088

Epoch: 6| Step: 13
Training loss: 2.514575715726383
Validation loss: 2.530402224499012

Epoch: 50| Step: 0
Training loss: 2.6916666776895277
Validation loss: 2.5323763030014637

Epoch: 6| Step: 1
Training loss: 3.280270820927804
Validation loss: 2.532145591021392

Epoch: 6| Step: 2
Training loss: 2.3141818760816353
Validation loss: 2.5303462673866735

Epoch: 6| Step: 3
Training loss: 3.0176242664352544
Validation loss: 2.5337818244483805

Epoch: 6| Step: 4
Training loss: 2.915513891656393
Validation loss: 2.5273650951225566

Epoch: 6| Step: 5
Training loss: 2.458706865111692
Validation loss: 2.5306512754256607

Epoch: 6| Step: 6
Training loss: 3.5880257835950227
Validation loss: 2.5321246628272314

Epoch: 6| Step: 7
Training loss: 2.903783264100998
Validation loss: 2.5329889633632456

Epoch: 6| Step: 8
Training loss: 2.820293901968631
Validation loss: 2.5289121451051244

Epoch: 6| Step: 9
Training loss: 2.8785039033106266
Validation loss: 2.5269088689222334

Epoch: 6| Step: 10
Training loss: 3.063423484607527
Validation loss: 2.531967288322178

Epoch: 6| Step: 11
Training loss: 2.6774572761895405
Validation loss: 2.540950582149358

Epoch: 6| Step: 12
Training loss: 2.53839271514357
Validation loss: 2.5513201264027043

Epoch: 6| Step: 13
Training loss: 3.273254535086577
Validation loss: 2.5664425805497557

Epoch: 51| Step: 0
Training loss: 2.648265911834141
Validation loss: 2.617690925502232

Epoch: 6| Step: 1
Training loss: 2.974586291358233
Validation loss: 2.6427004582961406

Epoch: 6| Step: 2
Training loss: 2.684372079690004
Validation loss: 2.6225415518526947

Epoch: 6| Step: 3
Training loss: 3.0967571401639247
Validation loss: 2.5906010398477646

Epoch: 6| Step: 4
Training loss: 2.97757029055656
Validation loss: 2.5702103577898856

Epoch: 6| Step: 5
Training loss: 2.8552950742326964
Validation loss: 2.5436299855895403

Epoch: 6| Step: 6
Training loss: 3.422264878170932
Validation loss: 2.5261706524922074

Epoch: 6| Step: 7
Training loss: 2.2541076464397793
Validation loss: 2.5243112330316837

Epoch: 6| Step: 8
Training loss: 3.110521881374847
Validation loss: 2.525442823276909

Epoch: 6| Step: 9
Training loss: 2.656783555242225
Validation loss: 2.527737680636497

Epoch: 6| Step: 10
Training loss: 3.252813588535355
Validation loss: 2.5272656652608534

Epoch: 6| Step: 11
Training loss: 2.566608391963081
Validation loss: 2.5375064081741225

Epoch: 6| Step: 12
Training loss: 2.6661789169886965
Validation loss: 2.541586952499302

Epoch: 6| Step: 13
Training loss: 3.5859700785301833
Validation loss: 2.547349183198307

Epoch: 52| Step: 0
Training loss: 2.657643928541882
Validation loss: 2.548840075018399

Epoch: 6| Step: 1
Training loss: 3.131571764222806
Validation loss: 2.547415949616875

Epoch: 6| Step: 2
Training loss: 2.9917138424468157
Validation loss: 2.548514591254482

Epoch: 6| Step: 3
Training loss: 2.9157861924664887
Validation loss: 2.551314020049125

Epoch: 6| Step: 4
Training loss: 3.1342957141466825
Validation loss: 2.549203158481741

Epoch: 6| Step: 5
Training loss: 3.0853567615148165
Validation loss: 2.547752203638452

Epoch: 6| Step: 6
Training loss: 3.2715575434914754
Validation loss: 2.549509107215799

Epoch: 6| Step: 7
Training loss: 2.7444974294001683
Validation loss: 2.5510058326840546

Epoch: 6| Step: 8
Training loss: 2.558743957303678
Validation loss: 2.5539088393908536

Epoch: 6| Step: 9
Training loss: 3.091059275665659
Validation loss: 2.56563950649033

Epoch: 6| Step: 10
Training loss: 2.215730681273068
Validation loss: 2.573635755268426

Epoch: 6| Step: 11
Training loss: 3.1382368886602783
Validation loss: 2.580673717012644

Epoch: 6| Step: 12
Training loss: 3.0721209686621633
Validation loss: 2.5951079851110337

Epoch: 6| Step: 13
Training loss: 1.9824202514040457
Validation loss: 2.627605900733963

Epoch: 53| Step: 0
Training loss: 2.319052203039501
Validation loss: 2.6787224085887367

Epoch: 6| Step: 1
Training loss: 2.299570279820183
Validation loss: 2.742001792991439

Epoch: 6| Step: 2
Training loss: 3.3698489121886466
Validation loss: 2.8405454118917373

Epoch: 6| Step: 3
Training loss: 3.791279126717922
Validation loss: 2.854907799564846

Epoch: 6| Step: 4
Training loss: 2.9298603464636797
Validation loss: 2.716109365779783

Epoch: 6| Step: 5
Training loss: 3.0366298480965024
Validation loss: 2.5974819774089886

Epoch: 6| Step: 6
Training loss: 2.992140806944343
Validation loss: 2.56165385488869

Epoch: 6| Step: 7
Training loss: 3.0210601370721903
Validation loss: 2.5579495548745923

Epoch: 6| Step: 8
Training loss: 2.8886215277792124
Validation loss: 2.574595860228398

Epoch: 6| Step: 9
Training loss: 2.5330642038575055
Validation loss: 2.603265071871689

Epoch: 6| Step: 10
Training loss: 3.3064052725605215
Validation loss: 2.6135081729728986

Epoch: 6| Step: 11
Training loss: 2.5261093497630798
Validation loss: 2.5656479813684583

Epoch: 6| Step: 12
Training loss: 3.5978009819218153
Validation loss: 2.5457200104500215

Epoch: 6| Step: 13
Training loss: 2.933261004191986
Validation loss: 2.5310139851774167

Epoch: 54| Step: 0
Training loss: 2.9096789077371357
Validation loss: 2.5289235044600464

Epoch: 6| Step: 1
Training loss: 2.8364280927888026
Validation loss: 2.5271724590832028

Epoch: 6| Step: 2
Training loss: 2.517547252101724
Validation loss: 2.52485295548519

Epoch: 6| Step: 3
Training loss: 3.335840156796602
Validation loss: 2.5240000806893326

Epoch: 6| Step: 4
Training loss: 3.0361466332308464
Validation loss: 2.528173495538799

Epoch: 6| Step: 5
Training loss: 3.1638081012697588
Validation loss: 2.5321896094218883

Epoch: 6| Step: 6
Training loss: 2.8854701912846856
Validation loss: 2.546663641047064

Epoch: 6| Step: 7
Training loss: 3.0812142453237388
Validation loss: 2.546215692497501

Epoch: 6| Step: 8
Training loss: 2.2940699258072774
Validation loss: 2.5598092146763682

Epoch: 6| Step: 9
Training loss: 2.923401133129127
Validation loss: 2.576931383964799

Epoch: 6| Step: 10
Training loss: 3.1091951097754955
Validation loss: 2.5980425256088417

Epoch: 6| Step: 11
Training loss: 3.247826656507803
Validation loss: 2.5863640328145947

Epoch: 6| Step: 12
Training loss: 2.4796900690903123
Validation loss: 2.5639622305791403

Epoch: 6| Step: 13
Training loss: 2.0953695381929447
Validation loss: 2.5423220094372323

Epoch: 55| Step: 0
Training loss: 2.7194086789654146
Validation loss: 2.5373389364664187

Epoch: 6| Step: 1
Training loss: 3.379316466021917
Validation loss: 2.5266957251440365

Epoch: 6| Step: 2
Training loss: 3.003341562201277
Validation loss: 2.5298938832954807

Epoch: 6| Step: 3
Training loss: 3.6634425958566905
Validation loss: 2.526563025358244

Epoch: 6| Step: 4
Training loss: 3.068932764395129
Validation loss: 2.528428625484079

Epoch: 6| Step: 5
Training loss: 2.3862771782343946
Validation loss: 2.525702115575642

Epoch: 6| Step: 6
Training loss: 3.2331227997603307
Validation loss: 2.528443618369898

Epoch: 6| Step: 7
Training loss: 3.1336963957259703
Validation loss: 2.5391066266714595

Epoch: 6| Step: 8
Training loss: 2.3020104329115547
Validation loss: 2.531267568410058

Epoch: 6| Step: 9
Training loss: 2.6520723588890722
Validation loss: 2.530223750312319

Epoch: 6| Step: 10
Training loss: 2.3724813658743242
Validation loss: 2.526731338119223

Epoch: 6| Step: 11
Training loss: 2.686144731037917
Validation loss: 2.5280303045386376

Epoch: 6| Step: 12
Training loss: 2.8211966103643067
Validation loss: 2.5216825185970357

Epoch: 6| Step: 13
Training loss: 2.5627421753119846
Validation loss: 2.52510967578923

Epoch: 56| Step: 0
Training loss: 2.405240330098476
Validation loss: 2.5175202331681423

Epoch: 6| Step: 1
Training loss: 2.1449734591462652
Validation loss: 2.525301644854968

Epoch: 6| Step: 2
Training loss: 2.2636657662099413
Validation loss: 2.533589920149775

Epoch: 6| Step: 3
Training loss: 2.9339838289258577
Validation loss: 2.5343421655226868

Epoch: 6| Step: 4
Training loss: 3.05506648763926
Validation loss: 2.544336354882938

Epoch: 6| Step: 5
Training loss: 3.105001930322216
Validation loss: 2.572275944261603

Epoch: 6| Step: 6
Training loss: 2.7355984811628296
Validation loss: 2.582275185491082

Epoch: 6| Step: 7
Training loss: 3.567977308543285
Validation loss: 2.6123508625705

Epoch: 6| Step: 8
Training loss: 2.650823997649809
Validation loss: 2.562975738527646

Epoch: 6| Step: 9
Training loss: 3.222309107723493
Validation loss: 2.5196178607405755

Epoch: 6| Step: 10
Training loss: 3.447067817005372
Validation loss: 2.5151747240256745

Epoch: 6| Step: 11
Training loss: 2.537176188586905
Validation loss: 2.5126660824666573

Epoch: 6| Step: 12
Training loss: 3.0372423541526756
Validation loss: 2.511447007956264

Epoch: 6| Step: 13
Training loss: 2.9751303123335977
Validation loss: 2.5167538950547526

Epoch: 57| Step: 0
Training loss: 2.6290392905774813
Validation loss: 2.5191768161960724

Epoch: 6| Step: 1
Training loss: 2.962801786736709
Validation loss: 2.5256013321317905

Epoch: 6| Step: 2
Training loss: 3.347266229012228
Validation loss: 2.5234120609371797

Epoch: 6| Step: 3
Training loss: 2.60871997766625
Validation loss: 2.526692319056264

Epoch: 6| Step: 4
Training loss: 3.032647508774402
Validation loss: 2.528459003551663

Epoch: 6| Step: 5
Training loss: 3.0184971863457237
Validation loss: 2.5301456085487164

Epoch: 6| Step: 6
Training loss: 3.254409146687455
Validation loss: 2.5327275069781843

Epoch: 6| Step: 7
Training loss: 2.714510099916751
Validation loss: 2.533744111932014

Epoch: 6| Step: 8
Training loss: 2.736491577581558
Validation loss: 2.5420566954201185

Epoch: 6| Step: 9
Training loss: 3.21636785855382
Validation loss: 2.550620406151257

Epoch: 6| Step: 10
Training loss: 2.297226029126007
Validation loss: 2.542590994138731

Epoch: 6| Step: 11
Training loss: 2.31094689667128
Validation loss: 2.546309491327709

Epoch: 6| Step: 12
Training loss: 3.638012386558883
Validation loss: 2.5455967649642455

Epoch: 6| Step: 13
Training loss: 2.645925134783328
Validation loss: 2.544881183563165

Epoch: 58| Step: 0
Training loss: 3.2241896801565395
Validation loss: 2.553496242937945

Epoch: 6| Step: 1
Training loss: 2.5828473854362897
Validation loss: 2.5546079188393858

Epoch: 6| Step: 2
Training loss: 2.6783160823637564
Validation loss: 2.543967132037048

Epoch: 6| Step: 3
Training loss: 3.111522603826547
Validation loss: 2.5478841771612792

Epoch: 6| Step: 4
Training loss: 3.061774031560284
Validation loss: 2.5378661875864825

Epoch: 6| Step: 5
Training loss: 3.088704474255293
Validation loss: 2.524430374032829

Epoch: 6| Step: 6
Training loss: 2.715993338693307
Validation loss: 2.526279480808964

Epoch: 6| Step: 7
Training loss: 3.0308220944752557
Validation loss: 2.5363973917785376

Epoch: 6| Step: 8
Training loss: 2.6744971542471627
Validation loss: 2.5372336491075655

Epoch: 6| Step: 9
Training loss: 2.7971337054921324
Validation loss: 2.558333476402848

Epoch: 6| Step: 10
Training loss: 3.285632594496912
Validation loss: 2.5359858797027752

Epoch: 6| Step: 11
Training loss: 2.7967887311023154
Validation loss: 2.5098340265487584

Epoch: 6| Step: 12
Training loss: 2.9197107143024295
Validation loss: 2.5179442543265527

Epoch: 6| Step: 13
Training loss: 1.860781161950289
Validation loss: 2.516999444173413

Epoch: 59| Step: 0
Training loss: 3.272198790930674
Validation loss: 2.514949702085273

Epoch: 6| Step: 1
Training loss: 2.7271472555255083
Validation loss: 2.535701869265611

Epoch: 6| Step: 2
Training loss: 2.153645587323016
Validation loss: 2.5395939591174117

Epoch: 6| Step: 3
Training loss: 2.8417264005436684
Validation loss: 2.5309320784679805

Epoch: 6| Step: 4
Training loss: 3.0767295501443486
Validation loss: 2.530850171133684

Epoch: 6| Step: 5
Training loss: 3.5199875276517982
Validation loss: 2.5304757157833597

Epoch: 6| Step: 6
Training loss: 3.058696798681132
Validation loss: 2.5208358629038226

Epoch: 6| Step: 7
Training loss: 2.7093974639418903
Validation loss: 2.5155157066638187

Epoch: 6| Step: 8
Training loss: 2.5338389966980426
Validation loss: 2.5113135085413796

Epoch: 6| Step: 9
Training loss: 2.378633730958995
Validation loss: 2.502204926600941

Epoch: 6| Step: 10
Training loss: 3.2527015901527947
Validation loss: 2.504592497126388

Epoch: 6| Step: 11
Training loss: 2.616981794329687
Validation loss: 2.512042449509681

Epoch: 6| Step: 12
Training loss: 2.903883103511128
Validation loss: 2.5149650801122583

Epoch: 6| Step: 13
Training loss: 3.2044847533074154
Validation loss: 2.535765998347524

Epoch: 60| Step: 0
Training loss: 2.3391759362041062
Validation loss: 2.5606571997642797

Epoch: 6| Step: 1
Training loss: 3.268770446129888
Validation loss: 2.592316579948613

Epoch: 6| Step: 2
Training loss: 2.2423097796442364
Validation loss: 2.567958269911785

Epoch: 6| Step: 3
Training loss: 2.591465874975889
Validation loss: 2.557142305750141

Epoch: 6| Step: 4
Training loss: 2.9353249796583096
Validation loss: 2.5446925150379447

Epoch: 6| Step: 5
Training loss: 2.9111519767798417
Validation loss: 2.5424336836612214

Epoch: 6| Step: 6
Training loss: 3.1513877657563327
Validation loss: 2.5520284044500157

Epoch: 6| Step: 7
Training loss: 2.9865507014218067
Validation loss: 2.5490424654818837

Epoch: 6| Step: 8
Training loss: 2.5718982755736435
Validation loss: 2.54561817456369

Epoch: 6| Step: 9
Training loss: 3.363741994881576
Validation loss: 2.5409423068940735

Epoch: 6| Step: 10
Training loss: 3.819641179113899
Validation loss: 2.531261493186325

Epoch: 6| Step: 11
Training loss: 2.5640756368445845
Validation loss: 2.521959821102571

Epoch: 6| Step: 12
Training loss: 2.6183813304455823
Validation loss: 2.5300545096857343

Epoch: 6| Step: 13
Training loss: 2.0547358866168715
Validation loss: 2.5166619864799706

Epoch: 61| Step: 0
Training loss: 2.9130510717512075
Validation loss: 2.5241202296900256

Epoch: 6| Step: 1
Training loss: 2.4851328335725817
Validation loss: 2.511298567533086

Epoch: 6| Step: 2
Training loss: 3.0857483624791846
Validation loss: 2.496877095944431

Epoch: 6| Step: 3
Training loss: 3.1939987055919796
Validation loss: 2.4972903775056072

Epoch: 6| Step: 4
Training loss: 3.0534534351876688
Validation loss: 2.4971478446120154

Epoch: 6| Step: 5
Training loss: 2.3558365517283817
Validation loss: 2.4992640181053787

Epoch: 6| Step: 6
Training loss: 2.962531393021629
Validation loss: 2.499608995768012

Epoch: 6| Step: 7
Training loss: 2.8007092326972685
Validation loss: 2.496840211106733

Epoch: 6| Step: 8
Training loss: 2.905128344591227
Validation loss: 2.4930420750635243

Epoch: 6| Step: 9
Training loss: 2.5147454281962682
Validation loss: 2.496248094014902

Epoch: 6| Step: 10
Training loss: 2.407835698000525
Validation loss: 2.502707196926842

Epoch: 6| Step: 11
Training loss: 2.630528124010872
Validation loss: 2.517058866576859

Epoch: 6| Step: 12
Training loss: 3.2507668104082543
Validation loss: 2.5084664679812345

Epoch: 6| Step: 13
Training loss: 3.6570167715612776
Validation loss: 2.5068345906565255

Epoch: 62| Step: 0
Training loss: 2.9858487469843755
Validation loss: 2.5054761816619857

Epoch: 6| Step: 1
Training loss: 2.9918324232448743
Validation loss: 2.500338863664434

Epoch: 6| Step: 2
Training loss: 2.9711212325448795
Validation loss: 2.5063886761462837

Epoch: 6| Step: 3
Training loss: 3.0819371817076653
Validation loss: 2.5027097782799776

Epoch: 6| Step: 4
Training loss: 2.8639233377947857
Validation loss: 2.5042070655361615

Epoch: 6| Step: 5
Training loss: 3.348287765423248
Validation loss: 2.504232404859272

Epoch: 6| Step: 6
Training loss: 3.1356199247225254
Validation loss: 2.5185449044295254

Epoch: 6| Step: 7
Training loss: 2.6369806004238483
Validation loss: 2.5154833816515305

Epoch: 6| Step: 8
Training loss: 2.502941118170348
Validation loss: 2.52905119498047

Epoch: 6| Step: 9
Training loss: 2.5059963792438333
Validation loss: 2.5252883053289787

Epoch: 6| Step: 10
Training loss: 2.419313811600356
Validation loss: 2.5290601132936255

Epoch: 6| Step: 11
Training loss: 2.8679251488530566
Validation loss: 2.522187909316059

Epoch: 6| Step: 12
Training loss: 3.180003307508752
Validation loss: 2.524451548808436

Epoch: 6| Step: 13
Training loss: 2.2410188081455082
Validation loss: 2.503799109318138

Epoch: 63| Step: 0
Training loss: 3.503918770009683
Validation loss: 2.495672636912088

Epoch: 6| Step: 1
Training loss: 2.337651571163689
Validation loss: 2.493077491120422

Epoch: 6| Step: 2
Training loss: 2.782619353525338
Validation loss: 2.4946831082640113

Epoch: 6| Step: 3
Training loss: 3.2748193123163776
Validation loss: 2.49340032465254

Epoch: 6| Step: 4
Training loss: 2.656048037760997
Validation loss: 2.489480664767293

Epoch: 6| Step: 5
Training loss: 2.35352352663352
Validation loss: 2.4908697318216375

Epoch: 6| Step: 6
Training loss: 2.959942089236014
Validation loss: 2.49332622227596

Epoch: 6| Step: 7
Training loss: 2.659745284053287
Validation loss: 2.4970431551586505

Epoch: 6| Step: 8
Training loss: 2.743214124342945
Validation loss: 2.511227162659314

Epoch: 6| Step: 9
Training loss: 2.997213022781441
Validation loss: 2.5637988473684126

Epoch: 6| Step: 10
Training loss: 2.6545847441222907
Validation loss: 2.5680110384968655

Epoch: 6| Step: 11
Training loss: 2.843618201251234
Validation loss: 2.6082625286870282

Epoch: 6| Step: 12
Training loss: 3.670637206179555
Validation loss: 2.5913897233789736

Epoch: 6| Step: 13
Training loss: 2.6764589662675595
Validation loss: 2.5594724692860265

Epoch: 64| Step: 0
Training loss: 2.917837852391582
Validation loss: 2.535025674865852

Epoch: 6| Step: 1
Training loss: 2.711606253771809
Validation loss: 2.5236314329302534

Epoch: 6| Step: 2
Training loss: 3.223530894566183
Validation loss: 2.525647519037102

Epoch: 6| Step: 3
Training loss: 3.150474778982973
Validation loss: 2.5173616218118475

Epoch: 6| Step: 4
Training loss: 2.4383283332500527
Validation loss: 2.4918729743268324

Epoch: 6| Step: 5
Training loss: 2.4349668985423745
Validation loss: 2.4892317841681044

Epoch: 6| Step: 6
Training loss: 2.6669477572907963
Validation loss: 2.493397274068828

Epoch: 6| Step: 7
Training loss: 2.8027410952391123
Validation loss: 2.495997879200498

Epoch: 6| Step: 8
Training loss: 3.037915795521046
Validation loss: 2.49905471670941

Epoch: 6| Step: 9
Training loss: 2.940526985375443
Validation loss: 2.495516813952088

Epoch: 6| Step: 10
Training loss: 2.784634363358618
Validation loss: 2.4992879366213328

Epoch: 6| Step: 11
Training loss: 3.5005977665107983
Validation loss: 2.499692614947077

Epoch: 6| Step: 12
Training loss: 2.681990365200957
Validation loss: 2.490899468754803

Epoch: 6| Step: 13
Training loss: 2.7075942473769876
Validation loss: 2.4913066498427376

Epoch: 65| Step: 0
Training loss: 3.2101013134330953
Validation loss: 2.4989546405322605

Epoch: 6| Step: 1
Training loss: 2.882928778724976
Validation loss: 2.5055272303579974

Epoch: 6| Step: 2
Training loss: 2.8085530030076207
Validation loss: 2.5409870587337187

Epoch: 6| Step: 3
Training loss: 3.3514372973409206
Validation loss: 2.5452879417490317

Epoch: 6| Step: 4
Training loss: 2.8273993135396256
Validation loss: 2.557866012054873

Epoch: 6| Step: 5
Training loss: 2.6204330134557976
Validation loss: 2.562494643611197

Epoch: 6| Step: 6
Training loss: 2.7461781387060156
Validation loss: 2.546851028117179

Epoch: 6| Step: 7
Training loss: 2.7274521739763147
Validation loss: 2.5328240584053776

Epoch: 6| Step: 8
Training loss: 2.7490052244623135
Validation loss: 2.502556362918187

Epoch: 6| Step: 9
Training loss: 2.852615454675056
Validation loss: 2.4929591675836034

Epoch: 6| Step: 10
Training loss: 2.7112048454270634
Validation loss: 2.485403844569267

Epoch: 6| Step: 11
Training loss: 2.944527356961724
Validation loss: 2.482074763658191

Epoch: 6| Step: 12
Training loss: 2.5326852379372635
Validation loss: 2.486815302679225

Epoch: 6| Step: 13
Training loss: 3.329888677941488
Validation loss: 2.493354902751047

Epoch: 66| Step: 0
Training loss: 2.933245073059933
Validation loss: 2.4870909822223455

Epoch: 6| Step: 1
Training loss: 2.751265148102075
Validation loss: 2.4851325571061813

Epoch: 6| Step: 2
Training loss: 2.330514385762528
Validation loss: 2.485040949096204

Epoch: 6| Step: 3
Training loss: 3.059995756208681
Validation loss: 2.484165382222968

Epoch: 6| Step: 4
Training loss: 2.779908102972852
Validation loss: 2.487660691286967

Epoch: 6| Step: 5
Training loss: 3.0396086292813522
Validation loss: 2.4819576839265878

Epoch: 6| Step: 6
Training loss: 3.0755382842048746
Validation loss: 2.4863091661829357

Epoch: 6| Step: 7
Training loss: 3.2144622390957194
Validation loss: 2.49969563220854

Epoch: 6| Step: 8
Training loss: 2.389205610979952
Validation loss: 2.496317088296224

Epoch: 6| Step: 9
Training loss: 2.628360686013712
Validation loss: 2.498409289176195

Epoch: 6| Step: 10
Training loss: 3.0654242431358947
Validation loss: 2.5043718745502908

Epoch: 6| Step: 11
Training loss: 2.5198266617635574
Validation loss: 2.5305824386988776

Epoch: 6| Step: 12
Training loss: 2.7817414096080135
Validation loss: 2.5404138727056407

Epoch: 6| Step: 13
Training loss: 3.5676876912134747
Validation loss: 2.529731423592561

Epoch: 67| Step: 0
Training loss: 2.9503752001077985
Validation loss: 2.516707734401274

Epoch: 6| Step: 1
Training loss: 2.9726576936695737
Validation loss: 2.5000769623836048

Epoch: 6| Step: 2
Training loss: 2.956191796663347
Validation loss: 2.487946659732195

Epoch: 6| Step: 3
Training loss: 2.547285737226037
Validation loss: 2.4829178489870563

Epoch: 6| Step: 4
Training loss: 3.0701644900611944
Validation loss: 2.481145514873398

Epoch: 6| Step: 5
Training loss: 3.0492672649788317
Validation loss: 2.478817105865671

Epoch: 6| Step: 6
Training loss: 2.406434683710092
Validation loss: 2.4794296215849534

Epoch: 6| Step: 7
Training loss: 2.8683472660250158
Validation loss: 2.4756027074513907

Epoch: 6| Step: 8
Training loss: 3.0772115058694727
Validation loss: 2.4791949156712074

Epoch: 6| Step: 9
Training loss: 2.879894899463869
Validation loss: 2.484847894901272

Epoch: 6| Step: 10
Training loss: 2.504389342839844
Validation loss: 2.496697162724123

Epoch: 6| Step: 11
Training loss: 3.11745365698783
Validation loss: 2.495900646839105

Epoch: 6| Step: 12
Training loss: 2.602030027610635
Validation loss: 2.5024292269774757

Epoch: 6| Step: 13
Training loss: 2.7760904008453635
Validation loss: 2.490695115249646

Epoch: 68| Step: 0
Training loss: 2.6586495724584127
Validation loss: 2.5019014756695594

Epoch: 6| Step: 1
Training loss: 2.411935603874774
Validation loss: 2.5084803282415526

Epoch: 6| Step: 2
Training loss: 2.611905817971453
Validation loss: 2.5106089181411586

Epoch: 6| Step: 3
Training loss: 2.5440079166960943
Validation loss: 2.51274453927444

Epoch: 6| Step: 4
Training loss: 3.183674030812931
Validation loss: 2.503060227565729

Epoch: 6| Step: 5
Training loss: 3.118822782657197
Validation loss: 2.4946453493356624

Epoch: 6| Step: 6
Training loss: 2.9039351565790383
Validation loss: 2.499597636012046

Epoch: 6| Step: 7
Training loss: 2.469353517570696
Validation loss: 2.4935246890536162

Epoch: 6| Step: 8
Training loss: 2.6245474652362133
Validation loss: 2.4958664695321446

Epoch: 6| Step: 9
Training loss: 2.803043064038396
Validation loss: 2.4866823695898104

Epoch: 6| Step: 10
Training loss: 3.1659083880666636
Validation loss: 2.4849271103406294

Epoch: 6| Step: 11
Training loss: 3.264396472898994
Validation loss: 2.4809690607006227

Epoch: 6| Step: 12
Training loss: 3.1793590629092714
Validation loss: 2.482580003805689

Epoch: 6| Step: 13
Training loss: 2.7113113365428494
Validation loss: 2.4817428746544716

Epoch: 69| Step: 0
Training loss: 3.144117851805183
Validation loss: 2.4784908067980247

Epoch: 6| Step: 1
Training loss: 2.83393019579069
Validation loss: 2.490179107908483

Epoch: 6| Step: 2
Training loss: 2.982723558078015
Validation loss: 2.4802415157973163

Epoch: 6| Step: 3
Training loss: 3.0365551016531835
Validation loss: 2.4885942568714823

Epoch: 6| Step: 4
Training loss: 2.745047878827556
Validation loss: 2.4806460158872823

Epoch: 6| Step: 5
Training loss: 2.1550108071607186
Validation loss: 2.483216293917852

Epoch: 6| Step: 6
Training loss: 2.865556050077411
Validation loss: 2.494197148728834

Epoch: 6| Step: 7
Training loss: 1.9376898641772133
Validation loss: 2.5045645697245655

Epoch: 6| Step: 8
Training loss: 2.878329960817954
Validation loss: 2.5208203549221744

Epoch: 6| Step: 9
Training loss: 2.743328324503013
Validation loss: 2.525673428889806

Epoch: 6| Step: 10
Training loss: 3.0937925393618957
Validation loss: 2.509786503681303

Epoch: 6| Step: 11
Training loss: 2.9890103915389017
Validation loss: 2.510582465809198

Epoch: 6| Step: 12
Training loss: 2.9484933529462407
Validation loss: 2.512111527914426

Epoch: 6| Step: 13
Training loss: 3.4570424225190224
Validation loss: 2.528660196692487

Epoch: 70| Step: 0
Training loss: 2.7889850509532885
Validation loss: 2.499588878216223

Epoch: 6| Step: 1
Training loss: 2.8160472963869556
Validation loss: 2.490599786504683

Epoch: 6| Step: 2
Training loss: 2.613350768939392
Validation loss: 2.4897590815791184

Epoch: 6| Step: 3
Training loss: 3.161367818342105
Validation loss: 2.4862713058577453

Epoch: 6| Step: 4
Training loss: 1.965716007230328
Validation loss: 2.495378626152603

Epoch: 6| Step: 5
Training loss: 2.5625641977595723
Validation loss: 2.4978925969730805

Epoch: 6| Step: 6
Training loss: 2.470391319412091
Validation loss: 2.498967484582229

Epoch: 6| Step: 7
Training loss: 3.2750136921137774
Validation loss: 2.490020569050321

Epoch: 6| Step: 8
Training loss: 3.5154809540802487
Validation loss: 2.4927387983700293

Epoch: 6| Step: 9
Training loss: 2.14027435326665
Validation loss: 2.5027555446144

Epoch: 6| Step: 10
Training loss: 2.9712985694134866
Validation loss: 2.5179216279154546

Epoch: 6| Step: 11
Training loss: 2.9967376136514257
Validation loss: 2.5488055102339446

Epoch: 6| Step: 12
Training loss: 2.968748715049064
Validation loss: 2.550011016754346

Epoch: 6| Step: 13
Training loss: 3.324656223508921
Validation loss: 2.5571548374850193

Epoch: 71| Step: 0
Training loss: 3.072424863264401
Validation loss: 2.5984382557025696

Epoch: 6| Step: 1
Training loss: 2.7237311147496412
Validation loss: 2.629328292332416

Epoch: 6| Step: 2
Training loss: 2.8821539397996485
Validation loss: 2.6710626911795106

Epoch: 6| Step: 3
Training loss: 2.6494297205697457
Validation loss: 2.623048176832808

Epoch: 6| Step: 4
Training loss: 3.397366760650382
Validation loss: 2.562897492039802

Epoch: 6| Step: 5
Training loss: 2.691808839316621
Validation loss: 2.5234125374139955

Epoch: 6| Step: 6
Training loss: 3.345336252597687
Validation loss: 2.515463893498087

Epoch: 6| Step: 7
Training loss: 2.270648832146222
Validation loss: 2.513219080446164

Epoch: 6| Step: 8
Training loss: 2.8686552942139083
Validation loss: 2.51360530255017

Epoch: 6| Step: 9
Training loss: 3.0363123200492423
Validation loss: 2.51825852792737

Epoch: 6| Step: 10
Training loss: 2.6462328351400672
Validation loss: 2.5182009683494013

Epoch: 6| Step: 11
Training loss: 3.066867438945075
Validation loss: 2.523571272334002

Epoch: 6| Step: 12
Training loss: 2.9262676980560127
Validation loss: 2.5134985763212305

Epoch: 6| Step: 13
Training loss: 2.354006488943434
Validation loss: 2.5150071576891473

Epoch: 72| Step: 0
Training loss: 2.58513543635613
Validation loss: 2.51395648258159

Epoch: 6| Step: 1
Training loss: 3.3607368015608174
Validation loss: 2.509738006446218

Epoch: 6| Step: 2
Training loss: 3.4069645683342897
Validation loss: 2.5084313499370907

Epoch: 6| Step: 3
Training loss: 3.0178815078074246
Validation loss: 2.5026727007791747

Epoch: 6| Step: 4
Training loss: 2.5990742649272134
Validation loss: 2.5017838430706703

Epoch: 6| Step: 5
Training loss: 2.63490361784789
Validation loss: 2.497978927585034

Epoch: 6| Step: 6
Training loss: 2.9797663229651983
Validation loss: 2.503333295793168

Epoch: 6| Step: 7
Training loss: 2.97073522747283
Validation loss: 2.5032786650725254

Epoch: 6| Step: 8
Training loss: 2.8140704538761394
Validation loss: 2.5051923810206946

Epoch: 6| Step: 9
Training loss: 2.68336514716708
Validation loss: 2.498554080269093

Epoch: 6| Step: 10
Training loss: 2.831223281835335
Validation loss: 2.5064352743676555

Epoch: 6| Step: 11
Training loss: 2.920121753192287
Validation loss: 2.507871671897376

Epoch: 6| Step: 12
Training loss: 2.5616468544539064
Validation loss: 2.499019107353938

Epoch: 6| Step: 13
Training loss: 2.3729403750536107
Validation loss: 2.503759631507309

Epoch: 73| Step: 0
Training loss: 2.570368154555135
Validation loss: 2.5063841204020463

Epoch: 6| Step: 1
Training loss: 2.98297453770399
Validation loss: 2.5276769357037647

Epoch: 6| Step: 2
Training loss: 2.950428857180627
Validation loss: 2.5503514751978527

Epoch: 6| Step: 3
Training loss: 2.6797989802624147
Validation loss: 2.5386786350712827

Epoch: 6| Step: 4
Training loss: 3.043175745376618
Validation loss: 2.5358488478368684

Epoch: 6| Step: 5
Training loss: 3.3312852925619345
Validation loss: 2.527860098638039

Epoch: 6| Step: 6
Training loss: 2.567630284318017
Validation loss: 2.499406555455959

Epoch: 6| Step: 7
Training loss: 3.18137054514752
Validation loss: 2.497482030565064

Epoch: 6| Step: 8
Training loss: 3.1797462851599154
Validation loss: 2.490762553234917

Epoch: 6| Step: 9
Training loss: 2.509850360315682
Validation loss: 2.497458006474689

Epoch: 6| Step: 10
Training loss: 2.292649410957489
Validation loss: 2.4979126517259562

Epoch: 6| Step: 11
Training loss: 3.0051582812675925
Validation loss: 2.500690331053629

Epoch: 6| Step: 12
Training loss: 2.6792228451579225
Validation loss: 2.5012024674295112

Epoch: 6| Step: 13
Training loss: 2.94866671416682
Validation loss: 2.502008494734298

Epoch: 74| Step: 0
Training loss: 3.3700454514152316
Validation loss: 2.502856806530747

Epoch: 6| Step: 1
Training loss: 3.0998805792171598
Validation loss: 2.4964509989141135

Epoch: 6| Step: 2
Training loss: 2.6412341978265683
Validation loss: 2.494548158803595

Epoch: 6| Step: 3
Training loss: 2.453885100381936
Validation loss: 2.5034296127536857

Epoch: 6| Step: 4
Training loss: 3.0473491593192454
Validation loss: 2.4922846036078927

Epoch: 6| Step: 5
Training loss: 2.444017256149832
Validation loss: 2.5041495279818973

Epoch: 6| Step: 6
Training loss: 3.041123189230452
Validation loss: 2.5076563047950042

Epoch: 6| Step: 7
Training loss: 2.3961076883433647
Validation loss: 2.4966233615160887

Epoch: 6| Step: 8
Training loss: 2.5784059313676
Validation loss: 2.5002869492611124

Epoch: 6| Step: 9
Training loss: 2.9600759576382147
Validation loss: 2.4968101373014107

Epoch: 6| Step: 10
Training loss: 2.6588795829153473
Validation loss: 2.500336296268654

Epoch: 6| Step: 11
Training loss: 2.77679231859297
Validation loss: 2.5016268297676034

Epoch: 6| Step: 12
Training loss: 3.2324292508412826
Validation loss: 2.509501392526889

Epoch: 6| Step: 13
Training loss: 3.1384778630434793
Validation loss: 2.5333591618405906

Epoch: 75| Step: 0
Training loss: 2.6924175250527966
Validation loss: 2.5304554550979175

Epoch: 6| Step: 1
Training loss: 2.6847846929793553
Validation loss: 2.5340428169518603

Epoch: 6| Step: 2
Training loss: 2.5821272793224375
Validation loss: 2.532349511126875

Epoch: 6| Step: 3
Training loss: 2.9511183930151437
Validation loss: 2.51345384911491

Epoch: 6| Step: 4
Training loss: 3.1623743145359655
Validation loss: 2.4782997239721456

Epoch: 6| Step: 5
Training loss: 2.8263960975432156
Validation loss: 2.4713607302695393

Epoch: 6| Step: 6
Training loss: 3.107400698682558
Validation loss: 2.476844813689405

Epoch: 6| Step: 7
Training loss: 2.9033272105114825
Validation loss: 2.474924744909669

Epoch: 6| Step: 8
Training loss: 3.0651706806097327
Validation loss: 2.4741939129842305

Epoch: 6| Step: 9
Training loss: 2.24515754095966
Validation loss: 2.479734861499

Epoch: 6| Step: 10
Training loss: 2.778055907206634
Validation loss: 2.473990839608087

Epoch: 6| Step: 11
Training loss: 2.9440980223632507
Validation loss: 2.4699940213934877

Epoch: 6| Step: 12
Training loss: 3.057154915051179
Validation loss: 2.478089560226724

Epoch: 6| Step: 13
Training loss: 2.9799407451294098
Validation loss: 2.4891779336071793

Epoch: 76| Step: 0
Training loss: 3.027633082191979
Validation loss: 2.516461211929525

Epoch: 6| Step: 1
Training loss: 2.9225177567907648
Validation loss: 2.536653774480914

Epoch: 6| Step: 2
Training loss: 2.004828109032078
Validation loss: 2.523707037734269

Epoch: 6| Step: 3
Training loss: 3.1235036700797956
Validation loss: 2.5321917223425614

Epoch: 6| Step: 4
Training loss: 2.5403932810612093
Validation loss: 2.5352435302777376

Epoch: 6| Step: 5
Training loss: 3.037808274689094
Validation loss: 2.5180884021806405

Epoch: 6| Step: 6
Training loss: 2.497578210837548
Validation loss: 2.5109155345007825

Epoch: 6| Step: 7
Training loss: 2.483895309490378
Validation loss: 2.5094472848030733

Epoch: 6| Step: 8
Training loss: 2.257841855818567
Validation loss: 2.4991781504088593

Epoch: 6| Step: 9
Training loss: 3.423372124065554
Validation loss: 2.4976595197977587

Epoch: 6| Step: 10
Training loss: 3.3269067961488235
Validation loss: 2.4945481762744506

Epoch: 6| Step: 11
Training loss: 3.089740505494982
Validation loss: 2.494481713171518

Epoch: 6| Step: 12
Training loss: 2.848447503989392
Validation loss: 2.4769365478427483

Epoch: 6| Step: 13
Training loss: 2.6949054797694405
Validation loss: 2.4724786393930804

Epoch: 77| Step: 0
Training loss: 2.689658961179579
Validation loss: 2.4803474673734356

Epoch: 6| Step: 1
Training loss: 3.204338476554351
Validation loss: 2.4730783631735838

Epoch: 6| Step: 2
Training loss: 3.004561453251903
Validation loss: 2.482249481604352

Epoch: 6| Step: 3
Training loss: 2.9214062646246726
Validation loss: 2.490656233107009

Epoch: 6| Step: 4
Training loss: 2.873896511436566
Validation loss: 2.501425414676303

Epoch: 6| Step: 5
Training loss: 2.8359396858311996
Validation loss: 2.5254398438827077

Epoch: 6| Step: 6
Training loss: 2.4033226933907343
Validation loss: 2.5485287859671146

Epoch: 6| Step: 7
Training loss: 3.260362098570333
Validation loss: 2.570294796013424

Epoch: 6| Step: 8
Training loss: 2.5640415114078983
Validation loss: 2.5234158280478023

Epoch: 6| Step: 9
Training loss: 2.7400989893274796
Validation loss: 2.495055148511705

Epoch: 6| Step: 10
Training loss: 2.7732904959390248
Validation loss: 2.4704618831098117

Epoch: 6| Step: 11
Training loss: 2.8791584955109624
Validation loss: 2.4576766863180888

Epoch: 6| Step: 12
Training loss: 2.6801317919879084
Validation loss: 2.4616712313343867

Epoch: 6| Step: 13
Training loss: 3.1763127293973494
Validation loss: 2.4647780434778888

Epoch: 78| Step: 0
Training loss: 2.578804527664056
Validation loss: 2.463833560564318

Epoch: 6| Step: 1
Training loss: 2.5890812966971475
Validation loss: 2.4621330861130066

Epoch: 6| Step: 2
Training loss: 3.062150584937649
Validation loss: 2.461849352976293

Epoch: 6| Step: 3
Training loss: 2.5831183887602913
Validation loss: 2.4697706844433496

Epoch: 6| Step: 4
Training loss: 3.0644251163872993
Validation loss: 2.5014440918722123

Epoch: 6| Step: 5
Training loss: 3.4424164725747954
Validation loss: 2.535057680912609

Epoch: 6| Step: 6
Training loss: 2.2871973556679395
Validation loss: 2.553167231920594

Epoch: 6| Step: 7
Training loss: 3.321725055687339
Validation loss: 2.5502756359476857

Epoch: 6| Step: 8
Training loss: 2.7773759413515466
Validation loss: 2.5417999701305054

Epoch: 6| Step: 9
Training loss: 2.8632922413030855
Validation loss: 2.509922927900763

Epoch: 6| Step: 10
Training loss: 2.362813200196888
Validation loss: 2.4919729305971092

Epoch: 6| Step: 11
Training loss: 3.3384117224166854
Validation loss: 2.4811371775747917

Epoch: 6| Step: 12
Training loss: 2.440222857725792
Validation loss: 2.4684044775417835

Epoch: 6| Step: 13
Training loss: 2.676572184369794
Validation loss: 2.458267620523067

Epoch: 79| Step: 0
Training loss: 3.021809930899673
Validation loss: 2.4552979108518964

Epoch: 6| Step: 1
Training loss: 2.589795970907545
Validation loss: 2.457367166115008

Epoch: 6| Step: 2
Training loss: 2.5124957601786657
Validation loss: 2.4642575480897846

Epoch: 6| Step: 3
Training loss: 3.286931813386096
Validation loss: 2.4591213594989623

Epoch: 6| Step: 4
Training loss: 2.9704384268886996
Validation loss: 2.4619729911413857

Epoch: 6| Step: 5
Training loss: 3.075408821531808
Validation loss: 2.4600004189180193

Epoch: 6| Step: 6
Training loss: 2.966511092946594
Validation loss: 2.464084372342512

Epoch: 6| Step: 7
Training loss: 2.8851199955835485
Validation loss: 2.4585871126620575

Epoch: 6| Step: 8
Training loss: 2.3398786997533283
Validation loss: 2.460536446863686

Epoch: 6| Step: 9
Training loss: 2.904889352237478
Validation loss: 2.46751395295793

Epoch: 6| Step: 10
Training loss: 2.965218782892743
Validation loss: 2.4754666080521988

Epoch: 6| Step: 11
Training loss: 1.8971116573510252
Validation loss: 2.49370627502553

Epoch: 6| Step: 12
Training loss: 3.1245853911970984
Validation loss: 2.4964609876872097

Epoch: 6| Step: 13
Training loss: 3.0706522901592987
Validation loss: 2.5346186564792195

Epoch: 80| Step: 0
Training loss: 3.369125198107797
Validation loss: 2.5137175671943575

Epoch: 6| Step: 1
Training loss: 3.318663135835765
Validation loss: 2.5163423848666873

Epoch: 6| Step: 2
Training loss: 2.9244914859954982
Validation loss: 2.536384909097449

Epoch: 6| Step: 3
Training loss: 2.39108710715777
Validation loss: 2.555152586057139

Epoch: 6| Step: 4
Training loss: 2.738322520251139
Validation loss: 2.5568635018762236

Epoch: 6| Step: 5
Training loss: 2.6273942654982885
Validation loss: 2.5313338429531616

Epoch: 6| Step: 6
Training loss: 2.928283517754311
Validation loss: 2.509247243788441

Epoch: 6| Step: 7
Training loss: 2.5063738632987205
Validation loss: 2.488908675686032

Epoch: 6| Step: 8
Training loss: 2.7082839863511947
Validation loss: 2.47880475725578

Epoch: 6| Step: 9
Training loss: 3.037512219565345
Validation loss: 2.464653794509505

Epoch: 6| Step: 10
Training loss: 2.880253511503344
Validation loss: 2.4655992613659694

Epoch: 6| Step: 11
Training loss: 2.845179607172509
Validation loss: 2.469644183374682

Epoch: 6| Step: 12
Training loss: 2.659982370303824
Validation loss: 2.4628579611148114

Epoch: 6| Step: 13
Training loss: 2.2152255366698466
Validation loss: 2.4669940607814382

Epoch: 81| Step: 0
Training loss: 2.753102892852945
Validation loss: 2.4660273437920157

Epoch: 6| Step: 1
Training loss: 2.90436615954261
Validation loss: 2.4619665538461004

Epoch: 6| Step: 2
Training loss: 1.999659688129935
Validation loss: 2.4725948480923097

Epoch: 6| Step: 3
Training loss: 2.9491325719507624
Validation loss: 2.491541789606903

Epoch: 6| Step: 4
Training loss: 3.0890738857987565
Validation loss: 2.503967397033837

Epoch: 6| Step: 5
Training loss: 2.681493745408525
Validation loss: 2.512484100541273

Epoch: 6| Step: 6
Training loss: 2.877558689132059
Validation loss: 2.520824045564008

Epoch: 6| Step: 7
Training loss: 3.071705897538317
Validation loss: 2.513735267826598

Epoch: 6| Step: 8
Training loss: 3.0210411964898247
Validation loss: 2.5263696472619483

Epoch: 6| Step: 9
Training loss: 2.388957819818983
Validation loss: 2.51374405384546

Epoch: 6| Step: 10
Training loss: 2.7810477708309507
Validation loss: 2.5027973716426866

Epoch: 6| Step: 11
Training loss: 2.818186711701426
Validation loss: 2.4988577899611117

Epoch: 6| Step: 12
Training loss: 2.983093785590787
Validation loss: 2.4835669091429757

Epoch: 6| Step: 13
Training loss: 3.0472100489359812
Validation loss: 2.482976419562451

Epoch: 82| Step: 0
Training loss: 2.6966186896709945
Validation loss: 2.493914042356878

Epoch: 6| Step: 1
Training loss: 3.4628840154336245
Validation loss: 2.510897046194466

Epoch: 6| Step: 2
Training loss: 3.0410247194990854
Validation loss: 2.508111135970568

Epoch: 6| Step: 3
Training loss: 2.725619789823588
Validation loss: 2.5240361481321316

Epoch: 6| Step: 4
Training loss: 2.703799301452795
Validation loss: 2.5355359658686276

Epoch: 6| Step: 5
Training loss: 2.775674782581206
Validation loss: 2.5180973079072158

Epoch: 6| Step: 6
Training loss: 2.8868826069868927
Validation loss: 2.4975026003159204

Epoch: 6| Step: 7
Training loss: 1.9684656331398167
Validation loss: 2.478898015662447

Epoch: 6| Step: 8
Training loss: 2.847067438482548
Validation loss: 2.463656911205534

Epoch: 6| Step: 9
Training loss: 2.623010517246163
Validation loss: 2.457905452804704

Epoch: 6| Step: 10
Training loss: 3.067565621044887
Validation loss: 2.457433337330607

Epoch: 6| Step: 11
Training loss: 2.580683230784551
Validation loss: 2.457834650652306

Epoch: 6| Step: 12
Training loss: 3.1040647007796047
Validation loss: 2.455986289178113

Epoch: 6| Step: 13
Training loss: 2.669170505530052
Validation loss: 2.466324395121482

Epoch: 83| Step: 0
Training loss: 2.275991990677027
Validation loss: 2.4595013703233106

Epoch: 6| Step: 1
Training loss: 2.3904837772319194
Validation loss: 2.4728404538322577

Epoch: 6| Step: 2
Training loss: 2.955409543853341
Validation loss: 2.498243208916112

Epoch: 6| Step: 3
Training loss: 3.0443813977206595
Validation loss: 2.510578128029031

Epoch: 6| Step: 4
Training loss: 2.798364594243079
Validation loss: 2.5242528994592233

Epoch: 6| Step: 5
Training loss: 2.7035527414574854
Validation loss: 2.5644222575969153

Epoch: 6| Step: 6
Training loss: 2.3156063763774326
Validation loss: 2.593136286464223

Epoch: 6| Step: 7
Training loss: 2.808517009339279
Validation loss: 2.5666123214112084

Epoch: 6| Step: 8
Training loss: 2.789562020328422
Validation loss: 2.537784245443235

Epoch: 6| Step: 9
Training loss: 2.430637284373136
Validation loss: 2.4849758565720284

Epoch: 6| Step: 10
Training loss: 3.158244796223227
Validation loss: 2.4514575540273107

Epoch: 6| Step: 11
Training loss: 2.6903072156221697
Validation loss: 2.4548802979850106

Epoch: 6| Step: 12
Training loss: 3.6018103392220087
Validation loss: 2.4612244839262947

Epoch: 6| Step: 13
Training loss: 3.3815870642344916
Validation loss: 2.4714902387395896

Epoch: 84| Step: 0
Training loss: 3.121563967922964
Validation loss: 2.464998303481261

Epoch: 6| Step: 1
Training loss: 2.4697493449917953
Validation loss: 2.465693994497204

Epoch: 6| Step: 2
Training loss: 2.8442390775884077
Validation loss: 2.4636015650713143

Epoch: 6| Step: 3
Training loss: 3.0315112758390907
Validation loss: 2.4589857543075078

Epoch: 6| Step: 4
Training loss: 3.520012724159825
Validation loss: 2.45594602923589

Epoch: 6| Step: 5
Training loss: 2.949906790602406
Validation loss: 2.457480130463979

Epoch: 6| Step: 6
Training loss: 2.697903126175727
Validation loss: 2.4549785597772886

Epoch: 6| Step: 7
Training loss: 2.8205168166610224
Validation loss: 2.4767765827217274

Epoch: 6| Step: 8
Training loss: 3.189573324243018
Validation loss: 2.4965753273844147

Epoch: 6| Step: 9
Training loss: 2.5291061741875764
Validation loss: 2.594313150079907

Epoch: 6| Step: 10
Training loss: 2.60775852958916
Validation loss: 2.63591188130127

Epoch: 6| Step: 11
Training loss: 2.4743306304815467
Validation loss: 2.5908466689340246

Epoch: 6| Step: 12
Training loss: 2.679951379534241
Validation loss: 2.5792499945319496

Epoch: 6| Step: 13
Training loss: 2.1929100710985705
Validation loss: 2.5620875543136568

Epoch: 85| Step: 0
Training loss: 3.008530885192672
Validation loss: 2.5080125936090036

Epoch: 6| Step: 1
Training loss: 3.653607840237392
Validation loss: 2.4688693944893028

Epoch: 6| Step: 2
Training loss: 2.804899499898135
Validation loss: 2.4749324899173013

Epoch: 6| Step: 3
Training loss: 2.9509391970651295
Validation loss: 2.459860609015316

Epoch: 6| Step: 4
Training loss: 3.019428917654716
Validation loss: 2.456110241272124

Epoch: 6| Step: 5
Training loss: 2.7887916754015643
Validation loss: 2.456386089732387

Epoch: 6| Step: 6
Training loss: 2.988513733041989
Validation loss: 2.4623887701936757

Epoch: 6| Step: 7
Training loss: 2.295505556592155
Validation loss: 2.4488246029005425

Epoch: 6| Step: 8
Training loss: 2.7293953156725186
Validation loss: 2.457942054134202

Epoch: 6| Step: 9
Training loss: 2.355843534750003
Validation loss: 2.456357275056329

Epoch: 6| Step: 10
Training loss: 2.786466870636503
Validation loss: 2.4621537283613217

Epoch: 6| Step: 11
Training loss: 3.185053765578224
Validation loss: 2.4666508984525968

Epoch: 6| Step: 12
Training loss: 2.333016090170801
Validation loss: 2.484118680500589

Epoch: 6| Step: 13
Training loss: 1.524722061469183
Validation loss: 2.523038669497502

Epoch: 86| Step: 0
Training loss: 2.9710677886799624
Validation loss: 2.550409273153951

Epoch: 6| Step: 1
Training loss: 2.6652084973278387
Validation loss: 2.6522219958566895

Epoch: 6| Step: 2
Training loss: 3.020642785387584
Validation loss: 2.702311413109916

Epoch: 6| Step: 3
Training loss: 3.5215423291473527
Validation loss: 2.6276880087463095

Epoch: 6| Step: 4
Training loss: 2.7059701047995426
Validation loss: 2.528922651407768

Epoch: 6| Step: 5
Training loss: 3.1357338239046824
Validation loss: 2.484044233641298

Epoch: 6| Step: 6
Training loss: 2.3420940398337042
Validation loss: 2.46293061424896

Epoch: 6| Step: 7
Training loss: 2.9853697711662557
Validation loss: 2.458328417743032

Epoch: 6| Step: 8
Training loss: 2.6487134941577395
Validation loss: 2.454843094382958

Epoch: 6| Step: 9
Training loss: 2.1492502235873068
Validation loss: 2.455741228699445

Epoch: 6| Step: 10
Training loss: 2.226637989571449
Validation loss: 2.4545708596438254

Epoch: 6| Step: 11
Training loss: 3.090185713140752
Validation loss: 2.4558910552747815

Epoch: 6| Step: 12
Training loss: 2.755538910983005
Validation loss: 2.448800418663464

Epoch: 6| Step: 13
Training loss: 3.4240870184759054
Validation loss: 2.45355290059796

Epoch: 87| Step: 0
Training loss: 2.7729229516909415
Validation loss: 2.4562357130409858

Epoch: 6| Step: 1
Training loss: 2.1969770860896523
Validation loss: 2.4657977632433545

Epoch: 6| Step: 2
Training loss: 2.7039225730193883
Validation loss: 2.471959287862327

Epoch: 6| Step: 3
Training loss: 2.851784558990815
Validation loss: 2.4724872443679717

Epoch: 6| Step: 4
Training loss: 3.0431586660488223
Validation loss: 2.476481835844505

Epoch: 6| Step: 5
Training loss: 2.866330551432986
Validation loss: 2.461161883298445

Epoch: 6| Step: 6
Training loss: 3.072225891748789
Validation loss: 2.4732900716723867

Epoch: 6| Step: 7
Training loss: 2.7380029643051786
Validation loss: 2.459525166867308

Epoch: 6| Step: 8
Training loss: 2.9872221621998407
Validation loss: 2.452890361252415

Epoch: 6| Step: 9
Training loss: 3.5252269590644856
Validation loss: 2.4631583515629147

Epoch: 6| Step: 10
Training loss: 2.4913766911243345
Validation loss: 2.4663478306303186

Epoch: 6| Step: 11
Training loss: 2.3541482795289843
Validation loss: 2.492384425082113

Epoch: 6| Step: 12
Training loss: 2.5616003178393174
Validation loss: 2.507487526488407

Epoch: 6| Step: 13
Training loss: 2.7650876142751644
Validation loss: 2.52385512215494

Epoch: 88| Step: 0
Training loss: 3.1809494925851056
Validation loss: 2.554764772698896

Epoch: 6| Step: 1
Training loss: 3.196102128709074
Validation loss: 2.5781971364201004

Epoch: 6| Step: 2
Training loss: 2.077648595827538
Validation loss: 2.567656755984989

Epoch: 6| Step: 3
Training loss: 3.2069927403766623
Validation loss: 2.566381844212402

Epoch: 6| Step: 4
Training loss: 2.171902773014028
Validation loss: 2.6185217629829016

Epoch: 6| Step: 5
Training loss: 2.9191104641824723
Validation loss: 2.6428146666924097

Epoch: 6| Step: 6
Training loss: 2.6377561435796038
Validation loss: 2.5816220915015333

Epoch: 6| Step: 7
Training loss: 3.011296936657469
Validation loss: 2.5291018712192526

Epoch: 6| Step: 8
Training loss: 3.054282705506124
Validation loss: 2.480146518635413

Epoch: 6| Step: 9
Training loss: 2.572958375744584
Validation loss: 2.454414282298327

Epoch: 6| Step: 10
Training loss: 2.685629792754025
Validation loss: 2.4512639235851856

Epoch: 6| Step: 11
Training loss: 3.0331496745532007
Validation loss: 2.4466482204248643

Epoch: 6| Step: 12
Training loss: 2.745451981068469
Validation loss: 2.4502257931372284

Epoch: 6| Step: 13
Training loss: 2.694371509766536
Validation loss: 2.4591724436852465

Epoch: 89| Step: 0
Training loss: 2.7641638220227196
Validation loss: 2.4531049192636214

Epoch: 6| Step: 1
Training loss: 2.677774975758938
Validation loss: 2.4623322383248425

Epoch: 6| Step: 2
Training loss: 2.5970509677214406
Validation loss: 2.4584015509510433

Epoch: 6| Step: 3
Training loss: 3.3062916282528207
Validation loss: 2.4546449674815487

Epoch: 6| Step: 4
Training loss: 2.695404316540742
Validation loss: 2.4553592900816947

Epoch: 6| Step: 5
Training loss: 2.1444807758888254
Validation loss: 2.452498110875119

Epoch: 6| Step: 6
Training loss: 2.9677596197029428
Validation loss: 2.462836471206476

Epoch: 6| Step: 7
Training loss: 2.768300804055773
Validation loss: 2.477341450969345

Epoch: 6| Step: 8
Training loss: 2.948279548299631
Validation loss: 2.486878804880901

Epoch: 6| Step: 9
Training loss: 2.6611683806395954
Validation loss: 2.5211570109557098

Epoch: 6| Step: 10
Training loss: 2.76470449182621
Validation loss: 2.5321482517072837

Epoch: 6| Step: 11
Training loss: 3.5834006517577777
Validation loss: 2.53236787014651

Epoch: 6| Step: 12
Training loss: 2.4738722187246527
Validation loss: 2.520101312986001

Epoch: 6| Step: 13
Training loss: 2.914027482300491
Validation loss: 2.5212263846501055

Epoch: 90| Step: 0
Training loss: 2.9800495537855705
Validation loss: 2.5018030084303327

Epoch: 6| Step: 1
Training loss: 2.7172326424760547
Validation loss: 2.4967535125485565

Epoch: 6| Step: 2
Training loss: 2.7545677743254116
Validation loss: 2.4657235838182

Epoch: 6| Step: 3
Training loss: 2.781954558209107
Validation loss: 2.4712868404943884

Epoch: 6| Step: 4
Training loss: 2.1894880797346326
Validation loss: 2.4685558150819955

Epoch: 6| Step: 5
Training loss: 2.134577988094101
Validation loss: 2.4718295571275126

Epoch: 6| Step: 6
Training loss: 2.3810303073573933
Validation loss: 2.4758233427905365

Epoch: 6| Step: 7
Training loss: 2.7876898115049418
Validation loss: 2.481617107837674

Epoch: 6| Step: 8
Training loss: 2.7956397029797944
Validation loss: 2.47703619607787

Epoch: 6| Step: 9
Training loss: 3.2602140873546546
Validation loss: 2.4803505298727884

Epoch: 6| Step: 10
Training loss: 3.178654833414253
Validation loss: 2.4711651041154954

Epoch: 6| Step: 11
Training loss: 2.851211986162913
Validation loss: 2.4615872745593266

Epoch: 6| Step: 12
Training loss: 2.6376287853744764
Validation loss: 2.470268212595255

Epoch: 6| Step: 13
Training loss: 3.6138961681149633
Validation loss: 2.4562083098239427

Epoch: 91| Step: 0
Training loss: 3.26802084614748
Validation loss: 2.456762344417444

Epoch: 6| Step: 1
Training loss: 3.0602477218984685
Validation loss: 2.4486864770299257

Epoch: 6| Step: 2
Training loss: 2.840155373205014
Validation loss: 2.4467147962664533

Epoch: 6| Step: 3
Training loss: 2.360456408317342
Validation loss: 2.4472508062693086

Epoch: 6| Step: 4
Training loss: 2.79660254488681
Validation loss: 2.450835467488111

Epoch: 6| Step: 5
Training loss: 2.953907212098577
Validation loss: 2.4529993712073006

Epoch: 6| Step: 6
Training loss: 2.9443851700900465
Validation loss: 2.4551017534868316

Epoch: 6| Step: 7
Training loss: 2.4314939401038447
Validation loss: 2.4546122816012788

Epoch: 6| Step: 8
Training loss: 2.217977899879859
Validation loss: 2.4574539606363515

Epoch: 6| Step: 9
Training loss: 2.851780378823118
Validation loss: 2.4688353933278013

Epoch: 6| Step: 10
Training loss: 3.3262140223217807
Validation loss: 2.474679526285462

Epoch: 6| Step: 11
Training loss: 2.2163897573229234
Validation loss: 2.5032389516972122

Epoch: 6| Step: 12
Training loss: 2.3921571696007486
Validation loss: 2.5202735422381757

Epoch: 6| Step: 13
Training loss: 3.1206066529712393
Validation loss: 2.5674421851455165

Epoch: 92| Step: 0
Training loss: 3.0709010523485496
Validation loss: 2.6278474797266496

Epoch: 6| Step: 1
Training loss: 2.3681384905191503
Validation loss: 2.5761220998210472

Epoch: 6| Step: 2
Training loss: 2.80503855768858
Validation loss: 2.6637974660979116

Epoch: 6| Step: 3
Training loss: 3.0954535831994296
Validation loss: 2.71918014746382

Epoch: 6| Step: 4
Training loss: 2.7259672110776316
Validation loss: 2.7163604241612163

Epoch: 6| Step: 5
Training loss: 2.805638059236008
Validation loss: 2.6306733810210803

Epoch: 6| Step: 6
Training loss: 1.872878845760835
Validation loss: 2.5639591759605063

Epoch: 6| Step: 7
Training loss: 2.9513234289551873
Validation loss: 2.515822559064833

Epoch: 6| Step: 8
Training loss: 2.5972110682319944
Validation loss: 2.4983266059848233

Epoch: 6| Step: 9
Training loss: 3.210960963550981
Validation loss: 2.493956415482455

Epoch: 6| Step: 10
Training loss: 2.273015563193266
Validation loss: 2.479776179467966

Epoch: 6| Step: 11
Training loss: 3.1659502590992834
Validation loss: 2.464540204058507

Epoch: 6| Step: 12
Training loss: 2.783359541931413
Validation loss: 2.451935231342888

Epoch: 6| Step: 13
Training loss: 3.183659502532261
Validation loss: 2.4540266516181686

Epoch: 93| Step: 0
Training loss: 3.0136818431360584
Validation loss: 2.447018590612063

Epoch: 6| Step: 1
Training loss: 2.43576330280244
Validation loss: 2.4633515413882905

Epoch: 6| Step: 2
Training loss: 2.9214581686926304
Validation loss: 2.4578301749273095

Epoch: 6| Step: 3
Training loss: 2.6485592974448013
Validation loss: 2.4494236364215074

Epoch: 6| Step: 4
Training loss: 2.5338942291657736
Validation loss: 2.4509122969839257

Epoch: 6| Step: 5
Training loss: 2.6903504624791754
Validation loss: 2.449506486263258

Epoch: 6| Step: 6
Training loss: 2.9484813854709597
Validation loss: 2.4374507565673795

Epoch: 6| Step: 7
Training loss: 2.865738754760222
Validation loss: 2.4454001563952437

Epoch: 6| Step: 8
Training loss: 3.2295640926471214
Validation loss: 2.4547641362892527

Epoch: 6| Step: 9
Training loss: 2.6644779004515367
Validation loss: 2.4566876284152386

Epoch: 6| Step: 10
Training loss: 2.5432005980199044
Validation loss: 2.4897730820195516

Epoch: 6| Step: 11
Training loss: 2.6377969077528114
Validation loss: 2.5449203297164424

Epoch: 6| Step: 12
Training loss: 3.137915813962761
Validation loss: 2.548779855649134

Epoch: 6| Step: 13
Training loss: 3.3317593355126043
Validation loss: 2.5328985882173565

Epoch: 94| Step: 0
Training loss: 2.720101557686929
Validation loss: 2.4994988205724273

Epoch: 6| Step: 1
Training loss: 2.499218914083253
Validation loss: 2.4845088324961306

Epoch: 6| Step: 2
Training loss: 2.394094604707141
Validation loss: 2.452357737363746

Epoch: 6| Step: 3
Training loss: 3.121982185425356
Validation loss: 2.4499625163154386

Epoch: 6| Step: 4
Training loss: 1.8171334728498194
Validation loss: 2.4698197381173546

Epoch: 6| Step: 5
Training loss: 3.3212805918647494
Validation loss: 2.4742601253108534

Epoch: 6| Step: 6
Training loss: 2.735368820511873
Validation loss: 2.4715545101792085

Epoch: 6| Step: 7
Training loss: 2.722113447113753
Validation loss: 2.4803338767763474

Epoch: 6| Step: 8
Training loss: 2.7990249809466907
Validation loss: 2.463261161138349

Epoch: 6| Step: 9
Training loss: 2.4912210820917515
Validation loss: 2.4565365887120456

Epoch: 6| Step: 10
Training loss: 3.1350497583459003
Validation loss: 2.4499728955344797

Epoch: 6| Step: 11
Training loss: 2.4810651888111224
Validation loss: 2.4640562558127366

Epoch: 6| Step: 12
Training loss: 2.9564009968622402
Validation loss: 2.4574797705603224

Epoch: 6| Step: 13
Training loss: 3.6981409712268145
Validation loss: 2.4608270394099705

Epoch: 95| Step: 0
Training loss: 2.9824273110011035
Validation loss: 2.461628024404578

Epoch: 6| Step: 1
Training loss: 2.6884914609785158
Validation loss: 2.454950112873389

Epoch: 6| Step: 2
Training loss: 2.8760665905370004
Validation loss: 2.4675358457605054

Epoch: 6| Step: 3
Training loss: 2.488972374768519
Validation loss: 2.483694738630856

Epoch: 6| Step: 4
Training loss: 2.78604244562966
Validation loss: 2.498450887294891

Epoch: 6| Step: 5
Training loss: 2.0560319222521386
Validation loss: 2.5165609652786536

Epoch: 6| Step: 6
Training loss: 2.5398546127701898
Validation loss: 2.5744446738363576

Epoch: 6| Step: 7
Training loss: 3.3246889241342177
Validation loss: 2.6195900911530337

Epoch: 6| Step: 8
Training loss: 2.6742979964590234
Validation loss: 2.5768988852427746

Epoch: 6| Step: 9
Training loss: 2.857180894870961
Validation loss: 2.5450004454887805

Epoch: 6| Step: 10
Training loss: 3.3755566173309317
Validation loss: 2.5239860151610816

Epoch: 6| Step: 11
Training loss: 2.7387613047127517
Validation loss: 2.508009141704334

Epoch: 6| Step: 12
Training loss: 2.412065488593676
Validation loss: 2.487235317988246

Epoch: 6| Step: 13
Training loss: 2.9755586949031883
Validation loss: 2.4729033372959366

Epoch: 96| Step: 0
Training loss: 2.6783430547088765
Validation loss: 2.4605171267780204

Epoch: 6| Step: 1
Training loss: 2.9448929950852953
Validation loss: 2.4588582511044077

Epoch: 6| Step: 2
Training loss: 2.8749180657694744
Validation loss: 2.4612811157120915

Epoch: 6| Step: 3
Training loss: 3.1938792700836576
Validation loss: 2.4647914593020164

Epoch: 6| Step: 4
Training loss: 2.6125631443405353
Validation loss: 2.4699178300873315

Epoch: 6| Step: 5
Training loss: 2.7697688378785696
Validation loss: 2.4755439354910838

Epoch: 6| Step: 6
Training loss: 2.321997650316152
Validation loss: 2.472419544315564

Epoch: 6| Step: 7
Training loss: 2.8666326417308374
Validation loss: 2.4765355970575706

Epoch: 6| Step: 8
Training loss: 3.1352511306272755
Validation loss: 2.4952710720556106

Epoch: 6| Step: 9
Training loss: 2.7206317922383376
Validation loss: 2.496599471895547

Epoch: 6| Step: 10
Training loss: 2.3544537079497694
Validation loss: 2.515678025592976

Epoch: 6| Step: 11
Training loss: 2.276223484578262
Validation loss: 2.516019121390413

Epoch: 6| Step: 12
Training loss: 3.26367041395464
Validation loss: 2.49595620835882

Epoch: 6| Step: 13
Training loss: 1.992547156088214
Validation loss: 2.5010087203451232

Epoch: 97| Step: 0
Training loss: 2.6832021013791905
Validation loss: 2.4933832600485104

Epoch: 6| Step: 1
Training loss: 2.7153384848787048
Validation loss: 2.4941941669573517

Epoch: 6| Step: 2
Training loss: 2.9594758384144955
Validation loss: 2.4827910007060776

Epoch: 6| Step: 3
Training loss: 2.4785581424273806
Validation loss: 2.4846108618006815

Epoch: 6| Step: 4
Training loss: 2.9699638695879305
Validation loss: 2.5020810561465905

Epoch: 6| Step: 5
Training loss: 2.683415880374926
Validation loss: 2.4972117770208406

Epoch: 6| Step: 6
Training loss: 2.9435678672735923
Validation loss: 2.494360104674287

Epoch: 6| Step: 7
Training loss: 3.149806328526654
Validation loss: 2.497402166303607

Epoch: 6| Step: 8
Training loss: 2.705174545607841
Validation loss: 2.48651590094073

Epoch: 6| Step: 9
Training loss: 2.9947466949182253
Validation loss: 2.4872861308839136

Epoch: 6| Step: 10
Training loss: 3.012062617163992
Validation loss: 2.495520294436919

Epoch: 6| Step: 11
Training loss: 2.1907152796711107
Validation loss: 2.5020920455057025

Epoch: 6| Step: 12
Training loss: 2.7071545505378976
Validation loss: 2.516345728554345

Epoch: 6| Step: 13
Training loss: 2.2037996381945426
Validation loss: 2.5287664077237273

Epoch: 98| Step: 0
Training loss: 2.6338361340574883
Validation loss: 2.5668544852655115

Epoch: 6| Step: 1
Training loss: 2.602951458003896
Validation loss: 2.6160097487055287

Epoch: 6| Step: 2
Training loss: 2.782776917064626
Validation loss: 2.6856136870813017

Epoch: 6| Step: 3
Training loss: 2.399702204666559
Validation loss: 2.7596581127077573

Epoch: 6| Step: 4
Training loss: 3.3797025062062107
Validation loss: 2.7791023788498284

Epoch: 6| Step: 5
Training loss: 2.3965936090248694
Validation loss: 2.6820717966484047

Epoch: 6| Step: 6
Training loss: 2.7146041654625237
Validation loss: 2.579847294640569

Epoch: 6| Step: 7
Training loss: 3.268976417416766
Validation loss: 2.5333580760146908

Epoch: 6| Step: 8
Training loss: 2.7251438067926244
Validation loss: 2.514001104989387

Epoch: 6| Step: 9
Training loss: 2.646923431349729
Validation loss: 2.490822595384414

Epoch: 6| Step: 10
Training loss: 2.907550479781988
Validation loss: 2.4791828160851335

Epoch: 6| Step: 11
Training loss: 3.0178889339833046
Validation loss: 2.4700729171434164

Epoch: 6| Step: 12
Training loss: 3.1637678597864407
Validation loss: 2.4757131725510853

Epoch: 6| Step: 13
Training loss: 2.3087783972001144
Validation loss: 2.4770159914491776

Epoch: 99| Step: 0
Training loss: 3.316737074240452
Validation loss: 2.467367100342522

Epoch: 6| Step: 1
Training loss: 2.4595449231398216
Validation loss: 2.460694220322648

Epoch: 6| Step: 2
Training loss: 2.8601803505326795
Validation loss: 2.447771713653449

Epoch: 6| Step: 3
Training loss: 2.6462449081580934
Validation loss: 2.4366363560382545

Epoch: 6| Step: 4
Training loss: 3.0357445498969446
Validation loss: 2.434733682396402

Epoch: 6| Step: 5
Training loss: 2.163908584574737
Validation loss: 2.43547138919768

Epoch: 6| Step: 6
Training loss: 3.2519821578095893
Validation loss: 2.4417482140380415

Epoch: 6| Step: 7
Training loss: 2.557320733821302
Validation loss: 2.4590093442035923

Epoch: 6| Step: 8
Training loss: 1.5720646889749867
Validation loss: 2.4756430070627307

Epoch: 6| Step: 9
Training loss: 3.444839272037007
Validation loss: 2.502714890785412

Epoch: 6| Step: 10
Training loss: 2.7681315641999333
Validation loss: 2.5517664776495024

Epoch: 6| Step: 11
Training loss: 2.6944948587147346
Validation loss: 2.571317788636813

Epoch: 6| Step: 12
Training loss: 2.7026731080290722
Validation loss: 2.6466546663980517

Epoch: 6| Step: 13
Training loss: 2.2840796909893575
Validation loss: 2.6874260726494525

Epoch: 100| Step: 0
Training loss: 3.378266907992283
Validation loss: 2.8797416179069053

Epoch: 6| Step: 1
Training loss: 2.6426078980792296
Validation loss: 2.866060593270748

Epoch: 6| Step: 2
Training loss: 2.7911302611057853
Validation loss: 2.8102961812537983

Epoch: 6| Step: 3
Training loss: 3.247545342367435
Validation loss: 2.6319346190760795

Epoch: 6| Step: 4
Training loss: 2.122294442655039
Validation loss: 2.500412687469176

Epoch: 6| Step: 5
Training loss: 2.7072130282582294
Validation loss: 2.464863346114849

Epoch: 6| Step: 6
Training loss: 3.0645755818725173
Validation loss: 2.4482672369407203

Epoch: 6| Step: 7
Training loss: 3.0090972930706377
Validation loss: 2.443055981382009

Epoch: 6| Step: 8
Training loss: 2.7128507255547745
Validation loss: 2.4542392551239

Epoch: 6| Step: 9
Training loss: 3.018795896066737
Validation loss: 2.4555833959194513

Epoch: 6| Step: 10
Training loss: 2.606638678606159
Validation loss: 2.4647279673865707

Epoch: 6| Step: 11
Training loss: 2.4852327989183096
Validation loss: 2.490143095720611

Epoch: 6| Step: 12
Training loss: 3.170512691398405
Validation loss: 2.4766378357932335

Epoch: 6| Step: 13
Training loss: 3.1077592955456335
Validation loss: 2.469787386966478

Epoch: 101| Step: 0
Training loss: 3.085836442668879
Validation loss: 2.4688373818645233

Epoch: 6| Step: 1
Training loss: 2.60903435042531
Validation loss: 2.4677648503703873

Epoch: 6| Step: 2
Training loss: 2.640475026222597
Validation loss: 2.4641284533007615

Epoch: 6| Step: 3
Training loss: 2.758739110443789
Validation loss: 2.4703603123814784

Epoch: 6| Step: 4
Training loss: 3.1582396628413645
Validation loss: 2.492734918050257

Epoch: 6| Step: 5
Training loss: 2.521005030898235
Validation loss: 2.498764730676813

Epoch: 6| Step: 6
Training loss: 3.1212211649719643
Validation loss: 2.4946445385138794

Epoch: 6| Step: 7
Training loss: 2.989556253733701
Validation loss: 2.5142814856409976

Epoch: 6| Step: 8
Training loss: 2.673377612818244
Validation loss: 2.5149993363017913

Epoch: 6| Step: 9
Training loss: 2.687318219091822
Validation loss: 2.5018119449732885

Epoch: 6| Step: 10
Training loss: 3.0633311798065996
Validation loss: 2.490068859862727

Epoch: 6| Step: 11
Training loss: 2.699127063215318
Validation loss: 2.4866529018236996

Epoch: 6| Step: 12
Training loss: 2.3928118906846105
Validation loss: 2.483527962368783

Epoch: 6| Step: 13
Training loss: 1.3084681208644258
Validation loss: 2.4864639350693323

Epoch: 102| Step: 0
Training loss: 2.8613432900088744
Validation loss: 2.4789021441279306

Epoch: 6| Step: 1
Training loss: 2.400896731378943
Validation loss: 2.468974391302975

Epoch: 6| Step: 2
Training loss: 2.487073092992093
Validation loss: 2.4701547412527645

Epoch: 6| Step: 3
Training loss: 2.648832578645469
Validation loss: 2.472269726007602

Epoch: 6| Step: 4
Training loss: 2.802048570684378
Validation loss: 2.485214468216204

Epoch: 6| Step: 5
Training loss: 2.5458002923880625
Validation loss: 2.4986173990451457

Epoch: 6| Step: 6
Training loss: 3.0530740911325465
Validation loss: 2.5064983715486573

Epoch: 6| Step: 7
Training loss: 2.6695653737393226
Validation loss: 2.5074428065685077

Epoch: 6| Step: 8
Training loss: 2.53014811327275
Validation loss: 2.503230866182447

Epoch: 6| Step: 9
Training loss: 3.0682103383700663
Validation loss: 2.502084777503195

Epoch: 6| Step: 10
Training loss: 2.9742162874300284
Validation loss: 2.494191933452972

Epoch: 6| Step: 11
Training loss: 2.6944194696411596
Validation loss: 2.498490531073475

Epoch: 6| Step: 12
Training loss: 2.5141497723099557
Validation loss: 2.493783025579177

Epoch: 6| Step: 13
Training loss: 2.9793833584885276
Validation loss: 2.4913449687368896

Epoch: 103| Step: 0
Training loss: 2.550486058304565
Validation loss: 2.4894988950611214

Epoch: 6| Step: 1
Training loss: 2.8615780874179593
Validation loss: 2.482109065800122

Epoch: 6| Step: 2
Training loss: 2.8156537493763243
Validation loss: 2.4642060283373985

Epoch: 6| Step: 3
Training loss: 2.7257076989328795
Validation loss: 2.4726475035716797

Epoch: 6| Step: 4
Training loss: 2.9469624155454874
Validation loss: 2.4735041811049268

Epoch: 6| Step: 5
Training loss: 2.999009763685858
Validation loss: 2.477962916892658

Epoch: 6| Step: 6
Training loss: 3.005648381869471
Validation loss: 2.4822208194709914

Epoch: 6| Step: 7
Training loss: 2.8325740320374075
Validation loss: 2.5028922076455027

Epoch: 6| Step: 8
Training loss: 2.8922929230389394
Validation loss: 2.5217980274841962

Epoch: 6| Step: 9
Training loss: 2.302035393079083
Validation loss: 2.5226841045129373

Epoch: 6| Step: 10
Training loss: 2.1927206683925675
Validation loss: 2.5507935185102766

Epoch: 6| Step: 11
Training loss: 3.0105918824487015
Validation loss: 2.5436335544439626

Epoch: 6| Step: 12
Training loss: 2.4736127645506185
Validation loss: 2.5258213594554846

Epoch: 6| Step: 13
Training loss: 2.0254523066487615
Validation loss: 2.5235773980711422

Epoch: 104| Step: 0
Training loss: 2.998530345789274
Validation loss: 2.5120797729437023

Epoch: 6| Step: 1
Training loss: 3.068804732259974
Validation loss: 2.5218716632775044

Epoch: 6| Step: 2
Training loss: 2.9738789473770355
Validation loss: 2.5239798497871173

Epoch: 6| Step: 3
Training loss: 3.219267720186664
Validation loss: 2.5100832093771777

Epoch: 6| Step: 4
Training loss: 1.9776838536885466
Validation loss: 2.52126363568057

Epoch: 6| Step: 5
Training loss: 2.2627806600083042
Validation loss: 2.5097500302278064

Epoch: 6| Step: 6
Training loss: 2.5722941727962154
Validation loss: 2.5143545258835216

Epoch: 6| Step: 7
Training loss: 2.615965782945003
Validation loss: 2.5029192666982283

Epoch: 6| Step: 8
Training loss: 2.297567250260635
Validation loss: 2.5103856080001523

Epoch: 6| Step: 9
Training loss: 2.3663506870037367
Validation loss: 2.513566802851063

Epoch: 6| Step: 10
Training loss: 2.741078818317036
Validation loss: 2.5349830911998823

Epoch: 6| Step: 11
Training loss: 2.5475491058737965
Validation loss: 2.5282617672294285

Epoch: 6| Step: 12
Training loss: 3.147220196395481
Validation loss: 2.5340307536498927

Epoch: 6| Step: 13
Training loss: 2.7044951213468957
Validation loss: 2.5260026494674825

Epoch: 105| Step: 0
Training loss: 2.915360312595735
Validation loss: 2.4990255333249305

Epoch: 6| Step: 1
Training loss: 2.871085778050157
Validation loss: 2.4867595492958032

Epoch: 6| Step: 2
Training loss: 2.763214094981529
Validation loss: 2.4729646714173854

Epoch: 6| Step: 3
Training loss: 3.0975962148383163
Validation loss: 2.476115990717103

Epoch: 6| Step: 4
Training loss: 2.86255756303638
Validation loss: 2.475409845115551

Epoch: 6| Step: 5
Training loss: 1.7487107023414132
Validation loss: 2.47522122664418

Epoch: 6| Step: 6
Training loss: 2.3462027367865064
Validation loss: 2.4732407017494076

Epoch: 6| Step: 7
Training loss: 2.5435548449737917
Validation loss: 2.468616061914754

Epoch: 6| Step: 8
Training loss: 3.03676002185864
Validation loss: 2.482018401806173

Epoch: 6| Step: 9
Training loss: 2.309880603165217
Validation loss: 2.5141457210984632

Epoch: 6| Step: 10
Training loss: 2.213276734298694
Validation loss: 2.586618821774963

Epoch: 6| Step: 11
Training loss: 2.616895061495286
Validation loss: 2.6532130562283025

Epoch: 6| Step: 12
Training loss: 3.0730232522012155
Validation loss: 2.769916238009608

Epoch: 6| Step: 13
Training loss: 3.703423081645882
Validation loss: 2.7926628479369944

Epoch: 106| Step: 0
Training loss: 3.297234538211619
Validation loss: 2.7033343850784903

Epoch: 6| Step: 1
Training loss: 2.5892499009836136
Validation loss: 2.5968994686382243

Epoch: 6| Step: 2
Training loss: 3.0831623201800658
Validation loss: 2.50568981983104

Epoch: 6| Step: 3
Training loss: 2.7353142569305415
Validation loss: 2.4625631202814633

Epoch: 6| Step: 4
Training loss: 2.567424043982344
Validation loss: 2.4710018832227436

Epoch: 6| Step: 5
Training loss: 2.9164067470448947
Validation loss: 2.4720284015873615

Epoch: 6| Step: 6
Training loss: 2.692476942695068
Validation loss: 2.471886158556773

Epoch: 6| Step: 7
Training loss: 2.831617696098022
Validation loss: 2.4838555204938997

Epoch: 6| Step: 8
Training loss: 2.450575846514999
Validation loss: 2.489962381415706

Epoch: 6| Step: 9
Training loss: 2.6215481541889414
Validation loss: 2.4892163491244217

Epoch: 6| Step: 10
Training loss: 3.074458383141722
Validation loss: 2.4902241584428313

Epoch: 6| Step: 11
Training loss: 2.2647372907321315
Validation loss: 2.494860068071222

Epoch: 6| Step: 12
Training loss: 2.5639217433383443
Validation loss: 2.4752170153956747

Epoch: 6| Step: 13
Training loss: 3.120329150908565
Validation loss: 2.4797566846595682

Epoch: 107| Step: 0
Training loss: 1.7259512116928575
Validation loss: 2.483460188570735

Epoch: 6| Step: 1
Training loss: 3.024752072349423
Validation loss: 2.505408220851059

Epoch: 6| Step: 2
Training loss: 2.731512347787526
Validation loss: 2.516978501062688

Epoch: 6| Step: 3
Training loss: 2.7809125717011156
Validation loss: 2.5319034407005288

Epoch: 6| Step: 4
Training loss: 2.5478959172907123
Validation loss: 2.517353684514941

Epoch: 6| Step: 5
Training loss: 2.3633344155628793
Validation loss: 2.5195035522902294

Epoch: 6| Step: 6
Training loss: 2.8692744089490807
Validation loss: 2.528067312329405

Epoch: 6| Step: 7
Training loss: 3.000010490399139
Validation loss: 2.53008624880181

Epoch: 6| Step: 8
Training loss: 2.8443406717755697
Validation loss: 2.544106776875038

Epoch: 6| Step: 9
Training loss: 1.9412880445143352
Validation loss: 2.5582987723247856

Epoch: 6| Step: 10
Training loss: 2.7885783654183625
Validation loss: 2.5772141484275015

Epoch: 6| Step: 11
Training loss: 3.105043854826058
Validation loss: 2.580806969208823

Epoch: 6| Step: 12
Training loss: 2.3603586331736257
Validation loss: 2.6140457291552983

Epoch: 6| Step: 13
Training loss: 2.971629462944373
Validation loss: 2.603963521273653

Epoch: 108| Step: 0
Training loss: 1.825985169683693
Validation loss: 2.5880515893527276

Epoch: 6| Step: 1
Training loss: 2.9531036860589968
Validation loss: 2.5851845957090505

Epoch: 6| Step: 2
Training loss: 3.2867443768313978
Validation loss: 2.5708309901996267

Epoch: 6| Step: 3
Training loss: 2.842026072694615
Validation loss: 2.586833720606644

Epoch: 6| Step: 4
Training loss: 2.0527594625607777
Validation loss: 2.582767599946219

Epoch: 6| Step: 5
Training loss: 2.6662527796305615
Validation loss: 2.557421002042271

Epoch: 6| Step: 6
Training loss: 2.2912006482325866
Validation loss: 2.542766287450964

Epoch: 6| Step: 7
Training loss: 2.7314489785348117
Validation loss: 2.5381894229677098

Epoch: 6| Step: 8
Training loss: 2.864428447813211
Validation loss: 2.5355141273645434

Epoch: 6| Step: 9
Training loss: 2.3050956752556973
Validation loss: 2.5188570349615342

Epoch: 6| Step: 10
Training loss: 2.5811332029653555
Validation loss: 2.5215941518089497

Epoch: 6| Step: 11
Training loss: 2.729258955542902
Validation loss: 2.517826326575653

Epoch: 6| Step: 12
Training loss: 2.9738228272110634
Validation loss: 2.5117140089747596

Epoch: 6| Step: 13
Training loss: 2.290756484105243
Validation loss: 2.517379276453846

Epoch: 109| Step: 0
Training loss: 2.76447138460238
Validation loss: 2.5212216884493306

Epoch: 6| Step: 1
Training loss: 2.574951252892557
Validation loss: 2.5282962640620648

Epoch: 6| Step: 2
Training loss: 2.864339052824175
Validation loss: 2.522883579550712

Epoch: 6| Step: 3
Training loss: 2.736163094204799
Validation loss: 2.5348244883589053

Epoch: 6| Step: 4
Training loss: 2.118594894808374
Validation loss: 2.5368481522827984

Epoch: 6| Step: 5
Training loss: 2.999869661678745
Validation loss: 2.5462781552931917

Epoch: 6| Step: 6
Training loss: 2.022545931074111
Validation loss: 2.543669317293788

Epoch: 6| Step: 7
Training loss: 3.1255007533364068
Validation loss: 2.557661344870451

Epoch: 6| Step: 8
Training loss: 2.4279832167697384
Validation loss: 2.5657910568470226

Epoch: 6| Step: 9
Training loss: 2.470953525323838
Validation loss: 2.5858391405788392

Epoch: 6| Step: 10
Training loss: 2.8724728963318578
Validation loss: 2.61713032948536

Epoch: 6| Step: 11
Training loss: 2.6124276219613383
Validation loss: 2.6022964009482723

Epoch: 6| Step: 12
Training loss: 2.0542174987487396
Validation loss: 2.5618800657182663

Epoch: 6| Step: 13
Training loss: 2.8598395632046403
Validation loss: 2.5257364474119193

Epoch: 110| Step: 0
Training loss: 2.9350257355115703
Validation loss: 2.5278652201129583

Epoch: 6| Step: 1
Training loss: 2.5548029415633895
Validation loss: 2.511828609653877

Epoch: 6| Step: 2
Training loss: 2.130477353544807
Validation loss: 2.529524079674785

Epoch: 6| Step: 3
Training loss: 2.5996288181325866
Validation loss: 2.509680436341544

Epoch: 6| Step: 4
Training loss: 2.9138838071468696
Validation loss: 2.51494453596045

Epoch: 6| Step: 5
Training loss: 1.88537518225567
Validation loss: 2.5224122408239618

Epoch: 6| Step: 6
Training loss: 3.0520360810633127
Validation loss: 2.5176836081099188

Epoch: 6| Step: 7
Training loss: 1.994459464861675
Validation loss: 2.524192885706382

Epoch: 6| Step: 8
Training loss: 3.18859590128889
Validation loss: 2.525078190377006

Epoch: 6| Step: 9
Training loss: 2.4584434829431574
Validation loss: 2.5247535627542987

Epoch: 6| Step: 10
Training loss: 2.139682757312616
Validation loss: 2.5400618703740347

Epoch: 6| Step: 11
Training loss: 2.7871547981308638
Validation loss: 2.5791649921805484

Epoch: 6| Step: 12
Training loss: 2.6891634029450975
Validation loss: 2.575844426676227

Epoch: 6| Step: 13
Training loss: 3.0745198006680177
Validation loss: 2.5885696757901195

Epoch: 111| Step: 0
Training loss: 2.5915793102624924
Validation loss: 2.6004412485673676

Epoch: 6| Step: 1
Training loss: 2.393949005380555
Validation loss: 2.5851323343628625

Epoch: 6| Step: 2
Training loss: 3.279000810228104
Validation loss: 2.5747888223797766

Epoch: 6| Step: 3
Training loss: 2.453752765391614
Validation loss: 2.568517546982859

Epoch: 6| Step: 4
Training loss: 2.235750855147215
Validation loss: 2.5570957132237657

Epoch: 6| Step: 5
Training loss: 2.3190962047155512
Validation loss: 2.55682206399788

Epoch: 6| Step: 6
Training loss: 2.510542479933089
Validation loss: 2.548738858672166

Epoch: 6| Step: 7
Training loss: 2.4918539846513386
Validation loss: 2.519807763716285

Epoch: 6| Step: 8
Training loss: 2.6792329897663154
Validation loss: 2.5367472154093913

Epoch: 6| Step: 9
Training loss: 2.347923124000405
Validation loss: 2.525739252890214

Epoch: 6| Step: 10
Training loss: 3.063756879458725
Validation loss: 2.541524992742613

Epoch: 6| Step: 11
Training loss: 2.679680738079114
Validation loss: 2.554626951829461

Epoch: 6| Step: 12
Training loss: 2.674791228088855
Validation loss: 2.5635373506697485

Epoch: 6| Step: 13
Training loss: 1.9259708458227893
Validation loss: 2.5414562054152388

Epoch: 112| Step: 0
Training loss: 2.4748604397969935
Validation loss: 2.522531099551243

Epoch: 6| Step: 1
Training loss: 2.258769218730388
Validation loss: 2.5087749362155503

Epoch: 6| Step: 2
Training loss: 2.915023849677641
Validation loss: 2.5005521287654395

Epoch: 6| Step: 3
Training loss: 2.257721684619297
Validation loss: 2.494926362853642

Epoch: 6| Step: 4
Training loss: 2.307935385250782
Validation loss: 2.5021153555332867

Epoch: 6| Step: 5
Training loss: 2.9117907139324357
Validation loss: 2.4939550452364134

Epoch: 6| Step: 6
Training loss: 2.332077460414227
Validation loss: 2.5024274229013654

Epoch: 6| Step: 7
Training loss: 2.7895257816166015
Validation loss: 2.4885954487618425

Epoch: 6| Step: 8
Training loss: 2.998691273376995
Validation loss: 2.5136584248025056

Epoch: 6| Step: 9
Training loss: 2.064176629352616
Validation loss: 2.5247579137495086

Epoch: 6| Step: 10
Training loss: 2.620296988216702
Validation loss: 2.535745403333829

Epoch: 6| Step: 11
Training loss: 1.9050243377132123
Validation loss: 2.585660876961575

Epoch: 6| Step: 12
Training loss: 3.269738048362166
Validation loss: 2.612043311715419

Epoch: 6| Step: 13
Training loss: 2.755093539081411
Validation loss: 2.5974285550542398

Epoch: 113| Step: 0
Training loss: 2.637498437962363
Validation loss: 2.556759589070694

Epoch: 6| Step: 1
Training loss: 1.9787919810812553
Validation loss: 2.553204011916405

Epoch: 6| Step: 2
Training loss: 2.7491171893704958
Validation loss: 2.5407957924770286

Epoch: 6| Step: 3
Training loss: 2.847161562720563
Validation loss: 2.542554347981098

Epoch: 6| Step: 4
Training loss: 2.2849171048743675
Validation loss: 2.5291365603352425

Epoch: 6| Step: 5
Training loss: 2.629799043643588
Validation loss: 2.5217650195304864

Epoch: 6| Step: 6
Training loss: 2.6415582395939152
Validation loss: 2.5233577491021277

Epoch: 6| Step: 7
Training loss: 2.7293111068902682
Validation loss: 2.5150783961262744

Epoch: 6| Step: 8
Training loss: 2.8410370010711015
Validation loss: 2.5090871122369522

Epoch: 6| Step: 9
Training loss: 2.29920446901491
Validation loss: 2.511405166762316

Epoch: 6| Step: 10
Training loss: 2.171504146831083
Validation loss: 2.5199523141499505

Epoch: 6| Step: 11
Training loss: 1.96885735355326
Validation loss: 2.5215605159233294

Epoch: 6| Step: 12
Training loss: 2.966560761207996
Validation loss: 2.522280614636341

Epoch: 6| Step: 13
Training loss: 2.945090045167636
Validation loss: 2.51953420483854

Epoch: 114| Step: 0
Training loss: 2.340127714372439
Validation loss: 2.505314512579974

Epoch: 6| Step: 1
Training loss: 2.622511819789204
Validation loss: 2.5144944297238747

Epoch: 6| Step: 2
Training loss: 2.5586293458282494
Validation loss: 2.517905490068336

Epoch: 6| Step: 3
Training loss: 2.907605255137318
Validation loss: 2.509615021640716

Epoch: 6| Step: 4
Training loss: 2.8437005342645802
Validation loss: 2.507386308444792

Epoch: 6| Step: 5
Training loss: 2.254573835546674
Validation loss: 2.5095867701185193

Epoch: 6| Step: 6
Training loss: 2.798804187871949
Validation loss: 2.5413159488703854

Epoch: 6| Step: 7
Training loss: 2.7674254682889257
Validation loss: 2.5472141777091037

Epoch: 6| Step: 8
Training loss: 2.464444425854436
Validation loss: 2.545772802941969

Epoch: 6| Step: 9
Training loss: 2.335662111105418
Validation loss: 2.5367717668443293

Epoch: 6| Step: 10
Training loss: 2.6226258213345015
Validation loss: 2.531219221946107

Epoch: 6| Step: 11
Training loss: 2.556349094400811
Validation loss: 2.540351010398039

Epoch: 6| Step: 12
Training loss: 2.122976349305831
Validation loss: 2.548750040645686

Epoch: 6| Step: 13
Training loss: 2.3263233561482464
Validation loss: 2.5411191994882145

Epoch: 115| Step: 0
Training loss: 2.537720122913717
Validation loss: 2.523399032461613

Epoch: 6| Step: 1
Training loss: 2.7876515813420335
Validation loss: 2.532369453460194

Epoch: 6| Step: 2
Training loss: 2.8580015458889645
Validation loss: 2.544380914027207

Epoch: 6| Step: 3
Training loss: 2.192524181132576
Validation loss: 2.5778771065927875

Epoch: 6| Step: 4
Training loss: 2.877209850699698
Validation loss: 2.5582495342544784

Epoch: 6| Step: 5
Training loss: 2.818235525475254
Validation loss: 2.5405056465403066

Epoch: 6| Step: 6
Training loss: 2.168736667207306
Validation loss: 2.535018134692514

Epoch: 6| Step: 7
Training loss: 2.6552840327689493
Validation loss: 2.5215067061134255

Epoch: 6| Step: 8
Training loss: 2.330608093413178
Validation loss: 2.5103855804273776

Epoch: 6| Step: 9
Training loss: 2.1171367118346183
Validation loss: 2.5064734836899643

Epoch: 6| Step: 10
Training loss: 1.9599453669349125
Validation loss: 2.4941689795313655

Epoch: 6| Step: 11
Training loss: 2.671624958318011
Validation loss: 2.502182178355517

Epoch: 6| Step: 12
Training loss: 2.524996249507725
Validation loss: 2.5017858484568376

Epoch: 6| Step: 13
Training loss: 1.9052541664357285
Validation loss: 2.500488657006299

Epoch: 116| Step: 0
Training loss: 2.5918194123749294
Validation loss: 2.498046263350146

Epoch: 6| Step: 1
Training loss: 1.563770083169632
Validation loss: 2.510045026406283

Epoch: 6| Step: 2
Training loss: 2.0638660184341227
Validation loss: 2.511498709026458

Epoch: 6| Step: 3
Training loss: 2.515610688921104
Validation loss: 2.52338316331364

Epoch: 6| Step: 4
Training loss: 2.52228597816218
Validation loss: 2.5140643640888563

Epoch: 6| Step: 5
Training loss: 2.8802795033459896
Validation loss: 2.5328308469995724

Epoch: 6| Step: 6
Training loss: 2.458852314451738
Validation loss: 2.514216705577185

Epoch: 6| Step: 7
Training loss: 2.1281381883926764
Validation loss: 2.5384421469947656

Epoch: 6| Step: 8
Training loss: 2.7976275236161756
Validation loss: 2.5381604168376777

Epoch: 6| Step: 9
Training loss: 2.481249877007239
Validation loss: 2.535616592494029

Epoch: 6| Step: 10
Training loss: 2.46106692988013
Validation loss: 2.547612477865584

Epoch: 6| Step: 11
Training loss: 2.7385051815310595
Validation loss: 2.5379856953132416

Epoch: 6| Step: 12
Training loss: 2.5412670717730803
Validation loss: 2.531861914278046

Epoch: 6| Step: 13
Training loss: 3.0404241105432406
Validation loss: 2.5353357147352686

Epoch: 117| Step: 0
Training loss: 2.5298488176733414
Validation loss: 2.511275567843301

Epoch: 6| Step: 1
Training loss: 2.5011447193078187
Validation loss: 2.5112389771792127

Epoch: 6| Step: 2
Training loss: 2.585666238899912
Validation loss: 2.5396098046983044

Epoch: 6| Step: 3
Training loss: 3.3425285033420877
Validation loss: 2.5643738718925024

Epoch: 6| Step: 4
Training loss: 2.741255642615067
Validation loss: 2.563616553637228

Epoch: 6| Step: 5
Training loss: 2.3135957956887925
Validation loss: 2.5493518877558157

Epoch: 6| Step: 6
Training loss: 2.423866290115525
Validation loss: 2.5497535429631784

Epoch: 6| Step: 7
Training loss: 2.781196079374392
Validation loss: 2.5432783739515865

Epoch: 6| Step: 8
Training loss: 2.5936726937780623
Validation loss: 2.562795468435301

Epoch: 6| Step: 9
Training loss: 2.497304321352046
Validation loss: 2.5680621817994487

Epoch: 6| Step: 10
Training loss: 2.3887187862702404
Validation loss: 2.564958177185705

Epoch: 6| Step: 11
Training loss: 2.0710306325624357
Validation loss: 2.5589779074850965

Epoch: 6| Step: 12
Training loss: 1.76108317953049
Validation loss: 2.5513819849401456

Epoch: 6| Step: 13
Training loss: 1.9089399650689454
Validation loss: 2.5526589901889745

Epoch: 118| Step: 0
Training loss: 3.080676265637483
Validation loss: 2.526984015519066

Epoch: 6| Step: 1
Training loss: 2.27423752803513
Validation loss: 2.515299986058122

Epoch: 6| Step: 2
Training loss: 2.6561329535333322
Validation loss: 2.5104618435226254

Epoch: 6| Step: 3
Training loss: 2.3547775241220457
Validation loss: 2.5126746304169245

Epoch: 6| Step: 4
Training loss: 2.3104644270541934
Validation loss: 2.5143879420939252

Epoch: 6| Step: 5
Training loss: 1.9959258066733414
Validation loss: 2.5239378557750847

Epoch: 6| Step: 6
Training loss: 2.764939735128345
Validation loss: 2.5480578657897035

Epoch: 6| Step: 7
Training loss: 1.9459718253320015
Validation loss: 2.5531612334074705

Epoch: 6| Step: 8
Training loss: 2.563605279506533
Validation loss: 2.5657210396224093

Epoch: 6| Step: 9
Training loss: 2.370110145938757
Validation loss: 2.567668220000184

Epoch: 6| Step: 10
Training loss: 2.730894129284643
Validation loss: 2.5928760137873437

Epoch: 6| Step: 11
Training loss: 2.501509496829031
Validation loss: 2.5904711693352778

Epoch: 6| Step: 12
Training loss: 2.3516841616161157
Validation loss: 2.592466273659248

Epoch: 6| Step: 13
Training loss: 2.3242757838327885
Validation loss: 2.570831467859868

Epoch: 119| Step: 0
Training loss: 2.2749876001041063
Validation loss: 2.5588522037744124

Epoch: 6| Step: 1
Training loss: 2.358601222195434
Validation loss: 2.545893498312588

Epoch: 6| Step: 2
Training loss: 2.7140137206302115
Validation loss: 2.5331295574945103

Epoch: 6| Step: 3
Training loss: 2.3272394121695292
Validation loss: 2.5436619478738116

Epoch: 6| Step: 4
Training loss: 2.6186642252638106
Validation loss: 2.5544757271678424

Epoch: 6| Step: 5
Training loss: 2.433042705720828
Validation loss: 2.5447301207093505

Epoch: 6| Step: 6
Training loss: 2.636903205353639
Validation loss: 2.569170178386341

Epoch: 6| Step: 7
Training loss: 2.737454494986461
Validation loss: 2.6239704343633683

Epoch: 6| Step: 8
Training loss: 2.6312920682538854
Validation loss: 2.637611299954178

Epoch: 6| Step: 9
Training loss: 2.4093144707306413
Validation loss: 2.5876473694619215

Epoch: 6| Step: 10
Training loss: 2.775602371546195
Validation loss: 2.539540071087054

Epoch: 6| Step: 11
Training loss: 2.34701900116584
Validation loss: 2.4865216447308582

Epoch: 6| Step: 12
Training loss: 2.021837345580411
Validation loss: 2.4608646786370767

Epoch: 6| Step: 13
Training loss: 2.5422124016215673
Validation loss: 2.457777647393206

Epoch: 120| Step: 0
Training loss: 2.123876050022834
Validation loss: 2.4574860766906697

Epoch: 6| Step: 1
Training loss: 2.552926205911481
Validation loss: 2.470707100621795

Epoch: 6| Step: 2
Training loss: 2.7189479185828596
Validation loss: 2.479427453878762

Epoch: 6| Step: 3
Training loss: 2.6728182014610575
Validation loss: 2.4847353875522686

Epoch: 6| Step: 4
Training loss: 2.0229739096255983
Validation loss: 2.511632419070191

Epoch: 6| Step: 5
Training loss: 2.5646401748948273
Validation loss: 2.527244328428126

Epoch: 6| Step: 6
Training loss: 3.0492474049563936
Validation loss: 2.552681255468135

Epoch: 6| Step: 7
Training loss: 3.0236929852084566
Validation loss: 2.5648311763099882

Epoch: 6| Step: 8
Training loss: 2.1405866856174214
Validation loss: 2.6054821936199386

Epoch: 6| Step: 9
Training loss: 2.723285268532952
Validation loss: 2.625648455552696

Epoch: 6| Step: 10
Training loss: 2.102111744633541
Validation loss: 2.6132977514243994

Epoch: 6| Step: 11
Training loss: 2.231818170093691
Validation loss: 2.570182744404706

Epoch: 6| Step: 12
Training loss: 1.963445996720397
Validation loss: 2.5313417257797877

Epoch: 6| Step: 13
Training loss: 2.6832252038371354
Validation loss: 2.5273650302039568

Epoch: 121| Step: 0
Training loss: 2.2342966772903905
Validation loss: 2.493465691790998

Epoch: 6| Step: 1
Training loss: 2.6355513185220802
Validation loss: 2.4607394283112294

Epoch: 6| Step: 2
Training loss: 2.6610688424077273
Validation loss: 2.422995538265203

Epoch: 6| Step: 3
Training loss: 2.0345981879795185
Validation loss: 2.4321752886949226

Epoch: 6| Step: 4
Training loss: 2.682837944821004
Validation loss: 2.4253923113812994

Epoch: 6| Step: 5
Training loss: 2.6043635688093283
Validation loss: 2.422316235729259

Epoch: 6| Step: 6
Training loss: 1.6721812885691612
Validation loss: 2.439136333456552

Epoch: 6| Step: 7
Training loss: 2.7109418973419848
Validation loss: 2.458714682059521

Epoch: 6| Step: 8
Training loss: 1.784506247481988
Validation loss: 2.471487140366285

Epoch: 6| Step: 9
Training loss: 2.5347735523153414
Validation loss: 2.4873363233046724

Epoch: 6| Step: 10
Training loss: 2.569028493073574
Validation loss: 2.5230358955634884

Epoch: 6| Step: 11
Training loss: 2.8860386110447167
Validation loss: 2.58464144859479

Epoch: 6| Step: 12
Training loss: 2.2252094641682225
Validation loss: 2.59960529030637

Epoch: 6| Step: 13
Training loss: 2.6212324625937553
Validation loss: 2.549497193516361

Epoch: 122| Step: 0
Training loss: 2.174899622913889
Validation loss: 2.511827508396872

Epoch: 6| Step: 1
Training loss: 2.7966036531747647
Validation loss: 2.508204533293286

Epoch: 6| Step: 2
Training loss: 2.444889702366608
Validation loss: 2.5119209828832205

Epoch: 6| Step: 3
Training loss: 2.7091358365248888
Validation loss: 2.515939936245055

Epoch: 6| Step: 4
Training loss: 2.6613415557464197
Validation loss: 2.5216574318898366

Epoch: 6| Step: 5
Training loss: 2.603702432579782
Validation loss: 2.5318144170657195

Epoch: 6| Step: 6
Training loss: 2.668080898625472
Validation loss: 2.527948855879635

Epoch: 6| Step: 7
Training loss: 2.055557356939586
Validation loss: 2.5471302304448455

Epoch: 6| Step: 8
Training loss: 1.66272606710882
Validation loss: 2.545085114719216

Epoch: 6| Step: 9
Training loss: 2.066364251847548
Validation loss: 2.541211665630425

Epoch: 6| Step: 10
Training loss: 2.0012434431894315
Validation loss: 2.5447939729154783

Epoch: 6| Step: 11
Training loss: 2.467192339514926
Validation loss: 2.5469218016450714

Epoch: 6| Step: 12
Training loss: 3.158288127672949
Validation loss: 2.562011437071008

Epoch: 6| Step: 13
Training loss: 1.589976312232957
Validation loss: 2.583428565369551

Epoch: 123| Step: 0
Training loss: 2.390124100212477
Validation loss: 2.5873560063206287

Epoch: 6| Step: 1
Training loss: 2.078651074815713
Validation loss: 2.585485923742273

Epoch: 6| Step: 2
Training loss: 2.544891052762076
Validation loss: 2.5680742170138986

Epoch: 6| Step: 3
Training loss: 2.201821448838647
Validation loss: 2.540237496659117

Epoch: 6| Step: 4
Training loss: 2.35897631782006
Validation loss: 2.539749878886764

Epoch: 6| Step: 5
Training loss: 2.2386470049793092
Validation loss: 2.5230913929696634

Epoch: 6| Step: 6
Training loss: 2.080414163730714
Validation loss: 2.5241061810819065

Epoch: 6| Step: 7
Training loss: 2.4357802364144887
Validation loss: 2.530982960143813

Epoch: 6| Step: 8
Training loss: 2.291887538554168
Validation loss: 2.5212048980745903

Epoch: 6| Step: 9
Training loss: 2.4717832835238625
Validation loss: 2.5131023223958997

Epoch: 6| Step: 10
Training loss: 2.099781742561365
Validation loss: 2.504148055818883

Epoch: 6| Step: 11
Training loss: 2.790529009801012
Validation loss: 2.49751749554699

Epoch: 6| Step: 12
Training loss: 2.523678605693281
Validation loss: 2.504759702911684

Epoch: 6| Step: 13
Training loss: 2.8247555213399576
Validation loss: 2.51520227676522

Epoch: 124| Step: 0
Training loss: 2.282362366252614
Validation loss: 2.516043627492185

Epoch: 6| Step: 1
Training loss: 2.4440374493141266
Validation loss: 2.5265706688943443

Epoch: 6| Step: 2
Training loss: 2.470337272968616
Validation loss: 2.540716613684626

Epoch: 6| Step: 3
Training loss: 2.194255750996508
Validation loss: 2.553268092739617

Epoch: 6| Step: 4
Training loss: 1.8798265007799704
Validation loss: 2.541635248510145

Epoch: 6| Step: 5
Training loss: 2.34399209361647
Validation loss: 2.53858013004181

Epoch: 6| Step: 6
Training loss: 2.733655388009891
Validation loss: 2.5290946742476255

Epoch: 6| Step: 7
Training loss: 1.6350670540034884
Validation loss: 2.5169554799400977

Epoch: 6| Step: 8
Training loss: 2.406652937010738
Validation loss: 2.493906436478863

Epoch: 6| Step: 9
Training loss: 2.906221779306868
Validation loss: 2.4800720305837265

Epoch: 6| Step: 10
Training loss: 2.574273393945348
Validation loss: 2.4728198904257694

Epoch: 6| Step: 11
Training loss: 2.028915942275054
Validation loss: 2.4661610077002614

Epoch: 6| Step: 12
Training loss: 2.625185278757051
Validation loss: 2.4524326730898167

Epoch: 6| Step: 13
Training loss: 1.9463748099525617
Validation loss: 2.442023001524759

Epoch: 125| Step: 0
Training loss: 1.9202668820108268
Validation loss: 2.4626801008442167

Epoch: 6| Step: 1
Training loss: 2.339541713472352
Validation loss: 2.4757292105711572

Epoch: 6| Step: 2
Training loss: 2.674787662670582
Validation loss: 2.4691209806413656

Epoch: 6| Step: 3
Training loss: 2.088797562318488
Validation loss: 2.4741901952685486

Epoch: 6| Step: 4
Training loss: 1.9927737102828025
Validation loss: 2.473115886432494

Epoch: 6| Step: 5
Training loss: 2.4463625472371042
Validation loss: 2.443586329225102

Epoch: 6| Step: 6
Training loss: 1.854346648778337
Validation loss: 2.4410350870837396

Epoch: 6| Step: 7
Training loss: 2.004036168577259
Validation loss: 2.468746090282679

Epoch: 6| Step: 8
Training loss: 2.2821648213527586
Validation loss: 2.4495607416576757

Epoch: 6| Step: 9
Training loss: 2.760838391220414
Validation loss: 2.461781432232247

Epoch: 6| Step: 10
Training loss: 2.66215397551826
Validation loss: 2.453096093720147

Epoch: 6| Step: 11
Training loss: 2.4268289413620243
Validation loss: 2.4600760889095445

Epoch: 6| Step: 12
Training loss: 2.3422480539099446
Validation loss: 2.448496188386967

Epoch: 6| Step: 13
Training loss: 2.28015925838335
Validation loss: 2.453388660548492

Epoch: 126| Step: 0
Training loss: 2.5660388979739817
Validation loss: 2.48197808279607

Epoch: 6| Step: 1
Training loss: 2.2385582877267343
Validation loss: 2.5029928433495967

Epoch: 6| Step: 2
Training loss: 2.1237261825043254
Validation loss: 2.4966453718023183

Epoch: 6| Step: 3
Training loss: 2.414820283635679
Validation loss: 2.5051559880415226

Epoch: 6| Step: 4
Training loss: 2.089684482102791
Validation loss: 2.501335389332856

Epoch: 6| Step: 5
Training loss: 1.9640042462506977
Validation loss: 2.485294532262581

Epoch: 6| Step: 6
Training loss: 2.0293556182847468
Validation loss: 2.4972809217615692

Epoch: 6| Step: 7
Training loss: 2.481919616743917
Validation loss: 2.5005246852627367

Epoch: 6| Step: 8
Training loss: 2.2278590660242417
Validation loss: 2.5186670206061956

Epoch: 6| Step: 9
Training loss: 2.6714419186829126
Validation loss: 2.508741428890284

Epoch: 6| Step: 10
Training loss: 2.1209416624730664
Validation loss: 2.527520327969064

Epoch: 6| Step: 11
Training loss: 2.5618555142400763
Validation loss: 2.517168366876652

Epoch: 6| Step: 12
Training loss: 2.4117226726968424
Validation loss: 2.5079279025110544

Epoch: 6| Step: 13
Training loss: 2.045070405974588
Validation loss: 2.5231459005393764

Epoch: 127| Step: 0
Training loss: 2.266689287334588
Validation loss: 2.531895997545427

Epoch: 6| Step: 1
Training loss: 2.3864754960236523
Validation loss: 2.534436920677254

Epoch: 6| Step: 2
Training loss: 2.543364275806166
Validation loss: 2.53934472622439

Epoch: 6| Step: 3
Training loss: 2.7076434699569276
Validation loss: 2.5401648650861435

Epoch: 6| Step: 4
Training loss: 2.2000357971746953
Validation loss: 2.5242840793164696

Epoch: 6| Step: 5
Training loss: 2.298222983156782
Validation loss: 2.507296360118035

Epoch: 6| Step: 6
Training loss: 2.131027424843944
Validation loss: 2.5118787688981077

Epoch: 6| Step: 7
Training loss: 2.0474888703692358
Validation loss: 2.4822631391721144

Epoch: 6| Step: 8
Training loss: 2.395253904737024
Validation loss: 2.49396963991137

Epoch: 6| Step: 9
Training loss: 2.014118429965517
Validation loss: 2.4695199191891235

Epoch: 6| Step: 10
Training loss: 1.8635869125352083
Validation loss: 2.4683116379830956

Epoch: 6| Step: 11
Training loss: 2.261325307828829
Validation loss: 2.480098772156095

Epoch: 6| Step: 12
Training loss: 2.272050152392991
Validation loss: 2.4747741935958736

Epoch: 6| Step: 13
Training loss: 2.42575658027034
Validation loss: 2.4794736499603354

Epoch: 128| Step: 0
Training loss: 2.2146280173539354
Validation loss: 2.458864573509052

Epoch: 6| Step: 1
Training loss: 2.2925880545009347
Validation loss: 2.477461318228183

Epoch: 6| Step: 2
Training loss: 2.8906535379186726
Validation loss: 2.46518663404176

Epoch: 6| Step: 3
Training loss: 2.2416993782842733
Validation loss: 2.4736270740190935

Epoch: 6| Step: 4
Training loss: 2.0608737198198703
Validation loss: 2.482937439778406

Epoch: 6| Step: 5
Training loss: 1.8893228255275614
Validation loss: 2.5077381733181157

Epoch: 6| Step: 6
Training loss: 1.7479081594315455
Validation loss: 2.52120551224076

Epoch: 6| Step: 7
Training loss: 2.1002046530774923
Validation loss: 2.5301351549467634

Epoch: 6| Step: 8
Training loss: 2.5916180408818383
Validation loss: 2.5259962860351104

Epoch: 6| Step: 9
Training loss: 2.6732953852610284
Validation loss: 2.507747979123666

Epoch: 6| Step: 10
Training loss: 2.0020601867332783
Validation loss: 2.481054898331795

Epoch: 6| Step: 11
Training loss: 2.303597920076412
Validation loss: 2.4870656888437597

Epoch: 6| Step: 12
Training loss: 2.33663419712742
Validation loss: 2.5024233189050964

Epoch: 6| Step: 13
Training loss: 2.088329529552035
Validation loss: 2.500977592680909

Epoch: 129| Step: 0
Training loss: 2.4680291584153395
Validation loss: 2.4972923854735685

Epoch: 6| Step: 1
Training loss: 2.3940889282918927
Validation loss: 2.486156315943565

Epoch: 6| Step: 2
Training loss: 2.0810735908412337
Validation loss: 2.4785022115756963

Epoch: 6| Step: 3
Training loss: 2.544470652630839
Validation loss: 2.488775350700397

Epoch: 6| Step: 4
Training loss: 2.850049095400184
Validation loss: 2.4879277111880267

Epoch: 6| Step: 5
Training loss: 2.319008611770833
Validation loss: 2.5081313558619045

Epoch: 6| Step: 6
Training loss: 2.4852201355844623
Validation loss: 2.5256342260000246

Epoch: 6| Step: 7
Training loss: 2.5495339771856296
Validation loss: 2.5330758446705532

Epoch: 6| Step: 8
Training loss: 1.8884715276768
Validation loss: 2.5553677955689276

Epoch: 6| Step: 9
Training loss: 2.453507314642728
Validation loss: 2.5264832056939346

Epoch: 6| Step: 10
Training loss: 1.4558583465564352
Validation loss: 2.5228546443726048

Epoch: 6| Step: 11
Training loss: 1.5276296986959539
Validation loss: 2.533697536356438

Epoch: 6| Step: 12
Training loss: 2.1343849729246327
Validation loss: 2.524079060709349

Epoch: 6| Step: 13
Training loss: 2.017351697271301
Validation loss: 2.4958739595319877

Epoch: 130| Step: 0
Training loss: 2.248254522813871
Validation loss: 2.5113261015495723

Epoch: 6| Step: 1
Training loss: 2.0080328794424345
Validation loss: 2.5154226032257765

Epoch: 6| Step: 2
Training loss: 2.5660519057723046
Validation loss: 2.5338125875628625

Epoch: 6| Step: 3
Training loss: 2.2962436976213927
Validation loss: 2.535921332601369

Epoch: 6| Step: 4
Training loss: 2.2175893837376033
Validation loss: 2.565139067838049

Epoch: 6| Step: 5
Training loss: 2.026302474493788
Validation loss: 2.5760017927310437

Epoch: 6| Step: 6
Training loss: 1.8827369009962074
Validation loss: 2.537943976483891

Epoch: 6| Step: 7
Training loss: 2.4353085961904704
Validation loss: 2.496779262246318

Epoch: 6| Step: 8
Training loss: 2.2132665006857764
Validation loss: 2.4737164122727706

Epoch: 6| Step: 9
Training loss: 2.1942229367043526
Validation loss: 2.4691439794898176

Epoch: 6| Step: 10
Training loss: 2.1400096593620987
Validation loss: 2.4793494544855434

Epoch: 6| Step: 11
Training loss: 2.1235499202787804
Validation loss: 2.461908364389735

Epoch: 6| Step: 12
Training loss: 2.4553678913624317
Validation loss: 2.4665043145817176

Epoch: 6| Step: 13
Training loss: 2.059364362813658
Validation loss: 2.445636228674188

Epoch: 131| Step: 0
Training loss: 2.3302601489764956
Validation loss: 2.4391358688948737

Epoch: 6| Step: 1
Training loss: 2.306858294728041
Validation loss: 2.4201936218381626

Epoch: 6| Step: 2
Training loss: 1.8560648713449175
Validation loss: 2.4188082148590513

Epoch: 6| Step: 3
Training loss: 2.3766822880057226
Validation loss: 2.417636084082895

Epoch: 6| Step: 4
Training loss: 2.5347893541988675
Validation loss: 2.434315268228017

Epoch: 6| Step: 5
Training loss: 1.8084930325965305
Validation loss: 2.450024400672843

Epoch: 6| Step: 6
Training loss: 2.1963486584914023
Validation loss: 2.473752345440258

Epoch: 6| Step: 7
Training loss: 1.9625589422619687
Validation loss: 2.5099092992950838

Epoch: 6| Step: 8
Training loss: 1.9585593343418768
Validation loss: 2.5129308166823185

Epoch: 6| Step: 9
Training loss: 2.4984722237622288
Validation loss: 2.5213468864649604

Epoch: 6| Step: 10
Training loss: 2.161779638714331
Validation loss: 2.5045553113597836

Epoch: 6| Step: 11
Training loss: 1.8678960373597555
Validation loss: 2.4802488979389565

Epoch: 6| Step: 12
Training loss: 2.573153609718344
Validation loss: 2.469835962837942

Epoch: 6| Step: 13
Training loss: 1.887189344394804
Validation loss: 2.4535434654154358

Epoch: 132| Step: 0
Training loss: 2.0264742535721063
Validation loss: 2.4519555752043782

Epoch: 6| Step: 1
Training loss: 1.901021446921758
Validation loss: 2.4475437753895353

Epoch: 6| Step: 2
Training loss: 2.336338582898033
Validation loss: 2.4482343276903795

Epoch: 6| Step: 3
Training loss: 2.1239913341683083
Validation loss: 2.4499874288786003

Epoch: 6| Step: 4
Training loss: 2.5275541097129564
Validation loss: 2.4526728724248996

Epoch: 6| Step: 5
Training loss: 1.784551939734552
Validation loss: 2.460963112964284

Epoch: 6| Step: 6
Training loss: 2.3540540910208816
Validation loss: 2.4730762868243565

Epoch: 6| Step: 7
Training loss: 2.246764611940037
Validation loss: 2.4824637234605182

Epoch: 6| Step: 8
Training loss: 2.240372085662191
Validation loss: 2.483476851671879

Epoch: 6| Step: 9
Training loss: 2.109244335507415
Validation loss: 2.491109980198606

Epoch: 6| Step: 10
Training loss: 1.8437847845384658
Validation loss: 2.494952778753341

Epoch: 6| Step: 11
Training loss: 2.2970476150526555
Validation loss: 2.5153819890148874

Epoch: 6| Step: 12
Training loss: 2.1911840751205753
Validation loss: 2.54648201182419

Epoch: 6| Step: 13
Training loss: 2.0731966478159123
Validation loss: 2.551930754275371

Epoch: 133| Step: 0
Training loss: 1.7642422553248271
Validation loss: 2.5595622787321024

Epoch: 6| Step: 1
Training loss: 2.393318603526969
Validation loss: 2.550868080074752

Epoch: 6| Step: 2
Training loss: 2.0054456958404145
Validation loss: 2.54005594789594

Epoch: 6| Step: 3
Training loss: 2.047292652181001
Validation loss: 2.5471404124992776

Epoch: 6| Step: 4
Training loss: 3.001948995097192
Validation loss: 2.5253854477491964

Epoch: 6| Step: 5
Training loss: 1.872998886368762
Validation loss: 2.518408385355232

Epoch: 6| Step: 6
Training loss: 2.23984492940243
Validation loss: 2.510698251544075

Epoch: 6| Step: 7
Training loss: 2.0867224655775254
Validation loss: 2.500763637037086

Epoch: 6| Step: 8
Training loss: 1.9547535934678666
Validation loss: 2.5043358345897757

Epoch: 6| Step: 9
Training loss: 1.5596605822977212
Validation loss: 2.4805195836872316

Epoch: 6| Step: 10
Training loss: 2.7471191749064903
Validation loss: 2.4828657427595977

Epoch: 6| Step: 11
Training loss: 1.558859360322246
Validation loss: 2.4433481744673275

Epoch: 6| Step: 12
Training loss: 2.280232032546999
Validation loss: 2.4735422637922673

Epoch: 6| Step: 13
Training loss: 2.1701566636099328
Validation loss: 2.4612015798163274

Epoch: 134| Step: 0
Training loss: 1.7971364370145186
Validation loss: 2.498830179602473

Epoch: 6| Step: 1
Training loss: 2.277736309366676
Validation loss: 2.5450401397981635

Epoch: 6| Step: 2
Training loss: 2.578792046459791
Validation loss: 2.5851987130330114

Epoch: 6| Step: 3
Training loss: 1.5876813799950338
Validation loss: 2.6010552752873006

Epoch: 6| Step: 4
Training loss: 1.805745264830092
Validation loss: 2.6086158996726048

Epoch: 6| Step: 5
Training loss: 2.519974449270386
Validation loss: 2.598403679786201

Epoch: 6| Step: 6
Training loss: 2.328587223738275
Validation loss: 2.5778687470018404

Epoch: 6| Step: 7
Training loss: 2.0896463746601652
Validation loss: 2.562199949940306

Epoch: 6| Step: 8
Training loss: 1.947888977615565
Validation loss: 2.502444296750396

Epoch: 6| Step: 9
Training loss: 2.2321975875684235
Validation loss: 2.4494625184230885

Epoch: 6| Step: 10
Training loss: 2.178204431823139
Validation loss: 2.423965765779513

Epoch: 6| Step: 11
Training loss: 2.095206138647874
Validation loss: 2.3975863980005365

Epoch: 6| Step: 12
Training loss: 2.1081797286257347
Validation loss: 2.389197328940746

Epoch: 6| Step: 13
Training loss: 2.1164332098386103
Validation loss: 2.396140960446849

Epoch: 135| Step: 0
Training loss: 2.2426223599021973
Validation loss: 2.3963233528672196

Epoch: 6| Step: 1
Training loss: 2.059865366971251
Validation loss: 2.4064863280942084

Epoch: 6| Step: 2
Training loss: 2.0017481554751084
Validation loss: 2.423987059856585

Epoch: 6| Step: 3
Training loss: 2.57508235910795
Validation loss: 2.413221269562077

Epoch: 6| Step: 4
Training loss: 1.698517121779797
Validation loss: 2.4274992716898103

Epoch: 6| Step: 5
Training loss: 1.7422203437206842
Validation loss: 2.4578783894570457

Epoch: 6| Step: 6
Training loss: 1.8853156833757752
Validation loss: 2.490703186906897

Epoch: 6| Step: 7
Training loss: 2.222122101382678
Validation loss: 2.5035915028794222

Epoch: 6| Step: 8
Training loss: 1.6330174221690925
Validation loss: 2.516030744267574

Epoch: 6| Step: 9
Training loss: 2.2088493488034056
Validation loss: 2.5125952306952106

Epoch: 6| Step: 10
Training loss: 2.242402920359936
Validation loss: 2.5372830878788992

Epoch: 6| Step: 11
Training loss: 2.1335327273805085
Validation loss: 2.5154696415100943

Epoch: 6| Step: 12
Training loss: 2.301818303060686
Validation loss: 2.5358407864325234

Epoch: 6| Step: 13
Training loss: 2.1764856153766905
Validation loss: 2.524481923958143

Epoch: 136| Step: 0
Training loss: 2.020685865651874
Validation loss: 2.5337406394342787

Epoch: 6| Step: 1
Training loss: 2.0146254789197173
Validation loss: 2.5234940786446862

Epoch: 6| Step: 2
Training loss: 2.022488522491141
Validation loss: 2.505574498920743

Epoch: 6| Step: 3
Training loss: 1.64098150830308
Validation loss: 2.5267733962950234

Epoch: 6| Step: 4
Training loss: 1.9596206073053544
Validation loss: 2.5291203044961383

Epoch: 6| Step: 5
Training loss: 2.4319555362100145
Validation loss: 2.5402155451728996

Epoch: 6| Step: 6
Training loss: 2.4337605867709096
Validation loss: 2.518669044103345

Epoch: 6| Step: 7
Training loss: 1.40337769371801
Validation loss: 2.4947990852215

Epoch: 6| Step: 8
Training loss: 2.0533293089682707
Validation loss: 2.4683021854740446

Epoch: 6| Step: 9
Training loss: 2.199857195640976
Validation loss: 2.462970067839651

Epoch: 6| Step: 10
Training loss: 2.6620274263168544
Validation loss: 2.4545753256454246

Epoch: 6| Step: 11
Training loss: 1.6092659626290995
Validation loss: 2.465721569896619

Epoch: 6| Step: 12
Training loss: 2.1464512746964455
Validation loss: 2.4931982907335732

Epoch: 6| Step: 13
Training loss: 2.2234674726491304
Validation loss: 2.5068055295455594

Epoch: 137| Step: 0
Training loss: 1.98849204394327
Validation loss: 2.500131383642965

Epoch: 6| Step: 1
Training loss: 2.074558036339928
Validation loss: 2.531116852270861

Epoch: 6| Step: 2
Training loss: 2.470818341248838
Validation loss: 2.540354157990697

Epoch: 6| Step: 3
Training loss: 1.5402678596093937
Validation loss: 2.5436858893400704

Epoch: 6| Step: 4
Training loss: 2.464555484703604
Validation loss: 2.562765078236299

Epoch: 6| Step: 5
Training loss: 1.9125436790315382
Validation loss: 2.552709232917063

Epoch: 6| Step: 6
Training loss: 2.6280468106970787
Validation loss: 2.566453521068911

Epoch: 6| Step: 7
Training loss: 1.903881540243774
Validation loss: 2.590956595012609

Epoch: 6| Step: 8
Training loss: 1.5224778502909213
Validation loss: 2.579766700866305

Epoch: 6| Step: 9
Training loss: 2.1575692605298107
Validation loss: 2.5995892492914554

Epoch: 6| Step: 10
Training loss: 1.8298925999878337
Validation loss: 2.5781109493465637

Epoch: 6| Step: 11
Training loss: 1.936283837374302
Validation loss: 2.547141887492272

Epoch: 6| Step: 12
Training loss: 1.9550987341649146
Validation loss: 2.5193033832525726

Epoch: 6| Step: 13
Training loss: 2.173984628203652
Validation loss: 2.520537471333326

Epoch: 138| Step: 0
Training loss: 2.0258668433487874
Validation loss: 2.48631428354145

Epoch: 6| Step: 1
Training loss: 1.9330621161902815
Validation loss: 2.4697925105318173

Epoch: 6| Step: 2
Training loss: 1.9992732277260588
Validation loss: 2.442730057341628

Epoch: 6| Step: 3
Training loss: 1.8170169583013696
Validation loss: 2.437050890822996

Epoch: 6| Step: 4
Training loss: 2.0015574589947986
Validation loss: 2.4385895745730983

Epoch: 6| Step: 5
Training loss: 2.073074973753182
Validation loss: 2.4269431760872053

Epoch: 6| Step: 6
Training loss: 2.2817001943676867
Validation loss: 2.4338238637502085

Epoch: 6| Step: 7
Training loss: 1.9179497929586
Validation loss: 2.454861941145529

Epoch: 6| Step: 8
Training loss: 2.0729398358709954
Validation loss: 2.471809979939381

Epoch: 6| Step: 9
Training loss: 2.038103718627514
Validation loss: 2.512038240287555

Epoch: 6| Step: 10
Training loss: 2.0184420040663285
Validation loss: 2.5231455266332046

Epoch: 6| Step: 11
Training loss: 2.3152065418952414
Validation loss: 2.556598684137569

Epoch: 6| Step: 12
Training loss: 1.9543370872750823
Validation loss: 2.58962790062171

Epoch: 6| Step: 13
Training loss: 1.8121179638457807
Validation loss: 2.603519483482081

Epoch: 139| Step: 0
Training loss: 2.609920969968712
Validation loss: 2.6377479047529557

Epoch: 6| Step: 1
Training loss: 2.1072297667159807
Validation loss: 2.6168978691700104

Epoch: 6| Step: 2
Training loss: 1.4524734841321316
Validation loss: 2.574357296584246

Epoch: 6| Step: 3
Training loss: 1.7789899978056314
Validation loss: 2.5418397366083867

Epoch: 6| Step: 4
Training loss: 2.365213912257943
Validation loss: 2.5419129889915086

Epoch: 6| Step: 5
Training loss: 1.736760466465424
Validation loss: 2.5186261635302434

Epoch: 6| Step: 6
Training loss: 1.7618508299989442
Validation loss: 2.505780031979531

Epoch: 6| Step: 7
Training loss: 1.9187635340508407
Validation loss: 2.494407028322448

Epoch: 6| Step: 8
Training loss: 2.344309828972858
Validation loss: 2.482264083136136

Epoch: 6| Step: 9
Training loss: 2.1267470863387796
Validation loss: 2.4880170542315776

Epoch: 6| Step: 10
Training loss: 1.686031762458574
Validation loss: 2.4646137188000257

Epoch: 6| Step: 11
Training loss: 2.0602240286922386
Validation loss: 2.4626954471624334

Epoch: 6| Step: 12
Training loss: 1.9029533145929096
Validation loss: 2.4522901402049246

Epoch: 6| Step: 13
Training loss: 1.9584786854904461
Validation loss: 2.4617690658586073

Epoch: 140| Step: 0
Training loss: 2.280109277080747
Validation loss: 2.4669106088733868

Epoch: 6| Step: 1
Training loss: 1.8663182489751098
Validation loss: 2.4507370228423064

Epoch: 6| Step: 2
Training loss: 1.7755228293435548
Validation loss: 2.466124388015299

Epoch: 6| Step: 3
Training loss: 2.156308159527579
Validation loss: 2.469324312274379

Epoch: 6| Step: 4
Training loss: 1.5710201661620367
Validation loss: 2.458085086344182

Epoch: 6| Step: 5
Training loss: 2.284387181950141
Validation loss: 2.4504406116563295

Epoch: 6| Step: 6
Training loss: 2.061573398405732
Validation loss: 2.460235569039761

Epoch: 6| Step: 7
Training loss: 2.2495383742756796
Validation loss: 2.465006182638982

Epoch: 6| Step: 8
Training loss: 2.170093711552325
Validation loss: 2.488382564174406

Epoch: 6| Step: 9
Training loss: 1.1049089935421446
Validation loss: 2.480313978081274

Epoch: 6| Step: 10
Training loss: 1.2902367070102203
Validation loss: 2.515660817594421

Epoch: 6| Step: 11
Training loss: 2.1194709204001536
Validation loss: 2.522553928526087

Epoch: 6| Step: 12
Training loss: 2.230848610727948
Validation loss: 2.563384679972954

Epoch: 6| Step: 13
Training loss: 2.35202944355655
Validation loss: 2.578073404988495

Epoch: 141| Step: 0
Training loss: 2.4243278633761247
Validation loss: 2.5810915915560506

Epoch: 6| Step: 1
Training loss: 1.5192993300882938
Validation loss: 2.5674337416522275

Epoch: 6| Step: 2
Training loss: 1.8711474576182512
Validation loss: 2.5499171741215703

Epoch: 6| Step: 3
Training loss: 2.0073200022570346
Validation loss: 2.5313020916289095

Epoch: 6| Step: 4
Training loss: 1.6036125646322086
Validation loss: 2.523936201149574

Epoch: 6| Step: 5
Training loss: 1.8424196131029598
Validation loss: 2.5018099160396083

Epoch: 6| Step: 6
Training loss: 1.5727781609527602
Validation loss: 2.494160018687336

Epoch: 6| Step: 7
Training loss: 1.8566447496518854
Validation loss: 2.5090708317410644

Epoch: 6| Step: 8
Training loss: 1.8917826741591592
Validation loss: 2.515865171026475

Epoch: 6| Step: 9
Training loss: 1.5506736276021529
Validation loss: 2.5312713942186384

Epoch: 6| Step: 10
Training loss: 2.2629971753556664
Validation loss: 2.5245590569776

Epoch: 6| Step: 11
Training loss: 2.43476283616277
Validation loss: 2.5302620178414057

Epoch: 6| Step: 12
Training loss: 2.2029092020170835
Validation loss: 2.511114572283729

Epoch: 6| Step: 13
Training loss: 1.9705550381055397
Validation loss: 2.490806296372992

Epoch: 142| Step: 0
Training loss: 1.9620114003743645
Validation loss: 2.4854353735726673

Epoch: 6| Step: 1
Training loss: 2.1538897879341214
Validation loss: 2.464755020012357

Epoch: 6| Step: 2
Training loss: 1.6747477441121368
Validation loss: 2.4464018079860126

Epoch: 6| Step: 3
Training loss: 1.9758275290213152
Validation loss: 2.4640775165977744

Epoch: 6| Step: 4
Training loss: 2.3775962893525096
Validation loss: 2.4540842987995863

Epoch: 6| Step: 5
Training loss: 1.5975376075771397
Validation loss: 2.468826315611361

Epoch: 6| Step: 6
Training loss: 1.8878411218462263
Validation loss: 2.492883473524966

Epoch: 6| Step: 7
Training loss: 1.5588886488713933
Validation loss: 2.502889264912351

Epoch: 6| Step: 8
Training loss: 1.9240072563930726
Validation loss: 2.523800931590921

Epoch: 6| Step: 9
Training loss: 2.2149963864540263
Validation loss: 2.5392176982186507

Epoch: 6| Step: 10
Training loss: 1.8727297708388633
Validation loss: 2.572846385335851

Epoch: 6| Step: 11
Training loss: 1.839215278599527
Validation loss: 2.577956392076696

Epoch: 6| Step: 12
Training loss: 1.9660486732038183
Validation loss: 2.5888508888291963

Epoch: 6| Step: 13
Training loss: 1.8438145900986147
Validation loss: 2.5827145571424253

Epoch: 143| Step: 0
Training loss: 1.7622614868239943
Validation loss: 2.580816480502827

Epoch: 6| Step: 1
Training loss: 2.7687861593050975
Validation loss: 2.582335356415498

Epoch: 6| Step: 2
Training loss: 1.4627133759911217
Validation loss: 2.568673286982144

Epoch: 6| Step: 3
Training loss: 1.4428830735278901
Validation loss: 2.5122683114653945

Epoch: 6| Step: 4
Training loss: 1.6321604033442525
Validation loss: 2.497036465364474

Epoch: 6| Step: 5
Training loss: 1.9149899473997163
Validation loss: 2.4684225685365915

Epoch: 6| Step: 6
Training loss: 2.3585717052681696
Validation loss: 2.4590656850550023

Epoch: 6| Step: 7
Training loss: 2.0862728235128833
Validation loss: 2.447662244642994

Epoch: 6| Step: 8
Training loss: 1.9418140497332528
Validation loss: 2.45617049069046

Epoch: 6| Step: 9
Training loss: 2.0862712235968273
Validation loss: 2.4623823631367614

Epoch: 6| Step: 10
Training loss: 1.7446293162258124
Validation loss: 2.4568577281969737

Epoch: 6| Step: 11
Training loss: 1.8116968282711512
Validation loss: 2.4804306785704906

Epoch: 6| Step: 12
Training loss: 1.791691077605741
Validation loss: 2.5110802610563323

Epoch: 6| Step: 13
Training loss: 1.6087161446945977
Validation loss: 2.5377975142354012

Epoch: 144| Step: 0
Training loss: 1.6603071794903899
Validation loss: 2.584717377476701

Epoch: 6| Step: 1
Training loss: 1.7642613098724744
Validation loss: 2.64415950667359

Epoch: 6| Step: 2
Training loss: 2.296981912836483
Validation loss: 2.681970946582334

Epoch: 6| Step: 3
Training loss: 1.8447639134403586
Validation loss: 2.7035752793409573

Epoch: 6| Step: 4
Training loss: 1.9984026132600128
Validation loss: 2.734594535862877

Epoch: 6| Step: 5
Training loss: 2.2316087792286248
Validation loss: 2.7131116923717675

Epoch: 6| Step: 6
Training loss: 1.7111827378467466
Validation loss: 2.6566373828518386

Epoch: 6| Step: 7
Training loss: 1.7286223125399633
Validation loss: 2.56516746408335

Epoch: 6| Step: 8
Training loss: 2.063359399403894
Validation loss: 2.5218236332828345

Epoch: 6| Step: 9
Training loss: 2.0237638585898488
Validation loss: 2.478925510368371

Epoch: 6| Step: 10
Training loss: 1.9235049523333703
Validation loss: 2.459655065046589

Epoch: 6| Step: 11
Training loss: 1.8111484355369925
Validation loss: 2.451520845850985

Epoch: 6| Step: 12
Training loss: 2.136613414336861
Validation loss: 2.4416796879384592

Epoch: 6| Step: 13
Training loss: 1.430116766183812
Validation loss: 2.400325394349063

Epoch: 145| Step: 0
Training loss: 2.231975627629375
Validation loss: 2.40561822109255

Epoch: 6| Step: 1
Training loss: 1.8501888281878613
Validation loss: 2.4074410850790597

Epoch: 6| Step: 2
Training loss: 1.5045708314976096
Validation loss: 2.417774405539788

Epoch: 6| Step: 3
Training loss: 1.791953204403977
Validation loss: 2.4317142171505743

Epoch: 6| Step: 4
Training loss: 2.1086928783519903
Validation loss: 2.467949188681242

Epoch: 6| Step: 5
Training loss: 2.079693080742712
Validation loss: 2.4823145345989923

Epoch: 6| Step: 6
Training loss: 1.6110161866618609
Validation loss: 2.496138761571168

Epoch: 6| Step: 7
Training loss: 1.6764367873245747
Validation loss: 2.5248354353470184

Epoch: 6| Step: 8
Training loss: 1.7550401314605628
Validation loss: 2.527618014457607

Epoch: 6| Step: 9
Training loss: 2.0762736169067852
Validation loss: 2.5178218505821612

Epoch: 6| Step: 10
Training loss: 2.2425424115477353
Validation loss: 2.504895321164061

Epoch: 6| Step: 11
Training loss: 1.6679022818192912
Validation loss: 2.513176176249569

Epoch: 6| Step: 12
Training loss: 2.193556113519036
Validation loss: 2.523245763001088

Epoch: 6| Step: 13
Training loss: 1.7360799159320297
Validation loss: 2.535230625298524

Epoch: 146| Step: 0
Training loss: 2.1859884216616225
Validation loss: 2.5712425767652007

Epoch: 6| Step: 1
Training loss: 2.102378715074113
Validation loss: 2.554821301791255

Epoch: 6| Step: 2
Training loss: 2.319101036624431
Validation loss: 2.53404551813623

Epoch: 6| Step: 3
Training loss: 2.2724605178340824
Validation loss: 2.529722169167808

Epoch: 6| Step: 4
Training loss: 1.2432503621606934
Validation loss: 2.5182849332235087

Epoch: 6| Step: 5
Training loss: 1.8725564929298841
Validation loss: 2.5197992999903724

Epoch: 6| Step: 6
Training loss: 1.7100434079154119
Validation loss: 2.500750849369121

Epoch: 6| Step: 7
Training loss: 1.7140878040876641
Validation loss: 2.4700120623435473

Epoch: 6| Step: 8
Training loss: 1.6024955450701273
Validation loss: 2.4796540172612622

Epoch: 6| Step: 9
Training loss: 2.170821558748945
Validation loss: 2.5128091736494036

Epoch: 6| Step: 10
Training loss: 1.6328629481356998
Validation loss: 2.481439033164558

Epoch: 6| Step: 11
Training loss: 1.8680471572151465
Validation loss: 2.4732842251150977

Epoch: 6| Step: 12
Training loss: 1.770053138150785
Validation loss: 2.4763097225494186

Epoch: 6| Step: 13
Training loss: 2.013228063210194
Validation loss: 2.4652747037565006

Epoch: 147| Step: 0
Training loss: 1.9796416532511294
Validation loss: 2.440738251817787

Epoch: 6| Step: 1
Training loss: 1.7815762940417958
Validation loss: 2.4406760805375463

Epoch: 6| Step: 2
Training loss: 1.74411642948468
Validation loss: 2.4511200279063954

Epoch: 6| Step: 3
Training loss: 1.7728764659060843
Validation loss: 2.4739679521374756

Epoch: 6| Step: 4
Training loss: 1.6177554400238643
Validation loss: 2.4695103332354367

Epoch: 6| Step: 5
Training loss: 2.2556714528734245
Validation loss: 2.48294685515644

Epoch: 6| Step: 6
Training loss: 1.818826617432851
Validation loss: 2.507913033332721

Epoch: 6| Step: 7
Training loss: 1.7851451648059133
Validation loss: 2.512683430347283

Epoch: 6| Step: 8
Training loss: 2.1051124738423965
Validation loss: 2.4991060360872437

Epoch: 6| Step: 9
Training loss: 2.036194168739823
Validation loss: 2.4877989326917667

Epoch: 6| Step: 10
Training loss: 1.697041276122944
Validation loss: 2.5285393488966132

Epoch: 6| Step: 11
Training loss: 1.6081904524090056
Validation loss: 2.488905060292163

Epoch: 6| Step: 12
Training loss: 1.9513737876672799
Validation loss: 2.46808391239081

Epoch: 6| Step: 13
Training loss: 1.0110793283961137
Validation loss: 2.477481698241494

Epoch: 148| Step: 0
Training loss: 2.1015881391471556
Validation loss: 2.434323830127121

Epoch: 6| Step: 1
Training loss: 1.7412118959878882
Validation loss: 2.431642437314108

Epoch: 6| Step: 2
Training loss: 1.199994858094961
Validation loss: 2.4275696332539094

Epoch: 6| Step: 3
Training loss: 2.120583488671922
Validation loss: 2.423247263947971

Epoch: 6| Step: 4
Training loss: 1.6949833141619641
Validation loss: 2.4513914871360853

Epoch: 6| Step: 5
Training loss: 1.859333198141588
Validation loss: 2.4408289724091214

Epoch: 6| Step: 6
Training loss: 2.0366723093723644
Validation loss: 2.4742914803007956

Epoch: 6| Step: 7
Training loss: 1.5665737452579962
Validation loss: 2.4630185231538686

Epoch: 6| Step: 8
Training loss: 1.0791884995734964
Validation loss: 2.4700585673652626

Epoch: 6| Step: 9
Training loss: 2.3484348522991145
Validation loss: 2.4633537716340763

Epoch: 6| Step: 10
Training loss: 1.7795585498529505
Validation loss: 2.4940188199860835

Epoch: 6| Step: 11
Training loss: 1.977214238369019
Validation loss: 2.5066210347145548

Epoch: 6| Step: 12
Training loss: 1.583361784361487
Validation loss: 2.5477468957366787

Epoch: 6| Step: 13
Training loss: 1.9734734079653597
Validation loss: 2.574333934138679

Epoch: 149| Step: 0
Training loss: 1.6932733463315155
Validation loss: 2.594539239083013

Epoch: 6| Step: 1
Training loss: 1.7479350986653133
Validation loss: 2.580931084121457

Epoch: 6| Step: 2
Training loss: 1.888582687086733
Validation loss: 2.586430887362765

Epoch: 6| Step: 3
Training loss: 1.657309786899114
Validation loss: 2.582934040751665

Epoch: 6| Step: 4
Training loss: 1.974926961683025
Validation loss: 2.572477133685255

Epoch: 6| Step: 5
Training loss: 1.2520293928175672
Validation loss: 2.5799659845666794

Epoch: 6| Step: 6
Training loss: 2.1090917326438277
Validation loss: 2.572387445259411

Epoch: 6| Step: 7
Training loss: 2.027308586859376
Validation loss: 2.5306210462533496

Epoch: 6| Step: 8
Training loss: 1.5818063081546818
Validation loss: 2.5224677265432494

Epoch: 6| Step: 9
Training loss: 1.8850672979509127
Validation loss: 2.5104406681852858

Epoch: 6| Step: 10
Training loss: 1.610120211905465
Validation loss: 2.525156555959325

Epoch: 6| Step: 11
Training loss: 1.8707819860105341
Validation loss: 2.541594989625975

Epoch: 6| Step: 12
Training loss: 2.139839195199264
Validation loss: 2.5089949657301873

Epoch: 6| Step: 13
Training loss: 1.2461040819271902
Validation loss: 2.5046057974369202

Epoch: 150| Step: 0
Training loss: 1.4528229102050767
Validation loss: 2.516941771261676

Epoch: 6| Step: 1
Training loss: 1.8685142240771444
Validation loss: 2.523139128561679

Epoch: 6| Step: 2
Training loss: 1.8274111535931736
Validation loss: 2.5243251505050766

Epoch: 6| Step: 3
Training loss: 1.405164808537606
Validation loss: 2.5031170978139503

Epoch: 6| Step: 4
Training loss: 1.9847591358747676
Validation loss: 2.5083533295415674

Epoch: 6| Step: 5
Training loss: 1.952531770259652
Validation loss: 2.4697909421157607

Epoch: 6| Step: 6
Training loss: 1.5769376915116704
Validation loss: 2.4546400217021707

Epoch: 6| Step: 7
Training loss: 1.9024685734523008
Validation loss: 2.4009363661495886

Epoch: 6| Step: 8
Training loss: 2.1168289162434766
Validation loss: 2.4301218315233104

Epoch: 6| Step: 9
Training loss: 1.2844917875408262
Validation loss: 2.4196790379529323

Epoch: 6| Step: 10
Training loss: 1.9175274063399828
Validation loss: 2.4321691857228336

Epoch: 6| Step: 11
Training loss: 1.6877936354997092
Validation loss: 2.44087495689156

Epoch: 6| Step: 12
Training loss: 1.7578266058461804
Validation loss: 2.451253862541457

Epoch: 6| Step: 13
Training loss: 1.2469119073668662
Validation loss: 2.486090408075226

Epoch: 151| Step: 0
Training loss: 1.2923789162798305
Validation loss: 2.51454080126898

Epoch: 6| Step: 1
Training loss: 1.8386099337114126
Validation loss: 2.502370856618457

Epoch: 6| Step: 2
Training loss: 1.7055628416393827
Validation loss: 2.513759084342567

Epoch: 6| Step: 3
Training loss: 2.0410282408401965
Validation loss: 2.5563712142188666

Epoch: 6| Step: 4
Training loss: 1.2624509122011311
Validation loss: 2.564519946951387

Epoch: 6| Step: 5
Training loss: 1.5950342875415648
Validation loss: 2.556587296832994

Epoch: 6| Step: 6
Training loss: 1.4478350097171118
Validation loss: 2.5797219956854582

Epoch: 6| Step: 7
Training loss: 1.9253946964826854
Validation loss: 2.569449310128142

Epoch: 6| Step: 8
Training loss: 1.7202248920858594
Validation loss: 2.556486157573736

Epoch: 6| Step: 9
Training loss: 1.5406750591571656
Validation loss: 2.5316318349047395

Epoch: 6| Step: 10
Training loss: 1.8589436006573208
Validation loss: 2.537588490623758

Epoch: 6| Step: 11
Training loss: 2.0403863694310593
Validation loss: 2.541828852024053

Epoch: 6| Step: 12
Training loss: 1.587650670388194
Validation loss: 2.488820138226856

Epoch: 6| Step: 13
Training loss: 2.0390751279242596
Validation loss: 2.4942287690603013

Epoch: 152| Step: 0
Training loss: 1.9766410842170663
Validation loss: 2.497027691399149

Epoch: 6| Step: 1
Training loss: 1.683382308675562
Validation loss: 2.4972630316135307

Epoch: 6| Step: 2
Training loss: 1.8494002194762242
Validation loss: 2.5075773820798783

Epoch: 6| Step: 3
Training loss: 2.099927301510902
Validation loss: 2.510554667329623

Epoch: 6| Step: 4
Training loss: 1.3848970294367156
Validation loss: 2.5093903102731296

Epoch: 6| Step: 5
Training loss: 1.6877561304192683
Validation loss: 2.519132434047283

Epoch: 6| Step: 6
Training loss: 1.307817371136015
Validation loss: 2.518129873226475

Epoch: 6| Step: 7
Training loss: 2.092297064125245
Validation loss: 2.5148684669077697

Epoch: 6| Step: 8
Training loss: 1.7376806014352495
Validation loss: 2.530498836280869

Epoch: 6| Step: 9
Training loss: 1.252019823889353
Validation loss: 2.544841921965606

Epoch: 6| Step: 10
Training loss: 1.5633954343411178
Validation loss: 2.562535117384184

Epoch: 6| Step: 11
Training loss: 1.7183201338997653
Validation loss: 2.55852700573573

Epoch: 6| Step: 12
Training loss: 1.5686463583947396
Validation loss: 2.5347893076752896

Epoch: 6| Step: 13
Training loss: 1.290057959696116
Validation loss: 2.5256212577101156

Epoch: 153| Step: 0
Training loss: 2.006682794301227
Validation loss: 2.5055895554039727

Epoch: 6| Step: 1
Training loss: 1.5721651601976592
Validation loss: 2.4970897378463945

Epoch: 6| Step: 2
Training loss: 1.7710047769767485
Validation loss: 2.4772056344134237

Epoch: 6| Step: 3
Training loss: 1.6052237739125677
Validation loss: 2.4820113089718143

Epoch: 6| Step: 4
Training loss: 1.5122872794133606
Validation loss: 2.4720243352735634

Epoch: 6| Step: 5
Training loss: 2.0563329337883296
Validation loss: 2.472675629718864

Epoch: 6| Step: 6
Training loss: 1.515728347243641
Validation loss: 2.4619162409407176

Epoch: 6| Step: 7
Training loss: 1.862126470398897
Validation loss: 2.4767428712514756

Epoch: 6| Step: 8
Training loss: 2.0665248555576814
Validation loss: 2.4551201886757266

Epoch: 6| Step: 9
Training loss: 1.2801504301546258
Validation loss: 2.4978710862101674

Epoch: 6| Step: 10
Training loss: 1.9991534348760622
Validation loss: 2.5194551830823637

Epoch: 6| Step: 11
Training loss: 0.948225969987155
Validation loss: 2.5474992725945653

Epoch: 6| Step: 12
Training loss: 0.89413133368908
Validation loss: 2.5797275279762006

Epoch: 6| Step: 13
Training loss: 2.098699612129064
Validation loss: 2.59073154804265

Epoch: 154| Step: 0
Training loss: 1.9457738857731863
Validation loss: 2.581895345327791

Epoch: 6| Step: 1
Training loss: 1.8741646495292035
Validation loss: 2.59138318316255

Epoch: 6| Step: 2
Training loss: 1.4882503316075657
Validation loss: 2.5605984106744284

Epoch: 6| Step: 3
Training loss: 1.1193180709155792
Validation loss: 2.559880692505203

Epoch: 6| Step: 4
Training loss: 1.40507322453187
Validation loss: 2.568616651536902

Epoch: 6| Step: 5
Training loss: 2.091766328704372
Validation loss: 2.541965639177457

Epoch: 6| Step: 6
Training loss: 1.4715746238988368
Validation loss: 2.5398533046326675

Epoch: 6| Step: 7
Training loss: 1.7456828408333598
Validation loss: 2.5009161326779488

Epoch: 6| Step: 8
Training loss: 1.8882925605356269
Validation loss: 2.4622374804909524

Epoch: 6| Step: 9
Training loss: 1.6346871597619306
Validation loss: 2.4380917457955986

Epoch: 6| Step: 10
Training loss: 1.5280185779420787
Validation loss: 2.432950610518775

Epoch: 6| Step: 11
Training loss: 1.5165981039682073
Validation loss: 2.4449136002332943

Epoch: 6| Step: 12
Training loss: 1.9659386801484944
Validation loss: 2.4612295971936495

Epoch: 6| Step: 13
Training loss: 1.30331778438168
Validation loss: 2.4564438996636846

Epoch: 155| Step: 0
Training loss: 1.6231148862762346
Validation loss: 2.464110114377894

Epoch: 6| Step: 1
Training loss: 2.0083531939314625
Validation loss: 2.4364757442013176

Epoch: 6| Step: 2
Training loss: 1.4965455491067245
Validation loss: 2.441459364446591

Epoch: 6| Step: 3
Training loss: 1.5218449019759426
Validation loss: 2.4252307445462855

Epoch: 6| Step: 4
Training loss: 1.7688132338796134
Validation loss: 2.4063478654239234

Epoch: 6| Step: 5
Training loss: 1.26164991822878
Validation loss: 2.420116667762864

Epoch: 6| Step: 6
Training loss: 1.3190393573363883
Validation loss: 2.4244324401291166

Epoch: 6| Step: 7
Training loss: 1.2592124019945135
Validation loss: 2.431098738377639

Epoch: 6| Step: 8
Training loss: 1.863894955315203
Validation loss: 2.48312128770373

Epoch: 6| Step: 9
Training loss: 1.6863406402003303
Validation loss: 2.521796541225712

Epoch: 6| Step: 10
Training loss: 2.1178829838502575
Validation loss: 2.5863455525518932

Epoch: 6| Step: 11
Training loss: 1.4277268603919033
Validation loss: 2.5980547298097343

Epoch: 6| Step: 12
Training loss: 1.6486503861350124
Validation loss: 2.597762756606806

Epoch: 6| Step: 13
Training loss: 1.72876995392356
Validation loss: 2.627582962950791

Epoch: 156| Step: 0
Training loss: 1.8167581196901819
Validation loss: 2.6202218173868768

Epoch: 6| Step: 1
Training loss: 1.3512429096554641
Validation loss: 2.5998938706448036

Epoch: 6| Step: 2
Training loss: 1.467181240470623
Validation loss: 2.5413966110232966

Epoch: 6| Step: 3
Training loss: 1.5091347702646631
Validation loss: 2.5310144308493046

Epoch: 6| Step: 4
Training loss: 1.1103562864070577
Validation loss: 2.4884812147565465

Epoch: 6| Step: 5
Training loss: 2.0605884131995067
Validation loss: 2.4668967800538777

Epoch: 6| Step: 6
Training loss: 1.6400056669090801
Validation loss: 2.441812195333339

Epoch: 6| Step: 7
Training loss: 1.8848451903947312
Validation loss: 2.479548946932379

Epoch: 6| Step: 8
Training loss: 1.5333146170151113
Validation loss: 2.4843812677871004

Epoch: 6| Step: 9
Training loss: 1.526439974971955
Validation loss: 2.4893389555429426

Epoch: 6| Step: 10
Training loss: 1.4029541812220596
Validation loss: 2.5175427460810504

Epoch: 6| Step: 11
Training loss: 1.8696162177806253
Validation loss: 2.517185404671824

Epoch: 6| Step: 12
Training loss: 1.7868692205441687
Validation loss: 2.565148664211066

Epoch: 6| Step: 13
Training loss: 1.3951165175913622
Validation loss: 2.569919799923357

Epoch: 157| Step: 0
Training loss: 1.3150068593299575
Validation loss: 2.619094452174888

Epoch: 6| Step: 1
Training loss: 1.282125778479171
Validation loss: 2.6372778826156176

Epoch: 6| Step: 2
Training loss: 2.1083181488736744
Validation loss: 2.673663909849608

Epoch: 6| Step: 3
Training loss: 1.7145026699789623
Validation loss: 2.6715138537966814

Epoch: 6| Step: 4
Training loss: 1.457788102087882
Validation loss: 2.6362134734187808

Epoch: 6| Step: 5
Training loss: 1.5477120032707505
Validation loss: 2.5944170948322993

Epoch: 6| Step: 6
Training loss: 1.5341008176387265
Validation loss: 2.5735361347333

Epoch: 6| Step: 7
Training loss: 1.9755375432391342
Validation loss: 2.544185653669469

Epoch: 6| Step: 8
Training loss: 1.276987708630776
Validation loss: 2.513355304066228

Epoch: 6| Step: 9
Training loss: 1.3794225747287616
Validation loss: 2.5029178112240342

Epoch: 6| Step: 10
Training loss: 1.552492441966753
Validation loss: 2.486289843239172

Epoch: 6| Step: 11
Training loss: 1.4971240606942837
Validation loss: 2.4627375694100917

Epoch: 6| Step: 12
Training loss: 1.9107381172374682
Validation loss: 2.446557620785576

Epoch: 6| Step: 13
Training loss: 1.2646393411080916
Validation loss: 2.427353392678363

Epoch: 158| Step: 0
Training loss: 1.8788031472450812
Validation loss: 2.4369806294301535

Epoch: 6| Step: 1
Training loss: 1.6464884295249604
Validation loss: 2.4273945535244437

Epoch: 6| Step: 2
Training loss: 1.4161388685591343
Validation loss: 2.432259323693122

Epoch: 6| Step: 3
Training loss: 1.9018877489438013
Validation loss: 2.447927710500157

Epoch: 6| Step: 4
Training loss: 1.001269726505333
Validation loss: 2.450539137255903

Epoch: 6| Step: 5
Training loss: 2.0683102696454894
Validation loss: 2.4574809212086386

Epoch: 6| Step: 6
Training loss: 1.42497435429568
Validation loss: 2.4918480587071583

Epoch: 6| Step: 7
Training loss: 1.11259294614529
Validation loss: 2.5298626428684985

Epoch: 6| Step: 8
Training loss: 1.6657992330893112
Validation loss: 2.5328401123334507

Epoch: 6| Step: 9
Training loss: 1.572174941581259
Validation loss: 2.549904504267083

Epoch: 6| Step: 10
Training loss: 1.8035906476368644
Validation loss: 2.548888781249387

Epoch: 6| Step: 11
Training loss: 1.2394867333136514
Validation loss: 2.5891316029818254

Epoch: 6| Step: 12
Training loss: 0.867992474277235
Validation loss: 2.5861867044707503

Epoch: 6| Step: 13
Training loss: 1.7811382994847647
Validation loss: 2.577525845161918

Epoch: 159| Step: 0
Training loss: 1.4773573577754444
Validation loss: 2.591460939539373

Epoch: 6| Step: 1
Training loss: 1.878689315232062
Validation loss: 2.5920201827054354

Epoch: 6| Step: 2
Training loss: 1.1349766021366987
Validation loss: 2.6053410410067315

Epoch: 6| Step: 3
Training loss: 1.0059989165760979
Validation loss: 2.5677842201348198

Epoch: 6| Step: 4
Training loss: 0.8812905079074084
Validation loss: 2.548464870408383

Epoch: 6| Step: 5
Training loss: 1.7832193029198367
Validation loss: 2.538135104380282

Epoch: 6| Step: 6
Training loss: 1.8330085929173885
Validation loss: 2.5405677537604086

Epoch: 6| Step: 7
Training loss: 1.8122230186606183
Validation loss: 2.552083201070401

Epoch: 6| Step: 8
Training loss: 1.5802560901738731
Validation loss: 2.571514121175741

Epoch: 6| Step: 9
Training loss: 1.427934916928514
Validation loss: 2.546591421777885

Epoch: 6| Step: 10
Training loss: 1.6972076090037727
Validation loss: 2.5444211600654905

Epoch: 6| Step: 11
Training loss: 1.4854959371351357
Validation loss: 2.5429849011840013

Epoch: 6| Step: 12
Training loss: 1.392766225558364
Validation loss: 2.533082093160031

Epoch: 6| Step: 13
Training loss: 1.6520578123464937
Validation loss: 2.5319412909978083

Epoch: 160| Step: 0
Training loss: 1.519061253681939
Validation loss: 2.5051126049711567

Epoch: 6| Step: 1
Training loss: 1.4672304774805667
Validation loss: 2.4795124133082616

Epoch: 6| Step: 2
Training loss: 1.5885382313508791
Validation loss: 2.4571159373370004

Epoch: 6| Step: 3
Training loss: 1.008333707184105
Validation loss: 2.4660632725657936

Epoch: 6| Step: 4
Training loss: 1.6707832122794066
Validation loss: 2.4362453579435797

Epoch: 6| Step: 5
Training loss: 1.9301052490749602
Validation loss: 2.4408542848827333

Epoch: 6| Step: 6
Training loss: 1.2110487363853837
Validation loss: 2.4645447227288426

Epoch: 6| Step: 7
Training loss: 1.3730374983010196
Validation loss: 2.46401810870823

Epoch: 6| Step: 8
Training loss: 1.385277700505572
Validation loss: 2.499440914109441

Epoch: 6| Step: 9
Training loss: 1.7455382007362348
Validation loss: 2.5113232697615664

Epoch: 6| Step: 10
Training loss: 1.7071868336742761
Validation loss: 2.552617895827252

Epoch: 6| Step: 11
Training loss: 1.2919879893078288
Validation loss: 2.560962131493432

Epoch: 6| Step: 12
Training loss: 1.3815161021478448
Validation loss: 2.5592334365042917

Epoch: 6| Step: 13
Training loss: 2.0627273665441552
Validation loss: 2.58832393957072

Epoch: 161| Step: 0
Training loss: 1.9610123335096912
Validation loss: 2.5764255285764968

Epoch: 6| Step: 1
Training loss: 1.4486852111021526
Validation loss: 2.565934540974997

Epoch: 6| Step: 2
Training loss: 1.5326103084872145
Validation loss: 2.559222112011147

Epoch: 6| Step: 3
Training loss: 1.2383212013899663
Validation loss: 2.524024703300728

Epoch: 6| Step: 4
Training loss: 2.1198562749691026
Validation loss: 2.498479682350636

Epoch: 6| Step: 5
Training loss: 1.5858799966243464
Validation loss: 2.4744968383052233

Epoch: 6| Step: 6
Training loss: 1.4638219906558854
Validation loss: 2.5155923339744737

Epoch: 6| Step: 7
Training loss: 0.807489498058326
Validation loss: 2.5025433923331857

Epoch: 6| Step: 8
Training loss: 1.5244016286378328
Validation loss: 2.5218048274613967

Epoch: 6| Step: 9
Training loss: 0.7484786975966119
Validation loss: 2.5090282520333225

Epoch: 6| Step: 10
Training loss: 0.880307652815913
Validation loss: 2.5360606244065607

Epoch: 6| Step: 11
Training loss: 1.7833105516612584
Validation loss: 2.539029339872769

Epoch: 6| Step: 12
Training loss: 1.8457305098828227
Validation loss: 2.5609016986406044

Epoch: 6| Step: 13
Training loss: 1.164126247222242
Validation loss: 2.5480556855363785

Epoch: 162| Step: 0
Training loss: 1.34485084330604
Validation loss: 2.5958320473746603

Epoch: 6| Step: 1
Training loss: 1.9999387850929995
Validation loss: 2.5658761280764706

Epoch: 6| Step: 2
Training loss: 1.5225586532544806
Validation loss: 2.5660675899723198

Epoch: 6| Step: 3
Training loss: 0.8239741753471079
Validation loss: 2.563440813962847

Epoch: 6| Step: 4
Training loss: 1.5494615911774579
Validation loss: 2.510501722439404

Epoch: 6| Step: 5
Training loss: 1.2523592143017208
Validation loss: 2.49149633690975

Epoch: 6| Step: 6
Training loss: 1.490900653167117
Validation loss: 2.4639046986074566

Epoch: 6| Step: 7
Training loss: 1.3741903088496215
Validation loss: 2.4501950697582666

Epoch: 6| Step: 8
Training loss: 1.5762270098831515
Validation loss: 2.4713614211376926

Epoch: 6| Step: 9
Training loss: 1.7206348834323772
Validation loss: 2.4190147655846452

Epoch: 6| Step: 10
Training loss: 1.2939672389062054
Validation loss: 2.437736740584583

Epoch: 6| Step: 11
Training loss: 1.130254712303175
Validation loss: 2.4790917999911715

Epoch: 6| Step: 12
Training loss: 1.8371947184130668
Validation loss: 2.4566847889536323

Epoch: 6| Step: 13
Training loss: 1.4303665632982376
Validation loss: 2.505762502791053

Epoch: 163| Step: 0
Training loss: 1.6554531843777716
Validation loss: 2.5185464750571764

Epoch: 6| Step: 1
Training loss: 1.90286203957365
Validation loss: 2.5268870968806194

Epoch: 6| Step: 2
Training loss: 1.3844599850576507
Validation loss: 2.535927996647547

Epoch: 6| Step: 3
Training loss: 1.3200910935614607
Validation loss: 2.5168358414732257

Epoch: 6| Step: 4
Training loss: 1.4651228575243718
Validation loss: 2.5206469039164827

Epoch: 6| Step: 5
Training loss: 1.0974464080169193
Validation loss: 2.509226081699878

Epoch: 6| Step: 6
Training loss: 1.693068324225099
Validation loss: 2.527420532969223

Epoch: 6| Step: 7
Training loss: 1.8144759227030856
Validation loss: 2.5016917114169406

Epoch: 6| Step: 8
Training loss: 0.9601601037987143
Validation loss: 2.5055201897496238

Epoch: 6| Step: 9
Training loss: 1.4517871892208047
Validation loss: 2.477153170000914

Epoch: 6| Step: 10
Training loss: 1.3449319033064668
Validation loss: 2.4962812411672153

Epoch: 6| Step: 11
Training loss: 1.484452737479227
Validation loss: 2.4755765552249516

Epoch: 6| Step: 12
Training loss: 1.1929735224840075
Validation loss: 2.5051813658632653

Epoch: 6| Step: 13
Training loss: 1.1359598569493299
Validation loss: 2.5201059171766573

Epoch: 164| Step: 0
Training loss: 1.5900982927134135
Validation loss: 2.509658652741918

Epoch: 6| Step: 1
Training loss: 1.317374623176339
Validation loss: 2.531565970699162

Epoch: 6| Step: 2
Training loss: 1.3835815187901193
Validation loss: 2.548883123185172

Epoch: 6| Step: 3
Training loss: 1.7157712613488874
Validation loss: 2.5718725453231994

Epoch: 6| Step: 4
Training loss: 1.0834079618913868
Validation loss: 2.5798670009865137

Epoch: 6| Step: 5
Training loss: 1.911612051483244
Validation loss: 2.5670225630488517

Epoch: 6| Step: 6
Training loss: 1.52307711520116
Validation loss: 2.586361883861417

Epoch: 6| Step: 7
Training loss: 1.244213156030658
Validation loss: 2.5910419530890083

Epoch: 6| Step: 8
Training loss: 1.4387297967441806
Validation loss: 2.5857405236041697

Epoch: 6| Step: 9
Training loss: 1.1696622175072446
Validation loss: 2.5698098608415285

Epoch: 6| Step: 10
Training loss: 1.5265923332180762
Validation loss: 2.592514447538348

Epoch: 6| Step: 11
Training loss: 1.1819321958358202
Validation loss: 2.5902389165248003

Epoch: 6| Step: 12
Training loss: 1.3790329828999832
Validation loss: 2.567988393501232

Epoch: 6| Step: 13
Training loss: 1.5406198126220034
Validation loss: 2.5867742509350107

Epoch: 165| Step: 0
Training loss: 1.2915824534538336
Validation loss: 2.5478362159369166

Epoch: 6| Step: 1
Training loss: 1.5586012455274807
Validation loss: 2.514106782025739

Epoch: 6| Step: 2
Training loss: 0.9873131997847995
Validation loss: 2.4750611045680206

Epoch: 6| Step: 3
Training loss: 1.529933285474144
Validation loss: 2.4750566988363287

Epoch: 6| Step: 4
Training loss: 0.9940715233669977
Validation loss: 2.475792537368326

Epoch: 6| Step: 5
Training loss: 1.859918851415324
Validation loss: 2.47514287408405

Epoch: 6| Step: 6
Training loss: 1.3349211100153446
Validation loss: 2.4827288271833465

Epoch: 6| Step: 7
Training loss: 1.7651135539411862
Validation loss: 2.502482627963331

Epoch: 6| Step: 8
Training loss: 1.354298991071546
Validation loss: 2.4844158579688154

Epoch: 6| Step: 9
Training loss: 1.38604814674785
Validation loss: 2.5456271919402242

Epoch: 6| Step: 10
Training loss: 1.2840123056612338
Validation loss: 2.548216216413722

Epoch: 6| Step: 11
Training loss: 1.6645916021505314
Validation loss: 2.5134410342135878

Epoch: 6| Step: 12
Training loss: 1.4608531254357704
Validation loss: 2.515281603873138

Epoch: 6| Step: 13
Training loss: 1.3990900658879795
Validation loss: 2.504630881953814

Epoch: 166| Step: 0
Training loss: 1.398194787471169
Validation loss: 2.4920988907750288

Epoch: 6| Step: 1
Training loss: 1.3120951255122262
Validation loss: 2.4825965230810962

Epoch: 6| Step: 2
Training loss: 1.4161993920357117
Validation loss: 2.4956224745006423

Epoch: 6| Step: 3
Training loss: 1.3923438946596827
Validation loss: 2.4811267696027866

Epoch: 6| Step: 4
Training loss: 1.4461164558231436
Validation loss: 2.5061493932447756

Epoch: 6| Step: 5
Training loss: 1.364806144908139
Validation loss: 2.537694641145469

Epoch: 6| Step: 6
Training loss: 1.4846597498775584
Validation loss: 2.522293916708343

Epoch: 6| Step: 7
Training loss: 1.4291304039687391
Validation loss: 2.4947579497797205

Epoch: 6| Step: 8
Training loss: 1.4510094614647182
Validation loss: 2.550781884181014

Epoch: 6| Step: 9
Training loss: 1.4288657906937732
Validation loss: 2.560983194413545

Epoch: 6| Step: 10
Training loss: 1.6997327706728544
Validation loss: 2.591429851712052

Epoch: 6| Step: 11
Training loss: 1.3688155154221167
Validation loss: 2.5767090957422947

Epoch: 6| Step: 12
Training loss: 1.4579818937906808
Validation loss: 2.575401042989834

Epoch: 6| Step: 13
Training loss: 0.6426089896816054
Validation loss: 2.5803113668949567

Epoch: 167| Step: 0
Training loss: 1.514141261017624
Validation loss: 2.5497681480364096

Epoch: 6| Step: 1
Training loss: 1.2311294961429498
Validation loss: 2.5036402912026885

Epoch: 6| Step: 2
Training loss: 1.2091048616632896
Validation loss: 2.483125038506979

Epoch: 6| Step: 3
Training loss: 1.6158537593899454
Validation loss: 2.4957134742791816

Epoch: 6| Step: 4
Training loss: 1.024844418324972
Validation loss: 2.4473176469804323

Epoch: 6| Step: 5
Training loss: 1.2381969627791691
Validation loss: 2.468812667821806

Epoch: 6| Step: 6
Training loss: 1.602745995885012
Validation loss: 2.468294453936597

Epoch: 6| Step: 7
Training loss: 1.1812207697728436
Validation loss: 2.4520202468085066

Epoch: 6| Step: 8
Training loss: 1.1961760051008958
Validation loss: 2.524567357502021

Epoch: 6| Step: 9
Training loss: 1.7556975123530854
Validation loss: 2.5294224603252675

Epoch: 6| Step: 10
Training loss: 1.6484931827921394
Validation loss: 2.544019682775376

Epoch: 6| Step: 11
Training loss: 1.922420641348801
Validation loss: 2.571835368429509

Epoch: 6| Step: 12
Training loss: 1.0596100267974866
Validation loss: 2.51543872133122

Epoch: 6| Step: 13
Training loss: 1.4622277259062821
Validation loss: 2.514248151626603

Epoch: 168| Step: 0
Training loss: 1.6862261874113136
Validation loss: 2.4800384104258613

Epoch: 6| Step: 1
Training loss: 1.2455450781310542
Validation loss: 2.463041037745867

Epoch: 6| Step: 2
Training loss: 1.3310683005540123
Validation loss: 2.4095757775756743

Epoch: 6| Step: 3
Training loss: 1.2616642329009018
Validation loss: 2.424550357442782

Epoch: 6| Step: 4
Training loss: 1.7693504257948038
Validation loss: 2.4280793546944577

Epoch: 6| Step: 5
Training loss: 1.4095141356951215
Validation loss: 2.4240287484939844

Epoch: 6| Step: 6
Training loss: 1.5930796690784959
Validation loss: 2.471873247425931

Epoch: 6| Step: 7
Training loss: 1.1662621932296928
Validation loss: 2.4971420852251285

Epoch: 6| Step: 8
Training loss: 1.0069532649797575
Validation loss: 2.487220893034373

Epoch: 6| Step: 9
Training loss: 0.45848790365588393
Validation loss: 2.5154949672576383

Epoch: 6| Step: 10
Training loss: 1.5209188132453897
Validation loss: 2.554913803342557

Epoch: 6| Step: 11
Training loss: 1.7007913262380232
Validation loss: 2.5597425141231285

Epoch: 6| Step: 12
Training loss: 1.4124407662994025
Validation loss: 2.551233562928949

Epoch: 6| Step: 13
Training loss: 1.4488608851551175
Validation loss: 2.607124397981958

Epoch: 169| Step: 0
Training loss: 0.8153353882132354
Validation loss: 2.5862241845760656

Epoch: 6| Step: 1
Training loss: 1.4651137446490363
Validation loss: 2.575866401972246

Epoch: 6| Step: 2
Training loss: 1.4655844481496803
Validation loss: 2.5930060278296465

Epoch: 6| Step: 3
Training loss: 1.8339909400050562
Validation loss: 2.553522987627873

Epoch: 6| Step: 4
Training loss: 1.4879971931492573
Validation loss: 2.5809101641307683

Epoch: 6| Step: 5
Training loss: 1.3784508317792603
Validation loss: 2.54083942592749

Epoch: 6| Step: 6
Training loss: 1.3330453273538632
Validation loss: 2.504803890416282

Epoch: 6| Step: 7
Training loss: 0.8542099492031555
Validation loss: 2.4642110625935523

Epoch: 6| Step: 8
Training loss: 1.220635349681005
Validation loss: 2.4893621507003947

Epoch: 6| Step: 9
Training loss: 1.5699971959520314
Validation loss: 2.469089702237464

Epoch: 6| Step: 10
Training loss: 1.5827990517228538
Validation loss: 2.483700146259442

Epoch: 6| Step: 11
Training loss: 1.171854044408989
Validation loss: 2.4943219585182557

Epoch: 6| Step: 12
Training loss: 1.4145935915920052
Validation loss: 2.4798685329673837

Epoch: 6| Step: 13
Training loss: 1.3507186372099975
Validation loss: 2.497580572699246

Epoch: 170| Step: 0
Training loss: 1.2598650752593614
Validation loss: 2.51771531022085

Epoch: 6| Step: 1
Training loss: 1.7400878433547378
Validation loss: 2.5470508026822927

Epoch: 6| Step: 2
Training loss: 1.3745433742746902
Validation loss: 2.5473058132234514

Epoch: 6| Step: 3
Training loss: 1.3203690195118816
Validation loss: 2.5673227589574963

Epoch: 6| Step: 4
Training loss: 0.7682382011959933
Validation loss: 2.5783142527515976

Epoch: 6| Step: 5
Training loss: 1.5909590874284272
Validation loss: 2.5694265949952584

Epoch: 6| Step: 6
Training loss: 1.3971983464962676
Validation loss: 2.54405522757286

Epoch: 6| Step: 7
Training loss: 1.3454381850809656
Validation loss: 2.5271160540931654

Epoch: 6| Step: 8
Training loss: 1.5878418261547573
Validation loss: 2.5120726552808255

Epoch: 6| Step: 9
Training loss: 1.1634116689564051
Validation loss: 2.5094763280908654

Epoch: 6| Step: 10
Training loss: 1.3020449619997183
Validation loss: 2.505133172445002

Epoch: 6| Step: 11
Training loss: 1.5644613544376251
Validation loss: 2.4819648373392953

Epoch: 6| Step: 12
Training loss: 0.8666291028526352
Validation loss: 2.4725190220661033

Epoch: 6| Step: 13
Training loss: 1.617276838847982
Validation loss: 2.4629412677383455

Epoch: 171| Step: 0
Training loss: 1.1182433787370956
Validation loss: 2.4590813458351235

Epoch: 6| Step: 1
Training loss: 1.0859030299582058
Validation loss: 2.4444307689371216

Epoch: 6| Step: 2
Training loss: 1.4651218811475828
Validation loss: 2.459302376131444

Epoch: 6| Step: 3
Training loss: 1.443425033789693
Validation loss: 2.439825721173881

Epoch: 6| Step: 4
Training loss: 0.828260374700278
Validation loss: 2.4905193572273516

Epoch: 6| Step: 5
Training loss: 1.525459082870853
Validation loss: 2.4956846277897395

Epoch: 6| Step: 6
Training loss: 0.7439505266691372
Validation loss: 2.50195257885843

Epoch: 6| Step: 7
Training loss: 1.9092406280235608
Validation loss: 2.5250254764081856

Epoch: 6| Step: 8
Training loss: 1.3159243553445437
Validation loss: 2.5220054647917287

Epoch: 6| Step: 9
Training loss: 1.294784975942489
Validation loss: 2.5646342242080378

Epoch: 6| Step: 10
Training loss: 1.873257399453405
Validation loss: 2.601216502709886

Epoch: 6| Step: 11
Training loss: 1.1109527329313966
Validation loss: 2.617033320712711

Epoch: 6| Step: 12
Training loss: 1.352401913736925
Validation loss: 2.597235575200327

Epoch: 6| Step: 13
Training loss: 1.2598605334585569
Validation loss: 2.6040953292099753

Epoch: 172| Step: 0
Training loss: 1.3977329034825803
Validation loss: 2.563554066788715

Epoch: 6| Step: 1
Training loss: 1.370958240039985
Validation loss: 2.5951408149319235

Epoch: 6| Step: 2
Training loss: 1.4465626027141607
Validation loss: 2.611229119731978

Epoch: 6| Step: 3
Training loss: 1.600286803766463
Validation loss: 2.5823805157047044

Epoch: 6| Step: 4
Training loss: 1.1873373120948258
Validation loss: 2.5600758493022133

Epoch: 6| Step: 5
Training loss: 1.4371586269888297
Validation loss: 2.552091692336764

Epoch: 6| Step: 6
Training loss: 0.9148314738244008
Validation loss: 2.5388352997177464

Epoch: 6| Step: 7
Training loss: 1.2660488784598865
Validation loss: 2.5282563798769857

Epoch: 6| Step: 8
Training loss: 1.5948407797432111
Validation loss: 2.4878395571884937

Epoch: 6| Step: 9
Training loss: 1.4841968630261124
Validation loss: 2.467367743495033

Epoch: 6| Step: 10
Training loss: 1.4192169832518695
Validation loss: 2.4560269085769924

Epoch: 6| Step: 11
Training loss: 0.586101051392887
Validation loss: 2.422498204566606

Epoch: 6| Step: 12
Training loss: 1.458323215267867
Validation loss: 2.424760149101587

Epoch: 6| Step: 13
Training loss: 0.9448008768515269
Validation loss: 2.4129177912773194

Epoch: 173| Step: 0
Training loss: 1.3072373377642152
Validation loss: 2.407552334988826

Epoch: 6| Step: 1
Training loss: 1.1095361189633994
Validation loss: 2.452606976247079

Epoch: 6| Step: 2
Training loss: 1.4688975483255484
Validation loss: 2.4611293329259865

Epoch: 6| Step: 3
Training loss: 1.4126509898007311
Validation loss: 2.4911086253672896

Epoch: 6| Step: 4
Training loss: 1.109093052670842
Validation loss: 2.52066504509024

Epoch: 6| Step: 5
Training loss: 1.5826450993697487
Validation loss: 2.5336704473156835

Epoch: 6| Step: 6
Training loss: 1.3085814518137127
Validation loss: 2.5207439556936992

Epoch: 6| Step: 7
Training loss: 1.0749820840806419
Validation loss: 2.5553566816804425

Epoch: 6| Step: 8
Training loss: 1.2853741678459474
Validation loss: 2.5147908399120453

Epoch: 6| Step: 9
Training loss: 0.9679508604747259
Validation loss: 2.552667631691265

Epoch: 6| Step: 10
Training loss: 1.6387625886272104
Validation loss: 2.5430068015457876

Epoch: 6| Step: 11
Training loss: 1.3946801541541192
Validation loss: 2.545561578064083

Epoch: 6| Step: 12
Training loss: 1.403927517041526
Validation loss: 2.506686090333505

Epoch: 6| Step: 13
Training loss: 1.2973938788674038
Validation loss: 2.489285858075737

Epoch: 174| Step: 0
Training loss: 1.575428311071953
Validation loss: 2.4953973876458684

Epoch: 6| Step: 1
Training loss: 1.1438106833447117
Validation loss: 2.49535085863713

Epoch: 6| Step: 2
Training loss: 0.801854303201412
Validation loss: 2.506352381854822

Epoch: 6| Step: 3
Training loss: 1.1990193253996722
Validation loss: 2.513418845634746

Epoch: 6| Step: 4
Training loss: 1.296847561465548
Validation loss: 2.4980377500101643

Epoch: 6| Step: 5
Training loss: 1.4797688543398155
Validation loss: 2.54559835213486

Epoch: 6| Step: 6
Training loss: 1.3818157073248605
Validation loss: 2.544861944710585

Epoch: 6| Step: 7
Training loss: 1.4891495862314639
Validation loss: 2.5214679620545613

Epoch: 6| Step: 8
Training loss: 1.5367014633315723
Validation loss: 2.494964347694942

Epoch: 6| Step: 9
Training loss: 1.5343898578242974
Validation loss: 2.472580069187931

Epoch: 6| Step: 10
Training loss: 1.3092319128110295
Validation loss: 2.454616357960371

Epoch: 6| Step: 11
Training loss: 1.1255643806465108
Validation loss: 2.4867487256833574

Epoch: 6| Step: 12
Training loss: 1.2158452165496598
Validation loss: 2.4687779088673487

Epoch: 6| Step: 13
Training loss: 0.7740796053632343
Validation loss: 2.457525613516301

Epoch: 175| Step: 0
Training loss: 1.3921419934714174
Validation loss: 2.4800284650815043

Epoch: 6| Step: 1
Training loss: 1.5060005962882312
Validation loss: 2.4974790835101834

Epoch: 6| Step: 2
Training loss: 1.1538683100553864
Validation loss: 2.4913092615310752

Epoch: 6| Step: 3
Training loss: 1.3001192716757108
Validation loss: 2.5637357959841918

Epoch: 6| Step: 4
Training loss: 1.351089835895239
Validation loss: 2.590371420347031

Epoch: 6| Step: 5
Training loss: 1.166845387439084
Validation loss: 2.56861435898571

Epoch: 6| Step: 6
Training loss: 1.4384130812218807
Validation loss: 2.577643680234629

Epoch: 6| Step: 7
Training loss: 1.0692204382544577
Validation loss: 2.5808972779042527

Epoch: 6| Step: 8
Training loss: 1.2607670551805312
Validation loss: 2.5523293830908202

Epoch: 6| Step: 9
Training loss: 1.2579828940655253
Validation loss: 2.546738674839346

Epoch: 6| Step: 10
Training loss: 1.0845090953573893
Validation loss: 2.560698873923841

Epoch: 6| Step: 11
Training loss: 1.2041404699272125
Validation loss: 2.5377176408164734

Epoch: 6| Step: 12
Training loss: 1.2950195459783387
Validation loss: 2.5254706685150294

Epoch: 6| Step: 13
Training loss: 1.9338299231358482
Validation loss: 2.497594716108545

Epoch: 176| Step: 0
Training loss: 1.6285249185971775
Validation loss: 2.5112003360506128

Epoch: 6| Step: 1
Training loss: 1.2092619594213658
Validation loss: 2.4613923829079543

Epoch: 6| Step: 2
Training loss: 1.4992937968734685
Validation loss: 2.4585512644126695

Epoch: 6| Step: 3
Training loss: 0.8012364652088604
Validation loss: 2.4610365314288933

Epoch: 6| Step: 4
Training loss: 1.3386443973211288
Validation loss: 2.45840973593687

Epoch: 6| Step: 5
Training loss: 1.2733544164596506
Validation loss: 2.4604719147049354

Epoch: 6| Step: 6
Training loss: 1.2053704548660757
Validation loss: 2.4435087290649484

Epoch: 6| Step: 7
Training loss: 1.422554608253882
Validation loss: 2.485531933879227

Epoch: 6| Step: 8
Training loss: 0.7863319665973209
Validation loss: 2.488690460263056

Epoch: 6| Step: 9
Training loss: 1.3545554654413046
Validation loss: 2.479683176367675

Epoch: 6| Step: 10
Training loss: 1.2163919966198882
Validation loss: 2.514266544936045

Epoch: 6| Step: 11
Training loss: 1.391841484937313
Validation loss: 2.5461381673908634

Epoch: 6| Step: 12
Training loss: 1.1190556199310504
Validation loss: 2.5040416738819147

Epoch: 6| Step: 13
Training loss: 1.5511530279178378
Validation loss: 2.567592109443185

Epoch: 177| Step: 0
Training loss: 1.3108515605560593
Validation loss: 2.562827269221974

Epoch: 6| Step: 1
Training loss: 1.2195016059473904
Validation loss: 2.589935660925699

Epoch: 6| Step: 2
Training loss: 1.5964313465605109
Validation loss: 2.5753003300207715

Epoch: 6| Step: 3
Training loss: 1.345512520589024
Validation loss: 2.540863864923239

Epoch: 6| Step: 4
Training loss: 1.1451392528028792
Validation loss: 2.5293394966254517

Epoch: 6| Step: 5
Training loss: 1.3908344068269756
Validation loss: 2.5208116078048644

Epoch: 6| Step: 6
Training loss: 1.3380096605348446
Validation loss: 2.4937902925904054

Epoch: 6| Step: 7
Training loss: 1.35367899207433
Validation loss: 2.483999411606408

Epoch: 6| Step: 8
Training loss: 1.202155924323635
Validation loss: 2.4661701861856877

Epoch: 6| Step: 9
Training loss: 0.8648522353337545
Validation loss: 2.4703114022776993

Epoch: 6| Step: 10
Training loss: 1.4643306392995423
Validation loss: 2.4962667370315104

Epoch: 6| Step: 11
Training loss: 1.2909328878556257
Validation loss: 2.4703188255094006

Epoch: 6| Step: 12
Training loss: 1.0052016394726657
Validation loss: 2.4850587828050053

Epoch: 6| Step: 13
Training loss: 1.3050333809511268
Validation loss: 2.493143206568593

Epoch: 178| Step: 0
Training loss: 1.6000522843401306
Validation loss: 2.5089640975693985

Epoch: 6| Step: 1
Training loss: 1.2112579906030774
Validation loss: 2.4768235103448495

Epoch: 6| Step: 2
Training loss: 1.098256717309657
Validation loss: 2.5168828034350823

Epoch: 6| Step: 3
Training loss: 1.3722420690150596
Validation loss: 2.496695477723729

Epoch: 6| Step: 4
Training loss: 0.9804532479204335
Validation loss: 2.5161170180233476

Epoch: 6| Step: 5
Training loss: 1.488583271289636
Validation loss: 2.5100509594356484

Epoch: 6| Step: 6
Training loss: 1.1323417474690307
Validation loss: 2.4950354083232944

Epoch: 6| Step: 7
Training loss: 1.2350750640111172
Validation loss: 2.481975508802439

Epoch: 6| Step: 8
Training loss: 1.0406606902912712
Validation loss: 2.478734113543982

Epoch: 6| Step: 9
Training loss: 1.5355357703188521
Validation loss: 2.45182404626937

Epoch: 6| Step: 10
Training loss: 1.1903233844462737
Validation loss: 2.441111885815852

Epoch: 6| Step: 11
Training loss: 1.2854488236883794
Validation loss: 2.441312426792618

Epoch: 6| Step: 12
Training loss: 1.0353978289010546
Validation loss: 2.4699061967643274

Epoch: 6| Step: 13
Training loss: 1.044717301637714
Validation loss: 2.4599312434295038

Epoch: 179| Step: 0
Training loss: 1.606621469967338
Validation loss: 2.4519143577329956

Epoch: 6| Step: 1
Training loss: 1.2080755561700554
Validation loss: 2.5015295917612073

Epoch: 6| Step: 2
Training loss: 1.4305525700477302
Validation loss: 2.5384586456095515

Epoch: 6| Step: 3
Training loss: 1.3807306512944333
Validation loss: 2.544451885226241

Epoch: 6| Step: 4
Training loss: 1.0404863282331547
Validation loss: 2.5499485297802416

Epoch: 6| Step: 5
Training loss: 0.8945854870208083
Validation loss: 2.54761368642132

Epoch: 6| Step: 6
Training loss: 0.9949694103542019
Validation loss: 2.53282616674812

Epoch: 6| Step: 7
Training loss: 1.1812523069813317
Validation loss: 2.5131258174579916

Epoch: 6| Step: 8
Training loss: 1.5087742875743002
Validation loss: 2.4986404475349393

Epoch: 6| Step: 9
Training loss: 1.1605255361243212
Validation loss: 2.501114858185469

Epoch: 6| Step: 10
Training loss: 1.2812370671805842
Validation loss: 2.4835804856611574

Epoch: 6| Step: 11
Training loss: 1.2345785625020977
Validation loss: 2.441884752335224

Epoch: 6| Step: 12
Training loss: 1.2962635851068156
Validation loss: 2.449430023997003

Epoch: 6| Step: 13
Training loss: 0.7885988213920444
Validation loss: 2.44008549204091

Epoch: 180| Step: 0
Training loss: 1.1744196412198076
Validation loss: 2.4057355100849582

Epoch: 6| Step: 1
Training loss: 1.3893418553594978
Validation loss: 2.4204607541530985

Epoch: 6| Step: 2
Training loss: 1.1866413827052729
Validation loss: 2.4543994033221863

Epoch: 6| Step: 3
Training loss: 1.2149989774095291
Validation loss: 2.4181615098031743

Epoch: 6| Step: 4
Training loss: 0.8058514741185753
Validation loss: 2.4968675066988366

Epoch: 6| Step: 5
Training loss: 1.2918421974686791
Validation loss: 2.5044847132836012

Epoch: 6| Step: 6
Training loss: 1.414151183661586
Validation loss: 2.5141542599393287

Epoch: 6| Step: 7
Training loss: 1.3276623986115181
Validation loss: 2.55912126421291

Epoch: 6| Step: 8
Training loss: 1.1523674396730743
Validation loss: 2.557845481727922

Epoch: 6| Step: 9
Training loss: 1.5179533230738302
Validation loss: 2.5763139670073874

Epoch: 6| Step: 10
Training loss: 1.421974346337245
Validation loss: 2.567041737682171

Epoch: 6| Step: 11
Training loss: 0.9049424571506103
Validation loss: 2.532247968715892

Epoch: 6| Step: 12
Training loss: 1.245347615779549
Validation loss: 2.5160151618357087

Epoch: 6| Step: 13
Training loss: 1.0379246957030146
Validation loss: 2.512384817460299

Epoch: 181| Step: 0
Training loss: 1.1988883293301
Validation loss: 2.5326128073304033

Epoch: 6| Step: 1
Training loss: 1.078935014809486
Validation loss: 2.4922118588067

Epoch: 6| Step: 2
Training loss: 1.1022507702000004
Validation loss: 2.496828649830101

Epoch: 6| Step: 3
Training loss: 0.9763334081872678
Validation loss: 2.475734958676639

Epoch: 6| Step: 4
Training loss: 1.5674726323806516
Validation loss: 2.456875191535082

Epoch: 6| Step: 5
Training loss: 1.4597732882646892
Validation loss: 2.4946044045615747

Epoch: 6| Step: 6
Training loss: 0.9536884393485519
Validation loss: 2.4768015961311707

Epoch: 6| Step: 7
Training loss: 0.8597484124144871
Validation loss: 2.4689454198243257

Epoch: 6| Step: 8
Training loss: 1.4094682108639105
Validation loss: 2.4993601082633985

Epoch: 6| Step: 9
Training loss: 1.2312363909438844
Validation loss: 2.472599952361548

Epoch: 6| Step: 10
Training loss: 1.1162890042349929
Validation loss: 2.4930890954998866

Epoch: 6| Step: 11
Training loss: 1.1004688434202692
Validation loss: 2.498118375425388

Epoch: 6| Step: 12
Training loss: 1.2187153737944714
Validation loss: 2.5030664127172084

Epoch: 6| Step: 13
Training loss: 1.8704375388559422
Validation loss: 2.5091488962379302

Epoch: 182| Step: 0
Training loss: 1.5491813651309816
Validation loss: 2.485394232202515

Epoch: 6| Step: 1
Training loss: 0.8924281956401166
Validation loss: 2.5291334910234955

Epoch: 6| Step: 2
Training loss: 1.1743580769146336
Validation loss: 2.505450472231752

Epoch: 6| Step: 3
Training loss: 1.4989563967347863
Validation loss: 2.502089219660475

Epoch: 6| Step: 4
Training loss: 1.0861833143232076
Validation loss: 2.506728113077934

Epoch: 6| Step: 5
Training loss: 1.1980604113152085
Validation loss: 2.4321987180627986

Epoch: 6| Step: 6
Training loss: 1.1669416217143769
Validation loss: 2.4213173225852955

Epoch: 6| Step: 7
Training loss: 1.3252433931178462
Validation loss: 2.3988550502836476

Epoch: 6| Step: 8
Training loss: 1.466331357267944
Validation loss: 2.3667275440729245

Epoch: 6| Step: 9
Training loss: 1.2686389780562777
Validation loss: 2.3493547897404308

Epoch: 6| Step: 10
Training loss: 1.1985597570495043
Validation loss: 2.336029880052513

Epoch: 6| Step: 11
Training loss: 1.335792042805434
Validation loss: 2.294144525492144

Epoch: 6| Step: 12
Training loss: 1.430887604522708
Validation loss: 2.3442420656226592

Epoch: 6| Step: 13
Training loss: 1.2371671941969262
Validation loss: 2.3389931132551083

Epoch: 183| Step: 0
Training loss: 1.1833125117086403
Validation loss: 2.331882658887829

Epoch: 6| Step: 1
Training loss: 0.9077589692240253
Validation loss: 2.3781152683166904

Epoch: 6| Step: 2
Training loss: 1.0837575864251348
Validation loss: 2.3764946168630705

Epoch: 6| Step: 3
Training loss: 1.2354024160419868
Validation loss: 2.380060072065171

Epoch: 6| Step: 4
Training loss: 1.6055170873340332
Validation loss: 2.4294220343750097

Epoch: 6| Step: 5
Training loss: 0.6912395254724615
Validation loss: 2.4443299362096296

Epoch: 6| Step: 6
Training loss: 1.2945987994585226
Validation loss: 2.486276934727915

Epoch: 6| Step: 7
Training loss: 1.3229991506658871
Validation loss: 2.4888727718109527

Epoch: 6| Step: 8
Training loss: 1.3958543329889226
Validation loss: 2.4941431165442753

Epoch: 6| Step: 9
Training loss: 1.171056232525812
Validation loss: 2.5228435732131658

Epoch: 6| Step: 10
Training loss: 1.216729567918
Validation loss: 2.514434814172345

Epoch: 6| Step: 11
Training loss: 1.3564707985029247
Validation loss: 2.495588538901379

Epoch: 6| Step: 12
Training loss: 0.9872703357610408
Validation loss: 2.4993553648223354

Epoch: 6| Step: 13
Training loss: 1.3748358281702115
Validation loss: 2.4972018723527105

Epoch: 184| Step: 0
Training loss: 1.3021829287268183
Validation loss: 2.4979775215729094

Epoch: 6| Step: 1
Training loss: 0.871312751097397
Validation loss: 2.470887403884463

Epoch: 6| Step: 2
Training loss: 1.3413598294188083
Validation loss: 2.489414905671082

Epoch: 6| Step: 3
Training loss: 1.370089040563631
Validation loss: 2.4771260095675194

Epoch: 6| Step: 4
Training loss: 1.3559019951920552
Validation loss: 2.4750561073997854

Epoch: 6| Step: 5
Training loss: 1.1493629308070001
Validation loss: 2.487920108648201

Epoch: 6| Step: 6
Training loss: 0.9147924133543301
Validation loss: 2.505531831657561

Epoch: 6| Step: 7
Training loss: 0.9729961429511658
Validation loss: 2.509851206060959

Epoch: 6| Step: 8
Training loss: 0.8130406634893566
Validation loss: 2.496057777955035

Epoch: 6| Step: 9
Training loss: 1.2943531012789382
Validation loss: 2.475827324169235

Epoch: 6| Step: 10
Training loss: 1.2093392931179017
Validation loss: 2.4968475297984085

Epoch: 6| Step: 11
Training loss: 1.2173415139223913
Validation loss: 2.4888578598648365

Epoch: 6| Step: 12
Training loss: 1.3356424641661182
Validation loss: 2.515474977773315

Epoch: 6| Step: 13
Training loss: 1.074087405411308
Validation loss: 2.4836752518716048

Epoch: 185| Step: 0
Training loss: 0.9555002227615265
Validation loss: 2.483879914565288

Epoch: 6| Step: 1
Training loss: 0.6843988745370236
Validation loss: 2.4806914431344085

Epoch: 6| Step: 2
Training loss: 1.0798878286531173
Validation loss: 2.4978396787678245

Epoch: 6| Step: 3
Training loss: 1.4985702376300538
Validation loss: 2.489060775492259

Epoch: 6| Step: 4
Training loss: 1.221324744070104
Validation loss: 2.49529718636336

Epoch: 6| Step: 5
Training loss: 1.3909631382317633
Validation loss: 2.5103654542632654

Epoch: 6| Step: 6
Training loss: 1.1751907741616863
Validation loss: 2.5064437678787326

Epoch: 6| Step: 7
Training loss: 1.063518260632248
Validation loss: 2.496257454052874

Epoch: 6| Step: 8
Training loss: 1.3149325217858046
Validation loss: 2.511953105738045

Epoch: 6| Step: 9
Training loss: 1.1769332565013146
Validation loss: 2.456664461818967

Epoch: 6| Step: 10
Training loss: 1.1727759394853903
Validation loss: 2.486934081402676

Epoch: 6| Step: 11
Training loss: 1.1246758629826719
Validation loss: 2.5204470616574715

Epoch: 6| Step: 12
Training loss: 1.1848242378263159
Validation loss: 2.4783942333482254

Epoch: 6| Step: 13
Training loss: 0.5676979594784798
Validation loss: 2.4785783924067823

Epoch: 186| Step: 0
Training loss: 1.439772758037739
Validation loss: 2.4908751362240444

Epoch: 6| Step: 1
Training loss: 0.5875884638798434
Validation loss: 2.4643503021517863

Epoch: 6| Step: 2
Training loss: 1.0286213288426527
Validation loss: 2.4682501113774635

Epoch: 6| Step: 3
Training loss: 1.0569902500904707
Validation loss: 2.480571325802326

Epoch: 6| Step: 4
Training loss: 1.2145723978186096
Validation loss: 2.4779933642733942

Epoch: 6| Step: 5
Training loss: 1.1597881311100406
Validation loss: 2.476955048480265

Epoch: 6| Step: 6
Training loss: 1.1835149354786003
Validation loss: 2.478779880928816

Epoch: 6| Step: 7
Training loss: 1.2576136935428879
Validation loss: 2.4752827477557826

Epoch: 6| Step: 8
Training loss: 0.9659578632342128
Validation loss: 2.4646851219268195

Epoch: 6| Step: 9
Training loss: 1.2752212482046237
Validation loss: 2.4585508754689664

Epoch: 6| Step: 10
Training loss: 0.6330420701674198
Validation loss: 2.4774101165208067

Epoch: 6| Step: 11
Training loss: 1.4141544712569591
Validation loss: 2.512009391949733

Epoch: 6| Step: 12
Training loss: 1.5219218221429258
Validation loss: 2.501633143487074

Epoch: 6| Step: 13
Training loss: 0.5359547915324476
Validation loss: 2.5155851207729594

Epoch: 187| Step: 0
Training loss: 0.9763519060038239
Validation loss: 2.500719172084124

Epoch: 6| Step: 1
Training loss: 0.9642848817125389
Validation loss: 2.4837226013653826

Epoch: 6| Step: 2
Training loss: 1.0400521864085408
Validation loss: 2.5123047044800186

Epoch: 6| Step: 3
Training loss: 0.5657772912974953
Validation loss: 2.507612264676408

Epoch: 6| Step: 4
Training loss: 1.3462039364413905
Validation loss: 2.529448453132304

Epoch: 6| Step: 5
Training loss: 1.1827892427161046
Validation loss: 2.537573669970966

Epoch: 6| Step: 6
Training loss: 1.3884737326775214
Validation loss: 2.5805753318058007

Epoch: 6| Step: 7
Training loss: 1.1907735176270853
Validation loss: 2.5752759239060525

Epoch: 6| Step: 8
Training loss: 1.267856655466151
Validation loss: 2.5960244027683412

Epoch: 6| Step: 9
Training loss: 1.0613544122489285
Validation loss: 2.589964706839893

Epoch: 6| Step: 10
Training loss: 1.2049640125424999
Validation loss: 2.5802031980088986

Epoch: 6| Step: 11
Training loss: 0.7687811899448376
Validation loss: 2.5490211972859154

Epoch: 6| Step: 12
Training loss: 1.3626816969644162
Validation loss: 2.5277986725833794

Epoch: 6| Step: 13
Training loss: 1.1240123546063896
Validation loss: 2.522378956327581

Epoch: 188| Step: 0
Training loss: 1.3038829218547265
Validation loss: 2.4778819165549235

Epoch: 6| Step: 1
Training loss: 0.5121293495408785
Validation loss: 2.5006613799957034

Epoch: 6| Step: 2
Training loss: 1.0993138080372045
Validation loss: 2.497845724434813

Epoch: 6| Step: 3
Training loss: 1.048524951272287
Validation loss: 2.497536533516385

Epoch: 6| Step: 4
Training loss: 1.5017727072586475
Validation loss: 2.481831031899656

Epoch: 6| Step: 5
Training loss: 0.827091796088623
Validation loss: 2.5091302906983683

Epoch: 6| Step: 6
Training loss: 1.120622010617968
Validation loss: 2.4741397050694705

Epoch: 6| Step: 7
Training loss: 0.6583641149672321
Validation loss: 2.4920036645953627

Epoch: 6| Step: 8
Training loss: 1.3225516569148177
Validation loss: 2.500172449132353

Epoch: 6| Step: 9
Training loss: 0.9649782280121219
Validation loss: 2.527507214169188

Epoch: 6| Step: 10
Training loss: 1.1252410418516807
Validation loss: 2.490341065719313

Epoch: 6| Step: 11
Training loss: 1.0959019879977239
Validation loss: 2.4960633426457255

Epoch: 6| Step: 12
Training loss: 0.7752643934068224
Validation loss: 2.4773305955221976

Epoch: 6| Step: 13
Training loss: 1.6735979275779949
Validation loss: 2.495579930372672

Epoch: 189| Step: 0
Training loss: 1.2805006580671343
Validation loss: 2.4742316959734727

Epoch: 6| Step: 1
Training loss: 1.000904746852126
Validation loss: 2.4702353286932413

Epoch: 6| Step: 2
Training loss: 1.1237825587969306
Validation loss: 2.4798981950643286

Epoch: 6| Step: 3
Training loss: 1.2019370022480576
Validation loss: 2.4320965623417714

Epoch: 6| Step: 4
Training loss: 0.7342891237085398
Validation loss: 2.4567747881677415

Epoch: 6| Step: 5
Training loss: 1.0372899359873589
Validation loss: 2.466804748932577

Epoch: 6| Step: 6
Training loss: 1.1318794880635317
Validation loss: 2.4306034413516886

Epoch: 6| Step: 7
Training loss: 0.779487452711284
Validation loss: 2.4594430214321403

Epoch: 6| Step: 8
Training loss: 1.2398089302428124
Validation loss: 2.478594730455293

Epoch: 6| Step: 9
Training loss: 1.0604401986159795
Validation loss: 2.4945848812441844

Epoch: 6| Step: 10
Training loss: 0.8996357432321962
Validation loss: 2.5156021162982154

Epoch: 6| Step: 11
Training loss: 1.4486320521319378
Validation loss: 2.468036401538809

Epoch: 6| Step: 12
Training loss: 1.0909996875619135
Validation loss: 2.460561216944116

Epoch: 6| Step: 13
Training loss: 0.8129580747016012
Validation loss: 2.461334036141331

Epoch: 190| Step: 0
Training loss: 1.2989076977210878
Validation loss: 2.473230068784266

Epoch: 6| Step: 1
Training loss: 1.3438570733991675
Validation loss: 2.489062071700424

Epoch: 6| Step: 2
Training loss: 1.3150895322482723
Validation loss: 2.4825541357440764

Epoch: 6| Step: 3
Training loss: 0.652428216091435
Validation loss: 2.4992771005916032

Epoch: 6| Step: 4
Training loss: 0.652416430781675
Validation loss: 2.5116057162140417

Epoch: 6| Step: 5
Training loss: 1.3792400874545203
Validation loss: 2.5209355982315116

Epoch: 6| Step: 6
Training loss: 0.824173406284754
Validation loss: 2.5218471985612014

Epoch: 6| Step: 7
Training loss: 1.3186986868036832
Validation loss: 2.5024119114812104

Epoch: 6| Step: 8
Training loss: 1.169540878184916
Validation loss: 2.541664803025322

Epoch: 6| Step: 9
Training loss: 0.9741029207068931
Validation loss: 2.4952309240363566

Epoch: 6| Step: 10
Training loss: 0.8506959127988707
Validation loss: 2.474498657564489

Epoch: 6| Step: 11
Training loss: 0.91539706104266
Validation loss: 2.464016259861786

Epoch: 6| Step: 12
Training loss: 1.1668671481129353
Validation loss: 2.4388628374159214

Epoch: 6| Step: 13
Training loss: 0.15641792333830074
Validation loss: 2.4587319226322473

Epoch: 191| Step: 0
Training loss: 0.9100575209348388
Validation loss: 2.410915805325952

Epoch: 6| Step: 1
Training loss: 1.3230322189127477
Validation loss: 2.4764144965551247

Epoch: 6| Step: 2
Training loss: 0.971442050725118
Validation loss: 2.4410499635020018

Epoch: 6| Step: 3
Training loss: 1.2234976801193562
Validation loss: 2.46147318015232

Epoch: 6| Step: 4
Training loss: 0.7715008311387713
Validation loss: 2.4845458415872774

Epoch: 6| Step: 5
Training loss: 1.3981027468878702
Validation loss: 2.5012674876912118

Epoch: 6| Step: 6
Training loss: 1.06865636404223
Validation loss: 2.5044672502655647

Epoch: 6| Step: 7
Training loss: 0.4801942149532755
Validation loss: 2.4679058132667158

Epoch: 6| Step: 8
Training loss: 0.9622476841538694
Validation loss: 2.4852391470657866

Epoch: 6| Step: 9
Training loss: 1.093012588418014
Validation loss: 2.466074271171442

Epoch: 6| Step: 10
Training loss: 1.1145394693935515
Validation loss: 2.499139840832181

Epoch: 6| Step: 11
Training loss: 1.3581052528206172
Validation loss: 2.4607194378417967

Epoch: 6| Step: 12
Training loss: 0.8229138136866565
Validation loss: 2.4143455337592954

Epoch: 6| Step: 13
Training loss: 1.1877464741353618
Validation loss: 2.40416990500202

Epoch: 192| Step: 0
Training loss: 1.0335633311621548
Validation loss: 2.43757347204449

Epoch: 6| Step: 1
Training loss: 0.8240343583661137
Validation loss: 2.438307454604218

Epoch: 6| Step: 2
Training loss: 0.9233269329973887
Validation loss: 2.4399174244842503

Epoch: 6| Step: 3
Training loss: 1.0242681262977777
Validation loss: 2.4549573047780644

Epoch: 6| Step: 4
Training loss: 0.8262046284416904
Validation loss: 2.4815803680883475

Epoch: 6| Step: 5
Training loss: 1.2949019900905356
Validation loss: 2.505638641438237

Epoch: 6| Step: 6
Training loss: 0.9341106181099992
Validation loss: 2.473462398714336

Epoch: 6| Step: 7
Training loss: 0.7368254664162978
Validation loss: 2.5327207823822198

Epoch: 6| Step: 8
Training loss: 1.1192772800170554
Validation loss: 2.547104206714258

Epoch: 6| Step: 9
Training loss: 1.2145083047104672
Validation loss: 2.5387911360171462

Epoch: 6| Step: 10
Training loss: 1.1983827541136662
Validation loss: 2.583710973991911

Epoch: 6| Step: 11
Training loss: 1.324451842371834
Validation loss: 2.54930689358073

Epoch: 6| Step: 12
Training loss: 0.8338868131010969
Validation loss: 2.5197040015004064

Epoch: 6| Step: 13
Training loss: 1.3433429633821632
Validation loss: 2.485095908530428

Epoch: 193| Step: 0
Training loss: 1.1683907655448313
Validation loss: 2.493105195522905

Epoch: 6| Step: 1
Training loss: 1.2079222517003958
Validation loss: 2.4549357592849548

Epoch: 6| Step: 2
Training loss: 1.3250493058441601
Validation loss: 2.4263866899496684

Epoch: 6| Step: 3
Training loss: 0.6021074328719758
Validation loss: 2.4599624006737955

Epoch: 6| Step: 4
Training loss: 1.1938183989577065
Validation loss: 2.463496744595772

Epoch: 6| Step: 5
Training loss: 1.016859800463128
Validation loss: 2.44966311671939

Epoch: 6| Step: 6
Training loss: 0.9288442939135791
Validation loss: 2.437473689805772

Epoch: 6| Step: 7
Training loss: 1.0143324623425927
Validation loss: 2.4598226375938923

Epoch: 6| Step: 8
Training loss: 0.835317970369282
Validation loss: 2.483762026074288

Epoch: 6| Step: 9
Training loss: 0.9959076950741214
Validation loss: 2.4532879274395576

Epoch: 6| Step: 10
Training loss: 1.1000442322594333
Validation loss: 2.4832787618472354

Epoch: 6| Step: 11
Training loss: 0.7568857484238587
Validation loss: 2.4887321569617793

Epoch: 6| Step: 12
Training loss: 1.136181681544181
Validation loss: 2.4689235426360243

Epoch: 6| Step: 13
Training loss: 1.1098395973159025
Validation loss: 2.48900962391156

Epoch: 194| Step: 0
Training loss: 1.0093262415585973
Validation loss: 2.429991717141087

Epoch: 6| Step: 1
Training loss: 1.2241951517193257
Validation loss: 2.401694049381784

Epoch: 6| Step: 2
Training loss: 1.405237893297225
Validation loss: 2.3681737076723928

Epoch: 6| Step: 3
Training loss: 1.315010938707697
Validation loss: 2.390454112398259

Epoch: 6| Step: 4
Training loss: 0.8781596764067715
Validation loss: 2.3622226807765667

Epoch: 6| Step: 5
Training loss: 0.9247756196139608
Validation loss: 2.3661887052669632

Epoch: 6| Step: 6
Training loss: 0.7197773681265658
Validation loss: 2.3234935991145877

Epoch: 6| Step: 7
Training loss: 0.8723857860081506
Validation loss: 2.3606844324891516

Epoch: 6| Step: 8
Training loss: 0.7615125328079612
Validation loss: 2.3857727007190475

Epoch: 6| Step: 9
Training loss: 1.081264292892628
Validation loss: 2.3765234613512773

Epoch: 6| Step: 10
Training loss: 1.0220077078504353
Validation loss: 2.3955304254385483

Epoch: 6| Step: 11
Training loss: 0.9198452862972483
Validation loss: 2.3791318011571643

Epoch: 6| Step: 12
Training loss: 0.9035872441334152
Validation loss: 2.4029040843899696

Epoch: 6| Step: 13
Training loss: 1.1639592681784512
Validation loss: 2.3997049181880614

Epoch: 195| Step: 0
Training loss: 0.9347986721600694
Validation loss: 2.397790793634365

Epoch: 6| Step: 1
Training loss: 1.2637696029395409
Validation loss: 2.3966068797093727

Epoch: 6| Step: 2
Training loss: 0.8352785454501869
Validation loss: 2.387707558957891

Epoch: 6| Step: 3
Training loss: 0.6015357717545929
Validation loss: 2.4120296621035915

Epoch: 6| Step: 4
Training loss: 0.9847273120440708
Validation loss: 2.4068433839395524

Epoch: 6| Step: 5
Training loss: 0.6546759574801267
Validation loss: 2.4271402836008114

Epoch: 6| Step: 6
Training loss: 1.2990792626828922
Validation loss: 2.424913902813688

Epoch: 6| Step: 7
Training loss: 0.9154330680626853
Validation loss: 2.4381456616435124

Epoch: 6| Step: 8
Training loss: 1.162275030045875
Validation loss: 2.4898742520908526

Epoch: 6| Step: 9
Training loss: 1.0476886946215023
Validation loss: 2.48142410030796

Epoch: 6| Step: 10
Training loss: 0.8929420580675193
Validation loss: 2.4773115057563433

Epoch: 6| Step: 11
Training loss: 0.9891695998120761
Validation loss: 2.4621307246079436

Epoch: 6| Step: 12
Training loss: 0.9574982418512283
Validation loss: 2.492165562468887

Epoch: 6| Step: 13
Training loss: 1.208766837569861
Validation loss: 2.495690770614022

Epoch: 196| Step: 0
Training loss: 0.6713615052083781
Validation loss: 2.452686477277932

Epoch: 6| Step: 1
Training loss: 0.8036256469116361
Validation loss: 2.464980343358792

Epoch: 6| Step: 2
Training loss: 0.9722745215260659
Validation loss: 2.4653146532940355

Epoch: 6| Step: 3
Training loss: 1.2765485522326503
Validation loss: 2.424760958974844

Epoch: 6| Step: 4
Training loss: 1.0080810898679677
Validation loss: 2.442512696607534

Epoch: 6| Step: 5
Training loss: 0.802363697610063
Validation loss: 2.416043608237612

Epoch: 6| Step: 6
Training loss: 0.9712808221666522
Validation loss: 2.3984201092677595

Epoch: 6| Step: 7
Training loss: 1.2917938887587856
Validation loss: 2.4341620198845546

Epoch: 6| Step: 8
Training loss: 0.5634456209516787
Validation loss: 2.4304464538589245

Epoch: 6| Step: 9
Training loss: 1.19936178640429
Validation loss: 2.423681802899165

Epoch: 6| Step: 10
Training loss: 1.0111336802198325
Validation loss: 2.4415540608607005

Epoch: 6| Step: 11
Training loss: 0.7719661319078147
Validation loss: 2.44943222086698

Epoch: 6| Step: 12
Training loss: 1.0943450399030799
Validation loss: 2.444804749856076

Epoch: 6| Step: 13
Training loss: 1.1983175961270636
Validation loss: 2.485701971424159

Epoch: 197| Step: 0
Training loss: 0.8196509100265817
Validation loss: 2.492184130072015

Epoch: 6| Step: 1
Training loss: 1.3329440482402612
Validation loss: 2.499567457178828

Epoch: 6| Step: 2
Training loss: 0.8563804819412958
Validation loss: 2.4985564699376743

Epoch: 6| Step: 3
Training loss: 0.9059170078303498
Validation loss: 2.484446822691785

Epoch: 6| Step: 4
Training loss: 0.6336555516667645
Validation loss: 2.4977029009430423

Epoch: 6| Step: 5
Training loss: 1.1004712807505586
Validation loss: 2.48216781761326

Epoch: 6| Step: 6
Training loss: 0.8366082610936928
Validation loss: 2.453545058323381

Epoch: 6| Step: 7
Training loss: 1.171098120988523
Validation loss: 2.4640464457219102

Epoch: 6| Step: 8
Training loss: 0.9299350056445911
Validation loss: 2.449784454953791

Epoch: 6| Step: 9
Training loss: 1.2505720260206206
Validation loss: 2.444233537021713

Epoch: 6| Step: 10
Training loss: 1.0504975910985273
Validation loss: 2.4060428148239352

Epoch: 6| Step: 11
Training loss: 0.772375591593323
Validation loss: 2.378118908765879

Epoch: 6| Step: 12
Training loss: 0.733681615212979
Validation loss: 2.418122914862381

Epoch: 6| Step: 13
Training loss: 1.068234675241468
Validation loss: 2.3949090217044726

Epoch: 198| Step: 0
Training loss: 0.9442906176512115
Validation loss: 2.4225205930788283

Epoch: 6| Step: 1
Training loss: 0.9708483336003381
Validation loss: 2.439104009422244

Epoch: 6| Step: 2
Training loss: 1.2498833125009987
Validation loss: 2.43928047363367

Epoch: 6| Step: 3
Training loss: 0.8749943801154452
Validation loss: 2.463793793035478

Epoch: 6| Step: 4
Training loss: 0.6942764449888424
Validation loss: 2.4796901145799435

Epoch: 6| Step: 5
Training loss: 1.1611559122032054
Validation loss: 2.4902911325445376

Epoch: 6| Step: 6
Training loss: 0.48710218361545427
Validation loss: 2.448589103952441

Epoch: 6| Step: 7
Training loss: 1.2107567436917375
Validation loss: 2.4706368609278697

Epoch: 6| Step: 8
Training loss: 1.071382363776213
Validation loss: 2.475236640208325

Epoch: 6| Step: 9
Training loss: 0.9422511191580328
Validation loss: 2.427993670940555

Epoch: 6| Step: 10
Training loss: 1.0370181056090988
Validation loss: 2.4172687636200227

Epoch: 6| Step: 11
Training loss: 0.6805820497774971
Validation loss: 2.447608684015569

Epoch: 6| Step: 12
Training loss: 0.9537389372637742
Validation loss: 2.3961742042712175

Epoch: 6| Step: 13
Training loss: 0.9972689110432452
Validation loss: 2.430403400664808

Epoch: 199| Step: 0
Training loss: 1.1711314576372307
Validation loss: 2.4272575085303516

Epoch: 6| Step: 1
Training loss: 1.2026056927648845
Validation loss: 2.448731899374542

Epoch: 6| Step: 2
Training loss: 0.8285294750590138
Validation loss: 2.400270910935844

Epoch: 6| Step: 3
Training loss: 0.8075996221733248
Validation loss: 2.4240399267183506

Epoch: 6| Step: 4
Training loss: 1.212390790524016
Validation loss: 2.4078415986020505

Epoch: 6| Step: 5
Training loss: 1.1198162815434458
Validation loss: 2.4086105994239886

Epoch: 6| Step: 6
Training loss: 1.0471089799085163
Validation loss: 2.4128338572095616

Epoch: 6| Step: 7
Training loss: 0.5502565197521558
Validation loss: 2.448666565359309

Epoch: 6| Step: 8
Training loss: 1.0695826137071207
Validation loss: 2.431156430973401

Epoch: 6| Step: 9
Training loss: 0.6926931484728341
Validation loss: 2.45157256839378

Epoch: 6| Step: 10
Training loss: 0.6946440923653896
Validation loss: 2.439570111367557

Epoch: 6| Step: 11
Training loss: 0.8333613549925357
Validation loss: 2.4490622753583637

Epoch: 6| Step: 12
Training loss: 0.837175717842263
Validation loss: 2.4791629360712415

Epoch: 6| Step: 13
Training loss: 0.9820749872462889
Validation loss: 2.4991821038137787

Epoch: 200| Step: 0
Training loss: 0.6220901462141839
Validation loss: 2.5173142013356364

Epoch: 6| Step: 1
Training loss: 0.8825772064736378
Validation loss: 2.4602239467245135

Epoch: 6| Step: 2
Training loss: 0.9194734618405872
Validation loss: 2.4637027609673523

Epoch: 6| Step: 3
Training loss: 0.7904402535846713
Validation loss: 2.439200458935833

Epoch: 6| Step: 4
Training loss: 1.1039438682674396
Validation loss: 2.4670948925509166

Epoch: 6| Step: 5
Training loss: 0.7578042020048467
Validation loss: 2.4808006844194783

Epoch: 6| Step: 6
Training loss: 1.040377938666657
Validation loss: 2.4545347908475885

Epoch: 6| Step: 7
Training loss: 1.084719956466603
Validation loss: 2.466441559005388

Epoch: 6| Step: 8
Training loss: 1.183488092018498
Validation loss: 2.4675918911564727

Epoch: 6| Step: 9
Training loss: 0.3093402862339492
Validation loss: 2.5457954768724265

Epoch: 6| Step: 10
Training loss: 1.2017867832668978
Validation loss: 2.5377646931681603

Epoch: 6| Step: 11
Training loss: 0.8207976586840143
Validation loss: 2.5432275789986427

Epoch: 6| Step: 12
Training loss: 1.0465409614212409
Validation loss: 2.5146580491647397

Epoch: 6| Step: 13
Training loss: 1.2514715116384987
Validation loss: 2.518680044041552

Epoch: 201| Step: 0
Training loss: 0.5966244186551986
Validation loss: 2.5383140592977376

Epoch: 6| Step: 1
Training loss: 0.8920849996768284
Validation loss: 2.4996359098555696

Epoch: 6| Step: 2
Training loss: 0.7158119440565363
Validation loss: 2.5083387388378875

Epoch: 6| Step: 3
Training loss: 0.9915869690153881
Validation loss: 2.52215816113089

Epoch: 6| Step: 4
Training loss: 0.8640666168280374
Validation loss: 2.502383329688492

Epoch: 6| Step: 5
Training loss: 0.9705734933916771
Validation loss: 2.4726456466623974

Epoch: 6| Step: 6
Training loss: 0.7899494662600497
Validation loss: 2.476091479777783

Epoch: 6| Step: 7
Training loss: 0.9878289616391875
Validation loss: 2.4673851480318882

Epoch: 6| Step: 8
Training loss: 0.7936471376826836
Validation loss: 2.4585940363743646

Epoch: 6| Step: 9
Training loss: 1.4924181215712025
Validation loss: 2.4484496371418785

Epoch: 6| Step: 10
Training loss: 0.4653765726137192
Validation loss: 2.4355655974073525

Epoch: 6| Step: 11
Training loss: 1.1659386895387625
Validation loss: 2.469061681642528

Epoch: 6| Step: 12
Training loss: 0.8873413857577815
Validation loss: 2.4349587600435547

Epoch: 6| Step: 13
Training loss: 1.097843412142708
Validation loss: 2.439536729073252

Epoch: 202| Step: 0
Training loss: 1.017448197341905
Validation loss: 2.461875460460691

Epoch: 6| Step: 1
Training loss: 0.9608978635475401
Validation loss: 2.52545344755484

Epoch: 6| Step: 2
Training loss: 0.894146899146736
Validation loss: 2.52031898047849

Epoch: 6| Step: 3
Training loss: 0.8423893872328848
Validation loss: 2.5354616409826445

Epoch: 6| Step: 4
Training loss: 1.083321033310144
Validation loss: 2.504038510334498

Epoch: 6| Step: 5
Training loss: 0.9608281391220659
Validation loss: 2.503303270294493

Epoch: 6| Step: 6
Training loss: 0.7179399984785674
Validation loss: 2.512436673717213

Epoch: 6| Step: 7
Training loss: 0.741320173534677
Validation loss: 2.487956085005194

Epoch: 6| Step: 8
Training loss: 0.7277883627374971
Validation loss: 2.4779191823983364

Epoch: 6| Step: 9
Training loss: 0.9813971208725671
Validation loss: 2.50652411421043

Epoch: 6| Step: 10
Training loss: 0.8581378007282731
Validation loss: 2.4960576485434762

Epoch: 6| Step: 11
Training loss: 0.9368752941311813
Validation loss: 2.4663739985981197

Epoch: 6| Step: 12
Training loss: 0.7879458164597113
Validation loss: 2.494115519263361

Epoch: 6| Step: 13
Training loss: 1.328985855256895
Validation loss: 2.50312477402579

Epoch: 203| Step: 0
Training loss: 1.0853428481779965
Validation loss: 2.458292788631272

Epoch: 6| Step: 1
Training loss: 0.8488533251515539
Validation loss: 2.470047605182894

Epoch: 6| Step: 2
Training loss: 0.7734075983605956
Validation loss: 2.465554316130187

Epoch: 6| Step: 3
Training loss: 0.7367642676813593
Validation loss: 2.4362657596885695

Epoch: 6| Step: 4
Training loss: 1.233858265943093
Validation loss: 2.463188114451067

Epoch: 6| Step: 5
Training loss: 0.965948854229732
Validation loss: 2.458986472631368

Epoch: 6| Step: 6
Training loss: 0.7769967843164699
Validation loss: 2.4366380604765743

Epoch: 6| Step: 7
Training loss: 1.235204393870934
Validation loss: 2.4767449155444963

Epoch: 6| Step: 8
Training loss: 0.7114227232019682
Validation loss: 2.4855379176861705

Epoch: 6| Step: 9
Training loss: 0.7965260657998174
Validation loss: 2.454780058445599

Epoch: 6| Step: 10
Training loss: 0.9580124165680014
Validation loss: 2.494743290352365

Epoch: 6| Step: 11
Training loss: 0.8744336066193098
Validation loss: 2.491226192447645

Epoch: 6| Step: 12
Training loss: 0.9157329196279513
Validation loss: 2.4771140509756138

Epoch: 6| Step: 13
Training loss: 0.6968258665066929
Validation loss: 2.481526667612853

Epoch: 204| Step: 0
Training loss: 0.8190795715602189
Validation loss: 2.451203373676092

Epoch: 6| Step: 1
Training loss: 0.8686714877870418
Validation loss: 2.5147109595591655

Epoch: 6| Step: 2
Training loss: 0.6036865584882216
Validation loss: 2.4973418245026604

Epoch: 6| Step: 3
Training loss: 0.6386053534812313
Validation loss: 2.480828637527093

Epoch: 6| Step: 4
Training loss: 0.3660190740888968
Validation loss: 2.514680279821753

Epoch: 6| Step: 5
Training loss: 0.5816592109124006
Validation loss: 2.5216995767240666

Epoch: 6| Step: 6
Training loss: 0.9043138144041482
Validation loss: 2.487291579147139

Epoch: 6| Step: 7
Training loss: 0.9785828710052127
Validation loss: 2.485987351539678

Epoch: 6| Step: 8
Training loss: 0.9072771171223684
Validation loss: 2.477721123680963

Epoch: 6| Step: 9
Training loss: 1.3159686077049269
Validation loss: 2.4652944857061847

Epoch: 6| Step: 10
Training loss: 1.1236065075568749
Validation loss: 2.46573790475985

Epoch: 6| Step: 11
Training loss: 1.039755167294077
Validation loss: 2.4617258570010403

Epoch: 6| Step: 12
Training loss: 0.9709378118057168
Validation loss: 2.419113932069796

Epoch: 6| Step: 13
Training loss: 1.1690209793675288
Validation loss: 2.4243099308269254

Epoch: 205| Step: 0
Training loss: 0.8214274504162264
Validation loss: 2.4297151843914215

Epoch: 6| Step: 1
Training loss: 0.4792883725333205
Validation loss: 2.419116079109484

Epoch: 6| Step: 2
Training loss: 1.0687018757297249
Validation loss: 2.4336375700012796

Epoch: 6| Step: 3
Training loss: 0.7637688070375994
Validation loss: 2.437123518046361

Epoch: 6| Step: 4
Training loss: 0.7015706153179364
Validation loss: 2.4106621076349

Epoch: 6| Step: 5
Training loss: 1.0451343926339722
Validation loss: 2.4777012453899836

Epoch: 6| Step: 6
Training loss: 1.0373160233593788
Validation loss: 2.4706084780982422

Epoch: 6| Step: 7
Training loss: 0.839368250884349
Validation loss: 2.470512150654298

Epoch: 6| Step: 8
Training loss: 0.9405355582058247
Validation loss: 2.4719035997291026

Epoch: 6| Step: 9
Training loss: 1.336118050136687
Validation loss: 2.4766158267741503

Epoch: 6| Step: 10
Training loss: 0.5166795523892713
Validation loss: 2.4588818328402877

Epoch: 6| Step: 11
Training loss: 0.9541561302425112
Validation loss: 2.4535461214804535

Epoch: 6| Step: 12
Training loss: 1.0091858016283484
Validation loss: 2.443381723450403

Epoch: 6| Step: 13
Training loss: 0.4776528033830046
Validation loss: 2.4474264476588776

Epoch: 206| Step: 0
Training loss: 0.36995673413165003
Validation loss: 2.45521263559234

Epoch: 6| Step: 1
Training loss: 0.8543079460972088
Validation loss: 2.4661107294311044

Epoch: 6| Step: 2
Training loss: 0.9655815114718828
Validation loss: 2.443890335182233

Epoch: 6| Step: 3
Training loss: 1.1517946130993888
Validation loss: 2.4311123094763976

Epoch: 6| Step: 4
Training loss: 0.7599965899165093
Validation loss: 2.4982175194598515

Epoch: 6| Step: 5
Training loss: 0.6981737223317456
Validation loss: 2.4593787050240783

Epoch: 6| Step: 6
Training loss: 1.0098678566630104
Validation loss: 2.477594137643676

Epoch: 6| Step: 7
Training loss: 0.7866521600689609
Validation loss: 2.4970396521563227

Epoch: 6| Step: 8
Training loss: 0.6419978202756083
Validation loss: 2.5153591611963857

Epoch: 6| Step: 9
Training loss: 0.8803772209407031
Validation loss: 2.5278194570848336

Epoch: 6| Step: 10
Training loss: 0.9733572276222087
Validation loss: 2.5373718367966025

Epoch: 6| Step: 11
Training loss: 1.0633883409014147
Validation loss: 2.5357955403899255

Epoch: 6| Step: 12
Training loss: 0.9959406417160346
Validation loss: 2.51203048976906

Epoch: 6| Step: 13
Training loss: 0.835850577425348
Validation loss: 2.4595657460625975

Epoch: 207| Step: 0
Training loss: 0.9444561381800393
Validation loss: 2.4852652450642836

Epoch: 6| Step: 1
Training loss: 1.1393403435237153
Validation loss: 2.499831214457409

Epoch: 6| Step: 2
Training loss: 0.5381410158633916
Validation loss: 2.481379228878368

Epoch: 6| Step: 3
Training loss: 0.8718963141895348
Validation loss: 2.4731734535390286

Epoch: 6| Step: 4
Training loss: 0.7968259310106911
Validation loss: 2.48431889878321

Epoch: 6| Step: 5
Training loss: 0.5759963463263398
Validation loss: 2.4950605407658704

Epoch: 6| Step: 6
Training loss: 0.8594612771854245
Validation loss: 2.50927057265661

Epoch: 6| Step: 7
Training loss: 0.8807449097281889
Validation loss: 2.45303806485044

Epoch: 6| Step: 8
Training loss: 0.5815186002992275
Validation loss: 2.4824823109607563

Epoch: 6| Step: 9
Training loss: 1.1295927395787209
Validation loss: 2.4699663774452882

Epoch: 6| Step: 10
Training loss: 0.8566042188291579
Validation loss: 2.493948882717716

Epoch: 6| Step: 11
Training loss: 0.9602866721287721
Validation loss: 2.4233258260633863

Epoch: 6| Step: 12
Training loss: 1.0380611326998848
Validation loss: 2.460238346570638

Epoch: 6| Step: 13
Training loss: 0.6054141112254172
Validation loss: 2.4547172903377747

Epoch: 208| Step: 0
Training loss: 0.6932286528813049
Validation loss: 2.4449343553582796

Epoch: 6| Step: 1
Training loss: 0.92167903951051
Validation loss: 2.4783509745375016

Epoch: 6| Step: 2
Training loss: 0.795113505291922
Validation loss: 2.4584883006122746

Epoch: 6| Step: 3
Training loss: 0.7261718602254865
Validation loss: 2.473776720998472

Epoch: 6| Step: 4
Training loss: 0.845188221988766
Validation loss: 2.4603653583371132

Epoch: 6| Step: 5
Training loss: 0.8924816588646287
Validation loss: 2.4904935757470703

Epoch: 6| Step: 6
Training loss: 1.0932995549853446
Validation loss: 2.453317917181929

Epoch: 6| Step: 7
Training loss: 0.6740823238607484
Validation loss: 2.494109885984445

Epoch: 6| Step: 8
Training loss: 0.5975376335566357
Validation loss: 2.4675827413351357

Epoch: 6| Step: 9
Training loss: 0.8236420046298142
Validation loss: 2.537783309503353

Epoch: 6| Step: 10
Training loss: 0.9091269767715612
Validation loss: 2.5113428492542997

Epoch: 6| Step: 11
Training loss: 1.08253417738598
Validation loss: 2.482873647819111

Epoch: 6| Step: 12
Training loss: 0.8663517817032175
Validation loss: 2.5170281482355437

Epoch: 6| Step: 13
Training loss: 0.8291585698203663
Validation loss: 2.5288519377967216

Epoch: 209| Step: 0
Training loss: 0.41766840402234706
Validation loss: 2.511097778135847

Epoch: 6| Step: 1
Training loss: 0.6191030063692945
Validation loss: 2.491046337835573

Epoch: 6| Step: 2
Training loss: 1.0478812548580287
Validation loss: 2.465897341523821

Epoch: 6| Step: 3
Training loss: 0.7820274299581634
Validation loss: 2.4595326883201434

Epoch: 6| Step: 4
Training loss: 0.8531820662419545
Validation loss: 2.4584030390375107

Epoch: 6| Step: 5
Training loss: 0.8354299555329618
Validation loss: 2.469960314916071

Epoch: 6| Step: 6
Training loss: 0.6639627269515318
Validation loss: 2.4730353773096065

Epoch: 6| Step: 7
Training loss: 0.8923020885523032
Validation loss: 2.4723166966619456

Epoch: 6| Step: 8
Training loss: 0.8532079495636861
Validation loss: 2.4533365865231507

Epoch: 6| Step: 9
Training loss: 0.412707198008414
Validation loss: 2.4552596673473404

Epoch: 6| Step: 10
Training loss: 1.0006593080508868
Validation loss: 2.4868119450582635

Epoch: 6| Step: 11
Training loss: 0.9983218536502378
Validation loss: 2.4925118990425976

Epoch: 6| Step: 12
Training loss: 1.0523455579440553
Validation loss: 2.4618147706247244

Epoch: 6| Step: 13
Training loss: 1.0411763308728785
Validation loss: 2.4955828467975967

Epoch: 210| Step: 0
Training loss: 0.9063770928548762
Validation loss: 2.4588676909156484

Epoch: 6| Step: 1
Training loss: 0.901655322606994
Validation loss: 2.470900079458939

Epoch: 6| Step: 2
Training loss: 0.9079671573707006
Validation loss: 2.477575083020029

Epoch: 6| Step: 3
Training loss: 0.8038338141991257
Validation loss: 2.466342120935143

Epoch: 6| Step: 4
Training loss: 0.7021435351459272
Validation loss: 2.4727642755848795

Epoch: 6| Step: 5
Training loss: 0.6704804119019563
Validation loss: 2.510001254433377

Epoch: 6| Step: 6
Training loss: 1.070545811527684
Validation loss: 2.47529200271864

Epoch: 6| Step: 7
Training loss: 0.7840413010651738
Validation loss: 2.464031663405014

Epoch: 6| Step: 8
Training loss: 0.6402288933566431
Validation loss: 2.5072924225747926

Epoch: 6| Step: 9
Training loss: 1.1052430262799684
Validation loss: 2.496198703160897

Epoch: 6| Step: 10
Training loss: 0.653434595168164
Validation loss: 2.4790881837241816

Epoch: 6| Step: 11
Training loss: 0.7957092809275137
Validation loss: 2.5046582988888657

Epoch: 6| Step: 12
Training loss: 0.7190964320008743
Validation loss: 2.4894105485135043

Epoch: 6| Step: 13
Training loss: 0.8829231530443766
Validation loss: 2.52221766528175

Epoch: 211| Step: 0
Training loss: 1.1807253484856326
Validation loss: 2.4734407589250362

Epoch: 6| Step: 1
Training loss: 0.549815420042616
Validation loss: 2.4821251699091915

Epoch: 6| Step: 2
Training loss: 0.7750405162557124
Validation loss: 2.450659457672218

Epoch: 6| Step: 3
Training loss: 0.9524651416397444
Validation loss: 2.449244311759748

Epoch: 6| Step: 4
Training loss: 0.5933731288458519
Validation loss: 2.429643044778747

Epoch: 6| Step: 5
Training loss: 0.7702794189778026
Validation loss: 2.4587666197655613

Epoch: 6| Step: 6
Training loss: 0.7218377504192323
Validation loss: 2.4131895842588946

Epoch: 6| Step: 7
Training loss: 0.6131582440493123
Validation loss: 2.415466776803945

Epoch: 6| Step: 8
Training loss: 0.8076620585328105
Validation loss: 2.4117457458793763

Epoch: 6| Step: 9
Training loss: 1.2351491890499768
Validation loss: 2.397852921634005

Epoch: 6| Step: 10
Training loss: 0.5573003239419715
Validation loss: 2.404042842987116

Epoch: 6| Step: 11
Training loss: 0.5227390012820009
Validation loss: 2.4160544069302983

Epoch: 6| Step: 12
Training loss: 1.0762249332924811
Validation loss: 2.397287540219021

Epoch: 6| Step: 13
Training loss: 0.4851343601466951
Validation loss: 2.3618790181465394

Epoch: 212| Step: 0
Training loss: 0.8846867001933124
Validation loss: 2.3365124628543548

Epoch: 6| Step: 1
Training loss: 1.250984662377417
Validation loss: 2.359353026611214

Epoch: 6| Step: 2
Training loss: 0.9527471450006154
Validation loss: 2.3733802938277218

Epoch: 6| Step: 3
Training loss: 0.7172218746682187
Validation loss: 2.350034380285799

Epoch: 6| Step: 4
Training loss: 0.6823262698496347
Validation loss: 2.3715184550658943

Epoch: 6| Step: 5
Training loss: 0.6199439820624618
Validation loss: 2.388897786533657

Epoch: 6| Step: 6
Training loss: 0.6459643528436019
Validation loss: 2.4074563117783745

Epoch: 6| Step: 7
Training loss: 1.1965316837832758
Validation loss: 2.4298093018938367

Epoch: 6| Step: 8
Training loss: 0.791251743067649
Validation loss: 2.425482068080177

Epoch: 6| Step: 9
Training loss: 0.30096167565326465
Validation loss: 2.4342793432031757

Epoch: 6| Step: 10
Training loss: 0.6551712115576612
Validation loss: 2.4911213282326647

Epoch: 6| Step: 11
Training loss: 0.9250424813490541
Validation loss: 2.487035367992441

Epoch: 6| Step: 12
Training loss: 0.6067962368298383
Validation loss: 2.4906070561132583

Epoch: 6| Step: 13
Training loss: 0.7241723318357597
Validation loss: 2.493849022607582

Epoch: 213| Step: 0
Training loss: 1.018339725095561
Validation loss: 2.5227189448833447

Epoch: 6| Step: 1
Training loss: 0.9848739933609614
Validation loss: 2.551112399680416

Epoch: 6| Step: 2
Training loss: 0.8254045390496718
Validation loss: 2.545487756403267

Epoch: 6| Step: 3
Training loss: 0.7521684214538193
Validation loss: 2.5370604219143926

Epoch: 6| Step: 4
Training loss: 0.6418287783568177
Validation loss: 2.503473790965941

Epoch: 6| Step: 5
Training loss: 0.7963557327950352
Validation loss: 2.4976994419748357

Epoch: 6| Step: 6
Training loss: 0.9741860121891043
Validation loss: 2.482200823326459

Epoch: 6| Step: 7
Training loss: 0.8857820916150816
Validation loss: 2.494457678684348

Epoch: 6| Step: 8
Training loss: 0.3852197900323111
Validation loss: 2.442829052395596

Epoch: 6| Step: 9
Training loss: 0.9099179721374212
Validation loss: 2.4069610619019333

Epoch: 6| Step: 10
Training loss: 0.8296486495237889
Validation loss: 2.4402015813590343

Epoch: 6| Step: 11
Training loss: 0.61054225536705
Validation loss: 2.429162719406185

Epoch: 6| Step: 12
Training loss: 0.8632442069413027
Validation loss: 2.459179269841593

Epoch: 6| Step: 13
Training loss: 0.43016161337826425
Validation loss: 2.4372294422789538

Epoch: 214| Step: 0
Training loss: 0.9272201237147818
Validation loss: 2.448989444237981

Epoch: 6| Step: 1
Training loss: 1.025648102904013
Validation loss: 2.4387897900035655

Epoch: 6| Step: 2
Training loss: 0.3261866766032439
Validation loss: 2.4625302594561265

Epoch: 6| Step: 3
Training loss: 0.36095196500915216
Validation loss: 2.4044821053495675

Epoch: 6| Step: 4
Training loss: 0.5520076759848189
Validation loss: 2.453065339405333

Epoch: 6| Step: 5
Training loss: 0.9313949164981069
Validation loss: 2.4466851614731726

Epoch: 6| Step: 6
Training loss: 0.6178810230974849
Validation loss: 2.450611295692537

Epoch: 6| Step: 7
Training loss: 1.0729465789081933
Validation loss: 2.474409756279973

Epoch: 6| Step: 8
Training loss: 0.834880445738736
Validation loss: 2.4435783862461435

Epoch: 6| Step: 9
Training loss: 0.6653089157875167
Validation loss: 2.4483107697081494

Epoch: 6| Step: 10
Training loss: 0.9105854250464741
Validation loss: 2.4829001320631443

Epoch: 6| Step: 11
Training loss: 0.7570873605820134
Validation loss: 2.4879418363114834

Epoch: 6| Step: 12
Training loss: 0.9187663732094775
Validation loss: 2.4725319681882114

Epoch: 6| Step: 13
Training loss: 0.8834159948850645
Validation loss: 2.460007428275504

Epoch: 215| Step: 0
Training loss: 0.830095394179279
Validation loss: 2.458474131397262

Epoch: 6| Step: 1
Training loss: 0.7949123522588781
Validation loss: 2.4848241030554923

Epoch: 6| Step: 2
Training loss: 0.3929426294522591
Validation loss: 2.4924824806545827

Epoch: 6| Step: 3
Training loss: 0.6919796823291694
Validation loss: 2.4618611503736987

Epoch: 6| Step: 4
Training loss: 0.5794767351343503
Validation loss: 2.4918407191588403

Epoch: 6| Step: 5
Training loss: 0.8698552654717666
Validation loss: 2.490553144705927

Epoch: 6| Step: 6
Training loss: 0.8639564462872176
Validation loss: 2.478855588869258

Epoch: 6| Step: 7
Training loss: 1.070693011063881
Validation loss: 2.4743665329715827

Epoch: 6| Step: 8
Training loss: 0.9729177590690106
Validation loss: 2.4605012156988817

Epoch: 6| Step: 9
Training loss: 0.5097342587463772
Validation loss: 2.4841566288451387

Epoch: 6| Step: 10
Training loss: 0.474895548002148
Validation loss: 2.47047328863255

Epoch: 6| Step: 11
Training loss: 0.879683290949182
Validation loss: 2.476388940914354

Epoch: 6| Step: 12
Training loss: 0.8011313440717783
Validation loss: 2.457234718180912

Epoch: 6| Step: 13
Training loss: 0.7655139764746954
Validation loss: 2.4733956887673414

Epoch: 216| Step: 0
Training loss: 0.8610214414020223
Validation loss: 2.4552742988707035

Epoch: 6| Step: 1
Training loss: 1.0943454211653194
Validation loss: 2.435582379243859

Epoch: 6| Step: 2
Training loss: 0.9494691997150727
Validation loss: 2.439657745006916

Epoch: 6| Step: 3
Training loss: 0.4473482746904077
Validation loss: 2.4462924411570146

Epoch: 6| Step: 4
Training loss: 0.40803250484152354
Validation loss: 2.414630512311495

Epoch: 6| Step: 5
Training loss: 0.5761815733012563
Validation loss: 2.428765352390504

Epoch: 6| Step: 6
Training loss: 0.5527835729695648
Validation loss: 2.438845258765661

Epoch: 6| Step: 7
Training loss: 0.7432216065594142
Validation loss: 2.430479420428049

Epoch: 6| Step: 8
Training loss: 0.8575508177132317
Validation loss: 2.44712947492955

Epoch: 6| Step: 9
Training loss: 0.8025747544240046
Validation loss: 2.435422494753032

Epoch: 6| Step: 10
Training loss: 0.7619661760732998
Validation loss: 2.447289487095205

Epoch: 6| Step: 11
Training loss: 0.5302900729722554
Validation loss: 2.469750001537161

Epoch: 6| Step: 12
Training loss: 1.0688072813868192
Validation loss: 2.4397704722478344

Epoch: 6| Step: 13
Training loss: 0.6596381733431758
Validation loss: 2.4800535025467068

Epoch: 217| Step: 0
Training loss: 0.7678941847652428
Validation loss: 2.44985113863632

Epoch: 6| Step: 1
Training loss: 0.7755149530239498
Validation loss: 2.4358598461788397

Epoch: 6| Step: 2
Training loss: 0.5713636300744346
Validation loss: 2.4221550193753583

Epoch: 6| Step: 3
Training loss: 0.9226763200636181
Validation loss: 2.4289783099196276

Epoch: 6| Step: 4
Training loss: 0.86464979689952
Validation loss: 2.4306381365863743

Epoch: 6| Step: 5
Training loss: 0.6836962159882173
Validation loss: 2.4266807010581286

Epoch: 6| Step: 6
Training loss: 0.7970513167451114
Validation loss: 2.415858242431131

Epoch: 6| Step: 7
Training loss: 0.7112410599426597
Validation loss: 2.472708212643393

Epoch: 6| Step: 8
Training loss: 0.557551097794763
Validation loss: 2.410664319628882

Epoch: 6| Step: 9
Training loss: 0.7899755350984466
Validation loss: 2.4565162645254888

Epoch: 6| Step: 10
Training loss: 0.8669443219114271
Validation loss: 2.4428809977967236

Epoch: 6| Step: 11
Training loss: 0.8474340543155714
Validation loss: 2.4438965772479677

Epoch: 6| Step: 12
Training loss: 0.598627784297169
Validation loss: 2.4539180853337452

Epoch: 6| Step: 13
Training loss: 0.8018014875032324
Validation loss: 2.455039091762004

Epoch: 218| Step: 0
Training loss: 0.6129902191641966
Validation loss: 2.4436722247401

Epoch: 6| Step: 1
Training loss: 0.9906580994668986
Validation loss: 2.472842659969265

Epoch: 6| Step: 2
Training loss: 0.9812312106137656
Validation loss: 2.533926935454386

Epoch: 6| Step: 3
Training loss: 0.8038276226121102
Validation loss: 2.495248162992967

Epoch: 6| Step: 4
Training loss: 0.6371728179048328
Validation loss: 2.4709146277053304

Epoch: 6| Step: 5
Training loss: 0.8212243960728025
Validation loss: 2.4634034099510806

Epoch: 6| Step: 6
Training loss: 1.0626826970719279
Validation loss: 2.474983274689833

Epoch: 6| Step: 7
Training loss: 0.42841980940051866
Validation loss: 2.4494128582004775

Epoch: 6| Step: 8
Training loss: 0.6561605982964533
Validation loss: 2.482564250652955

Epoch: 6| Step: 9
Training loss: 0.8101799191702401
Validation loss: 2.4748509677579023

Epoch: 6| Step: 10
Training loss: 0.34211421948313403
Validation loss: 2.447462875485366

Epoch: 6| Step: 11
Training loss: 0.6743038543704157
Validation loss: 2.4541789060641537

Epoch: 6| Step: 12
Training loss: 0.31877693922607636
Validation loss: 2.44346893081458

Epoch: 6| Step: 13
Training loss: 0.9255929103442974
Validation loss: 2.455138786098332

Epoch: 219| Step: 0
Training loss: 0.7422257262976514
Validation loss: 2.4372355315280174

Epoch: 6| Step: 1
Training loss: 0.5570583181773163
Validation loss: 2.4391738743722864

Epoch: 6| Step: 2
Training loss: 0.8340698484266431
Validation loss: 2.4455364750741206

Epoch: 6| Step: 3
Training loss: 0.38117834574747905
Validation loss: 2.4139267249772502

Epoch: 6| Step: 4
Training loss: 0.49973029074511516
Validation loss: 2.440894844160895

Epoch: 6| Step: 5
Training loss: 0.802810219850194
Validation loss: 2.447239954577216

Epoch: 6| Step: 6
Training loss: 0.7636865482725561
Validation loss: 2.463386959700721

Epoch: 6| Step: 7
Training loss: 0.690947773967878
Validation loss: 2.459985223050126

Epoch: 6| Step: 8
Training loss: 0.712050980743875
Validation loss: 2.46575585416589

Epoch: 6| Step: 9
Training loss: 0.44846499687720587
Validation loss: 2.4538960490991024

Epoch: 6| Step: 10
Training loss: 1.0307995939682504
Validation loss: 2.4859865770810243

Epoch: 6| Step: 11
Training loss: 0.7478838710625397
Validation loss: 2.462405220865828

Epoch: 6| Step: 12
Training loss: 0.9197606554920216
Validation loss: 2.465869911561677

Epoch: 6| Step: 13
Training loss: 1.0294352660982584
Validation loss: 2.4709712324549136

Epoch: 220| Step: 0
Training loss: 0.6391020792897303
Validation loss: 2.4967223020556455

Epoch: 6| Step: 1
Training loss: 0.8910189644008005
Validation loss: 2.475865218911496

Epoch: 6| Step: 2
Training loss: 0.6731261646682171
Validation loss: 2.5106951137426323

Epoch: 6| Step: 3
Training loss: 0.7076148475062874
Validation loss: 2.4698054553757443

Epoch: 6| Step: 4
Training loss: 0.8677524753866055
Validation loss: 2.431757942931456

Epoch: 6| Step: 5
Training loss: 0.343483561515322
Validation loss: 2.4615343533255656

Epoch: 6| Step: 6
Training loss: 0.7077942414276126
Validation loss: 2.457011209535925

Epoch: 6| Step: 7
Training loss: 0.7716038092381259
Validation loss: 2.4426675505320605

Epoch: 6| Step: 8
Training loss: 0.8810129644974987
Validation loss: 2.4488179331796025

Epoch: 6| Step: 9
Training loss: 0.47845164279976626
Validation loss: 2.4832171373780243

Epoch: 6| Step: 10
Training loss: 0.8051640849192162
Validation loss: 2.461618444169115

Epoch: 6| Step: 11
Training loss: 0.5228093206807183
Validation loss: 2.4759204555401917

Epoch: 6| Step: 12
Training loss: 0.8904973992744007
Validation loss: 2.465298433134014

Epoch: 6| Step: 13
Training loss: 0.7956672941295172
Validation loss: 2.4613782804048805

Epoch: 221| Step: 0
Training loss: 0.7608592735358615
Validation loss: 2.4644006548268402

Epoch: 6| Step: 1
Training loss: 0.7757723466836707
Validation loss: 2.454655855367457

Epoch: 6| Step: 2
Training loss: 1.0238180836079982
Validation loss: 2.446456461797741

Epoch: 6| Step: 3
Training loss: 0.6513560693069342
Validation loss: 2.482945674493327

Epoch: 6| Step: 4
Training loss: 0.8751998400682794
Validation loss: 2.4445812320922697

Epoch: 6| Step: 5
Training loss: 0.6906031454089244
Validation loss: 2.4417160279989485

Epoch: 6| Step: 6
Training loss: 0.6569538202371683
Validation loss: 2.439636937635554

Epoch: 6| Step: 7
Training loss: 0.6512689931080492
Validation loss: 2.4473679708906424

Epoch: 6| Step: 8
Training loss: 0.6801033939967356
Validation loss: 2.417664708650467

Epoch: 6| Step: 9
Training loss: 0.5490354641818803
Validation loss: 2.417874290877863

Epoch: 6| Step: 10
Training loss: 0.8008192099901409
Validation loss: 2.4062029979533

Epoch: 6| Step: 11
Training loss: 0.5370765814740281
Validation loss: 2.4530462677324056

Epoch: 6| Step: 12
Training loss: 0.7934532752314946
Validation loss: 2.4318882110732156

Epoch: 6| Step: 13
Training loss: 0.43656516675742163
Validation loss: 2.4595987199767184

Epoch: 222| Step: 0
Training loss: 0.6268237209169633
Validation loss: 2.4668798854481278

Epoch: 6| Step: 1
Training loss: 0.6515049824381419
Validation loss: 2.4923760790923315

Epoch: 6| Step: 2
Training loss: 0.5553233303716272
Validation loss: 2.468393248366885

Epoch: 6| Step: 3
Training loss: 1.0466778697691927
Validation loss: 2.481222517578861

Epoch: 6| Step: 4
Training loss: 0.6487915497265411
Validation loss: 2.429952922908391

Epoch: 6| Step: 5
Training loss: 0.5851189045008949
Validation loss: 2.393790251266734

Epoch: 6| Step: 6
Training loss: 0.7936228417496228
Validation loss: 2.415233969909751

Epoch: 6| Step: 7
Training loss: 0.9165718976074567
Validation loss: 2.44115836327654

Epoch: 6| Step: 8
Training loss: 0.8328878801595975
Validation loss: 2.412507260261861

Epoch: 6| Step: 9
Training loss: 0.5841656151660956
Validation loss: 2.4265761863331456

Epoch: 6| Step: 10
Training loss: 0.6253730137648789
Validation loss: 2.420651555340198

Epoch: 6| Step: 11
Training loss: 0.6992409345634508
Validation loss: 2.3726494895992745

Epoch: 6| Step: 12
Training loss: 0.7569505961534675
Validation loss: 2.4184021755877807

Epoch: 6| Step: 13
Training loss: 0.6109575604903891
Validation loss: 2.4344491042225984

Epoch: 223| Step: 0
Training loss: 0.6092590808653428
Validation loss: 2.4195605791452306

Epoch: 6| Step: 1
Training loss: 0.9964372229701044
Validation loss: 2.394202240956516

Epoch: 6| Step: 2
Training loss: 0.25763774497699904
Validation loss: 2.4223573784512014

Epoch: 6| Step: 3
Training loss: 0.7963913590549208
Validation loss: 2.392205863288395

Epoch: 6| Step: 4
Training loss: 0.7864264845978166
Validation loss: 2.3468975838079977

Epoch: 6| Step: 5
Training loss: 0.7986279075809654
Validation loss: 2.356906671348043

Epoch: 6| Step: 6
Training loss: 0.8894595166472181
Validation loss: 2.3430220372409325

Epoch: 6| Step: 7
Training loss: 0.46851107548229726
Validation loss: 2.366320935225142

Epoch: 6| Step: 8
Training loss: 0.6714023657622714
Validation loss: 2.3599982418789303

Epoch: 6| Step: 9
Training loss: 0.5292943693995555
Validation loss: 2.3668556973128867

Epoch: 6| Step: 10
Training loss: 0.8567518601254033
Validation loss: 2.3714112410848336

Epoch: 6| Step: 11
Training loss: 0.8297520614189248
Validation loss: 2.3910574476650104

Epoch: 6| Step: 12
Training loss: 0.7636276193268813
Validation loss: 2.375489346965449

Epoch: 6| Step: 13
Training loss: 0.334149871780283
Validation loss: 2.408355403350092

Epoch: 224| Step: 0
Training loss: 1.093487081262146
Validation loss: 2.392218409224629

Epoch: 6| Step: 1
Training loss: 0.7329926974829241
Validation loss: 2.407178038469323

Epoch: 6| Step: 2
Training loss: 0.3683917811066119
Validation loss: 2.382236821489

Epoch: 6| Step: 3
Training loss: 0.6994191740265212
Validation loss: 2.4440971928729134

Epoch: 6| Step: 4
Training loss: 0.63471616112115
Validation loss: 2.4024964722981395

Epoch: 6| Step: 5
Training loss: 0.8858248872853726
Validation loss: 2.4249399533590332

Epoch: 6| Step: 6
Training loss: 0.4677816083668306
Validation loss: 2.4230068699109157

Epoch: 6| Step: 7
Training loss: 0.6778870556262475
Validation loss: 2.4277588366695904

Epoch: 6| Step: 8
Training loss: 0.5404973766976073
Validation loss: 2.415358117698615

Epoch: 6| Step: 9
Training loss: 0.3101354068315391
Validation loss: 2.424028410063567

Epoch: 6| Step: 10
Training loss: 0.8594902654854407
Validation loss: 2.438236269989225

Epoch: 6| Step: 11
Training loss: 0.9101719343282949
Validation loss: 2.457760658810296

Epoch: 6| Step: 12
Training loss: 0.4492864806489042
Validation loss: 2.4509951937793746

Epoch: 6| Step: 13
Training loss: 0.8222197748661849
Validation loss: 2.4466855051520744

Epoch: 225| Step: 0
Training loss: 0.6862994462145662
Validation loss: 2.410667127156783

Epoch: 6| Step: 1
Training loss: 0.6159377180047813
Validation loss: 2.456481764681758

Epoch: 6| Step: 2
Training loss: 0.40388585819440664
Validation loss: 2.4402505665220025

Epoch: 6| Step: 3
Training loss: 0.6850085196000054
Validation loss: 2.4710100627832103

Epoch: 6| Step: 4
Training loss: 0.43408254616946046
Validation loss: 2.447668191678324

Epoch: 6| Step: 5
Training loss: 0.8286801043188404
Validation loss: 2.417282527432284

Epoch: 6| Step: 6
Training loss: 0.8340970751619755
Validation loss: 2.4646988362578863

Epoch: 6| Step: 7
Training loss: 0.8896964067576703
Validation loss: 2.4698294847955014

Epoch: 6| Step: 8
Training loss: 0.8442478477240485
Validation loss: 2.4691837844032953

Epoch: 6| Step: 9
Training loss: 0.5732855187436758
Validation loss: 2.446480760371933

Epoch: 6| Step: 10
Training loss: 0.6553608001823727
Validation loss: 2.439785489824125

Epoch: 6| Step: 11
Training loss: 0.4169441213309329
Validation loss: 2.4394928689632716

Epoch: 6| Step: 12
Training loss: 0.7377045008435833
Validation loss: 2.4457521824033237

Epoch: 6| Step: 13
Training loss: 0.9239816679188751
Validation loss: 2.4219880796477713

Epoch: 226| Step: 0
Training loss: 0.7228736344281194
Validation loss: 2.4079950198129962

Epoch: 6| Step: 1
Training loss: 0.7190464072020276
Validation loss: 2.446466255447371

Epoch: 6| Step: 2
Training loss: 0.7093469622612496
Validation loss: 2.4144950840450496

Epoch: 6| Step: 3
Training loss: 0.731855493899657
Validation loss: 2.4175953238825025

Epoch: 6| Step: 4
Training loss: 0.657339803340626
Validation loss: 2.4298605945429146

Epoch: 6| Step: 5
Training loss: 0.9239030610030626
Validation loss: 2.419347902616177

Epoch: 6| Step: 6
Training loss: 0.7586059349330758
Validation loss: 2.402548828762456

Epoch: 6| Step: 7
Training loss: 0.8041025646797404
Validation loss: 2.431256683371635

Epoch: 6| Step: 8
Training loss: 0.5384807488268705
Validation loss: 2.464346135784117

Epoch: 6| Step: 9
Training loss: 0.7968657249958087
Validation loss: 2.476537820606313

Epoch: 6| Step: 10
Training loss: 0.5551474907074256
Validation loss: 2.476590925354842

Epoch: 6| Step: 11
Training loss: 0.39247475397107257
Validation loss: 2.4623925718381066

Epoch: 6| Step: 12
Training loss: 0.6250907355248577
Validation loss: 2.4256953894227

Epoch: 6| Step: 13
Training loss: 0.5786445448271937
Validation loss: 2.407239773501953

Epoch: 227| Step: 0
Training loss: 0.7921880627993177
Validation loss: 2.420942316272052

Epoch: 6| Step: 1
Training loss: 0.4853226712567883
Validation loss: 2.436352194771742

Epoch: 6| Step: 2
Training loss: 0.942073348232996
Validation loss: 2.411606742717972

Epoch: 6| Step: 3
Training loss: 0.7868664084913091
Validation loss: 2.401203880269654

Epoch: 6| Step: 4
Training loss: 0.774910920161168
Validation loss: 2.4286038035822335

Epoch: 6| Step: 5
Training loss: 0.7643734570266983
Validation loss: 2.416125014781357

Epoch: 6| Step: 6
Training loss: 0.6995482281193812
Validation loss: 2.409217322772396

Epoch: 6| Step: 7
Training loss: 0.629950231448259
Validation loss: 2.443475381169493

Epoch: 6| Step: 8
Training loss: 0.6042855545887258
Validation loss: 2.4537427532099962

Epoch: 6| Step: 9
Training loss: 0.23074599739986218
Validation loss: 2.464891212663874

Epoch: 6| Step: 10
Training loss: 0.8231297028102363
Validation loss: 2.476179732104209

Epoch: 6| Step: 11
Training loss: 0.563303029860155
Validation loss: 2.45662947149611

Epoch: 6| Step: 12
Training loss: 0.5855249605665084
Validation loss: 2.4648655999544893

Epoch: 6| Step: 13
Training loss: 0.49820681229175445
Validation loss: 2.430858039804507

Epoch: 228| Step: 0
Training loss: 0.7097873396798035
Validation loss: 2.4125593537830192

Epoch: 6| Step: 1
Training loss: 0.8027893938575658
Validation loss: 2.4550121670287735

Epoch: 6| Step: 2
Training loss: 0.4735902432847087
Validation loss: 2.395286123766023

Epoch: 6| Step: 3
Training loss: 0.9200305591048251
Validation loss: 2.4385937376386497

Epoch: 6| Step: 4
Training loss: 0.6016860191063088
Validation loss: 2.41380087221974

Epoch: 6| Step: 5
Training loss: 0.6973571717246116
Validation loss: 2.4248046177210667

Epoch: 6| Step: 6
Training loss: 0.39670100190050805
Validation loss: 2.4319638766132927

Epoch: 6| Step: 7
Training loss: 0.7536452637208703
Validation loss: 2.4517461160551637

Epoch: 6| Step: 8
Training loss: 0.6667746416708336
Validation loss: 2.441628089719593

Epoch: 6| Step: 9
Training loss: 0.6432956295708793
Validation loss: 2.4533786103079684

Epoch: 6| Step: 10
Training loss: 0.7513370120139835
Validation loss: 2.4585101809816323

Epoch: 6| Step: 11
Training loss: 0.6923033072768828
Validation loss: 2.4699150432015062

Epoch: 6| Step: 12
Training loss: 0.6752835684761265
Validation loss: 2.5060291130649923

Epoch: 6| Step: 13
Training loss: 0.26905603948229256
Validation loss: 2.4779431646914634

Epoch: 229| Step: 0
Training loss: 0.3487616228915063
Validation loss: 2.4915266538911585

Epoch: 6| Step: 1
Training loss: 0.7158261828422533
Validation loss: 2.492948001707836

Epoch: 6| Step: 2
Training loss: 0.4025462113383734
Validation loss: 2.4747786873646422

Epoch: 6| Step: 3
Training loss: 0.5357007229314287
Validation loss: 2.4698589716361457

Epoch: 6| Step: 4
Training loss: 0.8543585623755406
Validation loss: 2.4631847417962875

Epoch: 6| Step: 5
Training loss: 0.7013256786261699
Validation loss: 2.4254859999729583

Epoch: 6| Step: 6
Training loss: 0.749635647645804
Validation loss: 2.4403332109312412

Epoch: 6| Step: 7
Training loss: 0.4758886670153335
Validation loss: 2.468602935327641

Epoch: 6| Step: 8
Training loss: 0.8622888583051306
Validation loss: 2.42072375321715

Epoch: 6| Step: 9
Training loss: 0.8481011695296908
Validation loss: 2.447127326801515

Epoch: 6| Step: 10
Training loss: 0.47203603358845436
Validation loss: 2.4340664850449185

Epoch: 6| Step: 11
Training loss: 0.8526685338938145
Validation loss: 2.475214067724603

Epoch: 6| Step: 12
Training loss: 0.653111628345335
Validation loss: 2.4903509328203097

Epoch: 6| Step: 13
Training loss: 0.6502494315086617
Validation loss: 2.464205385400038

Epoch: 230| Step: 0
Training loss: 0.7749245729965745
Validation loss: 2.474549181879698

Epoch: 6| Step: 1
Training loss: 0.8530477467866201
Validation loss: 2.450537831132635

Epoch: 6| Step: 2
Training loss: 0.5613496461696772
Validation loss: 2.4574150152106746

Epoch: 6| Step: 3
Training loss: 0.6483568118346154
Validation loss: 2.422613091654541

Epoch: 6| Step: 4
Training loss: 0.2343955348873592
Validation loss: 2.4100493007500803

Epoch: 6| Step: 5
Training loss: 0.6949640322372919
Validation loss: 2.398080803356729

Epoch: 6| Step: 6
Training loss: 0.790870408280128
Validation loss: 2.406012960370736

Epoch: 6| Step: 7
Training loss: 0.5349120536605687
Validation loss: 2.4343659114761453

Epoch: 6| Step: 8
Training loss: 0.7090110668696032
Validation loss: 2.4388224041234228

Epoch: 6| Step: 9
Training loss: 0.5936488768144853
Validation loss: 2.4827563682675864

Epoch: 6| Step: 10
Training loss: 0.6001878861459136
Validation loss: 2.443186117211515

Epoch: 6| Step: 11
Training loss: 0.5593449802974437
Validation loss: 2.4351962466791286

Epoch: 6| Step: 12
Training loss: 0.7503866550036713
Validation loss: 2.4842557503773928

Epoch: 6| Step: 13
Training loss: 0.8199727035840616
Validation loss: 2.473851926077183

Epoch: 231| Step: 0
Training loss: 0.919859088285777
Validation loss: 2.4329716357636646

Epoch: 6| Step: 1
Training loss: 0.5716846368104295
Validation loss: 2.469597425043699

Epoch: 6| Step: 2
Training loss: 0.5648408501894898
Validation loss: 2.4628446227166667

Epoch: 6| Step: 3
Training loss: 0.6270651316192591
Validation loss: 2.415324216615401

Epoch: 6| Step: 4
Training loss: 0.38740211373339883
Validation loss: 2.464474592426998

Epoch: 6| Step: 5
Training loss: 0.342956168219855
Validation loss: 2.4585108462636054

Epoch: 6| Step: 6
Training loss: 0.5903353631846107
Validation loss: 2.455045256924652

Epoch: 6| Step: 7
Training loss: 0.6953723110234071
Validation loss: 2.4298462177706237

Epoch: 6| Step: 8
Training loss: 0.8109510769745706
Validation loss: 2.4652172620980357

Epoch: 6| Step: 9
Training loss: 0.3981624850916747
Validation loss: 2.4083577728763

Epoch: 6| Step: 10
Training loss: 0.6627667519816822
Validation loss: 2.4504582787008373

Epoch: 6| Step: 11
Training loss: 0.8264024922153306
Validation loss: 2.4758991732344646

Epoch: 6| Step: 12
Training loss: 0.883072705026502
Validation loss: 2.467032536486617

Epoch: 6| Step: 13
Training loss: 0.6935132138080458
Validation loss: 2.5384005119179593

Epoch: 232| Step: 0
Training loss: 0.857753819749822
Validation loss: 2.508752924027689

Epoch: 6| Step: 1
Training loss: 0.8568482446145357
Validation loss: 2.504875216388297

Epoch: 6| Step: 2
Training loss: 0.6355957706448743
Validation loss: 2.506446941175552

Epoch: 6| Step: 3
Training loss: 0.7340822650949141
Validation loss: 2.500044279834372

Epoch: 6| Step: 4
Training loss: 0.5532500756009856
Validation loss: 2.4740264195829536

Epoch: 6| Step: 5
Training loss: 0.5907382876623055
Validation loss: 2.471954825266334

Epoch: 6| Step: 6
Training loss: 0.34712554844162846
Validation loss: 2.462276724460535

Epoch: 6| Step: 7
Training loss: 0.7340198632107037
Validation loss: 2.4386766852382387

Epoch: 6| Step: 8
Training loss: 0.34127466909090587
Validation loss: 2.4550502400021172

Epoch: 6| Step: 9
Training loss: 0.6348956165725383
Validation loss: 2.453219577378794

Epoch: 6| Step: 10
Training loss: 0.6237271221758556
Validation loss: 2.4578788765519577

Epoch: 6| Step: 11
Training loss: 0.5754352580756347
Validation loss: 2.4009883583654714

Epoch: 6| Step: 12
Training loss: 0.7195992221267211
Validation loss: 2.4471246590553926

Epoch: 6| Step: 13
Training loss: 0.6773629833689464
Validation loss: 2.4149866132391296

Epoch: 233| Step: 0
Training loss: 0.5927163965473443
Validation loss: 2.41774816645178

Epoch: 6| Step: 1
Training loss: 0.5817605483586887
Validation loss: 2.4103066010636165

Epoch: 6| Step: 2
Training loss: 0.4768462977639733
Validation loss: 2.3928812537703803

Epoch: 6| Step: 3
Training loss: 0.5615276037973834
Validation loss: 2.388452684879391

Epoch: 6| Step: 4
Training loss: 0.6131502485374775
Validation loss: 2.3999301815858445

Epoch: 6| Step: 5
Training loss: 0.6873005664438472
Validation loss: 2.417256783058059

Epoch: 6| Step: 6
Training loss: 0.7445091876736969
Validation loss: 2.4118472265693387

Epoch: 6| Step: 7
Training loss: 0.6818809632093902
Validation loss: 2.4300124826122906

Epoch: 6| Step: 8
Training loss: 0.5325213814414178
Validation loss: 2.444030472826018

Epoch: 6| Step: 9
Training loss: 0.5326036709622064
Validation loss: 2.4279459040616973

Epoch: 6| Step: 10
Training loss: 0.8081751675238993
Validation loss: 2.4879879098500597

Epoch: 6| Step: 11
Training loss: 0.7041661501399146
Validation loss: 2.451694209477529

Epoch: 6| Step: 12
Training loss: 0.7552519336260249
Validation loss: 2.4589705300146814

Epoch: 6| Step: 13
Training loss: 0.791306618748403
Validation loss: 2.4708385322285213

Epoch: 234| Step: 0
Training loss: 0.5772946038705459
Validation loss: 2.4644947360374685

Epoch: 6| Step: 1
Training loss: 0.645445712474188
Validation loss: 2.4798446152979663

Epoch: 6| Step: 2
Training loss: 0.6361802989650734
Validation loss: 2.4951752939669207

Epoch: 6| Step: 3
Training loss: 0.4888750052046087
Validation loss: 2.492388627895571

Epoch: 6| Step: 4
Training loss: 0.5303161491488787
Validation loss: 2.5029300644261627

Epoch: 6| Step: 5
Training loss: 0.5582474388648057
Validation loss: 2.516095200486827

Epoch: 6| Step: 6
Training loss: 0.7045437803696013
Validation loss: 2.492623486634745

Epoch: 6| Step: 7
Training loss: 0.704998106920122
Validation loss: 2.5087306510653744

Epoch: 6| Step: 8
Training loss: 0.27661737501061723
Validation loss: 2.460451727219444

Epoch: 6| Step: 9
Training loss: 0.9328514563830103
Validation loss: 2.4473592765482617

Epoch: 6| Step: 10
Training loss: 0.5780927288224361
Validation loss: 2.4105544321198416

Epoch: 6| Step: 11
Training loss: 0.41403867545053
Validation loss: 2.429523045806826

Epoch: 6| Step: 12
Training loss: 0.8585938110906911
Validation loss: 2.3954526854778377

Epoch: 6| Step: 13
Training loss: 0.8968040544581577
Validation loss: 2.406750411104084

Epoch: 235| Step: 0
Training loss: 0.7336605736275681
Validation loss: 2.40261360958459

Epoch: 6| Step: 1
Training loss: 0.4780460155296673
Validation loss: 2.3635905635016905

Epoch: 6| Step: 2
Training loss: 0.620230764966425
Validation loss: 2.385643495045057

Epoch: 6| Step: 3
Training loss: 0.7051654032530076
Validation loss: 2.3376299243726955

Epoch: 6| Step: 4
Training loss: 0.25710349415556516
Validation loss: 2.3860447933358735

Epoch: 6| Step: 5
Training loss: 0.6066995232281714
Validation loss: 2.3705198856465692

Epoch: 6| Step: 6
Training loss: 0.6118149205560448
Validation loss: 2.4071119789103332

Epoch: 6| Step: 7
Training loss: 0.7162191365035113
Validation loss: 2.4100899348759794

Epoch: 6| Step: 8
Training loss: 0.7680809955702755
Validation loss: 2.4112244492176718

Epoch: 6| Step: 9
Training loss: 0.7014576109234865
Validation loss: 2.443995499876649

Epoch: 6| Step: 10
Training loss: 0.7685829942621087
Validation loss: 2.4202211489540604

Epoch: 6| Step: 11
Training loss: 0.6661505688301881
Validation loss: 2.4410802117645156

Epoch: 6| Step: 12
Training loss: 0.5786949132322321
Validation loss: 2.48275323129238

Epoch: 6| Step: 13
Training loss: 0.5365850212600652
Validation loss: 2.4492345689936297

Epoch: 236| Step: 0
Training loss: 0.47362823484115973
Validation loss: 2.4658284063215534

Epoch: 6| Step: 1
Training loss: 0.9930557296918763
Validation loss: 2.4865539121919293

Epoch: 6| Step: 2
Training loss: 0.7759703191606375
Validation loss: 2.437996309214022

Epoch: 6| Step: 3
Training loss: 0.39634717249202817
Validation loss: 2.4866041008349646

Epoch: 6| Step: 4
Training loss: 0.1967284092035335
Validation loss: 2.4640421591920747

Epoch: 6| Step: 5
Training loss: 0.692582482304343
Validation loss: 2.430443382272535

Epoch: 6| Step: 6
Training loss: 0.636907397448524
Validation loss: 2.454457147763988

Epoch: 6| Step: 7
Training loss: 0.822431787659582
Validation loss: 2.4480142008861283

Epoch: 6| Step: 8
Training loss: 0.7379385743280763
Validation loss: 2.430074217247968

Epoch: 6| Step: 9
Training loss: 0.6439216736702975
Validation loss: 2.4369706109337064

Epoch: 6| Step: 10
Training loss: 0.5367412068251286
Validation loss: 2.4743227095255564

Epoch: 6| Step: 11
Training loss: 0.694956870696188
Validation loss: 2.4738887619486545

Epoch: 6| Step: 12
Training loss: 0.3020729345417262
Validation loss: 2.4774803783833077

Epoch: 6| Step: 13
Training loss: 0.5052371524836494
Validation loss: 2.4945774952808275

Epoch: 237| Step: 0
Training loss: 0.4904640389295485
Validation loss: 2.4572792746447254

Epoch: 6| Step: 1
Training loss: 0.505573235963578
Validation loss: 2.4350937734845117

Epoch: 6| Step: 2
Training loss: 0.5523134118021136
Validation loss: 2.4229530287798515

Epoch: 6| Step: 3
Training loss: 0.8840483058681278
Validation loss: 2.4510029934836943

Epoch: 6| Step: 4
Training loss: 0.7191486082612968
Validation loss: 2.408472380754494

Epoch: 6| Step: 5
Training loss: 0.7276682489383473
Validation loss: 2.3973240142365646

Epoch: 6| Step: 6
Training loss: 0.49126996696215347
Validation loss: 2.4199574961913304

Epoch: 6| Step: 7
Training loss: 0.6592342551922203
Validation loss: 2.4326285965735606

Epoch: 6| Step: 8
Training loss: 0.2572425698272193
Validation loss: 2.4354903963921495

Epoch: 6| Step: 9
Training loss: 0.676177421383999
Validation loss: 2.406371867994909

Epoch: 6| Step: 10
Training loss: 0.7859245450903088
Validation loss: 2.412880011852057

Epoch: 6| Step: 11
Training loss: 0.6841414301241208
Validation loss: 2.413457845533985

Epoch: 6| Step: 12
Training loss: 0.5978482505210604
Validation loss: 2.4302417239217045

Epoch: 6| Step: 13
Training loss: 0.4160827797429468
Validation loss: 2.4192479032722196

Epoch: 238| Step: 0
Training loss: 0.7958008501570332
Validation loss: 2.415452769678816

Epoch: 6| Step: 1
Training loss: 0.7898327306927729
Validation loss: 2.4209822846978826

Epoch: 6| Step: 2
Training loss: 0.5897388491285858
Validation loss: 2.4165598690492804

Epoch: 6| Step: 3
Training loss: 0.684136268050358
Validation loss: 2.4031870444603913

Epoch: 6| Step: 4
Training loss: 0.7335649039840212
Validation loss: 2.3892917935592908

Epoch: 6| Step: 5
Training loss: 0.44099037023765225
Validation loss: 2.3962811907916612

Epoch: 6| Step: 6
Training loss: 0.345001780843976
Validation loss: 2.414422146714481

Epoch: 6| Step: 7
Training loss: 0.6448926663730477
Validation loss: 2.424445692723719

Epoch: 6| Step: 8
Training loss: 0.28566552761541475
Validation loss: 2.418638468445997

Epoch: 6| Step: 9
Training loss: 0.7012905349847726
Validation loss: 2.40944643960258

Epoch: 6| Step: 10
Training loss: 0.571876315339457
Validation loss: 2.4475829216139875

Epoch: 6| Step: 11
Training loss: 0.4625954310448414
Validation loss: 2.4159005870594656

Epoch: 6| Step: 12
Training loss: 0.6112959490708767
Validation loss: 2.4621990043013064

Epoch: 6| Step: 13
Training loss: 0.8737667452690633
Validation loss: 2.4669099674203148

Epoch: 239| Step: 0
Training loss: 0.609470115476623
Validation loss: 2.4856538066888145

Epoch: 6| Step: 1
Training loss: 0.2274629441018341
Validation loss: 2.4715522002037096

Epoch: 6| Step: 2
Training loss: 0.5281096653715294
Validation loss: 2.487042863972131

Epoch: 6| Step: 3
Training loss: 0.8606817540644626
Validation loss: 2.514815749438393

Epoch: 6| Step: 4
Training loss: 0.5961706859290326
Validation loss: 2.4810675105952655

Epoch: 6| Step: 5
Training loss: 0.7775088187695786
Validation loss: 2.486109886215726

Epoch: 6| Step: 6
Training loss: 0.6357928137244416
Validation loss: 2.504716300695137

Epoch: 6| Step: 7
Training loss: 0.7778230655821564
Validation loss: 2.499784018303228

Epoch: 6| Step: 8
Training loss: 0.5519343811005782
Validation loss: 2.4787066094751578

Epoch: 6| Step: 9
Training loss: 0.49514284387209484
Validation loss: 2.461183980515482

Epoch: 6| Step: 10
Training loss: 0.5616957955584561
Validation loss: 2.500848593304882

Epoch: 6| Step: 11
Training loss: 0.5035636683613013
Validation loss: 2.489144891668456

Epoch: 6| Step: 12
Training loss: 0.5012211788006146
Validation loss: 2.474206682486854

Epoch: 6| Step: 13
Training loss: 0.7461277020303707
Validation loss: 2.4160157374768807

Epoch: 240| Step: 0
Training loss: 0.3228443151861747
Validation loss: 2.428655961405191

Epoch: 6| Step: 1
Training loss: 0.4058354904005205
Validation loss: 2.45792081850388

Epoch: 6| Step: 2
Training loss: 0.9791102629845139
Validation loss: 2.431553324472245

Epoch: 6| Step: 3
Training loss: 0.6139268574856775
Validation loss: 2.445484394237087

Epoch: 6| Step: 4
Training loss: 0.39699283187289924
Validation loss: 2.471080467718018

Epoch: 6| Step: 5
Training loss: 0.5932200978439686
Validation loss: 2.4354776486304606

Epoch: 6| Step: 6
Training loss: 0.6244126898279456
Validation loss: 2.4451326211493285

Epoch: 6| Step: 7
Training loss: 0.5569553221842373
Validation loss: 2.4520258288430723

Epoch: 6| Step: 8
Training loss: 0.5396474622178489
Validation loss: 2.475974267252648

Epoch: 6| Step: 9
Training loss: 0.5999998132387506
Validation loss: 2.4275860342196527

Epoch: 6| Step: 10
Training loss: 0.7138007220469014
Validation loss: 2.4338308610685084

Epoch: 6| Step: 11
Training loss: 0.8009641484989409
Validation loss: 2.4328038528632976

Epoch: 6| Step: 12
Training loss: 0.4249365064932252
Validation loss: 2.4096480306893557

Epoch: 6| Step: 13
Training loss: 0.604217195590249
Validation loss: 2.4082344586141726

Epoch: 241| Step: 0
Training loss: 0.8694794755106935
Validation loss: 2.415731996829538

Epoch: 6| Step: 1
Training loss: 0.6223192660002322
Validation loss: 2.4181466924169186

Epoch: 6| Step: 2
Training loss: 0.5163004814478928
Validation loss: 2.399880449802334

Epoch: 6| Step: 3
Training loss: 0.46359002114735504
Validation loss: 2.4269143783854923

Epoch: 6| Step: 4
Training loss: 0.4853518081142487
Validation loss: 2.413902517416957

Epoch: 6| Step: 5
Training loss: 0.5731997628572856
Validation loss: 2.422318642399298

Epoch: 6| Step: 6
Training loss: 0.5440289691581641
Validation loss: 2.429318147294587

Epoch: 6| Step: 7
Training loss: 0.5190615717944459
Validation loss: 2.4483790170248545

Epoch: 6| Step: 8
Training loss: 0.6175770556291639
Validation loss: 2.4436912998081284

Epoch: 6| Step: 9
Training loss: 0.8811917914787895
Validation loss: 2.411401535411033

Epoch: 6| Step: 10
Training loss: 0.43829375876461596
Validation loss: 2.4278838001178595

Epoch: 6| Step: 11
Training loss: 0.4875260578429444
Validation loss: 2.412631276336848

Epoch: 6| Step: 12
Training loss: 0.665721526333137
Validation loss: 2.4451284681683845

Epoch: 6| Step: 13
Training loss: 0.598103150473893
Validation loss: 2.4045907415076098

Epoch: 242| Step: 0
Training loss: 0.709310241297649
Validation loss: 2.405459110609301

Epoch: 6| Step: 1
Training loss: 0.3978106298350255
Validation loss: 2.4259631491457267

Epoch: 6| Step: 2
Training loss: 0.6524770452035206
Validation loss: 2.3711816958221923

Epoch: 6| Step: 3
Training loss: 0.7358672624832127
Validation loss: 2.4167606387115677

Epoch: 6| Step: 4
Training loss: 0.7999705607242761
Validation loss: 2.3916616586903796

Epoch: 6| Step: 5
Training loss: 0.4346481939242947
Validation loss: 2.4062414490114077

Epoch: 6| Step: 6
Training loss: 0.38776283733089717
Validation loss: 2.3979611701570698

Epoch: 6| Step: 7
Training loss: 0.7224439566896547
Validation loss: 2.398266047740522

Epoch: 6| Step: 8
Training loss: 0.6323068270261485
Validation loss: 2.4254716020269846

Epoch: 6| Step: 9
Training loss: 0.3124801867879753
Validation loss: 2.3914597584899453

Epoch: 6| Step: 10
Training loss: 0.7844384551502547
Validation loss: 2.389828938608579

Epoch: 6| Step: 11
Training loss: 0.6030840271784174
Validation loss: 2.4150482893163208

Epoch: 6| Step: 12
Training loss: 0.3283241666605046
Validation loss: 2.434844004314296

Epoch: 6| Step: 13
Training loss: 0.6697420818747902
Validation loss: 2.4021442332147256

Epoch: 243| Step: 0
Training loss: 0.6675301165698144
Validation loss: 2.4260364210872476

Epoch: 6| Step: 1
Training loss: 0.9680182246510294
Validation loss: 2.430351102075099

Epoch: 6| Step: 2
Training loss: 0.43305182743010656
Validation loss: 2.435160700485288

Epoch: 6| Step: 3
Training loss: 0.5324569343560258
Validation loss: 2.4629154609210637

Epoch: 6| Step: 4
Training loss: 0.5361350915856897
Validation loss: 2.423091384752837

Epoch: 6| Step: 5
Training loss: 0.6676934773721138
Validation loss: 2.4080625136600853

Epoch: 6| Step: 6
Training loss: 0.5703905914352609
Validation loss: 2.4395200711202096

Epoch: 6| Step: 7
Training loss: 0.45665706086091656
Validation loss: 2.413188411429388

Epoch: 6| Step: 8
Training loss: 0.532898281273385
Validation loss: 2.455501304978803

Epoch: 6| Step: 9
Training loss: 0.6604593698391855
Validation loss: 2.427077180940098

Epoch: 6| Step: 10
Training loss: 0.4631842635534126
Validation loss: 2.438862100551048

Epoch: 6| Step: 11
Training loss: 0.5418028079631473
Validation loss: 2.46361989425198

Epoch: 6| Step: 12
Training loss: 0.6585430546590757
Validation loss: 2.471268945784496

Epoch: 6| Step: 13
Training loss: 0.5065743243410022
Validation loss: 2.503517711370761

Epoch: 244| Step: 0
Training loss: 0.5833471642852703
Validation loss: 2.4625644705173073

Epoch: 6| Step: 1
Training loss: 0.4928682251981488
Validation loss: 2.412507268763027

Epoch: 6| Step: 2
Training loss: 0.7334672715232022
Validation loss: 2.3938598687279

Epoch: 6| Step: 3
Training loss: 0.46285653290569645
Validation loss: 2.3845581954557042

Epoch: 6| Step: 4
Training loss: 0.5942379051088195
Validation loss: 2.389185443678786

Epoch: 6| Step: 5
Training loss: 0.6370491621518087
Validation loss: 2.38108701291598

Epoch: 6| Step: 6
Training loss: 0.7821601906191389
Validation loss: 2.3857181084735397

Epoch: 6| Step: 7
Training loss: 0.538402429679501
Validation loss: 2.3754958416139194

Epoch: 6| Step: 8
Training loss: 0.4785320201322768
Validation loss: 2.3885053126930345

Epoch: 6| Step: 9
Training loss: 0.7369129883581159
Validation loss: 2.423955788148693

Epoch: 6| Step: 10
Training loss: 0.5862057135555042
Validation loss: 2.467558720165491

Epoch: 6| Step: 11
Training loss: 0.5628252148926174
Validation loss: 2.4867216040747553

Epoch: 6| Step: 12
Training loss: 0.38401413159022413
Validation loss: 2.482844551995884

Epoch: 6| Step: 13
Training loss: 0.8292189156701221
Validation loss: 2.467342693671799

Epoch: 245| Step: 0
Training loss: 0.8782418007059344
Validation loss: 2.518431012482899

Epoch: 6| Step: 1
Training loss: 0.44068632240230043
Validation loss: 2.5160692908339004

Epoch: 6| Step: 2
Training loss: 0.5023958799090738
Validation loss: 2.5039242431891022

Epoch: 6| Step: 3
Training loss: 0.335545599583077
Validation loss: 2.498233983564559

Epoch: 6| Step: 4
Training loss: 0.47916225417496583
Validation loss: 2.4576105299998154

Epoch: 6| Step: 5
Training loss: 0.5148319735070166
Validation loss: 2.508514542173762

Epoch: 6| Step: 6
Training loss: 0.8340065303244941
Validation loss: 2.543761071436553

Epoch: 6| Step: 7
Training loss: 0.67861063922802
Validation loss: 2.454406036985661

Epoch: 6| Step: 8
Training loss: 0.6553507956765059
Validation loss: 2.4939192011622757

Epoch: 6| Step: 9
Training loss: 0.5626767198800486
Validation loss: 2.463585340916676

Epoch: 6| Step: 10
Training loss: 0.39967568929608865
Validation loss: 2.488920122338594

Epoch: 6| Step: 11
Training loss: 0.36347181182823257
Validation loss: 2.498405797324313

Epoch: 6| Step: 12
Training loss: 0.6310008926627106
Validation loss: 2.4759263988973594

Epoch: 6| Step: 13
Training loss: 0.5402840856931901
Validation loss: 2.479460751456609

Epoch: 246| Step: 0
Training loss: 0.6452560741887999
Validation loss: 2.424235277419402

Epoch: 6| Step: 1
Training loss: 0.5784742486080455
Validation loss: 2.4563427673980778

Epoch: 6| Step: 2
Training loss: 0.4203437992056498
Validation loss: 2.4914527170161316

Epoch: 6| Step: 3
Training loss: 0.6083455315329307
Validation loss: 2.463333126953246

Epoch: 6| Step: 4
Training loss: 0.6132468438671833
Validation loss: 2.480167120526835

Epoch: 6| Step: 5
Training loss: 0.5824113922915545
Validation loss: 2.4943406724591024

Epoch: 6| Step: 6
Training loss: 0.4242405269365439
Validation loss: 2.4559912338121768

Epoch: 6| Step: 7
Training loss: 0.4083795485650423
Validation loss: 2.454931171758054

Epoch: 6| Step: 8
Training loss: 0.5060212454425539
Validation loss: 2.4826744958402904

Epoch: 6| Step: 9
Training loss: 0.8639925274790707
Validation loss: 2.494297330478572

Epoch: 6| Step: 10
Training loss: 0.27319870467151175
Validation loss: 2.492521378021286

Epoch: 6| Step: 11
Training loss: 0.4638315287486501
Validation loss: 2.497675849015262

Epoch: 6| Step: 12
Training loss: 0.7402527336320064
Validation loss: 2.469266758214834

Epoch: 6| Step: 13
Training loss: 0.7090663809941192
Validation loss: 2.4746314205116158

Epoch: 247| Step: 0
Training loss: 0.3817024485432835
Validation loss: 2.4768665877911555

Epoch: 6| Step: 1
Training loss: 0.776323310044006
Validation loss: 2.475309973984565

Epoch: 6| Step: 2
Training loss: 0.4198377303162907
Validation loss: 2.503657190667999

Epoch: 6| Step: 3
Training loss: 0.47881869625020496
Validation loss: 2.511073363634458

Epoch: 6| Step: 4
Training loss: 0.7293820789585288
Validation loss: 2.4937714727456304

Epoch: 6| Step: 5
Training loss: 0.415268885989701
Validation loss: 2.489797839758011

Epoch: 6| Step: 6
Training loss: 0.6997950219720017
Validation loss: 2.4936408571356514

Epoch: 6| Step: 7
Training loss: 0.7778311500137232
Validation loss: 2.4432059830451753

Epoch: 6| Step: 8
Training loss: 0.32950359204900165
Validation loss: 2.485328443378473

Epoch: 6| Step: 9
Training loss: 0.6177266096227916
Validation loss: 2.402776467841029

Epoch: 6| Step: 10
Training loss: 0.2721395203252089
Validation loss: 2.44055968605518

Epoch: 6| Step: 11
Training loss: 0.5450649278794665
Validation loss: 2.4303328595390687

Epoch: 6| Step: 12
Training loss: 0.5881450267385934
Validation loss: 2.443836693985369

Epoch: 6| Step: 13
Training loss: 0.8076790690210428
Validation loss: 2.473962146041514

Epoch: 248| Step: 0
Training loss: 0.7044749969339467
Validation loss: 2.4932724580916803

Epoch: 6| Step: 1
Training loss: 0.5409079213818233
Validation loss: 2.487934549126204

Epoch: 6| Step: 2
Training loss: 0.6464739104285467
Validation loss: 2.5187162416113873

Epoch: 6| Step: 3
Training loss: 0.7450706297401553
Validation loss: 2.5445630901790706

Epoch: 6| Step: 4
Training loss: 0.6050724824724805
Validation loss: 2.556546773019636

Epoch: 6| Step: 5
Training loss: 0.497559971381649
Validation loss: 2.5308622070518694

Epoch: 6| Step: 6
Training loss: 0.5191472003597855
Validation loss: 2.50597309048303

Epoch: 6| Step: 7
Training loss: 0.7815598064316707
Validation loss: 2.5012250831416036

Epoch: 6| Step: 8
Training loss: 0.47163915361266845
Validation loss: 2.516336296531863

Epoch: 6| Step: 9
Training loss: 0.6222236959216665
Validation loss: 2.471638524605808

Epoch: 6| Step: 10
Training loss: 0.3904751108604746
Validation loss: 2.4580062626386994

Epoch: 6| Step: 11
Training loss: 0.4786982907788467
Validation loss: 2.4761898575219354

Epoch: 6| Step: 12
Training loss: 0.5792869541298743
Validation loss: 2.4529682958738177

Epoch: 6| Step: 13
Training loss: 0.4939152501416713
Validation loss: 2.4521123435265135

Epoch: 249| Step: 0
Training loss: 0.5970896110373246
Validation loss: 2.464878944057438

Epoch: 6| Step: 1
Training loss: 0.8303637921818594
Validation loss: 2.5297877418947623

Epoch: 6| Step: 2
Training loss: 0.4212332188464355
Validation loss: 2.524315518776705

Epoch: 6| Step: 3
Training loss: 0.6846519345370329
Validation loss: 2.522159606518414

Epoch: 6| Step: 4
Training loss: 0.6227699310026001
Validation loss: 2.4883108452964056

Epoch: 6| Step: 5
Training loss: 0.45473804782807276
Validation loss: 2.4861168817687784

Epoch: 6| Step: 6
Training loss: 0.5832886394908406
Validation loss: 2.504371735843528

Epoch: 6| Step: 7
Training loss: 0.6064884090621112
Validation loss: 2.4770526809125415

Epoch: 6| Step: 8
Training loss: 0.3992965637337179
Validation loss: 2.424993586513241

Epoch: 6| Step: 9
Training loss: 0.6767155357465948
Validation loss: 2.425632348521369

Epoch: 6| Step: 10
Training loss: 0.4742081912780438
Validation loss: 2.4387144132521787

Epoch: 6| Step: 11
Training loss: 0.3629151827712148
Validation loss: 2.483345227468708

Epoch: 6| Step: 12
Training loss: 0.5725239766193344
Validation loss: 2.456538910720089

Epoch: 6| Step: 13
Training loss: 0.578192964631304
Validation loss: 2.420197411906415

Epoch: 250| Step: 0
Training loss: 0.48311383124663587
Validation loss: 2.442603116194529

Epoch: 6| Step: 1
Training loss: 0.38465368511160813
Validation loss: 2.4374067952878953

Epoch: 6| Step: 2
Training loss: 0.6491583528667795
Validation loss: 2.4519456231223917

Epoch: 6| Step: 3
Training loss: 0.4019448979224408
Validation loss: 2.4270486362228234

Epoch: 6| Step: 4
Training loss: 0.5633301701776681
Validation loss: 2.4609639869693027

Epoch: 6| Step: 5
Training loss: 0.4527029670043834
Validation loss: 2.4421492233060156

Epoch: 6| Step: 6
Training loss: 0.5153722432553406
Validation loss: 2.4438746552064265

Epoch: 6| Step: 7
Training loss: 0.7397107207147068
Validation loss: 2.4514888367458467

Epoch: 6| Step: 8
Training loss: 0.564732413181475
Validation loss: 2.4550600682887125

Epoch: 6| Step: 9
Training loss: 0.43389795989818336
Validation loss: 2.4062114041805795

Epoch: 6| Step: 10
Training loss: 0.5432479195605422
Validation loss: 2.451431112843661

Epoch: 6| Step: 11
Training loss: 0.6721152386203934
Validation loss: 2.4488380396478067

Epoch: 6| Step: 12
Training loss: 0.3928343093571591
Validation loss: 2.473460872529017

Epoch: 6| Step: 13
Training loss: 0.8867920160483928
Validation loss: 2.4602491138366456

Epoch: 251| Step: 0
Training loss: 0.5044956161376607
Validation loss: 2.4548787712124924

Epoch: 6| Step: 1
Training loss: 0.5224359238955959
Validation loss: 2.46220882591761

Epoch: 6| Step: 2
Training loss: 0.5718043945585274
Validation loss: 2.4538071353275375

Epoch: 6| Step: 3
Training loss: 0.17783506915594333
Validation loss: 2.472561545665112

Epoch: 6| Step: 4
Training loss: 0.7141299409967498
Validation loss: 2.47038994647272

Epoch: 6| Step: 5
Training loss: 0.7356212268431164
Validation loss: 2.466533875473203

Epoch: 6| Step: 6
Training loss: 0.6490260750656419
Validation loss: 2.4622067060427533

Epoch: 6| Step: 7
Training loss: 0.49468919964592944
Validation loss: 2.4632596249899223

Epoch: 6| Step: 8
Training loss: 0.4468963964715197
Validation loss: 2.4381967757652103

Epoch: 6| Step: 9
Training loss: 0.44230459165921615
Validation loss: 2.40728845390076

Epoch: 6| Step: 10
Training loss: 0.24113812293516554
Validation loss: 2.4589683612144784

Epoch: 6| Step: 11
Training loss: 0.7926861489625898
Validation loss: 2.4287010828082947

Epoch: 6| Step: 12
Training loss: 0.3222406204233251
Validation loss: 2.4574445842466575

Epoch: 6| Step: 13
Training loss: 0.7414935833350446
Validation loss: 2.4530003870486463

Epoch: 252| Step: 0
Training loss: 0.3891905960565114
Validation loss: 2.4527733130525426

Epoch: 6| Step: 1
Training loss: 0.5766760479112539
Validation loss: 2.487571427165962

Epoch: 6| Step: 2
Training loss: 0.6267420333155125
Validation loss: 2.46940489411329

Epoch: 6| Step: 3
Training loss: 0.25639758395858414
Validation loss: 2.4817607062381217

Epoch: 6| Step: 4
Training loss: 0.2273908304184585
Validation loss: 2.4655362971506642

Epoch: 6| Step: 5
Training loss: 0.4879787118159349
Validation loss: 2.4546065623630184

Epoch: 6| Step: 6
Training loss: 0.37946484870227754
Validation loss: 2.4247696888838863

Epoch: 6| Step: 7
Training loss: 0.5542451948681136
Validation loss: 2.450365539681736

Epoch: 6| Step: 8
Training loss: 0.46985055155472566
Validation loss: 2.4661002725949546

Epoch: 6| Step: 9
Training loss: 0.7778393876182267
Validation loss: 2.437944661429846

Epoch: 6| Step: 10
Training loss: 0.5601929401208885
Validation loss: 2.4843570014362006

Epoch: 6| Step: 11
Training loss: 0.6284974469578373
Validation loss: 2.4593778497399765

Epoch: 6| Step: 12
Training loss: 0.7438652750647825
Validation loss: 2.4449956859642246

Epoch: 6| Step: 13
Training loss: 0.6374283095796073
Validation loss: 2.4557058191242755

Epoch: 253| Step: 0
Training loss: 0.6596320062713071
Validation loss: 2.4635598946586654

Epoch: 6| Step: 1
Training loss: 0.6240611415689704
Validation loss: 2.46587989113787

Epoch: 6| Step: 2
Training loss: 0.606740219479051
Validation loss: 2.427952560374915

Epoch: 6| Step: 3
Training loss: 0.462749604582038
Validation loss: 2.4408213098199663

Epoch: 6| Step: 4
Training loss: 0.5040280690172917
Validation loss: 2.4349487916614945

Epoch: 6| Step: 5
Training loss: 0.662825610558584
Validation loss: 2.4372254420263846

Epoch: 6| Step: 6
Training loss: 0.37306708635631985
Validation loss: 2.43797434147863

Epoch: 6| Step: 7
Training loss: 0.6835852704203431
Validation loss: 2.420461574997292

Epoch: 6| Step: 8
Training loss: 0.31623595564646184
Validation loss: 2.4220627875006233

Epoch: 6| Step: 9
Training loss: 0.3805263726309614
Validation loss: 2.4125911621249685

Epoch: 6| Step: 10
Training loss: 0.4968121950775105
Validation loss: 2.404823814936285

Epoch: 6| Step: 11
Training loss: 0.4639364411708009
Validation loss: 2.4272661755948977

Epoch: 6| Step: 12
Training loss: 0.6434010161569982
Validation loss: 2.3953443562362247

Epoch: 6| Step: 13
Training loss: 0.4116780523348595
Validation loss: 2.4227915024402056

Epoch: 254| Step: 0
Training loss: 0.5225758648967643
Validation loss: 2.4468262480824565

Epoch: 6| Step: 1
Training loss: 0.5875035022063062
Validation loss: 2.4330597014681388

Epoch: 6| Step: 2
Training loss: 0.5088289505155156
Validation loss: 2.452339495451161

Epoch: 6| Step: 3
Training loss: 0.7833562306513824
Validation loss: 2.4481698032074752

Epoch: 6| Step: 4
Training loss: 0.3022366277293924
Validation loss: 2.4889886265646886

Epoch: 6| Step: 5
Training loss: 0.42372355071937484
Validation loss: 2.4702753100889727

Epoch: 6| Step: 6
Training loss: 0.34856349993352503
Validation loss: 2.4937741712900245

Epoch: 6| Step: 7
Training loss: 0.4780266423751159
Validation loss: 2.4695694335666363

Epoch: 6| Step: 8
Training loss: 0.5679465298720346
Validation loss: 2.509770087270918

Epoch: 6| Step: 9
Training loss: 0.683067097107654
Validation loss: 2.4829207451794497

Epoch: 6| Step: 10
Training loss: 0.3745399275479878
Validation loss: 2.4613483617916376

Epoch: 6| Step: 11
Training loss: 0.7630673720886731
Validation loss: 2.4563320284090686

Epoch: 6| Step: 12
Training loss: 0.5965535081972069
Validation loss: 2.4359825191947233

Epoch: 6| Step: 13
Training loss: 0.4623747256449112
Validation loss: 2.4283779648378343

Epoch: 255| Step: 0
Training loss: 0.5039811189611652
Validation loss: 2.4156829379178535

Epoch: 6| Step: 1
Training loss: 0.5435629687430606
Validation loss: 2.398944412763923

Epoch: 6| Step: 2
Training loss: 0.5946790052920774
Validation loss: 2.41766333837545

Epoch: 6| Step: 3
Training loss: 0.662565856035562
Validation loss: 2.434811217925073

Epoch: 6| Step: 4
Training loss: 0.4615097696069968
Validation loss: 2.442553090853094

Epoch: 6| Step: 5
Training loss: 0.5677946503373433
Validation loss: 2.409037640121494

Epoch: 6| Step: 6
Training loss: 0.3967177357309484
Validation loss: 2.457862719969003

Epoch: 6| Step: 7
Training loss: 0.514856343556705
Validation loss: 2.3934800902231337

Epoch: 6| Step: 8
Training loss: 0.6218775955222708
Validation loss: 2.438244858599733

Epoch: 6| Step: 9
Training loss: 0.4647117234915319
Validation loss: 2.395238615450453

Epoch: 6| Step: 10
Training loss: 0.44245477221654134
Validation loss: 2.3748907075960095

Epoch: 6| Step: 11
Training loss: 0.4609880096433971
Validation loss: 2.3916057055239173

Epoch: 6| Step: 12
Training loss: 0.5913436715441929
Validation loss: 2.400507517958976

Epoch: 6| Step: 13
Training loss: 0.5937575038636513
Validation loss: 2.4046183747421086

Epoch: 256| Step: 0
Training loss: 0.6021529433545532
Validation loss: 2.4229849556664207

Epoch: 6| Step: 1
Training loss: 0.5776665906364947
Validation loss: 2.4325413483650355

Epoch: 6| Step: 2
Training loss: 0.34413421356429336
Validation loss: 2.4313493973567106

Epoch: 6| Step: 3
Training loss: 0.5311461515463712
Validation loss: 2.386312810152982

Epoch: 6| Step: 4
Training loss: 0.6149664159071699
Validation loss: 2.398241031904141

Epoch: 6| Step: 5
Training loss: 0.48912102772586175
Validation loss: 2.417660578471138

Epoch: 6| Step: 6
Training loss: 0.4787090299919284
Validation loss: 2.4247165572215543

Epoch: 6| Step: 7
Training loss: 0.4565183908303208
Validation loss: 2.3986146238921657

Epoch: 6| Step: 8
Training loss: 0.5179786715700827
Validation loss: 2.4257719889729503

Epoch: 6| Step: 9
Training loss: 0.6258779082020245
Validation loss: 2.4209206523131743

Epoch: 6| Step: 10
Training loss: 0.6053057051135949
Validation loss: 2.4078002674696295

Epoch: 6| Step: 11
Training loss: 0.25540349109316623
Validation loss: 2.401195139419176

Epoch: 6| Step: 12
Training loss: 0.5620946483260251
Validation loss: 2.3826880637871106

Epoch: 6| Step: 13
Training loss: 0.608942024759942
Validation loss: 2.39511266055265

Epoch: 257| Step: 0
Training loss: 0.7479530853358815
Validation loss: 2.3836052033111996

Epoch: 6| Step: 1
Training loss: 0.7573931211981658
Validation loss: 2.3710933537379915

Epoch: 6| Step: 2
Training loss: 0.4048359175306825
Validation loss: 2.385412940988633

Epoch: 6| Step: 3
Training loss: 0.7022665081046202
Validation loss: 2.377155033260526

Epoch: 6| Step: 4
Training loss: 0.5403336726773369
Validation loss: 2.367584721521304

Epoch: 6| Step: 5
Training loss: 0.39219356319406445
Validation loss: 2.34571002671174

Epoch: 6| Step: 6
Training loss: 0.5308955356388639
Validation loss: 2.3788727282218876

Epoch: 6| Step: 7
Training loss: 0.4510964665002426
Validation loss: 2.3621281093219553

Epoch: 6| Step: 8
Training loss: 0.5118525381132089
Validation loss: 2.371226416744024

Epoch: 6| Step: 9
Training loss: 0.5330877773174617
Validation loss: 2.4391592871076604

Epoch: 6| Step: 10
Training loss: 0.36354565996237603
Validation loss: 2.4144998078591944

Epoch: 6| Step: 11
Training loss: 0.334620967755909
Validation loss: 2.4342120291528277

Epoch: 6| Step: 12
Training loss: 0.5519648610761866
Validation loss: 2.466625689607115

Epoch: 6| Step: 13
Training loss: 0.20520959908600123
Validation loss: 2.452414124400606

Epoch: 258| Step: 0
Training loss: 0.5570515504537943
Validation loss: 2.4639667212890894

Epoch: 6| Step: 1
Training loss: 0.3277997948481818
Validation loss: 2.417970777188664

Epoch: 6| Step: 2
Training loss: 0.5301739790852964
Validation loss: 2.40330745756936

Epoch: 6| Step: 3
Training loss: 0.4675042128245614
Validation loss: 2.438287331743791

Epoch: 6| Step: 4
Training loss: 0.5949786924906627
Validation loss: 2.4241362479960373

Epoch: 6| Step: 5
Training loss: 0.3749770912484435
Validation loss: 2.400112733064745

Epoch: 6| Step: 6
Training loss: 0.5155777765092465
Validation loss: 2.378890192883674

Epoch: 6| Step: 7
Training loss: 0.5991593949465145
Validation loss: 2.4063751737896344

Epoch: 6| Step: 8
Training loss: 0.7514151097546972
Validation loss: 2.3885277225245907

Epoch: 6| Step: 9
Training loss: 0.5401786637559471
Validation loss: 2.3936599382501527

Epoch: 6| Step: 10
Training loss: 0.5713723668063019
Validation loss: 2.4134111166436503

Epoch: 6| Step: 11
Training loss: 0.33698959609592116
Validation loss: 2.3991836429935045

Epoch: 6| Step: 12
Training loss: 0.6637025867561187
Validation loss: 2.4260359878321056

Epoch: 6| Step: 13
Training loss: 0.24888156514631005
Validation loss: 2.432026562599039

Epoch: 259| Step: 0
Training loss: 0.38686314208757544
Validation loss: 2.442835145527226

Epoch: 6| Step: 1
Training loss: 0.7029490144684855
Validation loss: 2.407537762708189

Epoch: 6| Step: 2
Training loss: 0.4641029321030487
Validation loss: 2.4240107333541534

Epoch: 6| Step: 3
Training loss: 0.5001465463456712
Validation loss: 2.4027534333624936

Epoch: 6| Step: 4
Training loss: 0.6650818126230746
Validation loss: 2.428429033828542

Epoch: 6| Step: 5
Training loss: 0.41329773868197833
Validation loss: 2.456494742098303

Epoch: 6| Step: 6
Training loss: 0.5667726055394025
Validation loss: 2.4413386551882486

Epoch: 6| Step: 7
Training loss: 0.32632280615265885
Validation loss: 2.429848853843889

Epoch: 6| Step: 8
Training loss: 0.4705285029377046
Validation loss: 2.435130654519491

Epoch: 6| Step: 9
Training loss: 0.4947606294501137
Validation loss: 2.4241460794718295

Epoch: 6| Step: 10
Training loss: 0.71152095118844
Validation loss: 2.4522936705409366

Epoch: 6| Step: 11
Training loss: 0.4210157651294016
Validation loss: 2.433740512692407

Epoch: 6| Step: 12
Training loss: 0.4911286453874914
Validation loss: 2.4501870707769235

Epoch: 6| Step: 13
Training loss: 0.1827678059286956
Validation loss: 2.4284828295599943

Epoch: 260| Step: 0
Training loss: 0.27047623267530624
Validation loss: 2.4590810466319644

Epoch: 6| Step: 1
Training loss: 0.45206201769711957
Validation loss: 2.433330758636074

Epoch: 6| Step: 2
Training loss: 0.6193379710394739
Validation loss: 2.463415060454174

Epoch: 6| Step: 3
Training loss: 0.19886036969263787
Validation loss: 2.4505203409399217

Epoch: 6| Step: 4
Training loss: 0.4503341096753239
Validation loss: 2.4450004604210074

Epoch: 6| Step: 5
Training loss: 0.5989376119816359
Validation loss: 2.472232877419467

Epoch: 6| Step: 6
Training loss: 0.33203466077062493
Validation loss: 2.463302964614678

Epoch: 6| Step: 7
Training loss: 0.6173994207516651
Validation loss: 2.4754068365710924

Epoch: 6| Step: 8
Training loss: 0.5291421530394694
Validation loss: 2.4388863864909234

Epoch: 6| Step: 9
Training loss: 0.5257493676867925
Validation loss: 2.4159337919065913

Epoch: 6| Step: 10
Training loss: 0.48184779987183235
Validation loss: 2.4502539475259866

Epoch: 6| Step: 11
Training loss: 0.6485530106944943
Validation loss: 2.4602570415486893

Epoch: 6| Step: 12
Training loss: 0.5788863040921686
Validation loss: 2.4364562901431137

Epoch: 6| Step: 13
Training loss: 0.5186622924654969
Validation loss: 2.446879096624895

Epoch: 261| Step: 0
Training loss: 0.5659876624993572
Validation loss: 2.4123927664957736

Epoch: 6| Step: 1
Training loss: 0.5401907461206332
Validation loss: 2.4391462952352323

Epoch: 6| Step: 2
Training loss: 0.3135878701031792
Validation loss: 2.4467978216512103

Epoch: 6| Step: 3
Training loss: 0.3674097808722737
Validation loss: 2.490706347835681

Epoch: 6| Step: 4
Training loss: 0.43983807128167507
Validation loss: 2.4340878719126833

Epoch: 6| Step: 5
Training loss: 0.58974039043733
Validation loss: 2.4588675386945487

Epoch: 6| Step: 6
Training loss: 0.29213639592708057
Validation loss: 2.4495428949309357

Epoch: 6| Step: 7
Training loss: 0.5544544590082954
Validation loss: 2.443311021906605

Epoch: 6| Step: 8
Training loss: 0.5427014907532464
Validation loss: 2.4575858631814675

Epoch: 6| Step: 9
Training loss: 0.5331962780635107
Validation loss: 2.44594774484009

Epoch: 6| Step: 10
Training loss: 0.5129698100269344
Validation loss: 2.4346378288211334

Epoch: 6| Step: 11
Training loss: 0.20884672426739825
Validation loss: 2.4020588308765825

Epoch: 6| Step: 12
Training loss: 0.8176059942329955
Validation loss: 2.4034009147934055

Epoch: 6| Step: 13
Training loss: 0.5408516370216204
Validation loss: 2.4528709004649505

Epoch: 262| Step: 0
Training loss: 0.6391395932730021
Validation loss: 2.407724103425403

Epoch: 6| Step: 1
Training loss: 0.43495695937092815
Validation loss: 2.4209320307339697

Epoch: 6| Step: 2
Training loss: 0.24346588736843888
Validation loss: 2.38970711148398

Epoch: 6| Step: 3
Training loss: 0.5069541425807909
Validation loss: 2.411328735214337

Epoch: 6| Step: 4
Training loss: 0.6582327363459286
Validation loss: 2.449619220762632

Epoch: 6| Step: 5
Training loss: 0.6327910478511487
Validation loss: 2.4399000793357577

Epoch: 6| Step: 6
Training loss: 0.6407349654929478
Validation loss: 2.4113566346323574

Epoch: 6| Step: 7
Training loss: 0.43565487057307595
Validation loss: 2.4162843523455186

Epoch: 6| Step: 8
Training loss: 0.5373708747302572
Validation loss: 2.4521809946990847

Epoch: 6| Step: 9
Training loss: 0.4286161417853715
Validation loss: 2.4627234673232294

Epoch: 6| Step: 10
Training loss: 0.4477005888332834
Validation loss: 2.4413507239149426

Epoch: 6| Step: 11
Training loss: 0.41699988829316215
Validation loss: 2.428855191845391

Epoch: 6| Step: 12
Training loss: 0.37161330944859655
Validation loss: 2.4378102286296124

Epoch: 6| Step: 13
Training loss: 0.2340924546742277
Validation loss: 2.4129138644035844

Epoch: 263| Step: 0
Training loss: 0.3378545047218626
Validation loss: 2.4023924100909784

Epoch: 6| Step: 1
Training loss: 0.34233987455207177
Validation loss: 2.381998688050986

Epoch: 6| Step: 2
Training loss: 0.5730189029910965
Validation loss: 2.395227066810178

Epoch: 6| Step: 3
Training loss: 0.7126974601849149
Validation loss: 2.4132430132624147

Epoch: 6| Step: 4
Training loss: 0.23932185970124187
Validation loss: 2.4250558469308547

Epoch: 6| Step: 5
Training loss: 0.34066828094029655
Validation loss: 2.41341090525633

Epoch: 6| Step: 6
Training loss: 0.38905984119288106
Validation loss: 2.39803142396136

Epoch: 6| Step: 7
Training loss: 0.47834894819669344
Validation loss: 2.4222982755875457

Epoch: 6| Step: 8
Training loss: 0.6288218708179923
Validation loss: 2.428358018344414

Epoch: 6| Step: 9
Training loss: 0.393546849780923
Validation loss: 2.4003518559323243

Epoch: 6| Step: 10
Training loss: 0.5206444652165372
Validation loss: 2.448063328175792

Epoch: 6| Step: 11
Training loss: 0.551461064032046
Validation loss: 2.400543379712736

Epoch: 6| Step: 12
Training loss: 0.6674979039491469
Validation loss: 2.40511090181348

Epoch: 6| Step: 13
Training loss: 0.596654638585625
Validation loss: 2.4142910784440215

Epoch: 264| Step: 0
Training loss: 0.3222922227460572
Validation loss: 2.441453869033249

Epoch: 6| Step: 1
Training loss: 0.6406254884671466
Validation loss: 2.459853487724884

Epoch: 6| Step: 2
Training loss: 0.3558361962952934
Validation loss: 2.486916694099136

Epoch: 6| Step: 3
Training loss: 0.5127039736061583
Validation loss: 2.4678185864446935

Epoch: 6| Step: 4
Training loss: 0.49329735493703836
Validation loss: 2.4700030834013846

Epoch: 6| Step: 5
Training loss: 0.44746076499772464
Validation loss: 2.4394279156903034

Epoch: 6| Step: 6
Training loss: 0.3512890706104204
Validation loss: 2.4203044073849416

Epoch: 6| Step: 7
Training loss: 0.46292114157220576
Validation loss: 2.4408527010227887

Epoch: 6| Step: 8
Training loss: 0.4405536350327576
Validation loss: 2.427733344362622

Epoch: 6| Step: 9
Training loss: 0.3804540972071543
Validation loss: 2.469582014692365

Epoch: 6| Step: 10
Training loss: 0.8045559377433044
Validation loss: 2.4508475658091933

Epoch: 6| Step: 11
Training loss: 0.6071248202089009
Validation loss: 2.426286680367541

Epoch: 6| Step: 12
Training loss: 0.3505869363329587
Validation loss: 2.4453629710599607

Epoch: 6| Step: 13
Training loss: 0.6196324654214663
Validation loss: 2.41813792852605

Epoch: 265| Step: 0
Training loss: 0.5389520559644533
Validation loss: 2.442617925337886

Epoch: 6| Step: 1
Training loss: 0.4278343118773562
Validation loss: 2.3943810989578402

Epoch: 6| Step: 2
Training loss: 0.3736417531022102
Validation loss: 2.410849028853708

Epoch: 6| Step: 3
Training loss: 0.4161757756403638
Validation loss: 2.413973841605708

Epoch: 6| Step: 4
Training loss: 0.5030736032142882
Validation loss: 2.391725389187661

Epoch: 6| Step: 5
Training loss: 0.46643213363212294
Validation loss: 2.4263310240672324

Epoch: 6| Step: 6
Training loss: 0.4594226286973114
Validation loss: 2.410340236620913

Epoch: 6| Step: 7
Training loss: 0.6920979805746988
Validation loss: 2.432419551533383

Epoch: 6| Step: 8
Training loss: 0.5072421171780043
Validation loss: 2.4519584980359324

Epoch: 6| Step: 9
Training loss: 0.682229036752062
Validation loss: 2.4225402066678017

Epoch: 6| Step: 10
Training loss: 0.4116951184666016
Validation loss: 2.400721247374751

Epoch: 6| Step: 11
Training loss: 0.3095897584216769
Validation loss: 2.390403809711031

Epoch: 6| Step: 12
Training loss: 0.6241190901204685
Validation loss: 2.4175398415693508

Epoch: 6| Step: 13
Training loss: 0.24930454917770709
Validation loss: 2.4005425146797164

Epoch: 266| Step: 0
Training loss: 0.460951239170983
Validation loss: 2.3690610708477675

Epoch: 6| Step: 1
Training loss: 0.33325560850716734
Validation loss: 2.4009840382698298

Epoch: 6| Step: 2
Training loss: 0.812146843673847
Validation loss: 2.3538611262141167

Epoch: 6| Step: 3
Training loss: 0.2731504295784262
Validation loss: 2.3538742756851767

Epoch: 6| Step: 4
Training loss: 0.3976023092202359
Validation loss: 2.3627354980834645

Epoch: 6| Step: 5
Training loss: 0.47348979875115377
Validation loss: 2.382034004057088

Epoch: 6| Step: 6
Training loss: 0.19203588506507116
Validation loss: 2.395990221220029

Epoch: 6| Step: 7
Training loss: 0.4119066037858874
Validation loss: 2.386115737501263

Epoch: 6| Step: 8
Training loss: 0.43670374071673645
Validation loss: 2.408054958131095

Epoch: 6| Step: 9
Training loss: 0.3435616844379918
Validation loss: 2.424778944223639

Epoch: 6| Step: 10
Training loss: 0.608608007692501
Validation loss: 2.443765384564905

Epoch: 6| Step: 11
Training loss: 0.5170182564867399
Validation loss: 2.3952183737191075

Epoch: 6| Step: 12
Training loss: 0.6093464624618523
Validation loss: 2.431595076326986

Epoch: 6| Step: 13
Training loss: 0.5044104249560588
Validation loss: 2.428041607926927

Epoch: 267| Step: 0
Training loss: 0.5501346444998806
Validation loss: 2.431191613394405

Epoch: 6| Step: 1
Training loss: 0.4923157297851494
Validation loss: 2.4030975266404266

Epoch: 6| Step: 2
Training loss: 0.6469053528524585
Validation loss: 2.404572542356088

Epoch: 6| Step: 3
Training loss: 0.7009520969920319
Validation loss: 2.4044464166918185

Epoch: 6| Step: 4
Training loss: 0.20950051324742797
Validation loss: 2.3986300375498106

Epoch: 6| Step: 5
Training loss: 0.31225508390782203
Validation loss: 2.4048149603839524

Epoch: 6| Step: 6
Training loss: 0.38703339232312706
Validation loss: 2.3626618748884223

Epoch: 6| Step: 7
Training loss: 0.3467896945121489
Validation loss: 2.3651725212441965

Epoch: 6| Step: 8
Training loss: 0.523370767011851
Validation loss: 2.3894892109813672

Epoch: 6| Step: 9
Training loss: 0.5947327762272889
Validation loss: 2.3888189955205794

Epoch: 6| Step: 10
Training loss: 0.4699746347238146
Validation loss: 2.3949003445862815

Epoch: 6| Step: 11
Training loss: 0.4072584510228453
Validation loss: 2.397487060720001

Epoch: 6| Step: 12
Training loss: 0.42358961293990943
Validation loss: 2.401955998466457

Epoch: 6| Step: 13
Training loss: 0.2730301138299838
Validation loss: 2.435193531648299

Epoch: 268| Step: 0
Training loss: 0.40437948147797714
Validation loss: 2.4154952243643923

Epoch: 6| Step: 1
Training loss: 0.7258396860173885
Validation loss: 2.421952055923569

Epoch: 6| Step: 2
Training loss: 0.3504994001349405
Validation loss: 2.424649026851014

Epoch: 6| Step: 3
Training loss: 0.5367609176840195
Validation loss: 2.395019856117864

Epoch: 6| Step: 4
Training loss: 0.4396484280098601
Validation loss: 2.419086676369241

Epoch: 6| Step: 5
Training loss: 0.6671540942081531
Validation loss: 2.4131971736418505

Epoch: 6| Step: 6
Training loss: 0.24819955107001251
Validation loss: 2.425262739754611

Epoch: 6| Step: 7
Training loss: 0.23517805644723874
Validation loss: 2.420880185153729

Epoch: 6| Step: 8
Training loss: 0.37967741054112053
Validation loss: 2.4600690742766607

Epoch: 6| Step: 9
Training loss: 0.4029350934981145
Validation loss: 2.442640629018197

Epoch: 6| Step: 10
Training loss: 0.4485280905743658
Validation loss: 2.500281666711239

Epoch: 6| Step: 11
Training loss: 0.5517880051715646
Validation loss: 2.4832702345291056

Epoch: 6| Step: 12
Training loss: 0.6810364546002149
Validation loss: 2.438399861075507

Epoch: 6| Step: 13
Training loss: 0.3594105329776609
Validation loss: 2.4629968629041765

Epoch: 269| Step: 0
Training loss: 0.493239414010619
Validation loss: 2.434300209533152

Epoch: 6| Step: 1
Training loss: 0.4718544835563091
Validation loss: 2.4258055427223546

Epoch: 6| Step: 2
Training loss: 0.5058592571714993
Validation loss: 2.418602214636687

Epoch: 6| Step: 3
Training loss: 0.7705622703347076
Validation loss: 2.426706995687532

Epoch: 6| Step: 4
Training loss: 0.3131031414785719
Validation loss: 2.432186798921849

Epoch: 6| Step: 5
Training loss: 0.6755936863971237
Validation loss: 2.4251017446499987

Epoch: 6| Step: 6
Training loss: 0.1932090984490027
Validation loss: 2.4494086245592204

Epoch: 6| Step: 7
Training loss: 0.4620479043043066
Validation loss: 2.412718469928181

Epoch: 6| Step: 8
Training loss: 0.3672479214567256
Validation loss: 2.4215947280439503

Epoch: 6| Step: 9
Training loss: 0.4879267511973458
Validation loss: 2.4521021926541744

Epoch: 6| Step: 10
Training loss: 0.2960598068106756
Validation loss: 2.436635664793485

Epoch: 6| Step: 11
Training loss: 0.5041166649868815
Validation loss: 2.462928965478141

Epoch: 6| Step: 12
Training loss: 0.446764519512626
Validation loss: 2.4536762045449305

Epoch: 6| Step: 13
Training loss: 0.3872301785067309
Validation loss: 2.45899650099438

Epoch: 270| Step: 0
Training loss: 0.5055720275365972
Validation loss: 2.417997291111952

Epoch: 6| Step: 1
Training loss: 0.2327013979543998
Validation loss: 2.4831250178584767

Epoch: 6| Step: 2
Training loss: 0.30948781018217136
Validation loss: 2.47909360863974

Epoch: 6| Step: 3
Training loss: 0.6483545135341529
Validation loss: 2.4814122647103454

Epoch: 6| Step: 4
Training loss: 0.5365752737738728
Validation loss: 2.4594768011663386

Epoch: 6| Step: 5
Training loss: 0.6440950478182612
Validation loss: 2.4246204154832927

Epoch: 6| Step: 6
Training loss: 0.21074588337539682
Validation loss: 2.4688762197942955

Epoch: 6| Step: 7
Training loss: 0.5111017948778164
Validation loss: 2.4884337440981166

Epoch: 6| Step: 8
Training loss: 0.397160859673955
Validation loss: 2.4398738165625016

Epoch: 6| Step: 9
Training loss: 0.37909915771979463
Validation loss: 2.450090831933718

Epoch: 6| Step: 10
Training loss: 0.5419422848384332
Validation loss: 2.42418252321448

Epoch: 6| Step: 11
Training loss: 0.5426736482554637
Validation loss: 2.412784986938271

Epoch: 6| Step: 12
Training loss: 0.4262315136712654
Validation loss: 2.436240616312813

Epoch: 6| Step: 13
Training loss: 0.35106152762233706
Validation loss: 2.397917709043168

Epoch: 271| Step: 0
Training loss: 0.1623780425625806
Validation loss: 2.4153779284901815

Epoch: 6| Step: 1
Training loss: 0.4547311499706436
Validation loss: 2.4375123969457757

Epoch: 6| Step: 2
Training loss: 0.36997010622533966
Validation loss: 2.4105828233258078

Epoch: 6| Step: 3
Training loss: 0.670634966204733
Validation loss: 2.373927328056501

Epoch: 6| Step: 4
Training loss: 0.4148886194766442
Validation loss: 2.393219037681554

Epoch: 6| Step: 5
Training loss: 0.494301389092082
Validation loss: 2.4255883416234028

Epoch: 6| Step: 6
Training loss: 0.4119585674294612
Validation loss: 2.4385851376414975

Epoch: 6| Step: 7
Training loss: 0.29500025535022867
Validation loss: 2.3938591672729466

Epoch: 6| Step: 8
Training loss: 0.5328700663771972
Validation loss: 2.4401371764602446

Epoch: 6| Step: 9
Training loss: 0.25665209902773223
Validation loss: 2.4246275884462167

Epoch: 6| Step: 10
Training loss: 0.5997817447191054
Validation loss: 2.445170938120669

Epoch: 6| Step: 11
Training loss: 0.4572313636811243
Validation loss: 2.4667067010131154

Epoch: 6| Step: 12
Training loss: 0.6912603278190481
Validation loss: 2.433315883489061

Epoch: 6| Step: 13
Training loss: 0.49206686812247113
Validation loss: 2.446291787223763

Epoch: 272| Step: 0
Training loss: 0.6126504557578053
Validation loss: 2.4424099633145593

Epoch: 6| Step: 1
Training loss: 0.5993949432157832
Validation loss: 2.4421758909520794

Epoch: 6| Step: 2
Training loss: 0.2743628919141291
Validation loss: 2.4608741826331957

Epoch: 6| Step: 3
Training loss: 0.405908422654734
Validation loss: 2.42483374919386

Epoch: 6| Step: 4
Training loss: 0.5640830176259538
Validation loss: 2.398819153671395

Epoch: 6| Step: 5
Training loss: 0.23019099875097535
Validation loss: 2.415454279979299

Epoch: 6| Step: 6
Training loss: 0.4551899326484161
Validation loss: 2.409440655715048

Epoch: 6| Step: 7
Training loss: 0.5109417964742992
Validation loss: 2.3971963412507984

Epoch: 6| Step: 8
Training loss: 0.4129420180803225
Validation loss: 2.432992225649354

Epoch: 6| Step: 9
Training loss: 0.524949154208158
Validation loss: 2.4343623140700035

Epoch: 6| Step: 10
Training loss: 0.4846473205214095
Validation loss: 2.4255144890938496

Epoch: 6| Step: 11
Training loss: 0.3708643153817633
Validation loss: 2.4429054232343708

Epoch: 6| Step: 12
Training loss: 0.6212523635727191
Validation loss: 2.4683321153524562

Epoch: 6| Step: 13
Training loss: 0.21047246853234608
Validation loss: 2.4677673934769726

Epoch: 273| Step: 0
Training loss: 0.6166208055772302
Validation loss: 2.493903559212028

Epoch: 6| Step: 1
Training loss: 0.39316031714302696
Validation loss: 2.461208437843141

Epoch: 6| Step: 2
Training loss: 0.509795498612062
Validation loss: 2.4764445944385765

Epoch: 6| Step: 3
Training loss: 0.2554104047171532
Validation loss: 2.429983074040327

Epoch: 6| Step: 4
Training loss: 0.5659032495541187
Validation loss: 2.4033173331831374

Epoch: 6| Step: 5
Training loss: 0.45032773997390724
Validation loss: 2.4239998167530588

Epoch: 6| Step: 6
Training loss: 0.573294122218182
Validation loss: 2.3734875684597196

Epoch: 6| Step: 7
Training loss: 0.559671149896285
Validation loss: 2.387411792553599

Epoch: 6| Step: 8
Training loss: 0.5132377153163002
Validation loss: 2.3907594342052776

Epoch: 6| Step: 9
Training loss: 0.37855007695897763
Validation loss: 2.395190272406732

Epoch: 6| Step: 10
Training loss: 0.4594533918276503
Validation loss: 2.4315538221122694

Epoch: 6| Step: 11
Training loss: 0.44879457100990444
Validation loss: 2.44498429842513

Epoch: 6| Step: 12
Training loss: 0.3407954559443542
Validation loss: 2.4495754935628455

Epoch: 6| Step: 13
Training loss: 0.3891009353894589
Validation loss: 2.4404443396542597

Epoch: 274| Step: 0
Training loss: 0.33336139600564474
Validation loss: 2.425921895322847

Epoch: 6| Step: 1
Training loss: 0.3200267121595139
Validation loss: 2.4424007425101397

Epoch: 6| Step: 2
Training loss: 0.3789424485681439
Validation loss: 2.4316998476474248

Epoch: 6| Step: 3
Training loss: 0.5702444323326884
Validation loss: 2.4550061834825656

Epoch: 6| Step: 4
Training loss: 0.5281459781610968
Validation loss: 2.4405565074475604

Epoch: 6| Step: 5
Training loss: 0.39124618729509975
Validation loss: 2.4372128741378276

Epoch: 6| Step: 6
Training loss: 0.2082074957526598
Validation loss: 2.4692464744392377

Epoch: 6| Step: 7
Training loss: 0.49579325909381133
Validation loss: 2.4441722971615407

Epoch: 6| Step: 8
Training loss: 0.33312959206227005
Validation loss: 2.4395918986995566

Epoch: 6| Step: 9
Training loss: 0.42387273878857273
Validation loss: 2.433960857113791

Epoch: 6| Step: 10
Training loss: 0.541559600029878
Validation loss: 2.4341872437088514

Epoch: 6| Step: 11
Training loss: 0.7545838152502815
Validation loss: 2.4091093246274142

Epoch: 6| Step: 12
Training loss: 0.35543938400201225
Validation loss: 2.425139218457003

Epoch: 6| Step: 13
Training loss: 0.41934570883891736
Validation loss: 2.411608990520444

Epoch: 275| Step: 0
Training loss: 0.5140207360645479
Validation loss: 2.4392385001918906

Epoch: 6| Step: 1
Training loss: 0.31081304599446297
Validation loss: 2.422175381041252

Epoch: 6| Step: 2
Training loss: 0.5520225767376901
Validation loss: 2.445637730293292

Epoch: 6| Step: 3
Training loss: 0.44617472379693746
Validation loss: 2.4462913606998975

Epoch: 6| Step: 4
Training loss: 0.34339980146744487
Validation loss: 2.451314743775071

Epoch: 6| Step: 5
Training loss: 0.7283649032990182
Validation loss: 2.4260875383106075

Epoch: 6| Step: 6
Training loss: 0.5411603162612403
Validation loss: 2.4031479049937974

Epoch: 6| Step: 7
Training loss: 0.49674356509582623
Validation loss: 2.439371160160769

Epoch: 6| Step: 8
Training loss: 0.11790042028819343
Validation loss: 2.4546369474913416

Epoch: 6| Step: 9
Training loss: 0.3613420638411513
Validation loss: 2.4615851999734075

Epoch: 6| Step: 10
Training loss: 0.3770473145130668
Validation loss: 2.42634411942643

Epoch: 6| Step: 11
Training loss: 0.18759895733328016
Validation loss: 2.441115443869948

Epoch: 6| Step: 12
Training loss: 0.4092568117715511
Validation loss: 2.463171143929759

Epoch: 6| Step: 13
Training loss: 0.5462907122142815
Validation loss: 2.4559938465206463

Epoch: 276| Step: 0
Training loss: 0.4573691659426531
Validation loss: 2.460513073739666

Epoch: 6| Step: 1
Training loss: 0.5213539732006323
Validation loss: 2.452490164354142

Epoch: 6| Step: 2
Training loss: 0.5324663374563122
Validation loss: 2.507824501323482

Epoch: 6| Step: 3
Training loss: 0.34618850082663255
Validation loss: 2.45287775879016

Epoch: 6| Step: 4
Training loss: 0.29903508169274845
Validation loss: 2.4656491851150766

Epoch: 6| Step: 5
Training loss: 0.36455589145744205
Validation loss: 2.4847963955671215

Epoch: 6| Step: 6
Training loss: 0.2891925570736483
Validation loss: 2.4912651876373326

Epoch: 6| Step: 7
Training loss: 0.4203742850459493
Validation loss: 2.501817338034965

Epoch: 6| Step: 8
Training loss: 0.4812432226719414
Validation loss: 2.4931656624843765

Epoch: 6| Step: 9
Training loss: 0.45380971410558457
Validation loss: 2.5106932390243766

Epoch: 6| Step: 10
Training loss: 0.4780336716635402
Validation loss: 2.4928750808717726

Epoch: 6| Step: 11
Training loss: 0.5910000110084029
Validation loss: 2.482505026991723

Epoch: 6| Step: 12
Training loss: 0.4652425834130214
Validation loss: 2.460138846383363

Epoch: 6| Step: 13
Training loss: 0.15528088077962657
Validation loss: 2.4889277918650645

Epoch: 277| Step: 0
Training loss: 0.6774325619456094
Validation loss: 2.4323855209362977

Epoch: 6| Step: 1
Training loss: 0.3002531443914824
Validation loss: 2.3984283653385416

Epoch: 6| Step: 2
Training loss: 0.49176599225316675
Validation loss: 2.3864315851019287

Epoch: 6| Step: 3
Training loss: 0.46825503602097296
Validation loss: 2.4004827807258864

Epoch: 6| Step: 4
Training loss: 0.4424195432256287
Validation loss: 2.412342578551435

Epoch: 6| Step: 5
Training loss: 0.3014019469551721
Validation loss: 2.3717648071371555

Epoch: 6| Step: 6
Training loss: 0.1947919393391324
Validation loss: 2.345806586250906

Epoch: 6| Step: 7
Training loss: 0.5640028110951514
Validation loss: 2.3328844977701673

Epoch: 6| Step: 8
Training loss: 0.24539606408349274
Validation loss: 2.3725991811259903

Epoch: 6| Step: 9
Training loss: 0.3109666877734171
Validation loss: 2.3754754402855602

Epoch: 6| Step: 10
Training loss: 0.5667019302484728
Validation loss: 2.359591475157577

Epoch: 6| Step: 11
Training loss: 0.593259006070187
Validation loss: 2.4128172587472836

Epoch: 6| Step: 12
Training loss: 0.21021605672311797
Validation loss: 2.456220347237415

Epoch: 6| Step: 13
Training loss: 0.4328042824856779
Validation loss: 2.470426728116189

Epoch: 278| Step: 0
Training loss: 0.4243479059640766
Validation loss: 2.4847198791794898

Epoch: 6| Step: 1
Training loss: 0.2674253821358933
Validation loss: 2.465261681566885

Epoch: 6| Step: 2
Training loss: 0.19105823174283398
Validation loss: 2.475519011380178

Epoch: 6| Step: 3
Training loss: 0.7313598256901208
Validation loss: 2.4920909306242525

Epoch: 6| Step: 4
Training loss: 0.6260335244671728
Validation loss: 2.4600063121570273

Epoch: 6| Step: 5
Training loss: 0.3003514922885264
Validation loss: 2.4577377610146205

Epoch: 6| Step: 6
Training loss: 0.4992506551322784
Validation loss: 2.486358420450342

Epoch: 6| Step: 7
Training loss: 0.4842664535476479
Validation loss: 2.4428321503865704

Epoch: 6| Step: 8
Training loss: 0.43417408914255784
Validation loss: 2.428740816942612

Epoch: 6| Step: 9
Training loss: 0.2558444506536712
Validation loss: 2.457788636138973

Epoch: 6| Step: 10
Training loss: 0.42642862643542534
Validation loss: 2.44860215146802

Epoch: 6| Step: 11
Training loss: 0.3060729366429238
Validation loss: 2.4786199634059742

Epoch: 6| Step: 12
Training loss: 0.5135051035938505
Validation loss: 2.424103773120837

Epoch: 6| Step: 13
Training loss: 0.31596943643876624
Validation loss: 2.4839374664912754

Epoch: 279| Step: 0
Training loss: 0.2963750544708472
Validation loss: 2.44764141628945

Epoch: 6| Step: 1
Training loss: 0.267421969213979
Validation loss: 2.4792665327196097

Epoch: 6| Step: 2
Training loss: 0.38676444660272785
Validation loss: 2.440758722092628

Epoch: 6| Step: 3
Training loss: 0.5710129290585088
Validation loss: 2.480936041700389

Epoch: 6| Step: 4
Training loss: 0.3259113664839043
Validation loss: 2.4479790549792404

Epoch: 6| Step: 5
Training loss: 0.299403142263363
Validation loss: 2.46760107834501

Epoch: 6| Step: 6
Training loss: 0.522856746016619
Validation loss: 2.4754871691495017

Epoch: 6| Step: 7
Training loss: 0.4635751226403099
Validation loss: 2.4602817164931348

Epoch: 6| Step: 8
Training loss: 0.3568961440869154
Validation loss: 2.491574892362383

Epoch: 6| Step: 9
Training loss: 0.5310384665814679
Validation loss: 2.4858462854842136

Epoch: 6| Step: 10
Training loss: 0.13905343765562098
Validation loss: 2.468866965702098

Epoch: 6| Step: 11
Training loss: 0.4816983623811786
Validation loss: 2.5030288038104405

Epoch: 6| Step: 12
Training loss: 0.4613831515526126
Validation loss: 2.450476903919304

Epoch: 6| Step: 13
Training loss: 0.8096218483860432
Validation loss: 2.47712040026548

Epoch: 280| Step: 0
Training loss: 0.28625874791250555
Validation loss: 2.4922321212846974

Epoch: 6| Step: 1
Training loss: 0.6535797060361175
Validation loss: 2.493703798465472

Epoch: 6| Step: 2
Training loss: 0.2655225724594451
Validation loss: 2.4589752984492126

Epoch: 6| Step: 3
Training loss: 0.5225405623465851
Validation loss: 2.4401195019282462

Epoch: 6| Step: 4
Training loss: 0.5019809106639619
Validation loss: 2.4327750950304923

Epoch: 6| Step: 5
Training loss: 0.3211553927465157
Validation loss: 2.433071673494197

Epoch: 6| Step: 6
Training loss: 0.3656162978220798
Validation loss: 2.422267020178391

Epoch: 6| Step: 7
Training loss: 0.4122757779118744
Validation loss: 2.44651443720153

Epoch: 6| Step: 8
Training loss: 0.40499357188975044
Validation loss: 2.4120468781865734

Epoch: 6| Step: 9
Training loss: 0.5876179312982958
Validation loss: 2.4228941922716762

Epoch: 6| Step: 10
Training loss: 0.6113137922952923
Validation loss: 2.4345584586739912

Epoch: 6| Step: 11
Training loss: 0.3493683479644843
Validation loss: 2.4285767018883178

Epoch: 6| Step: 12
Training loss: 0.1805534849190782
Validation loss: 2.3984675673913967

Epoch: 6| Step: 13
Training loss: 0.15718376572346254
Validation loss: 2.408987942046025

Epoch: 281| Step: 0
Training loss: 0.3623056334614293
Validation loss: 2.3803219474050086

Epoch: 6| Step: 1
Training loss: 0.514161953103312
Validation loss: 2.428080544615324

Epoch: 6| Step: 2
Training loss: 0.36200854184547526
Validation loss: 2.3985255377117456

Epoch: 6| Step: 3
Training loss: 0.3665681444727024
Validation loss: 2.383303122440481

Epoch: 6| Step: 4
Training loss: 0.43672034070539034
Validation loss: 2.3850675152630196

Epoch: 6| Step: 5
Training loss: 0.4695202380267973
Validation loss: 2.4184226812153033

Epoch: 6| Step: 6
Training loss: 0.5081352088812947
Validation loss: 2.4263478248698465

Epoch: 6| Step: 7
Training loss: 0.4697610283339186
Validation loss: 2.4457132463937774

Epoch: 6| Step: 8
Training loss: 0.45900255532478
Validation loss: 2.440528524019622

Epoch: 6| Step: 9
Training loss: 0.2884370636032622
Validation loss: 2.429277121933962

Epoch: 6| Step: 10
Training loss: 0.2756620381786242
Validation loss: 2.464933941176526

Epoch: 6| Step: 11
Training loss: 0.19657753391114843
Validation loss: 2.462009897490209

Epoch: 6| Step: 12
Training loss: 0.5620231991812464
Validation loss: 2.4614347170119784

Epoch: 6| Step: 13
Training loss: 0.6239639994173489
Validation loss: 2.4663099881914534

Epoch: 282| Step: 0
Training loss: 0.5420263881030936
Validation loss: 2.474865070144118

Epoch: 6| Step: 1
Training loss: 0.3600351034706015
Validation loss: 2.4734703649200096

Epoch: 6| Step: 2
Training loss: 0.49313434473522083
Validation loss: 2.4459446245923018

Epoch: 6| Step: 3
Training loss: 0.4407776601943373
Validation loss: 2.430896501101296

Epoch: 6| Step: 4
Training loss: 0.40405869032973407
Validation loss: 2.4603222811263254

Epoch: 6| Step: 5
Training loss: 0.25503398168629593
Validation loss: 2.4701367366318046

Epoch: 6| Step: 6
Training loss: 0.37287945011129264
Validation loss: 2.474126114566534

Epoch: 6| Step: 7
Training loss: 0.41914426974429914
Validation loss: 2.437628491014872

Epoch: 6| Step: 8
Training loss: 0.46290718725005675
Validation loss: 2.4118214831709888

Epoch: 6| Step: 9
Training loss: 0.25581023057312624
Validation loss: 2.4102083587026017

Epoch: 6| Step: 10
Training loss: 0.5000861808891995
Validation loss: 2.418566095961857

Epoch: 6| Step: 11
Training loss: 0.47917355829617986
Validation loss: 2.420550919840545

Epoch: 6| Step: 12
Training loss: 0.37161350994137754
Validation loss: 2.393481700075915

Epoch: 6| Step: 13
Training loss: 0.41753718119227873
Validation loss: 2.409083530688803

Epoch: 283| Step: 0
Training loss: 0.40411177373847573
Validation loss: 2.4115513570324247

Epoch: 6| Step: 1
Training loss: 0.5127491368696145
Validation loss: 2.4238596151770624

Epoch: 6| Step: 2
Training loss: 0.6163641109011417
Validation loss: 2.4295465978294066

Epoch: 6| Step: 3
Training loss: 0.2638181633801167
Validation loss: 2.395064266799279

Epoch: 6| Step: 4
Training loss: 0.4620530965656502
Validation loss: 2.466266758580553

Epoch: 6| Step: 5
Training loss: 0.170912900040247
Validation loss: 2.4282728580441453

Epoch: 6| Step: 6
Training loss: 0.4858530474071479
Validation loss: 2.4536951125107573

Epoch: 6| Step: 7
Training loss: 0.3141210828772943
Validation loss: 2.46086082410665

Epoch: 6| Step: 8
Training loss: 0.24342092100108673
Validation loss: 2.4595104428480123

Epoch: 6| Step: 9
Training loss: 0.4531568811974004
Validation loss: 2.4433145662657583

Epoch: 6| Step: 10
Training loss: 0.4287208434331242
Validation loss: 2.4584597858702253

Epoch: 6| Step: 11
Training loss: 0.23753346690491028
Validation loss: 2.433145776308896

Epoch: 6| Step: 12
Training loss: 0.23670937390533242
Validation loss: 2.417181525232403

Epoch: 6| Step: 13
Training loss: 0.6723837146410583
Validation loss: 2.422244775378027

Epoch: 284| Step: 0
Training loss: 0.40371837784435305
Validation loss: 2.4221234911603378

Epoch: 6| Step: 1
Training loss: 0.573491005129396
Validation loss: 2.391738611852605

Epoch: 6| Step: 2
Training loss: 0.38096114535091663
Validation loss: 2.402477444165789

Epoch: 6| Step: 3
Training loss: 0.3173484901062943
Validation loss: 2.4141989703653897

Epoch: 6| Step: 4
Training loss: 0.35880815333710586
Validation loss: 2.4307611754284366

Epoch: 6| Step: 5
Training loss: 0.27906406810102063
Validation loss: 2.4406537183413586

Epoch: 6| Step: 6
Training loss: 0.3855634637450505
Validation loss: 2.4126972336555412

Epoch: 6| Step: 7
Training loss: 0.40807276565299033
Validation loss: 2.459073392439816

Epoch: 6| Step: 8
Training loss: 0.4441190420793113
Validation loss: 2.4332936996601346

Epoch: 6| Step: 9
Training loss: 0.48359723867905124
Validation loss: 2.456694425995771

Epoch: 6| Step: 10
Training loss: 0.40699966659579107
Validation loss: 2.427183555221347

Epoch: 6| Step: 11
Training loss: 0.3089492898497636
Validation loss: 2.4636455636167574

Epoch: 6| Step: 12
Training loss: 0.5138233672146942
Validation loss: 2.4135248817633013

Epoch: 6| Step: 13
Training loss: 0.3003073960226799
Validation loss: 2.427693772202699

Epoch: 285| Step: 0
Training loss: 0.6016557546887087
Validation loss: 2.37449195946057

Epoch: 6| Step: 1
Training loss: 0.4043647230042222
Validation loss: 2.391409084596592

Epoch: 6| Step: 2
Training loss: 0.363967820982633
Validation loss: 2.3726721788471132

Epoch: 6| Step: 3
Training loss: 0.45999007730044206
Validation loss: 2.3583213174447817

Epoch: 6| Step: 4
Training loss: 0.5165622169784629
Validation loss: 2.37120964920006

Epoch: 6| Step: 5
Training loss: 0.5457181411020647
Validation loss: 2.376251527813458

Epoch: 6| Step: 6
Training loss: 0.30350854391628357
Validation loss: 2.3921847321265295

Epoch: 6| Step: 7
Training loss: 0.2630087815095067
Validation loss: 2.39250925460114

Epoch: 6| Step: 8
Training loss: 0.4147482537594411
Validation loss: 2.4107828231759525

Epoch: 6| Step: 9
Training loss: 0.3817065085448063
Validation loss: 2.4517743680045765

Epoch: 6| Step: 10
Training loss: 0.31866496578730935
Validation loss: 2.473020780377167

Epoch: 6| Step: 11
Training loss: 0.42257082035227633
Validation loss: 2.4321824298906614

Epoch: 6| Step: 12
Training loss: 0.3465077040773643
Validation loss: 2.47889403921562

Epoch: 6| Step: 13
Training loss: 0.27706973549215225
Validation loss: 2.491214283017629

Epoch: 286| Step: 0
Training loss: 0.4295939430341275
Validation loss: 2.4727838058215674

Epoch: 6| Step: 1
Training loss: 0.19193235417706503
Validation loss: 2.4471002411599545

Epoch: 6| Step: 2
Training loss: 0.5317690501492972
Validation loss: 2.4324747752121025

Epoch: 6| Step: 3
Training loss: 0.4149365646356359
Validation loss: 2.4427037861630825

Epoch: 6| Step: 4
Training loss: 0.40758109268766424
Validation loss: 2.4372501387214376

Epoch: 6| Step: 5
Training loss: 0.17096548672509268
Validation loss: 2.4365564959796666

Epoch: 6| Step: 6
Training loss: 0.16938003111155425
Validation loss: 2.39991054077638

Epoch: 6| Step: 7
Training loss: 0.27197591618719247
Validation loss: 2.4386150059568306

Epoch: 6| Step: 8
Training loss: 0.574738662873398
Validation loss: 2.4333914619683217

Epoch: 6| Step: 9
Training loss: 0.6553265795925619
Validation loss: 2.4078517952588383

Epoch: 6| Step: 10
Training loss: 0.3238732783883912
Validation loss: 2.3572444411118556

Epoch: 6| Step: 11
Training loss: 0.27712214038011834
Validation loss: 2.400391070894037

Epoch: 6| Step: 12
Training loss: 0.4299416917257462
Validation loss: 2.3810785524423412

Epoch: 6| Step: 13
Training loss: 0.5446656147537361
Validation loss: 2.4107966155107947

Epoch: 287| Step: 0
Training loss: 0.36480089462796944
Validation loss: 2.4129209361715893

Epoch: 6| Step: 1
Training loss: 0.3970818551220487
Validation loss: 2.478263420200566

Epoch: 6| Step: 2
Training loss: 0.449748547819379
Validation loss: 2.46587373227095

Epoch: 6| Step: 3
Training loss: 0.5182410259583161
Validation loss: 2.4790085862526072

Epoch: 6| Step: 4
Training loss: 0.19093551945322512
Validation loss: 2.4538891560097738

Epoch: 6| Step: 5
Training loss: 0.41573578641523357
Validation loss: 2.4832549121243304

Epoch: 6| Step: 6
Training loss: 0.37166160503427625
Validation loss: 2.4468428421510935

Epoch: 6| Step: 7
Training loss: 0.44983630646897016
Validation loss: 2.4404252455099895

Epoch: 6| Step: 8
Training loss: 0.7025248191223205
Validation loss: 2.428023156929144

Epoch: 6| Step: 9
Training loss: 0.3743488300710265
Validation loss: 2.422910642344397

Epoch: 6| Step: 10
Training loss: 0.26180500772628557
Validation loss: 2.3831691540253233

Epoch: 6| Step: 11
Training loss: 0.38381146469933203
Validation loss: 2.437274265065009

Epoch: 6| Step: 12
Training loss: 0.4047735233268876
Validation loss: 2.364931105296803

Epoch: 6| Step: 13
Training loss: 0.33298616534712083
Validation loss: 2.3904366882523655

Epoch: 288| Step: 0
Training loss: 0.6082051124613782
Validation loss: 2.4048144769325583

Epoch: 6| Step: 1
Training loss: 0.2048995557549363
Validation loss: 2.39786684607382

Epoch: 6| Step: 2
Training loss: 0.20816961451775365
Validation loss: 2.3640923148583735

Epoch: 6| Step: 3
Training loss: 0.33018549465095426
Validation loss: 2.4229833569514687

Epoch: 6| Step: 4
Training loss: 0.18675832289159433
Validation loss: 2.4181483165930477

Epoch: 6| Step: 5
Training loss: 0.47828114272486855
Validation loss: 2.4374052843907723

Epoch: 6| Step: 6
Training loss: 0.4689083308803271
Validation loss: 2.440163985863829

Epoch: 6| Step: 7
Training loss: 0.34798027326108766
Validation loss: 2.421702878130366

Epoch: 6| Step: 8
Training loss: 0.4194703979687168
Validation loss: 2.4725794512382726

Epoch: 6| Step: 9
Training loss: 0.44434261107411144
Validation loss: 2.433408167142496

Epoch: 6| Step: 10
Training loss: 0.49928159064516286
Validation loss: 2.4460067017870366

Epoch: 6| Step: 11
Training loss: 0.40662333866721656
Validation loss: 2.434236567378426

Epoch: 6| Step: 12
Training loss: 0.4781526395500491
Validation loss: 2.4160029580536464

Epoch: 6| Step: 13
Training loss: 0.5397421381008084
Validation loss: 2.4263595455294285

Epoch: 289| Step: 0
Training loss: 0.4783659720444879
Validation loss: 2.42489179753139

Epoch: 6| Step: 1
Training loss: 0.2801650366014273
Validation loss: 2.4022036814647256

Epoch: 6| Step: 2
Training loss: 0.23115850939180876
Validation loss: 2.4197813656360494

Epoch: 6| Step: 3
Training loss: 0.3668984025837769
Validation loss: 2.3768874916579628

Epoch: 6| Step: 4
Training loss: 0.440687150833063
Validation loss: 2.4418590053976024

Epoch: 6| Step: 5
Training loss: 0.366587818764066
Validation loss: 2.418125123742166

Epoch: 6| Step: 6
Training loss: 0.3464654932392875
Validation loss: 2.437195227968715

Epoch: 6| Step: 7
Training loss: 0.4906635913128379
Validation loss: 2.4195505833485056

Epoch: 6| Step: 8
Training loss: 0.3628630948993235
Validation loss: 2.4396731457731256

Epoch: 6| Step: 9
Training loss: 0.4026145394170535
Validation loss: 2.4364221149558434

Epoch: 6| Step: 10
Training loss: 0.523055834191351
Validation loss: 2.4193136595397013

Epoch: 6| Step: 11
Training loss: 0.4106415375408767
Validation loss: 2.3906594036087063

Epoch: 6| Step: 12
Training loss: 0.6079725608814089
Validation loss: 2.358113047620807

Epoch: 6| Step: 13
Training loss: 0.532687877948058
Validation loss: 2.3277111523897815

Epoch: 290| Step: 0
Training loss: 0.5327567723012501
Validation loss: 2.3905566819217463

Epoch: 6| Step: 1
Training loss: 0.4520560184553639
Validation loss: 2.3790875407943206

Epoch: 6| Step: 2
Training loss: 0.48577885077157945
Validation loss: 2.36815546492384

Epoch: 6| Step: 3
Training loss: 0.3562640839854537
Validation loss: 2.3713570328144895

Epoch: 6| Step: 4
Training loss: 0.49407442878350794
Validation loss: 2.3592702147873847

Epoch: 6| Step: 5
Training loss: 0.389115123943283
Validation loss: 2.3567895738401266

Epoch: 6| Step: 6
Training loss: 0.42382358952921395
Validation loss: 2.338448929598559

Epoch: 6| Step: 7
Training loss: 0.2971840680161876
Validation loss: 2.3116518852762717

Epoch: 6| Step: 8
Training loss: 0.394831118545799
Validation loss: 2.334164978473204

Epoch: 6| Step: 9
Training loss: 0.4413271470210145
Validation loss: 2.293355310859825

Epoch: 6| Step: 10
Training loss: 0.3914778935084874
Validation loss: 2.303960528603815

Epoch: 6| Step: 11
Training loss: 0.3345484626792566
Validation loss: 2.303989373768985

Epoch: 6| Step: 12
Training loss: 0.39821659771103296
Validation loss: 2.305076523184294

Epoch: 6| Step: 13
Training loss: 0.14058446299889155
Validation loss: 2.3365475831277065

Epoch: 291| Step: 0
Training loss: 0.3911841777118613
Validation loss: 2.2912505106652974

Epoch: 6| Step: 1
Training loss: 0.45836080844486604
Validation loss: 2.362147770711312

Epoch: 6| Step: 2
Training loss: 0.20431545676340873
Validation loss: 2.3405960344301895

Epoch: 6| Step: 3
Training loss: 0.3083231983366322
Validation loss: 2.3723361485521597

Epoch: 6| Step: 4
Training loss: 0.4975658112995435
Validation loss: 2.389042982251097

Epoch: 6| Step: 5
Training loss: 0.2829143498840381
Validation loss: 2.3785193026036024

Epoch: 6| Step: 6
Training loss: 0.33409190538271977
Validation loss: 2.4387227965043987

Epoch: 6| Step: 7
Training loss: 0.37185179934536283
Validation loss: 2.408011793376942

Epoch: 6| Step: 8
Training loss: 0.15682636293518032
Validation loss: 2.435797380932102

Epoch: 6| Step: 9
Training loss: 0.40908819737161783
Validation loss: 2.4590061889234467

Epoch: 6| Step: 10
Training loss: 0.4030504224236237
Validation loss: 2.4737602506048786

Epoch: 6| Step: 11
Training loss: 0.6241824047598376
Validation loss: 2.4514175637703506

Epoch: 6| Step: 12
Training loss: 0.1187891701042694
Validation loss: 2.437579824414763

Epoch: 6| Step: 13
Training loss: 0.7481519660137124
Validation loss: 2.4406392822503187

Epoch: 292| Step: 0
Training loss: 0.23311666614373558
Validation loss: 2.4452178013109926

Epoch: 6| Step: 1
Training loss: 0.5523119279254792
Validation loss: 2.423029267477535

Epoch: 6| Step: 2
Training loss: 0.5271077228326321
Validation loss: 2.416956255842397

Epoch: 6| Step: 3
Training loss: 0.34587096326503775
Validation loss: 2.3816705779269816

Epoch: 6| Step: 4
Training loss: 0.3793668012660063
Validation loss: 2.3999036560665896

Epoch: 6| Step: 5
Training loss: 0.276702663766118
Validation loss: 2.4098011719978496

Epoch: 6| Step: 6
Training loss: 0.35066351922073763
Validation loss: 2.4025312533113974

Epoch: 6| Step: 7
Training loss: 0.33814472500563025
Validation loss: 2.3940072626114635

Epoch: 6| Step: 8
Training loss: 0.3106837181071395
Validation loss: 2.404508412437846

Epoch: 6| Step: 9
Training loss: 0.3792195745206906
Validation loss: 2.398825560575835

Epoch: 6| Step: 10
Training loss: 0.4369051499666347
Validation loss: 2.3626230373964408

Epoch: 6| Step: 11
Training loss: 0.2646296307965416
Validation loss: 2.392407426736475

Epoch: 6| Step: 12
Training loss: 0.5492774780043223
Validation loss: 2.4288647904834453

Epoch: 6| Step: 13
Training loss: 0.4158060324937249
Validation loss: 2.4284409766915163

Epoch: 293| Step: 0
Training loss: 0.32896618648083575
Validation loss: 2.4617374123452906

Epoch: 6| Step: 1
Training loss: 0.2168256036092686
Validation loss: 2.4116035743175037

Epoch: 6| Step: 2
Training loss: 0.3837468558440492
Validation loss: 2.3835633454388665

Epoch: 6| Step: 3
Training loss: 0.6109501947123074
Validation loss: 2.360543894652652

Epoch: 6| Step: 4
Training loss: 0.23504411235175518
Validation loss: 2.3482366865405644

Epoch: 6| Step: 5
Training loss: 0.3613252588106866
Validation loss: 2.3528018632094017

Epoch: 6| Step: 6
Training loss: 0.7210751118839525
Validation loss: 2.3370725128398564

Epoch: 6| Step: 7
Training loss: 0.40985715951044815
Validation loss: 2.360759436226439

Epoch: 6| Step: 8
Training loss: 0.3912588508202034
Validation loss: 2.380438933048162

Epoch: 6| Step: 9
Training loss: 0.5167380370816338
Validation loss: 2.449215317810232

Epoch: 6| Step: 10
Training loss: 0.2988616949436029
Validation loss: 2.4270007250446337

Epoch: 6| Step: 11
Training loss: 0.5482586386957163
Validation loss: 2.424867977751436

Epoch: 6| Step: 12
Training loss: 0.3121701287638375
Validation loss: 2.4380304297378066

Epoch: 6| Step: 13
Training loss: 0.33107783368871213
Validation loss: 2.389266827004786

Epoch: 294| Step: 0
Training loss: 0.2724959238211215
Validation loss: 2.368122128723346

Epoch: 6| Step: 1
Training loss: 0.5099813070798398
Validation loss: 2.3629175711609336

Epoch: 6| Step: 2
Training loss: 0.4493459770157531
Validation loss: 2.359988933448297

Epoch: 6| Step: 3
Training loss: 0.33594328853144484
Validation loss: 2.3341159800787

Epoch: 6| Step: 4
Training loss: 0.3865971229485638
Validation loss: 2.3236649467438393

Epoch: 6| Step: 5
Training loss: 0.41563163192735375
Validation loss: 2.3768929335789895

Epoch: 6| Step: 6
Training loss: 0.3496554040710215
Validation loss: 2.3903958240727974

Epoch: 6| Step: 7
Training loss: 0.5128890770382557
Validation loss: 2.3846669480314806

Epoch: 6| Step: 8
Training loss: 0.5119997374191206
Validation loss: 2.4105652245610263

Epoch: 6| Step: 9
Training loss: 0.480711867688332
Validation loss: 2.396722365578758

Epoch: 6| Step: 10
Training loss: 0.5441254843024621
Validation loss: 2.4372635446125774

Epoch: 6| Step: 11
Training loss: 0.385408667747729
Validation loss: 2.402341552754713

Epoch: 6| Step: 12
Training loss: 0.4522679214300625
Validation loss: 2.4100480689509576

Epoch: 6| Step: 13
Training loss: 0.26246570635626293
Validation loss: 2.408393829624255

Epoch: 295| Step: 0
Training loss: 0.4136317189496033
Validation loss: 2.4260932481688275

Epoch: 6| Step: 1
Training loss: 0.36110800146736555
Validation loss: 2.4289458570366467

Epoch: 6| Step: 2
Training loss: 0.5385916215120271
Validation loss: 2.440959799359409

Epoch: 6| Step: 3
Training loss: 0.2813230790456656
Validation loss: 2.391863688687126

Epoch: 6| Step: 4
Training loss: 0.3221312502830844
Validation loss: 2.4238040869302058

Epoch: 6| Step: 5
Training loss: 0.4628481624136162
Validation loss: 2.422522808002166

Epoch: 6| Step: 6
Training loss: 0.25209742117890216
Validation loss: 2.454614040400139

Epoch: 6| Step: 7
Training loss: 0.41219220526773775
Validation loss: 2.4171174721198487

Epoch: 6| Step: 8
Training loss: 0.5445258229230149
Validation loss: 2.411285477826568

Epoch: 6| Step: 9
Training loss: 0.37991266206885915
Validation loss: 2.402067882893461

Epoch: 6| Step: 10
Training loss: 0.356207802431701
Validation loss: 2.4250609936458076

Epoch: 6| Step: 11
Training loss: 0.47002076514007024
Validation loss: 2.408840587059973

Epoch: 6| Step: 12
Training loss: 0.3492798237658424
Validation loss: 2.423720032724804

Epoch: 6| Step: 13
Training loss: 0.4263971231727191
Validation loss: 2.456052079553377

Epoch: 296| Step: 0
Training loss: 0.39611923617319283
Validation loss: 2.4337846845054143

Epoch: 6| Step: 1
Training loss: 0.36360355149235296
Validation loss: 2.4467375562313505

Epoch: 6| Step: 2
Training loss: 0.3531419243596875
Validation loss: 2.4462686835659597

Epoch: 6| Step: 3
Training loss: 0.5089149831807823
Validation loss: 2.4253923948843292

Epoch: 6| Step: 4
Training loss: 0.35412683917482624
Validation loss: 2.398301308060551

Epoch: 6| Step: 5
Training loss: 0.29277958166840296
Validation loss: 2.398666579861924

Epoch: 6| Step: 6
Training loss: 0.40980716563853525
Validation loss: 2.386120339685432

Epoch: 6| Step: 7
Training loss: 0.31731707552394245
Validation loss: 2.3585328330331015

Epoch: 6| Step: 8
Training loss: 0.4538309418913788
Validation loss: 2.387340581393133

Epoch: 6| Step: 9
Training loss: 0.25962820218443544
Validation loss: 2.371967360773638

Epoch: 6| Step: 10
Training loss: 0.4450899371065729
Validation loss: 2.4190240440028834

Epoch: 6| Step: 11
Training loss: 0.5279482167527879
Validation loss: 2.357435751157926

Epoch: 6| Step: 12
Training loss: 0.3151704650154439
Validation loss: 2.3651421357230857

Epoch: 6| Step: 13
Training loss: 0.2017839527460147
Validation loss: 2.363120229509118

Epoch: 297| Step: 0
Training loss: 0.2442189358047296
Validation loss: 2.4109544917143677

Epoch: 6| Step: 1
Training loss: 0.36312842487289304
Validation loss: 2.4114643997742955

Epoch: 6| Step: 2
Training loss: 0.38944633041775606
Validation loss: 2.4216672407967597

Epoch: 6| Step: 3
Training loss: 0.46766948142103026
Validation loss: 2.4409256688455847

Epoch: 6| Step: 4
Training loss: 0.3237399506942364
Validation loss: 2.4447086032395875

Epoch: 6| Step: 5
Training loss: 0.5207286030058593
Validation loss: 2.45953742778256

Epoch: 6| Step: 6
Training loss: 0.15816164061504973
Validation loss: 2.4293091224184247

Epoch: 6| Step: 7
Training loss: 0.4671815221142507
Validation loss: 2.4520683764097035

Epoch: 6| Step: 8
Training loss: 0.44145224340047895
Validation loss: 2.4491099936155387

Epoch: 6| Step: 9
Training loss: 0.45256642739212205
Validation loss: 2.443219918150362

Epoch: 6| Step: 10
Training loss: 0.34860500791145693
Validation loss: 2.4677248101206897

Epoch: 6| Step: 11
Training loss: 0.41654975164756564
Validation loss: 2.4477346104297415

Epoch: 6| Step: 12
Training loss: 0.27730525112242593
Validation loss: 2.462055384847878

Epoch: 6| Step: 13
Training loss: 0.33425771670681714
Validation loss: 2.4571719919104265

Epoch: 298| Step: 0
Training loss: 0.3311513348954677
Validation loss: 2.42682495882623

Epoch: 6| Step: 1
Training loss: 0.3287047985680026
Validation loss: 2.4148672050106432

Epoch: 6| Step: 2
Training loss: 0.45015579017051616
Validation loss: 2.438219107397607

Epoch: 6| Step: 3
Training loss: 0.37568746574197354
Validation loss: 2.383399446478153

Epoch: 6| Step: 4
Training loss: 0.42992612974933786
Validation loss: 2.396636987182028

Epoch: 6| Step: 5
Training loss: 0.2856157728536994
Validation loss: 2.4479328766763704

Epoch: 6| Step: 6
Training loss: 0.5108945192696763
Validation loss: 2.419673361165878

Epoch: 6| Step: 7
Training loss: 0.2499709261439326
Validation loss: 2.4256883855461653

Epoch: 6| Step: 8
Training loss: 0.32147103811528654
Validation loss: 2.3784549304619125

Epoch: 6| Step: 9
Training loss: 0.24195805571387816
Validation loss: 2.388649439689367

Epoch: 6| Step: 10
Training loss: 0.3082410027613295
Validation loss: 2.3704179713491986

Epoch: 6| Step: 11
Training loss: 0.47018629009188007
Validation loss: 2.400939901523543

Epoch: 6| Step: 12
Training loss: 0.3631904447544805
Validation loss: 2.417039342482199

Epoch: 6| Step: 13
Training loss: 0.5911661444268161
Validation loss: 2.4235908857777013

Epoch: 299| Step: 0
Training loss: 0.4995660090471776
Validation loss: 2.4355804882865963

Epoch: 6| Step: 1
Training loss: 0.4029550630360954
Validation loss: 2.4434647933666764

Epoch: 6| Step: 2
Training loss: 0.14468568206493657
Validation loss: 2.4688092774096733

Epoch: 6| Step: 3
Training loss: 0.4556742026471653
Validation loss: 2.4481973236273276

Epoch: 6| Step: 4
Training loss: 0.5104696739335539
Validation loss: 2.466780022319922

Epoch: 6| Step: 5
Training loss: 0.18271995141756703
Validation loss: 2.4542481313966027

Epoch: 6| Step: 6
Training loss: 0.36106322604768853
Validation loss: 2.457801505478055

Epoch: 6| Step: 7
Training loss: 0.38551627195158117
Validation loss: 2.4510902084279094

Epoch: 6| Step: 8
Training loss: 0.37288776219977593
Validation loss: 2.448387627121466

Epoch: 6| Step: 9
Training loss: 0.43930654836333366
Validation loss: 2.4684239488016626

Epoch: 6| Step: 10
Training loss: 0.15833986518796667
Validation loss: 2.455902281069316

Epoch: 6| Step: 11
Training loss: 0.37642844651311413
Validation loss: 2.4432894870337187

Epoch: 6| Step: 12
Training loss: 0.35214750572246345
Validation loss: 2.4662588148440454

Epoch: 6| Step: 13
Training loss: 0.5765445344601854
Validation loss: 2.430184595616701

Epoch: 300| Step: 0
Training loss: 0.49440366355663595
Validation loss: 2.4320033592641193

Epoch: 6| Step: 1
Training loss: 0.32344546653777245
Validation loss: 2.3936531437347686

Epoch: 6| Step: 2
Training loss: 0.26593085519398735
Validation loss: 2.4059661209822885

Epoch: 6| Step: 3
Training loss: 0.5080679324433689
Validation loss: 2.4126970455820427

Epoch: 6| Step: 4
Training loss: 0.601425948064472
Validation loss: 2.363378882537685

Epoch: 6| Step: 5
Training loss: 0.28548361655508214
Validation loss: 2.392102894534342

Epoch: 6| Step: 6
Training loss: 0.4265210435445348
Validation loss: 2.396752767888462

Epoch: 6| Step: 7
Training loss: 0.6105130401627683
Validation loss: 2.4193951523491632

Epoch: 6| Step: 8
Training loss: 0.45082101762182814
Validation loss: 2.4136353212448456

Epoch: 6| Step: 9
Training loss: 0.561097223817657
Validation loss: 2.415711284768414

Epoch: 6| Step: 10
Training loss: 0.5518100409980621
Validation loss: 2.352132619997565

Epoch: 6| Step: 11
Training loss: 0.5211122020559995
Validation loss: 2.345756698799488

Epoch: 6| Step: 12
Training loss: 0.40246572775083295
Validation loss: 2.3397062694951183

Epoch: 6| Step: 13
Training loss: 0.4653219920433403
Validation loss: 2.349248621834336

Epoch: 301| Step: 0
Training loss: 0.6466144995523543
Validation loss: 2.3499193513253775

Epoch: 6| Step: 1
Training loss: 0.37476850357842784
Validation loss: 2.3783814440882622

Epoch: 6| Step: 2
Training loss: 0.4772522734102801
Validation loss: 2.407707988277155

Epoch: 6| Step: 3
Training loss: 0.33170995313396423
Validation loss: 2.490898729787104

Epoch: 6| Step: 4
Training loss: 0.548674402395427
Validation loss: 2.477485292536174

Epoch: 6| Step: 5
Training loss: 0.412213407285063
Validation loss: 2.4875530230054523

Epoch: 6| Step: 6
Training loss: 0.4567039817800195
Validation loss: 2.4952938642991356

Epoch: 6| Step: 7
Training loss: 0.4219632939379553
Validation loss: 2.507266084535647

Epoch: 6| Step: 8
Training loss: 0.5749464030786839
Validation loss: 2.5171385440921394

Epoch: 6| Step: 9
Training loss: 0.4589302193366634
Validation loss: 2.4980083510294584

Epoch: 6| Step: 10
Training loss: 0.30161820425921965
Validation loss: 2.4476524882478192

Epoch: 6| Step: 11
Training loss: 0.3997139399584075
Validation loss: 2.458210083958883

Epoch: 6| Step: 12
Training loss: 0.40197168201728645
Validation loss: 2.443844193963024

Epoch: 6| Step: 13
Training loss: 0.3191529896090672
Validation loss: 2.4593284241333375

Epoch: 302| Step: 0
Training loss: 0.3599867589489062
Validation loss: 2.4148368598371333

Epoch: 6| Step: 1
Training loss: 0.342415723508237
Validation loss: 2.3742713717259423

Epoch: 6| Step: 2
Training loss: 0.39672802734344953
Validation loss: 2.414654993127842

Epoch: 6| Step: 3
Training loss: 0.5205264777009253
Validation loss: 2.391772866532582

Epoch: 6| Step: 4
Training loss: 0.3818872519742492
Validation loss: 2.3831173765460316

Epoch: 6| Step: 5
Training loss: 0.376650377363712
Validation loss: 2.3783515744086423

Epoch: 6| Step: 6
Training loss: 0.44620479731462276
Validation loss: 2.428483565351588

Epoch: 6| Step: 7
Training loss: 0.4471681813533
Validation loss: 2.4654932510176764

Epoch: 6| Step: 8
Training loss: 0.26977700625665113
Validation loss: 2.4987181402280183

Epoch: 6| Step: 9
Training loss: 0.31155226762396643
Validation loss: 2.4913581648381338

Epoch: 6| Step: 10
Training loss: 0.4874679047460862
Validation loss: 2.5088967574762067

Epoch: 6| Step: 11
Training loss: 0.4674218435285871
Validation loss: 2.5219617951975284

Epoch: 6| Step: 12
Training loss: 0.48349626880535485
Validation loss: 2.4832811863463236

Epoch: 6| Step: 13
Training loss: 0.4824841416673187
Validation loss: 2.4840823776602816

Epoch: 303| Step: 0
Training loss: 0.31329697072451573
Validation loss: 2.453892763444358

Epoch: 6| Step: 1
Training loss: 0.30369957905715994
Validation loss: 2.461722795804639

Epoch: 6| Step: 2
Training loss: 0.3470112034874412
Validation loss: 2.4369851844739823

Epoch: 6| Step: 3
Training loss: 0.4279444975316374
Validation loss: 2.42053452628087

Epoch: 6| Step: 4
Training loss: 0.3786744657427461
Validation loss: 2.4403140287228635

Epoch: 6| Step: 5
Training loss: 0.4320435003161466
Validation loss: 2.429974561202216

Epoch: 6| Step: 6
Training loss: 0.42563679195655596
Validation loss: 2.387362624166918

Epoch: 6| Step: 7
Training loss: 0.4424874222040061
Validation loss: 2.419938411489126

Epoch: 6| Step: 8
Training loss: 0.5901005672155387
Validation loss: 2.43296385991621

Epoch: 6| Step: 9
Training loss: 0.3010056018125898
Validation loss: 2.4449369631055373

Epoch: 6| Step: 10
Training loss: 0.5933747360521416
Validation loss: 2.48855259803895

Epoch: 6| Step: 11
Training loss: 0.31254526048962333
Validation loss: 2.4625454651249186

Epoch: 6| Step: 12
Training loss: 0.34655659599194055
Validation loss: 2.472483221320419

Epoch: 6| Step: 13
Training loss: 0.4423527991616677
Validation loss: 2.4798607961393264

Epoch: 304| Step: 0
Training loss: 0.4100988075359005
Validation loss: 2.436917195615072

Epoch: 6| Step: 1
Training loss: 0.3281923520127816
Validation loss: 2.4272896597411155

Epoch: 6| Step: 2
Training loss: 0.4381806324399009
Validation loss: 2.4003802129501857

Epoch: 6| Step: 3
Training loss: 0.18601608178580514
Validation loss: 2.4063553208420005

Epoch: 6| Step: 4
Training loss: 0.6322876437298551
Validation loss: 2.3592127794677724

Epoch: 6| Step: 5
Training loss: 0.3082335458302383
Validation loss: 2.359240497595511

Epoch: 6| Step: 6
Training loss: 0.3892482720032289
Validation loss: 2.3650479872305774

Epoch: 6| Step: 7
Training loss: 0.5323514739277616
Validation loss: 2.3884247583508804

Epoch: 6| Step: 8
Training loss: 0.46830047669778463
Validation loss: 2.4337660927087232

Epoch: 6| Step: 9
Training loss: 0.25248318000046543
Validation loss: 2.5052844924066378

Epoch: 6| Step: 10
Training loss: 0.523567923623507
Validation loss: 2.5304898298330176

Epoch: 6| Step: 11
Training loss: 0.4565606914487054
Validation loss: 2.515722995531619

Epoch: 6| Step: 12
Training loss: 0.4298139732804869
Validation loss: 2.4855712365470204

Epoch: 6| Step: 13
Training loss: 0.38835721721521665
Validation loss: 2.4735500747957126

Epoch: 305| Step: 0
Training loss: 0.5470414044751495
Validation loss: 2.4512150988991936

Epoch: 6| Step: 1
Training loss: 0.15947394875670162
Validation loss: 2.4272555250081815

Epoch: 6| Step: 2
Training loss: 0.22518828051027104
Validation loss: 2.4109542476800825

Epoch: 6| Step: 3
Training loss: 0.2853357063916902
Validation loss: 2.3661898025279067

Epoch: 6| Step: 4
Training loss: 0.41488386057247306
Validation loss: 2.3623222285275345

Epoch: 6| Step: 5
Training loss: 0.6312705669262982
Validation loss: 2.308834949141385

Epoch: 6| Step: 6
Training loss: 0.37957209650373985
Validation loss: 2.344650062915927

Epoch: 6| Step: 7
Training loss: 0.5155984698319499
Validation loss: 2.363171030510188

Epoch: 6| Step: 8
Training loss: 0.4867110985021313
Validation loss: 2.385736376770035

Epoch: 6| Step: 9
Training loss: 0.3734884195447494
Validation loss: 2.362475911920639

Epoch: 6| Step: 10
Training loss: 0.3122727640809003
Validation loss: 2.39678058026775

Epoch: 6| Step: 11
Training loss: 0.3924517072137215
Validation loss: 2.3891757145985126

Epoch: 6| Step: 12
Training loss: 0.4718055004450116
Validation loss: 2.3692694668201693

Epoch: 6| Step: 13
Training loss: 0.40738907094031446
Validation loss: 2.3617589628374787

Epoch: 306| Step: 0
Training loss: 0.27150844220301446
Validation loss: 2.366413413473784

Epoch: 6| Step: 1
Training loss: 0.4509482717251886
Validation loss: 2.3875916477870165

Epoch: 6| Step: 2
Training loss: 0.3846811501965141
Validation loss: 2.3689873663919068

Epoch: 6| Step: 3
Training loss: 0.5183820706582764
Validation loss: 2.390609150817309

Epoch: 6| Step: 4
Training loss: 0.4013092481834603
Validation loss: 2.3907472988167098

Epoch: 6| Step: 5
Training loss: 0.26646867171794486
Validation loss: 2.421664280875811

Epoch: 6| Step: 6
Training loss: 0.3006455003644349
Validation loss: 2.3866107354261845

Epoch: 6| Step: 7
Training loss: 0.36693312579292797
Validation loss: 2.375438746538172

Epoch: 6| Step: 8
Training loss: 0.3586090466928851
Validation loss: 2.4100600656689894

Epoch: 6| Step: 9
Training loss: 0.5062943580408773
Validation loss: 2.406229205255425

Epoch: 6| Step: 10
Training loss: 0.4371064834567267
Validation loss: 2.4268776925636324

Epoch: 6| Step: 11
Training loss: 0.40251915080553996
Validation loss: 2.389336284957594

Epoch: 6| Step: 12
Training loss: 0.3271922295710385
Validation loss: 2.432315353492883

Epoch: 6| Step: 13
Training loss: 0.3275479624294855
Validation loss: 2.4233905095448045

Epoch: 307| Step: 0
Training loss: 0.295624130562276
Validation loss: 2.4298468418402583

Epoch: 6| Step: 1
Training loss: 0.41746328218118783
Validation loss: 2.478591104154255

Epoch: 6| Step: 2
Training loss: 0.4899869195496214
Validation loss: 2.477933195418879

Epoch: 6| Step: 3
Training loss: 0.5729553700869959
Validation loss: 2.466646003248585

Epoch: 6| Step: 4
Training loss: 0.2691490255077408
Validation loss: 2.502038551140128

Epoch: 6| Step: 5
Training loss: 0.3076197064008974
Validation loss: 2.475489573836037

Epoch: 6| Step: 6
Training loss: 0.34964151074918287
Validation loss: 2.45643558810869

Epoch: 6| Step: 7
Training loss: 0.32059152592003637
Validation loss: 2.4538243508297652

Epoch: 6| Step: 8
Training loss: 0.3214080729268276
Validation loss: 2.423312547244222

Epoch: 6| Step: 9
Training loss: 0.5790989893426707
Validation loss: 2.4163485824422493

Epoch: 6| Step: 10
Training loss: 0.29375829482034516
Validation loss: 2.4111142480569367

Epoch: 6| Step: 11
Training loss: 0.44227337694138197
Validation loss: 2.4121769248348914

Epoch: 6| Step: 12
Training loss: 0.2595017175332784
Validation loss: 2.402634934450287

Epoch: 6| Step: 13
Training loss: 0.334796320110012
Validation loss: 2.4159174710090103

Epoch: 308| Step: 0
Training loss: 0.17496186121811536
Validation loss: 2.3745890511723493

Epoch: 6| Step: 1
Training loss: 0.47361852879959854
Validation loss: 2.362474333026923

Epoch: 6| Step: 2
Training loss: 0.4185084486077806
Validation loss: 2.4497953586862

Epoch: 6| Step: 3
Training loss: 0.25573884877032366
Validation loss: 2.4228620568006627

Epoch: 6| Step: 4
Training loss: 0.39956457011800767
Validation loss: 2.420628737558888

Epoch: 6| Step: 5
Training loss: 0.34729752624700544
Validation loss: 2.4486561751065423

Epoch: 6| Step: 6
Training loss: 0.44729922305853453
Validation loss: 2.4479891022538416

Epoch: 6| Step: 7
Training loss: 0.3256115583511989
Validation loss: 2.4392033345160744

Epoch: 6| Step: 8
Training loss: 0.39246518612408443
Validation loss: 2.433779396654746

Epoch: 6| Step: 9
Training loss: 0.2528842605388614
Validation loss: 2.440329805114075

Epoch: 6| Step: 10
Training loss: 0.49931521013617614
Validation loss: 2.438938462114098

Epoch: 6| Step: 11
Training loss: 0.45356799537112424
Validation loss: 2.4265184804522075

Epoch: 6| Step: 12
Training loss: 0.3682620780657804
Validation loss: 2.4412842921487554

Epoch: 6| Step: 13
Training loss: 0.21859807460779848
Validation loss: 2.4244031959761956

Epoch: 309| Step: 0
Training loss: 0.3563620064988202
Validation loss: 2.442892694752138

Epoch: 6| Step: 1
Training loss: 0.31771014426710636
Validation loss: 2.4251073294457344

Epoch: 6| Step: 2
Training loss: 0.4946476141055105
Validation loss: 2.4122516623492527

Epoch: 6| Step: 3
Training loss: 0.30047563409085365
Validation loss: 2.4216780429954516

Epoch: 6| Step: 4
Training loss: 0.4095518108913292
Validation loss: 2.388891314369923

Epoch: 6| Step: 5
Training loss: 0.24253696946383588
Validation loss: 2.392280973959451

Epoch: 6| Step: 6
Training loss: 0.32627036840427925
Validation loss: 2.398411060853037

Epoch: 6| Step: 7
Training loss: 0.25214036002248325
Validation loss: 2.430367367711072

Epoch: 6| Step: 8
Training loss: 0.3646052853469568
Validation loss: 2.410081167748976

Epoch: 6| Step: 9
Training loss: 0.2612268608058017
Validation loss: 2.384454464240425

Epoch: 6| Step: 10
Training loss: 0.49908539449003203
Validation loss: 2.418394941757925

Epoch: 6| Step: 11
Training loss: 0.3750764848275566
Validation loss: 2.3921767813687023

Epoch: 6| Step: 12
Training loss: 0.31334555196695724
Validation loss: 2.3975862044646647

Epoch: 6| Step: 13
Training loss: 0.5087706989042233
Validation loss: 2.4046930870469874

Epoch: 310| Step: 0
Training loss: 0.28856216121469447
Validation loss: 2.3798745367969603

Epoch: 6| Step: 1
Training loss: 0.18858745257870774
Validation loss: 2.375800890940718

Epoch: 6| Step: 2
Training loss: 0.37916473538392464
Validation loss: 2.337615614251631

Epoch: 6| Step: 3
Training loss: 0.4339101856727675
Validation loss: 2.384278081893584

Epoch: 6| Step: 4
Training loss: 0.3945953581440304
Validation loss: 2.3861181769232056

Epoch: 6| Step: 5
Training loss: 0.33420816252258245
Validation loss: 2.4046148916862897

Epoch: 6| Step: 6
Training loss: 0.41104003511824594
Validation loss: 2.38259835843548

Epoch: 6| Step: 7
Training loss: 0.32869348780010144
Validation loss: 2.419574767511247

Epoch: 6| Step: 8
Training loss: 0.3881286198298263
Validation loss: 2.420219874135716

Epoch: 6| Step: 9
Training loss: 0.31223450349817405
Validation loss: 2.4467140397627416

Epoch: 6| Step: 10
Training loss: 0.2927145427280547
Validation loss: 2.487862131562488

Epoch: 6| Step: 11
Training loss: 0.32285820780501895
Validation loss: 2.495105256570911

Epoch: 6| Step: 12
Training loss: 0.3636686658871317
Validation loss: 2.488222518899785

Epoch: 6| Step: 13
Training loss: 0.5059243826906352
Validation loss: 2.491838457824626

Epoch: 311| Step: 0
Training loss: 0.49477933232510374
Validation loss: 2.4505105132767846

Epoch: 6| Step: 1
Training loss: 0.6653131040800622
Validation loss: 2.5063061068554653

Epoch: 6| Step: 2
Training loss: 0.35035564116129336
Validation loss: 2.4614541100920615

Epoch: 6| Step: 3
Training loss: 0.4870696944140212
Validation loss: 2.4382733206086717

Epoch: 6| Step: 4
Training loss: 0.2697638599814158
Validation loss: 2.3959773772508006

Epoch: 6| Step: 5
Training loss: 0.22579875007047767
Validation loss: 2.406290363217746

Epoch: 6| Step: 6
Training loss: 0.21931608217205073
Validation loss: 2.4034849574832795

Epoch: 6| Step: 7
Training loss: 0.30898409914566244
Validation loss: 2.401406070951715

Epoch: 6| Step: 8
Training loss: 0.2984837685913195
Validation loss: 2.3953707615390676

Epoch: 6| Step: 9
Training loss: 0.1562584755506152
Validation loss: 2.393606436810102

Epoch: 6| Step: 10
Training loss: 0.291855668524374
Validation loss: 2.3920391923143964

Epoch: 6| Step: 11
Training loss: 0.21284353102808717
Validation loss: 2.419500825196455

Epoch: 6| Step: 12
Training loss: 0.20126296268204066
Validation loss: 2.3819097101442326

Epoch: 6| Step: 13
Training loss: 0.13941122462066277
Validation loss: 2.4067107272137895

Epoch: 312| Step: 0
Training loss: 0.1954006377670477
Validation loss: 2.437376595048142

Epoch: 6| Step: 1
Training loss: 0.23081690144209369
Validation loss: 2.401195164508996

Epoch: 6| Step: 2
Training loss: 0.4235412048372352
Validation loss: 2.4159339075706976

Epoch: 6| Step: 3
Training loss: 0.4598552477141587
Validation loss: 2.4273019271730707

Epoch: 6| Step: 4
Training loss: 0.3428228945794942
Validation loss: 2.4312626826622488

Epoch: 6| Step: 5
Training loss: 0.2505484763350906
Validation loss: 2.43063075881459

Epoch: 6| Step: 6
Training loss: 0.4623630752727382
Validation loss: 2.4170028122475418

Epoch: 6| Step: 7
Training loss: 0.2615519319356845
Validation loss: 2.46956473593568

Epoch: 6| Step: 8
Training loss: 0.2568825654031877
Validation loss: 2.4907216223422117

Epoch: 6| Step: 9
Training loss: 0.31226611922098296
Validation loss: 2.4576700906899576

Epoch: 6| Step: 10
Training loss: 0.32813810140702776
Validation loss: 2.4707590414834995

Epoch: 6| Step: 11
Training loss: 0.20022668360101026
Validation loss: 2.5056130032497768

Epoch: 6| Step: 12
Training loss: 0.47386814838387786
Validation loss: 2.4972224095069526

Epoch: 6| Step: 13
Training loss: 0.35228700159677373
Validation loss: 2.4896218819520737

Epoch: 313| Step: 0
Training loss: 0.48854564375027876
Validation loss: 2.5141706553705996

Epoch: 6| Step: 1
Training loss: 0.44758348123172376
Validation loss: 2.4914098156242845

Epoch: 6| Step: 2
Training loss: 0.2760741091803221
Validation loss: 2.4818625623908486

Epoch: 6| Step: 3
Training loss: 0.23131192061365352
Validation loss: 2.447442825282063

Epoch: 6| Step: 4
Training loss: 0.4667925016445728
Validation loss: 2.4540647858456786

Epoch: 6| Step: 5
Training loss: 0.4312839501603691
Validation loss: 2.393729430983434

Epoch: 6| Step: 6
Training loss: 0.24433020288459997
Validation loss: 2.3762533996332964

Epoch: 6| Step: 7
Training loss: 0.3878875563270602
Validation loss: 2.3722580915814806

Epoch: 6| Step: 8
Training loss: 0.3312049794642541
Validation loss: 2.395838023676479

Epoch: 6| Step: 9
Training loss: 0.21971232050198047
Validation loss: 2.3911021678163666

Epoch: 6| Step: 10
Training loss: 0.17210391903929365
Validation loss: 2.4104569326454377

Epoch: 6| Step: 11
Training loss: 0.25613660571332364
Validation loss: 2.4051070964985977

Epoch: 6| Step: 12
Training loss: 0.28374581791824915
Validation loss: 2.401790970083633

Epoch: 6| Step: 13
Training loss: 0.3962231983182122
Validation loss: 2.4357263039924115

Epoch: 314| Step: 0
Training loss: 0.5223523463832138
Validation loss: 2.404838872717393

Epoch: 6| Step: 1
Training loss: 0.22366801655299703
Validation loss: 2.4210995510086764

Epoch: 6| Step: 2
Training loss: 0.384207965254241
Validation loss: 2.4189487484259775

Epoch: 6| Step: 3
Training loss: 0.39571034461587407
Validation loss: 2.4563901694098305

Epoch: 6| Step: 4
Training loss: 0.22313898025386275
Validation loss: 2.3731735386769106

Epoch: 6| Step: 5
Training loss: 0.25593386723195716
Validation loss: 2.409361003489642

Epoch: 6| Step: 6
Training loss: 0.38297661358072366
Validation loss: 2.416529898933578

Epoch: 6| Step: 7
Training loss: 0.18312088965011528
Validation loss: 2.42106178118922

Epoch: 6| Step: 8
Training loss: 0.1985329436006728
Validation loss: 2.4214338363252743

Epoch: 6| Step: 9
Training loss: 0.4252422490846039
Validation loss: 2.4267376445761584

Epoch: 6| Step: 10
Training loss: 0.18545005681640503
Validation loss: 2.416712079100612

Epoch: 6| Step: 11
Training loss: 0.2541861238744857
Validation loss: 2.4304752972580848

Epoch: 6| Step: 12
Training loss: 0.4748861345791685
Validation loss: 2.4581256960916003

Epoch: 6| Step: 13
Training loss: 0.41452698476403765
Validation loss: 2.4354903406034034

Epoch: 315| Step: 0
Training loss: 0.19457912085858867
Validation loss: 2.447965497795539

Epoch: 6| Step: 1
Training loss: 0.32770420522124816
Validation loss: 2.42022537645238

Epoch: 6| Step: 2
Training loss: 0.27125234774263507
Validation loss: 2.434465014976172

Epoch: 6| Step: 3
Training loss: 0.21706492374933128
Validation loss: 2.4111672190738016

Epoch: 6| Step: 4
Training loss: 0.4080819127937901
Validation loss: 2.4305547369288067

Epoch: 6| Step: 5
Training loss: 0.32351414974698917
Validation loss: 2.399694216853364

Epoch: 6| Step: 6
Training loss: 0.2827884400391949
Validation loss: 2.4002861051524977

Epoch: 6| Step: 7
Training loss: 0.31387529534797337
Validation loss: 2.4361551990840375

Epoch: 6| Step: 8
Training loss: 0.40286865067930616
Validation loss: 2.4539094047963452

Epoch: 6| Step: 9
Training loss: 0.285901350331495
Validation loss: 2.451875893114048

Epoch: 6| Step: 10
Training loss: 0.343195999821807
Validation loss: 2.479896324976408

Epoch: 6| Step: 11
Training loss: 0.3265931612432325
Validation loss: 2.4548609239858856

Epoch: 6| Step: 12
Training loss: 0.42604008078182815
Validation loss: 2.469317975122778

Epoch: 6| Step: 13
Training loss: 0.5657118388161922
Validation loss: 2.442322656469814

Epoch: 316| Step: 0
Training loss: 0.4260640386414022
Validation loss: 2.4213730222055276

Epoch: 6| Step: 1
Training loss: 0.3834832212863402
Validation loss: 2.4510800488773405

Epoch: 6| Step: 2
Training loss: 0.37995243170053317
Validation loss: 2.414822848527372

Epoch: 6| Step: 3
Training loss: 0.20337540524142828
Validation loss: 2.4162328505402018

Epoch: 6| Step: 4
Training loss: 0.41944041485285904
Validation loss: 2.4106026042351036

Epoch: 6| Step: 5
Training loss: 0.33095531041071363
Validation loss: 2.4404304722139614

Epoch: 6| Step: 6
Training loss: 0.28256290022482705
Validation loss: 2.4290847597835374

Epoch: 6| Step: 7
Training loss: 0.17023380193662016
Validation loss: 2.4320224987109347

Epoch: 6| Step: 8
Training loss: 0.43772521353044336
Validation loss: 2.424425647260715

Epoch: 6| Step: 9
Training loss: 0.3264951645637658
Validation loss: 2.4325288818214332

Epoch: 6| Step: 10
Training loss: 0.29388211607014536
Validation loss: 2.4635890439377137

Epoch: 6| Step: 11
Training loss: 0.4233768363374452
Validation loss: 2.466567916675526

Epoch: 6| Step: 12
Training loss: 0.3145678056375208
Validation loss: 2.467617128571167

Epoch: 6| Step: 13
Training loss: 0.4778955763104625
Validation loss: 2.4218326455076915

Epoch: 317| Step: 0
Training loss: 0.3908240764690218
Validation loss: 2.4244416956989063

Epoch: 6| Step: 1
Training loss: 0.29029590781011877
Validation loss: 2.4067559181175495

Epoch: 6| Step: 2
Training loss: 0.2947291319111332
Validation loss: 2.423689273750281

Epoch: 6| Step: 3
Training loss: 0.5064075989956824
Validation loss: 2.401733467118832

Epoch: 6| Step: 4
Training loss: 0.3726890605501688
Validation loss: 2.3824420567705946

Epoch: 6| Step: 5
Training loss: 0.4146215156084454
Validation loss: 2.386938989178932

Epoch: 6| Step: 6
Training loss: 0.38164982076945797
Validation loss: 2.433318730202466

Epoch: 6| Step: 7
Training loss: 0.47833781150002064
Validation loss: 2.438009661580276

Epoch: 6| Step: 8
Training loss: 0.329770989264821
Validation loss: 2.4083653583250255

Epoch: 6| Step: 9
Training loss: 0.21749389565879323
Validation loss: 2.4449826978427813

Epoch: 6| Step: 10
Training loss: 0.37019967239515833
Validation loss: 2.434573259889015

Epoch: 6| Step: 11
Training loss: 0.3578214444370997
Validation loss: 2.423970793711472

Epoch: 6| Step: 12
Training loss: 0.30828967988233785
Validation loss: 2.4052427671777443

Epoch: 6| Step: 13
Training loss: 0.32812937097817046
Validation loss: 2.395357845752044

Epoch: 318| Step: 0
Training loss: 0.52559382823633
Validation loss: 2.3942127641961384

Epoch: 6| Step: 1
Training loss: 0.3962915449595827
Validation loss: 2.4041786339708424

Epoch: 6| Step: 2
Training loss: 0.2601675781441345
Validation loss: 2.388473247989636

Epoch: 6| Step: 3
Training loss: 0.400640549231515
Validation loss: 2.378938608936035

Epoch: 6| Step: 4
Training loss: 0.3623417015396124
Validation loss: 2.3645441461239356

Epoch: 6| Step: 5
Training loss: 0.30003857265293865
Validation loss: 2.4070311526106103

Epoch: 6| Step: 6
Training loss: 0.3520421888173215
Validation loss: 2.4028771900102837

Epoch: 6| Step: 7
Training loss: 0.2983750292918235
Validation loss: 2.455575519935275

Epoch: 6| Step: 8
Training loss: 0.1337043466149974
Validation loss: 2.4371633105185775

Epoch: 6| Step: 9
Training loss: 0.268754045877387
Validation loss: 2.4539633178646385

Epoch: 6| Step: 10
Training loss: 0.4343737897238577
Validation loss: 2.4620459286239096

Epoch: 6| Step: 11
Training loss: 0.3663097197500856
Validation loss: 2.46973904784639

Epoch: 6| Step: 12
Training loss: 0.45165398670828527
Validation loss: 2.4576406099038777

Epoch: 6| Step: 13
Training loss: 0.41804815589795524
Validation loss: 2.481064076999166

Epoch: 319| Step: 0
Training loss: 0.48239512504515203
Validation loss: 2.4506388179857947

Epoch: 6| Step: 1
Training loss: 0.3901947894939233
Validation loss: 2.470327996329786

Epoch: 6| Step: 2
Training loss: 0.23453505931660434
Validation loss: 2.4595803535334713

Epoch: 6| Step: 3
Training loss: 0.3671366473757397
Validation loss: 2.443863397766203

Epoch: 6| Step: 4
Training loss: 0.47664116382177635
Validation loss: 2.399093277472208

Epoch: 6| Step: 5
Training loss: 0.2391635241880774
Validation loss: 2.399348333034102

Epoch: 6| Step: 6
Training loss: 0.2779284479216801
Validation loss: 2.4534634247697404

Epoch: 6| Step: 7
Training loss: 0.2758718844169987
Validation loss: 2.3921207855944724

Epoch: 6| Step: 8
Training loss: 0.4126389702873502
Validation loss: 2.40293283590719

Epoch: 6| Step: 9
Training loss: 0.2768903976016717
Validation loss: 2.4096565483111796

Epoch: 6| Step: 10
Training loss: 0.3045577726758551
Validation loss: 2.4070354682433894

Epoch: 6| Step: 11
Training loss: 0.26601978024277695
Validation loss: 2.4325896457379885

Epoch: 6| Step: 12
Training loss: 0.3729091409992976
Validation loss: 2.4154809825833095

Epoch: 6| Step: 13
Training loss: 0.3467246013077134
Validation loss: 2.4438751367004072

Epoch: 320| Step: 0
Training loss: 0.30090068328506636
Validation loss: 2.463893255915143

Epoch: 6| Step: 1
Training loss: 0.3405281935501544
Validation loss: 2.4646685626934888

Epoch: 6| Step: 2
Training loss: 0.22396617513427056
Validation loss: 2.4670402366475113

Epoch: 6| Step: 3
Training loss: 0.4477071956118895
Validation loss: 2.487437169924364

Epoch: 6| Step: 4
Training loss: 0.4350565386893803
Validation loss: 2.4847419275869838

Epoch: 6| Step: 5
Training loss: 0.453848819743487
Validation loss: 2.46957034916374

Epoch: 6| Step: 6
Training loss: 0.3056435867617724
Validation loss: 2.44381344542946

Epoch: 6| Step: 7
Training loss: 0.41992856397402367
Validation loss: 2.4190365706058863

Epoch: 6| Step: 8
Training loss: 0.3043156212846217
Validation loss: 2.4195294526026556

Epoch: 6| Step: 9
Training loss: 0.20090287009520316
Validation loss: 2.4253263166636705

Epoch: 6| Step: 10
Training loss: 0.2572288263984527
Validation loss: 2.3496569570522667

Epoch: 6| Step: 11
Training loss: 0.3549170562060988
Validation loss: 2.3713750274209042

Epoch: 6| Step: 12
Training loss: 0.31069292676656635
Validation loss: 2.3745007457059013

Epoch: 6| Step: 13
Training loss: 0.2862717743467087
Validation loss: 2.4137179614046214

Epoch: 321| Step: 0
Training loss: 0.43295023823167755
Validation loss: 2.4031103730928387

Epoch: 6| Step: 1
Training loss: 0.2489956933816314
Validation loss: 2.4317937860784578

Epoch: 6| Step: 2
Training loss: 0.20520129365190234
Validation loss: 2.447636826612334

Epoch: 6| Step: 3
Training loss: 0.44517501582622687
Validation loss: 2.4598684264655324

Epoch: 6| Step: 4
Training loss: 0.5230027856114384
Validation loss: 2.4664117818472806

Epoch: 6| Step: 5
Training loss: 0.30269764092830126
Validation loss: 2.4979022135861184

Epoch: 6| Step: 6
Training loss: 0.367045496813919
Validation loss: 2.4843108703628722

Epoch: 6| Step: 7
Training loss: 0.4554848224820506
Validation loss: 2.4864602192029475

Epoch: 6| Step: 8
Training loss: 0.24890826684837505
Validation loss: 2.46478396585791

Epoch: 6| Step: 9
Training loss: 0.36596915846782224
Validation loss: 2.4296398956781204

Epoch: 6| Step: 10
Training loss: 0.2786982864256713
Validation loss: 2.4332749250040484

Epoch: 6| Step: 11
Training loss: 0.18923550327642816
Validation loss: 2.383247826596548

Epoch: 6| Step: 12
Training loss: 0.22752076595238915
Validation loss: 2.417732827491507

Epoch: 6| Step: 13
Training loss: 0.14939222612571296
Validation loss: 2.418563310323093

Epoch: 322| Step: 0
Training loss: 0.22721777076756766
Validation loss: 2.3877861190389833

Epoch: 6| Step: 1
Training loss: 0.2226800236642046
Validation loss: 2.429750539088955

Epoch: 6| Step: 2
Training loss: 0.30415504342998695
Validation loss: 2.408782524411537

Epoch: 6| Step: 3
Training loss: 0.18808971492345175
Validation loss: 2.4370109282013805

Epoch: 6| Step: 4
Training loss: 0.5397639479219767
Validation loss: 2.447061083809115

Epoch: 6| Step: 5
Training loss: 0.5125975306680285
Validation loss: 2.4311841234181384

Epoch: 6| Step: 6
Training loss: 0.2711369191518106
Validation loss: 2.445086841510225

Epoch: 6| Step: 7
Training loss: 0.12997780101397224
Validation loss: 2.4555525412103525

Epoch: 6| Step: 8
Training loss: 0.41320930604716666
Validation loss: 2.48290163024722

Epoch: 6| Step: 9
Training loss: 0.23973940434028948
Validation loss: 2.4805474211102903

Epoch: 6| Step: 10
Training loss: 0.2974898847094474
Validation loss: 2.4780669309673935

Epoch: 6| Step: 11
Training loss: 0.2455689116738286
Validation loss: 2.491777520370575

Epoch: 6| Step: 12
Training loss: 0.1734040208670845
Validation loss: 2.461544472331698

Epoch: 6| Step: 13
Training loss: 0.34703829847904244
Validation loss: 2.4334376149147294

Epoch: 323| Step: 0
Training loss: 0.2561923183091356
Validation loss: 2.4249952563193022

Epoch: 6| Step: 1
Training loss: 0.3562483988274179
Validation loss: 2.401996692659941

Epoch: 6| Step: 2
Training loss: 0.37330043623658876
Validation loss: 2.41720970072501

Epoch: 6| Step: 3
Training loss: 0.2514795539775444
Validation loss: 2.367600999324096

Epoch: 6| Step: 4
Training loss: 0.23636874330633037
Validation loss: 2.375385501405588

Epoch: 6| Step: 5
Training loss: 0.3716473916676504
Validation loss: 2.362104570464455

Epoch: 6| Step: 6
Training loss: 0.3844866830729632
Validation loss: 2.3689681205095816

Epoch: 6| Step: 7
Training loss: 0.5511732667814833
Validation loss: 2.3993976158782333

Epoch: 6| Step: 8
Training loss: 0.445498477849704
Validation loss: 2.4006020431752995

Epoch: 6| Step: 9
Training loss: 0.14060536883340435
Validation loss: 2.3787677360252264

Epoch: 6| Step: 10
Training loss: 0.24811148365257882
Validation loss: 2.41309923434836

Epoch: 6| Step: 11
Training loss: 0.23037676672845356
Validation loss: 2.428921796787957

Epoch: 6| Step: 12
Training loss: 0.14959683178942107
Validation loss: 2.4195068414512453

Epoch: 6| Step: 13
Training loss: 0.11816678950418151
Validation loss: 2.398563354050517

Epoch: 324| Step: 0
Training loss: 0.3131298631682569
Validation loss: 2.4353090709565084

Epoch: 6| Step: 1
Training loss: 0.24785417295363313
Validation loss: 2.470914297771723

Epoch: 6| Step: 2
Training loss: 0.36644247237958055
Validation loss: 2.4931292008888293

Epoch: 6| Step: 3
Training loss: 0.2527284889773938
Validation loss: 2.499531530766766

Epoch: 6| Step: 4
Training loss: 0.30085879725755144
Validation loss: 2.4678138067894744

Epoch: 6| Step: 5
Training loss: 0.23619354766932327
Validation loss: 2.4639441875833916

Epoch: 6| Step: 6
Training loss: 0.4319497981903244
Validation loss: 2.455267719760054

Epoch: 6| Step: 7
Training loss: 0.283182051302072
Validation loss: 2.4692563791137463

Epoch: 6| Step: 8
Training loss: 0.30369910066849537
Validation loss: 2.420958040469987

Epoch: 6| Step: 9
Training loss: 0.3962147364283364
Validation loss: 2.425138057749168

Epoch: 6| Step: 10
Training loss: 0.215489284679352
Validation loss: 2.4018816994733854

Epoch: 6| Step: 11
Training loss: 0.3423665884453296
Validation loss: 2.365233786992641

Epoch: 6| Step: 12
Training loss: 0.31070653541847565
Validation loss: 2.4267557271543745

Epoch: 6| Step: 13
Training loss: 0.44230076784834427
Validation loss: 2.4078935439268094

Epoch: 325| Step: 0
Training loss: 0.352702876783157
Validation loss: 2.3635522450924364

Epoch: 6| Step: 1
Training loss: 0.31735725886837796
Validation loss: 2.386463809369082

Epoch: 6| Step: 2
Training loss: 0.22147913191575624
Validation loss: 2.4023304603169717

Epoch: 6| Step: 3
Training loss: 0.3409945853997647
Validation loss: 2.4002182559187

Epoch: 6| Step: 4
Training loss: 0.5591163058373603
Validation loss: 2.422214862107358

Epoch: 6| Step: 5
Training loss: 0.2651614463894915
Validation loss: 2.4212025270134307

Epoch: 6| Step: 6
Training loss: 0.18328819821090822
Validation loss: 2.42022461007983

Epoch: 6| Step: 7
Training loss: 0.31462761675701656
Validation loss: 2.462735803921097

Epoch: 6| Step: 8
Training loss: 0.16798566023404396
Validation loss: 2.4277170737506246

Epoch: 6| Step: 9
Training loss: 0.32797564785969896
Validation loss: 2.4664293048669337

Epoch: 6| Step: 10
Training loss: 0.1848042030465197
Validation loss: 2.426949360861922

Epoch: 6| Step: 11
Training loss: 0.3945902412048885
Validation loss: 2.422553648456269

Epoch: 6| Step: 12
Training loss: 0.2713299181544185
Validation loss: 2.4377912106029545

Epoch: 6| Step: 13
Training loss: 0.13478908472840917
Validation loss: 2.385066859591433

Epoch: 326| Step: 0
Training loss: 0.31825189004652976
Validation loss: 2.403894017641485

Epoch: 6| Step: 1
Training loss: 0.2198510813219296
Validation loss: 2.420119273650692

Epoch: 6| Step: 2
Training loss: 0.3122305900841804
Validation loss: 2.401934221965544

Epoch: 6| Step: 3
Training loss: 0.22664499425243295
Validation loss: 2.421119151226222

Epoch: 6| Step: 4
Training loss: 0.3185266394695512
Validation loss: 2.3859623110610735

Epoch: 6| Step: 5
Training loss: 0.2552679083180842
Validation loss: 2.4222938114609462

Epoch: 6| Step: 6
Training loss: 0.2186983081504938
Validation loss: 2.425170402229558

Epoch: 6| Step: 7
Training loss: 0.33015771617284023
Validation loss: 2.4172846551528555

Epoch: 6| Step: 8
Training loss: 0.3568955386810455
Validation loss: 2.4437090733467506

Epoch: 6| Step: 9
Training loss: 0.35509991636648564
Validation loss: 2.4345256436929295

Epoch: 6| Step: 10
Training loss: 0.14218382332837598
Validation loss: 2.4475265261851793

Epoch: 6| Step: 11
Training loss: 0.3050691219862363
Validation loss: 2.4505276023378335

Epoch: 6| Step: 12
Training loss: 0.21150427191672144
Validation loss: 2.4451818503688805

Epoch: 6| Step: 13
Training loss: 0.4558754350175343
Validation loss: 2.425842240002633

Epoch: 327| Step: 0
Training loss: 0.17567729525172093
Validation loss: 2.4280801090853497

Epoch: 6| Step: 1
Training loss: 0.14923195555807295
Validation loss: 2.4414458162116466

Epoch: 6| Step: 2
Training loss: 0.29491843922615835
Validation loss: 2.418928055429675

Epoch: 6| Step: 3
Training loss: 0.38093793009983284
Validation loss: 2.4391072006960712

Epoch: 6| Step: 4
Training loss: 0.2270127623526754
Validation loss: 2.4283754892181237

Epoch: 6| Step: 5
Training loss: 0.29496204026927575
Validation loss: 2.4095923611292815

Epoch: 6| Step: 6
Training loss: 0.12148415022703517
Validation loss: 2.4054116486781316

Epoch: 6| Step: 7
Training loss: 0.397067594729991
Validation loss: 2.396561004290462

Epoch: 6| Step: 8
Training loss: 0.36066530623872767
Validation loss: 2.4071193904258226

Epoch: 6| Step: 9
Training loss: 0.18904165436762377
Validation loss: 2.4401786800614307

Epoch: 6| Step: 10
Training loss: 0.33925889651356483
Validation loss: 2.401252576004089

Epoch: 6| Step: 11
Training loss: 0.2883808113962729
Validation loss: 2.413729221897791

Epoch: 6| Step: 12
Training loss: 0.3225455715450809
Validation loss: 2.367541513823264

Epoch: 6| Step: 13
Training loss: 0.29797835856139654
Validation loss: 2.4015280187598944

Epoch: 328| Step: 0
Training loss: 0.18171887096817568
Validation loss: 2.3737309637810133

Epoch: 6| Step: 1
Training loss: 0.1739658549437745
Validation loss: 2.3878676740588363

Epoch: 6| Step: 2
Training loss: 0.507639635447614
Validation loss: 2.413462384426659

Epoch: 6| Step: 3
Training loss: 0.37794867179562536
Validation loss: 2.426580431152932

Epoch: 6| Step: 4
Training loss: 0.31040351485653894
Validation loss: 2.410941411654537

Epoch: 6| Step: 5
Training loss: 0.18068607299344108
Validation loss: 2.396035134446963

Epoch: 6| Step: 6
Training loss: 0.34409888942137973
Validation loss: 2.437607297173863

Epoch: 6| Step: 7
Training loss: 0.3831467628832099
Validation loss: 2.406502958504782

Epoch: 6| Step: 8
Training loss: 0.2460793687766112
Validation loss: 2.423817413296625

Epoch: 6| Step: 9
Training loss: 0.33107880135995094
Validation loss: 2.3995966217264124

Epoch: 6| Step: 10
Training loss: 0.21003844139230055
Validation loss: 2.4186522048546855

Epoch: 6| Step: 11
Training loss: 0.1579706461874695
Validation loss: 2.4097259188364974

Epoch: 6| Step: 12
Training loss: 0.2437525143860465
Validation loss: 2.419868587104594

Epoch: 6| Step: 13
Training loss: 0.09528698266944935
Validation loss: 2.405318914402067

Epoch: 329| Step: 0
Training loss: 0.3654992881890605
Validation loss: 2.4026611251874477

Epoch: 6| Step: 1
Training loss: 0.2809887308291047
Validation loss: 2.3976355860793057

Epoch: 6| Step: 2
Training loss: 0.22200708957147264
Validation loss: 2.3963293187249533

Epoch: 6| Step: 3
Training loss: 0.18263808554141084
Validation loss: 2.4116669819305923

Epoch: 6| Step: 4
Training loss: 0.3905115725820957
Validation loss: 2.388035192272116

Epoch: 6| Step: 5
Training loss: 0.20725271687320124
Validation loss: 2.378923871752185

Epoch: 6| Step: 6
Training loss: 0.38548157978702763
Validation loss: 2.392645375501812

Epoch: 6| Step: 7
Training loss: 0.35460423571923216
Validation loss: 2.3938504858138283

Epoch: 6| Step: 8
Training loss: 0.19694715229800142
Validation loss: 2.4134292735768987

Epoch: 6| Step: 9
Training loss: 0.35359178428760923
Validation loss: 2.4058794903776763

Epoch: 6| Step: 10
Training loss: 0.22395383290640916
Validation loss: 2.420050417948547

Epoch: 6| Step: 11
Training loss: 0.3048223050550482
Validation loss: 2.4319268294870566

Epoch: 6| Step: 12
Training loss: 0.31170985942963825
Validation loss: 2.4347447983112978

Epoch: 6| Step: 13
Training loss: 0.3378756525327624
Validation loss: 2.4295703068459087

Epoch: 330| Step: 0
Training loss: 0.13974691799941724
Validation loss: 2.484340709538119

Epoch: 6| Step: 1
Training loss: 0.2565160143995028
Validation loss: 2.4528402896507293

Epoch: 6| Step: 2
Training loss: 0.38807853380656226
Validation loss: 2.444769321345842

Epoch: 6| Step: 3
Training loss: 0.1594618595670958
Validation loss: 2.418182986450272

Epoch: 6| Step: 4
Training loss: 0.433359993823641
Validation loss: 2.439880793115329

Epoch: 6| Step: 5
Training loss: 0.3086682603914554
Validation loss: 2.432365878176944

Epoch: 6| Step: 6
Training loss: 0.2052939777641625
Validation loss: 2.432963455291175

Epoch: 6| Step: 7
Training loss: 0.43964969900891626
Validation loss: 2.4015798177627197

Epoch: 6| Step: 8
Training loss: 0.17240414121630093
Validation loss: 2.4129086508738458

Epoch: 6| Step: 9
Training loss: 0.12013048393035419
Validation loss: 2.4073788110401724

Epoch: 6| Step: 10
Training loss: 0.24301486819555415
Validation loss: 2.392346974755514

Epoch: 6| Step: 11
Training loss: 0.3770093727641573
Validation loss: 2.405870648235262

Epoch: 6| Step: 12
Training loss: 0.23828086696656506
Validation loss: 2.381405523895745

Epoch: 6| Step: 13
Training loss: 0.33851562424287107
Validation loss: 2.44627801004612

Epoch: 331| Step: 0
Training loss: 0.30062017214857906
Validation loss: 2.4230559910829674

Epoch: 6| Step: 1
Training loss: 0.2260192161535842
Validation loss: 2.4437992850182217

Epoch: 6| Step: 2
Training loss: 0.18871564969382262
Validation loss: 2.4484557089570327

Epoch: 6| Step: 3
Training loss: 0.25271559089770135
Validation loss: 2.466823617065361

Epoch: 6| Step: 4
Training loss: 0.36037903967825047
Validation loss: 2.4871216951175636

Epoch: 6| Step: 5
Training loss: 0.2979857470820995
Validation loss: 2.504969633949676

Epoch: 6| Step: 6
Training loss: 0.3282491812278141
Validation loss: 2.526436323250712

Epoch: 6| Step: 7
Training loss: 0.20946737429488482
Validation loss: 2.4840179680063175

Epoch: 6| Step: 8
Training loss: 0.40890920070214737
Validation loss: 2.49660001510072

Epoch: 6| Step: 9
Training loss: 0.26456930237209325
Validation loss: 2.4599836322280924

Epoch: 6| Step: 10
Training loss: 0.22742731190731139
Validation loss: 2.464280944996585

Epoch: 6| Step: 11
Training loss: 0.39841257279154557
Validation loss: 2.4506382185640225

Epoch: 6| Step: 12
Training loss: 0.2835374371654392
Validation loss: 2.455382855305618

Epoch: 6| Step: 13
Training loss: 0.5172612497812723
Validation loss: 2.4232302776672383

Epoch: 332| Step: 0
Training loss: 0.31788352789635804
Validation loss: 2.4483880323386926

Epoch: 6| Step: 1
Training loss: 0.18361355289227727
Validation loss: 2.4047260719204786

Epoch: 6| Step: 2
Training loss: 0.23058984290784698
Validation loss: 2.377889383552316

Epoch: 6| Step: 3
Training loss: 0.20621272891856787
Validation loss: 2.384580226858893

Epoch: 6| Step: 4
Training loss: 0.26161439437803696
Validation loss: 2.3904924510777907

Epoch: 6| Step: 5
Training loss: 0.31487368069880045
Validation loss: 2.3584463107302014

Epoch: 6| Step: 6
Training loss: 0.23767201129983906
Validation loss: 2.37476769905023

Epoch: 6| Step: 7
Training loss: 0.25420101368842307
Validation loss: 2.3328774240467127

Epoch: 6| Step: 8
Training loss: 0.48183773366703875
Validation loss: 2.370065559715141

Epoch: 6| Step: 9
Training loss: 0.1950164745016754
Validation loss: 2.4062377903807914

Epoch: 6| Step: 10
Training loss: 0.3446555672394183
Validation loss: 2.423372660508198

Epoch: 6| Step: 11
Training loss: 0.166141114770818
Validation loss: 2.4055333630515294

Epoch: 6| Step: 12
Training loss: 0.3528756096537692
Validation loss: 2.442752707898889

Epoch: 6| Step: 13
Training loss: 0.4491990789999314
Validation loss: 2.44400682016986

Epoch: 333| Step: 0
Training loss: 0.2567884161901942
Validation loss: 2.419149012509586

Epoch: 6| Step: 1
Training loss: 0.16571411353568297
Validation loss: 2.4100237094089207

Epoch: 6| Step: 2
Training loss: 0.2025683735870134
Validation loss: 2.4212430247850536

Epoch: 6| Step: 3
Training loss: 0.1689916558180829
Validation loss: 2.4150794513221876

Epoch: 6| Step: 4
Training loss: 0.26369820922457604
Validation loss: 2.449803665561625

Epoch: 6| Step: 5
Training loss: 0.3464117599826829
Validation loss: 2.450921170138698

Epoch: 6| Step: 6
Training loss: 0.2238526076263579
Validation loss: 2.41856037522307

Epoch: 6| Step: 7
Training loss: 0.19835289555799993
Validation loss: 2.408396485452293

Epoch: 6| Step: 8
Training loss: 0.3089724281595993
Validation loss: 2.409836979491042

Epoch: 6| Step: 9
Training loss: 0.14770535555726785
Validation loss: 2.4392555168799848

Epoch: 6| Step: 10
Training loss: 0.38616277243698094
Validation loss: 2.4180671419669792

Epoch: 6| Step: 11
Training loss: 0.42742333795586135
Validation loss: 2.4003888499671087

Epoch: 6| Step: 12
Training loss: 0.44797655932375774
Validation loss: 2.4001452446897558

Epoch: 6| Step: 13
Training loss: 0.2753464683681675
Validation loss: 2.435051761039235

Epoch: 334| Step: 0
Training loss: 0.22577555230155183
Validation loss: 2.439187005883827

Epoch: 6| Step: 1
Training loss: 0.2227119409615696
Validation loss: 2.4612691874185244

Epoch: 6| Step: 2
Training loss: 0.2782058748250208
Validation loss: 2.4392640729995323

Epoch: 6| Step: 3
Training loss: 0.1526667581824569
Validation loss: 2.4290885892763847

Epoch: 6| Step: 4
Training loss: 0.24112385556289065
Validation loss: 2.4166472624811965

Epoch: 6| Step: 5
Training loss: 0.14027163693221317
Validation loss: 2.4139906190261264

Epoch: 6| Step: 6
Training loss: 0.29070304878805914
Validation loss: 2.4606189433708767

Epoch: 6| Step: 7
Training loss: 0.33349436233093394
Validation loss: 2.4430313937481345

Epoch: 6| Step: 8
Training loss: 0.44716289956426325
Validation loss: 2.439799545863944

Epoch: 6| Step: 9
Training loss: 0.2181252174321706
Validation loss: 2.45809176950863

Epoch: 6| Step: 10
Training loss: 0.2193673907017199
Validation loss: 2.45465218430149

Epoch: 6| Step: 11
Training loss: 0.33795894086538053
Validation loss: 2.4119895304460455

Epoch: 6| Step: 12
Training loss: 0.32540959810076636
Validation loss: 2.4397941071307736

Epoch: 6| Step: 13
Training loss: 0.2718484618948019
Validation loss: 2.4281370522511474

Epoch: 335| Step: 0
Training loss: 0.3378396960558564
Validation loss: 2.409197880047807

Epoch: 6| Step: 1
Training loss: 0.19512197738740328
Validation loss: 2.397815032079783

Epoch: 6| Step: 2
Training loss: 0.24152514421778343
Validation loss: 2.37860378792426

Epoch: 6| Step: 3
Training loss: 0.2502577466289712
Validation loss: 2.406629062941476

Epoch: 6| Step: 4
Training loss: 0.2513466270118015
Validation loss: 2.4397840208545363

Epoch: 6| Step: 5
Training loss: 0.3274499557020653
Validation loss: 2.4106325353136664

Epoch: 6| Step: 6
Training loss: 0.176790076414597
Validation loss: 2.421427997431418

Epoch: 6| Step: 7
Training loss: 0.19596052431506253
Validation loss: 2.4516880573242363

Epoch: 6| Step: 8
Training loss: 0.2755106400669632
Validation loss: 2.439850690482951

Epoch: 6| Step: 9
Training loss: 0.20287661771781546
Validation loss: 2.4492289790274375

Epoch: 6| Step: 10
Training loss: 0.30466601711733654
Validation loss: 2.460202696403242

Epoch: 6| Step: 11
Training loss: 0.08626612231838962
Validation loss: 2.437155249831551

Epoch: 6| Step: 12
Training loss: 0.35082445027317755
Validation loss: 2.433898932981585

Epoch: 6| Step: 13
Training loss: 0.5881600253776129
Validation loss: 2.4066347406708273

Epoch: 336| Step: 0
Training loss: 0.19406511615212182
Validation loss: 2.4019223234146465

Epoch: 6| Step: 1
Training loss: 0.274218615235733
Validation loss: 2.406396129205184

Epoch: 6| Step: 2
Training loss: 0.22022922240552978
Validation loss: 2.420063789879189

Epoch: 6| Step: 3
Training loss: 0.21061743189235313
Validation loss: 2.3774964974770736

Epoch: 6| Step: 4
Training loss: 0.2515000846390553
Validation loss: 2.390176506741585

Epoch: 6| Step: 5
Training loss: 0.33878303384359626
Validation loss: 2.365634331378838

Epoch: 6| Step: 6
Training loss: 0.2656325591638603
Validation loss: 2.391545706011828

Epoch: 6| Step: 7
Training loss: 0.33483993524540284
Validation loss: 2.4137356795045815

Epoch: 6| Step: 8
Training loss: 0.5063074550285493
Validation loss: 2.3848935732454897

Epoch: 6| Step: 9
Training loss: 0.1408256781054511
Validation loss: 2.4234306777271284

Epoch: 6| Step: 10
Training loss: 0.18832191487176383
Validation loss: 2.3983227904551656

Epoch: 6| Step: 11
Training loss: 0.3036721992932574
Validation loss: 2.3990925246523287

Epoch: 6| Step: 12
Training loss: 0.24467936773902596
Validation loss: 2.4053045305648815

Epoch: 6| Step: 13
Training loss: 0.20258845478382936
Validation loss: 2.401409583749256

Epoch: 337| Step: 0
Training loss: 0.26452211412673193
Validation loss: 2.3870894800012077

Epoch: 6| Step: 1
Training loss: 0.2481280667045814
Validation loss: 2.3893187072740076

Epoch: 6| Step: 2
Training loss: 0.26042693435772307
Validation loss: 2.4068513472273683

Epoch: 6| Step: 3
Training loss: 0.18890805832823218
Validation loss: 2.3992487663132325

Epoch: 6| Step: 4
Training loss: 0.3101583966005544
Validation loss: 2.3825100087264195

Epoch: 6| Step: 5
Training loss: 0.1943286913570363
Validation loss: 2.3698723149270946

Epoch: 6| Step: 6
Training loss: 0.28705892314214826
Validation loss: 2.4102574104494776

Epoch: 6| Step: 7
Training loss: 0.5129799189122904
Validation loss: 2.3902492904896877

Epoch: 6| Step: 8
Training loss: 0.32089252988888234
Validation loss: 2.4067435044179337

Epoch: 6| Step: 9
Training loss: 0.13403647580346478
Validation loss: 2.416469824443715

Epoch: 6| Step: 10
Training loss: 0.17454358532002734
Validation loss: 2.390962957914184

Epoch: 6| Step: 11
Training loss: 0.3536940277287262
Validation loss: 2.424467418235928

Epoch: 6| Step: 12
Training loss: 0.18724959262273908
Validation loss: 2.4735668487036295

Epoch: 6| Step: 13
Training loss: 0.311234474694978
Validation loss: 2.4917288166619023

Epoch: 338| Step: 0
Training loss: 0.412096122781731
Validation loss: 2.454663214715456

Epoch: 6| Step: 1
Training loss: 0.16245266174422066
Validation loss: 2.444300416191086

Epoch: 6| Step: 2
Training loss: 0.3777678978767944
Validation loss: 2.467581367872027

Epoch: 6| Step: 3
Training loss: 0.20739131781431375
Validation loss: 2.4578782095343823

Epoch: 6| Step: 4
Training loss: 0.17199582491356802
Validation loss: 2.4326359408860645

Epoch: 6| Step: 5
Training loss: 0.30437925837081725
Validation loss: 2.4514403072632307

Epoch: 6| Step: 6
Training loss: 0.23108105222883252
Validation loss: 2.453896455496156

Epoch: 6| Step: 7
Training loss: 0.20858634049760894
Validation loss: 2.4122506357244524

Epoch: 6| Step: 8
Training loss: 0.2166449899711766
Validation loss: 2.400821488755741

Epoch: 6| Step: 9
Training loss: 0.38661350397926053
Validation loss: 2.3889248742427225

Epoch: 6| Step: 10
Training loss: 0.3699424552630719
Validation loss: 2.40402518141661

Epoch: 6| Step: 11
Training loss: 0.27665302066777525
Validation loss: 2.3809678405305235

Epoch: 6| Step: 12
Training loss: 0.1683894477945384
Validation loss: 2.40654460806529

Epoch: 6| Step: 13
Training loss: 0.20248900395431874
Validation loss: 2.353601627636226

Epoch: 339| Step: 0
Training loss: 0.24796405671214625
Validation loss: 2.416337281107621

Epoch: 6| Step: 1
Training loss: 0.27614870635190164
Validation loss: 2.3680906692429358

Epoch: 6| Step: 2
Training loss: 0.3240275796047211
Validation loss: 2.394087822133572

Epoch: 6| Step: 3
Training loss: 0.2964799033771392
Validation loss: 2.404815275933211

Epoch: 6| Step: 4
Training loss: 0.2736020819039636
Validation loss: 2.431803732077273

Epoch: 6| Step: 5
Training loss: 0.27505201801418944
Validation loss: 2.4553186116087184

Epoch: 6| Step: 6
Training loss: 0.36358767066269854
Validation loss: 2.4354730970828524

Epoch: 6| Step: 7
Training loss: 0.21818971406266216
Validation loss: 2.454065879594777

Epoch: 6| Step: 8
Training loss: 0.2901246429467459
Validation loss: 2.4532256593333575

Epoch: 6| Step: 9
Training loss: 0.10946832660208759
Validation loss: 2.395427823269108

Epoch: 6| Step: 10
Training loss: 0.3930734764079298
Validation loss: 2.406396500477678

Epoch: 6| Step: 11
Training loss: 0.26345748662644125
Validation loss: 2.3837367435426584

Epoch: 6| Step: 12
Training loss: 0.2514318203769391
Validation loss: 2.387546559082605

Epoch: 6| Step: 13
Training loss: 0.3686647122562977
Validation loss: 2.384100132141082

Epoch: 340| Step: 0
Training loss: 0.15745802244243362
Validation loss: 2.376910385823576

Epoch: 6| Step: 1
Training loss: 0.2506955127980958
Validation loss: 2.439684877022983

Epoch: 6| Step: 2
Training loss: 0.15157643898054846
Validation loss: 2.4337505260515226

Epoch: 6| Step: 3
Training loss: 0.27858135630135916
Validation loss: 2.450832192374665

Epoch: 6| Step: 4
Training loss: 0.36675517014731807
Validation loss: 2.4340424838390398

Epoch: 6| Step: 5
Training loss: 0.35045085631706907
Validation loss: 2.485994873366567

Epoch: 6| Step: 6
Training loss: 0.38136295380723984
Validation loss: 2.4636249765327243

Epoch: 6| Step: 7
Training loss: 0.32768183254046174
Validation loss: 2.442085237193588

Epoch: 6| Step: 8
Training loss: 0.28175811433319803
Validation loss: 2.4218724912695935

Epoch: 6| Step: 9
Training loss: 0.3526754142005972
Validation loss: 2.4166516097394988

Epoch: 6| Step: 10
Training loss: 0.16711597985104187
Validation loss: 2.424424573448596

Epoch: 6| Step: 11
Training loss: 0.35479817701240174
Validation loss: 2.3867717726490363

Epoch: 6| Step: 12
Training loss: 0.2821127322094126
Validation loss: 2.401172582496981

Epoch: 6| Step: 13
Training loss: 0.29631040241035694
Validation loss: 2.4163760589364034

Epoch: 341| Step: 0
Training loss: 0.3089972887583799
Validation loss: 2.369956226893944

Epoch: 6| Step: 1
Training loss: 0.41392819007680587
Validation loss: 2.3616293752976296

Epoch: 6| Step: 2
Training loss: 0.43147600927329355
Validation loss: 2.3494491617314615

Epoch: 6| Step: 3
Training loss: 0.22052453841777464
Validation loss: 2.405199069913047

Epoch: 6| Step: 4
Training loss: 0.31556042303292214
Validation loss: 2.3961454946954235

Epoch: 6| Step: 5
Training loss: 0.347991492406534
Validation loss: 2.3654342456768536

Epoch: 6| Step: 6
Training loss: 0.24493796038699947
Validation loss: 2.4046578346295804

Epoch: 6| Step: 7
Training loss: 0.20866334625661662
Validation loss: 2.4216080845657926

Epoch: 6| Step: 8
Training loss: 0.25655667457518483
Validation loss: 2.431650927444762

Epoch: 6| Step: 9
Training loss: 0.2763087881546917
Validation loss: 2.427678698835352

Epoch: 6| Step: 10
Training loss: 0.2795895197070686
Validation loss: 2.434659534986977

Epoch: 6| Step: 11
Training loss: 0.15749286820901193
Validation loss: 2.4354047075822542

Epoch: 6| Step: 12
Training loss: 0.30203200046625656
Validation loss: 2.48040394522746

Epoch: 6| Step: 13
Training loss: 0.2881995413545259
Validation loss: 2.436782678777899

Epoch: 342| Step: 0
Training loss: 0.266335560769537
Validation loss: 2.4311461955027855

Epoch: 6| Step: 1
Training loss: 0.27248952572054413
Validation loss: 2.4680554111310697

Epoch: 6| Step: 2
Training loss: 0.421526128841459
Validation loss: 2.4155976926646168

Epoch: 6| Step: 3
Training loss: 0.33865028497325445
Validation loss: 2.4105255864567585

Epoch: 6| Step: 4
Training loss: 0.2532885594051623
Validation loss: 2.4129999343584916

Epoch: 6| Step: 5
Training loss: 0.3277687113874317
Validation loss: 2.4048762070795524

Epoch: 6| Step: 6
Training loss: 0.34096727235977514
Validation loss: 2.4155161972407435

Epoch: 6| Step: 7
Training loss: 0.18052226507547664
Validation loss: 2.4095808759639645

Epoch: 6| Step: 8
Training loss: 0.1995657255370227
Validation loss: 2.4227014672292917

Epoch: 6| Step: 9
Training loss: 0.1880744538411196
Validation loss: 2.3976640580872

Epoch: 6| Step: 10
Training loss: 0.3209843683610934
Validation loss: 2.4036063555875415

Epoch: 6| Step: 11
Training loss: 0.22651981905411872
Validation loss: 2.4375259002580014

Epoch: 6| Step: 12
Training loss: 0.35366430370129864
Validation loss: 2.408871861298327

Epoch: 6| Step: 13
Training loss: 0.44875243489128186
Validation loss: 2.4392052775802995

Epoch: 343| Step: 0
Training loss: 0.24651811734525922
Validation loss: 2.4182527455416545

Epoch: 6| Step: 1
Training loss: 0.19517312799225145
Validation loss: 2.358489769837765

Epoch: 6| Step: 2
Training loss: 0.2525492867438003
Validation loss: 2.3534051725489396

Epoch: 6| Step: 3
Training loss: 0.3041286845965909
Validation loss: 2.3787118093513526

Epoch: 6| Step: 4
Training loss: 0.2831780521211838
Validation loss: 2.3621345565956453

Epoch: 6| Step: 5
Training loss: 0.31276056632176785
Validation loss: 2.3681841495509017

Epoch: 6| Step: 6
Training loss: 0.2570738035416243
Validation loss: 2.3719502704399935

Epoch: 6| Step: 7
Training loss: 0.44107769241319905
Validation loss: 2.386000454377371

Epoch: 6| Step: 8
Training loss: 0.13905855451837432
Validation loss: 2.4176824900787905

Epoch: 6| Step: 9
Training loss: 0.26911891966000495
Validation loss: 2.4306257467687185

Epoch: 6| Step: 10
Training loss: 0.20859887763303878
Validation loss: 2.4430035795481806

Epoch: 6| Step: 11
Training loss: 0.44575886356957184
Validation loss: 2.44658065150917

Epoch: 6| Step: 12
Training loss: 0.23766469139140559
Validation loss: 2.457536396840374

Epoch: 6| Step: 13
Training loss: 0.14090852500904671
Validation loss: 2.454366232646828

Epoch: 344| Step: 0
Training loss: 0.36065512176011955
Validation loss: 2.448840638003671

Epoch: 6| Step: 1
Training loss: 0.368689084274838
Validation loss: 2.455095216726504

Epoch: 6| Step: 2
Training loss: 0.26844965875020954
Validation loss: 2.4412866349645967

Epoch: 6| Step: 3
Training loss: 0.1999820224311533
Validation loss: 2.4429260736888354

Epoch: 6| Step: 4
Training loss: 0.2663123270073172
Validation loss: 2.4169580038584106

Epoch: 6| Step: 5
Training loss: 0.17538211861353817
Validation loss: 2.43668056688883

Epoch: 6| Step: 6
Training loss: 0.3050928598281735
Validation loss: 2.382383718228202

Epoch: 6| Step: 7
Training loss: 0.3171143203090354
Validation loss: 2.4234900787860014

Epoch: 6| Step: 8
Training loss: 0.29846173931967024
Validation loss: 2.4249272584973363

Epoch: 6| Step: 9
Training loss: 0.1625793492547446
Validation loss: 2.420594847275955

Epoch: 6| Step: 10
Training loss: 0.30073844307806663
Validation loss: 2.4377423937111193

Epoch: 6| Step: 11
Training loss: 0.16258102767274216
Validation loss: 2.467175400173618

Epoch: 6| Step: 12
Training loss: 0.19207671546775718
Validation loss: 2.4371333923287746

Epoch: 6| Step: 13
Training loss: 0.2771377201172187
Validation loss: 2.4448767252164822

Epoch: 345| Step: 0
Training loss: 0.1698356387667742
Validation loss: 2.4505739812501477

Epoch: 6| Step: 1
Training loss: 0.3085580636165874
Validation loss: 2.4660796945679087

Epoch: 6| Step: 2
Training loss: 0.2556034584575566
Validation loss: 2.45869780734741

Epoch: 6| Step: 3
Training loss: 0.2244845914443369
Validation loss: 2.4869502717830554

Epoch: 6| Step: 4
Training loss: 0.22369513830044194
Validation loss: 2.479892541377961

Epoch: 6| Step: 5
Training loss: 0.30741686883555924
Validation loss: 2.403233605721996

Epoch: 6| Step: 6
Training loss: 0.18980524433978344
Validation loss: 2.461111848732718

Epoch: 6| Step: 7
Training loss: 0.41572209421576406
Validation loss: 2.4296111399641607

Epoch: 6| Step: 8
Training loss: 0.3161928611145537
Validation loss: 2.40984127999274

Epoch: 6| Step: 9
Training loss: 0.21481706280117469
Validation loss: 2.39853534216332

Epoch: 6| Step: 10
Training loss: 0.2371779680409955
Validation loss: 2.41841095707197

Epoch: 6| Step: 11
Training loss: 0.2783376855614641
Validation loss: 2.3919543648468866

Epoch: 6| Step: 12
Training loss: 0.2535366302393316
Validation loss: 2.4014869542007786

Epoch: 6| Step: 13
Training loss: 0.27811212617032127
Validation loss: 2.355691072844859

Epoch: 346| Step: 0
Training loss: 0.2327662089109347
Validation loss: 2.388682316888816

Epoch: 6| Step: 1
Training loss: 0.1287476908259112
Validation loss: 2.3975126955237127

Epoch: 6| Step: 2
Training loss: 0.1249112991689663
Validation loss: 2.437746516946432

Epoch: 6| Step: 3
Training loss: 0.30830024088442753
Validation loss: 2.427855007237673

Epoch: 6| Step: 4
Training loss: 0.2471120897036034
Validation loss: 2.441926813621592

Epoch: 6| Step: 5
Training loss: 0.379431468682571
Validation loss: 2.4221262658248426

Epoch: 6| Step: 6
Training loss: 0.3328494817039508
Validation loss: 2.451469862612658

Epoch: 6| Step: 7
Training loss: 0.2443216644436091
Validation loss: 2.43384774913923

Epoch: 6| Step: 8
Training loss: 0.3036826632668599
Validation loss: 2.4105492889962625

Epoch: 6| Step: 9
Training loss: 0.3092527355043809
Validation loss: 2.393949624886615

Epoch: 6| Step: 10
Training loss: 0.2992217643924596
Validation loss: 2.411925837951584

Epoch: 6| Step: 11
Training loss: 0.1946417544459934
Validation loss: 2.3982788428412443

Epoch: 6| Step: 12
Training loss: 0.22288108650172211
Validation loss: 2.3975604587081496

Epoch: 6| Step: 13
Training loss: 0.2493007985245333
Validation loss: 2.3596741860757366

Epoch: 347| Step: 0
Training loss: 0.2902873867493808
Validation loss: 2.406387623480479

Epoch: 6| Step: 1
Training loss: 0.1262613079936635
Validation loss: 2.424783302277485

Epoch: 6| Step: 2
Training loss: 0.20086555863146144
Validation loss: 2.4332509138831715

Epoch: 6| Step: 3
Training loss: 0.20673546264341572
Validation loss: 2.4138251240785777

Epoch: 6| Step: 4
Training loss: 0.4702863153664822
Validation loss: 2.4672713071900234

Epoch: 6| Step: 5
Training loss: 0.23961567487665536
Validation loss: 2.4620241484013157

Epoch: 6| Step: 6
Training loss: 0.20939373316869375
Validation loss: 2.450843591968141

Epoch: 6| Step: 7
Training loss: 0.29173785714586453
Validation loss: 2.4518448547755383

Epoch: 6| Step: 8
Training loss: 0.2825071794306527
Validation loss: 2.4511191326108737

Epoch: 6| Step: 9
Training loss: 0.3299617788006713
Validation loss: 2.468731995518615

Epoch: 6| Step: 10
Training loss: 0.21232075494434563
Validation loss: 2.4332929431981167

Epoch: 6| Step: 11
Training loss: 0.2098676873654741
Validation loss: 2.4326030920668935

Epoch: 6| Step: 12
Training loss: 0.36572785112793926
Validation loss: 2.4446378289105883

Epoch: 6| Step: 13
Training loss: 0.30502270330682635
Validation loss: 2.4208116240517534

Epoch: 348| Step: 0
Training loss: 0.09553385381485005
Validation loss: 2.411208365969494

Epoch: 6| Step: 1
Training loss: 0.42353548767203536
Validation loss: 2.4204118599341875

Epoch: 6| Step: 2
Training loss: 0.21963241255468713
Validation loss: 2.4078545677369387

Epoch: 6| Step: 3
Training loss: 0.22460727690670468
Validation loss: 2.443841130299151

Epoch: 6| Step: 4
Training loss: 0.30917526935979917
Validation loss: 2.4285097190615175

Epoch: 6| Step: 5
Training loss: 0.2514774208256851
Validation loss: 2.449052943256016

Epoch: 6| Step: 6
Training loss: 0.2677956692226496
Validation loss: 2.4277886528570094

Epoch: 6| Step: 7
Training loss: 0.3131724275621133
Validation loss: 2.4430695301318264

Epoch: 6| Step: 8
Training loss: 0.21124626449803505
Validation loss: 2.4553247343049227

Epoch: 6| Step: 9
Training loss: 0.1947820134924435
Validation loss: 2.4509450478970143

Epoch: 6| Step: 10
Training loss: 0.3861088229625393
Validation loss: 2.460895456325082

Epoch: 6| Step: 11
Training loss: 0.3046866319106036
Validation loss: 2.4097601680997593

Epoch: 6| Step: 12
Training loss: 0.24256096009785674
Validation loss: 2.435931693808463

Epoch: 6| Step: 13
Training loss: 0.19327489375253504
Validation loss: 2.458769679950502

Epoch: 349| Step: 0
Training loss: 0.33569881920275885
Validation loss: 2.437888814638712

Epoch: 6| Step: 1
Training loss: 0.3593725121453458
Validation loss: 2.4222362951423557

Epoch: 6| Step: 2
Training loss: 0.29299456164777915
Validation loss: 2.3973034457713833

Epoch: 6| Step: 3
Training loss: 0.27440210228102846
Validation loss: 2.441878418512959

Epoch: 6| Step: 4
Training loss: 0.19077407800001486
Validation loss: 2.4342882011603426

Epoch: 6| Step: 5
Training loss: 0.23766115675105062
Validation loss: 2.4580347722122666

Epoch: 6| Step: 6
Training loss: 0.3786740722340656
Validation loss: 2.454364899835817

Epoch: 6| Step: 7
Training loss: 0.3493375094093772
Validation loss: 2.461718162607132

Epoch: 6| Step: 8
Training loss: 0.23281499330094402
Validation loss: 2.489741870515747

Epoch: 6| Step: 9
Training loss: 0.43717498286926687
Validation loss: 2.487706141928248

Epoch: 6| Step: 10
Training loss: 0.28585134990694344
Validation loss: 2.4829988285570885

Epoch: 6| Step: 11
Training loss: 0.3524314420226442
Validation loss: 2.477028659983842

Epoch: 6| Step: 12
Training loss: 0.25589913503370976
Validation loss: 2.4315177229140956

Epoch: 6| Step: 13
Training loss: 0.3738736482683168
Validation loss: 2.4402576798839175

Epoch: 350| Step: 0
Training loss: 0.25687477775434175
Validation loss: 2.434502243037387

Epoch: 6| Step: 1
Training loss: 0.3344493774332419
Validation loss: 2.3872779032908085

Epoch: 6| Step: 2
Training loss: 0.29394125697991363
Validation loss: 2.417715242599401

Epoch: 6| Step: 3
Training loss: 0.23496999715206962
Validation loss: 2.446744436987457

Epoch: 6| Step: 4
Training loss: 0.32439366184053575
Validation loss: 2.445939658600211

Epoch: 6| Step: 5
Training loss: 0.16581873157228363
Validation loss: 2.4607651016783048

Epoch: 6| Step: 6
Training loss: 0.23241860523648672
Validation loss: 2.44395571479789

Epoch: 6| Step: 7
Training loss: 0.23004133386927003
Validation loss: 2.449790143067481

Epoch: 6| Step: 8
Training loss: 0.3258470070978788
Validation loss: 2.457018608260158

Epoch: 6| Step: 9
Training loss: 0.24377743982262468
Validation loss: 2.4297957688860587

Epoch: 6| Step: 10
Training loss: 0.3089073374472943
Validation loss: 2.4214394592249806

Epoch: 6| Step: 11
Training loss: 0.3531344133995981
Validation loss: 2.387849988938673

Epoch: 6| Step: 12
Training loss: 0.27110244451206594
Validation loss: 2.383756320267727

Epoch: 6| Step: 13
Training loss: 0.26226026111943673
Validation loss: 2.356842321303001

Epoch: 351| Step: 0
Training loss: 0.22077036145702114
Validation loss: 2.3708880886840675

Epoch: 6| Step: 1
Training loss: 0.37608177397376724
Validation loss: 2.362242823232959

Epoch: 6| Step: 2
Training loss: 0.26597504831466573
Validation loss: 2.3590079260171333

Epoch: 6| Step: 3
Training loss: 0.19535083394562158
Validation loss: 2.399963500572546

Epoch: 6| Step: 4
Training loss: 0.1615077655758769
Validation loss: 2.4311581714156447

Epoch: 6| Step: 5
Training loss: 0.21960393238685424
Validation loss: 2.398341871859519

Epoch: 6| Step: 6
Training loss: 0.31373602091282793
Validation loss: 2.4661891974288337

Epoch: 6| Step: 7
Training loss: 0.2828351622927719
Validation loss: 2.4889992746086036

Epoch: 6| Step: 8
Training loss: 0.3892619192592963
Validation loss: 2.495847107593511

Epoch: 6| Step: 9
Training loss: 0.1322479168821592
Validation loss: 2.48504158896409

Epoch: 6| Step: 10
Training loss: 0.3887037139580205
Validation loss: 2.510886664585268

Epoch: 6| Step: 11
Training loss: 0.2997160914230285
Validation loss: 2.4498832596554325

Epoch: 6| Step: 12
Training loss: 0.36132136158154843
Validation loss: 2.4614416400049883

Epoch: 6| Step: 13
Training loss: 0.23471424664039825
Validation loss: 2.4138539324361443

Epoch: 352| Step: 0
Training loss: 0.2678771888520658
Validation loss: 2.4108061010183377

Epoch: 6| Step: 1
Training loss: 0.46962032583945
Validation loss: 2.4118635787302076

Epoch: 6| Step: 2
Training loss: 0.30918994484114687
Validation loss: 2.4054901455889857

Epoch: 6| Step: 3
Training loss: 0.22028241527031073
Validation loss: 2.4126938818010735

Epoch: 6| Step: 4
Training loss: 0.2616807141350075
Validation loss: 2.4155429201211693

Epoch: 6| Step: 5
Training loss: 0.2966439703410373
Validation loss: 2.450246467691133

Epoch: 6| Step: 6
Training loss: 0.20694413241544948
Validation loss: 2.4316937329394785

Epoch: 6| Step: 7
Training loss: 0.27655874562274474
Validation loss: 2.455138681678952

Epoch: 6| Step: 8
Training loss: 0.3688237884208365
Validation loss: 2.4478245375940264

Epoch: 6| Step: 9
Training loss: 0.2679757831862762
Validation loss: 2.457000764577827

Epoch: 6| Step: 10
Training loss: 0.3569649240334994
Validation loss: 2.449644614037408

Epoch: 6| Step: 11
Training loss: 0.23945648352801996
Validation loss: 2.425688847398915

Epoch: 6| Step: 12
Training loss: 0.21660456848810491
Validation loss: 2.4014088460675365

Epoch: 6| Step: 13
Training loss: 0.22555461682628408
Validation loss: 2.4211125211279843

Epoch: 353| Step: 0
Training loss: 0.28567043089213434
Validation loss: 2.4239147042869678

Epoch: 6| Step: 1
Training loss: 0.19666307790224333
Validation loss: 2.374177564199032

Epoch: 6| Step: 2
Training loss: 0.30365676642092615
Validation loss: 2.3821845136396456

Epoch: 6| Step: 3
Training loss: 0.17943315541845106
Validation loss: 2.4220811029093148

Epoch: 6| Step: 4
Training loss: 0.23937742396389833
Validation loss: 2.401496479148715

Epoch: 6| Step: 5
Training loss: 0.3607781838889369
Validation loss: 2.4671048359981183

Epoch: 6| Step: 6
Training loss: 0.31311118439978175
Validation loss: 2.4694334854295046

Epoch: 6| Step: 7
Training loss: 0.3968993397255247
Validation loss: 2.51552218833014

Epoch: 6| Step: 8
Training loss: 0.25148158341772553
Validation loss: 2.5229900327457515

Epoch: 6| Step: 9
Training loss: 0.41181298757232737
Validation loss: 2.540568349623131

Epoch: 6| Step: 10
Training loss: 0.4251581059211731
Validation loss: 2.543236336717251

Epoch: 6| Step: 11
Training loss: 0.432000816887507
Validation loss: 2.5475180618277173

Epoch: 6| Step: 12
Training loss: 0.2124458093126401
Validation loss: 2.5354745953414817

Epoch: 6| Step: 13
Training loss: 0.4408531099016587
Validation loss: 2.481266833915421

Epoch: 354| Step: 0
Training loss: 0.36698705193548664
Validation loss: 2.5064565413328617

Epoch: 6| Step: 1
Training loss: 0.22942063859828415
Validation loss: 2.4815305086388757

Epoch: 6| Step: 2
Training loss: 0.31181343476229334
Validation loss: 2.45963829059164

Epoch: 6| Step: 3
Training loss: 0.22687561497460448
Validation loss: 2.4209346622178094

Epoch: 6| Step: 4
Training loss: 0.44190383817029266
Validation loss: 2.4246842598168037

Epoch: 6| Step: 5
Training loss: 0.5394233104248148
Validation loss: 2.435217402550445

Epoch: 6| Step: 6
Training loss: 0.3568425930093632
Validation loss: 2.402517300418071

Epoch: 6| Step: 7
Training loss: 0.39853364121126433
Validation loss: 2.377983171327691

Epoch: 6| Step: 8
Training loss: 0.209785050641708
Validation loss: 2.3681932834166752

Epoch: 6| Step: 9
Training loss: 0.4153589788395609
Validation loss: 2.3770721681034663

Epoch: 6| Step: 10
Training loss: 0.2691053536256446
Validation loss: 2.3955900693842653

Epoch: 6| Step: 11
Training loss: 0.2710269532374942
Validation loss: 2.409232748935473

Epoch: 6| Step: 12
Training loss: 0.32188443845965653
Validation loss: 2.4003348347253843

Epoch: 6| Step: 13
Training loss: 0.31733308842760405
Validation loss: 2.3685584240807147

Epoch: 355| Step: 0
Training loss: 0.35098934076024113
Validation loss: 2.3874624100856927

Epoch: 6| Step: 1
Training loss: 0.36459286086939485
Validation loss: 2.397601446703308

Epoch: 6| Step: 2
Training loss: 0.21251685903092882
Validation loss: 2.3967461062184388

Epoch: 6| Step: 3
Training loss: 0.3143486299508578
Validation loss: 2.405155588763866

Epoch: 6| Step: 4
Training loss: 0.3005525165144399
Validation loss: 2.3699076418042906

Epoch: 6| Step: 5
Training loss: 0.21093252847252356
Validation loss: 2.3944940969465547

Epoch: 6| Step: 6
Training loss: 0.2999010086650937
Validation loss: 2.393209723490771

Epoch: 6| Step: 7
Training loss: 0.2639227486032986
Validation loss: 2.418916572197606

Epoch: 6| Step: 8
Training loss: 0.3678676109868092
Validation loss: 2.3592409452903698

Epoch: 6| Step: 9
Training loss: 0.36954883428758006
Validation loss: 2.3616160030484075

Epoch: 6| Step: 10
Training loss: 0.33324949382391544
Validation loss: 2.3793813590438226

Epoch: 6| Step: 11
Training loss: 0.22530048028786367
Validation loss: 2.4158392940731916

Epoch: 6| Step: 12
Training loss: 0.2729764866728781
Validation loss: 2.435256479791259

Epoch: 6| Step: 13
Training loss: 0.4212460421197979
Validation loss: 2.4090576667710506

Epoch: 356| Step: 0
Training loss: 0.4153891489384032
Validation loss: 2.4496705763584323

Epoch: 6| Step: 1
Training loss: 0.18121554770734521
Validation loss: 2.3541186240046836

Epoch: 6| Step: 2
Training loss: 0.2786523812258487
Validation loss: 2.3227155559648174

Epoch: 6| Step: 3
Training loss: 0.2662228000206078
Validation loss: 2.324032022460845

Epoch: 6| Step: 4
Training loss: 0.36432399608714827
Validation loss: 2.3318309107343063

Epoch: 6| Step: 5
Training loss: 0.24641384016307366
Validation loss: 2.3480131490789264

Epoch: 6| Step: 6
Training loss: 0.21546884113500714
Validation loss: 2.3316831721465836

Epoch: 6| Step: 7
Training loss: 0.48170490501124674
Validation loss: 2.337704461759583

Epoch: 6| Step: 8
Training loss: 0.32147079476171314
Validation loss: 2.316054569210478

Epoch: 6| Step: 9
Training loss: 0.32230152739317675
Validation loss: 2.3091767801628995

Epoch: 6| Step: 10
Training loss: 0.5072902635036648
Validation loss: 2.35581866151777

Epoch: 6| Step: 11
Training loss: 0.4313189831445317
Validation loss: 2.3575193391443707

Epoch: 6| Step: 12
Training loss: 0.3551504785326387
Validation loss: 2.3475534337641464

Epoch: 6| Step: 13
Training loss: 0.3811095174332716
Validation loss: 2.396654204729645

Epoch: 357| Step: 0
Training loss: 0.2454313795003166
Validation loss: 2.377977838631154

Epoch: 6| Step: 1
Training loss: 0.36700051193175615
Validation loss: 2.3834879310091175

Epoch: 6| Step: 2
Training loss: 0.45762885384498564
Validation loss: 2.381995396857536

Epoch: 6| Step: 3
Training loss: 0.3479138181002533
Validation loss: 2.404596349419919

Epoch: 6| Step: 4
Training loss: 0.3080443187068682
Validation loss: 2.393749684769907

Epoch: 6| Step: 5
Training loss: 0.29571264244092604
Validation loss: 2.3911703143149365

Epoch: 6| Step: 6
Training loss: 0.37616635771099133
Validation loss: 2.3610991640731704

Epoch: 6| Step: 7
Training loss: 0.29031328281260094
Validation loss: 2.3456770545979526

Epoch: 6| Step: 8
Training loss: 0.2798566876588519
Validation loss: 2.3261637471041547

Epoch: 6| Step: 9
Training loss: 0.37495014733503523
Validation loss: 2.3439169618483784

Epoch: 6| Step: 10
Training loss: 0.23536840354845112
Validation loss: 2.344943627934226

Epoch: 6| Step: 11
Training loss: 0.42156601999791304
Validation loss: 2.3652274175358197

Epoch: 6| Step: 12
Training loss: 0.36319452706784405
Validation loss: 2.3946024753588975

Epoch: 6| Step: 13
Training loss: 0.2838143428666214
Validation loss: 2.3894462266390333

Epoch: 358| Step: 0
Training loss: 0.24887018911155934
Validation loss: 2.362494928554533

Epoch: 6| Step: 1
Training loss: 0.3808779198459821
Validation loss: 2.381062768378331

Epoch: 6| Step: 2
Training loss: 0.3016324569912283
Validation loss: 2.425010258092941

Epoch: 6| Step: 3
Training loss: 0.41907580995295385
Validation loss: 2.3800107561087103

Epoch: 6| Step: 4
Training loss: 0.22534819456464428
Validation loss: 2.407221107682237

Epoch: 6| Step: 5
Training loss: 0.3161301173221698
Validation loss: 2.4180969626266657

Epoch: 6| Step: 6
Training loss: 0.3367304647226695
Validation loss: 2.4239984080193224

Epoch: 6| Step: 7
Training loss: 0.3036132851763529
Validation loss: 2.4347418095387514

Epoch: 6| Step: 8
Training loss: 0.3361915470566895
Validation loss: 2.4191791430464265

Epoch: 6| Step: 9
Training loss: 0.27116553705535457
Validation loss: 2.375468019615052

Epoch: 6| Step: 10
Training loss: 0.29772799070385536
Validation loss: 2.3666150791843563

Epoch: 6| Step: 11
Training loss: 0.3570993563010899
Validation loss: 2.379555770792511

Epoch: 6| Step: 12
Training loss: 0.2723854944930542
Validation loss: 2.336544327209042

Epoch: 6| Step: 13
Training loss: 0.2686677313349487
Validation loss: 2.4155924902337786

Epoch: 359| Step: 0
Training loss: 0.17690393298851617
Validation loss: 2.3968290345615952

Epoch: 6| Step: 1
Training loss: 0.260724413548142
Validation loss: 2.453600736310578

Epoch: 6| Step: 2
Training loss: 0.22095476000810582
Validation loss: 2.413482686652081

Epoch: 6| Step: 3
Training loss: 0.24211999506152046
Validation loss: 2.4213988133383753

Epoch: 6| Step: 4
Training loss: 0.27295658872750755
Validation loss: 2.4471351414528315

Epoch: 6| Step: 5
Training loss: 0.4084601802118103
Validation loss: 2.4602209597280034

Epoch: 6| Step: 6
Training loss: 0.36431193013653024
Validation loss: 2.444392842047678

Epoch: 6| Step: 7
Training loss: 0.13078219002097596
Validation loss: 2.4596723313382367

Epoch: 6| Step: 8
Training loss: 0.1918255048465536
Validation loss: 2.4681356695565055

Epoch: 6| Step: 9
Training loss: 0.3325396516289024
Validation loss: 2.4682918469780213

Epoch: 6| Step: 10
Training loss: 0.42808761990384797
Validation loss: 2.4893786465965944

Epoch: 6| Step: 11
Training loss: 0.17520191303522217
Validation loss: 2.4534039009313693

Epoch: 6| Step: 12
Training loss: 0.29730607407982945
Validation loss: 2.428201322773053

Epoch: 6| Step: 13
Training loss: 0.18245583816422778
Validation loss: 2.429887848086532

Epoch: 360| Step: 0
Training loss: 0.23426471340643504
Validation loss: 2.392932285384292

Epoch: 6| Step: 1
Training loss: 0.30728185632638694
Validation loss: 2.392686943775637

Epoch: 6| Step: 2
Training loss: 0.11381169385142718
Validation loss: 2.3881378200639154

Epoch: 6| Step: 3
Training loss: 0.21733420172093187
Validation loss: 2.41877463664387

Epoch: 6| Step: 4
Training loss: 0.1531973120672555
Validation loss: 2.419971013239206

Epoch: 6| Step: 5
Training loss: 0.2430908215384748
Validation loss: 2.3966335310353903

Epoch: 6| Step: 6
Training loss: 0.2664617374392612
Validation loss: 2.3871418919369467

Epoch: 6| Step: 7
Training loss: 0.26246045473227236
Validation loss: 2.409323203405774

Epoch: 6| Step: 8
Training loss: 0.18675004465416678
Validation loss: 2.3928149377228474

Epoch: 6| Step: 9
Training loss: 0.34077337428196247
Validation loss: 2.3649962607091863

Epoch: 6| Step: 10
Training loss: 0.22124157267216027
Validation loss: 2.384624221862686

Epoch: 6| Step: 11
Training loss: 0.25995252095504423
Validation loss: 2.416667269564148

Epoch: 6| Step: 12
Training loss: 0.41554448487981643
Validation loss: 2.4117178318288173

Epoch: 6| Step: 13
Training loss: 0.1691637226041951
Validation loss: 2.362070778767371

Epoch: 361| Step: 0
Training loss: 0.2560308915290199
Validation loss: 2.3805655044076426

Epoch: 6| Step: 1
Training loss: 0.1677415775339328
Validation loss: 2.3930335622321395

Epoch: 6| Step: 2
Training loss: 0.41250896516363156
Validation loss: 2.3985215797930337

Epoch: 6| Step: 3
Training loss: 0.2922323126266064
Validation loss: 2.4057353779459736

Epoch: 6| Step: 4
Training loss: 0.1973340510675334
Validation loss: 2.407544794896134

Epoch: 6| Step: 5
Training loss: 0.14961901178025155
Validation loss: 2.3723781450812873

Epoch: 6| Step: 6
Training loss: 0.27703657735746595
Validation loss: 2.3818814093027387

Epoch: 6| Step: 7
Training loss: 0.29655605047868394
Validation loss: 2.4024664382559755

Epoch: 6| Step: 8
Training loss: 0.22491378059410616
Validation loss: 2.4062875042386977

Epoch: 6| Step: 9
Training loss: 0.2670404643103481
Validation loss: 2.391528209957463

Epoch: 6| Step: 10
Training loss: 0.20838226498717924
Validation loss: 2.378380007256501

Epoch: 6| Step: 11
Training loss: 0.16617865691628292
Validation loss: 2.3647458910217574

Epoch: 6| Step: 12
Training loss: 0.14029537085752733
Validation loss: 2.3601696944542305

Epoch: 6| Step: 13
Training loss: 0.21851509969768865
Validation loss: 2.3831166471868173

Epoch: 362| Step: 0
Training loss: 0.33638454234332754
Validation loss: 2.3967199406936968

Epoch: 6| Step: 1
Training loss: 0.25417791651754706
Validation loss: 2.4162376208242065

Epoch: 6| Step: 2
Training loss: 0.1717518126580869
Validation loss: 2.415718294224361

Epoch: 6| Step: 3
Training loss: 0.23115347316838308
Validation loss: 2.400124852075996

Epoch: 6| Step: 4
Training loss: 0.21075135424089475
Validation loss: 2.3757162697934024

Epoch: 6| Step: 5
Training loss: 0.3525985921121382
Validation loss: 2.3973447750112853

Epoch: 6| Step: 6
Training loss: 0.2318643486656088
Validation loss: 2.4230039867474487

Epoch: 6| Step: 7
Training loss: 0.3216729465095624
Validation loss: 2.431989964434239

Epoch: 6| Step: 8
Training loss: 0.1849258873024375
Validation loss: 2.4494142156853833

Epoch: 6| Step: 9
Training loss: 0.1771672601594192
Validation loss: 2.4598191576673294

Epoch: 6| Step: 10
Training loss: 0.19103609026158028
Validation loss: 2.4313648739465936

Epoch: 6| Step: 11
Training loss: 0.2621060253219211
Validation loss: 2.431512277254134

Epoch: 6| Step: 12
Training loss: 0.3658603465042721
Validation loss: 2.458824914330597

Epoch: 6| Step: 13
Training loss: 0.25881478523677043
Validation loss: 2.4140598490779754

Epoch: 363| Step: 0
Training loss: 0.29976574275153905
Validation loss: 2.3943131948156546

Epoch: 6| Step: 1
Training loss: 0.29835518955152773
Validation loss: 2.4016872466398143

Epoch: 6| Step: 2
Training loss: 0.22645258703781848
Validation loss: 2.372895034961823

Epoch: 6| Step: 3
Training loss: 0.17571233882127316
Validation loss: 2.383394442672025

Epoch: 6| Step: 4
Training loss: 0.180065224489536
Validation loss: 2.381087096896097

Epoch: 6| Step: 5
Training loss: 0.3487315425466362
Validation loss: 2.4068529502669063

Epoch: 6| Step: 6
Training loss: 0.21466815014500834
Validation loss: 2.4183707044540004

Epoch: 6| Step: 7
Training loss: 0.16354116988460954
Validation loss: 2.4185125651326915

Epoch: 6| Step: 8
Training loss: 0.23285388066738213
Validation loss: 2.377114820250688

Epoch: 6| Step: 9
Training loss: 0.31766084670509215
Validation loss: 2.4079035194430602

Epoch: 6| Step: 10
Training loss: 0.2241789632979303
Validation loss: 2.4130542291717028

Epoch: 6| Step: 11
Training loss: 0.23534261916013882
Validation loss: 2.4082946805183036

Epoch: 6| Step: 12
Training loss: 0.15980340888594213
Validation loss: 2.414761653460405

Epoch: 6| Step: 13
Training loss: 0.20322667841526182
Validation loss: 2.4018905520310496

Epoch: 364| Step: 0
Training loss: 0.21128810778680915
Validation loss: 2.4455086133637587

Epoch: 6| Step: 1
Training loss: 0.12408976395823251
Validation loss: 2.376995376455549

Epoch: 6| Step: 2
Training loss: 0.25181262216496386
Validation loss: 2.444604738665834

Epoch: 6| Step: 3
Training loss: 0.21959209142069164
Validation loss: 2.3912436231592427

Epoch: 6| Step: 4
Training loss: 0.27157385469848483
Validation loss: 2.4421495781207265

Epoch: 6| Step: 5
Training loss: 0.20780531110734157
Validation loss: 2.3928316535084506

Epoch: 6| Step: 6
Training loss: 0.18483366167233092
Validation loss: 2.4141976944908343

Epoch: 6| Step: 7
Training loss: 0.30559890101263903
Validation loss: 2.363133421297977

Epoch: 6| Step: 8
Training loss: 0.31854318800330683
Validation loss: 2.426336505657527

Epoch: 6| Step: 9
Training loss: 0.22133877457602727
Validation loss: 2.3869995738238825

Epoch: 6| Step: 10
Training loss: 0.310979865173658
Validation loss: 2.3768402357806373

Epoch: 6| Step: 11
Training loss: 0.2466666425818247
Validation loss: 2.3753587406505825

Epoch: 6| Step: 12
Training loss: 0.12415643754556559
Validation loss: 2.372848279752034

Epoch: 6| Step: 13
Training loss: 0.26563076405722535
Validation loss: 2.3564764430553877

Epoch: 365| Step: 0
Training loss: 0.2089897137254114
Validation loss: 2.4010389320557803

Epoch: 6| Step: 1
Training loss: 0.1126342581607037
Validation loss: 2.368641333820644

Epoch: 6| Step: 2
Training loss: 0.18045220195981093
Validation loss: 2.4234309538275234

Epoch: 6| Step: 3
Training loss: 0.20793637763896586
Validation loss: 2.452401274876974

Epoch: 6| Step: 4
Training loss: 0.37183186256827977
Validation loss: 2.4459727989124946

Epoch: 6| Step: 5
Training loss: 0.20268559613246775
Validation loss: 2.4628606321167155

Epoch: 6| Step: 6
Training loss: 0.2777931172718444
Validation loss: 2.4718155048375383

Epoch: 6| Step: 7
Training loss: 0.22458899032307217
Validation loss: 2.428208572259321

Epoch: 6| Step: 8
Training loss: 0.20587358154266822
Validation loss: 2.449736761869111

Epoch: 6| Step: 9
Training loss: 0.3302103037529689
Validation loss: 2.399773517983626

Epoch: 6| Step: 10
Training loss: 0.1648274255416426
Validation loss: 2.3922885921667008

Epoch: 6| Step: 11
Training loss: 0.33446374588952554
Validation loss: 2.4031551900532513

Epoch: 6| Step: 12
Training loss: 0.1476014333223773
Validation loss: 2.3953246580246574

Epoch: 6| Step: 13
Training loss: 0.4035762685902683
Validation loss: 2.3975909787013614

Epoch: 366| Step: 0
Training loss: 0.256771761342526
Validation loss: 2.388741602995224

Epoch: 6| Step: 1
Training loss: 0.22900144173082917
Validation loss: 2.35077091077181

Epoch: 6| Step: 2
Training loss: 0.20609854281205095
Validation loss: 2.3994799691248927

Epoch: 6| Step: 3
Training loss: 0.20134389799989752
Validation loss: 2.3879587177438353

Epoch: 6| Step: 4
Training loss: 0.29901129899157525
Validation loss: 2.405362087246488

Epoch: 6| Step: 5
Training loss: 0.13531896080203995
Validation loss: 2.440705157020868

Epoch: 6| Step: 6
Training loss: 0.21978412298089975
Validation loss: 2.4168547372193916

Epoch: 6| Step: 7
Training loss: 0.21306087091214213
Validation loss: 2.4839939354810343

Epoch: 6| Step: 8
Training loss: 0.261431536434808
Validation loss: 2.479212249587742

Epoch: 6| Step: 9
Training loss: 0.38345827402362215
Validation loss: 2.4606463125754092

Epoch: 6| Step: 10
Training loss: 0.29891209887272396
Validation loss: 2.4772467943190404

Epoch: 6| Step: 11
Training loss: 0.1908672489785887
Validation loss: 2.461129611567918

Epoch: 6| Step: 12
Training loss: 0.2412241418598878
Validation loss: 2.4548532608127247

Epoch: 6| Step: 13
Training loss: 0.20413028934678207
Validation loss: 2.4453640823299394

Epoch: 367| Step: 0
Training loss: 0.2333846786465788
Validation loss: 2.453023469108064

Epoch: 6| Step: 1
Training loss: 0.20608344939478368
Validation loss: 2.4740676950700675

Epoch: 6| Step: 2
Training loss: 0.2953356436082221
Validation loss: 2.423389151234831

Epoch: 6| Step: 3
Training loss: 0.22144325184060976
Validation loss: 2.4263984209871348

Epoch: 6| Step: 4
Training loss: 0.3441661461536791
Validation loss: 2.4311147701822944

Epoch: 6| Step: 5
Training loss: 0.303433994229746
Validation loss: 2.436874884797943

Epoch: 6| Step: 6
Training loss: 0.3129467155481659
Validation loss: 2.4120661911310743

Epoch: 6| Step: 7
Training loss: 0.24776322373975943
Validation loss: 2.3768825464072587

Epoch: 6| Step: 8
Training loss: 0.3075051360941928
Validation loss: 2.4465529117151643

Epoch: 6| Step: 9
Training loss: 0.19634641691913582
Validation loss: 2.4356003398437815

Epoch: 6| Step: 10
Training loss: 0.25394944043714657
Validation loss: 2.4343426841020905

Epoch: 6| Step: 11
Training loss: 0.31904538670076943
Validation loss: 2.4241100381114977

Epoch: 6| Step: 12
Training loss: 0.27059161268791765
Validation loss: 2.466453912345989

Epoch: 6| Step: 13
Training loss: 0.22812932121416912
Validation loss: 2.4584025562176834

Epoch: 368| Step: 0
Training loss: 0.1902150436072862
Validation loss: 2.475955131825316

Epoch: 6| Step: 1
Training loss: 0.2825805134101484
Validation loss: 2.448205663674458

Epoch: 6| Step: 2
Training loss: 0.26791242613682165
Validation loss: 2.4813600700432645

Epoch: 6| Step: 3
Training loss: 0.2577129229509789
Validation loss: 2.4667775774454177

Epoch: 6| Step: 4
Training loss: 0.2511511911326753
Validation loss: 2.4594501355721627

Epoch: 6| Step: 5
Training loss: 0.3242312509355814
Validation loss: 2.447458083835333

Epoch: 6| Step: 6
Training loss: 0.3262633692168923
Validation loss: 2.422226336317861

Epoch: 6| Step: 7
Training loss: 0.3018621862941974
Validation loss: 2.4154460598152196

Epoch: 6| Step: 8
Training loss: 0.2445720218147239
Validation loss: 2.4186182667368272

Epoch: 6| Step: 9
Training loss: 0.16340756253364455
Validation loss: 2.363901730059863

Epoch: 6| Step: 10
Training loss: 0.19754631543625223
Validation loss: 2.379996635641104

Epoch: 6| Step: 11
Training loss: 0.41951915148120567
Validation loss: 2.337304447117343

Epoch: 6| Step: 12
Training loss: 0.2279937523353949
Validation loss: 2.355558399903852

Epoch: 6| Step: 13
Training loss: 0.4665020127125259
Validation loss: 2.373554887321751

Epoch: 369| Step: 0
Training loss: 0.22477720873183135
Validation loss: 2.3473879324496707

Epoch: 6| Step: 1
Training loss: 0.18101697938533393
Validation loss: 2.3991992357158525

Epoch: 6| Step: 2
Training loss: 0.1770105399318025
Validation loss: 2.4539001266479827

Epoch: 6| Step: 3
Training loss: 0.37696668373192427
Validation loss: 2.453235935921289

Epoch: 6| Step: 4
Training loss: 0.3728498967384788
Validation loss: 2.4743254614001264

Epoch: 6| Step: 5
Training loss: 0.24969054978170768
Validation loss: 2.43659824048791

Epoch: 6| Step: 6
Training loss: 0.26151166380859847
Validation loss: 2.478357262731471

Epoch: 6| Step: 7
Training loss: 0.2582502838559728
Validation loss: 2.4448785130390096

Epoch: 6| Step: 8
Training loss: 0.31641404413113156
Validation loss: 2.4543117789982922

Epoch: 6| Step: 9
Training loss: 0.18272043053441528
Validation loss: 2.46020534215275

Epoch: 6| Step: 10
Training loss: 0.17788077183484907
Validation loss: 2.4380922131849636

Epoch: 6| Step: 11
Training loss: 0.22207716878407205
Validation loss: 2.4303297730411706

Epoch: 6| Step: 12
Training loss: 0.15795371328341123
Validation loss: 2.408733726800823

Epoch: 6| Step: 13
Training loss: 0.389283547170414
Validation loss: 2.3793065813783767

Epoch: 370| Step: 0
Training loss: 0.2401403692898024
Validation loss: 2.412563941121393

Epoch: 6| Step: 1
Training loss: 0.2606605230451549
Validation loss: 2.3873868294259064

Epoch: 6| Step: 2
Training loss: 0.33564949997572446
Validation loss: 2.44013519080025

Epoch: 6| Step: 3
Training loss: 0.23973966073225486
Validation loss: 2.4109696063736084

Epoch: 6| Step: 4
Training loss: 0.26016534440007805
Validation loss: 2.461609674143728

Epoch: 6| Step: 5
Training loss: 0.21162076068987512
Validation loss: 2.467183641257702

Epoch: 6| Step: 6
Training loss: 0.3920211256718475
Validation loss: 2.4744642551038343

Epoch: 6| Step: 7
Training loss: 0.325585186001483
Validation loss: 2.495184126845151

Epoch: 6| Step: 8
Training loss: 0.21739322675108927
Validation loss: 2.480791064550741

Epoch: 6| Step: 9
Training loss: 0.2329662423411444
Validation loss: 2.406350451065247

Epoch: 6| Step: 10
Training loss: 0.21106212960804618
Validation loss: 2.4571056008116408

Epoch: 6| Step: 11
Training loss: 0.22365933056988804
Validation loss: 2.443818992184472

Epoch: 6| Step: 12
Training loss: 0.24048971547027734
Validation loss: 2.4391955958763

Epoch: 6| Step: 13
Training loss: 0.3057570635899024
Validation loss: 2.454204839220859

Epoch: 371| Step: 0
Training loss: 0.28974162047828494
Validation loss: 2.447813221341301

Epoch: 6| Step: 1
Training loss: 0.13750660593246766
Validation loss: 2.455018118710923

Epoch: 6| Step: 2
Training loss: 0.2870628812344289
Validation loss: 2.437406714300047

Epoch: 6| Step: 3
Training loss: 0.1874974171142696
Validation loss: 2.472144234275867

Epoch: 6| Step: 4
Training loss: 0.2207620339558847
Validation loss: 2.4952166768154513

Epoch: 6| Step: 5
Training loss: 0.2519758938696019
Validation loss: 2.4830756369903653

Epoch: 6| Step: 6
Training loss: 0.37407550499154196
Validation loss: 2.5239389578424256

Epoch: 6| Step: 7
Training loss: 0.19199248475898711
Validation loss: 2.5208020196032694

Epoch: 6| Step: 8
Training loss: 0.273686377478382
Validation loss: 2.500034845786128

Epoch: 6| Step: 9
Training loss: 0.3388895912349872
Validation loss: 2.506756553289554

Epoch: 6| Step: 10
Training loss: 0.3872844719624629
Validation loss: 2.4838323791904005

Epoch: 6| Step: 11
Training loss: 0.10506712419861891
Validation loss: 2.4514454801548515

Epoch: 6| Step: 12
Training loss: 0.18022443533129107
Validation loss: 2.4443630605895996

Epoch: 6| Step: 13
Training loss: 0.21286460297462093
Validation loss: 2.4229819846585734

Epoch: 372| Step: 0
Training loss: 0.18753929521148552
Validation loss: 2.392124215038421

Epoch: 6| Step: 1
Training loss: 0.2012283283020948
Validation loss: 2.394598683321424

Epoch: 6| Step: 2
Training loss: 0.18553786004904121
Validation loss: 2.3568989425827827

Epoch: 6| Step: 3
Training loss: 0.22273931292436125
Validation loss: 2.3919455366070195

Epoch: 6| Step: 4
Training loss: 0.14072772089085883
Validation loss: 2.4023393565745597

Epoch: 6| Step: 5
Training loss: 0.1553543287975251
Validation loss: 2.3851783179475907

Epoch: 6| Step: 6
Training loss: 0.2434689016619555
Validation loss: 2.4082189919911996

Epoch: 6| Step: 7
Training loss: 0.3167495043012298
Validation loss: 2.4311823350154933

Epoch: 6| Step: 8
Training loss: 0.30484427795677277
Validation loss: 2.4293836389046843

Epoch: 6| Step: 9
Training loss: 0.30882403074986503
Validation loss: 2.432214045899449

Epoch: 6| Step: 10
Training loss: 0.36258565285415
Validation loss: 2.4581749414718534

Epoch: 6| Step: 11
Training loss: 0.32039185448173213
Validation loss: 2.456268633027855

Epoch: 6| Step: 12
Training loss: 0.15870415269572083
Validation loss: 2.473246668130961

Epoch: 6| Step: 13
Training loss: 0.25696641631877704
Validation loss: 2.4787524745869796

Epoch: 373| Step: 0
Training loss: 0.3783942627403309
Validation loss: 2.434267088291089

Epoch: 6| Step: 1
Training loss: 0.20974411525587094
Validation loss: 2.4616348062597795

Epoch: 6| Step: 2
Training loss: 0.3123435821074759
Validation loss: 2.4595086750425157

Epoch: 6| Step: 3
Training loss: 0.28487970712178284
Validation loss: 2.427343489173026

Epoch: 6| Step: 4
Training loss: 0.15136080697670848
Validation loss: 2.4434621216218386

Epoch: 6| Step: 5
Training loss: 0.3873300825864605
Validation loss: 2.4221111593972426

Epoch: 6| Step: 6
Training loss: 0.22684141781432218
Validation loss: 2.385723790836216

Epoch: 6| Step: 7
Training loss: 0.3147991953483244
Validation loss: 2.3547699168352882

Epoch: 6| Step: 8
Training loss: 0.14028045380736695
Validation loss: 2.3661041461157524

Epoch: 6| Step: 9
Training loss: 0.2031610713621932
Validation loss: 2.3447169561803873

Epoch: 6| Step: 10
Training loss: 0.2131485819844588
Validation loss: 2.3693185573135396

Epoch: 6| Step: 11
Training loss: 0.18872096961077867
Validation loss: 2.3628613550416597

Epoch: 6| Step: 12
Training loss: 0.17638323806945877
Validation loss: 2.355163574040165

Epoch: 6| Step: 13
Training loss: 0.2790541761466199
Validation loss: 2.3818786329617976

Epoch: 374| Step: 0
Training loss: 0.19410058727391746
Validation loss: 2.4164057922506075

Epoch: 6| Step: 1
Training loss: 0.2652385087737486
Validation loss: 2.375595127232171

Epoch: 6| Step: 2
Training loss: 0.21875330377536198
Validation loss: 2.3917727507719264

Epoch: 6| Step: 3
Training loss: 0.37714152001349277
Validation loss: 2.39603770607326

Epoch: 6| Step: 4
Training loss: 0.13816036662690495
Validation loss: 2.366305372323981

Epoch: 6| Step: 5
Training loss: 0.20162462932957007
Validation loss: 2.3982121664132388

Epoch: 6| Step: 6
Training loss: 0.37745974398699345
Validation loss: 2.3831520391390795

Epoch: 6| Step: 7
Training loss: 0.17645003990814437
Validation loss: 2.409955044757589

Epoch: 6| Step: 8
Training loss: 0.20887680493869917
Validation loss: 2.3596800604408266

Epoch: 6| Step: 9
Training loss: 0.33438698444102116
Validation loss: 2.3905909261916594

Epoch: 6| Step: 10
Training loss: 0.2512256855373271
Validation loss: 2.382329544945755

Epoch: 6| Step: 11
Training loss: 0.23081430295337654
Validation loss: 2.399821336053949

Epoch: 6| Step: 12
Training loss: 0.28482326243468326
Validation loss: 2.3963911765141375

Epoch: 6| Step: 13
Training loss: 0.2134115687322108
Validation loss: 2.4090969762620364

Epoch: 375| Step: 0
Training loss: 0.20882684349754319
Validation loss: 2.3850164572545953

Epoch: 6| Step: 1
Training loss: 0.3432523528078853
Validation loss: 2.408874014274071

Epoch: 6| Step: 2
Training loss: 0.14894062656141582
Validation loss: 2.45663449336334

Epoch: 6| Step: 3
Training loss: 0.2795178532895154
Validation loss: 2.4294418929896326

Epoch: 6| Step: 4
Training loss: 0.27423706319579344
Validation loss: 2.42760402969158

Epoch: 6| Step: 5
Training loss: 0.2874004938167824
Validation loss: 2.420650010155856

Epoch: 6| Step: 6
Training loss: 0.14133905874568367
Validation loss: 2.4143802146887903

Epoch: 6| Step: 7
Training loss: 0.19151642606234218
Validation loss: 2.404323778023358

Epoch: 6| Step: 8
Training loss: 0.3113418097461899
Validation loss: 2.4241909157413093

Epoch: 6| Step: 9
Training loss: 0.250926550843639
Validation loss: 2.4389002443157426

Epoch: 6| Step: 10
Training loss: 0.17789049941817833
Validation loss: 2.4239521509673536

Epoch: 6| Step: 11
Training loss: 0.23257361195279333
Validation loss: 2.4246033743245783

Epoch: 6| Step: 12
Training loss: 0.33237144769088
Validation loss: 2.4201661632625586

Epoch: 6| Step: 13
Training loss: 0.12191730446677451
Validation loss: 2.404670353446756

Epoch: 376| Step: 0
Training loss: 0.15938037087235543
Validation loss: 2.403228127973335

Epoch: 6| Step: 1
Training loss: 0.14705289507058616
Validation loss: 2.414609778592262

Epoch: 6| Step: 2
Training loss: 0.19922478984578026
Validation loss: 2.4082714795299673

Epoch: 6| Step: 3
Training loss: 0.2166453338782609
Validation loss: 2.392886257558617

Epoch: 6| Step: 4
Training loss: 0.34197958286309266
Validation loss: 2.4103695982152873

Epoch: 6| Step: 5
Training loss: 0.1838341822763118
Validation loss: 2.3875436706792548

Epoch: 6| Step: 6
Training loss: 0.18140276850498252
Validation loss: 2.427644040506679

Epoch: 6| Step: 7
Training loss: 0.2296347317447832
Validation loss: 2.422894914947185

Epoch: 6| Step: 8
Training loss: 0.17438746054028686
Validation loss: 2.400788495085442

Epoch: 6| Step: 9
Training loss: 0.15648871901906006
Validation loss: 2.4289749652282673

Epoch: 6| Step: 10
Training loss: 0.18716998661565307
Validation loss: 2.411908082109436

Epoch: 6| Step: 11
Training loss: 0.3500161707923114
Validation loss: 2.4109268114763

Epoch: 6| Step: 12
Training loss: 0.3465712686707251
Validation loss: 2.3870298798000626

Epoch: 6| Step: 13
Training loss: 0.1780415071596371
Validation loss: 2.413184671969184

Epoch: 377| Step: 0
Training loss: 0.22439538464619252
Validation loss: 2.3745083459222434

Epoch: 6| Step: 1
Training loss: 0.10293491791785489
Validation loss: 2.3821001563918607

Epoch: 6| Step: 2
Training loss: 0.12105774728798452
Validation loss: 2.373957972617482

Epoch: 6| Step: 3
Training loss: 0.17285282328517612
Validation loss: 2.3686638569047505

Epoch: 6| Step: 4
Training loss: 0.18091608974959877
Validation loss: 2.3786689541209314

Epoch: 6| Step: 5
Training loss: 0.26824789383088965
Validation loss: 2.3864827041440435

Epoch: 6| Step: 6
Training loss: 0.1806993192345357
Validation loss: 2.384273592278202

Epoch: 6| Step: 7
Training loss: 0.23993839856670357
Validation loss: 2.386492683219044

Epoch: 6| Step: 8
Training loss: 0.22291436209037008
Validation loss: 2.4448748299134606

Epoch: 6| Step: 9
Training loss: 0.367369221299532
Validation loss: 2.4886228476605528

Epoch: 6| Step: 10
Training loss: 0.24208065721840452
Validation loss: 2.447395989508199

Epoch: 6| Step: 11
Training loss: 0.14656502093198795
Validation loss: 2.440858521808064

Epoch: 6| Step: 12
Training loss: 0.2155676350787953
Validation loss: 2.4201117229240996

Epoch: 6| Step: 13
Training loss: 0.22971340636689866
Validation loss: 2.440245651976286

Epoch: 378| Step: 0
Training loss: 0.2575781942361097
Validation loss: 2.4064409915049434

Epoch: 6| Step: 1
Training loss: 0.29450575417173924
Validation loss: 2.397113725333566

Epoch: 6| Step: 2
Training loss: 0.27487792318228743
Validation loss: 2.3686974311632114

Epoch: 6| Step: 3
Training loss: 0.19022290667170305
Validation loss: 2.400600755268608

Epoch: 6| Step: 4
Training loss: 0.24265746694187204
Validation loss: 2.372168002619649

Epoch: 6| Step: 5
Training loss: 0.30782259183886773
Validation loss: 2.3786984108093283

Epoch: 6| Step: 6
Training loss: 0.17210256077336933
Validation loss: 2.3830722010350307

Epoch: 6| Step: 7
Training loss: 0.10587271838533323
Validation loss: 2.398127080516584

Epoch: 6| Step: 8
Training loss: 0.2869699100494616
Validation loss: 2.4183283076692015

Epoch: 6| Step: 9
Training loss: 0.19301443447232866
Validation loss: 2.4205391461653045

Epoch: 6| Step: 10
Training loss: 0.16618521387092253
Validation loss: 2.4218139344348977

Epoch: 6| Step: 11
Training loss: 0.1930383850046245
Validation loss: 2.4258179238694377

Epoch: 6| Step: 12
Training loss: 0.3705427596724076
Validation loss: 2.435666205646258

Epoch: 6| Step: 13
Training loss: 0.17437268265001313
Validation loss: 2.4119526898936474

Epoch: 379| Step: 0
Training loss: 0.12431942920350647
Validation loss: 2.426384732658107

Epoch: 6| Step: 1
Training loss: 0.2389291179283355
Validation loss: 2.363846765023198

Epoch: 6| Step: 2
Training loss: 0.3007130607495731
Validation loss: 2.334790035113754

Epoch: 6| Step: 3
Training loss: 0.13151252071346733
Validation loss: 2.3463373790796567

Epoch: 6| Step: 4
Training loss: 0.10576442933417614
Validation loss: 2.352092793917571

Epoch: 6| Step: 5
Training loss: 0.31411371809816474
Validation loss: 2.380622963814423

Epoch: 6| Step: 6
Training loss: 0.2613618181800551
Validation loss: 2.3674129656361838

Epoch: 6| Step: 7
Training loss: 0.17822560347118993
Validation loss: 2.4183999113080774

Epoch: 6| Step: 8
Training loss: 0.21291778986093987
Validation loss: 2.3586998484004544

Epoch: 6| Step: 9
Training loss: 0.29265038039904384
Validation loss: 2.4012897870331087

Epoch: 6| Step: 10
Training loss: 0.31544173368239736
Validation loss: 2.4314374116360997

Epoch: 6| Step: 11
Training loss: 0.1696591922865335
Validation loss: 2.413069108106446

Epoch: 6| Step: 12
Training loss: 0.20847066684025206
Validation loss: 2.451831829744138

Epoch: 6| Step: 13
Training loss: 0.15967783766178534
Validation loss: 2.407090782638196

Epoch: 380| Step: 0
Training loss: 0.32539628380002755
Validation loss: 2.445614688593546

Epoch: 6| Step: 1
Training loss: 0.1362170551218236
Validation loss: 2.429304779870765

Epoch: 6| Step: 2
Training loss: 0.10726584026067797
Validation loss: 2.4156883152595725

Epoch: 6| Step: 3
Training loss: 0.15639661824068504
Validation loss: 2.3742044646029776

Epoch: 6| Step: 4
Training loss: 0.14879789020272524
Validation loss: 2.3744074017935413

Epoch: 6| Step: 5
Training loss: 0.15237690491459632
Validation loss: 2.3592465001767944

Epoch: 6| Step: 6
Training loss: 0.3859564077710975
Validation loss: 2.344332077321003

Epoch: 6| Step: 7
Training loss: 0.14891886460548845
Validation loss: 2.3703829689660267

Epoch: 6| Step: 8
Training loss: 0.21664120695721736
Validation loss: 2.369821979410421

Epoch: 6| Step: 9
Training loss: 0.31805254185987236
Validation loss: 2.3617105228237527

Epoch: 6| Step: 10
Training loss: 0.3233596956961591
Validation loss: 2.335770209787606

Epoch: 6| Step: 11
Training loss: 0.2009327958536722
Validation loss: 2.374632123079528

Epoch: 6| Step: 12
Training loss: 0.1216139923737549
Validation loss: 2.3783678205600123

Epoch: 6| Step: 13
Training loss: 0.18270417044133402
Validation loss: 2.3930985834909073

Epoch: 381| Step: 0
Training loss: 0.26854729382133885
Validation loss: 2.406579033364513

Epoch: 6| Step: 1
Training loss: 0.13107015231399494
Validation loss: 2.4290954778101237

Epoch: 6| Step: 2
Training loss: 0.1446512471625899
Validation loss: 2.437961350652495

Epoch: 6| Step: 3
Training loss: 0.2682569066613489
Validation loss: 2.4482517425902883

Epoch: 6| Step: 4
Training loss: 0.16865929885774614
Validation loss: 2.454388181098974

Epoch: 6| Step: 5
Training loss: 0.3127640085810793
Validation loss: 2.46403792051422

Epoch: 6| Step: 6
Training loss: 0.2550264005224481
Validation loss: 2.4383895224866494

Epoch: 6| Step: 7
Training loss: 0.19009989032551564
Validation loss: 2.4493829263567677

Epoch: 6| Step: 8
Training loss: 0.22094301672796512
Validation loss: 2.4213277716555615

Epoch: 6| Step: 9
Training loss: 0.2113974290122574
Validation loss: 2.421861123618532

Epoch: 6| Step: 10
Training loss: 0.22750160007123718
Validation loss: 2.398706776243212

Epoch: 6| Step: 11
Training loss: 0.21613839818430186
Validation loss: 2.39932849673752

Epoch: 6| Step: 12
Training loss: 0.19858354390688526
Validation loss: 2.395310473713639

Epoch: 6| Step: 13
Training loss: 0.12677708671754162
Validation loss: 2.4187829663231866

Epoch: 382| Step: 0
Training loss: 0.18950113690973813
Validation loss: 2.362205115676422

Epoch: 6| Step: 1
Training loss: 0.18829596964490503
Validation loss: 2.3859606596028753

Epoch: 6| Step: 2
Training loss: 0.2263171413022608
Validation loss: 2.378688147380249

Epoch: 6| Step: 3
Training loss: 0.27122910937714895
Validation loss: 2.401621117710692

Epoch: 6| Step: 4
Training loss: 0.26047074551152605
Validation loss: 2.3849623378615075

Epoch: 6| Step: 5
Training loss: 0.09714412875987329
Validation loss: 2.378717044483509

Epoch: 6| Step: 6
Training loss: 0.19952821070567628
Validation loss: 2.3822953917665437

Epoch: 6| Step: 7
Training loss: 0.18123126303080123
Validation loss: 2.3667228548929917

Epoch: 6| Step: 8
Training loss: 0.14597735077336604
Validation loss: 2.3935966341254997

Epoch: 6| Step: 9
Training loss: 0.127703182249851
Validation loss: 2.4111596833743887

Epoch: 6| Step: 10
Training loss: 0.3145886715484472
Validation loss: 2.4083458315475363

Epoch: 6| Step: 11
Training loss: 0.21995585875219073
Validation loss: 2.4405671787711696

Epoch: 6| Step: 12
Training loss: 0.18486036488791374
Validation loss: 2.4263189926304647

Epoch: 6| Step: 13
Training loss: 0.3405739623514237
Validation loss: 2.4299745944349422

Epoch: 383| Step: 0
Training loss: 0.12950236307845467
Validation loss: 2.4119750293485906

Epoch: 6| Step: 1
Training loss: 0.2474261951219939
Validation loss: 2.428305688371949

Epoch: 6| Step: 2
Training loss: 0.26757560506037836
Validation loss: 2.434081077552869

Epoch: 6| Step: 3
Training loss: 0.14089770498526885
Validation loss: 2.4283513124683944

Epoch: 6| Step: 4
Training loss: 0.1778076775270648
Validation loss: 2.38718422294681

Epoch: 6| Step: 5
Training loss: 0.17606337477412876
Validation loss: 2.425928301452015

Epoch: 6| Step: 6
Training loss: 0.19200095411835968
Validation loss: 2.422340341480337

Epoch: 6| Step: 7
Training loss: 0.2132756836832035
Validation loss: 2.4018288049215437

Epoch: 6| Step: 8
Training loss: 0.1638737682889832
Validation loss: 2.401206744767658

Epoch: 6| Step: 9
Training loss: 0.3105015751649766
Validation loss: 2.386006829086791

Epoch: 6| Step: 10
Training loss: 0.1079549998320595
Validation loss: 2.3982666324593267

Epoch: 6| Step: 11
Training loss: 0.22721905779040585
Validation loss: 2.398908220398696

Epoch: 6| Step: 12
Training loss: 0.19131660308351092
Validation loss: 2.4113272154193

Epoch: 6| Step: 13
Training loss: 0.39273026588100884
Validation loss: 2.408974988058587

Epoch: 384| Step: 0
Training loss: 0.11323279544822983
Validation loss: 2.3797206023971986

Epoch: 6| Step: 1
Training loss: 0.3187576681037513
Validation loss: 2.3692187349048077

Epoch: 6| Step: 2
Training loss: 0.23850443815354477
Validation loss: 2.4244128196424053

Epoch: 6| Step: 3
Training loss: 0.19357176396462036
Validation loss: 2.422534268848815

Epoch: 6| Step: 4
Training loss: 0.15221589787935366
Validation loss: 2.4194846072994953

Epoch: 6| Step: 5
Training loss: 0.2672990192557673
Validation loss: 2.4376137840737093

Epoch: 6| Step: 6
Training loss: 0.22080491680876643
Validation loss: 2.4466702517348264

Epoch: 6| Step: 7
Training loss: 0.18196043962097122
Validation loss: 2.42210613130948

Epoch: 6| Step: 8
Training loss: 0.14807564775383847
Validation loss: 2.4406005249123943

Epoch: 6| Step: 9
Training loss: 0.2693252743940125
Validation loss: 2.415550248457829

Epoch: 6| Step: 10
Training loss: 0.14591242073386668
Validation loss: 2.3959966945373052

Epoch: 6| Step: 11
Training loss: 0.12434443661988406
Validation loss: 2.3656269903758864

Epoch: 6| Step: 12
Training loss: 0.3453277877944744
Validation loss: 2.345162338982193

Epoch: 6| Step: 13
Training loss: 0.13967359089568188
Validation loss: 2.358283409941958

Epoch: 385| Step: 0
Training loss: 0.19945775449156283
Validation loss: 2.370523451242821

Epoch: 6| Step: 1
Training loss: 0.16792247378713834
Validation loss: 2.40717851878353

Epoch: 6| Step: 2
Training loss: 0.23806376772548268
Validation loss: 2.417583322670132

Epoch: 6| Step: 3
Training loss: 0.19780207859628376
Validation loss: 2.3777919958771085

Epoch: 6| Step: 4
Training loss: 0.18136279074314104
Validation loss: 2.401939341910507

Epoch: 6| Step: 5
Training loss: 0.18027878998221789
Validation loss: 2.403320697581502

Epoch: 6| Step: 6
Training loss: 0.27858919239434726
Validation loss: 2.414853300038292

Epoch: 6| Step: 7
Training loss: 0.15038095789963793
Validation loss: 2.43984066748509

Epoch: 6| Step: 8
Training loss: 0.1847675420165668
Validation loss: 2.44481000022827

Epoch: 6| Step: 9
Training loss: 0.32852476608495046
Validation loss: 2.4288117283490984

Epoch: 6| Step: 10
Training loss: 0.19991646862583387
Validation loss: 2.438070781003425

Epoch: 6| Step: 11
Training loss: 0.21547521212198148
Validation loss: 2.4712409561236313

Epoch: 6| Step: 12
Training loss: 0.2952949362279965
Validation loss: 2.4659841482113087

Epoch: 6| Step: 13
Training loss: 0.17387810535043782
Validation loss: 2.4642095842565337

Epoch: 386| Step: 0
Training loss: 0.20587046012493557
Validation loss: 2.412795172266592

Epoch: 6| Step: 1
Training loss: 0.11687130390534542
Validation loss: 2.3896793310327125

Epoch: 6| Step: 2
Training loss: 0.3229636637522947
Validation loss: 2.407032683638673

Epoch: 6| Step: 3
Training loss: 0.20950475415705513
Validation loss: 2.4097825919768803

Epoch: 6| Step: 4
Training loss: 0.2700659106744807
Validation loss: 2.37068489456766

Epoch: 6| Step: 5
Training loss: 0.2755447118948429
Validation loss: 2.345141119806119

Epoch: 6| Step: 6
Training loss: 0.3168179929493766
Validation loss: 2.3430257973182322

Epoch: 6| Step: 7
Training loss: 0.18025927172847123
Validation loss: 2.347036403569128

Epoch: 6| Step: 8
Training loss: 0.2657155135154008
Validation loss: 2.3708719194135104

Epoch: 6| Step: 9
Training loss: 0.2524106802032647
Validation loss: 2.4007408318964982

Epoch: 6| Step: 10
Training loss: 0.19135423848900635
Validation loss: 2.376786573070447

Epoch: 6| Step: 11
Training loss: 0.23110702998787458
Validation loss: 2.3709577109290896

Epoch: 6| Step: 12
Training loss: 0.19047753148727997
Validation loss: 2.405223396779325

Epoch: 6| Step: 13
Training loss: 0.10802813592267535
Validation loss: 2.3497873810527063

Epoch: 387| Step: 0
Training loss: 0.28061827602699463
Validation loss: 2.374812993673374

Epoch: 6| Step: 1
Training loss: 0.22041117507773464
Validation loss: 2.3838396682331884

Epoch: 6| Step: 2
Training loss: 0.200014516556938
Validation loss: 2.4156320802171765

Epoch: 6| Step: 3
Training loss: 0.22243538995327763
Validation loss: 2.3992314989992582

Epoch: 6| Step: 4
Training loss: 0.22813814726268422
Validation loss: 2.417777656511792

Epoch: 6| Step: 5
Training loss: 0.17566368091958312
Validation loss: 2.4263447269631637

Epoch: 6| Step: 6
Training loss: 0.2560867580462468
Validation loss: 2.4163236859097257

Epoch: 6| Step: 7
Training loss: 0.2045766785239164
Validation loss: 2.404554000829309

Epoch: 6| Step: 8
Training loss: 0.1697747207202701
Validation loss: 2.4536688448486164

Epoch: 6| Step: 9
Training loss: 0.2700790974205283
Validation loss: 2.4446655180771364

Epoch: 6| Step: 10
Training loss: 0.18423542542571028
Validation loss: 2.470717776091861

Epoch: 6| Step: 11
Training loss: 0.09099485176648789
Validation loss: 2.422821627358121

Epoch: 6| Step: 12
Training loss: 0.2701125993428614
Validation loss: 2.421390342315555

Epoch: 6| Step: 13
Training loss: 0.3038495719443704
Validation loss: 2.429764658719617

Epoch: 388| Step: 0
Training loss: 0.26532928049783805
Validation loss: 2.430172120147953

Epoch: 6| Step: 1
Training loss: 0.21776587639927097
Validation loss: 2.4447489821751183

Epoch: 6| Step: 2
Training loss: 0.17676110027480108
Validation loss: 2.4462362908139283

Epoch: 6| Step: 3
Training loss: 0.2574664886204914
Validation loss: 2.4111009817290423

Epoch: 6| Step: 4
Training loss: 0.2602972456182187
Validation loss: 2.413359591764373

Epoch: 6| Step: 5
Training loss: 0.1936818622169887
Validation loss: 2.381967408614366

Epoch: 6| Step: 6
Training loss: 0.18677314301222359
Validation loss: 2.3662500990921163

Epoch: 6| Step: 7
Training loss: 0.20837295076063972
Validation loss: 2.3382394952029033

Epoch: 6| Step: 8
Training loss: 0.2391794037307135
Validation loss: 2.3501319609948528

Epoch: 6| Step: 9
Training loss: 0.14363086392033006
Validation loss: 2.3358383193323613

Epoch: 6| Step: 10
Training loss: 0.3849045943044718
Validation loss: 2.360907830550414

Epoch: 6| Step: 11
Training loss: 0.1822884809124819
Validation loss: 2.3473514224328342

Epoch: 6| Step: 12
Training loss: 0.15649123642915105
Validation loss: 2.3766683055182147

Epoch: 6| Step: 13
Training loss: 0.05495374023092023
Validation loss: 2.373798290860201

Epoch: 389| Step: 0
Training loss: 0.13282550720024308
Validation loss: 2.356010180917382

Epoch: 6| Step: 1
Training loss: 0.09779999167776511
Validation loss: 2.404628959277468

Epoch: 6| Step: 2
Training loss: 0.23492669500513005
Validation loss: 2.434046565156108

Epoch: 6| Step: 3
Training loss: 0.2679979136086854
Validation loss: 2.406571977049208

Epoch: 6| Step: 4
Training loss: 0.1925807747648913
Validation loss: 2.420310849566986

Epoch: 6| Step: 5
Training loss: 0.22310317509762975
Validation loss: 2.442449210189242

Epoch: 6| Step: 6
Training loss: 0.18160846384465304
Validation loss: 2.4410734242643004

Epoch: 6| Step: 7
Training loss: 0.3246751124246634
Validation loss: 2.4283264619266363

Epoch: 6| Step: 8
Training loss: 0.26161698597655253
Validation loss: 2.4240912600120232

Epoch: 6| Step: 9
Training loss: 0.13801005759249949
Validation loss: 2.4031413143908926

Epoch: 6| Step: 10
Training loss: 0.10243700034355417
Validation loss: 2.4095462339480194

Epoch: 6| Step: 11
Training loss: 0.19652167813645796
Validation loss: 2.4076653355855897

Epoch: 6| Step: 12
Training loss: 0.1532780048287373
Validation loss: 2.4108932649177444

Epoch: 6| Step: 13
Training loss: 0.14904244652897694
Validation loss: 2.3949826148413886

Epoch: 390| Step: 0
Training loss: 0.08927891792673759
Validation loss: 2.4124099486381585

Epoch: 6| Step: 1
Training loss: 0.14671190393134542
Validation loss: 2.391982069038906

Epoch: 6| Step: 2
Training loss: 0.19943782504158944
Validation loss: 2.406340858503083

Epoch: 6| Step: 3
Training loss: 0.20689966410583824
Validation loss: 2.407407615605694

Epoch: 6| Step: 4
Training loss: 0.28602272493771147
Validation loss: 2.3893732320061143

Epoch: 6| Step: 5
Training loss: 0.17740933596111053
Validation loss: 2.4107773944828104

Epoch: 6| Step: 6
Training loss: 0.14239243604374188
Validation loss: 2.3896031912764486

Epoch: 6| Step: 7
Training loss: 0.18650602089620563
Validation loss: 2.392783270406467

Epoch: 6| Step: 8
Training loss: 0.21371667172676054
Validation loss: 2.43183213479853

Epoch: 6| Step: 9
Training loss: 0.15270604556253484
Validation loss: 2.4465745535596657

Epoch: 6| Step: 10
Training loss: 0.1698056733511069
Validation loss: 2.454588423850679

Epoch: 6| Step: 11
Training loss: 0.15570143726006466
Validation loss: 2.4359787263234813

Epoch: 6| Step: 12
Training loss: 0.3392810767437634
Validation loss: 2.432062013350754

Epoch: 6| Step: 13
Training loss: 0.09189995598667448
Validation loss: 2.4691806872888318

Epoch: 391| Step: 0
Training loss: 0.18693854790434983
Validation loss: 2.476432414125734

Epoch: 6| Step: 1
Training loss: 0.19038419913811075
Validation loss: 2.4630451709325523

Epoch: 6| Step: 2
Training loss: 0.14884345483800698
Validation loss: 2.4487661396290745

Epoch: 6| Step: 3
Training loss: 0.19487472109074236
Validation loss: 2.4428747735999687

Epoch: 6| Step: 4
Training loss: 0.19061561702086166
Validation loss: 2.42494639591249

Epoch: 6| Step: 5
Training loss: 0.11810640236618179
Validation loss: 2.4166568915735556

Epoch: 6| Step: 6
Training loss: 0.3663429530928321
Validation loss: 2.4401884710661492

Epoch: 6| Step: 7
Training loss: 0.17236585317967604
Validation loss: 2.3745533323996724

Epoch: 6| Step: 8
Training loss: 0.2826498217086324
Validation loss: 2.3993419959081086

Epoch: 6| Step: 9
Training loss: 0.09137112725200873
Validation loss: 2.3840713884619964

Epoch: 6| Step: 10
Training loss: 0.1876376064323615
Validation loss: 2.374846112890115

Epoch: 6| Step: 11
Training loss: 0.1855331114633354
Validation loss: 2.362681714667821

Epoch: 6| Step: 12
Training loss: 0.12205605995897496
Validation loss: 2.336812818557857

Epoch: 6| Step: 13
Training loss: 0.2974706246194441
Validation loss: 2.358236464506777

Epoch: 392| Step: 0
Training loss: 0.1880012408656908
Validation loss: 2.3627923464999268

Epoch: 6| Step: 1
Training loss: 0.1644367196243252
Validation loss: 2.3780955384296782

Epoch: 6| Step: 2
Training loss: 0.12418820857415598
Validation loss: 2.3604773510735395

Epoch: 6| Step: 3
Training loss: 0.11954545594239332
Validation loss: 2.4001466086772765

Epoch: 6| Step: 4
Training loss: 0.1580120510480605
Validation loss: 2.3979998338177695

Epoch: 6| Step: 5
Training loss: 0.21223020045284965
Validation loss: 2.4249669846931377

Epoch: 6| Step: 6
Training loss: 0.2793504356832881
Validation loss: 2.431286163529299

Epoch: 6| Step: 7
Training loss: 0.12170817254545689
Validation loss: 2.419573326004181

Epoch: 6| Step: 8
Training loss: 0.1651911627175409
Validation loss: 2.4057996067604104

Epoch: 6| Step: 9
Training loss: 0.3580470220277082
Validation loss: 2.411866320023496

Epoch: 6| Step: 10
Training loss: 0.18882776063845247
Validation loss: 2.4459784419128034

Epoch: 6| Step: 11
Training loss: 0.17192209747232107
Validation loss: 2.4390480872216607

Epoch: 6| Step: 12
Training loss: 0.21584961118371498
Validation loss: 2.4315959793382715

Epoch: 6| Step: 13
Training loss: 0.16125702549725848
Validation loss: 2.398292438512994

Epoch: 393| Step: 0
Training loss: 0.23254833467601213
Validation loss: 2.4137102047827033

Epoch: 6| Step: 1
Training loss: 0.1478181201499458
Validation loss: 2.4187066202782765

Epoch: 6| Step: 2
Training loss: 0.2008766953082849
Validation loss: 2.4264036401342044

Epoch: 6| Step: 3
Training loss: 0.12340473558076746
Validation loss: 2.4112360881616586

Epoch: 6| Step: 4
Training loss: 0.2970609835251509
Validation loss: 2.4341949382397177

Epoch: 6| Step: 5
Training loss: 0.26904337029678094
Validation loss: 2.4621322088786965

Epoch: 6| Step: 6
Training loss: 0.18673773633121127
Validation loss: 2.4492455819381003

Epoch: 6| Step: 7
Training loss: 0.11380986084174588
Validation loss: 2.4313313521063242

Epoch: 6| Step: 8
Training loss: 0.12353447774467047
Validation loss: 2.4332039150367883

Epoch: 6| Step: 9
Training loss: 0.18202995291644797
Validation loss: 2.4579940639654363

Epoch: 6| Step: 10
Training loss: 0.12678086257867854
Validation loss: 2.4197131979868125

Epoch: 6| Step: 11
Training loss: 0.18464822487105687
Validation loss: 2.4029008687734597

Epoch: 6| Step: 12
Training loss: 0.27724498010877296
Validation loss: 2.422510937555635

Epoch: 6| Step: 13
Training loss: 0.14186774261540783
Validation loss: 2.4384660460353476

Epoch: 394| Step: 0
Training loss: 0.09798033344655024
Validation loss: 2.438874943621923

Epoch: 6| Step: 1
Training loss: 0.2443879362618997
Validation loss: 2.420109395890922

Epoch: 6| Step: 2
Training loss: 0.276535185310951
Validation loss: 2.3924229495012654

Epoch: 6| Step: 3
Training loss: 0.2424851710907882
Validation loss: 2.4043724801427606

Epoch: 6| Step: 4
Training loss: 0.17275958658371068
Validation loss: 2.3881496241241846

Epoch: 6| Step: 5
Training loss: 0.16578641664110338
Validation loss: 2.41481086910093

Epoch: 6| Step: 6
Training loss: 0.20920531456949912
Validation loss: 2.408363665811874

Epoch: 6| Step: 7
Training loss: 0.1652401765296371
Validation loss: 2.426037528529308

Epoch: 6| Step: 8
Training loss: 0.23478639577423052
Validation loss: 2.4042691588985763

Epoch: 6| Step: 9
Training loss: 0.13786031427704415
Validation loss: 2.4025691026340943

Epoch: 6| Step: 10
Training loss: 0.13615795653094342
Validation loss: 2.421723435204751

Epoch: 6| Step: 11
Training loss: 0.09567017863961308
Validation loss: 2.436460099106108

Epoch: 6| Step: 12
Training loss: 0.22268173005056255
Validation loss: 2.4277476396652777

Epoch: 6| Step: 13
Training loss: 0.18320918896690536
Validation loss: 2.4197724667580687

Epoch: 395| Step: 0
Training loss: 0.2765156242817669
Validation loss: 2.430957499336193

Epoch: 6| Step: 1
Training loss: 0.10806393777553801
Validation loss: 2.4264882255197473

Epoch: 6| Step: 2
Training loss: 0.09203818238448491
Validation loss: 2.431684344197202

Epoch: 6| Step: 3
Training loss: 0.09989694150038873
Validation loss: 2.4137735160333857

Epoch: 6| Step: 4
Training loss: 0.225842878649044
Validation loss: 2.407158628796169

Epoch: 6| Step: 5
Training loss: 0.19142620800053645
Validation loss: 2.406047182307906

Epoch: 6| Step: 6
Training loss: 0.1420008390432909
Validation loss: 2.427434683436452

Epoch: 6| Step: 7
Training loss: 0.18441269214511258
Validation loss: 2.3824269112368195

Epoch: 6| Step: 8
Training loss: 0.16948740871327672
Validation loss: 2.3949604345369213

Epoch: 6| Step: 9
Training loss: 0.24129124899033016
Validation loss: 2.413134965281393

Epoch: 6| Step: 10
Training loss: 0.216024776630487
Validation loss: 2.381349175800324

Epoch: 6| Step: 11
Training loss: 0.20440271054090137
Validation loss: 2.3910755245279356

Epoch: 6| Step: 12
Training loss: 0.17341179227608258
Validation loss: 2.396096850041523

Epoch: 6| Step: 13
Training loss: 0.14218346962089784
Validation loss: 2.4014969776795527

Epoch: 396| Step: 0
Training loss: 0.1396646156810072
Validation loss: 2.3779411622056705

Epoch: 6| Step: 1
Training loss: 0.1548029170391096
Validation loss: 2.3584307757609957

Epoch: 6| Step: 2
Training loss: 0.12311720352008143
Validation loss: 2.4048865698154183

Epoch: 6| Step: 3
Training loss: 0.2759623308555077
Validation loss: 2.3505024868681983

Epoch: 6| Step: 4
Training loss: 0.1892779316950598
Validation loss: 2.3864396796140652

Epoch: 6| Step: 5
Training loss: 0.30126477056912065
Validation loss: 2.4057201840456206

Epoch: 6| Step: 6
Training loss: 0.18871448501666838
Validation loss: 2.441437618456075

Epoch: 6| Step: 7
Training loss: 0.23208929357003613
Validation loss: 2.4367905102970533

Epoch: 6| Step: 8
Training loss: 0.10050547260892084
Validation loss: 2.4196522865866523

Epoch: 6| Step: 9
Training loss: 0.21379528840233278
Validation loss: 2.446386974067513

Epoch: 6| Step: 10
Training loss: 0.09755632056107182
Validation loss: 2.4072843815304275

Epoch: 6| Step: 11
Training loss: 0.11105189855631335
Validation loss: 2.431622115913654

Epoch: 6| Step: 12
Training loss: 0.29924381240783204
Validation loss: 2.438961187432174

Epoch: 6| Step: 13
Training loss: 0.11294953515240837
Validation loss: 2.4135049867179372

Epoch: 397| Step: 0
Training loss: 0.2527279583265278
Validation loss: 2.427897345366744

Epoch: 6| Step: 1
Training loss: 0.2008437935013143
Validation loss: 2.4367929910443786

Epoch: 6| Step: 2
Training loss: 0.303259326726133
Validation loss: 2.429791611848305

Epoch: 6| Step: 3
Training loss: 0.11627402716796441
Validation loss: 2.4315303717697536

Epoch: 6| Step: 4
Training loss: 0.19630623737560945
Validation loss: 2.418811309699651

Epoch: 6| Step: 5
Training loss: 0.20032757367625853
Validation loss: 2.422972686480842

Epoch: 6| Step: 6
Training loss: 0.16225285672242973
Validation loss: 2.403056294206237

Epoch: 6| Step: 7
Training loss: 0.21595996981306248
Validation loss: 2.4007034844811463

Epoch: 6| Step: 8
Training loss: 0.21531495526136082
Validation loss: 2.4136826018188158

Epoch: 6| Step: 9
Training loss: 0.08071616732113022
Validation loss: 2.4078641933962537

Epoch: 6| Step: 10
Training loss: 0.09009449632198585
Validation loss: 2.3728428528641254

Epoch: 6| Step: 11
Training loss: 0.19326913057044373
Validation loss: 2.371664054846453

Epoch: 6| Step: 12
Training loss: 0.1996166052507293
Validation loss: 2.389809408410676

Epoch: 6| Step: 13
Training loss: 0.15816216468379038
Validation loss: 2.3807771787954475

Epoch: 398| Step: 0
Training loss: 0.10167119738509958
Validation loss: 2.3922524598520787

Epoch: 6| Step: 1
Training loss: 0.23130474570211743
Validation loss: 2.384876932159835

Epoch: 6| Step: 2
Training loss: 0.1931296245552103
Validation loss: 2.4187903219392983

Epoch: 6| Step: 3
Training loss: 0.1810504184454165
Validation loss: 2.4029147052825346

Epoch: 6| Step: 4
Training loss: 0.10969008463072244
Validation loss: 2.3966830194565083

Epoch: 6| Step: 5
Training loss: 0.2552547153183075
Validation loss: 2.3909293328279455

Epoch: 6| Step: 6
Training loss: 0.0920692926576152
Validation loss: 2.4305457794024097

Epoch: 6| Step: 7
Training loss: 0.15346104547086756
Validation loss: 2.423424192003434

Epoch: 6| Step: 8
Training loss: 0.19793880907643044
Validation loss: 2.4231681359161987

Epoch: 6| Step: 9
Training loss: 0.13254716960240634
Validation loss: 2.4375996128886017

Epoch: 6| Step: 10
Training loss: 0.28098796187608543
Validation loss: 2.4647436358742474

Epoch: 6| Step: 11
Training loss: 0.16555296437980282
Validation loss: 2.432498303793167

Epoch: 6| Step: 12
Training loss: 0.40438764354862095
Validation loss: 2.448519442737291

Epoch: 6| Step: 13
Training loss: 0.0800522698554524
Validation loss: 2.42396750239497

Epoch: 399| Step: 0
Training loss: 0.13957619966122586
Validation loss: 2.436588932194221

Epoch: 6| Step: 1
Training loss: 0.20060331126358294
Validation loss: 2.4216317659695497

Epoch: 6| Step: 2
Training loss: 0.10013698177552356
Validation loss: 2.3713834544065207

Epoch: 6| Step: 3
Training loss: 0.21539302316796552
Validation loss: 2.376579238882166

Epoch: 6| Step: 4
Training loss: 0.3280021346621715
Validation loss: 2.3616495059886007

Epoch: 6| Step: 5
Training loss: 0.16908738882084148
Validation loss: 2.377371446568945

Epoch: 6| Step: 6
Training loss: 0.27749401373893107
Validation loss: 2.394367049318403

Epoch: 6| Step: 7
Training loss: 0.2972935812558117
Validation loss: 2.3878514925413263

Epoch: 6| Step: 8
Training loss: 0.14509468828350203
Validation loss: 2.379511338393117

Epoch: 6| Step: 9
Training loss: 0.1592793416003791
Validation loss: 2.402198619712286

Epoch: 6| Step: 10
Training loss: 0.18296297759764996
Validation loss: 2.3699480804098063

Epoch: 6| Step: 11
Training loss: 0.2824555098685176
Validation loss: 2.386343229594823

Epoch: 6| Step: 12
Training loss: 0.18201244404453118
Validation loss: 2.381052327797732

Epoch: 6| Step: 13
Training loss: 0.27249309391054827
Validation loss: 2.367254559963316

Epoch: 400| Step: 0
Training loss: 0.1154597874106689
Validation loss: 2.4121381560225172

Epoch: 6| Step: 1
Training loss: 0.164552003759716
Validation loss: 2.4152944174462703

Epoch: 6| Step: 2
Training loss: 0.20838685937553833
Validation loss: 2.424463294886988

Epoch: 6| Step: 3
Training loss: 0.29774525730862406
Validation loss: 2.4357377516545737

Epoch: 6| Step: 4
Training loss: 0.14400874232329994
Validation loss: 2.4382067103650087

Epoch: 6| Step: 5
Training loss: 0.3606880911605927
Validation loss: 2.470995860583859

Epoch: 6| Step: 6
Training loss: 0.17755964094865914
Validation loss: 2.4288555454356557

Epoch: 6| Step: 7
Training loss: 0.2787852903872288
Validation loss: 2.4387298186615762

Epoch: 6| Step: 8
Training loss: 0.27241709913657247
Validation loss: 2.4153262115279484

Epoch: 6| Step: 9
Training loss: 0.2180620342521909
Validation loss: 2.430108319772534

Epoch: 6| Step: 10
Training loss: 0.29243377159923134
Validation loss: 2.4590967583973984

Epoch: 6| Step: 11
Training loss: 0.15600797266715283
Validation loss: 2.4458572547279305

Epoch: 6| Step: 12
Training loss: 0.14917923044482803
Validation loss: 2.4478057193857383

Epoch: 6| Step: 13
Training loss: 0.21765856428757624
Validation loss: 2.4331328439934183

Epoch: 401| Step: 0
Training loss: 0.22420371367382363
Validation loss: 2.480264725747135

Epoch: 6| Step: 1
Training loss: 0.2521175912299013
Validation loss: 2.4439735031970087

Epoch: 6| Step: 2
Training loss: 0.19773895772313085
Validation loss: 2.4648295965178866

Epoch: 6| Step: 3
Training loss: 0.23030654403925316
Validation loss: 2.4250480515159762

Epoch: 6| Step: 4
Training loss: 0.12991484627030478
Validation loss: 2.440380258415828

Epoch: 6| Step: 5
Training loss: 0.1720824073931311
Validation loss: 2.444192829665504

Epoch: 6| Step: 6
Training loss: 0.29108437103789464
Validation loss: 2.4428566098948297

Epoch: 6| Step: 7
Training loss: 0.11603804156612514
Validation loss: 2.4371074526601118

Epoch: 6| Step: 8
Training loss: 0.2560180579667346
Validation loss: 2.4085761031098007

Epoch: 6| Step: 9
Training loss: 0.3747347449899821
Validation loss: 2.410768857426046

Epoch: 6| Step: 10
Training loss: 0.25949706629287356
Validation loss: 2.380672144058143

Epoch: 6| Step: 11
Training loss: 0.21559291614725648
Validation loss: 2.4213274508468

Epoch: 6| Step: 12
Training loss: 0.13936990691189416
Validation loss: 2.378070919501089

Epoch: 6| Step: 13
Training loss: 0.2916551130708553
Validation loss: 2.382821440616903

Epoch: 402| Step: 0
Training loss: 0.32024337441352707
Validation loss: 2.332934968719493

Epoch: 6| Step: 1
Training loss: 0.25994428069692066
Validation loss: 2.3234399527742102

Epoch: 6| Step: 2
Training loss: 0.2432606823017425
Validation loss: 2.3159818746306766

Epoch: 6| Step: 3
Training loss: 0.16531838813095462
Validation loss: 2.335265297165767

Epoch: 6| Step: 4
Training loss: 0.15955474758926885
Validation loss: 2.3587688419029385

Epoch: 6| Step: 5
Training loss: 0.1744682441443083
Validation loss: 2.367955813108989

Epoch: 6| Step: 6
Training loss: 0.1899856868798684
Validation loss: 2.408858768865595

Epoch: 6| Step: 7
Training loss: 0.19497145440778235
Validation loss: 2.3859525777023913

Epoch: 6| Step: 8
Training loss: 0.28697107837907604
Validation loss: 2.3775898241631843

Epoch: 6| Step: 9
Training loss: 0.2770636850336446
Validation loss: 2.3909262930367974

Epoch: 6| Step: 10
Training loss: 0.23063492037725178
Validation loss: 2.398168090362882

Epoch: 6| Step: 11
Training loss: 0.22814116812592292
Validation loss: 2.3646366000810772

Epoch: 6| Step: 12
Training loss: 0.28883383702188176
Validation loss: 2.3956250892509163

Epoch: 6| Step: 13
Training loss: 0.16350956108634285
Validation loss: 2.4022415412845253

Epoch: 403| Step: 0
Training loss: 0.2844234089991547
Validation loss: 2.43907441459274

Epoch: 6| Step: 1
Training loss: 0.161092949762586
Validation loss: 2.4600869538004164

Epoch: 6| Step: 2
Training loss: 0.22282809602852127
Validation loss: 2.450120625384099

Epoch: 6| Step: 3
Training loss: 0.18992267506476807
Validation loss: 2.4603079646104513

Epoch: 6| Step: 4
Training loss: 0.15721990440913858
Validation loss: 2.471227345010759

Epoch: 6| Step: 5
Training loss: 0.17054693858992562
Validation loss: 2.4591338319695315

Epoch: 6| Step: 6
Training loss: 0.20564865496559848
Validation loss: 2.4453942017474937

Epoch: 6| Step: 7
Training loss: 0.1397186582919515
Validation loss: 2.4497975908085543

Epoch: 6| Step: 8
Training loss: 0.1446856627543326
Validation loss: 2.46136770347455

Epoch: 6| Step: 9
Training loss: 0.26276240856876254
Validation loss: 2.4392275529471754

Epoch: 6| Step: 10
Training loss: 0.2898311576267122
Validation loss: 2.4704767587402023

Epoch: 6| Step: 11
Training loss: 0.24828117298583557
Validation loss: 2.4400448215986787

Epoch: 6| Step: 12
Training loss: 0.32788375660062935
Validation loss: 2.3975182558345596

Epoch: 6| Step: 13
Training loss: 0.21647609141431834
Validation loss: 2.3784144575649835

Epoch: 404| Step: 0
Training loss: 0.28039383379146293
Validation loss: 2.3482845524123976

Epoch: 6| Step: 1
Training loss: 0.19125959071564536
Validation loss: 2.3667783014951684

Epoch: 6| Step: 2
Training loss: 0.20845550392153928
Validation loss: 2.356636122286466

Epoch: 6| Step: 3
Training loss: 0.21284371480408007
Validation loss: 2.3441206619143173

Epoch: 6| Step: 4
Training loss: 0.3268048318162826
Validation loss: 2.3551662501629576

Epoch: 6| Step: 5
Training loss: 0.22610744454616383
Validation loss: 2.373850224085878

Epoch: 6| Step: 6
Training loss: 0.22378013788806445
Validation loss: 2.394652268043708

Epoch: 6| Step: 7
Training loss: 0.2007055897039801
Validation loss: 2.436359944547531

Epoch: 6| Step: 8
Training loss: 0.22713468088492852
Validation loss: 2.4716337585609516

Epoch: 6| Step: 9
Training loss: 0.3268681136512751
Validation loss: 2.492556987638456

Epoch: 6| Step: 10
Training loss: 0.27217911942781664
Validation loss: 2.445949402961413

Epoch: 6| Step: 11
Training loss: 0.25908258454586897
Validation loss: 2.4622065207097963

Epoch: 6| Step: 12
Training loss: 0.17898226293402494
Validation loss: 2.4055513726961224

Epoch: 6| Step: 13
Training loss: 0.10542729234041824
Validation loss: 2.4453362102683296

Epoch: 405| Step: 0
Training loss: 0.24133486788027567
Validation loss: 2.3923925419971

Epoch: 6| Step: 1
Training loss: 0.22809300916880443
Validation loss: 2.383068029728236

Epoch: 6| Step: 2
Training loss: 0.1917726940442568
Validation loss: 2.3825957992032434

Epoch: 6| Step: 3
Training loss: 0.36365454987950263
Validation loss: 2.388127171025325

Epoch: 6| Step: 4
Training loss: 0.23132238060783233
Validation loss: 2.3955574536665933

Epoch: 6| Step: 5
Training loss: 0.19735204106882895
Validation loss: 2.4276935747309984

Epoch: 6| Step: 6
Training loss: 0.23150236496942908
Validation loss: 2.4177125397485777

Epoch: 6| Step: 7
Training loss: 0.29015607432255847
Validation loss: 2.4128970263725424

Epoch: 6| Step: 8
Training loss: 0.1938954445766138
Validation loss: 2.404704645663394

Epoch: 6| Step: 9
Training loss: 0.2932458203173158
Validation loss: 2.4079280670541015

Epoch: 6| Step: 10
Training loss: 0.16236855573471853
Validation loss: 2.385696937040194

Epoch: 6| Step: 11
Training loss: 0.2879915115004534
Validation loss: 2.3401201104034537

Epoch: 6| Step: 12
Training loss: 0.24519770086443093
Validation loss: 2.3557165628374164

Epoch: 6| Step: 13
Training loss: 0.26276932705357486
Validation loss: 2.3004277511022257

Epoch: 406| Step: 0
Training loss: 0.21212663843705673
Validation loss: 2.3365469884497245

Epoch: 6| Step: 1
Training loss: 0.24774261647364995
Validation loss: 2.3680671236161044

Epoch: 6| Step: 2
Training loss: 0.39640420187668
Validation loss: 2.360308307654577

Epoch: 6| Step: 3
Training loss: 0.21946539722648026
Validation loss: 2.3747659879894503

Epoch: 6| Step: 4
Training loss: 0.14783330348562687
Validation loss: 2.385659884967834

Epoch: 6| Step: 5
Training loss: 0.29136043321355237
Validation loss: 2.407688925732938

Epoch: 6| Step: 6
Training loss: 0.26211637211881694
Validation loss: 2.3813687753827004

Epoch: 6| Step: 7
Training loss: 0.2631616671740404
Validation loss: 2.408459309567677

Epoch: 6| Step: 8
Training loss: 0.2802224993522451
Validation loss: 2.4178222758198786

Epoch: 6| Step: 9
Training loss: 0.1785334972558659
Validation loss: 2.4064097570521343

Epoch: 6| Step: 10
Training loss: 0.17954024210190828
Validation loss: 2.426623680138445

Epoch: 6| Step: 11
Training loss: 0.1791771815415613
Validation loss: 2.4174603586386554

Epoch: 6| Step: 12
Training loss: 0.23145939586943745
Validation loss: 2.4085547600641233

Epoch: 6| Step: 13
Training loss: 0.41328782363019145
Validation loss: 2.425459248178755

Epoch: 407| Step: 0
Training loss: 0.3293636195552966
Validation loss: 2.4087615152559474

Epoch: 6| Step: 1
Training loss: 0.3155992129149854
Validation loss: 2.4026392649151416

Epoch: 6| Step: 2
Training loss: 0.19003694578209274
Validation loss: 2.430224307605402

Epoch: 6| Step: 3
Training loss: 0.2977475719585118
Validation loss: 2.413773488020806

Epoch: 6| Step: 4
Training loss: 0.22816960310253898
Validation loss: 2.3951678467770576

Epoch: 6| Step: 5
Training loss: 0.5428911606493262
Validation loss: 2.430179649637958

Epoch: 6| Step: 6
Training loss: 0.3399574265051637
Validation loss: 2.451727333175145

Epoch: 6| Step: 7
Training loss: 0.4637080993899691
Validation loss: 2.510711163152414

Epoch: 6| Step: 8
Training loss: 0.476866296961251
Validation loss: 2.511401743509531

Epoch: 6| Step: 9
Training loss: 0.238345215763533
Validation loss: 2.525377994519695

Epoch: 6| Step: 10
Training loss: 0.5164808337762873
Validation loss: 2.5036380364302113

Epoch: 6| Step: 11
Training loss: 0.22787731225927385
Validation loss: 2.4668459254544444

Epoch: 6| Step: 12
Training loss: 0.28975704880830566
Validation loss: 2.4475001074753546

Epoch: 6| Step: 13
Training loss: 0.17326290948531953
Validation loss: 2.418162621911856

Epoch: 408| Step: 0
Training loss: 0.21507876286964592
Validation loss: 2.388174571227485

Epoch: 6| Step: 1
Training loss: 0.2075340714690078
Validation loss: 2.4091998936005354

Epoch: 6| Step: 2
Training loss: 0.42525484634678845
Validation loss: 2.4028284511817937

Epoch: 6| Step: 3
Training loss: 0.18542456360048515
Validation loss: 2.43007577015437

Epoch: 6| Step: 4
Training loss: 0.29958657398027444
Validation loss: 2.4170464880925864

Epoch: 6| Step: 5
Training loss: 0.3425655549721718
Validation loss: 2.446411701406718

Epoch: 6| Step: 6
Training loss: 0.3502408935702685
Validation loss: 2.4557998999022486

Epoch: 6| Step: 7
Training loss: 0.38796914372940766
Validation loss: 2.4659552850682203

Epoch: 6| Step: 8
Training loss: 0.29707684682146657
Validation loss: 2.4215721764061913

Epoch: 6| Step: 9
Training loss: 0.3611320582248368
Validation loss: 2.438679754864479

Epoch: 6| Step: 10
Training loss: 0.2346389158808636
Validation loss: 2.4242089961656728

Epoch: 6| Step: 11
Training loss: 0.33779842022712175
Validation loss: 2.464268769061781

Epoch: 6| Step: 12
Training loss: 0.31428094260739436
Validation loss: 2.4480338102407715

Epoch: 6| Step: 13
Training loss: 0.32157013723722155
Validation loss: 2.466514875721455

Epoch: 409| Step: 0
Training loss: 0.29064949096524867
Validation loss: 2.495408002179186

Epoch: 6| Step: 1
Training loss: 0.3417402166000116
Validation loss: 2.438172847287153

Epoch: 6| Step: 2
Training loss: 0.3776457358093411
Validation loss: 2.4604874185813435

Epoch: 6| Step: 3
Training loss: 0.3572510483047662
Validation loss: 2.454597496779088

Epoch: 6| Step: 4
Training loss: 0.28851879381536005
Validation loss: 2.42816893974568

Epoch: 6| Step: 5
Training loss: 0.44385776151561984
Validation loss: 2.4332519442906797

Epoch: 6| Step: 6
Training loss: 0.31625323657690313
Validation loss: 2.424037331919644

Epoch: 6| Step: 7
Training loss: 0.21367149457601264
Validation loss: 2.4134100549267465

Epoch: 6| Step: 8
Training loss: 0.4748781173334628
Validation loss: 2.3787132869369123

Epoch: 6| Step: 9
Training loss: 0.26257643438338074
Validation loss: 2.3887418305174424

Epoch: 6| Step: 10
Training loss: 0.32444121300562867
Validation loss: 2.398990499077338

Epoch: 6| Step: 11
Training loss: 0.36749165700667674
Validation loss: 2.4074370374592418

Epoch: 6| Step: 12
Training loss: 0.3714693076430479
Validation loss: 2.3879349885101244

Epoch: 6| Step: 13
Training loss: 0.3421243679039398
Validation loss: 2.3867439204378895

Epoch: 410| Step: 0
Training loss: 0.3706577550620956
Validation loss: 2.3838946196634834

Epoch: 6| Step: 1
Training loss: 0.30550848563407523
Validation loss: 2.351552007208396

Epoch: 6| Step: 2
Training loss: 0.2583145253323344
Validation loss: 2.3464916423383246

Epoch: 6| Step: 3
Training loss: 0.32169551706190624
Validation loss: 2.3443507741905303

Epoch: 6| Step: 4
Training loss: 0.2558853340084088
Validation loss: 2.3235405006503265

Epoch: 6| Step: 5
Training loss: 0.37155981410975164
Validation loss: 2.3605549895919338

Epoch: 6| Step: 6
Training loss: 0.2749179815313142
Validation loss: 2.3349266173756447

Epoch: 6| Step: 7
Training loss: 0.32760142379283663
Validation loss: 2.3764456066437636

Epoch: 6| Step: 8
Training loss: 0.19129358595924773
Validation loss: 2.3778936572677565

Epoch: 6| Step: 9
Training loss: 0.1905058879493053
Validation loss: 2.381463720620224

Epoch: 6| Step: 10
Training loss: 0.2326675527067538
Validation loss: 2.392322676622592

Epoch: 6| Step: 11
Training loss: 0.22340011984252875
Validation loss: 2.4003773698941666

Epoch: 6| Step: 12
Training loss: 0.3712152382602412
Validation loss: 2.404157417701698

Epoch: 6| Step: 13
Training loss: 0.2485844876058172
Validation loss: 2.4038079607874083

Epoch: 411| Step: 0
Training loss: 0.16366161459943546
Validation loss: 2.382997205687405

Epoch: 6| Step: 1
Training loss: 0.27988434742561896
Validation loss: 2.428545716239987

Epoch: 6| Step: 2
Training loss: 0.2478902277085192
Validation loss: 2.3652252703535375

Epoch: 6| Step: 3
Training loss: 0.26145349411963154
Validation loss: 2.3515848094615213

Epoch: 6| Step: 4
Training loss: 0.29781641518259877
Validation loss: 2.3837627789492823

Epoch: 6| Step: 5
Training loss: 0.20559088771861092
Validation loss: 2.4177386286540385

Epoch: 6| Step: 6
Training loss: 0.3648565040989371
Validation loss: 2.4128140797175384

Epoch: 6| Step: 7
Training loss: 0.2813808083987542
Validation loss: 2.432702772162475

Epoch: 6| Step: 8
Training loss: 0.3283192422952632
Validation loss: 2.4438118603402774

Epoch: 6| Step: 9
Training loss: 0.2631244769963302
Validation loss: 2.4506405921896928

Epoch: 6| Step: 10
Training loss: 0.20263079898873812
Validation loss: 2.4700653406037882

Epoch: 6| Step: 11
Training loss: 0.2420547567641463
Validation loss: 2.4595328967858037

Epoch: 6| Step: 12
Training loss: 0.20766569487804593
Validation loss: 2.4540623789691547

Epoch: 6| Step: 13
Training loss: 0.16863085858960686
Validation loss: 2.4522338632236744

Epoch: 412| Step: 0
Training loss: 0.29711713453256616
Validation loss: 2.4664343413413183

Epoch: 6| Step: 1
Training loss: 0.22625226945687263
Validation loss: 2.4502677447219523

Epoch: 6| Step: 2
Training loss: 0.32806799030052114
Validation loss: 2.4431440429778095

Epoch: 6| Step: 3
Training loss: 0.2009140325164209
Validation loss: 2.4364024863263936

Epoch: 6| Step: 4
Training loss: 0.23282606578193019
Validation loss: 2.435107940828723

Epoch: 6| Step: 5
Training loss: 0.19806952074282583
Validation loss: 2.45116620525807

Epoch: 6| Step: 6
Training loss: 0.21220755579216946
Validation loss: 2.434343200127951

Epoch: 6| Step: 7
Training loss: 0.2675864782212916
Validation loss: 2.398423132078951

Epoch: 6| Step: 8
Training loss: 0.22117260143520506
Validation loss: 2.393626200035504

Epoch: 6| Step: 9
Training loss: 0.19342912514079177
Validation loss: 2.41074335773381

Epoch: 6| Step: 10
Training loss: 0.19787650370071674
Validation loss: 2.430714364691644

Epoch: 6| Step: 11
Training loss: 0.1894845444886192
Validation loss: 2.3977119182269235

Epoch: 6| Step: 12
Training loss: 0.28446631380312143
Validation loss: 2.39642903616172

Epoch: 6| Step: 13
Training loss: 0.2770067370220346
Validation loss: 2.396367409892334

Epoch: 413| Step: 0
Training loss: 0.20004711713703985
Validation loss: 2.425967063350795

Epoch: 6| Step: 1
Training loss: 0.1484800202554926
Validation loss: 2.4511161590978157

Epoch: 6| Step: 2
Training loss: 0.11639409097751534
Validation loss: 2.4286603388914645

Epoch: 6| Step: 3
Training loss: 0.27281133618712844
Validation loss: 2.4502836688934093

Epoch: 6| Step: 4
Training loss: 0.20986208695701575
Validation loss: 2.456582858352375

Epoch: 6| Step: 5
Training loss: 0.26594109520459946
Validation loss: 2.4718555104568147

Epoch: 6| Step: 6
Training loss: 0.2565029001183552
Validation loss: 2.453121224227977

Epoch: 6| Step: 7
Training loss: 0.12119378295830316
Validation loss: 2.466046204878166

Epoch: 6| Step: 8
Training loss: 0.21518406357847988
Validation loss: 2.4740497479391363

Epoch: 6| Step: 9
Training loss: 0.2527641726915067
Validation loss: 2.4914238325131484

Epoch: 6| Step: 10
Training loss: 0.342816515875552
Validation loss: 2.4692064088986885

Epoch: 6| Step: 11
Training loss: 0.19157660941083013
Validation loss: 2.4181085541790885

Epoch: 6| Step: 12
Training loss: 0.14801552045438512
Validation loss: 2.4279608701819533

Epoch: 6| Step: 13
Training loss: 0.2507372208445244
Validation loss: 2.4391488786905002

Epoch: 414| Step: 0
Training loss: 0.1612031667457313
Validation loss: 2.42569943696081

Epoch: 6| Step: 1
Training loss: 0.1877855471028736
Validation loss: 2.4560473438033195

Epoch: 6| Step: 2
Training loss: 0.2670040655389145
Validation loss: 2.4420468686566377

Epoch: 6| Step: 3
Training loss: 0.12471331563363415
Validation loss: 2.4387600179118647

Epoch: 6| Step: 4
Training loss: 0.24658444091828094
Validation loss: 2.409586102013553

Epoch: 6| Step: 5
Training loss: 0.3284689712509152
Validation loss: 2.4505751550176513

Epoch: 6| Step: 6
Training loss: 0.2932585999040027
Validation loss: 2.4629683134464955

Epoch: 6| Step: 7
Training loss: 0.19524992894209228
Validation loss: 2.4580836210099726

Epoch: 6| Step: 8
Training loss: 0.2512042574972355
Validation loss: 2.4248874349150418

Epoch: 6| Step: 9
Training loss: 0.30791296892608566
Validation loss: 2.4242361234231584

Epoch: 6| Step: 10
Training loss: 0.16081065137084524
Validation loss: 2.4158351321211704

Epoch: 6| Step: 11
Training loss: 0.20286310258226187
Validation loss: 2.4047158033748794

Epoch: 6| Step: 12
Training loss: 0.10003511289212569
Validation loss: 2.4117204350987542

Epoch: 6| Step: 13
Training loss: 0.16699774214223315
Validation loss: 2.452323702758568

Epoch: 415| Step: 0
Training loss: 0.19911872933458682
Validation loss: 2.4231217894840915

Epoch: 6| Step: 1
Training loss: 0.17392209545515985
Validation loss: 2.4424003869446858

Epoch: 6| Step: 2
Training loss: 0.34222792556468606
Validation loss: 2.4370106136649987

Epoch: 6| Step: 3
Training loss: 0.25587684629936125
Validation loss: 2.426717249353707

Epoch: 6| Step: 4
Training loss: 0.12930551021817335
Validation loss: 2.4226431230238608

Epoch: 6| Step: 5
Training loss: 0.19798404818154058
Validation loss: 2.4343703545181383

Epoch: 6| Step: 6
Training loss: 0.17426376188957018
Validation loss: 2.4457111061937495

Epoch: 6| Step: 7
Training loss: 0.220868942962975
Validation loss: 2.446273576579649

Epoch: 6| Step: 8
Training loss: 0.15783964598755632
Validation loss: 2.462938110729637

Epoch: 6| Step: 9
Training loss: 0.17003873117398408
Validation loss: 2.450652565940198

Epoch: 6| Step: 10
Training loss: 0.20879378496330128
Validation loss: 2.4525667569985483

Epoch: 6| Step: 11
Training loss: 0.21193853140343505
Validation loss: 2.3961084372864

Epoch: 6| Step: 12
Training loss: 0.18121482820275006
Validation loss: 2.4194845977632635

Epoch: 6| Step: 13
Training loss: 0.31082500742345665
Validation loss: 2.4135136606804632

Epoch: 416| Step: 0
Training loss: 0.16466314627945464
Validation loss: 2.4358790734615585

Epoch: 6| Step: 1
Training loss: 0.26522600837736604
Validation loss: 2.4396438899086625

Epoch: 6| Step: 2
Training loss: 0.12670416997388542
Validation loss: 2.430046534836889

Epoch: 6| Step: 3
Training loss: 0.17094688818638487
Validation loss: 2.411493544630557

Epoch: 6| Step: 4
Training loss: 0.2789077448871632
Validation loss: 2.406585518679536

Epoch: 6| Step: 5
Training loss: 0.2660097813349523
Validation loss: 2.4033173827851133

Epoch: 6| Step: 6
Training loss: 0.160230875074681
Validation loss: 2.420465922818991

Epoch: 6| Step: 7
Training loss: 0.1302221068408921
Validation loss: 2.410733492335753

Epoch: 6| Step: 8
Training loss: 0.19328009781613542
Validation loss: 2.4045603018299517

Epoch: 6| Step: 9
Training loss: 0.3341376192868794
Validation loss: 2.423912287567534

Epoch: 6| Step: 10
Training loss: 0.200932758773706
Validation loss: 2.450855826231532

Epoch: 6| Step: 11
Training loss: 0.2009154416816557
Validation loss: 2.4376855531906987

Epoch: 6| Step: 12
Training loss: 0.17718901122254405
Validation loss: 2.466038683539658

Epoch: 6| Step: 13
Training loss: 0.15867133380416315
Validation loss: 2.44907551243705

Epoch: 417| Step: 0
Training loss: 0.1648938143669419
Validation loss: 2.44365233017462

Epoch: 6| Step: 1
Training loss: 0.19476680817992548
Validation loss: 2.452640863721113

Epoch: 6| Step: 2
Training loss: 0.28370775448151875
Validation loss: 2.458236343767528

Epoch: 6| Step: 3
Training loss: 0.28454004622913315
Validation loss: 2.442246751321926

Epoch: 6| Step: 4
Training loss: 0.1301373447183883
Validation loss: 2.4085515775371196

Epoch: 6| Step: 5
Training loss: 0.15358143335051333
Validation loss: 2.4055269122004157

Epoch: 6| Step: 6
Training loss: 0.17112590365732033
Validation loss: 2.443665536235368

Epoch: 6| Step: 7
Training loss: 0.14209839051225742
Validation loss: 2.3803740754004967

Epoch: 6| Step: 8
Training loss: 0.22769808635504366
Validation loss: 2.392241611853166

Epoch: 6| Step: 9
Training loss: 0.2790534018627871
Validation loss: 2.3908362802278673

Epoch: 6| Step: 10
Training loss: 0.21282804951877543
Validation loss: 2.400657493524176

Epoch: 6| Step: 11
Training loss: 0.19344125805656906
Validation loss: 2.3618389813930034

Epoch: 6| Step: 12
Training loss: 0.2232131518607633
Validation loss: 2.423253785057001

Epoch: 6| Step: 13
Training loss: 0.32405488342781
Validation loss: 2.436601104409254

Epoch: 418| Step: 0
Training loss: 0.25406971584550414
Validation loss: 2.412160545571253

Epoch: 6| Step: 1
Training loss: 0.26692768034829467
Validation loss: 2.4502194484415742

Epoch: 6| Step: 2
Training loss: 0.2190118312601013
Validation loss: 2.4578372947787175

Epoch: 6| Step: 3
Training loss: 0.12796391327768677
Validation loss: 2.4682350166740905

Epoch: 6| Step: 4
Training loss: 0.41770648749776845
Validation loss: 2.4744412383618766

Epoch: 6| Step: 5
Training loss: 0.23581807606704336
Validation loss: 2.4741688068971817

Epoch: 6| Step: 6
Training loss: 0.10391894528267444
Validation loss: 2.456566744381398

Epoch: 6| Step: 7
Training loss: 0.210619678189541
Validation loss: 2.4691072607622098

Epoch: 6| Step: 8
Training loss: 0.20729640858624263
Validation loss: 2.4553147170481067

Epoch: 6| Step: 9
Training loss: 0.1969120898958613
Validation loss: 2.475400555381289

Epoch: 6| Step: 10
Training loss: 0.32631883337205353
Validation loss: 2.455687879254167

Epoch: 6| Step: 11
Training loss: 0.32220185544789776
Validation loss: 2.433710077347451

Epoch: 6| Step: 12
Training loss: 0.15510556004754253
Validation loss: 2.4390031130912107

Epoch: 6| Step: 13
Training loss: 0.23553482613183827
Validation loss: 2.4048359507157024

Epoch: 419| Step: 0
Training loss: 0.22028872314279793
Validation loss: 2.42781147567825

Epoch: 6| Step: 1
Training loss: 0.23353748887930884
Validation loss: 2.4511599189516717

Epoch: 6| Step: 2
Training loss: 0.31536500816831103
Validation loss: 2.451007128143224

Epoch: 6| Step: 3
Training loss: 0.19037418045573876
Validation loss: 2.4179677353447846

Epoch: 6| Step: 4
Training loss: 0.294596056296969
Validation loss: 2.4249294942165793

Epoch: 6| Step: 5
Training loss: 0.1722115613478466
Validation loss: 2.4015176618142813

Epoch: 6| Step: 6
Training loss: 0.18141802612380004
Validation loss: 2.3952993578129176

Epoch: 6| Step: 7
Training loss: 0.21278158072486394
Validation loss: 2.388363404817125

Epoch: 6| Step: 8
Training loss: 0.14995129311052674
Validation loss: 2.4197425369622536

Epoch: 6| Step: 9
Training loss: 0.3050015860266175
Validation loss: 2.3747920591323033

Epoch: 6| Step: 10
Training loss: 0.25461331732273834
Validation loss: 2.3835244016203108

Epoch: 6| Step: 11
Training loss: 0.18526000886074506
Validation loss: 2.3900765043063754

Epoch: 6| Step: 12
Training loss: 0.10696372387172381
Validation loss: 2.3890363656141567

Epoch: 6| Step: 13
Training loss: 0.22658359495152303
Validation loss: 2.4212747095202376

Epoch: 420| Step: 0
Training loss: 0.21969210884393062
Validation loss: 2.415538997515032

Epoch: 6| Step: 1
Training loss: 0.1641338851576268
Validation loss: 2.4232265907314594

Epoch: 6| Step: 2
Training loss: 0.23887261503826573
Validation loss: 2.445350765927588

Epoch: 6| Step: 3
Training loss: 0.25292080602186073
Validation loss: 2.4601604171693303

Epoch: 6| Step: 4
Training loss: 0.23360749781542436
Validation loss: 2.4277457278219203

Epoch: 6| Step: 5
Training loss: 0.22852062154670763
Validation loss: 2.4534194755957666

Epoch: 6| Step: 6
Training loss: 0.18470141886045832
Validation loss: 2.4523143098895934

Epoch: 6| Step: 7
Training loss: 0.2734795674253075
Validation loss: 2.4663753467476695

Epoch: 6| Step: 8
Training loss: 0.18307425677992398
Validation loss: 2.441236874585041

Epoch: 6| Step: 9
Training loss: 0.25988166053111855
Validation loss: 2.481602206011327

Epoch: 6| Step: 10
Training loss: 0.1346021573018531
Validation loss: 2.4659927927419094

Epoch: 6| Step: 11
Training loss: 0.2248474932101204
Validation loss: 2.4210367787895266

Epoch: 6| Step: 12
Training loss: 0.26815142785833274
Validation loss: 2.456142457354263

Epoch: 6| Step: 13
Training loss: 0.13047888225340884
Validation loss: 2.4435816815731326

Epoch: 421| Step: 0
Training loss: 0.15232397831480732
Validation loss: 2.456293239493154

Epoch: 6| Step: 1
Training loss: 0.19691589248675626
Validation loss: 2.4476134025761813

Epoch: 6| Step: 2
Training loss: 0.23026715367926653
Validation loss: 2.443442315051629

Epoch: 6| Step: 3
Training loss: 0.14902481788405905
Validation loss: 2.4540352178725353

Epoch: 6| Step: 4
Training loss: 0.28385518741715776
Validation loss: 2.4628910465673886

Epoch: 6| Step: 5
Training loss: 0.3256407313473214
Validation loss: 2.4800206522572905

Epoch: 6| Step: 6
Training loss: 0.17391157825872502
Validation loss: 2.4434867322000073

Epoch: 6| Step: 7
Training loss: 0.19166072161583436
Validation loss: 2.467405801408728

Epoch: 6| Step: 8
Training loss: 0.1736339813639343
Validation loss: 2.4499447525656204

Epoch: 6| Step: 9
Training loss: 0.20015965586138718
Validation loss: 2.461542158169905

Epoch: 6| Step: 10
Training loss: 0.20434861995752784
Validation loss: 2.477191958276067

Epoch: 6| Step: 11
Training loss: 0.31051676382277227
Validation loss: 2.439267077776319

Epoch: 6| Step: 12
Training loss: 0.20318400002970363
Validation loss: 2.4552790517738243

Epoch: 6| Step: 13
Training loss: 0.1520386783533647
Validation loss: 2.460000501246301

Epoch: 422| Step: 0
Training loss: 0.17156385304832897
Validation loss: 2.4117568667641285

Epoch: 6| Step: 1
Training loss: 0.21406328451750736
Validation loss: 2.4353520426894786

Epoch: 6| Step: 2
Training loss: 0.19401640957445362
Validation loss: 2.4330258821321475

Epoch: 6| Step: 3
Training loss: 0.24221434752029436
Validation loss: 2.4270832375653995

Epoch: 6| Step: 4
Training loss: 0.09863502669917848
Validation loss: 2.413857976199279

Epoch: 6| Step: 5
Training loss: 0.15589509234451332
Validation loss: 2.410046258082775

Epoch: 6| Step: 6
Training loss: 0.25560401228761365
Validation loss: 2.4358253047824934

Epoch: 6| Step: 7
Training loss: 0.23636904275569853
Validation loss: 2.392799882487705

Epoch: 6| Step: 8
Training loss: 0.10611079086170225
Validation loss: 2.399561896467282

Epoch: 6| Step: 9
Training loss: 0.1945017868924617
Validation loss: 2.4664463725020447

Epoch: 6| Step: 10
Training loss: 0.1306939930413408
Validation loss: 2.4086867077640943

Epoch: 6| Step: 11
Training loss: 0.1534013533988998
Validation loss: 2.390390082032793

Epoch: 6| Step: 12
Training loss: 0.24273725379633948
Validation loss: 2.4065458224826655

Epoch: 6| Step: 13
Training loss: 0.09433659184072953
Validation loss: 2.396318351976734

Epoch: 423| Step: 0
Training loss: 0.23114357767699253
Validation loss: 2.385256891469892

Epoch: 6| Step: 1
Training loss: 0.18233468138593362
Validation loss: 2.4008457265024887

Epoch: 6| Step: 2
Training loss: 0.20385640766553942
Validation loss: 2.417992003193848

Epoch: 6| Step: 3
Training loss: 0.14110268153735397
Validation loss: 2.4173529880573446

Epoch: 6| Step: 4
Training loss: 0.09522600353082233
Validation loss: 2.421192100696999

Epoch: 6| Step: 5
Training loss: 0.1126033171118249
Validation loss: 2.3821690952713217

Epoch: 6| Step: 6
Training loss: 0.2531455455495114
Validation loss: 2.412078950492547

Epoch: 6| Step: 7
Training loss: 0.25402887757665027
Validation loss: 2.4022552609997696

Epoch: 6| Step: 8
Training loss: 0.11282186839785698
Validation loss: 2.3983659657771392

Epoch: 6| Step: 9
Training loss: 0.12588070023991793
Validation loss: 2.4398239433085616

Epoch: 6| Step: 10
Training loss: 0.14676516007079993
Validation loss: 2.394945465043483

Epoch: 6| Step: 11
Training loss: 0.16662241055092677
Validation loss: 2.4006672155845488

Epoch: 6| Step: 12
Training loss: 0.20444989937616317
Validation loss: 2.390176188187153

Epoch: 6| Step: 13
Training loss: 0.24054640378097464
Validation loss: 2.404071415597288

Epoch: 424| Step: 0
Training loss: 0.22737796139322136
Validation loss: 2.4055582396435695

Epoch: 6| Step: 1
Training loss: 0.1365109499348812
Validation loss: 2.395603816491307

Epoch: 6| Step: 2
Training loss: 0.1477958022257237
Validation loss: 2.398161255704451

Epoch: 6| Step: 3
Training loss: 0.17476734103407793
Validation loss: 2.390203513996624

Epoch: 6| Step: 4
Training loss: 0.23822740040135326
Validation loss: 2.3981151791114215

Epoch: 6| Step: 5
Training loss: 0.14414175493164472
Validation loss: 2.4049164563735435

Epoch: 6| Step: 6
Training loss: 0.10552589316662273
Validation loss: 2.398506146733545

Epoch: 6| Step: 7
Training loss: 0.13069274598916697
Validation loss: 2.3951552092556923

Epoch: 6| Step: 8
Training loss: 0.10293135306876484
Validation loss: 2.4074918953866673

Epoch: 6| Step: 9
Training loss: 0.1328128225659212
Validation loss: 2.423538653855173

Epoch: 6| Step: 10
Training loss: 0.08054139876226543
Validation loss: 2.427455835664815

Epoch: 6| Step: 11
Training loss: 0.1614425283561598
Validation loss: 2.404617651904493

Epoch: 6| Step: 12
Training loss: 0.21647240009867832
Validation loss: 2.42550855961307

Epoch: 6| Step: 13
Training loss: 0.19038284899485725
Validation loss: 2.4392292797479684

Epoch: 425| Step: 0
Training loss: 0.08698605384751727
Validation loss: 2.444359069913771

Epoch: 6| Step: 1
Training loss: 0.17959163015616963
Validation loss: 2.4518369139793266

Epoch: 6| Step: 2
Training loss: 0.16118134432409786
Validation loss: 2.44416272690993

Epoch: 6| Step: 3
Training loss: 0.16664587328265307
Validation loss: 2.4111791916170064

Epoch: 6| Step: 4
Training loss: 0.13678877263498965
Validation loss: 2.472094176732112

Epoch: 6| Step: 5
Training loss: 0.28482387716135127
Validation loss: 2.454167102031132

Epoch: 6| Step: 6
Training loss: 0.1443287358532796
Validation loss: 2.4175958307581085

Epoch: 6| Step: 7
Training loss: 0.10076959287515339
Validation loss: 2.4199321934349927

Epoch: 6| Step: 8
Training loss: 0.10650838942879727
Validation loss: 2.4019349728274486

Epoch: 6| Step: 9
Training loss: 0.2221364680165093
Validation loss: 2.419674875188961

Epoch: 6| Step: 10
Training loss: 0.10432021080011561
Validation loss: 2.393441352747147

Epoch: 6| Step: 11
Training loss: 0.16178969379736421
Validation loss: 2.390869999909647

Epoch: 6| Step: 12
Training loss: 0.18165670344245108
Validation loss: 2.4077186654400444

Epoch: 6| Step: 13
Training loss: 0.1848863187320832
Validation loss: 2.4029594698817247

Epoch: 426| Step: 0
Training loss: 0.21050153820989018
Validation loss: 2.394633790485672

Epoch: 6| Step: 1
Training loss: 0.1241394536615498
Validation loss: 2.435051959493431

Epoch: 6| Step: 2
Training loss: 0.18343925062575706
Validation loss: 2.4003701191248585

Epoch: 6| Step: 3
Training loss: 0.11128557797590749
Validation loss: 2.405293428343117

Epoch: 6| Step: 4
Training loss: 0.1817484812305752
Validation loss: 2.3903014481312406

Epoch: 6| Step: 5
Training loss: 0.17344200991875625
Validation loss: 2.4246453938815713

Epoch: 6| Step: 6
Training loss: 0.19074374979298464
Validation loss: 2.407194664101127

Epoch: 6| Step: 7
Training loss: 0.12891149510203054
Validation loss: 2.4090554051482203

Epoch: 6| Step: 8
Training loss: 0.22686858711952498
Validation loss: 2.4051191279883124

Epoch: 6| Step: 9
Training loss: 0.10044673435225189
Validation loss: 2.416751665594393

Epoch: 6| Step: 10
Training loss: 0.1576469086109222
Validation loss: 2.3901404883703057

Epoch: 6| Step: 11
Training loss: 0.1448687787740287
Validation loss: 2.3798811131959314

Epoch: 6| Step: 12
Training loss: 0.20755597860365713
Validation loss: 2.3775235263844885

Epoch: 6| Step: 13
Training loss: 0.10242129783991509
Validation loss: 2.362885575310993

Epoch: 427| Step: 0
Training loss: 0.232113890589519
Validation loss: 2.3700561301946763

Epoch: 6| Step: 1
Training loss: 0.13348299365449137
Validation loss: 2.373683559740681

Epoch: 6| Step: 2
Training loss: 0.16985989678984978
Validation loss: 2.353008295270775

Epoch: 6| Step: 3
Training loss: 0.18910834804780224
Validation loss: 2.387874950982068

Epoch: 6| Step: 4
Training loss: 0.11973742409330464
Validation loss: 2.407946913708847

Epoch: 6| Step: 5
Training loss: 0.23983910459809837
Validation loss: 2.385957383544809

Epoch: 6| Step: 6
Training loss: 0.21827224944992984
Validation loss: 2.411783781176436

Epoch: 6| Step: 7
Training loss: 0.15907776383682226
Validation loss: 2.423578418679223

Epoch: 6| Step: 8
Training loss: 0.14759890941589135
Validation loss: 2.443274648909

Epoch: 6| Step: 9
Training loss: 0.08865073851186603
Validation loss: 2.4393907822431213

Epoch: 6| Step: 10
Training loss: 0.16884975818144257
Validation loss: 2.4493039497694236

Epoch: 6| Step: 11
Training loss: 0.09239131634306952
Validation loss: 2.463595189264966

Epoch: 6| Step: 12
Training loss: 0.07885109430206425
Validation loss: 2.4759361173945615

Epoch: 6| Step: 13
Training loss: 0.23630299710444666
Validation loss: 2.483064910373135

Epoch: 428| Step: 0
Training loss: 0.19974726339310894
Validation loss: 2.4531690067011938

Epoch: 6| Step: 1
Training loss: 0.15001609537078506
Validation loss: 2.487012094439583

Epoch: 6| Step: 2
Training loss: 0.15123187138743147
Validation loss: 2.470319104152572

Epoch: 6| Step: 3
Training loss: 0.1295448365925883
Validation loss: 2.446503853643947

Epoch: 6| Step: 4
Training loss: 0.19722585938257134
Validation loss: 2.4582669520466744

Epoch: 6| Step: 5
Training loss: 0.31200022071821404
Validation loss: 2.4498980886238555

Epoch: 6| Step: 6
Training loss: 0.15812943944240157
Validation loss: 2.4495355421777534

Epoch: 6| Step: 7
Training loss: 0.11474192185629925
Validation loss: 2.43068888176004

Epoch: 6| Step: 8
Training loss: 0.14799091645384527
Validation loss: 2.428092811746885

Epoch: 6| Step: 9
Training loss: 0.12639309530571044
Validation loss: 2.4431189247440517

Epoch: 6| Step: 10
Training loss: 0.09619944195174107
Validation loss: 2.425949578302684

Epoch: 6| Step: 11
Training loss: 0.07948728401000565
Validation loss: 2.442998522052999

Epoch: 6| Step: 12
Training loss: 0.2145390690978245
Validation loss: 2.41274994784794

Epoch: 6| Step: 13
Training loss: 0.19119187436332452
Validation loss: 2.4288292561229827

Epoch: 429| Step: 0
Training loss: 0.21004259162933253
Validation loss: 2.431125023184597

Epoch: 6| Step: 1
Training loss: 0.20178364812646749
Validation loss: 2.4567625468571563

Epoch: 6| Step: 2
Training loss: 0.2171704450264218
Validation loss: 2.4560449039020784

Epoch: 6| Step: 3
Training loss: 0.10708357252550067
Validation loss: 2.4201920366387664

Epoch: 6| Step: 4
Training loss: 0.20250885387774084
Validation loss: 2.4284507015357577

Epoch: 6| Step: 5
Training loss: 0.0753384441685411
Validation loss: 2.425346412290263

Epoch: 6| Step: 6
Training loss: 0.23627390121224245
Validation loss: 2.422454400541331

Epoch: 6| Step: 7
Training loss: 0.22805075351701
Validation loss: 2.391639883857492

Epoch: 6| Step: 8
Training loss: 0.22216770884739692
Validation loss: 2.396353834590878

Epoch: 6| Step: 9
Training loss: 0.10251515427655626
Validation loss: 2.3848906128321734

Epoch: 6| Step: 10
Training loss: 0.10563337758377724
Validation loss: 2.375204953955557

Epoch: 6| Step: 11
Training loss: 0.108781674098224
Validation loss: 2.392174831987598

Epoch: 6| Step: 12
Training loss: 0.18049288708007563
Validation loss: 2.38121698798199

Epoch: 6| Step: 13
Training loss: 0.2087574912628698
Validation loss: 2.4043636612468706

Epoch: 430| Step: 0
Training loss: 0.11146610058773904
Validation loss: 2.3691927809739357

Epoch: 6| Step: 1
Training loss: 0.21023120784181287
Validation loss: 2.385635375264525

Epoch: 6| Step: 2
Training loss: 0.20685733832140357
Validation loss: 2.3971704725987992

Epoch: 6| Step: 3
Training loss: 0.13353980296922832
Validation loss: 2.372060862308641

Epoch: 6| Step: 4
Training loss: 0.11739924691875026
Validation loss: 2.402347211804427

Epoch: 6| Step: 5
Training loss: 0.09551244833681106
Validation loss: 2.370127755210872

Epoch: 6| Step: 6
Training loss: 0.19987227265415886
Validation loss: 2.382535613682761

Epoch: 6| Step: 7
Training loss: 0.24630422522800072
Validation loss: 2.3706494170616246

Epoch: 6| Step: 8
Training loss: 0.15323742369268628
Validation loss: 2.369423190821341

Epoch: 6| Step: 9
Training loss: 0.11301268608272876
Validation loss: 2.3736683858628975

Epoch: 6| Step: 10
Training loss: 0.11641214087000884
Validation loss: 2.398543147859058

Epoch: 6| Step: 11
Training loss: 0.23146853752945348
Validation loss: 2.3911229686739377

Epoch: 6| Step: 12
Training loss: 0.283274976889182
Validation loss: 2.3894776793465624

Epoch: 6| Step: 13
Training loss: 0.15648070826736266
Validation loss: 2.38764708622713

Epoch: 431| Step: 0
Training loss: 0.1676952219708916
Validation loss: 2.380351154775018

Epoch: 6| Step: 1
Training loss: 0.17794779655014664
Validation loss: 2.3686434064728425

Epoch: 6| Step: 2
Training loss: 0.25549736329339967
Validation loss: 2.375470813700953

Epoch: 6| Step: 3
Training loss: 0.11145991756154106
Validation loss: 2.3771288327352003

Epoch: 6| Step: 4
Training loss: 0.2798764544215369
Validation loss: 2.3759747552011548

Epoch: 6| Step: 5
Training loss: 0.2335297761664124
Validation loss: 2.3823657836372507

Epoch: 6| Step: 6
Training loss: 0.16499191378156153
Validation loss: 2.394712803676805

Epoch: 6| Step: 7
Training loss: 0.10236921321259398
Validation loss: 2.4217969084609625

Epoch: 6| Step: 8
Training loss: 0.1322344655051604
Validation loss: 2.4294939832248423

Epoch: 6| Step: 9
Training loss: 0.09224112030230007
Validation loss: 2.4274284381156184

Epoch: 6| Step: 10
Training loss: 0.18844080373294042
Validation loss: 2.4079508848809814

Epoch: 6| Step: 11
Training loss: 0.08878983809857806
Validation loss: 2.4146919601977794

Epoch: 6| Step: 12
Training loss: 0.22360860701916827
Validation loss: 2.4146888675093217

Epoch: 6| Step: 13
Training loss: 0.22720306375968502
Validation loss: 2.3754603550180056

Epoch: 432| Step: 0
Training loss: 0.09249259704046786
Validation loss: 2.4240376074221452

Epoch: 6| Step: 1
Training loss: 0.17949589589535525
Validation loss: 2.3986025677916336

Epoch: 6| Step: 2
Training loss: 0.2931002512490514
Validation loss: 2.440124493423209

Epoch: 6| Step: 3
Training loss: 0.21012496750869364
Validation loss: 2.4487930500712247

Epoch: 6| Step: 4
Training loss: 0.1783981191098968
Validation loss: 2.452435307360271

Epoch: 6| Step: 5
Training loss: 0.14803080307979816
Validation loss: 2.4754442779312753

Epoch: 6| Step: 6
Training loss: 0.14043517015813892
Validation loss: 2.4624450680798247

Epoch: 6| Step: 7
Training loss: 0.131477107812212
Validation loss: 2.463883426446543

Epoch: 6| Step: 8
Training loss: 0.21338842095781957
Validation loss: 2.436449153056366

Epoch: 6| Step: 9
Training loss: 0.11374519153272399
Validation loss: 2.4433009784784954

Epoch: 6| Step: 10
Training loss: 0.16802246875956367
Validation loss: 2.4200507166805942

Epoch: 6| Step: 11
Training loss: 0.13904220534762246
Validation loss: 2.4290329462626823

Epoch: 6| Step: 12
Training loss: 0.12868152160708507
Validation loss: 2.4290973437371504

Epoch: 6| Step: 13
Training loss: 0.24543636560044338
Validation loss: 2.4015597837309746

Epoch: 433| Step: 0
Training loss: 0.10008476918698209
Validation loss: 2.3951582059501657

Epoch: 6| Step: 1
Training loss: 0.21852698197377565
Validation loss: 2.386278269749795

Epoch: 6| Step: 2
Training loss: 0.16243019301054326
Validation loss: 2.3781492901829933

Epoch: 6| Step: 3
Training loss: 0.1319600192471619
Validation loss: 2.388848313903336

Epoch: 6| Step: 4
Training loss: 0.08476965296971102
Validation loss: 2.3742019681287467

Epoch: 6| Step: 5
Training loss: 0.11211333350925365
Validation loss: 2.3644998024378494

Epoch: 6| Step: 6
Training loss: 0.12016321478923454
Validation loss: 2.359359499940115

Epoch: 6| Step: 7
Training loss: 0.11916751245496392
Validation loss: 2.382103393630132

Epoch: 6| Step: 8
Training loss: 0.1887684178208512
Validation loss: 2.4038671423356264

Epoch: 6| Step: 9
Training loss: 0.1910141704948607
Validation loss: 2.403613548598384

Epoch: 6| Step: 10
Training loss: 0.22530891285975901
Validation loss: 2.3869819246953403

Epoch: 6| Step: 11
Training loss: 0.14761136447538542
Validation loss: 2.406940874018901

Epoch: 6| Step: 12
Training loss: 0.11475720453240872
Validation loss: 2.4391780427467427

Epoch: 6| Step: 13
Training loss: 0.14371355180366244
Validation loss: 2.4501476928078776

Epoch: 434| Step: 0
Training loss: 0.08747666677945895
Validation loss: 2.4333710935424286

Epoch: 6| Step: 1
Training loss: 0.09867414231764819
Validation loss: 2.443676013538321

Epoch: 6| Step: 2
Training loss: 0.14719182525443114
Validation loss: 2.4509662691797627

Epoch: 6| Step: 3
Training loss: 0.20300162676807712
Validation loss: 2.473499357504772

Epoch: 6| Step: 4
Training loss: 0.1178204213396041
Validation loss: 2.473015226035667

Epoch: 6| Step: 5
Training loss: 0.136784987071988
Validation loss: 2.45606899906013

Epoch: 6| Step: 6
Training loss: 0.21652835678631902
Validation loss: 2.4610708434633377

Epoch: 6| Step: 7
Training loss: 0.1734609476340403
Validation loss: 2.452791159007425

Epoch: 6| Step: 8
Training loss: 0.17986726061995917
Validation loss: 2.440371004467351

Epoch: 6| Step: 9
Training loss: 0.10660561468964184
Validation loss: 2.43264191095587

Epoch: 6| Step: 10
Training loss: 0.14492158761214477
Validation loss: 2.4583548170694027

Epoch: 6| Step: 11
Training loss: 0.11862208133529727
Validation loss: 2.4384130530028743

Epoch: 6| Step: 12
Training loss: 0.15109091125867022
Validation loss: 2.4302611987177682

Epoch: 6| Step: 13
Training loss: 0.17617238292071083
Validation loss: 2.4307659303844633

Epoch: 435| Step: 0
Training loss: 0.21812689113616918
Validation loss: 2.413704088047936

Epoch: 6| Step: 1
Training loss: 0.1472678151461096
Validation loss: 2.4170344592297

Epoch: 6| Step: 2
Training loss: 0.2432226623642983
Validation loss: 2.3943018622812318

Epoch: 6| Step: 3
Training loss: 0.14263635256366508
Validation loss: 2.409127757137278

Epoch: 6| Step: 4
Training loss: 0.09888237832338684
Validation loss: 2.391352906822969

Epoch: 6| Step: 5
Training loss: 0.16688792001878394
Validation loss: 2.3944855189652645

Epoch: 6| Step: 6
Training loss: 0.11768051391201982
Validation loss: 2.399039984828188

Epoch: 6| Step: 7
Training loss: 0.1474418375138062
Validation loss: 2.4389492025336463

Epoch: 6| Step: 8
Training loss: 0.07068493013575891
Validation loss: 2.4490271984025362

Epoch: 6| Step: 9
Training loss: 0.10810343663787672
Validation loss: 2.4312696383200567

Epoch: 6| Step: 10
Training loss: 0.09825591509032609
Validation loss: 2.458785731001264

Epoch: 6| Step: 11
Training loss: 0.229340880816162
Validation loss: 2.4391255434106593

Epoch: 6| Step: 12
Training loss: 0.15164506079324178
Validation loss: 2.4790582911510572

Epoch: 6| Step: 13
Training loss: 0.11645727735318172
Validation loss: 2.4671240920258826

Epoch: 436| Step: 0
Training loss: 0.21069060110538815
Validation loss: 2.480083324720937

Epoch: 6| Step: 1
Training loss: 0.11454863095033603
Validation loss: 2.4857527084052586

Epoch: 6| Step: 2
Training loss: 0.2367102473529137
Validation loss: 2.4938583952477695

Epoch: 6| Step: 3
Training loss: 0.18005786955605352
Validation loss: 2.439799311544739

Epoch: 6| Step: 4
Training loss: 0.11945065043588873
Validation loss: 2.4291383367791157

Epoch: 6| Step: 5
Training loss: 0.14141314895408144
Validation loss: 2.4216606963601186

Epoch: 6| Step: 6
Training loss: 0.20781333320852188
Validation loss: 2.4093032364225992

Epoch: 6| Step: 7
Training loss: 0.13402462846743265
Validation loss: 2.392476005124416

Epoch: 6| Step: 8
Training loss: 0.1794383872245079
Validation loss: 2.3605892992973785

Epoch: 6| Step: 9
Training loss: 0.14603125107428666
Validation loss: 2.3819547559478154

Epoch: 6| Step: 10
Training loss: 0.11379986469134212
Validation loss: 2.3692023567636893

Epoch: 6| Step: 11
Training loss: 0.22356440401532884
Validation loss: 2.380474154807281

Epoch: 6| Step: 12
Training loss: 0.09778916850019138
Validation loss: 2.40991529901452

Epoch: 6| Step: 13
Training loss: 0.20920708634482837
Validation loss: 2.4136872820826993

Epoch: 437| Step: 0
Training loss: 0.10548901804691595
Validation loss: 2.3999748159868126

Epoch: 6| Step: 1
Training loss: 0.12091835070589617
Validation loss: 2.393484057549657

Epoch: 6| Step: 2
Training loss: 0.13720787971207093
Validation loss: 2.398327173066649

Epoch: 6| Step: 3
Training loss: 0.0941582473311344
Validation loss: 2.4139288283087286

Epoch: 6| Step: 4
Training loss: 0.21958719708127608
Validation loss: 2.4246566036259973

Epoch: 6| Step: 5
Training loss: 0.10593973185571025
Validation loss: 2.449314001552636

Epoch: 6| Step: 6
Training loss: 0.17420495902418542
Validation loss: 2.4354020001524135

Epoch: 6| Step: 7
Training loss: 0.1475287527815566
Validation loss: 2.447360061135366

Epoch: 6| Step: 8
Training loss: 0.21679179726917538
Validation loss: 2.4324684188636274

Epoch: 6| Step: 9
Training loss: 0.1263191090411519
Validation loss: 2.4067786128451054

Epoch: 6| Step: 10
Training loss: 0.20000387202925468
Validation loss: 2.4083718462810877

Epoch: 6| Step: 11
Training loss: 0.12105910128523088
Validation loss: 2.438456368492814

Epoch: 6| Step: 12
Training loss: 0.14277556218185383
Validation loss: 2.4258522743391984

Epoch: 6| Step: 13
Training loss: 0.13526177641628606
Validation loss: 2.4500282031912333

Epoch: 438| Step: 0
Training loss: 0.17072936823086093
Validation loss: 2.3901107592101365

Epoch: 6| Step: 1
Training loss: 0.10933907378626348
Validation loss: 2.427173774601309

Epoch: 6| Step: 2
Training loss: 0.13227644195082516
Validation loss: 2.4243778973210475

Epoch: 6| Step: 3
Training loss: 0.12248546576765491
Validation loss: 2.4226264711334937

Epoch: 6| Step: 4
Training loss: 0.1541546032885484
Validation loss: 2.44341394053283

Epoch: 6| Step: 5
Training loss: 0.24131192089644637
Validation loss: 2.450597187638277

Epoch: 6| Step: 6
Training loss: 0.12454627810301558
Validation loss: 2.4326721141206544

Epoch: 6| Step: 7
Training loss: 0.18952851909107196
Validation loss: 2.418198039496419

Epoch: 6| Step: 8
Training loss: 0.13325754100116402
Validation loss: 2.4734681422413427

Epoch: 6| Step: 9
Training loss: 0.1383275471788035
Validation loss: 2.4158829341809356

Epoch: 6| Step: 10
Training loss: 0.2216823846594119
Validation loss: 2.4476316912331444

Epoch: 6| Step: 11
Training loss: 0.10031819123912306
Validation loss: 2.436524615931848

Epoch: 6| Step: 12
Training loss: 0.14675004391775173
Validation loss: 2.459376831320859

Epoch: 6| Step: 13
Training loss: 0.07625324842303018
Validation loss: 2.4348711346938723

Epoch: 439| Step: 0
Training loss: 0.10298534187999724
Validation loss: 2.425658052090979

Epoch: 6| Step: 1
Training loss: 0.17419967162014266
Validation loss: 2.4341998844853214

Epoch: 6| Step: 2
Training loss: 0.1927281876379956
Validation loss: 2.4561811797638446

Epoch: 6| Step: 3
Training loss: 0.09739266586338009
Validation loss: 2.4247539344254787

Epoch: 6| Step: 4
Training loss: 0.12287487391070535
Validation loss: 2.411058500705889

Epoch: 6| Step: 5
Training loss: 0.1906411097707745
Validation loss: 2.3901731152609065

Epoch: 6| Step: 6
Training loss: 0.10116890604677949
Validation loss: 2.3737204936522027

Epoch: 6| Step: 7
Training loss: 0.14197197183844718
Validation loss: 2.370854304855446

Epoch: 6| Step: 8
Training loss: 0.11137919342182735
Validation loss: 2.365051041855551

Epoch: 6| Step: 9
Training loss: 0.0900545135943793
Validation loss: 2.352536444686234

Epoch: 6| Step: 10
Training loss: 0.17505709044723822
Validation loss: 2.3494218687664152

Epoch: 6| Step: 11
Training loss: 0.21441526165566258
Validation loss: 2.351380283604449

Epoch: 6| Step: 12
Training loss: 0.1575700313549152
Validation loss: 2.3556673173055946

Epoch: 6| Step: 13
Training loss: 0.2707550488940816
Validation loss: 2.3927456123572672

Epoch: 440| Step: 0
Training loss: 0.11080058070419671
Validation loss: 2.3879039768600525

Epoch: 6| Step: 1
Training loss: 0.10616294786818489
Validation loss: 2.3845710772797593

Epoch: 6| Step: 2
Training loss: 0.1340398595716978
Validation loss: 2.4020125013911735

Epoch: 6| Step: 3
Training loss: 0.2187959844076257
Validation loss: 2.3928453334310795

Epoch: 6| Step: 4
Training loss: 0.12857687658662761
Validation loss: 2.423186686830594

Epoch: 6| Step: 5
Training loss: 0.09630124844862623
Validation loss: 2.411860395254642

Epoch: 6| Step: 6
Training loss: 0.11638308845103709
Validation loss: 2.435984117797676

Epoch: 6| Step: 7
Training loss: 0.18879792877537124
Validation loss: 2.452546935106367

Epoch: 6| Step: 8
Training loss: 0.09550683658779942
Validation loss: 2.407310550436525

Epoch: 6| Step: 9
Training loss: 0.11652884556148237
Validation loss: 2.4658695404067466

Epoch: 6| Step: 10
Training loss: 0.1314306883024138
Validation loss: 2.4563224421296432

Epoch: 6| Step: 11
Training loss: 0.21661670174418515
Validation loss: 2.456340261516412

Epoch: 6| Step: 12
Training loss: 0.20866278388279946
Validation loss: 2.4582332500679533

Epoch: 6| Step: 13
Training loss: 0.11853153059162104
Validation loss: 2.443678393926612

Epoch: 441| Step: 0
Training loss: 0.17302598611893488
Validation loss: 2.4645800427590383

Epoch: 6| Step: 1
Training loss: 0.2013181043831901
Validation loss: 2.443397814208123

Epoch: 6| Step: 2
Training loss: 0.12316619295309608
Validation loss: 2.4599118456388487

Epoch: 6| Step: 3
Training loss: 0.1394753149954676
Validation loss: 2.4658388445570107

Epoch: 6| Step: 4
Training loss: 0.10225249619281715
Validation loss: 2.424240386220093

Epoch: 6| Step: 5
Training loss: 0.20478972182962485
Validation loss: 2.4418629922851927

Epoch: 6| Step: 6
Training loss: 0.16639204546697947
Validation loss: 2.4154607552625125

Epoch: 6| Step: 7
Training loss: 0.151935562403496
Validation loss: 2.401528004882343

Epoch: 6| Step: 8
Training loss: 0.11249184148398646
Validation loss: 2.427764183040099

Epoch: 6| Step: 9
Training loss: 0.2295518919204565
Validation loss: 2.3821466988024174

Epoch: 6| Step: 10
Training loss: 0.13359030696826846
Validation loss: 2.386042749767123

Epoch: 6| Step: 11
Training loss: 0.13504478317780394
Validation loss: 2.3964418017565956

Epoch: 6| Step: 12
Training loss: 0.1473744751538289
Validation loss: 2.405685605789296

Epoch: 6| Step: 13
Training loss: 0.16472726068672136
Validation loss: 2.3895840143434732

Epoch: 442| Step: 0
Training loss: 0.2599536100826609
Validation loss: 2.4055298621374512

Epoch: 6| Step: 1
Training loss: 0.1757340791777282
Validation loss: 2.4193864870223227

Epoch: 6| Step: 2
Training loss: 0.17858065875074386
Validation loss: 2.404230420384513

Epoch: 6| Step: 3
Training loss: 0.1884220321120643
Validation loss: 2.4087222114656703

Epoch: 6| Step: 4
Training loss: 0.10966511974897175
Validation loss: 2.423740921738408

Epoch: 6| Step: 5
Training loss: 0.1091247744645304
Validation loss: 2.437830179809791

Epoch: 6| Step: 6
Training loss: 0.07793772424162394
Validation loss: 2.4250996399091433

Epoch: 6| Step: 7
Training loss: 0.11728336069223874
Validation loss: 2.435743348375078

Epoch: 6| Step: 8
Training loss: 0.1340145452468568
Validation loss: 2.402339755686165

Epoch: 6| Step: 9
Training loss: 0.13376433429378265
Validation loss: 2.4150694061943665

Epoch: 6| Step: 10
Training loss: 0.14249370636343053
Validation loss: 2.43498418302331

Epoch: 6| Step: 11
Training loss: 0.17476782596585183
Validation loss: 2.4415245687055207

Epoch: 6| Step: 12
Training loss: 0.09967354035470043
Validation loss: 2.4090646125816617

Epoch: 6| Step: 13
Training loss: 0.07834692666925176
Validation loss: 2.3946293234976213

Epoch: 443| Step: 0
Training loss: 0.11628056692165235
Validation loss: 2.42461396413361

Epoch: 6| Step: 1
Training loss: 0.09042287846218233
Validation loss: 2.420705333283376

Epoch: 6| Step: 2
Training loss: 0.10643780533102239
Validation loss: 2.39401365481907

Epoch: 6| Step: 3
Training loss: 0.1361311547111373
Validation loss: 2.4105069194926263

Epoch: 6| Step: 4
Training loss: 0.0905979212639161
Validation loss: 2.4348638008085244

Epoch: 6| Step: 5
Training loss: 0.2355121207337499
Validation loss: 2.4002706845064696

Epoch: 6| Step: 6
Training loss: 0.10373970735436347
Validation loss: 2.4167465483886437

Epoch: 6| Step: 7
Training loss: 0.20878066178952556
Validation loss: 2.401418628071687

Epoch: 6| Step: 8
Training loss: 0.09904719637643983
Validation loss: 2.40523693214609

Epoch: 6| Step: 9
Training loss: 0.15542838924160085
Validation loss: 2.4100669649780975

Epoch: 6| Step: 10
Training loss: 0.08531742831901211
Validation loss: 2.4253974822217286

Epoch: 6| Step: 11
Training loss: 0.1781272110048903
Validation loss: 2.440376974523496

Epoch: 6| Step: 12
Training loss: 0.10923950283295773
Validation loss: 2.419918987101587

Epoch: 6| Step: 13
Training loss: 0.10041502904578896
Validation loss: 2.434584838807529

Epoch: 444| Step: 0
Training loss: 0.07774744894317327
Validation loss: 2.4340329308972373

Epoch: 6| Step: 1
Training loss: 0.11128659896025214
Validation loss: 2.411744419278345

Epoch: 6| Step: 2
Training loss: 0.09994498915341565
Validation loss: 2.410901927541354

Epoch: 6| Step: 3
Training loss: 0.06023831536742463
Validation loss: 2.4183318480952547

Epoch: 6| Step: 4
Training loss: 0.12071315884164947
Validation loss: 2.414660833535735

Epoch: 6| Step: 5
Training loss: 0.12408360200905816
Validation loss: 2.4287781733815317

Epoch: 6| Step: 6
Training loss: 0.08544775007893124
Validation loss: 2.418184466421495

Epoch: 6| Step: 7
Training loss: 0.10204688434370071
Validation loss: 2.429978320189929

Epoch: 6| Step: 8
Training loss: 0.09616959029148103
Validation loss: 2.4098741257853966

Epoch: 6| Step: 9
Training loss: 0.10317352735382594
Validation loss: 2.3975950857134976

Epoch: 6| Step: 10
Training loss: 0.07941451096959287
Validation loss: 2.3811135429489587

Epoch: 6| Step: 11
Training loss: 0.26262302183961356
Validation loss: 2.3791930118460782

Epoch: 6| Step: 12
Training loss: 0.20145682181633204
Validation loss: 2.3946298036523985

Epoch: 6| Step: 13
Training loss: 0.10589683158610881
Validation loss: 2.4009069975723496

Epoch: 445| Step: 0
Training loss: 0.09301691730895316
Validation loss: 2.4029646607225175

Epoch: 6| Step: 1
Training loss: 0.2650904184734894
Validation loss: 2.3925835848074843

Epoch: 6| Step: 2
Training loss: 0.1594613923336437
Validation loss: 2.4031629700755186

Epoch: 6| Step: 3
Training loss: 0.12698607383991353
Validation loss: 2.425803215074442

Epoch: 6| Step: 4
Training loss: 0.10798846290505486
Validation loss: 2.4315825205871553

Epoch: 6| Step: 5
Training loss: 0.17880600865410556
Validation loss: 2.4158348360513884

Epoch: 6| Step: 6
Training loss: 0.06476285237128285
Validation loss: 2.4491428094530034

Epoch: 6| Step: 7
Training loss: 0.07440195560839755
Validation loss: 2.4411917338972584

Epoch: 6| Step: 8
Training loss: 0.12628968823623327
Validation loss: 2.4211779662800215

Epoch: 6| Step: 9
Training loss: 0.0968094350072295
Validation loss: 2.3978660549146333

Epoch: 6| Step: 10
Training loss: 0.10709319549664108
Validation loss: 2.3985847501962883

Epoch: 6| Step: 11
Training loss: 0.10141999076652711
Validation loss: 2.4140306122813615

Epoch: 6| Step: 12
Training loss: 0.12056941292686152
Validation loss: 2.4203469046032406

Epoch: 6| Step: 13
Training loss: 0.09155838503883576
Validation loss: 2.464276107504058

Epoch: 446| Step: 0
Training loss: 0.08169106209966598
Validation loss: 2.416876399437491

Epoch: 6| Step: 1
Training loss: 0.11044337242836479
Validation loss: 2.4289215012578897

Epoch: 6| Step: 2
Training loss: 0.09783031686022092
Validation loss: 2.4048148345906553

Epoch: 6| Step: 3
Training loss: 0.09754209522120309
Validation loss: 2.403313546362604

Epoch: 6| Step: 4
Training loss: 0.11989975454986972
Validation loss: 2.421120176208247

Epoch: 6| Step: 5
Training loss: 0.18617358526676103
Validation loss: 2.3679481463905265

Epoch: 6| Step: 6
Training loss: 0.11674773432786716
Validation loss: 2.360461417305445

Epoch: 6| Step: 7
Training loss: 0.19108660925548204
Validation loss: 2.3963314974120564

Epoch: 6| Step: 8
Training loss: 0.11510543560030577
Validation loss: 2.3885013016770036

Epoch: 6| Step: 9
Training loss: 0.11516784913641308
Validation loss: 2.394455265597476

Epoch: 6| Step: 10
Training loss: 0.22970214329966396
Validation loss: 2.408182663293309

Epoch: 6| Step: 11
Training loss: 0.1698545179928018
Validation loss: 2.3871101568798094

Epoch: 6| Step: 12
Training loss: 0.176459645805372
Validation loss: 2.3756370942066436

Epoch: 6| Step: 13
Training loss: 0.0732881084173057
Validation loss: 2.3950748617132223

Epoch: 447| Step: 0
Training loss: 0.1469298962715172
Validation loss: 2.3850769370288445

Epoch: 6| Step: 1
Training loss: 0.06403622393677019
Validation loss: 2.405807961649755

Epoch: 6| Step: 2
Training loss: 0.1163261467590597
Validation loss: 2.4179937207745303

Epoch: 6| Step: 3
Training loss: 0.18638301976409016
Validation loss: 2.395852227334901

Epoch: 6| Step: 4
Training loss: 0.07178962693245243
Validation loss: 2.4228195544964226

Epoch: 6| Step: 5
Training loss: 0.1532207700419984
Validation loss: 2.4281386462530907

Epoch: 6| Step: 6
Training loss: 0.23669424937395675
Validation loss: 2.442683874789201

Epoch: 6| Step: 7
Training loss: 0.12156766783656404
Validation loss: 2.4235199443178312

Epoch: 6| Step: 8
Training loss: 0.07876465717788826
Validation loss: 2.451703463035702

Epoch: 6| Step: 9
Training loss: 0.16196463914306322
Validation loss: 2.4335675972025577

Epoch: 6| Step: 10
Training loss: 0.1680423941074693
Validation loss: 2.428268650890592

Epoch: 6| Step: 11
Training loss: 0.21516186830807643
Validation loss: 2.4312897288453335

Epoch: 6| Step: 12
Training loss: 0.11482157152462472
Validation loss: 2.4323532104786714

Epoch: 6| Step: 13
Training loss: 0.14546106854982013
Validation loss: 2.442942529493144

Epoch: 448| Step: 0
Training loss: 0.09817798480860368
Validation loss: 2.447877866759976

Epoch: 6| Step: 1
Training loss: 0.163870295834984
Validation loss: 2.4392041206755795

Epoch: 6| Step: 2
Training loss: 0.13608095037707404
Validation loss: 2.436411099815037

Epoch: 6| Step: 3
Training loss: 0.15377695878477035
Validation loss: 2.4057025563688312

Epoch: 6| Step: 4
Training loss: 0.09887964221453045
Validation loss: 2.445072728840707

Epoch: 6| Step: 5
Training loss: 0.1364703100956938
Validation loss: 2.4353726413983807

Epoch: 6| Step: 6
Training loss: 0.15236749219509427
Validation loss: 2.435730615619933

Epoch: 6| Step: 7
Training loss: 0.10248496127000896
Validation loss: 2.4486839465619887

Epoch: 6| Step: 8
Training loss: 0.19212914216621468
Validation loss: 2.431730959148741

Epoch: 6| Step: 9
Training loss: 0.18959724214556042
Validation loss: 2.4192339493003265

Epoch: 6| Step: 10
Training loss: 0.0809776100536257
Validation loss: 2.449894161378448

Epoch: 6| Step: 11
Training loss: 0.19383755712842257
Validation loss: 2.4437333520308

Epoch: 6| Step: 12
Training loss: 0.15515852220605975
Validation loss: 2.4458297674612144

Epoch: 6| Step: 13
Training loss: 0.10827008372140853
Validation loss: 2.4229421391553316

Epoch: 449| Step: 0
Training loss: 0.078053414807765
Validation loss: 2.468968742195037

Epoch: 6| Step: 1
Training loss: 0.1429681017084484
Validation loss: 2.4716589775239948

Epoch: 6| Step: 2
Training loss: 0.1255368758340011
Validation loss: 2.4378908105410293

Epoch: 6| Step: 3
Training loss: 0.0906534096977384
Validation loss: 2.4381138817622827

Epoch: 6| Step: 4
Training loss: 0.23772332270138147
Validation loss: 2.461530210832411

Epoch: 6| Step: 5
Training loss: 0.13738368327212205
Validation loss: 2.4394914807361174

Epoch: 6| Step: 6
Training loss: 0.1657999545159985
Validation loss: 2.4580801261061365

Epoch: 6| Step: 7
Training loss: 0.17239696724644565
Validation loss: 2.4421863777950037

Epoch: 6| Step: 8
Training loss: 0.08113128420988695
Validation loss: 2.468523673766788

Epoch: 6| Step: 9
Training loss: 0.1570015950456007
Validation loss: 2.4296144864176497

Epoch: 6| Step: 10
Training loss: 0.21242893973272192
Validation loss: 2.446204386004512

Epoch: 6| Step: 11
Training loss: 0.11631628278528523
Validation loss: 2.44719628543197

Epoch: 6| Step: 12
Training loss: 0.1718450758633658
Validation loss: 2.429917507853575

Epoch: 6| Step: 13
Training loss: 0.1510140761026125
Validation loss: 2.419515716141453

Epoch: 450| Step: 0
Training loss: 0.1269794216797573
Validation loss: 2.43891521837245

Epoch: 6| Step: 1
Training loss: 0.1280543687988806
Validation loss: 2.445097263444193

Epoch: 6| Step: 2
Training loss: 0.08524561467001353
Validation loss: 2.431230571865435

Epoch: 6| Step: 3
Training loss: 0.13681848838904517
Validation loss: 2.4315387030881004

Epoch: 6| Step: 4
Training loss: 0.14283616740068397
Validation loss: 2.4454097320254964

Epoch: 6| Step: 5
Training loss: 0.12675785305686738
Validation loss: 2.4378640087385195

Epoch: 6| Step: 6
Training loss: 0.26685772281530395
Validation loss: 2.465465229061391

Epoch: 6| Step: 7
Training loss: 0.15715513917238733
Validation loss: 2.4622605321821194

Epoch: 6| Step: 8
Training loss: 0.10444493428559212
Validation loss: 2.457518045236504

Epoch: 6| Step: 9
Training loss: 0.14955653460155635
Validation loss: 2.4494270358738857

Epoch: 6| Step: 10
Training loss: 0.13785451789124412
Validation loss: 2.4683438251615235

Epoch: 6| Step: 11
Training loss: 0.2072943059874646
Validation loss: 2.456668426244336

Epoch: 6| Step: 12
Training loss: 0.11879581442889739
Validation loss: 2.4462235948592537

Epoch: 6| Step: 13
Training loss: 0.11409789085031034
Validation loss: 2.4308748040459207

Epoch: 451| Step: 0
Training loss: 0.08574320764304058
Validation loss: 2.4587666380119906

Epoch: 6| Step: 1
Training loss: 0.17430637234572
Validation loss: 2.4555454711114297

Epoch: 6| Step: 2
Training loss: 0.11561117959550694
Validation loss: 2.4473010299427895

Epoch: 6| Step: 3
Training loss: 0.10509621648789438
Validation loss: 2.438939985200547

Epoch: 6| Step: 4
Training loss: 0.10802532540385783
Validation loss: 2.436201742169051

Epoch: 6| Step: 5
Training loss: 0.19283472032042695
Validation loss: 2.4561721272980135

Epoch: 6| Step: 6
Training loss: 0.11321070546318664
Validation loss: 2.4435856483393956

Epoch: 6| Step: 7
Training loss: 0.2335635921696705
Validation loss: 2.4644191715529207

Epoch: 6| Step: 8
Training loss: 0.13763296460796498
Validation loss: 2.4425285726774035

Epoch: 6| Step: 9
Training loss: 0.1379765283502366
Validation loss: 2.4615269463684455

Epoch: 6| Step: 10
Training loss: 0.2083749173306654
Validation loss: 2.4270119376422254

Epoch: 6| Step: 11
Training loss: 0.20663393330691032
Validation loss: 2.4451409873766967

Epoch: 6| Step: 12
Training loss: 0.1578406254567305
Validation loss: 2.446406080364209

Epoch: 6| Step: 13
Training loss: 0.15551279920005426
Validation loss: 2.4212473553213587

Epoch: 452| Step: 0
Training loss: 0.11074224872351944
Validation loss: 2.4193557153378884

Epoch: 6| Step: 1
Training loss: 0.1240069085468344
Validation loss: 2.4316133072849757

Epoch: 6| Step: 2
Training loss: 0.17108935999355002
Validation loss: 2.461471978253376

Epoch: 6| Step: 3
Training loss: 0.18565710708428032
Validation loss: 2.459062481369614

Epoch: 6| Step: 4
Training loss: 0.12351611899145029
Validation loss: 2.4745357391848986

Epoch: 6| Step: 5
Training loss: 0.14085335205031388
Validation loss: 2.438532530397649

Epoch: 6| Step: 6
Training loss: 0.10023678670406518
Validation loss: 2.508200376401388

Epoch: 6| Step: 7
Training loss: 0.20565672496375045
Validation loss: 2.462067138045951

Epoch: 6| Step: 8
Training loss: 0.08955572961179122
Validation loss: 2.4907024519980996

Epoch: 6| Step: 9
Training loss: 0.17797393164991226
Validation loss: 2.458326538025099

Epoch: 6| Step: 10
Training loss: 0.207981206419134
Validation loss: 2.473070857002211

Epoch: 6| Step: 11
Training loss: 0.15752823244529457
Validation loss: 2.4825288684286995

Epoch: 6| Step: 12
Training loss: 0.17498008623239966
Validation loss: 2.4813678517881317

Epoch: 6| Step: 13
Training loss: 0.12468895359195885
Validation loss: 2.4486704241660413

Epoch: 453| Step: 0
Training loss: 0.18946609256056687
Validation loss: 2.4300031912911955

Epoch: 6| Step: 1
Training loss: 0.09939631882700023
Validation loss: 2.446289797127744

Epoch: 6| Step: 2
Training loss: 0.20319086620836121
Validation loss: 2.476363134998386

Epoch: 6| Step: 3
Training loss: 0.20063254827934524
Validation loss: 2.470686930876911

Epoch: 6| Step: 4
Training loss: 0.12562225848855174
Validation loss: 2.4288459066521635

Epoch: 6| Step: 5
Training loss: 0.13412535648840734
Validation loss: 2.45672970027382

Epoch: 6| Step: 6
Training loss: 0.0816379125728573
Validation loss: 2.4160786833866803

Epoch: 6| Step: 7
Training loss: 0.10565197006386856
Validation loss: 2.417452647959669

Epoch: 6| Step: 8
Training loss: 0.12832018534336148
Validation loss: 2.4234562205830206

Epoch: 6| Step: 9
Training loss: 0.0953643114723957
Validation loss: 2.4202971220423315

Epoch: 6| Step: 10
Training loss: 0.07140247912018181
Validation loss: 2.4151148897068873

Epoch: 6| Step: 11
Training loss: 0.0751889585312305
Validation loss: 2.3697023854728796

Epoch: 6| Step: 12
Training loss: 0.11282628463234176
Validation loss: 2.3911798401532005

Epoch: 6| Step: 13
Training loss: 0.05506989987487053
Validation loss: 2.3868219816402054

Epoch: 454| Step: 0
Training loss: 0.21584009278389807
Validation loss: 2.4083467608400877

Epoch: 6| Step: 1
Training loss: 0.11951325723699237
Validation loss: 2.4017702616177385

Epoch: 6| Step: 2
Training loss: 0.0975864017555848
Validation loss: 2.411952797245545

Epoch: 6| Step: 3
Training loss: 0.19259979868905072
Validation loss: 2.4487234391524293

Epoch: 6| Step: 4
Training loss: 0.09388013093268828
Validation loss: 2.4205258594725065

Epoch: 6| Step: 5
Training loss: 0.18032072279905623
Validation loss: 2.426719621022848

Epoch: 6| Step: 6
Training loss: 0.1295428595499743
Validation loss: 2.4161166372099956

Epoch: 6| Step: 7
Training loss: 0.0957021275293179
Validation loss: 2.4557348178701983

Epoch: 6| Step: 8
Training loss: 0.09852889223480905
Validation loss: 2.437843054607092

Epoch: 6| Step: 9
Training loss: 0.11458304975936941
Validation loss: 2.433295096691043

Epoch: 6| Step: 10
Training loss: 0.1530060189097939
Validation loss: 2.451630878733401

Epoch: 6| Step: 11
Training loss: 0.07882226390523384
Validation loss: 2.43744471308227

Epoch: 6| Step: 12
Training loss: 0.09580255228752331
Validation loss: 2.452731505709336

Epoch: 6| Step: 13
Training loss: 0.10396021162395865
Validation loss: 2.443264298420312

Epoch: 455| Step: 0
Training loss: 0.1027641731822021
Validation loss: 2.439649214436959

Epoch: 6| Step: 1
Training loss: 0.18234393641994331
Validation loss: 2.4536249515960153

Epoch: 6| Step: 2
Training loss: 0.1323856971068502
Validation loss: 2.4288937719339083

Epoch: 6| Step: 3
Training loss: 0.19713617553128143
Validation loss: 2.437804265958684

Epoch: 6| Step: 4
Training loss: 0.0796377470803608
Validation loss: 2.3974177603152977

Epoch: 6| Step: 5
Training loss: 0.08149398543135652
Validation loss: 2.411955343397322

Epoch: 6| Step: 6
Training loss: 0.12191828607040812
Validation loss: 2.3996727499410455

Epoch: 6| Step: 7
Training loss: 0.10848948804521824
Validation loss: 2.37021521662312

Epoch: 6| Step: 8
Training loss: 0.22124692712686564
Validation loss: 2.382801043911404

Epoch: 6| Step: 9
Training loss: 0.11977911879984546
Validation loss: 2.400643278250465

Epoch: 6| Step: 10
Training loss: 0.1048606765730523
Validation loss: 2.3707815852975838

Epoch: 6| Step: 11
Training loss: 0.08356782553553523
Validation loss: 2.383388026555288

Epoch: 6| Step: 12
Training loss: 0.0928198597860618
Validation loss: 2.4061701142999636

Epoch: 6| Step: 13
Training loss: 0.1979165526858219
Validation loss: 2.410856733005443

Epoch: 456| Step: 0
Training loss: 0.13081812564301185
Validation loss: 2.391502880034096

Epoch: 6| Step: 1
Training loss: 0.10716899236597277
Validation loss: 2.372113444191085

Epoch: 6| Step: 2
Training loss: 0.11285949990736836
Validation loss: 2.405960090047748

Epoch: 6| Step: 3
Training loss: 0.09368962091967964
Validation loss: 2.3954717940251515

Epoch: 6| Step: 4
Training loss: 0.09728386930002371
Validation loss: 2.4080794046583214

Epoch: 6| Step: 5
Training loss: 0.07934311495741284
Validation loss: 2.3929003453545565

Epoch: 6| Step: 6
Training loss: 0.187562494989158
Validation loss: 2.3905903365123238

Epoch: 6| Step: 7
Training loss: 0.05849796452977701
Validation loss: 2.411231686484871

Epoch: 6| Step: 8
Training loss: 0.15403092074228433
Validation loss: 2.4242596527843348

Epoch: 6| Step: 9
Training loss: 0.19881464607102217
Validation loss: 2.4323162612432214

Epoch: 6| Step: 10
Training loss: 0.1420109979062705
Validation loss: 2.443557448593542

Epoch: 6| Step: 11
Training loss: 0.09334558939805626
Validation loss: 2.4355342385831094

Epoch: 6| Step: 12
Training loss: 0.16733754568593037
Validation loss: 2.4335470485293182

Epoch: 6| Step: 13
Training loss: 0.09125584593427982
Validation loss: 2.4298726949577714

Epoch: 457| Step: 0
Training loss: 0.13442119868790228
Validation loss: 2.430323006149799

Epoch: 6| Step: 1
Training loss: 0.19058500949190368
Validation loss: 2.432212808461125

Epoch: 6| Step: 2
Training loss: 0.12359387054148123
Validation loss: 2.449602559684303

Epoch: 6| Step: 3
Training loss: 0.07493047397380953
Validation loss: 2.4345531272239684

Epoch: 6| Step: 4
Training loss: 0.09952414363002995
Validation loss: 2.4177610750243987

Epoch: 6| Step: 5
Training loss: 0.18132364651311458
Validation loss: 2.4274646836701153

Epoch: 6| Step: 6
Training loss: 0.10833006068323844
Validation loss: 2.4314886715214628

Epoch: 6| Step: 7
Training loss: 0.0899435194266357
Validation loss: 2.425005796844418

Epoch: 6| Step: 8
Training loss: 0.10808455067562761
Validation loss: 2.4127348214969797

Epoch: 6| Step: 9
Training loss: 0.1947054680329031
Validation loss: 2.384758503065503

Epoch: 6| Step: 10
Training loss: 0.1635444727938345
Validation loss: 2.3827406381697522

Epoch: 6| Step: 11
Training loss: 0.07378193972364971
Validation loss: 2.359045759662543

Epoch: 6| Step: 12
Training loss: 0.10245694096311951
Validation loss: 2.3584013887739914

Epoch: 6| Step: 13
Training loss: 0.17003708802997555
Validation loss: 2.360582867894623

Epoch: 458| Step: 0
Training loss: 0.13593463154758953
Validation loss: 2.3413821493095024

Epoch: 6| Step: 1
Training loss: 0.13975944641853874
Validation loss: 2.3689105691454597

Epoch: 6| Step: 2
Training loss: 0.07736062193366222
Validation loss: 2.31695455415069

Epoch: 6| Step: 3
Training loss: 0.106235507369371
Validation loss: 2.3302992882095848

Epoch: 6| Step: 4
Training loss: 0.18777015218128343
Validation loss: 2.3486752830773847

Epoch: 6| Step: 5
Training loss: 0.093860164130348
Validation loss: 2.3801357631337634

Epoch: 6| Step: 6
Training loss: 0.15993103614213522
Validation loss: 2.3564355929395457

Epoch: 6| Step: 7
Training loss: 0.25689188996822543
Validation loss: 2.38209371203609

Epoch: 6| Step: 8
Training loss: 0.14917447946332021
Validation loss: 2.3839037347377423

Epoch: 6| Step: 9
Training loss: 0.09294994528707533
Validation loss: 2.407389281207892

Epoch: 6| Step: 10
Training loss: 0.0767664172904034
Validation loss: 2.4058416627655417

Epoch: 6| Step: 11
Training loss: 0.228435078306708
Validation loss: 2.39631332005083

Epoch: 6| Step: 12
Training loss: 0.17174390648494928
Validation loss: 2.420375551130052

Epoch: 6| Step: 13
Training loss: 0.12753525563235332
Validation loss: 2.4355701724652232

Epoch: 459| Step: 0
Training loss: 0.17307371206978034
Validation loss: 2.436136631692369

Epoch: 6| Step: 1
Training loss: 0.10635796296449038
Validation loss: 2.4267395112597163

Epoch: 6| Step: 2
Training loss: 0.15916250873380802
Validation loss: 2.449163199014559

Epoch: 6| Step: 3
Training loss: 0.08896894183806467
Validation loss: 2.45667906827901

Epoch: 6| Step: 4
Training loss: 0.1451678561117376
Validation loss: 2.4341129269379778

Epoch: 6| Step: 5
Training loss: 0.16456620910947106
Validation loss: 2.439641564430156

Epoch: 6| Step: 6
Training loss: 0.09040363669813196
Validation loss: 2.4454561471969365

Epoch: 6| Step: 7
Training loss: 0.12732477807385728
Validation loss: 2.4407217664467615

Epoch: 6| Step: 8
Training loss: 0.1390548441418961
Validation loss: 2.403097473300089

Epoch: 6| Step: 9
Training loss: 0.1679433814563848
Validation loss: 2.42477853294644

Epoch: 6| Step: 10
Training loss: 0.11113408394674515
Validation loss: 2.408312349099945

Epoch: 6| Step: 11
Training loss: 0.175782579840822
Validation loss: 2.424959707015244

Epoch: 6| Step: 12
Training loss: 0.21047799075258594
Validation loss: 2.3902793729335374

Epoch: 6| Step: 13
Training loss: 0.06640959128220339
Validation loss: 2.400614709156165

Epoch: 460| Step: 0
Training loss: 0.14487393452546304
Validation loss: 2.371905154610012

Epoch: 6| Step: 1
Training loss: 0.11940734743324301
Validation loss: 2.38831355562116

Epoch: 6| Step: 2
Training loss: 0.1947820326178753
Validation loss: 2.3925706223652115

Epoch: 6| Step: 3
Training loss: 0.10950688942183207
Validation loss: 2.3938732306023174

Epoch: 6| Step: 4
Training loss: 0.17984326494285732
Validation loss: 2.4149772625155554

Epoch: 6| Step: 5
Training loss: 0.11626443513082718
Validation loss: 2.410670909870076

Epoch: 6| Step: 6
Training loss: 0.25047091001839294
Validation loss: 2.3849653943908957

Epoch: 6| Step: 7
Training loss: 0.10611955422294904
Validation loss: 2.389048253227385

Epoch: 6| Step: 8
Training loss: 0.1092823436503437
Validation loss: 2.376080534357881

Epoch: 6| Step: 9
Training loss: 0.18662419019652432
Validation loss: 2.4007930429809137

Epoch: 6| Step: 10
Training loss: 0.21965674244707029
Validation loss: 2.411747402800913

Epoch: 6| Step: 11
Training loss: 0.12183894547213303
Validation loss: 2.406032205608701

Epoch: 6| Step: 12
Training loss: 0.13550501625076844
Validation loss: 2.422389708996578

Epoch: 6| Step: 13
Training loss: 0.10352120294477431
Validation loss: 2.413342550761278

Epoch: 461| Step: 0
Training loss: 0.17295254704672375
Validation loss: 2.4194414872544177

Epoch: 6| Step: 1
Training loss: 0.19290285452556924
Validation loss: 2.4136378427855423

Epoch: 6| Step: 2
Training loss: 0.11097283723990911
Validation loss: 2.438464701379644

Epoch: 6| Step: 3
Training loss: 0.19599129975542443
Validation loss: 2.448768671320714

Epoch: 6| Step: 4
Training loss: 0.13891364231328188
Validation loss: 2.4625008993197652

Epoch: 6| Step: 5
Training loss: 0.17439974334136316
Validation loss: 2.4392120508352155

Epoch: 6| Step: 6
Training loss: 0.1401256463863699
Validation loss: 2.454684991843687

Epoch: 6| Step: 7
Training loss: 0.07493402862820353
Validation loss: 2.4731526741812373

Epoch: 6| Step: 8
Training loss: 0.15034653896820638
Validation loss: 2.457832631309667

Epoch: 6| Step: 9
Training loss: 0.14043739838844768
Validation loss: 2.4258211323574885

Epoch: 6| Step: 10
Training loss: 0.162047052468109
Validation loss: 2.410069840748117

Epoch: 6| Step: 11
Training loss: 0.1262720914671129
Validation loss: 2.421734707169816

Epoch: 6| Step: 12
Training loss: 0.1159377131884278
Validation loss: 2.400175079203038

Epoch: 6| Step: 13
Training loss: 0.14893389820429248
Validation loss: 2.383729758345837

Epoch: 462| Step: 0
Training loss: 0.19856169748849528
Validation loss: 2.3569776887637306

Epoch: 6| Step: 1
Training loss: 0.15877219857804908
Validation loss: 2.362622524152418

Epoch: 6| Step: 2
Training loss: 0.1321638338849523
Validation loss: 2.358765167241994

Epoch: 6| Step: 3
Training loss: 0.15163038198553525
Validation loss: 2.372205050365956

Epoch: 6| Step: 4
Training loss: 0.09851266133496438
Validation loss: 2.3493898718963537

Epoch: 6| Step: 5
Training loss: 0.2290442782930854
Validation loss: 2.362913036077581

Epoch: 6| Step: 6
Training loss: 0.13000011883097498
Validation loss: 2.370977994348212

Epoch: 6| Step: 7
Training loss: 0.12195517641501183
Validation loss: 2.379104503888918

Epoch: 6| Step: 8
Training loss: 0.10903234109909339
Validation loss: 2.3750868980019537

Epoch: 6| Step: 9
Training loss: 0.1572900963593301
Validation loss: 2.390102157452669

Epoch: 6| Step: 10
Training loss: 0.14486130839466785
Validation loss: 2.360020727958539

Epoch: 6| Step: 11
Training loss: 0.14175677507514428
Validation loss: 2.3986788996273996

Epoch: 6| Step: 12
Training loss: 0.17580071447477333
Validation loss: 2.3863739977908516

Epoch: 6| Step: 13
Training loss: 0.12660426845795444
Validation loss: 2.4203219734654255

Epoch: 463| Step: 0
Training loss: 0.11421678898872191
Validation loss: 2.3856581634509464

Epoch: 6| Step: 1
Training loss: 0.09432241903711268
Validation loss: 2.405886588150093

Epoch: 6| Step: 2
Training loss: 0.13005123834280732
Validation loss: 2.4203574330661004

Epoch: 6| Step: 3
Training loss: 0.12805433243453335
Validation loss: 2.4345365799630354

Epoch: 6| Step: 4
Training loss: 0.13880270843889947
Validation loss: 2.4354720870886535

Epoch: 6| Step: 5
Training loss: 0.11867659521101576
Validation loss: 2.4606488875226833

Epoch: 6| Step: 6
Training loss: 0.11283625973330134
Validation loss: 2.441967488413731

Epoch: 6| Step: 7
Training loss: 0.13853439715919783
Validation loss: 2.408235210173058

Epoch: 6| Step: 8
Training loss: 0.1832896717507412
Validation loss: 2.408144970332661

Epoch: 6| Step: 9
Training loss: 0.07780752047343328
Validation loss: 2.423832685722729

Epoch: 6| Step: 10
Training loss: 0.1287449926263688
Validation loss: 2.4314474228819596

Epoch: 6| Step: 11
Training loss: 0.16198115276047173
Validation loss: 2.4273871658941517

Epoch: 6| Step: 12
Training loss: 0.20073513659230838
Validation loss: 2.432196148306008

Epoch: 6| Step: 13
Training loss: 0.10244954606874185
Validation loss: 2.423065159863134

Epoch: 464| Step: 0
Training loss: 0.10436777480324474
Validation loss: 2.4032224560634625

Epoch: 6| Step: 1
Training loss: 0.18007491681929677
Validation loss: 2.4028293772735587

Epoch: 6| Step: 2
Training loss: 0.18599249883877164
Validation loss: 2.380867062056675

Epoch: 6| Step: 3
Training loss: 0.11594644468304907
Validation loss: 2.3915392908603543

Epoch: 6| Step: 4
Training loss: 0.10815005154167548
Validation loss: 2.392033127338206

Epoch: 6| Step: 5
Training loss: 0.15885654953175204
Validation loss: 2.408604623007531

Epoch: 6| Step: 6
Training loss: 0.10735419048387655
Validation loss: 2.4234568928433173

Epoch: 6| Step: 7
Training loss: 0.1828458445860481
Validation loss: 2.412524126516567

Epoch: 6| Step: 8
Training loss: 0.11508614494673271
Validation loss: 2.393178179233461

Epoch: 6| Step: 9
Training loss: 0.21918740138782364
Validation loss: 2.4298464272006037

Epoch: 6| Step: 10
Training loss: 0.15812889759627877
Validation loss: 2.4066476438734807

Epoch: 6| Step: 11
Training loss: 0.13913765440933917
Validation loss: 2.378536012151061

Epoch: 6| Step: 12
Training loss: 0.11519678359387525
Validation loss: 2.397082486720493

Epoch: 6| Step: 13
Training loss: 0.12049782153590098
Validation loss: 2.387501754077176

Epoch: 465| Step: 0
Training loss: 0.12110543963707547
Validation loss: 2.3826253515239633

Epoch: 6| Step: 1
Training loss: 0.09703215495745658
Validation loss: 2.4023980498127817

Epoch: 6| Step: 2
Training loss: 0.1693147137815071
Validation loss: 2.386784542634977

Epoch: 6| Step: 3
Training loss: 0.07622389667572788
Validation loss: 2.387362786316446

Epoch: 6| Step: 4
Training loss: 0.10788515932021069
Validation loss: 2.369570452401055

Epoch: 6| Step: 5
Training loss: 0.1117660625683317
Validation loss: 2.3780700435985316

Epoch: 6| Step: 6
Training loss: 0.20725390319519368
Validation loss: 2.411170228296606

Epoch: 6| Step: 7
Training loss: 0.1024315406550795
Validation loss: 2.3962968561594646

Epoch: 6| Step: 8
Training loss: 0.14463883983387762
Validation loss: 2.4148931792165826

Epoch: 6| Step: 9
Training loss: 0.2139972482898754
Validation loss: 2.434302464288764

Epoch: 6| Step: 10
Training loss: 0.07995375127604852
Validation loss: 2.4385912298130177

Epoch: 6| Step: 11
Training loss: 0.18516038495689832
Validation loss: 2.4357532903503016

Epoch: 6| Step: 12
Training loss: 0.11752963983274152
Validation loss: 2.4262633304779504

Epoch: 6| Step: 13
Training loss: 0.11319841858852102
Validation loss: 2.451317173220029

Epoch: 466| Step: 0
Training loss: 0.14516435321326884
Validation loss: 2.4656622161753647

Epoch: 6| Step: 1
Training loss: 0.11684582491468626
Validation loss: 2.45626845246542

Epoch: 6| Step: 2
Training loss: 0.11550316739022601
Validation loss: 2.4647874652975825

Epoch: 6| Step: 3
Training loss: 0.09966166376724514
Validation loss: 2.4532195857388794

Epoch: 6| Step: 4
Training loss: 0.1252359086393139
Validation loss: 2.419776058838416

Epoch: 6| Step: 5
Training loss: 0.17440172452955763
Validation loss: 2.4273834789354414

Epoch: 6| Step: 6
Training loss: 0.10200693018828891
Validation loss: 2.4075894350741263

Epoch: 6| Step: 7
Training loss: 0.18768578504184733
Validation loss: 2.432186589166369

Epoch: 6| Step: 8
Training loss: 0.10485152376352
Validation loss: 2.4160648564790788

Epoch: 6| Step: 9
Training loss: 0.10581396261985507
Validation loss: 2.3960095234235053

Epoch: 6| Step: 10
Training loss: 0.14448467999311954
Validation loss: 2.387483509489755

Epoch: 6| Step: 11
Training loss: 0.12910568819364682
Validation loss: 2.407738378577635

Epoch: 6| Step: 12
Training loss: 0.061729170426593795
Validation loss: 2.399277648182536

Epoch: 6| Step: 13
Training loss: 0.2598872652852096
Validation loss: 2.3760384128328513

Epoch: 467| Step: 0
Training loss: 0.14266997475006682
Validation loss: 2.4187577281227584

Epoch: 6| Step: 1
Training loss: 0.13183154346066456
Validation loss: 2.4122809007802264

Epoch: 6| Step: 2
Training loss: 0.18366752319178045
Validation loss: 2.4067091453836373

Epoch: 6| Step: 3
Training loss: 0.1022689759118552
Validation loss: 2.3984039914630073

Epoch: 6| Step: 4
Training loss: 0.11890965884180993
Validation loss: 2.4155061125374417

Epoch: 6| Step: 5
Training loss: 0.09115749749980084
Validation loss: 2.4477676971147138

Epoch: 6| Step: 6
Training loss: 0.08967900721118076
Validation loss: 2.4505760531272553

Epoch: 6| Step: 7
Training loss: 0.13304037992176937
Validation loss: 2.4188686207684764

Epoch: 6| Step: 8
Training loss: 0.14334169143627348
Validation loss: 2.4044721796105892

Epoch: 6| Step: 9
Training loss: 0.12015447192990938
Validation loss: 2.432343484373523

Epoch: 6| Step: 10
Training loss: 0.13536045546168157
Validation loss: 2.402043571029585

Epoch: 6| Step: 11
Training loss: 0.17391158896902456
Validation loss: 2.422324845331589

Epoch: 6| Step: 12
Training loss: 0.18209936807534322
Validation loss: 2.41812376989576

Epoch: 6| Step: 13
Training loss: 0.08464939173225271
Validation loss: 2.411259023532046

Epoch: 468| Step: 0
Training loss: 0.12506393943084074
Validation loss: 2.4111360894389677

Epoch: 6| Step: 1
Training loss: 0.10618417538091107
Validation loss: 2.4158539818226035

Epoch: 6| Step: 2
Training loss: 0.10661173855446684
Validation loss: 2.421632359867532

Epoch: 6| Step: 3
Training loss: 0.12064846137402963
Validation loss: 2.436593136555082

Epoch: 6| Step: 4
Training loss: 0.09231618329372591
Validation loss: 2.4234402015858056

Epoch: 6| Step: 5
Training loss: 0.07282861931262134
Validation loss: 2.4175782735007743

Epoch: 6| Step: 6
Training loss: 0.08377551567276946
Validation loss: 2.433866494096912

Epoch: 6| Step: 7
Training loss: 0.14613995433405913
Validation loss: 2.4327196027278135

Epoch: 6| Step: 8
Training loss: 0.22636213979943615
Validation loss: 2.4411070591202475

Epoch: 6| Step: 9
Training loss: 0.248674117775408
Validation loss: 2.43271276977049

Epoch: 6| Step: 10
Training loss: 0.07339747814507716
Validation loss: 2.4549203884775914

Epoch: 6| Step: 11
Training loss: 0.09856077906425112
Validation loss: 2.417846161300592

Epoch: 6| Step: 12
Training loss: 0.06109132852170209
Validation loss: 2.442282706630802

Epoch: 6| Step: 13
Training loss: 0.08354224775394457
Validation loss: 2.437683971478586

Epoch: 469| Step: 0
Training loss: 0.0810046271195367
Validation loss: 2.4250880590446884

Epoch: 6| Step: 1
Training loss: 0.1328603504036983
Validation loss: 2.416657644226013

Epoch: 6| Step: 2
Training loss: 0.12960820818945526
Validation loss: 2.4308502788158997

Epoch: 6| Step: 3
Training loss: 0.1329802547592397
Validation loss: 2.4407531226928265

Epoch: 6| Step: 4
Training loss: 0.125708761118493
Validation loss: 2.4268820869900267

Epoch: 6| Step: 5
Training loss: 0.21800823981949458
Validation loss: 2.422588701309737

Epoch: 6| Step: 6
Training loss: 0.14582067176371968
Validation loss: 2.3936314432472408

Epoch: 6| Step: 7
Training loss: 0.11397500372857575
Validation loss: 2.4046802287938744

Epoch: 6| Step: 8
Training loss: 0.11990519945093546
Validation loss: 2.3777089173325123

Epoch: 6| Step: 9
Training loss: 0.156737259240547
Validation loss: 2.409023930299889

Epoch: 6| Step: 10
Training loss: 0.12100073102757808
Validation loss: 2.4173040065860545

Epoch: 6| Step: 11
Training loss: 0.13698143926942372
Validation loss: 2.4169899017465704

Epoch: 6| Step: 12
Training loss: 0.1879329451328385
Validation loss: 2.4188550859017823

Epoch: 6| Step: 13
Training loss: 0.13391713465382538
Validation loss: 2.429763594916492

Epoch: 470| Step: 0
Training loss: 0.13113972538558025
Validation loss: 2.434741258323826

Epoch: 6| Step: 1
Training loss: 0.10017452544884631
Validation loss: 2.4349851863764482

Epoch: 6| Step: 2
Training loss: 0.11167998508334999
Validation loss: 2.4222817646017196

Epoch: 6| Step: 3
Training loss: 0.22475681441471085
Validation loss: 2.430614667916846

Epoch: 6| Step: 4
Training loss: 0.1373409418723856
Validation loss: 2.461115375789392

Epoch: 6| Step: 5
Training loss: 0.10554597817526314
Validation loss: 2.4226984048706854

Epoch: 6| Step: 6
Training loss: 0.18165162781236197
Validation loss: 2.4319085471168287

Epoch: 6| Step: 7
Training loss: 0.11032681483036597
Validation loss: 2.478992141312146

Epoch: 6| Step: 8
Training loss: 0.14887966004660416
Validation loss: 2.4339142627505423

Epoch: 6| Step: 9
Training loss: 0.08501422241552904
Validation loss: 2.4575998497511105

Epoch: 6| Step: 10
Training loss: 0.20154355721582326
Validation loss: 2.4539236609618027

Epoch: 6| Step: 11
Training loss: 0.10725355833381797
Validation loss: 2.430995178154702

Epoch: 6| Step: 12
Training loss: 0.12497149827982455
Validation loss: 2.4360718635993344

Epoch: 6| Step: 13
Training loss: 0.05826431888196653
Validation loss: 2.4627114679420608

Epoch: 471| Step: 0
Training loss: 0.2183511026142776
Validation loss: 2.4708192252561303

Epoch: 6| Step: 1
Training loss: 0.07911236418453076
Validation loss: 2.4240048308655178

Epoch: 6| Step: 2
Training loss: 0.12296655091884717
Validation loss: 2.42913231271755

Epoch: 6| Step: 3
Training loss: 0.09821561829480362
Validation loss: 2.4227537129680425

Epoch: 6| Step: 4
Training loss: 0.11505584302964213
Validation loss: 2.4022529302758224

Epoch: 6| Step: 5
Training loss: 0.09584570015365139
Validation loss: 2.4170563956050044

Epoch: 6| Step: 6
Training loss: 0.11139352032214457
Validation loss: 2.4170329859789095

Epoch: 6| Step: 7
Training loss: 0.12727731247095375
Validation loss: 2.4244584450921653

Epoch: 6| Step: 8
Training loss: 0.09107496083362407
Validation loss: 2.410270616538915

Epoch: 6| Step: 9
Training loss: 0.13214749856018218
Validation loss: 2.4418930525256397

Epoch: 6| Step: 10
Training loss: 0.09689291646081276
Validation loss: 2.4236132493872398

Epoch: 6| Step: 11
Training loss: 0.1133357812908398
Validation loss: 2.4315674945212415

Epoch: 6| Step: 12
Training loss: 0.19095733119726058
Validation loss: 2.4328737259202384

Epoch: 6| Step: 13
Training loss: 0.21606949622524213
Validation loss: 2.4388112941797275

Epoch: 472| Step: 0
Training loss: 0.11333984470975496
Validation loss: 2.435584892799028

Epoch: 6| Step: 1
Training loss: 0.10149178427239605
Validation loss: 2.4054317151081666

Epoch: 6| Step: 2
Training loss: 0.10172537892652601
Validation loss: 2.4268548007481203

Epoch: 6| Step: 3
Training loss: 0.20338403251134618
Validation loss: 2.4251448808638982

Epoch: 6| Step: 4
Training loss: 0.10662730870928186
Validation loss: 2.425609340847636

Epoch: 6| Step: 5
Training loss: 0.10373455414495845
Validation loss: 2.377580569509511

Epoch: 6| Step: 6
Training loss: 0.21290590073962662
Validation loss: 2.4120450777203812

Epoch: 6| Step: 7
Training loss: 0.10967108975977316
Validation loss: 2.40442867891919

Epoch: 6| Step: 8
Training loss: 0.1315543593903181
Validation loss: 2.4056900048258294

Epoch: 6| Step: 9
Training loss: 0.1579487663159731
Validation loss: 2.414636041697906

Epoch: 6| Step: 10
Training loss: 0.10842055876862412
Validation loss: 2.3871938065737828

Epoch: 6| Step: 11
Training loss: 0.18548088908139332
Validation loss: 2.4039490745273446

Epoch: 6| Step: 12
Training loss: 0.10889977004860629
Validation loss: 2.3739226196207697

Epoch: 6| Step: 13
Training loss: 0.12366102237279404
Validation loss: 2.4202491238182233

Epoch: 473| Step: 0
Training loss: 0.08044258196804256
Validation loss: 2.4198391384176956

Epoch: 6| Step: 1
Training loss: 0.08687973952057806
Validation loss: 2.417634728372045

Epoch: 6| Step: 2
Training loss: 0.13692875128951762
Validation loss: 2.4271781412939104

Epoch: 6| Step: 3
Training loss: 0.12947016970412892
Validation loss: 2.4338864270459224

Epoch: 6| Step: 4
Training loss: 0.14471006286510002
Validation loss: 2.422981503244922

Epoch: 6| Step: 5
Training loss: 0.15545582406065367
Validation loss: 2.4370965258227373

Epoch: 6| Step: 6
Training loss: 0.13551624622640218
Validation loss: 2.425048127630807

Epoch: 6| Step: 7
Training loss: 0.09622917305267807
Validation loss: 2.4701987818623516

Epoch: 6| Step: 8
Training loss: 0.2523002894151549
Validation loss: 2.4677625389252413

Epoch: 6| Step: 9
Training loss: 0.1494616513728971
Validation loss: 2.446948874733551

Epoch: 6| Step: 10
Training loss: 0.08492807870996884
Validation loss: 2.4482647510658673

Epoch: 6| Step: 11
Training loss: 0.11386143979047907
Validation loss: 2.454524838256477

Epoch: 6| Step: 12
Training loss: 0.1884940045444236
Validation loss: 2.452046751165791

Epoch: 6| Step: 13
Training loss: 0.10808607580509029
Validation loss: 2.456221896138151

Epoch: 474| Step: 0
Training loss: 0.1413104781504316
Validation loss: 2.453706300290853

Epoch: 6| Step: 1
Training loss: 0.17034901175090544
Validation loss: 2.4536288070452787

Epoch: 6| Step: 2
Training loss: 0.11881047766748798
Validation loss: 2.4465149160802313

Epoch: 6| Step: 3
Training loss: 0.22124302074502172
Validation loss: 2.4732267922296423

Epoch: 6| Step: 4
Training loss: 0.13033012575105418
Validation loss: 2.4515223747147705

Epoch: 6| Step: 5
Training loss: 0.11180949293861939
Validation loss: 2.4864550083199224

Epoch: 6| Step: 6
Training loss: 0.10869805708944515
Validation loss: 2.5018222832870785

Epoch: 6| Step: 7
Training loss: 0.12191393945425584
Validation loss: 2.4770688903410165

Epoch: 6| Step: 8
Training loss: 0.07120080932872294
Validation loss: 2.46537432474079

Epoch: 6| Step: 9
Training loss: 0.1737078025231319
Validation loss: 2.466994821977627

Epoch: 6| Step: 10
Training loss: 0.16268545649831861
Validation loss: 2.4412606916453976

Epoch: 6| Step: 11
Training loss: 0.14954711873707524
Validation loss: 2.456270000292108

Epoch: 6| Step: 12
Training loss: 0.07691987500524569
Validation loss: 2.4350208298863025

Epoch: 6| Step: 13
Training loss: 0.049118788572185344
Validation loss: 2.4318914895614974

Epoch: 475| Step: 0
Training loss: 0.1836669248484212
Validation loss: 2.444060707277445

Epoch: 6| Step: 1
Training loss: 0.18270637251984537
Validation loss: 2.4081057789071023

Epoch: 6| Step: 2
Training loss: 0.17667170265974083
Validation loss: 2.4253964294513493

Epoch: 6| Step: 3
Training loss: 0.18370910835044954
Validation loss: 2.4344106274436883

Epoch: 6| Step: 4
Training loss: 0.08400051383268635
Validation loss: 2.4400864097709163

Epoch: 6| Step: 5
Training loss: 0.1255249904864858
Validation loss: 2.4248161851377095

Epoch: 6| Step: 6
Training loss: 0.11899818050396992
Validation loss: 2.4485845129107235

Epoch: 6| Step: 7
Training loss: 0.089928586959567
Validation loss: 2.4526731682288223

Epoch: 6| Step: 8
Training loss: 0.09907052201663358
Validation loss: 2.4689677721213

Epoch: 6| Step: 9
Training loss: 0.07860107208597933
Validation loss: 2.471742096425405

Epoch: 6| Step: 10
Training loss: 0.11322615780103654
Validation loss: 2.457021490897671

Epoch: 6| Step: 11
Training loss: 0.14149711966447415
Validation loss: 2.4619009918152153

Epoch: 6| Step: 12
Training loss: 0.16805548424616354
Validation loss: 2.4890972838098753

Epoch: 6| Step: 13
Training loss: 0.08211694510105386
Validation loss: 2.472881686912521

Epoch: 476| Step: 0
Training loss: 0.15956354372009662
Validation loss: 2.4865566092902034

Epoch: 6| Step: 1
Training loss: 0.1326067817886606
Validation loss: 2.4590693453620966

Epoch: 6| Step: 2
Training loss: 0.10049450524187092
Validation loss: 2.454224578780283

Epoch: 6| Step: 3
Training loss: 0.10428446327965452
Validation loss: 2.436197479255549

Epoch: 6| Step: 4
Training loss: 0.11630648203485386
Validation loss: 2.438493371875396

Epoch: 6| Step: 5
Training loss: 0.08529861256817176
Validation loss: 2.419992250302804

Epoch: 6| Step: 6
Training loss: 0.15805553097669786
Validation loss: 2.4074948876400253

Epoch: 6| Step: 7
Training loss: 0.11513688926263531
Validation loss: 2.4181889010289845

Epoch: 6| Step: 8
Training loss: 0.16063873373312862
Validation loss: 2.4118025716588773

Epoch: 6| Step: 9
Training loss: 0.12288064172818396
Validation loss: 2.4034870502197956

Epoch: 6| Step: 10
Training loss: 0.1066121797037563
Validation loss: 2.4031840100397424

Epoch: 6| Step: 11
Training loss: 0.17104934024576227
Validation loss: 2.4075476081914946

Epoch: 6| Step: 12
Training loss: 0.11459270939251759
Validation loss: 2.405954968536431

Epoch: 6| Step: 13
Training loss: 0.2442448660516929
Validation loss: 2.401349046121996

Epoch: 477| Step: 0
Training loss: 0.08574532023031402
Validation loss: 2.3935566818128517

Epoch: 6| Step: 1
Training loss: 0.07760357599172307
Validation loss: 2.4330462608237307

Epoch: 6| Step: 2
Training loss: 0.05304750222676611
Validation loss: 2.4404074254694956

Epoch: 6| Step: 3
Training loss: 0.11495961553064336
Validation loss: 2.4534678394970317

Epoch: 6| Step: 4
Training loss: 0.10421542476914036
Validation loss: 2.4338126414548293

Epoch: 6| Step: 5
Training loss: 0.10232224930165651
Validation loss: 2.4664362018875043

Epoch: 6| Step: 6
Training loss: 0.15300224502480897
Validation loss: 2.4497278373317877

Epoch: 6| Step: 7
Training loss: 0.10877241027742628
Validation loss: 2.45501513112388

Epoch: 6| Step: 8
Training loss: 0.11646981615899411
Validation loss: 2.4438524413417713

Epoch: 6| Step: 9
Training loss: 0.22506601107040095
Validation loss: 2.4120747650468015

Epoch: 6| Step: 10
Training loss: 0.13187712273313015
Validation loss: 2.382153975982915

Epoch: 6| Step: 11
Training loss: 0.11010829730647992
Validation loss: 2.393858454037623

Epoch: 6| Step: 12
Training loss: 0.18497802470150054
Validation loss: 2.3698990408177703

Epoch: 6| Step: 13
Training loss: 0.07894532645356113
Validation loss: 2.3930586421463387

Epoch: 478| Step: 0
Training loss: 0.10445352980079475
Validation loss: 2.4083914941962976

Epoch: 6| Step: 1
Training loss: 0.20944696548949668
Validation loss: 2.3591190865687275

Epoch: 6| Step: 2
Training loss: 0.18759208643129735
Validation loss: 2.363941806164463

Epoch: 6| Step: 3
Training loss: 0.11114843825183883
Validation loss: 2.413964848571499

Epoch: 6| Step: 4
Training loss: 0.0771719769890191
Validation loss: 2.3947203274341655

Epoch: 6| Step: 5
Training loss: 0.10090184832518469
Validation loss: 2.384506141727814

Epoch: 6| Step: 6
Training loss: 0.06525083551200786
Validation loss: 2.38334594113404

Epoch: 6| Step: 7
Training loss: 0.10382931341922001
Validation loss: 2.411934221044562

Epoch: 6| Step: 8
Training loss: 0.13926676631782098
Validation loss: 2.382933533309722

Epoch: 6| Step: 9
Training loss: 0.1392622723607592
Validation loss: 2.4043559586809424

Epoch: 6| Step: 10
Training loss: 0.11324907947712481
Validation loss: 2.4334378235088683

Epoch: 6| Step: 11
Training loss: 0.136139528281283
Validation loss: 2.405051674655975

Epoch: 6| Step: 12
Training loss: 0.1389976891567402
Validation loss: 2.442524236839132

Epoch: 6| Step: 13
Training loss: 0.10888923761849952
Validation loss: 2.4355889741629193

Epoch: 479| Step: 0
Training loss: 0.18716034324451464
Validation loss: 2.45550116820961

Epoch: 6| Step: 1
Training loss: 0.12388865964771323
Validation loss: 2.4494609380361343

Epoch: 6| Step: 2
Training loss: 0.09295085706747881
Validation loss: 2.4571534998643867

Epoch: 6| Step: 3
Training loss: 0.10665999208726529
Validation loss: 2.429948925447261

Epoch: 6| Step: 4
Training loss: 0.12613877491165404
Validation loss: 2.4325032708782253

Epoch: 6| Step: 5
Training loss: 0.08536515051358695
Validation loss: 2.4281396624650764

Epoch: 6| Step: 6
Training loss: 0.1455194481415335
Validation loss: 2.437405372741204

Epoch: 6| Step: 7
Training loss: 0.08322323726190718
Validation loss: 2.4384321182213307

Epoch: 6| Step: 8
Training loss: 0.13588809672215774
Validation loss: 2.4081814028609703

Epoch: 6| Step: 9
Training loss: 0.11275514571253499
Validation loss: 2.405901406454032

Epoch: 6| Step: 10
Training loss: 0.14039233616893657
Validation loss: 2.422963264474406

Epoch: 6| Step: 11
Training loss: 0.10692771477411414
Validation loss: 2.406505027843519

Epoch: 6| Step: 12
Training loss: 0.1893315662645208
Validation loss: 2.3916331286238925

Epoch: 6| Step: 13
Training loss: 0.1274856402921952
Validation loss: 2.3941547421859144

Epoch: 480| Step: 0
Training loss: 0.13809539622240416
Validation loss: 2.4214954588244253

Epoch: 6| Step: 1
Training loss: 0.10511551089103269
Validation loss: 2.439856827302864

Epoch: 6| Step: 2
Training loss: 0.08074665713292475
Validation loss: 2.4645191105794115

Epoch: 6| Step: 3
Training loss: 0.09834228349706833
Validation loss: 2.4864529173649776

Epoch: 6| Step: 4
Training loss: 0.12713726334465894
Validation loss: 2.48983650981399

Epoch: 6| Step: 5
Training loss: 0.11127464783528587
Validation loss: 2.4522172010921075

Epoch: 6| Step: 6
Training loss: 0.1831720866770157
Validation loss: 2.474598303479364

Epoch: 6| Step: 7
Training loss: 0.10941417026752802
Validation loss: 2.4371401161168076

Epoch: 6| Step: 8
Training loss: 0.15170911501021542
Validation loss: 2.472576445470868

Epoch: 6| Step: 9
Training loss: 0.18865664679318264
Validation loss: 2.454826515754121

Epoch: 6| Step: 10
Training loss: 0.17817216968052024
Validation loss: 2.422954218044081

Epoch: 6| Step: 11
Training loss: 0.17156933567624882
Validation loss: 2.418342229763835

Epoch: 6| Step: 12
Training loss: 0.08137059981525066
Validation loss: 2.410315450332387

Epoch: 6| Step: 13
Training loss: 0.12710223611058416
Validation loss: 2.392534088204981

Epoch: 481| Step: 0
Training loss: 0.1387869800440385
Validation loss: 2.3942410464282298

Epoch: 6| Step: 1
Training loss: 0.09203373503284881
Validation loss: 2.36833735351361

Epoch: 6| Step: 2
Training loss: 0.1813757205543954
Validation loss: 2.371144652629042

Epoch: 6| Step: 3
Training loss: 0.23210709356613898
Validation loss: 2.412874671282343

Epoch: 6| Step: 4
Training loss: 0.20007603511292293
Validation loss: 2.406529209412873

Epoch: 6| Step: 5
Training loss: 0.22686280703817313
Validation loss: 2.411035728238623

Epoch: 6| Step: 6
Training loss: 0.1538712268036701
Validation loss: 2.446554555804195

Epoch: 6| Step: 7
Training loss: 0.10918857234636782
Validation loss: 2.445962117633139

Epoch: 6| Step: 8
Training loss: 0.13499217410274897
Validation loss: 2.469172102976745

Epoch: 6| Step: 9
Training loss: 0.20863269020966912
Validation loss: 2.46063363366868

Epoch: 6| Step: 10
Training loss: 0.17792188792715666
Validation loss: 2.4428752710325634

Epoch: 6| Step: 11
Training loss: 0.09704062969372487
Validation loss: 2.438369465751588

Epoch: 6| Step: 12
Training loss: 0.15092561363031018
Validation loss: 2.439691998339098

Epoch: 6| Step: 13
Training loss: 0.2293447629711559
Validation loss: 2.429611340973085

Epoch: 482| Step: 0
Training loss: 0.20914836047020333
Validation loss: 2.411430198370468

Epoch: 6| Step: 1
Training loss: 0.2230952101944345
Validation loss: 2.38887118841496

Epoch: 6| Step: 2
Training loss: 0.13750551548646303
Validation loss: 2.4230981633756654

Epoch: 6| Step: 3
Training loss: 0.20161655499627423
Validation loss: 2.3778620704042304

Epoch: 6| Step: 4
Training loss: 0.10460836868001527
Validation loss: 2.425529401515399

Epoch: 6| Step: 5
Training loss: 0.19237906554005468
Validation loss: 2.4143030516892834

Epoch: 6| Step: 6
Training loss: 0.09222909950537972
Validation loss: 2.3810719998074608

Epoch: 6| Step: 7
Training loss: 0.18524283545458262
Validation loss: 2.4156857056531558

Epoch: 6| Step: 8
Training loss: 0.1642250663420958
Validation loss: 2.4341282521996135

Epoch: 6| Step: 9
Training loss: 0.16149820455861105
Validation loss: 2.4342965130353136

Epoch: 6| Step: 10
Training loss: 0.17782633362241437
Validation loss: 2.426055288745274

Epoch: 6| Step: 11
Training loss: 0.2091956096042595
Validation loss: 2.4497782174256564

Epoch: 6| Step: 12
Training loss: 0.1616305207329681
Validation loss: 2.472403378025375

Epoch: 6| Step: 13
Training loss: 0.11135365795668166
Validation loss: 2.428125936968569

Epoch: 483| Step: 0
Training loss: 0.1330041134245694
Validation loss: 2.4595153522540194

Epoch: 6| Step: 1
Training loss: 0.1539432541661952
Validation loss: 2.439251503134162

Epoch: 6| Step: 2
Training loss: 0.08731727082715253
Validation loss: 2.4348956315323083

Epoch: 6| Step: 3
Training loss: 0.1120067292676112
Validation loss: 2.3988183240855614

Epoch: 6| Step: 4
Training loss: 0.13223032417750366
Validation loss: 2.3940832154551863

Epoch: 6| Step: 5
Training loss: 0.16203625880034322
Validation loss: 2.416847665293694

Epoch: 6| Step: 6
Training loss: 0.15569917625017624
Validation loss: 2.422067588111342

Epoch: 6| Step: 7
Training loss: 0.11083489881735847
Validation loss: 2.425538337932179

Epoch: 6| Step: 8
Training loss: 0.20494456710566453
Validation loss: 2.434234612186061

Epoch: 6| Step: 9
Training loss: 0.12917001787832305
Validation loss: 2.454591599953871

Epoch: 6| Step: 10
Training loss: 0.17478214949757143
Validation loss: 2.4513490140999936

Epoch: 6| Step: 11
Training loss: 0.20562584713062765
Validation loss: 2.4662284148989904

Epoch: 6| Step: 12
Training loss: 0.09735149514995205
Validation loss: 2.4784303562558065

Epoch: 6| Step: 13
Training loss: 0.09993274874871029
Validation loss: 2.466470506365792

Epoch: 484| Step: 0
Training loss: 0.16806049946097557
Validation loss: 2.4881593209401585

Epoch: 6| Step: 1
Training loss: 0.18608527121778343
Validation loss: 2.493108607394102

Epoch: 6| Step: 2
Training loss: 0.11609443065577266
Validation loss: 2.468946160170987

Epoch: 6| Step: 3
Training loss: 0.10340787569960197
Validation loss: 2.4738840748512567

Epoch: 6| Step: 4
Training loss: 0.1339486972696008
Validation loss: 2.490714545028595

Epoch: 6| Step: 5
Training loss: 0.19502100172715778
Validation loss: 2.4196280212184718

Epoch: 6| Step: 6
Training loss: 0.12244597424194642
Validation loss: 2.4523821624972584

Epoch: 6| Step: 7
Training loss: 0.13602197751674933
Validation loss: 2.4166013654373515

Epoch: 6| Step: 8
Training loss: 0.15888970529929886
Validation loss: 2.423152448806418

Epoch: 6| Step: 9
Training loss: 0.1306407012355232
Validation loss: 2.416901251030093

Epoch: 6| Step: 10
Training loss: 0.18254438774950144
Validation loss: 2.428509622997952

Epoch: 6| Step: 11
Training loss: 0.13687488632110334
Validation loss: 2.4592186178642605

Epoch: 6| Step: 12
Training loss: 0.12344656470369639
Validation loss: 2.449245240188489

Epoch: 6| Step: 13
Training loss: 0.11489887617482286
Validation loss: 2.441765819035543

Epoch: 485| Step: 0
Training loss: 0.1287393935010502
Validation loss: 2.462173275083388

Epoch: 6| Step: 1
Training loss: 0.1873318892089692
Validation loss: 2.4479092261193243

Epoch: 6| Step: 2
Training loss: 0.17207138805940897
Validation loss: 2.4371481326740096

Epoch: 6| Step: 3
Training loss: 0.10995704464433108
Validation loss: 2.444093542397388

Epoch: 6| Step: 4
Training loss: 0.10158893351253981
Validation loss: 2.4500436067833675

Epoch: 6| Step: 5
Training loss: 0.12493951272774464
Validation loss: 2.450301884260932

Epoch: 6| Step: 6
Training loss: 0.1646390050174993
Validation loss: 2.457724266527748

Epoch: 6| Step: 7
Training loss: 0.11596415868067163
Validation loss: 2.485105408574835

Epoch: 6| Step: 8
Training loss: 0.19093078804393532
Validation loss: 2.4718809262847894

Epoch: 6| Step: 9
Training loss: 0.09477338420271152
Validation loss: 2.471943747041784

Epoch: 6| Step: 10
Training loss: 0.114636202196685
Validation loss: 2.4774094273394356

Epoch: 6| Step: 11
Training loss: 0.09300808094631581
Validation loss: 2.4791011544851984

Epoch: 6| Step: 12
Training loss: 0.1190478909846305
Validation loss: 2.46798965066154

Epoch: 6| Step: 13
Training loss: 0.08997755866937192
Validation loss: 2.4628280948276475

Epoch: 486| Step: 0
Training loss: 0.17071121860058702
Validation loss: 2.4243311616056356

Epoch: 6| Step: 1
Training loss: 0.11404883600068078
Validation loss: 2.3804928408131736

Epoch: 6| Step: 2
Training loss: 0.16439391336486947
Validation loss: 2.395853164683512

Epoch: 6| Step: 3
Training loss: 0.09402165691336366
Validation loss: 2.391802972687722

Epoch: 6| Step: 4
Training loss: 0.17472026427268972
Validation loss: 2.388904390676686

Epoch: 6| Step: 5
Training loss: 0.14811745448349745
Validation loss: 2.3928471970915033

Epoch: 6| Step: 6
Training loss: 0.2190283554039362
Validation loss: 2.371499073517048

Epoch: 6| Step: 7
Training loss: 0.11675309888629555
Validation loss: 2.3849389657895133

Epoch: 6| Step: 8
Training loss: 0.10368451250577025
Validation loss: 2.436785498296023

Epoch: 6| Step: 9
Training loss: 0.09067151996754055
Validation loss: 2.4534444387395795

Epoch: 6| Step: 10
Training loss: 0.18966177629259715
Validation loss: 2.4218560277941337

Epoch: 6| Step: 11
Training loss: 0.10017810937827977
Validation loss: 2.4691191600155045

Epoch: 6| Step: 12
Training loss: 0.11784945923898044
Validation loss: 2.4603703671086556

Epoch: 6| Step: 13
Training loss: 0.11758991527691423
Validation loss: 2.4284193020355915

Epoch: 487| Step: 0
Training loss: 0.09023368740232654
Validation loss: 2.4499610639118883

Epoch: 6| Step: 1
Training loss: 0.1230391204751978
Validation loss: 2.4398621356054893

Epoch: 6| Step: 2
Training loss: 0.16983852863620746
Validation loss: 2.4418046350447833

Epoch: 6| Step: 3
Training loss: 0.17335163667348796
Validation loss: 2.4406463430099934

Epoch: 6| Step: 4
Training loss: 0.1281217850886546
Validation loss: 2.416277766804751

Epoch: 6| Step: 5
Training loss: 0.16207137294375468
Validation loss: 2.4263069817377736

Epoch: 6| Step: 6
Training loss: 0.11634453939502555
Validation loss: 2.4018007585368473

Epoch: 6| Step: 7
Training loss: 0.12137049538187182
Validation loss: 2.399885292649025

Epoch: 6| Step: 8
Training loss: 0.09561370058244759
Validation loss: 2.4215544860016216

Epoch: 6| Step: 9
Training loss: 0.15673312954145885
Validation loss: 2.4570540536936467

Epoch: 6| Step: 10
Training loss: 0.09914396050435709
Validation loss: 2.433006668127101

Epoch: 6| Step: 11
Training loss: 0.17791087431118344
Validation loss: 2.441454964231736

Epoch: 6| Step: 12
Training loss: 0.11152335666312847
Validation loss: 2.4682511635266757

Epoch: 6| Step: 13
Training loss: 0.14647204029285288
Validation loss: 2.4532105505600144

Epoch: 488| Step: 0
Training loss: 0.1519684938243893
Validation loss: 2.4433322439163456

Epoch: 6| Step: 1
Training loss: 0.11154857776361209
Validation loss: 2.41557802482762

Epoch: 6| Step: 2
Training loss: 0.1325602730942132
Validation loss: 2.453126539882106

Epoch: 6| Step: 3
Training loss: 0.1453593860377316
Validation loss: 2.4383353523376856

Epoch: 6| Step: 4
Training loss: 0.13198291921010308
Validation loss: 2.4433305263107252

Epoch: 6| Step: 5
Training loss: 0.19063446576427237
Validation loss: 2.4343497104693097

Epoch: 6| Step: 6
Training loss: 0.07691325786396365
Validation loss: 2.4298546630070574

Epoch: 6| Step: 7
Training loss: 0.23453987997748757
Validation loss: 2.444629714218127

Epoch: 6| Step: 8
Training loss: 0.10038899149474881
Validation loss: 2.438147939129682

Epoch: 6| Step: 9
Training loss: 0.06497419934747267
Validation loss: 2.42202385515411

Epoch: 6| Step: 10
Training loss: 0.08236910579368505
Validation loss: 2.419371872640278

Epoch: 6| Step: 11
Training loss: 0.08242281770845028
Validation loss: 2.4198025935047824

Epoch: 6| Step: 12
Training loss: 0.10546836146530358
Validation loss: 2.4054158297310826

Epoch: 6| Step: 13
Training loss: 0.0997353346403612
Validation loss: 2.4005561495929317

Epoch: 489| Step: 0
Training loss: 0.12609849987041485
Validation loss: 2.4162123952943384

Epoch: 6| Step: 1
Training loss: 0.1690503163451524
Validation loss: 2.4361478674857917

Epoch: 6| Step: 2
Training loss: 0.11965824857259659
Validation loss: 2.418603743109871

Epoch: 6| Step: 3
Training loss: 0.12179897669899048
Validation loss: 2.406076036910703

Epoch: 6| Step: 4
Training loss: 0.09304735002628657
Validation loss: 2.4078090556783005

Epoch: 6| Step: 5
Training loss: 0.07186835869913906
Validation loss: 2.417499669092137

Epoch: 6| Step: 6
Training loss: 0.2149364791506445
Validation loss: 2.424627614879561

Epoch: 6| Step: 7
Training loss: 0.20420540901043366
Validation loss: 2.4323567107287123

Epoch: 6| Step: 8
Training loss: 0.12287384310271834
Validation loss: 2.4426409947816596

Epoch: 6| Step: 9
Training loss: 0.1219110288917869
Validation loss: 2.4301667062851706

Epoch: 6| Step: 10
Training loss: 0.10491401432015511
Validation loss: 2.432960389516754

Epoch: 6| Step: 11
Training loss: 0.06128697138295175
Validation loss: 2.432638078098969

Epoch: 6| Step: 12
Training loss: 0.11845324731178143
Validation loss: 2.4144033973246226

Epoch: 6| Step: 13
Training loss: 0.0767570357246989
Validation loss: 2.4392240940868883

Epoch: 490| Step: 0
Training loss: 0.12783062717724503
Validation loss: 2.4446695418100153

Epoch: 6| Step: 1
Training loss: 0.16234553611477753
Validation loss: 2.444742755393722

Epoch: 6| Step: 2
Training loss: 0.0572772748528265
Validation loss: 2.4473889901213832

Epoch: 6| Step: 3
Training loss: 0.1574121529012128
Validation loss: 2.449802569909601

Epoch: 6| Step: 4
Training loss: 0.1277662718608278
Validation loss: 2.4667551847764666

Epoch: 6| Step: 5
Training loss: 0.09512021668954726
Validation loss: 2.4536480236006906

Epoch: 6| Step: 6
Training loss: 0.12753999484832812
Validation loss: 2.47197687889546

Epoch: 6| Step: 7
Training loss: 0.06720452287067581
Validation loss: 2.4786993091016463

Epoch: 6| Step: 8
Training loss: 0.16723567099337705
Validation loss: 2.423279314966542

Epoch: 6| Step: 9
Training loss: 0.14015985091951644
Validation loss: 2.4163114200345923

Epoch: 6| Step: 10
Training loss: 0.08163093345101138
Validation loss: 2.416866027648546

Epoch: 6| Step: 11
Training loss: 0.08445788403158098
Validation loss: 2.4183917912613704

Epoch: 6| Step: 12
Training loss: 0.08564886475825058
Validation loss: 2.4143974124182197

Epoch: 6| Step: 13
Training loss: 0.13430827391460748
Validation loss: 2.43724936087245

Epoch: 491| Step: 0
Training loss: 0.07680157355529502
Validation loss: 2.4311607449058164

Epoch: 6| Step: 1
Training loss: 0.16040313695127092
Validation loss: 2.415121695759781

Epoch: 6| Step: 2
Training loss: 0.0822319459398763
Validation loss: 2.4128659913040202

Epoch: 6| Step: 3
Training loss: 0.1765754876381596
Validation loss: 2.4255794333991987

Epoch: 6| Step: 4
Training loss: 0.1037351017978361
Validation loss: 2.424276990869257

Epoch: 6| Step: 5
Training loss: 0.07674156410106216
Validation loss: 2.4248867112475216

Epoch: 6| Step: 6
Training loss: 0.09075564471467824
Validation loss: 2.4253086124176773

Epoch: 6| Step: 7
Training loss: 0.10802995927231059
Validation loss: 2.432464870293685

Epoch: 6| Step: 8
Training loss: 0.15967829259691224
Validation loss: 2.4433870041600247

Epoch: 6| Step: 9
Training loss: 0.12129813680934745
Validation loss: 2.4300268383562025

Epoch: 6| Step: 10
Training loss: 0.10489431882855306
Validation loss: 2.465737309008672

Epoch: 6| Step: 11
Training loss: 0.10631439487511113
Validation loss: 2.4202671383579655

Epoch: 6| Step: 12
Training loss: 0.06936741839577851
Validation loss: 2.447358161470429

Epoch: 6| Step: 13
Training loss: 0.06879510294113328
Validation loss: 2.464786879717743

Epoch: 492| Step: 0
Training loss: 0.07682992275532743
Validation loss: 2.4402760930049037

Epoch: 6| Step: 1
Training loss: 0.19290522019954787
Validation loss: 2.4312641314736867

Epoch: 6| Step: 2
Training loss: 0.09452624623005035
Validation loss: 2.4384693272444724

Epoch: 6| Step: 3
Training loss: 0.12905024664303616
Validation loss: 2.4299230520402095

Epoch: 6| Step: 4
Training loss: 0.07673661252268403
Validation loss: 2.411091220931444

Epoch: 6| Step: 5
Training loss: 0.11074215201052681
Validation loss: 2.422277689524138

Epoch: 6| Step: 6
Training loss: 0.061613012001510044
Validation loss: 2.414690164888896

Epoch: 6| Step: 7
Training loss: 0.17850881100260602
Validation loss: 2.4246349072995454

Epoch: 6| Step: 8
Training loss: 0.1491261619401096
Validation loss: 2.3953489915266872

Epoch: 6| Step: 9
Training loss: 0.11132739719353742
Validation loss: 2.3973415209262536

Epoch: 6| Step: 10
Training loss: 0.12730126696167396
Validation loss: 2.4252469398741408

Epoch: 6| Step: 11
Training loss: 0.11387840677021684
Validation loss: 2.4257736006457247

Epoch: 6| Step: 12
Training loss: 0.10012190455302293
Validation loss: 2.4317292734101184

Epoch: 6| Step: 13
Training loss: 0.12830614798534024
Validation loss: 2.4122956399523274

Epoch: 493| Step: 0
Training loss: 0.08769141774778806
Validation loss: 2.4028597684625383

Epoch: 6| Step: 1
Training loss: 0.08182287999683888
Validation loss: 2.3842334122365254

Epoch: 6| Step: 2
Training loss: 0.13431948607379177
Validation loss: 2.396938375877553

Epoch: 6| Step: 3
Training loss: 0.16934226925109783
Validation loss: 2.453604303420189

Epoch: 6| Step: 4
Training loss: 0.12248037889684424
Validation loss: 2.3975996369932666

Epoch: 6| Step: 5
Training loss: 0.09315892991136915
Validation loss: 2.404883499695673

Epoch: 6| Step: 6
Training loss: 0.10737638377251657
Validation loss: 2.428597023436883

Epoch: 6| Step: 7
Training loss: 0.18074055676109
Validation loss: 2.431235441366804

Epoch: 6| Step: 8
Training loss: 0.1554511870235522
Validation loss: 2.4028469249379794

Epoch: 6| Step: 9
Training loss: 0.12745007306441425
Validation loss: 2.4025196831716515

Epoch: 6| Step: 10
Training loss: 0.17316633324970399
Validation loss: 2.4397649640987957

Epoch: 6| Step: 11
Training loss: 0.10214612239745136
Validation loss: 2.448791673921222

Epoch: 6| Step: 12
Training loss: 0.15599254617015998
Validation loss: 2.4586474723877934

Epoch: 6| Step: 13
Training loss: 0.11272475834737261
Validation loss: 2.4528044682002013

Epoch: 494| Step: 0
Training loss: 0.1467410255215119
Validation loss: 2.4652364319977678

Epoch: 6| Step: 1
Training loss: 0.11187558502971336
Validation loss: 2.451411200197802

Epoch: 6| Step: 2
Training loss: 0.11732239906115344
Validation loss: 2.4575181912820963

Epoch: 6| Step: 3
Training loss: 0.06420301910075081
Validation loss: 2.463889329126738

Epoch: 6| Step: 4
Training loss: 0.1031327950898254
Validation loss: 2.4535016471630415

Epoch: 6| Step: 5
Training loss: 0.072038829460549
Validation loss: 2.456487313618477

Epoch: 6| Step: 6
Training loss: 0.09892884293965175
Validation loss: 2.4104248212086348

Epoch: 6| Step: 7
Training loss: 0.21564159502217978
Validation loss: 2.3972371445811254

Epoch: 6| Step: 8
Training loss: 0.09333798650317458
Validation loss: 2.3834599699726873

Epoch: 6| Step: 9
Training loss: 0.19249139422836103
Validation loss: 2.3658820524905195

Epoch: 6| Step: 10
Training loss: 0.05506922974687613
Validation loss: 2.362046015066933

Epoch: 6| Step: 11
Training loss: 0.0930250370108857
Validation loss: 2.36657366284634

Epoch: 6| Step: 12
Training loss: 0.08637574466185587
Validation loss: 2.361002506804167

Epoch: 6| Step: 13
Training loss: 0.14669396982362212
Validation loss: 2.3566648970835735

Epoch: 495| Step: 0
Training loss: 0.1100491329279954
Validation loss: 2.3517510545630773

Epoch: 6| Step: 1
Training loss: 0.15584887634139374
Validation loss: 2.375175000075823

Epoch: 6| Step: 2
Training loss: 0.07240154076051969
Validation loss: 2.386597603585065

Epoch: 6| Step: 3
Training loss: 0.10320340160127776
Validation loss: 2.419871308735481

Epoch: 6| Step: 4
Training loss: 0.17112636081190713
Validation loss: 2.4355591682076274

Epoch: 6| Step: 5
Training loss: 0.14829209383515096
Validation loss: 2.4138563539156044

Epoch: 6| Step: 6
Training loss: 0.08094632707241095
Validation loss: 2.432580635106842

Epoch: 6| Step: 7
Training loss: 0.13838476358426374
Validation loss: 2.4141737399934473

Epoch: 6| Step: 8
Training loss: 0.17093361628721496
Validation loss: 2.419340336766413

Epoch: 6| Step: 9
Training loss: 0.1508517256268692
Validation loss: 2.414396682421081

Epoch: 6| Step: 10
Training loss: 0.08069338473398437
Validation loss: 2.4351036865282527

Epoch: 6| Step: 11
Training loss: 0.07420301898082005
Validation loss: 2.3813028320397907

Epoch: 6| Step: 12
Training loss: 0.06756361946255707
Validation loss: 2.4304119425905553

Epoch: 6| Step: 13
Training loss: 0.20105229684828815
Validation loss: 2.4080663015294435

Epoch: 496| Step: 0
Training loss: 0.16340570452364356
Validation loss: 2.4063888827216786

Epoch: 6| Step: 1
Training loss: 0.11510715897872262
Validation loss: 2.3982276879513615

Epoch: 6| Step: 2
Training loss: 0.09958697048365849
Validation loss: 2.407170593054354

Epoch: 6| Step: 3
Training loss: 0.09055537887413312
Validation loss: 2.4128061023744554

Epoch: 6| Step: 4
Training loss: 0.10884885600092958
Validation loss: 2.378995391966071

Epoch: 6| Step: 5
Training loss: 0.15991730426765915
Validation loss: 2.4092645022378893

Epoch: 6| Step: 6
Training loss: 0.1221238819835445
Validation loss: 2.407749694719326

Epoch: 6| Step: 7
Training loss: 0.11435166197059216
Validation loss: 2.4054297913897886

Epoch: 6| Step: 8
Training loss: 0.08513541229148774
Validation loss: 2.388780360877913

Epoch: 6| Step: 9
Training loss: 0.151472375068863
Validation loss: 2.3995208041368206

Epoch: 6| Step: 10
Training loss: 0.11065030381715395
Validation loss: 2.41684876739957

Epoch: 6| Step: 11
Training loss: 0.1762557935777055
Validation loss: 2.408199103145569

Epoch: 6| Step: 12
Training loss: 0.11437746857626499
Validation loss: 2.390255596486846

Epoch: 6| Step: 13
Training loss: 0.11758820056518025
Validation loss: 2.4162153247584524

Epoch: 497| Step: 0
Training loss: 0.1301182999873981
Validation loss: 2.3855191936097975

Epoch: 6| Step: 1
Training loss: 0.1321133978765264
Validation loss: 2.360246985741292

Epoch: 6| Step: 2
Training loss: 0.12674979285922985
Validation loss: 2.385280503863329

Epoch: 6| Step: 3
Training loss: 0.11758298103468764
Validation loss: 2.40782361407286

Epoch: 6| Step: 4
Training loss: 0.14554376606019076
Validation loss: 2.3906356464910035

Epoch: 6| Step: 5
Training loss: 0.17577515697515644
Validation loss: 2.3757545058532448

Epoch: 6| Step: 6
Training loss: 0.10346864587950817
Validation loss: 2.352721938827537

Epoch: 6| Step: 7
Training loss: 0.10198732164333209
Validation loss: 2.3720737882242227

Epoch: 6| Step: 8
Training loss: 0.17252558882072086
Validation loss: 2.3905342862846135

Epoch: 6| Step: 9
Training loss: 0.12939291899054522
Validation loss: 2.3987577961412483

Epoch: 6| Step: 10
Training loss: 0.12032603119644673
Validation loss: 2.3815038472787182

Epoch: 6| Step: 11
Training loss: 0.1516347612095285
Validation loss: 2.402541656039109

Epoch: 6| Step: 12
Training loss: 0.08259636501584763
Validation loss: 2.411514998272774

Epoch: 6| Step: 13
Training loss: 0.10054115576287553
Validation loss: 2.432151336286175

Epoch: 498| Step: 0
Training loss: 0.1037219528411723
Validation loss: 2.4177225919207457

Epoch: 6| Step: 1
Training loss: 0.0879801612011607
Validation loss: 2.4138414107996518

Epoch: 6| Step: 2
Training loss: 0.17777537826588502
Validation loss: 2.4475759973904387

Epoch: 6| Step: 3
Training loss: 0.15005273140455405
Validation loss: 2.4398021664547715

Epoch: 6| Step: 4
Training loss: 0.1776211031802408
Validation loss: 2.4154085682950726

Epoch: 6| Step: 5
Training loss: 0.15358902532969276
Validation loss: 2.4192325865372144

Epoch: 6| Step: 6
Training loss: 0.09649226295413264
Validation loss: 2.4183081298714755

Epoch: 6| Step: 7
Training loss: 0.15273882305761063
Validation loss: 2.4190014898602015

Epoch: 6| Step: 8
Training loss: 0.12598839785551813
Validation loss: 2.4314753877266524

Epoch: 6| Step: 9
Training loss: 0.12351488618068758
Validation loss: 2.4120617888434253

Epoch: 6| Step: 10
Training loss: 0.06718712185598018
Validation loss: 2.4013500864818984

Epoch: 6| Step: 11
Training loss: 0.11825828893776837
Validation loss: 2.4187566957802122

Epoch: 6| Step: 12
Training loss: 0.07228820035761077
Validation loss: 2.3933054742138

Epoch: 6| Step: 13
Training loss: 0.1255166582017294
Validation loss: 2.4186390715585993

Epoch: 499| Step: 0
Training loss: 0.17481410677801862
Validation loss: 2.406703153593332

Epoch: 6| Step: 1
Training loss: 0.07011281241578392
Validation loss: 2.392859307902609

Epoch: 6| Step: 2
Training loss: 0.13286454919894128
Validation loss: 2.3982870013224895

Epoch: 6| Step: 3
Training loss: 0.0903062835289624
Validation loss: 2.412675744303962

Epoch: 6| Step: 4
Training loss: 0.12265030974078032
Validation loss: 2.4054231569475695

Epoch: 6| Step: 5
Training loss: 0.17433354483160654
Validation loss: 2.417111260596889

Epoch: 6| Step: 6
Training loss: 0.10457153070942221
Validation loss: 2.398443804777345

Epoch: 6| Step: 7
Training loss: 0.15135862880013673
Validation loss: 2.4050432260011787

Epoch: 6| Step: 8
Training loss: 0.07346227004933843
Validation loss: 2.3923059771055613

Epoch: 6| Step: 9
Training loss: 0.13493063402928948
Validation loss: 2.457786966708099

Epoch: 6| Step: 10
Training loss: 0.14825904308081164
Validation loss: 2.4100173365291457

Epoch: 6| Step: 11
Training loss: 0.10521944922873973
Validation loss: 2.4235120000990213

Epoch: 6| Step: 12
Training loss: 0.1047469536075441
Validation loss: 2.424668319244362

Epoch: 6| Step: 13
Training loss: 0.06974614720488043
Validation loss: 2.429911341183933

Epoch: 500| Step: 0
Training loss: 0.07873796562172819
Validation loss: 2.4356600009040976

Epoch: 6| Step: 1
Training loss: 0.10153934324806416
Validation loss: 2.4381803341948753

Epoch: 6| Step: 2
Training loss: 0.12354537484346266
Validation loss: 2.436350165515449

Epoch: 6| Step: 3
Training loss: 0.06280254732939589
Validation loss: 2.4158478386804187

Epoch: 6| Step: 4
Training loss: 0.1063836207673236
Validation loss: 2.4436352494223956

Epoch: 6| Step: 5
Training loss: 0.11141825256857171
Validation loss: 2.4177379887348556

Epoch: 6| Step: 6
Training loss: 0.13138685386064414
Validation loss: 2.428631179427328

Epoch: 6| Step: 7
Training loss: 0.14610073715473743
Validation loss: 2.409094104651451

Epoch: 6| Step: 8
Training loss: 0.1638891916880621
Validation loss: 2.4226664715623585

Epoch: 6| Step: 9
Training loss: 0.08281720660887963
Validation loss: 2.40924979240578

Epoch: 6| Step: 10
Training loss: 0.15206838443414744
Validation loss: 2.3941795083952706

Epoch: 6| Step: 11
Training loss: 0.05342444174913445
Validation loss: 2.396766054805715

Epoch: 6| Step: 12
Training loss: 0.1787355749938844
Validation loss: 2.4048628850192872

Epoch: 6| Step: 13
Training loss: 0.20813699749283465
Validation loss: 2.3848239273123233

Epoch: 501| Step: 0
Training loss: 0.10854649098609657
Validation loss: 2.399204875463969

Epoch: 6| Step: 1
Training loss: 0.1224825649845517
Validation loss: 2.3597438366133034

Epoch: 6| Step: 2
Training loss: 0.11050611829756854
Validation loss: 2.3716638089312383

Epoch: 6| Step: 3
Training loss: 0.09892305312014742
Validation loss: 2.381210872832644

Epoch: 6| Step: 4
Training loss: 0.15045130731568349
Validation loss: 2.396548509970216

Epoch: 6| Step: 5
Training loss: 0.06626604861421112
Validation loss: 2.3794051283287905

Epoch: 6| Step: 6
Training loss: 0.09737129599317268
Validation loss: 2.4072389886181713

Epoch: 6| Step: 7
Training loss: 0.17661060610479368
Validation loss: 2.3841718664348917

Epoch: 6| Step: 8
Training loss: 0.1734304809009147
Validation loss: 2.3824111361060205

Epoch: 6| Step: 9
Training loss: 0.11537518222965963
Validation loss: 2.397313711846564

Epoch: 6| Step: 10
Training loss: 0.16046071768829714
Validation loss: 2.3941052181005245

Epoch: 6| Step: 11
Training loss: 0.09341499455475022
Validation loss: 2.395572661726568

Epoch: 6| Step: 12
Training loss: 0.11286760313251018
Validation loss: 2.410136720713148

Epoch: 6| Step: 13
Training loss: 0.16326557476602593
Validation loss: 2.397946780672748

Epoch: 502| Step: 0
Training loss: 0.07533628390421548
Validation loss: 2.4051288975669785

Epoch: 6| Step: 1
Training loss: 0.08193242557588572
Validation loss: 2.4015178849235577

Epoch: 6| Step: 2
Training loss: 0.16451651898486383
Validation loss: 2.431293529295123

Epoch: 6| Step: 3
Training loss: 0.1819868070351968
Validation loss: 2.41504920329149

Epoch: 6| Step: 4
Training loss: 0.1413328712767157
Validation loss: 2.422038235490705

Epoch: 6| Step: 5
Training loss: 0.09835935207848437
Validation loss: 2.4034515854494085

Epoch: 6| Step: 6
Training loss: 0.10115543732715888
Validation loss: 2.4103692142599202

Epoch: 6| Step: 7
Training loss: 0.14877992585427638
Validation loss: 2.355087140251213

Epoch: 6| Step: 8
Training loss: 0.09275172129997707
Validation loss: 2.378665649159366

Epoch: 6| Step: 9
Training loss: 0.08494147812311145
Validation loss: 2.3627824523219907

Epoch: 6| Step: 10
Training loss: 0.11806403016506843
Validation loss: 2.3424457588184264

Epoch: 6| Step: 11
Training loss: 0.11837880664362428
Validation loss: 2.3968331963590823

Epoch: 6| Step: 12
Training loss: 0.1576874771231545
Validation loss: 2.367564762029846

Epoch: 6| Step: 13
Training loss: 0.1053388113042762
Validation loss: 2.3564006907488997

Epoch: 503| Step: 0
Training loss: 0.1734384927635304
Validation loss: 2.3758793742676994

Epoch: 6| Step: 1
Training loss: 0.16775129347514298
Validation loss: 2.4163138655756042

Epoch: 6| Step: 2
Training loss: 0.09363936810705772
Validation loss: 2.4114126525675648

Epoch: 6| Step: 3
Training loss: 0.1003682920647991
Validation loss: 2.4110503963393803

Epoch: 6| Step: 4
Training loss: 0.11054114286436065
Validation loss: 2.440590250267525

Epoch: 6| Step: 5
Training loss: 0.10974252209925023
Validation loss: 2.4296164490210517

Epoch: 6| Step: 6
Training loss: 0.10089212868255103
Validation loss: 2.4289735256058287

Epoch: 6| Step: 7
Training loss: 0.15114662960109151
Validation loss: 2.449003890252238

Epoch: 6| Step: 8
Training loss: 0.10631365026572727
Validation loss: 2.4256228448957398

Epoch: 6| Step: 9
Training loss: 0.0876284583423829
Validation loss: 2.4572369435454484

Epoch: 6| Step: 10
Training loss: 0.13418624562057865
Validation loss: 2.4373134523772713

Epoch: 6| Step: 11
Training loss: 0.07598599961222924
Validation loss: 2.4278239785884175

Epoch: 6| Step: 12
Training loss: 0.0914939182819096
Validation loss: 2.4238969188677815

Epoch: 6| Step: 13
Training loss: 0.10057222402476687
Validation loss: 2.405435239612029

Epoch: 504| Step: 0
Training loss: 0.10066551005396247
Validation loss: 2.4174585834136826

Epoch: 6| Step: 1
Training loss: 0.12114819717752388
Validation loss: 2.40989215405288

Epoch: 6| Step: 2
Training loss: 0.06606075222929834
Validation loss: 2.413413269818969

Epoch: 6| Step: 3
Training loss: 0.1033442716455574
Validation loss: 2.387889119339201

Epoch: 6| Step: 4
Training loss: 0.08176373389681649
Validation loss: 2.43561254541866

Epoch: 6| Step: 5
Training loss: 0.10037747326656503
Validation loss: 2.388597273343112

Epoch: 6| Step: 6
Training loss: 0.16913324168170762
Validation loss: 2.405341701557995

Epoch: 6| Step: 7
Training loss: 0.10545712866158509
Validation loss: 2.4003304173302475

Epoch: 6| Step: 8
Training loss: 0.12667060373669914
Validation loss: 2.4115375947937063

Epoch: 6| Step: 9
Training loss: 0.133529508771732
Validation loss: 2.4542317707219117

Epoch: 6| Step: 10
Training loss: 0.09850854410321419
Validation loss: 2.440750378131451

Epoch: 6| Step: 11
Training loss: 0.1633713332277681
Validation loss: 2.430971453506737

Epoch: 6| Step: 12
Training loss: 0.15969804019818282
Validation loss: 2.409159105328715

Epoch: 6| Step: 13
Training loss: 0.0950846784914366
Validation loss: 2.4284644526439645

Epoch: 505| Step: 0
Training loss: 0.09996557127336904
Validation loss: 2.4300940138291343

Epoch: 6| Step: 1
Training loss: 0.11036571057526921
Validation loss: 2.4011290380427757

Epoch: 6| Step: 2
Training loss: 0.09436693452323824
Validation loss: 2.4246506514294466

Epoch: 6| Step: 3
Training loss: 0.14045292207145396
Validation loss: 2.413197340960705

Epoch: 6| Step: 4
Training loss: 0.1413770144889916
Validation loss: 2.4014416027607117

Epoch: 6| Step: 5
Training loss: 0.16515338481990982
Validation loss: 2.417577829186091

Epoch: 6| Step: 6
Training loss: 0.08919684604690681
Validation loss: 2.4237888423529412

Epoch: 6| Step: 7
Training loss: 0.11827112895971074
Validation loss: 2.399410886012551

Epoch: 6| Step: 8
Training loss: 0.1344525598539614
Validation loss: 2.3916444834510444

Epoch: 6| Step: 9
Training loss: 0.11655029466917852
Validation loss: 2.381572832483523

Epoch: 6| Step: 10
Training loss: 0.07247088896081556
Validation loss: 2.430049339488816

Epoch: 6| Step: 11
Training loss: 0.18875183006687837
Validation loss: 2.3845950152266804

Epoch: 6| Step: 12
Training loss: 0.1428340417946561
Validation loss: 2.404971604178635

Epoch: 6| Step: 13
Training loss: 0.07697339359812086
Validation loss: 2.406274321035915

Epoch: 506| Step: 0
Training loss: 0.09848411606747486
Validation loss: 2.3878492443839203

Epoch: 6| Step: 1
Training loss: 0.09807068148199942
Validation loss: 2.4222345101878764

Epoch: 6| Step: 2
Training loss: 0.09664891938254451
Validation loss: 2.413851657517702

Epoch: 6| Step: 3
Training loss: 0.10594896206696167
Validation loss: 2.427260159561179

Epoch: 6| Step: 4
Training loss: 0.13234566940483058
Validation loss: 2.430227201191008

Epoch: 6| Step: 5
Training loss: 0.1564253419280983
Validation loss: 2.43855960765038

Epoch: 6| Step: 6
Training loss: 0.20738458172447113
Validation loss: 2.4089820203078536

Epoch: 6| Step: 7
Training loss: 0.21131047194499727
Validation loss: 2.4321160718271786

Epoch: 6| Step: 8
Training loss: 0.10203916766508317
Validation loss: 2.402998564409225

Epoch: 6| Step: 9
Training loss: 0.10865658444760985
Validation loss: 2.371587050790769

Epoch: 6| Step: 10
Training loss: 0.09241090008830181
Validation loss: 2.3596165582350856

Epoch: 6| Step: 11
Training loss: 0.20086132078292893
Validation loss: 2.3406098674040363

Epoch: 6| Step: 12
Training loss: 0.14809140212658423
Validation loss: 2.3229536598674185

Epoch: 6| Step: 13
Training loss: 0.13123892073190638
Validation loss: 2.345958143149676

Epoch: 507| Step: 0
Training loss: 0.10272518704307519
Validation loss: 2.3432962176564796

Epoch: 6| Step: 1
Training loss: 0.15076077104753197
Validation loss: 2.343137361039078

Epoch: 6| Step: 2
Training loss: 0.13530031502858653
Validation loss: 2.3724113550206654

Epoch: 6| Step: 3
Training loss: 0.09875255341488011
Validation loss: 2.3782049799955463

Epoch: 6| Step: 4
Training loss: 0.12653275363939734
Validation loss: 2.3766769885256247

Epoch: 6| Step: 5
Training loss: 0.10474377052167624
Validation loss: 2.397126838868501

Epoch: 6| Step: 6
Training loss: 0.11756254818538629
Validation loss: 2.3910121830724527

Epoch: 6| Step: 7
Training loss: 0.21854982413300347
Validation loss: 2.4030553810038264

Epoch: 6| Step: 8
Training loss: 0.16773147235805447
Validation loss: 2.404142671823168

Epoch: 6| Step: 9
Training loss: 0.11969066504882675
Validation loss: 2.398641209089782

Epoch: 6| Step: 10
Training loss: 0.09545598915649914
Validation loss: 2.411460943616419

Epoch: 6| Step: 11
Training loss: 0.13092827050859043
Validation loss: 2.3886029391968813

Epoch: 6| Step: 12
Training loss: 0.16950981008960728
Validation loss: 2.420314257073968

Epoch: 6| Step: 13
Training loss: 0.10696146876054352
Validation loss: 2.429789801318979

Epoch: 508| Step: 0
Training loss: 0.18891464473476413
Validation loss: 2.4016356944014947

Epoch: 6| Step: 1
Training loss: 0.0874264220417971
Validation loss: 2.4198212806661963

Epoch: 6| Step: 2
Training loss: 0.12198333693471014
Validation loss: 2.4108095113256613

Epoch: 6| Step: 3
Training loss: 0.18291442059598473
Validation loss: 2.39833441077164

Epoch: 6| Step: 4
Training loss: 0.1334752418847937
Validation loss: 2.3999828252981112

Epoch: 6| Step: 5
Training loss: 0.11731821558253813
Validation loss: 2.424810090074946

Epoch: 6| Step: 6
Training loss: 0.16820999497356026
Validation loss: 2.4144685056494186

Epoch: 6| Step: 7
Training loss: 0.1384350877319174
Validation loss: 2.4335020685993527

Epoch: 6| Step: 8
Training loss: 0.1720011313333287
Validation loss: 2.405031912048309

Epoch: 6| Step: 9
Training loss: 0.1981603143308593
Validation loss: 2.404643666991975

Epoch: 6| Step: 10
Training loss: 0.14041681907171058
Validation loss: 2.4460892366101255

Epoch: 6| Step: 11
Training loss: 0.12668552806328273
Validation loss: 2.4294507580321536

Epoch: 6| Step: 12
Training loss: 0.11352147331452354
Validation loss: 2.4007105051860447

Epoch: 6| Step: 13
Training loss: 0.07806915432977451
Validation loss: 2.3907078296934685

Epoch: 509| Step: 0
Training loss: 0.10642265813693669
Validation loss: 2.3941640473462855

Epoch: 6| Step: 1
Training loss: 0.10889734122290105
Validation loss: 2.4142677651814206

Epoch: 6| Step: 2
Training loss: 0.18235423285940247
Validation loss: 2.403161919299267

Epoch: 6| Step: 3
Training loss: 0.18686905640938983
Validation loss: 2.3655825223108327

Epoch: 6| Step: 4
Training loss: 0.20274467809585764
Validation loss: 2.425445449380146

Epoch: 6| Step: 5
Training loss: 0.11638840580188212
Validation loss: 2.379592868352741

Epoch: 6| Step: 6
Training loss: 0.08477603589126434
Validation loss: 2.401146746806868

Epoch: 6| Step: 7
Training loss: 0.1706476442189101
Validation loss: 2.4401307708623867

Epoch: 6| Step: 8
Training loss: 0.1135469149621883
Validation loss: 2.4308781962174706

Epoch: 6| Step: 9
Training loss: 0.11337612552830675
Validation loss: 2.4392348526922807

Epoch: 6| Step: 10
Training loss: 0.1558298780977051
Validation loss: 2.4374204603711074

Epoch: 6| Step: 11
Training loss: 0.1199042751556251
Validation loss: 2.434004396131609

Epoch: 6| Step: 12
Training loss: 0.10467528407149652
Validation loss: 2.4120718252397846

Epoch: 6| Step: 13
Training loss: 0.08053867267337053
Validation loss: 2.453884800022833

Epoch: 510| Step: 0
Training loss: 0.12045086669784245
Validation loss: 2.4535918174690106

Epoch: 6| Step: 1
Training loss: 0.12526443198093792
Validation loss: 2.431592650372063

Epoch: 6| Step: 2
Training loss: 0.07541824091977148
Validation loss: 2.4225260705921943

Epoch: 6| Step: 3
Training loss: 0.22348001415759008
Validation loss: 2.373389753347624

Epoch: 6| Step: 4
Training loss: 0.11845011018691165
Validation loss: 2.4006547271508345

Epoch: 6| Step: 5
Training loss: 0.1534390566760498
Validation loss: 2.411449192004721

Epoch: 6| Step: 6
Training loss: 0.09864984497458355
Validation loss: 2.393112845723199

Epoch: 6| Step: 7
Training loss: 0.14681789576576806
Validation loss: 2.4367487832856307

Epoch: 6| Step: 8
Training loss: 0.08598024486488162
Validation loss: 2.3983761829446477

Epoch: 6| Step: 9
Training loss: 0.17773758183195795
Validation loss: 2.402788775069517

Epoch: 6| Step: 10
Training loss: 0.11109056977255075
Validation loss: 2.4097310012150435

Epoch: 6| Step: 11
Training loss: 0.11109010029818862
Validation loss: 2.400727908692934

Epoch: 6| Step: 12
Training loss: 0.07433486313276533
Validation loss: 2.4031470643675634

Epoch: 6| Step: 13
Training loss: 0.14046973027618165
Validation loss: 2.3880396044990846

Epoch: 511| Step: 0
Training loss: 0.08735546261284563
Validation loss: 2.410332004333992

Epoch: 6| Step: 1
Training loss: 0.11052438824024201
Validation loss: 2.401130328869152

Epoch: 6| Step: 2
Training loss: 0.09974438736238252
Validation loss: 2.405800055914373

Epoch: 6| Step: 3
Training loss: 0.10613334506802957
Validation loss: 2.389493822224962

Epoch: 6| Step: 4
Training loss: 0.09725058220968548
Validation loss: 2.414899467040759

Epoch: 6| Step: 5
Training loss: 0.12785487134866805
Validation loss: 2.3744601989314855

Epoch: 6| Step: 6
Training loss: 0.09288633404021661
Validation loss: 2.353899861588779

Epoch: 6| Step: 7
Training loss: 0.1710251855857159
Validation loss: 2.3999074493358235

Epoch: 6| Step: 8
Training loss: 0.13582295820870086
Validation loss: 2.395547399984745

Epoch: 6| Step: 9
Training loss: 0.1988681719157473
Validation loss: 2.407638430503491

Epoch: 6| Step: 10
Training loss: 0.1197925538223698
Validation loss: 2.378384316671289

Epoch: 6| Step: 11
Training loss: 0.09563705051294305
Validation loss: 2.401174967118794

Epoch: 6| Step: 12
Training loss: 0.12462504969938315
Validation loss: 2.3912330608547254

Epoch: 6| Step: 13
Training loss: 0.2115367571722075
Validation loss: 2.4213084351756256

Epoch: 512| Step: 0
Training loss: 0.11244372178781772
Validation loss: 2.4216079326492026

Epoch: 6| Step: 1
Training loss: 0.14821468746546138
Validation loss: 2.476268209047859

Epoch: 6| Step: 2
Training loss: 0.22947989085916218
Validation loss: 2.4826502148720095

Epoch: 6| Step: 3
Training loss: 0.10103853950462469
Validation loss: 2.4948294966813362

Epoch: 6| Step: 4
Training loss: 0.20589860545951058
Validation loss: 2.4553824240964186

Epoch: 6| Step: 5
Training loss: 0.23941217230973208
Validation loss: 2.473615342582576

Epoch: 6| Step: 6
Training loss: 0.16397098986413722
Validation loss: 2.4269234216738695

Epoch: 6| Step: 7
Training loss: 0.22187696409027735
Validation loss: 2.402253374757006

Epoch: 6| Step: 8
Training loss: 0.07297172518368414
Validation loss: 2.3742399030241295

Epoch: 6| Step: 9
Training loss: 0.1463567877486118
Validation loss: 2.3457426945384405

Epoch: 6| Step: 10
Training loss: 0.17229646787234687
Validation loss: 2.38057544959578

Epoch: 6| Step: 11
Training loss: 0.13336434438304098
Validation loss: 2.349628221906803

Epoch: 6| Step: 12
Training loss: 0.13752021207506826
Validation loss: 2.372882171860975

Epoch: 6| Step: 13
Training loss: 0.20046833308853718
Validation loss: 2.3680661379196852

Epoch: 513| Step: 0
Training loss: 0.15803014458331363
Validation loss: 2.3676982415157646

Epoch: 6| Step: 1
Training loss: 0.13267902370867024
Validation loss: 2.405329216610712

Epoch: 6| Step: 2
Training loss: 0.13378130061891128
Validation loss: 2.392465631763165

Epoch: 6| Step: 3
Training loss: 0.11278419955955707
Validation loss: 2.3855268119175834

Epoch: 6| Step: 4
Training loss: 0.16661057173953733
Validation loss: 2.3983435741173627

Epoch: 6| Step: 5
Training loss: 0.1999065456498515
Validation loss: 2.405409237881615

Epoch: 6| Step: 6
Training loss: 0.10217034486090677
Validation loss: 2.4177505394966676

Epoch: 6| Step: 7
Training loss: 0.10252788573613901
Validation loss: 2.393960558579974

Epoch: 6| Step: 8
Training loss: 0.15888202076480332
Validation loss: 2.4076102111490285

Epoch: 6| Step: 9
Training loss: 0.16677432320970254
Validation loss: 2.4166361312153484

Epoch: 6| Step: 10
Training loss: 0.15378948880176016
Validation loss: 2.404976543903696

Epoch: 6| Step: 11
Training loss: 0.10471864030775918
Validation loss: 2.4141340496354307

Epoch: 6| Step: 12
Training loss: 0.12497646139963149
Validation loss: 2.424442882646777

Epoch: 6| Step: 13
Training loss: 0.13080591561668722
Validation loss: 2.41766741738684

Epoch: 514| Step: 0
Training loss: 0.10690888681173444
Validation loss: 2.4389194933539042

Epoch: 6| Step: 1
Training loss: 0.11082458391049077
Validation loss: 2.4329166078976785

Epoch: 6| Step: 2
Training loss: 0.1006169040011572
Validation loss: 2.4290029458729436

Epoch: 6| Step: 3
Training loss: 0.09367599148967508
Validation loss: 2.4325013221970084

Epoch: 6| Step: 4
Training loss: 0.11250068313338242
Validation loss: 2.400268151059373

Epoch: 6| Step: 5
Training loss: 0.08651521064534377
Validation loss: 2.4138878451409758

Epoch: 6| Step: 6
Training loss: 0.15695559211565435
Validation loss: 2.4298922692479112

Epoch: 6| Step: 7
Training loss: 0.09427560551386197
Validation loss: 2.3698884255715233

Epoch: 6| Step: 8
Training loss: 0.17892889895604963
Validation loss: 2.384702487906052

Epoch: 6| Step: 9
Training loss: 0.153298200239776
Validation loss: 2.386826031459962

Epoch: 6| Step: 10
Training loss: 0.0939756251342386
Validation loss: 2.426964453547454

Epoch: 6| Step: 11
Training loss: 0.15932438130706778
Validation loss: 2.436177830400564

Epoch: 6| Step: 12
Training loss: 0.08890791368520137
Validation loss: 2.4319654768036747

Epoch: 6| Step: 13
Training loss: 0.08995713977524745
Validation loss: 2.4277157247252967

Epoch: 515| Step: 0
Training loss: 0.14965305039463844
Validation loss: 2.4372415303017765

Epoch: 6| Step: 1
Training loss: 0.11435469978132616
Validation loss: 2.4560802506580868

Epoch: 6| Step: 2
Training loss: 0.14251345644123764
Validation loss: 2.4178164324455516

Epoch: 6| Step: 3
Training loss: 0.11885127906010753
Validation loss: 2.4423201236070717

Epoch: 6| Step: 4
Training loss: 0.11097571158158424
Validation loss: 2.4564291989208535

Epoch: 6| Step: 5
Training loss: 0.17065691638949845
Validation loss: 2.4499681072239503

Epoch: 6| Step: 6
Training loss: 0.10755504243473074
Validation loss: 2.4333961654296163

Epoch: 6| Step: 7
Training loss: 0.19864588069031713
Validation loss: 2.416941504785555

Epoch: 6| Step: 8
Training loss: 0.09854316414238967
Validation loss: 2.437828686526605

Epoch: 6| Step: 9
Training loss: 0.10017187576877068
Validation loss: 2.429592224475178

Epoch: 6| Step: 10
Training loss: 0.10997053632968307
Validation loss: 2.397973249260405

Epoch: 6| Step: 11
Training loss: 0.10342694028387987
Validation loss: 2.3987074313926913

Epoch: 6| Step: 12
Training loss: 0.15696632575635647
Validation loss: 2.390555841693691

Epoch: 6| Step: 13
Training loss: 0.18351950057132527
Validation loss: 2.413811013699253

Epoch: 516| Step: 0
Training loss: 0.05257732795320923
Validation loss: 2.409568003363916

Epoch: 6| Step: 1
Training loss: 0.11955797856501293
Validation loss: 2.4376587775268064

Epoch: 6| Step: 2
Training loss: 0.14937265607758574
Validation loss: 2.407450331697777

Epoch: 6| Step: 3
Training loss: 0.15294093678926818
Validation loss: 2.374573838276504

Epoch: 6| Step: 4
Training loss: 0.09347487352075205
Validation loss: 2.4090188520165836

Epoch: 6| Step: 5
Training loss: 0.1552721659290382
Validation loss: 2.4182184005561647

Epoch: 6| Step: 6
Training loss: 0.16543227534876578
Validation loss: 2.4395752941914184

Epoch: 6| Step: 7
Training loss: 0.20607679709465765
Validation loss: 2.4232745045901782

Epoch: 6| Step: 8
Training loss: 0.15333337788887863
Validation loss: 2.442919891058882

Epoch: 6| Step: 9
Training loss: 0.12682899128297395
Validation loss: 2.434743505826879

Epoch: 6| Step: 10
Training loss: 0.08987602400561122
Validation loss: 2.4600065424672306

Epoch: 6| Step: 11
Training loss: 0.06994510403306671
Validation loss: 2.4755212653565266

Epoch: 6| Step: 12
Training loss: 0.1581366835111376
Validation loss: 2.4813055547853935

Epoch: 6| Step: 13
Training loss: 0.0868992015906545
Validation loss: 2.5108727262272494

Epoch: 517| Step: 0
Training loss: 0.14838206360272016
Validation loss: 2.5155381009539535

Epoch: 6| Step: 1
Training loss: 0.09785889105088622
Validation loss: 2.4775855514404186

Epoch: 6| Step: 2
Training loss: 0.14122035574205874
Validation loss: 2.4953221815827598

Epoch: 6| Step: 3
Training loss: 0.20088377016194028
Validation loss: 2.487770971342074

Epoch: 6| Step: 4
Training loss: 0.07636912189775215
Validation loss: 2.4474630786942755

Epoch: 6| Step: 5
Training loss: 0.17775223191653378
Validation loss: 2.4449519804041326

Epoch: 6| Step: 6
Training loss: 0.10466274709003785
Validation loss: 2.4585080777300723

Epoch: 6| Step: 7
Training loss: 0.1281121023594751
Validation loss: 2.4175918754289047

Epoch: 6| Step: 8
Training loss: 0.14601977102109404
Validation loss: 2.4090741655659342

Epoch: 6| Step: 9
Training loss: 0.21793771543347207
Validation loss: 2.428482957294275

Epoch: 6| Step: 10
Training loss: 0.19376482022424948
Validation loss: 2.4042534644374873

Epoch: 6| Step: 11
Training loss: 0.12765276398679026
Validation loss: 2.4028568024445214

Epoch: 6| Step: 12
Training loss: 0.13793993249320396
Validation loss: 2.4147969510645253

Epoch: 6| Step: 13
Training loss: 0.14908728050686895
Validation loss: 2.352567563217418

Epoch: 518| Step: 0
Training loss: 0.1858767137621624
Validation loss: 2.4062262433907207

Epoch: 6| Step: 1
Training loss: 0.10739611403480696
Validation loss: 2.3863607830010483

Epoch: 6| Step: 2
Training loss: 0.15866267604448456
Validation loss: 2.405281299135243

Epoch: 6| Step: 3
Training loss: 0.17386046119557022
Validation loss: 2.3968027629813204

Epoch: 6| Step: 4
Training loss: 0.18005650405010476
Validation loss: 2.4049494525742334

Epoch: 6| Step: 5
Training loss: 0.1342865403233829
Validation loss: 2.447351267250828

Epoch: 6| Step: 6
Training loss: 0.17764240023024322
Validation loss: 2.4368749968380494

Epoch: 6| Step: 7
Training loss: 0.142856926257957
Validation loss: 2.44215656418095

Epoch: 6| Step: 8
Training loss: 0.15746710721427237
Validation loss: 2.439602937571694

Epoch: 6| Step: 9
Training loss: 0.22882564414396409
Validation loss: 2.456402425100012

Epoch: 6| Step: 10
Training loss: 0.16069556935731366
Validation loss: 2.421477650872024

Epoch: 6| Step: 11
Training loss: 0.13202756447698688
Validation loss: 2.427785500823056

Epoch: 6| Step: 12
Training loss: 0.05105964751838304
Validation loss: 2.4128412256492107

Epoch: 6| Step: 13
Training loss: 0.14675344550524885
Validation loss: 2.3989864201013567

Epoch: 519| Step: 0
Training loss: 0.11295486984878822
Validation loss: 2.3982776651250783

Epoch: 6| Step: 1
Training loss: 0.14260790135105056
Validation loss: 2.4167748954931296

Epoch: 6| Step: 2
Training loss: 0.1784841108990592
Validation loss: 2.411799203679624

Epoch: 6| Step: 3
Training loss: 0.19099225796492134
Validation loss: 2.436489655193933

Epoch: 6| Step: 4
Training loss: 0.14184071307178422
Validation loss: 2.4451399981513546

Epoch: 6| Step: 5
Training loss: 0.15948579760926326
Validation loss: 2.4351245405306363

Epoch: 6| Step: 6
Training loss: 0.13140115747324835
Validation loss: 2.434296142332087

Epoch: 6| Step: 7
Training loss: 0.11563513057378282
Validation loss: 2.419137688226621

Epoch: 6| Step: 8
Training loss: 0.11494046245696316
Validation loss: 2.39425524483778

Epoch: 6| Step: 9
Training loss: 0.18022593392066522
Validation loss: 2.4096479711105814

Epoch: 6| Step: 10
Training loss: 0.09243060059524036
Validation loss: 2.398490033782388

Epoch: 6| Step: 11
Training loss: 0.15604022965280956
Validation loss: 2.392680885798625

Epoch: 6| Step: 12
Training loss: 0.13427453471626788
Validation loss: 2.396222577748192

Epoch: 6| Step: 13
Training loss: 0.1383902685740751
Validation loss: 2.4084256450806394

Epoch: 520| Step: 0
Training loss: 0.12123735434421844
Validation loss: 2.3921511402893914

Epoch: 6| Step: 1
Training loss: 0.0970787328679265
Validation loss: 2.3876127981246866

Epoch: 6| Step: 2
Training loss: 0.13105324006738125
Validation loss: 2.4216272635617466

Epoch: 6| Step: 3
Training loss: 0.10940435986192289
Validation loss: 2.4154106337189556

Epoch: 6| Step: 4
Training loss: 0.12040685214469551
Validation loss: 2.409147719190057

Epoch: 6| Step: 5
Training loss: 0.17548081366731386
Validation loss: 2.4369461191736863

Epoch: 6| Step: 6
Training loss: 0.1007666584659295
Validation loss: 2.4403662267310957

Epoch: 6| Step: 7
Training loss: 0.16084081027603886
Validation loss: 2.422896660794889

Epoch: 6| Step: 8
Training loss: 0.10719154112568857
Validation loss: 2.423280638426673

Epoch: 6| Step: 9
Training loss: 0.11535166574093093
Validation loss: 2.379736847820627

Epoch: 6| Step: 10
Training loss: 0.19552822597153355
Validation loss: 2.385840225786003

Epoch: 6| Step: 11
Training loss: 0.12239069285318438
Validation loss: 2.3930186187163263

Epoch: 6| Step: 12
Training loss: 0.18821514362045064
Validation loss: 2.375713871487569

Epoch: 6| Step: 13
Training loss: 0.11177279942200334
Validation loss: 2.3796339374375544

Epoch: 521| Step: 0
Training loss: 0.08709024937824612
Validation loss: 2.3660149551204803

Epoch: 6| Step: 1
Training loss: 0.13178483891094858
Validation loss: 2.3352866793538802

Epoch: 6| Step: 2
Training loss: 0.1892594202561878
Validation loss: 2.360328872119976

Epoch: 6| Step: 3
Training loss: 0.10705163615358132
Validation loss: 2.3737212788189646

Epoch: 6| Step: 4
Training loss: 0.17544799049216744
Validation loss: 2.3815676601425966

Epoch: 6| Step: 5
Training loss: 0.0947225117554688
Validation loss: 2.3940896725123535

Epoch: 6| Step: 6
Training loss: 0.1355845269888416
Validation loss: 2.3829401910984047

Epoch: 6| Step: 7
Training loss: 0.13719196168947795
Validation loss: 2.383379235425467

Epoch: 6| Step: 8
Training loss: 0.152158324785908
Validation loss: 2.403700945586806

Epoch: 6| Step: 9
Training loss: 0.15813315575001125
Validation loss: 2.380805023280142

Epoch: 6| Step: 10
Training loss: 0.12563997592196194
Validation loss: 2.3504841928600215

Epoch: 6| Step: 11
Training loss: 0.09648599391613819
Validation loss: 2.3660465332150866

Epoch: 6| Step: 12
Training loss: 0.09947099142368555
Validation loss: 2.362595325314939

Epoch: 6| Step: 13
Training loss: 0.15406803472260885
Validation loss: 2.3614865341365197

Epoch: 522| Step: 0
Training loss: 0.12517843326087152
Validation loss: 2.3675389174706054

Epoch: 6| Step: 1
Training loss: 0.18143574635035659
Validation loss: 2.3630510180594877

Epoch: 6| Step: 2
Training loss: 0.09679387314231262
Validation loss: 2.380699100298652

Epoch: 6| Step: 3
Training loss: 0.08857029272124503
Validation loss: 2.413773680258785

Epoch: 6| Step: 4
Training loss: 0.08408376446044104
Validation loss: 2.3974142165393713

Epoch: 6| Step: 5
Training loss: 0.11937939840472271
Validation loss: 2.40870061427661

Epoch: 6| Step: 6
Training loss: 0.16568607832558793
Validation loss: 2.4204230511553106

Epoch: 6| Step: 7
Training loss: 0.1510160495694858
Validation loss: 2.427738072513592

Epoch: 6| Step: 8
Training loss: 0.10684505263363182
Validation loss: 2.4502204905464073

Epoch: 6| Step: 9
Training loss: 0.1598190677581483
Validation loss: 2.422411048676932

Epoch: 6| Step: 10
Training loss: 0.09236139851758851
Validation loss: 2.407571384771817

Epoch: 6| Step: 11
Training loss: 0.10523364565964016
Validation loss: 2.391579147169038

Epoch: 6| Step: 12
Training loss: 0.1914087801396271
Validation loss: 2.3999998511379292

Epoch: 6| Step: 13
Training loss: 0.14037313688847244
Validation loss: 2.3855623508031187

Epoch: 523| Step: 0
Training loss: 0.13233293173844748
Validation loss: 2.3856974799755784

Epoch: 6| Step: 1
Training loss: 0.14180965917666366
Validation loss: 2.4155925761981494

Epoch: 6| Step: 2
Training loss: 0.11834387850899238
Validation loss: 2.3729710528867693

Epoch: 6| Step: 3
Training loss: 0.12693068232604018
Validation loss: 2.3872087113784137

Epoch: 6| Step: 4
Training loss: 0.19334787276764712
Validation loss: 2.391027598026365

Epoch: 6| Step: 5
Training loss: 0.12326277985506713
Validation loss: 2.323861379251042

Epoch: 6| Step: 6
Training loss: 0.11995382364881298
Validation loss: 2.3670098168921156

Epoch: 6| Step: 7
Training loss: 0.15297089383315096
Validation loss: 2.366375764520102

Epoch: 6| Step: 8
Training loss: 0.09194323356891276
Validation loss: 2.384016320667546

Epoch: 6| Step: 9
Training loss: 0.2053465766439337
Validation loss: 2.3748533401154264

Epoch: 6| Step: 10
Training loss: 0.10451113894434888
Validation loss: 2.384791976510202

Epoch: 6| Step: 11
Training loss: 0.1455715219184058
Validation loss: 2.421078798037929

Epoch: 6| Step: 12
Training loss: 0.08995423054674234
Validation loss: 2.3880302862096854

Epoch: 6| Step: 13
Training loss: 0.12483336845937743
Validation loss: 2.4202267121750696

Epoch: 524| Step: 0
Training loss: 0.08998618031403252
Validation loss: 2.404515295691058

Epoch: 6| Step: 1
Training loss: 0.1487519171735488
Validation loss: 2.4174069523232715

Epoch: 6| Step: 2
Training loss: 0.17299928118302837
Validation loss: 2.4170746344008065

Epoch: 6| Step: 3
Training loss: 0.10545912892999075
Validation loss: 2.4072087778528855

Epoch: 6| Step: 4
Training loss: 0.17066462189488182
Validation loss: 2.4302158103809455

Epoch: 6| Step: 5
Training loss: 0.1205638087672759
Validation loss: 2.388038043580792

Epoch: 6| Step: 6
Training loss: 0.11251613779352422
Validation loss: 2.325179651848175

Epoch: 6| Step: 7
Training loss: 0.10582177807147546
Validation loss: 2.3371726947040266

Epoch: 6| Step: 8
Training loss: 0.1373214109174684
Validation loss: 2.322229745586782

Epoch: 6| Step: 9
Training loss: 0.1683687946490155
Validation loss: 2.354502182933922

Epoch: 6| Step: 10
Training loss: 0.18724168427888718
Validation loss: 2.3170274007753866

Epoch: 6| Step: 11
Training loss: 0.1014419628996036
Validation loss: 2.3352536336224494

Epoch: 6| Step: 12
Training loss: 0.10558609703833763
Validation loss: 2.3254321074661113

Epoch: 6| Step: 13
Training loss: 0.12725797145444123
Validation loss: 2.3964212653012074

Epoch: 525| Step: 0
Training loss: 0.1121671954524694
Validation loss: 2.38295390844052

Epoch: 6| Step: 1
Training loss: 0.08233989541425721
Validation loss: 2.3933830380926278

Epoch: 6| Step: 2
Training loss: 0.17225543638621105
Validation loss: 2.3988197425302156

Epoch: 6| Step: 3
Training loss: 0.14273989657875463
Validation loss: 2.432039949848571

Epoch: 6| Step: 4
Training loss: 0.10320189004573573
Validation loss: 2.4109101243867

Epoch: 6| Step: 5
Training loss: 0.12371626307976652
Validation loss: 2.415019664521714

Epoch: 6| Step: 6
Training loss: 0.11460665488964447
Validation loss: 2.3854077533305165

Epoch: 6| Step: 7
Training loss: 0.10358299006742548
Validation loss: 2.390852646883849

Epoch: 6| Step: 8
Training loss: 0.12201512424338394
Validation loss: 2.352650118978985

Epoch: 6| Step: 9
Training loss: 0.15125897754279422
Validation loss: 2.3399407154081384

Epoch: 6| Step: 10
Training loss: 0.12557722717026853
Validation loss: 2.343791079144089

Epoch: 6| Step: 11
Training loss: 0.10015758488222277
Validation loss: 2.329366067004357

Epoch: 6| Step: 12
Training loss: 0.09147857714425198
Validation loss: 2.324793462789976

Epoch: 6| Step: 13
Training loss: 0.1401199237714769
Validation loss: 2.291091043067587

Epoch: 526| Step: 0
Training loss: 0.14897071910818707
Validation loss: 2.376236730135674

Epoch: 6| Step: 1
Training loss: 0.1118582018569449
Validation loss: 2.3421384733359543

Epoch: 6| Step: 2
Training loss: 0.163605410889877
Validation loss: 2.3576749313115526

Epoch: 6| Step: 3
Training loss: 0.09003181573166376
Validation loss: 2.3434225421062087

Epoch: 6| Step: 4
Training loss: 0.10731862047500974
Validation loss: 2.3704372849506457

Epoch: 6| Step: 5
Training loss: 0.11469883046842703
Validation loss: 2.3809350923417396

Epoch: 6| Step: 6
Training loss: 0.05583615220454136
Validation loss: 2.366309023358365

Epoch: 6| Step: 7
Training loss: 0.17058182952735454
Validation loss: 2.4020110883006094

Epoch: 6| Step: 8
Training loss: 0.08653072408300726
Validation loss: 2.3905364654273376

Epoch: 6| Step: 9
Training loss: 0.09021702740031909
Validation loss: 2.428010632871563

Epoch: 6| Step: 10
Training loss: 0.1451091489452262
Validation loss: 2.4274556276127384

Epoch: 6| Step: 11
Training loss: 0.11218495828304816
Validation loss: 2.398298227372969

Epoch: 6| Step: 12
Training loss: 0.12080569769954942
Validation loss: 2.4274218886171455

Epoch: 6| Step: 13
Training loss: 0.06220143501105579
Validation loss: 2.4284015321888255

Epoch: 527| Step: 0
Training loss: 0.14814589744345288
Validation loss: 2.409553107065726

Epoch: 6| Step: 1
Training loss: 0.12890065065418346
Validation loss: 2.4195494750564377

Epoch: 6| Step: 2
Training loss: 0.09180468160833606
Validation loss: 2.403301858916759

Epoch: 6| Step: 3
Training loss: 0.14865967160734378
Validation loss: 2.4265083770276368

Epoch: 6| Step: 4
Training loss: 0.1460085707216213
Validation loss: 2.3776031521948204

Epoch: 6| Step: 5
Training loss: 0.08728851599553374
Validation loss: 2.3813129883852393

Epoch: 6| Step: 6
Training loss: 0.07736555163088822
Validation loss: 2.3899524398680025

Epoch: 6| Step: 7
Training loss: 0.06443255269578953
Validation loss: 2.3960221917474764

Epoch: 6| Step: 8
Training loss: 0.09739296708334849
Validation loss: 2.332176520162341

Epoch: 6| Step: 9
Training loss: 0.07933163151308559
Validation loss: 2.350347086335807

Epoch: 6| Step: 10
Training loss: 0.14803497422630885
Validation loss: 2.363917541950426

Epoch: 6| Step: 11
Training loss: 0.10481879626671083
Validation loss: 2.352093754154746

Epoch: 6| Step: 12
Training loss: 0.09741424137545414
Validation loss: 2.335207088648783

Epoch: 6| Step: 13
Training loss: 0.12914697970697767
Validation loss: 2.3263618370527706

Epoch: 528| Step: 0
Training loss: 0.10050211348760751
Validation loss: 2.333845752676063

Epoch: 6| Step: 1
Training loss: 0.22570634081045945
Validation loss: 2.331364115653338

Epoch: 6| Step: 2
Training loss: 0.1191758197643197
Validation loss: 2.3607992018901216

Epoch: 6| Step: 3
Training loss: 0.14155694982246306
Validation loss: 2.3646577258973114

Epoch: 6| Step: 4
Training loss: 0.14796375291396513
Validation loss: 2.3773868480657647

Epoch: 6| Step: 5
Training loss: 0.15857525609618342
Validation loss: 2.3998333774856633

Epoch: 6| Step: 6
Training loss: 0.11385326414879036
Validation loss: 2.3965472616043315

Epoch: 6| Step: 7
Training loss: 0.11283436960812016
Validation loss: 2.4037667245418333

Epoch: 6| Step: 8
Training loss: 0.14697685108978711
Validation loss: 2.3984246883762967

Epoch: 6| Step: 9
Training loss: 0.08787779184535138
Validation loss: 2.4352842908879393

Epoch: 6| Step: 10
Training loss: 0.11631607460799459
Validation loss: 2.3832100859126117

Epoch: 6| Step: 11
Training loss: 0.09714980410913439
Validation loss: 2.3919958551014746

Epoch: 6| Step: 12
Training loss: 0.18621679134782393
Validation loss: 2.4013607964511148

Epoch: 6| Step: 13
Training loss: 0.11639263070204395
Validation loss: 2.3692243648646683

Epoch: 529| Step: 0
Training loss: 0.10139811949764921
Validation loss: 2.3910884709516482

Epoch: 6| Step: 1
Training loss: 0.07535115107912947
Validation loss: 2.370640589506896

Epoch: 6| Step: 2
Training loss: 0.11379962735904915
Validation loss: 2.389244889247708

Epoch: 6| Step: 3
Training loss: 0.16981713585673477
Validation loss: 2.3869319247456517

Epoch: 6| Step: 4
Training loss: 0.14787573295574455
Validation loss: 2.409678969428935

Epoch: 6| Step: 5
Training loss: 0.09639439247913763
Validation loss: 2.3927459069983392

Epoch: 6| Step: 6
Training loss: 0.13072045624604542
Validation loss: 2.3831312386316656

Epoch: 6| Step: 7
Training loss: 0.0822881637755227
Validation loss: 2.393664210516737

Epoch: 6| Step: 8
Training loss: 0.07582263480142501
Validation loss: 2.4125963981242218

Epoch: 6| Step: 9
Training loss: 0.12562229555692037
Validation loss: 2.404107320694312

Epoch: 6| Step: 10
Training loss: 0.12090511781172757
Validation loss: 2.41772227911644

Epoch: 6| Step: 11
Training loss: 0.12967158472690804
Validation loss: 2.4308979749142288

Epoch: 6| Step: 12
Training loss: 0.18465645611490525
Validation loss: 2.416038071461654

Epoch: 6| Step: 13
Training loss: 0.19053822871975215
Validation loss: 2.425097867104906

Epoch: 530| Step: 0
Training loss: 0.09297671884956801
Validation loss: 2.4024627343942426

Epoch: 6| Step: 1
Training loss: 0.10618727143618373
Validation loss: 2.4188228040301603

Epoch: 6| Step: 2
Training loss: 0.08457380093786745
Validation loss: 2.4193174303232277

Epoch: 6| Step: 3
Training loss: 0.190202783236913
Validation loss: 2.388911298500614

Epoch: 6| Step: 4
Training loss: 0.19143991758119616
Validation loss: 2.410379403414857

Epoch: 6| Step: 5
Training loss: 0.13174731490124345
Validation loss: 2.3768428912724215

Epoch: 6| Step: 6
Training loss: 0.12163522621380098
Validation loss: 2.37155186135392

Epoch: 6| Step: 7
Training loss: 0.10640755254869705
Validation loss: 2.360848928931345

Epoch: 6| Step: 8
Training loss: 0.10946358771625017
Validation loss: 2.3448732961629046

Epoch: 6| Step: 9
Training loss: 0.07808516798265208
Validation loss: 2.356855257804576

Epoch: 6| Step: 10
Training loss: 0.08451792986627826
Validation loss: 2.3610907557569365

Epoch: 6| Step: 11
Training loss: 0.12103709310595002
Validation loss: 2.3916577923160482

Epoch: 6| Step: 12
Training loss: 0.11043714479244644
Validation loss: 2.362189966283109

Epoch: 6| Step: 13
Training loss: 0.05521535720019723
Validation loss: 2.389115336437552

Epoch: 531| Step: 0
Training loss: 0.09929411683952763
Validation loss: 2.4017190527354284

Epoch: 6| Step: 1
Training loss: 0.1014358758191135
Validation loss: 2.397523408734195

Epoch: 6| Step: 2
Training loss: 0.095234032678028
Validation loss: 2.386937345646168

Epoch: 6| Step: 3
Training loss: 0.14565956599813557
Validation loss: 2.4199829914871964

Epoch: 6| Step: 4
Training loss: 0.08072760090796444
Validation loss: 2.372589934018646

Epoch: 6| Step: 5
Training loss: 0.15009090356274146
Validation loss: 2.385815582544036

Epoch: 6| Step: 6
Training loss: 0.15770433231437012
Validation loss: 2.393169194823292

Epoch: 6| Step: 7
Training loss: 0.06965271019894033
Validation loss: 2.381704143746355

Epoch: 6| Step: 8
Training loss: 0.15573298030721333
Validation loss: 2.382464988485763

Epoch: 6| Step: 9
Training loss: 0.10044276594114675
Validation loss: 2.4023129008763786

Epoch: 6| Step: 10
Training loss: 0.14997062619015986
Validation loss: 2.3728039294622456

Epoch: 6| Step: 11
Training loss: 0.1933003345093889
Validation loss: 2.3542671418117718

Epoch: 6| Step: 12
Training loss: 0.12425898913846016
Validation loss: 2.38453477534293

Epoch: 6| Step: 13
Training loss: 0.09038659587113017
Validation loss: 2.401985891603619

Epoch: 532| Step: 0
Training loss: 0.09750546735784807
Validation loss: 2.376571084357244

Epoch: 6| Step: 1
Training loss: 0.1019882576432614
Validation loss: 2.389717418238382

Epoch: 6| Step: 2
Training loss: 0.16537563156906943
Validation loss: 2.3888056539369225

Epoch: 6| Step: 3
Training loss: 0.13394564494227743
Validation loss: 2.372929948432533

Epoch: 6| Step: 4
Training loss: 0.09404675385967565
Validation loss: 2.381825322175194

Epoch: 6| Step: 5
Training loss: 0.11826460478054451
Validation loss: 2.3882262868337527

Epoch: 6| Step: 6
Training loss: 0.09457395983803885
Validation loss: 2.3913026916548916

Epoch: 6| Step: 7
Training loss: 0.10599716586640424
Validation loss: 2.4011048859020288

Epoch: 6| Step: 8
Training loss: 0.10479171995454853
Validation loss: 2.3753304006116425

Epoch: 6| Step: 9
Training loss: 0.06975664523666138
Validation loss: 2.389663576957955

Epoch: 6| Step: 10
Training loss: 0.11818232671020337
Validation loss: 2.3828863908784954

Epoch: 6| Step: 11
Training loss: 0.19895811422112933
Validation loss: 2.3892418108316966

Epoch: 6| Step: 12
Training loss: 0.09926454846233568
Validation loss: 2.42741421644573

Epoch: 6| Step: 13
Training loss: 0.09289179830876908
Validation loss: 2.4449769670888064

Epoch: 533| Step: 0
Training loss: 0.13083172975861404
Validation loss: 2.4346972881337203

Epoch: 6| Step: 1
Training loss: 0.11714278798665147
Validation loss: 2.4558397441598436

Epoch: 6| Step: 2
Training loss: 0.12211326606345019
Validation loss: 2.442510792647759

Epoch: 6| Step: 3
Training loss: 0.1748427983514627
Validation loss: 2.446069314015902

Epoch: 6| Step: 4
Training loss: 0.10343981161876735
Validation loss: 2.464684840046329

Epoch: 6| Step: 5
Training loss: 0.08894751659538919
Validation loss: 2.506749732945299

Epoch: 6| Step: 6
Training loss: 0.14286903854425087
Validation loss: 2.4780623128102657

Epoch: 6| Step: 7
Training loss: 0.10705410685434325
Validation loss: 2.47923759982175

Epoch: 6| Step: 8
Training loss: 0.10390837853624961
Validation loss: 2.4712310490293503

Epoch: 6| Step: 9
Training loss: 0.1296178869334676
Validation loss: 2.4889208114227204

Epoch: 6| Step: 10
Training loss: 0.1090923727899808
Validation loss: 2.463915275572125

Epoch: 6| Step: 11
Training loss: 0.15297068683305984
Validation loss: 2.447558800784548

Epoch: 6| Step: 12
Training loss: 0.1066523253830617
Validation loss: 2.4141694434927152

Epoch: 6| Step: 13
Training loss: 0.18508555636093574
Validation loss: 2.4221619974829642

Epoch: 534| Step: 0
Training loss: 0.10548836914126643
Validation loss: 2.3983477348900832

Epoch: 6| Step: 1
Training loss: 0.11772826516207864
Validation loss: 2.405011027890742

Epoch: 6| Step: 2
Training loss: 0.07820097685958961
Validation loss: 2.4075978742614526

Epoch: 6| Step: 3
Training loss: 0.10147360432523303
Validation loss: 2.3677277551082025

Epoch: 6| Step: 4
Training loss: 0.09646022818800377
Validation loss: 2.356943195417045

Epoch: 6| Step: 5
Training loss: 0.09198120561883655
Validation loss: 2.3781036893442704

Epoch: 6| Step: 6
Training loss: 0.08657769951546292
Validation loss: 2.3669591903442693

Epoch: 6| Step: 7
Training loss: 0.1353619897632351
Validation loss: 2.3825915399073403

Epoch: 6| Step: 8
Training loss: 0.15560987000664844
Validation loss: 2.3752189782468927

Epoch: 6| Step: 9
Training loss: 0.10693806155551724
Validation loss: 2.378813048243939

Epoch: 6| Step: 10
Training loss: 0.18711582204586422
Validation loss: 2.3877977186985713

Epoch: 6| Step: 11
Training loss: 0.1463582831332148
Validation loss: 2.371003735734866

Epoch: 6| Step: 12
Training loss: 0.1483560953787182
Validation loss: 2.388549741463171

Epoch: 6| Step: 13
Training loss: 0.12218641481868882
Validation loss: 2.405255025014834

Epoch: 535| Step: 0
Training loss: 0.13259406920607472
Validation loss: 2.387730988749894

Epoch: 6| Step: 1
Training loss: 0.11198607319964952
Validation loss: 2.4039305524531986

Epoch: 6| Step: 2
Training loss: 0.1352390460172348
Validation loss: 2.424501652493975

Epoch: 6| Step: 3
Training loss: 0.053023352305915886
Validation loss: 2.4143488387236864

Epoch: 6| Step: 4
Training loss: 0.1281280145057914
Validation loss: 2.397863209946807

Epoch: 6| Step: 5
Training loss: 0.116530252181303
Validation loss: 2.3909202166596275

Epoch: 6| Step: 6
Training loss: 0.18215276444261724
Validation loss: 2.3646237321700023

Epoch: 6| Step: 7
Training loss: 0.11515254008244938
Validation loss: 2.3758146290012214

Epoch: 6| Step: 8
Training loss: 0.17744957459480198
Validation loss: 2.3604293930495084

Epoch: 6| Step: 9
Training loss: 0.14204010633673927
Validation loss: 2.3566518942671397

Epoch: 6| Step: 10
Training loss: 0.17946970220781808
Validation loss: 2.3308033564553097

Epoch: 6| Step: 11
Training loss: 0.13112107484322846
Validation loss: 2.342691869297639

Epoch: 6| Step: 12
Training loss: 0.08500772590972863
Validation loss: 2.3620850617469777

Epoch: 6| Step: 13
Training loss: 0.18795436206334096
Validation loss: 2.380033715558132

Epoch: 536| Step: 0
Training loss: 0.14815790421560737
Validation loss: 2.3838732685732578

Epoch: 6| Step: 1
Training loss: 0.09780701443643233
Validation loss: 2.368793654314879

Epoch: 6| Step: 2
Training loss: 0.08620295652722589
Validation loss: 2.3615193294808465

Epoch: 6| Step: 3
Training loss: 0.22010941952907825
Validation loss: 2.374461172796358

Epoch: 6| Step: 4
Training loss: 0.19909657677718542
Validation loss: 2.408635225509324

Epoch: 6| Step: 5
Training loss: 0.07164445239735005
Validation loss: 2.4091142574645743

Epoch: 6| Step: 6
Training loss: 0.11250317903503974
Validation loss: 2.4256708361333894

Epoch: 6| Step: 7
Training loss: 0.13832005344292278
Validation loss: 2.4483734821711316

Epoch: 6| Step: 8
Training loss: 0.10914479877106968
Validation loss: 2.4400426819427197

Epoch: 6| Step: 9
Training loss: 0.16698431810720907
Validation loss: 2.464522025272498

Epoch: 6| Step: 10
Training loss: 0.21354835294319674
Validation loss: 2.4406228308741365

Epoch: 6| Step: 11
Training loss: 0.1613441814902264
Validation loss: 2.438695512919177

Epoch: 6| Step: 12
Training loss: 0.21120477450455402
Validation loss: 2.4461663881000963

Epoch: 6| Step: 13
Training loss: 0.10577280756056082
Validation loss: 2.43242518276425

Epoch: 537| Step: 0
Training loss: 0.08640059680708453
Validation loss: 2.3944617816079865

Epoch: 6| Step: 1
Training loss: 0.11178637605228135
Validation loss: 2.3605641171387015

Epoch: 6| Step: 2
Training loss: 0.16540346602124528
Validation loss: 2.3661875400191636

Epoch: 6| Step: 3
Training loss: 0.1873733768469176
Validation loss: 2.315386171969556

Epoch: 6| Step: 4
Training loss: 0.1688521354262094
Validation loss: 2.3087648976142803

Epoch: 6| Step: 5
Training loss: 0.17858982672599796
Validation loss: 2.344693301024576

Epoch: 6| Step: 6
Training loss: 0.1433699190799285
Validation loss: 2.327190491033678

Epoch: 6| Step: 7
Training loss: 0.1616733904356739
Validation loss: 2.3608152788908012

Epoch: 6| Step: 8
Training loss: 0.1151961246952104
Validation loss: 2.388160635630263

Epoch: 6| Step: 9
Training loss: 0.18425821226237157
Validation loss: 2.410570656922481

Epoch: 6| Step: 10
Training loss: 0.14415315842347234
Validation loss: 2.4576406589310253

Epoch: 6| Step: 11
Training loss: 0.08846860622480561
Validation loss: 2.4449593584754643

Epoch: 6| Step: 12
Training loss: 0.1766279280805213
Validation loss: 2.4609705310589947

Epoch: 6| Step: 13
Training loss: 0.25959966133397555
Validation loss: 2.4664617972477414

Epoch: 538| Step: 0
Training loss: 0.12919327541299397
Validation loss: 2.436002487448875

Epoch: 6| Step: 1
Training loss: 0.1503194479516234
Validation loss: 2.421345572769508

Epoch: 6| Step: 2
Training loss: 0.16419057161502346
Validation loss: 2.4308189066204355

Epoch: 6| Step: 3
Training loss: 0.28142485216622637
Validation loss: 2.385340951148783

Epoch: 6| Step: 4
Training loss: 0.2841065040556193
Validation loss: 2.398676191357844

Epoch: 6| Step: 5
Training loss: 0.12506344794295873
Validation loss: 2.398424229824505

Epoch: 6| Step: 6
Training loss: 0.2053056363187966
Validation loss: 2.449157400060067

Epoch: 6| Step: 7
Training loss: 0.22255542212214474
Validation loss: 2.4871475579343567

Epoch: 6| Step: 8
Training loss: 0.18012278121042305
Validation loss: 2.482178414357198

Epoch: 6| Step: 9
Training loss: 0.37762649952408617
Validation loss: 2.4586950703049015

Epoch: 6| Step: 10
Training loss: 0.559276510337607
Validation loss: 2.454774607995859

Epoch: 6| Step: 11
Training loss: 0.10208040473671884
Validation loss: 2.3559568919664704

Epoch: 6| Step: 12
Training loss: 0.5083209793225983
Validation loss: 2.3206734446810002

Epoch: 6| Step: 13
Training loss: 0.7190915830219049
Validation loss: 2.388725768683446

Epoch: 539| Step: 0
Training loss: 0.5515732718218246
Validation loss: 2.318915832779167

Epoch: 6| Step: 1
Training loss: 0.2713833902380698
Validation loss: 2.320259821472546

Epoch: 6| Step: 2
Training loss: 0.37738413703195606
Validation loss: 2.3408281901811545

Epoch: 6| Step: 3
Training loss: 0.4934572613547804
Validation loss: 2.3495825986247088

Epoch: 6| Step: 4
Training loss: 0.5450060106086011
Validation loss: 2.33479507610728

Epoch: 6| Step: 5
Training loss: 0.3527976379609294
Validation loss: 2.3173609636535497

Epoch: 6| Step: 6
Training loss: 0.3847975741836355
Validation loss: 2.3097485573047845

Epoch: 6| Step: 7
Training loss: 0.4098935330369605
Validation loss: 2.2745952380904644

Epoch: 6| Step: 8
Training loss: 0.6637478475661499
Validation loss: 2.275595227367282

Epoch: 6| Step: 9
Training loss: 0.5542653048599915
Validation loss: 2.2550180506426596

Epoch: 6| Step: 10
Training loss: 0.5426939124633856
Validation loss: 2.2152130345171406

Epoch: 6| Step: 11
Training loss: 0.665690748343432
Validation loss: 2.250777645698841

Epoch: 6| Step: 12
Training loss: 0.7079858395027844
Validation loss: 2.251223408717582

Epoch: 6| Step: 13
Training loss: 0.4708669227107824
Validation loss: 2.267579411580684

Epoch: 540| Step: 0
Training loss: 0.3714466625369213
Validation loss: 2.3224087231580315

Epoch: 6| Step: 1
Training loss: 0.3036368914553136
Validation loss: 2.330770549909769

Epoch: 6| Step: 2
Training loss: 0.628407582728495
Validation loss: 2.3102989314430236

Epoch: 6| Step: 3
Training loss: 0.2841716385058705
Validation loss: 2.3153983746031095

Epoch: 6| Step: 4
Training loss: 0.38068787063357634
Validation loss: 2.3407153390194577

Epoch: 6| Step: 5
Training loss: 0.41148636718406806
Validation loss: 2.4045858351066838

Epoch: 6| Step: 6
Training loss: 0.2787023498880248
Validation loss: 2.4703365517187197

Epoch: 6| Step: 7
Training loss: 0.39352379007901706
Validation loss: 2.5010334032506156

Epoch: 6| Step: 8
Training loss: 0.4133772307717271
Validation loss: 2.5754400557265353

Epoch: 6| Step: 9
Training loss: 0.6267741770879932
Validation loss: 2.605516782850644

Epoch: 6| Step: 10
Training loss: 0.41920996356390944
Validation loss: 2.5756248803895456

Epoch: 6| Step: 11
Training loss: 0.48365356186358016
Validation loss: 2.5228955152785106

Epoch: 6| Step: 12
Training loss: 0.35491014962095735
Validation loss: 2.4796410225114482

Epoch: 6| Step: 13
Training loss: 0.46453199430804476
Validation loss: 2.4019062984880595

Epoch: 541| Step: 0
Training loss: 0.4281486351561652
Validation loss: 2.3204867367750874

Epoch: 6| Step: 1
Training loss: 0.4620978411204915
Validation loss: 2.321098710687478

Epoch: 6| Step: 2
Training loss: 0.5105570645472038
Validation loss: 2.3249413861223225

Epoch: 6| Step: 3
Training loss: 0.5714751633314326
Validation loss: 2.3185628729854146

Epoch: 6| Step: 4
Training loss: 0.4270858027999319
Validation loss: 2.351977286297041

Epoch: 6| Step: 5
Training loss: 0.3902873678186831
Validation loss: 2.401531179636997

Epoch: 6| Step: 6
Training loss: 0.30886838257330335
Validation loss: 2.4145732407983305

Epoch: 6| Step: 7
Training loss: 0.2513412023479461
Validation loss: 2.435496200519992

Epoch: 6| Step: 8
Training loss: 0.2608660857190579
Validation loss: 2.48358361075301

Epoch: 6| Step: 9
Training loss: 0.3948723291244578
Validation loss: 2.524415947339462

Epoch: 6| Step: 10
Training loss: 0.46880537341800954
Validation loss: 2.536177903933811

Epoch: 6| Step: 11
Training loss: 0.3172480605241247
Validation loss: 2.5220782366201124

Epoch: 6| Step: 12
Training loss: 0.42711460378965427
Validation loss: 2.5073262493562543

Epoch: 6| Step: 13
Training loss: 0.3848882373306325
Validation loss: 2.4991168974783458

Epoch: 542| Step: 0
Training loss: 0.49356922087501937
Validation loss: 2.468884115650744

Epoch: 6| Step: 1
Training loss: 0.33926985504615265
Validation loss: 2.43902108791737

Epoch: 6| Step: 2
Training loss: 0.29050763488082926
Validation loss: 2.4540493061619446

Epoch: 6| Step: 3
Training loss: 0.3204171312218826
Validation loss: 2.3997755541328463

Epoch: 6| Step: 4
Training loss: 0.4152695677692415
Validation loss: 2.4026419708515196

Epoch: 6| Step: 5
Training loss: 0.4033850001445251
Validation loss: 2.3660681491876954

Epoch: 6| Step: 6
Training loss: 0.4368650051605384
Validation loss: 2.3424694011021985

Epoch: 6| Step: 7
Training loss: 0.21257792264290137
Validation loss: 2.370817410636735

Epoch: 6| Step: 8
Training loss: 0.2003960324277271
Validation loss: 2.340334061605434

Epoch: 6| Step: 9
Training loss: 0.3083218209377049
Validation loss: 2.340558751423075

Epoch: 6| Step: 10
Training loss: 0.27607490531369133
Validation loss: 2.3754269141198194

Epoch: 6| Step: 11
Training loss: 0.43053387600998533
Validation loss: 2.393768150945982

Epoch: 6| Step: 12
Training loss: 0.30336609425497196
Validation loss: 2.4193321743112066

Epoch: 6| Step: 13
Training loss: 0.2955860465518251
Validation loss: 2.410911142012179

Epoch: 543| Step: 0
Training loss: 0.3602966432150882
Validation loss: 2.4600139837678756

Epoch: 6| Step: 1
Training loss: 0.4405935113896609
Validation loss: 2.4429406038308072

Epoch: 6| Step: 2
Training loss: 0.3492250727821442
Validation loss: 2.464607727358894

Epoch: 6| Step: 3
Training loss: 0.38537325056076766
Validation loss: 2.4309818958815392

Epoch: 6| Step: 4
Training loss: 0.6384337094904425
Validation loss: 2.4310114384266743

Epoch: 6| Step: 5
Training loss: 0.36400067455234486
Validation loss: 2.388166085946029

Epoch: 6| Step: 6
Training loss: 0.27102427293137876
Validation loss: 2.3730114662968504

Epoch: 6| Step: 7
Training loss: 0.46735953094866506
Validation loss: 2.4233323226293333

Epoch: 6| Step: 8
Training loss: 0.5208614214634806
Validation loss: 2.412042286676273

Epoch: 6| Step: 9
Training loss: 0.7179191597134931
Validation loss: 2.432783046937209

Epoch: 6| Step: 10
Training loss: 0.39840084730119496
Validation loss: 2.444284530653047

Epoch: 6| Step: 11
Training loss: 0.42089434840789397
Validation loss: 2.4120287809956564

Epoch: 6| Step: 12
Training loss: 0.4066170171651231
Validation loss: 2.4554998835184567

Epoch: 6| Step: 13
Training loss: 0.22322732069919884
Validation loss: 2.4492535227621226

Epoch: 544| Step: 0
Training loss: 0.25104147817412037
Validation loss: 2.448530584016164

Epoch: 6| Step: 1
Training loss: 0.37142375527654947
Validation loss: 2.404243528691047

Epoch: 6| Step: 2
Training loss: 0.29537713993409626
Validation loss: 2.4275783277174035

Epoch: 6| Step: 3
Training loss: 0.5591417305735411
Validation loss: 2.419591766740376

Epoch: 6| Step: 4
Training loss: 0.3114861732126747
Validation loss: 2.417227162026345

Epoch: 6| Step: 5
Training loss: 0.21679355859367783
Validation loss: 2.38921989591449

Epoch: 6| Step: 6
Training loss: 0.42670614946800633
Validation loss: 2.3685209063668116

Epoch: 6| Step: 7
Training loss: 0.508166761805341
Validation loss: 2.351387129948295

Epoch: 6| Step: 8
Training loss: 0.21394149151409816
Validation loss: 2.3262000022598257

Epoch: 6| Step: 9
Training loss: 0.3948471579727294
Validation loss: 2.3334420016982405

Epoch: 6| Step: 10
Training loss: 0.2606997508972962
Validation loss: 2.374604803774435

Epoch: 6| Step: 11
Training loss: 0.47997888543458656
Validation loss: 2.3668418124758275

Epoch: 6| Step: 12
Training loss: 0.26028558133950636
Validation loss: 2.3934248811501706

Epoch: 6| Step: 13
Training loss: 0.3026989823848833
Validation loss: 2.4242255668613955

Epoch: 545| Step: 0
Training loss: 0.16151528482031355
Validation loss: 2.4471440146844103

Epoch: 6| Step: 1
Training loss: 0.23270560825349468
Validation loss: 2.4583202804572073

Epoch: 6| Step: 2
Training loss: 0.2954036743461777
Validation loss: 2.483256015728804

Epoch: 6| Step: 3
Training loss: 0.2886844947131608
Validation loss: 2.469378405804319

Epoch: 6| Step: 4
Training loss: 0.20007611890008326
Validation loss: 2.4852633893302793

Epoch: 6| Step: 5
Training loss: 0.178092951150131
Validation loss: 2.500682689401139

Epoch: 6| Step: 6
Training loss: 0.4167952418630507
Validation loss: 2.4693429280822468

Epoch: 6| Step: 7
Training loss: 0.3072137639604677
Validation loss: 2.444247385769647

Epoch: 6| Step: 8
Training loss: 0.26332600832863523
Validation loss: 2.4195542801240166

Epoch: 6| Step: 9
Training loss: 0.33139144738504606
Validation loss: 2.3868522893342483

Epoch: 6| Step: 10
Training loss: 0.35027252469412357
Validation loss: 2.3854612156527404

Epoch: 6| Step: 11
Training loss: 0.3768577455015424
Validation loss: 2.4357165555707425

Epoch: 6| Step: 12
Training loss: 0.29588254879635617
Validation loss: 2.4428417549731845

Epoch: 6| Step: 13
Training loss: 0.5904937598329142
Validation loss: 2.477493348766327

Epoch: 546| Step: 0
Training loss: 0.5251974722185483
Validation loss: 2.4768823306052172

Epoch: 6| Step: 1
Training loss: 0.3212484316657706
Validation loss: 2.4948591638104194

Epoch: 6| Step: 2
Training loss: 0.19885175223572463
Validation loss: 2.4526634254950026

Epoch: 6| Step: 3
Training loss: 0.3097931093239217
Validation loss: 2.4340886102228456

Epoch: 6| Step: 4
Training loss: 0.379554881572978
Validation loss: 2.3996362795734756

Epoch: 6| Step: 5
Training loss: 0.6731200547598954
Validation loss: 2.39010140180082

Epoch: 6| Step: 6
Training loss: 0.6979810533192818
Validation loss: 2.3849977185483557

Epoch: 6| Step: 7
Training loss: 0.40934031026495665
Validation loss: 2.3541685117612143

Epoch: 6| Step: 8
Training loss: 0.2875787440559918
Validation loss: 2.340045311162793

Epoch: 6| Step: 9
Training loss: 0.4672396487216594
Validation loss: 2.3330473644030683

Epoch: 6| Step: 10
Training loss: 0.4106644524676114
Validation loss: 2.3543209780742744

Epoch: 6| Step: 11
Training loss: 0.35232404243519383
Validation loss: 2.371796642671885

Epoch: 6| Step: 12
Training loss: 0.38100088376095415
Validation loss: 2.417721984338108

Epoch: 6| Step: 13
Training loss: 0.5640074610605548
Validation loss: 2.4190973618612865

Epoch: 547| Step: 0
Training loss: 0.4850483029439172
Validation loss: 2.4407229344486794

Epoch: 6| Step: 1
Training loss: 0.545086169342741
Validation loss: 2.4825583634608757

Epoch: 6| Step: 2
Training loss: 0.4240286392321587
Validation loss: 2.5053308737657933

Epoch: 6| Step: 3
Training loss: 0.4832815934582984
Validation loss: 2.4815885634012385

Epoch: 6| Step: 4
Training loss: 0.5366050433187394
Validation loss: 2.44518298269008

Epoch: 6| Step: 5
Training loss: 0.4308499996655887
Validation loss: 2.342884237432909

Epoch: 6| Step: 6
Training loss: 0.3701595392882129
Validation loss: 2.3188780314947657

Epoch: 6| Step: 7
Training loss: 0.5105685637346647
Validation loss: 2.311054780309802

Epoch: 6| Step: 8
Training loss: 0.5224225466874923
Validation loss: 2.346594725780456

Epoch: 6| Step: 9
Training loss: 0.6286881584029784
Validation loss: 2.3542080849341676

Epoch: 6| Step: 10
Training loss: 0.6573812180910672
Validation loss: 2.3951995783606104

Epoch: 6| Step: 11
Training loss: 0.4032179584816179
Validation loss: 2.3480889653551538

Epoch: 6| Step: 12
Training loss: 0.3909493434950745
Validation loss: 2.337565094661811

Epoch: 6| Step: 13
Training loss: 0.7266689345633555
Validation loss: 2.350764654532668

Epoch: 548| Step: 0
Training loss: 0.45442542555833637
Validation loss: 2.4494290736591178

Epoch: 6| Step: 1
Training loss: 0.7532815271965361
Validation loss: 2.463072588637494

Epoch: 6| Step: 2
Training loss: 0.693288579200931
Validation loss: 2.435449387108538

Epoch: 6| Step: 3
Training loss: 0.45833369457346235
Validation loss: 2.4306560256123695

Epoch: 6| Step: 4
Training loss: 0.7170128769722469
Validation loss: 2.471222889910885

Epoch: 6| Step: 5
Training loss: 0.5320086111666079
Validation loss: 2.4921893927536463

Epoch: 6| Step: 6
Training loss: 0.4614083100094331
Validation loss: 2.4774300928665847

Epoch: 6| Step: 7
Training loss: 0.3925026778415277
Validation loss: 2.459119724854199

Epoch: 6| Step: 8
Training loss: 0.25187528132193404
Validation loss: 2.472078788685684

Epoch: 6| Step: 9
Training loss: 0.42099267033065724
Validation loss: 2.4444217185773813

Epoch: 6| Step: 10
Training loss: 0.453850116640164
Validation loss: 2.437700621471122

Epoch: 6| Step: 11
Training loss: 0.4574555929446843
Validation loss: 2.425836005905753

Epoch: 6| Step: 12
Training loss: 0.5565864135042784
Validation loss: 2.3987482181032815

Epoch: 6| Step: 13
Training loss: 0.292932152051639
Validation loss: 2.399683912887616

Epoch: 549| Step: 0
Training loss: 0.4681889036842726
Validation loss: 2.366835143522479

Epoch: 6| Step: 1
Training loss: 0.5224099107584267
Validation loss: 2.4092722295457136

Epoch: 6| Step: 2
Training loss: 0.39273117649953027
Validation loss: 2.369032209356684

Epoch: 6| Step: 3
Training loss: 0.6312806461939963
Validation loss: 2.381990472973953

Epoch: 6| Step: 4
Training loss: 0.2612288715634585
Validation loss: 2.36731927781682

Epoch: 6| Step: 5
Training loss: 0.27352726689012874
Validation loss: 2.369906711501632

Epoch: 6| Step: 6
Training loss: 0.38686102359651103
Validation loss: 2.3363469277725115

Epoch: 6| Step: 7
Training loss: 0.4094367483030525
Validation loss: 2.3365435311952125

Epoch: 6| Step: 8
Training loss: 0.3875559020481222
Validation loss: 2.388761742920487

Epoch: 6| Step: 9
Training loss: 0.28420779164617826
Validation loss: 2.3905555242622114

Epoch: 6| Step: 10
Training loss: 0.3559298616147342
Validation loss: 2.3806980595290668

Epoch: 6| Step: 11
Training loss: 0.20435456287497164
Validation loss: 2.416605189782281

Epoch: 6| Step: 12
Training loss: 0.27425417874994307
Validation loss: 2.4183705343128654

Epoch: 6| Step: 13
Training loss: 0.33894844070438296
Validation loss: 2.4283428920915506

Epoch: 550| Step: 0
Training loss: 0.4625383477164803
Validation loss: 2.421587032646709

Epoch: 6| Step: 1
Training loss: 0.22829780630848975
Validation loss: 2.41720381927979

Epoch: 6| Step: 2
Training loss: 0.3168888885042685
Validation loss: 2.372826902193103

Epoch: 6| Step: 3
Training loss: 0.4441809079867436
Validation loss: 2.344746964591613

Epoch: 6| Step: 4
Training loss: 0.30280427433411794
Validation loss: 2.325501214308794

Epoch: 6| Step: 5
Training loss: 0.3449308746304329
Validation loss: 2.3607230059512223

Epoch: 6| Step: 6
Training loss: 0.4284104182436884
Validation loss: 2.350020762604695

Epoch: 6| Step: 7
Training loss: 0.2264297688486053
Validation loss: 2.34835460352981

Epoch: 6| Step: 8
Training loss: 0.37672818840161565
Validation loss: 2.394871039544179

Epoch: 6| Step: 9
Training loss: 0.31696120208836753
Validation loss: 2.4062920470679865

Epoch: 6| Step: 10
Training loss: 0.3068227652205792
Validation loss: 2.443276717532507

Epoch: 6| Step: 11
Training loss: 0.4327463684789121
Validation loss: 2.451778255641404

Epoch: 6| Step: 12
Training loss: 0.3057643372464094
Validation loss: 2.4672572517979177

Epoch: 6| Step: 13
Training loss: 0.3125134703593983
Validation loss: 2.5117067489116596

Epoch: 551| Step: 0
Training loss: 0.3764107711096088
Validation loss: 2.5345337438096625

Epoch: 6| Step: 1
Training loss: 0.2021008587559203
Validation loss: 2.509829071546608

Epoch: 6| Step: 2
Training loss: 0.20609551517925082
Validation loss: 2.465804650853861

Epoch: 6| Step: 3
Training loss: 0.22830319923767164
Validation loss: 2.47757092026629

Epoch: 6| Step: 4
Training loss: 0.31419194671036876
Validation loss: 2.476529357032094

Epoch: 6| Step: 5
Training loss: 0.2612042137571019
Validation loss: 2.4555261185429433

Epoch: 6| Step: 6
Training loss: 0.23927767145690074
Validation loss: 2.4573989171287574

Epoch: 6| Step: 7
Training loss: 0.18488315529854996
Validation loss: 2.4394399439516694

Epoch: 6| Step: 8
Training loss: 0.2004058289290739
Validation loss: 2.416514680076754

Epoch: 6| Step: 9
Training loss: 0.34783813990420553
Validation loss: 2.4474635521500208

Epoch: 6| Step: 10
Training loss: 0.194738507837055
Validation loss: 2.4165701339446066

Epoch: 6| Step: 11
Training loss: 0.21910725099738806
Validation loss: 2.412152341284197

Epoch: 6| Step: 12
Training loss: 0.3449607248341256
Validation loss: 2.397648757438877

Epoch: 6| Step: 13
Training loss: 0.26773868393693456
Validation loss: 2.4261990765079164

Epoch: 552| Step: 0
Training loss: 0.2739774821784673
Validation loss: 2.3969227818170515

Epoch: 6| Step: 1
Training loss: 0.27284358783665114
Validation loss: 2.4122742097253744

Epoch: 6| Step: 2
Training loss: 0.17241136350338035
Validation loss: 2.357195815881048

Epoch: 6| Step: 3
Training loss: 0.26298620291879177
Validation loss: 2.368130004353738

Epoch: 6| Step: 4
Training loss: 0.37885785531167815
Validation loss: 2.3477414921568003

Epoch: 6| Step: 5
Training loss: 0.30953692909049124
Validation loss: 2.3360033949580647

Epoch: 6| Step: 6
Training loss: 0.2950379983020905
Validation loss: 2.3298092234045638

Epoch: 6| Step: 7
Training loss: 0.27352951408976367
Validation loss: 2.355629802687393

Epoch: 6| Step: 8
Training loss: 0.3549714434918059
Validation loss: 2.360856840769389

Epoch: 6| Step: 9
Training loss: 0.23087521448677895
Validation loss: 2.3944932613120598

Epoch: 6| Step: 10
Training loss: 0.21693968150515514
Validation loss: 2.4203786047765354

Epoch: 6| Step: 11
Training loss: 0.2573610022528562
Validation loss: 2.410929367750008

Epoch: 6| Step: 12
Training loss: 0.1951436361843694
Validation loss: 2.4210621613310748

Epoch: 6| Step: 13
Training loss: 0.19806263689750836
Validation loss: 2.4485791795438128

Epoch: 553| Step: 0
Training loss: 0.23826780437618747
Validation loss: 2.4311962177728397

Epoch: 6| Step: 1
Training loss: 0.20075224655789797
Validation loss: 2.4677703936745092

Epoch: 6| Step: 2
Training loss: 0.18181392647087577
Validation loss: 2.486482062726328

Epoch: 6| Step: 3
Training loss: 0.2655134668122765
Validation loss: 2.478218307407154

Epoch: 6| Step: 4
Training loss: 0.26719578345324657
Validation loss: 2.4992283255671413

Epoch: 6| Step: 5
Training loss: 0.23968743657505434
Validation loss: 2.465623122787889

Epoch: 6| Step: 6
Training loss: 0.2080159521525127
Validation loss: 2.472110169268542

Epoch: 6| Step: 7
Training loss: 0.21386619463128373
Validation loss: 2.461445469670957

Epoch: 6| Step: 8
Training loss: 0.14097412798548076
Validation loss: 2.443631345945592

Epoch: 6| Step: 9
Training loss: 0.30403944935712646
Validation loss: 2.4463750197846

Epoch: 6| Step: 10
Training loss: 0.19402040332121337
Validation loss: 2.459013216231914

Epoch: 6| Step: 11
Training loss: 0.2773924502745288
Validation loss: 2.435788560564113

Epoch: 6| Step: 12
Training loss: 0.33272808105721263
Validation loss: 2.432645211613064

Epoch: 6| Step: 13
Training loss: 0.19946362834966752
Validation loss: 2.4576743382639856

Epoch: 554| Step: 0
Training loss: 0.1887304246774705
Validation loss: 2.401686908263475

Epoch: 6| Step: 1
Training loss: 0.2702488675495173
Validation loss: 2.392313208915725

Epoch: 6| Step: 2
Training loss: 0.28650871036180714
Validation loss: 2.3788858455893753

Epoch: 6| Step: 3
Training loss: 0.15757520889511678
Validation loss: 2.3962970650446076

Epoch: 6| Step: 4
Training loss: 0.16572401577825155
Validation loss: 2.390378010190597

Epoch: 6| Step: 5
Training loss: 0.17807404056881318
Validation loss: 2.3709503939774335

Epoch: 6| Step: 6
Training loss: 0.1508549236014242
Validation loss: 2.4015336444990982

Epoch: 6| Step: 7
Training loss: 0.14821255102430986
Validation loss: 2.402368918399678

Epoch: 6| Step: 8
Training loss: 0.14914289189010177
Validation loss: 2.424834947050877

Epoch: 6| Step: 9
Training loss: 0.20720483592306288
Validation loss: 2.4678425510663207

Epoch: 6| Step: 10
Training loss: 0.33834592099725086
Validation loss: 2.4743646214040216

Epoch: 6| Step: 11
Training loss: 0.24734626407273372
Validation loss: 2.466355456009998

Epoch: 6| Step: 12
Training loss: 0.1975695091773361
Validation loss: 2.4672736242906663

Epoch: 6| Step: 13
Training loss: 0.23654363594783173
Validation loss: 2.465867639926283

Epoch: 555| Step: 0
Training loss: 0.17487699196071596
Validation loss: 2.452685698575642

Epoch: 6| Step: 1
Training loss: 0.18326299376431948
Validation loss: 2.45425683737246

Epoch: 6| Step: 2
Training loss: 0.1656671513146025
Validation loss: 2.463813193559821

Epoch: 6| Step: 3
Training loss: 0.21825466955352313
Validation loss: 2.4870706263194804

Epoch: 6| Step: 4
Training loss: 0.24870916244618732
Validation loss: 2.4764693922564947

Epoch: 6| Step: 5
Training loss: 0.19597816518333913
Validation loss: 2.451815034179257

Epoch: 6| Step: 6
Training loss: 0.25076923638680676
Validation loss: 2.4484038922997873

Epoch: 6| Step: 7
Training loss: 0.18223656548196931
Validation loss: 2.463728691688155

Epoch: 6| Step: 8
Training loss: 0.18748524727003665
Validation loss: 2.4062074791473145

Epoch: 6| Step: 9
Training loss: 0.16644702846033796
Validation loss: 2.427603407685475

Epoch: 6| Step: 10
Training loss: 0.15859089529352735
Validation loss: 2.4341112112525547

Epoch: 6| Step: 11
Training loss: 0.3248494689129737
Validation loss: 2.42995641923084

Epoch: 6| Step: 12
Training loss: 0.25001364909105817
Validation loss: 2.46700681195568

Epoch: 6| Step: 13
Training loss: 0.2329281893932601
Validation loss: 2.483446832821413

Epoch: 556| Step: 0
Training loss: 0.15692511383105384
Validation loss: 2.449898012496256

Epoch: 6| Step: 1
Training loss: 0.24298496621529542
Validation loss: 2.44975887737713

Epoch: 6| Step: 2
Training loss: 0.24258005721939785
Validation loss: 2.4352406742177073

Epoch: 6| Step: 3
Training loss: 0.37916758462075145
Validation loss: 2.4163425392267026

Epoch: 6| Step: 4
Training loss: 0.28927622446089996
Validation loss: 2.4505422568843116

Epoch: 6| Step: 5
Training loss: 0.18806295521872166
Validation loss: 2.4488270104758527

Epoch: 6| Step: 6
Training loss: 0.19604995740074274
Validation loss: 2.4866498244050432

Epoch: 6| Step: 7
Training loss: 0.17654620196646917
Validation loss: 2.474382674002696

Epoch: 6| Step: 8
Training loss: 0.3031085009853076
Validation loss: 2.5038382854845667

Epoch: 6| Step: 9
Training loss: 0.23952784966968574
Validation loss: 2.500570150190463

Epoch: 6| Step: 10
Training loss: 0.2902171554694144
Validation loss: 2.492757204352675

Epoch: 6| Step: 11
Training loss: 0.16275808650574036
Validation loss: 2.5209833329504043

Epoch: 6| Step: 12
Training loss: 0.20097433965730854
Validation loss: 2.476284659654558

Epoch: 6| Step: 13
Training loss: 0.2457612379818661
Validation loss: 2.435239221455699

Epoch: 557| Step: 0
Training loss: 0.12381301510918889
Validation loss: 2.4332605626104185

Epoch: 6| Step: 1
Training loss: 0.2077446468262644
Validation loss: 2.410565144798384

Epoch: 6| Step: 2
Training loss: 0.20110395822053503
Validation loss: 2.4207594436242195

Epoch: 6| Step: 3
Training loss: 0.23403867591397867
Validation loss: 2.3539318908164213

Epoch: 6| Step: 4
Training loss: 0.19945199252627788
Validation loss: 2.3645002485948003

Epoch: 6| Step: 5
Training loss: 0.23180549698117767
Validation loss: 2.3489221247623595

Epoch: 6| Step: 6
Training loss: 0.17858727142184253
Validation loss: 2.368768593467358

Epoch: 6| Step: 7
Training loss: 0.20592831175802748
Validation loss: 2.3720497066248707

Epoch: 6| Step: 8
Training loss: 0.21630263481801604
Validation loss: 2.3835248786343106

Epoch: 6| Step: 9
Training loss: 0.18413962720391044
Validation loss: 2.3913799854829194

Epoch: 6| Step: 10
Training loss: 0.20222727763104967
Validation loss: 2.4166225822538143

Epoch: 6| Step: 11
Training loss: 0.16947849569166365
Validation loss: 2.4255331716197874

Epoch: 6| Step: 12
Training loss: 0.19742239963716904
Validation loss: 2.4173215679564763

Epoch: 6| Step: 13
Training loss: 0.23585466768735916
Validation loss: 2.440397839665708

Epoch: 558| Step: 0
Training loss: 0.22687908777122062
Validation loss: 2.4318768891858062

Epoch: 6| Step: 1
Training loss: 0.2429987180572023
Validation loss: 2.4189319672409058

Epoch: 6| Step: 2
Training loss: 0.1829181374083055
Validation loss: 2.412145658375174

Epoch: 6| Step: 3
Training loss: 0.2989646126201771
Validation loss: 2.437423223144019

Epoch: 6| Step: 4
Training loss: 0.18982541973017872
Validation loss: 2.409503997890119

Epoch: 6| Step: 5
Training loss: 0.10949614321381052
Validation loss: 2.41149977753367

Epoch: 6| Step: 6
Training loss: 0.2095166584740167
Validation loss: 2.434580061299352

Epoch: 6| Step: 7
Training loss: 0.16199019083816735
Validation loss: 2.423379122567541

Epoch: 6| Step: 8
Training loss: 0.162557258971726
Validation loss: 2.414492378651263

Epoch: 6| Step: 9
Training loss: 0.19592281353436158
Validation loss: 2.4225313946471223

Epoch: 6| Step: 10
Training loss: 0.17793468045411612
Validation loss: 2.409102201765124

Epoch: 6| Step: 11
Training loss: 0.18996344980237245
Validation loss: 2.4114680185820943

Epoch: 6| Step: 12
Training loss: 0.14199635946869088
Validation loss: 2.4207358283486404

Epoch: 6| Step: 13
Training loss: 0.17570977347259223
Validation loss: 2.414269934582653

Epoch: 559| Step: 0
Training loss: 0.25260133676156343
Validation loss: 2.437717780877342

Epoch: 6| Step: 1
Training loss: 0.12382105587537512
Validation loss: 2.4045511882961117

Epoch: 6| Step: 2
Training loss: 0.1686690392372879
Validation loss: 2.408307785598113

Epoch: 6| Step: 3
Training loss: 0.23116072529535595
Validation loss: 2.4081915842398227

Epoch: 6| Step: 4
Training loss: 0.1487944101708102
Validation loss: 2.4211299008095053

Epoch: 6| Step: 5
Training loss: 0.25168259461053255
Validation loss: 2.4362395050904193

Epoch: 6| Step: 6
Training loss: 0.16870361745913867
Validation loss: 2.4400303383028272

Epoch: 6| Step: 7
Training loss: 0.2795239972260597
Validation loss: 2.4276333852415957

Epoch: 6| Step: 8
Training loss: 0.17873946207168634
Validation loss: 2.426980915115366

Epoch: 6| Step: 9
Training loss: 0.17050705371001817
Validation loss: 2.462290962374569

Epoch: 6| Step: 10
Training loss: 0.16575628668850603
Validation loss: 2.4355803346100715

Epoch: 6| Step: 11
Training loss: 0.11130462364965543
Validation loss: 2.443053927787302

Epoch: 6| Step: 12
Training loss: 0.1403668404918455
Validation loss: 2.4095381175793644

Epoch: 6| Step: 13
Training loss: 0.14282736483869174
Validation loss: 2.4126842469866228

Epoch: 560| Step: 0
Training loss: 0.14568635368468966
Validation loss: 2.427876455157102

Epoch: 6| Step: 1
Training loss: 0.1367933750848621
Validation loss: 2.432670674578464

Epoch: 6| Step: 2
Training loss: 0.15942075530708366
Validation loss: 2.4325069005431335

Epoch: 6| Step: 3
Training loss: 0.24675887913946673
Validation loss: 2.435267623848527

Epoch: 6| Step: 4
Training loss: 0.18431816841585547
Validation loss: 2.4222543017827154

Epoch: 6| Step: 5
Training loss: 0.205916082400156
Validation loss: 2.418912251266357

Epoch: 6| Step: 6
Training loss: 0.2010696392084367
Validation loss: 2.4237305401887546

Epoch: 6| Step: 7
Training loss: 0.20380891691144795
Validation loss: 2.430187744011491

Epoch: 6| Step: 8
Training loss: 0.16028641435533214
Validation loss: 2.414161326207487

Epoch: 6| Step: 9
Training loss: 0.26627813709929954
Validation loss: 2.429324228936263

Epoch: 6| Step: 10
Training loss: 0.17245493929185893
Validation loss: 2.424220269263692

Epoch: 6| Step: 11
Training loss: 0.1886442752656536
Validation loss: 2.4140658972113904

Epoch: 6| Step: 12
Training loss: 0.13832692776589225
Validation loss: 2.4141175270147617

Epoch: 6| Step: 13
Training loss: 0.12299270421411305
Validation loss: 2.4201749743616943

Epoch: 561| Step: 0
Training loss: 0.1807190579400695
Validation loss: 2.4027729074286253

Epoch: 6| Step: 1
Training loss: 0.09917407663376819
Validation loss: 2.4176970616545006

Epoch: 6| Step: 2
Training loss: 0.14009661881655563
Validation loss: 2.4211001519198945

Epoch: 6| Step: 3
Training loss: 0.11343477796278433
Validation loss: 2.4222471567181185

Epoch: 6| Step: 4
Training loss: 0.17925517276658232
Validation loss: 2.4291911828203996

Epoch: 6| Step: 5
Training loss: 0.09288898600519156
Validation loss: 2.424986387146306

Epoch: 6| Step: 6
Training loss: 0.1525291451858166
Validation loss: 2.4391990757973456

Epoch: 6| Step: 7
Training loss: 0.1562229669550807
Validation loss: 2.448876461952158

Epoch: 6| Step: 8
Training loss: 0.25491815080883024
Validation loss: 2.4646835367386957

Epoch: 6| Step: 9
Training loss: 0.12602484317558654
Validation loss: 2.439722655383374

Epoch: 6| Step: 10
Training loss: 0.15758749600651994
Validation loss: 2.473825925296422

Epoch: 6| Step: 11
Training loss: 0.14986286202546964
Validation loss: 2.4646133973845434

Epoch: 6| Step: 12
Training loss: 0.15889768838089272
Validation loss: 2.453230389035367

Epoch: 6| Step: 13
Training loss: 0.10752494375688172
Validation loss: 2.433767166612686

Epoch: 562| Step: 0
Training loss: 0.11894981551142011
Validation loss: 2.423289415456323

Epoch: 6| Step: 1
Training loss: 0.1867391627019294
Validation loss: 2.427566959855893

Epoch: 6| Step: 2
Training loss: 0.1140694124596346
Validation loss: 2.443854529931998

Epoch: 6| Step: 3
Training loss: 0.08857372582413058
Validation loss: 2.399146039459119

Epoch: 6| Step: 4
Training loss: 0.12866304314001248
Validation loss: 2.4112195456830228

Epoch: 6| Step: 5
Training loss: 0.1445776439643492
Validation loss: 2.389998963446282

Epoch: 6| Step: 6
Training loss: 0.16264507530149444
Validation loss: 2.412590719017052

Epoch: 6| Step: 7
Training loss: 0.11220341552937936
Validation loss: 2.4084950425436418

Epoch: 6| Step: 8
Training loss: 0.1869760384647723
Validation loss: 2.4127317209870878

Epoch: 6| Step: 9
Training loss: 0.07663512580577524
Validation loss: 2.373867155488769

Epoch: 6| Step: 10
Training loss: 0.11493078748321693
Validation loss: 2.401337239686972

Epoch: 6| Step: 11
Training loss: 0.1641254417844929
Validation loss: 2.39661398568893

Epoch: 6| Step: 12
Training loss: 0.14010791283128812
Validation loss: 2.394004850236012

Epoch: 6| Step: 13
Training loss: 0.20935225861440016
Validation loss: 2.383216670587481

Epoch: 563| Step: 0
Training loss: 0.11495639116718977
Validation loss: 2.403015909204868

Epoch: 6| Step: 1
Training loss: 0.1406043355381846
Validation loss: 2.4222830141249947

Epoch: 6| Step: 2
Training loss: 0.13074836007470156
Validation loss: 2.437868501139517

Epoch: 6| Step: 3
Training loss: 0.14963200201335775
Validation loss: 2.416882517690155

Epoch: 6| Step: 4
Training loss: 0.18050939795749824
Validation loss: 2.410449897785989

Epoch: 6| Step: 5
Training loss: 0.14616012289492028
Validation loss: 2.429873133859122

Epoch: 6| Step: 6
Training loss: 0.11213235071390548
Validation loss: 2.419668373041139

Epoch: 6| Step: 7
Training loss: 0.08834334970180471
Validation loss: 2.3998508231397806

Epoch: 6| Step: 8
Training loss: 0.10009698169760088
Validation loss: 2.4058843565790298

Epoch: 6| Step: 9
Training loss: 0.17735206441672557
Validation loss: 2.4001035321457804

Epoch: 6| Step: 10
Training loss: 0.08334008080265723
Validation loss: 2.3980645346740928

Epoch: 6| Step: 11
Training loss: 0.20595985870084585
Validation loss: 2.4053020978115085

Epoch: 6| Step: 12
Training loss: 0.17705846476307688
Validation loss: 2.3934322172265783

Epoch: 6| Step: 13
Training loss: 0.13318503248559535
Validation loss: 2.4340772058862434

Epoch: 564| Step: 0
Training loss: 0.11662963165119962
Validation loss: 2.426100121960147

Epoch: 6| Step: 1
Training loss: 0.15359155994844698
Validation loss: 2.4225269648141237

Epoch: 6| Step: 2
Training loss: 0.20797096964900483
Validation loss: 2.4090025316270895

Epoch: 6| Step: 3
Training loss: 0.1233263814832628
Validation loss: 2.4167937993890494

Epoch: 6| Step: 4
Training loss: 0.17168722949859005
Validation loss: 2.413806989240287

Epoch: 6| Step: 5
Training loss: 0.10491998393839264
Validation loss: 2.4493278312568165

Epoch: 6| Step: 6
Training loss: 0.14930200426242468
Validation loss: 2.4207641393289427

Epoch: 6| Step: 7
Training loss: 0.10517443104393528
Validation loss: 2.4651380008732784

Epoch: 6| Step: 8
Training loss: 0.06594612085565302
Validation loss: 2.434341133917623

Epoch: 6| Step: 9
Training loss: 0.1278080033931344
Validation loss: 2.445686939911442

Epoch: 6| Step: 10
Training loss: 0.12321936158694313
Validation loss: 2.4487573803693388

Epoch: 6| Step: 11
Training loss: 0.17989933961044147
Validation loss: 2.424508999219489

Epoch: 6| Step: 12
Training loss: 0.18698292204256584
Validation loss: 2.4122286907177894

Epoch: 6| Step: 13
Training loss: 0.12115699900567063
Validation loss: 2.4277848630240633

Epoch: 565| Step: 0
Training loss: 0.09135519460290435
Validation loss: 2.444532796197461

Epoch: 6| Step: 1
Training loss: 0.17494100977145846
Validation loss: 2.4267370492865608

Epoch: 6| Step: 2
Training loss: 0.14159728076643724
Validation loss: 2.4034767635809753

Epoch: 6| Step: 3
Training loss: 0.11408635667288825
Validation loss: 2.3917638768435037

Epoch: 6| Step: 4
Training loss: 0.08974327813547876
Validation loss: 2.4074268646030657

Epoch: 6| Step: 5
Training loss: 0.1356520662350213
Validation loss: 2.4231959714916713

Epoch: 6| Step: 6
Training loss: 0.10524924713372917
Validation loss: 2.390215411357166

Epoch: 6| Step: 7
Training loss: 0.14297670019172437
Validation loss: 2.396261654339653

Epoch: 6| Step: 8
Training loss: 0.12134414979076519
Validation loss: 2.4260278870034195

Epoch: 6| Step: 9
Training loss: 0.17950443603764182
Validation loss: 2.4015659251255266

Epoch: 6| Step: 10
Training loss: 0.13013257127267597
Validation loss: 2.37318876973126

Epoch: 6| Step: 11
Training loss: 0.15403678557575343
Validation loss: 2.3957414977746834

Epoch: 6| Step: 12
Training loss: 0.13558722645710977
Validation loss: 2.399832025070954

Epoch: 6| Step: 13
Training loss: 0.11962407550011073
Validation loss: 2.383730388573827

Epoch: 566| Step: 0
Training loss: 0.12786569523635422
Validation loss: 2.4080838312598463

Epoch: 6| Step: 1
Training loss: 0.08156991273621106
Validation loss: 2.385987509759219

Epoch: 6| Step: 2
Training loss: 0.1307992227571694
Validation loss: 2.415276437994142

Epoch: 6| Step: 3
Training loss: 0.11479369454516732
Validation loss: 2.4093696144307373

Epoch: 6| Step: 4
Training loss: 0.16012780006604868
Validation loss: 2.4145354522374767

Epoch: 6| Step: 5
Training loss: 0.15620843811401341
Validation loss: 2.4192558975224054

Epoch: 6| Step: 6
Training loss: 0.08860012945622907
Validation loss: 2.406620454711257

Epoch: 6| Step: 7
Training loss: 0.16411615811214578
Validation loss: 2.3920358324116564

Epoch: 6| Step: 8
Training loss: 0.11755878520721193
Validation loss: 2.410510341922009

Epoch: 6| Step: 9
Training loss: 0.18877878812697982
Validation loss: 2.403859842903531

Epoch: 6| Step: 10
Training loss: 0.10067751336075771
Validation loss: 2.4325988586786242

Epoch: 6| Step: 11
Training loss: 0.12401595055517102
Validation loss: 2.427219994549482

Epoch: 6| Step: 12
Training loss: 0.07215802778500725
Validation loss: 2.4386158732536947

Epoch: 6| Step: 13
Training loss: 0.12717176097476215
Validation loss: 2.412790309112377

Epoch: 567| Step: 0
Training loss: 0.09622015257274943
Validation loss: 2.4143653725033176

Epoch: 6| Step: 1
Training loss: 0.08325035619462624
Validation loss: 2.4040743022715314

Epoch: 6| Step: 2
Training loss: 0.14926149020821805
Validation loss: 2.439498955715246

Epoch: 6| Step: 3
Training loss: 0.139553531328657
Validation loss: 2.4232863342692186

Epoch: 6| Step: 4
Training loss: 0.15525298313754723
Validation loss: 2.4230417299953397

Epoch: 6| Step: 5
Training loss: 0.10853028226586277
Validation loss: 2.4182604759319823

Epoch: 6| Step: 6
Training loss: 0.11353809736777781
Validation loss: 2.4246067832003084

Epoch: 6| Step: 7
Training loss: 0.07853075102390651
Validation loss: 2.420072375715058

Epoch: 6| Step: 8
Training loss: 0.1654510434720718
Validation loss: 2.439832370294634

Epoch: 6| Step: 9
Training loss: 0.19935332222283067
Validation loss: 2.4311531952554417

Epoch: 6| Step: 10
Training loss: 0.0987569386724454
Validation loss: 2.4407311703168415

Epoch: 6| Step: 11
Training loss: 0.12547331843247891
Validation loss: 2.4488237632976815

Epoch: 6| Step: 12
Training loss: 0.19652724168159175
Validation loss: 2.4443670586004793

Epoch: 6| Step: 13
Training loss: 0.11110102344664093
Validation loss: 2.441004898125726

Epoch: 568| Step: 0
Training loss: 0.09612278499643172
Validation loss: 2.453595560126484

Epoch: 6| Step: 1
Training loss: 0.13079394654885235
Validation loss: 2.454903702808487

Epoch: 6| Step: 2
Training loss: 0.10581185903822606
Validation loss: 2.4403156985511516

Epoch: 6| Step: 3
Training loss: 0.14360628692847952
Validation loss: 2.4566837224589357

Epoch: 6| Step: 4
Training loss: 0.14277647539656282
Validation loss: 2.434156971402149

Epoch: 6| Step: 5
Training loss: 0.1270427314266506
Validation loss: 2.3915707704423657

Epoch: 6| Step: 6
Training loss: 0.10992857370387761
Validation loss: 2.4203057218795796

Epoch: 6| Step: 7
Training loss: 0.13801916739220133
Validation loss: 2.426057855496262

Epoch: 6| Step: 8
Training loss: 0.13318735404075957
Validation loss: 2.393846124457068

Epoch: 6| Step: 9
Training loss: 0.1374130196073888
Validation loss: 2.392439419423921

Epoch: 6| Step: 10
Training loss: 0.13226461299727646
Validation loss: 2.3950225064385644

Epoch: 6| Step: 11
Training loss: 0.12755918358692853
Validation loss: 2.389033976924311

Epoch: 6| Step: 12
Training loss: 0.11788315920640056
Validation loss: 2.394531396140058

Epoch: 6| Step: 13
Training loss: 0.10684632524553823
Validation loss: 2.4132837351655607

Epoch: 569| Step: 0
Training loss: 0.15250548922516788
Validation loss: 2.4264191443078644

Epoch: 6| Step: 1
Training loss: 0.09427743799913373
Validation loss: 2.413015535012626

Epoch: 6| Step: 2
Training loss: 0.1305174559632945
Validation loss: 2.4145443714783856

Epoch: 6| Step: 3
Training loss: 0.07636639626329682
Validation loss: 2.395719336267202

Epoch: 6| Step: 4
Training loss: 0.08302402898919306
Validation loss: 2.395390233551038

Epoch: 6| Step: 5
Training loss: 0.12170130076959201
Validation loss: 2.387210479029019

Epoch: 6| Step: 6
Training loss: 0.12730967996177273
Validation loss: 2.4076439786098724

Epoch: 6| Step: 7
Training loss: 0.12509873335387275
Validation loss: 2.4045002161591915

Epoch: 6| Step: 8
Training loss: 0.1747862630330159
Validation loss: 2.438000320820168

Epoch: 6| Step: 9
Training loss: 0.09187781032818336
Validation loss: 2.4334494889496048

Epoch: 6| Step: 10
Training loss: 0.07422268380230389
Validation loss: 2.4001393401208984

Epoch: 6| Step: 11
Training loss: 0.22219333713445172
Validation loss: 2.3789911526256837

Epoch: 6| Step: 12
Training loss: 0.08223972622933676
Validation loss: 2.3846446760781124

Epoch: 6| Step: 13
Training loss: 0.06519876481818615
Validation loss: 2.384419286224675

Epoch: 570| Step: 0
Training loss: 0.11082193255122755
Validation loss: 2.3700492934308546

Epoch: 6| Step: 1
Training loss: 0.12078656951027161
Validation loss: 2.3988728097653538

Epoch: 6| Step: 2
Training loss: 0.1380730716047805
Validation loss: 2.384161495921662

Epoch: 6| Step: 3
Training loss: 0.08174563822571736
Validation loss: 2.4049591983246046

Epoch: 6| Step: 4
Training loss: 0.08563108980318235
Validation loss: 2.41769823653831

Epoch: 6| Step: 5
Training loss: 0.14849645297232683
Validation loss: 2.371188499589024

Epoch: 6| Step: 6
Training loss: 0.16288306129513777
Validation loss: 2.3508937022143552

Epoch: 6| Step: 7
Training loss: 0.11332873467302812
Validation loss: 2.3864202183624275

Epoch: 6| Step: 8
Training loss: 0.11288314781374133
Validation loss: 2.4258645670054224

Epoch: 6| Step: 9
Training loss: 0.09282792147883945
Validation loss: 2.441688210364568

Epoch: 6| Step: 10
Training loss: 0.17317246966323144
Validation loss: 2.456317635929743

Epoch: 6| Step: 11
Training loss: 0.15453195168670475
Validation loss: 2.4514732519072533

Epoch: 6| Step: 12
Training loss: 0.2265682219736425
Validation loss: 2.434997116561018

Epoch: 6| Step: 13
Training loss: 0.08198264078243946
Validation loss: 2.461916520014246

Epoch: 571| Step: 0
Training loss: 0.17426501245766385
Validation loss: 2.4726064272928405

Epoch: 6| Step: 1
Training loss: 0.1804461324646469
Validation loss: 2.470039641430995

Epoch: 6| Step: 2
Training loss: 0.1435721834381233
Validation loss: 2.4757064530785535

Epoch: 6| Step: 3
Training loss: 0.13079365460668543
Validation loss: 2.4538428324427795

Epoch: 6| Step: 4
Training loss: 0.16624403555647008
Validation loss: 2.4655497182069586

Epoch: 6| Step: 5
Training loss: 0.11454719999655172
Validation loss: 2.486050952230797

Epoch: 6| Step: 6
Training loss: 0.18780770484528136
Validation loss: 2.462084695631442

Epoch: 6| Step: 7
Training loss: 0.13414288117339293
Validation loss: 2.476741298956101

Epoch: 6| Step: 8
Training loss: 0.17106991475572056
Validation loss: 2.4809170861115777

Epoch: 6| Step: 9
Training loss: 0.14526830072801641
Validation loss: 2.458284001787903

Epoch: 6| Step: 10
Training loss: 0.11885276397913233
Validation loss: 2.447580265100481

Epoch: 6| Step: 11
Training loss: 0.17241282196891577
Validation loss: 2.4302287107488834

Epoch: 6| Step: 12
Training loss: 0.11881510242479576
Validation loss: 2.4022974676287157

Epoch: 6| Step: 13
Training loss: 0.09568098357067158
Validation loss: 2.4310599491560705

Epoch: 572| Step: 0
Training loss: 0.19327581892963838
Validation loss: 2.4172881557462516

Epoch: 6| Step: 1
Training loss: 0.21257008035082037
Validation loss: 2.389277730087935

Epoch: 6| Step: 2
Training loss: 0.1499592055041611
Validation loss: 2.4018362754343743

Epoch: 6| Step: 3
Training loss: 0.11695436891723718
Validation loss: 2.3963944896583507

Epoch: 6| Step: 4
Training loss: 0.15581030969652507
Validation loss: 2.3844350179654183

Epoch: 6| Step: 5
Training loss: 0.13438396728890573
Validation loss: 2.3917354176681918

Epoch: 6| Step: 6
Training loss: 0.13699127012042994
Validation loss: 2.4132070746486844

Epoch: 6| Step: 7
Training loss: 0.08362332349021144
Validation loss: 2.427183648168735

Epoch: 6| Step: 8
Training loss: 0.04971032693800607
Validation loss: 2.4285544462671003

Epoch: 6| Step: 9
Training loss: 0.12617558276040172
Validation loss: 2.460946281796367

Epoch: 6| Step: 10
Training loss: 0.13409523145319147
Validation loss: 2.4352381529381617

Epoch: 6| Step: 11
Training loss: 0.08582856307047272
Validation loss: 2.4292728072948657

Epoch: 6| Step: 12
Training loss: 0.0615450881525275
Validation loss: 2.4399552924929435

Epoch: 6| Step: 13
Training loss: 0.08018614298950023
Validation loss: 2.443845085629583

Epoch: 573| Step: 0
Training loss: 0.11263383232930886
Validation loss: 2.462445315860556

Epoch: 6| Step: 1
Training loss: 0.2075109322954186
Validation loss: 2.4681738039169208

Epoch: 6| Step: 2
Training loss: 0.0741648415488709
Validation loss: 2.4836199007554685

Epoch: 6| Step: 3
Training loss: 0.12278479716234773
Validation loss: 2.4454361607381725

Epoch: 6| Step: 4
Training loss: 0.13510268671459985
Validation loss: 2.4746692071805674

Epoch: 6| Step: 5
Training loss: 0.1009436145944061
Validation loss: 2.4538221819213386

Epoch: 6| Step: 6
Training loss: 0.11810002286179586
Validation loss: 2.4450398678136573

Epoch: 6| Step: 7
Training loss: 0.12513471586012706
Validation loss: 2.447186818408269

Epoch: 6| Step: 8
Training loss: 0.07310076411276946
Validation loss: 2.416017738715598

Epoch: 6| Step: 9
Training loss: 0.0846985294314167
Validation loss: 2.4220273438701403

Epoch: 6| Step: 10
Training loss: 0.12927460060834373
Validation loss: 2.413695759959584

Epoch: 6| Step: 11
Training loss: 0.08519214105628077
Validation loss: 2.427000493714943

Epoch: 6| Step: 12
Training loss: 0.07902268020448042
Validation loss: 2.413825617939033

Epoch: 6| Step: 13
Training loss: 0.10395080034405219
Validation loss: 2.4087990240266954

Epoch: 574| Step: 0
Training loss: 0.14502179179372407
Validation loss: 2.404435073008806

Epoch: 6| Step: 1
Training loss: 0.14232855339877828
Validation loss: 2.4149358900256854

Epoch: 6| Step: 2
Training loss: 0.14460353074920707
Validation loss: 2.388160730364796

Epoch: 6| Step: 3
Training loss: 0.13879326087964075
Validation loss: 2.3902043999323865

Epoch: 6| Step: 4
Training loss: 0.1146110064150537
Validation loss: 2.418184433556814

Epoch: 6| Step: 5
Training loss: 0.16994221883425428
Validation loss: 2.4301764548162215

Epoch: 6| Step: 6
Training loss: 0.12433763938503672
Validation loss: 2.4126149230036704

Epoch: 6| Step: 7
Training loss: 0.08326397246913005
Validation loss: 2.3942352322327154

Epoch: 6| Step: 8
Training loss: 0.09554531749600624
Validation loss: 2.403938398751077

Epoch: 6| Step: 9
Training loss: 0.13302637158392738
Validation loss: 2.4290259720626555

Epoch: 6| Step: 10
Training loss: 0.12791509763498835
Validation loss: 2.400367167118825

Epoch: 6| Step: 11
Training loss: 0.11730011456316079
Validation loss: 2.4237666839726186

Epoch: 6| Step: 12
Training loss: 0.07567292415105059
Validation loss: 2.4378258082732644

Epoch: 6| Step: 13
Training loss: 0.12330610730556762
Validation loss: 2.420914740172629

Epoch: 575| Step: 0
Training loss: 0.09352527446725671
Validation loss: 2.434775481847852

Epoch: 6| Step: 1
Training loss: 0.07606108261909857
Validation loss: 2.430251388815763

Epoch: 6| Step: 2
Training loss: 0.07291592728149107
Validation loss: 2.4355404446982565

Epoch: 6| Step: 3
Training loss: 0.0852272911956796
Validation loss: 2.4414367668623655

Epoch: 6| Step: 4
Training loss: 0.12519856417475517
Validation loss: 2.4291495553402878

Epoch: 6| Step: 5
Training loss: 0.13149055167257173
Validation loss: 2.437926880567847

Epoch: 6| Step: 6
Training loss: 0.1341991890696422
Validation loss: 2.410652171715742

Epoch: 6| Step: 7
Training loss: 0.10397190622538661
Validation loss: 2.4419452383029405

Epoch: 6| Step: 8
Training loss: 0.1635485785586835
Validation loss: 2.444024823754637

Epoch: 6| Step: 9
Training loss: 0.1117211981818577
Validation loss: 2.451347816649436

Epoch: 6| Step: 10
Training loss: 0.10197621226617722
Validation loss: 2.45296338381561

Epoch: 6| Step: 11
Training loss: 0.17688325256128473
Validation loss: 2.4472097834985886

Epoch: 6| Step: 12
Training loss: 0.11761916844635965
Validation loss: 2.4294045836905043

Epoch: 6| Step: 13
Training loss: 0.09969826546749715
Validation loss: 2.437438381395406

Epoch: 576| Step: 0
Training loss: 0.0934467975749444
Validation loss: 2.446851091995336

Epoch: 6| Step: 1
Training loss: 0.101329361651425
Validation loss: 2.4215707138561

Epoch: 6| Step: 2
Training loss: 0.13152171234368062
Validation loss: 2.4322017911215483

Epoch: 6| Step: 3
Training loss: 0.09049774640791783
Validation loss: 2.4406713244061606

Epoch: 6| Step: 4
Training loss: 0.11897535665002332
Validation loss: 2.421025683324444

Epoch: 6| Step: 5
Training loss: 0.08572733170367529
Validation loss: 2.419951229454894

Epoch: 6| Step: 6
Training loss: 0.16966255723875975
Validation loss: 2.4128213260292317

Epoch: 6| Step: 7
Training loss: 0.11571300643411585
Validation loss: 2.4233886799518705

Epoch: 6| Step: 8
Training loss: 0.10990500611476378
Validation loss: 2.426555339687326

Epoch: 6| Step: 9
Training loss: 0.17085530963032886
Validation loss: 2.4041776593477495

Epoch: 6| Step: 10
Training loss: 0.09022839245636169
Validation loss: 2.395799172912719

Epoch: 6| Step: 11
Training loss: 0.1024330044802076
Validation loss: 2.443781375759647

Epoch: 6| Step: 12
Training loss: 0.10908039470869077
Validation loss: 2.41433845501472

Epoch: 6| Step: 13
Training loss: 0.09533722666201952
Validation loss: 2.437826806250419

Epoch: 577| Step: 0
Training loss: 0.11512626005108591
Validation loss: 2.442449781181808

Epoch: 6| Step: 1
Training loss: 0.1376630055288636
Validation loss: 2.4560707090620926

Epoch: 6| Step: 2
Training loss: 0.10775279312983226
Validation loss: 2.4310474059432976

Epoch: 6| Step: 3
Training loss: 0.1540940919909824
Validation loss: 2.432935305235883

Epoch: 6| Step: 4
Training loss: 0.12235678056526963
Validation loss: 2.4163586233133145

Epoch: 6| Step: 5
Training loss: 0.11682358503327639
Validation loss: 2.4186522954800633

Epoch: 6| Step: 6
Training loss: 0.1330380698027053
Validation loss: 2.4255377333642762

Epoch: 6| Step: 7
Training loss: 0.16459778473781128
Validation loss: 2.4134477123960774

Epoch: 6| Step: 8
Training loss: 0.10794934903077101
Validation loss: 2.436947856532985

Epoch: 6| Step: 9
Training loss: 0.13990413491544235
Validation loss: 2.402272501243355

Epoch: 6| Step: 10
Training loss: 0.1255421801047087
Validation loss: 2.4279337441530475

Epoch: 6| Step: 11
Training loss: 0.08541060528919565
Validation loss: 2.432731896522812

Epoch: 6| Step: 12
Training loss: 0.07493871715832194
Validation loss: 2.403483189002173

Epoch: 6| Step: 13
Training loss: 0.08874451900737082
Validation loss: 2.4388283264627364

Epoch: 578| Step: 0
Training loss: 0.12301263635600879
Validation loss: 2.430490315309344

Epoch: 6| Step: 1
Training loss: 0.0673626268254957
Validation loss: 2.422585982731679

Epoch: 6| Step: 2
Training loss: 0.09967126980263084
Validation loss: 2.4273906616876997

Epoch: 6| Step: 3
Training loss: 0.06563018923065603
Validation loss: 2.452592343706379

Epoch: 6| Step: 4
Training loss: 0.06617013594020955
Validation loss: 2.4354986496914783

Epoch: 6| Step: 5
Training loss: 0.15645727476184335
Validation loss: 2.457719367104232

Epoch: 6| Step: 6
Training loss: 0.08230034650625957
Validation loss: 2.429545684032071

Epoch: 6| Step: 7
Training loss: 0.13048160169886322
Validation loss: 2.424408548689223

Epoch: 6| Step: 8
Training loss: 0.13138369948477951
Validation loss: 2.410469252241367

Epoch: 6| Step: 9
Training loss: 0.12684619508460365
Validation loss: 2.4231911694135433

Epoch: 6| Step: 10
Training loss: 0.05502000694759886
Validation loss: 2.4224740591137297

Epoch: 6| Step: 11
Training loss: 0.09390500288403376
Validation loss: 2.425637210237165

Epoch: 6| Step: 12
Training loss: 0.10053927533640526
Validation loss: 2.438197956016922

Epoch: 6| Step: 13
Training loss: 0.10671449013944705
Validation loss: 2.4268044396841137

Epoch: 579| Step: 0
Training loss: 0.1367693671123457
Validation loss: 2.4362911932318854

Epoch: 6| Step: 1
Training loss: 0.11418794468332197
Validation loss: 2.4335122083029628

Epoch: 6| Step: 2
Training loss: 0.10912863197869785
Validation loss: 2.4479485039526825

Epoch: 6| Step: 3
Training loss: 0.07678271780175291
Validation loss: 2.4450868761102806

Epoch: 6| Step: 4
Training loss: 0.11803581434650232
Validation loss: 2.419534465383661

Epoch: 6| Step: 5
Training loss: 0.06753133907250457
Validation loss: 2.429604763593706

Epoch: 6| Step: 6
Training loss: 0.11497447235868068
Validation loss: 2.4210022824292796

Epoch: 6| Step: 7
Training loss: 0.057752488779728293
Validation loss: 2.462360944039154

Epoch: 6| Step: 8
Training loss: 0.13729041338721443
Validation loss: 2.4247009927322494

Epoch: 6| Step: 9
Training loss: 0.05287538325732237
Validation loss: 2.4329369764404736

Epoch: 6| Step: 10
Training loss: 0.11238441125384255
Validation loss: 2.4356027302298116

Epoch: 6| Step: 11
Training loss: 0.11574684566274043
Validation loss: 2.445812927011148

Epoch: 6| Step: 12
Training loss: 0.10929289358602673
Validation loss: 2.4662327610382153

Epoch: 6| Step: 13
Training loss: 0.12606538554006413
Validation loss: 2.4176775996423423

Epoch: 580| Step: 0
Training loss: 0.12137277819252909
Validation loss: 2.4160504718909994

Epoch: 6| Step: 1
Training loss: 0.12962734941654375
Validation loss: 2.439108401265605

Epoch: 6| Step: 2
Training loss: 0.09968780720821865
Validation loss: 2.4495250077805752

Epoch: 6| Step: 3
Training loss: 0.08034930310389973
Validation loss: 2.4359529074900337

Epoch: 6| Step: 4
Training loss: 0.1379703318374521
Validation loss: 2.430810940905921

Epoch: 6| Step: 5
Training loss: 0.11822182843321667
Validation loss: 2.468195921451356

Epoch: 6| Step: 6
Training loss: 0.08642367990816378
Validation loss: 2.424151026656637

Epoch: 6| Step: 7
Training loss: 0.08700550551660123
Validation loss: 2.4473389777573438

Epoch: 6| Step: 8
Training loss: 0.0659617667041578
Validation loss: 2.446903002302425

Epoch: 6| Step: 9
Training loss: 0.09725352215824169
Validation loss: 2.4644225529209383

Epoch: 6| Step: 10
Training loss: 0.08703015910189169
Validation loss: 2.4380549810564713

Epoch: 6| Step: 11
Training loss: 0.21653198693285344
Validation loss: 2.423713150067948

Epoch: 6| Step: 12
Training loss: 0.09780718583305201
Validation loss: 2.439042567981479

Epoch: 6| Step: 13
Training loss: 0.11787234308043718
Validation loss: 2.4227835992165407

Epoch: 581| Step: 0
Training loss: 0.11842624094321756
Validation loss: 2.4186347840501057

Epoch: 6| Step: 1
Training loss: 0.068257975305121
Validation loss: 2.4240649830135697

Epoch: 6| Step: 2
Training loss: 0.1304299725223522
Validation loss: 2.430357333029058

Epoch: 6| Step: 3
Training loss: 0.1482429295798966
Validation loss: 2.4230025954214653

Epoch: 6| Step: 4
Training loss: 0.14750795688423077
Validation loss: 2.404373726578224

Epoch: 6| Step: 5
Training loss: 0.15026171224774934
Validation loss: 2.403693266494241

Epoch: 6| Step: 6
Training loss: 0.1394841888835012
Validation loss: 2.4278013591553953

Epoch: 6| Step: 7
Training loss: 0.13364367695399532
Validation loss: 2.4206619876916067

Epoch: 6| Step: 8
Training loss: 0.14574429797032684
Validation loss: 2.4138670168927483

Epoch: 6| Step: 9
Training loss: 0.121011255990713
Validation loss: 2.420286597554034

Epoch: 6| Step: 10
Training loss: 0.10081579739947948
Validation loss: 2.418126037614566

Epoch: 6| Step: 11
Training loss: 0.09545161323674027
Validation loss: 2.438857122239876

Epoch: 6| Step: 12
Training loss: 0.09481532077704669
Validation loss: 2.4273296218741267

Epoch: 6| Step: 13
Training loss: 0.14769388582054596
Validation loss: 2.424112509098044

Epoch: 582| Step: 0
Training loss: 0.07437130032281314
Validation loss: 2.399153512448494

Epoch: 6| Step: 1
Training loss: 0.11474111830293145
Validation loss: 2.4139797091495288

Epoch: 6| Step: 2
Training loss: 0.09552989092144917
Validation loss: 2.3979390553565643

Epoch: 6| Step: 3
Training loss: 0.09663309554432452
Validation loss: 2.3890255252783508

Epoch: 6| Step: 4
Training loss: 0.08881831659333812
Validation loss: 2.415708754779622

Epoch: 6| Step: 5
Training loss: 0.11225295326483353
Validation loss: 2.387486549369189

Epoch: 6| Step: 6
Training loss: 0.11951319879225428
Validation loss: 2.348836281018412

Epoch: 6| Step: 7
Training loss: 0.14179987996177676
Validation loss: 2.3798566770153857

Epoch: 6| Step: 8
Training loss: 0.11092309304162509
Validation loss: 2.3873305097525694

Epoch: 6| Step: 9
Training loss: 0.1169511756594365
Validation loss: 2.410715249165511

Epoch: 6| Step: 10
Training loss: 0.11065175570733939
Validation loss: 2.406307263992077

Epoch: 6| Step: 11
Training loss: 0.08811185068666338
Validation loss: 2.424904298051526

Epoch: 6| Step: 12
Training loss: 0.14250552275479492
Validation loss: 2.420518641521534

Epoch: 6| Step: 13
Training loss: 0.13680317860387115
Validation loss: 2.4088289386699766

Epoch: 583| Step: 0
Training loss: 0.11981587493622477
Validation loss: 2.394580296886314

Epoch: 6| Step: 1
Training loss: 0.10056026834888737
Validation loss: 2.402885175777659

Epoch: 6| Step: 2
Training loss: 0.09398859676509316
Validation loss: 2.388254864038956

Epoch: 6| Step: 3
Training loss: 0.12537589773995775
Validation loss: 2.4181384946575033

Epoch: 6| Step: 4
Training loss: 0.09698554507496646
Validation loss: 2.4474656198516915

Epoch: 6| Step: 5
Training loss: 0.10606593586965571
Validation loss: 2.4221231387041575

Epoch: 6| Step: 6
Training loss: 0.1008821311501686
Validation loss: 2.4397009186067318

Epoch: 6| Step: 7
Training loss: 0.10343796137853796
Validation loss: 2.4545219090808006

Epoch: 6| Step: 8
Training loss: 0.13703818470057386
Validation loss: 2.4271619511944027

Epoch: 6| Step: 9
Training loss: 0.08583888985339276
Validation loss: 2.444670435535034

Epoch: 6| Step: 10
Training loss: 0.06575009905287313
Validation loss: 2.4295144749032374

Epoch: 6| Step: 11
Training loss: 0.1288879121394778
Validation loss: 2.436345548780094

Epoch: 6| Step: 12
Training loss: 0.08687046114639219
Validation loss: 2.4277125108212307

Epoch: 6| Step: 13
Training loss: 0.07940990198329134
Validation loss: 2.4173009204210576

Epoch: 584| Step: 0
Training loss: 0.11155842501146264
Validation loss: 2.417184868212486

Epoch: 6| Step: 1
Training loss: 0.10883888340014186
Validation loss: 2.4245646392629023

Epoch: 6| Step: 2
Training loss: 0.18729220240314426
Validation loss: 2.41341680178715

Epoch: 6| Step: 3
Training loss: 0.08710210260902443
Validation loss: 2.40994772945827

Epoch: 6| Step: 4
Training loss: 0.16869969788278652
Validation loss: 2.4341522904748736

Epoch: 6| Step: 5
Training loss: 0.14187758935968517
Validation loss: 2.40842751424825

Epoch: 6| Step: 6
Training loss: 0.09253009201956233
Validation loss: 2.434536737917566

Epoch: 6| Step: 7
Training loss: 0.13715124523403804
Validation loss: 2.4140396825944808

Epoch: 6| Step: 8
Training loss: 0.11952380020013761
Validation loss: 2.38952533465472

Epoch: 6| Step: 9
Training loss: 0.1503083449858104
Validation loss: 2.422370056089557

Epoch: 6| Step: 10
Training loss: 0.11156661856152181
Validation loss: 2.403910110367461

Epoch: 6| Step: 11
Training loss: 0.08087066649872396
Validation loss: 2.4128458825764643

Epoch: 6| Step: 12
Training loss: 0.09319793057575736
Validation loss: 2.4180148257126213

Epoch: 6| Step: 13
Training loss: 0.09485018911766388
Validation loss: 2.4043024558746633

Epoch: 585| Step: 0
Training loss: 0.14219151952323028
Validation loss: 2.420860981177512

Epoch: 6| Step: 1
Training loss: 0.09085277776965708
Validation loss: 2.4376222607683067

Epoch: 6| Step: 2
Training loss: 0.08079546531247161
Validation loss: 2.4325372350134304

Epoch: 6| Step: 3
Training loss: 0.10856390258149856
Validation loss: 2.4507547379610015

Epoch: 6| Step: 4
Training loss: 0.12797641628716488
Validation loss: 2.4183409327533787

Epoch: 6| Step: 5
Training loss: 0.10976082156657148
Validation loss: 2.452421658254492

Epoch: 6| Step: 6
Training loss: 0.07655791127797837
Validation loss: 2.445445455274274

Epoch: 6| Step: 7
Training loss: 0.07161744791139381
Validation loss: 2.4206011001665537

Epoch: 6| Step: 8
Training loss: 0.0848672201956681
Validation loss: 2.447142553274811

Epoch: 6| Step: 9
Training loss: 0.09508398306767692
Validation loss: 2.4453755325747797

Epoch: 6| Step: 10
Training loss: 0.10513214863909644
Validation loss: 2.471775537464483

Epoch: 6| Step: 11
Training loss: 0.12398680198423725
Validation loss: 2.438554742787189

Epoch: 6| Step: 12
Training loss: 0.1412151919049851
Validation loss: 2.4353304295426526

Epoch: 6| Step: 13
Training loss: 0.0946859292255707
Validation loss: 2.4758731152590676

Epoch: 586| Step: 0
Training loss: 0.07830854848378102
Validation loss: 2.437681460613666

Epoch: 6| Step: 1
Training loss: 0.09589023205367543
Validation loss: 2.463284365085003

Epoch: 6| Step: 2
Training loss: 0.17688245225176114
Validation loss: 2.4671277003711722

Epoch: 6| Step: 3
Training loss: 0.08700561255833339
Validation loss: 2.4283775335840065

Epoch: 6| Step: 4
Training loss: 0.0882237056950985
Validation loss: 2.4387721393450876

Epoch: 6| Step: 5
Training loss: 0.11556537015243194
Validation loss: 2.4370131552019583

Epoch: 6| Step: 6
Training loss: 0.07799747310650436
Validation loss: 2.4548590630212583

Epoch: 6| Step: 7
Training loss: 0.10023010609040559
Validation loss: 2.4443466174949875

Epoch: 6| Step: 8
Training loss: 0.053541699291116025
Validation loss: 2.442676968951159

Epoch: 6| Step: 9
Training loss: 0.11808508606104354
Validation loss: 2.422860014658603

Epoch: 6| Step: 10
Training loss: 0.1623470104319691
Validation loss: 2.416784851322971

Epoch: 6| Step: 11
Training loss: 0.10075786396867388
Validation loss: 2.430128760380733

Epoch: 6| Step: 12
Training loss: 0.09721895059358263
Validation loss: 2.4266763833872487

Epoch: 6| Step: 13
Training loss: 0.08935057517237739
Validation loss: 2.433171846189724

Epoch: 587| Step: 0
Training loss: 0.0636456511620278
Validation loss: 2.434940904208176

Epoch: 6| Step: 1
Training loss: 0.06724372967085862
Validation loss: 2.452991903924416

Epoch: 6| Step: 2
Training loss: 0.06215921642379513
Validation loss: 2.439473684876115

Epoch: 6| Step: 3
Training loss: 0.11113782562989673
Validation loss: 2.4319951149221373

Epoch: 6| Step: 4
Training loss: 0.10577370566000159
Validation loss: 2.446941343935734

Epoch: 6| Step: 5
Training loss: 0.1195912126596426
Validation loss: 2.4487766581847823

Epoch: 6| Step: 6
Training loss: 0.09907952738432517
Validation loss: 2.4546884644273836

Epoch: 6| Step: 7
Training loss: 0.13285089386634621
Validation loss: 2.4440362105195415

Epoch: 6| Step: 8
Training loss: 0.0663954396424463
Validation loss: 2.411100533030934

Epoch: 6| Step: 9
Training loss: 0.11882880711030527
Validation loss: 2.458014580355292

Epoch: 6| Step: 10
Training loss: 0.08742199575605056
Validation loss: 2.444156293053386

Epoch: 6| Step: 11
Training loss: 0.1575029621053869
Validation loss: 2.4301653696963803

Epoch: 6| Step: 12
Training loss: 0.13203158519634609
Validation loss: 2.4200400205672765

Epoch: 6| Step: 13
Training loss: 0.13377344082034381
Validation loss: 2.417077423876516

Epoch: 588| Step: 0
Training loss: 0.1308383070654344
Validation loss: 2.402730500025255

Epoch: 6| Step: 1
Training loss: 0.08612296292480087
Validation loss: 2.430808883294236

Epoch: 6| Step: 2
Training loss: 0.09917887990471741
Validation loss: 2.4046745304580757

Epoch: 6| Step: 3
Training loss: 0.11426226696884327
Validation loss: 2.395483365029943

Epoch: 6| Step: 4
Training loss: 0.10856663482030351
Validation loss: 2.4192122467296713

Epoch: 6| Step: 5
Training loss: 0.15016204629283506
Validation loss: 2.3966871205369213

Epoch: 6| Step: 6
Training loss: 0.11740504576334775
Validation loss: 2.4024293689692358

Epoch: 6| Step: 7
Training loss: 0.11676125094780213
Validation loss: 2.3927833400478096

Epoch: 6| Step: 8
Training loss: 0.1430330595660866
Validation loss: 2.422353088528249

Epoch: 6| Step: 9
Training loss: 0.08959781114816238
Validation loss: 2.4055029832602766

Epoch: 6| Step: 10
Training loss: 0.0964311864325823
Validation loss: 2.4449171857844254

Epoch: 6| Step: 11
Training loss: 0.11016607308384145
Validation loss: 2.4168743310233265

Epoch: 6| Step: 12
Training loss: 0.1670199700160691
Validation loss: 2.433048283352539

Epoch: 6| Step: 13
Training loss: 0.08635522904545914
Validation loss: 2.4199713140997914

Epoch: 589| Step: 0
Training loss: 0.12350751544984959
Validation loss: 2.4319364834676187

Epoch: 6| Step: 1
Training loss: 0.08562798737183924
Validation loss: 2.440385138023752

Epoch: 6| Step: 2
Training loss: 0.1283986037125308
Validation loss: 2.4222867247224484

Epoch: 6| Step: 3
Training loss: 0.1158112456453992
Validation loss: 2.4098077084821847

Epoch: 6| Step: 4
Training loss: 0.06634517624054657
Validation loss: 2.4021673130220402

Epoch: 6| Step: 5
Training loss: 0.12206997680617905
Validation loss: 2.4054617227841484

Epoch: 6| Step: 6
Training loss: 0.11522210185108375
Validation loss: 2.416929306748637

Epoch: 6| Step: 7
Training loss: 0.0648710472031883
Validation loss: 2.4202765994596085

Epoch: 6| Step: 8
Training loss: 0.09814492031039276
Validation loss: 2.4186602853392207

Epoch: 6| Step: 9
Training loss: 0.09337593993067513
Validation loss: 2.4288843317325015

Epoch: 6| Step: 10
Training loss: 0.11577882087851764
Validation loss: 2.42669092842454

Epoch: 6| Step: 11
Training loss: 0.09743744178975773
Validation loss: 2.4223252983006

Epoch: 6| Step: 12
Training loss: 0.11667830786641263
Validation loss: 2.4277611481869434

Epoch: 6| Step: 13
Training loss: 0.13062141617736567
Validation loss: 2.435943928243289

Epoch: 590| Step: 0
Training loss: 0.1326613969107674
Validation loss: 2.405028044783323

Epoch: 6| Step: 1
Training loss: 0.16138418415160896
Validation loss: 2.418865415776543

Epoch: 6| Step: 2
Training loss: 0.06994830622934994
Validation loss: 2.40694240989735

Epoch: 6| Step: 3
Training loss: 0.0693174827891936
Validation loss: 2.430228534581101

Epoch: 6| Step: 4
Training loss: 0.09325839331325309
Validation loss: 2.4241387623152946

Epoch: 6| Step: 5
Training loss: 0.09401570852959706
Validation loss: 2.417462830059304

Epoch: 6| Step: 6
Training loss: 0.08348466002943791
Validation loss: 2.429769927611193

Epoch: 6| Step: 7
Training loss: 0.11711660465881496
Validation loss: 2.4107649658665347

Epoch: 6| Step: 8
Training loss: 0.17223969694752306
Validation loss: 2.434753332376531

Epoch: 6| Step: 9
Training loss: 0.10155514543754204
Validation loss: 2.4191502576900006

Epoch: 6| Step: 10
Training loss: 0.05689314751819931
Validation loss: 2.416859927386582

Epoch: 6| Step: 11
Training loss: 0.1300679944649985
Validation loss: 2.4084602255110514

Epoch: 6| Step: 12
Training loss: 0.06766986518311603
Validation loss: 2.429816902143133

Epoch: 6| Step: 13
Training loss: 0.05628163132135924
Validation loss: 2.4263018841564157

Epoch: 591| Step: 0
Training loss: 0.0772570135738954
Validation loss: 2.4081031355335236

Epoch: 6| Step: 1
Training loss: 0.11064592698943271
Validation loss: 2.418812886794982

Epoch: 6| Step: 2
Training loss: 0.07834383594628433
Validation loss: 2.420672353277188

Epoch: 6| Step: 3
Training loss: 0.10167684903544638
Validation loss: 2.4235293768538058

Epoch: 6| Step: 4
Training loss: 0.06639887263887848
Validation loss: 2.405266190831631

Epoch: 6| Step: 5
Training loss: 0.10139409187798672
Validation loss: 2.4217992097902252

Epoch: 6| Step: 6
Training loss: 0.11589811198385237
Validation loss: 2.404400307806864

Epoch: 6| Step: 7
Training loss: 0.10948300989006875
Validation loss: 2.418246365724771

Epoch: 6| Step: 8
Training loss: 0.08315225543810753
Validation loss: 2.4235484750615375

Epoch: 6| Step: 9
Training loss: 0.09930604207322438
Validation loss: 2.4266096322955595

Epoch: 6| Step: 10
Training loss: 0.12297687734504568
Validation loss: 2.4245410917140884

Epoch: 6| Step: 11
Training loss: 0.1193013904468921
Validation loss: 2.4157490124874164

Epoch: 6| Step: 12
Training loss: 0.17022373528601067
Validation loss: 2.422499498292989

Epoch: 6| Step: 13
Training loss: 0.057180943386808146
Validation loss: 2.4081522754058917

Epoch: 592| Step: 0
Training loss: 0.09572562128474615
Validation loss: 2.3989004735992077

Epoch: 6| Step: 1
Training loss: 0.0962132753404885
Validation loss: 2.4116672678818847

Epoch: 6| Step: 2
Training loss: 0.10950191831541414
Validation loss: 2.3893570936776958

Epoch: 6| Step: 3
Training loss: 0.1389608327644628
Validation loss: 2.40614455042234

Epoch: 6| Step: 4
Training loss: 0.08047017216583072
Validation loss: 2.4022601657576126

Epoch: 6| Step: 5
Training loss: 0.1558032264531939
Validation loss: 2.420163678183596

Epoch: 6| Step: 6
Training loss: 0.12467933293415336
Validation loss: 2.4152398322693496

Epoch: 6| Step: 7
Training loss: 0.10260624274301279
Validation loss: 2.431308551254851

Epoch: 6| Step: 8
Training loss: 0.12129167563161988
Validation loss: 2.431542216108237

Epoch: 6| Step: 9
Training loss: 0.11142930235050975
Validation loss: 2.4430657613801268

Epoch: 6| Step: 10
Training loss: 0.06653727199980124
Validation loss: 2.445320205652747

Epoch: 6| Step: 11
Training loss: 0.08346211706940344
Validation loss: 2.480981729199575

Epoch: 6| Step: 12
Training loss: 0.10330435498035594
Validation loss: 2.431173071363991

Epoch: 6| Step: 13
Training loss: 0.07791358236380849
Validation loss: 2.447469652598152

Epoch: 593| Step: 0
Training loss: 0.11197839688620534
Validation loss: 2.4667509123071736

Epoch: 6| Step: 1
Training loss: 0.11275680589804765
Validation loss: 2.4516141298938114

Epoch: 6| Step: 2
Training loss: 0.15956766436841316
Validation loss: 2.475237883066458

Epoch: 6| Step: 3
Training loss: 0.07219647630393951
Validation loss: 2.469811531778963

Epoch: 6| Step: 4
Training loss: 0.103198429176986
Validation loss: 2.4522020756509

Epoch: 6| Step: 5
Training loss: 0.06892997473836641
Validation loss: 2.4482848285693195

Epoch: 6| Step: 6
Training loss: 0.1477241125531573
Validation loss: 2.4669596113420904

Epoch: 6| Step: 7
Training loss: 0.06322665538048058
Validation loss: 2.4705592709436783

Epoch: 6| Step: 8
Training loss: 0.10037214279740043
Validation loss: 2.4719237279148807

Epoch: 6| Step: 9
Training loss: 0.0686996438101179
Validation loss: 2.4626898174836116

Epoch: 6| Step: 10
Training loss: 0.08595650636130898
Validation loss: 2.471621607438737

Epoch: 6| Step: 11
Training loss: 0.07129331471551159
Validation loss: 2.4779353266698134

Epoch: 6| Step: 12
Training loss: 0.09915973116994153
Validation loss: 2.4514623023041118

Epoch: 6| Step: 13
Training loss: 0.10351875138509922
Validation loss: 2.4642275614403233

Epoch: 594| Step: 0
Training loss: 0.11146460917294251
Validation loss: 2.4426621654134024

Epoch: 6| Step: 1
Training loss: 0.07974624186718574
Validation loss: 2.440717931048043

Epoch: 6| Step: 2
Training loss: 0.11811841918638201
Validation loss: 2.436589866497261

Epoch: 6| Step: 3
Training loss: 0.12275449893781021
Validation loss: 2.447973597241341

Epoch: 6| Step: 4
Training loss: 0.09240523100579132
Validation loss: 2.440898384676512

Epoch: 6| Step: 5
Training loss: 0.05310226306239893
Validation loss: 2.428189770426755

Epoch: 6| Step: 6
Training loss: 0.09099671449795461
Validation loss: 2.4026078369907595

Epoch: 6| Step: 7
Training loss: 0.1232884661722504
Validation loss: 2.4386922498853894

Epoch: 6| Step: 8
Training loss: 0.08132745049936227
Validation loss: 2.3837797050105722

Epoch: 6| Step: 9
Training loss: 0.11862834640652699
Validation loss: 2.3937345395611302

Epoch: 6| Step: 10
Training loss: 0.10664281109256442
Validation loss: 2.4126769609480943

Epoch: 6| Step: 11
Training loss: 0.08379415105382432
Validation loss: 2.3785572494791114

Epoch: 6| Step: 12
Training loss: 0.10395000296657388
Validation loss: 2.393094396987085

Epoch: 6| Step: 13
Training loss: 0.09732113560205012
Validation loss: 2.388705056420962

Epoch: 595| Step: 0
Training loss: 0.14492265438888194
Validation loss: 2.408704670948492

Epoch: 6| Step: 1
Training loss: 0.07769432869408677
Validation loss: 2.415452275089697

Epoch: 6| Step: 2
Training loss: 0.07860412899787021
Validation loss: 2.4161646761474023

Epoch: 6| Step: 3
Training loss: 0.15505988352458147
Validation loss: 2.4375928927343793

Epoch: 6| Step: 4
Training loss: 0.0991794855792592
Validation loss: 2.425192241493345

Epoch: 6| Step: 5
Training loss: 0.11231597346112777
Validation loss: 2.4389214263956767

Epoch: 6| Step: 6
Training loss: 0.09440658048845293
Validation loss: 2.4340639614958763

Epoch: 6| Step: 7
Training loss: 0.09000767907688267
Validation loss: 2.440481303702997

Epoch: 6| Step: 8
Training loss: 0.07651322248432788
Validation loss: 2.4464056957771225

Epoch: 6| Step: 9
Training loss: 0.12136201983188004
Validation loss: 2.4448114462545014

Epoch: 6| Step: 10
Training loss: 0.10047575091209297
Validation loss: 2.4314608291355806

Epoch: 6| Step: 11
Training loss: 0.12514836476997382
Validation loss: 2.4588176096653207

Epoch: 6| Step: 12
Training loss: 0.08675644545012669
Validation loss: 2.4334600924106162

Epoch: 6| Step: 13
Training loss: 0.045830559759496875
Validation loss: 2.424117924319971

Epoch: 596| Step: 0
Training loss: 0.09364748853681772
Validation loss: 2.4311226832303565

Epoch: 6| Step: 1
Training loss: 0.09225512828438294
Validation loss: 2.429354949278069

Epoch: 6| Step: 2
Training loss: 0.08734435283439207
Validation loss: 2.4180647761241216

Epoch: 6| Step: 3
Training loss: 0.08741878109878415
Validation loss: 2.4296583496978696

Epoch: 6| Step: 4
Training loss: 0.127486385431999
Validation loss: 2.418139654219406

Epoch: 6| Step: 5
Training loss: 0.1462761352490771
Validation loss: 2.419104127831522

Epoch: 6| Step: 6
Training loss: 0.06651568511528254
Validation loss: 2.438122953959614

Epoch: 6| Step: 7
Training loss: 0.09052955065097848
Validation loss: 2.4237456661393924

Epoch: 6| Step: 8
Training loss: 0.11667111589116609
Validation loss: 2.425400464275907

Epoch: 6| Step: 9
Training loss: 0.054231230415194745
Validation loss: 2.457569857495249

Epoch: 6| Step: 10
Training loss: 0.08052856828349292
Validation loss: 2.4294042322906595

Epoch: 6| Step: 11
Training loss: 0.13225752920079517
Validation loss: 2.4317110617709883

Epoch: 6| Step: 12
Training loss: 0.10921090878975338
Validation loss: 2.431418364850265

Epoch: 6| Step: 13
Training loss: 0.04538088798727271
Validation loss: 2.4463862515201407

Epoch: 597| Step: 0
Training loss: 0.10453483566839991
Validation loss: 2.4707514992133266

Epoch: 6| Step: 1
Training loss: 0.11597257499354052
Validation loss: 2.43396526192392

Epoch: 6| Step: 2
Training loss: 0.09900551902825527
Validation loss: 2.4423928035478215

Epoch: 6| Step: 3
Training loss: 0.12756036635992354
Validation loss: 2.4216454732249098

Epoch: 6| Step: 4
Training loss: 0.055006937766600136
Validation loss: 2.429646516223527

Epoch: 6| Step: 5
Training loss: 0.10123711051400874
Validation loss: 2.4255529130463276

Epoch: 6| Step: 6
Training loss: 0.09292522862285418
Validation loss: 2.430600700095894

Epoch: 6| Step: 7
Training loss: 0.0847823853777021
Validation loss: 2.440056891471543

Epoch: 6| Step: 8
Training loss: 0.11816535113554144
Validation loss: 2.45776520819888

Epoch: 6| Step: 9
Training loss: 0.09016856274745655
Validation loss: 2.4432406498889985

Epoch: 6| Step: 10
Training loss: 0.07090416956027076
Validation loss: 2.4273856514007615

Epoch: 6| Step: 11
Training loss: 0.07099201093580174
Validation loss: 2.4504502361155387

Epoch: 6| Step: 12
Training loss: 0.06579690695363041
Validation loss: 2.4256218323853873

Epoch: 6| Step: 13
Training loss: 0.12337891872611866
Validation loss: 2.454043989372622

Epoch: 598| Step: 0
Training loss: 0.13428922427244971
Validation loss: 2.4293675502993586

Epoch: 6| Step: 1
Training loss: 0.0842955723185462
Validation loss: 2.4181352303883714

Epoch: 6| Step: 2
Training loss: 0.1052192412243993
Validation loss: 2.4292400005905974

Epoch: 6| Step: 3
Training loss: 0.07132580868280616
Validation loss: 2.428101976288955

Epoch: 6| Step: 4
Training loss: 0.090924106271915
Validation loss: 2.422159445654955

Epoch: 6| Step: 5
Training loss: 0.06868163171879593
Validation loss: 2.430652370507242

Epoch: 6| Step: 6
Training loss: 0.11549101151003961
Validation loss: 2.434993238454659

Epoch: 6| Step: 7
Training loss: 0.11822729546862892
Validation loss: 2.4526690708709618

Epoch: 6| Step: 8
Training loss: 0.0750738252446553
Validation loss: 2.4326860800595087

Epoch: 6| Step: 9
Training loss: 0.14151769324744878
Validation loss: 2.450592304303525

Epoch: 6| Step: 10
Training loss: 0.15712994515293083
Validation loss: 2.435215966091969

Epoch: 6| Step: 11
Training loss: 0.05527384238886729
Validation loss: 2.4322017268250407

Epoch: 6| Step: 12
Training loss: 0.1195785961627837
Validation loss: 2.4240348423485987

Epoch: 6| Step: 13
Training loss: 0.09840209339311855
Validation loss: 2.4443192393607034

Epoch: 599| Step: 0
Training loss: 0.1028267412554838
Validation loss: 2.4492869510828283

Epoch: 6| Step: 1
Training loss: 0.08896592178277805
Validation loss: 2.4102338816051914

Epoch: 6| Step: 2
Training loss: 0.07894475134490142
Validation loss: 2.450191665093664

Epoch: 6| Step: 3
Training loss: 0.0814189024170134
Validation loss: 2.4453252169349717

Epoch: 6| Step: 4
Training loss: 0.14411871260239653
Validation loss: 2.447156562866544

Epoch: 6| Step: 5
Training loss: 0.12920942922138903
Validation loss: 2.449128919038948

Epoch: 6| Step: 6
Training loss: 0.10111847429238516
Validation loss: 2.457224682627757

Epoch: 6| Step: 7
Training loss: 0.11495253477454472
Validation loss: 2.4344201731114237

Epoch: 6| Step: 8
Training loss: 0.1080100774958659
Validation loss: 2.4586343874651666

Epoch: 6| Step: 9
Training loss: 0.07012677167033105
Validation loss: 2.4486452118593194

Epoch: 6| Step: 10
Training loss: 0.16292571574903092
Validation loss: 2.453259620815867

Epoch: 6| Step: 11
Training loss: 0.11443492415944426
Validation loss: 2.4709985663638334

Epoch: 6| Step: 12
Training loss: 0.09113331663382246
Validation loss: 2.462782087212501

Epoch: 6| Step: 13
Training loss: 0.11258849067802713
Validation loss: 2.4150701853487537

Epoch: 600| Step: 0
Training loss: 0.10626165487374943
Validation loss: 2.4368385772200347

Epoch: 6| Step: 1
Training loss: 0.0821882346613579
Validation loss: 2.3986767204004793

Epoch: 6| Step: 2
Training loss: 0.14871896234638649
Validation loss: 2.419641358797825

Epoch: 6| Step: 3
Training loss: 0.0927232606617978
Validation loss: 2.4203037411339627

Epoch: 6| Step: 4
Training loss: 0.12520981108078522
Validation loss: 2.4237919794881035

Epoch: 6| Step: 5
Training loss: 0.07366332097519286
Validation loss: 2.410292231568793

Epoch: 6| Step: 6
Training loss: 0.07161363760005827
Validation loss: 2.4528820491530072

Epoch: 6| Step: 7
Training loss: 0.11823466059933954
Validation loss: 2.4319302038517296

Epoch: 6| Step: 8
Training loss: 0.09266949402170915
Validation loss: 2.4576127091257787

Epoch: 6| Step: 9
Training loss: 0.07910089727993276
Validation loss: 2.4344875524875245

Epoch: 6| Step: 10
Training loss: 0.13900272767131583
Validation loss: 2.4307332102770336

Epoch: 6| Step: 11
Training loss: 0.09845313144884207
Validation loss: 2.44815639316057

Epoch: 6| Step: 12
Training loss: 0.06069334832680096
Validation loss: 2.473355166487001

Epoch: 6| Step: 13
Training loss: 0.08180657055603502
Validation loss: 2.445662446339554

Epoch: 601| Step: 0
Training loss: 0.08872165395996628
Validation loss: 2.4584917167281395

Epoch: 6| Step: 1
Training loss: 0.10059260374034143
Validation loss: 2.4402263624462694

Epoch: 6| Step: 2
Training loss: 0.0637654187802731
Validation loss: 2.4387978374042008

Epoch: 6| Step: 3
Training loss: 0.12069680928863893
Validation loss: 2.4554037312739716

Epoch: 6| Step: 4
Training loss: 0.09622844234785002
Validation loss: 2.457808196715022

Epoch: 6| Step: 5
Training loss: 0.09628811926698928
Validation loss: 2.4445194731692585

Epoch: 6| Step: 6
Training loss: 0.10359466881725728
Validation loss: 2.4448839698217935

Epoch: 6| Step: 7
Training loss: 0.10682611420292723
Validation loss: 2.4168687866039082

Epoch: 6| Step: 8
Training loss: 0.08526359559849714
Validation loss: 2.4138558961712087

Epoch: 6| Step: 9
Training loss: 0.14361207813935098
Validation loss: 2.407293029451939

Epoch: 6| Step: 10
Training loss: 0.16476954512004732
Validation loss: 2.4081839269186487

Epoch: 6| Step: 11
Training loss: 0.10088919322176672
Validation loss: 2.395356839980903

Epoch: 6| Step: 12
Training loss: 0.09478170225499008
Validation loss: 2.402211540073051

Epoch: 6| Step: 13
Training loss: 0.06342390150158103
Validation loss: 2.430483049951001

Epoch: 602| Step: 0
Training loss: 0.12635632133638483
Validation loss: 2.4115237926109816

Epoch: 6| Step: 1
Training loss: 0.08915376567187175
Validation loss: 2.417998068792767

Epoch: 6| Step: 2
Training loss: 0.07608165349610466
Validation loss: 2.3736089703335077

Epoch: 6| Step: 3
Training loss: 0.048093161539997535
Validation loss: 2.4094069214144516

Epoch: 6| Step: 4
Training loss: 0.12995874006903427
Validation loss: 2.4068228033585477

Epoch: 6| Step: 5
Training loss: 0.11561282293532583
Validation loss: 2.4249833763033997

Epoch: 6| Step: 6
Training loss: 0.09518679181152968
Validation loss: 2.404325794325178

Epoch: 6| Step: 7
Training loss: 0.1070317553765833
Validation loss: 2.4142512296714562

Epoch: 6| Step: 8
Training loss: 0.08540248955513217
Validation loss: 2.437536171517763

Epoch: 6| Step: 9
Training loss: 0.08202571793476444
Validation loss: 2.4300926938159177

Epoch: 6| Step: 10
Training loss: 0.06211391985657146
Validation loss: 2.418762944943548

Epoch: 6| Step: 11
Training loss: 0.10283174976625525
Validation loss: 2.4444332314430173

Epoch: 6| Step: 12
Training loss: 0.11207005412675945
Validation loss: 2.448079737928618

Epoch: 6| Step: 13
Training loss: 0.08447165571292758
Validation loss: 2.4499178137020796

Epoch: 603| Step: 0
Training loss: 0.12158935019283583
Validation loss: 2.437296983811442

Epoch: 6| Step: 1
Training loss: 0.10959635202447793
Validation loss: 2.4449900752971554

Epoch: 6| Step: 2
Training loss: 0.07958715820462285
Validation loss: 2.4359383972339335

Epoch: 6| Step: 3
Training loss: 0.10833456546131674
Validation loss: 2.4518343966960754

Epoch: 6| Step: 4
Training loss: 0.0923771777864173
Validation loss: 2.428597506904203

Epoch: 6| Step: 5
Training loss: 0.05335691125188991
Validation loss: 2.428184816689498

Epoch: 6| Step: 6
Training loss: 0.09707781188978204
Validation loss: 2.4294864531926414

Epoch: 6| Step: 7
Training loss: 0.06327077814277081
Validation loss: 2.4227607274446195

Epoch: 6| Step: 8
Training loss: 0.06142096273144578
Validation loss: 2.425074685218122

Epoch: 6| Step: 9
Training loss: 0.08122568878635124
Validation loss: 2.4292278009890125

Epoch: 6| Step: 10
Training loss: 0.11033278280155163
Validation loss: 2.4004034432190156

Epoch: 6| Step: 11
Training loss: 0.08868977370247577
Validation loss: 2.4134843734509666

Epoch: 6| Step: 12
Training loss: 0.07595367233920411
Validation loss: 2.4282943798695893

Epoch: 6| Step: 13
Training loss: 0.0725523602001597
Validation loss: 2.4473968924506857

Epoch: 604| Step: 0
Training loss: 0.08471724760171997
Validation loss: 2.429337977210493

Epoch: 6| Step: 1
Training loss: 0.0542993501229424
Validation loss: 2.426588275657553

Epoch: 6| Step: 2
Training loss: 0.1069756081316441
Validation loss: 2.45228800182451

Epoch: 6| Step: 3
Training loss: 0.11003379728607568
Validation loss: 2.4439696828665185

Epoch: 6| Step: 4
Training loss: 0.06129058984600252
Validation loss: 2.4353083630182026

Epoch: 6| Step: 5
Training loss: 0.14522736039440906
Validation loss: 2.4495195362184687

Epoch: 6| Step: 6
Training loss: 0.09976968767442057
Validation loss: 2.4406379724046756

Epoch: 6| Step: 7
Training loss: 0.11482649076614472
Validation loss: 2.4513311176436896

Epoch: 6| Step: 8
Training loss: 0.10619690985184439
Validation loss: 2.467274977143937

Epoch: 6| Step: 9
Training loss: 0.11179009590281777
Validation loss: 2.4347991810115035

Epoch: 6| Step: 10
Training loss: 0.12346024183031334
Validation loss: 2.429919733442479

Epoch: 6| Step: 11
Training loss: 0.07976416062945302
Validation loss: 2.446627666875854

Epoch: 6| Step: 12
Training loss: 0.092181687656729
Validation loss: 2.465037862298103

Epoch: 6| Step: 13
Training loss: 0.08727558897025132
Validation loss: 2.4304712916903894

Epoch: 605| Step: 0
Training loss: 0.09020414320752503
Validation loss: 2.4098809394587257

Epoch: 6| Step: 1
Training loss: 0.06946199670476805
Validation loss: 2.447298283820586

Epoch: 6| Step: 2
Training loss: 0.08976791643682473
Validation loss: 2.4454404568184644

Epoch: 6| Step: 3
Training loss: 0.05742774750075904
Validation loss: 2.427675448450051

Epoch: 6| Step: 4
Training loss: 0.14684898775139538
Validation loss: 2.456231299113637

Epoch: 6| Step: 5
Training loss: 0.07085680882308507
Validation loss: 2.4338084881180118

Epoch: 6| Step: 6
Training loss: 0.09593882050366513
Validation loss: 2.4478387611226258

Epoch: 6| Step: 7
Training loss: 0.09398471735497935
Validation loss: 2.4279926678658206

Epoch: 6| Step: 8
Training loss: 0.08723686045577449
Validation loss: 2.4605365250064195

Epoch: 6| Step: 9
Training loss: 0.07877078478851696
Validation loss: 2.438027456559856

Epoch: 6| Step: 10
Training loss: 0.10119074862674561
Validation loss: 2.4696356650336684

Epoch: 6| Step: 11
Training loss: 0.0810664237384541
Validation loss: 2.4263105662571673

Epoch: 6| Step: 12
Training loss: 0.11731098741832548
Validation loss: 2.4288291241848943

Epoch: 6| Step: 13
Training loss: 0.11047594689743347
Validation loss: 2.451224577557418

Epoch: 606| Step: 0
Training loss: 0.0716513806509037
Validation loss: 2.448683134131513

Epoch: 6| Step: 1
Training loss: 0.07315454325381766
Validation loss: 2.455129756807638

Epoch: 6| Step: 2
Training loss: 0.05213053794371
Validation loss: 2.429504396072848

Epoch: 6| Step: 3
Training loss: 0.08602007778155726
Validation loss: 2.4333187986836875

Epoch: 6| Step: 4
Training loss: 0.09838904577141609
Validation loss: 2.4243032592249083

Epoch: 6| Step: 5
Training loss: 0.07058478655296355
Validation loss: 2.442951675581463

Epoch: 6| Step: 6
Training loss: 0.1076545190187547
Validation loss: 2.4183260009167786

Epoch: 6| Step: 7
Training loss: 0.13166342857559982
Validation loss: 2.403634197454164

Epoch: 6| Step: 8
Training loss: 0.10666633547542734
Validation loss: 2.4282975111840153

Epoch: 6| Step: 9
Training loss: 0.10224918080272216
Validation loss: 2.4040703033683486

Epoch: 6| Step: 10
Training loss: 0.07963484679484545
Validation loss: 2.4238781761353687

Epoch: 6| Step: 11
Training loss: 0.05637247226682474
Validation loss: 2.422875159270142

Epoch: 6| Step: 12
Training loss: 0.11703224228818981
Validation loss: 2.4456799665562823

Epoch: 6| Step: 13
Training loss: 0.0834688984490406
Validation loss: 2.4190433446944626

Epoch: 607| Step: 0
Training loss: 0.09245907577361537
Validation loss: 2.428845899263681

Epoch: 6| Step: 1
Training loss: 0.0836577579287931
Validation loss: 2.40160331290286

Epoch: 6| Step: 2
Training loss: 0.10628502703166065
Validation loss: 2.4248685407257886

Epoch: 6| Step: 3
Training loss: 0.08642379305864108
Validation loss: 2.434448770399995

Epoch: 6| Step: 4
Training loss: 0.14750118211700866
Validation loss: 2.415347275559855

Epoch: 6| Step: 5
Training loss: 0.09468742919044239
Validation loss: 2.4116194603942542

Epoch: 6| Step: 6
Training loss: 0.06835447021327062
Validation loss: 2.411131456853927

Epoch: 6| Step: 7
Training loss: 0.04746838832972343
Validation loss: 2.4321882519260183

Epoch: 6| Step: 8
Training loss: 0.06519064722574165
Validation loss: 2.425669329287647

Epoch: 6| Step: 9
Training loss: 0.075097469359365
Validation loss: 2.4485197212437053

Epoch: 6| Step: 10
Training loss: 0.11633975238602416
Validation loss: 2.4149214673961557

Epoch: 6| Step: 11
Training loss: 0.06690625971981586
Validation loss: 2.441980168177632

Epoch: 6| Step: 12
Training loss: 0.07581361860965832
Validation loss: 2.4299482850510556

Epoch: 6| Step: 13
Training loss: 0.11405042427624593
Validation loss: 2.422818486850272

Epoch: 608| Step: 0
Training loss: 0.10455959142560327
Validation loss: 2.4414889476921333

Epoch: 6| Step: 1
Training loss: 0.09748839257300392
Validation loss: 2.4278783610899684

Epoch: 6| Step: 2
Training loss: 0.05561875917419292
Validation loss: 2.446101329060432

Epoch: 6| Step: 3
Training loss: 0.12353836402196247
Validation loss: 2.4456982885393024

Epoch: 6| Step: 4
Training loss: 0.13834334800296452
Validation loss: 2.4338682152214384

Epoch: 6| Step: 5
Training loss: 0.12267048352260972
Validation loss: 2.4389431869374887

Epoch: 6| Step: 6
Training loss: 0.0540878100250826
Validation loss: 2.4738775638851718

Epoch: 6| Step: 7
Training loss: 0.10048871295120737
Validation loss: 2.47123405539577

Epoch: 6| Step: 8
Training loss: 0.1147633397554546
Validation loss: 2.4530600199608106

Epoch: 6| Step: 9
Training loss: 0.0663584859957786
Validation loss: 2.430377111217917

Epoch: 6| Step: 10
Training loss: 0.1224211762109518
Validation loss: 2.4350572719535966

Epoch: 6| Step: 11
Training loss: 0.07729715788662056
Validation loss: 2.428210788856824

Epoch: 6| Step: 12
Training loss: 0.08816966425229757
Validation loss: 2.4413358073254816

Epoch: 6| Step: 13
Training loss: 0.09186433788635451
Validation loss: 2.4504081145074195

Epoch: 609| Step: 0
Training loss: 0.08535363709833126
Validation loss: 2.4375730198055776

Epoch: 6| Step: 1
Training loss: 0.08570711454757149
Validation loss: 2.4346994519670604

Epoch: 6| Step: 2
Training loss: 0.07607010620910373
Validation loss: 2.4131657838883886

Epoch: 6| Step: 3
Training loss: 0.0815181951523467
Validation loss: 2.446275261727525

Epoch: 6| Step: 4
Training loss: 0.08535931080667902
Validation loss: 2.43829594067687

Epoch: 6| Step: 5
Training loss: 0.09394637045789998
Validation loss: 2.4053930539352835

Epoch: 6| Step: 6
Training loss: 0.10374887745893405
Validation loss: 2.4214816956670955

Epoch: 6| Step: 7
Training loss: 0.13353091067050749
Validation loss: 2.4353378020247587

Epoch: 6| Step: 8
Training loss: 0.09212325290061077
Validation loss: 2.4109363847286724

Epoch: 6| Step: 9
Training loss: 0.05938871250420298
Validation loss: 2.407274992901444

Epoch: 6| Step: 10
Training loss: 0.0991881383395792
Validation loss: 2.4095490933163197

Epoch: 6| Step: 11
Training loss: 0.07890551019076264
Validation loss: 2.4370815968698007

Epoch: 6| Step: 12
Training loss: 0.0753083030384024
Validation loss: 2.423732216682463

Epoch: 6| Step: 13
Training loss: 0.059578121173797495
Validation loss: 2.3962027155759156

Epoch: 610| Step: 0
Training loss: 0.045281571693475554
Validation loss: 2.3926403288867766

Epoch: 6| Step: 1
Training loss: 0.05821909733324158
Validation loss: 2.422460242252631

Epoch: 6| Step: 2
Training loss: 0.1375890822544788
Validation loss: 2.4255348014191975

Epoch: 6| Step: 3
Training loss: 0.1099190718666874
Validation loss: 2.4206074324727354

Epoch: 6| Step: 4
Training loss: 0.1126506287102186
Validation loss: 2.396492715831035

Epoch: 6| Step: 5
Training loss: 0.1481317898143784
Validation loss: 2.4072199383346886

Epoch: 6| Step: 6
Training loss: 0.07277202380614768
Validation loss: 2.4242357681016165

Epoch: 6| Step: 7
Training loss: 0.09952788666173178
Validation loss: 2.4295839339650933

Epoch: 6| Step: 8
Training loss: 0.09877952673711352
Validation loss: 2.436276407189148

Epoch: 6| Step: 9
Training loss: 0.1098094129953509
Validation loss: 2.447894526486014

Epoch: 6| Step: 10
Training loss: 0.11415340266552275
Validation loss: 2.438670149654705

Epoch: 6| Step: 11
Training loss: 0.074376575283991
Validation loss: 2.4168186645600103

Epoch: 6| Step: 12
Training loss: 0.11604816994972439
Validation loss: 2.424281255180559

Epoch: 6| Step: 13
Training loss: 0.07439749613407393
Validation loss: 2.413201149984562

Epoch: 611| Step: 0
Training loss: 0.113856883752423
Validation loss: 2.4408696213832313

Epoch: 6| Step: 1
Training loss: 0.09708081463007825
Validation loss: 2.4100659310403403

Epoch: 6| Step: 2
Training loss: 0.09341049311174379
Validation loss: 2.381074971428537

Epoch: 6| Step: 3
Training loss: 0.10104879805954496
Validation loss: 2.4355848975356245

Epoch: 6| Step: 4
Training loss: 0.10702084330622531
Validation loss: 2.4184822805385195

Epoch: 6| Step: 5
Training loss: 0.05821038439301923
Validation loss: 2.4287854620475486

Epoch: 6| Step: 6
Training loss: 0.10719004671113133
Validation loss: 2.413165672872206

Epoch: 6| Step: 7
Training loss: 0.11003218488829651
Validation loss: 2.4182140402124346

Epoch: 6| Step: 8
Training loss: 0.106141237907993
Validation loss: 2.424567793369383

Epoch: 6| Step: 9
Training loss: 0.06676673167195558
Validation loss: 2.416012935103229

Epoch: 6| Step: 10
Training loss: 0.09325322017593873
Validation loss: 2.394957112986263

Epoch: 6| Step: 11
Training loss: 0.06157131451470379
Validation loss: 2.4088670476931013

Epoch: 6| Step: 12
Training loss: 0.08293520613037238
Validation loss: 2.4174395362493724

Epoch: 6| Step: 13
Training loss: 0.061844073487506056
Validation loss: 2.3872604347531805

Epoch: 612| Step: 0
Training loss: 0.0937458226147424
Validation loss: 2.416493652212723

Epoch: 6| Step: 1
Training loss: 0.08808848045383233
Validation loss: 2.373989593000989

Epoch: 6| Step: 2
Training loss: 0.09378011537683491
Validation loss: 2.3476947033732345

Epoch: 6| Step: 3
Training loss: 0.12614811446203505
Validation loss: 2.406573091317765

Epoch: 6| Step: 4
Training loss: 0.06973661582662
Validation loss: 2.401004732162103

Epoch: 6| Step: 5
Training loss: 0.09847703756560541
Validation loss: 2.3849873841420846

Epoch: 6| Step: 6
Training loss: 0.08661788667850986
Validation loss: 2.413447249794133

Epoch: 6| Step: 7
Training loss: 0.06241502424060909
Validation loss: 2.3969606491110764

Epoch: 6| Step: 8
Training loss: 0.06506856501222029
Validation loss: 2.404111662369633

Epoch: 6| Step: 9
Training loss: 0.079840898943461
Validation loss: 2.417964120963447

Epoch: 6| Step: 10
Training loss: 0.10479353296192932
Validation loss: 2.4208868916044475

Epoch: 6| Step: 11
Training loss: 0.06597138112909542
Validation loss: 2.4056467046568364

Epoch: 6| Step: 12
Training loss: 0.08968255883405674
Validation loss: 2.4205328518088876

Epoch: 6| Step: 13
Training loss: 0.11956369607908426
Validation loss: 2.439398166625235

Epoch: 613| Step: 0
Training loss: 0.07811097376797917
Validation loss: 2.408660102527856

Epoch: 6| Step: 1
Training loss: 0.04783883947438253
Validation loss: 2.4319564775638387

Epoch: 6| Step: 2
Training loss: 0.14310993014254095
Validation loss: 2.424207107440746

Epoch: 6| Step: 3
Training loss: 0.121341475005907
Validation loss: 2.4117037566894037

Epoch: 6| Step: 4
Training loss: 0.12690543966450285
Validation loss: 2.422495939353226

Epoch: 6| Step: 5
Training loss: 0.0953484258405396
Validation loss: 2.414447583132732

Epoch: 6| Step: 6
Training loss: 0.11611911608230044
Validation loss: 2.4133958053553735

Epoch: 6| Step: 7
Training loss: 0.10035298974197895
Validation loss: 2.4123251722253882

Epoch: 6| Step: 8
Training loss: 0.0505158752944933
Validation loss: 2.3859443415871886

Epoch: 6| Step: 9
Training loss: 0.09517824985865318
Validation loss: 2.4122442453472126

Epoch: 6| Step: 10
Training loss: 0.12660693871965695
Validation loss: 2.375155579285971

Epoch: 6| Step: 11
Training loss: 0.11589950616959063
Validation loss: 2.388709717473773

Epoch: 6| Step: 12
Training loss: 0.09884839057461167
Validation loss: 2.371434199469988

Epoch: 6| Step: 13
Training loss: 0.1289839365978866
Validation loss: 2.383326254548101

Epoch: 614| Step: 0
Training loss: 0.11082807554041943
Validation loss: 2.369030433553112

Epoch: 6| Step: 1
Training loss: 0.08282072357066363
Validation loss: 2.3723758746963726

Epoch: 6| Step: 2
Training loss: 0.05648331336452273
Validation loss: 2.383096210515428

Epoch: 6| Step: 3
Training loss: 0.05255702006104427
Validation loss: 2.402607524352657

Epoch: 6| Step: 4
Training loss: 0.11191427953143154
Validation loss: 2.392685288387262

Epoch: 6| Step: 5
Training loss: 0.06579670879027771
Validation loss: 2.408897480839918

Epoch: 6| Step: 6
Training loss: 0.10477903246872437
Validation loss: 2.408908416926481

Epoch: 6| Step: 7
Training loss: 0.09092580144886649
Validation loss: 2.4098112305752553

Epoch: 6| Step: 8
Training loss: 0.08420397359473862
Validation loss: 2.4245189100734272

Epoch: 6| Step: 9
Training loss: 0.13049405617761367
Validation loss: 2.4173485614610377

Epoch: 6| Step: 10
Training loss: 0.10115846173099062
Validation loss: 2.4176949992442665

Epoch: 6| Step: 11
Training loss: 0.08422302559914525
Validation loss: 2.424785877775784

Epoch: 6| Step: 12
Training loss: 0.09076344853085351
Validation loss: 2.4432478290440516

Epoch: 6| Step: 13
Training loss: 0.07061373898306687
Validation loss: 2.4302253371863842

Epoch: 615| Step: 0
Training loss: 0.06770486509475857
Validation loss: 2.42123345787232

Epoch: 6| Step: 1
Training loss: 0.08154394526096793
Validation loss: 2.429688626880541

Epoch: 6| Step: 2
Training loss: 0.09346671318358944
Validation loss: 2.4264382879177164

Epoch: 6| Step: 3
Training loss: 0.10206300945119795
Validation loss: 2.390350088995783

Epoch: 6| Step: 4
Training loss: 0.060524709551280545
Validation loss: 2.412930081840823

Epoch: 6| Step: 5
Training loss: 0.08578790844678742
Validation loss: 2.432096990300933

Epoch: 6| Step: 6
Training loss: 0.08037990021228944
Validation loss: 2.4046874878890883

Epoch: 6| Step: 7
Training loss: 0.12924618404416519
Validation loss: 2.3817344331460473

Epoch: 6| Step: 8
Training loss: 0.12122457497628043
Validation loss: 2.394359641157235

Epoch: 6| Step: 9
Training loss: 0.1054622683476084
Validation loss: 2.3829239540655758

Epoch: 6| Step: 10
Training loss: 0.08767259894102564
Validation loss: 2.4036832185778767

Epoch: 6| Step: 11
Training loss: 0.08250905709691052
Validation loss: 2.3995755129142027

Epoch: 6| Step: 12
Training loss: 0.06145031307241003
Validation loss: 2.3893161053473966

Epoch: 6| Step: 13
Training loss: 0.08060247885277522
Validation loss: 2.424252188978451

Epoch: 616| Step: 0
Training loss: 0.08356354036107957
Validation loss: 2.394700894402707

Epoch: 6| Step: 1
Training loss: 0.06934165930980797
Validation loss: 2.406259505561173

Epoch: 6| Step: 2
Training loss: 0.06614274448907223
Validation loss: 2.390693143210811

Epoch: 6| Step: 3
Training loss: 0.07129996033550547
Validation loss: 2.4009860434956147

Epoch: 6| Step: 4
Training loss: 0.0950482108577108
Validation loss: 2.399833627457967

Epoch: 6| Step: 5
Training loss: 0.07670519046640692
Validation loss: 2.4105635516719968

Epoch: 6| Step: 6
Training loss: 0.0909788071571269
Validation loss: 2.4200376889629607

Epoch: 6| Step: 7
Training loss: 0.07292134902883753
Validation loss: 2.4079566872520837

Epoch: 6| Step: 8
Training loss: 0.12090633486712472
Validation loss: 2.4154212388892056

Epoch: 6| Step: 9
Training loss: 0.09884225683987001
Validation loss: 2.38818378321724

Epoch: 6| Step: 10
Training loss: 0.0806336093712043
Validation loss: 2.4073188175494145

Epoch: 6| Step: 11
Training loss: 0.1117757656753221
Validation loss: 2.4098831298298697

Epoch: 6| Step: 12
Training loss: 0.09105874112703007
Validation loss: 2.448590660821418

Epoch: 6| Step: 13
Training loss: 0.1913707077347328
Validation loss: 2.418927928250661

Epoch: 617| Step: 0
Training loss: 0.05821123834679947
Validation loss: 2.409608973294703

Epoch: 6| Step: 1
Training loss: 0.08961810926658863
Validation loss: 2.4269764416446318

Epoch: 6| Step: 2
Training loss: 0.1341587722224887
Validation loss: 2.418981840954845

Epoch: 6| Step: 3
Training loss: 0.10076346517706813
Validation loss: 2.4363552304981213

Epoch: 6| Step: 4
Training loss: 0.09711850407287748
Validation loss: 2.45513668309117

Epoch: 6| Step: 5
Training loss: 0.09998015974339469
Validation loss: 2.42522683232405

Epoch: 6| Step: 6
Training loss: 0.07266483358727271
Validation loss: 2.4177591229438713

Epoch: 6| Step: 7
Training loss: 0.09957243196903744
Validation loss: 2.4167908175880064

Epoch: 6| Step: 8
Training loss: 0.11500430172929031
Validation loss: 2.4046638672310303

Epoch: 6| Step: 9
Training loss: 0.09735300666063024
Validation loss: 2.4163114009370825

Epoch: 6| Step: 10
Training loss: 0.07119305560342915
Validation loss: 2.399365704216935

Epoch: 6| Step: 11
Training loss: 0.08350009239392965
Validation loss: 2.3965492972854694

Epoch: 6| Step: 12
Training loss: 0.12626540906746284
Validation loss: 2.4026586129334437

Epoch: 6| Step: 13
Training loss: 0.09499268167158398
Validation loss: 2.408698939028246

Epoch: 618| Step: 0
Training loss: 0.08444110468543994
Validation loss: 2.3842630856527265

Epoch: 6| Step: 1
Training loss: 0.07192965973975445
Validation loss: 2.41296526174535

Epoch: 6| Step: 2
Training loss: 0.10391422219633768
Validation loss: 2.3897573660796376

Epoch: 6| Step: 3
Training loss: 0.07652200411261735
Validation loss: 2.402361324688548

Epoch: 6| Step: 4
Training loss: 0.08175585989572864
Validation loss: 2.4191883842741895

Epoch: 6| Step: 5
Training loss: 0.09826391939092341
Validation loss: 2.4084314165035186

Epoch: 6| Step: 6
Training loss: 0.10280200306083372
Validation loss: 2.4016340611931297

Epoch: 6| Step: 7
Training loss: 0.11905540482714048
Validation loss: 2.4223221243407242

Epoch: 6| Step: 8
Training loss: 0.12296739160642954
Validation loss: 2.4337278890174945

Epoch: 6| Step: 9
Training loss: 0.06269330069026591
Validation loss: 2.3910902153629667

Epoch: 6| Step: 10
Training loss: 0.0727344525333733
Validation loss: 2.4130868450472893

Epoch: 6| Step: 11
Training loss: 0.08699913629649167
Validation loss: 2.406005399471093

Epoch: 6| Step: 12
Training loss: 0.07172586580267828
Validation loss: 2.412890638769701

Epoch: 6| Step: 13
Training loss: 0.07408860365267789
Validation loss: 2.4227733902746564

Epoch: 619| Step: 0
Training loss: 0.09208347343021339
Validation loss: 2.431515911561371

Epoch: 6| Step: 1
Training loss: 0.12672871048394885
Validation loss: 2.4190974424023546

Epoch: 6| Step: 2
Training loss: 0.11256186022992348
Validation loss: 2.4041015234285252

Epoch: 6| Step: 3
Training loss: 0.07185895004611308
Validation loss: 2.4269480531346113

Epoch: 6| Step: 4
Training loss: 0.10763172113829265
Validation loss: 2.4199769838317127

Epoch: 6| Step: 5
Training loss: 0.09449545206121172
Validation loss: 2.4348522011058433

Epoch: 6| Step: 6
Training loss: 0.09394574591522802
Validation loss: 2.408998159923387

Epoch: 6| Step: 7
Training loss: 0.08168931494756437
Validation loss: 2.390373893727803

Epoch: 6| Step: 8
Training loss: 0.0688868133981226
Validation loss: 2.416874015987783

Epoch: 6| Step: 9
Training loss: 0.10801059915903849
Validation loss: 2.4025925795636933

Epoch: 6| Step: 10
Training loss: 0.05567066253885684
Validation loss: 2.4089079050301927

Epoch: 6| Step: 11
Training loss: 0.1161082238587005
Validation loss: 2.4043583918585045

Epoch: 6| Step: 12
Training loss: 0.08790519911412176
Validation loss: 2.3846931802276092

Epoch: 6| Step: 13
Training loss: 0.10206933286410634
Validation loss: 2.402482144657766

Epoch: 620| Step: 0
Training loss: 0.10480671631494735
Validation loss: 2.4177461740677897

Epoch: 6| Step: 1
Training loss: 0.10728401527930057
Validation loss: 2.391827762176671

Epoch: 6| Step: 2
Training loss: 0.08662653092067786
Validation loss: 2.4067287205917403

Epoch: 6| Step: 3
Training loss: 0.09479371865989382
Validation loss: 2.4386717801356856

Epoch: 6| Step: 4
Training loss: 0.1409548229474276
Validation loss: 2.4194345013003447

Epoch: 6| Step: 5
Training loss: 0.10929315348677435
Validation loss: 2.4001884187378084

Epoch: 6| Step: 6
Training loss: 0.061099781155760126
Validation loss: 2.4169394565803524

Epoch: 6| Step: 7
Training loss: 0.09655718315017314
Validation loss: 2.433862344011959

Epoch: 6| Step: 8
Training loss: 0.10043766611722871
Validation loss: 2.4336871976557157

Epoch: 6| Step: 9
Training loss: 0.08437129096426672
Validation loss: 2.433413233507912

Epoch: 6| Step: 10
Training loss: 0.10711487336518126
Validation loss: 2.427199221030847

Epoch: 6| Step: 11
Training loss: 0.08155265339429506
Validation loss: 2.4366473570092886

Epoch: 6| Step: 12
Training loss: 0.08184622151436295
Validation loss: 2.415767395927717

Epoch: 6| Step: 13
Training loss: 0.13451580721027176
Validation loss: 2.3913154615664554

Epoch: 621| Step: 0
Training loss: 0.05707570394523836
Validation loss: 2.4082069967471127

Epoch: 6| Step: 1
Training loss: 0.10485445488118873
Validation loss: 2.4015088484475253

Epoch: 6| Step: 2
Training loss: 0.09591789863908552
Validation loss: 2.405820772317171

Epoch: 6| Step: 3
Training loss: 0.11136169513042653
Validation loss: 2.420038782465537

Epoch: 6| Step: 4
Training loss: 0.09378671920435594
Validation loss: 2.39427004866666

Epoch: 6| Step: 5
Training loss: 0.10596219942347943
Validation loss: 2.3935602741423354

Epoch: 6| Step: 6
Training loss: 0.09367418203622872
Validation loss: 2.4176940693034465

Epoch: 6| Step: 7
Training loss: 0.0773245455278977
Validation loss: 2.419793939172009

Epoch: 6| Step: 8
Training loss: 0.06233177044866443
Validation loss: 2.4110352816549603

Epoch: 6| Step: 9
Training loss: 0.07325631323337226
Validation loss: 2.4118805940435504

Epoch: 6| Step: 10
Training loss: 0.061865849028968516
Validation loss: 2.425593995583459

Epoch: 6| Step: 11
Training loss: 0.08614743394077749
Validation loss: 2.435057746768636

Epoch: 6| Step: 12
Training loss: 0.07624370293919512
Validation loss: 2.415655695507372

Epoch: 6| Step: 13
Training loss: 0.04597017586588801
Validation loss: 2.4249392608945235

Epoch: 622| Step: 0
Training loss: 0.060571215720633925
Validation loss: 2.4488363646385354

Epoch: 6| Step: 1
Training loss: 0.14638891288431194
Validation loss: 2.4310586536580465

Epoch: 6| Step: 2
Training loss: 0.11564374398039395
Validation loss: 2.460435552105093

Epoch: 6| Step: 3
Training loss: 0.10352192265769163
Validation loss: 2.446962372069584

Epoch: 6| Step: 4
Training loss: 0.0981433782936811
Validation loss: 2.438906704125937

Epoch: 6| Step: 5
Training loss: 0.06343310776078073
Validation loss: 2.415346165339081

Epoch: 6| Step: 6
Training loss: 0.07008613467292404
Validation loss: 2.4404881317171245

Epoch: 6| Step: 7
Training loss: 0.1263490463395013
Validation loss: 2.4481396017012163

Epoch: 6| Step: 8
Training loss: 0.12147672527919831
Validation loss: 2.435328737347744

Epoch: 6| Step: 9
Training loss: 0.14521942105804175
Validation loss: 2.4442451435967336

Epoch: 6| Step: 10
Training loss: 0.08523701339837461
Validation loss: 2.4418958388468335

Epoch: 6| Step: 11
Training loss: 0.12379818834231422
Validation loss: 2.4284338994464734

Epoch: 6| Step: 12
Training loss: 0.07100967306221338
Validation loss: 2.4204895984510824

Epoch: 6| Step: 13
Training loss: 0.07547677916016048
Validation loss: 2.407320150849002

Epoch: 623| Step: 0
Training loss: 0.06542206833730901
Validation loss: 2.4324289290063486

Epoch: 6| Step: 1
Training loss: 0.12597543878571618
Validation loss: 2.398182792803275

Epoch: 6| Step: 2
Training loss: 0.08633737838139245
Validation loss: 2.4016684757541333

Epoch: 6| Step: 3
Training loss: 0.1401351104537706
Validation loss: 2.4112801576469334

Epoch: 6| Step: 4
Training loss: 0.13156279773406637
Validation loss: 2.4440998350785055

Epoch: 6| Step: 5
Training loss: 0.145140754562486
Validation loss: 2.4075958058620213

Epoch: 6| Step: 6
Training loss: 0.09244276142074061
Validation loss: 2.4140039278830985

Epoch: 6| Step: 7
Training loss: 0.13276134234984033
Validation loss: 2.4271229020668135

Epoch: 6| Step: 8
Training loss: 0.0870007554071478
Validation loss: 2.4301979033457215

Epoch: 6| Step: 9
Training loss: 0.1336508545213519
Validation loss: 2.396820141917408

Epoch: 6| Step: 10
Training loss: 0.07958550821677036
Validation loss: 2.452482408056534

Epoch: 6| Step: 11
Training loss: 0.13664349119474825
Validation loss: 2.4456596307659164

Epoch: 6| Step: 12
Training loss: 0.09170264114802114
Validation loss: 2.407210690032242

Epoch: 6| Step: 13
Training loss: 0.09178194472459457
Validation loss: 2.398128572330518

Epoch: 624| Step: 0
Training loss: 0.10579755533450629
Validation loss: 2.42886103504985

Epoch: 6| Step: 1
Training loss: 0.1302915752086475
Validation loss: 2.3927855010712253

Epoch: 6| Step: 2
Training loss: 0.10619083222666799
Validation loss: 2.409538005332087

Epoch: 6| Step: 3
Training loss: 0.09954387717941551
Validation loss: 2.4044157360867797

Epoch: 6| Step: 4
Training loss: 0.10163066483881567
Validation loss: 2.4138660100718208

Epoch: 6| Step: 5
Training loss: 0.12438990674352358
Validation loss: 2.4138930868238666

Epoch: 6| Step: 6
Training loss: 0.10798613432476466
Validation loss: 2.4253414067649923

Epoch: 6| Step: 7
Training loss: 0.0654968017145811
Validation loss: 2.429253116149291

Epoch: 6| Step: 8
Training loss: 0.12535190965004672
Validation loss: 2.4526944449821406

Epoch: 6| Step: 9
Training loss: 0.06271084967279515
Validation loss: 2.4325083512482815

Epoch: 6| Step: 10
Training loss: 0.08851004192357066
Validation loss: 2.4610975300390323

Epoch: 6| Step: 11
Training loss: 0.14373221416945384
Validation loss: 2.4561899086347907

Epoch: 6| Step: 12
Training loss: 0.08567824597231724
Validation loss: 2.432457007984847

Epoch: 6| Step: 13
Training loss: 0.09623503300794427
Validation loss: 2.426408059984119

Epoch: 625| Step: 0
Training loss: 0.07862958679746142
Validation loss: 2.441334246880093

Epoch: 6| Step: 1
Training loss: 0.15189123192532392
Validation loss: 2.4277750721549194

Epoch: 6| Step: 2
Training loss: 0.0839926776552344
Validation loss: 2.415330856764852

Epoch: 6| Step: 3
Training loss: 0.09474017841759688
Validation loss: 2.4071876734900988

Epoch: 6| Step: 4
Training loss: 0.10171259279850457
Validation loss: 2.4187906886596315

Epoch: 6| Step: 5
Training loss: 0.03940509969042384
Validation loss: 2.3926889891697884

Epoch: 6| Step: 6
Training loss: 0.09166914088078155
Validation loss: 2.4110301895320614

Epoch: 6| Step: 7
Training loss: 0.12951273287676812
Validation loss: 2.4038361437252305

Epoch: 6| Step: 8
Training loss: 0.12416298967302528
Validation loss: 2.4024850631197805

Epoch: 6| Step: 9
Training loss: 0.06696834111990024
Validation loss: 2.379987674718102

Epoch: 6| Step: 10
Training loss: 0.09670182177007106
Validation loss: 2.4084083924673685

Epoch: 6| Step: 11
Training loss: 0.10329222414518481
Validation loss: 2.394969586974742

Epoch: 6| Step: 12
Training loss: 0.1210962572145859
Validation loss: 2.3938602692532314

Epoch: 6| Step: 13
Training loss: 0.06310788708713376
Validation loss: 2.393017280126712

Epoch: 626| Step: 0
Training loss: 0.08768703404627011
Validation loss: 2.406564090867992

Epoch: 6| Step: 1
Training loss: 0.15494898720913736
Validation loss: 2.4023833363537324

Epoch: 6| Step: 2
Training loss: 0.09199726268917661
Validation loss: 2.4161494316471446

Epoch: 6| Step: 3
Training loss: 0.06001156617234419
Validation loss: 2.4352134868963438

Epoch: 6| Step: 4
Training loss: 0.07768377041898526
Validation loss: 2.428694627520218

Epoch: 6| Step: 5
Training loss: 0.06873365527628415
Validation loss: 2.4491795579586593

Epoch: 6| Step: 6
Training loss: 0.10137814975183322
Validation loss: 2.447727944022854

Epoch: 6| Step: 7
Training loss: 0.09948958879902897
Validation loss: 2.4670470909135624

Epoch: 6| Step: 8
Training loss: 0.14350198569817982
Validation loss: 2.4535612524805

Epoch: 6| Step: 9
Training loss: 0.055615885281123885
Validation loss: 2.4512414576987833

Epoch: 6| Step: 10
Training loss: 0.10518865568514381
Validation loss: 2.462975291978942

Epoch: 6| Step: 11
Training loss: 0.11993937007515601
Validation loss: 2.424094343877495

Epoch: 6| Step: 12
Training loss: 0.07654659096220712
Validation loss: 2.3957359686529225

Epoch: 6| Step: 13
Training loss: 0.06282742238831808
Validation loss: 2.4146196881399593

Epoch: 627| Step: 0
Training loss: 0.0911694961440172
Validation loss: 2.3594275484112304

Epoch: 6| Step: 1
Training loss: 0.11403142884737784
Validation loss: 2.399324695073588

Epoch: 6| Step: 2
Training loss: 0.1217391710632893
Validation loss: 2.363851700400404

Epoch: 6| Step: 3
Training loss: 0.11486275606468303
Validation loss: 2.375557763277877

Epoch: 6| Step: 4
Training loss: 0.09595088126865951
Validation loss: 2.3803124804310043

Epoch: 6| Step: 5
Training loss: 0.06493669865690205
Validation loss: 2.3915315646775572

Epoch: 6| Step: 6
Training loss: 0.11666857744111074
Validation loss: 2.384469519485567

Epoch: 6| Step: 7
Training loss: 0.08594071317214412
Validation loss: 2.3702407905345386

Epoch: 6| Step: 8
Training loss: 0.09394271236318928
Validation loss: 2.386555125746605

Epoch: 6| Step: 9
Training loss: 0.08214849653436895
Validation loss: 2.385959789954413

Epoch: 6| Step: 10
Training loss: 0.08340227421996224
Validation loss: 2.3757738866771945

Epoch: 6| Step: 11
Training loss: 0.06646592950620689
Validation loss: 2.390444552566844

Epoch: 6| Step: 12
Training loss: 0.11966255648928538
Validation loss: 2.4494104488460784

Epoch: 6| Step: 13
Training loss: 0.17440099293438172
Validation loss: 2.4203957042782998

Epoch: 628| Step: 0
Training loss: 0.10780078644629294
Validation loss: 2.39613165226456

Epoch: 6| Step: 1
Training loss: 0.09052807438297339
Validation loss: 2.418306558807553

Epoch: 6| Step: 2
Training loss: 0.1763641124807903
Validation loss: 2.422026021842115

Epoch: 6| Step: 3
Training loss: 0.08509948549018438
Validation loss: 2.408187115786556

Epoch: 6| Step: 4
Training loss: 0.0973120727860439
Validation loss: 2.396016933973175

Epoch: 6| Step: 5
Training loss: 0.1535290797115322
Validation loss: 2.3894253543205046

Epoch: 6| Step: 6
Training loss: 0.07831810391610672
Validation loss: 2.4123561568651066

Epoch: 6| Step: 7
Training loss: 0.11227433997076812
Validation loss: 2.409986859017149

Epoch: 6| Step: 8
Training loss: 0.10847964123432279
Validation loss: 2.402025905431697

Epoch: 6| Step: 9
Training loss: 0.0999043342339832
Validation loss: 2.3869844808359555

Epoch: 6| Step: 10
Training loss: 0.1263781585529751
Validation loss: 2.3764601225421877

Epoch: 6| Step: 11
Training loss: 0.11075334913192841
Validation loss: 2.402358624838868

Epoch: 6| Step: 12
Training loss: 0.08822578791561479
Validation loss: 2.3927988903730957

Epoch: 6| Step: 13
Training loss: 0.09745973842395424
Validation loss: 2.40010286829822

Epoch: 629| Step: 0
Training loss: 0.11278372061991632
Validation loss: 2.396573780414358

Epoch: 6| Step: 1
Training loss: 0.12482892190676705
Validation loss: 2.4323575929047574

Epoch: 6| Step: 2
Training loss: 0.08321126519710721
Validation loss: 2.4069337133188538

Epoch: 6| Step: 3
Training loss: 0.1326798730491891
Validation loss: 2.3846318978581365

Epoch: 6| Step: 4
Training loss: 0.08024757182006917
Validation loss: 2.4073418498765062

Epoch: 6| Step: 5
Training loss: 0.07179299657472316
Validation loss: 2.398241659387716

Epoch: 6| Step: 6
Training loss: 0.07434813615352145
Validation loss: 2.38367282527088

Epoch: 6| Step: 7
Training loss: 0.09640607262723362
Validation loss: 2.412407331765975

Epoch: 6| Step: 8
Training loss: 0.08359556240719586
Validation loss: 2.385052690591892

Epoch: 6| Step: 9
Training loss: 0.11161462826831012
Validation loss: 2.405444386032495

Epoch: 6| Step: 10
Training loss: 0.1262037092386381
Validation loss: 2.4043950512935837

Epoch: 6| Step: 11
Training loss: 0.07792575582467239
Validation loss: 2.4047307147129864

Epoch: 6| Step: 12
Training loss: 0.10884632764163202
Validation loss: 2.388731382717749

Epoch: 6| Step: 13
Training loss: 0.1403208662461479
Validation loss: 2.3882285679131376

Epoch: 630| Step: 0
Training loss: 0.10225942719681473
Validation loss: 2.429558247132527

Epoch: 6| Step: 1
Training loss: 0.07525132929025474
Validation loss: 2.411368860858932

Epoch: 6| Step: 2
Training loss: 0.08242964787012702
Validation loss: 2.422603252899318

Epoch: 6| Step: 3
Training loss: 0.10160254184290503
Validation loss: 2.4220492011544468

Epoch: 6| Step: 4
Training loss: 0.10575729212915054
Validation loss: 2.4244434615810513

Epoch: 6| Step: 5
Training loss: 0.07872162041214283
Validation loss: 2.392232040678952

Epoch: 6| Step: 6
Training loss: 0.12001437928057725
Validation loss: 2.382484440080145

Epoch: 6| Step: 7
Training loss: 0.0639472493150437
Validation loss: 2.382700752369378

Epoch: 6| Step: 8
Training loss: 0.09014123923888717
Validation loss: 2.3556030487655515

Epoch: 6| Step: 9
Training loss: 0.10284094196776014
Validation loss: 2.3717494791146185

Epoch: 6| Step: 10
Training loss: 0.12879809986833873
Validation loss: 2.398653221175978

Epoch: 6| Step: 11
Training loss: 0.0885030338442861
Validation loss: 2.390907795797545

Epoch: 6| Step: 12
Training loss: 0.10414068424512204
Validation loss: 2.3836636394058464

Epoch: 6| Step: 13
Training loss: 0.1220704612731027
Validation loss: 2.408808051246861

Epoch: 631| Step: 0
Training loss: 0.11490135240427055
Validation loss: 2.3941867088476467

Epoch: 6| Step: 1
Training loss: 0.08424724149556696
Validation loss: 2.3991591010133098

Epoch: 6| Step: 2
Training loss: 0.1285737474372914
Validation loss: 2.3875167772214407

Epoch: 6| Step: 3
Training loss: 0.07518368172800217
Validation loss: 2.4382324233207218

Epoch: 6| Step: 4
Training loss: 0.06620447273539169
Validation loss: 2.402455325586554

Epoch: 6| Step: 5
Training loss: 0.08668868170787442
Validation loss: 2.4143881443581563

Epoch: 6| Step: 6
Training loss: 0.11076464181486005
Validation loss: 2.397044422424079

Epoch: 6| Step: 7
Training loss: 0.08493698812973303
Validation loss: 2.4033036918008914

Epoch: 6| Step: 8
Training loss: 0.08933979167889179
Validation loss: 2.417000159512214

Epoch: 6| Step: 9
Training loss: 0.08661928443782352
Validation loss: 2.408773598203533

Epoch: 6| Step: 10
Training loss: 0.12903962315881426
Validation loss: 2.389864736405452

Epoch: 6| Step: 11
Training loss: 0.05782991675337918
Validation loss: 2.421169453189603

Epoch: 6| Step: 12
Training loss: 0.08566848415577857
Validation loss: 2.392727789183511

Epoch: 6| Step: 13
Training loss: 0.0747130522452105
Validation loss: 2.393601481653108

Epoch: 632| Step: 0
Training loss: 0.07447998601067075
Validation loss: 2.434551794096383

Epoch: 6| Step: 1
Training loss: 0.1056875590572948
Validation loss: 2.400784905963331

Epoch: 6| Step: 2
Training loss: 0.09232223109136696
Validation loss: 2.3916742900177934

Epoch: 6| Step: 3
Training loss: 0.06819963865775229
Validation loss: 2.4037337542334765

Epoch: 6| Step: 4
Training loss: 0.10674770955765404
Validation loss: 2.396248857829113

Epoch: 6| Step: 5
Training loss: 0.07677222521830104
Validation loss: 2.3832182529505825

Epoch: 6| Step: 6
Training loss: 0.08019712375466576
Validation loss: 2.391510358951218

Epoch: 6| Step: 7
Training loss: 0.08505185513349958
Validation loss: 2.4170097360215252

Epoch: 6| Step: 8
Training loss: 0.07269011971930406
Validation loss: 2.405629282917898

Epoch: 6| Step: 9
Training loss: 0.07582272078174399
Validation loss: 2.400512985896488

Epoch: 6| Step: 10
Training loss: 0.11760061087046234
Validation loss: 2.4302294860979514

Epoch: 6| Step: 11
Training loss: 0.13175034746996464
Validation loss: 2.406164154196232

Epoch: 6| Step: 12
Training loss: 0.10096177928148271
Validation loss: 2.438725896558017

Epoch: 6| Step: 13
Training loss: 0.04919190317958767
Validation loss: 2.4146324637361785

Epoch: 633| Step: 0
Training loss: 0.07905307508163122
Validation loss: 2.4102524501699847

Epoch: 6| Step: 1
Training loss: 0.08562255172814306
Validation loss: 2.408608727737544

Epoch: 6| Step: 2
Training loss: 0.08720796430799864
Validation loss: 2.415598811260073

Epoch: 6| Step: 3
Training loss: 0.10069432021093196
Validation loss: 2.4220393595793683

Epoch: 6| Step: 4
Training loss: 0.07005673155850094
Validation loss: 2.433011965559875

Epoch: 6| Step: 5
Training loss: 0.07017378900058586
Validation loss: 2.4056968676477686

Epoch: 6| Step: 6
Training loss: 0.06680019019081614
Validation loss: 2.402732667039734

Epoch: 6| Step: 7
Training loss: 0.09268375880934547
Validation loss: 2.4078405253793194

Epoch: 6| Step: 8
Training loss: 0.07735626981532637
Validation loss: 2.4076125792790286

Epoch: 6| Step: 9
Training loss: 0.07607753119645333
Validation loss: 2.3972268894069497

Epoch: 6| Step: 10
Training loss: 0.0849455183660475
Validation loss: 2.413389019663873

Epoch: 6| Step: 11
Training loss: 0.1019214559017479
Validation loss: 2.388481528782914

Epoch: 6| Step: 12
Training loss: 0.11076064788510566
Validation loss: 2.423555284668845

Epoch: 6| Step: 13
Training loss: 0.13701519163030335
Validation loss: 2.3903137107310237

Epoch: 634| Step: 0
Training loss: 0.11438837498230264
Validation loss: 2.374692047395345

Epoch: 6| Step: 1
Training loss: 0.04960832970186273
Validation loss: 2.3935948776172706

Epoch: 6| Step: 2
Training loss: 0.1071969017320802
Validation loss: 2.379245538468994

Epoch: 6| Step: 3
Training loss: 0.0842307435998783
Validation loss: 2.3600395541824417

Epoch: 6| Step: 4
Training loss: 0.07705267262041145
Validation loss: 2.375861024244764

Epoch: 6| Step: 5
Training loss: 0.06852808297532746
Validation loss: 2.3921238795961517

Epoch: 6| Step: 6
Training loss: 0.07185814325509138
Validation loss: 2.393015988673597

Epoch: 6| Step: 7
Training loss: 0.09848095752028417
Validation loss: 2.3849685860870444

Epoch: 6| Step: 8
Training loss: 0.08283783394696001
Validation loss: 2.3887615540356935

Epoch: 6| Step: 9
Training loss: 0.046342884232799884
Validation loss: 2.3733157018247617

Epoch: 6| Step: 10
Training loss: 0.07102190542829288
Validation loss: 2.411866528357407

Epoch: 6| Step: 11
Training loss: 0.09914059752455646
Validation loss: 2.3997832665932033

Epoch: 6| Step: 12
Training loss: 0.044407821349288765
Validation loss: 2.384547261117044

Epoch: 6| Step: 13
Training loss: 0.07480217603247351
Validation loss: 2.4019836267909853

Epoch: 635| Step: 0
Training loss: 0.14636837498896046
Validation loss: 2.4106333472745387

Epoch: 6| Step: 1
Training loss: 0.10791419095052643
Validation loss: 2.4075477825581975

Epoch: 6| Step: 2
Training loss: 0.09127580594600582
Validation loss: 2.4234218097042195

Epoch: 6| Step: 3
Training loss: 0.08327875237360821
Validation loss: 2.411010176077016

Epoch: 6| Step: 4
Training loss: 0.08882792097888556
Validation loss: 2.3937176091894767

Epoch: 6| Step: 5
Training loss: 0.0761364279701286
Validation loss: 2.3743304780719647

Epoch: 6| Step: 6
Training loss: 0.0949187050592285
Validation loss: 2.3923786853525577

Epoch: 6| Step: 7
Training loss: 0.08802713283685369
Validation loss: 2.401035088789547

Epoch: 6| Step: 8
Training loss: 0.07756648095363568
Validation loss: 2.375780410222331

Epoch: 6| Step: 9
Training loss: 0.09575782886239512
Validation loss: 2.411376590991591

Epoch: 6| Step: 10
Training loss: 0.11013229917996668
Validation loss: 2.413584513869028

Epoch: 6| Step: 11
Training loss: 0.09304325119924432
Validation loss: 2.3897692533246073

Epoch: 6| Step: 12
Training loss: 0.05930324001352362
Validation loss: 2.394688423029175

Epoch: 6| Step: 13
Training loss: 0.07550587553943133
Validation loss: 2.3823864660024325

Epoch: 636| Step: 0
Training loss: 0.07332389406674232
Validation loss: 2.403444418620164

Epoch: 6| Step: 1
Training loss: 0.0709761486608253
Validation loss: 2.388497417038587

Epoch: 6| Step: 2
Training loss: 0.07194599786266906
Validation loss: 2.37956303004

Epoch: 6| Step: 3
Training loss: 0.08913556644586412
Validation loss: 2.36762022167011

Epoch: 6| Step: 4
Training loss: 0.08536256756312029
Validation loss: 2.3776594555700195

Epoch: 6| Step: 5
Training loss: 0.07467606158133323
Validation loss: 2.384771418745212

Epoch: 6| Step: 6
Training loss: 0.06765331346733247
Validation loss: 2.374245003867282

Epoch: 6| Step: 7
Training loss: 0.09237097730898255
Validation loss: 2.392695392131481

Epoch: 6| Step: 8
Training loss: 0.1113428808773101
Validation loss: 2.3712904899630556

Epoch: 6| Step: 9
Training loss: 0.06095250828251791
Validation loss: 2.3571908238804267

Epoch: 6| Step: 10
Training loss: 0.14489479351721857
Validation loss: 2.3688438363606945

Epoch: 6| Step: 11
Training loss: 0.06570839592568939
Validation loss: 2.3353650576292906

Epoch: 6| Step: 12
Training loss: 0.1130011235541002
Validation loss: 2.3734023733632323

Epoch: 6| Step: 13
Training loss: 0.13642606742026067
Validation loss: 2.330906544600266

Epoch: 637| Step: 0
Training loss: 0.08986992040201387
Validation loss: 2.3705459023717217

Epoch: 6| Step: 1
Training loss: 0.10554643701480823
Validation loss: 2.3788381040376687

Epoch: 6| Step: 2
Training loss: 0.1335813692278788
Validation loss: 2.380338709995633

Epoch: 6| Step: 3
Training loss: 0.05161861830140419
Validation loss: 2.3760574784463766

Epoch: 6| Step: 4
Training loss: 0.08840870223246304
Validation loss: 2.4169032897212563

Epoch: 6| Step: 5
Training loss: 0.1413796824055917
Validation loss: 2.409934387563149

Epoch: 6| Step: 6
Training loss: 0.05253028893868114
Validation loss: 2.426561253932327

Epoch: 6| Step: 7
Training loss: 0.1125189437413848
Validation loss: 2.4195950205682353

Epoch: 6| Step: 8
Training loss: 0.08324944724509449
Validation loss: 2.4124333627432293

Epoch: 6| Step: 9
Training loss: 0.12905530548132485
Validation loss: 2.390628175293022

Epoch: 6| Step: 10
Training loss: 0.0633752234025174
Validation loss: 2.406012510723761

Epoch: 6| Step: 11
Training loss: 0.1259586927766032
Validation loss: 2.420499380131311

Epoch: 6| Step: 12
Training loss: 0.08034059495120752
Validation loss: 2.3793643117271803

Epoch: 6| Step: 13
Training loss: 0.0945721134028499
Validation loss: 2.3924829945205452

Epoch: 638| Step: 0
Training loss: 0.0797017720475389
Validation loss: 2.383201450373714

Epoch: 6| Step: 1
Training loss: 0.10524075200640451
Validation loss: 2.3963484427480073

Epoch: 6| Step: 2
Training loss: 0.13713871622903182
Validation loss: 2.336456336689147

Epoch: 6| Step: 3
Training loss: 0.08874937779248762
Validation loss: 2.404929203566234

Epoch: 6| Step: 4
Training loss: 0.0804939695762846
Validation loss: 2.4067887106838146

Epoch: 6| Step: 5
Training loss: 0.08818577904174413
Validation loss: 2.3865794793772803

Epoch: 6| Step: 6
Training loss: 0.09538012610823747
Validation loss: 2.3879912423964553

Epoch: 6| Step: 7
Training loss: 0.04789149311579461
Validation loss: 2.40732667037517

Epoch: 6| Step: 8
Training loss: 0.10163574603610154
Validation loss: 2.4313686392200493

Epoch: 6| Step: 9
Training loss: 0.09688651474076591
Validation loss: 2.409668275152569

Epoch: 6| Step: 10
Training loss: 0.05628209671901206
Validation loss: 2.407164484197181

Epoch: 6| Step: 11
Training loss: 0.08887749916028803
Validation loss: 2.41781636034431

Epoch: 6| Step: 12
Training loss: 0.1039301830349616
Validation loss: 2.4116696883678594

Epoch: 6| Step: 13
Training loss: 0.06765638668033282
Validation loss: 2.4236792198811465

Epoch: 639| Step: 0
Training loss: 0.05957984066415512
Validation loss: 2.4269086282055703

Epoch: 6| Step: 1
Training loss: 0.08209411448883153
Validation loss: 2.433516095617091

Epoch: 6| Step: 2
Training loss: 0.08708738340233392
Validation loss: 2.3930750744844373

Epoch: 6| Step: 3
Training loss: 0.06380762551363861
Validation loss: 2.39843072222562

Epoch: 6| Step: 4
Training loss: 0.12193199332031839
Validation loss: 2.4093372413780663

Epoch: 6| Step: 5
Training loss: 0.0874904529438084
Validation loss: 2.3913329999154747

Epoch: 6| Step: 6
Training loss: 0.07558170043050394
Validation loss: 2.4148627011375043

Epoch: 6| Step: 7
Training loss: 0.04997902165591691
Validation loss: 2.4021343751900437

Epoch: 6| Step: 8
Training loss: 0.07760199784068716
Validation loss: 2.412577163275828

Epoch: 6| Step: 9
Training loss: 0.04721633492749744
Validation loss: 2.389947144068961

Epoch: 6| Step: 10
Training loss: 0.0993249703824911
Validation loss: 2.4174995712655036

Epoch: 6| Step: 11
Training loss: 0.11756572087655288
Validation loss: 2.4304934300824814

Epoch: 6| Step: 12
Training loss: 0.08022871918230728
Validation loss: 2.3981142554752446

Epoch: 6| Step: 13
Training loss: 0.07663977102898528
Validation loss: 2.404391492744855

Epoch: 640| Step: 0
Training loss: 0.08704129025880228
Validation loss: 2.4233170396444614

Epoch: 6| Step: 1
Training loss: 0.07556924487767398
Validation loss: 2.40091755575844

Epoch: 6| Step: 2
Training loss: 0.07526975513828617
Validation loss: 2.433371700378281

Epoch: 6| Step: 3
Training loss: 0.06129610355503386
Validation loss: 2.4031049654723033

Epoch: 6| Step: 4
Training loss: 0.09414348874940011
Validation loss: 2.4010278239905634

Epoch: 6| Step: 5
Training loss: 0.08881497159078439
Validation loss: 2.4076834788837354

Epoch: 6| Step: 6
Training loss: 0.04858238370932702
Validation loss: 2.403330578474391

Epoch: 6| Step: 7
Training loss: 0.0964781172263601
Validation loss: 2.361823654351093

Epoch: 6| Step: 8
Training loss: 0.11626219620741349
Validation loss: 2.3984999955002886

Epoch: 6| Step: 9
Training loss: 0.06344102818562157
Validation loss: 2.375294514363978

Epoch: 6| Step: 10
Training loss: 0.08289732311396
Validation loss: 2.3880686914451106

Epoch: 6| Step: 11
Training loss: 0.05470925775332794
Validation loss: 2.4054533299234206

Epoch: 6| Step: 12
Training loss: 0.12127306183025295
Validation loss: 2.3620732506189963

Epoch: 6| Step: 13
Training loss: 0.10923826662687916
Validation loss: 2.384872257972598

Epoch: 641| Step: 0
Training loss: 0.09767385324132544
Validation loss: 2.4101118179836494

Epoch: 6| Step: 1
Training loss: 0.09106952561065278
Validation loss: 2.4086380396597646

Epoch: 6| Step: 2
Training loss: 0.10325189048356047
Validation loss: 2.4129865020337298

Epoch: 6| Step: 3
Training loss: 0.0939706550090431
Validation loss: 2.4279323157920394

Epoch: 6| Step: 4
Training loss: 0.09547193005286697
Validation loss: 2.431344832808834

Epoch: 6| Step: 5
Training loss: 0.06467175970599488
Validation loss: 2.4178055525559974

Epoch: 6| Step: 6
Training loss: 0.0729060055256083
Validation loss: 2.4031227655551195

Epoch: 6| Step: 7
Training loss: 0.10015751049361434
Validation loss: 2.4081263551770262

Epoch: 6| Step: 8
Training loss: 0.11607816468331993
Validation loss: 2.415956896497724

Epoch: 6| Step: 9
Training loss: 0.08509686437925232
Validation loss: 2.4229083166767795

Epoch: 6| Step: 10
Training loss: 0.08108869666412795
Validation loss: 2.413095531933498

Epoch: 6| Step: 11
Training loss: 0.12817796972940437
Validation loss: 2.409476404726966

Epoch: 6| Step: 12
Training loss: 0.10966962913282124
Validation loss: 2.413767309845126

Epoch: 6| Step: 13
Training loss: 0.13736418551414906
Validation loss: 2.3817321081737926

Epoch: 642| Step: 0
Training loss: 0.07489512954645638
Validation loss: 2.3907015189913134

Epoch: 6| Step: 1
Training loss: 0.0838509875439283
Validation loss: 2.358041473510806

Epoch: 6| Step: 2
Training loss: 0.06199076253374595
Validation loss: 2.386326690202798

Epoch: 6| Step: 3
Training loss: 0.08590921294059092
Validation loss: 2.3695967586777806

Epoch: 6| Step: 4
Training loss: 0.10186056268815603
Validation loss: 2.385794428093828

Epoch: 6| Step: 5
Training loss: 0.08782126285825045
Validation loss: 2.390526082309198

Epoch: 6| Step: 6
Training loss: 0.1363276951627322
Validation loss: 2.3580850039507237

Epoch: 6| Step: 7
Training loss: 0.06111185595202668
Validation loss: 2.383323436326121

Epoch: 6| Step: 8
Training loss: 0.07382099329093224
Validation loss: 2.376251028841062

Epoch: 6| Step: 9
Training loss: 0.0770000104350696
Validation loss: 2.3622542878604254

Epoch: 6| Step: 10
Training loss: 0.11498859833608412
Validation loss: 2.390254638173697

Epoch: 6| Step: 11
Training loss: 0.1326896856966191
Validation loss: 2.3609399373569167

Epoch: 6| Step: 12
Training loss: 0.12136022412103863
Validation loss: 2.3604980308176144

Epoch: 6| Step: 13
Training loss: 0.06220739759759508
Validation loss: 2.4102286431327147

Epoch: 643| Step: 0
Training loss: 0.09426827027681169
Validation loss: 2.380424593265107

Epoch: 6| Step: 1
Training loss: 0.11550912995630443
Validation loss: 2.4194524477338537

Epoch: 6| Step: 2
Training loss: 0.05874132209271762
Validation loss: 2.4376026023639854

Epoch: 6| Step: 3
Training loss: 0.08379393987976273
Validation loss: 2.436549438624545

Epoch: 6| Step: 4
Training loss: 0.10116658620376832
Validation loss: 2.4400366475039346

Epoch: 6| Step: 5
Training loss: 0.08549491750239441
Validation loss: 2.4218190303478657

Epoch: 6| Step: 6
Training loss: 0.1180027499055284
Validation loss: 2.4212264267947083

Epoch: 6| Step: 7
Training loss: 0.08262674150168177
Validation loss: 2.413422429556145

Epoch: 6| Step: 8
Training loss: 0.07881541949354605
Validation loss: 2.3877304647977513

Epoch: 6| Step: 9
Training loss: 0.10225169012572057
Validation loss: 2.4042828299902372

Epoch: 6| Step: 10
Training loss: 0.1188496138913768
Validation loss: 2.3870907698278345

Epoch: 6| Step: 11
Training loss: 0.12195856319890104
Validation loss: 2.3870711227178947

Epoch: 6| Step: 12
Training loss: 0.06611608826103137
Validation loss: 2.3735146848736712

Epoch: 6| Step: 13
Training loss: 0.06769361549975501
Validation loss: 2.3763204162852434

Epoch: 644| Step: 0
Training loss: 0.09421732279106193
Validation loss: 2.3665775377035607

Epoch: 6| Step: 1
Training loss: 0.09481426976475267
Validation loss: 2.394500616063307

Epoch: 6| Step: 2
Training loss: 0.08195759384237085
Validation loss: 2.3781112688828183

Epoch: 6| Step: 3
Training loss: 0.10489151312970456
Validation loss: 2.390299946069715

Epoch: 6| Step: 4
Training loss: 0.06851122203672727
Validation loss: 2.394504997105355

Epoch: 6| Step: 5
Training loss: 0.11724738339400054
Validation loss: 2.392005056126

Epoch: 6| Step: 6
Training loss: 0.06223011045345005
Validation loss: 2.4135556975158354

Epoch: 6| Step: 7
Training loss: 0.08501207796618714
Validation loss: 2.4007795060523325

Epoch: 6| Step: 8
Training loss: 0.1076374232241953
Validation loss: 2.410260207814991

Epoch: 6| Step: 9
Training loss: 0.07109608724965127
Validation loss: 2.3961135397220756

Epoch: 6| Step: 10
Training loss: 0.07412862953005334
Validation loss: 2.4365400585972425

Epoch: 6| Step: 11
Training loss: 0.09403410223086235
Validation loss: 2.417128828670755

Epoch: 6| Step: 12
Training loss: 0.06977226752198412
Validation loss: 2.4378957571749242

Epoch: 6| Step: 13
Training loss: 0.07760447906371525
Validation loss: 2.4118946702768223

Epoch: 645| Step: 0
Training loss: 0.10229010104015851
Validation loss: 2.4035700574321957

Epoch: 6| Step: 1
Training loss: 0.044327223442363624
Validation loss: 2.389484549303308

Epoch: 6| Step: 2
Training loss: 0.09881960300598297
Validation loss: 2.4056123747161413

Epoch: 6| Step: 3
Training loss: 0.1000318543541911
Validation loss: 2.3774835934956067

Epoch: 6| Step: 4
Training loss: 0.0665888694514677
Validation loss: 2.409348281872452

Epoch: 6| Step: 5
Training loss: 0.11012558459512123
Validation loss: 2.3762362144377467

Epoch: 6| Step: 6
Training loss: 0.08842510786110606
Validation loss: 2.3936365514985543

Epoch: 6| Step: 7
Training loss: 0.05588856397955313
Validation loss: 2.4045817133810017

Epoch: 6| Step: 8
Training loss: 0.08031656076874578
Validation loss: 2.3953344520320856

Epoch: 6| Step: 9
Training loss: 0.1337607973410858
Validation loss: 2.4118279809628875

Epoch: 6| Step: 10
Training loss: 0.12790095756517536
Validation loss: 2.416026311341377

Epoch: 6| Step: 11
Training loss: 0.10501334097100605
Validation loss: 2.408075328302582

Epoch: 6| Step: 12
Training loss: 0.08763536898119972
Validation loss: 2.4145457129981693

Epoch: 6| Step: 13
Training loss: 0.04712784889274499
Validation loss: 2.3776245231328903

Epoch: 646| Step: 0
Training loss: 0.061050531358138496
Validation loss: 2.3859723514080664

Epoch: 6| Step: 1
Training loss: 0.09888367806630172
Validation loss: 2.3858979280577244

Epoch: 6| Step: 2
Training loss: 0.07844262228441534
Validation loss: 2.3738494789199454

Epoch: 6| Step: 3
Training loss: 0.08347334747121088
Validation loss: 2.4049331903813203

Epoch: 6| Step: 4
Training loss: 0.0984564800735117
Validation loss: 2.386755149760711

Epoch: 6| Step: 5
Training loss: 0.054536252680409486
Validation loss: 2.391225722319907

Epoch: 6| Step: 6
Training loss: 0.09432102188125434
Validation loss: 2.3794087775787944

Epoch: 6| Step: 7
Training loss: 0.04981028067279806
Validation loss: 2.384616943351321

Epoch: 6| Step: 8
Training loss: 0.08767591848211836
Validation loss: 2.4044209515053865

Epoch: 6| Step: 9
Training loss: 0.05452522614484968
Validation loss: 2.411484862338702

Epoch: 6| Step: 10
Training loss: 0.049478302914625974
Validation loss: 2.4063219651774146

Epoch: 6| Step: 11
Training loss: 0.06238242355254092
Validation loss: 2.41404574431852

Epoch: 6| Step: 12
Training loss: 0.09418787621205912
Validation loss: 2.4245544452219083

Epoch: 6| Step: 13
Training loss: 0.057272886545088525
Validation loss: 2.424408897640867

Epoch: 647| Step: 0
Training loss: 0.12538628942059063
Validation loss: 2.421798923976682

Epoch: 6| Step: 1
Training loss: 0.06938825903198013
Validation loss: 2.4082903831096174

Epoch: 6| Step: 2
Training loss: 0.12581694641395272
Validation loss: 2.3998964412540973

Epoch: 6| Step: 3
Training loss: 0.1071223548200362
Validation loss: 2.398790952401349

Epoch: 6| Step: 4
Training loss: 0.08530395694723439
Validation loss: 2.3982814112599486

Epoch: 6| Step: 5
Training loss: 0.08618233223872629
Validation loss: 2.378018336747108

Epoch: 6| Step: 6
Training loss: 0.08728247419663811
Validation loss: 2.3782263523301848

Epoch: 6| Step: 7
Training loss: 0.07104466297325336
Validation loss: 2.3748705709408764

Epoch: 6| Step: 8
Training loss: 0.08166201689962785
Validation loss: 2.3722408396188612

Epoch: 6| Step: 9
Training loss: 0.06970425283592306
Validation loss: 2.3589661337719745

Epoch: 6| Step: 10
Training loss: 0.07974383604416674
Validation loss: 2.362501615727854

Epoch: 6| Step: 11
Training loss: 0.1015346470567155
Validation loss: 2.397777479785747

Epoch: 6| Step: 12
Training loss: 0.07946171422497553
Validation loss: 2.3574009170618093

Epoch: 6| Step: 13
Training loss: 0.09870173152086678
Validation loss: 2.37969798897098

Epoch: 648| Step: 0
Training loss: 0.07114168178331434
Validation loss: 2.395431958605088

Epoch: 6| Step: 1
Training loss: 0.08908547326823152
Validation loss: 2.4104106098269513

Epoch: 6| Step: 2
Training loss: 0.1181888002715458
Validation loss: 2.3967399568858574

Epoch: 6| Step: 3
Training loss: 0.08376261631661254
Validation loss: 2.3944460070719256

Epoch: 6| Step: 4
Training loss: 0.05037363767763686
Validation loss: 2.4033331673618816

Epoch: 6| Step: 5
Training loss: 0.07021888156258041
Validation loss: 2.40075698153174

Epoch: 6| Step: 6
Training loss: 0.06548778602010104
Validation loss: 2.385013697193116

Epoch: 6| Step: 7
Training loss: 0.09229056529183739
Validation loss: 2.3878534132433744

Epoch: 6| Step: 8
Training loss: 0.08142426410907777
Validation loss: 2.4005745762261026

Epoch: 6| Step: 9
Training loss: 0.04102600908528338
Validation loss: 2.4155592525705063

Epoch: 6| Step: 10
Training loss: 0.0881657479902133
Validation loss: 2.3997022965417463

Epoch: 6| Step: 11
Training loss: 0.0969216661188094
Validation loss: 2.3920023295826436

Epoch: 6| Step: 12
Training loss: 0.047071400606075425
Validation loss: 2.396248510125967

Epoch: 6| Step: 13
Training loss: 0.11505426053882131
Validation loss: 2.4170587735716453

Epoch: 649| Step: 0
Training loss: 0.06143527298749377
Validation loss: 2.40526434585345

Epoch: 6| Step: 1
Training loss: 0.09194499605396486
Validation loss: 2.4171785407278774

Epoch: 6| Step: 2
Training loss: 0.06356423998451337
Validation loss: 2.423446502143074

Epoch: 6| Step: 3
Training loss: 0.05383066790765514
Validation loss: 2.3820684531789693

Epoch: 6| Step: 4
Training loss: 0.09369716049282904
Validation loss: 2.418455444912339

Epoch: 6| Step: 5
Training loss: 0.07655532618409117
Validation loss: 2.3746084873916207

Epoch: 6| Step: 6
Training loss: 0.14768226384289496
Validation loss: 2.398191059311952

Epoch: 6| Step: 7
Training loss: 0.1030482817793138
Validation loss: 2.417336316694099

Epoch: 6| Step: 8
Training loss: 0.12149259809280276
Validation loss: 2.3976020481575984

Epoch: 6| Step: 9
Training loss: 0.08373435920146431
Validation loss: 2.3591167697359103

Epoch: 6| Step: 10
Training loss: 0.13426246560640306
Validation loss: 2.405147706465667

Epoch: 6| Step: 11
Training loss: 0.095090579593997
Validation loss: 2.3722689599076983

Epoch: 6| Step: 12
Training loss: 0.10382426781446705
Validation loss: 2.3805044943190943

Epoch: 6| Step: 13
Training loss: 0.18614081638735894
Validation loss: 2.3724711241760166

Epoch: 650| Step: 0
Training loss: 0.07969298437356723
Validation loss: 2.370928449204347

Epoch: 6| Step: 1
Training loss: 0.0887175074974385
Validation loss: 2.4035636610414186

Epoch: 6| Step: 2
Training loss: 0.07752468614842245
Validation loss: 2.4084672667143208

Epoch: 6| Step: 3
Training loss: 0.09017955179740467
Validation loss: 2.3987433061644894

Epoch: 6| Step: 4
Training loss: 0.10171469875184573
Validation loss: 2.391671231879217

Epoch: 6| Step: 5
Training loss: 0.13092889647111428
Validation loss: 2.3738956528471338

Epoch: 6| Step: 6
Training loss: 0.14164265661155523
Validation loss: 2.372824103373275

Epoch: 6| Step: 7
Training loss: 0.1530765551694607
Validation loss: 2.395257375717925

Epoch: 6| Step: 8
Training loss: 0.098383721163175
Validation loss: 2.387615384727904

Epoch: 6| Step: 9
Training loss: 0.13021543403973465
Validation loss: 2.398850894131292

Epoch: 6| Step: 10
Training loss: 0.17037906745706935
Validation loss: 2.3893466271094126

Epoch: 6| Step: 11
Training loss: 0.08889625933146286
Validation loss: 2.364405879917517

Epoch: 6| Step: 12
Training loss: 0.11635723842361466
Validation loss: 2.354521494253392

Epoch: 6| Step: 13
Training loss: 0.22886808226905792
Validation loss: 2.3434557045645166

Epoch: 651| Step: 0
Training loss: 0.13424952132079315
Validation loss: 2.336706584934506

Epoch: 6| Step: 1
Training loss: 0.2112286289397743
Validation loss: 2.339215733420317

Epoch: 6| Step: 2
Training loss: 0.13729087467090584
Validation loss: 2.358623395516912

Epoch: 6| Step: 3
Training loss: 0.0988396326911668
Validation loss: 2.3748761022230775

Epoch: 6| Step: 4
Training loss: 0.14309233212481873
Validation loss: 2.4004676486287324

Epoch: 6| Step: 5
Training loss: 0.21241525194253943
Validation loss: 2.4093505993483695

Epoch: 6| Step: 6
Training loss: 0.1918829606234526
Validation loss: 2.4249298655588003

Epoch: 6| Step: 7
Training loss: 0.2010279575839095
Validation loss: 2.394232602455668

Epoch: 6| Step: 8
Training loss: 0.1905209835991146
Validation loss: 2.4030708469892956

Epoch: 6| Step: 9
Training loss: 0.09245424573572644
Validation loss: 2.411429404219399

Epoch: 6| Step: 10
Training loss: 0.14563199958637826
Validation loss: 2.393623692757688

Epoch: 6| Step: 11
Training loss: 0.12045503029211471
Validation loss: 2.390578957241034

Epoch: 6| Step: 12
Training loss: 0.13857608495508122
Validation loss: 2.3682259664002387

Epoch: 6| Step: 13
Training loss: 0.23247275877382034
Validation loss: 2.382321623711629

Epoch: 652| Step: 0
Training loss: 0.06591347573120782
Validation loss: 2.412107477332256

Epoch: 6| Step: 1
Training loss: 0.1760099353962808
Validation loss: 2.42149249551739

Epoch: 6| Step: 2
Training loss: 0.13062239297519398
Validation loss: 2.451058691039648

Epoch: 6| Step: 3
Training loss: 0.21829085187607622
Validation loss: 2.454713851214842

Epoch: 6| Step: 4
Training loss: 0.07553431648165958
Validation loss: 2.466386306542105

Epoch: 6| Step: 5
Training loss: 0.10439377455263157
Validation loss: 2.466733135388207

Epoch: 6| Step: 6
Training loss: 0.11747874784279382
Validation loss: 2.4437620658818973

Epoch: 6| Step: 7
Training loss: 0.09402294460717375
Validation loss: 2.425439099316823

Epoch: 6| Step: 8
Training loss: 0.08752822335651154
Validation loss: 2.444638787403112

Epoch: 6| Step: 9
Training loss: 0.09648401032506312
Validation loss: 2.423935027903075

Epoch: 6| Step: 10
Training loss: 0.09694017133161764
Validation loss: 2.427567803114483

Epoch: 6| Step: 11
Training loss: 0.10758421508737731
Validation loss: 2.3989048102711164

Epoch: 6| Step: 12
Training loss: 0.10801761334395138
Validation loss: 2.4061900854408997

Epoch: 6| Step: 13
Training loss: 0.06547873708188287
Validation loss: 2.41548916203252

Epoch: 653| Step: 0
Training loss: 0.13176512052443284
Validation loss: 2.4048303071168347

Epoch: 6| Step: 1
Training loss: 0.10643677721013343
Validation loss: 2.4037545652334815

Epoch: 6| Step: 2
Training loss: 0.14201794932399547
Validation loss: 2.3913680258417833

Epoch: 6| Step: 3
Training loss: 0.17480618993017594
Validation loss: 2.398453946792218

Epoch: 6| Step: 4
Training loss: 0.0876286204205068
Validation loss: 2.412303561595763

Epoch: 6| Step: 5
Training loss: 0.07480581770757742
Validation loss: 2.404147684696241

Epoch: 6| Step: 6
Training loss: 0.10791408307279599
Validation loss: 2.4153764043439723

Epoch: 6| Step: 7
Training loss: 0.13394608297985816
Validation loss: 2.433364957749197

Epoch: 6| Step: 8
Training loss: 0.07604892601619986
Validation loss: 2.427064976804768

Epoch: 6| Step: 9
Training loss: 0.10475184363481663
Validation loss: 2.416438371641039

Epoch: 6| Step: 10
Training loss: 0.09347599439053794
Validation loss: 2.4197281874803602

Epoch: 6| Step: 11
Training loss: 0.08871811635723964
Validation loss: 2.447383891932244

Epoch: 6| Step: 12
Training loss: 0.18562538092346154
Validation loss: 2.4413129833495613

Epoch: 6| Step: 13
Training loss: 0.10407532223471304
Validation loss: 2.4394259420640156

Epoch: 654| Step: 0
Training loss: 0.12548699730835974
Validation loss: 2.4368238812921397

Epoch: 6| Step: 1
Training loss: 0.11935381107742897
Validation loss: 2.4302285335262046

Epoch: 6| Step: 2
Training loss: 0.1669663637952094
Validation loss: 2.4015263299680587

Epoch: 6| Step: 3
Training loss: 0.06472860333086337
Validation loss: 2.416338004683202

Epoch: 6| Step: 4
Training loss: 0.12420207397519173
Validation loss: 2.423905385361256

Epoch: 6| Step: 5
Training loss: 0.1163983156713228
Validation loss: 2.4126996477954212

Epoch: 6| Step: 6
Training loss: 0.0697946352410372
Validation loss: 2.382068731921121

Epoch: 6| Step: 7
Training loss: 0.1219797714149454
Validation loss: 2.4039655563952533

Epoch: 6| Step: 8
Training loss: 0.12724944525262388
Validation loss: 2.371415155604137

Epoch: 6| Step: 9
Training loss: 0.12612368989279152
Validation loss: 2.370292392330447

Epoch: 6| Step: 10
Training loss: 0.14860220605273564
Validation loss: 2.376850193859531

Epoch: 6| Step: 11
Training loss: 0.129395992342779
Validation loss: 2.388206931384954

Epoch: 6| Step: 12
Training loss: 0.08913959420667163
Validation loss: 2.405157368273049

Epoch: 6| Step: 13
Training loss: 0.08413334597622929
Validation loss: 2.394892927102534

Epoch: 655| Step: 0
Training loss: 0.11618169448670447
Validation loss: 2.4355501380374425

Epoch: 6| Step: 1
Training loss: 0.15191813460777936
Validation loss: 2.444758449725705

Epoch: 6| Step: 2
Training loss: 0.1430097865010375
Validation loss: 2.4352047307361815

Epoch: 6| Step: 3
Training loss: 0.13411812098630393
Validation loss: 2.4553058331459097

Epoch: 6| Step: 4
Training loss: 0.10587243249464294
Validation loss: 2.4384278791826675

Epoch: 6| Step: 5
Training loss: 0.13887009758455313
Validation loss: 2.4062118537903876

Epoch: 6| Step: 6
Training loss: 0.0617814670372249
Validation loss: 2.433752411583713

Epoch: 6| Step: 7
Training loss: 0.09189676369236677
Validation loss: 2.4252498325273795

Epoch: 6| Step: 8
Training loss: 0.16385272784085378
Validation loss: 2.436163155742627

Epoch: 6| Step: 9
Training loss: 0.1054281801325884
Validation loss: 2.4624714243140584

Epoch: 6| Step: 10
Training loss: 0.09138129394924943
Validation loss: 2.4410853136669983

Epoch: 6| Step: 11
Training loss: 0.120760632521945
Validation loss: 2.440826113448508

Epoch: 6| Step: 12
Training loss: 0.11809264144770842
Validation loss: 2.466399933456833

Epoch: 6| Step: 13
Training loss: 0.11895548005016983
Validation loss: 2.456276876262936

Epoch: 656| Step: 0
Training loss: 0.1346795595089793
Validation loss: 2.436992269496366

Epoch: 6| Step: 1
Training loss: 0.10423334540663624
Validation loss: 2.4483970266779553

Epoch: 6| Step: 2
Training loss: 0.08732937585341302
Validation loss: 2.4252434697956184

Epoch: 6| Step: 3
Training loss: 0.08085251205455127
Validation loss: 2.420243849823697

Epoch: 6| Step: 4
Training loss: 0.09220826008177248
Validation loss: 2.4528575427711763

Epoch: 6| Step: 5
Training loss: 0.10522591928609332
Validation loss: 2.3918467565950174

Epoch: 6| Step: 6
Training loss: 0.18336432914721326
Validation loss: 2.404739587698853

Epoch: 6| Step: 7
Training loss: 0.10711107375107676
Validation loss: 2.4163101808180723

Epoch: 6| Step: 8
Training loss: 0.09603057525334407
Validation loss: 2.4116985532997197

Epoch: 6| Step: 9
Training loss: 0.08628031779161803
Validation loss: 2.3968631993786853

Epoch: 6| Step: 10
Training loss: 0.12853469185425737
Validation loss: 2.3736935321424304

Epoch: 6| Step: 11
Training loss: 0.1029393602346731
Validation loss: 2.3789924511534735

Epoch: 6| Step: 12
Training loss: 0.13804804485712646
Validation loss: 2.3873262755487383

Epoch: 6| Step: 13
Training loss: 0.086998748240701
Validation loss: 2.3784083449109508

Epoch: 657| Step: 0
Training loss: 0.11012382977152918
Validation loss: 2.3939513722997754

Epoch: 6| Step: 1
Training loss: 0.2157704653934918
Validation loss: 2.385733352390974

Epoch: 6| Step: 2
Training loss: 0.04690657486031132
Validation loss: 2.3951076298399663

Epoch: 6| Step: 3
Training loss: 0.047759366259642416
Validation loss: 2.3870526627285678

Epoch: 6| Step: 4
Training loss: 0.06848761926791352
Validation loss: 2.413449445426453

Epoch: 6| Step: 5
Training loss: 0.0962698853529371
Validation loss: 2.4024839021378757

Epoch: 6| Step: 6
Training loss: 0.13044053989079626
Validation loss: 2.4263799913042576

Epoch: 6| Step: 7
Training loss: 0.10730658326420237
Validation loss: 2.4193027985694546

Epoch: 6| Step: 8
Training loss: 0.06959619502747305
Validation loss: 2.432003884219356

Epoch: 6| Step: 9
Training loss: 0.12464312183135953
Validation loss: 2.413014128365573

Epoch: 6| Step: 10
Training loss: 0.07047025216377169
Validation loss: 2.4357067502737437

Epoch: 6| Step: 11
Training loss: 0.09156720364990999
Validation loss: 2.4409918236547297

Epoch: 6| Step: 12
Training loss: 0.0682146652416818
Validation loss: 2.42349752378247

Epoch: 6| Step: 13
Training loss: 0.07158921688386317
Validation loss: 2.405069814753447

Epoch: 658| Step: 0
Training loss: 0.10647541460441072
Validation loss: 2.4119752379388317

Epoch: 6| Step: 1
Training loss: 0.06235607719984827
Validation loss: 2.426969516463284

Epoch: 6| Step: 2
Training loss: 0.11121845699624344
Validation loss: 2.425662830525761

Epoch: 6| Step: 3
Training loss: 0.10524316787801133
Validation loss: 2.426682296280807

Epoch: 6| Step: 4
Training loss: 0.1312768241741961
Validation loss: 2.416302807572733

Epoch: 6| Step: 5
Training loss: 0.09892283187642022
Validation loss: 2.4344833434372593

Epoch: 6| Step: 6
Training loss: 0.08349268053005081
Validation loss: 2.4153191436180785

Epoch: 6| Step: 7
Training loss: 0.0896527135573025
Validation loss: 2.41942812883807

Epoch: 6| Step: 8
Training loss: 0.10540517020895292
Validation loss: 2.431038575195851

Epoch: 6| Step: 9
Training loss: 0.06555012393669819
Validation loss: 2.402544686469318

Epoch: 6| Step: 10
Training loss: 0.10086251169020977
Validation loss: 2.39375441900018

Epoch: 6| Step: 11
Training loss: 0.10603816358567077
Validation loss: 2.3960664618779357

Epoch: 6| Step: 12
Training loss: 0.10117624266044886
Validation loss: 2.4137881543538984

Epoch: 6| Step: 13
Training loss: 0.15224093856060408
Validation loss: 2.3932348990383714

Epoch: 659| Step: 0
Training loss: 0.09009614508631113
Validation loss: 2.423056499990323

Epoch: 6| Step: 1
Training loss: 0.10627920857224024
Validation loss: 2.3987342603048525

Epoch: 6| Step: 2
Training loss: 0.12852748943627024
Validation loss: 2.401251205438311

Epoch: 6| Step: 3
Training loss: 0.0733353975373064
Validation loss: 2.3966805934619746

Epoch: 6| Step: 4
Training loss: 0.09321102542120087
Validation loss: 2.392890827436794

Epoch: 6| Step: 5
Training loss: 0.09006385172359664
Validation loss: 2.409330982663618

Epoch: 6| Step: 6
Training loss: 0.07450557173425094
Validation loss: 2.3790109850010763

Epoch: 6| Step: 7
Training loss: 0.09882044649262083
Validation loss: 2.393061769216438

Epoch: 6| Step: 8
Training loss: 0.07920961593980023
Validation loss: 2.4017779692738874

Epoch: 6| Step: 9
Training loss: 0.1185320413066741
Validation loss: 2.3854304233241583

Epoch: 6| Step: 10
Training loss: 0.10012707161754524
Validation loss: 2.396297763646261

Epoch: 6| Step: 11
Training loss: 0.1413061414609974
Validation loss: 2.4259843570025095

Epoch: 6| Step: 12
Training loss: 0.09797029068905028
Validation loss: 2.42421477125555

Epoch: 6| Step: 13
Training loss: 0.07010226143956502
Validation loss: 2.4207204680762344

Epoch: 660| Step: 0
Training loss: 0.08777860018949786
Validation loss: 2.4359095201200454

Epoch: 6| Step: 1
Training loss: 0.13006452168539084
Validation loss: 2.424737808757453

Epoch: 6| Step: 2
Training loss: 0.08522345555130809
Validation loss: 2.43226040827551

Epoch: 6| Step: 3
Training loss: 0.10802219581373172
Validation loss: 2.4369697288495926

Epoch: 6| Step: 4
Training loss: 0.08646551932016479
Validation loss: 2.415240511593098

Epoch: 6| Step: 5
Training loss: 0.06443224554278916
Validation loss: 2.405658720126907

Epoch: 6| Step: 6
Training loss: 0.10600543344940126
Validation loss: 2.413979693219565

Epoch: 6| Step: 7
Training loss: 0.10873647768120216
Validation loss: 2.4012229003442984

Epoch: 6| Step: 8
Training loss: 0.12407991670199521
Validation loss: 2.400281330936202

Epoch: 6| Step: 9
Training loss: 0.07826118222960231
Validation loss: 2.402886422451173

Epoch: 6| Step: 10
Training loss: 0.07056773405412228
Validation loss: 2.4151832598522573

Epoch: 6| Step: 11
Training loss: 0.07320494022581832
Validation loss: 2.400035891384161

Epoch: 6| Step: 12
Training loss: 0.058374764594490716
Validation loss: 2.3924551546842614

Epoch: 6| Step: 13
Training loss: 0.13664993870543965
Validation loss: 2.405468462629772

Epoch: 661| Step: 0
Training loss: 0.10778004150785966
Validation loss: 2.3920711449143655

Epoch: 6| Step: 1
Training loss: 0.13398857276946846
Validation loss: 2.415262254097895

Epoch: 6| Step: 2
Training loss: 0.08422274362440926
Validation loss: 2.3867378156898846

Epoch: 6| Step: 3
Training loss: 0.053897680416891636
Validation loss: 2.3565499992203365

Epoch: 6| Step: 4
Training loss: 0.09304733000803404
Validation loss: 2.346522270460427

Epoch: 6| Step: 5
Training loss: 0.12629855206721244
Validation loss: 2.3814703443024396

Epoch: 6| Step: 6
Training loss: 0.09157452641849442
Validation loss: 2.365426890945784

Epoch: 6| Step: 7
Training loss: 0.11562996383270457
Validation loss: 2.3875614004814443

Epoch: 6| Step: 8
Training loss: 0.0732811760444512
Validation loss: 2.3798469862813447

Epoch: 6| Step: 9
Training loss: 0.12870087302051897
Validation loss: 2.367248366510266

Epoch: 6| Step: 10
Training loss: 0.05930158121169875
Validation loss: 2.3693799079095905

Epoch: 6| Step: 11
Training loss: 0.06529226390014285
Validation loss: 2.368387101426653

Epoch: 6| Step: 12
Training loss: 0.09929740896614143
Validation loss: 2.3793452537557127

Epoch: 6| Step: 13
Training loss: 0.06932928832502924
Validation loss: 2.382259913372075

Epoch: 662| Step: 0
Training loss: 0.13136986186707952
Validation loss: 2.3724278676950523

Epoch: 6| Step: 1
Training loss: 0.08667824396286927
Validation loss: 2.344076620334078

Epoch: 6| Step: 2
Training loss: 0.08129708113525991
Validation loss: 2.369708237142339

Epoch: 6| Step: 3
Training loss: 0.08610068887797463
Validation loss: 2.389844673088791

Epoch: 6| Step: 4
Training loss: 0.11474899126006322
Validation loss: 2.389899125213716

Epoch: 6| Step: 5
Training loss: 0.06860649536829494
Validation loss: 2.398549247677823

Epoch: 6| Step: 6
Training loss: 0.04034581808901238
Validation loss: 2.3893698723780425

Epoch: 6| Step: 7
Training loss: 0.09883907675844086
Validation loss: 2.4106926521146166

Epoch: 6| Step: 8
Training loss: 0.09818670685634147
Validation loss: 2.4172497595035516

Epoch: 6| Step: 9
Training loss: 0.0883024422350759
Validation loss: 2.406904167084437

Epoch: 6| Step: 10
Training loss: 0.08101644533049195
Validation loss: 2.417982416526668

Epoch: 6| Step: 11
Training loss: 0.08396865453633034
Validation loss: 2.4011713562869024

Epoch: 6| Step: 12
Training loss: 0.08087328639123852
Validation loss: 2.437583652656403

Epoch: 6| Step: 13
Training loss: 0.06865554411416291
Validation loss: 2.416898275725907

Epoch: 663| Step: 0
Training loss: 0.07193054665070726
Validation loss: 2.41733171508065

Epoch: 6| Step: 1
Training loss: 0.11924896629753175
Validation loss: 2.4066661213352183

Epoch: 6| Step: 2
Training loss: 0.13266548266144068
Validation loss: 2.420435020281682

Epoch: 6| Step: 3
Training loss: 0.11557958909701326
Validation loss: 2.4149920255702213

Epoch: 6| Step: 4
Training loss: 0.09894933994317867
Validation loss: 2.42343812026145

Epoch: 6| Step: 5
Training loss: 0.09509758208705402
Validation loss: 2.43681923652307

Epoch: 6| Step: 6
Training loss: 0.07024651650004213
Validation loss: 2.416135123427678

Epoch: 6| Step: 7
Training loss: 0.08153570165631298
Validation loss: 2.402906052806048

Epoch: 6| Step: 8
Training loss: 0.08961637896110773
Validation loss: 2.4036228406054363

Epoch: 6| Step: 9
Training loss: 0.1224479936150304
Validation loss: 2.417687002483785

Epoch: 6| Step: 10
Training loss: 0.06539091698092557
Validation loss: 2.4269218334758564

Epoch: 6| Step: 11
Training loss: 0.09165127346810656
Validation loss: 2.4128348341798906

Epoch: 6| Step: 12
Training loss: 0.08902938419514589
Validation loss: 2.3962131928521884

Epoch: 6| Step: 13
Training loss: 0.06045800270019297
Validation loss: 2.381469690869957

Epoch: 664| Step: 0
Training loss: 0.1147236984799438
Validation loss: 2.40996816022228

Epoch: 6| Step: 1
Training loss: 0.07337695756060462
Validation loss: 2.4159476683763956

Epoch: 6| Step: 2
Training loss: 0.06322216996555965
Validation loss: 2.421473808548658

Epoch: 6| Step: 3
Training loss: 0.0971574250448046
Validation loss: 2.4335470106048147

Epoch: 6| Step: 4
Training loss: 0.12597648857173674
Validation loss: 2.4307935581982316

Epoch: 6| Step: 5
Training loss: 0.06221991230474401
Validation loss: 2.420424847507771

Epoch: 6| Step: 6
Training loss: 0.08531179276285007
Validation loss: 2.4410925411688953

Epoch: 6| Step: 7
Training loss: 0.10232530292942167
Validation loss: 2.4285888720367046

Epoch: 6| Step: 8
Training loss: 0.11132395050520871
Validation loss: 2.4147394393162824

Epoch: 6| Step: 9
Training loss: 0.0709969860267451
Validation loss: 2.422577626974025

Epoch: 6| Step: 10
Training loss: 0.08957136368997698
Validation loss: 2.4078751014365825

Epoch: 6| Step: 11
Training loss: 0.09800346637027897
Validation loss: 2.3890787290502913

Epoch: 6| Step: 12
Training loss: 0.07320072271910069
Validation loss: 2.373046412624684

Epoch: 6| Step: 13
Training loss: 0.0871020972628699
Validation loss: 2.3733610878888878

Epoch: 665| Step: 0
Training loss: 0.08100812217858495
Validation loss: 2.3971882381440186

Epoch: 6| Step: 1
Training loss: 0.08301797131475681
Validation loss: 2.3887089222084406

Epoch: 6| Step: 2
Training loss: 0.10550077711486933
Validation loss: 2.392796317408723

Epoch: 6| Step: 3
Training loss: 0.08753081688012798
Validation loss: 2.3822151628253803

Epoch: 6| Step: 4
Training loss: 0.09820309120790663
Validation loss: 2.3913851548252483

Epoch: 6| Step: 5
Training loss: 0.1000775759024524
Validation loss: 2.3901617244841256

Epoch: 6| Step: 6
Training loss: 0.055236173594406905
Validation loss: 2.3912664522438996

Epoch: 6| Step: 7
Training loss: 0.07159250489825222
Validation loss: 2.403198569250049

Epoch: 6| Step: 8
Training loss: 0.045253696906272775
Validation loss: 2.412805766619959

Epoch: 6| Step: 9
Training loss: 0.09397984185388873
Validation loss: 2.4131270275101127

Epoch: 6| Step: 10
Training loss: 0.09788636275934992
Validation loss: 2.412049690482316

Epoch: 6| Step: 11
Training loss: 0.12797405842074935
Validation loss: 2.4018396408399783

Epoch: 6| Step: 12
Training loss: 0.11843817420052953
Validation loss: 2.4402867329877425

Epoch: 6| Step: 13
Training loss: 0.14292726488085425
Validation loss: 2.44712987825989

Epoch: 666| Step: 0
Training loss: 0.062201809327087326
Validation loss: 2.407630414715661

Epoch: 6| Step: 1
Training loss: 0.10552118022512723
Validation loss: 2.397730372598673

Epoch: 6| Step: 2
Training loss: 0.08332036583063106
Validation loss: 2.3786051782758055

Epoch: 6| Step: 3
Training loss: 0.0660805991912215
Validation loss: 2.3848720935038177

Epoch: 6| Step: 4
Training loss: 0.09084039896678679
Validation loss: 2.3525966411342543

Epoch: 6| Step: 5
Training loss: 0.12453496753332169
Validation loss: 2.3466117216479137

Epoch: 6| Step: 6
Training loss: 0.18318773583234627
Validation loss: 2.35963746797484

Epoch: 6| Step: 7
Training loss: 0.11301255422877143
Validation loss: 2.361479514063963

Epoch: 6| Step: 8
Training loss: 0.1302967716920651
Validation loss: 2.403208634127356

Epoch: 6| Step: 9
Training loss: 0.06953204320605168
Validation loss: 2.4063343080736845

Epoch: 6| Step: 10
Training loss: 0.08888879974316474
Validation loss: 2.4197393956365536

Epoch: 6| Step: 11
Training loss: 0.12315774645521736
Validation loss: 2.4075146470674116

Epoch: 6| Step: 12
Training loss: 0.23363348166875864
Validation loss: 2.415429727661865

Epoch: 6| Step: 13
Training loss: 0.07881407830913967
Validation loss: 2.3811303839455293

Epoch: 667| Step: 0
Training loss: 0.153805856831738
Validation loss: 2.3474610010160037

Epoch: 6| Step: 1
Training loss: 0.1637698697272609
Validation loss: 2.366432401174283

Epoch: 6| Step: 2
Training loss: 0.1302251034109716
Validation loss: 2.32355090506422

Epoch: 6| Step: 3
Training loss: 0.09385248880319016
Validation loss: 2.355064707758121

Epoch: 6| Step: 4
Training loss: 0.1040945419320336
Validation loss: 2.352062369128329

Epoch: 6| Step: 5
Training loss: 0.08218140710068196
Validation loss: 2.360108141915542

Epoch: 6| Step: 6
Training loss: 0.13798545137974125
Validation loss: 2.348216352979711

Epoch: 6| Step: 7
Training loss: 0.12704566370562898
Validation loss: 2.3504998419732988

Epoch: 6| Step: 8
Training loss: 0.11619413078013437
Validation loss: 2.3588263999754115

Epoch: 6| Step: 9
Training loss: 0.12446243956503952
Validation loss: 2.3721270225841575

Epoch: 6| Step: 10
Training loss: 0.1291211821729328
Validation loss: 2.3763611740517248

Epoch: 6| Step: 11
Training loss: 0.04554566295051457
Validation loss: 2.3721674914407824

Epoch: 6| Step: 12
Training loss: 0.11199967802695418
Validation loss: 2.391716353229152

Epoch: 6| Step: 13
Training loss: 0.13405615882726377
Validation loss: 2.3733051925971247

Epoch: 668| Step: 0
Training loss: 0.054716438913204185
Validation loss: 2.37839645370049

Epoch: 6| Step: 1
Training loss: 0.08024269441134933
Validation loss: 2.3619210453975117

Epoch: 6| Step: 2
Training loss: 0.09038729137283946
Validation loss: 2.347518562233809

Epoch: 6| Step: 3
Training loss: 0.04594661335173034
Validation loss: 2.35818619154016

Epoch: 6| Step: 4
Training loss: 0.07168632042674315
Validation loss: 2.337662263706298

Epoch: 6| Step: 5
Training loss: 0.06538870225264908
Validation loss: 2.3546779246932767

Epoch: 6| Step: 6
Training loss: 0.1519653437980079
Validation loss: 2.3476278032275375

Epoch: 6| Step: 7
Training loss: 0.13253883609139655
Validation loss: 2.3851411686071597

Epoch: 6| Step: 8
Training loss: 0.08669081422683307
Validation loss: 2.3534143654075774

Epoch: 6| Step: 9
Training loss: 0.09132292323966205
Validation loss: 2.366482048843991

Epoch: 6| Step: 10
Training loss: 0.118324926921726
Validation loss: 2.3583894727787857

Epoch: 6| Step: 11
Training loss: 0.12682164793404732
Validation loss: 2.3654376856327417

Epoch: 6| Step: 12
Training loss: 0.07500575684268566
Validation loss: 2.3611725531571586

Epoch: 6| Step: 13
Training loss: 0.0952119729024959
Validation loss: 2.3590990924004784

Epoch: 669| Step: 0
Training loss: 0.16279207811758423
Validation loss: 2.3633342094592744

Epoch: 6| Step: 1
Training loss: 0.13610772787023015
Validation loss: 2.384239965860058

Epoch: 6| Step: 2
Training loss: 0.11707172237663563
Validation loss: 2.3795182233873238

Epoch: 6| Step: 3
Training loss: 0.1556945703877259
Validation loss: 2.361746389696447

Epoch: 6| Step: 4
Training loss: 0.0974577985422423
Validation loss: 2.3917157728043157

Epoch: 6| Step: 5
Training loss: 0.07837925902077408
Validation loss: 2.3904210903864054

Epoch: 6| Step: 6
Training loss: 0.10360233256228807
Validation loss: 2.4020929298486315

Epoch: 6| Step: 7
Training loss: 0.09283319857373265
Validation loss: 2.394672876409498

Epoch: 6| Step: 8
Training loss: 0.08676651957761912
Validation loss: 2.409211818192949

Epoch: 6| Step: 9
Training loss: 0.07479934972139984
Validation loss: 2.374789504981517

Epoch: 6| Step: 10
Training loss: 0.09557459920273535
Validation loss: 2.394777898704226

Epoch: 6| Step: 11
Training loss: 0.15784872649585036
Validation loss: 2.3872007397519197

Epoch: 6| Step: 12
Training loss: 0.06926997835245939
Validation loss: 2.400005296732072

Epoch: 6| Step: 13
Training loss: 0.08055009965888961
Validation loss: 2.3927505976793126

Epoch: 670| Step: 0
Training loss: 0.10416517157276409
Validation loss: 2.373395014531029

Epoch: 6| Step: 1
Training loss: 0.09583014214254161
Validation loss: 2.3858426466855085

Epoch: 6| Step: 2
Training loss: 0.09750274514496934
Validation loss: 2.3829195786275688

Epoch: 6| Step: 3
Training loss: 0.08252779507311613
Validation loss: 2.3992003384490017

Epoch: 6| Step: 4
Training loss: 0.07113331608120067
Validation loss: 2.3774603366067604

Epoch: 6| Step: 5
Training loss: 0.1317961173496505
Validation loss: 2.3921021917603946

Epoch: 6| Step: 6
Training loss: 0.0864483970750244
Validation loss: 2.3863073408325404

Epoch: 6| Step: 7
Training loss: 0.09428451570077627
Validation loss: 2.3958701588786373

Epoch: 6| Step: 8
Training loss: 0.05747055938495302
Validation loss: 2.3849994265682333

Epoch: 6| Step: 9
Training loss: 0.08899053460187661
Validation loss: 2.3958686019919577

Epoch: 6| Step: 10
Training loss: 0.08222837831209327
Validation loss: 2.391029245984884

Epoch: 6| Step: 11
Training loss: 0.0498099277581862
Validation loss: 2.3852646320658697

Epoch: 6| Step: 12
Training loss: 0.07473593196467317
Validation loss: 2.3679340952767998

Epoch: 6| Step: 13
Training loss: 0.11560278128097302
Validation loss: 2.3691521503901365

Epoch: 671| Step: 0
Training loss: 0.08008403000342919
Validation loss: 2.3988520301541087

Epoch: 6| Step: 1
Training loss: 0.10743190111708305
Validation loss: 2.352142760608198

Epoch: 6| Step: 2
Training loss: 0.09560243993370372
Validation loss: 2.3388779920417972

Epoch: 6| Step: 3
Training loss: 0.12577848609114833
Validation loss: 2.338592240617359

Epoch: 6| Step: 4
Training loss: 0.09064058753494358
Validation loss: 2.3142468119365014

Epoch: 6| Step: 5
Training loss: 0.08761629631381783
Validation loss: 2.3086871364643047

Epoch: 6| Step: 6
Training loss: 0.08178447889965883
Validation loss: 2.3375536953874985

Epoch: 6| Step: 7
Training loss: 0.1277100300702094
Validation loss: 2.328440347872191

Epoch: 6| Step: 8
Training loss: 0.10577179939082933
Validation loss: 2.3281672511671854

Epoch: 6| Step: 9
Training loss: 0.09698362451702093
Validation loss: 2.3246105277180016

Epoch: 6| Step: 10
Training loss: 0.10434161237553231
Validation loss: 2.345255041871386

Epoch: 6| Step: 11
Training loss: 0.1350540309309026
Validation loss: 2.334718021614518

Epoch: 6| Step: 12
Training loss: 0.08459313296183557
Validation loss: 2.345219172021142

Epoch: 6| Step: 13
Training loss: 0.09951441108872439
Validation loss: 2.388264799749219

Epoch: 672| Step: 0
Training loss: 0.06569922144176682
Validation loss: 2.3839821126142517

Epoch: 6| Step: 1
Training loss: 0.10077671366100228
Validation loss: 2.3503842195289706

Epoch: 6| Step: 2
Training loss: 0.10109424392691557
Validation loss: 2.4156261307237834

Epoch: 6| Step: 3
Training loss: 0.07392148039387339
Validation loss: 2.386440924673283

Epoch: 6| Step: 4
Training loss: 0.13508272872501612
Validation loss: 2.3695197161106165

Epoch: 6| Step: 5
Training loss: 0.0957405445357899
Validation loss: 2.3763475788575024

Epoch: 6| Step: 6
Training loss: 0.1160866850478401
Validation loss: 2.383886729708364

Epoch: 6| Step: 7
Training loss: 0.10915092949360082
Validation loss: 2.403120571155703

Epoch: 6| Step: 8
Training loss: 0.12065093538672234
Validation loss: 2.3876962680824385

Epoch: 6| Step: 9
Training loss: 0.09761694117007826
Validation loss: 2.426011957637179

Epoch: 6| Step: 10
Training loss: 0.09011037282389603
Validation loss: 2.4351991554117838

Epoch: 6| Step: 11
Training loss: 0.0918636789126345
Validation loss: 2.4013278256708723

Epoch: 6| Step: 12
Training loss: 0.07347513664926657
Validation loss: 2.3915889532992183

Epoch: 6| Step: 13
Training loss: 0.08537900492244495
Validation loss: 2.371960348482784

Epoch: 673| Step: 0
Training loss: 0.07777445349420055
Validation loss: 2.3685838064457005

Epoch: 6| Step: 1
Training loss: 0.09990649694794652
Validation loss: 2.3796004496119787

Epoch: 6| Step: 2
Training loss: 0.08929347926247176
Validation loss: 2.365018738292124

Epoch: 6| Step: 3
Training loss: 0.06332958885950933
Validation loss: 2.395342537864231

Epoch: 6| Step: 4
Training loss: 0.06542144552672503
Validation loss: 2.3466406220966447

Epoch: 6| Step: 5
Training loss: 0.08953267645573312
Validation loss: 2.368084850384087

Epoch: 6| Step: 6
Training loss: 0.05487630600219657
Validation loss: 2.371298199930918

Epoch: 6| Step: 7
Training loss: 0.10299393713396074
Validation loss: 2.3666565045466865

Epoch: 6| Step: 8
Training loss: 0.041256802920901364
Validation loss: 2.37893361258523

Epoch: 6| Step: 9
Training loss: 0.06824481083457398
Validation loss: 2.4076167586394654

Epoch: 6| Step: 10
Training loss: 0.058549594135938174
Validation loss: 2.391626240452689

Epoch: 6| Step: 11
Training loss: 0.08927392626330065
Validation loss: 2.4034096038884036

Epoch: 6| Step: 12
Training loss: 0.07124493160541284
Validation loss: 2.4078393531384683

Epoch: 6| Step: 13
Training loss: 0.09470282581674193
Validation loss: 2.4120716339290085

Epoch: 674| Step: 0
Training loss: 0.09253333291785575
Validation loss: 2.4297846735887414

Epoch: 6| Step: 1
Training loss: 0.049619052911661
Validation loss: 2.404335293632367

Epoch: 6| Step: 2
Training loss: 0.08069652684576147
Validation loss: 2.4150664541098648

Epoch: 6| Step: 3
Training loss: 0.07221332152221081
Validation loss: 2.412466630721361

Epoch: 6| Step: 4
Training loss: 0.11773631015192157
Validation loss: 2.4229114549520285

Epoch: 6| Step: 5
Training loss: 0.09462385410171838
Validation loss: 2.4364445696530566

Epoch: 6| Step: 6
Training loss: 0.07425232805309485
Validation loss: 2.416817383173552

Epoch: 6| Step: 7
Training loss: 0.07802013273183474
Validation loss: 2.4018859432403303

Epoch: 6| Step: 8
Training loss: 0.09025897087179977
Validation loss: 2.4174155555489834

Epoch: 6| Step: 9
Training loss: 0.06770098589804563
Validation loss: 2.39585217490329

Epoch: 6| Step: 10
Training loss: 0.09108654603068576
Validation loss: 2.3688601428481597

Epoch: 6| Step: 11
Training loss: 0.07000073216472623
Validation loss: 2.403286121070173

Epoch: 6| Step: 12
Training loss: 0.11011618856306464
Validation loss: 2.3689885876173777

Epoch: 6| Step: 13
Training loss: 0.07112247455287561
Validation loss: 2.3605220738740433

Epoch: 675| Step: 0
Training loss: 0.092909863198672
Validation loss: 2.378997474994561

Epoch: 6| Step: 1
Training loss: 0.06839209863252957
Validation loss: 2.3822463066431934

Epoch: 6| Step: 2
Training loss: 0.1005013119151712
Validation loss: 2.3799907349433465

Epoch: 6| Step: 3
Training loss: 0.05989282495089217
Validation loss: 2.3992307707988494

Epoch: 6| Step: 4
Training loss: 0.07805643351047871
Validation loss: 2.3905833465424022

Epoch: 6| Step: 5
Training loss: 0.11299007912197005
Validation loss: 2.3926936210328473

Epoch: 6| Step: 6
Training loss: 0.06935126511304943
Validation loss: 2.411734083883305

Epoch: 6| Step: 7
Training loss: 0.07396084119122195
Validation loss: 2.4206255057726587

Epoch: 6| Step: 8
Training loss: 0.07374318752101784
Validation loss: 2.4122881231877296

Epoch: 6| Step: 9
Training loss: 0.049594498735501535
Validation loss: 2.4059339139117815

Epoch: 6| Step: 10
Training loss: 0.10989462511323499
Validation loss: 2.4315224653201346

Epoch: 6| Step: 11
Training loss: 0.07070562940450957
Validation loss: 2.409007581211682

Epoch: 6| Step: 12
Training loss: 0.08869868851977497
Validation loss: 2.4033620865496386

Epoch: 6| Step: 13
Training loss: 0.07009589421823048
Validation loss: 2.3938388962069244

Epoch: 676| Step: 0
Training loss: 0.09376879344761958
Validation loss: 2.3943144978823594

Epoch: 6| Step: 1
Training loss: 0.07035833096920915
Validation loss: 2.416606315337292

Epoch: 6| Step: 2
Training loss: 0.07638883869152635
Validation loss: 2.387835474105215

Epoch: 6| Step: 3
Training loss: 0.07374171303908549
Validation loss: 2.3901549050081683

Epoch: 6| Step: 4
Training loss: 0.06333730534334839
Validation loss: 2.359782181013098

Epoch: 6| Step: 5
Training loss: 0.09909406772732211
Validation loss: 2.3888489062931697

Epoch: 6| Step: 6
Training loss: 0.07331570750059069
Validation loss: 2.3807367561453696

Epoch: 6| Step: 7
Training loss: 0.09098229780418592
Validation loss: 2.369342887400845

Epoch: 6| Step: 8
Training loss: 0.07849949841923741
Validation loss: 2.367720278756034

Epoch: 6| Step: 9
Training loss: 0.0879610468284984
Validation loss: 2.350344715044526

Epoch: 6| Step: 10
Training loss: 0.08837557623053517
Validation loss: 2.367403076150342

Epoch: 6| Step: 11
Training loss: 0.11330399613734028
Validation loss: 2.3494831349603342

Epoch: 6| Step: 12
Training loss: 0.06043865546031276
Validation loss: 2.3310760307770635

Epoch: 6| Step: 13
Training loss: 0.04680663577405465
Validation loss: 2.358020299290695

Epoch: 677| Step: 0
Training loss: 0.09341385301332146
Validation loss: 2.3604761118687954

Epoch: 6| Step: 1
Training loss: 0.10277381546026404
Validation loss: 2.357949875919743

Epoch: 6| Step: 2
Training loss: 0.10562001524821511
Validation loss: 2.383617783760906

Epoch: 6| Step: 3
Training loss: 0.07596594532819005
Validation loss: 2.383524438189595

Epoch: 6| Step: 4
Training loss: 0.08946276304637522
Validation loss: 2.3691608882670825

Epoch: 6| Step: 5
Training loss: 0.12031799294578013
Validation loss: 2.363051096171268

Epoch: 6| Step: 6
Training loss: 0.09283663454366325
Validation loss: 2.3674455148287477

Epoch: 6| Step: 7
Training loss: 0.11030760032860025
Validation loss: 2.3668374473842384

Epoch: 6| Step: 8
Training loss: 0.08587232198801208
Validation loss: 2.348502990260566

Epoch: 6| Step: 9
Training loss: 0.06662292054108912
Validation loss: 2.347911245998561

Epoch: 6| Step: 10
Training loss: 0.10269902331792974
Validation loss: 2.349125637452533

Epoch: 6| Step: 11
Training loss: 0.06193383838156534
Validation loss: 2.356782794859264

Epoch: 6| Step: 12
Training loss: 0.06903275841912249
Validation loss: 2.3628749920272134

Epoch: 6| Step: 13
Training loss: 0.07258865611620752
Validation loss: 2.3772838461981247

Epoch: 678| Step: 0
Training loss: 0.09049533825533161
Validation loss: 2.3714173696127463

Epoch: 6| Step: 1
Training loss: 0.1159383437737764
Validation loss: 2.390245370348703

Epoch: 6| Step: 2
Training loss: 0.05627072336667994
Validation loss: 2.410856434197532

Epoch: 6| Step: 3
Training loss: 0.09488902465441913
Validation loss: 2.3922148223817197

Epoch: 6| Step: 4
Training loss: 0.08098791715874697
Validation loss: 2.4159273824882184

Epoch: 6| Step: 5
Training loss: 0.07838141562092497
Validation loss: 2.4019197063232434

Epoch: 6| Step: 6
Training loss: 0.06313094166609665
Validation loss: 2.4052300818680123

Epoch: 6| Step: 7
Training loss: 0.10459613976998162
Validation loss: 2.4086389635178156

Epoch: 6| Step: 8
Training loss: 0.05219135134942252
Validation loss: 2.4333225841119037

Epoch: 6| Step: 9
Training loss: 0.043738377306625636
Validation loss: 2.4297085033635684

Epoch: 6| Step: 10
Training loss: 0.0803899479856983
Validation loss: 2.391135919129345

Epoch: 6| Step: 11
Training loss: 0.05630585170914192
Validation loss: 2.4018594761438092

Epoch: 6| Step: 12
Training loss: 0.06879911673101533
Validation loss: 2.3902810675265687

Epoch: 6| Step: 13
Training loss: 0.053227240688718425
Validation loss: 2.4115285780569744

Epoch: 679| Step: 0
Training loss: 0.11338674631537994
Validation loss: 2.4079963657799692

Epoch: 6| Step: 1
Training loss: 0.06489520831837839
Validation loss: 2.3924110084685473

Epoch: 6| Step: 2
Training loss: 0.06384672294931126
Validation loss: 2.421430632611186

Epoch: 6| Step: 3
Training loss: 0.06586750359335511
Validation loss: 2.387516603270915

Epoch: 6| Step: 4
Training loss: 0.04584669686878861
Validation loss: 2.417275543723189

Epoch: 6| Step: 5
Training loss: 0.06133458884003624
Validation loss: 2.4180109028756127

Epoch: 6| Step: 6
Training loss: 0.08575988426149032
Validation loss: 2.410107650395814

Epoch: 6| Step: 7
Training loss: 0.06082856500825596
Validation loss: 2.3900961116948873

Epoch: 6| Step: 8
Training loss: 0.05713345028664589
Validation loss: 2.4056900746263685

Epoch: 6| Step: 9
Training loss: 0.0857959877227758
Validation loss: 2.4002996907898635

Epoch: 6| Step: 10
Training loss: 0.06411772577653149
Validation loss: 2.4087536043141564

Epoch: 6| Step: 11
Training loss: 0.07148988082402706
Validation loss: 2.375847087369152

Epoch: 6| Step: 12
Training loss: 0.04666872634042876
Validation loss: 2.412942791479849

Epoch: 6| Step: 13
Training loss: 0.11112315566706878
Validation loss: 2.421423582519553

Epoch: 680| Step: 0
Training loss: 0.077222426462437
Validation loss: 2.3904304165154158

Epoch: 6| Step: 1
Training loss: 0.08162965563952072
Validation loss: 2.387528405033695

Epoch: 6| Step: 2
Training loss: 0.06246425865855439
Validation loss: 2.3716533788598295

Epoch: 6| Step: 3
Training loss: 0.08051713535055234
Validation loss: 2.3922704162350246

Epoch: 6| Step: 4
Training loss: 0.10698347365377238
Validation loss: 2.3820568697455835

Epoch: 6| Step: 5
Training loss: 0.08032399323527369
Validation loss: 2.3973001242588965

Epoch: 6| Step: 6
Training loss: 0.09946569664451677
Validation loss: 2.3909527723293302

Epoch: 6| Step: 7
Training loss: 0.09879819771193286
Validation loss: 2.3484069094759685

Epoch: 6| Step: 8
Training loss: 0.07317378664849201
Validation loss: 2.3915688929238783

Epoch: 6| Step: 9
Training loss: 0.04790865888016831
Validation loss: 2.392732548471395

Epoch: 6| Step: 10
Training loss: 0.09846659147208424
Validation loss: 2.3965624291522976

Epoch: 6| Step: 11
Training loss: 0.06792606556336175
Validation loss: 2.410804163510749

Epoch: 6| Step: 12
Training loss: 0.08753995079141359
Validation loss: 2.400092837929101

Epoch: 6| Step: 13
Training loss: 0.04491536207254844
Validation loss: 2.381313744134462

Epoch: 681| Step: 0
Training loss: 0.06708902083646003
Validation loss: 2.416437650747805

Epoch: 6| Step: 1
Training loss: 0.08565789491444169
Validation loss: 2.3806585890970164

Epoch: 6| Step: 2
Training loss: 0.08044012171541658
Validation loss: 2.390708324040036

Epoch: 6| Step: 3
Training loss: 0.05053808607548986
Validation loss: 2.4050963619073675

Epoch: 6| Step: 4
Training loss: 0.061043681502994614
Validation loss: 2.3802404935783295

Epoch: 6| Step: 5
Training loss: 0.0681644931550071
Validation loss: 2.415270567231953

Epoch: 6| Step: 6
Training loss: 0.07970855203405526
Validation loss: 2.3484828096483827

Epoch: 6| Step: 7
Training loss: 0.06569555695998959
Validation loss: 2.3589152563435585

Epoch: 6| Step: 8
Training loss: 0.0645085335030906
Validation loss: 2.3582127759188496

Epoch: 6| Step: 9
Training loss: 0.08571263175369813
Validation loss: 2.375580901739093

Epoch: 6| Step: 10
Training loss: 0.11349254255986994
Validation loss: 2.3451613215221223

Epoch: 6| Step: 11
Training loss: 0.08923327841274471
Validation loss: 2.364050133179401

Epoch: 6| Step: 12
Training loss: 0.08581095286340898
Validation loss: 2.370834588073344

Epoch: 6| Step: 13
Training loss: 0.08401915750372084
Validation loss: 2.3813149628064934

Epoch: 682| Step: 0
Training loss: 0.048377467936055525
Validation loss: 2.393668564172384

Epoch: 6| Step: 1
Training loss: 0.07832149293062295
Validation loss: 2.393244027813753

Epoch: 6| Step: 2
Training loss: 0.10406654781768507
Validation loss: 2.3912786632596386

Epoch: 6| Step: 3
Training loss: 0.06923722574373732
Validation loss: 2.3967190090323083

Epoch: 6| Step: 4
Training loss: 0.08080252524032097
Validation loss: 2.3889820217927076

Epoch: 6| Step: 5
Training loss: 0.06309221992271723
Validation loss: 2.432178708039085

Epoch: 6| Step: 6
Training loss: 0.0842821696679982
Validation loss: 2.4182040812554026

Epoch: 6| Step: 7
Training loss: 0.09746557694823214
Validation loss: 2.394262967852781

Epoch: 6| Step: 8
Training loss: 0.08431423635122884
Validation loss: 2.4016605894832748

Epoch: 6| Step: 9
Training loss: 0.08552466740050119
Validation loss: 2.3928589307799037

Epoch: 6| Step: 10
Training loss: 0.1462233697659159
Validation loss: 2.41549220009902

Epoch: 6| Step: 11
Training loss: 0.07004128241970198
Validation loss: 2.372449698576839

Epoch: 6| Step: 12
Training loss: 0.09606508490379995
Validation loss: 2.362144931020316

Epoch: 6| Step: 13
Training loss: 0.12725048452839666
Validation loss: 2.372378290965061

Epoch: 683| Step: 0
Training loss: 0.10088059866151194
Validation loss: 2.3307775436846496

Epoch: 6| Step: 1
Training loss: 0.05956689637191575
Validation loss: 2.361814236971241

Epoch: 6| Step: 2
Training loss: 0.08656808484821449
Validation loss: 2.3698519517293186

Epoch: 6| Step: 3
Training loss: 0.07292077111147784
Validation loss: 2.340918544510569

Epoch: 6| Step: 4
Training loss: 0.09413308612031164
Validation loss: 2.337309515044514

Epoch: 6| Step: 5
Training loss: 0.09937845840374183
Validation loss: 2.3448093309136766

Epoch: 6| Step: 6
Training loss: 0.09625332190305003
Validation loss: 2.3552641499729496

Epoch: 6| Step: 7
Training loss: 0.09353278745948287
Validation loss: 2.365263364394442

Epoch: 6| Step: 8
Training loss: 0.07597653087428986
Validation loss: 2.39213228707271

Epoch: 6| Step: 9
Training loss: 0.12250206316091225
Validation loss: 2.3608453259197266

Epoch: 6| Step: 10
Training loss: 0.10588027881435635
Validation loss: 2.394780538587585

Epoch: 6| Step: 11
Training loss: 0.09965593521400994
Validation loss: 2.383999969986891

Epoch: 6| Step: 12
Training loss: 0.09265759413228308
Validation loss: 2.3982757805642194

Epoch: 6| Step: 13
Training loss: 0.09489055085300996
Validation loss: 2.3895680724285344

Epoch: 684| Step: 0
Training loss: 0.2189450246109716
Validation loss: 2.408107367271949

Epoch: 6| Step: 1
Training loss: 0.22691833570872622
Validation loss: 2.399401980499754

Epoch: 6| Step: 2
Training loss: 0.08795679568480125
Validation loss: 2.4043726667349365

Epoch: 6| Step: 3
Training loss: 0.06306545202502682
Validation loss: 2.4162461512908076

Epoch: 6| Step: 4
Training loss: 0.12733027849144612
Validation loss: 2.392929400267803

Epoch: 6| Step: 5
Training loss: 0.11512406371038264
Validation loss: 2.3751317404891723

Epoch: 6| Step: 6
Training loss: 0.12006883888722868
Validation loss: 2.3811999053590807

Epoch: 6| Step: 7
Training loss: 0.08844747043993194
Validation loss: 2.369529417704725

Epoch: 6| Step: 8
Training loss: 0.12813221573863673
Validation loss: 2.3806837514586467

Epoch: 6| Step: 9
Training loss: 0.15358628449870632
Validation loss: 2.388196495200221

Epoch: 6| Step: 10
Training loss: 0.1811642912757505
Validation loss: 2.3589197675959546

Epoch: 6| Step: 11
Training loss: 0.10580876960194764
Validation loss: 2.387435014782341

Epoch: 6| Step: 12
Training loss: 0.07679393660821578
Validation loss: 2.3687217903584123

Epoch: 6| Step: 13
Training loss: 0.11112972198238427
Validation loss: 2.3745191753382784

Epoch: 685| Step: 0
Training loss: 0.10928963412253233
Validation loss: 2.36099206872465

Epoch: 6| Step: 1
Training loss: 0.11340742647848989
Validation loss: 2.3828479932982254

Epoch: 6| Step: 2
Training loss: 0.1381372839225161
Validation loss: 2.3955713400813896

Epoch: 6| Step: 3
Training loss: 0.1513283218201326
Validation loss: 2.3806160876688693

Epoch: 6| Step: 4
Training loss: 0.1440950267278515
Validation loss: 2.3760974919464415

Epoch: 6| Step: 5
Training loss: 0.07634486216001642
Validation loss: 2.389377752006057

Epoch: 6| Step: 6
Training loss: 0.05998161468852105
Validation loss: 2.381395538036489

Epoch: 6| Step: 7
Training loss: 0.08873336273384419
Validation loss: 2.3730215306500377

Epoch: 6| Step: 8
Training loss: 0.08893766333450417
Validation loss: 2.3906863378507897

Epoch: 6| Step: 9
Training loss: 0.13759222974290417
Validation loss: 2.3946139906114956

Epoch: 6| Step: 10
Training loss: 0.09887997187021129
Validation loss: 2.376979328001349

Epoch: 6| Step: 11
Training loss: 0.17478286351196276
Validation loss: 2.4292591673495543

Epoch: 6| Step: 12
Training loss: 0.13051333151151367
Validation loss: 2.3978815904535438

Epoch: 6| Step: 13
Training loss: 0.13458136387196917
Validation loss: 2.4001754733340013

Epoch: 686| Step: 0
Training loss: 0.0680788790851703
Validation loss: 2.3973478141494784

Epoch: 6| Step: 1
Training loss: 0.05649537132129402
Validation loss: 2.3942667159861903

Epoch: 6| Step: 2
Training loss: 0.0833138322612786
Validation loss: 2.4057529246608564

Epoch: 6| Step: 3
Training loss: 0.11711069610186459
Validation loss: 2.398419290499999

Epoch: 6| Step: 4
Training loss: 0.08633701162211174
Validation loss: 2.3722389149214407

Epoch: 6| Step: 5
Training loss: 0.1341341677196259
Validation loss: 2.3913115565740823

Epoch: 6| Step: 6
Training loss: 0.18933237297932204
Validation loss: 2.4034154908230803

Epoch: 6| Step: 7
Training loss: 0.08365705657640689
Validation loss: 2.4030259231055644

Epoch: 6| Step: 8
Training loss: 0.07064518108496176
Validation loss: 2.376726469655475

Epoch: 6| Step: 9
Training loss: 0.08921864983908781
Validation loss: 2.3970065559187246

Epoch: 6| Step: 10
Training loss: 0.059815317264465
Validation loss: 2.39360725668865

Epoch: 6| Step: 11
Training loss: 0.10253071523932115
Validation loss: 2.377257920467511

Epoch: 6| Step: 12
Training loss: 0.10762595817702068
Validation loss: 2.3847999556509287

Epoch: 6| Step: 13
Training loss: 0.1206670634710664
Validation loss: 2.359473618851247

Epoch: 687| Step: 0
Training loss: 0.13002907971067842
Validation loss: 2.3709136856136026

Epoch: 6| Step: 1
Training loss: 0.0832030244835618
Validation loss: 2.358503728844938

Epoch: 6| Step: 2
Training loss: 0.12880519315845132
Validation loss: 2.4030795092738715

Epoch: 6| Step: 3
Training loss: 0.11338178514346205
Validation loss: 2.4170672894731315

Epoch: 6| Step: 4
Training loss: 0.04078825445832432
Validation loss: 2.412873707077957

Epoch: 6| Step: 5
Training loss: 0.10561205700006988
Validation loss: 2.4361910012122587

Epoch: 6| Step: 6
Training loss: 0.09232464202951685
Validation loss: 2.4323147990930902

Epoch: 6| Step: 7
Training loss: 0.07209964971787948
Validation loss: 2.434714799860655

Epoch: 6| Step: 8
Training loss: 0.1294814915216875
Validation loss: 2.4035234552238753

Epoch: 6| Step: 9
Training loss: 0.1019793356165722
Validation loss: 2.4348630743151976

Epoch: 6| Step: 10
Training loss: 0.10123273609587544
Validation loss: 2.433414369198276

Epoch: 6| Step: 11
Training loss: 0.04539594889472989
Validation loss: 2.424573779076099

Epoch: 6| Step: 12
Training loss: 0.06943526004449704
Validation loss: 2.437918301878606

Epoch: 6| Step: 13
Training loss: 0.03305069209209536
Validation loss: 2.413640715894204

Epoch: 688| Step: 0
Training loss: 0.12648465211306606
Validation loss: 2.4315181773335723

Epoch: 6| Step: 1
Training loss: 0.07725602506895383
Validation loss: 2.4418788899019215

Epoch: 6| Step: 2
Training loss: 0.12915959172202623
Validation loss: 2.4151560691254588

Epoch: 6| Step: 3
Training loss: 0.10907250536081897
Validation loss: 2.4444846561377296

Epoch: 6| Step: 4
Training loss: 0.10218413551578057
Validation loss: 2.4379939243294415

Epoch: 6| Step: 5
Training loss: 0.10132981660705878
Validation loss: 2.430916004398899

Epoch: 6| Step: 6
Training loss: 0.09846741433722284
Validation loss: 2.4181195021470976

Epoch: 6| Step: 7
Training loss: 0.07632915142290647
Validation loss: 2.4063822674366255

Epoch: 6| Step: 8
Training loss: 0.1349155310998683
Validation loss: 2.407563422002158

Epoch: 6| Step: 9
Training loss: 0.16857739999452395
Validation loss: 2.406606433648158

Epoch: 6| Step: 10
Training loss: 0.09705219368339625
Validation loss: 2.402098694608231

Epoch: 6| Step: 11
Training loss: 0.13717627944332234
Validation loss: 2.3963621395028993

Epoch: 6| Step: 12
Training loss: 0.11337292184733606
Validation loss: 2.365275902582246

Epoch: 6| Step: 13
Training loss: 0.06591863278654975
Validation loss: 2.3956551587665733

Epoch: 689| Step: 0
Training loss: 0.07808459548407631
Validation loss: 2.3795794079759194

Epoch: 6| Step: 1
Training loss: 0.09372199156721073
Validation loss: 2.370187296945187

Epoch: 6| Step: 2
Training loss: 0.09795469932398482
Validation loss: 2.3627724137957933

Epoch: 6| Step: 3
Training loss: 0.17728089550513415
Validation loss: 2.383682298257948

Epoch: 6| Step: 4
Training loss: 0.14214305602283628
Validation loss: 2.3730226455478505

Epoch: 6| Step: 5
Training loss: 0.08669870462800118
Validation loss: 2.38851944296478

Epoch: 6| Step: 6
Training loss: 0.0774538447479565
Validation loss: 2.4151662794830675

Epoch: 6| Step: 7
Training loss: 0.1286128418494201
Validation loss: 2.4177627249076354

Epoch: 6| Step: 8
Training loss: 0.15476916257617426
Validation loss: 2.4004179872543143

Epoch: 6| Step: 9
Training loss: 0.13253310210668243
Validation loss: 2.3945305626598268

Epoch: 6| Step: 10
Training loss: 0.14477764211515384
Validation loss: 2.4118175109313307

Epoch: 6| Step: 11
Training loss: 0.12511330922785774
Validation loss: 2.3883664135218146

Epoch: 6| Step: 12
Training loss: 0.19057494272338535
Validation loss: 2.395081305125578

Epoch: 6| Step: 13
Training loss: 0.12460511762347773
Validation loss: 2.3570334290537653

Epoch: 690| Step: 0
Training loss: 0.18103542822137203
Validation loss: 2.3715316563514404

Epoch: 6| Step: 1
Training loss: 0.12046760138596155
Validation loss: 2.369002596494831

Epoch: 6| Step: 2
Training loss: 0.11996418038981302
Validation loss: 2.3353982905939317

Epoch: 6| Step: 3
Training loss: 0.1368353618856918
Validation loss: 2.355123906435754

Epoch: 6| Step: 4
Training loss: 0.12186850078077387
Validation loss: 2.398062500813741

Epoch: 6| Step: 5
Training loss: 0.15924060568580412
Validation loss: 2.4068884895390146

Epoch: 6| Step: 6
Training loss: 0.0838867163075279
Validation loss: 2.3976198997868634

Epoch: 6| Step: 7
Training loss: 0.13851169952837397
Validation loss: 2.3844985943428743

Epoch: 6| Step: 8
Training loss: 0.13585649795513108
Validation loss: 2.4124467928344675

Epoch: 6| Step: 9
Training loss: 0.13977113415440312
Validation loss: 2.4172471600673324

Epoch: 6| Step: 10
Training loss: 0.19662568185230916
Validation loss: 2.428342148867318

Epoch: 6| Step: 11
Training loss: 0.15860716711331513
Validation loss: 2.432695714692719

Epoch: 6| Step: 12
Training loss: 0.1111514463038219
Validation loss: 2.4123643057294997

Epoch: 6| Step: 13
Training loss: 0.18397930932006154
Validation loss: 2.4065994671608766

Epoch: 691| Step: 0
Training loss: 0.16413472493174353
Validation loss: 2.3662578021896277

Epoch: 6| Step: 1
Training loss: 0.1840539804633919
Validation loss: 2.3373854575027937

Epoch: 6| Step: 2
Training loss: 0.23195954830106622
Validation loss: 2.2793453596728503

Epoch: 6| Step: 3
Training loss: 0.15701056386857679
Validation loss: 2.2980271374715224

Epoch: 6| Step: 4
Training loss: 0.2734369141708638
Validation loss: 2.248202594983652

Epoch: 6| Step: 5
Training loss: 0.41228277165341654
Validation loss: 2.2450134230241954

Epoch: 6| Step: 6
Training loss: 0.09380326148879539
Validation loss: 2.331025344161691

Epoch: 6| Step: 7
Training loss: 0.20571687315574794
Validation loss: 2.3988454891988082

Epoch: 6| Step: 8
Training loss: 0.253687720524931
Validation loss: 2.424136641932665

Epoch: 6| Step: 9
Training loss: 0.26082286943728034
Validation loss: 2.4384932754166417

Epoch: 6| Step: 10
Training loss: 0.2709970010278309
Validation loss: 2.435000378755923

Epoch: 6| Step: 11
Training loss: 0.272064207272789
Validation loss: 2.4271586008313566

Epoch: 6| Step: 12
Training loss: 0.43211007804585816
Validation loss: 2.4315466221368216

Epoch: 6| Step: 13
Training loss: 0.21578573579980215
Validation loss: 2.4176184799301264

Epoch: 692| Step: 0
Training loss: 0.26250422451616295
Validation loss: 2.3759019191043493

Epoch: 6| Step: 1
Training loss: 0.27884692514816284
Validation loss: 2.331646263936751

Epoch: 6| Step: 2
Training loss: 0.19618225987762147
Validation loss: 2.31592488229094

Epoch: 6| Step: 3
Training loss: 0.25878354912408996
Validation loss: 2.3064895339637705

Epoch: 6| Step: 4
Training loss: 0.27465425615653594
Validation loss: 2.2838668558165285

Epoch: 6| Step: 5
Training loss: 0.3485364166262629
Validation loss: 2.3041628026700867

Epoch: 6| Step: 6
Training loss: 0.45181725321654753
Validation loss: 2.310762621339349

Epoch: 6| Step: 7
Training loss: 0.23779489567346038
Validation loss: 2.310969497275105

Epoch: 6| Step: 8
Training loss: 0.2701368025514198
Validation loss: 2.3482999252459025

Epoch: 6| Step: 9
Training loss: 0.3587754265151706
Validation loss: 2.362042338449561

Epoch: 6| Step: 10
Training loss: 0.22765390829532714
Validation loss: 2.3697111115844036

Epoch: 6| Step: 11
Training loss: 0.4043497060267367
Validation loss: 2.3653642305411315

Epoch: 6| Step: 12
Training loss: 0.4070724085757587
Validation loss: 2.276051055227291

Epoch: 6| Step: 13
Training loss: 0.5355712506668585
Validation loss: 2.2715002193460347

Epoch: 693| Step: 0
Training loss: 0.30999335856783583
Validation loss: 2.3181103444241846

Epoch: 6| Step: 1
Training loss: 0.28960335882959815
Validation loss: 2.3636590682582197

Epoch: 6| Step: 2
Training loss: 0.3021367973940967
Validation loss: 2.354899334257089

Epoch: 6| Step: 3
Training loss: 0.31499739748015915
Validation loss: 2.331245808832807

Epoch: 6| Step: 4
Training loss: 0.40482642098031785
Validation loss: 2.2989332804242286

Epoch: 6| Step: 5
Training loss: 0.4772737542261082
Validation loss: 2.3326402918974227

Epoch: 6| Step: 6
Training loss: 0.4356797362081687
Validation loss: 2.372653596564785

Epoch: 6| Step: 7
Training loss: 0.3196227742372368
Validation loss: 2.3830770414629954

Epoch: 6| Step: 8
Training loss: 0.5391042389121564
Validation loss: 2.3973193210082875

Epoch: 6| Step: 9
Training loss: 0.4997745989336247
Validation loss: 2.3946712341701253

Epoch: 6| Step: 10
Training loss: 0.2592469105936489
Validation loss: 2.4262267415322305

Epoch: 6| Step: 11
Training loss: 0.3607026744077106
Validation loss: 2.4315442330349715

Epoch: 6| Step: 12
Training loss: 0.348020041787508
Validation loss: 2.424800526134653

Epoch: 6| Step: 13
Training loss: 0.2931802494833421
Validation loss: 2.412407704770062

Epoch: 694| Step: 0
Training loss: 0.472769148402996
Validation loss: 2.4106445009411934

Epoch: 6| Step: 1
Training loss: 0.2192942286686081
Validation loss: 2.411266910306112

Epoch: 6| Step: 2
Training loss: 0.37291319683883056
Validation loss: 2.4528695365317903

Epoch: 6| Step: 3
Training loss: 0.29857525068034757
Validation loss: 2.4433585985712885

Epoch: 6| Step: 4
Training loss: 0.303364448750536
Validation loss: 2.484122614011746

Epoch: 6| Step: 5
Training loss: 0.3153084678505511
Validation loss: 2.4699339939631066

Epoch: 6| Step: 6
Training loss: 0.377755255452425
Validation loss: 2.411145424756582

Epoch: 6| Step: 7
Training loss: 0.3886284923783046
Validation loss: 2.4157850894456683

Epoch: 6| Step: 8
Training loss: 0.293302003149579
Validation loss: 2.383613928000484

Epoch: 6| Step: 9
Training loss: 0.3062992747233787
Validation loss: 2.338850399517723

Epoch: 6| Step: 10
Training loss: 0.3939293906871931
Validation loss: 2.3373666248499574

Epoch: 6| Step: 11
Training loss: 0.35086326999579137
Validation loss: 2.3378943763335673

Epoch: 6| Step: 12
Training loss: 0.48471431230062173
Validation loss: 2.3194341984968476

Epoch: 6| Step: 13
Training loss: 0.26845737428112465
Validation loss: 2.29194875157527

Epoch: 695| Step: 0
Training loss: 0.4363177879700475
Validation loss: 2.3154444718764386

Epoch: 6| Step: 1
Training loss: 0.35630492489692867
Validation loss: 2.4051770877474477

Epoch: 6| Step: 2
Training loss: 0.4047335049906629
Validation loss: 2.40948862347057

Epoch: 6| Step: 3
Training loss: 0.3980209941143213
Validation loss: 2.43161566785299

Epoch: 6| Step: 4
Training loss: 0.4105824390690947
Validation loss: 2.450870751824645

Epoch: 6| Step: 5
Training loss: 0.335805345756195
Validation loss: 2.484888197265795

Epoch: 6| Step: 6
Training loss: 0.5276580721502044
Validation loss: 2.507210195934063

Epoch: 6| Step: 7
Training loss: 0.2729125569788829
Validation loss: 2.5191328909802038

Epoch: 6| Step: 8
Training loss: 0.3002227328899817
Validation loss: 2.4685211415650303

Epoch: 6| Step: 9
Training loss: 0.4029253117614513
Validation loss: 2.4901283859612997

Epoch: 6| Step: 10
Training loss: 0.27914654080357054
Validation loss: 2.4673851490708993

Epoch: 6| Step: 11
Training loss: 0.5287271227295132
Validation loss: 2.4237179437077687

Epoch: 6| Step: 12
Training loss: 0.36630831631736654
Validation loss: 2.3685811968943895

Epoch: 6| Step: 13
Training loss: 0.23345356054860927
Validation loss: 2.3364047842005613

Epoch: 696| Step: 0
Training loss: 0.3358010525054182
Validation loss: 2.3200508363192602

Epoch: 6| Step: 1
Training loss: 0.5373616683736654
Validation loss: 2.3262353895328878

Epoch: 6| Step: 2
Training loss: 0.561553503143807
Validation loss: 2.339050657625814

Epoch: 6| Step: 3
Training loss: 0.4131312785053865
Validation loss: 2.3114908145387187

Epoch: 6| Step: 4
Training loss: 0.4587882739011987
Validation loss: 2.3889975174516875

Epoch: 6| Step: 5
Training loss: 0.3457634544533702
Validation loss: 2.363713262183589

Epoch: 6| Step: 6
Training loss: 0.3177409689457984
Validation loss: 2.4136935879180426

Epoch: 6| Step: 7
Training loss: 0.2738192209926589
Validation loss: 2.4496118530635775

Epoch: 6| Step: 8
Training loss: 0.591443349664811
Validation loss: 2.4508236222471322

Epoch: 6| Step: 9
Training loss: 0.3367572585387741
Validation loss: 2.4303812092385186

Epoch: 6| Step: 10
Training loss: 0.4362971254707401
Validation loss: 2.4072760322977436

Epoch: 6| Step: 11
Training loss: 0.30400520125915
Validation loss: 2.3996992892299973

Epoch: 6| Step: 12
Training loss: 0.25006588425332954
Validation loss: 2.4002949817517827

Epoch: 6| Step: 13
Training loss: 0.1595585766215442
Validation loss: 2.42270436001179

Epoch: 697| Step: 0
Training loss: 0.5409377279562114
Validation loss: 2.4481082123063294

Epoch: 6| Step: 1
Training loss: 0.5342434247084876
Validation loss: 2.415086599546848

Epoch: 6| Step: 2
Training loss: 0.4250867060962689
Validation loss: 2.4333751601825764

Epoch: 6| Step: 3
Training loss: 0.5167216862588468
Validation loss: 2.4125774608080044

Epoch: 6| Step: 4
Training loss: 0.399742811937579
Validation loss: 2.3864175971616275

Epoch: 6| Step: 5
Training loss: 0.37942049190509664
Validation loss: 2.4134561050740455

Epoch: 6| Step: 6
Training loss: 0.28813486491959395
Validation loss: 2.4370540703211323

Epoch: 6| Step: 7
Training loss: 0.39349455646205705
Validation loss: 2.439720369910072

Epoch: 6| Step: 8
Training loss: 0.38660504374536764
Validation loss: 2.4237986810552137

Epoch: 6| Step: 9
Training loss: 0.2016662153391346
Validation loss: 2.4335910742654843

Epoch: 6| Step: 10
Training loss: 0.26263642626039946
Validation loss: 2.443062687820559

Epoch: 6| Step: 11
Training loss: 0.23743028809734834
Validation loss: 2.4259482425607195

Epoch: 6| Step: 12
Training loss: 0.3609558249441494
Validation loss: 2.4138614783104

Epoch: 6| Step: 13
Training loss: 0.40489384902508435
Validation loss: 2.4193292661053687

Epoch: 698| Step: 0
Training loss: 0.23371777575009656
Validation loss: 2.4080546004219343

Epoch: 6| Step: 1
Training loss: 0.40379154487607766
Validation loss: 2.3549330127673533

Epoch: 6| Step: 2
Training loss: 0.2492364010195497
Validation loss: 2.3865643633228677

Epoch: 6| Step: 3
Training loss: 0.266488942264011
Validation loss: 2.375394421680198

Epoch: 6| Step: 4
Training loss: 0.3439362519872567
Validation loss: 2.3803456060592656

Epoch: 6| Step: 5
Training loss: 0.3538868467220275
Validation loss: 2.3896026173117377

Epoch: 6| Step: 6
Training loss: 0.5448194291266156
Validation loss: 2.396913933372585

Epoch: 6| Step: 7
Training loss: 0.35612971299581997
Validation loss: 2.3920022004361536

Epoch: 6| Step: 8
Training loss: 0.3418176917140272
Validation loss: 2.408795328837921

Epoch: 6| Step: 9
Training loss: 0.46598611436056275
Validation loss: 2.3729980496136576

Epoch: 6| Step: 10
Training loss: 0.3357825032561831
Validation loss: 2.371003138886456

Epoch: 6| Step: 11
Training loss: 0.24759373612929236
Validation loss: 2.401322090020947

Epoch: 6| Step: 12
Training loss: 0.3239257361682565
Validation loss: 2.427838991921417

Epoch: 6| Step: 13
Training loss: 0.3620526653108451
Validation loss: 2.4207244341790712

Epoch: 699| Step: 0
Training loss: 0.28037467483896217
Validation loss: 2.45899704208069

Epoch: 6| Step: 1
Training loss: 0.342243447803226
Validation loss: 2.4228991938589575

Epoch: 6| Step: 2
Training loss: 0.3016096078318144
Validation loss: 2.4189133079186407

Epoch: 6| Step: 3
Training loss: 0.4030734177049966
Validation loss: 2.3801149771963486

Epoch: 6| Step: 4
Training loss: 0.36311032776071706
Validation loss: 2.384352967066082

Epoch: 6| Step: 5
Training loss: 0.305098830630413
Validation loss: 2.3757180343946076

Epoch: 6| Step: 6
Training loss: 0.6583791208842592
Validation loss: 2.3565521303738177

Epoch: 6| Step: 7
Training loss: 0.19870397967632977
Validation loss: 2.3370242533314376

Epoch: 6| Step: 8
Training loss: 0.3536013293834117
Validation loss: 2.362551773536172

Epoch: 6| Step: 9
Training loss: 0.22372059161305702
Validation loss: 2.341814092886025

Epoch: 6| Step: 10
Training loss: 0.2124406188153432
Validation loss: 2.3388799559754423

Epoch: 6| Step: 11
Training loss: 0.1832887469788511
Validation loss: 2.301056218803972

Epoch: 6| Step: 12
Training loss: 0.315227810059816
Validation loss: 2.2930060574371525

Epoch: 6| Step: 13
Training loss: 0.1948458341687414
Validation loss: 2.2960599287842656

Epoch: 700| Step: 0
Training loss: 0.26004045332218223
Validation loss: 2.3068423684525285

Epoch: 6| Step: 1
Training loss: 0.19905016815997248
Validation loss: 2.2906389417306436

Epoch: 6| Step: 2
Training loss: 0.30623745989913487
Validation loss: 2.3189672329141073

Epoch: 6| Step: 3
Training loss: 0.3100936509385662
Validation loss: 2.333717986526185

Epoch: 6| Step: 4
Training loss: 0.23055239953583692
Validation loss: 2.2984553995473678

Epoch: 6| Step: 5
Training loss: 0.3922436556184495
Validation loss: 2.2938923397082345

Epoch: 6| Step: 6
Training loss: 0.22477565912702263
Validation loss: 2.2896442076681036

Epoch: 6| Step: 7
Training loss: 0.17537830581390623
Validation loss: 2.234802026299101

Epoch: 6| Step: 8
Training loss: 0.3120817723678713
Validation loss: 2.2669724940631073

Epoch: 6| Step: 9
Training loss: 0.19843219239353185
Validation loss: 2.2519066273984434

Epoch: 6| Step: 10
Training loss: 0.3176429504072224
Validation loss: 2.2840944874805498

Epoch: 6| Step: 11
Training loss: 0.2867590914834011
Validation loss: 2.2533081441751555

Epoch: 6| Step: 12
Training loss: 0.26025330505874217
Validation loss: 2.2782302774727934

Epoch: 6| Step: 13
Training loss: 0.3857600147618556
Validation loss: 2.2870250048930783

Epoch: 701| Step: 0
Training loss: 0.30481442228770583
Validation loss: 2.304540042042717

Epoch: 6| Step: 1
Training loss: 0.2201842394621765
Validation loss: 2.3176954441650053

Epoch: 6| Step: 2
Training loss: 0.30025823128603335
Validation loss: 2.3532384181648123

Epoch: 6| Step: 3
Training loss: 0.3014892938928801
Validation loss: 2.3687876345299905

Epoch: 6| Step: 4
Training loss: 0.42076643358528504
Validation loss: 2.378329171094306

Epoch: 6| Step: 5
Training loss: 0.30422933071253694
Validation loss: 2.3726122597028416

Epoch: 6| Step: 6
Training loss: 0.18647879420776584
Validation loss: 2.362069133397304

Epoch: 6| Step: 7
Training loss: 0.2606795446461963
Validation loss: 2.3879184853723863

Epoch: 6| Step: 8
Training loss: 0.3525709312173357
Validation loss: 2.3690190363470065

Epoch: 6| Step: 9
Training loss: 0.2686812224097341
Validation loss: 2.387335107984186

Epoch: 6| Step: 10
Training loss: 0.2669444970134066
Validation loss: 2.3563061973354955

Epoch: 6| Step: 11
Training loss: 0.3023854983385063
Validation loss: 2.3701774001067313

Epoch: 6| Step: 12
Training loss: 0.335802372658142
Validation loss: 2.371305812573883

Epoch: 6| Step: 13
Training loss: 0.3022629666895549
Validation loss: 2.3936737617735395

Epoch: 702| Step: 0
Training loss: 0.2909832110690739
Validation loss: 2.372462916089623

Epoch: 6| Step: 1
Training loss: 0.21564194916716004
Validation loss: 2.35251956817658

Epoch: 6| Step: 2
Training loss: 0.16592885161885776
Validation loss: 2.3563468780669083

Epoch: 6| Step: 3
Training loss: 0.2099646811927779
Validation loss: 2.376287730813212

Epoch: 6| Step: 4
Training loss: 0.23655269136339072
Validation loss: 2.3534477084182632

Epoch: 6| Step: 5
Training loss: 0.18914224739749716
Validation loss: 2.408759666569199

Epoch: 6| Step: 6
Training loss: 0.2350843107247028
Validation loss: 2.3582173280586964

Epoch: 6| Step: 7
Training loss: 0.3279346413434152
Validation loss: 2.347322910805539

Epoch: 6| Step: 8
Training loss: 0.2675041876224482
Validation loss: 2.3429607065904556

Epoch: 6| Step: 9
Training loss: 0.21189091815341698
Validation loss: 2.33044830837256

Epoch: 6| Step: 10
Training loss: 0.20511383472347539
Validation loss: 2.381728020630263

Epoch: 6| Step: 11
Training loss: 0.23536045801596936
Validation loss: 2.3530856126065105

Epoch: 6| Step: 12
Training loss: 0.3298561659102041
Validation loss: 2.3689680306889653

Epoch: 6| Step: 13
Training loss: 0.19103957106072866
Validation loss: 2.34179602329813

Epoch: 703| Step: 0
Training loss: 0.1344764897306353
Validation loss: 2.3699319826108707

Epoch: 6| Step: 1
Training loss: 0.1925125168935772
Validation loss: 2.419247153280068

Epoch: 6| Step: 2
Training loss: 0.1570528563538008
Validation loss: 2.4089395285228563

Epoch: 6| Step: 3
Training loss: 0.44796145754873623
Validation loss: 2.4128007706725376

Epoch: 6| Step: 4
Training loss: 0.2581342654377963
Validation loss: 2.425208061814701

Epoch: 6| Step: 5
Training loss: 0.24290288357430614
Validation loss: 2.450477935975942

Epoch: 6| Step: 6
Training loss: 0.25513191765878473
Validation loss: 2.4685382723668488

Epoch: 6| Step: 7
Training loss: 0.18447548584916074
Validation loss: 2.5028957198692994

Epoch: 6| Step: 8
Training loss: 0.26886889023624755
Validation loss: 2.4996610678348095

Epoch: 6| Step: 9
Training loss: 0.28269976903489685
Validation loss: 2.4854577812842558

Epoch: 6| Step: 10
Training loss: 0.42184886144972955
Validation loss: 2.4930116376861746

Epoch: 6| Step: 11
Training loss: 0.19374048840340605
Validation loss: 2.4438716917609935

Epoch: 6| Step: 12
Training loss: 0.257295813250365
Validation loss: 2.434238166601393

Epoch: 6| Step: 13
Training loss: 0.15565360212419307
Validation loss: 2.3852147433657986

Epoch: 704| Step: 0
Training loss: 0.20993866913274878
Validation loss: 2.338761349730613

Epoch: 6| Step: 1
Training loss: 0.2511380488754198
Validation loss: 2.2973355937904483

Epoch: 6| Step: 2
Training loss: 0.3740626182651572
Validation loss: 2.2842171342775637

Epoch: 6| Step: 3
Training loss: 0.32032122251218026
Validation loss: 2.3263252824677165

Epoch: 6| Step: 4
Training loss: 0.4583049371621562
Validation loss: 2.303073492122729

Epoch: 6| Step: 5
Training loss: 0.1633949322088548
Validation loss: 2.3194348141416654

Epoch: 6| Step: 6
Training loss: 0.29901974586684726
Validation loss: 2.3668487987719153

Epoch: 6| Step: 7
Training loss: 0.35733910941649816
Validation loss: 2.3472001111372855

Epoch: 6| Step: 8
Training loss: 0.17935459770249507
Validation loss: 2.3332269714562726

Epoch: 6| Step: 9
Training loss: 0.2155417115608236
Validation loss: 2.2917325775721324

Epoch: 6| Step: 10
Training loss: 0.30231014183201993
Validation loss: 2.3212803586767436

Epoch: 6| Step: 11
Training loss: 0.36745791927414817
Validation loss: 2.314075901922479

Epoch: 6| Step: 12
Training loss: 0.3465697423111128
Validation loss: 2.301485095182949

Epoch: 6| Step: 13
Training loss: 0.30447273755058696
Validation loss: 2.3298983413656478

Epoch: 705| Step: 0
Training loss: 0.2462455568905164
Validation loss: 2.336072764669805

Epoch: 6| Step: 1
Training loss: 0.243668809842727
Validation loss: 2.3871400769822784

Epoch: 6| Step: 2
Training loss: 0.2988427102512525
Validation loss: 2.38975433928004

Epoch: 6| Step: 3
Training loss: 0.3149622000993404
Validation loss: 2.399782476599962

Epoch: 6| Step: 4
Training loss: 0.3026050414413616
Validation loss: 2.410167017632257

Epoch: 6| Step: 5
Training loss: 0.20764768345989887
Validation loss: 2.401515652762351

Epoch: 6| Step: 6
Training loss: 0.2622998888339463
Validation loss: 2.4092406263813553

Epoch: 6| Step: 7
Training loss: 0.29224769869731243
Validation loss: 2.3886279218133

Epoch: 6| Step: 8
Training loss: 0.18446563093420032
Validation loss: 2.4062989859461688

Epoch: 6| Step: 9
Training loss: 0.25956244876566215
Validation loss: 2.383358555221511

Epoch: 6| Step: 10
Training loss: 0.24782741780736642
Validation loss: 2.393153717605988

Epoch: 6| Step: 11
Training loss: 0.30556594931500347
Validation loss: 2.3657101453543037

Epoch: 6| Step: 12
Training loss: 0.15448760063219963
Validation loss: 2.382109778768387

Epoch: 6| Step: 13
Training loss: 0.1930343130448255
Validation loss: 2.410427571583109

Epoch: 706| Step: 0
Training loss: 0.18802396757590284
Validation loss: 2.4078235837285447

Epoch: 6| Step: 1
Training loss: 0.1652852541459592
Validation loss: 2.3975056526230105

Epoch: 6| Step: 2
Training loss: 0.16018039823701044
Validation loss: 2.395733143627395

Epoch: 6| Step: 3
Training loss: 0.3016832747265276
Validation loss: 2.3866830242465147

Epoch: 6| Step: 4
Training loss: 0.281071288232912
Validation loss: 2.412723454357964

Epoch: 6| Step: 5
Training loss: 0.3362697023341547
Validation loss: 2.3703364662286255

Epoch: 6| Step: 6
Training loss: 0.2308708336531146
Validation loss: 2.375094181971818

Epoch: 6| Step: 7
Training loss: 0.2675110809535587
Validation loss: 2.3508773905156914

Epoch: 6| Step: 8
Training loss: 0.19795103255778507
Validation loss: 2.354278853263699

Epoch: 6| Step: 9
Training loss: 0.24659470629455288
Validation loss: 2.3648003017911

Epoch: 6| Step: 10
Training loss: 0.27224123721036664
Validation loss: 2.4129496612974055

Epoch: 6| Step: 11
Training loss: 0.20041924025065538
Validation loss: 2.363056218996576

Epoch: 6| Step: 12
Training loss: 0.25323453228777854
Validation loss: 2.349686530323347

Epoch: 6| Step: 13
Training loss: 0.21310213938236172
Validation loss: 2.3752452359962697

Epoch: 707| Step: 0
Training loss: 0.14806371608152605
Validation loss: 2.342956502714509

Epoch: 6| Step: 1
Training loss: 0.15470731444562263
Validation loss: 2.370040506367494

Epoch: 6| Step: 2
Training loss: 0.256761358768517
Validation loss: 2.3588594828142795

Epoch: 6| Step: 3
Training loss: 0.14197489096593188
Validation loss: 2.3316395108096453

Epoch: 6| Step: 4
Training loss: 0.25721668986242924
Validation loss: 2.3484158216974196

Epoch: 6| Step: 5
Training loss: 0.16285970838143532
Validation loss: 2.3278378611486827

Epoch: 6| Step: 6
Training loss: 0.2772376031976294
Validation loss: 2.3088037183572

Epoch: 6| Step: 7
Training loss: 0.21539873054647446
Validation loss: 2.2739285067556314

Epoch: 6| Step: 8
Training loss: 0.1982421875
Validation loss: 2.273031429291746

Epoch: 6| Step: 9
Training loss: 0.14717119057716205
Validation loss: 2.2414278230767084

Epoch: 6| Step: 10
Training loss: 0.23638655200389133
Validation loss: 2.237772144305947

Epoch: 6| Step: 11
Training loss: 0.35236130139942984
Validation loss: 2.2818509129524305

Epoch: 6| Step: 12
Training loss: 0.2549514239689842
Validation loss: 2.2796688924714026

Epoch: 6| Step: 13
Training loss: 0.27199027040379276
Validation loss: 2.291210774319318

Epoch: 708| Step: 0
Training loss: 0.16618785899648236
Validation loss: 2.3079081528659313

Epoch: 6| Step: 1
Training loss: 0.10500086209249812
Validation loss: 2.3198032178634063

Epoch: 6| Step: 2
Training loss: 0.19057140456777236
Validation loss: 2.327906172492189

Epoch: 6| Step: 3
Training loss: 0.18058658691329088
Validation loss: 2.3072471157872743

Epoch: 6| Step: 4
Training loss: 0.15519456239601137
Validation loss: 2.346523524681919

Epoch: 6| Step: 5
Training loss: 0.180555125204413
Validation loss: 2.3395945407927465

Epoch: 6| Step: 6
Training loss: 0.15805676247842762
Validation loss: 2.3474503913296036

Epoch: 6| Step: 7
Training loss: 0.229807811160129
Validation loss: 2.3610365837505016

Epoch: 6| Step: 8
Training loss: 0.19904838083759013
Validation loss: 2.364151019641366

Epoch: 6| Step: 9
Training loss: 0.24913096630792003
Validation loss: 2.368822148856056

Epoch: 6| Step: 10
Training loss: 0.23563123049707232
Validation loss: 2.3701723986723215

Epoch: 6| Step: 11
Training loss: 0.18507290586018244
Validation loss: 2.360958065109175

Epoch: 6| Step: 12
Training loss: 0.1423145627729637
Validation loss: 2.3876550295207526

Epoch: 6| Step: 13
Training loss: 0.25944879757409
Validation loss: 2.3777285825017223

Epoch: 709| Step: 0
Training loss: 0.21006754453095894
Validation loss: 2.3842572159433226

Epoch: 6| Step: 1
Training loss: 0.18538201687870476
Validation loss: 2.351289728351335

Epoch: 6| Step: 2
Training loss: 0.23672921060041763
Validation loss: 2.3591387132680226

Epoch: 6| Step: 3
Training loss: 0.16402663111274693
Validation loss: 2.341699542519604

Epoch: 6| Step: 4
Training loss: 0.1994411965645949
Validation loss: 2.3697409809096186

Epoch: 6| Step: 5
Training loss: 0.17359011675468686
Validation loss: 2.32771506771011

Epoch: 6| Step: 6
Training loss: 0.14167482519733043
Validation loss: 2.3190385902526054

Epoch: 6| Step: 7
Training loss: 0.15943131714036254
Validation loss: 2.3441498347677183

Epoch: 6| Step: 8
Training loss: 0.20262521917965498
Validation loss: 2.3289363075394407

Epoch: 6| Step: 9
Training loss: 0.19569298875945806
Validation loss: 2.3487715460758984

Epoch: 6| Step: 10
Training loss: 0.1411442310223535
Validation loss: 2.334705187553262

Epoch: 6| Step: 11
Training loss: 0.1485380346757928
Validation loss: 2.3736395876832614

Epoch: 6| Step: 12
Training loss: 0.14144236725124604
Validation loss: 2.3790307924263683

Epoch: 6| Step: 13
Training loss: 0.1527343901222007
Validation loss: 2.372453305374176

Epoch: 710| Step: 0
Training loss: 0.1086840689651163
Validation loss: 2.367966880898693

Epoch: 6| Step: 1
Training loss: 0.1901733237808351
Validation loss: 2.3984413501008084

Epoch: 6| Step: 2
Training loss: 0.1509189922820867
Validation loss: 2.3864590343567897

Epoch: 6| Step: 3
Training loss: 0.23932031865970305
Validation loss: 2.3959475075872727

Epoch: 6| Step: 4
Training loss: 0.21067810003336312
Validation loss: 2.3701691813729178

Epoch: 6| Step: 5
Training loss: 0.14217610706545963
Validation loss: 2.3830080605365156

Epoch: 6| Step: 6
Training loss: 0.12641259811691405
Validation loss: 2.376502129257603

Epoch: 6| Step: 7
Training loss: 0.16555565335959263
Validation loss: 2.3618166922668404

Epoch: 6| Step: 8
Training loss: 0.17263270925334132
Validation loss: 2.3268697597254526

Epoch: 6| Step: 9
Training loss: 0.1581613226399112
Validation loss: 2.3337741796459155

Epoch: 6| Step: 10
Training loss: 0.18919928741217554
Validation loss: 2.3427594489867722

Epoch: 6| Step: 11
Training loss: 0.21793884359306043
Validation loss: 2.330607215072697

Epoch: 6| Step: 12
Training loss: 0.1924472449208788
Validation loss: 2.3299595878374766

Epoch: 6| Step: 13
Training loss: 0.16034828861067923
Validation loss: 2.343340789456635

Epoch: 711| Step: 0
Training loss: 0.18409677340217245
Validation loss: 2.308860655524505

Epoch: 6| Step: 1
Training loss: 0.20401187002836066
Validation loss: 2.3446279750362753

Epoch: 6| Step: 2
Training loss: 0.15641616687909055
Validation loss: 2.327719299112186

Epoch: 6| Step: 3
Training loss: 0.1429899747133636
Validation loss: 2.3367095734794394

Epoch: 6| Step: 4
Training loss: 0.08776402096982948
Validation loss: 2.3523809591954326

Epoch: 6| Step: 5
Training loss: 0.15926575235537438
Validation loss: 2.3140970561526157

Epoch: 6| Step: 6
Training loss: 0.150669718293267
Validation loss: 2.340102289017853

Epoch: 6| Step: 7
Training loss: 0.2344649460179039
Validation loss: 2.3492957174080873

Epoch: 6| Step: 8
Training loss: 0.2238518254645963
Validation loss: 2.3521396995740083

Epoch: 6| Step: 9
Training loss: 0.18995827254305322
Validation loss: 2.373020512981228

Epoch: 6| Step: 10
Training loss: 0.15456620383230701
Validation loss: 2.386190018688233

Epoch: 6| Step: 11
Training loss: 0.11801704214066688
Validation loss: 2.4041997876731793

Epoch: 6| Step: 12
Training loss: 0.16662584800854988
Validation loss: 2.4101972141860863

Epoch: 6| Step: 13
Training loss: 0.10171031740425757
Validation loss: 2.3884822425505305

Epoch: 712| Step: 0
Training loss: 0.1944365121343637
Validation loss: 2.3929226047494567

Epoch: 6| Step: 1
Training loss: 0.14651744469245606
Validation loss: 2.3919922400590914

Epoch: 6| Step: 2
Training loss: 0.13338741519458053
Validation loss: 2.407375501831537

Epoch: 6| Step: 3
Training loss: 0.14746508055670943
Validation loss: 2.41687132286976

Epoch: 6| Step: 4
Training loss: 0.1687032255056014
Validation loss: 2.4214163397174495

Epoch: 6| Step: 5
Training loss: 0.13124762061777942
Validation loss: 2.3887228366304636

Epoch: 6| Step: 6
Training loss: 0.1395016078390589
Validation loss: 2.4048984323801603

Epoch: 6| Step: 7
Training loss: 0.20210607517882628
Validation loss: 2.3912051158724736

Epoch: 6| Step: 8
Training loss: 0.17232167657686792
Validation loss: 2.385337402327944

Epoch: 6| Step: 9
Training loss: 0.10245558656019164
Validation loss: 2.372051209975742

Epoch: 6| Step: 10
Training loss: 0.1549222321152719
Validation loss: 2.3878063829762155

Epoch: 6| Step: 11
Training loss: 0.16273243218487843
Validation loss: 2.3761183378433843

Epoch: 6| Step: 12
Training loss: 0.1985590521171184
Validation loss: 2.4021330005916375

Epoch: 6| Step: 13
Training loss: 0.11509323771262008
Validation loss: 2.386352567900539

Epoch: 713| Step: 0
Training loss: 0.11018285683652468
Validation loss: 2.398250433450898

Epoch: 6| Step: 1
Training loss: 0.1215421159172757
Validation loss: 2.384979940665313

Epoch: 6| Step: 2
Training loss: 0.08504251696062853
Validation loss: 2.3782730799615743

Epoch: 6| Step: 3
Training loss: 0.12163411981783101
Validation loss: 2.36329834010739

Epoch: 6| Step: 4
Training loss: 0.16388600938116346
Validation loss: 2.3810302169151103

Epoch: 6| Step: 5
Training loss: 0.1254649456012711
Validation loss: 2.33598250715008

Epoch: 6| Step: 6
Training loss: 0.17479835264352528
Validation loss: 2.3775622358511925

Epoch: 6| Step: 7
Training loss: 0.09411994639700891
Validation loss: 2.3559659415702514

Epoch: 6| Step: 8
Training loss: 0.11042029426196806
Validation loss: 2.3521026578562574

Epoch: 6| Step: 9
Training loss: 0.1510814060900786
Validation loss: 2.3703857679643887

Epoch: 6| Step: 10
Training loss: 0.14634280675420758
Validation loss: 2.413750100722637

Epoch: 6| Step: 11
Training loss: 0.13203528838217204
Validation loss: 2.3897150216470493

Epoch: 6| Step: 12
Training loss: 0.16792578480372292
Validation loss: 2.390967077383624

Epoch: 6| Step: 13
Training loss: 0.10377931747228121
Validation loss: 2.4169029418073813

Epoch: 714| Step: 0
Training loss: 0.16225306336034054
Validation loss: 2.404240651816683

Epoch: 6| Step: 1
Training loss: 0.18360736471787573
Validation loss: 2.403345687212302

Epoch: 6| Step: 2
Training loss: 0.1628775550209325
Validation loss: 2.4068141351071786

Epoch: 6| Step: 3
Training loss: 0.11837560067205688
Validation loss: 2.4398810350444546

Epoch: 6| Step: 4
Training loss: 0.20522273278586664
Validation loss: 2.4442030419673317

Epoch: 6| Step: 5
Training loss: 0.16544175537481812
Validation loss: 2.4404366973923475

Epoch: 6| Step: 6
Training loss: 0.17067243618808714
Validation loss: 2.4653388065554744

Epoch: 6| Step: 7
Training loss: 0.16491042998703426
Validation loss: 2.4428503447075247

Epoch: 6| Step: 8
Training loss: 0.12163937223790183
Validation loss: 2.4359594293155182

Epoch: 6| Step: 9
Training loss: 0.12724905003284884
Validation loss: 2.436645722543369

Epoch: 6| Step: 10
Training loss: 0.16314592799955774
Validation loss: 2.4401875670322184

Epoch: 6| Step: 11
Training loss: 0.09418291234333996
Validation loss: 2.4146585020457487

Epoch: 6| Step: 12
Training loss: 0.18259195163591346
Validation loss: 2.4062862694484854

Epoch: 6| Step: 13
Training loss: 0.1926124383561014
Validation loss: 2.403215323753809

Epoch: 715| Step: 0
Training loss: 0.1255611846165663
Validation loss: 2.4231857346641603

Epoch: 6| Step: 1
Training loss: 0.1437210753614174
Validation loss: 2.4103446393938315

Epoch: 6| Step: 2
Training loss: 0.20062356129840506
Validation loss: 2.3964025531924906

Epoch: 6| Step: 3
Training loss: 0.11345244083978427
Validation loss: 2.396564691600093

Epoch: 6| Step: 4
Training loss: 0.15665277781158962
Validation loss: 2.403688708087967

Epoch: 6| Step: 5
Training loss: 0.15672510751283042
Validation loss: 2.3890064338486843

Epoch: 6| Step: 6
Training loss: 0.09760297752746389
Validation loss: 2.4034235942680104

Epoch: 6| Step: 7
Training loss: 0.10800915487879714
Validation loss: 2.4155006955209384

Epoch: 6| Step: 8
Training loss: 0.1697084796960925
Validation loss: 2.3613814941276927

Epoch: 6| Step: 9
Training loss: 0.17901760117607993
Validation loss: 2.3724060054773632

Epoch: 6| Step: 10
Training loss: 0.1395294242517306
Validation loss: 2.3682336711897314

Epoch: 6| Step: 11
Training loss: 0.17906655954416104
Validation loss: 2.3848088549547684

Epoch: 6| Step: 12
Training loss: 0.23228113737890088
Validation loss: 2.379525575403584

Epoch: 6| Step: 13
Training loss: 0.1302983513247659
Validation loss: 2.4035123519747317

Epoch: 716| Step: 0
Training loss: 0.10087487931906089
Validation loss: 2.3606831249767466

Epoch: 6| Step: 1
Training loss: 0.08406303293030856
Validation loss: 2.342519712598176

Epoch: 6| Step: 2
Training loss: 0.14118723927685295
Validation loss: 2.3452548527619546

Epoch: 6| Step: 3
Training loss: 0.12375049895609827
Validation loss: 2.357609005947771

Epoch: 6| Step: 4
Training loss: 0.06974256182348253
Validation loss: 2.3552665859735042

Epoch: 6| Step: 5
Training loss: 0.1746431595378713
Validation loss: 2.373161401402688

Epoch: 6| Step: 6
Training loss: 0.09866902659118822
Validation loss: 2.34663342159854

Epoch: 6| Step: 7
Training loss: 0.11277178776019603
Validation loss: 2.3702895288682413

Epoch: 6| Step: 8
Training loss: 0.11670864338506208
Validation loss: 2.3431539410626776

Epoch: 6| Step: 9
Training loss: 0.11093404522741514
Validation loss: 2.366400336387828

Epoch: 6| Step: 10
Training loss: 0.11926012221872631
Validation loss: 2.377111643623092

Epoch: 6| Step: 11
Training loss: 0.11392855683517533
Validation loss: 2.4133976473040315

Epoch: 6| Step: 12
Training loss: 0.13407203931592787
Validation loss: 2.419369429130722

Epoch: 6| Step: 13
Training loss: 0.12038973768972956
Validation loss: 2.4000387765031794

Epoch: 717| Step: 0
Training loss: 0.10683904674685063
Validation loss: 2.4238432551012035

Epoch: 6| Step: 1
Training loss: 0.10913281364312569
Validation loss: 2.40763443831866

Epoch: 6| Step: 2
Training loss: 0.09595006108761622
Validation loss: 2.4396517416660783

Epoch: 6| Step: 3
Training loss: 0.11265030628296892
Validation loss: 2.423191737538286

Epoch: 6| Step: 4
Training loss: 0.16971431310456017
Validation loss: 2.4039343468332706

Epoch: 6| Step: 5
Training loss: 0.11592137300398321
Validation loss: 2.4141756323203114

Epoch: 6| Step: 6
Training loss: 0.13298254487261135
Validation loss: 2.4175894330363996

Epoch: 6| Step: 7
Training loss: 0.2017110617167525
Validation loss: 2.4332215544609563

Epoch: 6| Step: 8
Training loss: 0.11175157924950713
Validation loss: 2.394555153684187

Epoch: 6| Step: 9
Training loss: 0.15013072853847434
Validation loss: 2.3982869393235884

Epoch: 6| Step: 10
Training loss: 0.08883616146884349
Validation loss: 2.386687715027628

Epoch: 6| Step: 11
Training loss: 0.09295195419797649
Validation loss: 2.3507384191518157

Epoch: 6| Step: 12
Training loss: 0.1318538159151134
Validation loss: 2.3614363906134512

Epoch: 6| Step: 13
Training loss: 0.11954391730262871
Validation loss: 2.33590053224959

Epoch: 718| Step: 0
Training loss: 0.11019941830076968
Validation loss: 2.3309181068509512

Epoch: 6| Step: 1
Training loss: 0.1520355849123406
Validation loss: 2.3483644438700373

Epoch: 6| Step: 2
Training loss: 0.11498086328246006
Validation loss: 2.3457721903830913

Epoch: 6| Step: 3
Training loss: 0.14584291517477715
Validation loss: 2.331197753116682

Epoch: 6| Step: 4
Training loss: 0.1681616030877621
Validation loss: 2.319127635710129

Epoch: 6| Step: 5
Training loss: 0.08011335958489746
Validation loss: 2.3256462684446313

Epoch: 6| Step: 6
Training loss: 0.15185251263749408
Validation loss: 2.3631681768611394

Epoch: 6| Step: 7
Training loss: 0.11318283080797548
Validation loss: 2.337361877863404

Epoch: 6| Step: 8
Training loss: 0.15502986757669007
Validation loss: 2.375171389653668

Epoch: 6| Step: 9
Training loss: 0.12012406461303882
Validation loss: 2.345703890036348

Epoch: 6| Step: 10
Training loss: 0.11723132506105433
Validation loss: 2.3460863288839415

Epoch: 6| Step: 11
Training loss: 0.09541231853803193
Validation loss: 2.37099163763151

Epoch: 6| Step: 12
Training loss: 0.12003913917874222
Validation loss: 2.349257760571949

Epoch: 6| Step: 13
Training loss: 0.09946471817966882
Validation loss: 2.325588828379869

Epoch: 719| Step: 0
Training loss: 0.06880373602229059
Validation loss: 2.341482367948664

Epoch: 6| Step: 1
Training loss: 0.10356434988891694
Validation loss: 2.3380487449044876

Epoch: 6| Step: 2
Training loss: 0.15375072056516187
Validation loss: 2.3558221960421686

Epoch: 6| Step: 3
Training loss: 0.11592120428800105
Validation loss: 2.3474742114555704

Epoch: 6| Step: 4
Training loss: 0.0946081542259982
Validation loss: 2.328340313283111

Epoch: 6| Step: 5
Training loss: 0.07979987521140151
Validation loss: 2.3134128251135704

Epoch: 6| Step: 6
Training loss: 0.06887686901014377
Validation loss: 2.306405961164809

Epoch: 6| Step: 7
Training loss: 0.13958952401320593
Validation loss: 2.333824394634418

Epoch: 6| Step: 8
Training loss: 0.12915096751554758
Validation loss: 2.3007419969407583

Epoch: 6| Step: 9
Training loss: 0.15925266488658663
Validation loss: 2.3255674744284995

Epoch: 6| Step: 10
Training loss: 0.12067287507359613
Validation loss: 2.3221149831604135

Epoch: 6| Step: 11
Training loss: 0.11810301551523075
Validation loss: 2.33146101148845

Epoch: 6| Step: 12
Training loss: 0.15925409181209715
Validation loss: 2.325182562594033

Epoch: 6| Step: 13
Training loss: 0.07320564311998173
Validation loss: 2.338263452468473

Epoch: 720| Step: 0
Training loss: 0.07262780955718724
Validation loss: 2.3558144729689063

Epoch: 6| Step: 1
Training loss: 0.10541026383472753
Validation loss: 2.3312553408999594

Epoch: 6| Step: 2
Training loss: 0.08822944553761658
Validation loss: 2.343322047605487

Epoch: 6| Step: 3
Training loss: 0.11693272711536397
Validation loss: 2.36074525707892

Epoch: 6| Step: 4
Training loss: 0.11932201335481256
Validation loss: 2.3606545875779323

Epoch: 6| Step: 5
Training loss: 0.10444433685316146
Validation loss: 2.382240935601249

Epoch: 6| Step: 6
Training loss: 0.08696010527308083
Validation loss: 2.39018176449244

Epoch: 6| Step: 7
Training loss: 0.09981620110019813
Validation loss: 2.4245448126015194

Epoch: 6| Step: 8
Training loss: 0.08401054706413585
Validation loss: 2.402058045367172

Epoch: 6| Step: 9
Training loss: 0.1361114912152119
Validation loss: 2.405132064370771

Epoch: 6| Step: 10
Training loss: 0.08829543613708775
Validation loss: 2.4349731376887678

Epoch: 6| Step: 11
Training loss: 0.1083702617833743
Validation loss: 2.428044402752532

Epoch: 6| Step: 12
Training loss: 0.09741189904058785
Validation loss: 2.412883503164096

Epoch: 6| Step: 13
Training loss: 0.08459334214083651
Validation loss: 2.4042867858887758

Epoch: 721| Step: 0
Training loss: 0.08535771511432434
Validation loss: 2.41135198758685

Epoch: 6| Step: 1
Training loss: 0.08894785164989545
Validation loss: 2.4210598386528215

Epoch: 6| Step: 2
Training loss: 0.0971027327803168
Validation loss: 2.4040184263274593

Epoch: 6| Step: 3
Training loss: 0.12211903553393455
Validation loss: 2.4032123971111994

Epoch: 6| Step: 4
Training loss: 0.08751896318516493
Validation loss: 2.4134293930788733

Epoch: 6| Step: 5
Training loss: 0.14077582483285395
Validation loss: 2.4024214313072103

Epoch: 6| Step: 6
Training loss: 0.10737309648860463
Validation loss: 2.3872081075740113

Epoch: 6| Step: 7
Training loss: 0.11306931137910081
Validation loss: 2.3967561267943003

Epoch: 6| Step: 8
Training loss: 0.09672221298519842
Validation loss: 2.3871802279676824

Epoch: 6| Step: 9
Training loss: 0.07586331102902835
Validation loss: 2.373740173503363

Epoch: 6| Step: 10
Training loss: 0.08933451672663972
Validation loss: 2.3858973607231366

Epoch: 6| Step: 11
Training loss: 0.08753865018489615
Validation loss: 2.3837608544134983

Epoch: 6| Step: 12
Training loss: 0.10893532390905088
Validation loss: 2.3563144704067933

Epoch: 6| Step: 13
Training loss: 0.06542583710457811
Validation loss: 2.401758135431722

Epoch: 722| Step: 0
Training loss: 0.08997413772789625
Validation loss: 2.3681344742359554

Epoch: 6| Step: 1
Training loss: 0.04950301584806438
Validation loss: 2.3909510262093954

Epoch: 6| Step: 2
Training loss: 0.09658022783406636
Validation loss: 2.383634975429067

Epoch: 6| Step: 3
Training loss: 0.0981498925561895
Validation loss: 2.382830757758389

Epoch: 6| Step: 4
Training loss: 0.07009557534373889
Validation loss: 2.3789603422866175

Epoch: 6| Step: 5
Training loss: 0.08113865352426831
Validation loss: 2.3536857128571373

Epoch: 6| Step: 6
Training loss: 0.10352558861771034
Validation loss: 2.378379467231736

Epoch: 6| Step: 7
Training loss: 0.09980970228253742
Validation loss: 2.360959875759345

Epoch: 6| Step: 8
Training loss: 0.08466869824721102
Validation loss: 2.387871039826469

Epoch: 6| Step: 9
Training loss: 0.10748288416171693
Validation loss: 2.372646930981019

Epoch: 6| Step: 10
Training loss: 0.07151316990429397
Validation loss: 2.3558303652566854

Epoch: 6| Step: 11
Training loss: 0.13922020135416271
Validation loss: 2.384505618142194

Epoch: 6| Step: 12
Training loss: 0.08519452147136272
Validation loss: 2.381647246209617

Epoch: 6| Step: 13
Training loss: 0.07555610008682423
Validation loss: 2.363095097645734

Epoch: 723| Step: 0
Training loss: 0.0827000944865911
Validation loss: 2.378808507900463

Epoch: 6| Step: 1
Training loss: 0.09052580078028132
Validation loss: 2.371130014180655

Epoch: 6| Step: 2
Training loss: 0.06789462964458083
Validation loss: 2.377592130542781

Epoch: 6| Step: 3
Training loss: 0.11529994973837493
Validation loss: 2.3569888635752596

Epoch: 6| Step: 4
Training loss: 0.06956489129553284
Validation loss: 2.3871327817097407

Epoch: 6| Step: 5
Training loss: 0.07839616268052706
Validation loss: 2.3748604205079618

Epoch: 6| Step: 6
Training loss: 0.06223090176440366
Validation loss: 2.360602976558662

Epoch: 6| Step: 7
Training loss: 0.07849608742855566
Validation loss: 2.340931007205113

Epoch: 6| Step: 8
Training loss: 0.10758728816637698
Validation loss: 2.363345136179804

Epoch: 6| Step: 9
Training loss: 0.09506527817821718
Validation loss: 2.3376258364806284

Epoch: 6| Step: 10
Training loss: 0.11547066014610818
Validation loss: 2.3262254952570647

Epoch: 6| Step: 11
Training loss: 0.14184461320730818
Validation loss: 2.3347605339385313

Epoch: 6| Step: 12
Training loss: 0.07867107873000359
Validation loss: 2.3798320386021956

Epoch: 6| Step: 13
Training loss: 0.08824407450957873
Validation loss: 2.3747568529551386

Epoch: 724| Step: 0
Training loss: 0.11467815173324189
Validation loss: 2.3888659234869563

Epoch: 6| Step: 1
Training loss: 0.10061185003033492
Validation loss: 2.364412352965894

Epoch: 6| Step: 2
Training loss: 0.06193914258972469
Validation loss: 2.3863810662928993

Epoch: 6| Step: 3
Training loss: 0.09217802520327797
Validation loss: 2.396506803286456

Epoch: 6| Step: 4
Training loss: 0.13416849059095257
Validation loss: 2.3882369998370807

Epoch: 6| Step: 5
Training loss: 0.059398308997295576
Validation loss: 2.403422576138909

Epoch: 6| Step: 6
Training loss: 0.06966288808739857
Validation loss: 2.402840154266812

Epoch: 6| Step: 7
Training loss: 0.07870874768658906
Validation loss: 2.3884419245426147

Epoch: 6| Step: 8
Training loss: 0.09163586720427444
Validation loss: 2.390460835036708

Epoch: 6| Step: 9
Training loss: 0.09440204247130513
Validation loss: 2.3833399314826327

Epoch: 6| Step: 10
Training loss: 0.06211671613397568
Validation loss: 2.415931826146509

Epoch: 6| Step: 11
Training loss: 0.10101404103263824
Validation loss: 2.385840839875924

Epoch: 6| Step: 12
Training loss: 0.07241863085034979
Validation loss: 2.355782423631065

Epoch: 6| Step: 13
Training loss: 0.10602497963335093
Validation loss: 2.4053346128358477

Epoch: 725| Step: 0
Training loss: 0.10944075396055729
Validation loss: 2.3824501562289666

Epoch: 6| Step: 1
Training loss: 0.11118438710609588
Validation loss: 2.3788452862654945

Epoch: 6| Step: 2
Training loss: 0.09344816793667307
Validation loss: 2.362091497742236

Epoch: 6| Step: 3
Training loss: 0.05106504624168758
Validation loss: 2.3534604653255045

Epoch: 6| Step: 4
Training loss: 0.11981660170466574
Validation loss: 2.3600021937957822

Epoch: 6| Step: 5
Training loss: 0.12629861105901188
Validation loss: 2.357984769313628

Epoch: 6| Step: 6
Training loss: 0.06006348597752316
Validation loss: 2.3826231920450995

Epoch: 6| Step: 7
Training loss: 0.07198011212181149
Validation loss: 2.3891727852437636

Epoch: 6| Step: 8
Training loss: 0.08992122854568811
Validation loss: 2.399976526166089

Epoch: 6| Step: 9
Training loss: 0.06404089592466965
Validation loss: 2.3842303897143355

Epoch: 6| Step: 10
Training loss: 0.0861241335183352
Validation loss: 2.375655940200664

Epoch: 6| Step: 11
Training loss: 0.09772163586339773
Validation loss: 2.399674483304659

Epoch: 6| Step: 12
Training loss: 0.11900880431314939
Validation loss: 2.3788667061922792

Epoch: 6| Step: 13
Training loss: 0.07876946353507448
Validation loss: 2.3935424227607474

Epoch: 726| Step: 0
Training loss: 0.09960314787305287
Validation loss: 2.3872328193995322

Epoch: 6| Step: 1
Training loss: 0.06360195685722317
Validation loss: 2.3768013479100034

Epoch: 6| Step: 2
Training loss: 0.10232769661861914
Validation loss: 2.3800494655154103

Epoch: 6| Step: 3
Training loss: 0.09861519627894205
Validation loss: 2.3965865051243043

Epoch: 6| Step: 4
Training loss: 0.07246099945024582
Validation loss: 2.4034739583203173

Epoch: 6| Step: 5
Training loss: 0.08425725087370824
Validation loss: 2.3715126856961954

Epoch: 6| Step: 6
Training loss: 0.07236845201353045
Validation loss: 2.3669388605719712

Epoch: 6| Step: 7
Training loss: 0.0717432888494393
Validation loss: 2.401448198028354

Epoch: 6| Step: 8
Training loss: 0.0788514899747971
Validation loss: 2.389744222564782

Epoch: 6| Step: 9
Training loss: 0.1743903871296577
Validation loss: 2.3769606736942204

Epoch: 6| Step: 10
Training loss: 0.09096077854562311
Validation loss: 2.389376874347251

Epoch: 6| Step: 11
Training loss: 0.05154679801668638
Validation loss: 2.365677148023631

Epoch: 6| Step: 12
Training loss: 0.09669364481660049
Validation loss: 2.3854106174522514

Epoch: 6| Step: 13
Training loss: 0.06903482588753336
Validation loss: 2.3677316600175855

Epoch: 727| Step: 0
Training loss: 0.07679736862916525
Validation loss: 2.394314094220851

Epoch: 6| Step: 1
Training loss: 0.10070622298075109
Validation loss: 2.363321411474973

Epoch: 6| Step: 2
Training loss: 0.07440108877010722
Validation loss: 2.3831630239841863

Epoch: 6| Step: 3
Training loss: 0.10773675026602321
Validation loss: 2.3834169726242607

Epoch: 6| Step: 4
Training loss: 0.10008264289473415
Validation loss: 2.3585424545483886

Epoch: 6| Step: 5
Training loss: 0.09482740167054993
Validation loss: 2.365993963862483

Epoch: 6| Step: 6
Training loss: 0.10093119079695115
Validation loss: 2.3472674106509217

Epoch: 6| Step: 7
Training loss: 0.11000875378586558
Validation loss: 2.385584953774708

Epoch: 6| Step: 8
Training loss: 0.10592389797277112
Validation loss: 2.371666598851363

Epoch: 6| Step: 9
Training loss: 0.12156085707037238
Validation loss: 2.3824169075993136

Epoch: 6| Step: 10
Training loss: 0.06443883275023715
Validation loss: 2.352346904122865

Epoch: 6| Step: 11
Training loss: 0.08128237629439727
Validation loss: 2.361148942342303

Epoch: 6| Step: 12
Training loss: 0.08782649349562908
Validation loss: 2.3656937954807478

Epoch: 6| Step: 13
Training loss: 0.06725611385199276
Validation loss: 2.3633541591201155

Epoch: 728| Step: 0
Training loss: 0.06994252086561918
Validation loss: 2.362083972075893

Epoch: 6| Step: 1
Training loss: 0.11016360454492545
Validation loss: 2.365304321361457

Epoch: 6| Step: 2
Training loss: 0.10330138889508356
Validation loss: 2.372729020948632

Epoch: 6| Step: 3
Training loss: 0.08202734154518161
Validation loss: 2.3589443847972893

Epoch: 6| Step: 4
Training loss: 0.05907811790305849
Validation loss: 2.327714528046096

Epoch: 6| Step: 5
Training loss: 0.07594822487526377
Validation loss: 2.348130226524553

Epoch: 6| Step: 6
Training loss: 0.08353518245875884
Validation loss: 2.3744626843374976

Epoch: 6| Step: 7
Training loss: 0.08485903054358683
Validation loss: 2.3386049102892543

Epoch: 6| Step: 8
Training loss: 0.12177319798758333
Validation loss: 2.311728187100428

Epoch: 6| Step: 9
Training loss: 0.1378244984414212
Validation loss: 2.338467223478494

Epoch: 6| Step: 10
Training loss: 0.07086865690270457
Validation loss: 2.3228907194435364

Epoch: 6| Step: 11
Training loss: 0.14098147404064357
Validation loss: 2.334342394096164

Epoch: 6| Step: 12
Training loss: 0.10959369644493315
Validation loss: 2.319997124735571

Epoch: 6| Step: 13
Training loss: 0.14355431770744184
Validation loss: 2.323679268307963

Epoch: 729| Step: 0
Training loss: 0.07133330970797935
Validation loss: 2.3137126870274924

Epoch: 6| Step: 1
Training loss: 0.0864577988407933
Validation loss: 2.3255725144681514

Epoch: 6| Step: 2
Training loss: 0.049266643723245976
Validation loss: 2.3237382642557995

Epoch: 6| Step: 3
Training loss: 0.10537100607202822
Validation loss: 2.322022621965927

Epoch: 6| Step: 4
Training loss: 0.04229199594238738
Validation loss: 2.3442928765630984

Epoch: 6| Step: 5
Training loss: 0.08059571051126675
Validation loss: 2.3392624024736506

Epoch: 6| Step: 6
Training loss: 0.08105457834443246
Validation loss: 2.3371379726804937

Epoch: 6| Step: 7
Training loss: 0.06580778732888053
Validation loss: 2.356041935542678

Epoch: 6| Step: 8
Training loss: 0.10879030791961762
Validation loss: 2.355891490910683

Epoch: 6| Step: 9
Training loss: 0.1358444459904791
Validation loss: 2.3711177094024722

Epoch: 6| Step: 10
Training loss: 0.06292785289038942
Validation loss: 2.37546652382264

Epoch: 6| Step: 11
Training loss: 0.09180047149917601
Validation loss: 2.3774131050558673

Epoch: 6| Step: 12
Training loss: 0.09687905995259978
Validation loss: 2.36423523226055

Epoch: 6| Step: 13
Training loss: 0.08153689241897857
Validation loss: 2.36473027818461

Epoch: 730| Step: 0
Training loss: 0.06505311235683457
Validation loss: 2.359975142912038

Epoch: 6| Step: 1
Training loss: 0.06415350224844245
Validation loss: 2.3451999251181532

Epoch: 6| Step: 2
Training loss: 0.11487758488387899
Validation loss: 2.362431257035284

Epoch: 6| Step: 3
Training loss: 0.05660467404513247
Validation loss: 2.3864886854709333

Epoch: 6| Step: 4
Training loss: 0.10305042821789631
Validation loss: 2.358769900499853

Epoch: 6| Step: 5
Training loss: 0.11140082311319738
Validation loss: 2.393230252690428

Epoch: 6| Step: 6
Training loss: 0.07584624808908448
Validation loss: 2.3710489552149707

Epoch: 6| Step: 7
Training loss: 0.05716937620543677
Validation loss: 2.381290816404931

Epoch: 6| Step: 8
Training loss: 0.07513459962454996
Validation loss: 2.3812884888463963

Epoch: 6| Step: 9
Training loss: 0.09617315884158538
Validation loss: 2.349047871101813

Epoch: 6| Step: 10
Training loss: 0.1285293154395843
Validation loss: 2.3687942065358287

Epoch: 6| Step: 11
Training loss: 0.071040736727324
Validation loss: 2.3902684392938895

Epoch: 6| Step: 12
Training loss: 0.10431175161553784
Validation loss: 2.3559942006154446

Epoch: 6| Step: 13
Training loss: 0.12329901112228944
Validation loss: 2.3906804131371047

Epoch: 731| Step: 0
Training loss: 0.11322024774679441
Validation loss: 2.3883780742292755

Epoch: 6| Step: 1
Training loss: 0.08564979989386975
Validation loss: 2.360080801673977

Epoch: 6| Step: 2
Training loss: 0.0712989447550544
Validation loss: 2.3819516180631943

Epoch: 6| Step: 3
Training loss: 0.08054582737593803
Validation loss: 2.38966424209634

Epoch: 6| Step: 4
Training loss: 0.08324697485215778
Validation loss: 2.3673526865074415

Epoch: 6| Step: 5
Training loss: 0.07324226697281658
Validation loss: 2.377606673136514

Epoch: 6| Step: 6
Training loss: 0.07669576801787671
Validation loss: 2.3753824611494747

Epoch: 6| Step: 7
Training loss: 0.06681395641341766
Validation loss: 2.3913334877004755

Epoch: 6| Step: 8
Training loss: 0.07122239169827617
Validation loss: 2.3689384600418864

Epoch: 6| Step: 9
Training loss: 0.08306301188939091
Validation loss: 2.380865160484243

Epoch: 6| Step: 10
Training loss: 0.10760860685836239
Validation loss: 2.3640452575889808

Epoch: 6| Step: 11
Training loss: 0.06387655338243338
Validation loss: 2.3729678928592404

Epoch: 6| Step: 12
Training loss: 0.06893735480379704
Validation loss: 2.3778673941963224

Epoch: 6| Step: 13
Training loss: 0.07158037980010433
Validation loss: 2.3601032000677193

Epoch: 732| Step: 0
Training loss: 0.08668156129290996
Validation loss: 2.383885560475392

Epoch: 6| Step: 1
Training loss: 0.08224303857459554
Validation loss: 2.381066584126178

Epoch: 6| Step: 2
Training loss: 0.11357471666038314
Validation loss: 2.3777819705835825

Epoch: 6| Step: 3
Training loss: 0.07385848470667368
Validation loss: 2.3707238751991455

Epoch: 6| Step: 4
Training loss: 0.095415427375676
Validation loss: 2.3784632310447114

Epoch: 6| Step: 5
Training loss: 0.08835212554671276
Validation loss: 2.3780361386448923

Epoch: 6| Step: 6
Training loss: 0.07564215910245714
Validation loss: 2.392504352355558

Epoch: 6| Step: 7
Training loss: 0.08752435287835232
Validation loss: 2.4143400318462915

Epoch: 6| Step: 8
Training loss: 0.09710909627044279
Validation loss: 2.3917646282185956

Epoch: 6| Step: 9
Training loss: 0.06506967067756926
Validation loss: 2.390628440168676

Epoch: 6| Step: 10
Training loss: 0.12581664292326486
Validation loss: 2.390001209581553

Epoch: 6| Step: 11
Training loss: 0.06781687045626499
Validation loss: 2.3680024040076795

Epoch: 6| Step: 12
Training loss: 0.10154177380867806
Validation loss: 2.4119070532125715

Epoch: 6| Step: 13
Training loss: 0.06122272471383504
Validation loss: 2.38069802103189

Epoch: 733| Step: 0
Training loss: 0.09554486911255763
Validation loss: 2.3868533086241537

Epoch: 6| Step: 1
Training loss: 0.07307329095455481
Validation loss: 2.3829882119394874

Epoch: 6| Step: 2
Training loss: 0.08605443249239131
Validation loss: 2.392421634152846

Epoch: 6| Step: 3
Training loss: 0.08555948499817885
Validation loss: 2.3908407698507457

Epoch: 6| Step: 4
Training loss: 0.09254534438788552
Validation loss: 2.3989755392360346

Epoch: 6| Step: 5
Training loss: 0.06717787551698692
Validation loss: 2.3913290161555643

Epoch: 6| Step: 6
Training loss: 0.12330906801914714
Validation loss: 2.409728508566232

Epoch: 6| Step: 7
Training loss: 0.12861679553167008
Validation loss: 2.3832880555245066

Epoch: 6| Step: 8
Training loss: 0.0876021126769233
Validation loss: 2.4242436258773004

Epoch: 6| Step: 9
Training loss: 0.08119878828503771
Validation loss: 2.4109869140280624

Epoch: 6| Step: 10
Training loss: 0.09327308725300403
Validation loss: 2.406006524657212

Epoch: 6| Step: 11
Training loss: 0.08115641977331349
Validation loss: 2.394455800122995

Epoch: 6| Step: 12
Training loss: 0.09877736291957978
Validation loss: 2.3913762355050703

Epoch: 6| Step: 13
Training loss: 0.09526896283635784
Validation loss: 2.39469149765513

Epoch: 734| Step: 0
Training loss: 0.07317361800834234
Validation loss: 2.3869000730480128

Epoch: 6| Step: 1
Training loss: 0.05807327131767491
Validation loss: 2.4010640943801635

Epoch: 6| Step: 2
Training loss: 0.09828098736774911
Validation loss: 2.405398163320685

Epoch: 6| Step: 3
Training loss: 0.08843531310171207
Validation loss: 2.378043576366173

Epoch: 6| Step: 4
Training loss: 0.08943017848521471
Validation loss: 2.386520470686625

Epoch: 6| Step: 5
Training loss: 0.06586576089749517
Validation loss: 2.386505129745687

Epoch: 6| Step: 6
Training loss: 0.08564734242261231
Validation loss: 2.3682898501738663

Epoch: 6| Step: 7
Training loss: 0.09453414762800684
Validation loss: 2.403417159087505

Epoch: 6| Step: 8
Training loss: 0.0958368330770846
Validation loss: 2.418233318745414

Epoch: 6| Step: 9
Training loss: 0.11896615464335782
Validation loss: 2.4106297867682525

Epoch: 6| Step: 10
Training loss: 0.1395797827492059
Validation loss: 2.411663767368007

Epoch: 6| Step: 11
Training loss: 0.10247569169546025
Validation loss: 2.3964959560921817

Epoch: 6| Step: 12
Training loss: 0.17229286246670847
Validation loss: 2.39235438593431

Epoch: 6| Step: 13
Training loss: 0.09113609625258881
Validation loss: 2.3959916314417122

Epoch: 735| Step: 0
Training loss: 0.06632776390579477
Validation loss: 2.4007605999278603

Epoch: 6| Step: 1
Training loss: 0.13331158213471575
Validation loss: 2.4167057227973427

Epoch: 6| Step: 2
Training loss: 0.13174324309079932
Validation loss: 2.415291328713499

Epoch: 6| Step: 3
Training loss: 0.07683540770712163
Validation loss: 2.417847367920915

Epoch: 6| Step: 4
Training loss: 0.07453527840537885
Validation loss: 2.3974714306638756

Epoch: 6| Step: 5
Training loss: 0.08332936332107262
Validation loss: 2.3923030708729587

Epoch: 6| Step: 6
Training loss: 0.14104929466576607
Validation loss: 2.39985186441624

Epoch: 6| Step: 7
Training loss: 0.08847901170384832
Validation loss: 2.3935243195437446

Epoch: 6| Step: 8
Training loss: 0.08153761200813087
Validation loss: 2.3976855868215026

Epoch: 6| Step: 9
Training loss: 0.10966721735736788
Validation loss: 2.401155013521257

Epoch: 6| Step: 10
Training loss: 0.07676657500495437
Validation loss: 2.3809734690885214

Epoch: 6| Step: 11
Training loss: 0.08457576104247949
Validation loss: 2.3386641627724725

Epoch: 6| Step: 12
Training loss: 0.0936607542030411
Validation loss: 2.355564400440558

Epoch: 6| Step: 13
Training loss: 0.08797478090671852
Validation loss: 2.3624355350446926

Epoch: 736| Step: 0
Training loss: 0.09550272142067809
Validation loss: 2.3601375619623566

Epoch: 6| Step: 1
Training loss: 0.09262853650241402
Validation loss: 2.3604302087035545

Epoch: 6| Step: 2
Training loss: 0.08923995780580535
Validation loss: 2.3425676416611636

Epoch: 6| Step: 3
Training loss: 0.07833444415524003
Validation loss: 2.340140609621955

Epoch: 6| Step: 4
Training loss: 0.09500962663488018
Validation loss: 2.3714108746050653

Epoch: 6| Step: 5
Training loss: 0.09154727665210334
Validation loss: 2.3524605873020468

Epoch: 6| Step: 6
Training loss: 0.08626674308183566
Validation loss: 2.394513553604246

Epoch: 6| Step: 7
Training loss: 0.10802839886624753
Validation loss: 2.385448856640786

Epoch: 6| Step: 8
Training loss: 0.10581644461636466
Validation loss: 2.390356636574197

Epoch: 6| Step: 9
Training loss: 0.1527550963762826
Validation loss: 2.393910644953178

Epoch: 6| Step: 10
Training loss: 0.09536687011553437
Validation loss: 2.393017875234072

Epoch: 6| Step: 11
Training loss: 0.09003618612266852
Validation loss: 2.401066377143496

Epoch: 6| Step: 12
Training loss: 0.09535168327001967
Validation loss: 2.400207195857859

Epoch: 6| Step: 13
Training loss: 0.09131239306863351
Validation loss: 2.394189339210491

Epoch: 737| Step: 0
Training loss: 0.06934713555293454
Validation loss: 2.389264788606094

Epoch: 6| Step: 1
Training loss: 0.1323094236541531
Validation loss: 2.3842620104185257

Epoch: 6| Step: 2
Training loss: 0.07711641637002879
Validation loss: 2.3802930948263876

Epoch: 6| Step: 3
Training loss: 0.05632538876124206
Validation loss: 2.3919972928643674

Epoch: 6| Step: 4
Training loss: 0.14567149639724883
Validation loss: 2.378820751612476

Epoch: 6| Step: 5
Training loss: 0.09543234607117805
Validation loss: 2.3740714243519374

Epoch: 6| Step: 6
Training loss: 0.07017017901657481
Validation loss: 2.3759957222109356

Epoch: 6| Step: 7
Training loss: 0.07132201217141261
Validation loss: 2.3966318339810617

Epoch: 6| Step: 8
Training loss: 0.12066745323537081
Validation loss: 2.387955850236873

Epoch: 6| Step: 9
Training loss: 0.11481207715757666
Validation loss: 2.3853293852191535

Epoch: 6| Step: 10
Training loss: 0.08162772177069468
Validation loss: 2.400756471634844

Epoch: 6| Step: 11
Training loss: 0.06019246873506434
Validation loss: 2.4019595536858875

Epoch: 6| Step: 12
Training loss: 0.09440037518846986
Validation loss: 2.3799782376523666

Epoch: 6| Step: 13
Training loss: 0.06998790215467664
Validation loss: 2.4012276513357786

Epoch: 738| Step: 0
Training loss: 0.08021801267262012
Validation loss: 2.3959736901072946

Epoch: 6| Step: 1
Training loss: 0.08869303417244896
Validation loss: 2.3985005331325993

Epoch: 6| Step: 2
Training loss: 0.09097706690182046
Validation loss: 2.3832398793707568

Epoch: 6| Step: 3
Training loss: 0.08128381997269074
Validation loss: 2.398105629508636

Epoch: 6| Step: 4
Training loss: 0.07650006032591511
Validation loss: 2.4083354890188295

Epoch: 6| Step: 5
Training loss: 0.08152488119567958
Validation loss: 2.3928907599412943

Epoch: 6| Step: 6
Training loss: 0.07929520100203104
Validation loss: 2.3628873063669436

Epoch: 6| Step: 7
Training loss: 0.13883261028808852
Validation loss: 2.395386881559377

Epoch: 6| Step: 8
Training loss: 0.10163421116559342
Validation loss: 2.391965996809676

Epoch: 6| Step: 9
Training loss: 0.08207114135272807
Validation loss: 2.3854444278001354

Epoch: 6| Step: 10
Training loss: 0.06649588748017199
Validation loss: 2.3871615384644325

Epoch: 6| Step: 11
Training loss: 0.07127358647458147
Validation loss: 2.3875105021092806

Epoch: 6| Step: 12
Training loss: 0.05452393014031821
Validation loss: 2.382147222368423

Epoch: 6| Step: 13
Training loss: 0.14482848430584447
Validation loss: 2.3758495605339065

Epoch: 739| Step: 0
Training loss: 0.08069158135470053
Validation loss: 2.4062279459306617

Epoch: 6| Step: 1
Training loss: 0.06357835530595371
Validation loss: 2.3809313183759655

Epoch: 6| Step: 2
Training loss: 0.07828052656520894
Validation loss: 2.387119397677972

Epoch: 6| Step: 3
Training loss: 0.0824209956714314
Validation loss: 2.3942217278257782

Epoch: 6| Step: 4
Training loss: 0.11310375629960623
Validation loss: 2.38324161177788

Epoch: 6| Step: 5
Training loss: 0.054873338064822
Validation loss: 2.399047858341479

Epoch: 6| Step: 6
Training loss: 0.08373313017313315
Validation loss: 2.4053148259072827

Epoch: 6| Step: 7
Training loss: 0.07942422356173486
Validation loss: 2.400996819153102

Epoch: 6| Step: 8
Training loss: 0.07270166582512055
Validation loss: 2.401631004528607

Epoch: 6| Step: 9
Training loss: 0.10111824403682565
Validation loss: 2.4146011090981783

Epoch: 6| Step: 10
Training loss: 0.10213842689374633
Validation loss: 2.3988605545828516

Epoch: 6| Step: 11
Training loss: 0.08130170341653825
Validation loss: 2.4045082205252992

Epoch: 6| Step: 12
Training loss: 0.10241991113952081
Validation loss: 2.408321801812412

Epoch: 6| Step: 13
Training loss: 0.09965829956707921
Validation loss: 2.4066505114791714

Epoch: 740| Step: 0
Training loss: 0.07115768057625269
Validation loss: 2.396921548619872

Epoch: 6| Step: 1
Training loss: 0.0668096491104613
Validation loss: 2.402138267391046

Epoch: 6| Step: 2
Training loss: 0.06842993092376584
Validation loss: 2.4052225600760684

Epoch: 6| Step: 3
Training loss: 0.10782934848465509
Validation loss: 2.404070622214473

Epoch: 6| Step: 4
Training loss: 0.07152049827369876
Validation loss: 2.3981933319821747

Epoch: 6| Step: 5
Training loss: 0.06781542848601016
Validation loss: 2.4064190467847437

Epoch: 6| Step: 6
Training loss: 0.08495289117704806
Validation loss: 2.378638245769447

Epoch: 6| Step: 7
Training loss: 0.09877967758972749
Validation loss: 2.3840956529436883

Epoch: 6| Step: 8
Training loss: 0.10389280877620127
Validation loss: 2.4032668549084355

Epoch: 6| Step: 9
Training loss: 0.06526571694423089
Validation loss: 2.415776320701665

Epoch: 6| Step: 10
Training loss: 0.09462455782824804
Validation loss: 2.403279797527775

Epoch: 6| Step: 11
Training loss: 0.06036888000640354
Validation loss: 2.3800781538238533

Epoch: 6| Step: 12
Training loss: 0.11043436606569129
Validation loss: 2.372155487891841

Epoch: 6| Step: 13
Training loss: 0.09871513877807357
Validation loss: 2.370761817897924

Epoch: 741| Step: 0
Training loss: 0.06491771423581007
Validation loss: 2.408568747167232

Epoch: 6| Step: 1
Training loss: 0.12227861180056375
Validation loss: 2.3949156092711106

Epoch: 6| Step: 2
Training loss: 0.06997388525020719
Validation loss: 2.409552325063384

Epoch: 6| Step: 3
Training loss: 0.09524695515177592
Validation loss: 2.3998134447812838

Epoch: 6| Step: 4
Training loss: 0.11809769650436744
Validation loss: 2.420322454348856

Epoch: 6| Step: 5
Training loss: 0.06439143175991105
Validation loss: 2.4164659860927897

Epoch: 6| Step: 6
Training loss: 0.11115393060849513
Validation loss: 2.411485066984731

Epoch: 6| Step: 7
Training loss: 0.0995470862014391
Validation loss: 2.408697561790154

Epoch: 6| Step: 8
Training loss: 0.06572224558777065
Validation loss: 2.4144722654186603

Epoch: 6| Step: 9
Training loss: 0.09268021165972402
Validation loss: 2.4046622605999413

Epoch: 6| Step: 10
Training loss: 0.060523322739030085
Validation loss: 2.387745361957786

Epoch: 6| Step: 11
Training loss: 0.09272616336398172
Validation loss: 2.4291414981390145

Epoch: 6| Step: 12
Training loss: 0.07782159541489261
Validation loss: 2.4124576426953253

Epoch: 6| Step: 13
Training loss: 0.07045797028740358
Validation loss: 2.384451966671105

Epoch: 742| Step: 0
Training loss: 0.07291692034075525
Validation loss: 2.3765248701796486

Epoch: 6| Step: 1
Training loss: 0.08968624011925938
Validation loss: 2.3924373063081092

Epoch: 6| Step: 2
Training loss: 0.06674286781092911
Validation loss: 2.367567616335143

Epoch: 6| Step: 3
Training loss: 0.07686101210014507
Validation loss: 2.337431117322711

Epoch: 6| Step: 4
Training loss: 0.06077033767464277
Validation loss: 2.364611389469306

Epoch: 6| Step: 5
Training loss: 0.09266588099893315
Validation loss: 2.3669661608598545

Epoch: 6| Step: 6
Training loss: 0.08795441855473703
Validation loss: 2.363838308458285

Epoch: 6| Step: 7
Training loss: 0.05620636621858969
Validation loss: 2.3419466703639658

Epoch: 6| Step: 8
Training loss: 0.04678258129893565
Validation loss: 2.346301577402787

Epoch: 6| Step: 9
Training loss: 0.07668689698749354
Validation loss: 2.3358152058931165

Epoch: 6| Step: 10
Training loss: 0.11262412459052308
Validation loss: 2.3417692306572633

Epoch: 6| Step: 11
Training loss: 0.13604573402438935
Validation loss: 2.341859200016245

Epoch: 6| Step: 12
Training loss: 0.1137262433914914
Validation loss: 2.334178399803225

Epoch: 6| Step: 13
Training loss: 0.09018962047487111
Validation loss: 2.3308784154303535

Epoch: 743| Step: 0
Training loss: 0.10681965824212247
Validation loss: 2.3306116865207898

Epoch: 6| Step: 1
Training loss: 0.09208311944321061
Validation loss: 2.3427322070078427

Epoch: 6| Step: 2
Training loss: 0.08771168188572774
Validation loss: 2.360647963046796

Epoch: 6| Step: 3
Training loss: 0.0480995515552021
Validation loss: 2.373581301189427

Epoch: 6| Step: 4
Training loss: 0.07472866966678546
Validation loss: 2.3703417358113956

Epoch: 6| Step: 5
Training loss: 0.09560601017051501
Validation loss: 2.374834840209865

Epoch: 6| Step: 6
Training loss: 0.10908001050042146
Validation loss: 2.3637249159874423

Epoch: 6| Step: 7
Training loss: 0.08697905414349402
Validation loss: 2.3794172299831287

Epoch: 6| Step: 8
Training loss: 0.07721485224743212
Validation loss: 2.3738893330895863

Epoch: 6| Step: 9
Training loss: 0.053839012814483445
Validation loss: 2.381192352877856

Epoch: 6| Step: 10
Training loss: 0.09583519075587399
Validation loss: 2.3958485961756044

Epoch: 6| Step: 11
Training loss: 0.14482569343294535
Validation loss: 2.3956849882007285

Epoch: 6| Step: 12
Training loss: 0.06504928262274323
Validation loss: 2.3970535195795857

Epoch: 6| Step: 13
Training loss: 0.07148750980987122
Validation loss: 2.4047555686921576

Epoch: 744| Step: 0
Training loss: 0.0857408777627863
Validation loss: 2.4225124910773084

Epoch: 6| Step: 1
Training loss: 0.10375480640004096
Validation loss: 2.413363944944846

Epoch: 6| Step: 2
Training loss: 0.07380081130681197
Validation loss: 2.422163167025803

Epoch: 6| Step: 3
Training loss: 0.14976689186416042
Validation loss: 2.4084127982396275

Epoch: 6| Step: 4
Training loss: 0.12108622419905568
Validation loss: 2.410842525233163

Epoch: 6| Step: 5
Training loss: 0.11181837188458907
Validation loss: 2.4057500069662567

Epoch: 6| Step: 6
Training loss: 0.07052388470348296
Validation loss: 2.3934933738861415

Epoch: 6| Step: 7
Training loss: 0.08412838941635771
Validation loss: 2.4143172616613535

Epoch: 6| Step: 8
Training loss: 0.06013678678636955
Validation loss: 2.4032995553423726

Epoch: 6| Step: 9
Training loss: 0.08233406736532378
Validation loss: 2.3650217355038374

Epoch: 6| Step: 10
Training loss: 0.08481146280642601
Validation loss: 2.378946612154587

Epoch: 6| Step: 11
Training loss: 0.07882771360518719
Validation loss: 2.401101379598725

Epoch: 6| Step: 12
Training loss: 0.0892504455314196
Validation loss: 2.385325479025075

Epoch: 6| Step: 13
Training loss: 0.06076673421082784
Validation loss: 2.386782917524066

Epoch: 745| Step: 0
Training loss: 0.08033483343154962
Validation loss: 2.388330188057564

Epoch: 6| Step: 1
Training loss: 0.0740581990705382
Validation loss: 2.3776923453738523

Epoch: 6| Step: 2
Training loss: 0.06994580306971149
Validation loss: 2.3862247945771604

Epoch: 6| Step: 3
Training loss: 0.09368679777242304
Validation loss: 2.3763995922994754

Epoch: 6| Step: 4
Training loss: 0.056965480073944016
Validation loss: 2.381026656285824

Epoch: 6| Step: 5
Training loss: 0.07064395504590722
Validation loss: 2.3768436419714294

Epoch: 6| Step: 6
Training loss: 0.12140379714206309
Validation loss: 2.388607863402122

Epoch: 6| Step: 7
Training loss: 0.07855692021854692
Validation loss: 2.3906925520822173

Epoch: 6| Step: 8
Training loss: 0.08312127269010502
Validation loss: 2.36402749456552

Epoch: 6| Step: 9
Training loss: 0.08943806150781293
Validation loss: 2.405450322341313

Epoch: 6| Step: 10
Training loss: 0.08771064662468889
Validation loss: 2.379227847983607

Epoch: 6| Step: 11
Training loss: 0.0971318661890575
Validation loss: 2.400079526169024

Epoch: 6| Step: 12
Training loss: 0.09236779625211369
Validation loss: 2.392176898717322

Epoch: 6| Step: 13
Training loss: 0.09706457666071873
Validation loss: 2.372909504516456

Epoch: 746| Step: 0
Training loss: 0.08368601030472525
Validation loss: 2.365987224798105

Epoch: 6| Step: 1
Training loss: 0.09965962657070761
Validation loss: 2.38931532262294

Epoch: 6| Step: 2
Training loss: 0.09617610751645522
Validation loss: 2.3682119255950513

Epoch: 6| Step: 3
Training loss: 0.10377533739713327
Validation loss: 2.373443786655541

Epoch: 6| Step: 4
Training loss: 0.11366544718445949
Validation loss: 2.386972048085964

Epoch: 6| Step: 5
Training loss: 0.08172019384651281
Validation loss: 2.3825123749044996

Epoch: 6| Step: 6
Training loss: 0.0777823743279143
Validation loss: 2.380838091446747

Epoch: 6| Step: 7
Training loss: 0.07484918670180592
Validation loss: 2.3835443113613533

Epoch: 6| Step: 8
Training loss: 0.06973844541811232
Validation loss: 2.389341044563265

Epoch: 6| Step: 9
Training loss: 0.07189470868346547
Validation loss: 2.3954288517526625

Epoch: 6| Step: 10
Training loss: 0.07107890191495309
Validation loss: 2.387519968459697

Epoch: 6| Step: 11
Training loss: 0.045087033883940926
Validation loss: 2.3811688835106914

Epoch: 6| Step: 12
Training loss: 0.08956988722595857
Validation loss: 2.3635510080421804

Epoch: 6| Step: 13
Training loss: 0.07122415370263474
Validation loss: 2.3887429402245557

Epoch: 747| Step: 0
Training loss: 0.08365663631878681
Validation loss: 2.3593919309690294

Epoch: 6| Step: 1
Training loss: 0.08355104021580409
Validation loss: 2.3832957487314563

Epoch: 6| Step: 2
Training loss: 0.11223301466316986
Validation loss: 2.3610914940916894

Epoch: 6| Step: 3
Training loss: 0.05807595344837218
Validation loss: 2.396248871737238

Epoch: 6| Step: 4
Training loss: 0.07001284151028883
Validation loss: 2.3961050049855404

Epoch: 6| Step: 5
Training loss: 0.09247879622980255
Validation loss: 2.3826689258815636

Epoch: 6| Step: 6
Training loss: 0.08173678543745717
Validation loss: 2.4003756439802295

Epoch: 6| Step: 7
Training loss: 0.09997270740654839
Validation loss: 2.387982438153276

Epoch: 6| Step: 8
Training loss: 0.06795036708588423
Validation loss: 2.3854028106973417

Epoch: 6| Step: 9
Training loss: 0.11144700312142714
Validation loss: 2.381473012393508

Epoch: 6| Step: 10
Training loss: 0.05084428176531462
Validation loss: 2.3715755242619334

Epoch: 6| Step: 11
Training loss: 0.10430636773503656
Validation loss: 2.3579090075688325

Epoch: 6| Step: 12
Training loss: 0.0797167509285167
Validation loss: 2.3735670063826873

Epoch: 6| Step: 13
Training loss: 0.0815064125580677
Validation loss: 2.357172938510364

Epoch: 748| Step: 0
Training loss: 0.070595845876537
Validation loss: 2.3558027503791767

Epoch: 6| Step: 1
Training loss: 0.052461816058893974
Validation loss: 2.3529825019230954

Epoch: 6| Step: 2
Training loss: 0.0777179455048276
Validation loss: 2.3674322203709632

Epoch: 6| Step: 3
Training loss: 0.09005600279615865
Validation loss: 2.353451765015512

Epoch: 6| Step: 4
Training loss: 0.08589002262287311
Validation loss: 2.382232279061756

Epoch: 6| Step: 5
Training loss: 0.09997784026309312
Validation loss: 2.4039840672689663

Epoch: 6| Step: 6
Training loss: 0.06658836944437463
Validation loss: 2.3970672155141655

Epoch: 6| Step: 7
Training loss: 0.09103110676998731
Validation loss: 2.3784118167624

Epoch: 6| Step: 8
Training loss: 0.11222073692898747
Validation loss: 2.3882299894270353

Epoch: 6| Step: 9
Training loss: 0.10654968429366052
Validation loss: 2.396548742099876

Epoch: 6| Step: 10
Training loss: 0.06425300872957894
Validation loss: 2.396027386382917

Epoch: 6| Step: 11
Training loss: 0.06177905507571179
Validation loss: 2.380859861162115

Epoch: 6| Step: 12
Training loss: 0.06772132169723588
Validation loss: 2.3644105650184573

Epoch: 6| Step: 13
Training loss: 0.088628027909963
Validation loss: 2.3942776915963537

Epoch: 749| Step: 0
Training loss: 0.09643718862946851
Validation loss: 2.386688765537912

Epoch: 6| Step: 1
Training loss: 0.07897760250419235
Validation loss: 2.378381506067107

Epoch: 6| Step: 2
Training loss: 0.05203533444396642
Validation loss: 2.3897304074212107

Epoch: 6| Step: 3
Training loss: 0.06221180647483022
Validation loss: 2.399930565608989

Epoch: 6| Step: 4
Training loss: 0.08840454109147543
Validation loss: 2.3754436821137044

Epoch: 6| Step: 5
Training loss: 0.09169505945752388
Validation loss: 2.383667448839243

Epoch: 6| Step: 6
Training loss: 0.08228966620232947
Validation loss: 2.3805746198445306

Epoch: 6| Step: 7
Training loss: 0.09102445649616277
Validation loss: 2.392841650032422

Epoch: 6| Step: 8
Training loss: 0.06499879853692507
Validation loss: 2.3731848921654732

Epoch: 6| Step: 9
Training loss: 0.05818711082915309
Validation loss: 2.3748151302977982

Epoch: 6| Step: 10
Training loss: 0.07984496983064765
Validation loss: 2.3722793364813333

Epoch: 6| Step: 11
Training loss: 0.06949730014809924
Validation loss: 2.3784604340069966

Epoch: 6| Step: 12
Training loss: 0.09740473783896195
Validation loss: 2.3626476078741585

Epoch: 6| Step: 13
Training loss: 0.0764567994554834
Validation loss: 2.3592295464312207

Epoch: 750| Step: 0
Training loss: 0.08437661405626663
Validation loss: 2.3937360871260167

Epoch: 6| Step: 1
Training loss: 0.08780511829295319
Validation loss: 2.3687280990103723

Epoch: 6| Step: 2
Training loss: 0.0923513397173449
Validation loss: 2.3642962691094453

Epoch: 6| Step: 3
Training loss: 0.08806598705954245
Validation loss: 2.3873581870643

Epoch: 6| Step: 4
Training loss: 0.055447437161010936
Validation loss: 2.3557101964866343

Epoch: 6| Step: 5
Training loss: 0.0717459954035603
Validation loss: 2.3516091649508972

Epoch: 6| Step: 6
Training loss: 0.05118658076527551
Validation loss: 2.3539913521305484

Epoch: 6| Step: 7
Training loss: 0.11856022543753854
Validation loss: 2.3795589640884356

Epoch: 6| Step: 8
Training loss: 0.06432021771816321
Validation loss: 2.364440834168227

Epoch: 6| Step: 9
Training loss: 0.09152984332966782
Validation loss: 2.357676567787288

Epoch: 6| Step: 10
Training loss: 0.0741396407091186
Validation loss: 2.364475372641261

Epoch: 6| Step: 11
Training loss: 0.09061918753860299
Validation loss: 2.376593440061566

Epoch: 6| Step: 12
Training loss: 0.06423132475141226
Validation loss: 2.4003460277018096

Epoch: 6| Step: 13
Training loss: 0.08782477561157559
Validation loss: 2.371682707576275

Epoch: 751| Step: 0
Training loss: 0.0718910426138273
Validation loss: 2.382454737516631

Epoch: 6| Step: 1
Training loss: 0.07666413181468568
Validation loss: 2.378189806399911

Epoch: 6| Step: 2
Training loss: 0.06128447347410551
Validation loss: 2.3664586383354744

Epoch: 6| Step: 3
Training loss: 0.051943159223136116
Validation loss: 2.3847101410738962

Epoch: 6| Step: 4
Training loss: 0.08138286840541839
Validation loss: 2.377054201526213

Epoch: 6| Step: 5
Training loss: 0.08579305137255482
Validation loss: 2.3490750952923802

Epoch: 6| Step: 6
Training loss: 0.09839028577214501
Validation loss: 2.3464281582349957

Epoch: 6| Step: 7
Training loss: 0.07432271552153334
Validation loss: 2.3615774561135363

Epoch: 6| Step: 8
Training loss: 0.08794696379703401
Validation loss: 2.355194474718885

Epoch: 6| Step: 9
Training loss: 0.08742885613713029
Validation loss: 2.3484035351804557

Epoch: 6| Step: 10
Training loss: 0.05937589908220299
Validation loss: 2.3359757654612614

Epoch: 6| Step: 11
Training loss: 0.0835912619425486
Validation loss: 2.356658005697704

Epoch: 6| Step: 12
Training loss: 0.08935058559561773
Validation loss: 2.363220850837889

Epoch: 6| Step: 13
Training loss: 0.05304863021275472
Validation loss: 2.3491966431898557

Epoch: 752| Step: 0
Training loss: 0.07143836521056933
Validation loss: 2.3511802606064576

Epoch: 6| Step: 1
Training loss: 0.05229028054307261
Validation loss: 2.3510134029341976

Epoch: 6| Step: 2
Training loss: 0.10135475332332769
Validation loss: 2.379732010832805

Epoch: 6| Step: 3
Training loss: 0.06919828370679493
Validation loss: 2.352957623506154

Epoch: 6| Step: 4
Training loss: 0.07152648803126568
Validation loss: 2.390372812126229

Epoch: 6| Step: 5
Training loss: 0.0480513683016844
Validation loss: 2.347121258644045

Epoch: 6| Step: 6
Training loss: 0.05937937325132785
Validation loss: 2.3732682560032474

Epoch: 6| Step: 7
Training loss: 0.09265163356255197
Validation loss: 2.400079726446804

Epoch: 6| Step: 8
Training loss: 0.057365522499967514
Validation loss: 2.38765446367738

Epoch: 6| Step: 9
Training loss: 0.09645275010809011
Validation loss: 2.3972608614082564

Epoch: 6| Step: 10
Training loss: 0.07456585378690489
Validation loss: 2.386364876037824

Epoch: 6| Step: 11
Training loss: 0.08586047253414862
Validation loss: 2.378163931509369

Epoch: 6| Step: 12
Training loss: 0.06035145247242598
Validation loss: 2.392421718806656

Epoch: 6| Step: 13
Training loss: 0.08103137370411632
Validation loss: 2.3763158452872646

Epoch: 753| Step: 0
Training loss: 0.06489115757244864
Validation loss: 2.368058690241935

Epoch: 6| Step: 1
Training loss: 0.06174892588708749
Validation loss: 2.3839413786788985

Epoch: 6| Step: 2
Training loss: 0.09352985004597074
Validation loss: 2.3828259625551325

Epoch: 6| Step: 3
Training loss: 0.08862808570513922
Validation loss: 2.3568750110408816

Epoch: 6| Step: 4
Training loss: 0.0546658038630291
Validation loss: 2.377440113884128

Epoch: 6| Step: 5
Training loss: 0.08728429611646088
Validation loss: 2.3663820731971326

Epoch: 6| Step: 6
Training loss: 0.04497549495370997
Validation loss: 2.3821281355419592

Epoch: 6| Step: 7
Training loss: 0.0772848131096515
Validation loss: 2.368092933993063

Epoch: 6| Step: 8
Training loss: 0.07198687869661805
Validation loss: 2.364094791644964

Epoch: 6| Step: 9
Training loss: 0.07966612454370238
Validation loss: 2.3727279313036904

Epoch: 6| Step: 10
Training loss: 0.06879269320098293
Validation loss: 2.3529712759431836

Epoch: 6| Step: 11
Training loss: 0.10110665689999494
Validation loss: 2.3784193602880457

Epoch: 6| Step: 12
Training loss: 0.07053581181145646
Validation loss: 2.3672030855300186

Epoch: 6| Step: 13
Training loss: 0.08200437809542149
Validation loss: 2.3580263370504406

Epoch: 754| Step: 0
Training loss: 0.038818693759365704
Validation loss: 2.3694597908192447

Epoch: 6| Step: 1
Training loss: 0.08609200265533931
Validation loss: 2.3697448105604493

Epoch: 6| Step: 2
Training loss: 0.07370525206779271
Validation loss: 2.360761618962729

Epoch: 6| Step: 3
Training loss: 0.06952258294447634
Validation loss: 2.3339586542529536

Epoch: 6| Step: 4
Training loss: 0.07831889767213147
Validation loss: 2.3732810364009027

Epoch: 6| Step: 5
Training loss: 0.08678344491326499
Validation loss: 2.3719050435541034

Epoch: 6| Step: 6
Training loss: 0.042813395480811395
Validation loss: 2.3544185390071677

Epoch: 6| Step: 7
Training loss: 0.06335766734727717
Validation loss: 2.365956466703908

Epoch: 6| Step: 8
Training loss: 0.06821638206224533
Validation loss: 2.356114507231628

Epoch: 6| Step: 9
Training loss: 0.12018380217534577
Validation loss: 2.3771842439525717

Epoch: 6| Step: 10
Training loss: 0.06205708428784574
Validation loss: 2.3648158778493897

Epoch: 6| Step: 11
Training loss: 0.0868286077037366
Validation loss: 2.363639454147948

Epoch: 6| Step: 12
Training loss: 0.04015997041452046
Validation loss: 2.378347209961195

Epoch: 6| Step: 13
Training loss: 0.052114883443400484
Validation loss: 2.371212503442495

Epoch: 755| Step: 0
Training loss: 0.07032154276767281
Validation loss: 2.377689634764028

Epoch: 6| Step: 1
Training loss: 0.055480014889547465
Validation loss: 2.3974022190973434

Epoch: 6| Step: 2
Training loss: 0.07195336628126846
Validation loss: 2.358828517117104

Epoch: 6| Step: 3
Training loss: 0.08166948086871421
Validation loss: 2.388447712053467

Epoch: 6| Step: 4
Training loss: 0.09226453641593305
Validation loss: 2.391461540150345

Epoch: 6| Step: 5
Training loss: 0.058859540193273774
Validation loss: 2.36079815506237

Epoch: 6| Step: 6
Training loss: 0.06351002031492198
Validation loss: 2.3513377648497746

Epoch: 6| Step: 7
Training loss: 0.07141067635153928
Validation loss: 2.360904594653514

Epoch: 6| Step: 8
Training loss: 0.08633470855396048
Validation loss: 2.34542192445397

Epoch: 6| Step: 9
Training loss: 0.07152388385047996
Validation loss: 2.3572802095437164

Epoch: 6| Step: 10
Training loss: 0.07634675906384378
Validation loss: 2.3588548029901495

Epoch: 6| Step: 11
Training loss: 0.06394617521697916
Validation loss: 2.347820592432461

Epoch: 6| Step: 12
Training loss: 0.0821994549927763
Validation loss: 2.358930894083293

Epoch: 6| Step: 13
Training loss: 0.08382576836475748
Validation loss: 2.3350408346750364

Epoch: 756| Step: 0
Training loss: 0.08963035035357171
Validation loss: 2.3864927986987032

Epoch: 6| Step: 1
Training loss: 0.06566909148992545
Validation loss: 2.374838634658844

Epoch: 6| Step: 2
Training loss: 0.05963498653995256
Validation loss: 2.352526476044361

Epoch: 6| Step: 3
Training loss: 0.06057501723391185
Validation loss: 2.3541242770089226

Epoch: 6| Step: 4
Training loss: 0.08454507413721717
Validation loss: 2.3694861480937637

Epoch: 6| Step: 5
Training loss: 0.08885526577138186
Validation loss: 2.3790077694174263

Epoch: 6| Step: 6
Training loss: 0.0733806667923891
Validation loss: 2.364591745041159

Epoch: 6| Step: 7
Training loss: 0.07625024993847704
Validation loss: 2.3733087777731354

Epoch: 6| Step: 8
Training loss: 0.06356863533499502
Validation loss: 2.3775693297418696

Epoch: 6| Step: 9
Training loss: 0.11789720920734083
Validation loss: 2.366913040318026

Epoch: 6| Step: 10
Training loss: 0.10461030505267614
Validation loss: 2.3834988234197967

Epoch: 6| Step: 11
Training loss: 0.06933501068355445
Validation loss: 2.3737470109768446

Epoch: 6| Step: 12
Training loss: 0.0828427384383838
Validation loss: 2.3747423007362003

Epoch: 6| Step: 13
Training loss: 0.08630787894666656
Validation loss: 2.38427556209732

Epoch: 757| Step: 0
Training loss: 0.07500052923770778
Validation loss: 2.36697692920059

Epoch: 6| Step: 1
Training loss: 0.1279644518492553
Validation loss: 2.394420109509082

Epoch: 6| Step: 2
Training loss: 0.0644797645771199
Validation loss: 2.3600876928416166

Epoch: 6| Step: 3
Training loss: 0.11570591543929491
Validation loss: 2.358824243705944

Epoch: 6| Step: 4
Training loss: 0.07025674755341732
Validation loss: 2.33563230976959

Epoch: 6| Step: 5
Training loss: 0.057679661727795144
Validation loss: 2.333383891075042

Epoch: 6| Step: 6
Training loss: 0.09314986706594706
Validation loss: 2.339539043036617

Epoch: 6| Step: 7
Training loss: 0.05580407444693146
Validation loss: 2.3325678922015465

Epoch: 6| Step: 8
Training loss: 0.0646246880877953
Validation loss: 2.337008571025428

Epoch: 6| Step: 9
Training loss: 0.10557539281433273
Validation loss: 2.3642834481404917

Epoch: 6| Step: 10
Training loss: 0.05486039946182713
Validation loss: 2.339032238703899

Epoch: 6| Step: 11
Training loss: 0.08122147497260096
Validation loss: 2.333939781866512

Epoch: 6| Step: 12
Training loss: 0.08395441485670223
Validation loss: 2.341542750859753

Epoch: 6| Step: 13
Training loss: 0.09366457245735864
Validation loss: 2.324941147945821

Epoch: 758| Step: 0
Training loss: 0.08536908888529986
Validation loss: 2.3633660327277157

Epoch: 6| Step: 1
Training loss: 0.09034375810540664
Validation loss: 2.349356920873588

Epoch: 6| Step: 2
Training loss: 0.06294138219583502
Validation loss: 2.3520844711190074

Epoch: 6| Step: 3
Training loss: 0.06219588176812735
Validation loss: 2.3996531177079206

Epoch: 6| Step: 4
Training loss: 0.0641514480464182
Validation loss: 2.367408854993705

Epoch: 6| Step: 5
Training loss: 0.0629785182690838
Validation loss: 2.380815108527401

Epoch: 6| Step: 6
Training loss: 0.0784619901380052
Validation loss: 2.3511829439889738

Epoch: 6| Step: 7
Training loss: 0.05384940375632318
Validation loss: 2.378260959549919

Epoch: 6| Step: 8
Training loss: 0.07350135092037138
Validation loss: 2.3528281009148624

Epoch: 6| Step: 9
Training loss: 0.13469703283229667
Validation loss: 2.353222722987681

Epoch: 6| Step: 10
Training loss: 0.06745716498583298
Validation loss: 2.3597395094529334

Epoch: 6| Step: 11
Training loss: 0.09461603894062992
Validation loss: 2.3585278721235046

Epoch: 6| Step: 12
Training loss: 0.042760308201563624
Validation loss: 2.380970060192048

Epoch: 6| Step: 13
Training loss: 0.04719909989202249
Validation loss: 2.358655064962683

Epoch: 759| Step: 0
Training loss: 0.07002236188968768
Validation loss: 2.371118382986868

Epoch: 6| Step: 1
Training loss: 0.08890095268417292
Validation loss: 2.352788415182331

Epoch: 6| Step: 2
Training loss: 0.06672550691498352
Validation loss: 2.3493760109609574

Epoch: 6| Step: 3
Training loss: 0.095445578333789
Validation loss: 2.3420126794836635

Epoch: 6| Step: 4
Training loss: 0.09256158532103473
Validation loss: 2.3397398705847707

Epoch: 6| Step: 5
Training loss: 0.08271310606283042
Validation loss: 2.327136191824639

Epoch: 6| Step: 6
Training loss: 0.0670476678158201
Validation loss: 2.3251591340185316

Epoch: 6| Step: 7
Training loss: 0.06332089336206499
Validation loss: 2.33146184222512

Epoch: 6| Step: 8
Training loss: 0.053887912319469024
Validation loss: 2.3332229762488192

Epoch: 6| Step: 9
Training loss: 0.07858149555257134
Validation loss: 2.356617512007633

Epoch: 6| Step: 10
Training loss: 0.0769276538075288
Validation loss: 2.341449543236407

Epoch: 6| Step: 11
Training loss: 0.08506693476129006
Validation loss: 2.364729862426297

Epoch: 6| Step: 12
Training loss: 0.07878412909280047
Validation loss: 2.3524253858376714

Epoch: 6| Step: 13
Training loss: 0.06416047733406537
Validation loss: 2.339073685389774

Epoch: 760| Step: 0
Training loss: 0.05513031107133588
Validation loss: 2.3542254205839326

Epoch: 6| Step: 1
Training loss: 0.08237074524852812
Validation loss: 2.3344867099987945

Epoch: 6| Step: 2
Training loss: 0.0682324491353115
Validation loss: 2.35578681682438

Epoch: 6| Step: 3
Training loss: 0.05732193557247548
Validation loss: 2.346806421901881

Epoch: 6| Step: 4
Training loss: 0.06222671125625292
Validation loss: 2.3516098855494665

Epoch: 6| Step: 5
Training loss: 0.08228690748798183
Validation loss: 2.3603987737792274

Epoch: 6| Step: 6
Training loss: 0.049404575356918064
Validation loss: 2.3672740553185965

Epoch: 6| Step: 7
Training loss: 0.061107318181279034
Validation loss: 2.3505968253236627

Epoch: 6| Step: 8
Training loss: 0.05801067513810273
Validation loss: 2.3731355262401106

Epoch: 6| Step: 9
Training loss: 0.08751114142108746
Validation loss: 2.3695495175242796

Epoch: 6| Step: 10
Training loss: 0.06129042269860982
Validation loss: 2.376358081103327

Epoch: 6| Step: 11
Training loss: 0.09122499933428357
Validation loss: 2.3682131607519095

Epoch: 6| Step: 12
Training loss: 0.06603360805823408
Validation loss: 2.368491982279631

Epoch: 6| Step: 13
Training loss: 0.08839320493914561
Validation loss: 2.368120274292751

Epoch: 761| Step: 0
Training loss: 0.08759979768514949
Validation loss: 2.3983158878258397

Epoch: 6| Step: 1
Training loss: 0.05525732134017324
Validation loss: 2.3826086674276374

Epoch: 6| Step: 2
Training loss: 0.08566868527346586
Validation loss: 2.366621773672555

Epoch: 6| Step: 3
Training loss: 0.06950076083025843
Validation loss: 2.363407586630387

Epoch: 6| Step: 4
Training loss: 0.11027824447456946
Validation loss: 2.354281102988287

Epoch: 6| Step: 5
Training loss: 0.06692559850408743
Validation loss: 2.382873775367415

Epoch: 6| Step: 6
Training loss: 0.0884738749081157
Validation loss: 2.37012862809952

Epoch: 6| Step: 7
Training loss: 0.06852869453962392
Validation loss: 2.3679131946525023

Epoch: 6| Step: 8
Training loss: 0.06733641201674868
Validation loss: 2.35407567553954

Epoch: 6| Step: 9
Training loss: 0.06387146839178717
Validation loss: 2.367272657770556

Epoch: 6| Step: 10
Training loss: 0.0538319460013722
Validation loss: 2.3595570879264782

Epoch: 6| Step: 11
Training loss: 0.07905468905920424
Validation loss: 2.3810955713360116

Epoch: 6| Step: 12
Training loss: 0.07772235226268556
Validation loss: 2.372600729510505

Epoch: 6| Step: 13
Training loss: 0.055626911180056554
Validation loss: 2.384795838965894

Epoch: 762| Step: 0
Training loss: 0.11447758201749635
Validation loss: 2.3880735150361123

Epoch: 6| Step: 1
Training loss: 0.05352817348253877
Validation loss: 2.361588895746615

Epoch: 6| Step: 2
Training loss: 0.06985198315902384
Validation loss: 2.364582593197743

Epoch: 6| Step: 3
Training loss: 0.049300568936447464
Validation loss: 2.354962799011487

Epoch: 6| Step: 4
Training loss: 0.07287170167586064
Validation loss: 2.350242173496172

Epoch: 6| Step: 5
Training loss: 0.06099130581164385
Validation loss: 2.3651999722590262

Epoch: 6| Step: 6
Training loss: 0.052713789719103295
Validation loss: 2.3368077462622723

Epoch: 6| Step: 7
Training loss: 0.09967472700125167
Validation loss: 2.3710521123938455

Epoch: 6| Step: 8
Training loss: 0.07556925103972137
Validation loss: 2.3556397726165113

Epoch: 6| Step: 9
Training loss: 0.047633166565876635
Validation loss: 2.360977536990865

Epoch: 6| Step: 10
Training loss: 0.10211286527159968
Validation loss: 2.3457096135932236

Epoch: 6| Step: 11
Training loss: 0.07809331370556585
Validation loss: 2.3499297414944786

Epoch: 6| Step: 12
Training loss: 0.08688451500455922
Validation loss: 2.3513479012563643

Epoch: 6| Step: 13
Training loss: 0.04699470216803949
Validation loss: 2.35417642699351

Epoch: 763| Step: 0
Training loss: 0.07515502444911688
Validation loss: 2.3916891497501043

Epoch: 6| Step: 1
Training loss: 0.10206193269827743
Validation loss: 2.3707028072244505

Epoch: 6| Step: 2
Training loss: 0.06517318722710082
Validation loss: 2.3604501345773317

Epoch: 6| Step: 3
Training loss: 0.11546230000688901
Validation loss: 2.3801351825776065

Epoch: 6| Step: 4
Training loss: 0.09561506423880513
Validation loss: 2.37309035840309

Epoch: 6| Step: 5
Training loss: 0.0785454522598384
Validation loss: 2.3769254899308265

Epoch: 6| Step: 6
Training loss: 0.04817137115139541
Validation loss: 2.382615462235257

Epoch: 6| Step: 7
Training loss: 0.10862310427892516
Validation loss: 2.411122617491216

Epoch: 6| Step: 8
Training loss: 0.11309504414656209
Validation loss: 2.378475088507952

Epoch: 6| Step: 9
Training loss: 0.08504156693365955
Validation loss: 2.398270750607382

Epoch: 6| Step: 10
Training loss: 0.05571493325597028
Validation loss: 2.3942697220909475

Epoch: 6| Step: 11
Training loss: 0.09105382657881694
Validation loss: 2.3714913755530054

Epoch: 6| Step: 12
Training loss: 0.0859652956530661
Validation loss: 2.3766690171705944

Epoch: 6| Step: 13
Training loss: 0.1304703666678219
Validation loss: 2.374277053410456

Epoch: 764| Step: 0
Training loss: 0.0943160551455265
Validation loss: 2.3907913728123993

Epoch: 6| Step: 1
Training loss: 0.09660359480370971
Validation loss: 2.3880609709417557

Epoch: 6| Step: 2
Training loss: 0.12251307109388868
Validation loss: 2.4225720680934515

Epoch: 6| Step: 3
Training loss: 0.046199271780454354
Validation loss: 2.4046900124158173

Epoch: 6| Step: 4
Training loss: 0.1346014515542369
Validation loss: 2.4158718429012005

Epoch: 6| Step: 5
Training loss: 0.09769502823524041
Validation loss: 2.4047409879922617

Epoch: 6| Step: 6
Training loss: 0.07589457238486944
Validation loss: 2.425355801520049

Epoch: 6| Step: 7
Training loss: 0.10435681174611929
Validation loss: 2.4036727426657807

Epoch: 6| Step: 8
Training loss: 0.0781774225784623
Validation loss: 2.420169172683411

Epoch: 6| Step: 9
Training loss: 0.09698783529059941
Validation loss: 2.4204059401957867

Epoch: 6| Step: 10
Training loss: 0.08834725809115095
Validation loss: 2.388350086718294

Epoch: 6| Step: 11
Training loss: 0.0854818935591937
Validation loss: 2.4041952792779844

Epoch: 6| Step: 12
Training loss: 0.05308027865709584
Validation loss: 2.4009737190183182

Epoch: 6| Step: 13
Training loss: 0.09668706615303811
Validation loss: 2.382486715896626

Epoch: 765| Step: 0
Training loss: 0.04582550463320555
Validation loss: 2.3828924264183375

Epoch: 6| Step: 1
Training loss: 0.10192160210404039
Validation loss: 2.3875499650318064

Epoch: 6| Step: 2
Training loss: 0.0476215048280887
Validation loss: 2.382019451093315

Epoch: 6| Step: 3
Training loss: 0.0892566697529569
Validation loss: 2.386733270013594

Epoch: 6| Step: 4
Training loss: 0.10027098187187844
Validation loss: 2.366524813319376

Epoch: 6| Step: 5
Training loss: 0.10610262365269087
Validation loss: 2.3927745202235267

Epoch: 6| Step: 6
Training loss: 0.09295219466320469
Validation loss: 2.3773272165170503

Epoch: 6| Step: 7
Training loss: 0.09361106790353103
Validation loss: 2.388382357017279

Epoch: 6| Step: 8
Training loss: 0.08708488629046236
Validation loss: 2.376376477991777

Epoch: 6| Step: 9
Training loss: 0.08215121738412062
Validation loss: 2.388406621710764

Epoch: 6| Step: 10
Training loss: 0.07842381967401006
Validation loss: 2.3754222021810727

Epoch: 6| Step: 11
Training loss: 0.09632990398450411
Validation loss: 2.3896404654296988

Epoch: 6| Step: 12
Training loss: 0.07792117830060263
Validation loss: 2.381859543444856

Epoch: 6| Step: 13
Training loss: 0.04552010075589271
Validation loss: 2.3772209805848625

Epoch: 766| Step: 0
Training loss: 0.0631672917757257
Validation loss: 2.37369907453756

Epoch: 6| Step: 1
Training loss: 0.0791995124952558
Validation loss: 2.3886937139154023

Epoch: 6| Step: 2
Training loss: 0.09958387497265143
Validation loss: 2.3841002638662414

Epoch: 6| Step: 3
Training loss: 0.0907275844257903
Validation loss: 2.3872063273032276

Epoch: 6| Step: 4
Training loss: 0.09872727072919739
Validation loss: 2.3904302545739737

Epoch: 6| Step: 5
Training loss: 0.10225155805762431
Validation loss: 2.3856664217775103

Epoch: 6| Step: 6
Training loss: 0.07822987550527774
Validation loss: 2.39010492960421

Epoch: 6| Step: 7
Training loss: 0.04233953512160059
Validation loss: 2.3875484209734705

Epoch: 6| Step: 8
Training loss: 0.06421173292884076
Validation loss: 2.38364181086942

Epoch: 6| Step: 9
Training loss: 0.07003388570279528
Validation loss: 2.3648994526859966

Epoch: 6| Step: 10
Training loss: 0.07143566003817853
Validation loss: 2.386681045672921

Epoch: 6| Step: 11
Training loss: 0.06507745274199975
Validation loss: 2.37256353990931

Epoch: 6| Step: 12
Training loss: 0.076541048810883
Validation loss: 2.354374556129136

Epoch: 6| Step: 13
Training loss: 0.09011428983781151
Validation loss: 2.3787503836255786

Epoch: 767| Step: 0
Training loss: 0.06371473964102418
Validation loss: 2.374066437060237

Epoch: 6| Step: 1
Training loss: 0.06447644967628924
Validation loss: 2.3523057553340037

Epoch: 6| Step: 2
Training loss: 0.07929671315707523
Validation loss: 2.382106283249008

Epoch: 6| Step: 3
Training loss: 0.06975793693617681
Validation loss: 2.3729524070429826

Epoch: 6| Step: 4
Training loss: 0.14620415269507409
Validation loss: 2.3790863732436263

Epoch: 6| Step: 5
Training loss: 0.11054288263828797
Validation loss: 2.3630676840172957

Epoch: 6| Step: 6
Training loss: 0.08643035553287225
Validation loss: 2.376206940305374

Epoch: 6| Step: 7
Training loss: 0.09017331381684193
Validation loss: 2.349786171122727

Epoch: 6| Step: 8
Training loss: 0.059920835287033826
Validation loss: 2.353109363703928

Epoch: 6| Step: 9
Training loss: 0.05989595621379742
Validation loss: 2.3629308514189495

Epoch: 6| Step: 10
Training loss: 0.0650828942672743
Validation loss: 2.3560890264407526

Epoch: 6| Step: 11
Training loss: 0.07359910466623655
Validation loss: 2.3760661623372914

Epoch: 6| Step: 12
Training loss: 0.06960943840700423
Validation loss: 2.372402814169981

Epoch: 6| Step: 13
Training loss: 0.10508277698415451
Validation loss: 2.357101586551042

Epoch: 768| Step: 0
Training loss: 0.10501609907311443
Validation loss: 2.3290371894088273

Epoch: 6| Step: 1
Training loss: 0.10160467299261615
Validation loss: 2.380381379809162

Epoch: 6| Step: 2
Training loss: 0.1061799828448976
Validation loss: 2.375142458586884

Epoch: 6| Step: 3
Training loss: 0.06820465699012292
Validation loss: 2.389027316265752

Epoch: 6| Step: 4
Training loss: 0.08953205233109557
Validation loss: 2.3719902181255756

Epoch: 6| Step: 5
Training loss: 0.05716991379220967
Validation loss: 2.36879473115914

Epoch: 6| Step: 6
Training loss: 0.07618330600748537
Validation loss: 2.3863998234105797

Epoch: 6| Step: 7
Training loss: 0.07410185794238534
Validation loss: 2.372161232462704

Epoch: 6| Step: 8
Training loss: 0.088757992824428
Validation loss: 2.3965084956154943

Epoch: 6| Step: 9
Training loss: 0.0790767925239131
Validation loss: 2.3963571515310456

Epoch: 6| Step: 10
Training loss: 0.06006117946982205
Validation loss: 2.3810698410731574

Epoch: 6| Step: 11
Training loss: 0.05300926379744952
Validation loss: 2.3758603536235183

Epoch: 6| Step: 12
Training loss: 0.07634655778689468
Validation loss: 2.3389911710633733

Epoch: 6| Step: 13
Training loss: 0.1154791043611322
Validation loss: 2.359454721832808

Epoch: 769| Step: 0
Training loss: 0.0706062934162526
Validation loss: 2.362261155323613

Epoch: 6| Step: 1
Training loss: 0.07167572171624928
Validation loss: 2.3436118880292787

Epoch: 6| Step: 2
Training loss: 0.055873022713067405
Validation loss: 2.347756087253552

Epoch: 6| Step: 3
Training loss: 0.09976389064192392
Validation loss: 2.3335168725297075

Epoch: 6| Step: 4
Training loss: 0.11188849578203776
Validation loss: 2.3608189352936835

Epoch: 6| Step: 5
Training loss: 0.07533913642898186
Validation loss: 2.3266099932386113

Epoch: 6| Step: 6
Training loss: 0.11815316173620798
Validation loss: 2.3545521028493543

Epoch: 6| Step: 7
Training loss: 0.10754900259019208
Validation loss: 2.3455108055262666

Epoch: 6| Step: 8
Training loss: 0.051665304392562436
Validation loss: 2.348350683320659

Epoch: 6| Step: 9
Training loss: 0.0844555214498659
Validation loss: 2.3635854282765116

Epoch: 6| Step: 10
Training loss: 0.054521265441137924
Validation loss: 2.3688755590989388

Epoch: 6| Step: 11
Training loss: 0.06247303984724679
Validation loss: 2.37535372152519

Epoch: 6| Step: 12
Training loss: 0.07757373870404492
Validation loss: 2.3831498129039566

Epoch: 6| Step: 13
Training loss: 0.06600650210800622
Validation loss: 2.3740066054807314

Epoch: 770| Step: 0
Training loss: 0.11506193804668433
Validation loss: 2.360218954663549

Epoch: 6| Step: 1
Training loss: 0.09927715268474102
Validation loss: 2.354788099706769

Epoch: 6| Step: 2
Training loss: 0.06893104886566861
Validation loss: 2.3880738864734177

Epoch: 6| Step: 3
Training loss: 0.055724709082227424
Validation loss: 2.368645683141197

Epoch: 6| Step: 4
Training loss: 0.07401792435258446
Validation loss: 2.3678243013324836

Epoch: 6| Step: 5
Training loss: 0.08202597340007246
Validation loss: 2.359873731383568

Epoch: 6| Step: 6
Training loss: 0.0902668227855338
Validation loss: 2.3531766652581063

Epoch: 6| Step: 7
Training loss: 0.07295209656826109
Validation loss: 2.336090612954604

Epoch: 6| Step: 8
Training loss: 0.06809983711818368
Validation loss: 2.337019304903909

Epoch: 6| Step: 9
Training loss: 0.10626900359213624
Validation loss: 2.3630268553580835

Epoch: 6| Step: 10
Training loss: 0.0869441489319105
Validation loss: 2.3357642460675563

Epoch: 6| Step: 11
Training loss: 0.10026706223530038
Validation loss: 2.369349129478943

Epoch: 6| Step: 12
Training loss: 0.09480550268959921
Validation loss: 2.3345635656788852

Epoch: 6| Step: 13
Training loss: 0.0652986145944812
Validation loss: 2.349417441847608

Epoch: 771| Step: 0
Training loss: 0.07072337951121768
Validation loss: 2.3556068001880326

Epoch: 6| Step: 1
Training loss: 0.07413292615730835
Validation loss: 2.3447860604509896

Epoch: 6| Step: 2
Training loss: 0.0682243921827343
Validation loss: 2.3656184681082784

Epoch: 6| Step: 3
Training loss: 0.07112673018069887
Validation loss: 2.3602574797951297

Epoch: 6| Step: 4
Training loss: 0.0673992337382906
Validation loss: 2.3475442867536938

Epoch: 6| Step: 5
Training loss: 0.10174066248959629
Validation loss: 2.3566659653281663

Epoch: 6| Step: 6
Training loss: 0.049379820229999816
Validation loss: 2.371170244626612

Epoch: 6| Step: 7
Training loss: 0.08879834956861701
Validation loss: 2.373623904279241

Epoch: 6| Step: 8
Training loss: 0.061360677504940016
Validation loss: 2.3656537793996595

Epoch: 6| Step: 9
Training loss: 0.07600751591974615
Validation loss: 2.3760117824338676

Epoch: 6| Step: 10
Training loss: 0.08508876250192586
Validation loss: 2.3754930918048034

Epoch: 6| Step: 11
Training loss: 0.09312251822153686
Validation loss: 2.382450346690191

Epoch: 6| Step: 12
Training loss: 0.05622998757469523
Validation loss: 2.3728272797985364

Epoch: 6| Step: 13
Training loss: 0.040056240944047396
Validation loss: 2.344074146456677

Epoch: 772| Step: 0
Training loss: 0.05686345949765445
Validation loss: 2.3612361576458447

Epoch: 6| Step: 1
Training loss: 0.0448139204815325
Validation loss: 2.352612154149585

Epoch: 6| Step: 2
Training loss: 0.08009496372239462
Validation loss: 2.362759726695564

Epoch: 6| Step: 3
Training loss: 0.09520286093405547
Validation loss: 2.338450481958283

Epoch: 6| Step: 4
Training loss: 0.07133627986982466
Validation loss: 2.346117916238617

Epoch: 6| Step: 5
Training loss: 0.09166870401657895
Validation loss: 2.3498611157809384

Epoch: 6| Step: 6
Training loss: 0.12751417165422782
Validation loss: 2.355048188184462

Epoch: 6| Step: 7
Training loss: 0.07322528644110468
Validation loss: 2.3647510486613452

Epoch: 6| Step: 8
Training loss: 0.05792055438707238
Validation loss: 2.3554732863556103

Epoch: 6| Step: 9
Training loss: 0.07620341613839847
Validation loss: 2.3895229298242318

Epoch: 6| Step: 10
Training loss: 0.05512099373217485
Validation loss: 2.386259566199115

Epoch: 6| Step: 11
Training loss: 0.07717883440749636
Validation loss: 2.4008569528684762

Epoch: 6| Step: 12
Training loss: 0.07046955502551401
Validation loss: 2.4061717566820495

Epoch: 6| Step: 13
Training loss: 0.11472236306749443
Validation loss: 2.3806848196941646

Epoch: 773| Step: 0
Training loss: 0.09029143168539557
Validation loss: 2.3777682336471884

Epoch: 6| Step: 1
Training loss: 0.09311770759422551
Validation loss: 2.422722754429877

Epoch: 6| Step: 2
Training loss: 0.08535235227834853
Validation loss: 2.396209646224943

Epoch: 6| Step: 3
Training loss: 0.07358291526478472
Validation loss: 2.3828857625789954

Epoch: 6| Step: 4
Training loss: 0.07257157077493107
Validation loss: 2.3883272458583047

Epoch: 6| Step: 5
Training loss: 0.07176244347507309
Validation loss: 2.374841731205389

Epoch: 6| Step: 6
Training loss: 0.11812535747595088
Validation loss: 2.3843977387751893

Epoch: 6| Step: 7
Training loss: 0.09391813301396047
Validation loss: 2.376201292230324

Epoch: 6| Step: 8
Training loss: 0.0649985943582659
Validation loss: 2.366860068598873

Epoch: 6| Step: 9
Training loss: 0.08418704407889933
Validation loss: 2.3755960504509943

Epoch: 6| Step: 10
Training loss: 0.05386289644819707
Validation loss: 2.3511114478628437

Epoch: 6| Step: 11
Training loss: 0.04475060237513727
Validation loss: 2.3648803518610686

Epoch: 6| Step: 12
Training loss: 0.09555996190742938
Validation loss: 2.360927539021333

Epoch: 6| Step: 13
Training loss: 0.10346706168918106
Validation loss: 2.3690566938837594

Epoch: 774| Step: 0
Training loss: 0.07092366899291765
Validation loss: 2.3864552992055312

Epoch: 6| Step: 1
Training loss: 0.08719042708583395
Validation loss: 2.364687960443392

Epoch: 6| Step: 2
Training loss: 0.052154375838302194
Validation loss: 2.405084496854613

Epoch: 6| Step: 3
Training loss: 0.08747724701318127
Validation loss: 2.371796440546285

Epoch: 6| Step: 4
Training loss: 0.09837406040485763
Validation loss: 2.394220990070937

Epoch: 6| Step: 5
Training loss: 0.0751566508841579
Validation loss: 2.3768028827708996

Epoch: 6| Step: 6
Training loss: 0.05160040130723705
Validation loss: 2.401996489873758

Epoch: 6| Step: 7
Training loss: 0.07359939570750615
Validation loss: 2.3816927210766945

Epoch: 6| Step: 8
Training loss: 0.08952270034258838
Validation loss: 2.392024199716719

Epoch: 6| Step: 9
Training loss: 0.08374199434438373
Validation loss: 2.38189310283425

Epoch: 6| Step: 10
Training loss: 0.048430434988437486
Validation loss: 2.3936486261853345

Epoch: 6| Step: 11
Training loss: 0.06650618088539123
Validation loss: 2.386351188508587

Epoch: 6| Step: 12
Training loss: 0.05292031171675882
Validation loss: 2.390895571092913

Epoch: 6| Step: 13
Training loss: 0.09593149108893703
Validation loss: 2.374101311167696

Epoch: 775| Step: 0
Training loss: 0.08180433348159322
Validation loss: 2.385867866660269

Epoch: 6| Step: 1
Training loss: 0.04737046275800309
Validation loss: 2.379409904567774

Epoch: 6| Step: 2
Training loss: 0.10959854017366844
Validation loss: 2.374244433748185

Epoch: 6| Step: 3
Training loss: 0.0690605173646277
Validation loss: 2.3903295538288547

Epoch: 6| Step: 4
Training loss: 0.04372365069726053
Validation loss: 2.3765822333802262

Epoch: 6| Step: 5
Training loss: 0.06534806184576107
Validation loss: 2.4077830545616337

Epoch: 6| Step: 6
Training loss: 0.0618619047802929
Validation loss: 2.4049961438737686

Epoch: 6| Step: 7
Training loss: 0.08223533221163734
Validation loss: 2.419878650714163

Epoch: 6| Step: 8
Training loss: 0.08201493941231457
Validation loss: 2.408670391510127

Epoch: 6| Step: 9
Training loss: 0.06422156584151427
Validation loss: 2.398024284230287

Epoch: 6| Step: 10
Training loss: 0.10662777162999049
Validation loss: 2.39223450333435

Epoch: 6| Step: 11
Training loss: 0.07067821021553256
Validation loss: 2.384066849530203

Epoch: 6| Step: 12
Training loss: 0.05977374657443941
Validation loss: 2.3890999204124417

Epoch: 6| Step: 13
Training loss: 0.08777691054592715
Validation loss: 2.417409170341187

Epoch: 776| Step: 0
Training loss: 0.09406041372716675
Validation loss: 2.398880613828667

Epoch: 6| Step: 1
Training loss: 0.08404312463116934
Validation loss: 2.3934618804956247

Epoch: 6| Step: 2
Training loss: 0.07598512939558705
Validation loss: 2.3788238068727474

Epoch: 6| Step: 3
Training loss: 0.08872957368970673
Validation loss: 2.3797550957803835

Epoch: 6| Step: 4
Training loss: 0.06965729962469863
Validation loss: 2.380047227222542

Epoch: 6| Step: 5
Training loss: 0.06988905184224896
Validation loss: 2.3921400643641038

Epoch: 6| Step: 6
Training loss: 0.052793619643703334
Validation loss: 2.3633182659350376

Epoch: 6| Step: 7
Training loss: 0.08095938756203257
Validation loss: 2.362787023461216

Epoch: 6| Step: 8
Training loss: 0.09479422463207496
Validation loss: 2.3761189269334104

Epoch: 6| Step: 9
Training loss: 0.07768519105955647
Validation loss: 2.362826242886433

Epoch: 6| Step: 10
Training loss: 0.07410554031610715
Validation loss: 2.3670381639501197

Epoch: 6| Step: 11
Training loss: 0.08348790624976322
Validation loss: 2.365295890059038

Epoch: 6| Step: 12
Training loss: 0.08283225174838317
Validation loss: 2.347433730803509

Epoch: 6| Step: 13
Training loss: 0.07650805223248805
Validation loss: 2.3445597055966494

Epoch: 777| Step: 0
Training loss: 0.08346429297316851
Validation loss: 2.3628992346695923

Epoch: 6| Step: 1
Training loss: 0.07207731895194543
Validation loss: 2.332156293909381

Epoch: 6| Step: 2
Training loss: 0.09060230546459005
Validation loss: 2.3502517910468605

Epoch: 6| Step: 3
Training loss: 0.05942730466379066
Validation loss: 2.336085376125708

Epoch: 6| Step: 4
Training loss: 0.07811590082108667
Validation loss: 2.3440472606436744

Epoch: 6| Step: 5
Training loss: 0.06343833432447567
Validation loss: 2.3617183384225977

Epoch: 6| Step: 6
Training loss: 0.05557931756726023
Validation loss: 2.3626185744483843

Epoch: 6| Step: 7
Training loss: 0.058926078980869274
Validation loss: 2.381019151706511

Epoch: 6| Step: 8
Training loss: 0.06148708495671583
Validation loss: 2.37447713786122

Epoch: 6| Step: 9
Training loss: 0.05035103760276279
Validation loss: 2.367241800500992

Epoch: 6| Step: 10
Training loss: 0.08331385461824921
Validation loss: 2.3758023940760564

Epoch: 6| Step: 11
Training loss: 0.05580563694673474
Validation loss: 2.381864580612359

Epoch: 6| Step: 12
Training loss: 0.08211069574210333
Validation loss: 2.3802326569416445

Epoch: 6| Step: 13
Training loss: 0.10158118204540424
Validation loss: 2.3819902674083187

Epoch: 778| Step: 0
Training loss: 0.058325012162033965
Validation loss: 2.39485072405431

Epoch: 6| Step: 1
Training loss: 0.04783414017501354
Validation loss: 2.38349596668098

Epoch: 6| Step: 2
Training loss: 0.0868989149030957
Validation loss: 2.357614073723772

Epoch: 6| Step: 3
Training loss: 0.07555473802509814
Validation loss: 2.403279496711072

Epoch: 6| Step: 4
Training loss: 0.05269628712280901
Validation loss: 2.3948202745824876

Epoch: 6| Step: 5
Training loss: 0.06301480850997959
Validation loss: 2.3905155924400097

Epoch: 6| Step: 6
Training loss: 0.05429696384944096
Validation loss: 2.388662127729142

Epoch: 6| Step: 7
Training loss: 0.09802158208051638
Validation loss: 2.343086086294674

Epoch: 6| Step: 8
Training loss: 0.08737615907020349
Validation loss: 2.3534914057942427

Epoch: 6| Step: 9
Training loss: 0.07323839177786545
Validation loss: 2.355525689989565

Epoch: 6| Step: 10
Training loss: 0.07807395280615315
Validation loss: 2.3401708662367455

Epoch: 6| Step: 11
Training loss: 0.09134303682598946
Validation loss: 2.3215037597286

Epoch: 6| Step: 12
Training loss: 0.06881634358625541
Validation loss: 2.353156263259816

Epoch: 6| Step: 13
Training loss: 0.07849096473192486
Validation loss: 2.3377677696112107

Epoch: 779| Step: 0
Training loss: 0.07065400661996776
Validation loss: 2.348497560604604

Epoch: 6| Step: 1
Training loss: 0.05931535865604715
Validation loss: 2.3433445186637147

Epoch: 6| Step: 2
Training loss: 0.07028396345254412
Validation loss: 2.3298285402328833

Epoch: 6| Step: 3
Training loss: 0.06459532569989758
Validation loss: 2.3481812358231577

Epoch: 6| Step: 4
Training loss: 0.07741686442932154
Validation loss: 2.349993557005886

Epoch: 6| Step: 5
Training loss: 0.08396411806703834
Validation loss: 2.3341657385047556

Epoch: 6| Step: 6
Training loss: 0.053070649664285284
Validation loss: 2.3347949685017815

Epoch: 6| Step: 7
Training loss: 0.05506442445773134
Validation loss: 2.3163969506667423

Epoch: 6| Step: 8
Training loss: 0.0685949625677105
Validation loss: 2.336342945718441

Epoch: 6| Step: 9
Training loss: 0.08791974962661041
Validation loss: 2.324442624134832

Epoch: 6| Step: 10
Training loss: 0.046393521964456924
Validation loss: 2.3511295330880597

Epoch: 6| Step: 11
Training loss: 0.103252517365278
Validation loss: 2.33424173931196

Epoch: 6| Step: 12
Training loss: 0.09023063742753448
Validation loss: 2.3791074871267868

Epoch: 6| Step: 13
Training loss: 0.0797327811718944
Validation loss: 2.3534615655251785

Epoch: 780| Step: 0
Training loss: 0.047105572283692956
Validation loss: 2.3504350542070642

Epoch: 6| Step: 1
Training loss: 0.045682763083556115
Validation loss: 2.347677573387249

Epoch: 6| Step: 2
Training loss: 0.07710003541680122
Validation loss: 2.3531339595726353

Epoch: 6| Step: 3
Training loss: 0.09621623246540961
Validation loss: 2.352005338209925

Epoch: 6| Step: 4
Training loss: 0.07569790981623052
Validation loss: 2.338845234086947

Epoch: 6| Step: 5
Training loss: 0.060964241793079195
Validation loss: 2.3183272922171443

Epoch: 6| Step: 6
Training loss: 0.05280896051526258
Validation loss: 2.3538158700601404

Epoch: 6| Step: 7
Training loss: 0.09830413480662566
Validation loss: 2.343769324438353

Epoch: 6| Step: 8
Training loss: 0.06021865589523485
Validation loss: 2.372788464454676

Epoch: 6| Step: 9
Training loss: 0.08075822478996668
Validation loss: 2.380050264212765

Epoch: 6| Step: 10
Training loss: 0.05398486036076951
Validation loss: 2.3821309971497184

Epoch: 6| Step: 11
Training loss: 0.0800479390075308
Validation loss: 2.3796161173275525

Epoch: 6| Step: 12
Training loss: 0.07913821160231975
Validation loss: 2.367807311561259

Epoch: 6| Step: 13
Training loss: 0.07257225092922046
Validation loss: 2.385938644169834

Epoch: 781| Step: 0
Training loss: 0.10651475933272135
Validation loss: 2.393074318967879

Epoch: 6| Step: 1
Training loss: 0.06588604471915023
Validation loss: 2.4023857149716914

Epoch: 6| Step: 2
Training loss: 0.06488149073182853
Validation loss: 2.385211988639097

Epoch: 6| Step: 3
Training loss: 0.08679799301927878
Validation loss: 2.4218390624535417

Epoch: 6| Step: 4
Training loss: 0.0912537843755582
Validation loss: 2.389739901452205

Epoch: 6| Step: 5
Training loss: 0.10313391484394654
Validation loss: 2.3788079054663904

Epoch: 6| Step: 6
Training loss: 0.06374869334761095
Validation loss: 2.384287842786086

Epoch: 6| Step: 7
Training loss: 0.05217908635459286
Validation loss: 2.361300060614661

Epoch: 6| Step: 8
Training loss: 0.09716765245549082
Validation loss: 2.373382774423713

Epoch: 6| Step: 9
Training loss: 0.08308314943769526
Validation loss: 2.3720927506094602

Epoch: 6| Step: 10
Training loss: 0.06304481837429214
Validation loss: 2.3859265417464948

Epoch: 6| Step: 11
Training loss: 0.08742874162431752
Validation loss: 2.35867169187646

Epoch: 6| Step: 12
Training loss: 0.05983748673675853
Validation loss: 2.3528517363913877

Epoch: 6| Step: 13
Training loss: 0.05494208130691294
Validation loss: 2.3244967778201273

Epoch: 782| Step: 0
Training loss: 0.07454827525559408
Validation loss: 2.3339954292377807

Epoch: 6| Step: 1
Training loss: 0.06602404148578009
Validation loss: 2.3520409105539692

Epoch: 6| Step: 2
Training loss: 0.05776139373349907
Validation loss: 2.3342302348471993

Epoch: 6| Step: 3
Training loss: 0.07130444047274222
Validation loss: 2.3446456576027472

Epoch: 6| Step: 4
Training loss: 0.05378722495221038
Validation loss: 2.3509507693685534

Epoch: 6| Step: 5
Training loss: 0.07316549736607818
Validation loss: 2.3466110890983893

Epoch: 6| Step: 6
Training loss: 0.04958659929567431
Validation loss: 2.368954324888738

Epoch: 6| Step: 7
Training loss: 0.05912857350499433
Validation loss: 2.386140253551513

Epoch: 6| Step: 8
Training loss: 0.07973900374100777
Validation loss: 2.3574248272246874

Epoch: 6| Step: 9
Training loss: 0.08601436103876124
Validation loss: 2.3734801512952126

Epoch: 6| Step: 10
Training loss: 0.08331458960031747
Validation loss: 2.3566880720082852

Epoch: 6| Step: 11
Training loss: 0.06694959893840093
Validation loss: 2.356762647073511

Epoch: 6| Step: 12
Training loss: 0.08589640631882842
Validation loss: 2.3681265239237432

Epoch: 6| Step: 13
Training loss: 0.09451078634793472
Validation loss: 2.3767824624603398

Epoch: 783| Step: 0
Training loss: 0.07587081149212307
Validation loss: 2.355165436495682

Epoch: 6| Step: 1
Training loss: 0.0858778312916007
Validation loss: 2.364470386251531

Epoch: 6| Step: 2
Training loss: 0.06864467757115067
Validation loss: 2.3754915453055783

Epoch: 6| Step: 3
Training loss: 0.07155661151118123
Validation loss: 2.390768602457462

Epoch: 6| Step: 4
Training loss: 0.10297309658647667
Validation loss: 2.369802562891861

Epoch: 6| Step: 5
Training loss: 0.07861559135881191
Validation loss: 2.383536098384768

Epoch: 6| Step: 6
Training loss: 0.08212546773418791
Validation loss: 2.358221539109761

Epoch: 6| Step: 7
Training loss: 0.06694152323112766
Validation loss: 2.3978038459989746

Epoch: 6| Step: 8
Training loss: 0.04830582221042029
Validation loss: 2.3675385815227745

Epoch: 6| Step: 9
Training loss: 0.06871221964595721
Validation loss: 2.390532044939877

Epoch: 6| Step: 10
Training loss: 0.05597737668104819
Validation loss: 2.368753312886984

Epoch: 6| Step: 11
Training loss: 0.06580361230817154
Validation loss: 2.3940932083594957

Epoch: 6| Step: 12
Training loss: 0.059396576411854037
Validation loss: 2.39359230390197

Epoch: 6| Step: 13
Training loss: 0.09739542940212405
Validation loss: 2.3919678054231523

Epoch: 784| Step: 0
Training loss: 0.10817026489731309
Validation loss: 2.3771705542488752

Epoch: 6| Step: 1
Training loss: 0.07377641395778331
Validation loss: 2.363390782596958

Epoch: 6| Step: 2
Training loss: 0.09294163865588762
Validation loss: 2.3520016110176623

Epoch: 6| Step: 3
Training loss: 0.05588144178281329
Validation loss: 2.359159833982998

Epoch: 6| Step: 4
Training loss: 0.0992738176703144
Validation loss: 2.3427771919577856

Epoch: 6| Step: 5
Training loss: 0.07903755211845766
Validation loss: 2.334116178877277

Epoch: 6| Step: 6
Training loss: 0.06047661611862378
Validation loss: 2.3465005487236796

Epoch: 6| Step: 7
Training loss: 0.09223543068735464
Validation loss: 2.347120679205927

Epoch: 6| Step: 8
Training loss: 0.11536850235513235
Validation loss: 2.342018019089582

Epoch: 6| Step: 9
Training loss: 0.12644432520016924
Validation loss: 2.354430231195423

Epoch: 6| Step: 10
Training loss: 0.050960497224693334
Validation loss: 2.3736559886695683

Epoch: 6| Step: 11
Training loss: 0.05415154843687791
Validation loss: 2.3862825487861614

Epoch: 6| Step: 12
Training loss: 0.08488170722245333
Validation loss: 2.380346642136442

Epoch: 6| Step: 13
Training loss: 0.07876779937448217
Validation loss: 2.402358829728753

Epoch: 785| Step: 0
Training loss: 0.10190935693524104
Validation loss: 2.4075792096208395

Epoch: 6| Step: 1
Training loss: 0.08172956691398085
Validation loss: 2.381435439238362

Epoch: 6| Step: 2
Training loss: 0.09251196303848984
Validation loss: 2.4025231820697384

Epoch: 6| Step: 3
Training loss: 0.09815520612822894
Validation loss: 2.396816836848793

Epoch: 6| Step: 4
Training loss: 0.04783217124793865
Validation loss: 2.397886035880676

Epoch: 6| Step: 5
Training loss: 0.07306817682522873
Validation loss: 2.369144312784673

Epoch: 6| Step: 6
Training loss: 0.09223289624721402
Validation loss: 2.3744596898655974

Epoch: 6| Step: 7
Training loss: 0.07021123826448619
Validation loss: 2.374531727271976

Epoch: 6| Step: 8
Training loss: 0.05956477780504875
Validation loss: 2.408541337541683

Epoch: 6| Step: 9
Training loss: 0.07021692522277077
Validation loss: 2.363530460765092

Epoch: 6| Step: 10
Training loss: 0.07910437932120673
Validation loss: 2.3844406560790583

Epoch: 6| Step: 11
Training loss: 0.08042359555069516
Validation loss: 2.3616150434263607

Epoch: 6| Step: 12
Training loss: 0.07443748103120724
Validation loss: 2.365083150950054

Epoch: 6| Step: 13
Training loss: 0.06548700028761469
Validation loss: 2.371590678560363

Epoch: 786| Step: 0
Training loss: 0.0814990650698214
Validation loss: 2.348125214977982

Epoch: 6| Step: 1
Training loss: 0.09057549324706816
Validation loss: 2.3396467412538358

Epoch: 6| Step: 2
Training loss: 0.05893299520763454
Validation loss: 2.352876482999521

Epoch: 6| Step: 3
Training loss: 0.06818125202000788
Validation loss: 2.3605999943707627

Epoch: 6| Step: 4
Training loss: 0.05257119212064485
Validation loss: 2.3953039300440695

Epoch: 6| Step: 5
Training loss: 0.08570352586393401
Validation loss: 2.385172863760295

Epoch: 6| Step: 6
Training loss: 0.05923832759421448
Validation loss: 2.3846728823103582

Epoch: 6| Step: 7
Training loss: 0.04939072504534269
Validation loss: 2.3679575507434865

Epoch: 6| Step: 8
Training loss: 0.05368818971789835
Validation loss: 2.3785520878256228

Epoch: 6| Step: 9
Training loss: 0.07177407717894634
Validation loss: 2.389991016143652

Epoch: 6| Step: 10
Training loss: 0.056193550166419755
Validation loss: 2.3719463730160713

Epoch: 6| Step: 11
Training loss: 0.04198720397875034
Validation loss: 2.3929810618605982

Epoch: 6| Step: 12
Training loss: 0.06709837310966833
Validation loss: 2.388436833088562

Epoch: 6| Step: 13
Training loss: 0.07900939681845696
Validation loss: 2.401773480882752

Epoch: 787| Step: 0
Training loss: 0.07494981435236006
Validation loss: 2.395620254379162

Epoch: 6| Step: 1
Training loss: 0.04815376233864257
Validation loss: 2.4126293349820407

Epoch: 6| Step: 2
Training loss: 0.08989876638285849
Validation loss: 2.3989693940152454

Epoch: 6| Step: 3
Training loss: 0.08243960680214446
Validation loss: 2.378649645654647

Epoch: 6| Step: 4
Training loss: 0.05484757666809251
Validation loss: 2.373092863608791

Epoch: 6| Step: 5
Training loss: 0.07824983755565576
Validation loss: 2.380702027696231

Epoch: 6| Step: 6
Training loss: 0.06289965656540976
Validation loss: 2.37425960394445

Epoch: 6| Step: 7
Training loss: 0.059190105474918105
Validation loss: 2.370868798759171

Epoch: 6| Step: 8
Training loss: 0.08278943676354131
Validation loss: 2.3510367753233887

Epoch: 6| Step: 9
Training loss: 0.05806030593928845
Validation loss: 2.3804723261533294

Epoch: 6| Step: 10
Training loss: 0.05471702187563543
Validation loss: 2.368317313226004

Epoch: 6| Step: 11
Training loss: 0.05244515945458268
Validation loss: 2.358478093426772

Epoch: 6| Step: 12
Training loss: 0.09661999217759319
Validation loss: 2.385067279866192

Epoch: 6| Step: 13
Training loss: 0.07735347060568373
Validation loss: 2.375651530873042

Epoch: 788| Step: 0
Training loss: 0.04837393762502532
Validation loss: 2.377897738936783

Epoch: 6| Step: 1
Training loss: 0.04290788305908916
Validation loss: 2.376032248210388

Epoch: 6| Step: 2
Training loss: 0.06643819040817148
Validation loss: 2.3779341917881154

Epoch: 6| Step: 3
Training loss: 0.06175680028796477
Validation loss: 2.3554417373886998

Epoch: 6| Step: 4
Training loss: 0.06565706400704839
Validation loss: 2.3757572639924565

Epoch: 6| Step: 5
Training loss: 0.10421449089927111
Validation loss: 2.3889021977040144

Epoch: 6| Step: 6
Training loss: 0.06570980972412559
Validation loss: 2.3794683391846667

Epoch: 6| Step: 7
Training loss: 0.07016148509435507
Validation loss: 2.384456430684683

Epoch: 6| Step: 8
Training loss: 0.07506523399749848
Validation loss: 2.3730379775003008

Epoch: 6| Step: 9
Training loss: 0.03227117549882561
Validation loss: 2.3595240963567816

Epoch: 6| Step: 10
Training loss: 0.07077782686326439
Validation loss: 2.3481973429880645

Epoch: 6| Step: 11
Training loss: 0.09186859575644436
Validation loss: 2.386215371434604

Epoch: 6| Step: 12
Training loss: 0.039166470087624194
Validation loss: 2.360923964362128

Epoch: 6| Step: 13
Training loss: 0.07813705112970333
Validation loss: 2.394463288018015

Epoch: 789| Step: 0
Training loss: 0.0395755528357969
Validation loss: 2.3819427995681965

Epoch: 6| Step: 1
Training loss: 0.0663594614014446
Validation loss: 2.3733601697416353

Epoch: 6| Step: 2
Training loss: 0.08485605079568212
Validation loss: 2.3909709523804135

Epoch: 6| Step: 3
Training loss: 0.08409069229337914
Validation loss: 2.3926555214694787

Epoch: 6| Step: 4
Training loss: 0.055951986285167024
Validation loss: 2.3852421346129122

Epoch: 6| Step: 5
Training loss: 0.06479034206415263
Validation loss: 2.392989567564624

Epoch: 6| Step: 6
Training loss: 0.05764272495646982
Validation loss: 2.389654390519676

Epoch: 6| Step: 7
Training loss: 0.057177455764599906
Validation loss: 2.4040352972190946

Epoch: 6| Step: 8
Training loss: 0.07696305709489783
Validation loss: 2.4049106935713294

Epoch: 6| Step: 9
Training loss: 0.041229750646412065
Validation loss: 2.4051163225114403

Epoch: 6| Step: 10
Training loss: 0.0822925040447912
Validation loss: 2.3894423727734444

Epoch: 6| Step: 11
Training loss: 0.051785722440979697
Validation loss: 2.375057884681011

Epoch: 6| Step: 12
Training loss: 0.05710371187352958
Validation loss: 2.3607844002021174

Epoch: 6| Step: 13
Training loss: 0.0639907042082639
Validation loss: 2.3863277940500436

Epoch: 790| Step: 0
Training loss: 0.05890838072791032
Validation loss: 2.3583870932684263

Epoch: 6| Step: 1
Training loss: 0.06530291816704958
Validation loss: 2.3710068567522278

Epoch: 6| Step: 2
Training loss: 0.054811927897633166
Validation loss: 2.354484254274637

Epoch: 6| Step: 3
Training loss: 0.07320084994759389
Validation loss: 2.388063041231787

Epoch: 6| Step: 4
Training loss: 0.04846313917019201
Validation loss: 2.3537220282259983

Epoch: 6| Step: 5
Training loss: 0.06183423904476873
Validation loss: 2.3789023860642255

Epoch: 6| Step: 6
Training loss: 0.0514191397417886
Validation loss: 2.3813611265480654

Epoch: 6| Step: 7
Training loss: 0.06755393179528929
Validation loss: 2.3654888638688956

Epoch: 6| Step: 8
Training loss: 0.07257150660910303
Validation loss: 2.391168890528535

Epoch: 6| Step: 9
Training loss: 0.0627959775722928
Validation loss: 2.3664667968319013

Epoch: 6| Step: 10
Training loss: 0.07017346384419533
Validation loss: 2.3502911007535685

Epoch: 6| Step: 11
Training loss: 0.061195947568070425
Validation loss: 2.357881049812232

Epoch: 6| Step: 12
Training loss: 0.080609211965338
Validation loss: 2.390973562156118

Epoch: 6| Step: 13
Training loss: 0.04162122330137486
Validation loss: 2.3738817551899762

Epoch: 791| Step: 0
Training loss: 0.07658783118951676
Validation loss: 2.3494468200866048

Epoch: 6| Step: 1
Training loss: 0.056238982492547426
Validation loss: 2.36293416943753

Epoch: 6| Step: 2
Training loss: 0.05046591143257812
Validation loss: 2.3842389400766946

Epoch: 6| Step: 3
Training loss: 0.06623735055743729
Validation loss: 2.425775626596145

Epoch: 6| Step: 4
Training loss: 0.08661642169502036
Validation loss: 2.3775609996207763

Epoch: 6| Step: 5
Training loss: 0.0643588735232597
Validation loss: 2.3692030611905612

Epoch: 6| Step: 6
Training loss: 0.07074942205836669
Validation loss: 2.3605228558285827

Epoch: 6| Step: 7
Training loss: 0.10796683536107146
Validation loss: 2.3570480215401055

Epoch: 6| Step: 8
Training loss: 0.06874768120474906
Validation loss: 2.3325547355479763

Epoch: 6| Step: 9
Training loss: 0.08135084830589459
Validation loss: 2.3576470697301

Epoch: 6| Step: 10
Training loss: 0.07342602546307499
Validation loss: 2.352830578663123

Epoch: 6| Step: 11
Training loss: 0.04911113736701005
Validation loss: 2.349135633894563

Epoch: 6| Step: 12
Training loss: 0.054011485876810574
Validation loss: 2.3696872666999953

Epoch: 6| Step: 13
Training loss: 0.08600500554908087
Validation loss: 2.3458649016842448

Epoch: 792| Step: 0
Training loss: 0.05480191914397196
Validation loss: 2.351209025304356

Epoch: 6| Step: 1
Training loss: 0.05059487271285489
Validation loss: 2.3530341221103463

Epoch: 6| Step: 2
Training loss: 0.053829642815637936
Validation loss: 2.3546320478552314

Epoch: 6| Step: 3
Training loss: 0.07318447382295712
Validation loss: 2.360864176515931

Epoch: 6| Step: 4
Training loss: 0.0712653277352692
Validation loss: 2.3760021709676535

Epoch: 6| Step: 5
Training loss: 0.05901893683138047
Validation loss: 2.376117420222091

Epoch: 6| Step: 6
Training loss: 0.04379003031347678
Validation loss: 2.357543533825908

Epoch: 6| Step: 7
Training loss: 0.07599167416088289
Validation loss: 2.3737935308696523

Epoch: 6| Step: 8
Training loss: 0.047435876917494874
Validation loss: 2.3768507736001796

Epoch: 6| Step: 9
Training loss: 0.05383072629838493
Validation loss: 2.366299745169748

Epoch: 6| Step: 10
Training loss: 0.07285679512049882
Validation loss: 2.365974326850406

Epoch: 6| Step: 11
Training loss: 0.06078053962493429
Validation loss: 2.379245995329586

Epoch: 6| Step: 12
Training loss: 0.07338115859261946
Validation loss: 2.393016530751887

Epoch: 6| Step: 13
Training loss: 0.09259137811239576
Validation loss: 2.3936898696601037

Epoch: 793| Step: 0
Training loss: 0.05417878822647479
Validation loss: 2.3996243835167785

Epoch: 6| Step: 1
Training loss: 0.07625190797454989
Validation loss: 2.34748413739229

Epoch: 6| Step: 2
Training loss: 0.08220274913399549
Validation loss: 2.3744302912603903

Epoch: 6| Step: 3
Training loss: 0.0801071079652117
Validation loss: 2.3620124379766794

Epoch: 6| Step: 4
Training loss: 0.08555106496783463
Validation loss: 2.375348259888789

Epoch: 6| Step: 5
Training loss: 0.05431711630921222
Validation loss: 2.382203086146253

Epoch: 6| Step: 6
Training loss: 0.059106368577317256
Validation loss: 2.353982047173306

Epoch: 6| Step: 7
Training loss: 0.058596058641093136
Validation loss: 2.3819341570131973

Epoch: 6| Step: 8
Training loss: 0.09083562127164353
Validation loss: 2.3627809061834126

Epoch: 6| Step: 9
Training loss: 0.06571686408832834
Validation loss: 2.381489928355042

Epoch: 6| Step: 10
Training loss: 0.07075909999031132
Validation loss: 2.3728665461139267

Epoch: 6| Step: 11
Training loss: 0.05350277182493278
Validation loss: 2.3721401869803445

Epoch: 6| Step: 12
Training loss: 0.06115944985861746
Validation loss: 2.353425069122134

Epoch: 6| Step: 13
Training loss: 0.09054313427305041
Validation loss: 2.359389737729763

Epoch: 794| Step: 0
Training loss: 0.05937173843836915
Validation loss: 2.373866821246463

Epoch: 6| Step: 1
Training loss: 0.05262062821186916
Validation loss: 2.3584265510882365

Epoch: 6| Step: 2
Training loss: 0.0531424477970379
Validation loss: 2.3608046955563657

Epoch: 6| Step: 3
Training loss: 0.07265340661053339
Validation loss: 2.371044745997008

Epoch: 6| Step: 4
Training loss: 0.08786003587142824
Validation loss: 2.388574135398043

Epoch: 6| Step: 5
Training loss: 0.07392196544640878
Validation loss: 2.367844109766341

Epoch: 6| Step: 6
Training loss: 0.07225390609883099
Validation loss: 2.3800139337140243

Epoch: 6| Step: 7
Training loss: 0.1288048244037596
Validation loss: 2.3606496354711646

Epoch: 6| Step: 8
Training loss: 0.06199313809027176
Validation loss: 2.378335598702662

Epoch: 6| Step: 9
Training loss: 0.04560219499735269
Validation loss: 2.3682254473341375

Epoch: 6| Step: 10
Training loss: 0.06205994690515781
Validation loss: 2.369727362339854

Epoch: 6| Step: 11
Training loss: 0.059522633154206354
Validation loss: 2.3618391398676173

Epoch: 6| Step: 12
Training loss: 0.06627255191996004
Validation loss: 2.33821560347641

Epoch: 6| Step: 13
Training loss: 0.06736574440553703
Validation loss: 2.339955239193459

Epoch: 795| Step: 0
Training loss: 0.08249843767973489
Validation loss: 2.346122255409926

Epoch: 6| Step: 1
Training loss: 0.07626933501996185
Validation loss: 2.329982812728208

Epoch: 6| Step: 2
Training loss: 0.0771376626421602
Validation loss: 2.364600367229719

Epoch: 6| Step: 3
Training loss: 0.09626996274554617
Validation loss: 2.3491355094849564

Epoch: 6| Step: 4
Training loss: 0.1079846810927294
Validation loss: 2.3352797336634152

Epoch: 6| Step: 5
Training loss: 0.057384822529800636
Validation loss: 2.3452326306578923

Epoch: 6| Step: 6
Training loss: 0.050266941984003395
Validation loss: 2.3307183513893417

Epoch: 6| Step: 7
Training loss: 0.07586836870586172
Validation loss: 2.323928452263424

Epoch: 6| Step: 8
Training loss: 0.06110623988729602
Validation loss: 2.32632255305549

Epoch: 6| Step: 9
Training loss: 0.04042893837497348
Validation loss: 2.3250817384089553

Epoch: 6| Step: 10
Training loss: 0.11343760634251804
Validation loss: 2.3445529079296987

Epoch: 6| Step: 11
Training loss: 0.04680784700248958
Validation loss: 2.318072060534498

Epoch: 6| Step: 12
Training loss: 0.07268858543850015
Validation loss: 2.3455240274962037

Epoch: 6| Step: 13
Training loss: 0.07285800309641312
Validation loss: 2.3647830458314028

Epoch: 796| Step: 0
Training loss: 0.04990933447692217
Validation loss: 2.369906634697559

Epoch: 6| Step: 1
Training loss: 0.057655338006185435
Validation loss: 2.379940080761363

Epoch: 6| Step: 2
Training loss: 0.0935729062811036
Validation loss: 2.393632214921086

Epoch: 6| Step: 3
Training loss: 0.05824759076100449
Validation loss: 2.3874730551097456

Epoch: 6| Step: 4
Training loss: 0.05126761478293566
Validation loss: 2.389390144342317

Epoch: 6| Step: 5
Training loss: 0.05848142068911287
Validation loss: 2.3890175715182003

Epoch: 6| Step: 6
Training loss: 0.08143576124615717
Validation loss: 2.3716218267768214

Epoch: 6| Step: 7
Training loss: 0.07968607157941632
Validation loss: 2.372571522896839

Epoch: 6| Step: 8
Training loss: 0.06588800243661233
Validation loss: 2.3928203118145857

Epoch: 6| Step: 9
Training loss: 0.0540045903733364
Validation loss: 2.4035208494754463

Epoch: 6| Step: 10
Training loss: 0.06053219124953833
Validation loss: 2.4010623486733444

Epoch: 6| Step: 11
Training loss: 0.08722486004020033
Validation loss: 2.3795051294375136

Epoch: 6| Step: 12
Training loss: 0.06424268411107842
Validation loss: 2.397040000034695

Epoch: 6| Step: 13
Training loss: 0.07512332827184566
Validation loss: 2.398414899505725

Epoch: 797| Step: 0
Training loss: 0.10628560535510292
Validation loss: 2.35599791550669

Epoch: 6| Step: 1
Training loss: 0.04661721134680638
Validation loss: 2.3783380129587504

Epoch: 6| Step: 2
Training loss: 0.05728141691175243
Validation loss: 2.3446639643637077

Epoch: 6| Step: 3
Training loss: 0.0642678748603466
Validation loss: 2.380800976678424

Epoch: 6| Step: 4
Training loss: 0.0862518300289047
Validation loss: 2.384259636299693

Epoch: 6| Step: 5
Training loss: 0.08686889589257507
Validation loss: 2.3784163125923103

Epoch: 6| Step: 6
Training loss: 0.06116683869195307
Validation loss: 2.3777094149207665

Epoch: 6| Step: 7
Training loss: 0.07500813149538439
Validation loss: 2.3993729858015596

Epoch: 6| Step: 8
Training loss: 0.08997586115339931
Validation loss: 2.3561479132212644

Epoch: 6| Step: 9
Training loss: 0.09010301375156819
Validation loss: 2.363244289081029

Epoch: 6| Step: 10
Training loss: 0.0931060150335317
Validation loss: 2.3758026902788516

Epoch: 6| Step: 11
Training loss: 0.05926842685292271
Validation loss: 2.3712093972913766

Epoch: 6| Step: 12
Training loss: 0.0698439230159349
Validation loss: 2.4025698943786633

Epoch: 6| Step: 13
Training loss: 0.050524758474435924
Validation loss: 2.393770987929178

Epoch: 798| Step: 0
Training loss: 0.07640973878864127
Validation loss: 2.40498313693914

Epoch: 6| Step: 1
Training loss: 0.0633947725817361
Validation loss: 2.4084497663856257

Epoch: 6| Step: 2
Training loss: 0.07937371566439264
Validation loss: 2.412884752640336

Epoch: 6| Step: 3
Training loss: 0.11608995824194834
Validation loss: 2.411153828638016

Epoch: 6| Step: 4
Training loss: 0.11212001627086794
Validation loss: 2.4026816291151762

Epoch: 6| Step: 5
Training loss: 0.05862043488348876
Validation loss: 2.4067686805994457

Epoch: 6| Step: 6
Training loss: 0.06780648071848615
Validation loss: 2.401332698160111

Epoch: 6| Step: 7
Training loss: 0.044216753498404746
Validation loss: 2.402085274431411

Epoch: 6| Step: 8
Training loss: 0.07003426802416253
Validation loss: 2.3999275089112433

Epoch: 6| Step: 9
Training loss: 0.040670685744054025
Validation loss: 2.372182964008976

Epoch: 6| Step: 10
Training loss: 0.051526318936614295
Validation loss: 2.3730987814580695

Epoch: 6| Step: 11
Training loss: 0.10098920923720833
Validation loss: 2.343789847524027

Epoch: 6| Step: 12
Training loss: 0.10162582623989282
Validation loss: 2.3634389197076504

Epoch: 6| Step: 13
Training loss: 0.07023288935277097
Validation loss: 2.3544339365769216

Epoch: 799| Step: 0
Training loss: 0.06781128780098977
Validation loss: 2.3823129439253337

Epoch: 6| Step: 1
Training loss: 0.09495708103108795
Validation loss: 2.3659651873980585

Epoch: 6| Step: 2
Training loss: 0.08424624933615879
Validation loss: 2.35263297385893

Epoch: 6| Step: 3
Training loss: 0.09189034329802377
Validation loss: 2.373879974374658

Epoch: 6| Step: 4
Training loss: 0.08827382896256188
Validation loss: 2.3989362001467804

Epoch: 6| Step: 5
Training loss: 0.06800968099675232
Validation loss: 2.383390941507363

Epoch: 6| Step: 6
Training loss: 0.07909020295228535
Validation loss: 2.407305753943225

Epoch: 6| Step: 7
Training loss: 0.06258716316770575
Validation loss: 2.3891440537703312

Epoch: 6| Step: 8
Training loss: 0.07303816353263762
Validation loss: 2.4098745640737844

Epoch: 6| Step: 9
Training loss: 0.06273426171098981
Validation loss: 2.4047663621057183

Epoch: 6| Step: 10
Training loss: 0.07336435302118861
Validation loss: 2.386448821491904

Epoch: 6| Step: 11
Training loss: 0.0690580764277288
Validation loss: 2.3898270173487974

Epoch: 6| Step: 12
Training loss: 0.06420907140225507
Validation loss: 2.3971654675935916

Epoch: 6| Step: 13
Training loss: 0.05242387213860924
Validation loss: 2.4044954188576697

Epoch: 800| Step: 0
Training loss: 0.04767020804770656
Validation loss: 2.4108484626055597

Epoch: 6| Step: 1
Training loss: 0.10339899960787707
Validation loss: 2.3920140952809175

Epoch: 6| Step: 2
Training loss: 0.051546615082766846
Validation loss: 2.406580788918005

Epoch: 6| Step: 3
Training loss: 0.06621265943645577
Validation loss: 2.417672430317259

Epoch: 6| Step: 4
Training loss: 0.0711174787756147
Validation loss: 2.37256965033328

Epoch: 6| Step: 5
Training loss: 0.05229745105429563
Validation loss: 2.411903209726185

Epoch: 6| Step: 6
Training loss: 0.059581692968698835
Validation loss: 2.4055443141656156

Epoch: 6| Step: 7
Training loss: 0.09371094088695499
Validation loss: 2.389324454571137

Epoch: 6| Step: 8
Training loss: 0.0586074654103578
Validation loss: 2.401470249021537

Epoch: 6| Step: 9
Training loss: 0.058195441174067226
Validation loss: 2.390654636172282

Epoch: 6| Step: 10
Training loss: 0.08529702392924302
Validation loss: 2.391568433057578

Epoch: 6| Step: 11
Training loss: 0.05397243997166498
Validation loss: 2.3755580028545364

Epoch: 6| Step: 12
Training loss: 0.04742223963369488
Validation loss: 2.371485088305304

Epoch: 6| Step: 13
Training loss: 0.06967432097940601
Validation loss: 2.3716991307424142

Testing loss: 2.613341455252346
