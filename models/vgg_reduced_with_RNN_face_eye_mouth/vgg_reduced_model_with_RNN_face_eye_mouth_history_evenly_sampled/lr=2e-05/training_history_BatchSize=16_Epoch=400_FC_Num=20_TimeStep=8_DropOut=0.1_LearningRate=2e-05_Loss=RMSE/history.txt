Epoch: 1| Step: 0
Training loss: 6.506999135565037
Validation loss: 5.835588363296653

Epoch: 6| Step: 1
Training loss: 5.867039583375963
Validation loss: 5.819375380526704

Epoch: 6| Step: 2
Training loss: 5.914686847823179
Validation loss: 5.801919345795754

Epoch: 6| Step: 3
Training loss: 5.292303132155881
Validation loss: 5.7825152883034105

Epoch: 6| Step: 4
Training loss: 5.017434432547386
Validation loss: 5.760146162979805

Epoch: 6| Step: 5
Training loss: 6.3127211730281925
Validation loss: 5.734788856751066

Epoch: 6| Step: 6
Training loss: 4.8330678976551456
Validation loss: 5.705932656093543

Epoch: 6| Step: 7
Training loss: 4.39569732793095
Validation loss: 5.672418441598676

Epoch: 6| Step: 8
Training loss: 5.7931649810830415
Validation loss: 5.634633693521505

Epoch: 6| Step: 9
Training loss: 5.326359162571647
Validation loss: 5.592156439019722

Epoch: 6| Step: 10
Training loss: 5.736324134957754
Validation loss: 5.543614248443598

Epoch: 6| Step: 11
Training loss: 5.69650193340999
Validation loss: 5.4904279522796395

Epoch: 6| Step: 12
Training loss: 6.373625962523707
Validation loss: 5.432365628950467

Epoch: 6| Step: 13
Training loss: 6.610820639219142
Validation loss: 5.37052486601189

Epoch: 2| Step: 0
Training loss: 5.124798282282145
Validation loss: 5.304948498685623

Epoch: 6| Step: 1
Training loss: 4.796775990809437
Validation loss: 5.236999968242586

Epoch: 6| Step: 2
Training loss: 5.307893438791736
Validation loss: 5.164894607247417

Epoch: 6| Step: 3
Training loss: 5.107994336345404
Validation loss: 5.090077418839305

Epoch: 6| Step: 4
Training loss: 5.649280617076701
Validation loss: 5.014936181399714

Epoch: 6| Step: 5
Training loss: 5.862012427252745
Validation loss: 4.939113251105026

Epoch: 6| Step: 6
Training loss: 4.430480993607443
Validation loss: 4.865972329534284

Epoch: 6| Step: 7
Training loss: 4.036262648566479
Validation loss: 4.795969678396545

Epoch: 6| Step: 8
Training loss: 6.2155637006388424
Validation loss: 4.7297473395760905

Epoch: 6| Step: 9
Training loss: 5.01868761149734
Validation loss: 4.671124459930222

Epoch: 6| Step: 10
Training loss: 3.8613133061172396
Validation loss: 4.619993285232989

Epoch: 6| Step: 11
Training loss: 4.247359858239099
Validation loss: 4.572610623652656

Epoch: 6| Step: 12
Training loss: 3.9524973495445557
Validation loss: 4.526592282555437

Epoch: 6| Step: 13
Training loss: 5.070825207008155
Validation loss: 4.488825441297758

Epoch: 3| Step: 0
Training loss: 2.882519053175355
Validation loss: 4.450706466781543

Epoch: 6| Step: 1
Training loss: 5.540912701172228
Validation loss: 4.415803957774024

Epoch: 6| Step: 2
Training loss: 4.968083942803719
Validation loss: 4.3738378396347946

Epoch: 6| Step: 3
Training loss: 3.7223559935968518
Validation loss: 4.33291087485337

Epoch: 6| Step: 4
Training loss: 3.4828099041565865
Validation loss: 4.303171677407411

Epoch: 6| Step: 5
Training loss: 5.093251022519267
Validation loss: 4.27319433629495

Epoch: 6| Step: 6
Training loss: 4.53010618308548
Validation loss: 4.24214177203415

Epoch: 6| Step: 7
Training loss: 4.330005003329375
Validation loss: 4.211354240629017

Epoch: 6| Step: 8
Training loss: 4.979881245985801
Validation loss: 4.18213810336966

Epoch: 6| Step: 9
Training loss: 4.074783534754029
Validation loss: 4.155275891769157

Epoch: 6| Step: 10
Training loss: 4.540620152470206
Validation loss: 4.131404693146305

Epoch: 6| Step: 11
Training loss: 3.654838354708434
Validation loss: 4.110911820867558

Epoch: 6| Step: 12
Training loss: 4.552169182125739
Validation loss: 4.095162945724476

Epoch: 6| Step: 13
Training loss: 3.9514447286303285
Validation loss: 4.081756484890772

Epoch: 4| Step: 0
Training loss: 4.253121968421724
Validation loss: 4.070209664924294

Epoch: 6| Step: 1
Training loss: 3.6678078060570254
Validation loss: 4.059374005558347

Epoch: 6| Step: 2
Training loss: 3.610948492121751
Validation loss: 4.048749650331496

Epoch: 6| Step: 3
Training loss: 4.394220041063842
Validation loss: 4.026854481645962

Epoch: 6| Step: 4
Training loss: 4.282269433045098
Validation loss: 4.008471073934736

Epoch: 6| Step: 5
Training loss: 3.862602089332099
Validation loss: 3.989832499748753

Epoch: 6| Step: 6
Training loss: 3.3228306455250367
Validation loss: 3.971605067995886

Epoch: 6| Step: 7
Training loss: 4.797054921109169
Validation loss: 3.956441694543294

Epoch: 6| Step: 8
Training loss: 4.296446178886267
Validation loss: 3.9439629146197945

Epoch: 6| Step: 9
Training loss: 5.008365880233113
Validation loss: 3.931553311437997

Epoch: 6| Step: 10
Training loss: 3.523334510126943
Validation loss: 3.917549618068854

Epoch: 6| Step: 11
Training loss: 3.807351059282956
Validation loss: 3.9069364499963193

Epoch: 6| Step: 12
Training loss: 4.650853659093219
Validation loss: 3.8930902427552456

Epoch: 6| Step: 13
Training loss: 3.6969889735293977
Validation loss: 3.8774212415617333

Epoch: 5| Step: 0
Training loss: 3.807348554458433
Validation loss: 3.871093878476939

Epoch: 6| Step: 1
Training loss: 3.3157065364436926
Validation loss: 3.8541591459077305

Epoch: 6| Step: 2
Training loss: 4.753388651721675
Validation loss: 3.8489050436523575

Epoch: 6| Step: 3
Training loss: 4.609070021028129
Validation loss: 3.8329419840911734

Epoch: 6| Step: 4
Training loss: 4.547818954380362
Validation loss: 3.815326572839858

Epoch: 6| Step: 5
Training loss: 4.513864985997743
Validation loss: 3.8069355974645305

Epoch: 6| Step: 6
Training loss: 3.3867491618444237
Validation loss: 3.795409489910499

Epoch: 6| Step: 7
Training loss: 2.800003092627861
Validation loss: 3.785329564013061

Epoch: 6| Step: 8
Training loss: 2.731197058123103
Validation loss: 3.7762486219994416

Epoch: 6| Step: 9
Training loss: 4.325485581497998
Validation loss: 3.7611158794261508

Epoch: 6| Step: 10
Training loss: 3.26730537074225
Validation loss: 3.751679775060448

Epoch: 6| Step: 11
Training loss: 4.368180327595193
Validation loss: 3.7492262202612365

Epoch: 6| Step: 12
Training loss: 3.6648890492297395
Validation loss: 3.733837797340543

Epoch: 6| Step: 13
Training loss: 5.156617862410464
Validation loss: 3.7241718864636093

Epoch: 6| Step: 0
Training loss: 3.697631882281582
Validation loss: 3.713287433638027

Epoch: 6| Step: 1
Training loss: 4.210025157717384
Validation loss: 3.706921209843803

Epoch: 6| Step: 2
Training loss: 4.8615866776613235
Validation loss: 3.6968818160549444

Epoch: 6| Step: 3
Training loss: 3.427562428913814
Validation loss: 3.6837370165237027

Epoch: 6| Step: 4
Training loss: 3.4467143625713694
Validation loss: 3.675964841184951

Epoch: 6| Step: 5
Training loss: 3.3662755310926213
Validation loss: 3.671018300756368

Epoch: 6| Step: 6
Training loss: 4.078018128613433
Validation loss: 3.66414743075728

Epoch: 6| Step: 7
Training loss: 3.976678093389917
Validation loss: 3.6534472263973288

Epoch: 6| Step: 8
Training loss: 3.836357886126415
Validation loss: 3.645718395103136

Epoch: 6| Step: 9
Training loss: 3.901462764786701
Validation loss: 3.64036139485797

Epoch: 6| Step: 10
Training loss: 4.1131574389307834
Validation loss: 3.629585768624123

Epoch: 6| Step: 11
Training loss: 3.343202635269605
Validation loss: 3.6219440318609513

Epoch: 6| Step: 12
Training loss: 3.730459035491278
Validation loss: 3.609684346031185

Epoch: 6| Step: 13
Training loss: 3.5492197764330315
Validation loss: 3.6078517785641027

Epoch: 7| Step: 0
Training loss: 3.563364024540114
Validation loss: 3.6025142624403426

Epoch: 6| Step: 1
Training loss: 3.7121577455118304
Validation loss: 3.59227201468557

Epoch: 6| Step: 2
Training loss: 3.6947268774035784
Validation loss: 3.5812608564047954

Epoch: 6| Step: 3
Training loss: 3.996385133025811
Validation loss: 3.568547738405835

Epoch: 6| Step: 4
Training loss: 4.353911445596779
Validation loss: 3.5580525063927753

Epoch: 6| Step: 5
Training loss: 3.4557693505939304
Validation loss: 3.5679392889059383

Epoch: 6| Step: 6
Training loss: 3.058631477756618
Validation loss: 3.5538181183410678

Epoch: 6| Step: 7
Training loss: 3.3712798914788213
Validation loss: 3.5393637961935314

Epoch: 6| Step: 8
Training loss: 3.6860493538295422
Validation loss: 3.53486533750651

Epoch: 6| Step: 9
Training loss: 4.087201887452935
Validation loss: 3.529115367640109

Epoch: 6| Step: 10
Training loss: 4.2320135647532915
Validation loss: 3.5210965276561508

Epoch: 6| Step: 11
Training loss: 3.545203802494393
Validation loss: 3.5149348806012575

Epoch: 6| Step: 12
Training loss: 3.599978812473255
Validation loss: 3.5066350270740476

Epoch: 6| Step: 13
Training loss: 4.233490911439543
Validation loss: 3.4972922696061084

Epoch: 8| Step: 0
Training loss: 3.080976530555846
Validation loss: 3.487855999776426

Epoch: 6| Step: 1
Training loss: 3.92905076558169
Validation loss: 3.4825557574673103

Epoch: 6| Step: 2
Training loss: 2.8865715681038715
Validation loss: 3.4778138634594895

Epoch: 6| Step: 3
Training loss: 3.1205010645112305
Validation loss: 3.4850800688042844

Epoch: 6| Step: 4
Training loss: 3.484757338275513
Validation loss: 3.466373675044101

Epoch: 6| Step: 5
Training loss: 3.8821630414462365
Validation loss: 3.456926435982733

Epoch: 6| Step: 6
Training loss: 3.76672575125026
Validation loss: 3.4600911131539505

Epoch: 6| Step: 7
Training loss: 3.7651564437157585
Validation loss: 3.454943575470674

Epoch: 6| Step: 8
Training loss: 3.3093245058467082
Validation loss: 3.449624259619973

Epoch: 6| Step: 9
Training loss: 4.75766016022533
Validation loss: 3.440719707533779

Epoch: 6| Step: 10
Training loss: 4.009075359942641
Validation loss: 3.430343844312623

Epoch: 6| Step: 11
Training loss: 3.627308603675572
Validation loss: 3.42264945529624

Epoch: 6| Step: 12
Training loss: 3.5445024394595865
Validation loss: 3.416060102471259

Epoch: 6| Step: 13
Training loss: 3.964321158409
Validation loss: 3.4088494974141024

Epoch: 9| Step: 0
Training loss: 2.4868888372557363
Validation loss: 3.4072644891573347

Epoch: 6| Step: 1
Training loss: 2.750104382007795
Validation loss: 3.401817010405295

Epoch: 6| Step: 2
Training loss: 4.397651669921225
Validation loss: 3.3891127882966203

Epoch: 6| Step: 3
Training loss: 3.02115278637648
Validation loss: 3.376364658031908

Epoch: 6| Step: 4
Training loss: 4.099844320179369
Validation loss: 3.376844727658982

Epoch: 6| Step: 5
Training loss: 3.6024481290620978
Validation loss: 3.36817518424301

Epoch: 6| Step: 6
Training loss: 3.7747215471454165
Validation loss: 3.3629818981605406

Epoch: 6| Step: 7
Training loss: 4.007313479760879
Validation loss: 3.3563012283939626

Epoch: 6| Step: 8
Training loss: 3.0392506205332297
Validation loss: 3.3461805772707827

Epoch: 6| Step: 9
Training loss: 4.572538854101256
Validation loss: 3.338168982584128

Epoch: 6| Step: 10
Training loss: 3.0673324449661297
Validation loss: 3.3296532040544196

Epoch: 6| Step: 11
Training loss: 3.4027706189415468
Validation loss: 3.327745875798348

Epoch: 6| Step: 12
Training loss: 3.8133096304292438
Validation loss: 3.322038069464828

Epoch: 6| Step: 13
Training loss: 3.572262421403703
Validation loss: 3.314634123613286

Epoch: 10| Step: 0
Training loss: 3.538183646309876
Validation loss: 3.3039690055692468

Epoch: 6| Step: 1
Training loss: 3.1117918503488404
Validation loss: 3.296539868917282

Epoch: 6| Step: 2
Training loss: 3.3816058184954274
Validation loss: 3.294311003865864

Epoch: 6| Step: 3
Training loss: 4.5002547297965965
Validation loss: 3.289166135604264

Epoch: 6| Step: 4
Training loss: 3.6715285117439613
Validation loss: 3.2783561684861113

Epoch: 6| Step: 5
Training loss: 3.442964406764903
Validation loss: 3.2714111029975643

Epoch: 6| Step: 6
Training loss: 3.2872136734697346
Validation loss: 3.26385516188025

Epoch: 6| Step: 7
Training loss: 3.155654095587172
Validation loss: 3.259784647581957

Epoch: 6| Step: 8
Training loss: 2.6332828090343727
Validation loss: 3.2773793460210827

Epoch: 6| Step: 9
Training loss: 3.8908054049539347
Validation loss: 3.2535208206789576

Epoch: 6| Step: 10
Training loss: 4.116067636332673
Validation loss: 3.2471131754866582

Epoch: 6| Step: 11
Training loss: 2.2334704935837473
Validation loss: 3.2505774690941407

Epoch: 6| Step: 12
Training loss: 4.125426299290645
Validation loss: 3.2583454379118706

Epoch: 6| Step: 13
Training loss: 3.5270814850936225
Validation loss: 3.244487661235503

Epoch: 11| Step: 0
Training loss: 4.175164572390287
Validation loss: 3.235075493663749

Epoch: 6| Step: 1
Training loss: 3.1154991683113997
Validation loss: 3.233573785405625

Epoch: 6| Step: 2
Training loss: 3.517716391820303
Validation loss: 3.232352852171938

Epoch: 6| Step: 3
Training loss: 3.5304726614342683
Validation loss: 3.2229166481912195

Epoch: 6| Step: 4
Training loss: 3.4450698732506995
Validation loss: 3.2177492229228957

Epoch: 6| Step: 5
Training loss: 3.368814805350544
Validation loss: 3.2174912072126167

Epoch: 6| Step: 6
Training loss: 2.9511280877066772
Validation loss: 3.2141314914059493

Epoch: 6| Step: 7
Training loss: 3.4360906312689057
Validation loss: 3.2107051706131498

Epoch: 6| Step: 8
Training loss: 3.4830964483969504
Validation loss: 3.2060040852480727

Epoch: 6| Step: 9
Training loss: 4.021639939013967
Validation loss: 3.20065028978625

Epoch: 6| Step: 10
Training loss: 3.4096662556047
Validation loss: 3.1946351123873518

Epoch: 6| Step: 11
Training loss: 3.183956195817519
Validation loss: 3.1916056537175415

Epoch: 6| Step: 12
Training loss: 3.2221460296859754
Validation loss: 3.1866092760392366

Epoch: 6| Step: 13
Training loss: 3.605546911183872
Validation loss: 3.1836833458845115

Epoch: 12| Step: 0
Training loss: 2.7148950366108915
Validation loss: 3.1781062001469977

Epoch: 6| Step: 1
Training loss: 2.873771404968164
Validation loss: 3.175040758120179

Epoch: 6| Step: 2
Training loss: 3.6892814858831358
Validation loss: 3.1730436003734934

Epoch: 6| Step: 3
Training loss: 3.8579805766279684
Validation loss: 3.1695140613471593

Epoch: 6| Step: 4
Training loss: 2.9249564664812615
Validation loss: 3.165898904089108

Epoch: 6| Step: 5
Training loss: 3.338453572381058
Validation loss: 3.1632427790926543

Epoch: 6| Step: 6
Training loss: 3.657356942352219
Validation loss: 3.1596725282063414

Epoch: 6| Step: 7
Training loss: 4.336495248474171
Validation loss: 3.1553049556085906

Epoch: 6| Step: 8
Training loss: 3.9505090313079037
Validation loss: 3.1541113213669485

Epoch: 6| Step: 9
Training loss: 3.48233574692813
Validation loss: 3.150609373811404

Epoch: 6| Step: 10
Training loss: 3.825294039525663
Validation loss: 3.1473312288841893

Epoch: 6| Step: 11
Training loss: 2.8560873840918886
Validation loss: 3.144564450862638

Epoch: 6| Step: 12
Training loss: 3.048825622596667
Validation loss: 3.1408834133239427

Epoch: 6| Step: 13
Training loss: 2.5368835489674586
Validation loss: 3.140166409419036

Epoch: 13| Step: 0
Training loss: 2.8585173774686132
Validation loss: 3.1387778894843557

Epoch: 6| Step: 1
Training loss: 3.521779281276763
Validation loss: 3.136859809561118

Epoch: 6| Step: 2
Training loss: 2.9854021950952423
Validation loss: 3.1348944731217947

Epoch: 6| Step: 3
Training loss: 3.472359918195298
Validation loss: 3.133291009980605

Epoch: 6| Step: 4
Training loss: 3.1992713635115817
Validation loss: 3.1315138970589955

Epoch: 6| Step: 5
Training loss: 4.005920082350215
Validation loss: 3.128698240307288

Epoch: 6| Step: 6
Training loss: 4.078040578852613
Validation loss: 3.1281789332971326

Epoch: 6| Step: 7
Training loss: 2.464943184033396
Validation loss: 3.125146731961848

Epoch: 6| Step: 8
Training loss: 2.898875242014083
Validation loss: 3.1234516565705395

Epoch: 6| Step: 9
Training loss: 4.040113537392177
Validation loss: 3.12242282548316

Epoch: 6| Step: 10
Training loss: 3.0854684980333142
Validation loss: 3.1215963651353995

Epoch: 6| Step: 11
Training loss: 4.309076249332169
Validation loss: 3.1174991869319943

Epoch: 6| Step: 12
Training loss: 2.9397997680261194
Validation loss: 3.115322664979447

Epoch: 6| Step: 13
Training loss: 2.943622458381889
Validation loss: 3.113518719833949

Epoch: 14| Step: 0
Training loss: 2.7235070189610897
Validation loss: 3.1117680674403947

Epoch: 6| Step: 1
Training loss: 3.196703917996012
Validation loss: 3.1105338402536247

Epoch: 6| Step: 2
Training loss: 3.789297572443908
Validation loss: 3.1079868007247713

Epoch: 6| Step: 3
Training loss: 3.098185432711197
Validation loss: 3.104358879944057

Epoch: 6| Step: 4
Training loss: 3.227876335677644
Validation loss: 3.102600448021627

Epoch: 6| Step: 5
Training loss: 3.1718739476695452
Validation loss: 3.103000342199472

Epoch: 6| Step: 6
Training loss: 3.7729537369444444
Validation loss: 3.1107150870508082

Epoch: 6| Step: 7
Training loss: 3.4874131167947944
Validation loss: 3.1041219729696503

Epoch: 6| Step: 8
Training loss: 2.6332569143417643
Validation loss: 3.11959804794387

Epoch: 6| Step: 9
Training loss: 4.169981566097946
Validation loss: 3.147887425507999

Epoch: 6| Step: 10
Training loss: 3.9004228998414288
Validation loss: 3.130381432660879

Epoch: 6| Step: 11
Training loss: 3.3406357567866456
Validation loss: 3.112343423107984

Epoch: 6| Step: 12
Training loss: 3.4673509955484123
Validation loss: 3.1160556694642594

Epoch: 6| Step: 13
Training loss: 2.984977461635543
Validation loss: 3.113330977926619

Epoch: 15| Step: 0
Training loss: 3.856880895609809
Validation loss: 3.1042855124315034

Epoch: 6| Step: 1
Training loss: 3.180158950383932
Validation loss: 3.097108609088944

Epoch: 6| Step: 2
Training loss: 3.6201505121797024
Validation loss: 3.0936837121402707

Epoch: 6| Step: 3
Training loss: 3.912078415457252
Validation loss: 3.0930521544549605

Epoch: 6| Step: 4
Training loss: 3.2093846633899368
Validation loss: 3.094729006249629

Epoch: 6| Step: 5
Training loss: 2.8338965435864054
Validation loss: 3.094845179052229

Epoch: 6| Step: 6
Training loss: 3.235628778824968
Validation loss: 3.092763232733123

Epoch: 6| Step: 7
Training loss: 3.177906634275443
Validation loss: 3.088905787105122

Epoch: 6| Step: 8
Training loss: 3.5808401675503463
Validation loss: 3.085249411611429

Epoch: 6| Step: 9
Training loss: 3.3025837868999823
Validation loss: 3.0788668720281893

Epoch: 6| Step: 10
Training loss: 3.6117759744614926
Validation loss: 3.0753566114639614

Epoch: 6| Step: 11
Training loss: 2.8281142092335574
Validation loss: 3.0724132341672727

Epoch: 6| Step: 12
Training loss: 3.585516478977681
Validation loss: 3.0709961515676407

Epoch: 6| Step: 13
Training loss: 2.7366895198758376
Validation loss: 3.069306374775203

Epoch: 16| Step: 0
Training loss: 2.927138539582168
Validation loss: 3.067481738200789

Epoch: 6| Step: 1
Training loss: 3.4774355360099047
Validation loss: 3.064836788779944

Epoch: 6| Step: 2
Training loss: 3.7645935925398626
Validation loss: 3.062981770843154

Epoch: 6| Step: 3
Training loss: 4.274289006231219
Validation loss: 3.061228037836925

Epoch: 6| Step: 4
Training loss: 2.56828102601504
Validation loss: 3.0579129611283506

Epoch: 6| Step: 5
Training loss: 3.4420768093159206
Validation loss: 3.0544221904092677

Epoch: 6| Step: 6
Training loss: 3.592865942977013
Validation loss: 3.058786881502733

Epoch: 6| Step: 7
Training loss: 3.78585157119777
Validation loss: 3.1150930422943586

Epoch: 6| Step: 8
Training loss: 3.6786325161288813
Validation loss: 3.12894275961426

Epoch: 6| Step: 9
Training loss: 3.3285464884035894
Validation loss: 3.115388953236842

Epoch: 6| Step: 10
Training loss: 2.822276860515049
Validation loss: 3.0661412035894204

Epoch: 6| Step: 11
Training loss: 2.4633362720077945
Validation loss: 3.0477761466554947

Epoch: 6| Step: 12
Training loss: 3.120256256681627
Validation loss: 3.054273845216357

Epoch: 6| Step: 13
Training loss: 3.3458616059954736
Validation loss: 3.062362490344554

Epoch: 17| Step: 0
Training loss: 3.6649488991457453
Validation loss: 3.065677823156888

Epoch: 6| Step: 1
Training loss: 3.422327577805007
Validation loss: 3.055919017845902

Epoch: 6| Step: 2
Training loss: 3.1647778114563163
Validation loss: 3.049258151344767

Epoch: 6| Step: 3
Training loss: 2.959910514097486
Validation loss: 3.0460275267070656

Epoch: 6| Step: 4
Training loss: 3.305176899341017
Validation loss: 3.0465010622576996

Epoch: 6| Step: 5
Training loss: 3.4739170939425046
Validation loss: 3.054344030160655

Epoch: 6| Step: 6
Training loss: 3.4731175874662217
Validation loss: 3.0410939659508474

Epoch: 6| Step: 7
Training loss: 3.2783635113608236
Validation loss: 3.03649886838109

Epoch: 6| Step: 8
Training loss: 3.3012752727565253
Validation loss: 3.036790716065007

Epoch: 6| Step: 9
Training loss: 3.016385471733829
Validation loss: 3.035358257895705

Epoch: 6| Step: 10
Training loss: 2.920418605846433
Validation loss: 3.0346410069086995

Epoch: 6| Step: 11
Training loss: 4.075699007894732
Validation loss: 3.0337205821078226

Epoch: 6| Step: 12
Training loss: 2.953267089008957
Validation loss: 3.0309970497720045

Epoch: 6| Step: 13
Training loss: 3.608447595656357
Validation loss: 3.028629118438439

Epoch: 18| Step: 0
Training loss: 3.258481037145006
Validation loss: 3.02627317978151

Epoch: 6| Step: 1
Training loss: 3.2002470159559193
Validation loss: 3.0251179307977414

Epoch: 6| Step: 2
Training loss: 3.071629676064861
Validation loss: 3.021778883455653

Epoch: 6| Step: 3
Training loss: 3.592881072771011
Validation loss: 3.0204384454793676

Epoch: 6| Step: 4
Training loss: 3.11721931766343
Validation loss: 3.0184408120013564

Epoch: 6| Step: 5
Training loss: 3.1961274914765934
Validation loss: 3.0180957569381706

Epoch: 6| Step: 6
Training loss: 3.689336545686618
Validation loss: 3.0156714144494976

Epoch: 6| Step: 7
Training loss: 3.579177368527016
Validation loss: 3.0129302597049556

Epoch: 6| Step: 8
Training loss: 3.2447335047685772
Validation loss: 3.0122531302773385

Epoch: 6| Step: 9
Training loss: 3.3727830740610716
Validation loss: 3.0117633545428903

Epoch: 6| Step: 10
Training loss: 3.299150739109269
Validation loss: 3.0086388115474123

Epoch: 6| Step: 11
Training loss: 3.0779005249586167
Validation loss: 3.006757865234592

Epoch: 6| Step: 12
Training loss: 3.0742198357586235
Validation loss: 3.006174687366233

Epoch: 6| Step: 13
Training loss: 3.6418544019643924
Validation loss: 3.005618697671376

Epoch: 19| Step: 0
Training loss: 3.864159710776166
Validation loss: 3.0027476839951723

Epoch: 6| Step: 1
Training loss: 3.2265852587915567
Validation loss: 3.0002922724134877

Epoch: 6| Step: 2
Training loss: 3.1302999185798845
Validation loss: 3.0043444418759075

Epoch: 6| Step: 3
Training loss: 2.944882632185227
Validation loss: 2.997667805848264

Epoch: 6| Step: 4
Training loss: 2.826454385742646
Validation loss: 2.9984126488993095

Epoch: 6| Step: 5
Training loss: 3.2019952037615718
Validation loss: 2.997813821140892

Epoch: 6| Step: 6
Training loss: 3.455355791026175
Validation loss: 2.9993463952747796

Epoch: 6| Step: 7
Training loss: 3.0820686908570245
Validation loss: 3.0019854774167274

Epoch: 6| Step: 8
Training loss: 2.740942169592562
Validation loss: 3.010704516997451

Epoch: 6| Step: 9
Training loss: 3.387730219714218
Validation loss: 3.0195201074487255

Epoch: 6| Step: 10
Training loss: 3.76803486430081
Validation loss: 3.026045597073793

Epoch: 6| Step: 11
Training loss: 3.3935964194826105
Validation loss: 2.993856300496106

Epoch: 6| Step: 12
Training loss: 3.333331839243236
Validation loss: 2.9959946696608344

Epoch: 6| Step: 13
Training loss: 3.945408704736698
Validation loss: 2.9944926028668277

Epoch: 20| Step: 0
Training loss: 3.303042171309537
Validation loss: 2.9911856147633493

Epoch: 6| Step: 1
Training loss: 3.6347225951241255
Validation loss: 2.9932168274836832

Epoch: 6| Step: 2
Training loss: 3.364135208442668
Validation loss: 3.00084075289935

Epoch: 6| Step: 3
Training loss: 2.9853849449699648
Validation loss: 3.0051168997746656

Epoch: 6| Step: 4
Training loss: 3.575210917193137
Validation loss: 2.993125480418315

Epoch: 6| Step: 5
Training loss: 3.9141187835118685
Validation loss: 2.984675544269391

Epoch: 6| Step: 6
Training loss: 3.0265564122333264
Validation loss: 2.9808376252093147

Epoch: 6| Step: 7
Training loss: 3.143436975991994
Validation loss: 2.979261908947454

Epoch: 6| Step: 8
Training loss: 3.5110356872709283
Validation loss: 2.979547911784231

Epoch: 6| Step: 9
Training loss: 2.803972158350922
Validation loss: 2.9832611402020524

Epoch: 6| Step: 10
Training loss: 3.0413591586528197
Validation loss: 3.00427623935413

Epoch: 6| Step: 11
Training loss: 2.8833930198651094
Validation loss: 3.031151265349498

Epoch: 6| Step: 12
Training loss: 3.6190979363712823
Validation loss: 3.033188968837213

Epoch: 6| Step: 13
Training loss: 3.1083421381466874
Validation loss: 3.01096567526377

Epoch: 21| Step: 0
Training loss: 4.286651545172124
Validation loss: 2.978855119061257

Epoch: 6| Step: 1
Training loss: 2.355414293459953
Validation loss: 2.9716260285123908

Epoch: 6| Step: 2
Training loss: 3.0949247037390046
Validation loss: 2.9698163002810984

Epoch: 6| Step: 3
Training loss: 3.9234359492059983
Validation loss: 2.9714084244367593

Epoch: 6| Step: 4
Training loss: 2.8939088056915647
Validation loss: 2.9679281240204336

Epoch: 6| Step: 5
Training loss: 2.837179621284168
Validation loss: 2.9681269338897214

Epoch: 6| Step: 6
Training loss: 3.139082952331176
Validation loss: 2.966323095445132

Epoch: 6| Step: 7
Training loss: 3.5098756699672324
Validation loss: 2.9656285073911293

Epoch: 6| Step: 8
Training loss: 3.2186411126246184
Validation loss: 2.9646049071595018

Epoch: 6| Step: 9
Training loss: 2.818673373447452
Validation loss: 2.9725461823602624

Epoch: 6| Step: 10
Training loss: 2.6416521952460346
Validation loss: 2.9805848056268918

Epoch: 6| Step: 11
Training loss: 3.709197140216167
Validation loss: 2.973093467866181

Epoch: 6| Step: 12
Training loss: 3.2104928481469837
Validation loss: 2.9657896626190956

Epoch: 6| Step: 13
Training loss: 3.9500433327917577
Validation loss: 2.9612137072606384

Epoch: 22| Step: 0
Training loss: 3.3070328418449395
Validation loss: 2.957756487703435

Epoch: 6| Step: 1
Training loss: 3.421222781378643
Validation loss: 2.959569041788823

Epoch: 6| Step: 2
Training loss: 3.026107673559806
Validation loss: 2.9594462688842644

Epoch: 6| Step: 3
Training loss: 3.4956613624900874
Validation loss: 2.9591856639572454

Epoch: 6| Step: 4
Training loss: 2.6537039728256477
Validation loss: 2.9576856316320055

Epoch: 6| Step: 5
Training loss: 3.7757248037402174
Validation loss: 2.9557742885658036

Epoch: 6| Step: 6
Training loss: 2.97441748678311
Validation loss: 2.95511282802517

Epoch: 6| Step: 7
Training loss: 3.411477932861558
Validation loss: 2.952098590149295

Epoch: 6| Step: 8
Training loss: 3.11425689381454
Validation loss: 2.952683123558845

Epoch: 6| Step: 9
Training loss: 2.630528758457559
Validation loss: 2.9512760598421717

Epoch: 6| Step: 10
Training loss: 2.9740968439256212
Validation loss: 2.948239269292579

Epoch: 6| Step: 11
Training loss: 3.6595660439129585
Validation loss: 2.9617077515573995

Epoch: 6| Step: 12
Training loss: 3.786443501285571
Validation loss: 2.981851178154475

Epoch: 6| Step: 13
Training loss: 3.171283835958694
Validation loss: 2.9478147558597474

Epoch: 23| Step: 0
Training loss: 3.2483269713489387
Validation loss: 2.9443013059754484

Epoch: 6| Step: 1
Training loss: 2.5995308672874935
Validation loss: 2.948487942199665

Epoch: 6| Step: 2
Training loss: 3.1108785856484333
Validation loss: 2.956302130666461

Epoch: 6| Step: 3
Training loss: 2.5873742851640773
Validation loss: 2.9685715514319138

Epoch: 6| Step: 4
Training loss: 3.075251598454804
Validation loss: 2.987642934850733

Epoch: 6| Step: 5
Training loss: 3.866643817329858
Validation loss: 2.9959527696846986

Epoch: 6| Step: 6
Training loss: 3.081803500773989
Validation loss: 2.996414273741292

Epoch: 6| Step: 7
Training loss: 2.5478571770731544
Validation loss: 2.9808621052973256

Epoch: 6| Step: 8
Training loss: 3.8872435555708558
Validation loss: 2.983810107622908

Epoch: 6| Step: 9
Training loss: 3.342157572950689
Validation loss: 2.9556193094390864

Epoch: 6| Step: 10
Training loss: 3.6592470584854175
Validation loss: 2.959735904151635

Epoch: 6| Step: 11
Training loss: 3.4557221601118604
Validation loss: 2.964338266952662

Epoch: 6| Step: 12
Training loss: 3.6787266215736136
Validation loss: 2.959154238421725

Epoch: 6| Step: 13
Training loss: 3.373862039374162
Validation loss: 2.9527815978143344

Epoch: 24| Step: 0
Training loss: 3.545881359045556
Validation loss: 2.95005447986729

Epoch: 6| Step: 1
Training loss: 2.539770784623631
Validation loss: 2.942986823184415

Epoch: 6| Step: 2
Training loss: 3.132354170075528
Validation loss: 2.9428850541051257

Epoch: 6| Step: 3
Training loss: 2.8474434143820857
Validation loss: 2.943257193743925

Epoch: 6| Step: 4
Training loss: 3.4198100509095175
Validation loss: 2.940295133880597

Epoch: 6| Step: 5
Training loss: 3.186684448027647
Validation loss: 2.934622592626522

Epoch: 6| Step: 6
Training loss: 3.05448877805296
Validation loss: 2.943094987629023

Epoch: 6| Step: 7
Training loss: 3.6468223901400862
Validation loss: 2.9670310120828205

Epoch: 6| Step: 8
Training loss: 3.3164534099267615
Validation loss: 2.9298458169799257

Epoch: 6| Step: 9
Training loss: 3.7133136409965606
Validation loss: 2.9293584272092184

Epoch: 6| Step: 10
Training loss: 3.5677224411882715
Validation loss: 2.932532492045357

Epoch: 6| Step: 11
Training loss: 2.857407857322076
Validation loss: 2.931654663756275

Epoch: 6| Step: 12
Training loss: 2.929722818797524
Validation loss: 2.936149216776851

Epoch: 6| Step: 13
Training loss: 3.7125158547213797
Validation loss: 2.9381801103287652

Epoch: 25| Step: 0
Training loss: 2.9154923027563697
Validation loss: 2.940845853981905

Epoch: 6| Step: 1
Training loss: 3.275301527746148
Validation loss: 2.9365601616859074

Epoch: 6| Step: 2
Training loss: 2.9614492492500677
Validation loss: 2.9281567216355833

Epoch: 6| Step: 3
Training loss: 3.1927061760269186
Validation loss: 2.923536430960525

Epoch: 6| Step: 4
Training loss: 3.338983578925184
Validation loss: 2.9206144614397855

Epoch: 6| Step: 5
Training loss: 4.004885550969863
Validation loss: 2.919529796076643

Epoch: 6| Step: 6
Training loss: 3.0254030763038644
Validation loss: 2.9195218791116098

Epoch: 6| Step: 7
Training loss: 2.989014220259103
Validation loss: 2.9218651849962316

Epoch: 6| Step: 8
Training loss: 3.2394890643731706
Validation loss: 2.9184400754351336

Epoch: 6| Step: 9
Training loss: 3.2739781773049055
Validation loss: 2.9229309216637485

Epoch: 6| Step: 10
Training loss: 3.5152502241645287
Validation loss: 2.9271493883196893

Epoch: 6| Step: 11
Training loss: 3.1559792581899204
Validation loss: 2.9256344077702

Epoch: 6| Step: 12
Training loss: 2.947148810537092
Validation loss: 2.922399298684054

Epoch: 6| Step: 13
Training loss: 3.4242748745899543
Validation loss: 2.923469337039265

Epoch: 26| Step: 0
Training loss: 2.5935411484062794
Validation loss: 2.9231245040778244

Epoch: 6| Step: 1
Training loss: 3.196115854467072
Validation loss: 2.925528378263041

Epoch: 6| Step: 2
Training loss: 3.0283910108947563
Validation loss: 2.9279901933638066

Epoch: 6| Step: 3
Training loss: 3.699613040587549
Validation loss: 2.9201802591184776

Epoch: 6| Step: 4
Training loss: 3.0968276619781676
Validation loss: 2.918007459549986

Epoch: 6| Step: 5
Training loss: 3.3550738101122706
Validation loss: 2.917764431327003

Epoch: 6| Step: 6
Training loss: 3.7918220460236447
Validation loss: 2.914198981787262

Epoch: 6| Step: 7
Training loss: 3.3777866868130273
Validation loss: 2.9095954486262414

Epoch: 6| Step: 8
Training loss: 2.9156174180237864
Validation loss: 2.9066412242621857

Epoch: 6| Step: 9
Training loss: 3.2048534660941588
Validation loss: 2.9085484366241103

Epoch: 6| Step: 10
Training loss: 3.115849640456611
Validation loss: 2.9142426703381576

Epoch: 6| Step: 11
Training loss: 2.8054471913005723
Validation loss: 2.92345194070348

Epoch: 6| Step: 12
Training loss: 3.1334345097811447
Validation loss: 2.9285999911940856

Epoch: 6| Step: 13
Training loss: 3.7449281090226614
Validation loss: 2.919857066872243

Epoch: 27| Step: 0
Training loss: 3.4057664440491413
Validation loss: 2.9044197856960396

Epoch: 6| Step: 1
Training loss: 3.303740958794279
Validation loss: 2.9059336359217616

Epoch: 6| Step: 2
Training loss: 3.078533939364696
Validation loss: 2.902047453043533

Epoch: 6| Step: 3
Training loss: 2.9440023002304545
Validation loss: 2.9050113465521017

Epoch: 6| Step: 4
Training loss: 3.041701712907223
Validation loss: 2.9035108194516863

Epoch: 6| Step: 5
Training loss: 2.3459748961137246
Validation loss: 2.9040856657568104

Epoch: 6| Step: 6
Training loss: 3.546834130408809
Validation loss: 2.9040129704765567

Epoch: 6| Step: 7
Training loss: 3.4500264208238063
Validation loss: 2.905407906523715

Epoch: 6| Step: 8
Training loss: 3.4042676004102024
Validation loss: 2.8974189769778524

Epoch: 6| Step: 9
Training loss: 2.9895677377823473
Validation loss: 2.8983526106589492

Epoch: 6| Step: 10
Training loss: 3.8956908065645512
Validation loss: 2.9000241496063976

Epoch: 6| Step: 11
Training loss: 3.346479781152006
Validation loss: 2.902650809516846

Epoch: 6| Step: 12
Training loss: 2.9380737718288312
Validation loss: 2.90416071968519

Epoch: 6| Step: 13
Training loss: 2.967614689629696
Validation loss: 2.9024351065288885

Epoch: 28| Step: 0
Training loss: 2.5534273825307165
Validation loss: 2.896926066112055

Epoch: 6| Step: 1
Training loss: 3.446551526161382
Validation loss: 2.8968452024906903

Epoch: 6| Step: 2
Training loss: 3.3995571352935796
Validation loss: 2.8932918841097646

Epoch: 6| Step: 3
Training loss: 3.032712131511929
Validation loss: 2.8923620218178874

Epoch: 6| Step: 4
Training loss: 3.1415388760939704
Validation loss: 2.89254625500117

Epoch: 6| Step: 5
Training loss: 2.7509800291733573
Validation loss: 2.8924191207086873

Epoch: 6| Step: 6
Training loss: 3.7318551088849814
Validation loss: 2.892251162318261

Epoch: 6| Step: 7
Training loss: 3.672809887634143
Validation loss: 2.891935108937142

Epoch: 6| Step: 8
Training loss: 3.102498026316197
Validation loss: 2.8915979213072247

Epoch: 6| Step: 9
Training loss: 3.3455721444826128
Validation loss: 2.892298393707181

Epoch: 6| Step: 10
Training loss: 2.764271291693051
Validation loss: 2.8968507512895614

Epoch: 6| Step: 11
Training loss: 2.6011282526916437
Validation loss: 2.8972751754707766

Epoch: 6| Step: 12
Training loss: 3.6404175269476733
Validation loss: 2.905795207866356

Epoch: 6| Step: 13
Training loss: 3.509551638797084
Validation loss: 2.9080092060655818

Epoch: 29| Step: 0
Training loss: 3.292809461042123
Validation loss: 2.9089864197185684

Epoch: 6| Step: 1
Training loss: 1.9750052488233136
Validation loss: 2.8903704592428823

Epoch: 6| Step: 2
Training loss: 3.3289759448011114
Validation loss: 2.8835204596551174

Epoch: 6| Step: 3
Training loss: 3.465070818112688
Validation loss: 2.8801453725239576

Epoch: 6| Step: 4
Training loss: 2.5226519516394066
Validation loss: 2.8801137948770004

Epoch: 6| Step: 5
Training loss: 3.423739130198566
Validation loss: 2.880216234935793

Epoch: 6| Step: 6
Training loss: 3.8060876670759667
Validation loss: 2.8808012380655414

Epoch: 6| Step: 7
Training loss: 3.396353808498885
Validation loss: 2.8789443244797854

Epoch: 6| Step: 8
Training loss: 3.6422139249061516
Validation loss: 2.8788689159150294

Epoch: 6| Step: 9
Training loss: 2.8454916514808932
Validation loss: 2.875063597201775

Epoch: 6| Step: 10
Training loss: 2.7992076842685267
Validation loss: 2.8768145847938524

Epoch: 6| Step: 11
Training loss: 2.9065635265926413
Validation loss: 2.87611446029474

Epoch: 6| Step: 12
Training loss: 3.146099727711139
Validation loss: 2.8755818099762034

Epoch: 6| Step: 13
Training loss: 3.8342976532015833
Validation loss: 2.8744382875774654

Epoch: 30| Step: 0
Training loss: 3.1016913322384934
Validation loss: 2.8878104447293538

Epoch: 6| Step: 1
Training loss: 3.271794382466621
Validation loss: 2.9089373036329365

Epoch: 6| Step: 2
Training loss: 2.919042509725404
Validation loss: 2.9110658060986547

Epoch: 6| Step: 3
Training loss: 2.986500088298138
Validation loss: 2.8728994745488805

Epoch: 6| Step: 4
Training loss: 2.864026398126854
Validation loss: 2.869890120689163

Epoch: 6| Step: 5
Training loss: 2.2231086578926735
Validation loss: 2.8719004686586636

Epoch: 6| Step: 6
Training loss: 3.661628614276265
Validation loss: 2.873709458104844

Epoch: 6| Step: 7
Training loss: 3.6174637954682334
Validation loss: 2.8773460687074004

Epoch: 6| Step: 8
Training loss: 3.668428012423908
Validation loss: 2.8797309297512745

Epoch: 6| Step: 9
Training loss: 3.3821963130071615
Validation loss: 2.8737861349935283

Epoch: 6| Step: 10
Training loss: 2.8455826439942435
Validation loss: 2.87349239446527

Epoch: 6| Step: 11
Training loss: 3.4376079195594955
Validation loss: 2.867305002472936

Epoch: 6| Step: 12
Training loss: 2.7817807494810936
Validation loss: 2.8683017102436765

Epoch: 6| Step: 13
Training loss: 4.033695159529863
Validation loss: 2.8695300044564975

Epoch: 31| Step: 0
Training loss: 2.1845624545846607
Validation loss: 2.867124101849275

Epoch: 6| Step: 1
Training loss: 2.839491285780593
Validation loss: 2.8667666786482955

Epoch: 6| Step: 2
Training loss: 2.7500338118815373
Validation loss: 2.8655822566427096

Epoch: 6| Step: 3
Training loss: 3.107606471133556
Validation loss: 2.8661765730844633

Epoch: 6| Step: 4
Training loss: 2.8616370753641407
Validation loss: 2.8644245510152553

Epoch: 6| Step: 5
Training loss: 3.466162876667144
Validation loss: 2.8690383059567277

Epoch: 6| Step: 6
Training loss: 3.488618328216175
Validation loss: 2.871445070634125

Epoch: 6| Step: 7
Training loss: 3.5015922739175087
Validation loss: 2.8729247226753984

Epoch: 6| Step: 8
Training loss: 2.9386234164346687
Validation loss: 2.874806575501522

Epoch: 6| Step: 9
Training loss: 3.3573664848724984
Validation loss: 2.9016803334404644

Epoch: 6| Step: 10
Training loss: 3.1260784577074636
Validation loss: 2.8964005843729175

Epoch: 6| Step: 11
Training loss: 3.2237495186292473
Validation loss: 2.868921153274996

Epoch: 6| Step: 12
Training loss: 3.924953999826856
Validation loss: 2.860568309454143

Epoch: 6| Step: 13
Training loss: 3.5001722020974824
Validation loss: 2.8531157269311596

Epoch: 32| Step: 0
Training loss: 3.135377818191163
Validation loss: 2.8551103696319626

Epoch: 6| Step: 1
Training loss: 2.639824920975503
Validation loss: 2.85304281121776

Epoch: 6| Step: 2
Training loss: 3.2259201629654677
Validation loss: 2.8556127499423494

Epoch: 6| Step: 3
Training loss: 3.2603151510764077
Validation loss: 2.859535722470326

Epoch: 6| Step: 4
Training loss: 3.2713394907283213
Validation loss: 2.861264063015705

Epoch: 6| Step: 5
Training loss: 3.2505764083296302
Validation loss: 2.859918569703097

Epoch: 6| Step: 6
Training loss: 3.4371850996566593
Validation loss: 2.856730752276531

Epoch: 6| Step: 7
Training loss: 4.042383477791111
Validation loss: 2.853940228260676

Epoch: 6| Step: 8
Training loss: 2.9955570381807357
Validation loss: 2.8515056159975685

Epoch: 6| Step: 9
Training loss: 3.4277941924089745
Validation loss: 2.84990459844486

Epoch: 6| Step: 10
Training loss: 3.255830962589736
Validation loss: 2.8483597747420863

Epoch: 6| Step: 11
Training loss: 1.7994717617591025
Validation loss: 2.846096085699583

Epoch: 6| Step: 12
Training loss: 2.147141166079388
Validation loss: 2.8459258420610114

Epoch: 6| Step: 13
Training loss: 4.144545056232895
Validation loss: 2.849066810517142

Epoch: 33| Step: 0
Training loss: 3.1364504270645033
Validation loss: 2.8519911352450515

Epoch: 6| Step: 1
Training loss: 2.993195286847739
Validation loss: 2.852001877919232

Epoch: 6| Step: 2
Training loss: 3.2598759179401617
Validation loss: 2.8516795135642297

Epoch: 6| Step: 3
Training loss: 2.917869555971703
Validation loss: 2.8458420780384865

Epoch: 6| Step: 4
Training loss: 3.2720597674966623
Validation loss: 2.845473127925219

Epoch: 6| Step: 5
Training loss: 3.3215698733648553
Validation loss: 2.843894018190779

Epoch: 6| Step: 6
Training loss: 3.57603026796712
Validation loss: 2.8450862977172227

Epoch: 6| Step: 7
Training loss: 3.0452601139109534
Validation loss: 2.8455216862331576

Epoch: 6| Step: 8
Training loss: 3.890033355216856
Validation loss: 2.8454324090140477

Epoch: 6| Step: 9
Training loss: 3.1229051816668467
Validation loss: 2.8430695105525348

Epoch: 6| Step: 10
Training loss: 2.7244366334689447
Validation loss: 2.8379348586459145

Epoch: 6| Step: 11
Training loss: 2.792382494879808
Validation loss: 2.839510873991924

Epoch: 6| Step: 12
Training loss: 2.994657527849628
Validation loss: 2.8389706156100405

Epoch: 6| Step: 13
Training loss: 2.740499732396294
Validation loss: 2.836481150559837

Epoch: 34| Step: 0
Training loss: 2.9171927567992944
Validation loss: 2.837133584924048

Epoch: 6| Step: 1
Training loss: 3.0437566988203524
Validation loss: 2.835011286382734

Epoch: 6| Step: 2
Training loss: 2.888774547596406
Validation loss: 2.835148020892919

Epoch: 6| Step: 3
Training loss: 2.983179941620504
Validation loss: 2.8380224304867396

Epoch: 6| Step: 4
Training loss: 2.7086835390254436
Validation loss: 2.8373743594384626

Epoch: 6| Step: 5
Training loss: 3.592303175555
Validation loss: 2.8331704180337103

Epoch: 6| Step: 6
Training loss: 3.418493542301182
Validation loss: 2.833217494220434

Epoch: 6| Step: 7
Training loss: 3.603870240004086
Validation loss: 2.8306455038978657

Epoch: 6| Step: 8
Training loss: 3.5142987949956406
Validation loss: 2.8299856519913327

Epoch: 6| Step: 9
Training loss: 3.265759186976556
Validation loss: 2.83204421377415

Epoch: 6| Step: 10
Training loss: 2.195290996405471
Validation loss: 2.8301404797530965

Epoch: 6| Step: 11
Training loss: 3.139855437625983
Validation loss: 2.833879897357739

Epoch: 6| Step: 12
Training loss: 3.4939259547929296
Validation loss: 2.8404501766972583

Epoch: 6| Step: 13
Training loss: 2.784101417535827
Validation loss: 2.836882885634584

Epoch: 35| Step: 0
Training loss: 2.525156764083573
Validation loss: 2.8314020703632137

Epoch: 6| Step: 1
Training loss: 3.4236994369355287
Validation loss: 2.8317778330042

Epoch: 6| Step: 2
Training loss: 3.5437724117801555
Validation loss: 2.8269885090108122

Epoch: 6| Step: 3
Training loss: 3.2953667105805007
Validation loss: 2.8264423323752825

Epoch: 6| Step: 4
Training loss: 3.5730019754766795
Validation loss: 2.826513313080399

Epoch: 6| Step: 5
Training loss: 2.5113256452378776
Validation loss: 2.8298546634710253

Epoch: 6| Step: 6
Training loss: 2.857906443875194
Validation loss: 2.8299072212210294

Epoch: 6| Step: 7
Training loss: 2.700932578343104
Validation loss: 2.8279684419231224

Epoch: 6| Step: 8
Training loss: 3.374431986164197
Validation loss: 2.8253438243235167

Epoch: 6| Step: 9
Training loss: 3.031482805573583
Validation loss: 2.824081749579424

Epoch: 6| Step: 10
Training loss: 2.7588509395715644
Validation loss: 2.823358457075086

Epoch: 6| Step: 11
Training loss: 3.448935612671185
Validation loss: 2.827020185839014

Epoch: 6| Step: 12
Training loss: 3.4641250157339574
Validation loss: 2.830981794909641

Epoch: 6| Step: 13
Training loss: 3.0544258649543212
Validation loss: 2.8227742804046567

Epoch: 36| Step: 0
Training loss: 3.0562563718639644
Validation loss: 2.8201290849639555

Epoch: 6| Step: 1
Training loss: 2.9114916713673433
Validation loss: 2.8194492857388163

Epoch: 6| Step: 2
Training loss: 3.2070707999426404
Validation loss: 2.8187944507361373

Epoch: 6| Step: 3
Training loss: 3.1165952956515612
Validation loss: 2.817706769635318

Epoch: 6| Step: 4
Training loss: 3.5616277329550172
Validation loss: 2.8129645388951845

Epoch: 6| Step: 5
Training loss: 2.549589711261454
Validation loss: 2.813447800316099

Epoch: 6| Step: 6
Training loss: 2.97447455758791
Validation loss: 2.816706542652505

Epoch: 6| Step: 7
Training loss: 2.85039674105569
Validation loss: 2.818048054358174

Epoch: 6| Step: 8
Training loss: 3.2772695467054116
Validation loss: 2.818768669553898

Epoch: 6| Step: 9
Training loss: 3.3314330088317825
Validation loss: 2.8133542220903096

Epoch: 6| Step: 10
Training loss: 3.332943718710576
Validation loss: 2.8092524603103772

Epoch: 6| Step: 11
Training loss: 2.5881402812949728
Validation loss: 2.8108957562353876

Epoch: 6| Step: 12
Training loss: 3.2548271423944586
Validation loss: 2.8124999781235998

Epoch: 6| Step: 13
Training loss: 3.8564226850675123
Validation loss: 2.8087037748796986

Epoch: 37| Step: 0
Training loss: 3.316582521173109
Validation loss: 2.8109740954648026

Epoch: 6| Step: 1
Training loss: 3.8217343919766824
Validation loss: 2.813545019233107

Epoch: 6| Step: 2
Training loss: 3.188163239534473
Validation loss: 2.8128750695696927

Epoch: 6| Step: 3
Training loss: 3.544722386992003
Validation loss: 2.8137176092973117

Epoch: 6| Step: 4
Training loss: 2.8699618437353953
Validation loss: 2.8199802530557747

Epoch: 6| Step: 5
Training loss: 2.6557573647032933
Validation loss: 2.8183405985278633

Epoch: 6| Step: 6
Training loss: 3.1876530330049544
Validation loss: 2.8146156366078676

Epoch: 6| Step: 7
Training loss: 2.937342051054003
Validation loss: 2.8120710130075937

Epoch: 6| Step: 8
Training loss: 3.224921966318375
Validation loss: 2.8102714469006904

Epoch: 6| Step: 9
Training loss: 2.643836061055378
Validation loss: 2.808328421156234

Epoch: 6| Step: 10
Training loss: 3.1864757014027085
Validation loss: 2.8067136181535517

Epoch: 6| Step: 11
Training loss: 2.61119007324875
Validation loss: 2.8051220998203643

Epoch: 6| Step: 12
Training loss: 3.069927317600787
Validation loss: 2.8045112023616654

Epoch: 6| Step: 13
Training loss: 3.5967772628801984
Validation loss: 2.8012188609766113

Epoch: 38| Step: 0
Training loss: 2.4939452283729135
Validation loss: 2.802347276849161

Epoch: 6| Step: 1
Training loss: 3.0339975391395564
Validation loss: 2.801268857226478

Epoch: 6| Step: 2
Training loss: 4.214118279924908
Validation loss: 2.799977934072128

Epoch: 6| Step: 3
Training loss: 3.07242703604914
Validation loss: 2.8072331763156186

Epoch: 6| Step: 4
Training loss: 3.471357585488439
Validation loss: 2.8150744524492652

Epoch: 6| Step: 5
Training loss: 3.4149171645477225
Validation loss: 2.8139758668831365

Epoch: 6| Step: 6
Training loss: 3.449899401096436
Validation loss: 2.811004620323187

Epoch: 6| Step: 7
Training loss: 2.2673827620273057
Validation loss: 2.802947909190894

Epoch: 6| Step: 8
Training loss: 3.1862443432883043
Validation loss: 2.7948634786190683

Epoch: 6| Step: 9
Training loss: 2.0512565715900717
Validation loss: 2.793052750441595

Epoch: 6| Step: 10
Training loss: 3.178623330685998
Validation loss: 2.792576604979938

Epoch: 6| Step: 11
Training loss: 1.9015818485977678
Validation loss: 2.7934366901389285

Epoch: 6| Step: 12
Training loss: 3.7613596205046895
Validation loss: 2.796127421079426

Epoch: 6| Step: 13
Training loss: 3.2927092498581714
Validation loss: 2.8000215004023703

Epoch: 39| Step: 0
Training loss: 2.9635838582142346
Validation loss: 2.7994001855414115

Epoch: 6| Step: 1
Training loss: 3.7449674534115536
Validation loss: 2.7933113666484894

Epoch: 6| Step: 2
Training loss: 2.7891878158668657
Validation loss: 2.7890841207852275

Epoch: 6| Step: 3
Training loss: 3.611780991328418
Validation loss: 2.7888687506318526

Epoch: 6| Step: 4
Training loss: 2.6136810042598557
Validation loss: 2.788639050131093

Epoch: 6| Step: 5
Training loss: 3.207771615400988
Validation loss: 2.7895723536788575

Epoch: 6| Step: 6
Training loss: 2.1948446949649694
Validation loss: 2.7900738096947224

Epoch: 6| Step: 7
Training loss: 2.7096920615487674
Validation loss: 2.7887393604170345

Epoch: 6| Step: 8
Training loss: 2.7561601654429415
Validation loss: 2.7884156409467047

Epoch: 6| Step: 9
Training loss: 3.6623018178602567
Validation loss: 2.789687706156698

Epoch: 6| Step: 10
Training loss: 3.0777127527222294
Validation loss: 2.7873483148351212

Epoch: 6| Step: 11
Training loss: 3.3673097097076337
Validation loss: 2.7878522666065413

Epoch: 6| Step: 12
Training loss: 3.262591691756592
Validation loss: 2.790738415352628

Epoch: 6| Step: 13
Training loss: 3.1070130545026053
Validation loss: 2.7871123359009595

Epoch: 40| Step: 0
Training loss: 2.714869305607012
Validation loss: 2.7878282692610714

Epoch: 6| Step: 1
Training loss: 2.917864489958829
Validation loss: 2.7854475879111797

Epoch: 6| Step: 2
Training loss: 3.8796998102528217
Validation loss: 2.7910812479176

Epoch: 6| Step: 3
Training loss: 3.334502936843126
Validation loss: 2.8038658400784966

Epoch: 6| Step: 4
Training loss: 2.9245317589686572
Validation loss: 2.83112032046719

Epoch: 6| Step: 5
Training loss: 2.7058889557862758
Validation loss: 2.816544811588323

Epoch: 6| Step: 6
Training loss: 3.2349286918504743
Validation loss: 2.781572449277539

Epoch: 6| Step: 7
Training loss: 2.84131408995054
Validation loss: 2.7811807548011616

Epoch: 6| Step: 8
Training loss: 2.693677323283666
Validation loss: 2.782772565984914

Epoch: 6| Step: 9
Training loss: 2.982684230694181
Validation loss: 2.77994130947366

Epoch: 6| Step: 10
Training loss: 3.453218346624333
Validation loss: 2.787506576744432

Epoch: 6| Step: 11
Training loss: 3.046397636383005
Validation loss: 2.7908454688780133

Epoch: 6| Step: 12
Training loss: 3.3638349868091693
Validation loss: 2.7896885911251244

Epoch: 6| Step: 13
Training loss: 3.208982591866516
Validation loss: 2.781456611851989

Epoch: 41| Step: 0
Training loss: 2.970696704463805
Validation loss: 2.7808837326837867

Epoch: 6| Step: 1
Training loss: 3.2544935413131824
Validation loss: 2.7799135716334886

Epoch: 6| Step: 2
Training loss: 2.904186541700471
Validation loss: 2.7786832780149977

Epoch: 6| Step: 3
Training loss: 3.47119892724296
Validation loss: 2.7742602516663126

Epoch: 6| Step: 4
Training loss: 2.644117585007279
Validation loss: 2.7772435090489345

Epoch: 6| Step: 5
Training loss: 2.76061411217444
Validation loss: 2.7774077391177

Epoch: 6| Step: 6
Training loss: 3.443174360457755
Validation loss: 2.7777459484929268

Epoch: 6| Step: 7
Training loss: 2.385472748165187
Validation loss: 2.7881897542956073

Epoch: 6| Step: 8
Training loss: 3.4077363577219755
Validation loss: 2.7956500734714362

Epoch: 6| Step: 9
Training loss: 3.4450639215526877
Validation loss: 2.7962007143451566

Epoch: 6| Step: 10
Training loss: 2.9800591543586115
Validation loss: 2.789241241925591

Epoch: 6| Step: 11
Training loss: 2.253519272929423
Validation loss: 2.7835697695800397

Epoch: 6| Step: 12
Training loss: 3.97231150943973
Validation loss: 2.7819351913725883

Epoch: 6| Step: 13
Training loss: 2.8413731629461907
Validation loss: 2.779804510859753

Epoch: 42| Step: 0
Training loss: 3.105305831762285
Validation loss: 2.773635071981057

Epoch: 6| Step: 1
Training loss: 2.8173861128392717
Validation loss: 2.773378897126794

Epoch: 6| Step: 2
Training loss: 2.95956252087051
Validation loss: 2.7742504767223792

Epoch: 6| Step: 3
Training loss: 3.2955584315365107
Validation loss: 2.773031374336169

Epoch: 6| Step: 4
Training loss: 3.13280123663421
Validation loss: 2.771623429565635

Epoch: 6| Step: 5
Training loss: 3.8748858035088434
Validation loss: 2.769647752802131

Epoch: 6| Step: 6
Training loss: 2.6795210272235694
Validation loss: 2.7680610711662466

Epoch: 6| Step: 7
Training loss: 2.4462656716696083
Validation loss: 2.770209676568322

Epoch: 6| Step: 8
Training loss: 3.0749014613792722
Validation loss: 2.769423540113074

Epoch: 6| Step: 9
Training loss: 2.6120420063607637
Validation loss: 2.7742292818494865

Epoch: 6| Step: 10
Training loss: 3.100495508031693
Validation loss: 2.775417661697189

Epoch: 6| Step: 11
Training loss: 3.909266901389419
Validation loss: 2.7713315662139997

Epoch: 6| Step: 12
Training loss: 2.8174058301702725
Validation loss: 2.7719918415976634

Epoch: 6| Step: 13
Training loss: 2.8637868062804834
Validation loss: 2.770170648050356

Epoch: 43| Step: 0
Training loss: 3.1028027877171525
Validation loss: 2.765250220749066

Epoch: 6| Step: 1
Training loss: 2.676388503173983
Validation loss: 2.7643234669255685

Epoch: 6| Step: 2
Training loss: 2.5503523788821276
Validation loss: 2.7650894732027873

Epoch: 6| Step: 3
Training loss: 2.6299948627726346
Validation loss: 2.7632402905812

Epoch: 6| Step: 4
Training loss: 2.884596192711785
Validation loss: 2.762598103481563

Epoch: 6| Step: 5
Training loss: 3.027877819574462
Validation loss: 2.7609654338302496

Epoch: 6| Step: 6
Training loss: 3.2221788827312703
Validation loss: 2.7595942526872697

Epoch: 6| Step: 7
Training loss: 3.3592249637189466
Validation loss: 2.7592181404894083

Epoch: 6| Step: 8
Training loss: 3.664659008280669
Validation loss: 2.761523734346905

Epoch: 6| Step: 9
Training loss: 2.9738898506007008
Validation loss: 2.7701579518410084

Epoch: 6| Step: 10
Training loss: 3.5193068827623706
Validation loss: 2.775441565908514

Epoch: 6| Step: 11
Training loss: 3.5298890048291285
Validation loss: 2.7684201719196584

Epoch: 6| Step: 12
Training loss: 2.9262124572718182
Validation loss: 2.763973406869131

Epoch: 6| Step: 13
Training loss: 2.589615617603515
Validation loss: 2.757848307654141

Epoch: 44| Step: 0
Training loss: 3.0863094057443172
Validation loss: 2.756675422820112

Epoch: 6| Step: 1
Training loss: 3.806605425496249
Validation loss: 2.7610234366647264

Epoch: 6| Step: 2
Training loss: 2.836930198426572
Validation loss: 2.758204090746386

Epoch: 6| Step: 3
Training loss: 2.312968335539792
Validation loss: 2.7565054161944866

Epoch: 6| Step: 4
Training loss: 2.7670042402691983
Validation loss: 2.76069516715539

Epoch: 6| Step: 5
Training loss: 2.7998292121571513
Validation loss: 2.762929797143101

Epoch: 6| Step: 6
Training loss: 3.610657831418804
Validation loss: 2.764883478802506

Epoch: 6| Step: 7
Training loss: 3.4619084152369313
Validation loss: 2.757003676262252

Epoch: 6| Step: 8
Training loss: 2.632611637773288
Validation loss: 2.7527805014641245

Epoch: 6| Step: 9
Training loss: 2.999927678825947
Validation loss: 2.7552656751648152

Epoch: 6| Step: 10
Training loss: 2.9622793252256243
Validation loss: 2.75267195359342

Epoch: 6| Step: 11
Training loss: 3.3766082887664957
Validation loss: 2.7562199668874796

Epoch: 6| Step: 12
Training loss: 2.663886011268176
Validation loss: 2.7609767210240275

Epoch: 6| Step: 13
Training loss: 3.4774045460240868
Validation loss: 2.7549279285415964

Epoch: 45| Step: 0
Training loss: 2.933111930930225
Validation loss: 2.7566510871135184

Epoch: 6| Step: 1
Training loss: 2.5056829710049278
Validation loss: 2.752222294961693

Epoch: 6| Step: 2
Training loss: 2.937786981078003
Validation loss: 2.7501744562711252

Epoch: 6| Step: 3
Training loss: 3.301984398419718
Validation loss: 2.7531936760416054

Epoch: 6| Step: 4
Training loss: 2.842183949959558
Validation loss: 2.7487285710215734

Epoch: 6| Step: 5
Training loss: 2.9390984913773477
Validation loss: 2.7495021928841

Epoch: 6| Step: 6
Training loss: 3.0233047022474984
Validation loss: 2.750815763697142

Epoch: 6| Step: 7
Training loss: 3.2299615353399167
Validation loss: 2.753389899001458

Epoch: 6| Step: 8
Training loss: 3.021283942628912
Validation loss: 2.7596012191885375

Epoch: 6| Step: 9
Training loss: 3.0039316481371023
Validation loss: 2.750150288626414

Epoch: 6| Step: 10
Training loss: 3.1425140924372945
Validation loss: 2.7462464722773654

Epoch: 6| Step: 11
Training loss: 3.3910974973197283
Validation loss: 2.7470303943512824

Epoch: 6| Step: 12
Training loss: 3.1819934028830437
Validation loss: 2.7428858572169936

Epoch: 6| Step: 13
Training loss: 3.7187484612982638
Validation loss: 2.7438310899575242

Epoch: 46| Step: 0
Training loss: 3.842197631971505
Validation loss: 2.7431706221412377

Epoch: 6| Step: 1
Training loss: 2.8618235292656835
Validation loss: 2.7414066911688377

Epoch: 6| Step: 2
Training loss: 3.40701201428444
Validation loss: 2.741798687670619

Epoch: 6| Step: 3
Training loss: 3.087702842566645
Validation loss: 2.742605822457812

Epoch: 6| Step: 4
Training loss: 2.7804797531128873
Validation loss: 2.744970158277786

Epoch: 6| Step: 5
Training loss: 2.844836352423512
Validation loss: 2.7529750907054167

Epoch: 6| Step: 6
Training loss: 2.2875466388888235
Validation loss: 2.7635898006399215

Epoch: 6| Step: 7
Training loss: 2.6871534612038923
Validation loss: 2.772722682782808

Epoch: 6| Step: 8
Training loss: 3.6998910423938076
Validation loss: 2.7745732617593246

Epoch: 6| Step: 9
Training loss: 2.5495572622077676
Validation loss: 2.7518562994987734

Epoch: 6| Step: 10
Training loss: 3.320438589058086
Validation loss: 2.736195747560462

Epoch: 6| Step: 11
Training loss: 3.1734071235198367
Validation loss: 2.7361530707241766

Epoch: 6| Step: 12
Training loss: 2.5162218227031103
Validation loss: 2.7402794627784255

Epoch: 6| Step: 13
Training loss: 3.5194430493682636
Validation loss: 2.7404046669583013

Epoch: 47| Step: 0
Training loss: 3.0150547575525124
Validation loss: 2.7418558916873237

Epoch: 6| Step: 1
Training loss: 2.932902857953931
Validation loss: 2.7403195054624883

Epoch: 6| Step: 2
Training loss: 2.689426707329858
Validation loss: 2.7384303487430133

Epoch: 6| Step: 3
Training loss: 3.1222256361406093
Validation loss: 2.7370885029802197

Epoch: 6| Step: 4
Training loss: 3.009276511857442
Validation loss: 2.7362366295258407

Epoch: 6| Step: 5
Training loss: 3.3626139795207766
Validation loss: 2.7352694209686255

Epoch: 6| Step: 6
Training loss: 2.74359129705232
Validation loss: 2.7355089630827556

Epoch: 6| Step: 7
Training loss: 3.6543824732759336
Validation loss: 2.733524532693966

Epoch: 6| Step: 8
Training loss: 3.0972947899528616
Validation loss: 2.731510771035543

Epoch: 6| Step: 9
Training loss: 2.685351377827472
Validation loss: 2.7323899712351047

Epoch: 6| Step: 10
Training loss: 2.912001466446811
Validation loss: 2.7306457205860992

Epoch: 6| Step: 11
Training loss: 3.147353825890359
Validation loss: 2.7314506792128848

Epoch: 6| Step: 12
Training loss: 3.3079213581723836
Validation loss: 2.7314054288017906

Epoch: 6| Step: 13
Training loss: 3.167049250998783
Validation loss: 2.731793870712142

Epoch: 48| Step: 0
Training loss: 3.228599958016448
Validation loss: 2.731573480951203

Epoch: 6| Step: 1
Training loss: 3.602142618256632
Validation loss: 2.730054516640679

Epoch: 6| Step: 2
Training loss: 3.283268915954814
Validation loss: 2.7331156700511205

Epoch: 6| Step: 3
Training loss: 2.674623915715093
Validation loss: 2.7285928324101976

Epoch: 6| Step: 4
Training loss: 2.997241341293521
Validation loss: 2.7271281800694225

Epoch: 6| Step: 5
Training loss: 3.335234163633722
Validation loss: 2.7250756317492852

Epoch: 6| Step: 6
Training loss: 3.0603502474528894
Validation loss: 2.7284779281161993

Epoch: 6| Step: 7
Training loss: 3.0362107103427616
Validation loss: 2.7242408611726776

Epoch: 6| Step: 8
Training loss: 2.669331014311422
Validation loss: 2.721951540353763

Epoch: 6| Step: 9
Training loss: 2.618153499139451
Validation loss: 2.7250167856699496

Epoch: 6| Step: 10
Training loss: 3.429913698005978
Validation loss: 2.726398393853331

Epoch: 6| Step: 11
Training loss: 2.617166365353098
Validation loss: 2.727126727689639

Epoch: 6| Step: 12
Training loss: 2.6009164185490614
Validation loss: 2.7377563196235917

Epoch: 6| Step: 13
Training loss: 3.2716493661753105
Validation loss: 2.754159539137648

Epoch: 49| Step: 0
Training loss: 2.6302118786073465
Validation loss: 2.782990753701035

Epoch: 6| Step: 1
Training loss: 2.5076034316146085
Validation loss: 2.817783303689128

Epoch: 6| Step: 2
Training loss: 3.4317328886287877
Validation loss: 2.894350750786149

Epoch: 6| Step: 3
Training loss: 3.340046337742793
Validation loss: 2.8536722090108717

Epoch: 6| Step: 4
Training loss: 3.1281652061172687
Validation loss: 2.794579677802101

Epoch: 6| Step: 5
Training loss: 2.9140052278428583
Validation loss: 2.747187191116461

Epoch: 6| Step: 6
Training loss: 2.9018902636128026
Validation loss: 2.730320792517421

Epoch: 6| Step: 7
Training loss: 3.412603769366484
Validation loss: 2.720211299700194

Epoch: 6| Step: 8
Training loss: 3.0306471392294307
Validation loss: 2.7167303051324807

Epoch: 6| Step: 9
Training loss: 3.4943668810375352
Validation loss: 2.7214661824156066

Epoch: 6| Step: 10
Training loss: 3.0985594078624237
Validation loss: 2.719780113514994

Epoch: 6| Step: 11
Training loss: 2.5786944136219816
Validation loss: 2.7215909710114174

Epoch: 6| Step: 12
Training loss: 2.8483654755961987
Validation loss: 2.72088252095672

Epoch: 6| Step: 13
Training loss: 3.4522889104641106
Validation loss: 2.7205763403766183

Epoch: 50| Step: 0
Training loss: 2.3665283091044924
Validation loss: 2.720056691510902

Epoch: 6| Step: 1
Training loss: 3.416055826307185
Validation loss: 2.7205949736550066

Epoch: 6| Step: 2
Training loss: 3.4712368410415335
Validation loss: 2.7213802313828412

Epoch: 6| Step: 3
Training loss: 2.8160776060312895
Validation loss: 2.719964995540505

Epoch: 6| Step: 4
Training loss: 2.840455378975127
Validation loss: 2.7211911749638795

Epoch: 6| Step: 5
Training loss: 3.2034971439687623
Validation loss: 2.7196989995101335

Epoch: 6| Step: 6
Training loss: 2.6495529121547774
Validation loss: 2.719980327585127

Epoch: 6| Step: 7
Training loss: 2.7877541259428575
Validation loss: 2.718411147392228

Epoch: 6| Step: 8
Training loss: 3.2904107961465026
Validation loss: 2.717102007696285

Epoch: 6| Step: 9
Training loss: 2.9085648044700254
Validation loss: 2.7169110513676293

Epoch: 6| Step: 10
Training loss: 2.8924099746449814
Validation loss: 2.716340900159928

Epoch: 6| Step: 11
Training loss: 3.445654335277666
Validation loss: 2.7189327466642372

Epoch: 6| Step: 12
Training loss: 3.1948591064525846
Validation loss: 2.7176215413926172

Epoch: 6| Step: 13
Training loss: 3.3296804598980447
Validation loss: 2.718214564815728

Epoch: 51| Step: 0
Training loss: 3.2854854314490076
Validation loss: 2.718552636590254

Epoch: 6| Step: 1
Training loss: 2.721150971390662
Validation loss: 2.725539613378451

Epoch: 6| Step: 2
Training loss: 3.4689751629307284
Validation loss: 2.718863066577132

Epoch: 6| Step: 3
Training loss: 3.126534657351977
Validation loss: 2.7240921527540896

Epoch: 6| Step: 4
Training loss: 2.9770739659099057
Validation loss: 2.7274237331319506

Epoch: 6| Step: 5
Training loss: 3.024721016117321
Validation loss: 2.735611401490947

Epoch: 6| Step: 6
Training loss: 2.928206982681185
Validation loss: 2.7459830762131343

Epoch: 6| Step: 7
Training loss: 2.666229172422718
Validation loss: 2.762041857905312

Epoch: 6| Step: 8
Training loss: 3.2907910369398587
Validation loss: 2.760187167291692

Epoch: 6| Step: 9
Training loss: 3.4408935442074284
Validation loss: 2.7300159526585586

Epoch: 6| Step: 10
Training loss: 2.591177066378319
Validation loss: 2.704823051839659

Epoch: 6| Step: 11
Training loss: 2.620257316649749
Validation loss: 2.7031830432831123

Epoch: 6| Step: 12
Training loss: 3.233294025326405
Validation loss: 2.704755955053016

Epoch: 6| Step: 13
Training loss: 2.987380506607715
Validation loss: 2.709787633029541

Epoch: 52| Step: 0
Training loss: 2.9342740790061757
Validation loss: 2.7139027531451845

Epoch: 6| Step: 1
Training loss: 2.4854826946926134
Validation loss: 2.7105706486124626

Epoch: 6| Step: 2
Training loss: 3.1908352923609318
Validation loss: 2.709375725781647

Epoch: 6| Step: 3
Training loss: 3.311929185736834
Validation loss: 2.709716493534324

Epoch: 6| Step: 4
Training loss: 2.4268202959762806
Validation loss: 2.707392190326723

Epoch: 6| Step: 5
Training loss: 3.6295499199990537
Validation loss: 2.7080945448444966

Epoch: 6| Step: 6
Training loss: 2.856839415921773
Validation loss: 2.707497145031324

Epoch: 6| Step: 7
Training loss: 3.2976779050461684
Validation loss: 2.7082691087199184

Epoch: 6| Step: 8
Training loss: 3.348286341300553
Validation loss: 2.7081290408593968

Epoch: 6| Step: 9
Training loss: 2.625401420781069
Validation loss: 2.705087154330859

Epoch: 6| Step: 10
Training loss: 3.2917634651984686
Validation loss: 2.7048136448740037

Epoch: 6| Step: 11
Training loss: 3.1756973161667488
Validation loss: 2.7052223054305173

Epoch: 6| Step: 12
Training loss: 2.613301138809313
Validation loss: 2.7039996160798303

Epoch: 6| Step: 13
Training loss: 3.2015935446712724
Validation loss: 2.6997741144033585

Epoch: 53| Step: 0
Training loss: 3.2331974263156558
Validation loss: 2.700944694454248

Epoch: 6| Step: 1
Training loss: 2.810207534674166
Validation loss: 2.7025865650070795

Epoch: 6| Step: 2
Training loss: 3.5779152354759574
Validation loss: 2.7150098783913537

Epoch: 6| Step: 3
Training loss: 3.3305574939062144
Validation loss: 2.7189149590823827

Epoch: 6| Step: 4
Training loss: 3.0102430951372163
Validation loss: 2.715944920636945

Epoch: 6| Step: 5
Training loss: 3.5280606881455827
Validation loss: 2.7136325918179436

Epoch: 6| Step: 6
Training loss: 2.9852862340026594
Validation loss: 2.7104639335547076

Epoch: 6| Step: 7
Training loss: 2.87874359540935
Validation loss: 2.702287034657364

Epoch: 6| Step: 8
Training loss: 2.762894397734638
Validation loss: 2.688745051430176

Epoch: 6| Step: 9
Training loss: 2.337326198379121
Validation loss: 2.688612255373728

Epoch: 6| Step: 10
Training loss: 2.4747923291866973
Validation loss: 2.6893505375019227

Epoch: 6| Step: 11
Training loss: 3.394213206116289
Validation loss: 2.6945502736097695

Epoch: 6| Step: 12
Training loss: 2.9451020264236893
Validation loss: 2.693868618970089

Epoch: 6| Step: 13
Training loss: 2.6448157649064803
Validation loss: 2.6975486682720886

Epoch: 54| Step: 0
Training loss: 3.033741035589641
Validation loss: 2.697485403057742

Epoch: 6| Step: 1
Training loss: 2.5111491505190098
Validation loss: 2.6968944090626956

Epoch: 6| Step: 2
Training loss: 2.9434052218870463
Validation loss: 2.6996967143057606

Epoch: 6| Step: 3
Training loss: 3.5022283000242465
Validation loss: 2.701930532179068

Epoch: 6| Step: 4
Training loss: 3.0206933000050356
Validation loss: 2.7026574378150348

Epoch: 6| Step: 5
Training loss: 2.8416149802182527
Validation loss: 2.6942508613028227

Epoch: 6| Step: 6
Training loss: 3.2084981372335033
Validation loss: 2.697091103659257

Epoch: 6| Step: 7
Training loss: 2.9272848220566714
Validation loss: 2.696359634003259

Epoch: 6| Step: 8
Training loss: 3.299988058819985
Validation loss: 2.694999033857941

Epoch: 6| Step: 9
Training loss: 2.9481622887898284
Validation loss: 2.6921059682536512

Epoch: 6| Step: 10
Training loss: 3.1409611308581207
Validation loss: 2.687671150353415

Epoch: 6| Step: 11
Training loss: 3.114781878382874
Validation loss: 2.6977978723481226

Epoch: 6| Step: 12
Training loss: 2.8257731569663105
Validation loss: 2.6918564572352968

Epoch: 6| Step: 13
Training loss: 2.998058644622663
Validation loss: 2.6911863955822817

Epoch: 55| Step: 0
Training loss: 3.127725709474617
Validation loss: 2.6965533348441704

Epoch: 6| Step: 1
Training loss: 2.910056298094773
Validation loss: 2.695876145484521

Epoch: 6| Step: 2
Training loss: 2.8973189095098455
Validation loss: 2.6989470314345265

Epoch: 6| Step: 3
Training loss: 3.518922471584583
Validation loss: 2.7058023261286346

Epoch: 6| Step: 4
Training loss: 2.9098455685671976
Validation loss: 2.7096892317611125

Epoch: 6| Step: 5
Training loss: 3.037279876142551
Validation loss: 2.723796025477711

Epoch: 6| Step: 6
Training loss: 3.1210465409739236
Validation loss: 2.7340445740456842

Epoch: 6| Step: 7
Training loss: 3.043717690047647
Validation loss: 2.769874668442291

Epoch: 6| Step: 8
Training loss: 2.977804730737779
Validation loss: 2.730587741879079

Epoch: 6| Step: 9
Training loss: 3.205007902186229
Validation loss: 2.7065206464418465

Epoch: 6| Step: 10
Training loss: 1.9028896668603186
Validation loss: 2.688283833168659

Epoch: 6| Step: 11
Training loss: 3.106732803372033
Validation loss: 2.6809565906715536

Epoch: 6| Step: 12
Training loss: 2.5089760811229294
Validation loss: 2.6747378541429634

Epoch: 6| Step: 13
Training loss: 4.074663234907306
Validation loss: 2.6780325437851165

Epoch: 56| Step: 0
Training loss: 2.451961168364416
Validation loss: 2.6805707311316684

Epoch: 6| Step: 1
Training loss: 3.3367307197858063
Validation loss: 2.6830504801131436

Epoch: 6| Step: 2
Training loss: 3.677423708167789
Validation loss: 2.6828318406300884

Epoch: 6| Step: 3
Training loss: 3.2841409209632153
Validation loss: 2.681921824448749

Epoch: 6| Step: 4
Training loss: 2.390760929008091
Validation loss: 2.6879937285277116

Epoch: 6| Step: 5
Training loss: 2.9955027568093215
Validation loss: 2.6872955849305833

Epoch: 6| Step: 6
Training loss: 2.896053516241215
Validation loss: 2.6843927797624527

Epoch: 6| Step: 7
Training loss: 3.3030340869702663
Validation loss: 2.6804478757395787

Epoch: 6| Step: 8
Training loss: 2.824828022811207
Validation loss: 2.6809173386032676

Epoch: 6| Step: 9
Training loss: 2.557018371605545
Validation loss: 2.6788992213694693

Epoch: 6| Step: 10
Training loss: 3.1573053993791493
Validation loss: 2.678949763548073

Epoch: 6| Step: 11
Training loss: 2.991642436688272
Validation loss: 2.6766570524220974

Epoch: 6| Step: 12
Training loss: 3.2568974296106403
Validation loss: 2.676432093709451

Epoch: 6| Step: 13
Training loss: 2.9289660570047475
Validation loss: 2.6763929630275656

Epoch: 57| Step: 0
Training loss: 3.172276363441528
Validation loss: 2.6750140084241143

Epoch: 6| Step: 1
Training loss: 2.826319671541453
Validation loss: 2.6721739146918457

Epoch: 6| Step: 2
Training loss: 3.0408193026304606
Validation loss: 2.675092527100149

Epoch: 6| Step: 3
Training loss: 2.815889647109721
Validation loss: 2.6709241505849453

Epoch: 6| Step: 4
Training loss: 2.97689120662874
Validation loss: 2.668584216528328

Epoch: 6| Step: 5
Training loss: 3.1539914954729387
Validation loss: 2.667877259596511

Epoch: 6| Step: 6
Training loss: 3.0535510356480255
Validation loss: 2.6719244920183507

Epoch: 6| Step: 7
Training loss: 2.929655273260252
Validation loss: 2.680002215628947

Epoch: 6| Step: 8
Training loss: 2.7375368856096243
Validation loss: 2.6781902039992445

Epoch: 6| Step: 9
Training loss: 3.681531051502718
Validation loss: 2.678475179764398

Epoch: 6| Step: 10
Training loss: 2.91978436914939
Validation loss: 2.6846283764057755

Epoch: 6| Step: 11
Training loss: 3.0651389449271274
Validation loss: 2.6691931618055396

Epoch: 6| Step: 12
Training loss: 2.8566135767748078
Validation loss: 2.66531496693963

Epoch: 6| Step: 13
Training loss: 2.8187614254603615
Validation loss: 2.662648032713865

Epoch: 58| Step: 0
Training loss: 3.441487028838773
Validation loss: 2.6645495559788874

Epoch: 6| Step: 1
Training loss: 2.5692450907126636
Validation loss: 2.663813083891233

Epoch: 6| Step: 2
Training loss: 2.9526668778562466
Validation loss: 2.663999966763269

Epoch: 6| Step: 3
Training loss: 3.0094725152335733
Validation loss: 2.665969988034805

Epoch: 6| Step: 4
Training loss: 2.32338051947352
Validation loss: 2.6659048136822436

Epoch: 6| Step: 5
Training loss: 3.061557235409535
Validation loss: 2.6678311567073822

Epoch: 6| Step: 6
Training loss: 2.6142102060126504
Validation loss: 2.66563922626452

Epoch: 6| Step: 7
Training loss: 3.303197502271651
Validation loss: 2.667022274389514

Epoch: 6| Step: 8
Training loss: 2.91060926764465
Validation loss: 2.6648826636949403

Epoch: 6| Step: 9
Training loss: 2.944872916933294
Validation loss: 2.6657103216343794

Epoch: 6| Step: 10
Training loss: 3.4215254931739807
Validation loss: 2.6709622249615155

Epoch: 6| Step: 11
Training loss: 3.0889683000463775
Validation loss: 2.6651478609397556

Epoch: 6| Step: 12
Training loss: 3.410765708130548
Validation loss: 2.6635450876474915

Epoch: 6| Step: 13
Training loss: 2.7523833264145643
Validation loss: 2.662924325443666

Epoch: 59| Step: 0
Training loss: 3.111196779782156
Validation loss: 2.661179499619745

Epoch: 6| Step: 1
Training loss: 2.8821385533994044
Validation loss: 2.6569739863715864

Epoch: 6| Step: 2
Training loss: 3.422460775882051
Validation loss: 2.6568808957898082

Epoch: 6| Step: 3
Training loss: 3.7217177401869246
Validation loss: 2.663127062889308

Epoch: 6| Step: 4
Training loss: 2.9440499187363027
Validation loss: 2.6682200172896793

Epoch: 6| Step: 5
Training loss: 2.9154329324569934
Validation loss: 2.6743297237799553

Epoch: 6| Step: 6
Training loss: 2.354775094147752
Validation loss: 2.6683715714158525

Epoch: 6| Step: 7
Training loss: 2.77887564474159
Validation loss: 2.6733344366176537

Epoch: 6| Step: 8
Training loss: 2.9180976808551504
Validation loss: 2.662903974506181

Epoch: 6| Step: 9
Training loss: 3.1155582462915303
Validation loss: 2.664205771812704

Epoch: 6| Step: 10
Training loss: 2.4582845284310335
Validation loss: 2.664644923393868

Epoch: 6| Step: 11
Training loss: 2.797934134498164
Validation loss: 2.662011226960712

Epoch: 6| Step: 12
Training loss: 3.291536465415752
Validation loss: 2.659292203888903

Epoch: 6| Step: 13
Training loss: 2.8167858106104635
Validation loss: 2.6596376179332646

Epoch: 60| Step: 0
Training loss: 3.179509338336398
Validation loss: 2.653869267523753

Epoch: 6| Step: 1
Training loss: 3.0331452727097212
Validation loss: 2.654683690143003

Epoch: 6| Step: 2
Training loss: 2.8511330477130876
Validation loss: 2.6481747630183627

Epoch: 6| Step: 3
Training loss: 3.044886639619335
Validation loss: 2.650745284296616

Epoch: 6| Step: 4
Training loss: 3.0410755227522728
Validation loss: 2.652782658014453

Epoch: 6| Step: 5
Training loss: 3.1832285665744555
Validation loss: 2.651517493688164

Epoch: 6| Step: 6
Training loss: 3.465198244971437
Validation loss: 2.650243584429047

Epoch: 6| Step: 7
Training loss: 2.5249695275611357
Validation loss: 2.653531083766725

Epoch: 6| Step: 8
Training loss: 3.5196968065078007
Validation loss: 2.651625552359461

Epoch: 6| Step: 9
Training loss: 2.6663363868106766
Validation loss: 2.653004332444171

Epoch: 6| Step: 10
Training loss: 2.227237853306242
Validation loss: 2.651381724992757

Epoch: 6| Step: 11
Training loss: 3.3848817060302654
Validation loss: 2.6454491065411063

Epoch: 6| Step: 12
Training loss: 2.5827912613029516
Validation loss: 2.644541438501715

Epoch: 6| Step: 13
Training loss: 2.7751434667118997
Validation loss: 2.647624682495695

Epoch: 61| Step: 0
Training loss: 2.8321238535506503
Validation loss: 2.6501616151424168

Epoch: 6| Step: 1
Training loss: 2.866887297752588
Validation loss: 2.672760737049483

Epoch: 6| Step: 2
Training loss: 2.566607277253264
Validation loss: 2.713937704321166

Epoch: 6| Step: 3
Training loss: 2.5595979772744264
Validation loss: 2.739843621848083

Epoch: 6| Step: 4
Training loss: 2.950805722135912
Validation loss: 2.716821543163399

Epoch: 6| Step: 5
Training loss: 3.5169704999036293
Validation loss: 2.6551622502794774

Epoch: 6| Step: 6
Training loss: 3.025465804878121
Validation loss: 2.6423067787090266

Epoch: 6| Step: 7
Training loss: 3.1990141005495953
Validation loss: 2.6426147490413845

Epoch: 6| Step: 8
Training loss: 2.442048353061709
Validation loss: 2.6446573461830045

Epoch: 6| Step: 9
Training loss: 3.336403450150736
Validation loss: 2.645592330125038

Epoch: 6| Step: 10
Training loss: 3.2921276172176066
Validation loss: 2.649679832674723

Epoch: 6| Step: 11
Training loss: 2.989304550588145
Validation loss: 2.653960466120748

Epoch: 6| Step: 12
Training loss: 3.282055565177128
Validation loss: 2.654150343020678

Epoch: 6| Step: 13
Training loss: 2.877715279805912
Validation loss: 2.6522299732033745

Epoch: 62| Step: 0
Training loss: 3.4522057599996847
Validation loss: 2.6540574687771277

Epoch: 6| Step: 1
Training loss: 3.1021292910855345
Validation loss: 2.6542789932765762

Epoch: 6| Step: 2
Training loss: 3.4258736714300566
Validation loss: 2.6512678314896707

Epoch: 6| Step: 3
Training loss: 2.5396838557622163
Validation loss: 2.650843535151094

Epoch: 6| Step: 4
Training loss: 2.615423353801559
Validation loss: 2.6523628432924276

Epoch: 6| Step: 5
Training loss: 3.181411013622361
Validation loss: 2.6496286779839675

Epoch: 6| Step: 6
Training loss: 2.845416241115714
Validation loss: 2.6509406828077364

Epoch: 6| Step: 7
Training loss: 3.053771835417723
Validation loss: 2.6469580001109474

Epoch: 6| Step: 8
Training loss: 2.6477447774117193
Validation loss: 2.6426541587058665

Epoch: 6| Step: 9
Training loss: 2.4423976502698035
Validation loss: 2.645300515918072

Epoch: 6| Step: 10
Training loss: 2.9769431043575607
Validation loss: 2.6404015231166267

Epoch: 6| Step: 11
Training loss: 3.0347735189432665
Validation loss: 2.641045781683172

Epoch: 6| Step: 12
Training loss: 3.263125690663982
Validation loss: 2.6415279752498075

Epoch: 6| Step: 13
Training loss: 3.2847627274800666
Validation loss: 2.642428851945829

Epoch: 63| Step: 0
Training loss: 3.461419409962485
Validation loss: 2.6481146562880937

Epoch: 6| Step: 1
Training loss: 2.9703271792238213
Validation loss: 2.648784005317998

Epoch: 6| Step: 2
Training loss: 3.0455784313102505
Validation loss: 2.648327668514355

Epoch: 6| Step: 3
Training loss: 2.9902869979244557
Validation loss: 2.6627859256037105

Epoch: 6| Step: 4
Training loss: 3.4639837838513556
Validation loss: 2.672649185748725

Epoch: 6| Step: 5
Training loss: 2.525738779897348
Validation loss: 2.6771255999922126

Epoch: 6| Step: 6
Training loss: 2.995510556832299
Validation loss: 2.6889608313919773

Epoch: 6| Step: 7
Training loss: 2.933611954836989
Validation loss: 2.681070455520412

Epoch: 6| Step: 8
Training loss: 2.5157058418505427
Validation loss: 2.6707903359808385

Epoch: 6| Step: 9
Training loss: 3.177914136644931
Validation loss: 2.651674100705937

Epoch: 6| Step: 10
Training loss: 2.8758523755551724
Validation loss: 2.634748145876734

Epoch: 6| Step: 11
Training loss: 2.758322692881303
Validation loss: 2.6323909261946823

Epoch: 6| Step: 12
Training loss: 2.845833319184139
Validation loss: 2.636040843501674

Epoch: 6| Step: 13
Training loss: 3.0422465847177085
Validation loss: 2.6356436236803655

Epoch: 64| Step: 0
Training loss: 3.0564911729637423
Validation loss: 2.633063808893901

Epoch: 6| Step: 1
Training loss: 3.0245001450858804
Validation loss: 2.6344464249330684

Epoch: 6| Step: 2
Training loss: 2.905976805613421
Validation loss: 2.6365159683915

Epoch: 6| Step: 3
Training loss: 2.2518682141271915
Validation loss: 2.6342553735080854

Epoch: 6| Step: 4
Training loss: 2.850178923762671
Validation loss: 2.633141287606087

Epoch: 6| Step: 5
Training loss: 2.570699552479331
Validation loss: 2.6354010258588696

Epoch: 6| Step: 6
Training loss: 2.633390006731109
Validation loss: 2.632831902412848

Epoch: 6| Step: 7
Training loss: 3.621929051783365
Validation loss: 2.6342268500205996

Epoch: 6| Step: 8
Training loss: 2.6671118861309266
Validation loss: 2.6319426272307145

Epoch: 6| Step: 9
Training loss: 2.8446600160106046
Validation loss: 2.6372914061344375

Epoch: 6| Step: 10
Training loss: 3.0868542818377103
Validation loss: 2.6375558259863823

Epoch: 6| Step: 11
Training loss: 3.4439095129604484
Validation loss: 2.6461344140593304

Epoch: 6| Step: 12
Training loss: 3.5064914994190484
Validation loss: 2.65631529446094

Epoch: 6| Step: 13
Training loss: 3.13685069869578
Validation loss: 2.6633495271342307

Epoch: 65| Step: 0
Training loss: 3.011111820482059
Validation loss: 2.638878377383644

Epoch: 6| Step: 1
Training loss: 3.034415096878404
Validation loss: 2.628894261185321

Epoch: 6| Step: 2
Training loss: 3.519376795827048
Validation loss: 2.6243305446460794

Epoch: 6| Step: 3
Training loss: 2.739649628005106
Validation loss: 2.622736284380315

Epoch: 6| Step: 4
Training loss: 3.235125615836909
Validation loss: 2.6300629183983846

Epoch: 6| Step: 5
Training loss: 3.211103968702188
Validation loss: 2.629428049825015

Epoch: 6| Step: 6
Training loss: 2.439251295037183
Validation loss: 2.6253989366257664

Epoch: 6| Step: 7
Training loss: 2.6311130189011647
Validation loss: 2.6216330276618653

Epoch: 6| Step: 8
Training loss: 2.991770423924639
Validation loss: 2.6194570316203993

Epoch: 6| Step: 9
Training loss: 3.1247381482090697
Validation loss: 2.6226924944284646

Epoch: 6| Step: 10
Training loss: 2.724770030545762
Validation loss: 2.620746895799219

Epoch: 6| Step: 11
Training loss: 2.9170239002712024
Validation loss: 2.62323563596687

Epoch: 6| Step: 12
Training loss: 2.862659339967664
Validation loss: 2.624289760810838

Epoch: 6| Step: 13
Training loss: 2.98586934808859
Validation loss: 2.6258268885124436

Epoch: 66| Step: 0
Training loss: 2.917440384465743
Validation loss: 2.6294597169955396

Epoch: 6| Step: 1
Training loss: 2.8701284849003583
Validation loss: 2.619742268484945

Epoch: 6| Step: 2
Training loss: 2.3075508563387817
Validation loss: 2.6216493269031504

Epoch: 6| Step: 3
Training loss: 2.9460058231024284
Validation loss: 2.6237567471296086

Epoch: 6| Step: 4
Training loss: 3.1845198518790423
Validation loss: 2.625387457141723

Epoch: 6| Step: 5
Training loss: 2.8300174682940757
Validation loss: 2.6281970244851456

Epoch: 6| Step: 6
Training loss: 3.2220822464658974
Validation loss: 2.6303872750077835

Epoch: 6| Step: 7
Training loss: 2.562504559024384
Validation loss: 2.632069866101793

Epoch: 6| Step: 8
Training loss: 3.7386434891762756
Validation loss: 2.636612076570757

Epoch: 6| Step: 9
Training loss: 2.6453198112301135
Validation loss: 2.646086861773395

Epoch: 6| Step: 10
Training loss: 3.2568431116394
Validation loss: 2.64049063535666

Epoch: 6| Step: 11
Training loss: 3.035739052294833
Validation loss: 2.638607462384201

Epoch: 6| Step: 12
Training loss: 3.0650442026258435
Validation loss: 2.6233795572975276

Epoch: 6| Step: 13
Training loss: 2.4768552396545798
Validation loss: 2.631747053362532

Epoch: 67| Step: 0
Training loss: 3.081792669888853
Validation loss: 2.6193663738471984

Epoch: 6| Step: 1
Training loss: 3.1969100577332994
Validation loss: 2.6174737491222357

Epoch: 6| Step: 2
Training loss: 2.745495748727453
Validation loss: 2.6124024420208385

Epoch: 6| Step: 3
Training loss: 2.7243607602466007
Validation loss: 2.6106257431182134

Epoch: 6| Step: 4
Training loss: 3.4149921469646993
Validation loss: 2.612566652883843

Epoch: 6| Step: 5
Training loss: 2.777850784825846
Validation loss: 2.6167225767137183

Epoch: 6| Step: 6
Training loss: 3.8097604382910966
Validation loss: 2.655857189843072

Epoch: 6| Step: 7
Training loss: 2.5135309258389733
Validation loss: 2.650998323318599

Epoch: 6| Step: 8
Training loss: 2.415156045772892
Validation loss: 2.658823425540144

Epoch: 6| Step: 9
Training loss: 2.74866158253436
Validation loss: 2.6576719923477286

Epoch: 6| Step: 10
Training loss: 3.0952197350317285
Validation loss: 2.6610552894369337

Epoch: 6| Step: 11
Training loss: 2.7925744265180867
Validation loss: 2.659703941549778

Epoch: 6| Step: 12
Training loss: 3.237546683309961
Validation loss: 2.663093240212587

Epoch: 6| Step: 13
Training loss: 2.8412459530950507
Validation loss: 2.6664569205684074

Epoch: 68| Step: 0
Training loss: 3.006548568904247
Validation loss: 2.676946754717511

Epoch: 6| Step: 1
Training loss: 3.328766380438788
Validation loss: 2.6703624232704284

Epoch: 6| Step: 2
Training loss: 3.278508376112712
Validation loss: 2.6612140267337443

Epoch: 6| Step: 3
Training loss: 2.9595631653402283
Validation loss: 2.6590953221505873

Epoch: 6| Step: 4
Training loss: 2.7054750667699863
Validation loss: 2.6566384404856715

Epoch: 6| Step: 5
Training loss: 2.3889387578958674
Validation loss: 2.655392621701003

Epoch: 6| Step: 6
Training loss: 3.3045126144992647
Validation loss: 2.655515573347367

Epoch: 6| Step: 7
Training loss: 3.203541202952394
Validation loss: 2.6632992905185473

Epoch: 6| Step: 8
Training loss: 2.479031267929928
Validation loss: 2.6672117447850656

Epoch: 6| Step: 9
Training loss: 2.9218922986829168
Validation loss: 2.6580298534419176

Epoch: 6| Step: 10
Training loss: 2.552078828353539
Validation loss: 2.655195844741725

Epoch: 6| Step: 11
Training loss: 3.216611577749831
Validation loss: 2.6519682896037153

Epoch: 6| Step: 12
Training loss: 3.2426692742579832
Validation loss: 2.6517422375337345

Epoch: 6| Step: 13
Training loss: 3.1134128135920807
Validation loss: 2.6498483417475267

Epoch: 69| Step: 0
Training loss: 2.4530964260502457
Validation loss: 2.6508963520273072

Epoch: 6| Step: 1
Training loss: 3.900959185486756
Validation loss: 2.652037203324679

Epoch: 6| Step: 2
Training loss: 2.8110688700997435
Validation loss: 2.6604766129979267

Epoch: 6| Step: 3
Training loss: 2.864615885231714
Validation loss: 2.668244846311511

Epoch: 6| Step: 4
Training loss: 3.1265053747201996
Validation loss: 2.6728931687392494

Epoch: 6| Step: 5
Training loss: 2.819214752520868
Validation loss: 2.6714075362368175

Epoch: 6| Step: 6
Training loss: 2.836933391984493
Validation loss: 2.6628340634851355

Epoch: 6| Step: 7
Training loss: 2.9573322984448827
Validation loss: 2.6600596865883577

Epoch: 6| Step: 8
Training loss: 3.0764586299877927
Validation loss: 2.6469471836200498

Epoch: 6| Step: 9
Training loss: 2.7842321802366943
Validation loss: 2.6547908821712554

Epoch: 6| Step: 10
Training loss: 2.8014166415828883
Validation loss: 2.6536986594833323

Epoch: 6| Step: 11
Training loss: 2.790815128628881
Validation loss: 2.6375940729598106

Epoch: 6| Step: 12
Training loss: 2.956100660104608
Validation loss: 2.6381659579843566

Epoch: 6| Step: 13
Training loss: 3.727834552408982
Validation loss: 2.6294769387843346

Epoch: 70| Step: 0
Training loss: 2.8347757445216923
Validation loss: 2.605642386090014

Epoch: 6| Step: 1
Training loss: 2.8118370122435707
Validation loss: 2.6039928350369412

Epoch: 6| Step: 2
Training loss: 3.035663027290544
Validation loss: 2.6075962270290907

Epoch: 6| Step: 3
Training loss: 3.24219970700827
Validation loss: 2.612375786877255

Epoch: 6| Step: 4
Training loss: 2.8944676607176714
Validation loss: 2.61421396192201

Epoch: 6| Step: 5
Training loss: 2.7344565243148264
Validation loss: 2.6163673238539955

Epoch: 6| Step: 6
Training loss: 2.96870582949254
Validation loss: 2.6087435923148794

Epoch: 6| Step: 7
Training loss: 3.3394842300099805
Validation loss: 2.6079656420090354

Epoch: 6| Step: 8
Training loss: 3.0616148623211163
Validation loss: 2.5997960786859666

Epoch: 6| Step: 9
Training loss: 2.798793198872713
Validation loss: 2.5948654298753357

Epoch: 6| Step: 10
Training loss: 2.0898327978684983
Validation loss: 2.5994750915253846

Epoch: 6| Step: 11
Training loss: 3.0217412877604612
Validation loss: 2.595644785960639

Epoch: 6| Step: 12
Training loss: 2.8815409019065394
Validation loss: 2.6046962270154905

Epoch: 6| Step: 13
Training loss: 3.7265569978749347
Validation loss: 2.6024303634985606

Epoch: 71| Step: 0
Training loss: 2.4971074536798348
Validation loss: 2.6124115880423373

Epoch: 6| Step: 1
Training loss: 3.198058200814729
Validation loss: 2.645739328815256

Epoch: 6| Step: 2
Training loss: 3.714418340767433
Validation loss: 2.6954354739510316

Epoch: 6| Step: 3
Training loss: 2.5406262086909988
Validation loss: 2.661001182838809

Epoch: 6| Step: 4
Training loss: 3.0240581969458895
Validation loss: 2.667446572968841

Epoch: 6| Step: 5
Training loss: 2.8936823991496436
Validation loss: 2.664652406555579

Epoch: 6| Step: 6
Training loss: 2.8883494725320333
Validation loss: 2.6435529070012596

Epoch: 6| Step: 7
Training loss: 2.460644707594772
Validation loss: 2.609910369807091

Epoch: 6| Step: 8
Training loss: 2.442055284822528
Validation loss: 2.594299778034021

Epoch: 6| Step: 9
Training loss: 3.1385292158482305
Validation loss: 2.593255011736104

Epoch: 6| Step: 10
Training loss: 3.2344469440217143
Validation loss: 2.5950102538483715

Epoch: 6| Step: 11
Training loss: 2.7508448256751685
Validation loss: 2.5999719858040757

Epoch: 6| Step: 12
Training loss: 3.037769660439661
Validation loss: 2.6024179601402935

Epoch: 6| Step: 13
Training loss: 3.630805661038605
Validation loss: 2.597667042773581

Epoch: 72| Step: 0
Training loss: 3.0052490407918238
Validation loss: 2.5949600605401724

Epoch: 6| Step: 1
Training loss: 3.097543105840741
Validation loss: 2.597794519643226

Epoch: 6| Step: 2
Training loss: 3.1318534467568706
Validation loss: 2.5977024372493447

Epoch: 6| Step: 3
Training loss: 2.1219459353291064
Validation loss: 2.5985058552477303

Epoch: 6| Step: 4
Training loss: 3.14727943647483
Validation loss: 2.6069607682029456

Epoch: 6| Step: 5
Training loss: 2.8177522572439058
Validation loss: 2.6416483832424333

Epoch: 6| Step: 6
Training loss: 3.295857204603192
Validation loss: 2.6500221337423207

Epoch: 6| Step: 7
Training loss: 3.1318625819824653
Validation loss: 2.6831770668037995

Epoch: 6| Step: 8
Training loss: 2.457257913829585
Validation loss: 2.633721934434054

Epoch: 6| Step: 9
Training loss: 3.2015156494406334
Validation loss: 2.592214491341677

Epoch: 6| Step: 10
Training loss: 2.8529226743191853
Validation loss: 2.5813938343428293

Epoch: 6| Step: 11
Training loss: 2.9057994206116753
Validation loss: 2.5841763880916595

Epoch: 6| Step: 12
Training loss: 2.9519369975244247
Validation loss: 2.58641038405111

Epoch: 6| Step: 13
Training loss: 3.1328510082284957
Validation loss: 2.588343225805998

Epoch: 73| Step: 0
Training loss: 3.0616044272580916
Validation loss: 2.589090417172558

Epoch: 6| Step: 1
Training loss: 2.7558379196099607
Validation loss: 2.5888552618224554

Epoch: 6| Step: 2
Training loss: 3.0434425778399983
Validation loss: 2.5908564728732784

Epoch: 6| Step: 3
Training loss: 3.325941058766917
Validation loss: 2.5892379691478835

Epoch: 6| Step: 4
Training loss: 3.383691404840778
Validation loss: 2.5876669312049994

Epoch: 6| Step: 5
Training loss: 3.0821197458381704
Validation loss: 2.5853626293929515

Epoch: 6| Step: 6
Training loss: 2.2101969742486816
Validation loss: 2.5847967467209454

Epoch: 6| Step: 7
Training loss: 3.190332687393276
Validation loss: 2.5816429794080062

Epoch: 6| Step: 8
Training loss: 2.8192789397706597
Validation loss: 2.582046993017051

Epoch: 6| Step: 9
Training loss: 2.8983285888609642
Validation loss: 2.581259168367104

Epoch: 6| Step: 10
Training loss: 2.57471355956111
Validation loss: 2.583425171563022

Epoch: 6| Step: 11
Training loss: 3.286324201568144
Validation loss: 2.5823175303457657

Epoch: 6| Step: 12
Training loss: 2.4903080948034235
Validation loss: 2.5823900082975086

Epoch: 6| Step: 13
Training loss: 2.7334746704156068
Validation loss: 2.5835618272993552

Epoch: 74| Step: 0
Training loss: 2.604392954849372
Validation loss: 2.586654743552545

Epoch: 6| Step: 1
Training loss: 3.0542174463010245
Validation loss: 2.582623165482872

Epoch: 6| Step: 2
Training loss: 2.7977124883628597
Validation loss: 2.580923918440307

Epoch: 6| Step: 3
Training loss: 2.720650545750013
Validation loss: 2.599805276944915

Epoch: 6| Step: 4
Training loss: 3.3082969919766247
Validation loss: 2.626449049258871

Epoch: 6| Step: 5
Training loss: 2.2084972272790315
Validation loss: 2.6498025124428253

Epoch: 6| Step: 6
Training loss: 3.4211307918253273
Validation loss: 2.666300260715477

Epoch: 6| Step: 7
Training loss: 2.6784264625194605
Validation loss: 2.60368051991353

Epoch: 6| Step: 8
Training loss: 3.366194930562827
Validation loss: 2.602026529983676

Epoch: 6| Step: 9
Training loss: 2.8443324571989113
Validation loss: 2.6211331428734277

Epoch: 6| Step: 10
Training loss: 2.9607708161876984
Validation loss: 2.676908215748106

Epoch: 6| Step: 11
Training loss: 3.3455355146282146
Validation loss: 2.669323073665549

Epoch: 6| Step: 12
Training loss: 3.283001096410972
Validation loss: 2.6064334515134617

Epoch: 6| Step: 13
Training loss: 2.6777316148383385
Validation loss: 2.5884539980397006

Epoch: 75| Step: 0
Training loss: 3.2521399275363856
Validation loss: 2.592456686440247

Epoch: 6| Step: 1
Training loss: 2.7618428031113393
Validation loss: 2.633950684959701

Epoch: 6| Step: 2
Training loss: 3.2700078291026426
Validation loss: 2.6058649451039444

Epoch: 6| Step: 3
Training loss: 2.857035028602745
Validation loss: 2.5920509850380227

Epoch: 6| Step: 4
Training loss: 2.9883265672625914
Validation loss: 2.5819617694860977

Epoch: 6| Step: 5
Training loss: 2.7345997745225623
Validation loss: 2.5772255440665512

Epoch: 6| Step: 6
Training loss: 2.8896238500664833
Validation loss: 2.5772722531265058

Epoch: 6| Step: 7
Training loss: 2.574141505562898
Validation loss: 2.576010854024013

Epoch: 6| Step: 8
Training loss: 2.8676764047999703
Validation loss: 2.5820661990501526

Epoch: 6| Step: 9
Training loss: 3.3239910975680163
Validation loss: 2.5953977766918728

Epoch: 6| Step: 10
Training loss: 2.9297421869895928
Validation loss: 2.5918248683981364

Epoch: 6| Step: 11
Training loss: 2.877658112769698
Validation loss: 2.6096497380571133

Epoch: 6| Step: 12
Training loss: 3.124923399940095
Validation loss: 2.5990922019460654

Epoch: 6| Step: 13
Training loss: 2.7209523368230277
Validation loss: 2.606020462938468

Epoch: 76| Step: 0
Training loss: 2.88543482658832
Validation loss: 2.610246897418162

Epoch: 6| Step: 1
Training loss: 2.595134687217564
Validation loss: 2.6144340880108494

Epoch: 6| Step: 2
Training loss: 3.1763915429222127
Validation loss: 2.6831009536483177

Epoch: 6| Step: 3
Training loss: 2.6414094922086173
Validation loss: 2.7327327492640907

Epoch: 6| Step: 4
Training loss: 3.040219594151722
Validation loss: 2.717523020968611

Epoch: 6| Step: 5
Training loss: 2.982119361908888
Validation loss: 2.6266720305870526

Epoch: 6| Step: 6
Training loss: 3.145633935398362
Validation loss: 2.57498129716312

Epoch: 6| Step: 7
Training loss: 3.4153201233266266
Validation loss: 2.5791097083606114

Epoch: 6| Step: 8
Training loss: 3.3037128138388847
Validation loss: 2.5891065014502077

Epoch: 6| Step: 9
Training loss: 2.7044827794214203
Validation loss: 2.5996375978683233

Epoch: 6| Step: 10
Training loss: 2.723156219506586
Validation loss: 2.6088663958513734

Epoch: 6| Step: 11
Training loss: 2.8851365229998485
Validation loss: 2.6109108990653165

Epoch: 6| Step: 12
Training loss: 2.559015090844221
Validation loss: 2.6032723375606186

Epoch: 6| Step: 13
Training loss: 3.352188300904966
Validation loss: 2.598885157717698

Epoch: 77| Step: 0
Training loss: 3.2799728087717037
Validation loss: 2.5875704411881646

Epoch: 6| Step: 1
Training loss: 2.591459802874069
Validation loss: 2.584505845838159

Epoch: 6| Step: 2
Training loss: 3.250929186112813
Validation loss: 2.5812386582402076

Epoch: 6| Step: 3
Training loss: 2.86267399821285
Validation loss: 2.5842277729639953

Epoch: 6| Step: 4
Training loss: 2.8276636579860965
Validation loss: 2.5818967274855984

Epoch: 6| Step: 5
Training loss: 3.263983939299619
Validation loss: 2.5836354362521097

Epoch: 6| Step: 6
Training loss: 2.5242313045849483
Validation loss: 2.5823885559191724

Epoch: 6| Step: 7
Training loss: 2.8876168759955294
Validation loss: 2.578688013197485

Epoch: 6| Step: 8
Training loss: 2.5144786236655206
Validation loss: 2.5697408100775263

Epoch: 6| Step: 9
Training loss: 3.1348657134527844
Validation loss: 2.570017953634964

Epoch: 6| Step: 10
Training loss: 2.628546090699921
Validation loss: 2.570437423842488

Epoch: 6| Step: 11
Training loss: 3.1463084251607936
Validation loss: 2.5844969730376257

Epoch: 6| Step: 12
Training loss: 3.313954735658023
Validation loss: 2.568663384402651

Epoch: 6| Step: 13
Training loss: 2.5597810975004016
Validation loss: 2.5634287149912494

Epoch: 78| Step: 0
Training loss: 2.1128234931604517
Validation loss: 2.564810030042987

Epoch: 6| Step: 1
Training loss: 3.314426653547797
Validation loss: 2.560597548651337

Epoch: 6| Step: 2
Training loss: 3.3737835987929596
Validation loss: 2.566925620601392

Epoch: 6| Step: 3
Training loss: 2.9394404718373845
Validation loss: 2.566557100826328

Epoch: 6| Step: 4
Training loss: 2.8809303818050043
Validation loss: 2.5628319432006266

Epoch: 6| Step: 5
Training loss: 2.298158870693297
Validation loss: 2.5638905995641443

Epoch: 6| Step: 6
Training loss: 2.72472269239601
Validation loss: 2.5629618578900337

Epoch: 6| Step: 7
Training loss: 3.6201274615446333
Validation loss: 2.5677413445755866

Epoch: 6| Step: 8
Training loss: 3.258134931164652
Validation loss: 2.56796369576792

Epoch: 6| Step: 9
Training loss: 3.3894538790587787
Validation loss: 2.576611237717414

Epoch: 6| Step: 10
Training loss: 2.111268048838861
Validation loss: 2.585367913613753

Epoch: 6| Step: 11
Training loss: 2.8028022571809963
Validation loss: 2.5938410915327443

Epoch: 6| Step: 12
Training loss: 2.469854663017037
Validation loss: 2.600721628431176

Epoch: 6| Step: 13
Training loss: 3.378248558643163
Validation loss: 2.5890033886452484

Epoch: 79| Step: 0
Training loss: 1.9127769045360437
Validation loss: 2.5974744774018728

Epoch: 6| Step: 1
Training loss: 3.1294133874280754
Validation loss: 2.5932745509507362

Epoch: 6| Step: 2
Training loss: 3.239111928383261
Validation loss: 2.600049831411378

Epoch: 6| Step: 3
Training loss: 2.7094338944137837
Validation loss: 2.6029620613898263

Epoch: 6| Step: 4
Training loss: 3.1279088024689115
Validation loss: 2.58668669551683

Epoch: 6| Step: 5
Training loss: 2.503414778300946
Validation loss: 2.589448327143614

Epoch: 6| Step: 6
Training loss: 3.292523300795197
Validation loss: 2.586610104890515

Epoch: 6| Step: 7
Training loss: 2.976803907482163
Validation loss: 2.567619418205305

Epoch: 6| Step: 8
Training loss: 3.0492112812768832
Validation loss: 2.5680278937072956

Epoch: 6| Step: 9
Training loss: 2.794195329985765
Validation loss: 2.5615233644396618

Epoch: 6| Step: 10
Training loss: 3.3206195285435407
Validation loss: 2.5553416982202397

Epoch: 6| Step: 11
Training loss: 2.76233602529089
Validation loss: 2.5523823371870944

Epoch: 6| Step: 12
Training loss: 2.493071109459923
Validation loss: 2.55313455923259

Epoch: 6| Step: 13
Training loss: 3.3047808550551374
Validation loss: 2.5482930309256804

Epoch: 80| Step: 0
Training loss: 2.0412036863867478
Validation loss: 2.5530410001099955

Epoch: 6| Step: 1
Training loss: 2.463090711508388
Validation loss: 2.5543737330140845

Epoch: 6| Step: 2
Training loss: 2.8979717199131714
Validation loss: 2.5556948942452324

Epoch: 6| Step: 3
Training loss: 2.369020866266722
Validation loss: 2.5533038423841523

Epoch: 6| Step: 4
Training loss: 3.04448759005093
Validation loss: 2.5552519631622195

Epoch: 6| Step: 5
Training loss: 2.907678560659961
Validation loss: 2.555030447755581

Epoch: 6| Step: 6
Training loss: 3.061787113595505
Validation loss: 2.5502422748093627

Epoch: 6| Step: 7
Training loss: 2.7598613444343414
Validation loss: 2.550312276704698

Epoch: 6| Step: 8
Training loss: 3.308535092316883
Validation loss: 2.549868959570178

Epoch: 6| Step: 9
Training loss: 3.1756749434467544
Validation loss: 2.555835552341867

Epoch: 6| Step: 10
Training loss: 2.5497348385743557
Validation loss: 2.553100510470979

Epoch: 6| Step: 11
Training loss: 2.8812865480434318
Validation loss: 2.560159320010783

Epoch: 6| Step: 12
Training loss: 3.365871375796794
Validation loss: 2.558521119487821

Epoch: 6| Step: 13
Training loss: 3.8731437667138406
Validation loss: 2.5609609892998084

Epoch: 81| Step: 0
Training loss: 2.4570729747922813
Validation loss: 2.600253508666556

Epoch: 6| Step: 1
Training loss: 2.788187782044221
Validation loss: 2.6019017798565653

Epoch: 6| Step: 2
Training loss: 2.934092391667617
Validation loss: 2.5773863190673465

Epoch: 6| Step: 3
Training loss: 3.241272578927635
Validation loss: 2.573451875583895

Epoch: 6| Step: 4
Training loss: 3.4007047259438212
Validation loss: 2.558463982249689

Epoch: 6| Step: 5
Training loss: 3.075328660474207
Validation loss: 2.5600163278456374

Epoch: 6| Step: 6
Training loss: 3.1249758910202825
Validation loss: 2.5536116018205752

Epoch: 6| Step: 7
Training loss: 3.014226717749289
Validation loss: 2.5462795728936225

Epoch: 6| Step: 8
Training loss: 3.417379692544084
Validation loss: 2.5473221673755058

Epoch: 6| Step: 9
Training loss: 2.0493877799289164
Validation loss: 2.5440913588498364

Epoch: 6| Step: 10
Training loss: 2.388923488287527
Validation loss: 2.5482003307869254

Epoch: 6| Step: 11
Training loss: 3.435421818316229
Validation loss: 2.5517194303059867

Epoch: 6| Step: 12
Training loss: 2.143721742137921
Validation loss: 2.549130390647438

Epoch: 6| Step: 13
Training loss: 2.838097456492005
Validation loss: 2.55364425033458

Epoch: 82| Step: 0
Training loss: 3.0459007857577514
Validation loss: 2.5533050115982454

Epoch: 6| Step: 1
Training loss: 2.8930066993443297
Validation loss: 2.559353340829864

Epoch: 6| Step: 2
Training loss: 3.048687674435491
Validation loss: 2.5587965993119943

Epoch: 6| Step: 3
Training loss: 3.252382725471333
Validation loss: 2.5594331961318613

Epoch: 6| Step: 4
Training loss: 2.4948775264058827
Validation loss: 2.5509278491592036

Epoch: 6| Step: 5
Training loss: 2.9967708692867014
Validation loss: 2.548288029478919

Epoch: 6| Step: 6
Training loss: 2.7731378097874533
Validation loss: 2.5440668634408237

Epoch: 6| Step: 7
Training loss: 2.993525830757781
Validation loss: 2.545721372974116

Epoch: 6| Step: 8
Training loss: 2.6268363160891197
Validation loss: 2.5429556634433057

Epoch: 6| Step: 9
Training loss: 2.684560365682737
Validation loss: 2.542450889937262

Epoch: 6| Step: 10
Training loss: 3.3558870882993164
Validation loss: 2.543045673114556

Epoch: 6| Step: 11
Training loss: 2.493906223690754
Validation loss: 2.5432709781985756

Epoch: 6| Step: 12
Training loss: 2.400916492787822
Validation loss: 2.544385474282731

Epoch: 6| Step: 13
Training loss: 3.6473162151258722
Validation loss: 2.5477148156498366

Epoch: 83| Step: 0
Training loss: 2.9744638168178468
Validation loss: 2.554456219855798

Epoch: 6| Step: 1
Training loss: 2.807622792113971
Validation loss: 2.565277517176777

Epoch: 6| Step: 2
Training loss: 3.05525362276225
Validation loss: 2.5927712661736853

Epoch: 6| Step: 3
Training loss: 3.2972335258903596
Validation loss: 2.551586335948007

Epoch: 6| Step: 4
Training loss: 2.793114291580511
Validation loss: 2.5384895025234657

Epoch: 6| Step: 5
Training loss: 2.6945925428277264
Validation loss: 2.5417971460696624

Epoch: 6| Step: 6
Training loss: 2.723744507390612
Validation loss: 2.554008780828916

Epoch: 6| Step: 7
Training loss: 3.1454106398468418
Validation loss: 2.556659054254765

Epoch: 6| Step: 8
Training loss: 2.805880662024004
Validation loss: 2.557508987994602

Epoch: 6| Step: 9
Training loss: 2.5496624629702156
Validation loss: 2.5563960806090353

Epoch: 6| Step: 10
Training loss: 3.445223091332091
Validation loss: 2.557765843467301

Epoch: 6| Step: 11
Training loss: 3.185868537609206
Validation loss: 2.5588244437732945

Epoch: 6| Step: 12
Training loss: 2.7764408666687643
Validation loss: 2.5601397663832137

Epoch: 6| Step: 13
Training loss: 2.208752418434706
Validation loss: 2.563397526223346

Epoch: 84| Step: 0
Training loss: 3.112864620805238
Validation loss: 2.562169059394682

Epoch: 6| Step: 1
Training loss: 1.9746685377666324
Validation loss: 2.566808188885885

Epoch: 6| Step: 2
Training loss: 3.312437668699744
Validation loss: 2.5772115123830104

Epoch: 6| Step: 3
Training loss: 2.8578091695942356
Validation loss: 2.556720754541121

Epoch: 6| Step: 4
Training loss: 2.7352107051603056
Validation loss: 2.5495956206430646

Epoch: 6| Step: 5
Training loss: 2.915318767987805
Validation loss: 2.5445436232403136

Epoch: 6| Step: 6
Training loss: 2.653877635012103
Validation loss: 2.540251655877663

Epoch: 6| Step: 7
Training loss: 3.2408197298464945
Validation loss: 2.542020298728785

Epoch: 6| Step: 8
Training loss: 3.3411866817618576
Validation loss: 2.548698049132099

Epoch: 6| Step: 9
Training loss: 3.202358247119692
Validation loss: 2.5613011512866843

Epoch: 6| Step: 10
Training loss: 2.9588499737422067
Validation loss: 2.5718233268922646

Epoch: 6| Step: 11
Training loss: 2.697157253378209
Validation loss: 2.587560651053581

Epoch: 6| Step: 12
Training loss: 2.8713798951264233
Validation loss: 2.6070613083151155

Epoch: 6| Step: 13
Training loss: 2.578899105493171
Validation loss: 2.6165903315302

Epoch: 85| Step: 0
Training loss: 2.896043801835262
Validation loss: 2.6382232435465665

Epoch: 6| Step: 1
Training loss: 3.1995068468132986
Validation loss: 2.6387217245459493

Epoch: 6| Step: 2
Training loss: 2.875987671084234
Validation loss: 2.657426542415739

Epoch: 6| Step: 3
Training loss: 3.700431391337317
Validation loss: 2.704368432879739

Epoch: 6| Step: 4
Training loss: 3.214097892481057
Validation loss: 2.6903051573197354

Epoch: 6| Step: 5
Training loss: 2.7683466219214683
Validation loss: 2.621750079155185

Epoch: 6| Step: 6
Training loss: 2.629432024816828
Validation loss: 2.5908092947859527

Epoch: 6| Step: 7
Training loss: 2.972596256888871
Validation loss: 2.5972443640132536

Epoch: 6| Step: 8
Training loss: 3.1185767727677454
Validation loss: 2.574009590503251

Epoch: 6| Step: 9
Training loss: 2.971895017666794
Validation loss: 2.5732754477154245

Epoch: 6| Step: 10
Training loss: 2.5571564575832215
Validation loss: 2.568627525407702

Epoch: 6| Step: 11
Training loss: 2.216800746830319
Validation loss: 2.565246309912637

Epoch: 6| Step: 12
Training loss: 2.654612676094765
Validation loss: 2.5552452873089893

Epoch: 6| Step: 13
Training loss: 3.1301977037872417
Validation loss: 2.552176542172584

Epoch: 86| Step: 0
Training loss: 3.478419941395272
Validation loss: 2.5520269779883376

Epoch: 6| Step: 1
Training loss: 2.7218981526175177
Validation loss: 2.54559395317225

Epoch: 6| Step: 2
Training loss: 2.260350263004033
Validation loss: 2.5422824925193734

Epoch: 6| Step: 3
Training loss: 3.7596735479796553
Validation loss: 2.5445985528320807

Epoch: 6| Step: 4
Training loss: 3.4238965059753736
Validation loss: 2.5395508857317854

Epoch: 6| Step: 5
Training loss: 3.0895401797085746
Validation loss: 2.5378514180533274

Epoch: 6| Step: 6
Training loss: 2.9407426508557344
Validation loss: 2.537908661258389

Epoch: 6| Step: 7
Training loss: 2.6337595518253094
Validation loss: 2.5403276107147104

Epoch: 6| Step: 8
Training loss: 2.4283963909702315
Validation loss: 2.5377897822807416

Epoch: 6| Step: 9
Training loss: 2.4609487381935855
Validation loss: 2.5399698009234717

Epoch: 6| Step: 10
Training loss: 2.688932170291892
Validation loss: 2.544223015932328

Epoch: 6| Step: 11
Training loss: 2.831953123922384
Validation loss: 2.5443741834539657

Epoch: 6| Step: 12
Training loss: 2.8468875553930397
Validation loss: 2.5435266463864474

Epoch: 6| Step: 13
Training loss: 2.5002452730024105
Validation loss: 2.5535654167271793

Epoch: 87| Step: 0
Training loss: 2.505062128084644
Validation loss: 2.5638979103408936

Epoch: 6| Step: 1
Training loss: 2.669621638374554
Validation loss: 2.5889114248174616

Epoch: 6| Step: 2
Training loss: 2.6605736941300786
Validation loss: 2.6368600920633494

Epoch: 6| Step: 3
Training loss: 2.637598232952957
Validation loss: 2.6451940015182873

Epoch: 6| Step: 4
Training loss: 3.1693893239113806
Validation loss: 2.641110886128904

Epoch: 6| Step: 5
Training loss: 2.965892983037084
Validation loss: 2.650441686637566

Epoch: 6| Step: 6
Training loss: 3.694978017367373
Validation loss: 2.637715302966879

Epoch: 6| Step: 7
Training loss: 3.425410704108529
Validation loss: 2.5660353293099507

Epoch: 6| Step: 8
Training loss: 3.1125852029314496
Validation loss: 2.532616763205439

Epoch: 6| Step: 9
Training loss: 2.538271455050209
Validation loss: 2.5309696779098387

Epoch: 6| Step: 10
Training loss: 2.4347320882371637
Validation loss: 2.534839274517453

Epoch: 6| Step: 11
Training loss: 3.282928909205984
Validation loss: 2.5373025367648747

Epoch: 6| Step: 12
Training loss: 2.101234155126556
Validation loss: 2.5415506802108405

Epoch: 6| Step: 13
Training loss: 3.3638735436837557
Validation loss: 2.54627257046336

Epoch: 88| Step: 0
Training loss: 3.577832339116266
Validation loss: 2.54985267805546

Epoch: 6| Step: 1
Training loss: 2.6638453778251563
Validation loss: 2.5530090136591843

Epoch: 6| Step: 2
Training loss: 2.678958359882052
Validation loss: 2.5536004090095528

Epoch: 6| Step: 3
Training loss: 2.250910468796482
Validation loss: 2.5534729059868044

Epoch: 6| Step: 4
Training loss: 2.9272225958841074
Validation loss: 2.549446081022463

Epoch: 6| Step: 5
Training loss: 3.342997528686888
Validation loss: 2.5440797749898794

Epoch: 6| Step: 6
Training loss: 2.973317698051273
Validation loss: 2.5446056344225862

Epoch: 6| Step: 7
Training loss: 2.7901238310757495
Validation loss: 2.5421264245389477

Epoch: 6| Step: 8
Training loss: 2.881045743442069
Validation loss: 2.537375250776278

Epoch: 6| Step: 9
Training loss: 2.9574601581692024
Validation loss: 2.531786663368277

Epoch: 6| Step: 10
Training loss: 3.3440781191685773
Validation loss: 2.5319279489895328

Epoch: 6| Step: 11
Training loss: 2.9617553225678988
Validation loss: 2.5243225059472985

Epoch: 6| Step: 12
Training loss: 2.6451265687712064
Validation loss: 2.5207728591644347

Epoch: 6| Step: 13
Training loss: 2.690606118732976
Validation loss: 2.5191762880355952

Epoch: 89| Step: 0
Training loss: 2.85722862523637
Validation loss: 2.5192649858964145

Epoch: 6| Step: 1
Training loss: 2.9991391854291556
Validation loss: 2.5172771423917357

Epoch: 6| Step: 2
Training loss: 2.9458578803853084
Validation loss: 2.5249184546455776

Epoch: 6| Step: 3
Training loss: 2.6135875938599815
Validation loss: 2.543016657856791

Epoch: 6| Step: 4
Training loss: 2.7610204264304197
Validation loss: 2.561935102423731

Epoch: 6| Step: 5
Training loss: 2.5232121511644507
Validation loss: 2.595789431148681

Epoch: 6| Step: 6
Training loss: 3.3543862849458486
Validation loss: 2.658202611925233

Epoch: 6| Step: 7
Training loss: 3.056914549427249
Validation loss: 2.6804065617952504

Epoch: 6| Step: 8
Training loss: 2.977082454893936
Validation loss: 2.661875855774431

Epoch: 6| Step: 9
Training loss: 3.0451501903858267
Validation loss: 2.6723119688675276

Epoch: 6| Step: 10
Training loss: 3.189011458530935
Validation loss: 2.63863324141563

Epoch: 6| Step: 11
Training loss: 2.4488618581556594
Validation loss: 2.586932508971549

Epoch: 6| Step: 12
Training loss: 2.9402261623664696
Validation loss: 2.5644998827547556

Epoch: 6| Step: 13
Training loss: 3.31891715855438
Validation loss: 2.5654831456365526

Epoch: 90| Step: 0
Training loss: 3.2273879207708664
Validation loss: 2.5666824861184674

Epoch: 6| Step: 1
Training loss: 2.58993157285342
Validation loss: 2.5700857959725494

Epoch: 6| Step: 2
Training loss: 2.5157675376932063
Validation loss: 2.5812442260143675

Epoch: 6| Step: 3
Training loss: 3.1927626305962726
Validation loss: 2.5816026845490523

Epoch: 6| Step: 4
Training loss: 3.3762512713207125
Validation loss: 2.592638128558361

Epoch: 6| Step: 5
Training loss: 2.6977127665839427
Validation loss: 2.5871408798565434

Epoch: 6| Step: 6
Training loss: 2.9599385451045936
Validation loss: 2.5939309059190454

Epoch: 6| Step: 7
Training loss: 3.0961755049194455
Validation loss: 2.5936509059217845

Epoch: 6| Step: 8
Training loss: 3.466138251697819
Validation loss: 2.5904014312511405

Epoch: 6| Step: 9
Training loss: 2.7104493506941285
Validation loss: 2.5833703163138133

Epoch: 6| Step: 10
Training loss: 2.9940990586950873
Validation loss: 2.5826812487461677

Epoch: 6| Step: 11
Training loss: 2.900664509900968
Validation loss: 2.5819377371214625

Epoch: 6| Step: 12
Training loss: 2.7045795738685
Validation loss: 2.5802716905932686

Epoch: 6| Step: 13
Training loss: 2.546743377841703
Validation loss: 2.5792844778398982

Epoch: 91| Step: 0
Training loss: 2.7297654890286003
Validation loss: 2.5801551181808127

Epoch: 6| Step: 1
Training loss: 2.9010098704998906
Validation loss: 2.5817217932515897

Epoch: 6| Step: 2
Training loss: 2.8719484471340366
Validation loss: 2.586845832998037

Epoch: 6| Step: 3
Training loss: 2.4936994313249308
Validation loss: 2.588429679304304

Epoch: 6| Step: 4
Training loss: 2.9700834793021285
Validation loss: 2.5914867879058576

Epoch: 6| Step: 5
Training loss: 3.047985637420697
Validation loss: 2.5898665983637765

Epoch: 6| Step: 6
Training loss: 3.020004965670716
Validation loss: 2.5787070106210592

Epoch: 6| Step: 7
Training loss: 3.459168819634204
Validation loss: 2.578367464628308

Epoch: 6| Step: 8
Training loss: 2.7992003593298502
Validation loss: 2.570026482404591

Epoch: 6| Step: 9
Training loss: 2.9231654290842757
Validation loss: 2.5696285716914553

Epoch: 6| Step: 10
Training loss: 2.8628497247406743
Validation loss: 2.570229816849211

Epoch: 6| Step: 11
Training loss: 2.938453519559036
Validation loss: 2.5720050982657896

Epoch: 6| Step: 12
Training loss: 3.3091554851690503
Validation loss: 2.581600065895212

Epoch: 6| Step: 13
Training loss: 2.361226851923876
Validation loss: 2.5939240607874234

Epoch: 92| Step: 0
Training loss: 3.2767414908210957
Validation loss: 2.614277763504625

Epoch: 6| Step: 1
Training loss: 3.48000701684354
Validation loss: 2.627914991005512

Epoch: 6| Step: 2
Training loss: 3.4503289549637057
Validation loss: 2.623475771473019

Epoch: 6| Step: 3
Training loss: 2.186563127710335
Validation loss: 2.6064369678162023

Epoch: 6| Step: 4
Training loss: 2.880710569514914
Validation loss: 2.589944923899497

Epoch: 6| Step: 5
Training loss: 2.2808537596332763
Validation loss: 2.5790500088936046

Epoch: 6| Step: 6
Training loss: 2.9146367956842987
Validation loss: 2.5768373368108324

Epoch: 6| Step: 7
Training loss: 2.730060421341404
Validation loss: 2.58443456102691

Epoch: 6| Step: 8
Training loss: 2.628173272486733
Validation loss: 2.587131291235076

Epoch: 6| Step: 9
Training loss: 3.224578469103483
Validation loss: 2.6002385394077208

Epoch: 6| Step: 10
Training loss: 2.8435856698313
Validation loss: 2.5759980010108525

Epoch: 6| Step: 11
Training loss: 2.595837775441426
Validation loss: 2.5688274646816596

Epoch: 6| Step: 12
Training loss: 3.0153239203652005
Validation loss: 2.5604820819900485

Epoch: 6| Step: 13
Training loss: 3.0245587933565146
Validation loss: 2.559895894756389

Epoch: 93| Step: 0
Training loss: 2.549471789236698
Validation loss: 2.5552149196819607

Epoch: 6| Step: 1
Training loss: 2.6938592946124564
Validation loss: 2.5556332965895994

Epoch: 6| Step: 2
Training loss: 3.356564361796206
Validation loss: 2.5601359061087745

Epoch: 6| Step: 3
Training loss: 2.938509990670611
Validation loss: 2.559879942404965

Epoch: 6| Step: 4
Training loss: 3.207939437532368
Validation loss: 2.558446831560645

Epoch: 6| Step: 5
Training loss: 3.324867911332361
Validation loss: 2.5613553852049047

Epoch: 6| Step: 6
Training loss: 2.332071735279859
Validation loss: 2.5535152972656032

Epoch: 6| Step: 7
Training loss: 3.0517915623133782
Validation loss: 2.5605017441395534

Epoch: 6| Step: 8
Training loss: 2.058544411692317
Validation loss: 2.549921173527729

Epoch: 6| Step: 9
Training loss: 2.476992596845841
Validation loss: 2.537525263317608

Epoch: 6| Step: 10
Training loss: 2.878063725617593
Validation loss: 2.530051450607075

Epoch: 6| Step: 11
Training loss: 2.9554468140480052
Validation loss: 2.5229326827284693

Epoch: 6| Step: 12
Training loss: 3.3565892223931337
Validation loss: 2.508568856522569

Epoch: 6| Step: 13
Training loss: 2.918109282718636
Validation loss: 2.505738747365705

Epoch: 94| Step: 0
Training loss: 2.9092395132212965
Validation loss: 2.5043109794953997

Epoch: 6| Step: 1
Training loss: 2.477452452171584
Validation loss: 2.5054219220331504

Epoch: 6| Step: 2
Training loss: 2.8451243003682456
Validation loss: 2.50284739537531

Epoch: 6| Step: 3
Training loss: 2.6393103402428895
Validation loss: 2.503666187661699

Epoch: 6| Step: 4
Training loss: 2.9206827760676046
Validation loss: 2.501705513909193

Epoch: 6| Step: 5
Training loss: 2.871580993413454
Validation loss: 2.503490355674497

Epoch: 6| Step: 6
Training loss: 2.9244807247022973
Validation loss: 2.4999697534720835

Epoch: 6| Step: 7
Training loss: 2.6523575929890044
Validation loss: 2.503346395928599

Epoch: 6| Step: 8
Training loss: 2.893895788619242
Validation loss: 2.504723199246515

Epoch: 6| Step: 9
Training loss: 2.93888530126047
Validation loss: 2.505336117017696

Epoch: 6| Step: 10
Training loss: 3.4285528091651694
Validation loss: 2.5065248025460822

Epoch: 6| Step: 11
Training loss: 3.32514885017099
Validation loss: 2.5177002116999123

Epoch: 6| Step: 12
Training loss: 2.6335084261407253
Validation loss: 2.5274773135584625

Epoch: 6| Step: 13
Training loss: 2.4474145793717774
Validation loss: 2.529585179048247

Epoch: 95| Step: 0
Training loss: 2.547668520638477
Validation loss: 2.5403108542816732

Epoch: 6| Step: 1
Training loss: 3.215055400792275
Validation loss: 2.55524868844469

Epoch: 6| Step: 2
Training loss: 3.3561368727842886
Validation loss: 2.5622871844791875

Epoch: 6| Step: 3
Training loss: 3.1162781117896925
Validation loss: 2.5749171381774985

Epoch: 6| Step: 4
Training loss: 2.9684433628132405
Validation loss: 2.5782355609553913

Epoch: 6| Step: 5
Training loss: 2.829100382669326
Validation loss: 2.580589798203986

Epoch: 6| Step: 6
Training loss: 2.905566227368348
Validation loss: 2.5887007498648704

Epoch: 6| Step: 7
Training loss: 2.924382240725067
Validation loss: 2.565834477057777

Epoch: 6| Step: 8
Training loss: 3.040249080492509
Validation loss: 2.5535186053289745

Epoch: 6| Step: 9
Training loss: 2.4729304590994854
Validation loss: 2.5360575225343007

Epoch: 6| Step: 10
Training loss: 2.6731718608039023
Validation loss: 2.5112911633505726

Epoch: 6| Step: 11
Training loss: 2.51077523315476
Validation loss: 2.5023521576540007

Epoch: 6| Step: 12
Training loss: 2.9515050249375223
Validation loss: 2.4999863562673075

Epoch: 6| Step: 13
Training loss: 2.4709675161155484
Validation loss: 2.499743040271637

Epoch: 96| Step: 0
Training loss: 3.808487203036896
Validation loss: 2.504554761691279

Epoch: 6| Step: 1
Training loss: 2.8184857568142414
Validation loss: 2.50589657415259

Epoch: 6| Step: 2
Training loss: 3.181385533531557
Validation loss: 2.5108973382021293

Epoch: 6| Step: 3
Training loss: 2.921229000383343
Validation loss: 2.510130802204774

Epoch: 6| Step: 4
Training loss: 2.8572503205934283
Validation loss: 2.5076567433725456

Epoch: 6| Step: 5
Training loss: 2.792361063971576
Validation loss: 2.509641362609324

Epoch: 6| Step: 6
Training loss: 2.163171577911049
Validation loss: 2.505998842632714

Epoch: 6| Step: 7
Training loss: 2.95657841025671
Validation loss: 2.508231906055082

Epoch: 6| Step: 8
Training loss: 2.5100304608567425
Validation loss: 2.5104659231448845

Epoch: 6| Step: 9
Training loss: 2.314385856584411
Validation loss: 2.5112525250666935

Epoch: 6| Step: 10
Training loss: 3.1601047959636035
Validation loss: 2.507379465275022

Epoch: 6| Step: 11
Training loss: 2.936094231759014
Validation loss: 2.518365635734925

Epoch: 6| Step: 12
Training loss: 2.9711252448082552
Validation loss: 2.5236009764330447

Epoch: 6| Step: 13
Training loss: 2.453000593979239
Validation loss: 2.524682483591066

Epoch: 97| Step: 0
Training loss: 3.371368149499976
Validation loss: 2.5356040372172086

Epoch: 6| Step: 1
Training loss: 3.170610899439881
Validation loss: 2.540143130465741

Epoch: 6| Step: 2
Training loss: 2.6959436534573915
Validation loss: 2.515495691865818

Epoch: 6| Step: 3
Training loss: 2.7716751731914826
Validation loss: 2.5144053708766556

Epoch: 6| Step: 4
Training loss: 2.509787094083758
Validation loss: 2.5062451508811936

Epoch: 6| Step: 5
Training loss: 2.8445007674614655
Validation loss: 2.5088829833061346

Epoch: 6| Step: 6
Training loss: 2.2034424897979905
Validation loss: 2.510836656033753

Epoch: 6| Step: 7
Training loss: 3.199126935114119
Validation loss: 2.5063627377513753

Epoch: 6| Step: 8
Training loss: 3.3159262733316157
Validation loss: 2.508967850610353

Epoch: 6| Step: 9
Training loss: 2.81345342794094
Validation loss: 2.510762738979147

Epoch: 6| Step: 10
Training loss: 2.9719147528106578
Validation loss: 2.51313337639054

Epoch: 6| Step: 11
Training loss: 2.8258665561851073
Validation loss: 2.5095268254969736

Epoch: 6| Step: 12
Training loss: 2.966575549008667
Validation loss: 2.510892732440939

Epoch: 6| Step: 13
Training loss: 2.331936986094757
Validation loss: 2.5110584375323266

Epoch: 98| Step: 0
Training loss: 3.140500346124998
Validation loss: 2.515047558799002

Epoch: 6| Step: 1
Training loss: 2.2182729503725946
Validation loss: 2.5102748395925167

Epoch: 6| Step: 2
Training loss: 3.0853400702352123
Validation loss: 2.515202509156087

Epoch: 6| Step: 3
Training loss: 3.1238359953731196
Validation loss: 2.5184083527804915

Epoch: 6| Step: 4
Training loss: 2.6636661894782776
Validation loss: 2.5194178992075797

Epoch: 6| Step: 5
Training loss: 3.1108555934820465
Validation loss: 2.519475383668596

Epoch: 6| Step: 6
Training loss: 3.020062596007121
Validation loss: 2.5214793290194137

Epoch: 6| Step: 7
Training loss: 2.625809862457077
Validation loss: 2.5207387455078254

Epoch: 6| Step: 8
Training loss: 2.4990251547839937
Validation loss: 2.5269601126283807

Epoch: 6| Step: 9
Training loss: 2.83319261612857
Validation loss: 2.535255064009399

Epoch: 6| Step: 10
Training loss: 2.759471016376539
Validation loss: 2.5360641771247474

Epoch: 6| Step: 11
Training loss: 3.024505505458912
Validation loss: 2.5448093106251193

Epoch: 6| Step: 12
Training loss: 2.7361672767343688
Validation loss: 2.548074984788243

Epoch: 6| Step: 13
Training loss: 3.6504972145353127
Validation loss: 2.543564924929112

Epoch: 99| Step: 0
Training loss: 3.514094719033045
Validation loss: 2.5528904793476377

Epoch: 6| Step: 1
Training loss: 2.8183756171569407
Validation loss: 2.553826266607803

Epoch: 6| Step: 2
Training loss: 2.6205425564084073
Validation loss: 2.5512000866978033

Epoch: 6| Step: 3
Training loss: 3.1197823262698416
Validation loss: 2.54704064190976

Epoch: 6| Step: 4
Training loss: 2.375197954461054
Validation loss: 2.547251506621324

Epoch: 6| Step: 5
Training loss: 2.2039839781232473
Validation loss: 2.5404829940177143

Epoch: 6| Step: 6
Training loss: 3.633730536514714
Validation loss: 2.5399366698001544

Epoch: 6| Step: 7
Training loss: 3.0682655091864657
Validation loss: 2.5399971926932583

Epoch: 6| Step: 8
Training loss: 3.1321355606791976
Validation loss: 2.5476294006125686

Epoch: 6| Step: 9
Training loss: 2.457244233086898
Validation loss: 2.54536712740354

Epoch: 6| Step: 10
Training loss: 2.995088052872237
Validation loss: 2.5385371040866316

Epoch: 6| Step: 11
Training loss: 3.0985908012535766
Validation loss: 2.5380316033140966

Epoch: 6| Step: 12
Training loss: 2.4390149421625202
Validation loss: 2.5331803201417786

Epoch: 6| Step: 13
Training loss: 2.701924228224155
Validation loss: 2.5361642708546297

Epoch: 100| Step: 0
Training loss: 2.637286451472028
Validation loss: 2.5426630427055104

Epoch: 6| Step: 1
Training loss: 3.1339071363896793
Validation loss: 2.5473432132534835

Epoch: 6| Step: 2
Training loss: 3.120626822863978
Validation loss: 2.5493997852707135

Epoch: 6| Step: 3
Training loss: 2.9394347941185073
Validation loss: 2.5364574614216315

Epoch: 6| Step: 4
Training loss: 2.7126114044516734
Validation loss: 2.5352999192709333

Epoch: 6| Step: 5
Training loss: 2.718312195353258
Validation loss: 2.5347717550774695

Epoch: 6| Step: 6
Training loss: 3.0071947924967435
Validation loss: 2.530104644002664

Epoch: 6| Step: 7
Training loss: 2.973336942639177
Validation loss: 2.5446398986047516

Epoch: 6| Step: 8
Training loss: 3.0672222242367053
Validation loss: 2.545949913231506

Epoch: 6| Step: 9
Training loss: 3.229861588716022
Validation loss: 2.5438079313802953

Epoch: 6| Step: 10
Training loss: 2.507270160155435
Validation loss: 2.5481400017269813

Epoch: 6| Step: 11
Training loss: 2.9053697791274
Validation loss: 2.5496416805705766

Epoch: 6| Step: 12
Training loss: 2.6841037493294304
Validation loss: 2.548526996417663

Epoch: 6| Step: 13
Training loss: 2.468512608184357
Validation loss: 2.5319304256247506

Epoch: 101| Step: 0
Training loss: 3.507710274818933
Validation loss: 2.5317680064832273

Epoch: 6| Step: 1
Training loss: 2.7358786671934126
Validation loss: 2.5235320591370325

Epoch: 6| Step: 2
Training loss: 2.7481537603591564
Validation loss: 2.519473090664728

Epoch: 6| Step: 3
Training loss: 3.136069414664827
Validation loss: 2.5233098764242707

Epoch: 6| Step: 4
Training loss: 2.9278561984744593
Validation loss: 2.5104668718220515

Epoch: 6| Step: 5
Training loss: 2.6710366166267434
Validation loss: 2.5122547721171276

Epoch: 6| Step: 6
Training loss: 2.9519143827267786
Validation loss: 2.5082451196095215

Epoch: 6| Step: 7
Training loss: 2.4068949441967553
Validation loss: 2.5105204740525804

Epoch: 6| Step: 8
Training loss: 2.9291285274043046
Validation loss: 2.5102853993878025

Epoch: 6| Step: 9
Training loss: 2.381220451431969
Validation loss: 2.5083857535914587

Epoch: 6| Step: 10
Training loss: 3.249858266234137
Validation loss: 2.5064620353760874

Epoch: 6| Step: 11
Training loss: 2.6836408363886757
Validation loss: 2.5160263618775733

Epoch: 6| Step: 12
Training loss: 2.815092544931612
Validation loss: 2.515793825452691

Epoch: 6| Step: 13
Training loss: 2.879451622412328
Validation loss: 2.5094549748531625

Epoch: 102| Step: 0
Training loss: 3.179821864482938
Validation loss: 2.5029596140315618

Epoch: 6| Step: 1
Training loss: 2.6303608060146644
Validation loss: 2.5057105575203598

Epoch: 6| Step: 2
Training loss: 2.8690189675960287
Validation loss: 2.5044306829664733

Epoch: 6| Step: 3
Training loss: 1.9147184532506354
Validation loss: 2.5089050617927957

Epoch: 6| Step: 4
Training loss: 2.525211242299801
Validation loss: 2.505298865541977

Epoch: 6| Step: 5
Training loss: 3.4100470421642206
Validation loss: 2.509736372081857

Epoch: 6| Step: 6
Training loss: 3.3122266260739384
Validation loss: 2.5178232648584897

Epoch: 6| Step: 7
Training loss: 2.4548869031971745
Validation loss: 2.5117394899664633

Epoch: 6| Step: 8
Training loss: 3.061861244072648
Validation loss: 2.5056481106605166

Epoch: 6| Step: 9
Training loss: 2.8773440880714403
Validation loss: 2.5105707012990233

Epoch: 6| Step: 10
Training loss: 3.3731947415294936
Validation loss: 2.505348256065616

Epoch: 6| Step: 11
Training loss: 2.373871987147737
Validation loss: 2.504814999347348

Epoch: 6| Step: 12
Training loss: 2.6466540968409897
Validation loss: 2.504567128691658

Epoch: 6| Step: 13
Training loss: 3.2078432641874466
Validation loss: 2.509633307936991

Epoch: 103| Step: 0
Training loss: 2.9220636480293796
Validation loss: 2.5045351403914813

Epoch: 6| Step: 1
Training loss: 2.5409503198276093
Validation loss: 2.5000202131992397

Epoch: 6| Step: 2
Training loss: 2.546842048291435
Validation loss: 2.4924170887586086

Epoch: 6| Step: 3
Training loss: 2.3235867706967674
Validation loss: 2.492173764120279

Epoch: 6| Step: 4
Training loss: 3.1676565597369195
Validation loss: 2.488269165749464

Epoch: 6| Step: 5
Training loss: 3.0056334690126185
Validation loss: 2.491626223811659

Epoch: 6| Step: 6
Training loss: 2.477386048869218
Validation loss: 2.4913157855947867

Epoch: 6| Step: 7
Training loss: 2.272892103286822
Validation loss: 2.4983918329463295

Epoch: 6| Step: 8
Training loss: 3.511960709736571
Validation loss: 2.493987819917372

Epoch: 6| Step: 9
Training loss: 2.667308809530758
Validation loss: 2.5064955690815394

Epoch: 6| Step: 10
Training loss: 2.802206403069344
Validation loss: 2.510107282172774

Epoch: 6| Step: 11
Training loss: 3.3138714236616114
Validation loss: 2.5132742142216316

Epoch: 6| Step: 12
Training loss: 2.814138147331802
Validation loss: 2.505838100408995

Epoch: 6| Step: 13
Training loss: 3.680477243865902
Validation loss: 2.4986776700276554

Epoch: 104| Step: 0
Training loss: 3.0578178893028642
Validation loss: 2.4823752391028395

Epoch: 6| Step: 1
Training loss: 2.991810747536058
Validation loss: 2.4766706264052742

Epoch: 6| Step: 2
Training loss: 3.128804751689427
Validation loss: 2.470468569112286

Epoch: 6| Step: 3
Training loss: 3.080934433320819
Validation loss: 2.472588595011165

Epoch: 6| Step: 4
Training loss: 2.5529447905162526
Validation loss: 2.474322651504072

Epoch: 6| Step: 5
Training loss: 2.8976450862551193
Validation loss: 2.4702508657324893

Epoch: 6| Step: 6
Training loss: 2.9189472728121553
Validation loss: 2.4746084695551454

Epoch: 6| Step: 7
Training loss: 3.236268894203759
Validation loss: 2.4787468513833364

Epoch: 6| Step: 8
Training loss: 2.426059971029617
Validation loss: 2.4796883260097213

Epoch: 6| Step: 9
Training loss: 2.9042492614414157
Validation loss: 2.48174606249073

Epoch: 6| Step: 10
Training loss: 2.1190330653866987
Validation loss: 2.479350093495791

Epoch: 6| Step: 11
Training loss: 2.453326951965381
Validation loss: 2.482070219061353

Epoch: 6| Step: 12
Training loss: 2.812451256223658
Validation loss: 2.479009183985151

Epoch: 6| Step: 13
Training loss: 3.183380456811988
Validation loss: 2.4893634482963902

Epoch: 105| Step: 0
Training loss: 2.797129614125265
Validation loss: 2.483677848876371

Epoch: 6| Step: 1
Training loss: 3.192361154188155
Validation loss: 2.495421993528058

Epoch: 6| Step: 2
Training loss: 2.4757833609025792
Validation loss: 2.4927389855467115

Epoch: 6| Step: 3
Training loss: 2.984826498180952
Validation loss: 2.495810587589648

Epoch: 6| Step: 4
Training loss: 2.5947302379302157
Validation loss: 2.4941756184291157

Epoch: 6| Step: 5
Training loss: 2.9363626753883065
Validation loss: 2.495225596877753

Epoch: 6| Step: 6
Training loss: 3.135483513982346
Validation loss: 2.488688179584499

Epoch: 6| Step: 7
Training loss: 2.7687348376132346
Validation loss: 2.488951955972016

Epoch: 6| Step: 8
Training loss: 3.0927820714475316
Validation loss: 2.488747690807004

Epoch: 6| Step: 9
Training loss: 2.4578613431603804
Validation loss: 2.5136630091780257

Epoch: 6| Step: 10
Training loss: 2.986142578747765
Validation loss: 2.521279147036479

Epoch: 6| Step: 11
Training loss: 2.491465783925584
Validation loss: 2.530004458478827

Epoch: 6| Step: 12
Training loss: 3.05121542055007
Validation loss: 2.5248338036478692

Epoch: 6| Step: 13
Training loss: 2.5366214227171344
Validation loss: 2.4825261607585096

Epoch: 106| Step: 0
Training loss: 3.5723901625793686
Validation loss: 2.476798207339272

Epoch: 6| Step: 1
Training loss: 2.7696942064905
Validation loss: 2.472154169857792

Epoch: 6| Step: 2
Training loss: 2.245145222612042
Validation loss: 2.4711837931991716

Epoch: 6| Step: 3
Training loss: 3.264690502739014
Validation loss: 2.474610118832024

Epoch: 6| Step: 4
Training loss: 2.6642348605693433
Validation loss: 2.4755584730159708

Epoch: 6| Step: 5
Training loss: 2.2041010216478623
Validation loss: 2.471964168396153

Epoch: 6| Step: 6
Training loss: 2.533938922359763
Validation loss: 2.4759377336889794

Epoch: 6| Step: 7
Training loss: 2.8813178263395094
Validation loss: 2.4800328707675026

Epoch: 6| Step: 8
Training loss: 2.6819956989637874
Validation loss: 2.4777767886690754

Epoch: 6| Step: 9
Training loss: 2.550221684113473
Validation loss: 2.4892472108769916

Epoch: 6| Step: 10
Training loss: 3.2070957786024854
Validation loss: 2.500354743727993

Epoch: 6| Step: 11
Training loss: 2.9847501349225065
Validation loss: 2.5008547967400303

Epoch: 6| Step: 12
Training loss: 3.039209671183454
Validation loss: 2.5046311767391516

Epoch: 6| Step: 13
Training loss: 2.8066219363721907
Validation loss: 2.4978117420643198

Epoch: 107| Step: 0
Training loss: 2.796870055806995
Validation loss: 2.4874635179771025

Epoch: 6| Step: 1
Training loss: 2.3790152889624707
Validation loss: 2.4914930272698927

Epoch: 6| Step: 2
Training loss: 2.493424733300519
Validation loss: 2.4964428277455504

Epoch: 6| Step: 3
Training loss: 3.3559206213128365
Validation loss: 2.48609701440855

Epoch: 6| Step: 4
Training loss: 2.9773005974634557
Validation loss: 2.483808144634042

Epoch: 6| Step: 5
Training loss: 3.012534658145582
Validation loss: 2.4834468194016255

Epoch: 6| Step: 6
Training loss: 2.0351100923718426
Validation loss: 2.4850141895240907

Epoch: 6| Step: 7
Training loss: 2.1004295273154847
Validation loss: 2.495359198786904

Epoch: 6| Step: 8
Training loss: 2.790024022644973
Validation loss: 2.4924767187158126

Epoch: 6| Step: 9
Training loss: 2.793532436015257
Validation loss: 2.5147245019944795

Epoch: 6| Step: 10
Training loss: 3.1646868054515473
Validation loss: 2.512220427990041

Epoch: 6| Step: 11
Training loss: 3.483526152121532
Validation loss: 2.5128774495030783

Epoch: 6| Step: 12
Training loss: 2.914040573078531
Validation loss: 2.500585344966108

Epoch: 6| Step: 13
Training loss: 3.0285342921116305
Validation loss: 2.4720545052752048

Epoch: 108| Step: 0
Training loss: 2.3835180019869577
Validation loss: 2.4701144870232503

Epoch: 6| Step: 1
Training loss: 2.4911500690819515
Validation loss: 2.4591904201625185

Epoch: 6| Step: 2
Training loss: 2.3623237624862883
Validation loss: 2.4632767348817284

Epoch: 6| Step: 3
Training loss: 3.2594733452886926
Validation loss: 2.466947848718414

Epoch: 6| Step: 4
Training loss: 2.4766849523650527
Validation loss: 2.4665510021480688

Epoch: 6| Step: 5
Training loss: 3.2942589961908544
Validation loss: 2.461235133343007

Epoch: 6| Step: 6
Training loss: 2.6893407151299487
Validation loss: 2.472839005535417

Epoch: 6| Step: 7
Training loss: 2.8897238486590355
Validation loss: 2.4806733062323967

Epoch: 6| Step: 8
Training loss: 2.5966631604400714
Validation loss: 2.478741874573738

Epoch: 6| Step: 9
Training loss: 3.1009789982158034
Validation loss: 2.504192179383258

Epoch: 6| Step: 10
Training loss: 3.2125378261372726
Validation loss: 2.5211531275993444

Epoch: 6| Step: 11
Training loss: 3.296839998610856
Validation loss: 2.53335612901536

Epoch: 6| Step: 12
Training loss: 2.5853670995132596
Validation loss: 2.552605140954121

Epoch: 6| Step: 13
Training loss: 2.6611738457272227
Validation loss: 2.5628248009376735

Epoch: 109| Step: 0
Training loss: 2.7407022567525385
Validation loss: 2.5426983695321823

Epoch: 6| Step: 1
Training loss: 3.043852886991098
Validation loss: 2.4838228913071805

Epoch: 6| Step: 2
Training loss: 2.8046682883112033
Validation loss: 2.4575640376940346

Epoch: 6| Step: 3
Training loss: 3.3537859177345575
Validation loss: 2.462669418118006

Epoch: 6| Step: 4
Training loss: 2.181341821874752
Validation loss: 2.4781528722252917

Epoch: 6| Step: 5
Training loss: 3.167623442282041
Validation loss: 2.472361742938604

Epoch: 6| Step: 6
Training loss: 2.6123404641241708
Validation loss: 2.474925228649654

Epoch: 6| Step: 7
Training loss: 2.9115733952496017
Validation loss: 2.4765692243959965

Epoch: 6| Step: 8
Training loss: 3.144936406352281
Validation loss: 2.4758233852448033

Epoch: 6| Step: 9
Training loss: 2.572528845919116
Validation loss: 2.473499660146055

Epoch: 6| Step: 10
Training loss: 3.19261745968672
Validation loss: 2.4630386927239964

Epoch: 6| Step: 11
Training loss: 2.490892797453508
Validation loss: 2.4570098374671434

Epoch: 6| Step: 12
Training loss: 2.91697861955959
Validation loss: 2.4540648349442638

Epoch: 6| Step: 13
Training loss: 2.8208931195803832
Validation loss: 2.4594847365795385

Epoch: 110| Step: 0
Training loss: 2.9554934414652227
Validation loss: 2.4662605019286707

Epoch: 6| Step: 1
Training loss: 3.3666382804152315
Validation loss: 2.4823732892947104

Epoch: 6| Step: 2
Training loss: 2.3658724616365574
Validation loss: 2.5003353119628637

Epoch: 6| Step: 3
Training loss: 3.003772430018681
Validation loss: 2.471059989262197

Epoch: 6| Step: 4
Training loss: 2.8299413085890306
Validation loss: 2.464964641014673

Epoch: 6| Step: 5
Training loss: 3.1298173013814807
Validation loss: 2.4600449247682596

Epoch: 6| Step: 6
Training loss: 2.8428608269267093
Validation loss: 2.4549611988614073

Epoch: 6| Step: 7
Training loss: 2.031743855229226
Validation loss: 2.456590305327666

Epoch: 6| Step: 8
Training loss: 3.103919068431718
Validation loss: 2.456049878688523

Epoch: 6| Step: 9
Training loss: 2.372759716100457
Validation loss: 2.4533862697276954

Epoch: 6| Step: 10
Training loss: 2.484477011067756
Validation loss: 2.459526484374012

Epoch: 6| Step: 11
Training loss: 3.1423403482237102
Validation loss: 2.4611475721873664

Epoch: 6| Step: 12
Training loss: 2.75007880704841
Validation loss: 2.4568016424530814

Epoch: 6| Step: 13
Training loss: 3.0169911822985798
Validation loss: 2.46453345724387

Epoch: 111| Step: 0
Training loss: 1.9843149851937514
Validation loss: 2.4632049776556957

Epoch: 6| Step: 1
Training loss: 2.6858462191122796
Validation loss: 2.4712934241589615

Epoch: 6| Step: 2
Training loss: 3.34310165251636
Validation loss: 2.4792678655863454

Epoch: 6| Step: 3
Training loss: 2.8370945779487284
Validation loss: 2.486648695501767

Epoch: 6| Step: 4
Training loss: 3.0298390988474595
Validation loss: 2.5034314570696035

Epoch: 6| Step: 5
Training loss: 2.9566258262156064
Validation loss: 2.498853123024006

Epoch: 6| Step: 6
Training loss: 2.690470096679294
Validation loss: 2.5038099667332783

Epoch: 6| Step: 7
Training loss: 2.512860028486687
Validation loss: 2.518924516898552

Epoch: 6| Step: 8
Training loss: 2.3405603702927347
Validation loss: 2.514037500452947

Epoch: 6| Step: 9
Training loss: 2.7800173653259206
Validation loss: 2.5033610485004214

Epoch: 6| Step: 10
Training loss: 3.5934817006675055
Validation loss: 2.506318874362523

Epoch: 6| Step: 11
Training loss: 3.200215129773474
Validation loss: 2.4859010438050686

Epoch: 6| Step: 12
Training loss: 2.401453166351712
Validation loss: 2.477204469124602

Epoch: 6| Step: 13
Training loss: 2.5331399714142546
Validation loss: 2.4725754304144067

Epoch: 112| Step: 0
Training loss: 2.9334471319261346
Validation loss: 2.472541317431903

Epoch: 6| Step: 1
Training loss: 2.8067060342173717
Validation loss: 2.467676467477487

Epoch: 6| Step: 2
Training loss: 2.3944642398288374
Validation loss: 2.475723888047605

Epoch: 6| Step: 3
Training loss: 3.1783064858860133
Validation loss: 2.489440510897757

Epoch: 6| Step: 4
Training loss: 3.195001339859898
Validation loss: 2.472507237158224

Epoch: 6| Step: 5
Training loss: 2.750309406560947
Validation loss: 2.480140489260176

Epoch: 6| Step: 6
Training loss: 2.584842784387712
Validation loss: 2.4878770793599836

Epoch: 6| Step: 7
Training loss: 2.2460535195106335
Validation loss: 2.529084380515287

Epoch: 6| Step: 8
Training loss: 3.044394084609814
Validation loss: 2.5428342227111544

Epoch: 6| Step: 9
Training loss: 2.7995350724190082
Validation loss: 2.5236774710055174

Epoch: 6| Step: 10
Training loss: 2.876779586002026
Validation loss: 2.5318104710753366

Epoch: 6| Step: 11
Training loss: 2.5472651457789763
Validation loss: 2.532185646805005

Epoch: 6| Step: 12
Training loss: 3.3897462048796654
Validation loss: 2.489758466863558

Epoch: 6| Step: 13
Training loss: 2.476616025520753
Validation loss: 2.4735745575429293

Epoch: 113| Step: 0
Training loss: 2.19657910281962
Validation loss: 2.4672051722718216

Epoch: 6| Step: 1
Training loss: 2.9967189966992605
Validation loss: 2.4640411270944567

Epoch: 6| Step: 2
Training loss: 2.71371660504556
Validation loss: 2.4578636055068688

Epoch: 6| Step: 3
Training loss: 2.908132784103578
Validation loss: 2.4589060545027945

Epoch: 6| Step: 4
Training loss: 2.6370328588944734
Validation loss: 2.4559482849959124

Epoch: 6| Step: 5
Training loss: 3.0583159221877696
Validation loss: 2.4523222507080527

Epoch: 6| Step: 6
Training loss: 2.1215432043879563
Validation loss: 2.455264045432373

Epoch: 6| Step: 7
Training loss: 2.6610614956040064
Validation loss: 2.45723847719916

Epoch: 6| Step: 8
Training loss: 3.0896920457484165
Validation loss: 2.4617595309516003

Epoch: 6| Step: 9
Training loss: 3.3984711744021294
Validation loss: 2.4636792846889386

Epoch: 6| Step: 10
Training loss: 3.181070762636288
Validation loss: 2.483399437809591

Epoch: 6| Step: 11
Training loss: 2.8250267803982037
Validation loss: 2.4864595583060414

Epoch: 6| Step: 12
Training loss: 2.823477957878455
Validation loss: 2.500478988312267

Epoch: 6| Step: 13
Training loss: 2.647252900981115
Validation loss: 2.5045571231154526

Epoch: 114| Step: 0
Training loss: 2.4827305371515815
Validation loss: 2.488823954606002

Epoch: 6| Step: 1
Training loss: 3.0721338514234713
Validation loss: 2.5097622224939413

Epoch: 6| Step: 2
Training loss: 2.781615672557389
Validation loss: 2.525752099789182

Epoch: 6| Step: 3
Training loss: 2.8818794539348307
Validation loss: 2.530249430928823

Epoch: 6| Step: 4
Training loss: 2.600952443487049
Validation loss: 2.515497632306386

Epoch: 6| Step: 5
Training loss: 2.420956443593342
Validation loss: 2.495938423753625

Epoch: 6| Step: 6
Training loss: 3.250036092704485
Validation loss: 2.487578324826386

Epoch: 6| Step: 7
Training loss: 2.6201723301246393
Validation loss: 2.468398120372738

Epoch: 6| Step: 8
Training loss: 2.8505083199650447
Validation loss: 2.455074287490064

Epoch: 6| Step: 9
Training loss: 2.736888144758376
Validation loss: 2.4467860364930503

Epoch: 6| Step: 10
Training loss: 2.6342275195850045
Validation loss: 2.4404220157784646

Epoch: 6| Step: 11
Training loss: 2.5378617014799336
Validation loss: 2.446606296366635

Epoch: 6| Step: 12
Training loss: 3.2642455769605543
Validation loss: 2.4534406415159165

Epoch: 6| Step: 13
Training loss: 3.237854638430659
Validation loss: 2.4560525247363767

Epoch: 115| Step: 0
Training loss: 3.0684824529739427
Validation loss: 2.4694224519541335

Epoch: 6| Step: 1
Training loss: 2.578404544355724
Validation loss: 2.4654557916348696

Epoch: 6| Step: 2
Training loss: 2.445667472644077
Validation loss: 2.4688178588297065

Epoch: 6| Step: 3
Training loss: 2.36332241054032
Validation loss: 2.4605330158742733

Epoch: 6| Step: 4
Training loss: 3.091918403131152
Validation loss: 2.4624999529851728

Epoch: 6| Step: 5
Training loss: 2.874334009404549
Validation loss: 2.4517858656883345

Epoch: 6| Step: 6
Training loss: 2.6268373144778874
Validation loss: 2.441966613908627

Epoch: 6| Step: 7
Training loss: 2.8810182689231842
Validation loss: 2.447516894942465

Epoch: 6| Step: 8
Training loss: 3.2342647220405953
Validation loss: 2.4541846785290122

Epoch: 6| Step: 9
Training loss: 2.727864563910849
Validation loss: 2.4759861609421905

Epoch: 6| Step: 10
Training loss: 2.8118858514573413
Validation loss: 2.502644783709596

Epoch: 6| Step: 11
Training loss: 3.3632656544535338
Validation loss: 2.540210191750783

Epoch: 6| Step: 12
Training loss: 2.383918680545052
Validation loss: 2.580297566597788

Epoch: 6| Step: 13
Training loss: 3.491763095540827
Validation loss: 2.5797903658969674

Epoch: 116| Step: 0
Training loss: 2.740879714247087
Validation loss: 2.5403291174157823

Epoch: 6| Step: 1
Training loss: 2.83820767085461
Validation loss: 2.507043840753549

Epoch: 6| Step: 2
Training loss: 2.26974743652199
Validation loss: 2.4771210533048027

Epoch: 6| Step: 3
Training loss: 3.254077407713379
Validation loss: 2.4643769199254972

Epoch: 6| Step: 4
Training loss: 2.2113457292760006
Validation loss: 2.4616213029344425

Epoch: 6| Step: 5
Training loss: 2.8211895960475473
Validation loss: 2.4585852138514044

Epoch: 6| Step: 6
Training loss: 2.507821626735729
Validation loss: 2.459000798404914

Epoch: 6| Step: 7
Training loss: 2.386710958265207
Validation loss: 2.4554423306489466

Epoch: 6| Step: 8
Training loss: 3.108335848509834
Validation loss: 2.452101098290554

Epoch: 6| Step: 9
Training loss: 2.9898659885955996
Validation loss: 2.455987635200975

Epoch: 6| Step: 10
Training loss: 3.296155371929679
Validation loss: 2.4561877428589907

Epoch: 6| Step: 11
Training loss: 2.303118569353461
Validation loss: 2.4524098520355517

Epoch: 6| Step: 12
Training loss: 2.846575496592404
Validation loss: 2.4602053817503973

Epoch: 6| Step: 13
Training loss: 3.744514267594627
Validation loss: 2.4584921244510527

Epoch: 117| Step: 0
Training loss: 3.1926754093598757
Validation loss: 2.450091912808009

Epoch: 6| Step: 1
Training loss: 3.04973354739115
Validation loss: 2.4504458509992117

Epoch: 6| Step: 2
Training loss: 2.9332338561905593
Validation loss: 2.4549415059517874

Epoch: 6| Step: 3
Training loss: 2.4464517200476634
Validation loss: 2.4606457525774155

Epoch: 6| Step: 4
Training loss: 2.7215253322865367
Validation loss: 2.4614632629062156

Epoch: 6| Step: 5
Training loss: 2.2313901798440785
Validation loss: 2.4642322669049097

Epoch: 6| Step: 6
Training loss: 2.78361924657887
Validation loss: 2.4626475653339512

Epoch: 6| Step: 7
Training loss: 2.214827603074409
Validation loss: 2.465133701682067

Epoch: 6| Step: 8
Training loss: 3.264674290159004
Validation loss: 2.4593142941585437

Epoch: 6| Step: 9
Training loss: 2.466150967929306
Validation loss: 2.4656008490846433

Epoch: 6| Step: 10
Training loss: 3.525405909116799
Validation loss: 2.4558192419620224

Epoch: 6| Step: 11
Training loss: 2.631476450981987
Validation loss: 2.458089740990755

Epoch: 6| Step: 12
Training loss: 2.7290635319992522
Validation loss: 2.4643467079448884

Epoch: 6| Step: 13
Training loss: 3.0995979909801976
Validation loss: 2.4881801872215146

Epoch: 118| Step: 0
Training loss: 2.915905408060228
Validation loss: 2.5104587258493813

Epoch: 6| Step: 1
Training loss: 2.5780149494149054
Validation loss: 2.5438878997804584

Epoch: 6| Step: 2
Training loss: 2.609194081139185
Validation loss: 2.5724351062034088

Epoch: 6| Step: 3
Training loss: 3.02553452111999
Validation loss: 2.5557957067209904

Epoch: 6| Step: 4
Training loss: 3.1604293497761913
Validation loss: 2.537707006260019

Epoch: 6| Step: 5
Training loss: 2.8755515854834472
Validation loss: 2.494797537664417

Epoch: 6| Step: 6
Training loss: 3.280523746590004
Validation loss: 2.469726390187661

Epoch: 6| Step: 7
Training loss: 1.9645906744206616
Validation loss: 2.4623003098977856

Epoch: 6| Step: 8
Training loss: 2.8421764002368812
Validation loss: 2.4520689524808437

Epoch: 6| Step: 9
Training loss: 2.332246958917595
Validation loss: 2.4504803615427195

Epoch: 6| Step: 10
Training loss: 2.5994855591874937
Validation loss: 2.4509634131531737

Epoch: 6| Step: 11
Training loss: 3.058596868014056
Validation loss: 2.453253092732079

Epoch: 6| Step: 12
Training loss: 3.0891007447564545
Validation loss: 2.451916562832718

Epoch: 6| Step: 13
Training loss: 3.1828387716760607
Validation loss: 2.4532586082168466

Epoch: 119| Step: 0
Training loss: 2.556589334438243
Validation loss: 2.4503936809564686

Epoch: 6| Step: 1
Training loss: 2.9605467848042273
Validation loss: 2.4510605716246014

Epoch: 6| Step: 2
Training loss: 3.5698519687254935
Validation loss: 2.460293151495381

Epoch: 6| Step: 3
Training loss: 2.40019365562514
Validation loss: 2.4689346183178067

Epoch: 6| Step: 4
Training loss: 2.8826550283041206
Validation loss: 2.4876356994697293

Epoch: 6| Step: 5
Training loss: 1.9354592928043677
Validation loss: 2.505897876486339

Epoch: 6| Step: 6
Training loss: 3.348350995860424
Validation loss: 2.5302444064808856

Epoch: 6| Step: 7
Training loss: 3.1086427986242606
Validation loss: 2.528865504866458

Epoch: 6| Step: 8
Training loss: 2.6224172692936474
Validation loss: 2.534332757991815

Epoch: 6| Step: 9
Training loss: 3.1918239810377598
Validation loss: 2.5198574049973383

Epoch: 6| Step: 10
Training loss: 2.3392186420438867
Validation loss: 2.5088929491505465

Epoch: 6| Step: 11
Training loss: 2.335060592943422
Validation loss: 2.487732766401256

Epoch: 6| Step: 12
Training loss: 2.6781549547761405
Validation loss: 2.4747960491055343

Epoch: 6| Step: 13
Training loss: 3.03406009002505
Validation loss: 2.469875188833261

Epoch: 120| Step: 0
Training loss: 3.225800431153617
Validation loss: 2.4661515511061856

Epoch: 6| Step: 1
Training loss: 2.4889991958144817
Validation loss: 2.4689982372387242

Epoch: 6| Step: 2
Training loss: 2.4971701818731393
Validation loss: 2.468440604354769

Epoch: 6| Step: 3
Training loss: 2.947389229722531
Validation loss: 2.468024847121158

Epoch: 6| Step: 4
Training loss: 3.2125256548499106
Validation loss: 2.4636425812890166

Epoch: 6| Step: 5
Training loss: 2.9728493746809668
Validation loss: 2.4620987961707677

Epoch: 6| Step: 6
Training loss: 2.5619262425141205
Validation loss: 2.458602863036556

Epoch: 6| Step: 7
Training loss: 2.1002875222059094
Validation loss: 2.4632012974747357

Epoch: 6| Step: 8
Training loss: 2.758400829983739
Validation loss: 2.458776300259201

Epoch: 6| Step: 9
Training loss: 2.756451581646311
Validation loss: 2.4654838521714764

Epoch: 6| Step: 10
Training loss: 2.817212882115361
Validation loss: 2.4659669100000223

Epoch: 6| Step: 11
Training loss: 2.7111541925283524
Validation loss: 2.473212121794388

Epoch: 6| Step: 12
Training loss: 3.067129567357562
Validation loss: 2.4907871266805737

Epoch: 6| Step: 13
Training loss: 2.9232864642617957
Validation loss: 2.5193781207210817

Epoch: 121| Step: 0
Training loss: 3.561312829022762
Validation loss: 2.5005284140617743

Epoch: 6| Step: 1
Training loss: 2.4363542455973604
Validation loss: 2.489351917175574

Epoch: 6| Step: 2
Training loss: 2.870610244417379
Validation loss: 2.4716661125125343

Epoch: 6| Step: 3
Training loss: 2.702511491777546
Validation loss: 2.4616521273997516

Epoch: 6| Step: 4
Training loss: 2.7776387805070706
Validation loss: 2.4557368817393788

Epoch: 6| Step: 5
Training loss: 2.3452164195061593
Validation loss: 2.452585373521952

Epoch: 6| Step: 6
Training loss: 2.394017623403084
Validation loss: 2.457141218706805

Epoch: 6| Step: 7
Training loss: 3.0266674836895664
Validation loss: 2.4564161188802633

Epoch: 6| Step: 8
Training loss: 2.843423677941835
Validation loss: 2.456083432660553

Epoch: 6| Step: 9
Training loss: 2.9867924191476924
Validation loss: 2.4625120887357594

Epoch: 6| Step: 10
Training loss: 2.934866028673576
Validation loss: 2.4768891317597492

Epoch: 6| Step: 11
Training loss: 2.7890306999894063
Validation loss: 2.4811651630548557

Epoch: 6| Step: 12
Training loss: 2.756740113017586
Validation loss: 2.4908402312557354

Epoch: 6| Step: 13
Training loss: 2.3382381477296206
Validation loss: 2.49615724826801

Epoch: 122| Step: 0
Training loss: 2.5548411098576467
Validation loss: 2.505709800412021

Epoch: 6| Step: 1
Training loss: 3.230780036440095
Validation loss: 2.499530607682992

Epoch: 6| Step: 2
Training loss: 2.392966028025764
Validation loss: 2.485385201556894

Epoch: 6| Step: 3
Training loss: 3.3405939341600286
Validation loss: 2.478273088155332

Epoch: 6| Step: 4
Training loss: 2.4738195976039274
Validation loss: 2.4772325300791938

Epoch: 6| Step: 5
Training loss: 3.18399693094997
Validation loss: 2.488438657224757

Epoch: 6| Step: 6
Training loss: 3.056529550697508
Validation loss: 2.4772610507152355

Epoch: 6| Step: 7
Training loss: 2.6748036178803996
Validation loss: 2.4918552932954454

Epoch: 6| Step: 8
Training loss: 2.414763808616447
Validation loss: 2.477251657709062

Epoch: 6| Step: 9
Training loss: 2.414446655126524
Validation loss: 2.483910780695344

Epoch: 6| Step: 10
Training loss: 2.9853817504913827
Validation loss: 2.468890046871909

Epoch: 6| Step: 11
Training loss: 2.3661983425105877
Validation loss: 2.4603843045062415

Epoch: 6| Step: 12
Training loss: 2.634147328305081
Validation loss: 2.4562671092057298

Epoch: 6| Step: 13
Training loss: 3.045108067641561
Validation loss: 2.4604526826773303

Epoch: 123| Step: 0
Training loss: 3.1258711554295835
Validation loss: 2.4563418818337746

Epoch: 6| Step: 1
Training loss: 1.8193029133476197
Validation loss: 2.449101856057217

Epoch: 6| Step: 2
Training loss: 2.2983935260520867
Validation loss: 2.4565288357982795

Epoch: 6| Step: 3
Training loss: 3.0919199453356256
Validation loss: 2.462281396171275

Epoch: 6| Step: 4
Training loss: 2.9880342269224034
Validation loss: 2.4610001209193983

Epoch: 6| Step: 5
Training loss: 2.6170331767117996
Validation loss: 2.4705905712112677

Epoch: 6| Step: 6
Training loss: 2.96139385964092
Validation loss: 2.4911337557474313

Epoch: 6| Step: 7
Training loss: 2.743554798733713
Validation loss: 2.484855886508513

Epoch: 6| Step: 8
Training loss: 2.529006717490449
Validation loss: 2.478837944263923

Epoch: 6| Step: 9
Training loss: 3.0056077679580167
Validation loss: 2.4866764416307734

Epoch: 6| Step: 10
Training loss: 3.1383871579598126
Validation loss: 2.481872584054258

Epoch: 6| Step: 11
Training loss: 2.3761499532139574
Validation loss: 2.479604842800728

Epoch: 6| Step: 12
Training loss: 3.2879584627335445
Validation loss: 2.469271721936764

Epoch: 6| Step: 13
Training loss: 2.364465136381704
Validation loss: 2.466758718313954

Epoch: 124| Step: 0
Training loss: 2.9084064317787686
Validation loss: 2.4580969487399926

Epoch: 6| Step: 1
Training loss: 2.8466376430750158
Validation loss: 2.469913078367264

Epoch: 6| Step: 2
Training loss: 2.494555744226508
Validation loss: 2.4710848810577155

Epoch: 6| Step: 3
Training loss: 2.665108662692754
Validation loss: 2.4694488603727223

Epoch: 6| Step: 4
Training loss: 2.964254086928129
Validation loss: 2.47913955242096

Epoch: 6| Step: 5
Training loss: 2.9260640026818496
Validation loss: 2.4738663854604925

Epoch: 6| Step: 6
Training loss: 3.4749030449603913
Validation loss: 2.4748890960164758

Epoch: 6| Step: 7
Training loss: 2.8676446451490554
Validation loss: 2.4595502754634224

Epoch: 6| Step: 8
Training loss: 2.501277501814376
Validation loss: 2.4692371802053903

Epoch: 6| Step: 9
Training loss: 2.6522200587874254
Validation loss: 2.473877387716824

Epoch: 6| Step: 10
Training loss: 2.8637806455586756
Validation loss: 2.4768194073961114

Epoch: 6| Step: 11
Training loss: 2.8821087730365518
Validation loss: 2.4977258952618486

Epoch: 6| Step: 12
Training loss: 2.122805303535859
Validation loss: 2.4901239003322164

Epoch: 6| Step: 13
Training loss: 2.0581605516983807
Validation loss: 2.5058384799668776

Epoch: 125| Step: 0
Training loss: 2.319072970289706
Validation loss: 2.4877292672923415

Epoch: 6| Step: 1
Training loss: 2.629693966164575
Validation loss: 2.4755042255965445

Epoch: 6| Step: 2
Training loss: 2.9591829038185447
Validation loss: 2.4606894164106414

Epoch: 6| Step: 3
Training loss: 3.1745033836953556
Validation loss: 2.452135433945124

Epoch: 6| Step: 4
Training loss: 2.3553587221982974
Validation loss: 2.4481789512341843

Epoch: 6| Step: 5
Training loss: 3.0428794289482144
Validation loss: 2.443419560065086

Epoch: 6| Step: 6
Training loss: 3.106353365062915
Validation loss: 2.4419710242246904

Epoch: 6| Step: 7
Training loss: 2.9867767735462114
Validation loss: 2.44565967793676

Epoch: 6| Step: 8
Training loss: 2.790627774945254
Validation loss: 2.453470861360222

Epoch: 6| Step: 9
Training loss: 2.633752490940011
Validation loss: 2.44832562390729

Epoch: 6| Step: 10
Training loss: 3.0422437634234485
Validation loss: 2.4532898334851754

Epoch: 6| Step: 11
Training loss: 2.8705413079265547
Validation loss: 2.4812928497118314

Epoch: 6| Step: 12
Training loss: 2.45561063176333
Validation loss: 2.4949523009515087

Epoch: 6| Step: 13
Training loss: 1.795585700513566
Validation loss: 2.502980645763495

Epoch: 126| Step: 0
Training loss: 3.034879733221267
Validation loss: 2.523886864573657

Epoch: 6| Step: 1
Training loss: 2.5365422813941607
Validation loss: 2.518110600008237

Epoch: 6| Step: 2
Training loss: 1.6405909216838308
Validation loss: 2.5152423689683943

Epoch: 6| Step: 3
Training loss: 2.9241692822425547
Validation loss: 2.5326923305694273

Epoch: 6| Step: 4
Training loss: 2.9024145597750906
Validation loss: 2.5120332870818705

Epoch: 6| Step: 5
Training loss: 3.1772745710673433
Validation loss: 2.487583306629893

Epoch: 6| Step: 6
Training loss: 3.0726489623968054
Validation loss: 2.461959002342051

Epoch: 6| Step: 7
Training loss: 3.069815170738316
Validation loss: 2.445354619745078

Epoch: 6| Step: 8
Training loss: 2.7683714252617126
Validation loss: 2.444974325831103

Epoch: 6| Step: 9
Training loss: 3.032206905381131
Validation loss: 2.4398837847866206

Epoch: 6| Step: 10
Training loss: 2.945085835525559
Validation loss: 2.444721457542244

Epoch: 6| Step: 11
Training loss: 2.308489853639801
Validation loss: 2.4546256981550245

Epoch: 6| Step: 12
Training loss: 2.424641659403235
Validation loss: 2.4533245109260813

Epoch: 6| Step: 13
Training loss: 2.695960190946033
Validation loss: 2.4513167695328284

Epoch: 127| Step: 0
Training loss: 2.9183259513002016
Validation loss: 2.4464550261749305

Epoch: 6| Step: 1
Training loss: 2.7319901011386785
Validation loss: 2.447632281964646

Epoch: 6| Step: 2
Training loss: 2.6871599381452174
Validation loss: 2.4438221969705185

Epoch: 6| Step: 3
Training loss: 2.5908701892225987
Validation loss: 2.45200046284233

Epoch: 6| Step: 4
Training loss: 3.2528317659195793
Validation loss: 2.445160047841317

Epoch: 6| Step: 5
Training loss: 2.6752870423511883
Validation loss: 2.4508670123282816

Epoch: 6| Step: 6
Training loss: 2.5567405920104576
Validation loss: 2.462269578922815

Epoch: 6| Step: 7
Training loss: 2.522522940706221
Validation loss: 2.4685748562434235

Epoch: 6| Step: 8
Training loss: 2.1295709254824446
Validation loss: 2.5173806930155673

Epoch: 6| Step: 9
Training loss: 2.1432619212086124
Validation loss: 2.563324428249353

Epoch: 6| Step: 10
Training loss: 3.775384688829076
Validation loss: 2.654529190270654

Epoch: 6| Step: 11
Training loss: 2.7571463928651765
Validation loss: 2.7477901357554897

Epoch: 6| Step: 12
Training loss: 3.46771197209502
Validation loss: 2.7182722557116503

Epoch: 6| Step: 13
Training loss: 3.2157012426236866
Validation loss: 2.5855753085186772

Epoch: 128| Step: 0
Training loss: 2.8340733814524843
Validation loss: 2.4940329147237743

Epoch: 6| Step: 1
Training loss: 2.613548732690748
Validation loss: 2.4829316185190318

Epoch: 6| Step: 2
Training loss: 2.877829113391514
Validation loss: 2.5063823426980747

Epoch: 6| Step: 3
Training loss: 2.2655303935325555
Validation loss: 2.566434218675275

Epoch: 6| Step: 4
Training loss: 2.9003518252876184
Validation loss: 2.6191453105585483

Epoch: 6| Step: 5
Training loss: 3.042990688102883
Validation loss: 2.592204189147296

Epoch: 6| Step: 6
Training loss: 3.1635392121293022
Validation loss: 2.5416042300711537

Epoch: 6| Step: 7
Training loss: 2.378476559773471
Validation loss: 2.5058912420453727

Epoch: 6| Step: 8
Training loss: 3.1003224851164677
Validation loss: 2.4923473307802464

Epoch: 6| Step: 9
Training loss: 2.531499026258215
Validation loss: 2.487676172051661

Epoch: 6| Step: 10
Training loss: 2.507025289127233
Validation loss: 2.490687891701505

Epoch: 6| Step: 11
Training loss: 3.2791889802269694
Validation loss: 2.5105206690939466

Epoch: 6| Step: 12
Training loss: 3.4471436216902207
Validation loss: 2.544544092737639

Epoch: 6| Step: 13
Training loss: 3.091766800676931
Validation loss: 2.5646467483234816

Epoch: 129| Step: 0
Training loss: 3.274001189066788
Validation loss: 2.581025307401957

Epoch: 6| Step: 1
Training loss: 2.6279186190425583
Validation loss: 2.5685890010572567

Epoch: 6| Step: 2
Training loss: 2.62800272000548
Validation loss: 2.5498459066279358

Epoch: 6| Step: 3
Training loss: 2.8637903029004788
Validation loss: 2.521853551115061

Epoch: 6| Step: 4
Training loss: 2.7815056158321454
Validation loss: 2.512333613203239

Epoch: 6| Step: 5
Training loss: 2.1862968405781658
Validation loss: 2.536579646076362

Epoch: 6| Step: 6
Training loss: 2.9793862393076993
Validation loss: 2.5712744141603587

Epoch: 6| Step: 7
Training loss: 2.1969622186356106
Validation loss: 2.5588628857041322

Epoch: 6| Step: 8
Training loss: 3.022061609070628
Validation loss: 2.5701087361966852

Epoch: 6| Step: 9
Training loss: 3.1213218405097956
Validation loss: 2.532760320442535

Epoch: 6| Step: 10
Training loss: 2.6506126271476065
Validation loss: 2.513219283438601

Epoch: 6| Step: 11
Training loss: 2.774310251379727
Validation loss: 2.506825165799936

Epoch: 6| Step: 12
Training loss: 3.560173479632436
Validation loss: 2.5140924245754213

Epoch: 6| Step: 13
Training loss: 2.837226511677285
Validation loss: 2.5066996970888122

Epoch: 130| Step: 0
Training loss: 2.797750836701277
Validation loss: 2.524082469307874

Epoch: 6| Step: 1
Training loss: 2.8948949670268154
Validation loss: 2.5508552601714505

Epoch: 6| Step: 2
Training loss: 2.6853727748964444
Validation loss: 2.5671357901803953

Epoch: 6| Step: 3
Training loss: 3.228893260251288
Validation loss: 2.5572179944890396

Epoch: 6| Step: 4
Training loss: 2.4245921981692296
Validation loss: 2.5691638021314214

Epoch: 6| Step: 5
Training loss: 3.262776423761683
Validation loss: 2.5921423741321594

Epoch: 6| Step: 6
Training loss: 2.4968860306096303
Validation loss: 2.595258972374995

Epoch: 6| Step: 7
Training loss: 3.354954992182869
Validation loss: 2.5963623268582676

Epoch: 6| Step: 8
Training loss: 2.810644173279984
Validation loss: 2.5596838442418117

Epoch: 6| Step: 9
Training loss: 2.7856667413252407
Validation loss: 2.521931046104309

Epoch: 6| Step: 10
Training loss: 3.0356454344562955
Validation loss: 2.5006082881744662

Epoch: 6| Step: 11
Training loss: 2.6954602187215544
Validation loss: 2.487196753338854

Epoch: 6| Step: 12
Training loss: 2.2726930008818447
Validation loss: 2.4818567272478416

Epoch: 6| Step: 13
Training loss: 2.917796179636
Validation loss: 2.479526815902152

Epoch: 131| Step: 0
Training loss: 2.1325999842254775
Validation loss: 2.4810325833752898

Epoch: 6| Step: 1
Training loss: 2.7693010457813227
Validation loss: 2.489753529569761

Epoch: 6| Step: 2
Training loss: 2.682707749967301
Validation loss: 2.4867309267744786

Epoch: 6| Step: 3
Training loss: 2.225900437821566
Validation loss: 2.4915259017332057

Epoch: 6| Step: 4
Training loss: 2.7909795760115084
Validation loss: 2.4938025813882003

Epoch: 6| Step: 5
Training loss: 3.351812606762868
Validation loss: 2.4882930755913764

Epoch: 6| Step: 6
Training loss: 2.9313540181978843
Validation loss: 2.4805088206956087

Epoch: 6| Step: 7
Training loss: 2.7111314160033055
Validation loss: 2.482414797776545

Epoch: 6| Step: 8
Training loss: 2.7601381173335895
Validation loss: 2.4874050190473764

Epoch: 6| Step: 9
Training loss: 2.735224390257109
Validation loss: 2.495403852736239

Epoch: 6| Step: 10
Training loss: 2.7994460750073005
Validation loss: 2.499729181818437

Epoch: 6| Step: 11
Training loss: 3.1757636826370668
Validation loss: 2.5200078733610622

Epoch: 6| Step: 12
Training loss: 2.815225255704496
Validation loss: 2.555291571461401

Epoch: 6| Step: 13
Training loss: 3.2215325633275214
Validation loss: 2.5873259808997933

Epoch: 132| Step: 0
Training loss: 2.8129904425357304
Validation loss: 2.5498356785712426

Epoch: 6| Step: 1
Training loss: 2.7016436977771088
Validation loss: 2.504871775512009

Epoch: 6| Step: 2
Training loss: 3.0990542784298403
Validation loss: 2.4755888629813603

Epoch: 6| Step: 3
Training loss: 2.4699335279284855
Validation loss: 2.4498570463486415

Epoch: 6| Step: 4
Training loss: 2.525583494393345
Validation loss: 2.4355950875122083

Epoch: 6| Step: 5
Training loss: 2.727416159008182
Validation loss: 2.438348435795812

Epoch: 6| Step: 6
Training loss: 2.877106102464994
Validation loss: 2.4486647486321456

Epoch: 6| Step: 7
Training loss: 2.936379888722015
Validation loss: 2.439625225070182

Epoch: 6| Step: 8
Training loss: 3.0033498181713796
Validation loss: 2.4414580440154516

Epoch: 6| Step: 9
Training loss: 2.8084089406718626
Validation loss: 2.445527735433397

Epoch: 6| Step: 10
Training loss: 2.8574283831842324
Validation loss: 2.445830651590811

Epoch: 6| Step: 11
Training loss: 3.309576507859722
Validation loss: 2.46493287305074

Epoch: 6| Step: 12
Training loss: 2.1043199791780873
Validation loss: 2.4649890181902046

Epoch: 6| Step: 13
Training loss: 2.3313735724621654
Validation loss: 2.479642145300221

Epoch: 133| Step: 0
Training loss: 2.4721243287705845
Validation loss: 2.499464221681087

Epoch: 6| Step: 1
Training loss: 2.48309513929585
Validation loss: 2.519840195018315

Epoch: 6| Step: 2
Training loss: 3.131121628617809
Validation loss: 2.5354756974498165

Epoch: 6| Step: 3
Training loss: 2.499579680395046
Validation loss: 2.5145344852952345

Epoch: 6| Step: 4
Training loss: 3.3864891035985196
Validation loss: 2.487273873794077

Epoch: 6| Step: 5
Training loss: 2.6726502303318007
Validation loss: 2.4650520327843304

Epoch: 6| Step: 6
Training loss: 2.58894040102412
Validation loss: 2.4550616607347595

Epoch: 6| Step: 7
Training loss: 2.7318026404745837
Validation loss: 2.445866379173346

Epoch: 6| Step: 8
Training loss: 2.8594061844589636
Validation loss: 2.4423434241657573

Epoch: 6| Step: 9
Training loss: 2.5761275443079747
Validation loss: 2.4405132050715888

Epoch: 6| Step: 10
Training loss: 2.169520357274262
Validation loss: 2.444683966161572

Epoch: 6| Step: 11
Training loss: 3.049997461036501
Validation loss: 2.451030423519333

Epoch: 6| Step: 12
Training loss: 3.1057291557486444
Validation loss: 2.455859798358934

Epoch: 6| Step: 13
Training loss: 2.845764787852855
Validation loss: 2.4468132241009797

Epoch: 134| Step: 0
Training loss: 2.506748151858196
Validation loss: 2.4422482775937153

Epoch: 6| Step: 1
Training loss: 2.3556057967620068
Validation loss: 2.4416364306813096

Epoch: 6| Step: 2
Training loss: 3.172697815555873
Validation loss: 2.4455841541545866

Epoch: 6| Step: 3
Training loss: 2.639088471433364
Validation loss: 2.436891720212691

Epoch: 6| Step: 4
Training loss: 3.1670752981116017
Validation loss: 2.439939407296954

Epoch: 6| Step: 5
Training loss: 2.8737126661001944
Validation loss: 2.4531979434725026

Epoch: 6| Step: 6
Training loss: 2.8520258278874353
Validation loss: 2.440613365662933

Epoch: 6| Step: 7
Training loss: 2.351401085874205
Validation loss: 2.4511558038988475

Epoch: 6| Step: 8
Training loss: 2.13222431274642
Validation loss: 2.456961260521514

Epoch: 6| Step: 9
Training loss: 3.4735397399324706
Validation loss: 2.463752274671736

Epoch: 6| Step: 10
Training loss: 2.769633002086659
Validation loss: 2.461458694835495

Epoch: 6| Step: 11
Training loss: 2.6129660195302904
Validation loss: 2.4674714722422024

Epoch: 6| Step: 12
Training loss: 2.5649240704874137
Validation loss: 2.4719810044008503

Epoch: 6| Step: 13
Training loss: 2.6400190933577465
Validation loss: 2.46141907745436

Epoch: 135| Step: 0
Training loss: 2.670954674053757
Validation loss: 2.484334401403715

Epoch: 6| Step: 1
Training loss: 3.091088894086914
Validation loss: 2.4835297337222078

Epoch: 6| Step: 2
Training loss: 2.4965749166392124
Validation loss: 2.490229359379832

Epoch: 6| Step: 3
Training loss: 2.935114764645605
Validation loss: 2.5445926358755764

Epoch: 6| Step: 4
Training loss: 3.026798873596264
Validation loss: 2.5471743260509396

Epoch: 6| Step: 5
Training loss: 2.8807834007460817
Validation loss: 2.567802695207189

Epoch: 6| Step: 6
Training loss: 2.9011168729849155
Validation loss: 2.5229208040803446

Epoch: 6| Step: 7
Training loss: 2.4115937581495155
Validation loss: 2.4892322095135855

Epoch: 6| Step: 8
Training loss: 2.238865108800178
Validation loss: 2.464808642808208

Epoch: 6| Step: 9
Training loss: 2.2230220017745066
Validation loss: 2.446036539218897

Epoch: 6| Step: 10
Training loss: 2.3775459496904374
Validation loss: 2.4466416626507286

Epoch: 6| Step: 11
Training loss: 3.166616355764033
Validation loss: 2.442098474823587

Epoch: 6| Step: 12
Training loss: 2.855778501229305
Validation loss: 2.4463700494265037

Epoch: 6| Step: 13
Training loss: 3.287244280598439
Validation loss: 2.4462192959623135

Epoch: 136| Step: 0
Training loss: 3.0912983746104388
Validation loss: 2.44013373885102

Epoch: 6| Step: 1
Training loss: 3.052528496436621
Validation loss: 2.439639236847777

Epoch: 6| Step: 2
Training loss: 2.463221480118998
Validation loss: 2.439339222837519

Epoch: 6| Step: 3
Training loss: 2.7687023735686256
Validation loss: 2.444513793241582

Epoch: 6| Step: 4
Training loss: 2.7898190965420437
Validation loss: 2.4510934356073686

Epoch: 6| Step: 5
Training loss: 2.9971867722363346
Validation loss: 2.454945243418781

Epoch: 6| Step: 6
Training loss: 2.3587514293284246
Validation loss: 2.488252685164496

Epoch: 6| Step: 7
Training loss: 2.5004568636201165
Validation loss: 2.5029987551988104

Epoch: 6| Step: 8
Training loss: 2.6305827765000203
Validation loss: 2.513101960256848

Epoch: 6| Step: 9
Training loss: 2.9392868451204195
Validation loss: 2.5333745363972557

Epoch: 6| Step: 10
Training loss: 2.656051987392002
Validation loss: 2.4997710687148182

Epoch: 6| Step: 11
Training loss: 2.785029725441766
Validation loss: 2.4801353085132223

Epoch: 6| Step: 12
Training loss: 2.989582571279892
Validation loss: 2.45410284531157

Epoch: 6| Step: 13
Training loss: 1.939352257632419
Validation loss: 2.45483480351605

Epoch: 137| Step: 0
Training loss: 3.016526477851164
Validation loss: 2.4457676129260957

Epoch: 6| Step: 1
Training loss: 2.812986458988192
Validation loss: 2.432900720737413

Epoch: 6| Step: 2
Training loss: 2.655210044583926
Validation loss: 2.43739812221029

Epoch: 6| Step: 3
Training loss: 2.7337665861906015
Validation loss: 2.43880779478401

Epoch: 6| Step: 4
Training loss: 2.9150020935679226
Validation loss: 2.439299763286782

Epoch: 6| Step: 5
Training loss: 2.7350598158911783
Validation loss: 2.442476255567403

Epoch: 6| Step: 6
Training loss: 3.0251910819241354
Validation loss: 2.443237999409293

Epoch: 6| Step: 7
Training loss: 2.6509292268921874
Validation loss: 2.4512156239234812

Epoch: 6| Step: 8
Training loss: 2.1774950383476903
Validation loss: 2.4469988877369406

Epoch: 6| Step: 9
Training loss: 2.5103554830310553
Validation loss: 2.4481217943557825

Epoch: 6| Step: 10
Training loss: 2.897877435992282
Validation loss: 2.4552499301784088

Epoch: 6| Step: 11
Training loss: 2.7257138218498005
Validation loss: 2.4707094575612008

Epoch: 6| Step: 12
Training loss: 2.6849339677018484
Validation loss: 2.46818512237752

Epoch: 6| Step: 13
Training loss: 2.512469284856759
Validation loss: 2.470895649188602

Epoch: 138| Step: 0
Training loss: 2.353049888273277
Validation loss: 2.469829471301724

Epoch: 6| Step: 1
Training loss: 2.8522038822784013
Validation loss: 2.4733208092755885

Epoch: 6| Step: 2
Training loss: 2.660513205532945
Validation loss: 2.4586198145185385

Epoch: 6| Step: 3
Training loss: 2.7133467025177533
Validation loss: 2.4556165532852376

Epoch: 6| Step: 4
Training loss: 3.4525270246349935
Validation loss: 2.445518485238675

Epoch: 6| Step: 5
Training loss: 3.0798222079299475
Validation loss: 2.426781132542414

Epoch: 6| Step: 6
Training loss: 2.4277107071892883
Validation loss: 2.437042241199546

Epoch: 6| Step: 7
Training loss: 2.726393467601374
Validation loss: 2.433009698017711

Epoch: 6| Step: 8
Training loss: 2.562202250231966
Validation loss: 2.4405587921378573

Epoch: 6| Step: 9
Training loss: 3.1612374963358487
Validation loss: 2.4548502740693645

Epoch: 6| Step: 10
Training loss: 2.373788825948457
Validation loss: 2.468910305539829

Epoch: 6| Step: 11
Training loss: 2.9546566175342717
Validation loss: 2.488077069901993

Epoch: 6| Step: 12
Training loss: 1.8988561600320597
Validation loss: 2.5410060989112915

Epoch: 6| Step: 13
Training loss: 2.3447148689381985
Validation loss: 2.5851085823722495

Epoch: 139| Step: 0
Training loss: 2.9817187886367282
Validation loss: 2.5482477227815643

Epoch: 6| Step: 1
Training loss: 2.477173546339966
Validation loss: 2.5505332299180115

Epoch: 6| Step: 2
Training loss: 2.690376250745414
Validation loss: 2.5299982297473584

Epoch: 6| Step: 3
Training loss: 3.025022106247512
Validation loss: 2.519255693023456

Epoch: 6| Step: 4
Training loss: 3.0938076437772173
Validation loss: 2.5161045498638943

Epoch: 6| Step: 5
Training loss: 2.8423934887043534
Validation loss: 2.528920749652632

Epoch: 6| Step: 6
Training loss: 2.835248542937979
Validation loss: 2.5277280482195286

Epoch: 6| Step: 7
Training loss: 1.8150257401966214
Validation loss: 2.498303137981654

Epoch: 6| Step: 8
Training loss: 2.794257958848535
Validation loss: 2.476170024916398

Epoch: 6| Step: 9
Training loss: 2.099156700838528
Validation loss: 2.4567138220589864

Epoch: 6| Step: 10
Training loss: 2.766706266081504
Validation loss: 2.453536793894045

Epoch: 6| Step: 11
Training loss: 3.004857105024905
Validation loss: 2.4563276480528233

Epoch: 6| Step: 12
Training loss: 2.7295458192964395
Validation loss: 2.45173211804985

Epoch: 6| Step: 13
Training loss: 2.041712533344775
Validation loss: 2.4561331051834405

Epoch: 140| Step: 0
Training loss: 3.0239446643428867
Validation loss: 2.4458653352133655

Epoch: 6| Step: 1
Training loss: 2.831084668045808
Validation loss: 2.449347757700008

Epoch: 6| Step: 2
Training loss: 2.325399967369
Validation loss: 2.4400743164046563

Epoch: 6| Step: 3
Training loss: 3.0321293764618664
Validation loss: 2.4474481061328297

Epoch: 6| Step: 4
Training loss: 3.019128217361941
Validation loss: 2.4672349429716913

Epoch: 6| Step: 5
Training loss: 2.954694381375018
Validation loss: 2.494717257081063

Epoch: 6| Step: 6
Training loss: 2.1261501565553207
Validation loss: 2.51061038447343

Epoch: 6| Step: 7
Training loss: 2.5750155105864394
Validation loss: 2.520337645826737

Epoch: 6| Step: 8
Training loss: 2.1089245350532484
Validation loss: 2.5047022793820823

Epoch: 6| Step: 9
Training loss: 2.8771075940795394
Validation loss: 2.523801571535766

Epoch: 6| Step: 10
Training loss: 2.584865935813293
Validation loss: 2.5333958479103846

Epoch: 6| Step: 11
Training loss: 2.751845520818125
Validation loss: 2.4867272628535324

Epoch: 6| Step: 12
Training loss: 2.646810476334079
Validation loss: 2.462558068081719

Epoch: 6| Step: 13
Training loss: 2.974484657082589
Validation loss: 2.4666691478122558

Epoch: 141| Step: 0
Training loss: 2.5939266650231394
Validation loss: 2.4728213304399898

Epoch: 6| Step: 1
Training loss: 2.6341185457379264
Validation loss: 2.4890366778450392

Epoch: 6| Step: 2
Training loss: 3.1239172013235397
Validation loss: 2.5114619348113756

Epoch: 6| Step: 3
Training loss: 2.3218879873905998
Validation loss: 2.5114310867643743

Epoch: 6| Step: 4
Training loss: 2.8286233536659307
Validation loss: 2.5025531324431087

Epoch: 6| Step: 5
Training loss: 2.7416450855213514
Validation loss: 2.5000693260343017

Epoch: 6| Step: 6
Training loss: 3.1315276062851147
Validation loss: 2.509589311195372

Epoch: 6| Step: 7
Training loss: 2.9781056006201028
Validation loss: 2.5122927561922457

Epoch: 6| Step: 8
Training loss: 2.8301266494287214
Validation loss: 2.514867536201308

Epoch: 6| Step: 9
Training loss: 2.162800775679994
Validation loss: 2.5141455049249

Epoch: 6| Step: 10
Training loss: 2.9568333830451676
Validation loss: 2.5318380371880105

Epoch: 6| Step: 11
Training loss: 2.6776145279411856
Validation loss: 2.5311274912204684

Epoch: 6| Step: 12
Training loss: 2.650702933883986
Validation loss: 2.5271011233287966

Epoch: 6| Step: 13
Training loss: 2.291508848362586
Validation loss: 2.4919077290293776

Epoch: 142| Step: 0
Training loss: 2.8861147773955182
Validation loss: 2.4936242840569425

Epoch: 6| Step: 1
Training loss: 2.3452957142553874
Validation loss: 2.4870621748806423

Epoch: 6| Step: 2
Training loss: 2.489406073948801
Validation loss: 2.4953716647828963

Epoch: 6| Step: 3
Training loss: 3.174096743440368
Validation loss: 2.490243416885796

Epoch: 6| Step: 4
Training loss: 2.621589261331178
Validation loss: 2.5359601277797648

Epoch: 6| Step: 5
Training loss: 2.7821530365525957
Validation loss: 2.5776676332870485

Epoch: 6| Step: 6
Training loss: 2.8667158107832944
Validation loss: 2.5614712378591813

Epoch: 6| Step: 7
Training loss: 3.08508443509731
Validation loss: 2.5462249242285138

Epoch: 6| Step: 8
Training loss: 3.07507265826967
Validation loss: 2.5232933473382104

Epoch: 6| Step: 9
Training loss: 2.212760470300792
Validation loss: 2.489716827511004

Epoch: 6| Step: 10
Training loss: 2.8334657600721025
Validation loss: 2.4745519707984847

Epoch: 6| Step: 11
Training loss: 2.198102488203182
Validation loss: 2.4625978076783723

Epoch: 6| Step: 12
Training loss: 2.2753570947100292
Validation loss: 2.450687020222129

Epoch: 6| Step: 13
Training loss: 2.8797467064734747
Validation loss: 2.4434862936455977

Epoch: 143| Step: 0
Training loss: 2.736775505311568
Validation loss: 2.441718110542116

Epoch: 6| Step: 1
Training loss: 2.6197660127651483
Validation loss: 2.446900175583743

Epoch: 6| Step: 2
Training loss: 2.697833046421202
Validation loss: 2.4506939495164133

Epoch: 6| Step: 3
Training loss: 2.563135114908899
Validation loss: 2.459036580676218

Epoch: 6| Step: 4
Training loss: 2.8014199607318284
Validation loss: 2.4570875047449103

Epoch: 6| Step: 5
Training loss: 3.079537779073226
Validation loss: 2.480771724461123

Epoch: 6| Step: 6
Training loss: 1.7712956741248311
Validation loss: 2.4790425161365532

Epoch: 6| Step: 7
Training loss: 2.968529462151854
Validation loss: 2.4816035996070607

Epoch: 6| Step: 8
Training loss: 2.7980855527699857
Validation loss: 2.4868580101501694

Epoch: 6| Step: 9
Training loss: 3.0928294035530675
Validation loss: 2.4872344119861025

Epoch: 6| Step: 10
Training loss: 2.4541860824706383
Validation loss: 2.478347838192648

Epoch: 6| Step: 11
Training loss: 2.4675433916259477
Validation loss: 2.478664366610954

Epoch: 6| Step: 12
Training loss: 2.5622884151286027
Validation loss: 2.4842873999837267

Epoch: 6| Step: 13
Training loss: 2.958135481831356
Validation loss: 2.4885377707093523

Epoch: 144| Step: 0
Training loss: 2.8807542684745733
Validation loss: 2.4959038700039096

Epoch: 6| Step: 1
Training loss: 2.632073997813941
Validation loss: 2.525794635073423

Epoch: 6| Step: 2
Training loss: 2.919662862153385
Validation loss: 2.5198284533826487

Epoch: 6| Step: 3
Training loss: 1.813035293984617
Validation loss: 2.508588279694933

Epoch: 6| Step: 4
Training loss: 2.2626373586530524
Validation loss: 2.5130250295180754

Epoch: 6| Step: 5
Training loss: 2.811963856775461
Validation loss: 2.4928536378796218

Epoch: 6| Step: 6
Training loss: 2.9511414986441316
Validation loss: 2.464163044796627

Epoch: 6| Step: 7
Training loss: 2.5322205366540333
Validation loss: 2.4590917616269343

Epoch: 6| Step: 8
Training loss: 2.7405815094962733
Validation loss: 2.466335738700604

Epoch: 6| Step: 9
Training loss: 2.8110723474801094
Validation loss: 2.4720547427593202

Epoch: 6| Step: 10
Training loss: 2.5731565747143343
Validation loss: 2.489265111259677

Epoch: 6| Step: 11
Training loss: 3.1377849738200916
Validation loss: 2.4962274964673914

Epoch: 6| Step: 12
Training loss: 3.0553271314222448
Validation loss: 2.4891782981969124

Epoch: 6| Step: 13
Training loss: 2.559050121810814
Validation loss: 2.4800020628466384

Epoch: 145| Step: 0
Training loss: 2.969839919942731
Validation loss: 2.489572518221756

Epoch: 6| Step: 1
Training loss: 2.2342627437109024
Validation loss: 2.4999262480983293

Epoch: 6| Step: 2
Training loss: 2.643133833846301
Validation loss: 2.528974643987638

Epoch: 6| Step: 3
Training loss: 2.685002341811084
Validation loss: 2.5383036302464204

Epoch: 6| Step: 4
Training loss: 3.432244462116516
Validation loss: 2.6051884726571584

Epoch: 6| Step: 5
Training loss: 2.6463398686331625
Validation loss: 2.626417335051124

Epoch: 6| Step: 6
Training loss: 2.3551726653345013
Validation loss: 2.6336745921748115

Epoch: 6| Step: 7
Training loss: 2.2059362345079996
Validation loss: 2.6521592569051857

Epoch: 6| Step: 8
Training loss: 3.082976105762283
Validation loss: 2.6619501787421016

Epoch: 6| Step: 9
Training loss: 3.0599535261626754
Validation loss: 2.6572868991936596

Epoch: 6| Step: 10
Training loss: 2.4293128212287174
Validation loss: 2.610938362527007

Epoch: 6| Step: 11
Training loss: 2.9435544218304073
Validation loss: 2.5604023645341094

Epoch: 6| Step: 12
Training loss: 2.824512851539313
Validation loss: 2.5269742082698072

Epoch: 6| Step: 13
Training loss: 2.609590898365074
Validation loss: 2.50540794866849

Epoch: 146| Step: 0
Training loss: 2.664775674621999
Validation loss: 2.523478980158255

Epoch: 6| Step: 1
Training loss: 2.5336322641518385
Validation loss: 2.538155301995774

Epoch: 6| Step: 2
Training loss: 2.5735914655625143
Validation loss: 2.533713021170956

Epoch: 6| Step: 3
Training loss: 3.2016397149458973
Validation loss: 2.5506558318265675

Epoch: 6| Step: 4
Training loss: 2.3532221314342228
Validation loss: 2.501842986428719

Epoch: 6| Step: 5
Training loss: 2.5169079275466295
Validation loss: 2.4817098483885514

Epoch: 6| Step: 6
Training loss: 2.3421950204638167
Validation loss: 2.4655387827680353

Epoch: 6| Step: 7
Training loss: 3.5587802674775384
Validation loss: 2.4839507452926535

Epoch: 6| Step: 8
Training loss: 1.9468370461476558
Validation loss: 2.5141423051461214

Epoch: 6| Step: 9
Training loss: 2.41133689711925
Validation loss: 2.5329469385573544

Epoch: 6| Step: 10
Training loss: 3.119473262241222
Validation loss: 2.5539586791021356

Epoch: 6| Step: 11
Training loss: 3.104620437396935
Validation loss: 2.5384520467824587

Epoch: 6| Step: 12
Training loss: 2.89868969090058
Validation loss: 2.5535610836945115

Epoch: 6| Step: 13
Training loss: 2.7450364140664476
Validation loss: 2.5470461133322795

Epoch: 147| Step: 0
Training loss: 2.992743617238287
Validation loss: 2.49208311549672

Epoch: 6| Step: 1
Training loss: 2.2727458727682377
Validation loss: 2.4568627795971487

Epoch: 6| Step: 2
Training loss: 2.669292428774431
Validation loss: 2.4485895850428596

Epoch: 6| Step: 3
Training loss: 3.2307127338052792
Validation loss: 2.452272180051401

Epoch: 6| Step: 4
Training loss: 2.857946820906213
Validation loss: 2.4439049041734546

Epoch: 6| Step: 5
Training loss: 2.883308347325488
Validation loss: 2.4422609286076185

Epoch: 6| Step: 6
Training loss: 2.644044907446773
Validation loss: 2.4570788009734663

Epoch: 6| Step: 7
Training loss: 2.6806770477258355
Validation loss: 2.448620711234982

Epoch: 6| Step: 8
Training loss: 1.912233186946871
Validation loss: 2.4489012096923317

Epoch: 6| Step: 9
Training loss: 2.7145153697814166
Validation loss: 2.457974982557485

Epoch: 6| Step: 10
Training loss: 3.1268503433100228
Validation loss: 2.4486541816973384

Epoch: 6| Step: 11
Training loss: 2.2424757503019155
Validation loss: 2.4706904141735757

Epoch: 6| Step: 12
Training loss: 2.74995491684459
Validation loss: 2.496324147672172

Epoch: 6| Step: 13
Training loss: 2.6589349976650163
Validation loss: 2.5179435161689345

Epoch: 148| Step: 0
Training loss: 2.6496177001714356
Validation loss: 2.5143212744067016

Epoch: 6| Step: 1
Training loss: 3.0901755288647172
Validation loss: 2.522380246085857

Epoch: 6| Step: 2
Training loss: 2.97314737801894
Validation loss: 2.5107914719674898

Epoch: 6| Step: 3
Training loss: 2.5096642618453644
Validation loss: 2.506362632397514

Epoch: 6| Step: 4
Training loss: 3.1527485073558856
Validation loss: 2.504095794494925

Epoch: 6| Step: 5
Training loss: 1.8614584525915392
Validation loss: 2.5181620848577237

Epoch: 6| Step: 6
Training loss: 2.8517838901643953
Validation loss: 2.5309246395467007

Epoch: 6| Step: 7
Training loss: 3.0837109995997896
Validation loss: 2.5303926736514644

Epoch: 6| Step: 8
Training loss: 2.7679252756760024
Validation loss: 2.5196632304262545

Epoch: 6| Step: 9
Training loss: 2.870896437735289
Validation loss: 2.5045578160860598

Epoch: 6| Step: 10
Training loss: 2.3260683537917
Validation loss: 2.490107153019985

Epoch: 6| Step: 11
Training loss: 2.5121648460531243
Validation loss: 2.488017561185926

Epoch: 6| Step: 12
Training loss: 1.7621745600447674
Validation loss: 2.473139517770058

Epoch: 6| Step: 13
Training loss: 2.1437224094405956
Validation loss: 2.482530555815875

Epoch: 149| Step: 0
Training loss: 2.5029079690825187
Validation loss: 2.4877843708590692

Epoch: 6| Step: 1
Training loss: 2.7290504275506713
Validation loss: 2.477373043257882

Epoch: 6| Step: 2
Training loss: 2.1330309186609036
Validation loss: 2.488972883588286

Epoch: 6| Step: 3
Training loss: 2.851508320332896
Validation loss: 2.4825260647198104

Epoch: 6| Step: 4
Training loss: 2.297988621636251
Validation loss: 2.4939269401213284

Epoch: 6| Step: 5
Training loss: 2.724821917813193
Validation loss: 2.520939604972534

Epoch: 6| Step: 6
Training loss: 2.7212937830503
Validation loss: 2.535569689350476

Epoch: 6| Step: 7
Training loss: 2.698666285549986
Validation loss: 2.537277796470908

Epoch: 6| Step: 8
Training loss: 2.813214190191536
Validation loss: 2.5406570433155036

Epoch: 6| Step: 9
Training loss: 2.35482814801621
Validation loss: 2.5729537495546375

Epoch: 6| Step: 10
Training loss: 2.4867482875420386
Validation loss: 2.6169344872031415

Epoch: 6| Step: 11
Training loss: 2.8157037925068487
Validation loss: 2.614341762593333

Epoch: 6| Step: 12
Training loss: 2.9513033945503757
Validation loss: 2.628780036069554

Epoch: 6| Step: 13
Training loss: 2.4344217474663985
Validation loss: 2.6144973998309786

Epoch: 150| Step: 0
Training loss: 2.807880762084543
Validation loss: 2.6026343568167807

Epoch: 6| Step: 1
Training loss: 2.1406223269257945
Validation loss: 2.5741492099933785

Epoch: 6| Step: 2
Training loss: 2.2405938522748943
Validation loss: 2.5187560020519184

Epoch: 6| Step: 3
Training loss: 1.8662960206762464
Validation loss: 2.4942122312370327

Epoch: 6| Step: 4
Training loss: 2.999136164592173
Validation loss: 2.4661605357550167

Epoch: 6| Step: 5
Training loss: 2.8158994686973573
Validation loss: 2.4632864694620795

Epoch: 6| Step: 6
Training loss: 2.8608391353712426
Validation loss: 2.4611495778728796

Epoch: 6| Step: 7
Training loss: 2.3246013422631546
Validation loss: 2.4763833113085227

Epoch: 6| Step: 8
Training loss: 2.6506712729083333
Validation loss: 2.4745173815600627

Epoch: 6| Step: 9
Training loss: 3.071962335534468
Validation loss: 2.478257997605533

Epoch: 6| Step: 10
Training loss: 2.771397745876768
Validation loss: 2.4714744387585226

Epoch: 6| Step: 11
Training loss: 2.477167194081595
Validation loss: 2.4688788437883185

Epoch: 6| Step: 12
Training loss: 2.8699420721076265
Validation loss: 2.481968887883605

Epoch: 6| Step: 13
Training loss: 1.9256507566240604
Validation loss: 2.494303961840114

Epoch: 151| Step: 0
Training loss: 3.080386652518822
Validation loss: 2.489479953182762

Epoch: 6| Step: 1
Training loss: 2.683280648924662
Validation loss: 2.5036767502436126

Epoch: 6| Step: 2
Training loss: 2.3850107527836335
Validation loss: 2.5121236168736774

Epoch: 6| Step: 3
Training loss: 2.482920958909022
Validation loss: 2.4887945740010293

Epoch: 6| Step: 4
Training loss: 2.8415783984961256
Validation loss: 2.47693786540321

Epoch: 6| Step: 5
Training loss: 1.8568659932352405
Validation loss: 2.46870135602981

Epoch: 6| Step: 6
Training loss: 2.1126843524375967
Validation loss: 2.452063126942139

Epoch: 6| Step: 7
Training loss: 2.766298373730658
Validation loss: 2.441275082581949

Epoch: 6| Step: 8
Training loss: 2.2078089061364947
Validation loss: 2.4423880890715055

Epoch: 6| Step: 9
Training loss: 2.4801319284111116
Validation loss: 2.43942005848331

Epoch: 6| Step: 10
Training loss: 2.5933199606438704
Validation loss: 2.437666015188133

Epoch: 6| Step: 11
Training loss: 2.8409253858619143
Validation loss: 2.44309948948103

Epoch: 6| Step: 12
Training loss: 2.8166859311981813
Validation loss: 2.450748260738476

Epoch: 6| Step: 13
Training loss: 2.9325001147336036
Validation loss: 2.472196085316503

Epoch: 152| Step: 0
Training loss: 2.711649160940181
Validation loss: 2.4764056060461535

Epoch: 6| Step: 1
Training loss: 3.127003752127636
Validation loss: 2.485043735524925

Epoch: 6| Step: 2
Training loss: 2.6996474636362207
Validation loss: 2.491514268465146

Epoch: 6| Step: 3
Training loss: 2.2290696333922533
Validation loss: 2.496978029517241

Epoch: 6| Step: 4
Training loss: 2.9057839953171687
Validation loss: 2.5012427107507302

Epoch: 6| Step: 5
Training loss: 2.5280935127551394
Validation loss: 2.5390705229046375

Epoch: 6| Step: 6
Training loss: 2.9726341136454044
Validation loss: 2.546183911285123

Epoch: 6| Step: 7
Training loss: 2.4801094335591722
Validation loss: 2.5864417398632384

Epoch: 6| Step: 8
Training loss: 2.47852899594379
Validation loss: 2.6336717712361266

Epoch: 6| Step: 9
Training loss: 2.166716012637315
Validation loss: 2.626230074716475

Epoch: 6| Step: 10
Training loss: 2.1996391260502426
Validation loss: 2.578931610819441

Epoch: 6| Step: 11
Training loss: 2.4886928439510574
Validation loss: 2.555475110627306

Epoch: 6| Step: 12
Training loss: 2.288306518290146
Validation loss: 2.5078869573691285

Epoch: 6| Step: 13
Training loss: 2.6695208970456075
Validation loss: 2.4641268261391285

Epoch: 153| Step: 0
Training loss: 2.0782569327099414
Validation loss: 2.438959970235028

Epoch: 6| Step: 1
Training loss: 2.9043590998188713
Validation loss: 2.4456578393214343

Epoch: 6| Step: 2
Training loss: 2.88388794065162
Validation loss: 2.442314599165049

Epoch: 6| Step: 3
Training loss: 3.1050777932955227
Validation loss: 2.444243535712845

Epoch: 6| Step: 4
Training loss: 2.984615935341454
Validation loss: 2.448496951145725

Epoch: 6| Step: 5
Training loss: 2.206886273238894
Validation loss: 2.4525469298798805

Epoch: 6| Step: 6
Training loss: 2.4154133890298746
Validation loss: 2.4891541239281434

Epoch: 6| Step: 7
Training loss: 2.7279601791249815
Validation loss: 2.559248271965264

Epoch: 6| Step: 8
Training loss: 2.389652029267836
Validation loss: 2.581587673678192

Epoch: 6| Step: 9
Training loss: 2.652134658145035
Validation loss: 2.552624830635071

Epoch: 6| Step: 10
Training loss: 2.4476367763374114
Validation loss: 2.5237576465638853

Epoch: 6| Step: 11
Training loss: 2.2845001061202166
Validation loss: 2.4640672477707484

Epoch: 6| Step: 12
Training loss: 2.7746477951747437
Validation loss: 2.4169216824139483

Epoch: 6| Step: 13
Training loss: 2.2835516618731986
Validation loss: 2.411027441971618

Epoch: 154| Step: 0
Training loss: 2.657373796482568
Validation loss: 2.40392583079847

Epoch: 6| Step: 1
Training loss: 2.160667869312517
Validation loss: 2.392569576580488

Epoch: 6| Step: 2
Training loss: 2.4100680095526235
Validation loss: 2.4197031509057623

Epoch: 6| Step: 3
Training loss: 2.189109319258364
Validation loss: 2.424995685003104

Epoch: 6| Step: 4
Training loss: 3.095928927589039
Validation loss: 2.46151512334995

Epoch: 6| Step: 5
Training loss: 2.2036015421281876
Validation loss: 2.4869232224701396

Epoch: 6| Step: 6
Training loss: 3.0299289616985168
Validation loss: 2.4909189936840486

Epoch: 6| Step: 7
Training loss: 3.0806688360313776
Validation loss: 2.497343700004699

Epoch: 6| Step: 8
Training loss: 1.9108405574435219
Validation loss: 2.5207183104507704

Epoch: 6| Step: 9
Training loss: 2.675890487334547
Validation loss: 2.4958939858240816

Epoch: 6| Step: 10
Training loss: 2.5087053367391023
Validation loss: 2.5098191533414047

Epoch: 6| Step: 11
Training loss: 2.8128316048002038
Validation loss: 2.5357963390646416

Epoch: 6| Step: 12
Training loss: 2.0805584420134764
Validation loss: 2.547020571874428

Epoch: 6| Step: 13
Training loss: 2.7853499635419383
Validation loss: 2.5406150050890526

Epoch: 155| Step: 0
Training loss: 2.6852130474335594
Validation loss: 2.61651534226931

Epoch: 6| Step: 1
Training loss: 2.656344333544368
Validation loss: 2.624607804001159

Epoch: 6| Step: 2
Training loss: 2.6192069845305697
Validation loss: 2.5930373864385827

Epoch: 6| Step: 3
Training loss: 2.3349370440668973
Validation loss: 2.555533585209486

Epoch: 6| Step: 4
Training loss: 2.0799882609696345
Validation loss: 2.519310657039815

Epoch: 6| Step: 5
Training loss: 2.892477565668489
Validation loss: 2.4719044408267092

Epoch: 6| Step: 6
Training loss: 2.3016150733345446
Validation loss: 2.469972695288613

Epoch: 6| Step: 7
Training loss: 2.590675278050352
Validation loss: 2.4831344397522135

Epoch: 6| Step: 8
Training loss: 2.439453515937719
Validation loss: 2.4864138477340423

Epoch: 6| Step: 9
Training loss: 1.9987711707658575
Validation loss: 2.489396861160336

Epoch: 6| Step: 10
Training loss: 2.815684063257025
Validation loss: 2.5044427178975

Epoch: 6| Step: 11
Training loss: 2.7021382024562213
Validation loss: 2.5096774300628164

Epoch: 6| Step: 12
Training loss: 2.569565313663788
Validation loss: 2.4985232842239564

Epoch: 6| Step: 13
Training loss: 3.100493201123002
Validation loss: 2.4882720958945526

Epoch: 156| Step: 0
Training loss: 2.538094485695253
Validation loss: 2.469239413441046

Epoch: 6| Step: 1
Training loss: 2.5904045130793447
Validation loss: 2.4795803611796106

Epoch: 6| Step: 2
Training loss: 2.8438200889585574
Validation loss: 2.4582989969944142

Epoch: 6| Step: 3
Training loss: 2.5856655012374574
Validation loss: 2.453204843729106

Epoch: 6| Step: 4
Training loss: 2.552512173077197
Validation loss: 2.432912109514152

Epoch: 6| Step: 5
Training loss: 2.3790645953817697
Validation loss: 2.437075558780844

Epoch: 6| Step: 6
Training loss: 2.9386015105123473
Validation loss: 2.440665070415405

Epoch: 6| Step: 7
Training loss: 2.3149609229989623
Validation loss: 2.451561400156419

Epoch: 6| Step: 8
Training loss: 2.3679961280662223
Validation loss: 2.4432020487152952

Epoch: 6| Step: 9
Training loss: 2.201612237242578
Validation loss: 2.4927848146144598

Epoch: 6| Step: 10
Training loss: 1.756010428816951
Validation loss: 2.540667729093542

Epoch: 6| Step: 11
Training loss: 2.90429621826657
Validation loss: 2.6148922985296164

Epoch: 6| Step: 12
Training loss: 2.1310990266100402
Validation loss: 2.6039451737911294

Epoch: 6| Step: 13
Training loss: 2.7846543125952845
Validation loss: 2.5883585263283897

Epoch: 157| Step: 0
Training loss: 2.3716928645831854
Validation loss: 2.5732541008534744

Epoch: 6| Step: 1
Training loss: 2.779370219160274
Validation loss: 2.5765531290565065

Epoch: 6| Step: 2
Training loss: 2.155246224553508
Validation loss: 2.5824736720513695

Epoch: 6| Step: 3
Training loss: 2.425044096712923
Validation loss: 2.517248095921173

Epoch: 6| Step: 4
Training loss: 1.9476883562351335
Validation loss: 2.5016760017536916

Epoch: 6| Step: 5
Training loss: 2.528362558188001
Validation loss: 2.4637825043468506

Epoch: 6| Step: 6
Training loss: 3.2670172684852106
Validation loss: 2.4601271532710096

Epoch: 6| Step: 7
Training loss: 2.701589953325527
Validation loss: 2.457177283673211

Epoch: 6| Step: 8
Training loss: 2.1826148935600362
Validation loss: 2.4705750466850676

Epoch: 6| Step: 9
Training loss: 2.1444776629091544
Validation loss: 2.4750656459799614

Epoch: 6| Step: 10
Training loss: 2.491160501039075
Validation loss: 2.476818729435966

Epoch: 6| Step: 11
Training loss: 2.6243454253276166
Validation loss: 2.4911369253918214

Epoch: 6| Step: 12
Training loss: 2.949961910971747
Validation loss: 2.5107181759301294

Epoch: 6| Step: 13
Training loss: 2.7081899653904187
Validation loss: 2.5291869794307584

Epoch: 158| Step: 0
Training loss: 2.4987003763069793
Validation loss: 2.604437288722884

Epoch: 6| Step: 1
Training loss: 2.3628649636589087
Validation loss: 2.6461657040087885

Epoch: 6| Step: 2
Training loss: 2.2272374251191907
Validation loss: 2.682410111377299

Epoch: 6| Step: 3
Training loss: 3.0105804785979786
Validation loss: 2.7307118610942314

Epoch: 6| Step: 4
Training loss: 2.5623598758253583
Validation loss: 2.6888410223019648

Epoch: 6| Step: 5
Training loss: 2.135819994045976
Validation loss: 2.6662646023863052

Epoch: 6| Step: 6
Training loss: 2.613970153965097
Validation loss: 2.616024172520535

Epoch: 6| Step: 7
Training loss: 2.8272280456192482
Validation loss: 2.5591823471666615

Epoch: 6| Step: 8
Training loss: 1.700394918347404
Validation loss: 2.5203517866432232

Epoch: 6| Step: 9
Training loss: 1.970516320742485
Validation loss: 2.4919358805798053

Epoch: 6| Step: 10
Training loss: 2.9068461801350653
Validation loss: 2.486272763859045

Epoch: 6| Step: 11
Training loss: 2.7603209760862466
Validation loss: 2.4720924951842393

Epoch: 6| Step: 12
Training loss: 2.4802652590927945
Validation loss: 2.458082019049297

Epoch: 6| Step: 13
Training loss: 2.9379437699828523
Validation loss: 2.458280864348222

Epoch: 159| Step: 0
Training loss: 2.929603188891006
Validation loss: 2.44159905362684

Epoch: 6| Step: 1
Training loss: 2.5652120241574257
Validation loss: 2.4433968111618998

Epoch: 6| Step: 2
Training loss: 2.4046716839503834
Validation loss: 2.442534444047196

Epoch: 6| Step: 3
Training loss: 1.9636587281751698
Validation loss: 2.4645682240498727

Epoch: 6| Step: 4
Training loss: 2.632598415466031
Validation loss: 2.4831537108515342

Epoch: 6| Step: 5
Training loss: 2.859876411542015
Validation loss: 2.521129322972029

Epoch: 6| Step: 6
Training loss: 2.5998901857513728
Validation loss: 2.548874176669239

Epoch: 6| Step: 7
Training loss: 2.305345447827631
Validation loss: 2.581692023045681

Epoch: 6| Step: 8
Training loss: 2.961798630756384
Validation loss: 2.6060456356814763

Epoch: 6| Step: 9
Training loss: 2.441181337296294
Validation loss: 2.609550198538832

Epoch: 6| Step: 10
Training loss: 2.518365824060835
Validation loss: 2.5844376856806517

Epoch: 6| Step: 11
Training loss: 2.298100669966513
Validation loss: 2.561550285532024

Epoch: 6| Step: 12
Training loss: 2.0333582574327793
Validation loss: 2.5194492701638427

Epoch: 6| Step: 13
Training loss: 2.0413578604369387
Validation loss: 2.5069854551251103

Epoch: 160| Step: 0
Training loss: 2.4989286034296905
Validation loss: 2.4939694929165483

Epoch: 6| Step: 1
Training loss: 2.2608252886994493
Validation loss: 2.489427003926352

Epoch: 6| Step: 2
Training loss: 2.7136804077840155
Validation loss: 2.4835776444305524

Epoch: 6| Step: 3
Training loss: 1.9097873823050493
Validation loss: 2.4782411276937557

Epoch: 6| Step: 4
Training loss: 2.189934493003999
Validation loss: 2.476349105328901

Epoch: 6| Step: 5
Training loss: 2.678561493991412
Validation loss: 2.4913414217068026

Epoch: 6| Step: 6
Training loss: 2.6168096013321303
Validation loss: 2.491572751171094

Epoch: 6| Step: 7
Training loss: 2.9211983126636882
Validation loss: 2.4978734529265836

Epoch: 6| Step: 8
Training loss: 2.6088820123103487
Validation loss: 2.5130388937102497

Epoch: 6| Step: 9
Training loss: 1.9173947347422071
Validation loss: 2.5244227382337634

Epoch: 6| Step: 10
Training loss: 2.5138160409318906
Validation loss: 2.5455526037606644

Epoch: 6| Step: 11
Training loss: 2.328540124941882
Validation loss: 2.538268337194754

Epoch: 6| Step: 12
Training loss: 2.1909286876235177
Validation loss: 2.54802003757654

Epoch: 6| Step: 13
Training loss: 2.728151049932008
Validation loss: 2.5395139372721105

Epoch: 161| Step: 0
Training loss: 2.1516969681705818
Validation loss: 2.536093583270853

Epoch: 6| Step: 1
Training loss: 2.183813094312307
Validation loss: 2.564619917712879

Epoch: 6| Step: 2
Training loss: 2.6640394103540275
Validation loss: 2.574487135536914

Epoch: 6| Step: 3
Training loss: 2.536316874878792
Validation loss: 2.569328310432703

Epoch: 6| Step: 4
Training loss: 2.235819636343358
Validation loss: 2.529919172062081

Epoch: 6| Step: 5
Training loss: 2.016210663158099
Validation loss: 2.502232435687809

Epoch: 6| Step: 6
Training loss: 2.676978874889835
Validation loss: 2.4998108658977833

Epoch: 6| Step: 7
Training loss: 2.060842483794304
Validation loss: 2.475803755763769

Epoch: 6| Step: 8
Training loss: 2.3014542999006626
Validation loss: 2.447875807261216

Epoch: 6| Step: 9
Training loss: 2.319201065157448
Validation loss: 2.440637211916586

Epoch: 6| Step: 10
Training loss: 2.428217501455543
Validation loss: 2.4372170691388546

Epoch: 6| Step: 11
Training loss: 2.3805492221011595
Validation loss: 2.452133281838641

Epoch: 6| Step: 12
Training loss: 3.0815973979729017
Validation loss: 2.454800286307038

Epoch: 6| Step: 13
Training loss: 2.626162407860976
Validation loss: 2.4631968866623706

Epoch: 162| Step: 0
Training loss: 2.7514318726534945
Validation loss: 2.4698261860838167

Epoch: 6| Step: 1
Training loss: 2.263484180163426
Validation loss: 2.4537426675373903

Epoch: 6| Step: 2
Training loss: 2.1344160263117558
Validation loss: 2.461298147698548

Epoch: 6| Step: 3
Training loss: 2.6647317442873026
Validation loss: 2.457929932324868

Epoch: 6| Step: 4
Training loss: 2.3103520495841274
Validation loss: 2.4870955258911054

Epoch: 6| Step: 5
Training loss: 2.183225324254756
Validation loss: 2.482842352681003

Epoch: 6| Step: 6
Training loss: 2.417006096077406
Validation loss: 2.4826199671075404

Epoch: 6| Step: 7
Training loss: 2.262912889605157
Validation loss: 2.461659384079694

Epoch: 6| Step: 8
Training loss: 2.3983104560331774
Validation loss: 2.489418212409784

Epoch: 6| Step: 9
Training loss: 2.7022140820315097
Validation loss: 2.4912419093504434

Epoch: 6| Step: 10
Training loss: 2.085448704288306
Validation loss: 2.490010517376711

Epoch: 6| Step: 11
Training loss: 2.4790823358463254
Validation loss: 2.5142014076049044

Epoch: 6| Step: 12
Training loss: 2.409425893758139
Validation loss: 2.5188674743025303

Epoch: 6| Step: 13
Training loss: 1.8028922791929458
Validation loss: 2.512979508360434

Epoch: 163| Step: 0
Training loss: 2.557901676140474
Validation loss: 2.5406611571940125

Epoch: 6| Step: 1
Training loss: 2.3374499269721896
Validation loss: 2.5522427302983544

Epoch: 6| Step: 2
Training loss: 2.37505320439224
Validation loss: 2.553670763580385

Epoch: 6| Step: 3
Training loss: 2.415171741831521
Validation loss: 2.584006961664298

Epoch: 6| Step: 4
Training loss: 2.1159686982808825
Validation loss: 2.5850588602633975

Epoch: 6| Step: 5
Training loss: 2.3135636435238816
Validation loss: 2.578730601868051

Epoch: 6| Step: 6
Training loss: 2.48488031202714
Validation loss: 2.548185704654878

Epoch: 6| Step: 7
Training loss: 2.605681403545381
Validation loss: 2.5285404104308875

Epoch: 6| Step: 8
Training loss: 1.9855666900132345
Validation loss: 2.534828615748775

Epoch: 6| Step: 9
Training loss: 1.9000331624801106
Validation loss: 2.5276680510511738

Epoch: 6| Step: 10
Training loss: 2.6478794826614953
Validation loss: 2.5155410074886886

Epoch: 6| Step: 11
Training loss: 2.406151707610944
Validation loss: 2.484055619114347

Epoch: 6| Step: 12
Training loss: 2.932276525283306
Validation loss: 2.4592743086523603

Epoch: 6| Step: 13
Training loss: 1.5274434947349622
Validation loss: 2.446548028690879

Epoch: 164| Step: 0
Training loss: 2.535725440033417
Validation loss: 2.4573458827431875

Epoch: 6| Step: 1
Training loss: 2.2876282452764096
Validation loss: 2.474426200075122

Epoch: 6| Step: 2
Training loss: 2.3882887650790536
Validation loss: 2.4595228205779103

Epoch: 6| Step: 3
Training loss: 2.3463641020761714
Validation loss: 2.488852610739659

Epoch: 6| Step: 4
Training loss: 2.4423853505459623
Validation loss: 2.49379950765242

Epoch: 6| Step: 5
Training loss: 2.563401412588943
Validation loss: 2.4902073726842877

Epoch: 6| Step: 6
Training loss: 1.7062057489379
Validation loss: 2.4877981691019215

Epoch: 6| Step: 7
Training loss: 2.0140259780117535
Validation loss: 2.497887772231504

Epoch: 6| Step: 8
Training loss: 2.266225169698587
Validation loss: 2.4890011558818923

Epoch: 6| Step: 9
Training loss: 2.5308198916627087
Validation loss: 2.4924362819146357

Epoch: 6| Step: 10
Training loss: 2.3973285708431398
Validation loss: 2.50873578195755

Epoch: 6| Step: 11
Training loss: 1.7773302014851051
Validation loss: 2.51117756924537

Epoch: 6| Step: 12
Training loss: 2.79607128337863
Validation loss: 2.4944627865204207

Epoch: 6| Step: 13
Training loss: 2.3947666170774458
Validation loss: 2.4916786551062793

Epoch: 165| Step: 0
Training loss: 2.7458649671601107
Validation loss: 2.4798074192247648

Epoch: 6| Step: 1
Training loss: 2.2188619665988347
Validation loss: 2.452930917998859

Epoch: 6| Step: 2
Training loss: 2.179253647808537
Validation loss: 2.461011369244047

Epoch: 6| Step: 3
Training loss: 2.041743011085242
Validation loss: 2.451040034680169

Epoch: 6| Step: 4
Training loss: 2.1081519077731468
Validation loss: 2.4534724214008614

Epoch: 6| Step: 5
Training loss: 2.5009881927565387
Validation loss: 2.4457224070157344

Epoch: 6| Step: 6
Training loss: 2.195998766733737
Validation loss: 2.428459602922229

Epoch: 6| Step: 7
Training loss: 2.0860586524098372
Validation loss: 2.458844521921719

Epoch: 6| Step: 8
Training loss: 2.066314176011677
Validation loss: 2.495736968687985

Epoch: 6| Step: 9
Training loss: 2.6466602224788796
Validation loss: 2.5359658707825035

Epoch: 6| Step: 10
Training loss: 1.8124080503094264
Validation loss: 2.5378190633737967

Epoch: 6| Step: 11
Training loss: 2.740055918575416
Validation loss: 2.53016732114078

Epoch: 6| Step: 12
Training loss: 2.4336580173095075
Validation loss: 2.528157771452929

Epoch: 6| Step: 13
Training loss: 1.987796207163906
Validation loss: 2.497807912732276

Epoch: 166| Step: 0
Training loss: 2.4835816082173126
Validation loss: 2.484854682507362

Epoch: 6| Step: 1
Training loss: 1.9474983650171276
Validation loss: 2.4920064432387465

Epoch: 6| Step: 2
Training loss: 2.1805276106267417
Validation loss: 2.49187823355041

Epoch: 6| Step: 3
Training loss: 2.137441899809451
Validation loss: 2.5135076089743174

Epoch: 6| Step: 4
Training loss: 2.163203320213738
Validation loss: 2.511715631845548

Epoch: 6| Step: 5
Training loss: 2.3046341194824436
Validation loss: 2.5223169251887607

Epoch: 6| Step: 6
Training loss: 2.370431823342272
Validation loss: 2.4946024966836555

Epoch: 6| Step: 7
Training loss: 2.3326658474918105
Validation loss: 2.503668208435386

Epoch: 6| Step: 8
Training loss: 2.2077924917816842
Validation loss: 2.493404040457925

Epoch: 6| Step: 9
Training loss: 2.064126731456473
Validation loss: 2.475610027312121

Epoch: 6| Step: 10
Training loss: 2.097522013824938
Validation loss: 2.4826249382081627

Epoch: 6| Step: 11
Training loss: 2.5576421700765355
Validation loss: 2.4928555702349007

Epoch: 6| Step: 12
Training loss: 2.6303318913712483
Validation loss: 2.478387105316379

Epoch: 6| Step: 13
Training loss: 1.8139077343171903
Validation loss: 2.4760878353156333

Epoch: 167| Step: 0
Training loss: 2.195471706930011
Validation loss: 2.499304069540309

Epoch: 6| Step: 1
Training loss: 2.0688965759903937
Validation loss: 2.4814179986181246

Epoch: 6| Step: 2
Training loss: 1.8882124459385692
Validation loss: 2.4529566448737925

Epoch: 6| Step: 3
Training loss: 2.4957925677486195
Validation loss: 2.4487011687683133

Epoch: 6| Step: 4
Training loss: 2.3876473825710813
Validation loss: 2.4466427995354163

Epoch: 6| Step: 5
Training loss: 2.1984170160376326
Validation loss: 2.4679143656258318

Epoch: 6| Step: 6
Training loss: 2.1281278814668796
Validation loss: 2.4689930466100654

Epoch: 6| Step: 7
Training loss: 2.099597565373764
Validation loss: 2.447133009567723

Epoch: 6| Step: 8
Training loss: 2.092711461547316
Validation loss: 2.426805766503739

Epoch: 6| Step: 9
Training loss: 2.655129140094665
Validation loss: 2.4399165376865795

Epoch: 6| Step: 10
Training loss: 2.308364572784163
Validation loss: 2.434406628351177

Epoch: 6| Step: 11
Training loss: 1.8723148828939475
Validation loss: 2.4387133943509123

Epoch: 6| Step: 12
Training loss: 2.4819339299656717
Validation loss: 2.4610687038580648

Epoch: 6| Step: 13
Training loss: 2.3999719339954924
Validation loss: 2.475061224201627

Epoch: 168| Step: 0
Training loss: 2.354062598524822
Validation loss: 2.4788730451253307

Epoch: 6| Step: 1
Training loss: 2.8919072786718214
Validation loss: 2.437507968045009

Epoch: 6| Step: 2
Training loss: 2.1770271281846276
Validation loss: 2.4387552790678915

Epoch: 6| Step: 3
Training loss: 2.468361739519559
Validation loss: 2.4255401061867365

Epoch: 6| Step: 4
Training loss: 2.491717925123907
Validation loss: 2.4273449698959193

Epoch: 6| Step: 5
Training loss: 2.1365041677343712
Validation loss: 2.411042268021572

Epoch: 6| Step: 6
Training loss: 1.8537234801789604
Validation loss: 2.4236339626740717

Epoch: 6| Step: 7
Training loss: 2.382654403694814
Validation loss: 2.448237908901729

Epoch: 6| Step: 8
Training loss: 1.392917928661825
Validation loss: 2.5130670161431974

Epoch: 6| Step: 9
Training loss: 2.4961936584441005
Validation loss: 2.5433017505183653

Epoch: 6| Step: 10
Training loss: 1.78218984069617
Validation loss: 2.654136193048466

Epoch: 6| Step: 11
Training loss: 1.955060564356699
Validation loss: 2.683068232191292

Epoch: 6| Step: 12
Training loss: 2.8481312631618136
Validation loss: 2.676658613598197

Epoch: 6| Step: 13
Training loss: 1.4313750599691317
Validation loss: 2.5857339512527617

Epoch: 169| Step: 0
Training loss: 2.3607951557462625
Validation loss: 2.502102729487413

Epoch: 6| Step: 1
Training loss: 2.007403499046317
Validation loss: 2.4488080882153564

Epoch: 6| Step: 2
Training loss: 2.3103444130838744
Validation loss: 2.4410437740198256

Epoch: 6| Step: 3
Training loss: 2.5040469792136264
Validation loss: 2.4499990437723205

Epoch: 6| Step: 4
Training loss: 2.278357880336163
Validation loss: 2.4634558154473924

Epoch: 6| Step: 5
Training loss: 1.9154534093477602
Validation loss: 2.469195972959348

Epoch: 6| Step: 6
Training loss: 2.0183671145311983
Validation loss: 2.4685187448893653

Epoch: 6| Step: 7
Training loss: 2.480302748043945
Validation loss: 2.4743218630334036

Epoch: 6| Step: 8
Training loss: 2.4490128572063403
Validation loss: 2.474990250937116

Epoch: 6| Step: 9
Training loss: 1.67494981320479
Validation loss: 2.49121146438588

Epoch: 6| Step: 10
Training loss: 2.0823535777040614
Validation loss: 2.474238275428589

Epoch: 6| Step: 11
Training loss: 2.219592082375948
Validation loss: 2.4786564036526673

Epoch: 6| Step: 12
Training loss: 2.2872915871321324
Validation loss: 2.4798405266518433

Epoch: 6| Step: 13
Training loss: 2.112248025346705
Validation loss: 2.4713138057620476

Epoch: 170| Step: 0
Training loss: 2.1430942744791746
Validation loss: 2.4519718914709663

Epoch: 6| Step: 1
Training loss: 2.0800302132833037
Validation loss: 2.4688398719463684

Epoch: 6| Step: 2
Training loss: 1.9624334457677777
Validation loss: 2.4788751993547025

Epoch: 6| Step: 3
Training loss: 1.9866189959372986
Validation loss: 2.4803378416125774

Epoch: 6| Step: 4
Training loss: 1.6248932583303457
Validation loss: 2.5060221066023916

Epoch: 6| Step: 5
Training loss: 2.1996195073979137
Validation loss: 2.5022459985296432

Epoch: 6| Step: 6
Training loss: 1.9891667221105551
Validation loss: 2.4867459988967187

Epoch: 6| Step: 7
Training loss: 1.698192698814395
Validation loss: 2.496364655513551

Epoch: 6| Step: 8
Training loss: 2.390347433494495
Validation loss: 2.5234922561030766

Epoch: 6| Step: 9
Training loss: 2.178136896131038
Validation loss: 2.5354931915860446

Epoch: 6| Step: 10
Training loss: 3.121819823486766
Validation loss: 2.5141292673820734

Epoch: 6| Step: 11
Training loss: 2.3059277317074405
Validation loss: 2.5101193021428423

Epoch: 6| Step: 12
Training loss: 2.1137509767066507
Validation loss: 2.522895582344419

Epoch: 6| Step: 13
Training loss: 2.186160958397837
Validation loss: 2.4951272925783186

Epoch: 171| Step: 0
Training loss: 1.8682860650178137
Validation loss: 2.4483588313969116

Epoch: 6| Step: 1
Training loss: 1.8515339780775584
Validation loss: 2.4225889378227095

Epoch: 6| Step: 2
Training loss: 2.2101240515091187
Validation loss: 2.394988034378788

Epoch: 6| Step: 3
Training loss: 2.724592923897467
Validation loss: 2.39706913524886

Epoch: 6| Step: 4
Training loss: 1.6713616126601831
Validation loss: 2.4153259551984956

Epoch: 6| Step: 5
Training loss: 2.431107477163698
Validation loss: 2.4121830847653665

Epoch: 6| Step: 6
Training loss: 2.479108975377665
Validation loss: 2.431150974486444

Epoch: 6| Step: 7
Training loss: 1.9785669589373354
Validation loss: 2.466742681209495

Epoch: 6| Step: 8
Training loss: 1.9070275393789433
Validation loss: 2.49323774914707

Epoch: 6| Step: 9
Training loss: 2.4318291648480606
Validation loss: 2.5524046490732633

Epoch: 6| Step: 10
Training loss: 2.2747141606104466
Validation loss: 2.556884761990422

Epoch: 6| Step: 11
Training loss: 2.098355366795941
Validation loss: 2.511495159836982

Epoch: 6| Step: 12
Training loss: 2.3250117640043864
Validation loss: 2.4496198654352446

Epoch: 6| Step: 13
Training loss: 1.780010059521142
Validation loss: 2.413232593987814

Epoch: 172| Step: 0
Training loss: 2.074035291586686
Validation loss: 2.3909199046377254

Epoch: 6| Step: 1
Training loss: 2.576051560282781
Validation loss: 2.3727047326063397

Epoch: 6| Step: 2
Training loss: 2.3744725093314516
Validation loss: 2.369788456242679

Epoch: 6| Step: 3
Training loss: 1.914232768056569
Validation loss: 2.371975412237084

Epoch: 6| Step: 4
Training loss: 1.9131878158291424
Validation loss: 2.3644655711607094

Epoch: 6| Step: 5
Training loss: 1.9706763274201635
Validation loss: 2.385168287693444

Epoch: 6| Step: 6
Training loss: 2.3069544101504684
Validation loss: 2.410583206183657

Epoch: 6| Step: 7
Training loss: 2.050768345383506
Validation loss: 2.451393781598211

Epoch: 6| Step: 8
Training loss: 2.1861711007784046
Validation loss: 2.510918559717092

Epoch: 6| Step: 9
Training loss: 2.2906486562051187
Validation loss: 2.564736175667555

Epoch: 6| Step: 10
Training loss: 1.7720359608034526
Validation loss: 2.6087383918038727

Epoch: 6| Step: 11
Training loss: 2.5377789348763704
Validation loss: 2.654380174002071

Epoch: 6| Step: 12
Training loss: 1.392160532269518
Validation loss: 2.6948203026376722

Epoch: 6| Step: 13
Training loss: 2.4895424513605837
Validation loss: 2.68074732637191

Epoch: 173| Step: 0
Training loss: 2.0156494848848965
Validation loss: 2.6606886027779026

Epoch: 6| Step: 1
Training loss: 1.9335422085144491
Validation loss: 2.5933837918736353

Epoch: 6| Step: 2
Training loss: 2.185639380303261
Validation loss: 2.5214940266933503

Epoch: 6| Step: 3
Training loss: 2.102604830891943
Validation loss: 2.4873720153972183

Epoch: 6| Step: 4
Training loss: 2.141253525285107
Validation loss: 2.456064836388999

Epoch: 6| Step: 5
Training loss: 2.8487588555741103
Validation loss: 2.4399874531641697

Epoch: 6| Step: 6
Training loss: 1.880496931954447
Validation loss: 2.4279068253065503

Epoch: 6| Step: 7
Training loss: 2.4086230577831937
Validation loss: 2.396783568779727

Epoch: 6| Step: 8
Training loss: 1.7598677763255186
Validation loss: 2.395073558792607

Epoch: 6| Step: 9
Training loss: 2.5618263847910865
Validation loss: 2.390791649465249

Epoch: 6| Step: 10
Training loss: 2.206843815499203
Validation loss: 2.3996309736296535

Epoch: 6| Step: 11
Training loss: 1.7300785218869492
Validation loss: 2.4195160639445166

Epoch: 6| Step: 12
Training loss: 1.736630940072885
Validation loss: 2.451372732912773

Epoch: 6| Step: 13
Training loss: 2.135010086678971
Validation loss: 2.511363005355737

Epoch: 174| Step: 0
Training loss: 1.6508451840268838
Validation loss: 2.5827740895202007

Epoch: 6| Step: 1
Training loss: 2.2210910964826525
Validation loss: 2.6527976061978276

Epoch: 6| Step: 2
Training loss: 2.2977436525076422
Validation loss: 2.6659904742332627

Epoch: 6| Step: 3
Training loss: 2.2989193907116956
Validation loss: 2.6692784546333876

Epoch: 6| Step: 4
Training loss: 1.7392437616773473
Validation loss: 2.626796468063402

Epoch: 6| Step: 5
Training loss: 2.1087284934095325
Validation loss: 2.5183901546319754

Epoch: 6| Step: 6
Training loss: 2.150693063143941
Validation loss: 2.4566948830629918

Epoch: 6| Step: 7
Training loss: 1.9476641186961863
Validation loss: 2.41826482241048

Epoch: 6| Step: 8
Training loss: 2.28290236738108
Validation loss: 2.4020652184673468

Epoch: 6| Step: 9
Training loss: 1.9049395450000455
Validation loss: 2.3753254499606316

Epoch: 6| Step: 10
Training loss: 2.454346176689282
Validation loss: 2.4014950219862494

Epoch: 6| Step: 11
Training loss: 2.084445376830897
Validation loss: 2.4039430414651894

Epoch: 6| Step: 12
Training loss: 2.2110714282122905
Validation loss: 2.4128653006868626

Epoch: 6| Step: 13
Training loss: 2.524495945087636
Validation loss: 2.4394544922308343

Epoch: 175| Step: 0
Training loss: 2.278138638679274
Validation loss: 2.529383294257273

Epoch: 6| Step: 1
Training loss: 1.0742206365395366
Validation loss: 2.6036355311695676

Epoch: 6| Step: 2
Training loss: 2.110810420166343
Validation loss: 2.6941714232174188

Epoch: 6| Step: 3
Training loss: 2.162589883865718
Validation loss: 2.773762303001828

Epoch: 6| Step: 4
Training loss: 2.3338713933820707
Validation loss: 2.805844001351983

Epoch: 6| Step: 5
Training loss: 2.288294536412648
Validation loss: 2.8356371645146985

Epoch: 6| Step: 6
Training loss: 2.2324389626423895
Validation loss: 2.734612219580268

Epoch: 6| Step: 7
Training loss: 1.604123333762674
Validation loss: 2.6361879245420194

Epoch: 6| Step: 8
Training loss: 1.8457456876499518
Validation loss: 2.5523105017131895

Epoch: 6| Step: 9
Training loss: 2.206751226704655
Validation loss: 2.4764432233023235

Epoch: 6| Step: 10
Training loss: 2.282602196836204
Validation loss: 2.439733351369973

Epoch: 6| Step: 11
Training loss: 2.3409390695913173
Validation loss: 2.420027993871764

Epoch: 6| Step: 12
Training loss: 1.7082178805656294
Validation loss: 2.4027475448057203

Epoch: 6| Step: 13
Training loss: 2.4329044351620355
Validation loss: 2.395789149136869

Epoch: 176| Step: 0
Training loss: 2.449198307517858
Validation loss: 2.397307694969396

Epoch: 6| Step: 1
Training loss: 2.441527536049829
Validation loss: 2.391702726338906

Epoch: 6| Step: 2
Training loss: 2.319151719657751
Validation loss: 2.4009621002642887

Epoch: 6| Step: 3
Training loss: 2.3088990088738637
Validation loss: 2.41097315468151

Epoch: 6| Step: 4
Training loss: 2.0073688180135716
Validation loss: 2.430191333355912

Epoch: 6| Step: 5
Training loss: 2.2088120019713062
Validation loss: 2.470718078036254

Epoch: 6| Step: 6
Training loss: 1.7638452387671122
Validation loss: 2.4889544032700206

Epoch: 6| Step: 7
Training loss: 2.089804618683
Validation loss: 2.5482672831536295

Epoch: 6| Step: 8
Training loss: 1.8632088253252825
Validation loss: 2.5809447360100815

Epoch: 6| Step: 9
Training loss: 1.6293588279445401
Validation loss: 2.6026754115338377

Epoch: 6| Step: 10
Training loss: 2.0789022497965086
Validation loss: 2.614269653677415

Epoch: 6| Step: 11
Training loss: 2.122842141872038
Validation loss: 2.610235107724353

Epoch: 6| Step: 12
Training loss: 2.2156653654782317
Validation loss: 2.5659306079911524

Epoch: 6| Step: 13
Training loss: 1.5730075767805083
Validation loss: 2.5420501482898095

Epoch: 177| Step: 0
Training loss: 1.9526913581104062
Validation loss: 2.528843232652819

Epoch: 6| Step: 1
Training loss: 2.0180943466604093
Validation loss: 2.529580641770944

Epoch: 6| Step: 2
Training loss: 2.27659340695443
Validation loss: 2.5492339305942275

Epoch: 6| Step: 3
Training loss: 2.410107381810593
Validation loss: 2.554807591589307

Epoch: 6| Step: 4
Training loss: 1.1108609308609776
Validation loss: 2.5081882583118267

Epoch: 6| Step: 5
Training loss: 1.5042175763391987
Validation loss: 2.459426654141314

Epoch: 6| Step: 6
Training loss: 2.3691522986367386
Validation loss: 2.4256693781683323

Epoch: 6| Step: 7
Training loss: 1.9467741595706967
Validation loss: 2.4388085295629205

Epoch: 6| Step: 8
Training loss: 2.5604004050582425
Validation loss: 2.4219158506570393

Epoch: 6| Step: 9
Training loss: 1.8170035087874885
Validation loss: 2.447959717996198

Epoch: 6| Step: 10
Training loss: 2.313487177285431
Validation loss: 2.4619394487122057

Epoch: 6| Step: 11
Training loss: 2.2938898111501
Validation loss: 2.4525186993737567

Epoch: 6| Step: 12
Training loss: 1.8522978662336969
Validation loss: 2.450266735071587

Epoch: 6| Step: 13
Training loss: 1.8727572060984772
Validation loss: 2.4556451428018007

Epoch: 178| Step: 0
Training loss: 2.0668992029646884
Validation loss: 2.451988689098016

Epoch: 6| Step: 1
Training loss: 1.6896477912369805
Validation loss: 2.5132220192446195

Epoch: 6| Step: 2
Training loss: 2.0694259184734207
Validation loss: 2.613331319989418

Epoch: 6| Step: 3
Training loss: 1.835894255433185
Validation loss: 2.6719170426560277

Epoch: 6| Step: 4
Training loss: 2.204675223723905
Validation loss: 2.7088049794247664

Epoch: 6| Step: 5
Training loss: 2.0749857430944942
Validation loss: 2.754739346729205

Epoch: 6| Step: 6
Training loss: 1.9990667907754667
Validation loss: 2.689433970928159

Epoch: 6| Step: 7
Training loss: 1.9895106863236733
Validation loss: 2.611390981015036

Epoch: 6| Step: 8
Training loss: 1.8950448824516921
Validation loss: 2.518380852423043

Epoch: 6| Step: 9
Training loss: 1.640737402562296
Validation loss: 2.4558907671655614

Epoch: 6| Step: 10
Training loss: 2.263065128456264
Validation loss: 2.4148852490823822

Epoch: 6| Step: 11
Training loss: 2.2410165739863666
Validation loss: 2.4066177852055675

Epoch: 6| Step: 12
Training loss: 1.9700043935775173
Validation loss: 2.406459067863799

Epoch: 6| Step: 13
Training loss: 2.5645743557121836
Validation loss: 2.4050666937028207

Epoch: 179| Step: 0
Training loss: 1.8451105044387146
Validation loss: 2.3869960838541204

Epoch: 6| Step: 1
Training loss: 2.3247802056227953
Validation loss: 2.3842056927365767

Epoch: 6| Step: 2
Training loss: 2.012871687785398
Validation loss: 2.386218440862734

Epoch: 6| Step: 3
Training loss: 2.440951129453811
Validation loss: 2.3969647497164797

Epoch: 6| Step: 4
Training loss: 2.1143762145685896
Validation loss: 2.424546510736937

Epoch: 6| Step: 5
Training loss: 1.9326760320200778
Validation loss: 2.477786038454854

Epoch: 6| Step: 6
Training loss: 2.0177618720402863
Validation loss: 2.560989448889235

Epoch: 6| Step: 7
Training loss: 1.852882912376035
Validation loss: 2.6520506129152164

Epoch: 6| Step: 8
Training loss: 2.041357159672145
Validation loss: 2.6791085228511258

Epoch: 6| Step: 9
Training loss: 2.4183572139739575
Validation loss: 2.6724174748550173

Epoch: 6| Step: 10
Training loss: 2.0267723616009548
Validation loss: 2.6030620291237057

Epoch: 6| Step: 11
Training loss: 1.8267146481990075
Validation loss: 2.554910617495707

Epoch: 6| Step: 12
Training loss: 1.3679793762108032
Validation loss: 2.4909443539416434

Epoch: 6| Step: 13
Training loss: 2.536939091066679
Validation loss: 2.459759398879023

Epoch: 180| Step: 0
Training loss: 2.1423631280291553
Validation loss: 2.438991100018811

Epoch: 6| Step: 1
Training loss: 1.8521713350355558
Validation loss: 2.4332757784006493

Epoch: 6| Step: 2
Training loss: 1.9677058281654525
Validation loss: 2.455933558321599

Epoch: 6| Step: 3
Training loss: 2.2599570045769943
Validation loss: 2.4735739564242993

Epoch: 6| Step: 4
Training loss: 2.141888878818825
Validation loss: 2.4659576834556143

Epoch: 6| Step: 5
Training loss: 1.930630349312062
Validation loss: 2.4869276169726615

Epoch: 6| Step: 6
Training loss: 1.9175799377768536
Validation loss: 2.4915680973405294

Epoch: 6| Step: 7
Training loss: 1.662061607669586
Validation loss: 2.5281733657431142

Epoch: 6| Step: 8
Training loss: 1.5716964165200302
Validation loss: 2.5532274442025424

Epoch: 6| Step: 9
Training loss: 2.749258895195001
Validation loss: 2.605464080187952

Epoch: 6| Step: 10
Training loss: 1.9137691350836135
Validation loss: 2.6295964323119274

Epoch: 6| Step: 11
Training loss: 1.7860288928686174
Validation loss: 2.5920590011902287

Epoch: 6| Step: 12
Training loss: 2.1091188628487756
Validation loss: 2.5805037814490643

Epoch: 6| Step: 13
Training loss: 1.7346579518496323
Validation loss: 2.5028744651552945

Epoch: 181| Step: 0
Training loss: 1.9697475630813748
Validation loss: 2.482523831302664

Epoch: 6| Step: 1
Training loss: 1.9488939767715774
Validation loss: 2.4363871743178214

Epoch: 6| Step: 2
Training loss: 2.0233143654844956
Validation loss: 2.4264891716359154

Epoch: 6| Step: 3
Training loss: 2.191730006164508
Validation loss: 2.434576104079176

Epoch: 6| Step: 4
Training loss: 1.6799357386060776
Validation loss: 2.4123023607043472

Epoch: 6| Step: 5
Training loss: 1.703776453698623
Validation loss: 2.429446236347444

Epoch: 6| Step: 6
Training loss: 1.7888250068383804
Validation loss: 2.4396003790293945

Epoch: 6| Step: 7
Training loss: 2.079144450077269
Validation loss: 2.4240025538399896

Epoch: 6| Step: 8
Training loss: 1.892912182688904
Validation loss: 2.4419576987678986

Epoch: 6| Step: 9
Training loss: 2.0853192845592465
Validation loss: 2.464688047865214

Epoch: 6| Step: 10
Training loss: 1.4289293624151673
Validation loss: 2.5010626657085346

Epoch: 6| Step: 11
Training loss: 2.4418386335865003
Validation loss: 2.545506826364802

Epoch: 6| Step: 12
Training loss: 2.038525506996609
Validation loss: 2.5747261541314717

Epoch: 6| Step: 13
Training loss: 1.3178819484200068
Validation loss: 2.6039534240702475

Epoch: 182| Step: 0
Training loss: 1.967388832994238
Validation loss: 2.623794313931344

Epoch: 6| Step: 1
Training loss: 2.247868694068113
Validation loss: 2.652995761690227

Epoch: 6| Step: 2
Training loss: 2.313382985391128
Validation loss: 2.649957796760272

Epoch: 6| Step: 3
Training loss: 2.079655363435024
Validation loss: 2.5795463564293497

Epoch: 6| Step: 4
Training loss: 2.090891010598277
Validation loss: 2.5123880909054113

Epoch: 6| Step: 5
Training loss: 1.6172104985909934
Validation loss: 2.455827655817478

Epoch: 6| Step: 6
Training loss: 1.5381334473069115
Validation loss: 2.425054113209072

Epoch: 6| Step: 7
Training loss: 1.7146212144501065
Validation loss: 2.4002679844413426

Epoch: 6| Step: 8
Training loss: 2.4700111354932086
Validation loss: 2.4009216928505532

Epoch: 6| Step: 9
Training loss: 1.9043913988960381
Validation loss: 2.404046568941279

Epoch: 6| Step: 10
Training loss: 1.8702008818780058
Validation loss: 2.413551276170212

Epoch: 6| Step: 11
Training loss: 1.65465180644008
Validation loss: 2.4420695167586506

Epoch: 6| Step: 12
Training loss: 1.7784227386757527
Validation loss: 2.483525500433166

Epoch: 6| Step: 13
Training loss: 1.371020192838582
Validation loss: 2.5363974968955914

Epoch: 183| Step: 0
Training loss: 1.6415441209137123
Validation loss: 2.5947832504918926

Epoch: 6| Step: 1
Training loss: 1.6541483518545843
Validation loss: 2.630549452445776

Epoch: 6| Step: 2
Training loss: 2.5846294310121705
Validation loss: 2.7177283197033097

Epoch: 6| Step: 3
Training loss: 2.2034938855139385
Validation loss: 2.7333699722395552

Epoch: 6| Step: 4
Training loss: 1.5594920387761997
Validation loss: 2.7738051803230035

Epoch: 6| Step: 5
Training loss: 1.5357640739937397
Validation loss: 2.770947002442053

Epoch: 6| Step: 6
Training loss: 2.1891980801078175
Validation loss: 2.748392019072943

Epoch: 6| Step: 7
Training loss: 1.760678747708868
Validation loss: 2.6576918557059015

Epoch: 6| Step: 8
Training loss: 1.681478707452379
Validation loss: 2.605538743044719

Epoch: 6| Step: 9
Training loss: 2.185060285002837
Validation loss: 2.525118644572397

Epoch: 6| Step: 10
Training loss: 1.6742138056608629
Validation loss: 2.48245070417571

Epoch: 6| Step: 11
Training loss: 2.1414599495758044
Validation loss: 2.450874463073017

Epoch: 6| Step: 12
Training loss: 1.771891453580807
Validation loss: 2.425378033377913

Epoch: 6| Step: 13
Training loss: 1.5998293547229963
Validation loss: 2.403573476939776

Epoch: 184| Step: 0
Training loss: 2.074107366470035
Validation loss: 2.3628617987955516

Epoch: 6| Step: 1
Training loss: 2.0823282742077294
Validation loss: 2.353273304071367

Epoch: 6| Step: 2
Training loss: 1.7047061405159234
Validation loss: 2.344532792821492

Epoch: 6| Step: 3
Training loss: 1.6613633020023748
Validation loss: 2.363039820926

Epoch: 6| Step: 4
Training loss: 2.6027163217952705
Validation loss: 2.363045296364536

Epoch: 6| Step: 5
Training loss: 1.6631275828103844
Validation loss: 2.3845022293470644

Epoch: 6| Step: 6
Training loss: 1.8837547002479322
Validation loss: 2.3982842723003737

Epoch: 6| Step: 7
Training loss: 2.147566629248785
Validation loss: 2.4216896930979135

Epoch: 6| Step: 8
Training loss: 1.8959952763848675
Validation loss: 2.45032165003096

Epoch: 6| Step: 9
Training loss: 1.862657550574195
Validation loss: 2.499659306887064

Epoch: 6| Step: 10
Training loss: 1.512540451013307
Validation loss: 2.570084028415694

Epoch: 6| Step: 11
Training loss: 1.351034028034876
Validation loss: 2.6350327325222227

Epoch: 6| Step: 12
Training loss: 2.093131700005548
Validation loss: 2.7095305630812025

Epoch: 6| Step: 13
Training loss: 2.0304946668790147
Validation loss: 2.7107646929970888

Epoch: 185| Step: 0
Training loss: 1.9388823346364543
Validation loss: 2.6964608690906977

Epoch: 6| Step: 1
Training loss: 1.3698052331907742
Validation loss: 2.6525849171645093

Epoch: 6| Step: 2
Training loss: 2.122078851225343
Validation loss: 2.5856993046016012

Epoch: 6| Step: 3
Training loss: 2.2704862860202666
Validation loss: 2.5227582316915096

Epoch: 6| Step: 4
Training loss: 1.473945680525787
Validation loss: 2.4537891737402227

Epoch: 6| Step: 5
Training loss: 1.614230562454322
Validation loss: 2.4183575023144095

Epoch: 6| Step: 6
Training loss: 1.7696923862546772
Validation loss: 2.393250752791695

Epoch: 6| Step: 7
Training loss: 2.283286244076221
Validation loss: 2.3666844658772304

Epoch: 6| Step: 8
Training loss: 1.8094987685280262
Validation loss: 2.38088200431449

Epoch: 6| Step: 9
Training loss: 1.7513693492880742
Validation loss: 2.400463357499341

Epoch: 6| Step: 10
Training loss: 1.6245087101010989
Validation loss: 2.4322677789960707

Epoch: 6| Step: 11
Training loss: 2.5488529131038415
Validation loss: 2.4853211877279775

Epoch: 6| Step: 12
Training loss: 1.5913115153442419
Validation loss: 2.5323078806582933

Epoch: 6| Step: 13
Training loss: 1.9612126252385955
Validation loss: 2.582025878527341

Epoch: 186| Step: 0
Training loss: 1.4459938711403193
Validation loss: 2.6546279481142037

Epoch: 6| Step: 1
Training loss: 1.7054157075833438
Validation loss: 2.71502052381408

Epoch: 6| Step: 2
Training loss: 2.061439357038621
Validation loss: 2.7090725523338075

Epoch: 6| Step: 3
Training loss: 1.7096928637446065
Validation loss: 2.6760308113603335

Epoch: 6| Step: 4
Training loss: 1.9588846959077433
Validation loss: 2.6612766196531124

Epoch: 6| Step: 5
Training loss: 1.7291157343460448
Validation loss: 2.621786581505075

Epoch: 6| Step: 6
Training loss: 1.7043886309065706
Validation loss: 2.576520828543595

Epoch: 6| Step: 7
Training loss: 1.925308014638933
Validation loss: 2.566518816094184

Epoch: 6| Step: 8
Training loss: 2.1280132695694984
Validation loss: 2.526225345294779

Epoch: 6| Step: 9
Training loss: 1.9809196004135585
Validation loss: 2.503279819247796

Epoch: 6| Step: 10
Training loss: 1.6130007299053812
Validation loss: 2.4853692547284703

Epoch: 6| Step: 11
Training loss: 2.534928557011825
Validation loss: 2.486294830717744

Epoch: 6| Step: 12
Training loss: 1.5788879061260441
Validation loss: 2.468745298992524

Epoch: 6| Step: 13
Training loss: 2.101244593970194
Validation loss: 2.4658420747868592

Epoch: 187| Step: 0
Training loss: 1.3248210426253464
Validation loss: 2.464451025197576

Epoch: 6| Step: 1
Training loss: 1.5997818142421583
Validation loss: 2.4709648123765846

Epoch: 6| Step: 2
Training loss: 1.678492915279742
Validation loss: 2.452536280890719

Epoch: 6| Step: 3
Training loss: 2.0777280041087227
Validation loss: 2.482145547778415

Epoch: 6| Step: 4
Training loss: 1.9538109147136273
Validation loss: 2.4904772745823682

Epoch: 6| Step: 5
Training loss: 1.3702494312070137
Validation loss: 2.472968745514972

Epoch: 6| Step: 6
Training loss: 1.8015339037700915
Validation loss: 2.526859357039337

Epoch: 6| Step: 7
Training loss: 1.9144518397867294
Validation loss: 2.545814562654954

Epoch: 6| Step: 8
Training loss: 1.9203586954592817
Validation loss: 2.5738371282467574

Epoch: 6| Step: 9
Training loss: 1.8547774462594124
Validation loss: 2.591053012853529

Epoch: 6| Step: 10
Training loss: 1.8547945423940164
Validation loss: 2.610412526969324

Epoch: 6| Step: 11
Training loss: 1.3996670395142858
Validation loss: 2.607959758723511

Epoch: 6| Step: 12
Training loss: 1.9816232059013201
Validation loss: 2.611530416106479

Epoch: 6| Step: 13
Training loss: 2.457064532856601
Validation loss: 2.610860875939909

Epoch: 188| Step: 0
Training loss: 1.4096037820672207
Validation loss: 2.5721387796144595

Epoch: 6| Step: 1
Training loss: 1.9118981405443374
Validation loss: 2.5665856611762305

Epoch: 6| Step: 2
Training loss: 2.017618066294508
Validation loss: 2.5343038685612624

Epoch: 6| Step: 3
Training loss: 1.5921697823359453
Validation loss: 2.5084128596733155

Epoch: 6| Step: 4
Training loss: 2.044550733579129
Validation loss: 2.4723690127720417

Epoch: 6| Step: 5
Training loss: 1.752598468228996
Validation loss: 2.4882606586244296

Epoch: 6| Step: 6
Training loss: 1.9469164015774907
Validation loss: 2.464914197935432

Epoch: 6| Step: 7
Training loss: 1.851181892517637
Validation loss: 2.475479879476088

Epoch: 6| Step: 8
Training loss: 1.7376232487717933
Validation loss: 2.4902078462490973

Epoch: 6| Step: 9
Training loss: 1.7504654674027649
Validation loss: 2.4945432566822214

Epoch: 6| Step: 10
Training loss: 1.5419929605860159
Validation loss: 2.5552585366634166

Epoch: 6| Step: 11
Training loss: 2.1138264345937103
Validation loss: 2.5607431333291784

Epoch: 6| Step: 12
Training loss: 1.6563552247216315
Validation loss: 2.5901230460851035

Epoch: 6| Step: 13
Training loss: 1.061899239733257
Validation loss: 2.621573141650349

Epoch: 189| Step: 0
Training loss: 1.8967268029631297
Validation loss: 2.6301256951250838

Epoch: 6| Step: 1
Training loss: 1.5632330128759326
Validation loss: 2.617580838155373

Epoch: 6| Step: 2
Training loss: 1.5495155992685936
Validation loss: 2.622843256290272

Epoch: 6| Step: 3
Training loss: 1.658189034374025
Validation loss: 2.609781003896955

Epoch: 6| Step: 4
Training loss: 1.5736948660842474
Validation loss: 2.5652380450757954

Epoch: 6| Step: 5
Training loss: 1.5947472687198676
Validation loss: 2.528800158628601

Epoch: 6| Step: 6
Training loss: 1.8343405413274867
Validation loss: 2.5092023222843083

Epoch: 6| Step: 7
Training loss: 1.8566891802524865
Validation loss: 2.499391540192472

Epoch: 6| Step: 8
Training loss: 1.991641459711192
Validation loss: 2.503115954829627

Epoch: 6| Step: 9
Training loss: 1.9190058807831587
Validation loss: 2.481608978734623

Epoch: 6| Step: 10
Training loss: 2.1057737904463436
Validation loss: 2.4750803996849533

Epoch: 6| Step: 11
Training loss: 1.831291781524946
Validation loss: 2.5080324452907155

Epoch: 6| Step: 12
Training loss: 1.6060360836569199
Validation loss: 2.513061802282685

Epoch: 6| Step: 13
Training loss: 1.5288946760438342
Validation loss: 2.488812226303163

Epoch: 190| Step: 0
Training loss: 1.7077682615031697
Validation loss: 2.5170596788356043

Epoch: 6| Step: 1
Training loss: 1.8780497861200347
Validation loss: 2.5353411072680565

Epoch: 6| Step: 2
Training loss: 1.6382561430237426
Validation loss: 2.517986280082781

Epoch: 6| Step: 3
Training loss: 1.9323949931881128
Validation loss: 2.5074123487179154

Epoch: 6| Step: 4
Training loss: 1.4351213927544695
Validation loss: 2.507649557438548

Epoch: 6| Step: 5
Training loss: 1.7881722046622388
Validation loss: 2.522381347817385

Epoch: 6| Step: 6
Training loss: 1.6276792300399119
Validation loss: 2.54230574816075

Epoch: 6| Step: 7
Training loss: 1.1275356116242878
Validation loss: 2.5475422005207875

Epoch: 6| Step: 8
Training loss: 2.1902627120235287
Validation loss: 2.542348875709994

Epoch: 6| Step: 9
Training loss: 1.4755948241273602
Validation loss: 2.533789165944528

Epoch: 6| Step: 10
Training loss: 1.898545250366182
Validation loss: 2.508084785063776

Epoch: 6| Step: 11
Training loss: 1.9516855046866801
Validation loss: 2.468870234543834

Epoch: 6| Step: 12
Training loss: 1.5846546415376372
Validation loss: 2.4509500989314645

Epoch: 6| Step: 13
Training loss: 1.8807385684123201
Validation loss: 2.4481232729829867

Epoch: 191| Step: 0
Training loss: 1.525285587772853
Validation loss: 2.4402771214965817

Epoch: 6| Step: 1
Training loss: 2.105262080932643
Validation loss: 2.454153192002178

Epoch: 6| Step: 2
Training loss: 1.6689040980822059
Validation loss: 2.4803408586461195

Epoch: 6| Step: 3
Training loss: 1.9357263383706302
Validation loss: 2.486905412439875

Epoch: 6| Step: 4
Training loss: 1.5902677903100033
Validation loss: 2.4765411693828914

Epoch: 6| Step: 5
Training loss: 1.7871429940485337
Validation loss: 2.5001218478954796

Epoch: 6| Step: 6
Training loss: 2.24074090421108
Validation loss: 2.5025362122047428

Epoch: 6| Step: 7
Training loss: 1.594622354554143
Validation loss: 2.5080534539046186

Epoch: 6| Step: 8
Training loss: 1.1771041170609053
Validation loss: 2.4844455132410075

Epoch: 6| Step: 9
Training loss: 2.1165536304638923
Validation loss: 2.5166205294456745

Epoch: 6| Step: 10
Training loss: 1.5940192500044552
Validation loss: 2.541945192221573

Epoch: 6| Step: 11
Training loss: 1.4338841780757134
Validation loss: 2.5292216988013245

Epoch: 6| Step: 12
Training loss: 1.4615424224668567
Validation loss: 2.566358556007866

Epoch: 6| Step: 13
Training loss: 1.21278314528882
Validation loss: 2.544242639490688

Epoch: 192| Step: 0
Training loss: 1.4457526284302287
Validation loss: 2.586683319860352

Epoch: 6| Step: 1
Training loss: 1.7173567239894105
Validation loss: 2.576860443262984

Epoch: 6| Step: 2
Training loss: 1.4754691945618357
Validation loss: 2.5448777635348105

Epoch: 6| Step: 3
Training loss: 1.7780709927205998
Validation loss: 2.578625663403566

Epoch: 6| Step: 4
Training loss: 1.6241792660272292
Validation loss: 2.5314204549677

Epoch: 6| Step: 5
Training loss: 1.7526234308764543
Validation loss: 2.547204780982612

Epoch: 6| Step: 6
Training loss: 1.7320035926217752
Validation loss: 2.516351126124864

Epoch: 6| Step: 7
Training loss: 1.7934028581994887
Validation loss: 2.5191180431620377

Epoch: 6| Step: 8
Training loss: 1.9093802344317572
Validation loss: 2.5209088342584662

Epoch: 6| Step: 9
Training loss: 1.32969877460151
Validation loss: 2.5139249961718186

Epoch: 6| Step: 10
Training loss: 1.6783191874014325
Validation loss: 2.5211491750909256

Epoch: 6| Step: 11
Training loss: 1.5279920524070922
Validation loss: 2.5057792825653675

Epoch: 6| Step: 12
Training loss: 2.0832325974587538
Validation loss: 2.5075430924848305

Epoch: 6| Step: 13
Training loss: 1.6746202550827816
Validation loss: 2.537308719274729

Epoch: 193| Step: 0
Training loss: 1.662224340889397
Validation loss: 2.533597764083509

Epoch: 6| Step: 1
Training loss: 1.6140205961329028
Validation loss: 2.529393791508135

Epoch: 6| Step: 2
Training loss: 2.012756909386163
Validation loss: 2.563437170676284

Epoch: 6| Step: 3
Training loss: 1.8515510397769677
Validation loss: 2.5656979182812005

Epoch: 6| Step: 4
Training loss: 1.037532511741749
Validation loss: 2.5443748121789267

Epoch: 6| Step: 5
Training loss: 1.6564179821118892
Validation loss: 2.5752008575019256

Epoch: 6| Step: 6
Training loss: 0.9388298139916453
Validation loss: 2.552869925074671

Epoch: 6| Step: 7
Training loss: 1.9102071743595272
Validation loss: 2.585712417736995

Epoch: 6| Step: 8
Training loss: 1.7608226180153008
Validation loss: 2.5708827066266697

Epoch: 6| Step: 9
Training loss: 1.8428110220936993
Validation loss: 2.581240897865399

Epoch: 6| Step: 10
Training loss: 1.5935745890707491
Validation loss: 2.5777471708621893

Epoch: 6| Step: 11
Training loss: 1.9265026420458318
Validation loss: 2.574440606972256

Epoch: 6| Step: 12
Training loss: 1.678283956660663
Validation loss: 2.566983733977697

Epoch: 6| Step: 13
Training loss: 1.6469471779918556
Validation loss: 2.560572208446828

Epoch: 194| Step: 0
Training loss: 1.5342601849704458
Validation loss: 2.5560466122321377

Epoch: 6| Step: 1
Training loss: 1.7964795548220287
Validation loss: 2.5723062579743607

Epoch: 6| Step: 2
Training loss: 1.5750610521381851
Validation loss: 2.526295120688665

Epoch: 6| Step: 3
Training loss: 1.8239796255086376
Validation loss: 2.516836919148284

Epoch: 6| Step: 4
Training loss: 1.2789964162912038
Validation loss: 2.5130866963034033

Epoch: 6| Step: 5
Training loss: 1.6261094047648357
Validation loss: 2.5051797264795077

Epoch: 6| Step: 6
Training loss: 1.6215913675252536
Validation loss: 2.5214464185670753

Epoch: 6| Step: 7
Training loss: 1.322008522089904
Validation loss: 2.5384787510210565

Epoch: 6| Step: 8
Training loss: 2.1045341044984447
Validation loss: 2.533648888694417

Epoch: 6| Step: 9
Training loss: 1.6975067985746848
Validation loss: 2.539135369579602

Epoch: 6| Step: 10
Training loss: 1.4163004832011532
Validation loss: 2.527813276213446

Epoch: 6| Step: 11
Training loss: 2.0125288730232413
Validation loss: 2.5260212545497316

Epoch: 6| Step: 12
Training loss: 1.4093022600505953
Validation loss: 2.5160723944227357

Epoch: 6| Step: 13
Training loss: 1.9098589145021216
Validation loss: 2.508987287553349

Epoch: 195| Step: 0
Training loss: 1.3398975773000035
Validation loss: 2.5264752108034556

Epoch: 6| Step: 1
Training loss: 1.7484457743621933
Validation loss: 2.563199269756766

Epoch: 6| Step: 2
Training loss: 1.7807386902558846
Validation loss: 2.604052086719277

Epoch: 6| Step: 3
Training loss: 1.70914905735556
Validation loss: 2.60494685408095

Epoch: 6| Step: 4
Training loss: 1.7818698808321547
Validation loss: 2.636251738894722

Epoch: 6| Step: 5
Training loss: 2.157602853279363
Validation loss: 2.637001926251416

Epoch: 6| Step: 6
Training loss: 1.8875763959771334
Validation loss: 2.6264337061152956

Epoch: 6| Step: 7
Training loss: 1.027913330922141
Validation loss: 2.5915031125364587

Epoch: 6| Step: 8
Training loss: 1.5856454514570526
Validation loss: 2.552015362341487

Epoch: 6| Step: 9
Training loss: 1.5232543052663836
Validation loss: 2.5545944844696042

Epoch: 6| Step: 10
Training loss: 1.308467574228344
Validation loss: 2.502533719796944

Epoch: 6| Step: 11
Training loss: 1.5808660289793093
Validation loss: 2.490225890030743

Epoch: 6| Step: 12
Training loss: 1.422230015963485
Validation loss: 2.4895321485526853

Epoch: 6| Step: 13
Training loss: 2.181114577322328
Validation loss: 2.480275609696893

Epoch: 196| Step: 0
Training loss: 1.663992078840219
Validation loss: 2.521711509922952

Epoch: 6| Step: 1
Training loss: 1.6917667136964147
Validation loss: 2.5487027233723896

Epoch: 6| Step: 2
Training loss: 1.8768166959880113
Validation loss: 2.5672882997192565

Epoch: 6| Step: 3
Training loss: 1.5186795002465117
Validation loss: 2.6128763678930222

Epoch: 6| Step: 4
Training loss: 1.7944866727906457
Validation loss: 2.6326315441442043

Epoch: 6| Step: 5
Training loss: 1.194307490686113
Validation loss: 2.64363113241211

Epoch: 6| Step: 6
Training loss: 1.662249943563822
Validation loss: 2.6183055122489955

Epoch: 6| Step: 7
Training loss: 1.8317829931783105
Validation loss: 2.608717104192128

Epoch: 6| Step: 8
Training loss: 1.3590051871447064
Validation loss: 2.570406435811449

Epoch: 6| Step: 9
Training loss: 1.3227417847791552
Validation loss: 2.550520812399535

Epoch: 6| Step: 10
Training loss: 1.848145885794583
Validation loss: 2.550457702648939

Epoch: 6| Step: 11
Training loss: 1.6476553557435563
Validation loss: 2.5148411184695343

Epoch: 6| Step: 12
Training loss: 1.893115334497149
Validation loss: 2.4970607809762115

Epoch: 6| Step: 13
Training loss: 1.5976852003986124
Validation loss: 2.4676542860700224

Epoch: 197| Step: 0
Training loss: 1.8058404583593102
Validation loss: 2.446549220107789

Epoch: 6| Step: 1
Training loss: 1.9927156832756043
Validation loss: 2.490332329930915

Epoch: 6| Step: 2
Training loss: 1.6530575484304386
Validation loss: 2.5223303993453143

Epoch: 6| Step: 3
Training loss: 1.785838190957122
Validation loss: 2.55098096701398

Epoch: 6| Step: 4
Training loss: 1.888017732464228
Validation loss: 2.582356414766149

Epoch: 6| Step: 5
Training loss: 1.5973392535839215
Validation loss: 2.5808104409593646

Epoch: 6| Step: 6
Training loss: 1.4540733606230913
Validation loss: 2.59076188132054

Epoch: 6| Step: 7
Training loss: 1.5811183226268946
Validation loss: 2.575506508011787

Epoch: 6| Step: 8
Training loss: 0.8411297555495088
Validation loss: 2.5837379625606

Epoch: 6| Step: 9
Training loss: 1.1760952552409731
Validation loss: 2.5509500210108786

Epoch: 6| Step: 10
Training loss: 1.6412257230057026
Validation loss: 2.558848927653098

Epoch: 6| Step: 11
Training loss: 1.9220941310104886
Validation loss: 2.5607127267824823

Epoch: 6| Step: 12
Training loss: 1.2144006736817583
Validation loss: 2.5649391199090514

Epoch: 6| Step: 13
Training loss: 1.6275616775052988
Validation loss: 2.567582522202576

Epoch: 198| Step: 0
Training loss: 1.634281793274306
Validation loss: 2.5624283631258593

Epoch: 6| Step: 1
Training loss: 1.585876614007905
Validation loss: 2.555369360618849

Epoch: 6| Step: 2
Training loss: 1.4319854778959977
Validation loss: 2.5268436110792307

Epoch: 6| Step: 3
Training loss: 1.8443474528971098
Validation loss: 2.519652218500972

Epoch: 6| Step: 4
Training loss: 1.6459855922657067
Validation loss: 2.533236697377221

Epoch: 6| Step: 5
Training loss: 1.7925147186058075
Validation loss: 2.4975616520816906

Epoch: 6| Step: 6
Training loss: 1.8362643336495559
Validation loss: 2.5100500912879684

Epoch: 6| Step: 7
Training loss: 1.7364048120236457
Validation loss: 2.531995716388519

Epoch: 6| Step: 8
Training loss: 1.7363898456189577
Validation loss: 2.560910448974334

Epoch: 6| Step: 9
Training loss: 1.430019402672444
Validation loss: 2.5899340593523883

Epoch: 6| Step: 10
Training loss: 1.457345228140249
Validation loss: 2.588549246366023

Epoch: 6| Step: 11
Training loss: 1.299819636670937
Validation loss: 2.6006261447474444

Epoch: 6| Step: 12
Training loss: 1.4861247942444111
Validation loss: 2.5920216959533082

Epoch: 6| Step: 13
Training loss: 0.9485077255368758
Validation loss: 2.5647826813720984

Epoch: 199| Step: 0
Training loss: 1.7454454554064622
Validation loss: 2.5560635122376762

Epoch: 6| Step: 1
Training loss: 1.63004912390142
Validation loss: 2.56314777737452

Epoch: 6| Step: 2
Training loss: 1.6355950406063473
Validation loss: 2.574540221386511

Epoch: 6| Step: 3
Training loss: 1.2579958764267916
Validation loss: 2.5692634515078034

Epoch: 6| Step: 4
Training loss: 1.505732391188591
Validation loss: 2.568626335721648

Epoch: 6| Step: 5
Training loss: 1.0723458904526804
Validation loss: 2.558799613004639

Epoch: 6| Step: 6
Training loss: 1.9835995938852413
Validation loss: 2.5605198963005806

Epoch: 6| Step: 7
Training loss: 1.5417095212736542
Validation loss: 2.5666112296764783

Epoch: 6| Step: 8
Training loss: 1.751690048487591
Validation loss: 2.5558349886255534

Epoch: 6| Step: 9
Training loss: 1.5848774491354454
Validation loss: 2.558725426842626

Epoch: 6| Step: 10
Training loss: 1.3786085634150167
Validation loss: 2.538894989571383

Epoch: 6| Step: 11
Training loss: 1.5734476704728089
Validation loss: 2.5536792264782084

Epoch: 6| Step: 12
Training loss: 1.6169824147680734
Validation loss: 2.574973011801313

Epoch: 6| Step: 13
Training loss: 1.6245582420261915
Validation loss: 2.5711627711698726

Epoch: 200| Step: 0
Training loss: 1.6231861995753356
Validation loss: 2.5798365286775384

Epoch: 6| Step: 1
Training loss: 1.549788842123235
Validation loss: 2.58852299429954

Epoch: 6| Step: 2
Training loss: 1.555639924115342
Validation loss: 2.559713351614463

Epoch: 6| Step: 3
Training loss: 1.6606993022658818
Validation loss: 2.548873866884876

Epoch: 6| Step: 4
Training loss: 1.7707559082458328
Validation loss: 2.534472394532277

Epoch: 6| Step: 5
Training loss: 1.3813349701995676
Validation loss: 2.5454161624540905

Epoch: 6| Step: 6
Training loss: 1.3344840905222721
Validation loss: 2.5678503274339692

Epoch: 6| Step: 7
Training loss: 1.1235212037547668
Validation loss: 2.564044664912846

Epoch: 6| Step: 8
Training loss: 1.4067380693959186
Validation loss: 2.571293684705833

Epoch: 6| Step: 9
Training loss: 1.5920420452009878
Validation loss: 2.5526724121483237

Epoch: 6| Step: 10
Training loss: 1.8141009396497982
Validation loss: 2.5338709125122056

Epoch: 6| Step: 11
Training loss: 1.352471900126248
Validation loss: 2.5308931682311577

Epoch: 6| Step: 12
Training loss: 1.987700251921463
Validation loss: 2.5368194855276625

Epoch: 6| Step: 13
Training loss: 1.4512734050325546
Validation loss: 2.5558489741699026

Epoch: 201| Step: 0
Training loss: 1.3928859204683508
Validation loss: 2.601301958737059

Epoch: 6| Step: 1
Training loss: 1.5618428183388933
Validation loss: 2.613382175754875

Epoch: 6| Step: 2
Training loss: 1.8025912706438654
Validation loss: 2.651735210513391

Epoch: 6| Step: 3
Training loss: 1.5019782849251986
Validation loss: 2.609514629265059

Epoch: 6| Step: 4
Training loss: 1.3888874986429673
Validation loss: 2.606175635074558

Epoch: 6| Step: 5
Training loss: 1.4396077335717006
Validation loss: 2.628757247014091

Epoch: 6| Step: 6
Training loss: 1.5132736371291473
Validation loss: 2.6064655259202305

Epoch: 6| Step: 7
Training loss: 1.3954879086611982
Validation loss: 2.57008142495784

Epoch: 6| Step: 8
Training loss: 1.7367984233501137
Validation loss: 2.5819574741790388

Epoch: 6| Step: 9
Training loss: 1.7773792975926626
Validation loss: 2.53631185335352

Epoch: 6| Step: 10
Training loss: 1.3478501332453297
Validation loss: 2.5558279155801356

Epoch: 6| Step: 11
Training loss: 1.4148227060270648
Validation loss: 2.561405617490247

Epoch: 6| Step: 12
Training loss: 1.5022922326517456
Validation loss: 2.552540440627464

Epoch: 6| Step: 13
Training loss: 1.879933669157864
Validation loss: 2.6015513735602878

Epoch: 202| Step: 0
Training loss: 1.2383282769837138
Validation loss: 2.6329218628511337

Epoch: 6| Step: 1
Training loss: 1.3553067421081684
Validation loss: 2.6705667540424525

Epoch: 6| Step: 2
Training loss: 1.3159636254254876
Validation loss: 2.705223870970287

Epoch: 6| Step: 3
Training loss: 1.5881212355603997
Validation loss: 2.710656113912541

Epoch: 6| Step: 4
Training loss: 1.5120364306314722
Validation loss: 2.6956839566024824

Epoch: 6| Step: 5
Training loss: 1.4849593769001566
Validation loss: 2.711791931299909

Epoch: 6| Step: 6
Training loss: 1.8153130635953303
Validation loss: 2.6876046402886096

Epoch: 6| Step: 7
Training loss: 1.32278472763095
Validation loss: 2.640228200895908

Epoch: 6| Step: 8
Training loss: 1.2272997541694828
Validation loss: 2.5862123200651186

Epoch: 6| Step: 9
Training loss: 2.048321045708588
Validation loss: 2.550883232522409

Epoch: 6| Step: 10
Training loss: 1.4776357958203779
Validation loss: 2.509304300744936

Epoch: 6| Step: 11
Training loss: 1.3758952087653842
Validation loss: 2.455870302973472

Epoch: 6| Step: 12
Training loss: 1.6173452401746287
Validation loss: 2.458317869404383

Epoch: 6| Step: 13
Training loss: 2.17663042629308
Validation loss: 2.474197962262403

Epoch: 203| Step: 0
Training loss: 1.3338965279514314
Validation loss: 2.4936921630208686

Epoch: 6| Step: 1
Training loss: 1.4121241483007907
Validation loss: 2.5556826653137463

Epoch: 6| Step: 2
Training loss: 1.8301506883042813
Validation loss: 2.6115999306067548

Epoch: 6| Step: 3
Training loss: 1.127407465011247
Validation loss: 2.649860655637978

Epoch: 6| Step: 4
Training loss: 1.6308787453237756
Validation loss: 2.672742724674096

Epoch: 6| Step: 5
Training loss: 1.8801753780051702
Validation loss: 2.7128105335137818

Epoch: 6| Step: 6
Training loss: 1.7002251812514924
Validation loss: 2.701560219147091

Epoch: 6| Step: 7
Training loss: 1.7001364849502838
Validation loss: 2.65852165780498

Epoch: 6| Step: 8
Training loss: 1.2581415634467292
Validation loss: 2.6334457086355574

Epoch: 6| Step: 9
Training loss: 1.291962707598409
Validation loss: 2.5963901229252775

Epoch: 6| Step: 10
Training loss: 1.1359659435378904
Validation loss: 2.5531228060397946

Epoch: 6| Step: 11
Training loss: 1.3849343868234225
Validation loss: 2.5310517809132818

Epoch: 6| Step: 12
Training loss: 1.5430518019331356
Validation loss: 2.519100874945164

Epoch: 6| Step: 13
Training loss: 2.0992394977618973
Validation loss: 2.5196931871369834

Epoch: 204| Step: 0
Training loss: 1.4164275734291054
Validation loss: 2.506476788379795

Epoch: 6| Step: 1
Training loss: 1.2372386405918214
Validation loss: 2.555742140244006

Epoch: 6| Step: 2
Training loss: 1.5392426516054056
Validation loss: 2.589121443975426

Epoch: 6| Step: 3
Training loss: 1.1552476404426417
Validation loss: 2.614229830824654

Epoch: 6| Step: 4
Training loss: 1.837254023793707
Validation loss: 2.648853560320819

Epoch: 6| Step: 5
Training loss: 1.8498479574461586
Validation loss: 2.6917774837348296

Epoch: 6| Step: 6
Training loss: 1.36725847332523
Validation loss: 2.683706494203349

Epoch: 6| Step: 7
Training loss: 1.5356171282580855
Validation loss: 2.6788054495374105

Epoch: 6| Step: 8
Training loss: 1.4796289966139653
Validation loss: 2.6835708656594512

Epoch: 6| Step: 9
Training loss: 1.7325915540584227
Validation loss: 2.6156973046586565

Epoch: 6| Step: 10
Training loss: 0.9926904920246984
Validation loss: 2.577746458780349

Epoch: 6| Step: 11
Training loss: 1.6788600569130956
Validation loss: 2.574077339588672

Epoch: 6| Step: 12
Training loss: 1.37552702080364
Validation loss: 2.523290465989119

Epoch: 6| Step: 13
Training loss: 1.6873040968598847
Validation loss: 2.5121534349012093

Epoch: 205| Step: 0
Training loss: 1.8429508740381666
Validation loss: 2.4716047565390626

Epoch: 6| Step: 1
Training loss: 1.5459795585356737
Validation loss: 2.5005079399440646

Epoch: 6| Step: 2
Training loss: 1.3959868711985495
Validation loss: 2.5307287269145187

Epoch: 6| Step: 3
Training loss: 1.536250299712882
Validation loss: 2.5609133150249743

Epoch: 6| Step: 4
Training loss: 1.6471050355142374
Validation loss: 2.6273313015377706

Epoch: 6| Step: 5
Training loss: 1.325380968710219
Validation loss: 2.662555678746039

Epoch: 6| Step: 6
Training loss: 2.2399940528109483
Validation loss: 2.6573402237658517

Epoch: 6| Step: 7
Training loss: 1.3306840365148296
Validation loss: 2.6956681012043497

Epoch: 6| Step: 8
Training loss: 1.2867497359935727
Validation loss: 2.6714699738092134

Epoch: 6| Step: 9
Training loss: 1.2460933673343848
Validation loss: 2.6973264232819476

Epoch: 6| Step: 10
Training loss: 1.2274921077466785
Validation loss: 2.622251484875471

Epoch: 6| Step: 11
Training loss: 1.3815006563762882
Validation loss: 2.5921614806408924

Epoch: 6| Step: 12
Training loss: 1.6966824951008124
Validation loss: 2.5790059026254335

Epoch: 6| Step: 13
Training loss: 1.0928543783557165
Validation loss: 2.5422587980067046

Epoch: 206| Step: 0
Training loss: 1.7533372665525542
Validation loss: 2.535598904074774

Epoch: 6| Step: 1
Training loss: 1.7570873884202955
Validation loss: 2.5477426876444187

Epoch: 6| Step: 2
Training loss: 1.294649535664588
Validation loss: 2.530074203619314

Epoch: 6| Step: 3
Training loss: 1.8715857892156702
Validation loss: 2.536733085139343

Epoch: 6| Step: 4
Training loss: 1.195010277931354
Validation loss: 2.5317333453217676

Epoch: 6| Step: 5
Training loss: 1.526931355795233
Validation loss: 2.545204726675042

Epoch: 6| Step: 6
Training loss: 0.8519066631340905
Validation loss: 2.5602895966107577

Epoch: 6| Step: 7
Training loss: 1.1848230304639429
Validation loss: 2.5549417051707133

Epoch: 6| Step: 8
Training loss: 1.4650486510338967
Validation loss: 2.5431471553618237

Epoch: 6| Step: 9
Training loss: 1.2548243883833956
Validation loss: 2.5578782796584076

Epoch: 6| Step: 10
Training loss: 1.3825253980624883
Validation loss: 2.555249577354336

Epoch: 6| Step: 11
Training loss: 1.481440886740464
Validation loss: 2.5754521042436807

Epoch: 6| Step: 12
Training loss: 1.560638692396272
Validation loss: 2.5773341562224936

Epoch: 6| Step: 13
Training loss: 2.071146440789042
Validation loss: 2.597252730335395

Epoch: 207| Step: 0
Training loss: 1.3378162669659202
Validation loss: 2.5995124954224917

Epoch: 6| Step: 1
Training loss: 1.602398091496299
Validation loss: 2.613730506534152

Epoch: 6| Step: 2
Training loss: 1.181758250537572
Validation loss: 2.612497195998764

Epoch: 6| Step: 3
Training loss: 1.7960699517065977
Validation loss: 2.63654344517543

Epoch: 6| Step: 4
Training loss: 1.5665559387982784
Validation loss: 2.6412481398075287

Epoch: 6| Step: 5
Training loss: 1.1652889575252716
Validation loss: 2.6430229111793024

Epoch: 6| Step: 6
Training loss: 1.5485675684001512
Validation loss: 2.645586350275437

Epoch: 6| Step: 7
Training loss: 1.4280676498417062
Validation loss: 2.6463193562500633

Epoch: 6| Step: 8
Training loss: 0.519869214034209
Validation loss: 2.640177485493212

Epoch: 6| Step: 9
Training loss: 1.869885143893865
Validation loss: 2.5993707913075443

Epoch: 6| Step: 10
Training loss: 1.660807833988625
Validation loss: 2.590385244170351

Epoch: 6| Step: 11
Training loss: 1.2398872430356338
Validation loss: 2.5972919774627883

Epoch: 6| Step: 12
Training loss: 1.4976662123562188
Validation loss: 2.585795271068564

Epoch: 6| Step: 13
Training loss: 1.376158962790133
Validation loss: 2.5506921118275483

Epoch: 208| Step: 0
Training loss: 1.4357989654294985
Validation loss: 2.5408483745011483

Epoch: 6| Step: 1
Training loss: 1.4724379967166035
Validation loss: 2.548301901515399

Epoch: 6| Step: 2
Training loss: 1.3076053359596416
Validation loss: 2.578110378568224

Epoch: 6| Step: 3
Training loss: 1.4864354339240078
Validation loss: 2.6134121215507986

Epoch: 6| Step: 4
Training loss: 1.324098069534986
Validation loss: 2.6010624264113993

Epoch: 6| Step: 5
Training loss: 1.8774263577298393
Validation loss: 2.6308026799199067

Epoch: 6| Step: 6
Training loss: 1.5593371614134923
Validation loss: 2.6345741705152355

Epoch: 6| Step: 7
Training loss: 1.542453496346361
Validation loss: 2.6447501758787446

Epoch: 6| Step: 8
Training loss: 1.3240233420622245
Validation loss: 2.6527918107426265

Epoch: 6| Step: 9
Training loss: 1.2235288583448936
Validation loss: 2.631152159463063

Epoch: 6| Step: 10
Training loss: 1.2803437354067415
Validation loss: 2.6539597281211647

Epoch: 6| Step: 11
Training loss: 1.4093673908848694
Validation loss: 2.638065000832291

Epoch: 6| Step: 12
Training loss: 1.5301266656440697
Validation loss: 2.6273480669654243

Epoch: 6| Step: 13
Training loss: 0.9848539004921676
Validation loss: 2.622768564082953

Epoch: 209| Step: 0
Training loss: 1.8826161515674023
Validation loss: 2.5857811242841287

Epoch: 6| Step: 1
Training loss: 1.5105149949613383
Validation loss: 2.603549618045175

Epoch: 6| Step: 2
Training loss: 1.3760543595488333
Validation loss: 2.5797157458819857

Epoch: 6| Step: 3
Training loss: 1.4161344912393852
Validation loss: 2.5743935169182928

Epoch: 6| Step: 4
Training loss: 1.3180816583937316
Validation loss: 2.5632063399642493

Epoch: 6| Step: 5
Training loss: 1.4343028796313555
Validation loss: 2.5693802865918736

Epoch: 6| Step: 6
Training loss: 1.499270341153465
Validation loss: 2.571477257128028

Epoch: 6| Step: 7
Training loss: 1.4943404718523956
Validation loss: 2.575614244586646

Epoch: 6| Step: 8
Training loss: 1.5373744324061915
Validation loss: 2.5701590737002764

Epoch: 6| Step: 9
Training loss: 1.0129130615856479
Validation loss: 2.591976519189495

Epoch: 6| Step: 10
Training loss: 1.4595500865521605
Validation loss: 2.594811010122923

Epoch: 6| Step: 11
Training loss: 1.1022806734873
Validation loss: 2.59873895255389

Epoch: 6| Step: 12
Training loss: 1.468337467778101
Validation loss: 2.6287935350394482

Epoch: 6| Step: 13
Training loss: 0.7605147799247618
Validation loss: 2.6495637460676904

Epoch: 210| Step: 0
Training loss: 1.1104996044874453
Validation loss: 2.653165219186164

Epoch: 6| Step: 1
Training loss: 1.3671471290077473
Validation loss: 2.634367989071554

Epoch: 6| Step: 2
Training loss: 2.0350017232676714
Validation loss: 2.6496924182549795

Epoch: 6| Step: 3
Training loss: 1.5487736311149578
Validation loss: 2.6301107779416126

Epoch: 6| Step: 4
Training loss: 0.9892787498073554
Validation loss: 2.6254708297077998

Epoch: 6| Step: 5
Training loss: 1.658560095511641
Validation loss: 2.628905058337282

Epoch: 6| Step: 6
Training loss: 1.242477287223045
Validation loss: 2.6274230231795928

Epoch: 6| Step: 7
Training loss: 1.4503103910569333
Validation loss: 2.587585217716941

Epoch: 6| Step: 8
Training loss: 1.4212827182516523
Validation loss: 2.607899313954264

Epoch: 6| Step: 9
Training loss: 1.3482226080082729
Validation loss: 2.5932599190437218

Epoch: 6| Step: 10
Training loss: 1.0744797268211297
Validation loss: 2.603108686247241

Epoch: 6| Step: 11
Training loss: 1.1324084383432858
Validation loss: 2.598120115247344

Epoch: 6| Step: 12
Training loss: 1.7127082753743104
Validation loss: 2.622003333195894

Epoch: 6| Step: 13
Training loss: 1.398587735593272
Validation loss: 2.635700793362356

Epoch: 211| Step: 0
Training loss: 1.4568484603317016
Validation loss: 2.6228942706976843

Epoch: 6| Step: 1
Training loss: 0.8832385630122218
Validation loss: 2.6266731910547496

Epoch: 6| Step: 2
Training loss: 1.3947284462892946
Validation loss: 2.623327209589137

Epoch: 6| Step: 3
Training loss: 1.3596470878415297
Validation loss: 2.608966064634527

Epoch: 6| Step: 4
Training loss: 1.1498116297485554
Validation loss: 2.569848147421605

Epoch: 6| Step: 5
Training loss: 1.2635372508769331
Validation loss: 2.5789414014042653

Epoch: 6| Step: 6
Training loss: 1.1811725792919627
Validation loss: 2.540517484340498

Epoch: 6| Step: 7
Training loss: 1.1138532273462702
Validation loss: 2.53824666158001

Epoch: 6| Step: 8
Training loss: 1.3152069152376427
Validation loss: 2.519525442063459

Epoch: 6| Step: 9
Training loss: 1.8269138073396463
Validation loss: 2.5304270593706795

Epoch: 6| Step: 10
Training loss: 1.4550795996741688
Validation loss: 2.505573202046375

Epoch: 6| Step: 11
Training loss: 2.0085135694277594
Validation loss: 2.506314191655181

Epoch: 6| Step: 12
Training loss: 1.3216039898327232
Validation loss: 2.5244970753454976

Epoch: 6| Step: 13
Training loss: 1.5075795680567632
Validation loss: 2.5580898464722783

Epoch: 212| Step: 0
Training loss: 1.5107044691174627
Validation loss: 2.5669047407712564

Epoch: 6| Step: 1
Training loss: 1.6073651402265456
Validation loss: 2.6052874732843914

Epoch: 6| Step: 2
Training loss: 1.538558102750013
Validation loss: 2.628033000609797

Epoch: 6| Step: 3
Training loss: 1.4223000027494357
Validation loss: 2.616281263424131

Epoch: 6| Step: 4
Training loss: 1.2468527273230037
Validation loss: 2.594486829223761

Epoch: 6| Step: 5
Training loss: 1.4789238672270155
Validation loss: 2.5770107462962057

Epoch: 6| Step: 6
Training loss: 1.4305595698295162
Validation loss: 2.5681302445072527

Epoch: 6| Step: 7
Training loss: 1.523792401569536
Validation loss: 2.5774751691329447

Epoch: 6| Step: 8
Training loss: 1.474195086153313
Validation loss: 2.557300570034121

Epoch: 6| Step: 9
Training loss: 1.0725839833631619
Validation loss: 2.5114123337839724

Epoch: 6| Step: 10
Training loss: 1.596897458032399
Validation loss: 2.54941118255653

Epoch: 6| Step: 11
Training loss: 1.0823051023460108
Validation loss: 2.5527399105433766

Epoch: 6| Step: 12
Training loss: 1.0744077758938
Validation loss: 2.562327931667476

Epoch: 6| Step: 13
Training loss: 0.6240775931056103
Validation loss: 2.5775205945947026

Epoch: 213| Step: 0
Training loss: 1.130713629678082
Validation loss: 2.624867055508059

Epoch: 6| Step: 1
Training loss: 1.6190384302225804
Validation loss: 2.589243587048346

Epoch: 6| Step: 2
Training loss: 1.2539315384545935
Validation loss: 2.667518847440324

Epoch: 6| Step: 3
Training loss: 1.0624180930487093
Validation loss: 2.6599396185598896

Epoch: 6| Step: 4
Training loss: 1.875198226622892
Validation loss: 2.6543776368044103

Epoch: 6| Step: 5
Training loss: 1.459368347544895
Validation loss: 2.6456746997001708

Epoch: 6| Step: 6
Training loss: 1.1775831944744934
Validation loss: 2.595266244672718

Epoch: 6| Step: 7
Training loss: 1.5319385148401787
Validation loss: 2.573262068961269

Epoch: 6| Step: 8
Training loss: 1.262946744758032
Validation loss: 2.547681908010157

Epoch: 6| Step: 9
Training loss: 1.4751459017215778
Validation loss: 2.516895111897617

Epoch: 6| Step: 10
Training loss: 1.1048146931373515
Validation loss: 2.5448116890951624

Epoch: 6| Step: 11
Training loss: 1.4943141462506926
Validation loss: 2.5297929212833954

Epoch: 6| Step: 12
Training loss: 1.2114238623681144
Validation loss: 2.52367435543676

Epoch: 6| Step: 13
Training loss: 1.0678680238474678
Validation loss: 2.5397490602577686

Epoch: 214| Step: 0
Training loss: 0.9653401507131187
Validation loss: 2.572488428727995

Epoch: 6| Step: 1
Training loss: 1.3484618501906822
Validation loss: 2.572354070911125

Epoch: 6| Step: 2
Training loss: 1.6655301351532237
Validation loss: 2.5444391115842055

Epoch: 6| Step: 3
Training loss: 1.0517723769629053
Validation loss: 2.57276113304987

Epoch: 6| Step: 4
Training loss: 1.8398160183187358
Validation loss: 2.545659142240193

Epoch: 6| Step: 5
Training loss: 1.8765305312305747
Validation loss: 2.544528064291741

Epoch: 6| Step: 6
Training loss: 1.11033803483679
Validation loss: 2.5912282303086696

Epoch: 6| Step: 7
Training loss: 1.608021657850064
Validation loss: 2.5751354491134917

Epoch: 6| Step: 8
Training loss: 1.321479417124623
Validation loss: 2.5795452642056538

Epoch: 6| Step: 9
Training loss: 1.1861025970494876
Validation loss: 2.5698487359963824

Epoch: 6| Step: 10
Training loss: 0.8646734412856089
Validation loss: 2.5871356849714755

Epoch: 6| Step: 11
Training loss: 0.9595922652764874
Validation loss: 2.5836490817891016

Epoch: 6| Step: 12
Training loss: 1.264693824218743
Validation loss: 2.5855237897984797

Epoch: 6| Step: 13
Training loss: 0.8708306843353818
Validation loss: 2.559058791820872

Epoch: 215| Step: 0
Training loss: 1.298300224236248
Validation loss: 2.600179130821746

Epoch: 6| Step: 1
Training loss: 1.3703189410381245
Validation loss: 2.5861147562137745

Epoch: 6| Step: 2
Training loss: 1.705982505874111
Validation loss: 2.6124064684331754

Epoch: 6| Step: 3
Training loss: 1.3167250612242782
Validation loss: 2.609641270999577

Epoch: 6| Step: 4
Training loss: 1.1584408598100682
Validation loss: 2.579125097953226

Epoch: 6| Step: 5
Training loss: 0.8265921603615825
Validation loss: 2.6024944519924453

Epoch: 6| Step: 6
Training loss: 1.3839701316675517
Validation loss: 2.6005988296750453

Epoch: 6| Step: 7
Training loss: 0.8400561396821572
Validation loss: 2.5637702594732827

Epoch: 6| Step: 8
Training loss: 1.285320051242007
Validation loss: 2.583250219759301

Epoch: 6| Step: 9
Training loss: 1.235676815353166
Validation loss: 2.5637898954052423

Epoch: 6| Step: 10
Training loss: 1.6105117486846743
Validation loss: 2.535816561626827

Epoch: 6| Step: 11
Training loss: 1.5092526214460575
Validation loss: 2.5488527702799937

Epoch: 6| Step: 12
Training loss: 1.1129880820302038
Validation loss: 2.536943911772101

Epoch: 6| Step: 13
Training loss: 1.6257868842302734
Validation loss: 2.569268384683156

Epoch: 216| Step: 0
Training loss: 1.289559008605665
Validation loss: 2.580685243404248

Epoch: 6| Step: 1
Training loss: 1.0947064713498418
Validation loss: 2.5712538672607304

Epoch: 6| Step: 2
Training loss: 1.3821584588004967
Validation loss: 2.586542082449232

Epoch: 6| Step: 3
Training loss: 1.4056356147579039
Validation loss: 2.6038728793561305

Epoch: 6| Step: 4
Training loss: 1.275128558166344
Validation loss: 2.587484534131539

Epoch: 6| Step: 5
Training loss: 1.0778436155354245
Validation loss: 2.598328036396864

Epoch: 6| Step: 6
Training loss: 1.1156987761565065
Validation loss: 2.614369398881435

Epoch: 6| Step: 7
Training loss: 1.5041421284175471
Validation loss: 2.58045590095085

Epoch: 6| Step: 8
Training loss: 1.1660487491369174
Validation loss: 2.600606943195322

Epoch: 6| Step: 9
Training loss: 1.5787254928414365
Validation loss: 2.6121102048701625

Epoch: 6| Step: 10
Training loss: 1.0896253469522845
Validation loss: 2.601303588790144

Epoch: 6| Step: 11
Training loss: 1.3332390553203848
Validation loss: 2.5977732657088546

Epoch: 6| Step: 12
Training loss: 1.4072597269442784
Validation loss: 2.563638609749536

Epoch: 6| Step: 13
Training loss: 1.6154958381894389
Validation loss: 2.5450847289268386

Epoch: 217| Step: 0
Training loss: 1.4367118001399504
Validation loss: 2.527674079636201

Epoch: 6| Step: 1
Training loss: 1.0337980753226288
Validation loss: 2.5507955918997705

Epoch: 6| Step: 2
Training loss: 1.2836463662041966
Validation loss: 2.5624052435890423

Epoch: 6| Step: 3
Training loss: 1.2813203838833949
Validation loss: 2.5534873286483712

Epoch: 6| Step: 4
Training loss: 1.3185800325322268
Validation loss: 2.589983175136512

Epoch: 6| Step: 5
Training loss: 1.345623661790068
Validation loss: 2.5980719762371454

Epoch: 6| Step: 6
Training loss: 1.1550257103605672
Validation loss: 2.584575870954503

Epoch: 6| Step: 7
Training loss: 1.048618629602646
Validation loss: 2.596550215803858

Epoch: 6| Step: 8
Training loss: 1.435028522354205
Validation loss: 2.6125884120272813

Epoch: 6| Step: 9
Training loss: 1.034790435067331
Validation loss: 2.622416455941263

Epoch: 6| Step: 10
Training loss: 1.7918611317454836
Validation loss: 2.6154446627947965

Epoch: 6| Step: 11
Training loss: 1.0478064535337992
Validation loss: 2.621716757238727

Epoch: 6| Step: 12
Training loss: 1.5687859550094423
Validation loss: 2.622676077528915

Epoch: 6| Step: 13
Training loss: 0.4227802137127724
Validation loss: 2.5897534167101077

Epoch: 218| Step: 0
Training loss: 1.5080190724601072
Validation loss: 2.60819918936811

Epoch: 6| Step: 1
Training loss: 1.0272327551695146
Validation loss: 2.6148246480877524

Epoch: 6| Step: 2
Training loss: 1.441651610293991
Validation loss: 2.5740455308860914

Epoch: 6| Step: 3
Training loss: 0.7809399943409224
Validation loss: 2.5661558169312233

Epoch: 6| Step: 4
Training loss: 0.8693211400168139
Validation loss: 2.5717388052771275

Epoch: 6| Step: 5
Training loss: 1.7088740896334584
Validation loss: 2.5351320429230104

Epoch: 6| Step: 6
Training loss: 1.3815443182790557
Validation loss: 2.5324417685365628

Epoch: 6| Step: 7
Training loss: 1.1599115698091909
Validation loss: 2.541457628731492

Epoch: 6| Step: 8
Training loss: 1.469615518931151
Validation loss: 2.584812680182609

Epoch: 6| Step: 9
Training loss: 1.4749782883937343
Validation loss: 2.6071968259556098

Epoch: 6| Step: 10
Training loss: 1.1603888589938929
Validation loss: 2.61317752829909

Epoch: 6| Step: 11
Training loss: 0.9746638342065614
Validation loss: 2.629046829254217

Epoch: 6| Step: 12
Training loss: 1.2019974019471589
Validation loss: 2.6688642682122907

Epoch: 6| Step: 13
Training loss: 1.2833672219710728
Validation loss: 2.647700509312057

Epoch: 219| Step: 0
Training loss: 1.0104600890487283
Validation loss: 2.6140611204918915

Epoch: 6| Step: 1
Training loss: 1.0605917230892041
Validation loss: 2.637924604787941

Epoch: 6| Step: 2
Training loss: 1.3019205780035656
Validation loss: 2.5838664857977776

Epoch: 6| Step: 3
Training loss: 1.1209657177272747
Validation loss: 2.5679620175972655

Epoch: 6| Step: 4
Training loss: 1.0729447456808952
Validation loss: 2.547304649810234

Epoch: 6| Step: 5
Training loss: 1.1676359180838014
Validation loss: 2.5261531557006816

Epoch: 6| Step: 6
Training loss: 1.3583282298984882
Validation loss: 2.5583681218906213

Epoch: 6| Step: 7
Training loss: 1.478127754966959
Validation loss: 2.552881726127674

Epoch: 6| Step: 8
Training loss: 1.0478240309028748
Validation loss: 2.558228298509701

Epoch: 6| Step: 9
Training loss: 1.4176392395687498
Validation loss: 2.5529942654547844

Epoch: 6| Step: 10
Training loss: 1.068784862641254
Validation loss: 2.5380016903291387

Epoch: 6| Step: 11
Training loss: 1.362809894911794
Validation loss: 2.5694679019355715

Epoch: 6| Step: 12
Training loss: 1.4571275449129926
Validation loss: 2.581603582259124

Epoch: 6| Step: 13
Training loss: 1.5777552709780047
Validation loss: 2.5659901378749055

Epoch: 220| Step: 0
Training loss: 1.1362382325422333
Validation loss: 2.5707413460611352

Epoch: 6| Step: 1
Training loss: 1.1544727378656352
Validation loss: 2.561382194963159

Epoch: 6| Step: 2
Training loss: 1.0123614181057774
Validation loss: 2.538075976184984

Epoch: 6| Step: 3
Training loss: 1.209306911158483
Validation loss: 2.539553626484337

Epoch: 6| Step: 4
Training loss: 1.145213473880235
Validation loss: 2.54770149788276

Epoch: 6| Step: 5
Training loss: 1.6554795398513553
Validation loss: 2.55012921442858

Epoch: 6| Step: 6
Training loss: 1.1303128254251642
Validation loss: 2.5336799195329456

Epoch: 6| Step: 7
Training loss: 1.1803850044522155
Validation loss: 2.5771111596456877

Epoch: 6| Step: 8
Training loss: 1.2078999476587773
Validation loss: 2.583739786759382

Epoch: 6| Step: 9
Training loss: 1.153869549807526
Validation loss: 2.5813743283475437

Epoch: 6| Step: 10
Training loss: 0.8269602663995861
Validation loss: 2.5721219712768693

Epoch: 6| Step: 11
Training loss: 1.470000688202366
Validation loss: 2.5867585436255007

Epoch: 6| Step: 12
Training loss: 0.7927437073028661
Validation loss: 2.5776196603229784

Epoch: 6| Step: 13
Training loss: 2.122784862475983
Validation loss: 2.5855225414540044

Epoch: 221| Step: 0
Training loss: 1.0754987269508847
Validation loss: 2.5446311235523567

Epoch: 6| Step: 1
Training loss: 1.4040558545829636
Validation loss: 2.538798068201793

Epoch: 6| Step: 2
Training loss: 1.223408233175595
Validation loss: 2.48475042844566

Epoch: 6| Step: 3
Training loss: 1.5547492240269576
Validation loss: 2.488504859346734

Epoch: 6| Step: 4
Training loss: 1.136835046436283
Validation loss: 2.481434027661203

Epoch: 6| Step: 5
Training loss: 1.0452047090022116
Validation loss: 2.5151615183366416

Epoch: 6| Step: 6
Training loss: 1.8750411982778559
Validation loss: 2.537240351638765

Epoch: 6| Step: 7
Training loss: 1.2917516229234307
Validation loss: 2.534824989997435

Epoch: 6| Step: 8
Training loss: 0.8745258954218026
Validation loss: 2.55023450720173

Epoch: 6| Step: 9
Training loss: 0.8675864049661522
Validation loss: 2.561923794876134

Epoch: 6| Step: 10
Training loss: 1.1571070098286151
Validation loss: 2.6022756960625557

Epoch: 6| Step: 11
Training loss: 1.088043311754118
Validation loss: 2.6136169889912977

Epoch: 6| Step: 12
Training loss: 1.0220166892650488
Validation loss: 2.6075571630140666

Epoch: 6| Step: 13
Training loss: 1.1396638661625667
Validation loss: 2.590552950129944

Epoch: 222| Step: 0
Training loss: 1.6116855664149363
Validation loss: 2.5928527470126173

Epoch: 6| Step: 1
Training loss: 1.118633002018652
Validation loss: 2.543555048568925

Epoch: 6| Step: 2
Training loss: 0.9397108077522685
Validation loss: 2.5311040498198185

Epoch: 6| Step: 3
Training loss: 1.2953057964229715
Validation loss: 2.5284925740299005

Epoch: 6| Step: 4
Training loss: 1.75051286539135
Validation loss: 2.512049260586623

Epoch: 6| Step: 5
Training loss: 1.1326455354966554
Validation loss: 2.525149868055159

Epoch: 6| Step: 6
Training loss: 1.2129300367552576
Validation loss: 2.556112417817045

Epoch: 6| Step: 7
Training loss: 0.9790785459000457
Validation loss: 2.575175876029138

Epoch: 6| Step: 8
Training loss: 0.9939498268605111
Validation loss: 2.6153537027303444

Epoch: 6| Step: 9
Training loss: 1.1272813659453027
Validation loss: 2.6404931499749646

Epoch: 6| Step: 10
Training loss: 1.2168598679207594
Validation loss: 2.61302878365721

Epoch: 6| Step: 11
Training loss: 1.3153532893843254
Validation loss: 2.603147079877775

Epoch: 6| Step: 12
Training loss: 0.4086457731778641
Validation loss: 2.6003500924764817

Epoch: 6| Step: 13
Training loss: 1.391370166479894
Validation loss: 2.603384430252444

Epoch: 223| Step: 0
Training loss: 0.9079679451254351
Validation loss: 2.589611485467272

Epoch: 6| Step: 1
Training loss: 1.0975242888384995
Validation loss: 2.579359274325817

Epoch: 6| Step: 2
Training loss: 1.7044193354100978
Validation loss: 2.5700780065438495

Epoch: 6| Step: 3
Training loss: 0.9087115105685907
Validation loss: 2.5689438665315856

Epoch: 6| Step: 4
Training loss: 0.8946759968883213
Validation loss: 2.538004849926292

Epoch: 6| Step: 5
Training loss: 1.3448212367952652
Validation loss: 2.57711315913867

Epoch: 6| Step: 6
Training loss: 0.9373164315112943
Validation loss: 2.5446318710953126

Epoch: 6| Step: 7
Training loss: 1.052900142039332
Validation loss: 2.6077193947647404

Epoch: 6| Step: 8
Training loss: 1.1798881208593703
Validation loss: 2.5704808443572227

Epoch: 6| Step: 9
Training loss: 1.187012723030221
Validation loss: 2.614178371767329

Epoch: 6| Step: 10
Training loss: 1.222859618607168
Validation loss: 2.6040360908176616

Epoch: 6| Step: 11
Training loss: 1.4470799541937363
Validation loss: 2.6035331247483464

Epoch: 6| Step: 12
Training loss: 1.444765389480122
Validation loss: 2.6156798735512634

Epoch: 6| Step: 13
Training loss: 1.2872605184398318
Validation loss: 2.599106747756573

Epoch: 224| Step: 0
Training loss: 0.9465554632993931
Validation loss: 2.587691512710662

Epoch: 6| Step: 1
Training loss: 1.4326954035609822
Validation loss: 2.5922357720624447

Epoch: 6| Step: 2
Training loss: 1.0173680533446028
Validation loss: 2.549079771643372

Epoch: 6| Step: 3
Training loss: 1.2307831862006915
Validation loss: 2.551055223629621

Epoch: 6| Step: 4
Training loss: 1.2500523556235261
Validation loss: 2.564312297764097

Epoch: 6| Step: 5
Training loss: 0.7596573544118825
Validation loss: 2.5600736121904952

Epoch: 6| Step: 6
Training loss: 0.884607734655072
Validation loss: 2.559353170545083

Epoch: 6| Step: 7
Training loss: 1.0718505278259904
Validation loss: 2.575952032179559

Epoch: 6| Step: 8
Training loss: 1.2913543672287884
Validation loss: 2.5559185256138264

Epoch: 6| Step: 9
Training loss: 1.2817425595166694
Validation loss: 2.5575339215086688

Epoch: 6| Step: 10
Training loss: 1.1853252373394931
Validation loss: 2.6002057640905853

Epoch: 6| Step: 11
Training loss: 1.4630557121156222
Validation loss: 2.553888631098825

Epoch: 6| Step: 12
Training loss: 1.3441806812742205
Validation loss: 2.6164878001730023

Epoch: 6| Step: 13
Training loss: 0.8699820570904157
Validation loss: 2.6290827115379733

Epoch: 225| Step: 0
Training loss: 1.3256576957069777
Validation loss: 2.6176318317196787

Epoch: 6| Step: 1
Training loss: 1.1713557809717101
Validation loss: 2.625913887696297

Epoch: 6| Step: 2
Training loss: 1.2597526135622876
Validation loss: 2.60088367838767

Epoch: 6| Step: 3
Training loss: 1.0579143187797448
Validation loss: 2.5485056947476967

Epoch: 6| Step: 4
Training loss: 1.375543010301307
Validation loss: 2.548161374867083

Epoch: 6| Step: 5
Training loss: 1.1144256064262907
Validation loss: 2.576476071520262

Epoch: 6| Step: 6
Training loss: 0.8495602648342289
Validation loss: 2.5591971358421897

Epoch: 6| Step: 7
Training loss: 0.9841828537163485
Validation loss: 2.5371808840538823

Epoch: 6| Step: 8
Training loss: 1.0621558922433114
Validation loss: 2.569257673174871

Epoch: 6| Step: 9
Training loss: 1.1215817123897567
Validation loss: 2.5856738633825787

Epoch: 6| Step: 10
Training loss: 0.9038037135622567
Validation loss: 2.5927204481152555

Epoch: 6| Step: 11
Training loss: 1.5215664059190648
Validation loss: 2.617284888982592

Epoch: 6| Step: 12
Training loss: 1.0814110806823964
Validation loss: 2.6216942108991432

Epoch: 6| Step: 13
Training loss: 1.5043892221131163
Validation loss: 2.643096043372273

Epoch: 226| Step: 0
Training loss: 1.4589454002230204
Validation loss: 2.6086639414017374

Epoch: 6| Step: 1
Training loss: 0.9792036123948533
Validation loss: 2.5744267373639005

Epoch: 6| Step: 2
Training loss: 1.2291062819740206
Validation loss: 2.6083278528437877

Epoch: 6| Step: 3
Training loss: 1.0946683570436009
Validation loss: 2.5247690496230484

Epoch: 6| Step: 4
Training loss: 1.1637271679729195
Validation loss: 2.5487873209125187

Epoch: 6| Step: 5
Training loss: 1.4285342041342908
Validation loss: 2.5380591382212847

Epoch: 6| Step: 6
Training loss: 1.1323431160663038
Validation loss: 2.544830127451433

Epoch: 6| Step: 7
Training loss: 1.0861073093613356
Validation loss: 2.516837744211107

Epoch: 6| Step: 8
Training loss: 1.0285796067692319
Validation loss: 2.5650462164276595

Epoch: 6| Step: 9
Training loss: 1.0100227190993893
Validation loss: 2.5900084008074953

Epoch: 6| Step: 10
Training loss: 1.48212961726094
Validation loss: 2.6245503037962914

Epoch: 6| Step: 11
Training loss: 0.9757616345012249
Validation loss: 2.6113930701028556

Epoch: 6| Step: 12
Training loss: 0.8480308162200175
Validation loss: 2.5940625086114113

Epoch: 6| Step: 13
Training loss: 1.1136609952322276
Validation loss: 2.588446041042768

Epoch: 227| Step: 0
Training loss: 1.1516817939489838
Validation loss: 2.5593965667541547

Epoch: 6| Step: 1
Training loss: 1.5862563240279923
Validation loss: 2.54349416685051

Epoch: 6| Step: 2
Training loss: 1.264643818614876
Validation loss: 2.558273267052524

Epoch: 6| Step: 3
Training loss: 1.000512111188265
Validation loss: 2.5414384814801347

Epoch: 6| Step: 4
Training loss: 0.9353176783894077
Validation loss: 2.5218291228199226

Epoch: 6| Step: 5
Training loss: 1.076500761036265
Validation loss: 2.537310936042856

Epoch: 6| Step: 6
Training loss: 0.9349412012736522
Validation loss: 2.5468173422830693

Epoch: 6| Step: 7
Training loss: 1.0056734079833176
Validation loss: 2.5530757806778928

Epoch: 6| Step: 8
Training loss: 1.0871954019976993
Validation loss: 2.5361543272627816

Epoch: 6| Step: 9
Training loss: 1.3364931256152777
Validation loss: 2.523879720786683

Epoch: 6| Step: 10
Training loss: 0.9844780217105766
Validation loss: 2.518475217656929

Epoch: 6| Step: 11
Training loss: 1.250915811747593
Validation loss: 2.5279108788709537

Epoch: 6| Step: 12
Training loss: 1.2395214524838214
Validation loss: 2.5844337238174564

Epoch: 6| Step: 13
Training loss: 1.046982090724882
Validation loss: 2.597788898523947

Epoch: 228| Step: 0
Training loss: 0.9040436688864101
Validation loss: 2.639248195776949

Epoch: 6| Step: 1
Training loss: 1.1911164978889655
Validation loss: 2.6178452296016954

Epoch: 6| Step: 2
Training loss: 1.335971898757041
Validation loss: 2.623057407414844

Epoch: 6| Step: 3
Training loss: 1.6323827150517303
Validation loss: 2.6467712312266993

Epoch: 6| Step: 4
Training loss: 0.9929581900454544
Validation loss: 2.6171176911497867

Epoch: 6| Step: 5
Training loss: 1.290337550409065
Validation loss: 2.583183203498507

Epoch: 6| Step: 6
Training loss: 1.061511533612533
Validation loss: 2.5850231245721917

Epoch: 6| Step: 7
Training loss: 0.7929887816055331
Validation loss: 2.5980112446816004

Epoch: 6| Step: 8
Training loss: 1.2538715488468866
Validation loss: 2.579046849879665

Epoch: 6| Step: 9
Training loss: 1.3522873186296116
Validation loss: 2.553506221403573

Epoch: 6| Step: 10
Training loss: 1.189011765950397
Validation loss: 2.556295630781387

Epoch: 6| Step: 11
Training loss: 0.8181603310272951
Validation loss: 2.581790696357394

Epoch: 6| Step: 12
Training loss: 1.021958483630974
Validation loss: 2.559921911627531

Epoch: 6| Step: 13
Training loss: 0.9335085139609131
Validation loss: 2.5693623975805804

Epoch: 229| Step: 0
Training loss: 1.186268519266037
Validation loss: 2.55296261481962

Epoch: 6| Step: 1
Training loss: 1.2004189217010117
Validation loss: 2.552282585182736

Epoch: 6| Step: 2
Training loss: 1.111632079273169
Validation loss: 2.551110113507114

Epoch: 6| Step: 3
Training loss: 1.1981363288610445
Validation loss: 2.5032242994348337

Epoch: 6| Step: 4
Training loss: 1.465118789283458
Validation loss: 2.5038996952622457

Epoch: 6| Step: 5
Training loss: 1.1613615819664813
Validation loss: 2.553015081817137

Epoch: 6| Step: 6
Training loss: 1.086118449771432
Validation loss: 2.5383268385136066

Epoch: 6| Step: 7
Training loss: 0.836364209369041
Validation loss: 2.5535966713687546

Epoch: 6| Step: 8
Training loss: 1.1350423504998761
Validation loss: 2.5908099998141876

Epoch: 6| Step: 9
Training loss: 1.0585439184643262
Validation loss: 2.5726654735866066

Epoch: 6| Step: 10
Training loss: 1.1182536126804818
Validation loss: 2.567213470098143

Epoch: 6| Step: 11
Training loss: 1.139943062715643
Validation loss: 2.594394560754459

Epoch: 6| Step: 12
Training loss: 0.4569356932554135
Validation loss: 2.5950741007993305

Epoch: 6| Step: 13
Training loss: 1.3850074201860207
Validation loss: 2.585054451096488

Epoch: 230| Step: 0
Training loss: 0.7937115727531955
Validation loss: 2.543715788896482

Epoch: 6| Step: 1
Training loss: 1.1812579079015126
Validation loss: 2.5233069493747537

Epoch: 6| Step: 2
Training loss: 1.0320973238704534
Validation loss: 2.549820217266991

Epoch: 6| Step: 3
Training loss: 1.3486728537966475
Validation loss: 2.5711265731252273

Epoch: 6| Step: 4
Training loss: 0.870719932096157
Validation loss: 2.5639463955166595

Epoch: 6| Step: 5
Training loss: 1.0436826969764703
Validation loss: 2.5599267957075473

Epoch: 6| Step: 6
Training loss: 0.907691926548889
Validation loss: 2.5659592502464497

Epoch: 6| Step: 7
Training loss: 1.3225278608419737
Validation loss: 2.6106003906402355

Epoch: 6| Step: 8
Training loss: 1.2623900526157663
Validation loss: 2.609051096846116

Epoch: 6| Step: 9
Training loss: 1.2462753115793466
Validation loss: 2.6097603023986498

Epoch: 6| Step: 10
Training loss: 1.074709748850068
Validation loss: 2.624014491201357

Epoch: 6| Step: 11
Training loss: 1.1936846350704338
Validation loss: 2.6387681485115366

Epoch: 6| Step: 12
Training loss: 0.9902000947996529
Validation loss: 2.623223742419514

Epoch: 6| Step: 13
Training loss: 1.0734800816159658
Validation loss: 2.629007668074745

Epoch: 231| Step: 0
Training loss: 1.1778359946571757
Validation loss: 2.6084833476736184

Epoch: 6| Step: 1
Training loss: 1.216005560921828
Validation loss: 2.5963890782701182

Epoch: 6| Step: 2
Training loss: 0.958890145017239
Validation loss: 2.5858754414930525

Epoch: 6| Step: 3
Training loss: 1.3078971261157473
Validation loss: 2.553100426124195

Epoch: 6| Step: 4
Training loss: 1.1160686732666882
Validation loss: 2.541537851639629

Epoch: 6| Step: 5
Training loss: 0.6758495141980017
Validation loss: 2.566428646740922

Epoch: 6| Step: 6
Training loss: 0.9897311585423464
Validation loss: 2.572685907570985

Epoch: 6| Step: 7
Training loss: 1.0944572886623936
Validation loss: 2.6134125345329737

Epoch: 6| Step: 8
Training loss: 1.1645445881484957
Validation loss: 2.620930067032977

Epoch: 6| Step: 9
Training loss: 1.2147091119373128
Validation loss: 2.6303389731345206

Epoch: 6| Step: 10
Training loss: 1.307171951628269
Validation loss: 2.6233914921590973

Epoch: 6| Step: 11
Training loss: 0.848771587653482
Validation loss: 2.601265070382349

Epoch: 6| Step: 12
Training loss: 1.3379008717388172
Validation loss: 2.5613928172989047

Epoch: 6| Step: 13
Training loss: 0.8469177052333442
Validation loss: 2.578798062894908

Epoch: 232| Step: 0
Training loss: 0.9624364683313054
Validation loss: 2.523504341337695

Epoch: 6| Step: 1
Training loss: 0.8493195839741633
Validation loss: 2.4897205838233205

Epoch: 6| Step: 2
Training loss: 0.6438765929107424
Validation loss: 2.4840485083600132

Epoch: 6| Step: 3
Training loss: 0.9317695320565249
Validation loss: 2.495476289779825

Epoch: 6| Step: 4
Training loss: 0.8791526618553174
Validation loss: 2.52174455822501

Epoch: 6| Step: 5
Training loss: 1.073237355770658
Validation loss: 2.532095327021298

Epoch: 6| Step: 6
Training loss: 1.4086474010132803
Validation loss: 2.5462208002092854

Epoch: 6| Step: 7
Training loss: 1.210999419567369
Validation loss: 2.5900795391426934

Epoch: 6| Step: 8
Training loss: 1.1884959210689716
Validation loss: 2.6164774475619406

Epoch: 6| Step: 9
Training loss: 1.294457998373065
Validation loss: 2.630713595693277

Epoch: 6| Step: 10
Training loss: 1.5192043864885414
Validation loss: 2.625139118498602

Epoch: 6| Step: 11
Training loss: 1.3837539140737256
Validation loss: 2.59386085266452

Epoch: 6| Step: 12
Training loss: 0.78212734550428
Validation loss: 2.5591221750684703

Epoch: 6| Step: 13
Training loss: 1.0348117471037763
Validation loss: 2.57232839903749

Epoch: 233| Step: 0
Training loss: 0.903788611192694
Validation loss: 2.544665174817899

Epoch: 6| Step: 1
Training loss: 1.3703593055795804
Validation loss: 2.556386932741889

Epoch: 6| Step: 2
Training loss: 0.9968010280034381
Validation loss: 2.5217863559601774

Epoch: 6| Step: 3
Training loss: 0.7834234141912119
Validation loss: 2.56346797593608

Epoch: 6| Step: 4
Training loss: 1.0857883597951032
Validation loss: 2.558870877585811

Epoch: 6| Step: 5
Training loss: 1.0778759654917922
Validation loss: 2.5610521569718037

Epoch: 6| Step: 6
Training loss: 1.2470911512672567
Validation loss: 2.5913726847500773

Epoch: 6| Step: 7
Training loss: 1.1588254032065755
Validation loss: 2.5834788130313386

Epoch: 6| Step: 8
Training loss: 1.4511195464730422
Validation loss: 2.58298018307923

Epoch: 6| Step: 9
Training loss: 1.3095038594134052
Validation loss: 2.568662334459511

Epoch: 6| Step: 10
Training loss: 1.068666626650817
Validation loss: 2.5669432184914953

Epoch: 6| Step: 11
Training loss: 1.2753998783821574
Validation loss: 2.544718096989027

Epoch: 6| Step: 12
Training loss: 1.0636108425756952
Validation loss: 2.5254703634732536

Epoch: 6| Step: 13
Training loss: 0.9907146244842158
Validation loss: 2.505428830920453

Epoch: 234| Step: 0
Training loss: 1.2016212677194784
Validation loss: 2.5278762723218926

Epoch: 6| Step: 1
Training loss: 0.847300828525098
Validation loss: 2.509666451956292

Epoch: 6| Step: 2
Training loss: 1.1478410067031546
Validation loss: 2.5377411251778295

Epoch: 6| Step: 3
Training loss: 1.3131846958047124
Validation loss: 2.553870986418321

Epoch: 6| Step: 4
Training loss: 1.2176967373380945
Validation loss: 2.558864093955615

Epoch: 6| Step: 5
Training loss: 0.8731291388684576
Validation loss: 2.5960355222831284

Epoch: 6| Step: 6
Training loss: 1.359591587395046
Validation loss: 2.597957677790746

Epoch: 6| Step: 7
Training loss: 1.0222246977412153
Validation loss: 2.634811279954114

Epoch: 6| Step: 8
Training loss: 1.2209067213027343
Validation loss: 2.5951226905670666

Epoch: 6| Step: 9
Training loss: 1.4422664401684022
Validation loss: 2.574339829043441

Epoch: 6| Step: 10
Training loss: 0.8290125930552095
Validation loss: 2.5653832155095504

Epoch: 6| Step: 11
Training loss: 0.8444594826495594
Validation loss: 2.5370499917516716

Epoch: 6| Step: 12
Training loss: 1.0555433968351249
Validation loss: 2.5714889284242557

Epoch: 6| Step: 13
Training loss: 0.5530882063444028
Validation loss: 2.582680338506517

Epoch: 235| Step: 0
Training loss: 1.380507924895456
Validation loss: 2.5663419046072704

Epoch: 6| Step: 1
Training loss: 1.4141000985052399
Validation loss: 2.5608986113403422

Epoch: 6| Step: 2
Training loss: 1.0479991058826272
Validation loss: 2.53359267746929

Epoch: 6| Step: 3
Training loss: 0.6663223857813615
Validation loss: 2.5307263894046006

Epoch: 6| Step: 4
Training loss: 0.9754095061173927
Validation loss: 2.509954683092237

Epoch: 6| Step: 5
Training loss: 1.0881260834523634
Validation loss: 2.48909747332029

Epoch: 6| Step: 6
Training loss: 1.0185436858975598
Validation loss: 2.5107806774163044

Epoch: 6| Step: 7
Training loss: 1.4590164038067388
Validation loss: 2.5240566609429034

Epoch: 6| Step: 8
Training loss: 1.150157496821284
Validation loss: 2.5238151891172858

Epoch: 6| Step: 9
Training loss: 0.8142809422850307
Validation loss: 2.5288832941113015

Epoch: 6| Step: 10
Training loss: 1.1465972896776118
Validation loss: 2.5631174863721427

Epoch: 6| Step: 11
Training loss: 0.7961859248204352
Validation loss: 2.568049590484941

Epoch: 6| Step: 12
Training loss: 0.5271438219646437
Validation loss: 2.601510556334441

Epoch: 6| Step: 13
Training loss: 1.2253799569343813
Validation loss: 2.5872499521977295

Epoch: 236| Step: 0
Training loss: 1.31465421728355
Validation loss: 2.585114009916208

Epoch: 6| Step: 1
Training loss: 0.7577824537475394
Validation loss: 2.587677194992812

Epoch: 6| Step: 2
Training loss: 1.42062801134199
Validation loss: 2.5610960128774893

Epoch: 6| Step: 3
Training loss: 1.0013254441544388
Validation loss: 2.5070443387475785

Epoch: 6| Step: 4
Training loss: 0.8305745155257048
Validation loss: 2.4858805275912847

Epoch: 6| Step: 5
Training loss: 0.9231188513177174
Validation loss: 2.4929923579517435

Epoch: 6| Step: 6
Training loss: 1.3610228712106778
Validation loss: 2.5051701214292676

Epoch: 6| Step: 7
Training loss: 0.7855758305035511
Validation loss: 2.5242037158309043

Epoch: 6| Step: 8
Training loss: 1.2529359194451162
Validation loss: 2.510478866583387

Epoch: 6| Step: 9
Training loss: 1.098585502453574
Validation loss: 2.5463499545545303

Epoch: 6| Step: 10
Training loss: 0.9154007399442057
Validation loss: 2.5768915461872894

Epoch: 6| Step: 11
Training loss: 0.9726975213911954
Validation loss: 2.6033862854902567

Epoch: 6| Step: 12
Training loss: 1.2813818793926643
Validation loss: 2.6319143543375314

Epoch: 6| Step: 13
Training loss: 0.6673146888230402
Validation loss: 2.655346771265344

Epoch: 237| Step: 0
Training loss: 1.12253958481486
Validation loss: 2.6308280404026485

Epoch: 6| Step: 1
Training loss: 1.0617766442419472
Validation loss: 2.584731493385161

Epoch: 6| Step: 2
Training loss: 0.8990146607528521
Validation loss: 2.53160778754427

Epoch: 6| Step: 3
Training loss: 0.7800977984274723
Validation loss: 2.5583178590247293

Epoch: 6| Step: 4
Training loss: 1.1914268616941441
Validation loss: 2.5359163608394923

Epoch: 6| Step: 5
Training loss: 1.102602690760448
Validation loss: 2.511945545294992

Epoch: 6| Step: 6
Training loss: 0.8981535753178641
Validation loss: 2.4730113168415886

Epoch: 6| Step: 7
Training loss: 0.9707267036874762
Validation loss: 2.466443697068008

Epoch: 6| Step: 8
Training loss: 0.8968341618720581
Validation loss: 2.477653492141679

Epoch: 6| Step: 9
Training loss: 1.0496926039366952
Validation loss: 2.4674584377496447

Epoch: 6| Step: 10
Training loss: 0.9951269506812218
Validation loss: 2.496698901117609

Epoch: 6| Step: 11
Training loss: 1.1833444968668574
Validation loss: 2.5263587082032433

Epoch: 6| Step: 12
Training loss: 0.9730454244644949
Validation loss: 2.602694976063672

Epoch: 6| Step: 13
Training loss: 1.42871886412168
Validation loss: 2.6385221409616366

Epoch: 238| Step: 0
Training loss: 1.1205381285935057
Validation loss: 2.664945888088824

Epoch: 6| Step: 1
Training loss: 0.823900640487746
Validation loss: 2.650810740461199

Epoch: 6| Step: 2
Training loss: 0.8804727792859224
Validation loss: 2.651575647619402

Epoch: 6| Step: 3
Training loss: 0.6718756653538448
Validation loss: 2.6506129617946215

Epoch: 6| Step: 4
Training loss: 1.0641407919605568
Validation loss: 2.612647165568404

Epoch: 6| Step: 5
Training loss: 1.240501170860885
Validation loss: 2.5850662653857728

Epoch: 6| Step: 6
Training loss: 1.1649828351274807
Validation loss: 2.5802348314439234

Epoch: 6| Step: 7
Training loss: 1.1297517665875394
Validation loss: 2.527631250406436

Epoch: 6| Step: 8
Training loss: 0.8067253012929592
Validation loss: 2.559306194551446

Epoch: 6| Step: 9
Training loss: 0.9608584735908625
Validation loss: 2.5434324949577656

Epoch: 6| Step: 10
Training loss: 0.9245840451921288
Validation loss: 2.5495484869860223

Epoch: 6| Step: 11
Training loss: 1.360441118675863
Validation loss: 2.5473903645673723

Epoch: 6| Step: 12
Training loss: 0.9546137267732444
Validation loss: 2.5645471354817313

Epoch: 6| Step: 13
Training loss: 1.446248591627591
Validation loss: 2.556665149847691

Epoch: 239| Step: 0
Training loss: 0.9760704937358573
Validation loss: 2.592013343407462

Epoch: 6| Step: 1
Training loss: 1.0734086744944156
Validation loss: 2.603801918983727

Epoch: 6| Step: 2
Training loss: 1.0763638250789547
Validation loss: 2.5869833128908026

Epoch: 6| Step: 3
Training loss: 0.9063118222952726
Validation loss: 2.560163207787271

Epoch: 6| Step: 4
Training loss: 0.9007576878982156
Validation loss: 2.6010068727336337

Epoch: 6| Step: 5
Training loss: 0.9173048824860297
Validation loss: 2.573734801194945

Epoch: 6| Step: 6
Training loss: 0.9114794301815782
Validation loss: 2.5425148437491316

Epoch: 6| Step: 7
Training loss: 1.0341156533564835
Validation loss: 2.561233277449016

Epoch: 6| Step: 8
Training loss: 0.8644714781014804
Validation loss: 2.550695528582735

Epoch: 6| Step: 9
Training loss: 1.1082547939170178
Validation loss: 2.5447018429645993

Epoch: 6| Step: 10
Training loss: 0.9118230398851351
Validation loss: 2.5375726526264577

Epoch: 6| Step: 11
Training loss: 0.9489765250635893
Validation loss: 2.544084747929131

Epoch: 6| Step: 12
Training loss: 1.4937633561690413
Validation loss: 2.52936156175877

Epoch: 6| Step: 13
Training loss: 0.9330113721320061
Validation loss: 2.5241319645648943

Epoch: 240| Step: 0
Training loss: 1.103377125918755
Validation loss: 2.535894552401222

Epoch: 6| Step: 1
Training loss: 1.2678229943326065
Validation loss: 2.5594838177120613

Epoch: 6| Step: 2
Training loss: 1.1629881028955118
Validation loss: 2.5697740048757036

Epoch: 6| Step: 3
Training loss: 1.4556288118750658
Validation loss: 2.5812919766831377

Epoch: 6| Step: 4
Training loss: 1.1814420675118686
Validation loss: 2.5936762303460967

Epoch: 6| Step: 5
Training loss: 0.5505835536811811
Validation loss: 2.5373816927686232

Epoch: 6| Step: 6
Training loss: 0.6825389462492032
Validation loss: 2.5229880757131373

Epoch: 6| Step: 7
Training loss: 1.0204341003955728
Validation loss: 2.511875335574375

Epoch: 6| Step: 8
Training loss: 0.8522289363130198
Validation loss: 2.5052174571058785

Epoch: 6| Step: 9
Training loss: 0.9226563908304726
Validation loss: 2.510395317682978

Epoch: 6| Step: 10
Training loss: 0.8035609683612421
Validation loss: 2.509934215901067

Epoch: 6| Step: 11
Training loss: 0.8730109631963174
Validation loss: 2.503928527994008

Epoch: 6| Step: 12
Training loss: 0.9786262069014502
Validation loss: 2.5034221340950364

Epoch: 6| Step: 13
Training loss: 1.1234272984239146
Validation loss: 2.5324299618246364

Epoch: 241| Step: 0
Training loss: 0.9776178989384187
Validation loss: 2.57083524725614

Epoch: 6| Step: 1
Training loss: 0.7967486561864718
Validation loss: 2.590816481117394

Epoch: 6| Step: 2
Training loss: 0.8625460294521006
Validation loss: 2.5537258391750504

Epoch: 6| Step: 3
Training loss: 0.8441960603869239
Validation loss: 2.570738892854794

Epoch: 6| Step: 4
Training loss: 1.1774583179847304
Validation loss: 2.556547904149341

Epoch: 6| Step: 5
Training loss: 0.6716191447826516
Validation loss: 2.571498358537697

Epoch: 6| Step: 6
Training loss: 1.0203324016598778
Validation loss: 2.5746615148254124

Epoch: 6| Step: 7
Training loss: 1.4100251282150527
Validation loss: 2.5432462052429416

Epoch: 6| Step: 8
Training loss: 1.0396317378352447
Validation loss: 2.541535345027297

Epoch: 6| Step: 9
Training loss: 0.879792237356514
Validation loss: 2.561636990763794

Epoch: 6| Step: 10
Training loss: 1.0497635802271565
Validation loss: 2.529309114942931

Epoch: 6| Step: 11
Training loss: 1.3266693665286888
Validation loss: 2.5158511904492755

Epoch: 6| Step: 12
Training loss: 0.9553266642640078
Validation loss: 2.512373273889416

Epoch: 6| Step: 13
Training loss: 0.6082360554565418
Validation loss: 2.524807968440037

Epoch: 242| Step: 0
Training loss: 0.9951782207845801
Validation loss: 2.567419048350007

Epoch: 6| Step: 1
Training loss: 0.9415413534003506
Validation loss: 2.6010191803154448

Epoch: 6| Step: 2
Training loss: 0.9553685283109785
Validation loss: 2.631172277588608

Epoch: 6| Step: 3
Training loss: 0.5843761240086481
Validation loss: 2.611487128372329

Epoch: 6| Step: 4
Training loss: 0.5580828804791608
Validation loss: 2.649006935684681

Epoch: 6| Step: 5
Training loss: 0.7858115730495594
Validation loss: 2.629161815041762

Epoch: 6| Step: 6
Training loss: 1.1943916314053538
Validation loss: 2.5736181354041863

Epoch: 6| Step: 7
Training loss: 1.2837718243401373
Validation loss: 2.545681186766736

Epoch: 6| Step: 8
Training loss: 1.030170742900959
Validation loss: 2.510650430534428

Epoch: 6| Step: 9
Training loss: 1.1756959801864333
Validation loss: 2.4746349987448344

Epoch: 6| Step: 10
Training loss: 1.3152039241409696
Validation loss: 2.477981715064876

Epoch: 6| Step: 11
Training loss: 0.8228484419214134
Validation loss: 2.4720161611433134

Epoch: 6| Step: 12
Training loss: 0.862811862844462
Validation loss: 2.455518343124178

Epoch: 6| Step: 13
Training loss: 1.0721644508421542
Validation loss: 2.4961509792390455

Epoch: 243| Step: 0
Training loss: 1.1468599864174505
Validation loss: 2.4570975252079226

Epoch: 6| Step: 1
Training loss: 0.9263528918056594
Validation loss: 2.4821492835308208

Epoch: 6| Step: 2
Training loss: 0.8389031754435774
Validation loss: 2.52212932029275

Epoch: 6| Step: 3
Training loss: 1.0834633614683176
Validation loss: 2.512432028942249

Epoch: 6| Step: 4
Training loss: 0.6513630696728441
Validation loss: 2.5600975964497548

Epoch: 6| Step: 5
Training loss: 1.0685903240293404
Validation loss: 2.571881556372673

Epoch: 6| Step: 6
Training loss: 0.6486082656474826
Validation loss: 2.5473779619201204

Epoch: 6| Step: 7
Training loss: 1.2593889486520105
Validation loss: 2.5585922986423886

Epoch: 6| Step: 8
Training loss: 1.1012502998931857
Validation loss: 2.573856923437955

Epoch: 6| Step: 9
Training loss: 1.1049990245763004
Validation loss: 2.572330356403546

Epoch: 6| Step: 10
Training loss: 0.8565942336852738
Validation loss: 2.5517834572385856

Epoch: 6| Step: 11
Training loss: 0.7755519593403511
Validation loss: 2.4999715034337413

Epoch: 6| Step: 12
Training loss: 0.8837571617818276
Validation loss: 2.5119867233072863

Epoch: 6| Step: 13
Training loss: 1.1021586218766788
Validation loss: 2.5200733509430773

Epoch: 244| Step: 0
Training loss: 1.162521007307014
Validation loss: 2.505946433716609

Epoch: 6| Step: 1
Training loss: 0.8202904834517564
Validation loss: 2.5081511054133867

Epoch: 6| Step: 2
Training loss: 1.1295095765280736
Validation loss: 2.4980300838230014

Epoch: 6| Step: 3
Training loss: 0.5023288433894835
Validation loss: 2.4921759840032207

Epoch: 6| Step: 4
Training loss: 0.8612052155077635
Validation loss: 2.50330570765868

Epoch: 6| Step: 5
Training loss: 1.206485365600614
Validation loss: 2.5099583554944616

Epoch: 6| Step: 6
Training loss: 1.0101799769613218
Validation loss: 2.5015831231430594

Epoch: 6| Step: 7
Training loss: 1.0287461372757212
Validation loss: 2.517682675898489

Epoch: 6| Step: 8
Training loss: 0.6117334210620589
Validation loss: 2.5343947944501837

Epoch: 6| Step: 9
Training loss: 1.1840465925753438
Validation loss: 2.5515729389198554

Epoch: 6| Step: 10
Training loss: 0.7217418349662742
Validation loss: 2.5971366496503787

Epoch: 6| Step: 11
Training loss: 0.8649497500470801
Validation loss: 2.5720492199291125

Epoch: 6| Step: 12
Training loss: 1.1282085651926672
Validation loss: 2.5860082258969492

Epoch: 6| Step: 13
Training loss: 0.9232702849365312
Validation loss: 2.548312773541681

Epoch: 245| Step: 0
Training loss: 1.1333694141385342
Validation loss: 2.5234732564855653

Epoch: 6| Step: 1
Training loss: 1.0126963719332092
Validation loss: 2.506057484485957

Epoch: 6| Step: 2
Training loss: 0.8184619921165354
Validation loss: 2.4911230242071967

Epoch: 6| Step: 3
Training loss: 0.8048018216894589
Validation loss: 2.480411276758281

Epoch: 6| Step: 4
Training loss: 0.9006011782903416
Validation loss: 2.5065886573848273

Epoch: 6| Step: 5
Training loss: 1.148588780410679
Validation loss: 2.51247075010328

Epoch: 6| Step: 6
Training loss: 0.3790254307143778
Validation loss: 2.5148199555407365

Epoch: 6| Step: 7
Training loss: 0.9578168486205512
Validation loss: 2.5381889724954894

Epoch: 6| Step: 8
Training loss: 1.0047844633829859
Validation loss: 2.55276886449348

Epoch: 6| Step: 9
Training loss: 1.0714855587654097
Validation loss: 2.604469103243148

Epoch: 6| Step: 10
Training loss: 0.8619111870796169
Validation loss: 2.6135174956134

Epoch: 6| Step: 11
Training loss: 0.6896503371755688
Validation loss: 2.6084474975072136

Epoch: 6| Step: 12
Training loss: 1.0498737827007378
Validation loss: 2.6081262953011706

Epoch: 6| Step: 13
Training loss: 1.3313867794207366
Validation loss: 2.5641583114831774

Epoch: 246| Step: 0
Training loss: 0.9001761158183137
Validation loss: 2.545558488272694

Epoch: 6| Step: 1
Training loss: 1.1863288625665256
Validation loss: 2.513903435972998

Epoch: 6| Step: 2
Training loss: 1.1484847286140731
Validation loss: 2.4605612523684655

Epoch: 6| Step: 3
Training loss: 0.8595722665658352
Validation loss: 2.4501306649230696

Epoch: 6| Step: 4
Training loss: 0.8204991446193628
Validation loss: 2.466592128340284

Epoch: 6| Step: 5
Training loss: 0.8499062907230179
Validation loss: 2.491974084864915

Epoch: 6| Step: 6
Training loss: 1.007677231811381
Validation loss: 2.5520879183324765

Epoch: 6| Step: 7
Training loss: 0.866010881478925
Validation loss: 2.591473497234101

Epoch: 6| Step: 8
Training loss: 0.4955714472476452
Validation loss: 2.570079274360015

Epoch: 6| Step: 9
Training loss: 1.3627459942694606
Validation loss: 2.603644557338049

Epoch: 6| Step: 10
Training loss: 0.9527137682173216
Validation loss: 2.6018014423831604

Epoch: 6| Step: 11
Training loss: 1.1455583878301352
Validation loss: 2.5713129959845493

Epoch: 6| Step: 12
Training loss: 0.44203367624328266
Validation loss: 2.5574608885002847

Epoch: 6| Step: 13
Training loss: 0.7790693749324521
Validation loss: 2.514172640679885

Epoch: 247| Step: 0
Training loss: 0.5456154077654612
Validation loss: 2.5045181997643264

Epoch: 6| Step: 1
Training loss: 1.0072779457606869
Validation loss: 2.4941616221442415

Epoch: 6| Step: 2
Training loss: 0.9237399875784794
Validation loss: 2.4577583577750555

Epoch: 6| Step: 3
Training loss: 0.7168719177046798
Validation loss: 2.476767939342817

Epoch: 6| Step: 4
Training loss: 0.8502597468063419
Validation loss: 2.501298470820763

Epoch: 6| Step: 5
Training loss: 1.2893563600303195
Validation loss: 2.5401313272541306

Epoch: 6| Step: 6
Training loss: 1.0510939802768093
Validation loss: 2.529205180983122

Epoch: 6| Step: 7
Training loss: 0.7228100587215667
Validation loss: 2.5540788521362163

Epoch: 6| Step: 8
Training loss: 1.0317437694889229
Validation loss: 2.5514447040792505

Epoch: 6| Step: 9
Training loss: 1.0403797719878773
Validation loss: 2.531438954404363

Epoch: 6| Step: 10
Training loss: 1.2304835727343804
Validation loss: 2.5257001383139994

Epoch: 6| Step: 11
Training loss: 0.660302185541303
Validation loss: 2.4936613346900622

Epoch: 6| Step: 12
Training loss: 0.9377450622697079
Validation loss: 2.521252491441997

Epoch: 6| Step: 13
Training loss: 0.4899106419595096
Validation loss: 2.499923130617405

Epoch: 248| Step: 0
Training loss: 0.8976191898992458
Validation loss: 2.51382621514855

Epoch: 6| Step: 1
Training loss: 1.023150804272313
Validation loss: 2.5418672897691637

Epoch: 6| Step: 2
Training loss: 0.6642209481091002
Validation loss: 2.5648013239994314

Epoch: 6| Step: 3
Training loss: 1.0973724324115628
Validation loss: 2.560445908166594

Epoch: 6| Step: 4
Training loss: 1.1748278227927733
Validation loss: 2.5527978000387326

Epoch: 6| Step: 5
Training loss: 0.9216539796872335
Validation loss: 2.5492691080369987

Epoch: 6| Step: 6
Training loss: 0.7018547451938579
Validation loss: 2.544530558888358

Epoch: 6| Step: 7
Training loss: 0.9424905191647899
Validation loss: 2.532524504072344

Epoch: 6| Step: 8
Training loss: 0.7936371490274421
Validation loss: 2.5238139478339936

Epoch: 6| Step: 9
Training loss: 0.5988807102712226
Validation loss: 2.525662335575162

Epoch: 6| Step: 10
Training loss: 0.8236155178180189
Validation loss: 2.5203151416044425

Epoch: 6| Step: 11
Training loss: 0.9822566839618418
Validation loss: 2.5466941267488528

Epoch: 6| Step: 12
Training loss: 1.3339736066749444
Validation loss: 2.569430661314632

Epoch: 6| Step: 13
Training loss: 0.3258098832132734
Validation loss: 2.5595998231846155

Epoch: 249| Step: 0
Training loss: 0.6876889966064188
Validation loss: 2.5347160006263367

Epoch: 6| Step: 1
Training loss: 0.7643085762164648
Validation loss: 2.527598127948099

Epoch: 6| Step: 2
Training loss: 1.3654337943365502
Validation loss: 2.5073325604822645

Epoch: 6| Step: 3
Training loss: 0.8291699636256423
Validation loss: 2.554080080718247

Epoch: 6| Step: 4
Training loss: 0.9471036477573809
Validation loss: 2.513636717492415

Epoch: 6| Step: 5
Training loss: 0.8958788387066777
Validation loss: 2.5021601983316044

Epoch: 6| Step: 6
Training loss: 0.8884710734783352
Validation loss: 2.557965572382161

Epoch: 6| Step: 7
Training loss: 0.7283077812804705
Validation loss: 2.521894671035857

Epoch: 6| Step: 8
Training loss: 0.8610516578050965
Validation loss: 2.555752291499604

Epoch: 6| Step: 9
Training loss: 0.7359620659164143
Validation loss: 2.580890912742187

Epoch: 6| Step: 10
Training loss: 1.0926833264762617
Validation loss: 2.587972011853597

Epoch: 6| Step: 11
Training loss: 1.1796625905217566
Validation loss: 2.6127001310339275

Epoch: 6| Step: 12
Training loss: 0.8578037810447079
Validation loss: 2.609482731841706

Epoch: 6| Step: 13
Training loss: 0.9085927476163994
Validation loss: 2.5800082759051937

Epoch: 250| Step: 0
Training loss: 0.7915932889026445
Validation loss: 2.603119758266132

Epoch: 6| Step: 1
Training loss: 0.9841183221804373
Validation loss: 2.5619631829512928

Epoch: 6| Step: 2
Training loss: 0.8372105681917443
Validation loss: 2.549287808803524

Epoch: 6| Step: 3
Training loss: 0.7308577863226403
Validation loss: 2.5803161130276173

Epoch: 6| Step: 4
Training loss: 0.6727740238951055
Validation loss: 2.543277956636942

Epoch: 6| Step: 5
Training loss: 0.5899541890414386
Validation loss: 2.547783796242266

Epoch: 6| Step: 6
Training loss: 0.9384653842986728
Validation loss: 2.5391065337825114

Epoch: 6| Step: 7
Training loss: 0.9422446035917328
Validation loss: 2.548613232863974

Epoch: 6| Step: 8
Training loss: 1.004952683165233
Validation loss: 2.5817704575640983

Epoch: 6| Step: 9
Training loss: 1.3106321940954537
Validation loss: 2.5579735319897763

Epoch: 6| Step: 10
Training loss: 1.0388722639969263
Validation loss: 2.5679573235055293

Epoch: 6| Step: 11
Training loss: 0.7153133246674123
Validation loss: 2.566685176924319

Epoch: 6| Step: 12
Training loss: 1.0817988177031568
Validation loss: 2.560194699810923

Epoch: 6| Step: 13
Training loss: 1.010018942249299
Validation loss: 2.5793907978494994

Epoch: 251| Step: 0
Training loss: 0.9371970004941813
Validation loss: 2.574879886761991

Epoch: 6| Step: 1
Training loss: 1.1614393338187567
Validation loss: 2.5815067161516594

Epoch: 6| Step: 2
Training loss: 0.5984531649538756
Validation loss: 2.537280623035935

Epoch: 6| Step: 3
Training loss: 0.8135681100830526
Validation loss: 2.515530402493339

Epoch: 6| Step: 4
Training loss: 1.142198705031179
Validation loss: 2.5466193936491774

Epoch: 6| Step: 5
Training loss: 0.715923640143228
Validation loss: 2.5074650255364954

Epoch: 6| Step: 6
Training loss: 0.5307201660511124
Validation loss: 2.5334986284125502

Epoch: 6| Step: 7
Training loss: 1.2227261556805262
Validation loss: 2.5304775378542037

Epoch: 6| Step: 8
Training loss: 0.7618160479099393
Validation loss: 2.4909294070542933

Epoch: 6| Step: 9
Training loss: 0.8508108128647444
Validation loss: 2.542460999477632

Epoch: 6| Step: 10
Training loss: 0.7396506874326256
Validation loss: 2.542920594748434

Epoch: 6| Step: 11
Training loss: 0.6216486245657341
Validation loss: 2.550217467036415

Epoch: 6| Step: 12
Training loss: 1.359914256155793
Validation loss: 2.554590371954743

Epoch: 6| Step: 13
Training loss: 0.6277867654374604
Validation loss: 2.595319677951721

Epoch: 252| Step: 0
Training loss: 0.6057894441937427
Validation loss: 2.57533252339992

Epoch: 6| Step: 1
Training loss: 0.9971152061047411
Validation loss: 2.5922184937287005

Epoch: 6| Step: 2
Training loss: 0.9264758759480379
Validation loss: 2.5897659737753527

Epoch: 6| Step: 3
Training loss: 0.6279880621133823
Validation loss: 2.5857810638064347

Epoch: 6| Step: 4
Training loss: 0.7401083484149423
Validation loss: 2.5785319126823834

Epoch: 6| Step: 5
Training loss: 0.7154713361584655
Validation loss: 2.5702933038859417

Epoch: 6| Step: 6
Training loss: 0.493440969550393
Validation loss: 2.549973071738508

Epoch: 6| Step: 7
Training loss: 1.0596161581923578
Validation loss: 2.564008153407055

Epoch: 6| Step: 8
Training loss: 0.9439137095759804
Validation loss: 2.545290399341365

Epoch: 6| Step: 9
Training loss: 1.2022649490083854
Validation loss: 2.5255712638015315

Epoch: 6| Step: 10
Training loss: 0.60644848219186
Validation loss: 2.5618152228676583

Epoch: 6| Step: 11
Training loss: 1.279289932814537
Validation loss: 2.5361055872287115

Epoch: 6| Step: 12
Training loss: 0.8488743902414037
Validation loss: 2.541946683844366

Epoch: 6| Step: 13
Training loss: 1.043996069221112
Validation loss: 2.5255736583589448

Epoch: 253| Step: 0
Training loss: 0.5615465773085421
Validation loss: 2.5387760729659696

Epoch: 6| Step: 1
Training loss: 1.220890512960954
Validation loss: 2.5752181076577796

Epoch: 6| Step: 2
Training loss: 1.211711709883189
Validation loss: 2.565466959218768

Epoch: 6| Step: 3
Training loss: 0.6002876843749991
Validation loss: 2.5607580391328235

Epoch: 6| Step: 4
Training loss: 0.8247972239202481
Validation loss: 2.5772106370166963

Epoch: 6| Step: 5
Training loss: 0.7676428459390189
Validation loss: 2.611234110091805

Epoch: 6| Step: 6
Training loss: 0.9368562713542626
Validation loss: 2.600583651443938

Epoch: 6| Step: 7
Training loss: 1.040164563840739
Validation loss: 2.589633963654429

Epoch: 6| Step: 8
Training loss: 0.7075260601703374
Validation loss: 2.562321772506299

Epoch: 6| Step: 9
Training loss: 0.8806135422426216
Validation loss: 2.5618546876643795

Epoch: 6| Step: 10
Training loss: 0.23607106060012176
Validation loss: 2.5501134839744757

Epoch: 6| Step: 11
Training loss: 0.8182174450289489
Validation loss: 2.529453283046023

Epoch: 6| Step: 12
Training loss: 0.8866673257175186
Validation loss: 2.515989549907777

Epoch: 6| Step: 13
Training loss: 1.1549146519127809
Validation loss: 2.5176944239774293

Epoch: 254| Step: 0
Training loss: 0.4558162678633842
Validation loss: 2.566233274767378

Epoch: 6| Step: 1
Training loss: 0.6761398025742889
Validation loss: 2.589185737634866

Epoch: 6| Step: 2
Training loss: 0.5459225398493909
Validation loss: 2.5723216877720985

Epoch: 6| Step: 3
Training loss: 0.7734766092912552
Validation loss: 2.590266499200674

Epoch: 6| Step: 4
Training loss: 0.989235940825129
Validation loss: 2.610969709010387

Epoch: 6| Step: 5
Training loss: 0.818826037072052
Validation loss: 2.5988382353692443

Epoch: 6| Step: 6
Training loss: 0.6119501039354217
Validation loss: 2.602406128083282

Epoch: 6| Step: 7
Training loss: 0.7191944406774025
Validation loss: 2.580641322043342

Epoch: 6| Step: 8
Training loss: 1.1285226031411493
Validation loss: 2.5863485698275754

Epoch: 6| Step: 9
Training loss: 1.0651356040338098
Validation loss: 2.5419515076597525

Epoch: 6| Step: 10
Training loss: 0.7661566153743772
Validation loss: 2.5485789592316443

Epoch: 6| Step: 11
Training loss: 1.291262096706572
Validation loss: 2.5375943064687507

Epoch: 6| Step: 12
Training loss: 1.154096143796643
Validation loss: 2.583279727878456

Epoch: 6| Step: 13
Training loss: 0.3962888564423711
Validation loss: 2.5831366360579944

Epoch: 255| Step: 0
Training loss: 0.9211751253195104
Validation loss: 2.5693161234417077

Epoch: 6| Step: 1
Training loss: 0.9752343874192339
Validation loss: 2.615621394939283

Epoch: 6| Step: 2
Training loss: 0.592420796762235
Validation loss: 2.5935330132758483

Epoch: 6| Step: 3
Training loss: 0.9931277528200114
Validation loss: 2.5888680519931313

Epoch: 6| Step: 4
Training loss: 0.4510182701309481
Validation loss: 2.579531500557319

Epoch: 6| Step: 5
Training loss: 0.6978903143922736
Validation loss: 2.5758721624943735

Epoch: 6| Step: 6
Training loss: 0.7447982245381066
Validation loss: 2.556180269668391

Epoch: 6| Step: 7
Training loss: 0.523027629654922
Validation loss: 2.563419768236064

Epoch: 6| Step: 8
Training loss: 0.9298130880206409
Validation loss: 2.5548131457200918

Epoch: 6| Step: 9
Training loss: 1.060801888114952
Validation loss: 2.5377018925246904

Epoch: 6| Step: 10
Training loss: 1.1052135267264505
Validation loss: 2.5662998625616025

Epoch: 6| Step: 11
Training loss: 0.7223746911117704
Validation loss: 2.5513428816603962

Epoch: 6| Step: 12
Training loss: 0.8660226507594463
Validation loss: 2.569281131669057

Epoch: 6| Step: 13
Training loss: 1.1800366825932256
Validation loss: 2.523656064217662

Epoch: 256| Step: 0
Training loss: 0.8466001691073243
Validation loss: 2.5864782003234303

Epoch: 6| Step: 1
Training loss: 0.5130223275822858
Validation loss: 2.5705214586699365

Epoch: 6| Step: 2
Training loss: 0.7925641009282468
Validation loss: 2.552033650205751

Epoch: 6| Step: 3
Training loss: 0.9526847698190318
Validation loss: 2.5706014527175087

Epoch: 6| Step: 4
Training loss: 1.0213728601332666
Validation loss: 2.562024562378566

Epoch: 6| Step: 5
Training loss: 0.8623055169694481
Validation loss: 2.5523522930714866

Epoch: 6| Step: 6
Training loss: 0.7975114636808057
Validation loss: 2.5312934901123296

Epoch: 6| Step: 7
Training loss: 0.723293703754477
Validation loss: 2.5192301903627548

Epoch: 6| Step: 8
Training loss: 0.34514551397284926
Validation loss: 2.5091253721103777

Epoch: 6| Step: 9
Training loss: 1.0233515929064472
Validation loss: 2.55196362420385

Epoch: 6| Step: 10
Training loss: 1.028139857500781
Validation loss: 2.5145457011079024

Epoch: 6| Step: 11
Training loss: 0.7974851179976554
Validation loss: 2.5572355764765744

Epoch: 6| Step: 12
Training loss: 1.0179587913371522
Validation loss: 2.5639427019545225

Epoch: 6| Step: 13
Training loss: 0.8801895944681069
Validation loss: 2.550059318345167

Epoch: 257| Step: 0
Training loss: 0.7193541268403526
Validation loss: 2.5942454590709927

Epoch: 6| Step: 1
Training loss: 0.6991662586477708
Validation loss: 2.529252205192648

Epoch: 6| Step: 2
Training loss: 0.7246248392681044
Validation loss: 2.5428820171636466

Epoch: 6| Step: 3
Training loss: 0.9093123686416282
Validation loss: 2.552824528948455

Epoch: 6| Step: 4
Training loss: 0.7747515680150145
Validation loss: 2.5440175383621035

Epoch: 6| Step: 5
Training loss: 0.39991490084690245
Validation loss: 2.555624843172047

Epoch: 6| Step: 6
Training loss: 1.0997855280821487
Validation loss: 2.575713007905321

Epoch: 6| Step: 7
Training loss: 1.1174223859660868
Validation loss: 2.5703764687235697

Epoch: 6| Step: 8
Training loss: 0.8071381740880306
Validation loss: 2.5913515641342393

Epoch: 6| Step: 9
Training loss: 0.9659618123603736
Validation loss: 2.5758310284214123

Epoch: 6| Step: 10
Training loss: 0.5797708898648896
Validation loss: 2.5725046098317152

Epoch: 6| Step: 11
Training loss: 0.9633565089024047
Validation loss: 2.5544223904364154

Epoch: 6| Step: 12
Training loss: 0.474110376333151
Validation loss: 2.550800159782941

Epoch: 6| Step: 13
Training loss: 1.1466997454459251
Validation loss: 2.5239995111324376

Epoch: 258| Step: 0
Training loss: 0.8469366016012994
Validation loss: 2.557585196134503

Epoch: 6| Step: 1
Training loss: 0.51598738449407
Validation loss: 2.5385036406899215

Epoch: 6| Step: 2
Training loss: 0.9723041310699
Validation loss: 2.537056612414087

Epoch: 6| Step: 3
Training loss: 0.425497870679743
Validation loss: 2.5632298648415635

Epoch: 6| Step: 4
Training loss: 1.0963202657766515
Validation loss: 2.587691074818722

Epoch: 6| Step: 5
Training loss: 1.05810479277205
Validation loss: 2.6029372143758804

Epoch: 6| Step: 6
Training loss: 1.0513139246715573
Validation loss: 2.577180572977018

Epoch: 6| Step: 7
Training loss: 1.0251380245970747
Validation loss: 2.6031021311565357

Epoch: 6| Step: 8
Training loss: 0.7138967442688481
Validation loss: 2.5985814855684195

Epoch: 6| Step: 9
Training loss: 0.5589843131544504
Validation loss: 2.6218660068285615

Epoch: 6| Step: 10
Training loss: 0.7717729632313524
Validation loss: 2.59458871726351

Epoch: 6| Step: 11
Training loss: 0.7863994264751916
Validation loss: 2.573250261996036

Epoch: 6| Step: 12
Training loss: 0.5737423120453149
Validation loss: 2.546653257262319

Epoch: 6| Step: 13
Training loss: 1.0192737473394382
Validation loss: 2.5904191442907742

Epoch: 259| Step: 0
Training loss: 0.810637246115131
Validation loss: 2.556044240204614

Epoch: 6| Step: 1
Training loss: 0.7615965133791542
Validation loss: 2.530529580547037

Epoch: 6| Step: 2
Training loss: 0.8355004068073444
Validation loss: 2.546432457675926

Epoch: 6| Step: 3
Training loss: 0.7950000021592626
Validation loss: 2.514027667172819

Epoch: 6| Step: 4
Training loss: 0.49011963189183544
Validation loss: 2.5266062927641415

Epoch: 6| Step: 5
Training loss: 1.103428227837519
Validation loss: 2.5107223582646494

Epoch: 6| Step: 6
Training loss: 0.7148549230150565
Validation loss: 2.5196436820127976

Epoch: 6| Step: 7
Training loss: 1.0564433423117547
Validation loss: 2.466934777685171

Epoch: 6| Step: 8
Training loss: 0.7350826100875375
Validation loss: 2.484039809268719

Epoch: 6| Step: 9
Training loss: 0.6337514904388418
Validation loss: 2.5028065596874525

Epoch: 6| Step: 10
Training loss: 0.788201948700601
Validation loss: 2.491950403750194

Epoch: 6| Step: 11
Training loss: 1.0275876296050541
Validation loss: 2.5321762601163798

Epoch: 6| Step: 12
Training loss: 0.8524051661615438
Validation loss: 2.5158541903697635

Epoch: 6| Step: 13
Training loss: 0.2764544669319088
Validation loss: 2.530832721888237

Epoch: 260| Step: 0
Training loss: 0.7330485600185126
Validation loss: 2.5673261266183576

Epoch: 6| Step: 1
Training loss: 0.6192709608107282
Validation loss: 2.5810330146258087

Epoch: 6| Step: 2
Training loss: 0.9564427025798128
Validation loss: 2.546452095417058

Epoch: 6| Step: 3
Training loss: 0.7777846346469657
Validation loss: 2.54997469036741

Epoch: 6| Step: 4
Training loss: 0.9660337576762801
Validation loss: 2.556941945045203

Epoch: 6| Step: 5
Training loss: 0.6270288201861781
Validation loss: 2.5524112469822486

Epoch: 6| Step: 6
Training loss: 0.782591659552246
Validation loss: 2.5210825702738107

Epoch: 6| Step: 7
Training loss: 0.7220486122525342
Validation loss: 2.5170438007846867

Epoch: 6| Step: 8
Training loss: 0.78572570495234
Validation loss: 2.5115844928497273

Epoch: 6| Step: 9
Training loss: 0.6217784586207882
Validation loss: 2.5430466570185426

Epoch: 6| Step: 10
Training loss: 0.9450396624824847
Validation loss: 2.4989959859293784

Epoch: 6| Step: 11
Training loss: 1.0372464938854982
Validation loss: 2.524711450622501

Epoch: 6| Step: 12
Training loss: 0.947919953868043
Validation loss: 2.518026172187232

Epoch: 6| Step: 13
Training loss: 0.4621654415218697
Validation loss: 2.522666056109462

Epoch: 261| Step: 0
Training loss: 0.860067920497803
Validation loss: 2.57098626897987

Epoch: 6| Step: 1
Training loss: 0.9115825168842979
Validation loss: 2.5977833642359194

Epoch: 6| Step: 2
Training loss: 0.5890229684936753
Validation loss: 2.5893432012707285

Epoch: 6| Step: 3
Training loss: 0.7172121928832229
Validation loss: 2.609624580432115

Epoch: 6| Step: 4
Training loss: 0.8586899541215474
Validation loss: 2.581701494337884

Epoch: 6| Step: 5
Training loss: 0.6232562535443125
Validation loss: 2.5795646220380704

Epoch: 6| Step: 6
Training loss: 0.8162516032228017
Validation loss: 2.5752244549852152

Epoch: 6| Step: 7
Training loss: 0.8907453890629475
Validation loss: 2.5606978927978177

Epoch: 6| Step: 8
Training loss: 0.48586583667021493
Validation loss: 2.4939341183094728

Epoch: 6| Step: 9
Training loss: 0.744030961894729
Validation loss: 2.4796193844321954

Epoch: 6| Step: 10
Training loss: 0.8658170438842896
Validation loss: 2.461374642279271

Epoch: 6| Step: 11
Training loss: 0.8897164043505328
Validation loss: 2.4413254774944892

Epoch: 6| Step: 12
Training loss: 1.034255186212237
Validation loss: 2.463896651531178

Epoch: 6| Step: 13
Training loss: 1.029080797131815
Validation loss: 2.547997552473257

Epoch: 262| Step: 0
Training loss: 0.29248500304616
Validation loss: 2.5456195643334305

Epoch: 6| Step: 1
Training loss: 0.7622267374134191
Validation loss: 2.5697487591504093

Epoch: 6| Step: 2
Training loss: 1.0764508725166106
Validation loss: 2.5945219830059916

Epoch: 6| Step: 3
Training loss: 0.8920293076494552
Validation loss: 2.57884887596102

Epoch: 6| Step: 4
Training loss: 1.025367256988193
Validation loss: 2.559374381931523

Epoch: 6| Step: 5
Training loss: 1.0031905536088224
Validation loss: 2.5358722858149934

Epoch: 6| Step: 6
Training loss: 0.5707443379084967
Validation loss: 2.4989726570635784

Epoch: 6| Step: 7
Training loss: 0.6195925919132392
Validation loss: 2.514341116043659

Epoch: 6| Step: 8
Training loss: 0.7198284599811671
Validation loss: 2.5214743501324395

Epoch: 6| Step: 9
Training loss: 1.00394496026717
Validation loss: 2.4952443893165386

Epoch: 6| Step: 10
Training loss: 0.8237059385472081
Validation loss: 2.4835615404495424

Epoch: 6| Step: 11
Training loss: 0.8358285066370802
Validation loss: 2.5087771700213226

Epoch: 6| Step: 12
Training loss: 0.7354206189561785
Validation loss: 2.4984382550435185

Epoch: 6| Step: 13
Training loss: 0.7765366855068654
Validation loss: 2.5393647539511677

Epoch: 263| Step: 0
Training loss: 0.9097830207704484
Validation loss: 2.5339323249148915

Epoch: 6| Step: 1
Training loss: 0.9834125597336586
Validation loss: 2.5662381378446795

Epoch: 6| Step: 2
Training loss: 0.6647342650009899
Validation loss: 2.542282020587583

Epoch: 6| Step: 3
Training loss: 0.778501022975203
Validation loss: 2.5717107826434176

Epoch: 6| Step: 4
Training loss: 0.8166458289413888
Validation loss: 2.554962776583511

Epoch: 6| Step: 5
Training loss: 0.6749723587734425
Validation loss: 2.556899751447799

Epoch: 6| Step: 6
Training loss: 0.7949669002744019
Validation loss: 2.5853174150996474

Epoch: 6| Step: 7
Training loss: 0.3761794100409806
Validation loss: 2.55712248342778

Epoch: 6| Step: 8
Training loss: 1.0475618756576142
Validation loss: 2.548412436483532

Epoch: 6| Step: 9
Training loss: 0.6012837643570533
Validation loss: 2.546135910984953

Epoch: 6| Step: 10
Training loss: 0.6521073786859335
Validation loss: 2.5295219543909364

Epoch: 6| Step: 11
Training loss: 0.8082739893441337
Validation loss: 2.535745171814635

Epoch: 6| Step: 12
Training loss: 0.7028726336788566
Validation loss: 2.527856349306158

Epoch: 6| Step: 13
Training loss: 1.1337181943156396
Validation loss: 2.5125244840619625

Epoch: 264| Step: 0
Training loss: 0.7090139671854585
Validation loss: 2.540989391344744

Epoch: 6| Step: 1
Training loss: 0.5624134209017749
Validation loss: 2.522616774977165

Epoch: 6| Step: 2
Training loss: 0.4984760604340508
Validation loss: 2.501105003311604

Epoch: 6| Step: 3
Training loss: 0.6494110795719792
Validation loss: 2.5531763360983026

Epoch: 6| Step: 4
Training loss: 0.5420027998151641
Validation loss: 2.585564435525643

Epoch: 6| Step: 5
Training loss: 0.7071816300280439
Validation loss: 2.5590242708912285

Epoch: 6| Step: 6
Training loss: 0.9754089867051743
Validation loss: 2.622838462001182

Epoch: 6| Step: 7
Training loss: 1.0060069151881472
Validation loss: 2.596342975777763

Epoch: 6| Step: 8
Training loss: 0.7439437165146802
Validation loss: 2.592608917796622

Epoch: 6| Step: 9
Training loss: 1.1589296580667878
Validation loss: 2.551691140599716

Epoch: 6| Step: 10
Training loss: 0.4604813209580753
Validation loss: 2.546769568332533

Epoch: 6| Step: 11
Training loss: 0.7869088270023156
Validation loss: 2.5655164464866673

Epoch: 6| Step: 12
Training loss: 0.8508825474764817
Validation loss: 2.5776407420319125

Epoch: 6| Step: 13
Training loss: 0.8591625297760057
Validation loss: 2.55458177860376

Epoch: 265| Step: 0
Training loss: 0.9160650113910637
Validation loss: 2.557685158300951

Epoch: 6| Step: 1
Training loss: 0.6224973162244678
Validation loss: 2.5618588305471515

Epoch: 6| Step: 2
Training loss: 0.6647912906879576
Validation loss: 2.551219165208879

Epoch: 6| Step: 3
Training loss: 0.5817215370687299
Validation loss: 2.5705222096541815

Epoch: 6| Step: 4
Training loss: 0.6332925694506032
Validation loss: 2.57780735499017

Epoch: 6| Step: 5
Training loss: 0.6404864929079329
Validation loss: 2.580290643569939

Epoch: 6| Step: 6
Training loss: 0.8351014849956887
Validation loss: 2.5809404260975715

Epoch: 6| Step: 7
Training loss: 1.0453059266116072
Validation loss: 2.6128111917972268

Epoch: 6| Step: 8
Training loss: 0.820903419916978
Validation loss: 2.569529111073833

Epoch: 6| Step: 9
Training loss: 0.6663420651865426
Validation loss: 2.567404689472576

Epoch: 6| Step: 10
Training loss: 0.8177833077304509
Validation loss: 2.5701236205999214

Epoch: 6| Step: 11
Training loss: 0.8628442616265869
Validation loss: 2.575782695792762

Epoch: 6| Step: 12
Training loss: 0.9724266363385777
Validation loss: 2.5615484920690363

Epoch: 6| Step: 13
Training loss: 0.5976110204399273
Validation loss: 2.576504378140608

Epoch: 266| Step: 0
Training loss: 0.510895102605458
Validation loss: 2.5988200085502426

Epoch: 6| Step: 1
Training loss: 0.2924972045389906
Validation loss: 2.580171957400476

Epoch: 6| Step: 2
Training loss: 0.7895452703261214
Validation loss: 2.590455203381934

Epoch: 6| Step: 3
Training loss: 0.7532522893314408
Validation loss: 2.5986142646007475

Epoch: 6| Step: 4
Training loss: 0.2821859046662818
Validation loss: 2.591364042225569

Epoch: 6| Step: 5
Training loss: 0.6190449493323563
Validation loss: 2.5561597348283898

Epoch: 6| Step: 6
Training loss: 0.9452268072964025
Validation loss: 2.5734903196673264

Epoch: 6| Step: 7
Training loss: 0.8842749171695032
Validation loss: 2.5525728105803394

Epoch: 6| Step: 8
Training loss: 0.6159782393485478
Validation loss: 2.547497603082329

Epoch: 6| Step: 9
Training loss: 1.2279330329248757
Validation loss: 2.5252673710647384

Epoch: 6| Step: 10
Training loss: 0.8801211289465755
Validation loss: 2.5350052437353163

Epoch: 6| Step: 11
Training loss: 0.7339338235464973
Validation loss: 2.5023176730039793

Epoch: 6| Step: 12
Training loss: 0.863865305247144
Validation loss: 2.534603490749026

Epoch: 6| Step: 13
Training loss: 0.7646505031825745
Validation loss: 2.5436517060377817

Epoch: 267| Step: 0
Training loss: 0.6219282961296531
Validation loss: 2.553912118335909

Epoch: 6| Step: 1
Training loss: 0.6976878706888282
Validation loss: 2.5642158882101516

Epoch: 6| Step: 2
Training loss: 0.9176525788937687
Validation loss: 2.554446778012369

Epoch: 6| Step: 3
Training loss: 0.8027703864194747
Validation loss: 2.5939337888545784

Epoch: 6| Step: 4
Training loss: 0.9161783492733864
Validation loss: 2.54830878368344

Epoch: 6| Step: 5
Training loss: 0.769340530230722
Validation loss: 2.532238728550213

Epoch: 6| Step: 6
Training loss: 0.5616969097703736
Validation loss: 2.5462250893502385

Epoch: 6| Step: 7
Training loss: 0.6113200324257196
Validation loss: 2.492505906779009

Epoch: 6| Step: 8
Training loss: 0.9944299303152347
Validation loss: 2.4871848813052995

Epoch: 6| Step: 9
Training loss: 0.7112177202244179
Validation loss: 2.5056195770380887

Epoch: 6| Step: 10
Training loss: 0.9745478486419241
Validation loss: 2.4846165470546415

Epoch: 6| Step: 11
Training loss: 0.7225199802896282
Validation loss: 2.512056506392885

Epoch: 6| Step: 12
Training loss: 0.32860000606210066
Validation loss: 2.5206683352425987

Epoch: 6| Step: 13
Training loss: 0.6409453312224768
Validation loss: 2.552240570695887

Epoch: 268| Step: 0
Training loss: 0.7900719936377747
Validation loss: 2.515996761949819

Epoch: 6| Step: 1
Training loss: 0.9666551890733209
Validation loss: 2.553377999317976

Epoch: 6| Step: 2
Training loss: 0.7882628968959549
Validation loss: 2.5828576395918317

Epoch: 6| Step: 3
Training loss: 0.6087716612594554
Validation loss: 2.584839911148731

Epoch: 6| Step: 4
Training loss: 1.0349936879467723
Validation loss: 2.5625823503173164

Epoch: 6| Step: 5
Training loss: 0.48967463237261566
Validation loss: 2.580370493725721

Epoch: 6| Step: 6
Training loss: 0.8708965266416999
Validation loss: 2.578249311635253

Epoch: 6| Step: 7
Training loss: 0.3597814086367667
Validation loss: 2.566251758008434

Epoch: 6| Step: 8
Training loss: 0.9437622726349817
Validation loss: 2.537443588003995

Epoch: 6| Step: 9
Training loss: 0.7701440298078744
Validation loss: 2.5347136844931932

Epoch: 6| Step: 10
Training loss: 0.5905664828744793
Validation loss: 2.5589794397715484

Epoch: 6| Step: 11
Training loss: 0.47983431604043375
Validation loss: 2.53237414670389

Epoch: 6| Step: 12
Training loss: 0.7178548546112723
Validation loss: 2.5292494857123566

Epoch: 6| Step: 13
Training loss: 0.5415750083645465
Validation loss: 2.5403586371728193

Epoch: 269| Step: 0
Training loss: 0.5664288220347471
Validation loss: 2.5048791229336653

Epoch: 6| Step: 1
Training loss: 0.5791423197872899
Validation loss: 2.524929917763137

Epoch: 6| Step: 2
Training loss: 0.9718176968966901
Validation loss: 2.541395398502289

Epoch: 6| Step: 3
Training loss: 0.9976438540985788
Validation loss: 2.535034281922035

Epoch: 6| Step: 4
Training loss: 0.8087963642821582
Validation loss: 2.539805235158301

Epoch: 6| Step: 5
Training loss: 0.7075699076807683
Validation loss: 2.5564877409921705

Epoch: 6| Step: 6
Training loss: 0.7910691984896209
Validation loss: 2.5267359738567636

Epoch: 6| Step: 7
Training loss: 0.7373206534772772
Validation loss: 2.5315567675384645

Epoch: 6| Step: 8
Training loss: 0.7136855618438608
Validation loss: 2.5020706400072394

Epoch: 6| Step: 9
Training loss: 0.466400552839439
Validation loss: 2.522157610724664

Epoch: 6| Step: 10
Training loss: 0.5648038625813373
Validation loss: 2.534406588974194

Epoch: 6| Step: 11
Training loss: 0.9509715157102876
Validation loss: 2.543597531058331

Epoch: 6| Step: 12
Training loss: 0.6172669757905005
Validation loss: 2.5632080892599935

Epoch: 6| Step: 13
Training loss: 0.5670979978284907
Validation loss: 2.565758547909902

Epoch: 270| Step: 0
Training loss: 0.9246936316510873
Validation loss: 2.610347265784886

Epoch: 6| Step: 1
Training loss: 0.7953154318405102
Validation loss: 2.607825177769029

Epoch: 6| Step: 2
Training loss: 0.3400889202904706
Validation loss: 2.5952568722754465

Epoch: 6| Step: 3
Training loss: 0.9216662671695922
Validation loss: 2.629065182930947

Epoch: 6| Step: 4
Training loss: 0.9500244865273346
Validation loss: 2.584032645991676

Epoch: 6| Step: 5
Training loss: 0.7058466054651144
Validation loss: 2.5839135560051183

Epoch: 6| Step: 6
Training loss: 0.8299663154247195
Validation loss: 2.5432808566699032

Epoch: 6| Step: 7
Training loss: 0.3727313999560219
Validation loss: 2.550664690681235

Epoch: 6| Step: 8
Training loss: 0.502284493518411
Validation loss: 2.5597846117887224

Epoch: 6| Step: 9
Training loss: 0.4101314718845581
Validation loss: 2.5028932370379398

Epoch: 6| Step: 10
Training loss: 0.7150889325354094
Validation loss: 2.5390183028925124

Epoch: 6| Step: 11
Training loss: 0.9237298570431887
Validation loss: 2.535984132858449

Epoch: 6| Step: 12
Training loss: 0.7493271193427685
Validation loss: 2.5594201346621426

Epoch: 6| Step: 13
Training loss: 0.5571246000720278
Validation loss: 2.5666109979449843

Epoch: 271| Step: 0
Training loss: 0.8413800050402135
Validation loss: 2.594074691017889

Epoch: 6| Step: 1
Training loss: 0.450988352387277
Validation loss: 2.6215345416332307

Epoch: 6| Step: 2
Training loss: 0.52476594794012
Validation loss: 2.581482731191295

Epoch: 6| Step: 3
Training loss: 0.6450237819811678
Validation loss: 2.581592958674567

Epoch: 6| Step: 4
Training loss: 0.8288851434175869
Validation loss: 2.54620097743771

Epoch: 6| Step: 5
Training loss: 0.4917218563925992
Validation loss: 2.537683350854268

Epoch: 6| Step: 6
Training loss: 0.824893657014923
Validation loss: 2.52817234968604

Epoch: 6| Step: 7
Training loss: 0.781810597512494
Validation loss: 2.5254238297055456

Epoch: 6| Step: 8
Training loss: 0.6499848574928623
Validation loss: 2.4977288912921742

Epoch: 6| Step: 9
Training loss: 0.8674634889510255
Validation loss: 2.4688135702002385

Epoch: 6| Step: 10
Training loss: 0.758163999857908
Validation loss: 2.4614675737157485

Epoch: 6| Step: 11
Training loss: 0.9514662895986461
Validation loss: 2.498844942269523

Epoch: 6| Step: 12
Training loss: 0.7908950525391213
Validation loss: 2.501763412018705

Epoch: 6| Step: 13
Training loss: 0.4818675141798288
Validation loss: 2.570056618161435

Epoch: 272| Step: 0
Training loss: 0.6812323191736924
Validation loss: 2.5508039889592298

Epoch: 6| Step: 1
Training loss: 0.779260275992377
Validation loss: 2.5897064966995074

Epoch: 6| Step: 2
Training loss: 0.8413916229705143
Validation loss: 2.5863538391481518

Epoch: 6| Step: 3
Training loss: 0.7383208087636718
Validation loss: 2.578429169919765

Epoch: 6| Step: 4
Training loss: 0.6510610933584343
Validation loss: 2.5548645040499123

Epoch: 6| Step: 5
Training loss: 0.836602810788705
Validation loss: 2.53043192743489

Epoch: 6| Step: 6
Training loss: 0.6244775734425876
Validation loss: 2.5302257990162196

Epoch: 6| Step: 7
Training loss: 0.6896862251950967
Validation loss: 2.5188949174412576

Epoch: 6| Step: 8
Training loss: 0.7242015091737847
Validation loss: 2.4881816796505456

Epoch: 6| Step: 9
Training loss: 0.46712150617951176
Validation loss: 2.4752461998427404

Epoch: 6| Step: 10
Training loss: 0.7887022876968955
Validation loss: 2.4764175608125814

Epoch: 6| Step: 11
Training loss: 0.590584952394421
Validation loss: 2.4881256689017532

Epoch: 6| Step: 12
Training loss: 1.0113681495028086
Validation loss: 2.5036024487452457

Epoch: 6| Step: 13
Training loss: 0.6656726390285445
Validation loss: 2.5182234028960244

Epoch: 273| Step: 0
Training loss: 0.815327419789293
Validation loss: 2.5851651044329804

Epoch: 6| Step: 1
Training loss: 0.9902730779965806
Validation loss: 2.5980266574963875

Epoch: 6| Step: 2
Training loss: 0.9026167155320003
Validation loss: 2.5947575051125513

Epoch: 6| Step: 3
Training loss: 0.6772276333339851
Validation loss: 2.6061046587063097

Epoch: 6| Step: 4
Training loss: 0.7769694745168916
Validation loss: 2.6176193769905125

Epoch: 6| Step: 5
Training loss: 0.5388490558379192
Validation loss: 2.591637140374979

Epoch: 6| Step: 6
Training loss: 0.956861893597124
Validation loss: 2.536817745320796

Epoch: 6| Step: 7
Training loss: 0.3458306244472135
Validation loss: 2.547111201825767

Epoch: 6| Step: 8
Training loss: 0.6202733841869669
Validation loss: 2.544878292405475

Epoch: 6| Step: 9
Training loss: 0.6424822518387296
Validation loss: 2.4973777154338017

Epoch: 6| Step: 10
Training loss: 0.6701005969749789
Validation loss: 2.5208812889745267

Epoch: 6| Step: 11
Training loss: 0.8887050412874333
Validation loss: 2.540111449896086

Epoch: 6| Step: 12
Training loss: 0.5079327367608774
Validation loss: 2.5434426343625343

Epoch: 6| Step: 13
Training loss: 0.5795523061704296
Validation loss: 2.5404809041387613

Epoch: 274| Step: 0
Training loss: 0.8023048235430993
Validation loss: 2.5904780968242482

Epoch: 6| Step: 1
Training loss: 0.9094710820357598
Validation loss: 2.5807302885217736

Epoch: 6| Step: 2
Training loss: 0.3303177319403745
Validation loss: 2.592282499434225

Epoch: 6| Step: 3
Training loss: 0.6178064019727597
Validation loss: 2.5688722037739016

Epoch: 6| Step: 4
Training loss: 0.6937648823147047
Validation loss: 2.599962219195694

Epoch: 6| Step: 5
Training loss: 0.8006286103452328
Validation loss: 2.5711341779076657

Epoch: 6| Step: 6
Training loss: 0.6658033552889103
Validation loss: 2.5591299269696086

Epoch: 6| Step: 7
Training loss: 0.8776750205818709
Validation loss: 2.5666939514887606

Epoch: 6| Step: 8
Training loss: 0.8222920828071535
Validation loss: 2.5246465147410984

Epoch: 6| Step: 9
Training loss: 0.4868959842023479
Validation loss: 2.5227924694528197

Epoch: 6| Step: 10
Training loss: 0.6728051865849516
Validation loss: 2.5704149912182777

Epoch: 6| Step: 11
Training loss: 0.6520394626358923
Validation loss: 2.547366933939463

Epoch: 6| Step: 12
Training loss: 0.8653187592219068
Validation loss: 2.550089612404046

Epoch: 6| Step: 13
Training loss: 0.70760356017091
Validation loss: 2.555346011178385

Epoch: 275| Step: 0
Training loss: 0.3891616112886459
Validation loss: 2.548680295591296

Epoch: 6| Step: 1
Training loss: 0.7303159013243747
Validation loss: 2.576647593519398

Epoch: 6| Step: 2
Training loss: 0.8964152257508837
Validation loss: 2.5871736774990652

Epoch: 6| Step: 3
Training loss: 0.6241506766200934
Validation loss: 2.5970730330626286

Epoch: 6| Step: 4
Training loss: 0.6521116746181196
Validation loss: 2.5764029217173787

Epoch: 6| Step: 5
Training loss: 0.9755124970402552
Validation loss: 2.595433775503247

Epoch: 6| Step: 6
Training loss: 0.8936954908487926
Validation loss: 2.5554884460677134

Epoch: 6| Step: 7
Training loss: 0.5885706165811742
Validation loss: 2.5709634213436936

Epoch: 6| Step: 8
Training loss: 0.60748011073768
Validation loss: 2.5639801652665954

Epoch: 6| Step: 9
Training loss: 0.6293367606463024
Validation loss: 2.551714080422871

Epoch: 6| Step: 10
Training loss: 0.7162849614796266
Validation loss: 2.5095071419371155

Epoch: 6| Step: 11
Training loss: 0.7936943380107981
Validation loss: 2.485709426045405

Epoch: 6| Step: 12
Training loss: 0.9325060393723363
Validation loss: 2.5167985371305055

Epoch: 6| Step: 13
Training loss: 0.35503994575933717
Validation loss: 2.4793159651548966

Epoch: 276| Step: 0
Training loss: 0.7351391651466873
Validation loss: 2.460005932822528

Epoch: 6| Step: 1
Training loss: 0.38114818479833085
Validation loss: 2.491955242044803

Epoch: 6| Step: 2
Training loss: 0.7454576426957656
Validation loss: 2.478058367093034

Epoch: 6| Step: 3
Training loss: 0.5538439178905632
Validation loss: 2.4766367551179047

Epoch: 6| Step: 4
Training loss: 0.5440789269208374
Validation loss: 2.5098152146488366

Epoch: 6| Step: 5
Training loss: 0.6847753068203594
Validation loss: 2.5383917556942897

Epoch: 6| Step: 6
Training loss: 0.8936488701218551
Validation loss: 2.4944022872816496

Epoch: 6| Step: 7
Training loss: 0.6287185673222574
Validation loss: 2.523860821599111

Epoch: 6| Step: 8
Training loss: 0.9309242421230896
Validation loss: 2.5461828248872305

Epoch: 6| Step: 9
Training loss: 0.693272201001011
Validation loss: 2.5292179829098003

Epoch: 6| Step: 10
Training loss: 0.7833649427718828
Validation loss: 2.567045177116873

Epoch: 6| Step: 11
Training loss: 0.5714295825779007
Validation loss: 2.5421195498368583

Epoch: 6| Step: 12
Training loss: 0.6557655362765835
Validation loss: 2.551414064133647

Epoch: 6| Step: 13
Training loss: 0.9334555806981255
Validation loss: 2.555423667257417

Epoch: 277| Step: 0
Training loss: 0.7005081222874696
Validation loss: 2.5634290270170235

Epoch: 6| Step: 1
Training loss: 0.8378758640367372
Validation loss: 2.5538238071912547

Epoch: 6| Step: 2
Training loss: 0.8022514802794858
Validation loss: 2.5520458403682156

Epoch: 6| Step: 3
Training loss: 0.6850662720427348
Validation loss: 2.5293417122694892

Epoch: 6| Step: 4
Training loss: 0.916779222224995
Validation loss: 2.488675569887238

Epoch: 6| Step: 5
Training loss: 0.7995150347853243
Validation loss: 2.498094521652877

Epoch: 6| Step: 6
Training loss: 0.476303123805302
Validation loss: 2.500539808548214

Epoch: 6| Step: 7
Training loss: 0.585427227354897
Validation loss: 2.5010516149375444

Epoch: 6| Step: 8
Training loss: 0.6584807130368575
Validation loss: 2.5391600473501006

Epoch: 6| Step: 9
Training loss: 0.6693642745240627
Validation loss: 2.5474738886448

Epoch: 6| Step: 10
Training loss: 0.47015397895018535
Validation loss: 2.5692628757704994

Epoch: 6| Step: 11
Training loss: 0.6451144267758537
Validation loss: 2.5579803310104623

Epoch: 6| Step: 12
Training loss: 0.6460604242773257
Validation loss: 2.5590254705511835

Epoch: 6| Step: 13
Training loss: 0.32968737254208097
Validation loss: 2.5852767615223047

Epoch: 278| Step: 0
Training loss: 0.5798786989337876
Validation loss: 2.6071792844257513

Epoch: 6| Step: 1
Training loss: 0.6978299931658148
Validation loss: 2.620549243964379

Epoch: 6| Step: 2
Training loss: 0.6832823997992091
Validation loss: 2.599911699460018

Epoch: 6| Step: 3
Training loss: 0.46625811718069976
Validation loss: 2.5869695907976404

Epoch: 6| Step: 4
Training loss: 0.6029740159397153
Validation loss: 2.603364841854057

Epoch: 6| Step: 5
Training loss: 0.6338495069931723
Validation loss: 2.6000186579518365

Epoch: 6| Step: 6
Training loss: 0.7690926478249649
Validation loss: 2.550561070108428

Epoch: 6| Step: 7
Training loss: 0.6908144600371995
Validation loss: 2.559693985874618

Epoch: 6| Step: 8
Training loss: 0.6777434334712985
Validation loss: 2.544206409094428

Epoch: 6| Step: 9
Training loss: 0.6099201111775955
Validation loss: 2.5736994541280067

Epoch: 6| Step: 10
Training loss: 0.6154167268357433
Validation loss: 2.513184274651267

Epoch: 6| Step: 11
Training loss: 0.7070412819503675
Validation loss: 2.5559806199000965

Epoch: 6| Step: 12
Training loss: 0.7986049200361648
Validation loss: 2.519748607588194

Epoch: 6| Step: 13
Training loss: 0.8382914191462024
Validation loss: 2.54401961828177

Epoch: 279| Step: 0
Training loss: 0.5193104095325088
Validation loss: 2.547446974780191

Epoch: 6| Step: 1
Training loss: 0.5811691556103622
Validation loss: 2.563866601791693

Epoch: 6| Step: 2
Training loss: 0.5241525804398821
Validation loss: 2.548176374390315

Epoch: 6| Step: 3
Training loss: 0.6807530699319925
Validation loss: 2.552004863209854

Epoch: 6| Step: 4
Training loss: 0.8024870034232
Validation loss: 2.542839891714307

Epoch: 6| Step: 5
Training loss: 0.7113884554086312
Validation loss: 2.514598916658626

Epoch: 6| Step: 6
Training loss: 0.49170967401565746
Validation loss: 2.5104306298529124

Epoch: 6| Step: 7
Training loss: 0.954220314405629
Validation loss: 2.519480057686216

Epoch: 6| Step: 8
Training loss: 0.7058344453970276
Validation loss: 2.5081128715636325

Epoch: 6| Step: 9
Training loss: 0.7059786216103413
Validation loss: 2.5055096937732473

Epoch: 6| Step: 10
Training loss: 0.5894207732547774
Validation loss: 2.519103410495643

Epoch: 6| Step: 11
Training loss: 0.6340347777689702
Validation loss: 2.523847553687619

Epoch: 6| Step: 12
Training loss: 0.6299166174991752
Validation loss: 2.544762190066122

Epoch: 6| Step: 13
Training loss: 0.6233779123458926
Validation loss: 2.5955249432599086

Epoch: 280| Step: 0
Training loss: 0.7094420750033326
Validation loss: 2.5958694425341666

Epoch: 6| Step: 1
Training loss: 0.9263282158037534
Validation loss: 2.583470471566387

Epoch: 6| Step: 2
Training loss: 0.5415699456743692
Validation loss: 2.5443263968795744

Epoch: 6| Step: 3
Training loss: 0.7281054039802667
Validation loss: 2.585645391922646

Epoch: 6| Step: 4
Training loss: 0.6605287212130854
Validation loss: 2.5537506198939024

Epoch: 6| Step: 5
Training loss: 0.5650071062215016
Validation loss: 2.5189743302809604

Epoch: 6| Step: 6
Training loss: 0.5150844746352625
Validation loss: 2.51629042622178

Epoch: 6| Step: 7
Training loss: 0.5723842979520697
Validation loss: 2.505325216075934

Epoch: 6| Step: 8
Training loss: 0.8183217187926108
Validation loss: 2.539425730632468

Epoch: 6| Step: 9
Training loss: 0.3200508072126424
Validation loss: 2.519706730265554

Epoch: 6| Step: 10
Training loss: 0.6942000544518615
Validation loss: 2.5649115407295646

Epoch: 6| Step: 11
Training loss: 0.6167216897164238
Validation loss: 2.5337055003629696

Epoch: 6| Step: 12
Training loss: 0.8005792130324905
Validation loss: 2.5214997904437295

Epoch: 6| Step: 13
Training loss: 0.3962922969891046
Validation loss: 2.51677609395711

Epoch: 281| Step: 0
Training loss: 0.8130160673508051
Validation loss: 2.5400870468075194

Epoch: 6| Step: 1
Training loss: 0.8965627931027284
Validation loss: 2.5794202363202245

Epoch: 6| Step: 2
Training loss: 0.4832833201194158
Validation loss: 2.5721034724102405

Epoch: 6| Step: 3
Training loss: 0.8163779221872164
Validation loss: 2.571655659574053

Epoch: 6| Step: 4
Training loss: 0.36223768247009186
Validation loss: 2.564104917708958

Epoch: 6| Step: 5
Training loss: 0.5592608436587059
Validation loss: 2.5605911270207047

Epoch: 6| Step: 6
Training loss: 0.7118435629851914
Validation loss: 2.5869708528130753

Epoch: 6| Step: 7
Training loss: 0.5866234642299705
Validation loss: 2.5748231150262284

Epoch: 6| Step: 8
Training loss: 0.8623141572287568
Validation loss: 2.5770496769661597

Epoch: 6| Step: 9
Training loss: 0.43822772945346405
Validation loss: 2.5637333180749726

Epoch: 6| Step: 10
Training loss: 0.2757438531650482
Validation loss: 2.566737437327972

Epoch: 6| Step: 11
Training loss: 0.7199410645550424
Validation loss: 2.564730117249387

Epoch: 6| Step: 12
Training loss: 0.598877998161415
Validation loss: 2.53424377417276

Epoch: 6| Step: 13
Training loss: 0.6241633537452421
Validation loss: 2.5367824326073047

Epoch: 282| Step: 0
Training loss: 0.4543610190506066
Validation loss: 2.538027542748584

Epoch: 6| Step: 1
Training loss: 0.7430317544145674
Validation loss: 2.514079522174587

Epoch: 6| Step: 2
Training loss: 0.3074954806360124
Validation loss: 2.537333961420049

Epoch: 6| Step: 3
Training loss: 0.46538127946779645
Validation loss: 2.4978142674085997

Epoch: 6| Step: 4
Training loss: 0.5260462304348525
Validation loss: 2.5057857328910633

Epoch: 6| Step: 5
Training loss: 0.4939135908180483
Validation loss: 2.5459343130329235

Epoch: 6| Step: 6
Training loss: 0.6827568380683174
Validation loss: 2.518938878357039

Epoch: 6| Step: 7
Training loss: 0.8492358559549943
Validation loss: 2.5252500801919813

Epoch: 6| Step: 8
Training loss: 0.7465519721277682
Validation loss: 2.534419425319167

Epoch: 6| Step: 9
Training loss: 0.5357362986764936
Validation loss: 2.5692469701033795

Epoch: 6| Step: 10
Training loss: 0.8178366218248384
Validation loss: 2.539792309953875

Epoch: 6| Step: 11
Training loss: 0.8917015663043378
Validation loss: 2.552569847787571

Epoch: 6| Step: 12
Training loss: 0.6023846742257267
Validation loss: 2.55598218457478

Epoch: 6| Step: 13
Training loss: 0.6000286214677641
Validation loss: 2.580335098464492

Epoch: 283| Step: 0
Training loss: 0.40673014803261637
Validation loss: 2.56005615784528

Epoch: 6| Step: 1
Training loss: 0.2233372196498714
Validation loss: 2.554520409014198

Epoch: 6| Step: 2
Training loss: 0.6170050435841579
Validation loss: 2.5420284434035603

Epoch: 6| Step: 3
Training loss: 0.7443405643700699
Validation loss: 2.5618879055902792

Epoch: 6| Step: 4
Training loss: 0.9057505974510974
Validation loss: 2.5204277847982737

Epoch: 6| Step: 5
Training loss: 0.4774312558795147
Validation loss: 2.5182310554566962

Epoch: 6| Step: 6
Training loss: 0.6386644788774609
Validation loss: 2.4907159716091356

Epoch: 6| Step: 7
Training loss: 0.7821926152438871
Validation loss: 2.4704802132773396

Epoch: 6| Step: 8
Training loss: 0.6708141868141467
Validation loss: 2.546307023644082

Epoch: 6| Step: 9
Training loss: 0.5436138464931896
Validation loss: 2.533662200391926

Epoch: 6| Step: 10
Training loss: 0.9967112104696152
Validation loss: 2.5593330518193294

Epoch: 6| Step: 11
Training loss: 0.6621925279283308
Validation loss: 2.5512672236132294

Epoch: 6| Step: 12
Training loss: 0.48413192125628157
Validation loss: 2.5831329431392804

Epoch: 6| Step: 13
Training loss: 0.33556220804515463
Validation loss: 2.581157399251909

Epoch: 284| Step: 0
Training loss: 0.6338691131869094
Validation loss: 2.5682383748621778

Epoch: 6| Step: 1
Training loss: 0.7179091967435589
Validation loss: 2.5366528234696584

Epoch: 6| Step: 2
Training loss: 0.5896623597802739
Validation loss: 2.538722661879372

Epoch: 6| Step: 3
Training loss: 0.8299340695312349
Validation loss: 2.532895791681001

Epoch: 6| Step: 4
Training loss: 0.5661762428246806
Validation loss: 2.510498556820791

Epoch: 6| Step: 5
Training loss: 0.34624981084880413
Validation loss: 2.5183499771497333

Epoch: 6| Step: 6
Training loss: 0.6963910941635264
Validation loss: 2.528002696905285

Epoch: 6| Step: 7
Training loss: 0.4355343188199402
Validation loss: 2.496074802706076

Epoch: 6| Step: 8
Training loss: 0.4450650113011754
Validation loss: 2.546612963447918

Epoch: 6| Step: 9
Training loss: 0.6573959971075972
Validation loss: 2.5402657706124105

Epoch: 6| Step: 10
Training loss: 0.7171553045621735
Validation loss: 2.561769605480433

Epoch: 6| Step: 11
Training loss: 0.5454411374055289
Validation loss: 2.56703112873478

Epoch: 6| Step: 12
Training loss: 0.7965403583452877
Validation loss: 2.568168107918851

Epoch: 6| Step: 13
Training loss: 0.911858370958106
Validation loss: 2.5663236063225914

Epoch: 285| Step: 0
Training loss: 0.4381903923090473
Validation loss: 2.573790628769687

Epoch: 6| Step: 1
Training loss: 0.6247274281277465
Validation loss: 2.5581883097739313

Epoch: 6| Step: 2
Training loss: 0.7380579858086724
Validation loss: 2.553923248046836

Epoch: 6| Step: 3
Training loss: 0.5705373660395638
Validation loss: 2.5485902334441164

Epoch: 6| Step: 4
Training loss: 0.4758381263048362
Validation loss: 2.5539142328592415

Epoch: 6| Step: 5
Training loss: 0.5778474399200658
Validation loss: 2.5328679526662987

Epoch: 6| Step: 6
Training loss: 0.9537665287450436
Validation loss: 2.502732149895624

Epoch: 6| Step: 7
Training loss: 0.5800716001612466
Validation loss: 2.514679787417785

Epoch: 6| Step: 8
Training loss: 0.7845683387691637
Validation loss: 2.5397184149792027

Epoch: 6| Step: 9
Training loss: 0.6345186897618456
Validation loss: 2.5365834704423214

Epoch: 6| Step: 10
Training loss: 0.6026774391284782
Validation loss: 2.5612144997472557

Epoch: 6| Step: 11
Training loss: 0.5300229712222572
Validation loss: 2.5882849823634064

Epoch: 6| Step: 12
Training loss: 0.4922676626652746
Validation loss: 2.5934928196238873

Epoch: 6| Step: 13
Training loss: 0.749820290333841
Validation loss: 2.568363854750478

Epoch: 286| Step: 0
Training loss: 0.4431345029062162
Validation loss: 2.594383961878698

Epoch: 6| Step: 1
Training loss: 0.5968769952231407
Validation loss: 2.564215115383449

Epoch: 6| Step: 2
Training loss: 0.4768591879676775
Validation loss: 2.563020810821224

Epoch: 6| Step: 3
Training loss: 0.5916013992828214
Validation loss: 2.541944122165737

Epoch: 6| Step: 4
Training loss: 0.5408890779310408
Validation loss: 2.5296251780842467

Epoch: 6| Step: 5
Training loss: 0.822424938869848
Validation loss: 2.5044395292657113

Epoch: 6| Step: 6
Training loss: 0.5984858819512187
Validation loss: 2.5270661364224702

Epoch: 6| Step: 7
Training loss: 0.7842217193018306
Validation loss: 2.531462699555302

Epoch: 6| Step: 8
Training loss: 0.7188162565790726
Validation loss: 2.524956604592698

Epoch: 6| Step: 9
Training loss: 0.7354744331070594
Validation loss: 2.5497095050340324

Epoch: 6| Step: 10
Training loss: 0.5496581239641805
Validation loss: 2.490290211182869

Epoch: 6| Step: 11
Training loss: 0.31355241945063533
Validation loss: 2.553368315534054

Epoch: 6| Step: 12
Training loss: 0.7589035831472888
Validation loss: 2.5703830574036863

Epoch: 6| Step: 13
Training loss: 0.728673186662454
Validation loss: 2.571976130615701

Epoch: 287| Step: 0
Training loss: 0.5889325461484427
Validation loss: 2.584174136129756

Epoch: 6| Step: 1
Training loss: 0.6096326576723428
Validation loss: 2.5824010991596884

Epoch: 6| Step: 2
Training loss: 0.5412727323432011
Validation loss: 2.608328809173675

Epoch: 6| Step: 3
Training loss: 0.5546247957275234
Validation loss: 2.589526816801345

Epoch: 6| Step: 4
Training loss: 0.6302031419608515
Validation loss: 2.5848063742529113

Epoch: 6| Step: 5
Training loss: 0.695074619362836
Validation loss: 2.5878346320371577

Epoch: 6| Step: 6
Training loss: 0.7923630529304297
Validation loss: 2.5601603924669085

Epoch: 6| Step: 7
Training loss: 0.8095343826842977
Validation loss: 2.570611041663594

Epoch: 6| Step: 8
Training loss: 0.5272867242568166
Validation loss: 2.5017686822172522

Epoch: 6| Step: 9
Training loss: 0.633717043506923
Validation loss: 2.529052316106812

Epoch: 6| Step: 10
Training loss: 0.45081652233889563
Validation loss: 2.54017635679224

Epoch: 6| Step: 11
Training loss: 0.6773564496989236
Validation loss: 2.5141526569969685

Epoch: 6| Step: 12
Training loss: 0.5370660105452575
Validation loss: 2.5335497580595523

Epoch: 6| Step: 13
Training loss: 0.5648051289588939
Validation loss: 2.5410173169313177

Epoch: 288| Step: 0
Training loss: 0.38441505533560566
Validation loss: 2.5554315966604375

Epoch: 6| Step: 1
Training loss: 0.6840893502017469
Validation loss: 2.604671322725908

Epoch: 6| Step: 2
Training loss: 0.648926607910732
Validation loss: 2.5783366305690794

Epoch: 6| Step: 3
Training loss: 0.6847437531394173
Validation loss: 2.586552023623719

Epoch: 6| Step: 4
Training loss: 0.4871843759021829
Validation loss: 2.5714554691376925

Epoch: 6| Step: 5
Training loss: 0.6590811196559854
Validation loss: 2.5458005819027756

Epoch: 6| Step: 6
Training loss: 0.5371165881973032
Validation loss: 2.525205414940101

Epoch: 6| Step: 7
Training loss: 0.828167788281842
Validation loss: 2.502121037899125

Epoch: 6| Step: 8
Training loss: 0.8434120137058956
Validation loss: 2.497955628733117

Epoch: 6| Step: 9
Training loss: 0.6215892710417684
Validation loss: 2.487339491604118

Epoch: 6| Step: 10
Training loss: 0.5672242144847426
Validation loss: 2.5039941649646953

Epoch: 6| Step: 11
Training loss: 0.5467003679742127
Validation loss: 2.5296087156002587

Epoch: 6| Step: 12
Training loss: 0.38746705530465025
Validation loss: 2.543779094128853

Epoch: 6| Step: 13
Training loss: 0.5698918659553449
Validation loss: 2.5299861745194354

Epoch: 289| Step: 0
Training loss: 0.5571177796599279
Validation loss: 2.569906059541064

Epoch: 6| Step: 1
Training loss: 0.42365463503131406
Validation loss: 2.5286836891352187

Epoch: 6| Step: 2
Training loss: 0.7524365741195832
Validation loss: 2.5572920950609013

Epoch: 6| Step: 3
Training loss: 0.8027697553054123
Validation loss: 2.5678991318289115

Epoch: 6| Step: 4
Training loss: 0.432002576045462
Validation loss: 2.5285304155661708

Epoch: 6| Step: 5
Training loss: 0.755850818989749
Validation loss: 2.519327589781594

Epoch: 6| Step: 6
Training loss: 0.38368571202690627
Validation loss: 2.5297543517603445

Epoch: 6| Step: 7
Training loss: 0.6063108924881376
Validation loss: 2.519685095411048

Epoch: 6| Step: 8
Training loss: 0.5601352682400466
Validation loss: 2.5233565350248544

Epoch: 6| Step: 9
Training loss: 0.6159029280019247
Validation loss: 2.502600668716628

Epoch: 6| Step: 10
Training loss: 0.10823106301781608
Validation loss: 2.4870190993091787

Epoch: 6| Step: 11
Training loss: 0.8450072775758732
Validation loss: 2.519688155883312

Epoch: 6| Step: 12
Training loss: 0.6431459277782334
Validation loss: 2.52922613713569

Epoch: 6| Step: 13
Training loss: 0.43682804616646376
Validation loss: 2.5146299929509386

Epoch: 290| Step: 0
Training loss: 0.6327561247403725
Validation loss: 2.5567803065947152

Epoch: 6| Step: 1
Training loss: 0.341571995462704
Validation loss: 2.547480726757966

Epoch: 6| Step: 2
Training loss: 0.5082266072764388
Validation loss: 2.5215616007293264

Epoch: 6| Step: 3
Training loss: 0.49329453055019284
Validation loss: 2.541095882039725

Epoch: 6| Step: 4
Training loss: 0.5744531114283311
Validation loss: 2.528029595692287

Epoch: 6| Step: 5
Training loss: 0.8836822951090907
Validation loss: 2.5297850645388595

Epoch: 6| Step: 6
Training loss: 0.34916997180586823
Validation loss: 2.5115968104355364

Epoch: 6| Step: 7
Training loss: 0.7055992462013072
Validation loss: 2.5125023618746303

Epoch: 6| Step: 8
Training loss: 0.6349349749680417
Validation loss: 2.5439538682155214

Epoch: 6| Step: 9
Training loss: 0.27839334433210694
Validation loss: 2.5088286297748046

Epoch: 6| Step: 10
Training loss: 0.6039595961604141
Validation loss: 2.516333491776945

Epoch: 6| Step: 11
Training loss: 0.525270781622015
Validation loss: 2.502372042971449

Epoch: 6| Step: 12
Training loss: 0.7277275097411052
Validation loss: 2.5192539915651238

Epoch: 6| Step: 13
Training loss: 0.9119493233797483
Validation loss: 2.54497107577382

Epoch: 291| Step: 0
Training loss: 0.7791180704299193
Validation loss: 2.5407132929888823

Epoch: 6| Step: 1
Training loss: 0.47772628141021034
Validation loss: 2.534446453249841

Epoch: 6| Step: 2
Training loss: 0.7548876684508878
Validation loss: 2.5587509616727946

Epoch: 6| Step: 3
Training loss: 0.26742042293706003
Validation loss: 2.5579069699857966

Epoch: 6| Step: 4
Training loss: 0.3389277005651002
Validation loss: 2.562412036353406

Epoch: 6| Step: 5
Training loss: 0.38913855977363354
Validation loss: 2.5379352207053687

Epoch: 6| Step: 6
Training loss: 0.7916268706776225
Validation loss: 2.555604368070326

Epoch: 6| Step: 7
Training loss: 0.5507321166720772
Validation loss: 2.574300225520362

Epoch: 6| Step: 8
Training loss: 0.7151851151658379
Validation loss: 2.5666046083403375

Epoch: 6| Step: 9
Training loss: 0.4272331366617842
Validation loss: 2.5371286150440957

Epoch: 6| Step: 10
Training loss: 0.6973378974793754
Validation loss: 2.537227118833637

Epoch: 6| Step: 11
Training loss: 0.6016298231624657
Validation loss: 2.5732096591215194

Epoch: 6| Step: 12
Training loss: 0.6360306092879752
Validation loss: 2.5371820682761594

Epoch: 6| Step: 13
Training loss: 0.5236534697951765
Validation loss: 2.5706230260506535

Epoch: 292| Step: 0
Training loss: 0.3972107570871295
Validation loss: 2.5353844008114654

Epoch: 6| Step: 1
Training loss: 0.8040139054856162
Validation loss: 2.5428701853302025

Epoch: 6| Step: 2
Training loss: 0.594585207722558
Validation loss: 2.535365756244798

Epoch: 6| Step: 3
Training loss: 0.8337336214621529
Validation loss: 2.5367770764878608

Epoch: 6| Step: 4
Training loss: 0.2694597840585426
Validation loss: 2.5376591284843424

Epoch: 6| Step: 5
Training loss: 0.6585342525156134
Validation loss: 2.5529164340525408

Epoch: 6| Step: 6
Training loss: 0.36745031569157577
Validation loss: 2.5300848023696756

Epoch: 6| Step: 7
Training loss: 0.8518210902126926
Validation loss: 2.583276857862965

Epoch: 6| Step: 8
Training loss: 0.38249738530281324
Validation loss: 2.5475313523766876

Epoch: 6| Step: 9
Training loss: 0.8741366009470865
Validation loss: 2.555878045361011

Epoch: 6| Step: 10
Training loss: 0.42895254222313517
Validation loss: 2.561317419080461

Epoch: 6| Step: 11
Training loss: 0.3705992767258991
Validation loss: 2.5733443149698094

Epoch: 6| Step: 12
Training loss: 0.3554396774643858
Validation loss: 2.5675838481634186

Epoch: 6| Step: 13
Training loss: 0.4503163901008135
Validation loss: 2.5746716153840477

Epoch: 293| Step: 0
Training loss: 0.3763511674101406
Validation loss: 2.5484002520783853

Epoch: 6| Step: 1
Training loss: 0.7203971813016498
Validation loss: 2.57941399323974

Epoch: 6| Step: 2
Training loss: 0.3840559596784405
Validation loss: 2.5790341163701465

Epoch: 6| Step: 3
Training loss: 0.4793277621712561
Validation loss: 2.5509021355193933

Epoch: 6| Step: 4
Training loss: 0.646719575721525
Validation loss: 2.570255429390792

Epoch: 6| Step: 5
Training loss: 0.7401531245347032
Validation loss: 2.5312202043702734

Epoch: 6| Step: 6
Training loss: 0.7464366344634379
Validation loss: 2.5365453195059997

Epoch: 6| Step: 7
Training loss: 0.64922181919442
Validation loss: 2.576783510325176

Epoch: 6| Step: 8
Training loss: 0.3260129667128478
Validation loss: 2.5330779755751998

Epoch: 6| Step: 9
Training loss: 0.4100558021706579
Validation loss: 2.568758913459879

Epoch: 6| Step: 10
Training loss: 0.634475829656837
Validation loss: 2.5559267744474075

Epoch: 6| Step: 11
Training loss: 0.8074777614259409
Validation loss: 2.5864772081616683

Epoch: 6| Step: 12
Training loss: 0.6373736751906965
Validation loss: 2.5877459890602332

Epoch: 6| Step: 13
Training loss: 0.18511504064773238
Validation loss: 2.561904977705432

Epoch: 294| Step: 0
Training loss: 0.6934038604649769
Validation loss: 2.567842090945675

Epoch: 6| Step: 1
Training loss: 0.40942255428254803
Validation loss: 2.57509581203123

Epoch: 6| Step: 2
Training loss: 0.3447618115264125
Validation loss: 2.545953383173929

Epoch: 6| Step: 3
Training loss: 0.44696844631126875
Validation loss: 2.550632833235869

Epoch: 6| Step: 4
Training loss: 0.5762421645916458
Validation loss: 2.5657919341110103

Epoch: 6| Step: 5
Training loss: 0.7562964306914718
Validation loss: 2.572477752552036

Epoch: 6| Step: 6
Training loss: 0.5691132412555974
Validation loss: 2.5457238512958207

Epoch: 6| Step: 7
Training loss: 0.7083734239190822
Validation loss: 2.5296460978207156

Epoch: 6| Step: 8
Training loss: 0.924548910313043
Validation loss: 2.493631724247399

Epoch: 6| Step: 9
Training loss: 0.5871684813045961
Validation loss: 2.543055815573762

Epoch: 6| Step: 10
Training loss: 0.4512450088742735
Validation loss: 2.4980576045045386

Epoch: 6| Step: 11
Training loss: 0.38010741118055785
Validation loss: 2.5164526946697703

Epoch: 6| Step: 12
Training loss: 0.6458172078324211
Validation loss: 2.5574369196103732

Epoch: 6| Step: 13
Training loss: 0.6773062681323451
Validation loss: 2.5577953118270904

Epoch: 295| Step: 0
Training loss: 0.550494721466175
Validation loss: 2.55742634299436

Epoch: 6| Step: 1
Training loss: 0.7272312409180325
Validation loss: 2.548403269011737

Epoch: 6| Step: 2
Training loss: 0.5653529930478829
Validation loss: 2.530498656962704

Epoch: 6| Step: 3
Training loss: 0.5570036657921581
Validation loss: 2.5283677060218093

Epoch: 6| Step: 4
Training loss: 0.5380677152618644
Validation loss: 2.5593721006341124

Epoch: 6| Step: 5
Training loss: 0.9019018635281484
Validation loss: 2.510140804968906

Epoch: 6| Step: 6
Training loss: 0.648433271647076
Validation loss: 2.5410541164109812

Epoch: 6| Step: 7
Training loss: 0.19847650257298136
Validation loss: 2.5398213327750483

Epoch: 6| Step: 8
Training loss: 0.328530447100494
Validation loss: 2.511261551506502

Epoch: 6| Step: 9
Training loss: 0.6562172790725944
Validation loss: 2.5367582653025336

Epoch: 6| Step: 10
Training loss: 0.5189505752336824
Validation loss: 2.5004921018635984

Epoch: 6| Step: 11
Training loss: 0.4417854638147971
Validation loss: 2.503525026925933

Epoch: 6| Step: 12
Training loss: 0.6261689222317359
Validation loss: 2.5247133403170383

Epoch: 6| Step: 13
Training loss: 0.6848606685608718
Validation loss: 2.529957617474788

Epoch: 296| Step: 0
Training loss: 0.6373650716594509
Validation loss: 2.5675319264999015

Epoch: 6| Step: 1
Training loss: 0.6483897915490134
Validation loss: 2.583299972710432

Epoch: 6| Step: 2
Training loss: 0.41274389801505645
Validation loss: 2.5989702879474392

Epoch: 6| Step: 3
Training loss: 0.4845862543204459
Validation loss: 2.604327875541475

Epoch: 6| Step: 4
Training loss: 0.5546166818032398
Validation loss: 2.5859852492635507

Epoch: 6| Step: 5
Training loss: 0.7710732825441271
Validation loss: 2.5976084566989597

Epoch: 6| Step: 6
Training loss: 0.41758771266225586
Validation loss: 2.5589104018175783

Epoch: 6| Step: 7
Training loss: 0.6967613041935631
Validation loss: 2.5658651925888836

Epoch: 6| Step: 8
Training loss: 0.38889517192457707
Validation loss: 2.5240688562153886

Epoch: 6| Step: 9
Training loss: 0.5693463280385602
Validation loss: 2.498549979145123

Epoch: 6| Step: 10
Training loss: 0.4454650952079863
Validation loss: 2.5208713776427794

Epoch: 6| Step: 11
Training loss: 0.762192642300922
Validation loss: 2.5284940228937245

Epoch: 6| Step: 12
Training loss: 0.5447448114653114
Validation loss: 2.526934034368481

Epoch: 6| Step: 13
Training loss: 0.7309991879178193
Validation loss: 2.522064089219797

Epoch: 297| Step: 0
Training loss: 0.4044715393484235
Validation loss: 2.532360043662604

Epoch: 6| Step: 1
Training loss: 0.6691237608415149
Validation loss: 2.5440735192502646

Epoch: 6| Step: 2
Training loss: 0.5837634635205878
Validation loss: 2.6077402186383645

Epoch: 6| Step: 3
Training loss: 0.3818963239681666
Validation loss: 2.587200692372613

Epoch: 6| Step: 4
Training loss: 0.7868119428000726
Validation loss: 2.566935967821841

Epoch: 6| Step: 5
Training loss: 0.6760085941761572
Validation loss: 2.60634521043306

Epoch: 6| Step: 6
Training loss: 0.38468655388573975
Validation loss: 2.5692472834181834

Epoch: 6| Step: 7
Training loss: 0.32728108236380876
Validation loss: 2.538134762731209

Epoch: 6| Step: 8
Training loss: 0.3715237184502818
Validation loss: 2.5416275494122433

Epoch: 6| Step: 9
Training loss: 0.7263322280713735
Validation loss: 2.542345348412364

Epoch: 6| Step: 10
Training loss: 0.7272559517583758
Validation loss: 2.4935283769144982

Epoch: 6| Step: 11
Training loss: 0.5165481395536909
Validation loss: 2.5096878554910678

Epoch: 6| Step: 12
Training loss: 0.6268234356470077
Validation loss: 2.537758584503467

Epoch: 6| Step: 13
Training loss: 0.7164245802802528
Validation loss: 2.5450418904997822

Epoch: 298| Step: 0
Training loss: 0.60643258442322
Validation loss: 2.5756330825338796

Epoch: 6| Step: 1
Training loss: 0.4151371738931175
Validation loss: 2.5977026854515946

Epoch: 6| Step: 2
Training loss: 0.7218176435002764
Validation loss: 2.5575109095899027

Epoch: 6| Step: 3
Training loss: 0.3591047597772051
Validation loss: 2.556738092281213

Epoch: 6| Step: 4
Training loss: 0.8005292170194591
Validation loss: 2.5280364691611084

Epoch: 6| Step: 5
Training loss: 0.6435530666857672
Validation loss: 2.51854709394324

Epoch: 6| Step: 6
Training loss: 0.2098619982013205
Validation loss: 2.5069144883116476

Epoch: 6| Step: 7
Training loss: 0.573527718289063
Validation loss: 2.5246823211221154

Epoch: 6| Step: 8
Training loss: 0.698754801349829
Validation loss: 2.4959809843674203

Epoch: 6| Step: 9
Training loss: 0.5193232069574851
Validation loss: 2.5073456550595066

Epoch: 6| Step: 10
Training loss: 0.5975624459646373
Validation loss: 2.512093622962857

Epoch: 6| Step: 11
Training loss: 0.5518630475988857
Validation loss: 2.5497066806846234

Epoch: 6| Step: 12
Training loss: 0.36244758194085097
Validation loss: 2.5026826800854063

Epoch: 6| Step: 13
Training loss: 0.9069257058730655
Validation loss: 2.5186343614630586

Epoch: 299| Step: 0
Training loss: 0.7120773484001037
Validation loss: 2.516980220355846

Epoch: 6| Step: 1
Training loss: 0.32645978042186063
Validation loss: 2.5465163088974507

Epoch: 6| Step: 2
Training loss: 0.7701096660373453
Validation loss: 2.536765428404914

Epoch: 6| Step: 3
Training loss: 0.3269615094785857
Validation loss: 2.5212595338744004

Epoch: 6| Step: 4
Training loss: 0.4447718232468571
Validation loss: 2.5128770424427596

Epoch: 6| Step: 5
Training loss: 0.7167386231412644
Validation loss: 2.5152007183188942

Epoch: 6| Step: 6
Training loss: 0.49823595833407913
Validation loss: 2.547852115908298

Epoch: 6| Step: 7
Training loss: 0.6548812989064697
Validation loss: 2.5159670373621226

Epoch: 6| Step: 8
Training loss: 0.3323113101825288
Validation loss: 2.546215150312236

Epoch: 6| Step: 9
Training loss: 0.39899848266183985
Validation loss: 2.5384736630783427

Epoch: 6| Step: 10
Training loss: 0.649513753252022
Validation loss: 2.572593291673935

Epoch: 6| Step: 11
Training loss: 0.5954307058328521
Validation loss: 2.5449399912139175

Epoch: 6| Step: 12
Training loss: 0.6540927169898811
Validation loss: 2.56359774139149

Epoch: 6| Step: 13
Training loss: 0.7036742502305635
Validation loss: 2.5513507986257613

Epoch: 300| Step: 0
Training loss: 0.5242077583263545
Validation loss: 2.4915280949263834

Epoch: 6| Step: 1
Training loss: 0.5964391944826807
Validation loss: 2.4998605330337655

Epoch: 6| Step: 2
Training loss: 0.5077856203447897
Validation loss: 2.52143612716319

Epoch: 6| Step: 3
Training loss: 0.689262342127344
Validation loss: 2.5047020900288253

Epoch: 6| Step: 4
Training loss: 0.4388571873447791
Validation loss: 2.5319962013750215

Epoch: 6| Step: 5
Training loss: 0.6084252561288493
Validation loss: 2.5354920369080185

Epoch: 6| Step: 6
Training loss: 0.8377185635976513
Validation loss: 2.51904838751024

Epoch: 6| Step: 7
Training loss: 0.2531677068781457
Validation loss: 2.5395196793045662

Epoch: 6| Step: 8
Training loss: 0.6193708118254777
Validation loss: 2.5583078802868857

Epoch: 6| Step: 9
Training loss: 0.5180221955816953
Validation loss: 2.5842325729138387

Epoch: 6| Step: 10
Training loss: 0.5249466562418418
Validation loss: 2.583882999460005

Epoch: 6| Step: 11
Training loss: 0.39908252190866994
Validation loss: 2.5748274809784335

Epoch: 6| Step: 12
Training loss: 0.6380325757457717
Validation loss: 2.568948892878991

Epoch: 6| Step: 13
Training loss: 0.47100573424475073
Validation loss: 2.576570127383322

Epoch: 301| Step: 0
Training loss: 0.3390822154347225
Validation loss: 2.588458092407232

Epoch: 6| Step: 1
Training loss: 0.5939360628220051
Validation loss: 2.5412915714713007

Epoch: 6| Step: 2
Training loss: 0.5164036506899053
Validation loss: 2.547424249129125

Epoch: 6| Step: 3
Training loss: 0.6496915525573312
Validation loss: 2.53184091792262

Epoch: 6| Step: 4
Training loss: 0.5243841976136623
Validation loss: 2.5368633985757265

Epoch: 6| Step: 5
Training loss: 0.4622176868105915
Validation loss: 2.5723591466543994

Epoch: 6| Step: 6
Training loss: 0.39875789924498517
Validation loss: 2.5636394657500694

Epoch: 6| Step: 7
Training loss: 0.6200972426203235
Validation loss: 2.5823000833927106

Epoch: 6| Step: 8
Training loss: 0.764145180064908
Validation loss: 2.579398031398754

Epoch: 6| Step: 9
Training loss: 0.6876560814286719
Validation loss: 2.533646162803068

Epoch: 6| Step: 10
Training loss: 0.4405922938443945
Validation loss: 2.549898929390518

Epoch: 6| Step: 11
Training loss: 0.20128292426017233
Validation loss: 2.5599570123029998

Epoch: 6| Step: 12
Training loss: 0.6948312100925276
Validation loss: 2.5646217600084804

Epoch: 6| Step: 13
Training loss: 0.583217793897867
Validation loss: 2.5124189823030183

Epoch: 302| Step: 0
Training loss: 0.7010948967717048
Validation loss: 2.5235201934692633

Epoch: 6| Step: 1
Training loss: 0.4469142016309
Validation loss: 2.554395126757707

Epoch: 6| Step: 2
Training loss: 0.31954705262222344
Validation loss: 2.5598256952540033

Epoch: 6| Step: 3
Training loss: 0.4006178048569358
Validation loss: 2.5496964038069176

Epoch: 6| Step: 4
Training loss: 0.4872715390231656
Validation loss: 2.529531106172766

Epoch: 6| Step: 5
Training loss: 0.45019862242038394
Validation loss: 2.555075275922553

Epoch: 6| Step: 6
Training loss: 0.4261522339264268
Validation loss: 2.5289608408014104

Epoch: 6| Step: 7
Training loss: 0.5960298986472119
Validation loss: 2.546170054894676

Epoch: 6| Step: 8
Training loss: 0.4984153730688936
Validation loss: 2.5562332402691386

Epoch: 6| Step: 9
Training loss: 0.5039789014385117
Validation loss: 2.5993160989858866

Epoch: 6| Step: 10
Training loss: 0.6901218747919975
Validation loss: 2.5662192399225607

Epoch: 6| Step: 11
Training loss: 0.7545641464611029
Validation loss: 2.5232816166911918

Epoch: 6| Step: 12
Training loss: 0.7558439977693335
Validation loss: 2.5476126358533353

Epoch: 6| Step: 13
Training loss: 0.14688855042751126
Validation loss: 2.5287827692438105

Epoch: 303| Step: 0
Training loss: 0.6604181029928896
Validation loss: 2.545107845895719

Epoch: 6| Step: 1
Training loss: 0.49066760005788723
Validation loss: 2.5424988257016756

Epoch: 6| Step: 2
Training loss: 0.6849008325507949
Validation loss: 2.511143017434512

Epoch: 6| Step: 3
Training loss: 0.40730734922586215
Validation loss: 2.5610735004332046

Epoch: 6| Step: 4
Training loss: 0.5301058172359046
Validation loss: 2.547739812815079

Epoch: 6| Step: 5
Training loss: 0.7518836843951457
Validation loss: 2.542589647077877

Epoch: 6| Step: 6
Training loss: 0.5259248931244189
Validation loss: 2.5527493476530574

Epoch: 6| Step: 7
Training loss: 0.3904154787822445
Validation loss: 2.548539983951228

Epoch: 6| Step: 8
Training loss: 0.42856830144490643
Validation loss: 2.567338157294822

Epoch: 6| Step: 9
Training loss: 0.1487369277964254
Validation loss: 2.5603537366484446

Epoch: 6| Step: 10
Training loss: 0.7859277682905821
Validation loss: 2.600583827901118

Epoch: 6| Step: 11
Training loss: 0.4952723393569856
Validation loss: 2.5611372534804415

Epoch: 6| Step: 12
Training loss: 0.5620027834714739
Validation loss: 2.571486841312859

Epoch: 6| Step: 13
Training loss: 0.438992933280523
Validation loss: 2.5709488160207496

Epoch: 304| Step: 0
Training loss: 0.6399807830995113
Validation loss: 2.536560167391451

Epoch: 6| Step: 1
Training loss: 0.4178185237544443
Validation loss: 2.5315027327253157

Epoch: 6| Step: 2
Training loss: 0.6818855741819074
Validation loss: 2.508414416204754

Epoch: 6| Step: 3
Training loss: 0.5625700377200985
Validation loss: 2.532033942962494

Epoch: 6| Step: 4
Training loss: 0.4298747608309494
Validation loss: 2.517690162600418

Epoch: 6| Step: 5
Training loss: 0.6083700501017404
Validation loss: 2.528489063902906

Epoch: 6| Step: 6
Training loss: 0.46600488488866404
Validation loss: 2.5721415885516494

Epoch: 6| Step: 7
Training loss: 0.381552510548639
Validation loss: 2.5600117864212457

Epoch: 6| Step: 8
Training loss: 0.6077472759642412
Validation loss: 2.568119635065223

Epoch: 6| Step: 9
Training loss: 0.3702462809142146
Validation loss: 2.563859767384986

Epoch: 6| Step: 10
Training loss: 0.8248667045762309
Validation loss: 2.580134188917691

Epoch: 6| Step: 11
Training loss: 0.5953384033334677
Validation loss: 2.5720026362973414

Epoch: 6| Step: 12
Training loss: 0.3529666304978511
Validation loss: 2.5739934577035517

Epoch: 6| Step: 13
Training loss: 0.5905043584741896
Validation loss: 2.549887638845727

Epoch: 305| Step: 0
Training loss: 0.314284190415738
Validation loss: 2.5510987469245134

Epoch: 6| Step: 1
Training loss: 0.3637253702483658
Validation loss: 2.5656111884135377

Epoch: 6| Step: 2
Training loss: 0.5166927610493797
Validation loss: 2.5365039276986385

Epoch: 6| Step: 3
Training loss: 0.46543692560366656
Validation loss: 2.549833148948219

Epoch: 6| Step: 4
Training loss: 0.246218059569329
Validation loss: 2.5404282912985505

Epoch: 6| Step: 5
Training loss: 0.7401685056342158
Validation loss: 2.5599323607633724

Epoch: 6| Step: 6
Training loss: 0.6635283172877495
Validation loss: 2.561348031639329

Epoch: 6| Step: 7
Training loss: 0.6717442895471232
Validation loss: 2.534099069786561

Epoch: 6| Step: 8
Training loss: 0.8290840209974445
Validation loss: 2.5177817963990328

Epoch: 6| Step: 9
Training loss: 0.5527413303759876
Validation loss: 2.5771214853688864

Epoch: 6| Step: 10
Training loss: 0.5978070237207516
Validation loss: 2.5303242696039403

Epoch: 6| Step: 11
Training loss: 0.3771128538424479
Validation loss: 2.5620451822940664

Epoch: 6| Step: 12
Training loss: 0.36786967683078226
Validation loss: 2.5691138013666217

Epoch: 6| Step: 13
Training loss: 0.19627271176081676
Validation loss: 2.546417668361493

Epoch: 306| Step: 0
Training loss: 0.5299423055015888
Validation loss: 2.5373451471777564

Epoch: 6| Step: 1
Training loss: 0.7490123762883153
Validation loss: 2.5357190797693248

Epoch: 6| Step: 2
Training loss: 0.51891519834573
Validation loss: 2.5351931851167646

Epoch: 6| Step: 3
Training loss: 0.3296217048221372
Validation loss: 2.5460702966256665

Epoch: 6| Step: 4
Training loss: 0.42573895375565174
Validation loss: 2.5092522438715545

Epoch: 6| Step: 5
Training loss: 0.6147798827371405
Validation loss: 2.5133103356242597

Epoch: 6| Step: 6
Training loss: 0.48255361078812825
Validation loss: 2.5345451189345587

Epoch: 6| Step: 7
Training loss: 0.7296371622305453
Validation loss: 2.5509449780420557

Epoch: 6| Step: 8
Training loss: 0.44877154439356814
Validation loss: 2.5908937102871348

Epoch: 6| Step: 9
Training loss: 0.3803842564314322
Validation loss: 2.5827733550020917

Epoch: 6| Step: 10
Training loss: 0.30047284453285666
Validation loss: 2.602982854380137

Epoch: 6| Step: 11
Training loss: 0.5877391835575935
Validation loss: 2.5688918595873385

Epoch: 6| Step: 12
Training loss: 0.6636602866613196
Validation loss: 2.588499324922137

Epoch: 6| Step: 13
Training loss: 0.5916815667447756
Validation loss: 2.574839035532298

Epoch: 307| Step: 0
Training loss: 0.704860537444718
Validation loss: 2.5850439894600705

Epoch: 6| Step: 1
Training loss: 0.5259275281100179
Validation loss: 2.5851066634406794

Epoch: 6| Step: 2
Training loss: 0.7042413961570843
Validation loss: 2.573812625585291

Epoch: 6| Step: 3
Training loss: 0.4740989200580948
Validation loss: 2.5452304595990687

Epoch: 6| Step: 4
Training loss: 0.2715461166760202
Validation loss: 2.5442398997588196

Epoch: 6| Step: 5
Training loss: 0.45553775218869447
Validation loss: 2.560392661259023

Epoch: 6| Step: 6
Training loss: 0.659744879406033
Validation loss: 2.563908589746915

Epoch: 6| Step: 7
Training loss: 0.30705360981521806
Validation loss: 2.570975438988313

Epoch: 6| Step: 8
Training loss: 0.34721185377322933
Validation loss: 2.5565926816425533

Epoch: 6| Step: 9
Training loss: 0.6952281214917947
Validation loss: 2.540225455710601

Epoch: 6| Step: 10
Training loss: 0.6424257045493927
Validation loss: 2.5716515633772232

Epoch: 6| Step: 11
Training loss: 0.637864655563497
Validation loss: 2.5462900055225166

Epoch: 6| Step: 12
Training loss: 0.15602867425282008
Validation loss: 2.5764951683366837

Epoch: 6| Step: 13
Training loss: 0.48488059882117585
Validation loss: 2.56536675814327

Epoch: 308| Step: 0
Training loss: 0.5050883953705383
Validation loss: 2.551404814001023

Epoch: 6| Step: 1
Training loss: 0.5220506715059049
Validation loss: 2.584077667977195

Epoch: 6| Step: 2
Training loss: 0.7487729684557931
Validation loss: 2.5010554618537166

Epoch: 6| Step: 3
Training loss: 0.6887104475846019
Validation loss: 2.5474255362706546

Epoch: 6| Step: 4
Training loss: 0.5329071453080026
Validation loss: 2.5028738116654927

Epoch: 6| Step: 5
Training loss: 0.48051545451117217
Validation loss: 2.5070732120064325

Epoch: 6| Step: 6
Training loss: 0.4582947115086721
Validation loss: 2.512197973000881

Epoch: 6| Step: 7
Training loss: 0.4146476785129064
Validation loss: 2.483799240336239

Epoch: 6| Step: 8
Training loss: 0.7030714862380433
Validation loss: 2.4970972190438236

Epoch: 6| Step: 9
Training loss: 0.4139482772474753
Validation loss: 2.497531222566746

Epoch: 6| Step: 10
Training loss: 0.30762044511311454
Validation loss: 2.5265098020436993

Epoch: 6| Step: 11
Training loss: 0.5725812594868884
Validation loss: 2.51762345303602

Epoch: 6| Step: 12
Training loss: 0.5521017167491509
Validation loss: 2.5435751449410193

Epoch: 6| Step: 13
Training loss: 0.4190969126181454
Validation loss: 2.549467493491176

Epoch: 309| Step: 0
Training loss: 0.44933896322159367
Validation loss: 2.54766270037016

Epoch: 6| Step: 1
Training loss: 0.5000499461976992
Validation loss: 2.5502753278414203

Epoch: 6| Step: 2
Training loss: 0.6942007628039645
Validation loss: 2.5234294152010466

Epoch: 6| Step: 3
Training loss: 0.6218687057176581
Validation loss: 2.4786352917085384

Epoch: 6| Step: 4
Training loss: 0.436052909395686
Validation loss: 2.477586436137357

Epoch: 6| Step: 5
Training loss: 0.6340151296925266
Validation loss: 2.471416094544661

Epoch: 6| Step: 6
Training loss: 0.7238098833942476
Validation loss: 2.4695101982802243

Epoch: 6| Step: 7
Training loss: 0.5602771495554364
Validation loss: 2.4979465285542903

Epoch: 6| Step: 8
Training loss: 0.6219517281895988
Validation loss: 2.5468283434520687

Epoch: 6| Step: 9
Training loss: 0.4621679080320998
Validation loss: 2.5870487205015067

Epoch: 6| Step: 10
Training loss: 0.3783140765903606
Validation loss: 2.594681959948974

Epoch: 6| Step: 11
Training loss: 0.7027518235776319
Validation loss: 2.600500314012802

Epoch: 6| Step: 12
Training loss: 0.45900338316171335
Validation loss: 2.5744785608013987

Epoch: 6| Step: 13
Training loss: 0.42228115804865035
Validation loss: 2.570913598174502

Epoch: 310| Step: 0
Training loss: 0.3477570248394088
Validation loss: 2.5492695062694213

Epoch: 6| Step: 1
Training loss: 0.7145413869292639
Validation loss: 2.51551540907748

Epoch: 6| Step: 2
Training loss: 0.36544188046362175
Validation loss: 2.4880343982970117

Epoch: 6| Step: 3
Training loss: 0.6254695082504323
Validation loss: 2.4568334884271805

Epoch: 6| Step: 4
Training loss: 0.37114185222268176
Validation loss: 2.439944104965352

Epoch: 6| Step: 5
Training loss: 0.5797044725838124
Validation loss: 2.46884258216604

Epoch: 6| Step: 6
Training loss: 0.6808097169049305
Validation loss: 2.4899126177397677

Epoch: 6| Step: 7
Training loss: 0.5555963726414144
Validation loss: 2.5356231127610322

Epoch: 6| Step: 8
Training loss: 0.5536957054128716
Validation loss: 2.5749565893429276

Epoch: 6| Step: 9
Training loss: 0.6072937563494352
Validation loss: 2.5884795307822848

Epoch: 6| Step: 10
Training loss: 0.4041176919497589
Validation loss: 2.6082812546801053

Epoch: 6| Step: 11
Training loss: 0.6619174645393586
Validation loss: 2.6152497534595467

Epoch: 6| Step: 12
Training loss: 0.34307752200870795
Validation loss: 2.6060160636596588

Epoch: 6| Step: 13
Training loss: 0.7240680821795873
Validation loss: 2.5664083849459653

Epoch: 311| Step: 0
Training loss: 0.5398458787183292
Validation loss: 2.548657120747805

Epoch: 6| Step: 1
Training loss: 0.4329342509043576
Validation loss: 2.5482742770845093

Epoch: 6| Step: 2
Training loss: 0.5481985696551963
Validation loss: 2.5447704307365178

Epoch: 6| Step: 3
Training loss: 0.28912512642098587
Validation loss: 2.5316911467676584

Epoch: 6| Step: 4
Training loss: 0.4814692214693138
Validation loss: 2.5698745363884434

Epoch: 6| Step: 5
Training loss: 0.9227015136158957
Validation loss: 2.594773702461752

Epoch: 6| Step: 6
Training loss: 0.23350423545794413
Validation loss: 2.554754798145491

Epoch: 6| Step: 7
Training loss: 0.4773604013938217
Validation loss: 2.519345765894947

Epoch: 6| Step: 8
Training loss: 0.5976978362331632
Validation loss: 2.5558197752595047

Epoch: 6| Step: 9
Training loss: 0.4496293554829486
Validation loss: 2.5639651262142626

Epoch: 6| Step: 10
Training loss: 0.6501632613776019
Validation loss: 2.575408777497002

Epoch: 6| Step: 11
Training loss: 0.48539988471015283
Validation loss: 2.5544146114532307

Epoch: 6| Step: 12
Training loss: 0.6620580152548581
Validation loss: 2.5927784999659487

Epoch: 6| Step: 13
Training loss: 0.5223134055354024
Validation loss: 2.580594343151651

Epoch: 312| Step: 0
Training loss: 0.2662808371984897
Validation loss: 2.558778779579419

Epoch: 6| Step: 1
Training loss: 0.576744286636607
Validation loss: 2.558712629274203

Epoch: 6| Step: 2
Training loss: 0.4570965190482013
Validation loss: 2.5612137710575467

Epoch: 6| Step: 3
Training loss: 0.7091289194268721
Validation loss: 2.5622097569327704

Epoch: 6| Step: 4
Training loss: 0.5202036357092605
Validation loss: 2.5737721568374092

Epoch: 6| Step: 5
Training loss: 0.5237096676740306
Validation loss: 2.5841687750636533

Epoch: 6| Step: 6
Training loss: 0.5195271771493609
Validation loss: 2.5851721105992467

Epoch: 6| Step: 7
Training loss: 0.4873617899430891
Validation loss: 2.576496682742745

Epoch: 6| Step: 8
Training loss: 0.623597526567532
Validation loss: 2.600425942241308

Epoch: 6| Step: 9
Training loss: 0.8510851090610433
Validation loss: 2.5362884558256984

Epoch: 6| Step: 10
Training loss: 0.5814029963955138
Validation loss: 2.5065008313757904

Epoch: 6| Step: 11
Training loss: 0.4788238622544436
Validation loss: 2.4930846789524383

Epoch: 6| Step: 12
Training loss: 0.3689111470628956
Validation loss: 2.5057088402141576

Epoch: 6| Step: 13
Training loss: 0.4185361664946891
Validation loss: 2.4938002981888405

Epoch: 313| Step: 0
Training loss: 0.6540897098354701
Validation loss: 2.498973916841231

Epoch: 6| Step: 1
Training loss: 0.37902273766772365
Validation loss: 2.544356637531575

Epoch: 6| Step: 2
Training loss: 0.7148804368574264
Validation loss: 2.5095930949689613

Epoch: 6| Step: 3
Training loss: 0.5925534639903782
Validation loss: 2.5370803383334724

Epoch: 6| Step: 4
Training loss: 0.5903870814854256
Validation loss: 2.5930700417783967

Epoch: 6| Step: 5
Training loss: 0.5365892701088888
Validation loss: 2.5673977786101045

Epoch: 6| Step: 6
Training loss: 0.2096371038538801
Validation loss: 2.6064725692536657

Epoch: 6| Step: 7
Training loss: 0.5526303034961294
Validation loss: 2.591408118205642

Epoch: 6| Step: 8
Training loss: 0.5351607329466231
Validation loss: 2.6000657709856805

Epoch: 6| Step: 9
Training loss: 0.661889121181431
Validation loss: 2.576794578060936

Epoch: 6| Step: 10
Training loss: 0.603735207915506
Validation loss: 2.5464449185379148

Epoch: 6| Step: 11
Training loss: 0.37248775263628325
Validation loss: 2.536501396908411

Epoch: 6| Step: 12
Training loss: 0.4982734015424741
Validation loss: 2.4810747626693934

Epoch: 6| Step: 13
Training loss: 0.3777886455252832
Validation loss: 2.4681501385380193

Epoch: 314| Step: 0
Training loss: 0.7055128875815165
Validation loss: 2.4706934720412206

Epoch: 6| Step: 1
Training loss: 0.4534235661243525
Validation loss: 2.4446835404058493

Epoch: 6| Step: 2
Training loss: 0.613942197124443
Validation loss: 2.4565031776431967

Epoch: 6| Step: 3
Training loss: 0.5402833410263748
Validation loss: 2.4858349115643916

Epoch: 6| Step: 4
Training loss: 0.6313061623092322
Validation loss: 2.4938825804544695

Epoch: 6| Step: 5
Training loss: 0.5510816904494696
Validation loss: 2.5163416594835253

Epoch: 6| Step: 6
Training loss: 0.2718674269531304
Validation loss: 2.5635876312023935

Epoch: 6| Step: 7
Training loss: 0.3967735476245345
Validation loss: 2.5548066453287848

Epoch: 6| Step: 8
Training loss: 0.5309803222128006
Validation loss: 2.571387658450507

Epoch: 6| Step: 9
Training loss: 0.5409042574289161
Validation loss: 2.604043260829287

Epoch: 6| Step: 10
Training loss: 0.6094621938288171
Validation loss: 2.5658857696508948

Epoch: 6| Step: 11
Training loss: 0.49061800471864836
Validation loss: 2.5393486004378167

Epoch: 6| Step: 12
Training loss: 0.5308199993516927
Validation loss: 2.513491047555601

Epoch: 6| Step: 13
Training loss: 0.35125811433413257
Validation loss: 2.488767288241988

Epoch: 315| Step: 0
Training loss: 0.7347956325278691
Validation loss: 2.5190945836345002

Epoch: 6| Step: 1
Training loss: 0.578361256756234
Validation loss: 2.4663889477371805

Epoch: 6| Step: 2
Training loss: 0.7002724534533884
Validation loss: 2.490317830266337

Epoch: 6| Step: 3
Training loss: 0.3311543497504603
Validation loss: 2.5015468395776206

Epoch: 6| Step: 4
Training loss: 0.24423175636797592
Validation loss: 2.490626441289285

Epoch: 6| Step: 5
Training loss: 0.41042235688397527
Validation loss: 2.5447501977274456

Epoch: 6| Step: 6
Training loss: 0.44805272571631577
Validation loss: 2.5693035113318663

Epoch: 6| Step: 7
Training loss: 0.24732412336296888
Validation loss: 2.5480807759438475

Epoch: 6| Step: 8
Training loss: 0.488967626711158
Validation loss: 2.5787840139204383

Epoch: 6| Step: 9
Training loss: 0.4828310632686341
Validation loss: 2.555981695112546

Epoch: 6| Step: 10
Training loss: 0.5968430415680139
Validation loss: 2.5664014291960733

Epoch: 6| Step: 11
Training loss: 0.6428434989253334
Validation loss: 2.5260146841255797

Epoch: 6| Step: 12
Training loss: 0.2686529777294736
Validation loss: 2.5224047869399784

Epoch: 6| Step: 13
Training loss: 0.7266399793434372
Validation loss: 2.5259145444431814

Epoch: 316| Step: 0
Training loss: 0.5450589680924143
Validation loss: 2.5043333296414834

Epoch: 6| Step: 1
Training loss: 0.4996927032295225
Validation loss: 2.510301292102348

Epoch: 6| Step: 2
Training loss: 0.5107383363188336
Validation loss: 2.545897851444013

Epoch: 6| Step: 3
Training loss: 0.23127743712891477
Validation loss: 2.5647623663415096

Epoch: 6| Step: 4
Training loss: 0.38427226391625363
Validation loss: 2.5284218737388993

Epoch: 6| Step: 5
Training loss: 0.5198119702957388
Validation loss: 2.547057440629185

Epoch: 6| Step: 6
Training loss: 0.6229418483692207
Validation loss: 2.524427813874551

Epoch: 6| Step: 7
Training loss: 0.4458909878336125
Validation loss: 2.5270408089599536

Epoch: 6| Step: 8
Training loss: 0.6806682219850266
Validation loss: 2.5393026907549165

Epoch: 6| Step: 9
Training loss: 0.48284748160535124
Validation loss: 2.5603013068909957

Epoch: 6| Step: 10
Training loss: 0.5147801616108136
Validation loss: 2.565692529350072

Epoch: 6| Step: 11
Training loss: 0.37319845345591685
Validation loss: 2.536699916795295

Epoch: 6| Step: 12
Training loss: 0.391465846110241
Validation loss: 2.527390953386842

Epoch: 6| Step: 13
Training loss: 0.45848762740015875
Validation loss: 2.54198963998647

Epoch: 317| Step: 0
Training loss: 0.6218552150166877
Validation loss: 2.5624635855395677

Epoch: 6| Step: 1
Training loss: 0.5670282040364668
Validation loss: 2.551868927123398

Epoch: 6| Step: 2
Training loss: 0.38886160508828166
Validation loss: 2.5650258015393548

Epoch: 6| Step: 3
Training loss: 0.1867543733204736
Validation loss: 2.5526258851661088

Epoch: 6| Step: 4
Training loss: 0.399531396172847
Validation loss: 2.54652070047809

Epoch: 6| Step: 5
Training loss: 0.44385203746484003
Validation loss: 2.547685035476808

Epoch: 6| Step: 6
Training loss: 0.5564167040791123
Validation loss: 2.478023222620752

Epoch: 6| Step: 7
Training loss: 0.33023239232612656
Validation loss: 2.4896134973539237

Epoch: 6| Step: 8
Training loss: 0.46808679075878795
Validation loss: 2.470713901654347

Epoch: 6| Step: 9
Training loss: 0.5668571518987142
Validation loss: 2.51448636205005

Epoch: 6| Step: 10
Training loss: 0.5074955464623386
Validation loss: 2.4822089835410464

Epoch: 6| Step: 11
Training loss: 0.510084118497473
Validation loss: 2.4941743541721975

Epoch: 6| Step: 12
Training loss: 0.6214695878970086
Validation loss: 2.499727651671481

Epoch: 6| Step: 13
Training loss: 0.4205468960045744
Validation loss: 2.4878895802702945

Epoch: 318| Step: 0
Training loss: 0.6650036593745228
Validation loss: 2.4837849693442435

Epoch: 6| Step: 1
Training loss: 0.40369946113297217
Validation loss: 2.4961446300852095

Epoch: 6| Step: 2
Training loss: 0.44930226752080243
Validation loss: 2.52695251896717

Epoch: 6| Step: 3
Training loss: 0.4740359134549044
Validation loss: 2.4910280905649067

Epoch: 6| Step: 4
Training loss: 0.2410678825420371
Validation loss: 2.54358090753811

Epoch: 6| Step: 5
Training loss: 0.4579596260278617
Validation loss: 2.5097855986696582

Epoch: 6| Step: 6
Training loss: 0.6525128767781854
Validation loss: 2.5813626496073008

Epoch: 6| Step: 7
Training loss: 0.5326445731608922
Validation loss: 2.56644487204423

Epoch: 6| Step: 8
Training loss: 0.38617753197788296
Validation loss: 2.560213118502372

Epoch: 6| Step: 9
Training loss: 0.52809214292264
Validation loss: 2.561798680035139

Epoch: 6| Step: 10
Training loss: 0.5839087140626188
Validation loss: 2.5357303262340514

Epoch: 6| Step: 11
Training loss: 0.5085976912525951
Validation loss: 2.5305652945676407

Epoch: 6| Step: 12
Training loss: 0.24951142014338173
Validation loss: 2.556097736161827

Epoch: 6| Step: 13
Training loss: 0.20448723999276006
Validation loss: 2.5089750675094304

Epoch: 319| Step: 0
Training loss: 0.27424218439025505
Validation loss: 2.538243234632314

Epoch: 6| Step: 1
Training loss: 0.49696642796246737
Validation loss: 2.5200208166206397

Epoch: 6| Step: 2
Training loss: 0.5221382071277003
Validation loss: 2.5177358887847943

Epoch: 6| Step: 3
Training loss: 0.38966583748498895
Validation loss: 2.5139281931678683

Epoch: 6| Step: 4
Training loss: 0.4628258832893521
Validation loss: 2.5531201511462074

Epoch: 6| Step: 5
Training loss: 0.5245578788881933
Validation loss: 2.5197110258771844

Epoch: 6| Step: 6
Training loss: 0.5277840365769335
Validation loss: 2.5202237931899303

Epoch: 6| Step: 7
Training loss: 0.22359807773349835
Validation loss: 2.5309249586185283

Epoch: 6| Step: 8
Training loss: 0.34545055149960274
Validation loss: 2.5931554637505934

Epoch: 6| Step: 9
Training loss: 0.5475077102501441
Validation loss: 2.5710533449088238

Epoch: 6| Step: 10
Training loss: 0.7951496369710364
Validation loss: 2.6038058626995353

Epoch: 6| Step: 11
Training loss: 0.31721238475580554
Validation loss: 2.557579622964356

Epoch: 6| Step: 12
Training loss: 0.4786142675751161
Validation loss: 2.5504654002203746

Epoch: 6| Step: 13
Training loss: 0.4866896208837789
Validation loss: 2.540486978002381

Epoch: 320| Step: 0
Training loss: 0.46196396539988666
Validation loss: 2.5057488116560513

Epoch: 6| Step: 1
Training loss: 0.5073658372625429
Validation loss: 2.5269228562947315

Epoch: 6| Step: 2
Training loss: 0.444356678908285
Validation loss: 2.4981145157764724

Epoch: 6| Step: 3
Training loss: 0.5099146833302782
Validation loss: 2.5546191002113834

Epoch: 6| Step: 4
Training loss: 0.3998235082179786
Validation loss: 2.537771377628619

Epoch: 6| Step: 5
Training loss: 0.5546812675018474
Validation loss: 2.556044396668231

Epoch: 6| Step: 6
Training loss: 0.3351260298329302
Validation loss: 2.5441442330012696

Epoch: 6| Step: 7
Training loss: 0.637632942362626
Validation loss: 2.546576597145413

Epoch: 6| Step: 8
Training loss: 0.34206207885799905
Validation loss: 2.574922541405014

Epoch: 6| Step: 9
Training loss: 0.6053932881244405
Validation loss: 2.560088096302624

Epoch: 6| Step: 10
Training loss: 0.5242561372480493
Validation loss: 2.5840856056864503

Epoch: 6| Step: 11
Training loss: 0.3152660973150165
Validation loss: 2.539738833934242

Epoch: 6| Step: 12
Training loss: 0.5456726480764774
Validation loss: 2.555612430330488

Epoch: 6| Step: 13
Training loss: 0.47177538483453246
Validation loss: 2.5532027588147006

Epoch: 321| Step: 0
Training loss: 0.2777935061704035
Validation loss: 2.554737520200164

Epoch: 6| Step: 1
Training loss: 0.25815260734892714
Validation loss: 2.5413361749230403

Epoch: 6| Step: 2
Training loss: 0.5944987144039232
Validation loss: 2.5259756336941552

Epoch: 6| Step: 3
Training loss: 0.354203140493705
Validation loss: 2.5196430786580097

Epoch: 6| Step: 4
Training loss: 0.4482561495731966
Validation loss: 2.500490599865389

Epoch: 6| Step: 5
Training loss: 0.3922739511171102
Validation loss: 2.5258708612365166

Epoch: 6| Step: 6
Training loss: 0.5842305050667391
Validation loss: 2.473948351457252

Epoch: 6| Step: 7
Training loss: 0.3712310336306317
Validation loss: 2.486954158035931

Epoch: 6| Step: 8
Training loss: 0.7259053365452116
Validation loss: 2.5233092373707087

Epoch: 6| Step: 9
Training loss: 0.42952659368506335
Validation loss: 2.521684447160362

Epoch: 6| Step: 10
Training loss: 0.45915306724837357
Validation loss: 2.5195451084069664

Epoch: 6| Step: 11
Training loss: 0.6899527665571054
Validation loss: 2.517791118130807

Epoch: 6| Step: 12
Training loss: 0.18427916679026388
Validation loss: 2.5424482521331617

Epoch: 6| Step: 13
Training loss: 0.5376966837385037
Validation loss: 2.5502105477980908

Epoch: 322| Step: 0
Training loss: 0.3113317228561675
Validation loss: 2.5157520351538945

Epoch: 6| Step: 1
Training loss: 0.5307750261563423
Validation loss: 2.5588381033986027

Epoch: 6| Step: 2
Training loss: 0.3838880183261717
Validation loss: 2.530070937857745

Epoch: 6| Step: 3
Training loss: 0.43335053779610055
Validation loss: 2.5227326811087765

Epoch: 6| Step: 4
Training loss: 0.5729947961650841
Validation loss: 2.5145760939653825

Epoch: 6| Step: 5
Training loss: 0.4379153323795935
Validation loss: 2.489155202258785

Epoch: 6| Step: 6
Training loss: 0.8634602287799495
Validation loss: 2.4925159494178932

Epoch: 6| Step: 7
Training loss: 0.4642725087216128
Validation loss: 2.4868110976628803

Epoch: 6| Step: 8
Training loss: 0.28648587730228114
Validation loss: 2.528869860951944

Epoch: 6| Step: 9
Training loss: 0.4412844667130377
Validation loss: 2.5183944280580914

Epoch: 6| Step: 10
Training loss: 0.4103566724558013
Validation loss: 2.5065964446735074

Epoch: 6| Step: 11
Training loss: 0.3694594888185434
Validation loss: 2.5099157474334874

Epoch: 6| Step: 12
Training loss: 0.3665802174584837
Validation loss: 2.4918504455474815

Epoch: 6| Step: 13
Training loss: 0.395093554903969
Validation loss: 2.529691567101914

Epoch: 323| Step: 0
Training loss: 0.5836035465914479
Validation loss: 2.4851995843499837

Epoch: 6| Step: 1
Training loss: 0.4484993190887794
Validation loss: 2.5071540576118134

Epoch: 6| Step: 2
Training loss: 0.4616840749716581
Validation loss: 2.5215359983699766

Epoch: 6| Step: 3
Training loss: 0.4142795929315579
Validation loss: 2.5209973684535716

Epoch: 6| Step: 4
Training loss: 0.16686367644777508
Validation loss: 2.5042657923428626

Epoch: 6| Step: 5
Training loss: 0.37474573972874875
Validation loss: 2.4844197698557755

Epoch: 6| Step: 6
Training loss: 0.47779106246729514
Validation loss: 2.493620555214712

Epoch: 6| Step: 7
Training loss: 0.3253082674907287
Validation loss: 2.5017388664581257

Epoch: 6| Step: 8
Training loss: 0.42436423432707787
Validation loss: 2.494363147913824

Epoch: 6| Step: 9
Training loss: 0.44716884782067007
Validation loss: 2.5164371576385696

Epoch: 6| Step: 10
Training loss: 0.6821741240688948
Validation loss: 2.5041924660303225

Epoch: 6| Step: 11
Training loss: 0.6008651952544718
Validation loss: 2.5089283550140222

Epoch: 6| Step: 12
Training loss: 0.38131444105008483
Validation loss: 2.5303874873853176

Epoch: 6| Step: 13
Training loss: 0.17498234293619827
Validation loss: 2.5310319821561507

Epoch: 324| Step: 0
Training loss: 0.4635958872026809
Validation loss: 2.5023806619422304

Epoch: 6| Step: 1
Training loss: 0.24748890364221077
Validation loss: 2.536497879166441

Epoch: 6| Step: 2
Training loss: 0.3410776363765819
Validation loss: 2.537617273963285

Epoch: 6| Step: 3
Training loss: 0.3938920915140452
Validation loss: 2.5247800047077575

Epoch: 6| Step: 4
Training loss: 0.5127218766369688
Validation loss: 2.498997728365991

Epoch: 6| Step: 5
Training loss: 0.3795208223684256
Validation loss: 2.493004888742042

Epoch: 6| Step: 6
Training loss: 0.4444565829301607
Validation loss: 2.5241518727964976

Epoch: 6| Step: 7
Training loss: 0.47863235606859267
Validation loss: 2.5188314061297405

Epoch: 6| Step: 8
Training loss: 0.3974589504782756
Validation loss: 2.476387336302006

Epoch: 6| Step: 9
Training loss: 0.5089555347202769
Validation loss: 2.505357292521753

Epoch: 6| Step: 10
Training loss: 0.41718196793792345
Validation loss: 2.5154854097479373

Epoch: 6| Step: 11
Training loss: 0.6330322543389213
Validation loss: 2.5221247823081905

Epoch: 6| Step: 12
Training loss: 0.5778631442102085
Validation loss: 2.5370255804359187

Epoch: 6| Step: 13
Training loss: 0.33180172784865875
Validation loss: 2.5331088600814335

Epoch: 325| Step: 0
Training loss: 0.4334108465205244
Validation loss: 2.5429071203089397

Epoch: 6| Step: 1
Training loss: 0.455503535046558
Validation loss: 2.559863949895117

Epoch: 6| Step: 2
Training loss: 0.4207783326318055
Validation loss: 2.5400727034873554

Epoch: 6| Step: 3
Training loss: 0.6504601793643172
Validation loss: 2.496781104287252

Epoch: 6| Step: 4
Training loss: 0.2496078440420753
Validation loss: 2.5370815357387695

Epoch: 6| Step: 5
Training loss: 0.3189297814217332
Validation loss: 2.5244761578767885

Epoch: 6| Step: 6
Training loss: 0.45901109333595164
Validation loss: 2.556139760463843

Epoch: 6| Step: 7
Training loss: 0.3903861650842348
Validation loss: 2.5484872306750352

Epoch: 6| Step: 8
Training loss: 0.3665238531281677
Validation loss: 2.5283298904413134

Epoch: 6| Step: 9
Training loss: 0.5112123094483321
Validation loss: 2.534902158216572

Epoch: 6| Step: 10
Training loss: 0.4918451783908244
Validation loss: 2.515778855515797

Epoch: 6| Step: 11
Training loss: 0.2524614307718063
Validation loss: 2.50837301091319

Epoch: 6| Step: 12
Training loss: 0.5917181837685099
Validation loss: 2.517821961565718

Epoch: 6| Step: 13
Training loss: 0.3239412498978359
Validation loss: 2.536404013133668

Epoch: 326| Step: 0
Training loss: 0.5017785091445264
Validation loss: 2.5139440108451216

Epoch: 6| Step: 1
Training loss: 0.5570513364532904
Validation loss: 2.5334752646061114

Epoch: 6| Step: 2
Training loss: 0.3453824123535655
Validation loss: 2.5264896762196245

Epoch: 6| Step: 3
Training loss: 0.271729173685187
Validation loss: 2.5407268449015414

Epoch: 6| Step: 4
Training loss: 0.48916718029935385
Validation loss: 2.5425288471061567

Epoch: 6| Step: 5
Training loss: 0.7002333413920531
Validation loss: 2.576167985011561

Epoch: 6| Step: 6
Training loss: 0.49349903778708976
Validation loss: 2.5332288973597024

Epoch: 6| Step: 7
Training loss: 0.1385667429245577
Validation loss: 2.5387004544321123

Epoch: 6| Step: 8
Training loss: 0.24195744755412382
Validation loss: 2.550926303493969

Epoch: 6| Step: 9
Training loss: 0.598048710835814
Validation loss: 2.544303161722692

Epoch: 6| Step: 10
Training loss: 0.28264238815942844
Validation loss: 2.534941388691032

Epoch: 6| Step: 11
Training loss: 0.39975352889430393
Validation loss: 2.525864602012567

Epoch: 6| Step: 12
Training loss: 0.39189810239113926
Validation loss: 2.533893350975819

Epoch: 6| Step: 13
Training loss: 0.4631410717974726
Validation loss: 2.546226786881493

Epoch: 327| Step: 0
Training loss: 0.46464011596565596
Validation loss: 2.5627523518582853

Epoch: 6| Step: 1
Training loss: 0.4250727016311231
Validation loss: 2.569770509735253

Epoch: 6| Step: 2
Training loss: 0.642965345037629
Validation loss: 2.5699810830890777

Epoch: 6| Step: 3
Training loss: 0.4645435100930229
Validation loss: 2.574336042095235

Epoch: 6| Step: 4
Training loss: 0.4580255110519654
Validation loss: 2.542292671300389

Epoch: 6| Step: 5
Training loss: 0.5012749272376932
Validation loss: 2.5466852671688027

Epoch: 6| Step: 6
Training loss: 0.4670612751564271
Validation loss: 2.51172069335846

Epoch: 6| Step: 7
Training loss: 0.42525204309402165
Validation loss: 2.5156557548373897

Epoch: 6| Step: 8
Training loss: 0.32725142950149383
Validation loss: 2.505460985850981

Epoch: 6| Step: 9
Training loss: 0.40165210273398355
Validation loss: 2.5135705153623085

Epoch: 6| Step: 10
Training loss: 0.14940086007224937
Validation loss: 2.534077328159367

Epoch: 6| Step: 11
Training loss: 0.39612788818837646
Validation loss: 2.536786517398721

Epoch: 6| Step: 12
Training loss: 0.5704972216215022
Validation loss: 2.573580255051858

Epoch: 6| Step: 13
Training loss: 0.142276235286382
Validation loss: 2.543678210558832

Epoch: 328| Step: 0
Training loss: 0.47074605025844174
Validation loss: 2.559872194026892

Epoch: 6| Step: 1
Training loss: 0.30233791601974347
Validation loss: 2.5569696573064524

Epoch: 6| Step: 2
Training loss: 0.29622048456300093
Validation loss: 2.5519043259229814

Epoch: 6| Step: 3
Training loss: 0.6746256876587345
Validation loss: 2.5340645224549805

Epoch: 6| Step: 4
Training loss: 0.3569762156200996
Validation loss: 2.5271213566337916

Epoch: 6| Step: 5
Training loss: 0.559746785988212
Validation loss: 2.534776348802799

Epoch: 6| Step: 6
Training loss: 0.4665141346692335
Validation loss: 2.540965753380717

Epoch: 6| Step: 7
Training loss: 0.4368344933227474
Validation loss: 2.511587624946779

Epoch: 6| Step: 8
Training loss: 0.556859933582975
Validation loss: 2.577664520317816

Epoch: 6| Step: 9
Training loss: 0.25185096502992016
Validation loss: 2.56029219901114

Epoch: 6| Step: 10
Training loss: 0.34211114876429516
Validation loss: 2.561339890345834

Epoch: 6| Step: 11
Training loss: 0.3514113843177239
Validation loss: 2.5695265190262466

Epoch: 6| Step: 12
Training loss: 0.5384525773853781
Validation loss: 2.556556334960697

Epoch: 6| Step: 13
Training loss: 0.19720733839012816
Validation loss: 2.543005199652214

Epoch: 329| Step: 0
Training loss: 0.5392359578900087
Validation loss: 2.558484987578825

Epoch: 6| Step: 1
Training loss: 0.3187209340475224
Validation loss: 2.5643801011032945

Epoch: 6| Step: 2
Training loss: 0.40345172726980844
Validation loss: 2.559863226829815

Epoch: 6| Step: 3
Training loss: 0.2198968015914795
Validation loss: 2.5048777289823625

Epoch: 6| Step: 4
Training loss: 0.467960391980969
Validation loss: 2.517896639153438

Epoch: 6| Step: 5
Training loss: 0.46588046407297196
Validation loss: 2.5199617763832833

Epoch: 6| Step: 6
Training loss: 0.2701221291840964
Validation loss: 2.511655461423615

Epoch: 6| Step: 7
Training loss: 0.5059604911928871
Validation loss: 2.539283655725027

Epoch: 6| Step: 8
Training loss: 0.49055075600017306
Validation loss: 2.555577805667312

Epoch: 6| Step: 9
Training loss: 0.5321319776009902
Validation loss: 2.529255856163826

Epoch: 6| Step: 10
Training loss: 0.3379061921342867
Validation loss: 2.540020624690205

Epoch: 6| Step: 11
Training loss: 0.3144988980357358
Validation loss: 2.5119599793122442

Epoch: 6| Step: 12
Training loss: 0.49130211774500454
Validation loss: 2.4841414945722002

Epoch: 6| Step: 13
Training loss: 0.546062192427994
Validation loss: 2.5201367973860194

Epoch: 330| Step: 0
Training loss: 0.39091013991792795
Validation loss: 2.554079821752476

Epoch: 6| Step: 1
Training loss: 0.24608344858800701
Validation loss: 2.555126175477365

Epoch: 6| Step: 2
Training loss: 0.4857015288254488
Validation loss: 2.5176579571504307

Epoch: 6| Step: 3
Training loss: 0.4941204654969013
Validation loss: 2.517377772310873

Epoch: 6| Step: 4
Training loss: 0.3341768390616614
Validation loss: 2.500647250342978

Epoch: 6| Step: 5
Training loss: 0.3116140921298366
Validation loss: 2.498290460858416

Epoch: 6| Step: 6
Training loss: 0.3458000521368028
Validation loss: 2.5434534021756416

Epoch: 6| Step: 7
Training loss: 0.37554730768656935
Validation loss: 2.5046285129224732

Epoch: 6| Step: 8
Training loss: 0.4097566019961238
Validation loss: 2.5175041548658843

Epoch: 6| Step: 9
Training loss: 0.49612039209149666
Validation loss: 2.5181756092423426

Epoch: 6| Step: 10
Training loss: 0.4456522632567942
Validation loss: 2.545688742688209

Epoch: 6| Step: 11
Training loss: 0.6552734829807407
Validation loss: 2.529058770176186

Epoch: 6| Step: 12
Training loss: 0.4720016233812314
Validation loss: 2.515965676046666

Epoch: 6| Step: 13
Training loss: 0.4567270326075426
Validation loss: 2.5237084923929425

Epoch: 331| Step: 0
Training loss: 0.48940768202176416
Validation loss: 2.52885471498172

Epoch: 6| Step: 1
Training loss: 0.44999741778692487
Validation loss: 2.5256925378195185

Epoch: 6| Step: 2
Training loss: 0.19375231341549815
Validation loss: 2.5036204456536875

Epoch: 6| Step: 3
Training loss: 0.5722772903034598
Validation loss: 2.5120616294714595

Epoch: 6| Step: 4
Training loss: 0.4551834181100125
Validation loss: 2.5237465529547376

Epoch: 6| Step: 5
Training loss: 0.17638646946605258
Validation loss: 2.504460009116745

Epoch: 6| Step: 6
Training loss: 0.37095904666118357
Validation loss: 2.5021568761581143

Epoch: 6| Step: 7
Training loss: 0.5959612677904927
Validation loss: 2.522448912311482

Epoch: 6| Step: 8
Training loss: 0.32725219219994717
Validation loss: 2.5372223395880042

Epoch: 6| Step: 9
Training loss: 0.22673368563838714
Validation loss: 2.5443947942669425

Epoch: 6| Step: 10
Training loss: 0.4185479687370871
Validation loss: 2.5580701236926933

Epoch: 6| Step: 11
Training loss: 0.5774978122422034
Validation loss: 2.5385238149228178

Epoch: 6| Step: 12
Training loss: 0.46913196577963145
Validation loss: 2.549403639678792

Epoch: 6| Step: 13
Training loss: 0.3802648550200466
Validation loss: 2.5267602562974876

Epoch: 332| Step: 0
Training loss: 0.265872307260254
Validation loss: 2.544485334373592

Epoch: 6| Step: 1
Training loss: 0.46374124523854937
Validation loss: 2.54620169532115

Epoch: 6| Step: 2
Training loss: 0.47258140034359597
Validation loss: 2.5552312954506085

Epoch: 6| Step: 3
Training loss: 0.4280245419444718
Validation loss: 2.5258937615210617

Epoch: 6| Step: 4
Training loss: 0.5252858450967345
Validation loss: 2.5713745639870065

Epoch: 6| Step: 5
Training loss: 0.393194161261199
Validation loss: 2.5886088564945084

Epoch: 6| Step: 6
Training loss: 0.3836838284329407
Validation loss: 2.531938602756369

Epoch: 6| Step: 7
Training loss: 0.295545966086224
Validation loss: 2.534671245277172

Epoch: 6| Step: 8
Training loss: 0.16480114960382347
Validation loss: 2.564821375842539

Epoch: 6| Step: 9
Training loss: 0.4513733649233474
Validation loss: 2.5878757060776603

Epoch: 6| Step: 10
Training loss: 0.5339915835292348
Validation loss: 2.5703183527615305

Epoch: 6| Step: 11
Training loss: 0.6553917904437729
Validation loss: 2.56759556112061

Epoch: 6| Step: 12
Training loss: 0.2827277435891131
Validation loss: 2.584990019477226

Epoch: 6| Step: 13
Training loss: 0.35077229809117727
Validation loss: 2.5371150800353828

Epoch: 333| Step: 0
Training loss: 0.3926006329664937
Validation loss: 2.5410334018249614

Epoch: 6| Step: 1
Training loss: 0.4813795683195031
Validation loss: 2.5721470172943586

Epoch: 6| Step: 2
Training loss: 0.4441174315718428
Validation loss: 2.507848322349298

Epoch: 6| Step: 3
Training loss: 0.5456653841330235
Validation loss: 2.5062310271360357

Epoch: 6| Step: 4
Training loss: 0.42685453946743995
Validation loss: 2.4760958614081305

Epoch: 6| Step: 5
Training loss: 0.36483383655353646
Validation loss: 2.511334234500469

Epoch: 6| Step: 6
Training loss: 0.46436604228050415
Validation loss: 2.5489011076490593

Epoch: 6| Step: 7
Training loss: 0.5978569740865521
Validation loss: 2.5800295231633896

Epoch: 6| Step: 8
Training loss: 0.2597932442344687
Validation loss: 2.5923386499862624

Epoch: 6| Step: 9
Training loss: 0.32420707589698905
Validation loss: 2.594276533910237

Epoch: 6| Step: 10
Training loss: 0.2607662747004903
Validation loss: 2.5867034260616184

Epoch: 6| Step: 11
Training loss: 0.4052651829625762
Validation loss: 2.6032059923427306

Epoch: 6| Step: 12
Training loss: 0.45674505809872806
Validation loss: 2.6193860109218043

Epoch: 6| Step: 13
Training loss: 0.5721835705774826
Validation loss: 2.6053792900589285

Epoch: 334| Step: 0
Training loss: 0.5411522207412472
Validation loss: 2.5909952073023317

Epoch: 6| Step: 1
Training loss: 0.5375134976488721
Validation loss: 2.5691002752081955

Epoch: 6| Step: 2
Training loss: 0.3560469400020203
Validation loss: 2.5328651427483844

Epoch: 6| Step: 3
Training loss: 0.20045740602408707
Validation loss: 2.554936746339641

Epoch: 6| Step: 4
Training loss: 0.44848458378535133
Validation loss: 2.5229881336315696

Epoch: 6| Step: 5
Training loss: 0.332259806338303
Validation loss: 2.5268133617188333

Epoch: 6| Step: 6
Training loss: 0.5397331378417798
Validation loss: 2.5163092808965732

Epoch: 6| Step: 7
Training loss: 0.49404490150605956
Validation loss: 2.532702878887163

Epoch: 6| Step: 8
Training loss: 0.4147576668429064
Validation loss: 2.502740170439897

Epoch: 6| Step: 9
Training loss: 0.379111833939311
Validation loss: 2.4675113202397534

Epoch: 6| Step: 10
Training loss: 0.3593388622192695
Validation loss: 2.505597288500553

Epoch: 6| Step: 11
Training loss: 0.43474649008485167
Validation loss: 2.5342446317563927

Epoch: 6| Step: 12
Training loss: 0.38056464895968894
Validation loss: 2.5159840894061327

Epoch: 6| Step: 13
Training loss: 0.19455557062178158
Validation loss: 2.501995901962225

Epoch: 335| Step: 0
Training loss: 0.3622229141945135
Validation loss: 2.5240476111939953

Epoch: 6| Step: 1
Training loss: 0.421552464144435
Validation loss: 2.530090571881085

Epoch: 6| Step: 2
Training loss: 0.4529164261745644
Validation loss: 2.523154585713877

Epoch: 6| Step: 3
Training loss: 0.317997182282524
Validation loss: 2.573067129165545

Epoch: 6| Step: 4
Training loss: 0.3873402773942662
Validation loss: 2.571973271908989

Epoch: 6| Step: 5
Training loss: 0.4880722819444845
Validation loss: 2.5657476828628702

Epoch: 6| Step: 6
Training loss: 0.5240190321672793
Validation loss: 2.5877363060888143

Epoch: 6| Step: 7
Training loss: 0.3881241279014827
Validation loss: 2.5478449593235357

Epoch: 6| Step: 8
Training loss: 0.5777447971025538
Validation loss: 2.541506651453029

Epoch: 6| Step: 9
Training loss: 0.36600346092114705
Validation loss: 2.5143000887491316

Epoch: 6| Step: 10
Training loss: 0.3576290384909252
Validation loss: 2.5199795857543617

Epoch: 6| Step: 11
Training loss: 0.4750522697701256
Validation loss: 2.4787363299492817

Epoch: 6| Step: 12
Training loss: 0.4334187713020145
Validation loss: 2.520971936292137

Epoch: 6| Step: 13
Training loss: 0.2565738080049904
Validation loss: 2.492063499387791

Epoch: 336| Step: 0
Training loss: 0.4895608538343419
Validation loss: 2.5004458040201314

Epoch: 6| Step: 1
Training loss: 0.4204203818181967
Validation loss: 2.484140316540882

Epoch: 6| Step: 2
Training loss: 0.3585045680761923
Validation loss: 2.501537643831477

Epoch: 6| Step: 3
Training loss: 0.5033309668944268
Validation loss: 2.514566541119302

Epoch: 6| Step: 4
Training loss: 0.5453113271706109
Validation loss: 2.514475478346951

Epoch: 6| Step: 5
Training loss: 0.5153642052688742
Validation loss: 2.523315254018022

Epoch: 6| Step: 6
Training loss: 0.3815319871066573
Validation loss: 2.516252732240258

Epoch: 6| Step: 7
Training loss: 0.46203237554718174
Validation loss: 2.5170385707174403

Epoch: 6| Step: 8
Training loss: 0.39160106782572796
Validation loss: 2.5049382505223154

Epoch: 6| Step: 9
Training loss: 0.1595771251144018
Validation loss: 2.4988395725447847

Epoch: 6| Step: 10
Training loss: 0.41045552189207823
Validation loss: 2.5131864433333226

Epoch: 6| Step: 11
Training loss: 0.3027194603968452
Validation loss: 2.5220184575190423

Epoch: 6| Step: 12
Training loss: 0.37543609216768076
Validation loss: 2.4895163755456844

Epoch: 6| Step: 13
Training loss: 0.29168514068316326
Validation loss: 2.5022933552003455

Epoch: 337| Step: 0
Training loss: 0.3492512387005924
Validation loss: 2.4894760894090786

Epoch: 6| Step: 1
Training loss: 0.3337858848353557
Validation loss: 2.4943823630953625

Epoch: 6| Step: 2
Training loss: 0.5746883107314995
Validation loss: 2.481221211075952

Epoch: 6| Step: 3
Training loss: 0.49438696589981057
Validation loss: 2.462219423182132

Epoch: 6| Step: 4
Training loss: 0.29464247396989157
Validation loss: 2.4882985608004273

Epoch: 6| Step: 5
Training loss: 0.33556894667200954
Validation loss: 2.4890416031711697

Epoch: 6| Step: 6
Training loss: 0.3741385977326307
Validation loss: 2.536745275053698

Epoch: 6| Step: 7
Training loss: 0.5143441272337654
Validation loss: 2.5585479784837575

Epoch: 6| Step: 8
Training loss: 0.4808127559620027
Validation loss: 2.5521008204417077

Epoch: 6| Step: 9
Training loss: 0.22992485329620305
Validation loss: 2.539998783362881

Epoch: 6| Step: 10
Training loss: 0.5439149584425097
Validation loss: 2.583817063240795

Epoch: 6| Step: 11
Training loss: 0.34421475377405947
Validation loss: 2.52859268765432

Epoch: 6| Step: 12
Training loss: 0.42175849436112767
Validation loss: 2.5443572491320308

Epoch: 6| Step: 13
Training loss: 0.29832301115758697
Validation loss: 2.5182241989996017

Epoch: 338| Step: 0
Training loss: 0.3287494711635963
Validation loss: 2.5218353849439357

Epoch: 6| Step: 1
Training loss: 0.5121367981854991
Validation loss: 2.518306311354364

Epoch: 6| Step: 2
Training loss: 0.47200777951998146
Validation loss: 2.5157843067821877

Epoch: 6| Step: 3
Training loss: 0.3393659411673801
Validation loss: 2.4932834178988954

Epoch: 6| Step: 4
Training loss: 0.32537879006431253
Validation loss: 2.5176799617407983

Epoch: 6| Step: 5
Training loss: 0.27989981334134223
Validation loss: 2.4917690632905938

Epoch: 6| Step: 6
Training loss: 0.40501984165001503
Validation loss: 2.5558094667908877

Epoch: 6| Step: 7
Training loss: 0.500361639608258
Validation loss: 2.5447096581873323

Epoch: 6| Step: 8
Training loss: 0.4264515316726259
Validation loss: 2.524333128846932

Epoch: 6| Step: 9
Training loss: 0.3997015256709915
Validation loss: 2.5802369686093694

Epoch: 6| Step: 10
Training loss: 0.3052423755465231
Validation loss: 2.5949722703466183

Epoch: 6| Step: 11
Training loss: 0.4129691894621284
Validation loss: 2.540133230708639

Epoch: 6| Step: 12
Training loss: 0.33567190760648863
Validation loss: 2.5643714435858813

Epoch: 6| Step: 13
Training loss: 0.6647689427606708
Validation loss: 2.520007107323102

Epoch: 339| Step: 0
Training loss: 0.28304807430542867
Validation loss: 2.5358244674189185

Epoch: 6| Step: 1
Training loss: 0.4431815105717265
Validation loss: 2.500992422113698

Epoch: 6| Step: 2
Training loss: 0.6665680012607823
Validation loss: 2.4725606576149834

Epoch: 6| Step: 3
Training loss: 0.30927464658948106
Validation loss: 2.4892899229690046

Epoch: 6| Step: 4
Training loss: 0.45466775359702494
Validation loss: 2.495526306172011

Epoch: 6| Step: 5
Training loss: 0.381092802064537
Validation loss: 2.492980848243758

Epoch: 6| Step: 6
Training loss: 0.36303583695189334
Validation loss: 2.523869897919609

Epoch: 6| Step: 7
Training loss: 0.3026827122075107
Validation loss: 2.5087582612933352

Epoch: 6| Step: 8
Training loss: 0.44257981922064427
Validation loss: 2.524359586375486

Epoch: 6| Step: 9
Training loss: 0.503353170226104
Validation loss: 2.523381270083081

Epoch: 6| Step: 10
Training loss: 0.3951240467300187
Validation loss: 2.536674879562426

Epoch: 6| Step: 11
Training loss: 0.40713834836263074
Validation loss: 2.529739134573926

Epoch: 6| Step: 12
Training loss: 0.3827655919198757
Validation loss: 2.480322645795521

Epoch: 6| Step: 13
Training loss: 0.30827664125828647
Validation loss: 2.511656809764748

Epoch: 340| Step: 0
Training loss: 0.299225412199986
Validation loss: 2.49271465246016

Epoch: 6| Step: 1
Training loss: 0.5217485366000173
Validation loss: 2.514241030415619

Epoch: 6| Step: 2
Training loss: 0.4844673437878015
Validation loss: 2.496903637001787

Epoch: 6| Step: 3
Training loss: 0.2541052112126793
Validation loss: 2.487189022299303

Epoch: 6| Step: 4
Training loss: 0.5097516814330892
Validation loss: 2.497096315593149

Epoch: 6| Step: 5
Training loss: 0.33310702459709535
Validation loss: 2.493651348067319

Epoch: 6| Step: 6
Training loss: 0.4841520965581204
Validation loss: 2.475756787065889

Epoch: 6| Step: 7
Training loss: 0.5446527835289796
Validation loss: 2.4885177696936776

Epoch: 6| Step: 8
Training loss: 0.3655757838323956
Validation loss: 2.487913189265723

Epoch: 6| Step: 9
Training loss: 0.4411789638084197
Validation loss: 2.4764345829007626

Epoch: 6| Step: 10
Training loss: 0.1844482017936132
Validation loss: 2.4939754395183162

Epoch: 6| Step: 11
Training loss: 0.45437369447439246
Validation loss: 2.463606980383349

Epoch: 6| Step: 12
Training loss: 0.44396469201460476
Validation loss: 2.487130439090697

Epoch: 6| Step: 13
Training loss: 0.2747307982403667
Validation loss: 2.480705618762023

Epoch: 341| Step: 0
Training loss: 0.40861257068475065
Validation loss: 2.487510590271284

Epoch: 6| Step: 1
Training loss: 0.2939672366865997
Validation loss: 2.520820805447218

Epoch: 6| Step: 2
Training loss: 0.5357085114122455
Validation loss: 2.5271146054537685

Epoch: 6| Step: 3
Training loss: 0.5446525372978299
Validation loss: 2.5612539798057425

Epoch: 6| Step: 4
Training loss: 0.6010246349369944
Validation loss: 2.552182558067416

Epoch: 6| Step: 5
Training loss: 0.21800262639121615
Validation loss: 2.547353641526263

Epoch: 6| Step: 6
Training loss: 0.3892054130630594
Validation loss: 2.5285072887293483

Epoch: 6| Step: 7
Training loss: 0.4752730137100519
Validation loss: 2.500360722307917

Epoch: 6| Step: 8
Training loss: 0.4036030736445126
Validation loss: 2.481157021105398

Epoch: 6| Step: 9
Training loss: 0.49345495124286415
Validation loss: 2.446653433834902

Epoch: 6| Step: 10
Training loss: 0.3337883848269365
Validation loss: 2.449482837294063

Epoch: 6| Step: 11
Training loss: 0.3851034163011225
Validation loss: 2.446587286463339

Epoch: 6| Step: 12
Training loss: 0.3513757845646945
Validation loss: 2.4780358296233946

Epoch: 6| Step: 13
Training loss: 0.17849650833644404
Validation loss: 2.5156056576551253

Epoch: 342| Step: 0
Training loss: 0.3332207857306068
Validation loss: 2.5228000004378774

Epoch: 6| Step: 1
Training loss: 0.289619128955939
Validation loss: 2.526327540758997

Epoch: 6| Step: 2
Training loss: 0.4672721135502635
Validation loss: 2.487155944145693

Epoch: 6| Step: 3
Training loss: 0.37516824603811005
Validation loss: 2.5218992638199955

Epoch: 6| Step: 4
Training loss: 0.3674324719999419
Validation loss: 2.5010104700923343

Epoch: 6| Step: 5
Training loss: 0.4497889010350394
Validation loss: 2.476670686441984

Epoch: 6| Step: 6
Training loss: 0.5772559103004415
Validation loss: 2.5137487706450075

Epoch: 6| Step: 7
Training loss: 0.5214015594902465
Validation loss: 2.520115888486047

Epoch: 6| Step: 8
Training loss: 0.5222043557131862
Validation loss: 2.529981723078818

Epoch: 6| Step: 9
Training loss: 0.3332092034164491
Validation loss: 2.509924431404254

Epoch: 6| Step: 10
Training loss: 0.4202360530379366
Validation loss: 2.514845255210049

Epoch: 6| Step: 11
Training loss: 0.1581531963916637
Validation loss: 2.549919443267564

Epoch: 6| Step: 12
Training loss: 0.2986456993620756
Validation loss: 2.5297300879253757

Epoch: 6| Step: 13
Training loss: 0.253316517186024
Validation loss: 2.533056402802792

Epoch: 343| Step: 0
Training loss: 0.15350705819335572
Validation loss: 2.5203708525127473

Epoch: 6| Step: 1
Training loss: 0.46025186397003065
Validation loss: 2.508977092692444

Epoch: 6| Step: 2
Training loss: 0.3126102491450361
Validation loss: 2.5302609327127943

Epoch: 6| Step: 3
Training loss: 0.42484467416868327
Validation loss: 2.535194519928158

Epoch: 6| Step: 4
Training loss: 0.37937742609571196
Validation loss: 2.4899541910129317

Epoch: 6| Step: 5
Training loss: 0.3041413008660078
Validation loss: 2.5126282601414847

Epoch: 6| Step: 6
Training loss: 0.5404999957794838
Validation loss: 2.554468130498812

Epoch: 6| Step: 7
Training loss: 0.4871434038477388
Validation loss: 2.5235979207060213

Epoch: 6| Step: 8
Training loss: 0.36329388340138336
Validation loss: 2.5395313945045683

Epoch: 6| Step: 9
Training loss: 0.3243969806581195
Validation loss: 2.5183077589526643

Epoch: 6| Step: 10
Training loss: 0.3028852763477328
Validation loss: 2.5031947012345324

Epoch: 6| Step: 11
Training loss: 0.3192602645385928
Validation loss: 2.5006197612375094

Epoch: 6| Step: 12
Training loss: 0.590515512076956
Validation loss: 2.5142171899145858

Epoch: 6| Step: 13
Training loss: 0.4823504870024261
Validation loss: 2.5340448575097567

Epoch: 344| Step: 0
Training loss: 0.3255412235231767
Validation loss: 2.5584766658297404

Epoch: 6| Step: 1
Training loss: 0.2131770333483355
Validation loss: 2.554772053897597

Epoch: 6| Step: 2
Training loss: 0.37209496203694736
Validation loss: 2.5183480572306887

Epoch: 6| Step: 3
Training loss: 0.34843661560493755
Validation loss: 2.5250391427223327

Epoch: 6| Step: 4
Training loss: 0.25746845640102556
Validation loss: 2.510616655689146

Epoch: 6| Step: 5
Training loss: 0.329119186608637
Validation loss: 2.4661029037008584

Epoch: 6| Step: 6
Training loss: 0.35356942710543926
Validation loss: 2.495510614198046

Epoch: 6| Step: 7
Training loss: 0.6233169066165218
Validation loss: 2.461494675713788

Epoch: 6| Step: 8
Training loss: 0.5123226882500441
Validation loss: 2.4938658152081867

Epoch: 6| Step: 9
Training loss: 0.5715224873264578
Validation loss: 2.4913817435368424

Epoch: 6| Step: 10
Training loss: 0.43772443055746535
Validation loss: 2.5202136910846145

Epoch: 6| Step: 11
Training loss: 0.4761661382115233
Validation loss: 2.512228926943667

Epoch: 6| Step: 12
Training loss: 0.20279540317576492
Validation loss: 2.506768293769712

Epoch: 6| Step: 13
Training loss: 0.29922581059265363
Validation loss: 2.5304771093105534

Epoch: 345| Step: 0
Training loss: 0.4230832352867612
Validation loss: 2.536110132038686

Epoch: 6| Step: 1
Training loss: 0.268117944873565
Validation loss: 2.5631930566795713

Epoch: 6| Step: 2
Training loss: 0.30142184569657426
Validation loss: 2.542364966296364

Epoch: 6| Step: 3
Training loss: 0.17858580080165043
Validation loss: 2.536463091108985

Epoch: 6| Step: 4
Training loss: 0.5037176089604907
Validation loss: 2.544654296274416

Epoch: 6| Step: 5
Training loss: 0.41416109458710904
Validation loss: 2.5178774761491827

Epoch: 6| Step: 6
Training loss: 0.3619714525713539
Validation loss: 2.518036843029681

Epoch: 6| Step: 7
Training loss: 0.5132965341089429
Validation loss: 2.536561495419446

Epoch: 6| Step: 8
Training loss: 0.3132898362807193
Validation loss: 2.5255995293819518

Epoch: 6| Step: 9
Training loss: 0.3548898489406197
Validation loss: 2.5117564778310943

Epoch: 6| Step: 10
Training loss: 0.3514727371910858
Validation loss: 2.537329899738079

Epoch: 6| Step: 11
Training loss: 0.4721207540865038
Validation loss: 2.5271952451167183

Epoch: 6| Step: 12
Training loss: 0.2862338385746397
Validation loss: 2.522816741073559

Epoch: 6| Step: 13
Training loss: 0.5205316878062338
Validation loss: 2.5446368872842116

Epoch: 346| Step: 0
Training loss: 0.4386253869007977
Validation loss: 2.524919489018928

Epoch: 6| Step: 1
Training loss: 0.48496229192304197
Validation loss: 2.50831731254845

Epoch: 6| Step: 2
Training loss: 0.3812504643296713
Validation loss: 2.5249316377339475

Epoch: 6| Step: 3
Training loss: 0.3608541318054576
Validation loss: 2.5183990465669193

Epoch: 6| Step: 4
Training loss: 0.2466471822046433
Validation loss: 2.498683574131568

Epoch: 6| Step: 5
Training loss: 0.5789906490440502
Validation loss: 2.5084219198378346

Epoch: 6| Step: 6
Training loss: 0.51406024712066
Validation loss: 2.5427593086165667

Epoch: 6| Step: 7
Training loss: 0.2550091485177564
Validation loss: 2.551640195631757

Epoch: 6| Step: 8
Training loss: 0.31154362245416617
Validation loss: 2.5176958739640436

Epoch: 6| Step: 9
Training loss: 0.21766060099802167
Validation loss: 2.5463338146468155

Epoch: 6| Step: 10
Training loss: 0.40277550503027437
Validation loss: 2.555591350230133

Epoch: 6| Step: 11
Training loss: 0.41418656703693657
Validation loss: 2.5496340554215298

Epoch: 6| Step: 12
Training loss: 0.15583043989089443
Validation loss: 2.527123844573497

Epoch: 6| Step: 13
Training loss: 0.20109637241683964
Validation loss: 2.544076212807561

Epoch: 347| Step: 0
Training loss: 0.28703002092558266
Validation loss: 2.5269435029232192

Epoch: 6| Step: 1
Training loss: 0.40009162717656943
Validation loss: 2.538374453226711

Epoch: 6| Step: 2
Training loss: 0.3907660420420251
Validation loss: 2.5243993229256314

Epoch: 6| Step: 3
Training loss: 0.3021360945939221
Validation loss: 2.5056306501234547

Epoch: 6| Step: 4
Training loss: 0.49388311861124273
Validation loss: 2.531810146545959

Epoch: 6| Step: 5
Training loss: 0.4616820416001961
Validation loss: 2.5078432167310383

Epoch: 6| Step: 6
Training loss: 0.14849282789571427
Validation loss: 2.5159216494238135

Epoch: 6| Step: 7
Training loss: 0.4073075687331783
Validation loss: 2.4989226604076125

Epoch: 6| Step: 8
Training loss: 0.32524044422476817
Validation loss: 2.4939704499246353

Epoch: 6| Step: 9
Training loss: 0.28216702582349035
Validation loss: 2.5374467301102777

Epoch: 6| Step: 10
Training loss: 0.21871552876938535
Validation loss: 2.507203825705721

Epoch: 6| Step: 11
Training loss: 0.4737746979860679
Validation loss: 2.505039225668213

Epoch: 6| Step: 12
Training loss: 0.5106380786878373
Validation loss: 2.5301234924979554

Epoch: 6| Step: 13
Training loss: 0.29586504757270393
Validation loss: 2.512067597538665

Epoch: 348| Step: 0
Training loss: 0.3010915913922662
Validation loss: 2.5337241075681742

Epoch: 6| Step: 1
Training loss: 0.5557444536084208
Validation loss: 2.549050287008164

Epoch: 6| Step: 2
Training loss: 0.2876684882043526
Validation loss: 2.562027779904818

Epoch: 6| Step: 3
Training loss: 0.19785660325884707
Validation loss: 2.5297760140010124

Epoch: 6| Step: 4
Training loss: 0.5454886165728363
Validation loss: 2.5148013608656825

Epoch: 6| Step: 5
Training loss: 0.33072730561981833
Validation loss: 2.528102430390453

Epoch: 6| Step: 6
Training loss: 0.3090059207778016
Validation loss: 2.514806001774267

Epoch: 6| Step: 7
Training loss: 0.36535075572306225
Validation loss: 2.5341445352954897

Epoch: 6| Step: 8
Training loss: 0.24559977318168086
Validation loss: 2.5147209395173418

Epoch: 6| Step: 9
Training loss: 0.41899944391418553
Validation loss: 2.535343920824816

Epoch: 6| Step: 10
Training loss: 0.20381716027966512
Validation loss: 2.5400160031052326

Epoch: 6| Step: 11
Training loss: 0.3589471675282284
Validation loss: 2.5553045045482423

Epoch: 6| Step: 12
Training loss: 0.42865824103986283
Validation loss: 2.5439127052857526

Epoch: 6| Step: 13
Training loss: 0.34832590950617365
Validation loss: 2.5661345237334974

Epoch: 349| Step: 0
Training loss: 0.3434109424496453
Validation loss: 2.5606238647539477

Epoch: 6| Step: 1
Training loss: 0.3764296934587276
Validation loss: 2.551221285481244

Epoch: 6| Step: 2
Training loss: 0.385704057957767
Validation loss: 2.5187571308142225

Epoch: 6| Step: 3
Training loss: 0.37061389214915763
Validation loss: 2.5607320788112027

Epoch: 6| Step: 4
Training loss: 0.3826007646713552
Validation loss: 2.537714730385152

Epoch: 6| Step: 5
Training loss: 0.3156430730272034
Validation loss: 2.534547762940805

Epoch: 6| Step: 6
Training loss: 0.26694540410630685
Validation loss: 2.5297783022264935

Epoch: 6| Step: 7
Training loss: 0.27351017394922367
Validation loss: 2.506682210638192

Epoch: 6| Step: 8
Training loss: 0.43167089986136964
Validation loss: 2.558639391445289

Epoch: 6| Step: 9
Training loss: 0.40931388092973037
Validation loss: 2.504709016254608

Epoch: 6| Step: 10
Training loss: 0.38535213789435313
Validation loss: 2.5031038520684388

Epoch: 6| Step: 11
Training loss: 0.49381744612203615
Validation loss: 2.5412467069631606

Epoch: 6| Step: 12
Training loss: 0.20532972251967904
Validation loss: 2.520489043648522

Epoch: 6| Step: 13
Training loss: 0.4630950605056129
Validation loss: 2.510294903676205

Epoch: 350| Step: 0
Training loss: 0.4218282673701243
Validation loss: 2.5131559362516813

Epoch: 6| Step: 1
Training loss: 0.1803816779335296
Validation loss: 2.5470602850269106

Epoch: 6| Step: 2
Training loss: 0.2783487271979251
Validation loss: 2.5322393137178354

Epoch: 6| Step: 3
Training loss: 0.5379199483354232
Validation loss: 2.5516241223420617

Epoch: 6| Step: 4
Training loss: 0.41264850370856193
Validation loss: 2.5400468098121567

Epoch: 6| Step: 5
Training loss: 0.32693640826842807
Validation loss: 2.5467245798731577

Epoch: 6| Step: 6
Training loss: 0.5255678863430833
Validation loss: 2.5397618514318396

Epoch: 6| Step: 7
Training loss: 0.292355658850845
Validation loss: 2.5150499531827446

Epoch: 6| Step: 8
Training loss: 0.4074768468211943
Validation loss: 2.495063383818967

Epoch: 6| Step: 9
Training loss: 0.3879771133301876
Validation loss: 2.504020040871096

Epoch: 6| Step: 10
Training loss: 0.2171066922862488
Validation loss: 2.544106734552558

Epoch: 6| Step: 11
Training loss: 0.1565863029960284
Validation loss: 2.543212429324196

Epoch: 6| Step: 12
Training loss: 0.46943731780665093
Validation loss: 2.522156410808181

Epoch: 6| Step: 13
Training loss: 0.27720353786514523
Validation loss: 2.513867286379763

Epoch: 351| Step: 0
Training loss: 0.4875000617442948
Validation loss: 2.531266020361184

Epoch: 6| Step: 1
Training loss: 0.19380039436474408
Validation loss: 2.5688586653657026

Epoch: 6| Step: 2
Training loss: 0.4070859524510185
Validation loss: 2.524546815329814

Epoch: 6| Step: 3
Training loss: 0.3822485604093799
Validation loss: 2.5388273911839665

Epoch: 6| Step: 4
Training loss: 0.4173481692555401
Validation loss: 2.527553953514255

Epoch: 6| Step: 5
Training loss: 0.275796482973067
Validation loss: 2.5318895527335434

Epoch: 6| Step: 6
Training loss: 0.3210647866953129
Validation loss: 2.5147565125799543

Epoch: 6| Step: 7
Training loss: 0.39574506260628856
Validation loss: 2.510861635419016

Epoch: 6| Step: 8
Training loss: 0.21351563287226205
Validation loss: 2.524635561615764

Epoch: 6| Step: 9
Training loss: 0.2831218339730393
Validation loss: 2.5543187025022815

Epoch: 6| Step: 10
Training loss: 0.2257318891535073
Validation loss: 2.524384413668221

Epoch: 6| Step: 11
Training loss: 0.5074497981680824
Validation loss: 2.547722596473978

Epoch: 6| Step: 12
Training loss: 0.47833918218437255
Validation loss: 2.533192290339697

Epoch: 6| Step: 13
Training loss: 0.24705268585896784
Validation loss: 2.5229689188646134

Epoch: 352| Step: 0
Training loss: 0.37317928740371165
Validation loss: 2.5213146595985725

Epoch: 6| Step: 1
Training loss: 0.37964852372415886
Validation loss: 2.5292321419882344

Epoch: 6| Step: 2
Training loss: 0.3414525177460189
Validation loss: 2.5125658607329946

Epoch: 6| Step: 3
Training loss: 0.2921275204789315
Validation loss: 2.524179951652363

Epoch: 6| Step: 4
Training loss: 0.30410191922421076
Validation loss: 2.4931534240173576

Epoch: 6| Step: 5
Training loss: 0.30187935217885153
Validation loss: 2.549842796390128

Epoch: 6| Step: 6
Training loss: 0.5116262279470598
Validation loss: 2.5150935674673316

Epoch: 6| Step: 7
Training loss: 0.2848562988429856
Validation loss: 2.525606601310456

Epoch: 6| Step: 8
Training loss: 0.4208249162864568
Validation loss: 2.520855499701663

Epoch: 6| Step: 9
Training loss: 0.47267734070689266
Validation loss: 2.5393483404744948

Epoch: 6| Step: 10
Training loss: 0.3829827027598147
Validation loss: 2.536215542860564

Epoch: 6| Step: 11
Training loss: 0.10705090537200619
Validation loss: 2.5595822549333285

Epoch: 6| Step: 12
Training loss: 0.24491658303903055
Validation loss: 2.569442014647797

Epoch: 6| Step: 13
Training loss: 0.3249699725437948
Validation loss: 2.544897944154076

Epoch: 353| Step: 0
Training loss: 0.3531302569850438
Validation loss: 2.533947209357497

Epoch: 6| Step: 1
Training loss: 0.4977313070422733
Validation loss: 2.549261367633341

Epoch: 6| Step: 2
Training loss: 0.4564664235944023
Validation loss: 2.507809591152684

Epoch: 6| Step: 3
Training loss: 0.5569606463400288
Validation loss: 2.505593778017355

Epoch: 6| Step: 4
Training loss: 0.40878816140663793
Validation loss: 2.4936121701827014

Epoch: 6| Step: 5
Training loss: 0.30028553775183864
Validation loss: 2.481901490882853

Epoch: 6| Step: 6
Training loss: 0.2953566825956685
Validation loss: 2.477616685339459

Epoch: 6| Step: 7
Training loss: 0.18224853391345455
Validation loss: 2.4750165170827123

Epoch: 6| Step: 8
Training loss: 0.3049550593403206
Validation loss: 2.51940579182698

Epoch: 6| Step: 9
Training loss: 0.2456723874732184
Validation loss: 2.5365273919657576

Epoch: 6| Step: 10
Training loss: 0.2764757839397696
Validation loss: 2.518568150229474

Epoch: 6| Step: 11
Training loss: 0.26008914219446955
Validation loss: 2.5357605854874175

Epoch: 6| Step: 12
Training loss: 0.41221593771727016
Validation loss: 2.5962502158646052

Epoch: 6| Step: 13
Training loss: 0.35286635108683256
Validation loss: 2.549137569268491

Epoch: 354| Step: 0
Training loss: 0.47569624543912575
Validation loss: 2.5846613157700244

Epoch: 6| Step: 1
Training loss: 0.5423366792130535
Validation loss: 2.5384183918914904

Epoch: 6| Step: 2
Training loss: 0.31370975460436995
Validation loss: 2.5362673394422903

Epoch: 6| Step: 3
Training loss: 0.4410462388258284
Validation loss: 2.5392052687774367

Epoch: 6| Step: 4
Training loss: 0.17494588083224213
Validation loss: 2.4556584983819265

Epoch: 6| Step: 5
Training loss: 0.30139660744200575
Validation loss: 2.5206569676717074

Epoch: 6| Step: 6
Training loss: 0.39428784633130626
Validation loss: 2.5294459983913806

Epoch: 6| Step: 7
Training loss: 0.39002400895946354
Validation loss: 2.5185866244665363

Epoch: 6| Step: 8
Training loss: 0.22078423992759252
Validation loss: 2.5342027939312803

Epoch: 6| Step: 9
Training loss: 0.2543376778537344
Validation loss: 2.5145992841893583

Epoch: 6| Step: 10
Training loss: 0.2911962038505032
Validation loss: 2.5707292116420413

Epoch: 6| Step: 11
Training loss: 0.3728142257548165
Validation loss: 2.5468747473476983

Epoch: 6| Step: 12
Training loss: 0.3008065894216146
Validation loss: 2.557281711325831

Epoch: 6| Step: 13
Training loss: 0.2568148615207005
Validation loss: 2.5558439719618344

Epoch: 355| Step: 0
Training loss: 0.27259902462879254
Validation loss: 2.515356988272423

Epoch: 6| Step: 1
Training loss: 0.29679247060360986
Validation loss: 2.552199805094218

Epoch: 6| Step: 2
Training loss: 0.4903232448317153
Validation loss: 2.5379228137720418

Epoch: 6| Step: 3
Training loss: 0.3682842918403088
Validation loss: 2.520127051992515

Epoch: 6| Step: 4
Training loss: 0.3164939758757989
Validation loss: 2.529345403653827

Epoch: 6| Step: 5
Training loss: 0.38893513413999603
Validation loss: 2.516244982986596

Epoch: 6| Step: 6
Training loss: 0.4501877988904082
Validation loss: 2.537697750613769

Epoch: 6| Step: 7
Training loss: 0.21005392455121608
Validation loss: 2.554670973229429

Epoch: 6| Step: 8
Training loss: 0.2523782381754075
Validation loss: 2.571507046892609

Epoch: 6| Step: 9
Training loss: 0.3079609479065876
Validation loss: 2.568295659485547

Epoch: 6| Step: 10
Training loss: 0.17102727121053157
Validation loss: 2.582302709278864

Epoch: 6| Step: 11
Training loss: 0.33547218388513195
Validation loss: 2.5490307256044766

Epoch: 6| Step: 12
Training loss: 0.46119734342063057
Validation loss: 2.561359635990566

Epoch: 6| Step: 13
Training loss: 0.4624766176344452
Validation loss: 2.5878032223938168

Epoch: 356| Step: 0
Training loss: 0.3074067864599004
Validation loss: 2.5591460397693364

Epoch: 6| Step: 1
Training loss: 0.4672856664704634
Validation loss: 2.5294549208868773

Epoch: 6| Step: 2
Training loss: 0.1827177698909282
Validation loss: 2.5551514001303373

Epoch: 6| Step: 3
Training loss: 0.31596642996587365
Validation loss: 2.4934850064206753

Epoch: 6| Step: 4
Training loss: 0.318887448128068
Validation loss: 2.5222396006161727

Epoch: 6| Step: 5
Training loss: 0.4388060998779965
Validation loss: 2.5012455257654476

Epoch: 6| Step: 6
Training loss: 0.2510628755930835
Validation loss: 2.5128239332581073

Epoch: 6| Step: 7
Training loss: 0.2925617187952452
Validation loss: 2.541626938163592

Epoch: 6| Step: 8
Training loss: 0.3254891863380298
Validation loss: 2.5360067810870337

Epoch: 6| Step: 9
Training loss: 0.45415950938660093
Validation loss: 2.5568595093185555

Epoch: 6| Step: 10
Training loss: 0.1804447079617125
Validation loss: 2.5532871289397985

Epoch: 6| Step: 11
Training loss: 0.413719286916779
Validation loss: 2.5904818624015524

Epoch: 6| Step: 12
Training loss: 0.3727006953704034
Validation loss: 2.5746963789603097

Epoch: 6| Step: 13
Training loss: 0.5725050285484992
Validation loss: 2.5368056416538307

Epoch: 357| Step: 0
Training loss: 0.23800511854341622
Validation loss: 2.5463162912889046

Epoch: 6| Step: 1
Training loss: 0.41509851366483225
Validation loss: 2.566218439227804

Epoch: 6| Step: 2
Training loss: 0.4135280975242391
Validation loss: 2.5103176830821865

Epoch: 6| Step: 3
Training loss: 0.42735412975586284
Validation loss: 2.5251817175489335

Epoch: 6| Step: 4
Training loss: 0.4467048127547694
Validation loss: 2.52664165232436

Epoch: 6| Step: 5
Training loss: 0.34631391759877295
Validation loss: 2.518554357699887

Epoch: 6| Step: 6
Training loss: 0.3601426757107987
Validation loss: 2.560764925867122

Epoch: 6| Step: 7
Training loss: 0.21670889572809413
Validation loss: 2.555849293139325

Epoch: 6| Step: 8
Training loss: 0.38839243902926185
Validation loss: 2.5621407399824108

Epoch: 6| Step: 9
Training loss: 0.2425796886522695
Validation loss: 2.569208283912941

Epoch: 6| Step: 10
Training loss: 0.358091966526881
Validation loss: 2.5493908888361854

Epoch: 6| Step: 11
Training loss: 0.39038841712606726
Validation loss: 2.5095453821266522

Epoch: 6| Step: 12
Training loss: 0.29843090809037925
Validation loss: 2.5200265328751636

Epoch: 6| Step: 13
Training loss: 0.4900447281061048
Validation loss: 2.5214340550497205

Epoch: 358| Step: 0
Training loss: 0.5023205966864115
Validation loss: 2.5249392466108325

Epoch: 6| Step: 1
Training loss: 0.18485073202172417
Validation loss: 2.461595526280413

Epoch: 6| Step: 2
Training loss: 0.17079527329669347
Validation loss: 2.467098222971127

Epoch: 6| Step: 3
Training loss: 0.3004603469951144
Validation loss: 2.5065437772161125

Epoch: 6| Step: 4
Training loss: 0.525191116741837
Validation loss: 2.504917223968905

Epoch: 6| Step: 5
Training loss: 0.35982222303433287
Validation loss: 2.5253488838745803

Epoch: 6| Step: 6
Training loss: 0.38244001600744254
Validation loss: 2.51867318982457

Epoch: 6| Step: 7
Training loss: 0.2703713578989868
Validation loss: 2.513132448356827

Epoch: 6| Step: 8
Training loss: 0.18282655963467198
Validation loss: 2.5094035892408053

Epoch: 6| Step: 9
Training loss: 0.250199000311302
Validation loss: 2.5359099151247526

Epoch: 6| Step: 10
Training loss: 0.4320634867831947
Validation loss: 2.498154101267747

Epoch: 6| Step: 11
Training loss: 0.35289598397980015
Validation loss: 2.53342061801836

Epoch: 6| Step: 12
Training loss: 0.27549632052943207
Validation loss: 2.5210030499525966

Epoch: 6| Step: 13
Training loss: 0.4632039196968178
Validation loss: 2.5114103095439217

Epoch: 359| Step: 0
Training loss: 0.43999490190391854
Validation loss: 2.5022959523481276

Epoch: 6| Step: 1
Training loss: 0.5258335954702765
Validation loss: 2.4936440857915265

Epoch: 6| Step: 2
Training loss: 0.2896531231347497
Validation loss: 2.518183533259007

Epoch: 6| Step: 3
Training loss: 0.25772434230124397
Validation loss: 2.511859306871011

Epoch: 6| Step: 4
Training loss: 0.2770726531104807
Validation loss: 2.5122644878416485

Epoch: 6| Step: 5
Training loss: 0.39303012467209814
Validation loss: 2.5264709157844196

Epoch: 6| Step: 6
Training loss: 0.34893326408333675
Validation loss: 2.517402402666223

Epoch: 6| Step: 7
Training loss: 0.3395486405365206
Validation loss: 2.539938473981362

Epoch: 6| Step: 8
Training loss: 0.34898485846792343
Validation loss: 2.5800034785296924

Epoch: 6| Step: 9
Training loss: 0.17247451996590646
Validation loss: 2.592651499780791

Epoch: 6| Step: 10
Training loss: 0.27173035270570317
Validation loss: 2.5538051085211255

Epoch: 6| Step: 11
Training loss: 0.34346941854283275
Validation loss: 2.57145581308919

Epoch: 6| Step: 12
Training loss: 0.2934226398341246
Validation loss: 2.588904577306856

Epoch: 6| Step: 13
Training loss: 0.3996140182389431
Validation loss: 2.5679874266407787

Epoch: 360| Step: 0
Training loss: 0.4433455444060852
Validation loss: 2.537011724550248

Epoch: 6| Step: 1
Training loss: 0.30092921890320945
Validation loss: 2.5497725297431537

Epoch: 6| Step: 2
Training loss: 0.38318145255146746
Validation loss: 2.5078261931579062

Epoch: 6| Step: 3
Training loss: 0.26735276805086083
Validation loss: 2.5132576742159864

Epoch: 6| Step: 4
Training loss: 0.26970338162440416
Validation loss: 2.490077535317664

Epoch: 6| Step: 5
Training loss: 0.28759424955620405
Validation loss: 2.4876439686139107

Epoch: 6| Step: 6
Training loss: 0.46783370424171444
Validation loss: 2.5176726333476798

Epoch: 6| Step: 7
Training loss: 0.32266667005140587
Validation loss: 2.5186810578207988

Epoch: 6| Step: 8
Training loss: 0.38751343273137834
Validation loss: 2.533771615524363

Epoch: 6| Step: 9
Training loss: 0.27410489786355025
Validation loss: 2.534991779304759

Epoch: 6| Step: 10
Training loss: 0.20273170542934696
Validation loss: 2.560996764444172

Epoch: 6| Step: 11
Training loss: 0.30055609859218496
Validation loss: 2.567765985542345

Epoch: 6| Step: 12
Training loss: 0.39172776012915067
Validation loss: 2.548530399477741

Epoch: 6| Step: 13
Training loss: 0.39755572189384497
Validation loss: 2.585617101593797

Epoch: 361| Step: 0
Training loss: 0.2321153189823462
Validation loss: 2.5815024091635577

Epoch: 6| Step: 1
Training loss: 0.12429920835720508
Validation loss: 2.5497590347057466

Epoch: 6| Step: 2
Training loss: 0.3719083178044178
Validation loss: 2.5337703437060712

Epoch: 6| Step: 3
Training loss: 0.3315116856329225
Validation loss: 2.513019062704493

Epoch: 6| Step: 4
Training loss: 0.4245650569244081
Validation loss: 2.492925283140522

Epoch: 6| Step: 5
Training loss: 0.28988035592941636
Validation loss: 2.4892855928842175

Epoch: 6| Step: 6
Training loss: 0.30641461200965864
Validation loss: 2.4681045116203757

Epoch: 6| Step: 7
Training loss: 0.43311627190673285
Validation loss: 2.5212656392996258

Epoch: 6| Step: 8
Training loss: 0.4879954149947367
Validation loss: 2.5092950486297623

Epoch: 6| Step: 9
Training loss: 0.5383376071256383
Validation loss: 2.500316471660153

Epoch: 6| Step: 10
Training loss: 0.36546098339607563
Validation loss: 2.521753953753411

Epoch: 6| Step: 11
Training loss: 0.2515541140420279
Validation loss: 2.5499146556386063

Epoch: 6| Step: 12
Training loss: 0.25648166605099515
Validation loss: 2.5567888424224683

Epoch: 6| Step: 13
Training loss: 0.32467880699996426
Validation loss: 2.5538311984837274

Epoch: 362| Step: 0
Training loss: 0.3653792843497328
Validation loss: 2.533666442494273

Epoch: 6| Step: 1
Training loss: 0.2926562868231299
Validation loss: 2.503185682063184

Epoch: 6| Step: 2
Training loss: 0.19529188047285714
Validation loss: 2.5288399962212917

Epoch: 6| Step: 3
Training loss: 0.312185307839671
Validation loss: 2.4887117691578338

Epoch: 6| Step: 4
Training loss: 0.27693799385090473
Validation loss: 2.4774069924373507

Epoch: 6| Step: 5
Training loss: 0.4050062654740568
Validation loss: 2.490251411767373

Epoch: 6| Step: 6
Training loss: 0.32047191002681313
Validation loss: 2.484359385154412

Epoch: 6| Step: 7
Training loss: 0.3654270581834357
Validation loss: 2.491807678577949

Epoch: 6| Step: 8
Training loss: 0.43587016607677626
Validation loss: 2.5309918939339076

Epoch: 6| Step: 9
Training loss: 0.3775217382854085
Validation loss: 2.5361377717074194

Epoch: 6| Step: 10
Training loss: 0.40588270603121485
Validation loss: 2.518788959870874

Epoch: 6| Step: 11
Training loss: 0.43972651137078644
Validation loss: 2.5263266325399543

Epoch: 6| Step: 12
Training loss: 0.291405461491804
Validation loss: 2.5124869769371125

Epoch: 6| Step: 13
Training loss: 0.1484686417287192
Validation loss: 2.504707901632009

Epoch: 363| Step: 0
Training loss: 0.41678490947790914
Validation loss: 2.499014795665862

Epoch: 6| Step: 1
Training loss: 0.27293592499107544
Validation loss: 2.536346441838469

Epoch: 6| Step: 2
Training loss: 0.21962087844689626
Validation loss: 2.529269281191594

Epoch: 6| Step: 3
Training loss: 0.36023677248499264
Validation loss: 2.534765081670266

Epoch: 6| Step: 4
Training loss: 0.2999314155263531
Validation loss: 2.5222387712218906

Epoch: 6| Step: 5
Training loss: 0.2593262620888756
Validation loss: 2.5302535657815994

Epoch: 6| Step: 6
Training loss: 0.3852391113225272
Validation loss: 2.502956636553332

Epoch: 6| Step: 7
Training loss: 0.2445136234524029
Validation loss: 2.511073814887327

Epoch: 6| Step: 8
Training loss: 0.44077669670730846
Validation loss: 2.4896324490283677

Epoch: 6| Step: 9
Training loss: 0.4651735722472181
Validation loss: 2.5226641730112775

Epoch: 6| Step: 10
Training loss: 0.10166364914814396
Validation loss: 2.485052300085611

Epoch: 6| Step: 11
Training loss: 0.17695704449487498
Validation loss: 2.534080718250872

Epoch: 6| Step: 12
Training loss: 0.3614174397373588
Validation loss: 2.5321438303909485

Epoch: 6| Step: 13
Training loss: 0.3906063456849522
Validation loss: 2.487116892773844

Epoch: 364| Step: 0
Training loss: 0.2510085623561144
Validation loss: 2.5285853361400323

Epoch: 6| Step: 1
Training loss: 0.2524055440726828
Validation loss: 2.5192441033422504

Epoch: 6| Step: 2
Training loss: 0.304308716980616
Validation loss: 2.5039668677129083

Epoch: 6| Step: 3
Training loss: 0.31261049939615604
Validation loss: 2.505824131411238

Epoch: 6| Step: 4
Training loss: 0.37010210957677064
Validation loss: 2.5431383015702336

Epoch: 6| Step: 5
Training loss: 0.505970121654993
Validation loss: 2.5239585217430323

Epoch: 6| Step: 6
Training loss: 0.34159703543418524
Validation loss: 2.5499857683968927

Epoch: 6| Step: 7
Training loss: 0.1245202117716078
Validation loss: 2.5347267154959634

Epoch: 6| Step: 8
Training loss: 0.340614354990939
Validation loss: 2.542373883282982

Epoch: 6| Step: 9
Training loss: 0.25372947995129214
Validation loss: 2.5482955253577444

Epoch: 6| Step: 10
Training loss: 0.34222387616927935
Validation loss: 2.579813183058043

Epoch: 6| Step: 11
Training loss: 0.3545326651170446
Validation loss: 2.5363882021054374

Epoch: 6| Step: 12
Training loss: 0.23040414971631304
Validation loss: 2.5889446332540764

Epoch: 6| Step: 13
Training loss: 0.49155823278302846
Validation loss: 2.573879188612983

Epoch: 365| Step: 0
Training loss: 0.2307959109500489
Validation loss: 2.5454141360479223

Epoch: 6| Step: 1
Training loss: 0.2166161256233692
Validation loss: 2.5115747617355977

Epoch: 6| Step: 2
Training loss: 0.32022110868039283
Validation loss: 2.5070517912624357

Epoch: 6| Step: 3
Training loss: 0.31919114449554625
Validation loss: 2.4579120968229917

Epoch: 6| Step: 4
Training loss: 0.335172136192581
Validation loss: 2.4806833905729713

Epoch: 6| Step: 5
Training loss: 0.5164904988828437
Validation loss: 2.4776033570695764

Epoch: 6| Step: 6
Training loss: 0.36608677094238745
Validation loss: 2.5021308370298043

Epoch: 6| Step: 7
Training loss: 0.18420400044392313
Validation loss: 2.516768934060883

Epoch: 6| Step: 8
Training loss: 0.45541109338487185
Validation loss: 2.6070706530256595

Epoch: 6| Step: 9
Training loss: 0.3542683002090109
Validation loss: 2.5550195917719245

Epoch: 6| Step: 10
Training loss: 0.308544613753073
Validation loss: 2.5789324020996847

Epoch: 6| Step: 11
Training loss: 0.3618288436996505
Validation loss: 2.5492901680107214

Epoch: 6| Step: 12
Training loss: 0.27467100664601873
Validation loss: 2.5466900105360257

Epoch: 6| Step: 13
Training loss: 0.47924635231468593
Validation loss: 2.5229648320243396

Epoch: 366| Step: 0
Training loss: 0.24083331120192833
Validation loss: 2.5368484746518414

Epoch: 6| Step: 1
Training loss: 0.4684159200989608
Validation loss: 2.50411633755965

Epoch: 6| Step: 2
Training loss: 0.19584947204204606
Validation loss: 2.4792085528400727

Epoch: 6| Step: 3
Training loss: 0.27825287118923026
Validation loss: 2.4622412875748796

Epoch: 6| Step: 4
Training loss: 0.434314060739218
Validation loss: 2.5064896347959342

Epoch: 6| Step: 5
Training loss: 0.345743942006316
Validation loss: 2.4821969539025845

Epoch: 6| Step: 6
Training loss: 0.230858723402314
Validation loss: 2.51977507611861

Epoch: 6| Step: 7
Training loss: 0.4876292033030225
Validation loss: 2.529917636868078

Epoch: 6| Step: 8
Training loss: 0.416604695082564
Validation loss: 2.575585563383173

Epoch: 6| Step: 9
Training loss: 0.29462355879753616
Validation loss: 2.565780520663285

Epoch: 6| Step: 10
Training loss: 0.1278726217523248
Validation loss: 2.547777462055713

Epoch: 6| Step: 11
Training loss: 0.248845279766987
Validation loss: 2.5309067542403048

Epoch: 6| Step: 12
Training loss: 0.41866889139640245
Validation loss: 2.5264538601920163

Epoch: 6| Step: 13
Training loss: 0.13696149665544738
Validation loss: 2.547232503062814

Epoch: 367| Step: 0
Training loss: 0.20970324293752482
Validation loss: 2.579505454870609

Epoch: 6| Step: 1
Training loss: 0.24784337354137712
Validation loss: 2.553510816564741

Epoch: 6| Step: 2
Training loss: 0.1723564622086688
Validation loss: 2.523841706926958

Epoch: 6| Step: 3
Training loss: 0.27984357560161394
Validation loss: 2.528589353064431

Epoch: 6| Step: 4
Training loss: 0.4214866758324415
Validation loss: 2.5718211079737032

Epoch: 6| Step: 5
Training loss: 0.28614674296660947
Validation loss: 2.5421646399599966

Epoch: 6| Step: 6
Training loss: 0.2092629830492639
Validation loss: 2.5516698834288785

Epoch: 6| Step: 7
Training loss: 0.364150903471193
Validation loss: 2.544187000892938

Epoch: 6| Step: 8
Training loss: 0.25578877880129286
Validation loss: 2.562460109941453

Epoch: 6| Step: 9
Training loss: 0.23142979565848307
Validation loss: 2.513994112586619

Epoch: 6| Step: 10
Training loss: 0.5020826892400174
Validation loss: 2.5287287998529884

Epoch: 6| Step: 11
Training loss: 0.48491152919956987
Validation loss: 2.509974704283716

Epoch: 6| Step: 12
Training loss: 0.3420585720395028
Validation loss: 2.518012437776179

Epoch: 6| Step: 13
Training loss: 0.29953189330412505
Validation loss: 2.5161374237136487

Epoch: 368| Step: 0
Training loss: 0.3687269728954705
Validation loss: 2.541908505488515

Epoch: 6| Step: 1
Training loss: 0.21910963978384493
Validation loss: 2.541061302714613

Epoch: 6| Step: 2
Training loss: 0.19899836673377833
Validation loss: 2.5527247138813878

Epoch: 6| Step: 3
Training loss: 0.36806598034776117
Validation loss: 2.5586356110676025

Epoch: 6| Step: 4
Training loss: 0.4335391035955881
Validation loss: 2.54377849952213

Epoch: 6| Step: 5
Training loss: 0.40146995769445876
Validation loss: 2.5581409646435898

Epoch: 6| Step: 6
Training loss: 0.19108786669803443
Validation loss: 2.546114651737117

Epoch: 6| Step: 7
Training loss: 0.35606907885036204
Validation loss: 2.520955424418791

Epoch: 6| Step: 8
Training loss: 0.4009500456680936
Validation loss: 2.512882596412954

Epoch: 6| Step: 9
Training loss: 0.17734117296001758
Validation loss: 2.5460969879199578

Epoch: 6| Step: 10
Training loss: 0.3073199334586763
Validation loss: 2.509210089201219

Epoch: 6| Step: 11
Training loss: 0.3171423015430823
Validation loss: 2.545871359961372

Epoch: 6| Step: 12
Training loss: 0.09199354733638442
Validation loss: 2.5301837133708163

Epoch: 6| Step: 13
Training loss: 0.2461755102065335
Validation loss: 2.5003755187447365

Epoch: 369| Step: 0
Training loss: 0.3791099472730215
Validation loss: 2.5244177489034514

Epoch: 6| Step: 1
Training loss: 0.177446278582343
Validation loss: 2.5236801401113302

Epoch: 6| Step: 2
Training loss: 0.19383044610868957
Validation loss: 2.524825430892521

Epoch: 6| Step: 3
Training loss: 0.24845819836889585
Validation loss: 2.529567315688766

Epoch: 6| Step: 4
Training loss: 0.13838024771396182
Validation loss: 2.539161529502972

Epoch: 6| Step: 5
Training loss: 0.34703370407315404
Validation loss: 2.5454384578512217

Epoch: 6| Step: 6
Training loss: 0.3063428611489538
Validation loss: 2.541505985705001

Epoch: 6| Step: 7
Training loss: 0.14072899152272825
Validation loss: 2.5876563136897675

Epoch: 6| Step: 8
Training loss: 0.4821311445302083
Validation loss: 2.564007084060131

Epoch: 6| Step: 9
Training loss: 0.41186791166420134
Validation loss: 2.5432685720793913

Epoch: 6| Step: 10
Training loss: 0.48947464636077725
Validation loss: 2.543144094894939

Epoch: 6| Step: 11
Training loss: 0.16410417822097279
Validation loss: 2.5176152543571586

Epoch: 6| Step: 12
Training loss: 0.25308953024929315
Validation loss: 2.539354490745251

Epoch: 6| Step: 13
Training loss: 0.28996229600800116
Validation loss: 2.532553171866776

Epoch: 370| Step: 0
Training loss: 0.49374535172121453
Validation loss: 2.5255445885423495

Epoch: 6| Step: 1
Training loss: 0.21412861318206508
Validation loss: 2.52144404652523

Epoch: 6| Step: 2
Training loss: 0.35742533530973125
Validation loss: 2.5295346599537623

Epoch: 6| Step: 3
Training loss: 0.2464078231161406
Validation loss: 2.5097375901941454

Epoch: 6| Step: 4
Training loss: 0.3508548608360825
Validation loss: 2.4916090462239717

Epoch: 6| Step: 5
Training loss: 0.17996054097639697
Validation loss: 2.4975188361236933

Epoch: 6| Step: 6
Training loss: 0.26331220043064824
Validation loss: 2.5144194451371944

Epoch: 6| Step: 7
Training loss: 0.23625647822333445
Validation loss: 2.5235962647147767

Epoch: 6| Step: 8
Training loss: 0.24312377504025454
Validation loss: 2.4876891588364054

Epoch: 6| Step: 9
Training loss: 0.3665242800092563
Validation loss: 2.4940398140441657

Epoch: 6| Step: 10
Training loss: 0.2607201984863208
Validation loss: 2.5342095363443766

Epoch: 6| Step: 11
Training loss: 0.3340236127681404
Validation loss: 2.5407815949219654

Epoch: 6| Step: 12
Training loss: 0.41783487546775927
Validation loss: 2.5369826544298286

Epoch: 6| Step: 13
Training loss: 0.3483580781031762
Validation loss: 2.5638190950388946

Epoch: 371| Step: 0
Training loss: 0.19552138602500954
Validation loss: 2.558710191587154

Epoch: 6| Step: 1
Training loss: 0.26497480812530094
Validation loss: 2.5287427011237664

Epoch: 6| Step: 2
Training loss: 0.3299077288272975
Validation loss: 2.5243039655289463

Epoch: 6| Step: 3
Training loss: 0.4455037291999003
Validation loss: 2.5429650451230925

Epoch: 6| Step: 4
Training loss: 0.12255637482234029
Validation loss: 2.525221875673767

Epoch: 6| Step: 5
Training loss: 0.4405584717976464
Validation loss: 2.5011548441081737

Epoch: 6| Step: 6
Training loss: 0.37063988486854876
Validation loss: 2.5191443102056343

Epoch: 6| Step: 7
Training loss: 0.13961189965781542
Validation loss: 2.5035959080598595

Epoch: 6| Step: 8
Training loss: 0.5218356660193556
Validation loss: 2.47946469339122

Epoch: 6| Step: 9
Training loss: 0.17129467397130163
Validation loss: 2.4634922843610525

Epoch: 6| Step: 10
Training loss: 0.3217777257983613
Validation loss: 2.508082328834425

Epoch: 6| Step: 11
Training loss: 0.3011900241989052
Validation loss: 2.5180647940898777

Epoch: 6| Step: 12
Training loss: 0.3144182339852568
Validation loss: 2.4691389293344166

Epoch: 6| Step: 13
Training loss: 0.2033792518401042
Validation loss: 2.488604668637735

Epoch: 372| Step: 0
Training loss: 0.18731542284037175
Validation loss: 2.514874743305881

Epoch: 6| Step: 1
Training loss: 0.276738244591858
Validation loss: 2.524838755602766

Epoch: 6| Step: 2
Training loss: 0.30244364160260384
Validation loss: 2.5648885380297792

Epoch: 6| Step: 3
Training loss: 0.36745254609210426
Validation loss: 2.5243108278151314

Epoch: 6| Step: 4
Training loss: 0.2304359509680105
Validation loss: 2.5593629188297036

Epoch: 6| Step: 5
Training loss: 0.2749661088780439
Validation loss: 2.5583962385626133

Epoch: 6| Step: 6
Training loss: 0.18693948451270254
Validation loss: 2.55681602593119

Epoch: 6| Step: 7
Training loss: 0.32829650302404917
Validation loss: 2.5142304495068952

Epoch: 6| Step: 8
Training loss: 0.48737213952241865
Validation loss: 2.555258914900074

Epoch: 6| Step: 9
Training loss: 0.35044898543323244
Validation loss: 2.5355912743576994

Epoch: 6| Step: 10
Training loss: 0.25106573932562626
Validation loss: 2.5310547233152403

Epoch: 6| Step: 11
Training loss: 0.4172466493315467
Validation loss: 2.4973159184092273

Epoch: 6| Step: 12
Training loss: 0.3580853084385156
Validation loss: 2.542402654796422

Epoch: 6| Step: 13
Training loss: 0.1891588599968543
Validation loss: 2.542413261644846

Epoch: 373| Step: 0
Training loss: 0.29540385089797144
Validation loss: 2.5463503451891674

Epoch: 6| Step: 1
Training loss: 0.2510682320817662
Validation loss: 2.533634438350727

Epoch: 6| Step: 2
Training loss: 0.21081666664418883
Validation loss: 2.540891744720849

Epoch: 6| Step: 3
Training loss: 0.20701464100558573
Validation loss: 2.547521155280379

Epoch: 6| Step: 4
Training loss: 0.35700071776074827
Validation loss: 2.5759706307957773

Epoch: 6| Step: 5
Training loss: 0.2887125732474633
Validation loss: 2.5689572049046907

Epoch: 6| Step: 6
Training loss: 0.5046495382009207
Validation loss: 2.5392498664729075

Epoch: 6| Step: 7
Training loss: 0.26305611376942056
Validation loss: 2.544282686194555

Epoch: 6| Step: 8
Training loss: 0.1938984513693344
Validation loss: 2.5170886999810977

Epoch: 6| Step: 9
Training loss: 0.2747574419240761
Validation loss: 2.531750308389435

Epoch: 6| Step: 10
Training loss: 0.48161755434642595
Validation loss: 2.5429343347621414

Epoch: 6| Step: 11
Training loss: 0.23054282565876671
Validation loss: 2.524995170238566

Epoch: 6| Step: 12
Training loss: 0.37073417107481665
Validation loss: 2.535119833116559

Epoch: 6| Step: 13
Training loss: 0.3217107677905316
Validation loss: 2.509393385855024

Epoch: 374| Step: 0
Training loss: 0.3053840597856675
Validation loss: 2.518855099144497

Epoch: 6| Step: 1
Training loss: 0.23386378165843044
Validation loss: 2.5197578467550934

Epoch: 6| Step: 2
Training loss: 0.3982406578764227
Validation loss: 2.5351763545510657

Epoch: 6| Step: 3
Training loss: 0.18385884240304212
Validation loss: 2.537590376790607

Epoch: 6| Step: 4
Training loss: 0.2672208503075827
Validation loss: 2.5345304463692835

Epoch: 6| Step: 5
Training loss: 0.41255362913444665
Validation loss: 2.5096425761709047

Epoch: 6| Step: 6
Training loss: 0.22430255500035123
Validation loss: 2.51878305149523

Epoch: 6| Step: 7
Training loss: 0.3146595721462025
Validation loss: 2.53967541890738

Epoch: 6| Step: 8
Training loss: 0.25626826919001844
Validation loss: 2.515352830970361

Epoch: 6| Step: 9
Training loss: 0.3529966032328099
Validation loss: 2.553763271670722

Epoch: 6| Step: 10
Training loss: 0.37208038476642136
Validation loss: 2.5532934524701782

Epoch: 6| Step: 11
Training loss: 0.18516158204911812
Validation loss: 2.4877866791589467

Epoch: 6| Step: 12
Training loss: 0.2140395632519131
Validation loss: 2.5290339766069723

Epoch: 6| Step: 13
Training loss: 0.4025365312062671
Validation loss: 2.5527380205061494

Epoch: 375| Step: 0
Training loss: 0.20253977467366654
Validation loss: 2.616785253188078

Epoch: 6| Step: 1
Training loss: 0.3707142344861162
Validation loss: 2.574362309623582

Epoch: 6| Step: 2
Training loss: 0.443359257366148
Validation loss: 2.5473512143551202

Epoch: 6| Step: 3
Training loss: 0.24942028363504068
Validation loss: 2.523510556636728

Epoch: 6| Step: 4
Training loss: 0.1946017015185513
Validation loss: 2.519297366182425

Epoch: 6| Step: 5
Training loss: 0.22209575443589782
Validation loss: 2.5618030681842336

Epoch: 6| Step: 6
Training loss: 0.23732790421308556
Validation loss: 2.546868623289813

Epoch: 6| Step: 7
Training loss: 0.20885863933546397
Validation loss: 2.5331319165698765

Epoch: 6| Step: 8
Training loss: 0.25610201737917476
Validation loss: 2.512059063851344

Epoch: 6| Step: 9
Training loss: 0.5085539173753584
Validation loss: 2.5232365538778767

Epoch: 6| Step: 10
Training loss: 0.22974271694465714
Validation loss: 2.5404229620395262

Epoch: 6| Step: 11
Training loss: 0.27032425915492997
Validation loss: 2.5550310848953854

Epoch: 6| Step: 12
Training loss: 0.2893785604583334
Validation loss: 2.541819001192992

Epoch: 6| Step: 13
Training loss: 0.32116954400829634
Validation loss: 2.5442518743503744

Epoch: 376| Step: 0
Training loss: 0.25343518207868254
Validation loss: 2.5465439415762776

Epoch: 6| Step: 1
Training loss: 0.33286200544711714
Validation loss: 2.579968636676583

Epoch: 6| Step: 2
Training loss: 0.17833637110924436
Validation loss: 2.5530546043219102

Epoch: 6| Step: 3
Training loss: 0.16905632120571168
Validation loss: 2.5522121049556454

Epoch: 6| Step: 4
Training loss: 0.17870106695880766
Validation loss: 2.5845455925357146

Epoch: 6| Step: 5
Training loss: 0.3876956007641698
Validation loss: 2.5815321160135105

Epoch: 6| Step: 6
Training loss: 0.3990741953259964
Validation loss: 2.5414381480928454

Epoch: 6| Step: 7
Training loss: 0.341917637880734
Validation loss: 2.5624071339993146

Epoch: 6| Step: 8
Training loss: 0.3089263186305694
Validation loss: 2.5481152595078043

Epoch: 6| Step: 9
Training loss: 0.27108060876397866
Validation loss: 2.5122119820721784

Epoch: 6| Step: 10
Training loss: 0.39730398842451253
Validation loss: 2.538533810836546

Epoch: 6| Step: 11
Training loss: 0.2789099888056776
Validation loss: 2.50014666773121

Epoch: 6| Step: 12
Training loss: 0.1768015812590062
Validation loss: 2.4984450000847196

Epoch: 6| Step: 13
Training loss: 0.27895412888942156
Validation loss: 2.537346652113574

Epoch: 377| Step: 0
Training loss: 0.18740408152638766
Validation loss: 2.530730609076948

Epoch: 6| Step: 1
Training loss: 0.19583242831291586
Validation loss: 2.55905574387164

Epoch: 6| Step: 2
Training loss: 0.2930598435243892
Validation loss: 2.509817560909132

Epoch: 6| Step: 3
Training loss: 0.19884690006847835
Validation loss: 2.5643904630935044

Epoch: 6| Step: 4
Training loss: 0.24654172057958748
Validation loss: 2.546016161530185

Epoch: 6| Step: 5
Training loss: 0.2803559264967151
Validation loss: 2.575946446995261

Epoch: 6| Step: 6
Training loss: 0.18724858793342503
Validation loss: 2.5363077556683247

Epoch: 6| Step: 7
Training loss: 0.4282349744567005
Validation loss: 2.5681590998116337

Epoch: 6| Step: 8
Training loss: 0.2953622448112854
Validation loss: 2.5264089158600367

Epoch: 6| Step: 9
Training loss: 0.3468242290216309
Validation loss: 2.5613732330524948

Epoch: 6| Step: 10
Training loss: 0.4317154452694112
Validation loss: 2.5461939415651806

Epoch: 6| Step: 11
Training loss: 0.36253458630881474
Validation loss: 2.5439939345809703

Epoch: 6| Step: 12
Training loss: 0.30503099592800326
Validation loss: 2.5357969451473754

Epoch: 6| Step: 13
Training loss: 0.24119125316780898
Validation loss: 2.5368496175962996

Epoch: 378| Step: 0
Training loss: 0.35872225983131617
Validation loss: 2.5389124450012064

Epoch: 6| Step: 1
Training loss: 0.32602727277303006
Validation loss: 2.555115318395425

Epoch: 6| Step: 2
Training loss: 0.33259381152188916
Validation loss: 2.529204208419219

Epoch: 6| Step: 3
Training loss: 0.1377672048337313
Validation loss: 2.558651652835937

Epoch: 6| Step: 4
Training loss: 0.3641381156555023
Validation loss: 2.5091705902658856

Epoch: 6| Step: 5
Training loss: 0.33988833957041065
Validation loss: 2.5383599926686453

Epoch: 6| Step: 6
Training loss: 0.16335583812984103
Validation loss: 2.5276263536205716

Epoch: 6| Step: 7
Training loss: 0.3388783345876296
Validation loss: 2.520461066073023

Epoch: 6| Step: 8
Training loss: 0.20288175910906278
Validation loss: 2.5653481131293265

Epoch: 6| Step: 9
Training loss: 0.4532370264413256
Validation loss: 2.541979698003069

Epoch: 6| Step: 10
Training loss: 0.3880449923305872
Validation loss: 2.536709563148487

Epoch: 6| Step: 11
Training loss: 0.18301348601089246
Validation loss: 2.538748035883046

Epoch: 6| Step: 12
Training loss: 0.2537779410486727
Validation loss: 2.56453199479075

Epoch: 6| Step: 13
Training loss: 0.15320263130618106
Validation loss: 2.5354672415366295

Epoch: 379| Step: 0
Training loss: 0.22159669809904736
Validation loss: 2.5365821100844776

Epoch: 6| Step: 1
Training loss: 0.36157142077546256
Validation loss: 2.5362102542793834

Epoch: 6| Step: 2
Training loss: 0.19084414837903235
Validation loss: 2.510690596445286

Epoch: 6| Step: 3
Training loss: 0.3437336679393516
Validation loss: 2.5668076103506396

Epoch: 6| Step: 4
Training loss: 0.4084564591015559
Validation loss: 2.5406187850362927

Epoch: 6| Step: 5
Training loss: 0.2860500619637526
Validation loss: 2.543534217275474

Epoch: 6| Step: 6
Training loss: 0.23501275237210748
Validation loss: 2.566089683461593

Epoch: 6| Step: 7
Training loss: 0.2333601118088269
Validation loss: 2.551428601423995

Epoch: 6| Step: 8
Training loss: 0.13232651317901678
Validation loss: 2.5514353093688595

Epoch: 6| Step: 9
Training loss: 0.3789349771208336
Validation loss: 2.5464443675923674

Epoch: 6| Step: 10
Training loss: 0.28766447369425496
Validation loss: 2.5584112101460157

Epoch: 6| Step: 11
Training loss: 0.31933997382083323
Validation loss: 2.520800834804932

Epoch: 6| Step: 12
Training loss: 0.42978251013692065
Validation loss: 2.524371182022043

Epoch: 6| Step: 13
Training loss: 0.316303448401138
Validation loss: 2.5199535573354135

Epoch: 380| Step: 0
Training loss: 0.3271879030022967
Validation loss: 2.5287448980285134

Epoch: 6| Step: 1
Training loss: 0.28403311813534216
Validation loss: 2.5187222132494504

Epoch: 6| Step: 2
Training loss: 0.3085242205166473
Validation loss: 2.548808492489753

Epoch: 6| Step: 3
Training loss: 0.3234485532189582
Validation loss: 2.5415753940417756

Epoch: 6| Step: 4
Training loss: 0.33372940682160585
Validation loss: 2.5296063501988413

Epoch: 6| Step: 5
Training loss: 0.3158511602638882
Validation loss: 2.559070670523456

Epoch: 6| Step: 6
Training loss: 0.10094348542799533
Validation loss: 2.5625554920893987

Epoch: 6| Step: 7
Training loss: 0.1698175142707607
Validation loss: 2.5514889059785713

Epoch: 6| Step: 8
Training loss: 0.1804874071988194
Validation loss: 2.528582750786527

Epoch: 6| Step: 9
Training loss: 0.43138562087848814
Validation loss: 2.5507440299064394

Epoch: 6| Step: 10
Training loss: 0.23746718819987278
Validation loss: 2.5347057954648595

Epoch: 6| Step: 11
Training loss: 0.34060689589309007
Validation loss: 2.5451805768929683

Epoch: 6| Step: 12
Training loss: 0.4023819136806263
Validation loss: 2.570399182443823

Epoch: 6| Step: 13
Training loss: 0.25695077337741357
Validation loss: 2.554484157793114

Epoch: 381| Step: 0
Training loss: 0.43484721416446426
Validation loss: 2.585918515048359

Epoch: 6| Step: 1
Training loss: 0.29502131825536915
Validation loss: 2.5473409553989925

Epoch: 6| Step: 2
Training loss: 0.3161610371339504
Validation loss: 2.557341441787064

Epoch: 6| Step: 3
Training loss: 0.18485259616157004
Validation loss: 2.5791984906089414

Epoch: 6| Step: 4
Training loss: 0.2835993658513349
Validation loss: 2.5279151057783675

Epoch: 6| Step: 5
Training loss: 0.39002028388069626
Validation loss: 2.532434882728752

Epoch: 6| Step: 6
Training loss: 0.16526461881345883
Validation loss: 2.525904409275781

Epoch: 6| Step: 7
Training loss: 0.3425385085788859
Validation loss: 2.5394311710138973

Epoch: 6| Step: 8
Training loss: 0.24921770185292025
Validation loss: 2.525677471761051

Epoch: 6| Step: 9
Training loss: 0.19536124574811592
Validation loss: 2.5519905828548506

Epoch: 6| Step: 10
Training loss: 0.3376842485935351
Validation loss: 2.5765211628638878

Epoch: 6| Step: 11
Training loss: 0.2721785308901788
Validation loss: 2.575165604227092

Epoch: 6| Step: 12
Training loss: 0.27437298015815553
Validation loss: 2.574384914983639

Epoch: 6| Step: 13
Training loss: 0.20201077588357477
Validation loss: 2.572641854624136

Epoch: 382| Step: 0
Training loss: 0.3158787698615116
Validation loss: 2.5483921277679444

Epoch: 6| Step: 1
Training loss: 0.3822778354536874
Validation loss: 2.5294753294503884

Epoch: 6| Step: 2
Training loss: 0.3077057241760947
Validation loss: 2.5237782164911833

Epoch: 6| Step: 3
Training loss: 0.38483060491417154
Validation loss: 2.4935110068056203

Epoch: 6| Step: 4
Training loss: 0.14055218400835917
Validation loss: 2.524822695475043

Epoch: 6| Step: 5
Training loss: 0.2182956216923736
Validation loss: 2.5117273465939864

Epoch: 6| Step: 6
Training loss: 0.43451589179306016
Validation loss: 2.555619524536634

Epoch: 6| Step: 7
Training loss: 0.25030461766837236
Validation loss: 2.528489261613828

Epoch: 6| Step: 8
Training loss: 0.11735230619117308
Validation loss: 2.5201151804653796

Epoch: 6| Step: 9
Training loss: 0.3738529025708618
Validation loss: 2.581762209877683

Epoch: 6| Step: 10
Training loss: 0.261866968801069
Validation loss: 2.5738824376351253

Epoch: 6| Step: 11
Training loss: 0.27921824915776433
Validation loss: 2.5677931486881476

Epoch: 6| Step: 12
Training loss: 0.2811111266282127
Validation loss: 2.5718732101882162

Epoch: 6| Step: 13
Training loss: 0.42333855898265077
Validation loss: 2.5285153877088096

Epoch: 383| Step: 0
Training loss: 0.3269961329969352
Validation loss: 2.485814278266974

Epoch: 6| Step: 1
Training loss: 0.4880428037172877
Validation loss: 2.4907395831481858

Epoch: 6| Step: 2
Training loss: 0.23184478665747532
Validation loss: 2.49756615001396

Epoch: 6| Step: 3
Training loss: 0.22747895261322001
Validation loss: 2.4758306573393516

Epoch: 6| Step: 4
Training loss: 0.21083533497345194
Validation loss: 2.465847187835948

Epoch: 6| Step: 5
Training loss: 0.27012288769536447
Validation loss: 2.5052029305161607

Epoch: 6| Step: 6
Training loss: 0.4442086173615053
Validation loss: 2.5172419731133857

Epoch: 6| Step: 7
Training loss: 0.25752424250992084
Validation loss: 2.530101192854515

Epoch: 6| Step: 8
Training loss: 0.3030075809329851
Validation loss: 2.51085934833256

Epoch: 6| Step: 9
Training loss: 0.35425578660350987
Validation loss: 2.485964222862211

Epoch: 6| Step: 10
Training loss: 0.24708863141446416
Validation loss: 2.52839372488121

Epoch: 6| Step: 11
Training loss: 0.20371876643965342
Validation loss: 2.533863352714542

Epoch: 6| Step: 12
Training loss: 0.23409552600906441
Validation loss: 2.5553950945169843

Epoch: 6| Step: 13
Training loss: 0.436516490770063
Validation loss: 2.5735955337684517

Epoch: 384| Step: 0
Training loss: 0.38381942357147075
Validation loss: 2.59560425462803

Epoch: 6| Step: 1
Training loss: 0.2526717767326622
Validation loss: 2.586887065444464

Epoch: 6| Step: 2
Training loss: 0.3564462322066474
Validation loss: 2.545859993149776

Epoch: 6| Step: 3
Training loss: 0.39870245856404196
Validation loss: 2.5615314561096767

Epoch: 6| Step: 4
Training loss: 0.3100534273453059
Validation loss: 2.532795104193991

Epoch: 6| Step: 5
Training loss: 0.22787746756321978
Validation loss: 2.5221696418760398

Epoch: 6| Step: 6
Training loss: 0.23218923032842362
Validation loss: 2.527609616440342

Epoch: 6| Step: 7
Training loss: 0.280303342067856
Validation loss: 2.4993011636121225

Epoch: 6| Step: 8
Training loss: 0.4622822235928548
Validation loss: 2.502190960885083

Epoch: 6| Step: 9
Training loss: 0.3213002629052543
Validation loss: 2.536934377973222

Epoch: 6| Step: 10
Training loss: 0.2127339547804914
Validation loss: 2.544797489767282

Epoch: 6| Step: 11
Training loss: 0.3334755172078593
Validation loss: 2.549844915293459

Epoch: 6| Step: 12
Training loss: 0.24223727822189536
Validation loss: 2.6045155766871693

Epoch: 6| Step: 13
Training loss: 0.28585604148353544
Validation loss: 2.622541415974559

Epoch: 385| Step: 0
Training loss: 0.3543547056331091
Validation loss: 2.5887924864792624

Epoch: 6| Step: 1
Training loss: 0.2246936639940361
Validation loss: 2.5589020223427172

Epoch: 6| Step: 2
Training loss: 0.28463498901074463
Validation loss: 2.5753307213677386

Epoch: 6| Step: 3
Training loss: 0.45293504745516333
Validation loss: 2.534666251846048

Epoch: 6| Step: 4
Training loss: 0.31031651620100253
Validation loss: 2.53830296769823

Epoch: 6| Step: 5
Training loss: 0.25401867064992945
Validation loss: 2.5371016025507047

Epoch: 6| Step: 6
Training loss: 0.293385400138343
Validation loss: 2.5348307932198213

Epoch: 6| Step: 7
Training loss: 0.2578290298249072
Validation loss: 2.5051572262895268

Epoch: 6| Step: 8
Training loss: 0.4347677232498029
Validation loss: 2.5176434173158064

Epoch: 6| Step: 9
Training loss: 0.29515612059510093
Validation loss: 2.551175321902357

Epoch: 6| Step: 10
Training loss: 0.2700233252260513
Validation loss: 2.555588761601083

Epoch: 6| Step: 11
Training loss: 0.20651935776111183
Validation loss: 2.55442325052896

Epoch: 6| Step: 12
Training loss: 0.320143980961259
Validation loss: 2.562224506622779

Epoch: 6| Step: 13
Training loss: 0.40708091930674495
Validation loss: 2.5909483280845866

Epoch: 386| Step: 0
Training loss: 0.2962469811627737
Validation loss: 2.598802688169405

Epoch: 6| Step: 1
Training loss: 0.33942351173666885
Validation loss: 2.599495745738501

Epoch: 6| Step: 2
Training loss: 0.45174767548385786
Validation loss: 2.603344459600775

Epoch: 6| Step: 3
Training loss: 0.43091643328277063
Validation loss: 2.5493646951070787

Epoch: 6| Step: 4
Training loss: 0.2665822507689821
Validation loss: 2.5292126847647896

Epoch: 6| Step: 5
Training loss: 0.26813049106265974
Validation loss: 2.522325406892594

Epoch: 6| Step: 6
Training loss: 0.3296921973775172
Validation loss: 2.5058006262022694

Epoch: 6| Step: 7
Training loss: 0.24140422042437948
Validation loss: 2.478730480207069

Epoch: 6| Step: 8
Training loss: 0.19358348382018084
Validation loss: 2.4820703667608806

Epoch: 6| Step: 9
Training loss: 0.3018932100494037
Validation loss: 2.5485114336218095

Epoch: 6| Step: 10
Training loss: 0.423068231129892
Validation loss: 2.582819300692852

Epoch: 6| Step: 11
Training loss: 0.2066599016626944
Validation loss: 2.5679371294290156

Epoch: 6| Step: 12
Training loss: 0.3000983499208
Validation loss: 2.602518535870831

Epoch: 6| Step: 13
Training loss: 0.3314872773578575
Validation loss: 2.6224600764948027

Epoch: 387| Step: 0
Training loss: 0.3600968698798288
Validation loss: 2.5749775437641147

Epoch: 6| Step: 1
Training loss: 0.3214996598458456
Validation loss: 2.563171313791338

Epoch: 6| Step: 2
Training loss: 0.2696085003706287
Validation loss: 2.56617613291876

Epoch: 6| Step: 3
Training loss: 0.2489760260234
Validation loss: 2.508943747467933

Epoch: 6| Step: 4
Training loss: 0.35302808241813066
Validation loss: 2.532108241904952

Epoch: 6| Step: 5
Training loss: 0.31009963357209347
Validation loss: 2.531010421825275

Epoch: 6| Step: 6
Training loss: 0.19133545091652904
Validation loss: 2.535335865398726

Epoch: 6| Step: 7
Training loss: 0.33219710302961497
Validation loss: 2.4926321033168213

Epoch: 6| Step: 8
Training loss: 0.37874072677288756
Validation loss: 2.5257721317673587

Epoch: 6| Step: 9
Training loss: 0.32567446580074205
Validation loss: 2.530417047642903

Epoch: 6| Step: 10
Training loss: 0.33654951192718147
Validation loss: 2.5395897622477857

Epoch: 6| Step: 11
Training loss: 0.24763918586210254
Validation loss: 2.5438728215590998

Epoch: 6| Step: 12
Training loss: 0.4130696322783057
Validation loss: 2.5662823306872133

Epoch: 6| Step: 13
Training loss: 0.0715904787707435
Validation loss: 2.5267462061341863

Epoch: 388| Step: 0
Training loss: 0.2822180090007362
Validation loss: 2.535093595081072

Epoch: 6| Step: 1
Training loss: 0.3009241185921956
Validation loss: 2.519644800711554

Epoch: 6| Step: 2
Training loss: 0.17328468842186465
Validation loss: 2.512339545930078

Epoch: 6| Step: 3
Training loss: 0.2305571822858461
Validation loss: 2.504787187010944

Epoch: 6| Step: 4
Training loss: 0.41180086565626106
Validation loss: 2.508580252299774

Epoch: 6| Step: 5
Training loss: 0.36653700490293073
Validation loss: 2.51135592190049

Epoch: 6| Step: 6
Training loss: 0.24199085558508593
Validation loss: 2.502607856855243

Epoch: 6| Step: 7
Training loss: 0.16027029559230638
Validation loss: 2.5455328775041273

Epoch: 6| Step: 8
Training loss: 0.22893267664513395
Validation loss: 2.589399323485938

Epoch: 6| Step: 9
Training loss: 0.3683321338989326
Validation loss: 2.6116624846147714

Epoch: 6| Step: 10
Training loss: 0.28783395382822197
Validation loss: 2.600746861333429

Epoch: 6| Step: 11
Training loss: 0.37553609833750506
Validation loss: 2.6105103552911224

Epoch: 6| Step: 12
Training loss: 0.2562683854834469
Validation loss: 2.582728257175248

Epoch: 6| Step: 13
Training loss: 0.2981162974049085
Validation loss: 2.544374054484724

Epoch: 389| Step: 0
Training loss: 0.1885564861919119
Validation loss: 2.5372303875091338

Epoch: 6| Step: 1
Training loss: 0.18009434128438673
Validation loss: 2.5139053582667032

Epoch: 6| Step: 2
Training loss: 0.3109707129294501
Validation loss: 2.519538119180264

Epoch: 6| Step: 3
Training loss: 0.26146655956311426
Validation loss: 2.5049791758050413

Epoch: 6| Step: 4
Training loss: 0.419777139959787
Validation loss: 2.4926043062336887

Epoch: 6| Step: 5
Training loss: 0.36282541532963863
Validation loss: 2.511030514661168

Epoch: 6| Step: 6
Training loss: 0.39119291982996457
Validation loss: 2.512397317344649

Epoch: 6| Step: 7
Training loss: 0.18829665219951627
Validation loss: 2.5394832361567743

Epoch: 6| Step: 8
Training loss: 0.3306770308644685
Validation loss: 2.543371653144433

Epoch: 6| Step: 9
Training loss: 0.1541204711665577
Validation loss: 2.546600373796684

Epoch: 6| Step: 10
Training loss: 0.24233205388299622
Validation loss: 2.54809642085192

Epoch: 6| Step: 11
Training loss: 0.29051019954585516
Validation loss: 2.564440766886846

Epoch: 6| Step: 12
Training loss: 0.3185117742938662
Validation loss: 2.52365169557716

Epoch: 6| Step: 13
Training loss: 0.28650088283226377
Validation loss: 2.5194108587502

Epoch: 390| Step: 0
Training loss: 0.23269062372427088
Validation loss: 2.5154862933452073

Epoch: 6| Step: 1
Training loss: 0.27462676143819287
Validation loss: 2.5220214257075693

Epoch: 6| Step: 2
Training loss: 0.18025255505924132
Validation loss: 2.531267462573577

Epoch: 6| Step: 3
Training loss: 0.31447193729211126
Validation loss: 2.5265009203896858

Epoch: 6| Step: 4
Training loss: 0.23033996798668702
Validation loss: 2.548163880997874

Epoch: 6| Step: 5
Training loss: 0.22372374705587103
Validation loss: 2.507177775597914

Epoch: 6| Step: 6
Training loss: 0.22555732545601292
Validation loss: 2.5518978156105994

Epoch: 6| Step: 7
Training loss: 0.2878046893531399
Validation loss: 2.543434924608567

Epoch: 6| Step: 8
Training loss: 0.28013623431520984
Validation loss: 2.534175804878596

Epoch: 6| Step: 9
Training loss: 0.25881170497662553
Validation loss: 2.535908952714245

Epoch: 6| Step: 10
Training loss: 0.23139076555876203
Validation loss: 2.546043890007503

Epoch: 6| Step: 11
Training loss: 0.37498944982946664
Validation loss: 2.564129078219577

Epoch: 6| Step: 12
Training loss: 0.2311791849608195
Validation loss: 2.5407469911392235

Epoch: 6| Step: 13
Training loss: 0.4600623600092435
Validation loss: 2.5487161857802776

Epoch: 391| Step: 0
Training loss: 0.4124525187359624
Validation loss: 2.504741617466794

Epoch: 6| Step: 1
Training loss: 0.3246758811751619
Validation loss: 2.5199534973125615

Epoch: 6| Step: 2
Training loss: 0.2892588901950457
Validation loss: 2.494470057717714

Epoch: 6| Step: 3
Training loss: 0.2584704471053218
Validation loss: 2.5005964644364225

Epoch: 6| Step: 4
Training loss: 0.2899028573856945
Validation loss: 2.4968246998861083

Epoch: 6| Step: 5
Training loss: 0.26737122994770457
Validation loss: 2.535468283992595

Epoch: 6| Step: 6
Training loss: 0.1364897308434211
Validation loss: 2.5138386808406583

Epoch: 6| Step: 7
Training loss: 0.2903462334324351
Validation loss: 2.5519880895230926

Epoch: 6| Step: 8
Training loss: 0.3042298939823397
Validation loss: 2.5206578438623404

Epoch: 6| Step: 9
Training loss: 0.3131358353801605
Validation loss: 2.5194572344375343

Epoch: 6| Step: 10
Training loss: 0.23426511095746644
Validation loss: 2.562653493698555

Epoch: 6| Step: 11
Training loss: 0.12958871198445995
Validation loss: 2.5479150089720726

Epoch: 6| Step: 12
Training loss: 0.159828711741056
Validation loss: 2.5620402202011605

Epoch: 6| Step: 13
Training loss: 0.45086904163405367
Validation loss: 2.554838656435264

Epoch: 392| Step: 0
Training loss: 0.2306198820719617
Validation loss: 2.577737863061837

Epoch: 6| Step: 1
Training loss: 0.32977461545284276
Validation loss: 2.5653687343119356

Epoch: 6| Step: 2
Training loss: 0.2651684989640113
Validation loss: 2.5278468192644414

Epoch: 6| Step: 3
Training loss: 0.34410861122965664
Validation loss: 2.5411147650278996

Epoch: 6| Step: 4
Training loss: 0.28523488462888963
Validation loss: 2.55234365703032

Epoch: 6| Step: 5
Training loss: 0.3298426696853619
Validation loss: 2.573170823783828

Epoch: 6| Step: 6
Training loss: 0.25486623775916895
Validation loss: 2.5568760851098546

Epoch: 6| Step: 7
Training loss: 0.17841075220739938
Validation loss: 2.5950775584024273

Epoch: 6| Step: 8
Training loss: 0.2587849742638459
Validation loss: 2.5839986615891353

Epoch: 6| Step: 9
Training loss: 0.30824593366367947
Validation loss: 2.560498231836725

Epoch: 6| Step: 10
Training loss: 0.23340777454294578
Validation loss: 2.571578687067102

Epoch: 6| Step: 11
Training loss: 0.21644286730723641
Validation loss: 2.563329087819844

Epoch: 6| Step: 12
Training loss: 0.25340259189296305
Validation loss: 2.5763207270801236

Epoch: 6| Step: 13
Training loss: 0.39259482580692046
Validation loss: 2.5775528333462554

Epoch: 393| Step: 0
Training loss: 0.26028910214619366
Validation loss: 2.568886442677324

Epoch: 6| Step: 1
Training loss: 0.30860822378089375
Validation loss: 2.532250076525888

Epoch: 6| Step: 2
Training loss: 0.24265301480565332
Validation loss: 2.550093289839787

Epoch: 6| Step: 3
Training loss: 0.20852674308112812
Validation loss: 2.5739099109812784

Epoch: 6| Step: 4
Training loss: 0.2226088791364635
Validation loss: 2.5521233839082207

Epoch: 6| Step: 5
Training loss: 0.3557514701244568
Validation loss: 2.5388928650636045

Epoch: 6| Step: 6
Training loss: 0.308746469106832
Validation loss: 2.532580549712432

Epoch: 6| Step: 7
Training loss: 0.29255870097610603
Validation loss: 2.548523776432601

Epoch: 6| Step: 8
Training loss: 0.26143457157830424
Validation loss: 2.5181522849910176

Epoch: 6| Step: 9
Training loss: 0.27015817680135096
Validation loss: 2.5776954864865456

Epoch: 6| Step: 10
Training loss: 0.2230949263247122
Validation loss: 2.5729078558650182

Epoch: 6| Step: 11
Training loss: 0.3619869514927228
Validation loss: 2.574702695462506

Epoch: 6| Step: 12
Training loss: 0.3926938773546108
Validation loss: 2.5463631273657747

Epoch: 6| Step: 13
Training loss: 0.09732762356229503
Validation loss: 2.5455190004487904

Epoch: 394| Step: 0
Training loss: 0.22929472849164492
Validation loss: 2.5237640583043937

Epoch: 6| Step: 1
Training loss: 0.280983135984954
Validation loss: 2.5669504331870883

Epoch: 6| Step: 2
Training loss: 0.27624552175076705
Validation loss: 2.5567797731672024

Epoch: 6| Step: 3
Training loss: 0.28249095952920117
Validation loss: 2.559430053973034

Epoch: 6| Step: 4
Training loss: 0.6026652990625626
Validation loss: 2.5581382192525473

Epoch: 6| Step: 5
Training loss: 0.28968311392911134
Validation loss: 2.5807049373912627

Epoch: 6| Step: 6
Training loss: 0.1777368063288802
Validation loss: 2.5577129186394316

Epoch: 6| Step: 7
Training loss: 0.36127949980302027
Validation loss: 2.5192533809936717

Epoch: 6| Step: 8
Training loss: 0.15002075141179103
Validation loss: 2.5335622450964452

Epoch: 6| Step: 9
Training loss: 0.28322759062223424
Validation loss: 2.5050718031388044

Epoch: 6| Step: 10
Training loss: 0.3803592822061418
Validation loss: 2.5392781120489336

Epoch: 6| Step: 11
Training loss: 0.22979829542318
Validation loss: 2.5451955677944236

Epoch: 6| Step: 12
Training loss: 0.4843342979311718
Validation loss: 2.55581929679983

Epoch: 6| Step: 13
Training loss: 0.19050842026939538
Validation loss: 2.591183404294025

Epoch: 395| Step: 0
Training loss: 0.4346740084596838
Validation loss: 2.6323526230996688

Epoch: 6| Step: 1
Training loss: 0.19691404795556752
Validation loss: 2.59935608128295

Epoch: 6| Step: 2
Training loss: 0.4334398632356429
Validation loss: 2.591296857881884

Epoch: 6| Step: 3
Training loss: 0.43208973162826825
Validation loss: 2.5978669911237486

Epoch: 6| Step: 4
Training loss: 0.6666525874041961
Validation loss: 2.588564545670666

Epoch: 6| Step: 5
Training loss: 0.3987551152490158
Validation loss: 2.5730648246382444

Epoch: 6| Step: 6
Training loss: 0.5127197841071895
Validation loss: 2.520075687652764

Epoch: 6| Step: 7
Training loss: 0.4708626504508503
Validation loss: 2.4840648351996193

Epoch: 6| Step: 8
Training loss: 0.7526070265842116
Validation loss: 2.4599346710896053

Epoch: 6| Step: 9
Training loss: 0.44670449585403876
Validation loss: 2.5180294255721445

Epoch: 6| Step: 10
Training loss: 0.32245816345685213
Validation loss: 2.5965954141915075

Epoch: 6| Step: 11
Training loss: 0.6278931887447222
Validation loss: 2.64086673351205

Epoch: 6| Step: 12
Training loss: 0.5883663951762429
Validation loss: 2.682951527252579

Epoch: 6| Step: 13
Training loss: 0.432944628106548
Validation loss: 2.6443022106526706

Epoch: 396| Step: 0
Training loss: 0.275585754740524
Validation loss: 2.5790405696132725

Epoch: 6| Step: 1
Training loss: 0.5394973383193519
Validation loss: 2.5435239073952176

Epoch: 6| Step: 2
Training loss: 0.49370121171596676
Validation loss: 2.5369715004207576

Epoch: 6| Step: 3
Training loss: 0.9005720241301661
Validation loss: 2.506633091345586

Epoch: 6| Step: 4
Training loss: 0.3910584143397292
Validation loss: 2.5980892176163684

Epoch: 6| Step: 5
Training loss: 0.4754934984799584
Validation loss: 2.6757004664206936

Epoch: 6| Step: 6
Training loss: 0.496755309053991
Validation loss: 2.7183347881665307

Epoch: 6| Step: 7
Training loss: 0.7031541394447473
Validation loss: 2.7069551588335488

Epoch: 6| Step: 8
Training loss: 0.5315383801602995
Validation loss: 2.606548989328994

Epoch: 6| Step: 9
Training loss: 0.4658753464536041
Validation loss: 2.565974955993706

Epoch: 6| Step: 10
Training loss: 0.51653077302161
Validation loss: 2.5045677889047435

Epoch: 6| Step: 11
Training loss: 0.6481397013895963
Validation loss: 2.542804046121462

Epoch: 6| Step: 12
Training loss: 0.7984594412997036
Validation loss: 2.5815190938611874

Epoch: 6| Step: 13
Training loss: 0.5149542462755476
Validation loss: 2.6261313847610532

Epoch: 397| Step: 0
Training loss: 0.66473789649954
Validation loss: 2.680318227622603

Epoch: 6| Step: 1
Training loss: 0.42865949248208085
Validation loss: 2.6911101307607534

Epoch: 6| Step: 2
Training loss: 0.43847741209767704
Validation loss: 2.734351467142638

Epoch: 6| Step: 3
Training loss: 0.5921108558597008
Validation loss: 2.66742854489134

Epoch: 6| Step: 4
Training loss: 0.43845340183320414
Validation loss: 2.566442304851067

Epoch: 6| Step: 5
Training loss: 0.422590038310059
Validation loss: 2.5172825685175897

Epoch: 6| Step: 6
Training loss: 0.39528342581120046
Validation loss: 2.499474862534806

Epoch: 6| Step: 7
Training loss: 0.5833332425072009
Validation loss: 2.471512722834723

Epoch: 6| Step: 8
Training loss: 0.5538609753871117
Validation loss: 2.507290291738634

Epoch: 6| Step: 9
Training loss: 0.42957932237565016
Validation loss: 2.538990694581487

Epoch: 6| Step: 10
Training loss: 0.556279758128852
Validation loss: 2.5864536865809016

Epoch: 6| Step: 11
Training loss: 0.4822946913633256
Validation loss: 2.637304770164698

Epoch: 6| Step: 12
Training loss: 0.5069902659164566
Validation loss: 2.705269128134782

Epoch: 6| Step: 13
Training loss: 0.8129751210106954
Validation loss: 2.7483032376590173

Epoch: 398| Step: 0
Training loss: 0.4770010665555742
Validation loss: 2.7238914155105878

Epoch: 6| Step: 1
Training loss: 0.4293022162371569
Validation loss: 2.591125439391337

Epoch: 6| Step: 2
Training loss: 0.2828066978070156
Validation loss: 2.552886111779322

Epoch: 6| Step: 3
Training loss: 0.5575756050812973
Validation loss: 2.5060676283111687

Epoch: 6| Step: 4
Training loss: 0.5502145977113825
Validation loss: 2.5281342112523992

Epoch: 6| Step: 5
Training loss: 0.3780095215688128
Validation loss: 2.537616636492276

Epoch: 6| Step: 6
Training loss: 0.42910008593007004
Validation loss: 2.518582102492332

Epoch: 6| Step: 7
Training loss: 0.5207571895888709
Validation loss: 2.5099623572883485

Epoch: 6| Step: 8
Training loss: 0.37687215775514066
Validation loss: 2.5430369701849505

Epoch: 6| Step: 9
Training loss: 0.32845485093356647
Validation loss: 2.5872933462023853

Epoch: 6| Step: 10
Training loss: 0.43584984133889165
Validation loss: 2.5739730141796975

Epoch: 6| Step: 11
Training loss: 0.4624184884593277
Validation loss: 2.6103544994848558

Epoch: 6| Step: 12
Training loss: 0.4635954693491404
Validation loss: 2.616191465716623

Epoch: 6| Step: 13
Training loss: 0.5281285697771221
Validation loss: 2.6266517696558878

Epoch: 399| Step: 0
Training loss: 0.2938190835516619
Validation loss: 2.570959097690136

Epoch: 6| Step: 1
Training loss: 0.4164436896063264
Validation loss: 2.5428423113454515

Epoch: 6| Step: 2
Training loss: 0.3227040862675548
Validation loss: 2.5499448199638604

Epoch: 6| Step: 3
Training loss: 0.4106878015171373
Validation loss: 2.4931287247940777

Epoch: 6| Step: 4
Training loss: 0.43125076293877823
Validation loss: 2.505735616654152

Epoch: 6| Step: 5
Training loss: 0.4371690179327967
Validation loss: 2.455543420653652

Epoch: 6| Step: 6
Training loss: 0.3496134454074652
Validation loss: 2.502993381070347

Epoch: 6| Step: 7
Training loss: 0.37330191317532224
Validation loss: 2.5232097579220207

Epoch: 6| Step: 8
Training loss: 0.3967820727070979
Validation loss: 2.5166938257358042

Epoch: 6| Step: 9
Training loss: 0.3985506345906803
Validation loss: 2.526665512061915

Epoch: 6| Step: 10
Training loss: 0.2971875402729316
Validation loss: 2.563685089364918

Epoch: 6| Step: 11
Training loss: 0.3028254956349307
Validation loss: 2.5590199976928907

Epoch: 6| Step: 12
Training loss: 0.37983022683792483
Validation loss: 2.5512510253812866

Epoch: 6| Step: 13
Training loss: 0.36933080628298887
Validation loss: 2.5421663286054725

Epoch: 400| Step: 0
Training loss: 0.29570224918049326
Validation loss: 2.5654542242594536

Epoch: 6| Step: 1
Training loss: 0.25815045718444973
Validation loss: 2.548934309325495

Epoch: 6| Step: 2
Training loss: 0.3976300978539157
Validation loss: 2.5171182458197237

Epoch: 6| Step: 3
Training loss: 0.3447707366737302
Validation loss: 2.533124135964632

Epoch: 6| Step: 4
Training loss: 0.30636329015130065
Validation loss: 2.527454034066743

Epoch: 6| Step: 5
Training loss: 0.27916677152337527
Validation loss: 2.5049947659937626

Epoch: 6| Step: 6
Training loss: 0.3679099584697304
Validation loss: 2.477251753952241

Epoch: 6| Step: 7
Training loss: 0.3321472077681715
Validation loss: 2.486742044277589

Epoch: 6| Step: 8
Training loss: 0.4552888505144017
Validation loss: 2.498880069874642

Epoch: 6| Step: 9
Training loss: 0.3331946243328757
Validation loss: 2.4865413133225553

Epoch: 6| Step: 10
Training loss: 0.19964329978080753
Validation loss: 2.5101266750571702

Epoch: 6| Step: 11
Training loss: 0.21796049970647607
Validation loss: 2.5347987119946764

Epoch: 6| Step: 12
Training loss: 0.42949405130256907
Validation loss: 2.5493280427419776

Epoch: 6| Step: 13
Training loss: 0.19263318998153836
Validation loss: 2.554567359612396

Testing loss: 2.530940338575712
