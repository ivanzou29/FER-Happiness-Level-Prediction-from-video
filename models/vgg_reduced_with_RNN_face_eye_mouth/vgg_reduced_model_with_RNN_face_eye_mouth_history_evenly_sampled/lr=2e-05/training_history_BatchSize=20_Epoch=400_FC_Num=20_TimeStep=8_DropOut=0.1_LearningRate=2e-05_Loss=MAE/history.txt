Epoch: 1| Step: 0
Training loss: 4.235150337219238
Validation loss: 5.182322204753917

Epoch: 5| Step: 1
Training loss: 4.348580360412598
Validation loss: 5.167517344156901

Epoch: 5| Step: 2
Training loss: 5.356525421142578
Validation loss: 5.155941609413393

Epoch: 5| Step: 3
Training loss: 5.148576259613037
Validation loss: 5.145045977766796

Epoch: 5| Step: 4
Training loss: 5.0969648361206055
Validation loss: 5.133145393863801

Epoch: 5| Step: 5
Training loss: 4.839534759521484
Validation loss: 5.1190730166691605

Epoch: 5| Step: 6
Training loss: 4.568113803863525
Validation loss: 5.101809194011073

Epoch: 5| Step: 7
Training loss: 5.404743671417236
Validation loss: 5.080759012570945

Epoch: 5| Step: 8
Training loss: 6.358155250549316
Validation loss: 5.0565038188811275

Epoch: 5| Step: 9
Training loss: 4.780404090881348
Validation loss: 5.027572772836172

Epoch: 5| Step: 10
Training loss: 3.5830774307250977
Validation loss: 4.994360534093714

Epoch: 2| Step: 0
Training loss: 3.9062583446502686
Validation loss: 4.9558117825497865

Epoch: 5| Step: 1
Training loss: 4.9464216232299805
Validation loss: 4.913008607843871

Epoch: 5| Step: 2
Training loss: 3.2303786277770996
Validation loss: 4.865942308979649

Epoch: 5| Step: 3
Training loss: 5.162990093231201
Validation loss: 4.813894887124339

Epoch: 5| Step: 4
Training loss: 5.245940208435059
Validation loss: 4.7553921053486485

Epoch: 5| Step: 5
Training loss: 3.9441940784454346
Validation loss: 4.694111506144206

Epoch: 5| Step: 6
Training loss: 4.652459144592285
Validation loss: 4.627900749124507

Epoch: 5| Step: 7
Training loss: 4.224681854248047
Validation loss: 4.561020369170814

Epoch: 5| Step: 8
Training loss: 4.662152290344238
Validation loss: 4.4880982419495945

Epoch: 5| Step: 9
Training loss: 5.150450229644775
Validation loss: 4.411925346620621

Epoch: 5| Step: 10
Training loss: 3.8587632179260254
Validation loss: 4.331779797871907

Epoch: 3| Step: 0
Training loss: 3.476198196411133
Validation loss: 4.253183698141447

Epoch: 5| Step: 1
Training loss: 3.7206902503967285
Validation loss: 4.178911852580245

Epoch: 5| Step: 2
Training loss: 5.170462608337402
Validation loss: 4.104396650868077

Epoch: 5| Step: 3
Training loss: 4.406472206115723
Validation loss: 4.032878201494935

Epoch: 5| Step: 4
Training loss: 3.8649678230285645
Validation loss: 3.969191781936153

Epoch: 5| Step: 5
Training loss: 3.413464307785034
Validation loss: 3.911409665179509

Epoch: 5| Step: 6
Training loss: 3.6611480712890625
Validation loss: 3.864389988683885

Epoch: 5| Step: 7
Training loss: 2.8273234367370605
Validation loss: 3.8241944825777443

Epoch: 5| Step: 8
Training loss: 3.9737696647644043
Validation loss: 3.7899220117958645

Epoch: 5| Step: 9
Training loss: 3.386779308319092
Validation loss: 3.7538429998582408

Epoch: 5| Step: 10
Training loss: 3.8307886123657227
Validation loss: 3.7228324951664096

Epoch: 4| Step: 0
Training loss: 3.335270643234253
Validation loss: 3.688692169804727

Epoch: 5| Step: 1
Training loss: 3.6669700145721436
Validation loss: 3.656713326772054

Epoch: 5| Step: 2
Training loss: 4.608211517333984
Validation loss: 3.635460515176096

Epoch: 5| Step: 3
Training loss: 3.3088440895080566
Validation loss: 3.6139166739679154

Epoch: 5| Step: 4
Training loss: 3.938786268234253
Validation loss: 3.597189498204057

Epoch: 5| Step: 5
Training loss: 2.937732219696045
Validation loss: 3.581475511673958

Epoch: 5| Step: 6
Training loss: 3.16135835647583
Validation loss: 3.570209180155108

Epoch: 5| Step: 7
Training loss: 2.9831509590148926
Validation loss: 3.5609043464865735

Epoch: 5| Step: 8
Training loss: 3.4030234813690186
Validation loss: 3.5462585982456

Epoch: 5| Step: 9
Training loss: 3.682823657989502
Validation loss: 3.533473542941514

Epoch: 5| Step: 10
Training loss: 3.6739325523376465
Validation loss: 3.5370254414055937

Epoch: 5| Step: 0
Training loss: 3.747481107711792
Validation loss: 3.520813718918831

Epoch: 5| Step: 1
Training loss: 3.493595838546753
Validation loss: 3.499141252169045

Epoch: 5| Step: 2
Training loss: 3.7325820922851562
Validation loss: 3.4943470083257204

Epoch: 5| Step: 3
Training loss: 3.511007308959961
Validation loss: 3.4861458962963474

Epoch: 5| Step: 4
Training loss: 3.946073055267334
Validation loss: 3.4764645227821926

Epoch: 5| Step: 5
Training loss: 3.2893314361572266
Validation loss: 3.457055345658333

Epoch: 5| Step: 6
Training loss: 3.246323347091675
Validation loss: 3.446436087290446

Epoch: 5| Step: 7
Training loss: 3.453219175338745
Validation loss: 3.4434274140224663

Epoch: 5| Step: 8
Training loss: 2.998854160308838
Validation loss: 3.430509736461024

Epoch: 5| Step: 9
Training loss: 2.5674729347229004
Validation loss: 3.423942945336783

Epoch: 5| Step: 10
Training loss: 3.520740270614624
Validation loss: 3.4152116006420505

Epoch: 6| Step: 0
Training loss: 3.477595567703247
Validation loss: 3.4036077632698962

Epoch: 5| Step: 1
Training loss: 2.7093491554260254
Validation loss: 3.3957321720738567

Epoch: 5| Step: 2
Training loss: 3.4533660411834717
Validation loss: 3.385460353666736

Epoch: 5| Step: 3
Training loss: 4.400631427764893
Validation loss: 3.3761508541722454

Epoch: 5| Step: 4
Training loss: 3.0768396854400635
Validation loss: 3.3676175763530116

Epoch: 5| Step: 5
Training loss: 3.5517303943634033
Validation loss: 3.355791404683103

Epoch: 5| Step: 6
Training loss: 2.3037526607513428
Validation loss: 3.344705932883806

Epoch: 5| Step: 7
Training loss: 3.802664279937744
Validation loss: 3.337775940536171

Epoch: 5| Step: 8
Training loss: 3.5893898010253906
Validation loss: 3.3283001966373895

Epoch: 5| Step: 9
Training loss: 2.7759621143341064
Validation loss: 3.3225743206598426

Epoch: 5| Step: 10
Training loss: 3.394855260848999
Validation loss: 3.316073215135964

Epoch: 7| Step: 0
Training loss: 3.5936038494110107
Validation loss: 3.3091416000038065

Epoch: 5| Step: 1
Training loss: 2.4908175468444824
Validation loss: 3.30242088789581

Epoch: 5| Step: 2
Training loss: 3.511204481124878
Validation loss: 3.295858560069915

Epoch: 5| Step: 3
Training loss: 3.2388014793395996
Validation loss: 3.29063069692222

Epoch: 5| Step: 4
Training loss: 3.458411455154419
Validation loss: 3.282468872685586

Epoch: 5| Step: 5
Training loss: 4.173778057098389
Validation loss: 3.274089187704107

Epoch: 5| Step: 6
Training loss: 2.9650166034698486
Validation loss: 3.2669014110360095

Epoch: 5| Step: 7
Training loss: 3.1263413429260254
Validation loss: 3.258736502739691

Epoch: 5| Step: 8
Training loss: 2.8912158012390137
Validation loss: 3.2581677001009703

Epoch: 5| Step: 9
Training loss: 2.884913921356201
Validation loss: 3.2435109076961393

Epoch: 5| Step: 10
Training loss: 3.506202459335327
Validation loss: 3.238372633534093

Epoch: 8| Step: 0
Training loss: 3.10176157951355
Validation loss: 3.2337880442219396

Epoch: 5| Step: 1
Training loss: 3.336470127105713
Validation loss: 3.228490993540774

Epoch: 5| Step: 2
Training loss: 3.724874496459961
Validation loss: 3.2221767415282545

Epoch: 5| Step: 3
Training loss: 2.755037307739258
Validation loss: 3.216330784623341

Epoch: 5| Step: 4
Training loss: 3.4581527709960938
Validation loss: 3.2097208525544856

Epoch: 5| Step: 5
Training loss: 2.9136452674865723
Validation loss: 3.2048464103411605

Epoch: 5| Step: 6
Training loss: 2.9556667804718018
Validation loss: 3.197509632315687

Epoch: 5| Step: 7
Training loss: 3.4220995903015137
Validation loss: 3.1904882436157553

Epoch: 5| Step: 8
Training loss: 3.135838031768799
Validation loss: 3.1862516044288554

Epoch: 5| Step: 9
Training loss: 2.8113043308258057
Validation loss: 3.177354848513039

Epoch: 5| Step: 10
Training loss: 3.658230781555176
Validation loss: 3.171419225713258

Epoch: 9| Step: 0
Training loss: 3.005126476287842
Validation loss: 3.1628328882237917

Epoch: 5| Step: 1
Training loss: 2.708777904510498
Validation loss: 3.1609159105567524

Epoch: 5| Step: 2
Training loss: 2.7581825256347656
Validation loss: 3.1535292133208244

Epoch: 5| Step: 3
Training loss: 3.812657117843628
Validation loss: 3.1475130716959634

Epoch: 5| Step: 4
Training loss: 2.695899724960327
Validation loss: 3.1388992212151967

Epoch: 5| Step: 5
Training loss: 3.301903486251831
Validation loss: 3.1358146590571248

Epoch: 5| Step: 6
Training loss: 3.0137436389923096
Validation loss: 3.131005141042894

Epoch: 5| Step: 7
Training loss: 3.154365062713623
Validation loss: 3.124142787789786

Epoch: 5| Step: 8
Training loss: 3.6671230792999268
Validation loss: 3.1204062046543246

Epoch: 5| Step: 9
Training loss: 3.6514639854431152
Validation loss: 3.1152661410711144

Epoch: 5| Step: 10
Training loss: 2.9091389179229736
Validation loss: 3.1089303672954602

Epoch: 10| Step: 0
Training loss: 3.9567222595214844
Validation loss: 3.1053011443025325

Epoch: 5| Step: 1
Training loss: 3.695791244506836
Validation loss: 3.097941393493324

Epoch: 5| Step: 2
Training loss: 2.726912498474121
Validation loss: 3.089435731211016

Epoch: 5| Step: 3
Training loss: 3.5164570808410645
Validation loss: 3.091714407808037

Epoch: 5| Step: 4
Training loss: 2.60553240776062
Validation loss: 3.0926915804545083

Epoch: 5| Step: 5
Training loss: 3.17121958732605
Validation loss: 3.084080126977736

Epoch: 5| Step: 6
Training loss: 2.7982096672058105
Validation loss: 3.0693253086459253

Epoch: 5| Step: 7
Training loss: 3.1952567100524902
Validation loss: 3.0728430209621305

Epoch: 5| Step: 8
Training loss: 3.708021640777588
Validation loss: 3.068284788439351

Epoch: 5| Step: 9
Training loss: 2.441234827041626
Validation loss: 3.05701550873377

Epoch: 5| Step: 10
Training loss: 2.416731595993042
Validation loss: 3.0542666476259948

Epoch: 11| Step: 0
Training loss: 2.5275843143463135
Validation loss: 3.0502368737292547

Epoch: 5| Step: 1
Training loss: 2.737687587738037
Validation loss: 3.0516062423747075

Epoch: 5| Step: 2
Training loss: 3.208707809448242
Validation loss: 3.046422871210242

Epoch: 5| Step: 3
Training loss: 2.893332004547119
Validation loss: 3.0416158219819427

Epoch: 5| Step: 4
Training loss: 3.9955902099609375
Validation loss: 3.0361249241777646

Epoch: 5| Step: 5
Training loss: 2.68839693069458
Validation loss: 3.0299664928067114

Epoch: 5| Step: 6
Training loss: 3.722484588623047
Validation loss: 3.024615131398683

Epoch: 5| Step: 7
Training loss: 3.1007914543151855
Validation loss: 3.020074421359647

Epoch: 5| Step: 8
Training loss: 3.123171091079712
Validation loss: 3.014078273568102

Epoch: 5| Step: 9
Training loss: 3.3494949340820312
Validation loss: 3.0137213558279057

Epoch: 5| Step: 10
Training loss: 2.500957489013672
Validation loss: 3.0089278836404123

Epoch: 12| Step: 0
Training loss: 2.3807730674743652
Validation loss: 3.005475515960365

Epoch: 5| Step: 1
Training loss: 3.2746529579162598
Validation loss: 3.003497028863558

Epoch: 5| Step: 2
Training loss: 3.0679526329040527
Validation loss: 2.996260502005136

Epoch: 5| Step: 3
Training loss: 3.6234543323516846
Validation loss: 2.9889511267344155

Epoch: 5| Step: 4
Training loss: 2.339815616607666
Validation loss: 2.9812357874326807

Epoch: 5| Step: 5
Training loss: 3.0515973567962646
Validation loss: 2.9791413327699066

Epoch: 5| Step: 6
Training loss: 3.5230820178985596
Validation loss: 2.9724993757022324

Epoch: 5| Step: 7
Training loss: 3.6065878868103027
Validation loss: 2.9685186724508963

Epoch: 5| Step: 8
Training loss: 3.278949022293091
Validation loss: 2.965642308676115

Epoch: 5| Step: 9
Training loss: 3.0391685962677
Validation loss: 2.963181572575723

Epoch: 5| Step: 10
Training loss: 2.3022990226745605
Validation loss: 2.9663823625092864

Epoch: 13| Step: 0
Training loss: 2.760216474533081
Validation loss: 2.9635513264645814

Epoch: 5| Step: 1
Training loss: 3.927931547164917
Validation loss: 2.9547813733418784

Epoch: 5| Step: 2
Training loss: 3.0715718269348145
Validation loss: 2.947952419198969

Epoch: 5| Step: 3
Training loss: 2.8507323265075684
Validation loss: 2.9445798320154988

Epoch: 5| Step: 4
Training loss: 3.259337902069092
Validation loss: 2.9443398649974535

Epoch: 5| Step: 5
Training loss: 2.895951747894287
Validation loss: 2.9367726720789427

Epoch: 5| Step: 6
Training loss: 3.3456435203552246
Validation loss: 2.9321392633581675

Epoch: 5| Step: 7
Training loss: 2.8398818969726562
Validation loss: 2.9305959901502057

Epoch: 5| Step: 8
Training loss: 2.7621166706085205
Validation loss: 2.928036976886052

Epoch: 5| Step: 9
Training loss: 3.1392784118652344
Validation loss: 2.928659136577319

Epoch: 5| Step: 10
Training loss: 2.352351665496826
Validation loss: 2.9242766275200793

Epoch: 14| Step: 0
Training loss: 3.0692667961120605
Validation loss: 2.91988447917405

Epoch: 5| Step: 1
Training loss: 2.7923619747161865
Validation loss: 2.917565422673379

Epoch: 5| Step: 2
Training loss: 3.5407886505126953
Validation loss: 2.9148756893732215

Epoch: 5| Step: 3
Training loss: 3.4900364875793457
Validation loss: 2.9102840654311644

Epoch: 5| Step: 4
Training loss: 2.117460250854492
Validation loss: 2.908265875231835

Epoch: 5| Step: 5
Training loss: 2.5186355113983154
Validation loss: 2.9039430054285194

Epoch: 5| Step: 6
Training loss: 3.6237876415252686
Validation loss: 2.9021517512618855

Epoch: 5| Step: 7
Training loss: 2.718842029571533
Validation loss: 2.9014192704231507

Epoch: 5| Step: 8
Training loss: 3.468972682952881
Validation loss: 2.8975692102985997

Epoch: 5| Step: 9
Training loss: 2.872056007385254
Validation loss: 2.8948309780448995

Epoch: 5| Step: 10
Training loss: 2.813638687133789
Validation loss: 2.892227829143565

Epoch: 15| Step: 0
Training loss: 2.4198334217071533
Validation loss: 2.89091057162131

Epoch: 5| Step: 1
Training loss: 2.8216395378112793
Validation loss: 2.888502920827558

Epoch: 5| Step: 2
Training loss: 3.2381443977355957
Validation loss: 2.887642962958223

Epoch: 5| Step: 3
Training loss: 3.063337802886963
Validation loss: 2.911823094532054

Epoch: 5| Step: 4
Training loss: 2.892698049545288
Validation loss: 2.911286661701818

Epoch: 5| Step: 5
Training loss: 2.933649778366089
Validation loss: 2.8880010958640807

Epoch: 5| Step: 6
Training loss: 3.1841931343078613
Validation loss: 2.8808802276529293

Epoch: 5| Step: 7
Training loss: 3.882441759109497
Validation loss: 2.882354926037532

Epoch: 5| Step: 8
Training loss: 2.724745988845825
Validation loss: 2.882871704716836

Epoch: 5| Step: 9
Training loss: 2.608924388885498
Validation loss: 2.8858307946112847

Epoch: 5| Step: 10
Training loss: 3.19038724899292
Validation loss: 2.8838889034845496

Epoch: 16| Step: 0
Training loss: 3.259822368621826
Validation loss: 2.8817519475055

Epoch: 5| Step: 1
Training loss: 3.1589560508728027
Validation loss: 2.8782076220358572

Epoch: 5| Step: 2
Training loss: 2.825525999069214
Validation loss: 2.877798041989726

Epoch: 5| Step: 3
Training loss: 3.166750431060791
Validation loss: 2.873828249592935

Epoch: 5| Step: 4
Training loss: 2.4187519550323486
Validation loss: 2.871107014276648

Epoch: 5| Step: 5
Training loss: 3.1821680068969727
Validation loss: 2.8688668845802225

Epoch: 5| Step: 6
Training loss: 3.3920836448669434
Validation loss: 2.8672657064212266

Epoch: 5| Step: 7
Training loss: 1.9418712854385376
Validation loss: 2.868553853804065

Epoch: 5| Step: 8
Training loss: 3.7722599506378174
Validation loss: 2.8903014506063154

Epoch: 5| Step: 9
Training loss: 2.519435167312622
Validation loss: 2.87426741661564

Epoch: 5| Step: 10
Training loss: 3.224982976913452
Validation loss: 2.861050159700455

Epoch: 17| Step: 0
Training loss: 3.196458101272583
Validation loss: 2.868034326902

Epoch: 5| Step: 1
Training loss: 2.747908115386963
Validation loss: 2.8726949871227307

Epoch: 5| Step: 2
Training loss: 2.8601109981536865
Validation loss: 2.859408632401497

Epoch: 5| Step: 3
Training loss: 2.5522549152374268
Validation loss: 2.856189294527936

Epoch: 5| Step: 4
Training loss: 3.1287684440612793
Validation loss: 2.8545554222599154

Epoch: 5| Step: 5
Training loss: 3.1076865196228027
Validation loss: 2.8536050217126006

Epoch: 5| Step: 6
Training loss: 2.538909912109375
Validation loss: 2.8528784449382494

Epoch: 5| Step: 7
Training loss: 3.481107711791992
Validation loss: 2.8556776636390278

Epoch: 5| Step: 8
Training loss: 3.8182151317596436
Validation loss: 2.852275320278701

Epoch: 5| Step: 9
Training loss: 2.854884624481201
Validation loss: 2.849692508738528

Epoch: 5| Step: 10
Training loss: 2.3045871257781982
Validation loss: 2.847502987871888

Epoch: 18| Step: 0
Training loss: 3.199732780456543
Validation loss: 2.8460851228365334

Epoch: 5| Step: 1
Training loss: 2.9650115966796875
Validation loss: 2.842849898081954

Epoch: 5| Step: 2
Training loss: 3.5040245056152344
Validation loss: 2.8434312881961947

Epoch: 5| Step: 3
Training loss: 2.183783531188965
Validation loss: 2.8427173142792075

Epoch: 5| Step: 4
Training loss: 3.1066818237304688
Validation loss: 2.841178427460373

Epoch: 5| Step: 5
Training loss: 3.2368502616882324
Validation loss: 2.839377828823623

Epoch: 5| Step: 6
Training loss: 3.059035539627075
Validation loss: 2.837761099620532

Epoch: 5| Step: 7
Training loss: 3.005323886871338
Validation loss: 2.8359298449690624

Epoch: 5| Step: 8
Training loss: 2.670018434524536
Validation loss: 2.8361673662739415

Epoch: 5| Step: 9
Training loss: 2.5516769886016846
Validation loss: 2.848066019755538

Epoch: 5| Step: 10
Training loss: 3.124713659286499
Validation loss: 2.844285108709848

Epoch: 19| Step: 0
Training loss: 2.631793975830078
Validation loss: 2.8349947980655137

Epoch: 5| Step: 1
Training loss: 3.77983021736145
Validation loss: 2.8362908568433536

Epoch: 5| Step: 2
Training loss: 3.2706916332244873
Validation loss: 2.8316992816104682

Epoch: 5| Step: 3
Training loss: 2.67858624458313
Validation loss: 2.8307153127526723

Epoch: 5| Step: 4
Training loss: 2.197028398513794
Validation loss: 2.8292462389956237

Epoch: 5| Step: 5
Training loss: 3.8597564697265625
Validation loss: 2.831395867050335

Epoch: 5| Step: 6
Training loss: 2.87687349319458
Validation loss: 2.83146845909857

Epoch: 5| Step: 7
Training loss: 3.410090684890747
Validation loss: 2.834083785292923

Epoch: 5| Step: 8
Training loss: 2.524751663208008
Validation loss: 2.8314963002358713

Epoch: 5| Step: 9
Training loss: 2.440948486328125
Validation loss: 2.8315657031151558

Epoch: 5| Step: 10
Training loss: 2.8409640789031982
Validation loss: 2.831210031304308

Epoch: 20| Step: 0
Training loss: 4.068326950073242
Validation loss: 2.829312742397349

Epoch: 5| Step: 1
Training loss: 3.0331006050109863
Validation loss: 2.825284860467398

Epoch: 5| Step: 2
Training loss: 2.6811022758483887
Validation loss: 2.824894215471001

Epoch: 5| Step: 3
Training loss: 2.9770355224609375
Validation loss: 2.821141917218444

Epoch: 5| Step: 4
Training loss: 2.856036901473999
Validation loss: 2.8231480993250364

Epoch: 5| Step: 5
Training loss: 2.8709514141082764
Validation loss: 2.820505185793805

Epoch: 5| Step: 6
Training loss: 2.545443296432495
Validation loss: 2.8184198794826383

Epoch: 5| Step: 7
Training loss: 3.1606862545013428
Validation loss: 2.8185715700990412

Epoch: 5| Step: 8
Training loss: 2.8680782318115234
Validation loss: 2.817879610164191

Epoch: 5| Step: 9
Training loss: 2.978713274002075
Validation loss: 2.8189246167418776

Epoch: 5| Step: 10
Training loss: 2.301081418991089
Validation loss: 2.8198397877395793

Epoch: 21| Step: 0
Training loss: 3.795738935470581
Validation loss: 2.8258699858060448

Epoch: 5| Step: 1
Training loss: 3.3163890838623047
Validation loss: 2.8216553272739535

Epoch: 5| Step: 2
Training loss: 2.6608595848083496
Validation loss: 2.807421712465184

Epoch: 5| Step: 3
Training loss: 3.7015388011932373
Validation loss: 2.807180143171741

Epoch: 5| Step: 4
Training loss: 3.1942336559295654
Validation loss: 2.81323738508327

Epoch: 5| Step: 5
Training loss: 2.5073819160461426
Validation loss: 2.8144787229517454

Epoch: 5| Step: 6
Training loss: 2.0169613361358643
Validation loss: 2.808424852227652

Epoch: 5| Step: 7
Training loss: 2.819979190826416
Validation loss: 2.8041318642195834

Epoch: 5| Step: 8
Training loss: 3.0364060401916504
Validation loss: 2.8066227487338486

Epoch: 5| Step: 9
Training loss: 3.0400288105010986
Validation loss: 2.805779241746472

Epoch: 5| Step: 10
Training loss: 2.1204886436462402
Validation loss: 2.808584459366337

Epoch: 22| Step: 0
Training loss: 3.313849687576294
Validation loss: 2.812515981735722

Epoch: 5| Step: 1
Training loss: 3.1087098121643066
Validation loss: 2.8102007963324107

Epoch: 5| Step: 2
Training loss: 2.5311439037323
Validation loss: 2.8034720549019436

Epoch: 5| Step: 3
Training loss: 2.9814724922180176
Validation loss: 2.797775555682439

Epoch: 5| Step: 4
Training loss: 2.7774930000305176
Validation loss: 2.799881896665019

Epoch: 5| Step: 5
Training loss: 3.0738182067871094
Validation loss: 2.799942849784769

Epoch: 5| Step: 6
Training loss: 3.0455098152160645
Validation loss: 2.797678675702823

Epoch: 5| Step: 7
Training loss: 2.772183656692505
Validation loss: 2.7981203653479136

Epoch: 5| Step: 8
Training loss: 3.1636340618133545
Validation loss: 2.797824505836733

Epoch: 5| Step: 9
Training loss: 2.61149001121521
Validation loss: 2.798366197975733

Epoch: 5| Step: 10
Training loss: 2.8957834243774414
Validation loss: 2.80294047376161

Epoch: 23| Step: 0
Training loss: 2.9590392112731934
Validation loss: 2.7996676532171105

Epoch: 5| Step: 1
Training loss: 2.688544988632202
Validation loss: 2.793287513076618

Epoch: 5| Step: 2
Training loss: 3.602160930633545
Validation loss: 2.794000953756353

Epoch: 5| Step: 3
Training loss: 2.2603118419647217
Validation loss: 2.7929203433375203

Epoch: 5| Step: 4
Training loss: 2.627368927001953
Validation loss: 2.807756306022726

Epoch: 5| Step: 5
Training loss: 3.0738861560821533
Validation loss: 2.8270217705798406

Epoch: 5| Step: 6
Training loss: 3.0746700763702393
Validation loss: 2.8043001569727415

Epoch: 5| Step: 7
Training loss: 3.3008575439453125
Validation loss: 2.7875592426587175

Epoch: 5| Step: 8
Training loss: 2.5031650066375732
Validation loss: 2.7858022284764115

Epoch: 5| Step: 9
Training loss: 3.1490607261657715
Validation loss: 2.8548720062419934

Epoch: 5| Step: 10
Training loss: 3.2343692779541016
Validation loss: 2.890250975085843

Epoch: 24| Step: 0
Training loss: 3.584152936935425
Validation loss: 2.8555516812109176

Epoch: 5| Step: 1
Training loss: 3.142693042755127
Validation loss: 2.825365743329448

Epoch: 5| Step: 2
Training loss: 2.9886879920959473
Validation loss: 2.825345044494957

Epoch: 5| Step: 3
Training loss: 3.275679349899292
Validation loss: 2.7929572930899997

Epoch: 5| Step: 4
Training loss: 2.560030937194824
Validation loss: 2.810615065277264

Epoch: 5| Step: 5
Training loss: 2.769735336303711
Validation loss: 2.8656820276732087

Epoch: 5| Step: 6
Training loss: 2.8894126415252686
Validation loss: 2.8366647971573697

Epoch: 5| Step: 7
Training loss: 3.350799560546875
Validation loss: 2.816173691903391

Epoch: 5| Step: 8
Training loss: 2.5176842212677
Validation loss: 2.786737190779819

Epoch: 5| Step: 9
Training loss: 2.916926145553589
Validation loss: 2.781421612667781

Epoch: 5| Step: 10
Training loss: 2.31711483001709
Validation loss: 2.8055978564805883

Epoch: 25| Step: 0
Training loss: 2.2294886112213135
Validation loss: 2.915078465656568

Epoch: 5| Step: 1
Training loss: 3.2974231243133545
Validation loss: 3.0422244994871077

Epoch: 5| Step: 2
Training loss: 2.090416669845581
Validation loss: 3.004656122576806

Epoch: 5| Step: 3
Training loss: 3.3492724895477295
Validation loss: 2.8680762039717806

Epoch: 5| Step: 4
Training loss: 2.759003162384033
Validation loss: 2.7838646622114283

Epoch: 5| Step: 5
Training loss: 2.9731853008270264
Validation loss: 2.8828544334698747

Epoch: 5| Step: 6
Training loss: 3.181522846221924
Validation loss: 2.9893362086306334

Epoch: 5| Step: 7
Training loss: 4.103023529052734
Validation loss: 3.0314506715343845

Epoch: 5| Step: 8
Training loss: 3.1952271461486816
Validation loss: 2.8949435936507357

Epoch: 5| Step: 9
Training loss: 2.5520060062408447
Validation loss: 2.7911851739370697

Epoch: 5| Step: 10
Training loss: 3.1978161334991455
Validation loss: 2.769763349204935

Epoch: 26| Step: 0
Training loss: 2.668213367462158
Validation loss: 2.792041301727295

Epoch: 5| Step: 1
Training loss: 3.3715381622314453
Validation loss: 2.8709862514208724

Epoch: 5| Step: 2
Training loss: 3.7374892234802246
Validation loss: 2.8728780567005114

Epoch: 5| Step: 3
Training loss: 1.8674490451812744
Validation loss: 2.8327518227279826

Epoch: 5| Step: 4
Training loss: 2.6599535942077637
Validation loss: 2.7829514498351724

Epoch: 5| Step: 5
Training loss: 3.1520917415618896
Validation loss: 2.7762740145447435

Epoch: 5| Step: 6
Training loss: 2.6234488487243652
Validation loss: 2.7754307613577893

Epoch: 5| Step: 7
Training loss: 3.0347137451171875
Validation loss: 2.7735379126764115

Epoch: 5| Step: 8
Training loss: 3.0904836654663086
Validation loss: 2.7727286636188464

Epoch: 5| Step: 9
Training loss: 2.969351291656494
Validation loss: 2.7765845970440934

Epoch: 5| Step: 10
Training loss: 3.0779666900634766
Validation loss: 2.773793552511482

Epoch: 27| Step: 0
Training loss: 2.7589478492736816
Validation loss: 2.772912617652647

Epoch: 5| Step: 1
Training loss: 2.9145398139953613
Validation loss: 2.7731700328088578

Epoch: 5| Step: 2
Training loss: 2.078227996826172
Validation loss: 2.7688720892834406

Epoch: 5| Step: 3
Training loss: 2.6416561603546143
Validation loss: 2.763055065626739

Epoch: 5| Step: 4
Training loss: 3.4300975799560547
Validation loss: 2.7565614228607505

Epoch: 5| Step: 5
Training loss: 3.230958938598633
Validation loss: 2.753521421904205

Epoch: 5| Step: 6
Training loss: 3.4064059257507324
Validation loss: 2.7526507505806546

Epoch: 5| Step: 7
Training loss: 3.1451926231384277
Validation loss: 2.751634000450052

Epoch: 5| Step: 8
Training loss: 2.312709331512451
Validation loss: 2.752358716021302

Epoch: 5| Step: 9
Training loss: 3.1575732231140137
Validation loss: 2.751381999702864

Epoch: 5| Step: 10
Training loss: 2.9408464431762695
Validation loss: 2.749693444980088

Epoch: 28| Step: 0
Training loss: 2.9242491722106934
Validation loss: 2.7476791976600565

Epoch: 5| Step: 1
Training loss: 3.006350040435791
Validation loss: 2.7426507037173034

Epoch: 5| Step: 2
Training loss: 3.5230095386505127
Validation loss: 2.738211193392354

Epoch: 5| Step: 3
Training loss: 2.197071075439453
Validation loss: 2.7348828956645024

Epoch: 5| Step: 4
Training loss: 3.8097050189971924
Validation loss: 2.7350503013980005

Epoch: 5| Step: 5
Training loss: 2.4720396995544434
Validation loss: 2.7326480496314263

Epoch: 5| Step: 6
Training loss: 3.2762908935546875
Validation loss: 2.7343195894713044

Epoch: 5| Step: 7
Training loss: 2.8339412212371826
Validation loss: 2.7292004785230084

Epoch: 5| Step: 8
Training loss: 2.2195944786071777
Validation loss: 2.731261694303123

Epoch: 5| Step: 9
Training loss: 2.5122337341308594
Validation loss: 2.7309789734501995

Epoch: 5| Step: 10
Training loss: 3.113290786743164
Validation loss: 2.7391021456769717

Epoch: 29| Step: 0
Training loss: 3.021775484085083
Validation loss: 2.740581609869516

Epoch: 5| Step: 1
Training loss: 3.0176825523376465
Validation loss: 2.740865768924836

Epoch: 5| Step: 2
Training loss: 2.6053364276885986
Validation loss: 2.7374486282307613

Epoch: 5| Step: 3
Training loss: 2.7781758308410645
Validation loss: 2.738575073980516

Epoch: 5| Step: 4
Training loss: 3.0595812797546387
Validation loss: 2.7427902939499065

Epoch: 5| Step: 5
Training loss: 2.759276866912842
Validation loss: 2.756510408975745

Epoch: 5| Step: 6
Training loss: 2.9128105640411377
Validation loss: 2.7797757271797425

Epoch: 5| Step: 7
Training loss: 2.513554573059082
Validation loss: 2.7901015896951

Epoch: 5| Step: 8
Training loss: 3.8559765815734863
Validation loss: 2.7902100624576693

Epoch: 5| Step: 9
Training loss: 2.6552681922912598
Validation loss: 2.7573898018047376

Epoch: 5| Step: 10
Training loss: 2.5282914638519287
Validation loss: 2.737591030777142

Epoch: 30| Step: 0
Training loss: 2.603529691696167
Validation loss: 2.7296434858793854

Epoch: 5| Step: 1
Training loss: 2.580639600753784
Validation loss: 2.730906778766263

Epoch: 5| Step: 2
Training loss: 3.7069382667541504
Validation loss: 2.7305201997039137

Epoch: 5| Step: 3
Training loss: 2.763810396194458
Validation loss: 2.727355408412154

Epoch: 5| Step: 4
Training loss: 2.608031749725342
Validation loss: 2.728760859017731

Epoch: 5| Step: 5
Training loss: 3.0574440956115723
Validation loss: 2.7296962122763357

Epoch: 5| Step: 6
Training loss: 2.7425005435943604
Validation loss: 2.73042280186889

Epoch: 5| Step: 7
Training loss: 3.2009472846984863
Validation loss: 2.733056681130522

Epoch: 5| Step: 8
Training loss: 2.874300718307495
Validation loss: 2.7294159576457035

Epoch: 5| Step: 9
Training loss: 2.6888856887817383
Validation loss: 2.728693159677649

Epoch: 5| Step: 10
Training loss: 2.9212772846221924
Validation loss: 2.727507560483871

Epoch: 31| Step: 0
Training loss: 2.246431589126587
Validation loss: 2.724356569269652

Epoch: 5| Step: 1
Training loss: 3.401454210281372
Validation loss: 2.7230289418210267

Epoch: 5| Step: 2
Training loss: 2.5579826831817627
Validation loss: 2.7219781132154566

Epoch: 5| Step: 3
Training loss: 3.359117031097412
Validation loss: 2.720504140341154

Epoch: 5| Step: 4
Training loss: 3.346625566482544
Validation loss: 2.719959082141999

Epoch: 5| Step: 5
Training loss: 2.365974187850952
Validation loss: 2.7194538680456017

Epoch: 5| Step: 6
Training loss: 2.801018476486206
Validation loss: 2.721462457410751

Epoch: 5| Step: 7
Training loss: 2.888735294342041
Validation loss: 2.7558557910303914

Epoch: 5| Step: 8
Training loss: 2.6980996131896973
Validation loss: 2.7337329464574016

Epoch: 5| Step: 9
Training loss: 3.2253997325897217
Validation loss: 2.7393106029879664

Epoch: 5| Step: 10
Training loss: 2.7924556732177734
Validation loss: 2.742755756583265

Epoch: 32| Step: 0
Training loss: 2.465737819671631
Validation loss: 2.7444374125490905

Epoch: 5| Step: 1
Training loss: 2.779770612716675
Validation loss: 2.738454254724646

Epoch: 5| Step: 2
Training loss: 2.601820468902588
Validation loss: 2.737177341215072

Epoch: 5| Step: 3
Training loss: 2.959653377532959
Validation loss: 2.7367504771037767

Epoch: 5| Step: 4
Training loss: 3.4543373584747314
Validation loss: 2.7365707018042125

Epoch: 5| Step: 5
Training loss: 2.414743661880493
Validation loss: 2.734723557708084

Epoch: 5| Step: 6
Training loss: 2.99782657623291
Validation loss: 2.732646685774608

Epoch: 5| Step: 7
Training loss: 2.580170154571533
Validation loss: 2.7333263966345016

Epoch: 5| Step: 8
Training loss: 3.361407518386841
Validation loss: 2.7351403056934314

Epoch: 5| Step: 9
Training loss: 3.3729248046875
Validation loss: 2.7358198088984333

Epoch: 5| Step: 10
Training loss: 2.53405499458313
Validation loss: 2.7241036481754755

Epoch: 33| Step: 0
Training loss: 3.098323345184326
Validation loss: 2.7148494079548824

Epoch: 5| Step: 1
Training loss: 2.7209129333496094
Validation loss: 2.7196959782672185

Epoch: 5| Step: 2
Training loss: 3.442319869995117
Validation loss: 2.734538791000202

Epoch: 5| Step: 3
Training loss: 3.266671657562256
Validation loss: 2.7421846415406916

Epoch: 5| Step: 4
Training loss: 1.9657148122787476
Validation loss: 2.748176982325892

Epoch: 5| Step: 5
Training loss: 2.8036677837371826
Validation loss: 2.7602628969377085

Epoch: 5| Step: 6
Training loss: 3.054548740386963
Validation loss: 2.7478875754981913

Epoch: 5| Step: 7
Training loss: 2.8147921562194824
Validation loss: 2.724022493567518

Epoch: 5| Step: 8
Training loss: 2.9288642406463623
Validation loss: 2.7103333191205095

Epoch: 5| Step: 9
Training loss: 2.360266923904419
Validation loss: 2.7055575052897134

Epoch: 5| Step: 10
Training loss: 3.054067850112915
Validation loss: 2.7038892494734896

Epoch: 34| Step: 0
Training loss: 3.146653175354004
Validation loss: 2.7046880875864336

Epoch: 5| Step: 1
Training loss: 3.3481361865997314
Validation loss: 2.709872522661763

Epoch: 5| Step: 2
Training loss: 2.010239362716675
Validation loss: 2.7081736339035856

Epoch: 5| Step: 3
Training loss: 3.2039895057678223
Validation loss: 2.7043318415200837

Epoch: 5| Step: 4
Training loss: 3.2768356800079346
Validation loss: 2.707160470306232

Epoch: 5| Step: 5
Training loss: 2.455414295196533
Validation loss: 2.704840470385808

Epoch: 5| Step: 6
Training loss: 2.5197596549987793
Validation loss: 2.7048480818348546

Epoch: 5| Step: 7
Training loss: 2.3363442420959473
Validation loss: 2.7073702786558416

Epoch: 5| Step: 8
Training loss: 2.762923240661621
Validation loss: 2.703491680083736

Epoch: 5| Step: 9
Training loss: 2.9908509254455566
Validation loss: 2.699266659316196

Epoch: 5| Step: 10
Training loss: 3.4539871215820312
Validation loss: 2.6978638505422943

Epoch: 35| Step: 0
Training loss: 2.975080966949463
Validation loss: 2.6935976397606636

Epoch: 5| Step: 1
Training loss: 2.5295162200927734
Validation loss: 2.6950722663633284

Epoch: 5| Step: 2
Training loss: 2.3723292350769043
Validation loss: 2.700346234024212

Epoch: 5| Step: 3
Training loss: 2.082085132598877
Validation loss: 2.7188343181405017

Epoch: 5| Step: 4
Training loss: 2.8099048137664795
Validation loss: 2.7617532437847507

Epoch: 5| Step: 5
Training loss: 2.89003324508667
Validation loss: 2.77173210472189

Epoch: 5| Step: 6
Training loss: 3.228426456451416
Validation loss: 2.7238545981786584

Epoch: 5| Step: 7
Training loss: 3.1482291221618652
Validation loss: 2.7052653143482823

Epoch: 5| Step: 8
Training loss: 2.511312961578369
Validation loss: 2.6956333344982517

Epoch: 5| Step: 9
Training loss: 3.0717759132385254
Validation loss: 2.6857671917125745

Epoch: 5| Step: 10
Training loss: 3.717888116836548
Validation loss: 2.686344018546484

Epoch: 36| Step: 0
Training loss: 2.877153158187866
Validation loss: 2.689650163855604

Epoch: 5| Step: 1
Training loss: 2.7894856929779053
Validation loss: 2.7239267723534697

Epoch: 5| Step: 2
Training loss: 3.3639283180236816
Validation loss: 2.785310947766868

Epoch: 5| Step: 3
Training loss: 2.6402430534362793
Validation loss: 2.739158045861029

Epoch: 5| Step: 4
Training loss: 2.713146924972534
Validation loss: 2.695550905760898

Epoch: 5| Step: 5
Training loss: 2.2657957077026367
Validation loss: 2.688555553395261

Epoch: 5| Step: 6
Training loss: 2.940089702606201
Validation loss: 2.6870409621987292

Epoch: 5| Step: 7
Training loss: 2.8673195838928223
Validation loss: 2.6824136472517446

Epoch: 5| Step: 8
Training loss: 2.8913984298706055
Validation loss: 2.687495708465576

Epoch: 5| Step: 9
Training loss: 3.1463820934295654
Validation loss: 2.695911822780486

Epoch: 5| Step: 10
Training loss: 3.015580415725708
Validation loss: 2.719177640894408

Epoch: 37| Step: 0
Training loss: 2.584218740463257
Validation loss: 2.716475655955653

Epoch: 5| Step: 1
Training loss: 2.728163242340088
Validation loss: 2.6968471721936296

Epoch: 5| Step: 2
Training loss: 2.7619404792785645
Validation loss: 2.690756090225712

Epoch: 5| Step: 3
Training loss: 2.6903414726257324
Validation loss: 2.6872385958189606

Epoch: 5| Step: 4
Training loss: 3.0977931022644043
Validation loss: 2.6850651464154645

Epoch: 5| Step: 5
Training loss: 1.9817520380020142
Validation loss: 2.6843458247441117

Epoch: 5| Step: 6
Training loss: 3.3791542053222656
Validation loss: 2.6790868646355084

Epoch: 5| Step: 7
Training loss: 2.94035005569458
Validation loss: 2.6733269332557597

Epoch: 5| Step: 8
Training loss: 3.275477647781372
Validation loss: 2.6722951448091896

Epoch: 5| Step: 9
Training loss: 2.4402270317077637
Validation loss: 2.6697210214471303

Epoch: 5| Step: 10
Training loss: 3.276305675506592
Validation loss: 2.666616775656259

Epoch: 38| Step: 0
Training loss: 2.067115306854248
Validation loss: 2.6698492829517653

Epoch: 5| Step: 1
Training loss: 2.58225417137146
Validation loss: 2.6682212634753157

Epoch: 5| Step: 2
Training loss: 3.6534264087677
Validation loss: 2.6712314749276764

Epoch: 5| Step: 3
Training loss: 2.764305830001831
Validation loss: 2.670452143556328

Epoch: 5| Step: 4
Training loss: 1.8460553884506226
Validation loss: 2.668664127267817

Epoch: 5| Step: 5
Training loss: 2.738901138305664
Validation loss: 2.6660796852521997

Epoch: 5| Step: 6
Training loss: 3.083160877227783
Validation loss: 2.6624842843701764

Epoch: 5| Step: 7
Training loss: 3.6366379261016846
Validation loss: 2.6617547004453597

Epoch: 5| Step: 8
Training loss: 2.7494475841522217
Validation loss: 2.6565658277080906

Epoch: 5| Step: 9
Training loss: 3.1898109912872314
Validation loss: 2.658864116155973

Epoch: 5| Step: 10
Training loss: 2.6820225715637207
Validation loss: 2.6640602465598815

Epoch: 39| Step: 0
Training loss: 3.10060977935791
Validation loss: 2.6565776794187483

Epoch: 5| Step: 1
Training loss: 2.7201461791992188
Validation loss: 2.6561323647857993

Epoch: 5| Step: 2
Training loss: 2.7167458534240723
Validation loss: 2.652611904246833

Epoch: 5| Step: 3
Training loss: 2.9391727447509766
Validation loss: 2.6510810185504217

Epoch: 5| Step: 4
Training loss: 3.0583302974700928
Validation loss: 2.6502299257504043

Epoch: 5| Step: 5
Training loss: 2.7052981853485107
Validation loss: 2.655778141431911

Epoch: 5| Step: 6
Training loss: 2.102116346359253
Validation loss: 2.651964479877103

Epoch: 5| Step: 7
Training loss: 2.646505832672119
Validation loss: 2.6486760672702583

Epoch: 5| Step: 8
Training loss: 2.850679874420166
Validation loss: 2.6490913616713656

Epoch: 5| Step: 9
Training loss: 2.9952468872070312
Validation loss: 2.6468467302219842

Epoch: 5| Step: 10
Training loss: 3.0261130332946777
Validation loss: 2.65090363512757

Epoch: 40| Step: 0
Training loss: 2.296888828277588
Validation loss: 2.654551395805933

Epoch: 5| Step: 1
Training loss: 2.383518695831299
Validation loss: 2.6552851738468295

Epoch: 5| Step: 2
Training loss: 2.8787682056427
Validation loss: 2.646536934760309

Epoch: 5| Step: 3
Training loss: 2.934274673461914
Validation loss: 2.642994652512253

Epoch: 5| Step: 4
Training loss: 3.0559442043304443
Validation loss: 2.6410338288994244

Epoch: 5| Step: 5
Training loss: 3.426492214202881
Validation loss: 2.6434014997174664

Epoch: 5| Step: 6
Training loss: 3.0921082496643066
Validation loss: 2.642700018421296

Epoch: 5| Step: 7
Training loss: 2.7174277305603027
Validation loss: 2.641234051796698

Epoch: 5| Step: 8
Training loss: 2.1279094219207764
Validation loss: 2.6433784654063563

Epoch: 5| Step: 9
Training loss: 2.6804263591766357
Validation loss: 2.640537913127612

Epoch: 5| Step: 10
Training loss: 3.322434902191162
Validation loss: 2.6396327352011077

Epoch: 41| Step: 0
Training loss: 2.7141871452331543
Validation loss: 2.647348755149431

Epoch: 5| Step: 1
Training loss: 2.8340630531311035
Validation loss: 2.6554063212487007

Epoch: 5| Step: 2
Training loss: 3.033385753631592
Validation loss: 2.662097043888543

Epoch: 5| Step: 3
Training loss: 2.8940422534942627
Validation loss: 2.669122470322476

Epoch: 5| Step: 4
Training loss: 2.5514769554138184
Validation loss: 2.6692039376945904

Epoch: 5| Step: 5
Training loss: 3.3111045360565186
Validation loss: 2.662000076745146

Epoch: 5| Step: 6
Training loss: 2.170311212539673
Validation loss: 2.660714513512068

Epoch: 5| Step: 7
Training loss: 2.6494221687316895
Validation loss: 2.6576297283172607

Epoch: 5| Step: 8
Training loss: 2.3769466876983643
Validation loss: 2.656466381524199

Epoch: 5| Step: 9
Training loss: 2.8195934295654297
Validation loss: 2.643640697643321

Epoch: 5| Step: 10
Training loss: 3.6394200325012207
Validation loss: 2.6340606045979325

Epoch: 42| Step: 0
Training loss: 2.851245164871216
Validation loss: 2.6333178320238666

Epoch: 5| Step: 1
Training loss: 3.135413408279419
Validation loss: 2.6341803253337903

Epoch: 5| Step: 2
Training loss: 2.8993570804595947
Validation loss: 2.6388889692162953

Epoch: 5| Step: 3
Training loss: 2.4542236328125
Validation loss: 2.6412507487881567

Epoch: 5| Step: 4
Training loss: 3.0028045177459717
Validation loss: 2.6418875712220387

Epoch: 5| Step: 5
Training loss: 2.9379525184631348
Validation loss: 2.638987536071449

Epoch: 5| Step: 6
Training loss: 3.0457558631896973
Validation loss: 2.640793877263223

Epoch: 5| Step: 7
Training loss: 2.4678890705108643
Validation loss: 2.635762631252248

Epoch: 5| Step: 8
Training loss: 2.542750835418701
Validation loss: 2.6337889932817027

Epoch: 5| Step: 9
Training loss: 2.6171538829803467
Validation loss: 2.6304944817737868

Epoch: 5| Step: 10
Training loss: 2.89410138130188
Validation loss: 2.6232259709347963

Epoch: 43| Step: 0
Training loss: 3.0487866401672363
Validation loss: 2.6296691074166247

Epoch: 5| Step: 1
Training loss: 3.119061231613159
Validation loss: 2.639119166199879

Epoch: 5| Step: 2
Training loss: 2.6106388568878174
Validation loss: 2.6444638416331303

Epoch: 5| Step: 3
Training loss: 2.5787622928619385
Validation loss: 2.6447022063757784

Epoch: 5| Step: 4
Training loss: 2.7905452251434326
Validation loss: 2.6564277141324935

Epoch: 5| Step: 5
Training loss: 2.6654434204101562
Validation loss: 2.654545548141644

Epoch: 5| Step: 6
Training loss: 3.174349308013916
Validation loss: 2.647890470361197

Epoch: 5| Step: 7
Training loss: 2.353661060333252
Validation loss: 2.6421087095814366

Epoch: 5| Step: 8
Training loss: 2.7944157123565674
Validation loss: 2.637989964536441

Epoch: 5| Step: 9
Training loss: 2.982062816619873
Validation loss: 2.634603915675994

Epoch: 5| Step: 10
Training loss: 2.563600778579712
Validation loss: 2.6234625975290933

Epoch: 44| Step: 0
Training loss: 2.391007661819458
Validation loss: 2.6255820669153684

Epoch: 5| Step: 1
Training loss: 3.081573963165283
Validation loss: 2.6209488171403126

Epoch: 5| Step: 2
Training loss: 3.2623493671417236
Validation loss: 2.6211758941732426

Epoch: 5| Step: 3
Training loss: 2.4051477909088135
Validation loss: 2.6184756345646356

Epoch: 5| Step: 4
Training loss: 2.126814365386963
Validation loss: 2.617132338144446

Epoch: 5| Step: 5
Training loss: 2.754434585571289
Validation loss: 2.614476719210225

Epoch: 5| Step: 6
Training loss: 2.913958787918091
Validation loss: 2.6153787156587005

Epoch: 5| Step: 7
Training loss: 3.192110776901245
Validation loss: 2.614391211540468

Epoch: 5| Step: 8
Training loss: 2.8612632751464844
Validation loss: 2.6124264655574674

Epoch: 5| Step: 9
Training loss: 2.907440423965454
Validation loss: 2.6152953229924685

Epoch: 5| Step: 10
Training loss: 2.612255811691284
Validation loss: 2.6169928273847027

Epoch: 45| Step: 0
Training loss: 2.182140588760376
Validation loss: 2.6193197670803277

Epoch: 5| Step: 1
Training loss: 2.526689052581787
Validation loss: 2.6240224581892773

Epoch: 5| Step: 2
Training loss: 2.3835623264312744
Validation loss: 2.620584821188322

Epoch: 5| Step: 3
Training loss: 2.6361565589904785
Validation loss: 2.63273343219552

Epoch: 5| Step: 4
Training loss: 2.4464173316955566
Validation loss: 2.6242626251712924

Epoch: 5| Step: 5
Training loss: 2.978433132171631
Validation loss: 2.6262163756996073

Epoch: 5| Step: 6
Training loss: 3.1586573123931885
Validation loss: 2.625206062870641

Epoch: 5| Step: 7
Training loss: 2.9826903343200684
Validation loss: 2.6369033808349283

Epoch: 5| Step: 8
Training loss: 3.10896372795105
Validation loss: 2.626111533052178

Epoch: 5| Step: 9
Training loss: 3.4560012817382812
Validation loss: 2.62082863110368

Epoch: 5| Step: 10
Training loss: 2.6117520332336426
Validation loss: 2.6126222507928007

Epoch: 46| Step: 0
Training loss: 2.869396686553955
Validation loss: 2.603717101517544

Epoch: 5| Step: 1
Training loss: 3.6700291633605957
Validation loss: 2.607592580138996

Epoch: 5| Step: 2
Training loss: 2.6659634113311768
Validation loss: 2.6041137864512782

Epoch: 5| Step: 3
Training loss: 2.0690360069274902
Validation loss: 2.6057847469083724

Epoch: 5| Step: 4
Training loss: 2.9183151721954346
Validation loss: 2.606241146723429

Epoch: 5| Step: 5
Training loss: 2.4691925048828125
Validation loss: 2.6040915673778904

Epoch: 5| Step: 6
Training loss: 3.3010716438293457
Validation loss: 2.610133853009952

Epoch: 5| Step: 7
Training loss: 3.012653350830078
Validation loss: 2.624122752938219

Epoch: 5| Step: 8
Training loss: 2.6505017280578613
Validation loss: 2.6291958285916235

Epoch: 5| Step: 9
Training loss: 2.9203333854675293
Validation loss: 2.6285797114013345

Epoch: 5| Step: 10
Training loss: 1.7154014110565186
Validation loss: 2.633127015124085

Epoch: 47| Step: 0
Training loss: 2.334953784942627
Validation loss: 2.628757410151984

Epoch: 5| Step: 1
Training loss: 3.1125106811523438
Validation loss: 2.6150507798758884

Epoch: 5| Step: 2
Training loss: 3.1042227745056152
Validation loss: 2.5993261901281213

Epoch: 5| Step: 3
Training loss: 2.7592616081237793
Validation loss: 2.59520403287744

Epoch: 5| Step: 4
Training loss: 3.18056058883667
Validation loss: 2.5935571937150854

Epoch: 5| Step: 5
Training loss: 2.28360652923584
Validation loss: 2.589843278290123

Epoch: 5| Step: 6
Training loss: 2.4349589347839355
Validation loss: 2.590096542912145

Epoch: 5| Step: 7
Training loss: 3.0412230491638184
Validation loss: 2.589331808910575

Epoch: 5| Step: 8
Training loss: 2.477015733718872
Validation loss: 2.5887022172251055

Epoch: 5| Step: 9
Training loss: 2.2582266330718994
Validation loss: 2.5866509201706096

Epoch: 5| Step: 10
Training loss: 3.4863104820251465
Validation loss: 2.5863396403610066

Epoch: 48| Step: 0
Training loss: 2.035257577896118
Validation loss: 2.586462220837993

Epoch: 5| Step: 1
Training loss: 3.0899367332458496
Validation loss: 2.58615485442582

Epoch: 5| Step: 2
Training loss: 2.787482976913452
Validation loss: 2.586332872349729

Epoch: 5| Step: 3
Training loss: 2.397536516189575
Validation loss: 2.592582771855016

Epoch: 5| Step: 4
Training loss: 2.259976387023926
Validation loss: 2.593116177025662

Epoch: 5| Step: 5
Training loss: 2.698564052581787
Validation loss: 2.60741731684695

Epoch: 5| Step: 6
Training loss: 3.381350040435791
Validation loss: 2.6084747545180784

Epoch: 5| Step: 7
Training loss: 3.0986812114715576
Validation loss: 2.605127211539976

Epoch: 5| Step: 8
Training loss: 3.1027607917785645
Validation loss: 2.602240408620527

Epoch: 5| Step: 9
Training loss: 2.5088443756103516
Validation loss: 2.589865758854856

Epoch: 5| Step: 10
Training loss: 3.0480215549468994
Validation loss: 2.581843973487936

Epoch: 49| Step: 0
Training loss: 2.891383171081543
Validation loss: 2.5798306234421267

Epoch: 5| Step: 1
Training loss: 2.4612185955047607
Validation loss: 2.5784997478608163

Epoch: 5| Step: 2
Training loss: 3.2204480171203613
Validation loss: 2.5793226585593274

Epoch: 5| Step: 3
Training loss: 2.629049301147461
Validation loss: 2.5790880418592885

Epoch: 5| Step: 4
Training loss: 2.77561616897583
Validation loss: 2.577140441504858

Epoch: 5| Step: 5
Training loss: 2.401111125946045
Validation loss: 2.578888782890894

Epoch: 5| Step: 6
Training loss: 2.6692614555358887
Validation loss: 2.575936660971693

Epoch: 5| Step: 7
Training loss: 3.279449939727783
Validation loss: 2.57359238337445

Epoch: 5| Step: 8
Training loss: 2.203460216522217
Validation loss: 2.5754097687300814

Epoch: 5| Step: 9
Training loss: 2.647918701171875
Validation loss: 2.5736960723835933

Epoch: 5| Step: 10
Training loss: 3.125528335571289
Validation loss: 2.573065878242575

Epoch: 50| Step: 0
Training loss: 3.0006284713745117
Validation loss: 2.5776889901007376

Epoch: 5| Step: 1
Training loss: 3.163954496383667
Validation loss: 2.5766553391692457

Epoch: 5| Step: 2
Training loss: 2.466130495071411
Validation loss: 2.576055931788619

Epoch: 5| Step: 3
Training loss: 2.4517972469329834
Validation loss: 2.577675860415223

Epoch: 5| Step: 4
Training loss: 1.9078056812286377
Validation loss: 2.5792474721067693

Epoch: 5| Step: 5
Training loss: 2.4664103984832764
Validation loss: 2.57853429548202

Epoch: 5| Step: 6
Training loss: 3.471417188644409
Validation loss: 2.5746297887576524

Epoch: 5| Step: 7
Training loss: 3.021994113922119
Validation loss: 2.567150790204284

Epoch: 5| Step: 8
Training loss: 2.6879210472106934
Validation loss: 2.567346619021508

Epoch: 5| Step: 9
Training loss: 2.751039505004883
Validation loss: 2.566399989589568

Epoch: 5| Step: 10
Training loss: 2.7767333984375
Validation loss: 2.562444599725867

Epoch: 51| Step: 0
Training loss: 2.443319797515869
Validation loss: 2.561181483730193

Epoch: 5| Step: 1
Training loss: 2.139954090118408
Validation loss: 2.5633858583306752

Epoch: 5| Step: 2
Training loss: 2.9695751667022705
Validation loss: 2.5599770956141974

Epoch: 5| Step: 3
Training loss: 2.482541561126709
Validation loss: 2.5614282290140786

Epoch: 5| Step: 4
Training loss: 2.7930328845977783
Validation loss: 2.558771558987197

Epoch: 5| Step: 5
Training loss: 3.3631796836853027
Validation loss: 2.5577097579997075

Epoch: 5| Step: 6
Training loss: 3.5207512378692627
Validation loss: 2.558262289211314

Epoch: 5| Step: 7
Training loss: 2.874330997467041
Validation loss: 2.5594487831156743

Epoch: 5| Step: 8
Training loss: 1.759169340133667
Validation loss: 2.5677589780540875

Epoch: 5| Step: 9
Training loss: 2.868928909301758
Validation loss: 2.5697174431175314

Epoch: 5| Step: 10
Training loss: 2.9157958030700684
Validation loss: 2.5627291587091263

Epoch: 52| Step: 0
Training loss: 3.2601044178009033
Validation loss: 2.559025038955032

Epoch: 5| Step: 1
Training loss: 2.8610446453094482
Validation loss: 2.557941508549516

Epoch: 5| Step: 2
Training loss: 2.4560742378234863
Validation loss: 2.55494107994982

Epoch: 5| Step: 3
Training loss: 2.2380285263061523
Validation loss: 2.5549997693748883

Epoch: 5| Step: 4
Training loss: 2.861940860748291
Validation loss: 2.553986249431487

Epoch: 5| Step: 5
Training loss: 2.6749107837677
Validation loss: 2.5514636834462485

Epoch: 5| Step: 6
Training loss: 2.8799514770507812
Validation loss: 2.5491396739918697

Epoch: 5| Step: 7
Training loss: 2.3217310905456543
Validation loss: 2.551137464020842

Epoch: 5| Step: 8
Training loss: 3.5868427753448486
Validation loss: 2.553451039457834

Epoch: 5| Step: 9
Training loss: 2.720423936843872
Validation loss: 2.5507636429161153

Epoch: 5| Step: 10
Training loss: 2.039743423461914
Validation loss: 2.551204481432515

Epoch: 53| Step: 0
Training loss: 3.160177230834961
Validation loss: 2.547824316127326

Epoch: 5| Step: 1
Training loss: 2.9319472312927246
Validation loss: 2.549432541734429

Epoch: 5| Step: 2
Training loss: 3.1363844871520996
Validation loss: 2.5439674649187314

Epoch: 5| Step: 3
Training loss: 2.492232084274292
Validation loss: 2.5458239022121636

Epoch: 5| Step: 4
Training loss: 2.283738613128662
Validation loss: 2.547413815734207

Epoch: 5| Step: 5
Training loss: 3.3812217712402344
Validation loss: 2.5486872324379544

Epoch: 5| Step: 6
Training loss: 2.2088961601257324
Validation loss: 2.5467637738873883

Epoch: 5| Step: 7
Training loss: 3.283367156982422
Validation loss: 2.549975370848051

Epoch: 5| Step: 8
Training loss: 2.89284086227417
Validation loss: 2.568674382343087

Epoch: 5| Step: 9
Training loss: 1.832209825515747
Validation loss: 2.5741948466147146

Epoch: 5| Step: 10
Training loss: 2.3625128269195557
Validation loss: 2.579504792408277

Epoch: 54| Step: 0
Training loss: 3.3590686321258545
Validation loss: 2.5702828361142065

Epoch: 5| Step: 1
Training loss: 2.121833086013794
Validation loss: 2.568230329021331

Epoch: 5| Step: 2
Training loss: 1.917127013206482
Validation loss: 2.5715643193132136

Epoch: 5| Step: 3
Training loss: 2.434448719024658
Validation loss: 2.5799640635008454

Epoch: 5| Step: 4
Training loss: 2.7900142669677734
Validation loss: 2.5710117842561457

Epoch: 5| Step: 5
Training loss: 2.498731851577759
Validation loss: 2.555653913046724

Epoch: 5| Step: 6
Training loss: 2.665989875793457
Validation loss: 2.545719254401422

Epoch: 5| Step: 7
Training loss: 3.090097665786743
Validation loss: 2.5400032945858535

Epoch: 5| Step: 8
Training loss: 2.998377799987793
Validation loss: 2.53270790653844

Epoch: 5| Step: 9
Training loss: 2.9310717582702637
Validation loss: 2.5349436575366604

Epoch: 5| Step: 10
Training loss: 3.311372756958008
Validation loss: 2.537821718441543

Epoch: 55| Step: 0
Training loss: 2.7926886081695557
Validation loss: 2.5331034250156854

Epoch: 5| Step: 1
Training loss: 3.2861733436584473
Validation loss: 2.529937349339967

Epoch: 5| Step: 2
Training loss: 2.440556764602661
Validation loss: 2.5309967687053065

Epoch: 5| Step: 3
Training loss: 1.724011778831482
Validation loss: 2.5363625121373

Epoch: 5| Step: 4
Training loss: 2.614408493041992
Validation loss: 2.5325427209177325

Epoch: 5| Step: 5
Training loss: 2.7520503997802734
Validation loss: 2.5357198894664807

Epoch: 5| Step: 6
Training loss: 3.127655029296875
Validation loss: 2.5354063510894775

Epoch: 5| Step: 7
Training loss: 1.9418306350708008
Validation loss: 2.538820691006158

Epoch: 5| Step: 8
Training loss: 3.2129712104797363
Validation loss: 2.536394921682214

Epoch: 5| Step: 9
Training loss: 2.7929916381835938
Validation loss: 2.54484982644358

Epoch: 5| Step: 10
Training loss: 3.2785229682922363
Validation loss: 2.550758518198485

Epoch: 56| Step: 0
Training loss: 3.1085193157196045
Validation loss: 2.5503708162615375

Epoch: 5| Step: 1
Training loss: 3.0901455879211426
Validation loss: 2.551689285103993

Epoch: 5| Step: 2
Training loss: 2.7789199352264404
Validation loss: 2.5510756559269403

Epoch: 5| Step: 3
Training loss: 2.1668713092803955
Validation loss: 2.54069100400453

Epoch: 5| Step: 4
Training loss: 2.9573440551757812
Validation loss: 2.5237553760569584

Epoch: 5| Step: 5
Training loss: 2.283221483230591
Validation loss: 2.526148990918231

Epoch: 5| Step: 6
Training loss: 3.382525682449341
Validation loss: 2.5208266653040403

Epoch: 5| Step: 7
Training loss: 1.878838300704956
Validation loss: 2.522014169282811

Epoch: 5| Step: 8
Training loss: 3.2614810466766357
Validation loss: 2.520862338363483

Epoch: 5| Step: 9
Training loss: 2.347280502319336
Validation loss: 2.5225874711108465

Epoch: 5| Step: 10
Training loss: 2.538224220275879
Validation loss: 2.5239434806249474

Epoch: 57| Step: 0
Training loss: 3.0365982055664062
Validation loss: 2.525884428331929

Epoch: 5| Step: 1
Training loss: 2.048273801803589
Validation loss: 2.5274330467306156

Epoch: 5| Step: 2
Training loss: 2.0388641357421875
Validation loss: 2.5241154316932923

Epoch: 5| Step: 3
Training loss: 3.1891016960144043
Validation loss: 2.5197579886323664

Epoch: 5| Step: 4
Training loss: 2.9479739665985107
Validation loss: 2.5169031850753294

Epoch: 5| Step: 5
Training loss: 2.483870029449463
Validation loss: 2.5153487959215717

Epoch: 5| Step: 6
Training loss: 2.6427695751190186
Validation loss: 2.5250353838807795

Epoch: 5| Step: 7
Training loss: 2.876115560531616
Validation loss: 2.523206546742429

Epoch: 5| Step: 8
Training loss: 3.052682638168335
Validation loss: 2.5293928628326743

Epoch: 5| Step: 9
Training loss: 2.747152805328369
Validation loss: 2.5330854615857525

Epoch: 5| Step: 10
Training loss: 2.6983585357666016
Validation loss: 2.5275860114764144

Epoch: 58| Step: 0
Training loss: 2.9791388511657715
Validation loss: 2.5474140413345827

Epoch: 5| Step: 1
Training loss: 2.8275821208953857
Validation loss: 2.546127829500424

Epoch: 5| Step: 2
Training loss: 2.8059182167053223
Validation loss: 2.542037917721656

Epoch: 5| Step: 3
Training loss: 3.2569777965545654
Validation loss: 2.531200211535218

Epoch: 5| Step: 4
Training loss: 2.9358954429626465
Validation loss: 2.521384016160042

Epoch: 5| Step: 5
Training loss: 2.0523743629455566
Validation loss: 2.5134588313359085

Epoch: 5| Step: 6
Training loss: 2.741774797439575
Validation loss: 2.503990022085046

Epoch: 5| Step: 7
Training loss: 2.606790542602539
Validation loss: 2.5059830116969284

Epoch: 5| Step: 8
Training loss: 2.657590866088867
Validation loss: 2.511709346566149

Epoch: 5| Step: 9
Training loss: 1.9327986240386963
Validation loss: 2.5123416582743325

Epoch: 5| Step: 10
Training loss: 3.1083154678344727
Validation loss: 2.5106467072681715

Epoch: 59| Step: 0
Training loss: 2.616725206375122
Validation loss: 2.516658890631891

Epoch: 5| Step: 1
Training loss: 2.400714635848999
Validation loss: 2.5155225210292365

Epoch: 5| Step: 2
Training loss: 3.4468226432800293
Validation loss: 2.511741186982842

Epoch: 5| Step: 3
Training loss: 2.4759490489959717
Validation loss: 2.5074083317992506

Epoch: 5| Step: 4
Training loss: 2.172600030899048
Validation loss: 2.508468427965718

Epoch: 5| Step: 5
Training loss: 2.442521572113037
Validation loss: 2.5056997422249085

Epoch: 5| Step: 6
Training loss: 2.4548048973083496
Validation loss: 2.5038068063797487

Epoch: 5| Step: 7
Training loss: 3.067525863647461
Validation loss: 2.500337262307444

Epoch: 5| Step: 8
Training loss: 2.9134836196899414
Validation loss: 2.495455353490768

Epoch: 5| Step: 9
Training loss: 2.8845372200012207
Validation loss: 2.5009138712318997

Epoch: 5| Step: 10
Training loss: 2.9252233505249023
Validation loss: 2.5004712227852113

Epoch: 60| Step: 0
Training loss: 2.281994581222534
Validation loss: 2.5073768528558875

Epoch: 5| Step: 1
Training loss: 2.341914653778076
Validation loss: 2.5253748970647014

Epoch: 5| Step: 2
Training loss: 2.3317959308624268
Validation loss: 2.527348779862927

Epoch: 5| Step: 3
Training loss: 2.936662435531616
Validation loss: 2.5223491012409167

Epoch: 5| Step: 4
Training loss: 3.0579090118408203
Validation loss: 2.529717740192208

Epoch: 5| Step: 5
Training loss: 2.857639789581299
Validation loss: 2.525453782850696

Epoch: 5| Step: 6
Training loss: 2.908531665802002
Validation loss: 2.5230683049848004

Epoch: 5| Step: 7
Training loss: 2.701965093612671
Validation loss: 2.5112195220044864

Epoch: 5| Step: 8
Training loss: 3.4123549461364746
Validation loss: 2.5073366011342695

Epoch: 5| Step: 9
Training loss: 2.4510624408721924
Validation loss: 2.500910071916478

Epoch: 5| Step: 10
Training loss: 2.3466460704803467
Validation loss: 2.495083773007957

Epoch: 61| Step: 0
Training loss: 2.454057216644287
Validation loss: 2.4933168785546416

Epoch: 5| Step: 1
Training loss: 2.5850720405578613
Validation loss: 2.4917153850678475

Epoch: 5| Step: 2
Training loss: 3.100684881210327
Validation loss: 2.490694753585323

Epoch: 5| Step: 3
Training loss: 3.319929599761963
Validation loss: 2.491049353794385

Epoch: 5| Step: 4
Training loss: 2.1203227043151855
Validation loss: 2.48986707451523

Epoch: 5| Step: 5
Training loss: 2.8683505058288574
Validation loss: 2.491661428123392

Epoch: 5| Step: 6
Training loss: 2.548734188079834
Validation loss: 2.485582128647835

Epoch: 5| Step: 7
Training loss: 2.7986652851104736
Validation loss: 2.486681648479995

Epoch: 5| Step: 8
Training loss: 2.2407195568084717
Validation loss: 2.4890104750151276

Epoch: 5| Step: 9
Training loss: 2.5154671669006348
Validation loss: 2.4876387760203373

Epoch: 5| Step: 10
Training loss: 3.1243841648101807
Validation loss: 2.482920296730534

Epoch: 62| Step: 0
Training loss: 1.9623420238494873
Validation loss: 2.487808963303925

Epoch: 5| Step: 1
Training loss: 2.8057327270507812
Validation loss: 2.4877620307348107

Epoch: 5| Step: 2
Training loss: 2.5120272636413574
Validation loss: 2.488644992151568

Epoch: 5| Step: 3
Training loss: 2.9132089614868164
Validation loss: 2.4890934523715766

Epoch: 5| Step: 4
Training loss: 3.4398274421691895
Validation loss: 2.4969701331148864

Epoch: 5| Step: 5
Training loss: 3.1325838565826416
Validation loss: 2.503973768603417

Epoch: 5| Step: 6
Training loss: 2.369199752807617
Validation loss: 2.492414297596101

Epoch: 5| Step: 7
Training loss: 2.882387638092041
Validation loss: 2.4833937357830744

Epoch: 5| Step: 8
Training loss: 3.2154126167297363
Validation loss: 2.4764376635192544

Epoch: 5| Step: 9
Training loss: 2.1779417991638184
Validation loss: 2.4873066871396956

Epoch: 5| Step: 10
Training loss: 2.0363094806671143
Validation loss: 2.4824486778628443

Epoch: 63| Step: 0
Training loss: 3.0531933307647705
Validation loss: 2.4894096851348877

Epoch: 5| Step: 1
Training loss: 3.3639323711395264
Validation loss: 2.486407226131808

Epoch: 5| Step: 2
Training loss: 2.1162877082824707
Validation loss: 2.492654149250318

Epoch: 5| Step: 3
Training loss: 3.0380513668060303
Validation loss: 2.4887451125729467

Epoch: 5| Step: 4
Training loss: 2.621215343475342
Validation loss: 2.4911900720288678

Epoch: 5| Step: 5
Training loss: 2.4033515453338623
Validation loss: 2.485658509756929

Epoch: 5| Step: 6
Training loss: 3.2500176429748535
Validation loss: 2.4748700152161303

Epoch: 5| Step: 7
Training loss: 2.741084098815918
Validation loss: 2.472488177719937

Epoch: 5| Step: 8
Training loss: 2.6364121437072754
Validation loss: 2.47994242688661

Epoch: 5| Step: 9
Training loss: 2.39153790473938
Validation loss: 2.487291089950069

Epoch: 5| Step: 10
Training loss: 1.887526512145996
Validation loss: 2.5284448003256195

Epoch: 64| Step: 0
Training loss: 2.8560352325439453
Validation loss: 2.5773394569273917

Epoch: 5| Step: 1
Training loss: 3.285539150238037
Validation loss: 2.601672626310779

Epoch: 5| Step: 2
Training loss: 2.566822052001953
Validation loss: 2.5647506739503596

Epoch: 5| Step: 3
Training loss: 2.7813353538513184
Validation loss: 2.506493132601502

Epoch: 5| Step: 4
Training loss: 2.7820253372192383
Validation loss: 2.4895653058123846

Epoch: 5| Step: 5
Training loss: 2.594453811645508
Validation loss: 2.4726662712712444

Epoch: 5| Step: 6
Training loss: 2.7607035636901855
Validation loss: 2.4724827299835863

Epoch: 5| Step: 7
Training loss: 2.661938428878784
Validation loss: 2.4734646915107645

Epoch: 5| Step: 8
Training loss: 2.319523572921753
Validation loss: 2.4708114798351

Epoch: 5| Step: 9
Training loss: 2.31451678276062
Validation loss: 2.468779117830338

Epoch: 5| Step: 10
Training loss: 2.7855989933013916
Validation loss: 2.4734690086815947

Epoch: 65| Step: 0
Training loss: 2.785745143890381
Validation loss: 2.4760588215243433

Epoch: 5| Step: 1
Training loss: 2.7688541412353516
Validation loss: 2.47959570218158

Epoch: 5| Step: 2
Training loss: 3.0359010696411133
Validation loss: 2.476410419710221

Epoch: 5| Step: 3
Training loss: 2.609222412109375
Validation loss: 2.4817601685882895

Epoch: 5| Step: 4
Training loss: 2.911726474761963
Validation loss: 2.485795808094804

Epoch: 5| Step: 5
Training loss: 1.9737739562988281
Validation loss: 2.479510909767561

Epoch: 5| Step: 6
Training loss: 2.6127781867980957
Validation loss: 2.4758354668976157

Epoch: 5| Step: 7
Training loss: 2.6782941818237305
Validation loss: 2.474583779611895

Epoch: 5| Step: 8
Training loss: 2.81325626373291
Validation loss: 2.4717014489635343

Epoch: 5| Step: 9
Training loss: 2.5359480381011963
Validation loss: 2.467948090645575

Epoch: 5| Step: 10
Training loss: 2.766592025756836
Validation loss: 2.4695113961414625

Epoch: 66| Step: 0
Training loss: 2.5692150592803955
Validation loss: 2.464053184755387

Epoch: 5| Step: 1
Training loss: 2.5852088928222656
Validation loss: 2.4651027161587953

Epoch: 5| Step: 2
Training loss: 2.5219333171844482
Validation loss: 2.4665228320706274

Epoch: 5| Step: 3
Training loss: 2.4531569480895996
Validation loss: 2.4684591421516995

Epoch: 5| Step: 4
Training loss: 2.9362518787384033
Validation loss: 2.4880676166985625

Epoch: 5| Step: 5
Training loss: 2.4700772762298584
Validation loss: 2.488796185421687

Epoch: 5| Step: 6
Training loss: 2.5240635871887207
Validation loss: 2.4881874912528583

Epoch: 5| Step: 7
Training loss: 2.6277856826782227
Validation loss: 2.4894038067069104

Epoch: 5| Step: 8
Training loss: 2.6815898418426514
Validation loss: 2.474884925350066

Epoch: 5| Step: 9
Training loss: 2.976186990737915
Validation loss: 2.4699991800451793

Epoch: 5| Step: 10
Training loss: 3.238795042037964
Validation loss: 2.4618117860568467

Epoch: 67| Step: 0
Training loss: 2.618783473968506
Validation loss: 2.4587828190095964

Epoch: 5| Step: 1
Training loss: 2.7560524940490723
Validation loss: 2.45362340763051

Epoch: 5| Step: 2
Training loss: 2.4854273796081543
Validation loss: 2.455975550477223

Epoch: 5| Step: 3
Training loss: 2.9364190101623535
Validation loss: 2.4598813672219553

Epoch: 5| Step: 4
Training loss: 2.923870086669922
Validation loss: 2.468525873717441

Epoch: 5| Step: 5
Training loss: 3.7605926990509033
Validation loss: 2.4699715888628395

Epoch: 5| Step: 6
Training loss: 2.394303798675537
Validation loss: 2.46250379982815

Epoch: 5| Step: 7
Training loss: 2.4243829250335693
Validation loss: 2.492274404853903

Epoch: 5| Step: 8
Training loss: 2.3393654823303223
Validation loss: 2.539002638991161

Epoch: 5| Step: 9
Training loss: 2.235377073287964
Validation loss: 2.538393715376495

Epoch: 5| Step: 10
Training loss: 2.6647777557373047
Validation loss: 2.509053135430941

Epoch: 68| Step: 0
Training loss: 3.029571533203125
Validation loss: 2.487796985974876

Epoch: 5| Step: 1
Training loss: 3.0829691886901855
Validation loss: 2.4771915840846237

Epoch: 5| Step: 2
Training loss: 2.711365222930908
Validation loss: 2.4690064409727692

Epoch: 5| Step: 3
Training loss: 3.1130118370056152
Validation loss: 2.4518345043223393

Epoch: 5| Step: 4
Training loss: 2.1825897693634033
Validation loss: 2.4481688109777306

Epoch: 5| Step: 5
Training loss: 2.564728260040283
Validation loss: 2.453254417706561

Epoch: 5| Step: 6
Training loss: 3.0765023231506348
Validation loss: 2.4603293685502905

Epoch: 5| Step: 7
Training loss: 2.2321934700012207
Validation loss: 2.4724803688705608

Epoch: 5| Step: 8
Training loss: 2.4747672080993652
Validation loss: 2.4888715513290895

Epoch: 5| Step: 9
Training loss: 2.518063545227051
Validation loss: 2.489156764040711

Epoch: 5| Step: 10
Training loss: 2.5655999183654785
Validation loss: 2.4535083411842264

Epoch: 69| Step: 0
Training loss: 2.4704747200012207
Validation loss: 2.455374240875244

Epoch: 5| Step: 1
Training loss: 3.018470048904419
Validation loss: 2.4668679365547757

Epoch: 5| Step: 2
Training loss: 2.547645330429077
Validation loss: 2.481513423304404

Epoch: 5| Step: 3
Training loss: 2.843458414077759
Validation loss: 2.502081696705152

Epoch: 5| Step: 4
Training loss: 2.5490951538085938
Validation loss: 2.5028626636792253

Epoch: 5| Step: 5
Training loss: 2.7619574069976807
Validation loss: 2.5034769068482103

Epoch: 5| Step: 6
Training loss: 2.7974352836608887
Validation loss: 2.479499734858031

Epoch: 5| Step: 7
Training loss: 3.0829017162323
Validation loss: 2.464902111279067

Epoch: 5| Step: 8
Training loss: 3.2053332328796387
Validation loss: 2.454739861590888

Epoch: 5| Step: 9
Training loss: 2.1478214263916016
Validation loss: 2.4443051276668424

Epoch: 5| Step: 10
Training loss: 2.0412871837615967
Validation loss: 2.445428099683536

Epoch: 70| Step: 0
Training loss: 2.5272231101989746
Validation loss: 2.443796134764148

Epoch: 5| Step: 1
Training loss: 2.4649808406829834
Validation loss: 2.4435978371609925

Epoch: 5| Step: 2
Training loss: 2.8043465614318848
Validation loss: 2.447995824198569

Epoch: 5| Step: 3
Training loss: 2.6000335216522217
Validation loss: 2.45034057863297

Epoch: 5| Step: 4
Training loss: 2.55755352973938
Validation loss: 2.45727897972189

Epoch: 5| Step: 5
Training loss: 2.2414662837982178
Validation loss: 2.456342625361617

Epoch: 5| Step: 6
Training loss: 3.185175895690918
Validation loss: 2.459831077565429

Epoch: 5| Step: 7
Training loss: 2.8017170429229736
Validation loss: 2.451973017825875

Epoch: 5| Step: 8
Training loss: 2.381011486053467
Validation loss: 2.4456827666169856

Epoch: 5| Step: 9
Training loss: 2.7273998260498047
Validation loss: 2.4414541003524617

Epoch: 5| Step: 10
Training loss: 3.2795073986053467
Validation loss: 2.438987091023435

Epoch: 71| Step: 0
Training loss: 2.1001415252685547
Validation loss: 2.4395197463291947

Epoch: 5| Step: 1
Training loss: 2.959540367126465
Validation loss: 2.4371711823248092

Epoch: 5| Step: 2
Training loss: 2.741480827331543
Validation loss: 2.442497081654046

Epoch: 5| Step: 3
Training loss: 3.5007991790771484
Validation loss: 2.4408512756388676

Epoch: 5| Step: 4
Training loss: 2.0520849227905273
Validation loss: 2.4479909276449554

Epoch: 5| Step: 5
Training loss: 2.2568211555480957
Validation loss: 2.446480562610011

Epoch: 5| Step: 6
Training loss: 3.0231354236602783
Validation loss: 2.4480883844437136

Epoch: 5| Step: 7
Training loss: 1.8863003253936768
Validation loss: 2.4524272975101264

Epoch: 5| Step: 8
Training loss: 2.763939380645752
Validation loss: 2.4544844794017013

Epoch: 5| Step: 9
Training loss: 2.9105217456817627
Validation loss: 2.4528878401684504

Epoch: 5| Step: 10
Training loss: 3.1084556579589844
Validation loss: 2.452177288711712

Epoch: 72| Step: 0
Training loss: 2.519261598587036
Validation loss: 2.4500206157725346

Epoch: 5| Step: 1
Training loss: 2.593165636062622
Validation loss: 2.4388215285475536

Epoch: 5| Step: 2
Training loss: 3.6368935108184814
Validation loss: 2.4348727067311606

Epoch: 5| Step: 3
Training loss: 2.449589967727661
Validation loss: 2.43257600004955

Epoch: 5| Step: 4
Training loss: 3.1504011154174805
Validation loss: 2.4304900271918184

Epoch: 5| Step: 5
Training loss: 2.234231472015381
Validation loss: 2.4292048113320464

Epoch: 5| Step: 6
Training loss: 1.9974530935287476
Validation loss: 2.4282930615127727

Epoch: 5| Step: 7
Training loss: 2.9168550968170166
Validation loss: 2.426402263743903

Epoch: 5| Step: 8
Training loss: 3.3685355186462402
Validation loss: 2.4249843089811263

Epoch: 5| Step: 9
Training loss: 2.021491050720215
Validation loss: 2.427085473973264

Epoch: 5| Step: 10
Training loss: 2.3568153381347656
Validation loss: 2.4262714949987267

Epoch: 73| Step: 0
Training loss: 3.097419261932373
Validation loss: 2.42447280499243

Epoch: 5| Step: 1
Training loss: 2.222663402557373
Validation loss: 2.4236630329521756

Epoch: 5| Step: 2
Training loss: 2.1509156227111816
Validation loss: 2.425040054064925

Epoch: 5| Step: 3
Training loss: 2.8140950202941895
Validation loss: 2.4299243598855953

Epoch: 5| Step: 4
Training loss: 2.442903757095337
Validation loss: 2.4270454863066315

Epoch: 5| Step: 5
Training loss: 2.2666006088256836
Validation loss: 2.43309026123375

Epoch: 5| Step: 6
Training loss: 2.328240394592285
Validation loss: 2.4307480076307892

Epoch: 5| Step: 7
Training loss: 2.6314480304718018
Validation loss: 2.4352036060825473

Epoch: 5| Step: 8
Training loss: 3.2750964164733887
Validation loss: 2.45268403842885

Epoch: 5| Step: 9
Training loss: 3.1714794635772705
Validation loss: 2.445914932476577

Epoch: 5| Step: 10
Training loss: 2.776182174682617
Validation loss: 2.436354831982684

Epoch: 74| Step: 0
Training loss: 2.790410280227661
Validation loss: 2.4281194261325303

Epoch: 5| Step: 1
Training loss: 2.286214828491211
Validation loss: 2.4288756744835966

Epoch: 5| Step: 2
Training loss: 2.697089672088623
Validation loss: 2.430350467722903

Epoch: 5| Step: 3
Training loss: 3.1479294300079346
Validation loss: 2.422720871945863

Epoch: 5| Step: 4
Training loss: 3.1513915061950684
Validation loss: 2.4252187564808834

Epoch: 5| Step: 5
Training loss: 2.6978280544281006
Validation loss: 2.42422390496859

Epoch: 5| Step: 6
Training loss: 2.898350477218628
Validation loss: 2.420701280716927

Epoch: 5| Step: 7
Training loss: 2.6383538246154785
Validation loss: 2.4234819796777542

Epoch: 5| Step: 8
Training loss: 2.4259610176086426
Validation loss: 2.4308431609984367

Epoch: 5| Step: 9
Training loss: 2.4325010776519775
Validation loss: 2.4200288557237193

Epoch: 5| Step: 10
Training loss: 1.833704948425293
Validation loss: 2.4174876700165453

Epoch: 75| Step: 0
Training loss: 2.885969877243042
Validation loss: 2.4109951860161236

Epoch: 5| Step: 1
Training loss: 2.5233571529388428
Validation loss: 2.4116888584629184

Epoch: 5| Step: 2
Training loss: 2.4733409881591797
Validation loss: 2.4156901605667604

Epoch: 5| Step: 3
Training loss: 2.220673084259033
Validation loss: 2.4139237942234164

Epoch: 5| Step: 4
Training loss: 2.7418901920318604
Validation loss: 2.415487584247384

Epoch: 5| Step: 5
Training loss: 3.150683879852295
Validation loss: 2.413060229311707

Epoch: 5| Step: 6
Training loss: 3.3864829540252686
Validation loss: 2.411693965235064

Epoch: 5| Step: 7
Training loss: 2.2561206817626953
Validation loss: 2.4174067999726985

Epoch: 5| Step: 8
Training loss: 2.52004337310791
Validation loss: 2.422945632729479

Epoch: 5| Step: 9
Training loss: 2.084099054336548
Validation loss: 2.441695979846421

Epoch: 5| Step: 10
Training loss: 2.9780373573303223
Validation loss: 2.462201013359972

Epoch: 76| Step: 0
Training loss: 2.2944514751434326
Validation loss: 2.4638722763266614

Epoch: 5| Step: 1
Training loss: 2.397350311279297
Validation loss: 2.469015493187853

Epoch: 5| Step: 2
Training loss: 2.8249526023864746
Validation loss: 2.4445851387516147

Epoch: 5| Step: 3
Training loss: 2.728222608566284
Validation loss: 2.4377958877112276

Epoch: 5| Step: 4
Training loss: 2.66178560256958
Validation loss: 2.4260982005826888

Epoch: 5| Step: 5
Training loss: 2.9319851398468018
Validation loss: 2.421032077522688

Epoch: 5| Step: 6
Training loss: 3.160623788833618
Validation loss: 2.427702614056167

Epoch: 5| Step: 7
Training loss: 2.657010793685913
Validation loss: 2.41761847465269

Epoch: 5| Step: 8
Training loss: 2.5795974731445312
Validation loss: 2.4133953637974237

Epoch: 5| Step: 9
Training loss: 2.570387125015259
Validation loss: 2.407486015750516

Epoch: 5| Step: 10
Training loss: 2.213698387145996
Validation loss: 2.4014048627627793

Epoch: 77| Step: 0
Training loss: 2.5819287300109863
Validation loss: 2.404215516582612

Epoch: 5| Step: 1
Training loss: 2.8677990436553955
Validation loss: 2.3986653897070114

Epoch: 5| Step: 2
Training loss: 2.9402148723602295
Validation loss: 2.400957161380399

Epoch: 5| Step: 3
Training loss: 1.9855473041534424
Validation loss: 2.401889985607516

Epoch: 5| Step: 4
Training loss: 2.9602978229522705
Validation loss: 2.401996830458282

Epoch: 5| Step: 5
Training loss: 2.674670696258545
Validation loss: 2.4013003482613513

Epoch: 5| Step: 6
Training loss: 2.1364471912384033
Validation loss: 2.3993057358649468

Epoch: 5| Step: 7
Training loss: 2.8788228034973145
Validation loss: 2.4005276772283737

Epoch: 5| Step: 8
Training loss: 2.4702091217041016
Validation loss: 2.40060176644274

Epoch: 5| Step: 9
Training loss: 3.4804821014404297
Validation loss: 2.395820099820373

Epoch: 5| Step: 10
Training loss: 2.051690101623535
Validation loss: 2.402006121091945

Epoch: 78| Step: 0
Training loss: 2.1487245559692383
Validation loss: 2.4044066808556996

Epoch: 5| Step: 1
Training loss: 2.583468437194824
Validation loss: 2.405135618743076

Epoch: 5| Step: 2
Training loss: 2.7171120643615723
Validation loss: 2.421073934083344

Epoch: 5| Step: 3
Training loss: 2.700345993041992
Validation loss: 2.445025387630668

Epoch: 5| Step: 4
Training loss: 3.0567517280578613
Validation loss: 2.4612959277245308

Epoch: 5| Step: 5
Training loss: 2.6260159015655518
Validation loss: 2.4500299653699322

Epoch: 5| Step: 6
Training loss: 3.137887477874756
Validation loss: 2.4396876545362574

Epoch: 5| Step: 7
Training loss: 2.7050845623016357
Validation loss: 2.417329295989006

Epoch: 5| Step: 8
Training loss: 2.4847187995910645
Validation loss: 2.4047275358630764

Epoch: 5| Step: 9
Training loss: 2.650822162628174
Validation loss: 2.400441636321365

Epoch: 5| Step: 10
Training loss: 2.2347605228424072
Validation loss: 2.3993656660920832

Epoch: 79| Step: 0
Training loss: 2.3770928382873535
Validation loss: 2.4098073846550396

Epoch: 5| Step: 1
Training loss: 2.1994881629943848
Validation loss: 2.417728626599876

Epoch: 5| Step: 2
Training loss: 3.220719575881958
Validation loss: 2.4532646286872124

Epoch: 5| Step: 3
Training loss: 3.1735587120056152
Validation loss: 2.4659932608245523

Epoch: 5| Step: 4
Training loss: 3.0764174461364746
Validation loss: 2.4876322977004515

Epoch: 5| Step: 5
Training loss: 2.767526149749756
Validation loss: 2.4659032437109176

Epoch: 5| Step: 6
Training loss: 1.8475033044815063
Validation loss: 2.4200092951456704

Epoch: 5| Step: 7
Training loss: 3.0428504943847656
Validation loss: 2.409336027278695

Epoch: 5| Step: 8
Training loss: 2.450566053390503
Validation loss: 2.4118635295539774

Epoch: 5| Step: 9
Training loss: 2.646001100540161
Validation loss: 2.441351318872103

Epoch: 5| Step: 10
Training loss: 2.4856066703796387
Validation loss: 2.4920776915806595

Epoch: 80| Step: 0
Training loss: 2.5829672813415527
Validation loss: 2.5412727491829985

Epoch: 5| Step: 1
Training loss: 2.785822629928589
Validation loss: 2.537480692709646

Epoch: 5| Step: 2
Training loss: 2.8009212017059326
Validation loss: 2.464275421634797

Epoch: 5| Step: 3
Training loss: 2.8340554237365723
Validation loss: 2.43301046791897

Epoch: 5| Step: 4
Training loss: 2.892962694168091
Validation loss: 2.4056842455299954

Epoch: 5| Step: 5
Training loss: 2.9109950065612793
Validation loss: 2.3951263145733903

Epoch: 5| Step: 6
Training loss: 2.5433509349823
Validation loss: 2.3984868103458035

Epoch: 5| Step: 7
Training loss: 2.8831894397735596
Validation loss: 2.4456799748123332

Epoch: 5| Step: 8
Training loss: 2.9073963165283203
Validation loss: 2.4907759953570623

Epoch: 5| Step: 9
Training loss: 2.1799843311309814
Validation loss: 2.4655661813674437

Epoch: 5| Step: 10
Training loss: 1.950323224067688
Validation loss: 2.4176106478578303

Epoch: 81| Step: 0
Training loss: 1.9281715154647827
Validation loss: 2.4004525958850818

Epoch: 5| Step: 1
Training loss: 2.599071502685547
Validation loss: 2.3948153821370934

Epoch: 5| Step: 2
Training loss: 2.9705991744995117
Validation loss: 2.4198688460934545

Epoch: 5| Step: 3
Training loss: 2.5433361530303955
Validation loss: 2.3925649478871334

Epoch: 5| Step: 4
Training loss: 2.1532607078552246
Validation loss: 2.3887737489515737

Epoch: 5| Step: 5
Training loss: 2.595885753631592
Validation loss: 2.3859454816387546

Epoch: 5| Step: 6
Training loss: 3.2844691276550293
Validation loss: 2.3887106487827916

Epoch: 5| Step: 7
Training loss: 2.4048125743865967
Validation loss: 2.3947169857640422

Epoch: 5| Step: 8
Training loss: 3.4687094688415527
Validation loss: 2.4100580702545824

Epoch: 5| Step: 9
Training loss: 2.6612746715545654
Validation loss: 2.4133260506455616

Epoch: 5| Step: 10
Training loss: 2.5396499633789062
Validation loss: 2.406803059321578

Epoch: 82| Step: 0
Training loss: 2.9224658012390137
Validation loss: 2.398465533410349

Epoch: 5| Step: 1
Training loss: 2.303314685821533
Validation loss: 2.3917805635800926

Epoch: 5| Step: 2
Training loss: 2.0794878005981445
Validation loss: 2.3853022257486978

Epoch: 5| Step: 3
Training loss: 2.7122435569763184
Validation loss: 2.3784661446848223

Epoch: 5| Step: 4
Training loss: 3.142495632171631
Validation loss: 2.375756456005958

Epoch: 5| Step: 5
Training loss: 1.788038969039917
Validation loss: 2.37339686834684

Epoch: 5| Step: 6
Training loss: 2.57609486579895
Validation loss: 2.3737659941437426

Epoch: 5| Step: 7
Training loss: 3.3208909034729004
Validation loss: 2.3824605352135113

Epoch: 5| Step: 8
Training loss: 3.039499282836914
Validation loss: 2.393168621165778

Epoch: 5| Step: 9
Training loss: 2.3505120277404785
Validation loss: 2.3995035207399757

Epoch: 5| Step: 10
Training loss: 2.848088264465332
Validation loss: 2.42401018065791

Epoch: 83| Step: 0
Training loss: 3.0475077629089355
Validation loss: 2.4011417178697485

Epoch: 5| Step: 1
Training loss: 3.21657133102417
Validation loss: 2.3827707434213288

Epoch: 5| Step: 2
Training loss: 1.8718230724334717
Validation loss: 2.3729084614784486

Epoch: 5| Step: 3
Training loss: 3.021829605102539
Validation loss: 2.367452884233126

Epoch: 5| Step: 4
Training loss: 3.1302366256713867
Validation loss: 2.3702084325974986

Epoch: 5| Step: 5
Training loss: 3.4510676860809326
Validation loss: 2.36633050569924

Epoch: 5| Step: 6
Training loss: 2.544236898422241
Validation loss: 2.3703111576777633

Epoch: 5| Step: 7
Training loss: 2.021700143814087
Validation loss: 2.3652781389092885

Epoch: 5| Step: 8
Training loss: 1.9401633739471436
Validation loss: 2.368249007450637

Epoch: 5| Step: 9
Training loss: 2.298449993133545
Validation loss: 2.3658463544743036

Epoch: 5| Step: 10
Training loss: 2.351593017578125
Validation loss: 2.369233339063583

Epoch: 84| Step: 0
Training loss: 3.072122812271118
Validation loss: 2.368422313403058

Epoch: 5| Step: 1
Training loss: 2.065498113632202
Validation loss: 2.3756537052892868

Epoch: 5| Step: 2
Training loss: 3.0067763328552246
Validation loss: 2.4008316686076503

Epoch: 5| Step: 3
Training loss: 2.1533143520355225
Validation loss: 2.408112851522302

Epoch: 5| Step: 4
Training loss: 2.9258947372436523
Validation loss: 2.416640050949589

Epoch: 5| Step: 5
Training loss: 2.482175827026367
Validation loss: 2.4172529251344743

Epoch: 5| Step: 6
Training loss: 2.5850882530212402
Validation loss: 2.417086749948481

Epoch: 5| Step: 7
Training loss: 2.7182259559631348
Validation loss: 2.419885318766358

Epoch: 5| Step: 8
Training loss: 2.4771440029144287
Validation loss: 2.4008467940874

Epoch: 5| Step: 9
Training loss: 2.7875094413757324
Validation loss: 2.3925938119170485

Epoch: 5| Step: 10
Training loss: 2.5747737884521484
Validation loss: 2.3841919488804315

Epoch: 85| Step: 0
Training loss: 2.6458897590637207
Validation loss: 2.3699832654768422

Epoch: 5| Step: 1
Training loss: 2.347999095916748
Validation loss: 2.364684594574795

Epoch: 5| Step: 2
Training loss: 2.761894941329956
Validation loss: 2.36202339203127

Epoch: 5| Step: 3
Training loss: 2.434530735015869
Validation loss: 2.3614418352803876

Epoch: 5| Step: 4
Training loss: 2.703014373779297
Validation loss: 2.3629040282259703

Epoch: 5| Step: 5
Training loss: 2.7224230766296387
Validation loss: 2.3582526535116215

Epoch: 5| Step: 6
Training loss: 2.299470901489258
Validation loss: 2.3571308325695735

Epoch: 5| Step: 7
Training loss: 2.88066029548645
Validation loss: 2.362517782436904

Epoch: 5| Step: 8
Training loss: 2.713624954223633
Validation loss: 2.369251472975618

Epoch: 5| Step: 9
Training loss: 2.8565704822540283
Validation loss: 2.382980949135237

Epoch: 5| Step: 10
Training loss: 2.4784657955169678
Validation loss: 2.3824860229287097

Epoch: 86| Step: 0
Training loss: 2.6098132133483887
Validation loss: 2.3928323074053695

Epoch: 5| Step: 1
Training loss: 2.3636393547058105
Validation loss: 2.3977454016285558

Epoch: 5| Step: 2
Training loss: 3.0511980056762695
Validation loss: 2.3958867083313646

Epoch: 5| Step: 3
Training loss: 2.9722797870635986
Validation loss: 2.3696387480663996

Epoch: 5| Step: 4
Training loss: 2.3387179374694824
Validation loss: 2.358284622110346

Epoch: 5| Step: 5
Training loss: 3.277653455734253
Validation loss: 2.3586750979064615

Epoch: 5| Step: 6
Training loss: 2.0632576942443848
Validation loss: 2.355706440505161

Epoch: 5| Step: 7
Training loss: 2.685086488723755
Validation loss: 2.3532442123659196

Epoch: 5| Step: 8
Training loss: 2.4877798557281494
Validation loss: 2.3499789494340138

Epoch: 5| Step: 9
Training loss: 2.3937621116638184
Validation loss: 2.351783860114313

Epoch: 5| Step: 10
Training loss: 2.499389171600342
Validation loss: 2.3530621028715566

Epoch: 87| Step: 0
Training loss: 2.1737771034240723
Validation loss: 2.3560347044339744

Epoch: 5| Step: 1
Training loss: 2.3411669731140137
Validation loss: 2.3604840437571206

Epoch: 5| Step: 2
Training loss: 3.071376323699951
Validation loss: 2.3827507162606842

Epoch: 5| Step: 3
Training loss: 2.725856304168701
Validation loss: 2.4031874979695966

Epoch: 5| Step: 4
Training loss: 2.350216865539551
Validation loss: 2.417012794043428

Epoch: 5| Step: 5
Training loss: 2.2351770401000977
Validation loss: 2.4249546476589736

Epoch: 5| Step: 6
Training loss: 2.431702136993408
Validation loss: 2.384957746792865

Epoch: 5| Step: 7
Training loss: 2.5195412635803223
Validation loss: 2.359729697627406

Epoch: 5| Step: 8
Training loss: 2.8715858459472656
Validation loss: 2.3464870632335706

Epoch: 5| Step: 9
Training loss: 3.253404140472412
Validation loss: 2.3518479639484036

Epoch: 5| Step: 10
Training loss: 2.7591238021850586
Validation loss: 2.357596233326902

Epoch: 88| Step: 0
Training loss: 3.155857563018799
Validation loss: 2.3587494383576098

Epoch: 5| Step: 1
Training loss: 2.5187530517578125
Validation loss: 2.359274064340899

Epoch: 5| Step: 2
Training loss: 2.3681766986846924
Validation loss: 2.358605894991147

Epoch: 5| Step: 3
Training loss: 3.3673911094665527
Validation loss: 2.362357085750949

Epoch: 5| Step: 4
Training loss: 2.621966600418091
Validation loss: 2.3563518780533985

Epoch: 5| Step: 5
Training loss: 2.3251030445098877
Validation loss: 2.3505264943645847

Epoch: 5| Step: 6
Training loss: 2.697206974029541
Validation loss: 2.33727208388749

Epoch: 5| Step: 7
Training loss: 2.038429021835327
Validation loss: 2.339776167305567

Epoch: 5| Step: 8
Training loss: 2.8733134269714355
Validation loss: 2.350004385876399

Epoch: 5| Step: 9
Training loss: 2.4877562522888184
Validation loss: 2.3627213073033158

Epoch: 5| Step: 10
Training loss: 2.410743474960327
Validation loss: 2.4062166316534883

Epoch: 89| Step: 0
Training loss: 2.772383213043213
Validation loss: 2.427515076052758

Epoch: 5| Step: 1
Training loss: 2.6636924743652344
Validation loss: 2.4646378588932816

Epoch: 5| Step: 2
Training loss: 2.75368070602417
Validation loss: 2.4999516138466458

Epoch: 5| Step: 3
Training loss: 2.926281452178955
Validation loss: 2.442692215724658

Epoch: 5| Step: 4
Training loss: 1.5423190593719482
Validation loss: 2.3991469029457337

Epoch: 5| Step: 5
Training loss: 2.7513668537139893
Validation loss: 2.3926334624649375

Epoch: 5| Step: 6
Training loss: 2.4851441383361816
Validation loss: 2.3577536767528904

Epoch: 5| Step: 7
Training loss: 2.530107021331787
Validation loss: 2.342661278222197

Epoch: 5| Step: 8
Training loss: 2.7890186309814453
Validation loss: 2.3321577041379866

Epoch: 5| Step: 9
Training loss: 2.538257598876953
Validation loss: 2.3337406112301733

Epoch: 5| Step: 10
Training loss: 3.093376874923706
Validation loss: 2.3466207878563994

Epoch: 90| Step: 0
Training loss: 2.6150853633880615
Validation loss: 2.3556222992558635

Epoch: 5| Step: 1
Training loss: 2.78973388671875
Validation loss: 2.3787546157836914

Epoch: 5| Step: 2
Training loss: 2.5375704765319824
Validation loss: 2.418330669403076

Epoch: 5| Step: 3
Training loss: 3.0578696727752686
Validation loss: 2.3889163924801733

Epoch: 5| Step: 4
Training loss: 2.437199354171753
Validation loss: 2.3626689039250857

Epoch: 5| Step: 5
Training loss: 2.287390947341919
Validation loss: 2.3540932952716784

Epoch: 5| Step: 6
Training loss: 2.9686946868896484
Validation loss: 2.3420516803700435

Epoch: 5| Step: 7
Training loss: 2.8408899307250977
Validation loss: 2.3366087713549213

Epoch: 5| Step: 8
Training loss: 2.8058629035949707
Validation loss: 2.333367265680785

Epoch: 5| Step: 9
Training loss: 2.6092100143432617
Validation loss: 2.3544220206558064

Epoch: 5| Step: 10
Training loss: 1.8315649032592773
Validation loss: 2.3700884465248353

Epoch: 91| Step: 0
Training loss: 3.11887788772583
Validation loss: 2.388039056972791

Epoch: 5| Step: 1
Training loss: 2.524167537689209
Validation loss: 2.4089621933557654

Epoch: 5| Step: 2
Training loss: 2.6687989234924316
Validation loss: 2.4104164531154018

Epoch: 5| Step: 3
Training loss: 2.8698184490203857
Validation loss: 2.366322079012471

Epoch: 5| Step: 4
Training loss: 2.5613608360290527
Validation loss: 2.335784912109375

Epoch: 5| Step: 5
Training loss: 2.571495532989502
Validation loss: 2.328356045548634

Epoch: 5| Step: 6
Training loss: 2.240025043487549
Validation loss: 2.3246155297884377

Epoch: 5| Step: 7
Training loss: 2.5209450721740723
Validation loss: 2.3252156934430523

Epoch: 5| Step: 8
Training loss: 2.3849475383758545
Validation loss: 2.3315434468689786

Epoch: 5| Step: 9
Training loss: 2.05112886428833
Validation loss: 2.3333067304344586

Epoch: 5| Step: 10
Training loss: 3.24149751663208
Validation loss: 2.3334463232307026

Epoch: 92| Step: 0
Training loss: 2.4579074382781982
Validation loss: 2.3298332716829036

Epoch: 5| Step: 1
Training loss: 2.395707845687866
Validation loss: 2.3306660575251423

Epoch: 5| Step: 2
Training loss: 3.040879726409912
Validation loss: 2.3275742607731975

Epoch: 5| Step: 3
Training loss: 1.973433494567871
Validation loss: 2.3279822000893216

Epoch: 5| Step: 4
Training loss: 2.592893123626709
Validation loss: 2.3408660568216795

Epoch: 5| Step: 5
Training loss: 2.260063886642456
Validation loss: 2.3560082066443657

Epoch: 5| Step: 6
Training loss: 2.5742218494415283
Validation loss: 2.369668742661835

Epoch: 5| Step: 7
Training loss: 2.3208565711975098
Validation loss: 2.39429049850792

Epoch: 5| Step: 8
Training loss: 2.581170082092285
Validation loss: 2.3992654046704693

Epoch: 5| Step: 9
Training loss: 3.8900656700134277
Validation loss: 2.380327137567664

Epoch: 5| Step: 10
Training loss: 2.582138776779175
Validation loss: 2.366258123869537

Epoch: 93| Step: 0
Training loss: 2.7153878211975098
Validation loss: 2.3462335871111963

Epoch: 5| Step: 1
Training loss: 2.786525011062622
Validation loss: 2.3265601819561375

Epoch: 5| Step: 2
Training loss: 2.4355666637420654
Validation loss: 2.321504057094615

Epoch: 5| Step: 3
Training loss: 2.17002534866333
Validation loss: 2.320473481250066

Epoch: 5| Step: 4
Training loss: 2.9197051525115967
Validation loss: 2.3246868835982455

Epoch: 5| Step: 5
Training loss: 2.8270814418792725
Validation loss: 2.317765989611226

Epoch: 5| Step: 6
Training loss: 2.6996142864227295
Validation loss: 2.3232630991166636

Epoch: 5| Step: 7
Training loss: 2.618490695953369
Validation loss: 2.3238585379815873

Epoch: 5| Step: 8
Training loss: 3.00077223777771
Validation loss: 2.3141081461342434

Epoch: 5| Step: 9
Training loss: 2.0152587890625
Validation loss: 2.3124262517498386

Epoch: 5| Step: 10
Training loss: 2.269869565963745
Validation loss: 2.31017311926811

Epoch: 94| Step: 0
Training loss: 2.1165614128112793
Validation loss: 2.3219128372848674

Epoch: 5| Step: 1
Training loss: 2.7994182109832764
Validation loss: 2.332271340072796

Epoch: 5| Step: 2
Training loss: 2.576024293899536
Validation loss: 2.3506164858418126

Epoch: 5| Step: 3
Training loss: 3.2016944885253906
Validation loss: 2.3626263090359267

Epoch: 5| Step: 4
Training loss: 2.0041167736053467
Validation loss: 2.36291673362896

Epoch: 5| Step: 5
Training loss: 2.527151584625244
Validation loss: 2.3461884990815194

Epoch: 5| Step: 6
Training loss: 2.562462091445923
Validation loss: 2.345637120226378

Epoch: 5| Step: 7
Training loss: 2.7103068828582764
Validation loss: 2.344048748734177

Epoch: 5| Step: 8
Training loss: 2.995767831802368
Validation loss: 2.344678222492177

Epoch: 5| Step: 9
Training loss: 2.653207778930664
Validation loss: 2.3268712156562397

Epoch: 5| Step: 10
Training loss: 2.323451519012451
Validation loss: 2.313802206388084

Epoch: 95| Step: 0
Training loss: 2.174792528152466
Validation loss: 2.309157309993621

Epoch: 5| Step: 1
Training loss: 2.69246506690979
Validation loss: 2.3124656933610157

Epoch: 5| Step: 2
Training loss: 2.2203638553619385
Validation loss: 2.313468631877694

Epoch: 5| Step: 3
Training loss: 2.849851131439209
Validation loss: 2.3122062580559843

Epoch: 5| Step: 4
Training loss: 2.336052894592285
Validation loss: 2.3069054670231317

Epoch: 5| Step: 5
Training loss: 2.744436740875244
Validation loss: 2.3110474822341756

Epoch: 5| Step: 6
Training loss: 2.3503546714782715
Validation loss: 2.3068111096659014

Epoch: 5| Step: 7
Training loss: 3.2986667156219482
Validation loss: 2.3047970674371205

Epoch: 5| Step: 8
Training loss: 2.548126459121704
Validation loss: 2.307965793917256

Epoch: 5| Step: 9
Training loss: 2.718021869659424
Validation loss: 2.3202937751687984

Epoch: 5| Step: 10
Training loss: 2.403198719024658
Validation loss: 2.3305953010436027

Epoch: 96| Step: 0
Training loss: 2.403769016265869
Validation loss: 2.3503707121777278

Epoch: 5| Step: 1
Training loss: 2.1927342414855957
Validation loss: 2.3602038455265824

Epoch: 5| Step: 2
Training loss: 2.782794952392578
Validation loss: 2.3808279422021683

Epoch: 5| Step: 3
Training loss: 2.939377784729004
Validation loss: 2.3625246786302134

Epoch: 5| Step: 4
Training loss: 2.6336491107940674
Validation loss: 2.337267296288603

Epoch: 5| Step: 5
Training loss: 2.438561201095581
Validation loss: 2.3355786672202488

Epoch: 5| Step: 6
Training loss: 2.9070825576782227
Validation loss: 2.32605492684149

Epoch: 5| Step: 7
Training loss: 2.7064547538757324
Validation loss: 2.3213715040555565

Epoch: 5| Step: 8
Training loss: 2.277709484100342
Validation loss: 2.3086606097477738

Epoch: 5| Step: 9
Training loss: 2.3347878456115723
Validation loss: 2.3094365583953036

Epoch: 5| Step: 10
Training loss: 2.8115944862365723
Validation loss: 2.309801559294424

Epoch: 97| Step: 0
Training loss: 2.466052532196045
Validation loss: 2.313888862568845

Epoch: 5| Step: 1
Training loss: 2.4757957458496094
Validation loss: 2.313048367859215

Epoch: 5| Step: 2
Training loss: 3.0162172317504883
Validation loss: 2.3232831108954644

Epoch: 5| Step: 3
Training loss: 2.694840431213379
Validation loss: 2.3220970963919036

Epoch: 5| Step: 4
Training loss: 2.218430995941162
Validation loss: 2.336715236786873

Epoch: 5| Step: 5
Training loss: 2.316713571548462
Validation loss: 2.360691944758097

Epoch: 5| Step: 6
Training loss: 2.8309035301208496
Validation loss: 2.3657982836487474

Epoch: 5| Step: 7
Training loss: 2.7203354835510254
Validation loss: 2.3584917130008822

Epoch: 5| Step: 8
Training loss: 2.4644947052001953
Validation loss: 2.365753020009687

Epoch: 5| Step: 9
Training loss: 2.388486623764038
Validation loss: 2.3657780578059535

Epoch: 5| Step: 10
Training loss: 2.707710027694702
Validation loss: 2.3717768346109698

Epoch: 98| Step: 0
Training loss: 2.0586986541748047
Validation loss: 2.3862455250114523

Epoch: 5| Step: 1
Training loss: 2.5330703258514404
Validation loss: 2.416924774005849

Epoch: 5| Step: 2
Training loss: 2.6598663330078125
Validation loss: 2.402325760933661

Epoch: 5| Step: 3
Training loss: 2.159147262573242
Validation loss: 2.3545857014194613

Epoch: 5| Step: 4
Training loss: 2.6242306232452393
Validation loss: 2.3564265927960797

Epoch: 5| Step: 5
Training loss: 2.8721957206726074
Validation loss: 2.321238745925247

Epoch: 5| Step: 6
Training loss: 2.6719229221343994
Validation loss: 2.3046379602083595

Epoch: 5| Step: 7
Training loss: 2.9521193504333496
Validation loss: 2.2947076110429663

Epoch: 5| Step: 8
Training loss: 2.4195516109466553
Validation loss: 2.287465928703226

Epoch: 5| Step: 9
Training loss: 2.3964781761169434
Validation loss: 2.28412373604313

Epoch: 5| Step: 10
Training loss: 3.0095129013061523
Validation loss: 2.2950878143310547

Epoch: 99| Step: 0
Training loss: 2.5615038871765137
Validation loss: 2.292967575852589

Epoch: 5| Step: 1
Training loss: 2.5394420623779297
Validation loss: 2.2892395950132802

Epoch: 5| Step: 2
Training loss: 2.5380337238311768
Validation loss: 2.2877293376512426

Epoch: 5| Step: 3
Training loss: 2.1391282081604004
Validation loss: 2.2944870148935625

Epoch: 5| Step: 4
Training loss: 2.601651430130005
Validation loss: 2.297842643594229

Epoch: 5| Step: 5
Training loss: 2.735271692276001
Validation loss: 2.3112232505634265

Epoch: 5| Step: 6
Training loss: 2.0402884483337402
Validation loss: 2.3180594790366387

Epoch: 5| Step: 7
Training loss: 2.8696398735046387
Validation loss: 2.3362172393388647

Epoch: 5| Step: 8
Training loss: 2.6170601844787598
Validation loss: 2.342465539132395

Epoch: 5| Step: 9
Training loss: 2.875136375427246
Validation loss: 2.3324724397351666

Epoch: 5| Step: 10
Training loss: 2.6259217262268066
Validation loss: 2.3309727330361643

Epoch: 100| Step: 0
Training loss: 3.0945961475372314
Validation loss: 2.3180747826894126

Epoch: 5| Step: 1
Training loss: 2.465789318084717
Validation loss: 2.304702792116391

Epoch: 5| Step: 2
Training loss: 2.3726162910461426
Validation loss: 2.2884760748955513

Epoch: 5| Step: 3
Training loss: 2.7364156246185303
Validation loss: 2.2869007407978015

Epoch: 5| Step: 4
Training loss: 3.3368725776672363
Validation loss: 2.2879821279997468

Epoch: 5| Step: 5
Training loss: 2.6374428272247314
Validation loss: 2.295824327776509

Epoch: 5| Step: 6
Training loss: 3.0706076622009277
Validation loss: 2.2952987019733717

Epoch: 5| Step: 7
Training loss: 1.8044328689575195
Validation loss: 2.2929457746526247

Epoch: 5| Step: 8
Training loss: 2.544161319732666
Validation loss: 2.3008365631103516

Epoch: 5| Step: 9
Training loss: 2.2928996086120605
Validation loss: 2.302565731028075

Epoch: 5| Step: 10
Training loss: 1.6277239322662354
Validation loss: 2.3023200599096154

Epoch: 101| Step: 0
Training loss: 2.4157376289367676
Validation loss: 2.31612132441613

Epoch: 5| Step: 1
Training loss: 2.0784096717834473
Validation loss: 2.358209225439256

Epoch: 5| Step: 2
Training loss: 2.384052276611328
Validation loss: 2.378143366946969

Epoch: 5| Step: 3
Training loss: 2.3240323066711426
Validation loss: 2.350630308992119

Epoch: 5| Step: 4
Training loss: 2.602649211883545
Validation loss: 2.313979502647154

Epoch: 5| Step: 5
Training loss: 2.5844979286193848
Validation loss: 2.3036074087183964

Epoch: 5| Step: 6
Training loss: 2.6600029468536377
Validation loss: 2.3015464159750167

Epoch: 5| Step: 7
Training loss: 2.949317216873169
Validation loss: 2.2980786138965237

Epoch: 5| Step: 8
Training loss: 2.4952123165130615
Validation loss: 2.2901989311300297

Epoch: 5| Step: 9
Training loss: 2.9773592948913574
Validation loss: 2.2870936675738265

Epoch: 5| Step: 10
Training loss: 2.717007637023926
Validation loss: 2.2806815357618433

Epoch: 102| Step: 0
Training loss: 2.3597052097320557
Validation loss: 2.276101763530444

Epoch: 5| Step: 1
Training loss: 3.2485790252685547
Validation loss: 2.278558641351679

Epoch: 5| Step: 2
Training loss: 2.7203104496002197
Validation loss: 2.278035968862554

Epoch: 5| Step: 3
Training loss: 2.4534084796905518
Validation loss: 2.2807658282659387

Epoch: 5| Step: 4
Training loss: 2.5242886543273926
Validation loss: 2.2938159178662043

Epoch: 5| Step: 5
Training loss: 2.2056033611297607
Validation loss: 2.3027169653164443

Epoch: 5| Step: 6
Training loss: 2.554783344268799
Validation loss: 2.315874333022743

Epoch: 5| Step: 7
Training loss: 2.2483530044555664
Validation loss: 2.330886956184141

Epoch: 5| Step: 8
Training loss: 2.256110191345215
Validation loss: 2.3381592637749127

Epoch: 5| Step: 9
Training loss: 3.21162486076355
Validation loss: 2.32863704107141

Epoch: 5| Step: 10
Training loss: 2.3831989765167236
Validation loss: 2.2927396259000226

Epoch: 103| Step: 0
Training loss: 2.1499199867248535
Validation loss: 2.276061778427452

Epoch: 5| Step: 1
Training loss: 2.2631325721740723
Validation loss: 2.2639793324214157

Epoch: 5| Step: 2
Training loss: 3.478466033935547
Validation loss: 2.269210797484203

Epoch: 5| Step: 3
Training loss: 2.5921576023101807
Validation loss: 2.2634137932972243

Epoch: 5| Step: 4
Training loss: 2.66178822517395
Validation loss: 2.2662532252650105

Epoch: 5| Step: 5
Training loss: 2.273519515991211
Validation loss: 2.278699880005211

Epoch: 5| Step: 6
Training loss: 2.0907540321350098
Validation loss: 2.2790413723197034

Epoch: 5| Step: 7
Training loss: 3.4413065910339355
Validation loss: 2.2941876508856334

Epoch: 5| Step: 8
Training loss: 3.19975209236145
Validation loss: 2.300158118688932

Epoch: 5| Step: 9
Training loss: 1.8714923858642578
Validation loss: 2.274952357815158

Epoch: 5| Step: 10
Training loss: 1.9682419300079346
Validation loss: 2.2712444233637985

Epoch: 104| Step: 0
Training loss: 3.292847156524658
Validation loss: 2.2698382023842103

Epoch: 5| Step: 1
Training loss: 2.102648973464966
Validation loss: 2.26512554384047

Epoch: 5| Step: 2
Training loss: 1.742987871170044
Validation loss: 2.2684582112937846

Epoch: 5| Step: 3
Training loss: 2.2636895179748535
Validation loss: 2.270145406005203

Epoch: 5| Step: 4
Training loss: 2.8696846961975098
Validation loss: 2.2689474680090465

Epoch: 5| Step: 5
Training loss: 3.149094343185425
Validation loss: 2.2750134929533927

Epoch: 5| Step: 6
Training loss: 2.6912741661071777
Validation loss: 2.2797429023250455

Epoch: 5| Step: 7
Training loss: 2.0048775672912598
Validation loss: 2.3031345875032487

Epoch: 5| Step: 8
Training loss: 2.915187120437622
Validation loss: 2.330862566988955

Epoch: 5| Step: 9
Training loss: 2.2255873680114746
Validation loss: 2.354849382113385

Epoch: 5| Step: 10
Training loss: 2.741689682006836
Validation loss: 2.3988792832179735

Epoch: 105| Step: 0
Training loss: 2.1882429122924805
Validation loss: 2.3605146638808714

Epoch: 5| Step: 1
Training loss: 1.9598751068115234
Validation loss: 2.3211366002277662

Epoch: 5| Step: 2
Training loss: 3.2030625343322754
Validation loss: 2.3236501652707338

Epoch: 5| Step: 3
Training loss: 2.5526301860809326
Validation loss: 2.2894782840564685

Epoch: 5| Step: 4
Training loss: 2.698700428009033
Validation loss: 2.2807297386148924

Epoch: 5| Step: 5
Training loss: 2.0922293663024902
Validation loss: 2.2726958413277902

Epoch: 5| Step: 6
Training loss: 2.726649284362793
Validation loss: 2.2671936532502532

Epoch: 5| Step: 7
Training loss: 2.4089255332946777
Validation loss: 2.2700116788187334

Epoch: 5| Step: 8
Training loss: 2.7751898765563965
Validation loss: 2.274003659525225

Epoch: 5| Step: 9
Training loss: 2.6490108966827393
Validation loss: 2.2643222116654917

Epoch: 5| Step: 10
Training loss: 2.794769287109375
Validation loss: 2.2715975635795185

Epoch: 106| Step: 0
Training loss: 2.605241060256958
Validation loss: 2.2691754089888705

Epoch: 5| Step: 1
Training loss: 2.3636116981506348
Validation loss: 2.2790693365117556

Epoch: 5| Step: 2
Training loss: 2.7845959663391113
Validation loss: 2.28295833833756

Epoch: 5| Step: 3
Training loss: 2.639827251434326
Validation loss: 2.2904910425986014

Epoch: 5| Step: 4
Training loss: 2.3583290576934814
Validation loss: 2.2983171504030944

Epoch: 5| Step: 5
Training loss: 2.461176633834839
Validation loss: 2.299851699541974

Epoch: 5| Step: 6
Training loss: 2.3616385459899902
Validation loss: 2.321754942658127

Epoch: 5| Step: 7
Training loss: 2.4059126377105713
Validation loss: 2.321438758603988

Epoch: 5| Step: 8
Training loss: 2.964517116546631
Validation loss: 2.2910167812019266

Epoch: 5| Step: 9
Training loss: 2.7140660285949707
Validation loss: 2.271559633234496

Epoch: 5| Step: 10
Training loss: 2.172973394393921
Validation loss: 2.258571959310962

Epoch: 107| Step: 0
Training loss: 1.8526710271835327
Validation loss: 2.258291364997946

Epoch: 5| Step: 1
Training loss: 2.6931190490722656
Validation loss: 2.2591019856032504

Epoch: 5| Step: 2
Training loss: 2.16434383392334
Validation loss: 2.260458723191292

Epoch: 5| Step: 3
Training loss: 2.373262405395508
Validation loss: 2.2775280501252864

Epoch: 5| Step: 4
Training loss: 2.8463730812072754
Validation loss: 2.2864232986204085

Epoch: 5| Step: 5
Training loss: 2.755568027496338
Validation loss: 2.272937907967516

Epoch: 5| Step: 6
Training loss: 2.4133832454681396
Validation loss: 2.2608635451204036

Epoch: 5| Step: 7
Training loss: 2.8242039680480957
Validation loss: 2.2611461172821703

Epoch: 5| Step: 8
Training loss: 2.4255027770996094
Validation loss: 2.269771302900007

Epoch: 5| Step: 9
Training loss: 2.7938039302825928
Validation loss: 2.293537237310922

Epoch: 5| Step: 10
Training loss: 2.6242740154266357
Validation loss: 2.3153565083780596

Epoch: 108| Step: 0
Training loss: 2.9444756507873535
Validation loss: 2.3327451098349785

Epoch: 5| Step: 1
Training loss: 1.9713737964630127
Validation loss: 2.3179168931899534

Epoch: 5| Step: 2
Training loss: 2.8266632556915283
Validation loss: 2.327194267703641

Epoch: 5| Step: 3
Training loss: 2.542090654373169
Validation loss: 2.3247343314591276

Epoch: 5| Step: 4
Training loss: 2.7334647178649902
Validation loss: 2.311196650228193

Epoch: 5| Step: 5
Training loss: 2.259943962097168
Validation loss: 2.3118229296899613

Epoch: 5| Step: 6
Training loss: 2.996222972869873
Validation loss: 2.314147044253606

Epoch: 5| Step: 7
Training loss: 2.0942740440368652
Validation loss: 2.291628122329712

Epoch: 5| Step: 8
Training loss: 2.779059648513794
Validation loss: 2.258966435668289

Epoch: 5| Step: 9
Training loss: 2.4447779655456543
Validation loss: 2.250013928259573

Epoch: 5| Step: 10
Training loss: 2.085020065307617
Validation loss: 2.245602261635565

Epoch: 109| Step: 0
Training loss: 2.479766845703125
Validation loss: 2.2450002675415366

Epoch: 5| Step: 1
Training loss: 2.1774990558624268
Validation loss: 2.243968540622342

Epoch: 5| Step: 2
Training loss: 2.2595086097717285
Validation loss: 2.253583505589475

Epoch: 5| Step: 3
Training loss: 2.9313836097717285
Validation loss: 2.250903502587349

Epoch: 5| Step: 4
Training loss: 2.0410192012786865
Validation loss: 2.245107417465538

Epoch: 5| Step: 5
Training loss: 2.290782928466797
Validation loss: 2.245934583807504

Epoch: 5| Step: 6
Training loss: 2.9208192825317383
Validation loss: 2.25060619590103

Epoch: 5| Step: 7
Training loss: 2.383826494216919
Validation loss: 2.261419193719023

Epoch: 5| Step: 8
Training loss: 3.0142264366149902
Validation loss: 2.283023370209561

Epoch: 5| Step: 9
Training loss: 3.0744564533233643
Validation loss: 2.3086819123196345

Epoch: 5| Step: 10
Training loss: 2.137375593185425
Validation loss: 2.309742422514064

Epoch: 110| Step: 0
Training loss: 2.1297295093536377
Validation loss: 2.306353686958231

Epoch: 5| Step: 1
Training loss: 2.52632474899292
Validation loss: 2.322304517992081

Epoch: 5| Step: 2
Training loss: 2.7970447540283203
Validation loss: 2.328148970039942

Epoch: 5| Step: 3
Training loss: 2.3270602226257324
Validation loss: 2.328056894322877

Epoch: 5| Step: 4
Training loss: 2.4224791526794434
Validation loss: 2.3155721515737553

Epoch: 5| Step: 5
Training loss: 2.861826181411743
Validation loss: 2.2799354291731313

Epoch: 5| Step: 6
Training loss: 2.2750630378723145
Validation loss: 2.2555005217111237

Epoch: 5| Step: 7
Training loss: 2.788034200668335
Validation loss: 2.2356047937946935

Epoch: 5| Step: 8
Training loss: 2.5879008769989014
Validation loss: 2.2236605651916994

Epoch: 5| Step: 9
Training loss: 2.707118511199951
Validation loss: 2.230994757785592

Epoch: 5| Step: 10
Training loss: 2.221359968185425
Validation loss: 2.2370121043215514

Epoch: 111| Step: 0
Training loss: 2.911746025085449
Validation loss: 2.240291319867616

Epoch: 5| Step: 1
Training loss: 2.42146635055542
Validation loss: 2.24281648922992

Epoch: 5| Step: 2
Training loss: 2.2460885047912598
Validation loss: 2.234147825548726

Epoch: 5| Step: 3
Training loss: 2.8022003173828125
Validation loss: 2.232563659708987

Epoch: 5| Step: 4
Training loss: 2.2677321434020996
Validation loss: 2.2239710002817135

Epoch: 5| Step: 5
Training loss: 2.753330945968628
Validation loss: 2.2362314219115884

Epoch: 5| Step: 6
Training loss: 2.3744101524353027
Validation loss: 2.2473152093989874

Epoch: 5| Step: 7
Training loss: 2.860790967941284
Validation loss: 2.265835410805159

Epoch: 5| Step: 8
Training loss: 1.9461498260498047
Validation loss: 2.2763905781571583

Epoch: 5| Step: 9
Training loss: 2.422147750854492
Validation loss: 2.281671611211633

Epoch: 5| Step: 10
Training loss: 2.939288854598999
Validation loss: 2.2592559668325607

Epoch: 112| Step: 0
Training loss: 2.5551204681396484
Validation loss: 2.2491336381563576

Epoch: 5| Step: 1
Training loss: 2.260881185531616
Validation loss: 2.2399819666339504

Epoch: 5| Step: 2
Training loss: 2.7742624282836914
Validation loss: 2.2351408491852465

Epoch: 5| Step: 3
Training loss: 2.498274564743042
Validation loss: 2.2257998528019076

Epoch: 5| Step: 4
Training loss: 2.4111990928649902
Validation loss: 2.214689031724007

Epoch: 5| Step: 5
Training loss: 3.0942940711975098
Validation loss: 2.2178656042263074

Epoch: 5| Step: 6
Training loss: 1.872926950454712
Validation loss: 2.219554534522436

Epoch: 5| Step: 7
Training loss: 2.5737216472625732
Validation loss: 2.231098218630719

Epoch: 5| Step: 8
Training loss: 2.511136293411255
Validation loss: 2.246779936616139

Epoch: 5| Step: 9
Training loss: 2.4659554958343506
Validation loss: 2.253889719645182

Epoch: 5| Step: 10
Training loss: 2.615692138671875
Validation loss: 2.2764803055794007

Epoch: 113| Step: 0
Training loss: 2.841209650039673
Validation loss: 2.2865959111080376

Epoch: 5| Step: 1
Training loss: 2.7055041790008545
Validation loss: 2.2769471676118913

Epoch: 5| Step: 2
Training loss: 2.2778666019439697
Validation loss: 2.2565258626014955

Epoch: 5| Step: 3
Training loss: 1.9466984272003174
Validation loss: 2.248577117919922

Epoch: 5| Step: 4
Training loss: 2.4477782249450684
Validation loss: 2.2378758743245113

Epoch: 5| Step: 5
Training loss: 2.673550844192505
Validation loss: 2.242932482432294

Epoch: 5| Step: 6
Training loss: 2.633835554122925
Validation loss: 2.218852784043999

Epoch: 5| Step: 7
Training loss: 2.7194061279296875
Validation loss: 2.2261589598912064

Epoch: 5| Step: 8
Training loss: 2.2990615367889404
Validation loss: 2.2402592884596957

Epoch: 5| Step: 9
Training loss: 2.1104040145874023
Validation loss: 2.2380559700791554

Epoch: 5| Step: 10
Training loss: 2.8898355960845947
Validation loss: 2.220290325021231

Epoch: 114| Step: 0
Training loss: 1.7773357629776
Validation loss: 2.23014933319502

Epoch: 5| Step: 1
Training loss: 2.26528000831604
Validation loss: 2.226186387000545

Epoch: 5| Step: 2
Training loss: 2.43650484085083
Validation loss: 2.225648764641054

Epoch: 5| Step: 3
Training loss: 2.4894890785217285
Validation loss: 2.221546032095468

Epoch: 5| Step: 4
Training loss: 3.062934398651123
Validation loss: 2.2260464827219644

Epoch: 5| Step: 5
Training loss: 2.0749640464782715
Validation loss: 2.235327313023229

Epoch: 5| Step: 6
Training loss: 2.6182761192321777
Validation loss: 2.239208593163439

Epoch: 5| Step: 7
Training loss: 2.6514029502868652
Validation loss: 2.2368383638320433

Epoch: 5| Step: 8
Training loss: 3.0174520015716553
Validation loss: 2.2511831278442056

Epoch: 5| Step: 9
Training loss: 2.562349557876587
Validation loss: 2.2689319861832487

Epoch: 5| Step: 10
Training loss: 2.411336898803711
Validation loss: 2.2678523307205527

Epoch: 115| Step: 0
Training loss: 2.432816982269287
Validation loss: 2.2559426753751692

Epoch: 5| Step: 1
Training loss: 2.183480739593506
Validation loss: 2.242246838026149

Epoch: 5| Step: 2
Training loss: 2.469845771789551
Validation loss: 2.244316521511283

Epoch: 5| Step: 3
Training loss: 3.3164546489715576
Validation loss: 2.2277556875700593

Epoch: 5| Step: 4
Training loss: 2.5924253463745117
Validation loss: 2.226040155656876

Epoch: 5| Step: 5
Training loss: 2.029876470565796
Validation loss: 2.208669820139485

Epoch: 5| Step: 6
Training loss: 2.401423692703247
Validation loss: 2.2101419228379444

Epoch: 5| Step: 7
Training loss: 2.461081027984619
Validation loss: 2.2115617952039166

Epoch: 5| Step: 8
Training loss: 2.5810601711273193
Validation loss: 2.2065462220099663

Epoch: 5| Step: 9
Training loss: 2.2244653701782227
Validation loss: 2.2086807143303657

Epoch: 5| Step: 10
Training loss: 2.6663427352905273
Validation loss: 2.220365262800647

Epoch: 116| Step: 0
Training loss: 2.579193115234375
Validation loss: 2.2246348165696666

Epoch: 5| Step: 1
Training loss: 2.2100157737731934
Validation loss: 2.237779507073023

Epoch: 5| Step: 2
Training loss: 2.4219446182250977
Validation loss: 2.258582265146317

Epoch: 5| Step: 3
Training loss: 2.7619986534118652
Validation loss: 2.2778677760913806

Epoch: 5| Step: 4
Training loss: 2.141930103302002
Validation loss: 2.2691036911420923

Epoch: 5| Step: 5
Training loss: 2.803820848464966
Validation loss: 2.270258570230135

Epoch: 5| Step: 6
Training loss: 2.6685264110565186
Validation loss: 2.2539197014224146

Epoch: 5| Step: 7
Training loss: 2.5478389263153076
Validation loss: 2.231494170363231

Epoch: 5| Step: 8
Training loss: 2.236490249633789
Validation loss: 2.2144689790664183

Epoch: 5| Step: 9
Training loss: 2.3298256397247314
Validation loss: 2.207594508765846

Epoch: 5| Step: 10
Training loss: 2.7257235050201416
Validation loss: 2.197214808515323

Epoch: 117| Step: 0
Training loss: 2.491105079650879
Validation loss: 2.1961804436099146

Epoch: 5| Step: 1
Training loss: 2.3714210987091064
Validation loss: 2.2084571956306376

Epoch: 5| Step: 2
Training loss: 2.8434479236602783
Validation loss: 2.218693653742472

Epoch: 5| Step: 3
Training loss: 2.8207221031188965
Validation loss: 2.222040304573633

Epoch: 5| Step: 4
Training loss: 2.7670814990997314
Validation loss: 2.2413658019035094

Epoch: 5| Step: 5
Training loss: 3.016631841659546
Validation loss: 2.2365488698405604

Epoch: 5| Step: 6
Training loss: 2.1218113899230957
Validation loss: 2.2237596178567536

Epoch: 5| Step: 7
Training loss: 2.5459001064300537
Validation loss: 2.2164080194247666

Epoch: 5| Step: 8
Training loss: 2.0744128227233887
Validation loss: 2.1968549323338333

Epoch: 5| Step: 9
Training loss: 2.369236707687378
Validation loss: 2.19886165665042

Epoch: 5| Step: 10
Training loss: 1.9497967958450317
Validation loss: 2.2041887724271385

Epoch: 118| Step: 0
Training loss: 2.7161343097686768
Validation loss: 2.2176561611954884

Epoch: 5| Step: 1
Training loss: 2.6027114391326904
Validation loss: 2.2223781360092985

Epoch: 5| Step: 2
Training loss: 2.3791542053222656
Validation loss: 2.2286292352984027

Epoch: 5| Step: 3
Training loss: 2.683803081512451
Validation loss: 2.217709405447847

Epoch: 5| Step: 4
Training loss: 2.470811128616333
Validation loss: 2.231126716060023

Epoch: 5| Step: 5
Training loss: 2.596993923187256
Validation loss: 2.2371128707803707

Epoch: 5| Step: 6
Training loss: 2.161587953567505
Validation loss: 2.2311139375932756

Epoch: 5| Step: 7
Training loss: 2.5610671043395996
Validation loss: 2.2010490766135593

Epoch: 5| Step: 8
Training loss: 1.9113401174545288
Validation loss: 2.1869744100878314

Epoch: 5| Step: 9
Training loss: 2.919370174407959
Validation loss: 2.185652453412292

Epoch: 5| Step: 10
Training loss: 2.215250253677368
Validation loss: 2.185530562554636

Epoch: 119| Step: 0
Training loss: 2.6198782920837402
Validation loss: 2.192699150372577

Epoch: 5| Step: 1
Training loss: 2.337345600128174
Validation loss: 2.196690749096614

Epoch: 5| Step: 2
Training loss: 3.1033966541290283
Validation loss: 2.2106739218517015

Epoch: 5| Step: 3
Training loss: 2.3687150478363037
Validation loss: 2.2043800866732033

Epoch: 5| Step: 4
Training loss: 2.384565830230713
Validation loss: 2.2357155584519908

Epoch: 5| Step: 5
Training loss: 2.114074468612671
Validation loss: 2.271136701747935

Epoch: 5| Step: 6
Training loss: 1.8095134496688843
Validation loss: 2.2539432279525267

Epoch: 5| Step: 7
Training loss: 2.9138576984405518
Validation loss: 2.2512002683454946

Epoch: 5| Step: 8
Training loss: 2.3644747734069824
Validation loss: 2.2355941777588217

Epoch: 5| Step: 9
Training loss: 2.3714871406555176
Validation loss: 2.2155767153668147

Epoch: 5| Step: 10
Training loss: 2.965378761291504
Validation loss: 2.21200648174491

Epoch: 120| Step: 0
Training loss: 2.234281063079834
Validation loss: 2.2086780353259017

Epoch: 5| Step: 1
Training loss: 2.6908528804779053
Validation loss: 2.2359618807351715

Epoch: 5| Step: 2
Training loss: 2.4942708015441895
Validation loss: 2.227392919601933

Epoch: 5| Step: 3
Training loss: 2.338935136795044
Validation loss: 2.219665555543797

Epoch: 5| Step: 4
Training loss: 2.2944483757019043
Validation loss: 2.1896103889711442

Epoch: 5| Step: 5
Training loss: 2.7247376441955566
Validation loss: 2.199386371079312

Epoch: 5| Step: 6
Training loss: 2.562509775161743
Validation loss: 2.1882845201799945

Epoch: 5| Step: 7
Training loss: 2.7810163497924805
Validation loss: 2.1825719828246744

Epoch: 5| Step: 8
Training loss: 2.111203670501709
Validation loss: 2.191666897907052

Epoch: 5| Step: 9
Training loss: 2.358400583267212
Validation loss: 2.1833640990718717

Epoch: 5| Step: 10
Training loss: 2.756025791168213
Validation loss: 2.1928177930975474

Epoch: 121| Step: 0
Training loss: 2.0070390701293945
Validation loss: 2.18741354891049

Epoch: 5| Step: 1
Training loss: 2.2330527305603027
Validation loss: 2.2028261641020417

Epoch: 5| Step: 2
Training loss: 2.359070301055908
Validation loss: 2.233219224919555

Epoch: 5| Step: 3
Training loss: 2.3022146224975586
Validation loss: 2.2578235300638343

Epoch: 5| Step: 4
Training loss: 2.72133731842041
Validation loss: 2.277158570545976

Epoch: 5| Step: 5
Training loss: 2.8848233222961426
Validation loss: 2.2897786107114566

Epoch: 5| Step: 6
Training loss: 3.3753859996795654
Validation loss: 2.24397789021974

Epoch: 5| Step: 7
Training loss: 2.4275527000427246
Validation loss: 2.185888577533025

Epoch: 5| Step: 8
Training loss: 1.8716299533843994
Validation loss: 2.1608687305963166

Epoch: 5| Step: 9
Training loss: 2.399463653564453
Validation loss: 2.157056458534733

Epoch: 5| Step: 10
Training loss: 2.839339017868042
Validation loss: 2.165421057772893

Epoch: 122| Step: 0
Training loss: 2.4455838203430176
Validation loss: 2.158651198110273

Epoch: 5| Step: 1
Training loss: 2.1935575008392334
Validation loss: 2.1668034279218285

Epoch: 5| Step: 2
Training loss: 2.041074275970459
Validation loss: 2.1784057360823437

Epoch: 5| Step: 3
Training loss: 2.315833330154419
Validation loss: 2.220675222335323

Epoch: 5| Step: 4
Training loss: 2.600189685821533
Validation loss: 2.2527617613474527

Epoch: 5| Step: 5
Training loss: 2.5061166286468506
Validation loss: 2.298462374235994

Epoch: 5| Step: 6
Training loss: 2.813216209411621
Validation loss: 2.3149296891304756

Epoch: 5| Step: 7
Training loss: 2.4035451412200928
Validation loss: 2.3305563490877867

Epoch: 5| Step: 8
Training loss: 2.7930634021759033
Validation loss: 2.30927417355199

Epoch: 5| Step: 9
Training loss: 2.4959232807159424
Validation loss: 2.2793155434311076

Epoch: 5| Step: 10
Training loss: 2.787686347961426
Validation loss: 2.2423303358016478

Epoch: 123| Step: 0
Training loss: 2.5187883377075195
Validation loss: 2.202717629812097

Epoch: 5| Step: 1
Training loss: 3.120069980621338
Validation loss: 2.1946791859083277

Epoch: 5| Step: 2
Training loss: 2.400325298309326
Validation loss: 2.19012176862327

Epoch: 5| Step: 3
Training loss: 1.904086709022522
Validation loss: 2.190917884149859

Epoch: 5| Step: 4
Training loss: 2.411228895187378
Validation loss: 2.1702889268116285

Epoch: 5| Step: 5
Training loss: 2.556305408477783
Validation loss: 2.16130926275766

Epoch: 5| Step: 6
Training loss: 2.4035110473632812
Validation loss: 2.1518537408562115

Epoch: 5| Step: 7
Training loss: 1.8214304447174072
Validation loss: 2.1484660948476484

Epoch: 5| Step: 8
Training loss: 2.5706429481506348
Validation loss: 2.1519882243166686

Epoch: 5| Step: 9
Training loss: 3.168919086456299
Validation loss: 2.2015627314967494

Epoch: 5| Step: 10
Training loss: 2.3140859603881836
Validation loss: 2.255521821719344

Epoch: 124| Step: 0
Training loss: 2.3255887031555176
Validation loss: 2.2498043301284953

Epoch: 5| Step: 1
Training loss: 2.8179125785827637
Validation loss: 2.200239876265167

Epoch: 5| Step: 2
Training loss: 2.0422558784484863
Validation loss: 2.160991350809733

Epoch: 5| Step: 3
Training loss: 2.6490139961242676
Validation loss: 2.1512115001678467

Epoch: 5| Step: 4
Training loss: 2.464951753616333
Validation loss: 2.151100452228259

Epoch: 5| Step: 5
Training loss: 2.8683197498321533
Validation loss: 2.157506545384725

Epoch: 5| Step: 6
Training loss: 3.022556781768799
Validation loss: 2.1690911977521834

Epoch: 5| Step: 7
Training loss: 2.400409698486328
Validation loss: 2.1720368913424912

Epoch: 5| Step: 8
Training loss: 2.202550172805786
Validation loss: 2.170734497808641

Epoch: 5| Step: 9
Training loss: 2.0691428184509277
Validation loss: 2.1952562268062303

Epoch: 5| Step: 10
Training loss: 2.2409236431121826
Validation loss: 2.2184361437315583

Epoch: 125| Step: 0
Training loss: 2.4787027835845947
Validation loss: 2.2206009639206754

Epoch: 5| Step: 1
Training loss: 3.264599561691284
Validation loss: 2.251458321848223

Epoch: 5| Step: 2
Training loss: 2.145522356033325
Validation loss: 2.2664300972415554

Epoch: 5| Step: 3
Training loss: 2.6490416526794434
Validation loss: 2.276505239548222

Epoch: 5| Step: 4
Training loss: 2.438255786895752
Validation loss: 2.2863739869927846

Epoch: 5| Step: 5
Training loss: 2.1711373329162598
Validation loss: 2.238674786783034

Epoch: 5| Step: 6
Training loss: 3.1054606437683105
Validation loss: 2.180882374445597

Epoch: 5| Step: 7
Training loss: 2.050905704498291
Validation loss: 2.1372001837658625

Epoch: 5| Step: 8
Training loss: 2.2076382637023926
Validation loss: 2.1381067152946227

Epoch: 5| Step: 9
Training loss: 2.230250835418701
Validation loss: 2.1443567788729103

Epoch: 5| Step: 10
Training loss: 2.195449113845825
Validation loss: 2.153979996199249

Epoch: 126| Step: 0
Training loss: 2.74590802192688
Validation loss: 2.153665522093414

Epoch: 5| Step: 1
Training loss: 2.2596096992492676
Validation loss: 2.1530794456440914

Epoch: 5| Step: 2
Training loss: 2.6610565185546875
Validation loss: 2.1489502524816864

Epoch: 5| Step: 3
Training loss: 2.533356189727783
Validation loss: 2.143925710390973

Epoch: 5| Step: 4
Training loss: 2.42250657081604
Validation loss: 2.1483344249827887

Epoch: 5| Step: 5
Training loss: 2.5493996143341064
Validation loss: 2.1578074116860666

Epoch: 5| Step: 6
Training loss: 2.495497226715088
Validation loss: 2.1605843215860348

Epoch: 5| Step: 7
Training loss: 2.855056047439575
Validation loss: 2.1753313028684227

Epoch: 5| Step: 8
Training loss: 2.6243629455566406
Validation loss: 2.1760903378968597

Epoch: 5| Step: 9
Training loss: 2.2735934257507324
Validation loss: 2.157234209840016

Epoch: 5| Step: 10
Training loss: 1.6600189208984375
Validation loss: 2.163152893384298

Epoch: 127| Step: 0
Training loss: 2.149266004562378
Validation loss: 2.1367541115771056

Epoch: 5| Step: 1
Training loss: 2.5850741863250732
Validation loss: 2.1269925884021226

Epoch: 5| Step: 2
Training loss: 1.6639835834503174
Validation loss: 2.1218439532864477

Epoch: 5| Step: 3
Training loss: 2.3571767807006836
Validation loss: 2.1206047483669814

Epoch: 5| Step: 4
Training loss: 2.632239580154419
Validation loss: 2.1223759112819547

Epoch: 5| Step: 5
Training loss: 3.0336263179779053
Validation loss: 2.1460295595148557

Epoch: 5| Step: 6
Training loss: 2.843959093093872
Validation loss: 2.171040656746075

Epoch: 5| Step: 7
Training loss: 1.9921276569366455
Validation loss: 2.1920704739068144

Epoch: 5| Step: 8
Training loss: 2.0630054473876953
Validation loss: 2.152464976874731

Epoch: 5| Step: 9
Training loss: 2.8053479194641113
Validation loss: 2.145859476058714

Epoch: 5| Step: 10
Training loss: 2.597895622253418
Validation loss: 2.1515868915024625

Epoch: 128| Step: 0
Training loss: 2.6607353687286377
Validation loss: 2.1491848781544673

Epoch: 5| Step: 1
Training loss: 2.65287446975708
Validation loss: 2.155811266232562

Epoch: 5| Step: 2
Training loss: 2.7791173458099365
Validation loss: 2.149523606864355

Epoch: 5| Step: 3
Training loss: 2.216130495071411
Validation loss: 2.1445557225135063

Epoch: 5| Step: 4
Training loss: 2.1668152809143066
Validation loss: 2.134250371686874

Epoch: 5| Step: 5
Training loss: 2.6643784046173096
Validation loss: 2.1394290219071093

Epoch: 5| Step: 6
Training loss: 2.2242677211761475
Validation loss: 2.1509143793454735

Epoch: 5| Step: 7
Training loss: 1.8997036218643188
Validation loss: 2.151842983820105

Epoch: 5| Step: 8
Training loss: 2.4088244438171387
Validation loss: 2.1345295957339707

Epoch: 5| Step: 9
Training loss: 2.0327670574188232
Validation loss: 2.128626840088957

Epoch: 5| Step: 10
Training loss: 2.927473783493042
Validation loss: 2.119106702907111

Epoch: 129| Step: 0
Training loss: 2.0225443840026855
Validation loss: 2.1188502388615764

Epoch: 5| Step: 1
Training loss: 2.676781177520752
Validation loss: 2.11586489728702

Epoch: 5| Step: 2
Training loss: 2.6314446926116943
Validation loss: 2.115793840859526

Epoch: 5| Step: 3
Training loss: 2.7934517860412598
Validation loss: 2.112256001400691

Epoch: 5| Step: 4
Training loss: 2.2993974685668945
Validation loss: 2.110164062951201

Epoch: 5| Step: 5
Training loss: 2.384706974029541
Validation loss: 2.1174614147473405

Epoch: 5| Step: 6
Training loss: 2.8084301948547363
Validation loss: 2.1296436658469577

Epoch: 5| Step: 7
Training loss: 1.4284865856170654
Validation loss: 2.1282834186348865

Epoch: 5| Step: 8
Training loss: 2.7346351146698
Validation loss: 2.1356747842604116

Epoch: 5| Step: 9
Training loss: 2.1144909858703613
Validation loss: 2.125835810938189

Epoch: 5| Step: 10
Training loss: 2.6083314418792725
Validation loss: 2.1303203387926986

Epoch: 130| Step: 0
Training loss: 2.6135783195495605
Validation loss: 2.14284993884384

Epoch: 5| Step: 1
Training loss: 2.331326961517334
Validation loss: 2.148044393908593

Epoch: 5| Step: 2
Training loss: 1.87688410282135
Validation loss: 2.1413327647793676

Epoch: 5| Step: 3
Training loss: 2.69466233253479
Validation loss: 2.1464132596087713

Epoch: 5| Step: 4
Training loss: 2.578562021255493
Validation loss: 2.1477673092196063

Epoch: 5| Step: 5
Training loss: 2.3063762187957764
Validation loss: 2.1397924500126995

Epoch: 5| Step: 6
Training loss: 1.4607689380645752
Validation loss: 2.140831493562268

Epoch: 5| Step: 7
Training loss: 2.767660617828369
Validation loss: 2.1303133041627946

Epoch: 5| Step: 8
Training loss: 2.676656484603882
Validation loss: 2.127497442307011

Epoch: 5| Step: 9
Training loss: 2.4591641426086426
Validation loss: 2.157252509106872

Epoch: 5| Step: 10
Training loss: 2.734163284301758
Validation loss: 2.195260090212668

Epoch: 131| Step: 0
Training loss: 1.8015506267547607
Validation loss: 2.1984296357759865

Epoch: 5| Step: 1
Training loss: 2.6378345489501953
Validation loss: 2.176582195425546

Epoch: 5| Step: 2
Training loss: 2.8871712684631348
Validation loss: 2.122210511597254

Epoch: 5| Step: 3
Training loss: 2.6178386211395264
Validation loss: 2.1043580334673644

Epoch: 5| Step: 4
Training loss: 2.370349884033203
Validation loss: 2.1074368722977175

Epoch: 5| Step: 5
Training loss: 2.680466651916504
Validation loss: 2.1159590303256945

Epoch: 5| Step: 6
Training loss: 2.153829336166382
Validation loss: 2.123196486503847

Epoch: 5| Step: 7
Training loss: 2.7031924724578857
Validation loss: 2.1269760362563597

Epoch: 5| Step: 8
Training loss: 2.3635430335998535
Validation loss: 2.130554135127734

Epoch: 5| Step: 9
Training loss: 2.0420329570770264
Validation loss: 2.1356739818408923

Epoch: 5| Step: 10
Training loss: 2.8233084678649902
Validation loss: 2.1449604136969453

Epoch: 132| Step: 0
Training loss: 1.9029289484024048
Validation loss: 2.1527701154831917

Epoch: 5| Step: 1
Training loss: 2.524010419845581
Validation loss: 2.169991925198545

Epoch: 5| Step: 2
Training loss: 2.768014430999756
Validation loss: 2.1944647732601372

Epoch: 5| Step: 3
Training loss: 2.523073673248291
Validation loss: 2.2220807536955802

Epoch: 5| Step: 4
Training loss: 2.6741385459899902
Validation loss: 2.197530195277224

Epoch: 5| Step: 5
Training loss: 2.6305031776428223
Validation loss: 2.157588166575278

Epoch: 5| Step: 6
Training loss: 1.5210000276565552
Validation loss: 2.1319624095834713

Epoch: 5| Step: 7
Training loss: 2.748577833175659
Validation loss: 2.124243567066808

Epoch: 5| Step: 8
Training loss: 2.43306565284729
Validation loss: 2.1156808535257974

Epoch: 5| Step: 9
Training loss: 2.5911781787872314
Validation loss: 2.119848394906649

Epoch: 5| Step: 10
Training loss: 2.4709904193878174
Validation loss: 2.106787586724886

Epoch: 133| Step: 0
Training loss: 2.4501545429229736
Validation loss: 2.098700459285449

Epoch: 5| Step: 1
Training loss: 2.3406577110290527
Validation loss: 2.104247978938523

Epoch: 5| Step: 2
Training loss: 2.735006809234619
Validation loss: 2.1050943072124193

Epoch: 5| Step: 3
Training loss: 2.3567662239074707
Validation loss: 2.1043633735308083

Epoch: 5| Step: 4
Training loss: 2.7625210285186768
Validation loss: 2.1534306515929518

Epoch: 5| Step: 5
Training loss: 2.190128803253174
Validation loss: 2.1689512883463213

Epoch: 5| Step: 6
Training loss: 2.0574169158935547
Validation loss: 2.1352273802603445

Epoch: 5| Step: 7
Training loss: 2.6854381561279297
Validation loss: 2.1079828841711885

Epoch: 5| Step: 8
Training loss: 2.0015580654144287
Validation loss: 2.0994052553689606

Epoch: 5| Step: 9
Training loss: 1.9165674448013306
Validation loss: 2.0918680288458384

Epoch: 5| Step: 10
Training loss: 2.8655073642730713
Validation loss: 2.097230311362974

Epoch: 134| Step: 0
Training loss: 2.5899040699005127
Validation loss: 2.101215011330061

Epoch: 5| Step: 1
Training loss: 1.9009673595428467
Validation loss: 2.094455316502561

Epoch: 5| Step: 2
Training loss: 2.5529706478118896
Validation loss: 2.1041016168491815

Epoch: 5| Step: 3
Training loss: 2.568531036376953
Validation loss: 2.1020273982837634

Epoch: 5| Step: 4
Training loss: 2.425384044647217
Validation loss: 2.1227346927888933

Epoch: 5| Step: 5
Training loss: 2.2407312393188477
Validation loss: 2.118561972853958

Epoch: 5| Step: 6
Training loss: 2.491318941116333
Validation loss: 2.136293042090631

Epoch: 5| Step: 7
Training loss: 2.22295880317688
Validation loss: 2.1477383029076362

Epoch: 5| Step: 8
Training loss: 2.4756064414978027
Validation loss: 2.155409780881738

Epoch: 5| Step: 9
Training loss: 2.9285356998443604
Validation loss: 2.1608252986784904

Epoch: 5| Step: 10
Training loss: 2.1302006244659424
Validation loss: 2.1486070848280385

Epoch: 135| Step: 0
Training loss: 2.3879497051239014
Validation loss: 2.1389416007585424

Epoch: 5| Step: 1
Training loss: 2.4597156047821045
Validation loss: 2.115492113174931

Epoch: 5| Step: 2
Training loss: 1.6717875003814697
Validation loss: 2.1130984701136106

Epoch: 5| Step: 3
Training loss: 2.873854160308838
Validation loss: 2.1131617510190575

Epoch: 5| Step: 4
Training loss: 2.1101670265197754
Validation loss: 2.116630078643881

Epoch: 5| Step: 5
Training loss: 2.9587290287017822
Validation loss: 2.1096229912132345

Epoch: 5| Step: 6
Training loss: 2.6336123943328857
Validation loss: 2.1120894852504937

Epoch: 5| Step: 7
Training loss: 2.9079174995422363
Validation loss: 2.096260804002003

Epoch: 5| Step: 8
Training loss: 1.6372514963150024
Validation loss: 2.094601232518432

Epoch: 5| Step: 9
Training loss: 2.7189419269561768
Validation loss: 2.1049817223702707

Epoch: 5| Step: 10
Training loss: 1.8847671747207642
Validation loss: 2.1054327962219075

Epoch: 136| Step: 0
Training loss: 2.3267765045166016
Validation loss: 2.106352424108854

Epoch: 5| Step: 1
Training loss: 3.006493330001831
Validation loss: 2.114603505339674

Epoch: 5| Step: 2
Training loss: 2.525461196899414
Validation loss: 2.1341549452914985

Epoch: 5| Step: 3
Training loss: 2.7496981620788574
Validation loss: 2.141793321537715

Epoch: 5| Step: 4
Training loss: 2.1467137336730957
Validation loss: 2.1589560457455215

Epoch: 5| Step: 5
Training loss: 2.353691816329956
Validation loss: 2.1130405292716077

Epoch: 5| Step: 6
Training loss: 2.167889356613159
Validation loss: 2.094511197459313

Epoch: 5| Step: 7
Training loss: 2.2915196418762207
Validation loss: 2.0799582389093216

Epoch: 5| Step: 8
Training loss: 1.7482839822769165
Validation loss: 2.078210658924554

Epoch: 5| Step: 9
Training loss: 2.1925644874572754
Validation loss: 2.0729780812417307

Epoch: 5| Step: 10
Training loss: 2.7815232276916504
Validation loss: 2.0717086151082027

Epoch: 137| Step: 0
Training loss: 2.1347806453704834
Validation loss: 2.0918941292711484

Epoch: 5| Step: 1
Training loss: 2.4086296558380127
Validation loss: 2.116061287541543

Epoch: 5| Step: 2
Training loss: 2.1984915733337402
Validation loss: 2.138808241454504

Epoch: 5| Step: 3
Training loss: 2.680781841278076
Validation loss: 2.1747272501709642

Epoch: 5| Step: 4
Training loss: 2.2017970085144043
Validation loss: 2.190172569726103

Epoch: 5| Step: 5
Training loss: 1.977056860923767
Validation loss: 2.187837508416945

Epoch: 5| Step: 6
Training loss: 2.6371729373931885
Validation loss: 2.149870123914493

Epoch: 5| Step: 7
Training loss: 2.6922049522399902
Validation loss: 2.127712708647533

Epoch: 5| Step: 8
Training loss: 2.4952120780944824
Validation loss: 2.100856437478014

Epoch: 5| Step: 9
Training loss: 2.6531596183776855
Validation loss: 2.093374039537163

Epoch: 5| Step: 10
Training loss: 2.057216167449951
Validation loss: 2.079876352381963

Epoch: 138| Step: 0
Training loss: 2.239081621170044
Validation loss: 2.0795426881441506

Epoch: 5| Step: 1
Training loss: 2.4468026161193848
Validation loss: 2.0724185884639783

Epoch: 5| Step: 2
Training loss: 2.6759448051452637
Validation loss: 2.0750369999998357

Epoch: 5| Step: 3
Training loss: 1.931123971939087
Validation loss: 2.079760309188597

Epoch: 5| Step: 4
Training loss: 2.5949668884277344
Validation loss: 2.1117402891958914

Epoch: 5| Step: 5
Training loss: 2.2276768684387207
Validation loss: 2.162907474784441

Epoch: 5| Step: 6
Training loss: 2.73478627204895
Validation loss: 2.2317566423005957

Epoch: 5| Step: 7
Training loss: 2.9534950256347656
Validation loss: 2.268826448789207

Epoch: 5| Step: 8
Training loss: 2.220149517059326
Validation loss: 2.1526667712837138

Epoch: 5| Step: 9
Training loss: 2.0828280448913574
Validation loss: 2.080821757675499

Epoch: 5| Step: 10
Training loss: 2.1359915733337402
Validation loss: 2.059133611699586

Epoch: 139| Step: 0
Training loss: 2.079113721847534
Validation loss: 2.070302083928098

Epoch: 5| Step: 1
Training loss: 2.433103561401367
Validation loss: 2.087759663981776

Epoch: 5| Step: 2
Training loss: 1.9895436763763428
Validation loss: 2.085709310347034

Epoch: 5| Step: 3
Training loss: 2.6088814735412598
Validation loss: 2.103049676905396

Epoch: 5| Step: 4
Training loss: 2.509629011154175
Validation loss: 2.0953751725535237

Epoch: 5| Step: 5
Training loss: 2.590719699859619
Validation loss: 2.0818178346080165

Epoch: 5| Step: 6
Training loss: 2.4399781227111816
Validation loss: 2.0703471450395483

Epoch: 5| Step: 7
Training loss: 2.0190234184265137
Validation loss: 2.0688038782406877

Epoch: 5| Step: 8
Training loss: 2.8936750888824463
Validation loss: 2.0779092170858897

Epoch: 5| Step: 9
Training loss: 2.9589858055114746
Validation loss: 2.1032676107139996

Epoch: 5| Step: 10
Training loss: 1.9309396743774414
Validation loss: 2.137735943640432

Epoch: 140| Step: 0
Training loss: 2.011038064956665
Validation loss: 2.1514042013434955

Epoch: 5| Step: 1
Training loss: 1.7952041625976562
Validation loss: 2.153652896163284

Epoch: 5| Step: 2
Training loss: 2.480048894882202
Validation loss: 2.142752706363637

Epoch: 5| Step: 3
Training loss: 2.375134229660034
Validation loss: 2.1137888713549544

Epoch: 5| Step: 4
Training loss: 2.1215882301330566
Validation loss: 2.0978911640823528

Epoch: 5| Step: 5
Training loss: 1.589219093322754
Validation loss: 2.0843763248894804

Epoch: 5| Step: 6
Training loss: 2.5204339027404785
Validation loss: 2.08306477403128

Epoch: 5| Step: 7
Training loss: 2.0643112659454346
Validation loss: 2.0672839610807356

Epoch: 5| Step: 8
Training loss: 2.647312641143799
Validation loss: 2.064462502797445

Epoch: 5| Step: 9
Training loss: 3.2119529247283936
Validation loss: 2.053575372183195

Epoch: 5| Step: 10
Training loss: 3.2093801498413086
Validation loss: 2.037115535428447

Epoch: 141| Step: 0
Training loss: 2.1336090564727783
Validation loss: 2.0372290124175367

Epoch: 5| Step: 1
Training loss: 1.7573665380477905
Validation loss: 2.0427566523193033

Epoch: 5| Step: 2
Training loss: 2.321568250656128
Validation loss: 2.0385634924775813

Epoch: 5| Step: 3
Training loss: 2.9219138622283936
Validation loss: 2.0452032319961058

Epoch: 5| Step: 4
Training loss: 2.5279927253723145
Validation loss: 2.063009400521555

Epoch: 5| Step: 5
Training loss: 2.3026812076568604
Validation loss: 2.0824890828901723

Epoch: 5| Step: 6
Training loss: 2.472362756729126
Validation loss: 2.0814212560653687

Epoch: 5| Step: 7
Training loss: 2.758716344833374
Validation loss: 2.081728635295745

Epoch: 5| Step: 8
Training loss: 2.2024941444396973
Validation loss: 2.101582165687315

Epoch: 5| Step: 9
Training loss: 2.0504777431488037
Validation loss: 2.0955380303885347

Epoch: 5| Step: 10
Training loss: 2.2081472873687744
Validation loss: 2.0909532808488414

Epoch: 142| Step: 0
Training loss: 2.466770648956299
Validation loss: 2.0678897596174672

Epoch: 5| Step: 1
Training loss: 2.544743061065674
Validation loss: 2.047330512795397

Epoch: 5| Step: 2
Training loss: 2.506337881088257
Validation loss: 2.043221196820659

Epoch: 5| Step: 3
Training loss: 2.373173475265503
Validation loss: 2.0430782789825113

Epoch: 5| Step: 4
Training loss: 2.6799802780151367
Validation loss: 2.0396939080248595

Epoch: 5| Step: 5
Training loss: 2.04944109916687
Validation loss: 2.0361278723644953

Epoch: 5| Step: 6
Training loss: 2.165010929107666
Validation loss: 2.0382727576840307

Epoch: 5| Step: 7
Training loss: 1.9967243671417236
Validation loss: 2.0505838099346367

Epoch: 5| Step: 8
Training loss: 2.8899013996124268
Validation loss: 2.0394861672514226

Epoch: 5| Step: 9
Training loss: 1.9134986400604248
Validation loss: 2.0300016172470583

Epoch: 5| Step: 10
Training loss: 2.0623221397399902
Validation loss: 2.036460445773217

Epoch: 143| Step: 0
Training loss: 2.2933342456817627
Validation loss: 2.047447964709292

Epoch: 5| Step: 1
Training loss: 2.067927598953247
Validation loss: 2.0333725162731704

Epoch: 5| Step: 2
Training loss: 3.284154176712036
Validation loss: 2.041632520255222

Epoch: 5| Step: 3
Training loss: 2.3230841159820557
Validation loss: 2.040190367288487

Epoch: 5| Step: 4
Training loss: 2.214984178543091
Validation loss: 2.049675700485065

Epoch: 5| Step: 5
Training loss: 1.9875303506851196
Validation loss: 2.079900645440625

Epoch: 5| Step: 6
Training loss: 2.4435038566589355
Validation loss: 2.095510916043353

Epoch: 5| Step: 7
Training loss: 2.5257515907287598
Validation loss: 2.103429937875399

Epoch: 5| Step: 8
Training loss: 1.620306372642517
Validation loss: 2.096674059026985

Epoch: 5| Step: 9
Training loss: 2.18198299407959
Validation loss: 2.080917212270921

Epoch: 5| Step: 10
Training loss: 2.7081642150878906
Validation loss: 2.0845033968648603

Epoch: 144| Step: 0
Training loss: 1.5895881652832031
Validation loss: 2.0785049687149706

Epoch: 5| Step: 1
Training loss: 2.517116069793701
Validation loss: 2.0676239946837067

Epoch: 5| Step: 2
Training loss: 2.3887691497802734
Validation loss: 2.0485583659141295

Epoch: 5| Step: 3
Training loss: 2.7205615043640137
Validation loss: 2.04371537188048

Epoch: 5| Step: 4
Training loss: 2.352482318878174
Validation loss: 2.043482349764916

Epoch: 5| Step: 5
Training loss: 2.0931854248046875
Validation loss: 2.0378999184536677

Epoch: 5| Step: 6
Training loss: 2.504948139190674
Validation loss: 2.0381562453444286

Epoch: 5| Step: 7
Training loss: 2.6232662200927734
Validation loss: 2.040068951986169

Epoch: 5| Step: 8
Training loss: 2.2195839881896973
Validation loss: 2.0335975616208968

Epoch: 5| Step: 9
Training loss: 2.387694835662842
Validation loss: 2.0345289861002276

Epoch: 5| Step: 10
Training loss: 2.4248905181884766
Validation loss: 2.0449214519992953

Epoch: 145| Step: 0
Training loss: 2.1513047218322754
Validation loss: 2.045045100232606

Epoch: 5| Step: 1
Training loss: 1.8956648111343384
Validation loss: 2.097178178448831

Epoch: 5| Step: 2
Training loss: 2.7632086277008057
Validation loss: 2.1486690839131675

Epoch: 5| Step: 3
Training loss: 2.7051684856414795
Validation loss: 2.180466736516645

Epoch: 5| Step: 4
Training loss: 2.0615153312683105
Validation loss: 2.1775897113225793

Epoch: 5| Step: 5
Training loss: 2.0766849517822266
Validation loss: 2.161850598550612

Epoch: 5| Step: 6
Training loss: 2.2092320919036865
Validation loss: 2.0883752453711724

Epoch: 5| Step: 7
Training loss: 2.891584634780884
Validation loss: 2.060264620729672

Epoch: 5| Step: 8
Training loss: 2.1390132904052734
Validation loss: 2.0549296973853983

Epoch: 5| Step: 9
Training loss: 2.3022403717041016
Validation loss: 2.0529312215825564

Epoch: 5| Step: 10
Training loss: 2.7483181953430176
Validation loss: 2.0439943011089037

Epoch: 146| Step: 0
Training loss: 1.8928636312484741
Validation loss: 2.0461750120245

Epoch: 5| Step: 1
Training loss: 2.662628412246704
Validation loss: 2.031912347321869

Epoch: 5| Step: 2
Training loss: 2.3410332202911377
Validation loss: 2.034848928451538

Epoch: 5| Step: 3
Training loss: 2.441723346710205
Validation loss: 2.028366963068644

Epoch: 5| Step: 4
Training loss: 2.0964415073394775
Validation loss: 2.039546292315247

Epoch: 5| Step: 5
Training loss: 2.5195975303649902
Validation loss: 2.051170395266625

Epoch: 5| Step: 6
Training loss: 2.397402763366699
Validation loss: 2.064794417350523

Epoch: 5| Step: 7
Training loss: 1.7664703130722046
Validation loss: 2.07530241756029

Epoch: 5| Step: 8
Training loss: 2.888624668121338
Validation loss: 2.079484034610051

Epoch: 5| Step: 9
Training loss: 2.3986401557922363
Validation loss: 2.081286076576479

Epoch: 5| Step: 10
Training loss: 2.134486198425293
Validation loss: 2.044809037639249

Epoch: 147| Step: 0
Training loss: 2.6205742359161377
Validation loss: 2.0323357556455877

Epoch: 5| Step: 1
Training loss: 2.649576425552368
Validation loss: 2.024367356813082

Epoch: 5| Step: 2
Training loss: 2.440697431564331
Validation loss: 2.0246227531022924

Epoch: 5| Step: 3
Training loss: 2.486809015274048
Validation loss: 2.01930062232479

Epoch: 5| Step: 4
Training loss: 1.9142532348632812
Validation loss: 2.01677583366312

Epoch: 5| Step: 5
Training loss: 2.2234625816345215
Validation loss: 2.011700052087025

Epoch: 5| Step: 6
Training loss: 1.2576987743377686
Validation loss: 2.0205463529914938

Epoch: 5| Step: 7
Training loss: 2.1671993732452393
Validation loss: 2.023289185698314

Epoch: 5| Step: 8
Training loss: 2.991431951522827
Validation loss: 2.0195831098864154

Epoch: 5| Step: 9
Training loss: 1.9412845373153687
Validation loss: 2.025610386684377

Epoch: 5| Step: 10
Training loss: 2.6956191062927246
Validation loss: 2.019286068536902

Epoch: 148| Step: 0
Training loss: 2.273406982421875
Validation loss: 2.027110566375076

Epoch: 5| Step: 1
Training loss: 2.6747734546661377
Validation loss: 2.0404161471192555

Epoch: 5| Step: 2
Training loss: 2.094386100769043
Validation loss: 2.0483042975907684

Epoch: 5| Step: 3
Training loss: 2.7885444164276123
Validation loss: 2.05790775950237

Epoch: 5| Step: 4
Training loss: 2.033761978149414
Validation loss: 2.039459136224562

Epoch: 5| Step: 5
Training loss: 2.443498134613037
Validation loss: 2.028088826005177

Epoch: 5| Step: 6
Training loss: 2.2208504676818848
Validation loss: 2.0350616414059877

Epoch: 5| Step: 7
Training loss: 2.1587331295013428
Validation loss: 2.0388451327559767

Epoch: 5| Step: 8
Training loss: 2.5051238536834717
Validation loss: 2.0498092917985815

Epoch: 5| Step: 9
Training loss: 2.0191562175750732
Validation loss: 2.063600197915108

Epoch: 5| Step: 10
Training loss: 2.050713539123535
Validation loss: 2.0470675729936167

Epoch: 149| Step: 0
Training loss: 2.421879529953003
Validation loss: 2.039625293465071

Epoch: 5| Step: 1
Training loss: 2.4182493686676025
Validation loss: 2.046123625129782

Epoch: 5| Step: 2
Training loss: 2.193957567214966
Validation loss: 2.0298610195036857

Epoch: 5| Step: 3
Training loss: 2.2865688800811768
Validation loss: 2.0540886796930784

Epoch: 5| Step: 4
Training loss: 2.718287944793701
Validation loss: 2.0633375183228524

Epoch: 5| Step: 5
Training loss: 2.315073251724243
Validation loss: 2.069523093520954

Epoch: 5| Step: 6
Training loss: 2.3298652172088623
Validation loss: 2.088179870318341

Epoch: 5| Step: 7
Training loss: 2.3745760917663574
Validation loss: 2.079749059933488

Epoch: 5| Step: 8
Training loss: 2.147869110107422
Validation loss: 2.0833821091600644

Epoch: 5| Step: 9
Training loss: 2.2605655193328857
Validation loss: 2.038615640773568

Epoch: 5| Step: 10
Training loss: 1.7540346384048462
Validation loss: 2.006250327633273

Epoch: 150| Step: 0
Training loss: 2.716841220855713
Validation loss: 2.0001224202494465

Epoch: 5| Step: 1
Training loss: 2.286123037338257
Validation loss: 1.9953156004669845

Epoch: 5| Step: 2
Training loss: 2.7061574459075928
Validation loss: 2.011280157232797

Epoch: 5| Step: 3
Training loss: 2.0179948806762695
Validation loss: 2.0138927454589517

Epoch: 5| Step: 4
Training loss: 2.490813970565796
Validation loss: 2.030134592005002

Epoch: 5| Step: 5
Training loss: 2.8007540702819824
Validation loss: 2.039627839160222

Epoch: 5| Step: 6
Training loss: 1.5394293069839478
Validation loss: 2.063390165246943

Epoch: 5| Step: 7
Training loss: 1.7842960357666016
Validation loss: 2.0729397522505892

Epoch: 5| Step: 8
Training loss: 2.6027112007141113
Validation loss: 2.1089673324297835

Epoch: 5| Step: 9
Training loss: 2.1878585815429688
Validation loss: 2.1514418842971965

Epoch: 5| Step: 10
Training loss: 2.3558731079101562
Validation loss: 2.204570001171481

Epoch: 151| Step: 0
Training loss: 2.744082450866699
Validation loss: 2.231208288541404

Epoch: 5| Step: 1
Training loss: 2.0862374305725098
Validation loss: 2.1720491968175417

Epoch: 5| Step: 2
Training loss: 2.0005221366882324
Validation loss: 2.0887662403045164

Epoch: 5| Step: 3
Training loss: 2.636460542678833
Validation loss: 2.0449977702991937

Epoch: 5| Step: 4
Training loss: 2.2894678115844727
Validation loss: 2.0277620938516434

Epoch: 5| Step: 5
Training loss: 2.4991374015808105
Validation loss: 2.0257881918261127

Epoch: 5| Step: 6
Training loss: 2.3901572227478027
Validation loss: 2.01574065608363

Epoch: 5| Step: 7
Training loss: 1.9696369171142578
Validation loss: 2.008160014306345

Epoch: 5| Step: 8
Training loss: 2.268012523651123
Validation loss: 1.9989671617425897

Epoch: 5| Step: 9
Training loss: 2.405977725982666
Validation loss: 2.001674158598787

Epoch: 5| Step: 10
Training loss: 2.0974109172821045
Validation loss: 2.0002414193204654

Epoch: 152| Step: 0
Training loss: 2.0435898303985596
Validation loss: 2.001271042772519

Epoch: 5| Step: 1
Training loss: 2.515394687652588
Validation loss: 2.0091565424396145

Epoch: 5| Step: 2
Training loss: 2.6271233558654785
Validation loss: 2.021416732060012

Epoch: 5| Step: 3
Training loss: 2.4761130809783936
Validation loss: 2.0276859075792375

Epoch: 5| Step: 4
Training loss: 2.5560052394866943
Validation loss: 2.0245210329691568

Epoch: 5| Step: 5
Training loss: 2.0792298316955566
Validation loss: 2.0387807725578226

Epoch: 5| Step: 6
Training loss: 1.7746450901031494
Validation loss: 2.0370474746150355

Epoch: 5| Step: 7
Training loss: 1.934617280960083
Validation loss: 2.0371199833449496

Epoch: 5| Step: 8
Training loss: 1.9788875579833984
Validation loss: 1.9960798435313727

Epoch: 5| Step: 9
Training loss: 2.865722179412842
Validation loss: 1.9839158724713069

Epoch: 5| Step: 10
Training loss: 2.327383518218994
Validation loss: 1.996398869381156

Epoch: 153| Step: 0
Training loss: 1.7504708766937256
Validation loss: 2.0014509565086773

Epoch: 5| Step: 1
Training loss: 2.774146556854248
Validation loss: 1.996432077500128

Epoch: 5| Step: 2
Training loss: 1.9470913410186768
Validation loss: 2.0058362765978743

Epoch: 5| Step: 3
Training loss: 2.416588306427002
Validation loss: 2.0015006885733655

Epoch: 5| Step: 4
Training loss: 2.2962629795074463
Validation loss: 2.0055065334484143

Epoch: 5| Step: 5
Training loss: 2.461456298828125
Validation loss: 2.004718893317766

Epoch: 5| Step: 6
Training loss: 1.9968124628067017
Validation loss: 2.0018329722906953

Epoch: 5| Step: 7
Training loss: 2.402052402496338
Validation loss: 2.0001647805654876

Epoch: 5| Step: 8
Training loss: 2.1210665702819824
Validation loss: 1.9959807267753027

Epoch: 5| Step: 9
Training loss: 2.5760395526885986
Validation loss: 1.9993091360215218

Epoch: 5| Step: 10
Training loss: 2.5541465282440186
Validation loss: 2.022489865620931

Epoch: 154| Step: 0
Training loss: 2.1670665740966797
Validation loss: 2.0509744587764946

Epoch: 5| Step: 1
Training loss: 2.1462626457214355
Validation loss: 2.079276095154465

Epoch: 5| Step: 2
Training loss: 2.34110689163208
Validation loss: 2.0671182986228698

Epoch: 5| Step: 3
Training loss: 1.626007080078125
Validation loss: 2.0669012172247774

Epoch: 5| Step: 4
Training loss: 2.036076068878174
Validation loss: 2.0476148102873113

Epoch: 5| Step: 5
Training loss: 2.6532082557678223
Validation loss: 2.0200908530143

Epoch: 5| Step: 6
Training loss: 3.085095167160034
Validation loss: 2.0063691446858067

Epoch: 5| Step: 7
Training loss: 2.419557571411133
Validation loss: 2.01069672389697

Epoch: 5| Step: 8
Training loss: 2.3452532291412354
Validation loss: 2.006321386624408

Epoch: 5| Step: 9
Training loss: 2.0577118396759033
Validation loss: 2.00648985626877

Epoch: 5| Step: 10
Training loss: 2.2632198333740234
Validation loss: 2.0158519616691013

Epoch: 155| Step: 0
Training loss: 1.9293310642242432
Validation loss: 2.019683409762639

Epoch: 5| Step: 1
Training loss: 2.6841444969177246
Validation loss: 2.0497162829163256

Epoch: 5| Step: 2
Training loss: 2.2261459827423096
Validation loss: 2.084629128056188

Epoch: 5| Step: 3
Training loss: 1.9733463525772095
Validation loss: 2.111035572585239

Epoch: 5| Step: 4
Training loss: 2.081425428390503
Validation loss: 2.112294581628615

Epoch: 5| Step: 5
Training loss: 2.270827054977417
Validation loss: 2.057378166465349

Epoch: 5| Step: 6
Training loss: 2.1640357971191406
Validation loss: 2.027939678520285

Epoch: 5| Step: 7
Training loss: 2.160191774368286
Validation loss: 2.0311103161945137

Epoch: 5| Step: 8
Training loss: 2.4017646312713623
Validation loss: 2.046335692046791

Epoch: 5| Step: 9
Training loss: 2.665027618408203
Validation loss: 2.022863462407102

Epoch: 5| Step: 10
Training loss: 2.511746644973755
Validation loss: 2.0061977371092765

Epoch: 156| Step: 0
Training loss: 1.9075199365615845
Validation loss: 1.9997736882137995

Epoch: 5| Step: 1
Training loss: 2.4061975479125977
Validation loss: 2.0034433423831897

Epoch: 5| Step: 2
Training loss: 2.225755214691162
Validation loss: 1.9967952479598343

Epoch: 5| Step: 3
Training loss: 2.2489378452301025
Validation loss: 2.0068282581144765

Epoch: 5| Step: 4
Training loss: 1.9037399291992188
Validation loss: 1.9986633434090564

Epoch: 5| Step: 5
Training loss: 2.4177167415618896
Validation loss: 2.008198725279941

Epoch: 5| Step: 6
Training loss: 2.056344509124756
Validation loss: 2.027253517540552

Epoch: 5| Step: 7
Training loss: 2.195620059967041
Validation loss: 2.038491097829675

Epoch: 5| Step: 8
Training loss: 2.324432134628296
Validation loss: 2.0287720721255065

Epoch: 5| Step: 9
Training loss: 2.7689788341522217
Validation loss: 2.0262702895749

Epoch: 5| Step: 10
Training loss: 2.616124391555786
Validation loss: 2.011352733899188

Epoch: 157| Step: 0
Training loss: 2.664964199066162
Validation loss: 2.0187495267519386

Epoch: 5| Step: 1
Training loss: 2.15553879737854
Validation loss: 2.021734599144228

Epoch: 5| Step: 2
Training loss: 2.010777235031128
Validation loss: 2.0142134210114837

Epoch: 5| Step: 3
Training loss: 2.417328119277954
Validation loss: 2.0214631070372877

Epoch: 5| Step: 4
Training loss: 2.7555437088012695
Validation loss: 2.025573281831639

Epoch: 5| Step: 5
Training loss: 1.9499499797821045
Validation loss: 2.031473934009511

Epoch: 5| Step: 6
Training loss: 1.813026785850525
Validation loss: 2.0592399553586076

Epoch: 5| Step: 7
Training loss: 2.4765098094940186
Validation loss: 2.058565475607431

Epoch: 5| Step: 8
Training loss: 2.043461561203003
Validation loss: 2.0372573252647155

Epoch: 5| Step: 9
Training loss: 2.31321382522583
Validation loss: 2.0247436749037875

Epoch: 5| Step: 10
Training loss: 2.0820796489715576
Validation loss: 2.015676303576398

Epoch: 158| Step: 0
Training loss: 2.2983498573303223
Validation loss: 2.0026362685747046

Epoch: 5| Step: 1
Training loss: 2.6218953132629395
Validation loss: 1.9996698876862884

Epoch: 5| Step: 2
Training loss: 2.7229247093200684
Validation loss: 1.9940382255020963

Epoch: 5| Step: 3
Training loss: 2.24455189704895
Validation loss: 1.997754161075879

Epoch: 5| Step: 4
Training loss: 2.1654489040374756
Validation loss: 1.9941738446553547

Epoch: 5| Step: 5
Training loss: 2.710139036178589
Validation loss: 1.9969733915021342

Epoch: 5| Step: 6
Training loss: 2.0695509910583496
Validation loss: 1.9952365608625515

Epoch: 5| Step: 7
Training loss: 2.3133082389831543
Validation loss: 1.987760087495209

Epoch: 5| Step: 8
Training loss: 1.5017365217208862
Validation loss: 1.9998816790119294

Epoch: 5| Step: 9
Training loss: 2.480940341949463
Validation loss: 1.9998621556066698

Epoch: 5| Step: 10
Training loss: 1.510359764099121
Validation loss: 1.997752051199636

Epoch: 159| Step: 0
Training loss: 2.844554901123047
Validation loss: 2.016326729969312

Epoch: 5| Step: 1
Training loss: 2.3344223499298096
Validation loss: 2.026283223141906

Epoch: 5| Step: 2
Training loss: 2.0151255130767822
Validation loss: 2.042659200647826

Epoch: 5| Step: 3
Training loss: 3.045963764190674
Validation loss: 2.044435553653266

Epoch: 5| Step: 4
Training loss: 2.0755298137664795
Validation loss: 2.0210902767796672

Epoch: 5| Step: 5
Training loss: 2.4105887413024902
Validation loss: 1.9865730577899563

Epoch: 5| Step: 6
Training loss: 1.524460792541504
Validation loss: 1.9746626154068978

Epoch: 5| Step: 7
Training loss: 1.9443070888519287
Validation loss: 1.9561547387030818

Epoch: 5| Step: 8
Training loss: 2.1111302375793457
Validation loss: 1.9674084135281142

Epoch: 5| Step: 9
Training loss: 2.2426822185516357
Validation loss: 1.9758789282973095

Epoch: 5| Step: 10
Training loss: 2.1998016834259033
Validation loss: 1.9755123315318939

Epoch: 160| Step: 0
Training loss: 2.652486801147461
Validation loss: 1.9755244742157638

Epoch: 5| Step: 1
Training loss: 1.8697082996368408
Validation loss: 1.9854543952531711

Epoch: 5| Step: 2
Training loss: 1.8461967706680298
Validation loss: 1.9875809748967488

Epoch: 5| Step: 3
Training loss: 2.4174959659576416
Validation loss: 1.9983836502157233

Epoch: 5| Step: 4
Training loss: 2.259828567504883
Validation loss: 2.015961591915418

Epoch: 5| Step: 5
Training loss: 1.9140344858169556
Validation loss: 2.026929178545552

Epoch: 5| Step: 6
Training loss: 2.388819932937622
Validation loss: 2.026090557857226

Epoch: 5| Step: 7
Training loss: 2.415421724319458
Validation loss: 2.0407522878339215

Epoch: 5| Step: 8
Training loss: 2.5542585849761963
Validation loss: 2.0641926642387145

Epoch: 5| Step: 9
Training loss: 2.445406436920166
Validation loss: 2.065654427774491

Epoch: 5| Step: 10
Training loss: 1.8927701711654663
Validation loss: 2.0491939347277404

Epoch: 161| Step: 0
Training loss: 2.003180503845215
Validation loss: 2.03411017951145

Epoch: 5| Step: 1
Training loss: 1.7147753238677979
Validation loss: 2.052146710375304

Epoch: 5| Step: 2
Training loss: 2.139464855194092
Validation loss: 2.069475696932885

Epoch: 5| Step: 3
Training loss: 2.122077703475952
Validation loss: 2.041673157804756

Epoch: 5| Step: 4
Training loss: 2.361203670501709
Validation loss: 2.026057744538912

Epoch: 5| Step: 5
Training loss: 2.579972743988037
Validation loss: 2.020109074090117

Epoch: 5| Step: 6
Training loss: 2.0496840476989746
Validation loss: 2.007108465317757

Epoch: 5| Step: 7
Training loss: 2.669081687927246
Validation loss: 2.046559520947036

Epoch: 5| Step: 8
Training loss: 2.1546504497528076
Validation loss: 2.0834543525531726

Epoch: 5| Step: 9
Training loss: 2.2861762046813965
Validation loss: 2.0793570395438903

Epoch: 5| Step: 10
Training loss: 2.620331048965454
Validation loss: 2.0666079623724825

Epoch: 162| Step: 0
Training loss: 2.2141077518463135
Validation loss: 2.0149326837191017

Epoch: 5| Step: 1
Training loss: 2.9311957359313965
Validation loss: 1.984243627517454

Epoch: 5| Step: 2
Training loss: 2.223172187805176
Validation loss: 1.9664666627043037

Epoch: 5| Step: 3
Training loss: 3.05900239944458
Validation loss: 1.9771954321092176

Epoch: 5| Step: 4
Training loss: 2.9182956218719482
Validation loss: 1.9821910037789294

Epoch: 5| Step: 5
Training loss: 2.1982998847961426
Validation loss: 1.9910797636996034

Epoch: 5| Step: 6
Training loss: 1.6188404560089111
Validation loss: 1.9915872184179162

Epoch: 5| Step: 7
Training loss: 2.020052671432495
Validation loss: 1.9888359487697642

Epoch: 5| Step: 8
Training loss: 1.9068939685821533
Validation loss: 2.010483916087817

Epoch: 5| Step: 9
Training loss: 1.5183842182159424
Validation loss: 2.0065190099900767

Epoch: 5| Step: 10
Training loss: 2.1840627193450928
Validation loss: 2.0297820157902215

Epoch: 163| Step: 0
Training loss: 2.4983420372009277
Validation loss: 2.0520004982589395

Epoch: 5| Step: 1
Training loss: 1.6022615432739258
Validation loss: 2.0347128337429417

Epoch: 5| Step: 2
Training loss: 2.0397911071777344
Validation loss: 2.0140403060502905

Epoch: 5| Step: 3
Training loss: 1.964943528175354
Validation loss: 1.9881389576901671

Epoch: 5| Step: 4
Training loss: 2.9742977619171143
Validation loss: 1.9720828635718233

Epoch: 5| Step: 5
Training loss: 1.7240406274795532
Validation loss: 1.9630230088387766

Epoch: 5| Step: 6
Training loss: 2.88226056098938
Validation loss: 1.9549085670901882

Epoch: 5| Step: 7
Training loss: 2.059239149093628
Validation loss: 1.9504995986979494

Epoch: 5| Step: 8
Training loss: 1.7426965236663818
Validation loss: 1.9484189018126457

Epoch: 5| Step: 9
Training loss: 2.561803102493286
Validation loss: 1.9461665614958732

Epoch: 5| Step: 10
Training loss: 2.4204564094543457
Validation loss: 1.9553664089531027

Epoch: 164| Step: 0
Training loss: 2.271367311477661
Validation loss: 1.9588036665352442

Epoch: 5| Step: 1
Training loss: 2.362093448638916
Validation loss: 1.96561429321125

Epoch: 5| Step: 2
Training loss: 2.056030511856079
Validation loss: 1.9672991896188388

Epoch: 5| Step: 3
Training loss: 2.6444249153137207
Validation loss: 1.977234782711152

Epoch: 5| Step: 4
Training loss: 1.7565120458602905
Validation loss: 1.9800352768231464

Epoch: 5| Step: 5
Training loss: 2.850782871246338
Validation loss: 1.9795188083443591

Epoch: 5| Step: 6
Training loss: 2.2781364917755127
Validation loss: 1.9687985604809177

Epoch: 5| Step: 7
Training loss: 1.7983973026275635
Validation loss: 1.98144026981887

Epoch: 5| Step: 8
Training loss: 2.0599589347839355
Validation loss: 1.9750592054859284

Epoch: 5| Step: 9
Training loss: 2.1472480297088623
Validation loss: 1.983121830929992

Epoch: 5| Step: 10
Training loss: 1.7933356761932373
Validation loss: 1.9872086868491223

Epoch: 165| Step: 0
Training loss: 2.723050355911255
Validation loss: 1.9766212663342875

Epoch: 5| Step: 1
Training loss: 2.2127041816711426
Validation loss: 1.9793416915401336

Epoch: 5| Step: 2
Training loss: 2.9029197692871094
Validation loss: 1.9811296950104416

Epoch: 5| Step: 3
Training loss: 1.9801130294799805
Validation loss: 1.9900287979392595

Epoch: 5| Step: 4
Training loss: 1.696622610092163
Validation loss: 1.9967642317536056

Epoch: 5| Step: 5
Training loss: 2.0626766681671143
Validation loss: 2.0159742537365166

Epoch: 5| Step: 6
Training loss: 1.8227275609970093
Validation loss: 2.0183248891625354

Epoch: 5| Step: 7
Training loss: 2.1626436710357666
Validation loss: 1.9962232138520928

Epoch: 5| Step: 8
Training loss: 1.9328527450561523
Validation loss: 1.976173944370721

Epoch: 5| Step: 9
Training loss: 2.4840312004089355
Validation loss: 1.9620594068240094

Epoch: 5| Step: 10
Training loss: 2.134676456451416
Validation loss: 1.9557755057529738

Epoch: 166| Step: 0
Training loss: 1.8828102350234985
Validation loss: 1.9560796253142818

Epoch: 5| Step: 1
Training loss: 2.5778634548187256
Validation loss: 1.973841546684183

Epoch: 5| Step: 2
Training loss: 2.245506763458252
Validation loss: 1.9776669753495084

Epoch: 5| Step: 3
Training loss: 2.8547234535217285
Validation loss: 1.99405982289263

Epoch: 5| Step: 4
Training loss: 1.9154655933380127
Validation loss: 2.0145386559988863

Epoch: 5| Step: 5
Training loss: 2.4277775287628174
Validation loss: 2.0350542017208633

Epoch: 5| Step: 6
Training loss: 2.1982836723327637
Validation loss: 2.051791221864762

Epoch: 5| Step: 7
Training loss: 1.6456724405288696
Validation loss: 2.071420923356087

Epoch: 5| Step: 8
Training loss: 2.6763973236083984
Validation loss: 2.081834484172124

Epoch: 5| Step: 9
Training loss: 2.029486656188965
Validation loss: 2.056804956928376

Epoch: 5| Step: 10
Training loss: 1.7571359872817993
Validation loss: 2.009893910859221

Epoch: 167| Step: 0
Training loss: 2.7083542346954346
Validation loss: 2.0007113141398274

Epoch: 5| Step: 1
Training loss: 2.3395166397094727
Validation loss: 1.9895129831888343

Epoch: 5| Step: 2
Training loss: 2.037703037261963
Validation loss: 1.9905460444829797

Epoch: 5| Step: 3
Training loss: 2.222463846206665
Validation loss: 1.9826360646114554

Epoch: 5| Step: 4
Training loss: 1.9481937885284424
Validation loss: 1.9747617808721398

Epoch: 5| Step: 5
Training loss: 1.8685986995697021
Validation loss: 1.9739625812858663

Epoch: 5| Step: 6
Training loss: 2.113032102584839
Validation loss: 1.9552887729419175

Epoch: 5| Step: 7
Training loss: 1.8500919342041016
Validation loss: 1.9674663953883673

Epoch: 5| Step: 8
Training loss: 1.9971990585327148
Validation loss: 1.9742004897004815

Epoch: 5| Step: 9
Training loss: 2.602978229522705
Validation loss: 1.997150537788227

Epoch: 5| Step: 10
Training loss: 2.6003341674804688
Validation loss: 2.0327048404242403

Epoch: 168| Step: 0
Training loss: 2.8554129600524902
Validation loss: 2.0506068980822

Epoch: 5| Step: 1
Training loss: 2.447138547897339
Validation loss: 2.0409958811216455

Epoch: 5| Step: 2
Training loss: 1.8541209697723389
Validation loss: 2.0205034543109197

Epoch: 5| Step: 3
Training loss: 2.367551326751709
Validation loss: 2.002530191534309

Epoch: 5| Step: 4
Training loss: 1.5232386589050293
Validation loss: 1.9878873901982461

Epoch: 5| Step: 5
Training loss: 2.3293347358703613
Validation loss: 2.015950410596786

Epoch: 5| Step: 6
Training loss: 1.6522839069366455
Validation loss: 2.0348664150443128

Epoch: 5| Step: 7
Training loss: 1.9832960367202759
Validation loss: 2.0339397538092827

Epoch: 5| Step: 8
Training loss: 2.415311813354492
Validation loss: 2.0253442641227477

Epoch: 5| Step: 9
Training loss: 2.986652374267578
Validation loss: 2.0055436075374646

Epoch: 5| Step: 10
Training loss: 1.9143511056900024
Validation loss: 2.009683911518384

Epoch: 169| Step: 0
Training loss: 1.3969513177871704
Validation loss: 2.02055618070787

Epoch: 5| Step: 1
Training loss: 2.0658164024353027
Validation loss: 2.0383998476048952

Epoch: 5| Step: 2
Training loss: 2.336149215698242
Validation loss: 2.0385267311526882

Epoch: 5| Step: 3
Training loss: 3.1163744926452637
Validation loss: 2.0241145164735856

Epoch: 5| Step: 4
Training loss: 2.192941188812256
Validation loss: 2.0081558958176644

Epoch: 5| Step: 5
Training loss: 2.835533618927002
Validation loss: 2.046321151077106

Epoch: 5| Step: 6
Training loss: 2.6256587505340576
Validation loss: 2.0714701170562417

Epoch: 5| Step: 7
Training loss: 2.055637836456299
Validation loss: 2.0919669699925247

Epoch: 5| Step: 8
Training loss: 1.8673107624053955
Validation loss: 2.08956007547276

Epoch: 5| Step: 9
Training loss: 1.5550315380096436
Validation loss: 2.053791774216519

Epoch: 5| Step: 10
Training loss: 2.2819583415985107
Validation loss: 2.031651453305316

Epoch: 170| Step: 0
Training loss: 1.947382926940918
Validation loss: 2.0371557922773462

Epoch: 5| Step: 1
Training loss: 2.4282114505767822
Validation loss: 2.0612186719012517

Epoch: 5| Step: 2
Training loss: 2.5842645168304443
Validation loss: 2.0678562541161813

Epoch: 5| Step: 3
Training loss: 2.5253329277038574
Validation loss: 2.105948407162902

Epoch: 5| Step: 4
Training loss: 2.1533255577087402
Validation loss: 2.10832009648764

Epoch: 5| Step: 5
Training loss: 1.9463084936141968
Validation loss: 2.0717118094044347

Epoch: 5| Step: 6
Training loss: 2.503253221511841
Validation loss: 2.006421496791224

Epoch: 5| Step: 7
Training loss: 1.8260520696640015
Validation loss: 1.987198527141284

Epoch: 5| Step: 8
Training loss: 2.285054922103882
Validation loss: 2.0215249523039787

Epoch: 5| Step: 9
Training loss: 1.78164541721344
Validation loss: 2.0132021198990526

Epoch: 5| Step: 10
Training loss: 2.5348217487335205
Validation loss: 1.9945207244606429

Epoch: 171| Step: 0
Training loss: 2.017467737197876
Validation loss: 1.9590577810041365

Epoch: 5| Step: 1
Training loss: 2.296708822250366
Validation loss: 1.9578623694758261

Epoch: 5| Step: 2
Training loss: 2.1542904376983643
Validation loss: 1.9532653490702312

Epoch: 5| Step: 3
Training loss: 2.224348545074463
Validation loss: 1.9633081343866163

Epoch: 5| Step: 4
Training loss: 2.6353447437286377
Validation loss: 1.9947441624056907

Epoch: 5| Step: 5
Training loss: 1.9571220874786377
Validation loss: 2.0149811506271362

Epoch: 5| Step: 6
Training loss: 2.4119553565979004
Validation loss: 2.040945370992025

Epoch: 5| Step: 7
Training loss: 1.9129126071929932
Validation loss: 2.0514842540987077

Epoch: 5| Step: 8
Training loss: 2.0053229331970215
Validation loss: 2.0358970203707294

Epoch: 5| Step: 9
Training loss: 2.017176389694214
Validation loss: 2.0264700625532415

Epoch: 5| Step: 10
Training loss: 2.303060531616211
Validation loss: 2.019102786176948

Epoch: 172| Step: 0
Training loss: 1.7472360134124756
Validation loss: 2.0047719478607178

Epoch: 5| Step: 1
Training loss: 2.6093387603759766
Validation loss: 1.9931250977259811

Epoch: 5| Step: 2
Training loss: 2.486710548400879
Validation loss: 1.980131378737829

Epoch: 5| Step: 3
Training loss: 2.101289749145508
Validation loss: 1.9667440716938307

Epoch: 5| Step: 4
Training loss: 2.2124552726745605
Validation loss: 1.952867422052609

Epoch: 5| Step: 5
Training loss: 2.0410192012786865
Validation loss: 1.9537327686945598

Epoch: 5| Step: 6
Training loss: 2.4808197021484375
Validation loss: 1.9442779710215907

Epoch: 5| Step: 7
Training loss: 2.147536277770996
Validation loss: 1.9507310851927726

Epoch: 5| Step: 8
Training loss: 2.0794601440429688
Validation loss: 1.9434540169213408

Epoch: 5| Step: 9
Training loss: 1.5018680095672607
Validation loss: 1.9500794038977673

Epoch: 5| Step: 10
Training loss: 2.2567880153656006
Validation loss: 1.950415002402439

Epoch: 173| Step: 0
Training loss: 2.7263965606689453
Validation loss: 1.9587654247078845

Epoch: 5| Step: 1
Training loss: 2.1178932189941406
Validation loss: 1.9536794026692708

Epoch: 5| Step: 2
Training loss: 1.6163043975830078
Validation loss: 1.958381373395202

Epoch: 5| Step: 3
Training loss: 1.7807594537734985
Validation loss: 1.9539490335731096

Epoch: 5| Step: 4
Training loss: 1.6766258478164673
Validation loss: 1.9823012377626152

Epoch: 5| Step: 5
Training loss: 1.6251227855682373
Validation loss: 1.9955865721548758

Epoch: 5| Step: 6
Training loss: 2.0571303367614746
Validation loss: 1.987193863878968

Epoch: 5| Step: 7
Training loss: 2.06769061088562
Validation loss: 1.9792918146297496

Epoch: 5| Step: 8
Training loss: 2.9050872325897217
Validation loss: 1.9771646427851852

Epoch: 5| Step: 9
Training loss: 2.730851650238037
Validation loss: 1.9737217041753954

Epoch: 5| Step: 10
Training loss: 2.3406412601470947
Validation loss: 1.9665213669500043

Epoch: 174| Step: 0
Training loss: 2.215522289276123
Validation loss: 1.9647886791536886

Epoch: 5| Step: 1
Training loss: 1.9152675867080688
Validation loss: 1.969566136278132

Epoch: 5| Step: 2
Training loss: 3.1943137645721436
Validation loss: 1.9756708401505665

Epoch: 5| Step: 3
Training loss: 1.9281078577041626
Validation loss: 1.9706865882360807

Epoch: 5| Step: 4
Training loss: 1.9146400690078735
Validation loss: 1.971002459526062

Epoch: 5| Step: 5
Training loss: 1.9363911151885986
Validation loss: 1.9722028175989788

Epoch: 5| Step: 6
Training loss: 2.320542573928833
Validation loss: 1.9770543344559208

Epoch: 5| Step: 7
Training loss: 2.0518336296081543
Validation loss: 1.9883099012477423

Epoch: 5| Step: 8
Training loss: 2.3113441467285156
Validation loss: 1.99509064356486

Epoch: 5| Step: 9
Training loss: 2.053842067718506
Validation loss: 2.0063867081878004

Epoch: 5| Step: 10
Training loss: 1.408695936203003
Validation loss: 2.042583816794939

Epoch: 175| Step: 0
Training loss: 2.4244461059570312
Validation loss: 2.0312415630586687

Epoch: 5| Step: 1
Training loss: 2.5127997398376465
Validation loss: 2.0362861925555813

Epoch: 5| Step: 2
Training loss: 2.1990017890930176
Validation loss: 2.0510409596145793

Epoch: 5| Step: 3
Training loss: 2.484360456466675
Validation loss: 2.059905775131718

Epoch: 5| Step: 4
Training loss: 1.7865873575210571
Validation loss: 2.0624815494783464

Epoch: 5| Step: 5
Training loss: 1.5970230102539062
Validation loss: 2.0499491255770446

Epoch: 5| Step: 6
Training loss: 2.3849191665649414
Validation loss: 2.0321994032911075

Epoch: 5| Step: 7
Training loss: 1.8188791275024414
Validation loss: 2.0177732975252214

Epoch: 5| Step: 8
Training loss: 1.9545751810073853
Validation loss: 1.9960857565684984

Epoch: 5| Step: 9
Training loss: 2.067901611328125
Validation loss: 1.9635618002183977

Epoch: 5| Step: 10
Training loss: 2.2868332862854004
Validation loss: 1.955190215059506

Epoch: 176| Step: 0
Training loss: 2.630628824234009
Validation loss: 1.9582276421208535

Epoch: 5| Step: 1
Training loss: 1.6216404438018799
Validation loss: 1.9775360668859174

Epoch: 5| Step: 2
Training loss: 2.468008041381836
Validation loss: 1.989864549329204

Epoch: 5| Step: 3
Training loss: 2.4615700244903564
Validation loss: 1.9747208523493942

Epoch: 5| Step: 4
Training loss: 1.5057337284088135
Validation loss: 1.9468524520115187

Epoch: 5| Step: 5
Training loss: 2.2890918254852295
Validation loss: 1.9485263196370934

Epoch: 5| Step: 6
Training loss: 2.4182686805725098
Validation loss: 1.9538287385817497

Epoch: 5| Step: 7
Training loss: 1.8671544790267944
Validation loss: 1.954224342940956

Epoch: 5| Step: 8
Training loss: 2.3759827613830566
Validation loss: 1.963761406560098

Epoch: 5| Step: 9
Training loss: 1.5101724863052368
Validation loss: 1.9782081675785843

Epoch: 5| Step: 10
Training loss: 2.2042269706726074
Validation loss: 2.0035589125848587

Epoch: 177| Step: 0
Training loss: 1.935167670249939
Validation loss: 2.0123452204529957

Epoch: 5| Step: 1
Training loss: 2.6337225437164307
Validation loss: 2.0538579712631884

Epoch: 5| Step: 2
Training loss: 1.6078860759735107
Validation loss: 2.0609754657232635

Epoch: 5| Step: 3
Training loss: 1.9838073253631592
Validation loss: 2.061141126899309

Epoch: 5| Step: 4
Training loss: 2.8454489707946777
Validation loss: 2.0678932718051377

Epoch: 5| Step: 5
Training loss: 1.9411108493804932
Validation loss: 2.0674476187716246

Epoch: 5| Step: 6
Training loss: 2.1180264949798584
Validation loss: 2.0701768821285618

Epoch: 5| Step: 7
Training loss: 2.1664493083953857
Validation loss: 2.0443963466152066

Epoch: 5| Step: 8
Training loss: 2.071908473968506
Validation loss: 2.042274054660592

Epoch: 5| Step: 9
Training loss: 1.645257592201233
Validation loss: 2.0356522298628286

Epoch: 5| Step: 10
Training loss: 2.1321351528167725
Validation loss: 1.998638274849102

Epoch: 178| Step: 0
Training loss: 2.46610689163208
Validation loss: 1.9912821528732136

Epoch: 5| Step: 1
Training loss: 1.4189014434814453
Validation loss: 1.9754764982449111

Epoch: 5| Step: 2
Training loss: 1.9583327770233154
Validation loss: 1.9788481625177528

Epoch: 5| Step: 3
Training loss: 2.2619853019714355
Validation loss: 1.9736875436639274

Epoch: 5| Step: 4
Training loss: 1.6066274642944336
Validation loss: 1.9588051329376877

Epoch: 5| Step: 5
Training loss: 2.450192451477051
Validation loss: 1.9562529287030619

Epoch: 5| Step: 6
Training loss: 1.921791434288025
Validation loss: 1.9570973047646143

Epoch: 5| Step: 7
Training loss: 2.340799331665039
Validation loss: 1.9540882854051487

Epoch: 5| Step: 8
Training loss: 2.706850051879883
Validation loss: 1.9700959087699972

Epoch: 5| Step: 9
Training loss: 2.069624423980713
Validation loss: 2.0005648084866103

Epoch: 5| Step: 10
Training loss: 1.8195292949676514
Validation loss: 2.004662334278066

Epoch: 179| Step: 0
Training loss: 2.3091084957122803
Validation loss: 2.0180346465879873

Epoch: 5| Step: 1
Training loss: 2.4021337032318115
Validation loss: 2.020365374062651

Epoch: 5| Step: 2
Training loss: 1.7980321645736694
Validation loss: 2.012938466123355

Epoch: 5| Step: 3
Training loss: 2.0860157012939453
Validation loss: 2.000519039810345

Epoch: 5| Step: 4
Training loss: 1.978088140487671
Validation loss: 1.9940305730347991

Epoch: 5| Step: 5
Training loss: 2.2414183616638184
Validation loss: 1.9932526439748786

Epoch: 5| Step: 6
Training loss: 1.869144082069397
Validation loss: 2.009956016335436

Epoch: 5| Step: 7
Training loss: 2.0879881381988525
Validation loss: 2.01043447115088

Epoch: 5| Step: 8
Training loss: 2.550672769546509
Validation loss: 1.999294597615478

Epoch: 5| Step: 9
Training loss: 2.0320887565612793
Validation loss: 2.001237623153194

Epoch: 5| Step: 10
Training loss: 1.6752914190292358
Validation loss: 1.9791219644649054

Epoch: 180| Step: 0
Training loss: 2.2016048431396484
Validation loss: 1.975650700189734

Epoch: 5| Step: 1
Training loss: 1.6770918369293213
Validation loss: 1.9674457068084388

Epoch: 5| Step: 2
Training loss: 1.7265043258666992
Validation loss: 1.9627179817486835

Epoch: 5| Step: 3
Training loss: 1.923092246055603
Validation loss: 1.9601352112267607

Epoch: 5| Step: 4
Training loss: 2.898235321044922
Validation loss: 1.976570830550245

Epoch: 5| Step: 5
Training loss: 1.9140570163726807
Validation loss: 1.988454044506114

Epoch: 5| Step: 6
Training loss: 2.226050853729248
Validation loss: 1.9758325930564635

Epoch: 5| Step: 7
Training loss: 2.447679042816162
Validation loss: 1.990985772942984

Epoch: 5| Step: 8
Training loss: 1.974041223526001
Validation loss: 1.9723858128311813

Epoch: 5| Step: 9
Training loss: 1.6030009984970093
Validation loss: 1.9769381630805232

Epoch: 5| Step: 10
Training loss: 2.4276156425476074
Validation loss: 1.9636481974714546

Epoch: 181| Step: 0
Training loss: 1.105946660041809
Validation loss: 1.9522243597174203

Epoch: 5| Step: 1
Training loss: 2.25801157951355
Validation loss: 1.9468261913586689

Epoch: 5| Step: 2
Training loss: 2.2044150829315186
Validation loss: 1.9437257397559382

Epoch: 5| Step: 3
Training loss: 2.038541316986084
Validation loss: 1.9567431711381482

Epoch: 5| Step: 4
Training loss: 2.066079616546631
Validation loss: 1.9637304275266585

Epoch: 5| Step: 5
Training loss: 2.083794355392456
Validation loss: 1.970152570355323

Epoch: 5| Step: 6
Training loss: 2.441166639328003
Validation loss: 1.9714068699908514

Epoch: 5| Step: 7
Training loss: 2.231398344039917
Validation loss: 1.9805639482313586

Epoch: 5| Step: 8
Training loss: 2.310512065887451
Validation loss: 1.971324300253263

Epoch: 5| Step: 9
Training loss: 2.3485302925109863
Validation loss: 1.9665007104155838

Epoch: 5| Step: 10
Training loss: 1.7172290086746216
Validation loss: 1.9622348713618454

Epoch: 182| Step: 0
Training loss: 2.290407657623291
Validation loss: 1.971808348932574

Epoch: 5| Step: 1
Training loss: 2.1478676795959473
Validation loss: 1.9889112493043304

Epoch: 5| Step: 2
Training loss: 1.5078028440475464
Validation loss: 2.011048288755519

Epoch: 5| Step: 3
Training loss: 2.357891082763672
Validation loss: 2.0187178952719576

Epoch: 5| Step: 4
Training loss: 2.4276766777038574
Validation loss: 2.009156124566191

Epoch: 5| Step: 5
Training loss: 1.431505560874939
Validation loss: 2.0123015231983636

Epoch: 5| Step: 6
Training loss: 2.173466444015503
Validation loss: 2.0068249945999472

Epoch: 5| Step: 7
Training loss: 1.5915454626083374
Validation loss: 2.0131019956322125

Epoch: 5| Step: 8
Training loss: 2.443098783493042
Validation loss: 2.008984383716378

Epoch: 5| Step: 9
Training loss: 2.7112109661102295
Validation loss: 2.0128099841456257

Epoch: 5| Step: 10
Training loss: 1.799126148223877
Validation loss: 1.997508236156997

Epoch: 183| Step: 0
Training loss: 1.891530990600586
Validation loss: 1.9925574410346247

Epoch: 5| Step: 1
Training loss: 1.9344028234481812
Validation loss: 2.01740090821379

Epoch: 5| Step: 2
Training loss: 1.6726305484771729
Validation loss: 2.0495772848847094

Epoch: 5| Step: 3
Training loss: 2.3160746097564697
Validation loss: 2.0611710574037287

Epoch: 5| Step: 4
Training loss: 2.165238380432129
Validation loss: 2.0161693019251667

Epoch: 5| Step: 5
Training loss: 1.739453673362732
Validation loss: 1.9939980147987284

Epoch: 5| Step: 6
Training loss: 1.96877920627594
Validation loss: 2.0154059253713137

Epoch: 5| Step: 7
Training loss: 2.4747822284698486
Validation loss: 2.0090383175880677

Epoch: 5| Step: 8
Training loss: 2.60872220993042
Validation loss: 1.9871725728434901

Epoch: 5| Step: 9
Training loss: 1.86533522605896
Validation loss: 1.9833061605371454

Epoch: 5| Step: 10
Training loss: 1.928587555885315
Validation loss: 1.9774212145036267

Epoch: 184| Step: 0
Training loss: 2.0387377738952637
Validation loss: 1.9755004426484466

Epoch: 5| Step: 1
Training loss: 2.0956523418426514
Validation loss: 1.9887218193341327

Epoch: 5| Step: 2
Training loss: 2.6524975299835205
Validation loss: 1.9926476094030565

Epoch: 5| Step: 3
Training loss: 1.6754770278930664
Validation loss: 2.0000414284326697

Epoch: 5| Step: 4
Training loss: 1.7908287048339844
Validation loss: 2.0255215680727394

Epoch: 5| Step: 5
Training loss: 2.1090259552001953
Validation loss: 2.028453291103404

Epoch: 5| Step: 6
Training loss: 1.753894567489624
Validation loss: 2.04405015642925

Epoch: 5| Step: 7
Training loss: 1.862607717514038
Validation loss: 2.0663671775530745

Epoch: 5| Step: 8
Training loss: 2.4326701164245605
Validation loss: 2.0582112355898787

Epoch: 5| Step: 9
Training loss: 1.859777808189392
Validation loss: 2.0341878821772914

Epoch: 5| Step: 10
Training loss: 2.169416904449463
Validation loss: 2.036271495203818

Epoch: 185| Step: 0
Training loss: 1.4709190130233765
Validation loss: 2.003807452417189

Epoch: 5| Step: 1
Training loss: 2.428598165512085
Validation loss: 1.979645457319034

Epoch: 5| Step: 2
Training loss: 2.3616061210632324
Validation loss: 1.9972363325857347

Epoch: 5| Step: 3
Training loss: 2.525066614151001
Validation loss: 2.0084014656723186

Epoch: 5| Step: 4
Training loss: 2.337404727935791
Validation loss: 2.0153620935255483

Epoch: 5| Step: 5
Training loss: 2.3767852783203125
Validation loss: 2.015794925792243

Epoch: 5| Step: 6
Training loss: 1.4916573762893677
Validation loss: 1.995041367828205

Epoch: 5| Step: 7
Training loss: 1.5496889352798462
Validation loss: 1.9695002366137762

Epoch: 5| Step: 8
Training loss: 2.5066819190979004
Validation loss: 1.9858664902307654

Epoch: 5| Step: 9
Training loss: 2.277315616607666
Validation loss: 2.010093160854873

Epoch: 5| Step: 10
Training loss: 1.3288034200668335
Validation loss: 2.0576497995725243

Epoch: 186| Step: 0
Training loss: 2.2507920265197754
Validation loss: 2.0797452811271913

Epoch: 5| Step: 1
Training loss: 2.0191829204559326
Validation loss: 2.1194843323000017

Epoch: 5| Step: 2
Training loss: 2.1212761402130127
Validation loss: 2.077400976611722

Epoch: 5| Step: 3
Training loss: 1.8952709436416626
Validation loss: 2.0328092305890975

Epoch: 5| Step: 4
Training loss: 1.5949398279190063
Validation loss: 2.0069627890022854

Epoch: 5| Step: 5
Training loss: 2.817436695098877
Validation loss: 2.0320622382625455

Epoch: 5| Step: 6
Training loss: 2.249546766281128
Validation loss: 2.063382148742676

Epoch: 5| Step: 7
Training loss: 1.805237054824829
Validation loss: 2.1003984533330446

Epoch: 5| Step: 8
Training loss: 2.303903341293335
Validation loss: 2.142792914503364

Epoch: 5| Step: 9
Training loss: 2.308893918991089
Validation loss: 2.063862746761691

Epoch: 5| Step: 10
Training loss: 1.8151583671569824
Validation loss: 2.0051999399738927

Epoch: 187| Step: 0
Training loss: 1.5536096096038818
Validation loss: 2.0023040156210623

Epoch: 5| Step: 1
Training loss: 2.2159228324890137
Validation loss: 2.024997716308922

Epoch: 5| Step: 2
Training loss: 2.2471041679382324
Validation loss: 2.0613245861504668

Epoch: 5| Step: 3
Training loss: 1.6041187047958374
Validation loss: 2.0571793099885345

Epoch: 5| Step: 4
Training loss: 1.9445688724517822
Validation loss: 2.0377252512080695

Epoch: 5| Step: 5
Training loss: 2.1477644443511963
Validation loss: 2.017064058652488

Epoch: 5| Step: 6
Training loss: 2.2722041606903076
Validation loss: 2.0052176111487934

Epoch: 5| Step: 7
Training loss: 2.605236291885376
Validation loss: 2.0280140292259956

Epoch: 5| Step: 8
Training loss: 1.4527626037597656
Validation loss: 2.0389181952322684

Epoch: 5| Step: 9
Training loss: 2.1358304023742676
Validation loss: 2.061157741854268

Epoch: 5| Step: 10
Training loss: 2.5416791439056396
Validation loss: 2.0361113561097013

Epoch: 188| Step: 0
Training loss: 2.0880212783813477
Validation loss: 2.048789793445218

Epoch: 5| Step: 1
Training loss: 1.7677249908447266
Validation loss: 2.0191422611154537

Epoch: 5| Step: 2
Training loss: 1.7281129360198975
Validation loss: 2.012242362063418

Epoch: 5| Step: 3
Training loss: 1.776995062828064
Validation loss: 2.0162217899035384

Epoch: 5| Step: 4
Training loss: 2.328986406326294
Validation loss: 2.014277127481276

Epoch: 5| Step: 5
Training loss: 1.6579701900482178
Validation loss: 2.0239568448835805

Epoch: 5| Step: 6
Training loss: 2.184360980987549
Validation loss: 2.017343164772116

Epoch: 5| Step: 7
Training loss: 1.5722296237945557
Validation loss: 2.009929815928141

Epoch: 5| Step: 8
Training loss: 2.3303284645080566
Validation loss: 2.0201236253143637

Epoch: 5| Step: 9
Training loss: 2.51814341545105
Validation loss: 2.030782876476165

Epoch: 5| Step: 10
Training loss: 2.1814639568328857
Validation loss: 2.035066414904851

Epoch: 189| Step: 0
Training loss: 1.6974477767944336
Validation loss: 2.0511567169620144

Epoch: 5| Step: 1
Training loss: 2.1787877082824707
Validation loss: 2.0362797629448677

Epoch: 5| Step: 2
Training loss: 2.139028787612915
Validation loss: 2.0406384698806272

Epoch: 5| Step: 3
Training loss: 2.4596147537231445
Validation loss: 2.0377182601600565

Epoch: 5| Step: 4
Training loss: 2.2900280952453613
Validation loss: 2.046168755459529

Epoch: 5| Step: 5
Training loss: 1.0821106433868408
Validation loss: 2.0503982882345877

Epoch: 5| Step: 6
Training loss: 2.340567111968994
Validation loss: 2.0431254358701807

Epoch: 5| Step: 7
Training loss: 1.5605462789535522
Validation loss: 2.057970105960805

Epoch: 5| Step: 8
Training loss: 2.331232786178589
Validation loss: 2.040303921186796

Epoch: 5| Step: 9
Training loss: 1.5794506072998047
Validation loss: 2.04010969977225

Epoch: 5| Step: 10
Training loss: 2.2355544567108154
Validation loss: 2.062050783506004

Epoch: 190| Step: 0
Training loss: 1.837384819984436
Validation loss: 2.0703141432936474

Epoch: 5| Step: 1
Training loss: 2.1566131114959717
Validation loss: 2.071134485224242

Epoch: 5| Step: 2
Training loss: 1.351255178451538
Validation loss: 2.0780700227265716

Epoch: 5| Step: 3
Training loss: 2.0284218788146973
Validation loss: 2.0895699172891598

Epoch: 5| Step: 4
Training loss: 1.4909701347351074
Validation loss: 2.0562773327673636

Epoch: 5| Step: 5
Training loss: 2.8393020629882812
Validation loss: 2.025797677296464

Epoch: 5| Step: 6
Training loss: 1.7830148935317993
Validation loss: 2.0152469424791235

Epoch: 5| Step: 7
Training loss: 2.325735092163086
Validation loss: 2.014638340601357

Epoch: 5| Step: 8
Training loss: 2.4722683429718018
Validation loss: 2.008674761300446

Epoch: 5| Step: 9
Training loss: 1.6369924545288086
Validation loss: 2.0086105023660967

Epoch: 5| Step: 10
Training loss: 1.8608189821243286
Validation loss: 1.9945454392381894

Epoch: 191| Step: 0
Training loss: 2.0336380004882812
Validation loss: 2.004973625624052

Epoch: 5| Step: 1
Training loss: 1.9901031255722046
Validation loss: 2.010324614022368

Epoch: 5| Step: 2
Training loss: 1.928696870803833
Validation loss: 2.013209806975498

Epoch: 5| Step: 3
Training loss: 2.3173131942749023
Validation loss: 2.0526883012504986

Epoch: 5| Step: 4
Training loss: 1.8304193019866943
Validation loss: 2.0740971616519395

Epoch: 5| Step: 5
Training loss: 1.92240309715271
Validation loss: 2.0783912366436375

Epoch: 5| Step: 6
Training loss: 2.62602162361145
Validation loss: 2.0521589632957213

Epoch: 5| Step: 7
Training loss: 1.7564823627471924
Validation loss: 2.055727949706457

Epoch: 5| Step: 8
Training loss: 1.8729760646820068
Validation loss: 2.0585989349631855

Epoch: 5| Step: 9
Training loss: 2.0324325561523438
Validation loss: 2.0729108971934163

Epoch: 5| Step: 10
Training loss: 1.5720458030700684
Validation loss: 2.1056785391223047

Epoch: 192| Step: 0
Training loss: 2.682453155517578
Validation loss: 2.098035268886115

Epoch: 5| Step: 1
Training loss: 2.45991587638855
Validation loss: 2.0878234883790374

Epoch: 5| Step: 2
Training loss: 1.7818467617034912
Validation loss: 2.0484990458334646

Epoch: 5| Step: 3
Training loss: 1.5805221796035767
Validation loss: 2.039557668470567

Epoch: 5| Step: 4
Training loss: 2.140411615371704
Validation loss: 2.05102789273826

Epoch: 5| Step: 5
Training loss: 1.423136830329895
Validation loss: 2.0602673330614643

Epoch: 5| Step: 6
Training loss: 2.3479485511779785
Validation loss: 2.041421144239364

Epoch: 5| Step: 7
Training loss: 2.060991048812866
Validation loss: 2.028902494779197

Epoch: 5| Step: 8
Training loss: 1.756434679031372
Validation loss: 2.0205337539795907

Epoch: 5| Step: 9
Training loss: 1.6324207782745361
Validation loss: 2.007947374415654

Epoch: 5| Step: 10
Training loss: 1.9446502923965454
Validation loss: 2.007652259642078

Epoch: 193| Step: 0
Training loss: 1.8809731006622314
Validation loss: 2.018142400249358

Epoch: 5| Step: 1
Training loss: 2.1048977375030518
Validation loss: 2.0528245087592834

Epoch: 5| Step: 2
Training loss: 2.102053165435791
Validation loss: 2.080841854054441

Epoch: 5| Step: 3
Training loss: 1.7195568084716797
Validation loss: 2.1339360129448677

Epoch: 5| Step: 4
Training loss: 1.8563562631607056
Validation loss: 2.174947343846803

Epoch: 5| Step: 5
Training loss: 1.741798996925354
Validation loss: 2.21076786774461

Epoch: 5| Step: 6
Training loss: 2.348034381866455
Validation loss: 2.1856220665798394

Epoch: 5| Step: 7
Training loss: 2.153278350830078
Validation loss: 2.1242386359040455

Epoch: 5| Step: 8
Training loss: 2.4903793334960938
Validation loss: 2.0802646119107484

Epoch: 5| Step: 9
Training loss: 2.3140292167663574
Validation loss: 2.047369441678447

Epoch: 5| Step: 10
Training loss: 1.3447054624557495
Validation loss: 2.036431489452239

Epoch: 194| Step: 0
Training loss: 2.5259032249450684
Validation loss: 2.0061843010687057

Epoch: 5| Step: 1
Training loss: 2.152592182159424
Validation loss: 1.9876999201313141

Epoch: 5| Step: 2
Training loss: 2.136171817779541
Validation loss: 1.9889966108465706

Epoch: 5| Step: 3
Training loss: 1.8613847494125366
Validation loss: 2.0028228708492812

Epoch: 5| Step: 4
Training loss: 1.8654171228408813
Validation loss: 2.0177397420329433

Epoch: 5| Step: 5
Training loss: 2.003933906555176
Validation loss: 2.0237889200128536

Epoch: 5| Step: 6
Training loss: 1.8285694122314453
Validation loss: 2.029293521758049

Epoch: 5| Step: 7
Training loss: 1.9428644180297852
Validation loss: 2.0508628493996075

Epoch: 5| Step: 8
Training loss: 2.1068644523620605
Validation loss: 2.0222876648749075

Epoch: 5| Step: 9
Training loss: 1.4399373531341553
Validation loss: 2.070440003948827

Epoch: 5| Step: 10
Training loss: 1.7240208387374878
Validation loss: 2.082428498934674

Epoch: 195| Step: 0
Training loss: 1.6285831928253174
Validation loss: 2.0871688883791686

Epoch: 5| Step: 1
Training loss: 1.6019108295440674
Validation loss: 2.103790144766531

Epoch: 5| Step: 2
Training loss: 1.744062066078186
Validation loss: 2.1132488186641405

Epoch: 5| Step: 3
Training loss: 1.7365814447402954
Validation loss: 2.1277625791488157

Epoch: 5| Step: 4
Training loss: 2.3679349422454834
Validation loss: 2.138815628584995

Epoch: 5| Step: 5
Training loss: 2.472458600997925
Validation loss: 2.0705539129113637

Epoch: 5| Step: 6
Training loss: 1.8893871307373047
Validation loss: 2.054077490683525

Epoch: 5| Step: 7
Training loss: 1.4656957387924194
Validation loss: 2.041704366284032

Epoch: 5| Step: 8
Training loss: 2.860076665878296
Validation loss: 2.0623325814482985

Epoch: 5| Step: 9
Training loss: 1.9157527685165405
Validation loss: 2.0773359088487524

Epoch: 5| Step: 10
Training loss: 1.8165440559387207
Validation loss: 2.0770139053303707

Epoch: 196| Step: 0
Training loss: 1.9932136535644531
Validation loss: 2.0342933362530125

Epoch: 5| Step: 1
Training loss: 1.7181885242462158
Validation loss: 2.0143534291175103

Epoch: 5| Step: 2
Training loss: 1.2082756757736206
Validation loss: 1.9820010239078152

Epoch: 5| Step: 3
Training loss: 2.1122004985809326
Validation loss: 1.984474338510985

Epoch: 5| Step: 4
Training loss: 1.3653829097747803
Validation loss: 1.9871055977318877

Epoch: 5| Step: 5
Training loss: 2.153231620788574
Validation loss: 1.997680002643216

Epoch: 5| Step: 6
Training loss: 2.4041028022766113
Validation loss: 2.031559803152597

Epoch: 5| Step: 7
Training loss: 2.7628703117370605
Validation loss: 2.0655491223899265

Epoch: 5| Step: 8
Training loss: 1.7003921270370483
Validation loss: 2.05966604012315

Epoch: 5| Step: 9
Training loss: 1.7647548913955688
Validation loss: 2.0633246385922996

Epoch: 5| Step: 10
Training loss: 2.3711273670196533
Validation loss: 2.042500429255988

Epoch: 197| Step: 0
Training loss: 2.309133529663086
Validation loss: 2.0409349164655133

Epoch: 5| Step: 1
Training loss: 2.0231857299804688
Validation loss: 2.0845919783397386

Epoch: 5| Step: 2
Training loss: 2.1202826499938965
Validation loss: 2.0922565408932265

Epoch: 5| Step: 3
Training loss: 1.8224003314971924
Validation loss: 2.09239806923815

Epoch: 5| Step: 4
Training loss: 1.8969701528549194
Validation loss: 2.085798312258977

Epoch: 5| Step: 5
Training loss: 1.906651496887207
Validation loss: 2.0800015746906237

Epoch: 5| Step: 6
Training loss: 1.7470576763153076
Validation loss: 2.077655307708248

Epoch: 5| Step: 7
Training loss: 1.6708018779754639
Validation loss: 2.0950918915451213

Epoch: 5| Step: 8
Training loss: 1.6424000263214111
Validation loss: 2.0716661881375056

Epoch: 5| Step: 9
Training loss: 2.444186210632324
Validation loss: 2.060336584685951

Epoch: 5| Step: 10
Training loss: 1.9034401178359985
Validation loss: 2.0539377376597416

Epoch: 198| Step: 0
Training loss: 2.064913749694824
Validation loss: 2.0599765444314606

Epoch: 5| Step: 1
Training loss: 1.9317970275878906
Validation loss: 2.0909427801767984

Epoch: 5| Step: 2
Training loss: 2.157832384109497
Validation loss: 2.0711842685617428

Epoch: 5| Step: 3
Training loss: 1.7642414569854736
Validation loss: 2.081124310852379

Epoch: 5| Step: 4
Training loss: 1.7545582056045532
Validation loss: 2.105650903076254

Epoch: 5| Step: 5
Training loss: 2.3539345264434814
Validation loss: 2.125671076518233

Epoch: 5| Step: 6
Training loss: 1.7499573230743408
Validation loss: 2.085154661568262

Epoch: 5| Step: 7
Training loss: 1.7874276638031006
Validation loss: 2.0726145698178198

Epoch: 5| Step: 8
Training loss: 1.7854747772216797
Validation loss: 2.058825800495763

Epoch: 5| Step: 9
Training loss: 2.3038196563720703
Validation loss: 2.0728045714798795

Epoch: 5| Step: 10
Training loss: 1.6891531944274902
Validation loss: 2.100155499673659

Epoch: 199| Step: 0
Training loss: 2.550931453704834
Validation loss: 2.0842705157495316

Epoch: 5| Step: 1
Training loss: 2.2272698879241943
Validation loss: 2.055491775594732

Epoch: 5| Step: 2
Training loss: 2.1465110778808594
Validation loss: 2.026730598941926

Epoch: 5| Step: 3
Training loss: 2.037445068359375
Validation loss: 2.003637126697007

Epoch: 5| Step: 4
Training loss: 1.2796845436096191
Validation loss: 1.9934011095313615

Epoch: 5| Step: 5
Training loss: 1.9290435314178467
Validation loss: 2.016103612479343

Epoch: 5| Step: 6
Training loss: 2.64694881439209
Validation loss: 2.043339930554872

Epoch: 5| Step: 7
Training loss: 1.6721436977386475
Validation loss: 2.0679838836833997

Epoch: 5| Step: 8
Training loss: 1.6170984506607056
Validation loss: 2.05972764056216

Epoch: 5| Step: 9
Training loss: 1.154569387435913
Validation loss: 2.0541543768298243

Epoch: 5| Step: 10
Training loss: 1.6609388589859009
Validation loss: 2.0423365357101604

Epoch: 200| Step: 0
Training loss: 2.093230724334717
Validation loss: 2.0260027531654603

Epoch: 5| Step: 1
Training loss: 2.1805107593536377
Validation loss: 2.0175759535963818

Epoch: 5| Step: 2
Training loss: 2.2993030548095703
Validation loss: 2.0167854088608936

Epoch: 5| Step: 3
Training loss: 1.951233148574829
Validation loss: 2.0029609703248545

Epoch: 5| Step: 4
Training loss: 2.2713000774383545
Validation loss: 1.995209978472802

Epoch: 5| Step: 5
Training loss: 1.3173086643218994
Validation loss: 1.9840767883485364

Epoch: 5| Step: 6
Training loss: 1.878411054611206
Validation loss: 1.995671135123058

Epoch: 5| Step: 7
Training loss: 2.021488904953003
Validation loss: 2.0066315589412564

Epoch: 5| Step: 8
Training loss: 1.5481748580932617
Validation loss: 2.005443655034547

Epoch: 5| Step: 9
Training loss: 1.2046153545379639
Validation loss: 2.028524852568103

Epoch: 5| Step: 10
Training loss: 1.9564752578735352
Validation loss: 2.0489273532744376

Epoch: 201| Step: 0
Training loss: 2.031386613845825
Validation loss: 2.048788765425323

Epoch: 5| Step: 1
Training loss: 1.9141552448272705
Validation loss: 2.058809857214651

Epoch: 5| Step: 2
Training loss: 1.65675950050354
Validation loss: 2.068278953593264

Epoch: 5| Step: 3
Training loss: 2.195462465286255
Validation loss: 2.0700377161784838

Epoch: 5| Step: 4
Training loss: 2.0665507316589355
Validation loss: 2.0816185564123173

Epoch: 5| Step: 5
Training loss: 1.6955686807632446
Validation loss: 2.0427000291885866

Epoch: 5| Step: 6
Training loss: 2.369284152984619
Validation loss: 2.0219206707451933

Epoch: 5| Step: 7
Training loss: 1.553990125656128
Validation loss: 2.018502417431083

Epoch: 5| Step: 8
Training loss: 1.397702693939209
Validation loss: 2.0505960615732337

Epoch: 5| Step: 9
Training loss: 1.8477013111114502
Validation loss: 2.0313437446471183

Epoch: 5| Step: 10
Training loss: 1.9216548204421997
Validation loss: 2.0421382175978793

Epoch: 202| Step: 0
Training loss: 1.7060457468032837
Validation loss: 2.0506562340644097

Epoch: 5| Step: 1
Training loss: 1.250185251235962
Validation loss: 2.0650888284047446

Epoch: 5| Step: 2
Training loss: 2.1565213203430176
Validation loss: 2.0699520469993673

Epoch: 5| Step: 3
Training loss: 2.0299220085144043
Validation loss: 2.1115888831435994

Epoch: 5| Step: 4
Training loss: 2.0695042610168457
Validation loss: 2.10283261986189

Epoch: 5| Step: 5
Training loss: 2.3528106212615967
Validation loss: 2.0734448689286427

Epoch: 5| Step: 6
Training loss: 1.49945867061615
Validation loss: 2.0511071605067097

Epoch: 5| Step: 7
Training loss: 1.6553943157196045
Validation loss: 2.0456647872924805

Epoch: 5| Step: 8
Training loss: 2.1417930126190186
Validation loss: 2.0233342596279678

Epoch: 5| Step: 9
Training loss: 1.6782796382904053
Validation loss: 2.008219757387715

Epoch: 5| Step: 10
Training loss: 1.9165700674057007
Validation loss: 2.0123420915296

Epoch: 203| Step: 0
Training loss: 2.0043182373046875
Validation loss: 2.049071801606045

Epoch: 5| Step: 1
Training loss: 1.4319795370101929
Validation loss: 2.0425638229616228

Epoch: 5| Step: 2
Training loss: 2.0256283283233643
Validation loss: 2.0428479435623332

Epoch: 5| Step: 3
Training loss: 2.062967300415039
Validation loss: 2.041088460594095

Epoch: 5| Step: 4
Training loss: 1.431488275527954
Validation loss: 2.0365749456549205

Epoch: 5| Step: 5
Training loss: 1.3760035037994385
Validation loss: 2.052873403795304

Epoch: 5| Step: 6
Training loss: 2.3754985332489014
Validation loss: 2.1124281191056773

Epoch: 5| Step: 7
Training loss: 1.7132259607315063
Validation loss: 2.10189175862138

Epoch: 5| Step: 8
Training loss: 2.389392375946045
Validation loss: 2.096166503044867

Epoch: 5| Step: 9
Training loss: 1.62503182888031
Validation loss: 2.103013032226152

Epoch: 5| Step: 10
Training loss: 1.9961766004562378
Validation loss: 2.0913534984793714

Epoch: 204| Step: 0
Training loss: 2.340153217315674
Validation loss: 2.112834466400967

Epoch: 5| Step: 1
Training loss: 1.5813779830932617
Validation loss: 2.1199544193924114

Epoch: 5| Step: 2
Training loss: 1.8306620121002197
Validation loss: 2.0945874734591414

Epoch: 5| Step: 3
Training loss: 1.5826431512832642
Validation loss: 2.0615556957901164

Epoch: 5| Step: 4
Training loss: 1.7154089212417603
Validation loss: 2.042902822135597

Epoch: 5| Step: 5
Training loss: 2.2971203327178955
Validation loss: 2.0138901497728083

Epoch: 5| Step: 6
Training loss: 1.8907015323638916
Validation loss: 2.0231610985212427

Epoch: 5| Step: 7
Training loss: 2.1509578227996826
Validation loss: 2.036931498076326

Epoch: 5| Step: 8
Training loss: 1.770644187927246
Validation loss: 2.0826961878807313

Epoch: 5| Step: 9
Training loss: 1.2731235027313232
Validation loss: 2.045715339722172

Epoch: 5| Step: 10
Training loss: 2.0118048191070557
Validation loss: 2.0493496361599175

Epoch: 205| Step: 0
Training loss: 1.4501903057098389
Validation loss: 2.0618358030114123

Epoch: 5| Step: 1
Training loss: 2.2834959030151367
Validation loss: 2.0938332362841536

Epoch: 5| Step: 2
Training loss: 1.601435899734497
Validation loss: 2.082227712036461

Epoch: 5| Step: 3
Training loss: 1.488464593887329
Validation loss: 2.0730346428450717

Epoch: 5| Step: 4
Training loss: 2.3269970417022705
Validation loss: 2.052173711920297

Epoch: 5| Step: 5
Training loss: 1.6915874481201172
Validation loss: 2.0512377215969946

Epoch: 5| Step: 6
Training loss: 1.9629615545272827
Validation loss: 2.0298764090384207

Epoch: 5| Step: 7
Training loss: 1.6177127361297607
Validation loss: 2.0288332111092022

Epoch: 5| Step: 8
Training loss: 1.6989965438842773
Validation loss: 2.0376833664473666

Epoch: 5| Step: 9
Training loss: 2.2306129932403564
Validation loss: 2.0495711013834965

Epoch: 5| Step: 10
Training loss: 1.73616623878479
Validation loss: 2.0508241294532694

Epoch: 206| Step: 0
Training loss: 1.6778085231781006
Validation loss: 2.058005366274106

Epoch: 5| Step: 1
Training loss: 1.209420919418335
Validation loss: 2.0393050691132903

Epoch: 5| Step: 2
Training loss: 2.0203702449798584
Validation loss: 2.0355252796603787

Epoch: 5| Step: 3
Training loss: 1.4146888256072998
Validation loss: 2.028280081287507

Epoch: 5| Step: 4
Training loss: 1.70084547996521
Validation loss: 2.018439923563311

Epoch: 5| Step: 5
Training loss: 2.04587721824646
Validation loss: 2.016151855068822

Epoch: 5| Step: 6
Training loss: 2.031485080718994
Validation loss: 1.999028698090584

Epoch: 5| Step: 7
Training loss: 1.609225869178772
Validation loss: 2.0129557681340042

Epoch: 5| Step: 8
Training loss: 2.0557103157043457
Validation loss: 2.0292770657488095

Epoch: 5| Step: 9
Training loss: 1.7610387802124023
Validation loss: 2.0351288959544194

Epoch: 5| Step: 10
Training loss: 2.0612525939941406
Validation loss: 2.0659737176792596

Epoch: 207| Step: 0
Training loss: 1.8531852960586548
Validation loss: 2.07606521473136

Epoch: 5| Step: 1
Training loss: 1.6682510375976562
Validation loss: 2.0945197792463404

Epoch: 5| Step: 2
Training loss: 1.290003776550293
Validation loss: 2.0827635847112185

Epoch: 5| Step: 3
Training loss: 2.1971182823181152
Validation loss: 2.0569825608243226

Epoch: 5| Step: 4
Training loss: 1.2770874500274658
Validation loss: 2.0557606835519113

Epoch: 5| Step: 5
Training loss: 2.095458984375
Validation loss: 2.0331140641243226

Epoch: 5| Step: 6
Training loss: 1.6948144435882568
Validation loss: 2.0175701802776707

Epoch: 5| Step: 7
Training loss: 1.6958796977996826
Validation loss: 2.0080400051609164

Epoch: 5| Step: 8
Training loss: 2.226255416870117
Validation loss: 2.026452168341606

Epoch: 5| Step: 9
Training loss: 1.8465192317962646
Validation loss: 2.0110397056866716

Epoch: 5| Step: 10
Training loss: 1.9178146123886108
Validation loss: 2.0208834486622966

Epoch: 208| Step: 0
Training loss: 2.0058493614196777
Validation loss: 2.0001555796592467

Epoch: 5| Step: 1
Training loss: 1.8530714511871338
Validation loss: 2.0036432255980787

Epoch: 5| Step: 2
Training loss: 1.928619146347046
Validation loss: 1.9961038174167756

Epoch: 5| Step: 3
Training loss: 1.383597731590271
Validation loss: 2.0107352477247997

Epoch: 5| Step: 4
Training loss: 1.880462884902954
Validation loss: 2.0125749213721162

Epoch: 5| Step: 5
Training loss: 1.6424270868301392
Validation loss: 2.0255218026458577

Epoch: 5| Step: 6
Training loss: 2.2470414638519287
Validation loss: 2.0128576845251103

Epoch: 5| Step: 7
Training loss: 1.186113953590393
Validation loss: 2.0300302479856756

Epoch: 5| Step: 8
Training loss: 1.3775458335876465
Validation loss: 2.0406645600513746

Epoch: 5| Step: 9
Training loss: 2.311018705368042
Validation loss: 2.060507761534824

Epoch: 5| Step: 10
Training loss: 1.5367100238800049
Validation loss: 2.081560621979416

Epoch: 209| Step: 0
Training loss: 1.8835737705230713
Validation loss: 2.057868967774094

Epoch: 5| Step: 1
Training loss: 1.8374626636505127
Validation loss: 2.068866059344302

Epoch: 5| Step: 2
Training loss: 1.194957971572876
Validation loss: 2.0616737104231313

Epoch: 5| Step: 3
Training loss: 1.7234165668487549
Validation loss: 2.0271130031155002

Epoch: 5| Step: 4
Training loss: 2.4198107719421387
Validation loss: 2.0055901914514522

Epoch: 5| Step: 5
Training loss: 1.055652141571045
Validation loss: 1.9928338899407336

Epoch: 5| Step: 6
Training loss: 1.7021299600601196
Validation loss: 1.9948787138026247

Epoch: 5| Step: 7
Training loss: 1.7649269104003906
Validation loss: 1.990239575345029

Epoch: 5| Step: 8
Training loss: 1.6998764276504517
Validation loss: 2.0130239366203226

Epoch: 5| Step: 9
Training loss: 2.126131057739258
Validation loss: 1.9992341713238788

Epoch: 5| Step: 10
Training loss: 1.9133646488189697
Validation loss: 2.0108992002343618

Epoch: 210| Step: 0
Training loss: 1.5241978168487549
Validation loss: 1.9920893228182228

Epoch: 5| Step: 1
Training loss: 1.8628511428833008
Validation loss: 1.9896691230035597

Epoch: 5| Step: 2
Training loss: 2.194319248199463
Validation loss: 2.003070403170842

Epoch: 5| Step: 3
Training loss: 1.5376055240631104
Validation loss: 2.0129704577948457

Epoch: 5| Step: 4
Training loss: 1.177498459815979
Validation loss: 2.029123278074367

Epoch: 5| Step: 5
Training loss: 1.8452656269073486
Validation loss: 2.0325489274917112

Epoch: 5| Step: 6
Training loss: 1.2905133962631226
Validation loss: 2.039961903325973

Epoch: 5| Step: 7
Training loss: 1.5097062587738037
Validation loss: 2.0439536840684953

Epoch: 5| Step: 8
Training loss: 2.0403075218200684
Validation loss: 2.045341480162836

Epoch: 5| Step: 9
Training loss: 2.212639808654785
Validation loss: 2.0469782249901884

Epoch: 5| Step: 10
Training loss: 1.8524705171585083
Validation loss: 2.0532475235641643

Epoch: 211| Step: 0
Training loss: 1.6688836812973022
Validation loss: 2.0549098150704497

Epoch: 5| Step: 1
Training loss: 2.3982930183410645
Validation loss: 2.062931388937017

Epoch: 5| Step: 2
Training loss: 1.8213733434677124
Validation loss: 2.0557375864316056

Epoch: 5| Step: 3
Training loss: 1.3889062404632568
Validation loss: 2.0877581975793325

Epoch: 5| Step: 4
Training loss: 1.6596367359161377
Validation loss: 2.097043985961586

Epoch: 5| Step: 5
Training loss: 1.5523908138275146
Validation loss: 2.08799405764508

Epoch: 5| Step: 6
Training loss: 1.2827775478363037
Validation loss: 2.064435310261224

Epoch: 5| Step: 7
Training loss: 1.5710582733154297
Validation loss: 2.0740308941051526

Epoch: 5| Step: 8
Training loss: 1.8077102899551392
Validation loss: 2.0625983156183714

Epoch: 5| Step: 9
Training loss: 2.1845314502716064
Validation loss: 2.0470108088626655

Epoch: 5| Step: 10
Training loss: 1.7215240001678467
Validation loss: 2.0447845817894064

Epoch: 212| Step: 0
Training loss: 1.6380481719970703
Validation loss: 2.043215774720715

Epoch: 5| Step: 1
Training loss: 1.5639384984970093
Validation loss: 2.032692866940652

Epoch: 5| Step: 2
Training loss: 1.4440568685531616
Validation loss: 2.0233012143001763

Epoch: 5| Step: 3
Training loss: 1.9244054555892944
Validation loss: 2.04858947056596

Epoch: 5| Step: 4
Training loss: 1.3645410537719727
Validation loss: 2.0427617001277145

Epoch: 5| Step: 5
Training loss: 1.848160743713379
Validation loss: 2.0395050356465

Epoch: 5| Step: 6
Training loss: 1.7108352184295654
Validation loss: 2.011554087361982

Epoch: 5| Step: 7
Training loss: 1.9423713684082031
Validation loss: 2.017775725292903

Epoch: 5| Step: 8
Training loss: 2.3832850456237793
Validation loss: 2.01064468455571

Epoch: 5| Step: 9
Training loss: 1.450471043586731
Validation loss: 2.007672796967209

Epoch: 5| Step: 10
Training loss: 1.5861284732818604
Validation loss: 2.0161630927875476

Epoch: 213| Step: 0
Training loss: 1.492725133895874
Validation loss: 2.0269676664824128

Epoch: 5| Step: 1
Training loss: 2.033374071121216
Validation loss: 2.031331739118022

Epoch: 5| Step: 2
Training loss: 1.92754328250885
Validation loss: 2.014469737647682

Epoch: 5| Step: 3
Training loss: 1.4733238220214844
Validation loss: 2.017373249094973

Epoch: 5| Step: 4
Training loss: 1.1825168132781982
Validation loss: 2.0189543180568243

Epoch: 5| Step: 5
Training loss: 1.5983376502990723
Validation loss: 2.0409637689590454

Epoch: 5| Step: 6
Training loss: 1.8851228952407837
Validation loss: 2.040270056775821

Epoch: 5| Step: 7
Training loss: 1.8999427556991577
Validation loss: 2.057515057184363

Epoch: 5| Step: 8
Training loss: 1.8697048425674438
Validation loss: 2.0687775599059237

Epoch: 5| Step: 9
Training loss: 1.6829856634140015
Validation loss: 2.0560332216242307

Epoch: 5| Step: 10
Training loss: 1.578997015953064
Validation loss: 2.069877657839047

Epoch: 214| Step: 0
Training loss: 1.0210201740264893
Validation loss: 2.039177825373988

Epoch: 5| Step: 1
Training loss: 2.081197738647461
Validation loss: 2.053887878694842

Epoch: 5| Step: 2
Training loss: 1.6455177068710327
Validation loss: 2.04128223465335

Epoch: 5| Step: 3
Training loss: 2.494577169418335
Validation loss: 2.041041843352779

Epoch: 5| Step: 4
Training loss: 1.325811505317688
Validation loss: 2.034636748734341

Epoch: 5| Step: 5
Training loss: 1.2723755836486816
Validation loss: 2.039383865171863

Epoch: 5| Step: 6
Training loss: 1.5880706310272217
Validation loss: 2.0687210085571452

Epoch: 5| Step: 7
Training loss: 2.076266050338745
Validation loss: 2.052403320548355

Epoch: 5| Step: 8
Training loss: 1.9932950735092163
Validation loss: 2.063195409313325

Epoch: 5| Step: 9
Training loss: 1.6283340454101562
Validation loss: 2.0669978818585797

Epoch: 5| Step: 10
Training loss: 1.4687505960464478
Validation loss: 2.057977722537133

Epoch: 215| Step: 0
Training loss: 1.460484266281128
Validation loss: 2.04725508920608

Epoch: 5| Step: 1
Training loss: 1.5658235549926758
Validation loss: 2.0431848508055492

Epoch: 5| Step: 2
Training loss: 1.631739616394043
Validation loss: 2.0393513684631674

Epoch: 5| Step: 3
Training loss: 1.9532268047332764
Validation loss: 2.0466906998747136

Epoch: 5| Step: 4
Training loss: 0.8582611083984375
Validation loss: 2.025147645704208

Epoch: 5| Step: 5
Training loss: 1.5297516584396362
Validation loss: 2.0276624489856023

Epoch: 5| Step: 6
Training loss: 2.195859432220459
Validation loss: 2.018519498968637

Epoch: 5| Step: 7
Training loss: 2.1954071521759033
Validation loss: 2.0212147082051923

Epoch: 5| Step: 8
Training loss: 1.3231841325759888
Validation loss: 2.02396128254552

Epoch: 5| Step: 9
Training loss: 2.210463523864746
Validation loss: 2.015523615703788

Epoch: 5| Step: 10
Training loss: 1.5306936502456665
Validation loss: 2.023553266320177

Epoch: 216| Step: 0
Training loss: 1.4279992580413818
Validation loss: 2.0303178782104165

Epoch: 5| Step: 1
Training loss: 1.0507036447525024
Validation loss: 2.0401106085828555

Epoch: 5| Step: 2
Training loss: 2.283621311187744
Validation loss: 2.0390424228483632

Epoch: 5| Step: 3
Training loss: 1.5191726684570312
Validation loss: 2.0451256152122252

Epoch: 5| Step: 4
Training loss: 1.167423129081726
Validation loss: 2.0204122758680776

Epoch: 5| Step: 5
Training loss: 1.7767369747161865
Validation loss: 2.0191943286567606

Epoch: 5| Step: 6
Training loss: 1.7482826709747314
Validation loss: 2.063897402055802

Epoch: 5| Step: 7
Training loss: 1.9003286361694336
Validation loss: 2.1059945219306537

Epoch: 5| Step: 8
Training loss: 1.7390203475952148
Validation loss: 2.09885694519166

Epoch: 5| Step: 9
Training loss: 2.1177659034729004
Validation loss: 2.1016530734236523

Epoch: 5| Step: 10
Training loss: 1.85711669921875
Validation loss: 2.098933982592757

Epoch: 217| Step: 0
Training loss: 1.8960597515106201
Validation loss: 2.0734347194753666

Epoch: 5| Step: 1
Training loss: 1.4138628244400024
Validation loss: 2.137762326066212

Epoch: 5| Step: 2
Training loss: 2.279674530029297
Validation loss: 2.1339783976154942

Epoch: 5| Step: 3
Training loss: 1.818121314048767
Validation loss: 2.071999038419416

Epoch: 5| Step: 4
Training loss: 1.2811641693115234
Validation loss: 2.0447196883539998

Epoch: 5| Step: 5
Training loss: 1.2560451030731201
Validation loss: 1.9803268704363095

Epoch: 5| Step: 6
Training loss: 1.9393835067749023
Validation loss: 1.9852104058829687

Epoch: 5| Step: 7
Training loss: 1.8907744884490967
Validation loss: 2.0205463594005955

Epoch: 5| Step: 8
Training loss: 2.00996732711792
Validation loss: 2.0284400729722876

Epoch: 5| Step: 9
Training loss: 1.7883552312850952
Validation loss: 2.033085846131848

Epoch: 5| Step: 10
Training loss: 1.7140141725540161
Validation loss: 1.9987227327080184

Epoch: 218| Step: 0
Training loss: 1.1371567249298096
Validation loss: 2.0058606440021145

Epoch: 5| Step: 1
Training loss: 1.7659753561019897
Validation loss: 2.017777055822393

Epoch: 5| Step: 2
Training loss: 1.3785371780395508
Validation loss: 2.057926206178563

Epoch: 5| Step: 3
Training loss: 1.9648557901382446
Validation loss: 2.1107750836239068

Epoch: 5| Step: 4
Training loss: 1.453107476234436
Validation loss: 2.1515437274850826

Epoch: 5| Step: 5
Training loss: 1.632239580154419
Validation loss: 2.131785624770708

Epoch: 5| Step: 6
Training loss: 2.260423183441162
Validation loss: 2.079896685897663

Epoch: 5| Step: 7
Training loss: 1.8559253215789795
Validation loss: 2.0628229712927215

Epoch: 5| Step: 8
Training loss: 1.5053058862686157
Validation loss: 2.0503330538349767

Epoch: 5| Step: 9
Training loss: 1.9511597156524658
Validation loss: 2.0417976071757655

Epoch: 5| Step: 10
Training loss: 1.660666823387146
Validation loss: 2.049073270572129

Epoch: 219| Step: 0
Training loss: 1.7361011505126953
Validation loss: 2.066337635440211

Epoch: 5| Step: 1
Training loss: 1.752233862876892
Validation loss: 2.0536283139259583

Epoch: 5| Step: 2
Training loss: 1.8012323379516602
Validation loss: 2.0183229856593634

Epoch: 5| Step: 3
Training loss: 2.179703950881958
Validation loss: 1.9911329823155557

Epoch: 5| Step: 4
Training loss: 1.4954094886779785
Validation loss: 1.9951964424502464

Epoch: 5| Step: 5
Training loss: 2.086103916168213
Validation loss: 2.047558502484393

Epoch: 5| Step: 6
Training loss: 1.0058143138885498
Validation loss: 2.095737703384892

Epoch: 5| Step: 7
Training loss: 2.2271032333374023
Validation loss: 2.132290417148221

Epoch: 5| Step: 8
Training loss: 2.06872820854187
Validation loss: 2.1546506240803707

Epoch: 5| Step: 9
Training loss: 1.40690279006958
Validation loss: 2.1324517162897254

Epoch: 5| Step: 10
Training loss: 1.6505632400512695
Validation loss: 2.1176326018507763

Epoch: 220| Step: 0
Training loss: 1.6149616241455078
Validation loss: 2.1254964490090646

Epoch: 5| Step: 1
Training loss: 1.5377728939056396
Validation loss: 2.145906042027217

Epoch: 5| Step: 2
Training loss: 1.4726821184158325
Validation loss: 2.1795844313918904

Epoch: 5| Step: 3
Training loss: 1.8494834899902344
Validation loss: 2.155690767431772

Epoch: 5| Step: 4
Training loss: 1.6856359243392944
Validation loss: 2.1458558805527224

Epoch: 5| Step: 5
Training loss: 1.4050012826919556
Validation loss: 2.107999916999571

Epoch: 5| Step: 6
Training loss: 1.7519481182098389
Validation loss: 2.064943159780195

Epoch: 5| Step: 7
Training loss: 1.6706138849258423
Validation loss: 2.0680872240374164

Epoch: 5| Step: 8
Training loss: 2.174583911895752
Validation loss: 2.110552332734549

Epoch: 5| Step: 9
Training loss: 1.6506407260894775
Validation loss: 2.129084863970357

Epoch: 5| Step: 10
Training loss: 2.085118055343628
Validation loss: 2.0850737646061885

Epoch: 221| Step: 0
Training loss: 1.5419771671295166
Validation loss: 2.0173555471563853

Epoch: 5| Step: 1
Training loss: 1.7076756954193115
Validation loss: 2.0025686089710524

Epoch: 5| Step: 2
Training loss: 2.16465425491333
Validation loss: 2.000831909077142

Epoch: 5| Step: 3
Training loss: 1.7451051473617554
Validation loss: 1.9936432248802596

Epoch: 5| Step: 4
Training loss: 1.9025661945343018
Validation loss: 1.9930448506468086

Epoch: 5| Step: 5
Training loss: 1.1209676265716553
Validation loss: 1.979404660963243

Epoch: 5| Step: 6
Training loss: 2.105167865753174
Validation loss: 1.9898749961647937

Epoch: 5| Step: 7
Training loss: 1.8847906589508057
Validation loss: 1.997424848618046

Epoch: 5| Step: 8
Training loss: 1.2202863693237305
Validation loss: 2.0096507610813266

Epoch: 5| Step: 9
Training loss: 1.5176677703857422
Validation loss: 2.0098457426153202

Epoch: 5| Step: 10
Training loss: 1.5120373964309692
Validation loss: 2.0167206743712067

Epoch: 222| Step: 0
Training loss: 1.3249027729034424
Validation loss: 2.050778204394925

Epoch: 5| Step: 1
Training loss: 1.650054931640625
Validation loss: 2.08522710492534

Epoch: 5| Step: 2
Training loss: 1.9325891733169556
Validation loss: 2.095067835623218

Epoch: 5| Step: 3
Training loss: 1.1522271633148193
Validation loss: 2.075352676453129

Epoch: 5| Step: 4
Training loss: 1.7232472896575928
Validation loss: 2.0681385737593456

Epoch: 5| Step: 5
Training loss: 1.724687933921814
Validation loss: 2.0395006313118884

Epoch: 5| Step: 6
Training loss: 1.3836119174957275
Validation loss: 2.021060005311043

Epoch: 5| Step: 7
Training loss: 1.4633041620254517
Validation loss: 2.001906971777639

Epoch: 5| Step: 8
Training loss: 1.876981496810913
Validation loss: 2.011663113870928

Epoch: 5| Step: 9
Training loss: 1.9361642599105835
Validation loss: 2.003124790806924

Epoch: 5| Step: 10
Training loss: 2.0283873081207275
Validation loss: 2.0165919885840466

Epoch: 223| Step: 0
Training loss: 1.8999103307724
Validation loss: 2.0297588366334156

Epoch: 5| Step: 1
Training loss: 1.1890313625335693
Validation loss: 2.0493847208638347

Epoch: 5| Step: 2
Training loss: 1.4315683841705322
Validation loss: 2.040037173096852

Epoch: 5| Step: 3
Training loss: 1.6008844375610352
Validation loss: 2.0736319275312525

Epoch: 5| Step: 4
Training loss: 1.266706943511963
Validation loss: 2.0690706968307495

Epoch: 5| Step: 5
Training loss: 2.159766435623169
Validation loss: 2.09010834334999

Epoch: 5| Step: 6
Training loss: 1.7008835077285767
Validation loss: 2.1143471476852254

Epoch: 5| Step: 7
Training loss: 2.0513689517974854
Validation loss: 2.1215478604839695

Epoch: 5| Step: 8
Training loss: 1.5836118459701538
Validation loss: 2.0861954637753066

Epoch: 5| Step: 9
Training loss: 1.6355369091033936
Validation loss: 2.095010106281568

Epoch: 5| Step: 10
Training loss: 1.3030498027801514
Validation loss: 2.0886199230788858

Epoch: 224| Step: 0
Training loss: 2.4414188861846924
Validation loss: 2.0722856521606445

Epoch: 5| Step: 1
Training loss: 2.0470237731933594
Validation loss: 2.068798001094531

Epoch: 5| Step: 2
Training loss: 1.8505630493164062
Validation loss: 2.0533197977209605

Epoch: 5| Step: 3
Training loss: 1.064892053604126
Validation loss: 2.046000193524104

Epoch: 5| Step: 4
Training loss: 1.262019395828247
Validation loss: 2.0217504744888632

Epoch: 5| Step: 5
Training loss: 2.0612525939941406
Validation loss: 2.0287086399652625

Epoch: 5| Step: 6
Training loss: 1.438535451889038
Validation loss: 2.024629949241556

Epoch: 5| Step: 7
Training loss: 1.576956868171692
Validation loss: 2.0144822802594913

Epoch: 5| Step: 8
Training loss: 1.3265498876571655
Validation loss: 2.0109413259772846

Epoch: 5| Step: 9
Training loss: 1.1082836389541626
Validation loss: 2.0226600041953464

Epoch: 5| Step: 10
Training loss: 1.3280950784683228
Validation loss: 2.044119217062509

Epoch: 225| Step: 0
Training loss: 1.5785953998565674
Validation loss: 2.053631462076659

Epoch: 5| Step: 1
Training loss: 1.6844593286514282
Validation loss: 2.039602541154431

Epoch: 5| Step: 2
Training loss: 1.1428418159484863
Validation loss: 2.040305636262381

Epoch: 5| Step: 3
Training loss: 2.1245908737182617
Validation loss: 2.072076593675921

Epoch: 5| Step: 4
Training loss: 1.739942193031311
Validation loss: 2.0674872680376937

Epoch: 5| Step: 5
Training loss: 1.4610919952392578
Validation loss: 2.0536810377592682

Epoch: 5| Step: 6
Training loss: 1.729941964149475
Validation loss: 2.0524408560927196

Epoch: 5| Step: 7
Training loss: 1.3143137693405151
Validation loss: 2.048828882555808

Epoch: 5| Step: 8
Training loss: 1.3435437679290771
Validation loss: 2.030291667548559

Epoch: 5| Step: 9
Training loss: 1.8728564977645874
Validation loss: 2.028038542757752

Epoch: 5| Step: 10
Training loss: 1.359541893005371
Validation loss: 2.026595413043935

Epoch: 226| Step: 0
Training loss: 0.8391133546829224
Validation loss: 2.026605366378702

Epoch: 5| Step: 1
Training loss: 1.732246994972229
Validation loss: 2.0457527176026375

Epoch: 5| Step: 2
Training loss: 1.5064259767532349
Validation loss: 2.0346012730752268

Epoch: 5| Step: 3
Training loss: 1.8183104991912842
Validation loss: 2.0262812965659687

Epoch: 5| Step: 4
Training loss: 1.1842949390411377
Validation loss: 2.034467863780196

Epoch: 5| Step: 5
Training loss: 2.1257131099700928
Validation loss: 2.039812654577276

Epoch: 5| Step: 6
Training loss: 1.255706548690796
Validation loss: 2.034586980778684

Epoch: 5| Step: 7
Training loss: 2.3123812675476074
Validation loss: 2.0405457058260517

Epoch: 5| Step: 8
Training loss: 1.1960182189941406
Validation loss: 2.0360071889815794

Epoch: 5| Step: 9
Training loss: 1.6441236734390259
Validation loss: 2.0427064100901284

Epoch: 5| Step: 10
Training loss: 1.5329313278198242
Validation loss: 2.0606560860910723

Epoch: 227| Step: 0
Training loss: 0.8275598287582397
Validation loss: 2.075399524422102

Epoch: 5| Step: 1
Training loss: 1.7966821193695068
Validation loss: 2.0633960577749435

Epoch: 5| Step: 2
Training loss: 1.6462491750717163
Validation loss: 2.051154072566699

Epoch: 5| Step: 3
Training loss: 1.587835669517517
Validation loss: 2.0386025764608897

Epoch: 5| Step: 4
Training loss: 1.3502117395401
Validation loss: 2.0144590408571306

Epoch: 5| Step: 5
Training loss: 1.5761089324951172
Validation loss: 2.0101493250939155

Epoch: 5| Step: 6
Training loss: 1.6268441677093506
Validation loss: 2.0369581150752243

Epoch: 5| Step: 7
Training loss: 1.5302072763442993
Validation loss: 2.013756252104236

Epoch: 5| Step: 8
Training loss: 1.4370213747024536
Validation loss: 2.037745387323441

Epoch: 5| Step: 9
Training loss: 1.4076063632965088
Validation loss: 2.0291661498367146

Epoch: 5| Step: 10
Training loss: 2.5278890132904053
Validation loss: 2.0423748544467393

Epoch: 228| Step: 0
Training loss: 1.257417917251587
Validation loss: 2.0578640763477614

Epoch: 5| Step: 1
Training loss: 1.9490859508514404
Validation loss: 2.06261380000781

Epoch: 5| Step: 2
Training loss: 1.0089359283447266
Validation loss: 2.057855067714568

Epoch: 5| Step: 3
Training loss: 1.229030966758728
Validation loss: 2.0627405284553446

Epoch: 5| Step: 4
Training loss: 1.3657622337341309
Validation loss: 2.0344126519336494

Epoch: 5| Step: 5
Training loss: 1.7087615728378296
Validation loss: 2.0250566544071322

Epoch: 5| Step: 6
Training loss: 1.3127338886260986
Validation loss: 2.024668485887589

Epoch: 5| Step: 7
Training loss: 2.2530760765075684
Validation loss: 2.0183808137011785

Epoch: 5| Step: 8
Training loss: 1.6355438232421875
Validation loss: 2.0313315058267243

Epoch: 5| Step: 9
Training loss: 1.7228130102157593
Validation loss: 2.0337520927511235

Epoch: 5| Step: 10
Training loss: 1.4305371046066284
Validation loss: 2.0520812029479654

Epoch: 229| Step: 0
Training loss: 1.3895719051361084
Validation loss: 2.0436811280506912

Epoch: 5| Step: 1
Training loss: 1.3051776885986328
Validation loss: 2.0700163789974746

Epoch: 5| Step: 2
Training loss: 1.597659707069397
Validation loss: 2.0952050724337177

Epoch: 5| Step: 3
Training loss: 1.892629623413086
Validation loss: 2.072389289896975

Epoch: 5| Step: 4
Training loss: 0.8732665777206421
Validation loss: 2.0699226356321767

Epoch: 5| Step: 5
Training loss: 1.9193313121795654
Validation loss: 2.103014903683816

Epoch: 5| Step: 6
Training loss: 1.311962366104126
Validation loss: 2.0915306422018234

Epoch: 5| Step: 7
Training loss: 1.5716030597686768
Validation loss: 2.0930242128269647

Epoch: 5| Step: 8
Training loss: 1.5720688104629517
Validation loss: 2.1004332624455935

Epoch: 5| Step: 9
Training loss: 1.7139606475830078
Validation loss: 2.094719789361441

Epoch: 5| Step: 10
Training loss: 1.6304839849472046
Validation loss: 2.0765156105000484

Epoch: 230| Step: 0
Training loss: 0.9251728057861328
Validation loss: 2.0577128164229856

Epoch: 5| Step: 1
Training loss: 1.7074886560440063
Validation loss: 2.0534496256100234

Epoch: 5| Step: 2
Training loss: 1.807369589805603
Validation loss: 2.040300133407757

Epoch: 5| Step: 3
Training loss: 1.8662364482879639
Validation loss: 2.027555472107344

Epoch: 5| Step: 4
Training loss: 1.537392020225525
Validation loss: 2.0309234819104596

Epoch: 5| Step: 5
Training loss: 1.2850697040557861
Validation loss: 2.021996924954076

Epoch: 5| Step: 6
Training loss: 1.386699914932251
Validation loss: 2.0167154342897478

Epoch: 5| Step: 7
Training loss: 1.7989187240600586
Validation loss: 2.0197354670493834

Epoch: 5| Step: 8
Training loss: 1.558098554611206
Validation loss: 2.014765368994846

Epoch: 5| Step: 9
Training loss: 1.1310579776763916
Validation loss: 2.0266101924321984

Epoch: 5| Step: 10
Training loss: 1.5592169761657715
Validation loss: 2.0329968390926236

Epoch: 231| Step: 0
Training loss: 1.5064510107040405
Validation loss: 2.039302859255063

Epoch: 5| Step: 1
Training loss: 1.8933143615722656
Validation loss: 2.0324652220613215

Epoch: 5| Step: 2
Training loss: 1.5791265964508057
Validation loss: 2.0537167838824693

Epoch: 5| Step: 3
Training loss: 1.9720159769058228
Validation loss: 2.047877706507201

Epoch: 5| Step: 4
Training loss: 1.6899051666259766
Validation loss: 2.0588517778663227

Epoch: 5| Step: 5
Training loss: 1.2906872034072876
Validation loss: 2.0472540573407243

Epoch: 5| Step: 6
Training loss: 1.0858075618743896
Validation loss: 2.037037157243298

Epoch: 5| Step: 7
Training loss: 1.0137059688568115
Validation loss: 2.0507932042562835

Epoch: 5| Step: 8
Training loss: 1.3422752618789673
Validation loss: 2.068200686926483

Epoch: 5| Step: 9
Training loss: 1.6478984355926514
Validation loss: 2.0769167920594573

Epoch: 5| Step: 10
Training loss: 1.4117575883865356
Validation loss: 2.0694500951356787

Epoch: 232| Step: 0
Training loss: 1.9321787357330322
Validation loss: 2.056566253785164

Epoch: 5| Step: 1
Training loss: 1.8850212097167969
Validation loss: 2.0704629472506944

Epoch: 5| Step: 2
Training loss: 1.2424588203430176
Validation loss: 2.047767985251642

Epoch: 5| Step: 3
Training loss: 2.048877239227295
Validation loss: 2.0239176058000132

Epoch: 5| Step: 4
Training loss: 1.3791347742080688
Validation loss: 2.0408866943851596

Epoch: 5| Step: 5
Training loss: 1.3212802410125732
Validation loss: 2.047592382277212

Epoch: 5| Step: 6
Training loss: 1.1227920055389404
Validation loss: 2.066219522107032

Epoch: 5| Step: 7
Training loss: 1.2281893491744995
Validation loss: 2.0684899796721754

Epoch: 5| Step: 8
Training loss: 1.4566494226455688
Validation loss: 2.0504967269077095

Epoch: 5| Step: 9
Training loss: 1.967206358909607
Validation loss: 2.0373842165034306

Epoch: 5| Step: 10
Training loss: 1.1403001546859741
Validation loss: 2.0436350478920886

Epoch: 233| Step: 0
Training loss: 1.4961992502212524
Validation loss: 2.0684208318751347

Epoch: 5| Step: 1
Training loss: 1.1049175262451172
Validation loss: 2.0683444751206266

Epoch: 5| Step: 2
Training loss: 1.3708709478378296
Validation loss: 2.072083724442349

Epoch: 5| Step: 3
Training loss: 2.208621025085449
Validation loss: 2.071639709575202

Epoch: 5| Step: 4
Training loss: 1.3042850494384766
Validation loss: 2.084524805827807

Epoch: 5| Step: 5
Training loss: 1.9460010528564453
Validation loss: 2.084032448389197

Epoch: 5| Step: 6
Training loss: 1.3846042156219482
Validation loss: 2.075134572162423

Epoch: 5| Step: 7
Training loss: 1.3705371618270874
Validation loss: 2.0544812576745146

Epoch: 5| Step: 8
Training loss: 1.7826871871948242
Validation loss: 2.02500408182862

Epoch: 5| Step: 9
Training loss: 1.1853854656219482
Validation loss: 2.017584995556903

Epoch: 5| Step: 10
Training loss: 1.4539753198623657
Validation loss: 2.036771671746367

Epoch: 234| Step: 0
Training loss: 1.2701246738433838
Validation loss: 1.9946324876559678

Epoch: 5| Step: 1
Training loss: 1.091200351715088
Validation loss: 2.024858984895932

Epoch: 5| Step: 2
Training loss: 1.3490636348724365
Validation loss: 2.0366631015654533

Epoch: 5| Step: 3
Training loss: 1.4368066787719727
Validation loss: 2.06439926931935

Epoch: 5| Step: 4
Training loss: 1.633334755897522
Validation loss: 2.071832049277521

Epoch: 5| Step: 5
Training loss: 1.933182716369629
Validation loss: 2.0777481217538156

Epoch: 5| Step: 6
Training loss: 1.5958656072616577
Validation loss: 2.0729714798670944

Epoch: 5| Step: 7
Training loss: 1.0491855144500732
Validation loss: 2.0827709154416154

Epoch: 5| Step: 8
Training loss: 1.3180921077728271
Validation loss: 2.0738540285377094

Epoch: 5| Step: 9
Training loss: 2.1082184314727783
Validation loss: 2.0674411840336298

Epoch: 5| Step: 10
Training loss: 1.626272201538086
Validation loss: 2.0805079103797994

Epoch: 235| Step: 0
Training loss: 1.3123184442520142
Validation loss: 2.056121433934858

Epoch: 5| Step: 1
Training loss: 1.128200888633728
Validation loss: 2.0584578975554435

Epoch: 5| Step: 2
Training loss: 1.3081640005111694
Validation loss: 2.047430289688931

Epoch: 5| Step: 3
Training loss: 1.2406729459762573
Validation loss: 2.082243429717197

Epoch: 5| Step: 4
Training loss: 1.5825059413909912
Validation loss: 2.0695730614405807

Epoch: 5| Step: 5
Training loss: 1.8130298852920532
Validation loss: 2.0373312734788462

Epoch: 5| Step: 6
Training loss: 1.8698527812957764
Validation loss: 2.035414280429963

Epoch: 5| Step: 7
Training loss: 1.9715334177017212
Validation loss: 2.0534801149881012

Epoch: 5| Step: 8
Training loss: 1.2179654836654663
Validation loss: 2.052727924880161

Epoch: 5| Step: 9
Training loss: 1.6472355127334595
Validation loss: 2.0153850073455484

Epoch: 5| Step: 10
Training loss: 1.1949090957641602
Validation loss: 2.0208296621999433

Epoch: 236| Step: 0
Training loss: 1.8118770122528076
Validation loss: 2.014834121991229

Epoch: 5| Step: 1
Training loss: 1.6959292888641357
Validation loss: 2.0170601798642065

Epoch: 5| Step: 2
Training loss: 1.073691487312317
Validation loss: 2.019280408018379

Epoch: 5| Step: 3
Training loss: 1.3219645023345947
Validation loss: 2.017451540116341

Epoch: 5| Step: 4
Training loss: 1.538028359413147
Validation loss: 2.048811299826509

Epoch: 5| Step: 5
Training loss: 1.4031693935394287
Validation loss: 2.07881857246481

Epoch: 5| Step: 6
Training loss: 1.6492341756820679
Validation loss: 2.076813672178535

Epoch: 5| Step: 7
Training loss: 1.506202220916748
Validation loss: 2.087775836708725

Epoch: 5| Step: 8
Training loss: 1.8108093738555908
Validation loss: 2.090964518567567

Epoch: 5| Step: 9
Training loss: 1.2632524967193604
Validation loss: 2.0782107307064916

Epoch: 5| Step: 10
Training loss: 0.7923111915588379
Validation loss: 2.063227574030558

Epoch: 237| Step: 0
Training loss: 1.5665687322616577
Validation loss: 2.028947071362567

Epoch: 5| Step: 1
Training loss: 1.2877072095870972
Validation loss: 2.0137621856504873

Epoch: 5| Step: 2
Training loss: 1.3010461330413818
Validation loss: 2.0273147552244124

Epoch: 5| Step: 3
Training loss: 1.6656324863433838
Validation loss: 2.0259655265397924

Epoch: 5| Step: 4
Training loss: 1.6334558725357056
Validation loss: 2.022699357360922

Epoch: 5| Step: 5
Training loss: 1.0149784088134766
Validation loss: 2.020954224371141

Epoch: 5| Step: 6
Training loss: 1.5719690322875977
Validation loss: 2.071015665608068

Epoch: 5| Step: 7
Training loss: 1.549018144607544
Validation loss: 2.104057360720891

Epoch: 5| Step: 8
Training loss: 1.6288974285125732
Validation loss: 2.0937686389492405

Epoch: 5| Step: 9
Training loss: 1.1586387157440186
Validation loss: 2.065245443774808

Epoch: 5| Step: 10
Training loss: 1.499053716659546
Validation loss: 2.0315441880174863

Epoch: 238| Step: 0
Training loss: 1.8614696264266968
Validation loss: 2.0120864837400374

Epoch: 5| Step: 1
Training loss: 1.3224427700042725
Validation loss: 2.0021321978620303

Epoch: 5| Step: 2
Training loss: 1.2979631423950195
Validation loss: 1.992593308930756

Epoch: 5| Step: 3
Training loss: 1.2061326503753662
Validation loss: 2.029546362097545

Epoch: 5| Step: 4
Training loss: 1.9459693431854248
Validation loss: 2.050493235229164

Epoch: 5| Step: 5
Training loss: 1.4287678003311157
Validation loss: 2.0730032523473105

Epoch: 5| Step: 6
Training loss: 1.5248138904571533
Validation loss: 2.0803300488379692

Epoch: 5| Step: 7
Training loss: 1.5570671558380127
Validation loss: 2.0429071405882477

Epoch: 5| Step: 8
Training loss: 1.2164500951766968
Validation loss: 2.011950792804841

Epoch: 5| Step: 9
Training loss: 1.432420253753662
Validation loss: 2.0210496892211256

Epoch: 5| Step: 10
Training loss: 1.0021889209747314
Validation loss: 1.9745347499847412

Epoch: 239| Step: 0
Training loss: 1.6484508514404297
Validation loss: 1.9892359215726134

Epoch: 5| Step: 1
Training loss: 1.710304617881775
Validation loss: 1.9772607318816646

Epoch: 5| Step: 2
Training loss: 1.0855464935302734
Validation loss: 1.9632655420610983

Epoch: 5| Step: 3
Training loss: 1.141686201095581
Validation loss: 1.9587842443937897

Epoch: 5| Step: 4
Training loss: 0.9754602313041687
Validation loss: 1.9755176959499237

Epoch: 5| Step: 5
Training loss: 1.0990753173828125
Validation loss: 2.000620590743198

Epoch: 5| Step: 6
Training loss: 1.6640799045562744
Validation loss: 2.0097613232110136

Epoch: 5| Step: 7
Training loss: 1.605810523033142
Validation loss: 2.050301874837568

Epoch: 5| Step: 8
Training loss: 1.1579720973968506
Validation loss: 2.072713280236849

Epoch: 5| Step: 9
Training loss: 1.2921825647354126
Validation loss: 2.1008274016841764

Epoch: 5| Step: 10
Training loss: 2.25264048576355
Validation loss: 2.136795932246793

Epoch: 240| Step: 0
Training loss: 1.4539546966552734
Validation loss: 2.1282692545203754

Epoch: 5| Step: 1
Training loss: 2.1213607788085938
Validation loss: 2.1021159259221887

Epoch: 5| Step: 2
Training loss: 1.5414321422576904
Validation loss: 2.051825119603065

Epoch: 5| Step: 3
Training loss: 1.0517767667770386
Validation loss: 2.073864741991925

Epoch: 5| Step: 4
Training loss: 1.5703637599945068
Validation loss: 2.068319892370573

Epoch: 5| Step: 5
Training loss: 1.3421751260757446
Validation loss: 2.0105175215710878

Epoch: 5| Step: 6
Training loss: 0.9593168497085571
Validation loss: 1.98718294020622

Epoch: 5| Step: 7
Training loss: 1.6278804540634155
Validation loss: 1.977804914597542

Epoch: 5| Step: 8
Training loss: 1.3115640878677368
Validation loss: 1.9867015833495765

Epoch: 5| Step: 9
Training loss: 1.223549246788025
Validation loss: 1.958554913920741

Epoch: 5| Step: 10
Training loss: 1.431525468826294
Validation loss: 1.9599599863893242

Epoch: 241| Step: 0
Training loss: 1.2707926034927368
Validation loss: 1.9537039110737462

Epoch: 5| Step: 1
Training loss: 1.3845659494400024
Validation loss: 1.9782146792257986

Epoch: 5| Step: 2
Training loss: 1.3808609247207642
Validation loss: 1.9868489670497116

Epoch: 5| Step: 3
Training loss: 1.0708253383636475
Validation loss: 1.9967507982766757

Epoch: 5| Step: 4
Training loss: 1.2765320539474487
Validation loss: 2.017958269324354

Epoch: 5| Step: 5
Training loss: 1.3400007486343384
Validation loss: 2.042308338226811

Epoch: 5| Step: 6
Training loss: 1.6932045221328735
Validation loss: 2.0754066821067565

Epoch: 5| Step: 7
Training loss: 1.6635574102401733
Validation loss: 2.0933143477286063

Epoch: 5| Step: 8
Training loss: 1.426530361175537
Validation loss: 2.109454970205984

Epoch: 5| Step: 9
Training loss: 1.6024143695831299
Validation loss: 2.096180505650018

Epoch: 5| Step: 10
Training loss: 1.2802190780639648
Validation loss: 2.055320011672153

Epoch: 242| Step: 0
Training loss: 1.1146265268325806
Validation loss: 2.0197908955235637

Epoch: 5| Step: 1
Training loss: 1.333370566368103
Validation loss: 1.972363200238956

Epoch: 5| Step: 2
Training loss: 1.2361195087432861
Validation loss: 1.9446906671729138

Epoch: 5| Step: 3
Training loss: 1.998705267906189
Validation loss: 1.9281829480201966

Epoch: 5| Step: 4
Training loss: 1.6661717891693115
Validation loss: 1.9542071460395731

Epoch: 5| Step: 5
Training loss: 1.7675085067749023
Validation loss: 1.9556804754400765

Epoch: 5| Step: 6
Training loss: 1.0509954690933228
Validation loss: 1.9737761071933213

Epoch: 5| Step: 7
Training loss: 0.9698038101196289
Validation loss: 1.9990182756095805

Epoch: 5| Step: 8
Training loss: 1.7686294317245483
Validation loss: 2.0465364904813867

Epoch: 5| Step: 9
Training loss: 1.7521429061889648
Validation loss: 2.0779573802025086

Epoch: 5| Step: 10
Training loss: 1.0877817869186401
Validation loss: 2.1259477561519993

Epoch: 243| Step: 0
Training loss: 1.4980213642120361
Validation loss: 2.12152603877488

Epoch: 5| Step: 1
Training loss: 1.3395909070968628
Validation loss: 2.1253964618969987

Epoch: 5| Step: 2
Training loss: 1.5342355966567993
Validation loss: 2.0886189553045456

Epoch: 5| Step: 3
Training loss: 1.304078459739685
Validation loss: 2.0766740563095256

Epoch: 5| Step: 4
Training loss: 1.4164395332336426
Validation loss: 2.043301469536238

Epoch: 5| Step: 5
Training loss: 1.0493896007537842
Validation loss: 2.024519681930542

Epoch: 5| Step: 6
Training loss: 1.3123769760131836
Validation loss: 2.0030007811002832

Epoch: 5| Step: 7
Training loss: 1.44661545753479
Validation loss: 1.9777432769857428

Epoch: 5| Step: 8
Training loss: 1.8140194416046143
Validation loss: 1.9870692837622859

Epoch: 5| Step: 9
Training loss: 1.3603878021240234
Validation loss: 1.9841929533148324

Epoch: 5| Step: 10
Training loss: 1.2145955562591553
Validation loss: 1.9487592251070085

Epoch: 244| Step: 0
Training loss: 0.9797364473342896
Validation loss: 1.945060876107985

Epoch: 5| Step: 1
Training loss: 1.3987209796905518
Validation loss: 1.944385681101071

Epoch: 5| Step: 2
Training loss: 1.5961462259292603
Validation loss: 1.9391289193143126

Epoch: 5| Step: 3
Training loss: 1.2438886165618896
Validation loss: 1.9561336463497532

Epoch: 5| Step: 4
Training loss: 1.7941467761993408
Validation loss: 1.9506698449452717

Epoch: 5| Step: 5
Training loss: 1.8334920406341553
Validation loss: 1.9716360158817743

Epoch: 5| Step: 6
Training loss: 1.2818485498428345
Validation loss: 2.0092332773311163

Epoch: 5| Step: 7
Training loss: 1.929517149925232
Validation loss: 2.0185339425199773

Epoch: 5| Step: 8
Training loss: 1.017427682876587
Validation loss: 2.026509197809363

Epoch: 5| Step: 9
Training loss: 0.8508318066596985
Validation loss: 2.0298010444128387

Epoch: 5| Step: 10
Training loss: 1.1393650770187378
Validation loss: 2.0331441740835867

Epoch: 245| Step: 0
Training loss: 1.439026951789856
Validation loss: 2.0236341671277116

Epoch: 5| Step: 1
Training loss: 2.049553632736206
Validation loss: 2.0210492405840146

Epoch: 5| Step: 2
Training loss: 1.2683265209197998
Validation loss: 2.0139320973427064

Epoch: 5| Step: 3
Training loss: 1.365678310394287
Validation loss: 1.964515938553759

Epoch: 5| Step: 4
Training loss: 1.261876106262207
Validation loss: 1.9620389822990663

Epoch: 5| Step: 5
Training loss: 1.6839176416397095
Validation loss: 1.9467652997662943

Epoch: 5| Step: 6
Training loss: 1.2674118280410767
Validation loss: 1.962218064133839

Epoch: 5| Step: 7
Training loss: 1.093490481376648
Validation loss: 1.9663163513265631

Epoch: 5| Step: 8
Training loss: 1.306193232536316
Validation loss: 1.9835945380631315

Epoch: 5| Step: 9
Training loss: 1.3241750001907349
Validation loss: 1.9961768542566607

Epoch: 5| Step: 10
Training loss: 0.9522637724876404
Validation loss: 2.017585459575858

Epoch: 246| Step: 0
Training loss: 1.2117919921875
Validation loss: 2.0585382189801944

Epoch: 5| Step: 1
Training loss: 1.2969729900360107
Validation loss: 2.0762137905243905

Epoch: 5| Step: 2
Training loss: 1.2585506439208984
Validation loss: 2.0649933789366033

Epoch: 5| Step: 3
Training loss: 1.656944990158081
Validation loss: 2.0806534418495755

Epoch: 5| Step: 4
Training loss: 1.3992668390274048
Validation loss: 2.054187733639953

Epoch: 5| Step: 5
Training loss: 2.008556365966797
Validation loss: 2.0324041830596102

Epoch: 5| Step: 6
Training loss: 1.6755542755126953
Validation loss: 1.9910116452042774

Epoch: 5| Step: 7
Training loss: 1.3968093395233154
Validation loss: 1.9847409622643584

Epoch: 5| Step: 8
Training loss: 0.4977894723415375
Validation loss: 1.9806464243960638

Epoch: 5| Step: 9
Training loss: 1.076294183731079
Validation loss: 1.9694292724773448

Epoch: 5| Step: 10
Training loss: 1.4308754205703735
Validation loss: 1.9810383319854736

Epoch: 247| Step: 0
Training loss: 1.4058406352996826
Validation loss: 1.9521915348627235

Epoch: 5| Step: 1
Training loss: 1.3171117305755615
Validation loss: 1.9767481639821043

Epoch: 5| Step: 2
Training loss: 1.1290799379348755
Validation loss: 1.9773040574084046

Epoch: 5| Step: 3
Training loss: 1.4108319282531738
Validation loss: 1.9932107592141757

Epoch: 5| Step: 4
Training loss: 1.214280128479004
Validation loss: 2.000743060983637

Epoch: 5| Step: 5
Training loss: 1.9743038415908813
Validation loss: 2.013089341502036

Epoch: 5| Step: 6
Training loss: 0.9052445292472839
Validation loss: 2.0195842994156705

Epoch: 5| Step: 7
Training loss: 1.3409483432769775
Validation loss: 1.984017514413403

Epoch: 5| Step: 8
Training loss: 1.579455852508545
Validation loss: 1.9592450382888957

Epoch: 5| Step: 9
Training loss: 1.5414378643035889
Validation loss: 1.986935055384072

Epoch: 5| Step: 10
Training loss: 0.9181913733482361
Validation loss: 1.96242912994918

Epoch: 248| Step: 0
Training loss: 1.28500497341156
Validation loss: 1.9834855435996928

Epoch: 5| Step: 1
Training loss: 2.361429214477539
Validation loss: 2.0126470032558648

Epoch: 5| Step: 2
Training loss: 1.2256006002426147
Validation loss: 2.032190219048531

Epoch: 5| Step: 3
Training loss: 1.1059361696243286
Validation loss: 2.0444163250666794

Epoch: 5| Step: 4
Training loss: 1.3571230173110962
Validation loss: 2.056023547726293

Epoch: 5| Step: 5
Training loss: 1.4708576202392578
Validation loss: 2.0178905815206547

Epoch: 5| Step: 6
Training loss: 1.1552565097808838
Validation loss: 2.019709130769135

Epoch: 5| Step: 7
Training loss: 1.07318913936615
Validation loss: 2.0254583422855665

Epoch: 5| Step: 8
Training loss: 1.336679220199585
Validation loss: 2.003868446555189

Epoch: 5| Step: 9
Training loss: 0.9557921290397644
Validation loss: 2.0163254327671503

Epoch: 5| Step: 10
Training loss: 1.5370389223098755
Validation loss: 2.0028608691307808

Epoch: 249| Step: 0
Training loss: 1.2304012775421143
Validation loss: 2.000249115369653

Epoch: 5| Step: 1
Training loss: 0.976237952709198
Validation loss: 1.9716752652199037

Epoch: 5| Step: 2
Training loss: 1.161981225013733
Validation loss: 2.0080705881118774

Epoch: 5| Step: 3
Training loss: 1.0119729042053223
Validation loss: 1.9848161884533462

Epoch: 5| Step: 4
Training loss: 1.4265120029449463
Validation loss: 1.996329105028542

Epoch: 5| Step: 5
Training loss: 1.4370765686035156
Validation loss: 2.0056927511768956

Epoch: 5| Step: 6
Training loss: 1.260775089263916
Validation loss: 2.028084739562004

Epoch: 5| Step: 7
Training loss: 1.501536250114441
Validation loss: 2.055881912990283

Epoch: 5| Step: 8
Training loss: 1.7170889377593994
Validation loss: 2.07219349697072

Epoch: 5| Step: 9
Training loss: 1.5564019680023193
Validation loss: 2.075869837114888

Epoch: 5| Step: 10
Training loss: 1.4041318893432617
Validation loss: 2.053161228856733

Epoch: 250| Step: 0
Training loss: 1.431367039680481
Validation loss: 2.0220065527064826

Epoch: 5| Step: 1
Training loss: 1.5006492137908936
Validation loss: 1.9962147205106673

Epoch: 5| Step: 2
Training loss: 0.8773212432861328
Validation loss: 1.9936420174055203

Epoch: 5| Step: 3
Training loss: 1.3556362390518188
Validation loss: 1.98667130162639

Epoch: 5| Step: 4
Training loss: 0.949378490447998
Validation loss: 1.9573065247586978

Epoch: 5| Step: 5
Training loss: 1.5767202377319336
Validation loss: 1.9496666616009128

Epoch: 5| Step: 6
Training loss: 1.6441940069198608
Validation loss: 1.9492273638325353

Epoch: 5| Step: 7
Training loss: 1.6463779211044312
Validation loss: 1.9169146578799012

Epoch: 5| Step: 8
Training loss: 1.4069687128067017
Validation loss: 1.9272523362149474

Epoch: 5| Step: 9
Training loss: 1.3592054843902588
Validation loss: 1.943562230756206

Epoch: 5| Step: 10
Training loss: 1.3297648429870605
Validation loss: 1.9443804179468462

Epoch: 251| Step: 0
Training loss: 1.2279679775238037
Validation loss: 1.9478827599556214

Epoch: 5| Step: 1
Training loss: 1.3244149684906006
Validation loss: 1.9571367797031198

Epoch: 5| Step: 2
Training loss: 1.2556169033050537
Validation loss: 1.9950293994718982

Epoch: 5| Step: 3
Training loss: 1.4463496208190918
Validation loss: 2.036053152494533

Epoch: 5| Step: 4
Training loss: 1.1231850385665894
Validation loss: 2.066445332701488

Epoch: 5| Step: 5
Training loss: 1.3868063688278198
Validation loss: 2.061164548320155

Epoch: 5| Step: 6
Training loss: 1.7116515636444092
Validation loss: 2.0541154748650006

Epoch: 5| Step: 7
Training loss: 1.099671721458435
Validation loss: 2.0231743666433517

Epoch: 5| Step: 8
Training loss: 1.4099547863006592
Validation loss: 2.032890048078311

Epoch: 5| Step: 9
Training loss: 1.2838071584701538
Validation loss: 1.9813943357877835

Epoch: 5| Step: 10
Training loss: 1.2104073762893677
Validation loss: 1.9595062604514502

Epoch: 252| Step: 0
Training loss: 1.1097136735916138
Validation loss: 1.9236793300156951

Epoch: 5| Step: 1
Training loss: 1.5261170864105225
Validation loss: 1.914662666218255

Epoch: 5| Step: 2
Training loss: 1.1032006740570068
Validation loss: 1.9030398886690858

Epoch: 5| Step: 3
Training loss: 1.4554109573364258
Validation loss: 1.9592311407930108

Epoch: 5| Step: 4
Training loss: 1.3296774625778198
Validation loss: 1.969224331199482

Epoch: 5| Step: 5
Training loss: 1.521156907081604
Validation loss: 1.9946587982998099

Epoch: 5| Step: 6
Training loss: 1.4384223222732544
Validation loss: 1.9983940034784295

Epoch: 5| Step: 7
Training loss: 1.7734787464141846
Validation loss: 2.0213203071266093

Epoch: 5| Step: 8
Training loss: 1.238018274307251
Validation loss: 2.039759679507184

Epoch: 5| Step: 9
Training loss: 1.169578194618225
Validation loss: 2.0344492530310028

Epoch: 5| Step: 10
Training loss: 1.165446400642395
Validation loss: 2.0320178026794107

Epoch: 253| Step: 0
Training loss: 1.2141144275665283
Validation loss: 2.0182422540521108

Epoch: 5| Step: 1
Training loss: 1.9132120609283447
Validation loss: 2.030409687308855

Epoch: 5| Step: 2
Training loss: 1.18017578125
Validation loss: 1.9474765510969265

Epoch: 5| Step: 3
Training loss: 1.5112810134887695
Validation loss: 1.9377828746713617

Epoch: 5| Step: 4
Training loss: 0.8997198343276978
Validation loss: 1.938459365598617

Epoch: 5| Step: 5
Training loss: 1.0608980655670166
Validation loss: 1.9186230090356642

Epoch: 5| Step: 6
Training loss: 1.4702556133270264
Validation loss: 1.934217578621321

Epoch: 5| Step: 7
Training loss: 1.4202539920806885
Validation loss: 1.9339324710189656

Epoch: 5| Step: 8
Training loss: 1.3159043788909912
Validation loss: 1.9255467127728205

Epoch: 5| Step: 9
Training loss: 1.1233657598495483
Validation loss: 1.9488893439692836

Epoch: 5| Step: 10
Training loss: 1.5795106887817383
Validation loss: 1.9733156363169353

Epoch: 254| Step: 0
Training loss: 0.8886957168579102
Validation loss: 2.003732091637068

Epoch: 5| Step: 1
Training loss: 1.5891484022140503
Validation loss: 2.017326183216546

Epoch: 5| Step: 2
Training loss: 1.0341013669967651
Validation loss: 2.0147245904450775

Epoch: 5| Step: 3
Training loss: 1.6693027019500732
Validation loss: 2.009947032056829

Epoch: 5| Step: 4
Training loss: 0.8800215721130371
Validation loss: 1.976484767852291

Epoch: 5| Step: 5
Training loss: 1.5003927946090698
Validation loss: 1.9730497855012135

Epoch: 5| Step: 6
Training loss: 1.297463059425354
Validation loss: 1.9637945839153823

Epoch: 5| Step: 7
Training loss: 1.3171489238739014
Validation loss: 1.9643081298438452

Epoch: 5| Step: 8
Training loss: 1.432134985923767
Validation loss: 1.9499493593810706

Epoch: 5| Step: 9
Training loss: 1.2848230600357056
Validation loss: 1.9391108353932698

Epoch: 5| Step: 10
Training loss: 1.4607518911361694
Validation loss: 1.9583662325336086

Epoch: 255| Step: 0
Training loss: 0.9060733914375305
Validation loss: 1.9501534456847816

Epoch: 5| Step: 1
Training loss: 1.5626490116119385
Validation loss: 1.9549979150936168

Epoch: 5| Step: 2
Training loss: 1.143451452255249
Validation loss: 1.9800002421102216

Epoch: 5| Step: 3
Training loss: 1.0624970197677612
Validation loss: 2.006572090169435

Epoch: 5| Step: 4
Training loss: 1.3964271545410156
Validation loss: 2.020949920018514

Epoch: 5| Step: 5
Training loss: 1.4195106029510498
Validation loss: 2.0292314201272945

Epoch: 5| Step: 6
Training loss: 0.9987081289291382
Validation loss: 2.075578874157321

Epoch: 5| Step: 7
Training loss: 0.9872003793716431
Validation loss: 2.0676997694917905

Epoch: 5| Step: 8
Training loss: 1.7436708211898804
Validation loss: 2.034928383365754

Epoch: 5| Step: 9
Training loss: 1.7618486881256104
Validation loss: 2.037459574719911

Epoch: 5| Step: 10
Training loss: 0.9181758761405945
Validation loss: 2.002772717065709

Epoch: 256| Step: 0
Training loss: 1.212710976600647
Validation loss: 1.9861664310578377

Epoch: 5| Step: 1
Training loss: 1.2424092292785645
Validation loss: 1.9775312792870305

Epoch: 5| Step: 2
Training loss: 1.6249563694000244
Validation loss: 1.9652252030628983

Epoch: 5| Step: 3
Training loss: 1.5433956384658813
Validation loss: 1.9600727635045205

Epoch: 5| Step: 4
Training loss: 1.1817761659622192
Validation loss: 1.9804004110315794

Epoch: 5| Step: 5
Training loss: 1.2377879619598389
Validation loss: 1.9485051119199364

Epoch: 5| Step: 6
Training loss: 0.9920147061347961
Validation loss: 1.9293869682537612

Epoch: 5| Step: 7
Training loss: 0.8842032551765442
Validation loss: 1.9496141056860647

Epoch: 5| Step: 8
Training loss: 1.3318703174591064
Validation loss: 1.973350142919889

Epoch: 5| Step: 9
Training loss: 1.4786089658737183
Validation loss: 1.9804424034651888

Epoch: 5| Step: 10
Training loss: 1.098120093345642
Validation loss: 2.021535914431336

Epoch: 257| Step: 0
Training loss: 1.1291911602020264
Validation loss: 1.9997031214416667

Epoch: 5| Step: 1
Training loss: 1.3119702339172363
Validation loss: 2.047820452720888

Epoch: 5| Step: 2
Training loss: 1.5237362384796143
Validation loss: 2.0360017681634552

Epoch: 5| Step: 3
Training loss: 1.245260238647461
Validation loss: 2.0312198195406186

Epoch: 5| Step: 4
Training loss: 1.3551756143569946
Validation loss: 1.99765303058009

Epoch: 5| Step: 5
Training loss: 0.8515297174453735
Validation loss: 1.978391465320382

Epoch: 5| Step: 6
Training loss: 1.0378718376159668
Validation loss: 1.95892382437183

Epoch: 5| Step: 7
Training loss: 1.2991106510162354
Validation loss: 1.9556008308164534

Epoch: 5| Step: 8
Training loss: 1.0520763397216797
Validation loss: 1.9669106544986847

Epoch: 5| Step: 9
Training loss: 1.2708741426467896
Validation loss: 1.9666850643773233

Epoch: 5| Step: 10
Training loss: 1.674961805343628
Validation loss: 1.975363592947683

Epoch: 258| Step: 0
Training loss: 0.8160643577575684
Validation loss: 1.956802821928455

Epoch: 5| Step: 1
Training loss: 1.5981296300888062
Validation loss: 1.9577110377691125

Epoch: 5| Step: 2
Training loss: 1.3848780393600464
Validation loss: 1.9877111732318837

Epoch: 5| Step: 3
Training loss: 0.9587982296943665
Validation loss: 1.983145263887221

Epoch: 5| Step: 4
Training loss: 1.752367615699768
Validation loss: 1.9861024374602942

Epoch: 5| Step: 5
Training loss: 0.8585271835327148
Validation loss: 1.9851763222807197

Epoch: 5| Step: 6
Training loss: 1.018662452697754
Validation loss: 1.9932629664738972

Epoch: 5| Step: 7
Training loss: 1.6763566732406616
Validation loss: 1.9803925739821566

Epoch: 5| Step: 8
Training loss: 1.2676113843917847
Validation loss: 1.9922212067470755

Epoch: 5| Step: 9
Training loss: 1.0722668170928955
Validation loss: 1.9719414057270173

Epoch: 5| Step: 10
Training loss: 1.183841586112976
Validation loss: 1.979211631641593

Epoch: 259| Step: 0
Training loss: 1.1934852600097656
Validation loss: 1.9453841306829964

Epoch: 5| Step: 1
Training loss: 0.8928230404853821
Validation loss: 1.9582516967609365

Epoch: 5| Step: 2
Training loss: 1.2868621349334717
Validation loss: 1.940770870895796

Epoch: 5| Step: 3
Training loss: 0.7783074975013733
Validation loss: 1.9613584946560603

Epoch: 5| Step: 4
Training loss: 1.7947235107421875
Validation loss: 1.947258633951987

Epoch: 5| Step: 5
Training loss: 1.2139034271240234
Validation loss: 1.9749864967920447

Epoch: 5| Step: 6
Training loss: 1.0477263927459717
Validation loss: 1.9831406506158973

Epoch: 5| Step: 7
Training loss: 1.0858451128005981
Validation loss: 2.004951371941515

Epoch: 5| Step: 8
Training loss: 1.0076574087142944
Validation loss: 1.9954381373620802

Epoch: 5| Step: 9
Training loss: 1.282308578491211
Validation loss: 2.0162617929520144

Epoch: 5| Step: 10
Training loss: 1.8925565481185913
Validation loss: 1.996939956500966

Epoch: 260| Step: 0
Training loss: 1.075264573097229
Validation loss: 2.0076400182580434

Epoch: 5| Step: 1
Training loss: 1.2259960174560547
Validation loss: 2.0119487342014106

Epoch: 5| Step: 2
Training loss: 1.6075626611709595
Validation loss: 2.0001409361439366

Epoch: 5| Step: 3
Training loss: 1.2324182987213135
Validation loss: 2.00174779276694

Epoch: 5| Step: 4
Training loss: 1.185610294342041
Validation loss: 1.9974602422406595

Epoch: 5| Step: 5
Training loss: 0.6866192817687988
Validation loss: 1.989790326805525

Epoch: 5| Step: 6
Training loss: 1.4775632619857788
Validation loss: 1.99886489939946

Epoch: 5| Step: 7
Training loss: 1.1735069751739502
Validation loss: 2.005083273815852

Epoch: 5| Step: 8
Training loss: 1.3749977350234985
Validation loss: 1.9941274068688835

Epoch: 5| Step: 9
Training loss: 1.0086536407470703
Validation loss: 1.9563843447674987

Epoch: 5| Step: 10
Training loss: 1.5608326196670532
Validation loss: 1.9202824818190707

Epoch: 261| Step: 0
Training loss: 1.245580792427063
Validation loss: 1.8953085202042774

Epoch: 5| Step: 1
Training loss: 1.4475977420806885
Validation loss: 1.9396037094054683

Epoch: 5| Step: 2
Training loss: 1.5358026027679443
Validation loss: 1.9401606052152571

Epoch: 5| Step: 3
Training loss: 1.2750321626663208
Validation loss: 1.9338725843737203

Epoch: 5| Step: 4
Training loss: 1.0180846452713013
Validation loss: 1.9690120425275577

Epoch: 5| Step: 5
Training loss: 1.2288166284561157
Validation loss: 1.9634862189651818

Epoch: 5| Step: 6
Training loss: 1.2914934158325195
Validation loss: 2.0103666846470167

Epoch: 5| Step: 7
Training loss: 0.882717490196228
Validation loss: 1.99281604572009

Epoch: 5| Step: 8
Training loss: 1.1924887895584106
Validation loss: 1.978600025177002

Epoch: 5| Step: 9
Training loss: 1.0469326972961426
Validation loss: 1.963381346835885

Epoch: 5| Step: 10
Training loss: 1.3240442276000977
Validation loss: 1.943651380077485

Epoch: 262| Step: 0
Training loss: 1.2727230787277222
Validation loss: 1.9647156423138035

Epoch: 5| Step: 1
Training loss: 1.3778066635131836
Validation loss: 1.9657151186338035

Epoch: 5| Step: 2
Training loss: 1.1780842542648315
Validation loss: 1.9978463572840537

Epoch: 5| Step: 3
Training loss: 1.083947777748108
Validation loss: 2.013686941516015

Epoch: 5| Step: 4
Training loss: 1.4789073467254639
Validation loss: 2.02898169332935

Epoch: 5| Step: 5
Training loss: 0.892734706401825
Validation loss: 2.013972964338077

Epoch: 5| Step: 6
Training loss: 1.2831618785858154
Validation loss: 2.0151497189716627

Epoch: 5| Step: 7
Training loss: 1.422522783279419
Validation loss: 2.008619450753735

Epoch: 5| Step: 8
Training loss: 0.7789069414138794
Validation loss: 1.9870005833205355

Epoch: 5| Step: 9
Training loss: 1.164058804512024
Validation loss: 1.9560647818350023

Epoch: 5| Step: 10
Training loss: 1.1041501760482788
Validation loss: 1.965684780510523

Epoch: 263| Step: 0
Training loss: 1.4813430309295654
Validation loss: 1.960960425356383

Epoch: 5| Step: 1
Training loss: 1.4579843282699585
Validation loss: 1.943281808207112

Epoch: 5| Step: 2
Training loss: 0.8050237894058228
Validation loss: 1.9312765175296414

Epoch: 5| Step: 3
Training loss: 1.2002644538879395
Validation loss: 1.9429758223154212

Epoch: 5| Step: 4
Training loss: 0.49816447496414185
Validation loss: 1.9482326033294841

Epoch: 5| Step: 5
Training loss: 1.1046419143676758
Validation loss: 1.9699416083674277

Epoch: 5| Step: 6
Training loss: 1.2790517807006836
Validation loss: 2.0138313142202233

Epoch: 5| Step: 7
Training loss: 0.8544076085090637
Validation loss: 2.025840336276639

Epoch: 5| Step: 8
Training loss: 1.6344413757324219
Validation loss: 2.0102531256214267

Epoch: 5| Step: 9
Training loss: 1.1552374362945557
Validation loss: 2.0194217748539423

Epoch: 5| Step: 10
Training loss: 1.265203595161438
Validation loss: 1.980052782643226

Epoch: 264| Step: 0
Training loss: 1.311312198638916
Validation loss: 1.973044377501293

Epoch: 5| Step: 1
Training loss: 1.157403826713562
Validation loss: 1.9734244526073497

Epoch: 5| Step: 2
Training loss: 1.445737600326538
Validation loss: 1.9536188315319758

Epoch: 5| Step: 3
Training loss: 0.8163920640945435
Validation loss: 1.9420428660608107

Epoch: 5| Step: 4
Training loss: 1.2896537780761719
Validation loss: 1.9705694913864136

Epoch: 5| Step: 5
Training loss: 1.3205976486206055
Validation loss: 1.959776375883369

Epoch: 5| Step: 6
Training loss: 0.9610945582389832
Validation loss: 1.9409659037026026

Epoch: 5| Step: 7
Training loss: 0.9074243307113647
Validation loss: 1.9819067447416243

Epoch: 5| Step: 8
Training loss: 1.0024964809417725
Validation loss: 1.9813189762894825

Epoch: 5| Step: 9
Training loss: 1.6172161102294922
Validation loss: 2.0274461879525134

Epoch: 5| Step: 10
Training loss: 0.6780747771263123
Validation loss: 2.0235560388975244

Epoch: 265| Step: 0
Training loss: 1.0344725847244263
Validation loss: 2.0027768945181244

Epoch: 5| Step: 1
Training loss: 1.4780906438827515
Validation loss: 1.9576068937137563

Epoch: 5| Step: 2
Training loss: 1.2189905643463135
Validation loss: 1.9430336477935954

Epoch: 5| Step: 3
Training loss: 0.9612029790878296
Validation loss: 1.9256894985834758

Epoch: 5| Step: 4
Training loss: 0.9760133028030396
Validation loss: 1.9047979975259433

Epoch: 5| Step: 5
Training loss: 1.3146473169326782
Validation loss: 1.907911495495868

Epoch: 5| Step: 6
Training loss: 1.2900865077972412
Validation loss: 1.9381029272592196

Epoch: 5| Step: 7
Training loss: 1.0652198791503906
Validation loss: 1.9595356590004378

Epoch: 5| Step: 8
Training loss: 1.0465763807296753
Validation loss: 1.9844208199490783

Epoch: 5| Step: 9
Training loss: 0.8574855923652649
Validation loss: 1.994941439679874

Epoch: 5| Step: 10
Training loss: 1.3437185287475586
Validation loss: 2.0190111257696666

Epoch: 266| Step: 0
Training loss: 0.7557498812675476
Validation loss: 2.0013434579295497

Epoch: 5| Step: 1
Training loss: 1.0963807106018066
Validation loss: 1.9788241796596076

Epoch: 5| Step: 2
Training loss: 1.2052117586135864
Validation loss: 1.978486971188617

Epoch: 5| Step: 3
Training loss: 1.4202649593353271
Validation loss: 1.949210714268428

Epoch: 5| Step: 4
Training loss: 1.1298854351043701
Validation loss: 1.9211346821118427

Epoch: 5| Step: 5
Training loss: 1.186763048171997
Validation loss: 1.9177157084147136

Epoch: 5| Step: 6
Training loss: 0.9846059679985046
Validation loss: 1.9260836211583947

Epoch: 5| Step: 7
Training loss: 1.406165361404419
Validation loss: 1.9449702385933167

Epoch: 5| Step: 8
Training loss: 1.1342880725860596
Validation loss: 1.938553564010128

Epoch: 5| Step: 9
Training loss: 1.123094081878662
Validation loss: 1.9568233489990234

Epoch: 5| Step: 10
Training loss: 0.9215239882469177
Validation loss: 1.9659797440293014

Epoch: 267| Step: 0
Training loss: 0.9953354597091675
Validation loss: 1.9774333597511373

Epoch: 5| Step: 1
Training loss: 1.022099494934082
Validation loss: 1.9827360081416305

Epoch: 5| Step: 2
Training loss: 1.4786365032196045
Validation loss: 2.0199424118124027

Epoch: 5| Step: 3
Training loss: 1.7021381855010986
Validation loss: 2.0351067691720943

Epoch: 5| Step: 4
Training loss: 0.6334040760993958
Validation loss: 2.0290911248935166

Epoch: 5| Step: 5
Training loss: 0.7449297904968262
Validation loss: 2.038765572732495

Epoch: 5| Step: 6
Training loss: 1.1040583848953247
Validation loss: 2.0113065204312726

Epoch: 5| Step: 7
Training loss: 1.3243128061294556
Validation loss: 1.9794777016485892

Epoch: 5| Step: 8
Training loss: 0.9866057634353638
Validation loss: 1.956247583512337

Epoch: 5| Step: 9
Training loss: 1.7522751092910767
Validation loss: 1.925129311059111

Epoch: 5| Step: 10
Training loss: 0.8854009509086609
Validation loss: 1.9150184072473997

Epoch: 268| Step: 0
Training loss: 1.0547294616699219
Validation loss: 1.8981270687554472

Epoch: 5| Step: 1
Training loss: 1.0368562936782837
Validation loss: 1.9109062251224314

Epoch: 5| Step: 2
Training loss: 1.07732093334198
Validation loss: 1.91901514222545

Epoch: 5| Step: 3
Training loss: 1.2781544923782349
Validation loss: 1.9241579835132887

Epoch: 5| Step: 4
Training loss: 0.8466137647628784
Validation loss: 1.948797365670563

Epoch: 5| Step: 5
Training loss: 1.1682913303375244
Validation loss: 2.0092387763402795

Epoch: 5| Step: 6
Training loss: 1.4873993396759033
Validation loss: 2.02030179321125

Epoch: 5| Step: 7
Training loss: 1.0953609943389893
Validation loss: 2.0204756234281804

Epoch: 5| Step: 8
Training loss: 1.0609486103057861
Validation loss: 2.016806810132919

Epoch: 5| Step: 9
Training loss: 0.9906150698661804
Validation loss: 2.064596470966134

Epoch: 5| Step: 10
Training loss: 1.4623007774353027
Validation loss: 2.0824093229027203

Epoch: 269| Step: 0
Training loss: 0.8801580667495728
Validation loss: 2.0705598246666694

Epoch: 5| Step: 1
Training loss: 1.0387274026870728
Validation loss: 2.0464592287617345

Epoch: 5| Step: 2
Training loss: 1.5522911548614502
Validation loss: 2.001557839814053

Epoch: 5| Step: 3
Training loss: 1.429896354675293
Validation loss: 1.9813451856695197

Epoch: 5| Step: 4
Training loss: 1.303147315979004
Validation loss: 1.9274577915027578

Epoch: 5| Step: 5
Training loss: 1.2760623693466187
Validation loss: 1.9232533080603487

Epoch: 5| Step: 6
Training loss: 1.1467236280441284
Validation loss: 1.8897578062549714

Epoch: 5| Step: 7
Training loss: 0.8291984796524048
Validation loss: 1.8667271009055517

Epoch: 5| Step: 8
Training loss: 1.1037548780441284
Validation loss: 1.8653538778264036

Epoch: 5| Step: 9
Training loss: 1.0547335147857666
Validation loss: 1.8728461880837717

Epoch: 5| Step: 10
Training loss: 0.8131136298179626
Validation loss: 1.8539402536166611

Epoch: 270| Step: 0
Training loss: 1.019446611404419
Validation loss: 1.9031005444065217

Epoch: 5| Step: 1
Training loss: 1.600775957107544
Validation loss: 1.9342296687505578

Epoch: 5| Step: 2
Training loss: 0.8690244555473328
Validation loss: 1.9404747857842395

Epoch: 5| Step: 3
Training loss: 1.0433740615844727
Validation loss: 1.9832445242071663

Epoch: 5| Step: 4
Training loss: 1.110275149345398
Validation loss: 2.008771324670443

Epoch: 5| Step: 5
Training loss: 1.1088335514068604
Validation loss: 1.992152854960452

Epoch: 5| Step: 6
Training loss: 1.022291898727417
Validation loss: 2.009359831451088

Epoch: 5| Step: 7
Training loss: 0.9547781944274902
Validation loss: 2.0275293063091975

Epoch: 5| Step: 8
Training loss: 1.1050713062286377
Validation loss: 2.031193340978315

Epoch: 5| Step: 9
Training loss: 1.1806329488754272
Validation loss: 2.0220724408344557

Epoch: 5| Step: 10
Training loss: 0.9679856896400452
Validation loss: 1.9699857952774211

Epoch: 271| Step: 0
Training loss: 1.247087001800537
Validation loss: 1.954167563428161

Epoch: 5| Step: 1
Training loss: 1.0470871925354004
Validation loss: 1.9425817292223695

Epoch: 5| Step: 2
Training loss: 1.1409623622894287
Validation loss: 1.917756970210742

Epoch: 5| Step: 3
Training loss: 0.7640835046768188
Validation loss: 1.9022068490264237

Epoch: 5| Step: 4
Training loss: 0.5674358606338501
Validation loss: 1.8892089346403718

Epoch: 5| Step: 5
Training loss: 1.3880075216293335
Validation loss: 1.900759079123056

Epoch: 5| Step: 6
Training loss: 1.2728849649429321
Validation loss: 1.9018814230477938

Epoch: 5| Step: 7
Training loss: 1.1468479633331299
Validation loss: 1.9082981540310768

Epoch: 5| Step: 8
Training loss: 0.8103585243225098
Validation loss: 1.9455891642519223

Epoch: 5| Step: 9
Training loss: 1.3709909915924072
Validation loss: 1.9827992621288504

Epoch: 5| Step: 10
Training loss: 1.0613352060317993
Validation loss: 1.9650797715751074

Epoch: 272| Step: 0
Training loss: 1.5479347705841064
Validation loss: 1.9871326646497172

Epoch: 5| Step: 1
Training loss: 1.8184349536895752
Validation loss: 1.9822352868254467

Epoch: 5| Step: 2
Training loss: 0.9113714098930359
Validation loss: 1.9969901807846562

Epoch: 5| Step: 3
Training loss: 1.1951904296875
Validation loss: 1.9619000957858177

Epoch: 5| Step: 4
Training loss: 0.8162072896957397
Validation loss: 1.9661086195258684

Epoch: 5| Step: 5
Training loss: 1.0349199771881104
Validation loss: 1.949225438538418

Epoch: 5| Step: 6
Training loss: 1.020275592803955
Validation loss: 1.9425258892838673

Epoch: 5| Step: 7
Training loss: 0.7933841943740845
Validation loss: 1.9422009196332706

Epoch: 5| Step: 8
Training loss: 1.0876845121383667
Validation loss: 1.898018539592784

Epoch: 5| Step: 9
Training loss: 0.7694071531295776
Validation loss: 1.8819532612318635

Epoch: 5| Step: 10
Training loss: 0.7213876247406006
Validation loss: 1.8915362223502128

Epoch: 273| Step: 0
Training loss: 0.7956554889678955
Validation loss: 1.9087985382285169

Epoch: 5| Step: 1
Training loss: 1.2803571224212646
Validation loss: 1.9080987668806506

Epoch: 5| Step: 2
Training loss: 0.8144358396530151
Validation loss: 1.91782090228091

Epoch: 5| Step: 3
Training loss: 1.592812180519104
Validation loss: 1.915489899214878

Epoch: 5| Step: 4
Training loss: 0.767259955406189
Validation loss: 1.9169019973406227

Epoch: 5| Step: 5
Training loss: 1.270653247833252
Validation loss: 1.9411653113621536

Epoch: 5| Step: 6
Training loss: 1.244036316871643
Validation loss: 1.9237432659313243

Epoch: 5| Step: 7
Training loss: 0.9740074872970581
Validation loss: 1.9637384542854883

Epoch: 5| Step: 8
Training loss: 0.7157761454582214
Validation loss: 1.9832390457071283

Epoch: 5| Step: 9
Training loss: 1.2186839580535889
Validation loss: 1.954704951214534

Epoch: 5| Step: 10
Training loss: 0.9545378684997559
Validation loss: 1.9516890459163214

Epoch: 274| Step: 0
Training loss: 1.3508317470550537
Validation loss: 1.939435794789304

Epoch: 5| Step: 1
Training loss: 1.2930177450180054
Validation loss: 1.9354579794791438

Epoch: 5| Step: 2
Training loss: 0.40504321455955505
Validation loss: 1.947186819968685

Epoch: 5| Step: 3
Training loss: 1.2251662015914917
Validation loss: 1.9516224681690175

Epoch: 5| Step: 4
Training loss: 0.9066904783248901
Validation loss: 1.9583463758550665

Epoch: 5| Step: 5
Training loss: 0.6578525900840759
Validation loss: 1.9689476143929265

Epoch: 5| Step: 6
Training loss: 1.2366129159927368
Validation loss: 1.9418341395675496

Epoch: 5| Step: 7
Training loss: 1.1201814413070679
Validation loss: 1.9341335322267266

Epoch: 5| Step: 8
Training loss: 1.202702283859253
Validation loss: 1.9090767496375627

Epoch: 5| Step: 9
Training loss: 1.3491599559783936
Validation loss: 1.9074597294612596

Epoch: 5| Step: 10
Training loss: 0.6930162310600281
Validation loss: 1.9006906786272604

Epoch: 275| Step: 0
Training loss: 0.9908404350280762
Validation loss: 1.8912212207753172

Epoch: 5| Step: 1
Training loss: 1.2178642749786377
Validation loss: 1.889695300850817

Epoch: 5| Step: 2
Training loss: 1.2765772342681885
Validation loss: 1.8839924130388486

Epoch: 5| Step: 3
Training loss: 1.2125999927520752
Validation loss: 1.9222922478952715

Epoch: 5| Step: 4
Training loss: 1.1603853702545166
Validation loss: 1.9520165753620926

Epoch: 5| Step: 5
Training loss: 1.2157098054885864
Validation loss: 1.9783940879247521

Epoch: 5| Step: 6
Training loss: 1.0677770376205444
Validation loss: 1.9944475261113976

Epoch: 5| Step: 7
Training loss: 0.7262071967124939
Validation loss: 2.0085660103828675

Epoch: 5| Step: 8
Training loss: 0.8479403257369995
Validation loss: 1.995826216154201

Epoch: 5| Step: 9
Training loss: 0.7299292683601379
Validation loss: 1.955392825988031

Epoch: 5| Step: 10
Training loss: 0.8607709407806396
Validation loss: 1.9070034180918047

Epoch: 276| Step: 0
Training loss: 1.1334445476531982
Validation loss: 1.8974160199524255

Epoch: 5| Step: 1
Training loss: 1.0304667949676514
Validation loss: 1.9162999814556492

Epoch: 5| Step: 2
Training loss: 0.9569199681282043
Validation loss: 1.920261558666024

Epoch: 5| Step: 3
Training loss: 1.0016664266586304
Validation loss: 1.9111555007196241

Epoch: 5| Step: 4
Training loss: 1.3436964750289917
Validation loss: 1.9362003931435205

Epoch: 5| Step: 5
Training loss: 1.0352498292922974
Validation loss: 1.926271028416131

Epoch: 5| Step: 6
Training loss: 1.0081504583358765
Validation loss: 1.9332246293303788

Epoch: 5| Step: 7
Training loss: 1.3523168563842773
Validation loss: 1.940551725766992

Epoch: 5| Step: 8
Training loss: 1.1641231775283813
Validation loss: 1.9607943693796794

Epoch: 5| Step: 9
Training loss: 0.6784788370132446
Validation loss: 1.966629897394488

Epoch: 5| Step: 10
Training loss: 0.9327131509780884
Validation loss: 1.9499973379155642

Epoch: 277| Step: 0
Training loss: 1.0590744018554688
Validation loss: 1.987985977562525

Epoch: 5| Step: 1
Training loss: 1.184164047241211
Validation loss: 1.9928172788312357

Epoch: 5| Step: 2
Training loss: 0.9893699884414673
Validation loss: 1.9726983680520007

Epoch: 5| Step: 3
Training loss: 1.0392911434173584
Validation loss: 1.95225949441233

Epoch: 5| Step: 4
Training loss: 1.0569406747817993
Validation loss: 1.9290508685573455

Epoch: 5| Step: 5
Training loss: 1.172829508781433
Validation loss: 1.921173148257758

Epoch: 5| Step: 6
Training loss: 1.1979560852050781
Validation loss: 1.9465918592227403

Epoch: 5| Step: 7
Training loss: 0.9991214871406555
Validation loss: 1.9548583312701153

Epoch: 5| Step: 8
Training loss: 1.0338331460952759
Validation loss: 1.9676644122728737

Epoch: 5| Step: 9
Training loss: 0.703528642654419
Validation loss: 1.9845371951339066

Epoch: 5| Step: 10
Training loss: 0.9360058903694153
Validation loss: 1.9823130869096326

Epoch: 278| Step: 0
Training loss: 0.7475194931030273
Validation loss: 1.9524363984343827

Epoch: 5| Step: 1
Training loss: 0.9633113145828247
Validation loss: 1.9381222340368456

Epoch: 5| Step: 2
Training loss: 1.200360894203186
Validation loss: 1.8968816700802054

Epoch: 5| Step: 3
Training loss: 1.2447636127471924
Validation loss: 1.875820093257453

Epoch: 5| Step: 4
Training loss: 0.6718689203262329
Validation loss: 1.878174066543579

Epoch: 5| Step: 5
Training loss: 0.8600069880485535
Validation loss: 1.9013755039502216

Epoch: 5| Step: 6
Training loss: 1.098319411277771
Validation loss: 1.9085567920438704

Epoch: 5| Step: 7
Training loss: 1.5858852863311768
Validation loss: 1.9248074536682458

Epoch: 5| Step: 8
Training loss: 0.7372893691062927
Validation loss: 1.9264324172850578

Epoch: 5| Step: 9
Training loss: 1.0524742603302002
Validation loss: 1.9294956602076048

Epoch: 5| Step: 10
Training loss: 0.8787323236465454
Validation loss: 1.9438421392953524

Epoch: 279| Step: 0
Training loss: 0.8754822015762329
Validation loss: 1.968705859235538

Epoch: 5| Step: 1
Training loss: 0.8765941858291626
Validation loss: 1.9473745669088056

Epoch: 5| Step: 2
Training loss: 0.9047688245773315
Validation loss: 1.902941167995494

Epoch: 5| Step: 3
Training loss: 1.1549463272094727
Validation loss: 1.9177856278675858

Epoch: 5| Step: 4
Training loss: 1.1101949214935303
Validation loss: 1.897512892241119

Epoch: 5| Step: 5
Training loss: 0.9597465395927429
Validation loss: 1.8790894298143284

Epoch: 5| Step: 6
Training loss: 1.2462432384490967
Validation loss: 1.8645634164092362

Epoch: 5| Step: 7
Training loss: 0.8321777582168579
Validation loss: 1.8586161341718448

Epoch: 5| Step: 8
Training loss: 0.8594080209732056
Validation loss: 1.8794960591100878

Epoch: 5| Step: 9
Training loss: 0.6890088319778442
Validation loss: 1.917161641582366

Epoch: 5| Step: 10
Training loss: 1.510002851486206
Validation loss: 1.9215715316034132

Epoch: 280| Step: 0
Training loss: 1.1198809146881104
Validation loss: 1.9732673007954833

Epoch: 5| Step: 1
Training loss: 1.0449820756912231
Validation loss: 1.9584997264287805

Epoch: 5| Step: 2
Training loss: 1.0420825481414795
Validation loss: 1.9593215398890997

Epoch: 5| Step: 3
Training loss: 1.218834638595581
Validation loss: 1.9594206681815527

Epoch: 5| Step: 4
Training loss: 0.7484407424926758
Validation loss: 1.9326900038667905

Epoch: 5| Step: 5
Training loss: 1.0613890886306763
Validation loss: 1.9246867267034387

Epoch: 5| Step: 6
Training loss: 0.9730243682861328
Validation loss: 1.8873864040579846

Epoch: 5| Step: 7
Training loss: 0.9798625111579895
Validation loss: 1.8608028696429344

Epoch: 5| Step: 8
Training loss: 0.8102733492851257
Validation loss: 1.8802796268975863

Epoch: 5| Step: 9
Training loss: 1.027721643447876
Validation loss: 1.8660052258481261

Epoch: 5| Step: 10
Training loss: 0.7644404172897339
Validation loss: 1.8532401874501219

Epoch: 281| Step: 0
Training loss: 0.865803599357605
Validation loss: 1.8562366193340671

Epoch: 5| Step: 1
Training loss: 0.6349460482597351
Validation loss: 1.8784480248728106

Epoch: 5| Step: 2
Training loss: 0.7528390288352966
Validation loss: 1.907142564814578

Epoch: 5| Step: 3
Training loss: 1.1214133501052856
Validation loss: 1.9221553520489765

Epoch: 5| Step: 4
Training loss: 1.1200498342514038
Validation loss: 1.9658324013474167

Epoch: 5| Step: 5
Training loss: 1.219190001487732
Validation loss: 1.9598619104713522

Epoch: 5| Step: 6
Training loss: 1.020997405052185
Validation loss: 1.9452820439492502

Epoch: 5| Step: 7
Training loss: 0.9060598611831665
Validation loss: 1.9312414546166696

Epoch: 5| Step: 8
Training loss: 0.7657434344291687
Validation loss: 1.928499578147806

Epoch: 5| Step: 9
Training loss: 1.1960580348968506
Validation loss: 1.9191871048301778

Epoch: 5| Step: 10
Training loss: 1.083783745765686
Validation loss: 1.9281718910381358

Epoch: 282| Step: 0
Training loss: 0.9221822023391724
Validation loss: 1.9110801181485575

Epoch: 5| Step: 1
Training loss: 0.9977504014968872
Validation loss: 1.9473634150720411

Epoch: 5| Step: 2
Training loss: 1.0615473985671997
Validation loss: 1.9581635523867864

Epoch: 5| Step: 3
Training loss: 0.8671249151229858
Validation loss: 1.9852319878916587

Epoch: 5| Step: 4
Training loss: 1.0596551895141602
Validation loss: 1.9832995476261261

Epoch: 5| Step: 5
Training loss: 1.050147294998169
Validation loss: 2.003336619305354

Epoch: 5| Step: 6
Training loss: 1.1816108226776123
Validation loss: 2.030553585739546

Epoch: 5| Step: 7
Training loss: 0.7224575877189636
Validation loss: 2.036241988981924

Epoch: 5| Step: 8
Training loss: 1.2580373287200928
Validation loss: 2.002635182872895

Epoch: 5| Step: 9
Training loss: 0.5728062987327576
Validation loss: 1.9522047991393714

Epoch: 5| Step: 10
Training loss: 1.0298088788986206
Validation loss: 1.8942735310523742

Epoch: 283| Step: 0
Training loss: 0.7669445276260376
Validation loss: 1.8413963010234218

Epoch: 5| Step: 1
Training loss: 1.308941125869751
Validation loss: 1.8292911821796047

Epoch: 5| Step: 2
Training loss: 0.8949610590934753
Validation loss: 1.8297772087076658

Epoch: 5| Step: 3
Training loss: 0.8766340017318726
Validation loss: 1.7990127917258971

Epoch: 5| Step: 4
Training loss: 1.4880895614624023
Validation loss: 1.8187590132477462

Epoch: 5| Step: 5
Training loss: 1.4512760639190674
Validation loss: 1.8357514796718475

Epoch: 5| Step: 6
Training loss: 0.5478703379631042
Validation loss: 1.8433508052620837

Epoch: 5| Step: 7
Training loss: 1.6214468479156494
Validation loss: 1.8530237828531573

Epoch: 5| Step: 8
Training loss: 0.7408913373947144
Validation loss: 1.8948973545464136

Epoch: 5| Step: 9
Training loss: 0.6414968967437744
Validation loss: 1.9205980147084882

Epoch: 5| Step: 10
Training loss: 0.5557874441146851
Validation loss: 1.9383022964641612

Epoch: 284| Step: 0
Training loss: 1.168614149093628
Validation loss: 1.9788389628933323

Epoch: 5| Step: 1
Training loss: 1.346522569656372
Validation loss: 1.996040331420078

Epoch: 5| Step: 2
Training loss: 1.2567075490951538
Validation loss: 1.9712095747711837

Epoch: 5| Step: 3
Training loss: 0.7165274620056152
Validation loss: 1.9216105373956824

Epoch: 5| Step: 4
Training loss: 1.1967182159423828
Validation loss: 1.8993584238072878

Epoch: 5| Step: 5
Training loss: 0.5679106116294861
Validation loss: 1.9006425039742583

Epoch: 5| Step: 6
Training loss: 0.8194851875305176
Validation loss: 1.872368142169009

Epoch: 5| Step: 7
Training loss: 1.299821138381958
Validation loss: 1.8042681960649387

Epoch: 5| Step: 8
Training loss: 0.7493959665298462
Validation loss: 1.8007996723216066

Epoch: 5| Step: 9
Training loss: 0.738486111164093
Validation loss: 1.7817878825690157

Epoch: 5| Step: 10
Training loss: 0.9047892689704895
Validation loss: 1.8193697903745918

Epoch: 285| Step: 0
Training loss: 0.9231049418449402
Validation loss: 1.8605747568991877

Epoch: 5| Step: 1
Training loss: 1.2979412078857422
Validation loss: 1.8834147376398886

Epoch: 5| Step: 2
Training loss: 1.1175318956375122
Validation loss: 1.9508568779114754

Epoch: 5| Step: 3
Training loss: 1.2710850238800049
Validation loss: 2.0285133277216265

Epoch: 5| Step: 4
Training loss: 0.8117728233337402
Validation loss: 2.046174357014318

Epoch: 5| Step: 5
Training loss: 0.8428471684455872
Validation loss: 2.0377435812386135

Epoch: 5| Step: 6
Training loss: 0.6451327204704285
Validation loss: 2.0081218237517984

Epoch: 5| Step: 7
Training loss: 1.2547305822372437
Validation loss: 1.9535857733859812

Epoch: 5| Step: 8
Training loss: 0.5459620952606201
Validation loss: 1.9164539050030451

Epoch: 5| Step: 9
Training loss: 0.7472885847091675
Validation loss: 1.8553045821446243

Epoch: 5| Step: 10
Training loss: 1.2446365356445312
Validation loss: 1.8179573038572907

Epoch: 286| Step: 0
Training loss: 1.365561604499817
Validation loss: 1.8322324714353007

Epoch: 5| Step: 1
Training loss: 0.8233437538146973
Validation loss: 1.8212449601901475

Epoch: 5| Step: 2
Training loss: 0.8849371075630188
Validation loss: 1.80899727600877

Epoch: 5| Step: 3
Training loss: 0.77892005443573
Validation loss: 1.8159736484609625

Epoch: 5| Step: 4
Training loss: 0.7166299819946289
Validation loss: 1.8343450741101337

Epoch: 5| Step: 5
Training loss: 1.1180403232574463
Validation loss: 1.8752976232959377

Epoch: 5| Step: 6
Training loss: 1.0668715238571167
Validation loss: 1.8531827567726054

Epoch: 5| Step: 7
Training loss: 0.8989654779434204
Validation loss: 1.8892004412989463

Epoch: 5| Step: 8
Training loss: 0.7924074530601501
Validation loss: 1.900258477016162

Epoch: 5| Step: 9
Training loss: 0.9805911779403687
Validation loss: 1.9177785535012521

Epoch: 5| Step: 10
Training loss: 0.8007694482803345
Validation loss: 1.9286412705657303

Epoch: 287| Step: 0
Training loss: 0.8223600387573242
Validation loss: 1.9303573241797827

Epoch: 5| Step: 1
Training loss: 1.2187751531600952
Validation loss: 1.9283657740521174

Epoch: 5| Step: 2
Training loss: 1.0053558349609375
Validation loss: 1.92113330030954

Epoch: 5| Step: 3
Training loss: 0.8392318487167358
Validation loss: 1.908939003944397

Epoch: 5| Step: 4
Training loss: 0.7575055956840515
Validation loss: 1.8892421030229138

Epoch: 5| Step: 5
Training loss: 0.8481928110122681
Validation loss: 1.8726468509243381

Epoch: 5| Step: 6
Training loss: 1.010892629623413
Validation loss: 1.8446283545545352

Epoch: 5| Step: 7
Training loss: 0.49574193358421326
Validation loss: 1.8450174306028633

Epoch: 5| Step: 8
Training loss: 0.9442899823188782
Validation loss: 1.8530997819797967

Epoch: 5| Step: 9
Training loss: 1.0334606170654297
Validation loss: 1.870087803051036

Epoch: 5| Step: 10
Training loss: 1.0389128923416138
Validation loss: 1.857981228059338

Epoch: 288| Step: 0
Training loss: 0.7676200866699219
Validation loss: 1.8814909329978369

Epoch: 5| Step: 1
Training loss: 0.8175274133682251
Validation loss: 1.8813463218750492

Epoch: 5| Step: 2
Training loss: 0.8987641334533691
Validation loss: 1.8958227172974618

Epoch: 5| Step: 3
Training loss: 1.0084465742111206
Validation loss: 1.9254349380411127

Epoch: 5| Step: 4
Training loss: 0.8326841592788696
Validation loss: 1.8950325981263192

Epoch: 5| Step: 5
Training loss: 0.8212559819221497
Validation loss: 1.893052831772835

Epoch: 5| Step: 6
Training loss: 1.0859944820404053
Validation loss: 1.8465323268726308

Epoch: 5| Step: 7
Training loss: 0.9594701528549194
Validation loss: 1.8029792244716356

Epoch: 5| Step: 8
Training loss: 0.638099193572998
Validation loss: 1.810955137334844

Epoch: 5| Step: 9
Training loss: 1.4889686107635498
Validation loss: 1.7960398094628447

Epoch: 5| Step: 10
Training loss: 0.7938361167907715
Validation loss: 1.8305937256864322

Epoch: 289| Step: 0
Training loss: 1.05560302734375
Validation loss: 1.8111502906327606

Epoch: 5| Step: 1
Training loss: 1.0604113340377808
Validation loss: 1.805488440298265

Epoch: 5| Step: 2
Training loss: 0.9059855341911316
Validation loss: 1.8063655745598577

Epoch: 5| Step: 3
Training loss: 0.9916467666625977
Validation loss: 1.820669198548922

Epoch: 5| Step: 4
Training loss: 0.7434277534484863
Validation loss: 1.8541173306844567

Epoch: 5| Step: 5
Training loss: 0.5870822668075562
Validation loss: 1.8656994745295534

Epoch: 5| Step: 6
Training loss: 0.8551519513130188
Validation loss: 1.90000331530007

Epoch: 5| Step: 7
Training loss: 0.7145003080368042
Validation loss: 1.870987037176727

Epoch: 5| Step: 8
Training loss: 0.963901162147522
Validation loss: 1.8549790497749084

Epoch: 5| Step: 9
Training loss: 1.1557166576385498
Validation loss: 1.8561838083369757

Epoch: 5| Step: 10
Training loss: 0.9801430702209473
Validation loss: 1.8549067999726983

Epoch: 290| Step: 0
Training loss: 1.3623355627059937
Validation loss: 1.877723551565601

Epoch: 5| Step: 1
Training loss: 0.6690129041671753
Validation loss: 1.8595634762958815

Epoch: 5| Step: 2
Training loss: 1.0389258861541748
Validation loss: 1.871284334890304

Epoch: 5| Step: 3
Training loss: 0.8748674392700195
Validation loss: 1.8661271833604383

Epoch: 5| Step: 4
Training loss: 1.2325108051300049
Validation loss: 1.9162479805689987

Epoch: 5| Step: 5
Training loss: 0.7504027485847473
Validation loss: 1.933403903438199

Epoch: 5| Step: 6
Training loss: 0.7717092633247375
Validation loss: 1.939972093028407

Epoch: 5| Step: 7
Training loss: 0.8823598623275757
Validation loss: 1.899880427186207

Epoch: 5| Step: 8
Training loss: 0.8693094253540039
Validation loss: 1.8848780073145384

Epoch: 5| Step: 9
Training loss: 0.6380289793014526
Validation loss: 1.8688971957852762

Epoch: 5| Step: 10
Training loss: 0.9094308018684387
Validation loss: 1.8514434086379183

Epoch: 291| Step: 0
Training loss: 1.2460310459136963
Validation loss: 1.852195147545107

Epoch: 5| Step: 1
Training loss: 0.9168118238449097
Validation loss: 1.831242420340097

Epoch: 5| Step: 2
Training loss: 0.9660603404045105
Validation loss: 1.8571265551351732

Epoch: 5| Step: 3
Training loss: 0.824653148651123
Validation loss: 1.875240042645444

Epoch: 5| Step: 4
Training loss: 0.8505877256393433
Validation loss: 1.8718599632222166

Epoch: 5| Step: 5
Training loss: 0.6241737604141235
Validation loss: 1.8993016263490081

Epoch: 5| Step: 6
Training loss: 1.0419642925262451
Validation loss: 1.8469546161672121

Epoch: 5| Step: 7
Training loss: 0.9398676753044128
Validation loss: 1.8690720206947737

Epoch: 5| Step: 8
Training loss: 0.991358757019043
Validation loss: 1.8458928959344023

Epoch: 5| Step: 9
Training loss: 0.6175540089607239
Validation loss: 1.8367191642843268

Epoch: 5| Step: 10
Training loss: 0.655775249004364
Validation loss: 1.8196703939027683

Epoch: 292| Step: 0
Training loss: 0.8817853927612305
Validation loss: 1.8416253097595707

Epoch: 5| Step: 1
Training loss: 0.6223896741867065
Validation loss: 1.8560705748937463

Epoch: 5| Step: 2
Training loss: 0.8164981007575989
Validation loss: 1.8607285932828022

Epoch: 5| Step: 3
Training loss: 0.7680407762527466
Validation loss: 1.9277746587671258

Epoch: 5| Step: 4
Training loss: 1.3297350406646729
Validation loss: 1.9759308535565612

Epoch: 5| Step: 5
Training loss: 1.2201108932495117
Validation loss: 1.960465984959756

Epoch: 5| Step: 6
Training loss: 0.9285955429077148
Validation loss: 1.934623565725101

Epoch: 5| Step: 7
Training loss: 0.8608361482620239
Validation loss: 1.9057842877603346

Epoch: 5| Step: 8
Training loss: 0.594862699508667
Validation loss: 1.8835689047331452

Epoch: 5| Step: 9
Training loss: 1.2602133750915527
Validation loss: 1.843963138518795

Epoch: 5| Step: 10
Training loss: 0.31715965270996094
Validation loss: 1.8416336198006906

Epoch: 293| Step: 0
Training loss: 0.8330008387565613
Validation loss: 1.827548820485351

Epoch: 5| Step: 1
Training loss: 0.3115929663181305
Validation loss: 1.8473854885306409

Epoch: 5| Step: 2
Training loss: 1.02560293674469
Validation loss: 1.8258677708205355

Epoch: 5| Step: 3
Training loss: 1.1037788391113281
Validation loss: 1.8138632146261071

Epoch: 5| Step: 4
Training loss: 1.1986178159713745
Validation loss: 1.8424194038555186

Epoch: 5| Step: 5
Training loss: 1.2490978240966797
Validation loss: 1.8068950176239014

Epoch: 5| Step: 6
Training loss: 1.2489891052246094
Validation loss: 1.8223110591211626

Epoch: 5| Step: 7
Training loss: 0.8742431402206421
Validation loss: 1.8187571225627777

Epoch: 5| Step: 8
Training loss: 0.899311900138855
Validation loss: 1.824959986953325

Epoch: 5| Step: 9
Training loss: 0.3941554129123688
Validation loss: 1.8547857999801636

Epoch: 5| Step: 10
Training loss: 0.513508677482605
Validation loss: 1.9098103174599268

Epoch: 294| Step: 0
Training loss: 0.9812651872634888
Validation loss: 1.9159806210507628

Epoch: 5| Step: 1
Training loss: 0.5927825570106506
Validation loss: 1.9261466508270593

Epoch: 5| Step: 2
Training loss: 0.9169338345527649
Validation loss: 1.9337120261243594

Epoch: 5| Step: 3
Training loss: 1.0875061750411987
Validation loss: 1.9107154312954153

Epoch: 5| Step: 4
Training loss: 1.208950161933899
Validation loss: 1.8840264530592068

Epoch: 5| Step: 5
Training loss: 0.6904168725013733
Validation loss: 1.8763599767479846

Epoch: 5| Step: 6
Training loss: 0.8291007280349731
Validation loss: 1.8526083051517446

Epoch: 5| Step: 7
Training loss: 0.88128662109375
Validation loss: 1.833484685549172

Epoch: 5| Step: 8
Training loss: 0.6963889598846436
Validation loss: 1.8313116104372087

Epoch: 5| Step: 9
Training loss: 1.0176483392715454
Validation loss: 1.805484410255186

Epoch: 5| Step: 10
Training loss: 0.4256637692451477
Validation loss: 1.8176247253212878

Epoch: 295| Step: 0
Training loss: 0.9386580586433411
Validation loss: 1.8438935972029162

Epoch: 5| Step: 1
Training loss: 0.7082063555717468
Validation loss: 1.8787232957860476

Epoch: 5| Step: 2
Training loss: 0.9887590408325195
Validation loss: 1.9276515963257

Epoch: 5| Step: 3
Training loss: 0.8039587140083313
Validation loss: 1.927819126395769

Epoch: 5| Step: 4
Training loss: 0.9152644872665405
Validation loss: 1.9539044646806614

Epoch: 5| Step: 5
Training loss: 0.6321457624435425
Validation loss: 1.945580961883709

Epoch: 5| Step: 6
Training loss: 0.657882809638977
Validation loss: 1.9353001476615987

Epoch: 5| Step: 7
Training loss: 0.8056238889694214
Validation loss: 1.8999729387221798

Epoch: 5| Step: 8
Training loss: 0.8342338800430298
Validation loss: 1.8996862262807868

Epoch: 5| Step: 9
Training loss: 0.951093852519989
Validation loss: 1.894976031395697

Epoch: 5| Step: 10
Training loss: 1.0357917547225952
Validation loss: 1.8809463054903093

Epoch: 296| Step: 0
Training loss: 0.9712160229682922
Validation loss: 1.8989315263686641

Epoch: 5| Step: 1
Training loss: 0.7404673099517822
Validation loss: 1.88206567687373

Epoch: 5| Step: 2
Training loss: 0.9140077829360962
Validation loss: 1.8771124373200119

Epoch: 5| Step: 3
Training loss: 0.5505778193473816
Validation loss: 1.8813136623751732

Epoch: 5| Step: 4
Training loss: 0.7333146333694458
Validation loss: 1.8611289788317937

Epoch: 5| Step: 5
Training loss: 1.1152172088623047
Validation loss: 1.8342807626211515

Epoch: 5| Step: 6
Training loss: 0.7432772517204285
Validation loss: 1.8374290850854689

Epoch: 5| Step: 7
Training loss: 0.6749335527420044
Validation loss: 1.8591039911393197

Epoch: 5| Step: 8
Training loss: 1.0242875814437866
Validation loss: 1.867663319392871

Epoch: 5| Step: 9
Training loss: 0.899664580821991
Validation loss: 1.9033212533561132

Epoch: 5| Step: 10
Training loss: 0.7364968061447144
Validation loss: 1.9178164902553763

Epoch: 297| Step: 0
Training loss: 0.7649049162864685
Validation loss: 1.9159685847579793

Epoch: 5| Step: 1
Training loss: 1.1018010377883911
Validation loss: 1.879378713587279

Epoch: 5| Step: 2
Training loss: 0.6196077466011047
Validation loss: 1.8559000107549852

Epoch: 5| Step: 3
Training loss: 0.9897493124008179
Validation loss: 1.8432643426361905

Epoch: 5| Step: 4
Training loss: 0.6809445023536682
Validation loss: 1.828182230713547

Epoch: 5| Step: 5
Training loss: 0.6715243458747864
Validation loss: 1.8666724005053121

Epoch: 5| Step: 6
Training loss: 1.0689817667007446
Validation loss: 1.8998666963269633

Epoch: 5| Step: 7
Training loss: 0.4501602053642273
Validation loss: 1.921190224668031

Epoch: 5| Step: 8
Training loss: 0.8073643445968628
Validation loss: 1.9101732315555695

Epoch: 5| Step: 9
Training loss: 0.9034937620162964
Validation loss: 1.8946057558059692

Epoch: 5| Step: 10
Training loss: 0.9555314183235168
Validation loss: 1.8962274828264791

Epoch: 298| Step: 0
Training loss: 1.3909177780151367
Validation loss: 1.8802046788636075

Epoch: 5| Step: 1
Training loss: 0.7889497876167297
Validation loss: 1.8604891325837822

Epoch: 5| Step: 2
Training loss: 0.6353944540023804
Validation loss: 1.8927740255991619

Epoch: 5| Step: 3
Training loss: 0.7443612217903137
Validation loss: 1.8987662125659246

Epoch: 5| Step: 4
Training loss: 0.46084117889404297
Validation loss: 1.9090693176433604

Epoch: 5| Step: 5
Training loss: 0.5247651934623718
Validation loss: 1.959053139532766

Epoch: 5| Step: 6
Training loss: 0.9994173049926758
Validation loss: 1.9548569443405315

Epoch: 5| Step: 7
Training loss: 0.7491751909255981
Validation loss: 1.956893474824967

Epoch: 5| Step: 8
Training loss: 0.858579158782959
Validation loss: 1.961706628081619

Epoch: 5| Step: 9
Training loss: 1.0209896564483643
Validation loss: 1.9463721603475592

Epoch: 5| Step: 10
Training loss: 0.6759296655654907
Validation loss: 1.9440312283013457

Epoch: 299| Step: 0
Training loss: 0.6375076174736023
Validation loss: 1.929606363337527

Epoch: 5| Step: 1
Training loss: 0.9161224365234375
Validation loss: 1.8804949919382732

Epoch: 5| Step: 2
Training loss: 1.2153517007827759
Validation loss: 1.866190477084088

Epoch: 5| Step: 3
Training loss: 0.6582252979278564
Validation loss: 1.8737434264152282

Epoch: 5| Step: 4
Training loss: 0.7121555805206299
Validation loss: 1.8561196916846818

Epoch: 5| Step: 5
Training loss: 0.753007709980011
Validation loss: 1.839149280260968

Epoch: 5| Step: 6
Training loss: 0.7507575750350952
Validation loss: 1.8516960195315781

Epoch: 5| Step: 7
Training loss: 0.9759575128555298
Validation loss: 1.8311090212996288

Epoch: 5| Step: 8
Training loss: 0.6051914095878601
Validation loss: 1.8152388039455618

Epoch: 5| Step: 9
Training loss: 0.7038487792015076
Validation loss: 1.8227906432203067

Epoch: 5| Step: 10
Training loss: 0.6728883981704712
Validation loss: 1.822858198355603

Epoch: 300| Step: 0
Training loss: 0.9438503384590149
Validation loss: 1.809294846750075

Epoch: 5| Step: 1
Training loss: 1.1742159128189087
Validation loss: 1.808423460170787

Epoch: 5| Step: 2
Training loss: 0.654204249382019
Validation loss: 1.826511433047633

Epoch: 5| Step: 3
Training loss: 0.5147129893302917
Validation loss: 1.824169692172799

Epoch: 5| Step: 4
Training loss: 0.6343238353729248
Validation loss: 1.8277871711279756

Epoch: 5| Step: 5
Training loss: 0.6402875781059265
Validation loss: 1.8755526875936857

Epoch: 5| Step: 6
Training loss: 0.759272575378418
Validation loss: 1.8783128799930695

Epoch: 5| Step: 7
Training loss: 0.8753630518913269
Validation loss: 1.867415246143136

Epoch: 5| Step: 8
Training loss: 0.9343510866165161
Validation loss: 1.8732958788512855

Epoch: 5| Step: 9
Training loss: 0.6484767198562622
Validation loss: 1.8478024121253722

Epoch: 5| Step: 10
Training loss: 0.9514727592468262
Validation loss: 1.8637979850974133

Epoch: 301| Step: 0
Training loss: 0.8009650111198425
Validation loss: 1.8644939520025765

Epoch: 5| Step: 1
Training loss: 0.8758667707443237
Validation loss: 1.8582430193501134

Epoch: 5| Step: 2
Training loss: 1.060476541519165
Validation loss: 1.8383274578279065

Epoch: 5| Step: 3
Training loss: 0.6560599207878113
Validation loss: 1.8542641209017845

Epoch: 5| Step: 4
Training loss: 0.7070247530937195
Validation loss: 1.8317657427121234

Epoch: 5| Step: 5
Training loss: 0.6097844839096069
Validation loss: 1.8382977759966286

Epoch: 5| Step: 6
Training loss: 0.633548378944397
Validation loss: 1.7904354820969284

Epoch: 5| Step: 7
Training loss: 0.9862254858016968
Validation loss: 1.7391072242490706

Epoch: 5| Step: 8
Training loss: 0.908072292804718
Validation loss: 1.7320687770843506

Epoch: 5| Step: 9
Training loss: 0.7865288853645325
Validation loss: 1.7306941657937982

Epoch: 5| Step: 10
Training loss: 0.9116535782814026
Validation loss: 1.7588131004764187

Epoch: 302| Step: 0
Training loss: 0.7708584070205688
Validation loss: 1.7509435210176694

Epoch: 5| Step: 1
Training loss: 0.5442900657653809
Validation loss: 1.7945190463014828

Epoch: 5| Step: 2
Training loss: 0.4743939936161041
Validation loss: 1.8301243999952912

Epoch: 5| Step: 3
Training loss: 0.6732536554336548
Validation loss: 1.8854574259891306

Epoch: 5| Step: 4
Training loss: 1.0574932098388672
Validation loss: 1.92733415736947

Epoch: 5| Step: 5
Training loss: 1.1367791891098022
Validation loss: 1.893622980322889

Epoch: 5| Step: 6
Training loss: 0.9942943453788757
Validation loss: 1.873329770180487

Epoch: 5| Step: 7
Training loss: 0.8265372514724731
Validation loss: 1.858353248206518

Epoch: 5| Step: 8
Training loss: 0.919867217540741
Validation loss: 1.8348043259753977

Epoch: 5| Step: 9
Training loss: 0.9831706881523132
Validation loss: 1.8072736955458117

Epoch: 5| Step: 10
Training loss: 0.4442300796508789
Validation loss: 1.8007322331910491

Epoch: 303| Step: 0
Training loss: 0.8479354977607727
Validation loss: 1.785808535032375

Epoch: 5| Step: 1
Training loss: 0.7324563264846802
Validation loss: 1.7623070081075032

Epoch: 5| Step: 2
Training loss: 1.0307238101959229
Validation loss: 1.7715854003865232

Epoch: 5| Step: 3
Training loss: 0.41111111640930176
Validation loss: 1.8057441967789845

Epoch: 5| Step: 4
Training loss: 0.4465722143650055
Validation loss: 1.8790985025385374

Epoch: 5| Step: 5
Training loss: 0.8324691653251648
Validation loss: 1.9153960007493214

Epoch: 5| Step: 6
Training loss: 0.5685436129570007
Validation loss: 1.9327863018999818

Epoch: 5| Step: 7
Training loss: 1.0101902484893799
Validation loss: 1.9525839564620808

Epoch: 5| Step: 8
Training loss: 1.143611192703247
Validation loss: 1.9410200657383088

Epoch: 5| Step: 9
Training loss: 0.5914682745933533
Validation loss: 1.9001762020972468

Epoch: 5| Step: 10
Training loss: 1.2859090566635132
Validation loss: 1.8758820692698162

Epoch: 304| Step: 0
Training loss: 0.6612393260002136
Validation loss: 1.849420093720959

Epoch: 5| Step: 1
Training loss: 0.6549869775772095
Validation loss: 1.8230008784160818

Epoch: 5| Step: 2
Training loss: 0.5653384327888489
Validation loss: 1.8040276970914615

Epoch: 5| Step: 3
Training loss: 1.0231825113296509
Validation loss: 1.7886751556909213

Epoch: 5| Step: 4
Training loss: 0.9980241656303406
Validation loss: 1.7871896861701884

Epoch: 5| Step: 5
Training loss: 0.7954086065292358
Validation loss: 1.7884474095477854

Epoch: 5| Step: 6
Training loss: 0.7559155821800232
Validation loss: 1.7877587451729724

Epoch: 5| Step: 7
Training loss: 1.0342596769332886
Validation loss: 1.814587426441972

Epoch: 5| Step: 8
Training loss: 0.5471997857093811
Validation loss: 1.8022412330873552

Epoch: 5| Step: 9
Training loss: 0.7995166778564453
Validation loss: 1.8188199291947067

Epoch: 5| Step: 10
Training loss: 0.8429319858551025
Validation loss: 1.821877839744732

Epoch: 305| Step: 0
Training loss: 0.8460155725479126
Validation loss: 1.889814502449446

Epoch: 5| Step: 1
Training loss: 0.6785784959793091
Validation loss: 1.9220666564920896

Epoch: 5| Step: 2
Training loss: 0.9012719392776489
Validation loss: 1.9068286483005812

Epoch: 5| Step: 3
Training loss: 0.7260164022445679
Validation loss: 1.9117870766629455

Epoch: 5| Step: 4
Training loss: 0.6440269947052002
Validation loss: 1.8801311036591888

Epoch: 5| Step: 5
Training loss: 0.6900877952575684
Validation loss: 1.8407472487418883

Epoch: 5| Step: 6
Training loss: 0.5940520167350769
Validation loss: 1.7984450388980169

Epoch: 5| Step: 7
Training loss: 1.1720459461212158
Validation loss: 1.8088680544207174

Epoch: 5| Step: 8
Training loss: 0.7150009274482727
Validation loss: 1.7856029836080407

Epoch: 5| Step: 9
Training loss: 0.9140308499336243
Validation loss: 1.767179008453123

Epoch: 5| Step: 10
Training loss: 0.6332153081893921
Validation loss: 1.7580064176231303

Epoch: 306| Step: 0
Training loss: 0.6617805361747742
Validation loss: 1.7600108244085824

Epoch: 5| Step: 1
Training loss: 0.7342627644538879
Validation loss: 1.7796498690882037

Epoch: 5| Step: 2
Training loss: 0.7519264221191406
Validation loss: 1.7707264679734425

Epoch: 5| Step: 3
Training loss: 0.5482521653175354
Validation loss: 1.8091066498910227

Epoch: 5| Step: 4
Training loss: 0.4170231819152832
Validation loss: 1.8423548270297307

Epoch: 5| Step: 5
Training loss: 0.7679482698440552
Validation loss: 1.873270269363157

Epoch: 5| Step: 6
Training loss: 0.7101644277572632
Validation loss: 1.8961301683097758

Epoch: 5| Step: 7
Training loss: 1.2036759853363037
Validation loss: 1.9368912212310299

Epoch: 5| Step: 8
Training loss: 0.6333616971969604
Validation loss: 1.9355820378949564

Epoch: 5| Step: 9
Training loss: 1.2431771755218506
Validation loss: 1.9122110156602756

Epoch: 5| Step: 10
Training loss: 0.7506009340286255
Validation loss: 1.8485924313145299

Epoch: 307| Step: 0
Training loss: 0.7364956140518188
Validation loss: 1.8255562795105802

Epoch: 5| Step: 1
Training loss: 1.0972850322723389
Validation loss: 1.7873303018590456

Epoch: 5| Step: 2
Training loss: 0.8556337356567383
Validation loss: 1.7436854083050963

Epoch: 5| Step: 3
Training loss: 0.7148088216781616
Validation loss: 1.718829563868943

Epoch: 5| Step: 4
Training loss: 0.7275503277778625
Validation loss: 1.7431845062522477

Epoch: 5| Step: 5
Training loss: 0.8628271818161011
Validation loss: 1.720425836501583

Epoch: 5| Step: 6
Training loss: 0.5883125066757202
Validation loss: 1.755104108523297

Epoch: 5| Step: 7
Training loss: 0.9147920608520508
Validation loss: 1.7970182229113836

Epoch: 5| Step: 8
Training loss: 0.5807121992111206
Validation loss: 1.7852574471504457

Epoch: 5| Step: 9
Training loss: 0.6820062398910522
Validation loss: 1.8084613020702074

Epoch: 5| Step: 10
Training loss: 0.701520562171936
Validation loss: 1.8216937293288529

Epoch: 308| Step: 0
Training loss: 0.7812495231628418
Validation loss: 1.875571555988763

Epoch: 5| Step: 1
Training loss: 0.7103287577629089
Validation loss: 1.8973140383279452

Epoch: 5| Step: 2
Training loss: 1.1724367141723633
Validation loss: 1.8904810592692385

Epoch: 5| Step: 3
Training loss: 0.7493531107902527
Validation loss: 1.89907935742409

Epoch: 5| Step: 4
Training loss: 0.7533854246139526
Validation loss: 1.9013391451169086

Epoch: 5| Step: 5
Training loss: 0.3345951437950134
Validation loss: 1.8931040661309355

Epoch: 5| Step: 6
Training loss: 0.5059703588485718
Validation loss: 1.832916517411509

Epoch: 5| Step: 7
Training loss: 0.5504144430160522
Validation loss: 1.829384305143869

Epoch: 5| Step: 8
Training loss: 0.9667011499404907
Validation loss: 1.78957365405175

Epoch: 5| Step: 9
Training loss: 0.9902098774909973
Validation loss: 1.790040889734863

Epoch: 5| Step: 10
Training loss: 0.6329622864723206
Validation loss: 1.7733313524594871

Epoch: 309| Step: 0
Training loss: 0.6107187867164612
Validation loss: 1.7437510503235685

Epoch: 5| Step: 1
Training loss: 0.4174758791923523
Validation loss: 1.7529894369904713

Epoch: 5| Step: 2
Training loss: 0.44314640760421753
Validation loss: 1.7490369940316806

Epoch: 5| Step: 3
Training loss: 0.4268389642238617
Validation loss: 1.7615170043001893

Epoch: 5| Step: 4
Training loss: 1.4278428554534912
Validation loss: 1.7967096695335962

Epoch: 5| Step: 5
Training loss: 0.758774995803833
Validation loss: 1.796784927768092

Epoch: 5| Step: 6
Training loss: 0.6198002099990845
Validation loss: 1.787896284493067

Epoch: 5| Step: 7
Training loss: 0.9528560638427734
Validation loss: 1.8021115051802767

Epoch: 5| Step: 8
Training loss: 1.0458624362945557
Validation loss: 1.8222145034420876

Epoch: 5| Step: 9
Training loss: 0.9896649122238159
Validation loss: 1.8263518425726122

Epoch: 5| Step: 10
Training loss: 0.48332539200782776
Validation loss: 1.853564211117324

Epoch: 310| Step: 0
Training loss: 0.4049248695373535
Validation loss: 1.8589642381155362

Epoch: 5| Step: 1
Training loss: 0.7830737829208374
Validation loss: 1.8764889176173876

Epoch: 5| Step: 2
Training loss: 0.5171541571617126
Validation loss: 1.8710971929693734

Epoch: 5| Step: 3
Training loss: 0.8489693403244019
Validation loss: 1.8375335290867796

Epoch: 5| Step: 4
Training loss: 0.8623876571655273
Validation loss: 1.8495069421747679

Epoch: 5| Step: 5
Training loss: 1.3616869449615479
Validation loss: 1.8169129458806847

Epoch: 5| Step: 6
Training loss: 0.722994863986969
Validation loss: 1.7961287101109822

Epoch: 5| Step: 7
Training loss: 0.2822047173976898
Validation loss: 1.7918521076120355

Epoch: 5| Step: 8
Training loss: 0.7947163581848145
Validation loss: 1.7732291298527871

Epoch: 5| Step: 9
Training loss: 0.6797449588775635
Validation loss: 1.7444422219389228

Epoch: 5| Step: 10
Training loss: 0.6326326727867126
Validation loss: 1.7657186920924852

Epoch: 311| Step: 0
Training loss: 0.8152316808700562
Validation loss: 1.8022398256486463

Epoch: 5| Step: 1
Training loss: 0.7352800369262695
Validation loss: 1.8424046193399737

Epoch: 5| Step: 2
Training loss: 0.7434927821159363
Validation loss: 1.906452844219823

Epoch: 5| Step: 3
Training loss: 0.7631382346153259
Validation loss: 1.9013626639560988

Epoch: 5| Step: 4
Training loss: 0.7630756497383118
Validation loss: 1.9114462226949713

Epoch: 5| Step: 5
Training loss: 0.8957251310348511
Validation loss: 1.8763151617460354

Epoch: 5| Step: 6
Training loss: 0.7610923051834106
Validation loss: 1.850196885806258

Epoch: 5| Step: 7
Training loss: 0.5498350858688354
Validation loss: 1.8021219443249445

Epoch: 5| Step: 8
Training loss: 0.8274103403091431
Validation loss: 1.7886851808076263

Epoch: 5| Step: 9
Training loss: 0.4193074703216553
Validation loss: 1.7939078025920416

Epoch: 5| Step: 10
Training loss: 0.7920281887054443
Validation loss: 1.7813012599945068

Epoch: 312| Step: 0
Training loss: 0.6405595541000366
Validation loss: 1.7753237960159138

Epoch: 5| Step: 1
Training loss: 1.0997841358184814
Validation loss: 1.7507632329899778

Epoch: 5| Step: 2
Training loss: 0.629073441028595
Validation loss: 1.7691244297130133

Epoch: 5| Step: 3
Training loss: 0.9762031435966492
Validation loss: 1.7709232479013421

Epoch: 5| Step: 4
Training loss: 0.5188665390014648
Validation loss: 1.8003284264636297

Epoch: 5| Step: 5
Training loss: 0.7487202882766724
Validation loss: 1.8270924001611688

Epoch: 5| Step: 6
Training loss: 0.6517683267593384
Validation loss: 1.862885743700048

Epoch: 5| Step: 7
Training loss: 0.4546540379524231
Validation loss: 1.8649962768759778

Epoch: 5| Step: 8
Training loss: 0.7799996137619019
Validation loss: 1.878276998637825

Epoch: 5| Step: 9
Training loss: 0.7091716527938843
Validation loss: 1.8909643991019136

Epoch: 5| Step: 10
Training loss: 0.7039320468902588
Validation loss: 1.894047628166855

Epoch: 313| Step: 0
Training loss: 0.778525710105896
Validation loss: 1.8324832441986247

Epoch: 5| Step: 1
Training loss: 0.9898554086685181
Validation loss: 1.7721988270359654

Epoch: 5| Step: 2
Training loss: 0.8592438697814941
Validation loss: 1.7546416072435276

Epoch: 5| Step: 3
Training loss: 0.5461663007736206
Validation loss: 1.7328802629183697

Epoch: 5| Step: 4
Training loss: 0.5780878663063049
Validation loss: 1.7472773598086448

Epoch: 5| Step: 5
Training loss: 0.5671241879463196
Validation loss: 1.7645618607920985

Epoch: 5| Step: 6
Training loss: 0.5244166254997253
Validation loss: 1.7614969079212477

Epoch: 5| Step: 7
Training loss: 0.7461870908737183
Validation loss: 1.7867822108730194

Epoch: 5| Step: 8
Training loss: 0.47383031249046326
Validation loss: 1.8153373887462

Epoch: 5| Step: 9
Training loss: 0.8528227806091309
Validation loss: 1.8548257453467256

Epoch: 5| Step: 10
Training loss: 0.7844005227088928
Validation loss: 1.8703630483278664

Epoch: 314| Step: 0
Training loss: 0.5172145366668701
Validation loss: 1.8725944949734596

Epoch: 5| Step: 1
Training loss: 0.8792558908462524
Validation loss: 1.8946392997618644

Epoch: 5| Step: 2
Training loss: 0.8075687289237976
Validation loss: 1.8910085821664462

Epoch: 5| Step: 3
Training loss: 1.074989914894104
Validation loss: 1.900735144974083

Epoch: 5| Step: 4
Training loss: 0.5978270173072815
Validation loss: 1.902884538455676

Epoch: 5| Step: 5
Training loss: 0.7997015714645386
Validation loss: 1.8407427021252212

Epoch: 5| Step: 6
Training loss: 0.8235558271408081
Validation loss: 1.8227561904538063

Epoch: 5| Step: 7
Training loss: 0.8628585934638977
Validation loss: 1.7705102633404475

Epoch: 5| Step: 8
Training loss: 0.34080398082733154
Validation loss: 1.770672223901236

Epoch: 5| Step: 9
Training loss: 0.41002923250198364
Validation loss: 1.7759330900766517

Epoch: 5| Step: 10
Training loss: 0.6885033845901489
Validation loss: 1.8019910012522051

Epoch: 315| Step: 0
Training loss: 0.47767695784568787
Validation loss: 1.803806052413038

Epoch: 5| Step: 1
Training loss: 0.7891965508460999
Validation loss: 1.8053709665934246

Epoch: 5| Step: 2
Training loss: 0.7722501754760742
Validation loss: 1.7956807895373272

Epoch: 5| Step: 3
Training loss: 0.5683733820915222
Validation loss: 1.775787668843423

Epoch: 5| Step: 4
Training loss: 0.9752861857414246
Validation loss: 1.8141457188513972

Epoch: 5| Step: 5
Training loss: 0.7856284976005554
Validation loss: 1.7850859998374857

Epoch: 5| Step: 6
Training loss: 0.5974298715591431
Validation loss: 1.7593505587629092

Epoch: 5| Step: 7
Training loss: 0.3239244818687439
Validation loss: 1.7675290402545725

Epoch: 5| Step: 8
Training loss: 1.0043275356292725
Validation loss: 1.7855215380268712

Epoch: 5| Step: 9
Training loss: 0.41717058420181274
Validation loss: 1.8179805996597453

Epoch: 5| Step: 10
Training loss: 0.8222982883453369
Validation loss: 1.8182646266875728

Epoch: 316| Step: 0
Training loss: 0.8749610781669617
Validation loss: 1.7999927433588172

Epoch: 5| Step: 1
Training loss: 0.556951642036438
Validation loss: 1.797330762750359

Epoch: 5| Step: 2
Training loss: 0.4808785915374756
Validation loss: 1.832821467871307

Epoch: 5| Step: 3
Training loss: 0.5514986515045166
Validation loss: 1.8230428426496443

Epoch: 5| Step: 4
Training loss: 0.41447338461875916
Validation loss: 1.8262859018900062

Epoch: 5| Step: 5
Training loss: 0.6406675577163696
Validation loss: 1.812056126133088

Epoch: 5| Step: 6
Training loss: 0.6768222451210022
Validation loss: 1.806775963434609

Epoch: 5| Step: 7
Training loss: 0.6013034582138062
Validation loss: 1.7897851531223585

Epoch: 5| Step: 8
Training loss: 0.9104278683662415
Validation loss: 1.8019374955085017

Epoch: 5| Step: 9
Training loss: 0.8995819091796875
Validation loss: 1.7832011381785076

Epoch: 5| Step: 10
Training loss: 0.8772889375686646
Validation loss: 1.7902647500397058

Epoch: 317| Step: 0
Training loss: 0.5603780150413513
Validation loss: 1.7824094398047334

Epoch: 5| Step: 1
Training loss: 0.7202550172805786
Validation loss: 1.8129829796411658

Epoch: 5| Step: 2
Training loss: 0.804765522480011
Validation loss: 1.771909659908664

Epoch: 5| Step: 3
Training loss: 0.9380816221237183
Validation loss: 1.7531100396187074

Epoch: 5| Step: 4
Training loss: 0.7060658931732178
Validation loss: 1.7571385970679663

Epoch: 5| Step: 5
Training loss: 0.4192134737968445
Validation loss: 1.7746441236106298

Epoch: 5| Step: 6
Training loss: 0.7552905082702637
Validation loss: 1.7774176289958339

Epoch: 5| Step: 7
Training loss: 0.4423008859157562
Validation loss: 1.7839325115244875

Epoch: 5| Step: 8
Training loss: 0.5592125654220581
Validation loss: 1.8230009963435512

Epoch: 5| Step: 9
Training loss: 0.6913812756538391
Validation loss: 1.8486410091000218

Epoch: 5| Step: 10
Training loss: 0.8957653045654297
Validation loss: 1.912107475342289

Epoch: 318| Step: 0
Training loss: 0.7832314372062683
Validation loss: 1.94547043308135

Epoch: 5| Step: 1
Training loss: 0.8992551565170288
Validation loss: 1.9303014560412335

Epoch: 5| Step: 2
Training loss: 0.6322952508926392
Validation loss: 1.9032139496136737

Epoch: 5| Step: 3
Training loss: 0.5593226552009583
Validation loss: 1.8683684282405402

Epoch: 5| Step: 4
Training loss: 1.1063672304153442
Validation loss: 1.8680531414606238

Epoch: 5| Step: 5
Training loss: 0.37568336725234985
Validation loss: 1.8075304159554102

Epoch: 5| Step: 6
Training loss: 0.7193132042884827
Validation loss: 1.8101853939794725

Epoch: 5| Step: 7
Training loss: 0.4718945622444153
Validation loss: 1.7964793917953328

Epoch: 5| Step: 8
Training loss: 0.8079687356948853
Validation loss: 1.7764369877435828

Epoch: 5| Step: 9
Training loss: 0.42610931396484375
Validation loss: 1.7720661432512346

Epoch: 5| Step: 10
Training loss: 0.7565199732780457
Validation loss: 1.749450486193421

Epoch: 319| Step: 0
Training loss: 0.5554882884025574
Validation loss: 1.7567137595145934

Epoch: 5| Step: 1
Training loss: 0.33313408493995667
Validation loss: 1.7705983961782148

Epoch: 5| Step: 2
Training loss: 0.4790005683898926
Validation loss: 1.8053520469255344

Epoch: 5| Step: 3
Training loss: 0.8473763465881348
Validation loss: 1.8347233790223316

Epoch: 5| Step: 4
Training loss: 0.6453078985214233
Validation loss: 1.8551694616194694

Epoch: 5| Step: 5
Training loss: 1.1361465454101562
Validation loss: 1.850507083759513

Epoch: 5| Step: 6
Training loss: 0.4272289276123047
Validation loss: 1.829671682850007

Epoch: 5| Step: 7
Training loss: 0.6158908009529114
Validation loss: 1.806426320024716

Epoch: 5| Step: 8
Training loss: 0.7668331861495972
Validation loss: 1.8155597743167673

Epoch: 5| Step: 9
Training loss: 0.9370366334915161
Validation loss: 1.808627805402202

Epoch: 5| Step: 10
Training loss: 0.7616917490959167
Validation loss: 1.7785995596198625

Epoch: 320| Step: 0
Training loss: 0.7023464441299438
Validation loss: 1.772085379528743

Epoch: 5| Step: 1
Training loss: 0.6699063181877136
Validation loss: 1.7603934106006418

Epoch: 5| Step: 2
Training loss: 0.8393142819404602
Validation loss: 1.7440779286046182

Epoch: 5| Step: 3
Training loss: 0.6763097643852234
Validation loss: 1.7628188902331936

Epoch: 5| Step: 4
Training loss: 0.6472009420394897
Validation loss: 1.7571139745814826

Epoch: 5| Step: 5
Training loss: 0.8119944334030151
Validation loss: 1.7201557056878203

Epoch: 5| Step: 6
Training loss: 0.5376154184341431
Validation loss: 1.734708023327653

Epoch: 5| Step: 7
Training loss: 0.8211042284965515
Validation loss: 1.735549651166444

Epoch: 5| Step: 8
Training loss: 0.5918259620666504
Validation loss: 1.7556387929506199

Epoch: 5| Step: 9
Training loss: 0.4572388529777527
Validation loss: 1.7875559355622979

Epoch: 5| Step: 10
Training loss: 0.7605897188186646
Validation loss: 1.8068613160041072

Epoch: 321| Step: 0
Training loss: 0.7791162729263306
Validation loss: 1.8572879978405532

Epoch: 5| Step: 1
Training loss: 0.6578301787376404
Validation loss: 1.8374304233058807

Epoch: 5| Step: 2
Training loss: 0.8048110008239746
Validation loss: 1.7981640151751939

Epoch: 5| Step: 3
Training loss: 0.4899722933769226
Validation loss: 1.7536037378413702

Epoch: 5| Step: 4
Training loss: 0.7560854554176331
Validation loss: 1.7520606133245653

Epoch: 5| Step: 5
Training loss: 0.5145748853683472
Validation loss: 1.7200116495932303

Epoch: 5| Step: 6
Training loss: 0.4728885293006897
Validation loss: 1.6819251647559545

Epoch: 5| Step: 7
Training loss: 0.7801446318626404
Validation loss: 1.7090052968712264

Epoch: 5| Step: 8
Training loss: 0.3974091708660126
Validation loss: 1.7385138907740194

Epoch: 5| Step: 9
Training loss: 0.9317619204521179
Validation loss: 1.7584376296689432

Epoch: 5| Step: 10
Training loss: 0.9945406317710876
Validation loss: 1.7799532439119072

Epoch: 322| Step: 0
Training loss: 0.5552692413330078
Validation loss: 1.8101421376710296

Epoch: 5| Step: 1
Training loss: 0.49472469091415405
Validation loss: 1.7904505486129432

Epoch: 5| Step: 2
Training loss: 0.5114430785179138
Validation loss: 1.7921102226421397

Epoch: 5| Step: 3
Training loss: 0.4654775559902191
Validation loss: 1.8071719356762466

Epoch: 5| Step: 4
Training loss: 0.7797935009002686
Validation loss: 1.7649793817150978

Epoch: 5| Step: 5
Training loss: 0.4071592688560486
Validation loss: 1.7480635130277244

Epoch: 5| Step: 6
Training loss: 0.6773775815963745
Validation loss: 1.7548633801039828

Epoch: 5| Step: 7
Training loss: 0.7239023447036743
Validation loss: 1.7693724914263653

Epoch: 5| Step: 8
Training loss: 0.864666759967804
Validation loss: 1.744935618933811

Epoch: 5| Step: 9
Training loss: 0.7558890581130981
Validation loss: 1.7584652464876893

Epoch: 5| Step: 10
Training loss: 0.8341032862663269
Validation loss: 1.7646820442650908

Epoch: 323| Step: 0
Training loss: 0.6419669985771179
Validation loss: 1.7977664778309483

Epoch: 5| Step: 1
Training loss: 0.6420989036560059
Validation loss: 1.810460832811171

Epoch: 5| Step: 2
Training loss: 0.7321158647537231
Validation loss: 1.798528149563779

Epoch: 5| Step: 3
Training loss: 0.3384009897708893
Validation loss: 1.7845525767213555

Epoch: 5| Step: 4
Training loss: 0.9123220443725586
Validation loss: 1.764231977924224

Epoch: 5| Step: 5
Training loss: 0.4780026376247406
Validation loss: 1.7252918853554675

Epoch: 5| Step: 6
Training loss: 0.6495712399482727
Validation loss: 1.7660966842405257

Epoch: 5| Step: 7
Training loss: 0.717589259147644
Validation loss: 1.7499500320803734

Epoch: 5| Step: 8
Training loss: 0.6476536989212036
Validation loss: 1.804277253407304

Epoch: 5| Step: 9
Training loss: 0.8119670152664185
Validation loss: 1.82219059108406

Epoch: 5| Step: 10
Training loss: 0.350347101688385
Validation loss: 1.8409467448470413

Epoch: 324| Step: 0
Training loss: 0.3446037769317627
Validation loss: 1.8395392971654092

Epoch: 5| Step: 1
Training loss: 0.4177885055541992
Validation loss: 1.8076726544287898

Epoch: 5| Step: 2
Training loss: 0.7786828279495239
Validation loss: 1.763431131198842

Epoch: 5| Step: 3
Training loss: 0.5901070833206177
Validation loss: 1.7827369474595594

Epoch: 5| Step: 4
Training loss: 0.7776833772659302
Validation loss: 1.7621052111348798

Epoch: 5| Step: 5
Training loss: 0.7426477670669556
Validation loss: 1.7192372814301522

Epoch: 5| Step: 6
Training loss: 0.5795968770980835
Validation loss: 1.7225186106979207

Epoch: 5| Step: 7
Training loss: 0.6486036777496338
Validation loss: 1.7176152672818912

Epoch: 5| Step: 8
Training loss: 0.6710391640663147
Validation loss: 1.7399904356207898

Epoch: 5| Step: 9
Training loss: 0.7607934474945068
Validation loss: 1.7391887531485608

Epoch: 5| Step: 10
Training loss: 0.7505883574485779
Validation loss: 1.7538125502165927

Epoch: 325| Step: 0
Training loss: 0.6802254915237427
Validation loss: 1.7914743551643946

Epoch: 5| Step: 1
Training loss: 0.5838986039161682
Validation loss: 1.7937084397962015

Epoch: 5| Step: 2
Training loss: 0.8011325597763062
Validation loss: 1.8401496589824717

Epoch: 5| Step: 3
Training loss: 0.4286886751651764
Validation loss: 1.8490749943640925

Epoch: 5| Step: 4
Training loss: 0.5752316117286682
Validation loss: 1.8546730561922955

Epoch: 5| Step: 5
Training loss: 0.6604482531547546
Validation loss: 1.8151555638159476

Epoch: 5| Step: 6
Training loss: 0.5137060880661011
Validation loss: 1.763186582954981

Epoch: 5| Step: 7
Training loss: 0.8970837593078613
Validation loss: 1.7656313309105494

Epoch: 5| Step: 8
Training loss: 0.44882932305336
Validation loss: 1.7435566648360221

Epoch: 5| Step: 9
Training loss: 0.6486555337905884
Validation loss: 1.7331515473704184

Epoch: 5| Step: 10
Training loss: 0.8299451470375061
Validation loss: 1.7199073337739514

Epoch: 326| Step: 0
Training loss: 0.7320252656936646
Validation loss: 1.6932681914298766

Epoch: 5| Step: 1
Training loss: 1.2870992422103882
Validation loss: 1.7063677836489934

Epoch: 5| Step: 2
Training loss: 0.7340689897537231
Validation loss: 1.7177151198028235

Epoch: 5| Step: 3
Training loss: 0.8544519543647766
Validation loss: 1.7406044442166564

Epoch: 5| Step: 4
Training loss: 0.3461117744445801
Validation loss: 1.7598559318050262

Epoch: 5| Step: 5
Training loss: 0.40115728974342346
Validation loss: 1.7609087203138618

Epoch: 5| Step: 6
Training loss: 0.24805183708667755
Validation loss: 1.758525404878842

Epoch: 5| Step: 7
Training loss: 0.5689139366149902
Validation loss: 1.766361641627486

Epoch: 5| Step: 8
Training loss: 0.7227350473403931
Validation loss: 1.8045824343158352

Epoch: 5| Step: 9
Training loss: 0.6535854935646057
Validation loss: 1.8158481133881437

Epoch: 5| Step: 10
Training loss: 0.43883800506591797
Validation loss: 1.84986953068805

Epoch: 327| Step: 0
Training loss: 0.5436864495277405
Validation loss: 1.8793891719592515

Epoch: 5| Step: 1
Training loss: 0.4701407849788666
Validation loss: 1.8987714757201493

Epoch: 5| Step: 2
Training loss: 1.1000219583511353
Validation loss: 1.9023274593455817

Epoch: 5| Step: 3
Training loss: 0.610261082649231
Validation loss: 1.8789629397853729

Epoch: 5| Step: 4
Training loss: 0.5325600504875183
Validation loss: 1.8631855069950063

Epoch: 5| Step: 5
Training loss: 0.7126295566558838
Validation loss: 1.839985245017595

Epoch: 5| Step: 6
Training loss: 0.6167032122612
Validation loss: 1.767679697723799

Epoch: 5| Step: 7
Training loss: 0.7340425252914429
Validation loss: 1.7024652522097352

Epoch: 5| Step: 8
Training loss: 0.4676533341407776
Validation loss: 1.6964740419900546

Epoch: 5| Step: 9
Training loss: 0.6160665154457092
Validation loss: 1.7012584517079015

Epoch: 5| Step: 10
Training loss: 0.6888812184333801
Validation loss: 1.6929539993245115

Epoch: 328| Step: 0
Training loss: 0.7657067775726318
Validation loss: 1.7111347913742065

Epoch: 5| Step: 1
Training loss: 0.5271323323249817
Validation loss: 1.7756261466651835

Epoch: 5| Step: 2
Training loss: 0.6625120639801025
Validation loss: 1.7820206765205628

Epoch: 5| Step: 3
Training loss: 0.5597964525222778
Validation loss: 1.818389206804255

Epoch: 5| Step: 4
Training loss: 0.4552145004272461
Validation loss: 1.7839019849736204

Epoch: 5| Step: 5
Training loss: 0.8969680666923523
Validation loss: 1.7757997089816677

Epoch: 5| Step: 6
Training loss: 0.8772101402282715
Validation loss: 1.779681597986529

Epoch: 5| Step: 7
Training loss: 0.7245074510574341
Validation loss: 1.733982006708781

Epoch: 5| Step: 8
Training loss: 0.22126546502113342
Validation loss: 1.7415239195669852

Epoch: 5| Step: 9
Training loss: 0.5265647172927856
Validation loss: 1.7452597079738494

Epoch: 5| Step: 10
Training loss: 0.8620181679725647
Validation loss: 1.7604065838680472

Epoch: 329| Step: 0
Training loss: 0.5069689154624939
Validation loss: 1.7426063937525595

Epoch: 5| Step: 1
Training loss: 0.5778835415840149
Validation loss: 1.7934389953972192

Epoch: 5| Step: 2
Training loss: 0.49364590644836426
Validation loss: 1.8040220731048173

Epoch: 5| Step: 3
Training loss: 0.7797536253929138
Validation loss: 1.7752537406900877

Epoch: 5| Step: 4
Training loss: 0.7100898027420044
Validation loss: 1.7519906720807474

Epoch: 5| Step: 5
Training loss: 0.40474534034729004
Validation loss: 1.75257477196314

Epoch: 5| Step: 6
Training loss: 0.5361142754554749
Validation loss: 1.72233235707847

Epoch: 5| Step: 7
Training loss: 0.5024430155754089
Validation loss: 1.7043522070812922

Epoch: 5| Step: 8
Training loss: 0.9982894062995911
Validation loss: 1.699704077935988

Epoch: 5| Step: 9
Training loss: 0.5860887765884399
Validation loss: 1.7249620832422727

Epoch: 5| Step: 10
Training loss: 0.7497463226318359
Validation loss: 1.7512677933580132

Epoch: 330| Step: 0
Training loss: 0.678275465965271
Validation loss: 1.803007980828644

Epoch: 5| Step: 1
Training loss: 0.6267067193984985
Validation loss: 1.8350622064323836

Epoch: 5| Step: 2
Training loss: 0.7214560508728027
Validation loss: 1.8538046088269962

Epoch: 5| Step: 3
Training loss: 0.7286256551742554
Validation loss: 1.852183449652887

Epoch: 5| Step: 4
Training loss: 0.600135087966919
Validation loss: 1.8537781225737704

Epoch: 5| Step: 5
Training loss: 0.5540247559547424
Validation loss: 1.8342310664474324

Epoch: 5| Step: 6
Training loss: 0.7413413524627686
Validation loss: 1.825531567296674

Epoch: 5| Step: 7
Training loss: 0.4830388128757477
Validation loss: 1.7993596241038332

Epoch: 5| Step: 8
Training loss: 0.5758675932884216
Validation loss: 1.7795141845621087

Epoch: 5| Step: 9
Training loss: 0.6575790643692017
Validation loss: 1.7547844840634255

Epoch: 5| Step: 10
Training loss: 0.4765605330467224
Validation loss: 1.7540068036766463

Epoch: 331| Step: 0
Training loss: 0.33092427253723145
Validation loss: 1.7749602512646747

Epoch: 5| Step: 1
Training loss: 0.6609531044960022
Validation loss: 1.7659550969318678

Epoch: 5| Step: 2
Training loss: 0.8877773284912109
Validation loss: 1.7486381018033592

Epoch: 5| Step: 3
Training loss: 0.5194581151008606
Validation loss: 1.7679644605164886

Epoch: 5| Step: 4
Training loss: 0.46617478132247925
Validation loss: 1.7435659413696618

Epoch: 5| Step: 5
Training loss: 0.42850226163864136
Validation loss: 1.7481785717830862

Epoch: 5| Step: 6
Training loss: 0.450878381729126
Validation loss: 1.7485451544484785

Epoch: 5| Step: 7
Training loss: 1.0729516744613647
Validation loss: 1.7537332350207913

Epoch: 5| Step: 8
Training loss: 0.613743782043457
Validation loss: 1.7936958946207517

Epoch: 5| Step: 9
Training loss: 0.6803295612335205
Validation loss: 1.8080945117499239

Epoch: 5| Step: 10
Training loss: 0.6318037509918213
Validation loss: 1.835748008502427

Epoch: 332| Step: 0
Training loss: 0.43661752343177795
Validation loss: 1.8908744101883264

Epoch: 5| Step: 1
Training loss: 0.7220848798751831
Validation loss: 1.9175495255377986

Epoch: 5| Step: 2
Training loss: 0.6575812697410583
Validation loss: 1.864336875177199

Epoch: 5| Step: 3
Training loss: 0.41434305906295776
Validation loss: 1.7992274427926669

Epoch: 5| Step: 4
Training loss: 0.6387223601341248
Validation loss: 1.7804707519469722

Epoch: 5| Step: 5
Training loss: 0.6166691780090332
Validation loss: 1.7315253134696715

Epoch: 5| Step: 6
Training loss: 0.9962347149848938
Validation loss: 1.7227496921375234

Epoch: 5| Step: 7
Training loss: 0.5535310506820679
Validation loss: 1.717049111602127

Epoch: 5| Step: 8
Training loss: 0.556257426738739
Validation loss: 1.7001688800832278

Epoch: 5| Step: 9
Training loss: 0.4663877487182617
Validation loss: 1.7214064482719666

Epoch: 5| Step: 10
Training loss: 0.8904538154602051
Validation loss: 1.7343010774222754

Epoch: 333| Step: 0
Training loss: 0.5002589225769043
Validation loss: 1.75865525327703

Epoch: 5| Step: 1
Training loss: 0.8425185084342957
Validation loss: 1.7565750832198768

Epoch: 5| Step: 2
Training loss: 0.6868990659713745
Validation loss: 1.8117840802797707

Epoch: 5| Step: 3
Training loss: 0.6291974782943726
Validation loss: 1.7770036061604817

Epoch: 5| Step: 4
Training loss: 0.7872496843338013
Validation loss: 1.812324941799205

Epoch: 5| Step: 5
Training loss: 0.3986729681491852
Validation loss: 1.7904562463042557

Epoch: 5| Step: 6
Training loss: 0.6764736771583557
Validation loss: 1.7818741580491424

Epoch: 5| Step: 7
Training loss: 0.5378134250640869
Validation loss: 1.812672625305832

Epoch: 5| Step: 8
Training loss: 0.43550580739974976
Validation loss: 1.7998273564923195

Epoch: 5| Step: 9
Training loss: 0.7111808061599731
Validation loss: 1.8095059997291976

Epoch: 5| Step: 10
Training loss: 0.4695218503475189
Validation loss: 1.8222370122068672

Epoch: 334| Step: 0
Training loss: 0.7927058935165405
Validation loss: 1.8388149417856687

Epoch: 5| Step: 1
Training loss: 0.36782360076904297
Validation loss: 1.7891313158055788

Epoch: 5| Step: 2
Training loss: 0.42257848381996155
Validation loss: 1.781310768537624

Epoch: 5| Step: 3
Training loss: 0.5671772956848145
Validation loss: 1.7397911228159422

Epoch: 5| Step: 4
Training loss: 0.6268693208694458
Validation loss: 1.7108679599659418

Epoch: 5| Step: 5
Training loss: 0.6437935829162598
Validation loss: 1.7070185163969636

Epoch: 5| Step: 6
Training loss: 0.4907859265804291
Validation loss: 1.7062446635256532

Epoch: 5| Step: 7
Training loss: 0.705723762512207
Validation loss: 1.7050415636390768

Epoch: 5| Step: 8
Training loss: 0.6151605248451233
Validation loss: 1.7238274530697895

Epoch: 5| Step: 9
Training loss: 0.5227267742156982
Validation loss: 1.710718261298313

Epoch: 5| Step: 10
Training loss: 0.6950579285621643
Validation loss: 1.7011465308486775

Epoch: 335| Step: 0
Training loss: 0.3840793967247009
Validation loss: 1.7152561949145408

Epoch: 5| Step: 1
Training loss: 0.5322762727737427
Validation loss: 1.730872888718882

Epoch: 5| Step: 2
Training loss: 0.6749845147132874
Validation loss: 1.7695860901186544

Epoch: 5| Step: 3
Training loss: 0.5573028326034546
Validation loss: 1.7691359071321384

Epoch: 5| Step: 4
Training loss: 0.7950103282928467
Validation loss: 1.75403384752171

Epoch: 5| Step: 5
Training loss: 0.8105282783508301
Validation loss: 1.7421955126588062

Epoch: 5| Step: 6
Training loss: 0.5302910804748535
Validation loss: 1.7904974183728617

Epoch: 5| Step: 7
Training loss: 0.8740233182907104
Validation loss: 1.7752017077579294

Epoch: 5| Step: 8
Training loss: 0.4708036482334137
Validation loss: 1.7841594116662138

Epoch: 5| Step: 9
Training loss: 0.23925718665122986
Validation loss: 1.7893720813976821

Epoch: 5| Step: 10
Training loss: 0.4445212185382843
Validation loss: 1.7673609538744854

Epoch: 336| Step: 0
Training loss: 0.4228339195251465
Validation loss: 1.7690881554798414

Epoch: 5| Step: 1
Training loss: 0.558912456035614
Validation loss: 1.7639271431071784

Epoch: 5| Step: 2
Training loss: 0.6415830850601196
Validation loss: 1.7861430478352371

Epoch: 5| Step: 3
Training loss: 0.5422550439834595
Validation loss: 1.7554025444933163

Epoch: 5| Step: 4
Training loss: 0.59892338514328
Validation loss: 1.7688052026174401

Epoch: 5| Step: 5
Training loss: 0.7572203278541565
Validation loss: 1.7814582278651576

Epoch: 5| Step: 6
Training loss: 0.6119698286056519
Validation loss: 1.8196822674043718

Epoch: 5| Step: 7
Training loss: 0.6049247980117798
Validation loss: 1.8378126249518445

Epoch: 5| Step: 8
Training loss: 0.4225970208644867
Validation loss: 1.789916665323319

Epoch: 5| Step: 9
Training loss: 0.6346931457519531
Validation loss: 1.748830218468943

Epoch: 5| Step: 10
Training loss: 0.5036972165107727
Validation loss: 1.728253726036318

Epoch: 337| Step: 0
Training loss: 0.25931909680366516
Validation loss: 1.7515146014510945

Epoch: 5| Step: 1
Training loss: 0.8675833940505981
Validation loss: 1.7441977582952028

Epoch: 5| Step: 2
Training loss: 0.7405294179916382
Validation loss: 1.759780486424764

Epoch: 5| Step: 3
Training loss: 0.7990165948867798
Validation loss: 1.7321739196777344

Epoch: 5| Step: 4
Training loss: 0.700535774230957
Validation loss: 1.7615750553787395

Epoch: 5| Step: 5
Training loss: 0.4052204489707947
Validation loss: 1.7707522082072433

Epoch: 5| Step: 6
Training loss: 0.5771949887275696
Validation loss: 1.778999056867374

Epoch: 5| Step: 7
Training loss: 0.4955212473869324
Validation loss: 1.7709370813062113

Epoch: 5| Step: 8
Training loss: 0.5676683783531189
Validation loss: 1.7497187609313636

Epoch: 5| Step: 9
Training loss: 0.4689379632472992
Validation loss: 1.7285240606595111

Epoch: 5| Step: 10
Training loss: 0.5228487849235535
Validation loss: 1.6948438754645727

Epoch: 338| Step: 0
Training loss: 0.7045373916625977
Validation loss: 1.6674592956419914

Epoch: 5| Step: 1
Training loss: 0.5514652132987976
Validation loss: 1.674945906926227

Epoch: 5| Step: 2
Training loss: 0.6143121123313904
Validation loss: 1.6863890988852388

Epoch: 5| Step: 3
Training loss: 0.5078350305557251
Validation loss: 1.685975509305154

Epoch: 5| Step: 4
Training loss: 0.5486556887626648
Validation loss: 1.731261162347691

Epoch: 5| Step: 5
Training loss: 0.7886394262313843
Validation loss: 1.7266513762935516

Epoch: 5| Step: 6
Training loss: 0.5225403308868408
Validation loss: 1.746378057746477

Epoch: 5| Step: 7
Training loss: 0.5306217074394226
Validation loss: 1.7501020123881679

Epoch: 5| Step: 8
Training loss: 0.4356633722782135
Validation loss: 1.7655105296001639

Epoch: 5| Step: 9
Training loss: 0.4969727098941803
Validation loss: 1.787479651871548

Epoch: 5| Step: 10
Training loss: 0.7351474761962891
Validation loss: 1.7750042497470815

Epoch: 339| Step: 0
Training loss: 0.5786739587783813
Validation loss: 1.8113399628669984

Epoch: 5| Step: 1
Training loss: 0.4704075753688812
Validation loss: 1.809766693781781

Epoch: 5| Step: 2
Training loss: 0.5674459338188171
Validation loss: 1.8123380484119538

Epoch: 5| Step: 3
Training loss: 0.8495895266532898
Validation loss: 1.7751486045058056

Epoch: 5| Step: 4
Training loss: 0.2526762783527374
Validation loss: 1.7713707057378625

Epoch: 5| Step: 5
Training loss: 0.42034703493118286
Validation loss: 1.752587228692988

Epoch: 5| Step: 6
Training loss: 0.3971292972564697
Validation loss: 1.7125285133238761

Epoch: 5| Step: 7
Training loss: 0.46628791093826294
Validation loss: 1.7308216620517034

Epoch: 5| Step: 8
Training loss: 0.7093755006790161
Validation loss: 1.7110254251828758

Epoch: 5| Step: 9
Training loss: 0.3185823857784271
Validation loss: 1.735929153298819

Epoch: 5| Step: 10
Training loss: 1.2673696279525757
Validation loss: 1.6986425781762728

Epoch: 340| Step: 0
Training loss: 0.7085128426551819
Validation loss: 1.7223835427273986

Epoch: 5| Step: 1
Training loss: 0.42207980155944824
Validation loss: 1.695568146244172

Epoch: 5| Step: 2
Training loss: 0.5598871111869812
Validation loss: 1.7347554506794098

Epoch: 5| Step: 3
Training loss: 0.4556998312473297
Validation loss: 1.7442991483596064

Epoch: 5| Step: 4
Training loss: 0.44724687933921814
Validation loss: 1.7620794311646493

Epoch: 5| Step: 5
Training loss: 0.5327909588813782
Validation loss: 1.7570219296281055

Epoch: 5| Step: 6
Training loss: 0.7371651530265808
Validation loss: 1.7576067140025478

Epoch: 5| Step: 7
Training loss: 0.6937336325645447
Validation loss: 1.7201823752413514

Epoch: 5| Step: 8
Training loss: 0.41620951890945435
Validation loss: 1.6977362068750526

Epoch: 5| Step: 9
Training loss: 0.610685408115387
Validation loss: 1.7130543801092333

Epoch: 5| Step: 10
Training loss: 0.4912970960140228
Validation loss: 1.6846249475274035

Epoch: 341| Step: 0
Training loss: 0.6597744226455688
Validation loss: 1.6770237402249408

Epoch: 5| Step: 1
Training loss: 0.5181596279144287
Validation loss: 1.6816476545026224

Epoch: 5| Step: 2
Training loss: 0.780417799949646
Validation loss: 1.6931222074775285

Epoch: 5| Step: 3
Training loss: 0.6608863472938538
Validation loss: 1.703652262687683

Epoch: 5| Step: 4
Training loss: 0.3510180711746216
Validation loss: 1.7193519812758251

Epoch: 5| Step: 5
Training loss: 0.3591720461845398
Validation loss: 1.7585174332382858

Epoch: 5| Step: 6
Training loss: 0.6538873910903931
Validation loss: 1.7680375332473426

Epoch: 5| Step: 7
Training loss: 0.7546710968017578
Validation loss: 1.80227142764676

Epoch: 5| Step: 8
Training loss: 0.7597947120666504
Validation loss: 1.7612272872719714

Epoch: 5| Step: 9
Training loss: 0.29712334275245667
Validation loss: 1.770580650657736

Epoch: 5| Step: 10
Training loss: 0.4182654023170471
Validation loss: 1.7562922213667183

Epoch: 342| Step: 0
Training loss: 0.6862270832061768
Validation loss: 1.7396420983858005

Epoch: 5| Step: 1
Training loss: 0.501895010471344
Validation loss: 1.7507126446693175

Epoch: 5| Step: 2
Training loss: 0.5591619610786438
Validation loss: 1.738283286812485

Epoch: 5| Step: 3
Training loss: 0.6831862926483154
Validation loss: 1.7727704330157208

Epoch: 5| Step: 4
Training loss: 0.5787302255630493
Validation loss: 1.8240649097709245

Epoch: 5| Step: 5
Training loss: 0.48709964752197266
Validation loss: 1.8361637976861769

Epoch: 5| Step: 6
Training loss: 0.6445068120956421
Validation loss: 1.8833279366134315

Epoch: 5| Step: 7
Training loss: 0.5215659141540527
Validation loss: 1.915771568975141

Epoch: 5| Step: 8
Training loss: 0.7017948031425476
Validation loss: 1.9629815188787316

Epoch: 5| Step: 9
Training loss: 0.49949851632118225
Validation loss: 1.8752175300352034

Epoch: 5| Step: 10
Training loss: 0.7126490473747253
Validation loss: 1.8251696645572622

Epoch: 343| Step: 0
Training loss: 0.5595746636390686
Validation loss: 1.7669964913398988

Epoch: 5| Step: 1
Training loss: 0.6451157927513123
Validation loss: 1.7159695163849862

Epoch: 5| Step: 2
Training loss: 0.46514758467674255
Validation loss: 1.6770012724784114

Epoch: 5| Step: 3
Training loss: 0.8117262721061707
Validation loss: 1.6606192281169276

Epoch: 5| Step: 4
Training loss: 0.8322908282279968
Validation loss: 1.6446336238614974

Epoch: 5| Step: 5
Training loss: 0.3874914050102234
Validation loss: 1.6481797784887335

Epoch: 5| Step: 6
Training loss: 0.5101931691169739
Validation loss: 1.6546951590045806

Epoch: 5| Step: 7
Training loss: 0.6964622139930725
Validation loss: 1.707148555786379

Epoch: 5| Step: 8
Training loss: 0.5548830628395081
Validation loss: 1.7332693364030571

Epoch: 5| Step: 9
Training loss: 0.5261346697807312
Validation loss: 1.7843622546042166

Epoch: 5| Step: 10
Training loss: 0.6840665340423584
Validation loss: 1.8329310814539592

Epoch: 344| Step: 0
Training loss: 0.5882012248039246
Validation loss: 1.8814569698866976

Epoch: 5| Step: 1
Training loss: 0.44408220052719116
Validation loss: 1.8683690063415035

Epoch: 5| Step: 2
Training loss: 0.3786122798919678
Validation loss: 1.821829475382323

Epoch: 5| Step: 3
Training loss: 0.6296504735946655
Validation loss: 1.7898230180945447

Epoch: 5| Step: 4
Training loss: 0.7104144096374512
Validation loss: 1.789990096963862

Epoch: 5| Step: 5
Training loss: 0.9537765383720398
Validation loss: 1.7583267073477469

Epoch: 5| Step: 6
Training loss: 0.8520607948303223
Validation loss: 1.740531374049443

Epoch: 5| Step: 7
Training loss: 0.5268563628196716
Validation loss: 1.691356446153374

Epoch: 5| Step: 8
Training loss: 0.40696001052856445
Validation loss: 1.691448737216252

Epoch: 5| Step: 9
Training loss: 0.4502362608909607
Validation loss: 1.716684151721257

Epoch: 5| Step: 10
Training loss: 0.597200870513916
Validation loss: 1.706283555235914

Epoch: 345| Step: 0
Training loss: 0.6800538897514343
Validation loss: 1.702151676659943

Epoch: 5| Step: 1
Training loss: 0.37551870942115784
Validation loss: 1.7556222805412867

Epoch: 5| Step: 2
Training loss: 0.4007405638694763
Validation loss: 1.7582443670559955

Epoch: 5| Step: 3
Training loss: 0.5360380411148071
Validation loss: 1.7591570782405075

Epoch: 5| Step: 4
Training loss: 0.8362401723861694
Validation loss: 1.742971577951985

Epoch: 5| Step: 5
Training loss: 0.386165052652359
Validation loss: 1.7593261605949813

Epoch: 5| Step: 6
Training loss: 0.6184940934181213
Validation loss: 1.7457850697220012

Epoch: 5| Step: 7
Training loss: 0.4701499342918396
Validation loss: 1.7350288783350298

Epoch: 5| Step: 8
Training loss: 0.7094922661781311
Validation loss: 1.7569754610779464

Epoch: 5| Step: 9
Training loss: 0.43564826250076294
Validation loss: 1.73229976495107

Epoch: 5| Step: 10
Training loss: 0.6948386430740356
Validation loss: 1.7884217500686646

Epoch: 346| Step: 0
Training loss: 0.6256742477416992
Validation loss: 1.760229415791009

Epoch: 5| Step: 1
Training loss: 0.5587043166160583
Validation loss: 1.7833550565986223

Epoch: 5| Step: 2
Training loss: 0.6342258453369141
Validation loss: 1.7988524026768182

Epoch: 5| Step: 3
Training loss: 0.43458589911460876
Validation loss: 1.7719852424437

Epoch: 5| Step: 4
Training loss: 0.47580188512802124
Validation loss: 1.7750333150227864

Epoch: 5| Step: 5
Training loss: 0.5291882157325745
Validation loss: 1.736319996977365

Epoch: 5| Step: 6
Training loss: 0.3831295967102051
Validation loss: 1.76814785311299

Epoch: 5| Step: 7
Training loss: 0.35732781887054443
Validation loss: 1.7357406718756563

Epoch: 5| Step: 8
Training loss: 0.8144429922103882
Validation loss: 1.7619095310088126

Epoch: 5| Step: 9
Training loss: 0.49691396951675415
Validation loss: 1.7434045640371179

Epoch: 5| Step: 10
Training loss: 0.5677090883255005
Validation loss: 1.725264613346387

Epoch: 347| Step: 0
Training loss: 0.5284475088119507
Validation loss: 1.7120546153796616

Epoch: 5| Step: 1
Training loss: 0.7338299751281738
Validation loss: 1.7301532094196608

Epoch: 5| Step: 2
Training loss: 0.8099955320358276
Validation loss: 1.7184890803470407

Epoch: 5| Step: 3
Training loss: 0.33070552349090576
Validation loss: 1.6779215220482118

Epoch: 5| Step: 4
Training loss: 0.5930183529853821
Validation loss: 1.7044102940508115

Epoch: 5| Step: 5
Training loss: 0.4581737518310547
Validation loss: 1.7042379507454493

Epoch: 5| Step: 6
Training loss: 0.7408177256584167
Validation loss: 1.7124041703439528

Epoch: 5| Step: 7
Training loss: 0.4889441132545471
Validation loss: 1.7261860011726298

Epoch: 5| Step: 8
Training loss: 0.24150285124778748
Validation loss: 1.7243712422668294

Epoch: 5| Step: 9
Training loss: 0.43144434690475464
Validation loss: 1.7806412071310065

Epoch: 5| Step: 10
Training loss: 0.5107654929161072
Validation loss: 1.7421744843964935

Epoch: 348| Step: 0
Training loss: 0.4316233694553375
Validation loss: 1.769207949279457

Epoch: 5| Step: 1
Training loss: 0.5036464929580688
Validation loss: 1.7538412642735306

Epoch: 5| Step: 2
Training loss: 0.7475059628486633
Validation loss: 1.7150822929156724

Epoch: 5| Step: 3
Training loss: 0.3437289893627167
Validation loss: 1.727379419470346

Epoch: 5| Step: 4
Training loss: 0.34646889567375183
Validation loss: 1.7285987228475592

Epoch: 5| Step: 5
Training loss: 0.627399742603302
Validation loss: 1.7206982002463391

Epoch: 5| Step: 6
Training loss: 0.5493226647377014
Validation loss: 1.6832245101210892

Epoch: 5| Step: 7
Training loss: 0.5555952787399292
Validation loss: 1.7033918211537022

Epoch: 5| Step: 8
Training loss: 0.4059419631958008
Validation loss: 1.7142989539331006

Epoch: 5| Step: 9
Training loss: 0.8617836833000183
Validation loss: 1.7331836710694015

Epoch: 5| Step: 10
Training loss: 0.26338621973991394
Validation loss: 1.7622472381079068

Epoch: 349| Step: 0
Training loss: 0.4647600054740906
Validation loss: 1.7379812245727868

Epoch: 5| Step: 1
Training loss: 0.6514335870742798
Validation loss: 1.7431574982981528

Epoch: 5| Step: 2
Training loss: 0.6537774801254272
Validation loss: 1.7074084640831075

Epoch: 5| Step: 3
Training loss: 0.4131692349910736
Validation loss: 1.7137280638499925

Epoch: 5| Step: 4
Training loss: 0.5674611330032349
Validation loss: 1.6925426221662951

Epoch: 5| Step: 5
Training loss: 0.4231061339378357
Validation loss: 1.703317217929389

Epoch: 5| Step: 6
Training loss: 0.601821780204773
Validation loss: 1.722859005774221

Epoch: 5| Step: 7
Training loss: 0.5052176713943481
Validation loss: 1.739683433245587

Epoch: 5| Step: 8
Training loss: 0.43692547082901
Validation loss: 1.7743961939247705

Epoch: 5| Step: 9
Training loss: 0.49614793062210083
Validation loss: 1.7780965361543881

Epoch: 5| Step: 10
Training loss: 0.7748990654945374
Validation loss: 1.7740777372032084

Epoch: 350| Step: 0
Training loss: 0.5613511204719543
Validation loss: 1.7678682393925165

Epoch: 5| Step: 1
Training loss: 0.4356386065483093
Validation loss: 1.7438127789446103

Epoch: 5| Step: 2
Training loss: 0.3501393496990204
Validation loss: 1.7191654174558577

Epoch: 5| Step: 3
Training loss: 0.31561166048049927
Validation loss: 1.6682628072718138

Epoch: 5| Step: 4
Training loss: 0.4618454575538635
Validation loss: 1.6854765440828057

Epoch: 5| Step: 5
Training loss: 0.4688708186149597
Validation loss: 1.6330191025169947

Epoch: 5| Step: 6
Training loss: 0.8144060373306274
Validation loss: 1.6454026545247724

Epoch: 5| Step: 7
Training loss: 0.4147627353668213
Validation loss: 1.6469763453288744

Epoch: 5| Step: 8
Training loss: 1.0180354118347168
Validation loss: 1.6799088255051644

Epoch: 5| Step: 9
Training loss: 0.48739734292030334
Validation loss: 1.6767918973840692

Epoch: 5| Step: 10
Training loss: 0.5650849342346191
Validation loss: 1.6904629007462533

Epoch: 351| Step: 0
Training loss: 0.4173773229122162
Validation loss: 1.7149703553927842

Epoch: 5| Step: 1
Training loss: 0.5106630325317383
Validation loss: 1.7555896979506298

Epoch: 5| Step: 2
Training loss: 0.4254069924354553
Validation loss: 1.7913085722154187

Epoch: 5| Step: 3
Training loss: 0.39166975021362305
Validation loss: 1.7942740250659246

Epoch: 5| Step: 4
Training loss: 0.630591869354248
Validation loss: 1.7960337656800465

Epoch: 5| Step: 5
Training loss: 0.7210499048233032
Validation loss: 1.7769204839583366

Epoch: 5| Step: 6
Training loss: 0.3793017268180847
Validation loss: 1.7565482611297278

Epoch: 5| Step: 7
Training loss: 0.5489572882652283
Validation loss: 1.724514078068477

Epoch: 5| Step: 8
Training loss: 0.676027238368988
Validation loss: 1.7225472593820224

Epoch: 5| Step: 9
Training loss: 0.5495052337646484
Validation loss: 1.728450830264758

Epoch: 5| Step: 10
Training loss: 0.5236030220985413
Validation loss: 1.72722658547022

Epoch: 352| Step: 0
Training loss: 0.5949557423591614
Validation loss: 1.686135426644356

Epoch: 5| Step: 1
Training loss: 0.3953692317008972
Validation loss: 1.7148828711560977

Epoch: 5| Step: 2
Training loss: 0.49988484382629395
Validation loss: 1.7334971876554592

Epoch: 5| Step: 3
Training loss: 0.6168230772018433
Validation loss: 1.7254852094957907

Epoch: 5| Step: 4
Training loss: 0.753768801689148
Validation loss: 1.7179077004873624

Epoch: 5| Step: 5
Training loss: 0.6089693307876587
Validation loss: 1.7445353692577732

Epoch: 5| Step: 6
Training loss: 0.22032232582569122
Validation loss: 1.757641787170082

Epoch: 5| Step: 7
Training loss: 0.5773085355758667
Validation loss: 1.7305757557192156

Epoch: 5| Step: 8
Training loss: 0.37497785687446594
Validation loss: 1.7439789284941971

Epoch: 5| Step: 9
Training loss: 0.5120782256126404
Validation loss: 1.753947345159387

Epoch: 5| Step: 10
Training loss: 0.3697420060634613
Validation loss: 1.7320251823753439

Epoch: 353| Step: 0
Training loss: 0.5362453460693359
Validation loss: 1.70522222083102

Epoch: 5| Step: 1
Training loss: 0.44881296157836914
Validation loss: 1.7203124505217358

Epoch: 5| Step: 2
Training loss: 0.4015299677848816
Validation loss: 1.686630194546074

Epoch: 5| Step: 3
Training loss: 0.58143150806427
Validation loss: 1.6997014707134617

Epoch: 5| Step: 4
Training loss: 0.5628805756568909
Validation loss: 1.720990668060959

Epoch: 5| Step: 5
Training loss: 0.4625953137874603
Validation loss: 1.7242038070514638

Epoch: 5| Step: 6
Training loss: 0.29272082448005676
Validation loss: 1.681180110541723

Epoch: 5| Step: 7
Training loss: 0.5882278084754944
Validation loss: 1.704966523314035

Epoch: 5| Step: 8
Training loss: 0.3850306570529938
Validation loss: 1.7181405610935663

Epoch: 5| Step: 9
Training loss: 0.2536396384239197
Validation loss: 1.7176806772908857

Epoch: 5| Step: 10
Training loss: 0.7679485082626343
Validation loss: 1.7100990703029018

Epoch: 354| Step: 0
Training loss: 0.3269502520561218
Validation loss: 1.730117864506219

Epoch: 5| Step: 1
Training loss: 0.46736741065979004
Validation loss: 1.738833608165864

Epoch: 5| Step: 2
Training loss: 0.31845822930336
Validation loss: 1.7663106405606834

Epoch: 5| Step: 3
Training loss: 0.4057994782924652
Validation loss: 1.7265727981444328

Epoch: 5| Step: 4
Training loss: 0.45372405648231506
Validation loss: 1.7227306404421407

Epoch: 5| Step: 5
Training loss: 0.6283653974533081
Validation loss: 1.6937625395354403

Epoch: 5| Step: 6
Training loss: 0.6150132417678833
Validation loss: 1.6898822669059999

Epoch: 5| Step: 7
Training loss: 0.6832373738288879
Validation loss: 1.6938761152246946

Epoch: 5| Step: 8
Training loss: 0.5176538228988647
Validation loss: 1.6775531640616796

Epoch: 5| Step: 9
Training loss: 0.34057772159576416
Validation loss: 1.680555373109797

Epoch: 5| Step: 10
Training loss: 0.5759021639823914
Validation loss: 1.679399759538712

Epoch: 355| Step: 0
Training loss: 0.72539883852005
Validation loss: 1.6547939315918954

Epoch: 5| Step: 1
Training loss: 0.5380648374557495
Validation loss: 1.6699051933903848

Epoch: 5| Step: 2
Training loss: 0.09046123176813126
Validation loss: 1.6467085346098869

Epoch: 5| Step: 3
Training loss: 0.383497416973114
Validation loss: 1.6695995689720236

Epoch: 5| Step: 4
Training loss: 0.6486378908157349
Validation loss: 1.6725581628020092

Epoch: 5| Step: 5
Training loss: 0.3328947424888611
Validation loss: 1.6731115297604633

Epoch: 5| Step: 6
Training loss: 0.7385031580924988
Validation loss: 1.6768717650444276

Epoch: 5| Step: 7
Training loss: 0.36293306946754456
Validation loss: 1.7236038510517409

Epoch: 5| Step: 8
Training loss: 0.4338105320930481
Validation loss: 1.7271751255117438

Epoch: 5| Step: 9
Training loss: 0.3738967478275299
Validation loss: 1.75879906710758

Epoch: 5| Step: 10
Training loss: 0.7803454399108887
Validation loss: 1.7877020861512871

Epoch: 356| Step: 0
Training loss: 0.4683005213737488
Validation loss: 1.7584676601553475

Epoch: 5| Step: 1
Training loss: 0.3182999789714813
Validation loss: 1.7640885024942377

Epoch: 5| Step: 2
Training loss: 0.6965703964233398
Validation loss: 1.7102839408382293

Epoch: 5| Step: 3
Training loss: 0.5607082843780518
Validation loss: 1.7071601395965905

Epoch: 5| Step: 4
Training loss: 0.25951436161994934
Validation loss: 1.6895576651378343

Epoch: 5| Step: 5
Training loss: 0.627536416053772
Validation loss: 1.6943337404599754

Epoch: 5| Step: 6
Training loss: 0.3446127474308014
Validation loss: 1.6840935035418438

Epoch: 5| Step: 7
Training loss: 0.6378887891769409
Validation loss: 1.648933014562053

Epoch: 5| Step: 8
Training loss: 0.38455119729042053
Validation loss: 1.6706587678642684

Epoch: 5| Step: 9
Training loss: 0.6211905479431152
Validation loss: 1.6580123209184217

Epoch: 5| Step: 10
Training loss: 0.1933409720659256
Validation loss: 1.6740407482270272

Epoch: 357| Step: 0
Training loss: 0.4175899922847748
Validation loss: 1.6934775139695855

Epoch: 5| Step: 1
Training loss: 0.31386399269104004
Validation loss: 1.7055880356860418

Epoch: 5| Step: 2
Training loss: 0.4782913327217102
Validation loss: 1.7105063135905931

Epoch: 5| Step: 3
Training loss: 0.43427038192749023
Validation loss: 1.721681720467024

Epoch: 5| Step: 4
Training loss: 0.4673495888710022
Validation loss: 1.7249145674449142

Epoch: 5| Step: 5
Training loss: 0.4252270758152008
Validation loss: 1.6700511324790217

Epoch: 5| Step: 6
Training loss: 0.6826573610305786
Validation loss: 1.6905619893022763

Epoch: 5| Step: 7
Training loss: 0.38604915142059326
Validation loss: 1.6506808432199622

Epoch: 5| Step: 8
Training loss: 0.4749508500099182
Validation loss: 1.6710564500542098

Epoch: 5| Step: 9
Training loss: 0.6986978650093079
Validation loss: 1.6615102239834365

Epoch: 5| Step: 10
Training loss: 0.405788779258728
Validation loss: 1.7205407363112255

Epoch: 358| Step: 0
Training loss: 0.35977092385292053
Validation loss: 1.7178155452974382

Epoch: 5| Step: 1
Training loss: 0.7418421506881714
Validation loss: 1.7451455900746007

Epoch: 5| Step: 2
Training loss: 0.6106457710266113
Validation loss: 1.7332116012932153

Epoch: 5| Step: 3
Training loss: 0.24111433327198029
Validation loss: 1.7522159878925612

Epoch: 5| Step: 4
Training loss: 0.312916100025177
Validation loss: 1.719010127488003

Epoch: 5| Step: 5
Training loss: 0.3665578365325928
Validation loss: 1.714869923489068

Epoch: 5| Step: 6
Training loss: 0.23564107716083527
Validation loss: 1.7163923581441243

Epoch: 5| Step: 7
Training loss: 0.7746961116790771
Validation loss: 1.711146366211676

Epoch: 5| Step: 8
Training loss: 0.6309541463851929
Validation loss: 1.684217599130446

Epoch: 5| Step: 9
Training loss: 0.5468274354934692
Validation loss: 1.669041137541494

Epoch: 5| Step: 10
Training loss: 0.4171459972858429
Validation loss: 1.6634501346977808

Epoch: 359| Step: 0
Training loss: 0.5650519132614136
Validation loss: 1.6753152775508102

Epoch: 5| Step: 1
Training loss: 0.17234715819358826
Validation loss: 1.6810257986027708

Epoch: 5| Step: 2
Training loss: 0.5722312927246094
Validation loss: 1.6923578323856476

Epoch: 5| Step: 3
Training loss: 0.5654870867729187
Validation loss: 1.6930170853932698

Epoch: 5| Step: 4
Training loss: 0.44902634620666504
Validation loss: 1.7125457409889466

Epoch: 5| Step: 5
Training loss: 0.541679322719574
Validation loss: 1.7576532812528713

Epoch: 5| Step: 6
Training loss: 0.3553124666213989
Validation loss: 1.7476592345904278

Epoch: 5| Step: 7
Training loss: 0.4040988087654114
Validation loss: 1.7609371754430956

Epoch: 5| Step: 8
Training loss: 0.49620017409324646
Validation loss: 1.7756591279019591

Epoch: 5| Step: 9
Training loss: 0.5380120873451233
Validation loss: 1.7618553074457313

Epoch: 5| Step: 10
Training loss: 0.3825748562812805
Validation loss: 1.768806638256196

Epoch: 360| Step: 0
Training loss: 0.43136247992515564
Validation loss: 1.7660426555141326

Epoch: 5| Step: 1
Training loss: 0.19606785476207733
Validation loss: 1.7205102212967411

Epoch: 5| Step: 2
Training loss: 0.39207515120506287
Validation loss: 1.7218037894977036

Epoch: 5| Step: 3
Training loss: 0.3863036036491394
Validation loss: 1.7193932315354705

Epoch: 5| Step: 4
Training loss: 0.49499160051345825
Validation loss: 1.7106121278578235

Epoch: 5| Step: 5
Training loss: 0.35636040568351746
Validation loss: 1.7043454877791866

Epoch: 5| Step: 6
Training loss: 0.8113389015197754
Validation loss: 1.7160271649719567

Epoch: 5| Step: 7
Training loss: 0.5534554719924927
Validation loss: 1.7112695401714695

Epoch: 5| Step: 8
Training loss: 0.7248114347457886
Validation loss: 1.7345741756500737

Epoch: 5| Step: 9
Training loss: 0.46566787362098694
Validation loss: 1.7558605030018797

Epoch: 5| Step: 10
Training loss: 0.3700653910636902
Validation loss: 1.7303942429122103

Epoch: 361| Step: 0
Training loss: 0.39504140615463257
Validation loss: 1.7107672063253259

Epoch: 5| Step: 1
Training loss: 0.31129613518714905
Validation loss: 1.7035414518848542

Epoch: 5| Step: 2
Training loss: 0.8013564348220825
Validation loss: 1.6855682455083376

Epoch: 5| Step: 3
Training loss: 0.3676210045814514
Validation loss: 1.7265991408337829

Epoch: 5| Step: 4
Training loss: 0.50490802526474
Validation loss: 1.7223380906607515

Epoch: 5| Step: 5
Training loss: 0.4061830937862396
Validation loss: 1.6992700215308898

Epoch: 5| Step: 6
Training loss: 0.3166210651397705
Validation loss: 1.7529034037743845

Epoch: 5| Step: 7
Training loss: 0.40778738260269165
Validation loss: 1.7248292930664555

Epoch: 5| Step: 8
Training loss: 0.3494921326637268
Validation loss: 1.6958318897472915

Epoch: 5| Step: 9
Training loss: 0.6206458210945129
Validation loss: 1.6664243616083616

Epoch: 5| Step: 10
Training loss: 0.46412748098373413
Validation loss: 1.670599450347244

Epoch: 362| Step: 0
Training loss: 0.4804556965827942
Validation loss: 1.666206709800228

Epoch: 5| Step: 1
Training loss: 0.432300329208374
Validation loss: 1.65987084116987

Epoch: 5| Step: 2
Training loss: 0.6426053047180176
Validation loss: 1.6557562940864152

Epoch: 5| Step: 3
Training loss: 0.2775208652019501
Validation loss: 1.6786578150205715

Epoch: 5| Step: 4
Training loss: 0.3089943826198578
Validation loss: 1.6993064611188826

Epoch: 5| Step: 5
Training loss: 0.5417129397392273
Validation loss: 1.7248531438971078

Epoch: 5| Step: 6
Training loss: 0.4808504581451416
Validation loss: 1.7167985644391788

Epoch: 5| Step: 7
Training loss: 0.3783400058746338
Validation loss: 1.7324396141113774

Epoch: 5| Step: 8
Training loss: 0.2542164623737335
Validation loss: 1.7229256322306972

Epoch: 5| Step: 9
Training loss: 0.6147195100784302
Validation loss: 1.7450119397973503

Epoch: 5| Step: 10
Training loss: 0.4561436176300049
Validation loss: 1.7386331289045271

Epoch: 363| Step: 0
Training loss: 0.29585808515548706
Validation loss: 1.7276019562957108

Epoch: 5| Step: 1
Training loss: 0.3781934678554535
Validation loss: 1.7205412798030402

Epoch: 5| Step: 2
Training loss: 0.668642520904541
Validation loss: 1.7164699018642466

Epoch: 5| Step: 3
Training loss: 0.55263751745224
Validation loss: 1.688968449510554

Epoch: 5| Step: 4
Training loss: 0.4341832995414734
Validation loss: 1.6885813820746638

Epoch: 5| Step: 5
Training loss: 0.5444835424423218
Validation loss: 1.6779424323830554

Epoch: 5| Step: 6
Training loss: 0.3363513946533203
Validation loss: 1.681656337553455

Epoch: 5| Step: 7
Training loss: 0.3716858923435211
Validation loss: 1.6571852237947526

Epoch: 5| Step: 8
Training loss: 0.3907198905944824
Validation loss: 1.710134357534429

Epoch: 5| Step: 9
Training loss: 0.487170547246933
Validation loss: 1.6796467150411298

Epoch: 5| Step: 10
Training loss: 0.45595163106918335
Validation loss: 1.7099643612420687

Epoch: 364| Step: 0
Training loss: 0.646634042263031
Validation loss: 1.693927203455279

Epoch: 5| Step: 1
Training loss: 0.3639427721500397
Validation loss: 1.6906489479926325

Epoch: 5| Step: 2
Training loss: 0.5131651163101196
Validation loss: 1.7011638892594205

Epoch: 5| Step: 3
Training loss: 0.47682562470436096
Validation loss: 1.7219502810508973

Epoch: 5| Step: 4
Training loss: 0.2861376106739044
Validation loss: 1.6785072126696188

Epoch: 5| Step: 5
Training loss: 0.7699517011642456
Validation loss: 1.704023527842696

Epoch: 5| Step: 6
Training loss: 0.31626302003860474
Validation loss: 1.6903596629378617

Epoch: 5| Step: 7
Training loss: 0.3977597951889038
Validation loss: 1.6919044474119782

Epoch: 5| Step: 8
Training loss: 0.41862717270851135
Validation loss: 1.6853553928354734

Epoch: 5| Step: 9
Training loss: 0.34615620970726013
Validation loss: 1.7051002710096297

Epoch: 5| Step: 10
Training loss: 0.17259936034679413
Validation loss: 1.7685582727514289

Epoch: 365| Step: 0
Training loss: 0.42085084319114685
Validation loss: 1.7698770133397912

Epoch: 5| Step: 1
Training loss: 0.2870451807975769
Validation loss: 1.7566184587376092

Epoch: 5| Step: 2
Training loss: 0.6098136305809021
Validation loss: 1.7381025155385335

Epoch: 5| Step: 3
Training loss: 0.31310850381851196
Validation loss: 1.7220612366994221

Epoch: 5| Step: 4
Training loss: 0.22198648750782013
Validation loss: 1.691341156600624

Epoch: 5| Step: 5
Training loss: 0.38120660185813904
Validation loss: 1.706112648851128

Epoch: 5| Step: 6
Training loss: 0.5525054931640625
Validation loss: 1.6592166321251982

Epoch: 5| Step: 7
Training loss: 0.43398982286453247
Validation loss: 1.6917209958517423

Epoch: 5| Step: 8
Training loss: 0.9027204513549805
Validation loss: 1.6944273966614918

Epoch: 5| Step: 9
Training loss: 0.2145334929227829
Validation loss: 1.6615146718999392

Epoch: 5| Step: 10
Training loss: 0.3578469455242157
Validation loss: 1.698312226162162

Epoch: 366| Step: 0
Training loss: 0.5900819897651672
Validation loss: 1.6624042731459423

Epoch: 5| Step: 1
Training loss: 0.13990432024002075
Validation loss: 1.659344119410361

Epoch: 5| Step: 2
Training loss: 0.38527020812034607
Validation loss: 1.6362058770272039

Epoch: 5| Step: 3
Training loss: 0.4330490231513977
Validation loss: 1.6161226021346224

Epoch: 5| Step: 4
Training loss: 0.5202630758285522
Validation loss: 1.5916425169155162

Epoch: 5| Step: 5
Training loss: 0.3676641285419464
Validation loss: 1.5972091882459578

Epoch: 5| Step: 6
Training loss: 0.2660831809043884
Validation loss: 1.6256326469041968

Epoch: 5| Step: 7
Training loss: 0.6282336711883545
Validation loss: 1.6238646673899826

Epoch: 5| Step: 8
Training loss: 0.5385164022445679
Validation loss: 1.6837224575781053

Epoch: 5| Step: 9
Training loss: 0.30810514092445374
Validation loss: 1.7069846096859183

Epoch: 5| Step: 10
Training loss: 0.468814492225647
Validation loss: 1.690744871734291

Epoch: 367| Step: 0
Training loss: 0.7045050859451294
Validation loss: 1.6706147924546273

Epoch: 5| Step: 1
Training loss: 0.4133991301059723
Validation loss: 1.6939432826093448

Epoch: 5| Step: 2
Training loss: 0.340707391500473
Validation loss: 1.6948547632463518

Epoch: 5| Step: 3
Training loss: 0.38916176557540894
Validation loss: 1.7248090531236382

Epoch: 5| Step: 4
Training loss: 0.34351587295532227
Validation loss: 1.6965972902954265

Epoch: 5| Step: 5
Training loss: 0.6078382730484009
Validation loss: 1.6888849863442041

Epoch: 5| Step: 6
Training loss: 0.28280359506607056
Validation loss: 1.6993142481773131

Epoch: 5| Step: 7
Training loss: 0.46812376379966736
Validation loss: 1.709184297951319

Epoch: 5| Step: 8
Training loss: 0.3503083288669586
Validation loss: 1.72075665638011

Epoch: 5| Step: 9
Training loss: 0.3568878173828125
Validation loss: 1.7352043531274284

Epoch: 5| Step: 10
Training loss: 0.2686455249786377
Validation loss: 1.7442967378964989

Epoch: 368| Step: 0
Training loss: 0.41527247428894043
Validation loss: 1.7670250477329377

Epoch: 5| Step: 1
Training loss: 0.40636324882507324
Validation loss: 1.7581924956331971

Epoch: 5| Step: 2
Training loss: 0.40577226877212524
Validation loss: 1.731206928530047

Epoch: 5| Step: 3
Training loss: 0.4433842599391937
Validation loss: 1.711549042373575

Epoch: 5| Step: 4
Training loss: 0.4579768776893616
Validation loss: 1.7290183908195906

Epoch: 5| Step: 5
Training loss: 0.4896894097328186
Validation loss: 1.690617580567637

Epoch: 5| Step: 6
Training loss: 0.34168583154678345
Validation loss: 1.6778018692488312

Epoch: 5| Step: 7
Training loss: 0.4396969676017761
Validation loss: 1.6679307542821413

Epoch: 5| Step: 8
Training loss: 0.6881535649299622
Validation loss: 1.6908794590221938

Epoch: 5| Step: 9
Training loss: 0.35391148924827576
Validation loss: 1.7067081505252468

Epoch: 5| Step: 10
Training loss: 0.24621117115020752
Validation loss: 1.7183066337339339

Epoch: 369| Step: 0
Training loss: 0.743437647819519
Validation loss: 1.7253776455438266

Epoch: 5| Step: 1
Training loss: 0.519802451133728
Validation loss: 1.6896811640390785

Epoch: 5| Step: 2
Training loss: 0.28130945563316345
Validation loss: 1.7078239148662937

Epoch: 5| Step: 3
Training loss: 0.25374680757522583
Validation loss: 1.697208103313241

Epoch: 5| Step: 4
Training loss: 0.3315763771533966
Validation loss: 1.6386969897054857

Epoch: 5| Step: 5
Training loss: 0.5186207294464111
Validation loss: 1.6509922999207691

Epoch: 5| Step: 6
Training loss: 0.21822433173656464
Validation loss: 1.6731059730693858

Epoch: 5| Step: 7
Training loss: 0.5040175914764404
Validation loss: 1.6796221771547872

Epoch: 5| Step: 8
Training loss: 0.40554553270339966
Validation loss: 1.6584212267270653

Epoch: 5| Step: 9
Training loss: 0.49241819977760315
Validation loss: 1.639717641697135

Epoch: 5| Step: 10
Training loss: 0.40146756172180176
Validation loss: 1.647156935866161

Epoch: 370| Step: 0
Training loss: 0.3763978183269501
Validation loss: 1.6448383113389373

Epoch: 5| Step: 1
Training loss: 0.44329842925071716
Validation loss: 1.6653576897036644

Epoch: 5| Step: 2
Training loss: 0.3860515058040619
Validation loss: 1.6541912965877081

Epoch: 5| Step: 3
Training loss: 0.15874965488910675
Validation loss: 1.6332716608560214

Epoch: 5| Step: 4
Training loss: 0.4076533317565918
Validation loss: 1.6666718490662114

Epoch: 5| Step: 5
Training loss: 0.6789060831069946
Validation loss: 1.668655918490502

Epoch: 5| Step: 6
Training loss: 0.4080114960670471
Validation loss: 1.7126222707891976

Epoch: 5| Step: 7
Training loss: 0.33290356397628784
Validation loss: 1.713449014130459

Epoch: 5| Step: 8
Training loss: 0.5429338216781616
Validation loss: 1.699219202482572

Epoch: 5| Step: 9
Training loss: 0.3983546793460846
Validation loss: 1.669972849148576

Epoch: 5| Step: 10
Training loss: 0.4944818615913391
Validation loss: 1.6488259582109348

Epoch: 371| Step: 0
Training loss: 0.24911586940288544
Validation loss: 1.6324994461510771

Epoch: 5| Step: 1
Training loss: 0.3737694323062897
Validation loss: 1.6586606938351867

Epoch: 5| Step: 2
Training loss: 0.42459017038345337
Validation loss: 1.6539747663723525

Epoch: 5| Step: 3
Training loss: 0.5386687517166138
Validation loss: 1.634529217596977

Epoch: 5| Step: 4
Training loss: 0.41934823989868164
Validation loss: 1.6493540976637153

Epoch: 5| Step: 5
Training loss: 0.4011836647987366
Validation loss: 1.6699206226615495

Epoch: 5| Step: 6
Training loss: 0.5280560255050659
Validation loss: 1.676172105214929

Epoch: 5| Step: 7
Training loss: 0.32211247086524963
Validation loss: 1.6854694081890969

Epoch: 5| Step: 8
Training loss: 0.5038599371910095
Validation loss: 1.681658798648465

Epoch: 5| Step: 9
Training loss: 0.3570900559425354
Validation loss: 1.6742381934196717

Epoch: 5| Step: 10
Training loss: 0.5576021671295166
Validation loss: 1.6668878806534635

Epoch: 372| Step: 0
Training loss: 0.3855387270450592
Validation loss: 1.6509397081149522

Epoch: 5| Step: 1
Training loss: 0.25313788652420044
Validation loss: 1.6164378594326716

Epoch: 5| Step: 2
Training loss: 0.29185065627098083
Validation loss: 1.6363481398551696

Epoch: 5| Step: 3
Training loss: 0.4388795793056488
Validation loss: 1.6403619807253602

Epoch: 5| Step: 4
Training loss: 0.5157912373542786
Validation loss: 1.6453160188531364

Epoch: 5| Step: 5
Training loss: 0.5284380912780762
Validation loss: 1.6530539207561041

Epoch: 5| Step: 6
Training loss: 0.4113802909851074
Validation loss: 1.6652489144315001

Epoch: 5| Step: 7
Training loss: 0.34812965989112854
Validation loss: 1.6225041202319566

Epoch: 5| Step: 8
Training loss: 0.642615795135498
Validation loss: 1.6289075548930834

Epoch: 5| Step: 9
Training loss: 0.5988004207611084
Validation loss: 1.6007698184700423

Epoch: 5| Step: 10
Training loss: 0.27421632409095764
Validation loss: 1.6145597683486117

Epoch: 373| Step: 0
Training loss: 0.5535184741020203
Validation loss: 1.6100447921342746

Epoch: 5| Step: 1
Training loss: 0.45612651109695435
Validation loss: 1.6441181718662221

Epoch: 5| Step: 2
Training loss: 0.47715798020362854
Validation loss: 1.6615931987762451

Epoch: 5| Step: 3
Training loss: 0.4797689914703369
Validation loss: 1.626371027320944

Epoch: 5| Step: 4
Training loss: 0.3538826107978821
Validation loss: 1.663668961935146

Epoch: 5| Step: 5
Training loss: 0.35595861077308655
Validation loss: 1.6747126643375685

Epoch: 5| Step: 6
Training loss: 0.32863858342170715
Validation loss: 1.6620698487886818

Epoch: 5| Step: 7
Training loss: 0.30420511960983276
Validation loss: 1.6946672367793258

Epoch: 5| Step: 8
Training loss: 0.5425491333007812
Validation loss: 1.6776072761063934

Epoch: 5| Step: 9
Training loss: 0.3022800087928772
Validation loss: 1.6634630054555914

Epoch: 5| Step: 10
Training loss: 0.4169160723686218
Validation loss: 1.665490492697685

Epoch: 374| Step: 0
Training loss: 0.269477903842926
Validation loss: 1.6577215143429336

Epoch: 5| Step: 1
Training loss: 0.41782617568969727
Validation loss: 1.6667486493305494

Epoch: 5| Step: 2
Training loss: 0.5136491060256958
Validation loss: 1.6881925034266647

Epoch: 5| Step: 3
Training loss: 0.5123622417449951
Validation loss: 1.6897775485951414

Epoch: 5| Step: 4
Training loss: 0.5458025932312012
Validation loss: 1.6801430127953971

Epoch: 5| Step: 5
Training loss: 0.4675932824611664
Validation loss: 1.657326885448989

Epoch: 5| Step: 6
Training loss: 0.35137438774108887
Validation loss: 1.6497828986055108

Epoch: 5| Step: 7
Training loss: 0.34889763593673706
Validation loss: 1.6812316166457308

Epoch: 5| Step: 8
Training loss: 0.4084934592247009
Validation loss: 1.6682413983088669

Epoch: 5| Step: 9
Training loss: 0.5935384035110474
Validation loss: 1.6988172890037618

Epoch: 5| Step: 10
Training loss: 0.20393197238445282
Validation loss: 1.713797789747997

Epoch: 375| Step: 0
Training loss: 0.4426599442958832
Validation loss: 1.7017741331490137

Epoch: 5| Step: 1
Training loss: 0.4597717821598053
Validation loss: 1.705674232975129

Epoch: 5| Step: 2
Training loss: 0.6472689509391785
Validation loss: 1.718533323657128

Epoch: 5| Step: 3
Training loss: 0.6625984907150269
Validation loss: 1.6844341819004347

Epoch: 5| Step: 4
Training loss: 0.3350948691368103
Validation loss: 1.660688200304585

Epoch: 5| Step: 5
Training loss: 0.16790349781513214
Validation loss: 1.6731359035738054

Epoch: 5| Step: 6
Training loss: 0.2990751266479492
Validation loss: 1.658297945094365

Epoch: 5| Step: 7
Training loss: 0.4832932949066162
Validation loss: 1.6337455126547045

Epoch: 5| Step: 8
Training loss: 0.3252835273742676
Validation loss: 1.6221218403949533

Epoch: 5| Step: 9
Training loss: 0.38259589672088623
Validation loss: 1.6517898485224733

Epoch: 5| Step: 10
Training loss: 0.38665682077407837
Validation loss: 1.6405984047920472

Epoch: 376| Step: 0
Training loss: 0.42966222763061523
Validation loss: 1.6205095853856815

Epoch: 5| Step: 1
Training loss: 0.3028355538845062
Validation loss: 1.6420735184864332

Epoch: 5| Step: 2
Training loss: 0.5168858766555786
Validation loss: 1.6891782270964755

Epoch: 5| Step: 3
Training loss: 0.4671567380428314
Validation loss: 1.6664077389624812

Epoch: 5| Step: 4
Training loss: 0.4690878987312317
Validation loss: 1.707303003598285

Epoch: 5| Step: 5
Training loss: 0.3567582666873932
Validation loss: 1.671723670856927

Epoch: 5| Step: 6
Training loss: 0.35831889510154724
Validation loss: 1.6677816926792104

Epoch: 5| Step: 7
Training loss: 0.6586509346961975
Validation loss: 1.6628167142150223

Epoch: 5| Step: 8
Training loss: 0.12243153899908066
Validation loss: 1.6212506319886895

Epoch: 5| Step: 9
Training loss: 0.38953158259391785
Validation loss: 1.6378906606346049

Epoch: 5| Step: 10
Training loss: 0.4008204936981201
Validation loss: 1.63540361004491

Epoch: 377| Step: 0
Training loss: 0.4956197142601013
Validation loss: 1.6457499457943825

Epoch: 5| Step: 1
Training loss: 0.655803382396698
Validation loss: 1.6631691455841064

Epoch: 5| Step: 2
Training loss: 0.6086567044258118
Validation loss: 1.6932051848339778

Epoch: 5| Step: 3
Training loss: 0.3435188829898834
Validation loss: 1.7050406586739324

Epoch: 5| Step: 4
Training loss: 0.5127931833267212
Validation loss: 1.7311310742491035

Epoch: 5| Step: 5
Training loss: 0.35744714736938477
Validation loss: 1.7013872964407808

Epoch: 5| Step: 6
Training loss: 0.4203411042690277
Validation loss: 1.7165659448151946

Epoch: 5| Step: 7
Training loss: 0.304131418466568
Validation loss: 1.741875688234965

Epoch: 5| Step: 8
Training loss: 0.3760637640953064
Validation loss: 1.7461652422464022

Epoch: 5| Step: 9
Training loss: 0.16631469130516052
Validation loss: 1.7422595101018106

Epoch: 5| Step: 10
Training loss: 0.4403904974460602
Validation loss: 1.749875085328215

Epoch: 378| Step: 0
Training loss: 0.20556840300559998
Validation loss: 1.7378323552429036

Epoch: 5| Step: 1
Training loss: 0.22336645424365997
Validation loss: 1.712197470408614

Epoch: 5| Step: 2
Training loss: 0.43236058950424194
Validation loss: 1.7042709396731468

Epoch: 5| Step: 3
Training loss: 0.4525594711303711
Validation loss: 1.6971829514349661

Epoch: 5| Step: 4
Training loss: 0.34560197591781616
Validation loss: 1.6944756430964316

Epoch: 5| Step: 5
Training loss: 0.42362889647483826
Validation loss: 1.6682439619495022

Epoch: 5| Step: 6
Training loss: 0.3622492253780365
Validation loss: 1.6332374964990923

Epoch: 5| Step: 7
Training loss: 0.6434844732284546
Validation loss: 1.6102559925407491

Epoch: 5| Step: 8
Training loss: 0.1958782970905304
Validation loss: 1.5857315460840862

Epoch: 5| Step: 9
Training loss: 0.5367456674575806
Validation loss: 1.583841989117284

Epoch: 5| Step: 10
Training loss: 0.5028675198554993
Validation loss: 1.5757449064203488

Epoch: 379| Step: 0
Training loss: 0.27369439601898193
Validation loss: 1.598759376874534

Epoch: 5| Step: 1
Training loss: 0.3011864721775055
Validation loss: 1.5917866800421028

Epoch: 5| Step: 2
Training loss: 0.5652725696563721
Validation loss: 1.6109282316700104

Epoch: 5| Step: 3
Training loss: 0.48707860708236694
Validation loss: 1.6375163973018687

Epoch: 5| Step: 4
Training loss: 0.4477235674858093
Validation loss: 1.6435027660862092

Epoch: 5| Step: 5
Training loss: 0.38295164704322815
Validation loss: 1.7029131497106245

Epoch: 5| Step: 6
Training loss: 0.4815586507320404
Validation loss: 1.6691618670699417

Epoch: 5| Step: 7
Training loss: 0.22346897423267365
Validation loss: 1.6473470977557603

Epoch: 5| Step: 8
Training loss: 0.6214839220046997
Validation loss: 1.6247701862806916

Epoch: 5| Step: 9
Training loss: 0.2629757523536682
Validation loss: 1.6190900712884881

Epoch: 5| Step: 10
Training loss: 0.3804272711277008
Validation loss: 1.5865019188132337

Epoch: 380| Step: 0
Training loss: 0.4709106981754303
Validation loss: 1.59804073456795

Epoch: 5| Step: 1
Training loss: 0.41982656717300415
Validation loss: 1.6154397623513335

Epoch: 5| Step: 2
Training loss: 0.14912831783294678
Validation loss: 1.6279536716399654

Epoch: 5| Step: 3
Training loss: 0.4378352761268616
Validation loss: 1.6149723850270754

Epoch: 5| Step: 4
Training loss: 0.353291392326355
Validation loss: 1.6490824568656184

Epoch: 5| Step: 5
Training loss: 0.2415381669998169
Validation loss: 1.6660480896631877

Epoch: 5| Step: 6
Training loss: 0.5175287127494812
Validation loss: 1.6484008040479434

Epoch: 5| Step: 7
Training loss: 0.3027903139591217
Validation loss: 1.6442691267177623

Epoch: 5| Step: 8
Training loss: 0.3500947654247284
Validation loss: 1.6685658078039847

Epoch: 5| Step: 9
Training loss: 0.330890417098999
Validation loss: 1.6617279027097969

Epoch: 5| Step: 10
Training loss: 0.5489403605461121
Validation loss: 1.6889308934570642

Epoch: 381| Step: 0
Training loss: 0.33450523018836975
Validation loss: 1.697724485910067

Epoch: 5| Step: 1
Training loss: 0.3949817717075348
Validation loss: 1.6862391951263591

Epoch: 5| Step: 2
Training loss: 0.5668939352035522
Validation loss: 1.6863840421040852

Epoch: 5| Step: 3
Training loss: 0.3512115478515625
Validation loss: 1.6445996774140226

Epoch: 5| Step: 4
Training loss: 0.35899966955184937
Validation loss: 1.6519593769504177

Epoch: 5| Step: 5
Training loss: 0.3841606378555298
Validation loss: 1.61702686484142

Epoch: 5| Step: 6
Training loss: 0.1619247943162918
Validation loss: 1.6002777417500813

Epoch: 5| Step: 7
Training loss: 0.2691591680049896
Validation loss: 1.608842756158562

Epoch: 5| Step: 8
Training loss: 0.323121577501297
Validation loss: 1.5797285238901775

Epoch: 5| Step: 9
Training loss: 0.41502222418785095
Validation loss: 1.6058034435395272

Epoch: 5| Step: 10
Training loss: 0.7225509285926819
Validation loss: 1.6178741544805548

Epoch: 382| Step: 0
Training loss: 0.257030189037323
Validation loss: 1.638111981012488

Epoch: 5| Step: 1
Training loss: 0.35703685879707336
Validation loss: 1.6452452854443622

Epoch: 5| Step: 2
Training loss: 0.3710625171661377
Validation loss: 1.6766425973625594

Epoch: 5| Step: 3
Training loss: 0.3516457974910736
Validation loss: 1.6879120731866488

Epoch: 5| Step: 4
Training loss: 0.24664239585399628
Validation loss: 1.672299429934512

Epoch: 5| Step: 5
Training loss: 0.6046231389045715
Validation loss: 1.661509798419091

Epoch: 5| Step: 6
Training loss: 0.3563443124294281
Validation loss: 1.6712495511577976

Epoch: 5| Step: 7
Training loss: 0.3485221862792969
Validation loss: 1.6352844622827345

Epoch: 5| Step: 8
Training loss: 0.2606469690799713
Validation loss: 1.6483856836954753

Epoch: 5| Step: 9
Training loss: 0.36847543716430664
Validation loss: 1.6340998372723978

Epoch: 5| Step: 10
Training loss: 0.6084884405136108
Validation loss: 1.6339497848223614

Epoch: 383| Step: 0
Training loss: 0.48158159852027893
Validation loss: 1.630611995215057

Epoch: 5| Step: 1
Training loss: 0.26154249906539917
Validation loss: 1.6130800125419453

Epoch: 5| Step: 2
Training loss: 0.3050634264945984
Validation loss: 1.607440629313069

Epoch: 5| Step: 3
Training loss: 0.2766396999359131
Validation loss: 1.609716546150946

Epoch: 5| Step: 4
Training loss: 0.3831512928009033
Validation loss: 1.6458905678923412

Epoch: 5| Step: 5
Training loss: 0.37075597047805786
Validation loss: 1.6284092985173708

Epoch: 5| Step: 6
Training loss: 0.44013500213623047
Validation loss: 1.624631581767913

Epoch: 5| Step: 7
Training loss: 0.412428617477417
Validation loss: 1.6487758185273858

Epoch: 5| Step: 8
Training loss: 0.47957053780555725
Validation loss: 1.6605412601142802

Epoch: 5| Step: 9
Training loss: 0.14760710299015045
Validation loss: 1.6966115819510592

Epoch: 5| Step: 10
Training loss: 0.4653993844985962
Validation loss: 1.682184385996993

Epoch: 384| Step: 0
Training loss: 0.34086164832115173
Validation loss: 1.6937068457244544

Epoch: 5| Step: 1
Training loss: 0.4347537159919739
Validation loss: 1.6624361456081431

Epoch: 5| Step: 2
Training loss: 0.6736330389976501
Validation loss: 1.6370394255525322

Epoch: 5| Step: 3
Training loss: 0.3026027977466583
Validation loss: 1.6082386675701346

Epoch: 5| Step: 4
Training loss: 0.23347285389900208
Validation loss: 1.6200274331595308

Epoch: 5| Step: 5
Training loss: 0.2027343511581421
Validation loss: 1.6206984750686153

Epoch: 5| Step: 6
Training loss: 0.2761325240135193
Validation loss: 1.6129342150944534

Epoch: 5| Step: 7
Training loss: 0.41945695877075195
Validation loss: 1.6401371930235176

Epoch: 5| Step: 8
Training loss: 0.38614165782928467
Validation loss: 1.6224204365925123

Epoch: 5| Step: 9
Training loss: 0.4041406512260437
Validation loss: 1.6665917711873208

Epoch: 5| Step: 10
Training loss: 0.38759365677833557
Validation loss: 1.7141830062353483

Epoch: 385| Step: 0
Training loss: 0.5193411707878113
Validation loss: 1.722505877094884

Epoch: 5| Step: 1
Training loss: 0.4087781012058258
Validation loss: 1.7178805284602667

Epoch: 5| Step: 2
Training loss: 0.4927242398262024
Validation loss: 1.7119647187571372

Epoch: 5| Step: 3
Training loss: 0.2522704005241394
Validation loss: 1.65663900298457

Epoch: 5| Step: 4
Training loss: 0.4625817835330963
Validation loss: 1.651312433263307

Epoch: 5| Step: 5
Training loss: 0.2578846514225006
Validation loss: 1.5898280271919825

Epoch: 5| Step: 6
Training loss: 0.2712237238883972
Validation loss: 1.6143678798470447

Epoch: 5| Step: 7
Training loss: 0.3420296907424927
Validation loss: 1.5923121244676652

Epoch: 5| Step: 8
Training loss: 0.3653278648853302
Validation loss: 1.5946946272286036

Epoch: 5| Step: 9
Training loss: 0.37066173553466797
Validation loss: 1.5984273905395179

Epoch: 5| Step: 10
Training loss: 0.5288187861442566
Validation loss: 1.5970390086532922

Epoch: 386| Step: 0
Training loss: 0.32750457525253296
Validation loss: 1.6343638153486355

Epoch: 5| Step: 1
Training loss: 0.2753467261791229
Validation loss: 1.6366057011388964

Epoch: 5| Step: 2
Training loss: 0.2537986636161804
Validation loss: 1.6374122327373875

Epoch: 5| Step: 3
Training loss: 0.3872396945953369
Validation loss: 1.663061300913493

Epoch: 5| Step: 4
Training loss: 0.2310108244419098
Validation loss: 1.6748193617789977

Epoch: 5| Step: 5
Training loss: 0.31301456689834595
Validation loss: 1.673445346534893

Epoch: 5| Step: 6
Training loss: 0.4315252900123596
Validation loss: 1.6656899670118928

Epoch: 5| Step: 7
Training loss: 0.444277822971344
Validation loss: 1.6234977142785185

Epoch: 5| Step: 8
Training loss: 0.5168340802192688
Validation loss: 1.611235854446247

Epoch: 5| Step: 9
Training loss: 0.43521127104759216
Validation loss: 1.6214458352775984

Epoch: 5| Step: 10
Training loss: 0.4033207595348358
Validation loss: 1.6189800808506627

Epoch: 387| Step: 0
Training loss: 0.4703037142753601
Validation loss: 1.6217038375075146

Epoch: 5| Step: 1
Training loss: 0.5550103187561035
Validation loss: 1.6354137005344513

Epoch: 5| Step: 2
Training loss: 0.20016451179981232
Validation loss: 1.6727300395247757

Epoch: 5| Step: 3
Training loss: 0.39651137590408325
Validation loss: 1.6485466418727752

Epoch: 5| Step: 4
Training loss: 0.32741403579711914
Validation loss: 1.6525884982078307

Epoch: 5| Step: 5
Training loss: 0.48860234022140503
Validation loss: 1.6371945168382378

Epoch: 5| Step: 6
Training loss: 0.2853702902793884
Validation loss: 1.6161680580467306

Epoch: 5| Step: 7
Training loss: 0.16777633130550385
Validation loss: 1.6342284012866277

Epoch: 5| Step: 8
Training loss: 0.3508504331111908
Validation loss: 1.633058205727608

Epoch: 5| Step: 9
Training loss: 0.19032786786556244
Validation loss: 1.6140179864821895

Epoch: 5| Step: 10
Training loss: 0.4917876422405243
Validation loss: 1.6577883292269964

Epoch: 388| Step: 0
Training loss: 0.242862269282341
Validation loss: 1.6690417810152935

Epoch: 5| Step: 1
Training loss: 0.2941942811012268
Validation loss: 1.6925370808570617

Epoch: 5| Step: 2
Training loss: 0.5917214155197144
Validation loss: 1.6842889849857619

Epoch: 5| Step: 3
Training loss: 0.1837598979473114
Validation loss: 1.6939883693572013

Epoch: 5| Step: 4
Training loss: 0.2934841513633728
Validation loss: 1.685626320941474

Epoch: 5| Step: 5
Training loss: 0.34960049390792847
Validation loss: 1.6434356333107076

Epoch: 5| Step: 6
Training loss: 0.47713232040405273
Validation loss: 1.6282421106933265

Epoch: 5| Step: 7
Training loss: 0.4278586804866791
Validation loss: 1.6139618978705457

Epoch: 5| Step: 8
Training loss: 0.3602316975593567
Validation loss: 1.6221445491237025

Epoch: 5| Step: 9
Training loss: 0.21294009685516357
Validation loss: 1.6040950731564594

Epoch: 5| Step: 10
Training loss: 0.5569342374801636
Validation loss: 1.5904050783444477

Epoch: 389| Step: 0
Training loss: 0.2530357837677002
Validation loss: 1.5912526448567708

Epoch: 5| Step: 1
Training loss: 0.3513060510158539
Validation loss: 1.5825676642438418

Epoch: 5| Step: 2
Training loss: 0.24648311734199524
Validation loss: 1.5985184818185785

Epoch: 5| Step: 3
Training loss: 0.40753158926963806
Validation loss: 1.6162851766873432

Epoch: 5| Step: 4
Training loss: 0.34724265336990356
Validation loss: 1.6593588962349841

Epoch: 5| Step: 5
Training loss: 0.4073503911495209
Validation loss: 1.7061888594781198

Epoch: 5| Step: 6
Training loss: 0.2121141403913498
Validation loss: 1.6684601845279816

Epoch: 5| Step: 7
Training loss: 0.4630538523197174
Validation loss: 1.6775032666421705

Epoch: 5| Step: 8
Training loss: 0.50702965259552
Validation loss: 1.6505180520396079

Epoch: 5| Step: 9
Training loss: 0.393566370010376
Validation loss: 1.650658938192552

Epoch: 5| Step: 10
Training loss: 0.3683288097381592
Validation loss: 1.6624537514102073

Epoch: 390| Step: 0
Training loss: 0.27313947677612305
Validation loss: 1.6479904997733332

Epoch: 5| Step: 1
Training loss: 0.4105376601219177
Validation loss: 1.6438404462670768

Epoch: 5| Step: 2
Training loss: 0.17515261471271515
Validation loss: 1.625456343414963

Epoch: 5| Step: 3
Training loss: 0.4687744975090027
Validation loss: 1.6106251990923317

Epoch: 5| Step: 4
Training loss: 0.4028762876987457
Validation loss: 1.609365140238116

Epoch: 5| Step: 5
Training loss: 0.2659232020378113
Validation loss: 1.5713849465052288

Epoch: 5| Step: 6
Training loss: 0.5421501398086548
Validation loss: 1.597107756522394

Epoch: 5| Step: 7
Training loss: 0.39785975217819214
Validation loss: 1.5956573217145857

Epoch: 5| Step: 8
Training loss: 0.39905720949172974
Validation loss: 1.5821854286296393

Epoch: 5| Step: 9
Training loss: 0.35887420177459717
Validation loss: 1.6306914488474529

Epoch: 5| Step: 10
Training loss: 0.15937362611293793
Validation loss: 1.6752908370828117

Epoch: 391| Step: 0
Training loss: 0.5682948231697083
Validation loss: 1.6750623282565866

Epoch: 5| Step: 1
Training loss: 0.36151260137557983
Validation loss: 1.6646646556033884

Epoch: 5| Step: 2
Training loss: 0.41253918409347534
Validation loss: 1.6515951592435119

Epoch: 5| Step: 3
Training loss: 0.25767093896865845
Validation loss: 1.6417204154435026

Epoch: 5| Step: 4
Training loss: 0.28721851110458374
Validation loss: 1.657649160713278

Epoch: 5| Step: 5
Training loss: 0.4134741723537445
Validation loss: 1.6558021364673492

Epoch: 5| Step: 6
Training loss: 0.31708312034606934
Validation loss: 1.6386869620251399

Epoch: 5| Step: 7
Training loss: 0.3015877604484558
Validation loss: 1.6340781245180356

Epoch: 5| Step: 8
Training loss: 0.49307623505592346
Validation loss: 1.6115681073998893

Epoch: 5| Step: 9
Training loss: 0.13655859231948853
Validation loss: 1.6032051835008847

Epoch: 5| Step: 10
Training loss: 0.2593005895614624
Validation loss: 1.6394856706742318

Epoch: 392| Step: 0
Training loss: 0.24307188391685486
Validation loss: 1.6065864851397853

Epoch: 5| Step: 1
Training loss: 0.193404883146286
Validation loss: 1.6279586111345599

Epoch: 5| Step: 2
Training loss: 0.4543309211730957
Validation loss: 1.6281239883874052

Epoch: 5| Step: 3
Training loss: 0.32751044631004333
Validation loss: 1.6100957534646476

Epoch: 5| Step: 4
Training loss: 0.3089239001274109
Validation loss: 1.6079174228893813

Epoch: 5| Step: 5
Training loss: 0.4209541380405426
Validation loss: 1.5869047975027433

Epoch: 5| Step: 6
Training loss: 0.41578882932662964
Validation loss: 1.614310453014989

Epoch: 5| Step: 7
Training loss: 0.42832690477371216
Validation loss: 1.5942194756641184

Epoch: 5| Step: 8
Training loss: 0.39010828733444214
Validation loss: 1.6036900166542298

Epoch: 5| Step: 9
Training loss: 0.39234939217567444
Validation loss: 1.5976483668050458

Epoch: 5| Step: 10
Training loss: 0.23075667023658752
Validation loss: 1.6265028490815112

Epoch: 393| Step: 0
Training loss: 0.45854711532592773
Validation loss: 1.5964765343614804

Epoch: 5| Step: 1
Training loss: 0.31799066066741943
Validation loss: 1.628185918254237

Epoch: 5| Step: 2
Training loss: 0.30037468671798706
Validation loss: 1.6359460571760773

Epoch: 5| Step: 3
Training loss: 0.21643021702766418
Validation loss: 1.6381934560755247

Epoch: 5| Step: 4
Training loss: 0.3900541067123413
Validation loss: 1.6361764041326379

Epoch: 5| Step: 5
Training loss: 0.37232157588005066
Validation loss: 1.6598613428813156

Epoch: 5| Step: 6
Training loss: 0.48775285482406616
Validation loss: 1.6751202883258942

Epoch: 5| Step: 7
Training loss: 0.4340605139732361
Validation loss: 1.689729252169209

Epoch: 5| Step: 8
Training loss: 0.32599204778671265
Validation loss: 1.712724716432633

Epoch: 5| Step: 9
Training loss: 0.33498522639274597
Validation loss: 1.7225973029290476

Epoch: 5| Step: 10
Training loss: 0.24119269847869873
Validation loss: 1.7208596685881257

Epoch: 394| Step: 0
Training loss: 0.4954398274421692
Validation loss: 1.717224399248759

Epoch: 5| Step: 1
Training loss: 0.5023308396339417
Validation loss: 1.6700916072373748

Epoch: 5| Step: 2
Training loss: 0.18873122334480286
Validation loss: 1.6619359729110554

Epoch: 5| Step: 3
Training loss: 0.4222053587436676
Validation loss: 1.6273214560683056

Epoch: 5| Step: 4
Training loss: 0.47323018312454224
Validation loss: 1.6224934567687332

Epoch: 5| Step: 5
Training loss: 0.35412803292274475
Validation loss: 1.5850226007482058

Epoch: 5| Step: 6
Training loss: 0.29617857933044434
Validation loss: 1.5771566052590646

Epoch: 5| Step: 7
Training loss: 0.30732765793800354
Validation loss: 1.5673168090081984

Epoch: 5| Step: 8
Training loss: 0.22032472491264343
Validation loss: 1.5777487908640215

Epoch: 5| Step: 9
Training loss: 0.3931059241294861
Validation loss: 1.5674153348451019

Epoch: 5| Step: 10
Training loss: 0.32894718647003174
Validation loss: 1.5765739217881234

Epoch: 395| Step: 0
Training loss: 0.26624399423599243
Validation loss: 1.5835454271685692

Epoch: 5| Step: 1
Training loss: 0.3323146402835846
Validation loss: 1.5981000200394662

Epoch: 5| Step: 2
Training loss: 0.46047115325927734
Validation loss: 1.6130158183395222

Epoch: 5| Step: 3
Training loss: 0.11560706794261932
Validation loss: 1.6416311751129806

Epoch: 5| Step: 4
Training loss: 0.2826464772224426
Validation loss: 1.6879033824448944

Epoch: 5| Step: 5
Training loss: 0.5873473882675171
Validation loss: 1.7103761332009428

Epoch: 5| Step: 6
Training loss: 0.27873584628105164
Validation loss: 1.6957972934169154

Epoch: 5| Step: 7
Training loss: 0.485487163066864
Validation loss: 1.6874805624767015

Epoch: 5| Step: 8
Training loss: 0.3830922245979309
Validation loss: 1.6514414491191987

Epoch: 5| Step: 9
Training loss: 0.2594216465950012
Validation loss: 1.5969342544514646

Epoch: 5| Step: 10
Training loss: 0.3544784486293793
Validation loss: 1.591086487616262

Epoch: 396| Step: 0
Training loss: 0.5023629069328308
Validation loss: 1.5748013206707534

Epoch: 5| Step: 1
Training loss: 0.3958192467689514
Validation loss: 1.5902689861994919

Epoch: 5| Step: 2
Training loss: 0.22139278054237366
Validation loss: 1.5332833067063363

Epoch: 5| Step: 3
Training loss: 0.24344691634178162
Validation loss: 1.543887892077046

Epoch: 5| Step: 4
Training loss: 0.3286680281162262
Validation loss: 1.574014703432719

Epoch: 5| Step: 5
Training loss: 0.5335724949836731
Validation loss: 1.5827554092612317

Epoch: 5| Step: 6
Training loss: 0.640518307685852
Validation loss: 1.5791998332546604

Epoch: 5| Step: 7
Training loss: 0.293586790561676
Validation loss: 1.5688233708822599

Epoch: 5| Step: 8
Training loss: 0.3695761561393738
Validation loss: 1.558841948868126

Epoch: 5| Step: 9
Training loss: 0.458010196685791
Validation loss: 1.5744148441540298

Epoch: 5| Step: 10
Training loss: 0.20924638211727142
Validation loss: 1.638439420730837

Epoch: 397| Step: 0
Training loss: 0.43267160654067993
Validation loss: 1.69190582665064

Epoch: 5| Step: 1
Training loss: 0.26953989267349243
Validation loss: 1.748150110244751

Epoch: 5| Step: 2
Training loss: 0.43438610434532166
Validation loss: 1.7176896679785945

Epoch: 5| Step: 3
Training loss: 0.35033151507377625
Validation loss: 1.6989465836555726

Epoch: 5| Step: 4
Training loss: 0.30235689878463745
Validation loss: 1.6878984000093193

Epoch: 5| Step: 5
Training loss: 0.47985905408859253
Validation loss: 1.6843013032790153

Epoch: 5| Step: 6
Training loss: 0.3392532467842102
Validation loss: 1.6605953785680956

Epoch: 5| Step: 7
Training loss: 0.29648977518081665
Validation loss: 1.6229012550846222

Epoch: 5| Step: 8
Training loss: 0.3583756685256958
Validation loss: 1.616810667899347

Epoch: 5| Step: 9
Training loss: 0.34639859199523926
Validation loss: 1.5712591371228617

Epoch: 5| Step: 10
Training loss: 0.2545309364795685
Validation loss: 1.5802798117360761

Epoch: 398| Step: 0
Training loss: 0.21310186386108398
Validation loss: 1.5826001244206582

Epoch: 5| Step: 1
Training loss: 0.39272385835647583
Validation loss: 1.579181755742719

Epoch: 5| Step: 2
Training loss: 0.4470704197883606
Validation loss: 1.5821657872969104

Epoch: 5| Step: 3
Training loss: 0.218074768781662
Validation loss: 1.5970174753537743

Epoch: 5| Step: 4
Training loss: 0.3186996579170227
Validation loss: 1.5895687867236394

Epoch: 5| Step: 5
Training loss: 0.5675251483917236
Validation loss: 1.627624047699795

Epoch: 5| Step: 6
Training loss: 0.36664479970932007
Validation loss: 1.6691927961123887

Epoch: 5| Step: 7
Training loss: 0.3987436592578888
Validation loss: 1.6908597766712148

Epoch: 5| Step: 8
Training loss: 0.20550942420959473
Validation loss: 1.6958815205481745

Epoch: 5| Step: 9
Training loss: 0.3347512483596802
Validation loss: 1.6974858930034022

Epoch: 5| Step: 10
Training loss: 0.3067345917224884
Validation loss: 1.6723390612550961

Epoch: 399| Step: 0
Training loss: 0.2896106243133545
Validation loss: 1.6538392818102272

Epoch: 5| Step: 1
Training loss: 0.3101215958595276
Validation loss: 1.6177806892702657

Epoch: 5| Step: 2
Training loss: 0.3961498737335205
Validation loss: 1.617449825809848

Epoch: 5| Step: 3
Training loss: 0.5205557942390442
Validation loss: 1.6350617331843222

Epoch: 5| Step: 4
Training loss: 0.2918435037136078
Validation loss: 1.6380096391964984

Epoch: 5| Step: 5
Training loss: 0.18462684750556946
Validation loss: 1.605701211960085

Epoch: 5| Step: 6
Training loss: 0.3087855875492096
Validation loss: 1.5885288997363018

Epoch: 5| Step: 7
Training loss: 0.4895060658454895
Validation loss: 1.5715076410642235

Epoch: 5| Step: 8
Training loss: 0.32722344994544983
Validation loss: 1.5776632434578353

Epoch: 5| Step: 9
Training loss: 0.14498403668403625
Validation loss: 1.5829084342525852

Epoch: 5| Step: 10
Training loss: 0.3984358310699463
Validation loss: 1.6159782960850706

Epoch: 400| Step: 0
Training loss: 0.2619125247001648
Validation loss: 1.6093408497430945

Epoch: 5| Step: 1
Training loss: 0.24713678658008575
Validation loss: 1.6373305487376388

Epoch: 5| Step: 2
Training loss: 0.37899157404899597
Validation loss: 1.6265966328241492

Epoch: 5| Step: 3
Training loss: 0.4960312247276306
Validation loss: 1.6036204048382339

Epoch: 5| Step: 4
Training loss: 0.17745164036750793
Validation loss: 1.6220715866293958

Epoch: 5| Step: 5
Training loss: 0.2580558657646179
Validation loss: 1.6137896942835983

Epoch: 5| Step: 6
Training loss: 0.17059621214866638
Validation loss: 1.6296678345690492

Epoch: 5| Step: 7
Training loss: 0.5560623407363892
Validation loss: 1.6328708253880984

Epoch: 5| Step: 8
Training loss: 0.4307233691215515
Validation loss: 1.622582721453841

Epoch: 5| Step: 9
Training loss: 0.3442379832267761
Validation loss: 1.616039881142237

Epoch: 5| Step: 10
Training loss: 0.2463449239730835
Validation loss: 1.6181117603855748

Testing loss: 2.187482131852044
