Epoch: 1| Step: 0
Training loss: 2.3898181915283203
Validation loss: 5.2214618754643265

Epoch: 5| Step: 1
Training loss: 6.071292400360107
Validation loss: 5.198216258838612

Epoch: 5| Step: 2
Training loss: 4.883209228515625
Validation loss: 5.175630261821132

Epoch: 5| Step: 3
Training loss: 5.713971138000488
Validation loss: 5.152916416045158

Epoch: 5| Step: 4
Training loss: 4.941867828369141
Validation loss: 5.127972141388924

Epoch: 5| Step: 5
Training loss: 4.807158946990967
Validation loss: 5.099090135225686

Epoch: 5| Step: 6
Training loss: 5.073416709899902
Validation loss: 5.065676053365071

Epoch: 5| Step: 7
Training loss: 5.5431718826293945
Validation loss: 5.027991997298374

Epoch: 5| Step: 8
Training loss: 4.898062705993652
Validation loss: 4.985792636871338

Epoch: 5| Step: 9
Training loss: 5.3065385818481445
Validation loss: 4.936580396467639

Epoch: 5| Step: 10
Training loss: 3.8114991188049316
Validation loss: 4.8834488520058255

Epoch: 2| Step: 0
Training loss: 4.9072980880737305
Validation loss: 4.822736955458118

Epoch: 5| Step: 1
Training loss: 4.353267192840576
Validation loss: 4.754923646168042

Epoch: 5| Step: 2
Training loss: 5.013057231903076
Validation loss: 4.685831823656636

Epoch: 5| Step: 3
Training loss: 3.674882411956787
Validation loss: 4.610555346294116

Epoch: 5| Step: 4
Training loss: 2.563157320022583
Validation loss: 4.530915962752475

Epoch: 5| Step: 5
Training loss: 3.957630157470703
Validation loss: 4.446315780762704

Epoch: 5| Step: 6
Training loss: 4.827879905700684
Validation loss: 4.364493831511466

Epoch: 5| Step: 7
Training loss: 4.019448280334473
Validation loss: 4.280957962877007

Epoch: 5| Step: 8
Training loss: 4.0165910720825195
Validation loss: 4.193525796295495

Epoch: 5| Step: 9
Training loss: 4.42055606842041
Validation loss: 4.107156604848882

Epoch: 5| Step: 10
Training loss: 4.903494358062744
Validation loss: 4.019541922435965

Epoch: 3| Step: 0
Training loss: 4.4089555740356445
Validation loss: 3.9327626484696583

Epoch: 5| Step: 1
Training loss: 3.438584089279175
Validation loss: 3.8516979012438046

Epoch: 5| Step: 2
Training loss: 4.1226911544799805
Validation loss: 3.778447781839678

Epoch: 5| Step: 3
Training loss: 4.249118804931641
Validation loss: 3.7154589006977696

Epoch: 5| Step: 4
Training loss: 3.2834415435791016
Validation loss: 3.6579187044533352

Epoch: 5| Step: 5
Training loss: 3.1393866539001465
Validation loss: 3.6058566852282454

Epoch: 5| Step: 6
Training loss: 3.1197314262390137
Validation loss: 3.5500474591409006

Epoch: 5| Step: 7
Training loss: 3.9614768028259277
Validation loss: 3.4810527729731735

Epoch: 5| Step: 8
Training loss: 3.1040749549865723
Validation loss: 3.4176787612258748

Epoch: 5| Step: 9
Training loss: 2.590322971343994
Validation loss: 3.4193234289846113

Epoch: 5| Step: 10
Training loss: 3.34061861038208
Validation loss: 3.3472883470596804

Epoch: 4| Step: 0
Training loss: 2.798901081085205
Validation loss: 3.304195455325547

Epoch: 5| Step: 1
Training loss: 3.484414577484131
Validation loss: 3.2727520132577546

Epoch: 5| Step: 2
Training loss: 3.083629608154297
Validation loss: 3.2456893869625625

Epoch: 5| Step: 3
Training loss: 3.2514312267303467
Validation loss: 3.2304267755118747

Epoch: 5| Step: 4
Training loss: 3.3166251182556152
Validation loss: 3.2100794033337663

Epoch: 5| Step: 5
Training loss: 3.3167076110839844
Validation loss: 3.1898102016859156

Epoch: 5| Step: 6
Training loss: 2.6686758995056152
Validation loss: 3.1633109379840154

Epoch: 5| Step: 7
Training loss: 3.8336033821105957
Validation loss: 3.1429908608877533

Epoch: 5| Step: 8
Training loss: 3.5688462257385254
Validation loss: 3.1239973473292526

Epoch: 5| Step: 9
Training loss: 2.867443799972534
Validation loss: 3.1085778128716255

Epoch: 5| Step: 10
Training loss: 2.856431484222412
Validation loss: 3.0987568286157425

Epoch: 5| Step: 0
Training loss: 2.7099204063415527
Validation loss: 3.0656984467660227

Epoch: 5| Step: 1
Training loss: 2.7288973331451416
Validation loss: 3.0511017281522035

Epoch: 5| Step: 2
Training loss: 3.2783195972442627
Validation loss: 3.0316533298902613

Epoch: 5| Step: 3
Training loss: 2.9794812202453613
Validation loss: 3.0080457912978305

Epoch: 5| Step: 4
Training loss: 2.691622734069824
Validation loss: 2.9871128477076048

Epoch: 5| Step: 5
Training loss: 2.8912036418914795
Validation loss: 2.9668213346953034

Epoch: 5| Step: 6
Training loss: 3.3252532482147217
Validation loss: 2.956076968100763

Epoch: 5| Step: 7
Training loss: 2.7488603591918945
Validation loss: 2.9518004591746996

Epoch: 5| Step: 8
Training loss: 3.4926059246063232
Validation loss: 2.922484887543545

Epoch: 5| Step: 9
Training loss: 2.972045421600342
Validation loss: 2.915933579526922

Epoch: 5| Step: 10
Training loss: 3.7424392700195312
Validation loss: 2.9045705026195896

Epoch: 6| Step: 0
Training loss: 2.948489189147949
Validation loss: 2.890142589487055

Epoch: 5| Step: 1
Training loss: 2.984823703765869
Validation loss: 2.9260261520262687

Epoch: 5| Step: 2
Training loss: 3.134683847427368
Validation loss: 2.9041506218653854

Epoch: 5| Step: 3
Training loss: 2.7673592567443848
Validation loss: 2.8575441247673443

Epoch: 5| Step: 4
Training loss: 3.3428237438201904
Validation loss: 2.8509016395896993

Epoch: 5| Step: 5
Training loss: 2.4533448219299316
Validation loss: 2.8482718877894904

Epoch: 5| Step: 6
Training loss: 3.2714476585388184
Validation loss: 2.832015742537796

Epoch: 5| Step: 7
Training loss: 3.7507481575012207
Validation loss: 2.8188182897465204

Epoch: 5| Step: 8
Training loss: 2.9093997478485107
Validation loss: 2.8065701120643207

Epoch: 5| Step: 9
Training loss: 2.83563494682312
Validation loss: 2.7962322722199144

Epoch: 5| Step: 10
Training loss: 2.062290906906128
Validation loss: 2.78850192921136

Epoch: 7| Step: 0
Training loss: 3.734640121459961
Validation loss: 2.781742931694113

Epoch: 5| Step: 1
Training loss: 2.274517059326172
Validation loss: 2.776059689060334

Epoch: 5| Step: 2
Training loss: 3.3968346118927
Validation loss: 2.7719851642526607

Epoch: 5| Step: 3
Training loss: 2.769740581512451
Validation loss: 2.7646622555230254

Epoch: 5| Step: 4
Training loss: 2.4691216945648193
Validation loss: 2.7579583455157537

Epoch: 5| Step: 5
Training loss: 3.203096866607666
Validation loss: 2.763351999303346

Epoch: 5| Step: 6
Training loss: 3.2804596424102783
Validation loss: 2.74400374966283

Epoch: 5| Step: 7
Training loss: 3.400787830352783
Validation loss: 2.746581159612184

Epoch: 5| Step: 8
Training loss: 2.682904005050659
Validation loss: 2.734239234719225

Epoch: 5| Step: 9
Training loss: 2.5404109954833984
Validation loss: 2.728953948584936

Epoch: 5| Step: 10
Training loss: 2.0368781089782715
Validation loss: 2.7309145799247165

Epoch: 8| Step: 0
Training loss: 3.357142925262451
Validation loss: 2.7309453333577802

Epoch: 5| Step: 1
Training loss: 2.3594658374786377
Validation loss: 2.7222728472883984

Epoch: 5| Step: 2
Training loss: 2.9046480655670166
Validation loss: 2.7241408389101744

Epoch: 5| Step: 3
Training loss: 2.6949336528778076
Validation loss: 2.713105515767169

Epoch: 5| Step: 4
Training loss: 2.297184467315674
Validation loss: 2.7124436670734036

Epoch: 5| Step: 5
Training loss: 3.3405685424804688
Validation loss: 2.7033815794093634

Epoch: 5| Step: 6
Training loss: 3.3292858600616455
Validation loss: 2.6959733732285036

Epoch: 5| Step: 7
Training loss: 2.5235257148742676
Validation loss: 2.682490876925889

Epoch: 5| Step: 8
Training loss: 2.988614559173584
Validation loss: 2.6769498471290833

Epoch: 5| Step: 9
Training loss: 3.4527230262756348
Validation loss: 2.6729668417284564

Epoch: 5| Step: 10
Training loss: 2.1464381217956543
Validation loss: 2.678920381812639

Epoch: 9| Step: 0
Training loss: 2.674074172973633
Validation loss: 2.6783737418472127

Epoch: 5| Step: 1
Training loss: 3.2395293712615967
Validation loss: 2.676864973960384

Epoch: 5| Step: 2
Training loss: 2.1503591537475586
Validation loss: 2.665279665300923

Epoch: 5| Step: 3
Training loss: 2.2424376010894775
Validation loss: 2.6635150268513668

Epoch: 5| Step: 4
Training loss: 3.54325795173645
Validation loss: 2.6678879081562

Epoch: 5| Step: 5
Training loss: 3.3259143829345703
Validation loss: 2.6682224581318517

Epoch: 5| Step: 6
Training loss: 3.105847120285034
Validation loss: 2.6603697423012025

Epoch: 5| Step: 7
Training loss: 3.058434009552002
Validation loss: 2.6538784247572704

Epoch: 5| Step: 8
Training loss: 2.9793574810028076
Validation loss: 2.6508922961450394

Epoch: 5| Step: 9
Training loss: 2.907270908355713
Validation loss: 2.6459042128696235

Epoch: 5| Step: 10
Training loss: 1.945110559463501
Validation loss: 2.6425388628436672

Epoch: 10| Step: 0
Training loss: 3.229626178741455
Validation loss: 2.642078656022267

Epoch: 5| Step: 1
Training loss: 2.5315051078796387
Validation loss: 2.640619529190884

Epoch: 5| Step: 2
Training loss: 2.766965866088867
Validation loss: 2.6342645691287134

Epoch: 5| Step: 3
Training loss: 2.622682571411133
Validation loss: 2.633446903638942

Epoch: 5| Step: 4
Training loss: 2.5015130043029785
Validation loss: 2.6319935014170985

Epoch: 5| Step: 5
Training loss: 2.8108248710632324
Validation loss: 2.6245184944521998

Epoch: 5| Step: 6
Training loss: 2.9415700435638428
Validation loss: 2.6244861695074264

Epoch: 5| Step: 7
Training loss: 2.5379538536071777
Validation loss: 2.624496759906892

Epoch: 5| Step: 8
Training loss: 2.557145595550537
Validation loss: 2.6265095433881207

Epoch: 5| Step: 9
Training loss: 3.7457199096679688
Validation loss: 2.6272891952145483

Epoch: 5| Step: 10
Training loss: 2.81496262550354
Validation loss: 2.621066701027655

Epoch: 11| Step: 0
Training loss: 2.6409695148468018
Validation loss: 2.618752700026317

Epoch: 5| Step: 1
Training loss: 2.580697536468506
Validation loss: 2.610590181043071

Epoch: 5| Step: 2
Training loss: 2.996204376220703
Validation loss: 2.6104057450448312

Epoch: 5| Step: 3
Training loss: 2.7904374599456787
Validation loss: 2.6089995932835404

Epoch: 5| Step: 4
Training loss: 3.368541717529297
Validation loss: 2.6035534181902484

Epoch: 5| Step: 5
Training loss: 3.194291114807129
Validation loss: 2.604432690528131

Epoch: 5| Step: 6
Training loss: 2.487645387649536
Validation loss: 2.600007282790317

Epoch: 5| Step: 7
Training loss: 3.0564754009246826
Validation loss: 2.59829641157581

Epoch: 5| Step: 8
Training loss: 2.309626579284668
Validation loss: 2.6002313962546726

Epoch: 5| Step: 9
Training loss: 2.8176379203796387
Validation loss: 2.597047728876914

Epoch: 5| Step: 10
Training loss: 2.6175339221954346
Validation loss: 2.6156281527652534

Epoch: 12| Step: 0
Training loss: 3.00591778755188
Validation loss: 2.5970069387907624

Epoch: 5| Step: 1
Training loss: 2.1211278438568115
Validation loss: 2.6007447986192602

Epoch: 5| Step: 2
Training loss: 2.5488243103027344
Validation loss: 2.6135827341387348

Epoch: 5| Step: 3
Training loss: 3.379432201385498
Validation loss: 2.628619929795624

Epoch: 5| Step: 4
Training loss: 2.851924419403076
Validation loss: 2.6284098573910293

Epoch: 5| Step: 5
Training loss: 3.034008264541626
Validation loss: 2.6162844191315355

Epoch: 5| Step: 6
Training loss: 2.4277091026306152
Validation loss: 2.6044916286263415

Epoch: 5| Step: 7
Training loss: 3.1191582679748535
Validation loss: 2.6067283948262534

Epoch: 5| Step: 8
Training loss: 3.5780842304229736
Validation loss: 2.5992418130238852

Epoch: 5| Step: 9
Training loss: 1.6177984476089478
Validation loss: 2.588510433832804

Epoch: 5| Step: 10
Training loss: 3.3242435455322266
Validation loss: 2.5845968236205397

Epoch: 13| Step: 0
Training loss: 2.4373250007629395
Validation loss: 2.5820502004315777

Epoch: 5| Step: 1
Training loss: 2.573929786682129
Validation loss: 2.5768964726437806

Epoch: 5| Step: 2
Training loss: 2.476367473602295
Validation loss: 2.58476685964933

Epoch: 5| Step: 3
Training loss: 3.3402092456817627
Validation loss: 2.596296505261493

Epoch: 5| Step: 4
Training loss: 2.2513794898986816
Validation loss: 2.591145077059346

Epoch: 5| Step: 5
Training loss: 3.7036521434783936
Validation loss: 2.627529690342565

Epoch: 5| Step: 6
Training loss: 2.7056145668029785
Validation loss: 2.564158567818262

Epoch: 5| Step: 7
Training loss: 3.059847116470337
Validation loss: 2.5660738432279198

Epoch: 5| Step: 8
Training loss: 3.182673931121826
Validation loss: 2.571189780389109

Epoch: 5| Step: 9
Training loss: 2.35304594039917
Validation loss: 2.5895960818054857

Epoch: 5| Step: 10
Training loss: 2.6836204528808594
Validation loss: 2.577455243756694

Epoch: 14| Step: 0
Training loss: 3.27386474609375
Validation loss: 2.5785273736523044

Epoch: 5| Step: 1
Training loss: 2.3385682106018066
Validation loss: 2.573021819514613

Epoch: 5| Step: 2
Training loss: 3.10105037689209
Validation loss: 2.567131406517439

Epoch: 5| Step: 3
Training loss: 2.7127084732055664
Validation loss: 2.564194199859455

Epoch: 5| Step: 4
Training loss: 2.9669852256774902
Validation loss: 2.561304907644949

Epoch: 5| Step: 5
Training loss: 2.4787662029266357
Validation loss: 2.5610783100128174

Epoch: 5| Step: 6
Training loss: 2.9023537635803223
Validation loss: 2.5516525545427875

Epoch: 5| Step: 7
Training loss: 2.968259811401367
Validation loss: 2.5593485947578185

Epoch: 5| Step: 8
Training loss: 2.261852502822876
Validation loss: 2.548177057696927

Epoch: 5| Step: 9
Training loss: 2.6108016967773438
Validation loss: 2.550036335504183

Epoch: 5| Step: 10
Training loss: 2.935694932937622
Validation loss: 2.5465088608444377

Epoch: 15| Step: 0
Training loss: 2.384242534637451
Validation loss: 2.5417840301349597

Epoch: 5| Step: 1
Training loss: 2.527702808380127
Validation loss: 2.5419903775697112

Epoch: 5| Step: 2
Training loss: 2.466580867767334
Validation loss: 2.5388948148296726

Epoch: 5| Step: 3
Training loss: 3.292921543121338
Validation loss: 2.529739982338362

Epoch: 5| Step: 4
Training loss: 2.774470806121826
Validation loss: 2.527699226974159

Epoch: 5| Step: 5
Training loss: 3.2670702934265137
Validation loss: 2.526009034085017

Epoch: 5| Step: 6
Training loss: 2.796877384185791
Validation loss: 2.526580374727967

Epoch: 5| Step: 7
Training loss: 2.2483551502227783
Validation loss: 2.5126413196645756

Epoch: 5| Step: 8
Training loss: 2.810822010040283
Validation loss: 2.5181426514861402

Epoch: 5| Step: 9
Training loss: 2.750627040863037
Validation loss: 2.5198315061548704

Epoch: 5| Step: 10
Training loss: 2.976093053817749
Validation loss: 2.5134681937515095

Epoch: 16| Step: 0
Training loss: 3.432952404022217
Validation loss: 2.5107328379026024

Epoch: 5| Step: 1
Training loss: 2.790748357772827
Validation loss: 2.5140693392804874

Epoch: 5| Step: 2
Training loss: 2.2819676399230957
Validation loss: 2.5191068777474026

Epoch: 5| Step: 3
Training loss: 2.8366401195526123
Validation loss: 2.520844664624942

Epoch: 5| Step: 4
Training loss: 3.167980670928955
Validation loss: 2.51717871491627

Epoch: 5| Step: 5
Training loss: 2.437016010284424
Validation loss: 2.515876546982796

Epoch: 5| Step: 6
Training loss: 3.0197746753692627
Validation loss: 2.5097801531514814

Epoch: 5| Step: 7
Training loss: 2.5935606956481934
Validation loss: 2.5063046024691675

Epoch: 5| Step: 8
Training loss: 2.7353031635284424
Validation loss: 2.508657927154213

Epoch: 5| Step: 9
Training loss: 2.2110280990600586
Validation loss: 2.510602251175911

Epoch: 5| Step: 10
Training loss: 2.8398406505584717
Validation loss: 2.526987116823914

Epoch: 17| Step: 0
Training loss: 3.242382049560547
Validation loss: 2.5553637332813715

Epoch: 5| Step: 1
Training loss: 2.356682300567627
Validation loss: 2.5644703244650238

Epoch: 5| Step: 2
Training loss: 2.8604583740234375
Validation loss: 2.575086206518194

Epoch: 5| Step: 3
Training loss: 2.5845327377319336
Validation loss: 2.560046142147433

Epoch: 5| Step: 4
Training loss: 3.2550957202911377
Validation loss: 2.5481186682178127

Epoch: 5| Step: 5
Training loss: 2.3330726623535156
Validation loss: 2.538937435355238

Epoch: 5| Step: 6
Training loss: 1.577566146850586
Validation loss: 2.5301164145110757

Epoch: 5| Step: 7
Training loss: 3.3864638805389404
Validation loss: 2.5304410534520305

Epoch: 5| Step: 8
Training loss: 3.329174518585205
Validation loss: 2.528269460124354

Epoch: 5| Step: 9
Training loss: 3.3461380004882812
Validation loss: 2.519905141604844

Epoch: 5| Step: 10
Training loss: 1.9185081720352173
Validation loss: 2.5130432498070503

Epoch: 18| Step: 0
Training loss: 2.144562244415283
Validation loss: 2.516023220554475

Epoch: 5| Step: 1
Training loss: 2.269301176071167
Validation loss: 2.5029637223930767

Epoch: 5| Step: 2
Training loss: 2.40631365776062
Validation loss: 2.5063123215911207

Epoch: 5| Step: 3
Training loss: 3.1203179359436035
Validation loss: 2.518282131482196

Epoch: 5| Step: 4
Training loss: 2.7982535362243652
Validation loss: 2.4734844853801112

Epoch: 5| Step: 5
Training loss: 2.7410078048706055
Validation loss: 2.467337372482464

Epoch: 5| Step: 6
Training loss: 2.8523497581481934
Validation loss: 2.4788567584048034

Epoch: 5| Step: 7
Training loss: 2.369591474533081
Validation loss: 2.4919205275915

Epoch: 5| Step: 8
Training loss: 2.9744632244110107
Validation loss: 2.5032929476871284

Epoch: 5| Step: 9
Training loss: 2.9778618812561035
Validation loss: 2.5145699131873345

Epoch: 5| Step: 10
Training loss: 3.4894208908081055
Validation loss: 2.5091443523283927

Epoch: 19| Step: 0
Training loss: 2.9253721237182617
Validation loss: 2.4930182862025436

Epoch: 5| Step: 1
Training loss: 2.3444762229919434
Validation loss: 2.472187337055001

Epoch: 5| Step: 2
Training loss: 2.673902988433838
Validation loss: 2.466010508998748

Epoch: 5| Step: 3
Training loss: 2.712146043777466
Validation loss: 2.4610163755314325

Epoch: 5| Step: 4
Training loss: 3.2008273601531982
Validation loss: 2.4604748449017926

Epoch: 5| Step: 5
Training loss: 3.006296396255493
Validation loss: 2.4642946181758756

Epoch: 5| Step: 6
Training loss: 2.9944798946380615
Validation loss: 2.4615236533585416

Epoch: 5| Step: 7
Training loss: 2.3755297660827637
Validation loss: 2.4654508995753464

Epoch: 5| Step: 8
Training loss: 2.9825127124786377
Validation loss: 2.4720543584515973

Epoch: 5| Step: 9
Training loss: 2.632162094116211
Validation loss: 2.4676581864715903

Epoch: 5| Step: 10
Training loss: 1.7903587818145752
Validation loss: 2.4688966351170696

Epoch: 20| Step: 0
Training loss: 2.385746717453003
Validation loss: 2.5164897364954792

Epoch: 5| Step: 1
Training loss: 2.7190353870391846
Validation loss: 2.4909092405790925

Epoch: 5| Step: 2
Training loss: 2.8711304664611816
Validation loss: 2.450317644303845

Epoch: 5| Step: 3
Training loss: 3.0014712810516357
Validation loss: 2.472448241326117

Epoch: 5| Step: 4
Training loss: 2.5134799480438232
Validation loss: 2.4419677539538314

Epoch: 5| Step: 5
Training loss: 2.6413538455963135
Validation loss: 2.4365534884955293

Epoch: 5| Step: 6
Training loss: 3.077946424484253
Validation loss: 2.438948210849557

Epoch: 5| Step: 7
Training loss: 2.9500234127044678
Validation loss: 2.448146163776357

Epoch: 5| Step: 8
Training loss: 2.503201961517334
Validation loss: 2.4486933805609263

Epoch: 5| Step: 9
Training loss: 2.6790051460266113
Validation loss: 2.4459205365950063

Epoch: 5| Step: 10
Training loss: 2.5007455348968506
Validation loss: 2.4542253940336165

Epoch: 21| Step: 0
Training loss: 2.457841396331787
Validation loss: 2.4575744290505686

Epoch: 5| Step: 1
Training loss: 2.505333423614502
Validation loss: 2.447962499433948

Epoch: 5| Step: 2
Training loss: 2.7355527877807617
Validation loss: 2.4563417767965667

Epoch: 5| Step: 3
Training loss: 3.2227654457092285
Validation loss: 2.454546874569308

Epoch: 5| Step: 4
Training loss: 2.9387574195861816
Validation loss: 2.4510290468892744

Epoch: 5| Step: 5
Training loss: 2.5286712646484375
Validation loss: 2.4277185419554352

Epoch: 5| Step: 6
Training loss: 2.6890814304351807
Validation loss: 2.413545787975352

Epoch: 5| Step: 7
Training loss: 2.281383991241455
Validation loss: 2.4005726742488083

Epoch: 5| Step: 8
Training loss: 2.4525647163391113
Validation loss: 2.396675640536893

Epoch: 5| Step: 9
Training loss: 3.422494888305664
Validation loss: 2.398054358779743

Epoch: 5| Step: 10
Training loss: 2.226452112197876
Validation loss: 2.3956099761429654

Epoch: 22| Step: 0
Training loss: 2.313605785369873
Validation loss: 2.39560039325427

Epoch: 5| Step: 1
Training loss: 2.415262460708618
Validation loss: 2.3902954157962593

Epoch: 5| Step: 2
Training loss: 3.0808839797973633
Validation loss: 2.389756812844225

Epoch: 5| Step: 3
Training loss: 2.886230707168579
Validation loss: 2.3836951922344904

Epoch: 5| Step: 4
Training loss: 2.617094039916992
Validation loss: 2.38281068494243

Epoch: 5| Step: 5
Training loss: 2.1435952186584473
Validation loss: 2.379907964378275

Epoch: 5| Step: 6
Training loss: 2.5004994869232178
Validation loss: 2.3885634124919934

Epoch: 5| Step: 7
Training loss: 3.3298721313476562
Validation loss: 2.4027475798001854

Epoch: 5| Step: 8
Training loss: 3.043978452682495
Validation loss: 2.41798815419597

Epoch: 5| Step: 9
Training loss: 2.274162769317627
Validation loss: 2.4225216360502344

Epoch: 5| Step: 10
Training loss: 2.7132370471954346
Validation loss: 2.447063487063172

Epoch: 23| Step: 0
Training loss: 2.7448842525482178
Validation loss: 2.4417808081514094

Epoch: 5| Step: 1
Training loss: 2.6059226989746094
Validation loss: 2.4154263901454147

Epoch: 5| Step: 2
Training loss: 3.0343315601348877
Validation loss: 2.4038942911291636

Epoch: 5| Step: 3
Training loss: 2.1670448780059814
Validation loss: 2.387200509348223

Epoch: 5| Step: 4
Training loss: 2.9013445377349854
Validation loss: 2.3750165175366145

Epoch: 5| Step: 5
Training loss: 2.1994054317474365
Validation loss: 2.3772840884424027

Epoch: 5| Step: 6
Training loss: 2.501199245452881
Validation loss: 2.3766676008060412

Epoch: 5| Step: 7
Training loss: 2.994703531265259
Validation loss: 2.381878024788313

Epoch: 5| Step: 8
Training loss: 2.690629482269287
Validation loss: 2.3864777100983487

Epoch: 5| Step: 9
Training loss: 2.7943503856658936
Validation loss: 2.3821394084602274

Epoch: 5| Step: 10
Training loss: 2.5089521408081055
Validation loss: 2.3774366532602618

Epoch: 24| Step: 0
Training loss: 3.1468145847320557
Validation loss: 2.372465113157867

Epoch: 5| Step: 1
Training loss: 2.3852667808532715
Validation loss: 2.377042252530334

Epoch: 5| Step: 2
Training loss: 2.350285768508911
Validation loss: 2.3732509125945387

Epoch: 5| Step: 3
Training loss: 2.5536043643951416
Validation loss: 2.395597593758696

Epoch: 5| Step: 4
Training loss: 2.679696798324585
Validation loss: 2.4005764351096204

Epoch: 5| Step: 5
Training loss: 2.1979877948760986
Validation loss: 2.4060802818626486

Epoch: 5| Step: 6
Training loss: 2.6662092208862305
Validation loss: 2.393190667193423

Epoch: 5| Step: 7
Training loss: 2.274423122406006
Validation loss: 2.3719256898408294

Epoch: 5| Step: 8
Training loss: 2.9148290157318115
Validation loss: 2.375434752433531

Epoch: 5| Step: 9
Training loss: 2.706754446029663
Validation loss: 2.3755377441324215

Epoch: 5| Step: 10
Training loss: 3.2643864154815674
Validation loss: 2.3656018421214116

Epoch: 25| Step: 0
Training loss: 3.341045379638672
Validation loss: 2.358197835183913

Epoch: 5| Step: 1
Training loss: 2.096169948577881
Validation loss: 2.3614144914893695

Epoch: 5| Step: 2
Training loss: 2.3319108486175537
Validation loss: 2.3608821874023764

Epoch: 5| Step: 3
Training loss: 2.658315658569336
Validation loss: 2.3517179822409027

Epoch: 5| Step: 4
Training loss: 2.905651092529297
Validation loss: 2.3577199238602833

Epoch: 5| Step: 5
Training loss: 2.709815502166748
Validation loss: 2.3759278276915192

Epoch: 5| Step: 6
Training loss: 2.4428813457489014
Validation loss: 2.383857932142032

Epoch: 5| Step: 7
Training loss: 2.732475519180298
Validation loss: 2.4148507989862913

Epoch: 5| Step: 8
Training loss: 2.7022953033447266
Validation loss: 2.4482704157470376

Epoch: 5| Step: 9
Training loss: 2.429023027420044
Validation loss: 2.461041958101334

Epoch: 5| Step: 10
Training loss: 2.7529966831207275
Validation loss: 2.4954663271545083

Epoch: 26| Step: 0
Training loss: 2.700958490371704
Validation loss: 2.4124078289155038

Epoch: 5| Step: 1
Training loss: 2.6376235485076904
Validation loss: 2.3824451174787296

Epoch: 5| Step: 2
Training loss: 3.27177357673645
Validation loss: 2.379912289240027

Epoch: 5| Step: 3
Training loss: 2.7352070808410645
Validation loss: 2.359246566731443

Epoch: 5| Step: 4
Training loss: 2.430281400680542
Validation loss: 2.3573082288106284

Epoch: 5| Step: 5
Training loss: 3.0957274436950684
Validation loss: 2.362713339508221

Epoch: 5| Step: 6
Training loss: 2.1328365802764893
Validation loss: 2.364260588922808

Epoch: 5| Step: 7
Training loss: 2.417935609817505
Validation loss: 2.3641369137712704

Epoch: 5| Step: 8
Training loss: 2.1787362098693848
Validation loss: 2.3539606473779164

Epoch: 5| Step: 9
Training loss: 2.2861294746398926
Validation loss: 2.351054714572045

Epoch: 5| Step: 10
Training loss: 3.0017542839050293
Validation loss: 2.3515168774512505

Epoch: 27| Step: 0
Training loss: 2.0092008113861084
Validation loss: 2.3432492389473865

Epoch: 5| Step: 1
Training loss: 2.99560284614563
Validation loss: 2.332268540577222

Epoch: 5| Step: 2
Training loss: 2.8624606132507324
Validation loss: 2.330144005437051

Epoch: 5| Step: 3
Training loss: 2.2590553760528564
Validation loss: 2.3292744595517396

Epoch: 5| Step: 4
Training loss: 1.9622776508331299
Validation loss: 2.328822412798482

Epoch: 5| Step: 5
Training loss: 2.3835670948028564
Validation loss: 2.3288642129590436

Epoch: 5| Step: 6
Training loss: 2.698516368865967
Validation loss: 2.329599224111085

Epoch: 5| Step: 7
Training loss: 2.8018195629119873
Validation loss: 2.328303837007092

Epoch: 5| Step: 8
Training loss: 2.927147388458252
Validation loss: 2.3221089275934363

Epoch: 5| Step: 9
Training loss: 3.2439231872558594
Validation loss: 2.32521637024418

Epoch: 5| Step: 10
Training loss: 2.732680320739746
Validation loss: 2.323147960888442

Epoch: 28| Step: 0
Training loss: 2.1486423015594482
Validation loss: 2.3338588463362826

Epoch: 5| Step: 1
Training loss: 2.935157060623169
Validation loss: 2.330138534627935

Epoch: 5| Step: 2
Training loss: 3.0970377922058105
Validation loss: 2.3314493369030695

Epoch: 5| Step: 3
Training loss: 2.7237324714660645
Validation loss: 2.338906406074442

Epoch: 5| Step: 4
Training loss: 2.4783802032470703
Validation loss: 2.3376595243330924

Epoch: 5| Step: 5
Training loss: 2.494720220565796
Validation loss: 2.329637306992726

Epoch: 5| Step: 6
Training loss: 2.1994829177856445
Validation loss: 2.319668810854676

Epoch: 5| Step: 7
Training loss: 3.273878574371338
Validation loss: 2.315812546719787

Epoch: 5| Step: 8
Training loss: 2.6681079864501953
Validation loss: 2.314014132304858

Epoch: 5| Step: 9
Training loss: 2.249769449234009
Validation loss: 2.3113282726657007

Epoch: 5| Step: 10
Training loss: 2.4611093997955322
Validation loss: 2.310912368118122

Epoch: 29| Step: 0
Training loss: 2.9712774753570557
Validation loss: 2.317234713544128

Epoch: 5| Step: 1
Training loss: 2.8295042514801025
Validation loss: 2.3385512982645342

Epoch: 5| Step: 2
Training loss: 2.3288073539733887
Validation loss: 2.3471210387445267

Epoch: 5| Step: 3
Training loss: 2.6926426887512207
Validation loss: 2.3397635747027654

Epoch: 5| Step: 4
Training loss: 2.2426795959472656
Validation loss: 2.3370183719101774

Epoch: 5| Step: 5
Training loss: 2.823585271835327
Validation loss: 2.3351188680177093

Epoch: 5| Step: 6
Training loss: 2.7176389694213867
Validation loss: 2.3296011801688903

Epoch: 5| Step: 7
Training loss: 2.093369245529175
Validation loss: 2.3148895053453344

Epoch: 5| Step: 8
Training loss: 2.140754222869873
Validation loss: 2.3166385235324984

Epoch: 5| Step: 9
Training loss: 2.902655839920044
Validation loss: 2.3216632643053607

Epoch: 5| Step: 10
Training loss: 2.864572525024414
Validation loss: 2.3225371606888308

Epoch: 30| Step: 0
Training loss: 2.364102602005005
Validation loss: 2.3238237288690384

Epoch: 5| Step: 1
Training loss: 2.558723211288452
Validation loss: 2.3245420199568554

Epoch: 5| Step: 2
Training loss: 2.7465415000915527
Validation loss: 2.339246852423555

Epoch: 5| Step: 3
Training loss: 1.7731904983520508
Validation loss: 2.3418560194712814

Epoch: 5| Step: 4
Training loss: 2.727640151977539
Validation loss: 2.3630303182909564

Epoch: 5| Step: 5
Training loss: 2.611091136932373
Validation loss: 2.3688863092853176

Epoch: 5| Step: 6
Training loss: 3.0316104888916016
Validation loss: 2.367025508675524

Epoch: 5| Step: 7
Training loss: 3.0725369453430176
Validation loss: 2.368315471115933

Epoch: 5| Step: 8
Training loss: 2.270838499069214
Validation loss: 2.339290493278093

Epoch: 5| Step: 9
Training loss: 2.5897884368896484
Validation loss: 2.3330122963074715

Epoch: 5| Step: 10
Training loss: 2.797872304916382
Validation loss: 2.3175102908124208

Epoch: 31| Step: 0
Training loss: 3.2075977325439453
Validation loss: 2.303291595110329

Epoch: 5| Step: 1
Training loss: 2.692596435546875
Validation loss: 2.295817559765231

Epoch: 5| Step: 2
Training loss: 2.491124153137207
Validation loss: 2.2907588404993855

Epoch: 5| Step: 3
Training loss: 2.6486923694610596
Validation loss: 2.2935273314035065

Epoch: 5| Step: 4
Training loss: 2.6563124656677246
Validation loss: 2.289540729215068

Epoch: 5| Step: 5
Training loss: 2.502840042114258
Validation loss: 2.2891492792355117

Epoch: 5| Step: 6
Training loss: 2.464048385620117
Validation loss: 2.291958237207064

Epoch: 5| Step: 7
Training loss: 2.0641069412231445
Validation loss: 2.2891322335889264

Epoch: 5| Step: 8
Training loss: 2.7081356048583984
Validation loss: 2.2894978292526735

Epoch: 5| Step: 9
Training loss: 2.3667404651641846
Validation loss: 2.291983263466948

Epoch: 5| Step: 10
Training loss: 2.6935195922851562
Validation loss: 2.300991521086744

Epoch: 32| Step: 0
Training loss: 2.7633843421936035
Validation loss: 2.324665779708534

Epoch: 5| Step: 1
Training loss: 2.4538872241973877
Validation loss: 2.35609717394716

Epoch: 5| Step: 2
Training loss: 2.044980525970459
Validation loss: 2.397560868211972

Epoch: 5| Step: 3
Training loss: 2.766698122024536
Validation loss: 2.4022673996545936

Epoch: 5| Step: 4
Training loss: 2.7217965126037598
Validation loss: 2.3731539890330327

Epoch: 5| Step: 5
Training loss: 2.060123920440674
Validation loss: 2.3494383904241745

Epoch: 5| Step: 6
Training loss: 2.7545857429504395
Validation loss: 2.3310991410286195

Epoch: 5| Step: 7
Training loss: 3.0328171253204346
Validation loss: 2.300844315559633

Epoch: 5| Step: 8
Training loss: 2.830040693283081
Validation loss: 2.2860799245936896

Epoch: 5| Step: 9
Training loss: 2.9254024028778076
Validation loss: 2.286415607698502

Epoch: 5| Step: 10
Training loss: 2.0546531677246094
Validation loss: 2.2878727887266423

Epoch: 33| Step: 0
Training loss: 2.0137667655944824
Validation loss: 2.2867004666277158

Epoch: 5| Step: 1
Training loss: 3.131023645401001
Validation loss: 2.283150839549239

Epoch: 5| Step: 2
Training loss: 2.7833006381988525
Validation loss: 2.2839069597182737

Epoch: 5| Step: 3
Training loss: 3.076931953430176
Validation loss: 2.281596747777795

Epoch: 5| Step: 4
Training loss: 2.53837251663208
Validation loss: 2.2807718464123306

Epoch: 5| Step: 5
Training loss: 2.842055559158325
Validation loss: 2.279773566030687

Epoch: 5| Step: 6
Training loss: 2.1077919006347656
Validation loss: 2.2857229965989307

Epoch: 5| Step: 7
Training loss: 2.9769980907440186
Validation loss: 2.2964997509474396

Epoch: 5| Step: 8
Training loss: 2.1862123012542725
Validation loss: 2.2982009662094938

Epoch: 5| Step: 9
Training loss: 2.682755947113037
Validation loss: 2.2971343558321715

Epoch: 5| Step: 10
Training loss: 1.9516561031341553
Validation loss: 2.292059744558027

Epoch: 34| Step: 0
Training loss: 2.146167278289795
Validation loss: 2.2963516699370516

Epoch: 5| Step: 1
Training loss: 2.128272294998169
Validation loss: 2.3009390728448027

Epoch: 5| Step: 2
Training loss: 2.698289632797241
Validation loss: 2.30487326652773

Epoch: 5| Step: 3
Training loss: 2.3666603565216064
Validation loss: 2.3165695782630675

Epoch: 5| Step: 4
Training loss: 3.171398878097534
Validation loss: 2.3102352862717

Epoch: 5| Step: 5
Training loss: 2.552631139755249
Validation loss: 2.3056081084794897

Epoch: 5| Step: 6
Training loss: 3.055110454559326
Validation loss: 2.295006577686597

Epoch: 5| Step: 7
Training loss: 2.2633602619171143
Validation loss: 2.3048392290710122

Epoch: 5| Step: 8
Training loss: 2.445934772491455
Validation loss: 2.278166970899028

Epoch: 5| Step: 9
Training loss: 2.525301694869995
Validation loss: 2.2724985179080757

Epoch: 5| Step: 10
Training loss: 3.013258218765259
Validation loss: 2.280161933232379

Epoch: 35| Step: 0
Training loss: 2.765040874481201
Validation loss: 2.281306858985655

Epoch: 5| Step: 1
Training loss: 2.9425225257873535
Validation loss: 2.2827376216970463

Epoch: 5| Step: 2
Training loss: 2.780270576477051
Validation loss: 2.2723184811171664

Epoch: 5| Step: 3
Training loss: 3.4969401359558105
Validation loss: 2.291606685166718

Epoch: 5| Step: 4
Training loss: 2.7070200443267822
Validation loss: 2.277521998651566

Epoch: 5| Step: 5
Training loss: 1.963425636291504
Validation loss: 2.268496174966135

Epoch: 5| Step: 6
Training loss: 2.0807480812072754
Validation loss: 2.275617366196007

Epoch: 5| Step: 7
Training loss: 1.8632017374038696
Validation loss: 2.275576924764982

Epoch: 5| Step: 8
Training loss: 2.270371198654175
Validation loss: 2.2704739801345335

Epoch: 5| Step: 9
Training loss: 2.663942575454712
Validation loss: 2.281257833203962

Epoch: 5| Step: 10
Training loss: 2.9507110118865967
Validation loss: 2.288133041833037

Epoch: 36| Step: 0
Training loss: 3.0421767234802246
Validation loss: 2.2943697808891215

Epoch: 5| Step: 1
Training loss: 2.590284585952759
Validation loss: 2.2930277291164605

Epoch: 5| Step: 2
Training loss: 3.0316522121429443
Validation loss: 2.287149049902475

Epoch: 5| Step: 3
Training loss: 2.3900444507598877
Validation loss: 2.2839182987008044

Epoch: 5| Step: 4
Training loss: 2.205061435699463
Validation loss: 2.2871298469522947

Epoch: 5| Step: 5
Training loss: 2.6794986724853516
Validation loss: 2.289367937272595

Epoch: 5| Step: 6
Training loss: 2.570169448852539
Validation loss: 2.2946719918199765

Epoch: 5| Step: 7
Training loss: 2.1676113605499268
Validation loss: 2.2981361689106112

Epoch: 5| Step: 8
Training loss: 2.530648946762085
Validation loss: 2.27957058465609

Epoch: 5| Step: 9
Training loss: 2.699522018432617
Validation loss: 2.257110518793906

Epoch: 5| Step: 10
Training loss: 2.1887619495391846
Validation loss: 2.257883770491487

Epoch: 37| Step: 0
Training loss: 2.623581647872925
Validation loss: 2.2602216812872116

Epoch: 5| Step: 1
Training loss: 2.8055367469787598
Validation loss: 2.2622567248600784

Epoch: 5| Step: 2
Training loss: 2.798565626144409
Validation loss: 2.266777874321066

Epoch: 5| Step: 3
Training loss: 2.147977113723755
Validation loss: 2.29527182989223

Epoch: 5| Step: 4
Training loss: 2.341284990310669
Validation loss: 2.3086888867039836

Epoch: 5| Step: 5
Training loss: 2.665693759918213
Validation loss: 2.3149957195405038

Epoch: 5| Step: 6
Training loss: 1.8157823085784912
Validation loss: 2.298670854619754

Epoch: 5| Step: 7
Training loss: 2.550421953201294
Validation loss: 2.3259934353572067

Epoch: 5| Step: 8
Training loss: 2.3994381427764893
Validation loss: 2.293370989061171

Epoch: 5| Step: 9
Training loss: 3.030916929244995
Validation loss: 2.276576667703608

Epoch: 5| Step: 10
Training loss: 3.093506336212158
Validation loss: 2.255296404643725

Epoch: 38| Step: 0
Training loss: 2.183568239212036
Validation loss: 2.2427845578039847

Epoch: 5| Step: 1
Training loss: 2.5976994037628174
Validation loss: 2.2453155632941955

Epoch: 5| Step: 2
Training loss: 2.88146710395813
Validation loss: 2.243781776838405

Epoch: 5| Step: 3
Training loss: 2.7679877281188965
Validation loss: 2.2435001583509546

Epoch: 5| Step: 4
Training loss: 1.7951500415802002
Validation loss: 2.2423220578060357

Epoch: 5| Step: 5
Training loss: 2.732675075531006
Validation loss: 2.243598968751969

Epoch: 5| Step: 6
Training loss: 3.0048232078552246
Validation loss: 2.2636343202283307

Epoch: 5| Step: 7
Training loss: 2.6662914752960205
Validation loss: 2.274043913810484

Epoch: 5| Step: 8
Training loss: 2.0274314880371094
Validation loss: 2.292158703650198

Epoch: 5| Step: 9
Training loss: 2.7070584297180176
Validation loss: 2.3253461032785396

Epoch: 5| Step: 10
Training loss: 2.6941208839416504
Validation loss: 2.332389936652235

Epoch: 39| Step: 0
Training loss: 2.926743984222412
Validation loss: 2.3190404086984615

Epoch: 5| Step: 1
Training loss: 2.7919647693634033
Validation loss: 2.2960023880004883

Epoch: 5| Step: 2
Training loss: 2.3759708404541016
Validation loss: 2.2881544815596713

Epoch: 5| Step: 3
Training loss: 2.4059674739837646
Validation loss: 2.2726586531567317

Epoch: 5| Step: 4
Training loss: 2.271710157394409
Validation loss: 2.2505332321249027

Epoch: 5| Step: 5
Training loss: 2.196654796600342
Validation loss: 2.2378429648696736

Epoch: 5| Step: 6
Training loss: 2.9540348052978516
Validation loss: 2.239901255535823

Epoch: 5| Step: 7
Training loss: 2.614013195037842
Validation loss: 2.243302701621927

Epoch: 5| Step: 8
Training loss: 2.6724820137023926
Validation loss: 2.2501591405560895

Epoch: 5| Step: 9
Training loss: 2.3010640144348145
Validation loss: 2.241495511865103

Epoch: 5| Step: 10
Training loss: 2.3700389862060547
Validation loss: 2.236954350625315

Epoch: 40| Step: 0
Training loss: 2.3814988136291504
Validation loss: 2.239569507619386

Epoch: 5| Step: 1
Training loss: 2.262904644012451
Validation loss: 2.2526774380796697

Epoch: 5| Step: 2
Training loss: 2.883387804031372
Validation loss: 2.2551607239630913

Epoch: 5| Step: 3
Training loss: 3.080315351486206
Validation loss: 2.261318399060157

Epoch: 5| Step: 4
Training loss: 2.098179340362549
Validation loss: 2.276254056602396

Epoch: 5| Step: 5
Training loss: 2.344409704208374
Validation loss: 2.2819920124546176

Epoch: 5| Step: 6
Training loss: 2.664606809616089
Validation loss: 2.2812667790279595

Epoch: 5| Step: 7
Training loss: 2.3133678436279297
Validation loss: 2.2708989189517115

Epoch: 5| Step: 8
Training loss: 2.076110363006592
Validation loss: 2.254686414554555

Epoch: 5| Step: 9
Training loss: 3.3182175159454346
Validation loss: 2.2533866102977465

Epoch: 5| Step: 10
Training loss: 2.365224599838257
Validation loss: 2.2420849005381265

Epoch: 41| Step: 0
Training loss: 2.11690354347229
Validation loss: 2.2474527512827227

Epoch: 5| Step: 1
Training loss: 2.7078800201416016
Validation loss: 2.269951899846395

Epoch: 5| Step: 2
Training loss: 2.6038432121276855
Validation loss: 2.317368268966675

Epoch: 5| Step: 3
Training loss: 2.350037097930908
Validation loss: 2.2950930108306227

Epoch: 5| Step: 4
Training loss: 2.5993919372558594
Validation loss: 2.261432529777609

Epoch: 5| Step: 5
Training loss: 2.472419261932373
Validation loss: 2.229877746233376

Epoch: 5| Step: 6
Training loss: 2.751164674758911
Validation loss: 2.2168968492938625

Epoch: 5| Step: 7
Training loss: 1.7834430932998657
Validation loss: 2.2173934444304435

Epoch: 5| Step: 8
Training loss: 2.7384769916534424
Validation loss: 2.2139228543927594

Epoch: 5| Step: 9
Training loss: 2.264596462249756
Validation loss: 2.223756787597492

Epoch: 5| Step: 10
Training loss: 3.740950345993042
Validation loss: 2.2228771307135142

Epoch: 42| Step: 0
Training loss: 2.3780834674835205
Validation loss: 2.2286537975393315

Epoch: 5| Step: 1
Training loss: 1.8534018993377686
Validation loss: 2.2452754743637575

Epoch: 5| Step: 2
Training loss: 2.362309217453003
Validation loss: 2.2440566273145777

Epoch: 5| Step: 3
Training loss: 2.47601318359375
Validation loss: 2.242961968145063

Epoch: 5| Step: 4
Training loss: 2.375082492828369
Validation loss: 2.2527640673422042

Epoch: 5| Step: 5
Training loss: 2.866116523742676
Validation loss: 2.2669302545567995

Epoch: 5| Step: 6
Training loss: 2.331623077392578
Validation loss: 2.2755860410710818

Epoch: 5| Step: 7
Training loss: 2.8543407917022705
Validation loss: 2.275413929775197

Epoch: 5| Step: 8
Training loss: 3.0992159843444824
Validation loss: 2.2516894045696465

Epoch: 5| Step: 9
Training loss: 2.579768657684326
Validation loss: 2.2150161240690496

Epoch: 5| Step: 10
Training loss: 2.7067816257476807
Validation loss: 2.2026168646350985

Epoch: 43| Step: 0
Training loss: 2.9831879138946533
Validation loss: 2.202122639584285

Epoch: 5| Step: 1
Training loss: 2.493752956390381
Validation loss: 2.2032013503454064

Epoch: 5| Step: 2
Training loss: 2.3169219493865967
Validation loss: 2.204337291820075

Epoch: 5| Step: 3
Training loss: 2.120500087738037
Validation loss: 2.2041379405606176

Epoch: 5| Step: 4
Training loss: 2.4262795448303223
Validation loss: 2.207619108179564

Epoch: 5| Step: 5
Training loss: 1.904801607131958
Validation loss: 2.2341906165563934

Epoch: 5| Step: 6
Training loss: 2.2516660690307617
Validation loss: 2.279051101335915

Epoch: 5| Step: 7
Training loss: 2.7911782264709473
Validation loss: 2.328021764755249

Epoch: 5| Step: 8
Training loss: 3.2169976234436035
Validation loss: 2.351258785493912

Epoch: 5| Step: 9
Training loss: 2.5170319080352783
Validation loss: 2.34617026646932

Epoch: 5| Step: 10
Training loss: 3.1030123233795166
Validation loss: 2.3286261122713805

Epoch: 44| Step: 0
Training loss: 2.2333579063415527
Validation loss: 2.2822427211269254

Epoch: 5| Step: 1
Training loss: 2.261629581451416
Validation loss: 2.247961095584336

Epoch: 5| Step: 2
Training loss: 2.902818202972412
Validation loss: 2.226426991083289

Epoch: 5| Step: 3
Training loss: 2.9601027965545654
Validation loss: 2.213043733309674

Epoch: 5| Step: 4
Training loss: 2.3025736808776855
Validation loss: 2.1977923762413765

Epoch: 5| Step: 5
Training loss: 3.109473705291748
Validation loss: 2.200842160050587

Epoch: 5| Step: 6
Training loss: 2.337740421295166
Validation loss: 2.204885385369742

Epoch: 5| Step: 7
Training loss: 2.3704686164855957
Validation loss: 2.2044895810465657

Epoch: 5| Step: 8
Training loss: 2.6034460067749023
Validation loss: 2.1952656956129175

Epoch: 5| Step: 9
Training loss: 2.3738741874694824
Validation loss: 2.200221256543231

Epoch: 5| Step: 10
Training loss: 2.2374625205993652
Validation loss: 2.210775024147444

Epoch: 45| Step: 0
Training loss: 2.1431987285614014
Validation loss: 2.2305649595875896

Epoch: 5| Step: 1
Training loss: 2.7509284019470215
Validation loss: 2.2718927103986024

Epoch: 5| Step: 2
Training loss: 2.3630409240722656
Validation loss: 2.3200988718258437

Epoch: 5| Step: 3
Training loss: 2.217311382293701
Validation loss: 2.320111866920225

Epoch: 5| Step: 4
Training loss: 2.7912516593933105
Validation loss: 2.292655578223608

Epoch: 5| Step: 5
Training loss: 2.620356559753418
Validation loss: 2.283365447034118

Epoch: 5| Step: 6
Training loss: 2.4994306564331055
Validation loss: 2.26626605115911

Epoch: 5| Step: 7
Training loss: 2.0603883266448975
Validation loss: 2.245538798711633

Epoch: 5| Step: 8
Training loss: 2.799424171447754
Validation loss: 2.2319995895508797

Epoch: 5| Step: 9
Training loss: 2.6736931800842285
Validation loss: 2.20421003782621

Epoch: 5| Step: 10
Training loss: 2.725299596786499
Validation loss: 2.192387101470783

Epoch: 46| Step: 0
Training loss: 2.9768013954162598
Validation loss: 2.189119355652922

Epoch: 5| Step: 1
Training loss: 3.041718006134033
Validation loss: 2.1919750603296424

Epoch: 5| Step: 2
Training loss: 2.7421841621398926
Validation loss: 2.194881457154469

Epoch: 5| Step: 3
Training loss: 2.5551674365997314
Validation loss: 2.191302361026887

Epoch: 5| Step: 4
Training loss: 2.037097215652466
Validation loss: 2.197846665177294

Epoch: 5| Step: 5
Training loss: 2.4846420288085938
Validation loss: 2.2204426232204644

Epoch: 5| Step: 6
Training loss: 2.4244954586029053
Validation loss: 2.2729509953529603

Epoch: 5| Step: 7
Training loss: 2.0072715282440186
Validation loss: 2.3309130873731387

Epoch: 5| Step: 8
Training loss: 2.5412232875823975
Validation loss: 2.389580821478239

Epoch: 5| Step: 9
Training loss: 2.2017900943756104
Validation loss: 2.395375795261834

Epoch: 5| Step: 10
Training loss: 2.9709739685058594
Validation loss: 2.3892814549066688

Epoch: 47| Step: 0
Training loss: 2.8129446506500244
Validation loss: 2.335187928650969

Epoch: 5| Step: 1
Training loss: 2.8270702362060547
Validation loss: 2.3020245900718113

Epoch: 5| Step: 2
Training loss: 2.9704902172088623
Validation loss: 2.269277366258765

Epoch: 5| Step: 3
Training loss: 2.0896310806274414
Validation loss: 2.254228436818687

Epoch: 5| Step: 4
Training loss: 2.5561509132385254
Validation loss: 2.2296956149480676

Epoch: 5| Step: 5
Training loss: 2.100430965423584
Validation loss: 2.223510116659185

Epoch: 5| Step: 6
Training loss: 2.6869070529937744
Validation loss: 2.216603772614592

Epoch: 5| Step: 7
Training loss: 2.045581102371216
Validation loss: 2.2363367836962462

Epoch: 5| Step: 8
Training loss: 2.159846782684326
Validation loss: 2.2581761216604583

Epoch: 5| Step: 9
Training loss: 3.1013779640197754
Validation loss: 2.2872857304029566

Epoch: 5| Step: 10
Training loss: 2.3939292430877686
Validation loss: 2.3068468109253915

Epoch: 48| Step: 0
Training loss: 3.0316174030303955
Validation loss: 2.303448497608144

Epoch: 5| Step: 1
Training loss: 2.6152005195617676
Validation loss: 2.312286356444

Epoch: 5| Step: 2
Training loss: 2.550309658050537
Validation loss: 2.2876240130393737

Epoch: 5| Step: 3
Training loss: 2.864427089691162
Validation loss: 2.275178414519115

Epoch: 5| Step: 4
Training loss: 2.377363443374634
Validation loss: 2.2572265645509124

Epoch: 5| Step: 5
Training loss: 2.1642918586730957
Validation loss: 2.2441035983383015

Epoch: 5| Step: 6
Training loss: 2.649815559387207
Validation loss: 2.2454791556122484

Epoch: 5| Step: 7
Training loss: 1.5205003023147583
Validation loss: 2.242074720321163

Epoch: 5| Step: 8
Training loss: 2.2289819717407227
Validation loss: 2.238682628959738

Epoch: 5| Step: 9
Training loss: 2.8860297203063965
Validation loss: 2.2434909112991823

Epoch: 5| Step: 10
Training loss: 2.8374037742614746
Validation loss: 2.230353897617709

Epoch: 49| Step: 0
Training loss: 1.9166316986083984
Validation loss: 2.2291806513263333

Epoch: 5| Step: 1
Training loss: 2.1889803409576416
Validation loss: 2.212836088672761

Epoch: 5| Step: 2
Training loss: 2.639122486114502
Validation loss: 2.207193636125134

Epoch: 5| Step: 3
Training loss: 2.291304349899292
Validation loss: 2.20289247779436

Epoch: 5| Step: 4
Training loss: 2.6184418201446533
Validation loss: 2.2053718374621485

Epoch: 5| Step: 5
Training loss: 2.6315104961395264
Validation loss: 2.202066813745806

Epoch: 5| Step: 6
Training loss: 3.2404942512512207
Validation loss: 2.222488059792467

Epoch: 5| Step: 7
Training loss: 2.338125228881836
Validation loss: 2.2341202625664334

Epoch: 5| Step: 8
Training loss: 2.2734055519104004
Validation loss: 2.2514080386007986

Epoch: 5| Step: 9
Training loss: 2.8846659660339355
Validation loss: 2.266345662455405

Epoch: 5| Step: 10
Training loss: 2.39315128326416
Validation loss: 2.2350081730914373

Epoch: 50| Step: 0
Training loss: 2.1071877479553223
Validation loss: 2.2151802842335035

Epoch: 5| Step: 1
Training loss: 1.6368238925933838
Validation loss: 2.200669801363381

Epoch: 5| Step: 2
Training loss: 2.798027515411377
Validation loss: 2.199624184639223

Epoch: 5| Step: 3
Training loss: 2.660994052886963
Validation loss: 2.1778796718966578

Epoch: 5| Step: 4
Training loss: 2.7223961353302
Validation loss: 2.225577026285151

Epoch: 5| Step: 5
Training loss: 2.9233875274658203
Validation loss: 2.230248546087614

Epoch: 5| Step: 6
Training loss: 2.0129711627960205
Validation loss: 2.212289930671774

Epoch: 5| Step: 7
Training loss: 2.1537389755249023
Validation loss: 2.2074860001123078

Epoch: 5| Step: 8
Training loss: 2.8041915893554688
Validation loss: 2.199887660241896

Epoch: 5| Step: 9
Training loss: 2.516721725463867
Validation loss: 2.193290777103875

Epoch: 5| Step: 10
Training loss: 3.3416824340820312
Validation loss: 2.2025323965216197

Epoch: 51| Step: 0
Training loss: 2.755751132965088
Validation loss: 2.204180017594368

Epoch: 5| Step: 1
Training loss: 2.309502124786377
Validation loss: 2.2080273474416425

Epoch: 5| Step: 2
Training loss: 2.0350565910339355
Validation loss: 2.196005650745925

Epoch: 5| Step: 3
Training loss: 2.3243725299835205
Validation loss: 2.188597550956152

Epoch: 5| Step: 4
Training loss: 1.8436775207519531
Validation loss: 2.194310430557497

Epoch: 5| Step: 5
Training loss: 2.7998173236846924
Validation loss: 2.224089781443278

Epoch: 5| Step: 6
Training loss: 2.3837790489196777
Validation loss: 2.215923532362907

Epoch: 5| Step: 7
Training loss: 1.7607609033584595
Validation loss: 2.218541406816052

Epoch: 5| Step: 8
Training loss: 3.167987823486328
Validation loss: 2.2221817149910876

Epoch: 5| Step: 9
Training loss: 3.1021666526794434
Validation loss: 2.2354931036631265

Epoch: 5| Step: 10
Training loss: 2.8703696727752686
Validation loss: 2.2375430240426013

Epoch: 52| Step: 0
Training loss: 2.303593397140503
Validation loss: 2.2345665090827533

Epoch: 5| Step: 1
Training loss: 2.8638827800750732
Validation loss: 2.235771161253734

Epoch: 5| Step: 2
Training loss: 2.081049680709839
Validation loss: 2.2043551821862497

Epoch: 5| Step: 3
Training loss: 1.7193714380264282
Validation loss: 2.1879512340791765

Epoch: 5| Step: 4
Training loss: 2.9548397064208984
Validation loss: 2.181893059002456

Epoch: 5| Step: 5
Training loss: 2.373495101928711
Validation loss: 2.1753967590229486

Epoch: 5| Step: 6
Training loss: 2.096475601196289
Validation loss: 2.176736534282725

Epoch: 5| Step: 7
Training loss: 2.9319825172424316
Validation loss: 2.1786458979370775

Epoch: 5| Step: 8
Training loss: 2.9100353717803955
Validation loss: 2.178103913543045

Epoch: 5| Step: 9
Training loss: 2.525850534439087
Validation loss: 2.172487307620305

Epoch: 5| Step: 10
Training loss: 2.428415060043335
Validation loss: 2.1820705757346204

Epoch: 53| Step: 0
Training loss: 2.894601345062256
Validation loss: 2.1777511130097094

Epoch: 5| Step: 1
Training loss: 1.967142105102539
Validation loss: 2.188065113559846

Epoch: 5| Step: 2
Training loss: 2.115692615509033
Validation loss: 2.20101249089805

Epoch: 5| Step: 3
Training loss: 2.6889443397521973
Validation loss: 2.2186202797838437

Epoch: 5| Step: 4
Training loss: 2.524679183959961
Validation loss: 2.2207435356673373

Epoch: 5| Step: 5
Training loss: 2.1267027854919434
Validation loss: 2.2029540179878153

Epoch: 5| Step: 6
Training loss: 2.8827998638153076
Validation loss: 2.1824473129805697

Epoch: 5| Step: 7
Training loss: 2.1235272884368896
Validation loss: 2.1727814764104862

Epoch: 5| Step: 8
Training loss: 2.636073589324951
Validation loss: 2.147951582426666

Epoch: 5| Step: 9
Training loss: 2.45106840133667
Validation loss: 2.14768966808114

Epoch: 5| Step: 10
Training loss: 2.591369152069092
Validation loss: 2.1516409484289025

Epoch: 54| Step: 0
Training loss: 2.8641304969787598
Validation loss: 2.147876253692053

Epoch: 5| Step: 1
Training loss: 2.343996524810791
Validation loss: 2.1560398558134675

Epoch: 5| Step: 2
Training loss: 2.54233980178833
Validation loss: 2.1673916668020268

Epoch: 5| Step: 3
Training loss: 2.2373931407928467
Validation loss: 2.1573823139231694

Epoch: 5| Step: 4
Training loss: 2.3651976585388184
Validation loss: 2.146352102679591

Epoch: 5| Step: 5
Training loss: 2.5966880321502686
Validation loss: 2.1647521808583248

Epoch: 5| Step: 6
Training loss: 2.5934224128723145
Validation loss: 2.1929526252131306

Epoch: 5| Step: 7
Training loss: 1.961735486984253
Validation loss: 2.242039465135144

Epoch: 5| Step: 8
Training loss: 2.981720447540283
Validation loss: 2.291708315572431

Epoch: 5| Step: 9
Training loss: 1.9544391632080078
Validation loss: 2.3179439395986576

Epoch: 5| Step: 10
Training loss: 2.934028148651123
Validation loss: 2.3058759730349303

Epoch: 55| Step: 0
Training loss: 2.6450142860412598
Validation loss: 2.2718014896556897

Epoch: 5| Step: 1
Training loss: 2.5716872215270996
Validation loss: 2.237654819283434

Epoch: 5| Step: 2
Training loss: 2.3356456756591797
Validation loss: 2.214017246359138

Epoch: 5| Step: 3
Training loss: 2.9995226860046387
Validation loss: 2.1982472019810833

Epoch: 5| Step: 4
Training loss: 1.5884453058242798
Validation loss: 2.1799840337486676

Epoch: 5| Step: 5
Training loss: 2.098238468170166
Validation loss: 2.190369326581237

Epoch: 5| Step: 6
Training loss: 2.531747341156006
Validation loss: 2.178693163779474

Epoch: 5| Step: 7
Training loss: 3.1674904823303223
Validation loss: 2.183889114728538

Epoch: 5| Step: 8
Training loss: 2.453813076019287
Validation loss: 2.1611472227240123

Epoch: 5| Step: 9
Training loss: 2.049215316772461
Validation loss: 2.1419234352727092

Epoch: 5| Step: 10
Training loss: 2.378617286682129
Validation loss: 2.139046730533723

Epoch: 56| Step: 0
Training loss: 3.034560203552246
Validation loss: 2.1345476540186072

Epoch: 5| Step: 1
Training loss: 2.3309733867645264
Validation loss: 2.138330413449195

Epoch: 5| Step: 2
Training loss: 2.635528326034546
Validation loss: 2.13253644974001

Epoch: 5| Step: 3
Training loss: 2.531444787979126
Validation loss: 2.134788413201609

Epoch: 5| Step: 4
Training loss: 2.8949897289276123
Validation loss: 2.138548094739196

Epoch: 5| Step: 5
Training loss: 2.160710573196411
Validation loss: 2.14106455028698

Epoch: 5| Step: 6
Training loss: 1.911895751953125
Validation loss: 2.1484036804527364

Epoch: 5| Step: 7
Training loss: 2.204615592956543
Validation loss: 2.1482107895676807

Epoch: 5| Step: 8
Training loss: 2.241166591644287
Validation loss: 2.155085191931776

Epoch: 5| Step: 9
Training loss: 2.3633499145507812
Validation loss: 2.1555979867135324

Epoch: 5| Step: 10
Training loss: 2.5904107093811035
Validation loss: 2.146971335975073

Epoch: 57| Step: 0
Training loss: 2.5393853187561035
Validation loss: 2.142079572523794

Epoch: 5| Step: 1
Training loss: 2.685826539993286
Validation loss: 2.153881303725704

Epoch: 5| Step: 2
Training loss: 1.8904775381088257
Validation loss: 2.1601352883923437

Epoch: 5| Step: 3
Training loss: 2.5203773975372314
Validation loss: 2.163318610960437

Epoch: 5| Step: 4
Training loss: 2.645051956176758
Validation loss: 2.1477980113798574

Epoch: 5| Step: 5
Training loss: 2.5840554237365723
Validation loss: 2.15633217493693

Epoch: 5| Step: 6
Training loss: 2.080902099609375
Validation loss: 2.167188690554711

Epoch: 5| Step: 7
Training loss: 2.121209144592285
Validation loss: 2.1537464023918234

Epoch: 5| Step: 8
Training loss: 2.3471856117248535
Validation loss: 2.156377205284693

Epoch: 5| Step: 9
Training loss: 2.4890778064727783
Validation loss: 2.1611027922681583

Epoch: 5| Step: 10
Training loss: 2.8366143703460693
Validation loss: 2.1506090856367543

Epoch: 58| Step: 0
Training loss: 2.0526556968688965
Validation loss: 2.134147274878717

Epoch: 5| Step: 1
Training loss: 2.2173073291778564
Validation loss: 2.1254226687133952

Epoch: 5| Step: 2
Training loss: 2.7844438552856445
Validation loss: 2.1284476326357935

Epoch: 5| Step: 3
Training loss: 2.655102491378784
Validation loss: 2.1285808368395736

Epoch: 5| Step: 4
Training loss: 2.8189475536346436
Validation loss: 2.1339323456569383

Epoch: 5| Step: 5
Training loss: 2.776395559310913
Validation loss: 2.1382822246961695

Epoch: 5| Step: 6
Training loss: 2.417457103729248
Validation loss: 2.1277391449097665

Epoch: 5| Step: 7
Training loss: 2.190908908843994
Validation loss: 2.127551583833592

Epoch: 5| Step: 8
Training loss: 2.4930405616760254
Validation loss: 2.1367562765716226

Epoch: 5| Step: 9
Training loss: 2.311206102371216
Validation loss: 2.152083126447534

Epoch: 5| Step: 10
Training loss: 2.0052623748779297
Validation loss: 2.1751677131140106

Epoch: 59| Step: 0
Training loss: 2.2622110843658447
Validation loss: 2.2383317742296445

Epoch: 5| Step: 1
Training loss: 2.252138137817383
Validation loss: 2.2826436693950365

Epoch: 5| Step: 2
Training loss: 2.139047384262085
Validation loss: 2.27759389979865

Epoch: 5| Step: 3
Training loss: 2.288421392440796
Validation loss: 2.268540359312488

Epoch: 5| Step: 4
Training loss: 2.661945343017578
Validation loss: 2.233818233654063

Epoch: 5| Step: 5
Training loss: 2.946629285812378
Validation loss: 2.160725771739919

Epoch: 5| Step: 6
Training loss: 2.6643593311309814
Validation loss: 2.14086922009786

Epoch: 5| Step: 7
Training loss: 2.1962687969207764
Validation loss: 2.154872966069047

Epoch: 5| Step: 8
Training loss: 2.1212151050567627
Validation loss: 2.20438281695048

Epoch: 5| Step: 9
Training loss: 2.7736356258392334
Validation loss: 2.202799202293478

Epoch: 5| Step: 10
Training loss: 2.8451621532440186
Validation loss: 2.1856917565868748

Epoch: 60| Step: 0
Training loss: 3.0429394245147705
Validation loss: 2.163337726746836

Epoch: 5| Step: 1
Training loss: 1.8443653583526611
Validation loss: 2.142315879944832

Epoch: 5| Step: 2
Training loss: 2.0245413780212402
Validation loss: 2.127768139685354

Epoch: 5| Step: 3
Training loss: 2.458021640777588
Validation loss: 2.1228125300458682

Epoch: 5| Step: 4
Training loss: 2.4757485389709473
Validation loss: 2.138394727501818

Epoch: 5| Step: 5
Training loss: 2.532944917678833
Validation loss: 2.1580842105291222

Epoch: 5| Step: 6
Training loss: 2.2974772453308105
Validation loss: 2.1824655891746603

Epoch: 5| Step: 7
Training loss: 3.0321857929229736
Validation loss: 2.1827389463301627

Epoch: 5| Step: 8
Training loss: 2.5125677585601807
Validation loss: 2.179915187179401

Epoch: 5| Step: 9
Training loss: 1.7522153854370117
Validation loss: 2.171274354380946

Epoch: 5| Step: 10
Training loss: 2.89341402053833
Validation loss: 2.1524815764478458

Epoch: 61| Step: 0
Training loss: 3.034945249557495
Validation loss: 2.134337256031652

Epoch: 5| Step: 1
Training loss: 2.371018171310425
Validation loss: 2.1373794194190734

Epoch: 5| Step: 2
Training loss: 2.32838773727417
Validation loss: 2.1166789736799014

Epoch: 5| Step: 3
Training loss: 1.8671200275421143
Validation loss: 2.1193390533488285

Epoch: 5| Step: 4
Training loss: 1.8994553089141846
Validation loss: 2.1079401328999507

Epoch: 5| Step: 5
Training loss: 2.070305347442627
Validation loss: 2.115551240982548

Epoch: 5| Step: 6
Training loss: 2.910020351409912
Validation loss: 2.1173738459105134

Epoch: 5| Step: 7
Training loss: 2.665910243988037
Validation loss: 2.1289189118210987

Epoch: 5| Step: 8
Training loss: 2.2987208366394043
Validation loss: 2.1289689105044127

Epoch: 5| Step: 9
Training loss: 2.8418803215026855
Validation loss: 2.1381940777583788

Epoch: 5| Step: 10
Training loss: 2.2009902000427246
Validation loss: 2.1336377256660053

Epoch: 62| Step: 0
Training loss: 1.971266508102417
Validation loss: 2.1358566873817035

Epoch: 5| Step: 1
Training loss: 2.155521869659424
Validation loss: 2.1384104092915854

Epoch: 5| Step: 2
Training loss: 3.0663440227508545
Validation loss: 2.1387333690479235

Epoch: 5| Step: 3
Training loss: 2.419656276702881
Validation loss: 2.1324819390491774

Epoch: 5| Step: 4
Training loss: 2.5167737007141113
Validation loss: 2.1306956878272434

Epoch: 5| Step: 5
Training loss: 1.724172830581665
Validation loss: 2.129706514778958

Epoch: 5| Step: 6
Training loss: 3.159858226776123
Validation loss: 2.1232920308266916

Epoch: 5| Step: 7
Training loss: 1.5559179782867432
Validation loss: 2.1143648803875013

Epoch: 5| Step: 8
Training loss: 2.697624683380127
Validation loss: 2.1223142775156165

Epoch: 5| Step: 9
Training loss: 2.941066026687622
Validation loss: 2.1181094595181045

Epoch: 5| Step: 10
Training loss: 2.465374708175659
Validation loss: 2.121440226031888

Epoch: 63| Step: 0
Training loss: 2.6850295066833496
Validation loss: 2.1325794778844362

Epoch: 5| Step: 1
Training loss: 2.4843392372131348
Validation loss: 2.152621752472334

Epoch: 5| Step: 2
Training loss: 2.441135883331299
Validation loss: 2.1770732659165577

Epoch: 5| Step: 3
Training loss: 2.337955951690674
Validation loss: 2.1958813487842517

Epoch: 5| Step: 4
Training loss: 3.0222389698028564
Validation loss: 2.2015700750453497

Epoch: 5| Step: 5
Training loss: 2.1504828929901123
Validation loss: 2.1926073566559823

Epoch: 5| Step: 6
Training loss: 2.588430881500244
Validation loss: 2.1648833495314403

Epoch: 5| Step: 7
Training loss: 2.549041748046875
Validation loss: 2.1269222382576234

Epoch: 5| Step: 8
Training loss: 2.258072853088379
Validation loss: 2.1085983578876784

Epoch: 5| Step: 9
Training loss: 1.4831657409667969
Validation loss: 2.0958394811999415

Epoch: 5| Step: 10
Training loss: 2.697995185852051
Validation loss: 2.0955110083344164

Epoch: 64| Step: 0
Training loss: 1.9822676181793213
Validation loss: 2.094016026425105

Epoch: 5| Step: 1
Training loss: 2.0808773040771484
Validation loss: 2.101848720222391

Epoch: 5| Step: 2
Training loss: 2.8480892181396484
Validation loss: 2.103973942418252

Epoch: 5| Step: 3
Training loss: 2.6386218070983887
Validation loss: 2.1094525578201457

Epoch: 5| Step: 4
Training loss: 2.250321388244629
Validation loss: 2.1118503462883735

Epoch: 5| Step: 5
Training loss: 3.045360565185547
Validation loss: 2.1111033616527433

Epoch: 5| Step: 6
Training loss: 2.305309772491455
Validation loss: 2.105946353686753

Epoch: 5| Step: 7
Training loss: 2.576845645904541
Validation loss: 2.107856591542562

Epoch: 5| Step: 8
Training loss: 2.166533946990967
Validation loss: 2.105654775455434

Epoch: 5| Step: 9
Training loss: 2.269237756729126
Validation loss: 2.097622622725784

Epoch: 5| Step: 10
Training loss: 2.1977667808532715
Validation loss: 2.0952798217855473

Epoch: 65| Step: 0
Training loss: 2.5605952739715576
Validation loss: 2.0877682252596785

Epoch: 5| Step: 1
Training loss: 2.871671438217163
Validation loss: 2.0896882587863552

Epoch: 5| Step: 2
Training loss: 2.6503207683563232
Validation loss: 2.0914097293730705

Epoch: 5| Step: 3
Training loss: 1.8354524374008179
Validation loss: 2.090744556919221

Epoch: 5| Step: 4
Training loss: 1.7347053289413452
Validation loss: 2.10218370217149

Epoch: 5| Step: 5
Training loss: 2.0197930335998535
Validation loss: 2.104533264713903

Epoch: 5| Step: 6
Training loss: 2.3487210273742676
Validation loss: 2.1032357164608535

Epoch: 5| Step: 7
Training loss: 2.827096462249756
Validation loss: 2.116082740086381

Epoch: 5| Step: 8
Training loss: 2.3968558311462402
Validation loss: 2.125828266143799

Epoch: 5| Step: 9
Training loss: 2.3701460361480713
Validation loss: 2.1231412977300663

Epoch: 5| Step: 10
Training loss: 2.738734483718872
Validation loss: 2.1190905288983415

Epoch: 66| Step: 0
Training loss: 2.509303331375122
Validation loss: 2.1142978629758282

Epoch: 5| Step: 1
Training loss: 2.3834385871887207
Validation loss: 2.103606076650722

Epoch: 5| Step: 2
Training loss: 2.535799026489258
Validation loss: 2.0899100585650374

Epoch: 5| Step: 3
Training loss: 2.1301662921905518
Validation loss: 2.083306017742362

Epoch: 5| Step: 4
Training loss: 2.2885184288024902
Validation loss: 2.079625214299848

Epoch: 5| Step: 5
Training loss: 2.6153769493103027
Validation loss: 2.077769285889082

Epoch: 5| Step: 6
Training loss: 2.2261621952056885
Validation loss: 2.082783677244699

Epoch: 5| Step: 7
Training loss: 2.1172308921813965
Validation loss: 2.071256337627288

Epoch: 5| Step: 8
Training loss: 2.4520323276519775
Validation loss: 2.0754486642858034

Epoch: 5| Step: 9
Training loss: 2.407627820968628
Validation loss: 2.078315434917327

Epoch: 5| Step: 10
Training loss: 2.7009143829345703
Validation loss: 2.0933396252252723

Epoch: 67| Step: 0
Training loss: 2.4568004608154297
Validation loss: 2.1167938529804187

Epoch: 5| Step: 1
Training loss: 2.634704351425171
Validation loss: 2.1254496664129277

Epoch: 5| Step: 2
Training loss: 2.7654592990875244
Validation loss: 2.149857126256471

Epoch: 5| Step: 3
Training loss: 1.8626601696014404
Validation loss: 2.1426628533230034

Epoch: 5| Step: 4
Training loss: 2.4343948364257812
Validation loss: 2.13335915406545

Epoch: 5| Step: 5
Training loss: 2.1483254432678223
Validation loss: 2.1047586266712477

Epoch: 5| Step: 6
Training loss: 2.102978229522705
Validation loss: 2.0968570273409606

Epoch: 5| Step: 7
Training loss: 2.681255340576172
Validation loss: 2.0740771678186234

Epoch: 5| Step: 8
Training loss: 2.482879400253296
Validation loss: 2.0671588413177

Epoch: 5| Step: 9
Training loss: 2.768712282180786
Validation loss: 2.0731601022904917

Epoch: 5| Step: 10
Training loss: 2.0682995319366455
Validation loss: 2.070806626350649

Epoch: 68| Step: 0
Training loss: 2.6250760555267334
Validation loss: 2.066548183400144

Epoch: 5| Step: 1
Training loss: 2.52787446975708
Validation loss: 2.06478298864057

Epoch: 5| Step: 2
Training loss: 2.4403316974639893
Validation loss: 2.060138461410358

Epoch: 5| Step: 3
Training loss: 2.119321823120117
Validation loss: 2.0704108720184653

Epoch: 5| Step: 4
Training loss: 2.960378646850586
Validation loss: 2.0832131472967004

Epoch: 5| Step: 5
Training loss: 2.6526808738708496
Validation loss: 2.090887120974961

Epoch: 5| Step: 6
Training loss: 2.1815524101257324
Validation loss: 2.1070399976545766

Epoch: 5| Step: 7
Training loss: 1.7372257709503174
Validation loss: 2.1174045660162486

Epoch: 5| Step: 8
Training loss: 2.132606029510498
Validation loss: 2.1079384972972255

Epoch: 5| Step: 9
Training loss: 2.5079541206359863
Validation loss: 2.11012795407285

Epoch: 5| Step: 10
Training loss: 2.1307787895202637
Validation loss: 2.095599833355155

Epoch: 69| Step: 0
Training loss: 2.375293493270874
Validation loss: 2.1014762898927093

Epoch: 5| Step: 1
Training loss: 2.109127998352051
Validation loss: 2.1063662831501295

Epoch: 5| Step: 2
Training loss: 2.541377305984497
Validation loss: 2.1031205897690146

Epoch: 5| Step: 3
Training loss: 1.7965551614761353
Validation loss: 2.1014717676306285

Epoch: 5| Step: 4
Training loss: 2.7244629859924316
Validation loss: 2.107670792969324

Epoch: 5| Step: 5
Training loss: 2.885505199432373
Validation loss: 2.09242767928749

Epoch: 5| Step: 6
Training loss: 2.681550979614258
Validation loss: 2.087034413891454

Epoch: 5| Step: 7
Training loss: 2.284419298171997
Validation loss: 2.080333666134906

Epoch: 5| Step: 8
Training loss: 2.458357095718384
Validation loss: 2.0802876410945768

Epoch: 5| Step: 9
Training loss: 2.3221945762634277
Validation loss: 2.078000242992114

Epoch: 5| Step: 10
Training loss: 1.736393928527832
Validation loss: 2.0763803605110414

Epoch: 70| Step: 0
Training loss: 2.6158695220947266
Validation loss: 2.0653129418691

Epoch: 5| Step: 1
Training loss: 2.164039134979248
Validation loss: 2.0710575708778958

Epoch: 5| Step: 2
Training loss: 1.7836936712265015
Validation loss: 2.069051170861849

Epoch: 5| Step: 3
Training loss: 2.2199862003326416
Validation loss: 2.0739081700642905

Epoch: 5| Step: 4
Training loss: 1.9026187658309937
Validation loss: 2.0871007237383115

Epoch: 5| Step: 5
Training loss: 2.382183313369751
Validation loss: 2.1041415122247513

Epoch: 5| Step: 6
Training loss: 2.350447654724121
Validation loss: 2.0864996628094743

Epoch: 5| Step: 7
Training loss: 2.7663238048553467
Validation loss: 2.088236883122434

Epoch: 5| Step: 8
Training loss: 2.2425525188446045
Validation loss: 2.0683059628291796

Epoch: 5| Step: 9
Training loss: 2.3428800106048584
Validation loss: 2.061541647039434

Epoch: 5| Step: 10
Training loss: 3.3627841472625732
Validation loss: 2.069087977050453

Epoch: 71| Step: 0
Training loss: 2.9874730110168457
Validation loss: 2.063323167062575

Epoch: 5| Step: 1
Training loss: 2.4780609607696533
Validation loss: 2.053538255794074

Epoch: 5| Step: 2
Training loss: 2.472303867340088
Validation loss: 2.0618264495685534

Epoch: 5| Step: 3
Training loss: 2.7419230937957764
Validation loss: 2.0631783316212315

Epoch: 5| Step: 4
Training loss: 2.2279820442199707
Validation loss: 2.0695818880552888

Epoch: 5| Step: 5
Training loss: 2.6271398067474365
Validation loss: 2.0727177525079377

Epoch: 5| Step: 6
Training loss: 2.7025487422943115
Validation loss: 2.070350936664048

Epoch: 5| Step: 7
Training loss: 1.7949316501617432
Validation loss: 2.0754803637022614

Epoch: 5| Step: 8
Training loss: 1.6116149425506592
Validation loss: 2.0798747308792604

Epoch: 5| Step: 9
Training loss: 2.0676064491271973
Validation loss: 2.096976867286108

Epoch: 5| Step: 10
Training loss: 2.0764002799987793
Validation loss: 2.0970650616512505

Epoch: 72| Step: 0
Training loss: 2.4972376823425293
Validation loss: 2.084991834496939

Epoch: 5| Step: 1
Training loss: 2.700019121170044
Validation loss: 2.07326513977461

Epoch: 5| Step: 2
Training loss: 2.3167548179626465
Validation loss: 2.0654623252089306

Epoch: 5| Step: 3
Training loss: 2.072744369506836
Validation loss: 2.061850522154121

Epoch: 5| Step: 4
Training loss: 2.3075313568115234
Validation loss: 2.0594262307690037

Epoch: 5| Step: 5
Training loss: 2.1378719806671143
Validation loss: 2.061702262970709

Epoch: 5| Step: 6
Training loss: 2.3104541301727295
Validation loss: 2.06438716765373

Epoch: 5| Step: 7
Training loss: 2.4323039054870605
Validation loss: 2.0639449050349574

Epoch: 5| Step: 8
Training loss: 2.44268536567688
Validation loss: 2.065488640980054

Epoch: 5| Step: 9
Training loss: 2.44207501411438
Validation loss: 2.0655204557603404

Epoch: 5| Step: 10
Training loss: 2.1696457862854004
Validation loss: 2.070151977641608

Epoch: 73| Step: 0
Training loss: 2.5943000316619873
Validation loss: 2.0707312283977384

Epoch: 5| Step: 1
Training loss: 2.306680202484131
Validation loss: 2.071535884693105

Epoch: 5| Step: 2
Training loss: 2.6613268852233887
Validation loss: 2.06213479785509

Epoch: 5| Step: 3
Training loss: 2.2734909057617188
Validation loss: 2.0772444458417993

Epoch: 5| Step: 4
Training loss: 2.1664414405822754
Validation loss: 2.0705435327304307

Epoch: 5| Step: 5
Training loss: 2.4100022315979004
Validation loss: 2.064503738957067

Epoch: 5| Step: 6
Training loss: 2.2140464782714844
Validation loss: 2.0694171126170824

Epoch: 5| Step: 7
Training loss: 2.554577589035034
Validation loss: 2.0587340413883166

Epoch: 5| Step: 8
Training loss: 2.150313377380371
Validation loss: 2.053102284349421

Epoch: 5| Step: 9
Training loss: 2.1973984241485596
Validation loss: 2.0620695519190964

Epoch: 5| Step: 10
Training loss: 2.063890218734741
Validation loss: 2.0595477114441576

Epoch: 74| Step: 0
Training loss: 2.0919270515441895
Validation loss: 2.07384350222926

Epoch: 5| Step: 1
Training loss: 2.2827372550964355
Validation loss: 2.0785384075615996

Epoch: 5| Step: 2
Training loss: 1.9451812505722046
Validation loss: 2.0698615120303248

Epoch: 5| Step: 3
Training loss: 2.3635411262512207
Validation loss: 2.0591868892792733

Epoch: 5| Step: 4
Training loss: 2.175316333770752
Validation loss: 2.0613903973692205

Epoch: 5| Step: 5
Training loss: 2.302137851715088
Validation loss: 2.05618630942478

Epoch: 5| Step: 6
Training loss: 2.345808744430542
Validation loss: 2.0617582669822117

Epoch: 5| Step: 7
Training loss: 2.741014242172241
Validation loss: 2.039429218538346

Epoch: 5| Step: 8
Training loss: 2.4557175636291504
Validation loss: 2.0396498839060464

Epoch: 5| Step: 9
Training loss: 2.8265130519866943
Validation loss: 2.0439389982531146

Epoch: 5| Step: 10
Training loss: 1.9713314771652222
Validation loss: 2.0360101397319506

Epoch: 75| Step: 0
Training loss: 2.1985321044921875
Validation loss: 2.040242615566459

Epoch: 5| Step: 1
Training loss: 2.3615758419036865
Validation loss: 2.0334101389813166

Epoch: 5| Step: 2
Training loss: 2.440659284591675
Validation loss: 2.032827995156729

Epoch: 5| Step: 3
Training loss: 2.0087368488311768
Validation loss: 2.0303534871788433

Epoch: 5| Step: 4
Training loss: 2.170471429824829
Validation loss: 2.043610812515341

Epoch: 5| Step: 5
Training loss: 3.4656920433044434
Validation loss: 2.0546874948727187

Epoch: 5| Step: 6
Training loss: 1.6388221979141235
Validation loss: 2.080949389806358

Epoch: 5| Step: 7
Training loss: 1.9155937433242798
Validation loss: 2.0989388535099645

Epoch: 5| Step: 8
Training loss: 2.8481056690216064
Validation loss: 2.1174308920419342

Epoch: 5| Step: 9
Training loss: 2.771418809890747
Validation loss: 2.104426924900342

Epoch: 5| Step: 10
Training loss: 2.026510000228882
Validation loss: 2.0770588228779454

Epoch: 76| Step: 0
Training loss: 2.329030990600586
Validation loss: 2.0587792537545644

Epoch: 5| Step: 1
Training loss: 1.786226511001587
Validation loss: 2.0541990610861007

Epoch: 5| Step: 2
Training loss: 1.941527009010315
Validation loss: 2.059131250586561

Epoch: 5| Step: 3
Training loss: 1.9302380084991455
Validation loss: 2.0635786082154963

Epoch: 5| Step: 4
Training loss: 2.391526222229004
Validation loss: 2.052809173061002

Epoch: 5| Step: 5
Training loss: 2.2293291091918945
Validation loss: 2.0504039513167513

Epoch: 5| Step: 6
Training loss: 2.337700605392456
Validation loss: 2.0437864539443806

Epoch: 5| Step: 7
Training loss: 2.730551242828369
Validation loss: 2.0507131930320495

Epoch: 5| Step: 8
Training loss: 2.4705810546875
Validation loss: 2.077244786806004

Epoch: 5| Step: 9
Training loss: 2.9606664180755615
Validation loss: 2.0841592563095914

Epoch: 5| Step: 10
Training loss: 2.434999704360962
Validation loss: 2.072960243430189

Epoch: 77| Step: 0
Training loss: 2.528655767440796
Validation loss: 2.0587271541677494

Epoch: 5| Step: 1
Training loss: 1.8206870555877686
Validation loss: 2.0409910627590713

Epoch: 5| Step: 2
Training loss: 2.4745967388153076
Validation loss: 2.0406420769230014

Epoch: 5| Step: 3
Training loss: 2.0960822105407715
Validation loss: 2.0369425973584576

Epoch: 5| Step: 4
Training loss: 2.3034374713897705
Validation loss: 2.034859000995595

Epoch: 5| Step: 5
Training loss: 3.0024850368499756
Validation loss: 2.040863719037784

Epoch: 5| Step: 6
Training loss: 1.925398826599121
Validation loss: 2.049619468309546

Epoch: 5| Step: 7
Training loss: 2.4991581439971924
Validation loss: 2.047643276952928

Epoch: 5| Step: 8
Training loss: 2.5203795433044434
Validation loss: 2.050400564747472

Epoch: 5| Step: 9
Training loss: 2.0386807918548584
Validation loss: 2.047192532529113

Epoch: 5| Step: 10
Training loss: 2.376171350479126
Validation loss: 2.038694267631859

Epoch: 78| Step: 0
Training loss: 1.8617572784423828
Validation loss: 2.039037635249476

Epoch: 5| Step: 1
Training loss: 1.6889406442642212
Validation loss: 2.0381095345302294

Epoch: 5| Step: 2
Training loss: 2.35874342918396
Validation loss: 2.031027323456221

Epoch: 5| Step: 3
Training loss: 1.9150903224945068
Validation loss: 2.047080784715632

Epoch: 5| Step: 4
Training loss: 3.0036356449127197
Validation loss: 2.0392582147352156

Epoch: 5| Step: 5
Training loss: 2.279837131500244
Validation loss: 2.0448542500054963

Epoch: 5| Step: 6
Training loss: 2.5555198192596436
Validation loss: 2.039218674423874

Epoch: 5| Step: 7
Training loss: 2.70772123336792
Validation loss: 2.0449411471684775

Epoch: 5| Step: 8
Training loss: 2.4661684036254883
Validation loss: 2.048105711578041

Epoch: 5| Step: 9
Training loss: 2.468834638595581
Validation loss: 2.0595095016623057

Epoch: 5| Step: 10
Training loss: 2.0966570377349854
Validation loss: 2.050972648846206

Epoch: 79| Step: 0
Training loss: 2.907456636428833
Validation loss: 2.047490350661739

Epoch: 5| Step: 1
Training loss: 2.432201385498047
Validation loss: 2.0405977438854914

Epoch: 5| Step: 2
Training loss: 1.8840274810791016
Validation loss: 2.0425348820224887

Epoch: 5| Step: 3
Training loss: 2.5988285541534424
Validation loss: 2.0348074872006654

Epoch: 5| Step: 4
Training loss: 1.727365493774414
Validation loss: 2.0345451729272

Epoch: 5| Step: 5
Training loss: 2.2314395904541016
Validation loss: 2.0327932911534465

Epoch: 5| Step: 6
Training loss: 2.9546642303466797
Validation loss: 2.0415357902485836

Epoch: 5| Step: 7
Training loss: 1.9669376611709595
Validation loss: 2.04656885772623

Epoch: 5| Step: 8
Training loss: 1.9494670629501343
Validation loss: 2.049563536079981

Epoch: 5| Step: 9
Training loss: 2.030958652496338
Validation loss: 2.072037617365519

Epoch: 5| Step: 10
Training loss: 2.72510027885437
Validation loss: 2.084044487245621

Epoch: 80| Step: 0
Training loss: 2.2506701946258545
Validation loss: 2.0808609377953315

Epoch: 5| Step: 1
Training loss: 1.6613943576812744
Validation loss: 2.1063436551760604

Epoch: 5| Step: 2
Training loss: 2.616746664047241
Validation loss: 2.0810621079578193

Epoch: 5| Step: 3
Training loss: 2.066502094268799
Validation loss: 2.0590691540830877

Epoch: 5| Step: 4
Training loss: 2.871407985687256
Validation loss: 2.0334305429971344

Epoch: 5| Step: 5
Training loss: 2.3914661407470703
Validation loss: 2.021451493745209

Epoch: 5| Step: 6
Training loss: 2.1342685222625732
Validation loss: 2.0201163548295216

Epoch: 5| Step: 7
Training loss: 2.480093240737915
Validation loss: 2.016961148990098

Epoch: 5| Step: 8
Training loss: 1.9714866876602173
Validation loss: 2.027114409272389

Epoch: 5| Step: 9
Training loss: 2.5233230590820312
Validation loss: 2.040630832795174

Epoch: 5| Step: 10
Training loss: 2.500441312789917
Validation loss: 2.0390662736790155

Epoch: 81| Step: 0
Training loss: 2.3398163318634033
Validation loss: 2.0364735421314033

Epoch: 5| Step: 1
Training loss: 1.8773953914642334
Validation loss: 2.0240117593478133

Epoch: 5| Step: 2
Training loss: 2.4972786903381348
Validation loss: 2.0192069674050934

Epoch: 5| Step: 3
Training loss: 2.789414644241333
Validation loss: 2.0158113420650525

Epoch: 5| Step: 4
Training loss: 2.2629148960113525
Validation loss: 2.023255932715631

Epoch: 5| Step: 5
Training loss: 1.8078391551971436
Validation loss: 2.0177800270818893

Epoch: 5| Step: 6
Training loss: 1.8622095584869385
Validation loss: 2.022712181973201

Epoch: 5| Step: 7
Training loss: 2.4770383834838867
Validation loss: 2.036714906333595

Epoch: 5| Step: 8
Training loss: 1.9401161670684814
Validation loss: 2.0498002357380365

Epoch: 5| Step: 9
Training loss: 2.394789934158325
Validation loss: 2.045219616223407

Epoch: 5| Step: 10
Training loss: 3.177245855331421
Validation loss: 2.0408799750830537

Epoch: 82| Step: 0
Training loss: 2.796511173248291
Validation loss: 2.0457298524918093

Epoch: 5| Step: 1
Training loss: 2.179105520248413
Validation loss: 2.0301596323649087

Epoch: 5| Step: 2
Training loss: 2.9168524742126465
Validation loss: 2.0346452420757664

Epoch: 5| Step: 3
Training loss: 2.2660326957702637
Validation loss: 2.0225228622395504

Epoch: 5| Step: 4
Training loss: 2.2754902839660645
Validation loss: 2.026376155114943

Epoch: 5| Step: 5
Training loss: 2.15356707572937
Validation loss: 2.022595710651849

Epoch: 5| Step: 6
Training loss: 1.4235353469848633
Validation loss: 2.0239389019627727

Epoch: 5| Step: 7
Training loss: 2.3491556644439697
Validation loss: 2.030250399343429

Epoch: 5| Step: 8
Training loss: 2.3116707801818848
Validation loss: 2.0365464456619753

Epoch: 5| Step: 9
Training loss: 2.2670133113861084
Validation loss: 2.0329948727802565

Epoch: 5| Step: 10
Training loss: 2.337355136871338
Validation loss: 2.045939732623357

Epoch: 83| Step: 0
Training loss: 1.6338703632354736
Validation loss: 2.0495036455892746

Epoch: 5| Step: 1
Training loss: 2.120889186859131
Validation loss: 2.0453372309284825

Epoch: 5| Step: 2
Training loss: 2.788727283477783
Validation loss: 2.0507454897767756

Epoch: 5| Step: 3
Training loss: 2.839839458465576
Validation loss: 2.035048770648177

Epoch: 5| Step: 4
Training loss: 2.2654709815979004
Validation loss: 2.033723085157333

Epoch: 5| Step: 5
Training loss: 2.382981777191162
Validation loss: 2.0343150515710153

Epoch: 5| Step: 6
Training loss: 2.204411745071411
Validation loss: 2.0278740031744844

Epoch: 5| Step: 7
Training loss: 2.4426538944244385
Validation loss: 2.0194373438435216

Epoch: 5| Step: 8
Training loss: 2.2934162616729736
Validation loss: 2.019015719813685

Epoch: 5| Step: 9
Training loss: 1.9382025003433228
Validation loss: 2.0053167907140588

Epoch: 5| Step: 10
Training loss: 2.2036149501800537
Validation loss: 2.006678808119989

Epoch: 84| Step: 0
Training loss: 1.6888644695281982
Validation loss: 2.0021617540749173

Epoch: 5| Step: 1
Training loss: 2.5070555210113525
Validation loss: 2.003396012449777

Epoch: 5| Step: 2
Training loss: 2.035886526107788
Validation loss: 2.0134936968485513

Epoch: 5| Step: 3
Training loss: 2.4252521991729736
Validation loss: 2.033864212292497

Epoch: 5| Step: 4
Training loss: 2.334050178527832
Validation loss: 2.040721265218591

Epoch: 5| Step: 5
Training loss: 2.303596258163452
Validation loss: 2.057225068410238

Epoch: 5| Step: 6
Training loss: 2.489600419998169
Validation loss: 2.0525867016084733

Epoch: 5| Step: 7
Training loss: 2.145461320877075
Validation loss: 2.0539934763344387

Epoch: 5| Step: 8
Training loss: 2.543851375579834
Validation loss: 2.05256514651801

Epoch: 5| Step: 9
Training loss: 2.5157320499420166
Validation loss: 2.0412972229783253

Epoch: 5| Step: 10
Training loss: 2.203517436981201
Validation loss: 2.0342077311649116

Epoch: 85| Step: 0
Training loss: 2.0502350330352783
Validation loss: 2.0169948031825404

Epoch: 5| Step: 1
Training loss: 2.4770395755767822
Validation loss: 2.0178878127887683

Epoch: 5| Step: 2
Training loss: 2.890899181365967
Validation loss: 2.014355658203043

Epoch: 5| Step: 3
Training loss: 1.8794975280761719
Validation loss: 2.001585791187902

Epoch: 5| Step: 4
Training loss: 2.972043037414551
Validation loss: 2.0018620106481735

Epoch: 5| Step: 5
Training loss: 1.6291577816009521
Validation loss: 2.0115976615618636

Epoch: 5| Step: 6
Training loss: 2.6398494243621826
Validation loss: 2.013599367551906

Epoch: 5| Step: 7
Training loss: 2.3474068641662598
Validation loss: 2.027901876357294

Epoch: 5| Step: 8
Training loss: 2.1317286491394043
Validation loss: 2.0269858785854873

Epoch: 5| Step: 9
Training loss: 1.8724594116210938
Validation loss: 2.041588044935657

Epoch: 5| Step: 10
Training loss: 2.1964728832244873
Validation loss: 2.0292491015567573

Epoch: 86| Step: 0
Training loss: 2.400480270385742
Validation loss: 2.0195831662865094

Epoch: 5| Step: 1
Training loss: 2.333954334259033
Validation loss: 2.012701144782446

Epoch: 5| Step: 2
Training loss: 2.739867687225342
Validation loss: 2.019225771709155

Epoch: 5| Step: 3
Training loss: 2.113981246948242
Validation loss: 2.0274057388305664

Epoch: 5| Step: 4
Training loss: 2.018815279006958
Validation loss: 2.0268575081261258

Epoch: 5| Step: 5
Training loss: 1.9289648532867432
Validation loss: 2.0245162620339343

Epoch: 5| Step: 6
Training loss: 2.3228859901428223
Validation loss: 2.009189204503131

Epoch: 5| Step: 7
Training loss: 2.8062100410461426
Validation loss: 2.0247957206541494

Epoch: 5| Step: 8
Training loss: 2.372480869293213
Validation loss: 2.0398480456362487

Epoch: 5| Step: 9
Training loss: 2.5075020790100098
Validation loss: 2.0710901739776775

Epoch: 5| Step: 10
Training loss: 1.973301649093628
Validation loss: 2.117032999633461

Epoch: 87| Step: 0
Training loss: 2.245046854019165
Validation loss: 2.116284226858488

Epoch: 5| Step: 1
Training loss: 1.911078691482544
Validation loss: 2.1198788868483676

Epoch: 5| Step: 2
Training loss: 2.663843870162964
Validation loss: 2.131350101963166

Epoch: 5| Step: 3
Training loss: 2.642273426055908
Validation loss: 2.1531432238958215

Epoch: 5| Step: 4
Training loss: 2.350550889968872
Validation loss: 2.152825706748552

Epoch: 5| Step: 5
Training loss: 2.6961464881896973
Validation loss: 2.170518990485899

Epoch: 5| Step: 6
Training loss: 2.183140993118286
Validation loss: 2.1398192016027306

Epoch: 5| Step: 7
Training loss: 2.780618667602539
Validation loss: 2.0824242048366095

Epoch: 5| Step: 8
Training loss: 1.7608966827392578
Validation loss: 2.0348475748492825

Epoch: 5| Step: 9
Training loss: 2.4011106491088867
Validation loss: 2.010502169209142

Epoch: 5| Step: 10
Training loss: 1.8526041507720947
Validation loss: 1.9975074068192513

Epoch: 88| Step: 0
Training loss: 2.400028944015503
Validation loss: 1.9882862414083173

Epoch: 5| Step: 1
Training loss: 2.7696123123168945
Validation loss: 1.9961522292065363

Epoch: 5| Step: 2
Training loss: 1.7278894186019897
Validation loss: 2.0268635634453065

Epoch: 5| Step: 3
Training loss: 2.1959381103515625
Validation loss: 2.0150658212682253

Epoch: 5| Step: 4
Training loss: 2.6876492500305176
Validation loss: 2.0044731170900407

Epoch: 5| Step: 5
Training loss: 2.173928737640381
Validation loss: 1.9941272427958827

Epoch: 5| Step: 6
Training loss: 1.6967039108276367
Validation loss: 1.9923567400183728

Epoch: 5| Step: 7
Training loss: 1.8542401790618896
Validation loss: 2.009125935134067

Epoch: 5| Step: 8
Training loss: 2.7591447830200195
Validation loss: 2.0226936160877185

Epoch: 5| Step: 9
Training loss: 2.2062525749206543
Validation loss: 2.025870136035386

Epoch: 5| Step: 10
Training loss: 2.751774787902832
Validation loss: 2.03401699373799

Epoch: 89| Step: 0
Training loss: 2.282113790512085
Validation loss: 2.034258614304245

Epoch: 5| Step: 1
Training loss: 2.2675671577453613
Validation loss: 2.01256146225878

Epoch: 5| Step: 2
Training loss: 2.361398458480835
Validation loss: 2.0065970754110687

Epoch: 5| Step: 3
Training loss: 1.3983508348464966
Validation loss: 2.002946102490989

Epoch: 5| Step: 4
Training loss: 2.2376105785369873
Validation loss: 2.0107278605943084

Epoch: 5| Step: 5
Training loss: 2.550649881362915
Validation loss: 2.0122217709018337

Epoch: 5| Step: 6
Training loss: 2.5542945861816406
Validation loss: 2.0085955230138635

Epoch: 5| Step: 7
Training loss: 1.9942686557769775
Validation loss: 2.0095756105197373

Epoch: 5| Step: 8
Training loss: 1.9291870594024658
Validation loss: 2.016304854423769

Epoch: 5| Step: 9
Training loss: 2.7489256858825684
Validation loss: 2.0144485940215406

Epoch: 5| Step: 10
Training loss: 2.6773152351379395
Validation loss: 2.0144593997668196

Epoch: 90| Step: 0
Training loss: 2.0899710655212402
Validation loss: 2.00376844662492

Epoch: 5| Step: 1
Training loss: 2.3438491821289062
Validation loss: 1.999876214611915

Epoch: 5| Step: 2
Training loss: 1.8709304332733154
Validation loss: 1.9991638480976064

Epoch: 5| Step: 3
Training loss: 1.9453504085540771
Validation loss: 2.003719129870015

Epoch: 5| Step: 4
Training loss: 2.646425724029541
Validation loss: 2.0162959021906697

Epoch: 5| Step: 5
Training loss: 2.2294507026672363
Validation loss: 2.0181951471554336

Epoch: 5| Step: 6
Training loss: 1.8337392807006836
Validation loss: 1.9974568505440988

Epoch: 5| Step: 7
Training loss: 2.4926517009735107
Validation loss: 1.983333069791076

Epoch: 5| Step: 8
Training loss: 2.739208936691284
Validation loss: 1.9668152678397395

Epoch: 5| Step: 9
Training loss: 1.7753000259399414
Validation loss: 1.9630146667521486

Epoch: 5| Step: 10
Training loss: 3.049779176712036
Validation loss: 1.9614532480957687

Epoch: 91| Step: 0
Training loss: 2.6656455993652344
Validation loss: 1.9692509020528486

Epoch: 5| Step: 1
Training loss: 1.9551613330841064
Validation loss: 1.9696591720786145

Epoch: 5| Step: 2
Training loss: 1.9473228454589844
Validation loss: 1.976639199000533

Epoch: 5| Step: 3
Training loss: 2.211315393447876
Validation loss: 1.9777115006600656

Epoch: 5| Step: 4
Training loss: 1.955578088760376
Validation loss: 1.9728667069506902

Epoch: 5| Step: 5
Training loss: 2.305504322052002
Validation loss: 1.9803160429000854

Epoch: 5| Step: 6
Training loss: 2.520805597305298
Validation loss: 1.9880142827187814

Epoch: 5| Step: 7
Training loss: 2.013634443283081
Validation loss: 1.9919383346393544

Epoch: 5| Step: 8
Training loss: 2.2627105712890625
Validation loss: 2.0049756162910053

Epoch: 5| Step: 9
Training loss: 2.240696668624878
Validation loss: 2.009562564152543

Epoch: 5| Step: 10
Training loss: 2.820161819458008
Validation loss: 2.0091750775614092

Epoch: 92| Step: 0
Training loss: 2.9607608318328857
Validation loss: 2.0059353356720298

Epoch: 5| Step: 1
Training loss: 2.808624029159546
Validation loss: 2.0184928524878716

Epoch: 5| Step: 2
Training loss: 2.408682107925415
Validation loss: 2.020012222310548

Epoch: 5| Step: 3
Training loss: 1.4545001983642578
Validation loss: 2.0116384337025304

Epoch: 5| Step: 4
Training loss: 2.253349781036377
Validation loss: 2.0032193301826395

Epoch: 5| Step: 5
Training loss: 1.7442585229873657
Validation loss: 1.996310544270341

Epoch: 5| Step: 6
Training loss: 1.6796098947525024
Validation loss: 1.981957483035262

Epoch: 5| Step: 7
Training loss: 2.505373239517212
Validation loss: 1.9978466623572892

Epoch: 5| Step: 8
Training loss: 2.163764715194702
Validation loss: 2.0134722673764793

Epoch: 5| Step: 9
Training loss: 2.456132411956787
Validation loss: 2.025048348211473

Epoch: 5| Step: 10
Training loss: 2.454904556274414
Validation loss: 2.018651436733943

Epoch: 93| Step: 0
Training loss: 2.946875810623169
Validation loss: 2.0113659699757895

Epoch: 5| Step: 1
Training loss: 2.2911391258239746
Validation loss: 2.022503085033868

Epoch: 5| Step: 2
Training loss: 1.7994530200958252
Validation loss: 2.031846691203374

Epoch: 5| Step: 3
Training loss: 2.2069618701934814
Validation loss: 2.0590886133973316

Epoch: 5| Step: 4
Training loss: 2.170914888381958
Validation loss: 2.075532505589147

Epoch: 5| Step: 5
Training loss: 2.906348705291748
Validation loss: 2.0815322963140344

Epoch: 5| Step: 6
Training loss: 2.5696685314178467
Validation loss: 2.085258901760142

Epoch: 5| Step: 7
Training loss: 1.7470203638076782
Validation loss: 2.0736071063626196

Epoch: 5| Step: 8
Training loss: 2.230672597885132
Validation loss: 2.075449082159227

Epoch: 5| Step: 9
Training loss: 2.3614633083343506
Validation loss: 2.057531895176057

Epoch: 5| Step: 10
Training loss: 2.065296173095703
Validation loss: 2.0640459778488323

Epoch: 94| Step: 0
Training loss: 2.359691619873047
Validation loss: 2.0566174740432412

Epoch: 5| Step: 1
Training loss: 1.7513840198516846
Validation loss: 2.04031543577871

Epoch: 5| Step: 2
Training loss: 2.8840243816375732
Validation loss: 2.0217016358529367

Epoch: 5| Step: 3
Training loss: 2.573667526245117
Validation loss: 2.027273170409664

Epoch: 5| Step: 4
Training loss: 2.163588047027588
Validation loss: 2.0232867656215543

Epoch: 5| Step: 5
Training loss: 2.5953121185302734
Validation loss: 2.020559141712804

Epoch: 5| Step: 6
Training loss: 1.7951675653457642
Validation loss: 2.009109745743454

Epoch: 5| Step: 7
Training loss: 1.1678485870361328
Validation loss: 1.9855173505762571

Epoch: 5| Step: 8
Training loss: 2.7213034629821777
Validation loss: 1.980391562625926

Epoch: 5| Step: 9
Training loss: 2.336761236190796
Validation loss: 1.9836970311339184

Epoch: 5| Step: 10
Training loss: 2.732008457183838
Validation loss: 1.991805322708622

Epoch: 95| Step: 0
Training loss: 1.9519891738891602
Validation loss: 2.017793104212771

Epoch: 5| Step: 1
Training loss: 2.4976696968078613
Validation loss: 2.011916793802733

Epoch: 5| Step: 2
Training loss: 2.3788235187530518
Validation loss: 2.025656569388605

Epoch: 5| Step: 3
Training loss: 1.739305853843689
Validation loss: 2.02031345264886

Epoch: 5| Step: 4
Training loss: 2.329848289489746
Validation loss: 2.031255340063444

Epoch: 5| Step: 5
Training loss: 1.6825428009033203
Validation loss: 2.0272076873369116

Epoch: 5| Step: 6
Training loss: 2.9668240547180176
Validation loss: 2.010341416123093

Epoch: 5| Step: 7
Training loss: 2.77223801612854
Validation loss: 2.0054910734135616

Epoch: 5| Step: 8
Training loss: 2.434561252593994
Validation loss: 1.990090298396285

Epoch: 5| Step: 9
Training loss: 1.8746086359024048
Validation loss: 1.978374082555053

Epoch: 5| Step: 10
Training loss: 2.2138164043426514
Validation loss: 1.9725934420862505

Epoch: 96| Step: 0
Training loss: 1.9996373653411865
Validation loss: 1.9556650538598337

Epoch: 5| Step: 1
Training loss: 2.06398344039917
Validation loss: 1.9534167551225232

Epoch: 5| Step: 2
Training loss: 2.5342040061950684
Validation loss: 1.964089903780209

Epoch: 5| Step: 3
Training loss: 1.6181869506835938
Validation loss: 1.9797412195513326

Epoch: 5| Step: 4
Training loss: 2.468604564666748
Validation loss: 1.9910071139694543

Epoch: 5| Step: 5
Training loss: 1.8591006994247437
Validation loss: 2.016798726973995

Epoch: 5| Step: 6
Training loss: 2.352102279663086
Validation loss: 1.9945416271045644

Epoch: 5| Step: 7
Training loss: 2.5616044998168945
Validation loss: 1.992669951531195

Epoch: 5| Step: 8
Training loss: 2.638458728790283
Validation loss: 1.9958110906744515

Epoch: 5| Step: 9
Training loss: 2.093557119369507
Validation loss: 1.9811367706585956

Epoch: 5| Step: 10
Training loss: 2.13559889793396
Validation loss: 1.9800690092066282

Epoch: 97| Step: 0
Training loss: 2.0848464965820312
Validation loss: 1.978589032285957

Epoch: 5| Step: 1
Training loss: 2.3716330528259277
Validation loss: 1.9572331649000927

Epoch: 5| Step: 2
Training loss: 1.9143034219741821
Validation loss: 1.9568557380348124

Epoch: 5| Step: 3
Training loss: 2.4312870502471924
Validation loss: 1.956575289849312

Epoch: 5| Step: 4
Training loss: 2.6084401607513428
Validation loss: 1.9527570496323288

Epoch: 5| Step: 5
Training loss: 2.108795166015625
Validation loss: 1.9622764382311093

Epoch: 5| Step: 6
Training loss: 2.4225564002990723
Validation loss: 1.9680315102300336

Epoch: 5| Step: 7
Training loss: 2.1087355613708496
Validation loss: 1.982648088086036

Epoch: 5| Step: 8
Training loss: 2.2088050842285156
Validation loss: 1.9940742882349158

Epoch: 5| Step: 9
Training loss: 2.1499392986297607
Validation loss: 2.0087495260341193

Epoch: 5| Step: 10
Training loss: 2.4064242839813232
Validation loss: 2.009727660045829

Epoch: 98| Step: 0
Training loss: 2.1164164543151855
Validation loss: 1.9861503134491623

Epoch: 5| Step: 1
Training loss: 2.4942739009857178
Validation loss: 1.98541227463753

Epoch: 5| Step: 2
Training loss: 1.8621690273284912
Validation loss: 1.995356454644152

Epoch: 5| Step: 3
Training loss: 2.4620513916015625
Validation loss: 2.0525761368454143

Epoch: 5| Step: 4
Training loss: 2.3588645458221436
Validation loss: 2.073397651795418

Epoch: 5| Step: 5
Training loss: 2.2203402519226074
Validation loss: 2.0547800474269415

Epoch: 5| Step: 6
Training loss: 2.636444091796875
Validation loss: 2.033219442572645

Epoch: 5| Step: 7
Training loss: 2.4892759323120117
Validation loss: 2.02648227830087

Epoch: 5| Step: 8
Training loss: 1.9383337497711182
Validation loss: 2.041094354403916

Epoch: 5| Step: 9
Training loss: 2.381948232650757
Validation loss: 2.0382577014225784

Epoch: 5| Step: 10
Training loss: 2.196504592895508
Validation loss: 2.0513804779257825

Epoch: 99| Step: 0
Training loss: 2.188387632369995
Validation loss: 2.0482321900706135

Epoch: 5| Step: 1
Training loss: 3.3497917652130127
Validation loss: 2.0403887289826588

Epoch: 5| Step: 2
Training loss: 2.1267001628875732
Validation loss: 2.0019744275718607

Epoch: 5| Step: 3
Training loss: 1.8517448902130127
Validation loss: 1.9690611080456806

Epoch: 5| Step: 4
Training loss: 2.511974811553955
Validation loss: 1.961170260624219

Epoch: 5| Step: 5
Training loss: 2.320159912109375
Validation loss: 1.9712166106829079

Epoch: 5| Step: 6
Training loss: 1.3574638366699219
Validation loss: 1.969222903251648

Epoch: 5| Step: 7
Training loss: 2.0527405738830566
Validation loss: 1.9789189343811364

Epoch: 5| Step: 8
Training loss: 2.3489136695861816
Validation loss: 1.9970924931187783

Epoch: 5| Step: 9
Training loss: 2.188300371170044
Validation loss: 1.9885192481420373

Epoch: 5| Step: 10
Training loss: 2.4059033393859863
Validation loss: 1.9971144225007744

Epoch: 100| Step: 0
Training loss: 2.522299289703369
Validation loss: 2.0094522994051696

Epoch: 5| Step: 1
Training loss: 2.2425014972686768
Validation loss: 2.023970104032947

Epoch: 5| Step: 2
Training loss: 2.0340142250061035
Validation loss: 2.0398554673758884

Epoch: 5| Step: 3
Training loss: 2.0501840114593506
Validation loss: 1.9799821479346162

Epoch: 5| Step: 4
Training loss: 1.9619497060775757
Validation loss: 1.958421435407413

Epoch: 5| Step: 5
Training loss: 2.1845545768737793
Validation loss: 1.9692975885124617

Epoch: 5| Step: 6
Training loss: 2.6274611949920654
Validation loss: 1.9966707114250428

Epoch: 5| Step: 7
Training loss: 2.0181431770324707
Validation loss: 2.0158834995761996

Epoch: 5| Step: 8
Training loss: 2.001309871673584
Validation loss: 2.0307346005593576

Epoch: 5| Step: 9
Training loss: 2.5362579822540283
Validation loss: 2.035522887783666

Epoch: 5| Step: 10
Training loss: 1.9128021001815796
Validation loss: 2.028056824079124

Epoch: 101| Step: 0
Training loss: 2.660177707672119
Validation loss: 2.0298561665319625

Epoch: 5| Step: 1
Training loss: 2.043260097503662
Validation loss: 2.035526810153838

Epoch: 5| Step: 2
Training loss: 2.135531187057495
Validation loss: 2.035829036466537

Epoch: 5| Step: 3
Training loss: 1.8665422201156616
Validation loss: 2.008774475384784

Epoch: 5| Step: 4
Training loss: 1.6586647033691406
Validation loss: 2.008326088228533

Epoch: 5| Step: 5
Training loss: 1.8402763605117798
Validation loss: 1.9784119513727003

Epoch: 5| Step: 6
Training loss: 2.4333133697509766
Validation loss: 1.963305845055529

Epoch: 5| Step: 7
Training loss: 3.270460605621338
Validation loss: 1.961782939972416

Epoch: 5| Step: 8
Training loss: 1.9100353717803955
Validation loss: 1.9605271393252957

Epoch: 5| Step: 9
Training loss: 2.173074245452881
Validation loss: 1.9548855981519144

Epoch: 5| Step: 10
Training loss: 2.2308359146118164
Validation loss: 1.967789159026197

Epoch: 102| Step: 0
Training loss: 2.6766622066497803
Validation loss: 1.9726954108925276

Epoch: 5| Step: 1
Training loss: 2.471991777420044
Validation loss: 1.9721996591937156

Epoch: 5| Step: 2
Training loss: 2.5819432735443115
Validation loss: 1.9776855091894827

Epoch: 5| Step: 3
Training loss: 1.773257851600647
Validation loss: 1.9899611114173807

Epoch: 5| Step: 4
Training loss: 2.948634386062622
Validation loss: 1.9991643659530147

Epoch: 5| Step: 5
Training loss: 2.0058438777923584
Validation loss: 1.9983011573873541

Epoch: 5| Step: 6
Training loss: 2.4094150066375732
Validation loss: 1.9924594894532235

Epoch: 5| Step: 7
Training loss: 1.6267616748809814
Validation loss: 2.0015889137021956

Epoch: 5| Step: 8
Training loss: 1.6310293674468994
Validation loss: 2.007873519774406

Epoch: 5| Step: 9
Training loss: 1.9982646703720093
Validation loss: 2.0183900197347007

Epoch: 5| Step: 10
Training loss: 2.0261454582214355
Validation loss: 1.9973217415553268

Epoch: 103| Step: 0
Training loss: 1.9624755382537842
Validation loss: 2.0146459866595525

Epoch: 5| Step: 1
Training loss: 2.074517250061035
Validation loss: 1.99920739025198

Epoch: 5| Step: 2
Training loss: 1.9500977993011475
Validation loss: 2.000806821289883

Epoch: 5| Step: 3
Training loss: 2.6346511840820312
Validation loss: 1.9923647578044603

Epoch: 5| Step: 4
Training loss: 2.536569833755493
Validation loss: 1.9936967536967287

Epoch: 5| Step: 5
Training loss: 1.9549682140350342
Validation loss: 1.9928335156492007

Epoch: 5| Step: 6
Training loss: 2.128936767578125
Validation loss: 1.981968661790253

Epoch: 5| Step: 7
Training loss: 2.2486982345581055
Validation loss: 1.9981355744023477

Epoch: 5| Step: 8
Training loss: 2.2132725715637207
Validation loss: 2.0040551975209224

Epoch: 5| Step: 9
Training loss: 1.84857177734375
Validation loss: 2.020249970497624

Epoch: 5| Step: 10
Training loss: 2.7388219833374023
Validation loss: 2.0152206984899377

Epoch: 104| Step: 0
Training loss: 2.479637384414673
Validation loss: 2.0069947435009863

Epoch: 5| Step: 1
Training loss: 2.0420191287994385
Validation loss: 1.9980941152059903

Epoch: 5| Step: 2
Training loss: 1.3663169145584106
Validation loss: 1.9938456422539168

Epoch: 5| Step: 3
Training loss: 2.3334364891052246
Validation loss: 1.9683771018059022

Epoch: 5| Step: 4
Training loss: 2.678520917892456
Validation loss: 1.9598219228047196

Epoch: 5| Step: 5
Training loss: 2.7715213298797607
Validation loss: 1.9463852938785349

Epoch: 5| Step: 6
Training loss: 2.1081175804138184
Validation loss: 1.9362140112025763

Epoch: 5| Step: 7
Training loss: 2.5137784481048584
Validation loss: 1.9434313363926385

Epoch: 5| Step: 8
Training loss: 2.250392198562622
Validation loss: 1.940802066556869

Epoch: 5| Step: 9
Training loss: 1.8820346593856812
Validation loss: 1.93904629061299

Epoch: 5| Step: 10
Training loss: 1.6889450550079346
Validation loss: 1.9357382892280497

Epoch: 105| Step: 0
Training loss: 1.503080129623413
Validation loss: 1.9538172701353669

Epoch: 5| Step: 1
Training loss: 2.6704964637756348
Validation loss: 1.9664156116465086

Epoch: 5| Step: 2
Training loss: 2.0510613918304443
Validation loss: 1.9475746116330546

Epoch: 5| Step: 3
Training loss: 2.1984405517578125
Validation loss: 1.9593258660326722

Epoch: 5| Step: 4
Training loss: 1.8489201068878174
Validation loss: 1.957147644412133

Epoch: 5| Step: 5
Training loss: 2.354271411895752
Validation loss: 1.9523614965459353

Epoch: 5| Step: 6
Training loss: 2.40932559967041
Validation loss: 1.9601980563132995

Epoch: 5| Step: 7
Training loss: 2.2800745964050293
Validation loss: 1.9740951804704563

Epoch: 5| Step: 8
Training loss: 1.6451542377471924
Validation loss: 1.9824798132783623

Epoch: 5| Step: 9
Training loss: 1.979799509048462
Validation loss: 1.9871452931434876

Epoch: 5| Step: 10
Training loss: 2.826073169708252
Validation loss: 1.9821302096048992

Epoch: 106| Step: 0
Training loss: 1.748422384262085
Validation loss: 2.0006401897758566

Epoch: 5| Step: 1
Training loss: 2.627861499786377
Validation loss: 2.0325607048567904

Epoch: 5| Step: 2
Training loss: 1.7260875701904297
Validation loss: 2.0620629659263034

Epoch: 5| Step: 3
Training loss: 2.524351119995117
Validation loss: 2.0546210465892667

Epoch: 5| Step: 4
Training loss: 2.481724739074707
Validation loss: 2.0300359033769175

Epoch: 5| Step: 5
Training loss: 2.0319695472717285
Validation loss: 2.0110142359169583

Epoch: 5| Step: 6
Training loss: 2.526139736175537
Validation loss: 1.9906745508152952

Epoch: 5| Step: 7
Training loss: 2.4828364849090576
Validation loss: 1.9716524795819355

Epoch: 5| Step: 8
Training loss: 1.9661962985992432
Validation loss: 1.9631371639108146

Epoch: 5| Step: 9
Training loss: 1.939548134803772
Validation loss: 1.9489125564534178

Epoch: 5| Step: 10
Training loss: 1.8332988023757935
Validation loss: 1.9462136068651754

Epoch: 107| Step: 0
Training loss: 1.5362361669540405
Validation loss: 1.9589970291301768

Epoch: 5| Step: 1
Training loss: 2.4318249225616455
Validation loss: 1.9848173023552023

Epoch: 5| Step: 2
Training loss: 1.8158725500106812
Validation loss: 2.009936773648826

Epoch: 5| Step: 3
Training loss: 2.380858898162842
Validation loss: 2.0666378185313237

Epoch: 5| Step: 4
Training loss: 2.4154505729675293
Validation loss: 2.0996559255866596

Epoch: 5| Step: 5
Training loss: 2.4610424041748047
Validation loss: 2.103415463560371

Epoch: 5| Step: 6
Training loss: 2.017249822616577
Validation loss: 2.0948267905942854

Epoch: 5| Step: 7
Training loss: 2.352581024169922
Validation loss: 2.041858301367811

Epoch: 5| Step: 8
Training loss: 1.7258764505386353
Validation loss: 2.0155203829529467

Epoch: 5| Step: 9
Training loss: 2.8059563636779785
Validation loss: 1.99011274819733

Epoch: 5| Step: 10
Training loss: 2.4213063716888428
Validation loss: 1.9710956773450297

Epoch: 108| Step: 0
Training loss: 1.8631136417388916
Validation loss: 1.9443126442611858

Epoch: 5| Step: 1
Training loss: 1.8333762884140015
Validation loss: 1.9580883390160018

Epoch: 5| Step: 2
Training loss: 2.0376524925231934
Validation loss: 1.9642005992192093

Epoch: 5| Step: 3
Training loss: 2.0343732833862305
Validation loss: 1.9689406387267574

Epoch: 5| Step: 4
Training loss: 2.6115684509277344
Validation loss: 1.9613024214262604

Epoch: 5| Step: 5
Training loss: 2.4072728157043457
Validation loss: 1.9609624134596957

Epoch: 5| Step: 6
Training loss: 2.3448853492736816
Validation loss: 1.9996069195449993

Epoch: 5| Step: 7
Training loss: 1.8820886611938477
Validation loss: 1.9924200016965148

Epoch: 5| Step: 8
Training loss: 2.348132610321045
Validation loss: 1.9970851123973887

Epoch: 5| Step: 9
Training loss: 2.5224719047546387
Validation loss: 2.0000540107809086

Epoch: 5| Step: 10
Training loss: 1.7403253316879272
Validation loss: 1.9820902270655478

Epoch: 109| Step: 0
Training loss: 2.8461127281188965
Validation loss: 1.9814901326292305

Epoch: 5| Step: 1
Training loss: 1.5724208354949951
Validation loss: 1.9699923274337605

Epoch: 5| Step: 2
Training loss: 2.2904133796691895
Validation loss: 1.972304408268262

Epoch: 5| Step: 3
Training loss: 1.6922935247421265
Validation loss: 1.956309319824301

Epoch: 5| Step: 4
Training loss: 2.2248573303222656
Validation loss: 1.954387362285327

Epoch: 5| Step: 5
Training loss: 2.547200918197632
Validation loss: 1.9744680107280772

Epoch: 5| Step: 6
Training loss: 2.354398012161255
Validation loss: 1.9909956301412275

Epoch: 5| Step: 7
Training loss: 2.053266763687134
Validation loss: 2.000008393359441

Epoch: 5| Step: 8
Training loss: 1.8380908966064453
Validation loss: 2.027990415532102

Epoch: 5| Step: 9
Training loss: 2.0721933841705322
Validation loss: 2.0186139024713987

Epoch: 5| Step: 10
Training loss: 2.0838510990142822
Validation loss: 2.017144754368772

Epoch: 110| Step: 0
Training loss: 2.564177989959717
Validation loss: 2.032719794140067

Epoch: 5| Step: 1
Training loss: 1.604604959487915
Validation loss: 2.0153619538071337

Epoch: 5| Step: 2
Training loss: 2.1101529598236084
Validation loss: 1.990026871363322

Epoch: 5| Step: 3
Training loss: 2.3393523693084717
Validation loss: 1.9903839467674174

Epoch: 5| Step: 4
Training loss: 2.504493236541748
Validation loss: 1.9824893269487607

Epoch: 5| Step: 5
Training loss: 1.9473381042480469
Validation loss: 1.994987376274601

Epoch: 5| Step: 6
Training loss: 1.702813744544983
Validation loss: 2.019251590133995

Epoch: 5| Step: 7
Training loss: 1.8774341344833374
Validation loss: 2.0281970449673232

Epoch: 5| Step: 8
Training loss: 1.9326741695404053
Validation loss: 2.048434167779902

Epoch: 5| Step: 9
Training loss: 2.4042983055114746
Validation loss: 2.0322856364711637

Epoch: 5| Step: 10
Training loss: 2.4842469692230225
Validation loss: 2.0231084567244335

Epoch: 111| Step: 0
Training loss: 1.815934419631958
Validation loss: 2.0193290300266717

Epoch: 5| Step: 1
Training loss: 2.29560923576355
Validation loss: 2.0147797933188816

Epoch: 5| Step: 2
Training loss: 2.2004597187042236
Validation loss: 2.0024279138093353

Epoch: 5| Step: 3
Training loss: 1.881861925125122
Validation loss: 2.00248820038252

Epoch: 5| Step: 4
Training loss: 2.592416286468506
Validation loss: 1.9707072345159387

Epoch: 5| Step: 5
Training loss: 1.5814443826675415
Validation loss: 1.9789403151440363

Epoch: 5| Step: 6
Training loss: 1.0747880935668945
Validation loss: 1.971546015431804

Epoch: 5| Step: 7
Training loss: 2.895512819290161
Validation loss: 1.9785937263119606

Epoch: 5| Step: 8
Training loss: 2.431431293487549
Validation loss: 1.9845363593870593

Epoch: 5| Step: 9
Training loss: 2.2717087268829346
Validation loss: 2.010105876512425

Epoch: 5| Step: 10
Training loss: 2.346938133239746
Validation loss: 2.0605721371148222

Epoch: 112| Step: 0
Training loss: 1.4374949932098389
Validation loss: 2.0198469315805743

Epoch: 5| Step: 1
Training loss: 2.274790048599243
Validation loss: 2.00024309209598

Epoch: 5| Step: 2
Training loss: 2.2477824687957764
Validation loss: 1.967315202118248

Epoch: 5| Step: 3
Training loss: 1.8799076080322266
Validation loss: 1.9607967484381892

Epoch: 5| Step: 4
Training loss: 2.0239906311035156
Validation loss: 1.9497629134885726

Epoch: 5| Step: 5
Training loss: 2.5263071060180664
Validation loss: 1.934395650381683

Epoch: 5| Step: 6
Training loss: 2.491472005844116
Validation loss: 1.9465873651607062

Epoch: 5| Step: 7
Training loss: 1.8355070352554321
Validation loss: 1.9373874587397422

Epoch: 5| Step: 8
Training loss: 2.457620143890381
Validation loss: 1.9532983559434132

Epoch: 5| Step: 9
Training loss: 2.4168918132781982
Validation loss: 1.9544945237457112

Epoch: 5| Step: 10
Training loss: 1.9121187925338745
Validation loss: 1.9665311216026224

Epoch: 113| Step: 0
Training loss: 1.7350168228149414
Validation loss: 1.982220257482221

Epoch: 5| Step: 1
Training loss: 2.190281391143799
Validation loss: 1.9900053906184372

Epoch: 5| Step: 2
Training loss: 2.6533493995666504
Validation loss: 2.0248496417076356

Epoch: 5| Step: 3
Training loss: 1.886034369468689
Validation loss: 2.048064677946029

Epoch: 5| Step: 4
Training loss: 2.0078940391540527
Validation loss: 2.096135602202467

Epoch: 5| Step: 5
Training loss: 2.54939341545105
Validation loss: 2.0898017460300076

Epoch: 5| Step: 6
Training loss: 2.3137223720550537
Validation loss: 2.03915136988445

Epoch: 5| Step: 7
Training loss: 1.6180874109268188
Validation loss: 1.985650247143161

Epoch: 5| Step: 8
Training loss: 2.3216373920440674
Validation loss: 1.9821594697172924

Epoch: 5| Step: 9
Training loss: 1.6797008514404297
Validation loss: 1.9479012534182558

Epoch: 5| Step: 10
Training loss: 2.3062245845794678
Validation loss: 1.9341404809746692

Epoch: 114| Step: 0
Training loss: 2.5048537254333496
Validation loss: 1.9663739947862522

Epoch: 5| Step: 1
Training loss: 2.02343487739563
Validation loss: 1.9661953487703878

Epoch: 5| Step: 2
Training loss: 1.8215770721435547
Validation loss: 1.9736760149719894

Epoch: 5| Step: 3
Training loss: 2.154613494873047
Validation loss: 1.9779231625218545

Epoch: 5| Step: 4
Training loss: 2.6919758319854736
Validation loss: 1.9569384231362292

Epoch: 5| Step: 5
Training loss: 2.3672173023223877
Validation loss: 1.9454203600524573

Epoch: 5| Step: 6
Training loss: 1.76485276222229
Validation loss: 1.9593620800202893

Epoch: 5| Step: 7
Training loss: 2.039928913116455
Validation loss: 1.9713314297378703

Epoch: 5| Step: 8
Training loss: 2.2802131175994873
Validation loss: 1.98793762986378

Epoch: 5| Step: 9
Training loss: 2.2500314712524414
Validation loss: 1.9919198072084816

Epoch: 5| Step: 10
Training loss: 1.919793725013733
Validation loss: 1.9752125534960019

Epoch: 115| Step: 0
Training loss: 1.8765573501586914
Validation loss: 1.9742955225770191

Epoch: 5| Step: 1
Training loss: 1.8626110553741455
Validation loss: 1.988761196854294

Epoch: 5| Step: 2
Training loss: 2.078242301940918
Validation loss: 2.007970645863523

Epoch: 5| Step: 3
Training loss: 1.7195930480957031
Validation loss: 1.999387441142913

Epoch: 5| Step: 4
Training loss: 2.3960354328155518
Validation loss: 2.0192333523945143

Epoch: 5| Step: 5
Training loss: 2.2014453411102295
Validation loss: 2.0316775588579077

Epoch: 5| Step: 6
Training loss: 2.4633376598358154
Validation loss: 2.033112751540317

Epoch: 5| Step: 7
Training loss: 1.9774633646011353
Validation loss: 2.0378207263126167

Epoch: 5| Step: 8
Training loss: 1.936704397201538
Validation loss: 2.0532608083499375

Epoch: 5| Step: 9
Training loss: 1.8502881526947021
Validation loss: 2.0515254377036967

Epoch: 5| Step: 10
Training loss: 2.1672754287719727
Validation loss: 2.0189547141393027

Epoch: 116| Step: 0
Training loss: 2.4932258129119873
Validation loss: 2.0197257123967653

Epoch: 5| Step: 1
Training loss: 2.1427905559539795
Validation loss: 1.9713032578909269

Epoch: 5| Step: 2
Training loss: 1.481088399887085
Validation loss: 1.957236579669419

Epoch: 5| Step: 3
Training loss: 1.91269850730896
Validation loss: 1.9313392716069375

Epoch: 5| Step: 4
Training loss: 3.067514419555664
Validation loss: 1.9288347075062413

Epoch: 5| Step: 5
Training loss: 2.0460093021392822
Validation loss: 1.9299615147293254

Epoch: 5| Step: 6
Training loss: 2.0675714015960693
Validation loss: 1.9399551268546813

Epoch: 5| Step: 7
Training loss: 2.0153000354766846
Validation loss: 1.918307763273998

Epoch: 5| Step: 8
Training loss: 2.054407835006714
Validation loss: 1.930010485392745

Epoch: 5| Step: 9
Training loss: 2.0946502685546875
Validation loss: 1.9178081045868576

Epoch: 5| Step: 10
Training loss: 1.681248664855957
Validation loss: 1.9120688835779827

Epoch: 117| Step: 0
Training loss: 1.6114574670791626
Validation loss: 1.9338628425393054

Epoch: 5| Step: 1
Training loss: 2.384780168533325
Validation loss: 1.9406552891577444

Epoch: 5| Step: 2
Training loss: 1.6974313259124756
Validation loss: 1.9596774296094013

Epoch: 5| Step: 3
Training loss: 2.0881781578063965
Validation loss: 1.995518094749861

Epoch: 5| Step: 4
Training loss: 1.6776775121688843
Validation loss: 2.0376532718699467

Epoch: 5| Step: 5
Training loss: 2.2949581146240234
Validation loss: 2.039402242629759

Epoch: 5| Step: 6
Training loss: 2.2029407024383545
Validation loss: 1.999723998449182

Epoch: 5| Step: 7
Training loss: 2.023416757583618
Validation loss: 1.9816161483846686

Epoch: 5| Step: 8
Training loss: 2.9603826999664307
Validation loss: 1.9602625575116885

Epoch: 5| Step: 9
Training loss: 2.056915760040283
Validation loss: 1.95130144908864

Epoch: 5| Step: 10
Training loss: 1.660341739654541
Validation loss: 1.9525540541577082

Epoch: 118| Step: 0
Training loss: 1.7913631200790405
Validation loss: 1.9609814126004455

Epoch: 5| Step: 1
Training loss: 2.426266670227051
Validation loss: 1.9788400242405553

Epoch: 5| Step: 2
Training loss: 1.795824646949768
Validation loss: 1.9846806026274157

Epoch: 5| Step: 3
Training loss: 2.7629730701446533
Validation loss: 2.010859704786731

Epoch: 5| Step: 4
Training loss: 2.531157970428467
Validation loss: 2.012425870023748

Epoch: 5| Step: 5
Training loss: 2.2530341148376465
Validation loss: 2.0022071305141655

Epoch: 5| Step: 6
Training loss: 1.2715587615966797
Validation loss: 2.0141780773798623

Epoch: 5| Step: 7
Training loss: 0.9712012410163879
Validation loss: 2.0160108612429712

Epoch: 5| Step: 8
Training loss: 1.7008380889892578
Validation loss: 2.0098100503285727

Epoch: 5| Step: 9
Training loss: 2.2206411361694336
Validation loss: 2.013488583667304

Epoch: 5| Step: 10
Training loss: 2.825968027114868
Validation loss: 1.993407335332645

Epoch: 119| Step: 0
Training loss: 1.6595947742462158
Validation loss: 1.9841257179937055

Epoch: 5| Step: 1
Training loss: 2.0230987071990967
Validation loss: 1.9654111862182617

Epoch: 5| Step: 2
Training loss: 2.4359402656555176
Validation loss: 1.9609044392903645

Epoch: 5| Step: 3
Training loss: 2.188119411468506
Validation loss: 1.94805577365301

Epoch: 5| Step: 4
Training loss: 2.27620267868042
Validation loss: 1.9592953446090862

Epoch: 5| Step: 5
Training loss: 1.24460768699646
Validation loss: 1.9524370124263148

Epoch: 5| Step: 6
Training loss: 2.223586082458496
Validation loss: 1.935497071153374

Epoch: 5| Step: 7
Training loss: 2.0002331733703613
Validation loss: 1.9456951848922237

Epoch: 5| Step: 8
Training loss: 2.3414249420166016
Validation loss: 1.9555212310565415

Epoch: 5| Step: 9
Training loss: 1.5714495182037354
Validation loss: 1.9421759895099107

Epoch: 5| Step: 10
Training loss: 2.2780349254608154
Validation loss: 1.9574563169992099

Epoch: 120| Step: 0
Training loss: 2.387238025665283
Validation loss: 1.962600056843091

Epoch: 5| Step: 1
Training loss: 1.6906076669692993
Validation loss: 1.9894404565134356

Epoch: 5| Step: 2
Training loss: 2.2096920013427734
Validation loss: 2.001704819740788

Epoch: 5| Step: 3
Training loss: 2.6841177940368652
Validation loss: 1.994586290851716

Epoch: 5| Step: 4
Training loss: 1.8235034942626953
Validation loss: 2.0009423443066177

Epoch: 5| Step: 5
Training loss: 1.829063057899475
Validation loss: 2.0184708179966098

Epoch: 5| Step: 6
Training loss: 1.9265754222869873
Validation loss: 2.0340978419908913

Epoch: 5| Step: 7
Training loss: 2.1991028785705566
Validation loss: 2.027346985314482

Epoch: 5| Step: 8
Training loss: 2.1109020709991455
Validation loss: 2.0230143711131108

Epoch: 5| Step: 9
Training loss: 1.826242208480835
Validation loss: 2.021323552695654

Epoch: 5| Step: 10
Training loss: 1.6562029123306274
Validation loss: 2.0290281182976178

Epoch: 121| Step: 0
Training loss: 1.9496837854385376
Validation loss: 2.0279751093156877

Epoch: 5| Step: 1
Training loss: 1.8863754272460938
Validation loss: 2.039381137458227

Epoch: 5| Step: 2
Training loss: 2.602293014526367
Validation loss: 2.046434578075204

Epoch: 5| Step: 3
Training loss: 2.5900044441223145
Validation loss: 2.080845530315112

Epoch: 5| Step: 4
Training loss: 1.8063846826553345
Validation loss: 2.113998520758844

Epoch: 5| Step: 5
Training loss: 1.932464361190796
Validation loss: 2.0769787757627425

Epoch: 5| Step: 6
Training loss: 1.7853825092315674
Validation loss: 2.0170170722469205

Epoch: 5| Step: 7
Training loss: 1.954561471939087
Validation loss: 1.9729711778702275

Epoch: 5| Step: 8
Training loss: 2.0583949089050293
Validation loss: 1.9377888274449173

Epoch: 5| Step: 9
Training loss: 1.812731146812439
Validation loss: 1.9414707870893582

Epoch: 5| Step: 10
Training loss: 1.974774956703186
Validation loss: 1.9607593372303953

Epoch: 122| Step: 0
Training loss: 1.8197349309921265
Validation loss: 1.9719718143504152

Epoch: 5| Step: 1
Training loss: 1.8606750965118408
Validation loss: 1.9673255669173373

Epoch: 5| Step: 2
Training loss: 1.7251335382461548
Validation loss: 1.9871899709906629

Epoch: 5| Step: 3
Training loss: 1.8837169408798218
Validation loss: 2.0067702826633247

Epoch: 5| Step: 4
Training loss: 2.435692310333252
Validation loss: 2.03921502892689

Epoch: 5| Step: 5
Training loss: 2.6159260272979736
Validation loss: 2.0658966341326312

Epoch: 5| Step: 6
Training loss: 2.2255754470825195
Validation loss: 2.0576831935554423

Epoch: 5| Step: 7
Training loss: 1.3947257995605469
Validation loss: 2.0280102376014955

Epoch: 5| Step: 8
Training loss: 1.9430516958236694
Validation loss: 2.048916975657145

Epoch: 5| Step: 9
Training loss: 2.099722385406494
Validation loss: 2.0510434771096833

Epoch: 5| Step: 10
Training loss: 2.0667943954467773
Validation loss: 2.0481369700483096

Epoch: 123| Step: 0
Training loss: 1.9525902271270752
Validation loss: 2.047835301327449

Epoch: 5| Step: 1
Training loss: 2.1822736263275146
Validation loss: 2.0517539670390468

Epoch: 5| Step: 2
Training loss: 2.4456379413604736
Validation loss: 2.0533613774084274

Epoch: 5| Step: 3
Training loss: 1.9695297479629517
Validation loss: 2.045674336853848

Epoch: 5| Step: 4
Training loss: 0.9683939218521118
Validation loss: 2.0177702775565525

Epoch: 5| Step: 5
Training loss: 2.085742235183716
Validation loss: 2.015429325001214

Epoch: 5| Step: 6
Training loss: 2.304670810699463
Validation loss: 1.9891276205739667

Epoch: 5| Step: 7
Training loss: 2.003084659576416
Validation loss: 1.9753271623324322

Epoch: 5| Step: 8
Training loss: 2.066920518875122
Validation loss: 1.9541439394797049

Epoch: 5| Step: 9
Training loss: 1.953514814376831
Validation loss: 1.9515852159069431

Epoch: 5| Step: 10
Training loss: 2.04288911819458
Validation loss: 1.9586628496005971

Epoch: 124| Step: 0
Training loss: 2.4307143688201904
Validation loss: 1.9375663367650842

Epoch: 5| Step: 1
Training loss: 1.8162866830825806
Validation loss: 1.9389355592830206

Epoch: 5| Step: 2
Training loss: 1.7798935174942017
Validation loss: 1.9459698302771455

Epoch: 5| Step: 3
Training loss: 1.6002657413482666
Validation loss: 1.961796324740174

Epoch: 5| Step: 4
Training loss: 1.8282477855682373
Validation loss: 1.9934681564249017

Epoch: 5| Step: 5
Training loss: 2.466278553009033
Validation loss: 2.0066108575431247

Epoch: 5| Step: 6
Training loss: 1.519596815109253
Validation loss: 2.019837106427839

Epoch: 5| Step: 7
Training loss: 1.9830057621002197
Validation loss: 2.0686613616122993

Epoch: 5| Step: 8
Training loss: 1.8541247844696045
Validation loss: 2.0982920072411977

Epoch: 5| Step: 9
Training loss: 2.533083200454712
Validation loss: 2.1252159841599

Epoch: 5| Step: 10
Training loss: 2.1925466060638428
Validation loss: 2.1671038391769573

Epoch: 125| Step: 0
Training loss: 1.918116569519043
Validation loss: 2.202480746853736

Epoch: 5| Step: 1
Training loss: 2.0815749168395996
Validation loss: 2.159672224393455

Epoch: 5| Step: 2
Training loss: 1.2438499927520752
Validation loss: 2.059880737335451

Epoch: 5| Step: 3
Training loss: 3.0055465698242188
Validation loss: 2.0319664478302

Epoch: 5| Step: 4
Training loss: 1.5459482669830322
Validation loss: 2.016492538554694

Epoch: 5| Step: 5
Training loss: 1.7653684616088867
Validation loss: 2.019667499808855

Epoch: 5| Step: 6
Training loss: 2.364124298095703
Validation loss: 2.027042765771189

Epoch: 5| Step: 7
Training loss: 2.084268093109131
Validation loss: 2.0279418883785123

Epoch: 5| Step: 8
Training loss: 2.005215883255005
Validation loss: 2.0297446520097795

Epoch: 5| Step: 9
Training loss: 1.9081923961639404
Validation loss: 2.047618104565528

Epoch: 5| Step: 10
Training loss: 2.5106067657470703
Validation loss: 2.048519819013534

Epoch: 126| Step: 0
Training loss: 2.4130899906158447
Validation loss: 2.0275621926912697

Epoch: 5| Step: 1
Training loss: 1.9331858158111572
Validation loss: 2.0013012860410955

Epoch: 5| Step: 2
Training loss: 1.4155876636505127
Validation loss: 1.9637285278689476

Epoch: 5| Step: 3
Training loss: 1.8677467107772827
Validation loss: 1.9210349590547624

Epoch: 5| Step: 4
Training loss: 1.9958775043487549
Validation loss: 1.9123623806943175

Epoch: 5| Step: 5
Training loss: 2.4754436016082764
Validation loss: 1.9221715363123084

Epoch: 5| Step: 6
Training loss: 1.8057667016983032
Validation loss: 1.9258658783410185

Epoch: 5| Step: 7
Training loss: 1.904466986656189
Validation loss: 1.9468114734977804

Epoch: 5| Step: 8
Training loss: 1.4346976280212402
Validation loss: 1.9910629615988782

Epoch: 5| Step: 9
Training loss: 2.209019184112549
Validation loss: 2.023751865151108

Epoch: 5| Step: 10
Training loss: 2.3332159519195557
Validation loss: 2.054741141616657

Epoch: 127| Step: 0
Training loss: 2.5763065814971924
Validation loss: 2.0541880464041107

Epoch: 5| Step: 1
Training loss: 1.85696280002594
Validation loss: 2.0269985237429218

Epoch: 5| Step: 2
Training loss: 1.6993309259414673
Validation loss: 2.005342222029163

Epoch: 5| Step: 3
Training loss: 2.17663311958313
Validation loss: 1.980806109725788

Epoch: 5| Step: 4
Training loss: 1.654031753540039
Validation loss: 1.9701405276534378

Epoch: 5| Step: 5
Training loss: 1.8220850229263306
Validation loss: 1.9740006269947175

Epoch: 5| Step: 6
Training loss: 2.300076723098755
Validation loss: 1.984695206406296

Epoch: 5| Step: 7
Training loss: 1.9153242111206055
Validation loss: 2.0054885392547934

Epoch: 5| Step: 8
Training loss: 2.3839902877807617
Validation loss: 2.0265806516011557

Epoch: 5| Step: 9
Training loss: 1.3491313457489014
Validation loss: 2.0598290248583724

Epoch: 5| Step: 10
Training loss: 1.5728487968444824
Validation loss: 2.08569791752805

Epoch: 128| Step: 0
Training loss: 2.337329149246216
Validation loss: 2.0651035936929847

Epoch: 5| Step: 1
Training loss: 1.5547417402267456
Validation loss: 1.9943505307679534

Epoch: 5| Step: 2
Training loss: 2.305209159851074
Validation loss: 1.9513648351033528

Epoch: 5| Step: 3
Training loss: 2.461592435836792
Validation loss: 1.9482185481697

Epoch: 5| Step: 4
Training loss: 1.981115698814392
Validation loss: 1.9365052510333318

Epoch: 5| Step: 5
Training loss: 1.81508469581604
Validation loss: 1.9324843883514404

Epoch: 5| Step: 6
Training loss: 1.3718140125274658
Validation loss: 1.9468573293378275

Epoch: 5| Step: 7
Training loss: 1.4702250957489014
Validation loss: 1.9646533535372825

Epoch: 5| Step: 8
Training loss: 1.871212363243103
Validation loss: 1.9702699966328119

Epoch: 5| Step: 9
Training loss: 1.9529609680175781
Validation loss: 1.9963358679125387

Epoch: 5| Step: 10
Training loss: 2.277758836746216
Validation loss: 2.030097146188059

Epoch: 129| Step: 0
Training loss: 2.2917566299438477
Validation loss: 2.0672825254419798

Epoch: 5| Step: 1
Training loss: 2.4408180713653564
Validation loss: 2.065939449494885

Epoch: 5| Step: 2
Training loss: 2.725806474685669
Validation loss: 2.073587917512463

Epoch: 5| Step: 3
Training loss: 1.7723356485366821
Validation loss: 2.0742759268770934

Epoch: 5| Step: 4
Training loss: 1.9458156824111938
Validation loss: 2.063369260039381

Epoch: 5| Step: 5
Training loss: 2.216440200805664
Validation loss: 2.068327578165198

Epoch: 5| Step: 6
Training loss: 1.9527692794799805
Validation loss: 2.028180822249382

Epoch: 5| Step: 7
Training loss: 1.3384041786193848
Validation loss: 2.0249555546750306

Epoch: 5| Step: 8
Training loss: 2.216622829437256
Validation loss: 2.0280270473931425

Epoch: 5| Step: 9
Training loss: 1.382348895072937
Validation loss: 2.012873036887056

Epoch: 5| Step: 10
Training loss: 1.568924903869629
Validation loss: 1.9914468155112317

Epoch: 130| Step: 0
Training loss: 1.5128575563430786
Validation loss: 1.9599533311782344

Epoch: 5| Step: 1
Training loss: 1.6889864206314087
Validation loss: 1.9520466327667236

Epoch: 5| Step: 2
Training loss: 1.8177289962768555
Validation loss: 1.9481321637348463

Epoch: 5| Step: 3
Training loss: 2.285696506500244
Validation loss: 1.9705303074211202

Epoch: 5| Step: 4
Training loss: 1.9827483892440796
Validation loss: 1.9660831036106232

Epoch: 5| Step: 5
Training loss: 1.8465383052825928
Validation loss: 1.976179248543196

Epoch: 5| Step: 6
Training loss: 2.0492489337921143
Validation loss: 1.9929395990986978

Epoch: 5| Step: 7
Training loss: 2.262589931488037
Validation loss: 1.9904699107652069

Epoch: 5| Step: 8
Training loss: 2.2313108444213867
Validation loss: 1.9877683911272275

Epoch: 5| Step: 9
Training loss: 1.7122987508773804
Validation loss: 1.973041957424533

Epoch: 5| Step: 10
Training loss: 1.7709267139434814
Validation loss: 1.9894501573296004

Epoch: 131| Step: 0
Training loss: 1.5200459957122803
Validation loss: 2.0208161979593258

Epoch: 5| Step: 1
Training loss: 1.7166179418563843
Validation loss: 2.02728356084516

Epoch: 5| Step: 2
Training loss: 1.789594054222107
Validation loss: 2.010662176275766

Epoch: 5| Step: 3
Training loss: 1.928826093673706
Validation loss: 2.023025002530826

Epoch: 5| Step: 4
Training loss: 2.3531110286712646
Validation loss: 1.9935010453706146

Epoch: 5| Step: 5
Training loss: 2.019439697265625
Validation loss: 1.9817905682389454

Epoch: 5| Step: 6
Training loss: 1.3237714767456055
Validation loss: 1.970703096799953

Epoch: 5| Step: 7
Training loss: 1.9545646905899048
Validation loss: 1.968013842900594

Epoch: 5| Step: 8
Training loss: 1.9825341701507568
Validation loss: 1.9620493855527652

Epoch: 5| Step: 9
Training loss: 2.1457412242889404
Validation loss: 1.9733060098463489

Epoch: 5| Step: 10
Training loss: 2.036207914352417
Validation loss: 1.9674123999893025

Epoch: 132| Step: 0
Training loss: 1.2980620861053467
Validation loss: 1.9980111045222129

Epoch: 5| Step: 1
Training loss: 1.7415786981582642
Validation loss: 2.0401607674937092

Epoch: 5| Step: 2
Training loss: 2.281087875366211
Validation loss: 2.0578561790527834

Epoch: 5| Step: 3
Training loss: 2.503722667694092
Validation loss: 2.0420174111602125

Epoch: 5| Step: 4
Training loss: 1.9300750494003296
Validation loss: 2.0172991726988103

Epoch: 5| Step: 5
Training loss: 1.644059181213379
Validation loss: 2.036011403606784

Epoch: 5| Step: 6
Training loss: 1.7855682373046875
Validation loss: 2.0418137837481756

Epoch: 5| Step: 7
Training loss: 2.198115587234497
Validation loss: 2.075292625734883

Epoch: 5| Step: 8
Training loss: 1.589720368385315
Validation loss: 2.076394606662053

Epoch: 5| Step: 9
Training loss: 1.411346435546875
Validation loss: 2.088391552689255

Epoch: 5| Step: 10
Training loss: 3.4344019889831543
Validation loss: 2.067171864612128

Epoch: 133| Step: 0
Training loss: 2.2675349712371826
Validation loss: 2.0388287523741364

Epoch: 5| Step: 1
Training loss: 2.176316499710083
Validation loss: 2.001417447161931

Epoch: 5| Step: 2
Training loss: 2.24271559715271
Validation loss: 1.969089654184157

Epoch: 5| Step: 3
Training loss: 1.2778856754302979
Validation loss: 1.9616424037564186

Epoch: 5| Step: 4
Training loss: 2.2551827430725098
Validation loss: 1.9949106798377088

Epoch: 5| Step: 5
Training loss: 1.5704028606414795
Validation loss: 2.05089375921475

Epoch: 5| Step: 6
Training loss: 2.5662996768951416
Validation loss: 2.065755175006005

Epoch: 5| Step: 7
Training loss: 1.9761146306991577
Validation loss: 2.038085599099436

Epoch: 5| Step: 8
Training loss: 2.340033769607544
Validation loss: 1.9984656995342625

Epoch: 5| Step: 9
Training loss: 1.2873626947402954
Validation loss: 1.9289562548360517

Epoch: 5| Step: 10
Training loss: 1.372685194015503
Validation loss: 1.9010716727984849

Epoch: 134| Step: 0
Training loss: 2.088300943374634
Validation loss: 1.9231982436231387

Epoch: 5| Step: 1
Training loss: 2.0461158752441406
Validation loss: 1.938708169485933

Epoch: 5| Step: 2
Training loss: 2.408740997314453
Validation loss: 1.9565683641741354

Epoch: 5| Step: 3
Training loss: 1.590815544128418
Validation loss: 1.9596701539972776

Epoch: 5| Step: 4
Training loss: 2.174267530441284
Validation loss: 1.960583809883364

Epoch: 5| Step: 5
Training loss: 1.732171654701233
Validation loss: 1.9861118614032705

Epoch: 5| Step: 6
Training loss: 1.8847579956054688
Validation loss: 2.0006428892894457

Epoch: 5| Step: 7
Training loss: 1.4514374732971191
Validation loss: 2.0097998034569526

Epoch: 5| Step: 8
Training loss: 2.0702085494995117
Validation loss: 2.0238641231290755

Epoch: 5| Step: 9
Training loss: 1.8573992252349854
Validation loss: 2.030821406713096

Epoch: 5| Step: 10
Training loss: 1.725561261177063
Validation loss: 2.0049572260149064

Epoch: 135| Step: 0
Training loss: 1.7671735286712646
Validation loss: 2.012473528103162

Epoch: 5| Step: 1
Training loss: 2.0010008811950684
Validation loss: 2.0149647728089364

Epoch: 5| Step: 2
Training loss: 1.7544567584991455
Validation loss: 1.995032698877396

Epoch: 5| Step: 3
Training loss: 2.2645344734191895
Validation loss: 2.000831909077142

Epoch: 5| Step: 4
Training loss: 1.9681190252304077
Validation loss: 2.0260601825611566

Epoch: 5| Step: 5
Training loss: 1.6545698642730713
Validation loss: 2.076949187504348

Epoch: 5| Step: 6
Training loss: 1.7303392887115479
Validation loss: 2.089293015900479

Epoch: 5| Step: 7
Training loss: 2.0676615238189697
Validation loss: 2.063833905804542

Epoch: 5| Step: 8
Training loss: 1.9139635562896729
Validation loss: 2.01827274727565

Epoch: 5| Step: 9
Training loss: 1.6651369333267212
Validation loss: 1.9788192510604858

Epoch: 5| Step: 10
Training loss: 2.087529182434082
Validation loss: 1.9687474081593175

Epoch: 136| Step: 0
Training loss: 1.3017085790634155
Validation loss: 1.9629877767255228

Epoch: 5| Step: 1
Training loss: 1.980443000793457
Validation loss: 1.9488717125308128

Epoch: 5| Step: 2
Training loss: 1.7518390417099
Validation loss: 1.9528174015783495

Epoch: 5| Step: 3
Training loss: 1.5457497835159302
Validation loss: 1.9483673059812157

Epoch: 5| Step: 4
Training loss: 1.7939083576202393
Validation loss: 1.962484972451323

Epoch: 5| Step: 5
Training loss: 2.6226589679718018
Validation loss: 2.006766508984309

Epoch: 5| Step: 6
Training loss: 1.6245357990264893
Validation loss: 2.05159511873799

Epoch: 5| Step: 7
Training loss: 2.4933292865753174
Validation loss: 2.043190433133033

Epoch: 5| Step: 8
Training loss: 1.5741864442825317
Validation loss: 2.0348506691635295

Epoch: 5| Step: 9
Training loss: 2.033534288406372
Validation loss: 1.983351271639588

Epoch: 5| Step: 10
Training loss: 2.054748296737671
Validation loss: 1.9992293209157965

Epoch: 137| Step: 0
Training loss: 1.8502576351165771
Validation loss: 1.9931598888930453

Epoch: 5| Step: 1
Training loss: 2.492633104324341
Validation loss: 1.9947010304338189

Epoch: 5| Step: 2
Training loss: 1.196807622909546
Validation loss: 2.015489570556148

Epoch: 5| Step: 3
Training loss: 1.9049615859985352
Validation loss: 2.0146400210677937

Epoch: 5| Step: 4
Training loss: 1.7596027851104736
Validation loss: 2.0576605309722242

Epoch: 5| Step: 5
Training loss: 1.56821608543396
Validation loss: 2.0530784335187686

Epoch: 5| Step: 6
Training loss: 2.50947642326355
Validation loss: 2.056746054721135

Epoch: 5| Step: 7
Training loss: 1.8644071817398071
Validation loss: 2.060473290822839

Epoch: 5| Step: 8
Training loss: 1.5624994039535522
Validation loss: 2.0217821495507353

Epoch: 5| Step: 9
Training loss: 1.6279691457748413
Validation loss: 1.9571667358439455

Epoch: 5| Step: 10
Training loss: 2.574429750442505
Validation loss: 1.926188302296464

Epoch: 138| Step: 0
Training loss: 1.4500243663787842
Validation loss: 1.9177860290773454

Epoch: 5| Step: 1
Training loss: 1.727949857711792
Validation loss: 1.9189735766380065

Epoch: 5| Step: 2
Training loss: 1.8652931451797485
Validation loss: 1.918470528817946

Epoch: 5| Step: 3
Training loss: 1.773930549621582
Validation loss: 1.9298214245867986

Epoch: 5| Step: 4
Training loss: 1.5072473287582397
Validation loss: 1.9535038394312705

Epoch: 5| Step: 5
Training loss: 2.084883213043213
Validation loss: 2.011238997982394

Epoch: 5| Step: 6
Training loss: 2.527939558029175
Validation loss: 2.0624159971872964

Epoch: 5| Step: 7
Training loss: 1.4856541156768799
Validation loss: 2.1286841977027153

Epoch: 5| Step: 8
Training loss: 1.5813884735107422
Validation loss: 2.126786314031129

Epoch: 5| Step: 9
Training loss: 2.5438225269317627
Validation loss: 2.0913788246852096

Epoch: 5| Step: 10
Training loss: 1.9482556581497192
Validation loss: 2.0873544780156945

Epoch: 139| Step: 0
Training loss: 1.641920804977417
Validation loss: 2.0586881765755276

Epoch: 5| Step: 1
Training loss: 1.426848292350769
Validation loss: 2.046754211507818

Epoch: 5| Step: 2
Training loss: 2.6394259929656982
Validation loss: 2.027614342269077

Epoch: 5| Step: 3
Training loss: 1.8620860576629639
Validation loss: 2.019875854574224

Epoch: 5| Step: 4
Training loss: 2.471187114715576
Validation loss: 1.9915834831935104

Epoch: 5| Step: 5
Training loss: 1.8344695568084717
Validation loss: 1.9613150858109998

Epoch: 5| Step: 6
Training loss: 1.9922618865966797
Validation loss: 2.0107518344797115

Epoch: 5| Step: 7
Training loss: 1.7719690799713135
Validation loss: 2.076139680800899

Epoch: 5| Step: 8
Training loss: 1.9094030857086182
Validation loss: 2.1027355553001486

Epoch: 5| Step: 9
Training loss: 1.4282666444778442
Validation loss: 2.099343994612335

Epoch: 5| Step: 10
Training loss: 2.2101669311523438
Validation loss: 2.088454325993856

Epoch: 140| Step: 0
Training loss: 2.1956608295440674
Validation loss: 2.077566550623986

Epoch: 5| Step: 1
Training loss: 1.2033392190933228
Validation loss: 2.051069377571024

Epoch: 5| Step: 2
Training loss: 1.6924527883529663
Validation loss: 2.0195196905443744

Epoch: 5| Step: 3
Training loss: 2.374699354171753
Validation loss: 1.9886622275075605

Epoch: 5| Step: 4
Training loss: 1.6965487003326416
Validation loss: 1.9485563975508495

Epoch: 5| Step: 5
Training loss: 2.134545087814331
Validation loss: 1.9639999917758408

Epoch: 5| Step: 6
Training loss: 1.408797025680542
Validation loss: 1.9976354722053773

Epoch: 5| Step: 7
Training loss: 1.8008575439453125
Validation loss: 1.9816734008891608

Epoch: 5| Step: 8
Training loss: 1.515448808670044
Validation loss: 1.998485549803703

Epoch: 5| Step: 9
Training loss: 2.2394015789031982
Validation loss: 2.0163141066028225

Epoch: 5| Step: 10
Training loss: 2.0716490745544434
Validation loss: 2.023197741918666

Epoch: 141| Step: 0
Training loss: 2.006134033203125
Validation loss: 2.0028020656237038

Epoch: 5| Step: 1
Training loss: 1.8311210870742798
Validation loss: 1.9924800754875265

Epoch: 5| Step: 2
Training loss: 2.2209320068359375
Validation loss: 1.9586982380959295

Epoch: 5| Step: 3
Training loss: 1.1199666261672974
Validation loss: 1.9453457132462533

Epoch: 5| Step: 4
Training loss: 1.4039547443389893
Validation loss: 1.9077843645567536

Epoch: 5| Step: 5
Training loss: 2.116825819015503
Validation loss: 1.9030889695690525

Epoch: 5| Step: 6
Training loss: 1.6218925714492798
Validation loss: 1.8998971472504318

Epoch: 5| Step: 7
Training loss: 2.612086772918701
Validation loss: 1.899799882724721

Epoch: 5| Step: 8
Training loss: 1.6443647146224976
Validation loss: 1.918132676873156

Epoch: 5| Step: 9
Training loss: 1.6145734786987305
Validation loss: 1.9368589180772022

Epoch: 5| Step: 10
Training loss: 2.0072665214538574
Validation loss: 1.9450634243667766

Epoch: 142| Step: 0
Training loss: 1.4603593349456787
Validation loss: 1.9892218958946966

Epoch: 5| Step: 1
Training loss: 2.173722267150879
Validation loss: 2.018728521562392

Epoch: 5| Step: 2
Training loss: 1.7509323358535767
Validation loss: 2.0450407997254403

Epoch: 5| Step: 3
Training loss: 1.9120804071426392
Validation loss: 2.0343803949253534

Epoch: 5| Step: 4
Training loss: 1.6559890508651733
Validation loss: 1.9884649912516277

Epoch: 5| Step: 5
Training loss: 1.7618200778961182
Validation loss: 1.94902753573592

Epoch: 5| Step: 6
Training loss: 2.095877170562744
Validation loss: 1.9335664985000447

Epoch: 5| Step: 7
Training loss: 1.8125890493392944
Validation loss: 1.9026673814301849

Epoch: 5| Step: 8
Training loss: 1.8412868976593018
Validation loss: 1.9165598641159713

Epoch: 5| Step: 9
Training loss: 1.6882795095443726
Validation loss: 1.9157095006717149

Epoch: 5| Step: 10
Training loss: 1.8218175172805786
Validation loss: 1.9483248136376823

Epoch: 143| Step: 0
Training loss: 2.0305731296539307
Validation loss: 1.9950693461202806

Epoch: 5| Step: 1
Training loss: 1.8836685419082642
Validation loss: 2.062154863470344

Epoch: 5| Step: 2
Training loss: 1.4593844413757324
Validation loss: 2.118218773154802

Epoch: 5| Step: 3
Training loss: 2.1519291400909424
Validation loss: 2.106355969623853

Epoch: 5| Step: 4
Training loss: 1.5099308490753174
Validation loss: 2.044121135947525

Epoch: 5| Step: 5
Training loss: 2.173431873321533
Validation loss: 1.9986918485292824

Epoch: 5| Step: 6
Training loss: 1.4245158433914185
Validation loss: 1.943890868976552

Epoch: 5| Step: 7
Training loss: 1.7944533824920654
Validation loss: 1.9504476080658615

Epoch: 5| Step: 8
Training loss: 1.691907525062561
Validation loss: 1.9463289860756166

Epoch: 5| Step: 9
Training loss: 1.8782320022583008
Validation loss: 1.9468593135956795

Epoch: 5| Step: 10
Training loss: 2.284952163696289
Validation loss: 1.9380616936632382

Epoch: 144| Step: 0
Training loss: 1.761687994003296
Validation loss: 1.9314660244090582

Epoch: 5| Step: 1
Training loss: 1.6358016729354858
Validation loss: 1.9009470990909043

Epoch: 5| Step: 2
Training loss: 1.5578420162200928
Validation loss: 1.8814658323923747

Epoch: 5| Step: 3
Training loss: 1.9696619510650635
Validation loss: 1.9119089188114289

Epoch: 5| Step: 4
Training loss: 2.0267200469970703
Validation loss: 1.961089753335522

Epoch: 5| Step: 5
Training loss: 2.0252623558044434
Validation loss: 2.0103899560948855

Epoch: 5| Step: 6
Training loss: 2.442225456237793
Validation loss: 2.050127024291664

Epoch: 5| Step: 7
Training loss: 1.5792677402496338
Validation loss: 2.0472823035332466

Epoch: 5| Step: 8
Training loss: 1.6392625570297241
Validation loss: 2.053827976667753

Epoch: 5| Step: 9
Training loss: 2.0616555213928223
Validation loss: 2.0445670094541324

Epoch: 5| Step: 10
Training loss: 2.02001953125
Validation loss: 2.0204732418060303

Epoch: 145| Step: 0
Training loss: 1.7430336475372314
Validation loss: 1.9864145607076666

Epoch: 5| Step: 1
Training loss: 1.9171276092529297
Validation loss: 1.9440318538296608

Epoch: 5| Step: 2
Training loss: 2.4764537811279297
Validation loss: 1.9210419603573379

Epoch: 5| Step: 3
Training loss: 1.7679569721221924
Validation loss: 1.9410333966696134

Epoch: 5| Step: 4
Training loss: 1.4814894199371338
Validation loss: 1.9663615226745605

Epoch: 5| Step: 5
Training loss: 2.410374641418457
Validation loss: 1.9989294569979432

Epoch: 5| Step: 6
Training loss: 1.6984100341796875
Validation loss: 2.027678241011917

Epoch: 5| Step: 7
Training loss: 1.4691381454467773
Validation loss: 2.04217698753521

Epoch: 5| Step: 8
Training loss: 1.742267370223999
Validation loss: 2.0363212746958577

Epoch: 5| Step: 9
Training loss: 1.9121326208114624
Validation loss: 1.992129805267498

Epoch: 5| Step: 10
Training loss: 2.065537929534912
Validation loss: 1.925613590466079

Epoch: 146| Step: 0
Training loss: 1.4804465770721436
Validation loss: 1.939319126067623

Epoch: 5| Step: 1
Training loss: 1.764025092124939
Validation loss: 1.946368989124093

Epoch: 5| Step: 2
Training loss: 1.4970128536224365
Validation loss: 2.0258435036546443

Epoch: 5| Step: 3
Training loss: 1.361035943031311
Validation loss: 2.054160964104437

Epoch: 5| Step: 4
Training loss: 2.562115430831909
Validation loss: 2.1028721024913173

Epoch: 5| Step: 5
Training loss: 2.1002328395843506
Validation loss: 2.13454572744267

Epoch: 5| Step: 6
Training loss: 1.549978494644165
Validation loss: 2.0787699171291885

Epoch: 5| Step: 7
Training loss: 2.035717010498047
Validation loss: 2.027639409547211

Epoch: 5| Step: 8
Training loss: 1.8402347564697266
Validation loss: 1.9753964306205831

Epoch: 5| Step: 9
Training loss: 1.699877381324768
Validation loss: 1.9442807346261957

Epoch: 5| Step: 10
Training loss: 2.0480480194091797
Validation loss: 1.9209750826640795

Epoch: 147| Step: 0
Training loss: 1.4300525188446045
Validation loss: 1.9115687826628327

Epoch: 5| Step: 1
Training loss: 2.1939501762390137
Validation loss: 1.9043339683163552

Epoch: 5| Step: 2
Training loss: 1.7831840515136719
Validation loss: 1.8977761166070097

Epoch: 5| Step: 3
Training loss: 1.6514904499053955
Validation loss: 1.897543861019996

Epoch: 5| Step: 4
Training loss: 1.8901338577270508
Validation loss: 1.9053427237336353

Epoch: 5| Step: 5
Training loss: 1.762703537940979
Validation loss: 1.9331708300498225

Epoch: 5| Step: 6
Training loss: 1.0362406969070435
Validation loss: 1.9620779624549292

Epoch: 5| Step: 7
Training loss: 2.145486354827881
Validation loss: 1.972965181514781

Epoch: 5| Step: 8
Training loss: 2.058553695678711
Validation loss: 1.9652939406774377

Epoch: 5| Step: 9
Training loss: 1.7187858819961548
Validation loss: 2.0067563595310336

Epoch: 5| Step: 10
Training loss: 1.409519910812378
Validation loss: 2.033659747851792

Epoch: 148| Step: 0
Training loss: 1.4184439182281494
Validation loss: 2.0575800070198635

Epoch: 5| Step: 1
Training loss: 2.4715425968170166
Validation loss: 2.0835049254919893

Epoch: 5| Step: 2
Training loss: 1.5298855304718018
Validation loss: 2.046485359950732

Epoch: 5| Step: 3
Training loss: 1.0775634050369263
Validation loss: 2.016676925843762

Epoch: 5| Step: 4
Training loss: 2.0256764888763428
Validation loss: 2.0067534369807087

Epoch: 5| Step: 5
Training loss: 2.3624982833862305
Validation loss: 1.9835195592654649

Epoch: 5| Step: 6
Training loss: 1.4281786680221558
Validation loss: 1.9512658901112054

Epoch: 5| Step: 7
Training loss: 1.5511928796768188
Validation loss: 1.9410033956650765

Epoch: 5| Step: 8
Training loss: 2.293203830718994
Validation loss: 1.9308022055574643

Epoch: 5| Step: 9
Training loss: 0.9819741249084473
Validation loss: 1.9400829961222987

Epoch: 5| Step: 10
Training loss: 2.0245275497436523
Validation loss: 1.9248705461461058

Epoch: 149| Step: 0
Training loss: 1.286313772201538
Validation loss: 1.9209216487023137

Epoch: 5| Step: 1
Training loss: 1.5873539447784424
Validation loss: 1.934936672128657

Epoch: 5| Step: 2
Training loss: 1.694624662399292
Validation loss: 1.9387496466277747

Epoch: 5| Step: 3
Training loss: 1.8297021389007568
Validation loss: 1.96117768749114

Epoch: 5| Step: 4
Training loss: 1.640904426574707
Validation loss: 1.9832568117367324

Epoch: 5| Step: 5
Training loss: 2.290379285812378
Validation loss: 1.9868040033566055

Epoch: 5| Step: 6
Training loss: 1.4558296203613281
Validation loss: 2.006813967099754

Epoch: 5| Step: 7
Training loss: 2.2010929584503174
Validation loss: 2.0289550314667406

Epoch: 5| Step: 8
Training loss: 1.3764145374298096
Validation loss: 2.031323820032099

Epoch: 5| Step: 9
Training loss: 1.7045841217041016
Validation loss: 2.058223655146937

Epoch: 5| Step: 10
Training loss: 1.7249927520751953
Validation loss: 2.0522958463238132

Epoch: 150| Step: 0
Training loss: 1.611151933670044
Validation loss: 2.0773677749018513

Epoch: 5| Step: 1
Training loss: 1.529180645942688
Validation loss: 2.079385088336083

Epoch: 5| Step: 2
Training loss: 1.2830579280853271
Validation loss: 2.0863520214634557

Epoch: 5| Step: 3
Training loss: 2.0687673091888428
Validation loss: 2.0778297019261185

Epoch: 5| Step: 4
Training loss: 1.588008165359497
Validation loss: 2.0639234230082524

Epoch: 5| Step: 5
Training loss: 1.9544296264648438
Validation loss: 2.028342189327363

Epoch: 5| Step: 6
Training loss: 1.97198486328125
Validation loss: 2.0224077932296263

Epoch: 5| Step: 7
Training loss: 1.6119838953018188
Validation loss: 2.016825037617837

Epoch: 5| Step: 8
Training loss: 1.7418572902679443
Validation loss: 2.003521405240541

Epoch: 5| Step: 9
Training loss: 1.6465247869491577
Validation loss: 1.9728178260146931

Epoch: 5| Step: 10
Training loss: 1.6668658256530762
Validation loss: 1.9351881575840775

Epoch: 151| Step: 0
Training loss: 1.3467962741851807
Validation loss: 1.9601801467198197

Epoch: 5| Step: 1
Training loss: 1.3081626892089844
Validation loss: 1.9662387755609327

Epoch: 5| Step: 2
Training loss: 1.8501697778701782
Validation loss: 1.9650145294845744

Epoch: 5| Step: 3
Training loss: 1.696128487586975
Validation loss: 2.005935561272406

Epoch: 5| Step: 4
Training loss: 1.9583642482757568
Validation loss: 2.0537131422309467

Epoch: 5| Step: 5
Training loss: 1.9401624202728271
Validation loss: 2.057883204952363

Epoch: 5| Step: 6
Training loss: 1.8686654567718506
Validation loss: 2.0037185607417936

Epoch: 5| Step: 7
Training loss: 1.401338815689087
Validation loss: 1.9935673372719878

Epoch: 5| Step: 8
Training loss: 2.2093398571014404
Validation loss: 2.0063722492546163

Epoch: 5| Step: 9
Training loss: 1.9994659423828125
Validation loss: 2.0025793198616273

Epoch: 5| Step: 10
Training loss: 1.5438133478164673
Validation loss: 2.005240653150825

Epoch: 152| Step: 0
Training loss: 2.2046189308166504
Validation loss: 1.9839804633971183

Epoch: 5| Step: 1
Training loss: 1.4914089441299438
Validation loss: 2.0639535611675632

Epoch: 5| Step: 2
Training loss: 1.4780685901641846
Validation loss: 2.108200914116316

Epoch: 5| Step: 3
Training loss: 1.9247400760650635
Validation loss: 2.143094147405317

Epoch: 5| Step: 4
Training loss: 1.2868518829345703
Validation loss: 2.12021440844382

Epoch: 5| Step: 5
Training loss: 1.893301010131836
Validation loss: 2.0609475387040006

Epoch: 5| Step: 6
Training loss: 1.0416648387908936
Validation loss: 2.002419594795473

Epoch: 5| Step: 7
Training loss: 1.807202935218811
Validation loss: 1.9886719872874599

Epoch: 5| Step: 8
Training loss: 2.003444194793701
Validation loss: 1.9713023580530638

Epoch: 5| Step: 9
Training loss: 1.8274379968643188
Validation loss: 1.9878771869085168

Epoch: 5| Step: 10
Training loss: 1.8037829399108887
Validation loss: 1.963257271756408

Epoch: 153| Step: 0
Training loss: 1.4679311513900757
Validation loss: 1.9603911651078092

Epoch: 5| Step: 1
Training loss: 1.4327266216278076
Validation loss: 1.9631674405067199

Epoch: 5| Step: 2
Training loss: 1.2921327352523804
Validation loss: 1.9720617814730572

Epoch: 5| Step: 3
Training loss: 2.181994676589966
Validation loss: 2.05506028667573

Epoch: 5| Step: 4
Training loss: 1.46792733669281
Validation loss: 2.1160586905735794

Epoch: 5| Step: 5
Training loss: 1.1298608779907227
Validation loss: 2.13288265146235

Epoch: 5| Step: 6
Training loss: 2.1563010215759277
Validation loss: 2.1015171876517673

Epoch: 5| Step: 7
Training loss: 1.9222774505615234
Validation loss: 2.0598935375931444

Epoch: 5| Step: 8
Training loss: 2.1399166584014893
Validation loss: 1.9877434135765157

Epoch: 5| Step: 9
Training loss: 1.814414620399475
Validation loss: 1.9646507950239285

Epoch: 5| Step: 10
Training loss: 1.8679760694503784
Validation loss: 1.9603719454939648

Epoch: 154| Step: 0
Training loss: 1.9313303232192993
Validation loss: 1.9542097494166384

Epoch: 5| Step: 1
Training loss: 2.371063709259033
Validation loss: 1.9349548150134344

Epoch: 5| Step: 2
Training loss: 1.2518144845962524
Validation loss: 1.936539525626808

Epoch: 5| Step: 3
Training loss: 1.7575372457504272
Validation loss: 1.9542978860998665

Epoch: 5| Step: 4
Training loss: 1.194504737854004
Validation loss: 1.976747025725662

Epoch: 5| Step: 5
Training loss: 1.5412777662277222
Validation loss: 2.000432822012132

Epoch: 5| Step: 6
Training loss: 1.3869706392288208
Validation loss: 1.9952659222387499

Epoch: 5| Step: 7
Training loss: 1.5460963249206543
Validation loss: 2.0123649874041156

Epoch: 5| Step: 8
Training loss: 1.655731201171875
Validation loss: 2.053016972798173

Epoch: 5| Step: 9
Training loss: 1.4499787092208862
Validation loss: 2.0649877030362367

Epoch: 5| Step: 10
Training loss: 1.7805922031402588
Validation loss: 2.0436853619032007

Epoch: 155| Step: 0
Training loss: 1.6100162267684937
Validation loss: 2.0012871091083815

Epoch: 5| Step: 1
Training loss: 1.1418471336364746
Validation loss: 2.004898889090425

Epoch: 5| Step: 2
Training loss: 1.5127981901168823
Validation loss: 1.9929371726128362

Epoch: 5| Step: 3
Training loss: 1.4828298091888428
Validation loss: 1.9789825831690142

Epoch: 5| Step: 4
Training loss: 1.6295671463012695
Validation loss: 1.9794241510411745

Epoch: 5| Step: 5
Training loss: 1.9781267642974854
Validation loss: 1.9672513597755021

Epoch: 5| Step: 6
Training loss: 1.8501718044281006
Validation loss: 1.963624123604067

Epoch: 5| Step: 7
Training loss: 1.7252098321914673
Validation loss: 1.946776633621544

Epoch: 5| Step: 8
Training loss: 1.7926509380340576
Validation loss: 1.9466810892986994

Epoch: 5| Step: 9
Training loss: 1.3796324729919434
Validation loss: 1.9343963130827873

Epoch: 5| Step: 10
Training loss: 1.4889038801193237
Validation loss: 1.9539181160670456

Epoch: 156| Step: 0
Training loss: 1.0344853401184082
Validation loss: 2.000913316203702

Epoch: 5| Step: 1
Training loss: 1.4918572902679443
Validation loss: 2.037717147540021

Epoch: 5| Step: 2
Training loss: 1.5377304553985596
Validation loss: 2.079037320229315

Epoch: 5| Step: 3
Training loss: 2.2803752422332764
Validation loss: 2.0467978305714105

Epoch: 5| Step: 4
Training loss: 1.398579478263855
Validation loss: 2.0292982439840994

Epoch: 5| Step: 5
Training loss: 1.9992449283599854
Validation loss: 2.0162459996438797

Epoch: 5| Step: 6
Training loss: 1.3213768005371094
Validation loss: 1.9745995024199128

Epoch: 5| Step: 7
Training loss: 1.4504185914993286
Validation loss: 1.9697119651302215

Epoch: 5| Step: 8
Training loss: 1.4858390092849731
Validation loss: 1.9634021815433298

Epoch: 5| Step: 9
Training loss: 1.7361596822738647
Validation loss: 1.9666713706908687

Epoch: 5| Step: 10
Training loss: 1.6996525526046753
Validation loss: 1.9800798085428053

Epoch: 157| Step: 0
Training loss: 1.6126432418823242
Validation loss: 1.9914591953318606

Epoch: 5| Step: 1
Training loss: 1.979570746421814
Validation loss: 1.9995570234073106

Epoch: 5| Step: 2
Training loss: 1.5865163803100586
Validation loss: 2.008178077718263

Epoch: 5| Step: 3
Training loss: 1.6084330081939697
Validation loss: 2.0222592251275175

Epoch: 5| Step: 4
Training loss: 1.6916885375976562
Validation loss: 2.034899996172997

Epoch: 5| Step: 5
Training loss: 1.8315893411636353
Validation loss: 2.0113962209352882

Epoch: 5| Step: 6
Training loss: 1.083200216293335
Validation loss: 1.9885307037702171

Epoch: 5| Step: 7
Training loss: 1.0822778940200806
Validation loss: 1.966649095217387

Epoch: 5| Step: 8
Training loss: 1.4677612781524658
Validation loss: 1.9283317750500095

Epoch: 5| Step: 9
Training loss: 1.7138433456420898
Validation loss: 1.9209876278395295

Epoch: 5| Step: 10
Training loss: 1.5653575658798218
Validation loss: 1.9269108131367674

Epoch: 158| Step: 0
Training loss: 1.6788877248764038
Validation loss: 1.9392103405408962

Epoch: 5| Step: 1
Training loss: 1.4340511560440063
Validation loss: 1.976389656784714

Epoch: 5| Step: 2
Training loss: 1.605447769165039
Validation loss: 2.002827371320417

Epoch: 5| Step: 3
Training loss: 1.2114959955215454
Validation loss: 2.0249035332792547

Epoch: 5| Step: 4
Training loss: 1.5926567316055298
Validation loss: 2.038148190385552

Epoch: 5| Step: 5
Training loss: 1.6856635808944702
Validation loss: 2.073531461018388

Epoch: 5| Step: 6
Training loss: 1.8915717601776123
Validation loss: 2.02714325663864

Epoch: 5| Step: 7
Training loss: 1.5210516452789307
Validation loss: 2.004106690806727

Epoch: 5| Step: 8
Training loss: 1.4010339975357056
Validation loss: 1.9736808897346578

Epoch: 5| Step: 9
Training loss: 1.8696739673614502
Validation loss: 1.9518275619834982

Epoch: 5| Step: 10
Training loss: 1.2589828968048096
Validation loss: 1.9560622322943904

Epoch: 159| Step: 0
Training loss: 1.8104861974716187
Validation loss: 1.9439662759022047

Epoch: 5| Step: 1
Training loss: 1.7543957233428955
Validation loss: 1.9614424449141308

Epoch: 5| Step: 2
Training loss: 1.4308912754058838
Validation loss: 1.9592301717368505

Epoch: 5| Step: 3
Training loss: 1.586515188217163
Validation loss: 1.9878186179745583

Epoch: 5| Step: 4
Training loss: 2.612928867340088
Validation loss: 2.0969436578853156

Epoch: 5| Step: 5
Training loss: 1.938446283340454
Validation loss: 2.135599367080196

Epoch: 5| Step: 6
Training loss: 1.4057552814483643
Validation loss: 2.0670159427068566

Epoch: 5| Step: 7
Training loss: 1.7102420330047607
Validation loss: 2.0164917745897846

Epoch: 5| Step: 8
Training loss: 1.0931293964385986
Validation loss: 1.9968434354310394

Epoch: 5| Step: 9
Training loss: 1.2621291875839233
Validation loss: 1.9956372322574738

Epoch: 5| Step: 10
Training loss: 1.7337837219238281
Validation loss: 2.014814538340415

Epoch: 160| Step: 0
Training loss: 2.1495425701141357
Validation loss: 2.040068006002775

Epoch: 5| Step: 1
Training loss: 1.972482681274414
Validation loss: 2.016928243380721

Epoch: 5| Step: 2
Training loss: 1.388981580734253
Validation loss: 1.9927043453339608

Epoch: 5| Step: 3
Training loss: 1.1009035110473633
Validation loss: 1.9831057556213871

Epoch: 5| Step: 4
Training loss: 1.4265069961547852
Validation loss: 1.9607257727653749

Epoch: 5| Step: 5
Training loss: 1.0703917741775513
Validation loss: 1.9706339272119666

Epoch: 5| Step: 6
Training loss: 1.291689157485962
Validation loss: 1.9449438100220056

Epoch: 5| Step: 7
Training loss: 1.7649242877960205
Validation loss: 1.927619634136077

Epoch: 5| Step: 8
Training loss: 1.8338711261749268
Validation loss: 1.9093236436126053

Epoch: 5| Step: 9
Training loss: 1.7686030864715576
Validation loss: 1.9255183178891417

Epoch: 5| Step: 10
Training loss: 1.5307203531265259
Validation loss: 1.9383613422352781

Epoch: 161| Step: 0
Training loss: 1.2570573091506958
Validation loss: 1.9919294157335836

Epoch: 5| Step: 1
Training loss: 1.398416519165039
Validation loss: 2.018129551282493

Epoch: 5| Step: 2
Training loss: 1.8494272232055664
Validation loss: 2.02177288968076

Epoch: 5| Step: 3
Training loss: 1.3028583526611328
Validation loss: 2.0796382863034486

Epoch: 5| Step: 4
Training loss: 1.9711230993270874
Validation loss: 2.0787828391598118

Epoch: 5| Step: 5
Training loss: 1.4663821458816528
Validation loss: 2.017403615418301

Epoch: 5| Step: 6
Training loss: 1.118260145187378
Validation loss: 1.9617306237579675

Epoch: 5| Step: 7
Training loss: 1.6497501134872437
Validation loss: 1.948196646987751

Epoch: 5| Step: 8
Training loss: 1.7098815441131592
Validation loss: 1.9282087126085836

Epoch: 5| Step: 9
Training loss: 1.7030128240585327
Validation loss: 1.913599826956308

Epoch: 5| Step: 10
Training loss: 1.717134714126587
Validation loss: 1.925691423877593

Epoch: 162| Step: 0
Training loss: 2.056154251098633
Validation loss: 1.9173826286869664

Epoch: 5| Step: 1
Training loss: 1.367051124572754
Validation loss: 1.9662909943570372

Epoch: 5| Step: 2
Training loss: 1.4722797870635986
Validation loss: 1.9749330564211773

Epoch: 5| Step: 3
Training loss: 1.5248316526412964
Validation loss: 2.0180418773363997

Epoch: 5| Step: 4
Training loss: 1.4294111728668213
Validation loss: 1.9965481347935174

Epoch: 5| Step: 5
Training loss: 1.3043245077133179
Validation loss: 1.98105501872237

Epoch: 5| Step: 6
Training loss: 1.4209315776824951
Validation loss: 1.9768024708635064

Epoch: 5| Step: 7
Training loss: 1.2734187841415405
Validation loss: 1.98378506014424

Epoch: 5| Step: 8
Training loss: 1.7628408670425415
Validation loss: 1.9758429501646309

Epoch: 5| Step: 9
Training loss: 1.7710472345352173
Validation loss: 1.9609181265677176

Epoch: 5| Step: 10
Training loss: 1.5274295806884766
Validation loss: 1.9681056289262668

Epoch: 163| Step: 0
Training loss: 1.066314458847046
Validation loss: 1.9710839358709191

Epoch: 5| Step: 1
Training loss: 1.5208468437194824
Validation loss: 1.9673638292538222

Epoch: 5| Step: 2
Training loss: 1.5280669927597046
Validation loss: 1.9507642971572055

Epoch: 5| Step: 3
Training loss: 1.8140417337417603
Validation loss: 1.9568033526020665

Epoch: 5| Step: 4
Training loss: 1.114005446434021
Validation loss: 1.945832606284849

Epoch: 5| Step: 5
Training loss: 1.2663850784301758
Validation loss: 1.9435620282285957

Epoch: 5| Step: 6
Training loss: 1.7390161752700806
Validation loss: 1.9174061513716174

Epoch: 5| Step: 7
Training loss: 2.026404619216919
Validation loss: 1.9243983504592732

Epoch: 5| Step: 8
Training loss: 1.4547245502471924
Validation loss: 1.953289419092158

Epoch: 5| Step: 9
Training loss: 1.6626335382461548
Validation loss: 1.9768073545989169

Epoch: 5| Step: 10
Training loss: 1.2872251272201538
Validation loss: 2.0404887481402327

Epoch: 164| Step: 0
Training loss: 1.505469799041748
Validation loss: 2.042273529114262

Epoch: 5| Step: 1
Training loss: 1.7293249368667603
Validation loss: 2.027671306363998

Epoch: 5| Step: 2
Training loss: 1.4511384963989258
Validation loss: 2.0176105601813203

Epoch: 5| Step: 3
Training loss: 1.2304199934005737
Validation loss: 1.9689815832722573

Epoch: 5| Step: 4
Training loss: 1.5153182744979858
Validation loss: 1.9616389556597638

Epoch: 5| Step: 5
Training loss: 1.8333756923675537
Validation loss: 1.9325972949304888

Epoch: 5| Step: 6
Training loss: 1.4407196044921875
Validation loss: 1.9190333415103216

Epoch: 5| Step: 7
Training loss: 1.567147970199585
Validation loss: 1.890659232293406

Epoch: 5| Step: 8
Training loss: 1.4479389190673828
Validation loss: 1.9086053294520224

Epoch: 5| Step: 9
Training loss: 1.5159225463867188
Validation loss: 1.9254181308131064

Epoch: 5| Step: 10
Training loss: 1.3086977005004883
Validation loss: 1.9620119371721823

Epoch: 165| Step: 0
Training loss: 1.445642352104187
Validation loss: 1.9859533143299881

Epoch: 5| Step: 1
Training loss: 1.4844818115234375
Validation loss: 1.9738155411135765

Epoch: 5| Step: 2
Training loss: 1.6422450542449951
Validation loss: 1.9636795264418407

Epoch: 5| Step: 3
Training loss: 1.9853127002716064
Validation loss: 1.9713944414610505

Epoch: 5| Step: 4
Training loss: 0.8454340100288391
Validation loss: 1.968491103059502

Epoch: 5| Step: 5
Training loss: 1.338632583618164
Validation loss: 1.9726469568026963

Epoch: 5| Step: 6
Training loss: 1.8778845071792603
Validation loss: 1.9521223845020417

Epoch: 5| Step: 7
Training loss: 0.9902200698852539
Validation loss: 1.9429862473600654

Epoch: 5| Step: 8
Training loss: 1.6017227172851562
Validation loss: 1.9251588467628724

Epoch: 5| Step: 9
Training loss: 1.3558170795440674
Validation loss: 1.9185883697643076

Epoch: 5| Step: 10
Training loss: 1.7322386503219604
Validation loss: 1.9322831297433505

Epoch: 166| Step: 0
Training loss: 1.5499151945114136
Validation loss: 1.9450130308828046

Epoch: 5| Step: 1
Training loss: 1.622654676437378
Validation loss: 1.962381757715697

Epoch: 5| Step: 2
Training loss: 1.6805059909820557
Validation loss: 1.9469430600443194

Epoch: 5| Step: 3
Training loss: 1.0750101804733276
Validation loss: 1.9413533210754395

Epoch: 5| Step: 4
Training loss: 1.335430383682251
Validation loss: 1.9350351928382792

Epoch: 5| Step: 5
Training loss: 1.3925822973251343
Validation loss: 1.9266011048388738

Epoch: 5| Step: 6
Training loss: 1.7449226379394531
Validation loss: 1.9524635960978847

Epoch: 5| Step: 7
Training loss: 1.3093253374099731
Validation loss: 1.952230457336672

Epoch: 5| Step: 8
Training loss: 1.2065954208374023
Validation loss: 1.9785852380978164

Epoch: 5| Step: 9
Training loss: 1.229557991027832
Validation loss: 1.9940959266436997

Epoch: 5| Step: 10
Training loss: 1.987910270690918
Validation loss: 2.0121214389801025

Epoch: 167| Step: 0
Training loss: 1.2144674062728882
Validation loss: 1.9922660127762826

Epoch: 5| Step: 1
Training loss: 1.3078744411468506
Validation loss: 1.9815932653283561

Epoch: 5| Step: 2
Training loss: 1.6623613834381104
Validation loss: 1.9744511740182036

Epoch: 5| Step: 3
Training loss: 1.1558135747909546
Validation loss: 1.9760352937124108

Epoch: 5| Step: 4
Training loss: 0.9471190571784973
Validation loss: 1.9770111012202438

Epoch: 5| Step: 5
Training loss: 1.732112169265747
Validation loss: 1.9778787833388134

Epoch: 5| Step: 6
Training loss: 1.2641738653182983
Validation loss: 1.981988045477098

Epoch: 5| Step: 7
Training loss: 1.2913916110992432
Validation loss: 1.9897078301316948

Epoch: 5| Step: 8
Training loss: 2.242393970489502
Validation loss: 1.9882818498919088

Epoch: 5| Step: 9
Training loss: 1.5542168617248535
Validation loss: 1.9896004943437473

Epoch: 5| Step: 10
Training loss: 1.4088590145111084
Validation loss: 1.949119625553008

Epoch: 168| Step: 0
Training loss: 1.1988400220870972
Validation loss: 1.925370385569911

Epoch: 5| Step: 1
Training loss: 1.8139305114746094
Validation loss: 1.9110020975912771

Epoch: 5| Step: 2
Training loss: 1.743790626525879
Validation loss: 1.9254221685471073

Epoch: 5| Step: 3
Training loss: 1.610698938369751
Validation loss: 1.941694413461993

Epoch: 5| Step: 4
Training loss: 1.2278859615325928
Validation loss: 1.9770148928447435

Epoch: 5| Step: 5
Training loss: 1.4192579984664917
Validation loss: 1.9707743698550808

Epoch: 5| Step: 6
Training loss: 1.1181808710098267
Validation loss: 1.9950572393273796

Epoch: 5| Step: 7
Training loss: 1.5693691968917847
Validation loss: 1.9778907324678154

Epoch: 5| Step: 8
Training loss: 1.430491328239441
Validation loss: 1.97575633500212

Epoch: 5| Step: 9
Training loss: 1.2147170305252075
Validation loss: 1.9723816456333283

Epoch: 5| Step: 10
Training loss: 1.2595188617706299
Validation loss: 1.9544223687982047

Epoch: 169| Step: 0
Training loss: 1.6336208581924438
Validation loss: 1.9219548766331007

Epoch: 5| Step: 1
Training loss: 1.2598481178283691
Validation loss: 1.911566335667846

Epoch: 5| Step: 2
Training loss: 1.5225350856781006
Validation loss: 1.9081249672879455

Epoch: 5| Step: 3
Training loss: 1.4315757751464844
Validation loss: 1.9260028626329155

Epoch: 5| Step: 4
Training loss: 1.3169400691986084
Validation loss: 1.911818874779568

Epoch: 5| Step: 5
Training loss: 1.3706424236297607
Validation loss: 1.9286116976891794

Epoch: 5| Step: 6
Training loss: 1.125192403793335
Validation loss: 1.9526489729522376

Epoch: 5| Step: 7
Training loss: 1.9934329986572266
Validation loss: 1.960294868356438

Epoch: 5| Step: 8
Training loss: 1.2331233024597168
Validation loss: 1.9699831431911838

Epoch: 5| Step: 9
Training loss: 1.5279958248138428
Validation loss: 2.029053786749481

Epoch: 5| Step: 10
Training loss: 1.0694938898086548
Validation loss: 2.0125571399606685

Epoch: 170| Step: 0
Training loss: 1.8369659185409546
Validation loss: 2.0333000254887406

Epoch: 5| Step: 1
Training loss: 1.1044665575027466
Validation loss: 1.945762973959728

Epoch: 5| Step: 2
Training loss: 1.4393078088760376
Validation loss: 1.8804775053454983

Epoch: 5| Step: 3
Training loss: 1.6908423900604248
Validation loss: 1.8888947515077488

Epoch: 5| Step: 4
Training loss: 2.0313916206359863
Validation loss: 1.878453980850917

Epoch: 5| Step: 5
Training loss: 1.2109187841415405
Validation loss: 1.8840757159776584

Epoch: 5| Step: 6
Training loss: 1.1717978715896606
Validation loss: 1.8909232026787215

Epoch: 5| Step: 7
Training loss: 1.2876771688461304
Validation loss: 1.9006297895985265

Epoch: 5| Step: 8
Training loss: 1.1929786205291748
Validation loss: 1.924843688164988

Epoch: 5| Step: 9
Training loss: 1.4519755840301514
Validation loss: 1.9984779575819611

Epoch: 5| Step: 10
Training loss: 1.6744706630706787
Validation loss: 2.012982230032644

Epoch: 171| Step: 0
Training loss: 1.1969172954559326
Validation loss: 2.0131839539415095

Epoch: 5| Step: 1
Training loss: 1.7277119159698486
Validation loss: 1.9960933654539046

Epoch: 5| Step: 2
Training loss: 1.4493238925933838
Validation loss: 2.0026884924980903

Epoch: 5| Step: 3
Training loss: 1.6173664331436157
Validation loss: 1.9953051510677542

Epoch: 5| Step: 4
Training loss: 1.6656547784805298
Validation loss: 1.9747537630860523

Epoch: 5| Step: 5
Training loss: 1.591658353805542
Validation loss: 1.958448535652571

Epoch: 5| Step: 6
Training loss: 1.5558632612228394
Validation loss: 1.9298676188274095

Epoch: 5| Step: 7
Training loss: 1.5253031253814697
Validation loss: 1.9105359008235316

Epoch: 5| Step: 8
Training loss: 0.9688873291015625
Validation loss: 1.9180187871379237

Epoch: 5| Step: 9
Training loss: 1.7634226083755493
Validation loss: 1.9685061298390871

Epoch: 5| Step: 10
Training loss: 1.0562562942504883
Validation loss: 1.9943039827449347

Epoch: 172| Step: 0
Training loss: 1.4854987859725952
Validation loss: 1.9996441077160578

Epoch: 5| Step: 1
Training loss: 1.5681953430175781
Validation loss: 1.9472805774340065

Epoch: 5| Step: 2
Training loss: 1.1461931467056274
Validation loss: 1.9020254124877274

Epoch: 5| Step: 3
Training loss: 1.4443376064300537
Validation loss: 1.9044039569875246

Epoch: 5| Step: 4
Training loss: 1.3882293701171875
Validation loss: 1.9189102893234582

Epoch: 5| Step: 5
Training loss: 1.174845814704895
Validation loss: 1.937694618778844

Epoch: 5| Step: 6
Training loss: 1.3229780197143555
Validation loss: 1.9640500776229366

Epoch: 5| Step: 7
Training loss: 2.2269296646118164
Validation loss: 2.021297618906985

Epoch: 5| Step: 8
Training loss: 1.5490052700042725
Validation loss: 2.0061802748710877

Epoch: 5| Step: 9
Training loss: 1.1232744455337524
Validation loss: 1.9910546528395785

Epoch: 5| Step: 10
Training loss: 1.3004552125930786
Validation loss: 2.0031836289231495

Epoch: 173| Step: 0
Training loss: 1.3445656299591064
Validation loss: 1.989961922809642

Epoch: 5| Step: 1
Training loss: 1.6376397609710693
Validation loss: 1.9393277963002522

Epoch: 5| Step: 2
Training loss: 1.3339811563491821
Validation loss: 1.901038646697998

Epoch: 5| Step: 3
Training loss: 1.218075156211853
Validation loss: 1.8893663703754384

Epoch: 5| Step: 4
Training loss: 1.0456230640411377
Validation loss: 1.9056178305738716

Epoch: 5| Step: 5
Training loss: 1.4242701530456543
Validation loss: 1.9258750754017984

Epoch: 5| Step: 6
Training loss: 1.664201021194458
Validation loss: 1.9390421349515197

Epoch: 5| Step: 7
Training loss: 1.564194917678833
Validation loss: 1.9429496949718845

Epoch: 5| Step: 8
Training loss: 1.5068200826644897
Validation loss: 1.9729177644175868

Epoch: 5| Step: 9
Training loss: 1.5172367095947266
Validation loss: 1.9870018061771189

Epoch: 5| Step: 10
Training loss: 0.8216477632522583
Validation loss: 2.0102485302955873

Epoch: 174| Step: 0
Training loss: 1.428034782409668
Validation loss: 2.042352663573398

Epoch: 5| Step: 1
Training loss: 1.3026376962661743
Validation loss: 1.9944158420767835

Epoch: 5| Step: 2
Training loss: 1.171241044998169
Validation loss: 1.9342356138331915

Epoch: 5| Step: 3
Training loss: 1.2335765361785889
Validation loss: 1.9108097322525517

Epoch: 5| Step: 4
Training loss: 1.2177075147628784
Validation loss: 1.911029105545372

Epoch: 5| Step: 5
Training loss: 2.1794168949127197
Validation loss: 1.9320255633323424

Epoch: 5| Step: 6
Training loss: 1.5747846364974976
Validation loss: 1.9173861024200276

Epoch: 5| Step: 7
Training loss: 1.146738052368164
Validation loss: 1.9308189435671734

Epoch: 5| Step: 8
Training loss: 1.5781506299972534
Validation loss: 1.9144679205391997

Epoch: 5| Step: 9
Training loss: 1.0222276449203491
Validation loss: 1.9280868576418968

Epoch: 5| Step: 10
Training loss: 1.4702008962631226
Validation loss: 1.9486041812486545

Epoch: 175| Step: 0
Training loss: 1.814030647277832
Validation loss: 1.9589158770858601

Epoch: 5| Step: 1
Training loss: 1.3918275833129883
Validation loss: 1.961421009032957

Epoch: 5| Step: 2
Training loss: 1.0523364543914795
Validation loss: 1.943223044436465

Epoch: 5| Step: 3
Training loss: 1.2744933366775513
Validation loss: 1.950546609458103

Epoch: 5| Step: 4
Training loss: 1.3322250843048096
Validation loss: 1.9447640526679255

Epoch: 5| Step: 5
Training loss: 1.3265687227249146
Validation loss: 1.935848597557314

Epoch: 5| Step: 6
Training loss: 1.4828159809112549
Validation loss: 1.9476007543584353

Epoch: 5| Step: 7
Training loss: 1.1701452732086182
Validation loss: 1.9446717026413127

Epoch: 5| Step: 8
Training loss: 1.5421521663665771
Validation loss: 1.9208057567637453

Epoch: 5| Step: 9
Training loss: 0.9633927345275879
Validation loss: 1.8951047094919349

Epoch: 5| Step: 10
Training loss: 1.6957118511199951
Validation loss: 1.8979154466300883

Epoch: 176| Step: 0
Training loss: 1.384817361831665
Validation loss: 1.8609874991960422

Epoch: 5| Step: 1
Training loss: 1.2407581806182861
Validation loss: 1.888747863872077

Epoch: 5| Step: 2
Training loss: 1.505159854888916
Validation loss: 1.9378995151929959

Epoch: 5| Step: 3
Training loss: 1.332951545715332
Validation loss: 1.9517406186749857

Epoch: 5| Step: 4
Training loss: 0.8838470578193665
Validation loss: 1.9345749488440893

Epoch: 5| Step: 5
Training loss: 1.0363805294036865
Validation loss: 1.9550850083751063

Epoch: 5| Step: 6
Training loss: 1.2695605754852295
Validation loss: 1.9596555899548274

Epoch: 5| Step: 7
Training loss: 1.2848575115203857
Validation loss: 1.9751581748326619

Epoch: 5| Step: 8
Training loss: 1.2242114543914795
Validation loss: 1.9659740758198563

Epoch: 5| Step: 9
Training loss: 1.881378412246704
Validation loss: 1.98471039084978

Epoch: 5| Step: 10
Training loss: 1.6611320972442627
Validation loss: 2.0018817968265985

Epoch: 177| Step: 0
Training loss: 1.1531031131744385
Validation loss: 1.9812328520641531

Epoch: 5| Step: 1
Training loss: 1.2352263927459717
Validation loss: 1.966925887651341

Epoch: 5| Step: 2
Training loss: 1.2696213722229004
Validation loss: 1.9681681920123357

Epoch: 5| Step: 3
Training loss: 0.9788393974304199
Validation loss: 1.9512371273450955

Epoch: 5| Step: 4
Training loss: 1.6832414865493774
Validation loss: 1.9476581645268265

Epoch: 5| Step: 5
Training loss: 1.3266639709472656
Validation loss: 1.9320359883769866

Epoch: 5| Step: 6
Training loss: 1.6026058197021484
Validation loss: 1.9222135928369337

Epoch: 5| Step: 7
Training loss: 1.4467694759368896
Validation loss: 1.9042856949631886

Epoch: 5| Step: 8
Training loss: 1.6046215295791626
Validation loss: 1.8922435788698093

Epoch: 5| Step: 9
Training loss: 1.0485975742340088
Validation loss: 1.901473714459327

Epoch: 5| Step: 10
Training loss: 1.0663955211639404
Validation loss: 1.8915039570100847

Epoch: 178| Step: 0
Training loss: 1.143917441368103
Validation loss: 1.9268810287598641

Epoch: 5| Step: 1
Training loss: 0.7958852052688599
Validation loss: 1.9406895599057596

Epoch: 5| Step: 2
Training loss: 1.220458745956421
Validation loss: 1.9550397524269678

Epoch: 5| Step: 3
Training loss: 1.4387813806533813
Validation loss: 1.9804969590197328

Epoch: 5| Step: 4
Training loss: 1.8326765298843384
Validation loss: 1.9971753384477349

Epoch: 5| Step: 5
Training loss: 1.4069627523422241
Validation loss: 2.0257467236570132

Epoch: 5| Step: 6
Training loss: 1.2766294479370117
Validation loss: 1.9781647087425314

Epoch: 5| Step: 7
Training loss: 1.3857395648956299
Validation loss: 1.937250409075009

Epoch: 5| Step: 8
Training loss: 1.3863648176193237
Validation loss: 1.9129294554392497

Epoch: 5| Step: 9
Training loss: 1.3447285890579224
Validation loss: 1.8983685393487253

Epoch: 5| Step: 10
Training loss: 1.3443795442581177
Validation loss: 1.9016438273973362

Epoch: 179| Step: 0
Training loss: 1.5320063829421997
Validation loss: 1.9044184197661698

Epoch: 5| Step: 1
Training loss: 1.2312822341918945
Validation loss: 1.932219483519113

Epoch: 5| Step: 2
Training loss: 1.0159950256347656
Validation loss: 2.0042859636327273

Epoch: 5| Step: 3
Training loss: 1.1419051885604858
Validation loss: 2.011529048283895

Epoch: 5| Step: 4
Training loss: 1.2924715280532837
Validation loss: 2.036088139780106

Epoch: 5| Step: 5
Training loss: 1.6276123523712158
Validation loss: 2.0038698193847493

Epoch: 5| Step: 6
Training loss: 1.4921506643295288
Validation loss: 1.9341320312151344

Epoch: 5| Step: 7
Training loss: 1.5532608032226562
Validation loss: 1.8757684358986475

Epoch: 5| Step: 8
Training loss: 1.44695246219635
Validation loss: 1.857204411619453

Epoch: 5| Step: 9
Training loss: 1.5210920572280884
Validation loss: 1.8311284280592395

Epoch: 5| Step: 10
Training loss: 1.243481159210205
Validation loss: 1.8144205808639526

Epoch: 180| Step: 0
Training loss: 0.768910825252533
Validation loss: 1.8127060141614688

Epoch: 5| Step: 1
Training loss: 1.4199026823043823
Validation loss: 1.8338304732435493

Epoch: 5| Step: 2
Training loss: 1.3958280086517334
Validation loss: 1.8658986001886346

Epoch: 5| Step: 3
Training loss: 1.8230438232421875
Validation loss: 1.901327617706791

Epoch: 5| Step: 4
Training loss: 1.1423556804656982
Validation loss: 1.8942169591944704

Epoch: 5| Step: 5
Training loss: 1.0096533298492432
Validation loss: 1.9032628664406397

Epoch: 5| Step: 6
Training loss: 1.1857916116714478
Validation loss: 1.916960435528909

Epoch: 5| Step: 7
Training loss: 1.2531999349594116
Validation loss: 1.9232955876217093

Epoch: 5| Step: 8
Training loss: 1.405961513519287
Validation loss: 1.9162675398652271

Epoch: 5| Step: 9
Training loss: 1.383081078529358
Validation loss: 1.919037595871956

Epoch: 5| Step: 10
Training loss: 1.780849814414978
Validation loss: 1.9243263429211033

Epoch: 181| Step: 0
Training loss: 1.0028049945831299
Validation loss: 1.911139275438042

Epoch: 5| Step: 1
Training loss: 1.3752844333648682
Validation loss: 1.9363444979472826

Epoch: 5| Step: 2
Training loss: 1.2529067993164062
Validation loss: 1.9370142208632601

Epoch: 5| Step: 3
Training loss: 1.0619128942489624
Validation loss: 1.9405574324310466

Epoch: 5| Step: 4
Training loss: 0.7915328145027161
Validation loss: 1.9195243440648562

Epoch: 5| Step: 5
Training loss: 1.3156709671020508
Validation loss: 1.918447248397335

Epoch: 5| Step: 6
Training loss: 1.4938580989837646
Validation loss: 1.8874354490669825

Epoch: 5| Step: 7
Training loss: 0.9126262664794922
Validation loss: 1.8907013221453595

Epoch: 5| Step: 8
Training loss: 1.7783321142196655
Validation loss: 1.892235106037509

Epoch: 5| Step: 9
Training loss: 1.3071810007095337
Validation loss: 1.9098624106376403

Epoch: 5| Step: 10
Training loss: 1.4978575706481934
Validation loss: 1.9059403275930753

Epoch: 182| Step: 0
Training loss: 1.444045901298523
Validation loss: 1.906162118399015

Epoch: 5| Step: 1
Training loss: 1.8346278667449951
Validation loss: 1.891304862114691

Epoch: 5| Step: 2
Training loss: 0.9202500581741333
Validation loss: 1.9004551185074674

Epoch: 5| Step: 3
Training loss: 0.8221667408943176
Validation loss: 1.9105444236468243

Epoch: 5| Step: 4
Training loss: 1.1294924020767212
Validation loss: 1.907308134981381

Epoch: 5| Step: 5
Training loss: 0.9150792956352234
Validation loss: 1.9304571818279963

Epoch: 5| Step: 6
Training loss: 1.2095515727996826
Validation loss: 1.9219680255459202

Epoch: 5| Step: 7
Training loss: 1.2005763053894043
Validation loss: 1.9029804929610221

Epoch: 5| Step: 8
Training loss: 1.7862056493759155
Validation loss: 1.890751523356284

Epoch: 5| Step: 9
Training loss: 1.0917844772338867
Validation loss: 1.8964555225064677

Epoch: 5| Step: 10
Training loss: 1.3624753952026367
Validation loss: 1.9022487466053297

Epoch: 183| Step: 0
Training loss: 1.18288254737854
Validation loss: 1.9001595538149598

Epoch: 5| Step: 1
Training loss: 1.3643919229507446
Validation loss: 1.9065968618598035

Epoch: 5| Step: 2
Training loss: 0.9583263397216797
Validation loss: 1.9596499922454997

Epoch: 5| Step: 3
Training loss: 1.6769886016845703
Validation loss: 1.9950474449383315

Epoch: 5| Step: 4
Training loss: 1.220324158668518
Validation loss: 2.022242243571948

Epoch: 5| Step: 5
Training loss: 1.215169906616211
Validation loss: 2.014877393681516

Epoch: 5| Step: 6
Training loss: 1.2716538906097412
Validation loss: 1.965758805633873

Epoch: 5| Step: 7
Training loss: 1.3328962326049805
Validation loss: 1.9547613090084446

Epoch: 5| Step: 8
Training loss: 0.9419103860855103
Validation loss: 1.9208320353620796

Epoch: 5| Step: 9
Training loss: 1.3777086734771729
Validation loss: 1.9076305051003732

Epoch: 5| Step: 10
Training loss: 0.9353032112121582
Validation loss: 1.8789754862426429

Epoch: 184| Step: 0
Training loss: 1.5232270956039429
Validation loss: 1.8863559871591546

Epoch: 5| Step: 1
Training loss: 1.0387036800384521
Validation loss: 1.8831718211532922

Epoch: 5| Step: 2
Training loss: 1.4927663803100586
Validation loss: 1.8855856003299836

Epoch: 5| Step: 3
Training loss: 1.4337832927703857
Validation loss: 1.882418163361088

Epoch: 5| Step: 4
Training loss: 0.9717144966125488
Validation loss: 1.8986386342715191

Epoch: 5| Step: 5
Training loss: 0.8949748873710632
Validation loss: 1.9135638385690668

Epoch: 5| Step: 6
Training loss: 1.5681315660476685
Validation loss: 1.9137575793009933

Epoch: 5| Step: 7
Training loss: 1.048869252204895
Validation loss: 1.9202212748988983

Epoch: 5| Step: 8
Training loss: 1.180686593055725
Validation loss: 1.906477605142901

Epoch: 5| Step: 9
Training loss: 0.8452226519584656
Validation loss: 1.9073829971333986

Epoch: 5| Step: 10
Training loss: 0.9017397165298462
Validation loss: 1.935651243373912

Epoch: 185| Step: 0
Training loss: 0.9555011987686157
Validation loss: 1.9135418220232892

Epoch: 5| Step: 1
Training loss: 1.549229383468628
Validation loss: 1.8959037770507157

Epoch: 5| Step: 2
Training loss: 1.1240215301513672
Validation loss: 1.888464589272776

Epoch: 5| Step: 3
Training loss: 0.9116796255111694
Validation loss: 1.8782263648125432

Epoch: 5| Step: 4
Training loss: 1.1151801347732544
Validation loss: 1.9290771535647813

Epoch: 5| Step: 5
Training loss: 1.3132679462432861
Validation loss: 1.9587025129666893

Epoch: 5| Step: 6
Training loss: 1.0513089895248413
Validation loss: 1.9547037155397478

Epoch: 5| Step: 7
Training loss: 1.4830116033554077
Validation loss: 1.9541137833749094

Epoch: 5| Step: 8
Training loss: 1.29506516456604
Validation loss: 1.9054150555723457

Epoch: 5| Step: 9
Training loss: 1.1861059665679932
Validation loss: 1.8828101452960764

Epoch: 5| Step: 10
Training loss: 1.264261245727539
Validation loss: 1.8761886800489118

Epoch: 186| Step: 0
Training loss: 0.8643995523452759
Validation loss: 1.8688403842269734

Epoch: 5| Step: 1
Training loss: 1.3261668682098389
Validation loss: 1.8816439746528544

Epoch: 5| Step: 2
Training loss: 1.0902884006500244
Validation loss: 1.906557657385385

Epoch: 5| Step: 3
Training loss: 0.9544684290885925
Validation loss: 1.9421564571319088

Epoch: 5| Step: 4
Training loss: 1.41838800907135
Validation loss: 1.9793831212546236

Epoch: 5| Step: 5
Training loss: 1.1154955625534058
Validation loss: 2.0189682514436784

Epoch: 5| Step: 6
Training loss: 1.2544300556182861
Validation loss: 2.0071014678606423

Epoch: 5| Step: 7
Training loss: 1.1346220970153809
Validation loss: 1.96719576210104

Epoch: 5| Step: 8
Training loss: 1.0202820301055908
Validation loss: 1.9311145864507204

Epoch: 5| Step: 9
Training loss: 1.3095649480819702
Validation loss: 1.880764748460503

Epoch: 5| Step: 10
Training loss: 1.5004377365112305
Validation loss: 1.8443731928384433

Epoch: 187| Step: 0
Training loss: 1.2553203105926514
Validation loss: 1.837318463992047

Epoch: 5| Step: 1
Training loss: 1.1200306415557861
Validation loss: 1.8368448877847323

Epoch: 5| Step: 2
Training loss: 0.9818730354309082
Validation loss: 1.8573258589672785

Epoch: 5| Step: 3
Training loss: 1.1861395835876465
Validation loss: 1.8727632953274636

Epoch: 5| Step: 4
Training loss: 1.1834489107131958
Validation loss: 1.895366435409874

Epoch: 5| Step: 5
Training loss: 1.1763626337051392
Validation loss: 1.9062698489876204

Epoch: 5| Step: 6
Training loss: 1.0995184183120728
Validation loss: 1.882427095085062

Epoch: 5| Step: 7
Training loss: 1.1326717138290405
Validation loss: 1.8585515445278538

Epoch: 5| Step: 8
Training loss: 1.4032657146453857
Validation loss: 1.8598396329469578

Epoch: 5| Step: 9
Training loss: 1.033813714981079
Validation loss: 1.8436532328205724

Epoch: 5| Step: 10
Training loss: 1.1543645858764648
Validation loss: 1.861232050003544

Epoch: 188| Step: 0
Training loss: 1.226146936416626
Validation loss: 1.8776399230444303

Epoch: 5| Step: 1
Training loss: 1.043370008468628
Validation loss: 1.9047452967653993

Epoch: 5| Step: 2
Training loss: 1.4005934000015259
Validation loss: 1.939742701027983

Epoch: 5| Step: 3
Training loss: 1.2607691287994385
Validation loss: 1.93283296913229

Epoch: 5| Step: 4
Training loss: 0.8866704702377319
Validation loss: 1.9400142841441657

Epoch: 5| Step: 5
Training loss: 0.8464951515197754
Validation loss: 1.9367869207935948

Epoch: 5| Step: 6
Training loss: 1.5254005193710327
Validation loss: 1.9338639602866223

Epoch: 5| Step: 7
Training loss: 1.2484616041183472
Validation loss: 1.9298340838442567

Epoch: 5| Step: 8
Training loss: 0.7665098905563354
Validation loss: 1.923442304775279

Epoch: 5| Step: 9
Training loss: 0.9448486566543579
Validation loss: 1.9276937310413649

Epoch: 5| Step: 10
Training loss: 1.2126214504241943
Validation loss: 1.9298213925412906

Epoch: 189| Step: 0
Training loss: 1.1314319372177124
Validation loss: 1.9317787719029251

Epoch: 5| Step: 1
Training loss: 1.0179224014282227
Validation loss: 1.9186209042867024

Epoch: 5| Step: 2
Training loss: 0.9484680891036987
Validation loss: 1.9264345143430976

Epoch: 5| Step: 3
Training loss: 1.1202894449234009
Validation loss: 1.9001030024661814

Epoch: 5| Step: 4
Training loss: 1.2242259979248047
Validation loss: 1.8648227824959704

Epoch: 5| Step: 5
Training loss: 0.7774161100387573
Validation loss: 1.875198209157554

Epoch: 5| Step: 6
Training loss: 0.8982648849487305
Validation loss: 1.884476702700379

Epoch: 5| Step: 7
Training loss: 1.7294199466705322
Validation loss: 1.8985771389417752

Epoch: 5| Step: 8
Training loss: 0.9074689745903015
Validation loss: 1.9279298256802302

Epoch: 5| Step: 9
Training loss: 1.634281873703003
Validation loss: 1.9613926141492781

Epoch: 5| Step: 10
Training loss: 1.1584361791610718
Validation loss: 1.9079219577133015

Epoch: 190| Step: 0
Training loss: 1.2144081592559814
Validation loss: 1.8564190108289

Epoch: 5| Step: 1
Training loss: 1.0081130266189575
Validation loss: 1.843191069941367

Epoch: 5| Step: 2
Training loss: 0.9716229438781738
Validation loss: 1.831137325174065

Epoch: 5| Step: 3
Training loss: 1.3027317523956299
Validation loss: 1.878699993574491

Epoch: 5| Step: 4
Training loss: 0.6422435641288757
Validation loss: 1.9165096141958748

Epoch: 5| Step: 5
Training loss: 1.3504470586776733
Validation loss: 1.923074371071272

Epoch: 5| Step: 6
Training loss: 1.2256406545639038
Validation loss: 1.9655693756636752

Epoch: 5| Step: 7
Training loss: 1.1931959390640259
Validation loss: 1.9627762891912972

Epoch: 5| Step: 8
Training loss: 1.085951566696167
Validation loss: 1.9322777973708285

Epoch: 5| Step: 9
Training loss: 1.255340576171875
Validation loss: 1.9597149459264611

Epoch: 5| Step: 10
Training loss: 1.0770769119262695
Validation loss: 1.9754112792271439

Epoch: 191| Step: 0
Training loss: 1.3501750230789185
Validation loss: 1.9659755076131513

Epoch: 5| Step: 1
Training loss: 0.9814649820327759
Validation loss: 1.9434546732133435

Epoch: 5| Step: 2
Training loss: 0.9030743837356567
Validation loss: 1.9221128289417555

Epoch: 5| Step: 3
Training loss: 0.9235388040542603
Validation loss: 1.855040709177653

Epoch: 5| Step: 4
Training loss: 1.096832036972046
Validation loss: 1.8777471665413148

Epoch: 5| Step: 5
Training loss: 1.117586612701416
Validation loss: 1.8638766247739074

Epoch: 5| Step: 6
Training loss: 1.1037050485610962
Validation loss: 1.8905938312571535

Epoch: 5| Step: 7
Training loss: 1.2407538890838623
Validation loss: 1.9310457578269384

Epoch: 5| Step: 8
Training loss: 0.997339129447937
Validation loss: 1.9238690919773553

Epoch: 5| Step: 9
Training loss: 1.5675318241119385
Validation loss: 1.9625273930129183

Epoch: 5| Step: 10
Training loss: 0.7592362761497498
Validation loss: 1.9181671937306721

Epoch: 192| Step: 0
Training loss: 0.8955742716789246
Validation loss: 1.921393161178917

Epoch: 5| Step: 1
Training loss: 1.0029590129852295
Validation loss: 1.9138502613190682

Epoch: 5| Step: 2
Training loss: 1.5756151676177979
Validation loss: 1.9138644062062746

Epoch: 5| Step: 3
Training loss: 0.7932876348495483
Validation loss: 1.9368634787938928

Epoch: 5| Step: 4
Training loss: 0.6883293986320496
Validation loss: 1.9189296153283888

Epoch: 5| Step: 5
Training loss: 0.9239218831062317
Validation loss: 1.9140643765849452

Epoch: 5| Step: 6
Training loss: 1.3173413276672363
Validation loss: 1.88370285495635

Epoch: 5| Step: 7
Training loss: 1.0725293159484863
Validation loss: 1.8936774666591356

Epoch: 5| Step: 8
Training loss: 1.1461246013641357
Validation loss: 1.871348996316233

Epoch: 5| Step: 9
Training loss: 1.3959993124008179
Validation loss: 1.871787368610341

Epoch: 5| Step: 10
Training loss: 1.0364222526550293
Validation loss: 1.912054979672996

Epoch: 193| Step: 0
Training loss: 1.1188994646072388
Validation loss: 1.9241975635610602

Epoch: 5| Step: 1
Training loss: 1.6023876667022705
Validation loss: 1.904599251285676

Epoch: 5| Step: 2
Training loss: 1.1477422714233398
Validation loss: 1.882888291471748

Epoch: 5| Step: 3
Training loss: 1.2690136432647705
Validation loss: 1.8832266407628213

Epoch: 5| Step: 4
Training loss: 0.760164737701416
Validation loss: 1.8953942304016442

Epoch: 5| Step: 5
Training loss: 0.8202362060546875
Validation loss: 1.9002404956407444

Epoch: 5| Step: 6
Training loss: 0.7055434584617615
Validation loss: 1.9154544799558577

Epoch: 5| Step: 7
Training loss: 1.2640045881271362
Validation loss: 1.9678912547326857

Epoch: 5| Step: 8
Training loss: 1.030678391456604
Validation loss: 1.9735100833318566

Epoch: 5| Step: 9
Training loss: 0.9766451716423035
Validation loss: 1.9879450413488573

Epoch: 5| Step: 10
Training loss: 1.0066041946411133
Validation loss: 1.9685805228448683

Epoch: 194| Step: 0
Training loss: 1.1122640371322632
Validation loss: 1.9287873314272972

Epoch: 5| Step: 1
Training loss: 0.7287007570266724
Validation loss: 1.890248034590034

Epoch: 5| Step: 2
Training loss: 0.9665836095809937
Validation loss: 1.8572391310045797

Epoch: 5| Step: 3
Training loss: 1.2322442531585693
Validation loss: 1.8833156606202484

Epoch: 5| Step: 4
Training loss: 1.1365610361099243
Validation loss: 1.9051749924177765

Epoch: 5| Step: 5
Training loss: 1.1932920217514038
Validation loss: 1.9424038010258828

Epoch: 5| Step: 6
Training loss: 0.912026584148407
Validation loss: 1.974533769392198

Epoch: 5| Step: 7
Training loss: 0.9530292749404907
Validation loss: 1.996909418413716

Epoch: 5| Step: 8
Training loss: 1.1209301948547363
Validation loss: 2.0048528614864556

Epoch: 5| Step: 9
Training loss: 1.0145676136016846
Validation loss: 1.949291657376033

Epoch: 5| Step: 10
Training loss: 1.3980016708374023
Validation loss: 1.898240525235412

Epoch: 195| Step: 0
Training loss: 0.7475572824478149
Validation loss: 1.899976566273679

Epoch: 5| Step: 1
Training loss: 0.6916733980178833
Validation loss: 1.8566768553949171

Epoch: 5| Step: 2
Training loss: 1.0780994892120361
Validation loss: 1.8663368673734768

Epoch: 5| Step: 3
Training loss: 1.1120080947875977
Validation loss: 1.8815861850656488

Epoch: 5| Step: 4
Training loss: 0.9744205474853516
Validation loss: 1.912940607276014

Epoch: 5| Step: 5
Training loss: 0.9981969594955444
Validation loss: 1.9384487764809721

Epoch: 5| Step: 6
Training loss: 1.394089937210083
Validation loss: 1.9343129819439304

Epoch: 5| Step: 7
Training loss: 1.0066237449645996
Validation loss: 1.9223218412809475

Epoch: 5| Step: 8
Training loss: 1.0062483549118042
Validation loss: 1.9107610371805006

Epoch: 5| Step: 9
Training loss: 1.111365556716919
Validation loss: 1.8922446594443372

Epoch: 5| Step: 10
Training loss: 1.4069257974624634
Validation loss: 1.8790482346729567

Epoch: 196| Step: 0
Training loss: 1.192893624305725
Validation loss: 1.8670146901120421

Epoch: 5| Step: 1
Training loss: 0.8914616703987122
Validation loss: 1.8804870190158967

Epoch: 5| Step: 2
Training loss: 0.839614987373352
Validation loss: 1.904987730005736

Epoch: 5| Step: 3
Training loss: 0.9719749689102173
Validation loss: 1.926470047684126

Epoch: 5| Step: 4
Training loss: 0.9225238561630249
Validation loss: 1.9662111754058509

Epoch: 5| Step: 5
Training loss: 1.0741817951202393
Validation loss: 2.0083877783949657

Epoch: 5| Step: 6
Training loss: 0.7610441446304321
Validation loss: 1.9576291538053943

Epoch: 5| Step: 7
Training loss: 0.9092540740966797
Validation loss: 1.9064691951197963

Epoch: 5| Step: 8
Training loss: 1.068984031677246
Validation loss: 1.8605455301141227

Epoch: 5| Step: 9
Training loss: 1.0994316339492798
Validation loss: 1.8609172374971452

Epoch: 5| Step: 10
Training loss: 1.8724781274795532
Validation loss: 1.8409603462424329

Epoch: 197| Step: 0
Training loss: 1.5024443864822388
Validation loss: 1.9059483235882175

Epoch: 5| Step: 1
Training loss: 1.097826600074768
Validation loss: 1.9435564087283226

Epoch: 5| Step: 2
Training loss: 1.0148200988769531
Validation loss: 1.9837428818466842

Epoch: 5| Step: 3
Training loss: 1.1546956300735474
Validation loss: 1.9878137111663818

Epoch: 5| Step: 4
Training loss: 1.2640506029129028
Validation loss: 1.9945690067865516

Epoch: 5| Step: 5
Training loss: 0.9907757043838501
Validation loss: 1.9398590339127408

Epoch: 5| Step: 6
Training loss: 1.2558910846710205
Validation loss: 1.9392731651183097

Epoch: 5| Step: 7
Training loss: 0.836756706237793
Validation loss: 1.9274357749569802

Epoch: 5| Step: 8
Training loss: 0.9120314717292786
Validation loss: 1.9435230583272955

Epoch: 5| Step: 9
Training loss: 1.0432695150375366
Validation loss: 1.9402129047660417

Epoch: 5| Step: 10
Training loss: 1.0740916728973389
Validation loss: 1.9535611175721692

Epoch: 198| Step: 0
Training loss: 0.7310227155685425
Validation loss: 1.9428764440680062

Epoch: 5| Step: 1
Training loss: 1.067076563835144
Validation loss: 1.9700682368329776

Epoch: 5| Step: 2
Training loss: 1.0259416103363037
Validation loss: 1.986375044750911

Epoch: 5| Step: 3
Training loss: 1.4071862697601318
Validation loss: 1.9332439707171531

Epoch: 5| Step: 4
Training loss: 0.7755109667778015
Validation loss: 1.8904807477869012

Epoch: 5| Step: 5
Training loss: 0.8239085078239441
Validation loss: 1.8542735679175264

Epoch: 5| Step: 6
Training loss: 0.9298235177993774
Validation loss: 1.8677788703672347

Epoch: 5| Step: 7
Training loss: 1.2150858640670776
Validation loss: 1.843579730679912

Epoch: 5| Step: 8
Training loss: 1.1303058862686157
Validation loss: 1.8799166653745918

Epoch: 5| Step: 9
Training loss: 1.3123610019683838
Validation loss: 1.913722433069701

Epoch: 5| Step: 10
Training loss: 1.2945739030838013
Validation loss: 1.8909769314591602

Epoch: 199| Step: 0
Training loss: 0.9591125249862671
Validation loss: 1.896279663167974

Epoch: 5| Step: 1
Training loss: 1.1110633611679077
Validation loss: 1.9109973663924842

Epoch: 5| Step: 2
Training loss: 1.0664100646972656
Validation loss: 1.9175382865372526

Epoch: 5| Step: 3
Training loss: 1.1351135969161987
Validation loss: 1.946546700692946

Epoch: 5| Step: 4
Training loss: 1.316887617111206
Validation loss: 1.9018535678104689

Epoch: 5| Step: 5
Training loss: 1.0343502759933472
Validation loss: 1.9028257887850526

Epoch: 5| Step: 6
Training loss: 1.3405309915542603
Validation loss: 1.8958709586051203

Epoch: 5| Step: 7
Training loss: 0.829062819480896
Validation loss: 1.9724413246236823

Epoch: 5| Step: 8
Training loss: 0.8718117475509644
Validation loss: 1.9744300637193906

Epoch: 5| Step: 9
Training loss: 1.2188191413879395
Validation loss: 1.963867582300658

Epoch: 5| Step: 10
Training loss: 0.8033983707427979
Validation loss: 1.945598002403013

Epoch: 200| Step: 0
Training loss: 1.314863920211792
Validation loss: 1.9892389646140478

Epoch: 5| Step: 1
Training loss: 1.357134461402893
Validation loss: 1.9918127982847151

Epoch: 5| Step: 2
Training loss: 1.6389272212982178
Validation loss: 1.9769119780550721

Epoch: 5| Step: 3
Training loss: 1.2513535022735596
Validation loss: 1.9495031513193601

Epoch: 5| Step: 4
Training loss: 0.7893660664558411
Validation loss: 1.9396098377884075

Epoch: 5| Step: 5
Training loss: 0.8909364938735962
Validation loss: 1.994699126930647

Epoch: 5| Step: 6
Training loss: 1.6163713932037354
Validation loss: 1.971355281850343

Epoch: 5| Step: 7
Training loss: 1.1853690147399902
Validation loss: 1.967885132758848

Epoch: 5| Step: 8
Training loss: 0.540290355682373
Validation loss: 1.9124792186162805

Epoch: 5| Step: 9
Training loss: 0.9925098419189453
Validation loss: 1.8702720890762985

Epoch: 5| Step: 10
Training loss: 1.5801191329956055
Validation loss: 1.7932415393091017

Epoch: 201| Step: 0
Training loss: 1.5029151439666748
Validation loss: 1.8326474863995788

Epoch: 5| Step: 1
Training loss: 1.0868864059448242
Validation loss: 1.8794539590035715

Epoch: 5| Step: 2
Training loss: 1.1783826351165771
Validation loss: 1.935239335542084

Epoch: 5| Step: 3
Training loss: 1.35757315158844
Validation loss: 1.995724247347924

Epoch: 5| Step: 4
Training loss: 0.8070489764213562
Validation loss: 2.0770952111931256

Epoch: 5| Step: 5
Training loss: 1.3295979499816895
Validation loss: 2.1240554060987247

Epoch: 5| Step: 6
Training loss: 0.9349559545516968
Validation loss: 2.1095118638007873

Epoch: 5| Step: 7
Training loss: 0.7570003271102905
Validation loss: 2.0476432743892876

Epoch: 5| Step: 8
Training loss: 0.7755105495452881
Validation loss: 1.9456803439765848

Epoch: 5| Step: 9
Training loss: 1.13132643699646
Validation loss: 1.8686882680462253

Epoch: 5| Step: 10
Training loss: 1.3767138719558716
Validation loss: 1.826196147549537

Epoch: 202| Step: 0
Training loss: 1.3171675205230713
Validation loss: 1.8133792992561095

Epoch: 5| Step: 1
Training loss: 1.0567677021026611
Validation loss: 1.8060554586431032

Epoch: 5| Step: 2
Training loss: 1.5058276653289795
Validation loss: 1.795156063572053

Epoch: 5| Step: 3
Training loss: 0.7937383651733398
Validation loss: 1.7992094024535148

Epoch: 5| Step: 4
Training loss: 0.9887256622314453
Validation loss: 1.8360923977308377

Epoch: 5| Step: 5
Training loss: 0.881079375743866
Validation loss: 1.8537325230977868

Epoch: 5| Step: 6
Training loss: 1.2220957279205322
Validation loss: 1.8978478921357023

Epoch: 5| Step: 7
Training loss: 1.4695066213607788
Validation loss: 2.005717582600091

Epoch: 5| Step: 8
Training loss: 0.6565592885017395
Validation loss: 2.065060184847924

Epoch: 5| Step: 9
Training loss: 1.5991287231445312
Validation loss: 2.0314184593897995

Epoch: 5| Step: 10
Training loss: 0.5165511965751648
Validation loss: 1.9737241498885616

Epoch: 203| Step: 0
Training loss: 1.0491185188293457
Validation loss: 1.9375638936155586

Epoch: 5| Step: 1
Training loss: 0.9315013885498047
Validation loss: 1.8849966218394618

Epoch: 5| Step: 2
Training loss: 1.1923823356628418
Validation loss: 1.8393974406744844

Epoch: 5| Step: 3
Training loss: 1.0581938028335571
Validation loss: 1.8497115796612156

Epoch: 5| Step: 4
Training loss: 1.3754169940948486
Validation loss: 1.8512720882251699

Epoch: 5| Step: 5
Training loss: 0.937442421913147
Validation loss: 1.8531444290632844

Epoch: 5| Step: 6
Training loss: 0.9587575793266296
Validation loss: 1.8301446284017255

Epoch: 5| Step: 7
Training loss: 1.0501558780670166
Validation loss: 1.8408438774847216

Epoch: 5| Step: 8
Training loss: 0.8368480801582336
Validation loss: 1.8522707800711355

Epoch: 5| Step: 9
Training loss: 1.0758306980133057
Validation loss: 1.8583877573731125

Epoch: 5| Step: 10
Training loss: 0.8977634310722351
Validation loss: 1.8850685191410843

Epoch: 204| Step: 0
Training loss: 1.0096099376678467
Validation loss: 1.884590002798265

Epoch: 5| Step: 1
Training loss: 0.7603613138198853
Validation loss: 1.916863900358959

Epoch: 5| Step: 2
Training loss: 1.0443775653839111
Validation loss: 1.9042001924207133

Epoch: 5| Step: 3
Training loss: 1.136282205581665
Validation loss: 1.9037067736348798

Epoch: 5| Step: 4
Training loss: 0.924219012260437
Validation loss: 1.8597097499396211

Epoch: 5| Step: 5
Training loss: 1.0245076417922974
Validation loss: 1.8522754394879906

Epoch: 5| Step: 6
Training loss: 0.9856075048446655
Validation loss: 1.8376053392246205

Epoch: 5| Step: 7
Training loss: 0.9902588725090027
Validation loss: 1.8719485062424854

Epoch: 5| Step: 8
Training loss: 0.5911561846733093
Validation loss: 1.912841667411148

Epoch: 5| Step: 9
Training loss: 1.0357234477996826
Validation loss: 1.9461332726222214

Epoch: 5| Step: 10
Training loss: 1.2747632265090942
Validation loss: 2.017182219413019

Epoch: 205| Step: 0
Training loss: 1.2284619808197021
Validation loss: 1.9950855355108938

Epoch: 5| Step: 1
Training loss: 1.1975635290145874
Validation loss: 1.9488841692606609

Epoch: 5| Step: 2
Training loss: 1.427480936050415
Validation loss: 1.9116645859133812

Epoch: 5| Step: 3
Training loss: 0.5543895959854126
Validation loss: 1.8989824671899118

Epoch: 5| Step: 4
Training loss: 1.3419628143310547
Validation loss: 1.8690363950626825

Epoch: 5| Step: 5
Training loss: 1.1439627408981323
Validation loss: 1.8746785784280429

Epoch: 5| Step: 6
Training loss: 0.6929324865341187
Validation loss: 1.863374174282115

Epoch: 5| Step: 7
Training loss: 0.36989420652389526
Validation loss: 1.8608780048226798

Epoch: 5| Step: 8
Training loss: 0.6945414543151855
Validation loss: 1.8961104462223668

Epoch: 5| Step: 9
Training loss: 1.076456904411316
Validation loss: 1.8729646154629287

Epoch: 5| Step: 10
Training loss: 0.7881871461868286
Validation loss: 1.860204094199724

Epoch: 206| Step: 0
Training loss: 1.056980848312378
Validation loss: 1.8355845982028591

Epoch: 5| Step: 1
Training loss: 1.246896743774414
Validation loss: 1.8411166591029013

Epoch: 5| Step: 2
Training loss: 1.0689523220062256
Validation loss: 1.8113610500930457

Epoch: 5| Step: 3
Training loss: 0.9467102885246277
Validation loss: 1.8526781143680695

Epoch: 5| Step: 4
Training loss: 0.4024619460105896
Validation loss: 1.8785043711303382

Epoch: 5| Step: 5
Training loss: 1.4724448919296265
Validation loss: 1.9487004767182052

Epoch: 5| Step: 6
Training loss: 0.6470305919647217
Validation loss: 1.947986243873514

Epoch: 5| Step: 7
Training loss: 1.0086872577667236
Validation loss: 1.9450031352299515

Epoch: 5| Step: 8
Training loss: 0.9380811452865601
Validation loss: 1.8938092877787929

Epoch: 5| Step: 9
Training loss: 0.989632785320282
Validation loss: 1.8488946691636117

Epoch: 5| Step: 10
Training loss: 0.9084372520446777
Validation loss: 1.800988853618663

Epoch: 207| Step: 0
Training loss: 0.8867157697677612
Validation loss: 1.814086737171296

Epoch: 5| Step: 1
Training loss: 0.7704702615737915
Validation loss: 1.8150573238249748

Epoch: 5| Step: 2
Training loss: 1.389225721359253
Validation loss: 1.8211071465605049

Epoch: 5| Step: 3
Training loss: 0.9468496441841125
Validation loss: 1.8268726589859172

Epoch: 5| Step: 4
Training loss: 0.699196457862854
Validation loss: 1.8304569990404191

Epoch: 5| Step: 5
Training loss: 0.7990787625312805
Validation loss: 1.903781146131536

Epoch: 5| Step: 6
Training loss: 0.7852743864059448
Validation loss: 1.9461384588672268

Epoch: 5| Step: 7
Training loss: 1.5367786884307861
Validation loss: 1.961620548720001

Epoch: 5| Step: 8
Training loss: 0.8257938623428345
Validation loss: 1.9117834260386806

Epoch: 5| Step: 9
Training loss: 1.0345938205718994
Validation loss: 1.881874030636203

Epoch: 5| Step: 10
Training loss: 0.8676530718803406
Validation loss: 1.8598809652431036

Epoch: 208| Step: 0
Training loss: 1.0972741842269897
Validation loss: 1.8307504910294727

Epoch: 5| Step: 1
Training loss: 1.3590940237045288
Validation loss: 1.8158851669680687

Epoch: 5| Step: 2
Training loss: 0.7490730285644531
Validation loss: 1.8130503034078946

Epoch: 5| Step: 3
Training loss: 0.805886447429657
Validation loss: 1.8593290467416086

Epoch: 5| Step: 4
Training loss: 0.5877830386161804
Validation loss: 1.9274175513175227

Epoch: 5| Step: 5
Training loss: 0.6546958088874817
Validation loss: 1.9739088960873183

Epoch: 5| Step: 6
Training loss: 1.1163263320922852
Validation loss: 1.9756365065933557

Epoch: 5| Step: 7
Training loss: 1.244381308555603
Validation loss: 1.9529403742923532

Epoch: 5| Step: 8
Training loss: 0.7911337018013
Validation loss: 1.9078775734029791

Epoch: 5| Step: 9
Training loss: 0.9119739532470703
Validation loss: 1.8579782491089196

Epoch: 5| Step: 10
Training loss: 1.167747974395752
Validation loss: 1.8485318191589848

Epoch: 209| Step: 0
Training loss: 1.25996994972229
Validation loss: 1.8185045578146493

Epoch: 5| Step: 1
Training loss: 0.5281031131744385
Validation loss: 1.809182579799365

Epoch: 5| Step: 2
Training loss: 0.8727973699569702
Validation loss: 1.857480574679631

Epoch: 5| Step: 3
Training loss: 1.0322306156158447
Validation loss: 1.9141609886641144

Epoch: 5| Step: 4
Training loss: 0.6906682848930359
Validation loss: 1.9420728273289178

Epoch: 5| Step: 5
Training loss: 0.8699203729629517
Validation loss: 1.9315321932556808

Epoch: 5| Step: 6
Training loss: 1.3815500736236572
Validation loss: 1.9070210751666818

Epoch: 5| Step: 7
Training loss: 0.8867171406745911
Validation loss: 1.8598575220313123

Epoch: 5| Step: 8
Training loss: 0.6040734052658081
Validation loss: 1.8648716659956082

Epoch: 5| Step: 9
Training loss: 1.1176875829696655
Validation loss: 1.904196721251293

Epoch: 5| Step: 10
Training loss: 0.8991398811340332
Validation loss: 1.881136219988587

Epoch: 210| Step: 0
Training loss: 1.2252236604690552
Validation loss: 1.8692308215684788

Epoch: 5| Step: 1
Training loss: 1.1372220516204834
Validation loss: 1.8652425555772678

Epoch: 5| Step: 2
Training loss: 0.6791201829910278
Validation loss: 1.848754523902811

Epoch: 5| Step: 3
Training loss: 0.8321306109428406
Validation loss: 1.8539231067062707

Epoch: 5| Step: 4
Training loss: 0.7338913083076477
Validation loss: 1.874354818815826

Epoch: 5| Step: 5
Training loss: 1.0676389932632446
Validation loss: 1.875485583018231

Epoch: 5| Step: 6
Training loss: 0.7477728128433228
Validation loss: 1.891944985235891

Epoch: 5| Step: 7
Training loss: 1.3002501726150513
Validation loss: 1.9070238221076228

Epoch: 5| Step: 8
Training loss: 0.7281454205513
Validation loss: 1.8846761718873055

Epoch: 5| Step: 9
Training loss: 0.9257148504257202
Validation loss: 1.870955858179318

Epoch: 5| Step: 10
Training loss: 0.7295712232589722
Validation loss: 1.835389729469053

Epoch: 211| Step: 0
Training loss: 0.9088699221611023
Validation loss: 1.8190115587685698

Epoch: 5| Step: 1
Training loss: 0.8516656756401062
Validation loss: 1.8418621632360643

Epoch: 5| Step: 2
Training loss: 1.0361301898956299
Validation loss: 1.8755888041629587

Epoch: 5| Step: 3
Training loss: 0.6156757473945618
Validation loss: 1.9095160807332685

Epoch: 5| Step: 4
Training loss: 1.2422881126403809
Validation loss: 1.9297600946118754

Epoch: 5| Step: 5
Training loss: 0.9027677774429321
Validation loss: 1.9398824630245086

Epoch: 5| Step: 6
Training loss: 0.8243627548217773
Validation loss: 1.9419669271797262

Epoch: 5| Step: 7
Training loss: 1.246135950088501
Validation loss: 1.8896938216301702

Epoch: 5| Step: 8
Training loss: 0.5026979446411133
Validation loss: 1.8509141168286722

Epoch: 5| Step: 9
Training loss: 0.73527991771698
Validation loss: 1.8306084217563752

Epoch: 5| Step: 10
Training loss: 1.0750198364257812
Validation loss: 1.8422788471303961

Epoch: 212| Step: 0
Training loss: 0.7465259432792664
Validation loss: 1.8344872126015284

Epoch: 5| Step: 1
Training loss: 1.0040180683135986
Validation loss: 1.8012776092816425

Epoch: 5| Step: 2
Training loss: 1.051605463027954
Validation loss: 1.7921367768318421

Epoch: 5| Step: 3
Training loss: 0.8599888682365417
Validation loss: 1.814179789635443

Epoch: 5| Step: 4
Training loss: 0.8824160695075989
Validation loss: 1.7995158549278014

Epoch: 5| Step: 5
Training loss: 0.8082173466682434
Validation loss: 1.8366294958258187

Epoch: 5| Step: 6
Training loss: 0.7858413457870483
Validation loss: 1.867842101281689

Epoch: 5| Step: 7
Training loss: 0.7554591298103333
Validation loss: 1.9192339348536667

Epoch: 5| Step: 8
Training loss: 1.272533655166626
Validation loss: 1.9271913677133539

Epoch: 5| Step: 9
Training loss: 1.024817705154419
Validation loss: 1.946800237060875

Epoch: 5| Step: 10
Training loss: 0.6832818388938904
Validation loss: 1.9121027697799027

Epoch: 213| Step: 0
Training loss: 1.3119380474090576
Validation loss: 1.8861153151399346

Epoch: 5| Step: 1
Training loss: 0.7200454473495483
Validation loss: 1.838554484869844

Epoch: 5| Step: 2
Training loss: 1.011522650718689
Validation loss: 1.8338323716194398

Epoch: 5| Step: 3
Training loss: 0.778087854385376
Validation loss: 1.8472854347639187

Epoch: 5| Step: 4
Training loss: 0.8457969427108765
Validation loss: 1.8361545506344046

Epoch: 5| Step: 5
Training loss: 0.8464354276657104
Validation loss: 1.840662205731997

Epoch: 5| Step: 6
Training loss: 0.9496967196464539
Validation loss: 1.8637965007494854

Epoch: 5| Step: 7
Training loss: 0.7341603636741638
Validation loss: 1.8880219228806034

Epoch: 5| Step: 8
Training loss: 0.8578422665596008
Validation loss: 1.9007201733127717

Epoch: 5| Step: 9
Training loss: 0.6895610094070435
Validation loss: 1.8784290116320375

Epoch: 5| Step: 10
Training loss: 0.7746012806892395
Validation loss: 1.8731802291767572

Epoch: 214| Step: 0
Training loss: 0.6468618512153625
Validation loss: 1.85987715823676

Epoch: 5| Step: 1
Training loss: 0.7671387791633606
Validation loss: 1.8756970846524803

Epoch: 5| Step: 2
Training loss: 0.5770585536956787
Validation loss: 1.8756576917504753

Epoch: 5| Step: 3
Training loss: 0.8002592325210571
Validation loss: 1.8796072903499808

Epoch: 5| Step: 4
Training loss: 1.008373498916626
Validation loss: 1.84119499498798

Epoch: 5| Step: 5
Training loss: 0.9500583410263062
Validation loss: 1.848679563050629

Epoch: 5| Step: 6
Training loss: 0.8296205401420593
Validation loss: 1.8320141069350704

Epoch: 5| Step: 7
Training loss: 1.046915054321289
Validation loss: 1.8365666533029208

Epoch: 5| Step: 8
Training loss: 0.9668566584587097
Validation loss: 1.8299085786265712

Epoch: 5| Step: 9
Training loss: 0.9341567158699036
Validation loss: 1.8588466477650467

Epoch: 5| Step: 10
Training loss: 0.7125356197357178
Validation loss: 1.9064073062712146

Epoch: 215| Step: 0
Training loss: 1.2357091903686523
Validation loss: 1.9393169008275515

Epoch: 5| Step: 1
Training loss: 0.7573528289794922
Validation loss: 1.8873267507040372

Epoch: 5| Step: 2
Training loss: 1.1041511297225952
Validation loss: 1.8451307153189054

Epoch: 5| Step: 3
Training loss: 1.1941815614700317
Validation loss: 1.800352458030947

Epoch: 5| Step: 4
Training loss: 0.9698154330253601
Validation loss: 1.8270172598541423

Epoch: 5| Step: 5
Training loss: 0.7978008985519409
Validation loss: 1.826735624703028

Epoch: 5| Step: 6
Training loss: 0.7121798992156982
Validation loss: 1.8247892459233601

Epoch: 5| Step: 7
Training loss: 0.8506037592887878
Validation loss: 1.8716333296991163

Epoch: 5| Step: 8
Training loss: 0.4713825583457947
Validation loss: 1.8864704614044518

Epoch: 5| Step: 9
Training loss: 0.8151508569717407
Validation loss: 1.9071804772141159

Epoch: 5| Step: 10
Training loss: 0.6604235768318176
Validation loss: 1.9763374533704532

Epoch: 216| Step: 0
Training loss: 0.9700315594673157
Validation loss: 1.9994993991749261

Epoch: 5| Step: 1
Training loss: 0.9503099322319031
Validation loss: 1.926264379614143

Epoch: 5| Step: 2
Training loss: 0.594095766544342
Validation loss: 1.8476852191391813

Epoch: 5| Step: 3
Training loss: 1.096380352973938
Validation loss: 1.8159979133195774

Epoch: 5| Step: 4
Training loss: 0.7309743762016296
Validation loss: 1.8014328531039658

Epoch: 5| Step: 5
Training loss: 0.9187150001525879
Validation loss: 1.7962746056177283

Epoch: 5| Step: 6
Training loss: 1.1130216121673584
Validation loss: 1.818961311412114

Epoch: 5| Step: 7
Training loss: 0.8015527725219727
Validation loss: 1.851800057195848

Epoch: 5| Step: 8
Training loss: 0.7229780554771423
Validation loss: 1.883446849802489

Epoch: 5| Step: 9
Training loss: 0.7391303777694702
Validation loss: 1.8900691411828483

Epoch: 5| Step: 10
Training loss: 0.807405948638916
Validation loss: 1.9001649861694665

Epoch: 217| Step: 0
Training loss: 0.915337085723877
Validation loss: 1.8219050950901483

Epoch: 5| Step: 1
Training loss: 1.116324782371521
Validation loss: 1.7789306486806562

Epoch: 5| Step: 2
Training loss: 0.5861666798591614
Validation loss: 1.7869163200419436

Epoch: 5| Step: 3
Training loss: 1.1242316961288452
Validation loss: 1.781314362761795

Epoch: 5| Step: 4
Training loss: 0.5187861919403076
Validation loss: 1.7760896118738319

Epoch: 5| Step: 5
Training loss: 0.840589165687561
Validation loss: 1.7810132913692023

Epoch: 5| Step: 6
Training loss: 0.7241246700286865
Validation loss: 1.7798302955524896

Epoch: 5| Step: 7
Training loss: 0.5856227278709412
Validation loss: 1.8250961060165076

Epoch: 5| Step: 8
Training loss: 0.8448551297187805
Validation loss: 1.8683444864006453

Epoch: 5| Step: 9
Training loss: 0.9896587133407593
Validation loss: 1.8783400058746338

Epoch: 5| Step: 10
Training loss: 0.8960544466972351
Validation loss: 1.8644796186877834

Epoch: 218| Step: 0
Training loss: 0.9424806833267212
Validation loss: 1.8754446801318918

Epoch: 5| Step: 1
Training loss: 0.8185455203056335
Validation loss: 1.8254817954955562

Epoch: 5| Step: 2
Training loss: 0.5647238492965698
Validation loss: 1.8339603780418314

Epoch: 5| Step: 3
Training loss: 0.8662749528884888
Validation loss: 1.8139932206881944

Epoch: 5| Step: 4
Training loss: 1.0934793949127197
Validation loss: 1.8486532152339976

Epoch: 5| Step: 5
Training loss: 0.7178986072540283
Validation loss: 1.8535655031922043

Epoch: 5| Step: 6
Training loss: 0.9024810791015625
Validation loss: 1.8577351570129395

Epoch: 5| Step: 7
Training loss: 0.6339833736419678
Validation loss: 1.8357001094407932

Epoch: 5| Step: 8
Training loss: 1.0222465991973877
Validation loss: 1.821199155622913

Epoch: 5| Step: 9
Training loss: 0.7338865995407104
Validation loss: 1.808283749447074

Epoch: 5| Step: 10
Training loss: 0.8660924434661865
Validation loss: 1.798522456999748

Epoch: 219| Step: 0
Training loss: 0.664588987827301
Validation loss: 1.7897654194985666

Epoch: 5| Step: 1
Training loss: 1.0855282545089722
Validation loss: 1.8324032996290474

Epoch: 5| Step: 2
Training loss: 0.8542631268501282
Validation loss: 1.8629082069602063

Epoch: 5| Step: 3
Training loss: 0.41182413697242737
Validation loss: 1.8827671504789782

Epoch: 5| Step: 4
Training loss: 0.9071555137634277
Validation loss: 1.844901301527536

Epoch: 5| Step: 5
Training loss: 0.9782150387763977
Validation loss: 1.8475805226192679

Epoch: 5| Step: 6
Training loss: 0.45805901288986206
Validation loss: 1.8407210919164843

Epoch: 5| Step: 7
Training loss: 0.8957948684692383
Validation loss: 1.843067402480751

Epoch: 5| Step: 8
Training loss: 0.6818419694900513
Validation loss: 1.8361495438442434

Epoch: 5| Step: 9
Training loss: 0.7546196579933167
Validation loss: 1.835495764209378

Epoch: 5| Step: 10
Training loss: 1.110735297203064
Validation loss: 1.8346715498996038

Epoch: 220| Step: 0
Training loss: 0.7377872467041016
Validation loss: 1.8217871291663057

Epoch: 5| Step: 1
Training loss: 0.971823513507843
Validation loss: 1.8241869377833542

Epoch: 5| Step: 2
Training loss: 0.6182965040206909
Validation loss: 1.8459860227441276

Epoch: 5| Step: 3
Training loss: 0.9664090871810913
Validation loss: 1.8629101707089333

Epoch: 5| Step: 4
Training loss: 0.839802086353302
Validation loss: 1.8677231265652565

Epoch: 5| Step: 5
Training loss: 0.7437010407447815
Validation loss: 1.9101928921156033

Epoch: 5| Step: 6
Training loss: 0.8398178219795227
Validation loss: 1.8921678040617256

Epoch: 5| Step: 7
Training loss: 0.5666640400886536
Validation loss: 1.868878690145349

Epoch: 5| Step: 8
Training loss: 0.6110485792160034
Validation loss: 1.8753942020477787

Epoch: 5| Step: 9
Training loss: 0.7881199717521667
Validation loss: 1.8549028365842757

Epoch: 5| Step: 10
Training loss: 1.0549516677856445
Validation loss: 1.7801695639087307

Epoch: 221| Step: 0
Training loss: 1.1364647150039673
Validation loss: 1.766611538907533

Epoch: 5| Step: 1
Training loss: 0.6111588478088379
Validation loss: 1.762437435888475

Epoch: 5| Step: 2
Training loss: 0.8136089444160461
Validation loss: 1.7739974760240125

Epoch: 5| Step: 3
Training loss: 0.5524476766586304
Validation loss: 1.773598281286096

Epoch: 5| Step: 4
Training loss: 1.0136407613754272
Validation loss: 1.81497718826417

Epoch: 5| Step: 5
Training loss: 0.7913437485694885
Validation loss: 1.8477583418610275

Epoch: 5| Step: 6
Training loss: 0.7046194076538086
Validation loss: 1.8682278510062926

Epoch: 5| Step: 7
Training loss: 1.0653680562973022
Validation loss: 1.8693651230104509

Epoch: 5| Step: 8
Training loss: 0.8801096677780151
Validation loss: 1.8887094861717635

Epoch: 5| Step: 9
Training loss: 0.5077330470085144
Validation loss: 1.8726401675132014

Epoch: 5| Step: 10
Training loss: 0.6803179383277893
Validation loss: 1.842744488869944

Epoch: 222| Step: 0
Training loss: 0.4387474060058594
Validation loss: 1.8279605091259044

Epoch: 5| Step: 1
Training loss: 1.0819036960601807
Validation loss: 1.8029656435853691

Epoch: 5| Step: 2
Training loss: 0.8640338182449341
Validation loss: 1.7979376751889464

Epoch: 5| Step: 3
Training loss: 0.8842935562133789
Validation loss: 1.7794799984142344

Epoch: 5| Step: 4
Training loss: 0.6369466781616211
Validation loss: 1.7976179276743243

Epoch: 5| Step: 5
Training loss: 0.8788616061210632
Validation loss: 1.8023746359732844

Epoch: 5| Step: 6
Training loss: 0.8881639242172241
Validation loss: 1.8269806113294376

Epoch: 5| Step: 7
Training loss: 0.8052037954330444
Validation loss: 1.8798919108606154

Epoch: 5| Step: 8
Training loss: 0.7959678769111633
Validation loss: 1.891432628836683

Epoch: 5| Step: 9
Training loss: 0.6829477548599243
Validation loss: 1.9074419352316088

Epoch: 5| Step: 10
Training loss: 0.6475400924682617
Validation loss: 1.8822282155354817

Epoch: 223| Step: 0
Training loss: 0.6909551024436951
Validation loss: 1.8422202551236717

Epoch: 5| Step: 1
Training loss: 0.731756865978241
Validation loss: 1.8480935776105492

Epoch: 5| Step: 2
Training loss: 0.35119375586509705
Validation loss: 1.809355616569519

Epoch: 5| Step: 3
Training loss: 0.8522528409957886
Validation loss: 1.7769210953866281

Epoch: 5| Step: 4
Training loss: 0.7491300702095032
Validation loss: 1.7786794131801975

Epoch: 5| Step: 5
Training loss: 0.9756280183792114
Validation loss: 1.8192082092326174

Epoch: 5| Step: 6
Training loss: 1.100841760635376
Validation loss: 1.8415666831436979

Epoch: 5| Step: 7
Training loss: 1.0958231687545776
Validation loss: 1.8547875650467411

Epoch: 5| Step: 8
Training loss: 0.5855646133422852
Validation loss: 1.8553024479137954

Epoch: 5| Step: 9
Training loss: 0.8302871584892273
Validation loss: 1.8537009582724622

Epoch: 5| Step: 10
Training loss: 0.8205156922340393
Validation loss: 1.834810754304291

Epoch: 224| Step: 0
Training loss: 1.0616753101348877
Validation loss: 1.8595392434827742

Epoch: 5| Step: 1
Training loss: 0.799785315990448
Validation loss: 1.8569068703600156

Epoch: 5| Step: 2
Training loss: 1.0072591304779053
Validation loss: 1.8241317220913467

Epoch: 5| Step: 3
Training loss: 0.4806385040283203
Validation loss: 1.7867858550881828

Epoch: 5| Step: 4
Training loss: 0.9201809167861938
Validation loss: 1.802847098278743

Epoch: 5| Step: 5
Training loss: 0.7367904186248779
Validation loss: 1.7778936611708773

Epoch: 5| Step: 6
Training loss: 1.1435960531234741
Validation loss: 1.8366480988840903

Epoch: 5| Step: 7
Training loss: 0.5797100067138672
Validation loss: 1.8210152759346911

Epoch: 5| Step: 8
Training loss: 0.9081485867500305
Validation loss: 1.8269381882042013

Epoch: 5| Step: 9
Training loss: 0.5470733642578125
Validation loss: 1.7738301689906786

Epoch: 5| Step: 10
Training loss: 0.6152653694152832
Validation loss: 1.7915689535038446

Epoch: 225| Step: 0
Training loss: 0.6785550117492676
Validation loss: 1.8240913434695172

Epoch: 5| Step: 1
Training loss: 0.9220935106277466
Validation loss: 1.835120044728761

Epoch: 5| Step: 2
Training loss: 1.0547674894332886
Validation loss: 1.8471477570072297

Epoch: 5| Step: 3
Training loss: 0.6034237742424011
Validation loss: 1.8482920046775573

Epoch: 5| Step: 4
Training loss: 0.8906313180923462
Validation loss: 1.8333035066563597

Epoch: 5| Step: 5
Training loss: 0.3874167799949646
Validation loss: 1.8142592253223542

Epoch: 5| Step: 6
Training loss: 0.8485555648803711
Validation loss: 1.8201645587080268

Epoch: 5| Step: 7
Training loss: 0.49952301383018494
Validation loss: 1.801684377013996

Epoch: 5| Step: 8
Training loss: 1.0090241432189941
Validation loss: 1.7753965200916413

Epoch: 5| Step: 9
Training loss: 0.7698324918746948
Validation loss: 1.8033897658830047

Epoch: 5| Step: 10
Training loss: 0.7637861371040344
Validation loss: 1.7918451575822727

Epoch: 226| Step: 0
Training loss: 0.7527543306350708
Validation loss: 1.8032122888872701

Epoch: 5| Step: 1
Training loss: 0.6754258871078491
Validation loss: 1.7940586266979095

Epoch: 5| Step: 2
Training loss: 0.8343278169631958
Validation loss: 1.8151513363725396

Epoch: 5| Step: 3
Training loss: 0.5657075643539429
Validation loss: 1.822939033149391

Epoch: 5| Step: 4
Training loss: 0.7351945638656616
Validation loss: 1.8566098046559159

Epoch: 5| Step: 5
Training loss: 0.7868008613586426
Validation loss: 1.8470957791933449

Epoch: 5| Step: 6
Training loss: 0.8056224584579468
Validation loss: 1.865970242408014

Epoch: 5| Step: 7
Training loss: 0.8971158266067505
Validation loss: 1.8447576799700338

Epoch: 5| Step: 8
Training loss: 0.561052143573761
Validation loss: 1.816565227764909

Epoch: 5| Step: 9
Training loss: 0.7553237676620483
Validation loss: 1.8329500036854898

Epoch: 5| Step: 10
Training loss: 0.788257360458374
Validation loss: 1.813386191603958

Epoch: 227| Step: 0
Training loss: 0.6863952279090881
Validation loss: 1.8222466232956096

Epoch: 5| Step: 1
Training loss: 0.7419005036354065
Validation loss: 1.8033610390078636

Epoch: 5| Step: 2
Training loss: 0.6121618151664734
Validation loss: 1.815783977508545

Epoch: 5| Step: 3
Training loss: 0.8573876619338989
Validation loss: 1.8647572737868114

Epoch: 5| Step: 4
Training loss: 0.7621517777442932
Validation loss: 1.8669929158303045

Epoch: 5| Step: 5
Training loss: 0.6411606669425964
Validation loss: 1.833841960917237

Epoch: 5| Step: 6
Training loss: 0.6196117401123047
Validation loss: 1.8323210747011247

Epoch: 5| Step: 7
Training loss: 0.4457196593284607
Validation loss: 1.824361006418864

Epoch: 5| Step: 8
Training loss: 1.1070942878723145
Validation loss: 1.8213005130008986

Epoch: 5| Step: 9
Training loss: 0.7700584530830383
Validation loss: 1.8400867267321515

Epoch: 5| Step: 10
Training loss: 0.6438009142875671
Validation loss: 1.8517264730186873

Epoch: 228| Step: 0
Training loss: 0.74076247215271
Validation loss: 1.8232135362522577

Epoch: 5| Step: 1
Training loss: 0.6166308522224426
Validation loss: 1.788273073011829

Epoch: 5| Step: 2
Training loss: 0.6140656471252441
Validation loss: 1.756754049690821

Epoch: 5| Step: 3
Training loss: 0.7337119579315186
Validation loss: 1.793301954064318

Epoch: 5| Step: 4
Training loss: 0.7990522384643555
Validation loss: 1.8226012401683356

Epoch: 5| Step: 5
Training loss: 0.7604182958602905
Validation loss: 1.8332751015181183

Epoch: 5| Step: 6
Training loss: 0.5381572842597961
Validation loss: 1.8693114339664418

Epoch: 5| Step: 7
Training loss: 0.6920562982559204
Validation loss: 1.8378722795876123

Epoch: 5| Step: 8
Training loss: 0.7129745483398438
Validation loss: 1.824276331932314

Epoch: 5| Step: 9
Training loss: 0.9051621556282043
Validation loss: 1.8211181894425423

Epoch: 5| Step: 10
Training loss: 0.9895903468132019
Validation loss: 1.8249339775372577

Epoch: 229| Step: 0
Training loss: 0.8184229135513306
Validation loss: 1.8043180076024865

Epoch: 5| Step: 1
Training loss: 0.8129321336746216
Validation loss: 1.796326478322347

Epoch: 5| Step: 2
Training loss: 0.9532896280288696
Validation loss: 1.8053728816329793

Epoch: 5| Step: 3
Training loss: 0.6173436641693115
Validation loss: 1.8151007775337464

Epoch: 5| Step: 4
Training loss: 0.9636353254318237
Validation loss: 1.8345308419196837

Epoch: 5| Step: 5
Training loss: 0.4687280058860779
Validation loss: 1.8497825514885686

Epoch: 5| Step: 6
Training loss: 0.528820276260376
Validation loss: 1.8827128717976231

Epoch: 5| Step: 7
Training loss: 0.6366802453994751
Validation loss: 1.8850842464354731

Epoch: 5| Step: 8
Training loss: 0.6664974093437195
Validation loss: 1.8773957529375631

Epoch: 5| Step: 9
Training loss: 0.8365774154663086
Validation loss: 1.8786210783066288

Epoch: 5| Step: 10
Training loss: 0.5230476260185242
Validation loss: 1.8964211581855692

Epoch: 230| Step: 0
Training loss: 0.43354058265686035
Validation loss: 1.8461275126344414

Epoch: 5| Step: 1
Training loss: 0.6221576929092407
Validation loss: 1.8540402894378991

Epoch: 5| Step: 2
Training loss: 0.8173729181289673
Validation loss: 1.8355467806580246

Epoch: 5| Step: 3
Training loss: 0.953027069568634
Validation loss: 1.8333784803267448

Epoch: 5| Step: 4
Training loss: 0.5127600431442261
Validation loss: 1.850749461881576

Epoch: 5| Step: 5
Training loss: 0.9625421762466431
Validation loss: 1.8529506139857794

Epoch: 5| Step: 6
Training loss: 0.7225867509841919
Validation loss: 1.8532001600470593

Epoch: 5| Step: 7
Training loss: 0.6105397939682007
Validation loss: 1.8696459852239138

Epoch: 5| Step: 8
Training loss: 0.5576924681663513
Validation loss: 1.8379907633668633

Epoch: 5| Step: 9
Training loss: 0.7708686590194702
Validation loss: 1.8286793360146143

Epoch: 5| Step: 10
Training loss: 0.9218316674232483
Validation loss: 1.8281344098429526

Epoch: 231| Step: 0
Training loss: 0.4694698452949524
Validation loss: 1.8390476216552079

Epoch: 5| Step: 1
Training loss: 0.7764906883239746
Validation loss: 1.8232035906084123

Epoch: 5| Step: 2
Training loss: 1.0814452171325684
Validation loss: 1.8372088529730355

Epoch: 5| Step: 3
Training loss: 1.019504427909851
Validation loss: 1.7914948514712754

Epoch: 5| Step: 4
Training loss: 0.5108777284622192
Validation loss: 1.792641293617987

Epoch: 5| Step: 5
Training loss: 0.7780877947807312
Validation loss: 1.7790446640342794

Epoch: 5| Step: 6
Training loss: 0.8099692463874817
Validation loss: 1.7817104875400502

Epoch: 5| Step: 7
Training loss: 0.8856987953186035
Validation loss: 1.8077890514045634

Epoch: 5| Step: 8
Training loss: 0.5200212001800537
Validation loss: 1.7975074642448015

Epoch: 5| Step: 9
Training loss: 0.5504494905471802
Validation loss: 1.7954548046153078

Epoch: 5| Step: 10
Training loss: 0.6289511322975159
Validation loss: 1.8043895626580844

Epoch: 232| Step: 0
Training loss: 0.5449950098991394
Validation loss: 1.8081056123138757

Epoch: 5| Step: 1
Training loss: 0.8457893133163452
Validation loss: 1.812267836704049

Epoch: 5| Step: 2
Training loss: 0.7432901859283447
Validation loss: 1.843713032302036

Epoch: 5| Step: 3
Training loss: 0.7188796997070312
Validation loss: 1.8715684196000457

Epoch: 5| Step: 4
Training loss: 0.5178090333938599
Validation loss: 1.8962595719163136

Epoch: 5| Step: 5
Training loss: 0.8787555694580078
Validation loss: 1.8524518615456038

Epoch: 5| Step: 6
Training loss: 0.6863922476768494
Validation loss: 1.8298083825777935

Epoch: 5| Step: 7
Training loss: 0.9438096880912781
Validation loss: 1.7960330914425593

Epoch: 5| Step: 8
Training loss: 0.584092378616333
Validation loss: 1.7984635265924598

Epoch: 5| Step: 9
Training loss: 0.6424599885940552
Validation loss: 1.7857250129022906

Epoch: 5| Step: 10
Training loss: 0.7867385745048523
Validation loss: 1.7597395194474088

Epoch: 233| Step: 0
Training loss: 0.5581544637680054
Validation loss: 1.7923871419763053

Epoch: 5| Step: 1
Training loss: 0.7840179204940796
Validation loss: 1.8590663248492825

Epoch: 5| Step: 2
Training loss: 0.8728863000869751
Validation loss: 1.8808524621430265

Epoch: 5| Step: 3
Training loss: 0.6083062887191772
Validation loss: 1.8984202915622341

Epoch: 5| Step: 4
Training loss: 0.9002378582954407
Validation loss: 1.8656978402086484

Epoch: 5| Step: 5
Training loss: 0.6546570658683777
Validation loss: 1.845215230859736

Epoch: 5| Step: 6
Training loss: 0.7416855096817017
Validation loss: 1.7889147330355901

Epoch: 5| Step: 7
Training loss: 0.7640488147735596
Validation loss: 1.7436892935024795

Epoch: 5| Step: 8
Training loss: 0.8307369351387024
Validation loss: 1.7215335958747453

Epoch: 5| Step: 9
Training loss: 0.3966057598590851
Validation loss: 1.7267507955592165

Epoch: 5| Step: 10
Training loss: 0.6784350275993347
Validation loss: 1.7469448953546503

Epoch: 234| Step: 0
Training loss: 0.7057629823684692
Validation loss: 1.8244665925220778

Epoch: 5| Step: 1
Training loss: 0.39902395009994507
Validation loss: 1.8726790361506964

Epoch: 5| Step: 2
Training loss: 0.6009893417358398
Validation loss: 1.9350894484468686

Epoch: 5| Step: 3
Training loss: 0.8818942308425903
Validation loss: 1.9991254409154255

Epoch: 5| Step: 4
Training loss: 0.9739586114883423
Validation loss: 1.9591957779340847

Epoch: 5| Step: 5
Training loss: 0.6931454539299011
Validation loss: 1.9153800754136936

Epoch: 5| Step: 6
Training loss: 1.096524953842163
Validation loss: 1.8279436429341633

Epoch: 5| Step: 7
Training loss: 0.4797242283821106
Validation loss: 1.7524582339871315

Epoch: 5| Step: 8
Training loss: 0.6582047343254089
Validation loss: 1.7500859627159693

Epoch: 5| Step: 9
Training loss: 0.6511865854263306
Validation loss: 1.7181932131449382

Epoch: 5| Step: 10
Training loss: 0.9258136749267578
Validation loss: 1.7252003531302176

Epoch: 235| Step: 0
Training loss: 0.6583345532417297
Validation loss: 1.745259355473262

Epoch: 5| Step: 1
Training loss: 0.8970026969909668
Validation loss: 1.768646437634704

Epoch: 5| Step: 2
Training loss: 0.6677759885787964
Validation loss: 1.805607311187252

Epoch: 5| Step: 3
Training loss: 0.5890986919403076
Validation loss: 1.8888804040929323

Epoch: 5| Step: 4
Training loss: 0.8133665323257446
Validation loss: 1.9203274211575907

Epoch: 5| Step: 5
Training loss: 0.5168894529342651
Validation loss: 1.934543240454889

Epoch: 5| Step: 6
Training loss: 0.7765839695930481
Validation loss: 1.84856972002214

Epoch: 5| Step: 7
Training loss: 0.4140391945838928
Validation loss: 1.8073889619560652

Epoch: 5| Step: 8
Training loss: 0.8916434049606323
Validation loss: 1.77029162837613

Epoch: 5| Step: 9
Training loss: 0.6905873417854309
Validation loss: 1.76672359307607

Epoch: 5| Step: 10
Training loss: 0.7306437492370605
Validation loss: 1.744360314902439

Epoch: 236| Step: 0
Training loss: 0.7274628281593323
Validation loss: 1.701761555928056

Epoch: 5| Step: 1
Training loss: 0.6115716695785522
Validation loss: 1.7069813179713424

Epoch: 5| Step: 2
Training loss: 0.7093572020530701
Validation loss: 1.7446978784376574

Epoch: 5| Step: 3
Training loss: 0.6733261346817017
Validation loss: 1.7692089196174376

Epoch: 5| Step: 4
Training loss: 0.6840364336967468
Validation loss: 1.8409689575113275

Epoch: 5| Step: 5
Training loss: 0.802097499370575
Validation loss: 1.8463240772165277

Epoch: 5| Step: 6
Training loss: 0.9009329080581665
Validation loss: 1.8398319457166938

Epoch: 5| Step: 7
Training loss: 0.4187653958797455
Validation loss: 1.8309345527361798

Epoch: 5| Step: 8
Training loss: 1.0214943885803223
Validation loss: 1.7998007401343314

Epoch: 5| Step: 9
Training loss: 0.6357520818710327
Validation loss: 1.7572240419285272

Epoch: 5| Step: 10
Training loss: 0.6187407970428467
Validation loss: 1.7621761342530609

Epoch: 237| Step: 0
Training loss: 0.5140331387519836
Validation loss: 1.730926344471593

Epoch: 5| Step: 1
Training loss: 0.3415148854255676
Validation loss: 1.7616405410151328

Epoch: 5| Step: 2
Training loss: 0.7472497224807739
Validation loss: 1.7568750945470666

Epoch: 5| Step: 3
Training loss: 0.8897585868835449
Validation loss: 1.8170883450456845

Epoch: 5| Step: 4
Training loss: 0.7246373891830444
Validation loss: 1.814521687005156

Epoch: 5| Step: 5
Training loss: 0.5672497749328613
Validation loss: 1.8597398855352913

Epoch: 5| Step: 6
Training loss: 0.7544225454330444
Validation loss: 1.846461147390386

Epoch: 5| Step: 7
Training loss: 0.6234273910522461
Validation loss: 1.820148750018048

Epoch: 5| Step: 8
Training loss: 0.5643715262413025
Validation loss: 1.8086570027053996

Epoch: 5| Step: 9
Training loss: 0.6544939279556274
Validation loss: 1.7680374832563504

Epoch: 5| Step: 10
Training loss: 0.7652891874313354
Validation loss: 1.698815413700637

Epoch: 238| Step: 0
Training loss: 0.7504864931106567
Validation loss: 1.6722895919635732

Epoch: 5| Step: 1
Training loss: 0.9400774240493774
Validation loss: 1.668726280171384

Epoch: 5| Step: 2
Training loss: 0.5331986546516418
Validation loss: 1.6686519217747513

Epoch: 5| Step: 3
Training loss: 0.7838075160980225
Validation loss: 1.7084487612529466

Epoch: 5| Step: 4
Training loss: 0.4721878170967102
Validation loss: 1.7685285319564163

Epoch: 5| Step: 5
Training loss: 0.6091036796569824
Validation loss: 1.8325525714505104

Epoch: 5| Step: 6
Training loss: 0.6238906979560852
Validation loss: 1.8583093317606116

Epoch: 5| Step: 7
Training loss: 0.5252091288566589
Validation loss: 1.8287492452129241

Epoch: 5| Step: 8
Training loss: 0.8325355648994446
Validation loss: 1.7872604477790095

Epoch: 5| Step: 9
Training loss: 0.3845362067222595
Validation loss: 1.773367125500915

Epoch: 5| Step: 10
Training loss: 0.8135440349578857
Validation loss: 1.7637265138728644

Epoch: 239| Step: 0
Training loss: 0.8928074836730957
Validation loss: 1.790871431750636

Epoch: 5| Step: 1
Training loss: 0.6107967495918274
Validation loss: 1.7722617528771842

Epoch: 5| Step: 2
Training loss: 0.5402283072471619
Validation loss: 1.7788399842477614

Epoch: 5| Step: 3
Training loss: 0.5991808772087097
Validation loss: 1.7693747551210466

Epoch: 5| Step: 4
Training loss: 0.6828028559684753
Validation loss: 1.7230732312766455

Epoch: 5| Step: 5
Training loss: 0.3636685013771057
Validation loss: 1.738646149635315

Epoch: 5| Step: 6
Training loss: 0.8354307413101196
Validation loss: 1.7760036453124015

Epoch: 5| Step: 7
Training loss: 0.9883297085762024
Validation loss: 1.757142864247804

Epoch: 5| Step: 8
Training loss: 0.4567294716835022
Validation loss: 1.7847352130438692

Epoch: 5| Step: 9
Training loss: 0.41299542784690857
Validation loss: 1.8375577490816835

Epoch: 5| Step: 10
Training loss: 0.48672452569007874
Validation loss: 1.8388727493183588

Epoch: 240| Step: 0
Training loss: 0.7211154699325562
Validation loss: 1.8073721175552697

Epoch: 5| Step: 1
Training loss: 0.5580922365188599
Validation loss: 1.8042904510292956

Epoch: 5| Step: 2
Training loss: 0.49969539046287537
Validation loss: 1.7801327679746894

Epoch: 5| Step: 3
Training loss: 0.41284608840942383
Validation loss: 1.7683406055614512

Epoch: 5| Step: 4
Training loss: 0.2716731131076813
Validation loss: 1.7645665163634925

Epoch: 5| Step: 5
Training loss: 0.6611925959587097
Validation loss: 1.7896684523551696

Epoch: 5| Step: 6
Training loss: 0.7079913020133972
Validation loss: 1.7909830026729132

Epoch: 5| Step: 7
Training loss: 0.3997421860694885
Validation loss: 1.8232435449477165

Epoch: 5| Step: 8
Training loss: 0.6435579061508179
Validation loss: 1.8624124321886288

Epoch: 5| Step: 9
Training loss: 0.8076799511909485
Validation loss: 1.8462362802156838

Epoch: 5| Step: 10
Training loss: 1.1529752016067505
Validation loss: 1.7910833589492305

Epoch: 241| Step: 0
Training loss: 0.6833391785621643
Validation loss: 1.7688577610959288

Epoch: 5| Step: 1
Training loss: 0.6753514409065247
Validation loss: 1.7583305143540906

Epoch: 5| Step: 2
Training loss: 0.4488343298435211
Validation loss: 1.743892664550453

Epoch: 5| Step: 3
Training loss: 0.7133710980415344
Validation loss: 1.7708389374517626

Epoch: 5| Step: 4
Training loss: 0.5991360545158386
Validation loss: 1.807741480488931

Epoch: 5| Step: 5
Training loss: 0.5450588464736938
Validation loss: 1.8563949382433327

Epoch: 5| Step: 6
Training loss: 0.8601104617118835
Validation loss: 1.9153004718083206

Epoch: 5| Step: 7
Training loss: 0.5877147912979126
Validation loss: 1.9012033836815947

Epoch: 5| Step: 8
Training loss: 0.7502574920654297
Validation loss: 1.803775397680139

Epoch: 5| Step: 9
Training loss: 0.3136918842792511
Validation loss: 1.764327323564919

Epoch: 5| Step: 10
Training loss: 0.8437305092811584
Validation loss: 1.7074634400747155

Epoch: 242| Step: 0
Training loss: 0.6641998291015625
Validation loss: 1.7151404119306994

Epoch: 5| Step: 1
Training loss: 1.2213823795318604
Validation loss: 1.7353447021976594

Epoch: 5| Step: 2
Training loss: 0.7264623045921326
Validation loss: 1.7451355854670207

Epoch: 5| Step: 3
Training loss: 0.5776992440223694
Validation loss: 1.7796044606034473

Epoch: 5| Step: 4
Training loss: 0.42077285051345825
Validation loss: 1.8120366347733365

Epoch: 5| Step: 5
Training loss: 0.7509536147117615
Validation loss: 1.8315834986266268

Epoch: 5| Step: 6
Training loss: 0.666072428226471
Validation loss: 1.8261709482439104

Epoch: 5| Step: 7
Training loss: 0.4038669168949127
Validation loss: 1.8120674343519314

Epoch: 5| Step: 8
Training loss: 0.5027670860290527
Validation loss: 1.7812150075871458

Epoch: 5| Step: 9
Training loss: 0.49785980582237244
Validation loss: 1.7569197723942418

Epoch: 5| Step: 10
Training loss: 0.2660214602947235
Validation loss: 1.7390467069482292

Epoch: 243| Step: 0
Training loss: 0.5277665853500366
Validation loss: 1.7234159964387135

Epoch: 5| Step: 1
Training loss: 0.7244972586631775
Validation loss: 1.7465337168785833

Epoch: 5| Step: 2
Training loss: 0.6363945603370667
Validation loss: 1.7540187784420547

Epoch: 5| Step: 3
Training loss: 0.7457070350646973
Validation loss: 1.7231067021687825

Epoch: 5| Step: 4
Training loss: 0.515436053276062
Validation loss: 1.729153779245192

Epoch: 5| Step: 5
Training loss: 0.6267768144607544
Validation loss: 1.7521294022119174

Epoch: 5| Step: 6
Training loss: 1.0453269481658936
Validation loss: 1.774442413801788

Epoch: 5| Step: 7
Training loss: 0.5052874684333801
Validation loss: 1.7720637949564124

Epoch: 5| Step: 8
Training loss: 0.3890833854675293
Validation loss: 1.8027601549702306

Epoch: 5| Step: 9
Training loss: 0.5094934701919556
Validation loss: 1.8480299057499054

Epoch: 5| Step: 10
Training loss: 0.43081194162368774
Validation loss: 1.874854051938621

Epoch: 244| Step: 0
Training loss: 0.5642045736312866
Validation loss: 1.8776249449740174

Epoch: 5| Step: 1
Training loss: 0.8139349222183228
Validation loss: 1.8216723895842029

Epoch: 5| Step: 2
Training loss: 0.5163199305534363
Validation loss: 1.7882455907842165

Epoch: 5| Step: 3
Training loss: 0.5537508130073547
Validation loss: 1.7423678444277855

Epoch: 5| Step: 4
Training loss: 0.6645992994308472
Validation loss: 1.7494145849699616

Epoch: 5| Step: 5
Training loss: 0.6802932620048523
Validation loss: 1.745944292314591

Epoch: 5| Step: 6
Training loss: 0.8292956352233887
Validation loss: 1.7216724721334313

Epoch: 5| Step: 7
Training loss: 0.47489404678344727
Validation loss: 1.7291794425697737

Epoch: 5| Step: 8
Training loss: 0.6648613810539246
Validation loss: 1.7251362646779707

Epoch: 5| Step: 9
Training loss: 0.5745706558227539
Validation loss: 1.7474147453103015

Epoch: 5| Step: 10
Training loss: 0.5645350217819214
Validation loss: 1.7953747587819253

Epoch: 245| Step: 0
Training loss: 0.49346810579299927
Validation loss: 1.8018470643669047

Epoch: 5| Step: 1
Training loss: 0.349104106426239
Validation loss: 1.8413845134037796

Epoch: 5| Step: 2
Training loss: 0.6749431490898132
Validation loss: 1.808321314473306

Epoch: 5| Step: 3
Training loss: 0.46356692910194397
Validation loss: 1.7526172348248061

Epoch: 5| Step: 4
Training loss: 0.9215900301933289
Validation loss: 1.7161985866485103

Epoch: 5| Step: 5
Training loss: 0.8090632557868958
Validation loss: 1.7053103293142011

Epoch: 5| Step: 6
Training loss: 0.48990756273269653
Validation loss: 1.702733483365787

Epoch: 5| Step: 7
Training loss: 0.8378559947013855
Validation loss: 1.6813958050102316

Epoch: 5| Step: 8
Training loss: 0.5631177425384521
Validation loss: 1.7073299256704186

Epoch: 5| Step: 9
Training loss: 0.44625139236450195
Validation loss: 1.7012458078322872

Epoch: 5| Step: 10
Training loss: 0.6128872632980347
Validation loss: 1.739825774264592

Epoch: 246| Step: 0
Training loss: 0.6265350580215454
Validation loss: 1.779746747785999

Epoch: 5| Step: 1
Training loss: 0.5553443431854248
Validation loss: 1.79604923084218

Epoch: 5| Step: 2
Training loss: 0.5678548812866211
Validation loss: 1.8128830412382722

Epoch: 5| Step: 3
Training loss: 0.5793365240097046
Validation loss: 1.8297299467107302

Epoch: 5| Step: 4
Training loss: 0.5040906071662903
Validation loss: 1.8185675708196496

Epoch: 5| Step: 5
Training loss: 0.3561345934867859
Validation loss: 1.784150312023778

Epoch: 5| Step: 6
Training loss: 0.6160144805908203
Validation loss: 1.7515112738455496

Epoch: 5| Step: 7
Training loss: 0.8937803506851196
Validation loss: 1.7435057881057903

Epoch: 5| Step: 8
Training loss: 0.5574787855148315
Validation loss: 1.7596771447889266

Epoch: 5| Step: 9
Training loss: 0.4667028486728668
Validation loss: 1.7226113016887377

Epoch: 5| Step: 10
Training loss: 0.7122194766998291
Validation loss: 1.7638604743506319

Epoch: 247| Step: 0
Training loss: 0.510576605796814
Validation loss: 1.787750490250126

Epoch: 5| Step: 1
Training loss: 0.6829530000686646
Validation loss: 1.8120154360289216

Epoch: 5| Step: 2
Training loss: 0.33027374744415283
Validation loss: 1.7968095682000602

Epoch: 5| Step: 3
Training loss: 0.7766144275665283
Validation loss: 1.7873205472064275

Epoch: 5| Step: 4
Training loss: 0.672764003276825
Validation loss: 1.7432637535115725

Epoch: 5| Step: 5
Training loss: 0.336029589176178
Validation loss: 1.748703033693375

Epoch: 5| Step: 6
Training loss: 0.2801922857761383
Validation loss: 1.7526496648788452

Epoch: 5| Step: 7
Training loss: 0.8533509373664856
Validation loss: 1.7610205995139254

Epoch: 5| Step: 8
Training loss: 0.5457159876823425
Validation loss: 1.7877274828572427

Epoch: 5| Step: 9
Training loss: 1.005567193031311
Validation loss: 1.8277457324407433

Epoch: 5| Step: 10
Training loss: 0.5901266932487488
Validation loss: 1.844244223768993

Epoch: 248| Step: 0
Training loss: 0.6594856381416321
Validation loss: 1.8258556473639704

Epoch: 5| Step: 1
Training loss: 0.6670997738838196
Validation loss: 1.7507684333350069

Epoch: 5| Step: 2
Training loss: 0.6413272023200989
Validation loss: 1.732418329485001

Epoch: 5| Step: 3
Training loss: 0.8014299273490906
Validation loss: 1.741686728692824

Epoch: 5| Step: 4
Training loss: 0.5354889035224915
Validation loss: 1.7063405193308347

Epoch: 5| Step: 5
Training loss: 0.6518566012382507
Validation loss: 1.7262732867271668

Epoch: 5| Step: 6
Training loss: 0.4374133050441742
Validation loss: 1.7386271235763386

Epoch: 5| Step: 7
Training loss: 0.7687270641326904
Validation loss: 1.782460222962082

Epoch: 5| Step: 8
Training loss: 0.5969111323356628
Validation loss: 1.8519895717661867

Epoch: 5| Step: 9
Training loss: 0.33647337555885315
Validation loss: 1.8701351176026046

Epoch: 5| Step: 10
Training loss: 0.5837506055831909
Validation loss: 1.832506525901056

Epoch: 249| Step: 0
Training loss: 0.15006142854690552
Validation loss: 1.7312914325344948

Epoch: 5| Step: 1
Training loss: 0.6634893417358398
Validation loss: 1.6861310101324511

Epoch: 5| Step: 2
Training loss: 0.7308480143547058
Validation loss: 1.6718586285909016

Epoch: 5| Step: 3
Training loss: 0.41148480772972107
Validation loss: 1.685264197728967

Epoch: 5| Step: 4
Training loss: 0.36473026871681213
Validation loss: 1.6896756772072083

Epoch: 5| Step: 5
Training loss: 0.699116051197052
Validation loss: 1.6918787238418416

Epoch: 5| Step: 6
Training loss: 0.7317460775375366
Validation loss: 1.7015401778682586

Epoch: 5| Step: 7
Training loss: 0.674466609954834
Validation loss: 1.7143578067902596

Epoch: 5| Step: 8
Training loss: 0.6017089486122131
Validation loss: 1.789142862443001

Epoch: 5| Step: 9
Training loss: 0.41340094804763794
Validation loss: 1.7705139908739316

Epoch: 5| Step: 10
Training loss: 0.8784558773040771
Validation loss: 1.7426702130225398

Epoch: 250| Step: 0
Training loss: 0.5969300866127014
Validation loss: 1.6964918746743152

Epoch: 5| Step: 1
Training loss: 0.5229489207267761
Validation loss: 1.697874205086821

Epoch: 5| Step: 2
Training loss: 0.4904528260231018
Validation loss: 1.6640971373486262

Epoch: 5| Step: 3
Training loss: 0.7805312871932983
Validation loss: 1.630093962915482

Epoch: 5| Step: 4
Training loss: 0.5679728984832764
Validation loss: 1.6537664718525384

Epoch: 5| Step: 5
Training loss: 0.6015645861625671
Validation loss: 1.6591381462671424

Epoch: 5| Step: 6
Training loss: 0.5821473002433777
Validation loss: 1.6975989418645059

Epoch: 5| Step: 7
Training loss: 0.7033678293228149
Validation loss: 1.7723522288824922

Epoch: 5| Step: 8
Training loss: 0.6590014696121216
Validation loss: 1.828234666137285

Epoch: 5| Step: 9
Training loss: 0.3487416207790375
Validation loss: 1.825127891314927

Epoch: 5| Step: 10
Training loss: 0.3154107332229614
Validation loss: 1.7794716037729734

Epoch: 251| Step: 0
Training loss: 0.6068385243415833
Validation loss: 1.7410055552759478

Epoch: 5| Step: 1
Training loss: 0.6955562829971313
Validation loss: 1.748419697566699

Epoch: 5| Step: 2
Training loss: 0.47474774718284607
Validation loss: 1.733485580772482

Epoch: 5| Step: 3
Training loss: 0.3225494921207428
Validation loss: 1.732886186210058

Epoch: 5| Step: 4
Training loss: 0.5295799970626831
Validation loss: 1.726594437835037

Epoch: 5| Step: 5
Training loss: 0.46130460500717163
Validation loss: 1.7228537682564027

Epoch: 5| Step: 6
Training loss: 0.6993473172187805
Validation loss: 1.7232847995655511

Epoch: 5| Step: 7
Training loss: 0.564355731010437
Validation loss: 1.7073761340110534

Epoch: 5| Step: 8
Training loss: 0.43991875648498535
Validation loss: 1.7202637785224504

Epoch: 5| Step: 9
Training loss: 0.7357598543167114
Validation loss: 1.7066643122703797

Epoch: 5| Step: 10
Training loss: 0.6010620594024658
Validation loss: 1.7199299540570987

Epoch: 252| Step: 0
Training loss: 0.565941572189331
Validation loss: 1.7608004821244108

Epoch: 5| Step: 1
Training loss: 0.6572616696357727
Validation loss: 1.742839991405446

Epoch: 5| Step: 2
Training loss: 0.7937386631965637
Validation loss: 1.7053734384557253

Epoch: 5| Step: 3
Training loss: 0.447030633687973
Validation loss: 1.7400276212282078

Epoch: 5| Step: 4
Training loss: 0.29915621876716614
Validation loss: 1.711450889546384

Epoch: 5| Step: 5
Training loss: 0.6343912482261658
Validation loss: 1.7343097322730607

Epoch: 5| Step: 6
Training loss: 0.6342639923095703
Validation loss: 1.7622934105575725

Epoch: 5| Step: 7
Training loss: 0.7364063262939453
Validation loss: 1.7656439222315305

Epoch: 5| Step: 8
Training loss: 0.6371405720710754
Validation loss: 1.7719826429120955

Epoch: 5| Step: 9
Training loss: 0.33902353048324585
Validation loss: 1.7809635567408737

Epoch: 5| Step: 10
Training loss: 0.739688515663147
Validation loss: 1.7743095832486306

Epoch: 253| Step: 0
Training loss: 0.558803915977478
Validation loss: 1.756013285729193

Epoch: 5| Step: 1
Training loss: 0.6244763135910034
Validation loss: 1.7138542026601813

Epoch: 5| Step: 2
Training loss: 0.4719305634498596
Validation loss: 1.683425397001287

Epoch: 5| Step: 3
Training loss: 0.4366154074668884
Validation loss: 1.7106841405232747

Epoch: 5| Step: 4
Training loss: 0.5784899592399597
Validation loss: 1.7459793052365702

Epoch: 5| Step: 5
Training loss: 0.6897929310798645
Validation loss: 1.789095469700393

Epoch: 5| Step: 6
Training loss: 0.3894863724708557
Validation loss: 1.7991566952838693

Epoch: 5| Step: 7
Training loss: 0.7297030687332153
Validation loss: 1.8211521704991658

Epoch: 5| Step: 8
Training loss: 0.7886670827865601
Validation loss: 1.7864778195658038

Epoch: 5| Step: 9
Training loss: 0.5766297578811646
Validation loss: 1.7402714631890739

Epoch: 5| Step: 10
Training loss: 0.3628404140472412
Validation loss: 1.694948633511861

Epoch: 254| Step: 0
Training loss: 0.3926466405391693
Validation loss: 1.674689672326529

Epoch: 5| Step: 1
Training loss: 0.7833223342895508
Validation loss: 1.6729175595827

Epoch: 5| Step: 2
Training loss: 0.45299920439720154
Validation loss: 1.6884671398388442

Epoch: 5| Step: 3
Training loss: 0.4958731532096863
Validation loss: 1.698657888238148

Epoch: 5| Step: 4
Training loss: 0.5547651052474976
Validation loss: 1.7546060239115069

Epoch: 5| Step: 5
Training loss: 0.4828132092952728
Validation loss: 1.7877312475635159

Epoch: 5| Step: 6
Training loss: 0.7133159041404724
Validation loss: 1.8518030451190086

Epoch: 5| Step: 7
Training loss: 0.66350919008255
Validation loss: 1.8740006313529065

Epoch: 5| Step: 8
Training loss: 0.4608532786369324
Validation loss: 1.8162254466805408

Epoch: 5| Step: 9
Training loss: 0.5373636484146118
Validation loss: 1.7382201251163278

Epoch: 5| Step: 10
Training loss: 0.6712095141410828
Validation loss: 1.7021529905257686

Epoch: 255| Step: 0
Training loss: 0.7348319292068481
Validation loss: 1.65593304429003

Epoch: 5| Step: 1
Training loss: 0.7138296961784363
Validation loss: 1.6733603016022713

Epoch: 5| Step: 2
Training loss: 0.5023000240325928
Validation loss: 1.673563600227397

Epoch: 5| Step: 3
Training loss: 0.4797450006008148
Validation loss: 1.6697040706552484

Epoch: 5| Step: 4
Training loss: 0.7000442743301392
Validation loss: 1.6685594384388258

Epoch: 5| Step: 5
Training loss: 0.5803912878036499
Validation loss: 1.711432460815676

Epoch: 5| Step: 6
Training loss: 0.4326173663139343
Validation loss: 1.7655635527385178

Epoch: 5| Step: 7
Training loss: 0.43249455094337463
Validation loss: 1.8178788538902038

Epoch: 5| Step: 8
Training loss: 0.8217538595199585
Validation loss: 1.822880998734505

Epoch: 5| Step: 9
Training loss: 0.4328640401363373
Validation loss: 1.7932434440940939

Epoch: 5| Step: 10
Training loss: 0.6644548773765564
Validation loss: 1.76366437122386

Epoch: 256| Step: 0
Training loss: 0.6183738708496094
Validation loss: 1.7391298868322884

Epoch: 5| Step: 1
Training loss: 0.5087482929229736
Validation loss: 1.6889247676377654

Epoch: 5| Step: 2
Training loss: 0.7545031309127808
Validation loss: 1.6977634673477502

Epoch: 5| Step: 3
Training loss: 0.43832093477249146
Validation loss: 1.6736834972135481

Epoch: 5| Step: 4
Training loss: 0.305004745721817
Validation loss: 1.687634987215842

Epoch: 5| Step: 5
Training loss: 0.6914125680923462
Validation loss: 1.7030830114118514

Epoch: 5| Step: 6
Training loss: 0.6164568662643433
Validation loss: 1.7378451875461045

Epoch: 5| Step: 7
Training loss: 0.44173377752304077
Validation loss: 1.7508193305743638

Epoch: 5| Step: 8
Training loss: 0.4314655661582947
Validation loss: 1.7542852381224274

Epoch: 5| Step: 9
Training loss: 0.5445460081100464
Validation loss: 1.7626631593191495

Epoch: 5| Step: 10
Training loss: 0.5643611550331116
Validation loss: 1.7568379961034304

Epoch: 257| Step: 0
Training loss: 0.458336740732193
Validation loss: 1.756208501836305

Epoch: 5| Step: 1
Training loss: 0.4390130937099457
Validation loss: 1.7239203696609826

Epoch: 5| Step: 2
Training loss: 0.43848466873168945
Validation loss: 1.7087189907668738

Epoch: 5| Step: 3
Training loss: 0.32867544889450073
Validation loss: 1.7162469330654349

Epoch: 5| Step: 4
Training loss: 0.6285691857337952
Validation loss: 1.7173366879904142

Epoch: 5| Step: 5
Training loss: 0.7270421981811523
Validation loss: 1.7523400655356787

Epoch: 5| Step: 6
Training loss: 0.4921661913394928
Validation loss: 1.7640395959218342

Epoch: 5| Step: 7
Training loss: 0.5122483968734741
Validation loss: 1.7760613554267473

Epoch: 5| Step: 8
Training loss: 0.6289281249046326
Validation loss: 1.7612624450396466

Epoch: 5| Step: 9
Training loss: 0.6994680166244507
Validation loss: 1.7724846742486442

Epoch: 5| Step: 10
Training loss: 0.3421281576156616
Validation loss: 1.74252147956561

Epoch: 258| Step: 0
Training loss: 0.6128979921340942
Validation loss: 1.7608136643645584

Epoch: 5| Step: 1
Training loss: 0.5746358633041382
Validation loss: 1.7409208769439368

Epoch: 5| Step: 2
Training loss: 0.7470024228096008
Validation loss: 1.7330149360882339

Epoch: 5| Step: 3
Training loss: 0.5405670404434204
Validation loss: 1.7194246438241774

Epoch: 5| Step: 4
Training loss: 0.3937200605869293
Validation loss: 1.6894411335709274

Epoch: 5| Step: 5
Training loss: 0.26913318037986755
Validation loss: 1.687853442725315

Epoch: 5| Step: 6
Training loss: 0.22349409759044647
Validation loss: 1.680342258945588

Epoch: 5| Step: 7
Training loss: 0.24882888793945312
Validation loss: 1.6766234636306763

Epoch: 5| Step: 8
Training loss: 0.6174285411834717
Validation loss: 1.6671494155801752

Epoch: 5| Step: 9
Training loss: 0.959405243396759
Validation loss: 1.6692880802257086

Epoch: 5| Step: 10
Training loss: 0.3108220398426056
Validation loss: 1.6740055968684535

Epoch: 259| Step: 0
Training loss: 0.42805957794189453
Validation loss: 1.6841050668429303

Epoch: 5| Step: 1
Training loss: 0.468782514333725
Validation loss: 1.7185514665419055

Epoch: 5| Step: 2
Training loss: 0.600431501865387
Validation loss: 1.768450052507462

Epoch: 5| Step: 3
Training loss: 0.40118464827537537
Validation loss: 1.7877837457964498

Epoch: 5| Step: 4
Training loss: 0.5212497711181641
Validation loss: 1.8089682927695654

Epoch: 5| Step: 5
Training loss: 0.37596988677978516
Validation loss: 1.8095388374020975

Epoch: 5| Step: 6
Training loss: 0.6157472729682922
Validation loss: 1.745522665721114

Epoch: 5| Step: 7
Training loss: 0.4733615815639496
Validation loss: 1.7398073968066965

Epoch: 5| Step: 8
Training loss: 0.5888498425483704
Validation loss: 1.6978652272173154

Epoch: 5| Step: 9
Training loss: 0.4811321794986725
Validation loss: 1.7177216019681705

Epoch: 5| Step: 10
Training loss: 0.983953595161438
Validation loss: 1.6959562634909024

Epoch: 260| Step: 0
Training loss: 0.6213829517364502
Validation loss: 1.672053087142206

Epoch: 5| Step: 1
Training loss: 0.3043319582939148
Validation loss: 1.6979048367469542

Epoch: 5| Step: 2
Training loss: 0.5157894492149353
Validation loss: 1.6942176652211014

Epoch: 5| Step: 3
Training loss: 0.29562997817993164
Validation loss: 1.707646713461927

Epoch: 5| Step: 4
Training loss: 0.5155322551727295
Validation loss: 1.7221605893104308

Epoch: 5| Step: 5
Training loss: 0.621768593788147
Validation loss: 1.7257782746386785

Epoch: 5| Step: 6
Training loss: 0.8373792767524719
Validation loss: 1.739258934092778

Epoch: 5| Step: 7
Training loss: 0.40779152512550354
Validation loss: 1.699121170146491

Epoch: 5| Step: 8
Training loss: 0.4479946494102478
Validation loss: 1.7155123192776915

Epoch: 5| Step: 9
Training loss: 0.525268018245697
Validation loss: 1.7057782373120707

Epoch: 5| Step: 10
Training loss: 0.42082205414772034
Validation loss: 1.7076246353887743

Epoch: 261| Step: 0
Training loss: 0.43301495909690857
Validation loss: 1.7171932061513264

Epoch: 5| Step: 1
Training loss: 0.3519928753376007
Validation loss: 1.7270477433358469

Epoch: 5| Step: 2
Training loss: 0.5001017451286316
Validation loss: 1.7507927033209032

Epoch: 5| Step: 3
Training loss: 0.3533545434474945
Validation loss: 1.7443264158823157

Epoch: 5| Step: 4
Training loss: 0.7227991223335266
Validation loss: 1.7255199673355266

Epoch: 5| Step: 5
Training loss: 0.4364953637123108
Validation loss: 1.724691355100242

Epoch: 5| Step: 6
Training loss: 0.5331308841705322
Validation loss: 1.7226372803411176

Epoch: 5| Step: 7
Training loss: 0.34109944105148315
Validation loss: 1.7367339775126467

Epoch: 5| Step: 8
Training loss: 0.5829997062683105
Validation loss: 1.7730264035604333

Epoch: 5| Step: 9
Training loss: 0.41845908761024475
Validation loss: 1.7748280789262505

Epoch: 5| Step: 10
Training loss: 0.6162590980529785
Validation loss: 1.7451294250385736

Epoch: 262| Step: 0
Training loss: 0.4018545150756836
Validation loss: 1.7700811214344476

Epoch: 5| Step: 1
Training loss: 0.7068799734115601
Validation loss: 1.7550762276495657

Epoch: 5| Step: 2
Training loss: 0.3995249271392822
Validation loss: 1.7006982475198724

Epoch: 5| Step: 3
Training loss: 0.35297709703445435
Validation loss: 1.6616119197619859

Epoch: 5| Step: 4
Training loss: 0.6001929044723511
Validation loss: 1.6337923234508884

Epoch: 5| Step: 5
Training loss: 0.4137142300605774
Validation loss: 1.6242747460642168

Epoch: 5| Step: 6
Training loss: 0.6083707213401794
Validation loss: 1.6508727509488341

Epoch: 5| Step: 7
Training loss: 0.32346025109291077
Validation loss: 1.6987029660132624

Epoch: 5| Step: 8
Training loss: 0.44711580872535706
Validation loss: 1.7818994060639413

Epoch: 5| Step: 9
Training loss: 0.6345006227493286
Validation loss: 1.8070640538328437

Epoch: 5| Step: 10
Training loss: 0.4702496826648712
Validation loss: 1.8148315055395967

Epoch: 263| Step: 0
Training loss: 0.40135636925697327
Validation loss: 1.8234173713191864

Epoch: 5| Step: 1
Training loss: 0.29177698493003845
Validation loss: 1.7744075867437548

Epoch: 5| Step: 2
Training loss: 0.45011967420578003
Validation loss: 1.769715170706472

Epoch: 5| Step: 3
Training loss: 0.5006881952285767
Validation loss: 1.720996420870545

Epoch: 5| Step: 4
Training loss: 0.5193985104560852
Validation loss: 1.7237202518729753

Epoch: 5| Step: 5
Training loss: 0.6494156122207642
Validation loss: 1.7006398009997543

Epoch: 5| Step: 6
Training loss: 0.337266206741333
Validation loss: 1.6690037788883332

Epoch: 5| Step: 7
Training loss: 0.5695884823799133
Validation loss: 1.6977052124597694

Epoch: 5| Step: 8
Training loss: 0.4915769696235657
Validation loss: 1.6910277143601449

Epoch: 5| Step: 9
Training loss: 0.5123817324638367
Validation loss: 1.6981290976206462

Epoch: 5| Step: 10
Training loss: 0.6844081282615662
Validation loss: 1.7065561920083978

Epoch: 264| Step: 0
Training loss: 0.38553762435913086
Validation loss: 1.7515492945589044

Epoch: 5| Step: 1
Training loss: 0.6403481960296631
Validation loss: 1.776831256446018

Epoch: 5| Step: 2
Training loss: 0.6157974600791931
Validation loss: 1.752326734604374

Epoch: 5| Step: 3
Training loss: 0.3460652232170105
Validation loss: 1.7433742618048063

Epoch: 5| Step: 4
Training loss: 0.43965163826942444
Validation loss: 1.696931831298336

Epoch: 5| Step: 5
Training loss: 0.2954168915748596
Validation loss: 1.6611543009358067

Epoch: 5| Step: 6
Training loss: 0.4237666130065918
Validation loss: 1.6426106986179148

Epoch: 5| Step: 7
Training loss: 0.6447626352310181
Validation loss: 1.6405610935662382

Epoch: 5| Step: 8
Training loss: 0.6429532766342163
Validation loss: 1.6468025099846624

Epoch: 5| Step: 9
Training loss: 0.5458532571792603
Validation loss: 1.6709992013951784

Epoch: 5| Step: 10
Training loss: 0.41058599948883057
Validation loss: 1.6616103341502528

Epoch: 265| Step: 0
Training loss: 0.6102798581123352
Validation loss: 1.7029625190201627

Epoch: 5| Step: 1
Training loss: 0.3550933003425598
Validation loss: 1.740263549230432

Epoch: 5| Step: 2
Training loss: 0.5474141240119934
Validation loss: 1.7242591047799716

Epoch: 5| Step: 3
Training loss: 0.43234139680862427
Validation loss: 1.7145257265337053

Epoch: 5| Step: 4
Training loss: 0.7202306389808655
Validation loss: 1.6633505975046465

Epoch: 5| Step: 5
Training loss: 0.43966594338417053
Validation loss: 1.6618361806356778

Epoch: 5| Step: 6
Training loss: 0.43136686086654663
Validation loss: 1.6372995056131834

Epoch: 5| Step: 7
Training loss: 0.4713561534881592
Validation loss: 1.6259934197189987

Epoch: 5| Step: 8
Training loss: 0.4236026704311371
Validation loss: 1.6395593240696897

Epoch: 5| Step: 9
Training loss: 0.5278463959693909
Validation loss: 1.6713970912400113

Epoch: 5| Step: 10
Training loss: 0.3485962748527527
Validation loss: 1.7082362655670411

Epoch: 266| Step: 0
Training loss: 0.34178000688552856
Validation loss: 1.7012232067764446

Epoch: 5| Step: 1
Training loss: 0.5595358610153198
Validation loss: 1.668596185663695

Epoch: 5| Step: 2
Training loss: 0.44760265946388245
Validation loss: 1.6628254895569177

Epoch: 5| Step: 3
Training loss: 0.5209401845932007
Validation loss: 1.6457229314311859

Epoch: 5| Step: 4
Training loss: 0.3943333923816681
Validation loss: 1.6652125812345935

Epoch: 5| Step: 5
Training loss: 0.3571128249168396
Validation loss: 1.6834565939441803

Epoch: 5| Step: 6
Training loss: 0.4337659776210785
Validation loss: 1.7102812913156324

Epoch: 5| Step: 7
Training loss: 0.5439954996109009
Validation loss: 1.738615930721324

Epoch: 5| Step: 8
Training loss: 0.5014320611953735
Validation loss: 1.7854321772052395

Epoch: 5| Step: 9
Training loss: 0.6199146509170532
Validation loss: 1.7937044469259118

Epoch: 5| Step: 10
Training loss: 0.35972702503204346
Validation loss: 1.726681524707425

Epoch: 267| Step: 0
Training loss: 0.47155284881591797
Validation loss: 1.6763318059264973

Epoch: 5| Step: 1
Training loss: 0.5189451575279236
Validation loss: 1.666515011941233

Epoch: 5| Step: 2
Training loss: 0.5487706065177917
Validation loss: 1.6266549107848958

Epoch: 5| Step: 3
Training loss: 0.4759228229522705
Validation loss: 1.6245705030297721

Epoch: 5| Step: 4
Training loss: 0.34572312235832214
Validation loss: 1.655543468331778

Epoch: 5| Step: 5
Training loss: 0.40202564001083374
Validation loss: 1.6487419733437159

Epoch: 5| Step: 6
Training loss: 0.7072593569755554
Validation loss: 1.6651829481124878

Epoch: 5| Step: 7
Training loss: 0.8300342559814453
Validation loss: 1.741007028087493

Epoch: 5| Step: 8
Training loss: 0.29645925760269165
Validation loss: 1.7993912261019471

Epoch: 5| Step: 9
Training loss: 0.3632931113243103
Validation loss: 1.7786388679217267

Epoch: 5| Step: 10
Training loss: 0.4107966721057892
Validation loss: 1.7419745204269246

Epoch: 268| Step: 0
Training loss: 0.48685088753700256
Validation loss: 1.7207895478894633

Epoch: 5| Step: 1
Training loss: 0.3656885027885437
Validation loss: 1.6623934738097652

Epoch: 5| Step: 2
Training loss: 0.3806914687156677
Validation loss: 1.6405405075319353

Epoch: 5| Step: 3
Training loss: 0.8172289133071899
Validation loss: 1.6336319959291847

Epoch: 5| Step: 4
Training loss: 0.5664161443710327
Validation loss: 1.6359000975085842

Epoch: 5| Step: 5
Training loss: 0.3970663249492645
Validation loss: 1.6516406613011514

Epoch: 5| Step: 6
Training loss: 0.3123723566532135
Validation loss: 1.6474303891581874

Epoch: 5| Step: 7
Training loss: 0.4735748767852783
Validation loss: 1.662235136955015

Epoch: 5| Step: 8
Training loss: 0.34695419669151306
Validation loss: 1.6914034863953948

Epoch: 5| Step: 9
Training loss: 0.49372634291648865
Validation loss: 1.7029412151664816

Epoch: 5| Step: 10
Training loss: 0.49117547273635864
Validation loss: 1.7058759222748459

Epoch: 269| Step: 0
Training loss: 0.29034823179244995
Validation loss: 1.7201012808789489

Epoch: 5| Step: 1
Training loss: 0.20067374408245087
Validation loss: 1.7313378857028099

Epoch: 5| Step: 2
Training loss: 0.31910833716392517
Validation loss: 1.7073198877355105

Epoch: 5| Step: 3
Training loss: 0.4035400450229645
Validation loss: 1.676701266919413

Epoch: 5| Step: 4
Training loss: 0.42041072249412537
Validation loss: 1.6353394260970495

Epoch: 5| Step: 5
Training loss: 0.5015627145767212
Validation loss: 1.641079504002807

Epoch: 5| Step: 6
Training loss: 0.7507152557373047
Validation loss: 1.6282465406643447

Epoch: 5| Step: 7
Training loss: 0.4956153929233551
Validation loss: 1.6384431828734696

Epoch: 5| Step: 8
Training loss: 0.3468569815158844
Validation loss: 1.6191343671532088

Epoch: 5| Step: 9
Training loss: 0.4590397775173187
Validation loss: 1.6282971277031848

Epoch: 5| Step: 10
Training loss: 0.7206165194511414
Validation loss: 1.6501520769570464

Epoch: 270| Step: 0
Training loss: 0.7539315819740295
Validation loss: 1.6568594049381953

Epoch: 5| Step: 1
Training loss: 0.4123227000236511
Validation loss: 1.6716743694838656

Epoch: 5| Step: 2
Training loss: 0.3808448314666748
Validation loss: 1.6834412255594808

Epoch: 5| Step: 3
Training loss: 0.6173975467681885
Validation loss: 1.722815885338732

Epoch: 5| Step: 4
Training loss: 0.3479838967323303
Validation loss: 1.735675323394037

Epoch: 5| Step: 5
Training loss: 0.3629418909549713
Validation loss: 1.7253228669525476

Epoch: 5| Step: 6
Training loss: 0.3267013132572174
Validation loss: 1.7300290574309647

Epoch: 5| Step: 7
Training loss: 0.37480252981185913
Validation loss: 1.6727119940583424

Epoch: 5| Step: 8
Training loss: 0.2032794952392578
Validation loss: 1.6542313714181223

Epoch: 5| Step: 9
Training loss: 0.44233638048171997
Validation loss: 1.6714201511875275

Epoch: 5| Step: 10
Training loss: 0.5786693692207336
Validation loss: 1.650615919020868

Epoch: 271| Step: 0
Training loss: 0.5284761190414429
Validation loss: 1.6677093505859375

Epoch: 5| Step: 1
Training loss: 0.5331116318702698
Validation loss: 1.6985298869430379

Epoch: 5| Step: 2
Training loss: 0.48514312505722046
Validation loss: 1.7315577140418432

Epoch: 5| Step: 3
Training loss: 0.2843594551086426
Validation loss: 1.7496210439230806

Epoch: 5| Step: 4
Training loss: 0.30767789483070374
Validation loss: 1.7330287720567437

Epoch: 5| Step: 5
Training loss: 0.5363171696662903
Validation loss: 1.7138275036247828

Epoch: 5| Step: 6
Training loss: 0.37535950541496277
Validation loss: 1.6902706905077862

Epoch: 5| Step: 7
Training loss: 0.2457023561000824
Validation loss: 1.6821384481204453

Epoch: 5| Step: 8
Training loss: 0.54759281873703
Validation loss: 1.675212388397545

Epoch: 5| Step: 9
Training loss: 0.4772912859916687
Validation loss: 1.6432911196062643

Epoch: 5| Step: 10
Training loss: 0.44259926676750183
Validation loss: 1.635080909857186

Epoch: 272| Step: 0
Training loss: 0.8102924227714539
Validation loss: 1.6454608953127297

Epoch: 5| Step: 1
Training loss: 0.4120877683162689
Validation loss: 1.6617200413057882

Epoch: 5| Step: 2
Training loss: 0.252634733915329
Validation loss: 1.6526656727637015

Epoch: 5| Step: 3
Training loss: 0.27327480912208557
Validation loss: 1.7045592325989918

Epoch: 5| Step: 4
Training loss: 0.43161582946777344
Validation loss: 1.7421312511608165

Epoch: 5| Step: 5
Training loss: 0.4493136405944824
Validation loss: 1.7512865707438479

Epoch: 5| Step: 6
Training loss: 0.429982990026474
Validation loss: 1.7777565602333314

Epoch: 5| Step: 7
Training loss: 0.5626761317253113
Validation loss: 1.7188378341736332

Epoch: 5| Step: 8
Training loss: 0.49805641174316406
Validation loss: 1.6607752884587934

Epoch: 5| Step: 9
Training loss: 0.3639792501926422
Validation loss: 1.6570984842956706

Epoch: 5| Step: 10
Training loss: 0.3333290219306946
Validation loss: 1.6297602679139824

Epoch: 273| Step: 0
Training loss: 0.3828425407409668
Validation loss: 1.6355421414939306

Epoch: 5| Step: 1
Training loss: 0.5449432134628296
Validation loss: 1.6480581939861338

Epoch: 5| Step: 2
Training loss: 0.4605434536933899
Validation loss: 1.6298776185640724

Epoch: 5| Step: 3
Training loss: 0.44918107986450195
Validation loss: 1.6659670337553947

Epoch: 5| Step: 4
Training loss: 0.3362160623073578
Validation loss: 1.6843064267148253

Epoch: 5| Step: 5
Training loss: 0.43605390191078186
Validation loss: 1.7006020263959003

Epoch: 5| Step: 6
Training loss: 0.23608025908470154
Validation loss: 1.7259596393954368

Epoch: 5| Step: 7
Training loss: 0.4755111634731293
Validation loss: 1.6727289743320917

Epoch: 5| Step: 8
Training loss: 0.41103944182395935
Validation loss: 1.7033313230801654

Epoch: 5| Step: 9
Training loss: 0.4249827265739441
Validation loss: 1.6825209099759337

Epoch: 5| Step: 10
Training loss: 0.3939363956451416
Validation loss: 1.6644508582289501

Epoch: 274| Step: 0
Training loss: 0.45299679040908813
Validation loss: 1.6621535619099934

Epoch: 5| Step: 1
Training loss: 0.2283637523651123
Validation loss: 1.6560657921657767

Epoch: 5| Step: 2
Training loss: 0.23492760956287384
Validation loss: 1.700912860132033

Epoch: 5| Step: 3
Training loss: 0.35206112265586853
Validation loss: 1.6941884871452086

Epoch: 5| Step: 4
Training loss: 0.5018629431724548
Validation loss: 1.7025429741028817

Epoch: 5| Step: 5
Training loss: 0.4204217791557312
Validation loss: 1.7034576862089095

Epoch: 5| Step: 6
Training loss: 0.6434409618377686
Validation loss: 1.6873707514937206

Epoch: 5| Step: 7
Training loss: 0.4096744954586029
Validation loss: 1.6842196756793606

Epoch: 5| Step: 8
Training loss: 0.4029260277748108
Validation loss: 1.6700314251325463

Epoch: 5| Step: 9
Training loss: 0.2666371464729309
Validation loss: 1.6796734166401688

Epoch: 5| Step: 10
Training loss: 0.6648939847946167
Validation loss: 1.6969977463445356

Epoch: 275| Step: 0
Training loss: 0.3126552104949951
Validation loss: 1.6933811326180734

Epoch: 5| Step: 1
Training loss: 0.5589812994003296
Validation loss: 1.7258916439548615

Epoch: 5| Step: 2
Training loss: 0.47556009888648987
Validation loss: 1.6916355317638767

Epoch: 5| Step: 3
Training loss: 0.6270822286605835
Validation loss: 1.7221090626972977

Epoch: 5| Step: 4
Training loss: 0.3808392882347107
Validation loss: 1.7187122145006735

Epoch: 5| Step: 5
Training loss: 0.2354813516139984
Validation loss: 1.6755427263116325

Epoch: 5| Step: 6
Training loss: 0.5670353174209595
Validation loss: 1.6929699451692644

Epoch: 5| Step: 7
Training loss: 0.31626778841018677
Validation loss: 1.7190083060213315

Epoch: 5| Step: 8
Training loss: 0.4107319414615631
Validation loss: 1.7289419738195275

Epoch: 5| Step: 9
Training loss: 0.29738861322402954
Validation loss: 1.716938982727707

Epoch: 5| Step: 10
Training loss: 0.21305888891220093
Validation loss: 1.7102238760199597

Epoch: 276| Step: 0
Training loss: 0.39898481965065
Validation loss: 1.6766321120723602

Epoch: 5| Step: 1
Training loss: 0.565794825553894
Validation loss: 1.6422545909881592

Epoch: 5| Step: 2
Training loss: 0.36229208111763
Validation loss: 1.632060779038296

Epoch: 5| Step: 3
Training loss: 0.4632571339607239
Validation loss: 1.6309762039492208

Epoch: 5| Step: 4
Training loss: 0.43561726808547974
Validation loss: 1.6511325002998434

Epoch: 5| Step: 5
Training loss: 0.287746787071228
Validation loss: 1.6578319572633313

Epoch: 5| Step: 6
Training loss: 0.2188706398010254
Validation loss: 1.6617666316288773

Epoch: 5| Step: 7
Training loss: 0.4336642622947693
Validation loss: 1.66053419984797

Epoch: 5| Step: 8
Training loss: 0.5247514843940735
Validation loss: 1.6583021866377963

Epoch: 5| Step: 9
Training loss: 0.26191604137420654
Validation loss: 1.663734402707828

Epoch: 5| Step: 10
Training loss: 0.24088941514492035
Validation loss: 1.65700440765709

Epoch: 277| Step: 0
Training loss: 0.1623850166797638
Validation loss: 1.660544321101199

Epoch: 5| Step: 1
Training loss: 0.3460029065608978
Validation loss: 1.6582584701558596

Epoch: 5| Step: 2
Training loss: 0.3015698790550232
Validation loss: 1.6629193546951457

Epoch: 5| Step: 3
Training loss: 0.4196855425834656
Validation loss: 1.640765864361999

Epoch: 5| Step: 4
Training loss: 0.28495272994041443
Validation loss: 1.6396638616438834

Epoch: 5| Step: 5
Training loss: 0.2762485444545746
Validation loss: 1.6622585545304

Epoch: 5| Step: 6
Training loss: 0.5460889339447021
Validation loss: 1.6503349452890375

Epoch: 5| Step: 7
Training loss: 0.24300236999988556
Validation loss: 1.685905957734713

Epoch: 5| Step: 8
Training loss: 0.6286060214042664
Validation loss: 1.7105804527959516

Epoch: 5| Step: 9
Training loss: 0.6062056422233582
Validation loss: 1.7083544679867324

Epoch: 5| Step: 10
Training loss: 0.38791152834892273
Validation loss: 1.704053271201349

Epoch: 278| Step: 0
Training loss: 0.38479453325271606
Validation loss: 1.709944946150626

Epoch: 5| Step: 1
Training loss: 0.33189746737480164
Validation loss: 1.7151625156402588

Epoch: 5| Step: 2
Training loss: 0.6465457081794739
Validation loss: 1.6896820606723908

Epoch: 5| Step: 3
Training loss: 0.46518436074256897
Validation loss: 1.6742929489381853

Epoch: 5| Step: 4
Training loss: 0.34906119108200073
Validation loss: 1.685123373103398

Epoch: 5| Step: 5
Training loss: 0.4055611491203308
Validation loss: 1.7236483584168136

Epoch: 5| Step: 6
Training loss: 0.30909886956214905
Validation loss: 1.8008037818375455

Epoch: 5| Step: 7
Training loss: 0.5667966604232788
Validation loss: 1.797164809319281

Epoch: 5| Step: 8
Training loss: 0.3203684389591217
Validation loss: 1.76300210209303

Epoch: 5| Step: 9
Training loss: 0.4063616394996643
Validation loss: 1.7193841306112145

Epoch: 5| Step: 10
Training loss: 0.2793180048465729
Validation loss: 1.6563277295840684

Epoch: 279| Step: 0
Training loss: 0.28714343905448914
Validation loss: 1.6069488012662498

Epoch: 5| Step: 1
Training loss: 0.44503849744796753
Validation loss: 1.5864125714507153

Epoch: 5| Step: 2
Training loss: 0.3686365783214569
Validation loss: 1.5618043163771271

Epoch: 5| Step: 3
Training loss: 0.47116413712501526
Validation loss: 1.5824007103520055

Epoch: 5| Step: 4
Training loss: 0.4465814530849457
Validation loss: 1.6078181523148731

Epoch: 5| Step: 5
Training loss: 0.6016565561294556
Validation loss: 1.6403635650552728

Epoch: 5| Step: 6
Training loss: 0.3148278295993805
Validation loss: 1.6682300926536642

Epoch: 5| Step: 7
Training loss: 0.3482897877693176
Validation loss: 1.7032340418907903

Epoch: 5| Step: 8
Training loss: 0.5566354393959045
Validation loss: 1.7004950943813528

Epoch: 5| Step: 9
Training loss: 0.41617459058761597
Validation loss: 1.6991296404151506

Epoch: 5| Step: 10
Training loss: 0.44252002239227295
Validation loss: 1.6676662493777532

Epoch: 280| Step: 0
Training loss: 0.27936500310897827
Validation loss: 1.7023871265431887

Epoch: 5| Step: 1
Training loss: 0.39024338126182556
Validation loss: 1.7016819741136284

Epoch: 5| Step: 2
Training loss: 0.6462315320968628
Validation loss: 1.6823841923026628

Epoch: 5| Step: 3
Training loss: 0.28452834486961365
Validation loss: 1.677797132922757

Epoch: 5| Step: 4
Training loss: 0.6140118837356567
Validation loss: 1.6846456066254647

Epoch: 5| Step: 5
Training loss: 0.2819674611091614
Validation loss: 1.6884856044605214

Epoch: 5| Step: 6
Training loss: 0.44970282912254333
Validation loss: 1.6914208217333722

Epoch: 5| Step: 7
Training loss: 0.45655912160873413
Validation loss: 1.6754945298676849

Epoch: 5| Step: 8
Training loss: 0.25659605860710144
Validation loss: 1.6553662259091613

Epoch: 5| Step: 9
Training loss: 0.3404027819633484
Validation loss: 1.6522905211294852

Epoch: 5| Step: 10
Training loss: 0.4437863826751709
Validation loss: 1.6321532425060068

Epoch: 281| Step: 0
Training loss: 0.548690915107727
Validation loss: 1.6469326237196564

Epoch: 5| Step: 1
Training loss: 0.4323655664920807
Validation loss: 1.6609615279782204

Epoch: 5| Step: 2
Training loss: 0.5809568166732788
Validation loss: 1.6619479745946906

Epoch: 5| Step: 3
Training loss: 0.5553725957870483
Validation loss: 1.71635962429867

Epoch: 5| Step: 4
Training loss: 0.31959080696105957
Validation loss: 1.7326836047634002

Epoch: 5| Step: 5
Training loss: 0.24960751831531525
Validation loss: 1.7586088693270119

Epoch: 5| Step: 6
Training loss: 0.5604227781295776
Validation loss: 1.783183515712779

Epoch: 5| Step: 7
Training loss: 0.39500412344932556
Validation loss: 1.7506108694179083

Epoch: 5| Step: 8
Training loss: 0.23838365077972412
Validation loss: 1.7210667671695832

Epoch: 5| Step: 9
Training loss: 0.5552096962928772
Validation loss: 1.6891677994881906

Epoch: 5| Step: 10
Training loss: 0.34145253896713257
Validation loss: 1.671046221128074

Epoch: 282| Step: 0
Training loss: 0.3396230936050415
Validation loss: 1.647311875897069

Epoch: 5| Step: 1
Training loss: 0.37086018919944763
Validation loss: 1.6605957156868392

Epoch: 5| Step: 2
Training loss: 0.49654918909072876
Validation loss: 1.6553758959616385

Epoch: 5| Step: 3
Training loss: 0.4944674074649811
Validation loss: 1.673442735466906

Epoch: 5| Step: 4
Training loss: 0.33518731594085693
Validation loss: 1.6918655544198968

Epoch: 5| Step: 5
Training loss: 0.4782676100730896
Validation loss: 1.7019376331760037

Epoch: 5| Step: 6
Training loss: 0.4346742630004883
Validation loss: 1.7355704692102247

Epoch: 5| Step: 7
Training loss: 0.43046146631240845
Validation loss: 1.7305720442084855

Epoch: 5| Step: 8
Training loss: 0.27630478143692017
Validation loss: 1.6636280443078728

Epoch: 5| Step: 9
Training loss: 0.36713138222694397
Validation loss: 1.6494900308629519

Epoch: 5| Step: 10
Training loss: 0.2777588963508606
Validation loss: 1.6172030856532436

Epoch: 283| Step: 0
Training loss: 0.5126411318778992
Validation loss: 1.6094037640479304

Epoch: 5| Step: 1
Training loss: 0.8703955411911011
Validation loss: 1.6349208047313075

Epoch: 5| Step: 2
Training loss: 0.23849038779735565
Validation loss: 1.6516989751528668

Epoch: 5| Step: 3
Training loss: 0.31723424792289734
Validation loss: 1.6811650606893724

Epoch: 5| Step: 4
Training loss: 0.3700549304485321
Validation loss: 1.6920294120747557

Epoch: 5| Step: 5
Training loss: 0.19043926894664764
Validation loss: 1.6724050275741085

Epoch: 5| Step: 6
Training loss: 0.4389719069004059
Validation loss: 1.6667095948291082

Epoch: 5| Step: 7
Training loss: 0.3652886748313904
Validation loss: 1.6791432121748566

Epoch: 5| Step: 8
Training loss: 0.29941898584365845
Validation loss: 1.6817543878350207

Epoch: 5| Step: 9
Training loss: 0.20373880863189697
Validation loss: 1.6892828326071463

Epoch: 5| Step: 10
Training loss: 0.2782335579395294
Validation loss: 1.6873439332490325

Epoch: 284| Step: 0
Training loss: 0.6112979650497437
Validation loss: 1.6709316430553314

Epoch: 5| Step: 1
Training loss: 0.3366601765155792
Validation loss: 1.6485556248695619

Epoch: 5| Step: 2
Training loss: 0.5639005899429321
Validation loss: 1.6580672725554435

Epoch: 5| Step: 3
Training loss: 0.309585839509964
Validation loss: 1.632541141202373

Epoch: 5| Step: 4
Training loss: 0.5044571161270142
Validation loss: 1.6218977205214962

Epoch: 5| Step: 5
Training loss: 0.2403174340724945
Validation loss: 1.6267665816891579

Epoch: 5| Step: 6
Training loss: 0.3773505985736847
Validation loss: 1.6459745143049507

Epoch: 5| Step: 7
Training loss: 0.3648396134376526
Validation loss: 1.6241303182417346

Epoch: 5| Step: 8
Training loss: 0.2881149351596832
Validation loss: 1.6507115402529318

Epoch: 5| Step: 9
Training loss: 0.22500550746917725
Validation loss: 1.6572980919191915

Epoch: 5| Step: 10
Training loss: 0.1865563690662384
Validation loss: 1.6899353227307718

Epoch: 285| Step: 0
Training loss: 0.23772387206554413
Validation loss: 1.7006838783141105

Epoch: 5| Step: 1
Training loss: 0.41159090399742126
Validation loss: 1.6994727426959622

Epoch: 5| Step: 2
Training loss: 0.16711625456809998
Validation loss: 1.7137982024941394

Epoch: 5| Step: 3
Training loss: 0.3435487151145935
Validation loss: 1.6783877700887702

Epoch: 5| Step: 4
Training loss: 0.5567142367362976
Validation loss: 1.70521968026315

Epoch: 5| Step: 5
Training loss: 0.2977723181247711
Validation loss: 1.7280695976749543

Epoch: 5| Step: 6
Training loss: 0.39825770258903503
Validation loss: 1.7045562626213155

Epoch: 5| Step: 7
Training loss: 0.2406337559223175
Validation loss: 1.7109751650082168

Epoch: 5| Step: 8
Training loss: 0.5208796858787537
Validation loss: 1.7312598484818653

Epoch: 5| Step: 9
Training loss: 0.4113994538784027
Validation loss: 1.706862957246842

Epoch: 5| Step: 10
Training loss: 0.3228759169578552
Validation loss: 1.6651539110368299

Epoch: 286| Step: 0
Training loss: 0.4878617823123932
Validation loss: 1.6788343357783493

Epoch: 5| Step: 1
Training loss: 0.30084267258644104
Validation loss: 1.6707935153797109

Epoch: 5| Step: 2
Training loss: 0.35092344880104065
Validation loss: 1.6909995027767715

Epoch: 5| Step: 3
Training loss: 0.25199875235557556
Validation loss: 1.6856650665242185

Epoch: 5| Step: 4
Training loss: 0.1753799170255661
Validation loss: 1.6609268335885898

Epoch: 5| Step: 5
Training loss: 0.6162693500518799
Validation loss: 1.6716556625981485

Epoch: 5| Step: 6
Training loss: 0.33804529905319214
Validation loss: 1.6766538017539567

Epoch: 5| Step: 7
Training loss: 0.42004984617233276
Validation loss: 1.7147449088352982

Epoch: 5| Step: 8
Training loss: 0.4369511604309082
Validation loss: 1.6820494590267059

Epoch: 5| Step: 9
Training loss: 0.37752261757850647
Validation loss: 1.664512292031319

Epoch: 5| Step: 10
Training loss: 0.34514403343200684
Validation loss: 1.6439835743237567

Epoch: 287| Step: 0
Training loss: 0.3738571107387543
Validation loss: 1.6661707765312606

Epoch: 5| Step: 1
Training loss: 0.31057101488113403
Validation loss: 1.7000062786122805

Epoch: 5| Step: 2
Training loss: 0.29857638478279114
Validation loss: 1.6672390084112845

Epoch: 5| Step: 3
Training loss: 0.30189865827560425
Validation loss: 1.6717222967455465

Epoch: 5| Step: 4
Training loss: 0.23929476737976074
Validation loss: 1.6542332172393799

Epoch: 5| Step: 5
Training loss: 0.33042895793914795
Validation loss: 1.6560949894689745

Epoch: 5| Step: 6
Training loss: 0.3114500641822815
Validation loss: 1.6687998605030838

Epoch: 5| Step: 7
Training loss: 0.5015610456466675
Validation loss: 1.6790576134958575

Epoch: 5| Step: 8
Training loss: 0.3774334788322449
Validation loss: 1.6380143242497598

Epoch: 5| Step: 9
Training loss: 0.39426541328430176
Validation loss: 1.590793635255547

Epoch: 5| Step: 10
Training loss: 0.6311625242233276
Validation loss: 1.6087492435209212

Epoch: 288| Step: 0
Training loss: 0.42023172974586487
Validation loss: 1.6167532936219247

Epoch: 5| Step: 1
Training loss: 0.2728636860847473
Validation loss: 1.6289501023548905

Epoch: 5| Step: 2
Training loss: 0.21696238219738007
Validation loss: 1.6672787153592674

Epoch: 5| Step: 3
Training loss: 0.32115650177001953
Validation loss: 1.705685994958365

Epoch: 5| Step: 4
Training loss: 0.3350762724876404
Validation loss: 1.6573814025489233

Epoch: 5| Step: 5
Training loss: 0.2644173204898834
Validation loss: 1.6547193681040118

Epoch: 5| Step: 6
Training loss: 0.32216763496398926
Validation loss: 1.6372976418464416

Epoch: 5| Step: 7
Training loss: 0.3404308259487152
Validation loss: 1.656873313329553

Epoch: 5| Step: 8
Training loss: 0.6152661442756653
Validation loss: 1.6691158099841046

Epoch: 5| Step: 9
Training loss: 0.4108557105064392
Validation loss: 1.6997868463557253

Epoch: 5| Step: 10
Training loss: 0.5925068855285645
Validation loss: 1.7222397558150753

Epoch: 289| Step: 0
Training loss: 0.2824432849884033
Validation loss: 1.7070451885141351

Epoch: 5| Step: 1
Training loss: 0.3297027051448822
Validation loss: 1.714363532681619

Epoch: 5| Step: 2
Training loss: 0.37047699093818665
Validation loss: 1.6889074053815616

Epoch: 5| Step: 3
Training loss: 0.5907038450241089
Validation loss: 1.6949664264596918

Epoch: 5| Step: 4
Training loss: 0.4699867367744446
Validation loss: 1.6971227533073836

Epoch: 5| Step: 5
Training loss: 0.32951754331588745
Validation loss: 1.6996425518425562

Epoch: 5| Step: 6
Training loss: 0.4206600785255432
Validation loss: 1.7174204626391012

Epoch: 5| Step: 7
Training loss: 0.3535015285015106
Validation loss: 1.745249040665165

Epoch: 5| Step: 8
Training loss: 0.47294363379478455
Validation loss: 1.72668715189862

Epoch: 5| Step: 9
Training loss: 0.2916771471500397
Validation loss: 1.7116831887152888

Epoch: 5| Step: 10
Training loss: 0.2035735547542572
Validation loss: 1.659253844650843

Epoch: 290| Step: 0
Training loss: 0.12287843227386475
Validation loss: 1.5942134305994997

Epoch: 5| Step: 1
Training loss: 0.3040115237236023
Validation loss: 1.6067719844079786

Epoch: 5| Step: 2
Training loss: 0.44119614362716675
Validation loss: 1.5956244404597948

Epoch: 5| Step: 3
Training loss: 0.29260316491127014
Validation loss: 1.6281797232166413

Epoch: 5| Step: 4
Training loss: 0.25395673513412476
Validation loss: 1.6656598429526053

Epoch: 5| Step: 5
Training loss: 0.35940665006637573
Validation loss: 1.6751218765012679

Epoch: 5| Step: 6
Training loss: 0.3302452862262726
Validation loss: 1.720133352023299

Epoch: 5| Step: 7
Training loss: 0.3558388352394104
Validation loss: 1.7174661056969756

Epoch: 5| Step: 8
Training loss: 0.5150343179702759
Validation loss: 1.733664310106667

Epoch: 5| Step: 9
Training loss: 0.5829946398735046
Validation loss: 1.7071825022338538

Epoch: 5| Step: 10
Training loss: 0.3973614275455475
Validation loss: 1.6368421623783727

Epoch: 291| Step: 0
Training loss: 0.43884772062301636
Validation loss: 1.6327407565168155

Epoch: 5| Step: 1
Training loss: 0.2907206118106842
Validation loss: 1.6265879690006215

Epoch: 5| Step: 2
Training loss: 0.2544810175895691
Validation loss: 1.636386493200897

Epoch: 5| Step: 3
Training loss: 0.35953226685523987
Validation loss: 1.636331695382313

Epoch: 5| Step: 4
Training loss: 0.3080306053161621
Validation loss: 1.6471450335236006

Epoch: 5| Step: 5
Training loss: 0.380532830953598
Validation loss: 1.654342141202701

Epoch: 5| Step: 6
Training loss: 0.2933582067489624
Validation loss: 1.697458069811585

Epoch: 5| Step: 7
Training loss: 0.3936214745044708
Validation loss: 1.708578960869902

Epoch: 5| Step: 8
Training loss: 0.3022746443748474
Validation loss: 1.7007824554238269

Epoch: 5| Step: 9
Training loss: 0.41774120926856995
Validation loss: 1.6706427502375778

Epoch: 5| Step: 10
Training loss: 0.7185800075531006
Validation loss: 1.6680882938446537

Epoch: 292| Step: 0
Training loss: 0.27075085043907166
Validation loss: 1.64623938709177

Epoch: 5| Step: 1
Training loss: 0.37783774733543396
Validation loss: 1.63645439891405

Epoch: 5| Step: 2
Training loss: 0.45355796813964844
Validation loss: 1.6496928507281887

Epoch: 5| Step: 3
Training loss: 0.41218677163124084
Validation loss: 1.7057597996086202

Epoch: 5| Step: 4
Training loss: 0.531002402305603
Validation loss: 1.6854402051177075

Epoch: 5| Step: 5
Training loss: 0.2104179859161377
Validation loss: 1.7035854452399797

Epoch: 5| Step: 6
Training loss: 0.2643987834453583
Validation loss: 1.6947402633646482

Epoch: 5| Step: 7
Training loss: 0.3740858733654022
Validation loss: 1.6917162044073946

Epoch: 5| Step: 8
Training loss: 0.4225960373878479
Validation loss: 1.6632143079593618

Epoch: 5| Step: 9
Training loss: 0.30221834778785706
Validation loss: 1.6743306254827848

Epoch: 5| Step: 10
Training loss: 0.4208589792251587
Validation loss: 1.6656121425731207

Epoch: 293| Step: 0
Training loss: 0.4987792372703552
Validation loss: 1.661460199663716

Epoch: 5| Step: 1
Training loss: 0.29082852602005005
Validation loss: 1.6911397031558457

Epoch: 5| Step: 2
Training loss: 0.49072161316871643
Validation loss: 1.6944716668898059

Epoch: 5| Step: 3
Training loss: 0.22781839966773987
Validation loss: 1.7062037337210871

Epoch: 5| Step: 4
Training loss: 0.3152868449687958
Validation loss: 1.707839935056625

Epoch: 5| Step: 5
Training loss: 0.6381403207778931
Validation loss: 1.7181608298773408

Epoch: 5| Step: 6
Training loss: 0.29402655363082886
Validation loss: 1.7007071266892135

Epoch: 5| Step: 7
Training loss: 0.3887064754962921
Validation loss: 1.6949313943104078

Epoch: 5| Step: 8
Training loss: 0.34035569429397583
Validation loss: 1.6711101173072733

Epoch: 5| Step: 9
Training loss: 0.1798713654279709
Validation loss: 1.659721291193398

Epoch: 5| Step: 10
Training loss: 0.2181517630815506
Validation loss: 1.6397394352061774

Epoch: 294| Step: 0
Training loss: 0.35974234342575073
Validation loss: 1.6085441150972921

Epoch: 5| Step: 1
Training loss: 0.34228262305259705
Validation loss: 1.638509376074678

Epoch: 5| Step: 2
Training loss: 0.34261685609817505
Validation loss: 1.6661307965555499

Epoch: 5| Step: 3
Training loss: 0.470447838306427
Validation loss: 1.682563945811282

Epoch: 5| Step: 4
Training loss: 0.33596643805503845
Validation loss: 1.7113796100821546

Epoch: 5| Step: 5
Training loss: 0.43220072984695435
Validation loss: 1.7073684623164516

Epoch: 5| Step: 6
Training loss: 0.6159479022026062
Validation loss: 1.7224203130250335

Epoch: 5| Step: 7
Training loss: 0.19584611058235168
Validation loss: 1.7105381155526767

Epoch: 5| Step: 8
Training loss: 0.27710455656051636
Validation loss: 1.658173567505293

Epoch: 5| Step: 9
Training loss: 0.47284287214279175
Validation loss: 1.6749210319211405

Epoch: 5| Step: 10
Training loss: 0.22396187484264374
Validation loss: 1.6497513863348192

Epoch: 295| Step: 0
Training loss: 0.2998553216457367
Validation loss: 1.6436233059052499

Epoch: 5| Step: 1
Training loss: 0.40039634704589844
Validation loss: 1.642623968021844

Epoch: 5| Step: 2
Training loss: 0.6175553202629089
Validation loss: 1.6502647886994064

Epoch: 5| Step: 3
Training loss: 0.3291444778442383
Validation loss: 1.6575032767429148

Epoch: 5| Step: 4
Training loss: 0.514217734336853
Validation loss: 1.6839447226575626

Epoch: 5| Step: 5
Training loss: 0.41666603088378906
Validation loss: 1.709935216493504

Epoch: 5| Step: 6
Training loss: 0.24430863559246063
Validation loss: 1.7369584268139255

Epoch: 5| Step: 7
Training loss: 0.44383978843688965
Validation loss: 1.7268681051910564

Epoch: 5| Step: 8
Training loss: 0.1742156445980072
Validation loss: 1.747621246563491

Epoch: 5| Step: 9
Training loss: 0.18751835823059082
Validation loss: 1.714805685063844

Epoch: 5| Step: 10
Training loss: 0.28085657954216003
Validation loss: 1.6941970996959235

Epoch: 296| Step: 0
Training loss: 0.401007741689682
Validation loss: 1.658454102854575

Epoch: 5| Step: 1
Training loss: 0.5436443090438843
Validation loss: 1.6436825862494848

Epoch: 5| Step: 2
Training loss: 0.252427875995636
Validation loss: 1.6142422024921705

Epoch: 5| Step: 3
Training loss: 0.30140218138694763
Validation loss: 1.593134489110721

Epoch: 5| Step: 4
Training loss: 0.258554607629776
Validation loss: 1.604440373759116

Epoch: 5| Step: 5
Training loss: 0.4855174124240875
Validation loss: 1.6316724067093225

Epoch: 5| Step: 6
Training loss: 0.2481653392314911
Validation loss: 1.6323754492626394

Epoch: 5| Step: 7
Training loss: 0.2785455584526062
Validation loss: 1.6477698395329137

Epoch: 5| Step: 8
Training loss: 0.22458156943321228
Validation loss: 1.6781027496501963

Epoch: 5| Step: 9
Training loss: 0.39009836316108704
Validation loss: 1.6738127380289056

Epoch: 5| Step: 10
Training loss: 0.25100427865982056
Validation loss: 1.6741520025396859

Epoch: 297| Step: 0
Training loss: 0.1699122041463852
Validation loss: 1.6677289265458302

Epoch: 5| Step: 1
Training loss: 0.26835471391677856
Validation loss: 1.6519489595966954

Epoch: 5| Step: 2
Training loss: 0.25877171754837036
Validation loss: 1.6522338159622685

Epoch: 5| Step: 3
Training loss: 0.5789164900779724
Validation loss: 1.652584336137259

Epoch: 5| Step: 4
Training loss: 0.41808876395225525
Validation loss: 1.6523376998081003

Epoch: 5| Step: 5
Training loss: 0.4729979932308197
Validation loss: 1.6970795790354412

Epoch: 5| Step: 6
Training loss: 0.14824707806110382
Validation loss: 1.6921925608829786

Epoch: 5| Step: 7
Training loss: 0.3275315761566162
Validation loss: 1.68290461263349

Epoch: 5| Step: 8
Training loss: 0.3307889401912689
Validation loss: 1.6960566505309074

Epoch: 5| Step: 9
Training loss: 0.20437797904014587
Validation loss: 1.7064807568826983

Epoch: 5| Step: 10
Training loss: 0.4748210906982422
Validation loss: 1.7006402938596663

Epoch: 298| Step: 0
Training loss: 0.7721019983291626
Validation loss: 1.690795950992133

Epoch: 5| Step: 1
Training loss: 0.27359041571617126
Validation loss: 1.687505555409257

Epoch: 5| Step: 2
Training loss: 0.3137570321559906
Validation loss: 1.6792120933532715

Epoch: 5| Step: 3
Training loss: 0.20165066421031952
Validation loss: 1.669797146192161

Epoch: 5| Step: 4
Training loss: 0.17963412404060364
Validation loss: 1.6476949478990288

Epoch: 5| Step: 5
Training loss: 0.3044281005859375
Validation loss: 1.6188564672265002

Epoch: 5| Step: 6
Training loss: 0.24231700599193573
Validation loss: 1.6428206287404543

Epoch: 5| Step: 7
Training loss: 0.35739731788635254
Validation loss: 1.6409522089906918

Epoch: 5| Step: 8
Training loss: 0.2584154009819031
Validation loss: 1.6264851324019893

Epoch: 5| Step: 9
Training loss: 0.32978108525276184
Validation loss: 1.6192334531455912

Epoch: 5| Step: 10
Training loss: 0.30381888151168823
Validation loss: 1.647941820083126

Epoch: 299| Step: 0
Training loss: 0.1770862340927124
Validation loss: 1.679427530175896

Epoch: 5| Step: 1
Training loss: 0.4741811752319336
Validation loss: 1.6805286997108049

Epoch: 5| Step: 2
Training loss: 0.3454078733921051
Validation loss: 1.7044173902080906

Epoch: 5| Step: 3
Training loss: 0.3436770439147949
Validation loss: 1.6662844778389059

Epoch: 5| Step: 4
Training loss: 0.33736681938171387
Validation loss: 1.6638796265407274

Epoch: 5| Step: 5
Training loss: 0.48820072412490845
Validation loss: 1.6076194945202078

Epoch: 5| Step: 6
Training loss: 0.355829119682312
Validation loss: 1.6023039766537246

Epoch: 5| Step: 7
Training loss: 0.2511272430419922
Validation loss: 1.592052226425499

Epoch: 5| Step: 8
Training loss: 0.2681877017021179
Validation loss: 1.5868809018083798

Epoch: 5| Step: 9
Training loss: 0.28552666306495667
Validation loss: 1.6279454872172365

Epoch: 5| Step: 10
Training loss: 0.3258971571922302
Validation loss: 1.672232767587067

Epoch: 300| Step: 0
Training loss: 0.19792647659778595
Validation loss: 1.7178108948533253

Epoch: 5| Step: 1
Training loss: 0.906756579875946
Validation loss: 1.7705533017394364

Epoch: 5| Step: 2
Training loss: 0.20030638575553894
Validation loss: 1.7397718685929493

Epoch: 5| Step: 3
Training loss: 0.3349953293800354
Validation loss: 1.6941215684337

Epoch: 5| Step: 4
Training loss: 0.1913597285747528
Validation loss: 1.6421124563422254

Epoch: 5| Step: 5
Training loss: 0.2904209792613983
Validation loss: 1.6193177289860223

Epoch: 5| Step: 6
Training loss: 0.24337132275104523
Validation loss: 1.6113343866922523

Epoch: 5| Step: 7
Training loss: 0.43780946731567383
Validation loss: 1.618795326960984

Epoch: 5| Step: 8
Training loss: 0.20004136860370636
Validation loss: 1.6140524610396354

Epoch: 5| Step: 9
Training loss: 0.2949610650539398
Validation loss: 1.638433632030282

Epoch: 5| Step: 10
Training loss: 0.30605876445770264
Validation loss: 1.6344654060179187

Epoch: 301| Step: 0
Training loss: 0.46802932024002075
Validation loss: 1.6631632774106917

Epoch: 5| Step: 1
Training loss: 0.20514564216136932
Validation loss: 1.6371560994014944

Epoch: 5| Step: 2
Training loss: 0.22411414980888367
Validation loss: 1.5927403729449037

Epoch: 5| Step: 3
Training loss: 0.3697519302368164
Validation loss: 1.6249595380598498

Epoch: 5| Step: 4
Training loss: 0.19208595156669617
Validation loss: 1.5973537173322452

Epoch: 5| Step: 5
Training loss: 0.4841242730617523
Validation loss: 1.6234738839569913

Epoch: 5| Step: 6
Training loss: 0.3776101768016815
Validation loss: 1.636535358685319

Epoch: 5| Step: 7
Training loss: 0.24365529417991638
Validation loss: 1.6651075399050148

Epoch: 5| Step: 8
Training loss: 0.31947845220565796
Validation loss: 1.6710656842877787

Epoch: 5| Step: 9
Training loss: 0.362922340631485
Validation loss: 1.712735023549808

Epoch: 5| Step: 10
Training loss: 0.2620548903942108
Validation loss: 1.6709168380306614

Epoch: 302| Step: 0
Training loss: 0.2286798506975174
Validation loss: 1.665331837951496

Epoch: 5| Step: 1
Training loss: 0.3239174783229828
Validation loss: 1.6484957407879572

Epoch: 5| Step: 2
Training loss: 0.3066053092479706
Validation loss: 1.6394701914120746

Epoch: 5| Step: 3
Training loss: 0.38685837388038635
Validation loss: 1.6422262999319261

Epoch: 5| Step: 4
Training loss: 0.3889695107936859
Validation loss: 1.648222872005996

Epoch: 5| Step: 5
Training loss: 0.23187828063964844
Validation loss: 1.6674779589458177

Epoch: 5| Step: 6
Training loss: 0.18186528980731964
Validation loss: 1.6849880513324533

Epoch: 5| Step: 7
Training loss: 0.2612746059894562
Validation loss: 1.704179230236238

Epoch: 5| Step: 8
Training loss: 0.5680086016654968
Validation loss: 1.6774039729948966

Epoch: 5| Step: 9
Training loss: 0.2678382098674774
Validation loss: 1.6215581560647616

Epoch: 5| Step: 10
Training loss: 0.30957871675491333
Validation loss: 1.6271017123294134

Epoch: 303| Step: 0
Training loss: 0.1853262484073639
Validation loss: 1.6388024437812068

Epoch: 5| Step: 1
Training loss: 0.34067195653915405
Validation loss: 1.631189525768321

Epoch: 5| Step: 2
Training loss: 0.22095756232738495
Validation loss: 1.6155143476301623

Epoch: 5| Step: 3
Training loss: 0.34975236654281616
Validation loss: 1.6085345604086434

Epoch: 5| Step: 4
Training loss: 0.4850958287715912
Validation loss: 1.602813237456865

Epoch: 5| Step: 5
Training loss: 0.3349349796772003
Validation loss: 1.6134554621993855

Epoch: 5| Step: 6
Training loss: 0.6738283634185791
Validation loss: 1.6283290886109876

Epoch: 5| Step: 7
Training loss: 0.2678714990615845
Validation loss: 1.6362492012721237

Epoch: 5| Step: 8
Training loss: 0.3143908977508545
Validation loss: 1.6441756051073793

Epoch: 5| Step: 9
Training loss: 0.2282722443342209
Validation loss: 1.619386495441519

Epoch: 5| Step: 10
Training loss: 0.35407641530036926
Validation loss: 1.6388750037839335

Epoch: 304| Step: 0
Training loss: 0.32323580980300903
Validation loss: 1.6280582515142297

Epoch: 5| Step: 1
Training loss: 0.24786636233329773
Validation loss: 1.6335797694421583

Epoch: 5| Step: 2
Training loss: 0.5270757675170898
Validation loss: 1.6155825340619652

Epoch: 5| Step: 3
Training loss: 0.3676019310951233
Validation loss: 1.664800154265537

Epoch: 5| Step: 4
Training loss: 0.26784634590148926
Validation loss: 1.6793228554469284

Epoch: 5| Step: 5
Training loss: 0.37633588910102844
Validation loss: 1.6889614341079549

Epoch: 5| Step: 6
Training loss: 0.2551724314689636
Validation loss: 1.6685136466897943

Epoch: 5| Step: 7
Training loss: 0.31934887170791626
Validation loss: 1.6553498750091882

Epoch: 5| Step: 8
Training loss: 0.30893537402153015
Validation loss: 1.6430468225991854

Epoch: 5| Step: 9
Training loss: 0.36946454644203186
Validation loss: 1.6169185510245703

Epoch: 5| Step: 10
Training loss: 0.25044235587120056
Validation loss: 1.6557080643151396

Epoch: 305| Step: 0
Training loss: 0.5999014973640442
Validation loss: 1.6568715264720302

Epoch: 5| Step: 1
Training loss: 0.2941766679286957
Validation loss: 1.6765074319736932

Epoch: 5| Step: 2
Training loss: 0.19684159755706787
Validation loss: 1.643112910691128

Epoch: 5| Step: 3
Training loss: 0.2885194420814514
Validation loss: 1.582437769059212

Epoch: 5| Step: 4
Training loss: 0.3584573268890381
Validation loss: 1.5731617225113737

Epoch: 5| Step: 5
Training loss: 0.2972177565097809
Validation loss: 1.5500737954211492

Epoch: 5| Step: 6
Training loss: 0.5607129335403442
Validation loss: 1.544888041352713

Epoch: 5| Step: 7
Training loss: 0.2973986566066742
Validation loss: 1.5876321651602303

Epoch: 5| Step: 8
Training loss: 0.350020170211792
Validation loss: 1.5966436055398756

Epoch: 5| Step: 9
Training loss: 0.27179643511772156
Validation loss: 1.6491463735539427

Epoch: 5| Step: 10
Training loss: 0.14876095950603485
Validation loss: 1.6641176810828588

Epoch: 306| Step: 0
Training loss: 0.3857158124446869
Validation loss: 1.7091799038712696

Epoch: 5| Step: 1
Training loss: 0.31343874335289
Validation loss: 1.7300135621460535

Epoch: 5| Step: 2
Training loss: 0.22634831070899963
Validation loss: 1.7141600821607856

Epoch: 5| Step: 3
Training loss: 0.2797001004219055
Validation loss: 1.6564432703038698

Epoch: 5| Step: 4
Training loss: 0.26578766107559204
Validation loss: 1.6457834653956915

Epoch: 5| Step: 5
Training loss: 0.26659122109413147
Validation loss: 1.613226072121692

Epoch: 5| Step: 6
Training loss: 0.42177677154541016
Validation loss: 1.603203950389739

Epoch: 5| Step: 7
Training loss: 0.4659537672996521
Validation loss: 1.6005759534015451

Epoch: 5| Step: 8
Training loss: 0.28009873628616333
Validation loss: 1.610767746484408

Epoch: 5| Step: 9
Training loss: 0.36075299978256226
Validation loss: 1.6235540630996868

Epoch: 5| Step: 10
Training loss: 0.24297955632209778
Validation loss: 1.6669977198364914

Epoch: 307| Step: 0
Training loss: 0.27254602313041687
Validation loss: 1.639419073699623

Epoch: 5| Step: 1
Training loss: 0.5399013757705688
Validation loss: 1.6187931920892449

Epoch: 5| Step: 2
Training loss: 0.28328830003738403
Validation loss: 1.600677647898274

Epoch: 5| Step: 3
Training loss: 0.3630695939064026
Validation loss: 1.562500640910159

Epoch: 5| Step: 4
Training loss: 0.4559091031551361
Validation loss: 1.5587864575847503

Epoch: 5| Step: 5
Training loss: 0.19806252419948578
Validation loss: 1.5864219742436563

Epoch: 5| Step: 6
Training loss: 0.2950480282306671
Validation loss: 1.5953919413269206

Epoch: 5| Step: 7
Training loss: 0.3189204931259155
Validation loss: 1.5960957657906316

Epoch: 5| Step: 8
Training loss: 0.22191710770130157
Validation loss: 1.6100520401872613

Epoch: 5| Step: 9
Training loss: 0.23825636506080627
Validation loss: 1.6363742441259406

Epoch: 5| Step: 10
Training loss: 0.23003645241260529
Validation loss: 1.6632750854697278

Epoch: 308| Step: 0
Training loss: 0.1978316307067871
Validation loss: 1.6641929303446124

Epoch: 5| Step: 1
Training loss: 0.2185043841600418
Validation loss: 1.6540875268238846

Epoch: 5| Step: 2
Training loss: 0.28884953260421753
Validation loss: 1.6304065219817623

Epoch: 5| Step: 3
Training loss: 0.36645248532295227
Validation loss: 1.6296097706722956

Epoch: 5| Step: 4
Training loss: 0.3188931941986084
Validation loss: 1.583190603922772

Epoch: 5| Step: 5
Training loss: 0.15034829080104828
Validation loss: 1.6034474757409864

Epoch: 5| Step: 6
Training loss: 0.13460297882556915
Validation loss: 1.5866757400574223

Epoch: 5| Step: 7
Training loss: 0.4579905867576599
Validation loss: 1.5968558032025573

Epoch: 5| Step: 8
Training loss: 0.40749025344848633
Validation loss: 1.6166026489709013

Epoch: 5| Step: 9
Training loss: 0.3380919396877289
Validation loss: 1.6206602640049432

Epoch: 5| Step: 10
Training loss: 0.346569299697876
Validation loss: 1.5762258313035453

Epoch: 309| Step: 0
Training loss: 0.4724394679069519
Validation loss: 1.5592780930380667

Epoch: 5| Step: 1
Training loss: 0.23864150047302246
Validation loss: 1.5142978314430482

Epoch: 5| Step: 2
Training loss: 0.3585299849510193
Validation loss: 1.5000932037189443

Epoch: 5| Step: 3
Training loss: 0.4380296766757965
Validation loss: 1.5126475108567106

Epoch: 5| Step: 4
Training loss: 0.20171506702899933
Validation loss: 1.5172476697993535

Epoch: 5| Step: 5
Training loss: 0.2730092704296112
Validation loss: 1.5245339614088818

Epoch: 5| Step: 6
Training loss: 0.3077157139778137
Validation loss: 1.5755796919586837

Epoch: 5| Step: 7
Training loss: 0.2952820658683777
Validation loss: 1.624498882601338

Epoch: 5| Step: 8
Training loss: 0.3989957869052887
Validation loss: 1.616913777525707

Epoch: 5| Step: 9
Training loss: 0.4142570495605469
Validation loss: 1.6462168937088342

Epoch: 5| Step: 10
Training loss: 0.1587713211774826
Validation loss: 1.6070640894674486

Epoch: 310| Step: 0
Training loss: 0.26191097497940063
Validation loss: 1.5928387859816193

Epoch: 5| Step: 1
Training loss: 0.36814194917678833
Validation loss: 1.5491991171272852

Epoch: 5| Step: 2
Training loss: 0.6555468440055847
Validation loss: 1.5804430925717918

Epoch: 5| Step: 3
Training loss: 0.2499796450138092
Validation loss: 1.5734222012181436

Epoch: 5| Step: 4
Training loss: 0.20883576571941376
Validation loss: 1.589961322405005

Epoch: 5| Step: 5
Training loss: 0.4363486170768738
Validation loss: 1.6074115460918796

Epoch: 5| Step: 6
Training loss: 0.3524736762046814
Validation loss: 1.6144202704070716

Epoch: 5| Step: 7
Training loss: 0.2730145752429962
Validation loss: 1.5947628495513753

Epoch: 5| Step: 8
Training loss: 0.30954939126968384
Validation loss: 1.5583196275977678

Epoch: 5| Step: 9
Training loss: 0.31974104046821594
Validation loss: 1.5455418889240553

Epoch: 5| Step: 10
Training loss: 0.1265837401151657
Validation loss: 1.5480337655672463

Epoch: 311| Step: 0
Training loss: 0.20624200999736786
Validation loss: 1.5771889276401971

Epoch: 5| Step: 1
Training loss: 0.5685702562332153
Validation loss: 1.5716722806294758

Epoch: 5| Step: 2
Training loss: 0.36261802911758423
Validation loss: 1.6130642929384786

Epoch: 5| Step: 3
Training loss: 0.270681768655777
Validation loss: 1.6443082927375712

Epoch: 5| Step: 4
Training loss: 0.44377580285072327
Validation loss: 1.6682066673873572

Epoch: 5| Step: 5
Training loss: 0.19034293293952942
Validation loss: 1.6658979769675963

Epoch: 5| Step: 6
Training loss: 0.28283169865608215
Validation loss: 1.6651509884865052

Epoch: 5| Step: 7
Training loss: 0.3221946358680725
Validation loss: 1.681052593774693

Epoch: 5| Step: 8
Training loss: 0.12630897760391235
Validation loss: 1.6627714864669307

Epoch: 5| Step: 9
Training loss: 0.20903006196022034
Validation loss: 1.6568495701718073

Epoch: 5| Step: 10
Training loss: 0.20746786892414093
Validation loss: 1.6407161220427482

Epoch: 312| Step: 0
Training loss: 0.3248943090438843
Validation loss: 1.6480649991702008

Epoch: 5| Step: 1
Training loss: 0.19769397377967834
Validation loss: 1.6375040149175992

Epoch: 5| Step: 2
Training loss: 0.33919256925582886
Validation loss: 1.61780075616734

Epoch: 5| Step: 3
Training loss: 0.49239712953567505
Validation loss: 1.6116435899529407

Epoch: 5| Step: 4
Training loss: 0.40414419770240784
Validation loss: 1.6411738511054748

Epoch: 5| Step: 5
Training loss: 0.24258127808570862
Validation loss: 1.6411433450637325

Epoch: 5| Step: 6
Training loss: 0.3701428771018982
Validation loss: 1.6545039171813636

Epoch: 5| Step: 7
Training loss: 0.19087715446949005
Validation loss: 1.6493213971455891

Epoch: 5| Step: 8
Training loss: 0.20321862399578094
Validation loss: 1.6272274922299128

Epoch: 5| Step: 9
Training loss: 0.26899653673171997
Validation loss: 1.6150331881738478

Epoch: 5| Step: 10
Training loss: 0.2619328498840332
Validation loss: 1.5826137899070658

Epoch: 313| Step: 0
Training loss: 0.15377072989940643
Validation loss: 1.5821429542315903

Epoch: 5| Step: 1
Training loss: 0.28446176648139954
Validation loss: 1.6121614492067726

Epoch: 5| Step: 2
Training loss: 0.32798391580581665
Validation loss: 1.5911013208409792

Epoch: 5| Step: 3
Training loss: 0.14231380820274353
Validation loss: 1.6092223685274842

Epoch: 5| Step: 4
Training loss: 0.2634282410144806
Validation loss: 1.6070786471007972

Epoch: 5| Step: 5
Training loss: 0.459829717874527
Validation loss: 1.61482330547866

Epoch: 5| Step: 6
Training loss: 0.2404506653547287
Validation loss: 1.6122985392488458

Epoch: 5| Step: 7
Training loss: 0.4522094130516052
Validation loss: 1.6186762522625666

Epoch: 5| Step: 8
Training loss: 0.4509977698326111
Validation loss: 1.5917429334373885

Epoch: 5| Step: 9
Training loss: 0.22565534710884094
Validation loss: 1.5646148330421858

Epoch: 5| Step: 10
Training loss: 0.186514750123024
Validation loss: 1.5574553525576027

Epoch: 314| Step: 0
Training loss: 0.2380983829498291
Validation loss: 1.562427096469428

Epoch: 5| Step: 1
Training loss: 0.2114732265472412
Validation loss: 1.5732124223504016

Epoch: 5| Step: 2
Training loss: 0.32758229970932007
Validation loss: 1.6100808548670944

Epoch: 5| Step: 3
Training loss: 0.21160702407360077
Validation loss: 1.668021766088342

Epoch: 5| Step: 4
Training loss: 0.24551424384117126
Validation loss: 1.682056160383327

Epoch: 5| Step: 5
Training loss: 0.28800129890441895
Validation loss: 1.6454800251991517

Epoch: 5| Step: 6
Training loss: 0.30112123489379883
Validation loss: 1.6119779130463958

Epoch: 5| Step: 7
Training loss: 0.1775105893611908
Validation loss: 1.6442902408620363

Epoch: 5| Step: 8
Training loss: 0.4232215881347656
Validation loss: 1.6629853261414396

Epoch: 5| Step: 9
Training loss: 0.31458714604377747
Validation loss: 1.6374133786847513

Epoch: 5| Step: 10
Training loss: 0.5006245374679565
Validation loss: 1.6556689905863937

Epoch: 315| Step: 0
Training loss: 0.2886422574520111
Validation loss: 1.6514956694777294

Epoch: 5| Step: 1
Training loss: 0.22032460570335388
Validation loss: 1.6191125941532913

Epoch: 5| Step: 2
Training loss: 0.30662545561790466
Validation loss: 1.6081340601367335

Epoch: 5| Step: 3
Training loss: 0.2376747876405716
Validation loss: 1.590310396686677

Epoch: 5| Step: 4
Training loss: 0.26268714666366577
Validation loss: 1.5704416562152166

Epoch: 5| Step: 5
Training loss: 0.5510390996932983
Validation loss: 1.5811032864355272

Epoch: 5| Step: 6
Training loss: 0.252683162689209
Validation loss: 1.5535599903393817

Epoch: 5| Step: 7
Training loss: 0.1947236806154251
Validation loss: 1.545171413370358

Epoch: 5| Step: 8
Training loss: 0.3442595601081848
Validation loss: 1.584394463928797

Epoch: 5| Step: 9
Training loss: 0.1922570765018463
Validation loss: 1.5771523573065316

Epoch: 5| Step: 10
Training loss: 0.25683295726776123
Validation loss: 1.5898184955760997

Epoch: 316| Step: 0
Training loss: 0.41756677627563477
Validation loss: 1.6133771455416115

Epoch: 5| Step: 1
Training loss: 0.36320316791534424
Validation loss: 1.6195292357475526

Epoch: 5| Step: 2
Training loss: 0.27392372488975525
Validation loss: 1.6119800421499437

Epoch: 5| Step: 3
Training loss: 0.25852662324905396
Validation loss: 1.6211314009081932

Epoch: 5| Step: 4
Training loss: 0.32053712010383606
Validation loss: 1.6407724913730417

Epoch: 5| Step: 5
Training loss: 0.2615068554878235
Validation loss: 1.64583158493042

Epoch: 5| Step: 6
Training loss: 0.30889397859573364
Validation loss: 1.6449780041171658

Epoch: 5| Step: 7
Training loss: 0.32530564069747925
Validation loss: 1.6753826115721016

Epoch: 5| Step: 8
Training loss: 0.17798683047294617
Validation loss: 1.6380181722743536

Epoch: 5| Step: 9
Training loss: 0.20588478446006775
Validation loss: 1.627396406665925

Epoch: 5| Step: 10
Training loss: 0.27283501625061035
Validation loss: 1.616774457757191

Epoch: 317| Step: 0
Training loss: 0.32628703117370605
Validation loss: 1.6127810734574513

Epoch: 5| Step: 1
Training loss: 0.1398516595363617
Validation loss: 1.5972004090586016

Epoch: 5| Step: 2
Training loss: 0.2863306403160095
Validation loss: 1.575609576317572

Epoch: 5| Step: 3
Training loss: 0.18250413239002228
Validation loss: 1.5782270431518555

Epoch: 5| Step: 4
Training loss: 0.2554560601711273
Validation loss: 1.5522478626620384

Epoch: 5| Step: 5
Training loss: 0.20518441498279572
Validation loss: 1.5227410562576786

Epoch: 5| Step: 6
Training loss: 0.575835108757019
Validation loss: 1.537265314850756

Epoch: 5| Step: 7
Training loss: 0.44886988401412964
Validation loss: 1.5437079334771762

Epoch: 5| Step: 8
Training loss: 0.24732618033885956
Validation loss: 1.5879901942386423

Epoch: 5| Step: 9
Training loss: 0.22181668877601624
Validation loss: 1.6187424993002286

Epoch: 5| Step: 10
Training loss: 0.16364304721355438
Validation loss: 1.6787914614523611

Epoch: 318| Step: 0
Training loss: 0.34512123465538025
Validation loss: 1.7092307280468684

Epoch: 5| Step: 1
Training loss: 0.32644668221473694
Validation loss: 1.6851538996542654

Epoch: 5| Step: 2
Training loss: 0.2704651951789856
Validation loss: 1.649946661405666

Epoch: 5| Step: 3
Training loss: 0.24984166026115417
Validation loss: 1.6186807335063975

Epoch: 5| Step: 4
Training loss: 0.24326837062835693
Validation loss: 1.5737536799523137

Epoch: 5| Step: 5
Training loss: 0.26669517159461975
Validation loss: 1.5834249988678963

Epoch: 5| Step: 6
Training loss: 0.4437657296657562
Validation loss: 1.583118288747726

Epoch: 5| Step: 7
Training loss: 0.2137337028980255
Validation loss: 1.5708672936244676

Epoch: 5| Step: 8
Training loss: 0.2521370053291321
Validation loss: 1.5948042677294823

Epoch: 5| Step: 9
Training loss: 0.3507109582424164
Validation loss: 1.6250436639273038

Epoch: 5| Step: 10
Training loss: 0.1428517997264862
Validation loss: 1.6250767413006033

Epoch: 319| Step: 0
Training loss: 0.19269202649593353
Validation loss: 1.5978887593874367

Epoch: 5| Step: 1
Training loss: 0.26935267448425293
Validation loss: 1.6089246401222803

Epoch: 5| Step: 2
Training loss: 0.2786611318588257
Validation loss: 1.5899200003634217

Epoch: 5| Step: 3
Training loss: 0.18545499444007874
Validation loss: 1.5944454631497782

Epoch: 5| Step: 4
Training loss: 0.12944987416267395
Validation loss: 1.597164116879945

Epoch: 5| Step: 5
Training loss: 0.254716694355011
Validation loss: 1.5706129791916057

Epoch: 5| Step: 6
Training loss: 0.23550362884998322
Validation loss: 1.5937447855549474

Epoch: 5| Step: 7
Training loss: 0.2765777111053467
Validation loss: 1.6130290826161702

Epoch: 5| Step: 8
Training loss: 0.31249523162841797
Validation loss: 1.6552661747060797

Epoch: 5| Step: 9
Training loss: 0.3040330111980438
Validation loss: 1.6952947929341307

Epoch: 5| Step: 10
Training loss: 0.6299402713775635
Validation loss: 1.6742854784893733

Epoch: 320| Step: 0
Training loss: 0.31909242272377014
Validation loss: 1.6209792373000935

Epoch: 5| Step: 1
Training loss: 0.4091634154319763
Validation loss: 1.5998132933852494

Epoch: 5| Step: 2
Training loss: 0.29238685965538025
Validation loss: 1.5610045194625854

Epoch: 5| Step: 3
Training loss: 0.22005435824394226
Validation loss: 1.556903410983342

Epoch: 5| Step: 4
Training loss: 0.4680010676383972
Validation loss: 1.5502040565654795

Epoch: 5| Step: 5
Training loss: 0.1737445890903473
Validation loss: 1.5734079691671556

Epoch: 5| Step: 6
Training loss: 0.3921205699443817
Validation loss: 1.5990398122418312

Epoch: 5| Step: 7
Training loss: 0.19721485674381256
Validation loss: 1.6448248176164524

Epoch: 5| Step: 8
Training loss: 0.2264041006565094
Validation loss: 1.6684637646521292

Epoch: 5| Step: 9
Training loss: 0.22571492195129395
Validation loss: 1.6869905738420383

Epoch: 5| Step: 10
Training loss: 0.25741833448410034
Validation loss: 1.683985948562622

Epoch: 321| Step: 0
Training loss: 0.5503264665603638
Validation loss: 1.6539841928789694

Epoch: 5| Step: 1
Training loss: 0.13898470997810364
Validation loss: 1.6168340829110914

Epoch: 5| Step: 2
Training loss: 0.2632843554019928
Validation loss: 1.6106373071670532

Epoch: 5| Step: 3
Training loss: 0.10909824073314667
Validation loss: 1.5694147438131354

Epoch: 5| Step: 4
Training loss: 0.24421779811382294
Validation loss: 1.612686393081501

Epoch: 5| Step: 5
Training loss: 0.22048771381378174
Validation loss: 1.6092151339336107

Epoch: 5| Step: 6
Training loss: 0.33069154620170593
Validation loss: 1.6106761963136735

Epoch: 5| Step: 7
Training loss: 0.259662389755249
Validation loss: 1.6471401209472327

Epoch: 5| Step: 8
Training loss: 0.250550240278244
Validation loss: 1.6490452892036849

Epoch: 5| Step: 9
Training loss: 0.2951146066188812
Validation loss: 1.649338767092715

Epoch: 5| Step: 10
Training loss: 0.3706818222999573
Validation loss: 1.6308950660049275

Epoch: 322| Step: 0
Training loss: 0.2600530683994293
Validation loss: 1.601281823650483

Epoch: 5| Step: 1
Training loss: 0.19743433594703674
Validation loss: 1.5992880617418597

Epoch: 5| Step: 2
Training loss: 0.164201021194458
Validation loss: 1.5748051366498392

Epoch: 5| Step: 3
Training loss: 0.46185392141342163
Validation loss: 1.5671658541566582

Epoch: 5| Step: 4
Training loss: 0.1793004274368286
Validation loss: 1.5602135030172204

Epoch: 5| Step: 5
Training loss: 0.2912755310535431
Validation loss: 1.5718929972699893

Epoch: 5| Step: 6
Training loss: 0.2704277038574219
Validation loss: 1.565384550761151

Epoch: 5| Step: 7
Training loss: 0.24316361546516418
Validation loss: 1.5905183976696384

Epoch: 5| Step: 8
Training loss: 0.21900597214698792
Validation loss: 1.6273821553876322

Epoch: 5| Step: 9
Training loss: 0.4022243618965149
Validation loss: 1.6262318459890222

Epoch: 5| Step: 10
Training loss: 0.1313953548669815
Validation loss: 1.6493279139200847

Epoch: 323| Step: 0
Training loss: 0.3754892945289612
Validation loss: 1.6600657932219967

Epoch: 5| Step: 1
Training loss: 0.14997684955596924
Validation loss: 1.6509616759515577

Epoch: 5| Step: 2
Training loss: 0.3224189281463623
Validation loss: 1.6159552848467262

Epoch: 5| Step: 3
Training loss: 0.18945583701133728
Validation loss: 1.5809790203648229

Epoch: 5| Step: 4
Training loss: 0.2458386868238449
Validation loss: 1.5921698257487307

Epoch: 5| Step: 5
Training loss: 0.44621482491493225
Validation loss: 1.556611454615029

Epoch: 5| Step: 6
Training loss: 0.3031490743160248
Validation loss: 1.5651327512597526

Epoch: 5| Step: 7
Training loss: 0.2525174617767334
Validation loss: 1.5777393118027718

Epoch: 5| Step: 8
Training loss: 0.3668826222419739
Validation loss: 1.6129938428119948

Epoch: 5| Step: 9
Training loss: 0.22936058044433594
Validation loss: 1.5936581921833817

Epoch: 5| Step: 10
Training loss: 0.08545731008052826
Validation loss: 1.5973370626408567

Epoch: 324| Step: 0
Training loss: 0.13781675696372986
Validation loss: 1.5956569845958422

Epoch: 5| Step: 1
Training loss: 0.5739986300468445
Validation loss: 1.6189748881965556

Epoch: 5| Step: 2
Training loss: 0.2883755564689636
Validation loss: 1.608427288711712

Epoch: 5| Step: 3
Training loss: 0.34950751066207886
Validation loss: 1.6228841517561226

Epoch: 5| Step: 4
Training loss: 0.1911931186914444
Validation loss: 1.5760281880696614

Epoch: 5| Step: 5
Training loss: 0.2375071942806244
Validation loss: 1.5764826510542183

Epoch: 5| Step: 6
Training loss: 0.13504305481910706
Validation loss: 1.586638210922159

Epoch: 5| Step: 7
Training loss: 0.2388453483581543
Validation loss: 1.6000521977742512

Epoch: 5| Step: 8
Training loss: 0.3211093544960022
Validation loss: 1.63606353985366

Epoch: 5| Step: 9
Training loss: 0.32175007462501526
Validation loss: 1.6765214076606176

Epoch: 5| Step: 10
Training loss: 0.2612546980381012
Validation loss: 1.6577745291494554

Epoch: 325| Step: 0
Training loss: 0.20770561695098877
Validation loss: 1.5743693331236481

Epoch: 5| Step: 1
Training loss: 0.20680037140846252
Validation loss: 1.5811973579468266

Epoch: 5| Step: 2
Training loss: 0.1945359706878662
Validation loss: 1.5396829561520649

Epoch: 5| Step: 3
Training loss: 0.27641868591308594
Validation loss: 1.514995865924384

Epoch: 5| Step: 4
Training loss: 0.14002326130867004
Validation loss: 1.52909073522014

Epoch: 5| Step: 5
Training loss: 0.3092499375343323
Validation loss: 1.5276886352928736

Epoch: 5| Step: 6
Training loss: 0.36490774154663086
Validation loss: 1.5266201009032547

Epoch: 5| Step: 7
Training loss: 0.11916180700063705
Validation loss: 1.5561397729381439

Epoch: 5| Step: 8
Training loss: 0.4050627648830414
Validation loss: 1.5815564470906411

Epoch: 5| Step: 9
Training loss: 0.3674289584159851
Validation loss: 1.5891803605582124

Epoch: 5| Step: 10
Training loss: 0.31551221013069153
Validation loss: 1.5928022194934148

Epoch: 326| Step: 0
Training loss: 0.24005575478076935
Validation loss: 1.5607264336719309

Epoch: 5| Step: 1
Training loss: 0.22554583847522736
Validation loss: 1.5598613369849421

Epoch: 5| Step: 2
Training loss: 0.16375096142292023
Validation loss: 1.558558011567721

Epoch: 5| Step: 3
Training loss: 0.30468904972076416
Validation loss: 1.5371502394317298

Epoch: 5| Step: 4
Training loss: 0.2887272536754608
Validation loss: 1.5415991121722805

Epoch: 5| Step: 5
Training loss: 0.15985830128192902
Validation loss: 1.5486391564851165

Epoch: 5| Step: 6
Training loss: 0.2905697226524353
Validation loss: 1.551583101672511

Epoch: 5| Step: 7
Training loss: 0.4290984272956848
Validation loss: 1.6294915804298975

Epoch: 5| Step: 8
Training loss: 0.4091378152370453
Validation loss: 1.6331132067147123

Epoch: 5| Step: 9
Training loss: 0.3384975492954254
Validation loss: 1.6394268133307015

Epoch: 5| Step: 10
Training loss: 0.1828509420156479
Validation loss: 1.6283147681143977

Epoch: 327| Step: 0
Training loss: 0.11563446372747421
Validation loss: 1.5845498807968632

Epoch: 5| Step: 1
Training loss: 0.276721328496933
Validation loss: 1.628079814295615

Epoch: 5| Step: 2
Training loss: 0.4220566153526306
Validation loss: 1.614001121572269

Epoch: 5| Step: 3
Training loss: 0.4527726173400879
Validation loss: 1.6574401496559061

Epoch: 5| Step: 4
Training loss: 0.24852414429187775
Validation loss: 1.642590615057176

Epoch: 5| Step: 5
Training loss: 0.19011199474334717
Validation loss: 1.667481630079208

Epoch: 5| Step: 6
Training loss: 0.2909291684627533
Validation loss: 1.6788517723801315

Epoch: 5| Step: 7
Training loss: 0.26716047525405884
Validation loss: 1.6309702447665635

Epoch: 5| Step: 8
Training loss: 0.2465018481016159
Validation loss: 1.6390290003950878

Epoch: 5| Step: 9
Training loss: 0.29910266399383545
Validation loss: 1.6126278574748705

Epoch: 5| Step: 10
Training loss: 0.24310404062271118
Validation loss: 1.5779498238717355

Epoch: 328| Step: 0
Training loss: 0.2804293632507324
Validation loss: 1.6036605014595935

Epoch: 5| Step: 1
Training loss: 0.36721402406692505
Validation loss: 1.6192626799306562

Epoch: 5| Step: 2
Training loss: 0.38718873262405396
Validation loss: 1.667084716981457

Epoch: 5| Step: 3
Training loss: 0.23352515697479248
Validation loss: 1.6181343499050345

Epoch: 5| Step: 4
Training loss: 0.3490760028362274
Validation loss: 1.662553817995133

Epoch: 5| Step: 5
Training loss: 0.22367405891418457
Validation loss: 1.6857859473074637

Epoch: 5| Step: 6
Training loss: 0.25241702795028687
Validation loss: 1.6861345729520243

Epoch: 5| Step: 7
Training loss: 0.24257402122020721
Validation loss: 1.658579646900136

Epoch: 5| Step: 8
Training loss: 0.21036680042743683
Validation loss: 1.646747136628756

Epoch: 5| Step: 9
Training loss: 0.13487093150615692
Validation loss: 1.6145547782221148

Epoch: 5| Step: 10
Training loss: 0.3414531648159027
Validation loss: 1.591057296722166

Epoch: 329| Step: 0
Training loss: 0.2200622856616974
Validation loss: 1.5761194671353986

Epoch: 5| Step: 1
Training loss: 0.30438441038131714
Validation loss: 1.5537744760513306

Epoch: 5| Step: 2
Training loss: 0.35647812485694885
Validation loss: 1.5326694980744393

Epoch: 5| Step: 3
Training loss: 0.1713673323392868
Validation loss: 1.5632141238899642

Epoch: 5| Step: 4
Training loss: 0.12698021531105042
Validation loss: 1.5751133093269922

Epoch: 5| Step: 5
Training loss: 0.17408542335033417
Validation loss: 1.5905218073116836

Epoch: 5| Step: 6
Training loss: 0.2686536908149719
Validation loss: 1.5883550592648086

Epoch: 5| Step: 7
Training loss: 0.2709609866142273
Validation loss: 1.6091773727888703

Epoch: 5| Step: 8
Training loss: 0.15586625039577484
Validation loss: 1.6396590766086374

Epoch: 5| Step: 9
Training loss: 0.21076419949531555
Validation loss: 1.636492488204792

Epoch: 5| Step: 10
Training loss: 0.5580052733421326
Validation loss: 1.644389162781418

Epoch: 330| Step: 0
Training loss: 0.2294788658618927
Validation loss: 1.6494919689752723

Epoch: 5| Step: 1
Training loss: 0.25047826766967773
Validation loss: 1.6445280941583778

Epoch: 5| Step: 2
Training loss: 0.2044452428817749
Validation loss: 1.6322951304015292

Epoch: 5| Step: 3
Training loss: 0.26664167642593384
Validation loss: 1.6430895930977278

Epoch: 5| Step: 4
Training loss: 0.30985453724861145
Validation loss: 1.640758102939975

Epoch: 5| Step: 5
Training loss: 0.25813156366348267
Validation loss: 1.6372848505614905

Epoch: 5| Step: 6
Training loss: 0.4165331721305847
Validation loss: 1.6204631085036902

Epoch: 5| Step: 7
Training loss: 0.20796439051628113
Validation loss: 1.5769908056464246

Epoch: 5| Step: 8
Training loss: 0.2548207640647888
Validation loss: 1.5788398635002874

Epoch: 5| Step: 9
Training loss: 0.19617612659931183
Validation loss: 1.5809753466677923

Epoch: 5| Step: 10
Training loss: 0.24082285165786743
Validation loss: 1.557304088146456

Epoch: 331| Step: 0
Training loss: 0.17133666574954987
Validation loss: 1.5403417989771853

Epoch: 5| Step: 1
Training loss: 0.17614327371120453
Validation loss: 1.5548655666330808

Epoch: 5| Step: 2
Training loss: 0.1300862580537796
Validation loss: 1.5677257481441702

Epoch: 5| Step: 3
Training loss: 0.22663059830665588
Validation loss: 1.576404502314906

Epoch: 5| Step: 4
Training loss: 0.17218758165836334
Validation loss: 1.5844534212543118

Epoch: 5| Step: 5
Training loss: 0.29680919647216797
Validation loss: 1.6001515183397519

Epoch: 5| Step: 6
Training loss: 0.14110465347766876
Validation loss: 1.6105505369042838

Epoch: 5| Step: 7
Training loss: 0.265485018491745
Validation loss: 1.6190001810750654

Epoch: 5| Step: 8
Training loss: 0.14502398669719696
Validation loss: 1.6107058576358262

Epoch: 5| Step: 9
Training loss: 0.3635108172893524
Validation loss: 1.596852675560982

Epoch: 5| Step: 10
Training loss: 0.6058497428894043
Validation loss: 1.6044953189870363

Epoch: 332| Step: 0
Training loss: 0.29618364572525024
Validation loss: 1.6357263275372085

Epoch: 5| Step: 1
Training loss: 0.18631789088249207
Validation loss: 1.6449391726524598

Epoch: 5| Step: 2
Training loss: 0.22590680420398712
Validation loss: 1.647707119423856

Epoch: 5| Step: 3
Training loss: 0.3003601133823395
Validation loss: 1.650183553336769

Epoch: 5| Step: 4
Training loss: 0.2679821848869324
Validation loss: 1.6185096374122045

Epoch: 5| Step: 5
Training loss: 0.19607602059841156
Validation loss: 1.602455767252112

Epoch: 5| Step: 6
Training loss: 0.3659472167491913
Validation loss: 1.6247774260018462

Epoch: 5| Step: 7
Training loss: 0.2990281581878662
Validation loss: 1.6078751997281147

Epoch: 5| Step: 8
Training loss: 0.2545252740383148
Validation loss: 1.584848682085673

Epoch: 5| Step: 9
Training loss: 0.1801917999982834
Validation loss: 1.5901654843361146

Epoch: 5| Step: 10
Training loss: 0.2013673186302185
Validation loss: 1.6047252378156107

Epoch: 333| Step: 0
Training loss: 0.322740375995636
Validation loss: 1.5746213704027154

Epoch: 5| Step: 1
Training loss: 0.1887768805027008
Validation loss: 1.5676806613963137

Epoch: 5| Step: 2
Training loss: 0.26063817739486694
Validation loss: 1.5966197406091998

Epoch: 5| Step: 3
Training loss: 0.1751416176557541
Validation loss: 1.6047143525974725

Epoch: 5| Step: 4
Training loss: 0.34517985582351685
Validation loss: 1.6168513195489043

Epoch: 5| Step: 5
Training loss: 0.17221790552139282
Validation loss: 1.6186434299715105

Epoch: 5| Step: 6
Training loss: 0.1979110836982727
Validation loss: 1.6349436852239794

Epoch: 5| Step: 7
Training loss: 0.2492278516292572
Validation loss: 1.6331549434251682

Epoch: 5| Step: 8
Training loss: 0.18976953625679016
Validation loss: 1.6639177991497902

Epoch: 5| Step: 9
Training loss: 0.15027406811714172
Validation loss: 1.6282522242556337

Epoch: 5| Step: 10
Training loss: 0.2943252623081207
Validation loss: 1.5885602530612741

Epoch: 334| Step: 0
Training loss: 0.1858053207397461
Validation loss: 1.5713740728234733

Epoch: 5| Step: 1
Training loss: 0.25739946961402893
Validation loss: 1.568671537983802

Epoch: 5| Step: 2
Training loss: 0.17656151950359344
Validation loss: 1.5799798362998552

Epoch: 5| Step: 3
Training loss: 0.2105182707309723
Validation loss: 1.5957671237248245

Epoch: 5| Step: 4
Training loss: 0.2331165373325348
Validation loss: 1.592903156434336

Epoch: 5| Step: 5
Training loss: 0.23984722793102264
Validation loss: 1.6038128432407175

Epoch: 5| Step: 6
Training loss: 0.40752965211868286
Validation loss: 1.5937417117498254

Epoch: 5| Step: 7
Training loss: 0.34081944823265076
Validation loss: 1.5984896780342184

Epoch: 5| Step: 8
Training loss: 0.1587737798690796
Validation loss: 1.627233406548859

Epoch: 5| Step: 9
Training loss: 0.22833871841430664
Validation loss: 1.5849786035476192

Epoch: 5| Step: 10
Training loss: 0.21008090674877167
Validation loss: 1.5939847769275788

Epoch: 335| Step: 0
Training loss: 0.16459113359451294
Validation loss: 1.6244340609478694

Epoch: 5| Step: 1
Training loss: 0.19865697622299194
Validation loss: 1.5755407432074189

Epoch: 5| Step: 2
Training loss: 0.25003933906555176
Validation loss: 1.578097672872646

Epoch: 5| Step: 3
Training loss: 0.2351323366165161
Validation loss: 1.5874343085032638

Epoch: 5| Step: 4
Training loss: 0.21955403685569763
Validation loss: 1.5966238494842284

Epoch: 5| Step: 5
Training loss: 0.24070651829242706
Validation loss: 1.6232554143474949

Epoch: 5| Step: 6
Training loss: 0.13028185069561005
Validation loss: 1.6103401023854491

Epoch: 5| Step: 7
Training loss: 0.23365013301372528
Validation loss: 1.60926123972862

Epoch: 5| Step: 8
Training loss: 0.4448183476924896
Validation loss: 1.592263178158832

Epoch: 5| Step: 9
Training loss: 0.2128438502550125
Validation loss: 1.6177946572662683

Epoch: 5| Step: 10
Training loss: 0.10946840047836304
Validation loss: 1.569787504852459

Epoch: 336| Step: 0
Training loss: 0.23567470908164978
Validation loss: 1.5500757745517197

Epoch: 5| Step: 1
Training loss: 0.39852529764175415
Validation loss: 1.5854525835283342

Epoch: 5| Step: 2
Training loss: 0.12066273391246796
Validation loss: 1.5862876574198406

Epoch: 5| Step: 3
Training loss: 0.22711119055747986
Validation loss: 1.6027658107460185

Epoch: 5| Step: 4
Training loss: 0.17839862406253815
Validation loss: 1.5864941676457722

Epoch: 5| Step: 5
Training loss: 0.27723008394241333
Validation loss: 1.5827225433882846

Epoch: 5| Step: 6
Training loss: 0.41962069272994995
Validation loss: 1.567931253422973

Epoch: 5| Step: 7
Training loss: 0.19307947158813477
Validation loss: 1.5651911715025544

Epoch: 5| Step: 8
Training loss: 0.21644215285778046
Validation loss: 1.5727424237035936

Epoch: 5| Step: 9
Training loss: 0.181045800447464
Validation loss: 1.5760359328280213

Epoch: 5| Step: 10
Training loss: 0.18185125291347504
Validation loss: 1.5871239528861096

Epoch: 337| Step: 0
Training loss: 0.29128798842430115
Validation loss: 1.6316022872924805

Epoch: 5| Step: 1
Training loss: 0.3876990079879761
Validation loss: 1.6336662596271885

Epoch: 5| Step: 2
Training loss: 0.1353067308664322
Validation loss: 1.6211083806971067

Epoch: 5| Step: 3
Training loss: 0.14589400589466095
Validation loss: 1.5919701809524207

Epoch: 5| Step: 4
Training loss: 0.21353153884410858
Validation loss: 1.59982100097082

Epoch: 5| Step: 5
Training loss: 0.1837264746427536
Validation loss: 1.5928287813740392

Epoch: 5| Step: 6
Training loss: 0.33775338530540466
Validation loss: 1.568222632972143

Epoch: 5| Step: 7
Training loss: 0.19748985767364502
Validation loss: 1.5533611800080986

Epoch: 5| Step: 8
Training loss: 0.2255690097808838
Validation loss: 1.5556010046312887

Epoch: 5| Step: 9
Training loss: 0.161553293466568
Validation loss: 1.5419499034522681

Epoch: 5| Step: 10
Training loss: 0.20754170417785645
Validation loss: 1.5502831730791318

Epoch: 338| Step: 0
Training loss: 0.13796024024486542
Validation loss: 1.559258960908459

Epoch: 5| Step: 1
Training loss: 0.25594136118888855
Validation loss: 1.5958151278957244

Epoch: 5| Step: 2
Training loss: 0.3242959678173065
Validation loss: 1.604616504843517

Epoch: 5| Step: 3
Training loss: 0.19658835232257843
Validation loss: 1.6041621238954606

Epoch: 5| Step: 4
Training loss: 0.20662948489189148
Validation loss: 1.6123273411104757

Epoch: 5| Step: 5
Training loss: 0.21141831576824188
Validation loss: 1.5873601199478231

Epoch: 5| Step: 6
Training loss: 0.1690499186515808
Validation loss: 1.596038503031577

Epoch: 5| Step: 7
Training loss: 0.16316702961921692
Validation loss: 1.55901082997681

Epoch: 5| Step: 8
Training loss: 0.31607404351234436
Validation loss: 1.575055028802605

Epoch: 5| Step: 9
Training loss: 0.23454079031944275
Validation loss: 1.5740951004848684

Epoch: 5| Step: 10
Training loss: 0.258767306804657
Validation loss: 1.567145537304622

Epoch: 339| Step: 0
Training loss: 0.18867479264736176
Validation loss: 1.6102015331227293

Epoch: 5| Step: 1
Training loss: 0.11367504298686981
Validation loss: 1.5959529466526483

Epoch: 5| Step: 2
Training loss: 0.22072315216064453
Validation loss: 1.6211416029161023

Epoch: 5| Step: 3
Training loss: 0.21392956376075745
Validation loss: 1.6164866057775353

Epoch: 5| Step: 4
Training loss: 0.34139901399612427
Validation loss: 1.6068751940163233

Epoch: 5| Step: 5
Training loss: 0.22540779411792755
Validation loss: 1.5840286401010328

Epoch: 5| Step: 6
Training loss: 0.1598242223262787
Validation loss: 1.56428123417721

Epoch: 5| Step: 7
Training loss: 0.23900337517261505
Validation loss: 1.5588833311552643

Epoch: 5| Step: 8
Training loss: 0.2435210645198822
Validation loss: 1.5732762813568115

Epoch: 5| Step: 9
Training loss: 0.2067399024963379
Validation loss: 1.550361096218068

Epoch: 5| Step: 10
Training loss: 0.2614462077617645
Validation loss: 1.5755760208252938

Epoch: 340| Step: 0
Training loss: 0.17474262416362762
Validation loss: 1.613620763824832

Epoch: 5| Step: 1
Training loss: 0.26427847146987915
Validation loss: 1.5905582917633878

Epoch: 5| Step: 2
Training loss: 0.1551496535539627
Validation loss: 1.582459315176933

Epoch: 5| Step: 3
Training loss: 0.07106931507587433
Validation loss: 1.5822523511866087

Epoch: 5| Step: 4
Training loss: 0.1965719759464264
Validation loss: 1.5741656211114698

Epoch: 5| Step: 5
Training loss: 0.35990458726882935
Validation loss: 1.5709340444175146

Epoch: 5| Step: 6
Training loss: 0.45406168699264526
Validation loss: 1.5873462333474109

Epoch: 5| Step: 7
Training loss: 0.14225688576698303
Validation loss: 1.6458663555883593

Epoch: 5| Step: 8
Training loss: 0.23648233711719513
Validation loss: 1.644628538880297

Epoch: 5| Step: 9
Training loss: 0.44598111510276794
Validation loss: 1.6547098467426915

Epoch: 5| Step: 10
Training loss: 0.32564353942871094
Validation loss: 1.6381207127724924

Epoch: 341| Step: 0
Training loss: 0.23595066368579865
Validation loss: 1.6006780555171352

Epoch: 5| Step: 1
Training loss: 0.4716463088989258
Validation loss: 1.582917494158591

Epoch: 5| Step: 2
Training loss: 0.1849515438079834
Validation loss: 1.5792934433106454

Epoch: 5| Step: 3
Training loss: 0.16110487282276154
Validation loss: 1.547059630834928

Epoch: 5| Step: 4
Training loss: 0.24903662502765656
Validation loss: 1.5641814329290902

Epoch: 5| Step: 5
Training loss: 0.15652993321418762
Validation loss: 1.56084055413482

Epoch: 5| Step: 6
Training loss: 0.18700240552425385
Validation loss: 1.5680496038929108

Epoch: 5| Step: 7
Training loss: 0.2997611165046692
Validation loss: 1.5805748995914255

Epoch: 5| Step: 8
Training loss: 0.15658751130104065
Validation loss: 1.5900736816467778

Epoch: 5| Step: 9
Training loss: 0.21879009902477264
Validation loss: 1.6209142567009054

Epoch: 5| Step: 10
Training loss: 0.20434144139289856
Validation loss: 1.604429195645035

Epoch: 342| Step: 0
Training loss: 0.11999684572219849
Validation loss: 1.5978620757338822

Epoch: 5| Step: 1
Training loss: 0.19049808382987976
Validation loss: 1.5761582953955537

Epoch: 5| Step: 2
Training loss: 0.3067939877510071
Validation loss: 1.5887952350801038

Epoch: 5| Step: 3
Training loss: 0.1970234364271164
Validation loss: 1.588759486393262

Epoch: 5| Step: 4
Training loss: 0.184157595038414
Validation loss: 1.6034866417607954

Epoch: 5| Step: 5
Training loss: 0.23115965723991394
Validation loss: 1.6006922593680761

Epoch: 5| Step: 6
Training loss: 0.2041764259338379
Validation loss: 1.6112084734824397

Epoch: 5| Step: 7
Training loss: 0.3561897873878479
Validation loss: 1.6266008333493305

Epoch: 5| Step: 8
Training loss: 0.221475288271904
Validation loss: 1.637411504663447

Epoch: 5| Step: 9
Training loss: 0.1993493139743805
Validation loss: 1.64585752384637

Epoch: 5| Step: 10
Training loss: 0.29997268319129944
Validation loss: 1.6466977609101163

Epoch: 343| Step: 0
Training loss: 0.23831012845039368
Validation loss: 1.6108112412114297

Epoch: 5| Step: 1
Training loss: 0.39415213465690613
Validation loss: 1.5905902206256826

Epoch: 5| Step: 2
Training loss: 0.1985321342945099
Validation loss: 1.5700604787436865

Epoch: 5| Step: 3
Training loss: 0.08879438787698746
Validation loss: 1.576252786062097

Epoch: 5| Step: 4
Training loss: 0.3174446225166321
Validation loss: 1.573898172506722

Epoch: 5| Step: 5
Training loss: 0.1414012759923935
Validation loss: 1.5647343281776673

Epoch: 5| Step: 6
Training loss: 0.26219791173934937
Validation loss: 1.5816372030524797

Epoch: 5| Step: 7
Training loss: 0.15733613073825836
Validation loss: 1.590198693736907

Epoch: 5| Step: 8
Training loss: 0.15953190624713898
Validation loss: 1.599800600800463

Epoch: 5| Step: 9
Training loss: 0.10208513587713242
Validation loss: 1.5852322578430176

Epoch: 5| Step: 10
Training loss: 0.24037329852581024
Validation loss: 1.6098924336894866

Epoch: 344| Step: 0
Training loss: 0.1751289665699005
Validation loss: 1.6126646072633806

Epoch: 5| Step: 1
Training loss: 0.273959219455719
Validation loss: 1.6083884239196777

Epoch: 5| Step: 2
Training loss: 0.24903817474842072
Validation loss: 1.6468212489158875

Epoch: 5| Step: 3
Training loss: 0.314959853887558
Validation loss: 1.6336365053730626

Epoch: 5| Step: 4
Training loss: 0.10461552441120148
Validation loss: 1.6183361199594313

Epoch: 5| Step: 5
Training loss: 0.22213158011436462
Validation loss: 1.6233564993386627

Epoch: 5| Step: 6
Training loss: 0.2580108642578125
Validation loss: 1.6002210917011384

Epoch: 5| Step: 7
Training loss: 0.2851703464984894
Validation loss: 1.6072755065015567

Epoch: 5| Step: 8
Training loss: 0.19094587862491608
Validation loss: 1.5808839682609803

Epoch: 5| Step: 9
Training loss: 0.19325116276741028
Validation loss: 1.5992552080462057

Epoch: 5| Step: 10
Training loss: 0.2216998040676117
Validation loss: 1.5821462952962486

Epoch: 345| Step: 0
Training loss: 0.30225494503974915
Validation loss: 1.6097596819682787

Epoch: 5| Step: 1
Training loss: 0.22969484329223633
Validation loss: 1.648748368345281

Epoch: 5| Step: 2
Training loss: 0.2292330265045166
Validation loss: 1.6213990090995707

Epoch: 5| Step: 3
Training loss: 0.13636179268360138
Validation loss: 1.6214160278279295

Epoch: 5| Step: 4
Training loss: 0.2865738868713379
Validation loss: 1.6123498396206928

Epoch: 5| Step: 5
Training loss: 0.18057850003242493
Validation loss: 1.611762946651828

Epoch: 5| Step: 6
Training loss: 0.3294835686683655
Validation loss: 1.5984337470864738

Epoch: 5| Step: 7
Training loss: 0.1934121549129486
Validation loss: 1.6380422256326164

Epoch: 5| Step: 8
Training loss: 0.281671941280365
Validation loss: 1.6291097697391306

Epoch: 5| Step: 9
Training loss: 0.26756709814071655
Validation loss: 1.6424090887910576

Epoch: 5| Step: 10
Training loss: 0.1663968712091446
Validation loss: 1.657837567790862

Epoch: 346| Step: 0
Training loss: 0.19810175895690918
Validation loss: 1.6575562697584911

Epoch: 5| Step: 1
Training loss: 0.23486189544200897
Validation loss: 1.6461351430544289

Epoch: 5| Step: 2
Training loss: 0.32547804713249207
Validation loss: 1.6554670000589022

Epoch: 5| Step: 3
Training loss: 0.2178904116153717
Validation loss: 1.6173802293756956

Epoch: 5| Step: 4
Training loss: 0.22314684092998505
Validation loss: 1.602235919685774

Epoch: 5| Step: 5
Training loss: 0.2818988859653473
Validation loss: 1.5704664209837556

Epoch: 5| Step: 6
Training loss: 0.09697065502405167
Validation loss: 1.572095949162719

Epoch: 5| Step: 7
Training loss: 0.46171218156814575
Validation loss: 1.5958217472158454

Epoch: 5| Step: 8
Training loss: 0.1274268925189972
Validation loss: 1.585607187722319

Epoch: 5| Step: 9
Training loss: 0.19046880304813385
Validation loss: 1.6074608179830736

Epoch: 5| Step: 10
Training loss: 0.1080867275595665
Validation loss: 1.6054906627183319

Epoch: 347| Step: 0
Training loss: 0.16865940392017365
Validation loss: 1.6031748505048855

Epoch: 5| Step: 1
Training loss: 0.22834177315235138
Validation loss: 1.5810473683059856

Epoch: 5| Step: 2
Training loss: 0.175575390458107
Validation loss: 1.5927394487524544

Epoch: 5| Step: 3
Training loss: 0.2349981814622879
Validation loss: 1.5677676431594356

Epoch: 5| Step: 4
Training loss: 0.16621924936771393
Validation loss: 1.556212689286919

Epoch: 5| Step: 5
Training loss: 0.14180761575698853
Validation loss: 1.5520050294937626

Epoch: 5| Step: 6
Training loss: 0.1867123544216156
Validation loss: 1.5383898083881666

Epoch: 5| Step: 7
Training loss: 0.5383967161178589
Validation loss: 1.5359826792952835

Epoch: 5| Step: 8
Training loss: 0.18829208612442017
Validation loss: 1.538530170917511

Epoch: 5| Step: 9
Training loss: 0.10001053661108017
Validation loss: 1.5482881748548118

Epoch: 5| Step: 10
Training loss: 0.21623440086841583
Validation loss: 1.5822095127515896

Epoch: 348| Step: 0
Training loss: 0.21821264922618866
Validation loss: 1.6143685925391413

Epoch: 5| Step: 1
Training loss: 0.19203981757164001
Validation loss: 1.5962378722365185

Epoch: 5| Step: 2
Training loss: 0.18704071640968323
Validation loss: 1.6153053795137713

Epoch: 5| Step: 3
Training loss: 0.2026447355747223
Validation loss: 1.5989869422810052

Epoch: 5| Step: 4
Training loss: 0.3537176847457886
Validation loss: 1.5839128750626759

Epoch: 5| Step: 5
Training loss: 0.12774495780467987
Validation loss: 1.5622065426200948

Epoch: 5| Step: 6
Training loss: 0.17736932635307312
Validation loss: 1.5685202780590262

Epoch: 5| Step: 7
Training loss: 0.33781513571739197
Validation loss: 1.5980037245699155

Epoch: 5| Step: 8
Training loss: 0.1744588017463684
Validation loss: 1.6016267614979898

Epoch: 5| Step: 9
Training loss: 0.2160002440214157
Validation loss: 1.6393727705042849

Epoch: 5| Step: 10
Training loss: 0.23696492612361908
Validation loss: 1.6455776960619035

Epoch: 349| Step: 0
Training loss: 0.15373313426971436
Validation loss: 1.6345634024630311

Epoch: 5| Step: 1
Training loss: 0.2627062201499939
Validation loss: 1.591868745383396

Epoch: 5| Step: 2
Training loss: 0.17666493356227875
Validation loss: 1.5732708913023754

Epoch: 5| Step: 3
Training loss: 0.3674534559249878
Validation loss: 1.5239768348714358

Epoch: 5| Step: 4
Training loss: 0.2720716595649719
Validation loss: 1.5122220106022333

Epoch: 5| Step: 5
Training loss: 0.2216721475124359
Validation loss: 1.5303025399484942

Epoch: 5| Step: 6
Training loss: 0.26318344473838806
Validation loss: 1.518203144432396

Epoch: 5| Step: 7
Training loss: 0.33229151368141174
Validation loss: 1.5215907058408182

Epoch: 5| Step: 8
Training loss: 0.2045547217130661
Validation loss: 1.5435842724256619

Epoch: 5| Step: 9
Training loss: 0.17824813723564148
Validation loss: 1.5536285754173034

Epoch: 5| Step: 10
Training loss: 0.26377150416374207
Validation loss: 1.600021667377923

Epoch: 350| Step: 0
Training loss: 0.4721105098724365
Validation loss: 1.612101670234434

Epoch: 5| Step: 1
Training loss: 0.19010110199451447
Validation loss: 1.6156572295773415

Epoch: 5| Step: 2
Training loss: 0.2515839636325836
Validation loss: 1.592414173387712

Epoch: 5| Step: 3
Training loss: 0.29352647066116333
Validation loss: 1.5948980598039524

Epoch: 5| Step: 4
Training loss: 0.24104256927967072
Validation loss: 1.6021662591606058

Epoch: 5| Step: 5
Training loss: 0.1749131828546524
Validation loss: 1.5699539492207188

Epoch: 5| Step: 6
Training loss: 0.2565428912639618
Validation loss: 1.5621523139297322

Epoch: 5| Step: 7
Training loss: 0.29789918661117554
Validation loss: 1.5929467652433662

Epoch: 5| Step: 8
Training loss: 0.1609337329864502
Validation loss: 1.6173050147230907

Epoch: 5| Step: 9
Training loss: 0.14241576194763184
Validation loss: 1.6240584901584092

Epoch: 5| Step: 10
Training loss: 0.28466495871543884
Validation loss: 1.6967956135349889

Epoch: 351| Step: 0
Training loss: 0.36210545897483826
Validation loss: 1.723519794402584

Epoch: 5| Step: 1
Training loss: 0.377067506313324
Validation loss: 1.6627852967990342

Epoch: 5| Step: 2
Training loss: 0.23158475756645203
Validation loss: 1.626201073328654

Epoch: 5| Step: 3
Training loss: 0.15649668872356415
Validation loss: 1.6121172232012595

Epoch: 5| Step: 4
Training loss: 0.3231426179409027
Validation loss: 1.5803529383033834

Epoch: 5| Step: 5
Training loss: 0.3622315227985382
Validation loss: 1.6165347727396155

Epoch: 5| Step: 6
Training loss: 0.3022446036338806
Validation loss: 1.6234232341089556

Epoch: 5| Step: 7
Training loss: 0.2815650999546051
Validation loss: 1.6589920149054578

Epoch: 5| Step: 8
Training loss: 0.22861719131469727
Validation loss: 1.6696836986849386

Epoch: 5| Step: 9
Training loss: 0.3025168776512146
Validation loss: 1.6582540606939664

Epoch: 5| Step: 10
Training loss: 0.32244086265563965
Validation loss: 1.6562266170337636

Epoch: 352| Step: 0
Training loss: 0.2819336950778961
Validation loss: 1.6328051852923569

Epoch: 5| Step: 1
Training loss: 0.17442747950553894
Validation loss: 1.5987366117456907

Epoch: 5| Step: 2
Training loss: 0.3347499668598175
Validation loss: 1.5949321510971233

Epoch: 5| Step: 3
Training loss: 0.25981125235557556
Validation loss: 1.5620084052444787

Epoch: 5| Step: 4
Training loss: 0.46468585729599
Validation loss: 1.5781385988317511

Epoch: 5| Step: 5
Training loss: 0.24072971940040588
Validation loss: 1.568734589443412

Epoch: 5| Step: 6
Training loss: 0.16435177624225616
Validation loss: 1.5987376769383748

Epoch: 5| Step: 7
Training loss: 0.09093192964792252
Validation loss: 1.6051057416905639

Epoch: 5| Step: 8
Training loss: 0.25467056035995483
Validation loss: 1.640499936637058

Epoch: 5| Step: 9
Training loss: 0.1671323925256729
Validation loss: 1.6536875937574653

Epoch: 5| Step: 10
Training loss: 0.15643838047981262
Validation loss: 1.637804530000174

Epoch: 353| Step: 0
Training loss: 0.21043506264686584
Validation loss: 1.6329250502330002

Epoch: 5| Step: 1
Training loss: 0.19405066967010498
Validation loss: 1.5766876948777067

Epoch: 5| Step: 2
Training loss: 0.32485252618789673
Validation loss: 1.5556616936960528

Epoch: 5| Step: 3
Training loss: 0.15393498539924622
Validation loss: 1.5564342621834046

Epoch: 5| Step: 4
Training loss: 0.2636761963367462
Validation loss: 1.5216540931373514

Epoch: 5| Step: 5
Training loss: 0.34224653244018555
Validation loss: 1.5281979877461669

Epoch: 5| Step: 6
Training loss: 0.19323250651359558
Validation loss: 1.53338614971407

Epoch: 5| Step: 7
Training loss: 0.15180841088294983
Validation loss: 1.5167508920033772

Epoch: 5| Step: 8
Training loss: 0.30566278100013733
Validation loss: 1.5334408667779738

Epoch: 5| Step: 9
Training loss: 0.26017463207244873
Validation loss: 1.5570334260181715

Epoch: 5| Step: 10
Training loss: 0.22497180104255676
Validation loss: 1.5387243199092087

Epoch: 354| Step: 0
Training loss: 0.29822835326194763
Validation loss: 1.5724602104515157

Epoch: 5| Step: 1
Training loss: 0.2339472770690918
Validation loss: 1.5833814682499054

Epoch: 5| Step: 2
Training loss: 0.23924198746681213
Validation loss: 1.5927536654215988

Epoch: 5| Step: 3
Training loss: 0.12581589818000793
Validation loss: 1.5836535564032934

Epoch: 5| Step: 4
Training loss: 0.18384616076946259
Validation loss: 1.5884582881004579

Epoch: 5| Step: 5
Training loss: 0.08720670640468597
Validation loss: 1.5830061845881964

Epoch: 5| Step: 6
Training loss: 0.2802211344242096
Validation loss: 1.5781876169225222

Epoch: 5| Step: 7
Training loss: 0.32558009028434753
Validation loss: 1.5949820036529212

Epoch: 5| Step: 8
Training loss: 0.23876997828483582
Validation loss: 1.5762280802572928

Epoch: 5| Step: 9
Training loss: 0.1764054149389267
Validation loss: 1.5247555061053204

Epoch: 5| Step: 10
Training loss: 0.1839083582162857
Validation loss: 1.5455190520132742

Epoch: 355| Step: 0
Training loss: 0.16433057188987732
Validation loss: 1.5628102928079584

Epoch: 5| Step: 1
Training loss: 0.22056512534618378
Validation loss: 1.56575640555351

Epoch: 5| Step: 2
Training loss: 0.1899881809949875
Validation loss: 1.6167457193456671

Epoch: 5| Step: 3
Training loss: 0.2698395848274231
Validation loss: 1.6285756377763645

Epoch: 5| Step: 4
Training loss: 0.32707977294921875
Validation loss: 1.6696045975531302

Epoch: 5| Step: 5
Training loss: 0.3213194012641907
Validation loss: 1.6815497093303229

Epoch: 5| Step: 6
Training loss: 0.3124178349971771
Validation loss: 1.6707022074730165

Epoch: 5| Step: 7
Training loss: 0.1522933542728424
Validation loss: 1.6224092181010912

Epoch: 5| Step: 8
Training loss: 0.2831341028213501
Validation loss: 1.646137854104401

Epoch: 5| Step: 9
Training loss: 0.16771039366722107
Validation loss: 1.612073157423286

Epoch: 5| Step: 10
Training loss: 0.1860608160495758
Validation loss: 1.6105124553044636

Epoch: 356| Step: 0
Training loss: 0.21623726189136505
Validation loss: 1.5817582389359832

Epoch: 5| Step: 1
Training loss: 0.3708032965660095
Validation loss: 1.6038503992942073

Epoch: 5| Step: 2
Training loss: 0.19723404943943024
Validation loss: 1.5930714273965487

Epoch: 5| Step: 3
Training loss: 0.2843189835548401
Validation loss: 1.5731218450812883

Epoch: 5| Step: 4
Training loss: 0.20654931664466858
Validation loss: 1.5580833009494248

Epoch: 5| Step: 5
Training loss: 0.1557222604751587
Validation loss: 1.567291364874891

Epoch: 5| Step: 6
Training loss: 0.21097564697265625
Validation loss: 1.5546021224350057

Epoch: 5| Step: 7
Training loss: 0.2510421574115753
Validation loss: 1.5671023425235544

Epoch: 5| Step: 8
Training loss: 0.2310781478881836
Validation loss: 1.546930686120064

Epoch: 5| Step: 9
Training loss: 0.18137237429618835
Validation loss: 1.5526790798351329

Epoch: 5| Step: 10
Training loss: 0.28862956166267395
Validation loss: 1.5736793241193217

Epoch: 357| Step: 0
Training loss: 0.18447822332382202
Validation loss: 1.5903625872827345

Epoch: 5| Step: 1
Training loss: 0.2792714536190033
Validation loss: 1.6097085463103427

Epoch: 5| Step: 2
Training loss: 0.22094745934009552
Validation loss: 1.6189878730363743

Epoch: 5| Step: 3
Training loss: 0.308958500623703
Validation loss: 1.640694140106119

Epoch: 5| Step: 4
Training loss: 0.23406119644641876
Validation loss: 1.5754445342607395

Epoch: 5| Step: 5
Training loss: 0.23152093589305878
Validation loss: 1.552053572029196

Epoch: 5| Step: 6
Training loss: 0.1670563668012619
Validation loss: 1.5434988006468742

Epoch: 5| Step: 7
Training loss: 0.18956060707569122
Validation loss: 1.5292395609681324

Epoch: 5| Step: 8
Training loss: 0.1837330311536789
Validation loss: 1.511773003685859

Epoch: 5| Step: 9
Training loss: 0.2878335118293762
Validation loss: 1.5009518592588362

Epoch: 5| Step: 10
Training loss: 0.15593670308589935
Validation loss: 1.5025892116690194

Epoch: 358| Step: 0
Training loss: 0.17012251913547516
Validation loss: 1.5191263332161853

Epoch: 5| Step: 1
Training loss: 0.16140016913414001
Validation loss: 1.5066885589271464

Epoch: 5| Step: 2
Training loss: 0.2021304816007614
Validation loss: 1.5117962796200988

Epoch: 5| Step: 3
Training loss: 0.38877588510513306
Validation loss: 1.5539112680701799

Epoch: 5| Step: 4
Training loss: 0.23383712768554688
Validation loss: 1.585663741634738

Epoch: 5| Step: 5
Training loss: 0.20871977508068085
Validation loss: 1.5741718469127532

Epoch: 5| Step: 6
Training loss: 0.21919605135917664
Validation loss: 1.5436225328394162

Epoch: 5| Step: 7
Training loss: 0.27056872844696045
Validation loss: 1.5448631817294705

Epoch: 5| Step: 8
Training loss: 0.13749800622463226
Validation loss: 1.5371878147125244

Epoch: 5| Step: 9
Training loss: 0.1862763613462448
Validation loss: 1.549048153943913

Epoch: 5| Step: 10
Training loss: 0.2409142255783081
Validation loss: 1.5898582140604656

Epoch: 359| Step: 0
Training loss: 0.3526473045349121
Validation loss: 1.6012051566954582

Epoch: 5| Step: 1
Training loss: 0.12363012880086899
Validation loss: 1.592521741826047

Epoch: 5| Step: 2
Training loss: 0.27172499895095825
Validation loss: 1.6197371816122403

Epoch: 5| Step: 3
Training loss: 0.3052886426448822
Validation loss: 1.603377684470146

Epoch: 5| Step: 4
Training loss: 0.2084832638502121
Validation loss: 1.5907937608739382

Epoch: 5| Step: 5
Training loss: 0.3088863790035248
Validation loss: 1.6338728627850931

Epoch: 5| Step: 6
Training loss: 0.1601715236902237
Validation loss: 1.6202223377843057

Epoch: 5| Step: 7
Training loss: 0.2030959576368332
Validation loss: 1.5994917436312603

Epoch: 5| Step: 8
Training loss: 0.28205299377441406
Validation loss: 1.5787706016212382

Epoch: 5| Step: 9
Training loss: 0.28654640913009644
Validation loss: 1.6074199279149373

Epoch: 5| Step: 10
Training loss: 0.1946152299642563
Validation loss: 1.599684174342822

Epoch: 360| Step: 0
Training loss: 0.19774945080280304
Validation loss: 1.6123922774868626

Epoch: 5| Step: 1
Training loss: 0.3313174545764923
Validation loss: 1.6166612153412194

Epoch: 5| Step: 2
Training loss: 0.28047943115234375
Validation loss: 1.6331893013369652

Epoch: 5| Step: 3
Training loss: 0.24938993155956268
Validation loss: 1.689181867466178

Epoch: 5| Step: 4
Training loss: 0.32228153944015503
Validation loss: 1.653471286578845

Epoch: 5| Step: 5
Training loss: 0.20417805016040802
Validation loss: 1.6468803626234814

Epoch: 5| Step: 6
Training loss: 0.19308677315711975
Validation loss: 1.6579078217988372

Epoch: 5| Step: 7
Training loss: 0.12780562043190002
Validation loss: 1.647419919249832

Epoch: 5| Step: 8
Training loss: 0.2098006010055542
Validation loss: 1.6212669111067248

Epoch: 5| Step: 9
Training loss: 0.37152737379074097
Validation loss: 1.6186794798861268

Epoch: 5| Step: 10
Training loss: 0.22188517451286316
Validation loss: 1.6271364983691965

Epoch: 361| Step: 0
Training loss: 0.19260209798812866
Validation loss: 1.6142778832425353

Epoch: 5| Step: 1
Training loss: 0.1581805944442749
Validation loss: 1.638554358995089

Epoch: 5| Step: 2
Training loss: 0.26614874601364136
Validation loss: 1.6475412243156022

Epoch: 5| Step: 3
Training loss: 0.2706182599067688
Validation loss: 1.6074248347231137

Epoch: 5| Step: 4
Training loss: 0.14191202819347382
Validation loss: 1.569066923151734

Epoch: 5| Step: 5
Training loss: 0.22641344368457794
Validation loss: 1.5349123785572667

Epoch: 5| Step: 6
Training loss: 0.17917023599147797
Validation loss: 1.5338580236640027

Epoch: 5| Step: 7
Training loss: 0.3137238025665283
Validation loss: 1.5243028812510993

Epoch: 5| Step: 8
Training loss: 0.2569384276866913
Validation loss: 1.5137560559857277

Epoch: 5| Step: 9
Training loss: 0.21692407131195068
Validation loss: 1.52440994785678

Epoch: 5| Step: 10
Training loss: 0.10021787136793137
Validation loss: 1.5843385586174585

Epoch: 362| Step: 0
Training loss: 0.1458229124546051
Validation loss: 1.6015500278883084

Epoch: 5| Step: 1
Training loss: 0.18129470944404602
Validation loss: 1.622091027998155

Epoch: 5| Step: 2
Training loss: 0.11372824013233185
Validation loss: 1.620529684969174

Epoch: 5| Step: 3
Training loss: 0.17178121209144592
Validation loss: 1.5981378850116525

Epoch: 5| Step: 4
Training loss: 0.23793311417102814
Validation loss: 1.5943165517622424

Epoch: 5| Step: 5
Training loss: 0.20739014446735382
Validation loss: 1.5789198234517088

Epoch: 5| Step: 6
Training loss: 0.24057769775390625
Validation loss: 1.5848360843555902

Epoch: 5| Step: 7
Training loss: 0.16894403100013733
Validation loss: 1.5772538159483223

Epoch: 5| Step: 8
Training loss: 0.22077354788780212
Validation loss: 1.5839530409023326

Epoch: 5| Step: 9
Training loss: 0.29225727915763855
Validation loss: 1.5910390859009118

Epoch: 5| Step: 10
Training loss: 0.3067268133163452
Validation loss: 1.5911956858891312

Epoch: 363| Step: 0
Training loss: 0.29693466424942017
Validation loss: 1.565875926325398

Epoch: 5| Step: 1
Training loss: 0.18707600235939026
Validation loss: 1.5898448626200359

Epoch: 5| Step: 2
Training loss: 0.2085581123828888
Validation loss: 1.568016106082547

Epoch: 5| Step: 3
Training loss: 0.25066888332366943
Validation loss: 1.5742624985274447

Epoch: 5| Step: 4
Training loss: 0.1654253751039505
Validation loss: 1.5546274672272384

Epoch: 5| Step: 5
Training loss: 0.14210228621959686
Validation loss: 1.559952675655324

Epoch: 5| Step: 6
Training loss: 0.08031675964593887
Validation loss: 1.5915953241368777

Epoch: 5| Step: 7
Training loss: 0.34367746114730835
Validation loss: 1.6122832605915685

Epoch: 5| Step: 8
Training loss: 0.28938066959381104
Validation loss: 1.6217707190462338

Epoch: 5| Step: 9
Training loss: 0.24619559943675995
Validation loss: 1.6277956347311697

Epoch: 5| Step: 10
Training loss: 0.13840927183628082
Validation loss: 1.6076126457542501

Epoch: 364| Step: 0
Training loss: 0.2525945007801056
Validation loss: 1.603631063174176

Epoch: 5| Step: 1
Training loss: 0.11323964595794678
Validation loss: 1.613327113530969

Epoch: 5| Step: 2
Training loss: 0.18864023685455322
Validation loss: 1.6160581419544835

Epoch: 5| Step: 3
Training loss: 0.33831241726875305
Validation loss: 1.5948242269536501

Epoch: 5| Step: 4
Training loss: 0.21847525238990784
Validation loss: 1.6011131642967142

Epoch: 5| Step: 5
Training loss: 0.2655823826789856
Validation loss: 1.585565250406983

Epoch: 5| Step: 6
Training loss: 0.11744606494903564
Validation loss: 1.530814225955676

Epoch: 5| Step: 7
Training loss: 0.1640920788049698
Validation loss: 1.536292661902725

Epoch: 5| Step: 8
Training loss: 0.25539252161979675
Validation loss: 1.5066203994135703

Epoch: 5| Step: 9
Training loss: 0.1441202312707901
Validation loss: 1.5230633071673814

Epoch: 5| Step: 10
Training loss: 0.14680232107639313
Validation loss: 1.5297606529728058

Epoch: 365| Step: 0
Training loss: 0.29733529686927795
Validation loss: 1.5377963217355872

Epoch: 5| Step: 1
Training loss: 0.1540348082780838
Validation loss: 1.5344019782158635

Epoch: 5| Step: 2
Training loss: 0.21279025077819824
Validation loss: 1.5468143256761695

Epoch: 5| Step: 3
Training loss: 0.16503894329071045
Validation loss: 1.5917105649107246

Epoch: 5| Step: 4
Training loss: 0.21789264678955078
Validation loss: 1.6086626078492852

Epoch: 5| Step: 5
Training loss: 0.213241845369339
Validation loss: 1.6078152489918534

Epoch: 5| Step: 6
Training loss: 0.2374887764453888
Validation loss: 1.574786352854903

Epoch: 5| Step: 7
Training loss: 0.16124549508094788
Validation loss: 1.5729697096732356

Epoch: 5| Step: 8
Training loss: 0.125578373670578
Validation loss: 1.5806068810083533

Epoch: 5| Step: 9
Training loss: 0.18198394775390625
Validation loss: 1.52437844199519

Epoch: 5| Step: 10
Training loss: 0.16362176835536957
Validation loss: 1.5452993018652803

Epoch: 366| Step: 0
Training loss: 0.18133768439292908
Validation loss: 1.55183885687141

Epoch: 5| Step: 1
Training loss: 0.07991448044776917
Validation loss: 1.5600576195665585

Epoch: 5| Step: 2
Training loss: 0.23837609589099884
Validation loss: 1.5593199140282088

Epoch: 5| Step: 3
Training loss: 0.3637081980705261
Validation loss: 1.558104891930857

Epoch: 5| Step: 4
Training loss: 0.2357783317565918
Validation loss: 1.5343790028684883

Epoch: 5| Step: 5
Training loss: 0.28080087900161743
Validation loss: 1.561935358150031

Epoch: 5| Step: 6
Training loss: 0.22687992453575134
Validation loss: 1.5637304564957977

Epoch: 5| Step: 7
Training loss: 0.12083771079778671
Validation loss: 1.581927727627498

Epoch: 5| Step: 8
Training loss: 0.16731509566307068
Validation loss: 1.5761315040690924

Epoch: 5| Step: 9
Training loss: 0.17815956473350525
Validation loss: 1.5993587445187312

Epoch: 5| Step: 10
Training loss: 0.18052297830581665
Validation loss: 1.5862129144771124

Epoch: 367| Step: 0
Training loss: 0.12899000942707062
Validation loss: 1.5754330055688017

Epoch: 5| Step: 1
Training loss: 0.14450711011886597
Validation loss: 1.596448480442006

Epoch: 5| Step: 2
Training loss: 0.3501691222190857
Validation loss: 1.567571109341037

Epoch: 5| Step: 3
Training loss: 0.1317576915025711
Validation loss: 1.565234491902013

Epoch: 5| Step: 4
Training loss: 0.14973409473896027
Validation loss: 1.5420520574815813

Epoch: 5| Step: 5
Training loss: 0.15283359587192535
Validation loss: 1.5701621809313375

Epoch: 5| Step: 6
Training loss: 0.1755146086215973
Validation loss: 1.5411062163691367

Epoch: 5| Step: 7
Training loss: 0.11845233291387558
Validation loss: 1.5573788381391955

Epoch: 5| Step: 8
Training loss: 0.1857619732618332
Validation loss: 1.5899890327966342

Epoch: 5| Step: 9
Training loss: 0.23355841636657715
Validation loss: 1.6208052609556465

Epoch: 5| Step: 10
Training loss: 0.36823707818984985
Validation loss: 1.598184497125687

Epoch: 368| Step: 0
Training loss: 0.2759089469909668
Validation loss: 1.601958223568496

Epoch: 5| Step: 1
Training loss: 0.14955653250217438
Validation loss: 1.6016258975510955

Epoch: 5| Step: 2
Training loss: 0.2813832461833954
Validation loss: 1.596484052237644

Epoch: 5| Step: 3
Training loss: 0.13814568519592285
Validation loss: 1.5957531044560094

Epoch: 5| Step: 4
Training loss: 0.0946250930428505
Validation loss: 1.5673722413278395

Epoch: 5| Step: 5
Training loss: 0.2917953133583069
Validation loss: 1.5900390160981046

Epoch: 5| Step: 6
Training loss: 0.18304142355918884
Validation loss: 1.6064485619145055

Epoch: 5| Step: 7
Training loss: 0.2348800003528595
Validation loss: 1.6112045613668298

Epoch: 5| Step: 8
Training loss: 0.1518748551607132
Validation loss: 1.6464324048770371

Epoch: 5| Step: 9
Training loss: 0.15249527990818024
Validation loss: 1.6227775722421625

Epoch: 5| Step: 10
Training loss: 0.09364134818315506
Validation loss: 1.6141095943348382

Epoch: 369| Step: 0
Training loss: 0.16129523515701294
Validation loss: 1.6127901372089182

Epoch: 5| Step: 1
Training loss: 0.12240706384181976
Validation loss: 1.6127375941122732

Epoch: 5| Step: 2
Training loss: 0.2535262107849121
Validation loss: 1.5785504899999148

Epoch: 5| Step: 3
Training loss: 0.08613357692956924
Validation loss: 1.5666035554742301

Epoch: 5| Step: 4
Training loss: 0.2717221975326538
Validation loss: 1.5783674845131495

Epoch: 5| Step: 5
Training loss: 0.13200075924396515
Validation loss: 1.5902956711348666

Epoch: 5| Step: 6
Training loss: 0.18847179412841797
Validation loss: 1.5886099235985869

Epoch: 5| Step: 7
Training loss: 0.11183973401784897
Validation loss: 1.5810400632119948

Epoch: 5| Step: 8
Training loss: 0.18223726749420166
Validation loss: 1.5604841350227274

Epoch: 5| Step: 9
Training loss: 0.272125244140625
Validation loss: 1.5783844827323832

Epoch: 5| Step: 10
Training loss: 0.20087240636348724
Validation loss: 1.5777013353122178

Epoch: 370| Step: 0
Training loss: 0.2387237548828125
Validation loss: 1.6003165783420685

Epoch: 5| Step: 1
Training loss: 0.28867989778518677
Validation loss: 1.5826759364015313

Epoch: 5| Step: 2
Training loss: 0.2478514015674591
Validation loss: 1.6076193971018637

Epoch: 5| Step: 3
Training loss: 0.13043394684791565
Validation loss: 1.5942789675087057

Epoch: 5| Step: 4
Training loss: 0.1821742057800293
Validation loss: 1.5843850822858914

Epoch: 5| Step: 5
Training loss: 0.11881433427333832
Validation loss: 1.5606188248562556

Epoch: 5| Step: 6
Training loss: 0.09168199449777603
Validation loss: 1.5463072676812448

Epoch: 5| Step: 7
Training loss: 0.13740821182727814
Validation loss: 1.5639756917953491

Epoch: 5| Step: 8
Training loss: 0.15880772471427917
Validation loss: 1.5531649313947207

Epoch: 5| Step: 9
Training loss: 0.18519099056720734
Validation loss: 1.5377870041836974

Epoch: 5| Step: 10
Training loss: 0.17937877774238586
Validation loss: 1.5481253900835592

Epoch: 371| Step: 0
Training loss: 0.2532629370689392
Validation loss: 1.5614428225383963

Epoch: 5| Step: 1
Training loss: 0.27918824553489685
Validation loss: 1.5586543852283108

Epoch: 5| Step: 2
Training loss: 0.16324976086616516
Validation loss: 1.5317150777386082

Epoch: 5| Step: 3
Training loss: 0.10655196011066437
Validation loss: 1.5638971700463244

Epoch: 5| Step: 4
Training loss: 0.11357615888118744
Validation loss: 1.5658144707320838

Epoch: 5| Step: 5
Training loss: 0.13909180462360382
Validation loss: 1.5676854707861458

Epoch: 5| Step: 6
Training loss: 0.19839441776275635
Validation loss: 1.5901036326603224

Epoch: 5| Step: 7
Training loss: 0.15184172987937927
Validation loss: 1.5794440520706998

Epoch: 5| Step: 8
Training loss: 0.14729294180870056
Validation loss: 1.6046577999668736

Epoch: 5| Step: 9
Training loss: 0.15242299437522888
Validation loss: 1.5927322551768313

Epoch: 5| Step: 10
Training loss: 0.2115422636270523
Validation loss: 1.581922677255446

Epoch: 372| Step: 0
Training loss: 0.2982674539089203
Validation loss: 1.5671844226057812

Epoch: 5| Step: 1
Training loss: 0.2536068558692932
Validation loss: 1.5805135580801195

Epoch: 5| Step: 2
Training loss: 0.13124911487102509
Validation loss: 1.5924108066866476

Epoch: 5| Step: 3
Training loss: 0.11640103906393051
Validation loss: 1.622544571276634

Epoch: 5| Step: 4
Training loss: 0.20083065330982208
Validation loss: 1.6029862678179176

Epoch: 5| Step: 5
Training loss: 0.08830656111240387
Validation loss: 1.6044617711856801

Epoch: 5| Step: 6
Training loss: 0.14796707034111023
Validation loss: 1.6038027706966604

Epoch: 5| Step: 7
Training loss: 0.2255266010761261
Validation loss: 1.5919707154714933

Epoch: 5| Step: 8
Training loss: 0.1419966220855713
Validation loss: 1.5973218615337084

Epoch: 5| Step: 9
Training loss: 0.17708037793636322
Validation loss: 1.6074889039480558

Epoch: 5| Step: 10
Training loss: 0.14686943590641022
Validation loss: 1.6131487661792385

Epoch: 373| Step: 0
Training loss: 0.16572049260139465
Validation loss: 1.5781084478542369

Epoch: 5| Step: 1
Training loss: 0.1409710943698883
Validation loss: 1.5830345589627501

Epoch: 5| Step: 2
Training loss: 0.22090819478034973
Validation loss: 1.5686768684335934

Epoch: 5| Step: 3
Training loss: 0.238867849111557
Validation loss: 1.5619897688588789

Epoch: 5| Step: 4
Training loss: 0.18566666543483734
Validation loss: 1.5532776771053192

Epoch: 5| Step: 5
Training loss: 0.3660341799259186
Validation loss: 1.5340414226696055

Epoch: 5| Step: 6
Training loss: 0.17988017201423645
Validation loss: 1.515472650527954

Epoch: 5| Step: 7
Training loss: 0.12293404340744019
Validation loss: 1.5211213134950208

Epoch: 5| Step: 8
Training loss: 0.14531630277633667
Validation loss: 1.5315847076395506

Epoch: 5| Step: 9
Training loss: 0.10683496296405792
Validation loss: 1.517722415026798

Epoch: 5| Step: 10
Training loss: 0.10876113176345825
Validation loss: 1.5341347853342693

Epoch: 374| Step: 0
Training loss: 0.19594025611877441
Validation loss: 1.525792997370484

Epoch: 5| Step: 1
Training loss: 0.10937066376209259
Validation loss: 1.5229621984625374

Epoch: 5| Step: 2
Training loss: 0.15145687758922577
Validation loss: 1.5068226796324535

Epoch: 5| Step: 3
Training loss: 0.22876973450183868
Validation loss: 1.5217205798754128

Epoch: 5| Step: 4
Training loss: 0.2829684615135193
Validation loss: 1.520594698126598

Epoch: 5| Step: 5
Training loss: 0.08753521740436554
Validation loss: 1.5372990139069096

Epoch: 5| Step: 6
Training loss: 0.18441203236579895
Validation loss: 1.5492157384913454

Epoch: 5| Step: 7
Training loss: 0.18448324501514435
Validation loss: 1.5546514500853836

Epoch: 5| Step: 8
Training loss: 0.1596141755580902
Validation loss: 1.5641434090111845

Epoch: 5| Step: 9
Training loss: 0.3016233444213867
Validation loss: 1.5546621814850838

Epoch: 5| Step: 10
Training loss: 0.06975654512643814
Validation loss: 1.5491127557651971

Epoch: 375| Step: 0
Training loss: 0.11590392887592316
Validation loss: 1.5438031393994567

Epoch: 5| Step: 1
Training loss: 0.1555936634540558
Validation loss: 1.5359361620359524

Epoch: 5| Step: 2
Training loss: 0.22144481539726257
Validation loss: 1.5610029543599775

Epoch: 5| Step: 3
Training loss: 0.24805466830730438
Validation loss: 1.5523298658350462

Epoch: 5| Step: 4
Training loss: 0.21713760495185852
Validation loss: 1.576679023363257

Epoch: 5| Step: 5
Training loss: 0.12334956973791122
Validation loss: 1.5731704042803856

Epoch: 5| Step: 6
Training loss: 0.2811782956123352
Validation loss: 1.5307480237817253

Epoch: 5| Step: 7
Training loss: 0.2025875300168991
Validation loss: 1.5420235408249723

Epoch: 5| Step: 8
Training loss: 0.16051563620567322
Validation loss: 1.543503890755356

Epoch: 5| Step: 9
Training loss: 0.0699257105588913
Validation loss: 1.51451777514591

Epoch: 5| Step: 10
Training loss: 0.09003567695617676
Validation loss: 1.5235082308451335

Epoch: 376| Step: 0
Training loss: 0.09494727849960327
Validation loss: 1.5376333152094195

Epoch: 5| Step: 1
Training loss: 0.15887781977653503
Validation loss: 1.5521890014730475

Epoch: 5| Step: 2
Training loss: 0.09565536677837372
Validation loss: 1.5491821342898953

Epoch: 5| Step: 3
Training loss: 0.24594691395759583
Validation loss: 1.531691837054427

Epoch: 5| Step: 4
Training loss: 0.23917904496192932
Validation loss: 1.548211173344684

Epoch: 5| Step: 5
Training loss: 0.12293938547372818
Validation loss: 1.513262919200364

Epoch: 5| Step: 6
Training loss: 0.18610581755638123
Validation loss: 1.5274039109547932

Epoch: 5| Step: 7
Training loss: 0.0945872962474823
Validation loss: 1.536572834496857

Epoch: 5| Step: 8
Training loss: 0.2815011143684387
Validation loss: 1.5656076746602212

Epoch: 5| Step: 9
Training loss: 0.147438645362854
Validation loss: 1.5590605223050682

Epoch: 5| Step: 10
Training loss: 0.19740688800811768
Validation loss: 1.5851419869289602

Epoch: 377| Step: 0
Training loss: 0.18060147762298584
Validation loss: 1.5895806717616257

Epoch: 5| Step: 1
Training loss: 0.1379314363002777
Validation loss: 1.5974866651719617

Epoch: 5| Step: 2
Training loss: 0.16211596131324768
Validation loss: 1.6155499565985896

Epoch: 5| Step: 3
Training loss: 0.13766635954380035
Validation loss: 1.5830507098987538

Epoch: 5| Step: 4
Training loss: 0.16011644899845123
Validation loss: 1.605139487533159

Epoch: 5| Step: 5
Training loss: 0.1277112066745758
Validation loss: 1.5455040290791502

Epoch: 5| Step: 6
Training loss: 0.23708026111125946
Validation loss: 1.5670552163995721

Epoch: 5| Step: 7
Training loss: 0.13357242941856384
Validation loss: 1.5563861298304733

Epoch: 5| Step: 8
Training loss: 0.23148410022258759
Validation loss: 1.54027319851742

Epoch: 5| Step: 9
Training loss: 0.22920802235603333
Validation loss: 1.5491787682297409

Epoch: 5| Step: 10
Training loss: 0.14741869270801544
Validation loss: 1.545063405267654

Epoch: 378| Step: 0
Training loss: 0.14943894743919373
Validation loss: 1.5351220036065707

Epoch: 5| Step: 1
Training loss: 0.11710468679666519
Validation loss: 1.554399323719804

Epoch: 5| Step: 2
Training loss: 0.2530754804611206
Validation loss: 1.55969968406103

Epoch: 5| Step: 3
Training loss: 0.09344896674156189
Validation loss: 1.5632075545608357

Epoch: 5| Step: 4
Training loss: 0.06697407364845276
Validation loss: 1.5544495864581036

Epoch: 5| Step: 5
Training loss: 0.17166106402873993
Validation loss: 1.530306279018361

Epoch: 5| Step: 6
Training loss: 0.11657768487930298
Validation loss: 1.5309814560797907

Epoch: 5| Step: 7
Training loss: 0.1808590292930603
Validation loss: 1.5262209061653382

Epoch: 5| Step: 8
Training loss: 0.2039267122745514
Validation loss: 1.499080620786195

Epoch: 5| Step: 9
Training loss: 0.21184656023979187
Validation loss: 1.527515071694569

Epoch: 5| Step: 10
Training loss: 0.20293165743350983
Validation loss: 1.5398172819486229

Epoch: 379| Step: 0
Training loss: 0.16740044951438904
Validation loss: 1.5913842865215835

Epoch: 5| Step: 1
Training loss: 0.17863881587982178
Validation loss: 1.6277569468303392

Epoch: 5| Step: 2
Training loss: 0.1499105840921402
Validation loss: 1.5967428786780244

Epoch: 5| Step: 3
Training loss: 0.1859227567911148
Validation loss: 1.6160144767453593

Epoch: 5| Step: 4
Training loss: 0.11373774707317352
Validation loss: 1.5809464390559862

Epoch: 5| Step: 5
Training loss: 0.21501047909259796
Validation loss: 1.5632676924428632

Epoch: 5| Step: 6
Training loss: 0.21983103454113007
Validation loss: 1.5647676324331632

Epoch: 5| Step: 7
Training loss: 0.06789471209049225
Validation loss: 1.5579727170287923

Epoch: 5| Step: 8
Training loss: 0.23187926411628723
Validation loss: 1.5574601427201302

Epoch: 5| Step: 9
Training loss: 0.1261991560459137
Validation loss: 1.5743275291176253

Epoch: 5| Step: 10
Training loss: 0.15171921253204346
Validation loss: 1.5871934147291287

Epoch: 380| Step: 0
Training loss: 0.12104721367359161
Validation loss: 1.6166431929475518

Epoch: 5| Step: 1
Training loss: 0.2621392011642456
Validation loss: 1.6303887418521348

Epoch: 5| Step: 2
Training loss: 0.13869227468967438
Validation loss: 1.600392537732278

Epoch: 5| Step: 3
Training loss: 0.16266696155071259
Validation loss: 1.5802453064149427

Epoch: 5| Step: 4
Training loss: 0.08540608733892441
Validation loss: 1.5612799967488935

Epoch: 5| Step: 5
Training loss: 0.18077506124973297
Validation loss: 1.5521245733384164

Epoch: 5| Step: 6
Training loss: 0.0993518978357315
Validation loss: 1.5310504372401903

Epoch: 5| Step: 7
Training loss: 0.19186252355575562
Validation loss: 1.545883084497144

Epoch: 5| Step: 8
Training loss: 0.15340080857276917
Validation loss: 1.538335834780047

Epoch: 5| Step: 9
Training loss: 0.2626921832561493
Validation loss: 1.5557557831528366

Epoch: 5| Step: 10
Training loss: 0.20871873199939728
Validation loss: 1.5635557648956135

Epoch: 381| Step: 0
Training loss: 0.16309776902198792
Validation loss: 1.5667462066937519

Epoch: 5| Step: 1
Training loss: 0.16922442615032196
Validation loss: 1.5510162999553065

Epoch: 5| Step: 2
Training loss: 0.059186022728681564
Validation loss: 1.5634984201000584

Epoch: 5| Step: 3
Training loss: 0.1492648869752884
Validation loss: 1.5274699708466888

Epoch: 5| Step: 4
Training loss: 0.213510662317276
Validation loss: 1.5266410702018327

Epoch: 5| Step: 5
Training loss: 0.1731022149324417
Validation loss: 1.5313530545080862

Epoch: 5| Step: 6
Training loss: 0.14504995942115784
Validation loss: 1.5459362332538893

Epoch: 5| Step: 7
Training loss: 0.14446921646595
Validation loss: 1.566484434630281

Epoch: 5| Step: 8
Training loss: 0.17301490902900696
Validation loss: 1.5695457996860627

Epoch: 5| Step: 9
Training loss: 0.2221793383359909
Validation loss: 1.5792072050033077

Epoch: 5| Step: 10
Training loss: 0.1292697936296463
Validation loss: 1.5816202432878557

Epoch: 382| Step: 0
Training loss: 0.1308709681034088
Validation loss: 1.6110397923377253

Epoch: 5| Step: 1
Training loss: 0.11962076276540756
Validation loss: 1.6106076452039904

Epoch: 5| Step: 2
Training loss: 0.19935046136379242
Validation loss: 1.6066479439376502

Epoch: 5| Step: 3
Training loss: 0.3192481994628906
Validation loss: 1.5721658916883572

Epoch: 5| Step: 4
Training loss: 0.10482821613550186
Validation loss: 1.5744119062218616

Epoch: 5| Step: 5
Training loss: 0.1550534963607788
Validation loss: 1.562576828464385

Epoch: 5| Step: 6
Training loss: 0.2094314992427826
Validation loss: 1.5732899917069303

Epoch: 5| Step: 7
Training loss: 0.22046825289726257
Validation loss: 1.5556324297381985

Epoch: 5| Step: 8
Training loss: 0.17224539816379547
Validation loss: 1.5885135448107155

Epoch: 5| Step: 9
Training loss: 0.12328405678272247
Validation loss: 1.565825500795918

Epoch: 5| Step: 10
Training loss: 0.12209078669548035
Validation loss: 1.5514400005340576

Epoch: 383| Step: 0
Training loss: 0.21762427687644958
Validation loss: 1.5514135514536211

Epoch: 5| Step: 1
Training loss: 0.10724575817584991
Validation loss: 1.5175063443440262

Epoch: 5| Step: 2
Training loss: 0.10783717781305313
Validation loss: 1.5325516103416361

Epoch: 5| Step: 3
Training loss: 0.1678445041179657
Validation loss: 1.5315847063577304

Epoch: 5| Step: 4
Training loss: 0.2057504951953888
Validation loss: 1.5388597467894196

Epoch: 5| Step: 5
Training loss: 0.2676582336425781
Validation loss: 1.5647348793604041

Epoch: 5| Step: 6
Training loss: 0.16907761991024017
Validation loss: 1.5648344319353822

Epoch: 5| Step: 7
Training loss: 0.12906920909881592
Validation loss: 1.5715128035955532

Epoch: 5| Step: 8
Training loss: 0.16922295093536377
Validation loss: 1.5805948818883588

Epoch: 5| Step: 9
Training loss: 0.11598904430866241
Validation loss: 1.6060166051310878

Epoch: 5| Step: 10
Training loss: 0.24951693415641785
Validation loss: 1.6276787429727533

Epoch: 384| Step: 0
Training loss: 0.15833988785743713
Validation loss: 1.6106233955711446

Epoch: 5| Step: 1
Training loss: 0.10393016040325165
Validation loss: 1.571645757203461

Epoch: 5| Step: 2
Training loss: 0.17419835925102234
Validation loss: 1.5300751757878128

Epoch: 5| Step: 3
Training loss: 0.14367607235908508
Validation loss: 1.5393616358439128

Epoch: 5| Step: 4
Training loss: 0.11401597410440445
Validation loss: 1.518317098258644

Epoch: 5| Step: 5
Training loss: 0.12106597423553467
Validation loss: 1.4960593062062417

Epoch: 5| Step: 6
Training loss: 0.14265181124210358
Validation loss: 1.5229958782913864

Epoch: 5| Step: 7
Training loss: 0.21672634780406952
Validation loss: 1.5219540762644943

Epoch: 5| Step: 8
Training loss: 0.2431844025850296
Validation loss: 1.5133030811945598

Epoch: 5| Step: 9
Training loss: 0.12301912158727646
Validation loss: 1.5370373161890174

Epoch: 5| Step: 10
Training loss: 0.1124635711312294
Validation loss: 1.5444338731868292

Epoch: 385| Step: 0
Training loss: 0.15188580751419067
Validation loss: 1.550480410616885

Epoch: 5| Step: 1
Training loss: 0.11464084684848785
Validation loss: 1.546672236534857

Epoch: 5| Step: 2
Training loss: 0.17889535427093506
Validation loss: 1.5484397680528703

Epoch: 5| Step: 3
Training loss: 0.1608898937702179
Validation loss: 1.5465407217702558

Epoch: 5| Step: 4
Training loss: 0.15458285808563232
Validation loss: 1.5319573481877644

Epoch: 5| Step: 5
Training loss: 0.14631244540214539
Validation loss: 1.5275031738383795

Epoch: 5| Step: 6
Training loss: 0.23572199046611786
Validation loss: 1.5421548537028733

Epoch: 5| Step: 7
Training loss: 0.08082006126642227
Validation loss: 1.5299595056041595

Epoch: 5| Step: 8
Training loss: 0.10572676360607147
Validation loss: 1.5465478256184568

Epoch: 5| Step: 9
Training loss: 0.11228110641241074
Validation loss: 1.5584615353615052

Epoch: 5| Step: 10
Training loss: 0.20202142000198364
Validation loss: 1.5380156014555244

Epoch: 386| Step: 0
Training loss: 0.1814621388912201
Validation loss: 1.5719742326326267

Epoch: 5| Step: 1
Training loss: 0.12624087929725647
Validation loss: 1.5759106387374222

Epoch: 5| Step: 2
Training loss: 0.2288416624069214
Validation loss: 1.5711292771882908

Epoch: 5| Step: 3
Training loss: 0.1115947961807251
Validation loss: 1.5525646337898829

Epoch: 5| Step: 4
Training loss: 0.14995503425598145
Validation loss: 1.5298467912981588

Epoch: 5| Step: 5
Training loss: 0.17076843976974487
Validation loss: 1.5506297811385124

Epoch: 5| Step: 6
Training loss: 0.06534460932016373
Validation loss: 1.564763581880959

Epoch: 5| Step: 7
Training loss: 0.20418527722358704
Validation loss: 1.573172112305959

Epoch: 5| Step: 8
Training loss: 0.12810775637626648
Validation loss: 1.5817013799503286

Epoch: 5| Step: 9
Training loss: 0.1775726079940796
Validation loss: 1.5996186835791475

Epoch: 5| Step: 10
Training loss: 0.12568672001361847
Validation loss: 1.5613867467449558

Epoch: 387| Step: 0
Training loss: 0.09377487003803253
Validation loss: 1.592048889847212

Epoch: 5| Step: 1
Training loss: 0.3258666694164276
Validation loss: 1.598063007477791

Epoch: 5| Step: 2
Training loss: 0.10651171207427979
Validation loss: 1.5898667266291957

Epoch: 5| Step: 3
Training loss: 0.1459072083234787
Validation loss: 1.5554497421428721

Epoch: 5| Step: 4
Training loss: 0.21773843467235565
Validation loss: 1.544962570231448

Epoch: 5| Step: 5
Training loss: 0.10733245313167572
Validation loss: 1.5437668369662376

Epoch: 5| Step: 6
Training loss: 0.13447587192058563
Validation loss: 1.5467408164854972

Epoch: 5| Step: 7
Training loss: 0.1013811007142067
Validation loss: 1.5463821695696922

Epoch: 5| Step: 8
Training loss: 0.13079361617565155
Validation loss: 1.5467939748558948

Epoch: 5| Step: 9
Training loss: 0.16888485848903656
Validation loss: 1.5334469554244832

Epoch: 5| Step: 10
Training loss: 0.12328004837036133
Validation loss: 1.5267101551896782

Epoch: 388| Step: 0
Training loss: 0.13738605380058289
Validation loss: 1.5417876294864121

Epoch: 5| Step: 1
Training loss: 0.13887670636177063
Validation loss: 1.5539537373409475

Epoch: 5| Step: 2
Training loss: 0.13884997367858887
Validation loss: 1.5892103295172415

Epoch: 5| Step: 3
Training loss: 0.19377492368221283
Validation loss: 1.5665454069773357

Epoch: 5| Step: 4
Training loss: 0.10585613548755646
Validation loss: 1.5420729114163307

Epoch: 5| Step: 5
Training loss: 0.15841181576251984
Validation loss: 1.542727889553193

Epoch: 5| Step: 6
Training loss: 0.07470934092998505
Validation loss: 1.520765576311337

Epoch: 5| Step: 7
Training loss: 0.21381418406963348
Validation loss: 1.5119014581044514

Epoch: 5| Step: 8
Training loss: 0.11750631034374237
Validation loss: 1.5048426043602727

Epoch: 5| Step: 9
Training loss: 0.12346844375133514
Validation loss: 1.4933445633098643

Epoch: 5| Step: 10
Training loss: 0.21639229357242584
Validation loss: 1.532482691990432

Epoch: 389| Step: 0
Training loss: 0.1281474381685257
Validation loss: 1.5345507462819417

Epoch: 5| Step: 1
Training loss: 0.18783701956272125
Validation loss: 1.5669003250778362

Epoch: 5| Step: 2
Training loss: 0.1881970912218094
Validation loss: 1.5552372637615408

Epoch: 5| Step: 3
Training loss: 0.08285465091466904
Validation loss: 1.5931481334470934

Epoch: 5| Step: 4
Training loss: 0.14296439290046692
Validation loss: 1.5724329794606855

Epoch: 5| Step: 5
Training loss: 0.1327749788761139
Validation loss: 1.5643242802671207

Epoch: 5| Step: 6
Training loss: 0.08887232840061188
Validation loss: 1.5522491265368719

Epoch: 5| Step: 7
Training loss: 0.10758058726787567
Validation loss: 1.5313164335425182

Epoch: 5| Step: 8
Training loss: 0.22158071398735046
Validation loss: 1.5260018943458475

Epoch: 5| Step: 9
Training loss: 0.15730980038642883
Validation loss: 1.4988506019756358

Epoch: 5| Step: 10
Training loss: 0.21743051707744598
Validation loss: 1.5269805051947152

Epoch: 390| Step: 0
Training loss: 0.30507543683052063
Validation loss: 1.5451545881968674

Epoch: 5| Step: 1
Training loss: 0.10470892488956451
Validation loss: 1.5902928293392222

Epoch: 5| Step: 2
Training loss: 0.15426762402057648
Validation loss: 1.585061119448754

Epoch: 5| Step: 3
Training loss: 0.13846305012702942
Validation loss: 1.6117938821033766

Epoch: 5| Step: 4
Training loss: 0.21667146682739258
Validation loss: 1.5938674237138482

Epoch: 5| Step: 5
Training loss: 0.18558210134506226
Validation loss: 1.6045395212788736

Epoch: 5| Step: 6
Training loss: 0.08841921389102936
Validation loss: 1.5617067519054617

Epoch: 5| Step: 7
Training loss: 0.11956222355365753
Validation loss: 1.5461216665083362

Epoch: 5| Step: 8
Training loss: 0.26350125670433044
Validation loss: 1.5085526051059845

Epoch: 5| Step: 9
Training loss: 0.1616576761007309
Validation loss: 1.5104919531012093

Epoch: 5| Step: 10
Training loss: 0.18987233936786652
Validation loss: 1.5021639075330508

Epoch: 391| Step: 0
Training loss: 0.16477110981941223
Validation loss: 1.4838968053940804

Epoch: 5| Step: 1
Training loss: 0.3590470552444458
Validation loss: 1.5205978590955016

Epoch: 5| Step: 2
Training loss: 0.11006094515323639
Validation loss: 1.533185629434483

Epoch: 5| Step: 3
Training loss: 0.13047046959400177
Validation loss: 1.565858994760821

Epoch: 5| Step: 4
Training loss: 0.11027170717716217
Validation loss: 1.5800784300732356

Epoch: 5| Step: 5
Training loss: 0.18607838451862335
Validation loss: 1.5924318951945151

Epoch: 5| Step: 6
Training loss: 0.13569477200508118
Validation loss: 1.5862948612500263

Epoch: 5| Step: 7
Training loss: 0.1939379870891571
Validation loss: 1.5326761622582712

Epoch: 5| Step: 8
Training loss: 0.15276683866977692
Validation loss: 1.5171288418513473

Epoch: 5| Step: 9
Training loss: 0.16483190655708313
Validation loss: 1.5348800741216189

Epoch: 5| Step: 10
Training loss: 0.07817430794239044
Validation loss: 1.5282028387951594

Epoch: 392| Step: 0
Training loss: 0.21837441623210907
Validation loss: 1.527701231741136

Epoch: 5| Step: 1
Training loss: 0.06773228943347931
Validation loss: 1.5376554727554321

Epoch: 5| Step: 2
Training loss: 0.09954217076301575
Validation loss: 1.5297645471429313

Epoch: 5| Step: 3
Training loss: 0.21102789044380188
Validation loss: 1.5316962836891093

Epoch: 5| Step: 4
Training loss: 0.19703300297260284
Validation loss: 1.5597399614190544

Epoch: 5| Step: 5
Training loss: 0.10939619690179825
Validation loss: 1.5328064798026957

Epoch: 5| Step: 6
Training loss: 0.2493012249469757
Validation loss: 1.5521658389799056

Epoch: 5| Step: 7
Training loss: 0.17388923466205597
Validation loss: 1.5236068746095062

Epoch: 5| Step: 8
Training loss: 0.13052231073379517
Validation loss: 1.5467390411643571

Epoch: 5| Step: 9
Training loss: 0.14321139454841614
Validation loss: 1.5528931092190486

Epoch: 5| Step: 10
Training loss: 0.06422248482704163
Validation loss: 1.5305433004133162

Epoch: 393| Step: 0
Training loss: 0.1311614215373993
Validation loss: 1.560665625397877

Epoch: 5| Step: 1
Training loss: 0.1891244649887085
Validation loss: 1.5694270351881623

Epoch: 5| Step: 2
Training loss: 0.12972566485404968
Validation loss: 1.5551064950163647

Epoch: 5| Step: 3
Training loss: 0.1785753220319748
Validation loss: 1.5458269888354885

Epoch: 5| Step: 4
Training loss: 0.21300168335437775
Validation loss: 1.5407021417412707

Epoch: 5| Step: 5
Training loss: 0.11176683753728867
Validation loss: 1.5364988247553508

Epoch: 5| Step: 6
Training loss: 0.13460907340049744
Validation loss: 1.5493100830303725

Epoch: 5| Step: 7
Training loss: 0.0966721698641777
Validation loss: 1.5566754559034943

Epoch: 5| Step: 8
Training loss: 0.09797294437885284
Validation loss: 1.5115031516680153

Epoch: 5| Step: 9
Training loss: 0.18991699814796448
Validation loss: 1.519850794987012

Epoch: 5| Step: 10
Training loss: 0.23121123015880585
Validation loss: 1.522691495956913

Epoch: 394| Step: 0
Training loss: 0.1509273648262024
Validation loss: 1.5197403700120988

Epoch: 5| Step: 1
Training loss: 0.1461547315120697
Validation loss: 1.5337989291837137

Epoch: 5| Step: 2
Training loss: 0.09108422696590424
Validation loss: 1.5467350085576375

Epoch: 5| Step: 3
Training loss: 0.1753310263156891
Validation loss: 1.5539837896182973

Epoch: 5| Step: 4
Training loss: 0.10210833698511124
Validation loss: 1.5595655543829805

Epoch: 5| Step: 5
Training loss: 0.21844716370105743
Validation loss: 1.5649012288739603

Epoch: 5| Step: 6
Training loss: 0.14386050403118134
Validation loss: 1.544783156405213

Epoch: 5| Step: 7
Training loss: 0.11675027757883072
Validation loss: 1.5589284563577304

Epoch: 5| Step: 8
Training loss: 0.10293348133563995
Validation loss: 1.5464659249910744

Epoch: 5| Step: 9
Training loss: 0.14128868281841278
Validation loss: 1.5557529221298874

Epoch: 5| Step: 10
Training loss: 0.2560088634490967
Validation loss: 1.5474673163506292

Epoch: 395| Step: 0
Training loss: 0.18461400270462036
Validation loss: 1.525454839070638

Epoch: 5| Step: 1
Training loss: 0.17367646098136902
Validation loss: 1.518455946317283

Epoch: 5| Step: 2
Training loss: 0.0930897518992424
Validation loss: 1.5278304674292122

Epoch: 5| Step: 3
Training loss: 0.08603721857070923
Validation loss: 1.4950746874655447

Epoch: 5| Step: 4
Training loss: 0.13543352484703064
Validation loss: 1.5147925602492465

Epoch: 5| Step: 5
Training loss: 0.09383552521467209
Validation loss: 1.5365354207254225

Epoch: 5| Step: 6
Training loss: 0.2193334996700287
Validation loss: 1.5147951431171869

Epoch: 5| Step: 7
Training loss: 0.12808552384376526
Validation loss: 1.535926761165742

Epoch: 5| Step: 8
Training loss: 0.16584226489067078
Validation loss: 1.539349736705903

Epoch: 5| Step: 9
Training loss: 0.20589995384216309
Validation loss: 1.5583954370150002

Epoch: 5| Step: 10
Training loss: 0.13132603466510773
Validation loss: 1.573750574101684

Epoch: 396| Step: 0
Training loss: 0.0974927619099617
Validation loss: 1.558491777348262

Epoch: 5| Step: 1
Training loss: 0.11619703471660614
Validation loss: 1.5446485018217435

Epoch: 5| Step: 2
Training loss: 0.11420218646526337
Validation loss: 1.5435381192033009

Epoch: 5| Step: 3
Training loss: 0.07425389438867569
Validation loss: 1.554118715306764

Epoch: 5| Step: 4
Training loss: 0.1076844185590744
Validation loss: 1.555231548124744

Epoch: 5| Step: 5
Training loss: 0.10471584647893906
Validation loss: 1.554877688807826

Epoch: 5| Step: 6
Training loss: 0.08318693935871124
Validation loss: 1.5829641536999774

Epoch: 5| Step: 7
Training loss: 0.20852074027061462
Validation loss: 1.5624940305627801

Epoch: 5| Step: 8
Training loss: 0.286527544260025
Validation loss: 1.5711094717825613

Epoch: 5| Step: 9
Training loss: 0.2191748321056366
Validation loss: 1.586097954421915

Epoch: 5| Step: 10
Training loss: 0.15605562925338745
Validation loss: 1.5672759381673669

Epoch: 397| Step: 0
Training loss: 0.07957752048969269
Validation loss: 1.5538902680079143

Epoch: 5| Step: 1
Training loss: 0.14454534649848938
Validation loss: 1.5341793388448737

Epoch: 5| Step: 2
Training loss: 0.21861322224140167
Validation loss: 1.5491874999897455

Epoch: 5| Step: 3
Training loss: 0.28908148407936096
Validation loss: 1.5537056230729627

Epoch: 5| Step: 4
Training loss: 0.10977666079998016
Validation loss: 1.5548320816409202

Epoch: 5| Step: 5
Training loss: 0.16701899468898773
Validation loss: 1.5704251720059303

Epoch: 5| Step: 6
Training loss: 0.11792774498462677
Validation loss: 1.569561114875219

Epoch: 5| Step: 7
Training loss: 0.1512773483991623
Validation loss: 1.5746657072856862

Epoch: 5| Step: 8
Training loss: 0.0917685329914093
Validation loss: 1.5657049840496433

Epoch: 5| Step: 9
Training loss: 0.09747926890850067
Validation loss: 1.594662553520613

Epoch: 5| Step: 10
Training loss: 0.09113523364067078
Validation loss: 1.5424286620591277

Epoch: 398| Step: 0
Training loss: 0.2833310663700104
Validation loss: 1.5621442653799569

Epoch: 5| Step: 1
Training loss: 0.14758948981761932
Validation loss: 1.539018464344804

Epoch: 5| Step: 2
Training loss: 0.14984306693077087
Validation loss: 1.5362953678254159

Epoch: 5| Step: 3
Training loss: 0.1690806895494461
Validation loss: 1.5186335514950495

Epoch: 5| Step: 4
Training loss: 0.14042314887046814
Validation loss: 1.5201884764496998

Epoch: 5| Step: 5
Training loss: 0.15440216660499573
Validation loss: 1.5140586130080684

Epoch: 5| Step: 6
Training loss: 0.10786481946706772
Validation loss: 1.5137430852459324

Epoch: 5| Step: 7
Training loss: 0.09805375337600708
Validation loss: 1.523286336211748

Epoch: 5| Step: 8
Training loss: 0.12420915067195892
Validation loss: 1.530579795119583

Epoch: 5| Step: 9
Training loss: 0.16500338912010193
Validation loss: 1.555303103180342

Epoch: 5| Step: 10
Training loss: 0.12999401986598969
Validation loss: 1.5489387832662111

Epoch: 399| Step: 0
Training loss: 0.241949200630188
Validation loss: 1.5938336349302722

Epoch: 5| Step: 1
Training loss: 0.257153183221817
Validation loss: 1.5993719382952618

Epoch: 5| Step: 2
Training loss: 0.14662817120552063
Validation loss: 1.5400350504024054

Epoch: 5| Step: 3
Training loss: 0.12552021443843842
Validation loss: 1.5477855654173

Epoch: 5| Step: 4
Training loss: 0.15677616000175476
Validation loss: 1.5324806577415877

Epoch: 5| Step: 5
Training loss: 0.12414679676294327
Validation loss: 1.5176396177661033

Epoch: 5| Step: 6
Training loss: 0.1416945904493332
Validation loss: 1.4979913548756671

Epoch: 5| Step: 7
Training loss: 0.12556858360767365
Validation loss: 1.5301323783013128

Epoch: 5| Step: 8
Training loss: 0.09965343773365021
Validation loss: 1.5402643296026415

Epoch: 5| Step: 9
Training loss: 0.16885915398597717
Validation loss: 1.5758402629565167

Epoch: 5| Step: 10
Training loss: 0.11325833201408386
Validation loss: 1.5559980164292038

Epoch: 400| Step: 0
Training loss: 0.1400572955608368
Validation loss: 1.5595901179057297

Epoch: 5| Step: 1
Training loss: 0.13544777035713196
Validation loss: 1.5312097149510537

Epoch: 5| Step: 2
Training loss: 0.16206154227256775
Validation loss: 1.5051293962745256

Epoch: 5| Step: 3
Training loss: 0.18462000787258148
Validation loss: 1.4806714532195882

Epoch: 5| Step: 4
Training loss: 0.19194206595420837
Validation loss: 1.4463402148216002

Epoch: 5| Step: 5
Training loss: 0.155493825674057
Validation loss: 1.4470750144732896

Epoch: 5| Step: 6
Training loss: 0.1509310007095337
Validation loss: 1.479751185704303

Epoch: 5| Step: 7
Training loss: 0.15754659473896027
Validation loss: 1.4966805237595753

Epoch: 5| Step: 8
Training loss: 0.14426857233047485
Validation loss: 1.4970260281716623

Epoch: 5| Step: 9
Training loss: 0.20339438319206238
Validation loss: 1.524717996197362

Epoch: 5| Step: 10
Training loss: 0.12629999220371246
Validation loss: 1.5605245642764594

Epoch: 401| Step: 0
Training loss: 0.131097674369812
Validation loss: 1.554271295506467

Epoch: 5| Step: 1
Training loss: 0.2491150200366974
Validation loss: 1.5837029103309876

Epoch: 5| Step: 2
Training loss: 0.09869836270809174
Validation loss: 1.5971224179831884

Epoch: 5| Step: 3
Training loss: 0.10587944835424423
Validation loss: 1.5633942580992175

Epoch: 5| Step: 4
Training loss: 0.13089939951896667
Validation loss: 1.5560104590590282

Epoch: 5| Step: 5
Training loss: 0.17253048717975616
Validation loss: 1.5348212757418234

Epoch: 5| Step: 6
Training loss: 0.21946081519126892
Validation loss: 1.5740815260077035

Epoch: 5| Step: 7
Training loss: 0.2603248953819275
Validation loss: 1.5647887811865857

Epoch: 5| Step: 8
Training loss: 0.14315010607242584
Validation loss: 1.5621453331362816

Epoch: 5| Step: 9
Training loss: 0.16858816146850586
Validation loss: 1.5714460457524946

Epoch: 5| Step: 10
Training loss: 0.13241027295589447
Validation loss: 1.591031256542411

Epoch: 402| Step: 0
Training loss: 0.1404666304588318
Validation loss: 1.5702111169856081

Epoch: 5| Step: 1
Training loss: 0.16283471882343292
Validation loss: 1.5915051903775943

Epoch: 5| Step: 2
Training loss: 0.22055307030677795
Validation loss: 1.5698640936164445

Epoch: 5| Step: 3
Training loss: 0.20039582252502441
Validation loss: 1.55110514356244

Epoch: 5| Step: 4
Training loss: 0.11588313430547714
Validation loss: 1.554968519877362

Epoch: 5| Step: 5
Training loss: 0.11096906661987305
Validation loss: 1.5411730184349963

Epoch: 5| Step: 6
Training loss: 0.16939382255077362
Validation loss: 1.5133730070565337

Epoch: 5| Step: 7
Training loss: 0.10836613178253174
Validation loss: 1.5194128405663274

Epoch: 5| Step: 8
Training loss: 0.12027235329151154
Validation loss: 1.5349759856859844

Epoch: 5| Step: 9
Training loss: 0.13284267485141754
Validation loss: 1.5347810906748618

Epoch: 5| Step: 10
Training loss: 0.10062988847494125
Validation loss: 1.5440303407689577

Epoch: 403| Step: 0
Training loss: 0.11242203414440155
Validation loss: 1.5574870173649122

Epoch: 5| Step: 1
Training loss: 0.15837079286575317
Validation loss: 1.5391282138004099

Epoch: 5| Step: 2
Training loss: 0.14181503653526306
Validation loss: 1.5403572872120848

Epoch: 5| Step: 3
Training loss: 0.09964065253734589
Validation loss: 1.5620340160144273

Epoch: 5| Step: 4
Training loss: 0.10319143533706665
Validation loss: 1.5481529684476956

Epoch: 5| Step: 5
Training loss: 0.1489739716053009
Validation loss: 1.5587400415892243

Epoch: 5| Step: 6
Training loss: 0.13905687630176544
Validation loss: 1.5653268374422544

Epoch: 5| Step: 7
Training loss: 0.12298177182674408
Validation loss: 1.5733214860321374

Epoch: 5| Step: 8
Training loss: 0.23621836304664612
Validation loss: 1.5753180865318543

Epoch: 5| Step: 9
Training loss: 0.20831629633903503
Validation loss: 1.5563517270549652

Epoch: 5| Step: 10
Training loss: 0.10172495990991592
Validation loss: 1.585798409677321

Epoch: 404| Step: 0
Training loss: 0.13153555989265442
Validation loss: 1.5679812815881544

Epoch: 5| Step: 1
Training loss: 0.0816764086484909
Validation loss: 1.5447283829412153

Epoch: 5| Step: 2
Training loss: 0.09926555305719376
Validation loss: 1.558644461375411

Epoch: 5| Step: 3
Training loss: 0.09710641950368881
Validation loss: 1.551232162983187

Epoch: 5| Step: 4
Training loss: 0.08362556993961334
Validation loss: 1.5602580347368795

Epoch: 5| Step: 5
Training loss: 0.1307833343744278
Validation loss: 1.535470203686786

Epoch: 5| Step: 6
Training loss: 0.3247993588447571
Validation loss: 1.5527295899647537

Epoch: 5| Step: 7
Training loss: 0.10125156491994858
Validation loss: 1.551859942815637

Epoch: 5| Step: 8
Training loss: 0.15441839396953583
Validation loss: 1.543306726281361

Epoch: 5| Step: 9
Training loss: 0.21485424041748047
Validation loss: 1.5791256632856143

Epoch: 5| Step: 10
Training loss: 0.16777271032333374
Validation loss: 1.5482269679346392

Epoch: 405| Step: 0
Training loss: 0.10167253017425537
Validation loss: 1.5367245981770177

Epoch: 5| Step: 1
Training loss: 0.1293388456106186
Validation loss: 1.54377463171559

Epoch: 5| Step: 2
Training loss: 0.11736428737640381
Validation loss: 1.5140631929520638

Epoch: 5| Step: 3
Training loss: 0.1257203072309494
Validation loss: 1.5041841140357397

Epoch: 5| Step: 4
Training loss: 0.28394776582717896
Validation loss: 1.5275838567364601

Epoch: 5| Step: 5
Training loss: 0.1447845995426178
Validation loss: 1.5303823127541492

Epoch: 5| Step: 6
Training loss: 0.11831605434417725
Validation loss: 1.5629665992593254

Epoch: 5| Step: 7
Training loss: 0.17099027335643768
Validation loss: 1.5268657733035345

Epoch: 5| Step: 8
Training loss: 0.11593747138977051
Validation loss: 1.5334959530061292

Epoch: 5| Step: 9
Training loss: 0.07975094765424728
Validation loss: 1.529683187443723

Epoch: 5| Step: 10
Training loss: 0.15441188216209412
Validation loss: 1.5283674911786151

Epoch: 406| Step: 0
Training loss: 0.13473951816558838
Validation loss: 1.5194779519111878

Epoch: 5| Step: 1
Training loss: 0.0906158909201622
Validation loss: 1.5030931400996383

Epoch: 5| Step: 2
Training loss: 0.0920829251408577
Validation loss: 1.495151419793406

Epoch: 5| Step: 3
Training loss: 0.20536799728870392
Validation loss: 1.477591872215271

Epoch: 5| Step: 4
Training loss: 0.08959078788757324
Validation loss: 1.4804184000979188

Epoch: 5| Step: 5
Training loss: 0.23687514662742615
Validation loss: 1.4832938435257121

Epoch: 5| Step: 6
Training loss: 0.19930346310138702
Validation loss: 1.516130228837331

Epoch: 5| Step: 7
Training loss: 0.062101811170578
Validation loss: 1.5242986973895822

Epoch: 5| Step: 8
Training loss: 0.08666478097438812
Validation loss: 1.5212574594764299

Epoch: 5| Step: 9
Training loss: 0.14617407321929932
Validation loss: 1.53969447458944

Epoch: 5| Step: 10
Training loss: 0.18938572704792023
Validation loss: 1.5711184137610978

Epoch: 407| Step: 0
Training loss: 0.13184210658073425
Validation loss: 1.5490384896596272

Epoch: 5| Step: 1
Training loss: 0.12793318927288055
Validation loss: 1.5264085672234977

Epoch: 5| Step: 2
Training loss: 0.11107482016086578
Validation loss: 1.5378903394104333

Epoch: 5| Step: 3
Training loss: 0.12262139469385147
Validation loss: 1.5349996013026084

Epoch: 5| Step: 4
Training loss: 0.15614037215709686
Validation loss: 1.542135743684666

Epoch: 5| Step: 5
Training loss: 0.23168301582336426
Validation loss: 1.530861367461502

Epoch: 5| Step: 6
Training loss: 0.06847472488880157
Validation loss: 1.5373316323885353

Epoch: 5| Step: 7
Training loss: 0.12473845481872559
Validation loss: 1.528616298911392

Epoch: 5| Step: 8
Training loss: 0.09976110607385635
Validation loss: 1.5276473427331576

Epoch: 5| Step: 9
Training loss: 0.1484270989894867
Validation loss: 1.5455536880800802

Epoch: 5| Step: 10
Training loss: 0.13624006509780884
Validation loss: 1.5473563440384404

Epoch: 408| Step: 0
Training loss: 0.12063709646463394
Validation loss: 1.564992404753162

Epoch: 5| Step: 1
Training loss: 0.0538560152053833
Validation loss: 1.5775287817883235

Epoch: 5| Step: 2
Training loss: 0.1499844491481781
Validation loss: 1.5730296386185514

Epoch: 5| Step: 3
Training loss: 0.22665545344352722
Validation loss: 1.5789628900507444

Epoch: 5| Step: 4
Training loss: 0.10782381147146225
Validation loss: 1.594509542629283

Epoch: 5| Step: 5
Training loss: 0.16878637671470642
Validation loss: 1.613563479915742

Epoch: 5| Step: 6
Training loss: 0.08956688642501831
Validation loss: 1.5796180687924868

Epoch: 5| Step: 7
Training loss: 0.16828158497810364
Validation loss: 1.549686824121783

Epoch: 5| Step: 8
Training loss: 0.1130162850022316
Validation loss: 1.566677785688831

Epoch: 5| Step: 9
Training loss: 0.21783235669136047
Validation loss: 1.57964030901591

Epoch: 5| Step: 10
Training loss: 0.10692080855369568
Validation loss: 1.5832975115827335

Epoch: 409| Step: 0
Training loss: 0.11008288711309433
Validation loss: 1.56239547780765

Epoch: 5| Step: 1
Training loss: 0.12354148924350739
Validation loss: 1.5587772259148218

Epoch: 5| Step: 2
Training loss: 0.08959424495697021
Validation loss: 1.541365828565372

Epoch: 5| Step: 3
Training loss: 0.08254753053188324
Validation loss: 1.5374078212245819

Epoch: 5| Step: 4
Training loss: 0.12875106930732727
Validation loss: 1.4976818036007624

Epoch: 5| Step: 5
Training loss: 0.17251737415790558
Validation loss: 1.4942066413100048

Epoch: 5| Step: 6
Training loss: 0.15471498668193817
Validation loss: 1.4854316711425781

Epoch: 5| Step: 7
Training loss: 0.131822407245636
Validation loss: 1.4878847804120792

Epoch: 5| Step: 8
Training loss: 0.14628532528877258
Validation loss: 1.52543907396255

Epoch: 5| Step: 9
Training loss: 0.13353057205677032
Validation loss: 1.5410577122883131

Epoch: 5| Step: 10
Training loss: 0.1921270340681076
Validation loss: 1.5383823866485267

Epoch: 410| Step: 0
Training loss: 0.0887250304222107
Validation loss: 1.5343340494299447

Epoch: 5| Step: 1
Training loss: 0.16241607069969177
Validation loss: 1.5638201236724854

Epoch: 5| Step: 2
Training loss: 0.16465309262275696
Validation loss: 1.5479667853283625

Epoch: 5| Step: 3
Training loss: 0.07771997153759003
Validation loss: 1.5151952159020208

Epoch: 5| Step: 4
Training loss: 0.0656099021434784
Validation loss: 1.5270468419597996

Epoch: 5| Step: 5
Training loss: 0.10043470561504364
Validation loss: 1.5448714276795745

Epoch: 5| Step: 6
Training loss: 0.1480262130498886
Validation loss: 1.525484167119508

Epoch: 5| Step: 7
Training loss: 0.09154105931520462
Validation loss: 1.559788014299126

Epoch: 5| Step: 8
Training loss: 0.20924215018749237
Validation loss: 1.555217812138219

Epoch: 5| Step: 9
Training loss: 0.11995740234851837
Validation loss: 1.565364098036161

Epoch: 5| Step: 10
Training loss: 0.12812389433383942
Validation loss: 1.5692339494664183

Epoch: 411| Step: 0
Training loss: 0.12579040229320526
Validation loss: 1.5691300130659533

Epoch: 5| Step: 1
Training loss: 0.14020046591758728
Validation loss: 1.5726253883813017

Epoch: 5| Step: 2
Training loss: 0.06548338383436203
Validation loss: 1.5452364221695931

Epoch: 5| Step: 3
Training loss: 0.08010877668857574
Validation loss: 1.5594218366889543

Epoch: 5| Step: 4
Training loss: 0.10090670734643936
Validation loss: 1.5355114308736657

Epoch: 5| Step: 5
Training loss: 0.10147781670093536
Validation loss: 1.5624865306321012

Epoch: 5| Step: 6
Training loss: 0.16775889694690704
Validation loss: 1.5581695257976491

Epoch: 5| Step: 7
Training loss: 0.16653680801391602
Validation loss: 1.5599022398712814

Epoch: 5| Step: 8
Training loss: 0.17215362191200256
Validation loss: 1.5492622326779109

Epoch: 5| Step: 9
Training loss: 0.05933248996734619
Validation loss: 1.5511005770775579

Epoch: 5| Step: 10
Training loss: 0.14856767654418945
Validation loss: 1.5642970249217043

Epoch: 412| Step: 0
Training loss: 0.15045806765556335
Validation loss: 1.5434744165789696

Epoch: 5| Step: 1
Training loss: 0.1444960981607437
Validation loss: 1.5681877700231408

Epoch: 5| Step: 2
Training loss: 0.09324973076581955
Validation loss: 1.5586807471449657

Epoch: 5| Step: 3
Training loss: 0.12546546757221222
Validation loss: 1.558177044314723

Epoch: 5| Step: 4
Training loss: 0.13123819231987
Validation loss: 1.5313586547810545

Epoch: 5| Step: 5
Training loss: 0.15455298125743866
Validation loss: 1.529675781085927

Epoch: 5| Step: 6
Training loss: 0.07132428884506226
Validation loss: 1.5349574140323106

Epoch: 5| Step: 7
Training loss: 0.18954887986183167
Validation loss: 1.5362262136192733

Epoch: 5| Step: 8
Training loss: 0.07305049896240234
Validation loss: 1.538266404982536

Epoch: 5| Step: 9
Training loss: 0.07254038751125336
Validation loss: 1.545843989618363

Epoch: 5| Step: 10
Training loss: 0.16599597036838531
Validation loss: 1.519038922684167

Epoch: 413| Step: 0
Training loss: 0.1646026074886322
Validation loss: 1.5129228279154787

Epoch: 5| Step: 1
Training loss: 0.2006112039089203
Validation loss: 1.5084740115750221

Epoch: 5| Step: 2
Training loss: 0.060794055461883545
Validation loss: 1.5221335875090731

Epoch: 5| Step: 3
Training loss: 0.1088782325387001
Validation loss: 1.5188843383583972

Epoch: 5| Step: 4
Training loss: 0.06393027305603027
Validation loss: 1.5379589475611204

Epoch: 5| Step: 5
Training loss: 0.14341631531715393
Validation loss: 1.5381849901650542

Epoch: 5| Step: 6
Training loss: 0.15316715836524963
Validation loss: 1.5631437865636681

Epoch: 5| Step: 7
Training loss: 0.09592149406671524
Validation loss: 1.565902070332599

Epoch: 5| Step: 8
Training loss: 0.13865868747234344
Validation loss: 1.547613766885573

Epoch: 5| Step: 9
Training loss: 0.07060904055833817
Validation loss: 1.560066524372306

Epoch: 5| Step: 10
Training loss: 0.07169774174690247
Validation loss: 1.5272798281843945

Epoch: 414| Step: 0
Training loss: 0.07380302250385284
Validation loss: 1.5101602026211318

Epoch: 5| Step: 1
Training loss: 0.12700670957565308
Validation loss: 1.513634563774191

Epoch: 5| Step: 2
Training loss: 0.1058230772614479
Validation loss: 1.5075616464819959

Epoch: 5| Step: 3
Training loss: 0.09160201251506805
Validation loss: 1.5108907927748978

Epoch: 5| Step: 4
Training loss: 0.09170176088809967
Validation loss: 1.5107611219088237

Epoch: 5| Step: 5
Training loss: 0.07931528985500336
Validation loss: 1.5260857574401363

Epoch: 5| Step: 6
Training loss: 0.10300333797931671
Validation loss: 1.5287508323628416

Epoch: 5| Step: 7
Training loss: 0.1580708771944046
Validation loss: 1.5450914162461475

Epoch: 5| Step: 8
Training loss: 0.18203088641166687
Validation loss: 1.5675272249406385

Epoch: 5| Step: 9
Training loss: 0.1629686802625656
Validation loss: 1.561755491841224

Epoch: 5| Step: 10
Training loss: 0.12702688574790955
Validation loss: 1.5711974482382498

Epoch: 415| Step: 0
Training loss: 0.11343522369861603
Validation loss: 1.5307484826733988

Epoch: 5| Step: 1
Training loss: 0.1028890386223793
Validation loss: 1.527868696438369

Epoch: 5| Step: 2
Training loss: 0.10901045799255371
Validation loss: 1.5155829460390153

Epoch: 5| Step: 3
Training loss: 0.13066568970680237
Validation loss: 1.530414222389139

Epoch: 5| Step: 4
Training loss: 0.17126567661762238
Validation loss: 1.5152785778045654

Epoch: 5| Step: 5
Training loss: 0.22711420059204102
Validation loss: 1.5211466358553978

Epoch: 5| Step: 6
Training loss: 0.14764368534088135
Validation loss: 1.5147529673832718

Epoch: 5| Step: 7
Training loss: 0.08552223443984985
Validation loss: 1.5300855662233086

Epoch: 5| Step: 8
Training loss: 0.100244902074337
Validation loss: 1.5657208786215833

Epoch: 5| Step: 9
Training loss: 0.15475435554981232
Validation loss: 1.5897899622558265

Epoch: 5| Step: 10
Training loss: 0.07033369690179825
Validation loss: 1.5310664933214906

Epoch: 416| Step: 0
Training loss: 0.13566556572914124
Validation loss: 1.5635713069669661

Epoch: 5| Step: 1
Training loss: 0.040932632982730865
Validation loss: 1.5448634970572688

Epoch: 5| Step: 2
Training loss: 0.2508935034275055
Validation loss: 1.5427408897748558

Epoch: 5| Step: 3
Training loss: 0.10493872314691544
Validation loss: 1.5575966565839705

Epoch: 5| Step: 4
Training loss: 0.12904122471809387
Validation loss: 1.566972069842841

Epoch: 5| Step: 5
Training loss: 0.05921081453561783
Validation loss: 1.5664574010397798

Epoch: 5| Step: 6
Training loss: 0.07149185985326767
Validation loss: 1.5596784314801615

Epoch: 5| Step: 7
Training loss: 0.09061557799577713
Validation loss: 1.5766495120140813

Epoch: 5| Step: 8
Training loss: 0.12712909281253815
Validation loss: 1.5488607229725007

Epoch: 5| Step: 9
Training loss: 0.16728760302066803
Validation loss: 1.5438965033459406

Epoch: 5| Step: 10
Training loss: 0.17740964889526367
Validation loss: 1.5240942861444207

Epoch: 417| Step: 0
Training loss: 0.14988335967063904
Validation loss: 1.5263505058903848

Epoch: 5| Step: 1
Training loss: 0.05997714400291443
Validation loss: 1.529347324884066

Epoch: 5| Step: 2
Training loss: 0.087691530585289
Validation loss: 1.5134551320024716

Epoch: 5| Step: 3
Training loss: 0.12544985115528107
Validation loss: 1.5222098776089248

Epoch: 5| Step: 4
Training loss: 0.17863591015338898
Validation loss: 1.5207657198752127

Epoch: 5| Step: 5
Training loss: 0.16556352376937866
Validation loss: 1.5066973893873152

Epoch: 5| Step: 6
Training loss: 0.1573711484670639
Validation loss: 1.5126315637301373

Epoch: 5| Step: 7
Training loss: 0.10914210230112076
Validation loss: 1.5216201518171577

Epoch: 5| Step: 8
Training loss: 0.06886699795722961
Validation loss: 1.5085925286816013

Epoch: 5| Step: 9
Training loss: 0.07230283319950104
Validation loss: 1.4891924178728493

Epoch: 5| Step: 10
Training loss: 0.07524765282869339
Validation loss: 1.5147877841867425

Epoch: 418| Step: 0
Training loss: 0.13833925127983093
Validation loss: 1.5233914288141395

Epoch: 5| Step: 1
Training loss: 0.12758688628673553
Validation loss: 1.5018210769981466

Epoch: 5| Step: 2
Training loss: 0.08611687272787094
Validation loss: 1.5282458759123279

Epoch: 5| Step: 3
Training loss: 0.13526204228401184
Validation loss: 1.5436636683761433

Epoch: 5| Step: 4
Training loss: 0.09579770267009735
Validation loss: 1.5677595407732072

Epoch: 5| Step: 5
Training loss: 0.1236499547958374
Validation loss: 1.5494612980914373

Epoch: 5| Step: 6
Training loss: 0.0916953757405281
Validation loss: 1.544262614301456

Epoch: 5| Step: 7
Training loss: 0.17105495929718018
Validation loss: 1.5159573901084162

Epoch: 5| Step: 8
Training loss: 0.1066005676984787
Validation loss: 1.4896833063453756

Epoch: 5| Step: 9
Training loss: 0.14530996978282928
Validation loss: 1.5039415013405584

Epoch: 5| Step: 10
Training loss: 0.05284227803349495
Validation loss: 1.4967320670363724

Epoch: 419| Step: 0
Training loss: 0.16567322611808777
Validation loss: 1.4996731576099191

Epoch: 5| Step: 1
Training loss: 0.07232616096735
Validation loss: 1.5191708905722505

Epoch: 5| Step: 2
Training loss: 0.08819052577018738
Validation loss: 1.5513923757819719

Epoch: 5| Step: 3
Training loss: 0.09906881302595139
Validation loss: 1.5839278185239403

Epoch: 5| Step: 4
Training loss: 0.1467466801404953
Validation loss: 1.5865353810530838

Epoch: 5| Step: 5
Training loss: 0.155548095703125
Validation loss: 1.5594722340183873

Epoch: 5| Step: 6
Training loss: 0.207280233502388
Validation loss: 1.606016598721986

Epoch: 5| Step: 7
Training loss: 0.12619294226169586
Validation loss: 1.5554489525415565

Epoch: 5| Step: 8
Training loss: 0.13057133555412292
Validation loss: 1.534666681802401

Epoch: 5| Step: 9
Training loss: 0.08997414261102676
Validation loss: 1.5280471155720372

Epoch: 5| Step: 10
Training loss: 0.11202031373977661
Validation loss: 1.4980991271234327

Epoch: 420| Step: 0
Training loss: 0.06076621264219284
Validation loss: 1.532744643508747

Epoch: 5| Step: 1
Training loss: 0.13533881306648254
Validation loss: 1.5293741380014727

Epoch: 5| Step: 2
Training loss: 0.1320897489786148
Validation loss: 1.5399893073625461

Epoch: 5| Step: 3
Training loss: 0.14946874976158142
Validation loss: 1.572730089387586

Epoch: 5| Step: 4
Training loss: 0.1150650605559349
Validation loss: 1.5594713662260322

Epoch: 5| Step: 5
Training loss: 0.11021041870117188
Validation loss: 1.5790542940939627

Epoch: 5| Step: 6
Training loss: 0.09502460807561874
Validation loss: 1.567012103655005

Epoch: 5| Step: 7
Training loss: 0.09367500245571136
Validation loss: 1.5740145765325075

Epoch: 5| Step: 8
Training loss: 0.10219664871692657
Validation loss: 1.5565764775840185

Epoch: 5| Step: 9
Training loss: 0.09265772253274918
Validation loss: 1.5722937942833028

Epoch: 5| Step: 10
Training loss: 0.11789386719465256
Validation loss: 1.5304042100906372

Epoch: 421| Step: 0
Training loss: 0.1770336776971817
Validation loss: 1.5442026212651243

Epoch: 5| Step: 1
Training loss: 0.25037094950675964
Validation loss: 1.5258996999391945

Epoch: 5| Step: 2
Training loss: 0.10970990359783173
Validation loss: 1.5179448012382752

Epoch: 5| Step: 3
Training loss: 0.14034557342529297
Validation loss: 1.5261838205399052

Epoch: 5| Step: 4
Training loss: 0.13646003603935242
Validation loss: 1.538291911925039

Epoch: 5| Step: 5
Training loss: 0.16844090819358826
Validation loss: 1.5407432042142397

Epoch: 5| Step: 6
Training loss: 0.10595560073852539
Validation loss: 1.5462462555977605

Epoch: 5| Step: 7
Training loss: 0.07246062159538269
Validation loss: 1.5001538056199268

Epoch: 5| Step: 8
Training loss: 0.10106208175420761
Validation loss: 1.5048904393308906

Epoch: 5| Step: 9
Training loss: 0.069420225918293
Validation loss: 1.4587656438991587

Epoch: 5| Step: 10
Training loss: 0.0970442071557045
Validation loss: 1.4851233472106278

Epoch: 422| Step: 0
Training loss: 0.08281585574150085
Validation loss: 1.485313234790679

Epoch: 5| Step: 1
Training loss: 0.0831179991364479
Validation loss: 1.4914781617861923

Epoch: 5| Step: 2
Training loss: 0.0806344524025917
Validation loss: 1.5081471755940428

Epoch: 5| Step: 3
Training loss: 0.1887042224407196
Validation loss: 1.5146463904329526

Epoch: 5| Step: 4
Training loss: 0.09840868413448334
Validation loss: 1.5643116120369203

Epoch: 5| Step: 5
Training loss: 0.2029607743024826
Validation loss: 1.548342376626948

Epoch: 5| Step: 6
Training loss: 0.14767523109912872
Validation loss: 1.5496085209231223

Epoch: 5| Step: 7
Training loss: 0.11414611339569092
Validation loss: 1.5216062607303742

Epoch: 5| Step: 8
Training loss: 0.10007598251104355
Validation loss: 1.5006931033185733

Epoch: 5| Step: 9
Training loss: 0.10962291061878204
Validation loss: 1.5043826923575452

Epoch: 5| Step: 10
Training loss: 0.05062534287571907
Validation loss: 1.5185529519152898

Epoch: 423| Step: 0
Training loss: 0.09107212722301483
Validation loss: 1.5057009202177807

Epoch: 5| Step: 1
Training loss: 0.1857088804244995
Validation loss: 1.5080648891387447

Epoch: 5| Step: 2
Training loss: 0.08562199026346207
Validation loss: 1.555180162511846

Epoch: 5| Step: 3
Training loss: 0.15010038018226624
Validation loss: 1.5672462960725189

Epoch: 5| Step: 4
Training loss: 0.09164558351039886
Validation loss: 1.56312685115363

Epoch: 5| Step: 5
Training loss: 0.09520930796861649
Validation loss: 1.5372547975150488

Epoch: 5| Step: 6
Training loss: 0.09184383600950241
Validation loss: 1.5114733557547293

Epoch: 5| Step: 7
Training loss: 0.1835538148880005
Validation loss: 1.5098684603168118

Epoch: 5| Step: 8
Training loss: 0.10612650215625763
Validation loss: 1.5282627151858421

Epoch: 5| Step: 9
Training loss: 0.14647942781448364
Validation loss: 1.523199119875508

Epoch: 5| Step: 10
Training loss: 0.13847889006137848
Validation loss: 1.5368049965109876

Epoch: 424| Step: 0
Training loss: 0.11844692379236221
Validation loss: 1.5186818338209582

Epoch: 5| Step: 1
Training loss: 0.12786459922790527
Validation loss: 1.5390863469851914

Epoch: 5| Step: 2
Training loss: 0.11237158626317978
Validation loss: 1.55371198666993

Epoch: 5| Step: 3
Training loss: 0.14446985721588135
Validation loss: 1.5589422333625056

Epoch: 5| Step: 4
Training loss: 0.12903133034706116
Validation loss: 1.5534417872787805

Epoch: 5| Step: 5
Training loss: 0.11426587402820587
Validation loss: 1.5418005835625432

Epoch: 5| Step: 6
Training loss: 0.05349239706993103
Validation loss: 1.5550459507972962

Epoch: 5| Step: 7
Training loss: 0.07805006951093674
Validation loss: 1.5465552217216902

Epoch: 5| Step: 8
Training loss: 0.18589185178279877
Validation loss: 1.549674642342393

Epoch: 5| Step: 9
Training loss: 0.10739080607891083
Validation loss: 1.5407304468975271

Epoch: 5| Step: 10
Training loss: 0.11744841188192368
Validation loss: 1.52533249444859

Epoch: 425| Step: 0
Training loss: 0.10146842151880264
Validation loss: 1.5086294438249321

Epoch: 5| Step: 1
Training loss: 0.07301104068756104
Validation loss: 1.5094712113821378

Epoch: 5| Step: 2
Training loss: 0.146138995885849
Validation loss: 1.4808756664235105

Epoch: 5| Step: 3
Training loss: 0.10972592979669571
Validation loss: 1.494812564183307

Epoch: 5| Step: 4
Training loss: 0.11209490150213242
Validation loss: 1.5015235088204826

Epoch: 5| Step: 5
Training loss: 0.09185219556093216
Validation loss: 1.5116692435356878

Epoch: 5| Step: 6
Training loss: 0.17834213376045227
Validation loss: 1.4897826980519038

Epoch: 5| Step: 7
Training loss: 0.14926302433013916
Validation loss: 1.4939798014138335

Epoch: 5| Step: 8
Training loss: 0.15276062488555908
Validation loss: 1.4944301138642013

Epoch: 5| Step: 9
Training loss: 0.1051609069108963
Validation loss: 1.5141446667332803

Epoch: 5| Step: 10
Training loss: 0.1203833743929863
Validation loss: 1.5182831851384972

Epoch: 426| Step: 0
Training loss: 0.18460993468761444
Validation loss: 1.524566415817507

Epoch: 5| Step: 1
Training loss: 0.1852739304304123
Validation loss: 1.5539292673910818

Epoch: 5| Step: 2
Training loss: 0.07334709167480469
Validation loss: 1.544808405701832

Epoch: 5| Step: 3
Training loss: 0.06980788707733154
Validation loss: 1.5615859864860453

Epoch: 5| Step: 4
Training loss: 0.20898409187793732
Validation loss: 1.5343846582597302

Epoch: 5| Step: 5
Training loss: 0.11071524769067764
Validation loss: 1.5548435109917835

Epoch: 5| Step: 6
Training loss: 0.08975476026535034
Validation loss: 1.5533261760588615

Epoch: 5| Step: 7
Training loss: 0.1329142153263092
Validation loss: 1.5443103749264953

Epoch: 5| Step: 8
Training loss: 0.08547503501176834
Validation loss: 1.5479052938440794

Epoch: 5| Step: 9
Training loss: 0.15758995711803436
Validation loss: 1.5197876166271906

Epoch: 5| Step: 10
Training loss: 0.15749181807041168
Validation loss: 1.496452316161125

Epoch: 427| Step: 0
Training loss: 0.08782743662595749
Validation loss: 1.4992521270628898

Epoch: 5| Step: 1
Training loss: 0.14814186096191406
Validation loss: 1.520914528959541

Epoch: 5| Step: 2
Training loss: 0.1578623503446579
Validation loss: 1.5079003405827347

Epoch: 5| Step: 3
Training loss: 0.19675308465957642
Validation loss: 1.534575379022988

Epoch: 5| Step: 4
Training loss: 0.11109665781259537
Validation loss: 1.5319461655873123

Epoch: 5| Step: 5
Training loss: 0.13769720494747162
Validation loss: 1.5423425923111618

Epoch: 5| Step: 6
Training loss: 0.09715045988559723
Validation loss: 1.5519127384308846

Epoch: 5| Step: 7
Training loss: 0.11914350092411041
Validation loss: 1.6008221583981668

Epoch: 5| Step: 8
Training loss: 0.13300642371177673
Validation loss: 1.5809429460956204

Epoch: 5| Step: 9
Training loss: 0.1274564564228058
Validation loss: 1.5836161182772728

Epoch: 5| Step: 10
Training loss: 0.1619735211133957
Validation loss: 1.5617429364112116

Epoch: 428| Step: 0
Training loss: 0.10766434669494629
Validation loss: 1.5406081791846984

Epoch: 5| Step: 1
Training loss: 0.18064270913600922
Validation loss: 1.5243493305739535

Epoch: 5| Step: 2
Training loss: 0.14991304278373718
Validation loss: 1.5048386499445925

Epoch: 5| Step: 3
Training loss: 0.13358652591705322
Validation loss: 1.490077631447905

Epoch: 5| Step: 4
Training loss: 0.09843134880065918
Validation loss: 1.4960270158706173

Epoch: 5| Step: 5
Training loss: 0.14717788994312286
Validation loss: 1.4947998664712394

Epoch: 5| Step: 6
Training loss: 0.0683528333902359
Validation loss: 1.4964406996644952

Epoch: 5| Step: 7
Training loss: 0.18065650761127472
Validation loss: 1.5277336797406595

Epoch: 5| Step: 8
Training loss: 0.16681000590324402
Validation loss: 1.5318933199810725

Epoch: 5| Step: 9
Training loss: 0.08536131680011749
Validation loss: 1.566122498563541

Epoch: 5| Step: 10
Training loss: 0.05893752723932266
Validation loss: 1.5480448815130419

Epoch: 429| Step: 0
Training loss: 0.06491007655858994
Validation loss: 1.564898439632949

Epoch: 5| Step: 1
Training loss: 0.09195776283740997
Validation loss: 1.5714139028262066

Epoch: 5| Step: 2
Training loss: 0.11009826511144638
Validation loss: 1.5625329645731116

Epoch: 5| Step: 3
Training loss: 0.10704205930233002
Validation loss: 1.5491998644285305

Epoch: 5| Step: 4
Training loss: 0.1411397010087967
Validation loss: 1.5537246837410876

Epoch: 5| Step: 5
Training loss: 0.16203323006629944
Validation loss: 1.5328649038909583

Epoch: 5| Step: 6
Training loss: 0.09637534618377686
Validation loss: 1.5436887843634493

Epoch: 5| Step: 7
Training loss: 0.1104089766740799
Validation loss: 1.5343301219324912

Epoch: 5| Step: 8
Training loss: 0.07913843542337418
Validation loss: 1.5153216585036247

Epoch: 5| Step: 9
Training loss: 0.08569744229316711
Validation loss: 1.4977590319930867

Epoch: 5| Step: 10
Training loss: 0.2653115391731262
Validation loss: 1.5022903962801861

Epoch: 430| Step: 0
Training loss: 0.12569385766983032
Validation loss: 1.5198755456555275

Epoch: 5| Step: 1
Training loss: 0.11554689705371857
Validation loss: 1.5164239701404367

Epoch: 5| Step: 2
Training loss: 0.16047462821006775
Validation loss: 1.5440833068663073

Epoch: 5| Step: 3
Training loss: 0.10267641395330429
Validation loss: 1.552919530099438

Epoch: 5| Step: 4
Training loss: 0.08389626443386078
Validation loss: 1.5309053082619943

Epoch: 5| Step: 5
Training loss: 0.07888813316822052
Validation loss: 1.5190407794008973

Epoch: 5| Step: 6
Training loss: 0.17362956702709198
Validation loss: 1.5007109988120295

Epoch: 5| Step: 7
Training loss: 0.07965558767318726
Validation loss: 1.5058600876920967

Epoch: 5| Step: 8
Training loss: 0.10271430015563965
Validation loss: 1.4994235480985334

Epoch: 5| Step: 9
Training loss: 0.13677023351192474
Validation loss: 1.5042143496133948

Epoch: 5| Step: 10
Training loss: 0.2200959175825119
Validation loss: 1.5133524017949258

Epoch: 431| Step: 0
Training loss: 0.155390664935112
Validation loss: 1.5186196552809847

Epoch: 5| Step: 1
Training loss: 0.11350999027490616
Validation loss: 1.5249244628414031

Epoch: 5| Step: 2
Training loss: 0.10835178196430206
Validation loss: 1.570160719656175

Epoch: 5| Step: 3
Training loss: 0.22998249530792236
Validation loss: 1.5459895044244745

Epoch: 5| Step: 4
Training loss: 0.27586859464645386
Validation loss: 1.5451984841336486

Epoch: 5| Step: 5
Training loss: 0.1140846237540245
Validation loss: 1.5432560366968955

Epoch: 5| Step: 6
Training loss: 0.09687920659780502
Validation loss: 1.5062368018652803

Epoch: 5| Step: 7
Training loss: 0.10214154422283173
Validation loss: 1.4640802837187243

Epoch: 5| Step: 8
Training loss: 0.14000749588012695
Validation loss: 1.4716837726613528

Epoch: 5| Step: 9
Training loss: 0.09443862736225128
Validation loss: 1.4369954204046598

Epoch: 5| Step: 10
Training loss: 0.13922470808029175
Validation loss: 1.4466245200044365

Epoch: 432| Step: 0
Training loss: 0.10333012044429779
Validation loss: 1.4482793884892617

Epoch: 5| Step: 1
Training loss: 0.10079524666070938
Validation loss: 1.4941731332450785

Epoch: 5| Step: 2
Training loss: 0.1173236146569252
Validation loss: 1.498917245095776

Epoch: 5| Step: 3
Training loss: 0.08251895010471344
Validation loss: 1.5244985780408304

Epoch: 5| Step: 4
Training loss: 0.08640407025814056
Validation loss: 1.5557289469626643

Epoch: 5| Step: 5
Training loss: 0.13363781571388245
Validation loss: 1.5495808996180052

Epoch: 5| Step: 6
Training loss: 0.08291511237621307
Validation loss: 1.5565075528237127

Epoch: 5| Step: 7
Training loss: 0.08374935388565063
Validation loss: 1.568662057640732

Epoch: 5| Step: 8
Training loss: 0.1239822655916214
Validation loss: 1.5338376158027238

Epoch: 5| Step: 9
Training loss: 0.13065609335899353
Validation loss: 1.5173713417463406

Epoch: 5| Step: 10
Training loss: 0.2476215958595276
Validation loss: 1.497990204441932

Epoch: 433| Step: 0
Training loss: 0.11489224433898926
Validation loss: 1.4892082163082656

Epoch: 5| Step: 1
Training loss: 0.15086697041988373
Validation loss: 1.5453867015018259

Epoch: 5| Step: 2
Training loss: 0.14705890417099
Validation loss: 1.5050113188323153

Epoch: 5| Step: 3
Training loss: 0.21067747473716736
Validation loss: 1.540721727955726

Epoch: 5| Step: 4
Training loss: 0.10124006122350693
Validation loss: 1.5496494757231845

Epoch: 5| Step: 5
Training loss: 0.12821030616760254
Validation loss: 1.529976958869606

Epoch: 5| Step: 6
Training loss: 0.1450074017047882
Validation loss: 1.5139263855513705

Epoch: 5| Step: 7
Training loss: 0.12768536806106567
Validation loss: 1.5093856524395686

Epoch: 5| Step: 8
Training loss: 0.12895706295967102
Validation loss: 1.501758308820827

Epoch: 5| Step: 9
Training loss: 0.09119676053524017
Validation loss: 1.4802772204081218

Epoch: 5| Step: 10
Training loss: 0.10576470196247101
Validation loss: 1.5032063722610474

Epoch: 434| Step: 0
Training loss: 0.10566110908985138
Validation loss: 1.4792963715009793

Epoch: 5| Step: 1
Training loss: 0.10647952556610107
Validation loss: 1.5099248347743865

Epoch: 5| Step: 2
Training loss: 0.10985203832387924
Validation loss: 1.5154948055103261

Epoch: 5| Step: 3
Training loss: 0.1346786767244339
Validation loss: 1.5451887974175074

Epoch: 5| Step: 4
Training loss: 0.11268346011638641
Validation loss: 1.5487537095623631

Epoch: 5| Step: 5
Training loss: 0.19108609855175018
Validation loss: 1.527075699580613

Epoch: 5| Step: 6
Training loss: 0.12913236021995544
Validation loss: 1.5268452616148098

Epoch: 5| Step: 7
Training loss: 0.09020054340362549
Validation loss: 1.5470728194841774

Epoch: 5| Step: 8
Training loss: 0.1823105365037918
Validation loss: 1.5581186663719915

Epoch: 5| Step: 9
Training loss: 0.13838668167591095
Validation loss: 1.5510103779454385

Epoch: 5| Step: 10
Training loss: 0.2143508791923523
Validation loss: 1.555029212787587

Epoch: 435| Step: 0
Training loss: 0.08425522595643997
Validation loss: 1.5571127835140433

Epoch: 5| Step: 1
Training loss: 0.14189815521240234
Validation loss: 1.6070051065055273

Epoch: 5| Step: 2
Training loss: 0.21571417152881622
Validation loss: 1.6353361914234776

Epoch: 5| Step: 3
Training loss: 0.25372689962387085
Validation loss: 1.6823627051486765

Epoch: 5| Step: 4
Training loss: 0.3051964342594147
Validation loss: 1.6766636525430987

Epoch: 5| Step: 5
Training loss: 0.1305655539035797
Validation loss: 1.6365955196401125

Epoch: 5| Step: 6
Training loss: 0.11032972484827042
Validation loss: 1.5665542925557783

Epoch: 5| Step: 7
Training loss: 0.17695510387420654
Validation loss: 1.526382787253267

Epoch: 5| Step: 8
Training loss: 0.20990462601184845
Validation loss: 1.5009905099868774

Epoch: 5| Step: 9
Training loss: 0.16819480061531067
Validation loss: 1.4685668586402811

Epoch: 5| Step: 10
Training loss: 0.08392021059989929
Validation loss: 1.492754860590863

Epoch: 436| Step: 0
Training loss: 0.08270187675952911
Validation loss: 1.4874862394025248

Epoch: 5| Step: 1
Training loss: 0.15750333666801453
Validation loss: 1.4866115758495946

Epoch: 5| Step: 2
Training loss: 0.132356196641922
Validation loss: 1.5138110729955858

Epoch: 5| Step: 3
Training loss: 0.18890267610549927
Validation loss: 1.5404177840038011

Epoch: 5| Step: 4
Training loss: 0.10013917833566666
Validation loss: 1.54588915968454

Epoch: 5| Step: 5
Training loss: 0.09955267608165741
Validation loss: 1.5532180519514187

Epoch: 5| Step: 6
Training loss: 0.15353281795978546
Validation loss: 1.5541823666582826

Epoch: 5| Step: 7
Training loss: 0.07497411966323853
Validation loss: 1.563974065165366

Epoch: 5| Step: 8
Training loss: 0.12866584956645966
Validation loss: 1.5848067627158215

Epoch: 5| Step: 9
Training loss: 0.22469666600227356
Validation loss: 1.5965423865984845

Epoch: 5| Step: 10
Training loss: 0.10501661151647568
Validation loss: 1.5903091936983087

Epoch: 437| Step: 0
Training loss: 0.1457517147064209
Validation loss: 1.597541351472178

Epoch: 5| Step: 1
Training loss: 0.07331571727991104
Validation loss: 1.6102697349363757

Epoch: 5| Step: 2
Training loss: 0.11154691874980927
Validation loss: 1.5890455399790118

Epoch: 5| Step: 3
Training loss: 0.16664519906044006
Validation loss: 1.5668099323908489

Epoch: 5| Step: 4
Training loss: 0.1924121081829071
Validation loss: 1.5754718677971953

Epoch: 5| Step: 5
Training loss: 0.08785746991634369
Validation loss: 1.5775857625469085

Epoch: 5| Step: 6
Training loss: 0.0863402858376503
Validation loss: 1.5649180053382792

Epoch: 5| Step: 7
Training loss: 0.11404474079608917
Validation loss: 1.5818699482948548

Epoch: 5| Step: 8
Training loss: 0.10886716842651367
Validation loss: 1.533579323881416

Epoch: 5| Step: 9
Training loss: 0.1955113708972931
Validation loss: 1.5536305289114676

Epoch: 5| Step: 10
Training loss: 0.16478320956230164
Validation loss: 1.5210602770569503

Epoch: 438| Step: 0
Training loss: 0.15924401581287384
Validation loss: 1.515933504668615

Epoch: 5| Step: 1
Training loss: 0.1110016331076622
Validation loss: 1.5036580216500066

Epoch: 5| Step: 2
Training loss: 0.17976628243923187
Validation loss: 1.5122221234024211

Epoch: 5| Step: 3
Training loss: 0.13886642456054688
Validation loss: 1.508540980277523

Epoch: 5| Step: 4
Training loss: 0.1110975369811058
Validation loss: 1.5317556717062508

Epoch: 5| Step: 5
Training loss: 0.144632026553154
Validation loss: 1.52391476784983

Epoch: 5| Step: 6
Training loss: 0.13845843076705933
Validation loss: 1.5337630036056682

Epoch: 5| Step: 7
Training loss: 0.12000962346792221
Validation loss: 1.5385343669563212

Epoch: 5| Step: 8
Training loss: 0.06927646696567535
Validation loss: 1.5214064037928017

Epoch: 5| Step: 9
Training loss: 0.07632286846637726
Validation loss: 1.5049512924686554

Epoch: 5| Step: 10
Training loss: 0.111947201192379
Validation loss: 1.5245056383071407

Epoch: 439| Step: 0
Training loss: 0.15289108455181122
Validation loss: 1.5240580651067919

Epoch: 5| Step: 1
Training loss: 0.11056701093912125
Validation loss: 1.5452084041410876

Epoch: 5| Step: 2
Training loss: 0.10626661777496338
Validation loss: 1.5209560958288049

Epoch: 5| Step: 3
Training loss: 0.17497554421424866
Validation loss: 1.5225673311500139

Epoch: 5| Step: 4
Training loss: 0.1690736711025238
Validation loss: 1.530224770627996

Epoch: 5| Step: 5
Training loss: 0.15463010966777802
Validation loss: 1.4992883641232726

Epoch: 5| Step: 6
Training loss: 0.1391308605670929
Validation loss: 1.4682587679996286

Epoch: 5| Step: 7
Training loss: 0.07081533223390579
Validation loss: 1.4702562362917009

Epoch: 5| Step: 8
Training loss: 0.11151192337274551
Validation loss: 1.4575801741692327

Epoch: 5| Step: 9
Training loss: 0.1619129329919815
Validation loss: 1.4614076742561914

Epoch: 5| Step: 10
Training loss: 0.1075681746006012
Validation loss: 1.4422293427169963

Epoch: 440| Step: 0
Training loss: 0.15498223900794983
Validation loss: 1.4823479575495566

Epoch: 5| Step: 1
Training loss: 0.08769021183252335
Validation loss: 1.5124781183017197

Epoch: 5| Step: 2
Training loss: 0.08459104597568512
Validation loss: 1.5330761850521128

Epoch: 5| Step: 3
Training loss: 0.10063047707080841
Validation loss: 1.5556793981982815

Epoch: 5| Step: 4
Training loss: 0.0727413073182106
Validation loss: 1.5577168618479083

Epoch: 5| Step: 5
Training loss: 0.13440576195716858
Validation loss: 1.5375900191645469

Epoch: 5| Step: 6
Training loss: 0.08543697744607925
Validation loss: 1.5351743698120117

Epoch: 5| Step: 7
Training loss: 0.16243673861026764
Validation loss: 1.5530680379559916

Epoch: 5| Step: 8
Training loss: 0.12332101166248322
Validation loss: 1.558076172746638

Epoch: 5| Step: 9
Training loss: 0.09194928407669067
Validation loss: 1.5546613316382132

Epoch: 5| Step: 10
Training loss: 0.24705976247787476
Validation loss: 1.5499439483047814

Epoch: 441| Step: 0
Training loss: 0.15699701011180878
Validation loss: 1.5364121749836912

Epoch: 5| Step: 1
Training loss: 0.0797160416841507
Validation loss: 1.5199694838575137

Epoch: 5| Step: 2
Training loss: 0.12433655560016632
Validation loss: 1.5289286516046012

Epoch: 5| Step: 3
Training loss: 0.06763727217912674
Validation loss: 1.5151429586513068

Epoch: 5| Step: 4
Training loss: 0.18043218553066254
Validation loss: 1.5103679113490607

Epoch: 5| Step: 5
Training loss: 0.13094428181648254
Validation loss: 1.5236766697258077

Epoch: 5| Step: 6
Training loss: 0.08307721465826035
Validation loss: 1.502235818934697

Epoch: 5| Step: 7
Training loss: 0.08115490525960922
Validation loss: 1.5294415386774207

Epoch: 5| Step: 8
Training loss: 0.1980559527873993
Validation loss: 1.5096718906074442

Epoch: 5| Step: 9
Training loss: 0.07864999771118164
Validation loss: 1.526161996267175

Epoch: 5| Step: 10
Training loss: 0.17443926632404327
Validation loss: 1.5300392591825096

Epoch: 442| Step: 0
Training loss: 0.15433518588542938
Validation loss: 1.5272362520617824

Epoch: 5| Step: 1
Training loss: 0.10556533187627792
Validation loss: 1.525159909520098

Epoch: 5| Step: 2
Training loss: 0.17948317527770996
Validation loss: 1.5186694591276106

Epoch: 5| Step: 3
Training loss: 0.13787712156772614
Validation loss: 1.5087644759044851

Epoch: 5| Step: 4
Training loss: 0.0958482101559639
Validation loss: 1.5225779394949637

Epoch: 5| Step: 5
Training loss: 0.10412393510341644
Validation loss: 1.5091269971222006

Epoch: 5| Step: 6
Training loss: 0.12743067741394043
Validation loss: 1.5645871777688303

Epoch: 5| Step: 7
Training loss: 0.23746883869171143
Validation loss: 1.5519468348513368

Epoch: 5| Step: 8
Training loss: 0.1651029735803604
Validation loss: 1.5178038484306746

Epoch: 5| Step: 9
Training loss: 0.15050294995307922
Validation loss: 1.5122416647531653

Epoch: 5| Step: 10
Training loss: 0.11334124207496643
Validation loss: 1.4628281888141428

Epoch: 443| Step: 0
Training loss: 0.1518133133649826
Validation loss: 1.492018356118151

Epoch: 5| Step: 1
Training loss: 0.1567787379026413
Validation loss: 1.4910836181332987

Epoch: 5| Step: 2
Training loss: 0.12377265840768814
Validation loss: 1.4858010302307785

Epoch: 5| Step: 3
Training loss: 0.18758058547973633
Validation loss: 1.4884340481091571

Epoch: 5| Step: 4
Training loss: 0.18924295902252197
Validation loss: 1.494902588987863

Epoch: 5| Step: 5
Training loss: 0.143122598528862
Validation loss: 1.4942966327872327

Epoch: 5| Step: 6
Training loss: 0.13341811299324036
Validation loss: 1.5006828936197425

Epoch: 5| Step: 7
Training loss: 0.12003852427005768
Validation loss: 1.5078315241362459

Epoch: 5| Step: 8
Training loss: 0.1835779994726181
Validation loss: 1.522744663940963

Epoch: 5| Step: 9
Training loss: 0.11590136587619781
Validation loss: 1.480365781373875

Epoch: 5| Step: 10
Training loss: 0.08123886585235596
Validation loss: 1.4645538701806018

Epoch: 444| Step: 0
Training loss: 0.11342991888523102
Validation loss: 1.4564994945321033

Epoch: 5| Step: 1
Training loss: 0.17219607532024384
Validation loss: 1.4628016762836005

Epoch: 5| Step: 2
Training loss: 0.09929624199867249
Validation loss: 1.5058068947125507

Epoch: 5| Step: 3
Training loss: 0.13678450882434845
Validation loss: 1.500125273581474

Epoch: 5| Step: 4
Training loss: 0.1512889564037323
Validation loss: 1.5330765875436927

Epoch: 5| Step: 5
Training loss: 0.09010843932628632
Validation loss: 1.546354140004804

Epoch: 5| Step: 6
Training loss: 0.1356021612882614
Validation loss: 1.5323952628720192

Epoch: 5| Step: 7
Training loss: 0.1176871657371521
Validation loss: 1.5448046948320122

Epoch: 5| Step: 8
Training loss: 0.18790991604328156
Validation loss: 1.5540986727642756

Epoch: 5| Step: 9
Training loss: 0.10064513981342316
Validation loss: 1.547314941242177

Epoch: 5| Step: 10
Training loss: 0.12804710865020752
Validation loss: 1.5236322546517977

Epoch: 445| Step: 0
Training loss: 0.049527838826179504
Validation loss: 1.5158074889131772

Epoch: 5| Step: 1
Training loss: 0.16431792080402374
Validation loss: 1.4959154641756447

Epoch: 5| Step: 2
Training loss: 0.1978953331708908
Validation loss: 1.4964503049850464

Epoch: 5| Step: 3
Training loss: 0.19157758355140686
Validation loss: 1.4539276675511432

Epoch: 5| Step: 4
Training loss: 0.12755225598812103
Validation loss: 1.4535965816949004

Epoch: 5| Step: 5
Training loss: 0.1359778195619583
Validation loss: 1.4452090827367639

Epoch: 5| Step: 6
Training loss: 0.1331201195716858
Validation loss: 1.4679131059236423

Epoch: 5| Step: 7
Training loss: 0.18698552250862122
Validation loss: 1.4720390022441905

Epoch: 5| Step: 8
Training loss: 0.10464273393154144
Validation loss: 1.4802988556123549

Epoch: 5| Step: 9
Training loss: 0.1291700303554535
Validation loss: 1.470380102434466

Epoch: 5| Step: 10
Training loss: 0.11705347895622253
Validation loss: 1.5038157893765358

Epoch: 446| Step: 0
Training loss: 0.12008778750896454
Validation loss: 1.5174195561357724

Epoch: 5| Step: 1
Training loss: 0.08310236036777496
Validation loss: 1.5321754114602202

Epoch: 5| Step: 2
Training loss: 0.11412511765956879
Validation loss: 1.5378543523050123

Epoch: 5| Step: 3
Training loss: 0.08656531572341919
Validation loss: 1.5225626178967056

Epoch: 5| Step: 4
Training loss: 0.07635113596916199
Validation loss: 1.5408108529224191

Epoch: 5| Step: 5
Training loss: 0.1888156682252884
Validation loss: 1.5443545887547154

Epoch: 5| Step: 6
Training loss: 0.1184546947479248
Validation loss: 1.5324772070812922

Epoch: 5| Step: 7
Training loss: 0.07502315193414688
Validation loss: 1.5542097912039807

Epoch: 5| Step: 8
Training loss: 0.11341756582260132
Validation loss: 1.5489068838857836

Epoch: 5| Step: 9
Training loss: 0.19315406680107117
Validation loss: 1.5548478787945164

Epoch: 5| Step: 10
Training loss: 0.0597861148416996
Validation loss: 1.5322168193837649

Epoch: 447| Step: 0
Training loss: 0.07968907058238983
Validation loss: 1.5479461070029967

Epoch: 5| Step: 1
Training loss: 0.1222083792090416
Validation loss: 1.4964205129172212

Epoch: 5| Step: 2
Training loss: 0.13076236844062805
Validation loss: 1.5241121143423102

Epoch: 5| Step: 3
Training loss: 0.07463719695806503
Validation loss: 1.4890837643736152

Epoch: 5| Step: 4
Training loss: 0.07923638075590134
Validation loss: 1.5004475462821223

Epoch: 5| Step: 5
Training loss: 0.1048535704612732
Validation loss: 1.4883807961658766

Epoch: 5| Step: 6
Training loss: 0.06990157812833786
Validation loss: 1.4972125945552703

Epoch: 5| Step: 7
Training loss: 0.2123018056154251
Validation loss: 1.4737297193978423

Epoch: 5| Step: 8
Training loss: 0.08259022980928421
Validation loss: 1.4941307806199597

Epoch: 5| Step: 9
Training loss: 0.13244560360908508
Validation loss: 1.4869380086980841

Epoch: 5| Step: 10
Training loss: 0.18098966777324677
Validation loss: 1.498212445166803

Epoch: 448| Step: 0
Training loss: 0.10037567466497421
Validation loss: 1.485401790629151

Epoch: 5| Step: 1
Training loss: 0.07340501993894577
Validation loss: 1.5097737152089354

Epoch: 5| Step: 2
Training loss: 0.08714441955089569
Validation loss: 1.491847224132989

Epoch: 5| Step: 3
Training loss: 0.14087016880512238
Validation loss: 1.4926048363408735

Epoch: 5| Step: 4
Training loss: 0.11051420122385025
Validation loss: 1.4998470467905844

Epoch: 5| Step: 5
Training loss: 0.12026027590036392
Validation loss: 1.493057526567931

Epoch: 5| Step: 6
Training loss: 0.12888102233409882
Validation loss: 1.4957731782749135

Epoch: 5| Step: 7
Training loss: 0.08754207193851471
Validation loss: 1.5198990350128503

Epoch: 5| Step: 8
Training loss: 0.07557321339845657
Validation loss: 1.4856826797608407

Epoch: 5| Step: 9
Training loss: 0.09127874672412872
Validation loss: 1.4871132284082391

Epoch: 5| Step: 10
Training loss: 0.21544979512691498
Validation loss: 1.465280245709163

Epoch: 449| Step: 0
Training loss: 0.12692700326442719
Validation loss: 1.4744055133352998

Epoch: 5| Step: 1
Training loss: 0.0772932916879654
Validation loss: 1.4683936154970558

Epoch: 5| Step: 2
Training loss: 0.1475481539964676
Validation loss: 1.4824239284761491

Epoch: 5| Step: 3
Training loss: 0.1293182224035263
Validation loss: 1.4645585962521133

Epoch: 5| Step: 4
Training loss: 0.19941028952598572
Validation loss: 1.5113410078069216

Epoch: 5| Step: 5
Training loss: 0.10155057907104492
Validation loss: 1.4901684817447458

Epoch: 5| Step: 6
Training loss: 0.11046488583087921
Validation loss: 1.4989400858520179

Epoch: 5| Step: 7
Training loss: 0.12168131023645401
Validation loss: 1.5133759744705693

Epoch: 5| Step: 8
Training loss: 0.12056656181812286
Validation loss: 1.542862476841096

Epoch: 5| Step: 9
Training loss: 0.0822284147143364
Validation loss: 1.5504657081378403

Epoch: 5| Step: 10
Training loss: 0.1372849941253662
Validation loss: 1.5613808196078065

Epoch: 450| Step: 0
Training loss: 0.1540517359972
Validation loss: 1.5369614298625658

Epoch: 5| Step: 1
Training loss: 0.11013314872980118
Validation loss: 1.5413093169530232

Epoch: 5| Step: 2
Training loss: 0.21938788890838623
Validation loss: 1.5525182857308337

Epoch: 5| Step: 3
Training loss: 0.09364473074674606
Validation loss: 1.5300808811700473

Epoch: 5| Step: 4
Training loss: 0.10684919357299805
Validation loss: 1.5451284044532365

Epoch: 5| Step: 5
Training loss: 0.16136066615581512
Validation loss: 1.5246486086999216

Epoch: 5| Step: 6
Training loss: 0.09716351330280304
Validation loss: 1.5375799299568258

Epoch: 5| Step: 7
Training loss: 0.13733741641044617
Validation loss: 1.535031795501709

Epoch: 5| Step: 8
Training loss: 0.0926525890827179
Validation loss: 1.5382308280596169

Epoch: 5| Step: 9
Training loss: 0.1371084451675415
Validation loss: 1.5102888999446746

Epoch: 5| Step: 10
Training loss: 0.11339812725782394
Validation loss: 1.5035792576369418

Epoch: 451| Step: 0
Training loss: 0.12050771713256836
Validation loss: 1.494981768310711

Epoch: 5| Step: 1
Training loss: 0.15187375247478485
Validation loss: 1.4794074335405905

Epoch: 5| Step: 2
Training loss: 0.12395955622196198
Validation loss: 1.503961028591279

Epoch: 5| Step: 3
Training loss: 0.183858722448349
Validation loss: 1.5088695710705173

Epoch: 5| Step: 4
Training loss: 0.18085239827632904
Validation loss: 1.4994737012411958

Epoch: 5| Step: 5
Training loss: 0.14030826091766357
Validation loss: 1.4659973972587175

Epoch: 5| Step: 6
Training loss: 0.07292938232421875
Validation loss: 1.4605186626475344

Epoch: 5| Step: 7
Training loss: 0.0924491137266159
Validation loss: 1.45476794627405

Epoch: 5| Step: 8
Training loss: 0.12946847081184387
Validation loss: 1.4577787903047377

Epoch: 5| Step: 9
Training loss: 0.11576284468173981
Validation loss: 1.4759306779471777

Epoch: 5| Step: 10
Training loss: 0.10638758540153503
Validation loss: 1.4616451622337423

Epoch: 452| Step: 0
Training loss: 0.08611715584993362
Validation loss: 1.4895668939877582

Epoch: 5| Step: 1
Training loss: 0.0801275447010994
Validation loss: 1.508546345977373

Epoch: 5| Step: 2
Training loss: 0.0955013781785965
Validation loss: 1.5273795230414278

Epoch: 5| Step: 3
Training loss: 0.1064508706331253
Validation loss: 1.5395591451275734

Epoch: 5| Step: 4
Training loss: 0.07045544683933258
Validation loss: 1.5464749054242206

Epoch: 5| Step: 5
Training loss: 0.08673691749572754
Validation loss: 1.543122068528206

Epoch: 5| Step: 6
Training loss: 0.08068374544382095
Validation loss: 1.5346966315341253

Epoch: 5| Step: 7
Training loss: 0.1646224856376648
Validation loss: 1.5404923474916847

Epoch: 5| Step: 8
Training loss: 0.1401197612285614
Validation loss: 1.5112700116249822

Epoch: 5| Step: 9
Training loss: 0.1723276674747467
Validation loss: 1.5340397127213017

Epoch: 5| Step: 10
Training loss: 0.07793250679969788
Validation loss: 1.5284030655378937

Epoch: 453| Step: 0
Training loss: 0.11188837140798569
Validation loss: 1.519174269450608

Epoch: 5| Step: 1
Training loss: 0.13096687197685242
Validation loss: 1.5498825337297173

Epoch: 5| Step: 2
Training loss: 0.13722917437553406
Validation loss: 1.516118147039926

Epoch: 5| Step: 3
Training loss: 0.08808942884206772
Validation loss: 1.510673499876453

Epoch: 5| Step: 4
Training loss: 0.11686189472675323
Validation loss: 1.467706395733741

Epoch: 5| Step: 5
Training loss: 0.08000359684228897
Validation loss: 1.4778647538154357

Epoch: 5| Step: 6
Training loss: 0.06766852736473083
Validation loss: 1.4893191578567668

Epoch: 5| Step: 7
Training loss: 0.12522470951080322
Validation loss: 1.4730409076136928

Epoch: 5| Step: 8
Training loss: 0.09908877313137054
Validation loss: 1.4944115672060239

Epoch: 5| Step: 9
Training loss: 0.16433922946453094
Validation loss: 1.504026513586762

Epoch: 5| Step: 10
Training loss: 0.13497240841388702
Validation loss: 1.5164482798627628

Epoch: 454| Step: 0
Training loss: 0.05445820838212967
Validation loss: 1.5135068765250586

Epoch: 5| Step: 1
Training loss: 0.13877496123313904
Validation loss: 1.490272682200196

Epoch: 5| Step: 2
Training loss: 0.07054422795772552
Validation loss: 1.4601350740719867

Epoch: 5| Step: 3
Training loss: 0.11681387573480606
Validation loss: 1.4753969997488043

Epoch: 5| Step: 4
Training loss: 0.10365273058414459
Validation loss: 1.4897528322794105

Epoch: 5| Step: 5
Training loss: 0.1016889214515686
Validation loss: 1.4610770953598844

Epoch: 5| Step: 6
Training loss: 0.14915356040000916
Validation loss: 1.4764838974962953

Epoch: 5| Step: 7
Training loss: 0.04897413030266762
Validation loss: 1.4829832507717995

Epoch: 5| Step: 8
Training loss: 0.06190686300396919
Validation loss: 1.4957602985443608

Epoch: 5| Step: 9
Training loss: 0.1826590597629547
Validation loss: 1.5136169541266657

Epoch: 5| Step: 10
Training loss: 0.1445125788450241
Validation loss: 1.5175669846996185

Epoch: 455| Step: 0
Training loss: 0.10831179469823837
Validation loss: 1.5218090652137675

Epoch: 5| Step: 1
Training loss: 0.0924621969461441
Validation loss: 1.5068696929562477

Epoch: 5| Step: 2
Training loss: 0.09778876602649689
Validation loss: 1.5124834378560383

Epoch: 5| Step: 3
Training loss: 0.07111683487892151
Validation loss: 1.5017752339763026

Epoch: 5| Step: 4
Training loss: 0.06609318405389786
Validation loss: 1.4958836827226865

Epoch: 5| Step: 5
Training loss: 0.10013846307992935
Validation loss: 1.5032206607121292

Epoch: 5| Step: 6
Training loss: 0.06490475684404373
Validation loss: 1.4814258096038655

Epoch: 5| Step: 7
Training loss: 0.09534062445163727
Validation loss: 1.5241183401435934

Epoch: 5| Step: 8
Training loss: 0.16282565891742706
Validation loss: 1.5090441447432323

Epoch: 5| Step: 9
Training loss: 0.10987186431884766
Validation loss: 1.50681177390519

Epoch: 5| Step: 10
Training loss: 0.1319444477558136
Validation loss: 1.517226621668826

Epoch: 456| Step: 0
Training loss: 0.05622633546590805
Validation loss: 1.5280789739342147

Epoch: 5| Step: 1
Training loss: 0.09704916179180145
Validation loss: 1.5023782099446943

Epoch: 5| Step: 2
Training loss: 0.04703221470117569
Validation loss: 1.5112251530411422

Epoch: 5| Step: 3
Training loss: 0.1530442088842392
Validation loss: 1.5106454940252407

Epoch: 5| Step: 4
Training loss: 0.0747324526309967
Validation loss: 1.5335719803328156

Epoch: 5| Step: 5
Training loss: 0.18279686570167542
Validation loss: 1.5056955827179777

Epoch: 5| Step: 6
Training loss: 0.045497797429561615
Validation loss: 1.5237090369706512

Epoch: 5| Step: 7
Training loss: 0.0568351149559021
Validation loss: 1.5179222360734017

Epoch: 5| Step: 8
Training loss: 0.14874760806560516
Validation loss: 1.5339481599869267

Epoch: 5| Step: 9
Training loss: 0.1306808739900589
Validation loss: 1.5188659775641657

Epoch: 5| Step: 10
Training loss: 0.14083661139011383
Validation loss: 1.5250101384296213

Epoch: 457| Step: 0
Training loss: 0.0977359339594841
Validation loss: 1.5370111209090038

Epoch: 5| Step: 1
Training loss: 0.0834277793765068
Validation loss: 1.5477538980463499

Epoch: 5| Step: 2
Training loss: 0.10355353355407715
Validation loss: 1.5452394485473633

Epoch: 5| Step: 3
Training loss: 0.13059495389461517
Validation loss: 1.5363853977572532

Epoch: 5| Step: 4
Training loss: 0.12030742317438126
Validation loss: 1.5401524805253552

Epoch: 5| Step: 5
Training loss: 0.13528811931610107
Validation loss: 1.530702382005671

Epoch: 5| Step: 6
Training loss: 0.06895851343870163
Validation loss: 1.548823909092975

Epoch: 5| Step: 7
Training loss: 0.1825212687253952
Validation loss: 1.5249342995305215

Epoch: 5| Step: 8
Training loss: 0.078374482691288
Validation loss: 1.5393661209332046

Epoch: 5| Step: 9
Training loss: 0.17267736792564392
Validation loss: 1.544404968138664

Epoch: 5| Step: 10
Training loss: 0.15614798665046692
Validation loss: 1.5398786414054133

Epoch: 458| Step: 0
Training loss: 0.15460489690303802
Validation loss: 1.5271663076134139

Epoch: 5| Step: 1
Training loss: 0.061690978705883026
Validation loss: 1.5072948278919343

Epoch: 5| Step: 2
Training loss: 0.09117323160171509
Validation loss: 1.5040306173345095

Epoch: 5| Step: 3
Training loss: 0.13548114895820618
Validation loss: 1.4888626747233893

Epoch: 5| Step: 4
Training loss: 0.22162361443042755
Validation loss: 1.4912525838421238

Epoch: 5| Step: 5
Training loss: 0.1154993325471878
Validation loss: 1.505346909646065

Epoch: 5| Step: 6
Training loss: 0.09360812604427338
Validation loss: 1.522611210423131

Epoch: 5| Step: 7
Training loss: 0.08119376748800278
Validation loss: 1.552916456294316

Epoch: 5| Step: 8
Training loss: 0.1146448478102684
Validation loss: 1.5755824247996013

Epoch: 5| Step: 9
Training loss: 0.1552625596523285
Validation loss: 1.5771016536220428

Epoch: 5| Step: 10
Training loss: 0.06090757995843887
Validation loss: 1.5801375283989856

Epoch: 459| Step: 0
Training loss: 0.11703872680664062
Validation loss: 1.570878751816288

Epoch: 5| Step: 1
Training loss: 0.08149366080760956
Validation loss: 1.5810839899124638

Epoch: 5| Step: 2
Training loss: 0.14487382769584656
Validation loss: 1.5814458503518054

Epoch: 5| Step: 3
Training loss: 0.20692744851112366
Validation loss: 1.5554322299136911

Epoch: 5| Step: 4
Training loss: 0.1074562817811966
Validation loss: 1.5444314185009207

Epoch: 5| Step: 5
Training loss: 0.1088806539773941
Validation loss: 1.530244158160302

Epoch: 5| Step: 6
Training loss: 0.09343566000461578
Validation loss: 1.5266002211519467

Epoch: 5| Step: 7
Training loss: 0.08174306154251099
Validation loss: 1.5173444312105897

Epoch: 5| Step: 8
Training loss: 0.15508271753787994
Validation loss: 1.4956197905284103

Epoch: 5| Step: 9
Training loss: 0.13267679512500763
Validation loss: 1.5048459473476614

Epoch: 5| Step: 10
Training loss: 0.06533189117908478
Validation loss: 1.473726264892086

Epoch: 460| Step: 0
Training loss: 0.12958069145679474
Validation loss: 1.4901652002847323

Epoch: 5| Step: 1
Training loss: 0.07794646918773651
Validation loss: 1.4736915788342875

Epoch: 5| Step: 2
Training loss: 0.059927958995103836
Validation loss: 1.4772657335445445

Epoch: 5| Step: 3
Training loss: 0.13663944602012634
Validation loss: 1.5010034320175007

Epoch: 5| Step: 4
Training loss: 0.10986962169408798
Validation loss: 1.4985543617638208

Epoch: 5| Step: 5
Training loss: 0.15611129999160767
Validation loss: 1.496241569519043

Epoch: 5| Step: 6
Training loss: 0.08835407346487045
Validation loss: 1.5029095718937535

Epoch: 5| Step: 7
Training loss: 0.05261869356036186
Validation loss: 1.5123150784482238

Epoch: 5| Step: 8
Training loss: 0.0763804167509079
Validation loss: 1.5127089978546224

Epoch: 5| Step: 9
Training loss: 0.09457169473171234
Validation loss: 1.5258961544241956

Epoch: 5| Step: 10
Training loss: 0.09131260216236115
Validation loss: 1.5278805622490503

Epoch: 461| Step: 0
Training loss: 0.08614108711481094
Validation loss: 1.5372132780731365

Epoch: 5| Step: 1
Training loss: 0.10442342609167099
Validation loss: 1.530904798097508

Epoch: 5| Step: 2
Training loss: 0.18397745490074158
Validation loss: 1.5414300093086817

Epoch: 5| Step: 3
Training loss: 0.09281791746616364
Validation loss: 1.5236756596513974

Epoch: 5| Step: 4
Training loss: 0.105127714574337
Validation loss: 1.5212387192633845

Epoch: 5| Step: 5
Training loss: 0.07611517608165741
Validation loss: 1.5167719856385262

Epoch: 5| Step: 6
Training loss: 0.13379405438899994
Validation loss: 1.5370822555275374

Epoch: 5| Step: 7
Training loss: 0.10571865737438202
Validation loss: 1.5359659656401603

Epoch: 5| Step: 8
Training loss: 0.11504639685153961
Validation loss: 1.5201264914645944

Epoch: 5| Step: 9
Training loss: 0.0636330172419548
Validation loss: 1.4892564665886663

Epoch: 5| Step: 10
Training loss: 0.051335643976926804
Validation loss: 1.464977789309717

Epoch: 462| Step: 0
Training loss: 0.1169373020529747
Validation loss: 1.453565751352618

Epoch: 5| Step: 1
Training loss: 0.138649582862854
Validation loss: 1.4510780175526936

Epoch: 5| Step: 2
Training loss: 0.12329618632793427
Validation loss: 1.467699311112845

Epoch: 5| Step: 3
Training loss: 0.050605159252882004
Validation loss: 1.4838870122868528

Epoch: 5| Step: 4
Training loss: 0.059662114828825
Validation loss: 1.4881041947231497

Epoch: 5| Step: 5
Training loss: 0.16596361994743347
Validation loss: 1.5193045472586026

Epoch: 5| Step: 6
Training loss: 0.08200486749410629
Validation loss: 1.5221354243575886

Epoch: 5| Step: 7
Training loss: 0.0773295909166336
Validation loss: 1.509689425909391

Epoch: 5| Step: 8
Training loss: 0.08104066550731659
Validation loss: 1.5183555131317468

Epoch: 5| Step: 9
Training loss: 0.14678792655467987
Validation loss: 1.4900384622235452

Epoch: 5| Step: 10
Training loss: 0.09588486701250076
Validation loss: 1.505682711960167

Epoch: 463| Step: 0
Training loss: 0.14173784852027893
Validation loss: 1.509676024477969

Epoch: 5| Step: 1
Training loss: 0.18930880725383759
Validation loss: 1.506091626741553

Epoch: 5| Step: 2
Training loss: 0.09021198004484177
Validation loss: 1.498170857788414

Epoch: 5| Step: 3
Training loss: 0.06585436314344406
Validation loss: 1.4924098958251297

Epoch: 5| Step: 4
Training loss: 0.06426040828227997
Validation loss: 1.4972986380259197

Epoch: 5| Step: 5
Training loss: 0.061614446341991425
Validation loss: 1.5078324553787068

Epoch: 5| Step: 6
Training loss: 0.15784001350402832
Validation loss: 1.516712309211813

Epoch: 5| Step: 7
Training loss: 0.10804708302021027
Validation loss: 1.509011899271319

Epoch: 5| Step: 8
Training loss: 0.08213961124420166
Validation loss: 1.5016080269249537

Epoch: 5| Step: 9
Training loss: 0.03429100662469864
Validation loss: 1.4903572810593473

Epoch: 5| Step: 10
Training loss: 0.15754759311676025
Validation loss: 1.5072333364076511

Epoch: 464| Step: 0
Training loss: 0.04462229833006859
Validation loss: 1.4735882794985207

Epoch: 5| Step: 1
Training loss: 0.13137856125831604
Validation loss: 1.4740861359462942

Epoch: 5| Step: 2
Training loss: 0.07684303820133209
Validation loss: 1.4805665451993224

Epoch: 5| Step: 3
Training loss: 0.08937867730855942
Validation loss: 1.4840592786829958

Epoch: 5| Step: 4
Training loss: 0.10080206394195557
Validation loss: 1.5050157000941615

Epoch: 5| Step: 5
Training loss: 0.04851280525326729
Validation loss: 1.4935318398219284

Epoch: 5| Step: 6
Training loss: 0.09627790004014969
Validation loss: 1.5180754648741854

Epoch: 5| Step: 7
Training loss: 0.15377573668956757
Validation loss: 1.4909506356844338

Epoch: 5| Step: 8
Training loss: 0.1082821935415268
Validation loss: 1.4850529547660583

Epoch: 5| Step: 9
Training loss: 0.08181078732013702
Validation loss: 1.4879942728627114

Epoch: 5| Step: 10
Training loss: 0.14002959430217743
Validation loss: 1.4512388962571339

Epoch: 465| Step: 0
Training loss: 0.09511061757802963
Validation loss: 1.4873012086396575

Epoch: 5| Step: 1
Training loss: 0.08923684060573578
Validation loss: 1.467892974935552

Epoch: 5| Step: 2
Training loss: 0.04860129952430725
Validation loss: 1.5041585019839707

Epoch: 5| Step: 3
Training loss: 0.07098229229450226
Validation loss: 1.492807622878782

Epoch: 5| Step: 4
Training loss: 0.0564488060772419
Validation loss: 1.5042646905427337

Epoch: 5| Step: 5
Training loss: 0.15857383608818054
Validation loss: 1.5287136788009315

Epoch: 5| Step: 6
Training loss: 0.10166428238153458
Validation loss: 1.5484782662442935

Epoch: 5| Step: 7
Training loss: 0.12201257050037384
Validation loss: 1.5157916251049246

Epoch: 5| Step: 8
Training loss: 0.07405096292495728
Validation loss: 1.5038675358218532

Epoch: 5| Step: 9
Training loss: 0.13150137662887573
Validation loss: 1.4849881856672225

Epoch: 5| Step: 10
Training loss: 0.10479364544153214
Validation loss: 1.4681243383756248

Epoch: 466| Step: 0
Training loss: 0.04971807450056076
Validation loss: 1.464051108206472

Epoch: 5| Step: 1
Training loss: 0.12743139266967773
Validation loss: 1.4470223560128161

Epoch: 5| Step: 2
Training loss: 0.11942070722579956
Validation loss: 1.463508043878822

Epoch: 5| Step: 3
Training loss: 0.12091121822595596
Validation loss: 1.4751697471064906

Epoch: 5| Step: 4
Training loss: 0.12974247336387634
Validation loss: 1.4779949675324142

Epoch: 5| Step: 5
Training loss: 0.10049319267272949
Validation loss: 1.4936556264918337

Epoch: 5| Step: 6
Training loss: 0.05412381887435913
Validation loss: 1.5097942249749297

Epoch: 5| Step: 7
Training loss: 0.1544405072927475
Validation loss: 1.5007785776610016

Epoch: 5| Step: 8
Training loss: 0.060486454516649246
Validation loss: 1.5184856294303812

Epoch: 5| Step: 9
Training loss: 0.07008163630962372
Validation loss: 1.5149821107105543

Epoch: 5| Step: 10
Training loss: 0.05416567996144295
Validation loss: 1.5307162141287198

Epoch: 467| Step: 0
Training loss: 0.10993187129497528
Validation loss: 1.537364972535

Epoch: 5| Step: 1
Training loss: 0.12644799053668976
Validation loss: 1.5358308925423572

Epoch: 5| Step: 2
Training loss: 0.06004682183265686
Validation loss: 1.5283466167347406

Epoch: 5| Step: 3
Training loss: 0.08278460800647736
Validation loss: 1.517712035486775

Epoch: 5| Step: 4
Training loss: 0.08612910658121109
Validation loss: 1.5250115138228222

Epoch: 5| Step: 5
Training loss: 0.128668412566185
Validation loss: 1.5100139225682905

Epoch: 5| Step: 6
Training loss: 0.09241657704114914
Validation loss: 1.5046390448847125

Epoch: 5| Step: 7
Training loss: 0.07016261667013168
Validation loss: 1.5002867637142059

Epoch: 5| Step: 8
Training loss: 0.17899012565612793
Validation loss: 1.5183009357862576

Epoch: 5| Step: 9
Training loss: 0.06532980501651764
Validation loss: 1.5035830069613714

Epoch: 5| Step: 10
Training loss: 0.12366928905248642
Validation loss: 1.5171245374987203

Epoch: 468| Step: 0
Training loss: 0.09144993871450424
Validation loss: 1.533116348328129

Epoch: 5| Step: 1
Training loss: 0.09479857981204987
Validation loss: 1.544936776802104

Epoch: 5| Step: 2
Training loss: 0.10027675330638885
Validation loss: 1.5188239120667981

Epoch: 5| Step: 3
Training loss: 0.04378928244113922
Validation loss: 1.551662455322922

Epoch: 5| Step: 4
Training loss: 0.09847794473171234
Validation loss: 1.532695649772562

Epoch: 5| Step: 5
Training loss: 0.1479242742061615
Validation loss: 1.5311091574289466

Epoch: 5| Step: 6
Training loss: 0.1608252376317978
Validation loss: 1.5130265566610521

Epoch: 5| Step: 7
Training loss: 0.06715106219053268
Validation loss: 1.4962176251155075

Epoch: 5| Step: 8
Training loss: 0.09568481147289276
Validation loss: 1.48082745780227

Epoch: 5| Step: 9
Training loss: 0.08422461897134781
Validation loss: 1.4784995125186058

Epoch: 5| Step: 10
Training loss: 0.14062324166297913
Validation loss: 1.4918496544643114

Epoch: 469| Step: 0
Training loss: 0.10288865864276886
Validation loss: 1.5006726505935832

Epoch: 5| Step: 1
Training loss: 0.15044455230236053
Validation loss: 1.5071828724235616

Epoch: 5| Step: 2
Training loss: 0.13878752291202545
Validation loss: 1.4586383232506372

Epoch: 5| Step: 3
Training loss: 0.10412774235010147
Validation loss: 1.4489312171936035

Epoch: 5| Step: 4
Training loss: 0.11808674037456512
Validation loss: 1.432209389184111

Epoch: 5| Step: 5
Training loss: 0.13285061717033386
Validation loss: 1.4428550594596452

Epoch: 5| Step: 6
Training loss: 0.1200491413474083
Validation loss: 1.4542495845466532

Epoch: 5| Step: 7
Training loss: 0.13503499329090118
Validation loss: 1.4446830928966563

Epoch: 5| Step: 8
Training loss: 0.17324505746364594
Validation loss: 1.452926665224055

Epoch: 5| Step: 9
Training loss: 0.17441371083259583
Validation loss: 1.4770158760009273

Epoch: 5| Step: 10
Training loss: 0.09894468635320663
Validation loss: 1.4745000094495795

Epoch: 470| Step: 0
Training loss: 0.12049183994531631
Validation loss: 1.511497563251885

Epoch: 5| Step: 1
Training loss: 0.1456284373998642
Validation loss: 1.5137858095989432

Epoch: 5| Step: 2
Training loss: 0.11288763582706451
Validation loss: 1.543077249680796

Epoch: 5| Step: 3
Training loss: 0.1863512545824051
Validation loss: 1.5712701018138597

Epoch: 5| Step: 4
Training loss: 0.18133077025413513
Validation loss: 1.5562072338596467

Epoch: 5| Step: 5
Training loss: 0.055303771048784256
Validation loss: 1.520654470689835

Epoch: 5| Step: 6
Training loss: 0.07795093953609467
Validation loss: 1.5093463736195718

Epoch: 5| Step: 7
Training loss: 0.14212551712989807
Validation loss: 1.4998975492292834

Epoch: 5| Step: 8
Training loss: 0.24080538749694824
Validation loss: 1.4988696203436902

Epoch: 5| Step: 9
Training loss: 0.1322663575410843
Validation loss: 1.4986216816850888

Epoch: 5| Step: 10
Training loss: 0.06321801990270615
Validation loss: 1.5131695014174267

Epoch: 471| Step: 0
Training loss: 0.1377098709344864
Validation loss: 1.5252970162258352

Epoch: 5| Step: 1
Training loss: 0.1276727318763733
Validation loss: 1.551114442527935

Epoch: 5| Step: 2
Training loss: 0.16365107893943787
Validation loss: 1.571358283360799

Epoch: 5| Step: 3
Training loss: 0.17075511813163757
Validation loss: 1.568478916281013

Epoch: 5| Step: 4
Training loss: 0.17744147777557373
Validation loss: 1.5862765786468342

Epoch: 5| Step: 5
Training loss: 0.1584073156118393
Validation loss: 1.534709124154942

Epoch: 5| Step: 6
Training loss: 0.11314704269170761
Validation loss: 1.5150843307536135

Epoch: 5| Step: 7
Training loss: 0.10451600700616837
Validation loss: 1.480962727659492

Epoch: 5| Step: 8
Training loss: 0.14195217192173004
Validation loss: 1.4713606962593653

Epoch: 5| Step: 9
Training loss: 0.10487504303455353
Validation loss: 1.4789328652043496

Epoch: 5| Step: 10
Training loss: 0.19668826460838318
Validation loss: 1.5008633290567706

Epoch: 472| Step: 0
Training loss: 0.21696290373802185
Validation loss: 1.4770243155058993

Epoch: 5| Step: 1
Training loss: 0.12536412477493286
Validation loss: 1.504503192440156

Epoch: 5| Step: 2
Training loss: 0.09500966966152191
Validation loss: 1.5188042489431237

Epoch: 5| Step: 3
Training loss: 0.08876717835664749
Validation loss: 1.5298029479160105

Epoch: 5| Step: 4
Training loss: 0.08527505397796631
Validation loss: 1.526919348265535

Epoch: 5| Step: 5
Training loss: 0.14972354471683502
Validation loss: 1.5492466540746792

Epoch: 5| Step: 6
Training loss: 0.15917673707008362
Validation loss: 1.5578540191855481

Epoch: 5| Step: 7
Training loss: 0.15741857886314392
Validation loss: 1.538450260957082

Epoch: 5| Step: 8
Training loss: 0.12784352898597717
Validation loss: 1.5110869946018342

Epoch: 5| Step: 9
Training loss: 0.08376466482877731
Validation loss: 1.50539299877741

Epoch: 5| Step: 10
Training loss: 0.13285143673419952
Validation loss: 1.4937053938065805

Epoch: 473| Step: 0
Training loss: 0.1221899539232254
Validation loss: 1.485424865317601

Epoch: 5| Step: 1
Training loss: 0.0760405957698822
Validation loss: 1.4701846825179232

Epoch: 5| Step: 2
Training loss: 0.18841634690761566
Validation loss: 1.4531949085573996

Epoch: 5| Step: 3
Training loss: 0.07623296231031418
Validation loss: 1.4643869733297696

Epoch: 5| Step: 4
Training loss: 0.12031467258930206
Validation loss: 1.47247947800544

Epoch: 5| Step: 5
Training loss: 0.12476237863302231
Validation loss: 1.4576781821507279

Epoch: 5| Step: 6
Training loss: 0.10410864651203156
Validation loss: 1.4473222923535172

Epoch: 5| Step: 7
Training loss: 0.10579968988895416
Validation loss: 1.4562202743304673

Epoch: 5| Step: 8
Training loss: 0.07335633039474487
Validation loss: 1.4757630350769206

Epoch: 5| Step: 9
Training loss: 0.08248139917850494
Validation loss: 1.4964692015801706

Epoch: 5| Step: 10
Training loss: 0.07732092589139938
Validation loss: 1.5087792770836943

Epoch: 474| Step: 0
Training loss: 0.08851171284914017
Validation loss: 1.5131896516328216

Epoch: 5| Step: 1
Training loss: 0.08194532990455627
Validation loss: 1.5134888374677269

Epoch: 5| Step: 2
Training loss: 0.09707309305667877
Validation loss: 1.5117987714787966

Epoch: 5| Step: 3
Training loss: 0.10649760812520981
Validation loss: 1.5060555524723505

Epoch: 5| Step: 4
Training loss: 0.12505020201206207
Validation loss: 1.5191241066942933

Epoch: 5| Step: 5
Training loss: 0.07532067596912384
Validation loss: 1.5112327593629078

Epoch: 5| Step: 6
Training loss: 0.1436324268579483
Validation loss: 1.5013560184868433

Epoch: 5| Step: 7
Training loss: 0.17613279819488525
Validation loss: 1.4954535371513777

Epoch: 5| Step: 8
Training loss: 0.0575481653213501
Validation loss: 1.494990897435014

Epoch: 5| Step: 9
Training loss: 0.08322586119174957
Validation loss: 1.468567770014527

Epoch: 5| Step: 10
Training loss: 0.06825973093509674
Validation loss: 1.4550312398582377

Epoch: 475| Step: 0
Training loss: 0.09992016106843948
Validation loss: 1.46013811326796

Epoch: 5| Step: 1
Training loss: 0.08823417127132416
Validation loss: 1.490885252593666

Epoch: 5| Step: 2
Training loss: 0.1897532194852829
Validation loss: 1.4633516419318415

Epoch: 5| Step: 3
Training loss: 0.12045786529779434
Validation loss: 1.4774656846959104

Epoch: 5| Step: 4
Training loss: 0.03699224442243576
Validation loss: 1.4887362718582153

Epoch: 5| Step: 5
Training loss: 0.06132373958826065
Validation loss: 1.5133685578582108

Epoch: 5| Step: 6
Training loss: 0.09900151193141937
Validation loss: 1.5355813631447413

Epoch: 5| Step: 7
Training loss: 0.09800156950950623
Validation loss: 1.5340235746035011

Epoch: 5| Step: 8
Training loss: 0.11485858261585236
Validation loss: 1.5247204842105988

Epoch: 5| Step: 9
Training loss: 0.07807786762714386
Validation loss: 1.5015146129874772

Epoch: 5| Step: 10
Training loss: 0.12889739871025085
Validation loss: 1.462760853511031

Epoch: 476| Step: 0
Training loss: 0.14686250686645508
Validation loss: 1.4533692341978832

Epoch: 5| Step: 1
Training loss: 0.12161071598529816
Validation loss: 1.4316588614576606

Epoch: 5| Step: 2
Training loss: 0.12774793803691864
Validation loss: 1.3964053328319261

Epoch: 5| Step: 3
Training loss: 0.15796241164207458
Validation loss: 1.4058426708303473

Epoch: 5| Step: 4
Training loss: 0.12583115696907043
Validation loss: 1.426290600530563

Epoch: 5| Step: 5
Training loss: 0.11245280504226685
Validation loss: 1.4512635020799534

Epoch: 5| Step: 6
Training loss: 0.08549957722425461
Validation loss: 1.4685318598183252

Epoch: 5| Step: 7
Training loss: 0.1737501174211502
Validation loss: 1.5107943390005378

Epoch: 5| Step: 8
Training loss: 0.12542782723903656
Validation loss: 1.5260319312413533

Epoch: 5| Step: 9
Training loss: 0.08646611124277115
Validation loss: 1.5321884142455233

Epoch: 5| Step: 10
Training loss: 0.08585748821496964
Validation loss: 1.520827579241927

Epoch: 477| Step: 0
Training loss: 0.11732281744480133
Validation loss: 1.5170014609572708

Epoch: 5| Step: 1
Training loss: 0.0653763860464096
Validation loss: 1.5063434147065686

Epoch: 5| Step: 2
Training loss: 0.15969963371753693
Validation loss: 1.526612183099152

Epoch: 5| Step: 3
Training loss: 0.10011563450098038
Validation loss: 1.5422509280584191

Epoch: 5| Step: 4
Training loss: 0.061019401997327805
Validation loss: 1.5375673796540947

Epoch: 5| Step: 5
Training loss: 0.06418566405773163
Validation loss: 1.527013531295202

Epoch: 5| Step: 6
Training loss: 0.10787463188171387
Validation loss: 1.5522828166202833

Epoch: 5| Step: 7
Training loss: 0.09917773306369781
Validation loss: 1.5223785574718187

Epoch: 5| Step: 8
Training loss: 0.12000901997089386
Validation loss: 1.5442445021803661

Epoch: 5| Step: 9
Training loss: 0.09214887022972107
Validation loss: 1.524180700702052

Epoch: 5| Step: 10
Training loss: 0.13087832927703857
Validation loss: 1.5269701506501885

Epoch: 478| Step: 0
Training loss: 0.11219306290149689
Validation loss: 1.5440966929158857

Epoch: 5| Step: 1
Training loss: 0.052092134952545166
Validation loss: 1.5153584807149825

Epoch: 5| Step: 2
Training loss: 0.16378769278526306
Validation loss: 1.5027774982554938

Epoch: 5| Step: 3
Training loss: 0.0733361691236496
Validation loss: 1.4945397812833068

Epoch: 5| Step: 4
Training loss: 0.11954247951507568
Validation loss: 1.5026551485061646

Epoch: 5| Step: 5
Training loss: 0.14130905270576477
Validation loss: 1.4907084536808792

Epoch: 5| Step: 6
Training loss: 0.1320846974849701
Validation loss: 1.4834872291934105

Epoch: 5| Step: 7
Training loss: 0.1222936287522316
Validation loss: 1.486740453268892

Epoch: 5| Step: 8
Training loss: 0.1060367077589035
Validation loss: 1.4815556490293114

Epoch: 5| Step: 9
Training loss: 0.06012468785047531
Validation loss: 1.4956133205403563

Epoch: 5| Step: 10
Training loss: 0.12367970496416092
Validation loss: 1.488939009686952

Epoch: 479| Step: 0
Training loss: 0.07193265855312347
Validation loss: 1.4747458132364417

Epoch: 5| Step: 1
Training loss: 0.06824208050966263
Validation loss: 1.4841428149131037

Epoch: 5| Step: 2
Training loss: 0.07855440676212311
Validation loss: 1.4972052048611384

Epoch: 5| Step: 3
Training loss: 0.057526297867298126
Validation loss: 1.5008799414480887

Epoch: 5| Step: 4
Training loss: 0.1786031424999237
Validation loss: 1.5058210818998274

Epoch: 5| Step: 5
Training loss: 0.17708393931388855
Validation loss: 1.5255006308196692

Epoch: 5| Step: 6
Training loss: 0.12210766971111298
Validation loss: 1.5364181316027077

Epoch: 5| Step: 7
Training loss: 0.09133177995681763
Validation loss: 1.5381221053420857

Epoch: 5| Step: 8
Training loss: 0.146900936961174
Validation loss: 1.504601066471428

Epoch: 5| Step: 9
Training loss: 0.09300106018781662
Validation loss: 1.490681440599503

Epoch: 5| Step: 10
Training loss: 0.06258058547973633
Validation loss: 1.494161840408079

Epoch: 480| Step: 0
Training loss: 0.17731444537639618
Validation loss: 1.4633089380879556

Epoch: 5| Step: 1
Training loss: 0.08773038536310196
Validation loss: 1.4491860482000536

Epoch: 5| Step: 2
Training loss: 0.10691354423761368
Validation loss: 1.4517902533213298

Epoch: 5| Step: 3
Training loss: 0.06442657858133316
Validation loss: 1.473519568802208

Epoch: 5| Step: 4
Training loss: 0.06255809962749481
Validation loss: 1.4574841389092066

Epoch: 5| Step: 5
Training loss: 0.07019376754760742
Validation loss: 1.4816305983451106

Epoch: 5| Step: 6
Training loss: 0.09205351769924164
Validation loss: 1.4605696406415714

Epoch: 5| Step: 7
Training loss: 0.15309873223304749
Validation loss: 1.5010709134481286

Epoch: 5| Step: 8
Training loss: 0.08496928215026855
Validation loss: 1.4958316267177623

Epoch: 5| Step: 9
Training loss: 0.07932831346988678
Validation loss: 1.495153602733407

Epoch: 5| Step: 10
Training loss: 0.05774342268705368
Validation loss: 1.4745773910194315

Epoch: 481| Step: 0
Training loss: 0.0623864009976387
Validation loss: 1.4854662597820323

Epoch: 5| Step: 1
Training loss: 0.09031835943460464
Validation loss: 1.4959479301206526

Epoch: 5| Step: 2
Training loss: 0.09386523067951202
Validation loss: 1.4487702910618117

Epoch: 5| Step: 3
Training loss: 0.12638898193836212
Validation loss: 1.4905879625710108

Epoch: 5| Step: 4
Training loss: 0.06278067827224731
Validation loss: 1.4748405935943767

Epoch: 5| Step: 5
Training loss: 0.09501025080680847
Validation loss: 1.4802057884072746

Epoch: 5| Step: 6
Training loss: 0.08004879206418991
Validation loss: 1.480630931033883

Epoch: 5| Step: 7
Training loss: 0.1790311634540558
Validation loss: 1.5218349759296705

Epoch: 5| Step: 8
Training loss: 0.053834378719329834
Validation loss: 1.5145771490630282

Epoch: 5| Step: 9
Training loss: 0.09514220803976059
Validation loss: 1.5191036988330144

Epoch: 5| Step: 10
Training loss: 0.11166831105947495
Validation loss: 1.506897331565939

Epoch: 482| Step: 0
Training loss: 0.11983463913202286
Validation loss: 1.4941494298237625

Epoch: 5| Step: 1
Training loss: 0.1110406145453453
Validation loss: 1.4951580314226047

Epoch: 5| Step: 2
Training loss: 0.0911519005894661
Validation loss: 1.4921684239500312

Epoch: 5| Step: 3
Training loss: 0.10990019142627716
Validation loss: 1.4983064551507272

Epoch: 5| Step: 4
Training loss: 0.12884406745433807
Validation loss: 1.5054402082197127

Epoch: 5| Step: 5
Training loss: 0.07556144148111343
Validation loss: 1.4933137239948395

Epoch: 5| Step: 6
Training loss: 0.0845613181591034
Validation loss: 1.507692942055323

Epoch: 5| Step: 7
Training loss: 0.08140209317207336
Validation loss: 1.5254248931843748

Epoch: 5| Step: 8
Training loss: 0.0854768306016922
Validation loss: 1.5126693915295344

Epoch: 5| Step: 9
Training loss: 0.10576990991830826
Validation loss: 1.4725447188141525

Epoch: 5| Step: 10
Training loss: 0.05044976621866226
Validation loss: 1.4843059637213265

Epoch: 483| Step: 0
Training loss: 0.0769277885556221
Validation loss: 1.4827018578847249

Epoch: 5| Step: 1
Training loss: 0.1251228153705597
Validation loss: 1.4589768327692503

Epoch: 5| Step: 2
Training loss: 0.05766339227557182
Validation loss: 1.4672825041637625

Epoch: 5| Step: 3
Training loss: 0.06150726601481438
Validation loss: 1.4460596038449196

Epoch: 5| Step: 4
Training loss: 0.12808522582054138
Validation loss: 1.4679715953847414

Epoch: 5| Step: 5
Training loss: 0.09260401874780655
Validation loss: 1.4698414161641111

Epoch: 5| Step: 6
Training loss: 0.15487323701381683
Validation loss: 1.4731195633129408

Epoch: 5| Step: 7
Training loss: 0.11706709861755371
Validation loss: 1.4827670833115936

Epoch: 5| Step: 8
Training loss: 0.10893324762582779
Validation loss: 1.4750229081799906

Epoch: 5| Step: 9
Training loss: 0.06059207767248154
Validation loss: 1.4850606700425506

Epoch: 5| Step: 10
Training loss: 0.07776343077421188
Validation loss: 1.4769989700727566

Epoch: 484| Step: 0
Training loss: 0.0760277733206749
Validation loss: 1.483471970404348

Epoch: 5| Step: 1
Training loss: 0.10667666047811508
Validation loss: 1.4796245341659875

Epoch: 5| Step: 2
Training loss: 0.06086421012878418
Validation loss: 1.4851963994323567

Epoch: 5| Step: 3
Training loss: 0.0647425577044487
Validation loss: 1.484038814421623

Epoch: 5| Step: 4
Training loss: 0.08530373126268387
Validation loss: 1.4640358141673508

Epoch: 5| Step: 5
Training loss: 0.17567656934261322
Validation loss: 1.4335088306857693

Epoch: 5| Step: 6
Training loss: 0.042602505534887314
Validation loss: 1.466427703057566

Epoch: 5| Step: 7
Training loss: 0.1544889211654663
Validation loss: 1.4526736069751043

Epoch: 5| Step: 8
Training loss: 0.08191440999507904
Validation loss: 1.4707944559794601

Epoch: 5| Step: 9
Training loss: 0.05233284831047058
Validation loss: 1.5035662087061072

Epoch: 5| Step: 10
Training loss: 0.06619022786617279
Validation loss: 1.5001171147951515

Epoch: 485| Step: 0
Training loss: 0.16224412620067596
Validation loss: 1.5058428927134442

Epoch: 5| Step: 1
Training loss: 0.0745885819196701
Validation loss: 1.5057328618982786

Epoch: 5| Step: 2
Training loss: 0.1238897442817688
Validation loss: 1.473603638269568

Epoch: 5| Step: 3
Training loss: 0.11338315159082413
Validation loss: 1.4698389319963352

Epoch: 5| Step: 4
Training loss: 0.08883952349424362
Validation loss: 1.486510512649372

Epoch: 5| Step: 5
Training loss: 0.09959964454174042
Validation loss: 1.4596645876925478

Epoch: 5| Step: 6
Training loss: 0.08172904700040817
Validation loss: 1.4743657573576896

Epoch: 5| Step: 7
Training loss: 0.09831243753433228
Validation loss: 1.4763941649467713

Epoch: 5| Step: 8
Training loss: 0.10050041973590851
Validation loss: 1.4831764018663796

Epoch: 5| Step: 9
Training loss: 0.06974244117736816
Validation loss: 1.5039551642633253

Epoch: 5| Step: 10
Training loss: 0.1080058217048645
Validation loss: 1.519654308595965

Epoch: 486| Step: 0
Training loss: 0.10833437740802765
Validation loss: 1.5100412022682927

Epoch: 5| Step: 1
Training loss: 0.0899558812379837
Validation loss: 1.519942145834687

Epoch: 5| Step: 2
Training loss: 0.09794102609157562
Validation loss: 1.5031199429624824

Epoch: 5| Step: 3
Training loss: 0.06301681697368622
Validation loss: 1.5158607280382546

Epoch: 5| Step: 4
Training loss: 0.15733864903450012
Validation loss: 1.4797062386748612

Epoch: 5| Step: 5
Training loss: 0.09266038239002228
Validation loss: 1.4751474870148527

Epoch: 5| Step: 6
Training loss: 0.13627344369888306
Validation loss: 1.484406159129194

Epoch: 5| Step: 7
Training loss: 0.0720449835062027
Validation loss: 1.4840414434350946

Epoch: 5| Step: 8
Training loss: 0.07099881023168564
Validation loss: 1.4587160771892917

Epoch: 5| Step: 9
Training loss: 0.10156814008951187
Validation loss: 1.4910709409303562

Epoch: 5| Step: 10
Training loss: 0.042643189430236816
Validation loss: 1.48466242513349

Epoch: 487| Step: 0
Training loss: 0.06004179269075394
Validation loss: 1.4947252824742308

Epoch: 5| Step: 1
Training loss: 0.07747767865657806
Validation loss: 1.5080059305314095

Epoch: 5| Step: 2
Training loss: 0.1320238709449768
Validation loss: 1.4848041521605624

Epoch: 5| Step: 3
Training loss: 0.05874645709991455
Validation loss: 1.4618919331540343

Epoch: 5| Step: 4
Training loss: 0.04905998706817627
Validation loss: 1.4798021265255508

Epoch: 5| Step: 5
Training loss: 0.09051048010587692
Validation loss: 1.4842253320960588

Epoch: 5| Step: 6
Training loss: 0.07765968143939972
Validation loss: 1.4942110302627727

Epoch: 5| Step: 7
Training loss: 0.1388666331768036
Validation loss: 1.4876974333998978

Epoch: 5| Step: 8
Training loss: 0.0935727134346962
Validation loss: 1.5077909705459431

Epoch: 5| Step: 9
Training loss: 0.07915189862251282
Validation loss: 1.5346478774983396

Epoch: 5| Step: 10
Training loss: 0.14043961465358734
Validation loss: 1.5243189988597747

Epoch: 488| Step: 0
Training loss: 0.154759019613266
Validation loss: 1.5213319550278366

Epoch: 5| Step: 1
Training loss: 0.11377133429050446
Validation loss: 1.5268083567260413

Epoch: 5| Step: 2
Training loss: 0.12245352566242218
Validation loss: 1.5232091719104397

Epoch: 5| Step: 3
Training loss: 0.15528403222560883
Validation loss: 1.4826260112947034

Epoch: 5| Step: 4
Training loss: 0.09037088602781296
Validation loss: 1.465982041051311

Epoch: 5| Step: 5
Training loss: 0.07659196853637695
Validation loss: 1.4689720074335735

Epoch: 5| Step: 6
Training loss: 0.11622488498687744
Validation loss: 1.475761003391717

Epoch: 5| Step: 7
Training loss: 0.08392456918954849
Validation loss: 1.4659960007154813

Epoch: 5| Step: 8
Training loss: 0.09506199508905411
Validation loss: 1.460091426808347

Epoch: 5| Step: 9
Training loss: 0.11394746601581573
Validation loss: 1.4899260600407918

Epoch: 5| Step: 10
Training loss: 0.11781487613916397
Validation loss: 1.487029585787045

Epoch: 489| Step: 0
Training loss: 0.11573426425457001
Validation loss: 1.498687332676303

Epoch: 5| Step: 1
Training loss: 0.05471009761095047
Validation loss: 1.51700940439778

Epoch: 5| Step: 2
Training loss: 0.10811863839626312
Validation loss: 1.5017863576130202

Epoch: 5| Step: 3
Training loss: 0.14682725071907043
Validation loss: 1.4904404532524846

Epoch: 5| Step: 4
Training loss: 0.12975473701953888
Validation loss: 1.5284455027631534

Epoch: 5| Step: 5
Training loss: 0.11122145503759384
Validation loss: 1.4912283555153878

Epoch: 5| Step: 6
Training loss: 0.09888375550508499
Validation loss: 1.4883521058226143

Epoch: 5| Step: 7
Training loss: 0.07618799805641174
Validation loss: 1.4718839609494774

Epoch: 5| Step: 8
Training loss: 0.06374038010835648
Validation loss: 1.4407973315126152

Epoch: 5| Step: 9
Training loss: 0.08915625512599945
Validation loss: 1.439841232633078

Epoch: 5| Step: 10
Training loss: 0.1115783229470253
Validation loss: 1.4517307576312815

Epoch: 490| Step: 0
Training loss: 0.09247450530529022
Validation loss: 1.465252427644627

Epoch: 5| Step: 1
Training loss: 0.06181776523590088
Validation loss: 1.4479504990321335

Epoch: 5| Step: 2
Training loss: 0.06474755704402924
Validation loss: 1.4686138988823019

Epoch: 5| Step: 3
Training loss: 0.08111129701137543
Validation loss: 1.470309486953161

Epoch: 5| Step: 4
Training loss: 0.08577372878789902
Validation loss: 1.471500756920025

Epoch: 5| Step: 5
Training loss: 0.06447546184062958
Validation loss: 1.5028060392666889

Epoch: 5| Step: 6
Training loss: 0.11872656643390656
Validation loss: 1.4855821222387335

Epoch: 5| Step: 7
Training loss: 0.057052336633205414
Validation loss: 1.5107826058582594

Epoch: 5| Step: 8
Training loss: 0.039197079837322235
Validation loss: 1.5095915858463576

Epoch: 5| Step: 9
Training loss: 0.06820809096097946
Validation loss: 1.4950923406949608

Epoch: 5| Step: 10
Training loss: 0.203156977891922
Validation loss: 1.496991321604739

Epoch: 491| Step: 0
Training loss: 0.047124769538640976
Validation loss: 1.492198838982531

Epoch: 5| Step: 1
Training loss: 0.10027401149272919
Validation loss: 1.5068867885938255

Epoch: 5| Step: 2
Training loss: 0.11800781637430191
Validation loss: 1.4749128145556296

Epoch: 5| Step: 3
Training loss: 0.08480887115001678
Validation loss: 1.4741399275359286

Epoch: 5| Step: 4
Training loss: 0.048953525722026825
Validation loss: 1.4926810854224748

Epoch: 5| Step: 5
Training loss: 0.046448756009340286
Validation loss: 1.4876907999797533

Epoch: 5| Step: 6
Training loss: 0.07955911010503769
Validation loss: 1.4999138552655455

Epoch: 5| Step: 7
Training loss: 0.17059829831123352
Validation loss: 1.5054766747259325

Epoch: 5| Step: 8
Training loss: 0.07086856663227081
Validation loss: 1.4803719507750643

Epoch: 5| Step: 9
Training loss: 0.06750494986772537
Validation loss: 1.5029304386467062

Epoch: 5| Step: 10
Training loss: 0.04165772721171379
Validation loss: 1.4671605146059425

Epoch: 492| Step: 0
Training loss: 0.07302404195070267
Validation loss: 1.471412375409116

Epoch: 5| Step: 1
Training loss: 0.09678053110837936
Validation loss: 1.465605967147376

Epoch: 5| Step: 2
Training loss: 0.055181920528411865
Validation loss: 1.4507106068313762

Epoch: 5| Step: 3
Training loss: 0.07941683381795883
Validation loss: 1.4507994818431076

Epoch: 5| Step: 4
Training loss: 0.10110591351985931
Validation loss: 1.445468368068818

Epoch: 5| Step: 5
Training loss: 0.12546902894973755
Validation loss: 1.4500397213043705

Epoch: 5| Step: 6
Training loss: 0.13934190571308136
Validation loss: 1.4615879648475236

Epoch: 5| Step: 7
Training loss: 0.05400437116622925
Validation loss: 1.4807512721707743

Epoch: 5| Step: 8
Training loss: 0.07517249882221222
Validation loss: 1.477251749525788

Epoch: 5| Step: 9
Training loss: 0.06688715517520905
Validation loss: 1.4671969183029667

Epoch: 5| Step: 10
Training loss: 0.07401971518993378
Validation loss: 1.463873778620074

Epoch: 493| Step: 0
Training loss: 0.11456149816513062
Validation loss: 1.4783617437526744

Epoch: 5| Step: 1
Training loss: 0.04169232398271561
Validation loss: 1.4982108845505664

Epoch: 5| Step: 2
Training loss: 0.08852145820856094
Validation loss: 1.499520485119153

Epoch: 5| Step: 3
Training loss: 0.07670772820711136
Validation loss: 1.4932605656244422

Epoch: 5| Step: 4
Training loss: 0.0867786854505539
Validation loss: 1.489608241665748

Epoch: 5| Step: 5
Training loss: 0.11100683361291885
Validation loss: 1.4801511783753671

Epoch: 5| Step: 6
Training loss: 0.11304561793804169
Validation loss: 1.4702610764452206

Epoch: 5| Step: 7
Training loss: 0.059663813561201096
Validation loss: 1.4784634869585755

Epoch: 5| Step: 8
Training loss: 0.06002616882324219
Validation loss: 1.4635641164677118

Epoch: 5| Step: 9
Training loss: 0.10209336131811142
Validation loss: 1.4642062123103807

Epoch: 5| Step: 10
Training loss: 0.060185641050338745
Validation loss: 1.4337873869044806

Epoch: 494| Step: 0
Training loss: 0.12679268419742584
Validation loss: 1.4421921853096253

Epoch: 5| Step: 1
Training loss: 0.10468830168247223
Validation loss: 1.4401103578588015

Epoch: 5| Step: 2
Training loss: 0.07767701148986816
Validation loss: 1.4489309198112899

Epoch: 5| Step: 3
Training loss: 0.15237964689731598
Validation loss: 1.46052760078061

Epoch: 5| Step: 4
Training loss: 0.07202615588903427
Validation loss: 1.4459814371601227

Epoch: 5| Step: 5
Training loss: 0.06331981718540192
Validation loss: 1.4877084865364978

Epoch: 5| Step: 6
Training loss: 0.07019004225730896
Validation loss: 1.4754451551745016

Epoch: 5| Step: 7
Training loss: 0.03967548534274101
Validation loss: 1.4946769693846345

Epoch: 5| Step: 8
Training loss: 0.08778829872608185
Validation loss: 1.4998220218125211

Epoch: 5| Step: 9
Training loss: 0.08138365298509598
Validation loss: 1.4961043455267464

Epoch: 5| Step: 10
Training loss: 0.1374850571155548
Validation loss: 1.4923953433190622

Epoch: 495| Step: 0
Training loss: 0.09503500163555145
Validation loss: 1.487346464587796

Epoch: 5| Step: 1
Training loss: 0.14242276549339294
Validation loss: 1.489795051595216

Epoch: 5| Step: 2
Training loss: 0.08215261995792389
Validation loss: 1.4908209731501918

Epoch: 5| Step: 3
Training loss: 0.09332722425460815
Validation loss: 1.4894664684931438

Epoch: 5| Step: 4
Training loss: 0.09210227429866791
Validation loss: 1.5073273745916222

Epoch: 5| Step: 5
Training loss: 0.038202978670597076
Validation loss: 1.4635558506493926

Epoch: 5| Step: 6
Training loss: 0.09405507147312164
Validation loss: 1.5051994323730469

Epoch: 5| Step: 7
Training loss: 0.11185023933649063
Validation loss: 1.4687057374626078

Epoch: 5| Step: 8
Training loss: 0.08313371986150742
Validation loss: 1.4865630019095637

Epoch: 5| Step: 9
Training loss: 0.06249549239873886
Validation loss: 1.4694296108779086

Epoch: 5| Step: 10
Training loss: 0.09671301394701004
Validation loss: 1.4552910353547783

Epoch: 496| Step: 0
Training loss: 0.13886690139770508
Validation loss: 1.448318459654367

Epoch: 5| Step: 1
Training loss: 0.05522773414850235
Validation loss: 1.452890206408757

Epoch: 5| Step: 2
Training loss: 0.05979866534471512
Validation loss: 1.4573383895299767

Epoch: 5| Step: 3
Training loss: 0.06248615309596062
Validation loss: 1.4832676546548003

Epoch: 5| Step: 4
Training loss: 0.11572879552841187
Validation loss: 1.5022838666874876

Epoch: 5| Step: 5
Training loss: 0.0761207565665245
Validation loss: 1.5506159900337138

Epoch: 5| Step: 6
Training loss: 0.07189453393220901
Validation loss: 1.5257178903907858

Epoch: 5| Step: 7
Training loss: 0.04287123307585716
Validation loss: 1.5212846443217287

Epoch: 5| Step: 8
Training loss: 0.13029861450195312
Validation loss: 1.5195907456900484

Epoch: 5| Step: 9
Training loss: 0.10429690033197403
Validation loss: 1.5152332757108955

Epoch: 5| Step: 10
Training loss: 0.14376194775104523
Validation loss: 1.4959451767706102

Epoch: 497| Step: 0
Training loss: 0.10759437084197998
Validation loss: 1.5109405786760393

Epoch: 5| Step: 1
Training loss: 0.10066217184066772
Validation loss: 1.5060060588262414

Epoch: 5| Step: 2
Training loss: 0.057311952114105225
Validation loss: 1.506552726991715

Epoch: 5| Step: 3
Training loss: 0.10417036712169647
Validation loss: 1.5036185121023526

Epoch: 5| Step: 4
Training loss: 0.09353198111057281
Validation loss: 1.476863916202258

Epoch: 5| Step: 5
Training loss: 0.11741659790277481
Validation loss: 1.4857169453815748

Epoch: 5| Step: 6
Training loss: 0.07626701891422272
Validation loss: 1.465842091909019

Epoch: 5| Step: 7
Training loss: 0.07958458364009857
Validation loss: 1.4696702790516678

Epoch: 5| Step: 8
Training loss: 0.08469977229833603
Validation loss: 1.4811906353119881

Epoch: 5| Step: 9
Training loss: 0.10300296545028687
Validation loss: 1.4893290445368776

Epoch: 5| Step: 10
Training loss: 0.12315772473812103
Validation loss: 1.4868428963486866

Epoch: 498| Step: 0
Training loss: 0.05172980949282646
Validation loss: 1.5152322630728445

Epoch: 5| Step: 1
Training loss: 0.12190450727939606
Validation loss: 1.4971149160015969

Epoch: 5| Step: 2
Training loss: 0.12278693914413452
Validation loss: 1.5000686081506873

Epoch: 5| Step: 3
Training loss: 0.07241004705429077
Validation loss: 1.5330752672687653

Epoch: 5| Step: 4
Training loss: 0.09041028469800949
Validation loss: 1.5188114937915598

Epoch: 5| Step: 5
Training loss: 0.05968562513589859
Validation loss: 1.5008520849289433

Epoch: 5| Step: 6
Training loss: 0.06129445880651474
Validation loss: 1.4979190595688359

Epoch: 5| Step: 7
Training loss: 0.046005524694919586
Validation loss: 1.5002343814860108

Epoch: 5| Step: 8
Training loss: 0.06887882947921753
Validation loss: 1.491903176871679

Epoch: 5| Step: 9
Training loss: 0.07343520224094391
Validation loss: 1.4868433731858448

Epoch: 5| Step: 10
Training loss: 0.10192607343196869
Validation loss: 1.4890824453805083

Epoch: 499| Step: 0
Training loss: 0.11158788204193115
Validation loss: 1.4790458692017423

Epoch: 5| Step: 1
Training loss: 0.07908715307712555
Validation loss: 1.487273245729426

Epoch: 5| Step: 2
Training loss: 0.09422843158245087
Validation loss: 1.50745149325299

Epoch: 5| Step: 3
Training loss: 0.07649976760149002
Validation loss: 1.4867084769792454

Epoch: 5| Step: 4
Training loss: 0.09087476879358292
Validation loss: 1.491218384876046

Epoch: 5| Step: 5
Training loss: 0.04841865971684456
Validation loss: 1.4838205165760492

Epoch: 5| Step: 6
Training loss: 0.06845559924840927
Validation loss: 1.4909943919028006

Epoch: 5| Step: 7
Training loss: 0.056321609765291214
Validation loss: 1.4795171394143054

Epoch: 5| Step: 8
Training loss: 0.05937318131327629
Validation loss: 1.4762018483172181

Epoch: 5| Step: 9
Training loss: 0.1234966367483139
Validation loss: 1.4921760091217615

Epoch: 5| Step: 10
Training loss: 0.08947867155075073
Validation loss: 1.476321897199077

Epoch: 500| Step: 0
Training loss: 0.057161152362823486
Validation loss: 1.488024333471893

Epoch: 5| Step: 1
Training loss: 0.0616316981613636
Validation loss: 1.496629249665045

Epoch: 5| Step: 2
Training loss: 0.1022351011633873
Validation loss: 1.4997240561310963

Epoch: 5| Step: 3
Training loss: 0.05678616836667061
Validation loss: 1.5118394744011663

Epoch: 5| Step: 4
Training loss: 0.0955187976360321
Validation loss: 1.4960350554476503

Epoch: 5| Step: 5
Training loss: 0.16617731750011444
Validation loss: 1.5083336919866583

Epoch: 5| Step: 6
Training loss: 0.07291871309280396
Validation loss: 1.4874706396492579

Epoch: 5| Step: 7
Training loss: 0.06079027056694031
Validation loss: 1.48385525326575

Epoch: 5| Step: 8
Training loss: 0.10085606575012207
Validation loss: 1.4811051096967471

Epoch: 5| Step: 9
Training loss: 0.12438802421092987
Validation loss: 1.4750114512699906

Epoch: 5| Step: 10
Training loss: 0.10062903165817261
Validation loss: 1.494953953450726

Epoch: 501| Step: 0
Training loss: 0.06292541325092316
Validation loss: 1.4857436777443014

Epoch: 5| Step: 1
Training loss: 0.05683368444442749
Validation loss: 1.4991911739431403

Epoch: 5| Step: 2
Training loss: 0.09950808435678482
Validation loss: 1.495490325394497

Epoch: 5| Step: 3
Training loss: 0.09397193044424057
Validation loss: 1.4751782289115332

Epoch: 5| Step: 4
Training loss: 0.07672905921936035
Validation loss: 1.4768011108521493

Epoch: 5| Step: 5
Training loss: 0.0932997614145279
Validation loss: 1.4908531224855812

Epoch: 5| Step: 6
Training loss: 0.10449043661355972
Validation loss: 1.493440886979462

Epoch: 5| Step: 7
Training loss: 0.07378684729337692
Validation loss: 1.4893588225046794

Epoch: 5| Step: 8
Training loss: 0.16608266532421112
Validation loss: 1.4830311664970972

Epoch: 5| Step: 9
Training loss: 0.11904631555080414
Validation loss: 1.4986597914849558

Epoch: 5| Step: 10
Training loss: 0.04357575252652168
Validation loss: 1.4797223062925442

Epoch: 502| Step: 0
Training loss: 0.07743959873914719
Validation loss: 1.4620423047773299

Epoch: 5| Step: 1
Training loss: 0.11568818241357803
Validation loss: 1.4584689345411075

Epoch: 5| Step: 2
Training loss: 0.1289253830909729
Validation loss: 1.445027930762178

Epoch: 5| Step: 3
Training loss: 0.10491210222244263
Validation loss: 1.4491740503618795

Epoch: 5| Step: 4
Training loss: 0.1054973155260086
Validation loss: 1.4148140953433128

Epoch: 5| Step: 5
Training loss: 0.06822001934051514
Validation loss: 1.4249006778963151

Epoch: 5| Step: 6
Training loss: 0.08843958377838135
Validation loss: 1.4601954977999452

Epoch: 5| Step: 7
Training loss: 0.04037303477525711
Validation loss: 1.453433043213301

Epoch: 5| Step: 8
Training loss: 0.09393584728240967
Validation loss: 1.5022823669577157

Epoch: 5| Step: 9
Training loss: 0.05632741004228592
Validation loss: 1.5032282106338009

Epoch: 5| Step: 10
Training loss: 0.11234625428915024
Validation loss: 1.5175096809223134

Epoch: 503| Step: 0
Training loss: 0.08659584075212479
Validation loss: 1.506998603061963

Epoch: 5| Step: 1
Training loss: 0.10675959289073944
Validation loss: 1.5017939024074103

Epoch: 5| Step: 2
Training loss: 0.0867733359336853
Validation loss: 1.4904358489539034

Epoch: 5| Step: 3
Training loss: 0.08376095443964005
Validation loss: 1.5164583133112999

Epoch: 5| Step: 4
Training loss: 0.04739107936620712
Validation loss: 1.5009053163630988

Epoch: 5| Step: 5
Training loss: 0.04412158578634262
Validation loss: 1.4969124364596542

Epoch: 5| Step: 6
Training loss: 0.12421835958957672
Validation loss: 1.4889407132261543

Epoch: 5| Step: 7
Training loss: 0.07544281333684921
Validation loss: 1.495927608141335

Epoch: 5| Step: 8
Training loss: 0.07133396714925766
Validation loss: 1.4978650410970051

Epoch: 5| Step: 9
Training loss: 0.08962450921535492
Validation loss: 1.5045845290665985

Epoch: 5| Step: 10
Training loss: 0.12573087215423584
Validation loss: 1.4756743318291121

Epoch: 504| Step: 0
Training loss: 0.1262298971414566
Validation loss: 1.5028599398110503

Epoch: 5| Step: 1
Training loss: 0.06727559864521027
Validation loss: 1.4777779656071817

Epoch: 5| Step: 2
Training loss: 0.15469031035900116
Validation loss: 1.4550945182000437

Epoch: 5| Step: 3
Training loss: 0.06185635179281235
Validation loss: 1.4732331127248786

Epoch: 5| Step: 4
Training loss: 0.08747953176498413
Validation loss: 1.4992850493359309

Epoch: 5| Step: 5
Training loss: 0.11241485923528671
Validation loss: 1.5029695187845538

Epoch: 5| Step: 6
Training loss: 0.07867283374071121
Validation loss: 1.495512193249118

Epoch: 5| Step: 7
Training loss: 0.12021192163228989
Validation loss: 1.5293539980406403

Epoch: 5| Step: 8
Training loss: 0.11265099048614502
Validation loss: 1.5397394075188586

Epoch: 5| Step: 9
Training loss: 0.09345223754644394
Validation loss: 1.5460004562972693

Epoch: 5| Step: 10
Training loss: 0.049470607191324234
Validation loss: 1.5098720122409124

Epoch: 505| Step: 0
Training loss: 0.06427378952503204
Validation loss: 1.5185809891711

Epoch: 5| Step: 1
Training loss: 0.12381956726312637
Validation loss: 1.4952945869456056

Epoch: 5| Step: 2
Training loss: 0.13359904289245605
Validation loss: 1.5103238667211225

Epoch: 5| Step: 3
Training loss: 0.07470504194498062
Validation loss: 1.4995177766328216

Epoch: 5| Step: 4
Training loss: 0.1388741433620453
Validation loss: 1.476561894660355

Epoch: 5| Step: 5
Training loss: 0.10864828526973724
Validation loss: 1.5049061595752675

Epoch: 5| Step: 6
Training loss: 0.09599199146032333
Validation loss: 1.4925012178318475

Epoch: 5| Step: 7
Training loss: 0.044879250228405
Validation loss: 1.4980708642672467

Epoch: 5| Step: 8
Training loss: 0.1358577013015747
Validation loss: 1.5231236437315583

Epoch: 5| Step: 9
Training loss: 0.09587929397821426
Validation loss: 1.5373832718018563

Epoch: 5| Step: 10
Training loss: 0.0975230261683464
Validation loss: 1.553924915611103

Epoch: 506| Step: 0
Training loss: 0.11851310729980469
Validation loss: 1.534785992355757

Epoch: 5| Step: 1
Training loss: 0.12998422980308533
Validation loss: 1.5295739891708537

Epoch: 5| Step: 2
Training loss: 0.08362647145986557
Validation loss: 1.5182540839718235

Epoch: 5| Step: 3
Training loss: 0.04349365085363388
Validation loss: 1.5112672262294318

Epoch: 5| Step: 4
Training loss: 0.07916931062936783
Validation loss: 1.496078779620509

Epoch: 5| Step: 5
Training loss: 0.08261869102716446
Validation loss: 1.4777523215099047

Epoch: 5| Step: 6
Training loss: 0.16171839833259583
Validation loss: 1.4799146549676054

Epoch: 5| Step: 7
Training loss: 0.09775497019290924
Validation loss: 1.458535336679028

Epoch: 5| Step: 8
Training loss: 0.08664111793041229
Validation loss: 1.4566744219872259

Epoch: 5| Step: 9
Training loss: 0.07013233006000519
Validation loss: 1.4688731201233403

Epoch: 5| Step: 10
Training loss: 0.07811111211776733
Validation loss: 1.4907275886945828

Epoch: 507| Step: 0
Training loss: 0.1121901124715805
Validation loss: 1.5015520306043728

Epoch: 5| Step: 1
Training loss: 0.10124421119689941
Validation loss: 1.5160733435743599

Epoch: 5| Step: 2
Training loss: 0.05303630977869034
Validation loss: 1.5067457986134354

Epoch: 5| Step: 3
Training loss: 0.0902913361787796
Validation loss: 1.4934024631336171

Epoch: 5| Step: 4
Training loss: 0.07308705896139145
Validation loss: 1.4832645744405768

Epoch: 5| Step: 5
Training loss: 0.1113361343741417
Validation loss: 1.4686401941443001

Epoch: 5| Step: 6
Training loss: 0.07719488441944122
Validation loss: 1.4258765277042185

Epoch: 5| Step: 7
Training loss: 0.06661047786474228
Validation loss: 1.4485953456612044

Epoch: 5| Step: 8
Training loss: 0.11093433201313019
Validation loss: 1.465100694728154

Epoch: 5| Step: 9
Training loss: 0.18265129625797272
Validation loss: 1.480033318201701

Epoch: 5| Step: 10
Training loss: 0.11063820868730545
Validation loss: 1.4710803711286156

Epoch: 508| Step: 0
Training loss: 0.0738786906003952
Validation loss: 1.4958910371667595

Epoch: 5| Step: 1
Training loss: 0.09125789254903793
Validation loss: 1.4981890340005197

Epoch: 5| Step: 2
Training loss: 0.08998963981866837
Validation loss: 1.5186441194626592

Epoch: 5| Step: 3
Training loss: 0.10452766716480255
Validation loss: 1.5005505854083645

Epoch: 5| Step: 4
Training loss: 0.18347346782684326
Validation loss: 1.518087281975695

Epoch: 5| Step: 5
Training loss: 0.09318245947360992
Validation loss: 1.5106359643320884

Epoch: 5| Step: 6
Training loss: 0.08227986842393875
Validation loss: 1.543804878829628

Epoch: 5| Step: 7
Training loss: 0.09137658029794693
Validation loss: 1.4834267388107956

Epoch: 5| Step: 8
Training loss: 0.09402962774038315
Validation loss: 1.478583425603887

Epoch: 5| Step: 9
Training loss: 0.06201491504907608
Validation loss: 1.4494893352190654

Epoch: 5| Step: 10
Training loss: 0.11191742867231369
Validation loss: 1.44769795351131

Epoch: 509| Step: 0
Training loss: 0.07320922613143921
Validation loss: 1.4191425359377297

Epoch: 5| Step: 1
Training loss: 0.08013853430747986
Validation loss: 1.4086029382162197

Epoch: 5| Step: 2
Training loss: 0.1558007299900055
Validation loss: 1.4264659676500546

Epoch: 5| Step: 3
Training loss: 0.056445468217134476
Validation loss: 1.4202217158450876

Epoch: 5| Step: 4
Training loss: 0.10631459951400757
Validation loss: 1.4533580413428686

Epoch: 5| Step: 5
Training loss: 0.06711986660957336
Validation loss: 1.451443677307457

Epoch: 5| Step: 6
Training loss: 0.11450078338384628
Validation loss: 1.4524348679409231

Epoch: 5| Step: 7
Training loss: 0.10515956580638885
Validation loss: 1.452226947712642

Epoch: 5| Step: 8
Training loss: 0.06396633386611938
Validation loss: 1.4478499312554636

Epoch: 5| Step: 9
Training loss: 0.06630633771419525
Validation loss: 1.4688741699341805

Epoch: 5| Step: 10
Training loss: 0.08202654123306274
Validation loss: 1.4403017567050072

Epoch: 510| Step: 0
Training loss: 0.12072756141424179
Validation loss: 1.4415596883784059

Epoch: 5| Step: 1
Training loss: 0.18670544028282166
Validation loss: 1.45560872426597

Epoch: 5| Step: 2
Training loss: 0.07565681636333466
Validation loss: 1.4401597335774412

Epoch: 5| Step: 3
Training loss: 0.060801636427640915
Validation loss: 1.4369011566203127

Epoch: 5| Step: 4
Training loss: 0.09668152779340744
Validation loss: 1.4493935556821926

Epoch: 5| Step: 5
Training loss: 0.05339452624320984
Validation loss: 1.4669688440138293

Epoch: 5| Step: 6
Training loss: 0.05960005521774292
Validation loss: 1.4813574360262962

Epoch: 5| Step: 7
Training loss: 0.0853167325258255
Validation loss: 1.4950459477722005

Epoch: 5| Step: 8
Training loss: 0.07210668921470642
Validation loss: 1.4915025631586711

Epoch: 5| Step: 9
Training loss: 0.10486165434122086
Validation loss: 1.4756472943931498

Epoch: 5| Step: 10
Training loss: 0.05770120024681091
Validation loss: 1.47187775950278

Epoch: 511| Step: 0
Training loss: 0.04730352759361267
Validation loss: 1.4793436719525246

Epoch: 5| Step: 1
Training loss: 0.07175717502832413
Validation loss: 1.4488868508287656

Epoch: 5| Step: 2
Training loss: 0.048961006104946136
Validation loss: 1.4559465249379475

Epoch: 5| Step: 3
Training loss: 0.11188013851642609
Validation loss: 1.4663725219747072

Epoch: 5| Step: 4
Training loss: 0.05061846226453781
Validation loss: 1.4759637053294847

Epoch: 5| Step: 5
Training loss: 0.06624366343021393
Validation loss: 1.4651769374006538

Epoch: 5| Step: 6
Training loss: 0.08661611378192902
Validation loss: 1.4835947559725853

Epoch: 5| Step: 7
Training loss: 0.06973174214363098
Validation loss: 1.486470191709457

Epoch: 5| Step: 8
Training loss: 0.08695071935653687
Validation loss: 1.4972637238041047

Epoch: 5| Step: 9
Training loss: 0.04651552811264992
Validation loss: 1.4898916598289245

Epoch: 5| Step: 10
Training loss: 0.1325434297323227
Validation loss: 1.5008304119110107

Epoch: 512| Step: 0
Training loss: 0.038521163165569305
Validation loss: 1.4974983635769095

Epoch: 5| Step: 1
Training loss: 0.053360771387815475
Validation loss: 1.483525046097335

Epoch: 5| Step: 2
Training loss: 0.06635180860757828
Validation loss: 1.4659382950875066

Epoch: 5| Step: 3
Training loss: 0.029500702396035194
Validation loss: 1.4761131604512532

Epoch: 5| Step: 4
Training loss: 0.10853538662195206
Validation loss: 1.4824870363358529

Epoch: 5| Step: 5
Training loss: 0.05103558301925659
Validation loss: 1.473562971238167

Epoch: 5| Step: 6
Training loss: 0.09908437728881836
Validation loss: 1.4453045655322332

Epoch: 5| Step: 7
Training loss: 0.06873143464326859
Validation loss: 1.4495461922819897

Epoch: 5| Step: 8
Training loss: 0.11785848438739777
Validation loss: 1.4416421433930755

Epoch: 5| Step: 9
Training loss: 0.11950967460870743
Validation loss: 1.4369125045755857

Epoch: 5| Step: 10
Training loss: 0.07215437293052673
Validation loss: 1.4364201288710359

Epoch: 513| Step: 0
Training loss: 0.08954975754022598
Validation loss: 1.43877673533655

Epoch: 5| Step: 1
Training loss: 0.06444446742534637
Validation loss: 1.4399039578694168

Epoch: 5| Step: 2
Training loss: 0.06812725961208344
Validation loss: 1.4428432705581828

Epoch: 5| Step: 3
Training loss: 0.04895935580134392
Validation loss: 1.4667108699839602

Epoch: 5| Step: 4
Training loss: 0.06075463443994522
Validation loss: 1.438582606213067

Epoch: 5| Step: 5
Training loss: 0.052725959569215775
Validation loss: 1.4612386188199442

Epoch: 5| Step: 6
Training loss: 0.08590443432331085
Validation loss: 1.4835732252367082

Epoch: 5| Step: 7
Training loss: 0.1086435317993164
Validation loss: 1.4663644811158538

Epoch: 5| Step: 8
Training loss: 0.09230117499828339
Validation loss: 1.4863974932701356

Epoch: 5| Step: 9
Training loss: 0.06014769524335861
Validation loss: 1.4759089651928152

Epoch: 5| Step: 10
Training loss: 0.1106947660446167
Validation loss: 1.4668867588043213

Epoch: 514| Step: 0
Training loss: 0.07052640616893768
Validation loss: 1.4921857740289421

Epoch: 5| Step: 1
Training loss: 0.11756370961666107
Validation loss: 1.4954759869524228

Epoch: 5| Step: 2
Training loss: 0.07482348382472992
Validation loss: 1.4803543936821721

Epoch: 5| Step: 3
Training loss: 0.07130157202482224
Validation loss: 1.4788063700481127

Epoch: 5| Step: 4
Training loss: 0.06927931308746338
Validation loss: 1.4664981865113782

Epoch: 5| Step: 5
Training loss: 0.12794992327690125
Validation loss: 1.4506488359102638

Epoch: 5| Step: 6
Training loss: 0.09423486888408661
Validation loss: 1.4575305484956311

Epoch: 5| Step: 7
Training loss: 0.05285573750734329
Validation loss: 1.4328146403835667

Epoch: 5| Step: 8
Training loss: 0.08932913839817047
Validation loss: 1.4272536462353123

Epoch: 5| Step: 9
Training loss: 0.1031387597322464
Validation loss: 1.4631896352255216

Epoch: 5| Step: 10
Training loss: 0.05415836349129677
Validation loss: 1.4356934870443037

Epoch: 515| Step: 0
Training loss: 0.07451747357845306
Validation loss: 1.440226044706119

Epoch: 5| Step: 1
Training loss: 0.09248741716146469
Validation loss: 1.440039812877614

Epoch: 5| Step: 2
Training loss: 0.08466958999633789
Validation loss: 1.421600777615783

Epoch: 5| Step: 3
Training loss: 0.06355161964893341
Validation loss: 1.4610786168806014

Epoch: 5| Step: 4
Training loss: 0.043258532881736755
Validation loss: 1.4388881691040531

Epoch: 5| Step: 5
Training loss: 0.06584592163562775
Validation loss: 1.419403649145557

Epoch: 5| Step: 6
Training loss: 0.10959452390670776
Validation loss: 1.4364085505085606

Epoch: 5| Step: 7
Training loss: 0.08643887937068939
Validation loss: 1.4597729534231207

Epoch: 5| Step: 8
Training loss: 0.037688128650188446
Validation loss: 1.4399247086176308

Epoch: 5| Step: 9
Training loss: 0.07956854999065399
Validation loss: 1.467504434688117

Epoch: 5| Step: 10
Training loss: 0.12648065388202667
Validation loss: 1.480318800095589

Epoch: 516| Step: 0
Training loss: 0.10240783542394638
Validation loss: 1.499036217248568

Epoch: 5| Step: 1
Training loss: 0.040428727865219116
Validation loss: 1.5113536286097702

Epoch: 5| Step: 2
Training loss: 0.09733477234840393
Validation loss: 1.5143294142138573

Epoch: 5| Step: 3
Training loss: 0.07700090110301971
Validation loss: 1.5084116984439153

Epoch: 5| Step: 4
Training loss: 0.0946001186966896
Validation loss: 1.4793386792623868

Epoch: 5| Step: 5
Training loss: 0.06093933433294296
Validation loss: 1.5040964208623415

Epoch: 5| Step: 6
Training loss: 0.10238558053970337
Validation loss: 1.505012176370108

Epoch: 5| Step: 7
Training loss: 0.052806414663791656
Validation loss: 1.5134529580352127

Epoch: 5| Step: 8
Training loss: 0.08916764706373215
Validation loss: 1.4891988218471568

Epoch: 5| Step: 9
Training loss: 0.14430204033851624
Validation loss: 1.4966361420128935

Epoch: 5| Step: 10
Training loss: 0.1202893853187561
Validation loss: 1.4950986011053926

Epoch: 517| Step: 0
Training loss: 0.055180132389068604
Validation loss: 1.5242489640430739

Epoch: 5| Step: 1
Training loss: 0.09295006841421127
Validation loss: 1.508091567665018

Epoch: 5| Step: 2
Training loss: 0.09377223998308182
Validation loss: 1.515487911239747

Epoch: 5| Step: 3
Training loss: 0.07722518593072891
Validation loss: 1.5239637545360032

Epoch: 5| Step: 4
Training loss: 0.14123639464378357
Validation loss: 1.5291408825946111

Epoch: 5| Step: 5
Training loss: 0.11214679479598999
Validation loss: 1.5280899052978845

Epoch: 5| Step: 6
Training loss: 0.09582509845495224
Validation loss: 1.5017020625452842

Epoch: 5| Step: 7
Training loss: 0.10367784649133682
Validation loss: 1.4779623708417338

Epoch: 5| Step: 8
Training loss: 0.08792732656002045
Validation loss: 1.4892983116129392

Epoch: 5| Step: 9
Training loss: 0.1582726389169693
Validation loss: 1.4629035245987676

Epoch: 5| Step: 10
Training loss: 0.10801101475954056
Validation loss: 1.4613100200571039

Epoch: 518| Step: 0
Training loss: 0.09500949829816818
Validation loss: 1.455345728064096

Epoch: 5| Step: 1
Training loss: 0.10174717754125595
Validation loss: 1.4391903377348376

Epoch: 5| Step: 2
Training loss: 0.15349814295768738
Validation loss: 1.4783947788259035

Epoch: 5| Step: 3
Training loss: 0.061845071613788605
Validation loss: 1.4740098202100365

Epoch: 5| Step: 4
Training loss: 0.05999196693301201
Validation loss: 1.5296663763702556

Epoch: 5| Step: 5
Training loss: 0.0626438558101654
Validation loss: 1.5225304736885974

Epoch: 5| Step: 6
Training loss: 0.08236442506313324
Validation loss: 1.5157345046279251

Epoch: 5| Step: 7
Training loss: 0.14465832710266113
Validation loss: 1.5415348570833924

Epoch: 5| Step: 8
Training loss: 0.1048785001039505
Validation loss: 1.5137259934538154

Epoch: 5| Step: 9
Training loss: 0.10255157947540283
Validation loss: 1.522839593630965

Epoch: 5| Step: 10
Training loss: 0.10527194291353226
Validation loss: 1.5183244917982368

Epoch: 519| Step: 0
Training loss: 0.0913485437631607
Validation loss: 1.5128246866246706

Epoch: 5| Step: 1
Training loss: 0.19114556908607483
Validation loss: 1.4971958937183503

Epoch: 5| Step: 2
Training loss: 0.10928776115179062
Validation loss: 1.4946978874103998

Epoch: 5| Step: 3
Training loss: 0.0866975486278534
Validation loss: 1.4831326930753645

Epoch: 5| Step: 4
Training loss: 0.06737908720970154
Validation loss: 1.4702321649879537

Epoch: 5| Step: 5
Training loss: 0.08667318522930145
Validation loss: 1.4970330454969918

Epoch: 5| Step: 6
Training loss: 0.1613418459892273
Validation loss: 1.5287552559247581

Epoch: 5| Step: 7
Training loss: 0.1066732183098793
Validation loss: 1.5226011635154806

Epoch: 5| Step: 8
Training loss: 0.10208755731582642
Validation loss: 1.5272672022542646

Epoch: 5| Step: 9
Training loss: 0.13093766570091248
Validation loss: 1.5363602407516972

Epoch: 5| Step: 10
Training loss: 0.12487944215536118
Validation loss: 1.529177256809768

Epoch: 520| Step: 0
Training loss: 0.05823110416531563
Validation loss: 1.5349859537616852

Epoch: 5| Step: 1
Training loss: 0.08750736713409424
Validation loss: 1.496900503353406

Epoch: 5| Step: 2
Training loss: 0.08506359159946442
Validation loss: 1.497021311072893

Epoch: 5| Step: 3
Training loss: 0.06270624697208405
Validation loss: 1.4946342258043186

Epoch: 5| Step: 4
Training loss: 0.12927980720996857
Validation loss: 1.4976136761326944

Epoch: 5| Step: 5
Training loss: 0.07131015509366989
Validation loss: 1.4619344075520833

Epoch: 5| Step: 6
Training loss: 0.15957102179527283
Validation loss: 1.477460689442132

Epoch: 5| Step: 7
Training loss: 0.09921585023403168
Validation loss: 1.470585242394478

Epoch: 5| Step: 8
Training loss: 0.08856532722711563
Validation loss: 1.481194423091027

Epoch: 5| Step: 9
Training loss: 0.05584144592285156
Validation loss: 1.490334121129846

Epoch: 5| Step: 10
Training loss: 0.06387149542570114
Validation loss: 1.5051977352429462

Epoch: 521| Step: 0
Training loss: 0.10800309479236603
Validation loss: 1.5107506244413313

Epoch: 5| Step: 1
Training loss: 0.12165043503046036
Validation loss: 1.5000794138959659

Epoch: 5| Step: 2
Training loss: 0.06238607317209244
Validation loss: 1.5025204702090191

Epoch: 5| Step: 3
Training loss: 0.07551096379756927
Validation loss: 1.4881791017388786

Epoch: 5| Step: 4
Training loss: 0.07596583664417267
Validation loss: 1.4824384374003257

Epoch: 5| Step: 5
Training loss: 0.14356312155723572
Validation loss: 1.493099735629174

Epoch: 5| Step: 6
Training loss: 0.09826640039682388
Validation loss: 1.4643989205360413

Epoch: 5| Step: 7
Training loss: 0.04172512888908386
Validation loss: 1.47231847880989

Epoch: 5| Step: 8
Training loss: 0.08662168681621552
Validation loss: 1.4819027839168426

Epoch: 5| Step: 9
Training loss: 0.10908512026071548
Validation loss: 1.5002866406594553

Epoch: 5| Step: 10
Training loss: 0.07128983736038208
Validation loss: 1.5068372398294427

Epoch: 522| Step: 0
Training loss: 0.0888625755906105
Validation loss: 1.5175157093232678

Epoch: 5| Step: 1
Training loss: 0.06515568494796753
Validation loss: 1.4988574597143358

Epoch: 5| Step: 2
Training loss: 0.08616158366203308
Validation loss: 1.4845177704288113

Epoch: 5| Step: 3
Training loss: 0.06774687767028809
Validation loss: 1.4882294759955457

Epoch: 5| Step: 4
Training loss: 0.07846195250749588
Validation loss: 1.4805995482270435

Epoch: 5| Step: 5
Training loss: 0.09864553064107895
Validation loss: 1.4836400208934661

Epoch: 5| Step: 6
Training loss: 0.10508278757333755
Validation loss: 1.4669979938896753

Epoch: 5| Step: 7
Training loss: 0.05996861308813095
Validation loss: 1.478668651914084

Epoch: 5| Step: 8
Training loss: 0.04490580037236214
Validation loss: 1.4666286424923969

Epoch: 5| Step: 9
Training loss: 0.08609673380851746
Validation loss: 1.4782402194956297

Epoch: 5| Step: 10
Training loss: 0.08057961612939835
Validation loss: 1.464387070748114

Epoch: 523| Step: 0
Training loss: 0.10399571806192398
Validation loss: 1.4601630972277733

Epoch: 5| Step: 1
Training loss: 0.04379270225763321
Validation loss: 1.4754693956785305

Epoch: 5| Step: 2
Training loss: 0.08257440477609634
Validation loss: 1.4633736520685174

Epoch: 5| Step: 3
Training loss: 0.06499157100915909
Validation loss: 1.4699771916994484

Epoch: 5| Step: 4
Training loss: 0.07531587034463882
Validation loss: 1.4845861004244896

Epoch: 5| Step: 5
Training loss: 0.12797561287879944
Validation loss: 1.4854590495427449

Epoch: 5| Step: 6
Training loss: 0.05309337377548218
Validation loss: 1.4661572620432863

Epoch: 5| Step: 7
Training loss: 0.05516313388943672
Validation loss: 1.4831668875550712

Epoch: 5| Step: 8
Training loss: 0.07155154645442963
Validation loss: 1.501041607190204

Epoch: 5| Step: 9
Training loss: 0.06127657741308212
Validation loss: 1.4849290001776911

Epoch: 5| Step: 10
Training loss: 0.10468082129955292
Validation loss: 1.4961694081624348

Epoch: 524| Step: 0
Training loss: 0.055932920426130295
Validation loss: 1.5072976773785007

Epoch: 5| Step: 1
Training loss: 0.04542933404445648
Validation loss: 1.5175418411531756

Epoch: 5| Step: 2
Training loss: 0.07129259407520294
Validation loss: 1.5028741936529837

Epoch: 5| Step: 3
Training loss: 0.1021643653512001
Validation loss: 1.4962131195170905

Epoch: 5| Step: 4
Training loss: 0.04587877541780472
Validation loss: 1.4769563110925819

Epoch: 5| Step: 5
Training loss: 0.07985874265432358
Validation loss: 1.5051369884962678

Epoch: 5| Step: 6
Training loss: 0.07515264302492142
Validation loss: 1.4810858080464024

Epoch: 5| Step: 7
Training loss: 0.06709393858909607
Validation loss: 1.4721957304144417

Epoch: 5| Step: 8
Training loss: 0.10791392624378204
Validation loss: 1.4761940894588348

Epoch: 5| Step: 9
Training loss: 0.12098824977874756
Validation loss: 1.4694365211712417

Epoch: 5| Step: 10
Training loss: 0.14984045922756195
Validation loss: 1.4619010776601813

Epoch: 525| Step: 0
Training loss: 0.03778313100337982
Validation loss: 1.434448052478093

Epoch: 5| Step: 1
Training loss: 0.0792308822274208
Validation loss: 1.4307191166826474

Epoch: 5| Step: 2
Training loss: 0.10672304779291153
Validation loss: 1.4556346939456077

Epoch: 5| Step: 3
Training loss: 0.08068212866783142
Validation loss: 1.4548742591693837

Epoch: 5| Step: 4
Training loss: 0.10268261283636093
Validation loss: 1.4701290451070315

Epoch: 5| Step: 5
Training loss: 0.07710372656583786
Validation loss: 1.4676032950801234

Epoch: 5| Step: 6
Training loss: 0.06369707733392715
Validation loss: 1.4828386640035978

Epoch: 5| Step: 7
Training loss: 0.1099693775177002
Validation loss: 1.509105308081514

Epoch: 5| Step: 8
Training loss: 0.07493346184492111
Validation loss: 1.5038995230069725

Epoch: 5| Step: 9
Training loss: 0.05530635267496109
Validation loss: 1.5032198621380715

Epoch: 5| Step: 10
Training loss: 0.09698336571455002
Validation loss: 1.5057716984902658

Epoch: 526| Step: 0
Training loss: 0.08498125523328781
Validation loss: 1.5076664891294254

Epoch: 5| Step: 1
Training loss: 0.07845720648765564
Validation loss: 1.5128355109563438

Epoch: 5| Step: 2
Training loss: 0.11353769153356552
Validation loss: 1.5011361427204584

Epoch: 5| Step: 3
Training loss: 0.10731993615627289
Validation loss: 1.4937033089258338

Epoch: 5| Step: 4
Training loss: 0.08379219472408295
Validation loss: 1.5035030431644891

Epoch: 5| Step: 5
Training loss: 0.07500781863927841
Validation loss: 1.4941739061827302

Epoch: 5| Step: 6
Training loss: 0.10127270221710205
Validation loss: 1.484770332613299

Epoch: 5| Step: 7
Training loss: 0.07593949139118195
Validation loss: 1.4802386735075264

Epoch: 5| Step: 8
Training loss: 0.07450781017541885
Validation loss: 1.441390013182035

Epoch: 5| Step: 9
Training loss: 0.1440849006175995
Validation loss: 1.4580494024420296

Epoch: 5| Step: 10
Training loss: 0.10820233076810837
Validation loss: 1.4201081209285285

Epoch: 527| Step: 0
Training loss: 0.05486941337585449
Validation loss: 1.4426425785146735

Epoch: 5| Step: 1
Training loss: 0.03962547704577446
Validation loss: 1.462795829260221

Epoch: 5| Step: 2
Training loss: 0.09337232261896133
Validation loss: 1.4437756115390408

Epoch: 5| Step: 3
Training loss: 0.0892186164855957
Validation loss: 1.472887695476573

Epoch: 5| Step: 4
Training loss: 0.17805162072181702
Validation loss: 1.4942108508079284

Epoch: 5| Step: 5
Training loss: 0.06305928528308868
Validation loss: 1.4883910789284656

Epoch: 5| Step: 6
Training loss: 0.058580078184604645
Validation loss: 1.4770826934486307

Epoch: 5| Step: 7
Training loss: 0.09577792137861252
Validation loss: 1.5011019399089198

Epoch: 5| Step: 8
Training loss: 0.1112610325217247
Validation loss: 1.492189968785932

Epoch: 5| Step: 9
Training loss: 0.087882861495018
Validation loss: 1.4826199380300378

Epoch: 5| Step: 10
Training loss: 0.0661773756146431
Validation loss: 1.4701911928833171

Epoch: 528| Step: 0
Training loss: 0.08270864188671112
Validation loss: 1.4576104699924428

Epoch: 5| Step: 1
Training loss: 0.06568954885005951
Validation loss: 1.4780805175022413

Epoch: 5| Step: 2
Training loss: 0.06913022696971893
Validation loss: 1.4715461769411642

Epoch: 5| Step: 3
Training loss: 0.08905865997076035
Validation loss: 1.4408173048368065

Epoch: 5| Step: 4
Training loss: 0.05017811059951782
Validation loss: 1.3956133255394556

Epoch: 5| Step: 5
Training loss: 0.10599061101675034
Validation loss: 1.4280117628394917

Epoch: 5| Step: 6
Training loss: 0.09015356004238129
Validation loss: 1.4250655315255607

Epoch: 5| Step: 7
Training loss: 0.05097929388284683
Validation loss: 1.4392043416218092

Epoch: 5| Step: 8
Training loss: 0.06033666804432869
Validation loss: 1.4547917765955771

Epoch: 5| Step: 9
Training loss: 0.04754768684506416
Validation loss: 1.4829271352419289

Epoch: 5| Step: 10
Training loss: 0.10240992903709412
Validation loss: 1.4764995972315471

Epoch: 529| Step: 0
Training loss: 0.13822825253009796
Validation loss: 1.5163206182500368

Epoch: 5| Step: 1
Training loss: 0.07071111351251602
Validation loss: 1.5122542509468653

Epoch: 5| Step: 2
Training loss: 0.0701487809419632
Validation loss: 1.4520516344296035

Epoch: 5| Step: 3
Training loss: 0.1008620411157608
Validation loss: 1.4701466380908925

Epoch: 5| Step: 4
Training loss: 0.09705816209316254
Validation loss: 1.459600765218017

Epoch: 5| Step: 5
Training loss: 0.07470780611038208
Validation loss: 1.4607962459646247

Epoch: 5| Step: 6
Training loss: 0.0674169510602951
Validation loss: 1.4652155727468512

Epoch: 5| Step: 7
Training loss: 0.04594530165195465
Validation loss: 1.4544842089376142

Epoch: 5| Step: 8
Training loss: 0.07330057770013809
Validation loss: 1.4851869280620287

Epoch: 5| Step: 9
Training loss: 0.10277146100997925
Validation loss: 1.4465780533770078

Epoch: 5| Step: 10
Training loss: 0.0742538645863533
Validation loss: 1.4801723559697468

Epoch: 530| Step: 0
Training loss: 0.05663151666522026
Validation loss: 1.4697123560854184

Epoch: 5| Step: 1
Training loss: 0.07717499136924744
Validation loss: 1.49519165613318

Epoch: 5| Step: 2
Training loss: 0.028065090999007225
Validation loss: 1.4881390179357221

Epoch: 5| Step: 3
Training loss: 0.15553513169288635
Validation loss: 1.4892999465747545

Epoch: 5| Step: 4
Training loss: 0.0514480285346508
Validation loss: 1.524220298695308

Epoch: 5| Step: 5
Training loss: 0.07758814841508865
Validation loss: 1.4998788346526444

Epoch: 5| Step: 6
Training loss: 0.06942912936210632
Validation loss: 1.5089859411280642

Epoch: 5| Step: 7
Training loss: 0.11533091217279434
Validation loss: 1.5002833515085199

Epoch: 5| Step: 8
Training loss: 0.10635106265544891
Validation loss: 1.473157504553436

Epoch: 5| Step: 9
Training loss: 0.08676674216985703
Validation loss: 1.4749540834016697

Epoch: 5| Step: 10
Training loss: 0.11762108653783798
Validation loss: 1.4524449366395191

Epoch: 531| Step: 0
Training loss: 0.10148902237415314
Validation loss: 1.4451553731836297

Epoch: 5| Step: 1
Training loss: 0.08289210498332977
Validation loss: 1.4419314476751512

Epoch: 5| Step: 2
Training loss: 0.09199939668178558
Validation loss: 1.4441926222975536

Epoch: 5| Step: 3
Training loss: 0.08123272657394409
Validation loss: 1.4465278425524313

Epoch: 5| Step: 4
Training loss: 0.08854258805513382
Validation loss: 1.4797084741694952

Epoch: 5| Step: 5
Training loss: 0.10105986893177032
Validation loss: 1.4877793872228233

Epoch: 5| Step: 6
Training loss: 0.048353713005781174
Validation loss: 1.4822087903176584

Epoch: 5| Step: 7
Training loss: 0.0514477863907814
Validation loss: 1.4860478934421335

Epoch: 5| Step: 8
Training loss: 0.03498942777514458
Validation loss: 1.494042408722703

Epoch: 5| Step: 9
Training loss: 0.09015432000160217
Validation loss: 1.4992878385769424

Epoch: 5| Step: 10
Training loss: 0.06414678692817688
Validation loss: 1.4930896323214295

Epoch: 532| Step: 0
Training loss: 0.07704974710941315
Validation loss: 1.471257653287662

Epoch: 5| Step: 1
Training loss: 0.07263749092817307
Validation loss: 1.476765122464908

Epoch: 5| Step: 2
Training loss: 0.05096357315778732
Validation loss: 1.4498547251506517

Epoch: 5| Step: 3
Training loss: 0.08072998374700546
Validation loss: 1.4609393842758671

Epoch: 5| Step: 4
Training loss: 0.08501283824443817
Validation loss: 1.4565057818607619

Epoch: 5| Step: 5
Training loss: 0.1297367513179779
Validation loss: 1.4643233386419152

Epoch: 5| Step: 6
Training loss: 0.0672205239534378
Validation loss: 1.4690171582724458

Epoch: 5| Step: 7
Training loss: 0.10890626907348633
Validation loss: 1.463469184214069

Epoch: 5| Step: 8
Training loss: 0.08873620629310608
Validation loss: 1.4835900734829646

Epoch: 5| Step: 9
Training loss: 0.10030434280633926
Validation loss: 1.4953472909107004

Epoch: 5| Step: 10
Training loss: 0.10041961818933487
Validation loss: 1.5123955101095221

Epoch: 533| Step: 0
Training loss: 0.11404267698526382
Validation loss: 1.5243099351083078

Epoch: 5| Step: 1
Training loss: 0.12130387872457504
Validation loss: 1.5227575622579104

Epoch: 5| Step: 2
Training loss: 0.15218058228492737
Validation loss: 1.5206752143880373

Epoch: 5| Step: 3
Training loss: 0.050487350672483444
Validation loss: 1.5163472403762162

Epoch: 5| Step: 4
Training loss: 0.10372169315814972
Validation loss: 1.4904602317399875

Epoch: 5| Step: 5
Training loss: 0.06326787918806076
Validation loss: 1.4742556387378323

Epoch: 5| Step: 6
Training loss: 0.09211602061986923
Validation loss: 1.5038202071702609

Epoch: 5| Step: 7
Training loss: 0.06301549822092056
Validation loss: 1.4516823099505516

Epoch: 5| Step: 8
Training loss: 0.055460166186094284
Validation loss: 1.4417948799748574

Epoch: 5| Step: 9
Training loss: 0.08970727026462555
Validation loss: 1.4477272623328752

Epoch: 5| Step: 10
Training loss: 0.07325269281864166
Validation loss: 1.4724122651161686

Epoch: 534| Step: 0
Training loss: 0.06867983192205429
Validation loss: 1.482492264880929

Epoch: 5| Step: 1
Training loss: 0.06976307928562164
Validation loss: 1.4605448938185168

Epoch: 5| Step: 2
Training loss: 0.12762923538684845
Validation loss: 1.4671599057412916

Epoch: 5| Step: 3
Training loss: 0.10279345512390137
Validation loss: 1.4799628539751934

Epoch: 5| Step: 4
Training loss: 0.07030026614665985
Validation loss: 1.4781080471572055

Epoch: 5| Step: 5
Training loss: 0.059098076075315475
Validation loss: 1.5151148944772699

Epoch: 5| Step: 6
Training loss: 0.16850721836090088
Validation loss: 1.4901384499765211

Epoch: 5| Step: 7
Training loss: 0.08225439488887787
Validation loss: 1.4963869740886073

Epoch: 5| Step: 8
Training loss: 0.0935821384191513
Validation loss: 1.4943064951127576

Epoch: 5| Step: 9
Training loss: 0.148150235414505
Validation loss: 1.499219822627242

Epoch: 5| Step: 10
Training loss: 0.1211949959397316
Validation loss: 1.5047339649610623

Epoch: 535| Step: 0
Training loss: 0.07254016399383545
Validation loss: 1.5021055308721398

Epoch: 5| Step: 1
Training loss: 0.06729438155889511
Validation loss: 1.5107681571796376

Epoch: 5| Step: 2
Training loss: 0.12432684749364853
Validation loss: 1.4882832957852272

Epoch: 5| Step: 3
Training loss: 0.0748615711927414
Validation loss: 1.466983542647413

Epoch: 5| Step: 4
Training loss: 0.11197976022958755
Validation loss: 1.4747650084957

Epoch: 5| Step: 5
Training loss: 0.09346753358840942
Validation loss: 1.4716702289478754

Epoch: 5| Step: 6
Training loss: 0.06260880827903748
Validation loss: 1.4957983109258837

Epoch: 5| Step: 7
Training loss: 0.04849144071340561
Validation loss: 1.493386976180538

Epoch: 5| Step: 8
Training loss: 0.10649390518665314
Validation loss: 1.49804126831793

Epoch: 5| Step: 9
Training loss: 0.053717613220214844
Validation loss: 1.505928320269431

Epoch: 5| Step: 10
Training loss: 0.04715350642800331
Validation loss: 1.494102874109822

Epoch: 536| Step: 0
Training loss: 0.1169828325510025
Validation loss: 1.5019731918970745

Epoch: 5| Step: 1
Training loss: 0.0916789323091507
Validation loss: 1.4928712178302068

Epoch: 5| Step: 2
Training loss: 0.06506367772817612
Validation loss: 1.4958960612614949

Epoch: 5| Step: 3
Training loss: 0.06040032580494881
Validation loss: 1.5001635500179824

Epoch: 5| Step: 4
Training loss: 0.05080261826515198
Validation loss: 1.4612152576446533

Epoch: 5| Step: 5
Training loss: 0.07482790946960449
Validation loss: 1.482354429460341

Epoch: 5| Step: 6
Training loss: 0.04999580979347229
Validation loss: 1.4639245335773756

Epoch: 5| Step: 7
Training loss: 0.10163629055023193
Validation loss: 1.4914259141491306

Epoch: 5| Step: 8
Training loss: 0.09667931497097015
Validation loss: 1.4927080715856245

Epoch: 5| Step: 9
Training loss: 0.07964210212230682
Validation loss: 1.4766482140428276

Epoch: 5| Step: 10
Training loss: 0.10471709817647934
Validation loss: 1.500240941201487

Epoch: 537| Step: 0
Training loss: 0.09180911630392075
Validation loss: 1.4961379965146382

Epoch: 5| Step: 1
Training loss: 0.09977176040410995
Validation loss: 1.4834132598292442

Epoch: 5| Step: 2
Training loss: 0.09431107342243195
Validation loss: 1.4867345261317428

Epoch: 5| Step: 3
Training loss: 0.06950336694717407
Validation loss: 1.4836612311742639

Epoch: 5| Step: 4
Training loss: 0.06492725759744644
Validation loss: 1.4862945489985968

Epoch: 5| Step: 5
Training loss: 0.10286007076501846
Validation loss: 1.4769346034655007

Epoch: 5| Step: 6
Training loss: 0.0670856386423111
Validation loss: 1.466565433368888

Epoch: 5| Step: 7
Training loss: 0.05674193054437637
Validation loss: 1.4527189052233132

Epoch: 5| Step: 8
Training loss: 0.12337897717952728
Validation loss: 1.462081741261226

Epoch: 5| Step: 9
Training loss: 0.10576434433460236
Validation loss: 1.4677849418373519

Epoch: 5| Step: 10
Training loss: 0.09308384358882904
Validation loss: 1.4646552890859625

Epoch: 538| Step: 0
Training loss: 0.11360158771276474
Validation loss: 1.4689328234682801

Epoch: 5| Step: 1
Training loss: 0.03966609388589859
Validation loss: 1.4700590692540652

Epoch: 5| Step: 2
Training loss: 0.08317722380161285
Validation loss: 1.4820431483689176

Epoch: 5| Step: 3
Training loss: 0.09419595450162888
Validation loss: 1.512798596453923

Epoch: 5| Step: 4
Training loss: 0.09733662754297256
Validation loss: 1.4872805892780263

Epoch: 5| Step: 5
Training loss: 0.04919884353876114
Validation loss: 1.4934243925156132

Epoch: 5| Step: 6
Training loss: 0.0919661670923233
Validation loss: 1.4745230649107246

Epoch: 5| Step: 7
Training loss: 0.1092466339468956
Validation loss: 1.4587267669298316

Epoch: 5| Step: 8
Training loss: 0.07406959682703018
Validation loss: 1.453610074135565

Epoch: 5| Step: 9
Training loss: 0.07621230185031891
Validation loss: 1.4689797316828082

Epoch: 5| Step: 10
Training loss: 0.07937678694725037
Validation loss: 1.462413505841327

Epoch: 539| Step: 0
Training loss: 0.10119354724884033
Validation loss: 1.4503516689423592

Epoch: 5| Step: 1
Training loss: 0.09914422780275345
Validation loss: 1.4642583657336492

Epoch: 5| Step: 2
Training loss: 0.0761570930480957
Validation loss: 1.4782270231554586

Epoch: 5| Step: 3
Training loss: 0.1031838208436966
Validation loss: 1.4683995964706584

Epoch: 5| Step: 4
Training loss: 0.1020287498831749
Validation loss: 1.504137949276996

Epoch: 5| Step: 5
Training loss: 0.11046657711267471
Validation loss: 1.5170910717338644

Epoch: 5| Step: 6
Training loss: 0.14458301663398743
Validation loss: 1.512528697649638

Epoch: 5| Step: 7
Training loss: 0.06544463336467743
Validation loss: 1.4842848341952088

Epoch: 5| Step: 8
Training loss: 0.05944204330444336
Validation loss: 1.4988881670018679

Epoch: 5| Step: 9
Training loss: 0.0719137042760849
Validation loss: 1.4848405199666177

Epoch: 5| Step: 10
Training loss: 0.049105267971754074
Validation loss: 1.4621855571705809

Epoch: 540| Step: 0
Training loss: 0.10542116314172745
Validation loss: 1.4975648522377014

Epoch: 5| Step: 1
Training loss: 0.09953518956899643
Validation loss: 1.4934199881810013

Epoch: 5| Step: 2
Training loss: 0.10463360697031021
Validation loss: 1.4855742121255526

Epoch: 5| Step: 3
Training loss: 0.08707556873559952
Validation loss: 1.463526609123394

Epoch: 5| Step: 4
Training loss: 0.0642780214548111
Validation loss: 1.4853385251055482

Epoch: 5| Step: 5
Training loss: 0.0570736899971962
Validation loss: 1.4746228148860316

Epoch: 5| Step: 6
Training loss: 0.11923141777515411
Validation loss: 1.4857828770914385

Epoch: 5| Step: 7
Training loss: 0.04541391134262085
Validation loss: 1.4630845874868414

Epoch: 5| Step: 8
Training loss: 0.057140052318573
Validation loss: 1.4579897977972542

Epoch: 5| Step: 9
Training loss: 0.05173072963953018
Validation loss: 1.463833402561885

Epoch: 5| Step: 10
Training loss: 0.10804367065429688
Validation loss: 1.4793859425411429

Epoch: 541| Step: 0
Training loss: 0.04130983352661133
Validation loss: 1.4510983241501676

Epoch: 5| Step: 1
Training loss: 0.10268761217594147
Validation loss: 1.4428005167233047

Epoch: 5| Step: 2
Training loss: 0.09750399738550186
Validation loss: 1.4596148716506137

Epoch: 5| Step: 3
Training loss: 0.08024319261312485
Validation loss: 1.4603627099785754

Epoch: 5| Step: 4
Training loss: 0.03744039684534073
Validation loss: 1.447495856592732

Epoch: 5| Step: 5
Training loss: 0.05631374195218086
Validation loss: 1.492428880865856

Epoch: 5| Step: 6
Training loss: 0.057145267724990845
Validation loss: 1.5076229956842238

Epoch: 5| Step: 7
Training loss: 0.08427771925926208
Validation loss: 1.5179952165131927

Epoch: 5| Step: 8
Training loss: 0.09932366013526917
Validation loss: 1.5125553197758173

Epoch: 5| Step: 9
Training loss: 0.04884503409266472
Validation loss: 1.5499951865083428

Epoch: 5| Step: 10
Training loss: 0.08337794244289398
Validation loss: 1.5397067685281076

Epoch: 542| Step: 0
Training loss: 0.09485186636447906
Validation loss: 1.5277182376512917

Epoch: 5| Step: 1
Training loss: 0.08881029486656189
Validation loss: 1.5001337746138215

Epoch: 5| Step: 2
Training loss: 0.04148469120264053
Validation loss: 1.4882429081906554

Epoch: 5| Step: 3
Training loss: 0.08561545610427856
Validation loss: 1.4948937636549755

Epoch: 5| Step: 4
Training loss: 0.07956765592098236
Validation loss: 1.469686713910872

Epoch: 5| Step: 5
Training loss: 0.1349928081035614
Validation loss: 1.4514227464634886

Epoch: 5| Step: 6
Training loss: 0.042493194341659546
Validation loss: 1.4281695786342825

Epoch: 5| Step: 7
Training loss: 0.062650665640831
Validation loss: 1.4573249374666521

Epoch: 5| Step: 8
Training loss: 0.044222742319107056
Validation loss: 1.4480575412832282

Epoch: 5| Step: 9
Training loss: 0.05503510311245918
Validation loss: 1.475635297836796

Epoch: 5| Step: 10
Training loss: 0.049264103174209595
Validation loss: 1.5150179132338493

Epoch: 543| Step: 0
Training loss: 0.05086923763155937
Validation loss: 1.4883560467791814

Epoch: 5| Step: 1
Training loss: 0.04801531881093979
Validation loss: 1.4898805951559415

Epoch: 5| Step: 2
Training loss: 0.05611404776573181
Validation loss: 1.4871554297785605

Epoch: 5| Step: 3
Training loss: 0.0918743908405304
Validation loss: 1.4981893390737555

Epoch: 5| Step: 4
Training loss: 0.048293761909008026
Validation loss: 1.4816150985738283

Epoch: 5| Step: 5
Training loss: 0.09117104113101959
Validation loss: 1.4726921178961312

Epoch: 5| Step: 6
Training loss: 0.10504300892353058
Validation loss: 1.4777804408022153

Epoch: 5| Step: 7
Training loss: 0.07487158477306366
Validation loss: 1.4921917171888455

Epoch: 5| Step: 8
Training loss: 0.08307557553052902
Validation loss: 1.4887566374194237

Epoch: 5| Step: 9
Training loss: 0.07163344323635101
Validation loss: 1.4761662367851502

Epoch: 5| Step: 10
Training loss: 0.1055479645729065
Validation loss: 1.494484491245721

Epoch: 544| Step: 0
Training loss: 0.05332787707448006
Validation loss: 1.5141649028306365

Epoch: 5| Step: 1
Training loss: 0.109405018389225
Validation loss: 1.503816480277687

Epoch: 5| Step: 2
Training loss: 0.0779566615819931
Validation loss: 1.4930929445451306

Epoch: 5| Step: 3
Training loss: 0.05296311900019646
Validation loss: 1.4730877427644626

Epoch: 5| Step: 4
Training loss: 0.0846751406788826
Validation loss: 1.4597438509746263

Epoch: 5| Step: 5
Training loss: 0.09537456929683685
Validation loss: 1.4709131166499148

Epoch: 5| Step: 6
Training loss: 0.05591447278857231
Validation loss: 1.4507790509090628

Epoch: 5| Step: 7
Training loss: 0.06233157962560654
Validation loss: 1.4404427479672175

Epoch: 5| Step: 8
Training loss: 0.10619121789932251
Validation loss: 1.4566207957524124

Epoch: 5| Step: 9
Training loss: 0.11576811969280243
Validation loss: 1.474403081401702

Epoch: 5| Step: 10
Training loss: 0.058367811143398285
Validation loss: 1.4824426558709913

Epoch: 545| Step: 0
Training loss: 0.0957469493150711
Validation loss: 1.4863246935670094

Epoch: 5| Step: 1
Training loss: 0.05294587463140488
Validation loss: 1.5030682317672237

Epoch: 5| Step: 2
Training loss: 0.08896447718143463
Validation loss: 1.4998150102553829

Epoch: 5| Step: 3
Training loss: 0.08939464390277863
Validation loss: 1.4845447437737578

Epoch: 5| Step: 4
Training loss: 0.09734552353620529
Validation loss: 1.5095222637217531

Epoch: 5| Step: 5
Training loss: 0.13189637660980225
Validation loss: 1.4766959759496874

Epoch: 5| Step: 6
Training loss: 0.08643797785043716
Validation loss: 1.473595812756528

Epoch: 5| Step: 7
Training loss: 0.0953628420829773
Validation loss: 1.4776224141479821

Epoch: 5| Step: 8
Training loss: 0.10218630731105804
Validation loss: 1.476733640316994

Epoch: 5| Step: 9
Training loss: 0.10907238721847534
Validation loss: 1.4790712960304753

Epoch: 5| Step: 10
Training loss: 0.08289562910795212
Validation loss: 1.4967671344357152

Epoch: 546| Step: 0
Training loss: 0.08503587543964386
Validation loss: 1.511883626061101

Epoch: 5| Step: 1
Training loss: 0.08900760859251022
Validation loss: 1.5100014453293176

Epoch: 5| Step: 2
Training loss: 0.05169152468442917
Validation loss: 1.5152475449346727

Epoch: 5| Step: 3
Training loss: 0.09585119038820267
Validation loss: 1.5185540491534817

Epoch: 5| Step: 4
Training loss: 0.06196952983736992
Validation loss: 1.4860981664349955

Epoch: 5| Step: 5
Training loss: 0.08245871216058731
Validation loss: 1.4819591673471595

Epoch: 5| Step: 6
Training loss: 0.0963045209646225
Validation loss: 1.4652325645569833

Epoch: 5| Step: 7
Training loss: 0.055734239518642426
Validation loss: 1.4672230020646126

Epoch: 5| Step: 8
Training loss: 0.09315499663352966
Validation loss: 1.4681581758683728

Epoch: 5| Step: 9
Training loss: 0.12472659349441528
Validation loss: 1.4429731804837462

Epoch: 5| Step: 10
Training loss: 0.08506154268980026
Validation loss: 1.4433494094879395

Epoch: 547| Step: 0
Training loss: 0.0751568078994751
Validation loss: 1.4344379414794266

Epoch: 5| Step: 1
Training loss: 0.07908265292644501
Validation loss: 1.443918017930882

Epoch: 5| Step: 2
Training loss: 0.08630801737308502
Validation loss: 1.4563443506917646

Epoch: 5| Step: 3
Training loss: 0.07466410845518112
Validation loss: 1.4859258026205084

Epoch: 5| Step: 4
Training loss: 0.0849437266588211
Validation loss: 1.4886350093349334

Epoch: 5| Step: 5
Training loss: 0.04499427229166031
Validation loss: 1.5026825756155036

Epoch: 5| Step: 6
Training loss: 0.08273054659366608
Validation loss: 1.5197151219973

Epoch: 5| Step: 7
Training loss: 0.09619350731372833
Validation loss: 1.5304655695474276

Epoch: 5| Step: 8
Training loss: 0.0937584787607193
Validation loss: 1.5436298719016455

Epoch: 5| Step: 9
Training loss: 0.12143013626337051
Validation loss: 1.5395208821501782

Epoch: 5| Step: 10
Training loss: 0.07289767265319824
Validation loss: 1.5204290331050914

Epoch: 548| Step: 0
Training loss: 0.11104967445135117
Validation loss: 1.4744040209759948

Epoch: 5| Step: 1
Training loss: 0.05207037180662155
Validation loss: 1.4529538539148146

Epoch: 5| Step: 2
Training loss: 0.08809319138526917
Validation loss: 1.416679492560766

Epoch: 5| Step: 3
Training loss: 0.1101030483841896
Validation loss: 1.4018031525355514

Epoch: 5| Step: 4
Training loss: 0.08385894447565079
Validation loss: 1.415887015481149

Epoch: 5| Step: 5
Training loss: 0.0644516795873642
Validation loss: 1.4234976063492477

Epoch: 5| Step: 6
Training loss: 0.11283920705318451
Validation loss: 1.4263654011552052

Epoch: 5| Step: 7
Training loss: 0.05725983530282974
Validation loss: 1.4499574681764007

Epoch: 5| Step: 8
Training loss: 0.08572345227003098
Validation loss: 1.4562991819074076

Epoch: 5| Step: 9
Training loss: 0.06781121343374252
Validation loss: 1.4574218232144591

Epoch: 5| Step: 10
Training loss: 0.08270100504159927
Validation loss: 1.4861889154680314

Epoch: 549| Step: 0
Training loss: 0.08596253395080566
Validation loss: 1.4887410408707076

Epoch: 5| Step: 1
Training loss: 0.06305201351642609
Validation loss: 1.494158028274454

Epoch: 5| Step: 2
Training loss: 0.08720382302999496
Validation loss: 1.5183608762679561

Epoch: 5| Step: 3
Training loss: 0.08193137496709824
Validation loss: 1.520640496284731

Epoch: 5| Step: 4
Training loss: 0.12458382546901703
Validation loss: 1.5057574369574105

Epoch: 5| Step: 5
Training loss: 0.09550745785236359
Validation loss: 1.5246163286188597

Epoch: 5| Step: 6
Training loss: 0.10707442462444305
Validation loss: 1.5336130280648508

Epoch: 5| Step: 7
Training loss: 0.1487213373184204
Validation loss: 1.5155632213879657

Epoch: 5| Step: 8
Training loss: 0.06666497886180878
Validation loss: 1.5171564650791947

Epoch: 5| Step: 9
Training loss: 0.11288640648126602
Validation loss: 1.499661548163301

Epoch: 5| Step: 10
Training loss: 0.055204372853040695
Validation loss: 1.5106141535184716

Epoch: 550| Step: 0
Training loss: 0.043247390538454056
Validation loss: 1.5230093848320745

Epoch: 5| Step: 1
Training loss: 0.07705358415842056
Validation loss: 1.5117553998065252

Epoch: 5| Step: 2
Training loss: 0.07902657985687256
Validation loss: 1.5075742621575632

Epoch: 5| Step: 3
Training loss: 0.0871398001909256
Validation loss: 1.5026710943509174

Epoch: 5| Step: 4
Training loss: 0.10209591686725616
Validation loss: 1.469357600135188

Epoch: 5| Step: 5
Training loss: 0.08689835667610168
Validation loss: 1.4404268700589415

Epoch: 5| Step: 6
Training loss: 0.037471190094947815
Validation loss: 1.4301359679109307

Epoch: 5| Step: 7
Training loss: 0.12570752203464508
Validation loss: 1.4170593279664234

Epoch: 5| Step: 8
Training loss: 0.0710182636976242
Validation loss: 1.4126338638285154

Epoch: 5| Step: 9
Training loss: 0.1378999501466751
Validation loss: 1.4004459406739922

Epoch: 5| Step: 10
Training loss: 0.14046964049339294
Validation loss: 1.4240100419008603

Epoch: 551| Step: 0
Training loss: 0.07260572910308838
Validation loss: 1.468423584456085

Epoch: 5| Step: 1
Training loss: 0.08180944621562958
Validation loss: 1.4646798013358988

Epoch: 5| Step: 2
Training loss: 0.057894639670848846
Validation loss: 1.4847438732783

Epoch: 5| Step: 3
Training loss: 0.10261009633541107
Validation loss: 1.5150639305832565

Epoch: 5| Step: 4
Training loss: 0.1052117720246315
Validation loss: 1.4877575937137808

Epoch: 5| Step: 5
Training loss: 0.08766503632068634
Validation loss: 1.4927759452532696

Epoch: 5| Step: 6
Training loss: 0.06080659478902817
Validation loss: 1.4873728905954668

Epoch: 5| Step: 7
Training loss: 0.05242717266082764
Validation loss: 1.471145119718326

Epoch: 5| Step: 8
Training loss: 0.058848123997449875
Validation loss: 1.455266224440708

Epoch: 5| Step: 9
Training loss: 0.08821313828229904
Validation loss: 1.469203774647046

Epoch: 5| Step: 10
Training loss: 0.045966748148202896
Validation loss: 1.4509696024720387

Epoch: 552| Step: 0
Training loss: 0.061862487345933914
Validation loss: 1.4330456487594112

Epoch: 5| Step: 1
Training loss: 0.12653407454490662
Validation loss: 1.4271013147087508

Epoch: 5| Step: 2
Training loss: 0.06385061889886856
Validation loss: 1.4469322889081893

Epoch: 5| Step: 3
Training loss: 0.10552436113357544
Validation loss: 1.4581187822485482

Epoch: 5| Step: 4
Training loss: 0.09448890388011932
Validation loss: 1.4690005151174401

Epoch: 5| Step: 5
Training loss: 0.05646786093711853
Validation loss: 1.4883444142597977

Epoch: 5| Step: 6
Training loss: 0.09241117537021637
Validation loss: 1.4904719770595591

Epoch: 5| Step: 7
Training loss: 0.07515691220760345
Validation loss: 1.4936050061256654

Epoch: 5| Step: 8
Training loss: 0.09661191701889038
Validation loss: 1.4966988486628379

Epoch: 5| Step: 9
Training loss: 0.07180526107549667
Validation loss: 1.4966052219431887

Epoch: 5| Step: 10
Training loss: 0.0874580591917038
Validation loss: 1.4907955123532204

Epoch: 553| Step: 0
Training loss: 0.07922640442848206
Validation loss: 1.5044571225361159

Epoch: 5| Step: 1
Training loss: 0.044107649475336075
Validation loss: 1.5080604937768751

Epoch: 5| Step: 2
Training loss: 0.035809338092803955
Validation loss: 1.5121603640176917

Epoch: 5| Step: 3
Training loss: 0.09054465591907501
Validation loss: 1.529565590684132

Epoch: 5| Step: 4
Training loss: 0.0469244047999382
Validation loss: 1.5051124454826437

Epoch: 5| Step: 5
Training loss: 0.0874597355723381
Validation loss: 1.4947490974139142

Epoch: 5| Step: 6
Training loss: 0.07707800716161728
Validation loss: 1.4739033855417722

Epoch: 5| Step: 7
Training loss: 0.07145895063877106
Validation loss: 1.473540444527903

Epoch: 5| Step: 8
Training loss: 0.11979814618825912
Validation loss: 1.4738651911417644

Epoch: 5| Step: 9
Training loss: 0.0713963732123375
Validation loss: 1.4875238928743588

Epoch: 5| Step: 10
Training loss: 0.07084092497825623
Validation loss: 1.4824146237424625

Epoch: 554| Step: 0
Training loss: 0.079344242811203
Validation loss: 1.4678189190485145

Epoch: 5| Step: 1
Training loss: 0.12307809293270111
Validation loss: 1.4687519291395783

Epoch: 5| Step: 2
Training loss: 0.08857037127017975
Validation loss: 1.4823968307946318

Epoch: 5| Step: 3
Training loss: 0.062348365783691406
Validation loss: 1.4691680810784782

Epoch: 5| Step: 4
Training loss: 0.06172361224889755
Validation loss: 1.5038372867850847

Epoch: 5| Step: 5
Training loss: 0.07916046679019928
Validation loss: 1.51360357833165

Epoch: 5| Step: 6
Training loss: 0.1613449901342392
Validation loss: 1.516954711688462

Epoch: 5| Step: 7
Training loss: 0.05498379468917847
Validation loss: 1.5280008495494883

Epoch: 5| Step: 8
Training loss: 0.09148282557725906
Validation loss: 1.5151227597267396

Epoch: 5| Step: 9
Training loss: 0.042710334062576294
Validation loss: 1.518380694491889

Epoch: 5| Step: 10
Training loss: 0.076689213514328
Validation loss: 1.4667853719444686

Epoch: 555| Step: 0
Training loss: 0.059995949268341064
Validation loss: 1.486284536700095

Epoch: 5| Step: 1
Training loss: 0.042951419949531555
Validation loss: 1.4723284885447512

Epoch: 5| Step: 2
Training loss: 0.07390955090522766
Validation loss: 1.4623161695336784

Epoch: 5| Step: 3
Training loss: 0.0865713506937027
Validation loss: 1.4713622370073873

Epoch: 5| Step: 4
Training loss: 0.06658784300088882
Validation loss: 1.4809047188810123

Epoch: 5| Step: 5
Training loss: 0.09325194358825684
Validation loss: 1.4933015633654851

Epoch: 5| Step: 6
Training loss: 0.1354987919330597
Validation loss: 1.471569158697641

Epoch: 5| Step: 7
Training loss: 0.06311376392841339
Validation loss: 1.4744863420404413

Epoch: 5| Step: 8
Training loss: 0.09896218776702881
Validation loss: 1.4865717862242012

Epoch: 5| Step: 9
Training loss: 0.06696079671382904
Validation loss: 1.4863987699631722

Epoch: 5| Step: 10
Training loss: 0.06361287832260132
Validation loss: 1.48631618484374

Epoch: 556| Step: 0
Training loss: 0.049183521419763565
Validation loss: 1.4923966033484346

Epoch: 5| Step: 1
Training loss: 0.07922518253326416
Validation loss: 1.4866764801804737

Epoch: 5| Step: 2
Training loss: 0.10081547498703003
Validation loss: 1.4640898102073259

Epoch: 5| Step: 3
Training loss: 0.06454621255397797
Validation loss: 1.481623129178119

Epoch: 5| Step: 4
Training loss: 0.06824247539043427
Validation loss: 1.488023187524529

Epoch: 5| Step: 5
Training loss: 0.07458142191171646
Validation loss: 1.4861784545324181

Epoch: 5| Step: 6
Training loss: 0.07749363034963608
Validation loss: 1.481061093268856

Epoch: 5| Step: 7
Training loss: 0.06061090901494026
Validation loss: 1.4868283041061894

Epoch: 5| Step: 8
Training loss: 0.08613960444927216
Validation loss: 1.4914725877905404

Epoch: 5| Step: 9
Training loss: 0.0600728802382946
Validation loss: 1.4799114132440219

Epoch: 5| Step: 10
Training loss: 0.13012577593326569
Validation loss: 1.4706365664800007

Epoch: 557| Step: 0
Training loss: 0.09192930907011032
Validation loss: 1.487346718388219

Epoch: 5| Step: 1
Training loss: 0.02936781384050846
Validation loss: 1.475837516528304

Epoch: 5| Step: 2
Training loss: 0.07957438379526138
Validation loss: 1.500407120232941

Epoch: 5| Step: 3
Training loss: 0.07546714693307877
Validation loss: 1.4971528860830492

Epoch: 5| Step: 4
Training loss: 0.055895477533340454
Validation loss: 1.474776779451678

Epoch: 5| Step: 5
Training loss: 0.054698776453733444
Validation loss: 1.4998278822950137

Epoch: 5| Step: 6
Training loss: 0.06897982209920883
Validation loss: 1.5007355072165047

Epoch: 5| Step: 7
Training loss: 0.06431785225868225
Validation loss: 1.5203187901486632

Epoch: 5| Step: 8
Training loss: 0.08426062762737274
Validation loss: 1.5000219678366056

Epoch: 5| Step: 9
Training loss: 0.07083369046449661
Validation loss: 1.5090521804748043

Epoch: 5| Step: 10
Training loss: 0.0751374214887619
Validation loss: 1.5085172531425313

Epoch: 558| Step: 0
Training loss: 0.05870508402585983
Validation loss: 1.4990299811927221

Epoch: 5| Step: 1
Training loss: 0.06195705384016037
Validation loss: 1.5199218398781233

Epoch: 5| Step: 2
Training loss: 0.08335500955581665
Validation loss: 1.50419988811657

Epoch: 5| Step: 3
Training loss: 0.07924532890319824
Validation loss: 1.4826668564991285

Epoch: 5| Step: 4
Training loss: 0.0723600760102272
Validation loss: 1.4886478288199312

Epoch: 5| Step: 5
Training loss: 0.09113453328609467
Validation loss: 1.4661385756666943

Epoch: 5| Step: 6
Training loss: 0.0520872063934803
Validation loss: 1.471909781937958

Epoch: 5| Step: 7
Training loss: 0.03576651215553284
Validation loss: 1.4790495967352262

Epoch: 5| Step: 8
Training loss: 0.06839393079280853
Validation loss: 1.4795698940113027

Epoch: 5| Step: 9
Training loss: 0.06286145746707916
Validation loss: 1.4667508332960066

Epoch: 5| Step: 10
Training loss: 0.0647604912519455
Validation loss: 1.4724063616926952

Epoch: 559| Step: 0
Training loss: 0.07763682305812836
Validation loss: 1.443899388595294

Epoch: 5| Step: 1
Training loss: 0.06500430405139923
Validation loss: 1.456942081451416

Epoch: 5| Step: 2
Training loss: 0.053280942142009735
Validation loss: 1.450172052588514

Epoch: 5| Step: 3
Training loss: 0.05637166649103165
Validation loss: 1.4652382045663812

Epoch: 5| Step: 4
Training loss: 0.0801827535033226
Validation loss: 1.4577870061320644

Epoch: 5| Step: 5
Training loss: 0.08120618015527725
Validation loss: 1.4435666709817865

Epoch: 5| Step: 6
Training loss: 0.07681072503328323
Validation loss: 1.450793538042294

Epoch: 5| Step: 7
Training loss: 0.05704491212964058
Validation loss: 1.477629550041691

Epoch: 5| Step: 8
Training loss: 0.09855030477046967
Validation loss: 1.484366415649332

Epoch: 5| Step: 9
Training loss: 0.04611361771821976
Validation loss: 1.4791082976966776

Epoch: 5| Step: 10
Training loss: 0.06392722576856613
Validation loss: 1.480484559971799

Epoch: 560| Step: 0
Training loss: 0.09881241619586945
Validation loss: 1.5063286481365081

Epoch: 5| Step: 1
Training loss: 0.07286393642425537
Validation loss: 1.494819055321396

Epoch: 5| Step: 2
Training loss: 0.07422149181365967
Validation loss: 1.490665147381444

Epoch: 5| Step: 3
Training loss: 0.07589958608150482
Validation loss: 1.487227479616801

Epoch: 5| Step: 4
Training loss: 0.08254384249448776
Validation loss: 1.4777198453103342

Epoch: 5| Step: 5
Training loss: 0.06068241596221924
Validation loss: 1.4797700156447708

Epoch: 5| Step: 6
Training loss: 0.08026101440191269
Validation loss: 1.4580390273883779

Epoch: 5| Step: 7
Training loss: 0.09690062701702118
Validation loss: 1.4563464477498045

Epoch: 5| Step: 8
Training loss: 0.11417458206415176
Validation loss: 1.4799098237868278

Epoch: 5| Step: 9
Training loss: 0.051824189722537994
Validation loss: 1.4852332011345895

Epoch: 5| Step: 10
Training loss: 0.06684732437133789
Validation loss: 1.5106004425274429

Epoch: 561| Step: 0
Training loss: 0.10449051856994629
Validation loss: 1.5141139979003577

Epoch: 5| Step: 1
Training loss: 0.04783986508846283
Validation loss: 1.5063014133002168

Epoch: 5| Step: 2
Training loss: 0.04548521339893341
Validation loss: 1.491288810647944

Epoch: 5| Step: 3
Training loss: 0.08685872703790665
Validation loss: 1.5105802474483367

Epoch: 5| Step: 4
Training loss: 0.08003146946430206
Validation loss: 1.5019237161964498

Epoch: 5| Step: 5
Training loss: 0.08648090064525604
Validation loss: 1.51701444707891

Epoch: 5| Step: 6
Training loss: 0.037015412002801895
Validation loss: 1.5074336977415188

Epoch: 5| Step: 7
Training loss: 0.04321758821606636
Validation loss: 1.5013146528633692

Epoch: 5| Step: 8
Training loss: 0.07300715148448944
Validation loss: 1.4661225080490112

Epoch: 5| Step: 9
Training loss: 0.09192059934139252
Validation loss: 1.4575342157835602

Epoch: 5| Step: 10
Training loss: 0.0554935485124588
Validation loss: 1.4513328485591437

Epoch: 562| Step: 0
Training loss: 0.054001469165086746
Validation loss: 1.458047746330179

Epoch: 5| Step: 1
Training loss: 0.09368260949850082
Validation loss: 1.4457380079453992

Epoch: 5| Step: 2
Training loss: 0.06003280356526375
Validation loss: 1.4562655277149652

Epoch: 5| Step: 3
Training loss: 0.10057814419269562
Validation loss: 1.4601873659318494

Epoch: 5| Step: 4
Training loss: 0.062217216938734055
Validation loss: 1.4556316021950013

Epoch: 5| Step: 5
Training loss: 0.09676623344421387
Validation loss: 1.5035331838874406

Epoch: 5| Step: 6
Training loss: 0.04757232218980789
Validation loss: 1.5039576612493044

Epoch: 5| Step: 7
Training loss: 0.08288414776325226
Validation loss: 1.5082859877617127

Epoch: 5| Step: 8
Training loss: 0.07118551433086395
Validation loss: 1.5164238893857567

Epoch: 5| Step: 9
Training loss: 0.07024089992046356
Validation loss: 1.5278611644621818

Epoch: 5| Step: 10
Training loss: 0.09069396555423737
Validation loss: 1.5200699798522457

Epoch: 563| Step: 0
Training loss: 0.09137280285358429
Validation loss: 1.5366226127070766

Epoch: 5| Step: 1
Training loss: 0.06996584683656693
Validation loss: 1.5194016932159342

Epoch: 5| Step: 2
Training loss: 0.04937376827001572
Validation loss: 1.5022761155200262

Epoch: 5| Step: 3
Training loss: 0.0847274661064148
Validation loss: 1.500000249954962

Epoch: 5| Step: 4
Training loss: 0.07436387985944748
Validation loss: 1.4980852975640246

Epoch: 5| Step: 5
Training loss: 0.06068217009305954
Validation loss: 1.485194529256513

Epoch: 5| Step: 6
Training loss: 0.05034599453210831
Validation loss: 1.468857490888206

Epoch: 5| Step: 7
Training loss: 0.05232870578765869
Validation loss: 1.4650641641309183

Epoch: 5| Step: 8
Training loss: 0.07910255342721939
Validation loss: 1.4618050193273893

Epoch: 5| Step: 9
Training loss: 0.08306755125522614
Validation loss: 1.470319580006343

Epoch: 5| Step: 10
Training loss: 0.049021124839782715
Validation loss: 1.468968205554511

Epoch: 564| Step: 0
Training loss: 0.05822383239865303
Validation loss: 1.48525010642185

Epoch: 5| Step: 1
Training loss: 0.057387590408325195
Validation loss: 1.4932388887610486

Epoch: 5| Step: 2
Training loss: 0.054217539727687836
Validation loss: 1.4872690170041976

Epoch: 5| Step: 3
Training loss: 0.07767543941736221
Validation loss: 1.4626649823240054

Epoch: 5| Step: 4
Training loss: 0.04426838457584381
Validation loss: 1.480335194577453

Epoch: 5| Step: 5
Training loss: 0.07248879969120026
Validation loss: 1.4743778551778486

Epoch: 5| Step: 6
Training loss: 0.0692334920167923
Validation loss: 1.4919370476917555

Epoch: 5| Step: 7
Training loss: 0.10272733867168427
Validation loss: 1.5172310824035316

Epoch: 5| Step: 8
Training loss: 0.09965354204177856
Validation loss: 1.528674566617576

Epoch: 5| Step: 9
Training loss: 0.11790850013494492
Validation loss: 1.5074797830274027

Epoch: 5| Step: 10
Training loss: 0.11168321222066879
Validation loss: 1.5085791605775074

Epoch: 565| Step: 0
Training loss: 0.05850307270884514
Validation loss: 1.5102875565969816

Epoch: 5| Step: 1
Training loss: 0.07848308980464935
Validation loss: 1.4984627423747894

Epoch: 5| Step: 2
Training loss: 0.07143358886241913
Validation loss: 1.4879573250329623

Epoch: 5| Step: 3
Training loss: 0.0409940667450428
Validation loss: 1.4820660339888705

Epoch: 5| Step: 4
Training loss: 0.07660272717475891
Validation loss: 1.5129323544040802

Epoch: 5| Step: 5
Training loss: 0.06321513652801514
Validation loss: 1.499651446137377

Epoch: 5| Step: 6
Training loss: 0.08712045848369598
Validation loss: 1.503664178232993

Epoch: 5| Step: 7
Training loss: 0.045700691640377045
Validation loss: 1.4970890347675612

Epoch: 5| Step: 8
Training loss: 0.06867723912000656
Validation loss: 1.5202938933526315

Epoch: 5| Step: 9
Training loss: 0.07947482168674469
Validation loss: 1.5124800564140402

Epoch: 5| Step: 10
Training loss: 0.09748777002096176
Validation loss: 1.4924070066021335

Epoch: 566| Step: 0
Training loss: 0.09063368290662766
Validation loss: 1.4981250198938514

Epoch: 5| Step: 1
Training loss: 0.07662545144557953
Validation loss: 1.4857876275175361

Epoch: 5| Step: 2
Training loss: 0.06894488632678986
Validation loss: 1.4952778649586502

Epoch: 5| Step: 3
Training loss: 0.05032616853713989
Validation loss: 1.4677561470257339

Epoch: 5| Step: 4
Training loss: 0.049235254526138306
Validation loss: 1.467114116555901

Epoch: 5| Step: 5
Training loss: 0.07067517936229706
Validation loss: 1.458799869783463

Epoch: 5| Step: 6
Training loss: 0.07434225082397461
Validation loss: 1.4397949557150564

Epoch: 5| Step: 7
Training loss: 0.04880977049469948
Validation loss: 1.4573716040580504

Epoch: 5| Step: 8
Training loss: 0.06798224151134491
Validation loss: 1.4681480815333705

Epoch: 5| Step: 9
Training loss: 0.057866863906383514
Validation loss: 1.4596283371730516

Epoch: 5| Step: 10
Training loss: 0.07898762077093124
Validation loss: 1.4734337368319113

Epoch: 567| Step: 0
Training loss: 0.08960084617137909
Validation loss: 1.4568624784869533

Epoch: 5| Step: 1
Training loss: 0.03946218639612198
Validation loss: 1.4463723551842473

Epoch: 5| Step: 2
Training loss: 0.06817720085382462
Validation loss: 1.449704990592054

Epoch: 5| Step: 3
Training loss: 0.05285486578941345
Validation loss: 1.4458087695542203

Epoch: 5| Step: 4
Training loss: 0.04454188421368599
Validation loss: 1.4464409543621926

Epoch: 5| Step: 5
Training loss: 0.05131525918841362
Validation loss: 1.4628444999776862

Epoch: 5| Step: 6
Training loss: 0.07140210270881653
Validation loss: 1.4608919748695948

Epoch: 5| Step: 7
Training loss: 0.04646974056959152
Validation loss: 1.4737854138497384

Epoch: 5| Step: 8
Training loss: 0.058735232800245285
Validation loss: 1.4638010263442993

Epoch: 5| Step: 9
Training loss: 0.05339454486966133
Validation loss: 1.4788941414125505

Epoch: 5| Step: 10
Training loss: 0.05369466915726662
Validation loss: 1.4663798988506358

Epoch: 568| Step: 0
Training loss: 0.043709658086299896
Validation loss: 1.4637084532809514

Epoch: 5| Step: 1
Training loss: 0.11309504508972168
Validation loss: 1.471181140151075

Epoch: 5| Step: 2
Training loss: 0.05132926627993584
Validation loss: 1.4681936169183383

Epoch: 5| Step: 3
Training loss: 0.08118702471256256
Validation loss: 1.431108094030811

Epoch: 5| Step: 4
Training loss: 0.07000182569026947
Validation loss: 1.4442510348494335

Epoch: 5| Step: 5
Training loss: 0.06823054701089859
Validation loss: 1.438363132938262

Epoch: 5| Step: 6
Training loss: 0.10968272387981415
Validation loss: 1.462784522323198

Epoch: 5| Step: 7
Training loss: 0.05931601673364639
Validation loss: 1.4646842633524249

Epoch: 5| Step: 8
Training loss: 0.06864431500434875
Validation loss: 1.47678417031483

Epoch: 5| Step: 9
Training loss: 0.05488407611846924
Validation loss: 1.4735177178536691

Epoch: 5| Step: 10
Training loss: 0.03323296085000038
Validation loss: 1.4828386627217776

Epoch: 569| Step: 0
Training loss: 0.08539114892482758
Validation loss: 1.5010072633784304

Epoch: 5| Step: 1
Training loss: 0.09487153589725494
Validation loss: 1.4444004361347487

Epoch: 5| Step: 2
Training loss: 0.08237899839878082
Validation loss: 1.480685369942778

Epoch: 5| Step: 3
Training loss: 0.08078424632549286
Validation loss: 1.4543795777905373

Epoch: 5| Step: 4
Training loss: 0.05982990935444832
Validation loss: 1.4754097333518408

Epoch: 5| Step: 5
Training loss: 0.0468667633831501
Validation loss: 1.4605853019222137

Epoch: 5| Step: 6
Training loss: 0.046308644115924835
Validation loss: 1.4832549889882405

Epoch: 5| Step: 7
Training loss: 0.04718383029103279
Validation loss: 1.4834207886008806

Epoch: 5| Step: 8
Training loss: 0.05715331435203552
Validation loss: 1.470285552804188

Epoch: 5| Step: 9
Training loss: 0.04947463795542717
Validation loss: 1.49490370545336

Epoch: 5| Step: 10
Training loss: 0.13636688888072968
Validation loss: 1.4791543983644055

Epoch: 570| Step: 0
Training loss: 0.07241225987672806
Validation loss: 1.4402924788895475

Epoch: 5| Step: 1
Training loss: 0.06053594499826431
Validation loss: 1.4711080315292522

Epoch: 5| Step: 2
Training loss: 0.07617402076721191
Validation loss: 1.4578476195694299

Epoch: 5| Step: 3
Training loss: 0.060402922332286835
Validation loss: 1.443746547545156

Epoch: 5| Step: 4
Training loss: 0.04597487300634384
Validation loss: 1.4640550485221289

Epoch: 5| Step: 5
Training loss: 0.10680735111236572
Validation loss: 1.4757909223597536

Epoch: 5| Step: 6
Training loss: 0.09247399121522903
Validation loss: 1.4686148743475638

Epoch: 5| Step: 7
Training loss: 0.04643544554710388
Validation loss: 1.4827441566733903

Epoch: 5| Step: 8
Training loss: 0.07932621240615845
Validation loss: 1.5075813595966627

Epoch: 5| Step: 9
Training loss: 0.07668153941631317
Validation loss: 1.4922967969730336

Epoch: 5| Step: 10
Training loss: 0.04328151047229767
Validation loss: 1.4952613999766688

Epoch: 571| Step: 0
Training loss: 0.11106550693511963
Validation loss: 1.4848781439565844

Epoch: 5| Step: 1
Training loss: 0.07449548691511154
Validation loss: 1.484702834519007

Epoch: 5| Step: 2
Training loss: 0.06830157339572906
Validation loss: 1.4701792527270574

Epoch: 5| Step: 3
Training loss: 0.0779663547873497
Validation loss: 1.474492041013574

Epoch: 5| Step: 4
Training loss: 0.06362982839345932
Validation loss: 1.4772478739420574

Epoch: 5| Step: 5
Training loss: 0.04650161415338516
Validation loss: 1.4782896734053088

Epoch: 5| Step: 6
Training loss: 0.11256792396306992
Validation loss: 1.4907897082708215

Epoch: 5| Step: 7
Training loss: 0.07390538603067398
Validation loss: 1.4818015931754984

Epoch: 5| Step: 8
Training loss: 0.0658840611577034
Validation loss: 1.4842486355894355

Epoch: 5| Step: 9
Training loss: 0.061507947742938995
Validation loss: 1.4836506997385333

Epoch: 5| Step: 10
Training loss: 0.06482748687267303
Validation loss: 1.471606421214278

Epoch: 572| Step: 0
Training loss: 0.05344013497233391
Validation loss: 1.482243017483783

Epoch: 5| Step: 1
Training loss: 0.0669565498828888
Validation loss: 1.4623785115057422

Epoch: 5| Step: 2
Training loss: 0.11487104743719101
Validation loss: 1.4563020429303568

Epoch: 5| Step: 3
Training loss: 0.0731387734413147
Validation loss: 1.4677244847820652

Epoch: 5| Step: 4
Training loss: 0.07078001648187637
Validation loss: 1.4333822804112588

Epoch: 5| Step: 5
Training loss: 0.08479596674442291
Validation loss: 1.4487023122849003

Epoch: 5| Step: 6
Training loss: 0.0682726800441742
Validation loss: 1.4436276292288175

Epoch: 5| Step: 7
Training loss: 0.0862230435013771
Validation loss: 1.4429230587456816

Epoch: 5| Step: 8
Training loss: 0.08950933068990707
Validation loss: 1.4348116279930196

Epoch: 5| Step: 9
Training loss: 0.05817091464996338
Validation loss: 1.4615852909703408

Epoch: 5| Step: 10
Training loss: 0.06570189446210861
Validation loss: 1.4714721043904622

Epoch: 573| Step: 0
Training loss: 0.07276655733585358
Validation loss: 1.4598903361187185

Epoch: 5| Step: 1
Training loss: 0.07914841920137405
Validation loss: 1.4841316694854407

Epoch: 5| Step: 2
Training loss: 0.04689180105924606
Validation loss: 1.4947762309864003

Epoch: 5| Step: 3
Training loss: 0.08966821432113647
Validation loss: 1.5221928178623159

Epoch: 5| Step: 4
Training loss: 0.051266469061374664
Validation loss: 1.486134720425452

Epoch: 5| Step: 5
Training loss: 0.08859656751155853
Validation loss: 1.491792248141381

Epoch: 5| Step: 6
Training loss: 0.11027844250202179
Validation loss: 1.5065849583636048

Epoch: 5| Step: 7
Training loss: 0.07171893864870071
Validation loss: 1.5096528581393662

Epoch: 5| Step: 8
Training loss: 0.0720362737774849
Validation loss: 1.5172748655401251

Epoch: 5| Step: 9
Training loss: 0.08450867980718613
Validation loss: 1.4802010565675714

Epoch: 5| Step: 10
Training loss: 0.033519648015499115
Validation loss: 1.4721505398391395

Epoch: 574| Step: 0
Training loss: 0.05966075509786606
Validation loss: 1.4692059434870237

Epoch: 5| Step: 1
Training loss: 0.12411312758922577
Validation loss: 1.484219015285533

Epoch: 5| Step: 2
Training loss: 0.10873832553625107
Validation loss: 1.4706995153939852

Epoch: 5| Step: 3
Training loss: 0.1714591085910797
Validation loss: 1.475038166969053

Epoch: 5| Step: 4
Training loss: 0.0964730754494667
Validation loss: 1.5060177003183672

Epoch: 5| Step: 5
Training loss: 0.08860312402248383
Validation loss: 1.519794330802015

Epoch: 5| Step: 6
Training loss: 0.14450997114181519
Validation loss: 1.5238243149172874

Epoch: 5| Step: 7
Training loss: 0.13246148824691772
Validation loss: 1.5314650458674277

Epoch: 5| Step: 8
Training loss: 0.07443588227033615
Validation loss: 1.5001842655161375

Epoch: 5| Step: 9
Training loss: 0.11244244873523712
Validation loss: 1.517962945404873

Epoch: 5| Step: 10
Training loss: 0.07490476220846176
Validation loss: 1.4857965835960962

Epoch: 575| Step: 0
Training loss: 0.09673235565423965
Validation loss: 1.4996809703047558

Epoch: 5| Step: 1
Training loss: 0.101384237408638
Validation loss: 1.5007027990074568

Epoch: 5| Step: 2
Training loss: 0.13188263773918152
Validation loss: 1.4594012844947077

Epoch: 5| Step: 3
Training loss: 0.07853318750858307
Validation loss: 1.4549371721923992

Epoch: 5| Step: 4
Training loss: 0.08408472687005997
Validation loss: 1.4466326967362435

Epoch: 5| Step: 5
Training loss: 0.04454910010099411
Validation loss: 1.4593475851961362

Epoch: 5| Step: 6
Training loss: 0.10489268600940704
Validation loss: 1.4722628234535136

Epoch: 5| Step: 7
Training loss: 0.07555150985717773
Validation loss: 1.4550871605514197

Epoch: 5| Step: 8
Training loss: 0.06643049418926239
Validation loss: 1.4619236005249845

Epoch: 5| Step: 9
Training loss: 0.03899062052369118
Validation loss: 1.480441383136216

Epoch: 5| Step: 10
Training loss: 0.06291040033102036
Validation loss: 1.4985206389939913

Epoch: 576| Step: 0
Training loss: 0.10208652168512344
Validation loss: 1.4851713545860783

Epoch: 5| Step: 1
Training loss: 0.09603773057460785
Validation loss: 1.4917852551706376

Epoch: 5| Step: 2
Training loss: 0.10206104815006256
Validation loss: 1.5034131971738671

Epoch: 5| Step: 3
Training loss: 0.062421463429927826
Validation loss: 1.4969375415514874

Epoch: 5| Step: 4
Training loss: 0.07629305869340897
Validation loss: 1.4837556269861036

Epoch: 5| Step: 5
Training loss: 0.041881099343299866
Validation loss: 1.4759821596965994

Epoch: 5| Step: 6
Training loss: 0.06632308661937714
Validation loss: 1.4840199652538504

Epoch: 5| Step: 7
Training loss: 0.0599842369556427
Validation loss: 1.47754426669049

Epoch: 5| Step: 8
Training loss: 0.06359411776065826
Validation loss: 1.4756891906902354

Epoch: 5| Step: 9
Training loss: 0.09705841541290283
Validation loss: 1.4669041531060332

Epoch: 5| Step: 10
Training loss: 0.04577445983886719
Validation loss: 1.463966259392359

Epoch: 577| Step: 0
Training loss: 0.09518972784280777
Validation loss: 1.4945717909002816

Epoch: 5| Step: 1
Training loss: 0.0792854055762291
Validation loss: 1.4699459140018751

Epoch: 5| Step: 2
Training loss: 0.04760705679655075
Validation loss: 1.519828232385779

Epoch: 5| Step: 3
Training loss: 0.07259662449359894
Validation loss: 1.5178219541426627

Epoch: 5| Step: 4
Training loss: 0.07621415704488754
Validation loss: 1.5000055759183821

Epoch: 5| Step: 5
Training loss: 0.13633188605308533
Validation loss: 1.4898168527951805

Epoch: 5| Step: 6
Training loss: 0.059526633471250534
Validation loss: 1.4727857933249524

Epoch: 5| Step: 7
Training loss: 0.09967796504497528
Validation loss: 1.4701777965791765

Epoch: 5| Step: 8
Training loss: 0.09578902274370193
Validation loss: 1.459259089603219

Epoch: 5| Step: 9
Training loss: 0.09323820471763611
Validation loss: 1.4491354470611901

Epoch: 5| Step: 10
Training loss: 0.05019629746675491
Validation loss: 1.4241549468809558

Epoch: 578| Step: 0
Training loss: 0.08443149924278259
Validation loss: 1.4240952826315356

Epoch: 5| Step: 1
Training loss: 0.11491324752569199
Validation loss: 1.4113550577112424

Epoch: 5| Step: 2
Training loss: 0.07526333630084991
Validation loss: 1.4530498840475594

Epoch: 5| Step: 3
Training loss: 0.07776081562042236
Validation loss: 1.4528649712121615

Epoch: 5| Step: 4
Training loss: 0.05013237148523331
Validation loss: 1.4673511981964111

Epoch: 5| Step: 5
Training loss: 0.0576305165886879
Validation loss: 1.4593612250461374

Epoch: 5| Step: 6
Training loss: 0.06976580619812012
Validation loss: 1.4651747941970825

Epoch: 5| Step: 7
Training loss: 0.06297179311513901
Validation loss: 1.497486024774531

Epoch: 5| Step: 8
Training loss: 0.07848093658685684
Validation loss: 1.4985292162946475

Epoch: 5| Step: 9
Training loss: 0.05315161496400833
Validation loss: 1.5057069434914538

Epoch: 5| Step: 10
Training loss: 0.12226931005716324
Validation loss: 1.5139087361674155

Epoch: 579| Step: 0
Training loss: 0.08222733438014984
Validation loss: 1.5164425693532473

Epoch: 5| Step: 1
Training loss: 0.08595005422830582
Validation loss: 1.5264743066603137

Epoch: 5| Step: 2
Training loss: 0.0663967877626419
Validation loss: 1.5346643309439383

Epoch: 5| Step: 3
Training loss: 0.0477442741394043
Validation loss: 1.5393865544308898

Epoch: 5| Step: 4
Training loss: 0.08440984785556793
Validation loss: 1.5009829716015888

Epoch: 5| Step: 5
Training loss: 0.056196123361587524
Validation loss: 1.4982462493322228

Epoch: 5| Step: 6
Training loss: 0.042932841926813126
Validation loss: 1.488449796553581

Epoch: 5| Step: 7
Training loss: 0.06299160420894623
Validation loss: 1.4914271164965887

Epoch: 5| Step: 8
Training loss: 0.09023761749267578
Validation loss: 1.4771619906989477

Epoch: 5| Step: 9
Training loss: 0.09527383744716644
Validation loss: 1.4616414629003054

Epoch: 5| Step: 10
Training loss: 0.06440084427595139
Validation loss: 1.4596982220167756

Epoch: 580| Step: 0
Training loss: 0.06748954206705093
Validation loss: 1.490954738791271

Epoch: 5| Step: 1
Training loss: 0.047968875616788864
Validation loss: 1.473541252074703

Epoch: 5| Step: 2
Training loss: 0.06594647467136383
Validation loss: 1.4667705899925643

Epoch: 5| Step: 3
Training loss: 0.07893611490726471
Validation loss: 1.4869337658728323

Epoch: 5| Step: 4
Training loss: 0.07680466026067734
Validation loss: 1.4685409248516124

Epoch: 5| Step: 5
Training loss: 0.05641205236315727
Validation loss: 1.4918858953701553

Epoch: 5| Step: 6
Training loss: 0.05467687174677849
Validation loss: 1.479214801583239

Epoch: 5| Step: 7
Training loss: 0.10272915661334991
Validation loss: 1.4825421405094925

Epoch: 5| Step: 8
Training loss: 0.037737488746643066
Validation loss: 1.4628188340894637

Epoch: 5| Step: 9
Training loss: 0.07422216236591339
Validation loss: 1.4673946724143079

Epoch: 5| Step: 10
Training loss: 0.053635694086551666
Validation loss: 1.4854449136282808

Epoch: 581| Step: 0
Training loss: 0.048432301729917526
Validation loss: 1.4801914768834268

Epoch: 5| Step: 1
Training loss: 0.10042496025562286
Validation loss: 1.4862520938278527

Epoch: 5| Step: 2
Training loss: 0.049624815583229065
Validation loss: 1.5122245114336732

Epoch: 5| Step: 3
Training loss: 0.08754086494445801
Validation loss: 1.500036229369461

Epoch: 5| Step: 4
Training loss: 0.08436097204685211
Validation loss: 1.499003411621176

Epoch: 5| Step: 5
Training loss: 0.10486434400081635
Validation loss: 1.5078731659919984

Epoch: 5| Step: 6
Training loss: 0.07515218108892441
Validation loss: 1.4646062556133475

Epoch: 5| Step: 7
Training loss: 0.08432993292808533
Validation loss: 1.4907200874820832

Epoch: 5| Step: 8
Training loss: 0.0632857233285904
Validation loss: 1.466650188610118

Epoch: 5| Step: 9
Training loss: 0.0604020357131958
Validation loss: 1.4780097776843655

Epoch: 5| Step: 10
Training loss: 0.05218968912959099
Validation loss: 1.455315762950528

Epoch: 582| Step: 0
Training loss: 0.06804883480072021
Validation loss: 1.4382853713086856

Epoch: 5| Step: 1
Training loss: 0.05263466760516167
Validation loss: 1.4340819517771404

Epoch: 5| Step: 2
Training loss: 0.07883153855800629
Validation loss: 1.422467331732473

Epoch: 5| Step: 3
Training loss: 0.05367245525121689
Validation loss: 1.4299948292393838

Epoch: 5| Step: 4
Training loss: 0.0657457485795021
Validation loss: 1.421916486114584

Epoch: 5| Step: 5
Training loss: 0.05229343846440315
Validation loss: 1.431263034061719

Epoch: 5| Step: 6
Training loss: 0.06554456055164337
Validation loss: 1.4352299180082095

Epoch: 5| Step: 7
Training loss: 0.045256610959768295
Validation loss: 1.4366609159336294

Epoch: 5| Step: 8
Training loss: 0.08022014796733856
Validation loss: 1.4555877895765408

Epoch: 5| Step: 9
Training loss: 0.09687569737434387
Validation loss: 1.464116757915866

Epoch: 5| Step: 10
Training loss: 0.08400260657072067
Validation loss: 1.4874639229107929

Epoch: 583| Step: 0
Training loss: 0.0735057145357132
Validation loss: 1.4611223372079993

Epoch: 5| Step: 1
Training loss: 0.0798427015542984
Validation loss: 1.4754819203448553

Epoch: 5| Step: 2
Training loss: 0.06241822987794876
Validation loss: 1.480640813868533

Epoch: 5| Step: 3
Training loss: 0.09527752548456192
Validation loss: 1.4732696676767

Epoch: 5| Step: 4
Training loss: 0.057395678013563156
Validation loss: 1.493933020099517

Epoch: 5| Step: 5
Training loss: 0.03006739914417267
Validation loss: 1.4657216430992208

Epoch: 5| Step: 6
Training loss: 0.057943232357501984
Validation loss: 1.4721673304034817

Epoch: 5| Step: 7
Training loss: 0.051454175263643265
Validation loss: 1.455505758203486

Epoch: 5| Step: 8
Training loss: 0.053152650594711304
Validation loss: 1.4814523971208962

Epoch: 5| Step: 9
Training loss: 0.05668642371892929
Validation loss: 1.4788134559508292

Epoch: 5| Step: 10
Training loss: 0.07113391160964966
Validation loss: 1.4697850045337473

Epoch: 584| Step: 0
Training loss: 0.07881893962621689
Validation loss: 1.460394819577535

Epoch: 5| Step: 1
Training loss: 0.03829424828290939
Validation loss: 1.4648194800141037

Epoch: 5| Step: 2
Training loss: 0.06918607652187347
Validation loss: 1.4903747830339658

Epoch: 5| Step: 3
Training loss: 0.08281831443309784
Validation loss: 1.48584787179065

Epoch: 5| Step: 4
Training loss: 0.06083829328417778
Validation loss: 1.4965397465613581

Epoch: 5| Step: 5
Training loss: 0.08147519826889038
Validation loss: 1.495702637139187

Epoch: 5| Step: 6
Training loss: 0.09931864589452744
Validation loss: 1.470206045335339

Epoch: 5| Step: 7
Training loss: 0.0633472353219986
Validation loss: 1.4536481903445335

Epoch: 5| Step: 8
Training loss: 0.07744627445936203
Validation loss: 1.4883238794983074

Epoch: 5| Step: 9
Training loss: 0.06452103704214096
Validation loss: 1.4756450101893435

Epoch: 5| Step: 10
Training loss: 0.09401074796915054
Validation loss: 1.4560295484399284

Epoch: 585| Step: 0
Training loss: 0.05489041283726692
Validation loss: 1.4487273616175498

Epoch: 5| Step: 1
Training loss: 0.08502727001905441
Validation loss: 1.4689241660538541

Epoch: 5| Step: 2
Training loss: 0.0761919617652893
Validation loss: 1.439909896542949

Epoch: 5| Step: 3
Training loss: 0.04679707810282707
Validation loss: 1.4882468843972811

Epoch: 5| Step: 4
Training loss: 0.06595215946435928
Validation loss: 1.4720562670820503

Epoch: 5| Step: 5
Training loss: 0.07989926636219025
Validation loss: 1.480205646125219

Epoch: 5| Step: 6
Training loss: 0.06345444917678833
Validation loss: 1.5031605100118985

Epoch: 5| Step: 7
Training loss: 0.10074810683727264
Validation loss: 1.491476494778869

Epoch: 5| Step: 8
Training loss: 0.05287020280957222
Validation loss: 1.4840531785001037

Epoch: 5| Step: 9
Training loss: 0.07922786474227905
Validation loss: 1.4697916610266573

Epoch: 5| Step: 10
Training loss: 0.04937337338924408
Validation loss: 1.4691174466122863

Epoch: 586| Step: 0
Training loss: 0.048334963619709015
Validation loss: 1.4840195576349895

Epoch: 5| Step: 1
Training loss: 0.09093060344457626
Validation loss: 1.478639796536456

Epoch: 5| Step: 2
Training loss: 0.08503428846597672
Validation loss: 1.4470152214009275

Epoch: 5| Step: 3
Training loss: 0.06173757463693619
Validation loss: 1.4473390630496445

Epoch: 5| Step: 4
Training loss: 0.11307515949010849
Validation loss: 1.4378163558180614

Epoch: 5| Step: 5
Training loss: 0.09941605478525162
Validation loss: 1.5041741094281595

Epoch: 5| Step: 6
Training loss: 0.0908091813325882
Validation loss: 1.5086560890238772

Epoch: 5| Step: 7
Training loss: 0.05824673920869827
Validation loss: 1.5106962047597414

Epoch: 5| Step: 8
Training loss: 0.0853123813867569
Validation loss: 1.491755259934292

Epoch: 5| Step: 9
Training loss: 0.048603687435388565
Validation loss: 1.4744547797787575

Epoch: 5| Step: 10
Training loss: 0.10375131666660309
Validation loss: 1.497751001388796

Epoch: 587| Step: 0
Training loss: 0.06037153676152229
Validation loss: 1.4958865078546668

Epoch: 5| Step: 1
Training loss: 0.06974136084318161
Validation loss: 1.5174097732831073

Epoch: 5| Step: 2
Training loss: 0.07617528736591339
Validation loss: 1.507941262696379

Epoch: 5| Step: 3
Training loss: 0.06920818984508514
Validation loss: 1.500564589936246

Epoch: 5| Step: 4
Training loss: 0.06841744482517242
Validation loss: 1.5278610055164625

Epoch: 5| Step: 5
Training loss: 0.10149909555912018
Validation loss: 1.4957158821885304

Epoch: 5| Step: 6
Training loss: 0.07429276406764984
Validation loss: 1.4772512784568212

Epoch: 5| Step: 7
Training loss: 0.0785321295261383
Validation loss: 1.4678013997693216

Epoch: 5| Step: 8
Training loss: 0.07777528464794159
Validation loss: 1.4701427259752828

Epoch: 5| Step: 9
Training loss: 0.06717686355113983
Validation loss: 1.4869475364685059

Epoch: 5| Step: 10
Training loss: 0.05502155423164368
Validation loss: 1.4566344381660543

Epoch: 588| Step: 0
Training loss: 0.03438418358564377
Validation loss: 1.4677199676472654

Epoch: 5| Step: 1
Training loss: 0.068254254758358
Validation loss: 1.4567075813970258

Epoch: 5| Step: 2
Training loss: 0.06771083176136017
Validation loss: 1.4709969143713675

Epoch: 5| Step: 3
Training loss: 0.04071396589279175
Validation loss: 1.4631122363510953

Epoch: 5| Step: 4
Training loss: 0.06269894540309906
Validation loss: 1.4777370832299674

Epoch: 5| Step: 5
Training loss: 0.04146791622042656
Validation loss: 1.4702584487135693

Epoch: 5| Step: 6
Training loss: 0.05929882451891899
Validation loss: 1.483710547929169

Epoch: 5| Step: 7
Training loss: 0.09427843242883682
Validation loss: 1.5206809915522093

Epoch: 5| Step: 8
Training loss: 0.09994718432426453
Validation loss: 1.510693896201349

Epoch: 5| Step: 9
Training loss: 0.10048089176416397
Validation loss: 1.5114200602295578

Epoch: 5| Step: 10
Training loss: 0.03351202607154846
Validation loss: 1.5053308548465851

Epoch: 589| Step: 0
Training loss: 0.05635904520750046
Validation loss: 1.5288835481930805

Epoch: 5| Step: 1
Training loss: 0.057934410870075226
Validation loss: 1.5011508118721746

Epoch: 5| Step: 2
Training loss: 0.04335213825106621
Validation loss: 1.5190687897384807

Epoch: 5| Step: 3
Training loss: 0.05696725845336914
Validation loss: 1.496586177938728

Epoch: 5| Step: 4
Training loss: 0.06985270977020264
Validation loss: 1.5240572960146013

Epoch: 5| Step: 5
Training loss: 0.1246822252869606
Validation loss: 1.5130804225962649

Epoch: 5| Step: 6
Training loss: 0.07003667950630188
Validation loss: 1.4950080404999435

Epoch: 5| Step: 7
Training loss: 0.0699240118265152
Validation loss: 1.4990808656138759

Epoch: 5| Step: 8
Training loss: 0.0844137966632843
Validation loss: 1.484214436623358

Epoch: 5| Step: 9
Training loss: 0.06828171014785767
Validation loss: 1.4665945217173586

Epoch: 5| Step: 10
Training loss: 0.03542843833565712
Validation loss: 1.4837839782878917

Epoch: 590| Step: 0
Training loss: 0.03988255560398102
Validation loss: 1.4621402858405985

Epoch: 5| Step: 1
Training loss: 0.0728694349527359
Validation loss: 1.4515385602110176

Epoch: 5| Step: 2
Training loss: 0.05070950835943222
Validation loss: 1.4515764072377195

Epoch: 5| Step: 3
Training loss: 0.05083267763257027
Validation loss: 1.4494720530766312

Epoch: 5| Step: 4
Training loss: 0.06583210080862045
Validation loss: 1.459414582098684

Epoch: 5| Step: 5
Training loss: 0.09505127370357513
Validation loss: 1.4718328993166647

Epoch: 5| Step: 6
Training loss: 0.08594600856304169
Validation loss: 1.4744804559215423

Epoch: 5| Step: 7
Training loss: 0.07676037400960922
Validation loss: 1.4999315969405635

Epoch: 5| Step: 8
Training loss: 0.08219518512487411
Validation loss: 1.4831411184803132

Epoch: 5| Step: 9
Training loss: 0.05289419740438461
Validation loss: 1.4784260552416566

Epoch: 5| Step: 10
Training loss: 0.04101041704416275
Validation loss: 1.489595474735383

Epoch: 591| Step: 0
Training loss: 0.07590056210756302
Validation loss: 1.4685865756004088

Epoch: 5| Step: 1
Training loss: 0.08975566923618317
Validation loss: 1.4970222198834984

Epoch: 5| Step: 2
Training loss: 0.06423543393611908
Validation loss: 1.4785545564466906

Epoch: 5| Step: 3
Training loss: 0.047844842076301575
Validation loss: 1.495421891571373

Epoch: 5| Step: 4
Training loss: 0.0824742317199707
Validation loss: 1.4666456150752243

Epoch: 5| Step: 5
Training loss: 0.054146815091371536
Validation loss: 1.4632668854087911

Epoch: 5| Step: 6
Training loss: 0.048522353172302246
Validation loss: 1.4979378215728267

Epoch: 5| Step: 7
Training loss: 0.10604319721460342
Validation loss: 1.4635568934102212

Epoch: 5| Step: 8
Training loss: 0.044268060475587845
Validation loss: 1.4688490206195461

Epoch: 5| Step: 9
Training loss: 0.08735421299934387
Validation loss: 1.4676409113791682

Epoch: 5| Step: 10
Training loss: 0.051377132534980774
Validation loss: 1.4483276772242721

Epoch: 592| Step: 0
Training loss: 0.036958515644073486
Validation loss: 1.44604661644146

Epoch: 5| Step: 1
Training loss: 0.0661214292049408
Validation loss: 1.4396252516777284

Epoch: 5| Step: 2
Training loss: 0.08463294804096222
Validation loss: 1.4513611357699159

Epoch: 5| Step: 3
Training loss: 0.1074565052986145
Validation loss: 1.4360092134885891

Epoch: 5| Step: 4
Training loss: 0.04164726287126541
Validation loss: 1.4638983818792528

Epoch: 5| Step: 5
Training loss: 0.08820261061191559
Validation loss: 1.4638201780216669

Epoch: 5| Step: 6
Training loss: 0.06987617164850235
Validation loss: 1.4675175105371783

Epoch: 5| Step: 7
Training loss: 0.07274247705936432
Validation loss: 1.469017131354219

Epoch: 5| Step: 8
Training loss: 0.060768019407987595
Validation loss: 1.4794452126308153

Epoch: 5| Step: 9
Training loss: 0.04874959588050842
Validation loss: 1.4719441936862083

Epoch: 5| Step: 10
Training loss: 0.06575240939855576
Validation loss: 1.4832870460325671

Epoch: 593| Step: 0
Training loss: 0.09963306039571762
Validation loss: 1.4833117608101136

Epoch: 5| Step: 1
Training loss: 0.057165682315826416
Validation loss: 1.4888061695201422

Epoch: 5| Step: 2
Training loss: 0.06329593807458878
Validation loss: 1.5092180441784602

Epoch: 5| Step: 3
Training loss: 0.05327778309583664
Validation loss: 1.528525681905849

Epoch: 5| Step: 4
Training loss: 0.035355985164642334
Validation loss: 1.5037499397031722

Epoch: 5| Step: 5
Training loss: 0.050306130200624466
Validation loss: 1.5099251244657783

Epoch: 5| Step: 6
Training loss: 0.06352724879980087
Validation loss: 1.5062420393830986

Epoch: 5| Step: 7
Training loss: 0.09256089478731155
Validation loss: 1.506767224880957

Epoch: 5| Step: 8
Training loss: 0.06606189906597137
Validation loss: 1.4690020494563605

Epoch: 5| Step: 9
Training loss: 0.0879741758108139
Validation loss: 1.4905262403590704

Epoch: 5| Step: 10
Training loss: 0.07121653854846954
Validation loss: 1.4821861508072063

Epoch: 594| Step: 0
Training loss: 0.09132955968379974
Validation loss: 1.5010657182303808

Epoch: 5| Step: 1
Training loss: 0.0443260483443737
Validation loss: 1.5084712338703934

Epoch: 5| Step: 2
Training loss: 0.09921065717935562
Validation loss: 1.506961735345984

Epoch: 5| Step: 3
Training loss: 0.06484930217266083
Validation loss: 1.5102156003316243

Epoch: 5| Step: 4
Training loss: 0.0479002445936203
Validation loss: 1.4934772996492283

Epoch: 5| Step: 5
Training loss: 0.04906322807073593
Validation loss: 1.50325487249641

Epoch: 5| Step: 6
Training loss: 0.054830171167850494
Validation loss: 1.4844944464263095

Epoch: 5| Step: 7
Training loss: 0.1184035912156105
Validation loss: 1.4869483773426344

Epoch: 5| Step: 8
Training loss: 0.06591296941041946
Validation loss: 1.4801654495218748

Epoch: 5| Step: 9
Training loss: 0.04242454469203949
Validation loss: 1.4700032767429148

Epoch: 5| Step: 10
Training loss: 0.08463660627603531
Validation loss: 1.4741244367373887

Epoch: 595| Step: 0
Training loss: 0.09076716750860214
Validation loss: 1.4780528571016045

Epoch: 5| Step: 1
Training loss: 0.04118414223194122
Validation loss: 1.4818856677701395

Epoch: 5| Step: 2
Training loss: 0.04205355793237686
Validation loss: 1.487271778045162

Epoch: 5| Step: 3
Training loss: 0.055098969489336014
Validation loss: 1.477624274069263

Epoch: 5| Step: 4
Training loss: 0.08654002845287323
Validation loss: 1.4896293622191235

Epoch: 5| Step: 5
Training loss: 0.05802983045578003
Validation loss: 1.4867069131584578

Epoch: 5| Step: 6
Training loss: 0.050808846950531006
Validation loss: 1.5097657813820788

Epoch: 5| Step: 7
Training loss: 0.09634752571582794
Validation loss: 1.4888500129022906

Epoch: 5| Step: 8
Training loss: 0.09311242401599884
Validation loss: 1.4900995198116507

Epoch: 5| Step: 9
Training loss: 0.06501021236181259
Validation loss: 1.4887440948076145

Epoch: 5| Step: 10
Training loss: 0.04624626040458679
Validation loss: 1.4781655188529723

Epoch: 596| Step: 0
Training loss: 0.06826210021972656
Validation loss: 1.4903083680778422

Epoch: 5| Step: 1
Training loss: 0.050778936594724655
Validation loss: 1.4971961129096247

Epoch: 5| Step: 2
Training loss: 0.04789183288812637
Validation loss: 1.4879060278656662

Epoch: 5| Step: 3
Training loss: 0.0626484602689743
Validation loss: 1.5151989934264973

Epoch: 5| Step: 4
Training loss: 0.06998622417449951
Validation loss: 1.5279307698690763

Epoch: 5| Step: 5
Training loss: 0.07310646772384644
Validation loss: 1.5167037415248092

Epoch: 5| Step: 6
Training loss: 0.054917048662900925
Validation loss: 1.5186907860540575

Epoch: 5| Step: 7
Training loss: 0.08790627866983414
Validation loss: 1.5020988538701048

Epoch: 5| Step: 8
Training loss: 0.06906525790691376
Validation loss: 1.513921997880423

Epoch: 5| Step: 9
Training loss: 0.05482487753033638
Validation loss: 1.5074879072045768

Epoch: 5| Step: 10
Training loss: 0.03844127058982849
Validation loss: 1.5010574761257376

Epoch: 597| Step: 0
Training loss: 0.06638821214437485
Validation loss: 1.4829516526191466

Epoch: 5| Step: 1
Training loss: 0.06581087410449982
Validation loss: 1.4730877261007986

Epoch: 5| Step: 2
Training loss: 0.044087935239076614
Validation loss: 1.4677716608970397

Epoch: 5| Step: 3
Training loss: 0.04836789891123772
Validation loss: 1.4874114092960153

Epoch: 5| Step: 4
Training loss: 0.026438945904374123
Validation loss: 1.4707901849541614

Epoch: 5| Step: 5
Training loss: 0.05790245532989502
Validation loss: 1.4886424028745262

Epoch: 5| Step: 6
Training loss: 0.070093534886837
Validation loss: 1.5087888029313856

Epoch: 5| Step: 7
Training loss: 0.04568924382328987
Validation loss: 1.4995531029598688

Epoch: 5| Step: 8
Training loss: 0.07274791598320007
Validation loss: 1.5005453696814917

Epoch: 5| Step: 9
Training loss: 0.0742824524641037
Validation loss: 1.516762315586049

Epoch: 5| Step: 10
Training loss: 0.06667988747358322
Validation loss: 1.515270717682377

Epoch: 598| Step: 0
Training loss: 0.05844306945800781
Validation loss: 1.5287307590566657

Epoch: 5| Step: 1
Training loss: 0.04310552775859833
Validation loss: 1.4949269884376115

Epoch: 5| Step: 2
Training loss: 0.06842385232448578
Validation loss: 1.5145121928184264

Epoch: 5| Step: 3
Training loss: 0.045252542942762375
Validation loss: 1.5020619425722348

Epoch: 5| Step: 4
Training loss: 0.07155828177928925
Validation loss: 1.5011740756291214

Epoch: 5| Step: 5
Training loss: 0.07991215586662292
Validation loss: 1.4852772605034612

Epoch: 5| Step: 6
Training loss: 0.0832076221704483
Validation loss: 1.4584059625543573

Epoch: 5| Step: 7
Training loss: 0.04857704043388367
Validation loss: 1.4505044183423441

Epoch: 5| Step: 8
Training loss: 0.06566821038722992
Validation loss: 1.4362335679351643

Epoch: 5| Step: 9
Training loss: 0.051712535321712494
Validation loss: 1.4479274365209764

Epoch: 5| Step: 10
Training loss: 0.04567720741033554
Validation loss: 1.4441395228908909

Epoch: 599| Step: 0
Training loss: 0.09302157908678055
Validation loss: 1.4672890702883403

Epoch: 5| Step: 1
Training loss: 0.05742964893579483
Validation loss: 1.4809340917935936

Epoch: 5| Step: 2
Training loss: 0.04847411438822746
Validation loss: 1.4774545982319822

Epoch: 5| Step: 3
Training loss: 0.0663733258843422
Validation loss: 1.467299489564793

Epoch: 5| Step: 4
Training loss: 0.08237253129482269
Validation loss: 1.462570010974843

Epoch: 5| Step: 5
Training loss: 0.05182826519012451
Validation loss: 1.489024152037918

Epoch: 5| Step: 6
Training loss: 0.05770159885287285
Validation loss: 1.4485685427983601

Epoch: 5| Step: 7
Training loss: 0.09330394119024277
Validation loss: 1.4465500821349442

Epoch: 5| Step: 8
Training loss: 0.08054077625274658
Validation loss: 1.4713184782253799

Epoch: 5| Step: 9
Training loss: 0.04185778647661209
Validation loss: 1.4722737073898315

Epoch: 5| Step: 10
Training loss: 0.03732755780220032
Validation loss: 1.438706951756631

Epoch: 600| Step: 0
Training loss: 0.08460211753845215
Validation loss: 1.4533271443459295

Epoch: 5| Step: 1
Training loss: 0.035140059888362885
Validation loss: 1.471461630636646

Epoch: 5| Step: 2
Training loss: 0.07960256189107895
Validation loss: 1.4800115580199866

Epoch: 5| Step: 3
Training loss: 0.09934697300195694
Validation loss: 1.4924880016234614

Epoch: 5| Step: 4
Training loss: 0.08707096427679062
Validation loss: 1.4691014123219315

Epoch: 5| Step: 5
Training loss: 0.11308284103870392
Validation loss: 1.4912068959205382

Epoch: 5| Step: 6
Training loss: 0.058119259774684906
Validation loss: 1.4888184916588567

Epoch: 5| Step: 7
Training loss: 0.06082770228385925
Validation loss: 1.4820767884613366

Epoch: 5| Step: 8
Training loss: 0.0458822175860405
Validation loss: 1.469382959027444

Epoch: 5| Step: 9
Training loss: 0.04668089747428894
Validation loss: 1.4677504108798118

Epoch: 5| Step: 10
Training loss: 0.06743048876523972
Validation loss: 1.4636715163466751

Epoch: 601| Step: 0
Training loss: 0.06358543783426285
Validation loss: 1.4680927985457963

Epoch: 5| Step: 1
Training loss: 0.06579013168811798
Validation loss: 1.4398626871006464

Epoch: 5| Step: 2
Training loss: 0.0751800686120987
Validation loss: 1.4503591522093742

Epoch: 5| Step: 3
Training loss: 0.09756100922822952
Validation loss: 1.4348253793613885

Epoch: 5| Step: 4
Training loss: 0.03987082093954086
Validation loss: 1.444492869479682

Epoch: 5| Step: 5
Training loss: 0.09026474505662918
Validation loss: 1.4398841986092188

Epoch: 5| Step: 6
Training loss: 0.05197439715266228
Validation loss: 1.4588177140041063

Epoch: 5| Step: 7
Training loss: 0.05154300853610039
Validation loss: 1.4525945007160146

Epoch: 5| Step: 8
Training loss: 0.09059528261423111
Validation loss: 1.4597906656162714

Epoch: 5| Step: 9
Training loss: 0.04674891382455826
Validation loss: 1.4845894677664644

Epoch: 5| Step: 10
Training loss: 0.04182662069797516
Validation loss: 1.4912663018831642

Epoch: 602| Step: 0
Training loss: 0.06126675754785538
Validation loss: 1.51033111797866

Epoch: 5| Step: 1
Training loss: 0.0559992790222168
Validation loss: 1.4817641627403997

Epoch: 5| Step: 2
Training loss: 0.060536373406648636
Validation loss: 1.5052585588988436

Epoch: 5| Step: 3
Training loss: 0.064240962266922
Validation loss: 1.4973018041221045

Epoch: 5| Step: 4
Training loss: 0.0678485631942749
Validation loss: 1.475128025136968

Epoch: 5| Step: 5
Training loss: 0.09741117060184479
Validation loss: 1.4887622441014936

Epoch: 5| Step: 6
Training loss: 0.06748265027999878
Validation loss: 1.4856617630168956

Epoch: 5| Step: 7
Training loss: 0.1491924524307251
Validation loss: 1.4890933100895216

Epoch: 5| Step: 8
Training loss: 0.05216671898961067
Validation loss: 1.4764712728479856

Epoch: 5| Step: 9
Training loss: 0.04774380475282669
Validation loss: 1.490937896954116

Epoch: 5| Step: 10
Training loss: 0.04833538830280304
Validation loss: 1.4862320846126926

Epoch: 603| Step: 0
Training loss: 0.05556686967611313
Validation loss: 1.4941063523292542

Epoch: 5| Step: 1
Training loss: 0.06381606310606003
Validation loss: 1.4774675561535744

Epoch: 5| Step: 2
Training loss: 0.06919287145137787
Validation loss: 1.4511082531303487

Epoch: 5| Step: 3
Training loss: 0.061044324189424515
Validation loss: 1.4862727772804998

Epoch: 5| Step: 4
Training loss: 0.06783580034971237
Validation loss: 1.4799631052119757

Epoch: 5| Step: 5
Training loss: 0.06492903083562851
Validation loss: 1.4775114584994573

Epoch: 5| Step: 6
Training loss: 0.07278595864772797
Validation loss: 1.4743649869836786

Epoch: 5| Step: 7
Training loss: 0.03908315673470497
Validation loss: 1.4812405083769111

Epoch: 5| Step: 8
Training loss: 0.0886395201086998
Validation loss: 1.5018447817012828

Epoch: 5| Step: 9
Training loss: 0.06330814957618713
Validation loss: 1.5050370706024991

Epoch: 5| Step: 10
Training loss: 0.06201983243227005
Validation loss: 1.5062616614885227

Epoch: 604| Step: 0
Training loss: 0.09359193593263626
Validation loss: 1.5165040057192567

Epoch: 5| Step: 1
Training loss: 0.08155445009469986
Validation loss: 1.501709250993626

Epoch: 5| Step: 2
Training loss: 0.05333326384425163
Validation loss: 1.4897189300547364

Epoch: 5| Step: 3
Training loss: 0.07083283364772797
Validation loss: 1.4957083758487497

Epoch: 5| Step: 4
Training loss: 0.047879207879304886
Validation loss: 1.502280217345043

Epoch: 5| Step: 5
Training loss: 0.0338432602584362
Validation loss: 1.504237174987793

Epoch: 5| Step: 6
Training loss: 0.06334368139505386
Validation loss: 1.4791833957036336

Epoch: 5| Step: 7
Training loss: 0.0631210058927536
Validation loss: 1.5010194573351132

Epoch: 5| Step: 8
Training loss: 0.07079713046550751
Validation loss: 1.471902601180538

Epoch: 5| Step: 9
Training loss: 0.0832645371556282
Validation loss: 1.4786548140228435

Epoch: 5| Step: 10
Training loss: 0.041057683527469635
Validation loss: 1.49136524046621

Epoch: 605| Step: 0
Training loss: 0.07107490301132202
Validation loss: 1.4653574689742057

Epoch: 5| Step: 1
Training loss: 0.056916773319244385
Validation loss: 1.459686731138537

Epoch: 5| Step: 2
Training loss: 0.10159466415643692
Validation loss: 1.488056889144323

Epoch: 5| Step: 3
Training loss: 0.07677845656871796
Validation loss: 1.4952741656252133

Epoch: 5| Step: 4
Training loss: 0.04960555583238602
Validation loss: 1.4666875549542007

Epoch: 5| Step: 5
Training loss: 0.03936358913779259
Validation loss: 1.4847399906445575

Epoch: 5| Step: 6
Training loss: 0.07195773720741272
Validation loss: 1.4914329654426985

Epoch: 5| Step: 7
Training loss: 0.033909715712070465
Validation loss: 1.5322076607775945

Epoch: 5| Step: 8
Training loss: 0.06864318996667862
Validation loss: 1.5024051499623123

Epoch: 5| Step: 9
Training loss: 0.050780851393938065
Validation loss: 1.512881657128693

Epoch: 5| Step: 10
Training loss: 0.05383514612913132
Validation loss: 1.5126490753184083

Epoch: 606| Step: 0
Training loss: 0.0666140615940094
Validation loss: 1.4888207130534674

Epoch: 5| Step: 1
Training loss: 0.07063297927379608
Validation loss: 1.494702983927983

Epoch: 5| Step: 2
Training loss: 0.08795152604579926
Validation loss: 1.496717745257962

Epoch: 5| Step: 3
Training loss: 0.04873954877257347
Validation loss: 1.5097296199490946

Epoch: 5| Step: 4
Training loss: 0.05477423593401909
Validation loss: 1.49698208865299

Epoch: 5| Step: 5
Training loss: 0.08805415779352188
Validation loss: 1.4983697963017288

Epoch: 5| Step: 6
Training loss: 0.04461345821619034
Validation loss: 1.4889885712695379

Epoch: 5| Step: 7
Training loss: 0.09484081715345383
Validation loss: 1.4952439403021207

Epoch: 5| Step: 8
Training loss: 0.06191164255142212
Validation loss: 1.481195439574539

Epoch: 5| Step: 9
Training loss: 0.061372846364974976
Validation loss: 1.4816947361474395

Epoch: 5| Step: 10
Training loss: 0.10924273729324341
Validation loss: 1.4709656014237353

Epoch: 607| Step: 0
Training loss: 0.09936344623565674
Validation loss: 1.4574583704753588

Epoch: 5| Step: 1
Training loss: 0.09660976380109787
Validation loss: 1.4715993481297647

Epoch: 5| Step: 2
Training loss: 0.054261695593595505
Validation loss: 1.4564157506471038

Epoch: 5| Step: 3
Training loss: 0.055636703968048096
Validation loss: 1.4959141746644051

Epoch: 5| Step: 4
Training loss: 0.08820783346891403
Validation loss: 1.5298692872447353

Epoch: 5| Step: 5
Training loss: 0.07999614626169205
Validation loss: 1.5044649288218508

Epoch: 5| Step: 6
Training loss: 0.10511825978755951
Validation loss: 1.517461892097227

Epoch: 5| Step: 7
Training loss: 0.07860670238733292
Validation loss: 1.4748829295558314

Epoch: 5| Step: 8
Training loss: 0.05205178260803223
Validation loss: 1.463357030063547

Epoch: 5| Step: 9
Training loss: 0.0667831152677536
Validation loss: 1.4677625317727365

Epoch: 5| Step: 10
Training loss: 0.06455180048942566
Validation loss: 1.4569090797055153

Epoch: 608| Step: 0
Training loss: 0.070513054728508
Validation loss: 1.4661720260497062

Epoch: 5| Step: 1
Training loss: 0.035164278000593185
Validation loss: 1.4793746984133156

Epoch: 5| Step: 2
Training loss: 0.07798604667186737
Validation loss: 1.450714180546422

Epoch: 5| Step: 3
Training loss: 0.08975866436958313
Validation loss: 1.4624215633638444

Epoch: 5| Step: 4
Training loss: 0.04554523155093193
Validation loss: 1.4709502202208324

Epoch: 5| Step: 5
Training loss: 0.03778628632426262
Validation loss: 1.4573990734674598

Epoch: 5| Step: 6
Training loss: 0.04470293968915939
Validation loss: 1.4748807773795178

Epoch: 5| Step: 7
Training loss: 0.02794804237782955
Validation loss: 1.4897840112768195

Epoch: 5| Step: 8
Training loss: 0.11714514344930649
Validation loss: 1.485789010601659

Epoch: 5| Step: 9
Training loss: 0.1019165962934494
Validation loss: 1.485079523055784

Epoch: 5| Step: 10
Training loss: 0.0967981219291687
Validation loss: 1.477212723865304

Epoch: 609| Step: 0
Training loss: 0.03973802179098129
Validation loss: 1.4645147522290547

Epoch: 5| Step: 1
Training loss: 0.06888974457979202
Validation loss: 1.482066604398912

Epoch: 5| Step: 2
Training loss: 0.10610582679510117
Validation loss: 1.4689831849067443

Epoch: 5| Step: 3
Training loss: 0.09937871992588043
Validation loss: 1.4499646912338913

Epoch: 5| Step: 4
Training loss: 0.07224830240011215
Validation loss: 1.484069617845679

Epoch: 5| Step: 5
Training loss: 0.04132739081978798
Validation loss: 1.4976192764056626

Epoch: 5| Step: 6
Training loss: 0.041734352707862854
Validation loss: 1.5178223027977893

Epoch: 5| Step: 7
Training loss: 0.036214884370565414
Validation loss: 1.5321912291229411

Epoch: 5| Step: 8
Training loss: 0.08967672288417816
Validation loss: 1.5307414993163078

Epoch: 5| Step: 9
Training loss: 0.10874694585800171
Validation loss: 1.5589770873387654

Epoch: 5| Step: 10
Training loss: 0.12185338139533997
Validation loss: 1.536073407178284

Epoch: 610| Step: 0
Training loss: 0.06901855766773224
Validation loss: 1.5431167438466062

Epoch: 5| Step: 1
Training loss: 0.06972052156925201
Validation loss: 1.504621362173429

Epoch: 5| Step: 2
Training loss: 0.07705391943454742
Validation loss: 1.4739381805542977

Epoch: 5| Step: 3
Training loss: 0.08625639975070953
Validation loss: 1.4505151574329664

Epoch: 5| Step: 4
Training loss: 0.07384692132472992
Validation loss: 1.4355332697591474

Epoch: 5| Step: 5
Training loss: 0.11157436668872833
Validation loss: 1.4695249757459086

Epoch: 5| Step: 6
Training loss: 0.09957098960876465
Validation loss: 1.4677820128779258

Epoch: 5| Step: 7
Training loss: 0.0610739104449749
Validation loss: 1.4932629741648191

Epoch: 5| Step: 8
Training loss: 0.04787523299455643
Validation loss: 1.4891523353515133

Epoch: 5| Step: 9
Training loss: 0.07543604075908661
Validation loss: 1.5078485781146633

Epoch: 5| Step: 10
Training loss: 0.10526467859745026
Validation loss: 1.5211333690151092

Epoch: 611| Step: 0
Training loss: 0.0627230629324913
Validation loss: 1.5020056142601916

Epoch: 5| Step: 1
Training loss: 0.0805528461933136
Validation loss: 1.504397830655498

Epoch: 5| Step: 2
Training loss: 0.04697223752737045
Validation loss: 1.479156142921858

Epoch: 5| Step: 3
Training loss: 0.08937274664640427
Validation loss: 1.509599660032539

Epoch: 5| Step: 4
Training loss: 0.10431939363479614
Validation loss: 1.4856200910383655

Epoch: 5| Step: 5
Training loss: 0.07886424660682678
Validation loss: 1.4836732238851569

Epoch: 5| Step: 6
Training loss: 0.09063373506069183
Validation loss: 1.480248987033803

Epoch: 5| Step: 7
Training loss: 0.07049863040447235
Validation loss: 1.4893447724721764

Epoch: 5| Step: 8
Training loss: 0.058523230254650116
Validation loss: 1.4933961411958099

Epoch: 5| Step: 9
Training loss: 0.05811517685651779
Validation loss: 1.4846469535622546

Epoch: 5| Step: 10
Training loss: 0.09226956218481064
Validation loss: 1.5046039832535612

Epoch: 612| Step: 0
Training loss: 0.09387779235839844
Validation loss: 1.4953819526139127

Epoch: 5| Step: 1
Training loss: 0.06455978006124496
Validation loss: 1.5008164580150316

Epoch: 5| Step: 2
Training loss: 0.08555639535188675
Validation loss: 1.4979680712505052

Epoch: 5| Step: 3
Training loss: 0.05009818077087402
Validation loss: 1.5048064557454919

Epoch: 5| Step: 4
Training loss: 0.04680807143449783
Validation loss: 1.5011500889255154

Epoch: 5| Step: 5
Training loss: 0.054918766021728516
Validation loss: 1.4893515340743526

Epoch: 5| Step: 6
Training loss: 0.06335383653640747
Validation loss: 1.4891529211433985

Epoch: 5| Step: 7
Training loss: 0.030611932277679443
Validation loss: 1.4828269994387062

Epoch: 5| Step: 8
Training loss: 0.07135336846113205
Validation loss: 1.4922226257221674

Epoch: 5| Step: 9
Training loss: 0.04153050109744072
Validation loss: 1.4859581980653989

Epoch: 5| Step: 10
Training loss: 0.06697866320610046
Validation loss: 1.4855535056001397

Epoch: 613| Step: 0
Training loss: 0.10298898071050644
Validation loss: 1.4830966444425686

Epoch: 5| Step: 1
Training loss: 0.060314200818538666
Validation loss: 1.497198768841323

Epoch: 5| Step: 2
Training loss: 0.04549329727888107
Validation loss: 1.4835813994048743

Epoch: 5| Step: 3
Training loss: 0.0459727980196476
Validation loss: 1.4702251444580734

Epoch: 5| Step: 4
Training loss: 0.07085555791854858
Validation loss: 1.4857150213692778

Epoch: 5| Step: 5
Training loss: 0.03509950637817383
Validation loss: 1.488216588574071

Epoch: 5| Step: 6
Training loss: 0.0380198173224926
Validation loss: 1.4934924815290718

Epoch: 5| Step: 7
Training loss: 0.06317397952079773
Validation loss: 1.4970195908700266

Epoch: 5| Step: 8
Training loss: 0.0950247198343277
Validation loss: 1.4893281318808114

Epoch: 5| Step: 9
Training loss: 0.03438231348991394
Validation loss: 1.4856442110512846

Epoch: 5| Step: 10
Training loss: 0.07823008298873901
Validation loss: 1.4896976338919772

Epoch: 614| Step: 0
Training loss: 0.043461598455905914
Validation loss: 1.4970229069391887

Epoch: 5| Step: 1
Training loss: 0.07488323748111725
Validation loss: 1.4923589780766477

Epoch: 5| Step: 2
Training loss: 0.04236697405576706
Validation loss: 1.498635950908866

Epoch: 5| Step: 3
Training loss: 0.05494345352053642
Validation loss: 1.5207749182178127

Epoch: 5| Step: 4
Training loss: 0.043167177587747574
Validation loss: 1.508101894009498

Epoch: 5| Step: 5
Training loss: 0.04121248051524162
Validation loss: 1.5275339657260525

Epoch: 5| Step: 6
Training loss: 0.06777229905128479
Validation loss: 1.5149795957790908

Epoch: 5| Step: 7
Training loss: 0.1196037083864212
Validation loss: 1.521717192024313

Epoch: 5| Step: 8
Training loss: 0.06708001345396042
Validation loss: 1.5062210931572864

Epoch: 5| Step: 9
Training loss: 0.05660095065832138
Validation loss: 1.4973178371306388

Epoch: 5| Step: 10
Training loss: 0.09162123501300812
Validation loss: 1.4819521468172792

Epoch: 615| Step: 0
Training loss: 0.054531026631593704
Validation loss: 1.5115457606571976

Epoch: 5| Step: 1
Training loss: 0.05120965093374252
Validation loss: 1.4841839023815688

Epoch: 5| Step: 2
Training loss: 0.0745527371764183
Validation loss: 1.510830093455571

Epoch: 5| Step: 3
Training loss: 0.05124548077583313
Validation loss: 1.4915777393566665

Epoch: 5| Step: 4
Training loss: 0.07212456315755844
Validation loss: 1.4919397036234539

Epoch: 5| Step: 5
Training loss: 0.06245676800608635
Validation loss: 1.5088064132198211

Epoch: 5| Step: 6
Training loss: 0.09683308750391006
Validation loss: 1.491840700949392

Epoch: 5| Step: 7
Training loss: 0.05404970049858093
Validation loss: 1.4937485418012064

Epoch: 5| Step: 8
Training loss: 0.0490993931889534
Validation loss: 1.486399665314664

Epoch: 5| Step: 9
Training loss: 0.03995036333799362
Validation loss: 1.4938336315975393

Epoch: 5| Step: 10
Training loss: 0.03933323919773102
Validation loss: 1.5066659860713507

Epoch: 616| Step: 0
Training loss: 0.061822421848773956
Validation loss: 1.4729099786409767

Epoch: 5| Step: 1
Training loss: 0.09855462610721588
Validation loss: 1.4811259636314966

Epoch: 5| Step: 2
Training loss: 0.055338095873594284
Validation loss: 1.4540242584802772

Epoch: 5| Step: 3
Training loss: 0.07245078682899475
Validation loss: 1.4586534833395353

Epoch: 5| Step: 4
Training loss: 0.08734922856092453
Validation loss: 1.4911079387510977

Epoch: 5| Step: 5
Training loss: 0.04416564106941223
Validation loss: 1.4785157390820083

Epoch: 5| Step: 6
Training loss: 0.05463097617030144
Validation loss: 1.473918995549602

Epoch: 5| Step: 7
Training loss: 0.07434269040822983
Validation loss: 1.4895707266305083

Epoch: 5| Step: 8
Training loss: 0.063163623213768
Validation loss: 1.5078492882431194

Epoch: 5| Step: 9
Training loss: 0.040822483599185944
Validation loss: 1.4951999764288626

Epoch: 5| Step: 10
Training loss: 0.05953086167573929
Validation loss: 1.5130948251293552

Epoch: 617| Step: 0
Training loss: 0.03222901374101639
Validation loss: 1.5052652512827227

Epoch: 5| Step: 1
Training loss: 0.0490284338593483
Validation loss: 1.507076031418257

Epoch: 5| Step: 2
Training loss: 0.06847616285085678
Validation loss: 1.5126347509763574

Epoch: 5| Step: 3
Training loss: 0.03861116245388985
Validation loss: 1.5079901897779076

Epoch: 5| Step: 4
Training loss: 0.05611908435821533
Validation loss: 1.5111628655464417

Epoch: 5| Step: 5
Training loss: 0.08020053803920746
Validation loss: 1.5148201482270354

Epoch: 5| Step: 6
Training loss: 0.08836837112903595
Validation loss: 1.507656128175797

Epoch: 5| Step: 7
Training loss: 0.07546941936016083
Validation loss: 1.5165689497865655

Epoch: 5| Step: 8
Training loss: 0.08238513767719269
Validation loss: 1.5110202091996388

Epoch: 5| Step: 9
Training loss: 0.04390556737780571
Validation loss: 1.487514422144941

Epoch: 5| Step: 10
Training loss: 0.07824450731277466
Validation loss: 1.4750493546967864

Epoch: 618| Step: 0
Training loss: 0.05020666867494583
Validation loss: 1.4421889461496824

Epoch: 5| Step: 1
Training loss: 0.05804403871297836
Validation loss: 1.4543795790723575

Epoch: 5| Step: 2
Training loss: 0.08802911639213562
Validation loss: 1.460109112083271

Epoch: 5| Step: 3
Training loss: 0.05866857245564461
Validation loss: 1.4765052545455195

Epoch: 5| Step: 4
Training loss: 0.04810304567217827
Validation loss: 1.4694829922850414

Epoch: 5| Step: 5
Training loss: 0.07566499710083008
Validation loss: 1.4716773776597873

Epoch: 5| Step: 6
Training loss: 0.0503239631652832
Validation loss: 1.4975872091067735

Epoch: 5| Step: 7
Training loss: 0.08736877888441086
Validation loss: 1.4827302489229428

Epoch: 5| Step: 8
Training loss: 0.06891793012619019
Validation loss: 1.4802475501132268

Epoch: 5| Step: 9
Training loss: 0.05842636898159981
Validation loss: 1.4867801909805627

Epoch: 5| Step: 10
Training loss: 0.10123327374458313
Validation loss: 1.4951603425446378

Epoch: 619| Step: 0
Training loss: 0.03513781726360321
Validation loss: 1.4912371212436306

Epoch: 5| Step: 1
Training loss: 0.05545421317219734
Validation loss: 1.5266978676601122

Epoch: 5| Step: 2
Training loss: 0.06994600594043732
Validation loss: 1.5126205105935373

Epoch: 5| Step: 3
Training loss: 0.046711064875125885
Validation loss: 1.5214632980285152

Epoch: 5| Step: 4
Training loss: 0.04718119651079178
Validation loss: 1.4962272669679375

Epoch: 5| Step: 5
Training loss: 0.06839698553085327
Validation loss: 1.470678933205143

Epoch: 5| Step: 6
Training loss: 0.06640839576721191
Validation loss: 1.4770501890490133

Epoch: 5| Step: 7
Training loss: 0.049818255007267
Validation loss: 1.465735912322998

Epoch: 5| Step: 8
Training loss: 0.07161296159029007
Validation loss: 1.4358327004217333

Epoch: 5| Step: 9
Training loss: 0.07632565498352051
Validation loss: 1.4540934351182753

Epoch: 5| Step: 10
Training loss: 0.07599830627441406
Validation loss: 1.4359442155848268

Epoch: 620| Step: 0
Training loss: 0.06275264918804169
Validation loss: 1.4502519497307398

Epoch: 5| Step: 1
Training loss: 0.08999617397785187
Validation loss: 1.4813389137227049

Epoch: 5| Step: 2
Training loss: 0.06221621483564377
Validation loss: 1.49281786077766

Epoch: 5| Step: 3
Training loss: 0.1240798681974411
Validation loss: 1.4906303997962707

Epoch: 5| Step: 4
Training loss: 0.07653768360614777
Validation loss: 1.4908922128779913

Epoch: 5| Step: 5
Training loss: 0.06106315925717354
Validation loss: 1.4720363975853048

Epoch: 5| Step: 6
Training loss: 0.08267264068126678
Validation loss: 1.4585589952366327

Epoch: 5| Step: 7
Training loss: 0.05853673815727234
Validation loss: 1.4868955637819024

Epoch: 5| Step: 8
Training loss: 0.06737147271633148
Validation loss: 1.4781848839534226

Epoch: 5| Step: 9
Training loss: 0.059237707406282425
Validation loss: 1.454998617531151

Epoch: 5| Step: 10
Training loss: 0.05553426221013069
Validation loss: 1.4684218232349684

Epoch: 621| Step: 0
Training loss: 0.07221481204032898
Validation loss: 1.4859929392414708

Epoch: 5| Step: 1
Training loss: 0.042653780430555344
Validation loss: 1.484208700477436

Epoch: 5| Step: 2
Training loss: 0.06351856142282486
Validation loss: 1.4783176119609545

Epoch: 5| Step: 3
Training loss: 0.0870799794793129
Validation loss: 1.4663769442548034

Epoch: 5| Step: 4
Training loss: 0.06526000797748566
Validation loss: 1.4796851706761185

Epoch: 5| Step: 5
Training loss: 0.06592783331871033
Validation loss: 1.491875643371254

Epoch: 5| Step: 6
Training loss: 0.08397392928600311
Validation loss: 1.4664198813899871

Epoch: 5| Step: 7
Training loss: 0.094895139336586
Validation loss: 1.4544049334782425

Epoch: 5| Step: 8
Training loss: 0.060414064675569534
Validation loss: 1.4620912164770148

Epoch: 5| Step: 9
Training loss: 0.05999189615249634
Validation loss: 1.4636358112417243

Epoch: 5| Step: 10
Training loss: 0.03575529530644417
Validation loss: 1.4811424286134782

Epoch: 622| Step: 0
Training loss: 0.10396796464920044
Validation loss: 1.4803892008719906

Epoch: 5| Step: 1
Training loss: 0.06838929653167725
Validation loss: 1.5077668979603758

Epoch: 5| Step: 2
Training loss: 0.060463447123765945
Validation loss: 1.4998518241349088

Epoch: 5| Step: 3
Training loss: 0.07289617508649826
Validation loss: 1.4757576257951799

Epoch: 5| Step: 4
Training loss: 0.08036413788795471
Validation loss: 1.5234369065171929

Epoch: 5| Step: 5
Training loss: 0.08000914007425308
Validation loss: 1.5405065615971882

Epoch: 5| Step: 6
Training loss: 0.09288378059864044
Validation loss: 1.512060498678556

Epoch: 5| Step: 7
Training loss: 0.06166096404194832
Validation loss: 1.532967951989943

Epoch: 5| Step: 8
Training loss: 0.03527998551726341
Validation loss: 1.5179904481416107

Epoch: 5| Step: 9
Training loss: 0.06715916097164154
Validation loss: 1.5214172140244515

Epoch: 5| Step: 10
Training loss: 0.04269188642501831
Validation loss: 1.5172778970451766

Epoch: 623| Step: 0
Training loss: 0.11663302034139633
Validation loss: 1.512984952618999

Epoch: 5| Step: 1
Training loss: 0.0694575160741806
Validation loss: 1.528695616670834

Epoch: 5| Step: 2
Training loss: 0.0476866140961647
Validation loss: 1.5115316055154289

Epoch: 5| Step: 3
Training loss: 0.06594058126211166
Validation loss: 1.5102007799251105

Epoch: 5| Step: 4
Training loss: 0.07738266885280609
Validation loss: 1.5174372298743135

Epoch: 5| Step: 5
Training loss: 0.06787075102329254
Validation loss: 1.548349900912213

Epoch: 5| Step: 6
Training loss: 0.07891717553138733
Validation loss: 1.5534121862021826

Epoch: 5| Step: 7
Training loss: 0.06250335276126862
Validation loss: 1.5322855422573705

Epoch: 5| Step: 8
Training loss: 0.06520430743694305
Validation loss: 1.4967743600568464

Epoch: 5| Step: 9
Training loss: 0.0548081174492836
Validation loss: 1.5099805221762708

Epoch: 5| Step: 10
Training loss: 0.039893895387649536
Validation loss: 1.4984103614284146

Epoch: 624| Step: 0
Training loss: 0.04961570352315903
Validation loss: 1.4817091175304946

Epoch: 5| Step: 1
Training loss: 0.06067296117544174
Validation loss: 1.4913356047804638

Epoch: 5| Step: 2
Training loss: 0.07602325826883316
Validation loss: 1.4597000627107517

Epoch: 5| Step: 3
Training loss: 0.08201201260089874
Validation loss: 1.462720662034968

Epoch: 5| Step: 4
Training loss: 0.06341220438480377
Validation loss: 1.4738882780075073

Epoch: 5| Step: 5
Training loss: 0.08014221489429474
Validation loss: 1.5059138767180904

Epoch: 5| Step: 6
Training loss: 0.06058761477470398
Validation loss: 1.507687701973864

Epoch: 5| Step: 7
Training loss: 0.08400174230337143
Validation loss: 1.5332445700963337

Epoch: 5| Step: 8
Training loss: 0.06381816416978836
Validation loss: 1.5335078829078264

Epoch: 5| Step: 9
Training loss: 0.057167816907167435
Validation loss: 1.535790135783534

Epoch: 5| Step: 10
Training loss: 0.07349502295255661
Validation loss: 1.5258284256022463

Epoch: 625| Step: 0
Training loss: 0.08515442907810211
Validation loss: 1.526940502146239

Epoch: 5| Step: 1
Training loss: 0.08980260789394379
Validation loss: 1.5154306228442858

Epoch: 5| Step: 2
Training loss: 0.07521408796310425
Validation loss: 1.527803982457807

Epoch: 5| Step: 3
Training loss: 0.07341829687356949
Validation loss: 1.51989350780364

Epoch: 5| Step: 4
Training loss: 0.04905875399708748
Validation loss: 1.5348998910637313

Epoch: 5| Step: 5
Training loss: 0.1205374002456665
Validation loss: 1.516895580035384

Epoch: 5| Step: 6
Training loss: 0.04208328574895859
Validation loss: 1.516365066651375

Epoch: 5| Step: 7
Training loss: 0.0509309247136116
Validation loss: 1.5221805341782109

Epoch: 5| Step: 8
Training loss: 0.03841131925582886
Validation loss: 1.5193312450121808

Epoch: 5| Step: 9
Training loss: 0.06444714218378067
Validation loss: 1.517332992246074

Epoch: 5| Step: 10
Training loss: 0.048718780279159546
Validation loss: 1.5001739148170716

Epoch: 626| Step: 0
Training loss: 0.10084311664104462
Validation loss: 1.4967488691370974

Epoch: 5| Step: 1
Training loss: 0.07492095232009888
Validation loss: 1.4845069762199157

Epoch: 5| Step: 2
Training loss: 0.04216095805168152
Validation loss: 1.4744613401351436

Epoch: 5| Step: 3
Training loss: 0.05798019841313362
Validation loss: 1.429538949843376

Epoch: 5| Step: 4
Training loss: 0.10646741092205048
Validation loss: 1.4494682127429592

Epoch: 5| Step: 5
Training loss: 0.08279155194759369
Validation loss: 1.4366076505312355

Epoch: 5| Step: 6
Training loss: 0.09387025982141495
Validation loss: 1.4448385251465665

Epoch: 5| Step: 7
Training loss: 0.06807418167591095
Validation loss: 1.4544119732354277

Epoch: 5| Step: 8
Training loss: 0.09038113802671432
Validation loss: 1.4765523569558257

Epoch: 5| Step: 9
Training loss: 0.059831809252500534
Validation loss: 1.4517551833583462

Epoch: 5| Step: 10
Training loss: 0.04990914836525917
Validation loss: 1.480013930669395

Epoch: 627| Step: 0
Training loss: 0.04986398294568062
Validation loss: 1.5119596053195257

Epoch: 5| Step: 1
Training loss: 0.0779135674238205
Validation loss: 1.5206603414268904

Epoch: 5| Step: 2
Training loss: 0.0692327544093132
Validation loss: 1.5366478895628324

Epoch: 5| Step: 3
Training loss: 0.10464292764663696
Validation loss: 1.4998596522115892

Epoch: 5| Step: 4
Training loss: 0.04553284868597984
Validation loss: 1.4798466646543114

Epoch: 5| Step: 5
Training loss: 0.05742660164833069
Validation loss: 1.4615009907753236

Epoch: 5| Step: 6
Training loss: 0.0565999373793602
Validation loss: 1.4496049829708633

Epoch: 5| Step: 7
Training loss: 0.0832885280251503
Validation loss: 1.4389124557536135

Epoch: 5| Step: 8
Training loss: 0.07766449451446533
Validation loss: 1.442694015400384

Epoch: 5| Step: 9
Training loss: 0.07453365623950958
Validation loss: 1.4537176726966776

Epoch: 5| Step: 10
Training loss: 0.036936987191438675
Validation loss: 1.4731625139072377

Epoch: 628| Step: 0
Training loss: 0.04648072272539139
Validation loss: 1.4802837756372267

Epoch: 5| Step: 1
Training loss: 0.03694559261202812
Validation loss: 1.4810284799145115

Epoch: 5| Step: 2
Training loss: 0.04498768597841263
Validation loss: 1.4772198136134813

Epoch: 5| Step: 3
Training loss: 0.05763347074389458
Validation loss: 1.4918058944004837

Epoch: 5| Step: 4
Training loss: 0.06002752110362053
Validation loss: 1.480459459366337

Epoch: 5| Step: 5
Training loss: 0.08180473744869232
Validation loss: 1.4944892416718185

Epoch: 5| Step: 6
Training loss: 0.09282387793064117
Validation loss: 1.4930251529139857

Epoch: 5| Step: 7
Training loss: 0.044346846640110016
Validation loss: 1.4990312162265982

Epoch: 5| Step: 8
Training loss: 0.07232563197612762
Validation loss: 1.4916983278848792

Epoch: 5| Step: 9
Training loss: 0.04119008034467697
Validation loss: 1.4891343667942991

Epoch: 5| Step: 10
Training loss: 0.07349994033575058
Validation loss: 1.4744016265356412

Epoch: 629| Step: 0
Training loss: 0.05453231930732727
Validation loss: 1.4784812940064298

Epoch: 5| Step: 1
Training loss: 0.09347705543041229
Validation loss: 1.4747653904781546

Epoch: 5| Step: 2
Training loss: 0.04764873906970024
Validation loss: 1.465035112955237

Epoch: 5| Step: 3
Training loss: 0.04967818781733513
Validation loss: 1.5042191487486645

Epoch: 5| Step: 4
Training loss: 0.03675777465105057
Validation loss: 1.485237483055361

Epoch: 5| Step: 5
Training loss: 0.06406266987323761
Validation loss: 1.5035836811988585

Epoch: 5| Step: 6
Training loss: 0.08774960041046143
Validation loss: 1.528516605336179

Epoch: 5| Step: 7
Training loss: 0.07218154519796371
Validation loss: 1.5186917416511043

Epoch: 5| Step: 8
Training loss: 0.06806448101997375
Validation loss: 1.505371065549953

Epoch: 5| Step: 9
Training loss: 0.07281248271465302
Validation loss: 1.5112188176442218

Epoch: 5| Step: 10
Training loss: 0.05054504796862602
Validation loss: 1.4845583977237824

Epoch: 630| Step: 0
Training loss: 0.038881201297044754
Validation loss: 1.483080731925144

Epoch: 5| Step: 1
Training loss: 0.027713501825928688
Validation loss: 1.5146968800534484

Epoch: 5| Step: 2
Training loss: 0.04362218454480171
Validation loss: 1.5036748391325756

Epoch: 5| Step: 3
Training loss: 0.08970487117767334
Validation loss: 1.4723741405753679

Epoch: 5| Step: 4
Training loss: 0.05726027488708496
Validation loss: 1.4893648829511417

Epoch: 5| Step: 5
Training loss: 0.07546274363994598
Validation loss: 1.4993282364260765

Epoch: 5| Step: 6
Training loss: 0.025424888357520103
Validation loss: 1.4580068254983554

Epoch: 5| Step: 7
Training loss: 0.029718244448304176
Validation loss: 1.4394537530919558

Epoch: 5| Step: 8
Training loss: 0.07303202152252197
Validation loss: 1.4358516136805217

Epoch: 5| Step: 9
Training loss: 0.0799194723367691
Validation loss: 1.4442582066341112

Epoch: 5| Step: 10
Training loss: 0.05595037341117859
Validation loss: 1.4496852544046217

Epoch: 631| Step: 0
Training loss: 0.0739724189043045
Validation loss: 1.4556188096282303

Epoch: 5| Step: 1
Training loss: 0.07886068522930145
Validation loss: 1.4629957060660086

Epoch: 5| Step: 2
Training loss: 0.042234376072883606
Validation loss: 1.457981849229464

Epoch: 5| Step: 3
Training loss: 0.06360330432653427
Validation loss: 1.4567399486418693

Epoch: 5| Step: 4
Training loss: 0.06011294201016426
Validation loss: 1.489148082271699

Epoch: 5| Step: 5
Training loss: 0.04575560241937637
Validation loss: 1.473604256106961

Epoch: 5| Step: 6
Training loss: 0.06119983270764351
Validation loss: 1.4573694993090887

Epoch: 5| Step: 7
Training loss: 0.053853582590818405
Validation loss: 1.4433408014235958

Epoch: 5| Step: 8
Training loss: 0.04565947875380516
Validation loss: 1.458505940693681

Epoch: 5| Step: 9
Training loss: 0.03806810826063156
Validation loss: 1.4291958526898456

Epoch: 5| Step: 10
Training loss: 0.027278441935777664
Validation loss: 1.4489397169441305

Epoch: 632| Step: 0
Training loss: 0.07146099954843521
Validation loss: 1.4286754951682141

Epoch: 5| Step: 1
Training loss: 0.05091022327542305
Validation loss: 1.4395201283116494

Epoch: 5| Step: 2
Training loss: 0.09988267719745636
Validation loss: 1.4437024054988739

Epoch: 5| Step: 3
Training loss: 0.04711950942873955
Validation loss: 1.4150111764989874

Epoch: 5| Step: 4
Training loss: 0.1114659532904625
Validation loss: 1.4156696193961686

Epoch: 5| Step: 5
Training loss: 0.051651351153850555
Validation loss: 1.451567809427938

Epoch: 5| Step: 6
Training loss: 0.06776399910449982
Validation loss: 1.4449952187076691

Epoch: 5| Step: 7
Training loss: 0.05150378867983818
Validation loss: 1.443443307312586

Epoch: 5| Step: 8
Training loss: 0.06586208194494247
Validation loss: 1.4430622016229937

Epoch: 5| Step: 9
Training loss: 0.06884882599115372
Validation loss: 1.4668025483367264

Epoch: 5| Step: 10
Training loss: 0.03930821642279625
Validation loss: 1.4497084540705527

Epoch: 633| Step: 0
Training loss: 0.08920745551586151
Validation loss: 1.4493925680396378

Epoch: 5| Step: 1
Training loss: 0.053487084805965424
Validation loss: 1.4489608182702014

Epoch: 5| Step: 2
Training loss: 0.04765058308839798
Validation loss: 1.467639079657934

Epoch: 5| Step: 3
Training loss: 0.05424105376005173
Validation loss: 1.4748477692245154

Epoch: 5| Step: 4
Training loss: 0.049091093242168427
Validation loss: 1.467263525532138

Epoch: 5| Step: 5
Training loss: 0.0502675399184227
Validation loss: 1.473308673468969

Epoch: 5| Step: 6
Training loss: 0.0474797785282135
Validation loss: 1.4825210097015544

Epoch: 5| Step: 7
Training loss: 0.06434347480535507
Validation loss: 1.4674951004725632

Epoch: 5| Step: 8
Training loss: 0.044177450239658356
Validation loss: 1.4728943006966704

Epoch: 5| Step: 9
Training loss: 0.10818742215633392
Validation loss: 1.4304136614645682

Epoch: 5| Step: 10
Training loss: 0.08204217255115509
Validation loss: 1.4563168671823317

Epoch: 634| Step: 0
Training loss: 0.10364427417516708
Validation loss: 1.4461829559777373

Epoch: 5| Step: 1
Training loss: 0.0526818223297596
Validation loss: 1.463290729830342

Epoch: 5| Step: 2
Training loss: 0.04942215234041214
Validation loss: 1.4639804869569757

Epoch: 5| Step: 3
Training loss: 0.06288159638643265
Validation loss: 1.455767830212911

Epoch: 5| Step: 4
Training loss: 0.06093514710664749
Validation loss: 1.4594964468350975

Epoch: 5| Step: 5
Training loss: 0.06277356296777725
Validation loss: 1.4817264163365929

Epoch: 5| Step: 6
Training loss: 0.058162666857242584
Validation loss: 1.445925098593517

Epoch: 5| Step: 7
Training loss: 0.056169092655181885
Validation loss: 1.4763028032036238

Epoch: 5| Step: 8
Training loss: 0.05083843320608139
Validation loss: 1.45733505423351

Epoch: 5| Step: 9
Training loss: 0.06904597580432892
Validation loss: 1.45227228313364

Epoch: 5| Step: 10
Training loss: 0.05385890603065491
Validation loss: 1.4597191579880253

Epoch: 635| Step: 0
Training loss: 0.06766287237405777
Validation loss: 1.4668767554785616

Epoch: 5| Step: 1
Training loss: 0.03279086947441101
Validation loss: 1.4726186990737915

Epoch: 5| Step: 2
Training loss: 0.09201499074697495
Validation loss: 1.497580611577598

Epoch: 5| Step: 3
Training loss: 0.07770735025405884
Validation loss: 1.4762178133892756

Epoch: 5| Step: 4
Training loss: 0.0742972120642662
Validation loss: 1.4921620802212787

Epoch: 5| Step: 5
Training loss: 0.074815534055233
Validation loss: 1.4727356549232238

Epoch: 5| Step: 6
Training loss: 0.05666027590632439
Validation loss: 1.4490239915027414

Epoch: 5| Step: 7
Training loss: 0.07418192923069
Validation loss: 1.4682876756114345

Epoch: 5| Step: 8
Training loss: 0.05828707292675972
Validation loss: 1.462347605536061

Epoch: 5| Step: 9
Training loss: 0.04346786066889763
Validation loss: 1.4576509127052881

Epoch: 5| Step: 10
Training loss: 0.03970449045300484
Validation loss: 1.460494956662578

Epoch: 636| Step: 0
Training loss: 0.07739146798849106
Validation loss: 1.4949887016768098

Epoch: 5| Step: 1
Training loss: 0.08056801557540894
Validation loss: 1.4963672853285266

Epoch: 5| Step: 2
Training loss: 0.07315127551555634
Validation loss: 1.501592086207482

Epoch: 5| Step: 3
Training loss: 0.07381586730480194
Validation loss: 1.5075388634076683

Epoch: 5| Step: 4
Training loss: 0.07170109450817108
Validation loss: 1.501438190860133

Epoch: 5| Step: 5
Training loss: 0.05163774639368057
Validation loss: 1.5172013967267928

Epoch: 5| Step: 6
Training loss: 0.052091777324676514
Validation loss: 1.4812449601388746

Epoch: 5| Step: 7
Training loss: 0.03612317889928818
Validation loss: 1.4728390683409989

Epoch: 5| Step: 8
Training loss: 0.06662706285715103
Validation loss: 1.4782286997764342

Epoch: 5| Step: 9
Training loss: 0.07230392843484879
Validation loss: 1.4656616744174753

Epoch: 5| Step: 10
Training loss: 0.05438593029975891
Validation loss: 1.4604565712713427

Epoch: 637| Step: 0
Training loss: 0.04773232713341713
Validation loss: 1.4480003490242908

Epoch: 5| Step: 1
Training loss: 0.08612044155597687
Validation loss: 1.459527172068114

Epoch: 5| Step: 2
Training loss: 0.08053295314311981
Validation loss: 1.449288493843489

Epoch: 5| Step: 3
Training loss: 0.07834421843290329
Validation loss: 1.4589732475178216

Epoch: 5| Step: 4
Training loss: 0.08265659958124161
Validation loss: 1.4505068884100965

Epoch: 5| Step: 5
Training loss: 0.07188279926776886
Validation loss: 1.4450829362356534

Epoch: 5| Step: 6
Training loss: 0.08209621906280518
Validation loss: 1.4470647945198962

Epoch: 5| Step: 7
Training loss: 0.03666189685463905
Validation loss: 1.428562976980722

Epoch: 5| Step: 8
Training loss: 0.05493038147687912
Validation loss: 1.4468394684535202

Epoch: 5| Step: 9
Training loss: 0.050821781158447266
Validation loss: 1.4434687642640964

Epoch: 5| Step: 10
Training loss: 0.06479662656784058
Validation loss: 1.43122439230642

Epoch: 638| Step: 0
Training loss: 0.050878096371889114
Validation loss: 1.4409618294367226

Epoch: 5| Step: 1
Training loss: 0.1180514544248581
Validation loss: 1.4639387489646993

Epoch: 5| Step: 2
Training loss: 0.07952616363763809
Validation loss: 1.4547606232345744

Epoch: 5| Step: 3
Training loss: 0.08124230057001114
Validation loss: 1.4677756550491496

Epoch: 5| Step: 4
Training loss: 0.04521728307008743
Validation loss: 1.4716056880130564

Epoch: 5| Step: 5
Training loss: 0.06117549538612366
Validation loss: 1.4796314085683515

Epoch: 5| Step: 6
Training loss: 0.05113215371966362
Validation loss: 1.4747724648444884

Epoch: 5| Step: 7
Training loss: 0.07820771634578705
Validation loss: 1.4952067482856013

Epoch: 5| Step: 8
Training loss: 0.04866500571370125
Validation loss: 1.483281312450286

Epoch: 5| Step: 9
Training loss: 0.06406359374523163
Validation loss: 1.482804129200597

Epoch: 5| Step: 10
Training loss: 0.056225989013910294
Validation loss: 1.4656880696614583

Epoch: 639| Step: 0
Training loss: 0.07062096893787384
Validation loss: 1.4855786267147268

Epoch: 5| Step: 1
Training loss: 0.0663098469376564
Validation loss: 1.4755664153765606

Epoch: 5| Step: 2
Training loss: 0.03028375841677189
Validation loss: 1.474484242418761

Epoch: 5| Step: 3
Training loss: 0.09545718133449554
Validation loss: 1.4701186117305551

Epoch: 5| Step: 4
Training loss: 0.043175630271434784
Validation loss: 1.4509335423028598

Epoch: 5| Step: 5
Training loss: 0.04948288947343826
Validation loss: 1.4537228871417303

Epoch: 5| Step: 6
Training loss: 0.056577764451503754
Validation loss: 1.4664941372409943

Epoch: 5| Step: 7
Training loss: 0.07629817724227905
Validation loss: 1.4529429084511214

Epoch: 5| Step: 8
Training loss: 0.0487833246588707
Validation loss: 1.436222707071612

Epoch: 5| Step: 9
Training loss: 0.07541754841804504
Validation loss: 1.4314990043640137

Epoch: 5| Step: 10
Training loss: 0.05281985551118851
Validation loss: 1.46972571521677

Epoch: 640| Step: 0
Training loss: 0.042052678763866425
Validation loss: 1.477061342167598

Epoch: 5| Step: 1
Training loss: 0.04164295643568039
Validation loss: 1.4564167684124363

Epoch: 5| Step: 2
Training loss: 0.05137072876095772
Validation loss: 1.4553772845575887

Epoch: 5| Step: 3
Training loss: 0.027033204212784767
Validation loss: 1.4523075588287846

Epoch: 5| Step: 4
Training loss: 0.04317963868379593
Validation loss: 1.484134308753475

Epoch: 5| Step: 5
Training loss: 0.06696002185344696
Validation loss: 1.4840973590009956

Epoch: 5| Step: 6
Training loss: 0.06799173355102539
Validation loss: 1.490632983946031

Epoch: 5| Step: 7
Training loss: 0.08369313180446625
Validation loss: 1.493518482292852

Epoch: 5| Step: 8
Training loss: 0.06814907491207123
Validation loss: 1.4862076825993036

Epoch: 5| Step: 9
Training loss: 0.04981331154704094
Validation loss: 1.4803271652549825

Epoch: 5| Step: 10
Training loss: 0.054080620408058167
Validation loss: 1.4720922464965491

Epoch: 641| Step: 0
Training loss: 0.05488606169819832
Validation loss: 1.4738683354470037

Epoch: 5| Step: 1
Training loss: 0.06702449172735214
Validation loss: 1.476578309971799

Epoch: 5| Step: 2
Training loss: 0.06636716425418854
Validation loss: 1.4890607787716774

Epoch: 5| Step: 3
Training loss: 0.06659150868654251
Validation loss: 1.5027754614430089

Epoch: 5| Step: 4
Training loss: 0.0576261505484581
Validation loss: 1.4923673406724007

Epoch: 5| Step: 5
Training loss: 0.06392444670200348
Validation loss: 1.4984828220900668

Epoch: 5| Step: 6
Training loss: 0.05036327987909317
Validation loss: 1.4911237468001663

Epoch: 5| Step: 7
Training loss: 0.04956343397498131
Validation loss: 1.4952022080780358

Epoch: 5| Step: 8
Training loss: 0.064457967877388
Validation loss: 1.4693726743421247

Epoch: 5| Step: 9
Training loss: 0.03158411383628845
Validation loss: 1.5092652138843332

Epoch: 5| Step: 10
Training loss: 0.046130482107400894
Validation loss: 1.4846123572318786

Epoch: 642| Step: 0
Training loss: 0.047797489911317825
Validation loss: 1.4757711784813994

Epoch: 5| Step: 1
Training loss: 0.03039703331887722
Validation loss: 1.4899365132854832

Epoch: 5| Step: 2
Training loss: 0.04721337556838989
Validation loss: 1.471121888006887

Epoch: 5| Step: 3
Training loss: 0.05386729910969734
Validation loss: 1.4767765678385252

Epoch: 5| Step: 4
Training loss: 0.0702480599284172
Validation loss: 1.4718788990410425

Epoch: 5| Step: 5
Training loss: 0.0754743441939354
Validation loss: 1.448295037592611

Epoch: 5| Step: 6
Training loss: 0.04273662343621254
Validation loss: 1.4795637079464492

Epoch: 5| Step: 7
Training loss: 0.041871000081300735
Validation loss: 1.4540049734935965

Epoch: 5| Step: 8
Training loss: 0.0530049093067646
Validation loss: 1.4756824675426687

Epoch: 5| Step: 9
Training loss: 0.057487599551677704
Validation loss: 1.4887197844443782

Epoch: 5| Step: 10
Training loss: 0.06544969975948334
Validation loss: 1.4631936434776551

Epoch: 643| Step: 0
Training loss: 0.059037089347839355
Validation loss: 1.4785354957785657

Epoch: 5| Step: 1
Training loss: 0.03552683815360069
Validation loss: 1.47337903002257

Epoch: 5| Step: 2
Training loss: 0.049363866448402405
Validation loss: 1.4614978349337013

Epoch: 5| Step: 3
Training loss: 0.0715346485376358
Validation loss: 1.4533969548440748

Epoch: 5| Step: 4
Training loss: 0.04147300869226456
Validation loss: 1.4444155193144275

Epoch: 5| Step: 5
Training loss: 0.05648015812039375
Validation loss: 1.4661544253749232

Epoch: 5| Step: 6
Training loss: 0.05344783514738083
Validation loss: 1.492627638642506

Epoch: 5| Step: 7
Training loss: 0.0458078570663929
Validation loss: 1.4814887815906155

Epoch: 5| Step: 8
Training loss: 0.046006813645362854
Validation loss: 1.4948272679441719

Epoch: 5| Step: 9
Training loss: 0.08633334189653397
Validation loss: 1.487136035837153

Epoch: 5| Step: 10
Training loss: 0.03970335051417351
Validation loss: 1.4996936936532297

Epoch: 644| Step: 0
Training loss: 0.024774881079792976
Validation loss: 1.5086222156401603

Epoch: 5| Step: 1
Training loss: 0.0966765359044075
Validation loss: 1.4953096002660773

Epoch: 5| Step: 2
Training loss: 0.06873414665460587
Validation loss: 1.4902102639598231

Epoch: 5| Step: 3
Training loss: 0.059495218098163605
Validation loss: 1.486927652871737

Epoch: 5| Step: 4
Training loss: 0.0724078044295311
Validation loss: 1.4682301270064486

Epoch: 5| Step: 5
Training loss: 0.049583107233047485
Validation loss: 1.4559652907873994

Epoch: 5| Step: 6
Training loss: 0.06936880946159363
Validation loss: 1.4464900378257997

Epoch: 5| Step: 7
Training loss: 0.0904642790555954
Validation loss: 1.4407146957612806

Epoch: 5| Step: 8
Training loss: 0.09305320680141449
Validation loss: 1.4624071044306601

Epoch: 5| Step: 9
Training loss: 0.06940729916095734
Validation loss: 1.4617655072160947

Epoch: 5| Step: 10
Training loss: 0.04778481274843216
Validation loss: 1.4829393458622757

Epoch: 645| Step: 0
Training loss: 0.047255661338567734
Validation loss: 1.4909107390270437

Epoch: 5| Step: 1
Training loss: 0.08843257278203964
Validation loss: 1.4993805141859158

Epoch: 5| Step: 2
Training loss: 0.049427974969148636
Validation loss: 1.5258844584547064

Epoch: 5| Step: 3
Training loss: 0.08172576129436493
Validation loss: 1.528924770252679

Epoch: 5| Step: 4
Training loss: 0.05946297198534012
Validation loss: 1.5122119072944886

Epoch: 5| Step: 5
Training loss: 0.06418415904045105
Validation loss: 1.5210445850126204

Epoch: 5| Step: 6
Training loss: 0.05584622174501419
Validation loss: 1.5139371515602194

Epoch: 5| Step: 7
Training loss: 0.04804692044854164
Validation loss: 1.5128734329695344

Epoch: 5| Step: 8
Training loss: 0.06720668077468872
Validation loss: 1.4931224238487981

Epoch: 5| Step: 9
Training loss: 0.07601407915353775
Validation loss: 1.4824551408008864

Epoch: 5| Step: 10
Training loss: 0.0538971982896328
Validation loss: 1.4739882266649635

Epoch: 646| Step: 0
Training loss: 0.07685868442058563
Validation loss: 1.4908938279715918

Epoch: 5| Step: 1
Training loss: 0.07374453544616699
Validation loss: 1.4749479306641446

Epoch: 5| Step: 2
Training loss: 0.06552065908908844
Validation loss: 1.4920609670300637

Epoch: 5| Step: 3
Training loss: 0.0593462698161602
Validation loss: 1.4910798233042482

Epoch: 5| Step: 4
Training loss: 0.07183559238910675
Validation loss: 1.5163994783996253

Epoch: 5| Step: 5
Training loss: 0.04282088205218315
Validation loss: 1.5114850280105427

Epoch: 5| Step: 6
Training loss: 0.05907128378748894
Validation loss: 1.5032159128496725

Epoch: 5| Step: 7
Training loss: 0.0459243580698967
Validation loss: 1.5030340251102243

Epoch: 5| Step: 8
Training loss: 0.06482920050621033
Validation loss: 1.4979319226357244

Epoch: 5| Step: 9
Training loss: 0.052491795271635056
Validation loss: 1.4789496903778405

Epoch: 5| Step: 10
Training loss: 0.045510582625865936
Validation loss: 1.4865453614983508

Epoch: 647| Step: 0
Training loss: 0.05726047605276108
Validation loss: 1.4948018186835832

Epoch: 5| Step: 1
Training loss: 0.06312393397092819
Validation loss: 1.464268143459033

Epoch: 5| Step: 2
Training loss: 0.052649032324552536
Validation loss: 1.4521666214030275

Epoch: 5| Step: 3
Training loss: 0.061731159687042236
Validation loss: 1.4703204413895965

Epoch: 5| Step: 4
Training loss: 0.04782731086015701
Validation loss: 1.4464193826080651

Epoch: 5| Step: 5
Training loss: 0.06495340168476105
Validation loss: 1.427834129461678

Epoch: 5| Step: 6
Training loss: 0.05030151456594467
Validation loss: 1.4601829526244954

Epoch: 5| Step: 7
Training loss: 0.0535396933555603
Validation loss: 1.466092267984985

Epoch: 5| Step: 8
Training loss: 0.06422153860330582
Validation loss: 1.463998975933239

Epoch: 5| Step: 9
Training loss: 0.05332787707448006
Validation loss: 1.4698014400338615

Epoch: 5| Step: 10
Training loss: 0.047614216804504395
Validation loss: 1.4602239426746164

Epoch: 648| Step: 0
Training loss: 0.0743040218949318
Validation loss: 1.496534211661226

Epoch: 5| Step: 1
Training loss: 0.07838799804449081
Validation loss: 1.5078473770490257

Epoch: 5| Step: 2
Training loss: 0.05098864436149597
Validation loss: 1.494118284153682

Epoch: 5| Step: 3
Training loss: 0.057260047644376755
Validation loss: 1.49905994502447

Epoch: 5| Step: 4
Training loss: 0.055029820650815964
Validation loss: 1.4806277187921668

Epoch: 5| Step: 5
Training loss: 0.05431848019361496
Validation loss: 1.4837257855681962

Epoch: 5| Step: 6
Training loss: 0.05110246688127518
Validation loss: 1.4777207714255138

Epoch: 5| Step: 7
Training loss: 0.04828847944736481
Validation loss: 1.4776112905112646

Epoch: 5| Step: 8
Training loss: 0.0405331626534462
Validation loss: 1.4867466483064877

Epoch: 5| Step: 9
Training loss: 0.04658813402056694
Validation loss: 1.473549505715729

Epoch: 5| Step: 10
Training loss: 0.03720328211784363
Validation loss: 1.4913575521079443

Epoch: 649| Step: 0
Training loss: 0.06409524381160736
Validation loss: 1.4871647966805326

Epoch: 5| Step: 1
Training loss: 0.07446245104074478
Validation loss: 1.4968997739976453

Epoch: 5| Step: 2
Training loss: 0.08826608955860138
Validation loss: 1.5038671903712775

Epoch: 5| Step: 3
Training loss: 0.055031467229127884
Validation loss: 1.5062024772808116

Epoch: 5| Step: 4
Training loss: 0.07391449064016342
Validation loss: 1.4668643269487607

Epoch: 5| Step: 5
Training loss: 0.05502203106880188
Validation loss: 1.4658597310384114

Epoch: 5| Step: 6
Training loss: 0.06168607622385025
Validation loss: 1.461543458764271

Epoch: 5| Step: 7
Training loss: 0.05179457738995552
Validation loss: 1.4594715282481203

Epoch: 5| Step: 8
Training loss: 0.0907890647649765
Validation loss: 1.4481779862475652

Epoch: 5| Step: 9
Training loss: 0.06389214843511581
Validation loss: 1.4382376401655135

Epoch: 5| Step: 10
Training loss: 0.04484955966472626
Validation loss: 1.4437609385418635

Epoch: 650| Step: 0
Training loss: 0.045622337609529495
Validation loss: 1.4394195143894484

Epoch: 5| Step: 1
Training loss: 0.05492033809423447
Validation loss: 1.4539029264962802

Epoch: 5| Step: 2
Training loss: 0.06753025949001312
Validation loss: 1.4683081437182683

Epoch: 5| Step: 3
Training loss: 0.05452524498105049
Validation loss: 1.4440499928689772

Epoch: 5| Step: 4
Training loss: 0.04276787489652634
Validation loss: 1.4627909045065604

Epoch: 5| Step: 5
Training loss: 0.045853544026613235
Validation loss: 1.4687688703178077

Epoch: 5| Step: 6
Training loss: 0.06867291033267975
Validation loss: 1.4734486892659178

Epoch: 5| Step: 7
Training loss: 0.03392397612333298
Validation loss: 1.4726300829200334

Epoch: 5| Step: 8
Training loss: 0.08716212213039398
Validation loss: 1.4889857615194013

Epoch: 5| Step: 9
Training loss: 0.052319467067718506
Validation loss: 1.4586432621043215

Epoch: 5| Step: 10
Training loss: 0.04423138499259949
Validation loss: 1.490577861826907

Testing loss: 2.0294684569040933
