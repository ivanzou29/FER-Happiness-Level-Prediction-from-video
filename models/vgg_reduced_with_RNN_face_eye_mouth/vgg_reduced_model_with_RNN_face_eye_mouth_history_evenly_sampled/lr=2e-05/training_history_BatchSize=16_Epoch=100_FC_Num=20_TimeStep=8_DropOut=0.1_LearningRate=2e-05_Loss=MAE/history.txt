Epoch: 1| Step: 0
Training loss: 5.499058246612549
Validation loss: 5.173556225274199

Epoch: 6| Step: 1
Training loss: 5.091372489929199
Validation loss: 5.152686688207811

Epoch: 6| Step: 2
Training loss: 5.009634971618652
Validation loss: 5.134599936905728

Epoch: 6| Step: 3
Training loss: 4.722861289978027
Validation loss: 5.114558819801577

Epoch: 6| Step: 4
Training loss: 3.8413894176483154
Validation loss: 5.091801627989738

Epoch: 6| Step: 5
Training loss: 5.089881896972656
Validation loss: 5.066022944706742

Epoch: 6| Step: 6
Training loss: 4.755207061767578
Validation loss: 5.03681077752062

Epoch: 6| Step: 7
Training loss: 4.2994914054870605
Validation loss: 5.003992316543415

Epoch: 6| Step: 8
Training loss: 5.691562175750732
Validation loss: 4.96703040728005

Epoch: 6| Step: 9
Training loss: 4.056114673614502
Validation loss: 4.924867912005353

Epoch: 6| Step: 10
Training loss: 4.598637580871582
Validation loss: 4.879327594593007

Epoch: 6| Step: 11
Training loss: 4.8966779708862305
Validation loss: 4.827833585841681

Epoch: 6| Step: 12
Training loss: 4.777856826782227
Validation loss: 4.771768369982319

Epoch: 6| Step: 13
Training loss: 4.749300956726074
Validation loss: 4.710770658267442

Epoch: 2| Step: 0
Training loss: 4.996034622192383
Validation loss: 4.647662613981513

Epoch: 6| Step: 1
Training loss: 5.464082717895508
Validation loss: 4.583715900298087

Epoch: 6| Step: 2
Training loss: 4.567410469055176
Validation loss: 4.5196743114020235

Epoch: 6| Step: 3
Training loss: 4.350055694580078
Validation loss: 4.455591022327382

Epoch: 6| Step: 4
Training loss: 3.9210259914398193
Validation loss: 4.397098884787611

Epoch: 6| Step: 5
Training loss: 3.9660656452178955
Validation loss: 4.3413790477219445

Epoch: 6| Step: 6
Training loss: 4.0980730056762695
Validation loss: 4.286479816641859

Epoch: 6| Step: 7
Training loss: 3.2545080184936523
Validation loss: 4.2357080495485695

Epoch: 6| Step: 8
Training loss: 3.2104992866516113
Validation loss: 4.187002402479931

Epoch: 6| Step: 9
Training loss: 4.8767194747924805
Validation loss: 4.144269240799771

Epoch: 6| Step: 10
Training loss: 3.4098105430603027
Validation loss: 4.101038648236182

Epoch: 6| Step: 11
Training loss: 4.577406883239746
Validation loss: 4.053996280957294

Epoch: 6| Step: 12
Training loss: 3.5652108192443848
Validation loss: 4.004850628555462

Epoch: 6| Step: 13
Training loss: 2.7805087566375732
Validation loss: 3.967458281465756

Epoch: 3| Step: 0
Training loss: 3.183745861053467
Validation loss: 3.9360871622639317

Epoch: 6| Step: 1
Training loss: 3.8077869415283203
Validation loss: 3.9024457931518555

Epoch: 6| Step: 2
Training loss: 3.9369864463806152
Validation loss: 3.8697519584368636

Epoch: 6| Step: 3
Training loss: 3.0832712650299072
Validation loss: 3.836846956642725

Epoch: 6| Step: 4
Training loss: 4.274914741516113
Validation loss: 3.81035122307398

Epoch: 6| Step: 5
Training loss: 2.7501943111419678
Validation loss: 3.7820629919728925

Epoch: 6| Step: 6
Training loss: 3.2658355236053467
Validation loss: 3.7603114292185795

Epoch: 6| Step: 7
Training loss: 3.972402572631836
Validation loss: 3.7393442123166976

Epoch: 6| Step: 8
Training loss: 4.363785743713379
Validation loss: 3.716792352737919

Epoch: 6| Step: 9
Training loss: 3.9094717502593994
Validation loss: 3.6948024534410044

Epoch: 6| Step: 10
Training loss: 4.19923210144043
Validation loss: 3.6706244509707213

Epoch: 6| Step: 11
Training loss: 2.8919737339019775
Validation loss: 3.648214776028869

Epoch: 6| Step: 12
Training loss: 3.619677782058716
Validation loss: 3.625247424648654

Epoch: 6| Step: 13
Training loss: 3.9656083583831787
Validation loss: 3.5952382190253145

Epoch: 4| Step: 0
Training loss: 3.8251192569732666
Validation loss: 3.569836596006988

Epoch: 6| Step: 1
Training loss: 4.137913703918457
Validation loss: 3.5435679830530638

Epoch: 6| Step: 2
Training loss: 3.4686203002929688
Validation loss: 3.5125601548020557

Epoch: 6| Step: 3
Training loss: 2.8659324645996094
Validation loss: 3.4902264994959675

Epoch: 6| Step: 4
Training loss: 2.5435099601745605
Validation loss: 3.4681386588722147

Epoch: 6| Step: 5
Training loss: 2.286806344985962
Validation loss: 3.446527732315884

Epoch: 6| Step: 6
Training loss: 4.332744121551514
Validation loss: 3.423640658778529

Epoch: 6| Step: 7
Training loss: 3.597163200378418
Validation loss: 3.4039671985051965

Epoch: 6| Step: 8
Training loss: 3.289031505584717
Validation loss: 3.3907673769099738

Epoch: 6| Step: 9
Training loss: 4.2138590812683105
Validation loss: 3.3765504001289286

Epoch: 6| Step: 10
Training loss: 2.809753179550171
Validation loss: 3.358606243646273

Epoch: 6| Step: 11
Training loss: 2.8204376697540283
Validation loss: 3.3407486254169094

Epoch: 6| Step: 12
Training loss: 3.6406309604644775
Validation loss: 3.322985972127607

Epoch: 6| Step: 13
Training loss: 3.3191676139831543
Validation loss: 3.3027817459516626

Epoch: 5| Step: 0
Training loss: 2.516508102416992
Validation loss: 3.2839996455818095

Epoch: 6| Step: 1
Training loss: 3.7239341735839844
Validation loss: 3.268483038871519

Epoch: 6| Step: 2
Training loss: 2.7477989196777344
Validation loss: 3.25356379888391

Epoch: 6| Step: 3
Training loss: 3.3983800411224365
Validation loss: 3.2381242013746694

Epoch: 6| Step: 4
Training loss: 3.2007949352264404
Validation loss: 3.226990120385283

Epoch: 6| Step: 5
Training loss: 2.8215432167053223
Validation loss: 3.211530803352274

Epoch: 6| Step: 6
Training loss: 3.3051252365112305
Validation loss: 3.2024334605022142

Epoch: 6| Step: 7
Training loss: 3.158771514892578
Validation loss: 3.1913301329458914

Epoch: 6| Step: 8
Training loss: 2.6986255645751953
Validation loss: 3.182992899289695

Epoch: 6| Step: 9
Training loss: 3.8101258277893066
Validation loss: 3.172937298333773

Epoch: 6| Step: 10
Training loss: 2.891446590423584
Validation loss: 3.161318414954729

Epoch: 6| Step: 11
Training loss: 3.6892240047454834
Validation loss: 3.1522079385736936

Epoch: 6| Step: 12
Training loss: 3.5392913818359375
Validation loss: 3.143236014150804

Epoch: 6| Step: 13
Training loss: 3.4008383750915527
Validation loss: 3.141378007909303

Epoch: 6| Step: 0
Training loss: 2.997781753540039
Validation loss: 3.128599715489213

Epoch: 6| Step: 1
Training loss: 2.8802013397216797
Validation loss: 3.1187508798414663

Epoch: 6| Step: 2
Training loss: 3.4221129417419434
Validation loss: 3.1094889922808577

Epoch: 6| Step: 3
Training loss: 3.363640546798706
Validation loss: 3.101668570631294

Epoch: 6| Step: 4
Training loss: 3.683029890060425
Validation loss: 3.0930520642188286

Epoch: 6| Step: 5
Training loss: 4.02559232711792
Validation loss: 3.087183044802758

Epoch: 6| Step: 6
Training loss: 4.19445276260376
Validation loss: 3.080026565059539

Epoch: 6| Step: 7
Training loss: 2.9347498416900635
Validation loss: 3.0728357914955384

Epoch: 6| Step: 8
Training loss: 1.938317894935608
Validation loss: 3.065884574767082

Epoch: 6| Step: 9
Training loss: 3.130129814147949
Validation loss: 3.0637938873742216

Epoch: 6| Step: 10
Training loss: 2.7520856857299805
Validation loss: 3.0527728655005015

Epoch: 6| Step: 11
Training loss: 2.9035418033599854
Validation loss: 3.077149739829443

Epoch: 6| Step: 12
Training loss: 2.6241183280944824
Validation loss: 3.0395878643117924

Epoch: 6| Step: 13
Training loss: 2.6637654304504395
Validation loss: 3.0379192316403953

Epoch: 7| Step: 0
Training loss: 3.1263811588287354
Validation loss: 3.039148981853198

Epoch: 6| Step: 1
Training loss: 2.5225489139556885
Validation loss: 3.0275771694798626

Epoch: 6| Step: 2
Training loss: 2.801760196685791
Validation loss: 3.0190772600071405

Epoch: 6| Step: 3
Training loss: 3.3373842239379883
Validation loss: 3.0147077447624615

Epoch: 6| Step: 4
Training loss: 2.921111822128296
Validation loss: 3.0113458171967538

Epoch: 6| Step: 5
Training loss: 2.935035467147827
Validation loss: 3.005707149864525

Epoch: 6| Step: 6
Training loss: 2.725494861602783
Validation loss: 3.0074021252252723

Epoch: 6| Step: 7
Training loss: 2.94919753074646
Validation loss: 3.032417904946112

Epoch: 6| Step: 8
Training loss: 2.9445457458496094
Validation loss: 2.9861050395555395

Epoch: 6| Step: 9
Training loss: 3.7589447498321533
Validation loss: 3.0393616999349287

Epoch: 6| Step: 10
Training loss: 3.2224857807159424
Validation loss: 3.0280588262824604

Epoch: 6| Step: 11
Training loss: 3.808948516845703
Validation loss: 2.9878562522190872

Epoch: 6| Step: 12
Training loss: 2.867252826690674
Validation loss: 2.977086833728257

Epoch: 6| Step: 13
Training loss: 3.216214895248413
Validation loss: 2.9811082937384166

Epoch: 8| Step: 0
Training loss: 3.353029489517212
Validation loss: 3.001655552976875

Epoch: 6| Step: 1
Training loss: 3.4074625968933105
Validation loss: 3.0060634356673046

Epoch: 6| Step: 2
Training loss: 3.3810009956359863
Validation loss: 3.0016685096166467

Epoch: 6| Step: 3
Training loss: 2.6963346004486084
Validation loss: 2.966621280998312

Epoch: 6| Step: 4
Training loss: 3.50467586517334
Validation loss: 2.9414747991869525

Epoch: 6| Step: 5
Training loss: 3.180572032928467
Validation loss: 2.932851327362881

Epoch: 6| Step: 6
Training loss: 2.600236415863037
Validation loss: 2.9263602636193715

Epoch: 6| Step: 7
Training loss: 3.4726946353912354
Validation loss: 2.9282321340294293

Epoch: 6| Step: 8
Training loss: 2.5585341453552246
Validation loss: 2.93379073245551

Epoch: 6| Step: 9
Training loss: 3.0014476776123047
Validation loss: 2.933781095730361

Epoch: 6| Step: 10
Training loss: 3.1473870277404785
Validation loss: 2.912524853983233

Epoch: 6| Step: 11
Training loss: 2.566056728363037
Validation loss: 2.8918819658217894

Epoch: 6| Step: 12
Training loss: 2.877471923828125
Validation loss: 2.8831165657248548

Epoch: 6| Step: 13
Training loss: 2.336509943008423
Validation loss: 2.8777784480843493

Epoch: 9| Step: 0
Training loss: 2.9967448711395264
Validation loss: 2.880570985937631

Epoch: 6| Step: 1
Training loss: 2.9579715728759766
Validation loss: 2.88054887453715

Epoch: 6| Step: 2
Training loss: 3.444082021713257
Validation loss: 2.8796974253910843

Epoch: 6| Step: 3
Training loss: 3.4484879970550537
Validation loss: 2.873925224427254

Epoch: 6| Step: 4
Training loss: 2.72015118598938
Validation loss: 2.8650649157903527

Epoch: 6| Step: 5
Training loss: 3.1762568950653076
Validation loss: 2.855485413664131

Epoch: 6| Step: 6
Training loss: 2.838467597961426
Validation loss: 2.8462706560729654

Epoch: 6| Step: 7
Training loss: 2.3810009956359863
Validation loss: 2.8409507069536435

Epoch: 6| Step: 8
Training loss: 2.794823169708252
Validation loss: 2.8372950682076077

Epoch: 6| Step: 9
Training loss: 2.5214061737060547
Validation loss: 2.8369503226331485

Epoch: 6| Step: 10
Training loss: 3.737813949584961
Validation loss: 2.836426055559548

Epoch: 6| Step: 11
Training loss: 2.896331787109375
Validation loss: 2.829213188540551

Epoch: 6| Step: 12
Training loss: 2.5251283645629883
Validation loss: 2.8204808670987367

Epoch: 6| Step: 13
Training loss: 3.184678792953491
Validation loss: 2.8117977701207644

Epoch: 10| Step: 0
Training loss: 3.177246570587158
Validation loss: 2.8081770943057154

Epoch: 6| Step: 1
Training loss: 3.3242716789245605
Validation loss: 2.8036295239643385

Epoch: 6| Step: 2
Training loss: 2.3039379119873047
Validation loss: 2.8011952882171958

Epoch: 6| Step: 3
Training loss: 2.5336694717407227
Validation loss: 2.798796089746619

Epoch: 6| Step: 4
Training loss: 3.141977071762085
Validation loss: 2.7977411362432663

Epoch: 6| Step: 5
Training loss: 1.974808692932129
Validation loss: 2.789856569741362

Epoch: 6| Step: 6
Training loss: 3.0653743743896484
Validation loss: 2.7848247507567048

Epoch: 6| Step: 7
Training loss: 3.9506113529205322
Validation loss: 2.781090710752754

Epoch: 6| Step: 8
Training loss: 3.056220531463623
Validation loss: 2.77548243922572

Epoch: 6| Step: 9
Training loss: 3.31449818611145
Validation loss: 2.7737113865472938

Epoch: 6| Step: 10
Training loss: 2.3763809204101562
Validation loss: 2.78021575045842

Epoch: 6| Step: 11
Training loss: 3.0844314098358154
Validation loss: 2.786886881756526

Epoch: 6| Step: 12
Training loss: 2.328592300415039
Validation loss: 2.762423635810934

Epoch: 6| Step: 13
Training loss: 3.62455153465271
Validation loss: 2.7604834187415337

Epoch: 11| Step: 0
Training loss: 2.8674774169921875
Validation loss: 2.7629445650244273

Epoch: 6| Step: 1
Training loss: 2.3811230659484863
Validation loss: 2.7608419515753306

Epoch: 6| Step: 2
Training loss: 3.262526512145996
Validation loss: 2.755767140337216

Epoch: 6| Step: 3
Training loss: 2.941514492034912
Validation loss: 2.7520543939323834

Epoch: 6| Step: 4
Training loss: 2.84863543510437
Validation loss: 2.748718043809296

Epoch: 6| Step: 5
Training loss: 2.602433681488037
Validation loss: 2.7496802345398934

Epoch: 6| Step: 6
Training loss: 2.901153087615967
Validation loss: 2.751190359874438

Epoch: 6| Step: 7
Training loss: 3.0183401107788086
Validation loss: 2.7578567792010564

Epoch: 6| Step: 8
Training loss: 4.195034980773926
Validation loss: 2.7428578125533236

Epoch: 6| Step: 9
Training loss: 3.125742197036743
Validation loss: 2.7455805732357885

Epoch: 6| Step: 10
Training loss: 3.2805421352386475
Validation loss: 2.739368082374655

Epoch: 6| Step: 11
Training loss: 1.750462293624878
Validation loss: 2.7301532017287387

Epoch: 6| Step: 12
Training loss: 2.9098124504089355
Validation loss: 2.7308886948452202

Epoch: 6| Step: 13
Training loss: 2.1409337520599365
Validation loss: 2.731096847082979

Epoch: 12| Step: 0
Training loss: 3.432499408721924
Validation loss: 2.7310745844277005

Epoch: 6| Step: 1
Training loss: 3.5182900428771973
Validation loss: 2.7331666177318943

Epoch: 6| Step: 2
Training loss: 2.7352733612060547
Validation loss: 2.725493226000058

Epoch: 6| Step: 3
Training loss: 2.619135856628418
Validation loss: 2.7197593335182435

Epoch: 6| Step: 4
Training loss: 2.258179187774658
Validation loss: 2.7210383722859044

Epoch: 6| Step: 5
Training loss: 2.5027108192443848
Validation loss: 2.7251259562789754

Epoch: 6| Step: 6
Training loss: 2.6544322967529297
Validation loss: 2.7362549228052937

Epoch: 6| Step: 7
Training loss: 2.37259578704834
Validation loss: 2.730858331085533

Epoch: 6| Step: 8
Training loss: 3.2428016662597656
Validation loss: 2.744891387160106

Epoch: 6| Step: 9
Training loss: 3.5285749435424805
Validation loss: 2.7075475210784585

Epoch: 6| Step: 10
Training loss: 2.848834276199341
Validation loss: 2.701415579806092

Epoch: 6| Step: 11
Training loss: 2.923274040222168
Validation loss: 2.7023556078633955

Epoch: 6| Step: 12
Training loss: 2.3767249584198
Validation loss: 2.703003719288816

Epoch: 6| Step: 13
Training loss: 3.647710084915161
Validation loss: 2.6975586119518487

Epoch: 13| Step: 0
Training loss: 3.2661170959472656
Validation loss: 2.740762943862587

Epoch: 6| Step: 1
Training loss: 2.722165107727051
Validation loss: 2.7881714579879597

Epoch: 6| Step: 2
Training loss: 3.3779094219207764
Validation loss: 2.754034580722932

Epoch: 6| Step: 3
Training loss: 3.1187009811401367
Validation loss: 2.7552725961131435

Epoch: 6| Step: 4
Training loss: 3.244101047515869
Validation loss: 2.7675228285533127

Epoch: 6| Step: 5
Training loss: 3.976314067840576
Validation loss: 2.779473307312176

Epoch: 6| Step: 6
Training loss: 2.2138991355895996
Validation loss: 2.7800833512377996

Epoch: 6| Step: 7
Training loss: 2.4513349533081055
Validation loss: 2.774470331848309

Epoch: 6| Step: 8
Training loss: 3.0961501598358154
Validation loss: 2.760811149433095

Epoch: 6| Step: 9
Training loss: 2.7141499519348145
Validation loss: 2.758191716286444

Epoch: 6| Step: 10
Training loss: 2.878333568572998
Validation loss: 2.7518745237781155

Epoch: 6| Step: 11
Training loss: 2.9857163429260254
Validation loss: 2.7439414121771373

Epoch: 6| Step: 12
Training loss: 2.169814109802246
Validation loss: 2.739343261206022

Epoch: 6| Step: 13
Training loss: 2.1309118270874023
Validation loss: 2.73791290098621

Epoch: 14| Step: 0
Training loss: 2.5916287899017334
Validation loss: 2.727966977703956

Epoch: 6| Step: 1
Training loss: 3.4514400959014893
Validation loss: 2.7247871532235095

Epoch: 6| Step: 2
Training loss: 2.7676730155944824
Validation loss: 2.7299314057955177

Epoch: 6| Step: 3
Training loss: 2.837693691253662
Validation loss: 2.7193909768135316

Epoch: 6| Step: 4
Training loss: 2.9030656814575195
Validation loss: 2.7117643484505276

Epoch: 6| Step: 5
Training loss: 2.7574844360351562
Validation loss: 2.708220958709717

Epoch: 6| Step: 6
Training loss: 3.045632839202881
Validation loss: 2.707807940821494

Epoch: 6| Step: 7
Training loss: 2.926579475402832
Validation loss: 2.6984576127862416

Epoch: 6| Step: 8
Training loss: 2.5926437377929688
Validation loss: 2.698590665735224

Epoch: 6| Step: 9
Training loss: 2.527876377105713
Validation loss: 2.689460785158219

Epoch: 6| Step: 10
Training loss: 2.6228814125061035
Validation loss: 2.6715400859873784

Epoch: 6| Step: 11
Training loss: 2.7427978515625
Validation loss: 2.663735892183037

Epoch: 6| Step: 12
Training loss: 2.779773712158203
Validation loss: 2.6527399478420133

Epoch: 6| Step: 13
Training loss: 4.05590295791626
Validation loss: 2.6514981921001146

Epoch: 15| Step: 0
Training loss: 2.4409914016723633
Validation loss: 2.6676828271599224

Epoch: 6| Step: 1
Training loss: 3.4739668369293213
Validation loss: 2.6682717620685534

Epoch: 6| Step: 2
Training loss: 2.7325336933135986
Validation loss: 2.6459795480133383

Epoch: 6| Step: 3
Training loss: 2.6449522972106934
Validation loss: 2.628607439738448

Epoch: 6| Step: 4
Training loss: 2.7047250270843506
Validation loss: 2.6196076408509286

Epoch: 6| Step: 5
Training loss: 4.116778373718262
Validation loss: 2.6171375333621936

Epoch: 6| Step: 6
Training loss: 2.616950273513794
Validation loss: 2.609128905880836

Epoch: 6| Step: 7
Training loss: 2.997802734375
Validation loss: 2.6118841555810746

Epoch: 6| Step: 8
Training loss: 2.695547580718994
Validation loss: 2.6277039384329193

Epoch: 6| Step: 9
Training loss: 2.210371732711792
Validation loss: 2.6178798419173046

Epoch: 6| Step: 10
Training loss: 2.65472412109375
Validation loss: 2.6098600754173855

Epoch: 6| Step: 11
Training loss: 2.806959390640259
Validation loss: 2.5938312122898717

Epoch: 6| Step: 12
Training loss: 2.6701974868774414
Validation loss: 2.5937758402157853

Epoch: 6| Step: 13
Training loss: 2.4670042991638184
Validation loss: 2.5838418288897445

Epoch: 16| Step: 0
Training loss: 3.052800178527832
Validation loss: 2.586243583310035

Epoch: 6| Step: 1
Training loss: 3.287318229675293
Validation loss: 2.582197020130773

Epoch: 6| Step: 2
Training loss: 2.674935817718506
Validation loss: 2.5846265285245833

Epoch: 6| Step: 3
Training loss: 2.5931267738342285
Validation loss: 2.5778728941435456

Epoch: 6| Step: 4
Training loss: 2.4572360515594482
Validation loss: 2.578963774506764

Epoch: 6| Step: 5
Training loss: 2.0360352993011475
Validation loss: 2.5817287147686048

Epoch: 6| Step: 6
Training loss: 3.5473904609680176
Validation loss: 2.572532538444765

Epoch: 6| Step: 7
Training loss: 2.630622386932373
Validation loss: 2.5726380989115727

Epoch: 6| Step: 8
Training loss: 2.4958744049072266
Validation loss: 2.571308530786986

Epoch: 6| Step: 9
Training loss: 2.967313766479492
Validation loss: 2.582842129533009

Epoch: 6| Step: 10
Training loss: 2.6373956203460693
Validation loss: 2.604468096968948

Epoch: 6| Step: 11
Training loss: 3.2716264724731445
Validation loss: 2.638788733431088

Epoch: 6| Step: 12
Training loss: 2.7833614349365234
Validation loss: 2.6171326585995254

Epoch: 6| Step: 13
Training loss: 2.122987747192383
Validation loss: 2.5712387177252

Epoch: 17| Step: 0
Training loss: 3.3507890701293945
Validation loss: 2.585031883690947

Epoch: 6| Step: 1
Training loss: 3.5727953910827637
Validation loss: 2.613112844446654

Epoch: 6| Step: 2
Training loss: 2.6550216674804688
Validation loss: 2.612928259757257

Epoch: 6| Step: 3
Training loss: 2.6981022357940674
Validation loss: 2.565228887783584

Epoch: 6| Step: 4
Training loss: 3.433894634246826
Validation loss: 2.559255423084382

Epoch: 6| Step: 5
Training loss: 2.6746134757995605
Validation loss: 2.576893857730332

Epoch: 6| Step: 6
Training loss: 2.740084648132324
Validation loss: 2.5858129019378335

Epoch: 6| Step: 7
Training loss: 2.6274914741516113
Validation loss: 2.57909240517565

Epoch: 6| Step: 8
Training loss: 2.375992774963379
Validation loss: 2.5709855479578816

Epoch: 6| Step: 9
Training loss: 2.3319289684295654
Validation loss: 2.5635751960098103

Epoch: 6| Step: 10
Training loss: 2.9755797386169434
Validation loss: 2.56444812333712

Epoch: 6| Step: 11
Training loss: 2.404541015625
Validation loss: 2.56009336697158

Epoch: 6| Step: 12
Training loss: 2.4225802421569824
Validation loss: 2.625500573906847

Epoch: 6| Step: 13
Training loss: 2.312203884124756
Validation loss: 2.7326108845331336

Epoch: 18| Step: 0
Training loss: 2.127264976501465
Validation loss: 2.7740153112719135

Epoch: 6| Step: 1
Training loss: 2.3515820503234863
Validation loss: 2.8369315465291343

Epoch: 6| Step: 2
Training loss: 2.825376033782959
Validation loss: 2.867310990569412

Epoch: 6| Step: 3
Training loss: 4.053292751312256
Validation loss: 2.840729964676724

Epoch: 6| Step: 4
Training loss: 2.6412761211395264
Validation loss: 2.7723239467990015

Epoch: 6| Step: 5
Training loss: 3.030348300933838
Validation loss: 2.755242104171425

Epoch: 6| Step: 6
Training loss: 3.332036018371582
Validation loss: 2.691751123756491

Epoch: 6| Step: 7
Training loss: 2.723806381225586
Validation loss: 2.666405044576173

Epoch: 6| Step: 8
Training loss: 2.7423884868621826
Validation loss: 2.706701683741744

Epoch: 6| Step: 9
Training loss: 2.74714994430542
Validation loss: 2.719064361305647

Epoch: 6| Step: 10
Training loss: 2.4030396938323975
Validation loss: 2.6617659420095463

Epoch: 6| Step: 11
Training loss: 3.260713577270508
Validation loss: 2.6417494743101058

Epoch: 6| Step: 12
Training loss: 3.170921802520752
Validation loss: 2.665720485871838

Epoch: 6| Step: 13
Training loss: 2.6517114639282227
Validation loss: 2.707474826484598

Epoch: 19| Step: 0
Training loss: 2.613786220550537
Validation loss: 2.7981855305292274

Epoch: 6| Step: 1
Training loss: 3.1562445163726807
Validation loss: 2.8699629281156804

Epoch: 6| Step: 2
Training loss: 1.651036262512207
Validation loss: 2.8830100156927623

Epoch: 6| Step: 3
Training loss: 3.5575380325317383
Validation loss: 2.7839670501729494

Epoch: 6| Step: 4
Training loss: 2.3987607955932617
Validation loss: 2.6538348505573888

Epoch: 6| Step: 5
Training loss: 2.6372227668762207
Validation loss: 2.614350270199519

Epoch: 6| Step: 6
Training loss: 3.06893253326416
Validation loss: 2.622890172466155

Epoch: 6| Step: 7
Training loss: 2.827406883239746
Validation loss: 2.6541342120016775

Epoch: 6| Step: 8
Training loss: 2.8835554122924805
Validation loss: 2.6352779557628017

Epoch: 6| Step: 9
Training loss: 3.1281187534332275
Validation loss: 2.620935183699413

Epoch: 6| Step: 10
Training loss: 3.1550469398498535
Validation loss: 2.5827192747464744

Epoch: 6| Step: 11
Training loss: 3.140202045440674
Validation loss: 2.562247036605753

Epoch: 6| Step: 12
Training loss: 2.788912057876587
Validation loss: 2.558565516625681

Epoch: 6| Step: 13
Training loss: 2.5050125122070312
Validation loss: 2.560975536223381

Epoch: 20| Step: 0
Training loss: 2.748077630996704
Validation loss: 2.5608651714940227

Epoch: 6| Step: 1
Training loss: 3.1848526000976562
Validation loss: 2.5594882272904917

Epoch: 6| Step: 2
Training loss: 2.609731435775757
Validation loss: 2.5590697616659184

Epoch: 6| Step: 3
Training loss: 2.3557047843933105
Validation loss: 2.5407942546311246

Epoch: 6| Step: 4
Training loss: 3.0392956733703613
Validation loss: 2.519530145070886

Epoch: 6| Step: 5
Training loss: 3.5845303535461426
Validation loss: 2.5105653244961976

Epoch: 6| Step: 6
Training loss: 3.117182731628418
Validation loss: 2.5039203833508235

Epoch: 6| Step: 7
Training loss: 3.141545057296753
Validation loss: 2.5038180607621388

Epoch: 6| Step: 8
Training loss: 3.099524974822998
Validation loss: 2.5030177049739386

Epoch: 6| Step: 9
Training loss: 2.0173587799072266
Validation loss: 2.5140374988637944

Epoch: 6| Step: 10
Training loss: 3.1088953018188477
Validation loss: 2.5192293556787635

Epoch: 6| Step: 11
Training loss: 1.67843759059906
Validation loss: 2.512779966477425

Epoch: 6| Step: 12
Training loss: 2.3058652877807617
Validation loss: 2.5069199608218287

Epoch: 6| Step: 13
Training loss: 2.5598843097686768
Validation loss: 2.498671862386888

Epoch: 21| Step: 0
Training loss: 3.357557773590088
Validation loss: 2.4957695596961567

Epoch: 6| Step: 1
Training loss: 2.346644401550293
Validation loss: 2.4858666517401256

Epoch: 6| Step: 2
Training loss: 2.538159132003784
Validation loss: 2.498971671186468

Epoch: 6| Step: 3
Training loss: 3.2420759201049805
Validation loss: 2.5266154684046263

Epoch: 6| Step: 4
Training loss: 2.7463178634643555
Validation loss: 2.5117865685493714

Epoch: 6| Step: 5
Training loss: 2.104320526123047
Validation loss: 2.5127327954897316

Epoch: 6| Step: 6
Training loss: 3.0140881538391113
Validation loss: 2.493850656735

Epoch: 6| Step: 7
Training loss: 2.643176555633545
Validation loss: 2.4831224333855415

Epoch: 6| Step: 8
Training loss: 2.228708028793335
Validation loss: 2.485491778260918

Epoch: 6| Step: 9
Training loss: 3.3162574768066406
Validation loss: 2.4907946945518575

Epoch: 6| Step: 10
Training loss: 2.8556463718414307
Validation loss: 2.492248832538564

Epoch: 6| Step: 11
Training loss: 2.9554085731506348
Validation loss: 2.5019955686343613

Epoch: 6| Step: 12
Training loss: 2.2691047191619873
Validation loss: 2.4964540491821947

Epoch: 6| Step: 13
Training loss: 2.4580295085906982
Validation loss: 2.5182761710177184

Epoch: 22| Step: 0
Training loss: 2.5020406246185303
Validation loss: 2.510754992884974

Epoch: 6| Step: 1
Training loss: 2.5211682319641113
Validation loss: 2.5013966380908923

Epoch: 6| Step: 2
Training loss: 3.250657558441162
Validation loss: 2.485506162848524

Epoch: 6| Step: 3
Training loss: 3.446566581726074
Validation loss: 2.475100209636073

Epoch: 6| Step: 4
Training loss: 2.7512171268463135
Validation loss: 2.4709961516882784

Epoch: 6| Step: 5
Training loss: 2.5969741344451904
Validation loss: 2.474683569323632

Epoch: 6| Step: 6
Training loss: 3.2387547492980957
Validation loss: 2.4741303100380847

Epoch: 6| Step: 7
Training loss: 2.5122148990631104
Validation loss: 2.4744257503940212

Epoch: 6| Step: 8
Training loss: 2.5057926177978516
Validation loss: 2.467374978526946

Epoch: 6| Step: 9
Training loss: 2.193777561187744
Validation loss: 2.4699374885969263

Epoch: 6| Step: 10
Training loss: 3.032825469970703
Validation loss: 2.470194785825668

Epoch: 6| Step: 11
Training loss: 3.010481595993042
Validation loss: 2.4694165440015894

Epoch: 6| Step: 12
Training loss: 2.220372438430786
Validation loss: 2.4720856425582722

Epoch: 6| Step: 13
Training loss: 1.6752333641052246
Validation loss: 2.4737490428391324

Epoch: 23| Step: 0
Training loss: 2.2691712379455566
Validation loss: 2.4759474697933403

Epoch: 6| Step: 1
Training loss: 2.2562732696533203
Validation loss: 2.4738407904101956

Epoch: 6| Step: 2
Training loss: 2.6767027378082275
Validation loss: 2.4753070851807952

Epoch: 6| Step: 3
Training loss: 2.3877665996551514
Validation loss: 2.4750383284784134

Epoch: 6| Step: 4
Training loss: 2.722869873046875
Validation loss: 2.4726698962591027

Epoch: 6| Step: 5
Training loss: 2.795167922973633
Validation loss: 2.4662005004062446

Epoch: 6| Step: 6
Training loss: 2.8435111045837402
Validation loss: 2.47167771093307

Epoch: 6| Step: 7
Training loss: 3.0682921409606934
Validation loss: 2.47968227119856

Epoch: 6| Step: 8
Training loss: 3.1181447505950928
Validation loss: 2.5005845869741132

Epoch: 6| Step: 9
Training loss: 3.5740067958831787
Validation loss: 2.49990443260439

Epoch: 6| Step: 10
Training loss: 2.115093946456909
Validation loss: 2.470522816463183

Epoch: 6| Step: 11
Training loss: 2.127744674682617
Validation loss: 2.459986307287729

Epoch: 6| Step: 12
Training loss: 2.539163827896118
Validation loss: 2.4606771443479802

Epoch: 6| Step: 13
Training loss: 3.640692710876465
Validation loss: 2.4558673879151702

Epoch: 24| Step: 0
Training loss: 2.650179386138916
Validation loss: 2.4558329095122633

Epoch: 6| Step: 1
Training loss: 2.5183215141296387
Validation loss: 2.454095948127008

Epoch: 6| Step: 2
Training loss: 2.244255304336548
Validation loss: 2.450777966489074

Epoch: 6| Step: 3
Training loss: 3.2352347373962402
Validation loss: 2.445871030130694

Epoch: 6| Step: 4
Training loss: 2.5386691093444824
Validation loss: 2.4502732420480378

Epoch: 6| Step: 5
Training loss: 2.9033401012420654
Validation loss: 2.4573478237275155

Epoch: 6| Step: 6
Training loss: 2.4627060890197754
Validation loss: 2.4639080339862454

Epoch: 6| Step: 7
Training loss: 2.4443726539611816
Validation loss: 2.4725427422472226

Epoch: 6| Step: 8
Training loss: 2.7467639446258545
Validation loss: 2.4763371611154206

Epoch: 6| Step: 9
Training loss: 2.6576974391937256
Validation loss: 2.4790467703214256

Epoch: 6| Step: 10
Training loss: 2.6284291744232178
Validation loss: 2.4809590488351803

Epoch: 6| Step: 11
Training loss: 3.053260326385498
Validation loss: 2.4874361868827575

Epoch: 6| Step: 12
Training loss: 2.8516554832458496
Validation loss: 2.4913147572548158

Epoch: 6| Step: 13
Training loss: 2.798163890838623
Validation loss: 2.4704395468517015

Epoch: 25| Step: 0
Training loss: 3.333425521850586
Validation loss: 2.4561201577545493

Epoch: 6| Step: 1
Training loss: 2.892219066619873
Validation loss: 2.4607018424618627

Epoch: 6| Step: 2
Training loss: 2.9910101890563965
Validation loss: 2.4595286359069166

Epoch: 6| Step: 3
Training loss: 2.2516531944274902
Validation loss: 2.451802671596568

Epoch: 6| Step: 4
Training loss: 2.193319082260132
Validation loss: 2.4405584284054336

Epoch: 6| Step: 5
Training loss: 2.5700016021728516
Validation loss: 2.4398746336660078

Epoch: 6| Step: 6
Training loss: 2.1471259593963623
Validation loss: 2.4372150897979736

Epoch: 6| Step: 7
Training loss: 2.3371458053588867
Validation loss: 2.4372203003975654

Epoch: 6| Step: 8
Training loss: 3.321808338165283
Validation loss: 2.4400417753445205

Epoch: 6| Step: 9
Training loss: 3.069268226623535
Validation loss: 2.4456776034447456

Epoch: 6| Step: 10
Training loss: 1.7187306880950928
Validation loss: 2.4594682698608725

Epoch: 6| Step: 11
Training loss: 2.5552399158477783
Validation loss: 2.4774990543242423

Epoch: 6| Step: 12
Training loss: 3.730598211288452
Validation loss: 2.5052388227114113

Epoch: 6| Step: 13
Training loss: 2.3992786407470703
Validation loss: 2.497272442745906

Epoch: 26| Step: 0
Training loss: 2.6310982704162598
Validation loss: 2.4607848608365623

Epoch: 6| Step: 1
Training loss: 2.5014114379882812
Validation loss: 2.442595133217432

Epoch: 6| Step: 2
Training loss: 3.003593921661377
Validation loss: 2.4392373023494596

Epoch: 6| Step: 3
Training loss: 2.317885637283325
Validation loss: 2.438600483761039

Epoch: 6| Step: 4
Training loss: 2.8402838706970215
Validation loss: 2.441280493172266

Epoch: 6| Step: 5
Training loss: 2.8081023693084717
Validation loss: 2.444578816813807

Epoch: 6| Step: 6
Training loss: 3.5168566703796387
Validation loss: 2.443649797029393

Epoch: 6| Step: 7
Training loss: 2.588688373565674
Validation loss: 2.4404678344726562

Epoch: 6| Step: 8
Training loss: 2.925732374191284
Validation loss: 2.431370001967235

Epoch: 6| Step: 9
Training loss: 2.165452718734741
Validation loss: 2.432062179811539

Epoch: 6| Step: 10
Training loss: 2.634883165359497
Validation loss: 2.434021152475829

Epoch: 6| Step: 11
Training loss: 2.0943143367767334
Validation loss: 2.4271720429902435

Epoch: 6| Step: 12
Training loss: 2.5072765350341797
Validation loss: 2.4287607669830322

Epoch: 6| Step: 13
Training loss: 3.1651699542999268
Validation loss: 2.4285700269924697

Epoch: 27| Step: 0
Training loss: 2.657498359680176
Validation loss: 2.4296746779513616

Epoch: 6| Step: 1
Training loss: 2.5732171535491943
Validation loss: 2.435785221797164

Epoch: 6| Step: 2
Training loss: 2.841433048248291
Validation loss: 2.4480514962186097

Epoch: 6| Step: 3
Training loss: 3.1601946353912354
Validation loss: 2.466568539219518

Epoch: 6| Step: 4
Training loss: 2.70619797706604
Validation loss: 2.491049446085448

Epoch: 6| Step: 5
Training loss: 2.4356918334960938
Validation loss: 2.5026828294159262

Epoch: 6| Step: 6
Training loss: 2.8142991065979004
Validation loss: 2.486623102618802

Epoch: 6| Step: 7
Training loss: 2.0451607704162598
Validation loss: 2.473787410284883

Epoch: 6| Step: 8
Training loss: 2.7529170513153076
Validation loss: 2.45388993652918

Epoch: 6| Step: 9
Training loss: 2.8340468406677246
Validation loss: 2.443198080985777

Epoch: 6| Step: 10
Training loss: 3.202634334564209
Validation loss: 2.4347357519211306

Epoch: 6| Step: 11
Training loss: 2.4219906330108643
Validation loss: 2.427876824973732

Epoch: 6| Step: 12
Training loss: 1.9840649366378784
Validation loss: 2.421158987988708

Epoch: 6| Step: 13
Training loss: 3.214566230773926
Validation loss: 2.4205177009746595

Epoch: 28| Step: 0
Training loss: 3.6988742351531982
Validation loss: 2.4181317642170894

Epoch: 6| Step: 1
Training loss: 2.6668381690979004
Validation loss: 2.421378876573296

Epoch: 6| Step: 2
Training loss: 3.001370906829834
Validation loss: 2.4116996129353843

Epoch: 6| Step: 3
Training loss: 2.346262216567993
Validation loss: 2.4122209548950195

Epoch: 6| Step: 4
Training loss: 2.1887292861938477
Validation loss: 2.411728766656691

Epoch: 6| Step: 5
Training loss: 2.687533140182495
Validation loss: 2.4106780508513093

Epoch: 6| Step: 6
Training loss: 2.963137149810791
Validation loss: 2.412660409045476

Epoch: 6| Step: 7
Training loss: 2.8385071754455566
Validation loss: 2.4208377663807203

Epoch: 6| Step: 8
Training loss: 3.210908889770508
Validation loss: 2.4218108525840183

Epoch: 6| Step: 9
Training loss: 2.759538173675537
Validation loss: 2.4308928264084684

Epoch: 6| Step: 10
Training loss: 2.122751235961914
Validation loss: 2.4645575887413433

Epoch: 6| Step: 11
Training loss: 1.7783704996109009
Validation loss: 2.4686836324712282

Epoch: 6| Step: 12
Training loss: 2.941905975341797
Validation loss: 2.4581743030137915

Epoch: 6| Step: 13
Training loss: 1.48452889919281
Validation loss: 2.4672232238195275

Epoch: 29| Step: 0
Training loss: 2.80245304107666
Validation loss: 2.4596196195130706

Epoch: 6| Step: 1
Training loss: 2.787998676300049
Validation loss: 2.458461433328608

Epoch: 6| Step: 2
Training loss: 3.306549549102783
Validation loss: 2.434776782989502

Epoch: 6| Step: 3
Training loss: 2.4771976470947266
Validation loss: 2.4202654130997194

Epoch: 6| Step: 4
Training loss: 2.4819633960723877
Validation loss: 2.4140530734933834

Epoch: 6| Step: 5
Training loss: 2.8682851791381836
Validation loss: 2.4114766966912056

Epoch: 6| Step: 6
Training loss: 2.0928587913513184
Validation loss: 2.4070298492267566

Epoch: 6| Step: 7
Training loss: 2.1137092113494873
Validation loss: 2.416956017094274

Epoch: 6| Step: 8
Training loss: 2.9519569873809814
Validation loss: 2.436457849317981

Epoch: 6| Step: 9
Training loss: 2.652776002883911
Validation loss: 2.437505570791101

Epoch: 6| Step: 10
Training loss: 2.124351739883423
Validation loss: 2.448319594065348

Epoch: 6| Step: 11
Training loss: 2.8057894706726074
Validation loss: 2.464266138692056

Epoch: 6| Step: 12
Training loss: 2.908146381378174
Validation loss: 2.493099767674682

Epoch: 6| Step: 13
Training loss: 2.8906612396240234
Validation loss: 2.4593311714869674

Epoch: 30| Step: 0
Training loss: 3.3628482818603516
Validation loss: 2.425268070672148

Epoch: 6| Step: 1
Training loss: 2.829371452331543
Validation loss: 2.4035608204462195

Epoch: 6| Step: 2
Training loss: 2.9239096641540527
Validation loss: 2.3939261436462402

Epoch: 6| Step: 3
Training loss: 2.4006872177124023
Validation loss: 2.396323788550592

Epoch: 6| Step: 4
Training loss: 2.512298583984375
Validation loss: 2.399244054671257

Epoch: 6| Step: 5
Training loss: 2.206946849822998
Validation loss: 2.4045032224347516

Epoch: 6| Step: 6
Training loss: 2.521949291229248
Validation loss: 2.412820754512664

Epoch: 6| Step: 7
Training loss: 2.533909320831299
Validation loss: 2.4100285755690707

Epoch: 6| Step: 8
Training loss: 2.358971357345581
Validation loss: 2.425113426741733

Epoch: 6| Step: 9
Training loss: 2.3118324279785156
Validation loss: 2.4156344090738604

Epoch: 6| Step: 10
Training loss: 2.7775461673736572
Validation loss: 2.421453905361955

Epoch: 6| Step: 11
Training loss: 2.7616167068481445
Validation loss: 2.422332791871922

Epoch: 6| Step: 12
Training loss: 3.0518651008605957
Validation loss: 2.4145417110894316

Epoch: 6| Step: 13
Training loss: 2.5059709548950195
Validation loss: 2.406825283522247

Epoch: 31| Step: 0
Training loss: 2.780862331390381
Validation loss: 2.398461216239519

Epoch: 6| Step: 1
Training loss: 2.2958755493164062
Validation loss: 2.3926646427441667

Epoch: 6| Step: 2
Training loss: 2.6008381843566895
Validation loss: 2.399913731441703

Epoch: 6| Step: 3
Training loss: 2.659416675567627
Validation loss: 2.3957856342356694

Epoch: 6| Step: 4
Training loss: 2.703061580657959
Validation loss: 2.3944036524782897

Epoch: 6| Step: 5
Training loss: 2.278437614440918
Validation loss: 2.3889788735297417

Epoch: 6| Step: 6
Training loss: 2.3656373023986816
Validation loss: 2.393529038275442

Epoch: 6| Step: 7
Training loss: 2.3509325981140137
Validation loss: 2.3835631826872468

Epoch: 6| Step: 8
Training loss: 3.086989402770996
Validation loss: 2.38401989013918

Epoch: 6| Step: 9
Training loss: 3.018901824951172
Validation loss: 2.3790033863436792

Epoch: 6| Step: 10
Training loss: 2.456857681274414
Validation loss: 2.3777090426414245

Epoch: 6| Step: 11
Training loss: 3.105231761932373
Validation loss: 2.3844803943428943

Epoch: 6| Step: 12
Training loss: 2.579423427581787
Validation loss: 2.3862525442595124

Epoch: 6| Step: 13
Training loss: 2.809445381164551
Validation loss: 2.377550478904478

Epoch: 32| Step: 0
Training loss: 2.989201068878174
Validation loss: 2.3811981883100284

Epoch: 6| Step: 1
Training loss: 3.726501703262329
Validation loss: 2.378536640956838

Epoch: 6| Step: 2
Training loss: 2.8415331840515137
Validation loss: 2.37934894715586

Epoch: 6| Step: 3
Training loss: 3.0298736095428467
Validation loss: 2.376999734550394

Epoch: 6| Step: 4
Training loss: 2.9236514568328857
Validation loss: 2.3763378615020425

Epoch: 6| Step: 5
Training loss: 2.4592783451080322
Validation loss: 2.3902186065591793

Epoch: 6| Step: 6
Training loss: 2.1095407009124756
Validation loss: 2.409248008522936

Epoch: 6| Step: 7
Training loss: 2.544684410095215
Validation loss: 2.417063977128716

Epoch: 6| Step: 8
Training loss: 2.726264476776123
Validation loss: 2.442082981909475

Epoch: 6| Step: 9
Training loss: 2.4937527179718018
Validation loss: 2.488644802442161

Epoch: 6| Step: 10
Training loss: 2.048412322998047
Validation loss: 2.4639318578986713

Epoch: 6| Step: 11
Training loss: 2.205493450164795
Validation loss: 2.4088226313232095

Epoch: 6| Step: 12
Training loss: 2.4896905422210693
Validation loss: 2.3927399445605535

Epoch: 6| Step: 13
Training loss: 2.094947338104248
Validation loss: 2.3843602954700427

Epoch: 33| Step: 0
Training loss: 2.0510497093200684
Validation loss: 2.3730765645222

Epoch: 6| Step: 1
Training loss: 2.105280876159668
Validation loss: 2.3708764301833285

Epoch: 6| Step: 2
Training loss: 2.0269010066986084
Validation loss: 2.370445233519359

Epoch: 6| Step: 3
Training loss: 2.353396415710449
Validation loss: 2.364188401929794

Epoch: 6| Step: 4
Training loss: 2.8990941047668457
Validation loss: 2.366371621367752

Epoch: 6| Step: 5
Training loss: 2.4512863159179688
Validation loss: 2.3667606358887046

Epoch: 6| Step: 6
Training loss: 2.9297213554382324
Validation loss: 2.371706590857557

Epoch: 6| Step: 7
Training loss: 3.2457892894744873
Validation loss: 2.3720867505637546

Epoch: 6| Step: 8
Training loss: 3.336775779724121
Validation loss: 2.3725648772331978

Epoch: 6| Step: 9
Training loss: 1.9303734302520752
Validation loss: 2.371730558333858

Epoch: 6| Step: 10
Training loss: 3.0961437225341797
Validation loss: 2.37046609258139

Epoch: 6| Step: 11
Training loss: 3.4154226779937744
Validation loss: 2.3650961857970043

Epoch: 6| Step: 12
Training loss: 2.500105381011963
Validation loss: 2.3660379891754477

Epoch: 6| Step: 13
Training loss: 2.512042999267578
Validation loss: 2.3651188214619956

Epoch: 34| Step: 0
Training loss: 2.5490031242370605
Validation loss: 2.3655790257197555

Epoch: 6| Step: 1
Training loss: 2.1448655128479004
Validation loss: 2.367941892275246

Epoch: 6| Step: 2
Training loss: 2.879249334335327
Validation loss: 2.3847916408251693

Epoch: 6| Step: 3
Training loss: 2.676431655883789
Validation loss: 2.419365470127393

Epoch: 6| Step: 4
Training loss: 3.108384132385254
Validation loss: 2.4370679957892305

Epoch: 6| Step: 5
Training loss: 3.237307071685791
Validation loss: 2.4363157056993052

Epoch: 6| Step: 6
Training loss: 2.4419097900390625
Validation loss: 2.421592540638421

Epoch: 6| Step: 7
Training loss: 2.451598882675171
Validation loss: 2.3959953118396062

Epoch: 6| Step: 8
Training loss: 2.157951593399048
Validation loss: 2.3762162603357786

Epoch: 6| Step: 9
Training loss: 2.992079496383667
Validation loss: 2.3602282283126668

Epoch: 6| Step: 10
Training loss: 2.4021425247192383
Validation loss: 2.3548011779785156

Epoch: 6| Step: 11
Training loss: 2.4736621379852295
Validation loss: 2.3648382694490495

Epoch: 6| Step: 12
Training loss: 3.114428758621216
Validation loss: 2.361242048202022

Epoch: 6| Step: 13
Training loss: 2.190291166305542
Validation loss: 2.3570553641165457

Epoch: 35| Step: 0
Training loss: 2.561297655105591
Validation loss: 2.3590139342892553

Epoch: 6| Step: 1
Training loss: 2.673762321472168
Validation loss: 2.353420792087432

Epoch: 6| Step: 2
Training loss: 3.019526481628418
Validation loss: 2.350304444630941

Epoch: 6| Step: 3
Training loss: 3.2024528980255127
Validation loss: 2.3535345062132804

Epoch: 6| Step: 4
Training loss: 1.8923630714416504
Validation loss: 2.357152028750348

Epoch: 6| Step: 5
Training loss: 2.9054436683654785
Validation loss: 2.3644809210172264

Epoch: 6| Step: 6
Training loss: 1.9530386924743652
Validation loss: 2.3816079221745974

Epoch: 6| Step: 7
Training loss: 2.495913505554199
Validation loss: 2.4462849170930925

Epoch: 6| Step: 8
Training loss: 2.41471004486084
Validation loss: 2.509660461897491

Epoch: 6| Step: 9
Training loss: 3.245889663696289
Validation loss: 2.452256892317085

Epoch: 6| Step: 10
Training loss: 2.7702932357788086
Validation loss: 2.3878554938941874

Epoch: 6| Step: 11
Training loss: 2.4684650897979736
Validation loss: 2.3542712888410016

Epoch: 6| Step: 12
Training loss: 2.5828330516815186
Validation loss: 2.3422055090627363

Epoch: 6| Step: 13
Training loss: 2.6810569763183594
Validation loss: 2.3549324902155067

Epoch: 36| Step: 0
Training loss: 2.294766426086426
Validation loss: 2.3766223640852076

Epoch: 6| Step: 1
Training loss: 3.1451005935668945
Validation loss: 2.403764997759173

Epoch: 6| Step: 2
Training loss: 2.6240031719207764
Validation loss: 2.386710571986373

Epoch: 6| Step: 3
Training loss: 2.782437324523926
Validation loss: 2.393434698863696

Epoch: 6| Step: 4
Training loss: 3.1442155838012695
Validation loss: 2.3979586478202575

Epoch: 6| Step: 5
Training loss: 1.7263838052749634
Validation loss: 2.3980039370957242

Epoch: 6| Step: 6
Training loss: 2.2163126468658447
Validation loss: 2.392050676448371

Epoch: 6| Step: 7
Training loss: 4.160666465759277
Validation loss: 2.3781499157669725

Epoch: 6| Step: 8
Training loss: 3.271308183670044
Validation loss: 2.364932660133608

Epoch: 6| Step: 9
Training loss: 2.970710277557373
Validation loss: 2.352547444323058

Epoch: 6| Step: 10
Training loss: 1.7112630605697632
Validation loss: 2.3481437237032

Epoch: 6| Step: 11
Training loss: 1.881949543952942
Validation loss: 2.3616190700120825

Epoch: 6| Step: 12
Training loss: 2.604253053665161
Validation loss: 2.3852679242369947

Epoch: 6| Step: 13
Training loss: 2.519761323928833
Validation loss: 2.4020055763183104

Epoch: 37| Step: 0
Training loss: 3.1653671264648438
Validation loss: 2.4311279225093063

Epoch: 6| Step: 1
Training loss: 3.593412399291992
Validation loss: 2.425640183110391

Epoch: 6| Step: 2
Training loss: 1.9595950841903687
Validation loss: 2.4091535486200804

Epoch: 6| Step: 3
Training loss: 2.5169355869293213
Validation loss: 2.3901809800055718

Epoch: 6| Step: 4
Training loss: 1.8124432563781738
Validation loss: 2.360808005896948

Epoch: 6| Step: 5
Training loss: 2.6694273948669434
Validation loss: 2.3487141491264425

Epoch: 6| Step: 6
Training loss: 1.6707677841186523
Validation loss: 2.3390383053851385

Epoch: 6| Step: 7
Training loss: 2.8361172676086426
Validation loss: 2.3377923298907537

Epoch: 6| Step: 8
Training loss: 3.0332837104797363
Validation loss: 2.3400380278146393

Epoch: 6| Step: 9
Training loss: 2.8628318309783936
Validation loss: 2.343872921441191

Epoch: 6| Step: 10
Training loss: 2.564732789993286
Validation loss: 2.3388796109025196

Epoch: 6| Step: 11
Training loss: 2.4192442893981934
Validation loss: 2.3424528080929994

Epoch: 6| Step: 12
Training loss: 2.822380542755127
Validation loss: 2.3394562813543502

Epoch: 6| Step: 13
Training loss: 3.071352481842041
Validation loss: 2.341770043937109

Epoch: 38| Step: 0
Training loss: 2.4094223976135254
Validation loss: 2.3384673159609557

Epoch: 6| Step: 1
Training loss: 3.462740421295166
Validation loss: 2.3408473332722983

Epoch: 6| Step: 2
Training loss: 2.7809362411499023
Validation loss: 2.3407301672043337

Epoch: 6| Step: 3
Training loss: 2.553046703338623
Validation loss: 2.340615410958567

Epoch: 6| Step: 4
Training loss: 2.515810966491699
Validation loss: 2.3452921503333637

Epoch: 6| Step: 5
Training loss: 2.5261101722717285
Validation loss: 2.3667246757015103

Epoch: 6| Step: 6
Training loss: 2.8369650840759277
Validation loss: 2.360371543515113

Epoch: 6| Step: 7
Training loss: 2.71690034866333
Validation loss: 2.351659615834554

Epoch: 6| Step: 8
Training loss: 2.12176513671875
Validation loss: 2.34541707013243

Epoch: 6| Step: 9
Training loss: 2.366842746734619
Validation loss: 2.3476600852063907

Epoch: 6| Step: 10
Training loss: 2.1299381256103516
Validation loss: 2.3494986385427494

Epoch: 6| Step: 11
Training loss: 2.6950793266296387
Validation loss: 2.352920232280608

Epoch: 6| Step: 12
Training loss: 2.886152505874634
Validation loss: 2.350723115346765

Epoch: 6| Step: 13
Training loss: 2.6605396270751953
Validation loss: 2.3469537791385444

Epoch: 39| Step: 0
Training loss: 2.207932472229004
Validation loss: 2.3454719474238734

Epoch: 6| Step: 1
Training loss: 2.9808437824249268
Validation loss: 2.3376388113985778

Epoch: 6| Step: 2
Training loss: 2.650984287261963
Validation loss: 2.3341621506598687

Epoch: 6| Step: 3
Training loss: 3.010413885116577
Validation loss: 2.3353892987774265

Epoch: 6| Step: 4
Training loss: 2.1247408390045166
Validation loss: 2.3281993789057576

Epoch: 6| Step: 5
Training loss: 2.798124313354492
Validation loss: 2.328694470467106

Epoch: 6| Step: 6
Training loss: 2.520547866821289
Validation loss: 2.3307480735163533

Epoch: 6| Step: 7
Training loss: 1.9055975675582886
Validation loss: 2.32636135496119

Epoch: 6| Step: 8
Training loss: 3.183487892150879
Validation loss: 2.3253458981872885

Epoch: 6| Step: 9
Training loss: 3.2324447631835938
Validation loss: 2.327758204552435

Epoch: 6| Step: 10
Training loss: 2.0137317180633545
Validation loss: 2.325635761343023

Epoch: 6| Step: 11
Training loss: 2.7160110473632812
Validation loss: 2.322489341100057

Epoch: 6| Step: 12
Training loss: 2.792109966278076
Validation loss: 2.3365984373195197

Epoch: 6| Step: 13
Training loss: 2.2211453914642334
Validation loss: 2.353819480506323

Epoch: 40| Step: 0
Training loss: 2.225508689880371
Validation loss: 2.416830039793445

Epoch: 6| Step: 1
Training loss: 2.762629985809326
Validation loss: 2.4559753018040813

Epoch: 6| Step: 2
Training loss: 2.4875359535217285
Validation loss: 2.4334109316590014

Epoch: 6| Step: 3
Training loss: 2.851205825805664
Validation loss: 2.3733668763150453

Epoch: 6| Step: 4
Training loss: 2.632197380065918
Validation loss: 2.3394881550983717

Epoch: 6| Step: 5
Training loss: 2.335172176361084
Validation loss: 2.323602171354396

Epoch: 6| Step: 6
Training loss: 2.6103639602661133
Validation loss: 2.316008788283153

Epoch: 6| Step: 7
Training loss: 3.3557538986206055
Validation loss: 2.3167182245562152

Epoch: 6| Step: 8
Training loss: 2.7968862056732178
Validation loss: 2.3199376265207925

Epoch: 6| Step: 9
Training loss: 3.142453193664551
Validation loss: 2.3263095066111577

Epoch: 6| Step: 10
Training loss: 2.3672831058502197
Validation loss: 2.3420578190075454

Epoch: 6| Step: 11
Training loss: 2.6981289386749268
Validation loss: 2.365156917161839

Epoch: 6| Step: 12
Training loss: 2.8145618438720703
Validation loss: 2.3609280022241736

Epoch: 6| Step: 13
Training loss: 1.4031398296356201
Validation loss: 2.336601711088611

Epoch: 41| Step: 0
Training loss: 1.8999652862548828
Validation loss: 2.324372242855769

Epoch: 6| Step: 1
Training loss: 2.7800774574279785
Validation loss: 2.32204177559063

Epoch: 6| Step: 2
Training loss: 2.58479380607605
Validation loss: 2.3378505194058983

Epoch: 6| Step: 3
Training loss: 2.4903664588928223
Validation loss: 2.356506650165845

Epoch: 6| Step: 4
Training loss: 2.1618528366088867
Validation loss: 2.3680273794358775

Epoch: 6| Step: 5
Training loss: 3.1429572105407715
Validation loss: 2.432882803742604

Epoch: 6| Step: 6
Training loss: 3.077075958251953
Validation loss: 2.477216666744601

Epoch: 6| Step: 7
Training loss: 3.024555206298828
Validation loss: 2.535078207651774

Epoch: 6| Step: 8
Training loss: 2.647695541381836
Validation loss: 2.521891506769324

Epoch: 6| Step: 9
Training loss: 2.788325309753418
Validation loss: 2.4840785072695826

Epoch: 6| Step: 10
Training loss: 2.5698766708374023
Validation loss: 2.421129257448258

Epoch: 6| Step: 11
Training loss: 2.7911455631256104
Validation loss: 2.355650835139777

Epoch: 6| Step: 12
Training loss: 2.622802257537842
Validation loss: 2.3206287994179675

Epoch: 6| Step: 13
Training loss: 1.9295940399169922
Validation loss: 2.3224532911854405

Epoch: 42| Step: 0
Training loss: 3.1360177993774414
Validation loss: 2.3556636610338764

Epoch: 6| Step: 1
Training loss: 2.3936758041381836
Validation loss: 2.3850363531420307

Epoch: 6| Step: 2
Training loss: 3.0721254348754883
Validation loss: 2.4285979194025837

Epoch: 6| Step: 3
Training loss: 2.242530345916748
Validation loss: 2.4308107463262414

Epoch: 6| Step: 4
Training loss: 2.608271598815918
Validation loss: 2.4068033438856884

Epoch: 6| Step: 5
Training loss: 3.0521678924560547
Validation loss: 2.3855892022450766

Epoch: 6| Step: 6
Training loss: 2.9118258953094482
Validation loss: 2.345327259391867

Epoch: 6| Step: 7
Training loss: 2.973010778427124
Validation loss: 2.3249879319180726

Epoch: 6| Step: 8
Training loss: 2.3782598972320557
Validation loss: 2.3233258467848583

Epoch: 6| Step: 9
Training loss: 1.7722058296203613
Validation loss: 2.324326751052692

Epoch: 6| Step: 10
Training loss: 2.763519287109375
Validation loss: 2.3390862634105067

Epoch: 6| Step: 11
Training loss: 2.5362045764923096
Validation loss: 2.3694479824394308

Epoch: 6| Step: 12
Training loss: 1.8432284593582153
Validation loss: 2.3973147587109636

Epoch: 6| Step: 13
Training loss: 3.593600273132324
Validation loss: 2.4165560686460106

Epoch: 43| Step: 0
Training loss: 2.1012701988220215
Validation loss: 2.394452405232255

Epoch: 6| Step: 1
Training loss: 2.4962034225463867
Validation loss: 2.3968429565429688

Epoch: 6| Step: 2
Training loss: 3.2491111755371094
Validation loss: 2.3845407168070474

Epoch: 6| Step: 3
Training loss: 3.172379493713379
Validation loss: 2.3997347559980167

Epoch: 6| Step: 4
Training loss: 1.8816568851470947
Validation loss: 2.3894840645533737

Epoch: 6| Step: 5
Training loss: 2.6435298919677734
Validation loss: 2.3666581261542534

Epoch: 6| Step: 6
Training loss: 2.584367513656616
Validation loss: 2.3386266205900457

Epoch: 6| Step: 7
Training loss: 2.4325761795043945
Validation loss: 2.3210902983142483

Epoch: 6| Step: 8
Training loss: 2.7612287998199463
Validation loss: 2.2999374251211844

Epoch: 6| Step: 9
Training loss: 2.188987970352173
Validation loss: 2.2921465212298977

Epoch: 6| Step: 10
Training loss: 2.8256008625030518
Validation loss: 2.2957895276367024

Epoch: 6| Step: 11
Training loss: 2.502373218536377
Validation loss: 2.29736989800648

Epoch: 6| Step: 12
Training loss: 2.818070888519287
Validation loss: 2.295174414111722

Epoch: 6| Step: 13
Training loss: 2.701601028442383
Validation loss: 2.294878080327024

Epoch: 44| Step: 0
Training loss: 2.738945484161377
Validation loss: 2.295688808605235

Epoch: 6| Step: 1
Training loss: 2.31608247756958
Validation loss: 2.2935290195608653

Epoch: 6| Step: 2
Training loss: 2.767651081085205
Validation loss: 2.2934029794508413

Epoch: 6| Step: 3
Training loss: 2.174504518508911
Validation loss: 2.2936441821436726

Epoch: 6| Step: 4
Training loss: 2.476184606552124
Validation loss: 2.306023436207925

Epoch: 6| Step: 5
Training loss: 2.3108744621276855
Validation loss: 2.3168393386307584

Epoch: 6| Step: 6
Training loss: 2.7492430210113525
Validation loss: 2.35537971988801

Epoch: 6| Step: 7
Training loss: 2.501507520675659
Validation loss: 2.379313302296464

Epoch: 6| Step: 8
Training loss: 2.9600324630737305
Validation loss: 2.4112429516289824

Epoch: 6| Step: 9
Training loss: 2.3685665130615234
Validation loss: 2.4236569507147676

Epoch: 6| Step: 10
Training loss: 2.6902599334716797
Validation loss: 2.3613441554448937

Epoch: 6| Step: 11
Training loss: 3.0157132148742676
Validation loss: 2.3122689365058817

Epoch: 6| Step: 12
Training loss: 2.6008872985839844
Validation loss: 2.2960625207552345

Epoch: 6| Step: 13
Training loss: 2.898984432220459
Validation loss: 2.2901905557160736

Epoch: 45| Step: 0
Training loss: 2.4338650703430176
Validation loss: 2.288141573629072

Epoch: 6| Step: 1
Training loss: 3.3478939533233643
Validation loss: 2.3160812085674656

Epoch: 6| Step: 2
Training loss: 2.543222188949585
Validation loss: 2.3189930633832048

Epoch: 6| Step: 3
Training loss: 3.1232216358184814
Validation loss: 2.3057890604901057

Epoch: 6| Step: 4
Training loss: 2.3149075508117676
Validation loss: 2.304108847853958

Epoch: 6| Step: 5
Training loss: 2.824402332305908
Validation loss: 2.295534560757299

Epoch: 6| Step: 6
Training loss: 2.3459815979003906
Validation loss: 2.2949581915332424

Epoch: 6| Step: 7
Training loss: 2.8934829235076904
Validation loss: 2.2887615414075952

Epoch: 6| Step: 8
Training loss: 2.018702268600464
Validation loss: 2.2884239753087363

Epoch: 6| Step: 9
Training loss: 2.5971508026123047
Validation loss: 2.277478443678989

Epoch: 6| Step: 10
Training loss: 2.499277114868164
Validation loss: 2.2765150326554493

Epoch: 6| Step: 11
Training loss: 2.300287961959839
Validation loss: 2.275229295094808

Epoch: 6| Step: 12
Training loss: 2.6250388622283936
Validation loss: 2.2873062241461968

Epoch: 6| Step: 13
Training loss: 2.313422203063965
Validation loss: 2.300247556419783

Epoch: 46| Step: 0
Training loss: 2.419189691543579
Validation loss: 2.3380425899259505

Epoch: 6| Step: 1
Training loss: 2.818373203277588
Validation loss: 2.3461713226892615

Epoch: 6| Step: 2
Training loss: 2.2804715633392334
Validation loss: 2.3439410963366107

Epoch: 6| Step: 3
Training loss: 2.705852508544922
Validation loss: 2.324285891748244

Epoch: 6| Step: 4
Training loss: 3.0650298595428467
Validation loss: 2.332211181681643

Epoch: 6| Step: 5
Training loss: 3.096202850341797
Validation loss: 2.3337385141721336

Epoch: 6| Step: 6
Training loss: 2.29962420463562
Validation loss: 2.318206964000579

Epoch: 6| Step: 7
Training loss: 2.7556862831115723
Validation loss: 2.3025144684699272

Epoch: 6| Step: 8
Training loss: 2.6139674186706543
Validation loss: 2.279218760869836

Epoch: 6| Step: 9
Training loss: 2.6133487224578857
Validation loss: 2.269049277869604

Epoch: 6| Step: 10
Training loss: 1.7473416328430176
Validation loss: 2.269928588662096

Epoch: 6| Step: 11
Training loss: 2.5777926445007324
Validation loss: 2.2775847386288386

Epoch: 6| Step: 12
Training loss: 2.48824143409729
Validation loss: 2.2814850679007908

Epoch: 6| Step: 13
Training loss: 3.054823875427246
Validation loss: 2.282181332188268

Epoch: 47| Step: 0
Training loss: 3.1467323303222656
Validation loss: 2.2814914782842

Epoch: 6| Step: 1
Training loss: 2.4914917945861816
Validation loss: 2.2796322837952645

Epoch: 6| Step: 2
Training loss: 2.4990315437316895
Validation loss: 2.2845911582310996

Epoch: 6| Step: 3
Training loss: 2.5116937160491943
Validation loss: 2.281084863088464

Epoch: 6| Step: 4
Training loss: 2.2148091793060303
Validation loss: 2.278744189969955

Epoch: 6| Step: 5
Training loss: 3.0513434410095215
Validation loss: 2.274655775357318

Epoch: 6| Step: 6
Training loss: 2.8671154975891113
Validation loss: 2.270701741659513

Epoch: 6| Step: 7
Training loss: 2.5955660343170166
Validation loss: 2.2621725015742804

Epoch: 6| Step: 8
Training loss: 3.159858226776123
Validation loss: 2.263196775990148

Epoch: 6| Step: 9
Training loss: 1.9412391185760498
Validation loss: 2.2636410164576706

Epoch: 6| Step: 10
Training loss: 2.3706398010253906
Validation loss: 2.2662051390576106

Epoch: 6| Step: 11
Training loss: 2.6224403381347656
Validation loss: 2.266740950204993

Epoch: 6| Step: 12
Training loss: 3.0099449157714844
Validation loss: 2.267512203544699

Epoch: 6| Step: 13
Training loss: 0.9385496973991394
Validation loss: 2.269619155955571

Epoch: 48| Step: 0
Training loss: 2.3355231285095215
Validation loss: 2.266190928797568

Epoch: 6| Step: 1
Training loss: 2.3653807640075684
Validation loss: 2.260785907827398

Epoch: 6| Step: 2
Training loss: 2.7974696159362793
Validation loss: 2.2651158071333364

Epoch: 6| Step: 3
Training loss: 2.3783602714538574
Validation loss: 2.261628202212754

Epoch: 6| Step: 4
Training loss: 2.4298787117004395
Validation loss: 2.26309601465861

Epoch: 6| Step: 5
Training loss: 2.6803460121154785
Validation loss: 2.2616711252479145

Epoch: 6| Step: 6
Training loss: 2.063789129257202
Validation loss: 2.266224081798266

Epoch: 6| Step: 7
Training loss: 3.4460859298706055
Validation loss: 2.2714339302432154

Epoch: 6| Step: 8
Training loss: 2.8323631286621094
Validation loss: 2.266527583522181

Epoch: 6| Step: 9
Training loss: 2.097545623779297
Validation loss: 2.2632296559631184

Epoch: 6| Step: 10
Training loss: 2.6750454902648926
Validation loss: 2.2722107005375687

Epoch: 6| Step: 11
Training loss: 2.770615577697754
Validation loss: 2.26594550378861

Epoch: 6| Step: 12
Training loss: 2.297604560852051
Validation loss: 2.2655759819092287

Epoch: 6| Step: 13
Training loss: 2.7718300819396973
Validation loss: 2.261314220325921

Epoch: 49| Step: 0
Training loss: 1.9716075658798218
Validation loss: 2.2590130785460114

Epoch: 6| Step: 1
Training loss: 2.1772615909576416
Validation loss: 2.2614962823929323

Epoch: 6| Step: 2
Training loss: 3.0336456298828125
Validation loss: 2.2636093657503844

Epoch: 6| Step: 3
Training loss: 2.314523220062256
Validation loss: 2.2606933821914015

Epoch: 6| Step: 4
Training loss: 2.737659454345703
Validation loss: 2.265980282137471

Epoch: 6| Step: 5
Training loss: 2.6312999725341797
Validation loss: 2.264551806193526

Epoch: 6| Step: 6
Training loss: 2.0362231731414795
Validation loss: 2.2595406398978284

Epoch: 6| Step: 7
Training loss: 3.0589146614074707
Validation loss: 2.2624083975309968

Epoch: 6| Step: 8
Training loss: 3.2112443447113037
Validation loss: 2.2663894212374123

Epoch: 6| Step: 9
Training loss: 2.157219171524048
Validation loss: 2.2653003046589513

Epoch: 6| Step: 10
Training loss: 2.899667263031006
Validation loss: 2.2640964882348174

Epoch: 6| Step: 11
Training loss: 2.413771629333496
Validation loss: 2.2658553226019746

Epoch: 6| Step: 12
Training loss: 2.6232640743255615
Validation loss: 2.2685481617527623

Epoch: 6| Step: 13
Training loss: 2.938906669616699
Validation loss: 2.268076099375243

Epoch: 50| Step: 0
Training loss: 3.2369611263275146
Validation loss: 2.2712389705001668

Epoch: 6| Step: 1
Training loss: 2.2282309532165527
Validation loss: 2.284328942657799

Epoch: 6| Step: 2
Training loss: 2.5461950302124023
Validation loss: 2.3015064526629705

Epoch: 6| Step: 3
Training loss: 2.6090593338012695
Validation loss: 2.2899579566012145

Epoch: 6| Step: 4
Training loss: 2.592214584350586
Validation loss: 2.2792162485020135

Epoch: 6| Step: 5
Training loss: 3.2377877235412598
Validation loss: 2.2669558678903887

Epoch: 6| Step: 6
Training loss: 2.487323045730591
Validation loss: 2.252670248349508

Epoch: 6| Step: 7
Training loss: 2.5723087787628174
Validation loss: 2.248724350365259

Epoch: 6| Step: 8
Training loss: 2.2435898780822754
Validation loss: 2.2485734339683288

Epoch: 6| Step: 9
Training loss: 2.319397211074829
Validation loss: 2.248497005431883

Epoch: 6| Step: 10
Training loss: 2.541813850402832
Validation loss: 2.2502133743737334

Epoch: 6| Step: 11
Training loss: 1.9059169292449951
Validation loss: 2.251682860876924

Epoch: 6| Step: 12
Training loss: 3.0904083251953125
Validation loss: 2.250001638166366

Epoch: 6| Step: 13
Training loss: 2.3496670722961426
Validation loss: 2.243101745523432

Epoch: 51| Step: 0
Training loss: 1.8729619979858398
Validation loss: 2.2380598309219524

Epoch: 6| Step: 1
Training loss: 3.1010665893554688
Validation loss: 2.2425187326246694

Epoch: 6| Step: 2
Training loss: 2.4373340606689453
Validation loss: 2.2440428862007717

Epoch: 6| Step: 3
Training loss: 2.569028854370117
Validation loss: 2.246959868297782

Epoch: 6| Step: 4
Training loss: 2.524021625518799
Validation loss: 2.2528985290117163

Epoch: 6| Step: 5
Training loss: 2.120608329772949
Validation loss: 2.256340713911159

Epoch: 6| Step: 6
Training loss: 3.253495693206787
Validation loss: 2.2906269950251423

Epoch: 6| Step: 7
Training loss: 2.2165417671203613
Validation loss: 2.317201165742772

Epoch: 6| Step: 8
Training loss: 2.8148093223571777
Validation loss: 2.358580025293494

Epoch: 6| Step: 9
Training loss: 2.549062490463257
Validation loss: 2.3641945956855692

Epoch: 6| Step: 10
Training loss: 2.376762866973877
Validation loss: 2.3876002809052825

Epoch: 6| Step: 11
Training loss: 1.9254724979400635
Validation loss: 2.351558244356545

Epoch: 6| Step: 12
Training loss: 3.507854461669922
Validation loss: 2.3127639998671827

Epoch: 6| Step: 13
Training loss: 2.1967859268188477
Validation loss: 2.276423636303153

Epoch: 52| Step: 0
Training loss: 2.5061545372009277
Validation loss: 2.2692509261510705

Epoch: 6| Step: 1
Training loss: 2.571047782897949
Validation loss: 2.2439474034053024

Epoch: 6| Step: 2
Training loss: 2.691920757293701
Validation loss: 2.2426340836350636

Epoch: 6| Step: 3
Training loss: 2.635967254638672
Validation loss: 2.2489225813137588

Epoch: 6| Step: 4
Training loss: 2.2472755908966064
Validation loss: 2.266706746111634

Epoch: 6| Step: 5
Training loss: 2.835397243499756
Validation loss: 2.2800819104717625

Epoch: 6| Step: 6
Training loss: 2.9424891471862793
Validation loss: 2.2783351713611233

Epoch: 6| Step: 7
Training loss: 2.436434745788574
Validation loss: 2.2706978782530753

Epoch: 6| Step: 8
Training loss: 2.601147174835205
Validation loss: 2.261393911095076

Epoch: 6| Step: 9
Training loss: 1.9347381591796875
Validation loss: 2.244624848006874

Epoch: 6| Step: 10
Training loss: 2.679888963699341
Validation loss: 2.2392203115647837

Epoch: 6| Step: 11
Training loss: 2.363596200942993
Validation loss: 2.2363464524669032

Epoch: 6| Step: 12
Training loss: 2.873422384262085
Validation loss: 2.2380253166280766

Epoch: 6| Step: 13
Training loss: 3.0779151916503906
Validation loss: 2.231297682690364

Epoch: 53| Step: 0
Training loss: 2.280668258666992
Validation loss: 2.232038523561211

Epoch: 6| Step: 1
Training loss: 1.3266239166259766
Validation loss: 2.236666230745213

Epoch: 6| Step: 2
Training loss: 2.351860284805298
Validation loss: 2.2405272606880433

Epoch: 6| Step: 3
Training loss: 2.310178756713867
Validation loss: 2.2359759499949794

Epoch: 6| Step: 4
Training loss: 2.184375047683716
Validation loss: 2.255393164132231

Epoch: 6| Step: 5
Training loss: 2.810654640197754
Validation loss: 2.2546085311520483

Epoch: 6| Step: 6
Training loss: 2.9784016609191895
Validation loss: 2.2656221107770036

Epoch: 6| Step: 7
Training loss: 2.868257761001587
Validation loss: 2.2807059928935063

Epoch: 6| Step: 8
Training loss: 2.8242886066436768
Validation loss: 2.261828600719411

Epoch: 6| Step: 9
Training loss: 2.76259183883667
Validation loss: 2.2483677171891734

Epoch: 6| Step: 10
Training loss: 2.717747449874878
Validation loss: 2.2400199700427312

Epoch: 6| Step: 11
Training loss: 3.149857759475708
Validation loss: 2.2309369194892144

Epoch: 6| Step: 12
Training loss: 2.574968099594116
Validation loss: 2.2258367243633477

Epoch: 6| Step: 13
Training loss: 2.41184401512146
Validation loss: 2.222885513818392

Epoch: 54| Step: 0
Training loss: 2.2030529975891113
Validation loss: 2.2233333305646013

Epoch: 6| Step: 1
Training loss: 2.3450965881347656
Validation loss: 2.2236625045858402

Epoch: 6| Step: 2
Training loss: 2.514272928237915
Validation loss: 2.2237111958124305

Epoch: 6| Step: 3
Training loss: 2.931689977645874
Validation loss: 2.224113133645827

Epoch: 6| Step: 4
Training loss: 2.8541009426116943
Validation loss: 2.223263866157942

Epoch: 6| Step: 5
Training loss: 2.6034364700317383
Validation loss: 2.222376896489051

Epoch: 6| Step: 6
Training loss: 2.5026612281799316
Validation loss: 2.2303653686277327

Epoch: 6| Step: 7
Training loss: 2.3608808517456055
Validation loss: 2.223961358429283

Epoch: 6| Step: 8
Training loss: 3.1362709999084473
Validation loss: 2.225902497127492

Epoch: 6| Step: 9
Training loss: 2.193112373352051
Validation loss: 2.2310286773148404

Epoch: 6| Step: 10
Training loss: 2.4499266147613525
Validation loss: 2.2251704123712357

Epoch: 6| Step: 11
Training loss: 2.5703587532043457
Validation loss: 2.2407040442189863

Epoch: 6| Step: 12
Training loss: 2.2393765449523926
Validation loss: 2.2480056465313

Epoch: 6| Step: 13
Training loss: 2.860966682434082
Validation loss: 2.2599105065868748

Epoch: 55| Step: 0
Training loss: 3.0814313888549805
Validation loss: 2.2682821622458835

Epoch: 6| Step: 1
Training loss: 2.3580806255340576
Validation loss: 2.266287503703948

Epoch: 6| Step: 2
Training loss: 2.4496655464172363
Validation loss: 2.2538807122938094

Epoch: 6| Step: 3
Training loss: 2.2830142974853516
Validation loss: 2.252361105334374

Epoch: 6| Step: 4
Training loss: 2.0475564002990723
Validation loss: 2.241947240726922

Epoch: 6| Step: 5
Training loss: 2.0916061401367188
Validation loss: 2.2404262917016142

Epoch: 6| Step: 6
Training loss: 2.3644886016845703
Validation loss: 2.2325494545762257

Epoch: 6| Step: 7
Training loss: 3.047691822052002
Validation loss: 2.230483408897154

Epoch: 6| Step: 8
Training loss: 2.4415364265441895
Validation loss: 2.2238715438432592

Epoch: 6| Step: 9
Training loss: 2.9941506385803223
Validation loss: 2.218745203428371

Epoch: 6| Step: 10
Training loss: 1.6312392950057983
Validation loss: 2.2146484364745436

Epoch: 6| Step: 11
Training loss: 3.3356709480285645
Validation loss: 2.21669170677021

Epoch: 6| Step: 12
Training loss: 3.2669217586517334
Validation loss: 2.2115922768910727

Epoch: 6| Step: 13
Training loss: 1.9902968406677246
Validation loss: 2.2143544791847147

Epoch: 56| Step: 0
Training loss: 2.155885696411133
Validation loss: 2.2175178425286406

Epoch: 6| Step: 1
Training loss: 2.958434581756592
Validation loss: 2.2172685797496507

Epoch: 6| Step: 2
Training loss: 1.8487486839294434
Validation loss: 2.2210708254127094

Epoch: 6| Step: 3
Training loss: 3.3087592124938965
Validation loss: 2.2202342607641734

Epoch: 6| Step: 4
Training loss: 1.863417148590088
Validation loss: 2.223392055880639

Epoch: 6| Step: 5
Training loss: 2.7630722522735596
Validation loss: 2.2211707176700717

Epoch: 6| Step: 6
Training loss: 2.816575527191162
Validation loss: 2.228134334728282

Epoch: 6| Step: 7
Training loss: 3.2563281059265137
Validation loss: 2.242832149228742

Epoch: 6| Step: 8
Training loss: 2.678572654724121
Validation loss: 2.243064231770013

Epoch: 6| Step: 9
Training loss: 2.368093490600586
Validation loss: 2.276402470886066

Epoch: 6| Step: 10
Training loss: 2.6926796436309814
Validation loss: 2.282967277752456

Epoch: 6| Step: 11
Training loss: 1.7012537717819214
Validation loss: 2.2572212885784846

Epoch: 6| Step: 12
Training loss: 2.146251916885376
Validation loss: 2.2442721936010543

Epoch: 6| Step: 13
Training loss: 2.926754951477051
Validation loss: 2.2380941734519055

Epoch: 57| Step: 0
Training loss: 3.1539106369018555
Validation loss: 2.2273382935472714

Epoch: 6| Step: 1
Training loss: 2.1416454315185547
Validation loss: 2.218203147252401

Epoch: 6| Step: 2
Training loss: 2.600978136062622
Validation loss: 2.2289251281369116

Epoch: 6| Step: 3
Training loss: 3.093242883682251
Validation loss: 2.2225357435082875

Epoch: 6| Step: 4
Training loss: 3.0663399696350098
Validation loss: 2.2193987215718916

Epoch: 6| Step: 5
Training loss: 2.2747488021850586
Validation loss: 2.22591172879742

Epoch: 6| Step: 6
Training loss: 2.304424524307251
Validation loss: 2.2195473665832193

Epoch: 6| Step: 7
Training loss: 2.315009355545044
Validation loss: 2.2248261820885444

Epoch: 6| Step: 8
Training loss: 2.041404962539673
Validation loss: 2.228038118731591

Epoch: 6| Step: 9
Training loss: 2.3414554595947266
Validation loss: 2.2188733623873804

Epoch: 6| Step: 10
Training loss: 2.341024160385132
Validation loss: 2.223257992857246

Epoch: 6| Step: 11
Training loss: 2.924915075302124
Validation loss: 2.22501741942539

Epoch: 6| Step: 12
Training loss: 2.0187039375305176
Validation loss: 2.237959752800644

Epoch: 6| Step: 13
Training loss: 2.7102880477905273
Validation loss: 2.2525370685003137

Epoch: 58| Step: 0
Training loss: 2.3852944374084473
Validation loss: 2.2332651717688448

Epoch: 6| Step: 1
Training loss: 2.207885503768921
Validation loss: 2.2229891925729732

Epoch: 6| Step: 2
Training loss: 2.7029480934143066
Validation loss: 2.208714400568316

Epoch: 6| Step: 3
Training loss: 2.462688684463501
Validation loss: 2.207229155366139

Epoch: 6| Step: 4
Training loss: 2.7887253761291504
Validation loss: 2.201398636705132

Epoch: 6| Step: 5
Training loss: 2.962519407272339
Validation loss: 2.1956870555877686

Epoch: 6| Step: 6
Training loss: 2.6500566005706787
Validation loss: 2.199154797420707

Epoch: 6| Step: 7
Training loss: 2.093421220779419
Validation loss: 2.1977771251432356

Epoch: 6| Step: 8
Training loss: 1.9280622005462646
Validation loss: 2.192955558018018

Epoch: 6| Step: 9
Training loss: 3.0156748294830322
Validation loss: 2.1945864256992134

Epoch: 6| Step: 10
Training loss: 2.476400852203369
Validation loss: 2.207986488137194

Epoch: 6| Step: 11
Training loss: 2.468806743621826
Validation loss: 2.2221343196848387

Epoch: 6| Step: 12
Training loss: 2.350691318511963
Validation loss: 2.2478139105663506

Epoch: 6| Step: 13
Training loss: 2.963343620300293
Validation loss: 2.279263757890271

Epoch: 59| Step: 0
Training loss: 2.0493416786193848
Validation loss: 2.2804707352833082

Epoch: 6| Step: 1
Training loss: 2.3396573066711426
Validation loss: 2.273374713877196

Epoch: 6| Step: 2
Training loss: 2.7185940742492676
Validation loss: 2.268993862213627

Epoch: 6| Step: 3
Training loss: 3.1497116088867188
Validation loss: 2.2639903560761483

Epoch: 6| Step: 4
Training loss: 2.4587666988372803
Validation loss: 2.2472240873562392

Epoch: 6| Step: 5
Training loss: 2.1757984161376953
Validation loss: 2.220017904876381

Epoch: 6| Step: 6
Training loss: 2.702728748321533
Validation loss: 2.2029670938368766

Epoch: 6| Step: 7
Training loss: 2.475264549255371
Validation loss: 2.1978541689534343

Epoch: 6| Step: 8
Training loss: 2.475804328918457
Validation loss: 2.1910209194306405

Epoch: 6| Step: 9
Training loss: 2.098069667816162
Validation loss: 2.189846049072922

Epoch: 6| Step: 10
Training loss: 2.6094069480895996
Validation loss: 2.186693540183447

Epoch: 6| Step: 11
Training loss: 3.1760518550872803
Validation loss: 2.1934357548272736

Epoch: 6| Step: 12
Training loss: 2.3478074073791504
Validation loss: 2.1884192651317966

Epoch: 6| Step: 13
Training loss: 2.828017234802246
Validation loss: 2.192533172586913

Epoch: 60| Step: 0
Training loss: 2.4324560165405273
Validation loss: 2.19867600933198

Epoch: 6| Step: 1
Training loss: 2.827909469604492
Validation loss: 2.2034979584396526

Epoch: 6| Step: 2
Training loss: 2.8131909370422363
Validation loss: 2.225237105482368

Epoch: 6| Step: 3
Training loss: 2.358617067337036
Validation loss: 2.23877606596998

Epoch: 6| Step: 4
Training loss: 2.308579444885254
Validation loss: 2.245920637602447

Epoch: 6| Step: 5
Training loss: 2.9296786785125732
Validation loss: 2.2165701184221493

Epoch: 6| Step: 6
Training loss: 2.8096892833709717
Validation loss: 2.1998752522212204

Epoch: 6| Step: 7
Training loss: 1.5160703659057617
Validation loss: 2.1864426059107624

Epoch: 6| Step: 8
Training loss: 3.1485934257507324
Validation loss: 2.1951086187875397

Epoch: 6| Step: 9
Training loss: 2.453033685684204
Validation loss: 2.1955406511983564

Epoch: 6| Step: 10
Training loss: 2.023712396621704
Validation loss: 2.201293881221484

Epoch: 6| Step: 11
Training loss: 2.656982421875
Validation loss: 2.198705452744679

Epoch: 6| Step: 12
Training loss: 2.2471134662628174
Validation loss: 2.1938444311900804

Epoch: 6| Step: 13
Training loss: 3.490159273147583
Validation loss: 2.186018451567619

Epoch: 61| Step: 0
Training loss: 1.8541498184204102
Validation loss: 2.1785712601036153

Epoch: 6| Step: 1
Training loss: 2.056609630584717
Validation loss: 2.175411706329674

Epoch: 6| Step: 2
Training loss: 2.8292317390441895
Validation loss: 2.177841253178094

Epoch: 6| Step: 3
Training loss: 3.4114937782287598
Validation loss: 2.183200848999844

Epoch: 6| Step: 4
Training loss: 2.0388381481170654
Validation loss: 2.1930146294255413

Epoch: 6| Step: 5
Training loss: 2.680027961730957
Validation loss: 2.202823726079797

Epoch: 6| Step: 6
Training loss: 2.458756446838379
Validation loss: 2.215671036833076

Epoch: 6| Step: 7
Training loss: 2.7428958415985107
Validation loss: 2.213373150876773

Epoch: 6| Step: 8
Training loss: 2.462151527404785
Validation loss: 2.2151909259057816

Epoch: 6| Step: 9
Training loss: 1.9973249435424805
Validation loss: 2.215633851225658

Epoch: 6| Step: 10
Training loss: 3.5041582584381104
Validation loss: 2.216762617070188

Epoch: 6| Step: 11
Training loss: 1.937154769897461
Validation loss: 2.2270226170939784

Epoch: 6| Step: 12
Training loss: 2.5108134746551514
Validation loss: 2.2329269686052875

Epoch: 6| Step: 13
Training loss: 2.6894009113311768
Validation loss: 2.289751188729399

Epoch: 62| Step: 0
Training loss: 2.355599880218506
Validation loss: 2.2919740317970194

Epoch: 6| Step: 1
Training loss: 2.7539000511169434
Validation loss: 2.2416631919081493

Epoch: 6| Step: 2
Training loss: 2.2469730377197266
Validation loss: 2.222720356397731

Epoch: 6| Step: 3
Training loss: 2.8077332973480225
Validation loss: 2.2099337065091698

Epoch: 6| Step: 4
Training loss: 1.6154825687408447
Validation loss: 2.2087661707273094

Epoch: 6| Step: 5
Training loss: 2.457395076751709
Validation loss: 2.220300743656774

Epoch: 6| Step: 6
Training loss: 2.8233561515808105
Validation loss: 2.2394626960959485

Epoch: 6| Step: 7
Training loss: 2.4905877113342285
Validation loss: 2.2748956116296912

Epoch: 6| Step: 8
Training loss: 2.6107304096221924
Validation loss: 2.3040323949629262

Epoch: 6| Step: 9
Training loss: 2.7416491508483887
Validation loss: 2.3191535985598

Epoch: 6| Step: 10
Training loss: 2.613337516784668
Validation loss: 2.313212799769576

Epoch: 6| Step: 11
Training loss: 3.157844066619873
Validation loss: 2.272045491844095

Epoch: 6| Step: 12
Training loss: 1.879135251045227
Validation loss: 2.2325366286821264

Epoch: 6| Step: 13
Training loss: 2.964447498321533
Validation loss: 2.2131624119256132

Epoch: 63| Step: 0
Training loss: 2.8224377632141113
Validation loss: 2.1801570410369546

Epoch: 6| Step: 1
Training loss: 2.1926279067993164
Validation loss: 2.1761388599231677

Epoch: 6| Step: 2
Training loss: 2.5795230865478516
Validation loss: 2.177170063859673

Epoch: 6| Step: 3
Training loss: 2.2822041511535645
Validation loss: 2.1749906796281055

Epoch: 6| Step: 4
Training loss: 2.840564250946045
Validation loss: 2.1750015302370955

Epoch: 6| Step: 5
Training loss: 2.2354321479797363
Validation loss: 2.174715893242949

Epoch: 6| Step: 6
Training loss: 2.270456314086914
Validation loss: 2.170590272513769

Epoch: 6| Step: 7
Training loss: 2.9690558910369873
Validation loss: 2.1702287632931947

Epoch: 6| Step: 8
Training loss: 2.98165225982666
Validation loss: 2.1673078511350896

Epoch: 6| Step: 9
Training loss: 3.484952211380005
Validation loss: 2.166236105785575

Epoch: 6| Step: 10
Training loss: 2.0965282917022705
Validation loss: 2.168815259010561

Epoch: 6| Step: 11
Training loss: 2.288923740386963
Validation loss: 2.171212471941466

Epoch: 6| Step: 12
Training loss: 2.143362045288086
Validation loss: 2.182990502285701

Epoch: 6| Step: 13
Training loss: 1.5517735481262207
Validation loss: 2.2170714165574763

Epoch: 64| Step: 0
Training loss: 2.1849567890167236
Validation loss: 2.2546674077228834

Epoch: 6| Step: 1
Training loss: 2.6173720359802246
Validation loss: 2.3253933216935847

Epoch: 6| Step: 2
Training loss: 2.5080933570861816
Validation loss: 2.3717805518898913

Epoch: 6| Step: 3
Training loss: 2.608788013458252
Validation loss: 2.4245847476425992

Epoch: 6| Step: 4
Training loss: 3.025141716003418
Validation loss: 2.4402695573786253

Epoch: 6| Step: 5
Training loss: 3.313844680786133
Validation loss: 2.3949408813189437

Epoch: 6| Step: 6
Training loss: 3.0956315994262695
Validation loss: 2.2911594016577608

Epoch: 6| Step: 7
Training loss: 2.4538254737854004
Validation loss: 2.21074398615027

Epoch: 6| Step: 8
Training loss: 2.3298439979553223
Validation loss: 2.1704972751678957

Epoch: 6| Step: 9
Training loss: 2.6191024780273438
Validation loss: 2.1592975354963735

Epoch: 6| Step: 10
Training loss: 2.238548755645752
Validation loss: 2.164110375988868

Epoch: 6| Step: 11
Training loss: 2.172318458557129
Validation loss: 2.172071462036461

Epoch: 6| Step: 12
Training loss: 2.157435178756714
Validation loss: 2.1719837445084766

Epoch: 6| Step: 13
Training loss: 2.4470622539520264
Validation loss: 2.1776492634127216

Epoch: 65| Step: 0
Training loss: 2.283433437347412
Validation loss: 2.184888691030523

Epoch: 6| Step: 1
Training loss: 2.58376145362854
Validation loss: 2.17815794996036

Epoch: 6| Step: 2
Training loss: 2.9414360523223877
Validation loss: 2.1717263114067817

Epoch: 6| Step: 3
Training loss: 2.887340545654297
Validation loss: 2.1717863287976993

Epoch: 6| Step: 4
Training loss: 2.8013205528259277
Validation loss: 2.169210849269744

Epoch: 6| Step: 5
Training loss: 2.6635327339172363
Validation loss: 2.1680958681209113

Epoch: 6| Step: 6
Training loss: 2.8810839653015137
Validation loss: 2.1734089877015803

Epoch: 6| Step: 7
Training loss: 1.9654031991958618
Validation loss: 2.1772855045974895

Epoch: 6| Step: 8
Training loss: 2.5790343284606934
Validation loss: 2.2020642513869912

Epoch: 6| Step: 9
Training loss: 2.635178804397583
Validation loss: 2.2170932305756437

Epoch: 6| Step: 10
Training loss: 2.6396727561950684
Validation loss: 2.213475727265881

Epoch: 6| Step: 11
Training loss: 1.8139557838439941
Validation loss: 2.2257349491119385

Epoch: 6| Step: 12
Training loss: 2.0951080322265625
Validation loss: 2.22492745871185

Epoch: 6| Step: 13
Training loss: 2.2393851280212402
Validation loss: 2.2068462500008206

Epoch: 66| Step: 0
Training loss: 2.112563133239746
Validation loss: 2.2077380303413636

Epoch: 6| Step: 1
Training loss: 2.178952693939209
Validation loss: 2.1994144147442234

Epoch: 6| Step: 2
Training loss: 1.9237160682678223
Validation loss: 2.1986063423977105

Epoch: 6| Step: 3
Training loss: 2.8618416786193848
Validation loss: 2.2209193578330417

Epoch: 6| Step: 4
Training loss: 2.751431465148926
Validation loss: 2.228438660662661

Epoch: 6| Step: 5
Training loss: 2.473409652709961
Validation loss: 2.218567373932049

Epoch: 6| Step: 6
Training loss: 3.165050506591797
Validation loss: 2.2178890256471533

Epoch: 6| Step: 7
Training loss: 2.6516900062561035
Validation loss: 2.185891253973848

Epoch: 6| Step: 8
Training loss: 2.8758554458618164
Validation loss: 2.1737623265994492

Epoch: 6| Step: 9
Training loss: 1.918165922164917
Validation loss: 2.156217005945021

Epoch: 6| Step: 10
Training loss: 2.158672332763672
Validation loss: 2.1523057953003915

Epoch: 6| Step: 11
Training loss: 2.618919610977173
Validation loss: 2.146312129112982

Epoch: 6| Step: 12
Training loss: 2.6542396545410156
Validation loss: 2.141430950933887

Epoch: 6| Step: 13
Training loss: 2.3145103454589844
Validation loss: 2.1436725354963735

Epoch: 67| Step: 0
Training loss: 2.7748303413391113
Validation loss: 2.1477984202805387

Epoch: 6| Step: 1
Training loss: 2.1373307704925537
Validation loss: 2.145156539896483

Epoch: 6| Step: 2
Training loss: 2.9728312492370605
Validation loss: 2.145545689008569

Epoch: 6| Step: 3
Training loss: 1.7670962810516357
Validation loss: 2.1435166148729223

Epoch: 6| Step: 4
Training loss: 2.5771732330322266
Validation loss: 2.1462378758256153

Epoch: 6| Step: 5
Training loss: 2.431208610534668
Validation loss: 2.158189494122741

Epoch: 6| Step: 6
Training loss: 2.5310966968536377
Validation loss: 2.2324136662226852

Epoch: 6| Step: 7
Training loss: 2.417590856552124
Validation loss: 2.329417651699435

Epoch: 6| Step: 8
Training loss: 3.2371156215667725
Validation loss: 2.43964966394568

Epoch: 6| Step: 9
Training loss: 1.7443687915802002
Validation loss: 2.4454653673274542

Epoch: 6| Step: 10
Training loss: 2.936647653579712
Validation loss: 2.3243744809140443

Epoch: 6| Step: 11
Training loss: 2.457864761352539
Validation loss: 2.1930306880704817

Epoch: 6| Step: 12
Training loss: 2.9257373809814453
Validation loss: 2.146799777143745

Epoch: 6| Step: 13
Training loss: 2.5160655975341797
Validation loss: 2.134565471321024

Epoch: 68| Step: 0
Training loss: 2.577949047088623
Validation loss: 2.1493041746078

Epoch: 6| Step: 1
Training loss: 3.115786075592041
Validation loss: 2.148569114746586

Epoch: 6| Step: 2
Training loss: 2.2187259197235107
Validation loss: 2.1573826587328346

Epoch: 6| Step: 3
Training loss: 2.5144190788269043
Validation loss: 2.1569789455782984

Epoch: 6| Step: 4
Training loss: 3.2105116844177246
Validation loss: 2.162550446807697

Epoch: 6| Step: 5
Training loss: 2.448996067047119
Validation loss: 2.1607237092910276

Epoch: 6| Step: 6
Training loss: 2.8366527557373047
Validation loss: 2.1566733711509296

Epoch: 6| Step: 7
Training loss: 2.6893794536590576
Validation loss: 2.1527485898745957

Epoch: 6| Step: 8
Training loss: 2.204052448272705
Validation loss: 2.1392141939491354

Epoch: 6| Step: 9
Training loss: 1.7560069561004639
Validation loss: 2.1389566313835884

Epoch: 6| Step: 10
Training loss: 2.478360652923584
Validation loss: 2.139498346595354

Epoch: 6| Step: 11
Training loss: 2.5896596908569336
Validation loss: 2.142184549762357

Epoch: 6| Step: 12
Training loss: 2.2355728149414062
Validation loss: 2.151236621282434

Epoch: 6| Step: 13
Training loss: 2.0789496898651123
Validation loss: 2.163171624624601

Epoch: 69| Step: 0
Training loss: 2.1124353408813477
Validation loss: 2.185378959102015

Epoch: 6| Step: 1
Training loss: 3.0538105964660645
Validation loss: 2.1943195378908547

Epoch: 6| Step: 2
Training loss: 2.3323915004730225
Validation loss: 2.201277063738915

Epoch: 6| Step: 3
Training loss: 3.496342420578003
Validation loss: 2.200753517048333

Epoch: 6| Step: 4
Training loss: 2.6097545623779297
Validation loss: 2.1839439279289654

Epoch: 6| Step: 5
Training loss: 2.6806044578552246
Validation loss: 2.1672775181390906

Epoch: 6| Step: 6
Training loss: 2.5092153549194336
Validation loss: 2.1588265690752255

Epoch: 6| Step: 7
Training loss: 2.6836447715759277
Validation loss: 2.145478633142287

Epoch: 6| Step: 8
Training loss: 2.2586987018585205
Validation loss: 2.138103272325249

Epoch: 6| Step: 9
Training loss: 2.5505971908569336
Validation loss: 2.1351914046913065

Epoch: 6| Step: 10
Training loss: 1.9093146324157715
Validation loss: 2.1335275365460302

Epoch: 6| Step: 11
Training loss: 2.281648635864258
Validation loss: 2.1358349079726846

Epoch: 6| Step: 12
Training loss: 1.9471995830535889
Validation loss: 2.134858662082303

Epoch: 6| Step: 13
Training loss: 2.4134554862976074
Validation loss: 2.141270537530222

Epoch: 70| Step: 0
Training loss: 2.1835556030273438
Validation loss: 2.137317410079382

Epoch: 6| Step: 1
Training loss: 2.2880001068115234
Validation loss: 2.144150149437689

Epoch: 6| Step: 2
Training loss: 2.683312177658081
Validation loss: 2.146060016847426

Epoch: 6| Step: 3
Training loss: 1.8300201892852783
Validation loss: 2.1570025554267307

Epoch: 6| Step: 4
Training loss: 2.383974552154541
Validation loss: 2.1612501246954805

Epoch: 6| Step: 5
Training loss: 2.587580919265747
Validation loss: 2.165375571097097

Epoch: 6| Step: 6
Training loss: 2.9644577503204346
Validation loss: 2.1870663935138333

Epoch: 6| Step: 7
Training loss: 2.2000370025634766
Validation loss: 2.1986785037543184

Epoch: 6| Step: 8
Training loss: 2.914698839187622
Validation loss: 2.193921732646163

Epoch: 6| Step: 9
Training loss: 2.731387138366699
Validation loss: 2.1817622133480605

Epoch: 6| Step: 10
Training loss: 2.291595458984375
Validation loss: 2.1728009793066208

Epoch: 6| Step: 11
Training loss: 2.666696786880493
Validation loss: 2.162803614011375

Epoch: 6| Step: 12
Training loss: 2.6778104305267334
Validation loss: 2.1554745525442143

Epoch: 6| Step: 13
Training loss: 2.022944211959839
Validation loss: 2.1530935610494306

Epoch: 71| Step: 0
Training loss: 2.6064505577087402
Validation loss: 2.1420254938064085

Epoch: 6| Step: 1
Training loss: 2.159605026245117
Validation loss: 2.1373018423716226

Epoch: 6| Step: 2
Training loss: 2.7684473991394043
Validation loss: 2.1392241985567155

Epoch: 6| Step: 3
Training loss: 2.6691789627075195
Validation loss: 2.141462163258624

Epoch: 6| Step: 4
Training loss: 2.2876458168029785
Validation loss: 2.141328773190898

Epoch: 6| Step: 5
Training loss: 2.913025379180908
Validation loss: 2.140700319761871

Epoch: 6| Step: 6
Training loss: 2.31587290763855
Validation loss: 2.141162230122474

Epoch: 6| Step: 7
Training loss: 2.125500202178955
Validation loss: 2.1365081815309424

Epoch: 6| Step: 8
Training loss: 2.209237813949585
Validation loss: 2.13257933175692

Epoch: 6| Step: 9
Training loss: 2.7839126586914062
Validation loss: 2.1359014972563712

Epoch: 6| Step: 10
Training loss: 2.7908577919006348
Validation loss: 2.1356411134043047

Epoch: 6| Step: 11
Training loss: 2.3057022094726562
Validation loss: 2.1303926949859946

Epoch: 6| Step: 12
Training loss: 1.4636099338531494
Validation loss: 2.1369580197077926

Epoch: 6| Step: 13
Training loss: 3.758283853530884
Validation loss: 2.1307068204367035

Epoch: 72| Step: 0
Training loss: 2.9578237533569336
Validation loss: 2.1366359982439267

Epoch: 6| Step: 1
Training loss: 2.264561176300049
Validation loss: 2.1594500310959353

Epoch: 6| Step: 2
Training loss: 2.806387424468994
Validation loss: 2.178600431770407

Epoch: 6| Step: 3
Training loss: 2.9103195667266846
Validation loss: 2.1877913962128344

Epoch: 6| Step: 4
Training loss: 2.4493889808654785
Validation loss: 2.1794259753278507

Epoch: 6| Step: 5
Training loss: 2.8878567218780518
Validation loss: 2.144001237807735

Epoch: 6| Step: 6
Training loss: 2.8281636238098145
Validation loss: 2.1422556830990698

Epoch: 6| Step: 7
Training loss: 1.3408132791519165
Validation loss: 2.149445108188096

Epoch: 6| Step: 8
Training loss: 2.244185447692871
Validation loss: 2.143536934288599

Epoch: 6| Step: 9
Training loss: 2.121006488800049
Validation loss: 2.145234638644803

Epoch: 6| Step: 10
Training loss: 2.1637520790100098
Validation loss: 2.1381097685906196

Epoch: 6| Step: 11
Training loss: 2.283721685409546
Validation loss: 2.140724966602941

Epoch: 6| Step: 12
Training loss: 2.2191715240478516
Validation loss: 2.1588598630761586

Epoch: 6| Step: 13
Training loss: 3.4209108352661133
Validation loss: 2.1745683839244228

Epoch: 73| Step: 0
Training loss: 2.4019925594329834
Validation loss: 2.161042433913036

Epoch: 6| Step: 1
Training loss: 2.8804283142089844
Validation loss: 2.138354565507622

Epoch: 6| Step: 2
Training loss: 3.0504329204559326
Validation loss: 2.1296411586064163

Epoch: 6| Step: 3
Training loss: 2.328826427459717
Validation loss: 2.127489553984775

Epoch: 6| Step: 4
Training loss: 1.994107723236084
Validation loss: 2.1195289934835126

Epoch: 6| Step: 5
Training loss: 2.361279010772705
Validation loss: 2.1276140648831605

Epoch: 6| Step: 6
Training loss: 2.4457149505615234
Validation loss: 2.122738689504644

Epoch: 6| Step: 7
Training loss: 2.8866095542907715
Validation loss: 2.1227249599272207

Epoch: 6| Step: 8
Training loss: 1.9124091863632202
Validation loss: 2.1267804663668395

Epoch: 6| Step: 9
Training loss: 2.300178050994873
Validation loss: 2.132279658830294

Epoch: 6| Step: 10
Training loss: 2.3296773433685303
Validation loss: 2.1337933335252988

Epoch: 6| Step: 11
Training loss: 2.6309285163879395
Validation loss: 2.1331689947394916

Epoch: 6| Step: 12
Training loss: 2.651069164276123
Validation loss: 2.1372912968358686

Epoch: 6| Step: 13
Training loss: 1.9897047281265259
Validation loss: 2.1309502432423253

Epoch: 74| Step: 0
Training loss: 2.528801918029785
Validation loss: 2.1294306734556794

Epoch: 6| Step: 1
Training loss: 2.8343727588653564
Validation loss: 2.125643467390409

Epoch: 6| Step: 2
Training loss: 2.0741310119628906
Validation loss: 2.1253857228063766

Epoch: 6| Step: 3
Training loss: 2.89090633392334
Validation loss: 2.129132378485895

Epoch: 6| Step: 4
Training loss: 2.543302536010742
Validation loss: 2.123625709164527

Epoch: 6| Step: 5
Training loss: 2.7574777603149414
Validation loss: 2.1346610271802513

Epoch: 6| Step: 6
Training loss: 2.688488245010376
Validation loss: 2.142232175796263

Epoch: 6| Step: 7
Training loss: 1.7251073122024536
Validation loss: 2.1335583938065397

Epoch: 6| Step: 8
Training loss: 2.656332492828369
Validation loss: 2.141609163694484

Epoch: 6| Step: 9
Training loss: 2.6967363357543945
Validation loss: 2.141799326865904

Epoch: 6| Step: 10
Training loss: 1.8357350826263428
Validation loss: 2.132668199077729

Epoch: 6| Step: 11
Training loss: 2.306758165359497
Validation loss: 2.1178971772552817

Epoch: 6| Step: 12
Training loss: 2.348361015319824
Validation loss: 2.115972985503494

Epoch: 6| Step: 13
Training loss: 2.479421377182007
Validation loss: 2.1160724701419955

Epoch: 75| Step: 0
Training loss: 1.776016116142273
Validation loss: 2.116879158122565

Epoch: 6| Step: 1
Training loss: 2.9216978549957275
Validation loss: 2.122550028626637

Epoch: 6| Step: 2
Training loss: 2.1440863609313965
Validation loss: 2.1177303021953953

Epoch: 6| Step: 3
Training loss: 2.7991294860839844
Validation loss: 2.1209193762912544

Epoch: 6| Step: 4
Training loss: 2.3387274742126465
Validation loss: 2.125152213599092

Epoch: 6| Step: 5
Training loss: 1.9949862957000732
Validation loss: 2.1210508987467778

Epoch: 6| Step: 6
Training loss: 2.4898128509521484
Validation loss: 2.118935710640364

Epoch: 6| Step: 7
Training loss: 2.7885608673095703
Validation loss: 2.119919321870291

Epoch: 6| Step: 8
Training loss: 2.6728339195251465
Validation loss: 2.1229254481612996

Epoch: 6| Step: 9
Training loss: 2.142519474029541
Validation loss: 2.1300977045489895

Epoch: 6| Step: 10
Training loss: 2.8500638008117676
Validation loss: 2.1276963192929506

Epoch: 6| Step: 11
Training loss: 2.409184455871582
Validation loss: 2.1359013806107225

Epoch: 6| Step: 12
Training loss: 2.1515138149261475
Validation loss: 2.1477001072258077

Epoch: 6| Step: 13
Training loss: 2.7316572666168213
Validation loss: 2.1458897821364866

Epoch: 76| Step: 0
Training loss: 2.645977258682251
Validation loss: 2.1467257648385982

Epoch: 6| Step: 1
Training loss: 3.0550076961517334
Validation loss: 2.1346573316922752

Epoch: 6| Step: 2
Training loss: 2.7551169395446777
Validation loss: 2.1300019435985114

Epoch: 6| Step: 3
Training loss: 1.7415540218353271
Validation loss: 2.1201287879738757

Epoch: 6| Step: 4
Training loss: 1.6657307147979736
Validation loss: 2.1122325927980485

Epoch: 6| Step: 5
Training loss: 2.18914532661438
Validation loss: 2.1016179900015555

Epoch: 6| Step: 6
Training loss: 2.1885323524475098
Validation loss: 2.108303746869487

Epoch: 6| Step: 7
Training loss: 2.727755069732666
Validation loss: 2.1052697166319816

Epoch: 6| Step: 8
Training loss: 1.8287568092346191
Validation loss: 2.106831512143535

Epoch: 6| Step: 9
Training loss: 2.8296151161193848
Validation loss: 2.1194750532027213

Epoch: 6| Step: 10
Training loss: 2.226134777069092
Validation loss: 2.1083532456428773

Epoch: 6| Step: 11
Training loss: 2.9754652976989746
Validation loss: 2.111665810308149

Epoch: 6| Step: 12
Training loss: 2.4846959114074707
Validation loss: 2.1021300669639342

Epoch: 6| Step: 13
Training loss: 2.9311320781707764
Validation loss: 2.0985334393798665

Epoch: 77| Step: 0
Training loss: 2.0331413745880127
Validation loss: 2.1067308802758493

Epoch: 6| Step: 1
Training loss: 1.9345308542251587
Validation loss: 2.1117498182481333

Epoch: 6| Step: 2
Training loss: 2.133535385131836
Validation loss: 2.103946626827281

Epoch: 6| Step: 3
Training loss: 2.721132755279541
Validation loss: 2.1185245719007266

Epoch: 6| Step: 4
Training loss: 2.4222185611724854
Validation loss: 2.143683483523707

Epoch: 6| Step: 5
Training loss: 2.023258924484253
Validation loss: 2.161388897126721

Epoch: 6| Step: 6
Training loss: 3.041224479675293
Validation loss: 2.18813721851636

Epoch: 6| Step: 7
Training loss: 2.268620729446411
Validation loss: 2.162885476184148

Epoch: 6| Step: 8
Training loss: 2.406221866607666
Validation loss: 2.1476928367409656

Epoch: 6| Step: 9
Training loss: 2.721893548965454
Validation loss: 2.1334696764587076

Epoch: 6| Step: 10
Training loss: 2.376188039779663
Validation loss: 2.106846768368957

Epoch: 6| Step: 11
Training loss: 2.438448429107666
Validation loss: 2.1073198113390195

Epoch: 6| Step: 12
Training loss: 2.6838111877441406
Validation loss: 2.1002781737235283

Epoch: 6| Step: 13
Training loss: 2.939601421356201
Validation loss: 2.0965786723680395

Epoch: 78| Step: 0
Training loss: 2.682420492172241
Validation loss: 2.0940703307428667

Epoch: 6| Step: 1
Training loss: 1.976963996887207
Validation loss: 2.087670913306616

Epoch: 6| Step: 2
Training loss: 2.5197901725769043
Validation loss: 2.0909098835401636

Epoch: 6| Step: 3
Training loss: 1.4186418056488037
Validation loss: 2.0878612584965204

Epoch: 6| Step: 4
Training loss: 2.0701255798339844
Validation loss: 2.089186931169161

Epoch: 6| Step: 5
Training loss: 2.898956537246704
Validation loss: 2.089943484593463

Epoch: 6| Step: 6
Training loss: 2.1815433502197266
Validation loss: 2.0888735837833856

Epoch: 6| Step: 7
Training loss: 3.380380153656006
Validation loss: 2.0971580961699128

Epoch: 6| Step: 8
Training loss: 3.211442470550537
Validation loss: 2.112999922485762

Epoch: 6| Step: 9
Training loss: 2.850449323654175
Validation loss: 2.1353219157905987

Epoch: 6| Step: 10
Training loss: 2.2333192825317383
Validation loss: 2.144764756643644

Epoch: 6| Step: 11
Training loss: 2.381436824798584
Validation loss: 2.1586587044500534

Epoch: 6| Step: 12
Training loss: 1.9411817789077759
Validation loss: 2.168245143787835

Epoch: 6| Step: 13
Training loss: 1.9939155578613281
Validation loss: 2.1321626927262995

Epoch: 79| Step: 0
Training loss: 2.346109628677368
Validation loss: 2.124953039230839

Epoch: 6| Step: 1
Training loss: 1.9386399984359741
Validation loss: 2.1171858951609623

Epoch: 6| Step: 2
Training loss: 2.5502984523773193
Validation loss: 2.0971076450040265

Epoch: 6| Step: 3
Training loss: 1.8105225563049316
Validation loss: 2.087790737869919

Epoch: 6| Step: 4
Training loss: 2.6856908798217773
Validation loss: 2.08782059402876

Epoch: 6| Step: 5
Training loss: 3.1029090881347656
Validation loss: 2.092370888238312

Epoch: 6| Step: 6
Training loss: 2.857673406600952
Validation loss: 2.096594789976715

Epoch: 6| Step: 7
Training loss: 2.7271056175231934
Validation loss: 2.094796601162162

Epoch: 6| Step: 8
Training loss: 2.2449467182159424
Validation loss: 2.098364655689527

Epoch: 6| Step: 9
Training loss: 2.3965775966644287
Validation loss: 2.107161068147229

Epoch: 6| Step: 10
Training loss: 2.585793972015381
Validation loss: 2.1142857882284347

Epoch: 6| Step: 11
Training loss: 2.0309133529663086
Validation loss: 2.112296559477365

Epoch: 6| Step: 12
Training loss: 2.148129940032959
Validation loss: 2.129275175832933

Epoch: 6| Step: 13
Training loss: 2.3329429626464844
Validation loss: 2.128624305930189

Epoch: 80| Step: 0
Training loss: 1.7663214206695557
Validation loss: 2.1007028343856975

Epoch: 6| Step: 1
Training loss: 2.4202816486358643
Validation loss: 2.0866597826762865

Epoch: 6| Step: 2
Training loss: 2.5333127975463867
Validation loss: 2.081304327134163

Epoch: 6| Step: 3
Training loss: 3.29514217376709
Validation loss: 2.082229880876439

Epoch: 6| Step: 4
Training loss: 2.329763889312744
Validation loss: 2.079536848170783

Epoch: 6| Step: 5
Training loss: 3.220357656478882
Validation loss: 2.0749621570751233

Epoch: 6| Step: 6
Training loss: 2.336042642593384
Validation loss: 2.0803484250140447

Epoch: 6| Step: 7
Training loss: 2.197873592376709
Validation loss: 2.07690703997048

Epoch: 6| Step: 8
Training loss: 1.3147177696228027
Validation loss: 2.0873480714777464

Epoch: 6| Step: 9
Training loss: 1.9369957447052002
Validation loss: 2.091873263800016

Epoch: 6| Step: 10
Training loss: 2.973203659057617
Validation loss: 2.083795573121758

Epoch: 6| Step: 11
Training loss: 2.955022096633911
Validation loss: 2.0913993133011686

Epoch: 6| Step: 12
Training loss: 1.9461272954940796
Validation loss: 2.102237334815405

Epoch: 6| Step: 13
Training loss: 2.311021566390991
Validation loss: 2.1088792585557505

Epoch: 81| Step: 0
Training loss: 2.6037099361419678
Validation loss: 2.105465973577192

Epoch: 6| Step: 1
Training loss: 1.8077260255813599
Validation loss: 2.099157871738557

Epoch: 6| Step: 2
Training loss: 3.082382917404175
Validation loss: 2.1178360241715626

Epoch: 6| Step: 3
Training loss: 1.6917951107025146
Validation loss: 2.1423795223236084

Epoch: 6| Step: 4
Training loss: 2.227499008178711
Validation loss: 2.1341092637790147

Epoch: 6| Step: 5
Training loss: 2.404731035232544
Validation loss: 2.1178227393857894

Epoch: 6| Step: 6
Training loss: 2.9132280349731445
Validation loss: 2.09806925507002

Epoch: 6| Step: 7
Training loss: 2.6653900146484375
Validation loss: 2.0850093877443703

Epoch: 6| Step: 8
Training loss: 2.3043065071105957
Validation loss: 2.0802691623728764

Epoch: 6| Step: 9
Training loss: 2.52810001373291
Validation loss: 2.0775181606251705

Epoch: 6| Step: 10
Training loss: 2.4934744834899902
Validation loss: 2.0795025543500016

Epoch: 6| Step: 11
Training loss: 2.2537288665771484
Validation loss: 2.0678928231680267

Epoch: 6| Step: 12
Training loss: 2.210824966430664
Validation loss: 2.0889338113928355

Epoch: 6| Step: 13
Training loss: 2.2339794635772705
Validation loss: 2.086591197598365

Epoch: 82| Step: 0
Training loss: 2.4172840118408203
Validation loss: 2.096402431047091

Epoch: 6| Step: 1
Training loss: 2.088198184967041
Validation loss: 2.099506947302049

Epoch: 6| Step: 2
Training loss: 2.7537834644317627
Validation loss: 2.1009378740864415

Epoch: 6| Step: 3
Training loss: 2.505146026611328
Validation loss: 2.1038828690846763

Epoch: 6| Step: 4
Training loss: 1.8221666812896729
Validation loss: 2.110141533677296

Epoch: 6| Step: 5
Training loss: 2.319356918334961
Validation loss: 2.1139341272333616

Epoch: 6| Step: 6
Training loss: 2.5620431900024414
Validation loss: 2.120130367176507

Epoch: 6| Step: 7
Training loss: 2.547408103942871
Validation loss: 2.1366491292112615

Epoch: 6| Step: 8
Training loss: 2.8385396003723145
Validation loss: 2.1743496541054017

Epoch: 6| Step: 9
Training loss: 2.344392776489258
Validation loss: 2.210616498865107

Epoch: 6| Step: 10
Training loss: 1.7768745422363281
Validation loss: 2.229119640524669

Epoch: 6| Step: 11
Training loss: 2.4352078437805176
Validation loss: 2.214383468833021

Epoch: 6| Step: 12
Training loss: 2.188290596008301
Validation loss: 2.190737839668028

Epoch: 6| Step: 13
Training loss: 4.024526596069336
Validation loss: 2.1302944255131546

Epoch: 83| Step: 0
Training loss: 2.5542545318603516
Validation loss: 2.083527918784849

Epoch: 6| Step: 1
Training loss: 2.574901580810547
Validation loss: 2.0723659902490597

Epoch: 6| Step: 2
Training loss: 2.845500946044922
Validation loss: 2.0723546499847085

Epoch: 6| Step: 3
Training loss: 2.078403949737549
Validation loss: 2.068018795341574

Epoch: 6| Step: 4
Training loss: 2.1375555992126465
Validation loss: 2.0713466828869236

Epoch: 6| Step: 5
Training loss: 2.526765823364258
Validation loss: 2.068084469405554

Epoch: 6| Step: 6
Training loss: 2.1392953395843506
Validation loss: 2.0621999822637087

Epoch: 6| Step: 7
Training loss: 2.630218505859375
Validation loss: 2.0595686204971804

Epoch: 6| Step: 8
Training loss: 2.6504244804382324
Validation loss: 2.0642014139442035

Epoch: 6| Step: 9
Training loss: 2.279783010482788
Validation loss: 2.0696847592630694

Epoch: 6| Step: 10
Training loss: 2.786667823791504
Validation loss: 2.058353829127486

Epoch: 6| Step: 11
Training loss: 2.270949363708496
Validation loss: 2.059452023557437

Epoch: 6| Step: 12
Training loss: 1.9587383270263672
Validation loss: 2.0587190658815446

Epoch: 6| Step: 13
Training loss: 2.1468188762664795
Validation loss: 2.0709177755540416

Epoch: 84| Step: 0
Training loss: 2.013707399368286
Validation loss: 2.1071272101453555

Epoch: 6| Step: 1
Training loss: 2.023043394088745
Validation loss: 2.182988182190926

Epoch: 6| Step: 2
Training loss: 2.342332363128662
Validation loss: 2.232699692890208

Epoch: 6| Step: 3
Training loss: 2.7264084815979004
Validation loss: 2.2615046860069357

Epoch: 6| Step: 4
Training loss: 2.5509471893310547
Validation loss: 2.296782583318731

Epoch: 6| Step: 5
Training loss: 2.180114984512329
Validation loss: 2.327778991832528

Epoch: 6| Step: 6
Training loss: 2.844419479370117
Validation loss: 2.401364205985941

Epoch: 6| Step: 7
Training loss: 3.4411354064941406
Validation loss: 2.419599074189381

Epoch: 6| Step: 8
Training loss: 2.526682138442993
Validation loss: 2.4240851850919825

Epoch: 6| Step: 9
Training loss: 2.1856932640075684
Validation loss: 2.2859584182821293

Epoch: 6| Step: 10
Training loss: 2.211256504058838
Validation loss: 2.183386823182465

Epoch: 6| Step: 11
Training loss: 2.5775158405303955
Validation loss: 2.0864984450801725

Epoch: 6| Step: 12
Training loss: 2.4584460258483887
Validation loss: 2.0640034444870485

Epoch: 6| Step: 13
Training loss: 2.559495687484741
Validation loss: 2.066881964283605

Epoch: 85| Step: 0
Training loss: 2.0665931701660156
Validation loss: 2.0731543879355154

Epoch: 6| Step: 1
Training loss: 1.9150599241256714
Validation loss: 2.095296485449678

Epoch: 6| Step: 2
Training loss: 2.0356011390686035
Validation loss: 2.0854296043354976

Epoch: 6| Step: 3
Training loss: 2.714548110961914
Validation loss: 2.077096749377507

Epoch: 6| Step: 4
Training loss: 2.5884127616882324
Validation loss: 2.070146187659233

Epoch: 6| Step: 5
Training loss: 2.394926071166992
Validation loss: 2.0603810446236723

Epoch: 6| Step: 6
Training loss: 3.067185163497925
Validation loss: 2.0751712860599643

Epoch: 6| Step: 7
Training loss: 2.8139119148254395
Validation loss: 2.0725817065085135

Epoch: 6| Step: 8
Training loss: 2.0263006687164307
Validation loss: 2.0815771882252028

Epoch: 6| Step: 9
Training loss: 2.560744285583496
Validation loss: 2.1075286044869372

Epoch: 6| Step: 10
Training loss: 2.6695094108581543
Validation loss: 2.1370263638034945

Epoch: 6| Step: 11
Training loss: 2.3146514892578125
Validation loss: 2.1842365123892344

Epoch: 6| Step: 12
Training loss: 2.6424307823181152
Validation loss: 2.2135804301948956

Epoch: 6| Step: 13
Training loss: 2.434523582458496
Validation loss: 2.226404615627822

Epoch: 86| Step: 0
Training loss: 3.030850648880005
Validation loss: 2.215140829804123

Epoch: 6| Step: 1
Training loss: 3.080054759979248
Validation loss: 2.164133711527753

Epoch: 6| Step: 2
Training loss: 1.8979260921478271
Validation loss: 2.1198982218260407

Epoch: 6| Step: 3
Training loss: 1.904666543006897
Validation loss: 2.1156801562155447

Epoch: 6| Step: 4
Training loss: 2.167788505554199
Validation loss: 2.100807564232939

Epoch: 6| Step: 5
Training loss: 2.349097728729248
Validation loss: 2.0878344838337233

Epoch: 6| Step: 6
Training loss: 2.291325807571411
Validation loss: 2.081275739977437

Epoch: 6| Step: 7
Training loss: 2.666710376739502
Validation loss: 2.073644691897977

Epoch: 6| Step: 8
Training loss: 2.9129786491394043
Validation loss: 2.0688731478106592

Epoch: 6| Step: 9
Training loss: 1.9795442819595337
Validation loss: 2.069516446000786

Epoch: 6| Step: 10
Training loss: 2.853632926940918
Validation loss: 2.0636887345262753

Epoch: 6| Step: 11
Training loss: 1.9504402875900269
Validation loss: 2.062041267271965

Epoch: 6| Step: 12
Training loss: 2.399510383605957
Validation loss: 2.0661373215336956

Epoch: 6| Step: 13
Training loss: 2.6262500286102295
Validation loss: 2.0782967639225784

Epoch: 87| Step: 0
Training loss: 2.487092971801758
Validation loss: 2.0679796921309603

Epoch: 6| Step: 1
Training loss: 2.349430561065674
Validation loss: 2.064727951121587

Epoch: 6| Step: 2
Training loss: 2.937920093536377
Validation loss: 2.0571261195726294

Epoch: 6| Step: 3
Training loss: 1.5953606367111206
Validation loss: 2.0561880527004117

Epoch: 6| Step: 4
Training loss: 2.126584053039551
Validation loss: 2.048486184048396

Epoch: 6| Step: 5
Training loss: 1.7781453132629395
Validation loss: 2.0428655045006865

Epoch: 6| Step: 6
Training loss: 2.4352991580963135
Validation loss: 2.043959394578011

Epoch: 6| Step: 7
Training loss: 2.4477972984313965
Validation loss: 2.037679914505251

Epoch: 6| Step: 8
Training loss: 2.4335975646972656
Validation loss: 2.0395751973634124

Epoch: 6| Step: 9
Training loss: 3.1729576587677
Validation loss: 2.0432465512265443

Epoch: 6| Step: 10
Training loss: 2.105254650115967
Validation loss: 2.0502044154751684

Epoch: 6| Step: 11
Training loss: 2.4231772422790527
Validation loss: 2.064905801127034

Epoch: 6| Step: 12
Training loss: 2.589914560317993
Validation loss: 2.121583310506677

Epoch: 6| Step: 13
Training loss: 2.7896740436553955
Validation loss: 2.170244980883855

Epoch: 88| Step: 0
Training loss: 1.877549409866333
Validation loss: 2.2506058908277944

Epoch: 6| Step: 1
Training loss: 2.825179100036621
Validation loss: 2.250040344012681

Epoch: 6| Step: 2
Training loss: 2.7329418659210205
Validation loss: 2.223587679606612

Epoch: 6| Step: 3
Training loss: 2.3414177894592285
Validation loss: 2.1852588063927105

Epoch: 6| Step: 4
Training loss: 2.0352795124053955
Validation loss: 2.1640054487412974

Epoch: 6| Step: 5
Training loss: 2.5266003608703613
Validation loss: 2.118366937483511

Epoch: 6| Step: 6
Training loss: 2.6676058769226074
Validation loss: 2.0735890660234677

Epoch: 6| Step: 7
Training loss: 2.096649646759033
Validation loss: 2.0512065349086637

Epoch: 6| Step: 8
Training loss: 3.3689091205596924
Validation loss: 2.0433352121742825

Epoch: 6| Step: 9
Training loss: 2.01552152633667
Validation loss: 2.037413307415542

Epoch: 6| Step: 10
Training loss: 2.6352486610412598
Validation loss: 2.0348427321321223

Epoch: 6| Step: 11
Training loss: 2.1805782318115234
Validation loss: 2.0508241781624417

Epoch: 6| Step: 12
Training loss: 2.203352451324463
Validation loss: 2.0397872283894527

Epoch: 6| Step: 13
Training loss: 2.3185031414031982
Validation loss: 2.041765562949642

Epoch: 89| Step: 0
Training loss: 2.445265293121338
Validation loss: 2.0340029731873543

Epoch: 6| Step: 1
Training loss: 3.296863079071045
Validation loss: 2.0337410139781174

Epoch: 6| Step: 2
Training loss: 2.163039207458496
Validation loss: 2.032919942691762

Epoch: 6| Step: 3
Training loss: 2.9472994804382324
Validation loss: 2.0356336460318616

Epoch: 6| Step: 4
Training loss: 1.7808960676193237
Validation loss: 2.066387199586438

Epoch: 6| Step: 5
Training loss: 2.110487461090088
Validation loss: 2.1098430387435423

Epoch: 6| Step: 6
Training loss: 2.786452293395996
Validation loss: 2.1177685183863484

Epoch: 6| Step: 7
Training loss: 1.6324987411499023
Validation loss: 2.130743021606117

Epoch: 6| Step: 8
Training loss: 2.2865657806396484
Validation loss: 2.141629489519263

Epoch: 6| Step: 9
Training loss: 2.565431833267212
Validation loss: 2.1188228053431355

Epoch: 6| Step: 10
Training loss: 2.1540870666503906
Validation loss: 2.092664836555399

Epoch: 6| Step: 11
Training loss: 2.6323328018188477
Validation loss: 2.066090432546472

Epoch: 6| Step: 12
Training loss: 2.114579677581787
Validation loss: 2.0585765261803903

Epoch: 6| Step: 13
Training loss: 2.636589527130127
Validation loss: 2.068684322859651

Epoch: 90| Step: 0
Training loss: 2.141328811645508
Validation loss: 2.069161956028272

Epoch: 6| Step: 1
Training loss: 3.086362838745117
Validation loss: 2.09798454084704

Epoch: 6| Step: 2
Training loss: 2.1989755630493164
Validation loss: 2.087077902209374

Epoch: 6| Step: 3
Training loss: 2.23325777053833
Validation loss: 2.0866238147981706

Epoch: 6| Step: 4
Training loss: 2.760542392730713
Validation loss: 2.113309862793133

Epoch: 6| Step: 5
Training loss: 1.4340717792510986
Validation loss: 2.090379233001381

Epoch: 6| Step: 6
Training loss: 2.762454032897949
Validation loss: 2.0456203209456576

Epoch: 6| Step: 7
Training loss: 1.8962934017181396
Validation loss: 2.037583233207785

Epoch: 6| Step: 8
Training loss: 2.7688918113708496
Validation loss: 2.0319465206515406

Epoch: 6| Step: 9
Training loss: 1.890791893005371
Validation loss: 2.025556686103985

Epoch: 6| Step: 10
Training loss: 2.610029935836792
Validation loss: 2.029561012021957

Epoch: 6| Step: 11
Training loss: 2.6603219509124756
Validation loss: 2.0276238995213665

Epoch: 6| Step: 12
Training loss: 2.2945618629455566
Validation loss: 2.0215261341423116

Epoch: 6| Step: 13
Training loss: 2.5379085540771484
Validation loss: 2.028063117816884

Epoch: 91| Step: 0
Training loss: 2.076606273651123
Validation loss: 2.0254791936566754

Epoch: 6| Step: 1
Training loss: 2.000778913497925
Validation loss: 2.0419947767770417

Epoch: 6| Step: 2
Training loss: 2.592862606048584
Validation loss: 2.065394596386981

Epoch: 6| Step: 3
Training loss: 2.266598701477051
Validation loss: 2.0783943591579312

Epoch: 6| Step: 4
Training loss: 1.8781874179840088
Validation loss: 2.0843580294680852

Epoch: 6| Step: 5
Training loss: 2.5657410621643066
Validation loss: 2.066870882946958

Epoch: 6| Step: 6
Training loss: 3.2318592071533203
Validation loss: 2.0522104117178146

Epoch: 6| Step: 7
Training loss: 2.74904203414917
Validation loss: 2.0400034637861353

Epoch: 6| Step: 8
Training loss: 2.7673165798187256
Validation loss: 2.0324398292008268

Epoch: 6| Step: 9
Training loss: 2.5887515544891357
Validation loss: 2.015377195932532

Epoch: 6| Step: 10
Training loss: 1.2363827228546143
Validation loss: 2.020827098559308

Epoch: 6| Step: 11
Training loss: 2.392385959625244
Validation loss: 2.0250779403153287

Epoch: 6| Step: 12
Training loss: 2.3555235862731934
Validation loss: 2.0260070728999313

Epoch: 6| Step: 13
Training loss: 2.5472707748413086
Validation loss: 2.016224076670985

Epoch: 92| Step: 0
Training loss: 2.4116506576538086
Validation loss: 2.025013731371972

Epoch: 6| Step: 1
Training loss: 2.1317524909973145
Validation loss: 2.019937910059447

Epoch: 6| Step: 2
Training loss: 2.506798028945923
Validation loss: 2.029798794818181

Epoch: 6| Step: 3
Training loss: 1.978712558746338
Validation loss: 2.0306901572853007

Epoch: 6| Step: 4
Training loss: 2.624530553817749
Validation loss: 2.0371941212684876

Epoch: 6| Step: 5
Training loss: 2.837101936340332
Validation loss: 2.0313093995535247

Epoch: 6| Step: 6
Training loss: 2.226294994354248
Validation loss: 2.0469263727946947

Epoch: 6| Step: 7
Training loss: 1.7487568855285645
Validation loss: 2.063981017758769

Epoch: 6| Step: 8
Training loss: 1.6302294731140137
Validation loss: 2.0743351995304065

Epoch: 6| Step: 9
Training loss: 2.268986463546753
Validation loss: 2.100767530420775

Epoch: 6| Step: 10
Training loss: 2.5515339374542236
Validation loss: 2.12968768612031

Epoch: 6| Step: 11
Training loss: 2.7218081951141357
Validation loss: 2.159808938221265

Epoch: 6| Step: 12
Training loss: 2.661907196044922
Validation loss: 2.130556485986197

Epoch: 6| Step: 13
Training loss: 2.9400503635406494
Validation loss: 2.120120236950536

Epoch: 93| Step: 0
Training loss: 3.256291151046753
Validation loss: 2.0992826748919744

Epoch: 6| Step: 1
Training loss: 2.1590380668640137
Validation loss: 2.0617420929734425

Epoch: 6| Step: 2
Training loss: 2.3854594230651855
Validation loss: 2.0431087529787453

Epoch: 6| Step: 3
Training loss: 2.3638064861297607
Validation loss: 2.0252604779376777

Epoch: 6| Step: 4
Training loss: 2.6193838119506836
Validation loss: 2.01412808510565

Epoch: 6| Step: 5
Training loss: 1.7371817827224731
Validation loss: 2.023123477094917

Epoch: 6| Step: 6
Training loss: 2.635673999786377
Validation loss: 2.0216864757640387

Epoch: 6| Step: 7
Training loss: 2.455610752105713
Validation loss: 2.0229060162780104

Epoch: 6| Step: 8
Training loss: 2.4162354469299316
Validation loss: 2.0343514873135473

Epoch: 6| Step: 9
Training loss: 1.6644456386566162
Validation loss: 2.0288553827552387

Epoch: 6| Step: 10
Training loss: 2.4355716705322266
Validation loss: 2.0262596735390286

Epoch: 6| Step: 11
Training loss: 2.325410842895508
Validation loss: 2.0298117232579056

Epoch: 6| Step: 12
Training loss: 2.5097339153289795
Validation loss: 2.031188065005887

Epoch: 6| Step: 13
Training loss: 2.107428550720215
Validation loss: 2.0290899840734338

Epoch: 94| Step: 0
Training loss: 2.8130080699920654
Validation loss: 2.0363682085467922

Epoch: 6| Step: 1
Training loss: 1.9342671632766724
Validation loss: 2.0469105230864657

Epoch: 6| Step: 2
Training loss: 2.2313337326049805
Validation loss: 2.0669570981815295

Epoch: 6| Step: 3
Training loss: 2.333178997039795
Validation loss: 2.0759405807782243

Epoch: 6| Step: 4
Training loss: 2.1239442825317383
Validation loss: 2.0846185556022068

Epoch: 6| Step: 5
Training loss: 2.3374433517456055
Validation loss: 2.084350985865439

Epoch: 6| Step: 6
Training loss: 1.911128282546997
Validation loss: 2.080209324436803

Epoch: 6| Step: 7
Training loss: 1.7367266416549683
Validation loss: 2.078058727325932

Epoch: 6| Step: 8
Training loss: 2.6329383850097656
Validation loss: 2.0768492939651653

Epoch: 6| Step: 9
Training loss: 2.4562020301818848
Validation loss: 2.065963327243764

Epoch: 6| Step: 10
Training loss: 2.9300084114074707
Validation loss: 2.055742811131221

Epoch: 6| Step: 11
Training loss: 2.1090474128723145
Validation loss: 2.0576366378415014

Epoch: 6| Step: 12
Training loss: 2.8861124515533447
Validation loss: 2.082944626449257

Epoch: 6| Step: 13
Training loss: 2.9707159996032715
Validation loss: 2.0933979429224485

Epoch: 95| Step: 0
Training loss: 2.7956085205078125
Validation loss: 2.087156420112938

Epoch: 6| Step: 1
Training loss: 2.3310301303863525
Validation loss: 2.0855482842332576

Epoch: 6| Step: 2
Training loss: 2.2771315574645996
Validation loss: 2.0731574950679654

Epoch: 6| Step: 3
Training loss: 2.060647487640381
Validation loss: 2.0583134351238126

Epoch: 6| Step: 4
Training loss: 2.5130727291107178
Validation loss: 2.047675548061248

Epoch: 6| Step: 5
Training loss: 2.581035614013672
Validation loss: 2.034608943488008

Epoch: 6| Step: 6
Training loss: 1.8947105407714844
Validation loss: 2.052970540138983

Epoch: 6| Step: 7
Training loss: 2.2101187705993652
Validation loss: 2.045702898374168

Epoch: 6| Step: 8
Training loss: 2.7431979179382324
Validation loss: 2.026964338876868

Epoch: 6| Step: 9
Training loss: 1.3969902992248535
Validation loss: 2.0186053527298795

Epoch: 6| Step: 10
Training loss: 2.541332721710205
Validation loss: 2.0084136480926187

Epoch: 6| Step: 11
Training loss: 1.9434436559677124
Validation loss: 1.9977826303051365

Epoch: 6| Step: 12
Training loss: 3.065870761871338
Validation loss: 2.0027573083036687

Epoch: 6| Step: 13
Training loss: 2.2617170810699463
Validation loss: 2.0025880618761946

Epoch: 96| Step: 0
Training loss: 1.7749568223953247
Validation loss: 2.0036404568661927

Epoch: 6| Step: 1
Training loss: 2.681408405303955
Validation loss: 1.9996049404144287

Epoch: 6| Step: 2
Training loss: 2.1531691551208496
Validation loss: 2.0079656288187993

Epoch: 6| Step: 3
Training loss: 1.9554263353347778
Validation loss: 2.015448033168752

Epoch: 6| Step: 4
Training loss: 2.223395586013794
Validation loss: 2.0400803319869505

Epoch: 6| Step: 5
Training loss: 2.7542543411254883
Validation loss: 2.0779670207731185

Epoch: 6| Step: 6
Training loss: 2.857369899749756
Validation loss: 2.0943159877613025

Epoch: 6| Step: 7
Training loss: 2.374368906021118
Validation loss: 2.087618799619777

Epoch: 6| Step: 8
Training loss: 1.91160249710083
Validation loss: 2.083176574399394

Epoch: 6| Step: 9
Training loss: 1.7963645458221436
Validation loss: 2.0703588365226664

Epoch: 6| Step: 10
Training loss: 2.6906702518463135
Validation loss: 2.043851016670145

Epoch: 6| Step: 11
Training loss: 2.387956380844116
Validation loss: 2.030838909969535

Epoch: 6| Step: 12
Training loss: 2.7195892333984375
Validation loss: 2.0233108843526533

Epoch: 6| Step: 13
Training loss: 3.004357099533081
Validation loss: 2.0297862099063013

Epoch: 97| Step: 0
Training loss: 2.8436741828918457
Validation loss: 2.0159819946494153

Epoch: 6| Step: 1
Training loss: 2.532238483428955
Validation loss: 2.020783567941317

Epoch: 6| Step: 2
Training loss: 2.206193208694458
Validation loss: 2.015998782650117

Epoch: 6| Step: 3
Training loss: 2.812918186187744
Validation loss: 2.021305496974658

Epoch: 6| Step: 4
Training loss: 2.060408115386963
Validation loss: 2.0159218798401537

Epoch: 6| Step: 5
Training loss: 3.0394105911254883
Validation loss: 2.020085072004667

Epoch: 6| Step: 6
Training loss: 1.6721935272216797
Validation loss: 2.0224317594241072

Epoch: 6| Step: 7
Training loss: 2.65786075592041
Validation loss: 2.017735619698801

Epoch: 6| Step: 8
Training loss: 2.4718291759490967
Validation loss: 2.028834928748428

Epoch: 6| Step: 9
Training loss: 1.6987929344177246
Validation loss: 2.030065478817109

Epoch: 6| Step: 10
Training loss: 1.9372084140777588
Validation loss: 2.0328697004625873

Epoch: 6| Step: 11
Training loss: 2.241969108581543
Validation loss: 2.0261095544343353

Epoch: 6| Step: 12
Training loss: 2.3167922496795654
Validation loss: 2.014190414900421

Epoch: 6| Step: 13
Training loss: 2.537447929382324
Validation loss: 2.0087696865040767

Epoch: 98| Step: 0
Training loss: 2.697493314743042
Validation loss: 2.0023606054244505

Epoch: 6| Step: 1
Training loss: 2.1906356811523438
Validation loss: 2.0153005712775776

Epoch: 6| Step: 2
Training loss: 2.9458603858947754
Validation loss: 2.034268538157145

Epoch: 6| Step: 3
Training loss: 3.1947760581970215
Validation loss: 2.0445903501202984

Epoch: 6| Step: 4
Training loss: 1.988286018371582
Validation loss: 2.057014678114204

Epoch: 6| Step: 5
Training loss: 2.323770523071289
Validation loss: 2.043252129708567

Epoch: 6| Step: 6
Training loss: 2.530452251434326
Validation loss: 2.0447175284867645

Epoch: 6| Step: 7
Training loss: 1.6661299467086792
Validation loss: 2.052715439950266

Epoch: 6| Step: 8
Training loss: 1.84320068359375
Validation loss: 2.035578320103307

Epoch: 6| Step: 9
Training loss: 2.387327194213867
Validation loss: 2.0311665893882833

Epoch: 6| Step: 10
Training loss: 2.413419723510742
Validation loss: 2.0055868318003993

Epoch: 6| Step: 11
Training loss: 1.9122440814971924
Validation loss: 2.004708851537397

Epoch: 6| Step: 12
Training loss: 2.33359432220459
Validation loss: 1.9983625476078322

Epoch: 6| Step: 13
Training loss: 2.0722546577453613
Validation loss: 1.987575525878578

Epoch: 99| Step: 0
Training loss: 2.298572540283203
Validation loss: 1.9816261773468347

Epoch: 6| Step: 1
Training loss: 2.5436959266662598
Validation loss: 1.9928355960435764

Epoch: 6| Step: 2
Training loss: 2.03108549118042
Validation loss: 1.9923331583699873

Epoch: 6| Step: 3
Training loss: 1.8908355236053467
Validation loss: 1.9843587080637615

Epoch: 6| Step: 4
Training loss: 2.1996912956237793
Validation loss: 1.9918754228981592

Epoch: 6| Step: 5
Training loss: 2.0130414962768555
Validation loss: 2.0039039888689594

Epoch: 6| Step: 6
Training loss: 2.724161148071289
Validation loss: 2.0165970812561693

Epoch: 6| Step: 7
Training loss: 2.133141040802002
Validation loss: 2.021595411403205

Epoch: 6| Step: 8
Training loss: 2.216801166534424
Validation loss: 2.0290514064091507

Epoch: 6| Step: 9
Training loss: 2.863023519515991
Validation loss: 2.028236663469704

Epoch: 6| Step: 10
Training loss: 2.4665300846099854
Validation loss: 2.031081041982097

Epoch: 6| Step: 11
Training loss: 1.9098988771438599
Validation loss: 2.022120452696277

Epoch: 6| Step: 12
Training loss: 2.7537522315979004
Validation loss: 2.02162479969763

Epoch: 6| Step: 13
Training loss: 2.3340258598327637
Validation loss: 2.021163850702265

Epoch: 100| Step: 0
Training loss: 2.0802760124206543
Validation loss: 2.0236979889613327

Epoch: 6| Step: 1
Training loss: 2.6023964881896973
Validation loss: 2.0142637580953617

Epoch: 6| Step: 2
Training loss: 2.421651601791382
Validation loss: 2.0038855152745403

Epoch: 6| Step: 3
Training loss: 2.323519229888916
Validation loss: 1.9906392276927989

Epoch: 6| Step: 4
Training loss: 2.193453311920166
Validation loss: 1.9838842127912788

Epoch: 6| Step: 5
Training loss: 2.1922976970672607
Validation loss: 1.9820763539242487

Epoch: 6| Step: 6
Training loss: 1.7437002658843994
Validation loss: 1.9767278189300208

Epoch: 6| Step: 7
Training loss: 1.7268214225769043
Validation loss: 1.9816553669591104

Epoch: 6| Step: 8
Training loss: 2.6725072860717773
Validation loss: 1.982767456321306

Epoch: 6| Step: 9
Training loss: 3.079113006591797
Validation loss: 1.985286743410172

Epoch: 6| Step: 10
Training loss: 2.1176586151123047
Validation loss: 1.9899018464549896

Epoch: 6| Step: 11
Training loss: 2.4694433212280273
Validation loss: 2.005650310106175

Epoch: 6| Step: 12
Training loss: 2.3260998725891113
Validation loss: 1.9799169173804663

Epoch: 6| Step: 13
Training loss: 2.55700945854187
Validation loss: 1.9763245121125252

Testing loss: 2.2987858560350207
