Epoch: 1| Step: 0
Training loss: 4.877528190612793
Validation loss: 5.207403844402682

Epoch: 6| Step: 1
Training loss: 6.290382385253906
Validation loss: 5.180460155651134

Epoch: 6| Step: 2
Training loss: 4.447488307952881
Validation loss: 5.157114346822103

Epoch: 6| Step: 3
Training loss: 4.033447742462158
Validation loss: 5.132345896895214

Epoch: 6| Step: 4
Training loss: 4.994153022766113
Validation loss: 5.104064300496091

Epoch: 6| Step: 5
Training loss: 4.267794609069824
Validation loss: 5.072714528729839

Epoch: 6| Step: 6
Training loss: 4.0595502853393555
Validation loss: 5.03729239843225

Epoch: 6| Step: 7
Training loss: 3.9680540561676025
Validation loss: 4.997589367692188

Epoch: 6| Step: 8
Training loss: 6.2008161544799805
Validation loss: 4.955190489369054

Epoch: 6| Step: 9
Training loss: 5.376504421234131
Validation loss: 4.9084854741250314

Epoch: 6| Step: 10
Training loss: 5.616405010223389
Validation loss: 4.857434600912114

Epoch: 6| Step: 11
Training loss: 4.376958847045898
Validation loss: 4.801512656673308

Epoch: 6| Step: 12
Training loss: 4.398075103759766
Validation loss: 4.742466475373956

Epoch: 6| Step: 13
Training loss: 3.662459373474121
Validation loss: 4.683846548039426

Epoch: 2| Step: 0
Training loss: 3.9100749492645264
Validation loss: 4.623298998801939

Epoch: 6| Step: 1
Training loss: 5.435308933258057
Validation loss: 4.561674533351775

Epoch: 6| Step: 2
Training loss: 3.9709725379943848
Validation loss: 4.499583685269919

Epoch: 6| Step: 3
Training loss: 4.296839714050293
Validation loss: 4.440439557516447

Epoch: 6| Step: 4
Training loss: 4.725466728210449
Validation loss: 4.381312462591356

Epoch: 6| Step: 5
Training loss: 3.3352880477905273
Validation loss: 4.324706062193839

Epoch: 6| Step: 6
Training loss: 4.77524471282959
Validation loss: 4.274232513161116

Epoch: 6| Step: 7
Training loss: 3.387033224105835
Validation loss: 4.221932267629972

Epoch: 6| Step: 8
Training loss: 4.84343147277832
Validation loss: 4.173089506805584

Epoch: 6| Step: 9
Training loss: 4.616069793701172
Validation loss: 4.128015013151272

Epoch: 6| Step: 10
Training loss: 4.605589389801025
Validation loss: 4.081583630654119

Epoch: 6| Step: 11
Training loss: 3.2696707248687744
Validation loss: 4.037173830052858

Epoch: 6| Step: 12
Training loss: 2.8145806789398193
Validation loss: 3.986974157312865

Epoch: 6| Step: 13
Training loss: 2.68108868598938
Validation loss: 3.9501409633185274

Epoch: 3| Step: 0
Training loss: 4.177292823791504
Validation loss: 3.92214451554001

Epoch: 6| Step: 1
Training loss: 3.8625473976135254
Validation loss: 3.897417381245603

Epoch: 6| Step: 2
Training loss: 3.556276559829712
Validation loss: 3.8732589957534627

Epoch: 6| Step: 3
Training loss: 3.791245937347412
Validation loss: 3.8465598321730092

Epoch: 6| Step: 4
Training loss: 3.910825729370117
Validation loss: 3.8187188871445192

Epoch: 6| Step: 5
Training loss: 3.5422186851501465
Validation loss: 3.7936196019572597

Epoch: 6| Step: 6
Training loss: 3.2581987380981445
Validation loss: 3.7717570591998357

Epoch: 6| Step: 7
Training loss: 3.7955286502838135
Validation loss: 3.7514927694874425

Epoch: 6| Step: 8
Training loss: 2.1312150955200195
Validation loss: 3.7262415014287478

Epoch: 6| Step: 9
Training loss: 5.321425914764404
Validation loss: 3.7049459436888337

Epoch: 6| Step: 10
Training loss: 2.854987621307373
Validation loss: 3.6798013307714976

Epoch: 6| Step: 11
Training loss: 3.5884146690368652
Validation loss: 3.655216101677187

Epoch: 6| Step: 12
Training loss: 3.256758451461792
Validation loss: 3.6211566796866794

Epoch: 6| Step: 13
Training loss: 4.470940589904785
Validation loss: 3.5914380217111237

Epoch: 4| Step: 0
Training loss: 2.82209849357605
Validation loss: 3.57175624498757

Epoch: 6| Step: 1
Training loss: 2.8866357803344727
Validation loss: 3.565151324836157

Epoch: 6| Step: 2
Training loss: 3.365159034729004
Validation loss: 3.5504664631300074

Epoch: 6| Step: 3
Training loss: 3.5072784423828125
Validation loss: 3.5303321217977874

Epoch: 6| Step: 4
Training loss: 2.717325210571289
Validation loss: 3.510942212996944

Epoch: 6| Step: 5
Training loss: 3.424628973007202
Validation loss: 3.5018090740326913

Epoch: 6| Step: 6
Training loss: 2.8529415130615234
Validation loss: 3.492755869383453

Epoch: 6| Step: 7
Training loss: 3.554431200027466
Validation loss: 3.4763501126279115

Epoch: 6| Step: 8
Training loss: 4.700990200042725
Validation loss: 3.4623160849335375

Epoch: 6| Step: 9
Training loss: 2.6667284965515137
Validation loss: 3.446278187536424

Epoch: 6| Step: 10
Training loss: 3.9622654914855957
Validation loss: 3.4288069458417993

Epoch: 6| Step: 11
Training loss: 3.858013391494751
Validation loss: 3.4196549128460627

Epoch: 6| Step: 12
Training loss: 3.8391852378845215
Validation loss: 3.405287952833278

Epoch: 6| Step: 13
Training loss: 3.8874964714050293
Validation loss: 3.3882168031507924

Epoch: 5| Step: 0
Training loss: 2.6423563957214355
Validation loss: 3.3898787037018807

Epoch: 6| Step: 1
Training loss: 3.6258509159088135
Validation loss: 3.367740185030045

Epoch: 6| Step: 2
Training loss: 3.034644365310669
Validation loss: 3.358612870657316

Epoch: 6| Step: 3
Training loss: 2.278383255004883
Validation loss: 3.3518088453559467

Epoch: 6| Step: 4
Training loss: 3.2184581756591797
Validation loss: 3.351976410035164

Epoch: 6| Step: 5
Training loss: 3.2194430828094482
Validation loss: 3.3329152445639334

Epoch: 6| Step: 6
Training loss: 3.000762462615967
Validation loss: 3.3248182445444088

Epoch: 6| Step: 7
Training loss: 3.606459617614746
Validation loss: 3.310482589147424

Epoch: 6| Step: 8
Training loss: 3.16825532913208
Validation loss: 3.299580302289737

Epoch: 6| Step: 9
Training loss: 3.4373903274536133
Validation loss: 3.289309973357826

Epoch: 6| Step: 10
Training loss: 3.1749331951141357
Validation loss: 3.281982724384595

Epoch: 6| Step: 11
Training loss: 3.1899538040161133
Validation loss: 3.2652412717060377

Epoch: 6| Step: 12
Training loss: 4.315361022949219
Validation loss: 3.2652034041702107

Epoch: 6| Step: 13
Training loss: 4.5795183181762695
Validation loss: 3.2582757293537097

Epoch: 6| Step: 0
Training loss: 2.6070480346679688
Validation loss: 3.2355794880979802

Epoch: 6| Step: 1
Training loss: 3.9039034843444824
Validation loss: 3.249166173319663

Epoch: 6| Step: 2
Training loss: 2.8797457218170166
Validation loss: 3.2249367314000286

Epoch: 6| Step: 3
Training loss: 3.153456926345825
Validation loss: 3.2269243886393886

Epoch: 6| Step: 4
Training loss: 2.418487310409546
Validation loss: 3.2176995713223695

Epoch: 6| Step: 5
Training loss: 4.630909442901611
Validation loss: 3.21676561140245

Epoch: 6| Step: 6
Training loss: 3.345952272415161
Validation loss: 3.197133602634553

Epoch: 6| Step: 7
Training loss: 2.978837013244629
Validation loss: 3.186468260262602

Epoch: 6| Step: 8
Training loss: 2.718043088912964
Validation loss: 3.1952671799608456

Epoch: 6| Step: 9
Training loss: 3.523529291152954
Validation loss: 3.1828720005609656

Epoch: 6| Step: 10
Training loss: 2.1356539726257324
Validation loss: 3.1573680498266734

Epoch: 6| Step: 11
Training loss: 4.203075408935547
Validation loss: 3.157404743215089

Epoch: 6| Step: 12
Training loss: 2.50453782081604
Validation loss: 3.154800873930736

Epoch: 6| Step: 13
Training loss: 4.159379482269287
Validation loss: 3.163897734816356

Epoch: 7| Step: 0
Training loss: 3.7055890560150146
Validation loss: 3.157758556386476

Epoch: 6| Step: 1
Training loss: 3.783742904663086
Validation loss: 3.130744141917075

Epoch: 6| Step: 2
Training loss: 2.789456367492676
Validation loss: 3.113693550068845

Epoch: 6| Step: 3
Training loss: 4.0591325759887695
Validation loss: 3.1232141089695755

Epoch: 6| Step: 4
Training loss: 3.256861925125122
Validation loss: 3.103785594304403

Epoch: 6| Step: 5
Training loss: 2.538161516189575
Validation loss: 3.097560792840937

Epoch: 6| Step: 6
Training loss: 3.68192195892334
Validation loss: 3.0803839724550963

Epoch: 6| Step: 7
Training loss: 2.1805307865142822
Validation loss: 3.069998759095387

Epoch: 6| Step: 8
Training loss: 3.174936532974243
Validation loss: 3.073467593039236

Epoch: 6| Step: 9
Training loss: 3.4811465740203857
Validation loss: 3.0662897120239916

Epoch: 6| Step: 10
Training loss: 3.2826647758483887
Validation loss: 3.059294080221525

Epoch: 6| Step: 11
Training loss: 2.4290242195129395
Validation loss: 3.053375300540719

Epoch: 6| Step: 12
Training loss: 2.488731861114502
Validation loss: 3.0411033553461873

Epoch: 6| Step: 13
Training loss: 2.727539539337158
Validation loss: 3.042147877395794

Epoch: 8| Step: 0
Training loss: 3.3713529109954834
Validation loss: 3.0480437304383967

Epoch: 6| Step: 1
Training loss: 2.5652663707733154
Validation loss: 3.037877990353492

Epoch: 6| Step: 2
Training loss: 2.694054126739502
Validation loss: 3.0256114313679356

Epoch: 6| Step: 3
Training loss: 3.394831418991089
Validation loss: 3.023947551686277

Epoch: 6| Step: 4
Training loss: 2.9020423889160156
Validation loss: 3.014811715772075

Epoch: 6| Step: 5
Training loss: 3.1226649284362793
Validation loss: 3.01459212200616

Epoch: 6| Step: 6
Training loss: 3.5393998622894287
Validation loss: 3.0065672371977117

Epoch: 6| Step: 7
Training loss: 3.680356502532959
Validation loss: 2.9975446552358647

Epoch: 6| Step: 8
Training loss: 3.8730008602142334
Validation loss: 2.98786356372218

Epoch: 6| Step: 9
Training loss: 2.813338041305542
Validation loss: 2.989010533978862

Epoch: 6| Step: 10
Training loss: 2.8584327697753906
Validation loss: 2.9851052889259915

Epoch: 6| Step: 11
Training loss: 3.109921932220459
Validation loss: 3.0217208605940624

Epoch: 6| Step: 12
Training loss: 2.126986026763916
Validation loss: 2.9916480254101496

Epoch: 6| Step: 13
Training loss: 2.8745298385620117
Validation loss: 2.968524202223747

Epoch: 9| Step: 0
Training loss: 2.8828444480895996
Validation loss: 2.967090045252154

Epoch: 6| Step: 1
Training loss: 2.0346643924713135
Validation loss: 2.972466294483472

Epoch: 6| Step: 2
Training loss: 3.024941921234131
Validation loss: 2.9829431810686664

Epoch: 6| Step: 3
Training loss: 3.2462105751037598
Validation loss: 2.979533544150732

Epoch: 6| Step: 4
Training loss: 2.729707717895508
Validation loss: 2.959343910217285

Epoch: 6| Step: 5
Training loss: 3.8128082752227783
Validation loss: 2.947237765917214

Epoch: 6| Step: 6
Training loss: 3.37332820892334
Validation loss: 2.947604730565061

Epoch: 6| Step: 7
Training loss: 2.6427512168884277
Validation loss: 2.9547114090252946

Epoch: 6| Step: 8
Training loss: 3.322885274887085
Validation loss: 2.959415017917592

Epoch: 6| Step: 9
Training loss: 3.2070724964141846
Validation loss: 2.9456212725690616

Epoch: 6| Step: 10
Training loss: 2.1070785522460938
Validation loss: 2.946312273702314

Epoch: 6| Step: 11
Training loss: 3.234104633331299
Validation loss: 2.9835086176472325

Epoch: 6| Step: 12
Training loss: 3.237992286682129
Validation loss: 2.986146383388068

Epoch: 6| Step: 13
Training loss: 4.25805139541626
Validation loss: 2.9750050703684487

Epoch: 10| Step: 0
Training loss: 3.4833569526672363
Validation loss: 2.947104905241279

Epoch: 6| Step: 1
Training loss: 3.1114559173583984
Validation loss: 2.927432603733514

Epoch: 6| Step: 2
Training loss: 1.973369836807251
Validation loss: 2.93103596215607

Epoch: 6| Step: 3
Training loss: 2.763120174407959
Validation loss: 2.9447948983920518

Epoch: 6| Step: 4
Training loss: 2.7968926429748535
Validation loss: 2.9830878421824467

Epoch: 6| Step: 5
Training loss: 3.5278563499450684
Validation loss: 2.9468394120534263

Epoch: 6| Step: 6
Training loss: 3.6730170249938965
Validation loss: 2.9315396380680863

Epoch: 6| Step: 7
Training loss: 3.19791316986084
Validation loss: 2.924257247678695

Epoch: 6| Step: 8
Training loss: 2.4951224327087402
Validation loss: 2.926593203698435

Epoch: 6| Step: 9
Training loss: 4.138672828674316
Validation loss: 2.932393766218616

Epoch: 6| Step: 10
Training loss: 3.4619839191436768
Validation loss: 2.9320806892969276

Epoch: 6| Step: 11
Training loss: 3.0069057941436768
Validation loss: 2.9214395425652944

Epoch: 6| Step: 12
Training loss: 2.0014171600341797
Validation loss: 2.9108848853777816

Epoch: 6| Step: 13
Training loss: 2.330138921737671
Validation loss: 2.9032112347182406

Epoch: 11| Step: 0
Training loss: 3.954012393951416
Validation loss: 2.9019015348085793

Epoch: 6| Step: 1
Training loss: 2.122002601623535
Validation loss: 2.89549845264804

Epoch: 6| Step: 2
Training loss: 2.9639766216278076
Validation loss: 2.897279316379178

Epoch: 6| Step: 3
Training loss: 3.986255645751953
Validation loss: 2.8897689439917125

Epoch: 6| Step: 4
Training loss: 3.1214776039123535
Validation loss: 2.8843858652217413

Epoch: 6| Step: 5
Training loss: 3.209610939025879
Validation loss: 2.8798198161586637

Epoch: 6| Step: 6
Training loss: 2.174657106399536
Validation loss: 2.877954629159743

Epoch: 6| Step: 7
Training loss: 2.8541224002838135
Validation loss: 2.8718513827170096

Epoch: 6| Step: 8
Training loss: 3.3167922496795654
Validation loss: 2.869529552357171

Epoch: 6| Step: 9
Training loss: 2.2343287467956543
Validation loss: 2.8624327567315873

Epoch: 6| Step: 10
Training loss: 1.9222204685211182
Validation loss: 2.8636552697868756

Epoch: 6| Step: 11
Training loss: 3.6183295249938965
Validation loss: 2.8638575435966573

Epoch: 6| Step: 12
Training loss: 3.3126039505004883
Validation loss: 2.8580957920320573

Epoch: 6| Step: 13
Training loss: 2.9053173065185547
Validation loss: 2.8524792168730047

Epoch: 12| Step: 0
Training loss: 2.4399499893188477
Validation loss: 2.85231460807144

Epoch: 6| Step: 1
Training loss: 2.3046700954437256
Validation loss: 2.84749073366965

Epoch: 6| Step: 2
Training loss: 2.951495885848999
Validation loss: 2.8502943541413996

Epoch: 6| Step: 3
Training loss: 3.871678352355957
Validation loss: 2.848526952087238

Epoch: 6| Step: 4
Training loss: 2.700256586074829
Validation loss: 2.8473491155973045

Epoch: 6| Step: 5
Training loss: 3.2641265392303467
Validation loss: 2.840104313306911

Epoch: 6| Step: 6
Training loss: 2.4067959785461426
Validation loss: 2.8393135480983283

Epoch: 6| Step: 7
Training loss: 3.2709269523620605
Validation loss: 2.841344230918474

Epoch: 6| Step: 8
Training loss: 3.8576388359069824
Validation loss: 2.844809078401135

Epoch: 6| Step: 9
Training loss: 2.2907204627990723
Validation loss: 2.8416566489845194

Epoch: 6| Step: 10
Training loss: 3.492114543914795
Validation loss: 2.8339665833339898

Epoch: 6| Step: 11
Training loss: 2.8428256511688232
Validation loss: 2.8275106568490305

Epoch: 6| Step: 12
Training loss: 2.8201375007629395
Validation loss: 2.8257185746264715

Epoch: 6| Step: 13
Training loss: 2.8124077320098877
Validation loss: 2.8206014043541363

Epoch: 13| Step: 0
Training loss: 2.653512716293335
Validation loss: 2.8190547676496607

Epoch: 6| Step: 1
Training loss: 3.0883946418762207
Validation loss: 2.8165729353504796

Epoch: 6| Step: 2
Training loss: 2.9068901538848877
Validation loss: 2.8149902538586686

Epoch: 6| Step: 3
Training loss: 3.0491342544555664
Validation loss: 2.8099287299699682

Epoch: 6| Step: 4
Training loss: 3.6323070526123047
Validation loss: 2.8114928737763436

Epoch: 6| Step: 5
Training loss: 3.2054319381713867
Validation loss: 2.8070022547116844

Epoch: 6| Step: 6
Training loss: 3.158937931060791
Validation loss: 2.805569356487643

Epoch: 6| Step: 7
Training loss: 2.4548051357269287
Validation loss: 2.8055671350930327

Epoch: 6| Step: 8
Training loss: 2.1137962341308594
Validation loss: 2.8044056277121268

Epoch: 6| Step: 9
Training loss: 3.222560167312622
Validation loss: 2.804026460134855

Epoch: 6| Step: 10
Training loss: 3.433305501937866
Validation loss: 2.803019085238057

Epoch: 6| Step: 11
Training loss: 2.6397666931152344
Validation loss: 2.8082767327626548

Epoch: 6| Step: 12
Training loss: 3.1148712635040283
Validation loss: 2.8404266475349345

Epoch: 6| Step: 13
Training loss: 2.0713295936584473
Validation loss: 2.8582279912887083

Epoch: 14| Step: 0
Training loss: 3.570906162261963
Validation loss: 2.8666182538514495

Epoch: 6| Step: 1
Training loss: 2.874516010284424
Validation loss: 2.8465329985464773

Epoch: 6| Step: 2
Training loss: 3.1340150833129883
Validation loss: 2.8343080653939197

Epoch: 6| Step: 3
Training loss: 3.27246356010437
Validation loss: 2.8312396131536013

Epoch: 6| Step: 4
Training loss: 3.2518653869628906
Validation loss: 2.824716680793352

Epoch: 6| Step: 5
Training loss: 3.1376559734344482
Validation loss: 2.8212642823496172

Epoch: 6| Step: 6
Training loss: 2.595559597015381
Validation loss: 2.8256924947102866

Epoch: 6| Step: 7
Training loss: 2.6555957794189453
Validation loss: 2.827697374487436

Epoch: 6| Step: 8
Training loss: 2.8400321006774902
Validation loss: 2.8234707386262956

Epoch: 6| Step: 9
Training loss: 2.574192762374878
Validation loss: 2.8210978456722793

Epoch: 6| Step: 10
Training loss: 3.592829465866089
Validation loss: 2.8210415224875174

Epoch: 6| Step: 11
Training loss: 2.8605356216430664
Validation loss: 2.8178497437507875

Epoch: 6| Step: 12
Training loss: 2.2245476245880127
Validation loss: 2.81523960380144

Epoch: 6| Step: 13
Training loss: 2.464383602142334
Validation loss: 2.8140395354199153

Epoch: 15| Step: 0
Training loss: 3.851982831954956
Validation loss: 2.808727782259705

Epoch: 6| Step: 1
Training loss: 2.4883229732513428
Validation loss: 2.8071453878956456

Epoch: 6| Step: 2
Training loss: 2.1251637935638428
Validation loss: 2.8081820446957826

Epoch: 6| Step: 3
Training loss: 3.7772157192230225
Validation loss: 2.808987102200908

Epoch: 6| Step: 4
Training loss: 2.62821102142334
Validation loss: 2.811705861040341

Epoch: 6| Step: 5
Training loss: 3.436272144317627
Validation loss: 2.8106158676967827

Epoch: 6| Step: 6
Training loss: 2.863348960876465
Validation loss: 2.803802259506718

Epoch: 6| Step: 7
Training loss: 3.1737594604492188
Validation loss: 2.799064343975436

Epoch: 6| Step: 8
Training loss: 2.9448535442352295
Validation loss: 2.797943112670734

Epoch: 6| Step: 9
Training loss: 2.0116138458251953
Validation loss: 2.797118971424718

Epoch: 6| Step: 10
Training loss: 2.5874037742614746
Validation loss: 2.7933554367352555

Epoch: 6| Step: 11
Training loss: 2.570176124572754
Validation loss: 2.791862554447625

Epoch: 6| Step: 12
Training loss: 3.8369340896606445
Validation loss: 2.7933811577417518

Epoch: 6| Step: 13
Training loss: 2.6631381511688232
Validation loss: 2.795124251355407

Epoch: 16| Step: 0
Training loss: 3.9524636268615723
Validation loss: 2.7931256473705335

Epoch: 6| Step: 1
Training loss: 2.0983893871307373
Validation loss: 2.791714317055159

Epoch: 6| Step: 2
Training loss: 2.5810201168060303
Validation loss: 2.788523530447355

Epoch: 6| Step: 3
Training loss: 2.8342552185058594
Validation loss: 2.790042925906438

Epoch: 6| Step: 4
Training loss: 2.749607563018799
Validation loss: 2.7870296406489548

Epoch: 6| Step: 5
Training loss: 3.265807628631592
Validation loss: 2.785521238080917

Epoch: 6| Step: 6
Training loss: 3.409019947052002
Validation loss: 2.783863236827235

Epoch: 6| Step: 7
Training loss: 2.9504506587982178
Validation loss: 2.783316781443934

Epoch: 6| Step: 8
Training loss: 2.7467892169952393
Validation loss: 2.781876592225926

Epoch: 6| Step: 9
Training loss: 2.479940891265869
Validation loss: 2.782236401752759

Epoch: 6| Step: 10
Training loss: 2.7405500411987305
Validation loss: 2.7777069819870817

Epoch: 6| Step: 11
Training loss: 2.741879940032959
Validation loss: 2.7775148294305287

Epoch: 6| Step: 12
Training loss: 2.3653974533081055
Validation loss: 2.776776785491615

Epoch: 6| Step: 13
Training loss: 4.834527969360352
Validation loss: 2.7743035157521567

Epoch: 17| Step: 0
Training loss: 2.686239242553711
Validation loss: 2.778512503511162

Epoch: 6| Step: 1
Training loss: 2.1355817317962646
Validation loss: 2.7783321821561424

Epoch: 6| Step: 2
Training loss: 2.9874987602233887
Validation loss: 2.787550554480604

Epoch: 6| Step: 3
Training loss: 2.5394396781921387
Validation loss: 2.7938858847464285

Epoch: 6| Step: 4
Training loss: 3.0640013217926025
Validation loss: 2.797795598224927

Epoch: 6| Step: 5
Training loss: 2.4506168365478516
Validation loss: 2.8045383525151077

Epoch: 6| Step: 6
Training loss: 4.2272114753723145
Validation loss: 2.7988266970521662

Epoch: 6| Step: 7
Training loss: 2.9309394359588623
Validation loss: 2.777320828489078

Epoch: 6| Step: 8
Training loss: 3.8506648540496826
Validation loss: 2.7695261252823697

Epoch: 6| Step: 9
Training loss: 2.78311824798584
Validation loss: 2.7688267743715675

Epoch: 6| Step: 10
Training loss: 2.476363182067871
Validation loss: 2.776964205567555

Epoch: 6| Step: 11
Training loss: 3.053710460662842
Validation loss: 2.7841722683240007

Epoch: 6| Step: 12
Training loss: 2.670452117919922
Validation loss: 2.814994142901513

Epoch: 6| Step: 13
Training loss: 3.0853562355041504
Validation loss: 2.8453634964522494

Epoch: 18| Step: 0
Training loss: 3.508179187774658
Validation loss: 2.7703241404666694

Epoch: 6| Step: 1
Training loss: 2.7277936935424805
Validation loss: 2.7746915791624334

Epoch: 6| Step: 2
Training loss: 2.9744462966918945
Validation loss: 2.8402781589056856

Epoch: 6| Step: 3
Training loss: 3.3064796924591064
Validation loss: 2.8927643504194034

Epoch: 6| Step: 4
Training loss: 1.8658854961395264
Validation loss: 2.896552998532531

Epoch: 6| Step: 5
Training loss: 2.8310699462890625
Validation loss: 2.863447199585617

Epoch: 6| Step: 6
Training loss: 3.506354331970215
Validation loss: 2.8283094513800835

Epoch: 6| Step: 7
Training loss: 3.360772132873535
Validation loss: 2.818221443442888

Epoch: 6| Step: 8
Training loss: 2.194272518157959
Validation loss: 2.819100708089849

Epoch: 6| Step: 9
Training loss: 2.804116725921631
Validation loss: 2.8314915857007428

Epoch: 6| Step: 10
Training loss: 4.153939247131348
Validation loss: 2.8084584718109458

Epoch: 6| Step: 11
Training loss: 2.184539556503296
Validation loss: 2.8041225094949045

Epoch: 6| Step: 12
Training loss: 2.6755733489990234
Validation loss: 2.8123622504613732

Epoch: 6| Step: 13
Training loss: 3.4071950912475586
Validation loss: 2.8145942816170315

Epoch: 19| Step: 0
Training loss: 2.855226516723633
Validation loss: 2.8126974644199496

Epoch: 6| Step: 1
Training loss: 2.6111106872558594
Validation loss: 2.818547776950303

Epoch: 6| Step: 2
Training loss: 3.0242061614990234
Validation loss: 2.8201473553975425

Epoch: 6| Step: 3
Training loss: 3.250370502471924
Validation loss: 2.816855005038682

Epoch: 6| Step: 4
Training loss: 2.9718594551086426
Validation loss: 2.8075808350757887

Epoch: 6| Step: 5
Training loss: 2.3725743293762207
Validation loss: 2.7998266348274807

Epoch: 6| Step: 6
Training loss: 3.5785136222839355
Validation loss: 2.7921752237504527

Epoch: 6| Step: 7
Training loss: 2.5659074783325195
Validation loss: 2.7791003104179137

Epoch: 6| Step: 8
Training loss: 3.5835461616516113
Validation loss: 2.7689993407136653

Epoch: 6| Step: 9
Training loss: 2.8043606281280518
Validation loss: 2.7546612780581237

Epoch: 6| Step: 10
Training loss: 2.3227128982543945
Validation loss: 2.7497999565575713

Epoch: 6| Step: 11
Training loss: 2.4480605125427246
Validation loss: 2.7479609058749292

Epoch: 6| Step: 12
Training loss: 3.407076358795166
Validation loss: 2.7547426223754883

Epoch: 6| Step: 13
Training loss: 3.2273671627044678
Validation loss: 2.737687167300973

Epoch: 20| Step: 0
Training loss: 3.2080016136169434
Validation loss: 2.7381339278272403

Epoch: 6| Step: 1
Training loss: 2.924121856689453
Validation loss: 2.7383030896545737

Epoch: 6| Step: 2
Training loss: 2.136695384979248
Validation loss: 2.7367721629399124

Epoch: 6| Step: 3
Training loss: 2.8062095642089844
Validation loss: 2.7364945283500095

Epoch: 6| Step: 4
Training loss: 2.105437755584717
Validation loss: 2.733833305297359

Epoch: 6| Step: 5
Training loss: 2.108182907104492
Validation loss: 2.7334434396477154

Epoch: 6| Step: 6
Training loss: 3.2413489818573
Validation loss: 2.7277925168314288

Epoch: 6| Step: 7
Training loss: 2.727325916290283
Validation loss: 2.7251746603237685

Epoch: 6| Step: 8
Training loss: 3.3119094371795654
Validation loss: 2.724823172374438

Epoch: 6| Step: 9
Training loss: 2.9616732597351074
Validation loss: 2.7242443561553955

Epoch: 6| Step: 10
Training loss: 3.0320403575897217
Validation loss: 2.719619189539263

Epoch: 6| Step: 11
Training loss: 3.3363449573516846
Validation loss: 2.717655994558847

Epoch: 6| Step: 12
Training loss: 2.98637318611145
Validation loss: 2.715381742805563

Epoch: 6| Step: 13
Training loss: 3.911067008972168
Validation loss: 2.715187954646285

Epoch: 21| Step: 0
Training loss: 3.30181884765625
Validation loss: 2.716452052516322

Epoch: 6| Step: 1
Training loss: 2.534292459487915
Validation loss: 2.7194048409820883

Epoch: 6| Step: 2
Training loss: 3.294588088989258
Validation loss: 2.725789685403147

Epoch: 6| Step: 3
Training loss: 3.3009045124053955
Validation loss: 2.708001426471177

Epoch: 6| Step: 4
Training loss: 2.334139347076416
Validation loss: 2.702710005544847

Epoch: 6| Step: 5
Training loss: 2.2066752910614014
Validation loss: 2.7013934709692515

Epoch: 6| Step: 6
Training loss: 2.168142318725586
Validation loss: 2.7015496133476176

Epoch: 6| Step: 7
Training loss: 2.6869945526123047
Validation loss: 2.700391515608757

Epoch: 6| Step: 8
Training loss: 2.673389434814453
Validation loss: 2.702170900119248

Epoch: 6| Step: 9
Training loss: 3.226994276046753
Validation loss: 2.7010922483218613

Epoch: 6| Step: 10
Training loss: 2.6368165016174316
Validation loss: 2.7018625351690475

Epoch: 6| Step: 11
Training loss: 3.4058163166046143
Validation loss: 2.699747649572229

Epoch: 6| Step: 12
Training loss: 3.2145981788635254
Validation loss: 2.6987024943033853

Epoch: 6| Step: 13
Training loss: 3.403522491455078
Validation loss: 2.699444998977005

Epoch: 22| Step: 0
Training loss: 3.0099353790283203
Validation loss: 2.6964308369544243

Epoch: 6| Step: 1
Training loss: 3.1811940670013428
Validation loss: 2.6968224586979037

Epoch: 6| Step: 2
Training loss: 2.8975605964660645
Validation loss: 2.692313363475184

Epoch: 6| Step: 3
Training loss: 2.557102680206299
Validation loss: 2.6916880479422947

Epoch: 6| Step: 4
Training loss: 2.9335272312164307
Validation loss: 2.6941464767661145

Epoch: 6| Step: 5
Training loss: 3.1032423973083496
Validation loss: 2.6989265616222093

Epoch: 6| Step: 6
Training loss: 1.985029697418213
Validation loss: 2.701606591542562

Epoch: 6| Step: 7
Training loss: 3.234025001525879
Validation loss: 2.7100912678626274

Epoch: 6| Step: 8
Training loss: 2.4264557361602783
Validation loss: 2.7035421299678024

Epoch: 6| Step: 9
Training loss: 2.3843295574188232
Validation loss: 2.702938272107032

Epoch: 6| Step: 10
Training loss: 3.085733413696289
Validation loss: 2.6912338964400755

Epoch: 6| Step: 11
Training loss: 2.6671698093414307
Validation loss: 2.687319714535949

Epoch: 6| Step: 12
Training loss: 3.977074146270752
Validation loss: 2.685671052625102

Epoch: 6| Step: 13
Training loss: 2.3465826511383057
Validation loss: 2.685287803731939

Epoch: 23| Step: 0
Training loss: 3.288452386856079
Validation loss: 2.685823873807025

Epoch: 6| Step: 1
Training loss: 2.814206123352051
Validation loss: 2.68338264701187

Epoch: 6| Step: 2
Training loss: 3.419255018234253
Validation loss: 2.6820740930495726

Epoch: 6| Step: 3
Training loss: 1.9878288507461548
Validation loss: 2.6839576305881625

Epoch: 6| Step: 4
Training loss: 3.0539238452911377
Validation loss: 2.6797966598182597

Epoch: 6| Step: 5
Training loss: 2.557363271713257
Validation loss: 2.6813927491505942

Epoch: 6| Step: 6
Training loss: 4.146999359130859
Validation loss: 2.68395213414264

Epoch: 6| Step: 7
Training loss: 1.8799299001693726
Validation loss: 2.6841015610643613

Epoch: 6| Step: 8
Training loss: 3.0916805267333984
Validation loss: 2.680250216555852

Epoch: 6| Step: 9
Training loss: 2.9240119457244873
Validation loss: 2.678235205270911

Epoch: 6| Step: 10
Training loss: 2.460793972015381
Validation loss: 2.6811615754199285

Epoch: 6| Step: 11
Training loss: 2.982121467590332
Validation loss: 2.680414963794011

Epoch: 6| Step: 12
Training loss: 2.412949323654175
Validation loss: 2.6820932178087133

Epoch: 6| Step: 13
Training loss: 2.9183552265167236
Validation loss: 2.681672006525019

Epoch: 24| Step: 0
Training loss: 2.356395721435547
Validation loss: 2.6794456615242908

Epoch: 6| Step: 1
Training loss: 2.177544593811035
Validation loss: 2.6789034899844917

Epoch: 6| Step: 2
Training loss: 3.4810163974761963
Validation loss: 2.6788011033047914

Epoch: 6| Step: 3
Training loss: 3.0718166828155518
Validation loss: 2.677918188033565

Epoch: 6| Step: 4
Training loss: 2.2340636253356934
Validation loss: 2.6744687480311238

Epoch: 6| Step: 5
Training loss: 3.213963031768799
Validation loss: 2.6722401034447456

Epoch: 6| Step: 6
Training loss: 3.3455607891082764
Validation loss: 2.670839414801649

Epoch: 6| Step: 7
Training loss: 2.7936649322509766
Validation loss: 2.671399049861457

Epoch: 6| Step: 8
Training loss: 2.855567455291748
Validation loss: 2.6713137883012013

Epoch: 6| Step: 9
Training loss: 3.205016613006592
Validation loss: 2.6701422814399964

Epoch: 6| Step: 10
Training loss: 2.364828586578369
Validation loss: 2.668880811301611

Epoch: 6| Step: 11
Training loss: 2.667750358581543
Validation loss: 2.6734493752961517

Epoch: 6| Step: 12
Training loss: 3.3414816856384277
Validation loss: 2.6827444286756617

Epoch: 6| Step: 13
Training loss: 2.544583559036255
Validation loss: 2.68574284994474

Epoch: 25| Step: 0
Training loss: 2.4062161445617676
Validation loss: 2.694397303365892

Epoch: 6| Step: 1
Training loss: 2.816817283630371
Validation loss: 2.6842746042436167

Epoch: 6| Step: 2
Training loss: 2.9994616508483887
Validation loss: 2.675386321160101

Epoch: 6| Step: 3
Training loss: 2.3077569007873535
Validation loss: 2.6646489789409022

Epoch: 6| Step: 4
Training loss: 3.211337089538574
Validation loss: 2.6641940916738203

Epoch: 6| Step: 5
Training loss: 2.8953521251678467
Validation loss: 2.664863412098218

Epoch: 6| Step: 6
Training loss: 2.2136294841766357
Validation loss: 2.665175227708714

Epoch: 6| Step: 7
Training loss: 3.9182331562042236
Validation loss: 2.6653787038659535

Epoch: 6| Step: 8
Training loss: 3.3391501903533936
Validation loss: 2.665524798054849

Epoch: 6| Step: 9
Training loss: 2.259023904800415
Validation loss: 2.66820538684886

Epoch: 6| Step: 10
Training loss: 2.470539093017578
Validation loss: 2.667622773878036

Epoch: 6| Step: 11
Training loss: 3.21122407913208
Validation loss: 2.6676745273733653

Epoch: 6| Step: 12
Training loss: 3.384355306625366
Validation loss: 2.670503762460524

Epoch: 6| Step: 13
Training loss: 1.9789613485336304
Validation loss: 2.6718749743635937

Epoch: 26| Step: 0
Training loss: 2.2567477226257324
Validation loss: 2.676926000143892

Epoch: 6| Step: 1
Training loss: 2.288555145263672
Validation loss: 2.6733635010257846

Epoch: 6| Step: 2
Training loss: 3.112088203430176
Validation loss: 2.6735150352601083

Epoch: 6| Step: 3
Training loss: 3.0199313163757324
Validation loss: 2.669577496026152

Epoch: 6| Step: 4
Training loss: 2.900310516357422
Validation loss: 2.6719505222894813

Epoch: 6| Step: 5
Training loss: 2.58805513381958
Validation loss: 2.670908945862965

Epoch: 6| Step: 6
Training loss: 2.986754894256592
Validation loss: 2.662105965357955

Epoch: 6| Step: 7
Training loss: 3.5288915634155273
Validation loss: 2.65662282769398

Epoch: 6| Step: 8
Training loss: 2.536562919616699
Validation loss: 2.651582876841227

Epoch: 6| Step: 9
Training loss: 2.436387300491333
Validation loss: 2.658295774972567

Epoch: 6| Step: 10
Training loss: 3.1960110664367676
Validation loss: 2.6573782044072307

Epoch: 6| Step: 11
Training loss: 3.2192559242248535
Validation loss: 2.6522135708921697

Epoch: 6| Step: 12
Training loss: 2.699517011642456
Validation loss: 2.650037178429224

Epoch: 6| Step: 13
Training loss: 2.79888916015625
Validation loss: 2.6485245561087005

Epoch: 27| Step: 0
Training loss: 2.5112199783325195
Validation loss: 2.6471123336463847

Epoch: 6| Step: 1
Training loss: 4.004848480224609
Validation loss: 2.6445082464525775

Epoch: 6| Step: 2
Training loss: 4.174455642700195
Validation loss: 2.641199460593603

Epoch: 6| Step: 3
Training loss: 2.3725838661193848
Validation loss: 2.6393198069705757

Epoch: 6| Step: 4
Training loss: 2.5794243812561035
Validation loss: 2.637542804082235

Epoch: 6| Step: 5
Training loss: 2.9373083114624023
Validation loss: 2.6375448396128993

Epoch: 6| Step: 6
Training loss: 2.22505521774292
Validation loss: 2.6406020195253435

Epoch: 6| Step: 7
Training loss: 2.640326499938965
Validation loss: 2.6388219889774116

Epoch: 6| Step: 8
Training loss: 2.7263717651367188
Validation loss: 2.6481845507057766

Epoch: 6| Step: 9
Training loss: 1.982213020324707
Validation loss: 2.645112027404129

Epoch: 6| Step: 10
Training loss: 2.9544003009796143
Validation loss: 2.644331616740073

Epoch: 6| Step: 11
Training loss: 2.7868850231170654
Validation loss: 2.6537054892509215

Epoch: 6| Step: 12
Training loss: 3.018608570098877
Validation loss: 2.6410782003915436

Epoch: 6| Step: 13
Training loss: 2.2008731365203857
Validation loss: 2.637110469161823

Epoch: 28| Step: 0
Training loss: 2.8743436336517334
Validation loss: 2.6418254298548542

Epoch: 6| Step: 1
Training loss: 3.1843018531799316
Validation loss: 2.643651371361107

Epoch: 6| Step: 2
Training loss: 2.6558847427368164
Validation loss: 2.638205974332748

Epoch: 6| Step: 3
Training loss: 2.8068957328796387
Validation loss: 2.6378419681261946

Epoch: 6| Step: 4
Training loss: 3.0608510971069336
Validation loss: 2.6359879150185535

Epoch: 6| Step: 5
Training loss: 3.033350706100464
Validation loss: 2.635624695849675

Epoch: 6| Step: 6
Training loss: 2.7653703689575195
Validation loss: 2.6363385415846303

Epoch: 6| Step: 7
Training loss: 2.327077865600586
Validation loss: 2.632585092257428

Epoch: 6| Step: 8
Training loss: 2.8568055629730225
Validation loss: 2.62784759459957

Epoch: 6| Step: 9
Training loss: 2.8085579872131348
Validation loss: 2.628667093092395

Epoch: 6| Step: 10
Training loss: 2.114886522293091
Validation loss: 2.6305376022092757

Epoch: 6| Step: 11
Training loss: 3.1065170764923096
Validation loss: 2.629538902672388

Epoch: 6| Step: 12
Training loss: 2.844891309738159
Validation loss: 2.630856303758519

Epoch: 6| Step: 13
Training loss: 2.8347859382629395
Validation loss: 2.627691243284492

Epoch: 29| Step: 0
Training loss: 3.7668328285217285
Validation loss: 2.6370123663256244

Epoch: 6| Step: 1
Training loss: 3.2528247833251953
Validation loss: 2.6387451669221282

Epoch: 6| Step: 2
Training loss: 2.431830406188965
Validation loss: 2.634878461078931

Epoch: 6| Step: 3
Training loss: 3.4952495098114014
Validation loss: 2.627822373502998

Epoch: 6| Step: 4
Training loss: 2.3919453620910645
Validation loss: 2.6175595714199926

Epoch: 6| Step: 5
Training loss: 2.303054094314575
Validation loss: 2.615956691003615

Epoch: 6| Step: 6
Training loss: 2.162510395050049
Validation loss: 2.623586808481524

Epoch: 6| Step: 7
Training loss: 2.479295253753662
Validation loss: 2.630187398643904

Epoch: 6| Step: 8
Training loss: 2.626685857772827
Validation loss: 2.6304852680493425

Epoch: 6| Step: 9
Training loss: 2.8950681686401367
Validation loss: 2.6307512611471195

Epoch: 6| Step: 10
Training loss: 3.119403600692749
Validation loss: 2.6304647666151806

Epoch: 6| Step: 11
Training loss: 2.569092273712158
Validation loss: 2.621332222415555

Epoch: 6| Step: 12
Training loss: 2.804701328277588
Validation loss: 2.629454407640683

Epoch: 6| Step: 13
Training loss: 3.364464282989502
Validation loss: 2.698720691024616

Epoch: 30| Step: 0
Training loss: 3.502373456954956
Validation loss: 2.7054330431005007

Epoch: 6| Step: 1
Training loss: 2.421598434448242
Validation loss: 2.670647123808502

Epoch: 6| Step: 2
Training loss: 3.096816062927246
Validation loss: 2.6480217928527505

Epoch: 6| Step: 3
Training loss: 2.1765193939208984
Validation loss: 2.6332786749768

Epoch: 6| Step: 4
Training loss: 3.4059247970581055
Validation loss: 2.6389318999423774

Epoch: 6| Step: 5
Training loss: 2.2125778198242188
Validation loss: 2.6582691977100987

Epoch: 6| Step: 6
Training loss: 2.4385972023010254
Validation loss: 2.6772710713007117

Epoch: 6| Step: 7
Training loss: 3.691188335418701
Validation loss: 2.6745998526132233

Epoch: 6| Step: 8
Training loss: 2.912062644958496
Validation loss: 2.631258387719431

Epoch: 6| Step: 9
Training loss: 1.8651517629623413
Validation loss: 2.6090315234276558

Epoch: 6| Step: 10
Training loss: 2.6359148025512695
Validation loss: 2.607681820469518

Epoch: 6| Step: 11
Training loss: 3.4924957752227783
Validation loss: 2.613121806934316

Epoch: 6| Step: 12
Training loss: 2.3104448318481445
Validation loss: 2.613148743106473

Epoch: 6| Step: 13
Training loss: 3.6632168292999268
Validation loss: 2.6029105237735215

Epoch: 31| Step: 0
Training loss: 2.3754427433013916
Validation loss: 2.599512461693056

Epoch: 6| Step: 1
Training loss: 3.5570666790008545
Validation loss: 2.602143495313583

Epoch: 6| Step: 2
Training loss: 2.509113311767578
Validation loss: 2.601527762669389

Epoch: 6| Step: 3
Training loss: 2.046985149383545
Validation loss: 2.6033725841071016

Epoch: 6| Step: 4
Training loss: 3.3742117881774902
Validation loss: 2.6024864924851285

Epoch: 6| Step: 5
Training loss: 2.0615878105163574
Validation loss: 2.6016934148726927

Epoch: 6| Step: 6
Training loss: 3.204051971435547
Validation loss: 2.600628517007315

Epoch: 6| Step: 7
Training loss: 3.069363832473755
Validation loss: 2.600435613304056

Epoch: 6| Step: 8
Training loss: 2.9076414108276367
Validation loss: 2.5977813197720434

Epoch: 6| Step: 9
Training loss: 3.2668161392211914
Validation loss: 2.5959796495335077

Epoch: 6| Step: 10
Training loss: 3.174262046813965
Validation loss: 2.599313384743147

Epoch: 6| Step: 11
Training loss: 2.1855039596557617
Validation loss: 2.6099001130750104

Epoch: 6| Step: 12
Training loss: 2.8395705223083496
Validation loss: 2.615043047935732

Epoch: 6| Step: 13
Training loss: 2.299280881881714
Validation loss: 2.6069470220996487

Epoch: 32| Step: 0
Training loss: 3.18971848487854
Validation loss: 2.5976587444223385

Epoch: 6| Step: 1
Training loss: 3.1450226306915283
Validation loss: 2.598681370417277

Epoch: 6| Step: 2
Training loss: 2.7087764739990234
Validation loss: 2.5954933961232505

Epoch: 6| Step: 3
Training loss: 2.72648286819458
Validation loss: 2.591070023916101

Epoch: 6| Step: 4
Training loss: 2.023935556411743
Validation loss: 2.597882786104756

Epoch: 6| Step: 5
Training loss: 3.6127212047576904
Validation loss: 2.603796346213228

Epoch: 6| Step: 6
Training loss: 2.610983371734619
Validation loss: 2.6083750981156544

Epoch: 6| Step: 7
Training loss: 2.9540774822235107
Validation loss: 2.6004237821025233

Epoch: 6| Step: 8
Training loss: 2.236841917037964
Validation loss: 2.5937984348625265

Epoch: 6| Step: 9
Training loss: 2.030816078186035
Validation loss: 2.5857817075585805

Epoch: 6| Step: 10
Training loss: 3.0409021377563477
Validation loss: 2.5823136401432816

Epoch: 6| Step: 11
Training loss: 2.227281332015991
Validation loss: 2.5930090847835747

Epoch: 6| Step: 12
Training loss: 3.2745139598846436
Validation loss: 2.594699821164531

Epoch: 6| Step: 13
Training loss: 3.56207537651062
Validation loss: 2.605914100523918

Epoch: 33| Step: 0
Training loss: 2.3550186157226562
Validation loss: 2.6111565866777973

Epoch: 6| Step: 1
Training loss: 2.8724136352539062
Validation loss: 2.639931058370939

Epoch: 6| Step: 2
Training loss: 2.406914234161377
Validation loss: 2.6568389938723658

Epoch: 6| Step: 3
Training loss: 1.9035838842391968
Validation loss: 2.590052563657043

Epoch: 6| Step: 4
Training loss: 3.5232105255126953
Validation loss: 2.580757825605331

Epoch: 6| Step: 5
Training loss: 3.354252338409424
Validation loss: 2.58984201441529

Epoch: 6| Step: 6
Training loss: 2.9678287506103516
Validation loss: 2.612751514680924

Epoch: 6| Step: 7
Training loss: 2.9831185340881348
Validation loss: 2.649312585912725

Epoch: 6| Step: 8
Training loss: 2.7054004669189453
Validation loss: 2.6707675944092455

Epoch: 6| Step: 9
Training loss: 3.530543804168701
Validation loss: 2.6449842786276214

Epoch: 6| Step: 10
Training loss: 2.5386884212493896
Validation loss: 2.5891866863414807

Epoch: 6| Step: 11
Training loss: 3.1949515342712402
Validation loss: 2.5775065063148417

Epoch: 6| Step: 12
Training loss: 2.2276811599731445
Validation loss: 2.574983427601476

Epoch: 6| Step: 13
Training loss: 2.44325852394104
Validation loss: 2.5841618968594458

Epoch: 34| Step: 0
Training loss: 3.017274856567383
Validation loss: 2.583584362460721

Epoch: 6| Step: 1
Training loss: 2.901425838470459
Validation loss: 2.5862107482007755

Epoch: 6| Step: 2
Training loss: 3.0787792205810547
Validation loss: 2.5879187250650055

Epoch: 6| Step: 3
Training loss: 3.501811981201172
Validation loss: 2.580713451549571

Epoch: 6| Step: 4
Training loss: 2.506675958633423
Validation loss: 2.5764374553516345

Epoch: 6| Step: 5
Training loss: 2.49438214302063
Validation loss: 2.573713010357272

Epoch: 6| Step: 6
Training loss: 2.7677035331726074
Validation loss: 2.5741462322973434

Epoch: 6| Step: 7
Training loss: 3.098062038421631
Validation loss: 2.5708359749086442

Epoch: 6| Step: 8
Training loss: 2.089773178100586
Validation loss: 2.57544699791939

Epoch: 6| Step: 9
Training loss: 2.870215892791748
Validation loss: 2.5713721295838714

Epoch: 6| Step: 10
Training loss: 3.2879748344421387
Validation loss: 2.571192292756932

Epoch: 6| Step: 11
Training loss: 2.506359577178955
Validation loss: 2.5702919242202595

Epoch: 6| Step: 12
Training loss: 1.7539117336273193
Validation loss: 2.5736953699460594

Epoch: 6| Step: 13
Training loss: 2.8803627490997314
Validation loss: 2.570300289379653

Epoch: 35| Step: 0
Training loss: 2.0970537662506104
Validation loss: 2.5700827106352775

Epoch: 6| Step: 1
Training loss: 1.7574903964996338
Validation loss: 2.5772410695270827

Epoch: 6| Step: 2
Training loss: 2.4135289192199707
Validation loss: 2.5991358654473418

Epoch: 6| Step: 3
Training loss: 3.0029196739196777
Validation loss: 2.6239559624784734

Epoch: 6| Step: 4
Training loss: 3.666998863220215
Validation loss: 2.6124078765992196

Epoch: 6| Step: 5
Training loss: 2.7468819618225098
Validation loss: 2.5648217021778064

Epoch: 6| Step: 6
Training loss: 2.752551794052124
Validation loss: 2.5583819035560853

Epoch: 6| Step: 7
Training loss: 3.1717350482940674
Validation loss: 2.5619417877607447

Epoch: 6| Step: 8
Training loss: 3.101809024810791
Validation loss: 2.5643924872080484

Epoch: 6| Step: 9
Training loss: 2.9475343227386475
Validation loss: 2.569105130369945

Epoch: 6| Step: 10
Training loss: 3.369330644607544
Validation loss: 2.5729736512707126

Epoch: 6| Step: 11
Training loss: 2.791841983795166
Validation loss: 2.5694331533165387

Epoch: 6| Step: 12
Training loss: 2.6116952896118164
Validation loss: 2.569151352810603

Epoch: 6| Step: 13
Training loss: 2.046046257019043
Validation loss: 2.5636910828210975

Epoch: 36| Step: 0
Training loss: 1.8010284900665283
Validation loss: 2.5635132712702595

Epoch: 6| Step: 1
Training loss: 2.638740062713623
Validation loss: 2.557114811353786

Epoch: 6| Step: 2
Training loss: 3.1277787685394287
Validation loss: 2.5548195403109313

Epoch: 6| Step: 3
Training loss: 3.1101601123809814
Validation loss: 2.5491776850915726

Epoch: 6| Step: 4
Training loss: 2.779632091522217
Validation loss: 2.546499959884151

Epoch: 6| Step: 5
Training loss: 2.06174635887146
Validation loss: 2.554271092978857

Epoch: 6| Step: 6
Training loss: 2.392378330230713
Validation loss: 2.5653377527831704

Epoch: 6| Step: 7
Training loss: 3.4576306343078613
Validation loss: 2.610896610444592

Epoch: 6| Step: 8
Training loss: 2.4093122482299805
Validation loss: 2.6357324225928194

Epoch: 6| Step: 9
Training loss: 3.094846248626709
Validation loss: 2.65396551675694

Epoch: 6| Step: 10
Training loss: 2.3241610527038574
Validation loss: 2.6294260383934103

Epoch: 6| Step: 11
Training loss: 3.4127585887908936
Validation loss: 2.5846484604702202

Epoch: 6| Step: 12
Training loss: 2.779712438583374
Validation loss: 2.5518860816955566

Epoch: 6| Step: 13
Training loss: 3.6178791522979736
Validation loss: 2.5411954925906275

Epoch: 37| Step: 0
Training loss: 2.695119619369507
Validation loss: 2.546973782200967

Epoch: 6| Step: 1
Training loss: 1.805978775024414
Validation loss: 2.5421009525176017

Epoch: 6| Step: 2
Training loss: 2.2026705741882324
Validation loss: 2.5427847293115433

Epoch: 6| Step: 3
Training loss: 4.483179569244385
Validation loss: 2.5428169952925814

Epoch: 6| Step: 4
Training loss: 2.802271842956543
Validation loss: 2.543613831202189

Epoch: 6| Step: 5
Training loss: 2.432509183883667
Validation loss: 2.5435887139330626

Epoch: 6| Step: 6
Training loss: 2.980292320251465
Validation loss: 2.54080363499221

Epoch: 6| Step: 7
Training loss: 3.231560468673706
Validation loss: 2.540117266357586

Epoch: 6| Step: 8
Training loss: 3.1223537921905518
Validation loss: 2.5369629372832594

Epoch: 6| Step: 9
Training loss: 1.544701337814331
Validation loss: 2.535954171611417

Epoch: 6| Step: 10
Training loss: 3.127220630645752
Validation loss: 2.5346902416598414

Epoch: 6| Step: 11
Training loss: 2.9029593467712402
Validation loss: 2.5364146219786776

Epoch: 6| Step: 12
Training loss: 2.6571123600006104
Validation loss: 2.544421039601808

Epoch: 6| Step: 13
Training loss: 2.164454460144043
Validation loss: 2.554094942667151

Epoch: 38| Step: 0
Training loss: 2.385521173477173
Validation loss: 2.5552548387999177

Epoch: 6| Step: 1
Training loss: 2.8743410110473633
Validation loss: 2.5618676370190037

Epoch: 6| Step: 2
Training loss: 2.1682310104370117
Validation loss: 2.554691145496984

Epoch: 6| Step: 3
Training loss: 2.724099636077881
Validation loss: 2.53895571924025

Epoch: 6| Step: 4
Training loss: 3.26894474029541
Validation loss: 2.5293091958568943

Epoch: 6| Step: 5
Training loss: 2.4140000343322754
Validation loss: 2.5275301369287635

Epoch: 6| Step: 6
Training loss: 2.229604721069336
Validation loss: 2.5309349234386156

Epoch: 6| Step: 7
Training loss: 1.8938024044036865
Validation loss: 2.5366077628186954

Epoch: 6| Step: 8
Training loss: 2.872037172317505
Validation loss: 2.5331352808142222

Epoch: 6| Step: 9
Training loss: 3.264676570892334
Validation loss: 2.532905635013375

Epoch: 6| Step: 10
Training loss: 3.6972241401672363
Validation loss: 2.530077862483199

Epoch: 6| Step: 11
Training loss: 2.5780181884765625
Validation loss: 2.5325920607454036

Epoch: 6| Step: 12
Training loss: 2.519763469696045
Validation loss: 2.52978987591241

Epoch: 6| Step: 13
Training loss: 4.127996921539307
Validation loss: 2.526477147174138

Epoch: 39| Step: 0
Training loss: 3.9005236625671387
Validation loss: 2.525895385332005

Epoch: 6| Step: 1
Training loss: 1.8791414499282837
Validation loss: 2.5224167557172876

Epoch: 6| Step: 2
Training loss: 2.3104164600372314
Validation loss: 2.530918049555953

Epoch: 6| Step: 3
Training loss: 2.546584129333496
Validation loss: 2.5437883612930134

Epoch: 6| Step: 4
Training loss: 2.8804516792297363
Validation loss: 2.612098042682935

Epoch: 6| Step: 5
Training loss: 4.128419399261475
Validation loss: 2.627640329381471

Epoch: 6| Step: 6
Training loss: 1.7415684461593628
Validation loss: 2.548115115011892

Epoch: 6| Step: 7
Training loss: 3.0357394218444824
Validation loss: 2.528437550349902

Epoch: 6| Step: 8
Training loss: 2.8395650386810303
Validation loss: 2.5294721921284995

Epoch: 6| Step: 9
Training loss: 2.420560121536255
Validation loss: 2.5293277540514545

Epoch: 6| Step: 10
Training loss: 2.7452776432037354
Validation loss: 2.545444027070076

Epoch: 6| Step: 11
Training loss: 2.292710781097412
Validation loss: 2.563131465706774

Epoch: 6| Step: 12
Training loss: 2.412004232406616
Validation loss: 2.5874265265721146

Epoch: 6| Step: 13
Training loss: 3.6101438999176025
Validation loss: 2.6666822818017777

Epoch: 40| Step: 0
Training loss: 2.1443169116973877
Validation loss: 2.5537482794894966

Epoch: 6| Step: 1
Training loss: 2.7919414043426514
Validation loss: 2.5277184619698474

Epoch: 6| Step: 2
Training loss: 2.9367783069610596
Validation loss: 2.527552902057607

Epoch: 6| Step: 3
Training loss: 2.9023079872131348
Validation loss: 2.5312833837283555

Epoch: 6| Step: 4
Training loss: 2.8524911403656006
Validation loss: 2.528944125739477

Epoch: 6| Step: 5
Training loss: 2.6043107509613037
Validation loss: 2.5620750022190872

Epoch: 6| Step: 6
Training loss: 3.253389835357666
Validation loss: 2.568657951970254

Epoch: 6| Step: 7
Training loss: 2.383972406387329
Validation loss: 2.581239573417171

Epoch: 6| Step: 8
Training loss: 2.4079642295837402
Validation loss: 2.585641073924239

Epoch: 6| Step: 9
Training loss: 2.771233320236206
Validation loss: 2.5588910656590618

Epoch: 6| Step: 10
Training loss: 2.756216287612915
Validation loss: 2.533211992632958

Epoch: 6| Step: 11
Training loss: 3.298104763031006
Validation loss: 2.5067310794707267

Epoch: 6| Step: 12
Training loss: 2.1756503582000732
Validation loss: 2.5081256410127044

Epoch: 6| Step: 13
Training loss: 2.9498422145843506
Validation loss: 2.509809324818273

Epoch: 41| Step: 0
Training loss: 2.7113170623779297
Validation loss: 2.515340543562366

Epoch: 6| Step: 1
Training loss: 2.0680222511291504
Validation loss: 2.5228822000565065

Epoch: 6| Step: 2
Training loss: 2.5126867294311523
Validation loss: 2.5264931289098596

Epoch: 6| Step: 3
Training loss: 3.0206193923950195
Validation loss: 2.5481945237805768

Epoch: 6| Step: 4
Training loss: 3.424384355545044
Validation loss: 2.5573177824738207

Epoch: 6| Step: 5
Training loss: 3.665098190307617
Validation loss: 2.5714908876726703

Epoch: 6| Step: 6
Training loss: 2.9492526054382324
Validation loss: 2.5475125107713925

Epoch: 6| Step: 7
Training loss: 2.19867205619812
Validation loss: 2.5183674648243892

Epoch: 6| Step: 8
Training loss: 2.540905714035034
Validation loss: 2.5185490833815707

Epoch: 6| Step: 9
Training loss: 2.4237122535705566
Validation loss: 2.5211045844580537

Epoch: 6| Step: 10
Training loss: 2.5874409675598145
Validation loss: 2.537389555285054

Epoch: 6| Step: 11
Training loss: 2.58298397064209
Validation loss: 2.563012574308662

Epoch: 6| Step: 12
Training loss: 2.2368688583374023
Validation loss: 2.5802852158905356

Epoch: 6| Step: 13
Training loss: 4.04794454574585
Validation loss: 2.570040584892355

Epoch: 42| Step: 0
Training loss: 2.969943046569824
Validation loss: 2.5266034192936395

Epoch: 6| Step: 1
Training loss: 2.0627219676971436
Validation loss: 2.508289867831815

Epoch: 6| Step: 2
Training loss: 2.1956615447998047
Validation loss: 2.505884237186883

Epoch: 6| Step: 3
Training loss: 3.2905185222625732
Validation loss: 2.5009550227913806

Epoch: 6| Step: 4
Training loss: 2.8168859481811523
Validation loss: 2.500254318278323

Epoch: 6| Step: 5
Training loss: 2.4127652645111084
Validation loss: 2.4949117527213147

Epoch: 6| Step: 6
Training loss: 2.6775832176208496
Validation loss: 2.50122219516385

Epoch: 6| Step: 7
Training loss: 2.762166976928711
Validation loss: 2.501305454520769

Epoch: 6| Step: 8
Training loss: 2.301574230194092
Validation loss: 2.501061498477895

Epoch: 6| Step: 9
Training loss: 3.3592984676361084
Validation loss: 2.5042658108536915

Epoch: 6| Step: 10
Training loss: 2.473841428756714
Validation loss: 2.5031576823162776

Epoch: 6| Step: 11
Training loss: 2.9319472312927246
Validation loss: 2.507035973251507

Epoch: 6| Step: 12
Training loss: 2.7750697135925293
Validation loss: 2.5186968131731917

Epoch: 6| Step: 13
Training loss: 2.901499032974243
Validation loss: 2.5112245236673663

Epoch: 43| Step: 0
Training loss: 2.782205581665039
Validation loss: 2.5081277534525883

Epoch: 6| Step: 1
Training loss: 2.953528881072998
Validation loss: 2.497413473744546

Epoch: 6| Step: 2
Training loss: 2.348198652267456
Validation loss: 2.4964383802106305

Epoch: 6| Step: 3
Training loss: 2.8049802780151367
Validation loss: 2.495336365956132

Epoch: 6| Step: 4
Training loss: 2.334679126739502
Validation loss: 2.4941647744947866

Epoch: 6| Step: 5
Training loss: 2.346965789794922
Validation loss: 2.494666240548575

Epoch: 6| Step: 6
Training loss: 3.252485752105713
Validation loss: 2.494267386774863

Epoch: 6| Step: 7
Training loss: 2.473076343536377
Validation loss: 2.489910976861113

Epoch: 6| Step: 8
Training loss: 2.573197841644287
Validation loss: 2.4868534482935423

Epoch: 6| Step: 9
Training loss: 2.725142002105713
Validation loss: 2.488881472618349

Epoch: 6| Step: 10
Training loss: 2.87434458732605
Validation loss: 2.4877523965733026

Epoch: 6| Step: 11
Training loss: 2.2999815940856934
Validation loss: 2.4899732989649617

Epoch: 6| Step: 12
Training loss: 2.7939939498901367
Validation loss: 2.4871256530925794

Epoch: 6| Step: 13
Training loss: 3.754055976867676
Validation loss: 2.4885224244927846

Epoch: 44| Step: 0
Training loss: 1.9368231296539307
Validation loss: 2.4893559307180424

Epoch: 6| Step: 1
Training loss: 3.185168743133545
Validation loss: 2.4859405691905687

Epoch: 6| Step: 2
Training loss: 3.309781074523926
Validation loss: 2.485154113461894

Epoch: 6| Step: 3
Training loss: 3.4078381061553955
Validation loss: 2.4858997867953394

Epoch: 6| Step: 4
Training loss: 2.3059306144714355
Validation loss: 2.4904762673121628

Epoch: 6| Step: 5
Training loss: 1.7599049806594849
Validation loss: 2.4901423197920605

Epoch: 6| Step: 6
Training loss: 2.8269219398498535
Validation loss: 2.501248922399295

Epoch: 6| Step: 7
Training loss: 2.514270782470703
Validation loss: 2.518292442444832

Epoch: 6| Step: 8
Training loss: 2.3306162357330322
Validation loss: 2.5153781419159262

Epoch: 6| Step: 9
Training loss: 2.8662734031677246
Validation loss: 2.5266213096598142

Epoch: 6| Step: 10
Training loss: 3.487086057662964
Validation loss: 2.5240923102184007

Epoch: 6| Step: 11
Training loss: 2.018374443054199
Validation loss: 2.5134185514142438

Epoch: 6| Step: 12
Training loss: 3.1977288722991943
Validation loss: 2.500538977243567

Epoch: 6| Step: 13
Training loss: 2.706878423690796
Validation loss: 2.4921234576932845

Epoch: 45| Step: 0
Training loss: 3.027419090270996
Validation loss: 2.4773721874401136

Epoch: 6| Step: 1
Training loss: 2.6977109909057617
Validation loss: 2.475683266116727

Epoch: 6| Step: 2
Training loss: 2.4915952682495117
Validation loss: 2.4765590237032984

Epoch: 6| Step: 3
Training loss: 2.418905258178711
Validation loss: 2.4783848639457458

Epoch: 6| Step: 4
Training loss: 3.0314016342163086
Validation loss: 2.483037917844711

Epoch: 6| Step: 5
Training loss: 2.619314193725586
Validation loss: 2.4817173070805048

Epoch: 6| Step: 6
Training loss: 2.1151161193847656
Validation loss: 2.491420410012686

Epoch: 6| Step: 7
Training loss: 3.0403707027435303
Validation loss: 2.4784674695743028

Epoch: 6| Step: 8
Training loss: 3.238961935043335
Validation loss: 2.475801480713711

Epoch: 6| Step: 9
Training loss: 2.760141372680664
Validation loss: 2.4738776735080186

Epoch: 6| Step: 10
Training loss: 2.8516619205474854
Validation loss: 2.4715050651181127

Epoch: 6| Step: 11
Training loss: 2.648003578186035
Validation loss: 2.4700146234163673

Epoch: 6| Step: 12
Training loss: 2.145928382873535
Validation loss: 2.474418819591563

Epoch: 6| Step: 13
Training loss: 2.6763551235198975
Validation loss: 2.4769251910589074

Epoch: 46| Step: 0
Training loss: 2.175165891647339
Validation loss: 2.479945900619671

Epoch: 6| Step: 1
Training loss: 2.460679769515991
Validation loss: 2.4783708459587506

Epoch: 6| Step: 2
Training loss: 2.6081204414367676
Validation loss: 2.4766433008255495

Epoch: 6| Step: 3
Training loss: 3.083209991455078
Validation loss: 2.4816186889525382

Epoch: 6| Step: 4
Training loss: 2.3396549224853516
Validation loss: 2.4704172431781726

Epoch: 6| Step: 5
Training loss: 3.055751323699951
Validation loss: 2.4703714873201106

Epoch: 6| Step: 6
Training loss: 2.5778987407684326
Validation loss: 2.4701247599817093

Epoch: 6| Step: 7
Training loss: 2.4613466262817383
Validation loss: 2.47084939992556

Epoch: 6| Step: 8
Training loss: 3.23128080368042
Validation loss: 2.4692517006269066

Epoch: 6| Step: 9
Training loss: 2.3178629875183105
Validation loss: 2.4753088284564275

Epoch: 6| Step: 10
Training loss: 3.2547335624694824
Validation loss: 2.471859032107938

Epoch: 6| Step: 11
Training loss: 2.3508055210113525
Validation loss: 2.4731649916659117

Epoch: 6| Step: 12
Training loss: 2.7739782333374023
Validation loss: 2.479882706878006

Epoch: 6| Step: 13
Training loss: 3.018937826156616
Validation loss: 2.483313145176057

Epoch: 47| Step: 0
Training loss: 1.8820949792861938
Validation loss: 2.48712981131769

Epoch: 6| Step: 1
Training loss: 2.814462661743164
Validation loss: 2.495160569426834

Epoch: 6| Step: 2
Training loss: 1.8435142040252686
Validation loss: 2.501321005564864

Epoch: 6| Step: 3
Training loss: 3.2394356727600098
Validation loss: 2.495614323564755

Epoch: 6| Step: 4
Training loss: 2.435734748840332
Validation loss: 2.481359371574976

Epoch: 6| Step: 5
Training loss: 3.241464138031006
Validation loss: 2.4727529735975367

Epoch: 6| Step: 6
Training loss: 1.8744819164276123
Validation loss: 2.470791942329817

Epoch: 6| Step: 7
Training loss: 3.4063940048217773
Validation loss: 2.462702633232199

Epoch: 6| Step: 8
Training loss: 2.695438861846924
Validation loss: 2.4574962598021313

Epoch: 6| Step: 9
Training loss: 3.2228236198425293
Validation loss: 2.460750751597907

Epoch: 6| Step: 10
Training loss: 2.4308691024780273
Validation loss: 2.4638557075172343

Epoch: 6| Step: 11
Training loss: 2.6712307929992676
Validation loss: 2.460748416121288

Epoch: 6| Step: 12
Training loss: 2.7384915351867676
Validation loss: 2.4561229367409982

Epoch: 6| Step: 13
Training loss: 3.234879493713379
Validation loss: 2.456365536617976

Epoch: 48| Step: 0
Training loss: 2.935026168823242
Validation loss: 2.4602888579009683

Epoch: 6| Step: 1
Training loss: 2.353929042816162
Validation loss: 2.4579838975783317

Epoch: 6| Step: 2
Training loss: 2.2089145183563232
Validation loss: 2.4631004615496566

Epoch: 6| Step: 3
Training loss: 2.816032648086548
Validation loss: 2.466922096026841

Epoch: 6| Step: 4
Training loss: 2.9005069732666016
Validation loss: 2.4660147518239994

Epoch: 6| Step: 5
Training loss: 2.4918994903564453
Validation loss: 2.4650411426380114

Epoch: 6| Step: 6
Training loss: 2.3034493923187256
Validation loss: 2.4687031571583082

Epoch: 6| Step: 7
Training loss: 3.020357131958008
Validation loss: 2.471949128694432

Epoch: 6| Step: 8
Training loss: 1.9774949550628662
Validation loss: 2.464900948668039

Epoch: 6| Step: 9
Training loss: 3.20965838432312
Validation loss: 2.4593006949270926

Epoch: 6| Step: 10
Training loss: 3.276890516281128
Validation loss: 2.4600314401811167

Epoch: 6| Step: 11
Training loss: 2.6425833702087402
Validation loss: 2.4589890767169256

Epoch: 6| Step: 12
Training loss: 2.2303617000579834
Validation loss: 2.458536265998758

Epoch: 6| Step: 13
Training loss: 3.3147268295288086
Validation loss: 2.4583298621639127

Epoch: 49| Step: 0
Training loss: 2.879307270050049
Validation loss: 2.455317399835074

Epoch: 6| Step: 1
Training loss: 2.6217143535614014
Validation loss: 2.4485371548642396

Epoch: 6| Step: 2
Training loss: 2.5621466636657715
Validation loss: 2.45471542368653

Epoch: 6| Step: 3
Training loss: 2.8081719875335693
Validation loss: 2.4527548795105307

Epoch: 6| Step: 4
Training loss: 2.4325385093688965
Validation loss: 2.4560564897393666

Epoch: 6| Step: 5
Training loss: 2.752035617828369
Validation loss: 2.451010206694244

Epoch: 6| Step: 6
Training loss: 2.5564136505126953
Validation loss: 2.448817250549152

Epoch: 6| Step: 7
Training loss: 3.3069357872009277
Validation loss: 2.452460999129921

Epoch: 6| Step: 8
Training loss: 2.7348554134368896
Validation loss: 2.461417801918522

Epoch: 6| Step: 9
Training loss: 2.8577280044555664
Validation loss: 2.468616339468187

Epoch: 6| Step: 10
Training loss: 2.4467248916625977
Validation loss: 2.4683352131997385

Epoch: 6| Step: 11
Training loss: 1.6766952276229858
Validation loss: 2.474480216221143

Epoch: 6| Step: 12
Training loss: 2.8498730659484863
Validation loss: 2.4703007462204143

Epoch: 6| Step: 13
Training loss: 3.303284168243408
Validation loss: 2.4563246311679965

Epoch: 50| Step: 0
Training loss: 2.071014404296875
Validation loss: 2.4520330787986837

Epoch: 6| Step: 1
Training loss: 2.2362782955169678
Validation loss: 2.446952473732733

Epoch: 6| Step: 2
Training loss: 2.7425553798675537
Validation loss: 2.4418959976524435

Epoch: 6| Step: 3
Training loss: 3.206674098968506
Validation loss: 2.4401883489342144

Epoch: 6| Step: 4
Training loss: 3.0133132934570312
Validation loss: 2.4441398318095873

Epoch: 6| Step: 5
Training loss: 2.3222713470458984
Validation loss: 2.4380138868926675

Epoch: 6| Step: 6
Training loss: 3.4546401500701904
Validation loss: 2.4417139202035885

Epoch: 6| Step: 7
Training loss: 3.1335256099700928
Validation loss: 2.4382617499238703

Epoch: 6| Step: 8
Training loss: 2.110665798187256
Validation loss: 2.4431618387981127

Epoch: 6| Step: 9
Training loss: 2.4436092376708984
Validation loss: 2.4432825401265132

Epoch: 6| Step: 10
Training loss: 2.93257737159729
Validation loss: 2.4530327961009037

Epoch: 6| Step: 11
Training loss: 2.5460073947906494
Validation loss: 2.4651127515300626

Epoch: 6| Step: 12
Training loss: 2.176840305328369
Validation loss: 2.4922826020948348

Epoch: 6| Step: 13
Training loss: 3.3777589797973633
Validation loss: 2.4969791853299705

Epoch: 51| Step: 0
Training loss: 3.0016117095947266
Validation loss: 2.460837120650917

Epoch: 6| Step: 1
Training loss: 2.3181252479553223
Validation loss: 2.4392775207437496

Epoch: 6| Step: 2
Training loss: 2.3733468055725098
Validation loss: 2.4319846989006124

Epoch: 6| Step: 3
Training loss: 2.3922414779663086
Validation loss: 2.4327769946026545

Epoch: 6| Step: 4
Training loss: 2.749173164367676
Validation loss: 2.4396019238297657

Epoch: 6| Step: 5
Training loss: 2.178351402282715
Validation loss: 2.4456378977785826

Epoch: 6| Step: 6
Training loss: 3.385061740875244
Validation loss: 2.4462492850518998

Epoch: 6| Step: 7
Training loss: 3.348778486251831
Validation loss: 2.4539565527310936

Epoch: 6| Step: 8
Training loss: 2.777679443359375
Validation loss: 2.4518827494754585

Epoch: 6| Step: 9
Training loss: 2.581545829772949
Validation loss: 2.44380872736695

Epoch: 6| Step: 10
Training loss: 1.7486035823822021
Validation loss: 2.4405852979229343

Epoch: 6| Step: 11
Training loss: 3.1505727767944336
Validation loss: 2.434939302423949

Epoch: 6| Step: 12
Training loss: 3.0275144577026367
Validation loss: 2.432033977200908

Epoch: 6| Step: 13
Training loss: 2.4257774353027344
Validation loss: 2.4328370504481818

Epoch: 52| Step: 0
Training loss: 2.3204500675201416
Validation loss: 2.430474324892926

Epoch: 6| Step: 1
Training loss: 3.2178955078125
Validation loss: 2.436495873235887

Epoch: 6| Step: 2
Training loss: 2.776273250579834
Validation loss: 2.4335017870831233

Epoch: 6| Step: 3
Training loss: 2.051673412322998
Validation loss: 2.442490936607443

Epoch: 6| Step: 4
Training loss: 3.800105571746826
Validation loss: 2.441706790718981

Epoch: 6| Step: 5
Training loss: 2.4670145511627197
Validation loss: 2.4476691779269966

Epoch: 6| Step: 6
Training loss: 3.940166711807251
Validation loss: 2.4423750856871247

Epoch: 6| Step: 7
Training loss: 2.536904811859131
Validation loss: 2.436210047814154

Epoch: 6| Step: 8
Training loss: 2.4276833534240723
Validation loss: 2.4284419372517574

Epoch: 6| Step: 9
Training loss: 2.0873255729675293
Validation loss: 2.427373009343301

Epoch: 6| Step: 10
Training loss: 1.8706879615783691
Validation loss: 2.4275751395892073

Epoch: 6| Step: 11
Training loss: 2.1688623428344727
Validation loss: 2.438888603641141

Epoch: 6| Step: 12
Training loss: 3.042386054992676
Validation loss: 2.4602659645900933

Epoch: 6| Step: 13
Training loss: 2.3380703926086426
Validation loss: 2.484919540343746

Epoch: 53| Step: 0
Training loss: 2.611541271209717
Validation loss: 2.4773825266027965

Epoch: 6| Step: 1
Training loss: 2.7415499687194824
Validation loss: 2.469254570622598

Epoch: 6| Step: 2
Training loss: 3.0548768043518066
Validation loss: 2.4450709486520417

Epoch: 6| Step: 3
Training loss: 2.711047649383545
Validation loss: 2.4386285620350994

Epoch: 6| Step: 4
Training loss: 2.0315446853637695
Validation loss: 2.4416159301675777

Epoch: 6| Step: 5
Training loss: 3.134247303009033
Validation loss: 2.4390571322492374

Epoch: 6| Step: 6
Training loss: 2.334550619125366
Validation loss: 2.4303174634133615

Epoch: 6| Step: 7
Training loss: 2.3059091567993164
Validation loss: 2.4340367624836583

Epoch: 6| Step: 8
Training loss: 2.730497360229492
Validation loss: 2.4295096679400374

Epoch: 6| Step: 9
Training loss: 2.504683017730713
Validation loss: 2.42248337499557

Epoch: 6| Step: 10
Training loss: 2.2594001293182373
Validation loss: 2.4251968270988873

Epoch: 6| Step: 11
Training loss: 3.1890392303466797
Validation loss: 2.4228122721436205

Epoch: 6| Step: 12
Training loss: 2.7068474292755127
Validation loss: 2.420532632899541

Epoch: 6| Step: 13
Training loss: 2.868506908416748
Validation loss: 2.4195058294521865

Epoch: 54| Step: 0
Training loss: 3.5509464740753174
Validation loss: 2.419566398025841

Epoch: 6| Step: 1
Training loss: 2.962430715560913
Validation loss: 2.415685620359195

Epoch: 6| Step: 2
Training loss: 2.543292999267578
Validation loss: 2.4176383146675686

Epoch: 6| Step: 3
Training loss: 3.515634775161743
Validation loss: 2.4187413210509927

Epoch: 6| Step: 4
Training loss: 2.6111512184143066
Validation loss: 2.4194825028860443

Epoch: 6| Step: 5
Training loss: 2.1777095794677734
Validation loss: 2.4172292704223306

Epoch: 6| Step: 6
Training loss: 3.0868124961853027
Validation loss: 2.425798116191741

Epoch: 6| Step: 7
Training loss: 3.0717873573303223
Validation loss: 2.430021780793385

Epoch: 6| Step: 8
Training loss: 2.097506046295166
Validation loss: 2.434141235966836

Epoch: 6| Step: 9
Training loss: 2.681152820587158
Validation loss: 2.4308556895102225

Epoch: 6| Step: 10
Training loss: 2.41989803314209
Validation loss: 2.4203301014438754

Epoch: 6| Step: 11
Training loss: 1.6110082864761353
Validation loss: 2.4146260881936676

Epoch: 6| Step: 12
Training loss: 2.4666695594787598
Validation loss: 2.4153921578520086

Epoch: 6| Step: 13
Training loss: 2.147030830383301
Validation loss: 2.412427061347551

Epoch: 55| Step: 0
Training loss: 2.6454274654388428
Validation loss: 2.4087968205892913

Epoch: 6| Step: 1
Training loss: 2.5491385459899902
Validation loss: 2.4128925877232708

Epoch: 6| Step: 2
Training loss: 3.055436849594116
Validation loss: 2.412087381526988

Epoch: 6| Step: 3
Training loss: 2.536928653717041
Validation loss: 2.4148918198001

Epoch: 6| Step: 4
Training loss: 3.0273847579956055
Validation loss: 2.41267043031672

Epoch: 6| Step: 5
Training loss: 1.9568958282470703
Validation loss: 2.4171529841679398

Epoch: 6| Step: 6
Training loss: 2.0973119735717773
Validation loss: 2.419493950823302

Epoch: 6| Step: 7
Training loss: 3.113466262817383
Validation loss: 2.4319822172964773

Epoch: 6| Step: 8
Training loss: 3.2639174461364746
Validation loss: 2.430273499540103

Epoch: 6| Step: 9
Training loss: 2.8377156257629395
Validation loss: 2.4179425906109553

Epoch: 6| Step: 10
Training loss: 2.5495553016662598
Validation loss: 2.4141229916644353

Epoch: 6| Step: 11
Training loss: 3.4235193729400635
Validation loss: 2.4072434517645065

Epoch: 6| Step: 12
Training loss: 1.9012930393218994
Validation loss: 2.409413153125394

Epoch: 6| Step: 13
Training loss: 1.6242620944976807
Validation loss: 2.4124624088246334

Epoch: 56| Step: 0
Training loss: 3.5831031799316406
Validation loss: 2.4253333640354935

Epoch: 6| Step: 1
Training loss: 2.880502223968506
Validation loss: 2.4278189354045416

Epoch: 6| Step: 2
Training loss: 2.801079750061035
Validation loss: 2.4375803086065475

Epoch: 6| Step: 3
Training loss: 2.1592016220092773
Validation loss: 2.4330006543026177

Epoch: 6| Step: 4
Training loss: 2.1085598468780518
Validation loss: 2.418278181424705

Epoch: 6| Step: 5
Training loss: 3.2239859104156494
Validation loss: 2.4084600787008963

Epoch: 6| Step: 6
Training loss: 2.9243597984313965
Validation loss: 2.4026857191516506

Epoch: 6| Step: 7
Training loss: 2.455152988433838
Validation loss: 2.4006471890275196

Epoch: 6| Step: 8
Training loss: 1.9979462623596191
Validation loss: 2.4074943450189408

Epoch: 6| Step: 9
Training loss: 2.6052584648132324
Validation loss: 2.40530712117431

Epoch: 6| Step: 10
Training loss: 2.3881359100341797
Validation loss: 2.4048893887509584

Epoch: 6| Step: 11
Training loss: 2.639866828918457
Validation loss: 2.420959972566174

Epoch: 6| Step: 12
Training loss: 2.3019886016845703
Validation loss: 2.417096819928897

Epoch: 6| Step: 13
Training loss: 3.4347779750823975
Validation loss: 2.4105383414094166

Epoch: 57| Step: 0
Training loss: 2.298429250717163
Validation loss: 2.398949266761862

Epoch: 6| Step: 1
Training loss: 2.5596675872802734
Validation loss: 2.3988121965880036

Epoch: 6| Step: 2
Training loss: 2.6604747772216797
Validation loss: 2.401710820454423

Epoch: 6| Step: 3
Training loss: 2.83329439163208
Validation loss: 2.4159304839308544

Epoch: 6| Step: 4
Training loss: 2.7970309257507324
Validation loss: 2.4258569748170915

Epoch: 6| Step: 5
Training loss: 2.336174726486206
Validation loss: 2.4425862245662238

Epoch: 6| Step: 6
Training loss: 2.382126808166504
Validation loss: 2.4496814896983485

Epoch: 6| Step: 7
Training loss: 3.0539958477020264
Validation loss: 2.46730028429339

Epoch: 6| Step: 8
Training loss: 2.941425323486328
Validation loss: 2.471729432382891

Epoch: 6| Step: 9
Training loss: 2.4279704093933105
Validation loss: 2.4571523871473087

Epoch: 6| Step: 10
Training loss: 2.9996578693389893
Validation loss: 2.425740562459474

Epoch: 6| Step: 11
Training loss: 2.2671313285827637
Validation loss: 2.408391801259851

Epoch: 6| Step: 12
Training loss: 2.737429618835449
Validation loss: 2.391116375564247

Epoch: 6| Step: 13
Training loss: 2.989682197570801
Validation loss: 2.3923908664334204

Epoch: 58| Step: 0
Training loss: 2.2067651748657227
Validation loss: 2.392468272998769

Epoch: 6| Step: 1
Training loss: 2.6673102378845215
Validation loss: 2.3950133451851467

Epoch: 6| Step: 2
Training loss: 2.433410167694092
Validation loss: 2.3924470075996975

Epoch: 6| Step: 3
Training loss: 2.6947569847106934
Validation loss: 2.3933852026539464

Epoch: 6| Step: 4
Training loss: 3.2685706615448
Validation loss: 2.3899342039579987

Epoch: 6| Step: 5
Training loss: 3.1321158409118652
Validation loss: 2.388947997041928

Epoch: 6| Step: 6
Training loss: 2.2406563758850098
Validation loss: 2.388275423357564

Epoch: 6| Step: 7
Training loss: 2.899409055709839
Validation loss: 2.3880929767444568

Epoch: 6| Step: 8
Training loss: 2.8421053886413574
Validation loss: 2.3903154583387476

Epoch: 6| Step: 9
Training loss: 2.686063289642334
Validation loss: 2.389674109797324

Epoch: 6| Step: 10
Training loss: 2.0659549236297607
Validation loss: 2.3872170140666347

Epoch: 6| Step: 11
Training loss: 1.9431228637695312
Validation loss: 2.3854670883506857

Epoch: 6| Step: 12
Training loss: 3.3521294593811035
Validation loss: 2.3879169443602204

Epoch: 6| Step: 13
Training loss: 2.543750762939453
Validation loss: 2.3989588855415263

Epoch: 59| Step: 0
Training loss: 2.8667712211608887
Validation loss: 2.4132637439235562

Epoch: 6| Step: 1
Training loss: 2.4077281951904297
Validation loss: 2.411471818083076

Epoch: 6| Step: 2
Training loss: 2.4462063312530518
Validation loss: 2.4104484511959936

Epoch: 6| Step: 3
Training loss: 2.3837966918945312
Validation loss: 2.413833902728173

Epoch: 6| Step: 4
Training loss: 2.541339874267578
Validation loss: 2.3984708016918552

Epoch: 6| Step: 5
Training loss: 2.6923439502716064
Validation loss: 2.3952769387152886

Epoch: 6| Step: 6
Training loss: 2.4360122680664062
Validation loss: 2.3943319935952463

Epoch: 6| Step: 7
Training loss: 3.1992413997650146
Validation loss: 2.396185721120527

Epoch: 6| Step: 8
Training loss: 3.121044158935547
Validation loss: 2.402625601778748

Epoch: 6| Step: 9
Training loss: 1.768693208694458
Validation loss: 2.403332425702003

Epoch: 6| Step: 10
Training loss: 2.5243449211120605
Validation loss: 2.39721966046159

Epoch: 6| Step: 11
Training loss: 3.1467790603637695
Validation loss: 2.386720400984569

Epoch: 6| Step: 12
Training loss: 2.2903809547424316
Validation loss: 2.3888111447775238

Epoch: 6| Step: 13
Training loss: 3.2998461723327637
Validation loss: 2.3825609709626887

Epoch: 60| Step: 0
Training loss: 2.7770020961761475
Validation loss: 2.3840679814738612

Epoch: 6| Step: 1
Training loss: 2.5504114627838135
Validation loss: 2.38960999314503

Epoch: 6| Step: 2
Training loss: 2.001224994659424
Validation loss: 2.3877711911355295

Epoch: 6| Step: 3
Training loss: 2.545167922973633
Validation loss: 2.3863984487390004

Epoch: 6| Step: 4
Training loss: 2.57067608833313
Validation loss: 2.3843965453486287

Epoch: 6| Step: 5
Training loss: 1.8380417823791504
Validation loss: 2.3843168930340837

Epoch: 6| Step: 6
Training loss: 2.9410154819488525
Validation loss: 2.384515667474398

Epoch: 6| Step: 7
Training loss: 2.358597993850708
Validation loss: 2.3830181655063423

Epoch: 6| Step: 8
Training loss: 3.2061939239501953
Validation loss: 2.389866731500113

Epoch: 6| Step: 9
Training loss: 2.785562038421631
Validation loss: 2.385688368992139

Epoch: 6| Step: 10
Training loss: 2.5917460918426514
Validation loss: 2.391488928948679

Epoch: 6| Step: 11
Training loss: 2.955169200897217
Validation loss: 2.4034027925101658

Epoch: 6| Step: 12
Training loss: 2.5703845024108887
Validation loss: 2.419321255017352

Epoch: 6| Step: 13
Training loss: 3.2464282512664795
Validation loss: 2.4138521584131385

Epoch: 61| Step: 0
Training loss: 2.2227001190185547
Validation loss: 2.412202263391146

Epoch: 6| Step: 1
Training loss: 3.003000259399414
Validation loss: 2.405699929883403

Epoch: 6| Step: 2
Training loss: 2.709254503250122
Validation loss: 2.402474175217331

Epoch: 6| Step: 3
Training loss: 2.5249791145324707
Validation loss: 2.394289352560556

Epoch: 6| Step: 4
Training loss: 2.7182564735412598
Validation loss: 2.383337684856948

Epoch: 6| Step: 5
Training loss: 2.9464941024780273
Validation loss: 2.3760631674079487

Epoch: 6| Step: 6
Training loss: 3.177595615386963
Validation loss: 2.3746368577403407

Epoch: 6| Step: 7
Training loss: 3.0719943046569824
Validation loss: 2.3724408508628927

Epoch: 6| Step: 8
Training loss: 2.481330633163452
Validation loss: 2.369063033852526

Epoch: 6| Step: 9
Training loss: 2.2142786979675293
Validation loss: 2.3668698854343866

Epoch: 6| Step: 10
Training loss: 2.109229564666748
Validation loss: 2.366401841563563

Epoch: 6| Step: 11
Training loss: 2.227691650390625
Validation loss: 2.3673853566569667

Epoch: 6| Step: 12
Training loss: 2.56844425201416
Validation loss: 2.365515293613557

Epoch: 6| Step: 13
Training loss: 2.833950996398926
Validation loss: 2.368447652427099

Epoch: 62| Step: 0
Training loss: 3.0426244735717773
Validation loss: 2.3668914635976157

Epoch: 6| Step: 1
Training loss: 2.6460368633270264
Validation loss: 2.373184214356125

Epoch: 6| Step: 2
Training loss: 2.6835765838623047
Validation loss: 2.372732416276009

Epoch: 6| Step: 3
Training loss: 2.2925307750701904
Validation loss: 2.3843801380485616

Epoch: 6| Step: 4
Training loss: 2.323371410369873
Validation loss: 2.41319844799657

Epoch: 6| Step: 5
Training loss: 2.279339551925659
Validation loss: 2.4361503303691907

Epoch: 6| Step: 6
Training loss: 2.4767401218414307
Validation loss: 2.4409565284687984

Epoch: 6| Step: 7
Training loss: 2.433424949645996
Validation loss: 2.46294032501918

Epoch: 6| Step: 8
Training loss: 2.2961840629577637
Validation loss: 2.4594529854354037

Epoch: 6| Step: 9
Training loss: 2.3970396518707275
Validation loss: 2.43336562443805

Epoch: 6| Step: 10
Training loss: 3.511225700378418
Validation loss: 2.4133825532851683

Epoch: 6| Step: 11
Training loss: 2.8153982162475586
Validation loss: 2.3774001803449405

Epoch: 6| Step: 12
Training loss: 3.0626425743103027
Validation loss: 2.3689860707970074

Epoch: 6| Step: 13
Training loss: 2.4566352367401123
Validation loss: 2.3639916117473314

Epoch: 63| Step: 0
Training loss: 2.9109115600585938
Validation loss: 2.3585619849543416

Epoch: 6| Step: 1
Training loss: 2.614360809326172
Validation loss: 2.3581521254713818

Epoch: 6| Step: 2
Training loss: 2.1529083251953125
Validation loss: 2.356188386999151

Epoch: 6| Step: 3
Training loss: 2.7705249786376953
Validation loss: 2.3595129982117684

Epoch: 6| Step: 4
Training loss: 2.823779821395874
Validation loss: 2.360014336083525

Epoch: 6| Step: 5
Training loss: 2.399071216583252
Validation loss: 2.3683796672410864

Epoch: 6| Step: 6
Training loss: 2.168313980102539
Validation loss: 2.3824667674238964

Epoch: 6| Step: 7
Training loss: 2.87995982170105
Validation loss: 2.390641930282757

Epoch: 6| Step: 8
Training loss: 2.30043888092041
Validation loss: 2.382351013921922

Epoch: 6| Step: 9
Training loss: 2.9705638885498047
Validation loss: 2.37663802664767

Epoch: 6| Step: 10
Training loss: 2.3416457176208496
Validation loss: 2.3599697056637017

Epoch: 6| Step: 11
Training loss: 2.4131925106048584
Validation loss: 2.3517520453340266

Epoch: 6| Step: 12
Training loss: 2.9307069778442383
Validation loss: 2.350724338203348

Epoch: 6| Step: 13
Training loss: 3.3258862495422363
Validation loss: 2.3478795046447427

Epoch: 64| Step: 0
Training loss: 1.779740333557129
Validation loss: 2.3534957234577467

Epoch: 6| Step: 1
Training loss: 2.9338552951812744
Validation loss: 2.3557667629693144

Epoch: 6| Step: 2
Training loss: 2.4277830123901367
Validation loss: 2.355759379684284

Epoch: 6| Step: 3
Training loss: 3.1399428844451904
Validation loss: 2.3614985507021666

Epoch: 6| Step: 4
Training loss: 2.712599515914917
Validation loss: 2.367388686826152

Epoch: 6| Step: 5
Training loss: 2.3464431762695312
Validation loss: 2.3757254410815496

Epoch: 6| Step: 6
Training loss: 2.334315299987793
Validation loss: 2.390336077700379

Epoch: 6| Step: 7
Training loss: 2.8553757667541504
Validation loss: 2.4010125155090005

Epoch: 6| Step: 8
Training loss: 2.787355899810791
Validation loss: 2.3922574443201863

Epoch: 6| Step: 9
Training loss: 1.9302351474761963
Validation loss: 2.3774767742362073

Epoch: 6| Step: 10
Training loss: 2.893126964569092
Validation loss: 2.3530143922375095

Epoch: 6| Step: 11
Training loss: 2.5513663291931152
Validation loss: 2.347016483224848

Epoch: 6| Step: 12
Training loss: 2.802371025085449
Validation loss: 2.3422776576011413

Epoch: 6| Step: 13
Training loss: 3.2789759635925293
Validation loss: 2.3422516161395657

Epoch: 65| Step: 0
Training loss: 2.5943479537963867
Validation loss: 2.3412116548066497

Epoch: 6| Step: 1
Training loss: 2.4090609550476074
Validation loss: 2.343658701066048

Epoch: 6| Step: 2
Training loss: 2.51405668258667
Validation loss: 2.3446361659675516

Epoch: 6| Step: 3
Training loss: 2.3833227157592773
Validation loss: 2.342624725834016

Epoch: 6| Step: 4
Training loss: 2.717047691345215
Validation loss: 2.344059713425175

Epoch: 6| Step: 5
Training loss: 1.8886326551437378
Validation loss: 2.342156579417567

Epoch: 6| Step: 6
Training loss: 2.8717031478881836
Validation loss: 2.3531635269041984

Epoch: 6| Step: 7
Training loss: 1.9768974781036377
Validation loss: 2.3754428843016266

Epoch: 6| Step: 8
Training loss: 3.1303563117980957
Validation loss: 2.4090723350483882

Epoch: 6| Step: 9
Training loss: 3.3067288398742676
Validation loss: 2.469077476891138

Epoch: 6| Step: 10
Training loss: 2.89693021774292
Validation loss: 2.5344939770237094

Epoch: 6| Step: 11
Training loss: 2.7785494327545166
Validation loss: 2.5275172520709295

Epoch: 6| Step: 12
Training loss: 2.8834428787231445
Validation loss: 2.4394538094920497

Epoch: 6| Step: 13
Training loss: 2.4747564792633057
Validation loss: 2.395171880722046

Epoch: 66| Step: 0
Training loss: 3.1154532432556152
Validation loss: 2.368377011309388

Epoch: 6| Step: 1
Training loss: 2.170128107070923
Validation loss: 2.3480495278553297

Epoch: 6| Step: 2
Training loss: 2.529374599456787
Validation loss: 2.339784837538196

Epoch: 6| Step: 3
Training loss: 1.869972825050354
Validation loss: 2.3396672177058395

Epoch: 6| Step: 4
Training loss: 2.4476523399353027
Validation loss: 2.3434584935506186

Epoch: 6| Step: 5
Training loss: 2.66656494140625
Validation loss: 2.352887640717209

Epoch: 6| Step: 6
Training loss: 3.0839405059814453
Validation loss: 2.351995832176619

Epoch: 6| Step: 7
Training loss: 2.5739259719848633
Validation loss: 2.349603804208899

Epoch: 6| Step: 8
Training loss: 2.986790657043457
Validation loss: 2.348411049894107

Epoch: 6| Step: 9
Training loss: 2.399606704711914
Validation loss: 2.347686962414813

Epoch: 6| Step: 10
Training loss: 2.8351330757141113
Validation loss: 2.340125478723998

Epoch: 6| Step: 11
Training loss: 2.674532890319824
Validation loss: 2.3490655499119915

Epoch: 6| Step: 12
Training loss: 3.0409185886383057
Validation loss: 2.3635702645906838

Epoch: 6| Step: 13
Training loss: 1.6688942909240723
Validation loss: 2.362663161370062

Epoch: 67| Step: 0
Training loss: 2.6876065731048584
Validation loss: 2.3438001294289865

Epoch: 6| Step: 1
Training loss: 2.6746511459350586
Validation loss: 2.3373868965333506

Epoch: 6| Step: 2
Training loss: 1.8224767446517944
Validation loss: 2.325304046753914

Epoch: 6| Step: 3
Training loss: 3.0299389362335205
Validation loss: 2.3249338801189134

Epoch: 6| Step: 4
Training loss: 3.104027271270752
Validation loss: 2.330136563188286

Epoch: 6| Step: 5
Training loss: 3.2390456199645996
Validation loss: 2.3582133413642965

Epoch: 6| Step: 6
Training loss: 2.396249771118164
Validation loss: 2.3416703029345443

Epoch: 6| Step: 7
Training loss: 2.340705394744873
Validation loss: 2.330843112801993

Epoch: 6| Step: 8
Training loss: 2.653869867324829
Validation loss: 2.324708374597693

Epoch: 6| Step: 9
Training loss: 2.61210298538208
Validation loss: 2.325199270761141

Epoch: 6| Step: 10
Training loss: 3.1024112701416016
Validation loss: 2.320763582824379

Epoch: 6| Step: 11
Training loss: 2.6865663528442383
Validation loss: 2.3270807727690666

Epoch: 6| Step: 12
Training loss: 2.0747742652893066
Validation loss: 2.326113162502166

Epoch: 6| Step: 13
Training loss: 1.7812494039535522
Validation loss: 2.330582126494377

Epoch: 68| Step: 0
Training loss: 2.5450851917266846
Validation loss: 2.336268953097764

Epoch: 6| Step: 1
Training loss: 2.111004590988159
Validation loss: 2.355555490780902

Epoch: 6| Step: 2
Training loss: 3.273440361022949
Validation loss: 2.405760972730575

Epoch: 6| Step: 3
Training loss: 1.9815187454223633
Validation loss: 2.458854990620767

Epoch: 6| Step: 4
Training loss: 2.234250783920288
Validation loss: 2.546423250629056

Epoch: 6| Step: 5
Training loss: 2.5541951656341553
Validation loss: 2.5624867511051956

Epoch: 6| Step: 6
Training loss: 2.6288866996765137
Validation loss: 2.597742062742992

Epoch: 6| Step: 7
Training loss: 2.6016929149627686
Validation loss: 2.5288778274290022

Epoch: 6| Step: 8
Training loss: 3.0335991382598877
Validation loss: 2.4452880044137277

Epoch: 6| Step: 9
Training loss: 3.1927804946899414
Validation loss: 2.392657858069225

Epoch: 6| Step: 10
Training loss: 3.111769199371338
Validation loss: 2.3563658447675806

Epoch: 6| Step: 11
Training loss: 2.438596248626709
Validation loss: 2.329185411494265

Epoch: 6| Step: 12
Training loss: 2.9082155227661133
Validation loss: 2.358016424281623

Epoch: 6| Step: 13
Training loss: 2.4770009517669678
Validation loss: 2.3775169490486063

Epoch: 69| Step: 0
Training loss: 2.6967365741729736
Validation loss: 2.396196255119898

Epoch: 6| Step: 1
Training loss: 2.4290266036987305
Validation loss: 2.3389484907991145

Epoch: 6| Step: 2
Training loss: 2.8039886951446533
Validation loss: 2.324116437665878

Epoch: 6| Step: 3
Training loss: 2.9681849479675293
Validation loss: 2.318314178015596

Epoch: 6| Step: 4
Training loss: 2.4639554023742676
Validation loss: 2.3117009747412895

Epoch: 6| Step: 5
Training loss: 2.1805741786956787
Validation loss: 2.3205720404142975

Epoch: 6| Step: 6
Training loss: 2.795959949493408
Validation loss: 2.3381966583190428

Epoch: 6| Step: 7
Training loss: 2.6288070678710938
Validation loss: 2.342454018131379

Epoch: 6| Step: 8
Training loss: 2.091301679611206
Validation loss: 2.341930030494608

Epoch: 6| Step: 9
Training loss: 2.561737537384033
Validation loss: 2.3416338697556527

Epoch: 6| Step: 10
Training loss: 2.439246416091919
Validation loss: 2.3405254451177453

Epoch: 6| Step: 11
Training loss: 3.0711779594421387
Validation loss: 2.339823233183994

Epoch: 6| Step: 12
Training loss: 2.7806143760681152
Validation loss: 2.346368961436774

Epoch: 6| Step: 13
Training loss: 2.4752511978149414
Validation loss: 2.3452390265721146

Epoch: 70| Step: 0
Training loss: 2.5786819458007812
Validation loss: 2.3307170688465075

Epoch: 6| Step: 1
Training loss: 3.47408390045166
Validation loss: 2.3227377630049184

Epoch: 6| Step: 2
Training loss: 2.4837610721588135
Validation loss: 2.3150680808610815

Epoch: 6| Step: 3
Training loss: 2.729318618774414
Validation loss: 2.3133569276461037

Epoch: 6| Step: 4
Training loss: 2.136537790298462
Validation loss: 2.3120134594619914

Epoch: 6| Step: 5
Training loss: 3.2338709831237793
Validation loss: 2.320222452122678

Epoch: 6| Step: 6
Training loss: 2.339170455932617
Validation loss: 2.3262738976427304

Epoch: 6| Step: 7
Training loss: 2.541159152984619
Validation loss: 2.328481110193396

Epoch: 6| Step: 8
Training loss: 2.291400909423828
Validation loss: 2.325162567118163

Epoch: 6| Step: 9
Training loss: 2.2925801277160645
Validation loss: 2.3229089501083537

Epoch: 6| Step: 10
Training loss: 2.867353916168213
Validation loss: 2.3165832975859284

Epoch: 6| Step: 11
Training loss: 2.3579487800598145
Validation loss: 2.3185061998264764

Epoch: 6| Step: 12
Training loss: 2.4078822135925293
Validation loss: 2.308700015467982

Epoch: 6| Step: 13
Training loss: 2.502842903137207
Validation loss: 2.307408255915488

Epoch: 71| Step: 0
Training loss: 3.0308685302734375
Validation loss: 2.304976145426432

Epoch: 6| Step: 1
Training loss: 2.726337432861328
Validation loss: 2.307771803230368

Epoch: 6| Step: 2
Training loss: 1.969733715057373
Validation loss: 2.3085884919730564

Epoch: 6| Step: 3
Training loss: 3.210232734680176
Validation loss: 2.3075578597284134

Epoch: 6| Step: 4
Training loss: 3.170361280441284
Validation loss: 2.3144444009309173

Epoch: 6| Step: 5
Training loss: 2.048926591873169
Validation loss: 2.3139305371110157

Epoch: 6| Step: 6
Training loss: 2.425016403198242
Validation loss: 2.3092416691523727

Epoch: 6| Step: 7
Training loss: 2.682342529296875
Validation loss: 2.3150203151087605

Epoch: 6| Step: 8
Training loss: 2.9466376304626465
Validation loss: 2.3206903037204536

Epoch: 6| Step: 9
Training loss: 2.3268353939056396
Validation loss: 2.3162195297979538

Epoch: 6| Step: 10
Training loss: 1.9909980297088623
Validation loss: 2.327998076715777

Epoch: 6| Step: 11
Training loss: 2.2804486751556396
Validation loss: 2.325361510758759

Epoch: 6| Step: 12
Training loss: 2.6848959922790527
Validation loss: 2.3268893329046105

Epoch: 6| Step: 13
Training loss: 2.6402037143707275
Validation loss: 2.3340102318794496

Epoch: 72| Step: 0
Training loss: 2.21213960647583
Validation loss: 2.3373994211996756

Epoch: 6| Step: 1
Training loss: 1.9074013233184814
Validation loss: 2.335207398219775

Epoch: 6| Step: 2
Training loss: 3.440434217453003
Validation loss: 2.339017475804975

Epoch: 6| Step: 3
Training loss: 2.128138780593872
Validation loss: 2.3207601360095444

Epoch: 6| Step: 4
Training loss: 2.9199328422546387
Validation loss: 2.315404171584755

Epoch: 6| Step: 5
Training loss: 2.315028190612793
Validation loss: 2.310616736770958

Epoch: 6| Step: 6
Training loss: 2.4925103187561035
Validation loss: 2.3056274075661936

Epoch: 6| Step: 7
Training loss: 2.405979871749878
Validation loss: 2.3079174718549176

Epoch: 6| Step: 8
Training loss: 2.777819871902466
Validation loss: 2.315009335035919

Epoch: 6| Step: 9
Training loss: 2.793602705001831
Validation loss: 2.3199704334300053

Epoch: 6| Step: 10
Training loss: 3.036115884780884
Validation loss: 2.336599378175633

Epoch: 6| Step: 11
Training loss: 2.853144884109497
Validation loss: 2.333233294948455

Epoch: 6| Step: 12
Training loss: 2.535830497741699
Validation loss: 2.319555418465727

Epoch: 6| Step: 13
Training loss: 1.8835091590881348
Validation loss: 2.3094813644245105

Epoch: 73| Step: 0
Training loss: 3.1037697792053223
Validation loss: 2.3105213744665987

Epoch: 6| Step: 1
Training loss: 1.8622238636016846
Validation loss: 2.3084117033148326

Epoch: 6| Step: 2
Training loss: 2.481137275695801
Validation loss: 2.317051408111408

Epoch: 6| Step: 3
Training loss: 1.8788871765136719
Validation loss: 2.3266528524378294

Epoch: 6| Step: 4
Training loss: 2.581709146499634
Validation loss: 2.3175051622493292

Epoch: 6| Step: 5
Training loss: 2.955397605895996
Validation loss: 2.3136350749641337

Epoch: 6| Step: 6
Training loss: 2.949376106262207
Validation loss: 2.294044699720157

Epoch: 6| Step: 7
Training loss: 2.3109378814697266
Validation loss: 2.2961456134755123

Epoch: 6| Step: 8
Training loss: 2.64884352684021
Validation loss: 2.2924331875257593

Epoch: 6| Step: 9
Training loss: 2.543733596801758
Validation loss: 2.2817273780863774

Epoch: 6| Step: 10
Training loss: 2.4358062744140625
Validation loss: 2.2837960784153273

Epoch: 6| Step: 11
Training loss: 2.545529842376709
Validation loss: 2.2873135151401645

Epoch: 6| Step: 12
Training loss: 3.2930402755737305
Validation loss: 2.286620823285913

Epoch: 6| Step: 13
Training loss: 2.326017141342163
Validation loss: 2.284914655070151

Epoch: 74| Step: 0
Training loss: 2.3710625171661377
Validation loss: 2.278622437548894

Epoch: 6| Step: 1
Training loss: 2.456918478012085
Validation loss: 2.283812592106481

Epoch: 6| Step: 2
Training loss: 2.9868357181549072
Validation loss: 2.2934312512797694

Epoch: 6| Step: 3
Training loss: 2.5881834030151367
Validation loss: 2.3039968372673116

Epoch: 6| Step: 4
Training loss: 2.802097797393799
Validation loss: 2.3202792418900358

Epoch: 6| Step: 5
Training loss: 2.3830628395080566
Validation loss: 2.3275874609588296

Epoch: 6| Step: 6
Training loss: 2.563983917236328
Validation loss: 2.3346465915761967

Epoch: 6| Step: 7
Training loss: 2.3472847938537598
Validation loss: 2.371730919807188

Epoch: 6| Step: 8
Training loss: 3.0529794692993164
Validation loss: 2.374138834655926

Epoch: 6| Step: 9
Training loss: 2.600623369216919
Validation loss: 2.354413260695755

Epoch: 6| Step: 10
Training loss: 2.8609066009521484
Validation loss: 2.3191073915009857

Epoch: 6| Step: 11
Training loss: 2.5191283226013184
Validation loss: 2.3026069287330873

Epoch: 6| Step: 12
Training loss: 2.192030429840088
Validation loss: 2.297685907733056

Epoch: 6| Step: 13
Training loss: 2.0278549194335938
Validation loss: 2.30142238063197

Epoch: 75| Step: 0
Training loss: 3.2170662879943848
Validation loss: 2.2951433184326335

Epoch: 6| Step: 1
Training loss: 2.8271284103393555
Validation loss: 2.295406800444408

Epoch: 6| Step: 2
Training loss: 2.8092775344848633
Validation loss: 2.2963374045587357

Epoch: 6| Step: 3
Training loss: 1.759768009185791
Validation loss: 2.2864395187747095

Epoch: 6| Step: 4
Training loss: 2.689554452896118
Validation loss: 2.2866858461851716

Epoch: 6| Step: 5
Training loss: 2.4873945713043213
Validation loss: 2.2903302818216305

Epoch: 6| Step: 6
Training loss: 2.01882266998291
Validation loss: 2.2927628460750786

Epoch: 6| Step: 7
Training loss: 2.5429482460021973
Validation loss: 2.3053268706926735

Epoch: 6| Step: 8
Training loss: 3.122771978378296
Validation loss: 2.3256454852319535

Epoch: 6| Step: 9
Training loss: 2.338712215423584
Validation loss: 2.3406445031524985

Epoch: 6| Step: 10
Training loss: 2.1642234325408936
Validation loss: 2.3226207879281815

Epoch: 6| Step: 11
Training loss: 1.8714052438735962
Validation loss: 2.3129689719087336

Epoch: 6| Step: 12
Training loss: 3.3559823036193848
Validation loss: 2.3109497383076656

Epoch: 6| Step: 13
Training loss: 2.7806057929992676
Validation loss: 2.3041489765208256

Epoch: 76| Step: 0
Training loss: 2.3146438598632812
Validation loss: 2.29777947548897

Epoch: 6| Step: 1
Training loss: 2.247023105621338
Validation loss: 2.2965042603913175

Epoch: 6| Step: 2
Training loss: 2.3377554416656494
Validation loss: 2.2991428157334686

Epoch: 6| Step: 3
Training loss: 2.7577004432678223
Validation loss: 2.3170649236248386

Epoch: 6| Step: 4
Training loss: 3.6680843830108643
Validation loss: 2.3254787755268875

Epoch: 6| Step: 5
Training loss: 2.1798465251922607
Validation loss: 2.313035483001381

Epoch: 6| Step: 6
Training loss: 2.195356845855713
Validation loss: 2.301646501787247

Epoch: 6| Step: 7
Training loss: 2.170649290084839
Validation loss: 2.295104842032156

Epoch: 6| Step: 8
Training loss: 2.3389782905578613
Validation loss: 2.2886616594047955

Epoch: 6| Step: 9
Training loss: 3.0246524810791016
Validation loss: 2.2884132208362704

Epoch: 6| Step: 10
Training loss: 2.8439526557922363
Validation loss: 2.2826403443531325

Epoch: 6| Step: 11
Training loss: 2.9767074584960938
Validation loss: 2.2811975350943943

Epoch: 6| Step: 12
Training loss: 2.388096809387207
Validation loss: 2.27946440891553

Epoch: 6| Step: 13
Training loss: 2.310262441635132
Validation loss: 2.2745550370985463

Epoch: 77| Step: 0
Training loss: 3.1072354316711426
Validation loss: 2.2775801202302337

Epoch: 6| Step: 1
Training loss: 1.6585206985473633
Validation loss: 2.283712881867604

Epoch: 6| Step: 2
Training loss: 2.6521458625793457
Validation loss: 2.2894636764321277

Epoch: 6| Step: 3
Training loss: 2.0955567359924316
Validation loss: 2.3096896550988637

Epoch: 6| Step: 4
Training loss: 2.6399412155151367
Validation loss: 2.3173527499680877

Epoch: 6| Step: 5
Training loss: 2.3533365726470947
Validation loss: 2.3216033161327405

Epoch: 6| Step: 6
Training loss: 2.1577908992767334
Validation loss: 2.360992077858217

Epoch: 6| Step: 7
Training loss: 2.9496023654937744
Validation loss: 2.3459223521653043

Epoch: 6| Step: 8
Training loss: 2.6192402839660645
Validation loss: 2.3381771349137828

Epoch: 6| Step: 9
Training loss: 2.6956329345703125
Validation loss: 2.3203829616628666

Epoch: 6| Step: 10
Training loss: 2.808201789855957
Validation loss: 2.320377008889311

Epoch: 6| Step: 11
Training loss: 2.6392874717712402
Validation loss: 2.3150125331776117

Epoch: 6| Step: 12
Training loss: 2.9188082218170166
Validation loss: 2.305512402647285

Epoch: 6| Step: 13
Training loss: 2.734590768814087
Validation loss: 2.3059183705237603

Epoch: 78| Step: 0
Training loss: 3.037151575088501
Validation loss: 2.2867301535862747

Epoch: 6| Step: 1
Training loss: 2.9876761436462402
Validation loss: 2.2927650969515563

Epoch: 6| Step: 2
Training loss: 2.797825813293457
Validation loss: 2.289724148729796

Epoch: 6| Step: 3
Training loss: 1.6887153387069702
Validation loss: 2.2841525000910603

Epoch: 6| Step: 4
Training loss: 2.727156162261963
Validation loss: 2.288140199517691

Epoch: 6| Step: 5
Training loss: 2.4829723834991455
Validation loss: 2.2857811348412627

Epoch: 6| Step: 6
Training loss: 2.4108493328094482
Validation loss: 2.2826439437045845

Epoch: 6| Step: 7
Training loss: 2.1468334197998047
Validation loss: 2.2766770983255036

Epoch: 6| Step: 8
Training loss: 2.2676210403442383
Validation loss: 2.2680634478087067

Epoch: 6| Step: 9
Training loss: 2.590996265411377
Validation loss: 2.2675551829799527

Epoch: 6| Step: 10
Training loss: 2.9383463859558105
Validation loss: 2.272019536264481

Epoch: 6| Step: 11
Training loss: 3.377894163131714
Validation loss: 2.2691342407657253

Epoch: 6| Step: 12
Training loss: 2.0439491271972656
Validation loss: 2.2699965994845153

Epoch: 6| Step: 13
Training loss: 2.121666193008423
Validation loss: 2.293075446159609

Epoch: 79| Step: 0
Training loss: 2.7762718200683594
Validation loss: 2.3033771386710544

Epoch: 6| Step: 1
Training loss: 2.679048776626587
Validation loss: 2.298793826051938

Epoch: 6| Step: 2
Training loss: 2.645862102508545
Validation loss: 2.2860306001478627

Epoch: 6| Step: 3
Training loss: 3.066596746444702
Validation loss: 2.2749901304962816

Epoch: 6| Step: 4
Training loss: 2.576502799987793
Validation loss: 2.2756066745327366

Epoch: 6| Step: 5
Training loss: 2.1384472846984863
Validation loss: 2.2633198179224485

Epoch: 6| Step: 6
Training loss: 1.9974607229232788
Validation loss: 2.276483566530289

Epoch: 6| Step: 7
Training loss: 1.9251788854599
Validation loss: 2.2785793581316547

Epoch: 6| Step: 8
Training loss: 2.608109474182129
Validation loss: 2.2811705348312215

Epoch: 6| Step: 9
Training loss: 2.256009101867676
Validation loss: 2.2755396648119857

Epoch: 6| Step: 10
Training loss: 2.2761802673339844
Validation loss: 2.278699464695428

Epoch: 6| Step: 11
Training loss: 2.9564080238342285
Validation loss: 2.2767101282714517

Epoch: 6| Step: 12
Training loss: 2.995774507522583
Validation loss: 2.257801563509049

Epoch: 6| Step: 13
Training loss: 2.9883155822753906
Validation loss: 2.256279981264504

Epoch: 80| Step: 0
Training loss: 2.095118522644043
Validation loss: 2.256138640065347

Epoch: 6| Step: 1
Training loss: 1.6498558521270752
Validation loss: 2.271296606268934

Epoch: 6| Step: 2
Training loss: 2.5432004928588867
Validation loss: 2.3006536986238215

Epoch: 6| Step: 3
Training loss: 3.0927605628967285
Validation loss: 2.3238422665544736

Epoch: 6| Step: 4
Training loss: 2.3760929107666016
Validation loss: 2.343894576513639

Epoch: 6| Step: 5
Training loss: 2.5540266036987305
Validation loss: 2.352908424151841

Epoch: 6| Step: 6
Training loss: 3.4111249446868896
Validation loss: 2.329531846507903

Epoch: 6| Step: 7
Training loss: 1.8345955610275269
Validation loss: 2.3048231934988372

Epoch: 6| Step: 8
Training loss: 2.9284043312072754
Validation loss: 2.2900728666654198

Epoch: 6| Step: 9
Training loss: 1.8595706224441528
Validation loss: 2.2738568808442805

Epoch: 6| Step: 10
Training loss: 2.489830255508423
Validation loss: 2.2738520253089165

Epoch: 6| Step: 11
Training loss: 2.7151944637298584
Validation loss: 2.269398796942926

Epoch: 6| Step: 12
Training loss: 2.8737449645996094
Validation loss: 2.2731748114350023

Epoch: 6| Step: 13
Training loss: 3.25321102142334
Validation loss: 2.274571613598895

Epoch: 81| Step: 0
Training loss: 2.8304195404052734
Validation loss: 2.274825780622421

Epoch: 6| Step: 1
Training loss: 1.995290756225586
Validation loss: 2.2789813703106296

Epoch: 6| Step: 2
Training loss: 3.063352108001709
Validation loss: 2.285950699160176

Epoch: 6| Step: 3
Training loss: 3.2422571182250977
Validation loss: 2.2963540836047103

Epoch: 6| Step: 4
Training loss: 2.706027030944824
Validation loss: 2.2928907409791024

Epoch: 6| Step: 5
Training loss: 2.1713004112243652
Validation loss: 2.288708003618384

Epoch: 6| Step: 6
Training loss: 3.070916175842285
Validation loss: 2.288860910682268

Epoch: 6| Step: 7
Training loss: 2.245328903198242
Validation loss: 2.2852985294916297

Epoch: 6| Step: 8
Training loss: 2.32291579246521
Validation loss: 2.2878120996618785

Epoch: 6| Step: 9
Training loss: 1.7267570495605469
Validation loss: 2.2879442143183883

Epoch: 6| Step: 10
Training loss: 1.799229621887207
Validation loss: 2.277459631684006

Epoch: 6| Step: 11
Training loss: 2.4872355461120605
Validation loss: 2.2826691084010626

Epoch: 6| Step: 12
Training loss: 2.756401538848877
Validation loss: 2.2665699502473236

Epoch: 6| Step: 13
Training loss: 2.9577059745788574
Validation loss: 2.2580388720317552

Epoch: 82| Step: 0
Training loss: 2.286512851715088
Validation loss: 2.2510293145333566

Epoch: 6| Step: 1
Training loss: 2.1215147972106934
Validation loss: 2.2476035215521373

Epoch: 6| Step: 2
Training loss: 2.4801740646362305
Validation loss: 2.2413425548102266

Epoch: 6| Step: 3
Training loss: 2.4323506355285645
Validation loss: 2.239100105019026

Epoch: 6| Step: 4
Training loss: 2.6724956035614014
Validation loss: 2.2420008259434856

Epoch: 6| Step: 5
Training loss: 2.302340507507324
Validation loss: 2.2344336458431777

Epoch: 6| Step: 6
Training loss: 2.292572021484375
Validation loss: 2.24622409061719

Epoch: 6| Step: 7
Training loss: 2.7508556842803955
Validation loss: 2.2576783036672943

Epoch: 6| Step: 8
Training loss: 2.6489267349243164
Validation loss: 2.2725405526417557

Epoch: 6| Step: 9
Training loss: 3.527181625366211
Validation loss: 2.271971497484433

Epoch: 6| Step: 10
Training loss: 1.8995718955993652
Validation loss: 2.2637613152944915

Epoch: 6| Step: 11
Training loss: 2.3367247581481934
Validation loss: 2.2579474526066936

Epoch: 6| Step: 12
Training loss: 2.7753353118896484
Validation loss: 2.2444606596423733

Epoch: 6| Step: 13
Training loss: 2.8162176609039307
Validation loss: 2.2421658987640054

Epoch: 83| Step: 0
Training loss: 2.5609211921691895
Validation loss: 2.2474315884292766

Epoch: 6| Step: 1
Training loss: 2.6481270790100098
Validation loss: 2.2516907568900817

Epoch: 6| Step: 2
Training loss: 2.430938243865967
Validation loss: 2.2568989402504376

Epoch: 6| Step: 3
Training loss: 1.7965706586837769
Validation loss: 2.2538055463503768

Epoch: 6| Step: 4
Training loss: 1.9877760410308838
Validation loss: 2.254438800196494

Epoch: 6| Step: 5
Training loss: 2.987995147705078
Validation loss: 2.244569392614467

Epoch: 6| Step: 6
Training loss: 2.2225446701049805
Validation loss: 2.25139219017439

Epoch: 6| Step: 7
Training loss: 2.73275089263916
Validation loss: 2.2559187232807116

Epoch: 6| Step: 8
Training loss: 3.017566442489624
Validation loss: 2.258059578557168

Epoch: 6| Step: 9
Training loss: 2.020599365234375
Validation loss: 2.2451034720226

Epoch: 6| Step: 10
Training loss: 1.7237117290496826
Validation loss: 2.2462628579908803

Epoch: 6| Step: 11
Training loss: 2.609532356262207
Validation loss: 2.2451650660525084

Epoch: 6| Step: 12
Training loss: 3.308999538421631
Validation loss: 2.2405641719859135

Epoch: 6| Step: 13
Training loss: 3.2615253925323486
Validation loss: 2.246828449669705

Epoch: 84| Step: 0
Training loss: 2.4599785804748535
Validation loss: 2.249666944626839

Epoch: 6| Step: 1
Training loss: 2.3258328437805176
Validation loss: 2.2543319476548063

Epoch: 6| Step: 2
Training loss: 2.631025791168213
Validation loss: 2.250156553842688

Epoch: 6| Step: 3
Training loss: 2.2588295936584473
Validation loss: 2.2589984965580765

Epoch: 6| Step: 4
Training loss: 2.222796678543091
Validation loss: 2.2485181823853524

Epoch: 6| Step: 5
Training loss: 2.3545031547546387
Validation loss: 2.253810751822687

Epoch: 6| Step: 6
Training loss: 2.6158812046051025
Validation loss: 2.243016319890176

Epoch: 6| Step: 7
Training loss: 3.0471010208129883
Validation loss: 2.251218711176226

Epoch: 6| Step: 8
Training loss: 1.6657233238220215
Validation loss: 2.2658103742907123

Epoch: 6| Step: 9
Training loss: 1.9895672798156738
Validation loss: 2.2682735202133015

Epoch: 6| Step: 10
Training loss: 2.3846030235290527
Validation loss: 2.261911666521462

Epoch: 6| Step: 11
Training loss: 3.1114518642425537
Validation loss: 2.240684346486163

Epoch: 6| Step: 12
Training loss: 3.1404666900634766
Validation loss: 2.239967740992064

Epoch: 6| Step: 13
Training loss: 2.8137242794036865
Validation loss: 2.2364299348605576

Epoch: 85| Step: 0
Training loss: 2.5572147369384766
Validation loss: 2.227374930535593

Epoch: 6| Step: 1
Training loss: 1.911884069442749
Validation loss: 2.223548114940684

Epoch: 6| Step: 2
Training loss: 2.1981701850891113
Validation loss: 2.219709421998711

Epoch: 6| Step: 3
Training loss: 2.6989269256591797
Validation loss: 2.2180166013779177

Epoch: 6| Step: 4
Training loss: 3.0386433601379395
Validation loss: 2.2171868688316754

Epoch: 6| Step: 5
Training loss: 2.3917737007141113
Validation loss: 2.2147728140636156

Epoch: 6| Step: 6
Training loss: 3.4363746643066406
Validation loss: 2.226584944673764

Epoch: 6| Step: 7
Training loss: 2.4945626258850098
Validation loss: 2.245808765452395

Epoch: 6| Step: 8
Training loss: 2.00532865524292
Validation loss: 2.2658762060185915

Epoch: 6| Step: 9
Training loss: 2.9221386909484863
Validation loss: 2.2664909721702657

Epoch: 6| Step: 10
Training loss: 2.3491404056549072
Validation loss: 2.2807462138514363

Epoch: 6| Step: 11
Training loss: 1.8233702182769775
Validation loss: 2.249541626181654

Epoch: 6| Step: 12
Training loss: 2.9500932693481445
Validation loss: 2.2504322631384737

Epoch: 6| Step: 13
Training loss: 1.758320927619934
Validation loss: 2.229117352475402

Epoch: 86| Step: 0
Training loss: 2.5301291942596436
Validation loss: 2.2126837494552776

Epoch: 6| Step: 1
Training loss: 2.596404790878296
Validation loss: 2.2137527158183437

Epoch: 6| Step: 2
Training loss: 2.4786853790283203
Validation loss: 2.2121454105582288

Epoch: 6| Step: 3
Training loss: 2.3837015628814697
Validation loss: 2.210079526388517

Epoch: 6| Step: 4
Training loss: 1.7824316024780273
Validation loss: 2.211312360661004

Epoch: 6| Step: 5
Training loss: 1.9830243587493896
Validation loss: 2.2080966554662234

Epoch: 6| Step: 6
Training loss: 2.5947251319885254
Validation loss: 2.216621566844243

Epoch: 6| Step: 7
Training loss: 2.9256370067596436
Validation loss: 2.210806208272134

Epoch: 6| Step: 8
Training loss: 2.9018173217773438
Validation loss: 2.2123748820315123

Epoch: 6| Step: 9
Training loss: 2.2517597675323486
Validation loss: 2.22081184259025

Epoch: 6| Step: 10
Training loss: 3.16526460647583
Validation loss: 2.2509838586212485

Epoch: 6| Step: 11
Training loss: 2.640475034713745
Validation loss: 2.2598845317799556

Epoch: 6| Step: 12
Training loss: 2.0146431922912598
Validation loss: 2.2665048209569787

Epoch: 6| Step: 13
Training loss: 2.8765909671783447
Validation loss: 2.271519191803471

Epoch: 87| Step: 0
Training loss: 2.9497110843658447
Validation loss: 2.2405533893134004

Epoch: 6| Step: 1
Training loss: 2.3000330924987793
Validation loss: 2.215753996244041

Epoch: 6| Step: 2
Training loss: 2.8486227989196777
Validation loss: 2.2023371919508903

Epoch: 6| Step: 3
Training loss: 1.8784129619598389
Validation loss: 2.1991867506375877

Epoch: 6| Step: 4
Training loss: 2.583845615386963
Validation loss: 2.198732419680524

Epoch: 6| Step: 5
Training loss: 2.3220646381378174
Validation loss: 2.2030283443389402

Epoch: 6| Step: 6
Training loss: 2.773118495941162
Validation loss: 2.2050815320784047

Epoch: 6| Step: 7
Training loss: 2.853564739227295
Validation loss: 2.2076637667994343

Epoch: 6| Step: 8
Training loss: 2.2612924575805664
Validation loss: 2.202013910457652

Epoch: 6| Step: 9
Training loss: 2.307999610900879
Validation loss: 2.1964772491044897

Epoch: 6| Step: 10
Training loss: 2.82651424407959
Validation loss: 2.193260363353196

Epoch: 6| Step: 11
Training loss: 1.7492012977600098
Validation loss: 2.2035048456602198

Epoch: 6| Step: 12
Training loss: 2.5421206951141357
Validation loss: 2.20880030047509

Epoch: 6| Step: 13
Training loss: 3.244582176208496
Validation loss: 2.2672222891161518

Epoch: 88| Step: 0
Training loss: 2.1278491020202637
Validation loss: 2.300199531739758

Epoch: 6| Step: 1
Training loss: 2.7048416137695312
Validation loss: 2.3213370205253683

Epoch: 6| Step: 2
Training loss: 2.747152090072632
Validation loss: 2.323740977112965

Epoch: 6| Step: 3
Training loss: 2.043504238128662
Validation loss: 2.326150482700717

Epoch: 6| Step: 4
Training loss: 2.257215738296509
Validation loss: 2.292352132899787

Epoch: 6| Step: 5
Training loss: 3.566591739654541
Validation loss: 2.27862669960145

Epoch: 6| Step: 6
Training loss: 2.636930227279663
Validation loss: 2.2486066536236833

Epoch: 6| Step: 7
Training loss: 2.7644925117492676
Validation loss: 2.2230791661047165

Epoch: 6| Step: 8
Training loss: 1.9304478168487549
Validation loss: 2.210712868680236

Epoch: 6| Step: 9
Training loss: 2.7817869186401367
Validation loss: 2.1978440130910566

Epoch: 6| Step: 10
Training loss: 2.380791425704956
Validation loss: 2.2000187802058395

Epoch: 6| Step: 11
Training loss: 2.103799343109131
Validation loss: 2.196726995129739

Epoch: 6| Step: 12
Training loss: 2.141845703125
Validation loss: 2.2053628134471115

Epoch: 6| Step: 13
Training loss: 2.6402747631073
Validation loss: 2.1967783063970585

Epoch: 89| Step: 0
Training loss: 2.0239360332489014
Validation loss: 2.1938410420571604

Epoch: 6| Step: 1
Training loss: 2.609163284301758
Validation loss: 2.2003850590798164

Epoch: 6| Step: 2
Training loss: 2.4316024780273438
Validation loss: 2.213607641958421

Epoch: 6| Step: 3
Training loss: 2.218914031982422
Validation loss: 2.221033973078574

Epoch: 6| Step: 4
Training loss: 2.7445335388183594
Validation loss: 2.235574068561677

Epoch: 6| Step: 5
Training loss: 2.1064932346343994
Validation loss: 2.2558423806262273

Epoch: 6| Step: 6
Training loss: 2.928750991821289
Validation loss: 2.291882954617982

Epoch: 6| Step: 7
Training loss: 2.035785675048828
Validation loss: 2.3329824247667865

Epoch: 6| Step: 8
Training loss: 3.0563645362854004
Validation loss: 2.351089608284735

Epoch: 6| Step: 9
Training loss: 2.7554221153259277
Validation loss: 2.2625020063051613

Epoch: 6| Step: 10
Training loss: 1.9931540489196777
Validation loss: 2.211521202518094

Epoch: 6| Step: 11
Training loss: 2.6968536376953125
Validation loss: 2.2012516785693426

Epoch: 6| Step: 12
Training loss: 2.7684402465820312
Validation loss: 2.2166040866605696

Epoch: 6| Step: 13
Training loss: 2.293686866760254
Validation loss: 2.211779814894481

Epoch: 90| Step: 0
Training loss: 2.3248066902160645
Validation loss: 2.2577870558666926

Epoch: 6| Step: 1
Training loss: 2.3312368392944336
Validation loss: 2.349306075803695

Epoch: 6| Step: 2
Training loss: 3.3026537895202637
Validation loss: 2.4091646850750013

Epoch: 6| Step: 3
Training loss: 3.277392625808716
Validation loss: 2.3973988512510895

Epoch: 6| Step: 4
Training loss: 2.6674365997314453
Validation loss: 2.382134750325193

Epoch: 6| Step: 5
Training loss: 2.7831766605377197
Validation loss: 2.395913980340445

Epoch: 6| Step: 6
Training loss: 3.36328125
Validation loss: 2.406780663356986

Epoch: 6| Step: 7
Training loss: 2.30260968208313
Validation loss: 2.4125690793478363

Epoch: 6| Step: 8
Training loss: 2.578145980834961
Validation loss: 2.437370369511266

Epoch: 6| Step: 9
Training loss: 2.7017385959625244
Validation loss: 2.4557522573778705

Epoch: 6| Step: 10
Training loss: 2.1598784923553467
Validation loss: 2.442170573819068

Epoch: 6| Step: 11
Training loss: 2.017983913421631
Validation loss: 2.4048512674147084

Epoch: 6| Step: 12
Training loss: 2.0050861835479736
Validation loss: 2.37268385066781

Epoch: 6| Step: 13
Training loss: 2.7137646675109863
Validation loss: 2.3557180973791305

Epoch: 91| Step: 0
Training loss: 2.584916114807129
Validation loss: 2.3350858098717144

Epoch: 6| Step: 1
Training loss: 2.4973866939544678
Validation loss: 2.324612625183598

Epoch: 6| Step: 2
Training loss: 2.7244794368743896
Validation loss: 2.3320886473501883

Epoch: 6| Step: 3
Training loss: 2.4617528915405273
Validation loss: 2.3372239476890972

Epoch: 6| Step: 4
Training loss: 1.9281344413757324
Validation loss: 2.3217980041298816

Epoch: 6| Step: 5
Training loss: 1.7556813955307007
Validation loss: 2.298707490326256

Epoch: 6| Step: 6
Training loss: 2.1514368057250977
Validation loss: 2.2988952334209154

Epoch: 6| Step: 7
Training loss: 2.905189275741577
Validation loss: 2.2888523404316237

Epoch: 6| Step: 8
Training loss: 2.254912853240967
Validation loss: 2.299749284662226

Epoch: 6| Step: 9
Training loss: 3.5630385875701904
Validation loss: 2.3024477779224353

Epoch: 6| Step: 10
Training loss: 3.127758026123047
Validation loss: 2.270067621302861

Epoch: 6| Step: 11
Training loss: 2.8466620445251465
Validation loss: 2.2659734628533803

Epoch: 6| Step: 12
Training loss: 2.181406021118164
Validation loss: 2.254956024949269

Epoch: 6| Step: 13
Training loss: 2.4806034564971924
Validation loss: 2.244493084569131

Epoch: 92| Step: 0
Training loss: 1.880012035369873
Validation loss: 2.244539540301087

Epoch: 6| Step: 1
Training loss: 2.6262264251708984
Validation loss: 2.238652237000004

Epoch: 6| Step: 2
Training loss: 3.1356887817382812
Validation loss: 2.239863380309074

Epoch: 6| Step: 3
Training loss: 2.757295608520508
Validation loss: 2.245797262396864

Epoch: 6| Step: 4
Training loss: 2.3205838203430176
Validation loss: 2.244701862335205

Epoch: 6| Step: 5
Training loss: 1.5593452453613281
Validation loss: 2.2539066550552205

Epoch: 6| Step: 6
Training loss: 2.089754581451416
Validation loss: 2.2633188052843978

Epoch: 6| Step: 7
Training loss: 3.453886032104492
Validation loss: 2.2546847725427277

Epoch: 6| Step: 8
Training loss: 3.3996405601501465
Validation loss: 2.260789967352344

Epoch: 6| Step: 9
Training loss: 2.368436098098755
Validation loss: 2.2567653873915314

Epoch: 6| Step: 10
Training loss: 2.174985408782959
Validation loss: 2.2487205715589624

Epoch: 6| Step: 11
Training loss: 2.4069857597351074
Validation loss: 2.244754265713435

Epoch: 6| Step: 12
Training loss: 2.40634822845459
Validation loss: 2.254976552019837

Epoch: 6| Step: 13
Training loss: 1.8374754190444946
Validation loss: 2.256719309796569

Epoch: 93| Step: 0
Training loss: 2.4737634658813477
Validation loss: 2.2686116669767644

Epoch: 6| Step: 1
Training loss: 2.8849949836730957
Validation loss: 2.2362257152475338

Epoch: 6| Step: 2
Training loss: 1.683110237121582
Validation loss: 2.2174337999795073

Epoch: 6| Step: 3
Training loss: 2.6570467948913574
Validation loss: 2.207861638838245

Epoch: 6| Step: 4
Training loss: 2.3534626960754395
Validation loss: 2.198959255731234

Epoch: 6| Step: 5
Training loss: 2.7940833568573
Validation loss: 2.184626812575966

Epoch: 6| Step: 6
Training loss: 2.483466148376465
Validation loss: 2.1829170155268844

Epoch: 6| Step: 7
Training loss: 2.322789192199707
Validation loss: 2.181614522011049

Epoch: 6| Step: 8
Training loss: 2.752506732940674
Validation loss: 2.179172113377561

Epoch: 6| Step: 9
Training loss: 2.322556495666504
Validation loss: 2.1806617475325063

Epoch: 6| Step: 10
Training loss: 2.2839112281799316
Validation loss: 2.1808801440782446

Epoch: 6| Step: 11
Training loss: 2.7036702632904053
Validation loss: 2.1845661440203266

Epoch: 6| Step: 12
Training loss: 2.273618221282959
Validation loss: 2.190423077152621

Epoch: 6| Step: 13
Training loss: 2.3390519618988037
Validation loss: 2.19961981363194

Epoch: 94| Step: 0
Training loss: 2.7354559898376465
Validation loss: 2.216420058281191

Epoch: 6| Step: 1
Training loss: 2.4963114261627197
Validation loss: 2.224269249105966

Epoch: 6| Step: 2
Training loss: 2.1397452354431152
Validation loss: 2.223713605634628

Epoch: 6| Step: 3
Training loss: 2.47263240814209
Validation loss: 2.2291449551941245

Epoch: 6| Step: 4
Training loss: 2.198855400085449
Validation loss: 2.223882673889078

Epoch: 6| Step: 5
Training loss: 1.7418526411056519
Validation loss: 2.2241525932024886

Epoch: 6| Step: 6
Training loss: 2.5907745361328125
Validation loss: 2.210671563302317

Epoch: 6| Step: 7
Training loss: 2.4677631855010986
Validation loss: 2.1956861775408507

Epoch: 6| Step: 8
Training loss: 3.2737584114074707
Validation loss: 2.188877918386972

Epoch: 6| Step: 9
Training loss: 2.241116523742676
Validation loss: 2.1813370156031784

Epoch: 6| Step: 10
Training loss: 2.6234569549560547
Validation loss: 2.1818716346576648

Epoch: 6| Step: 11
Training loss: 1.9253480434417725
Validation loss: 2.1881494906640824

Epoch: 6| Step: 12
Training loss: 2.8833203315734863
Validation loss: 2.1887476290425947

Epoch: 6| Step: 13
Training loss: 2.2912936210632324
Validation loss: 2.189441834726641

Epoch: 95| Step: 0
Training loss: 2.575009346008301
Validation loss: 2.2055059504765335

Epoch: 6| Step: 1
Training loss: 2.3206801414489746
Validation loss: 2.2400596193088

Epoch: 6| Step: 2
Training loss: 2.206761121749878
Validation loss: 2.264065347692018

Epoch: 6| Step: 3
Training loss: 2.826167583465576
Validation loss: 2.261973827115951

Epoch: 6| Step: 4
Training loss: 3.0318737030029297
Validation loss: 2.2298336080325547

Epoch: 6| Step: 5
Training loss: 2.145991086959839
Validation loss: 2.196959269944058

Epoch: 6| Step: 6
Training loss: 2.275071620941162
Validation loss: 2.1808461732761835

Epoch: 6| Step: 7
Training loss: 2.0851168632507324
Validation loss: 2.1949402119523738

Epoch: 6| Step: 8
Training loss: 3.2207136154174805
Validation loss: 2.208564278899982

Epoch: 6| Step: 9
Training loss: 2.8233227729797363
Validation loss: 2.3090204551655757

Epoch: 6| Step: 10
Training loss: 1.9744771718978882
Validation loss: 2.2262027661005654

Epoch: 6| Step: 11
Training loss: 2.7923922538757324
Validation loss: 2.2020304523488528

Epoch: 6| Step: 12
Training loss: 1.6776256561279297
Validation loss: 2.2036535227170555

Epoch: 6| Step: 13
Training loss: 2.204770803451538
Validation loss: 2.1886170243704193

Epoch: 96| Step: 0
Training loss: 2.8944716453552246
Validation loss: 2.188982984071137

Epoch: 6| Step: 1
Training loss: 2.788729190826416
Validation loss: 2.185493755084212

Epoch: 6| Step: 2
Training loss: 2.1176037788391113
Validation loss: 2.183192173639933

Epoch: 6| Step: 3
Training loss: 1.8272889852523804
Validation loss: 2.203377946730583

Epoch: 6| Step: 4
Training loss: 1.8438892364501953
Validation loss: 2.207399583631946

Epoch: 6| Step: 5
Training loss: 2.325538396835327
Validation loss: 2.194048179093228

Epoch: 6| Step: 6
Training loss: 1.8169481754302979
Validation loss: 2.1784937099743913

Epoch: 6| Step: 7
Training loss: 2.7285001277923584
Validation loss: 2.169563352420766

Epoch: 6| Step: 8
Training loss: 2.934072971343994
Validation loss: 2.1628438606057117

Epoch: 6| Step: 9
Training loss: 2.972755193710327
Validation loss: 2.1704041727127565

Epoch: 6| Step: 10
Training loss: 2.328202486038208
Validation loss: 2.1673389480959986

Epoch: 6| Step: 11
Training loss: 2.774662971496582
Validation loss: 2.1742552249662337

Epoch: 6| Step: 12
Training loss: 2.0762112140655518
Validation loss: 2.168167153994242

Epoch: 6| Step: 13
Training loss: 2.5578033924102783
Validation loss: 2.167621753549063

Epoch: 97| Step: 0
Training loss: 1.6269659996032715
Validation loss: 2.171533494867304

Epoch: 6| Step: 1
Training loss: 2.397691249847412
Validation loss: 2.1637420167205152

Epoch: 6| Step: 2
Training loss: 1.285881757736206
Validation loss: 2.1885369016278173

Epoch: 6| Step: 3
Training loss: 2.1717472076416016
Validation loss: 2.1981576360682005

Epoch: 6| Step: 4
Training loss: 2.04150390625
Validation loss: 2.2315038891248804

Epoch: 6| Step: 5
Training loss: 2.1589133739471436
Validation loss: 2.2395253642912833

Epoch: 6| Step: 6
Training loss: 2.3781588077545166
Validation loss: 2.2047924277602986

Epoch: 6| Step: 7
Training loss: 2.7983832359313965
Validation loss: 2.1868378769966865

Epoch: 6| Step: 8
Training loss: 3.0255179405212402
Validation loss: 2.1909801677990983

Epoch: 6| Step: 9
Training loss: 3.4738821983337402
Validation loss: 2.174803405679682

Epoch: 6| Step: 10
Training loss: 1.6522793769836426
Validation loss: 2.171292171683363

Epoch: 6| Step: 11
Training loss: 3.066751480102539
Validation loss: 2.169129520334223

Epoch: 6| Step: 12
Training loss: 2.988135814666748
Validation loss: 2.1570923366854267

Epoch: 6| Step: 13
Training loss: 2.9209365844726562
Validation loss: 2.1555231386615383

Epoch: 98| Step: 0
Training loss: 2.850722312927246
Validation loss: 2.1529572086949504

Epoch: 6| Step: 1
Training loss: 2.4851481914520264
Validation loss: 2.1522994554170998

Epoch: 6| Step: 2
Training loss: 2.5914368629455566
Validation loss: 2.153478480154468

Epoch: 6| Step: 3
Training loss: 2.5425033569335938
Validation loss: 2.1537083605284333

Epoch: 6| Step: 4
Training loss: 2.463040828704834
Validation loss: 2.146555257099931

Epoch: 6| Step: 5
Training loss: 2.5803608894348145
Validation loss: 2.144594389905212

Epoch: 6| Step: 6
Training loss: 2.41135311126709
Validation loss: 2.1395762505069857

Epoch: 6| Step: 7
Training loss: 2.396334171295166
Validation loss: 2.14915527835969

Epoch: 6| Step: 8
Training loss: 2.093945026397705
Validation loss: 2.139617348230013

Epoch: 6| Step: 9
Training loss: 2.373084306716919
Validation loss: 2.146270787844094

Epoch: 6| Step: 10
Training loss: 1.724008560180664
Validation loss: 2.1535114857458297

Epoch: 6| Step: 11
Training loss: 2.097011089324951
Validation loss: 2.1638856446871193

Epoch: 6| Step: 12
Training loss: 2.5762438774108887
Validation loss: 2.150692826958113

Epoch: 6| Step: 13
Training loss: 2.269428253173828
Validation loss: 2.1479003480685654

Epoch: 99| Step: 0
Training loss: 2.5795254707336426
Validation loss: 2.1441830153106363

Epoch: 6| Step: 1
Training loss: 1.6506774425506592
Validation loss: 2.1459853854230655

Epoch: 6| Step: 2
Training loss: 2.0596752166748047
Validation loss: 2.1412176726966776

Epoch: 6| Step: 3
Training loss: 2.2789034843444824
Validation loss: 2.139004293308463

Epoch: 6| Step: 4
Training loss: 2.3231725692749023
Validation loss: 2.136195180236652

Epoch: 6| Step: 5
Training loss: 2.1519775390625
Validation loss: 2.1474433560525217

Epoch: 6| Step: 6
Training loss: 3.234571933746338
Validation loss: 2.147456255010379

Epoch: 6| Step: 7
Training loss: 2.9866862297058105
Validation loss: 2.1532065227467525

Epoch: 6| Step: 8
Training loss: 3.1647846698760986
Validation loss: 2.1469971697817565

Epoch: 6| Step: 9
Training loss: 1.5020146369934082
Validation loss: 2.1582141896729827

Epoch: 6| Step: 10
Training loss: 2.27195143699646
Validation loss: 2.160455157679896

Epoch: 6| Step: 11
Training loss: 2.076610803604126
Validation loss: 2.170531557452294

Epoch: 6| Step: 12
Training loss: 2.780470609664917
Validation loss: 2.174143524580104

Epoch: 6| Step: 13
Training loss: 2.047682285308838
Validation loss: 2.1647333893724667

Epoch: 100| Step: 0
Training loss: 1.4423904418945312
Validation loss: 2.1436850998991277

Epoch: 6| Step: 1
Training loss: 2.8572144508361816
Validation loss: 2.1381779486133206

Epoch: 6| Step: 2
Training loss: 3.282581329345703
Validation loss: 2.1362538517162366

Epoch: 6| Step: 3
Training loss: 2.0541906356811523
Validation loss: 2.1293112462566746

Epoch: 6| Step: 4
Training loss: 2.7454915046691895
Validation loss: 2.1283859488784627

Epoch: 6| Step: 5
Training loss: 2.116529703140259
Validation loss: 2.1355798398294756

Epoch: 6| Step: 6
Training loss: 2.8474459648132324
Validation loss: 2.1327145535458802

Epoch: 6| Step: 7
Training loss: 2.220853567123413
Validation loss: 2.1322328864887194

Epoch: 6| Step: 8
Training loss: 2.1392173767089844
Validation loss: 2.1312604258137364

Epoch: 6| Step: 9
Training loss: 2.1215314865112305
Validation loss: 2.137444201336112

Epoch: 6| Step: 10
Training loss: 2.7426586151123047
Validation loss: 2.16959233309633

Epoch: 6| Step: 11
Training loss: 2.675720453262329
Validation loss: 2.203215468314386

Epoch: 6| Step: 12
Training loss: 1.733006477355957
Validation loss: 2.226702377360354

Epoch: 6| Step: 13
Training loss: 2.9014172554016113
Validation loss: 2.2341485318317207

Epoch: 101| Step: 0
Training loss: 2.1858386993408203
Validation loss: 2.231842887017035

Epoch: 6| Step: 1
Training loss: 2.8382043838500977
Validation loss: 2.2156258090849845

Epoch: 6| Step: 2
Training loss: 2.2756571769714355
Validation loss: 2.189031171542342

Epoch: 6| Step: 3
Training loss: 2.149728298187256
Validation loss: 2.149093307474608

Epoch: 6| Step: 4
Training loss: 1.8793418407440186
Validation loss: 2.125957877405228

Epoch: 6| Step: 5
Training loss: 1.644160270690918
Validation loss: 2.113310435766815

Epoch: 6| Step: 6
Training loss: 2.215736150741577
Validation loss: 2.1131652555158063

Epoch: 6| Step: 7
Training loss: 2.6848151683807373
Validation loss: 2.126900860058364

Epoch: 6| Step: 8
Training loss: 2.2220029830932617
Validation loss: 2.135413323679278

Epoch: 6| Step: 9
Training loss: 2.015070915222168
Validation loss: 2.15154109462615

Epoch: 6| Step: 10
Training loss: 3.4367024898529053
Validation loss: 2.168071395607405

Epoch: 6| Step: 11
Training loss: 2.225916624069214
Validation loss: 2.1766912475708993

Epoch: 6| Step: 12
Training loss: 2.9399099349975586
Validation loss: 2.2030765651374735

Epoch: 6| Step: 13
Training loss: 2.954805612564087
Validation loss: 2.202404091435094

Epoch: 102| Step: 0
Training loss: 2.0940515995025635
Validation loss: 2.186785149317916

Epoch: 6| Step: 1
Training loss: 3.1243176460266113
Validation loss: 2.1501505964545795

Epoch: 6| Step: 2
Training loss: 2.4215641021728516
Validation loss: 2.15458325160447

Epoch: 6| Step: 3
Training loss: 2.9630167484283447
Validation loss: 2.1417460390316543

Epoch: 6| Step: 4
Training loss: 2.022980213165283
Validation loss: 2.1514136688683623

Epoch: 6| Step: 5
Training loss: 2.2926101684570312
Validation loss: 2.1389349250383276

Epoch: 6| Step: 6
Training loss: 2.3976385593414307
Validation loss: 2.150480571613517

Epoch: 6| Step: 7
Training loss: 2.3808093070983887
Validation loss: 2.15906088582931

Epoch: 6| Step: 8
Training loss: 2.303299903869629
Validation loss: 2.14606717325026

Epoch: 6| Step: 9
Training loss: 2.5099611282348633
Validation loss: 2.159139102505099

Epoch: 6| Step: 10
Training loss: 1.9119247198104858
Validation loss: 2.1827827307485763

Epoch: 6| Step: 11
Training loss: 2.6743290424346924
Validation loss: 2.1953246849839405

Epoch: 6| Step: 12
Training loss: 2.6922059059143066
Validation loss: 2.216343266989595

Epoch: 6| Step: 13
Training loss: 2.1584718227386475
Validation loss: 2.210566343799714

Epoch: 103| Step: 0
Training loss: 2.3081002235412598
Validation loss: 2.15142781888285

Epoch: 6| Step: 1
Training loss: 2.287924289703369
Validation loss: 2.1300234333161385

Epoch: 6| Step: 2
Training loss: 3.0710349082946777
Validation loss: 2.1288230188431276

Epoch: 6| Step: 3
Training loss: 2.1340341567993164
Validation loss: 2.1226240768227527

Epoch: 6| Step: 4
Training loss: 2.299959421157837
Validation loss: 2.119487811160344

Epoch: 6| Step: 5
Training loss: 2.4618375301361084
Validation loss: 2.134532020938012

Epoch: 6| Step: 6
Training loss: 2.5337185859680176
Validation loss: 2.1366525773079164

Epoch: 6| Step: 7
Training loss: 2.905702590942383
Validation loss: 2.1517991840198474

Epoch: 6| Step: 8
Training loss: 2.198866605758667
Validation loss: 2.1724620198690765

Epoch: 6| Step: 9
Training loss: 2.211629629135132
Validation loss: 2.1772642648348244

Epoch: 6| Step: 10
Training loss: 2.5059738159179688
Validation loss: 2.1357961162444083

Epoch: 6| Step: 11
Training loss: 2.3654322624206543
Validation loss: 2.1290119604397844

Epoch: 6| Step: 12
Training loss: 1.9787263870239258
Validation loss: 2.1288539260946293

Epoch: 6| Step: 13
Training loss: 2.154935359954834
Validation loss: 2.127788564210297

Epoch: 104| Step: 0
Training loss: 2.7077999114990234
Validation loss: 2.128303461177375

Epoch: 6| Step: 1
Training loss: 2.134976863861084
Validation loss: 2.128381318943475

Epoch: 6| Step: 2
Training loss: 2.3515090942382812
Validation loss: 2.116448760032654

Epoch: 6| Step: 3
Training loss: 1.9550888538360596
Validation loss: 2.1170566184546358

Epoch: 6| Step: 4
Training loss: 2.479187488555908
Validation loss: 2.1051738492904173

Epoch: 6| Step: 5
Training loss: 2.142035961151123
Validation loss: 2.094976125224944

Epoch: 6| Step: 6
Training loss: 2.4157938957214355
Validation loss: 2.100296458890361

Epoch: 6| Step: 7
Training loss: 2.6161201000213623
Validation loss: 2.1013759566891577

Epoch: 6| Step: 8
Training loss: 2.370365619659424
Validation loss: 2.1073726325906734

Epoch: 6| Step: 9
Training loss: 2.2522902488708496
Validation loss: 2.1118863936393493

Epoch: 6| Step: 10
Training loss: 2.253699779510498
Validation loss: 2.1119821045988347

Epoch: 6| Step: 11
Training loss: 3.08801007270813
Validation loss: 2.1209796039007043

Epoch: 6| Step: 12
Training loss: 2.5535151958465576
Validation loss: 2.1311702882089922

Epoch: 6| Step: 13
Training loss: 1.750488519668579
Validation loss: 2.142457131416567

Epoch: 105| Step: 0
Training loss: 3.002683162689209
Validation loss: 2.156722801987843

Epoch: 6| Step: 1
Training loss: 2.1487715244293213
Validation loss: 2.1533965782452653

Epoch: 6| Step: 2
Training loss: 2.101306915283203
Validation loss: 2.162229491818336

Epoch: 6| Step: 3
Training loss: 3.006549835205078
Validation loss: 2.1804195245107016

Epoch: 6| Step: 4
Training loss: 3.119056224822998
Validation loss: 2.173884504584856

Epoch: 6| Step: 5
Training loss: 2.2220749855041504
Validation loss: 2.1681841586225774

Epoch: 6| Step: 6
Training loss: 2.3611514568328857
Validation loss: 2.1741165371351343

Epoch: 6| Step: 7
Training loss: 2.2187469005584717
Validation loss: 2.156456532016877

Epoch: 6| Step: 8
Training loss: 2.5395634174346924
Validation loss: 2.154157648804367

Epoch: 6| Step: 9
Training loss: 2.701984167098999
Validation loss: 2.1572349532958

Epoch: 6| Step: 10
Training loss: 2.583772659301758
Validation loss: 2.1608412124777354

Epoch: 6| Step: 11
Training loss: 1.530057430267334
Validation loss: 2.1789112347428516

Epoch: 6| Step: 12
Training loss: 2.195274829864502
Validation loss: 2.176862285983178

Epoch: 6| Step: 13
Training loss: 1.5981659889221191
Validation loss: 2.1831911225472727

Epoch: 106| Step: 0
Training loss: 2.4278573989868164
Validation loss: 2.1705632184141423

Epoch: 6| Step: 1
Training loss: 3.1233091354370117
Validation loss: 2.164351745318341

Epoch: 6| Step: 2
Training loss: 2.449554443359375
Validation loss: 2.1561238740080144

Epoch: 6| Step: 3
Training loss: 2.120586395263672
Validation loss: 2.15734459764214

Epoch: 6| Step: 4
Training loss: 2.332188129425049
Validation loss: 2.1601725086089103

Epoch: 6| Step: 5
Training loss: 2.2574000358581543
Validation loss: 2.157037863167383

Epoch: 6| Step: 6
Training loss: 2.2925021648406982
Validation loss: 2.1359612582832255

Epoch: 6| Step: 7
Training loss: 2.854733467102051
Validation loss: 2.124107171130437

Epoch: 6| Step: 8
Training loss: 1.9391576051712036
Validation loss: 2.12482794894967

Epoch: 6| Step: 9
Training loss: 2.434082269668579
Validation loss: 2.1292176631189164

Epoch: 6| Step: 10
Training loss: 2.424644708633423
Validation loss: 2.128860324941656

Epoch: 6| Step: 11
Training loss: 2.394681930541992
Validation loss: 2.1367277688877557

Epoch: 6| Step: 12
Training loss: 1.992490530014038
Validation loss: 2.145133056948262

Epoch: 6| Step: 13
Training loss: 2.2421751022338867
Validation loss: 2.1442809835557015

Epoch: 107| Step: 0
Training loss: 2.455077886581421
Validation loss: 2.138218997627176

Epoch: 6| Step: 1
Training loss: 2.2292306423187256
Validation loss: 2.133804354616391

Epoch: 6| Step: 2
Training loss: 2.406914710998535
Validation loss: 2.1200341806616834

Epoch: 6| Step: 3
Training loss: 2.4092905521392822
Validation loss: 2.112706284369192

Epoch: 6| Step: 4
Training loss: 2.0789337158203125
Validation loss: 2.1032784497866066

Epoch: 6| Step: 5
Training loss: 1.7684822082519531
Validation loss: 2.0995461607492096

Epoch: 6| Step: 6
Training loss: 3.5106730461120605
Validation loss: 2.091076684254472

Epoch: 6| Step: 7
Training loss: 1.9543721675872803
Validation loss: 2.085662918706094

Epoch: 6| Step: 8
Training loss: 2.4489171504974365
Validation loss: 2.0942212509852585

Epoch: 6| Step: 9
Training loss: 2.0705041885375977
Validation loss: 2.0928053830259588

Epoch: 6| Step: 10
Training loss: 2.2994489669799805
Validation loss: 2.102904570999966

Epoch: 6| Step: 11
Training loss: 2.4506912231445312
Validation loss: 2.1139741674546273

Epoch: 6| Step: 12
Training loss: 2.6084752082824707
Validation loss: 2.1236035875094834

Epoch: 6| Step: 13
Training loss: 2.0167672634124756
Validation loss: 2.1266470468172463

Epoch: 108| Step: 0
Training loss: 3.1997804641723633
Validation loss: 2.1432194914869083

Epoch: 6| Step: 1
Training loss: 2.308960437774658
Validation loss: 2.144890030225118

Epoch: 6| Step: 2
Training loss: 2.269502878189087
Validation loss: 2.1187116663943053

Epoch: 6| Step: 3
Training loss: 1.9259966611862183
Validation loss: 2.113616312703779

Epoch: 6| Step: 4
Training loss: 2.0415661334991455
Validation loss: 2.099127964306903

Epoch: 6| Step: 5
Training loss: 2.226285457611084
Validation loss: 2.095311833966163

Epoch: 6| Step: 6
Training loss: 2.5302233695983887
Validation loss: 2.100405470017464

Epoch: 6| Step: 7
Training loss: 2.2178685665130615
Validation loss: 2.093415989670702

Epoch: 6| Step: 8
Training loss: 2.419708728790283
Validation loss: 2.0947627380330074

Epoch: 6| Step: 9
Training loss: 2.737043619155884
Validation loss: 2.09120504061381

Epoch: 6| Step: 10
Training loss: 2.021500587463379
Validation loss: 2.094846756227555

Epoch: 6| Step: 11
Training loss: 1.551887035369873
Validation loss: 2.092496392547443

Epoch: 6| Step: 12
Training loss: 2.5853238105773926
Validation loss: 2.1078756317015617

Epoch: 6| Step: 13
Training loss: 3.107800245285034
Validation loss: 2.1056366402615785

Epoch: 109| Step: 0
Training loss: 3.5893802642822266
Validation loss: 2.120279824861916

Epoch: 6| Step: 1
Training loss: 1.919029951095581
Validation loss: 2.128954884826496

Epoch: 6| Step: 2
Training loss: 2.206277370452881
Validation loss: 2.131625057548605

Epoch: 6| Step: 3
Training loss: 1.8737446069717407
Validation loss: 2.112020746354134

Epoch: 6| Step: 4
Training loss: 2.425320863723755
Validation loss: 2.102691355571952

Epoch: 6| Step: 5
Training loss: 2.406012535095215
Validation loss: 2.0842223616056543

Epoch: 6| Step: 6
Training loss: 2.119018316268921
Validation loss: 2.070292918912826

Epoch: 6| Step: 7
Training loss: 2.6191439628601074
Validation loss: 2.072588392483291

Epoch: 6| Step: 8
Training loss: 2.202563524246216
Validation loss: 2.0676114930901477

Epoch: 6| Step: 9
Training loss: 2.367374897003174
Validation loss: 2.0707328422095186

Epoch: 6| Step: 10
Training loss: 2.7101433277130127
Validation loss: 2.078318499749707

Epoch: 6| Step: 11
Training loss: 1.8797460794448853
Validation loss: 2.0791655766066683

Epoch: 6| Step: 12
Training loss: 2.043247699737549
Validation loss: 2.082445752236151

Epoch: 6| Step: 13
Training loss: 2.2668116092681885
Validation loss: 2.0914759238560996

Epoch: 110| Step: 0
Training loss: 2.7759580612182617
Validation loss: 2.0841977134827645

Epoch: 6| Step: 1
Training loss: 2.632603645324707
Validation loss: 2.0904451352293774

Epoch: 6| Step: 2
Training loss: 1.795426607131958
Validation loss: 2.0955575025209816

Epoch: 6| Step: 3
Training loss: 2.690201997756958
Validation loss: 2.0913143209231797

Epoch: 6| Step: 4
Training loss: 1.3608894348144531
Validation loss: 2.0943378838159705

Epoch: 6| Step: 5
Training loss: 2.59969425201416
Validation loss: 2.086275498072306

Epoch: 6| Step: 6
Training loss: 2.0449776649475098
Validation loss: 2.0707760087905394

Epoch: 6| Step: 7
Training loss: 2.213378429412842
Validation loss: 2.0732166254392235

Epoch: 6| Step: 8
Training loss: 2.2874205112457275
Validation loss: 2.0597698675688876

Epoch: 6| Step: 9
Training loss: 2.546922206878662
Validation loss: 2.053720042269717

Epoch: 6| Step: 10
Training loss: 2.5701804161071777
Validation loss: 2.060248731285013

Epoch: 6| Step: 11
Training loss: 1.9644140005111694
Validation loss: 2.061799967160789

Epoch: 6| Step: 12
Training loss: 2.47141170501709
Validation loss: 2.0612036925490185

Epoch: 6| Step: 13
Training loss: 2.675395965576172
Validation loss: 2.061864632432179

Epoch: 111| Step: 0
Training loss: 3.6162824630737305
Validation loss: 2.054518113854111

Epoch: 6| Step: 1
Training loss: 1.9947969913482666
Validation loss: 2.058694444676881

Epoch: 6| Step: 2
Training loss: 1.8433631658554077
Validation loss: 2.068356244794784

Epoch: 6| Step: 3
Training loss: 1.9784789085388184
Validation loss: 2.0775096954837924

Epoch: 6| Step: 4
Training loss: 2.1388235092163086
Validation loss: 2.0762074160319504

Epoch: 6| Step: 5
Training loss: 2.775331497192383
Validation loss: 2.074702642297232

Epoch: 6| Step: 6
Training loss: 2.416252374649048
Validation loss: 2.0640994002742152

Epoch: 6| Step: 7
Training loss: 2.107630729675293
Validation loss: 2.062068693099483

Epoch: 6| Step: 8
Training loss: 2.3331875801086426
Validation loss: 2.065971436039094

Epoch: 6| Step: 9
Training loss: 1.7179765701293945
Validation loss: 2.066928240560716

Epoch: 6| Step: 10
Training loss: 2.051382303237915
Validation loss: 2.071255606989707

Epoch: 6| Step: 11
Training loss: 2.6292853355407715
Validation loss: 2.0771637039799846

Epoch: 6| Step: 12
Training loss: 2.49615478515625
Validation loss: 2.0644638307632937

Epoch: 6| Step: 13
Training loss: 2.494795799255371
Validation loss: 2.0654930401873846

Epoch: 112| Step: 0
Training loss: 2.7353596687316895
Validation loss: 2.064169014653852

Epoch: 6| Step: 1
Training loss: 1.7339272499084473
Validation loss: 2.065408286227975

Epoch: 6| Step: 2
Training loss: 2.3387975692749023
Validation loss: 2.0605471262367825

Epoch: 6| Step: 3
Training loss: 2.155846118927002
Validation loss: 2.0646337347645916

Epoch: 6| Step: 4
Training loss: 1.794283151626587
Validation loss: 2.0679403684472524

Epoch: 6| Step: 5
Training loss: 2.0085625648498535
Validation loss: 2.0850003714202554

Epoch: 6| Step: 6
Training loss: 1.9806652069091797
Validation loss: 2.1089322797713743

Epoch: 6| Step: 7
Training loss: 1.7880553007125854
Validation loss: 2.145396945297077

Epoch: 6| Step: 8
Training loss: 3.059643030166626
Validation loss: 2.157238580847299

Epoch: 6| Step: 9
Training loss: 3.4867758750915527
Validation loss: 2.1484949063229304

Epoch: 6| Step: 10
Training loss: 2.3165316581726074
Validation loss: 2.1433345143513014

Epoch: 6| Step: 11
Training loss: 2.425990104675293
Validation loss: 2.109884613303728

Epoch: 6| Step: 12
Training loss: 2.558811902999878
Validation loss: 2.0858486570337766

Epoch: 6| Step: 13
Training loss: 2.0318174362182617
Validation loss: 2.06222713634532

Epoch: 113| Step: 0
Training loss: 1.5700587034225464
Validation loss: 2.0461167366273942

Epoch: 6| Step: 1
Training loss: 2.218451976776123
Validation loss: 2.063899072267676

Epoch: 6| Step: 2
Training loss: 2.1707842350006104
Validation loss: 2.0857292862348658

Epoch: 6| Step: 3
Training loss: 2.764585494995117
Validation loss: 2.0673789183298745

Epoch: 6| Step: 4
Training loss: 2.8287432193756104
Validation loss: 2.05786705658

Epoch: 6| Step: 5
Training loss: 2.0343453884124756
Validation loss: 2.0501898245144914

Epoch: 6| Step: 6
Training loss: 1.9864425659179688
Validation loss: 2.0519932944287538

Epoch: 6| Step: 7
Training loss: 2.7002010345458984
Validation loss: 2.048129632908811

Epoch: 6| Step: 8
Training loss: 2.4827239513397217
Validation loss: 2.041530970604189

Epoch: 6| Step: 9
Training loss: 2.728869915008545
Validation loss: 2.042488944145941

Epoch: 6| Step: 10
Training loss: 2.085343599319458
Validation loss: 2.04884998900916

Epoch: 6| Step: 11
Training loss: 2.3506758213043213
Validation loss: 2.0566941999620005

Epoch: 6| Step: 12
Training loss: 2.509976387023926
Validation loss: 2.070553843693067

Epoch: 6| Step: 13
Training loss: 1.8218722343444824
Validation loss: 2.081630014604138

Epoch: 114| Step: 0
Training loss: 2.3268797397613525
Validation loss: 2.0824052518413914

Epoch: 6| Step: 1
Training loss: 2.0140347480773926
Validation loss: 2.0829530915906354

Epoch: 6| Step: 2
Training loss: 2.592451333999634
Validation loss: 2.074959224270236

Epoch: 6| Step: 3
Training loss: 2.7439229488372803
Validation loss: 2.06819910131475

Epoch: 6| Step: 4
Training loss: 2.6685636043548584
Validation loss: 2.0406124322645125

Epoch: 6| Step: 5
Training loss: 1.9347211122512817
Validation loss: 2.038012500732176

Epoch: 6| Step: 6
Training loss: 2.563922882080078
Validation loss: 2.040976793535294

Epoch: 6| Step: 7
Training loss: 1.8811016082763672
Validation loss: 2.032852772743471

Epoch: 6| Step: 8
Training loss: 2.211857795715332
Validation loss: 2.033223166260668

Epoch: 6| Step: 9
Training loss: 1.9541486501693726
Validation loss: 2.0355647680579976

Epoch: 6| Step: 10
Training loss: 2.861149311065674
Validation loss: 2.040992647088984

Epoch: 6| Step: 11
Training loss: 2.1487159729003906
Validation loss: 2.0381380883596276

Epoch: 6| Step: 12
Training loss: 2.0337250232696533
Validation loss: 2.0370393414651193

Epoch: 6| Step: 13
Training loss: 2.1116669178009033
Validation loss: 2.044122349831366

Epoch: 115| Step: 0
Training loss: 2.004220962524414
Validation loss: 2.0539296160462084

Epoch: 6| Step: 1
Training loss: 2.7839603424072266
Validation loss: 2.0708196919451476

Epoch: 6| Step: 2
Training loss: 1.7471380233764648
Validation loss: 2.0757991383152623

Epoch: 6| Step: 3
Training loss: 2.583573341369629
Validation loss: 2.0748565876355736

Epoch: 6| Step: 4
Training loss: 2.336047649383545
Validation loss: 2.067977741200437

Epoch: 6| Step: 5
Training loss: 2.736206531524658
Validation loss: 2.052839691920947

Epoch: 6| Step: 6
Training loss: 1.9492743015289307
Validation loss: 2.048719706073884

Epoch: 6| Step: 7
Training loss: 2.1738674640655518
Validation loss: 2.0415592437149375

Epoch: 6| Step: 8
Training loss: 2.5975992679595947
Validation loss: 2.0391721725463867

Epoch: 6| Step: 9
Training loss: 2.608792781829834
Validation loss: 2.0396738462550665

Epoch: 6| Step: 10
Training loss: 2.767152786254883
Validation loss: 2.034297109932028

Epoch: 6| Step: 11
Training loss: 2.2005443572998047
Validation loss: 2.03622910540591

Epoch: 6| Step: 12
Training loss: 1.8592989444732666
Validation loss: 2.0404271489830426

Epoch: 6| Step: 13
Training loss: 1.4705605506896973
Validation loss: 2.03597278236061

Epoch: 116| Step: 0
Training loss: 1.9150809049606323
Validation loss: 2.0386035237261044

Epoch: 6| Step: 1
Training loss: 2.2764711380004883
Validation loss: 2.0382671022927887

Epoch: 6| Step: 2
Training loss: 2.4005346298217773
Validation loss: 2.047702779052078

Epoch: 6| Step: 3
Training loss: 2.7889111042022705
Validation loss: 2.052766230798537

Epoch: 6| Step: 4
Training loss: 2.993025302886963
Validation loss: 2.066278780660322

Epoch: 6| Step: 5
Training loss: 2.480653762817383
Validation loss: 2.069316799922656

Epoch: 6| Step: 6
Training loss: 2.380697727203369
Validation loss: 2.072438996325257

Epoch: 6| Step: 7
Training loss: 2.1993942260742188
Validation loss: 2.0644234893142537

Epoch: 6| Step: 8
Training loss: 1.9358958005905151
Validation loss: 2.0649444134004655

Epoch: 6| Step: 9
Training loss: 0.930543065071106
Validation loss: 2.0662364793080155

Epoch: 6| Step: 10
Training loss: 2.3907253742218018
Validation loss: 2.059253636226859

Epoch: 6| Step: 11
Training loss: 2.770615577697754
Validation loss: 2.0556645918917913

Epoch: 6| Step: 12
Training loss: 1.9660805463790894
Validation loss: 2.055916304229408

Epoch: 6| Step: 13
Training loss: 2.7069053649902344
Validation loss: 2.039271257256949

Epoch: 117| Step: 0
Training loss: 2.2327003479003906
Validation loss: 2.0454555198710453

Epoch: 6| Step: 1
Training loss: 2.2577860355377197
Validation loss: 2.0467704470439623

Epoch: 6| Step: 2
Training loss: 2.0733463764190674
Validation loss: 2.037693399254994

Epoch: 6| Step: 3
Training loss: 2.4119248390197754
Validation loss: 2.0408397400251

Epoch: 6| Step: 4
Training loss: 2.909454345703125
Validation loss: 2.0361220605911745

Epoch: 6| Step: 5
Training loss: 1.93839693069458
Validation loss: 2.0287110959329913

Epoch: 6| Step: 6
Training loss: 2.279788017272949
Validation loss: 2.031579035584645

Epoch: 6| Step: 7
Training loss: 1.6512277126312256
Validation loss: 2.0296154855400004

Epoch: 6| Step: 8
Training loss: 2.9578146934509277
Validation loss: 2.0322908752708027

Epoch: 6| Step: 9
Training loss: 2.817899465560913
Validation loss: 2.026896958710045

Epoch: 6| Step: 10
Training loss: 2.1928749084472656
Validation loss: 2.0354176208537114

Epoch: 6| Step: 11
Training loss: 2.1682488918304443
Validation loss: 2.051240292928552

Epoch: 6| Step: 12
Training loss: 1.8647499084472656
Validation loss: 2.040605543762125

Epoch: 6| Step: 13
Training loss: 2.101006507873535
Validation loss: 2.037056633221206

Epoch: 118| Step: 0
Training loss: 2.0038347244262695
Validation loss: 2.0321133572568177

Epoch: 6| Step: 1
Training loss: 1.92409348487854
Validation loss: 2.029619014391335

Epoch: 6| Step: 2
Training loss: 2.476565361022949
Validation loss: 2.0135338588427474

Epoch: 6| Step: 3
Training loss: 2.485496997833252
Validation loss: 2.031852704222484

Epoch: 6| Step: 4
Training loss: 3.1457512378692627
Validation loss: 2.0260281998624086

Epoch: 6| Step: 5
Training loss: 2.4312639236450195
Validation loss: 2.0200713821636733

Epoch: 6| Step: 6
Training loss: 2.386258125305176
Validation loss: 2.0141657898502965

Epoch: 6| Step: 7
Training loss: 1.5669162273406982
Validation loss: 2.0187696026217554

Epoch: 6| Step: 8
Training loss: 1.8315551280975342
Validation loss: 2.0291748739057973

Epoch: 6| Step: 9
Training loss: 2.427137613296509
Validation loss: 2.0401829699034333

Epoch: 6| Step: 10
Training loss: 2.109870672225952
Validation loss: 2.0349889006665958

Epoch: 6| Step: 11
Training loss: 2.2010810375213623
Validation loss: 2.035219887251495

Epoch: 6| Step: 12
Training loss: 2.50221586227417
Validation loss: 2.0362164922939834

Epoch: 6| Step: 13
Training loss: 2.5064890384674072
Validation loss: 2.0307268583646385

Epoch: 119| Step: 0
Training loss: 2.529127597808838
Validation loss: 2.0178287798358547

Epoch: 6| Step: 1
Training loss: 2.5912046432495117
Validation loss: 2.0114103209587837

Epoch: 6| Step: 2
Training loss: 2.718982696533203
Validation loss: 2.0064586644531577

Epoch: 6| Step: 3
Training loss: 1.8610910177230835
Validation loss: 2.010805247932352

Epoch: 6| Step: 4
Training loss: 2.382227897644043
Validation loss: 2.0150668185244323

Epoch: 6| Step: 5
Training loss: 1.8556549549102783
Validation loss: 2.033707049585158

Epoch: 6| Step: 6
Training loss: 2.204380512237549
Validation loss: 2.0579912098505164

Epoch: 6| Step: 7
Training loss: 1.907487154006958
Validation loss: 2.052637223274477

Epoch: 6| Step: 8
Training loss: 2.3022027015686035
Validation loss: 2.030745344777261

Epoch: 6| Step: 9
Training loss: 1.189124345779419
Validation loss: 2.0179088102873934

Epoch: 6| Step: 10
Training loss: 2.7873950004577637
Validation loss: 2.010287234860082

Epoch: 6| Step: 11
Training loss: 2.7769622802734375
Validation loss: 2.0029783633447464

Epoch: 6| Step: 12
Training loss: 2.7596945762634277
Validation loss: 1.999076779170703

Epoch: 6| Step: 13
Training loss: 1.442180871963501
Validation loss: 1.9990785416736399

Epoch: 120| Step: 0
Training loss: 2.1884605884552
Validation loss: 2.0026635098200973

Epoch: 6| Step: 1
Training loss: 2.6501388549804688
Validation loss: 2.0040973232638453

Epoch: 6| Step: 2
Training loss: 2.0907464027404785
Validation loss: 2.0086072209060832

Epoch: 6| Step: 3
Training loss: 1.8364372253417969
Validation loss: 2.0208580660563644

Epoch: 6| Step: 4
Training loss: 2.222538471221924
Validation loss: 2.0338516491715626

Epoch: 6| Step: 5
Training loss: 2.7075936794281006
Validation loss: 2.034494392333492

Epoch: 6| Step: 6
Training loss: 2.6167778968811035
Validation loss: 2.0272884086896013

Epoch: 6| Step: 7
Training loss: 2.14077091217041
Validation loss: 2.0283334460309757

Epoch: 6| Step: 8
Training loss: 2.1947197914123535
Validation loss: 2.010303576787313

Epoch: 6| Step: 9
Training loss: 2.9335532188415527
Validation loss: 2.005550064066405

Epoch: 6| Step: 10
Training loss: 1.1303749084472656
Validation loss: 2.0040366931628157

Epoch: 6| Step: 11
Training loss: 1.739723801612854
Validation loss: 2.000767925734161

Epoch: 6| Step: 12
Training loss: 2.968897819519043
Validation loss: 2.0105514321275937

Epoch: 6| Step: 13
Training loss: 2.08479380607605
Validation loss: 2.0132661609239477

Epoch: 121| Step: 0
Training loss: 2.7201688289642334
Validation loss: 2.026542422591999

Epoch: 6| Step: 1
Training loss: 2.1202569007873535
Validation loss: 2.037403734781409

Epoch: 6| Step: 2
Training loss: 2.138601064682007
Validation loss: 2.027065816745963

Epoch: 6| Step: 3
Training loss: 2.3394501209259033
Validation loss: 2.024039024947792

Epoch: 6| Step: 4
Training loss: 2.7277438640594482
Validation loss: 2.0082425276438394

Epoch: 6| Step: 5
Training loss: 2.240446090698242
Validation loss: 2.0056948200348885

Epoch: 6| Step: 6
Training loss: 2.252603769302368
Validation loss: 2.0162689121820594

Epoch: 6| Step: 7
Training loss: 1.7232143878936768
Validation loss: 2.0057156188513643

Epoch: 6| Step: 8
Training loss: 2.2292652130126953
Validation loss: 2.00869006751686

Epoch: 6| Step: 9
Training loss: 2.274129867553711
Validation loss: 2.022612642216426

Epoch: 6| Step: 10
Training loss: 2.803258180618286
Validation loss: 2.039632958750571

Epoch: 6| Step: 11
Training loss: 1.8629497289657593
Validation loss: 2.057831697566535

Epoch: 6| Step: 12
Training loss: 2.2815444469451904
Validation loss: 2.0743408664580314

Epoch: 6| Step: 13
Training loss: 1.730557918548584
Validation loss: 2.0538110476668163

Epoch: 122| Step: 0
Training loss: 1.785020351409912
Validation loss: 2.023513529890327

Epoch: 6| Step: 1
Training loss: 2.8248157501220703
Validation loss: 2.0200691043689685

Epoch: 6| Step: 2
Training loss: 2.1036829948425293
Validation loss: 2.012827947575559

Epoch: 6| Step: 3
Training loss: 1.9690440893173218
Validation loss: 2.0034209477004183

Epoch: 6| Step: 4
Training loss: 2.3957738876342773
Validation loss: 2.0245185308558966

Epoch: 6| Step: 5
Training loss: 2.395019769668579
Validation loss: 2.028733898234624

Epoch: 6| Step: 6
Training loss: 2.4118032455444336
Validation loss: 2.041702634544783

Epoch: 6| Step: 7
Training loss: 1.7777551412582397
Validation loss: 2.0365093318364953

Epoch: 6| Step: 8
Training loss: 2.594482898712158
Validation loss: 2.0320618178254817

Epoch: 6| Step: 9
Training loss: 2.1270649433135986
Validation loss: 2.037312211528901

Epoch: 6| Step: 10
Training loss: 2.424304485321045
Validation loss: 2.0330115364443873

Epoch: 6| Step: 11
Training loss: 2.3709325790405273
Validation loss: 2.045796322566207

Epoch: 6| Step: 12
Training loss: 2.218614101409912
Validation loss: 2.0395381168652604

Epoch: 6| Step: 13
Training loss: 2.496779441833496
Validation loss: 2.0555355625767864

Epoch: 123| Step: 0
Training loss: 2.282114267349243
Validation loss: 2.053547341336486

Epoch: 6| Step: 1
Training loss: 2.2775888442993164
Validation loss: 2.0584970469115884

Epoch: 6| Step: 2
Training loss: 2.3549129962921143
Validation loss: 2.0466296967639717

Epoch: 6| Step: 3
Training loss: 2.015136480331421
Validation loss: 2.0346868948269914

Epoch: 6| Step: 4
Training loss: 2.814143419265747
Validation loss: 2.0167126629942205

Epoch: 6| Step: 5
Training loss: 2.5374746322631836
Validation loss: 2.0223678542721655

Epoch: 6| Step: 6
Training loss: 2.1913514137268066
Validation loss: 2.022296950381289

Epoch: 6| Step: 7
Training loss: 1.9633724689483643
Validation loss: 2.020431269881546

Epoch: 6| Step: 8
Training loss: 2.4663639068603516
Validation loss: 2.024234092363747

Epoch: 6| Step: 9
Training loss: 2.687056064605713
Validation loss: 2.0123739498917774

Epoch: 6| Step: 10
Training loss: 1.845415472984314
Validation loss: 2.019602939646731

Epoch: 6| Step: 11
Training loss: 1.31794011592865
Validation loss: 2.00852309760227

Epoch: 6| Step: 12
Training loss: 3.1154332160949707
Validation loss: 2.0089020626519316

Epoch: 6| Step: 13
Training loss: 1.9953293800354004
Validation loss: 2.0210013402405607

Epoch: 124| Step: 0
Training loss: 2.1512248516082764
Validation loss: 2.064238481624152

Epoch: 6| Step: 1
Training loss: 2.110445261001587
Validation loss: 2.1340629554563955

Epoch: 6| Step: 2
Training loss: 2.5788931846618652
Validation loss: 2.1895758746772684

Epoch: 6| Step: 3
Training loss: 2.0217936038970947
Validation loss: 2.1470087420555855

Epoch: 6| Step: 4
Training loss: 2.512766122817993
Validation loss: 2.1078871437298354

Epoch: 6| Step: 5
Training loss: 3.1564362049102783
Validation loss: 2.060395804784631

Epoch: 6| Step: 6
Training loss: 1.9894695281982422
Validation loss: 2.0191811233438473

Epoch: 6| Step: 7
Training loss: 1.9032350778579712
Validation loss: 2.0103962805963334

Epoch: 6| Step: 8
Training loss: 2.186666965484619
Validation loss: 2.024633043555803

Epoch: 6| Step: 9
Training loss: 2.4024758338928223
Validation loss: 2.0349164573095178

Epoch: 6| Step: 10
Training loss: 2.2686028480529785
Validation loss: 2.0321722697186213

Epoch: 6| Step: 11
Training loss: 2.2678439617156982
Validation loss: 2.000190718199617

Epoch: 6| Step: 12
Training loss: 2.185331344604492
Validation loss: 2.0022978295562086

Epoch: 6| Step: 13
Training loss: 2.670567512512207
Validation loss: 1.996910220833235

Epoch: 125| Step: 0
Training loss: 2.154898166656494
Validation loss: 2.001260167808943

Epoch: 6| Step: 1
Training loss: 2.270402669906616
Validation loss: 1.997201799064554

Epoch: 6| Step: 2
Training loss: 2.2410974502563477
Validation loss: 2.003898920551423

Epoch: 6| Step: 3
Training loss: 1.6739797592163086
Validation loss: 2.004834145627996

Epoch: 6| Step: 4
Training loss: 3.211308240890503
Validation loss: 1.9920993902349984

Epoch: 6| Step: 5
Training loss: 2.4116921424865723
Validation loss: 1.991769621449132

Epoch: 6| Step: 6
Training loss: 1.9872959852218628
Validation loss: 1.9861303606340963

Epoch: 6| Step: 7
Training loss: 2.325087308883667
Validation loss: 1.9930260514700284

Epoch: 6| Step: 8
Training loss: 1.7336256504058838
Validation loss: 1.980390296187452

Epoch: 6| Step: 9
Training loss: 2.222506046295166
Validation loss: 1.9818904553690264

Epoch: 6| Step: 10
Training loss: 2.1618611812591553
Validation loss: 1.9834717319857689

Epoch: 6| Step: 11
Training loss: 1.8085854053497314
Validation loss: 1.9815434627635504

Epoch: 6| Step: 12
Training loss: 2.7361745834350586
Validation loss: 1.9900054008729997

Epoch: 6| Step: 13
Training loss: 2.5431149005889893
Validation loss: 2.0298322708375993

Epoch: 126| Step: 0
Training loss: 2.449613094329834
Validation loss: 2.0363663011981594

Epoch: 6| Step: 1
Training loss: 2.092939853668213
Validation loss: 2.046991939185768

Epoch: 6| Step: 2
Training loss: 2.487433433532715
Validation loss: 2.0318181386557956

Epoch: 6| Step: 3
Training loss: 2.3876523971557617
Validation loss: 2.031852800359008

Epoch: 6| Step: 4
Training loss: 1.6194982528686523
Validation loss: 2.0090159036779918

Epoch: 6| Step: 5
Training loss: 1.486257791519165
Validation loss: 1.9909043312072754

Epoch: 6| Step: 6
Training loss: 2.7431468963623047
Validation loss: 1.969918127982847

Epoch: 6| Step: 7
Training loss: 2.3334808349609375
Validation loss: 1.9660121728015203

Epoch: 6| Step: 8
Training loss: 3.2561862468719482
Validation loss: 1.9711058755074777

Epoch: 6| Step: 9
Training loss: 1.884486198425293
Validation loss: 1.985300999815746

Epoch: 6| Step: 10
Training loss: 2.312955379486084
Validation loss: 1.9996615417541996

Epoch: 6| Step: 11
Training loss: 1.807030200958252
Validation loss: 1.9892965747464089

Epoch: 6| Step: 12
Training loss: 2.4202780723571777
Validation loss: 1.9795214488942137

Epoch: 6| Step: 13
Training loss: 2.7111918926239014
Validation loss: 1.9811421325129848

Epoch: 127| Step: 0
Training loss: 2.5882136821746826
Validation loss: 1.9819228726048623

Epoch: 6| Step: 1
Training loss: 1.8871004581451416
Validation loss: 2.0023255655842442

Epoch: 6| Step: 2
Training loss: 1.7410768270492554
Validation loss: 2.034438358840122

Epoch: 6| Step: 3
Training loss: 2.73738431930542
Validation loss: 2.0438929937219106

Epoch: 6| Step: 4
Training loss: 3.021770477294922
Validation loss: 2.043726642926534

Epoch: 6| Step: 5
Training loss: 2.8157472610473633
Validation loss: 2.0455277248095443

Epoch: 6| Step: 6
Training loss: 1.7063071727752686
Validation loss: 2.0111689490656697

Epoch: 6| Step: 7
Training loss: 1.7548116445541382
Validation loss: 2.0000680979862007

Epoch: 6| Step: 8
Training loss: 1.847112774848938
Validation loss: 1.9802092762403591

Epoch: 6| Step: 9
Training loss: 2.7233121395111084
Validation loss: 1.9649025650434597

Epoch: 6| Step: 10
Training loss: 2.64475679397583
Validation loss: 1.972946600247455

Epoch: 6| Step: 11
Training loss: 1.9032514095306396
Validation loss: 1.9755833251501924

Epoch: 6| Step: 12
Training loss: 2.053422451019287
Validation loss: 1.9879233824309481

Epoch: 6| Step: 13
Training loss: 2.553443431854248
Validation loss: 1.9876774280301985

Epoch: 128| Step: 0
Training loss: 2.1765685081481934
Validation loss: 1.9863819870897519

Epoch: 6| Step: 1
Training loss: 2.504708766937256
Validation loss: 1.9838464131919287

Epoch: 6| Step: 2
Training loss: 2.810436725616455
Validation loss: 1.972876246257495

Epoch: 6| Step: 3
Training loss: 3.00342059135437
Validation loss: 1.9749785418151526

Epoch: 6| Step: 4
Training loss: 2.1163101196289062
Validation loss: 1.980003777370658

Epoch: 6| Step: 5
Training loss: 1.996290922164917
Validation loss: 1.9684510102836035

Epoch: 6| Step: 6
Training loss: 1.9808082580566406
Validation loss: 1.9751225158732424

Epoch: 6| Step: 7
Training loss: 1.8729826211929321
Validation loss: 1.9694856110439505

Epoch: 6| Step: 8
Training loss: 2.1408395767211914
Validation loss: 1.966385095350204

Epoch: 6| Step: 9
Training loss: 2.2735891342163086
Validation loss: 1.9693515557114796

Epoch: 6| Step: 10
Training loss: 1.5142831802368164
Validation loss: 1.9760735060579033

Epoch: 6| Step: 11
Training loss: 2.1104578971862793
Validation loss: 1.9894325579366376

Epoch: 6| Step: 12
Training loss: 2.7972447872161865
Validation loss: 1.9899785300736785

Epoch: 6| Step: 13
Training loss: 1.490753173828125
Validation loss: 2.032755087780696

Epoch: 129| Step: 0
Training loss: 2.4078855514526367
Validation loss: 2.062630637999504

Epoch: 6| Step: 1
Training loss: 1.5859811305999756
Validation loss: 2.0868847408602313

Epoch: 6| Step: 2
Training loss: 2.634354829788208
Validation loss: 2.0826929487207884

Epoch: 6| Step: 3
Training loss: 2.2729310989379883
Validation loss: 2.0544749870095202

Epoch: 6| Step: 4
Training loss: 3.202998161315918
Validation loss: 2.00235173010057

Epoch: 6| Step: 5
Training loss: 3.269232988357544
Validation loss: 1.9786920726940196

Epoch: 6| Step: 6
Training loss: 1.666978359222412
Validation loss: 1.975419029112785

Epoch: 6| Step: 7
Training loss: 2.028130531311035
Validation loss: 1.977759099775745

Epoch: 6| Step: 8
Training loss: 2.478912353515625
Validation loss: 1.9802411679298646

Epoch: 6| Step: 9
Training loss: 1.3437700271606445
Validation loss: 1.9928073011418825

Epoch: 6| Step: 10
Training loss: 2.3846287727355957
Validation loss: 1.9739601483909033

Epoch: 6| Step: 11
Training loss: 2.231092929840088
Validation loss: 1.9682828226397115

Epoch: 6| Step: 12
Training loss: 1.7196029424667358
Validation loss: 1.9724990680653562

Epoch: 6| Step: 13
Training loss: 2.897738456726074
Validation loss: 1.9513726119072206

Epoch: 130| Step: 0
Training loss: 2.313838481903076
Validation loss: 1.9655774357498332

Epoch: 6| Step: 1
Training loss: 2.0532045364379883
Validation loss: 1.9676778111406552

Epoch: 6| Step: 2
Training loss: 2.0437135696411133
Validation loss: 1.959613295011623

Epoch: 6| Step: 3
Training loss: 1.711106777191162
Validation loss: 1.9618503252665203

Epoch: 6| Step: 4
Training loss: 2.179536819458008
Validation loss: 1.9604519515909173

Epoch: 6| Step: 5
Training loss: 2.292168140411377
Validation loss: 1.9617595108606483

Epoch: 6| Step: 6
Training loss: 1.6948745250701904
Validation loss: 1.9631648832751858

Epoch: 6| Step: 7
Training loss: 2.0032715797424316
Validation loss: 1.9887235215915147

Epoch: 6| Step: 8
Training loss: 1.9542409181594849
Validation loss: 1.96325042170863

Epoch: 6| Step: 9
Training loss: 2.1284797191619873
Validation loss: 1.9700416595705095

Epoch: 6| Step: 10
Training loss: 2.625581741333008
Validation loss: 1.9612505641034854

Epoch: 6| Step: 11
Training loss: 2.448908567428589
Validation loss: 1.96238281906292

Epoch: 6| Step: 12
Training loss: 2.493394374847412
Validation loss: 1.9515892600500455

Epoch: 6| Step: 13
Training loss: 3.497471332550049
Validation loss: 1.9549344162787161

Epoch: 131| Step: 0
Training loss: 2.889720916748047
Validation loss: 1.9566057600000852

Epoch: 6| Step: 1
Training loss: 1.7281999588012695
Validation loss: 1.9587726875018048

Epoch: 6| Step: 2
Training loss: 2.134594440460205
Validation loss: 1.9583495688694779

Epoch: 6| Step: 3
Training loss: 2.359229326248169
Validation loss: 1.9578278705637941

Epoch: 6| Step: 4
Training loss: 2.446791172027588
Validation loss: 1.9550880911529704

Epoch: 6| Step: 5
Training loss: 2.0722298622131348
Validation loss: 1.9464456829973447

Epoch: 6| Step: 6
Training loss: 1.992984652519226
Validation loss: 1.9635379557968469

Epoch: 6| Step: 7
Training loss: 1.8901033401489258
Validation loss: 1.9523377059608378

Epoch: 6| Step: 8
Training loss: 2.03275990486145
Validation loss: 1.9556088665480256

Epoch: 6| Step: 9
Training loss: 1.669623851776123
Validation loss: 1.9518702235273135

Epoch: 6| Step: 10
Training loss: 2.3581485748291016
Validation loss: 1.9590775825644051

Epoch: 6| Step: 11
Training loss: 2.119556427001953
Validation loss: 1.9521868152003135

Epoch: 6| Step: 12
Training loss: 2.8112752437591553
Validation loss: 1.9637825066043484

Epoch: 6| Step: 13
Training loss: 2.0553417205810547
Validation loss: 1.9773402188413887

Epoch: 132| Step: 0
Training loss: 1.5324959754943848
Validation loss: 1.9997358578507618

Epoch: 6| Step: 1
Training loss: 2.315122127532959
Validation loss: 2.015109782577843

Epoch: 6| Step: 2
Training loss: 1.9896842241287231
Validation loss: 2.013310791343771

Epoch: 6| Step: 3
Training loss: 3.5047178268432617
Validation loss: 2.0249785582224527

Epoch: 6| Step: 4
Training loss: 1.7287704944610596
Validation loss: 2.021652583153017

Epoch: 6| Step: 5
Training loss: 2.2872817516326904
Validation loss: 2.0012206287794214

Epoch: 6| Step: 6
Training loss: 1.5781852006912231
Validation loss: 2.0007918009193997

Epoch: 6| Step: 7
Training loss: 2.4875593185424805
Validation loss: 1.9889550439773067

Epoch: 6| Step: 8
Training loss: 1.6430610418319702
Validation loss: 1.9889773502144763

Epoch: 6| Step: 9
Training loss: 2.4829773902893066
Validation loss: 1.9805024336743098

Epoch: 6| Step: 10
Training loss: 2.1655380725860596
Validation loss: 1.96653841387841

Epoch: 6| Step: 11
Training loss: 2.642117738723755
Validation loss: 1.970841912813084

Epoch: 6| Step: 12
Training loss: 2.081157922744751
Validation loss: 1.9900191765959545

Epoch: 6| Step: 13
Training loss: 2.959874153137207
Validation loss: 2.0098123217141755

Epoch: 133| Step: 0
Training loss: 2.1774003505706787
Validation loss: 2.0092007601132957

Epoch: 6| Step: 1
Training loss: 2.513075351715088
Validation loss: 2.0247756768298406

Epoch: 6| Step: 2
Training loss: 2.2826662063598633
Validation loss: 2.0258733046952115

Epoch: 6| Step: 3
Training loss: 1.9349496364593506
Validation loss: 2.0368005101398756

Epoch: 6| Step: 4
Training loss: 2.7027297019958496
Validation loss: 2.022348552621821

Epoch: 6| Step: 5
Training loss: 1.8476409912109375
Validation loss: 2.00588491142437

Epoch: 6| Step: 6
Training loss: 2.667006731033325
Validation loss: 1.989772186484388

Epoch: 6| Step: 7
Training loss: 2.41501784324646
Validation loss: 1.98423142843349

Epoch: 6| Step: 8
Training loss: 2.333812713623047
Validation loss: 1.963391512952825

Epoch: 6| Step: 9
Training loss: 1.4454368352890015
Validation loss: 1.972316688106906

Epoch: 6| Step: 10
Training loss: 2.440499782562256
Validation loss: 1.9634051246027793

Epoch: 6| Step: 11
Training loss: 2.2398805618286133
Validation loss: 1.960251013437907

Epoch: 6| Step: 12
Training loss: 2.34818959236145
Validation loss: 1.9721331404101463

Epoch: 6| Step: 13
Training loss: 1.252442479133606
Validation loss: 1.9657708009084065

Epoch: 134| Step: 0
Training loss: 1.7912269830703735
Validation loss: 1.968400022035004

Epoch: 6| Step: 1
Training loss: 1.557286024093628
Validation loss: 1.9764821631934053

Epoch: 6| Step: 2
Training loss: 1.8408727645874023
Validation loss: 2.0041423677116312

Epoch: 6| Step: 3
Training loss: 2.434701919555664
Validation loss: 1.9932679437821912

Epoch: 6| Step: 4
Training loss: 2.26240873336792
Validation loss: 1.962500282513198

Epoch: 6| Step: 5
Training loss: 2.2675845623016357
Validation loss: 1.9550523181115427

Epoch: 6| Step: 6
Training loss: 2.2742466926574707
Validation loss: 1.9442156873723513

Epoch: 6| Step: 7
Training loss: 2.567608118057251
Validation loss: 1.9443671562338387

Epoch: 6| Step: 8
Training loss: 2.1354498863220215
Validation loss: 1.9376116901315668

Epoch: 6| Step: 9
Training loss: 2.6320128440856934
Validation loss: 1.9420908471589446

Epoch: 6| Step: 10
Training loss: 1.9231359958648682
Validation loss: 1.9441645171052666

Epoch: 6| Step: 11
Training loss: 2.3097727298736572
Validation loss: 1.9610928694407146

Epoch: 6| Step: 12
Training loss: 2.658021926879883
Validation loss: 1.9796645231144403

Epoch: 6| Step: 13
Training loss: 2.1439061164855957
Validation loss: 1.980265627625168

Epoch: 135| Step: 0
Training loss: 2.1102166175842285
Validation loss: 2.0037346424595004

Epoch: 6| Step: 1
Training loss: 2.0477030277252197
Validation loss: 2.0047194239913777

Epoch: 6| Step: 2
Training loss: 2.4530117511749268
Validation loss: 2.005415895933746

Epoch: 6| Step: 3
Training loss: 2.238053798675537
Validation loss: 1.980980255270517

Epoch: 6| Step: 4
Training loss: 1.713698387145996
Validation loss: 1.9745777704382454

Epoch: 6| Step: 5
Training loss: 1.6421582698822021
Validation loss: 1.9774759507948352

Epoch: 6| Step: 6
Training loss: 1.9588640928268433
Validation loss: 1.9640170092223792

Epoch: 6| Step: 7
Training loss: 1.9299917221069336
Validation loss: 1.9563692128786476

Epoch: 6| Step: 8
Training loss: 2.324578046798706
Validation loss: 1.9602024247569423

Epoch: 6| Step: 9
Training loss: 2.241013526916504
Validation loss: 1.9533636287976337

Epoch: 6| Step: 10
Training loss: 2.6579885482788086
Validation loss: 1.9523018713920348

Epoch: 6| Step: 11
Training loss: 2.6805505752563477
Validation loss: 1.9660876617636731

Epoch: 6| Step: 12
Training loss: 2.379703998565674
Validation loss: 1.9826417353845411

Epoch: 6| Step: 13
Training loss: 2.4853954315185547
Validation loss: 1.9817489782969158

Epoch: 136| Step: 0
Training loss: 1.9873369932174683
Validation loss: 1.9551980879998976

Epoch: 6| Step: 1
Training loss: 1.9157843589782715
Validation loss: 1.9497088116984214

Epoch: 6| Step: 2
Training loss: 2.8792829513549805
Validation loss: 1.9510104758765108

Epoch: 6| Step: 3
Training loss: 2.494612216949463
Validation loss: 1.9481264852708386

Epoch: 6| Step: 4
Training loss: 1.6180419921875
Validation loss: 1.9546714982678812

Epoch: 6| Step: 5
Training loss: 2.0548319816589355
Validation loss: 1.9524584957348403

Epoch: 6| Step: 6
Training loss: 2.3321523666381836
Validation loss: 1.9560320633713917

Epoch: 6| Step: 7
Training loss: 2.742341995239258
Validation loss: 1.9520887521005446

Epoch: 6| Step: 8
Training loss: 2.7981362342834473
Validation loss: 1.9465986990159558

Epoch: 6| Step: 9
Training loss: 2.024531602859497
Validation loss: 1.9590181791654198

Epoch: 6| Step: 10
Training loss: 2.255937099456787
Validation loss: 1.9926074038269699

Epoch: 6| Step: 11
Training loss: 2.1427078247070312
Validation loss: 2.0301082570065736

Epoch: 6| Step: 12
Training loss: 1.9979233741760254
Validation loss: 2.0314403656990296

Epoch: 6| Step: 13
Training loss: 1.873182773590088
Validation loss: 2.030486270945559

Epoch: 137| Step: 0
Training loss: 2.6639697551727295
Validation loss: 1.9929637742298905

Epoch: 6| Step: 1
Training loss: 2.503943920135498
Validation loss: 1.9829198288661178

Epoch: 6| Step: 2
Training loss: 2.530086040496826
Validation loss: 1.9682743395528486

Epoch: 6| Step: 3
Training loss: 1.7397325038909912
Validation loss: 1.965517000485492

Epoch: 6| Step: 4
Training loss: 2.9162306785583496
Validation loss: 1.9676666221311014

Epoch: 6| Step: 5
Training loss: 1.7544509172439575
Validation loss: 1.9728407449619745

Epoch: 6| Step: 6
Training loss: 1.887934923171997
Validation loss: 1.9775421632233487

Epoch: 6| Step: 7
Training loss: 1.5833954811096191
Validation loss: 1.963521675396991

Epoch: 6| Step: 8
Training loss: 1.9454967975616455
Validation loss: 1.964461249689902

Epoch: 6| Step: 9
Training loss: 1.6718311309814453
Validation loss: 1.9563560408930625

Epoch: 6| Step: 10
Training loss: 2.6045737266540527
Validation loss: 1.961512973231654

Epoch: 6| Step: 11
Training loss: 2.625608444213867
Validation loss: 1.9609383972742225

Epoch: 6| Step: 12
Training loss: 2.094082832336426
Validation loss: 1.9562297341644124

Epoch: 6| Step: 13
Training loss: 2.2258923053741455
Validation loss: 1.953051551695793

Epoch: 138| Step: 0
Training loss: 1.7649332284927368
Validation loss: 1.9629671419820478

Epoch: 6| Step: 1
Training loss: 2.9097867012023926
Validation loss: 1.9763325388713548

Epoch: 6| Step: 2
Training loss: 2.3587379455566406
Validation loss: 1.969399707291716

Epoch: 6| Step: 3
Training loss: 2.2229056358337402
Validation loss: 1.9805098643866919

Epoch: 6| Step: 4
Training loss: 1.5882937908172607
Validation loss: 1.971457109656385

Epoch: 6| Step: 5
Training loss: 2.4498472213745117
Validation loss: 1.9808239629191737

Epoch: 6| Step: 6
Training loss: 2.532000780105591
Validation loss: 1.9809753523078015

Epoch: 6| Step: 7
Training loss: 1.9848034381866455
Validation loss: 1.981531390579798

Epoch: 6| Step: 8
Training loss: 2.3511037826538086
Validation loss: 1.9729897540102723

Epoch: 6| Step: 9
Training loss: 2.3554420471191406
Validation loss: 1.9617533952959123

Epoch: 6| Step: 10
Training loss: 1.6320929527282715
Validation loss: 1.953668760996993

Epoch: 6| Step: 11
Training loss: 2.031512975692749
Validation loss: 1.9487173506008681

Epoch: 6| Step: 12
Training loss: 2.2290148735046387
Validation loss: 1.950217475173294

Epoch: 6| Step: 13
Training loss: 1.9214301109313965
Validation loss: 1.9538089793215516

Epoch: 139| Step: 0
Training loss: 2.148200035095215
Validation loss: 1.9515546842287945

Epoch: 6| Step: 1
Training loss: 2.087124824523926
Validation loss: 1.9550354801198488

Epoch: 6| Step: 2
Training loss: 2.331566572189331
Validation loss: 1.9519922823034308

Epoch: 6| Step: 3
Training loss: 2.0590715408325195
Validation loss: 1.951200367302023

Epoch: 6| Step: 4
Training loss: 2.874742031097412
Validation loss: 1.9478897779218611

Epoch: 6| Step: 5
Training loss: 2.717508316040039
Validation loss: 1.9434455440890404

Epoch: 6| Step: 6
Training loss: 2.547546625137329
Validation loss: 1.945340702610631

Epoch: 6| Step: 7
Training loss: 1.3599097728729248
Validation loss: 1.9466508498755835

Epoch: 6| Step: 8
Training loss: 1.9125579595565796
Validation loss: 1.9490658442179363

Epoch: 6| Step: 9
Training loss: 1.8879151344299316
Validation loss: 1.9641140519931752

Epoch: 6| Step: 10
Training loss: 2.5736217498779297
Validation loss: 1.9677046152853197

Epoch: 6| Step: 11
Training loss: 2.357473373413086
Validation loss: 1.970994350730732

Epoch: 6| Step: 12
Training loss: 1.861776351928711
Validation loss: 1.9735104422415457

Epoch: 6| Step: 13
Training loss: 1.4705251455307007
Validation loss: 1.9730762845726424

Epoch: 140| Step: 0
Training loss: 2.4307446479797363
Validation loss: 1.9905839684189006

Epoch: 6| Step: 1
Training loss: 1.7160015106201172
Validation loss: 1.968561682649838

Epoch: 6| Step: 2
Training loss: 2.3927271366119385
Validation loss: 1.9585398858593357

Epoch: 6| Step: 3
Training loss: 1.7289986610412598
Validation loss: 1.9449973913931078

Epoch: 6| Step: 4
Training loss: 1.081679344177246
Validation loss: 1.931363195501348

Epoch: 6| Step: 5
Training loss: 2.3298161029815674
Validation loss: 1.932859730976884

Epoch: 6| Step: 6
Training loss: 1.5567697286605835
Validation loss: 1.931601990935623

Epoch: 6| Step: 7
Training loss: 2.386242389678955
Validation loss: 1.921035744810617

Epoch: 6| Step: 8
Training loss: 2.5465610027313232
Validation loss: 1.9289274382334884

Epoch: 6| Step: 9
Training loss: 2.399540424346924
Validation loss: 1.9306259962820238

Epoch: 6| Step: 10
Training loss: 2.921764612197876
Validation loss: 1.9262006398170226

Epoch: 6| Step: 11
Training loss: 2.116724967956543
Validation loss: 1.9228802470750705

Epoch: 6| Step: 12
Training loss: 2.5468406677246094
Validation loss: 1.9323140498130553

Epoch: 6| Step: 13
Training loss: 2.069674253463745
Validation loss: 1.9383834715812438

Epoch: 141| Step: 0
Training loss: 2.3233370780944824
Validation loss: 1.9251972795814596

Epoch: 6| Step: 1
Training loss: 2.2088630199432373
Validation loss: 1.929950011673794

Epoch: 6| Step: 2
Training loss: 2.492459774017334
Validation loss: 1.9224311651722077

Epoch: 6| Step: 3
Training loss: 1.8631515502929688
Validation loss: 1.9274168245254024

Epoch: 6| Step: 4
Training loss: 2.1534881591796875
Validation loss: 1.9282128631427724

Epoch: 6| Step: 5
Training loss: 1.850614070892334
Validation loss: 1.9224336198581162

Epoch: 6| Step: 6
Training loss: 2.7058746814727783
Validation loss: 1.9285770705951157

Epoch: 6| Step: 7
Training loss: 1.654653549194336
Validation loss: 1.9307103054497832

Epoch: 6| Step: 8
Training loss: 1.8509418964385986
Validation loss: 1.938465238899313

Epoch: 6| Step: 9
Training loss: 2.1415953636169434
Validation loss: 1.927924967581226

Epoch: 6| Step: 10
Training loss: 2.6949474811553955
Validation loss: 1.9181063995566419

Epoch: 6| Step: 11
Training loss: 2.3083176612854004
Validation loss: 1.9199117204194427

Epoch: 6| Step: 12
Training loss: 1.7448066473007202
Validation loss: 1.9237732477085565

Epoch: 6| Step: 13
Training loss: 2.065354347229004
Validation loss: 1.9154499820483628

Epoch: 142| Step: 0
Training loss: 2.072356700897217
Validation loss: 1.9124164235207342

Epoch: 6| Step: 1
Training loss: 2.727264881134033
Validation loss: 1.9240725758255168

Epoch: 6| Step: 2
Training loss: 2.196044683456421
Validation loss: 1.9274167168524958

Epoch: 6| Step: 3
Training loss: 1.9640313386917114
Validation loss: 1.9291432006384737

Epoch: 6| Step: 4
Training loss: 2.120959758758545
Validation loss: 1.9269631742149271

Epoch: 6| Step: 5
Training loss: 2.2944774627685547
Validation loss: 1.9376646716107604

Epoch: 6| Step: 6
Training loss: 1.8373405933380127
Validation loss: 1.9332073798743628

Epoch: 6| Step: 7
Training loss: 1.9429532289505005
Validation loss: 1.9283912643309562

Epoch: 6| Step: 8
Training loss: 2.7668867111206055
Validation loss: 1.9263014011485602

Epoch: 6| Step: 9
Training loss: 1.4057210683822632
Validation loss: 1.9255049049213369

Epoch: 6| Step: 10
Training loss: 2.425899028778076
Validation loss: 1.9262674764920307

Epoch: 6| Step: 11
Training loss: 1.7948627471923828
Validation loss: 1.9180322731694868

Epoch: 6| Step: 12
Training loss: 2.213233470916748
Validation loss: 1.9165232361003917

Epoch: 6| Step: 13
Training loss: 2.5321402549743652
Validation loss: 1.9118378367475284

Epoch: 143| Step: 0
Training loss: 2.7797276973724365
Validation loss: 1.9124466911438973

Epoch: 6| Step: 1
Training loss: 2.072944164276123
Validation loss: 1.9199196536053893

Epoch: 6| Step: 2
Training loss: 1.1408385038375854
Validation loss: 1.91244347505672

Epoch: 6| Step: 3
Training loss: 2.6235010623931885
Validation loss: 1.9171942792912966

Epoch: 6| Step: 4
Training loss: 2.0554299354553223
Validation loss: 1.9271368544588807

Epoch: 6| Step: 5
Training loss: 1.9585564136505127
Validation loss: 1.9269472604156823

Epoch: 6| Step: 6
Training loss: 2.2577250003814697
Validation loss: 1.9214865917800574

Epoch: 6| Step: 7
Training loss: 1.7871606349945068
Validation loss: 1.9264396980244627

Epoch: 6| Step: 8
Training loss: 2.2927980422973633
Validation loss: 1.9203919159468783

Epoch: 6| Step: 9
Training loss: 2.3013381958007812
Validation loss: 1.913981911956623

Epoch: 6| Step: 10
Training loss: 2.0188605785369873
Validation loss: 1.9070571430267826

Epoch: 6| Step: 11
Training loss: 2.126751184463501
Validation loss: 1.9159040540777228

Epoch: 6| Step: 12
Training loss: 1.7668218612670898
Validation loss: 1.9105247605231501

Epoch: 6| Step: 13
Training loss: 3.14273738861084
Validation loss: 1.9138597134620912

Epoch: 144| Step: 0
Training loss: 2.294600009918213
Validation loss: 1.9094287157058716

Epoch: 6| Step: 1
Training loss: 2.6252033710479736
Validation loss: 1.9098857013128137

Epoch: 6| Step: 2
Training loss: 2.574720859527588
Validation loss: 1.914868753443482

Epoch: 6| Step: 3
Training loss: 2.193784713745117
Validation loss: 1.915210562367593

Epoch: 6| Step: 4
Training loss: 1.9991247653961182
Validation loss: 1.9208186185488136

Epoch: 6| Step: 5
Training loss: 1.7939624786376953
Validation loss: 1.931736671796409

Epoch: 6| Step: 6
Training loss: 2.144247531890869
Validation loss: 1.9256670321187666

Epoch: 6| Step: 7
Training loss: 1.860805869102478
Validation loss: 1.919692103580762

Epoch: 6| Step: 8
Training loss: 2.3574626445770264
Validation loss: 1.9153012460277927

Epoch: 6| Step: 9
Training loss: 1.8381019830703735
Validation loss: 1.9148305000797394

Epoch: 6| Step: 10
Training loss: 2.4620063304901123
Validation loss: 1.9196356945140387

Epoch: 6| Step: 11
Training loss: 2.0250627994537354
Validation loss: 1.9171587164684007

Epoch: 6| Step: 12
Training loss: 1.8529812097549438
Validation loss: 1.9487066563739572

Epoch: 6| Step: 13
Training loss: 1.4798603057861328
Validation loss: 1.9392978901504188

Epoch: 145| Step: 0
Training loss: 3.220489978790283
Validation loss: 1.9372815355177848

Epoch: 6| Step: 1
Training loss: 2.094527244567871
Validation loss: 1.9501554863427275

Epoch: 6| Step: 2
Training loss: 2.395468235015869
Validation loss: 1.9609066414576706

Epoch: 6| Step: 3
Training loss: 1.60575532913208
Validation loss: 1.9794626723053634

Epoch: 6| Step: 4
Training loss: 1.9321837425231934
Validation loss: 1.999343672106343

Epoch: 6| Step: 5
Training loss: 2.166287422180176
Validation loss: 1.9906421515249437

Epoch: 6| Step: 6
Training loss: 2.6650936603546143
Validation loss: 2.001506136309716

Epoch: 6| Step: 7
Training loss: 2.296069383621216
Validation loss: 1.9887949343650573

Epoch: 6| Step: 8
Training loss: 2.219243049621582
Validation loss: 1.979109441080401

Epoch: 6| Step: 9
Training loss: 2.1887521743774414
Validation loss: 1.9467482682197326

Epoch: 6| Step: 10
Training loss: 2.1811418533325195
Validation loss: 1.9166181472039991

Epoch: 6| Step: 11
Training loss: 1.6978342533111572
Validation loss: 1.9076988697052002

Epoch: 6| Step: 12
Training loss: 1.4698424339294434
Validation loss: 1.9124776304409068

Epoch: 6| Step: 13
Training loss: 2.040705680847168
Validation loss: 1.9171945254007976

Epoch: 146| Step: 0
Training loss: 2.0602293014526367
Validation loss: 1.9173287640335739

Epoch: 6| Step: 1
Training loss: 1.7869993448257446
Validation loss: 1.9342847716423772

Epoch: 6| Step: 2
Training loss: 1.9122474193572998
Validation loss: 1.9985232942847795

Epoch: 6| Step: 3
Training loss: 2.5759544372558594
Validation loss: 2.0813938328014907

Epoch: 6| Step: 4
Training loss: 2.069735527038574
Validation loss: 2.0868343589126424

Epoch: 6| Step: 5
Training loss: 1.7721420526504517
Validation loss: 2.0061722147849297

Epoch: 6| Step: 6
Training loss: 1.9667141437530518
Validation loss: 1.9579734327972576

Epoch: 6| Step: 7
Training loss: 2.395486354827881
Validation loss: 1.9503700707548408

Epoch: 6| Step: 8
Training loss: 2.1551339626312256
Validation loss: 1.931223718068933

Epoch: 6| Step: 9
Training loss: 1.9492557048797607
Validation loss: 1.9386490173237299

Epoch: 6| Step: 10
Training loss: 2.6627821922302246
Validation loss: 1.955168798405637

Epoch: 6| Step: 11
Training loss: 1.7033417224884033
Validation loss: 1.9786798236190632

Epoch: 6| Step: 12
Training loss: 2.8035593032836914
Validation loss: 1.9860527387229345

Epoch: 6| Step: 13
Training loss: 3.0673091411590576
Validation loss: 2.014789281352874

Epoch: 147| Step: 0
Training loss: 1.7040979862213135
Validation loss: 2.0229553894330095

Epoch: 6| Step: 1
Training loss: 3.1293435096740723
Validation loss: 2.0069602227980092

Epoch: 6| Step: 2
Training loss: 2.7540817260742188
Validation loss: 1.9947227931791736

Epoch: 6| Step: 3
Training loss: 1.8898104429244995
Validation loss: 1.9864232591403428

Epoch: 6| Step: 4
Training loss: 2.8366684913635254
Validation loss: 1.979513947681714

Epoch: 6| Step: 5
Training loss: 2.1702752113342285
Validation loss: 1.9805352303289598

Epoch: 6| Step: 6
Training loss: 1.9597135782241821
Validation loss: 1.9655408269615584

Epoch: 6| Step: 7
Training loss: 2.086566925048828
Validation loss: 1.9483099778493245

Epoch: 6| Step: 8
Training loss: 1.9815821647644043
Validation loss: 1.9638164286972375

Epoch: 6| Step: 9
Training loss: 2.5735511779785156
Validation loss: 1.9741625785827637

Epoch: 6| Step: 10
Training loss: 1.6069445610046387
Validation loss: 1.9754395151651034

Epoch: 6| Step: 11
Training loss: 1.6371732950210571
Validation loss: 1.950704279766288

Epoch: 6| Step: 12
Training loss: 1.917541265487671
Validation loss: 1.9574697299670147

Epoch: 6| Step: 13
Training loss: 2.627425193786621
Validation loss: 1.9517704645792644

Epoch: 148| Step: 0
Training loss: 2.6696181297302246
Validation loss: 1.9703286386305285

Epoch: 6| Step: 1
Training loss: 1.787367343902588
Validation loss: 1.9955467703521892

Epoch: 6| Step: 2
Training loss: 2.403036594390869
Validation loss: 1.98066956509826

Epoch: 6| Step: 3
Training loss: 1.7730883359909058
Validation loss: 1.9819500023318875

Epoch: 6| Step: 4
Training loss: 2.325575828552246
Validation loss: 1.9593037097684798

Epoch: 6| Step: 5
Training loss: 2.197340965270996
Validation loss: 1.9452170402772966

Epoch: 6| Step: 6
Training loss: 2.334784507751465
Validation loss: 1.9466027880227694

Epoch: 6| Step: 7
Training loss: 3.1933908462524414
Validation loss: 1.9505779448375906

Epoch: 6| Step: 8
Training loss: 1.4323985576629639
Validation loss: 1.9586622022813367

Epoch: 6| Step: 9
Training loss: 2.7152633666992188
Validation loss: 1.9983018777703727

Epoch: 6| Step: 10
Training loss: 2.9451904296875
Validation loss: 2.0354057255611626

Epoch: 6| Step: 11
Training loss: 1.367995262145996
Validation loss: 2.0222590033726027

Epoch: 6| Step: 12
Training loss: 1.9272794723510742
Validation loss: 2.0174119959595385

Epoch: 6| Step: 13
Training loss: 1.5644243955612183
Validation loss: 2.018426267049646

Epoch: 149| Step: 0
Training loss: 1.775120496749878
Validation loss: 2.0050937232150825

Epoch: 6| Step: 1
Training loss: 1.9441605806350708
Validation loss: 1.9915653787633425

Epoch: 6| Step: 2
Training loss: 2.041480541229248
Validation loss: 1.9706833670216222

Epoch: 6| Step: 3
Training loss: 2.559666156768799
Validation loss: 1.9695234221796836

Epoch: 6| Step: 4
Training loss: 2.10315203666687
Validation loss: 1.968942012838138

Epoch: 6| Step: 5
Training loss: 1.861757516860962
Validation loss: 1.9756816587140482

Epoch: 6| Step: 6
Training loss: 2.185316324234009
Validation loss: 1.966015051769954

Epoch: 6| Step: 7
Training loss: 1.7232775688171387
Validation loss: 1.9617490178795272

Epoch: 6| Step: 8
Training loss: 2.5716805458068848
Validation loss: 1.9551673089304278

Epoch: 6| Step: 9
Training loss: 2.3143320083618164
Validation loss: 1.943077338639126

Epoch: 6| Step: 10
Training loss: 2.615837574005127
Validation loss: 1.9278399162395026

Epoch: 6| Step: 11
Training loss: 2.084495782852173
Validation loss: 1.921090131164879

Epoch: 6| Step: 12
Training loss: 2.3152942657470703
Validation loss: 1.9188451869513399

Epoch: 6| Step: 13
Training loss: 2.50010347366333
Validation loss: 1.9278391317654682

Epoch: 150| Step: 0
Training loss: 2.5228688716888428
Validation loss: 1.9388805858550533

Epoch: 6| Step: 1
Training loss: 1.775254487991333
Validation loss: 1.9506419268987512

Epoch: 6| Step: 2
Training loss: 3.0423412322998047
Validation loss: 1.9283521630430733

Epoch: 6| Step: 3
Training loss: 2.075625419616699
Validation loss: 1.914242890573317

Epoch: 6| Step: 4
Training loss: 2.2308638095855713
Validation loss: 1.908285246100477

Epoch: 6| Step: 5
Training loss: 2.2111825942993164
Validation loss: 1.9236083761338265

Epoch: 6| Step: 6
Training loss: 1.6203718185424805
Validation loss: 1.9486861767307404

Epoch: 6| Step: 7
Training loss: 2.103370189666748
Validation loss: 1.9547307670757335

Epoch: 6| Step: 8
Training loss: 1.9430854320526123
Validation loss: 1.9520508320100847

Epoch: 6| Step: 9
Training loss: 2.7702250480651855
Validation loss: 1.9425479801752235

Epoch: 6| Step: 10
Training loss: 1.911651372909546
Validation loss: 1.928309194503292

Epoch: 6| Step: 11
Training loss: 2.115269184112549
Validation loss: 1.915261705716451

Epoch: 6| Step: 12
Training loss: 1.6675093173980713
Validation loss: 1.9191417001908826

Epoch: 6| Step: 13
Training loss: 1.539020299911499
Validation loss: 1.9230487218467138

Epoch: 151| Step: 0
Training loss: 2.317020893096924
Validation loss: 1.934609607983661

Epoch: 6| Step: 1
Training loss: 2.6420154571533203
Validation loss: 1.9339244634874406

Epoch: 6| Step: 2
Training loss: 1.8012943267822266
Validation loss: 1.942034855965645

Epoch: 6| Step: 3
Training loss: 2.2713167667388916
Validation loss: 1.930507739384969

Epoch: 6| Step: 4
Training loss: 2.202000856399536
Validation loss: 1.9208052683902044

Epoch: 6| Step: 5
Training loss: 1.5212154388427734
Validation loss: 1.9218816372656053

Epoch: 6| Step: 6
Training loss: 1.675850749015808
Validation loss: 1.9185395779148224

Epoch: 6| Step: 7
Training loss: 2.525099754333496
Validation loss: 1.9092808564503987

Epoch: 6| Step: 8
Training loss: 2.1415858268737793
Validation loss: 1.9101733289739138

Epoch: 6| Step: 9
Training loss: 2.2808496952056885
Validation loss: 1.9049036707929385

Epoch: 6| Step: 10
Training loss: 2.0010924339294434
Validation loss: 1.908128526902968

Epoch: 6| Step: 11
Training loss: 2.101895809173584
Validation loss: 1.900589439176744

Epoch: 6| Step: 12
Training loss: 2.016361713409424
Validation loss: 1.896899151545699

Epoch: 6| Step: 13
Training loss: 2.0266904830932617
Validation loss: 1.8996794454513057

Epoch: 152| Step: 0
Training loss: 2.4108312129974365
Validation loss: 1.9064166635595343

Epoch: 6| Step: 1
Training loss: 2.4307923316955566
Validation loss: 1.9054716312757103

Epoch: 6| Step: 2
Training loss: 1.4731996059417725
Validation loss: 1.9101087995754775

Epoch: 6| Step: 3
Training loss: 2.201488494873047
Validation loss: 1.9273335497866395

Epoch: 6| Step: 4
Training loss: 1.8458359241485596
Validation loss: 1.9257753587538196

Epoch: 6| Step: 5
Training loss: 2.173492431640625
Validation loss: 1.9329782685925883

Epoch: 6| Step: 6
Training loss: 2.1522250175476074
Validation loss: 1.9205073092573433

Epoch: 6| Step: 7
Training loss: 2.1728219985961914
Validation loss: 1.9058720732247958

Epoch: 6| Step: 8
Training loss: 2.286634922027588
Validation loss: 1.920778807773385

Epoch: 6| Step: 9
Training loss: 1.5465291738510132
Validation loss: 1.917066410023679

Epoch: 6| Step: 10
Training loss: 1.8695321083068848
Validation loss: 1.9302610146102084

Epoch: 6| Step: 11
Training loss: 1.9789503812789917
Validation loss: 1.9165720196180447

Epoch: 6| Step: 12
Training loss: 2.4428281784057617
Validation loss: 1.9287832372932023

Epoch: 6| Step: 13
Training loss: 2.789679527282715
Validation loss: 1.9320109787807669

Epoch: 153| Step: 0
Training loss: 1.8613783121109009
Validation loss: 1.9348259125986407

Epoch: 6| Step: 1
Training loss: 2.2886571884155273
Validation loss: 1.9466866241988314

Epoch: 6| Step: 2
Training loss: 2.6000964641571045
Validation loss: 1.9581600158445296

Epoch: 6| Step: 3
Training loss: 1.9897745847702026
Validation loss: 1.9610753854115803

Epoch: 6| Step: 4
Training loss: 2.910299301147461
Validation loss: 1.9606945450587938

Epoch: 6| Step: 5
Training loss: 1.4851861000061035
Validation loss: 1.936031710716986

Epoch: 6| Step: 6
Training loss: 2.286687135696411
Validation loss: 1.9455891578428206

Epoch: 6| Step: 7
Training loss: 2.030698299407959
Validation loss: 1.9303736366251463

Epoch: 6| Step: 8
Training loss: 1.8568332195281982
Validation loss: 1.9231944186713106

Epoch: 6| Step: 9
Training loss: 1.8794643878936768
Validation loss: 1.9234685039007535

Epoch: 6| Step: 10
Training loss: 1.7912613153457642
Validation loss: 1.920605920976208

Epoch: 6| Step: 11
Training loss: 2.1323330402374268
Validation loss: 1.9200569968069754

Epoch: 6| Step: 12
Training loss: 2.1538052558898926
Validation loss: 1.915503022491291

Epoch: 6| Step: 13
Training loss: 2.1452834606170654
Validation loss: 1.9085770832595004

Epoch: 154| Step: 0
Training loss: 1.7908161878585815
Validation loss: 1.9152716923785467

Epoch: 6| Step: 1
Training loss: 2.522155284881592
Validation loss: 1.9258682343267626

Epoch: 6| Step: 2
Training loss: 2.1027636528015137
Validation loss: 1.9389898084825086

Epoch: 6| Step: 3
Training loss: 3.0180604457855225
Validation loss: 1.9418804619901924

Epoch: 6| Step: 4
Training loss: 1.67611825466156
Validation loss: 1.9542741826785508

Epoch: 6| Step: 5
Training loss: 2.1786177158355713
Validation loss: 1.9720225180349042

Epoch: 6| Step: 6
Training loss: 1.795374870300293
Validation loss: 1.9783883043514785

Epoch: 6| Step: 7
Training loss: 1.562196969985962
Validation loss: 1.9814595304509646

Epoch: 6| Step: 8
Training loss: 2.3160510063171387
Validation loss: 1.958494314583399

Epoch: 6| Step: 9
Training loss: 2.1442179679870605
Validation loss: 1.9319914925482966

Epoch: 6| Step: 10
Training loss: 1.8262090682983398
Validation loss: 1.9156913065141248

Epoch: 6| Step: 11
Training loss: 2.001444101333618
Validation loss: 1.903448768841323

Epoch: 6| Step: 12
Training loss: 1.9353402853012085
Validation loss: 1.9006012498691518

Epoch: 6| Step: 13
Training loss: 2.3408987522125244
Validation loss: 1.8872689034349175

Epoch: 155| Step: 0
Training loss: 1.9709060192108154
Validation loss: 1.882040516022713

Epoch: 6| Step: 1
Training loss: 1.7624197006225586
Validation loss: 1.897507090722361

Epoch: 6| Step: 2
Training loss: 2.0911052227020264
Validation loss: 1.9222928721417663

Epoch: 6| Step: 3
Training loss: 2.0772204399108887
Validation loss: 1.962837109001734

Epoch: 6| Step: 4
Training loss: 2.7427079677581787
Validation loss: 1.972141235105453

Epoch: 6| Step: 5
Training loss: 2.896916151046753
Validation loss: 1.9751370517156457

Epoch: 6| Step: 6
Training loss: 2.060319662094116
Validation loss: 1.9874832002065514

Epoch: 6| Step: 7
Training loss: 2.5562925338745117
Validation loss: 1.9674104452133179

Epoch: 6| Step: 8
Training loss: 2.1586923599243164
Validation loss: 1.951968728855092

Epoch: 6| Step: 9
Training loss: 1.6179119348526
Validation loss: 1.941554638647264

Epoch: 6| Step: 10
Training loss: 1.37013840675354
Validation loss: 1.9294161924751856

Epoch: 6| Step: 11
Training loss: 2.3567733764648438
Validation loss: 1.9501984221960909

Epoch: 6| Step: 12
Training loss: 1.8069519996643066
Validation loss: 1.9531155094023673

Epoch: 6| Step: 13
Training loss: 2.4947662353515625
Validation loss: 1.9361140061450262

Epoch: 156| Step: 0
Training loss: 2.321101427078247
Validation loss: 1.9576020984239475

Epoch: 6| Step: 1
Training loss: 2.192829132080078
Validation loss: 1.9160691140800394

Epoch: 6| Step: 2
Training loss: 1.7424554824829102
Validation loss: 1.9459596731329476

Epoch: 6| Step: 3
Training loss: 2.685791492462158
Validation loss: 1.9525114618321902

Epoch: 6| Step: 4
Training loss: 2.6747617721557617
Validation loss: 1.9766963476775794

Epoch: 6| Step: 5
Training loss: 1.9008897542953491
Validation loss: 1.9936041088514431

Epoch: 6| Step: 6
Training loss: 2.724419593811035
Validation loss: 2.016829575261762

Epoch: 6| Step: 7
Training loss: 2.1785402297973633
Validation loss: 1.9995149245826147

Epoch: 6| Step: 8
Training loss: 1.9203016757965088
Validation loss: 1.9805075660828622

Epoch: 6| Step: 9
Training loss: 2.348034381866455
Validation loss: 1.9789793234999462

Epoch: 6| Step: 10
Training loss: 1.722030758857727
Validation loss: 1.9854194579585906

Epoch: 6| Step: 11
Training loss: 1.4471758604049683
Validation loss: 1.985645003216241

Epoch: 6| Step: 12
Training loss: 1.8229750394821167
Validation loss: 1.9883865771755096

Epoch: 6| Step: 13
Training loss: 2.0226309299468994
Validation loss: 1.9756026806369904

Epoch: 157| Step: 0
Training loss: 2.1080379486083984
Validation loss: 1.9729967040400351

Epoch: 6| Step: 1
Training loss: 1.8359036445617676
Validation loss: 1.9900245820322344

Epoch: 6| Step: 2
Training loss: 2.392861843109131
Validation loss: 1.9424499824482908

Epoch: 6| Step: 3
Training loss: 1.585005521774292
Validation loss: 1.9375914283978042

Epoch: 6| Step: 4
Training loss: 2.649068593978882
Validation loss: 1.927598198254903

Epoch: 6| Step: 5
Training loss: 1.640965223312378
Validation loss: 1.940294458020118

Epoch: 6| Step: 6
Training loss: 1.5001240968704224
Validation loss: 1.93059633111441

Epoch: 6| Step: 7
Training loss: 2.218575954437256
Validation loss: 1.9171178276820848

Epoch: 6| Step: 8
Training loss: 2.348392963409424
Validation loss: 1.9425100959757322

Epoch: 6| Step: 9
Training loss: 2.2816927433013916
Validation loss: 1.9265115722533195

Epoch: 6| Step: 10
Training loss: 1.683305025100708
Validation loss: 1.9247597494433004

Epoch: 6| Step: 11
Training loss: 2.4477131366729736
Validation loss: 1.9265639166678152

Epoch: 6| Step: 12
Training loss: 2.547485828399658
Validation loss: 1.9139020776235929

Epoch: 6| Step: 13
Training loss: 2.038923740386963
Validation loss: 1.9185446923778904

Epoch: 158| Step: 0
Training loss: 1.9646587371826172
Validation loss: 1.9251767409745084

Epoch: 6| Step: 1
Training loss: 1.9838746786117554
Validation loss: 1.9196059062916746

Epoch: 6| Step: 2
Training loss: 2.751492500305176
Validation loss: 1.923152719774554

Epoch: 6| Step: 3
Training loss: 2.2107598781585693
Validation loss: 1.9193627308773737

Epoch: 6| Step: 4
Training loss: 1.588998794555664
Validation loss: 1.915817524797173

Epoch: 6| Step: 5
Training loss: 2.1068320274353027
Validation loss: 1.92053525165845

Epoch: 6| Step: 6
Training loss: 2.0216026306152344
Validation loss: 1.9268155931144633

Epoch: 6| Step: 7
Training loss: 1.9603493213653564
Validation loss: 1.918519445644912

Epoch: 6| Step: 8
Training loss: 1.8009226322174072
Validation loss: 1.9239415366162536

Epoch: 6| Step: 9
Training loss: 1.9191210269927979
Validation loss: 1.9395319518222605

Epoch: 6| Step: 10
Training loss: 1.8782857656478882
Validation loss: 1.9481355785041727

Epoch: 6| Step: 11
Training loss: 2.80118989944458
Validation loss: 1.9574010859253586

Epoch: 6| Step: 12
Training loss: 2.3428235054016113
Validation loss: 1.969860138431672

Epoch: 6| Step: 13
Training loss: 1.975281834602356
Validation loss: 1.98590983370299

Epoch: 159| Step: 0
Training loss: 2.2119758129119873
Validation loss: 2.002489366839009

Epoch: 6| Step: 1
Training loss: 2.036719799041748
Validation loss: 2.029817165866975

Epoch: 6| Step: 2
Training loss: 1.8249115943908691
Validation loss: 2.031691707590575

Epoch: 6| Step: 3
Training loss: 2.2367725372314453
Validation loss: 2.027900029254216

Epoch: 6| Step: 4
Training loss: 2.332545280456543
Validation loss: 2.008140092254967

Epoch: 6| Step: 5
Training loss: 1.9107626676559448
Validation loss: 1.987927334282988

Epoch: 6| Step: 6
Training loss: 2.31144642829895
Validation loss: 1.9675480601608113

Epoch: 6| Step: 7
Training loss: 2.039259433746338
Validation loss: 1.9648787962493075

Epoch: 6| Step: 8
Training loss: 1.856853723526001
Validation loss: 1.943241729531237

Epoch: 6| Step: 9
Training loss: 2.192166328430176
Validation loss: 1.92507347624789

Epoch: 6| Step: 10
Training loss: 2.069084644317627
Validation loss: 1.9144707469530002

Epoch: 6| Step: 11
Training loss: 2.38155198097229
Validation loss: 1.9176305814455914

Epoch: 6| Step: 12
Training loss: 2.0906460285186768
Validation loss: 1.9300955828799997

Epoch: 6| Step: 13
Training loss: 2.51084303855896
Validation loss: 1.9260006591837893

Epoch: 160| Step: 0
Training loss: 2.4794583320617676
Validation loss: 1.922444414067012

Epoch: 6| Step: 1
Training loss: 1.7091495990753174
Validation loss: 1.9133396981864847

Epoch: 6| Step: 2
Training loss: 1.4700793027877808
Validation loss: 1.9234541436677337

Epoch: 6| Step: 3
Training loss: 2.1671948432922363
Validation loss: 1.9339060988477481

Epoch: 6| Step: 4
Training loss: 2.0103626251220703
Validation loss: 1.9409877074662076

Epoch: 6| Step: 5
Training loss: 1.955025315284729
Validation loss: 1.9495061982062556

Epoch: 6| Step: 6
Training loss: 2.4992079734802246
Validation loss: 1.9686821378687376

Epoch: 6| Step: 7
Training loss: 2.0336878299713135
Validation loss: 1.9770376579735869

Epoch: 6| Step: 8
Training loss: 2.5131442546844482
Validation loss: 1.9862564891897223

Epoch: 6| Step: 9
Training loss: 2.819046974182129
Validation loss: 1.9956243102268507

Epoch: 6| Step: 10
Training loss: 1.6298143863677979
Validation loss: 1.9946678761513001

Epoch: 6| Step: 11
Training loss: 2.3126213550567627
Validation loss: 2.0005764461332753

Epoch: 6| Step: 12
Training loss: 1.5509109497070312
Validation loss: 1.9681924760982554

Epoch: 6| Step: 13
Training loss: 1.9347052574157715
Validation loss: 1.9544793534022507

Epoch: 161| Step: 0
Training loss: 2.7515358924865723
Validation loss: 1.924629311407766

Epoch: 6| Step: 1
Training loss: 1.903315782546997
Validation loss: 1.9099719883293234

Epoch: 6| Step: 2
Training loss: 2.014644145965576
Validation loss: 1.909381507545389

Epoch: 6| Step: 3
Training loss: 2.4400954246520996
Validation loss: 1.9042635707445041

Epoch: 6| Step: 4
Training loss: 1.7401630878448486
Validation loss: 1.9060656460382606

Epoch: 6| Step: 5
Training loss: 2.3329501152038574
Validation loss: 1.908643727661461

Epoch: 6| Step: 6
Training loss: 1.821589469909668
Validation loss: 1.9228174519795243

Epoch: 6| Step: 7
Training loss: 1.726459264755249
Validation loss: 1.9192095495039416

Epoch: 6| Step: 8
Training loss: 2.311483383178711
Validation loss: 1.9164843392628494

Epoch: 6| Step: 9
Training loss: 0.8673776984214783
Validation loss: 1.9012304159902758

Epoch: 6| Step: 10
Training loss: 2.609652042388916
Validation loss: 1.8960299902064826

Epoch: 6| Step: 11
Training loss: 2.5762438774108887
Validation loss: 1.9044295357119652

Epoch: 6| Step: 12
Training loss: 0.9474635720252991
Validation loss: 1.8931677546552432

Epoch: 6| Step: 13
Training loss: 3.2997448444366455
Validation loss: 1.8976214367856261

Epoch: 162| Step: 0
Training loss: 2.4052186012268066
Validation loss: 1.9099082023866716

Epoch: 6| Step: 1
Training loss: 1.6871025562286377
Validation loss: 1.904624972292172

Epoch: 6| Step: 2
Training loss: 2.014228343963623
Validation loss: 1.9011507098392775

Epoch: 6| Step: 3
Training loss: 1.8821099996566772
Validation loss: 1.9009097071104153

Epoch: 6| Step: 4
Training loss: 2.224703550338745
Validation loss: 1.9199498776466615

Epoch: 6| Step: 5
Training loss: 2.0694780349731445
Validation loss: 1.9278188097861506

Epoch: 6| Step: 6
Training loss: 1.727686882019043
Validation loss: 1.9324229019944386

Epoch: 6| Step: 7
Training loss: 2.295060634613037
Validation loss: 1.9517359579763105

Epoch: 6| Step: 8
Training loss: 2.0504238605499268
Validation loss: 1.968243988611365

Epoch: 6| Step: 9
Training loss: 2.161093235015869
Validation loss: 1.9798495551591277

Epoch: 6| Step: 10
Training loss: 1.6612434387207031
Validation loss: 1.991590497314289

Epoch: 6| Step: 11
Training loss: 2.1965935230255127
Validation loss: 2.0011383230968187

Epoch: 6| Step: 12
Training loss: 2.302624225616455
Validation loss: 2.012308846237839

Epoch: 6| Step: 13
Training loss: 2.0420522689819336
Validation loss: 2.0193928646784958

Epoch: 163| Step: 0
Training loss: 1.7423169612884521
Validation loss: 2.0687120101785146

Epoch: 6| Step: 1
Training loss: 2.1046810150146484
Validation loss: 2.106298811974064

Epoch: 6| Step: 2
Training loss: 2.0492465496063232
Validation loss: 2.1304141911127235

Epoch: 6| Step: 3
Training loss: 1.839906096458435
Validation loss: 2.0993260414369646

Epoch: 6| Step: 4
Training loss: 2.5544397830963135
Validation loss: 2.0876591346597158

Epoch: 6| Step: 5
Training loss: 2.027988910675049
Validation loss: 2.044497441220027

Epoch: 6| Step: 6
Training loss: 1.9061942100524902
Validation loss: 2.0134404141415834

Epoch: 6| Step: 7
Training loss: 2.7186570167541504
Validation loss: 1.9921009309830204

Epoch: 6| Step: 8
Training loss: 2.0442636013031006
Validation loss: 2.017255675408148

Epoch: 6| Step: 9
Training loss: 3.003124952316284
Validation loss: 2.019116514472551

Epoch: 6| Step: 10
Training loss: 2.048834800720215
Validation loss: 2.1057312821829193

Epoch: 6| Step: 11
Training loss: 1.3760809898376465
Validation loss: 2.0796255962823027

Epoch: 6| Step: 12
Training loss: 2.63451886177063
Validation loss: 2.045946257088774

Epoch: 6| Step: 13
Training loss: 1.5609235763549805
Validation loss: 2.0491893958019953

Epoch: 164| Step: 0
Training loss: 1.9146862030029297
Validation loss: 2.007057515523767

Epoch: 6| Step: 1
Training loss: 1.8701368570327759
Validation loss: 1.9549641096463768

Epoch: 6| Step: 2
Training loss: 1.944244146347046
Validation loss: 1.9352205530289681

Epoch: 6| Step: 3
Training loss: 2.0857629776000977
Validation loss: 1.958339378397952

Epoch: 6| Step: 4
Training loss: 2.338552951812744
Validation loss: 1.9762565499992781

Epoch: 6| Step: 5
Training loss: 2.5105414390563965
Validation loss: 1.9982251685152772

Epoch: 6| Step: 6
Training loss: 2.5918357372283936
Validation loss: 2.003141264761648

Epoch: 6| Step: 7
Training loss: 2.350062608718872
Validation loss: 1.9836333413277902

Epoch: 6| Step: 8
Training loss: 1.9711610078811646
Validation loss: 1.9529900281660018

Epoch: 6| Step: 9
Training loss: 2.061988353729248
Validation loss: 1.9208536289071525

Epoch: 6| Step: 10
Training loss: 1.8311755657196045
Validation loss: 1.8918089238546227

Epoch: 6| Step: 11
Training loss: 1.7971841096878052
Validation loss: 1.916301501694546

Epoch: 6| Step: 12
Training loss: 2.124373197555542
Validation loss: 1.93436949740174

Epoch: 6| Step: 13
Training loss: 1.7916910648345947
Validation loss: 1.9721111789826424

Epoch: 165| Step: 0
Training loss: 2.0307817459106445
Validation loss: 2.0775476758198073

Epoch: 6| Step: 1
Training loss: 1.7360148429870605
Validation loss: 2.1299038189713673

Epoch: 6| Step: 2
Training loss: 2.6483957767486572
Validation loss: 2.144991946476762

Epoch: 6| Step: 3
Training loss: 2.5141584873199463
Validation loss: 2.085861864910331

Epoch: 6| Step: 4
Training loss: 1.6829993724822998
Validation loss: 1.9595295203629362

Epoch: 6| Step: 5
Training loss: 1.452216386795044
Validation loss: 1.920995972489798

Epoch: 6| Step: 6
Training loss: 2.097726821899414
Validation loss: 1.930765369886993

Epoch: 6| Step: 7
Training loss: 2.666412115097046
Validation loss: 1.9527559434213946

Epoch: 6| Step: 8
Training loss: 2.438662052154541
Validation loss: 1.9894586865619948

Epoch: 6| Step: 9
Training loss: 1.7926216125488281
Validation loss: 2.059044768733363

Epoch: 6| Step: 10
Training loss: 3.0178651809692383
Validation loss: 2.1018177488798737

Epoch: 6| Step: 11
Training loss: 2.4068808555603027
Validation loss: 2.1001735015582015

Epoch: 6| Step: 12
Training loss: 1.7110238075256348
Validation loss: 2.0513015036941855

Epoch: 6| Step: 13
Training loss: 2.578343629837036
Validation loss: 1.9930452300656227

Epoch: 166| Step: 0
Training loss: 1.6312267780303955
Validation loss: 1.9437069841610488

Epoch: 6| Step: 1
Training loss: 2.3856444358825684
Validation loss: 1.8909338199964134

Epoch: 6| Step: 2
Training loss: 2.54971981048584
Validation loss: 1.8908604844923942

Epoch: 6| Step: 3
Training loss: 1.8610146045684814
Validation loss: 1.9230660623119724

Epoch: 6| Step: 4
Training loss: 2.811845302581787
Validation loss: 1.9349907905824724

Epoch: 6| Step: 5
Training loss: 2.0559611320495605
Validation loss: 1.9498205479755197

Epoch: 6| Step: 6
Training loss: 2.2241029739379883
Validation loss: 1.954704438486407

Epoch: 6| Step: 7
Training loss: 1.2605845928192139
Validation loss: 1.9638689730757026

Epoch: 6| Step: 8
Training loss: 1.7169270515441895
Validation loss: 1.986021049561039

Epoch: 6| Step: 9
Training loss: 2.1542320251464844
Validation loss: 2.0012253958691835

Epoch: 6| Step: 10
Training loss: 2.415569305419922
Validation loss: 2.00259582970732

Epoch: 6| Step: 11
Training loss: 1.8007609844207764
Validation loss: 2.012484804276497

Epoch: 6| Step: 12
Training loss: 2.2239739894866943
Validation loss: 2.008562475122431

Epoch: 6| Step: 13
Training loss: 2.4428870677948
Validation loss: 1.9816352705801688

Epoch: 167| Step: 0
Training loss: 1.5077177286148071
Validation loss: 1.9556067194989932

Epoch: 6| Step: 1
Training loss: 2.16726016998291
Validation loss: 1.9440097065382107

Epoch: 6| Step: 2
Training loss: 2.0874247550964355
Validation loss: 1.930757161109678

Epoch: 6| Step: 3
Training loss: 2.670097827911377
Validation loss: 1.9125889244899954

Epoch: 6| Step: 4
Training loss: 2.3732848167419434
Validation loss: 1.9227648358191214

Epoch: 6| Step: 5
Training loss: 1.8664302825927734
Validation loss: 1.9208918822708951

Epoch: 6| Step: 6
Training loss: 1.7788268327713013
Validation loss: 1.922158920636741

Epoch: 6| Step: 7
Training loss: 2.259777545928955
Validation loss: 1.9225970570759108

Epoch: 6| Step: 8
Training loss: 2.141530990600586
Validation loss: 1.9201782659817768

Epoch: 6| Step: 9
Training loss: 1.7641870975494385
Validation loss: 1.9261312971832931

Epoch: 6| Step: 10
Training loss: 2.018578052520752
Validation loss: 1.9223154103884132

Epoch: 6| Step: 11
Training loss: 2.272679090499878
Validation loss: 1.9268824720895419

Epoch: 6| Step: 12
Training loss: 1.7491711378097534
Validation loss: 1.9068077328384563

Epoch: 6| Step: 13
Training loss: 1.9874022006988525
Validation loss: 1.9082756439844768

Epoch: 168| Step: 0
Training loss: 2.014950752258301
Validation loss: 1.893376870821881

Epoch: 6| Step: 1
Training loss: 1.6534466743469238
Validation loss: 1.8892695519231981

Epoch: 6| Step: 2
Training loss: 2.258090019226074
Validation loss: 1.8804273656619492

Epoch: 6| Step: 3
Training loss: 2.393589496612549
Validation loss: 1.9012179028603338

Epoch: 6| Step: 4
Training loss: 2.008695602416992
Validation loss: 1.917731200495074

Epoch: 6| Step: 5
Training loss: 1.4228134155273438
Validation loss: 1.9245479388903546

Epoch: 6| Step: 6
Training loss: 2.385329246520996
Validation loss: 1.9438586863138343

Epoch: 6| Step: 7
Training loss: 1.7456597089767456
Validation loss: 1.9562895246731338

Epoch: 6| Step: 8
Training loss: 2.0812387466430664
Validation loss: 1.9391888815869567

Epoch: 6| Step: 9
Training loss: 2.5272130966186523
Validation loss: 1.9611471442766086

Epoch: 6| Step: 10
Training loss: 1.7407984733581543
Validation loss: 1.9424184804321618

Epoch: 6| Step: 11
Training loss: 2.022934913635254
Validation loss: 1.9375578434236589

Epoch: 6| Step: 12
Training loss: 2.5516462326049805
Validation loss: 1.9332691943773659

Epoch: 6| Step: 13
Training loss: 1.8875384330749512
Validation loss: 1.935636342212718

Epoch: 169| Step: 0
Training loss: 1.1835265159606934
Validation loss: 1.940614213225662

Epoch: 6| Step: 1
Training loss: 2.082092761993408
Validation loss: 1.9419757114943637

Epoch: 6| Step: 2
Training loss: 1.5761914253234863
Validation loss: 1.9409615557680848

Epoch: 6| Step: 3
Training loss: 2.2687392234802246
Validation loss: 1.9325669375799035

Epoch: 6| Step: 4
Training loss: 1.9906013011932373
Validation loss: 1.9195468630841983

Epoch: 6| Step: 5
Training loss: 2.511874198913574
Validation loss: 1.9278296116859681

Epoch: 6| Step: 6
Training loss: 2.1725432872772217
Validation loss: 1.9234670874893025

Epoch: 6| Step: 7
Training loss: 1.7465837001800537
Validation loss: 1.9387593910258303

Epoch: 6| Step: 8
Training loss: 2.032331705093384
Validation loss: 1.9537203235010947

Epoch: 6| Step: 9
Training loss: 1.4816975593566895
Validation loss: 1.944739523754325

Epoch: 6| Step: 10
Training loss: 2.035972833633423
Validation loss: 1.960499999343708

Epoch: 6| Step: 11
Training loss: 2.3647706508636475
Validation loss: 1.965808222370763

Epoch: 6| Step: 12
Training loss: 2.895872116088867
Validation loss: 1.9635058961888796

Epoch: 6| Step: 13
Training loss: 2.065786361694336
Validation loss: 1.9830744804874543

Epoch: 170| Step: 0
Training loss: 1.733121633529663
Validation loss: 2.0024135612672374

Epoch: 6| Step: 1
Training loss: 2.5491127967834473
Validation loss: 2.007565034333096

Epoch: 6| Step: 2
Training loss: 2.0081615447998047
Validation loss: 2.0018759107076995

Epoch: 6| Step: 3
Training loss: 1.5537679195404053
Validation loss: 2.0151629217209353

Epoch: 6| Step: 4
Training loss: 2.7858991622924805
Validation loss: 2.005116549871301

Epoch: 6| Step: 5
Training loss: 1.581973910331726
Validation loss: 2.003492614274384

Epoch: 6| Step: 6
Training loss: 1.9897005558013916
Validation loss: 1.977437227003036

Epoch: 6| Step: 7
Training loss: 2.101449728012085
Validation loss: 1.9608662410448956

Epoch: 6| Step: 8
Training loss: 1.146517276763916
Validation loss: 1.9512809655999626

Epoch: 6| Step: 9
Training loss: 2.276928424835205
Validation loss: 1.9457802105975408

Epoch: 6| Step: 10
Training loss: 2.5896177291870117
Validation loss: 1.9498238307173534

Epoch: 6| Step: 11
Training loss: 1.7520167827606201
Validation loss: 1.9571966791665683

Epoch: 6| Step: 12
Training loss: 1.5364129543304443
Validation loss: 1.9848082309128137

Epoch: 6| Step: 13
Training loss: 2.92209529876709
Validation loss: 2.0182642218887166

Epoch: 171| Step: 0
Training loss: 1.9954466819763184
Validation loss: 2.0240435369553103

Epoch: 6| Step: 1
Training loss: 1.7457315921783447
Validation loss: 2.0235834378068165

Epoch: 6| Step: 2
Training loss: 2.348971366882324
Validation loss: 2.004728323669844

Epoch: 6| Step: 3
Training loss: 1.4784222841262817
Validation loss: 2.0003145279422885

Epoch: 6| Step: 4
Training loss: 1.6675443649291992
Validation loss: 1.9878350701383365

Epoch: 6| Step: 5
Training loss: 2.2465434074401855
Validation loss: 1.980746119253097

Epoch: 6| Step: 6
Training loss: 2.0715129375457764
Validation loss: 1.9933494162815872

Epoch: 6| Step: 7
Training loss: 2.8001670837402344
Validation loss: 1.9824638648699688

Epoch: 6| Step: 8
Training loss: 1.8988291025161743
Validation loss: 1.9696883732272732

Epoch: 6| Step: 9
Training loss: 1.8572707176208496
Validation loss: 1.9712762460913709

Epoch: 6| Step: 10
Training loss: 1.8421064615249634
Validation loss: 1.979023507846299

Epoch: 6| Step: 11
Training loss: 1.9785149097442627
Validation loss: 1.989294675088698

Epoch: 6| Step: 12
Training loss: 1.9879945516586304
Validation loss: 2.0003078035129014

Epoch: 6| Step: 13
Training loss: 3.1139028072357178
Validation loss: 2.0098361379356793

Epoch: 172| Step: 0
Training loss: 1.8469387292861938
Validation loss: 1.9911730122822586

Epoch: 6| Step: 1
Training loss: 1.6779944896697998
Validation loss: 1.9431334926236061

Epoch: 6| Step: 2
Training loss: 1.6861227750778198
Validation loss: 1.913685474344479

Epoch: 6| Step: 3
Training loss: 1.8274221420288086
Validation loss: 1.9110923813235374

Epoch: 6| Step: 4
Training loss: 1.2566730976104736
Validation loss: 1.9164367465562717

Epoch: 6| Step: 5
Training loss: 2.340334415435791
Validation loss: 1.9163066007757699

Epoch: 6| Step: 6
Training loss: 2.560488224029541
Validation loss: 1.924444240908469

Epoch: 6| Step: 7
Training loss: 2.32761812210083
Validation loss: 1.9257998030672792

Epoch: 6| Step: 8
Training loss: 2.808779716491699
Validation loss: 1.9359077817650252

Epoch: 6| Step: 9
Training loss: 2.146021604537964
Validation loss: 1.9346231491334978

Epoch: 6| Step: 10
Training loss: 2.1732354164123535
Validation loss: 1.943694260812575

Epoch: 6| Step: 11
Training loss: 1.9832100868225098
Validation loss: 1.9447489438518402

Epoch: 6| Step: 12
Training loss: 1.8076914548873901
Validation loss: 1.9319384662053918

Epoch: 6| Step: 13
Training loss: 1.7846742868423462
Validation loss: 1.9444022768287248

Epoch: 173| Step: 0
Training loss: 1.0270721912384033
Validation loss: 1.929565844997283

Epoch: 6| Step: 1
Training loss: 2.2011961936950684
Validation loss: 1.9145223684208368

Epoch: 6| Step: 2
Training loss: 1.8696599006652832
Validation loss: 1.90491489056618

Epoch: 6| Step: 3
Training loss: 2.7771944999694824
Validation loss: 1.8948728717783445

Epoch: 6| Step: 4
Training loss: 1.9687933921813965
Validation loss: 1.8974758963431082

Epoch: 6| Step: 5
Training loss: 1.6112234592437744
Validation loss: 1.8967649321402273

Epoch: 6| Step: 6
Training loss: 1.3363674879074097
Validation loss: 1.9043336722158617

Epoch: 6| Step: 7
Training loss: 2.199209213256836
Validation loss: 1.914815588663983

Epoch: 6| Step: 8
Training loss: 1.6041340827941895
Validation loss: 1.9304664199070265

Epoch: 6| Step: 9
Training loss: 2.1971092224121094
Validation loss: 1.944387823022822

Epoch: 6| Step: 10
Training loss: 2.463876247406006
Validation loss: 1.963623885185488

Epoch: 6| Step: 11
Training loss: 2.4207282066345215
Validation loss: 1.9311223017272128

Epoch: 6| Step: 12
Training loss: 2.0934877395629883
Validation loss: 1.9180334460350774

Epoch: 6| Step: 13
Training loss: 2.3195648193359375
Validation loss: 1.9242636913894324

Epoch: 174| Step: 0
Training loss: 2.310805320739746
Validation loss: 1.9369624327587824

Epoch: 6| Step: 1
Training loss: 1.4222561120986938
Validation loss: 1.9529527361674974

Epoch: 6| Step: 2
Training loss: 1.7517892122268677
Validation loss: 1.9608010168998473

Epoch: 6| Step: 3
Training loss: 2.7015628814697266
Validation loss: 1.977521042669973

Epoch: 6| Step: 4
Training loss: 2.2664530277252197
Validation loss: 1.9614496397715744

Epoch: 6| Step: 5
Training loss: 1.868422269821167
Validation loss: 1.950905599901753

Epoch: 6| Step: 6
Training loss: 1.9500123262405396
Validation loss: 1.9305912499786706

Epoch: 6| Step: 7
Training loss: 1.398407220840454
Validation loss: 1.9208314585429367

Epoch: 6| Step: 8
Training loss: 1.99823796749115
Validation loss: 1.9164195688821937

Epoch: 6| Step: 9
Training loss: 1.5793687105178833
Validation loss: 1.9223878050363192

Epoch: 6| Step: 10
Training loss: 1.8927520513534546
Validation loss: 1.9002289656669862

Epoch: 6| Step: 11
Training loss: 2.3332648277282715
Validation loss: 1.8827071600062872

Epoch: 6| Step: 12
Training loss: 2.465785026550293
Validation loss: 1.8866431584922216

Epoch: 6| Step: 13
Training loss: 1.95307457447052
Validation loss: 1.896294004173689

Epoch: 175| Step: 0
Training loss: 2.383265256881714
Validation loss: 1.9278960689421623

Epoch: 6| Step: 1
Training loss: 1.5775721073150635
Validation loss: 1.9470250273263583

Epoch: 6| Step: 2
Training loss: 2.6688766479492188
Validation loss: 1.9457574262413928

Epoch: 6| Step: 3
Training loss: 2.2192959785461426
Validation loss: 1.9601768908962127

Epoch: 6| Step: 4
Training loss: 2.1120378971099854
Validation loss: 2.0019135885341193

Epoch: 6| Step: 5
Training loss: 1.736742377281189
Validation loss: 2.006089770665733

Epoch: 6| Step: 6
Training loss: 1.9215309619903564
Validation loss: 2.0021251593866656

Epoch: 6| Step: 7
Training loss: 1.5835316181182861
Validation loss: 1.9981756774328088

Epoch: 6| Step: 8
Training loss: 2.7709999084472656
Validation loss: 1.9544017289274482

Epoch: 6| Step: 9
Training loss: 2.0276994705200195
Validation loss: 1.9287368507795437

Epoch: 6| Step: 10
Training loss: 1.8763067722320557
Validation loss: 1.9123442647277669

Epoch: 6| Step: 11
Training loss: 1.294761061668396
Validation loss: 1.8937595557141047

Epoch: 6| Step: 12
Training loss: 1.9010392427444458
Validation loss: 1.8854431977836035

Epoch: 6| Step: 13
Training loss: 1.9092881679534912
Validation loss: 1.868348575407459

Epoch: 176| Step: 0
Training loss: 2.572943687438965
Validation loss: 1.8576353467920774

Epoch: 6| Step: 1
Training loss: 2.9914512634277344
Validation loss: 1.863297031771752

Epoch: 6| Step: 2
Training loss: 0.8006230592727661
Validation loss: 1.8647915765803347

Epoch: 6| Step: 3
Training loss: 1.6989598274230957
Validation loss: 1.8729207002988426

Epoch: 6| Step: 4
Training loss: 1.525212287902832
Validation loss: 1.879372812086536

Epoch: 6| Step: 5
Training loss: 2.559809684753418
Validation loss: 1.877196842624295

Epoch: 6| Step: 6
Training loss: 1.568253755569458
Validation loss: 1.8895895840019308

Epoch: 6| Step: 7
Training loss: 1.9363584518432617
Validation loss: 1.901243689239666

Epoch: 6| Step: 8
Training loss: 2.004570484161377
Validation loss: 1.9082533749200965

Epoch: 6| Step: 9
Training loss: 2.3333091735839844
Validation loss: 1.9059110623534008

Epoch: 6| Step: 10
Training loss: 1.7626185417175293
Validation loss: 1.9290194665232012

Epoch: 6| Step: 11
Training loss: 1.7534260749816895
Validation loss: 1.9607149067745413

Epoch: 6| Step: 12
Training loss: 2.141841411590576
Validation loss: 1.9891016432034072

Epoch: 6| Step: 13
Training loss: 2.0704164505004883
Validation loss: 1.9773776428673857

Epoch: 177| Step: 0
Training loss: 2.81799054145813
Validation loss: 1.9836455878391062

Epoch: 6| Step: 1
Training loss: 1.7797428369522095
Validation loss: 1.991786121040262

Epoch: 6| Step: 2
Training loss: 1.6352325677871704
Validation loss: 1.997107736525997

Epoch: 6| Step: 3
Training loss: 1.696913242340088
Validation loss: 1.9969028452391266

Epoch: 6| Step: 4
Training loss: 1.3728059530258179
Validation loss: 1.99572786208122

Epoch: 6| Step: 5
Training loss: 2.128556251525879
Validation loss: 1.9919772865951701

Epoch: 6| Step: 6
Training loss: 2.004734516143799
Validation loss: 1.9931430765377578

Epoch: 6| Step: 7
Training loss: 2.0025389194488525
Validation loss: 1.9533940874120241

Epoch: 6| Step: 8
Training loss: 2.4739022254943848
Validation loss: 1.950774569665232

Epoch: 6| Step: 9
Training loss: 1.9637119770050049
Validation loss: 1.9413659252146238

Epoch: 6| Step: 10
Training loss: 1.8952224254608154
Validation loss: 1.9198992585623136

Epoch: 6| Step: 11
Training loss: 1.7185360193252563
Validation loss: 1.8957350395059074

Epoch: 6| Step: 12
Training loss: 1.5748486518859863
Validation loss: 1.8863806340002245

Epoch: 6| Step: 13
Training loss: 2.405224084854126
Validation loss: 1.8832796978694137

Epoch: 178| Step: 0
Training loss: 2.533876419067383
Validation loss: 1.8859814636168941

Epoch: 6| Step: 1
Training loss: 1.8425407409667969
Validation loss: 1.8761180036811418

Epoch: 6| Step: 2
Training loss: 2.3966939449310303
Validation loss: 1.8632318588995165

Epoch: 6| Step: 3
Training loss: 2.4231960773468018
Validation loss: 1.8557099116745817

Epoch: 6| Step: 4
Training loss: 1.9878597259521484
Validation loss: 1.8648246718991188

Epoch: 6| Step: 5
Training loss: 2.0436015129089355
Validation loss: 1.8723017413129088

Epoch: 6| Step: 6
Training loss: 1.147521734237671
Validation loss: 1.8680678285578245

Epoch: 6| Step: 7
Training loss: 2.929849863052368
Validation loss: 1.8767423655397149

Epoch: 6| Step: 8
Training loss: 1.3122448921203613
Validation loss: 1.8857224551580285

Epoch: 6| Step: 9
Training loss: 1.4969220161437988
Validation loss: 1.8818684457450785

Epoch: 6| Step: 10
Training loss: 2.5280418395996094
Validation loss: 1.8841818391635854

Epoch: 6| Step: 11
Training loss: 1.5193920135498047
Validation loss: 1.911766141973516

Epoch: 6| Step: 12
Training loss: 1.1668310165405273
Validation loss: 1.9178935622656217

Epoch: 6| Step: 13
Training loss: 2.015073299407959
Validation loss: 1.9255786570169593

Epoch: 179| Step: 0
Training loss: 1.5766019821166992
Validation loss: 1.9504670776346678

Epoch: 6| Step: 1
Training loss: 1.9538578987121582
Validation loss: 1.9826221478882657

Epoch: 6| Step: 2
Training loss: 2.1739792823791504
Validation loss: 2.028476475387491

Epoch: 6| Step: 3
Training loss: 2.202299118041992
Validation loss: 2.064879842983779

Epoch: 6| Step: 4
Training loss: 1.9770840406417847
Validation loss: 2.079784107464616

Epoch: 6| Step: 5
Training loss: 1.9681408405303955
Validation loss: 2.0451125085994764

Epoch: 6| Step: 6
Training loss: 1.9276962280273438
Validation loss: 2.047031335933234

Epoch: 6| Step: 7
Training loss: 1.7614848613739014
Validation loss: 2.0087920132503716

Epoch: 6| Step: 8
Training loss: 2.0551939010620117
Validation loss: 1.9828391357134747

Epoch: 6| Step: 9
Training loss: 2.8245038986206055
Validation loss: 1.9683763686046805

Epoch: 6| Step: 10
Training loss: 1.9250431060791016
Validation loss: 1.9553513937099005

Epoch: 6| Step: 11
Training loss: 1.1779922246932983
Validation loss: 1.9401945965264433

Epoch: 6| Step: 12
Training loss: 1.9253332614898682
Validation loss: 1.9080332530442106

Epoch: 6| Step: 13
Training loss: 1.6698230504989624
Validation loss: 1.8878983477110505

Epoch: 180| Step: 0
Training loss: 1.0110549926757812
Validation loss: 1.8991808314477243

Epoch: 6| Step: 1
Training loss: 2.279679536819458
Validation loss: 1.9007568538829844

Epoch: 6| Step: 2
Training loss: 1.7317688465118408
Validation loss: 1.9332636684499762

Epoch: 6| Step: 3
Training loss: 2.2960243225097656
Validation loss: 1.9437123472972582

Epoch: 6| Step: 4
Training loss: 1.7914314270019531
Validation loss: 1.9304908757568688

Epoch: 6| Step: 5
Training loss: 1.477510690689087
Validation loss: 1.9344035566494029

Epoch: 6| Step: 6
Training loss: 2.368717908859253
Validation loss: 1.9126903651863016

Epoch: 6| Step: 7
Training loss: 2.0625147819519043
Validation loss: 1.8839206105919295

Epoch: 6| Step: 8
Training loss: 2.24680233001709
Validation loss: 1.8848127216421149

Epoch: 6| Step: 9
Training loss: 2.047168493270874
Validation loss: 1.8903497739504742

Epoch: 6| Step: 10
Training loss: 1.7500120401382446
Validation loss: 1.899443926349763

Epoch: 6| Step: 11
Training loss: 2.492077112197876
Validation loss: 1.934081244212325

Epoch: 6| Step: 12
Training loss: 2.236781120300293
Validation loss: 1.9474132766005814

Epoch: 6| Step: 13
Training loss: 1.9682954549789429
Validation loss: 1.9453012468994304

Epoch: 181| Step: 0
Training loss: 1.6169614791870117
Validation loss: 1.9431504293154644

Epoch: 6| Step: 1
Training loss: 2.013505220413208
Validation loss: 1.9466549555460613

Epoch: 6| Step: 2
Training loss: 2.578599452972412
Validation loss: 1.9371024511193717

Epoch: 6| Step: 3
Training loss: 2.4543886184692383
Validation loss: 1.939189536597139

Epoch: 6| Step: 4
Training loss: 1.83098566532135
Validation loss: 1.9243685737732918

Epoch: 6| Step: 5
Training loss: 1.7461416721343994
Validation loss: 1.9175900028597923

Epoch: 6| Step: 6
Training loss: 1.856112003326416
Validation loss: 1.9304305058653637

Epoch: 6| Step: 7
Training loss: 1.9894917011260986
Validation loss: 1.928052245929677

Epoch: 6| Step: 8
Training loss: 1.6769367456436157
Validation loss: 1.9262280541081582

Epoch: 6| Step: 9
Training loss: 1.7083685398101807
Validation loss: 1.9430664162481985

Epoch: 6| Step: 10
Training loss: 2.405935764312744
Validation loss: 1.9704414913731236

Epoch: 6| Step: 11
Training loss: 1.95440673828125
Validation loss: 1.9416019878079813

Epoch: 6| Step: 12
Training loss: 1.2923693656921387
Validation loss: 1.9431326568767588

Epoch: 6| Step: 13
Training loss: 2.246469259262085
Validation loss: 1.9379365008364442

Epoch: 182| Step: 0
Training loss: 1.810453176498413
Validation loss: 1.9705230600090438

Epoch: 6| Step: 1
Training loss: 2.163224458694458
Validation loss: 2.01524979324751

Epoch: 6| Step: 2
Training loss: 2.0592315196990967
Validation loss: 2.024550361018027

Epoch: 6| Step: 3
Training loss: 1.5242668390274048
Validation loss: 2.0443173544381255

Epoch: 6| Step: 4
Training loss: 2.113248348236084
Validation loss: 2.0176331381643973

Epoch: 6| Step: 5
Training loss: 2.056286573410034
Validation loss: 2.0132837449350665

Epoch: 6| Step: 6
Training loss: 1.4406906366348267
Validation loss: 1.9957756175789783

Epoch: 6| Step: 7
Training loss: 2.1773061752319336
Validation loss: 2.007412100350985

Epoch: 6| Step: 8
Training loss: 1.7228626012802124
Validation loss: 1.9982952558866112

Epoch: 6| Step: 9
Training loss: 2.0432894229888916
Validation loss: 1.9797492296464982

Epoch: 6| Step: 10
Training loss: 1.4463114738464355
Validation loss: 1.978334003879178

Epoch: 6| Step: 11
Training loss: 1.923532247543335
Validation loss: 1.9893414974212646

Epoch: 6| Step: 12
Training loss: 2.1638519763946533
Validation loss: 2.007399087311119

Epoch: 6| Step: 13
Training loss: 2.593007802963257
Validation loss: 2.002480761979216

Epoch: 183| Step: 0
Training loss: 2.302496910095215
Validation loss: 1.9890513650832637

Epoch: 6| Step: 1
Training loss: 2.1306700706481934
Validation loss: 1.9392988489520164

Epoch: 6| Step: 2
Training loss: 1.71274995803833
Validation loss: 1.924670470658169

Epoch: 6| Step: 3
Training loss: 1.9811275005340576
Validation loss: 1.9392921104226062

Epoch: 6| Step: 4
Training loss: 2.1316089630126953
Validation loss: 1.9470447750501736

Epoch: 6| Step: 5
Training loss: 1.6654534339904785
Validation loss: 1.9569936836919477

Epoch: 6| Step: 6
Training loss: 2.4908061027526855
Validation loss: 1.9546947786884923

Epoch: 6| Step: 7
Training loss: 1.5883638858795166
Validation loss: 1.9518617071131223

Epoch: 6| Step: 8
Training loss: 1.7754276990890503
Validation loss: 1.9597406002783007

Epoch: 6| Step: 9
Training loss: 1.5747915506362915
Validation loss: 1.9649261864282752

Epoch: 6| Step: 10
Training loss: 1.834526538848877
Validation loss: 1.9784553794450657

Epoch: 6| Step: 11
Training loss: 1.5292370319366455
Validation loss: 1.9822026350164925

Epoch: 6| Step: 12
Training loss: 2.3599190711975098
Validation loss: 1.9632078998832292

Epoch: 6| Step: 13
Training loss: 2.1728627681732178
Validation loss: 1.9667909145355225

Epoch: 184| Step: 0
Training loss: 1.859598994255066
Validation loss: 1.9395685093377226

Epoch: 6| Step: 1
Training loss: 2.0390801429748535
Validation loss: 1.9254124395308956

Epoch: 6| Step: 2
Training loss: 2.1816277503967285
Validation loss: 1.937649021866501

Epoch: 6| Step: 3
Training loss: 1.4206326007843018
Validation loss: 1.9183815551060501

Epoch: 6| Step: 4
Training loss: 2.344860553741455
Validation loss: 1.9220487558713524

Epoch: 6| Step: 5
Training loss: 1.7844150066375732
Validation loss: 1.925719149651066

Epoch: 6| Step: 6
Training loss: 1.0992047786712646
Validation loss: 1.9201388846161545

Epoch: 6| Step: 7
Training loss: 1.7435417175292969
Validation loss: 1.9347494315075617

Epoch: 6| Step: 8
Training loss: 2.2863879203796387
Validation loss: 1.9343838896802676

Epoch: 6| Step: 9
Training loss: 1.3885676860809326
Validation loss: 1.9645155245257961

Epoch: 6| Step: 10
Training loss: 2.39733624458313
Validation loss: 1.9839581866418161

Epoch: 6| Step: 11
Training loss: 2.487539768218994
Validation loss: 2.0440237252942977

Epoch: 6| Step: 12
Training loss: 1.4754366874694824
Validation loss: 2.0797621973099245

Epoch: 6| Step: 13
Training loss: 1.9530253410339355
Validation loss: 2.1242357120719007

Epoch: 185| Step: 0
Training loss: 2.3845467567443848
Validation loss: 2.0978752810467958

Epoch: 6| Step: 1
Training loss: 1.6773478984832764
Validation loss: 2.0839733718543925

Epoch: 6| Step: 2
Training loss: 2.7119085788726807
Validation loss: 2.042865362218631

Epoch: 6| Step: 3
Training loss: 2.4290552139282227
Validation loss: 2.007229289700908

Epoch: 6| Step: 4
Training loss: 2.137667417526245
Validation loss: 1.9710085084361415

Epoch: 6| Step: 5
Training loss: 2.119763135910034
Validation loss: 1.94857979653984

Epoch: 6| Step: 6
Training loss: 1.22742760181427
Validation loss: 1.950662987206572

Epoch: 6| Step: 7
Training loss: 2.256618022918701
Validation loss: 1.9508428932518087

Epoch: 6| Step: 8
Training loss: 1.4510540962219238
Validation loss: 1.963805139705699

Epoch: 6| Step: 9
Training loss: 2.1913013458251953
Validation loss: 1.9612836350676834

Epoch: 6| Step: 10
Training loss: 1.8895890712738037
Validation loss: 1.934502786205661

Epoch: 6| Step: 11
Training loss: 1.7953031063079834
Validation loss: 1.9320465518582253

Epoch: 6| Step: 12
Training loss: 1.4244213104248047
Validation loss: 1.9446455624795729

Epoch: 6| Step: 13
Training loss: 1.4576258659362793
Validation loss: 1.9754954435492074

Epoch: 186| Step: 0
Training loss: 2.0417652130126953
Validation loss: 2.058476899259834

Epoch: 6| Step: 1
Training loss: 1.7029304504394531
Validation loss: 2.0906597632233814

Epoch: 6| Step: 2
Training loss: 2.0741653442382812
Validation loss: 2.102402622981738

Epoch: 6| Step: 3
Training loss: 1.309959888458252
Validation loss: 2.093860460865882

Epoch: 6| Step: 4
Training loss: 2.7668392658233643
Validation loss: 2.053319566993303

Epoch: 6| Step: 5
Training loss: 1.6358033418655396
Validation loss: 2.0248907125124367

Epoch: 6| Step: 6
Training loss: 2.121262788772583
Validation loss: 2.0260070934090564

Epoch: 6| Step: 7
Training loss: 1.2012603282928467
Validation loss: 1.9951306363587737

Epoch: 6| Step: 8
Training loss: 2.1504483222961426
Validation loss: 1.9771069813800115

Epoch: 6| Step: 9
Training loss: 1.850395679473877
Validation loss: 1.9718476572344381

Epoch: 6| Step: 10
Training loss: 1.7285504341125488
Validation loss: 1.956170920402773

Epoch: 6| Step: 11
Training loss: 1.686153531074524
Validation loss: 1.9373131772523284

Epoch: 6| Step: 12
Training loss: 2.565988779067993
Validation loss: 1.9367876706584808

Epoch: 6| Step: 13
Training loss: 3.1190977096557617
Validation loss: 1.9084152072988532

Epoch: 187| Step: 0
Training loss: 1.6907458305358887
Validation loss: 1.9151643142905286

Epoch: 6| Step: 1
Training loss: 1.6908563375473022
Validation loss: 1.9478963523782709

Epoch: 6| Step: 2
Training loss: 2.063533067703247
Validation loss: 1.9370782990609445

Epoch: 6| Step: 3
Training loss: 1.3888806104660034
Validation loss: 1.945227494803808

Epoch: 6| Step: 4
Training loss: 2.0476863384246826
Validation loss: 1.9174289831551172

Epoch: 6| Step: 5
Training loss: 1.8864867687225342
Validation loss: 1.918045715619159

Epoch: 6| Step: 6
Training loss: 2.1157801151275635
Validation loss: 1.9090615895486647

Epoch: 6| Step: 7
Training loss: 1.3353720903396606
Validation loss: 1.898125776680567

Epoch: 6| Step: 8
Training loss: 1.6008687019348145
Validation loss: 1.9203043240372852

Epoch: 6| Step: 9
Training loss: 2.6955933570861816
Validation loss: 1.9530192139328166

Epoch: 6| Step: 10
Training loss: 2.216172933578491
Validation loss: 1.967204322097122

Epoch: 6| Step: 11
Training loss: 1.7155841588974
Validation loss: 1.9680258868842997

Epoch: 6| Step: 12
Training loss: 2.0732712745666504
Validation loss: 1.9789104923125236

Epoch: 6| Step: 13
Training loss: 2.185906410217285
Validation loss: 1.9954062059361448

Epoch: 188| Step: 0
Training loss: 1.471578598022461
Validation loss: 1.9797947304223174

Epoch: 6| Step: 1
Training loss: 2.2932472229003906
Validation loss: 1.9674821463964318

Epoch: 6| Step: 2
Training loss: 1.585071325302124
Validation loss: 1.9549324204844813

Epoch: 6| Step: 3
Training loss: 2.1959972381591797
Validation loss: 1.9453414217118294

Epoch: 6| Step: 4
Training loss: 2.442133903503418
Validation loss: 1.9474040885125437

Epoch: 6| Step: 5
Training loss: 1.4314998388290405
Validation loss: 1.9587370093150804

Epoch: 6| Step: 6
Training loss: 1.7718069553375244
Validation loss: 1.9847032036832584

Epoch: 6| Step: 7
Training loss: 1.8365635871887207
Validation loss: 2.031274967296149

Epoch: 6| Step: 8
Training loss: 2.3705146312713623
Validation loss: 2.063658969376677

Epoch: 6| Step: 9
Training loss: 1.923370599746704
Validation loss: 2.0875783543432913

Epoch: 6| Step: 10
Training loss: 1.6718571186065674
Validation loss: 2.0937372074332288

Epoch: 6| Step: 11
Training loss: 2.0840206146240234
Validation loss: 2.099391770619218

Epoch: 6| Step: 12
Training loss: 2.212354898452759
Validation loss: 2.109977755495297

Epoch: 6| Step: 13
Training loss: 1.3386467695236206
Validation loss: 2.092772706862419

Epoch: 189| Step: 0
Training loss: 1.9636236429214478
Validation loss: 2.06056535115806

Epoch: 6| Step: 1
Training loss: 1.028012752532959
Validation loss: 2.046005154168734

Epoch: 6| Step: 2
Training loss: 2.2282514572143555
Validation loss: 2.008924171488772

Epoch: 6| Step: 3
Training loss: 2.377531051635742
Validation loss: 1.9963126169737948

Epoch: 6| Step: 4
Training loss: 2.0488815307617188
Validation loss: 1.996548778267317

Epoch: 6| Step: 5
Training loss: 2.7685558795928955
Validation loss: 2.013726749727803

Epoch: 6| Step: 6
Training loss: 2.4481990337371826
Validation loss: 2.0174082491987493

Epoch: 6| Step: 7
Training loss: 2.5496068000793457
Validation loss: 2.016912220626749

Epoch: 6| Step: 8
Training loss: 1.8551218509674072
Validation loss: 2.0501721110395206

Epoch: 6| Step: 9
Training loss: 2.1981992721557617
Validation loss: 2.055537503252747

Epoch: 6| Step: 10
Training loss: 1.4180371761322021
Validation loss: 2.1105203128630117

Epoch: 6| Step: 11
Training loss: 0.9074851870536804
Validation loss: 2.109595585894841

Epoch: 6| Step: 12
Training loss: 1.5869519710540771
Validation loss: 2.1307254581041235

Epoch: 6| Step: 13
Training loss: 1.6787790060043335
Validation loss: 2.0850792789971955

Epoch: 190| Step: 0
Training loss: 1.9801623821258545
Validation loss: 2.0478632706467823

Epoch: 6| Step: 1
Training loss: 1.962925672531128
Validation loss: 1.9682383511656074

Epoch: 6| Step: 2
Training loss: 1.6105608940124512
Validation loss: 1.9238884833551222

Epoch: 6| Step: 3
Training loss: 1.6410231590270996
Validation loss: 1.8960540474102061

Epoch: 6| Step: 4
Training loss: 2.1091275215148926
Validation loss: 1.9051083249430503

Epoch: 6| Step: 5
Training loss: 2.2986655235290527
Validation loss: 1.90866760541034

Epoch: 6| Step: 6
Training loss: 2.307190418243408
Validation loss: 1.9099011203294158

Epoch: 6| Step: 7
Training loss: 1.675231695175171
Validation loss: 1.9108528039788688

Epoch: 6| Step: 8
Training loss: 2.0671486854553223
Validation loss: 1.9143943337983982

Epoch: 6| Step: 9
Training loss: 1.7541574239730835
Validation loss: 1.939051797313075

Epoch: 6| Step: 10
Training loss: 2.444429636001587
Validation loss: 1.9489946314083633

Epoch: 6| Step: 11
Training loss: 2.0614376068115234
Validation loss: 1.9514885307640157

Epoch: 6| Step: 12
Training loss: 1.011300802230835
Validation loss: 1.9339589611176522

Epoch: 6| Step: 13
Training loss: 1.5629520416259766
Validation loss: 1.92407396019146

Epoch: 191| Step: 0
Training loss: 2.133575439453125
Validation loss: 1.9283262837317683

Epoch: 6| Step: 1
Training loss: 1.8202458620071411
Validation loss: 1.948164721970917

Epoch: 6| Step: 2
Training loss: 2.0436205863952637
Validation loss: 1.9567871324477657

Epoch: 6| Step: 3
Training loss: 1.6793873310089111
Validation loss: 1.9733266856080742

Epoch: 6| Step: 4
Training loss: 1.6529653072357178
Validation loss: 2.027532354477913

Epoch: 6| Step: 5
Training loss: 2.31240177154541
Validation loss: 2.067648349269744

Epoch: 6| Step: 6
Training loss: 1.6798049211502075
Validation loss: 2.0584423990659815

Epoch: 6| Step: 7
Training loss: 1.9547674655914307
Validation loss: 2.0474903198980514

Epoch: 6| Step: 8
Training loss: 2.0809335708618164
Validation loss: 2.0203303290951635

Epoch: 6| Step: 9
Training loss: 1.587430477142334
Validation loss: 2.0116492573932936

Epoch: 6| Step: 10
Training loss: 2.0562744140625
Validation loss: 1.983993818683009

Epoch: 6| Step: 11
Training loss: 1.0086684226989746
Validation loss: 1.9929348537998814

Epoch: 6| Step: 12
Training loss: 1.9718422889709473
Validation loss: 1.9781707563707907

Epoch: 6| Step: 13
Training loss: 2.4929115772247314
Validation loss: 1.9927016150566839

Epoch: 192| Step: 0
Training loss: 1.6210660934448242
Validation loss: 1.9802424471865419

Epoch: 6| Step: 1
Training loss: 1.4717211723327637
Validation loss: 1.9551429094806794

Epoch: 6| Step: 2
Training loss: 1.7048566341400146
Validation loss: 1.9349724323518815

Epoch: 6| Step: 3
Training loss: 2.036287307739258
Validation loss: 1.909012459939526

Epoch: 6| Step: 4
Training loss: 2.493091583251953
Validation loss: 1.9321103442099787

Epoch: 6| Step: 5
Training loss: 1.7351932525634766
Validation loss: 1.9185127673610565

Epoch: 6| Step: 6
Training loss: 2.0714354515075684
Validation loss: 1.9426584487320275

Epoch: 6| Step: 7
Training loss: 1.4229984283447266
Validation loss: 1.96067597276421

Epoch: 6| Step: 8
Training loss: 1.505431890487671
Validation loss: 1.9684672073651386

Epoch: 6| Step: 9
Training loss: 2.4396486282348633
Validation loss: 1.9969721712091917

Epoch: 6| Step: 10
Training loss: 1.4730827808380127
Validation loss: 2.021485218437769

Epoch: 6| Step: 11
Training loss: 2.0980138778686523
Validation loss: 2.0169959939936155

Epoch: 6| Step: 12
Training loss: 2.0866458415985107
Validation loss: 2.0038423922754105

Epoch: 6| Step: 13
Training loss: 2.413280487060547
Validation loss: 1.9911688707208122

Epoch: 193| Step: 0
Training loss: 1.4913402795791626
Validation loss: 1.9868477441931283

Epoch: 6| Step: 1
Training loss: 2.441716194152832
Validation loss: 1.9964553233115905

Epoch: 6| Step: 2
Training loss: 2.030073881149292
Validation loss: 1.9784745529133787

Epoch: 6| Step: 3
Training loss: 2.0136959552764893
Validation loss: 1.978922677296464

Epoch: 6| Step: 4
Training loss: 1.8879003524780273
Validation loss: 1.9493973165430047

Epoch: 6| Step: 5
Training loss: 1.2885663509368896
Validation loss: 1.9321274770203458

Epoch: 6| Step: 6
Training loss: 1.787203311920166
Validation loss: 1.9225438179508332

Epoch: 6| Step: 7
Training loss: 1.767998456954956
Validation loss: 1.9134684326828166

Epoch: 6| Step: 8
Training loss: 1.7996594905853271
Validation loss: 1.926687035509335

Epoch: 6| Step: 9
Training loss: 2.473881959915161
Validation loss: 1.9501472852563346

Epoch: 6| Step: 10
Training loss: 1.799077033996582
Validation loss: 1.9966187707839473

Epoch: 6| Step: 11
Training loss: 1.6315335035324097
Validation loss: 2.013125074807034

Epoch: 6| Step: 12
Training loss: 1.799318790435791
Validation loss: 2.07660404200195

Epoch: 6| Step: 13
Training loss: 2.1911680698394775
Validation loss: 2.0955333453352734

Epoch: 194| Step: 0
Training loss: 1.6959805488586426
Validation loss: 2.1348806888826433

Epoch: 6| Step: 1
Training loss: 1.9988895654678345
Validation loss: 2.1167052830419233

Epoch: 6| Step: 2
Training loss: 2.0864651203155518
Validation loss: 2.051797350247701

Epoch: 6| Step: 3
Training loss: 1.775355577468872
Validation loss: 2.0364792859682472

Epoch: 6| Step: 4
Training loss: 1.7286713123321533
Validation loss: 1.9935218249597857

Epoch: 6| Step: 5
Training loss: 2.136047601699829
Validation loss: 1.9540904337360012

Epoch: 6| Step: 6
Training loss: 1.7506935596466064
Validation loss: 1.9511414766311646

Epoch: 6| Step: 7
Training loss: 1.8845175504684448
Validation loss: 1.9587506401923396

Epoch: 6| Step: 8
Training loss: 1.1865434646606445
Validation loss: 1.9515971393995388

Epoch: 6| Step: 9
Training loss: 1.696089744567871
Validation loss: 1.9637936007591985

Epoch: 6| Step: 10
Training loss: 2.2122890949249268
Validation loss: 1.9383665156620804

Epoch: 6| Step: 11
Training loss: 2.3955819606781006
Validation loss: 1.9457222979555848

Epoch: 6| Step: 12
Training loss: 1.9428682327270508
Validation loss: 1.9414955031487249

Epoch: 6| Step: 13
Training loss: 1.6501071453094482
Validation loss: 1.9937214928288614

Epoch: 195| Step: 0
Training loss: 1.3495101928710938
Validation loss: 2.0180829391684583

Epoch: 6| Step: 1
Training loss: 2.0245444774627686
Validation loss: 2.082092300538094

Epoch: 6| Step: 2
Training loss: 2.0084052085876465
Validation loss: 2.1168698444161365

Epoch: 6| Step: 3
Training loss: 1.804957389831543
Validation loss: 2.130191074904575

Epoch: 6| Step: 4
Training loss: 2.020528554916382
Validation loss: 2.1008190185792985

Epoch: 6| Step: 5
Training loss: 2.1037135124206543
Validation loss: 2.047871829361044

Epoch: 6| Step: 6
Training loss: 1.6006660461425781
Validation loss: 1.9829149092397382

Epoch: 6| Step: 7
Training loss: 1.305201530456543
Validation loss: 1.974005122338572

Epoch: 6| Step: 8
Training loss: 2.1397674083709717
Validation loss: 1.9400501174311484

Epoch: 6| Step: 9
Training loss: 1.7749898433685303
Validation loss: 1.9277712939887919

Epoch: 6| Step: 10
Training loss: 2.129486560821533
Validation loss: 1.930096855727575

Epoch: 6| Step: 11
Training loss: 1.68290376663208
Validation loss: 1.935998878171367

Epoch: 6| Step: 12
Training loss: 1.844227910041809
Validation loss: 1.9248537081544117

Epoch: 6| Step: 13
Training loss: 1.8081419467926025
Validation loss: 1.93513140883497

Epoch: 196| Step: 0
Training loss: 1.9092726707458496
Validation loss: 1.9459096847041961

Epoch: 6| Step: 1
Training loss: 1.728043556213379
Validation loss: 1.931863687371695

Epoch: 6| Step: 2
Training loss: 1.677351951599121
Validation loss: 1.9412124362043155

Epoch: 6| Step: 3
Training loss: 1.4905815124511719
Validation loss: 1.9590514039480558

Epoch: 6| Step: 4
Training loss: 1.809767723083496
Validation loss: 1.98012759095879

Epoch: 6| Step: 5
Training loss: 1.8186516761779785
Validation loss: 2.0136792429031862

Epoch: 6| Step: 6
Training loss: 1.8830833435058594
Validation loss: 2.014979257378527

Epoch: 6| Step: 7
Training loss: 1.7151868343353271
Validation loss: 2.028924770252679

Epoch: 6| Step: 8
Training loss: 1.8329377174377441
Validation loss: 2.0316941174127723

Epoch: 6| Step: 9
Training loss: 2.9180989265441895
Validation loss: 2.0413376977366786

Epoch: 6| Step: 10
Training loss: 1.6406445503234863
Validation loss: 2.038918815633302

Epoch: 6| Step: 11
Training loss: 1.6302592754364014
Validation loss: 2.0283443902128484

Epoch: 6| Step: 12
Training loss: 1.5523428916931152
Validation loss: 2.0015642617338445

Epoch: 6| Step: 13
Training loss: 1.3883157968521118
Validation loss: 1.990166591059777

Epoch: 197| Step: 0
Training loss: 1.449225902557373
Validation loss: 1.9933155146978234

Epoch: 6| Step: 1
Training loss: 1.2322217226028442
Validation loss: 2.0080704842844317

Epoch: 6| Step: 2
Training loss: 1.7507328987121582
Validation loss: 2.0195230078953568

Epoch: 6| Step: 3
Training loss: 1.3757457733154297
Validation loss: 2.040810990077193

Epoch: 6| Step: 4
Training loss: 2.0856213569641113
Validation loss: 2.030631624242311

Epoch: 6| Step: 5
Training loss: 1.5953257083892822
Validation loss: 2.0208075482358216

Epoch: 6| Step: 6
Training loss: 2.343921422958374
Validation loss: 2.002715249215403

Epoch: 6| Step: 7
Training loss: 2.356752634048462
Validation loss: 1.9613365229739939

Epoch: 6| Step: 8
Training loss: 2.235952615737915
Validation loss: 1.9501995271252048

Epoch: 6| Step: 9
Training loss: 2.151787281036377
Validation loss: 1.9292856877849949

Epoch: 6| Step: 10
Training loss: 2.067394971847534
Validation loss: 1.9278093512340257

Epoch: 6| Step: 11
Training loss: 1.7869865894317627
Validation loss: 1.9152163767045545

Epoch: 6| Step: 12
Training loss: 1.2187142372131348
Validation loss: 1.8921901590080672

Epoch: 6| Step: 13
Training loss: 1.9835180044174194
Validation loss: 1.8999062827838364

Epoch: 198| Step: 0
Training loss: 1.8429715633392334
Validation loss: 1.9346911112467449

Epoch: 6| Step: 1
Training loss: 1.7331767082214355
Validation loss: 1.9958772326028476

Epoch: 6| Step: 2
Training loss: 1.5531212091445923
Validation loss: 2.061831076939901

Epoch: 6| Step: 3
Training loss: 1.8589046001434326
Validation loss: 2.113343277285176

Epoch: 6| Step: 4
Training loss: 2.40910005569458
Validation loss: 2.137738512408349

Epoch: 6| Step: 5
Training loss: 2.359482765197754
Validation loss: 2.1330248309719946

Epoch: 6| Step: 6
Training loss: 1.592146873474121
Validation loss: 2.111406530103376

Epoch: 6| Step: 7
Training loss: 2.5219554901123047
Validation loss: 2.123552405706016

Epoch: 6| Step: 8
Training loss: 1.3865232467651367
Validation loss: 2.0715520843382804

Epoch: 6| Step: 9
Training loss: 1.8902233839035034
Validation loss: 2.0007881784951813

Epoch: 6| Step: 10
Training loss: 1.7756550312042236
Validation loss: 1.9416158494128977

Epoch: 6| Step: 11
Training loss: 1.8261499404907227
Validation loss: 1.9361765705129153

Epoch: 6| Step: 12
Training loss: 1.58558988571167
Validation loss: 1.931630693456178

Epoch: 6| Step: 13
Training loss: 1.282089114189148
Validation loss: 1.9302109800359255

Epoch: 199| Step: 0
Training loss: 1.630040168762207
Validation loss: 1.9062903427308606

Epoch: 6| Step: 1
Training loss: 1.9803862571716309
Validation loss: 1.9207059862793132

Epoch: 6| Step: 2
Training loss: 2.2467269897460938
Validation loss: 1.9302510946027693

Epoch: 6| Step: 3
Training loss: 1.5240325927734375
Validation loss: 1.9429749468321442

Epoch: 6| Step: 4
Training loss: 1.2271995544433594
Validation loss: 1.947672664478261

Epoch: 6| Step: 5
Training loss: 2.372096538543701
Validation loss: 1.9939213696346487

Epoch: 6| Step: 6
Training loss: 1.623863697052002
Validation loss: 2.0177698494285665

Epoch: 6| Step: 7
Training loss: 1.5808563232421875
Validation loss: 2.0165557271690777

Epoch: 6| Step: 8
Training loss: 1.8666223287582397
Validation loss: 1.9897556561295704

Epoch: 6| Step: 9
Training loss: 1.0242289304733276
Validation loss: 1.9851299152579358

Epoch: 6| Step: 10
Training loss: 1.9347059726715088
Validation loss: 1.9791463959601618

Epoch: 6| Step: 11
Training loss: 2.337721824645996
Validation loss: 1.9847573157279723

Epoch: 6| Step: 12
Training loss: 1.9630032777786255
Validation loss: 2.0154293506376204

Epoch: 6| Step: 13
Training loss: 2.316680669784546
Validation loss: 2.0258868304632043

Epoch: 200| Step: 0
Training loss: 1.8366103172302246
Validation loss: 2.0317312684110416

Epoch: 6| Step: 1
Training loss: 1.292604684829712
Validation loss: 2.054656687603202

Epoch: 6| Step: 2
Training loss: 2.311458110809326
Validation loss: 2.0644543222201768

Epoch: 6| Step: 3
Training loss: 1.6593925952911377
Validation loss: 2.0684373032662178

Epoch: 6| Step: 4
Training loss: 1.6741012334823608
Validation loss: 2.0390283446158133

Epoch: 6| Step: 5
Training loss: 1.3082849979400635
Validation loss: 2.0294290973294165

Epoch: 6| Step: 6
Training loss: 1.5090938806533813
Validation loss: 2.0031179945955992

Epoch: 6| Step: 7
Training loss: 2.0788488388061523
Validation loss: 1.972852781254758

Epoch: 6| Step: 8
Training loss: 1.388176679611206
Validation loss: 1.9659205880216373

Epoch: 6| Step: 9
Training loss: 1.945573329925537
Validation loss: 1.9558973568741993

Epoch: 6| Step: 10
Training loss: 2.3279855251312256
Validation loss: 1.958061905317409

Epoch: 6| Step: 11
Training loss: 2.079434633255005
Validation loss: 1.9585813155738256

Epoch: 6| Step: 12
Training loss: 1.715524435043335
Validation loss: 1.9260511564952072

Epoch: 6| Step: 13
Training loss: 1.3928831815719604
Validation loss: 1.920819551714005

Epoch: 201| Step: 0
Training loss: 1.8862642049789429
Validation loss: 1.9265801470766786

Epoch: 6| Step: 1
Training loss: 2.309567451477051
Validation loss: 1.9300870126293552

Epoch: 6| Step: 2
Training loss: 2.0268383026123047
Validation loss: 1.947284035785224

Epoch: 6| Step: 3
Training loss: 1.3209823369979858
Validation loss: 1.9363204509981218

Epoch: 6| Step: 4
Training loss: 1.2713514566421509
Validation loss: 1.9198852328843967

Epoch: 6| Step: 5
Training loss: 2.285478353500366
Validation loss: 1.928005753024932

Epoch: 6| Step: 6
Training loss: 1.7015337944030762
Validation loss: 1.9664188431155296

Epoch: 6| Step: 7
Training loss: 1.5174479484558105
Validation loss: 2.0289871705475675

Epoch: 6| Step: 8
Training loss: 1.592206358909607
Validation loss: 2.0653760048650924

Epoch: 6| Step: 9
Training loss: 2.594203233718872
Validation loss: 2.0555202307239657

Epoch: 6| Step: 10
Training loss: 1.1463215351104736
Validation loss: 2.0170911076248332

Epoch: 6| Step: 11
Training loss: 2.2879385948181152
Validation loss: 2.0020828580343597

Epoch: 6| Step: 12
Training loss: 1.1781871318817139
Validation loss: 1.972137717790501

Epoch: 6| Step: 13
Training loss: 2.03401517868042
Validation loss: 1.978181577497913

Epoch: 202| Step: 0
Training loss: 1.910165548324585
Validation loss: 1.9848863617066415

Epoch: 6| Step: 1
Training loss: 2.0072412490844727
Validation loss: 1.9814731280008953

Epoch: 6| Step: 2
Training loss: 1.1857666969299316
Validation loss: 1.984955192894064

Epoch: 6| Step: 3
Training loss: 1.7929840087890625
Validation loss: 2.0219168470751856

Epoch: 6| Step: 4
Training loss: 1.8486738204956055
Validation loss: 1.9876351997416506

Epoch: 6| Step: 5
Training loss: 2.0679612159729004
Validation loss: 2.0584273312681463

Epoch: 6| Step: 6
Training loss: 2.3583600521087646
Validation loss: 2.048875390842397

Epoch: 6| Step: 7
Training loss: 1.7829017639160156
Validation loss: 2.0600781440734863

Epoch: 6| Step: 8
Training loss: 1.366820216178894
Validation loss: 2.031810459270272

Epoch: 6| Step: 9
Training loss: 1.785294771194458
Validation loss: 2.0086891612698956

Epoch: 6| Step: 10
Training loss: 1.0815446376800537
Validation loss: 1.957715037048504

Epoch: 6| Step: 11
Training loss: 1.522532343864441
Validation loss: 1.9204383204060216

Epoch: 6| Step: 12
Training loss: 2.224619150161743
Validation loss: 1.9214229224830546

Epoch: 6| Step: 13
Training loss: 1.5644166469573975
Validation loss: 1.9197088749177995

Epoch: 203| Step: 0
Training loss: 1.970165729522705
Validation loss: 1.934406001080749

Epoch: 6| Step: 1
Training loss: 1.3357748985290527
Validation loss: 1.9520047890242709

Epoch: 6| Step: 2
Training loss: 1.7049612998962402
Validation loss: 1.955780634316065

Epoch: 6| Step: 3
Training loss: 2.2384328842163086
Validation loss: 1.9823508672816779

Epoch: 6| Step: 4
Training loss: 2.061429738998413
Validation loss: 1.9868484107396935

Epoch: 6| Step: 5
Training loss: 1.905898928642273
Validation loss: 1.974295723822809

Epoch: 6| Step: 6
Training loss: 1.409091830253601
Validation loss: 1.9992279788499236

Epoch: 6| Step: 7
Training loss: 1.4879201650619507
Validation loss: 2.006348120268955

Epoch: 6| Step: 8
Training loss: 1.7571063041687012
Validation loss: 1.9758885496406144

Epoch: 6| Step: 9
Training loss: 1.828920841217041
Validation loss: 2.0037084266703618

Epoch: 6| Step: 10
Training loss: 2.0609705448150635
Validation loss: 2.012729001301591

Epoch: 6| Step: 11
Training loss: 1.3674298524856567
Validation loss: 2.0441183428610525

Epoch: 6| Step: 12
Training loss: 1.4663586616516113
Validation loss: 2.038926648837264

Epoch: 6| Step: 13
Training loss: 1.0795320272445679
Validation loss: 2.014748973231162

Epoch: 204| Step: 0
Training loss: 2.33616304397583
Validation loss: 2.014552107421301

Epoch: 6| Step: 1
Training loss: 1.9735612869262695
Validation loss: 2.0351047092868435

Epoch: 6| Step: 2
Training loss: 1.6010926961898804
Validation loss: 2.002569539572603

Epoch: 6| Step: 3
Training loss: 2.084567070007324
Validation loss: 1.9811141939573391

Epoch: 6| Step: 4
Training loss: 1.7112765312194824
Validation loss: 1.9702030740758425

Epoch: 6| Step: 5
Training loss: 1.2140161991119385
Validation loss: 1.9426420901411323

Epoch: 6| Step: 6
Training loss: 1.7672607898712158
Validation loss: 1.9441473586584932

Epoch: 6| Step: 7
Training loss: 1.4165077209472656
Validation loss: 1.9649479594281924

Epoch: 6| Step: 8
Training loss: 1.4071967601776123
Validation loss: 1.9780202270835958

Epoch: 6| Step: 9
Training loss: 1.5009926557540894
Validation loss: 1.9937971407367336

Epoch: 6| Step: 10
Training loss: 1.683260440826416
Validation loss: 2.016447974789527

Epoch: 6| Step: 11
Training loss: 1.8958038091659546
Validation loss: 2.0423214409940984

Epoch: 6| Step: 12
Training loss: 1.562110185623169
Validation loss: 2.006298276685899

Epoch: 6| Step: 13
Training loss: 1.7818154096603394
Validation loss: 1.9840866750286472

Epoch: 205| Step: 0
Training loss: 1.840211033821106
Validation loss: 1.9615214819549232

Epoch: 6| Step: 1
Training loss: 2.5096664428710938
Validation loss: 1.9373228703775713

Epoch: 6| Step: 2
Training loss: 2.032599925994873
Validation loss: 1.9106144071907125

Epoch: 6| Step: 3
Training loss: 1.9427367448806763
Validation loss: 1.9205894406123827

Epoch: 6| Step: 4
Training loss: 0.7991518974304199
Validation loss: 1.931389331817627

Epoch: 6| Step: 5
Training loss: 1.3821699619293213
Validation loss: 1.9646449768415062

Epoch: 6| Step: 6
Training loss: 1.3741729259490967
Validation loss: 2.0253042226196616

Epoch: 6| Step: 7
Training loss: 1.3441333770751953
Validation loss: 2.082603262316796

Epoch: 6| Step: 8
Training loss: 2.8609700202941895
Validation loss: 2.149705366421771

Epoch: 6| Step: 9
Training loss: 2.3763861656188965
Validation loss: 2.093958339383525

Epoch: 6| Step: 10
Training loss: 1.4103161096572876
Validation loss: 2.0436392881536998

Epoch: 6| Step: 11
Training loss: 1.049393653869629
Validation loss: 2.0143107803918983

Epoch: 6| Step: 12
Training loss: 1.869773030281067
Validation loss: 1.972681741560659

Epoch: 6| Step: 13
Training loss: 1.79037606716156
Validation loss: 1.9447480004320863

Epoch: 206| Step: 0
Training loss: 1.4382381439208984
Validation loss: 1.9451378404453237

Epoch: 6| Step: 1
Training loss: 2.4717178344726562
Validation loss: 1.9335885535004318

Epoch: 6| Step: 2
Training loss: 1.186004638671875
Validation loss: 1.9036789530067033

Epoch: 6| Step: 3
Training loss: 1.960869550704956
Validation loss: 1.8924834189876434

Epoch: 6| Step: 4
Training loss: 1.1112011671066284
Validation loss: 1.899996692134488

Epoch: 6| Step: 5
Training loss: 1.4516515731811523
Validation loss: 1.9239573427425918

Epoch: 6| Step: 6
Training loss: 1.8396286964416504
Validation loss: 1.9231934778151973

Epoch: 6| Step: 7
Training loss: 1.3973253965377808
Validation loss: 1.948322549943001

Epoch: 6| Step: 8
Training loss: 2.8250343799591064
Validation loss: 1.965682796252671

Epoch: 6| Step: 9
Training loss: 1.8131407499313354
Validation loss: 2.007619778315226

Epoch: 6| Step: 10
Training loss: 1.66384756565094
Validation loss: 2.0687805273199595

Epoch: 6| Step: 11
Training loss: 2.447805404663086
Validation loss: 2.0857943027250228

Epoch: 6| Step: 12
Training loss: 1.6683673858642578
Validation loss: 1.9974096180290304

Epoch: 6| Step: 13
Training loss: 1.271880030632019
Validation loss: 1.9334099715755833

Epoch: 207| Step: 0
Training loss: 1.1836822032928467
Validation loss: 1.910024445544007

Epoch: 6| Step: 1
Training loss: 1.4336739778518677
Validation loss: 1.9160735440510575

Epoch: 6| Step: 2
Training loss: 1.4675037860870361
Validation loss: 1.9249829746061755

Epoch: 6| Step: 3
Training loss: 2.5388050079345703
Validation loss: 1.9475563290298625

Epoch: 6| Step: 4
Training loss: 1.4808982610702515
Validation loss: 1.9474495969792849

Epoch: 6| Step: 5
Training loss: 1.5877771377563477
Validation loss: 2.009678938055551

Epoch: 6| Step: 6
Training loss: 1.6520782709121704
Validation loss: 2.0111311430572183

Epoch: 6| Step: 7
Training loss: 1.7935311794281006
Validation loss: 2.060218213706888

Epoch: 6| Step: 8
Training loss: 1.7888579368591309
Validation loss: 2.096872075911491

Epoch: 6| Step: 9
Training loss: 2.1869473457336426
Validation loss: 2.0501770691205095

Epoch: 6| Step: 10
Training loss: 1.971897006034851
Validation loss: 2.015743524797501

Epoch: 6| Step: 11
Training loss: 1.8087341785430908
Validation loss: 2.005560500647432

Epoch: 6| Step: 12
Training loss: 1.5949455499649048
Validation loss: 1.96885770879766

Epoch: 6| Step: 13
Training loss: 1.8547261953353882
Validation loss: 1.9526844281022266

Epoch: 208| Step: 0
Training loss: 1.9038608074188232
Validation loss: 1.9267419281826224

Epoch: 6| Step: 1
Training loss: 2.115901470184326
Validation loss: 1.9107746155031267

Epoch: 6| Step: 2
Training loss: 1.5369536876678467
Validation loss: 1.9089071237912743

Epoch: 6| Step: 3
Training loss: 2.1918585300445557
Validation loss: 1.939745496678096

Epoch: 6| Step: 4
Training loss: 1.5349873304367065
Validation loss: 1.9959945217255624

Epoch: 6| Step: 5
Training loss: 1.524855136871338
Validation loss: 2.0001080459164036

Epoch: 6| Step: 6
Training loss: 1.2438695430755615
Validation loss: 1.994650899723012

Epoch: 6| Step: 7
Training loss: 1.946460485458374
Validation loss: 1.9705178506912724

Epoch: 6| Step: 8
Training loss: 1.753549337387085
Validation loss: 1.9385513285154938

Epoch: 6| Step: 9
Training loss: 2.1238176822662354
Validation loss: 1.9103850908176874

Epoch: 6| Step: 10
Training loss: 1.6444683074951172
Validation loss: 1.9052570519908782

Epoch: 6| Step: 11
Training loss: 1.5757070779800415
Validation loss: 1.9397180836687806

Epoch: 6| Step: 12
Training loss: 0.9749835729598999
Validation loss: 1.947260069590743

Epoch: 6| Step: 13
Training loss: 1.431818962097168
Validation loss: 1.9631527482822377

Epoch: 209| Step: 0
Training loss: 2.268004894256592
Validation loss: 2.006558887420162

Epoch: 6| Step: 1
Training loss: 2.1342930793762207
Validation loss: 2.0028680139972317

Epoch: 6| Step: 2
Training loss: 0.69017493724823
Validation loss: 1.9631859564012097

Epoch: 6| Step: 3
Training loss: 1.7330834865570068
Validation loss: 1.9558129618244786

Epoch: 6| Step: 4
Training loss: 0.8972749710083008
Validation loss: 1.9537793692722116

Epoch: 6| Step: 5
Training loss: 1.7043346166610718
Validation loss: 1.9392262107582503

Epoch: 6| Step: 6
Training loss: 2.184122085571289
Validation loss: 1.9297326303297473

Epoch: 6| Step: 7
Training loss: 1.6211180686950684
Validation loss: 1.9144466077127764

Epoch: 6| Step: 8
Training loss: 1.6349529027938843
Validation loss: 1.8885424624207199

Epoch: 6| Step: 9
Training loss: 1.3849949836730957
Validation loss: 1.9200502557139243

Epoch: 6| Step: 10
Training loss: 1.3052184581756592
Validation loss: 1.9141222071904007

Epoch: 6| Step: 11
Training loss: 1.9356427192687988
Validation loss: 1.9351564556039789

Epoch: 6| Step: 12
Training loss: 1.764585256576538
Validation loss: 1.9519867256123533

Epoch: 6| Step: 13
Training loss: 1.647472620010376
Validation loss: 2.041638153855519

Epoch: 210| Step: 0
Training loss: 1.1444677114486694
Validation loss: 2.069907513997888

Epoch: 6| Step: 1
Training loss: 2.54634952545166
Validation loss: 2.052933108422064

Epoch: 6| Step: 2
Training loss: 1.9945435523986816
Validation loss: 2.012614876993241

Epoch: 6| Step: 3
Training loss: 1.4804856777191162
Validation loss: 1.956623145329055

Epoch: 6| Step: 4
Training loss: 1.239854097366333
Validation loss: 1.9491788174516411

Epoch: 6| Step: 5
Training loss: 1.323547601699829
Validation loss: 1.947561619102314

Epoch: 6| Step: 6
Training loss: 1.4503767490386963
Validation loss: 1.9207236202814246

Epoch: 6| Step: 7
Training loss: 1.4097706079483032
Validation loss: 1.9083113311439432

Epoch: 6| Step: 8
Training loss: 2.463408946990967
Validation loss: 1.9049692333385508

Epoch: 6| Step: 9
Training loss: 1.8549010753631592
Validation loss: 1.8835833354662823

Epoch: 6| Step: 10
Training loss: 2.167276382446289
Validation loss: 1.9162093465046217

Epoch: 6| Step: 11
Training loss: 1.348476529121399
Validation loss: 1.9236523182161394

Epoch: 6| Step: 12
Training loss: 1.320446491241455
Validation loss: 1.985649734415034

Epoch: 6| Step: 13
Training loss: 1.2661141157150269
Validation loss: 2.0674690610619

Epoch: 211| Step: 0
Training loss: 1.259406328201294
Validation loss: 2.0957652189398326

Epoch: 6| Step: 1
Training loss: 1.9225876331329346
Validation loss: 2.1167918097588325

Epoch: 6| Step: 2
Training loss: 1.8799140453338623
Validation loss: 2.0500462452570596

Epoch: 6| Step: 3
Training loss: 1.8507986068725586
Validation loss: 1.9925736329888786

Epoch: 6| Step: 4
Training loss: 2.0287537574768066
Validation loss: 1.9668995641892957

Epoch: 6| Step: 5
Training loss: 1.2461243867874146
Validation loss: 1.970367326531359

Epoch: 6| Step: 6
Training loss: 1.7226903438568115
Validation loss: 1.9654912038515973

Epoch: 6| Step: 7
Training loss: 1.9900270700454712
Validation loss: 1.9928933587125552

Epoch: 6| Step: 8
Training loss: 1.8959170579910278
Validation loss: 1.994326332563995

Epoch: 6| Step: 9
Training loss: 1.2442421913146973
Validation loss: 1.965440703976539

Epoch: 6| Step: 10
Training loss: 1.568187952041626
Validation loss: 1.9562312556851296

Epoch: 6| Step: 11
Training loss: 2.0627365112304688
Validation loss: 1.9579590802551599

Epoch: 6| Step: 12
Training loss: 1.7963757514953613
Validation loss: 1.9636050731905046

Epoch: 6| Step: 13
Training loss: 1.4878038167953491
Validation loss: 2.0086067773962535

Epoch: 212| Step: 0
Training loss: 1.493586778640747
Validation loss: 2.0630741119384766

Epoch: 6| Step: 1
Training loss: 2.05354642868042
Validation loss: 2.0546868475534583

Epoch: 6| Step: 2
Training loss: 1.273716688156128
Validation loss: 2.058541282530754

Epoch: 6| Step: 3
Training loss: 1.8318040370941162
Validation loss: 2.0027905715409147

Epoch: 6| Step: 4
Training loss: 1.1761966943740845
Validation loss: 1.97117599620614

Epoch: 6| Step: 5
Training loss: 0.846000611782074
Validation loss: 1.9695853597374373

Epoch: 6| Step: 6
Training loss: 1.8933287858963013
Validation loss: 1.963621489463314

Epoch: 6| Step: 7
Training loss: 2.1621334552764893
Validation loss: 1.9504543504407328

Epoch: 6| Step: 8
Training loss: 1.4790313243865967
Validation loss: 1.9728248132172452

Epoch: 6| Step: 9
Training loss: 1.2622010707855225
Validation loss: 1.9887491926070182

Epoch: 6| Step: 10
Training loss: 1.7715349197387695
Validation loss: 2.0452450116475425

Epoch: 6| Step: 11
Training loss: 2.016960620880127
Validation loss: 2.0982138751655497

Epoch: 6| Step: 12
Training loss: 2.2230653762817383
Validation loss: 2.1570405434536677

Epoch: 6| Step: 13
Training loss: 2.1096887588500977
Validation loss: 2.1107302481128323

Epoch: 213| Step: 0
Training loss: 1.2886251211166382
Validation loss: 2.0488265381064465

Epoch: 6| Step: 1
Training loss: 1.9277193546295166
Validation loss: 1.9858245080517185

Epoch: 6| Step: 2
Training loss: 1.5338597297668457
Validation loss: 1.969047636114141

Epoch: 6| Step: 3
Training loss: 1.145794153213501
Validation loss: 1.9794381485190442

Epoch: 6| Step: 4
Training loss: 1.8746174573898315
Validation loss: 2.0239828325087026

Epoch: 6| Step: 5
Training loss: 1.8349826335906982
Validation loss: 2.0364350695763864

Epoch: 6| Step: 6
Training loss: 2.0064048767089844
Validation loss: 2.0631616628298195

Epoch: 6| Step: 7
Training loss: 1.648975133895874
Validation loss: 2.082322479576193

Epoch: 6| Step: 8
Training loss: 1.5751383304595947
Validation loss: 2.1218031350002495

Epoch: 6| Step: 9
Training loss: 1.8575246334075928
Validation loss: 2.0844251212253364

Epoch: 6| Step: 10
Training loss: 0.9757997393608093
Validation loss: 2.060242035055673

Epoch: 6| Step: 11
Training loss: 2.2229537963867188
Validation loss: 2.008459488550822

Epoch: 6| Step: 12
Training loss: 1.806396484375
Validation loss: 1.968680226674644

Epoch: 6| Step: 13
Training loss: 1.6658128499984741
Validation loss: 1.9234438429596603

Epoch: 214| Step: 0
Training loss: 1.8874446153640747
Validation loss: 1.8861316839853923

Epoch: 6| Step: 1
Training loss: 1.2709403038024902
Validation loss: 1.8792590197696482

Epoch: 6| Step: 2
Training loss: 1.6599435806274414
Validation loss: 1.8782949178449568

Epoch: 6| Step: 3
Training loss: 1.8242992162704468
Validation loss: 1.8762110766544138

Epoch: 6| Step: 4
Training loss: 1.1197590827941895
Validation loss: 1.8655478428768855

Epoch: 6| Step: 5
Training loss: 2.607372522354126
Validation loss: 1.926981226090462

Epoch: 6| Step: 6
Training loss: 1.8663251399993896
Validation loss: 1.9608009733179563

Epoch: 6| Step: 7
Training loss: 1.6535637378692627
Validation loss: 1.9591253765167729

Epoch: 6| Step: 8
Training loss: 1.3823232650756836
Validation loss: 1.9534770263138639

Epoch: 6| Step: 9
Training loss: 1.8568358421325684
Validation loss: 1.9292520707653416

Epoch: 6| Step: 10
Training loss: 1.6645629405975342
Validation loss: 1.9186995516541183

Epoch: 6| Step: 11
Training loss: 1.5765877962112427
Validation loss: 1.9133827532491376

Epoch: 6| Step: 12
Training loss: 1.6699283123016357
Validation loss: 1.9415379519103675

Epoch: 6| Step: 13
Training loss: 0.9268616437911987
Validation loss: 1.978968738227762

Epoch: 215| Step: 0
Training loss: 1.3993666172027588
Validation loss: 1.9953165925959104

Epoch: 6| Step: 1
Training loss: 2.1411375999450684
Validation loss: 2.018023047395932

Epoch: 6| Step: 2
Training loss: 1.7610820531845093
Validation loss: 2.065225475577898

Epoch: 6| Step: 3
Training loss: 1.844313144683838
Validation loss: 2.0763248448730796

Epoch: 6| Step: 4
Training loss: 2.4043636322021484
Validation loss: 2.082755720743569

Epoch: 6| Step: 5
Training loss: 1.9318838119506836
Validation loss: 2.084588405906513

Epoch: 6| Step: 6
Training loss: 2.038898229598999
Validation loss: 2.0501362444252096

Epoch: 6| Step: 7
Training loss: 1.361762523651123
Validation loss: 2.0086409084258543

Epoch: 6| Step: 8
Training loss: 1.6186096668243408
Validation loss: 1.9928940291045814

Epoch: 6| Step: 9
Training loss: 1.598480224609375
Validation loss: 1.946986077934183

Epoch: 6| Step: 10
Training loss: 0.9321040511131287
Validation loss: 1.92740802098346

Epoch: 6| Step: 11
Training loss: 0.8309873342514038
Validation loss: 1.936942426107263

Epoch: 6| Step: 12
Training loss: 1.0301839113235474
Validation loss: 1.9686493642868534

Epoch: 6| Step: 13
Training loss: 2.336432695388794
Validation loss: 2.002774046313378

Epoch: 216| Step: 0
Training loss: 1.4670724868774414
Validation loss: 2.0082933825831257

Epoch: 6| Step: 1
Training loss: 1.68850839138031
Validation loss: 2.032326691894121

Epoch: 6| Step: 2
Training loss: 2.098707675933838
Validation loss: 2.021796585411154

Epoch: 6| Step: 3
Training loss: 1.6345219612121582
Validation loss: 2.019238797567224

Epoch: 6| Step: 4
Training loss: 1.0144126415252686
Validation loss: 1.9909462544225878

Epoch: 6| Step: 5
Training loss: 1.3010809421539307
Validation loss: 1.9867108419377317

Epoch: 6| Step: 6
Training loss: 1.3883439302444458
Validation loss: 1.9666267364255843

Epoch: 6| Step: 7
Training loss: 2.025186777114868
Validation loss: 1.956297005376508

Epoch: 6| Step: 8
Training loss: 1.3602008819580078
Validation loss: 1.9625370989563644

Epoch: 6| Step: 9
Training loss: 1.4340956211090088
Validation loss: 1.9764504624951271

Epoch: 6| Step: 10
Training loss: 1.5283660888671875
Validation loss: 2.002884026496641

Epoch: 6| Step: 11
Training loss: 1.2545719146728516
Validation loss: 2.002186640616386

Epoch: 6| Step: 12
Training loss: 1.9025909900665283
Validation loss: 2.032254253664324

Epoch: 6| Step: 13
Training loss: 1.5265100002288818
Validation loss: 2.00889935288378

Epoch: 217| Step: 0
Training loss: 1.4850258827209473
Validation loss: 1.9920149413488244

Epoch: 6| Step: 1
Training loss: 1.3978315591812134
Validation loss: 1.9807332984862789

Epoch: 6| Step: 2
Training loss: 1.4201500415802002
Validation loss: 1.9476447438680997

Epoch: 6| Step: 3
Training loss: 1.4406218528747559
Validation loss: 1.9359020494645642

Epoch: 6| Step: 4
Training loss: 1.3763577938079834
Validation loss: 1.9128810154494418

Epoch: 6| Step: 5
Training loss: 1.6883432865142822
Validation loss: 1.9094177702421784

Epoch: 6| Step: 6
Training loss: 1.7249438762664795
Validation loss: 1.9336426078632314

Epoch: 6| Step: 7
Training loss: 1.4394288063049316
Validation loss: 1.9605842969750846

Epoch: 6| Step: 8
Training loss: 1.5837297439575195
Validation loss: 2.0607823684651363

Epoch: 6| Step: 9
Training loss: 1.738802194595337
Validation loss: 2.138604712742631

Epoch: 6| Step: 10
Training loss: 2.036348342895508
Validation loss: 2.1559497515360513

Epoch: 6| Step: 11
Training loss: 1.9926981925964355
Validation loss: 2.0936222640416955

Epoch: 6| Step: 12
Training loss: 1.4868574142456055
Validation loss: 1.964004716565532

Epoch: 6| Step: 13
Training loss: 1.223345160484314
Validation loss: 1.891881372338982

Epoch: 218| Step: 0
Training loss: 1.398883581161499
Validation loss: 1.8732008613565916

Epoch: 6| Step: 1
Training loss: 1.8598318099975586
Validation loss: 1.8922865288231963

Epoch: 6| Step: 2
Training loss: 2.361128568649292
Validation loss: 1.9086125550731536

Epoch: 6| Step: 3
Training loss: 1.9047086238861084
Validation loss: 1.887208064397176

Epoch: 6| Step: 4
Training loss: 1.9050947427749634
Validation loss: 1.8849389014705535

Epoch: 6| Step: 5
Training loss: 1.999279260635376
Validation loss: 1.9621392116751721

Epoch: 6| Step: 6
Training loss: 1.272376537322998
Validation loss: 2.082559998317431

Epoch: 6| Step: 7
Training loss: 2.221971035003662
Validation loss: 2.1353382115722983

Epoch: 6| Step: 8
Training loss: 1.0162581205368042
Validation loss: 2.098413513552758

Epoch: 6| Step: 9
Training loss: 2.113471508026123
Validation loss: 2.0128153242090696

Epoch: 6| Step: 10
Training loss: 1.4406862258911133
Validation loss: 1.9050878017179427

Epoch: 6| Step: 11
Training loss: 1.38014817237854
Validation loss: 1.8859953623945995

Epoch: 6| Step: 12
Training loss: 1.464754581451416
Validation loss: 1.929619227686236

Epoch: 6| Step: 13
Training loss: 0.5746454000473022
Validation loss: 1.9779087984433739

Epoch: 219| Step: 0
Training loss: 0.9937459230422974
Validation loss: 2.010617652247029

Epoch: 6| Step: 1
Training loss: 1.2943284511566162
Validation loss: 2.0302643263211815

Epoch: 6| Step: 2
Training loss: 1.4619851112365723
Validation loss: 2.040741353906611

Epoch: 6| Step: 3
Training loss: 1.8023954629898071
Validation loss: 2.038928565158639

Epoch: 6| Step: 4
Training loss: 1.4967923164367676
Validation loss: 2.0264769472101682

Epoch: 6| Step: 5
Training loss: 1.8013863563537598
Validation loss: 2.012570542673911

Epoch: 6| Step: 6
Training loss: 1.2471895217895508
Validation loss: 1.9717060622348581

Epoch: 6| Step: 7
Training loss: 1.479980230331421
Validation loss: 1.9364793915902414

Epoch: 6| Step: 8
Training loss: 1.8601562976837158
Validation loss: 1.944412471145712

Epoch: 6| Step: 9
Training loss: 1.7299823760986328
Validation loss: 1.9404181844444686

Epoch: 6| Step: 10
Training loss: 1.506047010421753
Validation loss: 1.912268732183723

Epoch: 6| Step: 11
Training loss: 1.7761011123657227
Validation loss: 1.939797180955128

Epoch: 6| Step: 12
Training loss: 1.7996551990509033
Validation loss: 1.9645811344987603

Epoch: 6| Step: 13
Training loss: 1.4338164329528809
Validation loss: 2.004052180115895

Epoch: 220| Step: 0
Training loss: 1.255247712135315
Validation loss: 2.079171380689067

Epoch: 6| Step: 1
Training loss: 2.0549988746643066
Validation loss: 2.153385482808595

Epoch: 6| Step: 2
Training loss: 1.6118640899658203
Validation loss: 2.1402848638514036

Epoch: 6| Step: 3
Training loss: 1.6817741394042969
Validation loss: 2.0701314710801646

Epoch: 6| Step: 4
Training loss: 1.5857007503509521
Validation loss: 1.9955110088471444

Epoch: 6| Step: 5
Training loss: 1.070130467414856
Validation loss: 1.9673196897711804

Epoch: 6| Step: 6
Training loss: 1.2012205123901367
Validation loss: 1.9528463066265147

Epoch: 6| Step: 7
Training loss: 2.326712131500244
Validation loss: 1.9467846347439675

Epoch: 6| Step: 8
Training loss: 2.0267984867095947
Validation loss: 1.9592405775541901

Epoch: 6| Step: 9
Training loss: 1.98012113571167
Validation loss: 1.9846816191109278

Epoch: 6| Step: 10
Training loss: 1.5751594305038452
Validation loss: 2.0002359933750604

Epoch: 6| Step: 11
Training loss: 1.063499093055725
Validation loss: 1.982824061506538

Epoch: 6| Step: 12
Training loss: 1.4424877166748047
Validation loss: 1.9496333381181121

Epoch: 6| Step: 13
Training loss: 1.4310311079025269
Validation loss: 1.9404199225928194

Epoch: 221| Step: 0
Training loss: 1.1788115501403809
Validation loss: 1.8959218084171254

Epoch: 6| Step: 1
Training loss: 1.3362491130828857
Validation loss: 1.8821173765326058

Epoch: 6| Step: 2
Training loss: 2.0377657413482666
Validation loss: 1.8700916203119422

Epoch: 6| Step: 3
Training loss: 1.4534828662872314
Validation loss: 1.858737971193047

Epoch: 6| Step: 4
Training loss: 1.8133312463760376
Validation loss: 1.8849501250892557

Epoch: 6| Step: 5
Training loss: 1.2935621738433838
Validation loss: 1.8811116333930724

Epoch: 6| Step: 6
Training loss: 1.3424530029296875
Validation loss: 1.8903149058741908

Epoch: 6| Step: 7
Training loss: 1.1633737087249756
Validation loss: 1.9121267564835087

Epoch: 6| Step: 8
Training loss: 1.587601900100708
Validation loss: 1.9763038799326906

Epoch: 6| Step: 9
Training loss: 1.732069730758667
Validation loss: 1.9762311443205802

Epoch: 6| Step: 10
Training loss: 1.8481475114822388
Validation loss: 1.958780809115338

Epoch: 6| Step: 11
Training loss: 1.4830416440963745
Validation loss: 1.9612147436347058

Epoch: 6| Step: 12
Training loss: 1.2871036529541016
Validation loss: 1.9554283016471452

Epoch: 6| Step: 13
Training loss: 1.5727477073669434
Validation loss: 1.9403412495889971

Epoch: 222| Step: 0
Training loss: 1.4505298137664795
Validation loss: 1.961106861791303

Epoch: 6| Step: 1
Training loss: 0.9771756529808044
Validation loss: 1.9767498880304315

Epoch: 6| Step: 2
Training loss: 1.1668024063110352
Validation loss: 2.011874334786528

Epoch: 6| Step: 3
Training loss: 1.767679214477539
Validation loss: 1.9859237747807656

Epoch: 6| Step: 4
Training loss: 1.7058079242706299
Validation loss: 1.975200339030194

Epoch: 6| Step: 5
Training loss: 1.0928421020507812
Validation loss: 1.9395271770415767

Epoch: 6| Step: 6
Training loss: 1.5918169021606445
Validation loss: 1.9386431555594168

Epoch: 6| Step: 7
Training loss: 1.6620914936065674
Validation loss: 1.9370618161334787

Epoch: 6| Step: 8
Training loss: 2.426889181137085
Validation loss: 1.9455732196889899

Epoch: 6| Step: 9
Training loss: 0.7632781267166138
Validation loss: 1.9462269403601204

Epoch: 6| Step: 10
Training loss: 1.8067671060562134
Validation loss: 1.9519755994119952

Epoch: 6| Step: 11
Training loss: 1.6607611179351807
Validation loss: 1.9386561634720012

Epoch: 6| Step: 12
Training loss: 1.4811028242111206
Validation loss: 1.945527522794662

Epoch: 6| Step: 13
Training loss: 1.631539225578308
Validation loss: 1.9631033828181605

Epoch: 223| Step: 0
Training loss: 1.3425778150558472
Validation loss: 1.9651579946599982

Epoch: 6| Step: 1
Training loss: 0.8072556853294373
Validation loss: 1.975941409346878

Epoch: 6| Step: 2
Training loss: 1.4147127866744995
Validation loss: 2.0134568137507283

Epoch: 6| Step: 3
Training loss: 1.6043142080307007
Validation loss: 2.0333367342590005

Epoch: 6| Step: 4
Training loss: 1.6565014123916626
Validation loss: 2.0401134503785

Epoch: 6| Step: 5
Training loss: 1.2317454814910889
Validation loss: 2.0226679924995667

Epoch: 6| Step: 6
Training loss: 1.5993647575378418
Validation loss: 2.0334204089257026

Epoch: 6| Step: 7
Training loss: 1.5844027996063232
Validation loss: 2.014148450666858

Epoch: 6| Step: 8
Training loss: 1.5170767307281494
Validation loss: 2.0148659342078754

Epoch: 6| Step: 9
Training loss: 2.1875815391540527
Validation loss: 2.0351331772342807

Epoch: 6| Step: 10
Training loss: 1.7795383930206299
Validation loss: 2.0462077817609234

Epoch: 6| Step: 11
Training loss: 1.420851230621338
Validation loss: 2.0121939233554307

Epoch: 6| Step: 12
Training loss: 0.9039708375930786
Validation loss: 1.9756965906389299

Epoch: 6| Step: 13
Training loss: 1.71504545211792
Validation loss: 1.9618618244765906

Epoch: 224| Step: 0
Training loss: 1.2706468105316162
Validation loss: 1.9454009635474092

Epoch: 6| Step: 1
Training loss: 1.2325891256332397
Validation loss: 1.9250480641600907

Epoch: 6| Step: 2
Training loss: 1.5156623125076294
Validation loss: 1.9484921040073517

Epoch: 6| Step: 3
Training loss: 1.4925730228424072
Validation loss: 1.9591381306289344

Epoch: 6| Step: 4
Training loss: 1.972360610961914
Validation loss: 1.9645925439814085

Epoch: 6| Step: 5
Training loss: 0.5595370531082153
Validation loss: 1.9292477997400428

Epoch: 6| Step: 6
Training loss: 1.7274982929229736
Validation loss: 1.9074654117707284

Epoch: 6| Step: 7
Training loss: 1.381946086883545
Validation loss: 1.9061925077951083

Epoch: 6| Step: 8
Training loss: 1.6779792308807373
Validation loss: 1.8906770175503147

Epoch: 6| Step: 9
Training loss: 1.7175877094268799
Validation loss: 1.911450711629724

Epoch: 6| Step: 10
Training loss: 1.5058491230010986
Validation loss: 1.898832969768073

Epoch: 6| Step: 11
Training loss: 1.8387742042541504
Validation loss: 1.9091253460094493

Epoch: 6| Step: 12
Training loss: 0.9835659861564636
Validation loss: 1.9238690253226989

Epoch: 6| Step: 13
Training loss: 1.1788465976715088
Validation loss: 1.9213769692246632

Epoch: 225| Step: 0
Training loss: 1.1241934299468994
Validation loss: 1.9454282535019742

Epoch: 6| Step: 1
Training loss: 1.0947344303131104
Validation loss: 1.9829754060314548

Epoch: 6| Step: 2
Training loss: 1.1092309951782227
Validation loss: 1.9934449400953067

Epoch: 6| Step: 3
Training loss: 1.3711438179016113
Validation loss: 1.964008371035258

Epoch: 6| Step: 4
Training loss: 1.389432430267334
Validation loss: 1.9390006065368652

Epoch: 6| Step: 5
Training loss: 1.4899988174438477
Validation loss: 1.9297471225902598

Epoch: 6| Step: 6
Training loss: 1.7382667064666748
Validation loss: 1.8898832772367744

Epoch: 6| Step: 7
Training loss: 1.5887470245361328
Validation loss: 1.877784521989925

Epoch: 6| Step: 8
Training loss: 1.8621689081192017
Validation loss: 1.8765555556102465

Epoch: 6| Step: 9
Training loss: 1.2314202785491943
Validation loss: 1.8770245736645115

Epoch: 6| Step: 10
Training loss: 1.286371111869812
Validation loss: 1.8430044420303837

Epoch: 6| Step: 11
Training loss: 1.5050172805786133
Validation loss: 1.8682671131626252

Epoch: 6| Step: 12
Training loss: 1.239986777305603
Validation loss: 1.8805706949644192

Epoch: 6| Step: 13
Training loss: 1.9779376983642578
Validation loss: 1.915044907600649

Epoch: 226| Step: 0
Training loss: 1.3696577548980713
Validation loss: 1.9164065545605076

Epoch: 6| Step: 1
Training loss: 1.891601800918579
Validation loss: 1.893787617324501

Epoch: 6| Step: 2
Training loss: 1.6000304222106934
Validation loss: 1.9580692860387987

Epoch: 6| Step: 3
Training loss: 1.0843238830566406
Validation loss: 1.9829410186377905

Epoch: 6| Step: 4
Training loss: 1.562389612197876
Validation loss: 1.98829996714028

Epoch: 6| Step: 5
Training loss: 1.4915499687194824
Validation loss: 1.9960905236582602

Epoch: 6| Step: 6
Training loss: 1.2159236669540405
Validation loss: 1.9635935444985666

Epoch: 6| Step: 7
Training loss: 0.9468744993209839
Validation loss: 1.9488574945798485

Epoch: 6| Step: 8
Training loss: 1.411377191543579
Validation loss: 1.9241817356437765

Epoch: 6| Step: 9
Training loss: 1.4832476377487183
Validation loss: 1.9343257745107014

Epoch: 6| Step: 10
Training loss: 1.4038766622543335
Validation loss: 1.9269416178426435

Epoch: 6| Step: 11
Training loss: 1.1777148246765137
Validation loss: 1.9157060269386537

Epoch: 6| Step: 12
Training loss: 1.725327730178833
Validation loss: 1.9309177501227266

Epoch: 6| Step: 13
Training loss: 0.84059739112854
Validation loss: 1.936089143958143

Epoch: 227| Step: 0
Training loss: 1.6441649198532104
Validation loss: 1.9056569812118367

Epoch: 6| Step: 1
Training loss: 1.1514655351638794
Validation loss: 1.8814522861152567

Epoch: 6| Step: 2
Training loss: 2.026602029800415
Validation loss: 1.8609567701175649

Epoch: 6| Step: 3
Training loss: 1.3636678457260132
Validation loss: 1.8501158170802618

Epoch: 6| Step: 4
Training loss: 1.4817347526550293
Validation loss: 1.867602030436198

Epoch: 6| Step: 5
Training loss: 1.6428712606430054
Validation loss: 1.8688170371517059

Epoch: 6| Step: 6
Training loss: 1.2214980125427246
Validation loss: 1.9189739086294686

Epoch: 6| Step: 7
Training loss: 1.234720230102539
Validation loss: 1.93295790303138

Epoch: 6| Step: 8
Training loss: 1.4061471223831177
Validation loss: 1.965562589706913

Epoch: 6| Step: 9
Training loss: 1.5773382186889648
Validation loss: 2.0015755545708442

Epoch: 6| Step: 10
Training loss: 1.243862271308899
Validation loss: 2.0352031441145044

Epoch: 6| Step: 11
Training loss: 1.4483351707458496
Validation loss: 2.002370818968742

Epoch: 6| Step: 12
Training loss: 1.1030423641204834
Validation loss: 1.9686575064095118

Epoch: 6| Step: 13
Training loss: 1.3540250062942505
Validation loss: 1.9516030332093597

Epoch: 228| Step: 0
Training loss: 1.415778398513794
Validation loss: 1.9013361623210292

Epoch: 6| Step: 1
Training loss: 2.047595739364624
Validation loss: 1.8944610639285016

Epoch: 6| Step: 2
Training loss: 1.466062068939209
Validation loss: 1.8825867932329896

Epoch: 6| Step: 3
Training loss: 1.7499197721481323
Validation loss: 1.8836332008402834

Epoch: 6| Step: 4
Training loss: 1.3732376098632812
Validation loss: 1.874173500204599

Epoch: 6| Step: 5
Training loss: 0.9785085320472717
Validation loss: 1.9013526926758468

Epoch: 6| Step: 6
Training loss: 1.1596777439117432
Validation loss: 2.0258736354048534

Epoch: 6| Step: 7
Training loss: 2.124056577682495
Validation loss: 2.087557869572793

Epoch: 6| Step: 8
Training loss: 1.4113068580627441
Validation loss: 2.0578828678336194

Epoch: 6| Step: 9
Training loss: 1.3859025239944458
Validation loss: 2.0545608189798172

Epoch: 6| Step: 10
Training loss: 1.3614040613174438
Validation loss: 2.017058280206496

Epoch: 6| Step: 11
Training loss: 1.4852291345596313
Validation loss: 1.9769784532567507

Epoch: 6| Step: 12
Training loss: 1.5881321430206299
Validation loss: 1.9462199364939043

Epoch: 6| Step: 13
Training loss: 0.8109358549118042
Validation loss: 1.9563364905695761

Epoch: 229| Step: 0
Training loss: 1.9341158866882324
Validation loss: 1.954824616832118

Epoch: 6| Step: 1
Training loss: 1.4278472661972046
Validation loss: 1.9712933032743392

Epoch: 6| Step: 2
Training loss: 1.4897680282592773
Validation loss: 2.007197622329958

Epoch: 6| Step: 3
Training loss: 1.07440185546875
Validation loss: 2.0397022257569017

Epoch: 6| Step: 4
Training loss: 1.4836034774780273
Validation loss: 2.147847088434363

Epoch: 6| Step: 5
Training loss: 1.7907187938690186
Validation loss: 2.143595859568606

Epoch: 6| Step: 6
Training loss: 1.54120671749115
Validation loss: 2.079439381117462

Epoch: 6| Step: 7
Training loss: 1.462188959121704
Validation loss: 1.9865163564682007

Epoch: 6| Step: 8
Training loss: 0.8911494016647339
Validation loss: 1.9584442877000379

Epoch: 6| Step: 9
Training loss: 1.4258227348327637
Validation loss: 1.8873820561234669

Epoch: 6| Step: 10
Training loss: 1.4146175384521484
Validation loss: 1.886810956462737

Epoch: 6| Step: 11
Training loss: 1.1577459573745728
Validation loss: 1.8915939689964376

Epoch: 6| Step: 12
Training loss: 1.830125331878662
Validation loss: 1.8712318789574407

Epoch: 6| Step: 13
Training loss: 1.7671172618865967
Validation loss: 1.8679849819470478

Epoch: 230| Step: 0
Training loss: 1.562124252319336
Validation loss: 1.8622859972779469

Epoch: 6| Step: 1
Training loss: 1.2291593551635742
Validation loss: 1.8533518737362278

Epoch: 6| Step: 2
Training loss: 0.9273063540458679
Validation loss: 1.9056255561049267

Epoch: 6| Step: 3
Training loss: 1.1082632541656494
Validation loss: 1.9170128555708035

Epoch: 6| Step: 4
Training loss: 1.4368672370910645
Validation loss: 1.9618204075803038

Epoch: 6| Step: 5
Training loss: 0.743377685546875
Validation loss: 1.9656389041613507

Epoch: 6| Step: 6
Training loss: 1.8611392974853516
Validation loss: 1.975063826448174

Epoch: 6| Step: 7
Training loss: 1.0936846733093262
Validation loss: 2.013129465041622

Epoch: 6| Step: 8
Training loss: 1.5822670459747314
Validation loss: 2.000562033345622

Epoch: 6| Step: 9
Training loss: 1.6756682395935059
Validation loss: 2.0198815740564817

Epoch: 6| Step: 10
Training loss: 1.6133179664611816
Validation loss: 2.001583883839269

Epoch: 6| Step: 11
Training loss: 1.274395227432251
Validation loss: 1.9749383439299881

Epoch: 6| Step: 12
Training loss: 1.2043519020080566
Validation loss: 1.9645544046996741

Epoch: 6| Step: 13
Training loss: 1.6989974975585938
Validation loss: 1.9565303171834638

Epoch: 231| Step: 0
Training loss: 1.6116180419921875
Validation loss: 1.9682599793198288

Epoch: 6| Step: 1
Training loss: 1.2847846746444702
Validation loss: 1.983933617991786

Epoch: 6| Step: 2
Training loss: 1.1803287267684937
Validation loss: 1.9782021096957627

Epoch: 6| Step: 3
Training loss: 0.9219037294387817
Validation loss: 1.9915424444342171

Epoch: 6| Step: 4
Training loss: 1.4501049518585205
Validation loss: 1.9818979873452136

Epoch: 6| Step: 5
Training loss: 1.7251605987548828
Validation loss: 1.916619949443366

Epoch: 6| Step: 6
Training loss: 1.17569899559021
Validation loss: 1.890615060765256

Epoch: 6| Step: 7
Training loss: 2.0018882751464844
Validation loss: 1.8827330271402996

Epoch: 6| Step: 8
Training loss: 1.6770434379577637
Validation loss: 1.8800128659894388

Epoch: 6| Step: 9
Training loss: 1.7363165616989136
Validation loss: 1.8767731523001066

Epoch: 6| Step: 10
Training loss: 1.209672451019287
Validation loss: 1.8364921769788187

Epoch: 6| Step: 11
Training loss: 1.023566722869873
Validation loss: 1.8508495284665016

Epoch: 6| Step: 12
Training loss: 0.8838046193122864
Validation loss: 1.8689297476122457

Epoch: 6| Step: 13
Training loss: 0.7990976572036743
Validation loss: 1.9451603017827517

Epoch: 232| Step: 0
Training loss: 1.903935194015503
Validation loss: 1.944592115699604

Epoch: 6| Step: 1
Training loss: 1.9290680885314941
Validation loss: 1.9309500173855854

Epoch: 6| Step: 2
Training loss: 1.2586286067962646
Validation loss: 1.9324074996415006

Epoch: 6| Step: 3
Training loss: 1.430873990058899
Validation loss: 1.9453234698182793

Epoch: 6| Step: 4
Training loss: 0.9423868060112
Validation loss: 1.9550187049373504

Epoch: 6| Step: 5
Training loss: 1.4948129653930664
Validation loss: 1.9399914228787987

Epoch: 6| Step: 6
Training loss: 1.2125585079193115
Validation loss: 1.9433916512356009

Epoch: 6| Step: 7
Training loss: 1.2063792943954468
Validation loss: 1.9745177581746092

Epoch: 6| Step: 8
Training loss: 1.2034971714019775
Validation loss: 1.9555319560471403

Epoch: 6| Step: 9
Training loss: 1.462548017501831
Validation loss: 1.933864693487844

Epoch: 6| Step: 10
Training loss: 1.1757583618164062
Validation loss: 1.9442297079229867

Epoch: 6| Step: 11
Training loss: 0.8392326831817627
Validation loss: 1.9141901436672415

Epoch: 6| Step: 12
Training loss: 1.1651382446289062
Validation loss: 1.9064241263174242

Epoch: 6| Step: 13
Training loss: 1.0559778213500977
Validation loss: 1.8815636275916972

Epoch: 233| Step: 0
Training loss: 0.8797283172607422
Validation loss: 1.9003557287236696

Epoch: 6| Step: 1
Training loss: 1.6790032386779785
Validation loss: 1.9073429697303361

Epoch: 6| Step: 2
Training loss: 1.6442509889602661
Validation loss: 1.9067062998330722

Epoch: 6| Step: 3
Training loss: 1.728379487991333
Validation loss: 1.9705892352647678

Epoch: 6| Step: 4
Training loss: 0.8495649099349976
Validation loss: 2.0342834098364717

Epoch: 6| Step: 5
Training loss: 1.396729826927185
Validation loss: 2.046911152460242

Epoch: 6| Step: 6
Training loss: 0.8452072143554688
Validation loss: 2.009470376917111

Epoch: 6| Step: 7
Training loss: 0.9097920656204224
Validation loss: 2.015253054198398

Epoch: 6| Step: 8
Training loss: 1.2918310165405273
Validation loss: 1.9922014359504945

Epoch: 6| Step: 9
Training loss: 1.4118072986602783
Validation loss: 2.0057713959806707

Epoch: 6| Step: 10
Training loss: 1.6788930892944336
Validation loss: 2.010619457050036

Epoch: 6| Step: 11
Training loss: 1.3716706037521362
Validation loss: 1.9854401311566752

Epoch: 6| Step: 12
Training loss: 1.154695987701416
Validation loss: 1.9689082381545857

Epoch: 6| Step: 13
Training loss: 2.1286184787750244
Validation loss: 1.9567893679423998

Epoch: 234| Step: 0
Training loss: 0.9727178812026978
Validation loss: 1.9296176446381437

Epoch: 6| Step: 1
Training loss: 1.4470728635787964
Validation loss: 1.9562753092858098

Epoch: 6| Step: 2
Training loss: 0.9193339943885803
Validation loss: 1.962569744356217

Epoch: 6| Step: 3
Training loss: 1.0930750370025635
Validation loss: 2.0026096259394

Epoch: 6| Step: 4
Training loss: 1.4834342002868652
Validation loss: 1.9985566728858537

Epoch: 6| Step: 5
Training loss: 1.0441203117370605
Validation loss: 1.9394890954417567

Epoch: 6| Step: 6
Training loss: 1.4234493970870972
Validation loss: 1.8881279063481156

Epoch: 6| Step: 7
Training loss: 1.4832842350006104
Validation loss: 1.8707498081268803

Epoch: 6| Step: 8
Training loss: 0.9498952627182007
Validation loss: 1.8734218766612392

Epoch: 6| Step: 9
Training loss: 1.2156354188919067
Validation loss: 1.8985155436300463

Epoch: 6| Step: 10
Training loss: 1.6664406061172485
Validation loss: 1.8839142014903407

Epoch: 6| Step: 11
Training loss: 1.484007477760315
Validation loss: 1.9021079181342997

Epoch: 6| Step: 12
Training loss: 1.9254522323608398
Validation loss: 1.9736540843081731

Epoch: 6| Step: 13
Training loss: 1.993001937866211
Validation loss: 2.042448248914493

Epoch: 235| Step: 0
Training loss: 1.798292875289917
Validation loss: 2.1184514619970836

Epoch: 6| Step: 1
Training loss: 0.9074152708053589
Validation loss: 2.115958761143428

Epoch: 6| Step: 2
Training loss: 1.1385879516601562
Validation loss: 2.075139186715567

Epoch: 6| Step: 3
Training loss: 1.6415464878082275
Validation loss: 2.044110086656386

Epoch: 6| Step: 4
Training loss: 1.5561376810073853
Validation loss: 1.9920067658988379

Epoch: 6| Step: 5
Training loss: 1.5331964492797852
Validation loss: 1.9668947227539555

Epoch: 6| Step: 6
Training loss: 1.3375232219696045
Validation loss: 1.9713420021918513

Epoch: 6| Step: 7
Training loss: 1.346773386001587
Validation loss: 1.9701520448089929

Epoch: 6| Step: 8
Training loss: 1.1340060234069824
Validation loss: 1.9312013631225915

Epoch: 6| Step: 9
Training loss: 0.8213315606117249
Validation loss: 1.930153949286348

Epoch: 6| Step: 10
Training loss: 1.3226709365844727
Validation loss: 1.9183232284361316

Epoch: 6| Step: 11
Training loss: 1.3376399278640747
Validation loss: 1.9218665784405125

Epoch: 6| Step: 12
Training loss: 1.508397102355957
Validation loss: 1.986545060270576

Epoch: 6| Step: 13
Training loss: 1.8783032894134521
Validation loss: 2.0520598247487056

Epoch: 236| Step: 0
Training loss: 1.4398608207702637
Validation loss: 2.086485457676713

Epoch: 6| Step: 1
Training loss: 1.631603717803955
Validation loss: 2.0675219720409763

Epoch: 6| Step: 2
Training loss: 1.187636375427246
Validation loss: 1.9541978605331913

Epoch: 6| Step: 3
Training loss: 1.7370084524154663
Validation loss: 1.9094603907677434

Epoch: 6| Step: 4
Training loss: 1.6157562732696533
Validation loss: 1.8885533335388347

Epoch: 6| Step: 5
Training loss: 1.4808166027069092
Validation loss: 1.8939081379162368

Epoch: 6| Step: 6
Training loss: 1.082674503326416
Validation loss: 1.8951345618053148

Epoch: 6| Step: 7
Training loss: 1.0123021602630615
Validation loss: 1.921124642895114

Epoch: 6| Step: 8
Training loss: 0.9859568476676941
Validation loss: 1.8921917369288783

Epoch: 6| Step: 9
Training loss: 1.134408950805664
Validation loss: 1.9127815026108936

Epoch: 6| Step: 10
Training loss: 1.1188991069793701
Validation loss: 1.926774449245904

Epoch: 6| Step: 11
Training loss: 1.5442001819610596
Validation loss: 1.9777882201697237

Epoch: 6| Step: 12
Training loss: 1.2368690967559814
Validation loss: 1.993875806049634

Epoch: 6| Step: 13
Training loss: 0.9423340559005737
Validation loss: 1.982021895788049

Epoch: 237| Step: 0
Training loss: 0.9685890078544617
Validation loss: 1.9654370943705242

Epoch: 6| Step: 1
Training loss: 0.8719825148582458
Validation loss: 1.9450177710543397

Epoch: 6| Step: 2
Training loss: 0.9429337978363037
Validation loss: 1.967685766117547

Epoch: 6| Step: 3
Training loss: 1.6160715818405151
Validation loss: 1.9228102109765495

Epoch: 6| Step: 4
Training loss: 1.2137341499328613
Validation loss: 1.9139285241403887

Epoch: 6| Step: 5
Training loss: 0.7631111741065979
Validation loss: 1.8716882582633727

Epoch: 6| Step: 6
Training loss: 1.1197181940078735
Validation loss: 1.87608390854251

Epoch: 6| Step: 7
Training loss: 1.0311273336410522
Validation loss: 1.8626842626961329

Epoch: 6| Step: 8
Training loss: 1.8948068618774414
Validation loss: 1.8664660299977949

Epoch: 6| Step: 9
Training loss: 1.5006158351898193
Validation loss: 1.8931163946787517

Epoch: 6| Step: 10
Training loss: 0.9712438583374023
Validation loss: 1.9244024958661807

Epoch: 6| Step: 11
Training loss: 1.3697763681411743
Validation loss: 1.9443750227651289

Epoch: 6| Step: 12
Training loss: 1.7130458354949951
Validation loss: 1.9525950301078059

Epoch: 6| Step: 13
Training loss: 2.117629051208496
Validation loss: 1.9064113119597077

Epoch: 238| Step: 0
Training loss: 1.4824495315551758
Validation loss: 1.8781778889317666

Epoch: 6| Step: 1
Training loss: 0.9635487794876099
Validation loss: 1.847106481111178

Epoch: 6| Step: 2
Training loss: 1.2536004781723022
Validation loss: 1.849405098986882

Epoch: 6| Step: 3
Training loss: 1.1044301986694336
Validation loss: 1.8628971653599893

Epoch: 6| Step: 4
Training loss: 1.373443365097046
Validation loss: 1.8737568252830095

Epoch: 6| Step: 5
Training loss: 1.5646536350250244
Validation loss: 1.8981004453474475

Epoch: 6| Step: 6
Training loss: 1.16709566116333
Validation loss: 1.9231051539862027

Epoch: 6| Step: 7
Training loss: 0.8499990105628967
Validation loss: 1.9427068733399915

Epoch: 6| Step: 8
Training loss: 1.4481542110443115
Validation loss: 1.9624738641964492

Epoch: 6| Step: 9
Training loss: 0.8522910475730896
Validation loss: 1.9740504295595231

Epoch: 6| Step: 10
Training loss: 1.4541906118392944
Validation loss: 1.994301765195785

Epoch: 6| Step: 11
Training loss: 1.5363231897354126
Validation loss: 1.9772564467563425

Epoch: 6| Step: 12
Training loss: 1.3643068075180054
Validation loss: 1.9267759758939025

Epoch: 6| Step: 13
Training loss: 0.7807797193527222
Validation loss: 1.9213734083278204

Epoch: 239| Step: 0
Training loss: 0.7348651885986328
Validation loss: 1.9077427297510126

Epoch: 6| Step: 1
Training loss: 1.354520559310913
Validation loss: 1.9033613410047305

Epoch: 6| Step: 2
Training loss: 1.1228363513946533
Validation loss: 1.9001131198739494

Epoch: 6| Step: 3
Training loss: 1.0494698286056519
Validation loss: 1.9180712007707166

Epoch: 6| Step: 4
Training loss: 1.6887651681900024
Validation loss: 1.8950110981541295

Epoch: 6| Step: 5
Training loss: 1.2199628353118896
Validation loss: 1.9199817257542764

Epoch: 6| Step: 6
Training loss: 0.858025074005127
Validation loss: 1.9091990493958997

Epoch: 6| Step: 7
Training loss: 1.646997332572937
Validation loss: 1.9316566503176125

Epoch: 6| Step: 8
Training loss: 0.9122240543365479
Validation loss: 1.911285695209298

Epoch: 6| Step: 9
Training loss: 1.2268954515457153
Validation loss: 1.918812059587048

Epoch: 6| Step: 10
Training loss: 1.3599720001220703
Validation loss: 1.9200141609355967

Epoch: 6| Step: 11
Training loss: 1.1045255661010742
Validation loss: 1.9167079258990545

Epoch: 6| Step: 12
Training loss: 1.0422555208206177
Validation loss: 1.9009133205618909

Epoch: 6| Step: 13
Training loss: 1.3710638284683228
Validation loss: 1.9272377119269422

Epoch: 240| Step: 0
Training loss: 0.8295662999153137
Validation loss: 1.9087579147790068

Epoch: 6| Step: 1
Training loss: 0.9817456007003784
Validation loss: 1.8844290856392152

Epoch: 6| Step: 2
Training loss: 0.5401630401611328
Validation loss: 1.9084443725565428

Epoch: 6| Step: 3
Training loss: 1.4695181846618652
Validation loss: 1.8830235645335207

Epoch: 6| Step: 4
Training loss: 0.9306254386901855
Validation loss: 1.8721026297538512

Epoch: 6| Step: 5
Training loss: 1.037693977355957
Validation loss: 1.8923976562356437

Epoch: 6| Step: 6
Training loss: 1.1528608798980713
Validation loss: 1.8888206558842813

Epoch: 6| Step: 7
Training loss: 1.3333011865615845
Validation loss: 1.9093812486176849

Epoch: 6| Step: 8
Training loss: 0.9517793655395508
Validation loss: 1.894239471804711

Epoch: 6| Step: 9
Training loss: 2.032992124557495
Validation loss: 1.9112235922967233

Epoch: 6| Step: 10
Training loss: 1.0570354461669922
Validation loss: 1.8930521357444026

Epoch: 6| Step: 11
Training loss: 1.4800366163253784
Validation loss: 1.9269376621451428

Epoch: 6| Step: 12
Training loss: 1.1728215217590332
Validation loss: 1.9182504505239508

Epoch: 6| Step: 13
Training loss: 1.8370767831802368
Validation loss: 1.920395125624954

Epoch: 241| Step: 0
Training loss: 1.6750472784042358
Validation loss: 1.937614297354093

Epoch: 6| Step: 1
Training loss: 0.9634848237037659
Validation loss: 1.9345604399199128

Epoch: 6| Step: 2
Training loss: 1.6588526964187622
Validation loss: 1.9529147327587169

Epoch: 6| Step: 3
Training loss: 1.4888569116592407
Validation loss: 1.948479115322072

Epoch: 6| Step: 4
Training loss: 0.7766448855400085
Validation loss: 1.9256735053113712

Epoch: 6| Step: 5
Training loss: 1.273711085319519
Validation loss: 1.90222176044218

Epoch: 6| Step: 6
Training loss: 1.4982913732528687
Validation loss: 1.8881387966935352

Epoch: 6| Step: 7
Training loss: 0.783226490020752
Validation loss: 1.870448209906137

Epoch: 6| Step: 8
Training loss: 1.0897843837738037
Validation loss: 1.9080884712998585

Epoch: 6| Step: 9
Training loss: 0.9922970533370972
Validation loss: 1.899604110307591

Epoch: 6| Step: 10
Training loss: 1.2220784425735474
Validation loss: 1.9347980150612452

Epoch: 6| Step: 11
Training loss: 1.539040207862854
Validation loss: 1.929850116852791

Epoch: 6| Step: 12
Training loss: 0.7606753706932068
Validation loss: 1.9148649861735683

Epoch: 6| Step: 13
Training loss: 0.9268763065338135
Validation loss: 1.910275258043761

Epoch: 242| Step: 0
Training loss: 0.724216103553772
Validation loss: 1.8965289362015263

Epoch: 6| Step: 1
Training loss: 1.3935048580169678
Validation loss: 1.8983212209516955

Epoch: 6| Step: 2
Training loss: 0.886276125907898
Validation loss: 1.876039283249968

Epoch: 6| Step: 3
Training loss: 0.9892416596412659
Validation loss: 1.878816399523007

Epoch: 6| Step: 4
Training loss: 1.240588665008545
Validation loss: 1.8954659661939066

Epoch: 6| Step: 5
Training loss: 1.036989688873291
Validation loss: 1.8550913436438448

Epoch: 6| Step: 6
Training loss: 0.9000939130783081
Validation loss: 1.8217582164272186

Epoch: 6| Step: 7
Training loss: 1.6159162521362305
Validation loss: 1.8315858917851602

Epoch: 6| Step: 8
Training loss: 1.1612141132354736
Validation loss: 1.8631625713840607

Epoch: 6| Step: 9
Training loss: 1.1157948970794678
Validation loss: 1.8580934616827196

Epoch: 6| Step: 10
Training loss: 1.5404341220855713
Validation loss: 1.890531239971038

Epoch: 6| Step: 11
Training loss: 0.881173849105835
Validation loss: 1.899582137343704

Epoch: 6| Step: 12
Training loss: 1.7411417961120605
Validation loss: 1.927538623091995

Epoch: 6| Step: 13
Training loss: 1.8996130228042603
Validation loss: 1.9918764329725696

Epoch: 243| Step: 0
Training loss: 1.3082550764083862
Validation loss: 2.0604167010194514

Epoch: 6| Step: 1
Training loss: 1.5386326313018799
Validation loss: 2.0447983677669237

Epoch: 6| Step: 2
Training loss: 0.8381766080856323
Validation loss: 1.9430680300599785

Epoch: 6| Step: 3
Training loss: 1.2747339010238647
Validation loss: 1.9018933914041007

Epoch: 6| Step: 4
Training loss: 1.1873968839645386
Validation loss: 1.865485796364405

Epoch: 6| Step: 5
Training loss: 1.0573867559432983
Validation loss: 1.8591516120459444

Epoch: 6| Step: 6
Training loss: 0.8547748327255249
Validation loss: 1.8337124868105816

Epoch: 6| Step: 7
Training loss: 1.4254642724990845
Validation loss: 1.8381739047265822

Epoch: 6| Step: 8
Training loss: 1.593817114830017
Validation loss: 1.8912580987458587

Epoch: 6| Step: 9
Training loss: 1.0274832248687744
Validation loss: 1.9369192046503867

Epoch: 6| Step: 10
Training loss: 1.153205156326294
Validation loss: 2.0030366400236725

Epoch: 6| Step: 11
Training loss: 1.242506742477417
Validation loss: 2.0366168355429046

Epoch: 6| Step: 12
Training loss: 1.277068018913269
Validation loss: 2.028554416471912

Epoch: 6| Step: 13
Training loss: 1.8190797567367554
Validation loss: 2.008951381970477

Epoch: 244| Step: 0
Training loss: 1.2106516361236572
Validation loss: 2.0319438839471466

Epoch: 6| Step: 1
Training loss: 1.0431344509124756
Validation loss: 2.022214925417336

Epoch: 6| Step: 2
Training loss: 1.1257214546203613
Validation loss: 2.0075538876236125

Epoch: 6| Step: 3
Training loss: 1.2940616607666016
Validation loss: 1.9762109787233415

Epoch: 6| Step: 4
Training loss: 1.577906847000122
Validation loss: 1.947192592005576

Epoch: 6| Step: 5
Training loss: 1.2761385440826416
Validation loss: 1.9341719970908215

Epoch: 6| Step: 6
Training loss: 0.967296302318573
Validation loss: 1.8967798063831944

Epoch: 6| Step: 7
Training loss: 1.117730736732483
Validation loss: 1.8946948525726155

Epoch: 6| Step: 8
Training loss: 1.244938611984253
Validation loss: 1.897216627674718

Epoch: 6| Step: 9
Training loss: 1.13051438331604
Validation loss: 1.8866984844207764

Epoch: 6| Step: 10
Training loss: 1.42958664894104
Validation loss: 1.8695932434451195

Epoch: 6| Step: 11
Training loss: 0.75096195936203
Validation loss: 1.868943678435459

Epoch: 6| Step: 12
Training loss: 1.1489777565002441
Validation loss: 1.8559557827570106

Epoch: 6| Step: 13
Training loss: 1.5831223726272583
Validation loss: 1.8736926381305983

Epoch: 245| Step: 0
Training loss: 1.1158121824264526
Validation loss: 1.8917191246504426

Epoch: 6| Step: 1
Training loss: 1.4531173706054688
Validation loss: 1.9380560177628712

Epoch: 6| Step: 2
Training loss: 1.0500855445861816
Validation loss: 1.9119414385928903

Epoch: 6| Step: 3
Training loss: 1.4912530183792114
Validation loss: 1.8922149468493719

Epoch: 6| Step: 4
Training loss: 1.4292528629302979
Validation loss: 1.8455266747423398

Epoch: 6| Step: 5
Training loss: 0.6419353485107422
Validation loss: 1.8423561203864314

Epoch: 6| Step: 6
Training loss: 1.3085229396820068
Validation loss: 1.8327662970430108

Epoch: 6| Step: 7
Training loss: 0.8548498153686523
Validation loss: 1.8549657585800334

Epoch: 6| Step: 8
Training loss: 1.4290533065795898
Validation loss: 1.884342675567955

Epoch: 6| Step: 9
Training loss: 1.4043807983398438
Validation loss: 1.8804744969132126

Epoch: 6| Step: 10
Training loss: 0.6942510008811951
Validation loss: 1.8787061796393445

Epoch: 6| Step: 11
Training loss: 1.4186989068984985
Validation loss: 1.8762861221067366

Epoch: 6| Step: 12
Training loss: 1.2056479454040527
Validation loss: 1.914351333854019

Epoch: 6| Step: 13
Training loss: 1.4171022176742554
Validation loss: 1.9053659849269415

Epoch: 246| Step: 0
Training loss: 1.4365901947021484
Validation loss: 1.9077065042270127

Epoch: 6| Step: 1
Training loss: 1.3447070121765137
Validation loss: 1.9220893767572218

Epoch: 6| Step: 2
Training loss: 0.7765704989433289
Validation loss: 1.9231119181520195

Epoch: 6| Step: 3
Training loss: 1.8506957292556763
Validation loss: 1.9153490002437303

Epoch: 6| Step: 4
Training loss: 1.2442700862884521
Validation loss: 1.9161857148652435

Epoch: 6| Step: 5
Training loss: 0.9473367929458618
Validation loss: 1.8983244504979861

Epoch: 6| Step: 6
Training loss: 1.2962075471878052
Validation loss: 1.9058887279161842

Epoch: 6| Step: 7
Training loss: 1.3693029880523682
Validation loss: 1.9262416465308076

Epoch: 6| Step: 8
Training loss: 1.206192135810852
Validation loss: 1.915209185692572

Epoch: 6| Step: 9
Training loss: 0.8113821148872375
Validation loss: 1.9094299667625017

Epoch: 6| Step: 10
Training loss: 1.3411141633987427
Validation loss: 1.923693041647634

Epoch: 6| Step: 11
Training loss: 0.6743060350418091
Validation loss: 1.9498419556566464

Epoch: 6| Step: 12
Training loss: 0.8674379587173462
Validation loss: 1.937050675833097

Epoch: 6| Step: 13
Training loss: 0.9941077828407288
Validation loss: 1.9341566152470087

Epoch: 247| Step: 0
Training loss: 0.6301661729812622
Validation loss: 1.9415679234330372

Epoch: 6| Step: 1
Training loss: 1.3947770595550537
Validation loss: 1.908810325848159

Epoch: 6| Step: 2
Training loss: 0.9769126176834106
Validation loss: 1.9016289185452204

Epoch: 6| Step: 3
Training loss: 1.1500263214111328
Validation loss: 1.8974766167261268

Epoch: 6| Step: 4
Training loss: 1.9080333709716797
Validation loss: 1.8997976754301338

Epoch: 6| Step: 5
Training loss: 1.2644479274749756
Validation loss: 1.9030762359660158

Epoch: 6| Step: 6
Training loss: 1.1038973331451416
Validation loss: 1.905659814034739

Epoch: 6| Step: 7
Training loss: 0.9859876036643982
Validation loss: 1.9140925920137795

Epoch: 6| Step: 8
Training loss: 0.8563502430915833
Validation loss: 1.8996325231367541

Epoch: 6| Step: 9
Training loss: 0.6964921951293945
Validation loss: 1.8852082529375631

Epoch: 6| Step: 10
Training loss: 1.4727272987365723
Validation loss: 1.8723826036658338

Epoch: 6| Step: 11
Training loss: 1.2079335451126099
Validation loss: 1.8846595389868623

Epoch: 6| Step: 12
Training loss: 0.8931789398193359
Validation loss: 1.8924640199189544

Epoch: 6| Step: 13
Training loss: 1.1079444885253906
Validation loss: 1.8998797990942513

Epoch: 248| Step: 0
Training loss: 1.300384759902954
Validation loss: 1.9197310657911404

Epoch: 6| Step: 1
Training loss: 0.9574199318885803
Validation loss: 1.9479064223586873

Epoch: 6| Step: 2
Training loss: 1.215929627418518
Validation loss: 1.9815095316979192

Epoch: 6| Step: 3
Training loss: 1.05205500125885
Validation loss: 1.9680774660520657

Epoch: 6| Step: 4
Training loss: 1.4594354629516602
Validation loss: 1.940468195945986

Epoch: 6| Step: 5
Training loss: 1.390103816986084
Validation loss: 1.9331523256917154

Epoch: 6| Step: 6
Training loss: 1.3559300899505615
Validation loss: 1.9327290006863174

Epoch: 6| Step: 7
Training loss: 0.5790126323699951
Validation loss: 1.89854944521381

Epoch: 6| Step: 8
Training loss: 0.9886664748191833
Validation loss: 1.8987098073446622

Epoch: 6| Step: 9
Training loss: 1.224562406539917
Validation loss: 1.8730956815904187

Epoch: 6| Step: 10
Training loss: 0.7288367748260498
Validation loss: 1.8738240054858628

Epoch: 6| Step: 11
Training loss: 1.0019805431365967
Validation loss: 1.8770553463248796

Epoch: 6| Step: 12
Training loss: 1.0405538082122803
Validation loss: 1.9110685330565258

Epoch: 6| Step: 13
Training loss: 0.91861492395401
Validation loss: 1.9040300564099384

Epoch: 249| Step: 0
Training loss: 0.7464739084243774
Validation loss: 1.9207561477538078

Epoch: 6| Step: 1
Training loss: 1.3449361324310303
Validation loss: 1.9307935327611945

Epoch: 6| Step: 2
Training loss: 1.5113974809646606
Validation loss: 1.9577912207572692

Epoch: 6| Step: 3
Training loss: 1.0940868854522705
Validation loss: 1.9347079774384857

Epoch: 6| Step: 4
Training loss: 0.9207049608230591
Validation loss: 1.9041224602730042

Epoch: 6| Step: 5
Training loss: 1.3648321628570557
Validation loss: 1.8810702741786998

Epoch: 6| Step: 6
Training loss: 0.9009310007095337
Validation loss: 1.8532700025907127

Epoch: 6| Step: 7
Training loss: 1.4422821998596191
Validation loss: 1.822677408495257

Epoch: 6| Step: 8
Training loss: 1.1830397844314575
Validation loss: 1.8416745329415927

Epoch: 6| Step: 9
Training loss: 0.8361890316009521
Validation loss: 1.8752760874327792

Epoch: 6| Step: 10
Training loss: 0.7472297549247742
Validation loss: 1.8762726296660721

Epoch: 6| Step: 11
Training loss: 1.0676071643829346
Validation loss: 1.9118483181922667

Epoch: 6| Step: 12
Training loss: 1.1431019306182861
Validation loss: 1.9499111329355547

Epoch: 6| Step: 13
Training loss: 0.8758144378662109
Validation loss: 1.967497310330791

Epoch: 250| Step: 0
Training loss: 1.3925073146820068
Validation loss: 1.9118067987503544

Epoch: 6| Step: 1
Training loss: 1.4944097995758057
Validation loss: 1.8558647158325359

Epoch: 6| Step: 2
Training loss: 1.2076129913330078
Validation loss: 1.8407865942165416

Epoch: 6| Step: 3
Training loss: 1.7786805629730225
Validation loss: 1.8515727955807921

Epoch: 6| Step: 4
Training loss: 1.1278799772262573
Validation loss: 1.8517151327543362

Epoch: 6| Step: 5
Training loss: 0.9051807522773743
Validation loss: 1.8472727960155857

Epoch: 6| Step: 6
Training loss: 1.4841147661209106
Validation loss: 1.8440744402588054

Epoch: 6| Step: 7
Training loss: 0.7073317766189575
Validation loss: 1.8701230582370554

Epoch: 6| Step: 8
Training loss: 0.5968910455703735
Validation loss: 1.9019844378194501

Epoch: 6| Step: 9
Training loss: 0.812650203704834
Validation loss: 1.9410996078163065

Epoch: 6| Step: 10
Training loss: 0.8498020172119141
Validation loss: 1.9665435719233688

Epoch: 6| Step: 11
Training loss: 1.2696493864059448
Validation loss: 1.999040292155358

Epoch: 6| Step: 12
Training loss: 0.5408546924591064
Validation loss: 2.0190017018266904

Epoch: 6| Step: 13
Training loss: 1.2873620986938477
Validation loss: 2.0157615984639814

Epoch: 251| Step: 0
Training loss: 1.3217874765396118
Validation loss: 1.950031683009158

Epoch: 6| Step: 1
Training loss: 1.1364481449127197
Validation loss: 1.9157701871728385

Epoch: 6| Step: 2
Training loss: 0.7958332300186157
Validation loss: 1.9007774322263655

Epoch: 6| Step: 3
Training loss: 1.4119243621826172
Validation loss: 1.872083229403342

Epoch: 6| Step: 4
Training loss: 1.1509249210357666
Validation loss: 1.841529142472052

Epoch: 6| Step: 5
Training loss: 1.6309380531311035
Validation loss: 1.843053795958078

Epoch: 6| Step: 6
Training loss: 1.2057955265045166
Validation loss: 1.8673979338779245

Epoch: 6| Step: 7
Training loss: 0.8536908626556396
Validation loss: 1.85313928896381

Epoch: 6| Step: 8
Training loss: 1.1286602020263672
Validation loss: 1.900387058975876

Epoch: 6| Step: 9
Training loss: 1.185413122177124
Validation loss: 1.898834123406359

Epoch: 6| Step: 10
Training loss: 0.8208736181259155
Validation loss: 1.913293037363278

Epoch: 6| Step: 11
Training loss: 0.6026641130447388
Validation loss: 1.880034109597565

Epoch: 6| Step: 12
Training loss: 0.48467567563056946
Validation loss: 1.8610412305401218

Epoch: 6| Step: 13
Training loss: 1.8194016218185425
Validation loss: 1.8716237519377021

Epoch: 252| Step: 0
Training loss: 1.3874506950378418
Validation loss: 1.8621893646896526

Epoch: 6| Step: 1
Training loss: 0.9985503554344177
Validation loss: 1.8766669598958825

Epoch: 6| Step: 2
Training loss: 0.908433198928833
Validation loss: 1.8713457584381104

Epoch: 6| Step: 3
Training loss: 0.9945563077926636
Validation loss: 1.8859620940300725

Epoch: 6| Step: 4
Training loss: 0.9002424478530884
Validation loss: 1.9392399275174705

Epoch: 6| Step: 5
Training loss: 1.6047744750976562
Validation loss: 1.9843914944638488

Epoch: 6| Step: 6
Training loss: 1.0819891691207886
Validation loss: 1.965833157621404

Epoch: 6| Step: 7
Training loss: 1.506366491317749
Validation loss: 1.93741092886976

Epoch: 6| Step: 8
Training loss: 0.9204905033111572
Validation loss: 1.8895934794538765

Epoch: 6| Step: 9
Training loss: 0.60074782371521
Validation loss: 1.8681868455743278

Epoch: 6| Step: 10
Training loss: 0.9498370885848999
Validation loss: 1.8716283639272053

Epoch: 6| Step: 11
Training loss: 0.9992661476135254
Validation loss: 1.8462315400441487

Epoch: 6| Step: 12
Training loss: 0.8458834290504456
Validation loss: 1.8183537016632736

Epoch: 6| Step: 13
Training loss: 0.8635801076889038
Validation loss: 1.8400581011208155

Epoch: 253| Step: 0
Training loss: 1.0976213216781616
Validation loss: 1.8672731358517882

Epoch: 6| Step: 1
Training loss: 0.8744351863861084
Validation loss: 1.9222948781905635

Epoch: 6| Step: 2
Training loss: 1.2099297046661377
Validation loss: 1.9543442046770485

Epoch: 6| Step: 3
Training loss: 0.7166966199874878
Validation loss: 1.9158766346593057

Epoch: 6| Step: 4
Training loss: 1.1502697467803955
Validation loss: 1.8932530546701083

Epoch: 6| Step: 5
Training loss: 1.0931403636932373
Validation loss: 1.8499318553555397

Epoch: 6| Step: 6
Training loss: 1.1193006038665771
Validation loss: 1.8420326350837626

Epoch: 6| Step: 7
Training loss: 1.727051019668579
Validation loss: 1.8625648508789718

Epoch: 6| Step: 8
Training loss: 1.0801899433135986
Validation loss: 1.8412961101019254

Epoch: 6| Step: 9
Training loss: 1.3475100994110107
Validation loss: 1.8456786576137747

Epoch: 6| Step: 10
Training loss: 0.5273008346557617
Validation loss: 1.805884276666949

Epoch: 6| Step: 11
Training loss: 1.1622934341430664
Validation loss: 1.8659231175658524

Epoch: 6| Step: 12
Training loss: 0.9688295125961304
Validation loss: 1.9169009424025012

Epoch: 6| Step: 13
Training loss: 1.089027762413025
Validation loss: 1.9682850812071113

Epoch: 254| Step: 0
Training loss: 1.2731385231018066
Validation loss: 1.986394025946176

Epoch: 6| Step: 1
Training loss: 0.7693815231323242
Validation loss: 1.963228133416945

Epoch: 6| Step: 2
Training loss: 1.3017878532409668
Validation loss: 1.944359560166636

Epoch: 6| Step: 3
Training loss: 1.4240734577178955
Validation loss: 1.9019497389434485

Epoch: 6| Step: 4
Training loss: 0.6787533164024353
Validation loss: 1.905603011449178

Epoch: 6| Step: 5
Training loss: 1.315650463104248
Validation loss: 1.9185837635429956

Epoch: 6| Step: 6
Training loss: 1.1467220783233643
Validation loss: 1.8926000672001992

Epoch: 6| Step: 7
Training loss: 1.2210450172424316
Validation loss: 1.877075606776822

Epoch: 6| Step: 8
Training loss: 0.4711581766605377
Validation loss: 1.8967298294908257

Epoch: 6| Step: 9
Training loss: 1.2029104232788086
Validation loss: 1.9253850470307052

Epoch: 6| Step: 10
Training loss: 1.2007701396942139
Validation loss: 1.9364385348494335

Epoch: 6| Step: 11
Training loss: 1.0891934633255005
Validation loss: 1.924972245770116

Epoch: 6| Step: 12
Training loss: 1.391391634941101
Validation loss: 1.906400639523742

Epoch: 6| Step: 13
Training loss: 0.6702319383621216
Validation loss: 1.8713512164290234

Epoch: 255| Step: 0
Training loss: 1.358691930770874
Validation loss: 1.8928211222412765

Epoch: 6| Step: 1
Training loss: 1.0278016328811646
Validation loss: 1.898605832489588

Epoch: 6| Step: 2
Training loss: 0.9284998178482056
Validation loss: 1.9179944453700897

Epoch: 6| Step: 3
Training loss: 1.3886878490447998
Validation loss: 1.9021138016895582

Epoch: 6| Step: 4
Training loss: 0.8193916082382202
Validation loss: 1.8953662790277952

Epoch: 6| Step: 5
Training loss: 0.9230345487594604
Validation loss: 1.9034360262655443

Epoch: 6| Step: 6
Training loss: 1.0765249729156494
Validation loss: 1.9153067501642371

Epoch: 6| Step: 7
Training loss: 1.815521240234375
Validation loss: 1.896626118690737

Epoch: 6| Step: 8
Training loss: 0.6415853500366211
Validation loss: 1.8949936115613548

Epoch: 6| Step: 9
Training loss: 1.1063897609710693
Validation loss: 1.8953030032496299

Epoch: 6| Step: 10
Training loss: 0.7869701385498047
Validation loss: 1.9229815672802668

Epoch: 6| Step: 11
Training loss: 1.3967139720916748
Validation loss: 1.9433939200575634

Epoch: 6| Step: 12
Training loss: 0.8597574234008789
Validation loss: 1.9654782408027238

Epoch: 6| Step: 13
Training loss: 0.7383172512054443
Validation loss: 1.9321374521460584

Epoch: 256| Step: 0
Training loss: 1.2692036628723145
Validation loss: 1.9310859480211813

Epoch: 6| Step: 1
Training loss: 1.2385129928588867
Validation loss: 1.8840039814672163

Epoch: 6| Step: 2
Training loss: 0.7072389721870422
Validation loss: 1.8584541120836813

Epoch: 6| Step: 3
Training loss: 0.8077031373977661
Validation loss: 1.8423478462362801

Epoch: 6| Step: 4
Training loss: 0.8723610639572144
Validation loss: 1.8263460115719867

Epoch: 6| Step: 5
Training loss: 1.3089594841003418
Validation loss: 1.8111025312895417

Epoch: 6| Step: 6
Training loss: 1.1688830852508545
Validation loss: 1.8093463669541061

Epoch: 6| Step: 7
Training loss: 0.8134044408798218
Validation loss: 1.820805206093737

Epoch: 6| Step: 8
Training loss: 0.8011059165000916
Validation loss: 1.8269857398925289

Epoch: 6| Step: 9
Training loss: 0.7409188747406006
Validation loss: 1.8619808073966735

Epoch: 6| Step: 10
Training loss: 1.1052939891815186
Validation loss: 1.896572123291672

Epoch: 6| Step: 11
Training loss: 1.487544059753418
Validation loss: 1.965801920942081

Epoch: 6| Step: 12
Training loss: 1.0038635730743408
Validation loss: 1.9642324268176992

Epoch: 6| Step: 13
Training loss: 1.047768235206604
Validation loss: 1.9075110202194543

Epoch: 257| Step: 0
Training loss: 0.7792984247207642
Validation loss: 1.8797347737896828

Epoch: 6| Step: 1
Training loss: 0.8031705617904663
Validation loss: 1.8842515150705974

Epoch: 6| Step: 2
Training loss: 1.0024993419647217
Validation loss: 1.876303772772512

Epoch: 6| Step: 3
Training loss: 0.6995668411254883
Validation loss: 1.8372369773926274

Epoch: 6| Step: 4
Training loss: 1.541028618812561
Validation loss: 1.86676206896382

Epoch: 6| Step: 5
Training loss: 1.122573971748352
Validation loss: 1.8842238944063905

Epoch: 6| Step: 6
Training loss: 0.9729592204093933
Validation loss: 1.8937894041820238

Epoch: 6| Step: 7
Training loss: 0.8187096118927002
Validation loss: 1.9396477130151564

Epoch: 6| Step: 8
Training loss: 1.1836061477661133
Validation loss: 1.9359723547453522

Epoch: 6| Step: 9
Training loss: 1.1276326179504395
Validation loss: 1.9383843906464115

Epoch: 6| Step: 10
Training loss: 1.0534656047821045
Validation loss: 1.9238239411384828

Epoch: 6| Step: 11
Training loss: 1.080381155014038
Validation loss: 1.9300652332203363

Epoch: 6| Step: 12
Training loss: 0.8282252550125122
Validation loss: 1.8969843938786497

Epoch: 6| Step: 13
Training loss: 1.0796599388122559
Validation loss: 1.9072688471886419

Epoch: 258| Step: 0
Training loss: 0.8879375457763672
Validation loss: 1.881061304000116

Epoch: 6| Step: 1
Training loss: 0.8794815540313721
Validation loss: 1.885255411107053

Epoch: 6| Step: 2
Training loss: 0.9503465890884399
Validation loss: 1.907947717174407

Epoch: 6| Step: 3
Training loss: 1.6256625652313232
Validation loss: 1.9097426732381184

Epoch: 6| Step: 4
Training loss: 1.0438365936279297
Validation loss: 1.9373092343730312

Epoch: 6| Step: 5
Training loss: 0.9189512729644775
Validation loss: 1.8979311450835197

Epoch: 6| Step: 6
Training loss: 1.1980094909667969
Validation loss: 1.8997478497925626

Epoch: 6| Step: 7
Training loss: 0.9375672936439514
Validation loss: 1.8489306434508292

Epoch: 6| Step: 8
Training loss: 0.9356286525726318
Validation loss: 1.8504749433968657

Epoch: 6| Step: 9
Training loss: 1.0383410453796387
Validation loss: 1.8355896472930908

Epoch: 6| Step: 10
Training loss: 0.8943385481834412
Validation loss: 1.8296818784488145

Epoch: 6| Step: 11
Training loss: 0.9766601324081421
Validation loss: 1.8386030274052774

Epoch: 6| Step: 12
Training loss: 0.5284461379051208
Validation loss: 1.8748443511224562

Epoch: 6| Step: 13
Training loss: 1.5941756963729858
Validation loss: 1.8983179356462212

Epoch: 259| Step: 0
Training loss: 0.9231558442115784
Validation loss: 1.935729003721668

Epoch: 6| Step: 1
Training loss: 1.0699257850646973
Validation loss: 1.9353124454457273

Epoch: 6| Step: 2
Training loss: 0.4956960082054138
Validation loss: 1.9194247338079637

Epoch: 6| Step: 3
Training loss: 1.0220129489898682
Validation loss: 1.9055633288557812

Epoch: 6| Step: 4
Training loss: 1.2178809642791748
Validation loss: 1.9039521730074318

Epoch: 6| Step: 5
Training loss: 0.9435214996337891
Validation loss: 1.9300244892797163

Epoch: 6| Step: 6
Training loss: 1.08339262008667
Validation loss: 1.9309454323143087

Epoch: 6| Step: 7
Training loss: 0.847937822341919
Validation loss: 1.945536300700198

Epoch: 6| Step: 8
Training loss: 1.4025603532791138
Validation loss: 1.940983610768472

Epoch: 6| Step: 9
Training loss: 1.087138056755066
Validation loss: 1.9183179075999925

Epoch: 6| Step: 10
Training loss: 0.8573105335235596
Validation loss: 1.907128401981887

Epoch: 6| Step: 11
Training loss: 0.9453054666519165
Validation loss: 1.8822238470918389

Epoch: 6| Step: 12
Training loss: 1.1283254623413086
Validation loss: 1.883933828723046

Epoch: 6| Step: 13
Training loss: 1.2397503852844238
Validation loss: 1.894600490088104

Epoch: 260| Step: 0
Training loss: 1.0708019733428955
Validation loss: 1.9001660500803301

Epoch: 6| Step: 1
Training loss: 1.8341537714004517
Validation loss: 1.943060387847244

Epoch: 6| Step: 2
Training loss: 0.7829017043113708
Validation loss: 1.9470012572503859

Epoch: 6| Step: 3
Training loss: 0.736515462398529
Validation loss: 1.9333915082357263

Epoch: 6| Step: 4
Training loss: 1.1564421653747559
Validation loss: 1.9111292887759466

Epoch: 6| Step: 5
Training loss: 0.9811973571777344
Validation loss: 1.8608337371580062

Epoch: 6| Step: 6
Training loss: 0.8917121291160583
Validation loss: 1.8588858266030588

Epoch: 6| Step: 7
Training loss: 1.0512317419052124
Validation loss: 1.853430535203667

Epoch: 6| Step: 8
Training loss: 1.3136199712753296
Validation loss: 1.852600428365892

Epoch: 6| Step: 9
Training loss: 0.585951030254364
Validation loss: 1.8648645826565322

Epoch: 6| Step: 10
Training loss: 0.7878763675689697
Validation loss: 1.8851614844414495

Epoch: 6| Step: 11
Training loss: 0.9473965764045715
Validation loss: 1.9407889971169092

Epoch: 6| Step: 12
Training loss: 1.0859434604644775
Validation loss: 1.9728454851335095

Epoch: 6| Step: 13
Training loss: 0.9454182386398315
Validation loss: 1.9783677272899176

Epoch: 261| Step: 0
Training loss: 0.8691755533218384
Validation loss: 1.9653841372459167

Epoch: 6| Step: 1
Training loss: 1.046252965927124
Validation loss: 1.9747482499768656

Epoch: 6| Step: 2
Training loss: 1.2289667129516602
Validation loss: 1.953348926318589

Epoch: 6| Step: 3
Training loss: 1.1609796285629272
Validation loss: 1.8904050242516302

Epoch: 6| Step: 4
Training loss: 0.8318060636520386
Validation loss: 1.8692760390620078

Epoch: 6| Step: 5
Training loss: 1.0439728498458862
Validation loss: 1.861223638698619

Epoch: 6| Step: 6
Training loss: 1.1099975109100342
Validation loss: 1.8448658168956797

Epoch: 6| Step: 7
Training loss: 0.9416358470916748
Validation loss: 1.8367156854239843

Epoch: 6| Step: 8
Training loss: 0.7454798221588135
Validation loss: 1.8381682031898088

Epoch: 6| Step: 9
Training loss: 1.5093227624893188
Validation loss: 1.8035165507306334

Epoch: 6| Step: 10
Training loss: 0.4989284574985504
Validation loss: 1.8298230350658458

Epoch: 6| Step: 11
Training loss: 0.9291325807571411
Validation loss: 1.867630773975003

Epoch: 6| Step: 12
Training loss: 0.6080377101898193
Validation loss: 1.8595654426082489

Epoch: 6| Step: 13
Training loss: 1.2580866813659668
Validation loss: 1.8913154550777969

Epoch: 262| Step: 0
Training loss: 1.1754977703094482
Validation loss: 1.868928260700677

Epoch: 6| Step: 1
Training loss: 1.1691962480545044
Validation loss: 1.8411715799762356

Epoch: 6| Step: 2
Training loss: 0.7781978845596313
Validation loss: 1.8431915403694235

Epoch: 6| Step: 3
Training loss: 1.1035985946655273
Validation loss: 1.8543732576472785

Epoch: 6| Step: 4
Training loss: 1.3795628547668457
Validation loss: 1.8464386578529113

Epoch: 6| Step: 5
Training loss: 0.8842000365257263
Validation loss: 1.8663320361926992

Epoch: 6| Step: 6
Training loss: 0.7753980159759521
Validation loss: 1.8938821925911853

Epoch: 6| Step: 7
Training loss: 0.728573739528656
Validation loss: 1.9114470661327403

Epoch: 6| Step: 8
Training loss: 1.0745635032653809
Validation loss: 1.8994347536435692

Epoch: 6| Step: 9
Training loss: 0.8321698904037476
Validation loss: 1.888641365112797

Epoch: 6| Step: 10
Training loss: 0.9883277416229248
Validation loss: 1.8896328717149713

Epoch: 6| Step: 11
Training loss: 0.9644112586975098
Validation loss: 1.889412958134887

Epoch: 6| Step: 12
Training loss: 0.8061199188232422
Validation loss: 1.870475826724883

Epoch: 6| Step: 13
Training loss: 0.6049697995185852
Validation loss: 1.8644576175238496

Epoch: 263| Step: 0
Training loss: 0.5954659581184387
Validation loss: 1.8263775558881863

Epoch: 6| Step: 1
Training loss: 0.84171462059021
Validation loss: 1.806340512409005

Epoch: 6| Step: 2
Training loss: 0.9820088744163513
Validation loss: 1.8618098407663324

Epoch: 6| Step: 3
Training loss: 1.008457064628601
Validation loss: 1.8339308077289211

Epoch: 6| Step: 4
Training loss: 0.6415473818778992
Validation loss: 1.8363359384639288

Epoch: 6| Step: 5
Training loss: 0.9146229028701782
Validation loss: 1.8506138478555987

Epoch: 6| Step: 6
Training loss: 1.2552695274353027
Validation loss: 1.858899502344029

Epoch: 6| Step: 7
Training loss: 0.7954964637756348
Validation loss: 1.8785257031840663

Epoch: 6| Step: 8
Training loss: 1.024332880973816
Validation loss: 1.9015681538530576

Epoch: 6| Step: 9
Training loss: 1.0472465753555298
Validation loss: 1.8915801048278809

Epoch: 6| Step: 10
Training loss: 0.8137705326080322
Validation loss: 1.882423250905929

Epoch: 6| Step: 11
Training loss: 0.7677638530731201
Validation loss: 1.8567658880705475

Epoch: 6| Step: 12
Training loss: 1.1797927618026733
Validation loss: 1.8646750232224822

Epoch: 6| Step: 13
Training loss: 1.1043932437896729
Validation loss: 1.8322422055787937

Epoch: 264| Step: 0
Training loss: 1.0836321115493774
Validation loss: 1.834378698820709

Epoch: 6| Step: 1
Training loss: 0.9129475355148315
Validation loss: 1.8113160646089943

Epoch: 6| Step: 2
Training loss: 1.2445068359375
Validation loss: 1.8273969747686898

Epoch: 6| Step: 3
Training loss: 0.8160170316696167
Validation loss: 1.8180338118665962

Epoch: 6| Step: 4
Training loss: 0.7897335290908813
Validation loss: 1.8554533784107496

Epoch: 6| Step: 5
Training loss: 0.8708846569061279
Validation loss: 1.8893894469866188

Epoch: 6| Step: 6
Training loss: 0.8170566558837891
Validation loss: 1.9350216593793643

Epoch: 6| Step: 7
Training loss: 1.1368911266326904
Validation loss: 1.9122368904852098

Epoch: 6| Step: 8
Training loss: 0.663952112197876
Validation loss: 1.8834395831631077

Epoch: 6| Step: 9
Training loss: 0.9893394112586975
Validation loss: 1.863278292840527

Epoch: 6| Step: 10
Training loss: 1.014526128768921
Validation loss: 1.8481238913792435

Epoch: 6| Step: 11
Training loss: 1.1038717031478882
Validation loss: 1.8423677323966898

Epoch: 6| Step: 12
Training loss: 0.7299245595932007
Validation loss: 1.8515429419855918

Epoch: 6| Step: 13
Training loss: 0.7900341749191284
Validation loss: 1.8532048040820706

Epoch: 265| Step: 0
Training loss: 0.7158462405204773
Validation loss: 1.8399147397728377

Epoch: 6| Step: 1
Training loss: 0.7718076705932617
Validation loss: 1.8472818046487787

Epoch: 6| Step: 2
Training loss: 0.975275993347168
Validation loss: 1.8550239096405685

Epoch: 6| Step: 3
Training loss: 1.2576813697814941
Validation loss: 1.855353488717028

Epoch: 6| Step: 4
Training loss: 0.3301578164100647
Validation loss: 1.8779148465843611

Epoch: 6| Step: 5
Training loss: 0.7276321053504944
Validation loss: 1.869786782931256

Epoch: 6| Step: 6
Training loss: 1.0719995498657227
Validation loss: 1.8434778362192132

Epoch: 6| Step: 7
Training loss: 0.8724081516265869
Validation loss: 1.8615627276000155

Epoch: 6| Step: 8
Training loss: 0.7464560270309448
Validation loss: 1.8500197138837589

Epoch: 6| Step: 9
Training loss: 0.8999438285827637
Validation loss: 1.882318881250197

Epoch: 6| Step: 10
Training loss: 0.5984688997268677
Validation loss: 1.8991417692553612

Epoch: 6| Step: 11
Training loss: 1.2074486017227173
Validation loss: 1.9178868609090005

Epoch: 6| Step: 12
Training loss: 1.4404704570770264
Validation loss: 1.9009636948185582

Epoch: 6| Step: 13
Training loss: 1.2412776947021484
Validation loss: 1.878477006830195

Epoch: 266| Step: 0
Training loss: 0.6342166066169739
Validation loss: 1.8487967829550467

Epoch: 6| Step: 1
Training loss: 1.1351704597473145
Validation loss: 1.8375016463700162

Epoch: 6| Step: 2
Training loss: 1.0247788429260254
Validation loss: 1.8701857456596949

Epoch: 6| Step: 3
Training loss: 0.9127797484397888
Validation loss: 1.8662736902954757

Epoch: 6| Step: 4
Training loss: 0.9999263286590576
Validation loss: 1.894650206770948

Epoch: 6| Step: 5
Training loss: 0.4703219532966614
Validation loss: 1.9038532677517142

Epoch: 6| Step: 6
Training loss: 1.2389533519744873
Validation loss: 1.9510081609090169

Epoch: 6| Step: 7
Training loss: 0.7923946380615234
Validation loss: 1.90909283455982

Epoch: 6| Step: 8
Training loss: 0.8147550225257874
Validation loss: 1.8994187834442302

Epoch: 6| Step: 9
Training loss: 0.9672039151191711
Validation loss: 1.846845789622235

Epoch: 6| Step: 10
Training loss: 1.0714328289031982
Validation loss: 1.8292953903957079

Epoch: 6| Step: 11
Training loss: 0.9134806394577026
Validation loss: 1.8309810353863625

Epoch: 6| Step: 12
Training loss: 1.05411958694458
Validation loss: 1.830637752368886

Epoch: 6| Step: 13
Training loss: 0.6388968229293823
Validation loss: 1.8190160835942915

Epoch: 267| Step: 0
Training loss: 0.441456139087677
Validation loss: 1.8420952379062612

Epoch: 6| Step: 1
Training loss: 0.5806723833084106
Validation loss: 1.8739172361230338

Epoch: 6| Step: 2
Training loss: 1.1231207847595215
Validation loss: 1.9132853336231683

Epoch: 6| Step: 3
Training loss: 0.9053794145584106
Validation loss: 1.8994987639047767

Epoch: 6| Step: 4
Training loss: 0.6427966952323914
Validation loss: 1.8995900692478302

Epoch: 6| Step: 5
Training loss: 0.73435378074646
Validation loss: 1.8786266132067608

Epoch: 6| Step: 6
Training loss: 0.9655145406723022
Validation loss: 1.8860661714307723

Epoch: 6| Step: 7
Training loss: 0.7169313430786133
Validation loss: 1.8593804387636081

Epoch: 6| Step: 8
Training loss: 0.8895666599273682
Validation loss: 1.862090168460723

Epoch: 6| Step: 9
Training loss: 1.1678634881973267
Validation loss: 1.847437899599793

Epoch: 6| Step: 10
Training loss: 1.0844300985336304
Validation loss: 1.8508296858879827

Epoch: 6| Step: 11
Training loss: 1.6811213493347168
Validation loss: 1.8333514377635012

Epoch: 6| Step: 12
Training loss: 0.7946840524673462
Validation loss: 1.8899385352288522

Epoch: 6| Step: 13
Training loss: 1.210835337638855
Validation loss: 1.8787744109348585

Epoch: 268| Step: 0
Training loss: 1.0593571662902832
Validation loss: 1.9442069761214718

Epoch: 6| Step: 1
Training loss: 1.103618860244751
Validation loss: 1.9673036016443723

Epoch: 6| Step: 2
Training loss: 0.9010498523712158
Validation loss: 1.9398618757083852

Epoch: 6| Step: 3
Training loss: 1.0061702728271484
Validation loss: 1.8581821969760361

Epoch: 6| Step: 4
Training loss: 0.7759480476379395
Validation loss: 1.8143924013260873

Epoch: 6| Step: 5
Training loss: 0.9281410574913025
Validation loss: 1.803005228760422

Epoch: 6| Step: 6
Training loss: 1.0157231092453003
Validation loss: 1.7844961202272804

Epoch: 6| Step: 7
Training loss: 1.0386645793914795
Validation loss: 1.7927055410159531

Epoch: 6| Step: 8
Training loss: 0.8033360242843628
Validation loss: 1.797995646794637

Epoch: 6| Step: 9
Training loss: 1.3413177728652954
Validation loss: 1.8077438582656205

Epoch: 6| Step: 10
Training loss: 1.1427552700042725
Validation loss: 1.8233613967895508

Epoch: 6| Step: 11
Training loss: 0.5052068829536438
Validation loss: 1.8250812599735875

Epoch: 6| Step: 12
Training loss: 1.3239277601242065
Validation loss: 1.92433718199371

Epoch: 6| Step: 13
Training loss: 0.5122864842414856
Validation loss: 2.000923487447923

Epoch: 269| Step: 0
Training loss: 1.3113930225372314
Validation loss: 2.088840059054795

Epoch: 6| Step: 1
Training loss: 1.6661930084228516
Validation loss: 2.122143469830995

Epoch: 6| Step: 2
Training loss: 0.8415558338165283
Validation loss: 2.0440310867883826

Epoch: 6| Step: 3
Training loss: 0.5445544719696045
Validation loss: 1.9406728500960975

Epoch: 6| Step: 4
Training loss: 0.5957437753677368
Validation loss: 1.8828581199851087

Epoch: 6| Step: 5
Training loss: 1.0507245063781738
Validation loss: 1.873473241765012

Epoch: 6| Step: 6
Training loss: 0.8131129741668701
Validation loss: 1.8199230073600687

Epoch: 6| Step: 7
Training loss: 1.1667442321777344
Validation loss: 1.8319971484522666

Epoch: 6| Step: 8
Training loss: 1.338857889175415
Validation loss: 1.8143096713609592

Epoch: 6| Step: 9
Training loss: 0.5916774868965149
Validation loss: 1.7947775266503776

Epoch: 6| Step: 10
Training loss: 0.7785235047340393
Validation loss: 1.7979350410481936

Epoch: 6| Step: 11
Training loss: 1.2594399452209473
Validation loss: 1.8193202916012015

Epoch: 6| Step: 12
Training loss: 0.9124597311019897
Validation loss: 1.8746599356333415

Epoch: 6| Step: 13
Training loss: 0.8031324148178101
Validation loss: 1.9496660258180352

Epoch: 270| Step: 0
Training loss: 1.2385238409042358
Validation loss: 1.9487248005405549

Epoch: 6| Step: 1
Training loss: 0.7687674164772034
Validation loss: 1.8727009847599974

Epoch: 6| Step: 2
Training loss: 0.5522618293762207
Validation loss: 1.8583318700072586

Epoch: 6| Step: 3
Training loss: 1.3414661884307861
Validation loss: 1.853122071553302

Epoch: 6| Step: 4
Training loss: 0.9054632782936096
Validation loss: 1.8404228482195126

Epoch: 6| Step: 5
Training loss: 0.8603971600532532
Validation loss: 1.883785774630885

Epoch: 6| Step: 6
Training loss: 0.4672308564186096
Validation loss: 1.881509521956085

Epoch: 6| Step: 7
Training loss: 1.0367627143859863
Validation loss: 1.931000849252106

Epoch: 6| Step: 8
Training loss: 1.1201536655426025
Validation loss: 1.9414452968105194

Epoch: 6| Step: 9
Training loss: 0.7874940633773804
Validation loss: 1.9403539601192679

Epoch: 6| Step: 10
Training loss: 0.9093218445777893
Validation loss: 1.9862953232180687

Epoch: 6| Step: 11
Training loss: 0.9897754192352295
Validation loss: 2.0034184981417913

Epoch: 6| Step: 12
Training loss: 0.9114992618560791
Validation loss: 1.9787755089421426

Epoch: 6| Step: 13
Training loss: 1.3769251108169556
Validation loss: 1.9357952046137985

Epoch: 271| Step: 0
Training loss: 0.7934379577636719
Validation loss: 1.9233743324074695

Epoch: 6| Step: 1
Training loss: 1.1787856817245483
Validation loss: 1.871880695384036

Epoch: 6| Step: 2
Training loss: 0.6687184572219849
Validation loss: 1.8213718783470891

Epoch: 6| Step: 3
Training loss: 1.1164718866348267
Validation loss: 1.8068784770145212

Epoch: 6| Step: 4
Training loss: 0.7990400791168213
Validation loss: 1.8061006530638664

Epoch: 6| Step: 5
Training loss: 0.8886755704879761
Validation loss: 1.7610161663383566

Epoch: 6| Step: 6
Training loss: 1.0504655838012695
Validation loss: 1.7737698272992206

Epoch: 6| Step: 7
Training loss: 0.8689711689949036
Validation loss: 1.7820627394542898

Epoch: 6| Step: 8
Training loss: 0.4673711657524109
Validation loss: 1.812246666159681

Epoch: 6| Step: 9
Training loss: 0.946069598197937
Validation loss: 1.799098249404661

Epoch: 6| Step: 10
Training loss: 1.0517137050628662
Validation loss: 1.857493108318698

Epoch: 6| Step: 11
Training loss: 0.7616147398948669
Validation loss: 1.877982859970421

Epoch: 6| Step: 12
Training loss: 1.1510193347930908
Validation loss: 1.9305736646857312

Epoch: 6| Step: 13
Training loss: 0.6467806696891785
Validation loss: 1.9191476747553835

Epoch: 272| Step: 0
Training loss: 0.692696213722229
Validation loss: 1.923697761310044

Epoch: 6| Step: 1
Training loss: 1.080119252204895
Validation loss: 1.8454094189469532

Epoch: 6| Step: 2
Training loss: 0.6353166103363037
Validation loss: 1.7927515340107743

Epoch: 6| Step: 3
Training loss: 0.5951848030090332
Validation loss: 1.763780686163133

Epoch: 6| Step: 4
Training loss: 1.1434369087219238
Validation loss: 1.7874144405447028

Epoch: 6| Step: 5
Training loss: 0.8979098796844482
Validation loss: 1.7745996764911118

Epoch: 6| Step: 6
Training loss: 0.6527442932128906
Validation loss: 1.7484447161356609

Epoch: 6| Step: 7
Training loss: 0.6688584089279175
Validation loss: 1.7760883262080531

Epoch: 6| Step: 8
Training loss: 1.270280361175537
Validation loss: 1.8064681304398404

Epoch: 6| Step: 9
Training loss: 1.016908884048462
Validation loss: 1.880743266433798

Epoch: 6| Step: 10
Training loss: 0.9571764469146729
Validation loss: 1.9604948579624135

Epoch: 6| Step: 11
Training loss: 1.002810001373291
Validation loss: 1.9574757442679456

Epoch: 6| Step: 12
Training loss: 1.1098666191101074
Validation loss: 1.899370329354399

Epoch: 6| Step: 13
Training loss: 1.0213218927383423
Validation loss: 1.8453176380485616

Epoch: 273| Step: 0
Training loss: 0.9621392488479614
Validation loss: 1.8168073072228381

Epoch: 6| Step: 1
Training loss: 0.622880220413208
Validation loss: 1.8158145566140451

Epoch: 6| Step: 2
Training loss: 1.0680322647094727
Validation loss: 1.8450290772222704

Epoch: 6| Step: 3
Training loss: 1.0167334079742432
Validation loss: 1.8450348556682628

Epoch: 6| Step: 4
Training loss: 0.651439368724823
Validation loss: 1.8248599306229623

Epoch: 6| Step: 5
Training loss: 0.9316829442977905
Validation loss: 1.8700362072196057

Epoch: 6| Step: 6
Training loss: 1.1362346410751343
Validation loss: 1.8846479462039085

Epoch: 6| Step: 7
Training loss: 1.1425966024398804
Validation loss: 1.89777091369834

Epoch: 6| Step: 8
Training loss: 0.42567580938339233
Validation loss: 1.9286965862397225

Epoch: 6| Step: 9
Training loss: 0.7491503953933716
Validation loss: 1.9325973295396375

Epoch: 6| Step: 10
Training loss: 0.7347723245620728
Validation loss: 1.9175292900813523

Epoch: 6| Step: 11
Training loss: 1.138549566268921
Validation loss: 1.8719918599692724

Epoch: 6| Step: 12
Training loss: 1.178976058959961
Validation loss: 1.8488540687868673

Epoch: 6| Step: 13
Training loss: 0.9943764805793762
Validation loss: 1.8153029552070044

Epoch: 274| Step: 0
Training loss: 1.2090777158737183
Validation loss: 1.7982203537417996

Epoch: 6| Step: 1
Training loss: 0.9068026542663574
Validation loss: 1.796921346777229

Epoch: 6| Step: 2
Training loss: 0.6402746438980103
Validation loss: 1.7810957226701962

Epoch: 6| Step: 3
Training loss: 0.990537703037262
Validation loss: 1.7685669878477692

Epoch: 6| Step: 4
Training loss: 0.5277160406112671
Validation loss: 1.7679973879168112

Epoch: 6| Step: 5
Training loss: 0.7660060524940491
Validation loss: 1.7927400771007742

Epoch: 6| Step: 6
Training loss: 0.42469021677970886
Validation loss: 1.8193445167233866

Epoch: 6| Step: 7
Training loss: 0.7496349811553955
Validation loss: 1.8105489823126024

Epoch: 6| Step: 8
Training loss: 0.9651092290878296
Validation loss: 1.8013552799019763

Epoch: 6| Step: 9
Training loss: 0.8880811333656311
Validation loss: 1.8145356947375881

Epoch: 6| Step: 10
Training loss: 1.0116965770721436
Validation loss: 1.8177548666154184

Epoch: 6| Step: 11
Training loss: 0.8678785562515259
Validation loss: 1.834158871763496

Epoch: 6| Step: 12
Training loss: 1.1182641983032227
Validation loss: 1.8389698779711159

Epoch: 6| Step: 13
Training loss: 0.5505699515342712
Validation loss: 1.8201989384107693

Epoch: 275| Step: 0
Training loss: 0.8060251474380493
Validation loss: 1.8226672334055747

Epoch: 6| Step: 1
Training loss: 0.6378476619720459
Validation loss: 1.8185184283923077

Epoch: 6| Step: 2
Training loss: 1.1387150287628174
Validation loss: 1.8371727710129113

Epoch: 6| Step: 3
Training loss: 0.8201954364776611
Validation loss: 1.822325683409168

Epoch: 6| Step: 4
Training loss: 0.6663762331008911
Validation loss: 1.8490973916105045

Epoch: 6| Step: 5
Training loss: 1.0994280576705933
Validation loss: 1.8436384136958788

Epoch: 6| Step: 6
Training loss: 0.8961689472198486
Validation loss: 1.85345184674827

Epoch: 6| Step: 7
Training loss: 0.5232439041137695
Validation loss: 1.8486305629053423

Epoch: 6| Step: 8
Training loss: 0.49868911504745483
Validation loss: 1.8356776968125375

Epoch: 6| Step: 9
Training loss: 0.6337154507637024
Validation loss: 1.828369653353127

Epoch: 6| Step: 10
Training loss: 1.3990646600723267
Validation loss: 1.8431779005194222

Epoch: 6| Step: 11
Training loss: 0.6550232172012329
Validation loss: 1.8270427270602154

Epoch: 6| Step: 12
Training loss: 0.9658020734786987
Validation loss: 1.8372983817131288

Epoch: 6| Step: 13
Training loss: 0.25978291034698486
Validation loss: 1.8041504198505032

Epoch: 276| Step: 0
Training loss: 0.7528634071350098
Validation loss: 1.8390180795423445

Epoch: 6| Step: 1
Training loss: 0.8650121688842773
Validation loss: 1.8297952477649977

Epoch: 6| Step: 2
Training loss: 0.3426957130432129
Validation loss: 1.840964323730879

Epoch: 6| Step: 3
Training loss: 1.008058786392212
Validation loss: 1.8661763770605928

Epoch: 6| Step: 4
Training loss: 0.8623292446136475
Validation loss: 1.8821301665357364

Epoch: 6| Step: 5
Training loss: 0.936315655708313
Validation loss: 1.8716063268723027

Epoch: 6| Step: 6
Training loss: 0.7555158734321594
Validation loss: 1.8905423764259583

Epoch: 6| Step: 7
Training loss: 1.3081353902816772
Validation loss: 1.8742367913646083

Epoch: 6| Step: 8
Training loss: 0.2956294119358063
Validation loss: 1.8717887299035185

Epoch: 6| Step: 9
Training loss: 0.7888145446777344
Validation loss: 1.8497850984655402

Epoch: 6| Step: 10
Training loss: 0.7188683748245239
Validation loss: 1.8413989313187138

Epoch: 6| Step: 11
Training loss: 1.0819361209869385
Validation loss: 1.8364829888907812

Epoch: 6| Step: 12
Training loss: 0.4965578317642212
Validation loss: 1.8365691015797276

Epoch: 6| Step: 13
Training loss: 0.9647570848464966
Validation loss: 1.787307434184577

Epoch: 277| Step: 0
Training loss: 0.5968084335327148
Validation loss: 1.792661307960428

Epoch: 6| Step: 1
Training loss: 0.9935407042503357
Validation loss: 1.7745938852269163

Epoch: 6| Step: 2
Training loss: 0.5880631804466248
Validation loss: 1.755736130540089

Epoch: 6| Step: 3
Training loss: 0.6909855604171753
Validation loss: 1.7371863626664685

Epoch: 6| Step: 4
Training loss: 0.9537690281867981
Validation loss: 1.7788791669312345

Epoch: 6| Step: 5
Training loss: 0.7682874798774719
Validation loss: 1.783244296427696

Epoch: 6| Step: 6
Training loss: 0.9331750869750977
Validation loss: 1.7559260783656951

Epoch: 6| Step: 7
Training loss: 0.8285501003265381
Validation loss: 1.7750053431398125

Epoch: 6| Step: 8
Training loss: 0.5354392528533936
Validation loss: 1.7589489875301239

Epoch: 6| Step: 9
Training loss: 1.2078654766082764
Validation loss: 1.7582925801636071

Epoch: 6| Step: 10
Training loss: 0.5942531228065491
Validation loss: 1.7724512571929603

Epoch: 6| Step: 11
Training loss: 0.5825002789497375
Validation loss: 1.7860032191840551

Epoch: 6| Step: 12
Training loss: 1.0506287813186646
Validation loss: 1.7913489316099434

Epoch: 6| Step: 13
Training loss: 0.701554000377655
Validation loss: 1.7890312774207002

Epoch: 278| Step: 0
Training loss: 0.8126944303512573
Validation loss: 1.7939525573484358

Epoch: 6| Step: 1
Training loss: 0.5825414061546326
Validation loss: 1.7794084215676913

Epoch: 6| Step: 2
Training loss: 0.7167012691497803
Validation loss: 1.7877230362225605

Epoch: 6| Step: 3
Training loss: 1.0029253959655762
Validation loss: 1.8131408332496561

Epoch: 6| Step: 4
Training loss: 0.8421662449836731
Validation loss: 1.7937471674334617

Epoch: 6| Step: 5
Training loss: 1.039729356765747
Validation loss: 1.7998608607117847

Epoch: 6| Step: 6
Training loss: 0.8756954073905945
Validation loss: 1.8159295640965945

Epoch: 6| Step: 7
Training loss: 0.5603199601173401
Validation loss: 1.8259821809748167

Epoch: 6| Step: 8
Training loss: 1.0296821594238281
Validation loss: 1.8151165349509126

Epoch: 6| Step: 9
Training loss: 0.7870184779167175
Validation loss: 1.8194439782891223

Epoch: 6| Step: 10
Training loss: 0.5515064597129822
Validation loss: 1.8221764615786973

Epoch: 6| Step: 11
Training loss: 0.5538392066955566
Validation loss: 1.806018070508075

Epoch: 6| Step: 12
Training loss: 0.7412719130516052
Validation loss: 1.7901911838080293

Epoch: 6| Step: 13
Training loss: 0.5989612340927124
Validation loss: 1.7797559307467552

Epoch: 279| Step: 0
Training loss: 0.5445333123207092
Validation loss: 1.78408920380377

Epoch: 6| Step: 1
Training loss: 0.6025871634483337
Validation loss: 1.7884264889583792

Epoch: 6| Step: 2
Training loss: 0.8354880809783936
Validation loss: 1.769385205161187

Epoch: 6| Step: 3
Training loss: 1.209172010421753
Validation loss: 1.788672935578131

Epoch: 6| Step: 4
Training loss: 0.944401204586029
Validation loss: 1.7883018511597828

Epoch: 6| Step: 5
Training loss: 0.35332024097442627
Validation loss: 1.7526026438641291

Epoch: 6| Step: 6
Training loss: 0.6942001581192017
Validation loss: 1.7679944153754943

Epoch: 6| Step: 7
Training loss: 0.9906261563301086
Validation loss: 1.7775692221938924

Epoch: 6| Step: 8
Training loss: 0.5261842012405396
Validation loss: 1.7543424842178181

Epoch: 6| Step: 9
Training loss: 0.7303537726402283
Validation loss: 1.7679193622322493

Epoch: 6| Step: 10
Training loss: 0.6569356322288513
Validation loss: 1.7548005939811788

Epoch: 6| Step: 11
Training loss: 0.7589148879051208
Validation loss: 1.7437419737538984

Epoch: 6| Step: 12
Training loss: 0.45684969425201416
Validation loss: 1.7402141876118158

Epoch: 6| Step: 13
Training loss: 1.5419328212738037
Validation loss: 1.757486561293243

Epoch: 280| Step: 0
Training loss: 0.6887062788009644
Validation loss: 1.7680134824527207

Epoch: 6| Step: 1
Training loss: 0.7291859984397888
Validation loss: 1.7692898383704565

Epoch: 6| Step: 2
Training loss: 0.762306272983551
Validation loss: 1.7689209856012815

Epoch: 6| Step: 3
Training loss: 0.8384428024291992
Validation loss: 1.7523518550780512

Epoch: 6| Step: 4
Training loss: 0.7887762784957886
Validation loss: 1.7818688577221287

Epoch: 6| Step: 5
Training loss: 0.8147600889205933
Validation loss: 1.7664992219658309

Epoch: 6| Step: 6
Training loss: 0.5827112197875977
Validation loss: 1.784874467439549

Epoch: 6| Step: 7
Training loss: 0.7571630477905273
Validation loss: 1.8158432360618346

Epoch: 6| Step: 8
Training loss: 0.5363414883613586
Validation loss: 1.8440257926141062

Epoch: 6| Step: 9
Training loss: 0.9234585165977478
Validation loss: 1.8316706124172415

Epoch: 6| Step: 10
Training loss: 0.9237048625946045
Validation loss: 1.836461595309678

Epoch: 6| Step: 11
Training loss: 0.7814352512359619
Validation loss: 1.8121333609345138

Epoch: 6| Step: 12
Training loss: 0.9225478172302246
Validation loss: 1.8447776994397562

Epoch: 6| Step: 13
Training loss: 0.3499528467655182
Validation loss: 1.8399225114494242

Epoch: 281| Step: 0
Training loss: 0.6828222274780273
Validation loss: 1.8220624269977692

Epoch: 6| Step: 1
Training loss: 0.6072832942008972
Validation loss: 1.8570406924011886

Epoch: 6| Step: 2
Training loss: 0.9246395826339722
Validation loss: 1.8731075563738424

Epoch: 6| Step: 3
Training loss: 0.7727195024490356
Validation loss: 1.8998067455907022

Epoch: 6| Step: 4
Training loss: 0.7464432716369629
Validation loss: 1.864587091630505

Epoch: 6| Step: 5
Training loss: 0.6111094951629639
Validation loss: 1.826359284821377

Epoch: 6| Step: 6
Training loss: 0.5131068229675293
Validation loss: 1.8129060640129993

Epoch: 6| Step: 7
Training loss: 0.9173359870910645
Validation loss: 1.801076163527786

Epoch: 6| Step: 8
Training loss: 0.8585811853408813
Validation loss: 1.8036151060494043

Epoch: 6| Step: 9
Training loss: 0.6496281027793884
Validation loss: 1.8184960657550442

Epoch: 6| Step: 10
Training loss: 0.9842649698257446
Validation loss: 1.8270234497644569

Epoch: 6| Step: 11
Training loss: 0.9311468601226807
Validation loss: 1.8215075769732076

Epoch: 6| Step: 12
Training loss: 0.7231448888778687
Validation loss: 1.8322154347614577

Epoch: 6| Step: 13
Training loss: 1.1810665130615234
Validation loss: 1.8730002962132937

Epoch: 282| Step: 0
Training loss: 0.6511903405189514
Validation loss: 1.855170867776358

Epoch: 6| Step: 1
Training loss: 1.315159559249878
Validation loss: 1.8407302133498653

Epoch: 6| Step: 2
Training loss: 1.1290608644485474
Validation loss: 1.7955182752301615

Epoch: 6| Step: 3
Training loss: 0.9288635849952698
Validation loss: 1.7856381554757395

Epoch: 6| Step: 4
Training loss: 0.6765495538711548
Validation loss: 1.7533697614105799

Epoch: 6| Step: 5
Training loss: 0.5371163487434387
Validation loss: 1.78115677320829

Epoch: 6| Step: 6
Training loss: 0.6813116073608398
Validation loss: 1.7590538276139127

Epoch: 6| Step: 7
Training loss: 0.6719950437545776
Validation loss: 1.74699447231908

Epoch: 6| Step: 8
Training loss: 0.33425286412239075
Validation loss: 1.7544008019149944

Epoch: 6| Step: 9
Training loss: 0.6543673872947693
Validation loss: 1.7904081203604256

Epoch: 6| Step: 10
Training loss: 0.7029212713241577
Validation loss: 1.7683901415076306

Epoch: 6| Step: 11
Training loss: 0.9954116344451904
Validation loss: 1.7950681935074508

Epoch: 6| Step: 12
Training loss: 0.40675631165504456
Validation loss: 1.7844988146135885

Epoch: 6| Step: 13
Training loss: 0.7500870227813721
Validation loss: 1.7668415064452796

Epoch: 283| Step: 0
Training loss: 0.6193003058433533
Validation loss: 1.7576435637730423

Epoch: 6| Step: 1
Training loss: 0.755923867225647
Validation loss: 1.743624041157384

Epoch: 6| Step: 2
Training loss: 0.837364673614502
Validation loss: 1.73999624483047

Epoch: 6| Step: 3
Training loss: 1.164905071258545
Validation loss: 1.7543098708634735

Epoch: 6| Step: 4
Training loss: 0.7593855857849121
Validation loss: 1.7657633712214809

Epoch: 6| Step: 5
Training loss: 0.5742666721343994
Validation loss: 1.763354605244052

Epoch: 6| Step: 6
Training loss: 0.8450134992599487
Validation loss: 1.7784639917394167

Epoch: 6| Step: 7
Training loss: 0.5652785301208496
Validation loss: 1.7814283242789648

Epoch: 6| Step: 8
Training loss: 0.8514492511749268
Validation loss: 1.8119179971756474

Epoch: 6| Step: 9
Training loss: 0.48400330543518066
Validation loss: 1.81222148992682

Epoch: 6| Step: 10
Training loss: 0.7029486894607544
Validation loss: 1.8043761099538496

Epoch: 6| Step: 11
Training loss: 0.5247126221656799
Validation loss: 1.7819214456824846

Epoch: 6| Step: 12
Training loss: 0.8243982791900635
Validation loss: 1.7677981738121278

Epoch: 6| Step: 13
Training loss: 0.6783927083015442
Validation loss: 1.768826921780904

Epoch: 284| Step: 0
Training loss: 1.0406508445739746
Validation loss: 1.7970846801675775

Epoch: 6| Step: 1
Training loss: 0.7144241333007812
Validation loss: 1.760946907022948

Epoch: 6| Step: 2
Training loss: 1.0790326595306396
Validation loss: 1.7988222696447884

Epoch: 6| Step: 3
Training loss: 0.692460298538208
Validation loss: 1.7762729108974498

Epoch: 6| Step: 4
Training loss: 0.8222345113754272
Validation loss: 1.7621675870751823

Epoch: 6| Step: 5
Training loss: 0.7478154897689819
Validation loss: 1.784278856810703

Epoch: 6| Step: 6
Training loss: 0.7169476747512817
Validation loss: 1.8023465807719896

Epoch: 6| Step: 7
Training loss: 0.6451104879379272
Validation loss: 1.822084847316947

Epoch: 6| Step: 8
Training loss: 0.547399640083313
Validation loss: 1.8116208404623053

Epoch: 6| Step: 9
Training loss: 0.5104469060897827
Validation loss: 1.8556503634299002

Epoch: 6| Step: 10
Training loss: 1.0985451936721802
Validation loss: 1.8539950001624323

Epoch: 6| Step: 11
Training loss: 0.43285417556762695
Validation loss: 1.8480477717614943

Epoch: 6| Step: 12
Training loss: 0.4939064681529999
Validation loss: 1.8446980368706487

Epoch: 6| Step: 13
Training loss: 0.9930095672607422
Validation loss: 1.79724887494118

Epoch: 285| Step: 0
Training loss: 0.7226065993309021
Validation loss: 1.776321259878015

Epoch: 6| Step: 1
Training loss: 0.9068973064422607
Validation loss: 1.7613042246910833

Epoch: 6| Step: 2
Training loss: 0.6220380067825317
Validation loss: 1.7709736900944864

Epoch: 6| Step: 3
Training loss: 0.581091582775116
Validation loss: 1.7776299407405238

Epoch: 6| Step: 4
Training loss: 0.8615049123764038
Validation loss: 1.7602646376497002

Epoch: 6| Step: 5
Training loss: 1.0687745809555054
Validation loss: 1.7406953598863335

Epoch: 6| Step: 6
Training loss: 0.5193226337432861
Validation loss: 1.735495372485089

Epoch: 6| Step: 7
Training loss: 0.7415562272071838
Validation loss: 1.7512516270401657

Epoch: 6| Step: 8
Training loss: 0.5882657170295715
Validation loss: 1.7508528040301414

Epoch: 6| Step: 9
Training loss: 0.7218437194824219
Validation loss: 1.7406724229935677

Epoch: 6| Step: 10
Training loss: 0.6175481677055359
Validation loss: 1.756416231073359

Epoch: 6| Step: 11
Training loss: 0.4446293115615845
Validation loss: 1.7733900816209855

Epoch: 6| Step: 12
Training loss: 0.8613887429237366
Validation loss: 1.8026987852588776

Epoch: 6| Step: 13
Training loss: 0.7761663198471069
Validation loss: 1.8085329276259228

Epoch: 286| Step: 0
Training loss: 0.45604294538497925
Validation loss: 1.81526618747301

Epoch: 6| Step: 1
Training loss: 0.8063149452209473
Validation loss: 1.7995760030643915

Epoch: 6| Step: 2
Training loss: 0.8295780420303345
Validation loss: 1.7934803334615563

Epoch: 6| Step: 3
Training loss: 0.8286195397377014
Validation loss: 1.797243595123291

Epoch: 6| Step: 4
Training loss: 0.6656866669654846
Validation loss: 1.7947818938122

Epoch: 6| Step: 5
Training loss: 0.5518925189971924
Validation loss: 1.7763070175724645

Epoch: 6| Step: 6
Training loss: 0.802093505859375
Validation loss: 1.7656726209066247

Epoch: 6| Step: 7
Training loss: 0.532141923904419
Validation loss: 1.7697141965230305

Epoch: 6| Step: 8
Training loss: 0.5984779596328735
Validation loss: 1.7875824589883127

Epoch: 6| Step: 9
Training loss: 0.6714346408843994
Validation loss: 1.7736196261580273

Epoch: 6| Step: 10
Training loss: 0.634719967842102
Validation loss: 1.7772549070337766

Epoch: 6| Step: 11
Training loss: 0.9086546301841736
Validation loss: 1.7823997351431078

Epoch: 6| Step: 12
Training loss: 0.940845251083374
Validation loss: 1.7647629335362425

Epoch: 6| Step: 13
Training loss: 1.0124379396438599
Validation loss: 1.7516199824630574

Epoch: 287| Step: 0
Training loss: 0.42072534561157227
Validation loss: 1.7537745160441245

Epoch: 6| Step: 1
Training loss: 0.844418466091156
Validation loss: 1.7684926422693397

Epoch: 6| Step: 2
Training loss: 0.910765528678894
Validation loss: 1.7491357916144914

Epoch: 6| Step: 3
Training loss: 0.7634338140487671
Validation loss: 1.7783346714511994

Epoch: 6| Step: 4
Training loss: 0.5471618175506592
Validation loss: 1.7481359845848494

Epoch: 6| Step: 5
Training loss: 0.8602569103240967
Validation loss: 1.7579466630053777

Epoch: 6| Step: 6
Training loss: 0.8533868789672852
Validation loss: 1.7652752707081456

Epoch: 6| Step: 7
Training loss: 0.6133540868759155
Validation loss: 1.7745626562385148

Epoch: 6| Step: 8
Training loss: 0.775810956954956
Validation loss: 1.7848628285110637

Epoch: 6| Step: 9
Training loss: 0.5412046909332275
Validation loss: 1.8192913750166535

Epoch: 6| Step: 10
Training loss: 0.7754755020141602
Validation loss: 1.822198889588797

Epoch: 6| Step: 11
Training loss: 0.9302338361740112
Validation loss: 1.8091003805078485

Epoch: 6| Step: 12
Training loss: 0.3799806535243988
Validation loss: 1.788584578421808

Epoch: 6| Step: 13
Training loss: 0.9879485368728638
Validation loss: 1.813906882398872

Epoch: 288| Step: 0
Training loss: 0.461764931678772
Validation loss: 1.799423679228752

Epoch: 6| Step: 1
Training loss: 0.8654388189315796
Validation loss: 1.7869582022390058

Epoch: 6| Step: 2
Training loss: 0.8826337456703186
Validation loss: 1.7930911740949076

Epoch: 6| Step: 3
Training loss: 0.618653416633606
Validation loss: 1.7718403441931612

Epoch: 6| Step: 4
Training loss: 1.0279000997543335
Validation loss: 1.76742588063722

Epoch: 6| Step: 5
Training loss: 0.8148102760314941
Validation loss: 1.7627705732981365

Epoch: 6| Step: 6
Training loss: 0.4762836694717407
Validation loss: 1.769495460294908

Epoch: 6| Step: 7
Training loss: 0.5113185048103333
Validation loss: 1.7608315662671161

Epoch: 6| Step: 8
Training loss: 0.897716760635376
Validation loss: 1.7594394453110234

Epoch: 6| Step: 9
Training loss: 0.5964553356170654
Validation loss: 1.753402848397532

Epoch: 6| Step: 10
Training loss: 0.6539865732192993
Validation loss: 1.7468215188672465

Epoch: 6| Step: 11
Training loss: 0.6219622492790222
Validation loss: 1.7678112829885175

Epoch: 6| Step: 12
Training loss: 0.7653725743293762
Validation loss: 1.7559122423971854

Epoch: 6| Step: 13
Training loss: 0.5868344902992249
Validation loss: 1.7891735581941501

Epoch: 289| Step: 0
Training loss: 0.9261446595191956
Validation loss: 1.7935982019670549

Epoch: 6| Step: 1
Training loss: 0.5591930747032166
Validation loss: 1.8164663686547229

Epoch: 6| Step: 2
Training loss: 0.7731794714927673
Validation loss: 1.8120121673871112

Epoch: 6| Step: 3
Training loss: 0.9179585576057434
Validation loss: 1.7924926242520731

Epoch: 6| Step: 4
Training loss: 0.6434042453765869
Validation loss: 1.7868841386610461

Epoch: 6| Step: 5
Training loss: 0.6918023228645325
Validation loss: 1.7833522494121263

Epoch: 6| Step: 6
Training loss: 0.5518787503242493
Validation loss: 1.8038292674608127

Epoch: 6| Step: 7
Training loss: 0.8465625047683716
Validation loss: 1.7957806138582126

Epoch: 6| Step: 8
Training loss: 0.8378647565841675
Validation loss: 1.8013814982547556

Epoch: 6| Step: 9
Training loss: 0.5858220458030701
Validation loss: 1.7996441292506393

Epoch: 6| Step: 10
Training loss: 0.7484772801399231
Validation loss: 1.8161328595171693

Epoch: 6| Step: 11
Training loss: 0.538891613483429
Validation loss: 1.798715522212367

Epoch: 6| Step: 12
Training loss: 0.843593955039978
Validation loss: 1.7969169796154063

Epoch: 6| Step: 13
Training loss: 0.6308301687240601
Validation loss: 1.783764418735299

Epoch: 290| Step: 0
Training loss: 0.5926340818405151
Validation loss: 1.8040572379225044

Epoch: 6| Step: 1
Training loss: 1.2198759317398071
Validation loss: 1.7847789833622594

Epoch: 6| Step: 2
Training loss: 0.6292406320571899
Validation loss: 1.7680442166584793

Epoch: 6| Step: 3
Training loss: 0.6765514612197876
Validation loss: 1.7659351248894968

Epoch: 6| Step: 4
Training loss: 0.9684317708015442
Validation loss: 1.75131118682123

Epoch: 6| Step: 5
Training loss: 0.700713574886322
Validation loss: 1.7592608492861512

Epoch: 6| Step: 6
Training loss: 0.2664850056171417
Validation loss: 1.772393991870265

Epoch: 6| Step: 7
Training loss: 0.958798885345459
Validation loss: 1.7828618326494772

Epoch: 6| Step: 8
Training loss: 0.6559933423995972
Validation loss: 1.787726927829045

Epoch: 6| Step: 9
Training loss: 0.36416155099868774
Validation loss: 1.8088482708059332

Epoch: 6| Step: 10
Training loss: 0.5261057019233704
Validation loss: 1.7927736518203572

Epoch: 6| Step: 11
Training loss: 0.5542763471603394
Validation loss: 1.8239350549636348

Epoch: 6| Step: 12
Training loss: 0.9280434846878052
Validation loss: 1.829705422924411

Epoch: 6| Step: 13
Training loss: 0.49069732427597046
Validation loss: 1.8442091300923338

Epoch: 291| Step: 0
Training loss: 0.8824341297149658
Validation loss: 1.8552246888478596

Epoch: 6| Step: 1
Training loss: 0.6689413785934448
Validation loss: 1.8391162721059655

Epoch: 6| Step: 2
Training loss: 0.3170388340950012
Validation loss: 1.7659699942476006

Epoch: 6| Step: 3
Training loss: 0.522442102432251
Validation loss: 1.7485568331133934

Epoch: 6| Step: 4
Training loss: 0.648242712020874
Validation loss: 1.7299242455472228

Epoch: 6| Step: 5
Training loss: 0.3677949607372284
Validation loss: 1.7141551202343357

Epoch: 6| Step: 6
Training loss: 1.0808100700378418
Validation loss: 1.7307832946059525

Epoch: 6| Step: 7
Training loss: 0.6854151487350464
Validation loss: 1.7016743831737067

Epoch: 6| Step: 8
Training loss: 0.8940243721008301
Validation loss: 1.7259744751837947

Epoch: 6| Step: 9
Training loss: 0.6237465739250183
Validation loss: 1.7166020190843971

Epoch: 6| Step: 10
Training loss: 0.6877888441085815
Validation loss: 1.7181618777654504

Epoch: 6| Step: 11
Training loss: 0.906487226486206
Validation loss: 1.7551299936027938

Epoch: 6| Step: 12
Training loss: 0.9662067294120789
Validation loss: 1.7554957892305108

Epoch: 6| Step: 13
Training loss: 0.1293429285287857
Validation loss: 1.7716887740678684

Epoch: 292| Step: 0
Training loss: 0.7444256544113159
Validation loss: 1.7711751435392646

Epoch: 6| Step: 1
Training loss: 0.6667906641960144
Validation loss: 1.7797362009684246

Epoch: 6| Step: 2
Training loss: 0.5060045719146729
Validation loss: 1.7965368115773765

Epoch: 6| Step: 3
Training loss: 0.6927267909049988
Validation loss: 1.8090598211493543

Epoch: 6| Step: 4
Training loss: 0.6308250427246094
Validation loss: 1.8268496580021356

Epoch: 6| Step: 5
Training loss: 0.8221967220306396
Validation loss: 1.7981918857943626

Epoch: 6| Step: 6
Training loss: 0.4801796078681946
Validation loss: 1.8521258202932214

Epoch: 6| Step: 7
Training loss: 0.9141742587089539
Validation loss: 1.88665432571083

Epoch: 6| Step: 8
Training loss: 0.5735622048377991
Validation loss: 1.8370560305092924

Epoch: 6| Step: 9
Training loss: 0.6927841901779175
Validation loss: 1.8091375827789307

Epoch: 6| Step: 10
Training loss: 0.9467581510543823
Validation loss: 1.7900300654031898

Epoch: 6| Step: 11
Training loss: 0.6860305070877075
Validation loss: 1.7857764215879544

Epoch: 6| Step: 12
Training loss: 0.7097229361534119
Validation loss: 1.770999808465281

Epoch: 6| Step: 13
Training loss: 0.5268276929855347
Validation loss: 1.743305649808658

Epoch: 293| Step: 0
Training loss: 0.7416286468505859
Validation loss: 1.7460689954860236

Epoch: 6| Step: 1
Training loss: 0.5869451761245728
Validation loss: 1.7615023620666996

Epoch: 6| Step: 2
Training loss: 0.5061706304550171
Validation loss: 1.7290454705556233

Epoch: 6| Step: 3
Training loss: 0.44926953315734863
Validation loss: 1.729840660607943

Epoch: 6| Step: 4
Training loss: 0.5111345648765564
Validation loss: 1.7291105158867375

Epoch: 6| Step: 5
Training loss: 0.6791945695877075
Validation loss: 1.726945939884391

Epoch: 6| Step: 6
Training loss: 0.7329096794128418
Validation loss: 1.754818070319391

Epoch: 6| Step: 7
Training loss: 0.7720416784286499
Validation loss: 1.7574494487495833

Epoch: 6| Step: 8
Training loss: 0.6199350357055664
Validation loss: 1.7576192463597944

Epoch: 6| Step: 9
Training loss: 0.8142081499099731
Validation loss: 1.7587242305919688

Epoch: 6| Step: 10
Training loss: 0.687202513217926
Validation loss: 1.7451237260654409

Epoch: 6| Step: 11
Training loss: 0.5681202411651611
Validation loss: 1.7390679531199957

Epoch: 6| Step: 12
Training loss: 0.7803622484207153
Validation loss: 1.7242933652734245

Epoch: 6| Step: 13
Training loss: 0.8402557969093323
Validation loss: 1.7435693484480663

Epoch: 294| Step: 0
Training loss: 1.1998381614685059
Validation loss: 1.7144484404594666

Epoch: 6| Step: 1
Training loss: 0.35857999324798584
Validation loss: 1.7620184652266964

Epoch: 6| Step: 2
Training loss: 0.6646453142166138
Validation loss: 1.746540904045105

Epoch: 6| Step: 3
Training loss: 0.8980415463447571
Validation loss: 1.7851899029106222

Epoch: 6| Step: 4
Training loss: 0.4381116032600403
Validation loss: 1.8063573555279804

Epoch: 6| Step: 5
Training loss: 0.752984881401062
Validation loss: 1.7908727045982116

Epoch: 6| Step: 6
Training loss: 0.4265187084674835
Validation loss: 1.7791478749244445

Epoch: 6| Step: 7
Training loss: 0.7699723243713379
Validation loss: 1.7531851055801555

Epoch: 6| Step: 8
Training loss: 0.5733655095100403
Validation loss: 1.7289649196850356

Epoch: 6| Step: 9
Training loss: 0.7005321383476257
Validation loss: 1.7522164198660082

Epoch: 6| Step: 10
Training loss: 0.6138718128204346
Validation loss: 1.7343086568258141

Epoch: 6| Step: 11
Training loss: 0.5480611324310303
Validation loss: 1.7381574184663835

Epoch: 6| Step: 12
Training loss: 0.6566392183303833
Validation loss: 1.764272323218725

Epoch: 6| Step: 13
Training loss: 0.43036365509033203
Validation loss: 1.76453451571926

Epoch: 295| Step: 0
Training loss: 0.46653008460998535
Validation loss: 1.7801445453397688

Epoch: 6| Step: 1
Training loss: 0.47889280319213867
Validation loss: 1.8026425774379442

Epoch: 6| Step: 2
Training loss: 0.47725236415863037
Validation loss: 1.8076000905806018

Epoch: 6| Step: 3
Training loss: 1.1277616024017334
Validation loss: 1.8048850695292156

Epoch: 6| Step: 4
Training loss: 0.7941179275512695
Validation loss: 1.7999199173783744

Epoch: 6| Step: 5
Training loss: 0.8524048328399658
Validation loss: 1.7762886676737057

Epoch: 6| Step: 6
Training loss: 0.950620710849762
Validation loss: 1.7960088381203272

Epoch: 6| Step: 7
Training loss: 0.8301067352294922
Validation loss: 1.803536069008612

Epoch: 6| Step: 8
Training loss: 0.5430738925933838
Validation loss: 1.7923401735162223

Epoch: 6| Step: 9
Training loss: 0.6501505374908447
Validation loss: 1.7887475285478818

Epoch: 6| Step: 10
Training loss: 0.4122152030467987
Validation loss: 1.805477858871542

Epoch: 6| Step: 11
Training loss: 0.2851702570915222
Validation loss: 1.8072410937278502

Epoch: 6| Step: 12
Training loss: 0.5439648628234863
Validation loss: 1.7803257255144016

Epoch: 6| Step: 13
Training loss: 0.4571848511695862
Validation loss: 1.7814565666260258

Epoch: 296| Step: 0
Training loss: 0.553375244140625
Validation loss: 1.7514476596668203

Epoch: 6| Step: 1
Training loss: 0.5349533557891846
Validation loss: 1.7512036882421023

Epoch: 6| Step: 2
Training loss: 0.428006112575531
Validation loss: 1.7548007093450075

Epoch: 6| Step: 3
Training loss: 0.8465940952301025
Validation loss: 1.7624519114853234

Epoch: 6| Step: 4
Training loss: 0.7498667240142822
Validation loss: 1.7717206837028585

Epoch: 6| Step: 5
Training loss: 0.7146241664886475
Validation loss: 1.7770352773768927

Epoch: 6| Step: 6
Training loss: 0.5747284293174744
Validation loss: 1.7721395992463636

Epoch: 6| Step: 7
Training loss: 0.5046952962875366
Validation loss: 1.7834124180578417

Epoch: 6| Step: 8
Training loss: 0.5206259489059448
Validation loss: 1.7596912435306016

Epoch: 6| Step: 9
Training loss: 0.5095786452293396
Validation loss: 1.7372512009836012

Epoch: 6| Step: 10
Training loss: 0.7778182029724121
Validation loss: 1.7521532812426168

Epoch: 6| Step: 11
Training loss: 0.49442338943481445
Validation loss: 1.7477736883265997

Epoch: 6| Step: 12
Training loss: 0.6987358331680298
Validation loss: 1.7670793597416212

Epoch: 6| Step: 13
Training loss: 0.9649948477745056
Validation loss: 1.7777075049697713

Epoch: 297| Step: 0
Training loss: 0.5962734222412109
Validation loss: 1.8219285344564786

Epoch: 6| Step: 1
Training loss: 0.4862338900566101
Validation loss: 1.8069912182387484

Epoch: 6| Step: 2
Training loss: 0.3627919852733612
Validation loss: 1.762996114710326

Epoch: 6| Step: 3
Training loss: 0.8077301383018494
Validation loss: 1.745916446050008

Epoch: 6| Step: 4
Training loss: 0.9001777768135071
Validation loss: 1.7125649247118222

Epoch: 6| Step: 5
Training loss: 0.7862266302108765
Validation loss: 1.7294372294538765

Epoch: 6| Step: 6
Training loss: 0.3422527313232422
Validation loss: 1.7450125114892119

Epoch: 6| Step: 7
Training loss: 0.49816519021987915
Validation loss: 1.767173595325921

Epoch: 6| Step: 8
Training loss: 0.6231783032417297
Validation loss: 1.7595440162125455

Epoch: 6| Step: 9
Training loss: 0.3289077579975128
Validation loss: 1.7667634653788742

Epoch: 6| Step: 10
Training loss: 1.027897596359253
Validation loss: 1.7424767683911067

Epoch: 6| Step: 11
Training loss: 0.6370388269424438
Validation loss: 1.716065505499481

Epoch: 6| Step: 12
Training loss: 0.8872489333152771
Validation loss: 1.7245703525440668

Epoch: 6| Step: 13
Training loss: 0.7178357839584351
Validation loss: 1.7270125753136092

Epoch: 298| Step: 0
Training loss: 0.4396643340587616
Validation loss: 1.7416214481476815

Epoch: 6| Step: 1
Training loss: 0.5601440072059631
Validation loss: 1.7472987456988263

Epoch: 6| Step: 2
Training loss: 0.36410120129585266
Validation loss: 1.7655539384452246

Epoch: 6| Step: 3
Training loss: 0.5517433285713196
Validation loss: 1.7475599255613101

Epoch: 6| Step: 4
Training loss: 0.35533517599105835
Validation loss: 1.792426871997054

Epoch: 6| Step: 5
Training loss: 0.8473247289657593
Validation loss: 1.8244951463514758

Epoch: 6| Step: 6
Training loss: 0.9599472880363464
Validation loss: 1.8743449141902309

Epoch: 6| Step: 7
Training loss: 0.5145045518875122
Validation loss: 1.8738713866920882

Epoch: 6| Step: 8
Training loss: 0.9630695581436157
Validation loss: 1.850136044204876

Epoch: 6| Step: 9
Training loss: 0.8953869342803955
Validation loss: 1.796103846642279

Epoch: 6| Step: 10
Training loss: 0.4632440209388733
Validation loss: 1.7713085156615063

Epoch: 6| Step: 11
Training loss: 0.932252824306488
Validation loss: 1.7685620272031395

Epoch: 6| Step: 12
Training loss: 1.1663756370544434
Validation loss: 1.7827891726647653

Epoch: 6| Step: 13
Training loss: 0.7086195945739746
Validation loss: 1.769440504812425

Epoch: 299| Step: 0
Training loss: 0.8125420808792114
Validation loss: 1.7450430444491807

Epoch: 6| Step: 1
Training loss: 0.6637892723083496
Validation loss: 1.784143715776423

Epoch: 6| Step: 2
Training loss: 0.5369999408721924
Validation loss: 1.8122417426878406

Epoch: 6| Step: 3
Training loss: 0.4411080479621887
Validation loss: 1.7913636046071206

Epoch: 6| Step: 4
Training loss: 0.6813395023345947
Validation loss: 1.801642862699365

Epoch: 6| Step: 5
Training loss: 0.7743432521820068
Validation loss: 1.8084877921688942

Epoch: 6| Step: 6
Training loss: 0.16585735976696014
Validation loss: 1.8160797908741941

Epoch: 6| Step: 7
Training loss: 0.6690381765365601
Validation loss: 1.8045520513288436

Epoch: 6| Step: 8
Training loss: 0.5836954116821289
Validation loss: 1.8033480759589904

Epoch: 6| Step: 9
Training loss: 0.7011844515800476
Validation loss: 1.789082593815301

Epoch: 6| Step: 10
Training loss: 1.364414930343628
Validation loss: 1.7826166614409416

Epoch: 6| Step: 11
Training loss: 0.6696348786354065
Validation loss: 1.806026497835754

Epoch: 6| Step: 12
Training loss: 0.633346438407898
Validation loss: 1.8091908603586175

Epoch: 6| Step: 13
Training loss: 0.8700363636016846
Validation loss: 1.8475335157045754

Epoch: 300| Step: 0
Training loss: 0.5202114582061768
Validation loss: 1.8407313913427374

Epoch: 6| Step: 1
Training loss: 0.8817554116249084
Validation loss: 1.8728325930974816

Epoch: 6| Step: 2
Training loss: 0.7464143633842468
Validation loss: 1.8164181888744395

Epoch: 6| Step: 3
Training loss: 0.6208135485649109
Validation loss: 1.817795112568845

Epoch: 6| Step: 4
Training loss: 0.7293381690979004
Validation loss: 1.7506923983173985

Epoch: 6| Step: 5
Training loss: 0.62562096118927
Validation loss: 1.739356360127849

Epoch: 6| Step: 6
Training loss: 0.44168737530708313
Validation loss: 1.7507619742424256

Epoch: 6| Step: 7
Training loss: 0.6902652382850647
Validation loss: 1.7909655071073962

Epoch: 6| Step: 8
Training loss: 0.6773130893707275
Validation loss: 1.8118818370244836

Epoch: 6| Step: 9
Training loss: 0.7597575187683105
Validation loss: 1.7861130865671302

Epoch: 6| Step: 10
Training loss: 0.7067493200302124
Validation loss: 1.7896646632943103

Epoch: 6| Step: 11
Training loss: 0.5890055894851685
Validation loss: 1.800389652611107

Epoch: 6| Step: 12
Training loss: 0.832572340965271
Validation loss: 1.8603146922203802

Epoch: 6| Step: 13
Training loss: 0.7214340567588806
Validation loss: 1.8980499441905687

Epoch: 301| Step: 0
Training loss: 0.43282538652420044
Validation loss: 1.8911381126731954

Epoch: 6| Step: 1
Training loss: 0.76189124584198
Validation loss: 1.8167950261023738

Epoch: 6| Step: 2
Training loss: 0.6993895173072815
Validation loss: 1.7691066149742372

Epoch: 6| Step: 3
Training loss: 0.5637450218200684
Validation loss: 1.750140296515598

Epoch: 6| Step: 4
Training loss: 0.6077014207839966
Validation loss: 1.7108968496322632

Epoch: 6| Step: 5
Training loss: 0.5909610986709595
Validation loss: 1.7628145076895272

Epoch: 6| Step: 6
Training loss: 0.3680001497268677
Validation loss: 1.7579699306077854

Epoch: 6| Step: 7
Training loss: 0.6316498517990112
Validation loss: 1.764466384405731

Epoch: 6| Step: 8
Training loss: 0.6308294534683228
Validation loss: 1.8009048110695296

Epoch: 6| Step: 9
Training loss: 1.044687271118164
Validation loss: 1.8131545820543844

Epoch: 6| Step: 10
Training loss: 0.6275166273117065
Validation loss: 1.7937899545956684

Epoch: 6| Step: 11
Training loss: 0.7638901472091675
Validation loss: 1.8248808819760558

Epoch: 6| Step: 12
Training loss: 0.4982303977012634
Validation loss: 1.7790882202886766

Epoch: 6| Step: 13
Training loss: 0.8825204372406006
Validation loss: 1.7722211845459477

Epoch: 302| Step: 0
Training loss: 0.6036296486854553
Validation loss: 1.7651898014929988

Epoch: 6| Step: 1
Training loss: 0.3668856620788574
Validation loss: 1.7378600951164

Epoch: 6| Step: 2
Training loss: 0.5843738317489624
Validation loss: 1.7452546614472584

Epoch: 6| Step: 3
Training loss: 0.4765623211860657
Validation loss: 1.7380589310840895

Epoch: 6| Step: 4
Training loss: 0.4710516631603241
Validation loss: 1.7329434963964647

Epoch: 6| Step: 5
Training loss: 0.7822847962379456
Validation loss: 1.707776750287702

Epoch: 6| Step: 6
Training loss: 0.570925235748291
Validation loss: 1.7058773322771954

Epoch: 6| Step: 7
Training loss: 0.6409733295440674
Validation loss: 1.7136985384007937

Epoch: 6| Step: 8
Training loss: 0.6098366379737854
Validation loss: 1.7576792829780168

Epoch: 6| Step: 9
Training loss: 0.6380441188812256
Validation loss: 1.7575960736120901

Epoch: 6| Step: 10
Training loss: 0.5007132291793823
Validation loss: 1.7786144992356658

Epoch: 6| Step: 11
Training loss: 0.732616662979126
Validation loss: 1.7851608363530969

Epoch: 6| Step: 12
Training loss: 0.5303974747657776
Validation loss: 1.8012292974738664

Epoch: 6| Step: 13
Training loss: 0.6993355751037598
Validation loss: 1.8025411405870992

Epoch: 303| Step: 0
Training loss: 0.6209428310394287
Validation loss: 1.8244549407753894

Epoch: 6| Step: 1
Training loss: 0.2646740674972534
Validation loss: 1.8029619852701824

Epoch: 6| Step: 2
Training loss: 0.45882290601730347
Validation loss: 1.798221395861718

Epoch: 6| Step: 3
Training loss: 0.5010639429092407
Validation loss: 1.787313630503993

Epoch: 6| Step: 4
Training loss: 0.5967503190040588
Validation loss: 1.7579340934753418

Epoch: 6| Step: 5
Training loss: 0.669265627861023
Validation loss: 1.7505850484294276

Epoch: 6| Step: 6
Training loss: 0.9655251502990723
Validation loss: 1.7677257214823077

Epoch: 6| Step: 7
Training loss: 0.6465169191360474
Validation loss: 1.7579624755408174

Epoch: 6| Step: 8
Training loss: 0.4741356074810028
Validation loss: 1.731482203288745

Epoch: 6| Step: 9
Training loss: 0.4359385371208191
Validation loss: 1.7531310730083014

Epoch: 6| Step: 10
Training loss: 0.7069790959358215
Validation loss: 1.7377979447764735

Epoch: 6| Step: 11
Training loss: 0.6736147403717041
Validation loss: 1.7428485847288562

Epoch: 6| Step: 12
Training loss: 0.45190417766571045
Validation loss: 1.7579252873697588

Epoch: 6| Step: 13
Training loss: 0.8597519397735596
Validation loss: 1.7741778178881573

Epoch: 304| Step: 0
Training loss: 0.4083365201950073
Validation loss: 1.751051745107097

Epoch: 6| Step: 1
Training loss: 0.5961889028549194
Validation loss: 1.7719634117618683

Epoch: 6| Step: 2
Training loss: 0.8803536295890808
Validation loss: 1.751058893819009

Epoch: 6| Step: 3
Training loss: 0.3880079388618469
Validation loss: 1.7531555878218783

Epoch: 6| Step: 4
Training loss: 0.5044944882392883
Validation loss: 1.749814970518953

Epoch: 6| Step: 5
Training loss: 0.38758111000061035
Validation loss: 1.7370344336314867

Epoch: 6| Step: 6
Training loss: 0.6455873847007751
Validation loss: 1.748920606028649

Epoch: 6| Step: 7
Training loss: 0.6273729205131531
Validation loss: 1.7612938201555641

Epoch: 6| Step: 8
Training loss: 0.43593156337738037
Validation loss: 1.7408531942675192

Epoch: 6| Step: 9
Training loss: 0.9595338106155396
Validation loss: 1.750203005729183

Epoch: 6| Step: 10
Training loss: 0.5186160802841187
Validation loss: 1.753297132830466

Epoch: 6| Step: 11
Training loss: 0.7198052406311035
Validation loss: 1.7675793017110517

Epoch: 6| Step: 12
Training loss: 0.631527304649353
Validation loss: 1.7336425729977187

Epoch: 6| Step: 13
Training loss: 0.7911743521690369
Validation loss: 1.752508597989236

Epoch: 305| Step: 0
Training loss: 1.0700347423553467
Validation loss: 1.7723191797092397

Epoch: 6| Step: 1
Training loss: 0.4299105107784271
Validation loss: 1.7457233744282876

Epoch: 6| Step: 2
Training loss: 0.7106117010116577
Validation loss: 1.7631439726839784

Epoch: 6| Step: 3
Training loss: 0.28681880235671997
Validation loss: 1.775981669784874

Epoch: 6| Step: 4
Training loss: 0.4009649455547333
Validation loss: 1.7950954129618983

Epoch: 6| Step: 5
Training loss: 0.42383527755737305
Validation loss: 1.7942007510892806

Epoch: 6| Step: 6
Training loss: 0.6948281526565552
Validation loss: 1.812306542550364

Epoch: 6| Step: 7
Training loss: 0.5159287452697754
Validation loss: 1.8269230819517566

Epoch: 6| Step: 8
Training loss: 0.7249156832695007
Validation loss: 1.8280292262313187

Epoch: 6| Step: 9
Training loss: 0.6022071838378906
Validation loss: 1.8389551588284072

Epoch: 6| Step: 10
Training loss: 0.7182600498199463
Validation loss: 1.8269976339032572

Epoch: 6| Step: 11
Training loss: 0.9726077914237976
Validation loss: 1.813056694563999

Epoch: 6| Step: 12
Training loss: 0.42420220375061035
Validation loss: 1.7839113589256042

Epoch: 6| Step: 13
Training loss: 0.6860664486885071
Validation loss: 1.7624634209499563

Epoch: 306| Step: 0
Training loss: 0.8394282460212708
Validation loss: 1.767659560326607

Epoch: 6| Step: 1
Training loss: 0.619296669960022
Validation loss: 1.7691352623765186

Epoch: 6| Step: 2
Training loss: 0.6193991899490356
Validation loss: 1.7548542766160862

Epoch: 6| Step: 3
Training loss: 0.5345791578292847
Validation loss: 1.7815711562351515

Epoch: 6| Step: 4
Training loss: 0.21685948967933655
Validation loss: 1.7770793604594406

Epoch: 6| Step: 5
Training loss: 0.5202837586402893
Validation loss: 1.7823474778923938

Epoch: 6| Step: 6
Training loss: 0.5663659572601318
Validation loss: 1.782799313145299

Epoch: 6| Step: 7
Training loss: 0.7408304214477539
Validation loss: 1.7439669460378668

Epoch: 6| Step: 8
Training loss: 0.9686166048049927
Validation loss: 1.7456219145046767

Epoch: 6| Step: 9
Training loss: 0.4587863087654114
Validation loss: 1.740952140541487

Epoch: 6| Step: 10
Training loss: 0.4392789304256439
Validation loss: 1.7308977624421478

Epoch: 6| Step: 11
Training loss: 0.5192717909812927
Validation loss: 1.743339769301876

Epoch: 6| Step: 12
Training loss: 0.4003845453262329
Validation loss: 1.749421347853958

Epoch: 6| Step: 13
Training loss: 0.8080382347106934
Validation loss: 1.7446307623258202

Epoch: 307| Step: 0
Training loss: 0.4280926585197449
Validation loss: 1.7553585588291127

Epoch: 6| Step: 1
Training loss: 0.7641773223876953
Validation loss: 1.7577789188713155

Epoch: 6| Step: 2
Training loss: 0.44748014211654663
Validation loss: 1.7571196671455138

Epoch: 6| Step: 3
Training loss: 0.5211836099624634
Validation loss: 1.7513535150917627

Epoch: 6| Step: 4
Training loss: 0.7031967639923096
Validation loss: 1.7852289292120165

Epoch: 6| Step: 5
Training loss: 0.5246566534042358
Validation loss: 1.7725014584038847

Epoch: 6| Step: 6
Training loss: 0.6913295388221741
Validation loss: 1.7859838572881555

Epoch: 6| Step: 7
Training loss: 0.4944835305213928
Validation loss: 1.7767860402343094

Epoch: 6| Step: 8
Training loss: 0.4918603301048279
Validation loss: 1.7873535745887346

Epoch: 6| Step: 9
Training loss: 0.5678359866142273
Validation loss: 1.796548230673677

Epoch: 6| Step: 10
Training loss: 0.5258534550666809
Validation loss: 1.7804022681328557

Epoch: 6| Step: 11
Training loss: 0.5416408777236938
Validation loss: 1.8015193631572108

Epoch: 6| Step: 12
Training loss: 0.6101909875869751
Validation loss: 1.8001853445524811

Epoch: 6| Step: 13
Training loss: 0.48364341259002686
Validation loss: 1.7449332219298168

Epoch: 308| Step: 0
Training loss: 0.5407794713973999
Validation loss: 1.7704249902438092

Epoch: 6| Step: 1
Training loss: 0.5216931700706482
Validation loss: 1.7535784244537354

Epoch: 6| Step: 2
Training loss: 0.30591654777526855
Validation loss: 1.746613266647503

Epoch: 6| Step: 3
Training loss: 0.8193984031677246
Validation loss: 1.7244072216813282

Epoch: 6| Step: 4
Training loss: 0.4892265796661377
Validation loss: 1.7214822602528397

Epoch: 6| Step: 5
Training loss: 0.6538480520248413
Validation loss: 1.70883338041203

Epoch: 6| Step: 6
Training loss: 0.3802016079425812
Validation loss: 1.6891570155338576

Epoch: 6| Step: 7
Training loss: 0.4156996011734009
Validation loss: 1.7022342707521172

Epoch: 6| Step: 8
Training loss: 0.7053744792938232
Validation loss: 1.7247447582983202

Epoch: 6| Step: 9
Training loss: 0.49346786737442017
Validation loss: 1.726798060119793

Epoch: 6| Step: 10
Training loss: 0.3543117642402649
Validation loss: 1.6848759561456659

Epoch: 6| Step: 11
Training loss: 0.8760066628456116
Validation loss: 1.7121969487077446

Epoch: 6| Step: 12
Training loss: 0.4686874747276306
Validation loss: 1.7118852458974367

Epoch: 6| Step: 13
Training loss: 0.8219314813613892
Validation loss: 1.7047562817091584

Epoch: 309| Step: 0
Training loss: 0.5209099650382996
Validation loss: 1.7400153208804388

Epoch: 6| Step: 1
Training loss: 0.47427141666412354
Validation loss: 1.7411581905939246

Epoch: 6| Step: 2
Training loss: 0.35452932119369507
Validation loss: 1.7041612081630255

Epoch: 6| Step: 3
Training loss: 0.5900015830993652
Validation loss: 1.7446271052924536

Epoch: 6| Step: 4
Training loss: 0.6886329054832458
Validation loss: 1.7463242661568426

Epoch: 6| Step: 5
Training loss: 0.44206351041793823
Validation loss: 1.7295537302570958

Epoch: 6| Step: 6
Training loss: 0.48236361145973206
Validation loss: 1.7300831425574519

Epoch: 6| Step: 7
Training loss: 0.4965454339981079
Validation loss: 1.7276658306839645

Epoch: 6| Step: 8
Training loss: 0.41358107328414917
Validation loss: 1.7290173730542582

Epoch: 6| Step: 9
Training loss: 0.5570424795150757
Validation loss: 1.735988768198157

Epoch: 6| Step: 10
Training loss: 0.7268590927124023
Validation loss: 1.7524056050085253

Epoch: 6| Step: 11
Training loss: 0.7568726539611816
Validation loss: 1.7283118219785794

Epoch: 6| Step: 12
Training loss: 0.48620471358299255
Validation loss: 1.7113169034322102

Epoch: 6| Step: 13
Training loss: 0.663640558719635
Validation loss: 1.7012337997395506

Epoch: 310| Step: 0
Training loss: 0.7094192504882812
Validation loss: 1.725245673169372

Epoch: 6| Step: 1
Training loss: 0.38680583238601685
Validation loss: 1.7102252616677234

Epoch: 6| Step: 2
Training loss: 0.7084312438964844
Validation loss: 1.727772928053333

Epoch: 6| Step: 3
Training loss: 0.38510364294052124
Validation loss: 1.7174926137411466

Epoch: 6| Step: 4
Training loss: 0.4688805043697357
Validation loss: 1.7329329841880388

Epoch: 6| Step: 5
Training loss: 0.7560145258903503
Validation loss: 1.7434584889360654

Epoch: 6| Step: 6
Training loss: 0.2531965374946594
Validation loss: 1.7144823510159728

Epoch: 6| Step: 7
Training loss: 0.6562751531600952
Validation loss: 1.7111056812347905

Epoch: 6| Step: 8
Training loss: 0.5163736939430237
Validation loss: 1.687986913547721

Epoch: 6| Step: 9
Training loss: 0.5902428030967712
Validation loss: 1.7026130358378093

Epoch: 6| Step: 10
Training loss: 0.45724382996559143
Validation loss: 1.7011252705768873

Epoch: 6| Step: 11
Training loss: 0.44467905163764954
Validation loss: 1.6908250547224475

Epoch: 6| Step: 12
Training loss: 0.7036572694778442
Validation loss: 1.707211781573552

Epoch: 6| Step: 13
Training loss: 0.34216102957725525
Validation loss: 1.727290568813201

Epoch: 311| Step: 0
Training loss: 0.3248489797115326
Validation loss: 1.716229433654457

Epoch: 6| Step: 1
Training loss: 0.7978806495666504
Validation loss: 1.730466636278296

Epoch: 6| Step: 2
Training loss: 0.7009260654449463
Validation loss: 1.7170909335536342

Epoch: 6| Step: 3
Training loss: 0.2999398708343506
Validation loss: 1.6857861485532535

Epoch: 6| Step: 4
Training loss: 0.6861369609832764
Validation loss: 1.6706419772999261

Epoch: 6| Step: 5
Training loss: 0.49879276752471924
Validation loss: 1.6588294095890497

Epoch: 6| Step: 6
Training loss: 0.5680435299873352
Validation loss: 1.6786130243732083

Epoch: 6| Step: 7
Training loss: 0.29973161220550537
Validation loss: 1.671826789456029

Epoch: 6| Step: 8
Training loss: 0.46345430612564087
Validation loss: 1.688974416384133

Epoch: 6| Step: 9
Training loss: 0.657136082649231
Validation loss: 1.7618380118441839

Epoch: 6| Step: 10
Training loss: 0.5166240334510803
Validation loss: 1.8099363106553272

Epoch: 6| Step: 11
Training loss: 0.6437021493911743
Validation loss: 1.8096129586619716

Epoch: 6| Step: 12
Training loss: 0.6377549171447754
Validation loss: 1.7877390179582822

Epoch: 6| Step: 13
Training loss: 0.7106891870498657
Validation loss: 1.7184086384311799

Epoch: 312| Step: 0
Training loss: 0.3603457510471344
Validation loss: 1.7161430287104782

Epoch: 6| Step: 1
Training loss: 0.6716263294219971
Validation loss: 1.728371266395815

Epoch: 6| Step: 2
Training loss: 0.7204241752624512
Validation loss: 1.7356902655734812

Epoch: 6| Step: 3
Training loss: 0.5319932699203491
Validation loss: 1.704024730190154

Epoch: 6| Step: 4
Training loss: 0.4245952069759369
Validation loss: 1.7133311610068045

Epoch: 6| Step: 5
Training loss: 0.5507440567016602
Validation loss: 1.7096598936665444

Epoch: 6| Step: 6
Training loss: 0.5357234477996826
Validation loss: 1.7159165464421755

Epoch: 6| Step: 7
Training loss: 1.0404887199401855
Validation loss: 1.7786963126992668

Epoch: 6| Step: 8
Training loss: 0.8108072280883789
Validation loss: 1.8049559631655294

Epoch: 6| Step: 9
Training loss: 0.7232376337051392
Validation loss: 1.807974769223121

Epoch: 6| Step: 10
Training loss: 0.5082000494003296
Validation loss: 1.748546258095772

Epoch: 6| Step: 11
Training loss: 0.521302342414856
Validation loss: 1.7127245869687808

Epoch: 6| Step: 12
Training loss: 0.4547713100910187
Validation loss: 1.7123199944855065

Epoch: 6| Step: 13
Training loss: 0.23590326309204102
Validation loss: 1.7302500868356356

Epoch: 313| Step: 0
Training loss: 0.8167470693588257
Validation loss: 1.727022893967167

Epoch: 6| Step: 1
Training loss: 0.5658153295516968
Validation loss: 1.7034359990909536

Epoch: 6| Step: 2
Training loss: 0.4378812909126282
Validation loss: 1.6986466338557582

Epoch: 6| Step: 3
Training loss: 0.33446982502937317
Validation loss: 1.7006438675747122

Epoch: 6| Step: 4
Training loss: 0.5379213094711304
Validation loss: 1.721374866782978

Epoch: 6| Step: 5
Training loss: 0.7272424697875977
Validation loss: 1.7321583442790534

Epoch: 6| Step: 6
Training loss: 0.39591214060783386
Validation loss: 1.7362202470020582

Epoch: 6| Step: 7
Training loss: 0.4789949059486389
Validation loss: 1.7519973375463997

Epoch: 6| Step: 8
Training loss: 0.39943718910217285
Validation loss: 1.7620408240184988

Epoch: 6| Step: 9
Training loss: 0.47939780354499817
Validation loss: 1.7442619544203564

Epoch: 6| Step: 10
Training loss: 0.6858742237091064
Validation loss: 1.7198879821326143

Epoch: 6| Step: 11
Training loss: 0.7046324610710144
Validation loss: 1.727990081233363

Epoch: 6| Step: 12
Training loss: 0.7441238760948181
Validation loss: 1.738964437156595

Epoch: 6| Step: 13
Training loss: 0.1759905219078064
Validation loss: 1.7310327304306852

Epoch: 314| Step: 0
Training loss: 0.5719812512397766
Validation loss: 1.7194101451545634

Epoch: 6| Step: 1
Training loss: 0.6778102517127991
Validation loss: 1.7464189644782775

Epoch: 6| Step: 2
Training loss: 0.46953707933425903
Validation loss: 1.731706710271938

Epoch: 6| Step: 3
Training loss: 0.45665642619132996
Validation loss: 1.7242665995833695

Epoch: 6| Step: 4
Training loss: 0.3924540579319
Validation loss: 1.7060892787030948

Epoch: 6| Step: 5
Training loss: 0.3900405168533325
Validation loss: 1.7116679465898903

Epoch: 6| Step: 6
Training loss: 0.4049556851387024
Validation loss: 1.6836609507119784

Epoch: 6| Step: 7
Training loss: 0.616692066192627
Validation loss: 1.6822170108877204

Epoch: 6| Step: 8
Training loss: 0.6074209809303284
Validation loss: 1.6922076504717591

Epoch: 6| Step: 9
Training loss: 0.7923298478126526
Validation loss: 1.6902311771146712

Epoch: 6| Step: 10
Training loss: 0.48497462272644043
Validation loss: 1.6853075373557307

Epoch: 6| Step: 11
Training loss: 0.5549356341362
Validation loss: 1.7129664190353886

Epoch: 6| Step: 12
Training loss: 0.49847841262817383
Validation loss: 1.727066332294095

Epoch: 6| Step: 13
Training loss: 0.6189336776733398
Validation loss: 1.7751549725891442

Epoch: 315| Step: 0
Training loss: 0.5013183355331421
Validation loss: 1.7612410950404342

Epoch: 6| Step: 1
Training loss: 0.5107784271240234
Validation loss: 1.734855600582656

Epoch: 6| Step: 2
Training loss: 0.5827310085296631
Validation loss: 1.725110520598709

Epoch: 6| Step: 3
Training loss: 0.5102065801620483
Validation loss: 1.7346579464532996

Epoch: 6| Step: 4
Training loss: 0.8104501366615295
Validation loss: 1.7155827681223552

Epoch: 6| Step: 5
Training loss: 0.3772171139717102
Validation loss: 1.7059911117758801

Epoch: 6| Step: 6
Training loss: 0.49479907751083374
Validation loss: 1.712656678691987

Epoch: 6| Step: 7
Training loss: 0.40454351902008057
Validation loss: 1.73840029521655

Epoch: 6| Step: 8
Training loss: 0.36633068323135376
Validation loss: 1.7263567934754074

Epoch: 6| Step: 9
Training loss: 0.4830591678619385
Validation loss: 1.7007700858577606

Epoch: 6| Step: 10
Training loss: 0.41575998067855835
Validation loss: 1.7119185206710652

Epoch: 6| Step: 11
Training loss: 0.7108497619628906
Validation loss: 1.6955480408924881

Epoch: 6| Step: 12
Training loss: 0.5601369738578796
Validation loss: 1.7001637874111053

Epoch: 6| Step: 13
Training loss: 0.5621554851531982
Validation loss: 1.6949949187617148

Epoch: 316| Step: 0
Training loss: 0.6603060364723206
Validation loss: 1.6841882813361384

Epoch: 6| Step: 1
Training loss: 0.590924859046936
Validation loss: 1.729064360741646

Epoch: 6| Step: 2
Training loss: 0.5400856733322144
Validation loss: 1.7368738882003292

Epoch: 6| Step: 3
Training loss: 0.46283987164497375
Validation loss: 1.761578207374901

Epoch: 6| Step: 4
Training loss: 0.37200069427490234
Validation loss: 1.7644268722944363

Epoch: 6| Step: 5
Training loss: 0.5173847079277039
Validation loss: 1.7371035468193792

Epoch: 6| Step: 6
Training loss: 0.6583620309829712
Validation loss: 1.7192346370348366

Epoch: 6| Step: 7
Training loss: 0.6470821499824524
Validation loss: 1.7277855603925643

Epoch: 6| Step: 8
Training loss: 0.35110506415367126
Validation loss: 1.7419739833442114

Epoch: 6| Step: 9
Training loss: 0.5091204047203064
Validation loss: 1.7459432822401806

Epoch: 6| Step: 10
Training loss: 0.3375345468521118
Validation loss: 1.7472948105104509

Epoch: 6| Step: 11
Training loss: 0.708855926990509
Validation loss: 1.7709844048305223

Epoch: 6| Step: 12
Training loss: 0.4349096417427063
Validation loss: 1.7985058728084768

Epoch: 6| Step: 13
Training loss: 0.4909069836139679
Validation loss: 1.8465145762248705

Epoch: 317| Step: 0
Training loss: 0.4504556655883789
Validation loss: 1.8496920870196434

Epoch: 6| Step: 1
Training loss: 0.6270389556884766
Validation loss: 1.8422187861575876

Epoch: 6| Step: 2
Training loss: 0.6327314972877502
Validation loss: 1.8132774842682706

Epoch: 6| Step: 3
Training loss: 0.334179550409317
Validation loss: 1.7288493725561327

Epoch: 6| Step: 4
Training loss: 0.5407356023788452
Validation loss: 1.7025012623879217

Epoch: 6| Step: 5
Training loss: 0.4439111649990082
Validation loss: 1.6755289390522947

Epoch: 6| Step: 6
Training loss: 0.7940940856933594
Validation loss: 1.6938971011869368

Epoch: 6| Step: 7
Training loss: 0.6193133592605591
Validation loss: 1.7169855102416007

Epoch: 6| Step: 8
Training loss: 0.7930812835693359
Validation loss: 1.7489216878849974

Epoch: 6| Step: 9
Training loss: 0.9043693542480469
Validation loss: 1.7044136216563563

Epoch: 6| Step: 10
Training loss: 0.9923676252365112
Validation loss: 1.7100787675508888

Epoch: 6| Step: 11
Training loss: 0.5572277307510376
Validation loss: 1.6889223962701776

Epoch: 6| Step: 12
Training loss: 0.2403026968240738
Validation loss: 1.7088362247713151

Epoch: 6| Step: 13
Training loss: 0.7921872735023499
Validation loss: 1.7615129614389071

Epoch: 318| Step: 0
Training loss: 0.5706154704093933
Validation loss: 1.7734938103665587

Epoch: 6| Step: 1
Training loss: 0.4407981038093567
Validation loss: 1.7455603935385262

Epoch: 6| Step: 2
Training loss: 0.4279974102973938
Validation loss: 1.7173529414720432

Epoch: 6| Step: 3
Training loss: 0.5925788879394531
Validation loss: 1.658197646499962

Epoch: 6| Step: 4
Training loss: 0.4889548420906067
Validation loss: 1.6628527538750761

Epoch: 6| Step: 5
Training loss: 0.7173877954483032
Validation loss: 1.6734856040247026

Epoch: 6| Step: 6
Training loss: 0.6414834260940552
Validation loss: 1.6603014930602042

Epoch: 6| Step: 7
Training loss: 0.4458940923213959
Validation loss: 1.6463231771223006

Epoch: 6| Step: 8
Training loss: 0.5951474905014038
Validation loss: 1.677400165988553

Epoch: 6| Step: 9
Training loss: 0.47222262620925903
Validation loss: 1.6781142680875716

Epoch: 6| Step: 10
Training loss: 0.5476846694946289
Validation loss: 1.7286546320043585

Epoch: 6| Step: 11
Training loss: 0.4341157078742981
Validation loss: 1.688306240625279

Epoch: 6| Step: 12
Training loss: 0.3343837857246399
Validation loss: 1.6774247871932162

Epoch: 6| Step: 13
Training loss: 0.4658523201942444
Validation loss: 1.695564373846977

Epoch: 319| Step: 0
Training loss: 0.32530444860458374
Validation loss: 1.6766343398760724

Epoch: 6| Step: 1
Training loss: 0.2711786925792694
Validation loss: 1.6650908134316886

Epoch: 6| Step: 2
Training loss: 0.5573818683624268
Validation loss: 1.660697232010544

Epoch: 6| Step: 3
Training loss: 0.46754559874534607
Validation loss: 1.6420257014612998

Epoch: 6| Step: 4
Training loss: 0.5092523694038391
Validation loss: 1.671748863753452

Epoch: 6| Step: 5
Training loss: 0.4871000349521637
Validation loss: 1.6388189472177976

Epoch: 6| Step: 6
Training loss: 0.7262983322143555
Validation loss: 1.7011779790283532

Epoch: 6| Step: 7
Training loss: 0.8676986694335938
Validation loss: 1.721767653701126

Epoch: 6| Step: 8
Training loss: 0.5224111080169678
Validation loss: 1.7752672369762132

Epoch: 6| Step: 9
Training loss: 0.4053400754928589
Validation loss: 1.8017067217057752

Epoch: 6| Step: 10
Training loss: 0.5987033247947693
Validation loss: 1.832354719920825

Epoch: 6| Step: 11
Training loss: 0.8161231875419617
Validation loss: 1.8306107085238221

Epoch: 6| Step: 12
Training loss: 0.6111405491828918
Validation loss: 1.7786021386423418

Epoch: 6| Step: 13
Training loss: 0.17278197407722473
Validation loss: 1.7452123498403898

Epoch: 320| Step: 0
Training loss: 0.38387420773506165
Validation loss: 1.7017123058278074

Epoch: 6| Step: 1
Training loss: 0.28003719449043274
Validation loss: 1.7051661873376498

Epoch: 6| Step: 2
Training loss: 0.4465221166610718
Validation loss: 1.7111690762222453

Epoch: 6| Step: 3
Training loss: 0.4503936767578125
Validation loss: 1.6877680965649184

Epoch: 6| Step: 4
Training loss: 0.6756608486175537
Validation loss: 1.6788178631054458

Epoch: 6| Step: 5
Training loss: 0.26161009073257446
Validation loss: 1.6965885585354221

Epoch: 6| Step: 6
Training loss: 0.6988643407821655
Validation loss: 1.6995313782845773

Epoch: 6| Step: 7
Training loss: 0.8174093961715698
Validation loss: 1.7347991684431672

Epoch: 6| Step: 8
Training loss: 0.8204416036605835
Validation loss: 1.700690714261865

Epoch: 6| Step: 9
Training loss: 0.484708696603775
Validation loss: 1.673007087040973

Epoch: 6| Step: 10
Training loss: 0.5478657484054565
Validation loss: 1.6651413081794657

Epoch: 6| Step: 11
Training loss: 0.33534112572669983
Validation loss: 1.6605973474441036

Epoch: 6| Step: 12
Training loss: 0.48860740661621094
Validation loss: 1.6660423432627032

Epoch: 6| Step: 13
Training loss: 0.5541583299636841
Validation loss: 1.6627656952027352

Epoch: 321| Step: 0
Training loss: 0.628589928150177
Validation loss: 1.6727228395400509

Epoch: 6| Step: 1
Training loss: 0.7214058637619019
Validation loss: 1.7135736724381805

Epoch: 6| Step: 2
Training loss: 0.5732291340827942
Validation loss: 1.7469768447260703

Epoch: 6| Step: 3
Training loss: 0.3590877950191498
Validation loss: 1.7275806005283068

Epoch: 6| Step: 4
Training loss: 0.6618872880935669
Validation loss: 1.7160679858217958

Epoch: 6| Step: 5
Training loss: 0.3765261173248291
Validation loss: 1.7034540432755665

Epoch: 6| Step: 6
Training loss: 0.2813190221786499
Validation loss: 1.6788184181336434

Epoch: 6| Step: 7
Training loss: 0.4400999844074249
Validation loss: 1.6754009826208955

Epoch: 6| Step: 8
Training loss: 0.3830508589744568
Validation loss: 1.6880944723724036

Epoch: 6| Step: 9
Training loss: 0.8070811629295349
Validation loss: 1.6728207449759207

Epoch: 6| Step: 10
Training loss: 0.2759885787963867
Validation loss: 1.6769582866340556

Epoch: 6| Step: 11
Training loss: 0.6489453315734863
Validation loss: 1.6756063674085884

Epoch: 6| Step: 12
Training loss: 0.5224939584732056
Validation loss: 1.650256892686249

Epoch: 6| Step: 13
Training loss: 0.26222145557403564
Validation loss: 1.682930620767737

Epoch: 322| Step: 0
Training loss: 0.4182317852973938
Validation loss: 1.6903823114210559

Epoch: 6| Step: 1
Training loss: 0.49135079979896545
Validation loss: 1.7095512497809626

Epoch: 6| Step: 2
Training loss: 0.6428276896476746
Validation loss: 1.7173135370336554

Epoch: 6| Step: 3
Training loss: 0.5888551473617554
Validation loss: 1.7163837494388703

Epoch: 6| Step: 4
Training loss: 0.6870680451393127
Validation loss: 1.7169310892781904

Epoch: 6| Step: 5
Training loss: 0.6191257238388062
Validation loss: 1.692715867873161

Epoch: 6| Step: 6
Training loss: 0.3823133111000061
Validation loss: 1.6900252142260153

Epoch: 6| Step: 7
Training loss: 0.4905818700790405
Validation loss: 1.6903051176378805

Epoch: 6| Step: 8
Training loss: 0.519479513168335
Validation loss: 1.687045576751873

Epoch: 6| Step: 9
Training loss: 0.4246438145637512
Validation loss: 1.6891524817353936

Epoch: 6| Step: 10
Training loss: 0.3798821270465851
Validation loss: 1.6988375988057864

Epoch: 6| Step: 11
Training loss: 0.1459430307149887
Validation loss: 1.6967105583478046

Epoch: 6| Step: 12
Training loss: 0.5319786667823792
Validation loss: 1.6926030523033553

Epoch: 6| Step: 13
Training loss: 0.36604833602905273
Validation loss: 1.670499449776065

Epoch: 323| Step: 0
Training loss: 0.6135315895080566
Validation loss: 1.6658970489296863

Epoch: 6| Step: 1
Training loss: 0.3825322985649109
Validation loss: 1.6483264161694435

Epoch: 6| Step: 2
Training loss: 0.6056219935417175
Validation loss: 1.658484678114614

Epoch: 6| Step: 3
Training loss: 0.2773264944553375
Validation loss: 1.6461024143362557

Epoch: 6| Step: 4
Training loss: 0.6258277893066406
Validation loss: 1.63952721447073

Epoch: 6| Step: 5
Training loss: 0.5371510982513428
Validation loss: 1.668946712247787

Epoch: 6| Step: 6
Training loss: 0.5230028033256531
Validation loss: 1.6589715634622881

Epoch: 6| Step: 7
Training loss: 0.5076895952224731
Validation loss: 1.6631993401435115

Epoch: 6| Step: 8
Training loss: 0.31529828906059265
Validation loss: 1.7012794863793157

Epoch: 6| Step: 9
Training loss: 0.4209601581096649
Validation loss: 1.6926068349551129

Epoch: 6| Step: 10
Training loss: 0.4643765687942505
Validation loss: 1.6869987416011032

Epoch: 6| Step: 11
Training loss: 0.40997523069381714
Validation loss: 1.6760490286734797

Epoch: 6| Step: 12
Training loss: 0.4317711591720581
Validation loss: 1.6876732072522562

Epoch: 6| Step: 13
Training loss: 0.35291221737861633
Validation loss: 1.6778907647696875

Epoch: 324| Step: 0
Training loss: 0.22497966885566711
Validation loss: 1.6777940398903304

Epoch: 6| Step: 1
Training loss: 0.4278361201286316
Validation loss: 1.6911981772351008

Epoch: 6| Step: 2
Training loss: 0.485038697719574
Validation loss: 1.6768665108629452

Epoch: 6| Step: 3
Training loss: 0.5328222513198853
Validation loss: 1.6926602432804723

Epoch: 6| Step: 4
Training loss: 0.5589095950126648
Validation loss: 1.7004647229307441

Epoch: 6| Step: 5
Training loss: 0.6775668859481812
Validation loss: 1.6987163725719656

Epoch: 6| Step: 6
Training loss: 0.5667666792869568
Validation loss: 1.6664693547833351

Epoch: 6| Step: 7
Training loss: 0.43126219511032104
Validation loss: 1.657093935115363

Epoch: 6| Step: 8
Training loss: 0.601809024810791
Validation loss: 1.6906377653921805

Epoch: 6| Step: 9
Training loss: 0.346699982881546
Validation loss: 1.708196561823609

Epoch: 6| Step: 10
Training loss: 0.579801619052887
Validation loss: 1.7370834940223283

Epoch: 6| Step: 11
Training loss: 0.5296122431755066
Validation loss: 1.7491828395474343

Epoch: 6| Step: 12
Training loss: 0.3401637673377991
Validation loss: 1.781269456750603

Epoch: 6| Step: 13
Training loss: 0.5412508249282837
Validation loss: 1.8112377210329937

Epoch: 325| Step: 0
Training loss: 0.44183504581451416
Validation loss: 1.8066834711259412

Epoch: 6| Step: 1
Training loss: 0.8062803745269775
Validation loss: 1.774127818563933

Epoch: 6| Step: 2
Training loss: 0.25536084175109863
Validation loss: 1.7480012268148444

Epoch: 6| Step: 3
Training loss: 0.4644032120704651
Validation loss: 1.7354681639261142

Epoch: 6| Step: 4
Training loss: 0.6500644683837891
Validation loss: 1.6895094276756368

Epoch: 6| Step: 5
Training loss: 0.15627872943878174
Validation loss: 1.7048800876063686

Epoch: 6| Step: 6
Training loss: 0.5949088335037231
Validation loss: 1.7030797004699707

Epoch: 6| Step: 7
Training loss: 0.4695536494255066
Validation loss: 1.6998303910737396

Epoch: 6| Step: 8
Training loss: 0.7067112326622009
Validation loss: 1.715333209242872

Epoch: 6| Step: 9
Training loss: 0.5852738618850708
Validation loss: 1.7205505191638906

Epoch: 6| Step: 10
Training loss: 0.5919541120529175
Validation loss: 1.7040542197483841

Epoch: 6| Step: 11
Training loss: 0.3553069233894348
Validation loss: 1.6935508584463468

Epoch: 6| Step: 12
Training loss: 0.5391119718551636
Validation loss: 1.6876461467435282

Epoch: 6| Step: 13
Training loss: 0.4022054672241211
Validation loss: 1.6545283679039247

Epoch: 326| Step: 0
Training loss: 0.4758957028388977
Validation loss: 1.6950097468591505

Epoch: 6| Step: 1
Training loss: 0.323277086019516
Validation loss: 1.681415468133906

Epoch: 6| Step: 2
Training loss: 0.5015838146209717
Validation loss: 1.6961057301490539

Epoch: 6| Step: 3
Training loss: 0.5110917687416077
Validation loss: 1.6831715094145907

Epoch: 6| Step: 4
Training loss: 0.4386218786239624
Validation loss: 1.7427804546971475

Epoch: 6| Step: 5
Training loss: 0.36263608932495117
Validation loss: 1.7469524888582126

Epoch: 6| Step: 6
Training loss: 0.23707705736160278
Validation loss: 1.7870740557229647

Epoch: 6| Step: 7
Training loss: 0.5737098455429077
Validation loss: 1.7430071241112166

Epoch: 6| Step: 8
Training loss: 0.6345094442367554
Validation loss: 1.781218567202168

Epoch: 6| Step: 9
Training loss: 0.49960827827453613
Validation loss: 1.7285595581095705

Epoch: 6| Step: 10
Training loss: 0.4082143306732178
Validation loss: 1.6979009233495241

Epoch: 6| Step: 11
Training loss: 0.9039071798324585
Validation loss: 1.689697539934548

Epoch: 6| Step: 12
Training loss: 0.15458734333515167
Validation loss: 1.6732669594467326

Epoch: 6| Step: 13
Training loss: 0.43479490280151367
Validation loss: 1.6736130727234708

Epoch: 327| Step: 0
Training loss: 0.3163999021053314
Validation loss: 1.682688772037465

Epoch: 6| Step: 1
Training loss: 0.44048011302948
Validation loss: 1.7143187779252247

Epoch: 6| Step: 2
Training loss: 0.4516931474208832
Validation loss: 1.7391883455297

Epoch: 6| Step: 3
Training loss: 0.3305279314517975
Validation loss: 1.7370600585014588

Epoch: 6| Step: 4
Training loss: 0.2917851507663727
Validation loss: 1.7046777945692821

Epoch: 6| Step: 5
Training loss: 0.5803775191307068
Validation loss: 1.7199512540653188

Epoch: 6| Step: 6
Training loss: 0.6852157115936279
Validation loss: 1.6658344012434765

Epoch: 6| Step: 7
Training loss: 0.6879506707191467
Validation loss: 1.6572683049786476

Epoch: 6| Step: 8
Training loss: 0.5260502099990845
Validation loss: 1.6596999559351193

Epoch: 6| Step: 9
Training loss: 0.5955960154533386
Validation loss: 1.6710083420558641

Epoch: 6| Step: 10
Training loss: 0.48484134674072266
Validation loss: 1.6840072139616935

Epoch: 6| Step: 11
Training loss: 0.6588827967643738
Validation loss: 1.6881855034059094

Epoch: 6| Step: 12
Training loss: 0.5403762459754944
Validation loss: 1.6953294815555695

Epoch: 6| Step: 13
Training loss: 0.2001192271709442
Validation loss: 1.7109869462187572

Epoch: 328| Step: 0
Training loss: 0.4185904562473297
Validation loss: 1.7364936169757639

Epoch: 6| Step: 1
Training loss: 0.3032867908477783
Validation loss: 1.7697216349263345

Epoch: 6| Step: 2
Training loss: 0.7004975080490112
Validation loss: 1.7674840355432162

Epoch: 6| Step: 3
Training loss: 0.6291473507881165
Validation loss: 1.7473894626863542

Epoch: 6| Step: 4
Training loss: 0.5277842283248901
Validation loss: 1.7184327071712864

Epoch: 6| Step: 5
Training loss: 0.38959449529647827
Validation loss: 1.710383112712573

Epoch: 6| Step: 6
Training loss: 0.2042510211467743
Validation loss: 1.6947009025081512

Epoch: 6| Step: 7
Training loss: 0.14717517793178558
Validation loss: 1.7052658821946831

Epoch: 6| Step: 8
Training loss: 0.42511674761772156
Validation loss: 1.6615257340092813

Epoch: 6| Step: 9
Training loss: 0.4774400293827057
Validation loss: 1.687700463879493

Epoch: 6| Step: 10
Training loss: 0.6135799884796143
Validation loss: 1.7117965093222998

Epoch: 6| Step: 11
Training loss: 0.4564610719680786
Validation loss: 1.729628486018027

Epoch: 6| Step: 12
Training loss: 0.5566157102584839
Validation loss: 1.7109634568614345

Epoch: 6| Step: 13
Training loss: 0.530249834060669
Validation loss: 1.684920620533728

Epoch: 329| Step: 0
Training loss: 0.6292933225631714
Validation loss: 1.7168465686100784

Epoch: 6| Step: 1
Training loss: 0.49436354637145996
Validation loss: 1.6922155669940415

Epoch: 6| Step: 2
Training loss: 0.6836352348327637
Validation loss: 1.722262358152738

Epoch: 6| Step: 3
Training loss: 0.4233482778072357
Validation loss: 1.6605898795589324

Epoch: 6| Step: 4
Training loss: 0.4565683603286743
Validation loss: 1.6776438887401293

Epoch: 6| Step: 5
Training loss: 0.44805389642715454
Validation loss: 1.6879124551691034

Epoch: 6| Step: 6
Training loss: 0.3421410918235779
Validation loss: 1.6976680960706485

Epoch: 6| Step: 7
Training loss: 0.3194751441478729
Validation loss: 1.685015764287723

Epoch: 6| Step: 8
Training loss: 0.43804123997688293
Validation loss: 1.6994263690005067

Epoch: 6| Step: 9
Training loss: 0.32678890228271484
Validation loss: 1.72602431748503

Epoch: 6| Step: 10
Training loss: 0.4672524631023407
Validation loss: 1.7163480725339664

Epoch: 6| Step: 11
Training loss: 0.3563370406627655
Validation loss: 1.7055902006805583

Epoch: 6| Step: 12
Training loss: 0.21556462347507477
Validation loss: 1.659024065540683

Epoch: 6| Step: 13
Training loss: 0.5365129113197327
Validation loss: 1.6369750474088935

Epoch: 330| Step: 0
Training loss: 0.2728348970413208
Validation loss: 1.658086956188243

Epoch: 6| Step: 1
Training loss: 0.42740368843078613
Validation loss: 1.6623931956547562

Epoch: 6| Step: 2
Training loss: 0.17742058634757996
Validation loss: 1.643786177840284

Epoch: 6| Step: 3
Training loss: 0.4125345051288605
Validation loss: 1.663902090441796

Epoch: 6| Step: 4
Training loss: 0.565767765045166
Validation loss: 1.6614707503267514

Epoch: 6| Step: 5
Training loss: 0.3484905958175659
Validation loss: 1.655435936425322

Epoch: 6| Step: 6
Training loss: 0.43738043308258057
Validation loss: 1.66391033511008

Epoch: 6| Step: 7
Training loss: 0.42633911967277527
Validation loss: 1.6425314641767932

Epoch: 6| Step: 8
Training loss: 0.606918215751648
Validation loss: 1.6358792704920615

Epoch: 6| Step: 9
Training loss: 0.36048224568367004
Validation loss: 1.6504438513068742

Epoch: 6| Step: 10
Training loss: 0.584770917892456
Validation loss: 1.6745854398255706

Epoch: 6| Step: 11
Training loss: 0.38054829835891724
Validation loss: 1.6500545996491627

Epoch: 6| Step: 12
Training loss: 0.7032157182693481
Validation loss: 1.652602716158795

Epoch: 6| Step: 13
Training loss: 0.07489018142223358
Validation loss: 1.669184245089049

Epoch: 331| Step: 0
Training loss: 0.46321403980255127
Validation loss: 1.6422709547063357

Epoch: 6| Step: 1
Training loss: 0.3060569167137146
Validation loss: 1.6819299677366852

Epoch: 6| Step: 2
Training loss: 0.32151317596435547
Validation loss: 1.6637830285615818

Epoch: 6| Step: 3
Training loss: 0.4697491526603699
Validation loss: 1.6676401656161073

Epoch: 6| Step: 4
Training loss: 0.4217126965522766
Validation loss: 1.6667758636577155

Epoch: 6| Step: 5
Training loss: 0.3583311438560486
Validation loss: 1.7010088287374026

Epoch: 6| Step: 6
Training loss: 0.5497329831123352
Validation loss: 1.691914273846534

Epoch: 6| Step: 7
Training loss: 0.4015951156616211
Validation loss: 1.700763496019507

Epoch: 6| Step: 8
Training loss: 0.5257017016410828
Validation loss: 1.6564542337130475

Epoch: 6| Step: 9
Training loss: 0.3124360144138336
Validation loss: 1.6837428026301886

Epoch: 6| Step: 10
Training loss: 0.5528169870376587
Validation loss: 1.6612205684825938

Epoch: 6| Step: 11
Training loss: 0.2888490557670593
Validation loss: 1.656712539734379

Epoch: 6| Step: 12
Training loss: 0.35355451703071594
Validation loss: 1.6877583329395582

Epoch: 6| Step: 13
Training loss: 0.3055194616317749
Validation loss: 1.662408709526062

Epoch: 332| Step: 0
Training loss: 0.2980613708496094
Validation loss: 1.6751458426957488

Epoch: 6| Step: 1
Training loss: 0.3958108425140381
Validation loss: 1.6487423476352487

Epoch: 6| Step: 2
Training loss: 0.3538607656955719
Validation loss: 1.657742937405904

Epoch: 6| Step: 3
Training loss: 0.1402500718832016
Validation loss: 1.6784063975016277

Epoch: 6| Step: 4
Training loss: 0.5633003115653992
Validation loss: 1.6703055263847433

Epoch: 6| Step: 5
Training loss: 0.21481260657310486
Validation loss: 1.6554602961386404

Epoch: 6| Step: 6
Training loss: 0.39248865842819214
Validation loss: 1.6536919314374205

Epoch: 6| Step: 7
Training loss: 0.4402928650379181
Validation loss: 1.6319442013258576

Epoch: 6| Step: 8
Training loss: 0.20824578404426575
Validation loss: 1.6550136317488968

Epoch: 6| Step: 9
Training loss: 0.8564966320991516
Validation loss: 1.6477625728935323

Epoch: 6| Step: 10
Training loss: 0.3105413317680359
Validation loss: 1.6568777202278056

Epoch: 6| Step: 11
Training loss: 0.4907498061656952
Validation loss: 1.6698126433998026

Epoch: 6| Step: 12
Training loss: 0.3817044794559479
Validation loss: 1.674698878360051

Epoch: 6| Step: 13
Training loss: 0.5403921604156494
Validation loss: 1.6539108061021375

Epoch: 333| Step: 0
Training loss: 0.36908650398254395
Validation loss: 1.6251457660428938

Epoch: 6| Step: 1
Training loss: 0.5227574706077576
Validation loss: 1.6319499092717324

Epoch: 6| Step: 2
Training loss: 0.3229944109916687
Validation loss: 1.629681299450577

Epoch: 6| Step: 3
Training loss: 0.46723419427871704
Validation loss: 1.649250397118189

Epoch: 6| Step: 4
Training loss: 0.46922749280929565
Validation loss: 1.6438581597420476

Epoch: 6| Step: 5
Training loss: 0.1875368356704712
Validation loss: 1.6796385293365808

Epoch: 6| Step: 6
Training loss: 0.3712998628616333
Validation loss: 1.7161943989415323

Epoch: 6| Step: 7
Training loss: 0.5457739233970642
Validation loss: 1.7234180024875108

Epoch: 6| Step: 8
Training loss: 0.17285895347595215
Validation loss: 1.7337292189239173

Epoch: 6| Step: 9
Training loss: 0.522685706615448
Validation loss: 1.7580498777410036

Epoch: 6| Step: 10
Training loss: 0.5570212602615356
Validation loss: 1.761502940167663

Epoch: 6| Step: 11
Training loss: 0.2800784409046173
Validation loss: 1.743562581718609

Epoch: 6| Step: 12
Training loss: 0.37581509351730347
Validation loss: 1.7503028338955295

Epoch: 6| Step: 13
Training loss: 0.40490517020225525
Validation loss: 1.7270677461419055

Epoch: 334| Step: 0
Training loss: 0.7045989036560059
Validation loss: 1.7055783733244865

Epoch: 6| Step: 1
Training loss: 0.25110363960266113
Validation loss: 1.7084249424678024

Epoch: 6| Step: 2
Training loss: 0.6296617388725281
Validation loss: 1.6999799846321024

Epoch: 6| Step: 3
Training loss: 0.483984112739563
Validation loss: 1.7139070123754523

Epoch: 6| Step: 4
Training loss: 0.3418102264404297
Validation loss: 1.7215840585770146

Epoch: 6| Step: 5
Training loss: 0.20826520025730133
Validation loss: 1.7270017259864396

Epoch: 6| Step: 6
Training loss: 0.37622231245040894
Validation loss: 1.7023014740277362

Epoch: 6| Step: 7
Training loss: 0.4486128091812134
Validation loss: 1.6819860063573366

Epoch: 6| Step: 8
Training loss: 0.2666160464286804
Validation loss: 1.6470039698385424

Epoch: 6| Step: 9
Training loss: 0.26734495162963867
Validation loss: 1.6518941771599553

Epoch: 6| Step: 10
Training loss: 0.5527153611183167
Validation loss: 1.6768470477032404

Epoch: 6| Step: 11
Training loss: 0.2718563675880432
Validation loss: 1.6655328132772957

Epoch: 6| Step: 12
Training loss: 0.5924603939056396
Validation loss: 1.6541638951147757

Epoch: 6| Step: 13
Training loss: 0.2736705541610718
Validation loss: 1.6885331010305753

Epoch: 335| Step: 0
Training loss: 0.312721848487854
Validation loss: 1.699563491728998

Epoch: 6| Step: 1
Training loss: 0.3587414622306824
Validation loss: 1.7041079510924637

Epoch: 6| Step: 2
Training loss: 0.39543744921684265
Validation loss: 1.7041159137602775

Epoch: 6| Step: 3
Training loss: 0.43117964267730713
Validation loss: 1.6837608955239738

Epoch: 6| Step: 4
Training loss: 0.44513261318206787
Validation loss: 1.6891900070251957

Epoch: 6| Step: 5
Training loss: 0.2677903473377228
Validation loss: 1.6435975707987303

Epoch: 6| Step: 6
Training loss: 0.37704920768737793
Validation loss: 1.6431746149575839

Epoch: 6| Step: 7
Training loss: 0.426774263381958
Validation loss: 1.666897551987761

Epoch: 6| Step: 8
Training loss: 0.4549027383327484
Validation loss: 1.667443794588889

Epoch: 6| Step: 9
Training loss: 0.5692434310913086
Validation loss: 1.6650755943790558

Epoch: 6| Step: 10
Training loss: 0.24422983825206757
Validation loss: 1.7041580984669347

Epoch: 6| Step: 11
Training loss: 0.2136784791946411
Validation loss: 1.6854772888204104

Epoch: 6| Step: 12
Training loss: 0.5650462508201599
Validation loss: 1.676038848456516

Epoch: 6| Step: 13
Training loss: 0.47472646832466125
Validation loss: 1.6814824778546569

Epoch: 336| Step: 0
Training loss: 0.35480374097824097
Validation loss: 1.6443939465348438

Epoch: 6| Step: 1
Training loss: 0.5378552675247192
Validation loss: 1.633973563871076

Epoch: 6| Step: 2
Training loss: 0.39406663179397583
Validation loss: 1.6394719539150115

Epoch: 6| Step: 3
Training loss: 0.45731857419013977
Validation loss: 1.6355925452324651

Epoch: 6| Step: 4
Training loss: 0.26710745692253113
Validation loss: 1.6420188744862874

Epoch: 6| Step: 5
Training loss: 0.49939942359924316
Validation loss: 1.667502869841873

Epoch: 6| Step: 6
Training loss: 0.3460293412208557
Validation loss: 1.638526221757294

Epoch: 6| Step: 7
Training loss: 0.4491313397884369
Validation loss: 1.6495237709373556

Epoch: 6| Step: 8
Training loss: 0.42001163959503174
Validation loss: 1.6581900965782903

Epoch: 6| Step: 9
Training loss: 0.388309508562088
Validation loss: 1.6917741990858508

Epoch: 6| Step: 10
Training loss: 0.5177537798881531
Validation loss: 1.6987515329032816

Epoch: 6| Step: 11
Training loss: 0.2890816330909729
Validation loss: 1.7140998096876248

Epoch: 6| Step: 12
Training loss: 0.21734502911567688
Validation loss: 1.7546950886326451

Epoch: 6| Step: 13
Training loss: 0.6401454210281372
Validation loss: 1.7607740394530758

Epoch: 337| Step: 0
Training loss: 0.24380062520503998
Validation loss: 1.7599088556023055

Epoch: 6| Step: 1
Training loss: 0.23862364888191223
Validation loss: 1.7052167474582631

Epoch: 6| Step: 2
Training loss: 0.42654678225517273
Validation loss: 1.6938039666862899

Epoch: 6| Step: 3
Training loss: 0.3101373314857483
Validation loss: 1.648275258720562

Epoch: 6| Step: 4
Training loss: 0.3067767024040222
Validation loss: 1.6396873920194563

Epoch: 6| Step: 5
Training loss: 0.7749167084693909
Validation loss: 1.61193258659814

Epoch: 6| Step: 6
Training loss: 0.3280940055847168
Validation loss: 1.6211009602392874

Epoch: 6| Step: 7
Training loss: 0.22078734636306763
Validation loss: 1.6235229058932232

Epoch: 6| Step: 8
Training loss: 0.48423540592193604
Validation loss: 1.6844919599512571

Epoch: 6| Step: 9
Training loss: 0.41268298029899597
Validation loss: 1.650501871621737

Epoch: 6| Step: 10
Training loss: 0.42193666100502014
Validation loss: 1.6817278759453886

Epoch: 6| Step: 11
Training loss: 0.5889247059822083
Validation loss: 1.6813842186363794

Epoch: 6| Step: 12
Training loss: 0.34618696570396423
Validation loss: 1.6877852024570588

Epoch: 6| Step: 13
Training loss: 0.5837860107421875
Validation loss: 1.6880974538864628

Epoch: 338| Step: 0
Training loss: 0.5366155505180359
Validation loss: 1.686506889199698

Epoch: 6| Step: 1
Training loss: 0.6018221974372864
Validation loss: 1.7055370134692038

Epoch: 6| Step: 2
Training loss: 0.4563777446746826
Validation loss: 1.6919016658618886

Epoch: 6| Step: 3
Training loss: 0.3790629506111145
Validation loss: 1.6993307041865524

Epoch: 6| Step: 4
Training loss: 0.2648468017578125
Validation loss: 1.6974148314486268

Epoch: 6| Step: 5
Training loss: 0.37806200981140137
Validation loss: 1.6689719794898905

Epoch: 6| Step: 6
Training loss: 0.2269521951675415
Validation loss: 1.6770837057021357

Epoch: 6| Step: 7
Training loss: 0.31139254570007324
Validation loss: 1.6584711395284182

Epoch: 6| Step: 8
Training loss: 0.39348188042640686
Validation loss: 1.6445789657613283

Epoch: 6| Step: 9
Training loss: 0.41840237379074097
Validation loss: 1.6268491552722069

Epoch: 6| Step: 10
Training loss: 0.23938965797424316
Validation loss: 1.6295471165769844

Epoch: 6| Step: 11
Training loss: 0.32552623748779297
Validation loss: 1.6740047982943955

Epoch: 6| Step: 12
Training loss: 0.3313584327697754
Validation loss: 1.67421495017185

Epoch: 6| Step: 13
Training loss: 0.7398805618286133
Validation loss: 1.6956760870513095

Epoch: 339| Step: 0
Training loss: 0.5494030117988586
Validation loss: 1.667758189221864

Epoch: 6| Step: 1
Training loss: 0.34568873047828674
Validation loss: 1.6523834133660922

Epoch: 6| Step: 2
Training loss: 0.2852800488471985
Validation loss: 1.6428997362813642

Epoch: 6| Step: 3
Training loss: 0.4727441668510437
Validation loss: 1.681742343851315

Epoch: 6| Step: 4
Training loss: 0.2763950228691101
Validation loss: 1.6612094897095875

Epoch: 6| Step: 5
Training loss: 0.43039438128471375
Validation loss: 1.6500187932804067

Epoch: 6| Step: 6
Training loss: 0.21048323810100555
Validation loss: 1.6276205432030462

Epoch: 6| Step: 7
Training loss: 0.5090433359146118
Validation loss: 1.645325203095713

Epoch: 6| Step: 8
Training loss: 0.43453896045684814
Validation loss: 1.6481341982400546

Epoch: 6| Step: 9
Training loss: 0.24994419515132904
Validation loss: 1.6615746585271691

Epoch: 6| Step: 10
Training loss: 0.7247340083122253
Validation loss: 1.6776179088059293

Epoch: 6| Step: 11
Training loss: 0.3553977608680725
Validation loss: 1.7201601177133539

Epoch: 6| Step: 12
Training loss: 0.38916295766830444
Validation loss: 1.7225558783418389

Epoch: 6| Step: 13
Training loss: 0.5925936698913574
Validation loss: 1.6665629180528785

Epoch: 340| Step: 0
Training loss: 0.4003675580024719
Validation loss: 1.6356978852261779

Epoch: 6| Step: 1
Training loss: 0.3256799578666687
Validation loss: 1.6280115740273589

Epoch: 6| Step: 2
Training loss: 0.3204619586467743
Validation loss: 1.6276980023230276

Epoch: 6| Step: 3
Training loss: 0.49659407138824463
Validation loss: 1.6509798854909918

Epoch: 6| Step: 4
Training loss: 0.5897240042686462
Validation loss: 1.661154600881761

Epoch: 6| Step: 5
Training loss: 0.37513041496276855
Validation loss: 1.6586187116561397

Epoch: 6| Step: 6
Training loss: 0.3764553666114807
Validation loss: 1.671652788756996

Epoch: 6| Step: 7
Training loss: 0.279188334941864
Validation loss: 1.6722350581999748

Epoch: 6| Step: 8
Training loss: 0.6360819935798645
Validation loss: 1.6789879350252048

Epoch: 6| Step: 9
Training loss: 0.2619696855545044
Validation loss: 1.6629675190935853

Epoch: 6| Step: 10
Training loss: 0.3153330683708191
Validation loss: 1.6663778776763587

Epoch: 6| Step: 11
Training loss: 0.43408405780792236
Validation loss: 1.6775806514165734

Epoch: 6| Step: 12
Training loss: 0.35534781217575073
Validation loss: 1.6753424547051872

Epoch: 6| Step: 13
Training loss: 0.36023223400115967
Validation loss: 1.663070217255623

Epoch: 341| Step: 0
Training loss: 0.3699360489845276
Validation loss: 1.648505546713388

Epoch: 6| Step: 1
Training loss: 0.31448888778686523
Validation loss: 1.6448335070763864

Epoch: 6| Step: 2
Training loss: 0.25335055589675903
Validation loss: 1.6556397907195552

Epoch: 6| Step: 3
Training loss: 0.31062737107276917
Validation loss: 1.6507224152165074

Epoch: 6| Step: 4
Training loss: 0.43115705251693726
Validation loss: 1.6708565822211645

Epoch: 6| Step: 5
Training loss: 0.20091375708580017
Validation loss: 1.6715079866429812

Epoch: 6| Step: 6
Training loss: 0.31977033615112305
Validation loss: 1.6677041348590647

Epoch: 6| Step: 7
Training loss: 0.5363177061080933
Validation loss: 1.6634745956749044

Epoch: 6| Step: 8
Training loss: 0.4925549328327179
Validation loss: 1.6817486529709191

Epoch: 6| Step: 9
Training loss: 0.2320326864719391
Validation loss: 1.7048896538313998

Epoch: 6| Step: 10
Training loss: 0.29603901505470276
Validation loss: 1.6999632248314478

Epoch: 6| Step: 11
Training loss: 0.5978345274925232
Validation loss: 1.70866608876054

Epoch: 6| Step: 12
Training loss: 0.4898616075515747
Validation loss: 1.731260747037908

Epoch: 6| Step: 13
Training loss: 0.13349270820617676
Validation loss: 1.7094672315864152

Epoch: 342| Step: 0
Training loss: 0.42818784713745117
Validation loss: 1.6821750440905172

Epoch: 6| Step: 1
Training loss: 0.3438652753829956
Validation loss: 1.6619426178675827

Epoch: 6| Step: 2
Training loss: 0.3774229884147644
Validation loss: 1.670431888231667

Epoch: 6| Step: 3
Training loss: 0.4768490493297577
Validation loss: 1.6468678712844849

Epoch: 6| Step: 4
Training loss: 0.24810414016246796
Validation loss: 1.659014355751776

Epoch: 6| Step: 5
Training loss: 0.41177937388420105
Validation loss: 1.6551208265366093

Epoch: 6| Step: 6
Training loss: 0.3945643901824951
Validation loss: 1.6943332854137625

Epoch: 6| Step: 7
Training loss: 0.32957351207733154
Validation loss: 1.7153254465390277

Epoch: 6| Step: 8
Training loss: 0.5379503965377808
Validation loss: 1.6968438958608976

Epoch: 6| Step: 9
Training loss: 0.25610947608947754
Validation loss: 1.6629964754145632

Epoch: 6| Step: 10
Training loss: 0.29488927125930786
Validation loss: 1.6347568009489326

Epoch: 6| Step: 11
Training loss: 0.22714291512966156
Validation loss: 1.6425990020075152

Epoch: 6| Step: 12
Training loss: 0.30789607763290405
Validation loss: 1.6355415531384048

Epoch: 6| Step: 13
Training loss: 0.45257723331451416
Validation loss: 1.6288498716969644

Epoch: 343| Step: 0
Training loss: 0.526636004447937
Validation loss: 1.5879591280414211

Epoch: 6| Step: 1
Training loss: 0.29064905643463135
Validation loss: 1.6011661893577986

Epoch: 6| Step: 2
Training loss: 0.3648023009300232
Validation loss: 1.6079404828368977

Epoch: 6| Step: 3
Training loss: 0.5009182691574097
Validation loss: 1.6206262983301634

Epoch: 6| Step: 4
Training loss: 0.2613351345062256
Validation loss: 1.6131522347850185

Epoch: 6| Step: 5
Training loss: 0.34941959381103516
Validation loss: 1.5974650421450216

Epoch: 6| Step: 6
Training loss: 0.2915741801261902
Validation loss: 1.598733764822765

Epoch: 6| Step: 7
Training loss: 0.22298119962215424
Validation loss: 1.6269997191685501

Epoch: 6| Step: 8
Training loss: 0.2622601091861725
Validation loss: 1.5899463776619203

Epoch: 6| Step: 9
Training loss: 0.4477479159832001
Validation loss: 1.5894645080771497

Epoch: 6| Step: 10
Training loss: 0.4927269518375397
Validation loss: 1.589483678981822

Epoch: 6| Step: 11
Training loss: 0.4251832067966461
Validation loss: 1.606869807807348

Epoch: 6| Step: 12
Training loss: 0.3358422517776489
Validation loss: 1.6276227915158836

Epoch: 6| Step: 13
Training loss: 0.22564071416854858
Validation loss: 1.605178815062328

Epoch: 344| Step: 0
Training loss: 0.1808948665857315
Validation loss: 1.6556311717597387

Epoch: 6| Step: 1
Training loss: 0.28937429189682007
Validation loss: 1.672100809312636

Epoch: 6| Step: 2
Training loss: 0.2893322706222534
Validation loss: 1.7138865763141262

Epoch: 6| Step: 3
Training loss: 0.5678256154060364
Validation loss: 1.7205804189046223

Epoch: 6| Step: 4
Training loss: 0.4089967608451843
Validation loss: 1.7121160338001866

Epoch: 6| Step: 5
Training loss: 0.32474052906036377
Validation loss: 1.6937524144367506

Epoch: 6| Step: 6
Training loss: 0.45728954672813416
Validation loss: 1.7046489766848985

Epoch: 6| Step: 7
Training loss: 0.3793010413646698
Validation loss: 1.7033152567443026

Epoch: 6| Step: 8
Training loss: 0.49224236607551575
Validation loss: 1.7060078267128236

Epoch: 6| Step: 9
Training loss: 0.45229268074035645
Validation loss: 1.6799449446380779

Epoch: 6| Step: 10
Training loss: 0.4770405888557434
Validation loss: 1.688928291361819

Epoch: 6| Step: 11
Training loss: 0.4323299527168274
Validation loss: 1.6702833829387542

Epoch: 6| Step: 12
Training loss: 0.3215375244617462
Validation loss: 1.7017445705270255

Epoch: 6| Step: 13
Training loss: 0.5173917412757874
Validation loss: 1.694533057110284

Epoch: 345| Step: 0
Training loss: 0.46036669611930847
Validation loss: 1.6949106461258345

Epoch: 6| Step: 1
Training loss: 0.44876837730407715
Validation loss: 1.7265120206340667

Epoch: 6| Step: 2
Training loss: 0.6287888884544373
Validation loss: 1.7139071854211951

Epoch: 6| Step: 3
Training loss: 0.3981819748878479
Validation loss: 1.7308729438371555

Epoch: 6| Step: 4
Training loss: 0.3183221220970154
Validation loss: 1.7224844373682493

Epoch: 6| Step: 5
Training loss: 0.4735684096813202
Validation loss: 1.7224809354351414

Epoch: 6| Step: 6
Training loss: 0.43095412850379944
Validation loss: 1.7595954556618967

Epoch: 6| Step: 7
Training loss: 0.4853166937828064
Validation loss: 1.7391122656483804

Epoch: 6| Step: 8
Training loss: 0.618484616279602
Validation loss: 1.7297032251152942

Epoch: 6| Step: 9
Training loss: 0.23888325691223145
Validation loss: 1.76080483646803

Epoch: 6| Step: 10
Training loss: 0.43270018696784973
Validation loss: 1.7052599383938698

Epoch: 6| Step: 11
Training loss: 0.32087060809135437
Validation loss: 1.741801349065637

Epoch: 6| Step: 12
Training loss: 0.3885136842727661
Validation loss: 1.759385625521342

Epoch: 6| Step: 13
Training loss: 0.5263878107070923
Validation loss: 1.820878545443217

Epoch: 346| Step: 0
Training loss: 0.6255667209625244
Validation loss: 1.7883866179373957

Epoch: 6| Step: 1
Training loss: 0.4198489785194397
Validation loss: 1.6933638946984404

Epoch: 6| Step: 2
Training loss: 0.36001789569854736
Validation loss: 1.6454150958727765

Epoch: 6| Step: 3
Training loss: 0.4580579698085785
Validation loss: 1.6248633284722604

Epoch: 6| Step: 4
Training loss: 0.3784015476703644
Validation loss: 1.6023852696982763

Epoch: 6| Step: 5
Training loss: 0.40774232149124146
Validation loss: 1.6373281145608554

Epoch: 6| Step: 6
Training loss: 0.3990011513233185
Validation loss: 1.662185324135647

Epoch: 6| Step: 7
Training loss: 0.3387709856033325
Validation loss: 1.698764956125649

Epoch: 6| Step: 8
Training loss: 0.2621811032295227
Validation loss: 1.704522991052238

Epoch: 6| Step: 9
Training loss: 0.472354918718338
Validation loss: 1.7433406819579422

Epoch: 6| Step: 10
Training loss: 0.5609592795372009
Validation loss: 1.7674880643044748

Epoch: 6| Step: 11
Training loss: 0.5214937925338745
Validation loss: 1.7755534905259327

Epoch: 6| Step: 12
Training loss: 0.4173729717731476
Validation loss: 1.7755768747739895

Epoch: 6| Step: 13
Training loss: 0.6644943952560425
Validation loss: 1.7132772322623961

Epoch: 347| Step: 0
Training loss: 0.3117111921310425
Validation loss: 1.6649150015205465

Epoch: 6| Step: 1
Training loss: 0.5727962255477905
Validation loss: 1.6512014109601256

Epoch: 6| Step: 2
Training loss: 0.3731154203414917
Validation loss: 1.6376839658265472

Epoch: 6| Step: 3
Training loss: 0.3521813154220581
Validation loss: 1.622883117327126

Epoch: 6| Step: 4
Training loss: 0.4294310212135315
Validation loss: 1.6547668774922688

Epoch: 6| Step: 5
Training loss: 0.5260428190231323
Validation loss: 1.6765067743998703

Epoch: 6| Step: 6
Training loss: 0.49440068006515503
Validation loss: 1.7235915853131203

Epoch: 6| Step: 7
Training loss: 0.3218405246734619
Validation loss: 1.743544279888112

Epoch: 6| Step: 8
Training loss: 0.5218545794487
Validation loss: 1.7488364904157576

Epoch: 6| Step: 9
Training loss: 0.5072531700134277
Validation loss: 1.7192963451467536

Epoch: 6| Step: 10
Training loss: 0.38232770562171936
Validation loss: 1.7007826361604916

Epoch: 6| Step: 11
Training loss: 0.46627870202064514
Validation loss: 1.6863763909186087

Epoch: 6| Step: 12
Training loss: 0.36081361770629883
Validation loss: 1.644550044049499

Epoch: 6| Step: 13
Training loss: 0.22191081941127777
Validation loss: 1.6298385807262954

Epoch: 348| Step: 0
Training loss: 0.5730283856391907
Validation loss: 1.6396280847569948

Epoch: 6| Step: 1
Training loss: 0.2934405505657196
Validation loss: 1.63231913633244

Epoch: 6| Step: 2
Training loss: 0.3739042580127716
Validation loss: 1.619328547549504

Epoch: 6| Step: 3
Training loss: 0.2415929138660431
Validation loss: 1.6161680401012462

Epoch: 6| Step: 4
Training loss: 0.17634540796279907
Validation loss: 1.6459180988291258

Epoch: 6| Step: 5
Training loss: 0.25210198760032654
Validation loss: 1.6137095215500041

Epoch: 6| Step: 6
Training loss: 0.23292110860347748
Validation loss: 1.6359642321063625

Epoch: 6| Step: 7
Training loss: 0.4495340585708618
Validation loss: 1.616362520443496

Epoch: 6| Step: 8
Training loss: 0.19132618606090546
Validation loss: 1.5995127808663152

Epoch: 6| Step: 9
Training loss: 0.3173702359199524
Validation loss: 1.640715055568244

Epoch: 6| Step: 10
Training loss: 0.5459675788879395
Validation loss: 1.6926708657254455

Epoch: 6| Step: 11
Training loss: 0.14183813333511353
Validation loss: 1.6869226655652445

Epoch: 6| Step: 12
Training loss: 0.6558932065963745
Validation loss: 1.7129992156900384

Epoch: 6| Step: 13
Training loss: 0.4362899661064148
Validation loss: 1.686394609430785

Epoch: 349| Step: 0
Training loss: 0.821929931640625
Validation loss: 1.7143235527059084

Epoch: 6| Step: 1
Training loss: 0.30170369148254395
Validation loss: 1.750805434360299

Epoch: 6| Step: 2
Training loss: 0.2684100568294525
Validation loss: 1.7257760519622474

Epoch: 6| Step: 3
Training loss: 0.3838461637496948
Validation loss: 1.706778932643193

Epoch: 6| Step: 4
Training loss: 0.2580236494541168
Validation loss: 1.7043242531438028

Epoch: 6| Step: 5
Training loss: 0.37179186940193176
Validation loss: 1.6389906150038525

Epoch: 6| Step: 6
Training loss: 0.2623763084411621
Validation loss: 1.6483093192500453

Epoch: 6| Step: 7
Training loss: 0.299861341714859
Validation loss: 1.6285020600083053

Epoch: 6| Step: 8
Training loss: 0.4902196228504181
Validation loss: 1.6375238100687664

Epoch: 6| Step: 9
Training loss: 0.23578211665153503
Validation loss: 1.6662667374457083

Epoch: 6| Step: 10
Training loss: 0.2858777642250061
Validation loss: 1.6557932874207855

Epoch: 6| Step: 11
Training loss: 0.1917620599269867
Validation loss: 1.662480068463151

Epoch: 6| Step: 12
Training loss: 0.20527808368206024
Validation loss: 1.6459248681222238

Epoch: 6| Step: 13
Training loss: 0.20496433973312378
Validation loss: 1.6349239913366174

Epoch: 350| Step: 0
Training loss: 0.5389297604560852
Validation loss: 1.6512508571788829

Epoch: 6| Step: 1
Training loss: 0.3708066940307617
Validation loss: 1.6332230657659552

Epoch: 6| Step: 2
Training loss: 0.3416863977909088
Validation loss: 1.657598828756681

Epoch: 6| Step: 3
Training loss: 0.2966264486312866
Validation loss: 1.6775044805260115

Epoch: 6| Step: 4
Training loss: 0.3468008041381836
Validation loss: 1.7428550899669688

Epoch: 6| Step: 5
Training loss: 0.4078676402568817
Validation loss: 1.755279460260945

Epoch: 6| Step: 6
Training loss: 0.21988801658153534
Validation loss: 1.7140303119536369

Epoch: 6| Step: 7
Training loss: 0.2724214494228363
Validation loss: 1.6839976336366387

Epoch: 6| Step: 8
Training loss: 0.3568086624145508
Validation loss: 1.691357163972752

Epoch: 6| Step: 9
Training loss: 0.24415931105613708
Validation loss: 1.6302362859890025

Epoch: 6| Step: 10
Training loss: 0.5073946714401245
Validation loss: 1.6250767720642911

Epoch: 6| Step: 11
Training loss: 0.2841152846813202
Validation loss: 1.61185868324772

Epoch: 6| Step: 12
Training loss: 0.3603869676589966
Validation loss: 1.5933206427481867

Epoch: 6| Step: 13
Training loss: 0.31126996874809265
Validation loss: 1.6170896522460445

Epoch: 351| Step: 0
Training loss: 0.5611225962638855
Validation loss: 1.6219794596395185

Epoch: 6| Step: 1
Training loss: 0.334367573261261
Validation loss: 1.6306112889320619

Epoch: 6| Step: 2
Training loss: 0.2453213632106781
Validation loss: 1.6600630744811027

Epoch: 6| Step: 3
Training loss: 0.3089348077774048
Validation loss: 1.6612173434226745

Epoch: 6| Step: 4
Training loss: 0.2692490816116333
Validation loss: 1.6050344936309322

Epoch: 6| Step: 5
Training loss: 0.50691819190979
Validation loss: 1.633130145329301

Epoch: 6| Step: 6
Training loss: 0.25876402854919434
Validation loss: 1.6257198984904955

Epoch: 6| Step: 7
Training loss: 0.4222550392150879
Validation loss: 1.6479000968317832

Epoch: 6| Step: 8
Training loss: 0.3810644745826721
Validation loss: 1.645084015784725

Epoch: 6| Step: 9
Training loss: 0.3131738305091858
Validation loss: 1.6609035666270922

Epoch: 6| Step: 10
Training loss: 0.33591657876968384
Validation loss: 1.6396968774898077

Epoch: 6| Step: 11
Training loss: 0.23531627655029297
Validation loss: 1.6679054178217405

Epoch: 6| Step: 12
Training loss: 0.38716191053390503
Validation loss: 1.668446474177863

Epoch: 6| Step: 13
Training loss: 0.31472671031951904
Validation loss: 1.668327308470203

Epoch: 352| Step: 0
Training loss: 0.3504549264907837
Validation loss: 1.6816198646381337

Epoch: 6| Step: 1
Training loss: 0.23403286933898926
Validation loss: 1.685114486243135

Epoch: 6| Step: 2
Training loss: 0.21351951360702515
Validation loss: 1.6953957285932315

Epoch: 6| Step: 3
Training loss: 0.4874393343925476
Validation loss: 1.7077901465918428

Epoch: 6| Step: 4
Training loss: 0.39065924286842346
Validation loss: 1.6845056254376647

Epoch: 6| Step: 5
Training loss: 0.32778897881507874
Validation loss: 1.6680535129321519

Epoch: 6| Step: 6
Training loss: 0.2879571318626404
Validation loss: 1.6484834788947977

Epoch: 6| Step: 7
Training loss: 0.2120935469865799
Validation loss: 1.642515165831453

Epoch: 6| Step: 8
Training loss: 0.392787903547287
Validation loss: 1.6346400553180325

Epoch: 6| Step: 9
Training loss: 0.31204867362976074
Validation loss: 1.6100211220402871

Epoch: 6| Step: 10
Training loss: 0.3747665584087372
Validation loss: 1.610922195578134

Epoch: 6| Step: 11
Training loss: 0.3449930250644684
Validation loss: 1.6353372476434196

Epoch: 6| Step: 12
Training loss: 0.32270917296409607
Validation loss: 1.6389591065786218

Epoch: 6| Step: 13
Training loss: 0.3994138240814209
Validation loss: 1.6471269156343193

Epoch: 353| Step: 0
Training loss: 0.17216230928897858
Validation loss: 1.6671237163646246

Epoch: 6| Step: 1
Training loss: 0.41363510489463806
Validation loss: 1.7079107235836726

Epoch: 6| Step: 2
Training loss: 0.41432905197143555
Validation loss: 1.7372285909550165

Epoch: 6| Step: 3
Training loss: 0.19493170082569122
Validation loss: 1.7253614433350102

Epoch: 6| Step: 4
Training loss: 0.3922269642353058
Validation loss: 1.673985267198214

Epoch: 6| Step: 5
Training loss: 0.4374696612358093
Validation loss: 1.6437075548274542

Epoch: 6| Step: 6
Training loss: 0.366544246673584
Validation loss: 1.6297764778137207

Epoch: 6| Step: 7
Training loss: 0.3111376464366913
Validation loss: 1.6127198319281302

Epoch: 6| Step: 8
Training loss: 0.26534008979797363
Validation loss: 1.5973025445015199

Epoch: 6| Step: 9
Training loss: 0.205659419298172
Validation loss: 1.6045177085425264

Epoch: 6| Step: 10
Training loss: 0.40004515647888184
Validation loss: 1.606183014890199

Epoch: 6| Step: 11
Training loss: 0.5542661547660828
Validation loss: 1.5898736317952473

Epoch: 6| Step: 12
Training loss: 0.6330065727233887
Validation loss: 1.5902560680143294

Epoch: 6| Step: 13
Training loss: 0.25305071473121643
Validation loss: 1.6163564830697992

Epoch: 354| Step: 0
Training loss: 0.23916533589363098
Validation loss: 1.6246288258542296

Epoch: 6| Step: 1
Training loss: 0.19636616110801697
Validation loss: 1.6449365051843787

Epoch: 6| Step: 2
Training loss: 0.46330446004867554
Validation loss: 1.6542598842292704

Epoch: 6| Step: 3
Training loss: 0.5988986492156982
Validation loss: 1.6559340107825495

Epoch: 6| Step: 4
Training loss: 0.3182342052459717
Validation loss: 1.607228417550364

Epoch: 6| Step: 5
Training loss: 0.5103254318237305
Validation loss: 1.5592790149873303

Epoch: 6| Step: 6
Training loss: 0.30229178071022034
Validation loss: 1.5646537068069621

Epoch: 6| Step: 7
Training loss: 0.3540351986885071
Validation loss: 1.6205149786446684

Epoch: 6| Step: 8
Training loss: 0.4670475125312805
Validation loss: 1.6110718237456454

Epoch: 6| Step: 9
Training loss: 0.5268036127090454
Validation loss: 1.607765204163008

Epoch: 6| Step: 10
Training loss: 0.4823281466960907
Validation loss: 1.6136158922667145

Epoch: 6| Step: 11
Training loss: 0.5623840093612671
Validation loss: 1.5485261858150523

Epoch: 6| Step: 12
Training loss: 0.3925315737724304
Validation loss: 1.6126025030689854

Epoch: 6| Step: 13
Training loss: 0.3147388696670532
Validation loss: 1.6788844370072888

Epoch: 355| Step: 0
Training loss: 0.6915048956871033
Validation loss: 1.7570580679883239

Epoch: 6| Step: 1
Training loss: 0.4995605945587158
Validation loss: 1.819107706828784

Epoch: 6| Step: 2
Training loss: 0.7202351689338684
Validation loss: 1.852376860956992

Epoch: 6| Step: 3
Training loss: 0.26268261671066284
Validation loss: 1.7627236535472255

Epoch: 6| Step: 4
Training loss: 0.3147854208946228
Validation loss: 1.7086137533187866

Epoch: 6| Step: 5
Training loss: 0.315496027469635
Validation loss: 1.6551581018714494

Epoch: 6| Step: 6
Training loss: 0.5338588356971741
Validation loss: 1.683539108563495

Epoch: 6| Step: 7
Training loss: 0.3724810779094696
Validation loss: 1.70945688345099

Epoch: 6| Step: 8
Training loss: 0.46232283115386963
Validation loss: 1.684761062745125

Epoch: 6| Step: 9
Training loss: 0.3011753261089325
Validation loss: 1.7340318144008677

Epoch: 6| Step: 10
Training loss: 0.4052692949771881
Validation loss: 1.7337591237919305

Epoch: 6| Step: 11
Training loss: 0.4638269245624542
Validation loss: 1.7270772739123272

Epoch: 6| Step: 12
Training loss: 0.4089510440826416
Validation loss: 1.731970944712239

Epoch: 6| Step: 13
Training loss: 0.290863960981369
Validation loss: 1.7471727760889197

Epoch: 356| Step: 0
Training loss: 0.5939493775367737
Validation loss: 1.750650905793713

Epoch: 6| Step: 1
Training loss: 0.3866950571537018
Validation loss: 1.7281153407148135

Epoch: 6| Step: 2
Training loss: 0.3885156214237213
Validation loss: 1.6617024278128019

Epoch: 6| Step: 3
Training loss: 0.4116326570510864
Validation loss: 1.614794131248228

Epoch: 6| Step: 4
Training loss: 0.2743043303489685
Validation loss: 1.629066066716307

Epoch: 6| Step: 5
Training loss: 0.280220091342926
Validation loss: 1.6871614417722147

Epoch: 6| Step: 6
Training loss: 0.4176473021507263
Validation loss: 1.6554310655081144

Epoch: 6| Step: 7
Training loss: 0.25979602336883545
Validation loss: 1.696741836045378

Epoch: 6| Step: 8
Training loss: 0.3861807584762573
Validation loss: 1.711484670639038

Epoch: 6| Step: 9
Training loss: 0.6995868682861328
Validation loss: 1.7313755981383785

Epoch: 6| Step: 10
Training loss: 0.4416932463645935
Validation loss: 1.7516451599777385

Epoch: 6| Step: 11
Training loss: 0.3779951333999634
Validation loss: 1.7877830805317048

Epoch: 6| Step: 12
Training loss: 0.7075326442718506
Validation loss: 1.8280428391630932

Epoch: 6| Step: 13
Training loss: 0.4167637228965759
Validation loss: 1.7912125561826973

Epoch: 357| Step: 0
Training loss: 0.35077521204948425
Validation loss: 1.7384517064658545

Epoch: 6| Step: 1
Training loss: 0.4342823624610901
Validation loss: 1.696892120504892

Epoch: 6| Step: 2
Training loss: 0.3116638660430908
Validation loss: 1.6443750371215164

Epoch: 6| Step: 3
Training loss: 0.2991931438446045
Validation loss: 1.6403643956748388

Epoch: 6| Step: 4
Training loss: 0.3337688148021698
Validation loss: 1.6168306553235618

Epoch: 6| Step: 5
Training loss: 0.2562263011932373
Validation loss: 1.6234895811286023

Epoch: 6| Step: 6
Training loss: 0.4941907227039337
Validation loss: 1.6114419788442633

Epoch: 6| Step: 7
Training loss: 0.5415058732032776
Validation loss: 1.6192963994959348

Epoch: 6| Step: 8
Training loss: 0.27870962023735046
Validation loss: 1.6152529408854823

Epoch: 6| Step: 9
Training loss: 0.277111291885376
Validation loss: 1.6089348985302834

Epoch: 6| Step: 10
Training loss: 0.30914539098739624
Validation loss: 1.5925513928936375

Epoch: 6| Step: 11
Training loss: 0.34583592414855957
Validation loss: 1.628844072741847

Epoch: 6| Step: 12
Training loss: 0.49539124965667725
Validation loss: 1.6631267968044485

Epoch: 6| Step: 13
Training loss: 0.4501326382160187
Validation loss: 1.6700168860855924

Epoch: 358| Step: 0
Training loss: 0.634545087814331
Validation loss: 1.6978322293168755

Epoch: 6| Step: 1
Training loss: 0.38037824630737305
Validation loss: 1.6570563752164122

Epoch: 6| Step: 2
Training loss: 0.3028211295604706
Validation loss: 1.6504172804535076

Epoch: 6| Step: 3
Training loss: 0.20848089456558228
Validation loss: 1.601068345449304

Epoch: 6| Step: 4
Training loss: 0.2803151309490204
Validation loss: 1.6180254541417605

Epoch: 6| Step: 5
Training loss: 0.6004230380058289
Validation loss: 1.6308640703078239

Epoch: 6| Step: 6
Training loss: 0.3606041669845581
Validation loss: 1.6365385504179104

Epoch: 6| Step: 7
Training loss: 0.5051389932632446
Validation loss: 1.6410902084842804

Epoch: 6| Step: 8
Training loss: 0.27831071615219116
Validation loss: 1.6184830075951033

Epoch: 6| Step: 9
Training loss: 0.34272879362106323
Validation loss: 1.6299183701956144

Epoch: 6| Step: 10
Training loss: 0.34813398122787476
Validation loss: 1.6493214215001752

Epoch: 6| Step: 11
Training loss: 0.22544389963150024
Validation loss: 1.6882428892197148

Epoch: 6| Step: 12
Training loss: 0.2096083164215088
Validation loss: 1.7263718894732896

Epoch: 6| Step: 13
Training loss: 0.4157380759716034
Validation loss: 1.7518715820004862

Epoch: 359| Step: 0
Training loss: 0.6919382810592651
Validation loss: 1.783121729409823

Epoch: 6| Step: 1
Training loss: 0.3516814708709717
Validation loss: 1.7591180493754726

Epoch: 6| Step: 2
Training loss: 0.404013067483902
Validation loss: 1.721602782126396

Epoch: 6| Step: 3
Training loss: 0.24629151821136475
Validation loss: 1.6781591266714118

Epoch: 6| Step: 4
Training loss: 0.20969823002815247
Validation loss: 1.6082475698122414

Epoch: 6| Step: 5
Training loss: 0.2834317684173584
Validation loss: 1.6088098467037242

Epoch: 6| Step: 6
Training loss: 0.21829469501972198
Validation loss: 1.6241321384265859

Epoch: 6| Step: 7
Training loss: 0.25280851125717163
Validation loss: 1.6105768167844383

Epoch: 6| Step: 8
Training loss: 0.3536120653152466
Validation loss: 1.6459310926416868

Epoch: 6| Step: 9
Training loss: 0.2837974429130554
Validation loss: 1.6530473232269287

Epoch: 6| Step: 10
Training loss: 0.5100271701812744
Validation loss: 1.6418608644957184

Epoch: 6| Step: 11
Training loss: 0.3060376048088074
Validation loss: 1.6293917086816603

Epoch: 6| Step: 12
Training loss: 0.5722622871398926
Validation loss: 1.6620399836570985

Epoch: 6| Step: 13
Training loss: 0.7654927372932434
Validation loss: 1.6844046295330088

Epoch: 360| Step: 0
Training loss: 0.4230373799800873
Validation loss: 1.6832253381770144

Epoch: 6| Step: 1
Training loss: 0.40410932898521423
Validation loss: 1.7571518177627234

Epoch: 6| Step: 2
Training loss: 0.5481232404708862
Validation loss: 1.7904106493919127

Epoch: 6| Step: 3
Training loss: 0.32228901982307434
Validation loss: 1.75239481336327

Epoch: 6| Step: 4
Training loss: 0.4883144497871399
Validation loss: 1.7254806423699984

Epoch: 6| Step: 5
Training loss: 0.2769359350204468
Validation loss: 1.6490816723915838

Epoch: 6| Step: 6
Training loss: 0.17952501773834229
Validation loss: 1.616767027044809

Epoch: 6| Step: 7
Training loss: 0.4501142203807831
Validation loss: 1.6291976628764984

Epoch: 6| Step: 8
Training loss: 0.3945944309234619
Validation loss: 1.6600094790099769

Epoch: 6| Step: 9
Training loss: 0.47475218772888184
Validation loss: 1.6576523498822284

Epoch: 6| Step: 10
Training loss: 0.36107170581817627
Validation loss: 1.661417886775027

Epoch: 6| Step: 11
Training loss: 0.5653766989707947
Validation loss: 1.6805683605132564

Epoch: 6| Step: 12
Training loss: 0.40268462896347046
Validation loss: 1.6537215812231905

Epoch: 6| Step: 13
Training loss: 0.2403363138437271
Validation loss: 1.6469770618664321

Epoch: 361| Step: 0
Training loss: 0.25344106554985046
Validation loss: 1.6789582596030286

Epoch: 6| Step: 1
Training loss: 0.32557499408721924
Validation loss: 1.702878850762562

Epoch: 6| Step: 2
Training loss: 0.44466033577919006
Validation loss: 1.7149686903081915

Epoch: 6| Step: 3
Training loss: 0.5631963014602661
Validation loss: 1.7201781349797403

Epoch: 6| Step: 4
Training loss: 0.37951362133026123
Validation loss: 1.7033838789950135

Epoch: 6| Step: 5
Training loss: 0.44616690278053284
Validation loss: 1.665553303175075

Epoch: 6| Step: 6
Training loss: 0.3037800192832947
Validation loss: 1.610353422421281

Epoch: 6| Step: 7
Training loss: 0.3689122200012207
Validation loss: 1.6062790655320691

Epoch: 6| Step: 8
Training loss: 0.25273144245147705
Validation loss: 1.5576472795137795

Epoch: 6| Step: 9
Training loss: 0.42678889632225037
Validation loss: 1.5891367197036743

Epoch: 6| Step: 10
Training loss: 0.3303067088127136
Validation loss: 1.55740737658675

Epoch: 6| Step: 11
Training loss: 0.3163081109523773
Validation loss: 1.5653831676770282

Epoch: 6| Step: 12
Training loss: 0.2124314308166504
Validation loss: 1.5852868954340618

Epoch: 6| Step: 13
Training loss: 0.28570881485939026
Validation loss: 1.5609874827887422

Epoch: 362| Step: 0
Training loss: 0.36358642578125
Validation loss: 1.5771413887700727

Epoch: 6| Step: 1
Training loss: 0.38661590218544006
Validation loss: 1.6141257234798965

Epoch: 6| Step: 2
Training loss: 0.24729833006858826
Validation loss: 1.6652903941369825

Epoch: 6| Step: 3
Training loss: 0.5258416533470154
Validation loss: 1.6625825025702035

Epoch: 6| Step: 4
Training loss: 0.2994288504123688
Validation loss: 1.6655608915513562

Epoch: 6| Step: 5
Training loss: 0.18328145146369934
Validation loss: 1.6540700850948211

Epoch: 6| Step: 6
Training loss: 0.41602492332458496
Validation loss: 1.675128202284536

Epoch: 6| Step: 7
Training loss: 0.1660872995853424
Validation loss: 1.6029752736450524

Epoch: 6| Step: 8
Training loss: 0.25787150859832764
Validation loss: 1.606550291020383

Epoch: 6| Step: 9
Training loss: 0.29431501030921936
Validation loss: 1.5901720011106102

Epoch: 6| Step: 10
Training loss: 0.39922916889190674
Validation loss: 1.5924494625419698

Epoch: 6| Step: 11
Training loss: 0.3292188048362732
Validation loss: 1.570970077668467

Epoch: 6| Step: 12
Training loss: 0.3305521309375763
Validation loss: 1.575756827990214

Epoch: 6| Step: 13
Training loss: 0.21090556681156158
Validation loss: 1.5956315020079255

Epoch: 363| Step: 0
Training loss: 0.4545746445655823
Validation loss: 1.6336590282378658

Epoch: 6| Step: 1
Training loss: 0.2919604182243347
Validation loss: 1.6526912284153763

Epoch: 6| Step: 2
Training loss: 0.3491057753562927
Validation loss: 1.6541083499949465

Epoch: 6| Step: 3
Training loss: 0.3154926598072052
Validation loss: 1.6132961870521627

Epoch: 6| Step: 4
Training loss: 0.22374150156974792
Validation loss: 1.6212636129830473

Epoch: 6| Step: 5
Training loss: 0.4125449061393738
Validation loss: 1.5991852386023409

Epoch: 6| Step: 6
Training loss: 0.327034056186676
Validation loss: 1.5895740344960203

Epoch: 6| Step: 7
Training loss: 0.18205538392066956
Validation loss: 1.6080158782261673

Epoch: 6| Step: 8
Training loss: 0.18863923847675323
Validation loss: 1.595437519011959

Epoch: 6| Step: 9
Training loss: 0.3048303723335266
Validation loss: 1.618043279135099

Epoch: 6| Step: 10
Training loss: 0.20189133286476135
Validation loss: 1.6101630721040951

Epoch: 6| Step: 11
Training loss: 0.25517141819000244
Validation loss: 1.617349801524993

Epoch: 6| Step: 12
Training loss: 0.31006330251693726
Validation loss: 1.6171663602193196

Epoch: 6| Step: 13
Training loss: 0.16441407799720764
Validation loss: 1.6064644411046018

Epoch: 364| Step: 0
Training loss: 0.36550459265708923
Validation loss: 1.6215787933718773

Epoch: 6| Step: 1
Training loss: 0.16577032208442688
Validation loss: 1.615778116769688

Epoch: 6| Step: 2
Training loss: 0.23133161664009094
Validation loss: 1.6253762572042403

Epoch: 6| Step: 3
Training loss: 0.11959505826234818
Validation loss: 1.598240533823608

Epoch: 6| Step: 4
Training loss: 0.3543136417865753
Validation loss: 1.6034364751590195

Epoch: 6| Step: 5
Training loss: 0.39537620544433594
Validation loss: 1.5908207598552908

Epoch: 6| Step: 6
Training loss: 0.2679674029350281
Validation loss: 1.5924556973159953

Epoch: 6| Step: 7
Training loss: 0.24383452534675598
Validation loss: 1.6198168185449415

Epoch: 6| Step: 8
Training loss: 0.2076062113046646
Validation loss: 1.621927898417237

Epoch: 6| Step: 9
Training loss: 0.2911439836025238
Validation loss: 1.5968645977717575

Epoch: 6| Step: 10
Training loss: 0.33954232931137085
Validation loss: 1.5939333156872821

Epoch: 6| Step: 11
Training loss: 0.38672178983688354
Validation loss: 1.6058570133742465

Epoch: 6| Step: 12
Training loss: 0.270239919424057
Validation loss: 1.6041641337897188

Epoch: 6| Step: 13
Training loss: 0.23621521890163422
Validation loss: 1.6167928877697195

Epoch: 365| Step: 0
Training loss: 0.3459357023239136
Validation loss: 1.6207657872989614

Epoch: 6| Step: 1
Training loss: 0.4382355213165283
Validation loss: 1.598054753836765

Epoch: 6| Step: 2
Training loss: 0.3080655038356781
Validation loss: 1.5837706327438354

Epoch: 6| Step: 3
Training loss: 0.31276991963386536
Validation loss: 1.605562888806866

Epoch: 6| Step: 4
Training loss: 0.21831688284873962
Validation loss: 1.6022854428137503

Epoch: 6| Step: 5
Training loss: 0.17691391706466675
Validation loss: 1.595085314525071

Epoch: 6| Step: 6
Training loss: 0.37325340509414673
Validation loss: 1.5789825724017235

Epoch: 6| Step: 7
Training loss: 0.17456790804862976
Validation loss: 1.6078311576638171

Epoch: 6| Step: 8
Training loss: 0.19807256758213043
Validation loss: 1.6058544112790016

Epoch: 6| Step: 9
Training loss: 0.15757440030574799
Validation loss: 1.6028051145615116

Epoch: 6| Step: 10
Training loss: 0.2094513326883316
Validation loss: 1.5882107583425378

Epoch: 6| Step: 11
Training loss: 0.163862407207489
Validation loss: 1.6040716312264884

Epoch: 6| Step: 12
Training loss: 0.28434044122695923
Validation loss: 1.598829879555651

Epoch: 6| Step: 13
Training loss: 0.4421957731246948
Validation loss: 1.5981178911783362

Epoch: 366| Step: 0
Training loss: 0.21216543018817902
Validation loss: 1.574132054082809

Epoch: 6| Step: 1
Training loss: 0.1819276511669159
Validation loss: 1.6051037567918018

Epoch: 6| Step: 2
Training loss: 0.24257643520832062
Validation loss: 1.6111626945516115

Epoch: 6| Step: 3
Training loss: 0.1546696573495865
Validation loss: 1.6252518507742113

Epoch: 6| Step: 4
Training loss: 0.32024291157722473
Validation loss: 1.6053026671050696

Epoch: 6| Step: 5
Training loss: 0.3169635832309723
Validation loss: 1.624783553102965

Epoch: 6| Step: 6
Training loss: 0.3008688688278198
Validation loss: 1.6154093460370136

Epoch: 6| Step: 7
Training loss: 0.24396108090877533
Validation loss: 1.6436114836764593

Epoch: 6| Step: 8
Training loss: 0.2403377890586853
Validation loss: 1.6355184919090682

Epoch: 6| Step: 9
Training loss: 0.4014926552772522
Validation loss: 1.6212854705831057

Epoch: 6| Step: 10
Training loss: 0.37103933095932007
Validation loss: 1.6329285688297723

Epoch: 6| Step: 11
Training loss: 0.2911681532859802
Validation loss: 1.622449868468828

Epoch: 6| Step: 12
Training loss: 0.31969720125198364
Validation loss: 1.624188365474824

Epoch: 6| Step: 13
Training loss: 0.22982358932495117
Validation loss: 1.6142201808191114

Epoch: 367| Step: 0
Training loss: 0.16185127198696136
Validation loss: 1.6133238628346434

Epoch: 6| Step: 1
Training loss: 0.475795179605484
Validation loss: 1.6498141775849045

Epoch: 6| Step: 2
Training loss: 0.1772647500038147
Validation loss: 1.6089416357778734

Epoch: 6| Step: 3
Training loss: 0.24490341544151306
Validation loss: 1.6101869242165678

Epoch: 6| Step: 4
Training loss: 0.249167799949646
Validation loss: 1.6227210888298609

Epoch: 6| Step: 5
Training loss: 0.3467957079410553
Validation loss: 1.6264190417464062

Epoch: 6| Step: 6
Training loss: 0.3666059970855713
Validation loss: 1.6153216400454122

Epoch: 6| Step: 7
Training loss: 0.12379768490791321
Validation loss: 1.5869568163348782

Epoch: 6| Step: 8
Training loss: 0.19227561354637146
Validation loss: 1.5599282031418176

Epoch: 6| Step: 9
Training loss: 0.18475569784641266
Validation loss: 1.5546039490289585

Epoch: 6| Step: 10
Training loss: 0.4049699306488037
Validation loss: 1.5390327566413469

Epoch: 6| Step: 11
Training loss: 0.2935628294944763
Validation loss: 1.5586051607644686

Epoch: 6| Step: 12
Training loss: 0.354417085647583
Validation loss: 1.5390352690091698

Epoch: 6| Step: 13
Training loss: 0.20076031982898712
Validation loss: 1.5548359681201238

Epoch: 368| Step: 0
Training loss: 0.12599146366119385
Validation loss: 1.5643592957527406

Epoch: 6| Step: 1
Training loss: 0.2587816119194031
Validation loss: 1.5889173720472602

Epoch: 6| Step: 2
Training loss: 0.2808372974395752
Validation loss: 1.6045975274937128

Epoch: 6| Step: 3
Training loss: 0.37727946043014526
Validation loss: 1.6171985198092718

Epoch: 6| Step: 4
Training loss: 0.25800374150276184
Validation loss: 1.6015087122558265

Epoch: 6| Step: 5
Training loss: 0.2864348292350769
Validation loss: 1.5788425578865954

Epoch: 6| Step: 6
Training loss: 0.22198081016540527
Validation loss: 1.5714254904818792

Epoch: 6| Step: 7
Training loss: 0.390786349773407
Validation loss: 1.5648196692107825

Epoch: 6| Step: 8
Training loss: 0.3180398643016815
Validation loss: 1.579064751184115

Epoch: 6| Step: 9
Training loss: 0.3202587366104126
Validation loss: 1.5582394215368456

Epoch: 6| Step: 10
Training loss: 0.17380475997924805
Validation loss: 1.5769828391331497

Epoch: 6| Step: 11
Training loss: 0.2517181932926178
Validation loss: 1.5614875490947435

Epoch: 6| Step: 12
Training loss: 0.12010830640792847
Validation loss: 1.5578090516469811

Epoch: 6| Step: 13
Training loss: 0.14558465778827667
Validation loss: 1.5276220960001792

Epoch: 369| Step: 0
Training loss: 0.3041820228099823
Validation loss: 1.5415418878678353

Epoch: 6| Step: 1
Training loss: 0.17763946950435638
Validation loss: 1.5366862345767278

Epoch: 6| Step: 2
Training loss: 0.24445709586143494
Validation loss: 1.550064202277891

Epoch: 6| Step: 3
Training loss: 0.24768519401550293
Validation loss: 1.5555469477048485

Epoch: 6| Step: 4
Training loss: 0.2008131742477417
Validation loss: 1.572370074128592

Epoch: 6| Step: 5
Training loss: 0.2420712411403656
Validation loss: 1.5511919311297837

Epoch: 6| Step: 6
Training loss: 0.25006920099258423
Validation loss: 1.5824009641524284

Epoch: 6| Step: 7
Training loss: 0.28640860319137573
Validation loss: 1.5707156876082062

Epoch: 6| Step: 8
Training loss: 0.2272036224603653
Validation loss: 1.56353965497786

Epoch: 6| Step: 9
Training loss: 0.27627503871917725
Validation loss: 1.5579317205695695

Epoch: 6| Step: 10
Training loss: 0.20266878604888916
Validation loss: 1.5520554075958908

Epoch: 6| Step: 11
Training loss: 0.2087644785642624
Validation loss: 1.5347804869374921

Epoch: 6| Step: 12
Training loss: 0.411457896232605
Validation loss: 1.5400980749437887

Epoch: 6| Step: 13
Training loss: 0.39890918135643005
Validation loss: 1.5247304093453191

Epoch: 370| Step: 0
Training loss: 0.3307444453239441
Validation loss: 1.5431135034048429

Epoch: 6| Step: 1
Training loss: 0.20959405601024628
Validation loss: 1.5710767199916225

Epoch: 6| Step: 2
Training loss: 0.2217893898487091
Validation loss: 1.5869514070531374

Epoch: 6| Step: 3
Training loss: 0.30509018898010254
Validation loss: 1.6165061176464122

Epoch: 6| Step: 4
Training loss: 0.2548943758010864
Validation loss: 1.609124033681808

Epoch: 6| Step: 5
Training loss: 0.1676752269268036
Validation loss: 1.6244530267612909

Epoch: 6| Step: 6
Training loss: 0.41340941190719604
Validation loss: 1.6128743310128488

Epoch: 6| Step: 7
Training loss: 0.21781691908836365
Validation loss: 1.6016503880100865

Epoch: 6| Step: 8
Training loss: 0.27881860733032227
Validation loss: 1.5862272112600264

Epoch: 6| Step: 9
Training loss: 0.2364196479320526
Validation loss: 1.57962066383772

Epoch: 6| Step: 10
Training loss: 0.24235323071479797
Validation loss: 1.5841577834980463

Epoch: 6| Step: 11
Training loss: 0.16804170608520508
Validation loss: 1.5722253399510537

Epoch: 6| Step: 12
Training loss: 0.36865851283073425
Validation loss: 1.5529793936719176

Epoch: 6| Step: 13
Training loss: 0.13244618475437164
Validation loss: 1.5838070043953516

Epoch: 371| Step: 0
Training loss: 0.2878430485725403
Validation loss: 1.5810271168267855

Epoch: 6| Step: 1
Training loss: 0.20256870985031128
Validation loss: 1.6017939506038543

Epoch: 6| Step: 2
Training loss: 0.2217274308204651
Validation loss: 1.6384108528014152

Epoch: 6| Step: 3
Training loss: 0.33239179849624634
Validation loss: 1.6451686928349156

Epoch: 6| Step: 4
Training loss: 0.3434140384197235
Validation loss: 1.6450590382340133

Epoch: 6| Step: 5
Training loss: 0.3774223327636719
Validation loss: 1.6310140394395398

Epoch: 6| Step: 6
Training loss: 0.2805318832397461
Validation loss: 1.6096481482187908

Epoch: 6| Step: 7
Training loss: 0.15966126322746277
Validation loss: 1.5927761664954565

Epoch: 6| Step: 8
Training loss: 0.14911338686943054
Validation loss: 1.5703170273893623

Epoch: 6| Step: 9
Training loss: 0.21678569912910461
Validation loss: 1.598464314655591

Epoch: 6| Step: 10
Training loss: 0.15809060633182526
Validation loss: 1.5982676295823948

Epoch: 6| Step: 11
Training loss: 0.31626319885253906
Validation loss: 1.6109844971728582

Epoch: 6| Step: 12
Training loss: 0.2550233006477356
Validation loss: 1.594591930348386

Epoch: 6| Step: 13
Training loss: 0.19552405178546906
Validation loss: 1.6082723256080382

Epoch: 372| Step: 0
Training loss: 0.26849833130836487
Validation loss: 1.6442801990816671

Epoch: 6| Step: 1
Training loss: 0.2811660170555115
Validation loss: 1.6731689489015968

Epoch: 6| Step: 2
Training loss: 0.4173480272293091
Validation loss: 1.6467937000336186

Epoch: 6| Step: 3
Training loss: 0.33898723125457764
Validation loss: 1.5945465974910285

Epoch: 6| Step: 4
Training loss: 0.25068601965904236
Validation loss: 1.5973199452123334

Epoch: 6| Step: 5
Training loss: 0.31222617626190186
Validation loss: 1.570836123599801

Epoch: 6| Step: 6
Training loss: 0.299879252910614
Validation loss: 1.548298607590378

Epoch: 6| Step: 7
Training loss: 0.1908791959285736
Validation loss: 1.5535290125877625

Epoch: 6| Step: 8
Training loss: 0.21191291511058807
Validation loss: 1.5851018069892802

Epoch: 6| Step: 9
Training loss: 0.16691166162490845
Validation loss: 1.5551277770791003

Epoch: 6| Step: 10
Training loss: 0.2660213112831116
Validation loss: 1.5815638060210853

Epoch: 6| Step: 11
Training loss: 0.20503993332386017
Validation loss: 1.6051066357602355

Epoch: 6| Step: 12
Training loss: 0.24438750743865967
Validation loss: 1.6233064461779851

Epoch: 6| Step: 13
Training loss: 0.2679370641708374
Validation loss: 1.6261079901008195

Epoch: 373| Step: 0
Training loss: 0.16369858384132385
Validation loss: 1.636215563743345

Epoch: 6| Step: 1
Training loss: 0.1864960789680481
Validation loss: 1.6225450064546318

Epoch: 6| Step: 2
Training loss: 0.3187258243560791
Validation loss: 1.6093515362790836

Epoch: 6| Step: 3
Training loss: 0.24648407101631165
Validation loss: 1.6069319658381964

Epoch: 6| Step: 4
Training loss: 0.20079268515110016
Validation loss: 1.6076718197073987

Epoch: 6| Step: 5
Training loss: 0.1821225881576538
Validation loss: 1.6094512119088122

Epoch: 6| Step: 6
Training loss: 0.41555464267730713
Validation loss: 1.6142582893371582

Epoch: 6| Step: 7
Training loss: 0.25964123010635376
Validation loss: 1.5981845516030506

Epoch: 6| Step: 8
Training loss: 0.2289484292268753
Validation loss: 1.561514889040301

Epoch: 6| Step: 9
Training loss: 0.3551335334777832
Validation loss: 1.577547086182461

Epoch: 6| Step: 10
Training loss: 0.2386123090982437
Validation loss: 1.580535050361387

Epoch: 6| Step: 11
Training loss: 0.3432433605194092
Validation loss: 1.5601148977074573

Epoch: 6| Step: 12
Training loss: 0.17677156627178192
Validation loss: 1.56554627162154

Epoch: 6| Step: 13
Training loss: 0.29545319080352783
Validation loss: 1.5776209318509666

Epoch: 374| Step: 0
Training loss: 0.3052915334701538
Validation loss: 1.5953812496636504

Epoch: 6| Step: 1
Training loss: 0.22655245661735535
Validation loss: 1.5950792938150384

Epoch: 6| Step: 2
Training loss: 0.23552533984184265
Validation loss: 1.6118307818648636

Epoch: 6| Step: 3
Training loss: 0.3558700680732727
Validation loss: 1.618612133046632

Epoch: 6| Step: 4
Training loss: 0.21147434413433075
Validation loss: 1.5862984375287128

Epoch: 6| Step: 5
Training loss: 0.1450437605381012
Validation loss: 1.5955103635787964

Epoch: 6| Step: 6
Training loss: 0.2001354694366455
Validation loss: 1.6164279227615685

Epoch: 6| Step: 7
Training loss: 0.28020817041397095
Validation loss: 1.603071710114838

Epoch: 6| Step: 8
Training loss: 0.13409769535064697
Validation loss: 1.5738628654069797

Epoch: 6| Step: 9
Training loss: 0.34303075075149536
Validation loss: 1.5719408014769196

Epoch: 6| Step: 10
Training loss: 0.10257844626903534
Validation loss: 1.5773523981853197

Epoch: 6| Step: 11
Training loss: 0.2296144664287567
Validation loss: 1.5642655895602318

Epoch: 6| Step: 12
Training loss: 0.3403088450431824
Validation loss: 1.5476106674440446

Epoch: 6| Step: 13
Training loss: 0.47373729944229126
Validation loss: 1.530035384239689

Epoch: 375| Step: 0
Training loss: 0.15817822515964508
Validation loss: 1.5356254731455157

Epoch: 6| Step: 1
Training loss: 0.2094011902809143
Validation loss: 1.5573572420304822

Epoch: 6| Step: 2
Training loss: 0.34744396805763245
Validation loss: 1.5457793358833558

Epoch: 6| Step: 3
Training loss: 0.09786903858184814
Validation loss: 1.5457755711770826

Epoch: 6| Step: 4
Training loss: 0.21227967739105225
Validation loss: 1.5251858952224895

Epoch: 6| Step: 5
Training loss: 0.1709916591644287
Validation loss: 1.5338652851761028

Epoch: 6| Step: 6
Training loss: 0.3249512314796448
Validation loss: 1.526310634869401

Epoch: 6| Step: 7
Training loss: 0.19439572095870972
Validation loss: 1.5351883890808269

Epoch: 6| Step: 8
Training loss: 0.14637793600559235
Validation loss: 1.5393251424194665

Epoch: 6| Step: 9
Training loss: 0.2456626296043396
Validation loss: 1.531171480814616

Epoch: 6| Step: 10
Training loss: 0.3350599706172943
Validation loss: 1.5769909261375346

Epoch: 6| Step: 11
Training loss: 0.32039791345596313
Validation loss: 1.5952904262850363

Epoch: 6| Step: 12
Training loss: 0.2863021194934845
Validation loss: 1.6247730293581564

Epoch: 6| Step: 13
Training loss: 0.4074188470840454
Validation loss: 1.6260177371322468

Epoch: 376| Step: 0
Training loss: 0.22166523337364197
Validation loss: 1.5904568049215502

Epoch: 6| Step: 1
Training loss: 0.10127754509449005
Validation loss: 1.5970589986411474

Epoch: 6| Step: 2
Training loss: 0.19519564509391785
Validation loss: 1.5841768518570931

Epoch: 6| Step: 3
Training loss: 0.23589487373828888
Validation loss: 1.5907779778203657

Epoch: 6| Step: 4
Training loss: 0.24609126150608063
Validation loss: 1.5667978166252055

Epoch: 6| Step: 5
Training loss: 0.29064297676086426
Validation loss: 1.5337617448581162

Epoch: 6| Step: 6
Training loss: 0.37344104051589966
Validation loss: 1.5370282716648553

Epoch: 6| Step: 7
Training loss: 0.21779638528823853
Validation loss: 1.5268763278120308

Epoch: 6| Step: 8
Training loss: 0.2747599184513092
Validation loss: 1.5531528380609327

Epoch: 6| Step: 9
Training loss: 0.19855058193206787
Validation loss: 1.562804454116411

Epoch: 6| Step: 10
Training loss: 0.2866953909397125
Validation loss: 1.5665624192965928

Epoch: 6| Step: 11
Training loss: 0.23376044631004333
Validation loss: 1.602312195685602

Epoch: 6| Step: 12
Training loss: 0.10798396170139313
Validation loss: 1.6015650713315575

Epoch: 6| Step: 13
Training loss: 0.28219473361968994
Validation loss: 1.6353320895984609

Epoch: 377| Step: 0
Training loss: 0.26768285036087036
Validation loss: 1.5862526483433221

Epoch: 6| Step: 1
Training loss: 0.1404237002134323
Validation loss: 1.605696428206659

Epoch: 6| Step: 2
Training loss: 0.15580618381500244
Validation loss: 1.5857993082333637

Epoch: 6| Step: 3
Training loss: 0.21720243990421295
Validation loss: 1.5740121205647786

Epoch: 6| Step: 4
Training loss: 0.32018011808395386
Validation loss: 1.6044403186408422

Epoch: 6| Step: 5
Training loss: 0.4039655327796936
Validation loss: 1.580020655867874

Epoch: 6| Step: 6
Training loss: 0.21900790929794312
Validation loss: 1.5724742425385343

Epoch: 6| Step: 7
Training loss: 0.15121616423130035
Validation loss: 1.6153481980805755

Epoch: 6| Step: 8
Training loss: 0.2537649869918823
Validation loss: 1.5682213767882316

Epoch: 6| Step: 9
Training loss: 0.2474239617586136
Validation loss: 1.5364746726969236

Epoch: 6| Step: 10
Training loss: 0.3767024874687195
Validation loss: 1.5369005498065744

Epoch: 6| Step: 11
Training loss: 0.2999500036239624
Validation loss: 1.5399467329825125

Epoch: 6| Step: 12
Training loss: 0.23096485435962677
Validation loss: 1.5200489336444485

Epoch: 6| Step: 13
Training loss: 0.1790665239095688
Validation loss: 1.5393708636683803

Epoch: 378| Step: 0
Training loss: 0.4469110369682312
Validation loss: 1.5590116618781962

Epoch: 6| Step: 1
Training loss: 0.30502602458000183
Validation loss: 1.5918869446682673

Epoch: 6| Step: 2
Training loss: 0.35626834630966187
Validation loss: 1.5809666937397373

Epoch: 6| Step: 3
Training loss: 0.15375827252864838
Validation loss: 1.5944588748357629

Epoch: 6| Step: 4
Training loss: 0.27823883295059204
Validation loss: 1.5721878902886504

Epoch: 6| Step: 5
Training loss: 0.18037062883377075
Validation loss: 1.5862486875185402

Epoch: 6| Step: 6
Training loss: 0.1670326441526413
Validation loss: 1.586138572744144

Epoch: 6| Step: 7
Training loss: 0.24554722011089325
Validation loss: 1.5687732491441952

Epoch: 6| Step: 8
Training loss: 0.18210889399051666
Validation loss: 1.572959691606542

Epoch: 6| Step: 9
Training loss: 0.1807047724723816
Validation loss: 1.5728431696532874

Epoch: 6| Step: 10
Training loss: 0.24234461784362793
Validation loss: 1.5727469139201666

Epoch: 6| Step: 11
Training loss: 0.3676576316356659
Validation loss: 1.5516307097609325

Epoch: 6| Step: 12
Training loss: 0.2741970419883728
Validation loss: 1.557276782169137

Epoch: 6| Step: 13
Training loss: 0.14087176322937012
Validation loss: 1.5771280155386975

Epoch: 379| Step: 0
Training loss: 0.2706182897090912
Validation loss: 1.5638258072637743

Epoch: 6| Step: 1
Training loss: 0.28503942489624023
Validation loss: 1.531998433092589

Epoch: 6| Step: 2
Training loss: 0.25853145122528076
Validation loss: 1.5480391030670495

Epoch: 6| Step: 3
Training loss: 0.2098814845085144
Validation loss: 1.5370161661537745

Epoch: 6| Step: 4
Training loss: 0.12026473879814148
Validation loss: 1.544782200167256

Epoch: 6| Step: 5
Training loss: 0.13451649248600006
Validation loss: 1.5281627178192139

Epoch: 6| Step: 6
Training loss: 0.1682024896144867
Validation loss: 1.5531005192828435

Epoch: 6| Step: 7
Training loss: 0.31953537464141846
Validation loss: 1.5513136899599465

Epoch: 6| Step: 8
Training loss: 0.0871521532535553
Validation loss: 1.5558607719277824

Epoch: 6| Step: 9
Training loss: 0.16823415458202362
Validation loss: 1.5518729943101124

Epoch: 6| Step: 10
Training loss: 0.38210615515708923
Validation loss: 1.5634884744562128

Epoch: 6| Step: 11
Training loss: 0.2104928195476532
Validation loss: 1.5453430965382566

Epoch: 6| Step: 12
Training loss: 0.30315232276916504
Validation loss: 1.5478009280338083

Epoch: 6| Step: 13
Training loss: 0.43648242950439453
Validation loss: 1.553936340475595

Epoch: 380| Step: 0
Training loss: 0.20633567869663239
Validation loss: 1.5970325848107696

Epoch: 6| Step: 1
Training loss: 0.26738595962524414
Validation loss: 1.5832424843183128

Epoch: 6| Step: 2
Training loss: 0.21462737023830414
Validation loss: 1.599008688362696

Epoch: 6| Step: 3
Training loss: 0.16605883836746216
Validation loss: 1.5843517382939656

Epoch: 6| Step: 4
Training loss: 0.292426735162735
Validation loss: 1.5771148473985734

Epoch: 6| Step: 5
Training loss: 0.31636014580726624
Validation loss: 1.5877515667228288

Epoch: 6| Step: 6
Training loss: 0.27527809143066406
Validation loss: 1.6043385562076364

Epoch: 6| Step: 7
Training loss: 0.2972967028617859
Validation loss: 1.5696796089090326

Epoch: 6| Step: 8
Training loss: 0.15355154871940613
Validation loss: 1.5578021016172183

Epoch: 6| Step: 9
Training loss: 0.19408753514289856
Validation loss: 1.5468878579396073

Epoch: 6| Step: 10
Training loss: 0.3220188021659851
Validation loss: 1.5528307601969729

Epoch: 6| Step: 11
Training loss: 0.14477761089801788
Validation loss: 1.55106653833902

Epoch: 6| Step: 12
Training loss: 0.35268062353134155
Validation loss: 1.5616345982397757

Epoch: 6| Step: 13
Training loss: 0.10688804090023041
Validation loss: 1.566729083497037

Epoch: 381| Step: 0
Training loss: 0.17734506726264954
Validation loss: 1.519310192395282

Epoch: 6| Step: 1
Training loss: 0.30367228388786316
Validation loss: 1.5222337169031943

Epoch: 6| Step: 2
Training loss: 0.2607344090938568
Validation loss: 1.5455372653981692

Epoch: 6| Step: 3
Training loss: 0.22624042630195618
Validation loss: 1.5329979799127067

Epoch: 6| Step: 4
Training loss: 0.18893195688724518
Validation loss: 1.5633601783424296

Epoch: 6| Step: 5
Training loss: 0.2618291974067688
Validation loss: 1.5947236989134101

Epoch: 6| Step: 6
Training loss: 0.2007470428943634
Validation loss: 1.5692046931994859

Epoch: 6| Step: 7
Training loss: 0.24527397751808167
Validation loss: 1.5338028964175974

Epoch: 6| Step: 8
Training loss: 0.18999946117401123
Validation loss: 1.5347774746597453

Epoch: 6| Step: 9
Training loss: 0.22624757885932922
Validation loss: 1.5290416440656107

Epoch: 6| Step: 10
Training loss: 0.2538832724094391
Validation loss: 1.5568558810859598

Epoch: 6| Step: 11
Training loss: 0.1839972734451294
Validation loss: 1.5577085556522492

Epoch: 6| Step: 12
Training loss: 0.3599280118942261
Validation loss: 1.5621509270001483

Epoch: 6| Step: 13
Training loss: 0.14773418009281158
Validation loss: 1.5632473332907564

Epoch: 382| Step: 0
Training loss: 0.23029819130897522
Validation loss: 1.5479218459898425

Epoch: 6| Step: 1
Training loss: 0.1603277176618576
Validation loss: 1.5555216817445652

Epoch: 6| Step: 2
Training loss: 0.19420048594474792
Validation loss: 1.5714650102840957

Epoch: 6| Step: 3
Training loss: 0.16847270727157593
Validation loss: 1.571791322000565

Epoch: 6| Step: 4
Training loss: 0.26170122623443604
Validation loss: 1.5565845889429892

Epoch: 6| Step: 5
Training loss: 0.25261712074279785
Validation loss: 1.5205840103087886

Epoch: 6| Step: 6
Training loss: 0.20142440497875214
Validation loss: 1.5374990829857447

Epoch: 6| Step: 7
Training loss: 0.1406199336051941
Validation loss: 1.533048859206579

Epoch: 6| Step: 8
Training loss: 0.18861530721187592
Validation loss: 1.5398749651447419

Epoch: 6| Step: 9
Training loss: 0.17187389731407166
Validation loss: 1.5413151864082582

Epoch: 6| Step: 10
Training loss: 0.2166208028793335
Validation loss: 1.5887069663693827

Epoch: 6| Step: 11
Training loss: 0.24273234605789185
Validation loss: 1.5795786624313684

Epoch: 6| Step: 12
Training loss: 0.3196505308151245
Validation loss: 1.5924517454639557

Epoch: 6| Step: 13
Training loss: 0.25768089294433594
Validation loss: 1.5893745999182425

Epoch: 383| Step: 0
Training loss: 0.1154099553823471
Validation loss: 1.6203614704070552

Epoch: 6| Step: 1
Training loss: 0.166908860206604
Validation loss: 1.588839332262675

Epoch: 6| Step: 2
Training loss: 0.20136936008930206
Validation loss: 1.5533263247500184

Epoch: 6| Step: 3
Training loss: 0.2732768654823303
Validation loss: 1.576481484597729

Epoch: 6| Step: 4
Training loss: 0.2008218914270401
Validation loss: 1.5811094507094352

Epoch: 6| Step: 5
Training loss: 0.16559621691703796
Validation loss: 1.5604223820470995

Epoch: 6| Step: 6
Training loss: 0.4330716133117676
Validation loss: 1.5654769917970062

Epoch: 6| Step: 7
Training loss: 0.169980987906456
Validation loss: 1.5619322817812684

Epoch: 6| Step: 8
Training loss: 0.13416200876235962
Validation loss: 1.5457808740677372

Epoch: 6| Step: 9
Training loss: 0.3248368501663208
Validation loss: 1.5395768906480523

Epoch: 6| Step: 10
Training loss: 0.1570979207754135
Validation loss: 1.5459850308715657

Epoch: 6| Step: 11
Training loss: 0.3531246781349182
Validation loss: 1.5466994854711718

Epoch: 6| Step: 12
Training loss: 0.1943473070859909
Validation loss: 1.5909832292987454

Epoch: 6| Step: 13
Training loss: 0.09351947903633118
Validation loss: 1.5809905631567842

Epoch: 384| Step: 0
Training loss: 0.16205057501792908
Validation loss: 1.570159751240925

Epoch: 6| Step: 1
Training loss: 0.42443764209747314
Validation loss: 1.5888858790038733

Epoch: 6| Step: 2
Training loss: 0.35684993863105774
Validation loss: 1.6224106947580974

Epoch: 6| Step: 3
Training loss: 0.23056621849536896
Validation loss: 1.5850988216297601

Epoch: 6| Step: 4
Training loss: 0.12109239399433136
Validation loss: 1.600077509880066

Epoch: 6| Step: 5
Training loss: 0.1541137397289276
Validation loss: 1.6197519622823244

Epoch: 6| Step: 6
Training loss: 0.23145189881324768
Validation loss: 1.593483458283127

Epoch: 6| Step: 7
Training loss: 0.15213419497013092
Validation loss: 1.596341036981152

Epoch: 6| Step: 8
Training loss: 0.09708227217197418
Validation loss: 1.582492277186404

Epoch: 6| Step: 9
Training loss: 0.18727803230285645
Validation loss: 1.5695844863050727

Epoch: 6| Step: 10
Training loss: 0.18736326694488525
Validation loss: 1.5558481101066834

Epoch: 6| Step: 11
Training loss: 0.17859414219856262
Validation loss: 1.5166827747898717

Epoch: 6| Step: 12
Training loss: 0.19276612997055054
Validation loss: 1.5153437391404183

Epoch: 6| Step: 13
Training loss: 0.348256379365921
Validation loss: 1.5172247809748496

Epoch: 385| Step: 0
Training loss: 0.1676875650882721
Validation loss: 1.5201767875302223

Epoch: 6| Step: 1
Training loss: 0.19711926579475403
Validation loss: 1.5243090544977496

Epoch: 6| Step: 2
Training loss: 0.28969162702560425
Validation loss: 1.5344215170029671

Epoch: 6| Step: 3
Training loss: 0.346496045589447
Validation loss: 1.5461190618494505

Epoch: 6| Step: 4
Training loss: 0.1311766803264618
Validation loss: 1.5486380118195728

Epoch: 6| Step: 5
Training loss: 0.3011525869369507
Validation loss: 1.5884024032982447

Epoch: 6| Step: 6
Training loss: 0.26755526661872864
Validation loss: 1.5867687591942408

Epoch: 6| Step: 7
Training loss: 0.3302585184574127
Validation loss: 1.5950613355123868

Epoch: 6| Step: 8
Training loss: 0.15237480401992798
Validation loss: 1.606378939843947

Epoch: 6| Step: 9
Training loss: 0.2903628945350647
Validation loss: 1.6038601706104894

Epoch: 6| Step: 10
Training loss: 0.3293594717979431
Validation loss: 1.6306378472876806

Epoch: 6| Step: 11
Training loss: 0.30436140298843384
Validation loss: 1.6422317066500265

Epoch: 6| Step: 12
Training loss: 0.14640307426452637
Validation loss: 1.6960305667692614

Epoch: 6| Step: 13
Training loss: 0.11159888654947281
Validation loss: 1.642418610152378

Epoch: 386| Step: 0
Training loss: 0.22561907768249512
Validation loss: 1.6623707432900705

Epoch: 6| Step: 1
Training loss: 0.27504414319992065
Validation loss: 1.6020591746094406

Epoch: 6| Step: 2
Training loss: 0.16632947325706482
Validation loss: 1.575402880227694

Epoch: 6| Step: 3
Training loss: 0.376814603805542
Validation loss: 1.5824065182798652

Epoch: 6| Step: 4
Training loss: 0.4043715000152588
Validation loss: 1.55600719874905

Epoch: 6| Step: 5
Training loss: 0.36343783140182495
Validation loss: 1.5659083935522264

Epoch: 6| Step: 6
Training loss: 0.33987441658973694
Validation loss: 1.5793653688123148

Epoch: 6| Step: 7
Training loss: 0.1476903259754181
Validation loss: 1.6322101662235875

Epoch: 6| Step: 8
Training loss: 0.17649689316749573
Validation loss: 1.6371818280989123

Epoch: 6| Step: 9
Training loss: 0.3064752519130707
Validation loss: 1.653485163565605

Epoch: 6| Step: 10
Training loss: 0.39565759897232056
Validation loss: 1.6159420782519924

Epoch: 6| Step: 11
Training loss: 0.35443323850631714
Validation loss: 1.660082899114137

Epoch: 6| Step: 12
Training loss: 0.4162020683288574
Validation loss: 1.6592816409244333

Epoch: 6| Step: 13
Training loss: 0.24698394536972046
Validation loss: 1.6644736054123088

Epoch: 387| Step: 0
Training loss: 0.45098936557769775
Validation loss: 1.6940360171820528

Epoch: 6| Step: 1
Training loss: 0.2762267589569092
Validation loss: 1.6403228031691683

Epoch: 6| Step: 2
Training loss: 0.2628767490386963
Validation loss: 1.6530613399321032

Epoch: 6| Step: 3
Training loss: 0.3570800721645355
Validation loss: 1.6369624022514588

Epoch: 6| Step: 4
Training loss: 0.3589094579219818
Validation loss: 1.59120766193636

Epoch: 6| Step: 5
Training loss: 0.1948612779378891
Validation loss: 1.6111001917110976

Epoch: 6| Step: 6
Training loss: 0.27535000443458557
Validation loss: 1.5709617650637062

Epoch: 6| Step: 7
Training loss: 0.2924732565879822
Validation loss: 1.5986763379907096

Epoch: 6| Step: 8
Training loss: 0.2788742184638977
Validation loss: 1.574175202718345

Epoch: 6| Step: 9
Training loss: 0.32451197504997253
Validation loss: 1.5434122188116914

Epoch: 6| Step: 10
Training loss: 0.289122074842453
Validation loss: 1.5535257170277257

Epoch: 6| Step: 11
Training loss: 0.3229188919067383
Validation loss: 1.5487006838603685

Epoch: 6| Step: 12
Training loss: 0.2622825503349304
Validation loss: 1.5852437070620957

Epoch: 6| Step: 13
Training loss: 0.30561721324920654
Validation loss: 1.5767466278486355

Epoch: 388| Step: 0
Training loss: 0.24526050686836243
Validation loss: 1.5970718232534264

Epoch: 6| Step: 1
Training loss: 0.36413538455963135
Validation loss: 1.5566438692872242

Epoch: 6| Step: 2
Training loss: 0.2812112271785736
Validation loss: 1.5716959238052368

Epoch: 6| Step: 3
Training loss: 0.3188644051551819
Validation loss: 1.5773760913520731

Epoch: 6| Step: 4
Training loss: 0.26981014013290405
Validation loss: 1.5802695020552604

Epoch: 6| Step: 5
Training loss: 0.3124569058418274
Validation loss: 1.5813478103248022

Epoch: 6| Step: 6
Training loss: 0.3509671092033386
Validation loss: 1.562294178111579

Epoch: 6| Step: 7
Training loss: 0.2274130880832672
Validation loss: 1.5435630756039773

Epoch: 6| Step: 8
Training loss: 0.22264833748340607
Validation loss: 1.5780962667157572

Epoch: 6| Step: 9
Training loss: 0.13213905692100525
Validation loss: 1.594199962513421

Epoch: 6| Step: 10
Training loss: 0.20717781782150269
Validation loss: 1.5950805640989734

Epoch: 6| Step: 11
Training loss: 0.28409069776535034
Validation loss: 1.6359717922825967

Epoch: 6| Step: 12
Training loss: 0.3072746992111206
Validation loss: 1.632005222382084

Epoch: 6| Step: 13
Training loss: 0.2687891721725464
Validation loss: 1.5934034598770963

Epoch: 389| Step: 0
Training loss: 0.29989147186279297
Validation loss: 1.6117925477284256

Epoch: 6| Step: 1
Training loss: 0.43476712703704834
Validation loss: 1.5777642444897724

Epoch: 6| Step: 2
Training loss: 0.41753557324409485
Validation loss: 1.5728247960408528

Epoch: 6| Step: 3
Training loss: 0.16859722137451172
Validation loss: 1.5911453488052532

Epoch: 6| Step: 4
Training loss: 0.1601412445306778
Validation loss: 1.5685388221535632

Epoch: 6| Step: 5
Training loss: 0.15213683247566223
Validation loss: 1.5757071830893075

Epoch: 6| Step: 6
Training loss: 0.1949452906847
Validation loss: 1.5513477043438983

Epoch: 6| Step: 7
Training loss: 0.10986343026161194
Validation loss: 1.5472298001730314

Epoch: 6| Step: 8
Training loss: 0.2701749801635742
Validation loss: 1.5421208745689803

Epoch: 6| Step: 9
Training loss: 0.17686213552951813
Validation loss: 1.5405579965601686

Epoch: 6| Step: 10
Training loss: 0.23346778750419617
Validation loss: 1.550631397513933

Epoch: 6| Step: 11
Training loss: 0.2506047785282135
Validation loss: 1.5490022859265726

Epoch: 6| Step: 12
Training loss: 0.1271049678325653
Validation loss: 1.5404645717272194

Epoch: 6| Step: 13
Training loss: 0.30048978328704834
Validation loss: 1.5311480747756137

Epoch: 390| Step: 0
Training loss: 0.18792936205863953
Validation loss: 1.5197574605223954

Epoch: 6| Step: 1
Training loss: 0.18150901794433594
Validation loss: 1.5598864952723186

Epoch: 6| Step: 2
Training loss: 0.12421363592147827
Validation loss: 1.5605075372162687

Epoch: 6| Step: 3
Training loss: 0.21188268065452576
Validation loss: 1.5828579664230347

Epoch: 6| Step: 4
Training loss: 0.28639012575149536
Validation loss: 1.5725701342346847

Epoch: 6| Step: 5
Training loss: 0.39779701828956604
Validation loss: 1.584948080842213

Epoch: 6| Step: 6
Training loss: 0.18648508191108704
Validation loss: 1.5666317555212206

Epoch: 6| Step: 7
Training loss: 0.3250780403614044
Validation loss: 1.5547367988094207

Epoch: 6| Step: 8
Training loss: 0.18820062279701233
Validation loss: 1.5570977951890679

Epoch: 6| Step: 9
Training loss: 0.25664418935775757
Validation loss: 1.563515495228511

Epoch: 6| Step: 10
Training loss: 0.18931201100349426
Validation loss: 1.5655665051552556

Epoch: 6| Step: 11
Training loss: 0.37169820070266724
Validation loss: 1.5484592683853642

Epoch: 6| Step: 12
Training loss: 0.2251771092414856
Validation loss: 1.5573933457815519

Epoch: 6| Step: 13
Training loss: 0.22262467443943024
Validation loss: 1.5796407422711771

Epoch: 391| Step: 0
Training loss: 0.15376189351081848
Validation loss: 1.5638295463336411

Epoch: 6| Step: 1
Training loss: 0.3245037794113159
Validation loss: 1.5888683565201298

Epoch: 6| Step: 2
Training loss: 0.26807937026023865
Validation loss: 1.6107999022288988

Epoch: 6| Step: 3
Training loss: 0.18259620666503906
Validation loss: 1.6086414065412296

Epoch: 6| Step: 4
Training loss: 0.2511410713195801
Validation loss: 1.5994487731687483

Epoch: 6| Step: 5
Training loss: 0.16254083812236786
Validation loss: 1.5972174406051636

Epoch: 6| Step: 6
Training loss: 0.3463429808616638
Validation loss: 1.5826993834587835

Epoch: 6| Step: 7
Training loss: 0.21656520664691925
Validation loss: 1.57337018751329

Epoch: 6| Step: 8
Training loss: 0.17700248956680298
Validation loss: 1.57775955559105

Epoch: 6| Step: 9
Training loss: 0.3152318298816681
Validation loss: 1.5788447959448701

Epoch: 6| Step: 10
Training loss: 0.1950111985206604
Validation loss: 1.5877559672119796

Epoch: 6| Step: 11
Training loss: 0.20273876190185547
Validation loss: 1.5799966935188539

Epoch: 6| Step: 12
Training loss: 0.2217990756034851
Validation loss: 1.583182736750572

Epoch: 6| Step: 13
Training loss: 0.2516654431819916
Validation loss: 1.5747007272576774

Epoch: 392| Step: 0
Training loss: 0.20970116555690765
Validation loss: 1.5802692392820954

Epoch: 6| Step: 1
Training loss: 0.2454361915588379
Validation loss: 1.591614124595478

Epoch: 6| Step: 2
Training loss: 0.14300799369812012
Validation loss: 1.6006743254200104

Epoch: 6| Step: 3
Training loss: 0.24893926084041595
Validation loss: 1.560426164698857

Epoch: 6| Step: 4
Training loss: 0.13237842917442322
Validation loss: 1.5719699321254608

Epoch: 6| Step: 5
Training loss: 0.20049922168254852
Validation loss: 1.5932349620326873

Epoch: 6| Step: 6
Training loss: 0.2499331831932068
Validation loss: 1.5721285932807512

Epoch: 6| Step: 7
Training loss: 0.2375858724117279
Validation loss: 1.5936376753673758

Epoch: 6| Step: 8
Training loss: 0.2067507654428482
Validation loss: 1.572747661221412

Epoch: 6| Step: 9
Training loss: 0.14973914623260498
Validation loss: 1.5798155678215848

Epoch: 6| Step: 10
Training loss: 0.20889100432395935
Validation loss: 1.6086760054352462

Epoch: 6| Step: 11
Training loss: 0.389903724193573
Validation loss: 1.5987817625845633

Epoch: 6| Step: 12
Training loss: 0.19437365233898163
Validation loss: 1.6176620965362878

Epoch: 6| Step: 13
Training loss: 0.2057320773601532
Validation loss: 1.6299078784963137

Epoch: 393| Step: 0
Training loss: 0.22739063203334808
Validation loss: 1.6192624722757647

Epoch: 6| Step: 1
Training loss: 0.2581077814102173
Validation loss: 1.618036957197292

Epoch: 6| Step: 2
Training loss: 0.2519388198852539
Validation loss: 1.5565119558765041

Epoch: 6| Step: 3
Training loss: 0.17270207405090332
Validation loss: 1.5829411398979925

Epoch: 6| Step: 4
Training loss: 0.09952399879693985
Validation loss: 1.5755025904665712

Epoch: 6| Step: 5
Training loss: 0.25271546840667725
Validation loss: 1.5470734129669845

Epoch: 6| Step: 6
Training loss: 0.10851036757230759
Validation loss: 1.5484410729459537

Epoch: 6| Step: 7
Training loss: 0.15425944328308105
Validation loss: 1.5577891526683685

Epoch: 6| Step: 8
Training loss: 0.21895447373390198
Validation loss: 1.583919309800671

Epoch: 6| Step: 9
Training loss: 0.35928982496261597
Validation loss: 1.5710580951424056

Epoch: 6| Step: 10
Training loss: 0.2953750193119049
Validation loss: 1.5911734104156494

Epoch: 6| Step: 11
Training loss: 0.23261138796806335
Validation loss: 1.580300041424331

Epoch: 6| Step: 12
Training loss: 0.22363385558128357
Validation loss: 1.61622481448676

Epoch: 6| Step: 13
Training loss: 0.3238203525543213
Validation loss: 1.607516127247964

Epoch: 394| Step: 0
Training loss: 0.23104295134544373
Validation loss: 1.5547637593361638

Epoch: 6| Step: 1
Training loss: 0.1700689047574997
Validation loss: 1.5328032931973856

Epoch: 6| Step: 2
Training loss: 0.15340855717658997
Validation loss: 1.5693956805813698

Epoch: 6| Step: 3
Training loss: 0.28056228160858154
Validation loss: 1.5823401789511404

Epoch: 6| Step: 4
Training loss: 0.3520351052284241
Validation loss: 1.604143145263836

Epoch: 6| Step: 5
Training loss: 0.41833245754241943
Validation loss: 1.5906361809340857

Epoch: 6| Step: 6
Training loss: 0.3462703824043274
Validation loss: 1.5947838521772815

Epoch: 6| Step: 7
Training loss: 0.16763192415237427
Validation loss: 1.6055672476368565

Epoch: 6| Step: 8
Training loss: 0.2919285297393799
Validation loss: 1.6120342875039706

Epoch: 6| Step: 9
Training loss: 0.22218529880046844
Validation loss: 1.6958518041077482

Epoch: 6| Step: 10
Training loss: 0.422061949968338
Validation loss: 1.7347503797982329

Epoch: 6| Step: 11
Training loss: 0.3443842828273773
Validation loss: 1.650555190219674

Epoch: 6| Step: 12
Training loss: 0.275267630815506
Validation loss: 1.5914499567401024

Epoch: 6| Step: 13
Training loss: 0.14359794557094574
Validation loss: 1.5773156496786302

Epoch: 395| Step: 0
Training loss: 0.26556670665740967
Validation loss: 1.561567118090968

Epoch: 6| Step: 1
Training loss: 0.355510413646698
Validation loss: 1.6077927632998394

Epoch: 6| Step: 2
Training loss: 0.5590633153915405
Validation loss: 1.5961189193110312

Epoch: 6| Step: 3
Training loss: 0.37873631715774536
Validation loss: 1.5895648464079826

Epoch: 6| Step: 4
Training loss: 0.30517637729644775
Validation loss: 1.6151900547806934

Epoch: 6| Step: 5
Training loss: 0.2261638343334198
Validation loss: 1.6316455769282516

Epoch: 6| Step: 6
Training loss: 0.36886918544769287
Validation loss: 1.6913395338161017

Epoch: 6| Step: 7
Training loss: 0.2890078127384186
Validation loss: 1.7332031419200282

Epoch: 6| Step: 8
Training loss: 0.19248437881469727
Validation loss: 1.8016676902770996

Epoch: 6| Step: 9
Training loss: 0.35226643085479736
Validation loss: 1.794056607830909

Epoch: 6| Step: 10
Training loss: 0.465537965297699
Validation loss: 1.7483716305866037

Epoch: 6| Step: 11
Training loss: 0.2546936869621277
Validation loss: 1.6509490372032247

Epoch: 6| Step: 12
Training loss: 0.2176530957221985
Validation loss: 1.616215407207448

Epoch: 6| Step: 13
Training loss: 0.5036674737930298
Validation loss: 1.6190382152475336

Epoch: 396| Step: 0
Training loss: 0.4685043692588806
Validation loss: 1.6278844648791897

Epoch: 6| Step: 1
Training loss: 0.37795594334602356
Validation loss: 1.6189092551508257

Epoch: 6| Step: 2
Training loss: 0.3886563777923584
Validation loss: 1.6475327412287395

Epoch: 6| Step: 3
Training loss: 0.28962475061416626
Validation loss: 1.6051452121426981

Epoch: 6| Step: 4
Training loss: 0.3263225555419922
Validation loss: 1.6181397143230642

Epoch: 6| Step: 5
Training loss: 0.3759479522705078
Validation loss: 1.6469683339518886

Epoch: 6| Step: 6
Training loss: 0.2935454249382019
Validation loss: 1.6743047852669992

Epoch: 6| Step: 7
Training loss: 0.3236006498336792
Validation loss: 1.7392565716979325

Epoch: 6| Step: 8
Training loss: 0.5968965291976929
Validation loss: 1.7823834496159707

Epoch: 6| Step: 9
Training loss: 0.42908987402915955
Validation loss: 1.7654242515563965

Epoch: 6| Step: 10
Training loss: 0.325149267911911
Validation loss: 1.7199743409310617

Epoch: 6| Step: 11
Training loss: 0.2675549387931824
Validation loss: 1.6350825089280323

Epoch: 6| Step: 12
Training loss: 0.2986951768398285
Validation loss: 1.585930242333361

Epoch: 6| Step: 13
Training loss: 0.3842598497867584
Validation loss: 1.5405127720166278

Epoch: 397| Step: 0
Training loss: 0.258689284324646
Validation loss: 1.5508804923744612

Epoch: 6| Step: 1
Training loss: 0.14206784963607788
Validation loss: 1.528427436787595

Epoch: 6| Step: 2
Training loss: 0.29827752709388733
Validation loss: 1.576057626355079

Epoch: 6| Step: 3
Training loss: 0.2777880132198334
Validation loss: 1.5766734307812107

Epoch: 6| Step: 4
Training loss: 0.16255396604537964
Validation loss: 1.5960779061881445

Epoch: 6| Step: 5
Training loss: 0.18137137591838837
Validation loss: 1.6289311147505237

Epoch: 6| Step: 6
Training loss: 0.37945693731307983
Validation loss: 1.648125656189457

Epoch: 6| Step: 7
Training loss: 0.21323943138122559
Validation loss: 1.6505463097685127

Epoch: 6| Step: 8
Training loss: 0.5461777448654175
Validation loss: 1.6703664987317977

Epoch: 6| Step: 9
Training loss: 0.41287684440612793
Validation loss: 1.6182119256706649

Epoch: 6| Step: 10
Training loss: 0.18345588445663452
Validation loss: 1.5768798525615404

Epoch: 6| Step: 11
Training loss: 0.2886577248573303
Validation loss: 1.527162681343735

Epoch: 6| Step: 12
Training loss: 0.5054711699485779
Validation loss: 1.5292441075847996

Epoch: 6| Step: 13
Training loss: 0.2320827692747116
Validation loss: 1.5890822320856073

Epoch: 398| Step: 0
Training loss: 0.27411088347435
Validation loss: 1.5474814650832966

Epoch: 6| Step: 1
Training loss: 0.3632390797138214
Validation loss: 1.5852635240042081

Epoch: 6| Step: 2
Training loss: 0.3234339952468872
Validation loss: 1.5656289144228863

Epoch: 6| Step: 3
Training loss: 0.31165701150894165
Validation loss: 1.5926324654650945

Epoch: 6| Step: 4
Training loss: 0.3196203112602234
Validation loss: 1.6011850077618834

Epoch: 6| Step: 5
Training loss: 0.3592953383922577
Validation loss: 1.6617653805722472

Epoch: 6| Step: 6
Training loss: 0.6938954591751099
Validation loss: 1.630067592026085

Epoch: 6| Step: 7
Training loss: 0.18971218168735504
Validation loss: 1.5521715558985227

Epoch: 6| Step: 8
Training loss: 0.3175336718559265
Validation loss: 1.515529606931953

Epoch: 6| Step: 9
Training loss: 0.44450339674949646
Validation loss: 1.515925931674178

Epoch: 6| Step: 10
Training loss: 0.2759529948234558
Validation loss: 1.532785798913689

Epoch: 6| Step: 11
Training loss: 0.629646360874176
Validation loss: 1.5340217851823377

Epoch: 6| Step: 12
Training loss: 0.3147405982017517
Validation loss: 1.5484553793425202

Epoch: 6| Step: 13
Training loss: 0.14462946355342865
Validation loss: 1.5433674499552736

Epoch: 399| Step: 0
Training loss: 0.19278627634048462
Validation loss: 1.5451482072953255

Epoch: 6| Step: 1
Training loss: 0.17446330189704895
Validation loss: 1.5906759449230727

Epoch: 6| Step: 2
Training loss: 0.3097478747367859
Validation loss: 1.6095335163095945

Epoch: 6| Step: 3
Training loss: 0.1651563048362732
Validation loss: 1.5935006128844393

Epoch: 6| Step: 4
Training loss: 0.4988988935947418
Validation loss: 1.586320092601161

Epoch: 6| Step: 5
Training loss: 0.3485187888145447
Validation loss: 1.558736663992687

Epoch: 6| Step: 6
Training loss: 0.24254979193210602
Validation loss: 1.544774382345138

Epoch: 6| Step: 7
Training loss: 0.24361974000930786
Validation loss: 1.517420886665262

Epoch: 6| Step: 8
Training loss: 0.2429351806640625
Validation loss: 1.4938540727861467

Epoch: 6| Step: 9
Training loss: 0.24796587228775024
Validation loss: 1.5128843925332511

Epoch: 6| Step: 10
Training loss: 0.30504110455513
Validation loss: 1.5026360839925788

Epoch: 6| Step: 11
Training loss: 0.45958173274993896
Validation loss: 1.5441523175085745

Epoch: 6| Step: 12
Training loss: 0.34111830592155457
Validation loss: 1.5544737526165542

Epoch: 6| Step: 13
Training loss: 0.32267510890960693
Validation loss: 1.5603212618058728

Epoch: 400| Step: 0
Training loss: 0.36538606882095337
Validation loss: 1.5752665560732606

Epoch: 6| Step: 1
Training loss: 0.3041132688522339
Validation loss: 1.613503720170708

Epoch: 6| Step: 2
Training loss: 0.15911683440208435
Validation loss: 1.5799015952694802

Epoch: 6| Step: 3
Training loss: 0.3230639696121216
Validation loss: 1.5789506025211786

Epoch: 6| Step: 4
Training loss: 0.2919002175331116
Validation loss: 1.5794514443284722

Epoch: 6| Step: 5
Training loss: 0.21856243908405304
Validation loss: 1.5950522217699277

Epoch: 6| Step: 6
Training loss: 0.3003646731376648
Validation loss: 1.553914882803476

Epoch: 6| Step: 7
Training loss: 0.224210724234581
Validation loss: 1.5622751046252508

Epoch: 6| Step: 8
Training loss: 0.26527202129364014
Validation loss: 1.5627621040549329

Epoch: 6| Step: 9
Training loss: 0.23722273111343384
Validation loss: 1.5322272880102998

Epoch: 6| Step: 10
Training loss: 0.18523597717285156
Validation loss: 1.5458070949841571

Epoch: 6| Step: 11
Training loss: 0.17625275254249573
Validation loss: 1.5492733652873705

Epoch: 6| Step: 12
Training loss: 0.21556076407432556
Validation loss: 1.5603069400274625

Epoch: 6| Step: 13
Training loss: 0.14441049098968506
Validation loss: 1.5701505471301336

Epoch: 401| Step: 0
Training loss: 0.1793632209300995
Validation loss: 1.5664461889574606

Epoch: 6| Step: 1
Training loss: 0.29393061995506287
Validation loss: 1.5552316455430881

Epoch: 6| Step: 2
Training loss: 0.24522963166236877
Validation loss: 1.5517468131998533

Epoch: 6| Step: 3
Training loss: 0.15631137788295746
Validation loss: 1.4816417912001252

Epoch: 6| Step: 4
Training loss: 0.21624134480953217
Validation loss: 1.5232763046859412

Epoch: 6| Step: 5
Training loss: 0.37468409538269043
Validation loss: 1.5106574194405669

Epoch: 6| Step: 6
Training loss: 0.3060571849346161
Validation loss: 1.4922559030594365

Epoch: 6| Step: 7
Training loss: 0.2423810213804245
Validation loss: 1.4914498764981505

Epoch: 6| Step: 8
Training loss: 0.15381844341754913
Validation loss: 1.4909754735167309

Epoch: 6| Step: 9
Training loss: 0.2840266227722168
Validation loss: 1.496895283781072

Epoch: 6| Step: 10
Training loss: 0.26908379793167114
Validation loss: 1.488505107100292

Epoch: 6| Step: 11
Training loss: 0.18786749243736267
Validation loss: 1.5053103111123527

Epoch: 6| Step: 12
Training loss: 0.23726166784763336
Validation loss: 1.4661212191786817

Epoch: 6| Step: 13
Training loss: 0.2948016822338104
Validation loss: 1.4665364873024724

Epoch: 402| Step: 0
Training loss: 0.2048749327659607
Validation loss: 1.483431810973793

Epoch: 6| Step: 1
Training loss: 0.21766497194766998
Validation loss: 1.4746259322730444

Epoch: 6| Step: 2
Training loss: 0.34033796191215515
Validation loss: 1.4842383899996359

Epoch: 6| Step: 3
Training loss: 0.19974763691425323
Validation loss: 1.4663073016751198

Epoch: 6| Step: 4
Training loss: 0.17889142036437988
Validation loss: 1.4968678925627021

Epoch: 6| Step: 5
Training loss: 0.24945101141929626
Validation loss: 1.497346842160789

Epoch: 6| Step: 6
Training loss: 0.17400410771369934
Validation loss: 1.5060063414676215

Epoch: 6| Step: 7
Training loss: 0.22436925768852234
Validation loss: 1.556406541537213

Epoch: 6| Step: 8
Training loss: 0.19268076121807098
Validation loss: 1.5584205888932752

Epoch: 6| Step: 9
Training loss: 0.15238454937934875
Validation loss: 1.6076516669283631

Epoch: 6| Step: 10
Training loss: 0.28860872983932495
Validation loss: 1.5962868557181409

Epoch: 6| Step: 11
Training loss: 0.3789790868759155
Validation loss: 1.5732906556898547

Epoch: 6| Step: 12
Training loss: 0.20342418551445007
Validation loss: 1.5566351452181417

Epoch: 6| Step: 13
Training loss: 0.10770079493522644
Validation loss: 1.5515025008109309

Epoch: 403| Step: 0
Training loss: 0.12159351259469986
Validation loss: 1.533089090419072

Epoch: 6| Step: 1
Training loss: 0.24772825837135315
Validation loss: 1.5692139492240003

Epoch: 6| Step: 2
Training loss: 0.46806782484054565
Validation loss: 1.5682807814690374

Epoch: 6| Step: 3
Training loss: 0.3803335428237915
Validation loss: 1.5569600514186326

Epoch: 6| Step: 4
Training loss: 0.19508151710033417
Validation loss: 1.5410978524915633

Epoch: 6| Step: 5
Training loss: 0.315956175327301
Validation loss: 1.5260306519846762

Epoch: 6| Step: 6
Training loss: 0.3051258325576782
Validation loss: 1.5151554307629984

Epoch: 6| Step: 7
Training loss: 0.228959858417511
Validation loss: 1.527865420746547

Epoch: 6| Step: 8
Training loss: 0.31184980273246765
Validation loss: 1.558201757810449

Epoch: 6| Step: 9
Training loss: 0.2479708045721054
Validation loss: 1.573519802862598

Epoch: 6| Step: 10
Training loss: 0.17449361085891724
Validation loss: 1.5563410584644606

Epoch: 6| Step: 11
Training loss: 0.1469021886587143
Validation loss: 1.5544412661624212

Epoch: 6| Step: 12
Training loss: 0.16800931096076965
Validation loss: 1.5105934822431175

Epoch: 6| Step: 13
Training loss: 0.1909487545490265
Validation loss: 1.5275082190831502

Epoch: 404| Step: 0
Training loss: 0.20474180579185486
Validation loss: 1.5364864154528546

Epoch: 6| Step: 1
Training loss: 0.2687343955039978
Validation loss: 1.553940449991534

Epoch: 6| Step: 2
Training loss: 0.23776021599769592
Validation loss: 1.5245079263564079

Epoch: 6| Step: 3
Training loss: 0.2561084032058716
Validation loss: 1.5361892241303639

Epoch: 6| Step: 4
Training loss: 0.22444409132003784
Validation loss: 1.5429679680896062

Epoch: 6| Step: 5
Training loss: 0.24919980764389038
Validation loss: 1.5356941966600315

Epoch: 6| Step: 6
Training loss: 0.17489685118198395
Validation loss: 1.5440247635687552

Epoch: 6| Step: 7
Training loss: 0.10116217285394669
Validation loss: 1.5500696000232492

Epoch: 6| Step: 8
Training loss: 0.25731921195983887
Validation loss: 1.5448287789539625

Epoch: 6| Step: 9
Training loss: 0.39737167954444885
Validation loss: 1.5508889075248473

Epoch: 6| Step: 10
Training loss: 0.2527434229850769
Validation loss: 1.5240488231823008

Epoch: 6| Step: 11
Training loss: 0.23081284761428833
Validation loss: 1.5164223947832662

Epoch: 6| Step: 12
Training loss: 0.27479541301727295
Validation loss: 1.500926524080256

Epoch: 6| Step: 13
Training loss: 0.11896546930074692
Validation loss: 1.5222551604752899

Epoch: 405| Step: 0
Training loss: 0.20169246196746826
Validation loss: 1.488522155310518

Epoch: 6| Step: 1
Training loss: 0.22813746333122253
Validation loss: 1.5194227003282117

Epoch: 6| Step: 2
Training loss: 0.20399987697601318
Validation loss: 1.4836339284014959

Epoch: 6| Step: 3
Training loss: 0.3515394330024719
Validation loss: 1.509340832310338

Epoch: 6| Step: 4
Training loss: 0.16033127903938293
Validation loss: 1.5100670783750472

Epoch: 6| Step: 5
Training loss: 0.2964581847190857
Validation loss: 1.5163355514567385

Epoch: 6| Step: 6
Training loss: 0.35000377893447876
Validation loss: 1.5362041086278937

Epoch: 6| Step: 7
Training loss: 0.24183928966522217
Validation loss: 1.577079708858203

Epoch: 6| Step: 8
Training loss: 0.13688981533050537
Validation loss: 1.5645747992300219

Epoch: 6| Step: 9
Training loss: 0.19219011068344116
Validation loss: 1.5533793805747904

Epoch: 6| Step: 10
Training loss: 0.1295672059059143
Validation loss: 1.5634548561547392

Epoch: 6| Step: 11
Training loss: 0.17666034400463104
Validation loss: 1.5455717047055562

Epoch: 6| Step: 12
Training loss: 0.2532643675804138
Validation loss: 1.5555766064633605

Epoch: 6| Step: 13
Training loss: 0.3097018599510193
Validation loss: 1.5219762966197024

Epoch: 406| Step: 0
Training loss: 0.09423279017210007
Validation loss: 1.5469884141798942

Epoch: 6| Step: 1
Training loss: 0.2045208364725113
Validation loss: 1.5482902001309138

Epoch: 6| Step: 2
Training loss: 0.14259979128837585
Validation loss: 1.5356547890170928

Epoch: 6| Step: 3
Training loss: 0.16563883423805237
Validation loss: 1.5172465270565403

Epoch: 6| Step: 4
Training loss: 0.2904984951019287
Validation loss: 1.52343362762082

Epoch: 6| Step: 5
Training loss: 0.2317512035369873
Validation loss: 1.5171810991020613

Epoch: 6| Step: 6
Training loss: 0.17960286140441895
Validation loss: 1.5100178718566895

Epoch: 6| Step: 7
Training loss: 0.13012778759002686
Validation loss: 1.5101712621668333

Epoch: 6| Step: 8
Training loss: 0.29364365339279175
Validation loss: 1.526394171099509

Epoch: 6| Step: 9
Training loss: 0.2531113922595978
Validation loss: 1.5178148156853133

Epoch: 6| Step: 10
Training loss: 0.16865390539169312
Validation loss: 1.5191490957813878

Epoch: 6| Step: 11
Training loss: 0.12159398943185806
Validation loss: 1.511775303912419

Epoch: 6| Step: 12
Training loss: 0.20033684372901917
Validation loss: 1.5396369131662513

Epoch: 6| Step: 13
Training loss: 0.19366371631622314
Validation loss: 1.5214485878585486

Epoch: 407| Step: 0
Training loss: 0.26217490434646606
Validation loss: 1.536207410597032

Epoch: 6| Step: 1
Training loss: 0.33356544375419617
Validation loss: 1.5689025489232873

Epoch: 6| Step: 2
Training loss: 0.1417856067419052
Validation loss: 1.540033181508382

Epoch: 6| Step: 3
Training loss: 0.22870132327079773
Validation loss: 1.531353783863847

Epoch: 6| Step: 4
Training loss: 0.20143194496631622
Validation loss: 1.5537415768510552

Epoch: 6| Step: 5
Training loss: 0.13380204141139984
Validation loss: 1.510281962733115

Epoch: 6| Step: 6
Training loss: 0.2395695149898529
Validation loss: 1.5289849952984882

Epoch: 6| Step: 7
Training loss: 0.13014227151870728
Validation loss: 1.5353457350884714

Epoch: 6| Step: 8
Training loss: 0.31952568888664246
Validation loss: 1.527583772136319

Epoch: 6| Step: 9
Training loss: 0.21831507980823517
Validation loss: 1.5577338228943527

Epoch: 6| Step: 10
Training loss: 0.3689073324203491
Validation loss: 1.540271883369774

Epoch: 6| Step: 11
Training loss: 0.15109671652317047
Validation loss: 1.5232691059830368

Epoch: 6| Step: 12
Training loss: 0.16970713436603546
Validation loss: 1.5171046680019749

Epoch: 6| Step: 13
Training loss: 0.0715126097202301
Validation loss: 1.5276264541892595

Epoch: 408| Step: 0
Training loss: 0.16752903163433075
Validation loss: 1.5515191055113269

Epoch: 6| Step: 1
Training loss: 0.08899460732936859
Validation loss: 1.5343504054571993

Epoch: 6| Step: 2
Training loss: 0.330735445022583
Validation loss: 1.5590485129305112

Epoch: 6| Step: 3
Training loss: 0.23052316904067993
Validation loss: 1.5559061957943825

Epoch: 6| Step: 4
Training loss: 0.21443282067775726
Validation loss: 1.539963306919221

Epoch: 6| Step: 5
Training loss: 0.295477956533432
Validation loss: 1.529665530368846

Epoch: 6| Step: 6
Training loss: 0.184006929397583
Validation loss: 1.5533000781971922

Epoch: 6| Step: 7
Training loss: 0.23029480874538422
Validation loss: 1.558901281766994

Epoch: 6| Step: 8
Training loss: 0.18555666506290436
Validation loss: 1.579988759051087

Epoch: 6| Step: 9
Training loss: 0.1332082897424698
Validation loss: 1.579413466556098

Epoch: 6| Step: 10
Training loss: 0.15100052952766418
Validation loss: 1.5871114455243593

Epoch: 6| Step: 11
Training loss: 0.27572914958000183
Validation loss: 1.557734904750701

Epoch: 6| Step: 12
Training loss: 0.29499951004981995
Validation loss: 1.5521486548967258

Epoch: 6| Step: 13
Training loss: 0.10949528217315674
Validation loss: 1.5432163425671157

Epoch: 409| Step: 0
Training loss: 0.17099535465240479
Validation loss: 1.5369972234131188

Epoch: 6| Step: 1
Training loss: 0.23010504245758057
Validation loss: 1.513184799942919

Epoch: 6| Step: 2
Training loss: 0.22618967294692993
Validation loss: 1.5022820554753786

Epoch: 6| Step: 3
Training loss: 0.2906914949417114
Validation loss: 1.498899217574827

Epoch: 6| Step: 4
Training loss: 0.20087487995624542
Validation loss: 1.5221280692726054

Epoch: 6| Step: 5
Training loss: 0.17274482548236847
Validation loss: 1.5229984393683813

Epoch: 6| Step: 6
Training loss: 0.12939947843551636
Validation loss: 1.4962025021993985

Epoch: 6| Step: 7
Training loss: 0.16598552465438843
Validation loss: 1.488547122606667

Epoch: 6| Step: 8
Training loss: 0.21152189373970032
Validation loss: 1.5140103012002923

Epoch: 6| Step: 9
Training loss: 0.1354634165763855
Validation loss: 1.511748706140826

Epoch: 6| Step: 10
Training loss: 0.11795535683631897
Validation loss: 1.492861795169051

Epoch: 6| Step: 11
Training loss: 0.20316505432128906
Validation loss: 1.496104190426488

Epoch: 6| Step: 12
Training loss: 0.31347769498825073
Validation loss: 1.5392055690929454

Epoch: 6| Step: 13
Training loss: 0.26538729667663574
Validation loss: 1.5325202313802575

Epoch: 410| Step: 0
Training loss: 0.11348788440227509
Validation loss: 1.5320421970018776

Epoch: 6| Step: 1
Training loss: 0.211765855550766
Validation loss: 1.5643502755831646

Epoch: 6| Step: 2
Training loss: 0.35575395822525024
Validation loss: 1.5528680778318835

Epoch: 6| Step: 3
Training loss: 0.1408013552427292
Validation loss: 1.5422160869003625

Epoch: 6| Step: 4
Training loss: 0.2021258920431137
Validation loss: 1.5250447603964037

Epoch: 6| Step: 5
Training loss: 0.1074991524219513
Validation loss: 1.5247577505726968

Epoch: 6| Step: 6
Training loss: 0.21530300378799438
Validation loss: 1.519749769600489

Epoch: 6| Step: 7
Training loss: 0.20660267770290375
Validation loss: 1.4867047712367067

Epoch: 6| Step: 8
Training loss: 0.16027875244617462
Validation loss: 1.5114842896820397

Epoch: 6| Step: 9
Training loss: 0.10975567996501923
Validation loss: 1.4945884180325333

Epoch: 6| Step: 10
Training loss: 0.17519938945770264
Validation loss: 1.4705510139465332

Epoch: 6| Step: 11
Training loss: 0.2627166509628296
Validation loss: 1.5221627694304272

Epoch: 6| Step: 12
Training loss: 0.1679316759109497
Validation loss: 1.522357399745654

Epoch: 6| Step: 13
Training loss: 0.23172681033611298
Validation loss: 1.5057301457210253

Epoch: 411| Step: 0
Training loss: 0.21317757666110992
Validation loss: 1.5418532099775089

Epoch: 6| Step: 1
Training loss: 0.25929102301597595
Validation loss: 1.519196189859862

Epoch: 6| Step: 2
Training loss: 0.2725723683834076
Validation loss: 1.5351975015414658

Epoch: 6| Step: 3
Training loss: 0.17241311073303223
Validation loss: 1.5257578549846527

Epoch: 6| Step: 4
Training loss: 0.16462665796279907
Validation loss: 1.518934275514336

Epoch: 6| Step: 5
Training loss: 0.1409166157245636
Validation loss: 1.5175744090028989

Epoch: 6| Step: 6
Training loss: 0.1388164907693863
Validation loss: 1.5162174438917508

Epoch: 6| Step: 7
Training loss: 0.1837785691022873
Validation loss: 1.4859325091044109

Epoch: 6| Step: 8
Training loss: 0.32065272331237793
Validation loss: 1.4821352868951776

Epoch: 6| Step: 9
Training loss: 0.16113272309303284
Validation loss: 1.509282365922005

Epoch: 6| Step: 10
Training loss: 0.14287668466567993
Validation loss: 1.5267702558989167

Epoch: 6| Step: 11
Training loss: 0.14480236172676086
Validation loss: 1.5068979942670433

Epoch: 6| Step: 12
Training loss: 0.2496715486049652
Validation loss: 1.5662893069687711

Epoch: 6| Step: 13
Training loss: 0.08528876304626465
Validation loss: 1.5659421720812399

Epoch: 412| Step: 0
Training loss: 0.18848754465579987
Validation loss: 1.5452858094246156

Epoch: 6| Step: 1
Training loss: 0.15250885486602783
Validation loss: 1.5338516696806876

Epoch: 6| Step: 2
Training loss: 0.14234060049057007
Validation loss: 1.52758780987032

Epoch: 6| Step: 3
Training loss: 0.16753961145877838
Validation loss: 1.4889865895753265

Epoch: 6| Step: 4
Training loss: 0.28222358226776123
Validation loss: 1.488826367162889

Epoch: 6| Step: 5
Training loss: 0.2592829167842865
Validation loss: 1.485631303120685

Epoch: 6| Step: 6
Training loss: 0.28364020586013794
Validation loss: 1.4815570539043796

Epoch: 6| Step: 7
Training loss: 0.19514745473861694
Validation loss: 1.4743108159752303

Epoch: 6| Step: 8
Training loss: 0.24125893414020538
Validation loss: 1.4798903285816152

Epoch: 6| Step: 9
Training loss: 0.1286093145608902
Validation loss: 1.4806791915688464

Epoch: 6| Step: 10
Training loss: 0.13045985996723175
Validation loss: 1.475619089218878

Epoch: 6| Step: 11
Training loss: 0.2263398915529251
Validation loss: 1.5147026174811906

Epoch: 6| Step: 12
Training loss: 0.13895373046398163
Validation loss: 1.5571581266259635

Epoch: 6| Step: 13
Training loss: 0.1684219241142273
Validation loss: 1.5905147752454203

Epoch: 413| Step: 0
Training loss: 0.3272861838340759
Validation loss: 1.596710813942776

Epoch: 6| Step: 1
Training loss: 0.22574764490127563
Validation loss: 1.5507320524543844

Epoch: 6| Step: 2
Training loss: 0.14054162800312042
Validation loss: 1.5060855047677153

Epoch: 6| Step: 3
Training loss: 0.22357195615768433
Validation loss: 1.473232735869705

Epoch: 6| Step: 4
Training loss: 0.1480293869972229
Validation loss: 1.4623478029363899

Epoch: 6| Step: 5
Training loss: 0.24527090787887573
Validation loss: 1.4616519199904574

Epoch: 6| Step: 6
Training loss: 0.14129313826560974
Validation loss: 1.4594601572200816

Epoch: 6| Step: 7
Training loss: 0.16225752234458923
Validation loss: 1.444160694717079

Epoch: 6| Step: 8
Training loss: 0.22381484508514404
Validation loss: 1.4722860641376947

Epoch: 6| Step: 9
Training loss: 0.10423185676336288
Validation loss: 1.4691084969428279

Epoch: 6| Step: 10
Training loss: 0.14944426715373993
Validation loss: 1.4815334607196111

Epoch: 6| Step: 11
Training loss: 0.26784801483154297
Validation loss: 1.521608425724891

Epoch: 6| Step: 12
Training loss: 0.172402486205101
Validation loss: 1.4990676885010095

Epoch: 6| Step: 13
Training loss: 0.13374274969100952
Validation loss: 1.4912713843007241

Epoch: 414| Step: 0
Training loss: 0.11555676907300949
Validation loss: 1.4885577501789216

Epoch: 6| Step: 1
Training loss: 0.18250080943107605
Validation loss: 1.479482171356037

Epoch: 6| Step: 2
Training loss: 0.1291675567626953
Validation loss: 1.4910950006977204

Epoch: 6| Step: 3
Training loss: 0.18242479860782623
Validation loss: 1.5055760222096597

Epoch: 6| Step: 4
Training loss: 0.18350833654403687
Validation loss: 1.4969749822411487

Epoch: 6| Step: 5
Training loss: 0.13557344675064087
Validation loss: 1.4915020773487706

Epoch: 6| Step: 6
Training loss: 0.14201965928077698
Validation loss: 1.493432774979581

Epoch: 6| Step: 7
Training loss: 0.22197222709655762
Validation loss: 1.520623609583865

Epoch: 6| Step: 8
Training loss: 0.14293217658996582
Validation loss: 1.5375549793243408

Epoch: 6| Step: 9
Training loss: 0.2303498089313507
Validation loss: 1.529192416898666

Epoch: 6| Step: 10
Training loss: 0.3061666488647461
Validation loss: 1.5171075277431036

Epoch: 6| Step: 11
Training loss: 0.1366349309682846
Validation loss: 1.5229491572226248

Epoch: 6| Step: 12
Training loss: 0.1647416055202484
Validation loss: 1.5129211897491126

Epoch: 6| Step: 13
Training loss: 0.16266100108623505
Validation loss: 1.53588088609839

Epoch: 415| Step: 0
Training loss: 0.16792182624340057
Validation loss: 1.5319155993000153

Epoch: 6| Step: 1
Training loss: 0.12193432450294495
Validation loss: 1.546479699432209

Epoch: 6| Step: 2
Training loss: 0.1880565881729126
Validation loss: 1.5319753718632523

Epoch: 6| Step: 3
Training loss: 0.1473180651664734
Validation loss: 1.4951998802923387

Epoch: 6| Step: 4
Training loss: 0.22839736938476562
Validation loss: 1.4956905431644891

Epoch: 6| Step: 5
Training loss: 0.23643477261066437
Validation loss: 1.4953222915690432

Epoch: 6| Step: 6
Training loss: 0.10724559426307678
Validation loss: 1.5323792760090162

Epoch: 6| Step: 7
Training loss: 0.16330377757549286
Validation loss: 1.5265807977286718

Epoch: 6| Step: 8
Training loss: 0.2264491468667984
Validation loss: 1.5222007023390902

Epoch: 6| Step: 9
Training loss: 0.2816161811351776
Validation loss: 1.5250317230019519

Epoch: 6| Step: 10
Training loss: 0.3304741680622101
Validation loss: 1.5177596717752435

Epoch: 6| Step: 11
Training loss: 0.23050418496131897
Validation loss: 1.5200429263935293

Epoch: 6| Step: 12
Training loss: 0.10100268572568893
Validation loss: 1.5217564657170286

Epoch: 6| Step: 13
Training loss: 0.22294190526008606
Validation loss: 1.5208885464617001

Epoch: 416| Step: 0
Training loss: 0.2294209897518158
Validation loss: 1.5082682781322028

Epoch: 6| Step: 1
Training loss: 0.10644581913948059
Validation loss: 1.5163104290603309

Epoch: 6| Step: 2
Training loss: 0.21068036556243896
Validation loss: 1.51324829939873

Epoch: 6| Step: 3
Training loss: 0.19255681335926056
Validation loss: 1.5201652716564875

Epoch: 6| Step: 4
Training loss: 0.13712745904922485
Validation loss: 1.4966547181529384

Epoch: 6| Step: 5
Training loss: 0.07672905176877975
Validation loss: 1.4778994629459996

Epoch: 6| Step: 6
Training loss: 0.211319237947464
Validation loss: 1.49805365198402

Epoch: 6| Step: 7
Training loss: 0.14410626888275146
Validation loss: 1.5126625235362718

Epoch: 6| Step: 8
Training loss: 0.10338984429836273
Validation loss: 1.5221603903719174

Epoch: 6| Step: 9
Training loss: 0.13532738387584686
Validation loss: 1.500994320838682

Epoch: 6| Step: 10
Training loss: 0.07525311410427094
Validation loss: 1.56571243398933

Epoch: 6| Step: 11
Training loss: 0.19419938325881958
Validation loss: 1.5434066249478249

Epoch: 6| Step: 12
Training loss: 0.27890992164611816
Validation loss: 1.5693873641311482

Epoch: 6| Step: 13
Training loss: 0.31327906250953674
Validation loss: 1.5608166552359057

Epoch: 417| Step: 0
Training loss: 0.1370987892150879
Validation loss: 1.5143500374209495

Epoch: 6| Step: 1
Training loss: 0.19292739033699036
Validation loss: 1.5227364532409176

Epoch: 6| Step: 2
Training loss: 0.24336402118206024
Validation loss: 1.5368078036974835

Epoch: 6| Step: 3
Training loss: 0.25995904207229614
Validation loss: 1.5375392693345264

Epoch: 6| Step: 4
Training loss: 0.2570630609989166
Validation loss: 1.516036295121716

Epoch: 6| Step: 5
Training loss: 0.14665132761001587
Validation loss: 1.5310583486351916

Epoch: 6| Step: 6
Training loss: 0.14035093784332275
Validation loss: 1.4949693500354726

Epoch: 6| Step: 7
Training loss: 0.13052552938461304
Validation loss: 1.5374974435375584

Epoch: 6| Step: 8
Training loss: 0.2037748545408249
Validation loss: 1.5210361288439842

Epoch: 6| Step: 9
Training loss: 0.1548246145248413
Validation loss: 1.5119361185258435

Epoch: 6| Step: 10
Training loss: 0.21288302540779114
Validation loss: 1.5000254595151512

Epoch: 6| Step: 11
Training loss: 0.12078358232975006
Validation loss: 1.5314799137012933

Epoch: 6| Step: 12
Training loss: 0.19431431591510773
Validation loss: 1.5115889118563743

Epoch: 6| Step: 13
Training loss: 0.4410000443458557
Validation loss: 1.5312694221414545

Epoch: 418| Step: 0
Training loss: 0.15309664607048035
Validation loss: 1.559409620300416

Epoch: 6| Step: 1
Training loss: 0.21727705001831055
Validation loss: 1.6055230748268865

Epoch: 6| Step: 2
Training loss: 0.39747416973114014
Validation loss: 1.5825847528314079

Epoch: 6| Step: 3
Training loss: 0.2496694028377533
Validation loss: 1.591435650343536

Epoch: 6| Step: 4
Training loss: 0.12213566899299622
Validation loss: 1.560815586838671

Epoch: 6| Step: 5
Training loss: 0.1560916304588318
Validation loss: 1.5521546666340162

Epoch: 6| Step: 6
Training loss: 0.19099821150302887
Validation loss: 1.5252444090381745

Epoch: 6| Step: 7
Training loss: 0.21594849228858948
Validation loss: 1.5148432395791496

Epoch: 6| Step: 8
Training loss: 0.2824280261993408
Validation loss: 1.5073225216198993

Epoch: 6| Step: 9
Training loss: 0.12075641751289368
Validation loss: 1.5108987990246023

Epoch: 6| Step: 10
Training loss: 0.14313870668411255
Validation loss: 1.511458658402966

Epoch: 6| Step: 11
Training loss: 0.1447795331478119
Validation loss: 1.5293129887632144

Epoch: 6| Step: 12
Training loss: 0.15822531282901764
Validation loss: 1.5459175520045783

Epoch: 6| Step: 13
Training loss: 0.12826788425445557
Validation loss: 1.5256556477597965

Epoch: 419| Step: 0
Training loss: 0.12133536487817764
Validation loss: 1.5372949601501547

Epoch: 6| Step: 1
Training loss: 0.18691232800483704
Validation loss: 1.506832222784719

Epoch: 6| Step: 2
Training loss: 0.1393316686153412
Validation loss: 1.514570229796953

Epoch: 6| Step: 3
Training loss: 0.18835146725177765
Validation loss: 1.5488378450434694

Epoch: 6| Step: 4
Training loss: 0.20471172034740448
Validation loss: 1.5551639231302405

Epoch: 6| Step: 5
Training loss: 0.1321989893913269
Validation loss: 1.5491435015073387

Epoch: 6| Step: 6
Training loss: 0.20970815420150757
Validation loss: 1.5371145509904431

Epoch: 6| Step: 7
Training loss: 0.14847518503665924
Validation loss: 1.5337098849717008

Epoch: 6| Step: 8
Training loss: 0.23734581470489502
Validation loss: 1.5484525977924306

Epoch: 6| Step: 9
Training loss: 0.22003662586212158
Validation loss: 1.5101249448714718

Epoch: 6| Step: 10
Training loss: 0.29892873764038086
Validation loss: 1.536094602077238

Epoch: 6| Step: 11
Training loss: 0.22690296173095703
Validation loss: 1.5302414612103534

Epoch: 6| Step: 12
Training loss: 0.13070720434188843
Validation loss: 1.4995597754755328

Epoch: 6| Step: 13
Training loss: 0.2597636282444
Validation loss: 1.5038300393730082

Epoch: 420| Step: 0
Training loss: 0.20733073353767395
Validation loss: 1.489302276283182

Epoch: 6| Step: 1
Training loss: 0.2335090935230255
Validation loss: 1.476502990209928

Epoch: 6| Step: 2
Training loss: 0.1538577675819397
Validation loss: 1.478774978268531

Epoch: 6| Step: 3
Training loss: 0.21509090065956116
Validation loss: 1.4775965136866416

Epoch: 6| Step: 4
Training loss: 0.10258114337921143
Validation loss: 1.52893159210041

Epoch: 6| Step: 5
Training loss: 0.18164917826652527
Validation loss: 1.5242990537356305

Epoch: 6| Step: 6
Training loss: 0.23515787720680237
Validation loss: 1.5522792928962297

Epoch: 6| Step: 7
Training loss: 0.15962575376033783
Validation loss: 1.550509581001856

Epoch: 6| Step: 8
Training loss: 0.17850345373153687
Validation loss: 1.559710624397442

Epoch: 6| Step: 9
Training loss: 0.16643941402435303
Validation loss: 1.543166051628769

Epoch: 6| Step: 10
Training loss: 0.09704992175102234
Validation loss: 1.5430438390342138

Epoch: 6| Step: 11
Training loss: 0.18716229498386383
Validation loss: 1.5550935781130226

Epoch: 6| Step: 12
Training loss: 0.1951921284198761
Validation loss: 1.5596220095952351

Epoch: 6| Step: 13
Training loss: 0.08432472497224808
Validation loss: 1.5242659430350027

Epoch: 421| Step: 0
Training loss: 0.11690741777420044
Validation loss: 1.517710308874807

Epoch: 6| Step: 1
Training loss: 0.2029401659965515
Validation loss: 1.513659522097598

Epoch: 6| Step: 2
Training loss: 0.15407176315784454
Validation loss: 1.5187814145959833

Epoch: 6| Step: 3
Training loss: 0.10902675986289978
Validation loss: 1.4917991853529406

Epoch: 6| Step: 4
Training loss: 0.1203099936246872
Validation loss: 1.4939823509544454

Epoch: 6| Step: 5
Training loss: 0.1453726589679718
Validation loss: 1.4813156051020469

Epoch: 6| Step: 6
Training loss: 0.20580865442752838
Validation loss: 1.5031154360822452

Epoch: 6| Step: 7
Training loss: 0.13600191473960876
Validation loss: 1.4867589627542803

Epoch: 6| Step: 8
Training loss: 0.13487645983695984
Validation loss: 1.484127434351111

Epoch: 6| Step: 9
Training loss: 0.1611330509185791
Validation loss: 1.4616673543889036

Epoch: 6| Step: 10
Training loss: 0.1998012214899063
Validation loss: 1.5049809948090584

Epoch: 6| Step: 11
Training loss: 0.17209407687187195
Validation loss: 1.520711750112554

Epoch: 6| Step: 12
Training loss: 0.26312410831451416
Validation loss: 1.4962888981706353

Epoch: 6| Step: 13
Training loss: 0.3082699775695801
Validation loss: 1.5180147117184055

Epoch: 422| Step: 0
Training loss: 0.1355392336845398
Validation loss: 1.5109947317390031

Epoch: 6| Step: 1
Training loss: 0.08471468836069107
Validation loss: 1.4889128656797512

Epoch: 6| Step: 2
Training loss: 0.1888314187526703
Validation loss: 1.4885977878365466

Epoch: 6| Step: 3
Training loss: 0.1694478690624237
Validation loss: 1.5026850335059627

Epoch: 6| Step: 4
Training loss: 0.23372794687747955
Validation loss: 1.500782710249706

Epoch: 6| Step: 5
Training loss: 0.14333990216255188
Validation loss: 1.485870667683181

Epoch: 6| Step: 6
Training loss: 0.2249128818511963
Validation loss: 1.5100292121210406

Epoch: 6| Step: 7
Training loss: 0.14297571778297424
Validation loss: 1.4829334302615094

Epoch: 6| Step: 8
Training loss: 0.11710567772388458
Validation loss: 1.4892662225231048

Epoch: 6| Step: 9
Training loss: 0.2178533524274826
Validation loss: 1.5154882932222018

Epoch: 6| Step: 10
Training loss: 0.07179306447505951
Validation loss: 1.5011603691244637

Epoch: 6| Step: 11
Training loss: 0.15202844142913818
Validation loss: 1.5123139222462971

Epoch: 6| Step: 12
Training loss: 0.11179880797863007
Validation loss: 1.5210982932839343

Epoch: 6| Step: 13
Training loss: 0.09870988875627518
Validation loss: 1.522155136831345

Epoch: 423| Step: 0
Training loss: 0.18311402201652527
Validation loss: 1.531530443058219

Epoch: 6| Step: 1
Training loss: 0.20432375371456146
Validation loss: 1.5097438667410163

Epoch: 6| Step: 2
Training loss: 0.08231142163276672
Validation loss: 1.5275301125741774

Epoch: 6| Step: 3
Training loss: 0.21052144467830658
Validation loss: 1.5227669304417026

Epoch: 6| Step: 4
Training loss: 0.15927718579769135
Validation loss: 1.514594320328005

Epoch: 6| Step: 5
Training loss: 0.16128508746623993
Validation loss: 1.5231097077810636

Epoch: 6| Step: 6
Training loss: 0.1372784823179245
Validation loss: 1.5406065974184262

Epoch: 6| Step: 7
Training loss: 0.16265636682510376
Validation loss: 1.5374119057450244

Epoch: 6| Step: 8
Training loss: 0.20512092113494873
Validation loss: 1.5269673780728412

Epoch: 6| Step: 9
Training loss: 0.1507485806941986
Validation loss: 1.509405512963572

Epoch: 6| Step: 10
Training loss: 0.09832267463207245
Validation loss: 1.554464813201658

Epoch: 6| Step: 11
Training loss: 0.1385873258113861
Validation loss: 1.5544422698277298

Epoch: 6| Step: 12
Training loss: 0.1793534755706787
Validation loss: 1.5329976838122132

Epoch: 6| Step: 13
Training loss: 0.08538997173309326
Validation loss: 1.5555499580598646

Epoch: 424| Step: 0
Training loss: 0.08823460340499878
Validation loss: 1.5296015829168341

Epoch: 6| Step: 1
Training loss: 0.15935710072517395
Validation loss: 1.5131270359921198

Epoch: 6| Step: 2
Training loss: 0.06784828752279282
Validation loss: 1.507459903276095

Epoch: 6| Step: 3
Training loss: 0.15283501148223877
Validation loss: 1.5222913013991488

Epoch: 6| Step: 4
Training loss: 0.1957521140575409
Validation loss: 1.4984829207902313

Epoch: 6| Step: 5
Training loss: 0.25258970260620117
Validation loss: 1.5073193375782301

Epoch: 6| Step: 6
Training loss: 0.08908949792385101
Validation loss: 1.5089062099815698

Epoch: 6| Step: 7
Training loss: 0.10121320188045502
Validation loss: 1.5236758403880621

Epoch: 6| Step: 8
Training loss: 0.1856679916381836
Validation loss: 1.5269936899985037

Epoch: 6| Step: 9
Training loss: 0.14231008291244507
Validation loss: 1.5344286682785198

Epoch: 6| Step: 10
Training loss: 0.307971715927124
Validation loss: 1.5318894117109236

Epoch: 6| Step: 11
Training loss: 0.14037305116653442
Validation loss: 1.5363489325328539

Epoch: 6| Step: 12
Training loss: 0.15030357241630554
Validation loss: 1.507006167083658

Epoch: 6| Step: 13
Training loss: 0.14063170552253723
Validation loss: 1.4881645505146315

Epoch: 425| Step: 0
Training loss: 0.10857955366373062
Validation loss: 1.4841041385486562

Epoch: 6| Step: 1
Training loss: 0.13786324858665466
Validation loss: 1.4812066837023663

Epoch: 6| Step: 2
Training loss: 0.15151552855968475
Validation loss: 1.4909608729424015

Epoch: 6| Step: 3
Training loss: 0.20068588852882385
Validation loss: 1.4993812140598093

Epoch: 6| Step: 4
Training loss: 0.18800555169582367
Validation loss: 1.4748536412433912

Epoch: 6| Step: 5
Training loss: 0.07508081197738647
Validation loss: 1.4664882120265756

Epoch: 6| Step: 6
Training loss: 0.11839279532432556
Validation loss: 1.4823894628914454

Epoch: 6| Step: 7
Training loss: 0.18116286396980286
Validation loss: 1.4745831476744784

Epoch: 6| Step: 8
Training loss: 0.1305398941040039
Validation loss: 1.5065994313968125

Epoch: 6| Step: 9
Training loss: 0.29417896270751953
Validation loss: 1.5102897305642404

Epoch: 6| Step: 10
Training loss: 0.21650484204292297
Validation loss: 1.5176817883727372

Epoch: 6| Step: 11
Training loss: 0.09045493602752686
Validation loss: 1.5333267693878503

Epoch: 6| Step: 12
Training loss: 0.2289792001247406
Validation loss: 1.52354226445639

Epoch: 6| Step: 13
Training loss: 0.15424683690071106
Validation loss: 1.5447207702103483

Epoch: 426| Step: 0
Training loss: 0.17234274744987488
Validation loss: 1.5692531498529578

Epoch: 6| Step: 1
Training loss: 0.20267528295516968
Validation loss: 1.5402215539768178

Epoch: 6| Step: 2
Training loss: 0.18808391690254211
Validation loss: 1.5437183803127659

Epoch: 6| Step: 3
Training loss: 0.15640626847743988
Validation loss: 1.5109310842329455

Epoch: 6| Step: 4
Training loss: 0.12149914354085922
Validation loss: 1.5121518065852504

Epoch: 6| Step: 5
Training loss: 0.07231341302394867
Validation loss: 1.5215839083476732

Epoch: 6| Step: 6
Training loss: 0.15257519483566284
Validation loss: 1.5124851695952877

Epoch: 6| Step: 7
Training loss: 0.13284766674041748
Validation loss: 1.528699823605117

Epoch: 6| Step: 8
Training loss: 0.2350492924451828
Validation loss: 1.5401809574455343

Epoch: 6| Step: 9
Training loss: 0.18107321858406067
Validation loss: 1.5443493473914363

Epoch: 6| Step: 10
Training loss: 0.18745100498199463
Validation loss: 1.5464719354465444

Epoch: 6| Step: 11
Training loss: 0.10296483337879181
Validation loss: 1.5119143468077465

Epoch: 6| Step: 12
Training loss: 0.20772799849510193
Validation loss: 1.5197292265071665

Epoch: 6| Step: 13
Training loss: 0.20129020512104034
Validation loss: 1.5125118327397171

Epoch: 427| Step: 0
Training loss: 0.19380220770835876
Validation loss: 1.521121346822349

Epoch: 6| Step: 1
Training loss: 0.14675965905189514
Validation loss: 1.4995163140758392

Epoch: 6| Step: 2
Training loss: 0.19017398357391357
Validation loss: 1.4872421949140486

Epoch: 6| Step: 3
Training loss: 0.11248088628053665
Validation loss: 1.4915874440182921

Epoch: 6| Step: 4
Training loss: 0.12846773862838745
Validation loss: 1.494047684054221

Epoch: 6| Step: 5
Training loss: 0.15162846446037292
Validation loss: 1.4723029213566934

Epoch: 6| Step: 6
Training loss: 0.15676012635231018
Validation loss: 1.470719696373068

Epoch: 6| Step: 7
Training loss: 0.10473576188087463
Validation loss: 1.499634104390298

Epoch: 6| Step: 8
Training loss: 0.13696429133415222
Validation loss: 1.4876775613395117

Epoch: 6| Step: 9
Training loss: 0.2589450478553772
Validation loss: 1.5168387492497761

Epoch: 6| Step: 10
Training loss: 0.16120800375938416
Validation loss: 1.5093390377618934

Epoch: 6| Step: 11
Training loss: 0.11343127489089966
Validation loss: 1.5356047063745477

Epoch: 6| Step: 12
Training loss: 0.13543672859668732
Validation loss: 1.5154758768696939

Epoch: 6| Step: 13
Training loss: 0.280347615480423
Validation loss: 1.567195007877965

Epoch: 428| Step: 0
Training loss: 0.20285668969154358
Validation loss: 1.5700685337025633

Epoch: 6| Step: 1
Training loss: 0.19073864817619324
Validation loss: 1.5583231269672353

Epoch: 6| Step: 2
Training loss: 0.1780562698841095
Validation loss: 1.5636868681958926

Epoch: 6| Step: 3
Training loss: 0.09189155697822571
Validation loss: 1.5355064561290126

Epoch: 6| Step: 4
Training loss: 0.11652226746082306
Validation loss: 1.4986220123947307

Epoch: 6| Step: 5
Training loss: 0.19010719656944275
Validation loss: 1.463989975631878

Epoch: 6| Step: 6
Training loss: 0.084591343998909
Validation loss: 1.476245451998967

Epoch: 6| Step: 7
Training loss: 0.14878535270690918
Validation loss: 1.4642849429961173

Epoch: 6| Step: 8
Training loss: 0.10824140906333923
Validation loss: 1.4328812783764255

Epoch: 6| Step: 9
Training loss: 0.13724514842033386
Validation loss: 1.4773892779504099

Epoch: 6| Step: 10
Training loss: 0.09651695191860199
Validation loss: 1.4318719961309945

Epoch: 6| Step: 11
Training loss: 0.10394023358821869
Validation loss: 1.4456280803167691

Epoch: 6| Step: 12
Training loss: 0.12263184785842896
Validation loss: 1.4448650767726283

Epoch: 6| Step: 13
Training loss: 0.2444312870502472
Validation loss: 1.450771709924103

Epoch: 429| Step: 0
Training loss: 0.10065457224845886
Validation loss: 1.4539309111974572

Epoch: 6| Step: 1
Training loss: 0.12787312269210815
Validation loss: 1.4364140418268019

Epoch: 6| Step: 2
Training loss: 0.1683916300535202
Validation loss: 1.4315360451257357

Epoch: 6| Step: 3
Training loss: 0.08316751569509506
Validation loss: 1.4492068957257014

Epoch: 6| Step: 4
Training loss: 0.11687353998422623
Validation loss: 1.4384869349900113

Epoch: 6| Step: 5
Training loss: 0.22381538152694702
Validation loss: 1.431832213555613

Epoch: 6| Step: 6
Training loss: 0.1153382658958435
Validation loss: 1.4439964704616095

Epoch: 6| Step: 7
Training loss: 0.11677616089582443
Validation loss: 1.454188100753292

Epoch: 6| Step: 8
Training loss: 0.1519273817539215
Validation loss: 1.481586069189092

Epoch: 6| Step: 9
Training loss: 0.17354407906532288
Validation loss: 1.4726382638177564

Epoch: 6| Step: 10
Training loss: 0.18328183889389038
Validation loss: 1.4978141002757575

Epoch: 6| Step: 11
Training loss: 0.21095655858516693
Validation loss: 1.4727689425150554

Epoch: 6| Step: 12
Training loss: 0.12010078132152557
Validation loss: 1.5012871180811236

Epoch: 6| Step: 13
Training loss: 0.1907828152179718
Validation loss: 1.50568139296706

Epoch: 430| Step: 0
Training loss: 0.13115525245666504
Validation loss: 1.5174577825812883

Epoch: 6| Step: 1
Training loss: 0.15557590126991272
Validation loss: 1.525660212321948

Epoch: 6| Step: 2
Training loss: 0.2945311665534973
Validation loss: 1.5321576723488428

Epoch: 6| Step: 3
Training loss: 0.1909884810447693
Validation loss: 1.5412042551143195

Epoch: 6| Step: 4
Training loss: 0.20390433073043823
Validation loss: 1.5585154333422262

Epoch: 6| Step: 5
Training loss: 0.15872152149677277
Validation loss: 1.54208759210443

Epoch: 6| Step: 6
Training loss: 0.22979439795017242
Validation loss: 1.5454173716165687

Epoch: 6| Step: 7
Training loss: 0.2157929390668869
Validation loss: 1.5471472329990839

Epoch: 6| Step: 8
Training loss: 0.10039199143648148
Validation loss: 1.5315555757091892

Epoch: 6| Step: 9
Training loss: 0.11076825857162476
Validation loss: 1.4948659532813615

Epoch: 6| Step: 10
Training loss: 0.14460569620132446
Validation loss: 1.4880350059078586

Epoch: 6| Step: 11
Training loss: 0.16608917713165283
Validation loss: 1.4622991905417493

Epoch: 6| Step: 12
Training loss: 0.09184609353542328
Validation loss: 1.445361073299121

Epoch: 6| Step: 13
Training loss: 0.13142754137516022
Validation loss: 1.470417861015566

Epoch: 431| Step: 0
Training loss: 0.139469712972641
Validation loss: 1.46650650424342

Epoch: 6| Step: 1
Training loss: 0.17660541832447052
Validation loss: 1.4604234362161288

Epoch: 6| Step: 2
Training loss: 0.1435643434524536
Validation loss: 1.4399358649407663

Epoch: 6| Step: 3
Training loss: 0.1661859005689621
Validation loss: 1.4608098563327585

Epoch: 6| Step: 4
Training loss: 0.17254522442817688
Validation loss: 1.4646426375194261

Epoch: 6| Step: 5
Training loss: 0.2218777984380722
Validation loss: 1.485217805831663

Epoch: 6| Step: 6
Training loss: 0.16918377578258514
Validation loss: 1.4955140762431647

Epoch: 6| Step: 7
Training loss: 0.15901786088943481
Validation loss: 1.4760432961166545

Epoch: 6| Step: 8
Training loss: 0.10782353579998016
Validation loss: 1.4527493590308773

Epoch: 6| Step: 9
Training loss: 0.20350325107574463
Validation loss: 1.459420419508411

Epoch: 6| Step: 10
Training loss: 0.07744824886322021
Validation loss: 1.4753269046865485

Epoch: 6| Step: 11
Training loss: 0.13070130348205566
Validation loss: 1.4731512101747657

Epoch: 6| Step: 12
Training loss: 0.12270595133304596
Validation loss: 1.468568685234234

Epoch: 6| Step: 13
Training loss: 0.15011222660541534
Validation loss: 1.5065915764019053

Epoch: 432| Step: 0
Training loss: 0.12757983803749084
Validation loss: 1.5209628958855905

Epoch: 6| Step: 1
Training loss: 0.25293493270874023
Validation loss: 1.5229371440026067

Epoch: 6| Step: 2
Training loss: 0.1193983405828476
Validation loss: 1.5186618745967906

Epoch: 6| Step: 3
Training loss: 0.11998142302036285
Validation loss: 1.4870424116811445

Epoch: 6| Step: 4
Training loss: 0.22326165437698364
Validation loss: 1.4610986953140588

Epoch: 6| Step: 5
Training loss: 0.1393771767616272
Validation loss: 1.4897201074066984

Epoch: 6| Step: 6
Training loss: 0.16259025037288666
Validation loss: 1.491797157513198

Epoch: 6| Step: 7
Training loss: 0.21831396222114563
Validation loss: 1.4858184040233653

Epoch: 6| Step: 8
Training loss: 0.13067491352558136
Validation loss: 1.5010718658406248

Epoch: 6| Step: 9
Training loss: 0.1511020064353943
Validation loss: 1.4913436674302625

Epoch: 6| Step: 10
Training loss: 0.1364710032939911
Validation loss: 1.4895253091730096

Epoch: 6| Step: 11
Training loss: 0.07736483216285706
Validation loss: 1.5017934242884319

Epoch: 6| Step: 12
Training loss: 0.21729035675525665
Validation loss: 1.477409790920955

Epoch: 6| Step: 13
Training loss: 0.18155309557914734
Validation loss: 1.4929907373202744

Epoch: 433| Step: 0
Training loss: 0.10316227376461029
Validation loss: 1.5126283630248039

Epoch: 6| Step: 1
Training loss: 0.17154046893119812
Validation loss: 1.4805242976834696

Epoch: 6| Step: 2
Training loss: 0.07160867750644684
Validation loss: 1.4940878454075064

Epoch: 6| Step: 3
Training loss: 0.13434189558029175
Validation loss: 1.4836144190962597

Epoch: 6| Step: 4
Training loss: 0.1570349931716919
Validation loss: 1.488864020634723

Epoch: 6| Step: 5
Training loss: 0.21001000702381134
Validation loss: 1.4752358646803005

Epoch: 6| Step: 6
Training loss: 0.19020146131515503
Validation loss: 1.4895388131500573

Epoch: 6| Step: 7
Training loss: 0.06467036157846451
Validation loss: 1.4935869939865605

Epoch: 6| Step: 8
Training loss: 0.15983912348747253
Validation loss: 1.482315686441237

Epoch: 6| Step: 9
Training loss: 0.1168375313282013
Validation loss: 1.4703721295120895

Epoch: 6| Step: 10
Training loss: 0.22664393484592438
Validation loss: 1.471640552884789

Epoch: 6| Step: 11
Training loss: 0.17385828495025635
Validation loss: 1.4848467880679714

Epoch: 6| Step: 12
Training loss: 0.14582009613513947
Validation loss: 1.4915364544878724

Epoch: 6| Step: 13
Training loss: 0.061259374022483826
Validation loss: 1.5005639214669504

Epoch: 434| Step: 0
Training loss: 0.08460099995136261
Validation loss: 1.4893145266399588

Epoch: 6| Step: 1
Training loss: 0.16638439893722534
Validation loss: 1.525770245059844

Epoch: 6| Step: 2
Training loss: 0.17911291122436523
Validation loss: 1.5137333562297206

Epoch: 6| Step: 3
Training loss: 0.11317266523838043
Validation loss: 1.5099268690232308

Epoch: 6| Step: 4
Training loss: 0.20948748290538788
Validation loss: 1.5293259556575487

Epoch: 6| Step: 5
Training loss: 0.10920803248882294
Validation loss: 1.487657896934017

Epoch: 6| Step: 6
Training loss: 0.07938302308320999
Validation loss: 1.4915225102055458

Epoch: 6| Step: 7
Training loss: 0.13497322797775269
Validation loss: 1.5376292223571448

Epoch: 6| Step: 8
Training loss: 0.1570124477148056
Validation loss: 1.5201149268816876

Epoch: 6| Step: 9
Training loss: 0.19157065451145172
Validation loss: 1.5147457186893751

Epoch: 6| Step: 10
Training loss: 0.22623001039028168
Validation loss: 1.4890065705904396

Epoch: 6| Step: 11
Training loss: 0.15447835624217987
Validation loss: 1.5202677916455012

Epoch: 6| Step: 12
Training loss: 0.22645938396453857
Validation loss: 1.5030631416587419

Epoch: 6| Step: 13
Training loss: 0.15470750629901886
Validation loss: 1.4969243375203942

Epoch: 435| Step: 0
Training loss: 0.12312853336334229
Validation loss: 1.497969191561463

Epoch: 6| Step: 1
Training loss: 0.1469590961933136
Validation loss: 1.5444684310625958

Epoch: 6| Step: 2
Training loss: 0.14694932103157043
Validation loss: 1.5188909166602678

Epoch: 6| Step: 3
Training loss: 0.07971427589654922
Validation loss: 1.518230676651001

Epoch: 6| Step: 4
Training loss: 0.203817218542099
Validation loss: 1.5218421733507546

Epoch: 6| Step: 5
Training loss: 0.14678877592086792
Validation loss: 1.4979766671375563

Epoch: 6| Step: 6
Training loss: 0.10692644119262695
Validation loss: 1.5087285951901508

Epoch: 6| Step: 7
Training loss: 0.1290326714515686
Validation loss: 1.5253700338384157

Epoch: 6| Step: 8
Training loss: 0.11508996039628983
Validation loss: 1.5270532036340365

Epoch: 6| Step: 9
Training loss: 0.27589207887649536
Validation loss: 1.5889951926405712

Epoch: 6| Step: 10
Training loss: 0.24954798817634583
Validation loss: 1.5464578661867368

Epoch: 6| Step: 11
Training loss: 0.11713657528162003
Validation loss: 1.5070303460603118

Epoch: 6| Step: 12
Training loss: 0.10566166043281555
Validation loss: 1.494010950929375

Epoch: 6| Step: 13
Training loss: 0.10681667923927307
Validation loss: 1.4999134643103487

Epoch: 436| Step: 0
Training loss: 0.11124923080205917
Validation loss: 1.5039698154695573

Epoch: 6| Step: 1
Training loss: 0.2233618050813675
Validation loss: 1.5126355482685951

Epoch: 6| Step: 2
Training loss: 0.09850449860095978
Validation loss: 1.506350532654793

Epoch: 6| Step: 3
Training loss: 0.18615317344665527
Validation loss: 1.5123294514994468

Epoch: 6| Step: 4
Training loss: 0.12287023663520813
Validation loss: 1.5258707218272711

Epoch: 6| Step: 5
Training loss: 0.20726102590560913
Validation loss: 1.5345353221380582

Epoch: 6| Step: 6
Training loss: 0.1497746855020523
Validation loss: 1.5182908299148723

Epoch: 6| Step: 7
Training loss: 0.26644763350486755
Validation loss: 1.5509214708881993

Epoch: 6| Step: 8
Training loss: 0.08418622612953186
Validation loss: 1.5678567142896755

Epoch: 6| Step: 9
Training loss: 0.13690660893917084
Validation loss: 1.5297714497453423

Epoch: 6| Step: 10
Training loss: 0.135238915681839
Validation loss: 1.5459369805551344

Epoch: 6| Step: 11
Training loss: 0.11975464224815369
Validation loss: 1.531372247203704

Epoch: 6| Step: 12
Training loss: 0.11219760775566101
Validation loss: 1.5405935689967165

Epoch: 6| Step: 13
Training loss: 0.0963042750954628
Validation loss: 1.5506209019691712

Epoch: 437| Step: 0
Training loss: 0.14853687584400177
Validation loss: 1.5172487920330417

Epoch: 6| Step: 1
Training loss: 0.08219723403453827
Validation loss: 1.505255542775636

Epoch: 6| Step: 2
Training loss: 0.1295277178287506
Validation loss: 1.4995252227270475

Epoch: 6| Step: 3
Training loss: 0.10257086157798767
Validation loss: 1.5261833411391064

Epoch: 6| Step: 4
Training loss: 0.11526986211538315
Validation loss: 1.5443402362126175

Epoch: 6| Step: 5
Training loss: 0.2632429003715515
Validation loss: 1.540760863211847

Epoch: 6| Step: 6
Training loss: 0.1739451140165329
Validation loss: 1.5075718600262877

Epoch: 6| Step: 7
Training loss: 0.0904068797826767
Validation loss: 1.5265300440531906

Epoch: 6| Step: 8
Training loss: 0.11585326492786407
Validation loss: 1.5281026786373508

Epoch: 6| Step: 9
Training loss: 0.13033810257911682
Validation loss: 1.52096184479293

Epoch: 6| Step: 10
Training loss: 0.12041014432907104
Validation loss: 1.5264030605234125

Epoch: 6| Step: 11
Training loss: 0.18355460464954376
Validation loss: 1.517403079617408

Epoch: 6| Step: 12
Training loss: 0.20323500037193298
Validation loss: 1.513871471087138

Epoch: 6| Step: 13
Training loss: 0.09819385409355164
Validation loss: 1.5337901705054826

Epoch: 438| Step: 0
Training loss: 0.11209744960069656
Validation loss: 1.513069382277868

Epoch: 6| Step: 1
Training loss: 0.16049310564994812
Validation loss: 1.5335227597144343

Epoch: 6| Step: 2
Training loss: 0.07143720239400864
Validation loss: 1.5271664357954455

Epoch: 6| Step: 3
Training loss: 0.12741020321846008
Validation loss: 1.4982905541696856

Epoch: 6| Step: 4
Training loss: 0.09543545544147491
Validation loss: 1.4973151119806434

Epoch: 6| Step: 5
Training loss: 0.1441512107849121
Validation loss: 1.4980735163534842

Epoch: 6| Step: 6
Training loss: 0.14263102412223816
Validation loss: 1.5308270172406269

Epoch: 6| Step: 7
Training loss: 0.15593485534191132
Validation loss: 1.5029857761116439

Epoch: 6| Step: 8
Training loss: 0.11202578991651535
Validation loss: 1.5120510414082518

Epoch: 6| Step: 9
Training loss: 0.17774580419063568
Validation loss: 1.5106850144683674

Epoch: 6| Step: 10
Training loss: 0.1897590160369873
Validation loss: 1.5378756817950998

Epoch: 6| Step: 11
Training loss: 0.05718577653169632
Validation loss: 1.5428209804719495

Epoch: 6| Step: 12
Training loss: 0.17935045063495636
Validation loss: 1.5491263315241823

Epoch: 6| Step: 13
Training loss: 0.16772760450839996
Validation loss: 1.5263060882527342

Epoch: 439| Step: 0
Training loss: 0.0946999117732048
Validation loss: 1.52443649179192

Epoch: 6| Step: 1
Training loss: 0.11380792409181595
Validation loss: 1.5009829177651355

Epoch: 6| Step: 2
Training loss: 0.12185706198215485
Validation loss: 1.488987644513448

Epoch: 6| Step: 3
Training loss: 0.21221667528152466
Validation loss: 1.4874559397338538

Epoch: 6| Step: 4
Training loss: 0.272560715675354
Validation loss: 1.4962680647450108

Epoch: 6| Step: 5
Training loss: 0.1517913043498993
Validation loss: 1.4985811184811335

Epoch: 6| Step: 6
Training loss: 0.21359843015670776
Validation loss: 1.4739635567511282

Epoch: 6| Step: 7
Training loss: 0.15149565041065216
Validation loss: 1.5033411082401071

Epoch: 6| Step: 8
Training loss: 0.19120115041732788
Validation loss: 1.506898242940185

Epoch: 6| Step: 9
Training loss: 0.10691632330417633
Validation loss: 1.528793046551366

Epoch: 6| Step: 10
Training loss: 0.07825683802366257
Validation loss: 1.520524339650267

Epoch: 6| Step: 11
Training loss: 0.14053954184055328
Validation loss: 1.5534765861367668

Epoch: 6| Step: 12
Training loss: 0.18386484682559967
Validation loss: 1.5547138260256859

Epoch: 6| Step: 13
Training loss: 0.09761478006839752
Validation loss: 1.5090821302065285

Epoch: 440| Step: 0
Training loss: 0.10877848416566849
Validation loss: 1.4917456129545807

Epoch: 6| Step: 1
Training loss: 0.10770232230424881
Validation loss: 1.462027967617076

Epoch: 6| Step: 2
Training loss: 0.13674578070640564
Validation loss: 1.4841739695559266

Epoch: 6| Step: 3
Training loss: 0.2223503440618515
Validation loss: 1.4650400812907884

Epoch: 6| Step: 4
Training loss: 0.19561974704265594
Validation loss: 1.4530116447838404

Epoch: 6| Step: 5
Training loss: 0.19994014501571655
Validation loss: 1.464607145196648

Epoch: 6| Step: 6
Training loss: 0.12866534292697906
Validation loss: 1.4709257951346777

Epoch: 6| Step: 7
Training loss: 0.10113201290369034
Validation loss: 1.4852774835401965

Epoch: 6| Step: 8
Training loss: 0.10067050158977509
Validation loss: 1.5165046786749234

Epoch: 6| Step: 9
Training loss: 0.1887049823999405
Validation loss: 1.5193406112732426

Epoch: 6| Step: 10
Training loss: 0.22567827999591827
Validation loss: 1.4941057453873337

Epoch: 6| Step: 11
Training loss: 0.16405093669891357
Validation loss: 1.5073370497713807

Epoch: 6| Step: 12
Training loss: 0.17912012338638306
Validation loss: 1.4771790171182284

Epoch: 6| Step: 13
Training loss: 0.0471959263086319
Validation loss: 1.4721592062263078

Epoch: 441| Step: 0
Training loss: 0.21134662628173828
Validation loss: 1.5121299169396842

Epoch: 6| Step: 1
Training loss: 0.12521600723266602
Validation loss: 1.485641876856486

Epoch: 6| Step: 2
Training loss: 0.1629602015018463
Validation loss: 1.478684397153957

Epoch: 6| Step: 3
Training loss: 0.11774919927120209
Validation loss: 1.4694913177080051

Epoch: 6| Step: 4
Training loss: 0.10172820836305618
Validation loss: 1.512516269119837

Epoch: 6| Step: 5
Training loss: 0.18433623015880585
Validation loss: 1.4871703078669887

Epoch: 6| Step: 6
Training loss: 0.08115079998970032
Validation loss: 1.493045655629968

Epoch: 6| Step: 7
Training loss: 0.16229455173015594
Validation loss: 1.5270037279334119

Epoch: 6| Step: 8
Training loss: 0.14069414138793945
Validation loss: 1.5092532493734871

Epoch: 6| Step: 9
Training loss: 0.051823556423187256
Validation loss: 1.5073520342508953

Epoch: 6| Step: 10
Training loss: 0.1763327568769455
Validation loss: 1.5070602393919421

Epoch: 6| Step: 11
Training loss: 0.07901410758495331
Validation loss: 1.510897736395559

Epoch: 6| Step: 12
Training loss: 0.09156715869903564
Validation loss: 1.5290324277775262

Epoch: 6| Step: 13
Training loss: 0.13443167507648468
Validation loss: 1.4941785463722803

Epoch: 442| Step: 0
Training loss: 0.07623142749071121
Validation loss: 1.488436742495465

Epoch: 6| Step: 1
Training loss: 0.12651509046554565
Validation loss: 1.5094353101586784

Epoch: 6| Step: 2
Training loss: 0.21631136536598206
Validation loss: 1.4927103814258371

Epoch: 6| Step: 3
Training loss: 0.18582473695278168
Validation loss: 1.511389038896048

Epoch: 6| Step: 4
Training loss: 0.09665699303150177
Validation loss: 1.4989610218232678

Epoch: 6| Step: 5
Training loss: 0.1629059910774231
Validation loss: 1.450912764636419

Epoch: 6| Step: 6
Training loss: 0.15192854404449463
Validation loss: 1.4526979987339308

Epoch: 6| Step: 7
Training loss: 0.1691131889820099
Validation loss: 1.4539437499097598

Epoch: 6| Step: 8
Training loss: 0.1719816029071808
Validation loss: 1.4475899332313127

Epoch: 6| Step: 9
Training loss: 0.17379742860794067
Validation loss: 1.4649744995178715

Epoch: 6| Step: 10
Training loss: 0.14993074536323547
Validation loss: 1.4432665660817137

Epoch: 6| Step: 11
Training loss: 0.09288324415683746
Validation loss: 1.4552246383441392

Epoch: 6| Step: 12
Training loss: 0.19184845685958862
Validation loss: 1.4711261981277055

Epoch: 6| Step: 13
Training loss: 0.1290225237607956
Validation loss: 1.5114620923995972

Epoch: 443| Step: 0
Training loss: 0.13512177765369415
Validation loss: 1.490986131852673

Epoch: 6| Step: 1
Training loss: 0.09933707863092422
Validation loss: 1.5103553418190248

Epoch: 6| Step: 2
Training loss: 0.07323507964611053
Validation loss: 1.502276970494178

Epoch: 6| Step: 3
Training loss: 0.13911470770835876
Validation loss: 1.5052756032636088

Epoch: 6| Step: 4
Training loss: 0.08232706785202026
Validation loss: 1.5182125286389423

Epoch: 6| Step: 5
Training loss: 0.08583668619394302
Validation loss: 1.5074510599977227

Epoch: 6| Step: 6
Training loss: 0.14195552468299866
Validation loss: 1.516458022978998

Epoch: 6| Step: 7
Training loss: 0.1211124062538147
Validation loss: 1.5189064292497532

Epoch: 6| Step: 8
Training loss: 0.24199245870113373
Validation loss: 1.5266367696946668

Epoch: 6| Step: 9
Training loss: 0.19127464294433594
Validation loss: 1.535454994888716

Epoch: 6| Step: 10
Training loss: 0.09367451071739197
Validation loss: 1.533342440923055

Epoch: 6| Step: 11
Training loss: 0.2417028248310089
Validation loss: 1.5101530731365245

Epoch: 6| Step: 12
Training loss: 0.1762746125459671
Validation loss: 1.5521442928621847

Epoch: 6| Step: 13
Training loss: 0.21013309061527252
Validation loss: 1.5481293765447472

Epoch: 444| Step: 0
Training loss: 0.20742735266685486
Validation loss: 1.541762521190028

Epoch: 6| Step: 1
Training loss: 0.10589836537837982
Validation loss: 1.5102121253167429

Epoch: 6| Step: 2
Training loss: 0.11893913894891739
Validation loss: 1.506336505695056

Epoch: 6| Step: 3
Training loss: 0.13495680689811707
Validation loss: 1.4991491853549916

Epoch: 6| Step: 4
Training loss: 0.10599270462989807
Validation loss: 1.4632180211364583

Epoch: 6| Step: 5
Training loss: 0.15557822585105896
Validation loss: 1.4978257802224928

Epoch: 6| Step: 6
Training loss: 0.11200220882892609
Validation loss: 1.504754824664003

Epoch: 6| Step: 7
Training loss: 0.17480571568012238
Validation loss: 1.5280408551616054

Epoch: 6| Step: 8
Training loss: 0.10006550699472427
Validation loss: 1.5320770330326532

Epoch: 6| Step: 9
Training loss: 0.121908999979496
Validation loss: 1.4972169713307453

Epoch: 6| Step: 10
Training loss: 0.09344911575317383
Validation loss: 1.5240919589996338

Epoch: 6| Step: 11
Training loss: 0.25291940569877625
Validation loss: 1.4955865926640008

Epoch: 6| Step: 12
Training loss: 0.13693121075630188
Validation loss: 1.4976086065333376

Epoch: 6| Step: 13
Training loss: 0.27264726161956787
Validation loss: 1.498941501622559

Epoch: 445| Step: 0
Training loss: 0.22617751359939575
Validation loss: 1.467134024507256

Epoch: 6| Step: 1
Training loss: 0.13928793370723724
Validation loss: 1.4832000424785

Epoch: 6| Step: 2
Training loss: 0.08713272213935852
Validation loss: 1.4872618413740588

Epoch: 6| Step: 3
Training loss: 0.17086046934127808
Validation loss: 1.4789760138398858

Epoch: 6| Step: 4
Training loss: 0.08947202563285828
Validation loss: 1.4778297447389173

Epoch: 6| Step: 5
Training loss: 0.08369921147823334
Validation loss: 1.5039112619174424

Epoch: 6| Step: 6
Training loss: 0.12250479310750961
Validation loss: 1.483091736352572

Epoch: 6| Step: 7
Training loss: 0.18013642728328705
Validation loss: 1.4568682947466451

Epoch: 6| Step: 8
Training loss: 0.15831533074378967
Validation loss: 1.493121567592826

Epoch: 6| Step: 9
Training loss: 0.13289758563041687
Validation loss: 1.4887597945428663

Epoch: 6| Step: 10
Training loss: 0.11608900874853134
Validation loss: 1.4910754003832418

Epoch: 6| Step: 11
Training loss: 0.14243128895759583
Validation loss: 1.486427108446757

Epoch: 6| Step: 12
Training loss: 0.1617986559867859
Validation loss: 1.5006548973821825

Epoch: 6| Step: 13
Training loss: 0.12423893809318542
Validation loss: 1.4802896604743054

Epoch: 446| Step: 0
Training loss: 0.0849444717168808
Validation loss: 1.4925438255392096

Epoch: 6| Step: 1
Training loss: 0.12080702185630798
Validation loss: 1.50516209038355

Epoch: 6| Step: 2
Training loss: 0.1514969915151596
Validation loss: 1.488095615499763

Epoch: 6| Step: 3
Training loss: 0.15269684791564941
Validation loss: 1.4757234550291491

Epoch: 6| Step: 4
Training loss: 0.12873120605945587
Validation loss: 1.4736429324714087

Epoch: 6| Step: 5
Training loss: 0.14835961163043976
Validation loss: 1.4809340251389371

Epoch: 6| Step: 6
Training loss: 0.15771810710430145
Validation loss: 1.47909277613445

Epoch: 6| Step: 7
Training loss: 0.057811811566352844
Validation loss: 1.4666666138556697

Epoch: 6| Step: 8
Training loss: 0.1419355273246765
Validation loss: 1.4749710611117783

Epoch: 6| Step: 9
Training loss: 0.09840675443410873
Validation loss: 1.4941578757378362

Epoch: 6| Step: 10
Training loss: 0.18622927367687225
Validation loss: 1.461267186749366

Epoch: 6| Step: 11
Training loss: 0.07242988049983978
Validation loss: 1.4835212563955655

Epoch: 6| Step: 12
Training loss: 0.0871717557311058
Validation loss: 1.4787455476740354

Epoch: 6| Step: 13
Training loss: 0.09912994503974915
Validation loss: 1.4928660264579199

Epoch: 447| Step: 0
Training loss: 0.12050972878932953
Validation loss: 1.4752287839048652

Epoch: 6| Step: 1
Training loss: 0.2315138578414917
Validation loss: 1.4613448048150668

Epoch: 6| Step: 2
Training loss: 0.08078764379024506
Validation loss: 1.4707816371353724

Epoch: 6| Step: 3
Training loss: 0.06475099921226501
Validation loss: 1.4559503402761234

Epoch: 6| Step: 4
Training loss: 0.1236436516046524
Validation loss: 1.4462823271751404

Epoch: 6| Step: 5
Training loss: 0.10031798481941223
Validation loss: 1.4502458226296209

Epoch: 6| Step: 6
Training loss: 0.12305998057126999
Validation loss: 1.4380101055227301

Epoch: 6| Step: 7
Training loss: 0.13558204472064972
Validation loss: 1.4706359653062717

Epoch: 6| Step: 8
Training loss: 0.12830278277397156
Validation loss: 1.46686182355368

Epoch: 6| Step: 9
Training loss: 0.08984100073575974
Validation loss: 1.461417406476954

Epoch: 6| Step: 10
Training loss: 0.07109248638153076
Validation loss: 1.4596872464303048

Epoch: 6| Step: 11
Training loss: 0.08007551729679108
Validation loss: 1.4509563311453788

Epoch: 6| Step: 12
Training loss: 0.16024281084537506
Validation loss: 1.46300918568847

Epoch: 6| Step: 13
Training loss: 0.1616220772266388
Validation loss: 1.4663320228617678

Epoch: 448| Step: 0
Training loss: 0.1081341877579689
Validation loss: 1.4818900528774466

Epoch: 6| Step: 1
Training loss: 0.11786762624979019
Validation loss: 1.4553354658106321

Epoch: 6| Step: 2
Training loss: 0.21548058092594147
Validation loss: 1.4625819575402044

Epoch: 6| Step: 3
Training loss: 0.09446005523204803
Validation loss: 1.4657869223625428

Epoch: 6| Step: 4
Training loss: 0.14654698967933655
Validation loss: 1.4754299861128612

Epoch: 6| Step: 5
Training loss: 0.08407904207706451
Validation loss: 1.5146873856103549

Epoch: 6| Step: 6
Training loss: 0.1631828099489212
Validation loss: 1.5027624932668542

Epoch: 6| Step: 7
Training loss: 0.09207531809806824
Validation loss: 1.477234963447817

Epoch: 6| Step: 8
Training loss: 0.10910458117723465
Validation loss: 1.4955154118999359

Epoch: 6| Step: 9
Training loss: 0.1102105975151062
Validation loss: 1.4703341286669496

Epoch: 6| Step: 10
Training loss: 0.1698800027370453
Validation loss: 1.4764455095414193

Epoch: 6| Step: 11
Training loss: 0.20087014138698578
Validation loss: 1.4773048072732904

Epoch: 6| Step: 12
Training loss: 0.25321075320243835
Validation loss: 1.4592072630441317

Epoch: 6| Step: 13
Training loss: 0.17629879713058472
Validation loss: 1.5163103713784167

Epoch: 449| Step: 0
Training loss: 0.14935022592544556
Validation loss: 1.486831772711969

Epoch: 6| Step: 1
Training loss: 0.14883030951023102
Validation loss: 1.5462298970068655

Epoch: 6| Step: 2
Training loss: 0.10019822418689728
Validation loss: 1.536247181636031

Epoch: 6| Step: 3
Training loss: 0.13618488609790802
Validation loss: 1.5337730658951627

Epoch: 6| Step: 4
Training loss: 0.11333108693361282
Validation loss: 1.4995000349578036

Epoch: 6| Step: 5
Training loss: 0.14273326098918915
Validation loss: 1.509018821101035

Epoch: 6| Step: 6
Training loss: 0.22024348378181458
Validation loss: 1.5118142956046647

Epoch: 6| Step: 7
Training loss: 0.14595265686511993
Validation loss: 1.4663487999669966

Epoch: 6| Step: 8
Training loss: 0.11373193562030792
Validation loss: 1.4673620795690885

Epoch: 6| Step: 9
Training loss: 0.12116102874279022
Validation loss: 1.4670042607092089

Epoch: 6| Step: 10
Training loss: 0.09154853224754333
Validation loss: 1.4745738717817491

Epoch: 6| Step: 11
Training loss: 0.10363353043794632
Validation loss: 1.4720828994627921

Epoch: 6| Step: 12
Training loss: 0.21769271790981293
Validation loss: 1.4724198964334303

Epoch: 6| Step: 13
Training loss: 0.24290138483047485
Validation loss: 1.4784628242574713

Epoch: 450| Step: 0
Training loss: 0.1274683177471161
Validation loss: 1.46597372716473

Epoch: 6| Step: 1
Training loss: 0.08827026188373566
Validation loss: 1.4529554068401296

Epoch: 6| Step: 2
Training loss: 0.07179830968379974
Validation loss: 1.436725672855172

Epoch: 6| Step: 3
Training loss: 0.07816153019666672
Validation loss: 1.452116411219361

Epoch: 6| Step: 4
Training loss: 0.0923597514629364
Validation loss: 1.4416582879199777

Epoch: 6| Step: 5
Training loss: 0.15997076034545898
Validation loss: 1.4413896517087055

Epoch: 6| Step: 6
Training loss: 0.13500180840492249
Validation loss: 1.4822869903297835

Epoch: 6| Step: 7
Training loss: 0.15961554646492004
Validation loss: 1.4845331766272103

Epoch: 6| Step: 8
Training loss: 0.2060137391090393
Validation loss: 1.5102133430460447

Epoch: 6| Step: 9
Training loss: 0.1414344608783722
Validation loss: 1.5160971315958167

Epoch: 6| Step: 10
Training loss: 0.22700995206832886
Validation loss: 1.5289837288600143

Epoch: 6| Step: 11
Training loss: 0.14960414171218872
Validation loss: 1.5459769015671105

Epoch: 6| Step: 12
Training loss: 0.16521018743515015
Validation loss: 1.5509645644054617

Epoch: 6| Step: 13
Training loss: 0.15645435452461243
Validation loss: 1.5190547050968293

Testing loss: 2.161446327633328
